{"patent_id": "10-2019-0159149", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2021-0069389", "출원번호": "10-2019-0159149", "발명의 명칭": "인공지능 기반의 단층촬영 영상 인공음영 제거 방법 및 장치", "출원인": "서울대학교산학협력단", "발명자": "예성준"}}
{"patent_id": "10-2019-0159149", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "인공지능 기반의 단층촬영 영상 인공음영 제거 방법으로서, 단층촬영기 또는 영상 저장 장치를 통해 메탈 인공 구조물이 삽입되지 않은 신체 부위의 단층촬영 영상을 획득하는 단계;상기 단층촬영 영상에 인공 메탈 형태(artificial metal shape)가 삽입된 영상을 생성하는 단계;상기 인공 메탈 형태가 삽입된 단층촬영 영상으로부터 인공음영이 생성된 영상을 획득하는 단계;상기 인공 메탈 형태가 삽입된 단층촬영 영상과 상기 인공음영이 생성된 영상의 쌍을 이용하여 딥러닝 기반의인공음영 제거 모델을 학습하는 단계; 및메탈 인공 구조물이 삽입된 신체 부위의 단층촬영 영상으로부터 상기 딥러닝 기반의 인공음영 제거 모델에 기초하여 인공음영이 제거된 영상을 생성하는 단계;를 포함하는 것을 특징으로 하는 단층촬영 영상 인공음영 제거방법."}
{"patent_id": "10-2019-0159149", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 인공음영이 생성된 영상을 획득하는 단계는,사이노그램(sinogram) 기법에 기반하여 라돈 변환(radon transform)을 통해 상기 인공 메탈 형태가 삽입된 단층촬영 영상으로부터 상기 인공음영이 생성된 영상을 획득하는 단계를 포함하는 것을 특징으로 하는 단층촬영 영상 인공음영 제거 방법."}
{"patent_id": "10-2019-0159149", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,상기 인공음영이 생성된 영상을 획득하는 단계는,상기 인공 메탈 형태가 삽입된 단층촬영 영상을 라돈 변환하는 단계;상기 인공 메탈 형태만 있는 영상을 라돈 변환하는 단계; 및상기 인공 메탈 형태가 삽입된 단층촬영 영상의 라돈 변환 결과와 상기 인공 메탈 형태만 있는 영상의 라돈 변환 결과를 연산한 결과를 역 라돈 변환하는 단계;를 포함하는 것을 특징으로 하는 단층촬영 영상 인공음영 제거방법."}
{"patent_id": "10-2019-0159149", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서, 상기 역 라돈 변환하는 단계는, 상기 인공 메탈 형태가 삽입된 단층촬영 영상의 라돈 변환 결과에 상기 인공 메탈 형태만 있는 영상의 라돈 변환 결과와 상수 k를 연산하여 더한 결과를 역 라돈 변환하는 단계;를 포함하고, 상기 상수 k는 상기 인공 메탈 형태의 모양과 크기에 따라 변하는 것을 특징으로 하는 단층촬영 영상 인공음영제거 방법."}
{"patent_id": "10-2019-0159149", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서, 공개특허 10-2021-0069389-3-상기 딥러닝 기반의 인공음영 제거 모델은, 바이리니어 업샘플링(bilinear upsampling)과 스트라이디드 컨볼루션(strided convolution)을 포함하는 것을 특징으로 하는 단층촬영 영상 인공음영 제거 방법."}
{"patent_id": "10-2019-0159149", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "단층촬영 영상 인공음영 제거 장치로서, 영상을 출력하는 출력부;단층촬영 영상을 얻기 위해 단층촬영기 또는 영상 저장 장치와의 연동을 제어하는 제어부;를 포함하고, 상기 제어부는, 상기 단층촬영기 또는 상기 영상 저장 장치를 통해 메탈 인공 구조물이 삽입되지 않은 신체 부위의 단층촬영 영상을 획득하고, 상기 단층촬영 영상에 인공 메탈 형태가 삽입된 영상을 생성하고, 상기 인공메탈 형태가 삽입된 단층촬영 영상으로부터 인공음영이 생성된 영상을 획득하고, 상기 인공 메탈 형태가 삽입된단층촬영 영상과 상기 인공음영이 생성된 영상의 쌍을 이용하여 딥러닝 기반의 인공음영 제거 모델을 학습하고,메탈 인공 구조물이 삽입된 신체 부위의 단층촬영 영상으로부터 상기 딥러닝 기반의 인공음영 제거 모델에 기초하여 인공음영이 제거된 영상을 생성하도록 제어하는 것을 특징으로 하는 단층촬영 영상 인공음영 제거 장치."}
{"patent_id": "10-2019-0159149", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6항에 있어서,상기 제어부는, 사이노그램 기법에 기반하여 라돈 변환을 통해 상기 인공 메탈 형태가 삽입된 단층촬영 영상으로부터 상기 인공음영이 생성된 영상을 획득하도록 제어하는 것을 특징으로 하는 단층촬영 영상 인공음영 제거 장치."}
{"patent_id": "10-2019-0159149", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서,상기 제어부는, 상기 인공 메탈 형태가 삽입된 단층촬영 영상을 라돈 변환하고, 상기 인공 메탈 형태만 있는 영상을 라돈 변환하고, 상기 인공 메탈 형태가 삽입된 단층촬영 영상의 라돈 변환 결과와 상기 인공 메탈 형태만 있는 영상의 라돈 변환 결과를 연산한 결과를 역 라돈 변환하도록 제어하는 것을 특징으로 하는 단층촬영 영상 인공음영 제거장치."}
{"patent_id": "10-2019-0159149", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서,상기 제어부는, 상기 인공 메탈 형태가 삽입된 단층촬영 영상의 라돈 변환 결과에 상기 인공 메탈 형태만 있는 영상의 라돈 변환 결과와 상수 k를 연산하여 더한 결과를 역 라돈 변환하도록 제어하고, 상기 상수 k는 상기 인공 메탈 형태의 모양과 크기에 따라 변하는 것을 특징으로 하는 단층촬영 영상 인공음영제거 장치."}
{"patent_id": "10-2019-0159149", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제6항에 있어서,상기 딥러닝 기반의 인공음영 제거 모델은, 바이리니어 업샘플링(bilinear upsampling)과 스트라이디드 컨볼루션(strided convolution)을 포함하는 것을 특징으로 하는 단층촬영 영상 인공음영 제거 장치."}
{"patent_id": "10-2019-0159149", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "인공지능 기반의 단층촬영 영상 인공음영 제거 방법은, 단층촬영기 또는 영상 저장 장치를 통해 메탈 인공 구조 물이 삽입되지 않은 신체 부위의 단층촬영 영상을 획득하는 단계, 상기 단층촬영 영상에 인공 메탈 형태가 삽입 된 영상을 생성하는 단계, 상기 인공 메탈 형태가 삽입된 단층촬영 영상으로부터 인공음영이 생성된 영상을 획득 하는 단계, 상기 인공 메탈 형태가 삽입된 단층촬영 영상과 상기 인공음영이 생성된 영상의 쌍을 이용하여 딥러 닝 기반의 인공음영 제거 모델을 학습하는 단계 및 메탈 인공 구조물이 삽입된 신체 부위의 단층촬영 영상으로부 터 상기 딥러닝 기반의 인공음영 제거 모델에 기초하여 인공음영이 제거된 영상을 생성하는 단계를 포함한다. 또 한, 단층촬영 영상 인공음영 제거 장치는, 영상을 출력하는 출력부와 단층촬영 영상을 얻기 위해 단층촬영기 또 는 영상 저장 장치와의 연동을 제어하고, 상술한 단계들을 제어하는 제어부를 포함한다."}
{"patent_id": "10-2019-0159149", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 인공지능 기반 단층촬영 영상 인공음영 제거 방법 및 장치에 관한 것으로서, 구체적으로 딥러닝 모델 의 학습을 위한 가상의 데이터 생성을 통한 인공지능 기반의 단층촬영 영상 인공음영 제거 방법 및 장치에 관한 것이다."}
{"patent_id": "10-2019-0159149", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "일반적으로 컴퓨터 단층촬영(computed tomography, CT)에서 사용되는 X-선 등 광원은 다양한 에너지 대역폭을 갖는다. 물질은 광원에 대한 고유한 흡수 계수(attenuation coefficient)를 가지며, 흡수 계수는 에너지 대역에 따라 다른 값이다. X-선 단층촬영에서 투영을 통해 측정된 영상은 인공음영을 갖는 경우가 있다. 특히, 밀도가 큰 금속성 물질에 대하여 인공음영이 강하게 나타나며, 일부 금속성 물질은 X-선 투과도가 상당히 낮아 광자가 이러한 금속성 물 질을 전혀 투과하지 못하며, 심각한 정도의 인공음영이 생성될 수 있다. 도 1a는 인체에 메탈 보철물 등의 메탈 인공 구조물이 삽입된 경우, 단층촬영된 이미지를 도시한다. 도 1a에 도 시된 바와 같이, 메탈 인공 구조물에 의해 인체 구성 성분에 비해 심한 인공음영이 생성된다. 인체에 삽입된 메 탈 인공 구조물은 그 주위에 강한 값(striking artifact) 및 어두운 음영(shading artifact)를 발생시킬 수 있 다. 이러한 메탈 인공음영은 메탈 인공 구조물의 실제 모양을 정확하게 알기 어렵게 하고, 실제 체내 구조와 보 철물이 인접한 경우 실제 체내 구조 및 인공 구조물 사이에 어두운 인공음영을 발생시켜 양자 간의 구분을 어렵 게 한다. 이러한 메탈 인공 구조물에 의한 인공음영을 제거하기 위한 방법으로, 다양한 인공음영 제거 알고리즘이 논의되 어 왔다(예를 들어, O-MAR, Smart MAR, MARs, 등). 도 1b에는 도 1a와 같이 획득된 인공음영이 포함된 단층촬영 된 이미지로부터 O-MAR 방식에 의해 인공음영이 제거된 단층촬영 이미지가 도시된다. 그러나, 도 1b에 도시된 바와 같이, 종래의 알고리즘을 이용하여 인공음영이 제거된 이미지는 실제 조직 이미지 가 함께 지워지는 등, 실제 인체 내의 조직과 가까운 이미지를 얻는 데 어려움이 있었다. 예를 들어, 도 1b의 종래의 알고리즘을 이용하여 인공음영이 제거된 이미지에서 A 영역과 같이 신체 조직으로 보이는 부위(A 영역의 경우, 뼈)가 지워질 수 있고, B 영역과 같이 신체의 캐비티 영역에 어떤 조직이 형성된 것처럼 보일 수도 있어, 의학적 진단 또는 판단을 어렵게 할 수 있다. 따라서, 메탈 인공음영을 적절히 제거하여 실제 메탈 인공 구조물이 없는 상태의 단층촬영과 가까운 영상을 획 득하는 것을 가능하도록 하는 방안이 필요하다. 선행기술문헌 특허문헌 (특허문헌 0001) 한국특허등록공보 제10-1056287호(공개일 2011.08.11.)"}
{"patent_id": "10-2019-0159149", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 전술한 필요성을 감안하여 안출된 것으로서, 인공지능 알고리즘을 이용한 학습을 통해 메탈 인공 구 조물이 없는 실제 단층촬영 영상에 가까운 영상을 얻기 위해, 인공 메탈 형태(artificial metal shape)가 삽입 된 영상과 이로부터 인공음영이 생성된 영상을 역으로 획득하여 학습을 위한 데이터 쌍을 생성하고, 학습된 모 델을 이용하여 단층촬영 영상 인공음영 제거 방법 및 장치를 제공함에 그 목적이 있다. 본 발명이 이루고자 하는 기술적 과제는 이상에서 언급한 기술적 과제들로 제한되지 않으며, 언급되지 않은 또"}
{"patent_id": "10-2019-0159149", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 2, "content": "다른 기술적 과제들은 아래의 기재로부터 본 발명이 속하는 기술분야에서 통상의 지식을 가진 자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2019-0159149", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "전술한 목적을 달성하기 위해, 본 발명의 일 측면에 따르면, 인공지능 기반의 단층촬영 영상 인공음영 제거 방 법은, 단층촬영기 또는 영상 저장 장치를 통해 메탈 인공 구조물이 삽입되지 않은 신체 부위의 단층촬영 영상을획득하는 단계, 상기 단층촬영 영상에 인공 메탈 형태가 삽입된 영상을 생성하는 단계, 상기 인공 메탈 형태가 삽입된 단층촬영 영상으로부터 인공음영이 생성된 영상을 획득하는 단계, 상기 인공 메탈 형태가 삽입된 단층촬 영 영상과 상기 인공음영이 생성된 영상의 쌍을 이용하여 딥러닝 기반의 인공음영 제거 모델을 학습하는 단계 및 메탈 인공 구조물이 삽입된 신체 부위의 단층촬영 영상으로부터 상기 딥러닝 기반의 인공음영 제거 모델에 기초하여 인공음영이 제거된 영상을 생성하는 단계를 포함한다. 본 발명의 일 실시예에 따르면, 상기 인공음영이 생성된 영상을 획득하는 단계는, 사이노그램(sinogram) 기법에 기반하여 라돈 변환(radon transform)을 통해 상기 인공 메탈 형태가 삽입된 단층촬영 영상으로부터 상기 인공 음영이 생성된 영상을 획득하는 단계를 포함할 수 있다. 본 발명의 일 실시예에 따르면, 상기 인공음영이 생성된 영상을 획득하는 단계는, 상기 인공 메탈 형태가 삽입 된 단층촬영 영상을 라돈 변환하는 단계, 상기 인공 메탈 형태만 있는 영상을 라돈 변환하는 단계 및 상기 인공 메탈 형태가 삽입된 단층촬영 영상의 라돈 변환 결과와 상기 인공 메탈 형태만 있는 영상의 라돈 변환 결과를 연산한 결과를 역 라돈 변환하는 단계를 포함할 수 있다. 본 발명의 일 실시예에 따르면, 상기 역 라돈 변환하는 단계는, 상기 인공 메탈 형태가 삽입된 단층촬영 영상의 라돈 변환 결과에 상기 인공 메탈 형태만 있는 영상의 라돈 변환 결과와 상수 k를 연산하여 더한 결과를 역 라 돈 변환하는 단계를 포함하고, 상기 상수 k는 상기 인공 메탈 형태의 모양과 크기에 따라 변할 수 있다. 본 발명의 일 실시예에 따르면, 상기 딥러닝 기반의 인공음영 제거 모델은, 바이리니어 업샘플링(bilinear upsampling)과 스트라이디드 컨볼루션(strided convolution)을 포함할 수 있다. 본 발명의 다른 일 측면에 따르면, 단층촬영 영상 인공음영 제거 장치는, 영상을 출력하는 출력부, 단층촬영 영 상을 얻기 위해 단층촬영기 또는 영상 저장 장치와의 연동을 제어하는 제어부를 포함하고, 상기 제어부는, 상기 단층촬영기 또는 상기 영장 저장 장치를 통해 메탈 인공 구조물이 삽입되지 않은 신체 부위의 단층촬영 영상을 획득하고, 상기 단층촬영 영상에 인공 메탈 형태가 삽입된 영상을 생성하고, 상기 인공 메탈 형태가 삽입된 단 층촬영 영상으로부터 인공음영이 생성된 영상을 획득하고, 상기 인공 메탈 형태가 삽입된 단층촬영 영상과 상기 인공음영이 생성된 영상의 쌍을 이용하여 딥러닝 기반의 인공음영 제거 모델을 학습하고, 메탈 인공 구조물이 삽입된 신체 부위의 단층촬영 영상으로부터 상기 딥러닝 기반의 인공음영 제거 모델에 기초하여 인공음영이 제 거된 영상을 생성하도록 제어한다. 본 발명의 일 실시예에 따르면, 상기 제어부는, 사이노그램 기법에 기반하여 라돈 변환을 통해 상기 인공 메탈 형태가 삽입된 단층촬영 영상으로부터 상기 인공음영이 생성된 영상을 획득하도록 제어할 수 있다. 본 발명의 일 실시예에 따르면, 상기 제어부는, 상기 인공 메탈 형태가 삽입된 단층촬영 영상을 라돈 변환하고, 상기 인공 메탈 형태만 있는 영상을 라돈 변환하고, 상기 인공 메탈 형태가 삽입된 단층촬영 영상의 라돈 변환 결과와 상기 인공 메탈 형태만 있는 영상의 라돈 변환 결과를 연산한 결과를 역 라돈 변환하도록 제어할 수 있 다. 본 발명의 일 실시예에 따르면, 상기 제어부는, 상기 인공 메탈 형태가 삽입된 단층촬영 영상의 라돈 변환 결과 에 상기 인공 메탈 형태만 있는 영상의 라돈 변환 결과와 상수 k를 연산하여 더한 결과를 역 라돈 변환하도록 제어하고, 상기 상수 k는 상기 인공 메탈 형태의 모양과 크기에 따라 변할 수 있다."}
{"patent_id": "10-2019-0159149", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명의 인공지능 기반의 단층촬영 영상 인공음영 제거 방법 및 장치에 따르면, 인공지능 알고리즘에 기반하 여 학습된 인공음영 제거 모델을 이용하여 메탈 인공음영이 효과적으로 제거된 단층촬영 영상을 얻을 수 있다. 이를 위해, 메탈 인공 구조물이 없는 단층촬영 영상으로부터 인공 메탈 형태가 삽입된 영상을 생성하고, 이로부 터 인공음영이 생성된 영상을 획득하여 학습을 위한 적절한 데이터 쌍을 제공할 수 있다. 결과적으로, 학습된 인공음영 제거 모델을 통해 메탈 인공 구조물이 없는 실제에 가까운 단층촬영 영상을 얻을 수 있고, 인공 메탈 구조물이 신체에 삽입된 대상자의 경우라도 임상적 판단 또는 처치에 유용한 정도로 인공음영이 제거된 단층촬 영 영상을 제공할 수 있다. 본 발명에서 얻을 수 있는 효과는 이상에서 언급한 효과들로 제한되지 않으며, 언급하지 않은 또 다른 효과들은 아래의 기재로부터 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2019-0159149", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명의 이점 및 특징, 그리고 그것들을 달성하는 방법은 첨부되는 도면과 함께 상세하게 후술되어 있는 실시 예들을 참조하면 명확해질 것이다. 그러나 본 발명은 이하에서 개시되는 실시예들에 한정되는 것이 아니라 서로 다른 다양한 형태로 구현될 수 있으며, 단지 본 실시예들은 본 발명의 개시가 완전하도록 하고, 본 발명이 속하"}
{"patent_id": "10-2019-0159149", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "는 기술분야에서 통상의 지식을 가진 자에게 발명의 범주를 완전하게 알려주기 위해 제공되는 것이며, 본 발명 은 청구항의 범주에 의해 정의될 뿐이다. 명세서 전체에 걸쳐 동일 참조 부호는 동일 구성 요소를 지칭한다. 본 발명의 실시예들을 설명함에 있어서 공지 기능 또는 구성에 대한 구체적인 설명이 본 발명의 요지를 불필요 하게 흐릴 수 있다고 판단되는 경우에는 그 상세한 설명을 생략할 것이며, 후술되는 용어들은 본 발명의 실시예 에서의 기능을 고려하여 정의된 용어들로서 이는 사용자, 운용자의 의도 또는 관례 등에 따라 달라질 수 있다. 그러므로 그 정의는 본 명세서 전반에 걸친 내용을 토대로 내려져야 할 것이다. 첨부된 블록도의 각 블록과 흐름도의 각 단계의 조합들은 컴퓨터 프로그램 인스트럭션들(실행 엔진)에 의해 수 행될 수도 있으며, 이들 컴퓨터 프로그램 인스트럭션들은 범용 컴퓨터, 특수용 컴퓨터 또는 기타 프로그램 가능 한 데이터 프로세싱 장비의 프로세서에 탑재될 수 있으므로, 컴퓨터 또는 기타 프로그램 가능한 데이터 프로세 싱 장비의 프로세서를 통해 수행되는 그 인스트럭션들이 블록도의 각 블록 또는 흐름도의 각 단계에서 설명된 기능들을 수행하는 수단을 생성하게 된다. 이들 컴퓨터 프로그램 인스트럭션들은 특정 방식으로 기능을 구현하기 위해 컴퓨터 또는 기타 프로그램 가능한 데이터 프로세싱 장비를 지향할 수 있는 컴퓨터 이용가능 또는 컴퓨터 판독 가능 메모리에 저장되는 것도 가능 하므로, 그 컴퓨터 이용가능 또는 컴퓨터 판독 가능 메모리에 저장된 인스트럭션들은 블록도의 각 블록 또는 흐 름도의 각 단계에서 설명된 기능을 수행하는 인스트럭션 수단을 내포하는 제조 품목을 생산하는 것도 가능하다. 그리고 컴퓨터 프로그램 인스트럭션들은 컴퓨터 또는 기타 프로그램 가능한 데이터 프로세싱 장비 상에 탑재되 는 것도 가능하므로, 컴퓨터 또는 기타 프로그램 가능한 데이터 프로세싱 장비 상에서 일련의 동작 단계들이 수 행되어 컴퓨터로 실행되는 프로세스를 생성해서 컴퓨터 또는 기타 프로그램 가능한 데이터 프로세싱 장비를 수 행하는 인스트럭션들은 블록도의 각 블록 및 흐름도의 각 단계에서 설명되는 기능들을 실행하기 위한 단계들을 제공하는 것도 가능하다. 또한, 각 블록 또는 각 단계는 특정된 논리적 기능들을 실행하기 위한 하나 이상의 실행 가능한 인스트럭션들을 포함하는 모듈, 세그먼트 또는 코드의 일부를 나타낼 수 있으며, 몇 가지 대체 실시예들에서는 블록들 또는 단 계들에서 언급된 기능들이 순서를 벗어나서 발생하는 것도 가능함을 주목해야 한다. 예컨대, 잇달아 도시되어 있는 두 개의 블록들 또는 단계들은 사실 실질적으로 동시에 수행되는 것도 가능하며, 또한 그 블록들 또는 단 계들이 필요에 따라 해당하는 기능의 역순으로 수행되는 것도 가능하다. 이하, 첨부 도면을 참조하여 본 발명의 실시예를 상세하게 설명한다. 그러나 다음에 예시하는 본 발명의 실시예 는 여러 가지 다른 형태로 변형될 수 있으며, 본 발명의 범위가 다음에 상술하는 실시예에 한정되는 것은 아니 다. 본 발명의 실시예는 당업계에서 통상의 지식을 가진 자에게 본 발명을 보다 완전하게 설명하기 위하여 제공 된다. 도 2는 본 발명의 일 실시예에 따른 인공지능 기반의 단층촬영 영상 인공음영 제거를 위한 영상 처리 시스템 의 구성도를 도시한다. 이하 사용되는 '…부', '…기' 등의 용어는 적어도 하나의 기능이나 동작을 처리하 는 단위를 의미하며, 이는 하드웨어나 소프트웨어, 또는 하드웨어 및 소프트웨어의 결합으로 구현될 수 있다. 도 2를 참조하면, 영상 처리 시스템은 단층촬영기와, 단층촬영기에 연결된 인공음영 제거 장치 를 포함한다. 단층촬영기는 CT 촬영 장치로서, X-선 등 광선을 사용하여 여러 각도로부터 물체의 투영 이미지를 촬영하 는 장치이다. 예를 들어, 단층촬영기는 X-선 광선이 회전 이동함으로써, 측정 대상의 여러 각도로부터 투 영 이미지를 획득하는 구조로 구성될 수 있다. 이와 같이 촬영된 영상은 인공음영 제거 장치로 전달되거나 영상 저장 장치에 저장될 수 있다. 인공음영 제거 장치는 단층촬영기로부터 촬영된 영상 데이터를 수신하고, 수집된 영상 데이터를 처리 하여 단면이미지를 얻는 장치이다. 예를 들어, 도 2에 도시된 바와 같이 인공음영 제거 장치는 인공음영 제거 장치의 전반적인 동작을 제어하는 제어부, 사용자 명령을 입력받는 입력부, 소리, 화면을 출력하는 출력부, 데이터를 저장하는 저장부 및 단층촬영기와 데이터를 주고받는 통신부를 포함할 수 있다. 제어부는 인공음영 제거 장치의 전반적인 동작을 제어한다. 제어부는 통신부를 통해 외부 장치와의 연동을 제어하고, 신호의 송수신을 제어한다. 또한, 제어부는 저장부에 데이터를 기록하고, 읽는다. 단층촬영기로부터 촬영된 영상 데이터를 수신하고, 이들 영상을 처리하고 인공음영을 제거하여 단 면 이미지를 생성한다. 제어부는 통신부를 통해 수신된 단층촬영기로부터 촬영된 영상 데이터를 처리하여 CT 단면 이미 지를 생성한다. 이 때, 인공지능 기반으로 인공음영이 포함된 CT 단면 이미지는 인공음영을 제거하여 재구성될 수 있다. 예를 들어, 메탈 인공 구조물로 인한 인공음영이 제거된 단층촬영 이미지를 획득하기 위해, 인공지능 알고리즘 을 이용할 수 있다. 인공지능 알고리즘의 예로는 기계 학습, 신경망, 유전자, 딥러닝, 분류 알고리즘이 있는데, 이들 중 적어도 하나를 이용하여 학습을 통해 다양한 인공음영이 포함된 데이터와 여기서 인공음영이 제거된 데 이터 셋을 통해 학습된 결과값을 이용하여 인공음영이 없는 이미지에 가깝게 인공음영을 제거할 수 있다. 신경 망 알고리즘으로는, 예를 들어 CNN(convolution neural network) 방식 등이 있다. 제어부는 학습된 알고리즘을 이용하여 메탈 인공 구조물로 인해 인공음영이 생긴 단층촬영 이미지로부터 인공음영이 제거된 이미지를 적절하게 생성할 수 있다. 상술한 제어부의 동작은 하나 이상의 프로세서(processor)에 의해 수행될 수 있다. 예를 들어, 인공음영 제거를 위한 학습과 학습된 알고리즘에 기반해 인공음영을 제거하는 동작은 각각 별개의 하나 이상의 프로세서 에 의해서 수행될 수도 있고, 동일한 프로세서에 의해 수행될 수도 있다. 각 동작은 동일한 프로세서에서 별개 의 소프트웨어 블록으로 구분되어 실행될 수 있다. 본 발명의 일 실시예에 따라, 제어부는 학습을 위한 데 이터 셋을 구성하고 이를 이용하여 인공음영 제거 모델을 학습하는 학습부와 학습된 모델에 기초하여 인공음영 이 발생한 단층촬영 영상을 입력으로 하여 인공음영이 제거된 단층촬영 영상을 생성하는 추론부를 포함할 수 있 다. 학습부와 추론부는 하드웨어 및/또는 소프트웨어적으로 구분될 수 있다. 제어부는 입력부, 출력부, 저장부 및 통신부와 연결되어 이들의 전반적인 동작을 제 어할 수 있다. 입력부는 사용자의 명령을 입력받는 인터페이스를 제공할 수 있다. 예를 들어, 입력부는 키보드, 터 치 패널, 버튼 입력 장치, 마우스, 펜 센서, 마이크 등 다양한 형태로 제공될 수 있다. 입력부를 통한 사 용자 입력은 제어부로 전달되고, 제어부에 의해 다양한 설정 변경으로 저장부에 저장되거나, 출 력부로 관련 내용을 출력하도록 제어될 수 있다. 출력부는 제어부에 의해 처리된 정보, 통신부를 통해 수신된 정보를 출력한다. 출력 형태는 음 성 신호, 영상 신호, 진동 형태일 수 있다. 출력부는 음성 신호 형태의 경고음 등을 출력하는 오디오, 화 면에 다양한 문자, 이미지 등 영상 신호를 출력하는 디스플레이 등을 포함할 수 있다. 저장부는 인공음영 제거 장치에서 동작 수행을 위해 필요한 정보와 동작 수행에 따라 생성되는 정보 가 저장된다. 저장부는 단층촬영기로부터 수집된 영상 데이터, 처리된 영상 데이터, 학습을 위해 생 성된 데이터 셋이나, 인공음영 제거 또는 이미지 처리를 위한 다양한 설정, 판단 기준 등이 저장될 수 있다. 저 장부는 인공음영 제거 장치에 포함된 메모리일 수도 있으나, 인공음영 제거 장치 외부에 연결된 외부 저장 장치일 수도 있다. 예를 들어, 저장부는 인공음영 제거 장치와 연결된 PACS(의료영상저장 전송시스템)로 단층촬영기에서 기존에 촬영된 영상을 저장하는 외부의 영상 저장 장치일 수 있다. 인공음 영 제거 장치는 단층촬영기에서 촬영된 영상을 직접 획득하거나, PACS에 저장된 영상을 획득하여 후 술하는 바와 같이 인공음영이 제거된 영상을 제공할 수 있다. 통신부는 유/무선 방식으로 단층촬영기와 연결된다. 통신부는 유/무선 네트워크를 통해 연결된 단층촬영기로부터 수집된 영상을 수신하고, 제어부로부터의 단층촬영기에 대한 제어 명령을 단 층촬영기로 전송한다. 도 3은 본 발명의 일 실시예에 따른 학습을 위한 인공음영을 삽입한 단층촬영 영상 데이터를 생성하여 인공음영 제거 모델을 학습하는 과정의 개략도를 도시한다. 단층촬영은 절개를 통하지 않고도 신체 내부의 단면이미지를 얻을 수 있는 방식으로, 신체 내부 상태를 진단하 고 치료에 활용하기 위해 중요한 수단이 되고 있다. 최근 의료 수술 등으로 신체 내부에 메탈 인공 구조물이 삽 입된 환자가 늘어나고 있는데, 이러한 경우 단층촬영 이미지에 메탈 인공 구조물에 의한 인공음영이 포함되어 신체 내부의 상태를 정확하게 판단하기 어렵게 한다. 인공음영은 선속 경화(beam hardening), 스캐터(scatter), 포아송 잡음(Poisson noise), 모션, 및 에지 효과(edge effects)를 포함한다. 이러한 인공음영을 제거하기 위해 O-MAR, Smart MAR, MARs 등 다양한 제거 알고리즘이 고안되어왔다. 그러나, 이러한 알고리즘에 의해 제거된 이미지는 도 1b에 도시된 바와 같이 제거된 부분의 원래 이미지를 적절히 복원 하지 못하여 여전히 실제 신체 내의 상태를 판단하기에 부족한 면이 있었다. 본 발명에서는 최근 다양한 분야에서 사용되고 있는 인공지능 알고리즘에 의한 학습에 기반하여 인공음영을 제 거하는 MAR(metal artifact reduction) 학습 모델을 제안하고, 학습된 모델을 이용하여 인공음영이 적절히 제거 된 단층촬영 이미지를 제공하고자 한다. 예를 들어, 딥러닝 모델을 학습하기 위해서는 인공음영을 포함하는 단층촬영 이미지와 이로부터 인공음영이 제 거된 정답 이미지 쌍이 필요하다. 그러나, 근본적으로 메탈 인공 구조물이 신체 내부에 삽입된 환자로 메탈 인 공 구조물이 제거되어 인공음영이 없는 정답 이미지를 얻을 수가 없다. 종래의 O-MAR 방식에 의해 인공음영이 제거된 이미지는 정답에 가까운 이미지가 아니라 그 결과물 자체가 내부 상태를 판단하기에 적절하지 못한 이미 지이므로, 학습을 위한 데이터 쌍으로 사용되기 어렵다. 이에 따라, 학습을 위한 데이터 쌍을 적절히 구성하는 것이 중요하다. 도 3에 도시된 바와 같이, 학습을 위한 데이터 셋 구성을 위해 메탈 인공 구조물이 삽입되지 않은 일반 단층촬 영 이미지에 처리를 통해 인공 메탈 형태를 삽입하고 인공음영을 생성하여 인공음영이 있는 이미지를 획득한다. 예를 들어, 인공음영이 발생한 이미지는 인공 메탈 형태가 삽입된 이미지로부터 사이노그램 처리(sinogram handling)를 거쳐 생성될 수 있다. 이와 같이 생성된 데이터 셋은, 인공 메탈 형태가 삽입되어 인공음영이 생성 된 이미지를 입력으로 하고, 인공 메탈 형태만 삽입되어 있는 단층촬영 이미지를 결과로 하여 딥러닝 기반의 MAR 학습에 이용된다. 본 발명에서 제안하는 데이터 셋은 출력으로 얻어야 할 정답 이미지를 획득한 후 역으로 입력 이미지(인공음영이 생성된 이미지)를 생성하여 데이터 셋을 구성하므로, 학습의 정확도를 더욱 높일 수 있다. 이하, 도 4 내지 6을 통해, 학습을 위한 데이터 쌍을 구성하고, 학습된 모델을 이용하여 인공음영이 제거된 단 층촬영 이미지를 획득하는 구체적인 과정이 도시된다. 도 4는 본 발명의 일 실시예에 따른 인공음영 제거 모델 학습에 기반하여 인공음영이 제거된 단층촬영 영상을 생성하는 과정의 흐름도를 도시한다. 예를 들어, 인공지능 기반의 단층촬영 영상 인공음영 제거를 위한 인공음 영 제거 장치의 동작의 흐름이 도시된다. 도 4를 참조하면, 인공지능 기반의 단층촬영 영상 인공음영 제거 방법은 신체 부위의 단층촬영 영상 획득 단계 (S410), 인공 메탈 형태가 삽입된 영상 생성 단계(S420), 인공 메탈 형태가 삽입된 영상으로부터 인공음영이 생 성된 영상 획득 단계(S430), 인공 메탈 형태가 삽입된 영상과 인공음영이 생성된 영상 쌍을 이용한 모델 학습 단계(S440) 및 학습된 모델에 기초하여 인공음영이 제거된 단층촬영 영상 생성 단계(S450)를 포함한다. 먼저, 인공음영 제거 장치는 신체 부위의 단층촬영 영상을 획득한다(S410). 인공음영 제거 장치는 메 탈 인공 구조물이 삽입되지 않은 일반적인 신체 부위의 단층촬영 영상을 획득한다. 이와 같이 획득된 단층촬영 영상은 인공 메탈 형태를 삽입하여 인공음영을 생성하기 위한 기초 영상이 된다. 예를 들어, 신체 부위의 단층 촬영 영상은 단층촬영기로부터 촬영된 영상을 수신하거나, 미리 촬영되어 영상 저장 장치(예를 들어, PACS(의료영상저장전송시스템) 등)에 저장된 영상을 획득할 수 있다. 다음으로, 인공음영 제거 장치는 인공 메탈 형태가 삽입된 영상을 생성한다(S420). 이 과정은 메탈 인공 구조물이 삽입되지 않은 일반적인 신체 부위의 단층촬영 영상에 인공 메탈 형태를 삽입하여 후술하는 도 5a에 도시된 바와 같이 인공 메탈 형태가 삽입된 이미지를 얻을 수 있다. 이와 같이, 일반 단층촬영 영상에 인공 메 탈 형태가 삽입된 영상이 결과적으로 인공음영이 제거되고 획득되어야 할 출력(정답) 이미지로 이용될 수 있다. 다음으로, 인공음영 제거 장치는 인공 메탈 형태가 삽입된 영상으로부터 인공음영이 생성된 영상을 획득한 다(S430). 인공 메탈 형태가 삽입된 영상에 사이노그램 처리를 통해 인공음영이 생성된 이미지를 얻을 수 있다. 이와 같이 획득된 단층촬영 영상은 결과적으로 인공음영이 생성된 입력 이미지로 이용될 수 있고, 출력 이미지 와 데이터 쌍을 이룬다. 그 다음, 인공음영 제거 장치는 인공 메탈 형태가 삽입된 영상과 그로부터 인공음영이 생성된 영상 쌍을 이용하여 인공음영 제거 모델을 학습한다(S440). 즉, 인공음영 제거 장치는 인공음영이 생성된 이미지와 인공 메탈 형태만 삽입된 단층촬영 이미지 데이터 쌍을 구성하고, 인공음영이 생성된 이미지를 입력으로 하고 인공 메탈 형태가 삽입된 단층촬영 이미지를 출력(정답) 이미지로 구성하여 딥러닝 기반의 MAR 학습하기 위한 동작을 수행할 수 있다. 구체적인 예를 들어, 도 5a 내지 5e에 도시된 바와 같이 처리를 통해 인공음영이 생성 된 단층촬영 이미지를 획득하는 동작을 수행할 수 있다. 마지막으로, 인공음영 제거 장치는 학습된 모델에 기초하여 인공음영이 제거된 단층촬영 영상을 생성한다 (S450). 즉, 인공음영 제거 장치는 인공지능 알고리즘을 이용하여 인공음영 제거 모델을 학습하고, 학습된 모델에 기반하여 단층촬영기 또는 영상 저장 장치로부터 수집된 단층촬영 영상으로부터 인공음영이 제거된 영상을 생성할 수 있다. 본 발명의 다른 일 실시예에 따라, S450 단계의 인공음영이 발생한 단층촬영 영상을 입력으로 받아 학습된 모델 에 기초하여 인공음영이 제거된 단층촬영 영상을 생성하는 단계는 상술한 S410 내지 S440 단계와 독립적으로 수 행될 수 있다. 즉, 학습을 위한 데이터 셋을 구성하고 이를 이용하여 인공음영 제거 모델을 학습한 후, 학습 과 정과 독립적으로 인공음영이 발생한 단층촬영 영상을 입력으로 받아 학습된 모델에 기초하여 인공음영이 제거된 단층촬영 영상을 생성하는 과정을 수행할 수 있다. 예를 들어, 인공음영 제거 장치의 제어부는 상술 한 학습을 위한 데이터 셋을 구성하고 이를 이용하여 인공음영 제거 모델을 학습하는 단계(S410 내지 S440)를 수행하는 학습부와 학습된 모델에 기초하여 인공음영이 발생한 단층촬영 영상을 입력으로 하여 인공음영이 제거 된 단층촬영 영상을 생성하는 단계(S450)를 수행하는 추론부를 포함할 수 있다. 도 5a 내지 5e는 본 발명의 일 실시예에 따른 메탈 인공 구조물이 없는 단층촬영 영상으로부터 인공음영을 삽입 한 단층촬영 영상을 생성하는 과정을 도시한다. 예를 들어, 인공음영 제거 장치의 인공 메탈 형태가 삽입 된 영상 생성 단계(S420)와 인공 메탈 형태가 삽입된 영상으로부터 인공음영이 생성된 영상 획득 단계(S430)에대한 구체적인 예시적 동작의 흐름을 도시할 수 있다. 먼저, 도 5a를 참조하면, 메탈 인공 구조물이 삽입되지 않은 대상자의 신체 내부 단층촬영 영상을 획득하고, 인 공 메탈 형태를 삽입하는 과정이 도시된다. 본 발명의 일 실시예에 따라, 도 5a에 도시된 바와 같은 단층 촬영 영상은 미리 촬영된 대상자의 영상이 저장부에 저장될 수 있고, 제어부가 저장부로부터 저 장된 단층촬영 영상(예를 들어, 의료용 디지털 영상 및 통신(Digital Imaging and Communications in Medicine, DICOM) 표준에 의해 저장된 단층촬영 영상)을 읽어올 수 있다. 읽어온 단층촬영 영상에 인공 메탈 형 태를 삽입한다. 도 5a에 도시된 바와 같이, 메탈 인공 구조물이 삽입되지 않아 대상자의 신체 내의 조직 등 단층 영상이 선명하게 얻어진 단층촬영 영상에 인공 메탈 형태가 삽입된 단층촬영 영상을 형성할 수 있 다. 인공 메탈 형태는 후처리로 삽입된 것이므로, 도 5a에 도시된 단층촬영 영상에는 아직 인공음영이 포함되지 않는다. 다음으로, 도 5b 내지 5d를 참조하면, 사이노그램 처리를 통한 인공 메탈 형태만이 삽입된 단층촬영 영상에 인 공음영을 생성하기 위한 라돈 변환(Radon transform)의 수행과정이 도시된다. 라돈 변환이란, 주어진 선이나 에 너지 전달 경로를 따라 대상체의 물성을 적분하는 것을 의미하여, 토모그래피에서는 투영을 얻기 위한 파선 적 분을 말한다. 먼저, 도 5a에 도시된 바와 같이 인공 메탈 형태가 삽입된 영상을 라돈 변환한다. 도 5b에 도시된 바와 같 이 라돈 변환 결과(RCT with metal)를 얻을 수 있다. 라돈 변환을 하면 사이노그램 도메인으로 변환이 가능하다. 구체적으로, 함수 f(x, y)로 표시되는 이미지의 라 돈 변환은 원점과 다른 오프셋에서 f(x, y)를 통한 일련의 선 적분으로 정의될 수 있다. 이 경우 라돈 변환은 <수학식 1>과 같이 나타낼 수 있다. 수학식 1"}
{"patent_id": "10-2019-0159149", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "여기서, R은 사이노그램 도메인을 나타내고, θ는 선의 각도이며, r은 선의 수직 오프셋을 의미한다. δ(x)는 아래의 <수학식 2>와 같이 정의될 수 있다. 수학식 2"}
{"patent_id": "10-2019-0159149", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "상기와 같은 라돈 변환 형식을 이용하여, 인공 메탈 형태만 있는 영상에 대해서도 라돈 변환을 수행한다. 라돈 변환을 하면 사이노그램 도메인으로 변환이 가능하다. 인공 메탈 형태만 있는 영상에 대해 라돈 변환 한 영상을 2진 영상(0과 1의 값만 가지는 binary 영상)으로 변환하여 가우시안(Gaussian) 필터를 적용하면, 도 5c와 같은 라돈 변환 결과(Rmetal)를 얻을 수 있다. 이와 같이 얻어진 결과를 바탕으로 아래의 <수학식 3>과 같은 연산을 통해 최종 라돈 변환 결과(Rfinal)를 얻는다. <수학식 3>과 같은 연산을 통해 얻어진 최종 라돈 변환 결과(Rfinal)는 도 5d에 도시된 바와 같다. 수학식 3 여기서, Rmetal은 인공 메탈 형태만 있는 영상에 대해 라돈 변환한 영상을 2진 영상으로 변환한 뒤 가우시안 필터를 적용한 결과이고, RCT with metal은 인공 메탈 형태가 삽입된 영상의 라돈 변환 결과이며, k는 상수를 의미한다. 이 때, 상수 k는 메탈의 모양과 크기에 따라 달라질 수 있고, 모양이 클수록 k 값이 커질 수 있다. 예를 들어, [0, 4095] 범위의 단층촬영 영상을 라돈 변환했을 때, k 값의 범위는 다음과 같다."}
{"patent_id": "10-2019-0159149", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "마지막으로, 최종 라돈 변환 결과(Rfinal)에 역 라돈 변환(inverse radon transform)을 수행하여 CT 이미지 도메 인으로 변환한다. 이와 같은 역 라돈 변환을 수행하면, 도 5e에 도시된 바와 같이 인공음영이 생성된 단층촬영 이미지가 얻어질 수 있다. 즉, 상술한 라돈 변환을 통해 메탈 인공 구조물이 삽입되지 않은 대상자의 단층촬영 영상으로부터 인공 메탈 형태에 의한 인공음영이 생성된 단층촬영 영상을 도 5e와 같이 얻을 수 있다. 본 발명에서는 사이노그램 기법의 라돈 변환을 이용한 인공 메탈 형태 삽입을 통해 메탈 인공 구조물이 삽입되 지 않은 대상자의 단층촬영 영상으로부터 인공음영이 생성된 단층촬영 영상을 생성하는 방법을 제안하나, 반드 시 이러한 기법에 한정되는 것은 아니며, 다양한 변형 예에 따라 정상 단층촬영 영상으로부터 메탈 인공 구조물 이 삽입된 경우 인공음영을 예측하여 인공음영이 생성된 단층촬영 영상을 획득하는 다양한 방법이 활용될 수 있 다. 도 6은 본 발명의 일 실시예에 따른 딥러닝 기반의 인공음영 제거 모델(DL-MAR) 학습 개념도를 도시한다. 도 6 을 참조하면, 이 과정에서 본 발명의 일 실시예에 따라, 다운샘플링(down sampling)에 맥스 풀링(Max Pooling) 대신 스트라이디드 컨볼루션(Strided convolution)이 사용되고, 업샘플링(up sampling)에 디컨볼루션 (Deconvolution) 대신 바이리니어 업샘플링(Bilinear upsampling)과 스트라이디드 컨볼루션이 사용될 수 있다. 일반 신경망(neural network)은 이미지를 다루기에 적절하지 않으므로, 컨볼루션 신경망(convolutional neural network)이 이용될 수 있다. 컨볼루션 신경망은 일반 신경망과 유사하지만, 컨볼루션 신경망 아키텍쳐는 입력 데이터로 이미지를 주로 받기 때문에, 이미지 데이터의 특성들을 잘 추출할 수 있도록 설계되었다. 특히, 일반 신경망과 달리 컨볼루션 신경망의 레이어들은 가로, 세로, 깊이 의 3개 차원을 갖게 된다. 여기에서 말하는 깊 이란, 전체 신경망의 깊이가 아니라 각 층(layer)에서의 피처 맵(feature map)의 수를 이야기 한다. 컨볼루셔널 레이어(convolutional layer)는 컨볼루션 신경망을 이루는 핵심 요소이다. 컨볼루셔널 레이어의 출 력은 3차원으로 정렬된 뉴런들로 해석될 수 있다. 컨볼루셔널 레이어를 정의하기 위한 주요 파라미터로 커널 사 이즈(kernel size), 스트라이드(stride), 패딩(padding) 및 입력 & 출력 채널(input & output channels)이 있 다. 커널 사이즈는 컨볼루션의 시야(view)를 결정한다. 예를 들면, 일반적으로 2D에서 3×3 픽셀로 사용한다. 스트 라이드는 이미지를 횡단할 때 커널의 스텝 사이즈를 결정한다. 예를 들어, 기본 스트라이드 값은 1이지만, 보통 Max Pooling과 비슷하게 이미지를 다운샘플링 하기 위해 스트라이드를 2로 사용할 수 있다. 패딩은 샘플 테두 리를 어떻게 조절할지를 결정한다. 패딩된 컨볼루션은 입력과 동일한 출력 차원을 유지하는 반면, 패딩되지 않 은 컨볼루션은 커널이 1보다 큰 경우 출력 차원이 축소될 수 있다. 컨볼루셔널 레이어는 입력 채널의 특정 수 (I)를 받아 출력 채널의 특정 수(O)로 계산한다. 이런 계층에서 필요한 파라미터의 수는 I×O×K로 계산할 수 있다. 여기서, K는 커널의 수(3×3 커널의 경우, K=9)이다. 본 발명에서는, 도 6에 도시된 바와 같이 업샘플링에 디컨볼루션(Deconvolution) 대신 바이리니어 업샘플링과 스트라이디드 컨볼루션을 사용하여 체커보드 현상(checkerboard artifacts)을 줄이고, 좀더 정밀한 이미지를 얻 을 수 있다. 상술한 예는 본 발명의 일 실시예에 불과하며, 정상 단층촬영에 인공 메탈 형태가 삽입된 영상과 그로부터 얻어진 인공음영이 생성된 단층촬영 영상의 데이터 셋을 이용한 딥러닝 기반의 인공음영 제거 모델 (DL-MAR) 학습인 경우 세부적인 알고리즘은 다양하게 변형될 수 있다. 상술한 바와 같이, 본 발명에서 제안하는 딥러닝 기반의 인공음영 제거 모델(DL-MAR) 학습을 통해 보다 효율적 으로 인공음영이 제거된 단층촬영 영상을 얻을 수 있다. 이하, 딥러닝 기반의 인공음영 제거 모델(DL-MAR) 학습 의 인공음영 제거 성능 결과를 비교하기 위한 방법과 그 결과가 도 7 내지 9에 도시된다.도 7a 및 7b는 본 발명의 일 실시예에 따른 인공음영 제거 성능 평가 지표 산출을 위한 영역이 표시된 이미지를 각각 도시한다. 도 7a를 참조하면, 실제 메탈 인공 구조물이 삽입된 대상자의 단층 촬영 이미지가 도시된다. 메탈 인공 구조물 에 의해 인공음영이 형성된 것을 확인할 수 있으며, 특히 다크 스트릭(dark streak) 형태의 메탈 인공음영의 면 적을 중심으로 성능평가 지표가 산출될 수 있다. 도 7b를 참조하면, 도 7a에서 다크 스트릭 인공음영 부분이 하늘색으로 표시된 이미지가 도시된다. 인공음영 제 거 성능 평가 지표는 이와 같은 하늘색 표시 영역을 기준으로 산출될 수 있다. 도 8은 일 실시예에 따른 인공음영을 포함하는 단층촬영 영상, 종래의 O-MAR 방식에 의해 획득된 영상과 딥러닝 기반의 인공음영 제거 모델(DL-MAR)에 의해 획득된 영상의 성능 지표 비교 그래프를 도시한다. 도 8의 성능 지표 비교 그래프는 도 7b와 같이 하늘색으로 표시된 부분을 이용하여 산출된 것이다. 도 8의 성능 지표 비교 그래프 산출에 사용된 이미지는, 메탈 인공 구조물이 삽입된 환자 10명의 단층촬영 영상을 획득하여 각 환자 별로 영상의 femoral epicondyle level에서 랜덤하게 1장씩 선택되었다. 이로써 총 10장의 메탈 인공 구조물을 포함하는 단층촬영 영상과, 이들을 이용하여 종래의 O-MAR 방식에 의해 획득된 영상과, 본 발명에서 제안하는 딥러닝 기반의 인공음영 제거 모델(DL-MAR)에 의해 획득된 영상의 예를 이용하여 계산된 구체적인 파 라미터는 다음과 같이 산출된다. 먼저, Area(mm2)는 다크 스트릭 인공음영 부분의 면적으로, 면적이 작을수록 우수한 성능을 의미한다. 이러한 면적은 도 7b와 같이 하늘색으로 표시된 부분을 이용하여 산출될 수 있다. 또한, Mean(HU)는 메탈 인공음영 영 역 내의 평균 CT 값(CT number)으로, 평균 감쇠(mean attenuation) 값이 높을수록 우수한 성능을 의미한다. Artifact Index(HU)는 메탈 인공음영에 의한 노이즈에서 백그라운드(reference tissue)에 의한 노이즈의 영향을 제외시킨 지표로, <수학식 4>와 같이 계산될 수 있다. 수학식 4"}
{"patent_id": "10-2019-0159149", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "여기서, SDartifact는 도 7b의 하늘색 영역의 표준편차(standard deviation, SD)를 계산한 값이며, SDreference는 인 공음영이 없는 조직(tissue) 부위에 원형의 ROI(Region of Interest)를 위치시킨 뒤, 그 영역의 표준편차를 계 산한 값이다. Artifact Index(HU)는 그 값이 작을수록 우수한 성능을 의미한다. 상술한 방법으로 본 실시예에 따른 인공음영을 포함하는 단층촬영 영상, 종래의 O-MAR 방식에 의해 획득된 영상 과 딥러닝 기반의 인공음영 제거 모델(DL-MAR)에 의해 획득된 영상의 예를 이용하여 계산된 각각의 파라미터는 <표 1>과 같다. 표 1 Area (mm2)Mean Attenuation (HU) Artifact Index (HU) No MAR 1910.3±158.8 -755.3±15.5 278.2±3.2 O-MAR 1453.9±207.9 -431.6±19.2 209.5±13.7 DL-MAR 12.6±2.1 -308.3±23.1 119.1±23.3 P-value < .001 < .001 < .001 <표 1> 및 도 8에 도시된 바와 같이, 본 발명에서 제안하는 딥러닝 기반의 인공음영 제거 모델(DL-MAR)에 의해 획득된 영상이 모든 면에서 종래의 O-MAR 방식에 비해 월등히 개선된 성능 지표를 보였다. 도 9a 내지 9c는 일 실시예에 따른 인공음영을 포함하는 단층촬영 영상, 종래의 O-MAR 방식에 의해 획득된 영상 과 딥러닝 기반의 인공음영 제거 모델(DL-MAR)에 의해 획득된 영상의 다양한 예를 각각 도시한다. 도 9a 내지 9c에 도시된 바와 같이, 육안으로 보기에도 본 발명에서 제안하는 딥러닝 기반의 인공음영 제거 모 델(DL-MAR)에 의한 영상이 인공음영을 제거하면서도 신체조직을 적절히 표현하여 효율적인 이미지를 제공함을 확인할 수 있다. 특히, 화살표로 표시된 영역을 O-MAR 방식과 비교하면 인공음영의 다크 스트릭 부분이 제거되 면서도 신체 조직이 적절히 표시되는 본 발명의 인공음영 제거 모델(DL-MAR)이 우수한 성능을 보인다. 본 발명의 인공지능 기반의 단층촬영 영상 인공음영 제거 방법 및 장치는 상술한 실시예에 국한되지 않고 본 발 명의 기술 사상이 허용하는 범위 내에서 다양하게 변형하여 실시할 수 있다."}
{"patent_id": "10-2019-0159149", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1a 및 1b는 인체에 메탈 인공 구조물이 삽입된 경우 단층촬영 영상과 종래의 O-MAR 방식을 통해 인공음영이 제거된 영상을 각각 도시한다. 도 2는 본 발명의 일 실시예에 따른 인공지능 기반의 단층촬영 영상 인공음영 제거를 위한 영상 처리 시스템의 구성도를 도시한다. 도 3은 본 발명의 일 실시예에 따른 학습을 위한 인공음영을 삽입한 단층촬영 영상 데이터를 생성하여 인공음영 제거 모델을 학습하는 과정의 개략도를 도시한다. 도 4는 본 발명의 일 실시예에 따른 인공음영 제거 모델 학습에 기반하여 인공음영이 제거된 단층촬영 영상을 생성하는 과정의 흐름도를 도시한다. 도 5a 내지 5e는 본 발명의 일 실시예에 따른 메탈 인공 구조물이 없는 단층촬영 영상으로부터 인공음영을 삽입 한 단층촬영 영상을 생성하는 과정을 도시한다. 도 6은 본 발명의 일 실시예에 따른 딥러닝 기반의 인공음영 제거 모델(DL-MAR) 학습 개념도를 도시한다. 도 7a 및 7b는 본 발명의 일 실시예에 따른 인공음영 제거 성능 평가 지표 산출을 위한 영역이 표시된 이미지를 각각 도시한다. 도 8은 일 실시예에 따른 인공음영을 포함하는 단층촬영 영상, 종래의 O-MAR 방식에 의해 획득된 영상과 딥러닝 기반의 인공음영 제거 모델(DL-MAR)에 의해 획득된 영상의 성능 지표 비교 그래프를 도시한다. 도 9a 내지 9c는 일 실시예에 따른 인공음영을 포함하는 단층촬영 영상, 종래의 O-MAR 방식에 의해 획득된 영상 과 딥러닝 기반의 인공음영 제거 모델(DL-MAR)에 의해 획득된 영상의 다양한 예를 각각 도시한다."}
