{"patent_id": "10-2023-0010059", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0117796", "출원번호": "10-2023-0010059", "발명의 명칭": "WebRTC 환경에서 클라우드와 인공지능 기반의 실시간 미디어 처리를 통한 서비스 품질 제어", "출원인": "주식회사 케이티", "발명자": "조복연"}}
{"patent_id": "10-2023-0010059", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "복수의 WebRTC(Web Real-Time Communication) 클라이언트와 연결되는 WebRTC 모바일 엣지 컴퓨팅 서버의 동작방법으로서,상기 복수의 WebRTC 클라이언트로부터 복수의 AV(AudioVideo) 스트림을 각각 수신하여 합성하는 단계, 상기 WebRTC 모바일 엣지 컴퓨팅 서버 및 각 WebRTC 클라이언트의 하드웨어 리소스 용량 및 네트워크 리소스 용량을 토대로, 합성된 AV 스트림에 대한 해상도 처리 작업을 해당 WebRTC 클라이언트로 오프로딩(Offloading) 시킬지 여부를 결정하는 단계, 그리고각 WebRTC 클라이언트에 대한 오프로딩 여부에 따라, 해당 WebRTC 클라이언트에게 합성된 AV 스트림 또는 해상도 처리된 합성 AV 스트림을 전송하는 단계를 포함하는, 방법."}
{"patent_id": "10-2023-0010059", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에서, 상기 해상도 처리 작업은, 서로 다른 종류의 해상도 처리를 수행하는, 모듈화된 복수개의 QoE(Quality of Experience) API(ApplicationProgramming Interface)를 통해 수행되고,상기 오프로딩은,QoE API 단위로 결정되는, 방법."}
{"patent_id": "10-2023-0010059", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에서, 상기 결정하는 단계 이전에,사전 정의된 QoS(Quality of Service) 피드백 메시지를 이용하여, 상기 각 WebRTC 클라이언트의 하드웨어 리소스 용량 및 네트워크 리소스 용량을 획득하는 단계를 더 포함하는, 방법."}
{"patent_id": "10-2023-0010059", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에서, 상기 결정하는 단계와 상기 전송하는 단계 사이에,사전 정의된 QoS(Quality of Service) 피드백 메시지를 이용하여, 오프로딩 여부에 관한 정보를 해당 WebRTC 클라이언트에게 전송하는 단계를 더 포함하는, 방법."}
{"patent_id": "10-2023-0010059", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에서, 상기 결정하는 단계는,상기 하드웨어 리소스 용량 및 상기 네트워크 리소스 용량을 이용하여, AV 스트림에 대한 해상도 처리 작업에필요한 하드웨어 연산량을 에너지 단위의 미디어 프로세싱 에너지로 환산하고, 상기 AV 스트림의 전송률을 에너공개특허 10-2024-0117796-3-지 단위의 전송 에너지로 환산하는 단계, 그리고상기 미디어 프로세싱 에너지와 상기 전송 에너지를 이용하여, 상기 오프로딩의 여부를 결정하는 단계를 포함하는, 방법."}
{"patent_id": "10-2023-0010059", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5항에서, 상기 결정하는 단계는,상기 WebRTC 서버의 하드웨어 리소스 가용량, 각 WebRTC 클라이언트의 하드웨어 리소스 가용량, 상기 미디어 프로세싱 에너지 및 상기 전송 에너지를 이용하여, 상기 각 WebRTC 클라이언트의 QoE(Quality of Experience) 지표와 상기 WebRTC 모바일 엣지 컴퓨팅 서버의 QoE 지표를 계산하는 단계, 그리고 상기 각 WebRTC 클라이언트의 QoE 지표와 상기 WebRTC 모바일 엣지 컴퓨팅 서버의 QoE 지표가 최대값을 가지는지에 기초하여 상기 오프로딩 여부를 결정하는 단계를 포함하는, 방법."}
{"patent_id": "10-2023-0010059", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6항에서, 상기 계산하는 단계는,상기 미디어 프로세싱 에너지, 상기 전송 에너지 및 상기 각 WebRTC 클라이언트로부터 수신한 하드웨어 리소스용량 정보를 이용하여, 상기 각 WebRTC 클라이언트의 QoE 지표를 계산하는 단계, 그리고상기 미디어 프로세싱 에너지, 상기 전송 에너지 및 상기 WebRTC 모바일 엣지 컴퓨팅 서버의 하드웨어 리소스용량 정보를 이용하여, 상기 WebRTC 모바일 엣지 컴퓨팅 서버의 QoE 지표를 계산하는 단계를 포함하는, 방법."}
{"patent_id": "10-2023-0010059", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에서, 상기 각 WebRTC 클라이언트의 QoE 지표를 계산하는 단계는,상기 각 WebRTC 클라이언트로부터 수신한 하드웨어 리소스 용량 정보를 이용하여, 상기 각 WebRTC 클라이언트의품질 지표를 계산하는 단계,상기 각 WebRTC 클라이언트로부터 수신한 네트워크 리소스 용량 정보 및 상기 전송 에너지를 이용하여, 상기 각WebRTC 클라이언트의 실시간성 지표를 계산하는 단계, 그리고 상기 각 WebRTC 클라이언트의 품질 지표와 상기 각 WebRTC 클라이언트의 실시간성 지표를 합산하여 상기 각WebRTC 클라이언트의 QoE 지표를 계산하는 단계를 포함하는, 방법."}
{"patent_id": "10-2023-0010059", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제7항에서, 상기 WebRTC MEC 서버의 QoE 지표를 계산하는 단계는,상기 WebRTC MEC 서버의 하드웨어 리소스 용량 정보를 이용하여, 상기 WebRTC MEC 서버의 품질 지표를 계산하는단계,상기 WebRTC MEC 서버의 네트워크 리소스 용량 정보 및 상기 전송 에너지를 이용하여, 상기 WebRTC MEC 서버의실시간성 지표를 계산하는 단계, 그리고 상기 WebRTC MEC 서버의 품질 지표와 상기 WebRTC MEC 서버의 실시간성 지표를 합산하여 상기 WebRTC MEC 서버공개특허 10-2024-0117796-4-의 QoE 지표를 계산하는 단계를 포함하는, 방법."}
{"patent_id": "10-2023-0010059", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "WebRTC(Web Real-Time Communication) 모바일 엣지 컴퓨팅 서버와 연결되어 동작하는 WebRTC 클라이언트의 동작 방법으로서,상기 WebRTC 모바일 엣지 컴퓨팅 서버로부터 AV(AudioVideo) 스트림을 수신하는 단계,상기 WebRTC 모바일 엣지 컴퓨팅 서버로부터 상기 AV 스트림에 대한 해상도 처리 작업의 오프로딩 여부를 나타내는 오프로딩 결정 정보를 수신하는 단계, 그리고상기 오프로딩 결정 정보가 오프로딩을 나타내는 경우, 상기 AV 스트림에 대한 해상도 처리 작업을 수행한 후,재생하는 단계를 포함하는, 방법."}
{"patent_id": "10-2023-0010059", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제10항에서, 상기 AV 스트림을 수신하는 단계 이전에,사전 정의된 QoS(Quality of Service) 피드백 메시지를 이용하여, 상기 WebRTC 클라이언트의 하드웨어 리소스용량 및 네트워크 리소스 용량을 상기 WebRTC 모바일 엣지 컴퓨팅 서버에게 전송하는 단계를 더 포함하고,상기 오프로딩 결정 정보는,상기 WebRTC 모바일 엣지 컴퓨팅 서버에서 상기 WebRTC 클라이언트의 하드웨어 리소스 용량 및 네트워크 리소스용량을 이용하여 생성되는, 방법."}
{"patent_id": "10-2023-0010059", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제10항에서, 상기 해상도 처리 작업은, 서로 다른 종류의 해상도 처리를 수행하는, 모듈화된 복수개의 QoE(Quality of Experience) API(ApplicationProgramming Interface)를 통해 수행되고,상기 오프로딩 결정 정보는,QoE API 단위의 오프로딩 결정 정보가 포함되는, 방법."}
{"patent_id": "10-2023-0010059", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "WebRTC(Web Real-Time Communication) 모바일 엣지 컴퓨팅 서버로서,AV(AudioVideo) 스트림에 대한 적어도 하나의 해상도 처리 작업을 수행하는 QoE(Quality of Experience)API(Application Programming Interface) 엔진, 그리고연결된 WebRTC 클라이언트로부터 수신한 하드웨어 리소스 용량 및 네트워크 리소스 용량을 이용하여, 상기 적어도 하나의 해상도 처리 작업의 오프로딩 여부를 결정하고, 오프로딩 결정 정보를 상기 WebRTC 클라이언트에게전송하는 QoS(Quality of Service) 매니저 모듈을 포함하고,상기 적어도 하나의 해상도 처리 작업은,상기 오프로딩 결정 정보가 오프로딩 결정을 지시하는 경우, 상기 WebRTC 클라이언트에서 수행되는, WebRTC 모바일 엣지 컴퓨팅 서버."}
{"patent_id": "10-2023-0010059", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제13항에서, 공개특허 10-2024-0117796-5-상기 오프로딩 결정 정보는,서로 다른 종류의 복수의 해상도 처리 작업 단위로 결정되는, WebRTC 모바일 엣지 컴퓨팅 서버."}
{"patent_id": "10-2023-0010059", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제14항에서, 상기 복수의 해상도 처리 작업은,딥러닝 기반의 초해상도를 위한 인코딩, 프레임 보간(Interpolation), 오브젝트 보간 및 고주파수 보간 중 적어도 하나의 작업을 포함하는, WebRTC 모바일 엣지 컴퓨팅 서버."}
{"patent_id": "10-2023-0010059", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제13항에서, 상기 QoS 매니저 모듈은,상기 WebRTC 클라이언트로부터 수신되는 사전 정의된 QoS(Quality of Service) 피드백 메시지를 이용하여, 상기WebRTC 클라이언트의 하드웨어 리소스 용량 및 네트워크 리소스 용량을 획득하고,상기 오프로딩 결정 정보가 포함된 QoS 피드백 메시지를 상기 WebRTC 클라이언트에게 전공하는, WebRTC 모바일엣지 컴퓨팅 서버."}
{"patent_id": "10-2023-0010059", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제13항에서, 상기 QoS 매니저 모듈은,상기 WebRTC 클라이언트 및 상기 WebRTC 모바일 엣지 컴퓨팅 서버 각각의 하드웨어 리소스 용량 및 네트워크 리소스 용량을 이용하여, 상기 해상도 처리 작업에 필요한 하드웨어 연산량을 에너지 단위의 미디어 프로세싱 에너지로 환산하고, 상기 AV 스트림의 전송률을 에너지 단위의 전송 에너지로 환산하며, 상기 미디어 프로세싱 에너지와 상기 전송 에너지를 이용하여, 상기 해상도 처리 작업의 오프로딩 여부를 결정하는, WebRTC 모바일 엣지컴퓨팅 서버."}
{"patent_id": "10-2023-0010059", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제17항에서, 상기 QoS 매니저 모듈은,상기 WebRTC 모바일 엣지 컴퓨팅 서버의 하드웨어 리소스 가용량, 상기 WebRTC 클라이언트의 하드웨어 리소스가용량, 상기 미디어 프로세싱 에너지 및 상기 전송 에너지를 이용하여, 상기 WebRTC 클라이언트의 QoE(Qualityof Experience) 지표와 상기 WebRTC 모바일 엣지 컴퓨팅 서버의 QoE 지표를 계산하고,상기 WebRTC 클라이언트의 QoE 지표와 상기 WebRTC 모바일 엣지 컴퓨팅 서버의 QoE 지표가 최대가 되는지에 기초하여 오프로딩 여부를 결정하는, WebRTC 모바일 엣지 컴퓨팅 서버."}
{"patent_id": "10-2023-0010059", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제18항에서, 상기 미디어 프로세싱 에너지는,해상도 처리 작업 단위로 계산된 미디어 프로세싱 에너지를 합산한 전체 에너지가 사용되는, WebRTC 모바일 엣지 컴퓨팅 서버."}
{"patent_id": "10-2023-0010059", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제18항에서, 상기 QoS 매니저 모듈은,공개특허 10-2024-0117796-6-입력 데이터로부터 오프로딩 여부를 결정하도록 학습된 최적화 모델을 이용하여, 상기 WebRTC 모바일 엣지 컴퓨팅 서버의 하드웨어 리소스 가용량, 상기 WebRTC 클라이언트의 하드웨어 리소스 가용량, 상기 미디어 프로세싱에너지 및 상기 전송 에너지에 따른 오프로딩 여부를 판단하는, WebRTC 모바일 엣지 컴퓨팅 서버."}
{"patent_id": "10-2023-0010059", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "복수의 WebRTC(Web Real-Time Communication) 클라이언트와 연결되는 WebRTC 모바일 엣지 컴퓨팅 서버의 동작 방법으로서, 상기 복수의 WebRTC 클라이언트로부터 복수의 AV(AudioVideo) 스트림을 각각 수신하여 합성하는 단 계, 상기 WebRTC 모바일 엣지 컴퓨팅 서버 및 각 WebRTC 클라이언트의 하드웨어 리소스 용량 및 네트워크 리소스 용량을 토대로, 합성된 AV 스트림에 대한 해상도 처리 작업을 해당 WebRTC 클라이언트로 오프로딩(Offloading) 시킬지 여부를 결정하는 단계, 그리고 각 WebRTC 클라이언트에 대한 오프로딩 여부에 따라, 해당 WebRTC 클라이 언트에게 합성된 AV 스트림 또는 해상도 처리된 합성 AV 스트림을 전송하는 단계를 포함한다."}
{"patent_id": "10-2023-0010059", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 WebRTC 환경에서 클라우드와 인공지능 기반의 실시간 미디어 처리를 통한 서비스 품질 제어 방법 및 장치에 관한 것이다."}
{"patent_id": "10-2023-0010059", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "인공지능 에듀테크(AI Edu tech) 기반 온라인 교육 서비스를 포함한 실시간 화상 회의 수요가 날로 증가하는 추 세에 있다. 따라서, 멀티미디어, 방송 컨텐츠의 개인화에 따른 전문 방송 플랫폼(high-end multimedia equipment, guaranteed bandwidth) 대비 낮은 수준의 미디어 품질 및 네트워킹(networking) 개선이 필요하다. 그런데, 종래에는 WebRTC 전송 표준에서 정의하고 있는 네트워크 파라미터(network parameter) 측정/예측 알고 리즘을 통해 QoS(Quality of Service) 적응(adaptation)을 수행한다. 종래에는 네트워크 리소스만을 고려해서 QoS 적응을 수행하므로, 실시간성(seamless, low latency)을 가장 높은 우선 순위로 정의한 WebRTC 프로토콜을 통해 QoS를 일정 수준 유지하기 위해 영상의 해상도를 일괄적으로 낮추어 전송하는 방식을 사용한다. 따라서, 고해상도(ex. 720p)의 영상 전송시 QoS 적응에 의한 영상 열화에 따른 QoE는 저하되는 문제가 있다. 또한, 높은 수준의 연산량과 복잡도를 요구하는 인공지능 기반 차세대 멀티미디어 서비스 산업의 발전과 더불어 CPU(central processing unit), GPU(graphics processing unit), NPU(Neural Processing Unit) 등의 컴퓨팅 디바이스의 성능도 지수적으로 증가하는 추세이다. 하지만, 기존의 WebRTC 표준은 P2P 기반 다중 클라이언트 간의 직접통신(direct communication)을 위해 실시간 성을 가장 높은 우선순위로 정의한 전송 기술이기 때문에, 전술한 것처럼, 표준에 정의된 QoS management 모델 을 통해 실시간성은 보장할 수 있지만 패킷 손실(packet drop), 프레임 손실(frame drop), 차이 트랜스코딩 (differential transcoding)으로 인한 QoE(Quality of Experience) 저하 문제를 야기하게 된다."}
{"patent_id": "10-2023-0010059", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 개시는 네트워크 리소스뿐만 아니라 하드웨어 리소스를 함께 고려한 QoS 적응(adaptation)을 통해 WebRTC에 서 요구하는 실시간성을 보장하면서도 동시에 사용자가 제공받은 AV 스트림의 QoE를 유지시키거나 또는 향상시 킬 수 있는 WebRTC 서비스 품질 제어 방법 및 그 장치를 제공한다. 본 개시는 WebRTC 프로토콜 환경에서 종단간 하드웨어 리소스 가용량 및 네트워 및 리소스 가용량의 실시간 혼 잡도를 바탕으로, DL(Deep Learning)-SR(Super Resolution) QoE API(Application Programming Interface)의 적용을 서버와 클라이언트로 분산시켜 QoS와 QoE를 모두 보장하는 WebRTC 서비스 품질 제어 방법 및 그 장치를 제공한다."}
{"patent_id": "10-2023-0010059", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "하나의 특징에 따르면, 복수의 WebRTC(Web Real-Time Communication) 클라이언트와 연결되는 WebRTC 모바일 엣 지 컴퓨팅 서버의 동작 방법으로서, 상기 복수의 WebRTC 클라이언트로부터 복수의 AV(AudioVideo) 스트림을 각 각 수신하여 합성하는 단계, 상기 WebRTC 모바일 엣지 컴퓨팅 서버 및 각 WebRTC 클라이언트의 하드웨어 리소스 용량 및 네트워크 리소스 용량을 토대로, 합성된 AV 스트림에 대한 해상도 처리 작업을 해당 WebRTC 클라이언트 로 오프로딩(Offloading) 시킬지 여부를 결정하는 단계, 그리고 각 WebRTC 클라이언트에 대한 오프로딩 여부에 따라, 해당 WebRTC 클라이언트에게 합성된 AV 스트림 또는 해상도 처리된 합성 AV 스트림을 전송하는 단계를 포 함한다. 상기 해상도 처리 작업은, 서로 다른 종류의 해상도 처리를 수행하는, 모듈화된 복수개의 QoE(Quality of Experience) API(Application Programming Interface)를 통해 수행되고, 상기 오프로딩은, QoE API 단위로 결정될 수 있다. 상기 결정하는 단계 이전에, 사전 정의된 QoS(Quality of Service) 피드백 메시지를 이용하여, 상기 각 WebRTC 클라이언트의 하드웨어 리소스 용량 및 네트워크 리소스 용량을 획득하는 단계를 더 포함할 수 있다. 상기 결정하는 단계와 상기 전송하는 단계 사이에, 사전 정의된 QoS(Quality of Service) 피드백 메시지를 이용 하여, 오프로딩 여부에 관한 정보를 해당 WebRTC 클라이언트에게 전송하는 단계를 더 포함할 수 있다. 상기 결정하는 단계는, 상기 하드웨어 리소스 용량 및 상기 네트워크 리소스 용량을 이용하여, AV 스트림에 대 한 해상도 처리 작업에 필요한 하드웨어 연산량을 에너지 단위의 미디어 프로세싱 에너지로 환산하고, 상기 AV 스트림의 전송률을 에너지 단위의 전송 에너지로 환산하는 단계, 그리고 상기 미디어 프로세싱 에너지와 상기 전송 에너지를 이용하여, 상기 오프로딩의 여부를 결정하는 단계를 포함할 수 있다. 상기 결정하는 단계는, 상기 WebRTC 서버의 하드웨어 리소스 가용량, 각 WebRTC 클라이언트의 하드웨어 리소스 가용량, 상기 미디어 프로세싱 에너지 및 상기 전송 에너지를 이용하여, 상기 각 WebRTC 클라이언트의 QoE(Quality of Experience) 지표와 상기 WebRTC 모바일 엣지 컴퓨팅 서버의 QoE 지표를 계산하는 단계, 그리 고 상기 각 WebRTC 클라이언트의 QoE 지표와 상기 WebRTC 모바일 엣지 컴퓨팅 서버의 QoE 지표가 최대값을 가지 는지에 기초하여 상기 오프로딩 여부를 결정하는 단계를 포함할 수 있다. 상기 계산하는 단계는, 상기 미디어 프로세싱 에너지, 상기 전송 에너지 및 상기 각 WebRTC 클라이언트로부터 수신한 하드웨어 리소스 용량 정보를 이용하여, 상기 각 WebRTC 클라이언트의 QoE 지표를 계산하는 단계, 그리 고 상기 미디어 프로세싱 에너지, 상기 전송 에너지 및 상기 WebRTC 모바일 엣지 컴퓨팅 서버의 하드웨어 리소 스 용량 정보를 이용하여, 상기 WebRTC 모바일 엣지 컴퓨팅 서버의 QoE 지표를 계산하는 단계를 포함할 수 있다. 상기 각 WebRTC 클라이언트의 QoE 지표를 계산하는 단계는, 상기 각 WebRTC 클라이언트로부터 수신한 하드웨어 리소스 용량 정보를 이용하여, 상기 각 WebRTC 클라이언트의 품질 지표를 계산하는 단계, 상기 각 WebRTC 클라 이언트로부터 수신한 네트워크 리소스 용량 정보 및 상기 전송 에너지를 이용하여, 상기 각 WebRTC 클라이언트 의 실시간성 지표를 계산하는 단계, 그리고 상기 각 WebRTC 클라이언트의 품질 지표와 상기 각 WebRTC 클라이언 트의 실시간성 지표를 합산하여 상기 각 WebRTC 클라이언트의 QoE 지표를 계산하는 단계를 포함할 수 있다. 상기 WebRTC MEC 서버의 QoE 지표를 계산하는 단계는, 상기 WebRTC MEC 서버의 하드웨어 리소스 용량 정보를 이 용하여, 상기 WebRTC MEC 서버의 품질 지표를 계산하는 단계, 상기 WebRTC MEC 서버의 네트워크 리소스 용량 정 보 및 상기 전송 에너지를 이용하여, 상기 WebRTC MEC 서버의 실시간성 지표를 계산하는 단계, 그리고 상기 WebRTC MEC 서버의 품질 지표와 상기 WebRTC MEC 서버의 실시간성 지표를 합산하여 상기 WebRTC MEC 서버의 QoE 지표를 계산하는 단계를 포함할 수 있다. 다른 특징에 따르면, WebRTC(Web Real-Time Communication) 모바일 엣지 컴퓨팅 서버와 연결되어 동작하는 WebRTC 클라이언트의 동작 방법으로서, 상기 WebRTC 모바일 엣지 컴퓨팅 서버로부터 AV(AudioVideo) 스트림을 수신하는 단계, 상기 WebRTC 모바일 엣지 컴퓨팅 서버로부터 상기 AV 스트림에 대한 해상도 처리 작업의 오프로 딩 여부를 나타내는 오프로딩 결정 정보를 수신하는 단계, 그리고 상기 오프로딩 결정 정보가 오프로딩을 나타 내는 경우, 상기 AV 스트림에 대한 해상도 처리 작업을 수행한 후, 재생하는 단계를 포함한다. 상기 AV 스트림을 수신하는 단계 이전에, 사전 정의된 QoS(Quality of Service) 피드백 메시지를 이용하여, 상 기 WebRTC 클라이언트의 하드웨어 리소스 용량 및 네트워크 리소스 용량을 상기 WebRTC 모바일 엣지 컴퓨팅 서 버에게 전송하는 단계를 더 포함하고, 상기 오프로딩 결정 정보는, 상기 WebRTC 모바일 엣지 컴퓨팅 서버에서 상기 WebRTC 클라이언트의 하드웨어 리소스 용량 및 네트워크 리소스 용량을 이용하여 생성될 수 있다. 상기 해상도 처리 작업은, 서로 다른 종류의 해상도 처리를 수행하는, 모듈화된 복수개의 QoE(Quality of Experience) API(Application Programming Interface)를 통해 수행되고, 상기 오프로딩 결정 정보는, QoE API 단위의 오프로딩 결정 정보가 포함될 수 있다. 또 다른 특징에 따르면, WebRTC(Web Real-Time Communication) 모바일 엣지 컴퓨팅 서버로서, AV(AudioVideo) 스트림에 대한 적어도 하나의 해상도 처리 작업을 수행하는 QoE(Quality of Experience) API(Application Programming Interface) 엔진, 그리고 연결된 WebRTC 클라이언트로부터 수신한 하드웨어 리소스 용량 및 네트워 크 리소스 용량을 이용하여, 상기 적어도 하나의 해상도 처리 작업의 오프로딩 여부를 결정하고, 오프로딩 결정 정보를 상기 WebRTC 클라이언트에게 전송하는 QoS(Quality of Service) 매니저 모듈을 포함하고, 상기 적어도하나의 해상도 처리 작업은, 상기 오프로딩 결정 정보가 오프로딩 결정을 지시하는 경우, 상기 WebRTC 클라이언 트에서 수행된다. 상기 오프로딩 결정 정보는, 서로 다른 종류의 복수의 해상도 처리 작업 단위로 결정될 수 있다. 상기 복수의 해상도 처리 작업은, 딥러닝 기반의 초해상도를 위한 인코딩, 프레임 보간(Interpolation), 오브젝 트 보간 및 고주파수 보간 중 적어도 하나의 작업을 포함할 수 있다. 상기 QoS 매니저 모듈은, 상기 WebRTC 클라이언트로부터 수신되는 사전 정의된 QoS(Quality of Service) 피드백 메시지를 이용하여, 상기 WebRTC 클라이언트의 하드웨어 리소스 용량 및 네트워크 리소스 용량을 획득하고, 상 기 오프로딩 결정 정보가 포함된 QoS 피드백 메시지를 상기 WebRTC 클라이언트에게 전공할 수 있다. 상기 QoS 매니저 모듈은, 상기 WebRTC 클라이언트 및 상기 WebRTC 모바일 엣지 컴퓨팅 서버 각각의 하드웨어 리 소스 용량 및 네트워크 리소스 용량을 이용하여, 상기 해상도 처리 작업에 필요한 하드웨어 연산량을 에너지 단 위의 미디어 프로세싱 에너지로 환산하고, 상기 AV 스트림의 전송률을 에너지 단위의 전송 에너지로 환산하며, 상기 미디어 프로세싱 에너지와 상기 전송 에너지를 이용하여, 상기 해상도 처리 작업의 오프로딩 여부를 결정 할 수 있다. 상기 QoS 매니저 모듈은, 상기 WebRTC 모바일 엣지 컴퓨팅 서버의 하드웨어 리소스 가용량, 상기 WebRTC 클라이 언트의 하드웨어 리소스 가용량, 상기 미디어 프로세싱 에너지 및 상기 전송 에너지를 이용하여, 상기 WebRTC 클라이언트의 QoE(Quality of Experience) 지표와 상기 WebRTC 모바일 엣지 컴퓨팅 서버의 QoE 지표를 계산하 고, 상기 WebRTC 클라이언트의 QoE 지표와 상기 WebRTC 모바일 엣지 컴퓨팅 서버의 QoE 지표가 최대가 되는지에 기초하여 오프로딩 여부를 결정할 수 있다. 상기 미디어 프로세싱 에너지는, 해상도 처리 작업 단위로 계산된 미디어 프로세싱 에너지를 합산한 전체 에너 지가 사용될 수 있다. 상기 QoS 매니저 모듈은, 입력 데이터로부터 오프로딩 여부를 결정하도록 학습된 최적화 모델을 이용하여, 상기 WebRTC 모바일 엣지 컴퓨팅 서버의 하드웨어 리소스 가용량, 상기 WebRTC 클라이언트의 하드웨어 리소스 가용량, 상기 미디어 프로세싱 에너지 및 상기 전송 에너지에 따른 오프로딩 여부를 판단할 수 있다."}
{"patent_id": "10-2023-0010059", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "실시예에 따르면, 미디어 처리를 위한 DL-SR 기반의 QoE API의 모듈화(modulization)를 통해 QoS 적응을 서버 단과 클라이언트 단으로 분산시켜 수행함으로써, 네트워크 리소스(network resource)(transmission bitrate)를 절약할 수 있고 제로 지연(zero delay)을 제공할 수 있다. 또한, 실시간성을 보장하며 동시에 사용자가 제공받는 스트림 영상의 공간적 품질을 유지시키거나 또는 향상시 킬 수 있다. 또한, 가용 리소스를 고려하여 고해상도의 영상 품질을 복원할 수 있는 저해상도 수준 또는 그 이하의 정보(ex. 360p) 전송을 통해 QoE 유지 및 향상을 제공할 수 있다. 또한, DL-SR을 포함한 다양한 미디어 처리 엔진을 통해 멀티미디어, 방송 서비스의 개인화에 따른 전문 방송 플 랫폼 대비 낮은 성능의 물리 장비로 인한 사용자 체감 품질 저하 문제를 완화시킬 수 있다."}
{"patent_id": "10-2023-0010059", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "아래에서는 첨부한 도면을 참고로 하여 본 개시의 실시예에 대하여 본 개시가 속하는 기술 분야에서 통상의 지 식을 가진 자가 용이하게 실시할 수 있도록 상세히 설명한다. 그러나 본 개시는 여러가지 상이한 형태로 구현될 수 있으며 여기에서 설명하는 실시예에 한정되지 않는다. 그리고 도면에서 본 개시를 명확하게 설명하기 위해서 설명과 관계없는 부분은 생략하였으며, 명세서 전체를 통하여 유사한 부분에 대해서는 유사한 도면 부호를 붙였 다. 명세서 전체에서, 어떤 부분이 어떤 구성요소를 \"포함\"한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다 른 구성요소를 제외하는 것이 아니라 다른 구성요소를 더 포함할 수 있는 것을 의미한다. 또한, 명세서에 기재된 \"…부\", \"…기\", \"…모듈\" 등의 용어는 적어도 하나의 기능이나 동작을 처리하는 단위를 의미하며, 이는 하드웨어나 소프트웨어 또는 하드웨어 및 소프트웨어의 결합으로 구현될 수 있다. 본 발명에서 설명하는 장치들은 적어도 하나의 프로세서, 메모리 장치, 통신 장치 등을 포함하는 하드웨어로 구 성되고, 지정된 장소에 하드웨어와 결합되어 실행되는 프로그램이 저장된다. 하드웨어는 본 발명의 방법을 실행 할 수 있는 구성과 성능을 가진다. 프로그램은 도면들을 참고로 설명한 본 발명의 동작 방법을 구현한 명령어 (instructions)를 포함하고, 프로세서와 메모리 장치 등의 하드웨어와 결합하여 본 발명을 실행한다. 본 명세서에서 \"전송 또는 제공\"은 직접적인 전송 또는 제공하는 것뿐만 아니라 다른 장치를 통해 또는 우회 경 로를 이용하여 간접적으로 전송 또는 제공도 포함할 수 있다. 본 명세서에서 단수로 기재된 표현은 \"하나\" 또는 \"단일\" 등의 명시적인 표현을 사용하지 않은 이상, 단수 또는 복수로 해석될 수 있다. 본 명세서에서 도면에 관계없이 동일한 도면번호는 동일한 구성요소를 지칭하며, \"및/또는\" 은 언급된 구성 요 소들의 각각 및 하나 이상의 모든 조합을 포함한다. 본 명세서에서, 제1, 제2 등과 같이 서수를 포함하는 용어들은 다양한 구성요소들을 설명하는데 사용될 수 있지 만, 상기 구성요소들은 상기 용어들에 의해 한정되지는 않는다. 상기 용어들은 하나의 구성요소를 다른 구성요 소로부터 구별하는 목적으로만 사용된다. 예를 들어, 본 개시의 권리 범위를 벗어나지 않으면서 제1 구성요소는 제2 구성요소로 명명될 수 있고, 유사하게 제2 구성요소도 제1 구성요소로 명명될 수 있다. 본 명세서에서 도면을 참고하여 설명한 흐름도에서, 동작 순서는 변경될 수 있고, 여러 동작들이 병합되거나, 어느 동작이 분할될 수 있고, 특정 동작은 수행되지 않을 수 있다. 도 1은 한 실시예에 따른 WebRTC(Web Real-Time Communication) 스트림 제어 시스템의 구성도이다. 도 1을 참조하면, WebRTC 스트림 제어 시스템은 WebRTC MEC(Mobile Edge Computing) 서버(i), 그리고 복 수의 WebRTC 클라이언트(j)를 포함하는 각각의 사용자 단말을 포함한다. 복수의 WebRTC 클라이언트는 마이크 입력 신호 및 카메라 입력 신호를 토대로, 개별 AV(AudioVideo) 스트 림을 각각 생성하여 WebRTC MEC 서버로 전송할 수 있다. WebRTC MEC 서버는 복수의 WebRTC 클라이언트로부터 수신한 개별 AV 스트림들을 합성 및 가공하고, 합성 및 가공된 AV 스트림을 복수의 WebRTC 클라이언트에게 각각 전송한다. 개별 AV 스트림들의 가공은 WebRTC MEC 서버에서 이루어질 수도 있고, 개별 WebRTC 클라이언트으로 오프로딩 될 수도 있다. WebRTC MEC 서버는 WebRTC MEC 서버 및 개별 WebRTC 클라이언트의 하드웨어 리소스 및 네트워 크 리소스에 기초하여, 오프로딩 여부를 결정할 수 있다. 오프로딩이 결정되면, WebRTC MEC 서버는 개별 AV 스트림들을 가공하지 않고, 합성된 채로 개별 WebRTC 클라이언트에게 전송한다. 그러면, 개별 WebRTC 클라이언트는 합성된 AV 스트림을 직접 가공하여 렌더링한다. 각 WebRTC client entity로부터 모인 AV stream을 재구성한 후, 실시간성을 보장하면서 broadcasting 서비스를 제공하는 것과 network uplink 환경에서 각 WebRTC client entity로부터 AV stream을 실시간으로 전송받는 것 을 함께 고려할 필요가 있다.이에 본 특허에서 제안하는 WebRTC MEC server entity의 QoE API engine 및 enhanced QoS manager module을 기 반으로 각 WebRTC client entity가 실시간으로 업로드하는 LR-AV stream을 재구성하여 HR-AV stream을 제공한 다. 이 때, 상기 HR-AV stream의 transmission bitrate는 LR-AV stream과 동일 또는 그 이하의 bandwidth resource를 소모한다. uplink/downlink 양방향에서의 network bandwidth가 50% 이상 절감되며 그에 따른 전송속도 향상에 따른 실시 간성이 보장되고 동시에 보다 많은 수의 사용자를 수용할 수 있다. 이러한 AV 스트림의 가공은 도 3 ~ 도 7을 참고하여 자세히 설명하기로 한다. 이처럼, WebRTC MEC 서버의 제어에 따라 복수의 WebRTC 클라이언트는 다자간 통화와 같은 WebRTC 기 반의 서비스를 제공받을 수 있다. 도 2는 도 1의 WebRTC 스트림 제어 시스템이 적용된 일반적인 클라우드 환경 구조를 나타낸다. 도 2를 참조하면, WebRTC 코어 클라우드(Core Cloud) 서버는 인터넷을 통해 복수의 WebRTC MEC 서버(10 0)와 연결된다. 복수의 WebRTC MEC 서버는 도 1에서 설명한 바와 같이, 복수의 복수의 WebRTC 클라이언트 와 연결된다. 즉, k(j=k)개의 WebRTC 클라이언트는 하나의 WebRTC MEC 서버에 연결되고, n(i=n)개의 WebRTC MEC 서버는 인터넷과 같은 상용 네트워크를 통해 WebRTC 코어 클라우드 서버에 연결될 수 있다. WebRTC MEC 서버, WebRTC 클라이언트, WebRTC 코어 클라우드 서버는 WebRTC 표준 프로토콜을 기반으로 동작한다. WebRTC MEC 서버는 WebRTC 클라이언트들의 연결을 관리하는 엔티티로서, 실시간 리소스(resource)를 모니터링하고 그에 따라 적응적으로 QoS(Quality of Service)/QoE(Quality of Experience) 제어를 수행할 수 있다. 기본적으로, WebRTC 표준은 P2P(Peer-To-Peer) 기반 다중 클라이언트 간의 직접 통신(direct communication)을 위해 실시간성을 가장 높은 우선순위로 정의한 전송 기술로서 표준에 정의된 QoS 관리(management) 모델을 통해 실시간성은 보장할 수 있지만, 패킷 유실(packet drop), 프레임 유실(frame drop), differential transcoding 으로 인한 QoE 저하 문제를 야기한다. 따라서, 본 발명의 실시예에서는 네트워크 리소스뿐만 아니라 하드웨어 리소스를 함께 고려한 QoS 적응 (adaptation) 제어를 통해, QoE를 개선시킬 수 있다. 이를 위해, WebRTC MEC 서버는 WebRTC 전송 프로토 콜 환경에서 딥러닝(Deep Learning, 이하, DL로 통칭함)-based 초고해상도(Super Resoultion, 이하, SR로 통칭 함)을 활용한 적응적인 QoS 관리(adaptive QoS management)를 통해 QoE를 향상시킨다. DL-SR을 활용한 적응적인 QoS 관리를 위해, 복수개의 QoE API(Application Programming Interface)가 정의될 수 있다. 복수개의 QoE API는 딥러닝-고해상도 비디오 인코더 API, 딥러닝-고해상도 보간(Interpolation) API, 딥러닝-고해상도 오브젝트(Object) 보간 API, 딥러닝-고해상도 고주파수(High Frequency) 보간 API 등을 포함할 수 있다. 이외에도 추가적인 QoE API들이 정의될 수 있다. DL-SR 비디오 인코더 API는 디코딩된 로 비디오 스트림(decoded raw video stream)을 입력받아, DL-SR 인코딩 을 수행한 후, 인코딩된 비디오 스트림(encoded video stream)을 출력한다. DL-SR 비디오 인코더 API는 LR(Low Resoultion) 비디오를 이용하여 DL-SR을 통해 LR 비디오 전송 비트레이트(Tramsmission Bitrate) 이하의 부호 화 효율을 제공한다. DL-SR 비디오 인코더 API는 LR 비디오 전송 비트레이트 이하 수준의 정보를 통해 HR(High Resolution) 수준의 비디오 품질을 제공할 수 있다. DL-SR 보간 API는 디코딩된 로 비디오 스트림(decoded raw video stream)을 입력받아, 프레임 전체에 대한 DL- SR 보간을 수행한 후, 보간된 로 비디오 스트림(interpolated raw video stream)을 출력한다. DL-SR 오브젝트 보간 API는 디코딩된 로 비디오 스트림(decoded raw video stream)을 입력받아, 오브젝트에 대 한 DL-SR 보간을 수행한 후, 보간된 로 비디오 스트림(interpolated raw video stream)을 출력한다. DL-SR 보간 API 및 DL-SR 오브젝트 보간 API는 네트워크 모델에 따라 모듈화(Modulization) 기능을 제공할 수 있다.DL-SR 고주파수 보간 API는 공간적 해상도 영역 내의 고주파 성분(edge pixel)에 대한 DL-SR 보간을 수행한다. WebRTC MEC 서버는 복수개의 WebRTC 클라이언트로부터 수신한 AV 스트림을 합성하고, 합성한 AV 스트 림에 전술한 복수개의 QoE API를 이용하여 가공을 한다. 이때, 복수개의 QoE API 중 일부는 WebRTC 클라이언트에서 처리하도록 오프로딩할 수 있다. 오프로딩 여부 는 네트워크 리소스와 하드웨어 리소스를 고려하여 결정될 수 있다. WebRTC 클라이언트는 WebRTC 표준 프로토콜 기반 양방향 스트리밍을 수행하고, 네트워크 리소스와 하드웨 어 리소스에 관련된 파라미터를 QoS 피드백 메시지를 통해 WebRTC MEC 서버로 리포트할 수 있다. WebRTC 코어 클라우드 서버는 네트워크 상에 산재되어 있는 다수의 WebRTC MEC 서버의 리소스를 관리 할 수 있다. WebRTC 코어 클라우드 서버는 사설 클라우드 인프라(Cloud infra) 기반으로 정의된 정책(policy)을 따르는 로드밸런싱(load balancing)을 수행하고, WebRTC MEC 서버에 대한 관리를 수행할 수 있다. 이때, WebRTC 코어 클라우드 서버는 WebRTC MEC 서버와 WebRTC 클라이언트 간 실시간 스트리밍 플로우와는 독 립적으로 동작한다. WebRTC 코어 클라우드 서버는 WebRTC MEC 서버의 실시간 모니터링 및 관리 동작을 수행한다. 즉, 각 WebRTC MEC 서버에서 실시간으로 소비되는 리소스를 모니터링하고 적응적으로 컴퓨테이션(computation)을 분산하여 처리하는 기능을 수행한다. WebRTC 서비스를 다자간 통화에 적용하는 경우를 예시로, 도 2의 구성 요소 간의 동작 흐름을 설명하면, 다음과 같다. WebRTC 클라이언트는 다자간 통화를 위해 생성된 AV 스트림을 연결된 WebRTC MEC 서버로 전송한다. 이때, 동시에 WebRTC 클라이언트가 소비하는 리소스 용량 정보를 WebRTC MEC 서버에게 전송한다. 각 WebRTC MEC 서버는 수신한 AV 스트림을 합성 및 가공하여 다자간 통화에 참여하는, 즉, 연결된 복수개 의 WebRTC 클라이언트에게 전송한다. 그리고 동시에 자신의 리소스 용량 정보와 가용 리소스 정보를 연결 된 WebRTC 코어 클라우드에게 전송할 수 있다. WebRTC 코어 클라우드는 연결된 각 WebRTC MEC 서버의 리소스를 실시간으로 모니터링하고 컴퓨테이션 (computation) 분산을 통한 로드밸런싱을 수행할 수 있다. WebRTC 코어 클라우드는 오버 프로비저닝(over provisioning) 또는 언더 프로비저닝(under provisioning) 예방을 통한 QoS (Quality of Service) 관리를 수행 할 수 있다. 도 3은 한 실시예에 따른 WebRTC MEC 서버의 구성을 나타낸 블록도이다. 도 3을 참조하면, WebRTC MEC 서버는 QoS 매니저(Manager) 모듈(Module), WebRTC 수신 모듈, WebRTC 역패킷화 모듈(de-packetizer), MPEG(Moving Picture Experts Group) 디코더(Decoder, QoE API 엔진(engine), MPEG 인코더(encoder), WebRTC 패킷화 모듈(packetizer), WebRTC 송신 모듈 (sending module)을 포함할 수 있다. 여기서, QoE API 엔진은 AV 스트림의 가공부에 해당하는 동작을 한다. QoS 매니저 모듈은 QoE API 엔 진의 동작을 제어하는 제어부에 해당한다. WebRTC MEC 서버는 다수의 WebRTC 클라이언트로부터 수신되는 AV 스트림을 재구성하고, 재구성한 AV 스트림을 다수의 WebRTC 클라이언트에게 브로드캐스팅(broadcasting)한다. QoS 매니저 모듈은 AV 스트림을 재구성하기 위한 QoE API를 결정하기 위해 WebRTC MEC 서버 및 WebRTC 클라이언트의 실시간 리소스 용량(resource capacity)을 고려한다. WebRTC 클라이언트의 실 시간 리소스 용량은 QoS 피드백 메시지(feedback message)를 통해 수집될 수 있다. QoS 매니저 모듈은 WebRTC MEC 서버에 연결된 다수의 WebRTC 클라이언트로부터 수신한 QoS 피 드백 메시지와 WebRTC MEC 서버의 리소스 가용량을 실시간으로 모니터링하고, 모니터링을 통해 모듈화된 QoE API의 오프로딩 여부와 동작 여부를 결정하고, 결정에 따라 QoE API 엔진을 제어한다.한 실시예에 따르면, QoS 피드백 메시지는 표 1과 같은 Syntax를 포함할 수 있다. 표 1"}
{"patent_id": "10-2023-0010059", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "QoS_adaptation_feedback_message () { message_id version length extension { reserved } if (message_id == “0x00”) { WebRTC_client_index } else If (message_id == “0x01”) { WebRTC_MEC_server_index } offloading_decision_flag"}
{"patent_id": "10-2023-0010059", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "QoS_resource_parameter_info { for (i=0; i<N1; i++) { IT_resource_capacity modulized_process_complexity full_reference_IQA_index no_reference_IQA_index peak_signal_to_noise_ratio reserved } } } 표 1에서, QoS 피드백 메시지에 포함되는 데이터 항목은 다음 표 2와 같이 정의되나, 이는 단지 메시지의 구조 를 설명하기 위한 예시로서, 이에 국한되는 것은 아니고, 다양한 변형이 가능하다. 표 2 항목 설명 message_id QoS 피드백 메시지의 ID로서, 8비트 크기임 version QoS 피드백 메시지가 최신인지에 관계된 버전으로서, 8비트 크 기임 length QoS 적응 피드백 메시지의 길이로서, 32비트 크기임. 값이 0이 면 메시지가 사용되지 않음 reserved 예약 필드 WebRTC_client_index 서비스 사용자의 인덱스를 나타내며, 값이 0이면 서비스 사용 자는 WebRTC 클라이언트 엔티티 측이고, 이 필드의 길이는 8비 트임 WebRTC_MEC_server_index 서비스 사용자의 인덱스를 나타내며, 값이 1이면 서비스 사용 자는 WebRTC MEC 서버 엔티티 측이고, 이 필드의 길이는 8비트 임 offloading_decision_flag 오프로딩 결정 플래그로서, 이 필드의 길이는 8비트임. MEC 서 버와 같은 지능형 라우터 엔티티는 WebRTC 표준을 기반으로 정 의된 QoS_resource_parameter_info 및 측정된 네트워크 매개변 수의 실시간 정보에 따라 모듈의 오프로드 여부를 결정할 수 있도록 정의됨 resource_capacity 하드웨어 리소스 용량 및 네트워크 리소스 용량의 정보가 포함 됨.modulized_process_complexity 모듈화된 프로세스의 복잡도를 나타내며. 이 필드의 길이는 32 비트임. 복잡도의 단위는 NTP(Network Time Protocol) 기반의 CPU 또는 초의 클럭 수일 수 있음 full_reference_IQA_index 전체 참조(FR, full_reference) 이미지 품질 평가(IQA, Image Quality Assessment)의 인덱스를 나타내고, 8비트임. FR-IQA는 PSNR에 대해 예상되는 SSIM (structural similarity index measure), E-PSNR(Estimated Peak Signal to Noise Ratio), MSE(Mean Squared Error) 등과 같은 다양한 평가 메트릭이 될 수 있음 no_reference_IQA_index 이미지 품질 평가 인덱스로서, 8비트이고, NR(no_reference)- IQA 방법은 MOS(Mean Of Score) 메트릭이 될 수 있음 peak_signal_to_noise_ratio 피크 신호 대 잡음비(PSNR, Peak Signal-to-Noise Ratio)를 나 타내고, 32비트이며, 임시 필드로 통합되어 예약된 필드로 변 경될 수 있음 reserved 예약 필드 표 2에서, 리소스 용량 필드(resource_capacity)는 QoS 피드백 메시지의 발신 주체가 WebRTC 클라이언트 인 경우, 초기 하드웨어 리소스 용량, 하드웨어 리소스 사용량, 네트워크 용량을 포함할 수 있다. 오프로딩 결정 플래그(offloading_decision_flag)는 QoS 피드백 메시지의 발신 주체가 WebRTC MEC 서버인 경우, 오프로딩 여부를 나타내는 지시자와 오프로딩 되기로 결정된 QoE API 식별자를 포함할 수 있다. QoS 매니저 모듈은 QoS 피드백 메시지와 리소스 파라미터들을 입력받아, QoE API의 오프로딩 결정값 (Offloading decision value) 및 QoE API 결정값을 출력한다. 이에 대해서는 도 7을 참조하여 자세히 설명하기 로 한다. QoS 매니저 모듈은 WebRTC 클라이언트로부터 QoS 피드백 메시지를 수신하고, 수신한 QoS 피드백 메시 지로부터 WebRTC 클라이언트의 리소스 파라미터들을 획득한다. WebRTC MEC 서버의 리소스 파라미터들 은 별도의 측정 수단(미도시)을 통해 측정되어 저장된다. WebRTC 수신 모듈은 WebRTC 클라이언트로부터 업링크(Uplink) AV 스트림을 수신한다. WebRTC 송신 모듈은 다운링크(Downlink) AV 스트림을 연결된 복수의 WebRTC 클라이언트에게 브로드캐 스팅한다. WebRTC 수신 모듈 및 WebRTC 송신 모듈은 WebRTC 표준을 따르는 UDP(User Datagram Protocol) 또는 IP(Internet Protocol) 기반의 RTP(Real Time Transport Protocol)를 사용하여 패킷 단위의 AV 스트림을 송수 신할 수 있다. WebRTC 역패킷화 모듈은 WebRTC 수신 모듈로부터 WebRTC 표준 기반의 패킷들을 입력받아, 역패킷화 동작을 통해 인코딩된 AV 컨테이너 스트림(Encoded AV container stram)을 MPEG 디코더로 출력한다. WebRTC 역패킷화 모듈은 패킷 헤더 정보를 바탕으로, 입력 패킷을 MPEG 국제 표준 코덱(Codec)을 통해 복 호화가 가능한 프레임으로 재구성한다. MPEG 디코더는 WebRTC 역패킷화 모듈로부터 인코딩된 AV 컨테이너 스트림을 입력받아 디코딩을 수행 한 후, AV 로(raw) 스트림을 QoE API 엔진으로 출력한다. MPEG 디코더는 MPEG 국제 표준 코덱 기반의 미디어 복호화 모듈로서, AV 스트림 패키지를 분리하기 위한 디먹싱(De-muxing) 기능을 제공한다. MPEG 인코더는 QoE API 엔진으로부터 AV 로(Raw) 스트림을 입력받아 인코딩을 수행한 후, 인코딩된 AV 컨테이너 스트림을 WebRTC 패킷화 모듈로 출력한다. MPEG 인코더는 H.264/AVC(Advanced Video Coding), H.265/HEVC(High Efficiency Video Coding)를 지원할 수 있다. MPEG 인코더는 MP4, avi, mkw format 등을 지원할 수 있다. MPEG 인코더는 MPEG 국제 표준 코덱 기반의 미디어 부호화 모듈로서, 비디오 스트림을 포함한 오디오 스트 림을 패키지 형태로 구성하기 위한 먹싱(muxing)을 통한 컨테이너(container) 기능을 제공한다. WebRTC 패킷화 모듈은 MPEG 인코더로부터 인코딩된 AV 컨테이너 스트림을 입력받아 패킷화를 수행하 여 WebRTC 표준 기반의 패킷들을 WebRTC 송신 모듈로 출력한다. 이때, WebRTC 패킷화 모듈은 적어도하나의 QoE API를 적용한 인코딩된 AV 컨테이너 스트림을 입력받을 수 있다. WebRTC 패킷화 모듈은 WebRTC 표준 기반의 실시간 미디어 전송을 위해 부호화된 AV 스트림을 정의한 크기 의 패킷으로 재구성한다. QoE API 엔진은 복수개의 DL-SR 기반의 QoE API를 입력받은 디코딩된 로 비디오 스트림에 적용하여 적응적 인 QoS 관리를 수행한다. 앞서 설명한 바와 같이, 한 실시예에 따르면, QoE API 엔진은 DL-SR 비디오 인코 더, DL-SR 보간 모듈, DL-SR 오브젝트 보간 모듈, DL-SR 고주파수 보간 모듈 등을 포함할 수 있다. 이때, QoE API 엔진은 도면에 표시된 모듈로 제한되지 않고, 다양한 QoE API 모듈로 확장될 수 있다. DL-SR 비디오 인코더는 AV 로 스트림에 DL-SR 비디오 인코딩 API를 적용한다. 이때, DL-SR 비디오 인코딩 API를 적용한 경우, AV 스트림은 MPEG 인코더를 바이패스한다. DL-SR 보간 모듈은 AV 로 스트림에 DL-SR 보간 API를 적용한다. DL-SR 오브젝트 보간 모듈은 AV 로 스트림에 DL-SR 오브젝트 보간 API를 적용한다. DL-SR 고주파수 보간 모듈은 AV 로 스트림에 DL-SR 고주파수 보간 API를 적용한다. 도 4는 한 실시예에 따른 WebRTC 클라이언트의 구성을 나타낸 블록도이다. 도 4를 참조하면, WebRTC 클라이언트는 QoS 제어 모듈, WebRTC 수신 모듈, WebRTC 역패킷화 모 듈, MPEG 디코더, QoE API 엔진, MPEG 인코더, WebRTC 패킷화 모듈, WebRTC 송신 모 듈, 재생부를 포함할 수 있다. 이때, WebRTC 수신 모듈은 도 3에서 설명한 WebRTC 수신 모듈과 유사한 동작을 수행하고, WebRTC 역 패킷화 모듈은 도 3에서 설명한 WebRTC 역패킷화 모듈과 유사한 동작을 수행하고, MPEG 디코더 는 도 3에서 설명한 MPEG 디코더와 유사한 동작을 수행하고, QoE API 엔진은 도 3에서 설명한 QoE API 엔진과 유사한 동작을 수행하고, MPEG 인코더는 도 3에서 설명한 MPEG 인코더와 유사한 동 작을 수행하고, WebRTC 패킷화 모듈은 도 3에서 설명한 WebRTC 패킷화 모듈과 유사한 동작을 수행하 고, WebRTC 송신 모듈은 도 3에서 설명한 WebRTC 송신 모듈과 유사한 동작을 수행한다. 다만, 업링크와 다운링크의 방향이 달라지고 그에 따른 상이한 동작을 수행할 수 있다. QoE API 엔진은 QoS 제어 모듈의 제어에 따라 오프로딩이 결정된 QoE API를 수신 AV 스트림에 적용한 다. QoE API를 적용하여 가공된 AV 스트림은 재생부로 출력된다. 재생부는 QoE API를 적용하여 가공 된 AV 스트림을 재생하여 스크린 및 스피커를 통해 출력할 수 있다. QoS 제어 모듈은 WebRTC MEC 서버와 QoS 피드백 메시지를 송수신한다. QoS 제어 모듈은 QoS 피 드백 메시지를 이용하여 초기 하드웨어 리소스 용량, 하드웨어 리소스 사용량, 네트워크 용량을 WebRTC MEC 서 버에게 리포트한다. QoS 제어 모듈은 QoS 피드백 메시지를 이용하여 WebRTC MEC 서버로부터 QoE API의 오프로딩 결정값, QoE API 결정값을 수신할 수 있다. QoS 제어 모듈은 QoE API의 오프로딩 결정값, QoE API 결정값에 따라 WebRTC 클라이언트에서 수행해 야할 QoE API를 AV 스트림에 적용하도록 QoE API 엔진을 제어한다. 도 5는 한 실시예에 따른 WebRTC 스트림 제어 방법을 나타낸 흐름도로서, 도 1 ~ 도 4에서 설명한 WebRTC MEC 서버와 WebRTC 클라이언트 간의 연동 동작에 대해 설명한다. 도 5를 참조하면, WebRTC MEC 서버는 WebRTC 클라이언트로부터 WebRTC 연결 요청 메시지를 수신 (S101)하고, WebRTC 연결 응답 메시지를 회신(S102)함으로써, WebRTC 클라이언트와 연결된다. 이때, WebRTC MEC 서버와 WebRTC 클라이언트는 TCP(Transmission Control Protocol)/IP(Internet Protocol) 기반의 WebRTC 연결 요청/응답 메시지를 송수신한다.S101의 WebRTC 연결 요청 메시지는 WebRTC 클라이언트의 초기 하드웨어 파라미터를 포함한다. 초기 하드웨 어 파라미터는 초기 하드웨어 리소스 용량을 포함할 수 있다. WebRTC 클라이언트는 마이크 입력 신호 및 카메라 입력 신호를 토대로 AV 스트림을 생성(S103)하여 WebRTC MEC 서버에게 전송한다(S104). WebRTC 클라이언트는 AV 스트림을 송수신 하는 과정에서 QoS 피드백 메시지를 전송(S105)하며 이 메시지는 WebRTC 표준을 따른다. S103의 AV 스트림은 UDP(User Datagram Protocol)/IP(Internet Protocol) 기반으로 전송되고, S105의 피드백 메시지는 TCP/IP 기반으로 전송된다. 이때, 사용되는 IP 주소와 포트는 다를 수 있으며, WebRTC 표준을 따른다. S105의 피드백 메시지는 하드웨어 리소스 사용량, 네트워크 용량을 포함한다. 네트워크 용량은 WebRTC MEC 서버 와 WebRTC 클라이언트 간의 송수신이 수행되는 동안 발생하는 네트워크 자원의 소비 그리고 상태에 대한 정보로서, 소비 대역폭(consumed bandwidth), 가용 대역폭(available bandwidth), 레이턴시(latency), BER(bit error ratio), PLR(packet loss rate)을 포함할 수 있으며, 이러한 정보를 바탕으로 실시간 QoS 적응 (adaptation)에 이용된다. S101의 초기 하드웨어 리소스 용량, S105의 하드웨어 리소스 사용량은 하드웨어 성능을 나타내는 지표로서, CPU(Central Processing Unit) 성능 수치, GPU(Graphic Processing Unit) 성능 수치, RAM(Random access memory) 성능 수치, 스토리지(storage) 성능 수치 중 적어도 하나를 포함할 수 있다. CPU 성능 수치, GPU 성능 수치, RAM 성능 수치는 CPU, GPU, RAM의 실시간 사용량과 가용량을 나타내는 지표로서, 초당 클럭(clock) 수 (number of clocks/sec)로 표현된다. 스토리지 성능 수치는 스토리지의 실시간 사용량과 사용량을 나타내기 위 한 지표로서, 바이트(bytes) 단위로 표현된다. 이때, 하드웨어 리소스 용량/사용량은 CPU, GPU, RAM의 초당 clock 수를 합산하여 하나의 통합된 수치로 표현될 수 있다. WebRTC MEC 서버는 연결되어 있는 WebRTC 클라이언트의 전체 개수를 카운트하고, 카운트 개수에 기초 하여 실시간 스트리밍 모드 또는 메시 모드(Mesh mode) 중에서 동작 모드를 결정한다(S106). 여기서, 실시간 스 트리밍 모드는 SFU(Selective Forwarding Unit) 모드 또는 MCU(Multi-point Control Unit) 모드를 포함할 수 있다. 이때, 동작 모드가 결정되면, WebRTC 표준 기반 시그널링을 통해 WebRTC 클라이언트는 결정된 동작 모드로 동작하도록 포트를 조정하고 연결 형식을 맞추는 작업을 수행하며, 이는 AV 스트림 전송을 동작 모드에 맞게 진 행하기 위한 절차이다. WebRTC 클라이언트의 카운트 개수에 기초하여 동작 모드를 결정하는 이유는, 클라이언트 수에 따른 하드웨 어 및 네트워크 리소스의 과부하로 인해 발생할 수 있는 문제들, 예, 패킷 손실(packet loss), 레이턴시 (latency), 차단(disconnection)을 예방하기 위해서이다. 또한, 본 발명의 동작은 WebRTC 표준을 따르지만, WebRTC MEC 서버와 같은 중간 서버가 없는 형태의 스트 리밍 방식(Mesh 모드)에는 적용되지 않기 때문에, 동작 모드가 SFU 또는 MCU인지 판단한다. 이 때, 해당 과정은 WebRTC 표준을 따른다. WebRTC 표준에서는 중앙 서버가 존재하며, 중앙 서버에서는 접속한 클라이언트의 수와 네트워크 정보를 바탕으로 모드를 결정한다. 메시 모드는 초기 클라이언트 간의 연결을 위한 중계를 수행하고 연결이 완료된 후에 중앙 서버는 별도의 동작을 수행하지 않고 클라이언트간 직접 연결을 통해 데이터를 송수신 하는 모드이다. MCU 모드 또는 SFU 모드는 중앙 서버가 데이터 송수신에 관여하며 클라이언트의 수에 따른 네트워크 또는 하드 웨어 리소스를 고려하여 모드를 결정한다. 클라이언트의 수가 적은 경우 실시간성이 보장되는 SFU가 적절하며 반대로, 클라이언트의 수가 급격히 증가하는 경우 네트워크 및 하드웨어 리소스의 과부하 문제를 해결하기 위해 MCU 방식의 스트리밍이 적절하다. 이 때, SFU 모드의 중앙 서버는 네트워크 트래픽 제어 즉, QoS 제어를 수행하고 MCU 모드의 중앙 서버는 QoS 제 어를 포함한 AV 스트림의 합성 및 가공을 수행하고 이를 위해 높은 컴퓨팅 파워(computing power)를 필요로 한 다.여기서, 본 발명의 실시예에서 중앙 서버는 WebRTC MEC 서버이다. WebRTC MEC 서버는 S106에서 결정한 동작 모드가 SFU 모드 또는 MCU 모드인지 판단(S107)하고, SFU 모드 또는 MCU 모드가 아니라면, 메시 모드 동작을 구동한다(S108). 메시 모드는 종래에 공지된 기술이므로, 자세한 설명은 생략한다. WebRTC MEC 서버는 QoE API 단위로 오프로딩 여부를 결정한다(S109). 즉, 복수개의 QoE API 별로 해당 QoE API를 클라이언트로 분산하여 적용할지 여부를 결정한다(S109). 이때, WebRTC MEC 서버는 WebRTC MEC 서버와 WebRTC 클라이언트 각각의 하드웨어 리소스 사용 량, 네트워크 용량을 토대로, 오프로딩 여부를 결정할 수 있다. WebRTC MEC 서버는 자신의 실시간 하드웨 어 리소스 사용량을 측정할 수 있다. WebRTC MEC 서버는 오프로딩 결정 정보를 포함하는 QoS 피드백 메시지를 WebRTC 클라이언트에게 전송 한다(S110). 오프로딩 결정 정보는 오프로딩 여부를 나타내는 지시자(플래그)를 포함하고, 오프로딩이 결정된 경우, 오프로딩 되기로 결정된 QoE API 식별자를 추가로 포함할 수 있다. WebRTC MEC 서버는 S109의 결정에 기초하여, QoE API의 오프로딩 결정 여부를 판단한다(S111). WebRTC MEC 서버는 QoE API의 오프로딩이 결정되지 않은 경우, 복수의 WebRTC 클라이언트로로부터 수 신한 AV 스트림을 합성하고, 복수의 QoE API를 이용하여, 합성된 AV 스트림을 가공한다(S112). WebRTC MEC 서버는 가공/합성된 AV 스트림을 개별 WebRTC 클라이언트에게 전송한다(S113). 그러면, WebRTC 클라이언트는 가공/합성된 AV 스트림을 재생한다(S114). WebRTC MEC 서버는 QoE API의 오프로딩이 결정된 경우, 복수의 WebRTC 클라이언트로로부터 수신한 AV 스트림을 합성(S115)하고, 합성된 AV 스트림을 러프(Rough)하게 가공한 후, WebRTC 클라이언트로에게 전송한다(S116). 그러면, WebRTC 클라이언트로는 오프로딩 결정된 QoE API를 이용하여, 합성된 AV 스트림 을 가공한 후 재생한다(S117). 이때, WebRTC MEC 서버는 일부 QoE API에 대해서 오프로딩을 결정할 수 있으므로, S112~S117은 QoE API 단위로 이루어질 수 있다. 즉, 일부 QoE API를 이용해서 서버 단에서 가공이 이루어지고, 나머지 QoE API는 클 라이언트 단에서 가공이 이루어질 수 있다. WebRTC MEC 서버는 S109의 결정에 따라, 복수개의 QoE API를 모듈화된(modulized) API 단위로 일부 처리 하고 나머지는 WebRTC 클라이언트에 오프로딩하여 처리할 수 있다. 시변하는 상황에서 특정 시간에 따른 하드웨어 리소스와 네트워크 리소스 측정값에 따라 모듈화된 복수개의 QoE API의 오프로딩 비율은 적응적으로 변화할 수 있다. 예를 들어, DL-SR 고주파 보간 API는 영상의 고주파 영역은 서버에서 가공하고 영상의 나머지 저주파 영역은 클라이언트에서 가공할 수 있다. 이에 대한 비율 정도는 영상 특성에 따라 다르겠지만 normal한 영상 회의라고 가정했을 때, '고주파 영역:저주파 영역 = 4 : 6' 정도로 표현 될 수 있으며, 이는 DL-SR 고주파 보간 API에 설정되어 있는 정보에 따라 수행된다. S103 ~ S117은 WebRTC 클라이언트가 서비스를 종료할 때까지 반복적으로 이루어진다. 통상, 서비스 종료는 WebRTC 클라이언트가 웹 기반 윈도우 창을 닫거나 접속 종료 버튼의 클릭에 따른 시그널링 절차를 통해 종 료 메시지가 WebRTC MEC 서버로 전달되면, 서비스가 종료된다. 또한, 복수개의 QoE API 중에서 룰 기반의 우선순위를 적용할 수 있다. S109를 통해 오프로딩하기로 결정되었다 하더라도, 혹은, 오프로딩 여부를 결정하기 전에 서버의 리소스 가용량만을 고려해서 다른 QoE API들에 비해 상 대적으로 우선순위가 높은 QoE API를 우선적으로 서버 단에서 수행할 수 있다. 기본적으로, DL-SR 기반의 미디어 처리는 매우 높은 수준의 연산량과 복잡도를 요구한다. 따라서, 이를 충족할 수 있도록 본 발명의 실시예에 따라 QoE API를 모듈화하여 E2E(End to End) 간 가용 리소스를 고려한 분산 처리 (offloading)를 수행한다. 도 6은 한 실시예에 따른 QoE API 오프로딩 결정 동작을 설명하는 순서도로서, 도 1 ~ 도 5에서 설명한 WebRTC MEC 서버의 QoS 매니저 모듈의 동작을 나타낸다.도 6을 참조하면, QoS 매니저 모듈은 WebRTC 클라이언트로부터 수신한 연결 요청 메시지로부터 초기 하드웨어 리소스(Resource) 정보를 추출한다(S201). 여기서, 초기 하드웨어 리소스 정보는 초기 하드웨어 리소 스 용량을 포함한다. QoS 매니저 모듈은 WebRTC 클라이언트로부터 수신한 QoS 피드백 메시지로부터 QoS 리소스 용량 정보 를 추출한다(S202). 여기서, 추출한 QoS 리소스 용량 정보는 하드웨어 리소스 사용량과 네트워크 용량을 포함한 다. 초기 하드웨어 리소스 용량과 하드웨어 리소스 사용량은 CPU, GPU, RAM의 용량을 초당 클록(Clock)수로 변환하 여 computation된 수치를 통합한 수치로 표현되어 수학식 1과 2에서 이용될 수 있다. QoS 매니저 모듈은 S201에서 수신한 초기 하드웨어 리소스 용량과 S202에서 수신한 하드웨어 리소스 사용 량을 이용하여, WebRTC 클라이언트의 하드웨어 리소스 가용량을 계산한다(S203). 하드웨어 리소스 가용량 의 계산을 수식으로 나타내면 수학식 1과 같다. [수학식 1]"}
{"patent_id": "10-2023-0010059", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "는 WebRTC MEC 서버(i)에 연결된 WebRTC 클라이언트(j)의 하드웨어 리소스 가용량이다. 는 WebRTC MEC 서버(i)에 연결된 WebRTC 클라이언트(j)의 초기 하드웨어 리소스 용량(consumed IT resource in client side), 즉, 사용되기 전의 초기 가용량을 의미한다. 는 WebRTC MEC 서버(i)에 연결된 WebRTC 클라이언트(j)의 하드웨어 리소스 사용량(consumed IT resource in client side)을 의미한다. 여기서, 는 S201에서 수신하였고, 는 S202에서 수신하였다. QoS 매니저 모듈은 WebRTC MEC 서버의 하드웨어 리소스 가용량을 계산(S204)하며, 이를 수식으로 나 타내면, 수학식 2와 같다. [수학식 2]"}
{"patent_id": "10-2023-0010059", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "는 MEC 서버(i)의 하드웨어 리소스 가용량이다. 는 MEC 서버(i)에 설정/측정된 값으로서, MEC 서버(i)의 초기 하드웨어 리소스 가용량(initial IT resource in server side), 즉, 사용되기 전의 초기 가용량을 의미한다. 는 WebRTC 코어 클라우드(core cloud)의 로드 밸런싱 정책(load balancing policy)에 따라 가변될 수 있다. 는 MEC 서버(i)의 하드웨어 리소스 사용량(consumed IT resource in server side)으로서, MEC 서버(i)에 연 결된 k개의 클라이언트(j)의 하드웨어 리소스 사용량( )을 합산하여 도출된다. QoS 매니저 모듈은 QoE API 엔진에 정의된 QoE API들의 실시간성을 고려한 전송률(transmission rate)과 연산량(computation)을 에너지 단위로 변환한다(S205). 연산량을 에너지 단위로 변환하면, 수학식 3, 4와 같은 미디어 프로세싱 에너지로 환산된다. 실시간 전송률을 에너지 단위로 변환하면, 수학식 5와 같은 전송 에너지로 환산된다. 여기서, QoE API는 복수개로 구성되고, 분산 처리를 위해 모듈 단위로 분리가 가능하며 본 발명의 실시예에서는 모듈화된(modulized) API로 정의한다. 전술한 바와 같이, 모듈화된 API는 DL-SR 비디오 인코더 API, DL-SR 보 간 API, DL-SR 오브젝트 보간 API, DL-SR 주파수 보간 API, 다른 예약된 DL-SR API 등을 포함할 수 있다. 하나의 AV 스트림에 대해 모듈화된 API를 적용할 수 있으며, 이중에서 일부 QoE API는 WebRTC MEC 서버를 통해 적용하고, 일부는 WebRTC 클라이언트를 통해 적용할 수 있으며, 이처럼 모듈화된 API를 분산하여 적 용하는 것을 오프로딩이라 한다. WebRTC MEC 서버에서 모듈화된 QoE API를 AV 스트림에 적용하기 위해 필요한 미디어 프로세싱 에너지 (media processing energy), 즉, 은 수학식 3과 같다. [수학식 3]"}
{"patent_id": "10-2023-0010059", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "여기서, 은 하나의 어플리케이션을 구성하는 복수개의 모듈화된 API 중에서 단일 모듈화된 API를 AV 스트림 에 적용할 때 필요한 프로세싱 에너지라 정의할 수 있다. 예컨대, 은 DL-SR 비디오 인코더 API를 AV 스트림 에 적용하기 위해 필요한 프로세싱 에너지이고, 은 DL-SR 보간 API를 AV 스트림에 적용하기 위해 필요한 프 로세싱 에너지일 수 있다. 여기서, , , 는 하드웨어 리소스 용량 관련 파라미터에 해당한다. , , 는 특정 모듈화된 API를 AV 스트림에 적용하기 위해 정의된 상수로서, WebRTC MEC 서버에 저장되 어 있다. 는 특정 모듈화된 API를 AV 스트림에 적용하기 위해 필요한 미디어 프로세서 성능치(modulized media processor computation)이다. 는 디바이스 사양(device specification)으로서, 단위는 Hz를 사용한다. 는 프로세서(예, CPU)의 단위 시간당 처리량으로서, 예컨대, 초당 처리 클럭수이다. 는 특정 모듈화된 API를 AV 스트림에 적용하는데 필요한 소비 전력(device consumed power)이다. 복수개의 모듈화된 API에 대한 전체 프로세싱 에너지, 즉, 은 수학식 4와 같다. 수학식 4를 구하는 이유는, 네트워크 리소스와 하드웨어 리소스를 에너지 변환 계수를 이용하여 에너지 단위로 통합하고 오프로딩에 따른 전체 에너지 효율을 계산한다. 이를 통해, 가장 에너지 효율이 높은 경우를 찾고 해 당 방식으로 스트리밍 서비스를 수행하기 위함이다. [수학식 4] 수학식 3에서 설명한 바와 같이, 하나의 어플리케이션은 복수개( )의 모듈화된 API로 구성되며, 각각의 모듈화된 API를 대상으로 계산된 수학식 3의 미디어 프로세싱 에너지를 합산하면, 수학식 4와 같이, 전체 미디 어 프로세싱 에너지가 산출된다. AV 스트림을 다양한 어플리케이션을 통해 가공할 수 있는데, 이때, 하나의 어플리케이션을 여러 개의 모듈, 즉, 복수개( )의 모듈화된 API로 분리하고, 복수개의 모듈화된 API는 오프로딩(offloading)을 통한 분산 처 리될 수 있다. AV 스트림을 상용 네트워크의 다운링크(Downlink) 환경에서 전송할 때, 발생하는 전송 에너지(transmission energy), 즉, 는 수학식 5와 같이 정의될 수 있다. [수학식 5]"}
{"patent_id": "10-2023-0010059", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 7, "content": "여기서, D, B, Tx는 네트워크 리소스 용량 관련 파라미터에 해당한다. D는 전송 데이터 사이즈(transmission data size)로서, 전송할 AV 스트림의 데이터 사이즈를 말한다. B는 네트워크 대역폭(network bandwidth)으로서, WebRTC 클라이언트와 WebRTC MEC 서버 간의 데이터 송수신 경 로 상의 네트워크 대역폭을 말한다. B는 bits/sec(bitrate)로 표현된다. B는 WebRTC 클라이언트로부터 수신한 QoS 피드백 메시지로부터 획득된다. 는 AV 스트림을 전송할 때 필요한 전송 전력이다. 여기서, D와 는 WebRTC MEC 서버에 설정된 상수이다. , 는 에너지 단위로 변환하기 위한 상관 계수(coefficient)로서 상용 무선망 전송 및 소비 전력에 따른 전 력 소모 표준을 따른다. QoS 매니저 모듈은 WebRTC 클라이언트와 WebRTC MEC 서버 각각의 하드웨어 리소스 가용량, 그 리고 미디어 프로세싱 에너지, 전송 에너지를 토대로 QoE를 측정하고, 측정 결과를 토대로 모듈화된 QoE API의 오프로딩(offloading) 여부를 결정한다. QoE는 품질(Quality)과 실시간성(realtime)에 좌우되며, 이를 수식화하면, 수학식 6과 같다. [수학식 6]"}
{"patent_id": "10-2023-0010059", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 8, "content": "여기서, α, β는 가중치(weight)로서, 서비스의 종류에 따라 다른 값으로 정의된다. 예를 들어, WebRTC 기반 화상 회의 서비스에서의 QoE는 realtime에 대한 중요도가 높다. 따라서, β는 α보다 상대적으로 큰 값으로 정의될 수 있다. 수학식 6을 하드웨어 리소스 가용량, 그리고 미디어 프로세싱 에너지, 전송 에너지를 적용하여, 수학식 7과 같 이 나타낼 수 있다. 이때, 수학식 7은 복수개의 모듈화된 API 중에서 특정 모듈화된 API를 대상으로 계산된다. 즉, 특정 모듈화된 API의 수행 주체를 서버로 할지 또는 클라이언트로 할지, 즉, 오프로딩 여부를 결정하는 수식이다.[수학식 7]"}
{"patent_id": "10-2023-0010059", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 9, "content": "는 WebRTC MEC 서버의 프로세서(예, CPU)의 단위 시간당 처리량이고, 는 WebRTC 클라이언트의 프로세서 (예, CPU)의 단위 시간당 처리량이다. 는 WebRTC MEC 서버의 특정 모듈화된 QoE API를 수행하는데 필요한 소비 전력이고, 는 WebRTC 클라이언 트의 특정 모듈화된 QoE API를 수행하는데 필요한 소비 전력이다. 수학식 7을 해석하면, WebRTC MEC 서버 관점의 E와 WebRTC 클라이언트 관점의 E를 모두 최대가 되게 하는"}
{"patent_id": "10-2023-0010059", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 10, "content": "를 구하고자 한다. 이 때, 에 대해 이다. =0이면, QoS 매니저 모듈은 특정 모듈화된 QoE API(y)를 WebRTC MEC 서버에서 수행하기로 결정, 즉, 오프로딩하지 않기로 결정한다. =1이면, QoS 매니저 모듈은 특정 모듈화된 QoE API(y)를 WebRTC 클라이언트에서 수행하기로 결정, 즉, 오프로딩하기로 결정한다. QoS 매니저 모듈은 오프로딩 결정 정보(offloading decision flag)를 포함하는 QoS 피드백 메시지를 WebRTC 클라이언트에게 전송한다(S111). 오프로딩 결정 정보는 오프로딩 여부를 나타내는 지시자, 즉, 와 해당하는 특정 QoE API 식별자를 포함할 수 있다. 한편, QoS 매니저 모듈은 수학식 7의 변수들, 즉, , , , , , , , 을 학습 데이터로 사용하여, 를 도출하는 최적화 모델을 생성할 수 있다. 예시적으로, 최적화 모델은 CPLEX Optimizer 엔진이 사용될 수 있으나, 이에 국한되는 것은 아니다. 최적화 모델은 수학식 8과 같이 정의된다. [수학식 8]"}
{"patent_id": "10-2023-0010059", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 11, "content": "수학식 8의 최적화 모델은 결정계수( )를 출력하며, 결정 계수가 1이면 오프로딩을 결정하고, 결정 계수가 0이 면 오프로딩을 하지 않기로 결정된다. 이상, 도 1 ~ 도 6에서 설명한 WebRTC MEC 서버와 WebRTC 클라이언트는 컴퓨팅 장치로 구현될 수 있 다. 도 7은 한 실시예에 따른 컴퓨팅 장치의 하드웨어 구성을 나타낸 블록도이다. 도 7을 참조하면, 컴퓨팅 장치는 하나 이상의 프로세서, 프로세서에 의하여 수행되는 프로그램 을 로드하는 메모리, 프로그램 및 각종 데이터를 저장하는 스토리지, 및 통신 인터페이스를 포 함할 수 있다. 다만, 상술한 구성 요소들은 본 개시에 따른 컴퓨팅 장치를 구현하는데 있어서 필수적인 것 은 아니어서, 컴퓨팅 장치는 위에서 열거된 구성요소들 보다 많거나, 또는 적은 구성요소들을 가질 수 있 다. 예컨대 컴퓨팅 장치는 출력부 및/또는 입력부(미도시)를 더 포함하거나, 또는 스토리지가 생략될 수도 있다. 프로그램은 메모리에 로드될 때 프로세서로 하여금 본 개시의 다양한 실시예에 따른 방법/동작을 수 행하게끔 하는 명령어들(instructions)을 포함할 수 있다. 즉, 프로세서는 명령어들을 실행함으로써, 본 개시의 다양한 실시예에 따른 방법/동작들을 수행할 수 있다. 프로그램은 기능을 기준으로 묶인 일련의 컴퓨터 판독가능 명령어들로 구성되고, 프로세서에 의해 실행되는 것을 가리킨다. 프로세서는 컴퓨팅 장치의 각 구성의 전반적인 동작을 제어한다. 프로세서는 CPU(Central Processing Unit), MPU(Micro Processor Unit), MCU(Micro Controller Unit), GPU(Graphic Processing Unit) 또는 본 개시의 기술 분야에 잘 알려진 임의의 형태의 프로세서 중 적어도 하나를 포함하여 구성될 수 있다. 또 한, 프로세서는 본 개시의 다양한 실시예들에 따른 방법/동작을 실행하기 위한 적어도 하나의 애플리케이 션 또는 프로그램에 대한 연산을 수행할 수 있다. 메모리는 각종 데이터, 명령 및/또는 정보를 저장한다. 메모리는 본 개시의 다양한 실시예들에 따른 방법/동작을 실행하기 위하여 스토리지로부터 하나 이상의 프로그램을 로드할 수 있다. 메모리는 RAM 과 같은 휘발성 메모리로 구현될 수 있을 것이나, 본 개시의 기술적 범위는 이에 한정되지 않는다. 스토리지는 프로그램을 비임시적으로 저장할 수 있다. 스토리지는 ROM(Read Only Memory), EPROM(Erasable Programmable ROM), EEPROM(Electrically Erasable Programmable ROM), 플래시 메모리 등과 같은 비휘발성 메모리, 하드 디스크, 착탈형 디스크, 또는 본 개시가 속하는 기술 분야에서 잘 알려진 임의의 형태의 컴퓨터로 읽을 수 있는 기록 매체를 포함하여 구성될 수 있다. 통신 인터페이스는 유/무선 통신 모 듈일 수 있다. 이상에서 설명한 본 개시의 실시예는 장치 및 방법을 통해서만 구현이 되는 것은 아니며, 본 개시의 실시예의 구성에 대응하는 기능을 실현하는 프로그램 또는 그 프로그램이 기록된 기록 매체를 통해 구현될 수도 있다. 이상에서 본 개시의 실시예에 대하여 상세하게 설명하였지만 본 개시의 권리범위는 이에 한정되는 것은 아니고 다음의 청구범위에서 정의하고 있는 본 개시의 기본 개념을 이용한 당업자의 여러 변형 및 개량 형태 또한 본 개시의 권리범위에 속하는 것이다.도면 도면1 도면2 도면3 도면4 도면5 도면6 도면7"}
{"patent_id": "10-2023-0010059", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 한 실시예에 따른 WebRTC(Web Real-Time Communication) 스트림 제어 시스템의 구성도이다. 도 2는 도 1의 WebRTC 스트림 제어 시스템이 적용된 일반적인 클라우드 환경 구조를 나타낸다. 도 3은 한 실시예에 따른 WebRTC MEC 서버의 구성을 나타낸 블록도이다. 도 4는 한 실시예에 따른 WebRTC 클라이언트의 구성을 나타낸 블록도이다. 도 5는 한 실시예에 따른 WebRTC 스트림 제어 방법을 나타낸 흐름도이다. 도 6은 한 실시예에 따른 QoE API 오프로딩 결정 동작을 설명하는 순서도이다. 도 7은 한 실시예에 따른 컴퓨팅 장치의 하드웨어 구성을 나타낸 블록도이다."}
