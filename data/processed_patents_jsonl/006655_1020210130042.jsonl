{"patent_id": "10-2021-0130042", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2022-0065666", "출원번호": "10-2021-0130042", "발명의 명칭": "비디오 처리 장치 및 방법", "출원인": "삼성전자주식회사", "발명자": "후이 장"}}
{"patent_id": "10-2021-0130042", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "비디오 데이터의 제1 이미지의 제1 이미지 특징 및 제1 이미지 이전의 제2 이미지의 제2 이미지 특징을 획득하는 단계;상기 제1 이미지 특징 및 상기 제2 이미지 특징에 대해 시간-도메인(time domain) 정보 융합 처리를 진행하여,시간-도메인 정보 융합 처리 결과를 획득하는 단계; 및상기 시간-도메인 정보 융합 처리 결과에 따라 상기 제1 이미지의 파노라마 분할 결과를 획득하는 단계를 포함하는 비디오 처리 방법."}
{"patent_id": "10-2021-0130042", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 시간-도메인 정보 융합 처리 결과에 따라 상기 제1 이미지의 파노라마 분할 결과를 획득하는 단계는,상기 시간-도메인 정보 융합 처리 결과를 기반으로 상기 제1 이미지에 대해 인스턴스 추적을 수행하여, 상기 제1 이미지의 프레임 간의 인스턴스 대응을 획득하는 단계; 및상기 제1 이미지의 프레임 간의 인스턴스 대응에 따라, 상기 제1 이미지의 파노라마 분할 결과를 획득하는 단계를 포함하는 비디오 처리 방법."}
{"patent_id": "10-2021-0130042", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,상기 시간-도메인 정보 융합 처리 결과에 따라 상기 제1 이미지의 파노라마 분할 결과를 획득하는 단계는,상기 시간-도메인 정보 융합 처리 결과를 기반으로 상기 제1 이미지에 대해 시맨틱(semantic) 분할, 인스턴스분할 및 바운딩 박스 세분화(refinement)를 수행하여, 상기 제1 이미지의 시맨틱 분할 결과, 상기 제1 이미지의인스턴스 분할 결과 및 상기 제1 이미지의 바운딩 박스를 획득하는 단계를 더 포함하고,상기 제1 이미지의 프레임 간의 인스턴스 대응에 따라, 상기 제1 이미지의 파노라마 분할 결과를 획득하는 단계는,상기 제1 이미지의 시맨틱 분할 결과, 상기 제1 이미지의 인스턴스 분할 결과, 상기 제1 이미지의 바운딩 박스및 상기 제1 이미지의 프레임 간의 인스턴스 대응을 융합하여, 상기 제1 이미지의 파노라마 분할 결과를 획득하는 단계를 포함하는 비디오 처리 방법."}
{"patent_id": "10-2021-0130042", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,상기 비디오 데이터의 상기 제1 이미지의 제1 이미지 특징 및 상기 제1 이미지 이전의 상기 제2 이미지의 제2이미지 특징을 획득하는 단계는,공개특허 10-2022-0065666-3-특징 추출 네트워크를 통해 상기 제1 이미지 및 상기 제2 이미지 각각에 대해 특징 추출을 수행하여, 상기 제1이미지의 제1 이미지 특징 및 상기 제2 이미지의 제2 이미지 특징을 획득하는 단계를 포함하는 비디오 처리 방법."}
{"patent_id": "10-2021-0130042", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서,상기 시간-도메인 정보 융합 처리 결과는,상기 제1 이미지의 제1 시간-도메인 통합 특징 및 상기 제2 이미지의 제2 시간-도메인 통합 특징을 포함하는 비디오 처리 방법."}
{"patent_id": "10-2021-0130042", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서,상기 제1 이미지 특징 및 상기 제2 이미지 특징에 대해 상기 시간-도메인 정보 융합 처리를 진행하여, 상기 시간-도메인 정보 융합 처리 결과를 획득하는 단계는,상기 제1 이미지 특징 및 상기 제2 이미지 특징에 대해 조합 연산을 수행하는 단계;조합된 이미지 특징을 2개의 경로(path)로 분할하고, 제1 경로에 대해 상관성 처리를 수행하는 단계;상기 제1 경로의 상관성 처리 결과와 제2 경로에 대해 요소별로 덧셈 연산(add operation)을 진행하는 단계; 및요소별 덧셈 연산 결과에 따라 상기 시간-도메인 정보 융합 처리 결과를 획득하는 단계를 포함하는 비디오 처리 방법."}
{"patent_id": "10-2021-0130042", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6항에 있어서,상기 제1 경로에 대해 상관성 처리를 수행하는 단계는,상기 제1 경로에 대해 적어도 한 번의 컨볼루션 연산을 수행하는 단계; 및상기 컨볼루션 연산 후의 상기 제1 경로를 공간-도메인(space domain) 융합을 위한 네트워크에 입력하고, 상기공간-도메인 융합을 위한 네트워크를 통해 상관성 처리를 수행하는 단계를 포함하는 비디오 처리 방법."}
{"patent_id": "10-2021-0130042", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서,상기 공간-도메인 융합을 위한 네트워크를 통해 상기 상관성 처리를 수행하는 단계는,상기 공간-도메인 융합을 위한 네트워크에 입력된 특징을 적어도 2개의 경로로 나누고, 상기 적어도 2개의 경로중 일부 또는 전부에 대해 서브 도메인을 추출하는 단계;서브 도메인 추출 결과에 대해 행렬 곱셈 연산을 수행하는 단계; 및행렬 곱셈 연산 결과와 상기 공간-도메인 융합을 위한 네트워크에 입력된 특징에 대해 요소별 덧셈 연산을 수행하는 단계공개특허 10-2022-0065666-4-를 포함하는 것인, 비디오 처리 방법."}
{"patent_id": "10-2021-0130042", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제7항에 있어서,상기 공간-도메인 융합을 위한 네트워크를 통해 상기 상관성 처리를 수행하는 단계는,컨볼루션 연산된 조합 특징을 4개의 경로로 나누는 단계;상기 4개의 경로 중 제1 경로, 제2 경로 및 제3 경로에 대해 각각 서브 도메인 추출을 진행하는 단계;상기 4개의 경로 중 상기 제1 경로의 서브 도메인 추출 결과와 상기 제2 경로의 서브 도메인 추출 결과에 대해행렬 곱셈 연산을 수행하고, 행렬 곱셈 연산 결과와 상기 4개의 경로 중 상기 제3 경로의 서브 도메인 추출 결과에 대해 행렬 곱셈 연산을 수행하는 단계; 및상기 제3 경로의 서브 도메인 추출 결과에 대해 행렬 곱셈 연산을 수행한 결과와 상기 4개의 경로 중 제4 경로에 대해 요소별 덧셈 연산을 수행하는 단계를 포함하는 비디오 처리 방법."}
{"patent_id": "10-2021-0130042", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9항에 있어서,상기 서브 도메인 추출을 진행하는 단계는,데이터 재구성을 통해 상기 서브 도메인 추출을 진행하는 단계를 포함하는 비디오 처리 방법."}
{"patent_id": "10-2021-0130042", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제6항에 있어서,상기 제1 이미지 특징 및 상기 제2 이미지 특징에 대해 조합 연산을 수행하는 단계는,상기 제1 이미지 특징에 대해 적어도 한 번의 컨볼루션 연산을 수행하는 단계;상기 제2 이미지 특징에 대해 적어도 한 번의 컨볼루션 연산을 수행하는 단계; 및컨볼루션 연산된 제1 이미지 특징 및 컨볼루션 연산된 제2 이미지 특징에 대해 조합 연산을 수행하는 단계를 포함하는 비디오 처리 방법."}
{"patent_id": "10-2021-0130042", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항에 있어서,상기 요소별 덧셈 연산 결과에 따라 상기 시간-도메인 정보 융합 처리 결과를 획득하는 단계는,상기 요소별 덧셈 연산 결과를 2개의 경로로 나누는 단계; 상기 2개의 경로 중 각 경로의 요소별 덧셈 연산 결과에 대해 적어도 한 번의 컨볼루션 연산을 수행하는 단계;컨볼루션 연산된 상기 제1 경로의 요소별 덧셈 연산 결과와 상기 컨볼루션 연산된 제1 이미지 특징에 대해 요소별 덧셈 연산을 수행하여 제1 시간-도메인 통합 특징을 획득하는 단계; 및컨볼루션 연산된 상기 제2 경로의 요소별 덧셈 연산 결과와 상기 컨볼루션 연산된 제2 이미지 특징에 대해 요소공개특허 10-2022-0065666-5-별 덧셈 연산을 수행하여 제2 시간-도메인 통합 특징을 획득하는 단계를 포함하는 비디오 처리 방법."}
{"patent_id": "10-2021-0130042", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제6항에 있어서,상기 요소별 덧셈 연산 결과에 따라 상기 시간-도메인 정보 융합 처리 결과를 획득하는 단계는,상기 요소별 덧셈 연산 결과에 대해 적어도 한 번의 컨볼루션 연산을 수행하고, 컨볼루션 연산된 요소별 덧셈연산 결과와 상기 제2 이미지 특징을 상기 시간-도메인 정보 융합 처리 결과로 취하는 단계를 포함하는 비디오 처리 방법."}
{"patent_id": "10-2021-0130042", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제2항에 있어서,상기 시간-도메인 정보 융합 처리 결과를 기반으로 상기 제1 이미지에 대해 인스턴스 추적을 수행하여, 상기 제1 이미지의 프레임 간의 인스턴스 대응을 획득하는 단계는,제2 시간-도메인 통합 특징을 기반으로 상기 비디오 데이터의 인스턴스 데이터베이스(instance database)를 업데이트하는 단계; 및업데이트된 인스턴스 데이터베이스를 기반으로 제1 시간-도메인 통합 특징에 대해 각각 인스턴스 추적을 진행하는 단계를 포함하는 비디오 처리 방법."}
{"patent_id": "10-2021-0130042", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제14항에 있어서,상기 제2 시간-도메인 통합 특징을 기반으로 상기 비디오 데이터의 상기 인스턴스 데이터베이스를 업데이트하는단계는,상기 제2 시간-도메인 통합 특징에서 제1 개수의 기설정된 특징을 선택하는 단계; 및선택한 상기 제1 개수의 기설정된 특징을 상기 비디오 데이터의 상기 인스턴스 데이터베이스에 추가하는 단계를 포함하는 비디오 처리 방법."}
{"patent_id": "10-2021-0130042", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제14항에 있어서,업데이트된 상기 인스턴스 데이터베이스를 기반으로 상기 제1 시간-도메인 통합 특징에 대해 각각 인스턴스 추적을 진행하는 단계는,상기 제1 시간-도메인 통합 특징에서 제2 개수의 기설정된 특징을 선택하는 단계; 및선택한 상기 제2 개수의 기설정된 특징과 업데이트된 상기 인스턴스 데이터베이스를 기반으로 추적 네트워크를통해 인스턴스 대응을 진행하는 단계를 포함하는 비디오 처리 방법.공개특허 10-2022-0065666-6-청구항 17 제15항에 있어서,상기 기설정된 특징은,관심 영역 특징, 바운딩 박스에 기초하여 표현되는 특징 및 마스크에 기초하여 표현되는 특징 중에서 적어도 하나를 포함하는비디오 처리 방법."}
{"patent_id": "10-2021-0130042", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제1항 내지 제17항 중 어느 한 항의 방법을 실행하기 위한 프로그램이 기록되어 있는 것을 특징으로 하는 컴퓨터에서 판독 가능한 기록 매체."}
{"patent_id": "10-2021-0130042", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "비디오 데이터의 제1 이미지의 제1 이미지 특징 및 제1 이미지 앞의 제2 이미지의 제2 이미지 특징을 획득하도록 구성된 특징 획득부;상기 제1 이미지 특징 및 상기 제2 이미지 특징에 대해 시간-도메인 정보 융합 처리를 진행하여, 시간-도메인정보 융합 처리 결과를 획득하도록 구성된 시간-도메인 정보 융합부; 및상기 시간-도메인 정보 융합 처리 결과에 따라 상기 제1 이미지의 파노라마 분할 결과를 획득하도록 구성된 파노라마 분할부를 포함하는 것인, 비디오 처리 장치."}
{"patent_id": "10-2021-0130042", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제19항에 있어서,상기 파노라마 분할부는,상기 시간-도메인 정보 융합 처리 결과를 기반으로 상기 제1 이미지에 대해 인스턴스 추적을 수행하여, 상기 제1 이미지의 프레임 간의 인스턴스 대응을 획득하고,상기 제1 이미지의 프레임 간의 인스턴스 대응에 따라, 상기 제1 이미지의 파노라마 분할 결과를 획득하는 비디오 처리 장치."}
{"patent_id": "10-2021-0130042", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 개시는 비디오 처리 장치 및 방법에 관한 것으로, 비디오 처리 방법은 비디오 데이터의 제1 이미지의 제1 이 미지 특징 및 제1 이미지 앞의 제2 이미지의 제2 이미지 특징을 획득하고, 제1 이미지 특징 및 제2 이미지 특징 에 대해 시간-도메인 정보 융합 처리를 진행하여, 시간-도메인 정보 융합 처리 결과를 획득하고, 시간-도메인 정 보 융합 처리 결과에 따라 제1 이미지의 파노라마 분할 결과를 획득한다."}
{"patent_id": "10-2021-0130042", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "비디오 분할 기술 분야에 관한 것으로, 비디오 처리 장치 및 방법에 관한 것이다."}
{"patent_id": "10-2021-0130042", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "이미지 파노라마 분할은 2차원 이미지의 각 픽셀에 레이블 정보를 할당하는 과정이다. 이미지 콘텐츠는 두 가지 범주로 나눌 수 있다: 하나는 '비고정 형태의 사물(stuff)'로, 풀밭, 하늘, 건축물 등 다른 객체를 구별할 필요 가 없는 콘텐츠이고, 다른 하나는 '고정 형태의 사물(thing)'로, 사람, 차량 등 다른 객체를 구별해야 하는 콘 텐츠이다. 파노라마 분할 작업은 시맨틱 분할 및 인스턴스 분할 두 가지 작업의 복합 작업으로 간주할 수 있다. '비고정 형태의 사물(stuff)' 범주에 속하는 픽셀의 경우 그 시맨틱 레이블을 예측하고, '고정 형태의 사물(thing)' 범 주에 속하는 픽셀의 경우 그 인스턴스 레이블을 예측한다. 비디오 파노라마 분할은 시간-도메인 상에서의 이미지 파노라마 분할의 확장이다. 각 이미지의 파노라마 분할 외에도 객체 추적의 작업, 즉 다른 이미지의 동일한 인스턴스에 속하는 픽셀에 대해 동일한 레이블을 할당해야 하는 작업도 결합한다. 기존 비디오 파노라마 분할 기술은 비용이 많이 들고 속도가 느리며 정확도 또한 낮다."}
{"patent_id": "10-2021-0130042", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 개시의 일 실시 예에 따른 비디오 처리 방법은, 비디오 데이터의 제1 이미지의 제1 이미지 특징 및 제1 이미 지 이전의 제2 이미지의 제2 이미지 특징을 획득하는 단계; 상기 제1 이미지 특징 및 상기 제2 이미지 특징에 대해 시간-도메인(time domain) 정보 융합 처리를 진행하여, 시간-도메인 정보 융합 처리 결과를 획득하는 단계; 및 상기 시간-도메인 정보 융합 처리 결과에 따라 상기 제1 이미지의 파노라마 분할 결과를 획득하는 단 계를 포함한다. 이때, 상기 시간-도메인 정보 융합 처리 결과에 따라 상기 제1 이미지의 파노라마 분할 결과를 획득하는 단계는, 상기 시간-도메인 정보 융합 처리 결과를 기반으로 상기 제1 이미지에 대해 인스턴스 추적을 수행하여, 상기 제1 이미지의 프레임 간의 인스턴스 대응을 획득하는 단계; 및 상기 제1 이미지의 프레임 간의 인스턴스 대응에 따라, 상기 제1 이미지의 파노라마 분할 결과를 획득하는 단계를 포함할 수 있다. 이때, 상기 시간-도메인 정보 융합 처리 결과에 따라 상기 제1 이미지의 파노라마 분할 결과를 획득하는 단계는, 상기 시간-도메인 정보 융합 처리 결과를 기반으로 상기 제1 이미지에 대해 시맨틱(semantic) 분할, 인 스턴스 분할 및 바운딩 박스 세분화(refinement)를 수행하여, 상기 제1 이미지의 시맨틱 분할 결과, 상기 제1 이미지의 인스턴스 분할 결과 및 상기 제1 이미지의 바운딩 박스를 획득하는 단계를 더 포함하고, 상기 제1 이 미지의 프레임 간의 인스턴스 대응에 따라, 상기 제1 이미지의 파노라마 분할 결과를 획득하는 단계는, 상기 제 1 이미지의 시맨틱 분할 결과, 상기 제1 이미지의 인스턴스 분할 결과, 상기 제1 이미지의 바운딩 박스 및 상기 제1 이미지의 프레임 간의 인스턴스 대응을 융합하여, 상기 제1 이미지의 파노라마 분할 결과를 획득하는 단계 를 포함할 수 있다. 이때, 상기 비디오 데이터의 상기 제1 이미지의 제1 이미지 특징 및 상기 제1 이미지 이전의 상기 제2 이미지의 제2 이미지 특징을 획득하는 단계는, 특징 추출 네트워크를 통해 상기 제1 이미지 및 상기 제2 이미지 각각에 대해 특징 추출을 수행하여, 상기 제1 이미지의 제1 이미지 특징 및 상기 제2 이미지의 제2 이미지 특징을 획득 하는 단계를 포함할 수 있다. 이때, 상기 시간-도메인 정보 융합 처리 결과는, 상기 제1 이미지의 제1 시간-도메인 통합 특징 및 상기 제2 이 미지의 제2 시간-도메인 통합 특징을 포함할 수 있다. 이때, 상기 제1 이미지 특징 및 상기 제2 이미지 특징에 대해 상기 시간-도메인 정보 융합 처리를 진행하여, 상 기 시간-도메인 정보 융합 처리 결과를 획득하는 단계는, 상기 제1 이미지 특징 및 상기 제2 이미지 특징에 대 해 조합 연산을 수행하는 단계; 조합된 이미지 특징을 2개의 경로(path)로 분할하고, 제1 경로에 대해 상관성 처리를 수행하는 단계; 상기 제1 경로의 상관성 처리 결과와 제2 경로에 대해 요소별로 덧셈 연산(add operation)을 진행하는 단계; 및 요소별 덧셈 연산 결과에 따라 상기 시간-도메인 정보 융합 처리 결과를 획득 하는 단계를 포함할 수 있다. 이때, 상기 제1 경로에 대해 상관성 처리를 수행하는 단계는, 상기 제1 경로에 대해 적어도 한 번의 컨볼루션 연산을 수행하는 단계; 및 상기 컨볼루션 연산 후의 상기 제1 경로를 공간-도메인(space domain) 융합을 위한 네트워크에 입력하고, 상기 공간-도메인 융합을 위한 네트워크를 통해 상관성 처리를 수행하는 단계를 포함할 수 있다. 이때, 상기 공간-도메인 융합을 위한 네트워크를 통해 상기 상관성 처리를 수행하는 단계는, 상기 공간-도메인 융합을 위한 네트워크에 입력된 특징을 적어도 2개의 경로로 나누고, 상기 적어도 2개의 경로 중 일부 또는 전 부에 대해 서브 도메인을 추출하는 단계; 서브 도메인 추출 결과에 대해 행렬 곱셈 연산을 수행하는 단계; 및 행렬 곱셈 연산 결과와 상기 공간-도메인 융합을 위한 네트워크에 입력된 특징에 대해 요소별 덧셈 연산을 수행하는 단계를 포함할 수 있다. 이때, 상기 공간-도메인 융합을 위한 네트워크를 통해 상기 상관성 처리를 수행하는 단계는, 컨볼루션 연산된 조합 특징을 4개의 경로로 나누는 단계; 상기 4개의 경로 중 제1 경로, 제2 경로 및 제3 경로에 대해 각각 서브 도메인 추출을 진행하는 단계; 상기 4개의 경로 중 상기 제1 경로의 서브 도메인 추출 결과와 상기 제2 경로의 서브 도메인 추출 결과에 대해 행렬 곱셈 연산을 수행하고, 행렬 곱셈 연산 결과와 상기 4개의 경로 중 상기 제 3 경로의 서브 도메인 추출 결과에 대해 행렬 곱셈 연산을 수행하는 단계; 및 상기 제3 경로의 서브 도메인 추 출 결과에 대해 행렬 곱셈 연산을 수행한 결과와 상기 4개의 경로 중 제4 경로에 대해 요소별 덧셈 연산을 수행 하는 단계를 포함할 수 있다. 이때, 상기 서브 도메인 추출을 진행하는 단계는, 데이터 재구성을 통해 상기 서브 도메인 추출을 진행하는 단 계를 포함할 수 있다. 이때, 상기 제1 이미지 특징 및 상기 제2 이미지 특징에 대해 조합 연산을 수행하는 단계는, 상기 제1 이미지 특징에 대해 적어도 한 번의 컨볼루션 연산을 수행하는 단계; 상기 제2 이미지 특징에 대해 적어도 한 번의 컨 볼루션 연산을 수행하는 단계; 및 컨볼루션 연산된 제1 이미지 특징 및 컨볼루션 연산된 제2 이미지 특징에 대 해 조합 연산을 수행하는 단계를 포함할 수 있다. 이때, 상기 요소별 덧셈 연산 결과에 따라 상기 시간-도메인 정보 융합 처리 결과를 획득하는 단계는, 상기 요 소별 덧셈 연산 결과를 2개의 경로로 나누는 단계; 상기 2개의 경로 중 각 경로의 요소별 덧셈 연산 결과에 대 해 적어도 한 번의 컨볼루션 연산을 수행하는 단계; 컨볼루션 연산된 상기 제1 경로의 요소별 덧셈 연산 결과와 상기 컨볼루션 연산된 제1 이미지 특징에 대해 요소별 덧셈 연산을 수행하여 제1 시간-도메인 통합 특징을 획득 하는 단계; 및 컨볼루션 연산된 상기 제2 경로의 요소별 덧셈 연산 결과와 상기 컨볼루션 연산된 제2 이미지 특 징에 대해 요소별 덧셈 연산을 수행하여 제2 시간-도메인 통합 특징을 획득하는 단계를 포함할 수 있다. 이때, 상기 요소별 덧셈 연산 결과에 따라 상기 시간-도메인 정보 융합 처리 결과를 획득하는 단계는, 상기 요 소별 덧셈 연산 결과에 대해 적어도 한 번의 컨볼루션 연산을 수행하고, 컨볼루션 연산된 요소별 덧셈 연산 결 과와 상기 제2 이미지 특징을 상기 시간-도메인 정보 융합 처리 결과로 취하는 단계를 포함할 수 있다. 이때, 상기 시간-도메인 정보 융합 처리 결과를 기반으로 상기 제1 이미지에 대해 인스턴스 추적을 수행하여, 상기 제1 이미지의 프레임 간의 인스턴스 대응을 획득하는 단계는, 제2 시간-도메인 통합 특징을 기반으로 상기 비디오 데이터의 인스턴스 데이터베이스(instance database)를 업데이트하는 단계; 및 업데이트된 인스턴스 데 이터베이스를 기반으로 제1 시간-도메인 통합 특징에 대해 각각 인스턴스 추적을 진행하는 단계를 포함할 수 있 다. 이때, 상기 제2 시간-도메인 통합 특징을 기반으로 상기 비디오 데이터의 상기 인스턴스 데이터베이스를 업데이 트하는 단계는, 상기 제2 시간-도메인 통합 특징에서 제1 개수의 기설정된 특징을 선택하는 단계; 및 선택한 상 기 제1 개수의 기설정된 특징을 상기 비디오 데이터의 상기 인스턴스 데이터베이스에 추가하는 단계를 포함할 수 있다. 이때, 업데이트된 상기 인스턴스 데이터베이스를 기반으로 상기 제1 시간-도메인 통합 특징에 대해 각각 인스턴 스 추적을 진행하는 단계는, 상기 제1 시간-도메인 통합 특징에서 제2 개수의 기설정된 특징을 선택하는 단계; 및 선택한 상기 제2 개수의 기설정된 특징과 업데이트된 상기 인스턴스 데이터베이스를 기반으로 추적 네트워크 를 통해 인스턴스 대응을 진행하는 단계를 포함할 수 있다. 이때, 상기 기설정된 특징은, 관심 영역 특징, 바운딩 박스에 기초하여 표현되는 특징 및 마스크에 기초하여 표 현되는 특징 중에서 적어도 하나를 포함할 수 있다. 본 개시의 일 실시 예에 따른 비디오 처리 장치는, 비디오 데이터의 제1 이미지의 제1 이미지 특징 및 제1 이미 지 앞의 제2 이미지의 제2 이미지 특징을 획득하도록 구성된 특징 획득부; 상기 제1 이미지 특징 및 상기 제2 이미지 특징에 대해 시간-도메인 정보 융합 처리를 진행하여, 시간-도메인 정보 융합 처리 결과를 획득하도록 구성된 시간-도메인 정보 융합부; 및 상기 시간-도메인 정보 융합 처리 결과에 따라 상기 제1 이미지의 파노라 마 분할 결과를 획득하도록 구성된 파노라마 분할부를 포함한다. 이때, 상기 파노라마 분할부는, 상기 시간-도메인 정보 융합 처리 결과를 기반으로 상기 제1 이미지에 대해 인 스턴스 추적을 수행하여, 상기 제1 이미지의 프레임 간의 인스턴스 대응을 획득하고, 상기 제1 이미지의 프레임 간의 인스턴스 대응에 따라, 상기 제1 이미지의 파노라마 분할 결과를 획득할 수 있다."}
{"patent_id": "10-2021-0130042", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하에서, 첨부된 도면을 참조하여 실시예들을 상세하게 설명한다. 그러나, 실시예들에는 다양한 변경이 가해 질 수 있어서 특허출원의 권리 범위가 이러한 실시예들에 의해 제한되거나 한정되는 것은 아니다. 실시예들에 대한 모든 변경, 균등물 내지 대체물이 권리 범위에 포함되는 것으로 이해되어야 한다. 실시예에서 사용한 용어는 단지 설명을 목적으로 사용된 것으로, 한정하려는 의도로 해석되어서는 안된다. 단 수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 명세서에서, \"포함하다\" 또 는 \"가지다\" 등의 용어는 명세서 상에 기재된 특징, 숫자, 단계, 동작, 구성요소, 부품 또는 이들을 조합한 것 이 존재함을 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성요소, 부품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되어야 한다. 다르게 정의되지 않는 한, 기술적이거나 과학적인 용어를 포함해서 여기서 사용되는 모든 용어들은 실시예가 속 하는 기술 분야에서 통상의 지식을 가진 자에 의해 일반적으로 이해되는 것과 동일한 의미를 가지고 있다. 일 반적으로 사용되는 사전에 정의되어 있는 것과 같은 용어들은 관련 기술의 문맥 상 가지는 의미와 일치하는 의 미를 가지는 것으로 해석되어야 하며, 본 출원에서 명백하게 정의하지 않는 한, 이상적이거나 과도하게 형식적 인 의미로 해석되지 않는다. 또한, 첨부 도면을 참조하여 설명함에 있어, 도면 부호에 관계없이 동일한 구성 요소는 동일한 참조부호를 부여 하고 이에 대한 중복되는 설명은 생략하기로 한다. 실시예를 설명함에 있어서 관련된 공지 기술에 대한 구체적 인 설명이 실시예의 요지를 불필요하게 흐릴 수 있다고 판단되는 경우 그 상세한 설명을 생략한다. 또한, 실시 예의 구성 요소를 설명하는 데 있어서, 제1, 제2, A, B, (a), (b) 등의 용어를 사용할 수 있다. 이 러한 용어는 그 구성 요소를 다른 구성 요소와 구별하기 위한 것일 뿐, 그 용어에 의해 해당 구성 요소의 본질 이나 차례 또는 순서 등이 한정되지 않는다. 어떤 구성 요소가 다른 구성요소에 \"연결\", \"결합\" 또는 \"접속\"된 다고 기재된 경우, 그 구성 요소는 그 다른 구성요소에 직접적으로 연결되거나 접속될 수 있지만, 각 구성 요소 사이에 또 다른 구성 요소가 \"연결\", \"결합\" 또는 \"접속\"될 수도 있다고 이해되어야 할 것이다. 어느 하나의 실시 예에 포함된 구성요소와, 공통적인 기능을 포함하는 구성요소는, 다른 실시 예에서 동일한 명 칭을 사용하여 설명하기로 한다. 반대되는 기재가 없는 이상, 어느 하나의 실시 예에 기재한 설명은 다른 실시 예에도 적용될 수 있으며, 중복되는 범위에서 구체적인 설명은 생략하기로 한다. 도 1은 일 실시예에 따른 비디오 처리 알고리즘의 예시적 네트워크 구조를 도시한 도면이다. 도 1을 참조하면, 비디오 처리 알고리즘의 예시적 네트워크 구조는 특징 추출 네트워크, 특징 추출 네트워 크, 시간-도메인 통합 모듈(TUM), 바운딩 박스 제안 네트워크(RPN), 시맨틱 분할 모듈, 바운딩 박스 모듈, 마스크 모듈 및 추적 모듈을 포함한다.특징 추출 네트워크와 특징 추출 네트워크에서 각각 추출한 t번째 프레임의 특징맵과 t-τ번째 프레 임의 특징맵은 시간-도메인 통합 모듈에 입력된다. 시간-도메인 통합 모듈은 t번째 프레임 시간-도메 인 통합 특징맵 및 t-τ번째 프레임 시간-도메인 통합 특징맵(즉, 매칭에 적합한 특징)을 출력한다. 비디오 처리 알고리즘은 t-τ번째 프레임의 시간-도메인 통합 특징맵에서 추출한 m개의 마스킹된 특징을 인스턴 스 데이터베이스에 추가하고, t번째 프레임의 시간-도메인 통합 특징맵에서 추출한 n개의 마스킹된 특징과 인스 턴스 데이터베이스를 함께 추적 모듈에 입력하여 프레임 간의 인스턴스 대응을 구축한다. 여기서, 마스킹된 특 징은 마스크를 기반으로 표시한 특징이다. t번째 프레임 시간-도메인 통합 특징맵은 또한 시맨틱 분할 모듈, 바운딩 박스 모듈 및 마스크 모듈 에 입력된다. 그리고, 시맨틱 분할 모듈, 바운딩 박스 모듈, 마스크 모듈 및 추적 모듈의 출력 결과는 t 번째 프레임 파노라마 레이블맵으로 조합된다. 보다 구체적으로 설명하면, 특징 추출 네트워크는 t번째 프레임의 경우, 일반적인 특징 추출 네트워크를 사용하여 다중 해상도의 이미지 특징(피라미드로 다양한 해상도를 표시함)을 추출하고, 추출된 이미지 특징을 융합하여 t번째 프레임 특징맵을 획득한다. 특징 추출 네트워크는 t-τ번째 프레임의 경우, 특징 추출 네트워크와 동일한 특징 추출 네트워크를 사용하여 다중 해상도의 이미지 특징을 추출하고, 추출된 이미지 특징을 융합하여 t-τ번째 프레임 특징맵을 획 득한다. 시간-도메인 통합 모듈은 t번째 프레임 특징과 t-τ번째 프레임 특징을 수신하고 이를 이용해서 t번째 프 레임 시간-도메인 통합 특징맵(즉, 매칭에 적합한 특징) 및 t-τ번째 프레임 시간-도메인 통합 특징맵을 획득한 다. 바운딩 박스 제안 네트워크는 t번째 프레임 시간-도메인 특징맵에서, 바운딩 박스 제안 네트워크(RPN)를 호출하여 후보 바운딩 박스(즉, 시간-도메인 통합 특징맵 상의 박스들)를 획득한다. 시맨틱 분할 모듈은 시간-도메인 통합 모듈에서 얻은 t번째 프레임 시간-도메인 통합 특징맵에 대해 시맨틱 분할을 진행하여, 모든 픽셀의 시맨틱 레이블을 획득한다. 바운딩 박스 모듈은 시간-도메인 통합 모듈에서 얻은 t번째 프레임 시간-도메인 통합 특징맵에 바운 딩 박스 제안 네트워크에서 얻은 후보 바운딩 박스를 세분화하여, 그 종류 및 정확한 바운딩 박스 위치를 확인한다. 마스크 모듈은 시간-도메인 통합 모듈에서 얻은 t번째 프레임 시간-도메인 통합 특징맵에서 바운딩 박스 제안 네트워크에서 얻은 후보 바운딩 박스에 대한 마스크를 계산한다(즉, 바운딩 박스 내의 각 픽셀 에 대해 이것이 전경 또는 배경에 속하는지 확인). 추적 모듈은 시간-도메인 통합 모듈에서 얻은 t번째 프레임 시간-도메인 통합 특징맵에서 추출된 n개 의 마스크된 특징을 수신하고, t-τ번째 프레임 시간-도메인 통합 특징맵에서 추출된 m개의 마스크된 특징(훈련 시 미리 수동으로 표시된 올바른 마스크)이 추가된 인스턴스 데이터베이스를 이용하여 프레임 간의 인스턴스 대 응을 구축한다(즉, 이전 프레임에 나타난 인스턴스를 식별함). 마지막으로, 비디오 처리 알고리즘은 4개의 모듈(시맨틱 분할 모듈, 바운딩 박스 모듈, 마스크 모듈 및 추적 모듈)에서 계산된 모든 정보를 조합하여, 파노라마 레이블맵을 획득할 수 있다. 도 2는 일 실시예에 따른 비디오 처리 과정을 도시한 흐름도이다. 도 2를 참조하면, 비디오 처리 장치는 비디오 데이터의 제1 이미지의 제1 이미지 특징 및 제1 이미지 앞의 제2 이미지의 제2 이미지 특징을 획득한다. 구체적으로, 비디오 처리 장치는 비디오를 여러 개의 프레임 이미지로 나눌 수 있고, 이후 모든 이미지 파노라 마 분할 방법을 사용하여 비디오 데이터의 첫 번째 프레임 이미지에 대해 이미지 파노라마 분할을 진행하여, 첫 번째 프레임 이미지의 파노라마 분할 결과를 얻을 수 있다. 비디오 데이터의 첫 번째 프레임 이미지 이후의 각 프레임 이미지를 순차적으로 제1 이미지로 취하고, 본 개시의 비디오 처리 방법을 수행하여, 첫 번째 프레임 이미지 이후의 각 프레임 이미지의 파노라마 분할 결과를 획득할 수 있다. 첫 번째 프레임 이미지의 파노라마 분할 결과를 획득한 후, 이전 각 프레임 이미지의 파노라마 분할 결과를 기 반으로, 후속의 각 프레임 이미지에 대해 이미지 파노라마 분할을 진행할 수 있다. 일 실시예에서, 210단계에서 비디오 처리 장치는 비디오 데이터에서 제1 이미지의 제1 이미지 특징 및 제1 이미 지 앞의 제2 이미지의 제2 이미지 특징을 획득할 때, 특징 추출 네트워크를 통해 제1 이미지(예, t번째 프레임 이미지) 및 제2 이미지(예, t-τ번째 프레임 이미지)에 대해 각각 특징 추출을 수행하여, 제1 이미지의 제1 이 미지 특징 및 제2 이미지의 제2 이미지 특징을 획득할 수 있다. 여기서, 제1 이미지 특징 및 제2 이미지 특징 은 다중 해상도의 이미지 특징일 수 있으며, 구체적으로, 피라미드를 사용하여 여러 상이한 해상도를 나타낼 수 있다. 비디오 처리 장치는 제1 이미지 특징 및 제2 이미지 특징에 대해 시간-도메인 정보 융합 처리를 진행하여, 시간 -도메인 정보 융합 처리 결과를 획득한다. 이때, 시간-도메인 정보 융합 처리 결과는 제1 이미지의 제1 시간-도메인 통합 특징 및 제2 이미지의 시간-도메 인 통합 특징을 포함할 수 있다. 다시 말해, 제1 이미지 특징 및 제2 이미지 특징에 대해 시간-도메인 정보 융 합 처리를 진행하여, 제1 이미지의 제1 시간-도메인 통합 특징 및 제2 이미지의 제2 시간-도메인 통합 특징을 획득할 수 있다. 220단계에서 비디오 처리 장치는 제1 이미지 특징 및 제2 이미지 특징에 대해 시간-도메인 정보 융합 처리 시, 먼저 제1 이미지 특징 및 제2 이미지 특징에 대해 조합 연산을 수행하고, 조합된 이미지 특징을 2개의 경로로 분할하고, 제1 경로에 대해 상관성 처리를 수행하고, 제1 경로의 상관성 처리 결과와 제2 경로에 대해 요소별로 덧셈 연산을 진행한 후, 요소별 덧셈 연산 결과에 따라 시간-도메인 정보 융합 처리 결과를 획득할 수 있다. 여 기서, 비디오 처리 장치는 제1 경로에 대해 상관성 처리 시, 먼저 제1 경로에 대해 적어도 한 번의 컨볼루션 연 산을 수행한 후, 컨볼루션 연산 후의 제1 경로를 공간-도메인 융합을 위한 네트워크에 입력하고, 공간-도메인 융합을 위한 네트워크를 통해 상관성 처리를 수행할 수 있다. 220단계에서 비디오 처리 장치는 제1 이미지 특징 및 제2 이미지 특징에 대해 조합 연산 수행 시, 먼저 제1 이 미지 특징에 대해 적어도 한 번의 컨볼루션 연산을 수행하고, 제2 이미지 특징에 대해 적어도 한 번의 컨볼루션 연산을 수행한 후, 컨볼루션 연산된 제1 이미지 특징 및 컨볼루션 연산된 제2 이미지 특징에 대해 조합 연산을 수행할 수 있다. 220단계에서 비디오 처리 장치는 요소별 덧셈 연산 결과에 따라 시간-도메인 정보 융합 처리 결과 획득 시, 먼 저 요소별 덧셈 연산 결과를 2개의 경로로 나누고, 2개의 경로 중 각 경로의 요소별 덧셈 연산 결과에 대해 적 어도 한 번의 컨볼루션 연산을 수행한 다음, 컨볼루션 연산된 제1 경로의 요소별 덧셈 연산 결과와 컨볼루션 연 산된 제1 이미지 특징에 대해 요소별 덧셈 연산을 수행하여 제1 시간-도메인 통합 특징을 획득하고, 컨볼루션 연산된 제2 경로의 요소별 덧셈 연산 결과와 컨볼루션 연산된 제2 이미지 특징에 대해 요소별 덧셈 연산을 수행 하여 제2 시간-도메인 통합 특징을 획득할 수 있다. 220단계에서 비디오 처리 장치는 공간-도메인 융합을 위한 네트워크를 통해 상관성 처리 시, 먼저 공간-도메인 융합을 위한 네트워크에 입력된 특징을 적어도 2개의 경로로 나누고, 적어도 2개의 경로 중 일부 또는 전부에 대해 서브 도메인을 추출하고, 서브 도메인 추출 결과에 대해 행렬 곱셈 연산을 수행한 후, 행렬 곱셈 연산 결 과와 공간-도메인 융합을 위한 네트워크에 입력된 특징에 대해 요소별 덧셈 연산을 수행할 수 있다. 220단계에서 비디오 처리 장치는 공간-도메인 융합을 위한 네트워크를 통해 상관성 처리 시, 먼저 컨볼루션 연 산된 조합 특징을 4개의 경로로 나누고, 4개의 경로 중 제1 경로, 제2 경로 및 제3 경로에 대해 각각 서브 도메 인 추출을 진행하고, 4개의 경로 중 제1 경로의 서브 도메인 추출 결과와 제2 경로의 서브 도메인 추출 결과에 대해 행렬 곱셈 연산을 수행하고, 행렬 곱셈 연산 결과와 4개의 경로 중 제3 경로의 서브 도메인 추출 결과에 대해 행렬 곱셈 연산을 수행한 후, 제3 경로의 서브 도메인 추출 결과에 대해 행렬 곱셈 연산을 수행한 결과와 4개의 경로 중 제4 경로에 대해 요소별 덧셈 연산을 수행할 수 있다. 이때, 비디오 처리 장치는 데이터 재구성 을 통해 서브 도메인 추출을 진행할 수 있다. 220단계에서 비디오 처리 장치는 요소별 덧셈 연산 결과에 따라 시간-도메인 정보 융합 처리 결과 획득 시, 먼 저 요소별 덧셈 연산 결과에 대해 적어도 한 번의 컨볼루션 연산을 수행한 다음, 컨볼루션 연산된 요소별 덧셈 연산 결과와 제2 이미지 특징을 시간-도메인 정보 융합 처리 결과로 취할 수 있다.한편, 220단계에서 시간-도메인 통합 네트워크를 통해 제1 이미지 특징 및 제2 이미지 특징에 대해 시간-도메인 정보 융합 처리를 진행하는 것에 대한 보다 구체적인 설명은 이후 도 3 - 도 6을 참조하여 후술한다. 그리고, 비디오 처리 장치는 시간-도메인 정보 융합 처리 결과에 따라 제1 이미지의 파노라마 분할 결과를 획득 한다. 230단계에서 비디오 처리 장치는 시간-도메인 정보 융합 처리 결과에 기초하여 제1 이미지에 대해 먼저 인스턴 스 추적을 실행하여, 제1 이미지의 프레임 간의 인스턴스 대응을 획득할 수 있고, 그런 다음 프레임 간의 인스 턴스 대응에 따라 제1 이미지의 파노라마 분할 결과를 얻을 수 있다. 230단계에서 비디오 처리 장치는 시간-도메인 정보 융합 처리 결과에 기초하여 제1 이미지에 대해 시맨틱 분할, 인스턴스 분할, 바운딩 박스를 세분화하여, 제1 이미지의 시맨틱 분할 결과, 인스턴스 분할 결과, 바운딩 박스 를 획득할 수 있다. 이때, 비디오 처리 장치는 프레임 간의 인스턴스 대응에 따라 제1 이미지의 파노라마 분할 결과를 획득할 때, 제1 이미지의 시맨틱 분할 결과, 인스턴스 분할 결과, 바운딩 박스, 프레임 간의 인스턴스 대응을 융합하여, 제1 이미지의 파노라마 분할 결과를 획득할 수 있다. 230단계에서 비디오 처리 장치는 시간-도메인 정보 융합 처리 결과에 기초하여 제1 이미지에 대해 인스턴스 추 적을 수행할 때, 먼저 제2 시간-도메인 통합 특징에 기반하여 비디오 데이터의 인스턴스 데이터베이스를 업데이 트하고, 업데이트된 인스턴스 데이터베이스에 기반하여 제1 시간-도메인 통합 특징에 대해 각각 인스턴스 추적 을 진행할 수 있다. 230단계에서 비디오 처리 장치는 제2 시간-도메인 통합 특징에 기반하여 비디오 데이터의 인스턴스 데이터베이 스를 업데이트할 때, 먼저 제2 시간-도메인 통합 특징으로부터 제1 개수(예, m)의 기설정된 특징을 선택한 다음, 선택한 제1 개수(예, m)의 기설정된 특징을 비디오 데이터의 인스턴스 데이터베이스에 추가할 수 있다. 230단계에서 비디오 처리 장치는 업데이트된 인스턴스 데이터베이스를 기반으로 제1 시간-도메인 통합 특징에 대해 각각 인스턴스 추적하는 경우, 먼저 제1 시간-도메인 통합 특징에서 제2 개수(예, n)의 기설정된 특징을 선택한 다음, 추적 네트워크를 통해, 선택된 제2 개수(예, n)의 기설정된 특징과 업데이트된 인스턴스 데이터베 이스를 기반으로, 인스턴스 대응을 진행할 수 있다. 일 실시예에서, 인스턴스 데이터베이스는 비디오의 첫 번째 프레임부터 현재 프레임의 이전 프레임까지 모든 인 스턴스를 기록할 수 있다. 인스턴스 데이터베이스의 크기는 인스턴스의 개수이며, 사전의 방식으로 저장된다. 키워드는 인스턴스 id이고, 값은 대응되는 인스턴스 특징이다. 인스턴스 데이터베이스의 초기화 상태는 모두 0 인 텐서일 수 있다. 첫 번째 프레임 이미지부터 t-1번째 프레임 이미지까지 읽기 및 쓰기 작업이 필요하며, 추출된 인스턴스의 id에 대응하는 값이 초기화 상태일 경우, 그 값은 현재의 특징으로 대체하고. 추출된 인스턴스의 id에 대응하는 값이 초기화 상태가 아닌 경우, 매개변수 alpha(예를 들어, 0.5(제한되지 않음))를 사용하여 원래 특징과 현재 특징 을 융합한다(즉, feat_memory_new = alpha*feat_memory_org + (1-alpha)*feat_current). t번째 프레임 이미지 는 읽기만 수행하고, 인스턴스 데이터베이스에 있는 모든 인스턴스의 특징을 읽어, t번째 프레임 이미지에서 검 출된 모든 인스턴스의 특징과 함께 유사도를 계산한다(모든 유사도 알고리즘 선택 가능, 예를 들어, 두 개의 특 징의 벡터 내적을 유사도로 취하는 것에 국한되지 않음). t 번째 프레임 이미지의 모든 인스턴스에 대해, 예측 된 id는 즉 가장 유사한 인스턴스 데이터베이스의 인스턴스의 id이다. 이러한 방식을 통해, 네트워크는 훈련 과 정에서 충분히 큰 인스턴스 데이터베이스를 갖게 된다. 일 실시예에서, 기설정된 특징은 관심 영역 특징, 바운딩 박스에 기초하여 표현되는 특징(roi 특징), 또는 마스 크에 기초하여 표현되는 특징(마스크된 특징)일 수 있다. roi 특징은 인스턴스를 직사각형 영역(일반적으로 bounding box, 즉 '바운딩 박스'라고 함)으로 나타내며, 해당 직사각형 영역의 특징맵 상의 모든 정보는 해당 인스턴스의 정보로 간주된다. 일반적으로 인스턴스의 모양이 직 사각형이 아니기 때문에, 인스턴스 특징에는 배경 영역 정보의 일부 또한 포함되므로 정확하지 않다. 마스킹된 특징은 인스턴스의 마스크를 사용하고, 마스크 영역의 정보만 인스턴스 정보로 사용하며, 배경 영역의 영향을 제거한다. 여기서 특징은 roi 특징 또는 마스크된 특징일 수 있다. roi 특징은 바운딩 박스(직사각형 모양)에 의해 추출 되기 때문에, 약간의 배경 노이즈가 발생하여 인스턴스 특징의 식별도가 낮아지게 된다. 마스크된 특징을 선택 하면 인스턴스 특징의 식별도를 높일 수 있으므로, 인스턴스 id 예측의 정확도를 높이기 위해 마스킹된 특징을선호하게 된다. 도 3은 일 실시예에 따른 시간-도메인 통합 네트워크의 예시적 구조 및 그 사용 흐름을 도시한 도면이다. 도 3을 참조하면, 시간-도메인 통합 네트워크(모듈)는 수집 부분, 공간 융합을 위한 네트워크(예, 부분 비로컬 적(nonlocal) 어텐션 네트워크) 및 분배 부분을 포함한다. 수집 부분은 두 프레임의 특징을 함께 조합하고(ⓒ는 조합을 나타냄), 분배 부분은 어텐션 네트워크를 통과하는 조합된 정보를 두 프레임의 정보로 나눈다. 공간 융 합을 위한 네트워크(예, 부분 비로컬적 어텐션 네트워크)는 수집 부분과 분배 부분 사이에 위치하며, 본 개시에 서 제안하는 새로운 어텐션 네트워크로서, 종래의 광류(Optical flow) 해결 및 종래의 정렬 작업을 수행하지 않 는 상황에서 두 프레임의 정보를 융합할 수 있다. 도 3에서 시간-도메인 통합 네트워크의 입력은 제1 이미지 특징(t번째 프레임 특징맵)과 제2 이미지 특징(t-τ 번째 프레임 특징맵)이고 (두 프레임 이미지의 특징맵 모두 N*C*H*W의 텐서(tensor)로 표시된다. 이때, N은 동 일한 배치에 속하는 이미지 데이터의 수(즉, batch size)이고, C는 채널 수이고, H 및 W는 특징맵의 높이와 너 비이다. 시간-도메인 통합 네트워크의 출력은 두 프레임 간의 시간-도메인 통합 특징이다. 도 3의 시간-도메인 통합 네 트워크(모듈)에서 시간-도메인 정보 융합 처리하는 구체적인 과정은 311단계에서 322단계를 포함할 수 있다. 시간-도메인 통합 네트워크는 t번째 프레임 특징맵에 대해 컨볼루션 연산(1*1 컨볼루션)을 진행하여, 특징맵 (A)를 획득한다. 그리고, 시간-도메인 통합 네트워크는 t-τ번째 프레임 특징맵에 대해 컨볼루션 연산(1*1 컨볼루션)을 진행하여, 특징맵(A')를 획득한다. 그리고, 시간-도메인 통합 네트워크는 A와 A'를 조합하여 특징맵(E)를 획득한다. 이때, 특징맵(E)의 크기 는 N*2C*H*W이다. 그리고, 시간-도메인 통합 네트워크는 획득한 특징맵(E)에 대해 컨볼루션 연산(예를 들어, 1*1 컨볼루션)을 진 행한다. 그리고, 시간-도메인 통합 네트워크는 계속해서 컨볼루션 연산(예를 들어, 3*3 컨볼루션)을 진행한다. 그리고, 시간-도메인 통합 네트워크는 계속해서 컨볼루션 연산(예, 1*1 컨볼루션)을 진행하여, 특징맵(X)를 획 득한다. 여기서, 314단계에서 316단계의 컨볼루션 연산은 다른 매개변수의 컨볼루션 연산일 수 있다. 그리고, 시간-도메인 통합 네트워크는 특징맵 X를 공간 융합을 위한 네트워크(예를 들어, 부분 비로컬적 어텐션 네트워크)에 입력한다. 그리고, 시간-도메인 통합 네트워크는 317단계에서 출력된 특징맵과 특징맵E를 요소별로 덧셈 연산을 진행한다 . 그리고, 시간-도메인 통합 네트워크는 318단계에서 출력된 결과에 대해 컨볼루션 연산(예를 들어, 1*1 컨볼루션)을 수행한다. 그리고, 시간-도메인 통합 네트워크는 318단계에서 출력된 결과에 대해 컨볼루션 연산(예를 들어, 1*1 컨볼루션)을 수행한다. 여기서 319단계 및 320단계의 컨볼루션 연산은 다른 매개변수의 컨볼루션 연산일 수 있다. 그리고, 시간-도메인 통합 네트워크는 319에서 출력된 결과와 특징맵A를 요소별로 덧셈 연산을 진행하여, t번째 프레임의 시간-도메인 통합 특징맵을 획득한다. 그리고, 시간-도메인 통합 네트워크는 320단계에서 출력된 결과와 특징맵A'를 요소별로 덧셈 연산을 진행하여, t-τ번째 프레임의 시간-도메인 통합 특징맵을 획득한다. 도 3은 시간-도메인 통합 네트워크의 예시적 구조 및 예시적 흐름만을 도시하고 있으며, 시간-도메인 통합 네트 워크는 또한 기능을 구현할 수 있는 다른 구조를 가질 수 있고 및/또는 다른 상이한 흐름을 가질 수 있다. 본개시는 도 3의 시간-도메인 통합 네트워크로 제한되지 않는다. 도 4는 다른 일 실시예에 따른 시간-도메인 통합 네트워크의 예시적 구조 및 그 사용 흐름을 도시한 도면이다. 도 4를 참조하면, 시간-도메인 통합 네트워크(모듈)은 공간 융합을 위한 네트워크(예를 들어, 부분 비로컬적 어 텐션 네트워크)를 포함하며, 종래의 광류 해결 및 종래의 정렬 작업을 수행하지 않는 상황에서 두 프레임의 정 보를 융합할 수 있다. 도 4에서 시간-도메인 통합 네트워크(모듈)의 입력은 제1 이미지 특징과 제2 이미지 특징이고(두 프레임 이미지 의 특징맵 모두 N*C*H*W의 텐서로 표시된다. 이때, N은 동일한 배치에 속하는 이미지 데이터의 수(즉, batch size)이고, C는 채널 수이고, H 및 W는 특징맵의 높이와 너비임)이다. 시간-도메인 통합 네트워크의 출력은 두 프레임 간의 시간-도메인 통합 특징이다. 도 4의 시간-도메인 통합 네트워크(모듈)에서 시간-도메인 정보 융합 처리하는 구체적인 과정은 411단계에서 417단계를 포함할 수 있다. 시간-도메인 통합 네트워크는 t번째 프레임 특징맵 및 t-τ번째 프레임 특징맵을 조합하여, N, 2C, H, W차원의 특징맵을 획득한다. 그리고, 시간-도메인 통합 네트워크는 411단계에서 출력된 결과에 대해 컨볼루션 연산(예를 들어, 1*1 컨볼루션)을 진행한다. 그리고, 시간-도메인 통합 네트워크는 계속해서 컨볼루션 연산(예를 들어, 3*3 컨볼루션)을 진행한다. 그리고, 시간-도메인 통합 네트워크는 계속해서 컨볼루션 연산(예를 들어, 1*1 컨볼루션)을 진행하여, 특징맵 (X)를 획득한다. 여기서 412단계에서 414단계의 컨볼루션 연산은 다른 매개변수의 컨볼루션 연산일 수 있다. 그리고, 시간-도메인 통합 네트워크는 특징맵 X를 공간 융합을 위한 네트워크(예를 들어, 부분 비로컬적 어텐션 네트워크)에 입력한다. 그리고, 시간-도메인 통합 네트워크는 415단계에서 출력된 결과와 단계(5-1)에서 출력된 결과를 요소별로 덧셈 연산을 진행한다. 그리고, 시간-도메인 통합 네트워크는 416단계에서 출력된 결과에 대해 컨볼루션 연산(예를 들어, 1*1 컨볼루션)을 수행하여, t번째 프레임의 시간-도메인 통합 특징맵을 획득한다. 이때, 417단계에서의 컨볼루 션 연산은 다른 매개변수의 컨볼루션 연산일 수 있다. 도 4는 시간-도메인 통합 네트워크의 예시적 구조 및 예시적 흐름만을 도시하고 있으며, 시간-도메인 통합 네트 워크는 또한 기능을 구현할 수 있는 다른 구조를 가질 수 있고 및/또는 다른 상이한 흐름을 가질 수 있다. 본 개시는 도 4의 시간-도메인 통합 네트워크로 제한되지 않는다. 본 개시의 일 실시예에서, 시간-도메인 통합 네트워크로 인해서 종래에 계산하던 프레임 간의 광류를 더는 계산 할 필요가 없으므로, 계산 속도가 크게 향상되고, 해당 네트워크의 데이터 양 훈련에 대한 수요 또한 크게 줄어 든다. 또한, 시간-도메인 통합 네트워크에서 두 프레임의 특징이 동일한 어텐션 네트워크를 통과하여 시맨틱 상의 일관성 또한 향상된다. 도 5는 일 실시예에 따른 시간-도메인 통합 네트워크에서 공간 융합을 위한 네트워크의 예시적 구조를 도시한 도면이다. 도 6은 일 실시예에 따른 시간-도메인 통합 네트워크에서 공간 융합을 위한 네트워크의 예시적 구조 및 사용 흐 름을 도시한 도면이다. 도 5를 참조하면, 공간 융합을 위한 네트워크(예를 들어, 부분 비로컬적 어텐션 네트워크)는 특징맵 수신부 , 컨볼루션 연산부(511, 521, 541, 651), 서브 도메인 추출부(512, 522, 542), 행렬 곱셈부(530, 550) 소 프트맥스 연산부, 요소별 덧셈부를 포함하여 구성될 수 있다.도 5에 도시된 바와 같이, 공간 융합을 위한 네트워크(예를 들어, 부분 비로컬적 어텐션 네트워크)는 서브 도메 인 추출 및 행렬 곱셈을 통해 프레임 간의 관련 정보를 학습하므로, 종래 기술의 광류를 사용한 정렬 작업을 제 거할 수 있다. 도 5의 C/4 및 C/2는 예시의 채널 수로, 본 개시에서 채널의 수는 이에 한정되지 않는다. 공간 융합을 위한 네트워크(예를 들어, 부분 비로컬적 어텐션 네트워크)의 입력은 특징맵(예를 들어, 도 3의 316단계 의 출력 또는 도 4의 414단계의 출력인 특징맵X)이고, 크기는 N*2C*H*W(아래에서는 다른 쓰기 방법이 사용됨, N, 2C, H, W)이다. 이때, 서브 도메인 추출부는 데이터 재구성 연산을 통해 서브 도메인의 추출을 수행할 수 있다. 데이터 재구성 연산을 통해 서브 도메인 추출을 수행하는 경우, 도 6에 도시된 바와 같이, 공간 융합을 위한 네트워크(예를 들어, 부분 비로컬적 어텐션 네트워크)가 프레임 간의 관련 정보를 학습하는 구체적인 과정 은 아래의 610단계에서 652단계를 포함할 수 있다. 공간 융합을 위한 네트워크는 도 3의 316단계 또는 도 4의 414단계로부터 특징맵 X를 수신하고, 특징맵 X 에 대해 컨볼루션 연산(예를 들어, 1*1 컨볼루션)을 수행한다. 그리고, 공간 융합을 위한 네트워크는 611단계에서 얻은 특징맵에 대해 데이터 재구성(reshape)을 진행하여, 크 기가 N, C/4, H/k, W/k, k*k인 특징맵을 획득한다. 이때, C/4는 예시의 채널 수로, 본 개시에서 채널의 수 는 이에 한정되지 않는다. 여기서, k는 특정 픽셀과 관련된 이웃(neighborhood)의 크기를 나타내며, 예를 들어, 16으로 설정할 수 있으며, 이 경우, 각 픽셀의 관련 이웃의 크기는 16Х16이다. 그리고, 공간 융합을 위한 네트워크는 612단계에서 얻은 특징맵에 대해 데이터 재구성(reshape)을 진행하여, 크 기가 N*(H/k)*(W/k), k*k, C/4인 특징맵을 획득한다. 이때, C/4는 예시의 채널 수로, 본 개시에서 채널 의 수는 이에 한정되지 않는다. 그리고, 공간 융합을 위한 네트워크는 특징맵 X에 대해 컨볼루션 연산(예를 들어, 1*1 컨볼루션)을 수행한다 . 그리고, 공간 융합을 위한 네트워크는 621단계에서 얻은 특징맵에 대해 데이터 재구성(reshape)을 진행하여, 크 기가 N, C/4, H/k, W/k, k*k인 특징맵을 획득한다. 이때, C/4는 예시의 채널 수로, 본 개시에서 채널의 수는 이에 한정되지 않는다. 그리고, 공간 융합을 위한 네트워크는 622단계에서 얻은 특징맵에 대해 데이터 재구성(reshape)을 진행하여, 크 기가 N*(H/k)*(W/k), C/4, k*k인 특징맵을 획득한다. 이때, C/4는 예시의 채널 수로, 본 개시에서 채널의 수는 이에 한정되지 않는다. 그리고, 공간 융합을 위한 네트워크는 특징맵 X에 대해 컨볼루션 연산(예를 들어, 1*1 컨볼루션)을 수행한다 . 그리고, 공간 융합을 위한 네트워크는 641단계에서 얻은 특징맵에 대해 데이터 재구성(reshape)을 진행하여, 크 기가 N, C/2, H/k, W/k, k*k인 특징맵을 획득한다. 이때, C/2는 예시의 채널 수로, 본 개시에서 채널의 수 는 이에 한정되지 않는다. 그리고, 공간 융합을 위한 네트워크는 642단계에서 얻은 특징맵에 대해 데이터 재구성(reshape)을 진행하여, 크 기가 N*(H/k)*(W/k), k*k, C/2인 특징맵을 획득한다. 이때, C/2는 예시의 채널 수로, 본 개시에서 채널의 수는 이에 한정되지 않는다. 그리고, 공간 융합을 위한 네트워크는 613단계 및 623단계에서 얻은 특징맵에 대해 행렬 곱셈 연산을 진행하여, 크기가 N*(H/k)*(W/k), k*k, k*k 인 특징맵을 획득한다. 그리고, 공간 융합을 위한 네트워크는 63단계에서 얻은 특징맵에 대해 소프트맥스(Softmax) 연산을 수행한다 . 그리고, 공간 융합을 위한 네트워크는 631단계 및 643단계에서 얻은 특징맵에 대해 행렬 곱셈 연산을 진행하여, 크기가 N*(H/k)*(W/k), k*k, C/2인 특징맵을 획득한다. 이때, C/2는 예시의 채널 수로, 본 개시에서 채널 의 수는 이에 한정되지 않는다. 그리고, 공간 융합을 위한 네트워크는 계속해서 컨볼루션 연산(예를 들어, 1*1 컨볼루션)을 진행하여, 크기가 N, 2C, H, W로 복원된 특징맵을 획득한다. 그리고, 공간 융합을 위한 네트워크는 651단계에서 출력된 특징맵과 특징맵X를 요소별로 덧셈 연산을 진행한다 . 도 5 및 도 6은 시간-도메인 통합 모듈에서 공간 융합을 위한 네트워크(예를 들어, 부분 비로컬적 어텐션 네트 워크)의 예시적 구조 및 예시적 흐름만을 도시하고 있으며, 시간-도메인 통합 모듈에서 공간 융합을 위한 네트 워크(예를 들어, 부분 비로컬적 어텐션 네트워크)는 또한 기능을 구현할 수 있는 다른 구조를 가질 수 있고 및/ 또는 다른 상이한 흐름을 가질 수 있음을 이해해야 한다. 본 개시는 도 5 및 도 6의 공간 융합을 위한 네트워크 로 제한되지 않는다. 실시예에 따른 방법은 다양한 컴퓨터 수단을 통하여 수행될 수 있는 프로그램 명령 형태로 구현되어 컴퓨터 판 독 가능 매체에 기록될 수 있다. 상기 컴퓨터 판독 가능 매체는 프로그램 명령, 데이터 파일, 데이터 구조 등 을 단독으로 또는 조합하여 저장할 수 있다. 상기 매체에 기록되는 프로그램 명령은 실시예를 위하여 특별히 설계되고 구성된 것들이거나 컴퓨터 소프트웨어 당업자에게 공지되어 사용 가능한 것일 수도 있다. 컴퓨터 판 독 가능 기록 매체의 예에는 하드 디스크, 플로피 디스크 및 자기 테이프와 같은 자기 매체(magnetic media), CD-ROM, DVD와 같은 광기록 매체(optical media), 플롭티컬 디스크(floptical disk)와 같은 자기-광 매체 (magneto-optical media), 및 롬(ROM), 램(RAM), 플래시 메모리 등과 같은 프로그램 명령을 저장하고 수행하도 록 특별히 구성된 하드웨어 장치가 포함된다. 프로그램 명령의 예에는 컴파일러에 의해 만들어지는 것과 같은 기계어 코드뿐만 아니라 인터프리터 등을 사용해서 컴퓨터에 의해서 실행될 수 있는 고급 언어 코드를 포함한다. 상기된 하드웨어 장치는 실시예의 동작을 수행하기 위해 하나 이상의 소프트웨어 모듈로서 작동하도 록 구성될 수 있으며, 그 역도 마찬가지이다. 소프트웨어는 컴퓨터 프로그램(computer program), 코드(code), 명령(instruction), 또는 이들 중 하나 이상의 조합을 포함할 수 있으며, 원하는 대로 동작하도록 처리 장치를 구성하거나 독립적으로 또는 결합적으로 (collectively) 처리 장치를 명령할 수 있다. 소프트웨어 및/또는 데이터는, 처리 장치에 의하여 해석되거나 처리 장치에 명령 또는 데이터를 제공하기 위하여, 어떤 유형의 기계, 구성요소(component), 물리적 장치, 가상 장치(virtual equipment), 컴퓨터 저장 매체 또는 장치, 또는 전송되는 신호 파(signal wave)에 영구적으로, 또는 일시적으로 구체화(embody)될 수 있다. 소프트웨어는 네트워크로 연결된 컴퓨터 시스템 상에 분산되어서, 분산된 방법으로 저장되거나 실행될 수도 있다. 소프트웨어 및 데이터는 하나 이상의 컴퓨터 판독 가능 기록 매 체에 저장될 수 있다. 이상, 도 1 내지 도 6을 참조하여 일 실시예에 따른 비디오 처리 방법에 대해 설명하였다. 이하, 도 7 및 도 8 을 참조하여 일 실시예에 따른 비디오 처리 장치 및 그 유닛에 대해 설명한다. 도 7은 일 실시예에 따른 비디오 처리 장치를 도시한 도면이다. 도 7을 참조하면, 비디오 처리 장치는 특징 획득부, 시간-도메인 정보 융합부 및 파노라마 분할부 를 포함한다. 특징 획득부는 비디오 데이터에서 제1 이미지의 제1 이미지 특징 및 제1 이미지 앞의 제2 이미지의 제2 이 미지 특징을 획득하도록 구성될 수 있다. 특징 획득부는 특징 추출 네트워크를 통해 제1 이미지 및 제2 이미지 각각에 대해 특징 추출을 수행하여, 제1 이미지의 제1 이미지 특징 및 제2 이미지의 제2 이미지 특징을 획득하도록 구성될 수 있다. 시간-도메인 정보 융합부는 제1 이미지 특징 및 제2 이미지 특징에 대해 시간-도메인 정보 융합 처리를 진 행하여, 시간-도메인 정보 융합 처리 결과를 획득하도록 구성될 수 있다. 시간-도메인 정보 융합 처리 결과는 제1 이미지의 제1 시간-도메인 통합 특징 및 제2 이미지의 제2 시간-도메인 통합 특징을 포함할 수 있다. 시간-도메인 정보 융합부는 제1 이미지 특징 및 제2 이미지 특징에 대해 조합 연산을 수행하고, 조합된 이 미지 특징을 2개의 경로로 분할하고, 제1 경로에 대해 상관성 처리를 수행하고, 제1 경로의 상관성 처리 결과와 제2 경로에 대해 요소별로 덧셈 연산을 진행하고, 요소별 덧셈 연산 결과에 따라 시간-도메인 정보 융합 처리 결과를 획득하도록 구성될 수 있다.시간-도메인 정보 융합부는 제1 경로에 대해 적어도 한 번의 컨볼루션 연산을 수행하고, 컨볼루션 연산 후 의 제1 경로를 공간-도메인 융합을 위한 네트워크에 입력하고, 공간-도메인 융합을 위한 네트워크를 통해 상관 성 처리를 수행하도록 구성될 수 있다. 시간-도메인 정보 융합부는 공간-도메인 융합을 위한 네트워크에 입력된 특징을 적어도 2개의 경로로 나누 고, 적어도 2개의 경로 중 일부 또는 전부에 대해 서브 도메인을 추출하고, 서브 도메인 추출 결과에 대해 행렬 곱셈 연산을 수행하고, 행렬 곱셈 연산 결과와 공간-도메인 융합을 위한 네트워크에 입력된 특징에 대해 요소별 덧셈 연산을 수행하도록 구성될 수 있다. 시간-도메인 정보 융합부는 컨볼루션 연산된 조합 특징을 4개의 경로로 나누고, 4개의 경로 중 제1 경로, 제2 경로 및 제3 경로에 대해 각각 서브 도메인 추출을 진행하고, 4개의 경로 중 제1 경로의 서브 도메인 추출 결과와 제2 경로의 서브 도메인 추출 결과에 대해 행렬 곱셈 연산을 수행하고, 행렬 곱셈 연산 결과와 4개의 경 로 중 제3 경로의 서브 도메인 추출 결과에 대해 행렬 곱셈 연산을 수행한 후, 제3 경로의 서브 도메인 추출 결 과에 대해 행렬 곱셈 연산을 수행한 결과와 4개의 경로 중 제4 경로에 대해 요소별 덧셈 연산을 수행하도록 구 성될 수 있다. 시간-도메인 정보 융합부는 제1 이미지 특징에 대해 적어도 한 번의 컨볼루션 연산을 수행하고, 제2 이미 지 특징에 대해 적어도 한 번의 컨볼루션 연산을 수행하고, 컨볼루션 연산된 제1 이미지 특징 및 컨볼루션 연산 된 제2 이미지 특징에 대해 조합 연산을 수행하도록 구성될 수 있다. 시간-도메인 정보 융합부는 요소별 덧셈 연산 결과를 2개의 경로로 나누고, 2개의 경로 중 각 경로의 요소 별 덧셈 연산 결과에 대해 적어도 한 번의 컨볼루션 연산을 수행한 다음, 컨볼루션 연산된 제1 경로의 요소별 덧셈 연산 결과와 컨볼루션 연산된 제1 이미지 특징에 대해 요소별 덧셈 연산을 수행하여 제1 시간-도메인 통합 특징을 획득하고, 컨볼루션 연산된 제2 경로의 요소별 덧셈 연산 결과와 컨볼루션 연산된 제2 이미지 특징에 대 해 요소별 덧셈 연산을 수행하여 제2 시간-도메인 통합 특징을 획득하도록 구성될 수 있다. 시간-도메인 정보 융합부는 요소별 덧셈 연산 결과에 대해 적어도 한 번의 컨볼루션 연산을 수행하고, 컨 볼루션 연산된 요소별 덧셈 연산 결과와 제2 이미지 특징을 시간-도메인 정보 융합 처리 결과로 취하도록 구성 될 수 있다. 파노라마 분할부는 시간-도메인 정보 융합 처리 결과에 따라 제1 이미지의 파노라마 분할 결과를 획득하도 록 구성된다. 파노라마 분할부는 시간-도메인 정보 융합 처리 결과에 기초하여 제1 이미지에 대해 인스턴스 추적을 수행 하여, 제1 이미지의 프레임 간의 인스턴스 대응을 획득하고, 프레임 간의 인스턴스 대응에 따라 제1 이미지의 파노라마 분할 결과를 획득하도록 구성될 수 있다. 도 8은 일 실시예에 따른 비디오 처리 장치 중 파노라마 분할부를 도시한 도면이다. 도 8을 참조하면, 파노라마 분할부는 인스턴스 데이터베이스 업데이트부 및 인스턴스 추적부을 포함할 수 있다. 인스턴스 데이터베이스 업데이트부는 제2 시간-도메인 통합 특징에 기초하여 비디오 데이터의 인스턴스 데 이터베이스를 업데이트하도록 구성된다. 인스턴스 데이터베이스 업데이트부는 제2 시간-도메인 통합 특징에서 제1 개수의 기설정된 특징을 선택하 고, 선택한 제1 개수의 기설정된 특징을 비디오 데이터의 인스턴스 데이터베이스에 추가하도록 구성될 수 있다. 인스턴스 추적부는 업데이트된 인스턴스 데이터베이스에 기초하여 제1 시간-도메인 통합 특징에 대해 인스 턴스 추적을 수행하도록 구성된다. 인스턴스 추적부는 제1 시간-도메인 통합 특징에서 제2 개수의 기설정된 특징을 선택하고, 선택한 제2 개 수의 기설정된 특징과 업데이트된 인스턴스 데이터베이스를 기반으로 추적 네트워크를 통해 인스턴스 대응을 진 행하도록 구성될 수 있다. 이때, 기설정된 특징은 관심 영역 특징, 바운딩 박스에 기초하여 표현되는 특징, 또는 마스크에 기초하여 표현 되는 특징을 포함할 수 있다.파노라마 분할부는 또한, 시간-도메인 정보 융합 처리 결과를 바탕으로 제1 이미지에 대해 시맨틱 분할, 인스턴스 분할, 바운딩 박스 세분화를 수행하여, 제1 이미지의 시맨틱 분할 결과, 인스턴스 분할 결과, 바운딩 박스를 획득하고, 제1 이미지의 시맨틱 분할 결과, 인스턴스 분할 결과, 바운딩 박스, 프레임 간의 인스턴스 대 응을 융합하여, 제1 이미지의 파노라마 분할 결과를 획득하도록 구성될 수 있다. 이상, 도 7 및 도 8을 참조하여 일 실시예에 따른 비디오 처리 장치에 대해 설명하였다. 다음으로 도 9를 참조 하여 일 실시예에 따른 전자 장치에 대해 설명한다. 도 9는 일 실시예에 따른 전자 장치를 도시한 도면이다. 도 9를 참조하면, 전자 장치는 메모리와 프로세서를 포함하고, 메모리 상에는 컴퓨터 프로 그램이 저장된다. 컴퓨터 프로그램이 프로세서에 의해 실행될 때, 본 개시의 일 실시예에 따른 비디오 처리 방법이 구현된다. 컴퓨터 프로그램이 프로세서에 의해 실행될 때, 비디오 데이터의 제1 이미지의 제1 이미지 특징 및 제1 이미지 앞의 제2 이미지의 제2 이미지 특징을 획득하는 단계, 제1 이미지 특징 및 제2 이미지 특징에 대해 시간-도메인 정보 융합 처리를 진행하여, 시간-도메인 정보 융합 처리 결과를 획득하는 단계, 시간-도메인 정보 융합 처리 결과에 따라 제1 이미지의 파노라마 분할 결과를 획득하는 단계가 구현될 수 있다. 도 9에 도시된 전자 장치는 예시일 뿐이며, 본 개시의 실시예의 기능 및 사용 범위를 제한해서는 안 된다. 이상, 도 1 내지 도 9를 참조하여 본 발명의 일 실시예에 따른 비디오 처리 방법 및 장치에 대해 설명하였다. 그러나, 도 7 및 도 8에 도시된 비디오 처리 장치 및 그 구성들은 각각 소프트웨어, 하드웨어, 펌웨어 또는 항 목들의 임의의 조합으로 구성되어 특정 기능을 수행할 수 있고, 도 9에 도시된 전자 장치는 도시된 구성 요소를 포함하는 것으로 제한되지 않고, 필요에 따라 일부 구성 요소를 추가하거나 삭제할 수 있으며, 구성 요소를 결 합할 수도 있다. 본 개시의 일 실시예에 따른 비디오 처리 장치 및 방법은 비디오 데이터의 제1 이미지의 제1 이미지 특징 및 제 1 이미지 앞의 제2 이미지의 제2 이미지 특징을 획득하고, 제1 이미지 특징 및 제2 이미지 특징에 대해 시간-도 메인 정보 융합 처리를 진행하여, 시간-도메인 정보 융합 처리 결과를 획득하고, 시간-도메인 정보 융합 처리 결과에 따라 제1 이미지의 파노라마 분할 결과를 획득하여, 비디오 처리 비용을 낮추고, 비디오 처리의 속도 및 정확도를 향상시킨다. 또한, 인공지능 네트워크를 통해 시간-도메인 정보 융합 처리를 진행할 수 있다. 본 개 시의 비디오 처리 방법은 인공지능을 통해 구현 가능하며, 자율 주행, 증강 현실 및 비디오 편집 등 비디오 분 할의 글로벌한 관점이 필요한 응용 분야에 인공지능 기반을 제공할 수 있다. 본 개시의 비디오 처리 장치 및 방법을 통해, 자율주행 차량의 주변 환경에 대한 자동 인식 효과 및 자동 인식 속도를 향상시킬 수 있으며, 이 를 통해 자율 주행의 안전성을 향상시킬 수 있다."}
{"patent_id": "10-2021-0130042", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "이상과 같이 실시예들이 비록 한정된 도면에 의해 설명되었으나, 해당 기술분야에서 통상의 지식을 가진 자라면 상기를 기초로 다양한 기술적 수정 및 변형을 적용할 수 있다. 예를 들어, 설명된 기술들이 설명된 방법과 다 른 순서로 수행되거나, 및/또는 설명된 시스템, 구조, 장치, 회로 등의 구성요소들이 설명된 방법과 다른 형태 로 결합 또는 조합되거나, 다른 구성요소 또는 균등물에 의하여 대치되거나 치환되더라도 적절한 결과가 달성될 수 있다. 그러므로, 다른 구현들, 다른 실시예들 및 특허청구범위와 균등한 것들도 후술하는 청구범위의 범위에 속한다. 도면 도면1 도면2 도면3 도면4 도면5 도면6 도면7 도면8 도면9"}
{"patent_id": "10-2021-0130042", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 일 실시예에 따른 비디오 처리 알고리즘의 예시적 네트워크 구조를 도시한 도면이다. 도 2는 일 실시예에 따른 비디오 처리 과정을 도시한 흐름도이다. 도 3은 일 실시예에 따른 시간-도메인 통합 네트워크의 예시적 구조 및 그 사용 흐름을 도시한 도면이다. 도 4는 다른 일 실시예에 따른 시간-도메인 통합 네트워크의 예시적 구조 및 그 사용 흐름을 도시한 도면이다. 도 5는 일 실시예에 따른 시간-도메인 통합 네트워크에서 공간 융합을 위한 네트워크의 예시적 구조를 도시한 도면이다. 도 6은 일 실시예에 따른 시간-도메인 통합 네트워크에서 공간 융합을 위한 네트워크의 예시적 구조 및 사용 흐 름을 도시한 도면이다. 도 7은 일 실시예에 따른 비디오 처리 장치를 도시한 도면이다. 도 8은 일 실시예에 따른 비디오 처리 장치 중 파노라마 분할부를 도시한 도면이다. 도 9는 일 실시예에 따른 전자 장치를 도시한 도면이다."}
