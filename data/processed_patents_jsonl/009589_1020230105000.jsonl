{"patent_id": "10-2023-0105000", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2025-0023813", "출원번호": "10-2023-0105000", "발명의 명칭": "RGB 이미지 및 깊이 정보를 기반으로 객체의 포즈를 추정하는 장치 및 방법", "출원인": "한국로봇융합연구원", "발명자": "엄태영"}}
{"patent_id": "10-2023-0105000", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "목표 객체가 포함된 RGB 이미지와 깊이 이미지를 기반으로 시맨틱 영역을 분할하고, 상기 분할된 시맨틱 영역에대한 깊이 정보를 각각 산출하는 영역 분할부;상기 RGB 이미지를 기 학습된 인식모델에 적용하여 상기 목표 객체를 인식하고, 3차원 포즈를 추정하는 포즈 추정부; 및상기 깊이 정보를 상기 추정된 3차원 포즈에 반영하여 상기 목표 객체의 3차원 포즈를 보정하고, 상기 시맨틱영역과 상기 보정된 목표 객체의 3차원 포즈가 결합된 시맨틱 맵을 생성하는 시맨틱 맵 생성부;를 포함하는 포즈 추정 장치."}
{"patent_id": "10-2023-0105000", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1항에 있어서,상기 인식모델을 이용하여 상기 목표 객체의 특징을 픽셀 단위로 학습하는 학습부;를 더 포함하고,상기 인식모델은,학습용 RGB 이미지를 이용하여 상기 목표 객체의 인식을 학습하는 합성곱 신경망;학습용 깊이 이미지를 이용하여 상기 목표 객체의 특징 추출을 학습하는 PointNet; 및상기 합성곱 신경망과 상기 PointNet의 각 결과값을 입력값으로 하고, 상기 입력값을 통해 상기 목표 객체의 전역 특징을 추출하여 상기 픽셀 단위의 학습을 하는 다층 퍼셉트론(MLP);을 포함하는 것을 특징으로 하는 포즈 추정 장치."}
{"patent_id": "10-2023-0105000", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 1항에 있어서,상기 영역 분할부는,히스토그램 분석을 이용하여 상기 시맨틱 영역에 대한 깊이 정보를 산출하는 것을 특징으로 하는 포즈 추정 장치."}
{"patent_id": "10-2023-0105000", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 1항에 있어서,상기 포즈 추정부는,상기 3차원 포즈가 추정되면 상기 목표 객체를 3차원 경계 박스(bounding box)로 특정하는 것을 특징으로 하는포즈 추정 장치."}
{"patent_id": "10-2023-0105000", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제 1항에 있어서,상기 포즈 추정부는,상기 목표 객체가 복수개 인식되면, 기 설정된 우선순위가 가장 높은 목표 객체의 3차원 포즈만 추정하는 것을특징으로 하는 포즈 추정 장치."}
{"patent_id": "10-2023-0105000", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "공개특허 10-2025-0023813-3-제 1항에 있어서,상기 포즈 추정부는,상기 목표 객체가 복수개 인식되면, 기 설정된 우선순위를 기준으로 우선순위가 높은 목표 객체부터 라벨링을하여 순번을 설정하는 것을 특징으로 하는 포즈 추정 장치."}
{"patent_id": "10-2023-0105000", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제 6항에 있어서,상기 시맨틱 맵 생성부는,각 목표 객체별로 순번이 포함되도록 시맨틱 맵을 생성하는 것을 특징으로 하는 포즈 추정 장치."}
{"patent_id": "10-2023-0105000", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "포즈 추정 장치가 목표 객체가 포함된 RGB 이미지와 깊이 이미지를 기반으로 시맨틱 영역을 분할하고, 상기 분할된 시맨틱 영역에 대한 깊이 정보를 각각 산출하는 단계;상기 포즈 추정 장치가 상기 RGB 이미지를 기 학습된 인식모델에 적용하여 상기 목표 객체를 인식하고, 3차원포즈를 추정하는 단계; 및상기 포즈 추정 장치가 상기 깊이 정보를 상기 추정된 3차원 포즈에 반영하여 상기 목표 객체의 3차원 포즈를보정하고, 상기 시맨틱 영역과 상기 보정된 목표 객체의 3차원 포즈가 결합된 시맨틱 맵을 생성하는 단계;를 포함하는 포즈 추정 방법."}
{"patent_id": "10-2023-0105000", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "매니퓰레이션 관련 작업을 수행하는 로봇; 및상기 로봇에 구비되고, 상기 작업을 위해 목표 객체의 포즈를 추정하는 포즈 추정 장치;를 포함하되,상기 포즈 추정 장치는,상기 목표 객체가 포함된 RGB 이미지와 깊이 이미지를 기반으로 시맨틱 영역을 분할하고, 상기 분할된 시맨틱영역에 대한 깊이 정보를 각각 산출하는 영역 분할부;상기 RGB 이미지를 기 학습된 인식모델에 적용하여 상기 목표 객체를 인식하고, 3차원 포즈를 추정하는 포즈 추정부; 및상기 깊이 정보를 상기 추정된 3차원 포즈에 반영하여 상기 목표 객체의 3차원 포즈를 보정하고, 상기 시맨틱영역과 상기 보정된 목표 객체의 3차원 포즈가 결합된 시맨틱 맵을 생성하는 시맨틱 맵 생성부;를 포함하는 것을 특징으로 하는 객체 포즈 추정 시스템."}
{"patent_id": "10-2023-0105000", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제 9항에 있어서,상기 로봇은,상기 시맨틱 맵에 포함된 목표 객체가 복수개인 경우, 상기 시맨틱 맵에 포함된 목표 객체의 순번을 기반으로작업을 수행하는 것을 특징으로 하는 객체 포즈 추정 시스템."}
{"patent_id": "10-2023-0105000", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "RGB 이미지 및 깊이 정보를 기반으로 객체의 포즈를 추정하는 장치 및 방법이 개시된다. 포즈 추정 장치가 목표 객체가 포함된 RGB 이미지와 깊이 이미지를 기반으로 시맨틱 영역을 분할하고, 분할된 시맨틱 영역에 대한 깊이 정보를 각각 산출하는 영역 분할부, RGB 이미지를 기 학습된 인식모델에 적용하여 목표 객체를 인식하고, 3차원 포즈를 추정하는 포즈 추정부 및 깊이 정보를 추정된 3차원 포즈에 반영하여 목표 객체의 3차원 포즈를 보정하고, 시맨틱 영역과 보정된 목표 객체의 3차원 포즈가 결합된 시맨틱 맵을 생성하는 시맨틱 맵 생성부를 포 함한다."}
{"patent_id": "10-2023-0105000", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 객체의 포즈를 추정하는 기술에 관한 것으로, 더욱 상세하게는 목표 객체와 형상이 유사하지만 크기 가 다른 객체를 정확하게 구분하는 RGB 이미지 및 깊이 정보를 기반으로 객체의 포즈를 추정하는 장치 및 방법에 관한 것이다."}
{"patent_id": "10-2023-0105000", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "로봇의 작업을 위한 매니퓰레이션은 대부분 이송하고자 하는 객체를 특정하고, 이를 픽킹(picking)하여 원하는 목적지에 이송하는 것을 목적으로 한다. 이를 위해 카메라 영상으로부터 객체를 특정하는 기술은 계속 발전하여 왔다. 최근에는 객체의 3차원 정보와 영상을 기반으로 모델링하여 인식하고, 위치를 특정하는 기술을 이용하여 매니퓰 레이션에 이용하고 있다. 하지만 이러한 방법은 객체의 특징량이 같고, 크기만 다른 경우에 정확한 위치와 포즈를 특정하기 어렵다는 문 제점을 가지고 있다. 따라서 이러한 문제점을 해결해줄 연구가 필요한 실정이다. 선행기술문헌 특허문헌 (특허문헌 0001) 한국공개특허공보 제10-2022-0043847호(2022.04.05.)"}
{"patent_id": "10-2023-0105000", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명이 해결하고자 하는 과제는, RGB 이미지 및 깊이 정보를 기반으로 목표 객체의 포즈를 정확하게 추정하 여 형상이 유사하지만 크기가 다른 객체와의 구분을 정확하게 수행하는 RGB 이미지 및 깊이 정보를 기반으로 객 체의 포즈를 추정하는 장치 및 방법을 제공하는 것이다."}
{"patent_id": "10-2023-0105000", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기 과제를 달성하기 위해 본 발명에 따른 포즈 추정 장치는 목표 객체가 포함된 RGB 이미지와 깊이 이미지를 기반으로 시맨틱 영역을 분할하고, 상기 분할된 시맨틱 영역에 대한 깊이 정보를 각각 산출하는 영역 분할부, 상기 RGB 이미지를 기 학습된 인식모델에 적용하여 상기 목표 객체를 인식하고, 3차원 포즈를 추정하는 포즈 추 정부 및 상기 깊이 정보를 상기 추정된 3차원 포즈에 반영하여 상기 목표 객체의 3차원 포즈를 보정하고, 상기 시맨틱 영역과 상기 보정된 목표 객체의 3차원 포즈가 결합된 시맨틱 맵을 생성하는 시맨틱 맵 생성부를 포함한 다. 또한 상기 인식모델을 이용하여 상기 목표 객체의 특징을 픽셀 단위로 학습하는 학습부를 더 포함하고, 상기 인 식모델은, 학습용 RGB 이미지를 이용하여 상기 목표 객체의 인식을 학습하는 합성곱 신경망, 학습용 깊이 이미 지를 이용하여 상기 목표 객체의 특징 추출을 학습하는 PointNet 및 상기 합성곱 신경망과 상기 PointNet의 각 결과값을 입력값으로 하고, 상기 입력값을 통해 상기 목표 객체의 전역 특징을 추출하여 상기 픽셀 단위의 학습 을 하는 다층 퍼셉트론(MLP)을 포함하는 것을 특징으로 한다. 또한 상기 영역 분할부는, 히스토그램 분석을 이용하여 상기 시맨틱 영역에 대한 깊이 정보를 산출하는 것을 특 징으로 한다. 또한 상기 포즈 추정부는, 상기 3차원 포즈가 추정되면 상기 목표 객체를 3차원 경계 박스(bounding box)로 특 정하는 것을 특징으로 한다. 또한 상기 포즈 추정부는, 상기 목표 객체가 복수개 인식되면, 기 설정된 우선순위가 가장 높은 목표 객체의 3 차원 포즈만 추정하는 것을 특징으로 한다. 또한 상기 포즈 추정부는, 상기 목표 객체가 복수개 인식되면, 기 설정된 우선순위를 기준으로 우선순위가 높은 목표 객체부터 라벨링을 하여 순번을 설정하는 것을 특징으로 한다. 또한 상기 시맨틱 맵 생성부는, 각 목표 객체별로 순번이 포함되도록 시맨틱 맵을 생성하는 것을 특징으로 한다. 본 발명에 따른 포즈 추정 방법은 포즈 추정 장치가 목표 객체가 포함된 RGB 이미지와 깊이 이미지를 기반으로 시맨틱 영역을 분할하고, 상기 분할된 시맨틱 영역에 대한 깊이 정보를 각각 산출하는 단계, 상기 포즈 추정 장 치가 상기 RGB 이미지를 기 학습된 인식모델에 적용하여 상기 목표 객체를 인식하고, 3차원 포즈를 추정하는 단 계 및 상기 포즈 추정 장치가 상기 깊이 정보를 상기 추정된 3차원 포즈에 반영하여 상기 목표 객체의 3차원 포 즈를 보정하고, 상기 시맨틱 영역과 상기 보정된 목표 객체의 3차원 포즈가 결합된 시맨틱 맵을 생성하는 단계 를 포함한다. 본 발명에 따른 객체 포즈 추정 시스템은 매니퓰레이션 관련 작업을 수행하는 로봇 및 상기 로봇에 구비되고, 상기 작업을 위해 목표 객체의 포즈를 추정하는 포즈 추정 장치를 포함하되, 상기 포즈 추정 장치는, 상기 목표 객체가 포함된 RGB 이미지와 깊이 이미지를 기반으로 시맨틱 영역을 분할하고, 상기 분할된 시맨틱 영역에 대한 깊이 정보를 각각 산출하는 영역 분할부, 상기 RGB 이미지를 기 학습된 인식모델에 적용하여 상기 목표 객체를 인식하고, 3차원 포즈를 추정하는 포즈 추정부 및 상기 깊이 정보를 상기 추정된 3차원 포즈에 반영하여 상기 목표 객체의 3차원 포즈를 보정하고, 상기 시맨틱 영역과 상기 보정된 목표 객체의 3차원 포즈가 결합된 시맨틱 맵을 생성하는 시맨틱 맵 생성부를 포함하는 것을 특징으로 한다. 또한 상기 로봇은, 상기 시맨틱 맵에 포함된 목표 객체가 복수개인 경우, 상기 시맨틱 맵에 포함된 목표 객체의 순번을 기반으로 작업을 수행하는 것을 특징으로 한다."}
{"patent_id": "10-2023-0105000", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명의 실시예에 따르면, 목표 객체가 포함된 깊이 이미지를 기반으로 시맨틱 영역 분할과 히스토그램 분석 을 수행하여 깊이 정보를 특정하고, 목표 객체가 포함된 RGB 이미지를 기 학습된 인식모델을 적용하여 목표 객 체의 인식 및 포즈를 추정하며, 특정된 깊이 정보를 추정된 포즈에 반영하여 목표 객체에 대한 시맨틱 맵을 생 성할 수 있다. 이를 통해 목표 객체 관련 시맨틱 맵을 기반으로 로봇의 매니퓰레이션을 수행함으로써, 작업의 정확성과 정밀도 를 향상시킬 수 있다."}
{"patent_id": "10-2023-0105000", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "아래에서는 첨부한 도면을 참고로 하여 본 발명의 실시예에 대하여 본 발명이 속하는 기술 분야에서 통상의 지 식을 가진 자가 용이하게 실시할 수 있도록 상세히 설명한다. 그러나 본 발명은 여러 가지 상이한 형태로 구현 될 수 있으며 여기에서 설명하는 실시예에 한정되지 않는다. 그리고 도면에서 본 발명을 명확하게 설명하기 위 해서 설명과 관계없는 부분은 생략하였으며, 명세서 전체를 통하여 유사한 부분에 대해서는 유사한 도면 부호를 붙였다. 본 명세서 및 도면(이하 '본 명세서')에서, 동일한 구성요소에 대해서 중복된 설명은 생략한다. 또한 본 명세서에서, 어떤 구성요소가 다른 구성요소에 '연결되어' 있다거나 '접속되어' 있다고 언급된 때에는, 그 다른 구성요소에 직접적으로 연결되어 있거나 또는 접속되어 있을 수도 있지만, 중간에 다른 구성요소가 존 재할 수도 있다고 이해되어야 할 것이다. 반면에 본 명세서에서, 어떤 구성요소가 다른 구성요소에 '직접 연결 되어' 있다거나 '직접 접속되어' 있다고 언급된 때에는, 중간에 다른 구성요소가 존재하지 않는 것으로 이해되 어야 할 것이다. 또한, 본 명세서에서 사용되는 용어는 단지 특정한 실시예를 설명하기 위해 사용되는 것으로써, 본 발명을 한정 하려는 의도로 사용되는 것이 아니다. 또한 본 명세서에서, 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함할 수 있다. 또한 본 명세서에서, '포함하다' 또는 '가지다' 등의 용어는 명세서에 기재된 특징, 숫자, 단계, 동작, 구성요 소, 부품, 또는 이들을 조합한 것이 존재함을 지정하려는 것일 뿐, 하나 또는 그 이상의 다른 특징, 숫자, 단계, 동작, 구성요소, 부품 또는 이들을 조합한 것의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이 해되어야 할 것이다. 또한 본 명세서에서, '및/또는' 이라는 용어는 복수의 기재된 항목들의 조합 또는 복수의 기재된 항목들 중의 어느 항목을 포함한다. 본 명세서에서, 'A 또는 B'는, 'A', 'B', 또는 'A와 B 모두'를 포함할 수 있다. 또한 본 명세서에서, 본 발명의 요지를 흐리게 할 수 있는 공지 기능 및 구성에 대한 상세한 설명은 생략될 것 이다. 도 1은 본 발명의 실시예에 따른 객체 포즈 추정 시스템을 설명하기 위한 구성도이다. 도 1은 참조하면, 객체 포즈 추정 시스템은 RGB 이미지 및 깊이 정보를 기반으로 목표 객체의 포즈를 정확 하게 추정하여 형상이 유사하지만 크기가 다른 객체와의 구분을 정확하게 수행한다. 이를 통해 객체 포즈 추정 시스템은 형상이 유사하지만 크기가 다른 객체로 인해 발생되는 작업의 오류를 줄일 수 있다. 객체 포즈 추정 시스템은 포즈 추정 장치 및 로봇을 포함하고, 사용자 단말을 더 포함할 수 있다. 포즈 추정 장치는 로봇이 매니퓰레이션 관련 작업을 수행하기 위해 사용되는 목표 객체의 포즈를 추 정한다. 이를 위해 포즈 추정 장치는 목표 객체가 포함된 RGB 이미지와 깊이 이미지를 기반으로 시맨틱 영 역을 분할하고, 분할된 시맨틱(semantic) 영역에 대한 깊이 정보를 각각 산출한다. 또한 포즈 추정 장치는 RGB 이미지를 기 학습된 인식모델에 적용하여 목표 객체를 인식하고, 3차원 포즈를 추정한다. 포즈 추정 장치 는 깊이 정보를 추정된 3차원 포즈에 반영하여 목표 객체의 3차원 포즈를 보정한다. 포즈 추정 장치 는 시맨틱 영역과 보정된 목표 객체의 3차원 포즈가 결합된 시맨틱 맵(semantic map)을 생성한다. 포즈 추정 장 치는 생성된 시맨틱 맵을 로봇에 전송하여 로봇이 시맨틱 맵을 기반으로 작업을 수행하도록 제 어한다. 로봇은 매니퓰레이션 관련 작업을 수행한다. 바람직하게는 로봇은 목표 객체를 픽킹(picking)하여 원 하는 목적지에 이송하는 구동을 수행할 수 있으나, 이에 한정하지 않는다. 로봇은 포즈 추정 장치로 부터 시맨틱 맵을 수신하고, 수신된 시맨틱 맵을 이용하여 작업을 수행한다. 즉 로봇은 시맨틱 맵에 포함 된 목표 객체의 크기, 형상, 거리를 이용하여 정확하고, 정밀한 픽킹을 한 후, 목적지에 해당 목표 객체를 이송 시킬 수 있다. 여기서 로봇은 시맨틱 맵에 포함된 목표 객체가 복수개인 경우, 시맨틱 맵에 포함된 목표 객체의 순번을 기반으로 작업을 수행할 수 있다. 즉 로봇은 순번이 높은 목표 객체를 우선적으로 이송할 수 있다. 또한 로봇은 작업과 관련된 모니터링 정보를 생성할 수 있다. 모니터링 정보는 로봇의 작업 상태, 작업 시간, 작업 강도, 작업 완료율, 주변 환경 정보, 시맨틱 맵 등을 포함할 수 있다. 로봇은 모니 터링 정보를 사용자 단말로 전송한다. 사용자 단말은 사용자(또는 관리자)가 사용하는 단말로써, 로봇의 작업 상태에 대해 사용자에게 알려 준다. 즉 사용자 단말은 로봇으로부터 모니터링 정보를 수신하고, 수신된 모니터링 정보를 출력한다. 이를 통해 사용자 단말은 사용자에게 로봇의 작업 상태를 직관적으로 인지시켜 줌으로써, 비상 상황 이 발생시 사용자가 즉각적인 대처를 할 수 있도록 지원한다. 한편 도면에는 포즈 추정 장치가 로봇에 포함되는 구조로 도시되고 있으나, 이에 한정하지 않고 포즈 추정 장치가 로봇과 분리되어 개별 구성으로 구현될 수 있다. 또한 객체 포즈 추정 시스템은 포즈 추정 장치, 로봇 및 사용자 단말 사이에 통신망 을 구축하여 서로 간에 통신이 이루어지도록 지원할 수 있다. 통신망은 백본망과 가입자망으로 구성될 수 있다. 백본망은 X.25 망, Frame Relay 망, ATM망, MPLS(Multi-Protocol Label Switching) 망 및 GMPLS(Generalized Multi-Protocol Label Switching) 망 등 중에 하나 또는 복수의 통합된 망으로 구성될 수 있다. 가입자망은 FTTH(Fiber To The Home), ADSL(Asymmetric Digital Subscriber Line), 케이블망, 지그비 (zigbee), 블루투스(bluetooth), Wireless LAN(IEEE 802.11b, IEEE 802.11a, IEEE 802.11g, IEEE 802.11n), Wireless Hart(ISO/IEC62591-1), ISA100.11a(ISO/IEC 62734), CoAP(Constrained Application Protocol), MQTT(Message Queuing Telemetry Transport), WIBro(Wireless Broadband), Wimax, 3G, HSDPA(High Speed Downlink Packet Access), 4G, 5G 및 6G 등일 수 있다. 일부 실시예로, 통신망은 인터넷망일 수 있고, 이 동 통신망일 수 있다. 또한 통신망은 기타 널리 공지되었거나 향후 개발될 모든 무선통신 또는 유선통신 방식을 포함할 수 있다. 도 2는 본 발명의 실시예에 따른 포즈 추정 장치를 설명하기 위한 블록도이고, 도 3은 본 발명의 실시예에 따른 제어부를 설명하기 위한 블록도이며, 도 4는 본 발명의 실시예에 따른 객체의 포즈를 추정하는 과정을 개략적으 로 설명하기 위한 도면이고, 도 5는 본 발명의 실시예에 따른 학습 과정을 설명하기 위한 도면이며, 도 6은 본 발명의 실시예에 따른 시맨틱 맵을 생성하는 과정을 설명하기 위한 도면이다. 도 1 내지 도 6를 참조하면, 포즈 추정 장치는 학습용 목표 객체(T1)에 대한 학습을 수행하고(도 4의 (a)), 학습이 완료되면 실제 목표 객체(T2)에 대한 인식 및 포즈를 추정한다(도 4의 (b), (c)). 이때 학습용 목 표 객체(T1)과 실제 목표 객체(T2)가 형상은 동일하고, 크기가 다른 경우, 포즈 추정 장치는 깊이 정보를 이용하여 실제 목표 객체(T2)를 학습용 목표 객체(T1)와 동일한 객체로 인식하지 않고, 다른 객체로 인식함으로 써, 정확한 객체 인식을 할 수 있다. 이를 수행하기 위해 포즈 추정 장치는 카메라부, 센서부, 제 어부, 통신부 및 저장부를 포함한다. 카메라부는 매니퓰레이션 관련 작업에서 사용되는 목표 객체가 포함된 영상을 촬영한다. 카메라부는 적 어도 하나의 카메라를 포함할 수 있다. 여기서 카메라는 RGB 이미지를 생성하는 RGB 카메라이거나, RGB 이미지 및 깊이 이미지를 생성하는 RGBD 카메라일 수 있다. 센서부는 매니퓰레이션 관련 작업에서 사용되는 목표 객체가 포함된 깊이 이미지를 생성한다. 센서부는 3차원 라이다(LiDAR)일 수 있으며, 3차원 포인트 클라우드(3D point cloud)를 측정하여 깊이 이미지를 생성할 수 있다. 여기서 센서부는 카메라가 RGBD 카메라인 경우, 생략될 수 있다. 제어부는 포즈 추정 장치의 전반적인 제어를 수행한다. 제어부는 목표 객체의 정확한 포즈를 추정 하여 로봇의 작업이 원활하게 진행될 수 있도록 도와준다. 이를 위해 제어부는 영역 분할부, 포즈 추정부 및 시맨틱 맵 생성부를 포함하고, 학습부를 더 포함할 수 있다. 학습부는 인공지능 기술이 적용된 인식모델을 이용하여 목표 객체의 특징을 픽셀 단위로 학습을 한다. 인식 모델은 합성곱 신경망(CNN)(M1), PointNet(M2) 및 다층 퍼셉트론(MLP)(M3)을 포함한다. 합성곱 신경망(M1)은 학 습용 RGB 이미지를 이용하여 목표 객체의 인식을 학습한다. 합성곱 신경망(M1)은 목표 객체의 형상에 대한 학습 을 수행할 수 있다. PointNet(M2)은 학습용 깊이 이미지를 이용하여 목표 객체의 특징 추출을 학습한다. PointNet(M2)은 포인트 클라우드를 기반으로 목표 객체의 크기에 대한 학습을 수행할 수 있다. 다층 퍼셉트론 (M3)은 합성곱 신경망(M1)과 PointNet(M2)의 각 결과값을 입력값으로 하고, 입력값을 통해 목표 객체의 전역 특 징(global feature)을 추출하여 픽셀 단위의 학습을 한다. 이와 같이 학습부는 인식모델을 통해 목표 객체 의 형상뿐만 아니라 크기에 대해서도 학습을 수행할 수 있다. 여기서 학습부는 사용자가 원하는 평가 지표 의 정확도에 도달할 때까지 인식모델에 대한 학습을 반복할 수 있다. 한편 학습부는 하나의 특정 목표 객체 에 대해서만 학습을 하거나, 다양한 형상, 크기의 목표 객체에 대해서 학습을 할 수 있다. 영역 분할부는 목표 객체(T)가 포함된 RGB 이미지와 깊이 이미지가 수집되면(도 6의 (a)) RGB 이미지와 깊 이 이미지를 기반으로 시맨틱 영역을 분할한다(도 6의 (b)). 영역 분할부는 분할된 시맨틱 영역에 대한 깊 이 정보를 각각 산출한다. 이때 영역 분할부는 히스토그램 분석을 이용하여 시맨틱 영역에 대한 깊이 정보 를 산출한다. 즉 영역 분할부는 시맨틱 영역별로 깊이 정보를 산출함으로써, 이미지에 포함된 모든 객체에대한 깊이 정보를 각각 특정할 수 있다. 포즈 추정부는 RGB 이미지를 학습부로부터 학습된 인식모델에 적용하여 목표 객체(T)를 인식하고, 3차 원 포즈를 추정한다(도 6의 (C)). 이때 포즈 추정부는 인식모델에서 기 학습된 목표 객체(T)만을 인식하고, 인식된 목표 객체(T)의 3차원 포즈를 추정할 수 있다. 예를 들면 기 학습된 목표 객체(T)가 컵인 경우, 포즈 추 정부는 RGB 이미지에 포함된 컵을 인식하고, 인식된 컵의 손잡이 방향을 확인하여 포즈를 추정할 수 있다. 여기서 포즈 추정부는 목표 객체(T)의 3차원 포즈가 추정되면 목표 객체(T)를 3차원 경계 박스(bounding box)로 특정할 수 있다. 포즈 추정부는 목표 객체(T)가 복수개 인식되면 기 설정된 우선순위가 가장 높은 목표 객체의 3차원 포즈만 추정할 수 있다. 즉 포즈 추정부는 우선순위가 가장 높은 목표 객체에 대해서만 목표 객체(T)에 대해 인식 하고, 포즈를 추정할 수 있다. 또는 포즈 추정부는 목표 객체(T)가 복수개 인식되면 기 설정된 우선순위를 기준으로 우선순위가 높은 목표 객체부터 라벨링을 하여 순번을 설정할 수 있다. 즉 포즈 추정부는 기 학습된 모든 목표 객체(T)에 대해 인 식하고, 포즈를 추정할 수 있다. 여기서 우선순위는 로봇이 수행하는 작업에서의 중요도, 객체의 크기, 색 깔, 모양 등을 기준으로 설정될 수 있다. 시맨틱 맵 생성부는 영역 분할부로부터 산출된 깊이 정보를 포즈 추정부로부터 추정된 목표 객체 (T)의 3차원 포즈에 반영하여 목표 객체(T)의 3차원 포즈를 보정한다. 시맨틱 맵 생성부는 3차원 포즈를 보 정함으로써, 목표 객체(T)의 크기 및 자세를 보다 정확하게 추정할 수 있다. 시맨틱 맵 생성부는 분할된 시 맨틱 영역과 보정된 3차원 포즈가 결합된 시맨틱 맵을 생성한다. 즉 시맨틱 맵 생성부는 보정된 목표 객체 (T)의 3차원 포즈에 대한 정보가 포함된 시맨틱 맵을 생성한다. 시맨틱 맵은 목표 객체(T) 이외의 나머지 객체 에 대한 깊이 정보도 포함한다. 이때 시맨틱 맵 생성부는 목표 객체(T)가 복수개 인식되어 각 목표 객체마 다 라벨링으로 순번이 설정된 경우, 목표 객체(T)에 순번이 나타나도록 시맨틱 맵을 생성한다. 이를 통해 시맨 틱 맵 생성부는 로봇이 순번에 따라 목표 객체(T)을 픽킹하여 목적지로 이송하도록 지원할 수 있다. 통신부는 로봇과의 통신을 수행한다. 통신부는 시맨틱 맵을 로봇으로 전송한다. 통신부 는 포즈 추정 장치가 로봇의 내부에 포함되면 내부 회선을 통해 시맨틱 맵을 전송하고, 포즈 추정 장 치가 로봇과 개별 구성으로 구현되면 통신망을 통해 시맨틱 맵을 전송할 수 있다. 저장부는 포즈 추정 장치가 구동되기 위한 프로그램 또는 알고리즘이 저장된다. 저정부는 학습용 RGB 이미지, 학습용 깊이 이미지 등과 같은 학습을 위한 정보가 저장되고, 매니퓰레이션 관련 작업 수행에 필요 한 목표 객체가 포함된 RGB 이미지, 깊이 이미지가 저장된다. 또한 저장부는 시맨틱 맵을 생성하는 과정에 서 생성되는 정보가 저장된다. 저장부는 플래시 메모리 타입(flash memory type), 하드디스크 타입(hard disk type), 미디어 카드 마이크로 타입(multimedia card micro type), 카드 타입의 메모리(예를 들어 SD 또는 XD 메모리 등), 램(Random Access Memory, RAM), SRAM(Static Random Access Memory), 롬(Read-Only Memory, ROM), EEPROM(Electrically Erasable Programmable Read-Only Memory), PROM(Programmable Read-Only Memory), 자기메모리, 자기 디스크 및 광디스크 중 적어도 하나의 저장매체를 포함할 수 있다. 도 7은 본 발명의 실시예에 따른 포즈 추정 장치 관점에서의 포즈 추정 방법을 설명하기 위한 순서도이다. 도 1 및 도 7을 참조하면, 포즈 추정 방법은 목표 객체가 포함된 깊이 이미지를 기반으로 시맨틱 영역 분할과 히스토그램 분석을 수행하여 깊이 정보를 특정하고, 목표 객체가 포함된 RGB 이미지를 기 학습된 인식모델을 적 용하여 목표 객체의 인식 및 포즈를 추정한다. 이를 통해 포즈 추정 방법은 특정된 깊이 정보를 추정된 포즈에 반영한 목표 객체에 대한 시맨틱 맵을 생성하여 목표 객체의 정확한 형상, 크기 등을 산출할 수 있다. S110 단계에서, 포즈 추정 장치는 시맨틱 영역을 분할한다. 포즈 추정 장치는 목표 객체가 포함된 RGB 이미지와 깊이 이미지를 기반으로 시맨틱 영역을 분할하고, 분할된 시맨틱 영역에 대한 깊이 정보를 각각 산출한다. 이때 포즈 추정 장치는 히스토그램 분석을 이용하여 시맨틱 영역에 대한 깊이 정보를 산출할 수 있다. S120 단계에서, 포즈 추정 장치는 목표 객체에 대한 객체 인식과 포즈 추정을 한다. 포즈 추정 장치 는 RGB 이미지를 기 학습된 인식모델에 적용하여 목표 객체를 인식하고, 3차원 포즈를 추정한다. 여기서 인식모 델은 인공지능 기술이 적용된 모델로써, 목표 객체의 특징을 픽셀 단위로 인식하도록 학습된다. S130 단계에서, 포즈 추정 장치는 산출된 깊이 정보를 추정된 3차원 포즈에 반영하여 목표 객체의 3차원 포즈를 보정한다. 이를 통해 포즈 추정 장치는 목표 객체의 크기와 자세를 보다 정확하게 추정할 수 있다. S140 단계에서, 포즈 추정 장치는 목표 객체 관련 시맨틱 맵을 생성한다. 포즈 추정 장치는 시맨틱 영역과 보정된 목표 객체의 3차원 포즈가 결합된 시맨틱 맵을 생성한다. 도 8은 본 발명의 실시예에 따른 객체 포즈 추정 시스템 관점에서의 포즈 추정 방법을 설명하기 위한 순서도이 다. 도 8을 참조하면, 포즈 추정 방법은 목표 객체 관련 시맨틱 맵을 기반으로 로봇의 매니퓰레이션을 수행함 으로써, 작업의 정확성과 정밀도를 향상시킬 수 있다. S210 단계에서, 포즈 추정 장치는 목표 객체 관련 정보를 수집한다. 포즈 추정 장치는 목표 객체가 포함된 RGB 이미지 및 깊이 이미지를 수집한다. 이때 포즈 추정 장치는 RGB 카메라와 라이다 센서 또는 RGBD 카메라를 이용하여 해당 정보를 수집할 수 있으나, 이에 한정하지 않는다. S220 단계에서, 포즈 추정 장치는 목표 객체 관련 시맨틱 맵을 생성한다. 포즈 추정 장치는 수집된 RGB 이미지 및 깊이 이미지를 기반으로 시맨틱 영역과 목표 객체의 3차원 포즈가 결합된 시맨틱 맵을 생성한다. S230 단계에서, 포즈 추정 장치는 시맨틱 맵을 로봇으로 전송한다. 이때 포즈 추정 장치는 로봇 의 내부에 포함되면 내부 회선을 통해 시맨틱 맵을 전송하고, 로봇과 개별 구성으로 구현되면 통신망 을 통해 시맨틱 맵을 전송할 수 있다. S240 단계에서, 로봇은 매니퓰레이션 관련 작업을 수행한다. 로봇은 시맨틱 맵을 기반으로 작업을 수 행하여 작업 중 오류 발생율을 낮출 수 있다. S250 단계에서, 로봇은 모니터링 정보를 생성한다. 로봇은 수행되는 작업과 관련하여 모니터링 정보 를 생성한다. 모니터링 정보는 모니터링 정보는 로봇의 작업 상태, 작업 시간, 작업 강도, 작업 완료율, 주변 환경 정보, 시맨틱 맵 등을 포함할 수 있다. S260 단계에서, 로봇은 모니터링 정보를 사용자 단말로 전송한다. 로봇은 통신망을 통해 모니터 링 정보를 전송할 수 있다. S270 단계에서, 사용자 단말은 모니터링 정보를 출력한다. 사용자 단말은 수신된 모니터링 정보를 실 시간으로 출력하여 사용자가 작업 관련 정보를 직관적으로 인지할 수 있게 도와준다. 도 9는 본 발명의 실시예에 따른 컴퓨팅 장치를 설명하기 위한 블록도이다. 도 9를 참조하면, 컴퓨팅 장치(TN100)는 본 명세서에서 기술된 장치(예를 들면 포즈 추정 장치, 로봇, 사용자 단말 등) 일 수 있다. 컴퓨팅 장치(TN100)는 적어도 하나의 프로세서(TN110), 송수신 장치(TN120), 및 메모리(TN130)를 포함할 수 있 다. 또한, 컴퓨팅 장치(TN100)는 저장 장치(TN140), 입력 인터페이스 장치(TN150), 출력 인터페이스 장치 (TN160) 등을 더 포함할 수 있다. 컴퓨팅 장치(TN100)에 포함된 구성 요소들은 버스(bus)(TN170)에 의해 연결 되어 서로 통신을 수행할 수 있다. 프로세서(TN110)는 메모리(TN130) 및 저장 장치(TN140) 중에서 적어도 하나에 저장된 프로그램 명령(program command)을 실행할 수 있다. 프로세서(TN110)는 중앙 처리 장치(CPU: central processing unit), 그래픽 처리 장치(GPU: graphics processing unit), 또는 본 발명의 실시예에 따른 방법들이 수행되는 전용의 프로세서를 의 미할 수 있다. 프로세서(TN110)는 본 발명의 실시예와 관련하여 기술된 절차, 기능, 및 방법 등을 구현하도록 구성될 수 있다. 프로세서(TN110)는 컴퓨팅 장치(TN100)의 각 구성 요소를 제어할 수 있다. 메모리(TN130) 및 저장 장치(TN140) 각각은 프로세서(TN110)의 동작과 관련된 다양한 정보를 저장할 수 있다. 메모리(TN130) 및 저장 장치(TN140) 각각은 휘발성 저장 매체 및 비휘발성 저장 매체 중에서 적어도 하나로 구 성될 수 있다. 예를 들어, 메모리(TN130)는 읽기 전용 메모리(ROM: read only memory) 및 랜덤 액세스 메모리 (RAM: random access memory) 중에서 적어도 하나로 구성될 수 있다. 송수신 장치(TN120)는 유선 신호 또는 무선 신호를 송신 또는 수신할 수 있다. 송수신 장치(TN120)는 네트워크 에 연결되어 통신을 수행할 수 있다. 한편, 본 발명의 실시예는 지금까지 설명한 장치 및/또는 방법을 통해서만 구현되는 것은 아니며, 본 발명의 실 시예의 구성에 대응하는 기능을 실현하는 프로그램 또는 그 프로그램이 기록된 기록 매체를 통해 구현될 수도 있으며, 이러한 구현은 상술한 실시예의 기재로부터 본 발명이 속하는 기술 분야의 통상의 기술자라면 쉽게 구 현할 수 있는 것이다. 이상에서 본 발명의 실시예에 대하여 상세하게 설명하였지만 본 발명의 권리범위는 이에 한정되는 것은 아니고 다음의 청구범위에서 정의하고 있는 본 발명의 기본 개념을 이용한 통상의 기술자의 여러 변형 및 개량 형태 또 한 본 발명의 권리범위에 속하는 것이다."}
{"patent_id": "10-2023-0105000", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 실시예에 따른 객체 포즈 추정 시스템을 설명하기 위한 구성도이다. 도 2는 본 발명의 실시예에 따른 포즈 추정 장치를 설명하기 위한 블록도이다. 도 3은 본 발명의 실시예에 따른 제어부를 설명하기 위한 블록도이다. 도 4는 본 발명의 실시예에 따른 객체의 포즈를 추정하는 과정을 개략적으로 설명하기 위한 도면이다. 도 5는 본 발명의 실시예에 따른 학습 과정을 설명하기 위한 도면이다. 도 6은 본 발명의 실시예에 따른 시맨틱 맵을 생성하는 과정을 설명하기 위한 도면이다. 도 7은 본 발명의 실시예에 따른 포즈 추정 장치 관점에서의 포즈 추정 방법을 설명하기 위한 순서도이다. 도 8은 본 발명의 실시예에 따른 객체 포즈 추정 시스템 관점에서의 포즈 추정 방법을 설명하기 위한 순서도이 다. 도 9는 본 발명의 실시예에 따른 컴퓨팅 장치를 설명하기 위한 블록도이다."}
