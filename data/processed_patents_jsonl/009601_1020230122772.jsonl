{"patent_id": "10-2023-0122772", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2025-0039829", "출원번호": "10-2023-0122772", "발명의 명칭": "유튜브 영상 분류 방법, 이를 이용한 인플루언서 전문 분야 분류 방법 및 그 장치", "출원인": "주식회사 아이피씨엑스", "발명자": "정재훈"}}
{"patent_id": "10-2023-0122772", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "영상 분류 장치가 클라이언트의 웹 브라우저를 통해 입력받은 YouTube 컨텐츠의 URL(uniform resourcelocator) 정보를 프론트엔드(frontend)에 제공하는 단계;상기 영상 분류 장치가 상기 프론트엔드로부터 백엔드(backend)로 상기 URL 정보를 전달하는 단계;상기 영상 분류 장치가 상기 백엔드를 통해 YouTube API(application programming interface)를 이용하여 상기URL 정보의 자막(subtitle) 데이터를 수집하고, 상기 자막 데이터를 기반으로 유효 키워드를 추출하는 전처리작업을 수행하는 단계; 및상기 영상 분류 장치가 상기 유효 키워드를 사전 학습된 언어 모델에 입력하여 상기 URL 정보에 대응하는YouTube 컨텐츠의 분류 결과를 출력하는 단계;를 포함하는 영상 분류 방법."}
{"patent_id": "10-2023-0122772", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1 항에 있어서,상기 전처리 작업을 수행하는 단계는,상기 자막 데이터를 토큰화(tokenization)하는 단계; 및금칙어 리스트(forbidden words list)를 이용하여 토큰화된 상기 자막 데이터를 필터링함으로써 상기 유효 키워드를 추출하는 단계;를 포함하는, 영상 분류 방법."}
{"patent_id": "10-2023-0122772", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 2 항에 있어서,상기 토큰화하는 단계는,상기 자막 데이터 내 감지된 자연어를 형태소 라이브러리를 통해 품사 정보를 인식하고, 각 자연어에 해당하는품사를 태깅(tagging)된 형태로 토큰화를 수행하고, 품사 중 명사의 특성이 태깅된 토큰만을 수집하고, 각 명사토큰들의 반복도를 측정하여 가장 높은 빈도수를 기준으로 정렬하는, 영상 분류 방법."}
{"patent_id": "10-2023-0122772", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 2 항에 있어서,상기 금칙어 리스트는,말버릇, 유행어 및 합성어 중 적어도 하나 이상의 비표준어적인 특성 및 의미가 없거나 독자적으로 의미를 가질수 없는 특성을 지닌 자연어를 노이즈로서 포함하는, 영상 분류 방법."}
{"patent_id": "10-2023-0122772", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제 2 항에 있어서,상기 유효 키워드를 추출하는 단계는,정렬된 토큰들을 상기 금칙어 리스트를 기반으로 필터링을 수행하고, 상기 정렬된 토큰 중 상기 금칙어 리스트의 노이즈에 해당하지 않는 토큰을 유효한 키워드로서 반환하는, 영상 분류 방법."}
{"patent_id": "10-2023-0122772", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제 1 항에 있어서,상기 분류 결과를 출력하는 단계는,공개특허 10-2025-0039829-3-상기 전처리 작업을 통해 추출된 상기 유효 키워드를 상기 URL 정보의 전문 분야 분류를 위해 상기 언어 모델에입력하는 단계; 및상기 언어 모델에 입력된 상기 유효 키워드를 상기 언어 모델 내 라벨링된 전문 분야 중 하나로 분류하고, 상기백엔드로부터 상기 프론트엔드에 전송하는 것으로 상기 URL 정보의 분류 결과를 출력하는 단계;를 포함하는, 영상 분류 방법."}
{"patent_id": "10-2023-0122772", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제 1 항에 있어서,상기 영상 분류 장치가 상기 분류 결과에 따라 상기 YouTube 컨텐츠의 인플루언서 전문 분야를 설정하는 단계;를 더 포함하는, 영상 분류 방법."}
{"patent_id": "10-2023-0122772", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "영상 분류 장치가 영상의 음성 데이터로부터 추출된 자막 데이터를 입력받는 단계;상기 영상 분류 장치가 제공된 상기 자막 데이터를 전처리하는 것으로 유효 키워드를 추출하는 단계; 및상기 영상 분류 장치가 상기 유효 키워드를 사전 학습된 언어 모델에 입력하여 상기 영상의 분류를 수행하는 단계;를 포함하는, 영상 분류 방법."}
{"patent_id": "10-2023-0122772", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제 8 항에 있어서,상기 유효 키워드를 추출하는 단계는,상기 자막 데이터 중 명사의 특성을 포함하는 자막 데이터를 토큰화하고, 각 토큰의 반복도에 기반하여 높은 빈도수대로 정렬하는 단계; 및정렬된 토큰을 금칙어 리스트를 통해 필터링함으로써 상기 정렬된 토큰 중 일부를 유효 키워드로서 반환하는 단계;를 포함하는, 영상 분류 방법."}
{"patent_id": "10-2023-0122772", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제 9 항에 있어서,상기 금칙어 리스트는,기설정된 상기 금칙어 리스트를 우회할 토큰의 개수에 따라 상기 정렬된 토큰을 탐색하여 영상 분류에 불필요한노이즈에 해당하는 토큰을 제거하고, 상기 노이즈에 해당하지 않는 토큰은 유효한 키워드로서 반환하는, 영상분류 방법."}
{"patent_id": "10-2023-0122772", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제 8 항에 있어서,상기 사전 학습된 언어 모델은,상기 유효 키워드를 검증하기 위한 인공 지능 모델로서, 비선형력이 sigmoid 함수보다 상대적으로 강한 tanh()함수를 사용하고, SNS 데이터 및 기설정된 개수의 카테고리별 영상을 학습 데이터로 사용하고, 입력된 상기 유효 키워드에 따라 logit을 출력하는, 영상 분류 방법."}
{"patent_id": "10-2023-0122772", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제 8 항에 있어서,상기 영상의 분류를 수행하는 단계는,상기 유효 키워드를 상기 사전 학습된 언어 모델에 입력함으로써 유효 키워드 별 logit을 출력하고, 상기 logit중 최대값을 기설정된 임계값(threshold)과 비교하는 것으로 영상의 분류 결과를 출력하는 단계; 및공개특허 10-2025-0039829-4-상기 유효 키워드를 금칙어 리스트에 노이즈로서 반환하는 단계; 중 적어도 하나를 수행하는, 영상 분류 방법."}
{"patent_id": "10-2023-0122772", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제 12 항에 있어서,상기 영상의 분류 결과를 출력하는 단계는,상기 언어 모델로부터 출력된 최대 logit이 상기 임계값보다 크다면 상기 영상에 해당하는 상기 언어 모델 내라벨링된 영상 분류 결과를 출력하는, 영상 분류 방법."}
{"patent_id": "10-2023-0122772", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제 12 항에 있어서,상기 금칙어 리스트에 노이즈로서 반환하는 단계는,상기 언어 모델로부터 출력된 최대 logit이 상기 임계값보다 작다면 반환된 유효 키워드를 상기 금칙어 리스트에 재반환하여 노이즈로서 추가하고, 상기 언어 모델로부터 출력된 최대 logit이 임계값을 넘어서게 하는 임의의 유효 키워드를 추출할 때까지 상기 금칙어 리스트를 이용하여 정렬된 토큰의 탐색을 반복하는 단계;를 더 포함하는 영상 분류 방법."}
{"patent_id": "10-2023-0122772", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제 1 항 내지 제 14 항 중에 어느 한 항의 방법을 컴퓨터에서 실행시키기 위한 프로그램을 기록한 컴퓨터로 읽을 수 있는 기록매체."}
{"patent_id": "10-2023-0122772", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "클라이언트로부터 입력된 YouTube 컨텐츠의 URL 정보를 제공받는 통신부; 및YouTube API를 이용하여 상기 URL 정보의 자막 데이터를 수집하고, 상기 자막 데이터를 기반으로 유효 키워드를추출하는 전처리 작업을 수행하고, 상기 유효 키워드를 사전 학습된 언어 모델에 입력하여 상기 URL 정보에 대응하는 YouTube 컨텐츠의 분류 결과를 출력하는 처리부;를 포함하는 영상 분류 장치."}
{"patent_id": "10-2023-0122772", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제 16 항에 있어서,상기 처리부는,상기 자막 데이터를 토큰화하고, 금칙어 리스트를 이용하여 토큰화된 상기 자막 데이터를 필터링함으로써 상기유효 키워드를 추출하는, 영상 분류 장치."}
{"patent_id": "10-2023-0122772", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제 17 항에 있어서,상기 처리부는,말버릇, 유행어 및 합성어 중 적어도 하나 이상의 비표준어적인 특성 및 의미가 없거나 독자적으로 의미를 가질수 없는 특성을 지닌 자연어를 노이즈로서 금칙어 리스트 내에 저장하고, 상기 금칙어 리스트를 참조하여 상기금칙어 리스트를 우회할 토큰의 개수를 미리 설정하고, 설정된 상기 토큰의 개수에 따라 최빈도수로 정렬된 토큰을 탐색하는 것으로 영상 분류에 불필요한 상기 노이즈에 해당하는 토큰을 제거하거나, 상기 노이즈에 해당하지 않는 토큰을 유효한 키워드로서 반환하는, 영상 분류 장치."}
{"patent_id": "10-2023-0122772", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제 16 항에 있어서,상기 처리부는,상기 전처리 작업을 통해 추출된 상기 유효 키워드를 상기 URL 정보의 전문 분야 분류를 위해 상기 언어 모델에공개특허 10-2025-0039829-5-입력하고, 상기 언어 모델에 입력된 상기 유효 키워드를 상기 언어 모델 내 라벨링된 전문 분야 중 하나로 분류하여 상기 URL 정보의 분류 결과를 출력하는, 영상 분류 장치."}
{"patent_id": "10-2023-0122772", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제 16 항에 있어서,상기 분류 결과에 따라 상기 YouTube 컨텐츠의 인플루언서 전문 분야를 설정하는 인플루언서 설정부;를 더 포함하는, 영상 분류 장치."}
{"patent_id": "10-2023-0122772", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 유튜브 영상 분류 방법, 이를 이용한 인플루언서 전문 분야 분류 기술에 관한 것으로, 영상 분류 장치 는, 클라이언트의 웹 브라우저를 통해 입력받은 YouTube 컨텐츠의 URL(uniform resource locator) 정보를 프론 트엔드(frontend)에 제공하고, 프론트엔드로부터 백엔드(backend)로 URL 정보를 전달하고, 백엔드를 통해 YouTube API(application programming interface)를 이용하여 URL 정보의 자막(subtitle) 데이터를 수집하고, 자막 데이터를 기반으로 유효 키워드를 추출하는 전처리 작업을 수행하고, 유효 키워드를 사전 학습된 언어 모델 에 입력하여 URL 정보에 대응하는 YouTube 컨텐츠의 분류 결과를 출력한다."}
{"patent_id": "10-2023-0122772", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 명세서는 인플루언서가 업로드하는 유튜브 컨텐츠의 전문 분야를 분석하기 위해, 유튜브 자막 데이터의 전처 리 및 키워드 추출법과 추출된 키워드를 이용한 딥러닝 기반 분석에 관한 것이다."}
{"patent_id": "10-2023-0122772", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "현재 국내에 존재하는 인플루언서 플랫폼들은 인플루언서와 클라이언트간의 매칭을 위하여 인플루언서가 클라이 언트들이 업로드한 광고 및 홍보 아이템을 확인 후 신청하여 매칭 작업이 이루어진다. 자연어 처리 기술의 발전 으로 인한 고도화된 자연어 처리 기술을 통해 인플루언서의 SNS 데이터의 전처리를 통해 인플루언서의 성향을 쉽게 분석할 수 있게 되었다. 또한, 인공지능 기술의 발전으로 BERT와 같은 대용량 모델의 학습을 통해 자연어 데이터를 특정 클래스로 분류할 수 있게 되어 인플루언서의 전문분야와 클라이언트가 신청하는 캠페인의 전문분 야를 자동화로 분류할 수 있게 되었다. 이러한 기술을 통해 인플루언서들은 클라이언트들이 업로드한 모든 광고 및 홍보 아이템들을 일일이 확인해야 하는 불편함이 줄었으며 또한 클라이언트들은 의뢰한 캠페인에 참여 신청 한 인플루언서 중 누가 캠페인 아이템을 홍보하기에 적합한지 검증하는데 있는 어려움을 극복할 수 있게 되었다. 하지만, 자연어처리를 이용하여 SNS 데이터를 분석하는 작업은 전처리 작업 만으로는 한계가 있다. 인플루언서 가 업로드하는 광고목적의 SNS 포스팅 데이터는 캠페인에서 필요로 하는 글귀인 캡션이나 해시태그가 필수불가 결 하기 때문에 포스팅 자체에서 제목과 해시태그 등 유의미한 데이터의 추출이 가능하지만 YouTube와 같은 영 상 컨텐츠 플랫폼의 컨텐츠는 SNS 포스팅과 달리 기존의 기술 도입을 통한 분석이 제한적이다. 컨텐츠 기반의 포스팅은 인스타그램이나 페이스북처럼 설명을 자세히 기입할 필요 없이 영상에서 설명을 하기 때문에 YouTube 컨텐츠의 제목, 설명 및 해시태그는 불필요하거나 광고성과 연관성이 낮은 경우가 있다. 이러한 경우에 기존 기 술처럼 제목, 설명 및 해시태그를 추출하여 분석하는데 어려움이 있을 수 있기에 새로운 기술이 필요하다. 즉, SNS기반의 분석은 인플루언서의 포스팅 데이터를 수집하여 분석하는 것으로 신뢰성 있는 분석이 가능했지만, 유튜브와 같은 컨텐츠 플랫폼의 데이터는 포스팅 데이터보다는 영상의 분석이 중요해진 것이다."}
{"patent_id": "10-2023-0122772", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 명세서의 실시예들이 해결하고자 하는 기술적 과제는, 인플루언서가 업로드하는 유튜브 컨텐츠를 분석하여 인플루언서의 전문 분야를 분류함에 있어서, 컨텐츠 내 인플루언서가 반복적으로 언급하는 단어 중 격조사, 보 조사, 감탄사 및 유행어와 컨텐츠에 상관없는 제목 및 해시태그 내용이 컨텐츠 분석에 사용됨으로써 인플루언서 의 전문 분야 분류 결과의 신뢰성이 낮아지는 것으로 발생하는 부정확한 분류를 극복하고자 한다."}
{"patent_id": "10-2023-0122772", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기 기술적 과제를 해결하기 위하여, 본 명세서의 일 실시예에 따른 유튜브 영상 분류 방법, 이를 이용한 인플 루언서 전문 분야 분류 방법은, 상 분류 장치가 클라이언트의 웹 브라우저를 통해 입력받은 YouTube 컨텐츠의 URL(uniform resource locator) 정보를 프론트엔드(frontend)에 제공하는 단계; 상기 영상 분류 장치가 상기 프론트엔드로부터 백엔드(backend)로 상기 URL 정보를 전달하는 단계; 상기 영상 분류 장치가 상기 백엔드를 통 해 YouTube API(application programming interface)를 이용하여 상기 URL 정보의 자막(subtitle) 데이터를 수집하고, 상기 자막 데이터를 기반으로 유효 키워드를 추출하는 전처리 작업을 수행하는 단계; 및 상기 영상 분 류 장치가 상기 유효 키워드를 사전 학습된 언어 모델에 입력하여 상기 URL 정보에 대응하는 YouTube 컨텐츠의 분류 결과를 출력하는 단계;를 포함한다. 일 실시예에 따른, 인플루언서 전문 분야 분류 방법에서, 상기 전처리 작업을 수행하는 단계는, 상기 자막 데이 터를 토큰화(tokenization)하는 단계; 및 금칙어 리스트(forbidden words list)를 이용하여 토큰화된 상기 자 막 데이터를 필터링함으로써 상기 유효 키워드를 추출하는 단계;를 포함할 수 있다. 일 실시예에 따른, 인플루언서 전문 분야 분류 방법에서, 상기 분류 결과를 출력하는 단계는, 상기 전처리 작업 을 통해 추출된 상기 유효 키워드를 상기 URL 정보의 전문 분야 분류를 위해 상기 언어 모델에 입력하는 단계; 및 상기 언어 모델에 입력된 상기 유효 키워드를 상기 언어 모델 내 라벨링된 전문 분야 중 하나로 분류하고, 상기 백엔드로부터 상기 프론트엔드에 전송하는 것으로 상기 URL 정보의 분류 결과를 출력하는 단계;를 포함할 수 있다. 일 실시예에 따른, 인플루언서 전문 분야 분류 방법에서, 상기 영상 분류 장치가 상기 분류 결과에 따라 상기 YouTube 컨텐츠의 인플루언서 전문 분야를 설정하는 단계;를 더 포함할 수 있다. 상기 기술적 과제를 해결하기 위하여, 본 명세서의 일 실시예에 따른 인플루언서 전문 분야 분류 방법은, 영상 분류 장치가 영상의 음성 데이터로부터 추출된 자막 데이터를 입력받는 단계; 상기 영상 분류 장치가 제공된 상 기 자막 데이터를 전처리하는 것으로 유효 키워드를 추출하는 단계; 및 상기 영상 분류 장치가 상기 유효 키워 드를 사전 학습된 언어 모델에 입력하여 상기 영상의 분류를 수행하는 단계;를 포함한다. 일 실시예에 따른, 인플루언서 전문 분야 분류 방법에서, 상기 유효 키워드를 추출하는 단계는, 상기 자막 데이 터 중 명사의 특성을 포함하는 자막 데이터를 토큰화하고, 각 토큰의 반복도에 기반하여 높은 빈도수대로 정렬 하는 단계; 및 정렬된 토큰을 금칙어 리스트를 통해 필터링함으로써 상기 유효 키워드를 반환하는 단계;를 포함 할 수 있다. 일 실시예에 따른, 인플루언서 전문 분야 분류 방법에서, 상기 금칙어 리스트는, 기설정된 상기 금칙어 리스트 를 우회할 토큰의 개수에 따라 상기 정렬된 토큰을 탐색하여 영상 분류에 불필요한 노이즈에 해당하는 토큰을 제거하고, 상기 노이즈에 해당하지 않는 토큰은 유효한 키워드로서 반환할 수 있다. 일 실시예에 따른, 인플루언서 전문 분야 분류 방법에서, 상기 영상의 분류를 수행하는 단계는, 상기 유효 키워 드를 상기 사전 학습된 언어 모델에 입력함으로써 유효 키워드 별 logit을 출력하고, 상기 logit 중 최대값을 기설정된 임계값(threshold)과 비교하는 것으로 영상의 분류 결과를 출력하는 단계; 및 상기 유효 키워드를 금 칙어 리스트에 노이즈로서 반환하는 단계; 중 적어도 하나를 수행할 수 있다. 나아가, 이하에서는 상기 기재된 인플루언서 전문 분야 분류 방법을 컴퓨터에서 실행시키기 위한 프로그램을 기 록한 컴퓨터로 읽을 수 있는 기록매체를 제공한다. 상기 기술적 과제를 해결하기 위하여, 본 명세서의 일 실시예에 따른 인플루언서 전문 분야 분류 장치는, 클라 이언트로부터 입력된 YouTube 컨텐츠의 URL 정보를 제공받는 통신부; 및 YouTube API를 이용하여 상기 URL 정보 의 자막 데이터를 수집하고, 상기 자막 데이터를 기반으로 유효 키워드를 추출하는 전처리 작업을 수행하고, 상 기 유효 키워드를 사전 학습된 언어 모델에 입력하여 상기 URL 정보에 대응하는 YouTube 컨텐츠의 분류 결과를 출력하는 처리부;를 포함한다. 일 실시예에 따른, 인플루언서 전문 분야 분류 장치에서, 상기 처리부는, 상기 자막 데이터를 토큰화하고, 금칙 어 리스트를 이용하여 토큰화된 상기 자막 데이터를 필터링함으로써 상기 유효 키워드를 추출할 수 있다. 일 실시예에 따른, 인플루언서 전문 분야 분류 장치에서, 상기 처리부는, 말버릇, 유행어 및 합성어 중 적어도 하나 이상의 비표준어적인 특성 및 의미가 없거나 독자적으로 의미를 가질 수 없는 특성을 지닌 자연어를 노이 즈로서 금칙어 리스트 내에 저장하고, 상기 금칙어 리스트를 참조하여 상기 금칙어 리스트를 우회할 토큰의 개 수를 미리 설정하고, 설정된 상기 토큰의 개수에 따라 최빈도수로 정렬된 토큰을 탐색하는 것으로 영상 분류에 불필요한 상기 노이즈에 해당하는 토큰을 제거하거나, 상기 노이즈에 해당하지 않는 토큰을 유효한 키워드로서 반환할 수 있다. 일 실시예에 따른, 인플루언서 전문 분야 분류 장치에서, 상기 처리부는, 상기 전처리 작업을 통해 추출된 상기 유효 키워드를 상기 URL 정보의 전문 분야 분류를 위해 상기 언어 모델에 입력하고, 상기 언어 모델에 입력된 상기 유효 키워드를 상기 언어 모델 내 라벨링된 전문 분야 중 하나로 분류하여 상기 URL 정보의 분류 결과를출력할 수 있다. 일 실시예에 따른, 인플루언서 전문 분야 분류 장치에서, 상기 분류 결과에 따라 상기 YouTube 컨텐츠의 인플루 언서 전문 분야를 설정하는 인플루언서 설정부;를 더 포함할 수 있다."}
{"patent_id": "10-2023-0122772", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "상기된 본 명세서의 실시예들에 따르면, 인플루언서가 업로드하는 유튜브 영상 분석을 위해 자막 데이터를 기반 으로 키워드를 추출하여 학습된 딥러닝 모델에 입력 예제로 사용함으로써 전문 분야를 분류하는 프레임워크를 제안하였다. 이 프레임워크는 금칙어 딕셔너리를 통한 핵심적인 키워드 추출이 가능하고, 추출한 키워드는 일반 적으로 제공되는 제목과 해시 태그 데이터보다 더 유의미함을 확인했다. 또한, STT 기반의 자막 데이터의 분석 이 가능해지는 것으로 신뢰성 있는 분류가 가능하다."}
{"patent_id": "10-2023-0122772", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 명세서의 실시예들을 구체적으로 설명하기에 앞서, 본 명세서의 실시예들이 구현되는 인플루언서 전문 분야 분류 기술의 분야에서 나타나는 목표와 이를 해결하기 위해 고려될 수 있는 기술적 수단과 구성을 소개하도록 한다. API(application programming interface)는 응용 프로그램 프로그래밍 인터페이스로서, 프로그래밍에서 프로그 램을 작성하기 위한 일련의 부(sub) 프로그램, 프로토콜 등을 정의하여 상호 작용을 하기 위한 인터페이스 사양 을 말한다. API는 흔히 function, method 또는 operation 등으로 다양하게 불리는 '소프트웨어 컴포넌트'의 기능, 입력, 출 력, 그리고 이에 사용되는 자료형으로 표현된다. API 자체는 어디까지나 사양(specification)만을 정의하기 때 문에 구현(implementation)과는 독립적이다. 이를 실제로 구현한 것은 라이브러리(library)라고 부른다. API는 다양한 형태로 존재하며, 유닉스의 POSIX 표준, 윈도우의 MFC나 Win32, C++의 표준 템플릿 라이브러리(STL), Java SE API 등이 이에 해당한다. 예를 들어, 그래픽 카드나 디스크 드라이브 등의 하드웨어 또는 데이터베이스를 저레벨에서 직접 조작할 때, API는 작업을 편리하게 해준다. 컴퓨터 운영체제에서 일련의 과정들은 밑바닥에서부터 매우 저수준으로 작업이 수행되는데, API는 이러한 작업들에 대한 기능을 대상이 되는 언어에 맞게 추상화하고 프로그래머가 사용하기 편리하게 해준다. 따라서, 프로그래머는 C언어나 어셈블리어 같이 저단계 프로그래밍 언어에서 다루는 메모리 조작이나 하드웨어 조작 등을 직접 제어할 필요 없이 API만을 가지고도 손쉽게 이를 고레벨 프로그래밍 언어에 서도 제어할 수 있다. API는 라이브러리와는 분명한 차이가 있다. API는 소프트웨어 개발에서 호환성을 위해 지켜야 하는 추상적인 원 칙이다. 라이브러리는 이러한 하나 이상의 API를 기반으로 개발자에게 다양한 기능을 제공할 수 있도록 실제 구 현된 구현체다. API는 여러 기업과 개발자들이 서로의 프로그램이 호환되도록 합의한 원칙이다. 라이브러리는 실제 이를 바탕으로 구현된 결과물이다. 대개의 경우 독립된 응용 프로그램(application) 간의 상호작용은 이미 구현된 코드의 재사용이기 때문에 라이브러리는 다시 쓰기 위해 미리 구성된 코드 뭉치들을 의미하는 것이고,API를 기반으로 구현되었다고 볼 수 있다. 프레임워크는 그 자체를 기반으로 명확하게 정의된 대량의 라이브러리가 있다는 점에서 API와 비슷하다. 하지만 일반적인 API는 전체 제어 구조를 호출하는 쪽에서 원하는대로 진행할 수 있지만, 프레임워크는 특정 목적을 벗 어나면 기능하지 않는다. 프로그램에 플러그인 형태로 설계된 API가 적용되면, 이미 작성되어 컴파일(compile)되고 완성된 프로그램의 수 정없이 프로그램의 기능을 추가하는 것이 가능하다. Internet Explorer, 파이어폭스, 크롬과 같은 다양한 웹 브 라우저 프로그램의 플러그인, 애드온과 같은 것이 바로 이러한 형식의 플러그인 API를 사용해 구현된 것이다. API가 실제 기능 구현체인 라이브러리와 함께 제공되는 경우도 있으며, 이 경우를 SDK(software development kit)라고 한다. SDK는 일반적으로 API, 라이브러리와 함께 프로그램을 개발하는데 필요한 여러 보조 프로그램을 포함한다. 즉, API는 소스 코드 수준에서 정의되는 인터페이스라고 할 수 있다. 이와는 달리 기계어 이진 바이너리 수준에 서 정의되는 이러한 인터페이스는 ABI(application binary interface)라고 한다. 자연어처리와 인공지능을 활용한 SNS 데이터 기반 인플루언서와 클라이언트간 매칭 시스템 프레임워크는 SNS 플 랫폼 중 하나인 인스타그램 서부터 추출한 빅데이터를 활용하여 분석하는 기술이다. 해당 기술은 분류하고자 하 는 클래스별 인플루언서들의 데이터를 수집해 전처리 작업 후 라벨링하여 사전 학습된 딥러닝 모델인 BERT에 전 이학습을 수행한다. 학습이 완료된 프레임워크는 입력 예제를 라벨링한 전문분야 중 하나로 자동분류해줄 수 있 게 한다. 해당 프레임워크를 이용하여 인플루언서가 업로드하는 포스팅이 어떠한 전문분야인지 알 수 있다. BERT 모델은 bidirectional encoder representations from transformers로, 이름에서 알 수 있듯 Transformer 기반의 인코더 모델이다. 딥러닝 기반 번역 모델로 크게 지명된 모델인 Transformer는 시계열 데이터로써 분류 되는 자연어의 가중치를 Attention 기반으로 유용한 표현(representation)을 학습하는 모델이다. 해당 모델은 1 억개가 넘는 파라미터로 구성된 대용량 모델로서 8백만개 이상의 말뭉치 데이터 및 25억개의 위키피디아 데이터 로 사전 학습되었기에 빅 데이터들의 표현을 학습하여 문장의 예측이 가능하다. 이처럼 고도로 학습된 BERT 모 델에 분류하는 출력층을 추가하여 전이학습을 통해 사용자들이 원하는 학습을 진행할 수 있다. 이하에서는 도면을 참조하여 본 명세서의 실시예들을 구체적으로 설명하도록 한다. 다만, 하기의 설명 및 첨부 된 도면에서 실시예들의 요지를 흐릴 수 있는 공지 기능 또는 구성에 대한 상세한 설명은 생략한다. 덧붙여, 명 세서 전체에서, 어떤 구성 요소를 '포함'한다는 것은, 특별히 반대되는 기재가 없는 한 다른 구성요소를 제외하 는 것이 아니라, 다른 구성요소를 더 포함할 수 있는 것을 의미한다. 본 명세서에서 사용한 용어는 단지 특정한 실시예를 설명하기 위해 사용된 것으로, 본 명세서를 한정하려는 의 도가 아니다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 출원에서, \"포함하다\" 또는 \"구비하다\" 등의 용어는 설시된 특징, 숫자, 단계, 동작, 구성요소, 부분품 또는 이들을 조합 한 것이 존재함을 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성요소, 부분 품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되어야 한다. 특별히 다르게 정의되지 않는 한, 기술적이거나 과학적인 용어를 포함해서 여기서 사용되는 모든 용어들은 본 명세서가 속하는 기술 분야에서 통상의 지식을 가진 자에 의해 일반적으로 이해되는 것과 동일한 의미이다. 일 반적으로 사용되는 사전에 정의되어 있는 것과 같은 용어들은 관련 기술의 문맥상 가지는 의미와 일치하는 의미 인 것으로 해석되어야 하며, 본 명세서에서 명백하게 정의하지 않는 한, 이상적이거나 과도하게 형식적인 의미 로 해석되지 않는다. 도 1은 일 실시예에 따른 유튜브 영상 분류 방법, 이를 이용한 인플루언서 전문 분야 분류 방법을 도시한 흐름 도이다. S110 단계에서, 영상 분류 장치는, 클라이언트의 웹 브라우저를 통해 입력받은 YouTube 컨텐츠의 URL(uniform resource locator) 정보를 프론트엔드(frontend)에 제공한다. S130 단계에서, 상기 영상 분류 장치는, 상기 프론트엔드로부터 백엔드(backend)로 상기 URL 정보를 전달한다. S150 단계에서, 상기 영상 분류 장치는, 상기 백엔드를 통해 YouTube API(application programming interfac e)를 이용하여 상기 URL 정보의 자막(subtitle) 데이터를 수집하고, 상기 자막 데이터를 기반으로 유효 키워드 를 추출하는 전처리 작업을 수행한다.S170 단계에서, 상기 영상 분류 장치는, 상기 유효 키워드를 사전 학습된 언어 모델에 입력하여 상기 URL 정보 에 대응하는 YouTube 컨텐츠의 분류 결과를 출력한다. 상기 분류 결과를 출력하는 과정은, 상기 전처리 작업을 통해 추출된 상기 유효 키워드를 상기 URL 정보의 전문 분야 분류를 위해 상기 언어 모델에 입력하고, 상기 언어 모델에 입력된 상기 유효 키워드를 상기 언어 모델 내 라벨링된 전문 분야 중 하나로 분류하고, 상기 백엔드로부터 상기 프론트엔드에 전송하는 것으로 상기 URL 정보 의 분류 결과를 출력할 수 있다. 또한, 상기 영상 분류 장치는, 상기 분류 결과에 따라 상기 YouTube 컨텐츠의 인플루언서 전문 분야를 설정할 수 있다. 도 2는 유튜브 자막 데이터 분석 프레임워크를 도시한 흐름도이다. 상기 프레임워크는 유튜브 데이터를 분석할 때 불충분한 데이터를 충당하거나 불필요한 데이터의 오용을 방지하 기 위해 컨텐츠의 전체를 포괄하는 데이터인 자막 데이터를 활용한다. 이 때, 컨텐츠는 동영상을 포함할 수 있 다. Google에서는 기본적으로 STT 기술을 통한 Subtitle 생성을 API로 지원한다. 상기 API는 영상에서 음성을 Subtitle데이터로써 제공하기 때문에 이를 통해 컨텐츠 전체에서 인플루언서가 말하는 내용을 자연어 데이터로 써 사용할 수 있다. 이러한 데이터는 함축적인 의미나 컨텐츠와 무관한 내용을 담은 제목이나 설명문 데이터와 는 달리 컨텐츠의 모든 내용을 담고 있기 때문에 사용가치가 매우 높다. 본 명세서는 자막 데이터에서 분류에 있어 핵심적인 정보를 내포한 키워드를 추출하여 BERT 모델과 연계해 전문분야 분류를 수행하고자 한다. 도 2는 상기 프레임워크의 전반적인 Workflow를 보여준다. 클라이언트가 분석하고자 하는 YouTube 컨텐츠의 URL 정보를 클라이언트의 웹 브라우저를 통해 프론트엔드(frontend)에 입력하게 되면, 프론트엔드는 YouTube API를 통해 해당 URL 정보의 섬네일(thumbnail)을 요청하고, 프론트엔드에 섬네일 데이터를 전송하는 것으로 클라이언 트에게 섬네일 데이터를 출력한다. 클라이언트의 섬네일 데이터 검수가 진행되고, 이후 프론트엔드는 입력된 URL 정보를 백엔드(backend)에 전달한다. URL 정보를 전달받은 백엔드는 YouTube API와 통신을 통해 해당 영상 의 자막(subtitle) 데이터를 반환 받은 후 전처리 작업을 진행한다. 전처리 작업을 통해 유효한 키워드를 추출 하게 되며 추출된 키워드는 사전 학습된 언어 모델로 사용되는 딥러닝 모델인 BERT 모델에 입력 예제로 사용된 다. 이후 딥러닝 모델은 인플루언서의 전문분야 클래스 중 하나로 분류하여 백엔드에 반환해주고, 백엔드는 모 델로부터 반환 받은 결과값을 프론트엔드를 통해 클라이언트에게 반환해준다. 최종적으로 클라이언트는 입력한 YouTube URL에 대한 분석결과를 확인할 수 있게 된다. 도 3은 일 실시예에 따른 전처리 프로세스를 도시한 흐름도이다. 본 명세서에서 제안되는 프레임워크는 전처리과정에서 방대한 양의 자막 데이터를 다수의 핵심 키워드로 만드는 데, 이때 핵심 키워드의 데이터 양이 상당하다. 이는 전처리 과정이 까다롭기 때문인데, 전처리 작업은 자연어 처리에서 매우 중요하며 다양하기 때문에 그 중요성은 주목할 만하다. 전처리 작업이 중요한 가장 큰 이유는 아 무리 잘 학습된 BERT 모델이라도 전처리를 거치지 않은 데이터가 입력으로 들어간다면 제대로 된 분류를 할 수 없기 때문이다. 단어와 문장만으로 학습된 모델은 특수기호와 합성어 등 노이즈에 대한 학습이 이루어지지 않았 기 때문에 이러한 노이즈를 제거하기 위해서 전처리 과정을 거쳐야만 올바른 분류가 가능해진다. 노이즈는 언어 모델의 학습에 사용된 데이터가 아니어서 분류하는데 어려움을 주기 때문에 제거할수록 성능이 올라간다. YouTube API를 통해 수집한 자막 데이터는 일반적으로 수집한 제목, 해시 태그와 같은 메타 데이터보 다 용량이 크기 때문에 노이즈의 출현빈도도 높아지게 된다. 그 이유는 자막 데이터는 학습데이터로써 사용되지 않은 인플루언서 특유의 말버릇이나 합성어 유행어가 많이 포함 되어있을 확률이 높기 때문이다. 또한, 한국어 특유의 문법인 품사와 조사 등의 빈도도 매우 높기에 노이즈로 간주되어야 한다. 이러한 높은 빈도수의 노이즈 를 처리하면서 유의미한 단어만을 추출하기위해 빈도수가 가장 높지만, 노이즈가 아닌 키워드를 추출하는 필터 링 기능을 전처리 단계에 추가하였다. 도 3은 백엔드 내에서 동작하는 전처리 프로세스를 보여준다. 먼저, 백엔드는 클라이언트로부터 입력 받은 URL 정보에 해당하는 자막 데이터를 YouTube API를 통해 반환 받는다. 이후 상기 자막 데이터 내 감지된 자연어를 KoNLPy 한국어 형태소 라이브러리를 통해 품사 정보를 인식하고, 각 자연어에 해당하는 품사가 태깅(tagging)된 형태로 토큰화(tokenization)한 뒤, 품사가 태깅된 토큰들 중 유의미한 단어를 찾기 위해 태그가 명사인 토큰들 만을 수집한다. 수집한 명사 토큰들의 반복도를 측정하여 가장 높은 순서로 정렬한다. 도 3은 백엔드 내에서 동작하는 전처리 프로세스를 보여준다. 먼저, 백엔드는 클라이언트로부터 입력 받은 URL 정보에 해당하는 자막 데이터를 YouTube API를 통해 반환 받는다. 이후 상기 자막 데이터 내 감지된 자연어를 KoNLPy 한국어 형태소 라이브러리를 통해 품사 정보를 인식하고, 각 자연어에 해당하는 품사가 태깅(tagging)된 형태로 토큰화(tokenization) 한 뒤, 품사가 태깅된 토큰들 중 유의미한 단어를 찾기 위해 태그가 명사인 토큰 들만을 수집한다. 수집한 명사 토큰들의 반복도를 측정하여 가장 높은 순서로 정렬한다. 그 후, 본 프레임워크의 핵심인 금칙어 리스트로 정렬된 토큰들에 대한 금칙어 탐색이 이루어진다. 상기 금칙어 리스트는 높은 빈도수별로 정렬된 토큰들 중 학습된 언어 모델에 노이즈로써 판단되는 토큰들을 모아서 만든 독 자적인 딕셔너리이다. 이 때, 노이즈는 말버릇, 유행어 및 합성어 중 적어도 하나 이상의 비표준어적인 특성 및 의미가 없거나 독자적으로 의미를 가질 수 없는 특성을 지닌 자연어에 해당한다. 탐색이 이뤄졌을 때 금칙어 리 스트에 포함되어 있는 토큰은 반환되지 않고 금칙어 리스트에 포함되지 않은 토큰만이 반환되는데, 반환되는 토 큰들은 노이즈가 아니며 빈도수가 높은 토큰들이기 때문에 인플루언서가 컨텐츠에서 강조하는 내용과 직관됨으 로 이러한 토큰들이 최종적으로 유효 키워드로써 반환된다. 이러한 알고리즘으로 반환된 키워드들은 전문분야 분류를 위해 사전 학습된 언어 모델로서 사용되는 딥러닝 모델에 입력으로 사용된다. 이와 같은 방법으로 유튜 브 컨텐츠를 통해 신뢰성 있는 인플루언서의 전문 분야 분류가 가능해진다. 도 4a 내지 도 4b는 금칙어 리스트의 성능을 비교한 도면으로, 금칙어 리스트를 사용한 키워드 추출 성능 비교 를 위한 워드 클라우드이다. 화장품에 대한 광고를 진행하는 영상의 예시로 키워드를 추출했을 때, 금칙어 탐색을 하지 않은 결과가 도 4a이 고, 금칙어 탐색을 한 결과가 도 4b이다. 도 4a에서 보다시피 명사 토큰 중 가장 높은 빈도수의 키워드를 추출 했을 때 조사가 많은 것을 볼 수 있다. 하지만 도 4b에선 금칙어 리스트에 조사들이 포함되어 있기 때문에 핵심 적인 키워드가 가장 많이 언급되어 추출된 키워드들이 화장품에 대한 것이란 것을 유추할 수 있다. 이렇게 추출 한 유효 키워드는 딥러닝 모델에 입력 시 신뢰성 있는 결과 값을 얻을 수 있다. 도 5는 키워드 추출의 성능을 비교한 도면이다. 도 5는 유튜브 영상에서 추출한 제목과 영상만으로 학습된 모델의 입력 결과와 추출한 유효 키워드를 기반으로 추가 학습된 모델의 입력 결과의 성능차이를 보여준다. 실험에 사용된 영상은 화장품 검색어에 해당하는 영상이 다. 상단의 결과는 제목과 해시 태그를 추출하여 딥러닝 모델에 입력했을 때 결과이다. 기존의 인공지능을 활용 한 SNS 데이터 기반 인플루언서와 클라이언트 간 매칭 시스템의 알고리즘에 따라 제목과 해시 태그를 이용해서 유튜브 컨텐츠를 분석했을 때, 불필요한 단어들이 포함 되어있거나 해시 태그가 없는 경우도 있다. 이러한 경우, 아무리 많은 데이터로 학습된 모델일지라도 제대로 된 분류를 해낼 수가 없다. 도 5에서 나타난 분류 결 과가 기타로 나온 것을 확인할 수 있다. 이는 본 명세서의 모델이 분류할 수 없는 결과값의 경우 기타로 출력하 도록 디자인되었기 때문이다. 반면, 하단은 본 명세서의 프레임워크가 추출한 유효 키워드를 모델에 입력한 결 과이다. 유효 키워드를 추출했을 때, 인플루언서가 ‘컬러, 향, 비비, 브라운, 수분’ 등의 언급을 가장 많이 한 것을 확인할 수 있었다. 또한, 유효 키워드 집합들을 모델에 입력한 경우에 타겟으로 정한 화장품을 모델이 정확히 분류해낸 것을 확인할 수 있다. 도 6은 일 실시예에 따른 영상 분류 방법을 도시한 흐름도이다. S610 단계에서, 영상 분류 장치는, 영상의 음성 데이터로부터 추출된 자막 데이터를 입력받는다. S630 단계에서, 영상 분류 장치는, 제공된 상기 자막 데이터를 전처리하는 것으로 유효 키워드를 추출한다. 상 기 유효 키워드를 추출함에 있어서, 상기 자막 데이터 중 명사의 특성을 포함하는 자막 데이터를 토큰화하고, 각 토큰의 반복도에 기반하여 높은 빈도수대로 정렬하고, 정렬된 토큰을 금칙어 리스트를 통해 필터링함으로써 상기 정렬된 토큰 중 일부를 유효 키워드로서 반환할 수 있다. 이 때, 상기 금칙어 리스트는 기설정된 상기 금 칙어 리스트를 우회할 토큰의 개수에 따라 상기 정렬된 토큰을 탐색하여 영상 분류에 불필요한 노이즈에 해당하 는 토큰을 제거하고, 상기 노이즈에 해당하지 않는 토큰은 유효한 키워드로서 반환할 수 있다. S650 단계에서, 영상 분류 장치는, 상기 유효 키워드를 사전 학습된 언어 모델에 입력하여 상기 영상의 분류를 수행한다. 상기 사전 학습된 언어 모델은 상기 유효 키워드를 검증하기 위한 인공 지능 모델로서, 비선형력이 sigmoid 함수보다 상대적으로 강한 tanh() 함수를 사용하고, SNS 데이터 및 기설정된 개수의 카테고리별 영상을 학습 데이터로 사용하고, 입력된 상기 유효 키워드에 따라 logit을 출력할 수 있다. 상기 S650 단계의 상세한 설명은 이하의 도 7a 내지 7c를 통해 보충하겠다. 도 7a 내지 도 7c는 본 명세서의 금칙어 리스트를 구성하는 코드를 도시한 도면이다. 본 명세서는 인플루언서의 전문성 분류를 위해 자막 데이터에서 유효 키워드를 추출하는 전처리 기법을 사용하 고 있다. 본 명세서의 자체적인 금칙어 리스트는 핵심적인 키워드를 자막 데이터에서 추출하기 위해 설계되었다. 또한 금칙어 리스트의 검증을 위해 학습된 인공지능 모델을 이용했다. 추출한 키워드가 유의미한 키워드인지, 노이즈인지 검증을 위해 추출한 키워드를 학습된 인공지능 모델에 입력 예제로써 사용한다. 검증에 사용한 BERT 모델은 SNS 데이터로 학습되어 11개의 전문성을 분류하는 모델이다. 도 7a는 본 명세서에서 사용된 금칙어 리스트를 내장하고 있는 모델의 분류 코드이다. 학습된 BERT model에 입 력되는 데이터는 YouTube API를 통해 수신 받고, 전처리를 거친 자막 데이터의 키워드 토큰들이다. 상기 분류 코드는 BERT 모델로부터 출력된 logit 중 최대값을 반환 받아서 임계값(threshold)과 비교한다. BERT 모델로부 터 출력된 최대 logit이 만약 임계값보다 크다면 index에 해당하는 클래스를 반환하도록 설계되었다. 도 7b는 tanh() 활성화 함수를 사용하는 BERT 모델을 도시하고 있다. 머신 러닝에서 대게 sigmoid 활성 함수를 사용하지만 sigmoid 활성화 함수는 0 내지 1사이의 값만 출력하기에 기울기가 tanh 함수보다 가파르다. tanh() 함수는 -1 내지 1 사이의 공간이 더 넓으며 x좌표의 값이 커질수록 y좌표의 값이 1에 수렴한다. 즉 비선형력이 sigmoid 함수보다 강하다. 도 7c는 임계값을 5로 설정한 상기 모델의 분류 코드를 도시하고 있다. 상기 임계값을 5로 설정한 이유는 신뢰 성 있는 분류를 하기 위함이다. 도 7c는 5번째 index의 logit 값이 가장 크지만 신뢰성이 적어 기타로 분류된 모습이다. 이는 설정된 임계값 보다 작기 때문인데, 결국 임계값을 5로 설정한 이유는 결국 tanh 활성 함수에 적합한 최대값의 신뢰성 있는 출력을 위함이다. 본 명세서의 상기 모델은 상기 임계값을 기반으로 필터링하여 추가해서 만든 금칙어 리스트를 내장하고 있다. 상기 금칙어 리스트는 다음과 같은 과정으로 만들어졌다. 먼저, 11개의 카테고리별 광고영상을 20개씩 수집하여 순차적으로 상기 모델에 입력했다. API를 통해 유튜브 URL 정보를 입력하여 반환되는 자막 데이터는 전처리를 거친 후 명사만을 추출, 높은 빈도순대로 정렬된다. 이후 전처리를 거친 데이터를 금칙어 리스트를 통해 탐색이 수행되는 것으로 금칙어 리스트를 우회한 top N개가 상기 모델에 입력된다. 이 때, N의 값을 3으로 지정한다. 금칙어 리스트가 비어 있는 초기단계엔, 예를 들어 아, 어, 음 또는 이건 등과 같이 컨텐츠에 불필요한 노이즈 들이 키워드로 반환된다. 반환된 키워드들이 상기 모델에 입력되었을 때 상기 모델은 임계값보다 낮은 값의 잘 못된 클래스의 인덱스 logit을 반환했다. 즉 노이즈는 상기 모델의 출력값을 임계값보다 낮게 만든다. 임계값보 다 낮은 결과값을 만드는 상기 데이터이자 토큰들을 노이즈로 판단하고, top 1의 유효 키워드 토큰을 금칙어 리 스트에 추가한다. 새롭게 업데이트된 top 3 토큰들이 상기 모델에 입력으로 들어가며 이러한 과정을 상기 모델 의 출력값이 임계값을 넘어서는 경우까지 반복한다. 이와 같은 과정을 반복하여 만들어진 금칙어 리스트는 다양 한 인플루언서들의 말버릇과 노이즈들을 포함하고 있기에 키워드 추출 전 필터링 단계에서 노이즈들을 효과적으 로 제거하여 컨텐츠에 연관성이 높은 키워드만을 추출하게 된다. 입력예제로써 사용된 토큰들의 상기 모델 출력 값이 임계값보다 높다면 상기 토큰들은 노이즈의 집합인 금칙어 리스트를 우회한 핵심 키워드이며, 해당 키워드 를 입력받은 BERT 모델의 출력값은 해당 영상의 신뢰성 있는 분류 결과라고 할 수 있다. 즉, S650 단계에서, 상기 영상의 분류를 수행함에 있어 상기 유효 키워드를 상기 사전 학습된 언어 모델에 입력 함으로써 유효 키워드 별 logit을 출력하고, 상기 logit 중 최대값을 기설정된 임계값(threshold)과 비교하는 것으로 영상의 분류 결과를 출력하거나 상기 유효 키워드를 금칙어 리스트에 노이즈로서 반환하는 것 중 적어도 하나를 수행할 수 있다. 상기 영상의 분류 결과를 출력하는 것은 상기 언어 모델로부터 출력된 최대 logit이 상 기 임계값보다 크다면 상기 영상에 해당하는 상기 언어 모델 내 라벨링된 영상 분류 결과를 출력한다는 의미이 며, 상기 금칙어 리스트에 노이즈로서 반환하는 것은 상기 언어 모델로부터 출력된 최대 logit이 상기 임계값보 다 작다면 반환된 유효 키워드를 상기 금칙어 리스트에 재반환하여 노이즈로서 추가하고, 상기 언어 모델로부터 출력된 최대 logit이 임계값을 넘어서게 하는 임의의 유효 키워드를 추출할 때까지 상기 금칙어 리스트를 이용 하여 정렬된 토큰의 탐색을 반복한다는 의미이다. 도 8은 일 실시예에 따른 인플루언서 전문 분야 분류 장치를 도시한 블록도로서, 도 1의 일 실시예에 따른 유튜 브 영상 분류 방법, 이를 이용한 인플루언서 전문 분야 분류 방법을 하드웨어적 구성의 관점에서 재구성한 것이다. 따라서, 여기서는 설명의 중복을 피하고자 각 구성의 동작 및 기능의 개요만 약술하도록 한다. 통신부는, 클라이언트로부터 입력된 YouTube 컨텐츠의 URL 정보를 제공받는다. 처리부는, YouTube API를 이용하여 상기 URL 정보의 자막 데이터를 수집하고, 상기 자막 데이터를 기반으 로 유효 키워드를 추출하는 전처리 작업을 수행하고, 상기 유효 키워드를 사전 학습된 언어 모델에 입력하여 상기 URL 정보에 대응하는 YouTube 컨텐츠의 분류 결과를 출력한다. 상기 처리부는, 상기 자막 데이터를 토큰화하고, 금칙어 리스트를 이용하여 토큰화된 상기 자막 데이터를 필터링함으로써 상기 유효 키워드를 추출할 수 있다. 상기 처리부는, 말버릇, 유행어 및 합성어 중 적어도 하나 이상의 비표준어적인 특성 및 의미가 없거나 독 자적으로 의미를 가질 수 없는 특성을 지닌 자연어를 노이즈로서 금칙어 리스트 내에 저장하고, 상기 금칙어 리 스트를 참조하여 상기 금칙어 리스트를 우회할 토큰의 개수를 미리 설정하고, 설정된 상기 토큰의 개수에 따라 최빈도수로 정렬된 토큰을 탐색하는 것으로 영상 분류에 불필요한 상기 노이즈에 해당하는 토큰을 제거하거나, 상기 노이즈에 해당하지 않는 토큰을 유효한 키워드로서 반환할 수 있다. 상기 처리부는, 상기 전처리 작업을 통해 추출된 상기 유효 키워드를 상기 URL 정보의 전문 분야 분류를 위해 상기 언어 모델에 입력하고, 상기 언어 모델에 입력된 상기 유효 키워드를 상기 언어 모델 내 라벨링된 전 문 분야 중 하나로 분류하여 상기 URL 정보의 분류 결과를 출력할 수 있다. 상기 분류 결과에 따라 상기 YouTube 컨텐츠의 인플루언서 전문 분야를 설정하는 인플루언서 설정부를 더 포함할 수 있다. 상기 통신부, 처리부 및 인플루언서 설정부는 영상 분류 장치에 포함될 수 있다. 상기된 본 명세서의 실시예들에 따르면, 인플루언서가 업로드하는 유튜브 영상 분석을 위해 자막 데이터를 기반 으로 키워드를 추출하여 학습된 딥러닝 모델에 입력 예제로 사용함으로써 전문 분야를 분류하는 프레임워크를 제안하였다. 이 프레임워크는 금칙어 딕셔너리를 통한 핵심적인 키워드 추출이 가능하고, 추출한 키워드는 일반 적으로 제공되는 제목과 해시 태그 데이터보다 더 유의미함을 확인했다. 또한, STT 기반의 자막 데이터의 분석 이 가능해지는 것으로 신뢰성 있는 분류가 가능하다. 본 명세서에 따른 실시예는 다양한 수단, 예를 들어, 하드웨어, 펌웨어(firmware), 소프트웨어 또는 그것들의 결합 등에 의해 구현될 수 있다. 하드웨어에 의한 구현의 경우, 본 명세서의 일 실시예는 하나 또는 그 이상의 ASICs(application specific integrated circuits), DSPs(digital signal processors), DSPDs(digital signal processing devices), PLDs(programmable logic devices), FPGAs(field programmable gate arrays), 프로세서, 콘트롤러, 마이크로 콘트롤러, 마이크로 프로세서 등에 의해 구현될 수 있다. 펌웨어나 소프트웨어에 의한 구현의 경우, 본 명세서의 일 실시예는 이상에서 설명된 능력 또는 동작들을 수행하는 모듈, 절차, 함수 등의 형태로 구현될 수 있다. 소프트웨어 코드는 메모리에 저장되어 프로세서에 의해 구동될 수 있다. 상기 메 모리는 상기 프로세서 내부 또는 외부에 위치하여, 이미 공지된 다양한 수단에 의해 상기 프로세서와 데이터를 주고받을 수 있다. 한편, 본 명세서의 실시예들은 컴퓨터로 읽을 수 있는 기록 매체에 컴퓨터가 읽을 수 있는 코드로 구현하는 것 이 가능하다. 컴퓨터가 읽을 수 있는 기록 매체는 컴퓨터 시스템에 의하여 읽힐 수 있는 데이터가 저장되는 모 든 종류의 기록 장치를 포함한다. 컴퓨터가 읽을 수 있는 기록 매체의 예로는 ROM, RAM, CD-ROM, 자기 테이프, 플로피디스크, 광 데이터 저장장치 등을 포함한다. 또한, 컴퓨터가 읽을 수 있는 기록 매체는 네트워크로 연결 된 컴퓨터 시스템에 분산되어, 분산 방식으로 컴퓨터가 읽을 수 있는 코드가 저장되고 실행될 수 있다. 그리고 실시예들을 구현하기 위한 기능적인(functional) 프로그램, 코드 및 코드 세그먼트들은 본 명세서가 속하는 기 술 분야의 프로그래머들에 의하여 용이하게 추론될 수 있다. 이상에서 본 명세서에 대하여 그 다양한 실시예들을 중심으로 살펴보았다. 본 명세서에 속하는 기술 분야에서 통상의 지식을 가진 자는 다양한 실시예들이 본 명세서의 본질적인 특성에서 벗어나지 않는 범위에서 변형된 형 태로 구현될 수 있음을 이해할 수 있을 것이다. 그러므로 개시된 실시예들은 한정적인 관점이 아니라 설명적인 관점에서 고려되어야 한다. 본 명세서의 범위는 전술한 설명이 아니라 특허청구범위에 나타나 있으며, 그와 동 등한 범위 내에 있는 모든 차이점은 본 명세서에 포함된 것으로 해석되어야 할 것이다.도면 도면1 도면2 도면3 도면4a 도면4b 도면5 도면6 도면7a 도면7b 도면7c 도면8"}
{"patent_id": "10-2023-0122772", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 일 실시예에 따른 유튜브 영상 분류 방법, 이를 이용한 인플루언서 전문 분야 분류 방법을 도시한 흐름 도이다. 도 2는 유튜브 자막 데이터 분석 프레임워크를 도시한 흐름도이다. 도 3은 일 실시예에 따른 전처리 프로세스를 도시한 흐름도이다. 도 4a 내지 도 4b는 금칙어 리스트의 성능을 비교한 도면이다. 도 5는 키워드 추출의 성능을 비교한 도면이다. 도 6은 일 실시예에 따른 영상 분류 방법을 도시한 흐름도이다. 도 7a 내지 도 7c는 본 명세서의 금칙어 리스트를 구성하는 코드를 도시한 도면이다. 도 8은 일 실시예에 따른 인플루언서 전문 분야 분류 장치를 도시한 블록도이다."}
