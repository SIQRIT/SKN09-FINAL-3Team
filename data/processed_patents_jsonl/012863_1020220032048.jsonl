{"patent_id": "10-2022-0032048", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0134809", "출원번호": "10-2022-0032048", "발명의 명칭": "언어 모델 압축을 위한 언어 컨텍스트 지식 증류의 방법 및 그를 수행하는 컴퓨터 시스템", "출원인": "한국과학기술원", "발명자": "양은호"}}
{"patent_id": "10-2022-0032048", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "인공 신경망 모델에 지식 증류를 적용하는 컴퓨터 시스템의 방법에 있어서, 대규모 네트워크를 통해, 문장을 학습하는 단계; 및상기 대규모 네트워크와 지식 연결되는 복수의 소규모 네트워크들을 통해, 상기 대규모 네트워크로부터 전달되는 정보에 기반하여 학습하는 단계를 포함하고, 상기 정보는,상기 대규모 네트워크로부터 출력되는 단어 임베딩 벡터들의 분포를 기반으로 정의되는 컨텍스트 지식을 포함하는,컴퓨터 시스템의 방법."}
{"patent_id": "10-2022-0032048", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1 항에 있어서, 상기 컨텍스트 지식은, 상기 단어 임베딩 벡터들 사이의 거리 및 각도를 기반으로 결정되는, 컴퓨터 시스템의 방법."}
{"patent_id": "10-2022-0032048", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 1 항에 있어서, 상기 단어 임베딩 벡터들은,복수의 계층들로 분포되고, 상기 계층들의 각각에는, 상이한 단어들에 대한 단어 임베딩 벡터들이 배치되고, 상기 계층들에 걸쳐, 동일한 단어에 대한 단어 임베딩 벡터들이 배치되는,컴퓨터 시스템의 방법."}
{"patent_id": "10-2022-0032048", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 3 항에 있어서, 상기 컨텍스트 지식은,상기 계층들의 각각에서의 상기 상이한 단어들에 대한 단어 임베딩 벡터들 사이의 단어 관계를 포함하는,컴퓨터 시스템의 방법."}
{"patent_id": "10-2022-0032048", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "공개특허 10-2023-0134809-3-제 4 항에 있어서, 상기 계층들의 각각의 상기 상이한 단어들에 대한 단어 임베딩 벡터들 사이에서 페어들과 트리플들이 결정되고, 상기 단어 관계는,상기 페어들을 각각 구성하는 단어 임베딩 벡터들 사이의 거리들로 정의되는 페어-와이즈 관계와 상기 트리플들을 각각 구성하는 단어 임베딩 벡터들 사이의 각도들로 정의되는 트리플-와이즈 관계의 합으로 정의되는,컴퓨터 시스템의 방법."}
{"patent_id": "10-2022-0032048", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제 3 항에 있어서, 상기 컨텍스트 지식은,상기 계층들에 걸친 상기 동일한 단어에 대한 단어 임베딩 벡터들 사이의 계층 변환 관계를 포함하는,컴퓨터 시스템의 방법."}
{"patent_id": "10-2022-0032048", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제 6 항에 있어서, 상기 계층들에 걸쳐 상기 동일한 단어에 대한 단어 임베딩 벡터들 사이에서 페어들과 트리플들이 결정되고, 상기 계층 변환 관계는,상기 페어들을 각각 구성하는 단어 임베딩 벡터들 사이의 거리들로 정의되는 페어-와이즈 관계와 상기 트리플들을 각각 구성하는 단어 임베딩 벡터들 사이의 각도들로 정의되는 트리플-와이즈 관계의 합으로 정의되는,컴퓨터 시스템의 방법."}
{"patent_id": "10-2022-0032048", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제 3 항에 있어서, 상기 단어 임베딩 벡터들의 상기 계층들의 수는,상기 대규모 네트워크에서의 계층들의 수로 결정되고,상기 컨텍스트 지식은,상기 대규모 네트워크에서의 계층들의 수와 상기 소규모 네트워크들의 각각에서의 계층들의 수가 상이하면, 상기 단어 임베딩 벡터들의 상기 계층들의 수를 상기 소규모 네트워크들의 각각에서의 계층들의 수와 일치시키는,컴퓨터 시스템의 방법."}
{"patent_id": "10-2022-0032048", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제 5 항 또는 제 7 항에 있어서, 상기 페어-와이즈 관계 및 상기 트리플-와이즈 관계는,상기 대규모 네트워크와 상기 소규모 네트워크들 사이에서 일치되는,컴퓨터 시스템의 방법. 공개특허 10-2023-0134809-4-청구항 10 인공 신경망 모델에 지식 증류를 적용하는 컴퓨터 시스템에 있어서,메모리; 및상기 메모리와 연결되고, 상기 메모리에 저장된 적어도 하나의 명령을 실행하도록 구성되는 프로세서를 포함하고, 상기 프로세서는,문장을 학습하는 대규모 네트워크, 및 상기 대규모 네트워크와 지식 연결되고, 상기 대규모 네트워크로부터 전달되는 정보에 기반하여 학습하는 복수의 소규모 네트워크들을 포함하는 인공 신경망 모델을 포함하고, 상기 정보는, 상기 대규모 네트워크로부터 출력되는 단어 임베딩 벡터들의 분포를 기반으로 정의되는 컨텍스트 지식을 포함하는,컴퓨터 시스템."}
{"patent_id": "10-2022-0032048", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제 10 항에 있어서, 상기 프로세서는,상기 단어 임베딩 벡터들 사이의 거리 및 각도를 기반으로, 상기 컨텍스트 지식을 결정하도록 구성되는, 컴퓨터 시스템."}
{"patent_id": "10-2022-0032048", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제 10 항에 있어서, 상기 단어 임베딩 벡터들은,복수의 계층들로 분포되고, 상기 계층들의 각각에는, 상이한 단어들에 대한 단어 임베딩 벡터들이 배치되고, 상기 계층들에 걸쳐, 동일한 단어에 대한 단어 임베딩 벡터들이 배치되는,컴퓨터 시스템."}
{"patent_id": "10-2022-0032048", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제 12 항에 있어서, 상기 컨텍스트 지식은,상기 계층들의 각각에서의 상기 상이한 단어들에 대한 단어 임베딩 벡터들 사이의 단어 관계를 포함하는,컴퓨터 시스템."}
{"patent_id": "10-2022-0032048", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제 13 항에 있어서, 공개특허 10-2023-0134809-5-상기 프로세서는,상기 계층들의 각각의 상기 상이한 단어들에 대한 단어 임베딩 벡터들 사이에서 페어들과 트리플들을 결정하고, 상기 페어들을 각각 구성하는 단어 임베딩 벡터들 사이의 거리들로 정의되는 페어-와이즈 관계와 상기 트리플들을 각각 구성하는 단어 임베딩 벡터들 사이의 각도들로 정의되는 트리플-와이즈 관계의 합으로, 상기 단어 관계를 결정하도록 구성되는,컴퓨터 시스템."}
{"patent_id": "10-2022-0032048", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제 12 항에 있어서, 상기 컨텍스트 지식은,상기 계층들에 걸친 상기 동일한 단어에 대한 단어 임베딩 벡터들 사이의 계층 변환 관계를 포함하는,컴퓨터 시스템."}
{"patent_id": "10-2022-0032048", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제 15 항에 있어서, 상기 프로세서는,상기 계층들에 걸쳐 상기 동일한 단어에 대한 단어 임베딩 벡터들 사이에서 페어들과 트리플들을 결정하고, 상기 페어들을 각각 구성하는 단어 임베딩 벡터들 사이의 거리들로 정의되는 페어-와이즈 관계와 상기 트리플들을 각각 구성하는 단어 임베딩 벡터들 사이의 각도들로 정의되는 트리플-와이즈 관계의 합으로, 상기 계층 변환관계를 결정하도록 구성되는,컴퓨터 시스템."}
{"patent_id": "10-2022-0032048", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제 12 항에 있어서, 상기 단어 임베딩 벡터들의 상기 계층들의 수는,상기 대규모 네트워크에서의 계층들의 수로 결정되고,상기 컨텍스트 지식은,상기 대규모 네트워크에서의 계층들의 수와 상기 소규모 네트워크들의 각각에서의 계층들의 수가 상이하면, 상기 단어 임베딩 벡터들의 상기 계층들의 수를 상기 소규모 네트워크들의 각각에서의 계층들의 수와 일치시키는,컴퓨터 시스템."}
{"patent_id": "10-2022-0032048", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제 14 항 또는 제 16 항에 있어서,상기 페어-와이즈 관계 및 상기 트리플-와이즈 관계는,상기 대규모 네트워크와 상기 소규모 네트워크들 사이에서 일치되는,공개특허 10-2023-0134809-6-컴퓨터 시스템."}
{"patent_id": "10-2022-0032048", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "인공 신경망 모델에 지식 증류를 적용하는 방법을 컴퓨터 시스템에 실행시키기 위한 하나 이상의 프로그램을 저장하는 비-일시적인 컴퓨터 판독 가능한 기록 매체에 있어서,상기 방법은,대규모 네트워크를 통해, 문장을 학습하는 단계; 및상기 대규모 네트워크와 지식 연결되는 복수의 소규모 네트워크들을 통해, 상기 대규모 네트워크로부터 전달되는 정보에 기반하여 학습하는 단계를 포함하고, 상기 정보는,상기 대규모 네트워크로부터 출력되는 단어 임베딩 벡터들의 분포를 기반으로 정의되는 컨텍스트 지식을 포함하는,비-일시적인 컴퓨터 판독 가능한 기록 매체."}
{"patent_id": "10-2022-0032048", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제 19 항에 있어서,상기 컨텍스트 지식은, 상기 단어 임베딩 벡터들 사이의 거리 및 각도를 기반으로 결정되는, 비-일시적인 컴퓨터 판독 가능한 기록 매체."}
{"patent_id": "10-2022-0032048", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 개시는 언어 모델 압축을 위한 언어 컨텍스트 지식 증류의 방법 및 그를 수행하는 컴퓨터 시스템에 관한 것으 로, 대규모 네트워크를 통해, 문장을 학습하고, 대규모 네트워크와 지식 연결되는 복수의 소규모 네트워크들을 통해, 대규모 네트워크로부터 전달되는 정보에 기반하여 학습하도록 구성되며, 정보는 대규모 네트워크로부터 출 력되는 단어 임베딩 벡터들의 분포를 기반으로 정의되는 컨텍스트 지식을 포함할 수 있다."}
{"patent_id": "10-2022-0032048", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 언어 모델 압축을 위한 언어 컨텍스트 지식 증류의 방법 및 그를 수행하는 컴퓨터 시스템에 관한 것 이다."}
{"patent_id": "10-2022-0032048", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "최근 자연어 처리(natural language processing; NLP) 분야에서 뛰어난 성능을 보이는 다양한 네트워크 아키텍 처들이 등장하며, 인공 신경망 모델들이 요구하는 연산량과 그에 필요한 메모리의 규모가 커지고 있다. 하지만, IoT(internet of things) 센서, 모바일 디바이스와 같은 연산량이 제한된 환경에서는 이러한 모델들을 직접적으 로 활용하기 어렵다. 이에 따라, 기존의 학습된 모델의 정확도를 유지하면서, 보다 크기가 작고, 연산량과 파라 미터들의 수가 적은 네트워크를 학습하는 네트워크 압축 연구가 활발히 요구되고 있다."}
{"patent_id": "10-2022-0032048", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 개시는 인공 신경망 모델의 대표적인 압축 방식인 지식 증류(knowledge distillation)를 이용하여 모델 파라 미터들의 수가 적은 환경에서 일반화(generalization) 성능 보장을 위한 방법 및 그를 수행하는 컴퓨터 시스템 을 제공한다."}
{"patent_id": "10-2022-0032048", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 개시는 언어 모델 압축을 위한 언어 컨텍스트 지식 증류의 방법 및 그를 수행하는 컴퓨터 시스템을 제공한다. 본 개시에 따른 컴퓨터 시스템의 방법은, 대규모 네트워크를 통해, 문장을 학습하는 단계, 및 상기 대규모 네트 워크와 지식 연결되는 복수의 소규모 네트워크들을 통해, 상기 대규모 네트워크로부터 전달되는 정보에 기반하 여 학습하는 단계를 포함하고, 상기 정보는 상기 대규모 네트워크로부터 출력되는 단어 임베딩 벡터들의 분포를 기반으로 정의되는 컨텍스트 지식을 포함할 수 있다. 본 개시에 따른 컴퓨터 시스템은, 메모리, 및 상기 메모리와 연결되고, 상기 메모리에 저장된 적어도 하나의 명 령을 실행하도록 구성되는 프로세서를 포함하고, 상기 프로세서는, 문장을 학습하는 대규모 네트워크, 및 상기 대규모 네트워크와 지식 연결되고, 상기 대규모 네트워크로부터 전달되는 정보에 기반하여 학습하는 복수의 소 규모 네트워크들을 포함하는 인공 신경망 모델을 포함하고, 상기 정보는, 상기 대규모 네트워크로부터 출력되는 단어 임베딩 벡터들의 분포를 기반으로 정의되는 컨텍스트 지식을 포함할 수 있다."}
{"patent_id": "10-2022-0032048", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 개시는 컨텍스트 지식 증류를 이용하여, 높은 정확도를 유지하면서도 연산량과 파라미터들의 수가 적은 네트 워크를 통해 학습할 수 있다. 따라서, 본 개시는 네트워크의 사이즈 또는 추론 시간을 줄임과 동시에 정확한 서 비스를 제공할 수 있다. 이는, 학문적인 의의뿐만 아니라, 모바일과 같은 환경에의 적용을 통해, 사용자들에게 다수의 태스크(컴퓨터 비전, 자연 언어 처리 등)들에서 정확하고 간편한 서비스가 제공될 수 있게 하며, 언어 처리를 활용하는 다양한 서비스를 제공하도록 활용될 수 있다."}
{"patent_id": "10-2022-0032048", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 본 개시의 다양한 실시예들이 첨부된 도면을 참조하여 설명된다. 직관적으로, 각 단어 표현(word representation)은 각각의 지식(knowledge)을 가지고 있지만, 임베딩 공간 (embedding space)의 단어(word)들은 상대적으로 학습(learning)에 의해 배치되기 때문에 단어들 전체의 표현들 의 집합은 의미론적으로 더 의미가 있다. 이러한 관찰에서 영감을 받아, 본 개시는 단어 표현들 사이의 관계들 의 통계를 활용하는 언어 작업들에 대해, 컨텍스트 지식 증류(contextual knowledge distillation; CKD)라는 새로운 증류 목표를 제안한다. 본 개시에서, 두 가지 유형들의 컨텍스트 지식, 즉 단어 관계(word-relation; WR) 및 계층 변환 관계(layer transforming relation; LTR)가 정의된다. 구체적으로, 단어 관계는 단어 표현들 사이의 관계들에 대한 지식을 포착하기 위해 제안되며, 계층 변환 관계는 각 단어 표현이 네트워크 계층 (network layer)들을 통과할 때 어떻게 변화하는 지를 정의한다. 요컨대, 본 개시는 다음의 세 가지로 정리된다. 신경망들의 단어 표현들이 구조화된다는 최근의 관찰들에서 영감을 받아, 단어 표현들 전반에 걸친 관계들을 전달하는 새로운 지식 증류 전략인 컨텍스트 지식 증류를 제안 한다. 본 개시는 두 가지 유형들의 보완적인 컨텍스트 지식 유형, 즉 단일 계층의 단어 표현들에 걸친 수평 적인 단어 관계, 및 동일한 단어에 대한 단어 표현들에 걸친 수직적인 계층 변환 관계를 제시한다. 본 개시 는 표준 언어 이해 벤치마크 데이터셋들에 대해 컨텍스트 지식 증류를 검증하고, 컨텍스트 지식 증류가 기존 증 류 방식들 능가할 뿐만 아니라 적응형 프루닝(pruning) 방법의 성능을 향상시킨다는 것을 보여준다. 컨텍스트 지식 증류 본 개시는 단어 표현들의 분포를 기반으로 정의되는 구조적 또는 컨텍스트 지식을 전달하는 증류 목표로서, 컨 텍스트 지식 증류를 제시한다. 각 단어를 별도로 증류하는 이전 방법과 달리, 본 개시의 컨텍스트 지식 증류는 단어들 간 또는 계층들 간 관계들에 포함된 정보를 전송하고, 표현들을 직접 일치시키는 것보다 더 유연한 임베딩 공간 구성 방식을 제공한다. 도 1은 본 개시에 따른 컨텍스트 지식 증류를 설명하기 위한 도면이다. 여기서, 교사-학생 프레임워크(teacher- student framework)를 예로 들어 도시하였으나, 이에 제한되지 않는다. 도 2는 본 개시에 따른 단어 관계 기반 컨텍스트 지식 증류 및 계층 변환 관계 기반 컨텍스트 지식 증류를 설명하기 위한 도면이다. 도 1을 참조하면, 인공 신경망 모델은 대규모 네트워크(예컨대, 교사 네트워크) 및 복수의 소규모 네트워크(예 컨대, 학생 네트워크)들을 포함하고, 대규모 네트워크와 소규모 네트워크들 사이에는 지식 연결(knowledge connection)이 설정되어 있을 수 있다. 대규모 네트워크는 복수의 단어들(we, totally, agree …)로 이루어지는 문장(예: We totally agree …)을 학습하고, 소규모 네트워크들의 각각은 대규모 네트워크로부터 전달되는 정보 에 기반하여 학습할 수 있다. 정보는, 대규모 네트워크로부터 출력되는 단어 임베딩 벡터(이하에서, 단어 표현 으로도 지칭됨)들의 분포를 기반으로 정의되는 컨텍스트 지식을 포함한다. 도 1 및 도 2에 도시된 바와 같이, 단어 임베딩 벡터들은 복수의 계층들로 분포될 수 있다. 각 계층에는 상이한 단어들에 대한 단어 표현들이 배치 되며, 이로써, 각 계층 내에서 수평적인 단어 관계가 정의된다. 동일한 단어에 대한 단어 표현들이 복수의 계층 들에 걸쳐 배치되며, 이로써, 동일한 단어에 대해 복수의 계층들에 걸친 수직적인 계층 변환 관계가 정의된다. 단어 관계 기반 컨텍스트 지식 증류 신경망들이 단어들 간 컨텍스트 관계들를 성공적으로 포착할 수 있음을 시사하는 이전 연구에서 영감을 받아, 도 2에 도시된 바와 같이, 단어 관계 기반 컨텍스트 지식 증류는 특정 계층의 단어들 간 관계들에 포함된 컨텍 스트 지식을 증류하는 것을 목표로 한다. 단어들의 \"관계\"는 다양한 방식들로 정의될 수 있다. 본 개시는 그것 을 페어-와이즈(pair-wise) 또는 트리플-와이즈(triple-wise) 관계들의 합으로 정의하는 데 초점을 맞춘다. 구 체적으로, n 개의 단어들이 있는 각 입력 X에 대해, 언어 모델(예: 대규모 네트워크(이하에서, 교사 네트워크로 도 지칭됨) 또는 소규모 네트워크(이하에서, 학생 네트워크로도 지칭됨)일 수 있음)에서 계층 l에, 단어 표현들, 즉 Rl = [rl,1, …, rl,n]이 있다. 그리고, 단어 관계 기반 컨텍스트 지식 증류의 목적은 하기 [수학식 1]과 같은 손실 함수를 최소화하는 것이다. 수학식 1"}
{"patent_id": "10-2022-0032048", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "여기서, χ = {1, …, n}이다. 함수 φ 및 ψ는 페어-와이즈 및 트리플-와이즈 관계들을 각각 정의하며, λWR은 두 손실 함수들의 스케일을 조정한다. 이 때, 명확성을 위해 계층 인덱스 l의 표현을 억제하지만, 전체 네트워 크에 대한 증류 손실은 모든 계층들에 대해 간단히 합산된다. 상기 [수학식 1]의 모든 항들이 컨텍스트 지식을 정의하는 데 동일하게 중요한 것은 아니기 때문에, 본 개시는 가중치 값들 wij와 wijk를 도입하여 페어-와이즈 항 과 트리플-와이즈 항이 얼마나 중요한 지에 대한 가중치를 제어한다. 이러한 가중치 값들의 결정은 구현의 결정 문제로 여러 방향으로 열려 있지만, 관련 단어들 간의 관계에만 초점을 맞추기 위해, 단어들의 로컬리티 (locality)(즉, |i - j| ≤ δ이면, wij = 1, 아니면 wij = 0), 또는 어텐션 정보(attention information) A에 의해, 결정될 수 있다. 본 개시에서는 단어들의 로컬리티를 가중치 값들로 사용한다. 페어-와이즈 및 트리플-와이즈 관계를 정의하는 함수들 φ 및 ψ도 다양한 가능성을 가지고 있지만, 가장 간단 한 선택은 페어-와이즈 함수 φ의 경우 두 단어들 사이의 거리(distance)를 사용하고, 및 트리플-와이즈 함수 ψ의 경우 세 단어들 사이의 각도(angle)를 사용하는 것이다. 거리를 통한 페어-와이즈 함수 φ. 동일한 층에서 한 페어의 단어 표현들 (ri, rj)가 주어지면, φ(ri, rj)는 코 사인 거리(cosine distance), 즉 cos(ri, rj) 또는 l2 거리, 즉 ∥ri - rj∥2로 정의될 수 있다. 각도를 통한 트리플-와이즈 함수 ψ. 트리플-와이즈 관계는 고차 구조를 포착하고, 컨텍스트 지식을 구성하는 데 있어 더 많은 유연성을 제공한다. ψ의 가장 간단한 형태들 중 하나는 하기 [수학식 2]와 같이 계산되는 각 도이다. 수학식 2"}
{"patent_id": "10-2022-0032048", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "여기서 <·, ·>는 두 벡터들 사이의 내적을 나타낸다. 간단한 형태에도 불구하고, n 개의 단어 중 가능한 모든 트리플들에 대해 상기 [수학식 2]의 각도들을 효율적으 로 계산하려면 (n, n, dr) 텐서(tensor)에 모든 상대적 표현들 (ri - rj)을 저장해야 한다. 이로 인해, O(n2dr) 의 추가 메모리 비용이 발생한다. 이 경우, 상기 [수학식 1]의 wijk에 대한 로컬리티를 사용하는 것이 도움이 될 수 있다. 구체적으로, rj로부터 δ의 거리 내의 트리플들만을 고려함으로써, 효율적인 연산에 필요한 추가 메모 리 공간은 O(δndr)이며, 이는 δ ≪ n에 유리하다. 이는 또한 트리플-와이즈 관계 연산의 연산 복잡성을 O(n3dr)에서 O(δ2ndr)로 줄인다. 계층 변환 관계 기반 컨텍스트 지식 증류 계층 변환 관계는 \"각 단어가 계층들을 통과할 때 어떻게 변환되는가\"에 관한 것이다. 트랜스포머 기반 언어 모 델들은 동일한 계층들로 구성된 스택으로 구성되므로, 상위 계층에서 더 추상적인 개념으로, 각 계층에 하나씩, 각 단어에 대한 표현들의 집합을 생성한다. 따라서, 도 2에 도시된 바와 같이, 계층 변환 관계 기반 컨텍스트 지식 증류는 각 단어가 계층들 내에서 보다 추상적인 개념으로 발전하는 방법에 대한 지식을 증류하는 것을 목 표로 한다. 이를 위해, L 개의 계층들에서 단일 단어에 대한 표현들의 집합, 예컨대, 학생의 경우 및 교사 네트워크의 경우 (여기서, {1, …, L}은 반 드시 학생 네트워크 또는 교사 네트워크의 전체 계층들은 아님. 이것은 정렬 전략에서 정의되는 계층들의 인덱 스 집합임. 이 때, 아래의 단어 인덱스의 표현을 억제할 것임.) 계층 변환 관계 기반 컨텍스트 지식 증류의 목 표는 하기 [수학식 3]과 같은 손실 함수를 최소화하는 것이다. 수학식 3"}
{"patent_id": "10-2022-0032048", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "여기서, ρ = {1, …, L}이고, λLTR은 두 손실 함수들의 스케일을 조절한다. 이 때, 상기 [수학식 3]의 구성은 상기 [수학식 1]과 동일하지만, 관계들이 포착되는 대상들만이 한 계층에서의 단어 표현들에서 계층들에서의 단 일 단어에 대한 표현들로 변경되었다. 즉, 상이한 계층들에 있는 단어에 대한 표현들 사이의 관계들은 상기 [수 학식 2]에서처럼 거리 또는 각도로 정의될 수 있다: 또는 , 및 . 정렬 전략. 교사 네트워크와 학생 네트워크의 계층들 수가 다를 때, 학생의 어느 계층이 교사 네트워크의 어느 계층에서 정보를 학습하는지 파악하는 것이 중요하다. 이전 연구들은 균일한(즉, 스킵(skip)) 전략을 통해 이 정렬 이슈를 해결하고, 그 효과를 실험적으로 입증했다. Lt-계층의 교사 네트워크와 Ls-계층의 학생 네트워크의 경우, 계층 일치 함수(layer matching function) f는 하기 [수학식 4]와 같이 정의된다. 수학식 4"}
{"patent_id": "10-2022-0032048", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "여기서, g는 Lt와 Ls의 최대 공약수이고, stept = Lt/g이며, steps = Ls/g이다. 전반적인 학습 목표. 증류 목표는 교사 네트워크의 지식을 바탕으로 학생 네트워크의 학습을 돕는 것이 목적이 다. 여러 지식 증류 손실 함수들은 훈련(training) 중에 단독으로 또는 함께 사용될 수 있다. 본 개시는 제안된 컨텍스트 지식 증류를 클래스 확률 매칭(class probability matching)과 추가로 결합한다. 이 경우, 전반적인 손실 함수는 하기 [수학식 5]와 같다. 수학식 5"}
{"patent_id": "10-2022-0032048", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "여기서 λCKD는 손실 항들의 균형을 맞추기 위한 조정 가능한 파라미터이다. 증류 목표들의 구조적 제약 조건들 일반적으로 사용되는 기존의 지식 증류 목표들은 어텐션 매트릭스들 또는 단어 표현들과 같이 교사 및 학생 네 트워크들의 일부와 직접 일치하기 때문에 학생 네트워크들을 설계하는 데 제약이 따른다. 예를 들어, 일부 이전 연구들은 코사인 유사성 를 사용하여 각 단어 표현과 독립적으로 일치하므로, 학 생 네트워크의 임베딩 크기는 주어진 교사 네트워크의 임베딩 크기를 따라야 한다. 마찬가지로, 다른 이전 연구 는 을 통해 어텐션 매트릭스를 일치시킴으로써 지식을 증류한다. 따라서, 본 개시는 교사 및 학생 네트워크들에 대해 동일한 수의 어텐션 헤드들을 가져야 한다. 본 개시의 컨텍스트 지식 증류 방식은 컨텍스트 정보를 증류할 수 있다는 장점 외에도 기존 지식 증류 방식에 나타나는 제약 없이 학생 네트워크 구조를 보다 자유롭게 선택할 수 있다는 장점이 있다. 이는 컨텍스트 지식 증류가 상기 [수학식 1]과 같이 임의의 네트워크들(학생 및 교사)에서 단어들의 페어-와이즈 또는 트리플-와이 즈 관계들을 일치시키기 때문에, 구조의 직접적인 영향을 받지 않고 항상 동일한 차원의 정보를 일치시킬 수 있 다. 이러한 장점 덕분에 컨텍스트 지식 증류가 학습 단계에서 유연한 아키텍처 변경을 수반하는 최근 제안된 다 른 네트워크 압축 기술의 성능을 더욱 향상시킬 수 있다. 실험 본 개시의 컨텍스트 지식 증류 방식의 성능을 확인하기 위해, 실험이 진행되었다. 이러한 실험에서, 표준 언어 이해 벤치마크 데이터셋들로서, GLUE 및 SQuAD가 사용되었다. 구체적으로, 동일한 데이터셋들을 사용하여, 본 개시의 컨텍스트 지식 증류 방식과 기존 증류 방식들의 성능들을 검증하였다. 그 결과, 본 개시의 컨텍스트 지 식 증류 방식의 성능은 GLUE 및 SQuAD에 대해 약 82.4 %(평균 값) 및 약 81.8 %(EM)에 도달하였으며, 이는 기존 의 증류 방식들의 성능들에 비해 약 +0.7 % 및 약 +2.1 %만큼 향상됨을 나타낸다. 즉, 본 개시의 컨텍스트 증류 방식은 기존의 증류 방식들을 능가할 뿐만 아니라, 적응형 프루닝 방법의 성능을 향상시킬 수 있다. 도 3은 본 개시의 다양한 실시예들에 따른 컴퓨터 시스템의 구성을 개략적으로 도시하는 도면이다. 도 3을 참조하면, 다양한 실시예들은 스마트폰 데이터 기반 지능형 스트레스 예측 및 관리를 위한 컴퓨터 시스 템을 제공한다. 컴퓨터 시스템은 입력 모듈, 출력 모듈, 메모리, 또는 프로세서 중 적어도 하나를 포함할 수 있다. 어떤 실시예들에서, 컴퓨터 시스템의 구성 요소들 중 적어도 하나가 생 략될 수 있으며, 적어도 하나의 다른 구성 요소가 추가될 수 있다. 어떤 실시예들에서, 컴퓨터 시스템의 구성 요소들 중 적어도 두 개가 하나의 통합된 회로로 구현될 수 있다. 이 때, 컴퓨터 시스템의 구성 요소 들은 단일 장치로 구현될 수 있으며, 적어도 두 개의 개별 장치들로 나뉘어 구현될 수도 있다. 입력 모듈은 컴퓨터 시스템의 적어도 하나의 구성 요소에 사용될 신호를 입력할 수 있다. 입력 모듈 은, 컴퓨터 시스템에 직접적으로 신호를 입력하도록 구성되는 입력 장치, 주변의 변화를 감지하여 신 호를 발생하도록 구성되는 센서 장치, 또는 외부 기기로부터 신호를 수신하도록 구성되는 수신 장치 중 적어도 하나를 포함할 수 있다. 예를 들면, 입력 장치는 카메라 모듈, 마이크로폰(microphone), 마우스(mouse) 또는 키 보드(keyboard) 중 적어도 하나를 포함할 수 있다. 어떤 실시예에서, 센서 장치는 터치를 감지하도록 설정된 터 치 회로(touch circuitry) 또는 터치에 의해 발생되는 힘의 세기를 측정하도록 설정된 센서 회로 중 적어도 하 나를 포함할 수 있다. 출력 모듈은 컴퓨터 시스템의 외부로 정보를 출력할 수 있다. 출력 모듈은, 정보를 시각적으로 출력하도록 구성되는 표시 장치, 정보를 오디오 신호로 출력할 수 있는 오디오 출력 장치, 또는 정보를 무선으 로 송신할 수 있는 송신 장치 중 적어도 하나를 포함할 수 있다. 예를 들면, 표시 장치는 디스플레이, 홀로그램 장치 또는 프로젝터 중 적어도 하나를 포함할 수 있다. 일 예로, 표시 장치는 입력 모듈의 터치 회로 또는 센서 회로 중 적어도 하나와 조립되어, 터치 스크린으로 구현될 수 있다. 예를 들면, 오디오 출력 장치는 스피 커 또는 리시버 중 적어도 하나를 포함할 수 있다. 일부 실시예들에 따르면, 수신 장치와 송신 장치는 통신 모듈로 구현될 수 있다. 통신 모듈은 컴퓨터 시스템 에서 외부 기기와 통신을 수행할 수 있다. 통신 모듈은 컴퓨터 시스템과 외부 기기 간 통신 채널을 수립하고, 통신 채널을 통해, 외부 기기와 통신을 수행할 수 있다. 여기서, 외부 기기는 위성, 기지국, 서버 또 는 다른 컴퓨터 시스템 중 적어도 하나를 포함할 수 있다. 통신 모듈은 유선 통신 모듈 또는 무선 통신 모듈 중 적어도 하나를 포함할 수 있다. 유선 통신 모듈은 외부 기기와 유선으로 연결되어, 유선으로 통신할 수 있다. 무선 통신 모듈은 근거리 통신 모듈 또는 원거리 통신 모듈 중 적어도 하나를 포함할 수 있다. 근거리 통신 모 듈은 외부 기기와 근거리 통신 방식으로 통신할 수 있다. 예를 들면, 근거리 통신 방식은, 블루투스 (Bluetooth), 와이파이 다이렉트(WiFi direct), 또는 적외선 통신(IrDA; infrared data association) 중 적어 도 하나를 포함할 수 있다. 원거리 통신 모듈은 외부 기기와 원거리 통신 방식으로 통신할 수 있다. 여기서, 원 거리 통신 모듈은 네트워크를 통해 외부 기기와 통신할 수 있다. 예를 들면, 네트워크는 셀룰러 네트워크, 인터 넷, 또는 LAN(local area network)이나 WAN(wide area network)과 같은 컴퓨터 네트워크 중 적어도 하나를 포 함할 수 있다. 메모리는 컴퓨터 시스템의 적어도 하나의 구성 요소에 의해 사용되는 다양한 데이터를 저장할 수 있 다. 예를 들면, 메모리는 휘발성 메모리 또는 비휘발성 메모리 중 적어도 하나를 포함할 수 있다. 데이터 는 적어도 하나의 프로그램 및 이와 관련된 입력 데이터 또는 출력 데이터를 포함할 수 있다. 프로그램은 메모 리에 적어도 하나의 명령을 포함하는 소프트웨어로서 저장될 수 있으며, 운영 체제, 미들 웨어 또는 어플 리케이션 중 적어도 하나를 포함할 수 있다. 프로세서는 메모리의 프로그램을 실행하여, 컴퓨터 시스템의 적어도 하나의 구성 요소를 제어할 수 있다. 이를 통해, 프로세서는 데이터 처리 또는 연산을 수행할 수 있다. 이 때, 프로세서는 메모 리에 저장된 명령을 실행할 수 있다. 다양한 실시예들에 따르면, 프로세서는 인공 신경망 모델을 포함할 수 있다. 인공 신경망 모델 은 대규모 네트워크 및 복수의 소규모 네트워크들을 포함하고, 대규모 네트워크와 소규모 네트워크들 사이에는 지식 연결이 설정되어 있을 수 있다. 대규모 네트워크는 복수의 단어들로 이루어지는 문장을 학습하고, 소규모 네트워크들의 각각은 대규모 네트워크로부터 전달되는 정보에 기반하여 학습할 수 있다. 다양한 실시예들에 따르면, 정보는, 대규모 네트워크로부터 출력되는 단어 임베딩 벡터들의 분포를 기반으로 정 의되는 컨텍스트 지식을 포함할 수 있다. 단어 임베딩 벡터들은 복수의 계층들로 분포될 수 있다. 여기서, 계층 들의 각각에는, 상이한 단어들에 대한 단어 임베딩 벡터들이 수평으로 배치되고, 계층들에 걸쳐, 동일한 단어에 대한 단어 임베딩 벡터들이 수직으로 배치될 수 있다. 이 때, 프로세서는 단어 임베딩 벡터들 사이의 거리 및 각도를 기반으로, 컨텍스트 지식을 결정할 수 있다. 일 실시예에 따르면, 컨텍스트 지식은 계층들의 각각에서의 상이한 단어들에 대한 단어 임베딩 벡터들 사이의 수평적 단어 관계를 포함할 수 있다. 이러한 경우, 계층들의 각각의 상이한 단어들에 대한 단어 임베딩 벡터들 사이에서, 페어들과 트리플들이 결정될 수 있다. 그리고, 프로세서는 페어들을 각각 구성하는 단어 임베딩 벡터들 사이의 거리들로 정의되는 페어-와이즈 관계와 트리플들을 각각 구성하는 단어 임베딩 벡터들 사이의 각 도들로 정의되는 트리플-와이즈 관계의 합으로, 단어 관계를 결정할 수 있다. 다른 실시예에 따르면, 컨텍스트 지식은 계층들에 걸친 동일한 단어에 대한 단어 임베딩 벡터들 사이의 수직적 계층 변환 관계를 포함할 수 있다. 이러한 경우, 계층들에 걸쳐 상기 동일한 단어에 대한 단어 임베딩 벡터들 사이에서, 페어들과 트리플들이 결정될 수 있다. 그리고, 프로세서는 페어들을 각각 구성하는 단어 임베딩 벡터들 사이의 거리들로 정의되는 페어-와이즈 관계와 트리플들을 각각 구성하는 단어 임베딩 벡터들 사이의 각 도들로 정의되는 트리플-와이즈 관계의 합으로, 계층 변환 관계를 결정할 수 있다. 다양한 실시예들에 따르면, 대규모 네트워크에서의 계층들의 수와 소규모 네트워크들의 각각에서의 계층들의 수 는 동일하거나 상이할 수 있다. 그리고, 단어 임베딩 벡터들의 계층들의 수는 대규모 네트워크에서의 계층들의 수로 결정될 수 있다. 이 때, 대규모 네트워크에서의 계층들의 수와 소규모 네트워크들의 각각에서의 계층들의 수가 상이한 경우, 컨텍스트 지식은 단어 임베딩 벡터들의 계층들의 수를 소규모 네트워크들의 각각에서의 계층 들의 수와 일치시킬 수 있다. 다양한 실시예들에 따르면, 페어-와이즈 관계 및 트리플-와이즈 관계는, 대규모 네트워크와 소규모 네트워크들 사이에서 일치될 수 있다. 도 4는 본 개시의 다양한 실시예들에 따른 컴퓨터 시스템의 방법을 개략적으로 도시하는 도면이다. 도 4를 참조하면, 컴퓨터 시스템은 210 단계에서, 대규모 네트워크를 통해, 문장을 학습할 수 있다. 프로 세서는 인공 신경망 모델을 포함할 수 있다. 인공 신경망 모델은 대규모 네트워크 및 복수의 소 규모 네트워크들을 포함하고, 대규모 네트워크와 소규모 네트워크들 사이에는 지식 연결이 설정되어 있을 수 있 다. 이러한 대규모 네트워크가 복수의 단어들로 이루어지는 문장을 학습하고, 이를 통해, 대규모 네트워크로부 터, 복수의 단어 임베딩 벡터들이 출력될 수 있다. 다음으로, 컴퓨터 시스템은 220 단계에서, 대규모 네트워크로부터의 단어 임베딩 벡터들의 분포를 기반으 로 정의되는 컨텍스트 지식을 소규모 네트워크들로 전달할 수 있다. 단어 임베딩 벡터들은 복수의 계층들로 분 포될 수 있다. 여기서, 계층들의 각각에는, 상이한 단어들에 대한 단어 임베딩 벡터들이 수평으로 배치되고, 계 층들에 걸쳐, 동일한 단어에 대한 단어 임베딩 벡터들이 수직으로 배치될 수 있다. 이 때, 프로세서는 단 어 임베딩 벡터들 사이의 거리 및 각도를 기반으로, 컨텍스트 지식을 결정할 수 있다. 일 실시예에 따르면, 컨텍스트 지식은 계층들의 각각에서의 상이한 단어들에 대한 단어 임베딩 벡터들 사이의 수평적 단어 관계를 포함할 수 있다. 이러한 경우, 계층들의 각각의 상이한 단어들에 대한 단어 임베딩 벡터들 사이에서, 페어들과 트리플들이 결정될 수 있다. 그리고, 단어 관계는 페어들을 각각 구성하는 단어 임베딩 벡 터들 사이의 거리들로 정의되는 페어-와이즈 관계와 트리플들을 각각 구성하는 단어 임베딩 벡터들 사이의 각도 들로 정의되는 트리플-와이즈 관계의 합으로, 정의될 수 있다. 다른 실시예에 따르면, 컨텍스트 지식은 계층들에 걸친 동일한 단어에 대한 단어 임베딩 벡터들 사이의 수직적 계층 변환 관계를 포함할 수 있다. 이러한 경우, 계층들에 걸쳐 상기 동일한 단어에 대한 단어 임베딩 벡터들 사이에서, 페어들과 트리플들이 결정될 수 있다. 그리고, 계층 변환 관계는 페어들을 각각 구성하는 단어 임베 딩 벡터들 사이의 거리들로 정의되는 페어-와이즈 관계와 트리플들을 각각 구성하는 단어 임베딩 벡터들 사이의각도들로 정의되는 트리플-와이즈 관계의 합으로, 정의될 수 있다. 다양한 실시예들에 따르면, 대규모 네트워크에서의 계층들의 수와 소규모 네트워크들의 각각에서의 계층들의 수 는 동일하거나 상이할 수 있다. 그리고, 단어 임베딩 벡터들의 계층들의 수는 대규모 네트워크에서의 계층들의 수로 결정될 수 있다. 이 때, 대규모 네트워크에서의 계층들의 수와 소규모 네트워크들의 각각에서의 계층들의 수가 상이한 경우, 컨텍스트 지식은 단어 임베딩 벡터들의 계층들의 수를 소규모 네트워크들의 각각에서의 계층 들의 수와 일치시킬 수 있다. 다양한 실시예들에 따르면, 페어-와이즈 관계 및 트리플-와이즈 관계는, 대규모 네트워크와 소규모 네트워크들 사이에서 일치될 수 있다. 다음으로, 컴퓨터 시스템은 230 단계에서, 소규모 네트워크들을 통해, 컨텍스트 지식에 기반하여 학습할 수 있다. 본 개시는 컨텍스트 지식 증류를 이용하여, 높은 정확도를 유지하면서도 연산량과 파라미터들의 수가 적은 네트 워크를 통해 학습할 수 있다. 따라서, 본 개시는 네트워크의 사이즈 또는 추론 시간을 줄임과 동시에 정확한 서 비스를 제공할 수 있다. 이는, 학문적인 의의뿐만 아니라, 모바일과 같은 환경에의 적용을 통해, 사용자들에게 다수의 태스크(컴퓨터 비전, 자연 언어 처리 등)들에서 정확하고 간편한 서비스가 제공될 수 있게 하며, 언어 처리를 활용하는 다양한 서비스를 제공하도록 활용될 수 있다. 이상에서 설명된 장치는 하드웨어 구성 요소, 소프트웨어 구성 요소, 및/또는 하드웨어 구성 요소 및 소프트웨 어 구성 요소의 조합으로 구현될 수 있다. 예를 들어, 실시예들에서 설명된 장치 및 구성 요소는, 프로세서, 컨 트롤러, ALU(arithmetic logic unit), 디지털 신호 프로세서(digital signal processor), 마이크로컴퓨터, FPGA(field programmable gate array), PLU(programmable logic unit), 마이크로프로세서, 또는 명령 (instruction)을 실행하고 응답할 수 있는 다른 어떠한 장치와 같이, 하나 이상의 범용 컴퓨터 또는 특수 목적 컴퓨터를 이용하여 구현될 수 있다. 처리 장치는 운영 체제(OS) 및 상기 운영 체제 상에서 수행되는 하나 이상 의 소프트웨어 어플리케이션을 수행할 수 있다. 또한, 처리 장치는 소프트웨어의 실행에 응답하여, 데이터를 접 근, 저장, 조작, 처리 및 생성할 수도 있다. 이해의 편의를 위하여, 처리 장치는 하나가 사용되는 것으로 설명"}
{"patent_id": "10-2022-0032048", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 7, "content": "된 경우도 있지만, 해당 기술분야에서 통상의 지식을 가진 자는, 처리 장치가 복수 개의 처리 요소(processing element) 및/또는 복수 유형의 처리 요소를 포함할 수 있음을 알 수 있다. 예를 들어, 처리 장치는 복수 개의 프로세서 또는 하나의 프로세서 및 하나의 컨트롤러를 포함할 수 있다. 또한, 병렬 프로세서(parallel processor)와 같은, 다른 처리 구성(processing configuration)도 가능하다. 소프트웨어는 컴퓨터 프로그램(computer program), 코드(code), 명령(instruction), 또는 이들 중 하나 이상의 조합을 포함할 수 있으며, 원하는 대로 동작하도록 처리 장치를 구성하거나 독립적으로 또는 결합적으로 (collectively) 처리 장치를 명령할 수 있다. 소프트웨어 및/또는 데이터는, 처리 장치에 의하여 해석되거나 처 리 장치에 명령 또는 데이터를 제공하기 위하여, 어떤 유형의 기계, 구성 요소(component), 물리적 장치, 컴퓨 터 저장 매체 또는 장치에 구체화(embody)될 수 있다. 소프트웨어는 네트워크로 연결된 컴퓨터 시스템 상에 분 산되어서, 분산된 방법으로 저장되거나 실행될 수도 있다. 소프트웨어 및 데이터는 하나 이상의 컴퓨터 판독 가 능 기록 매체에 저장될 수 있다. 다양한 실시예들에 따른 방법은 다양한 컴퓨터 수단을 통하여 수행될 수 있는 프로그램 명령 형태로 구현되어 컴퓨터-판독 가능 매체에 기록될 수 있다. 이 때, 매체는 컴퓨터로 실행 가능한 프로그램을 계속 저장하거나, 실행 또는 다운로드를 위해 임시 저장하는 것일 수도 있다. 그리고, 매체는 단일 또는 수 개의 하드웨어가 결합 된 형태의 다양한 기록수단 또는 저장수단일 수 있는데, 어떤 컴퓨터 시스템에 직접 접속되는 매체에 한정되지 않고, 네트워크 상에 분산 존재하는 것일 수도 있다. 매체의 예시로는, 하드 디스크, 플로피 디스크 및 자기 테 이프와 같은 자기 매체, CD-ROM 및 DVD와 같은 광기록 매체, 플롭티컬 디스크(floptical disk)와 같은 자기-광 매체(magneto-optical medium), 및 ROM, RAM, 플래시 메모리 등을 포함하여 프로그램 명령어가 저장되도록 구성 된 것이 있을 수 있다. 또한, 다른 매체의 예시로, 어플리케이션을 유통하는 앱 스토어나 기타 다양한 소프트웨 어를 공급 내지 유통하는 사이트, 서버 등에서 관리하는 기록매체 내지 저장매체도 들 수 있다. 본 문서의 다양한 실시예들 및 이에 사용된 용어들은 본 문서에 기재된 기술을 특정한 실시 형태에 대해 한정하 려는 것이 아니며, 해당 실시 예의 다양한 변경, 균등물, 및/또는 대체물을 포함하는 것으로 이해되어야 한다. 도면의 설명과 관련하여, 유사한 구성 요소에 대해서는 유사한 참조 부호가 사용될 수 있다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함할 수 있다. 본 문서에서, \"A 또는 B\", \"A 및/또는 B 중 적어도 하나\", \"A, B 또는 C\" 또는 \"A, B 및/또는 C 중 적어도 하나\" 등의 표현은 함께 나열된 항목들의 모 든 가능한 조합을 포함할 수 있다. \"제 1\", \"제 2\", \"첫째\" 또는 \"둘째\" 등의 표현들은 해당 구성 요소들을, 순 서 또는 중요도에 상관없이 수식할 수 있고, 한 구성 요소를 다른 구성 요소와 구분하기 위해 사용될 뿐 해당 구성 요소들을 한정하지 않는다. 어떤(예: 제 1) 구성 요소가 다른(예: 제 2) 구성 요소에 \"(기능적으로 또는 통신적으로) 연결되어\" 있다거나 \"접속되어\" 있다고 언급된 때에는, 상기 어떤 구성 요소가 상기 다른 구성 요 소에 직접적으로 연결되거나, 다른 구성 요소(예: 제 3 구성 요소)를 통하여 연결될 수 있다. 본 문서에서 사용된 용어 \"모듈\"은 하드웨어, 소프트웨어 또는 펌웨어로 구성된 유닛을 포함하며, 예를 들면, 로직, 논리 블록, 부품, 또는 회로 등의 용어와 상호 호환적으로 사용될 수 있다. 모듈은, 일체로 구성된 부품 또는 하나 또는 그 이상의 기능을 수행하는 최소 단위 또는 그 일부가 될 수 있다. 예를 들면, 모듈은 ASIC(application-specific integrated circuit)으로 구성될 수 있다. 다양한 실시예들에 따르면, 기술한 구성 요소들의 각각의 구성 요소(예: 모듈 또는 프로그램)는 단수 또는 복수 의 개체를 포함할 수 있다. 다양한 실시예들에 따르면, 전술한 해당 구성 요소들 중 하나 이상의 구성 요소들 또는 단계들이 생략되거나, 또는 하나 이상의 다른 구성 요소들 또는 단계들이 추가될 수 있다. 대체적으로 또 는 추가적으로, 복수의 구성 요소들(예: 모듈 또는 프로그램)은 하나의 구성 요소로 통합될 수 있다. 이런 경우, 통합된 구성 요소는 복수의 구성 요소들 각각의 구성 요소의 하나 이상의 기능들을 통합 이전에 복수의 구성 요소들 중 해당 구성 요소에 의해 수행되는 것과 동일 또는 유사하게 수행할 수 있다. 다양한 실시예들에 따르면, 모듈, 프로그램 또는 다른 구성 요소에 의해 수행되는 단계들은 순차적으로, 병렬적으로, 반복적으로, 또는 휴리스틱하게 실행되거나, 단계들 중 하나 이상이 다른 순서로 실행되거나, 생략되거나, 또는 하나 이상의 다른 단계들이 추가될 수 있다."}
{"patent_id": "10-2022-0032048", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 개시에 따른 컨텍스트 지식 증류를 설명하기 위한 도면이다. 도 2는 본 개시에 따른 단어 관계 기반 컨텍스트 지식 증류 및 계층 변환 관계 기반 컨텍스트 지식 증류를 설명 하기 위한 도면이다. 도 3은 본 개시의 다양한 실시예들에 따른 컴퓨터 시스템의 구성을 도시하는 도면이다. 도 4는 본 개시의 다양한 실시예들에 따른 컴퓨터 시스템의 방법을 도시하는 도면이다."}
