{"patent_id": "10-2020-0152728", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2022-0066559", "출원번호": "10-2020-0152728", "발명의 명칭": "전자 장치 및 그 제어 방법", "출원인": "삼성전자주식회사", "발명자": "신동의"}}
{"patent_id": "10-2020-0152728", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "전자 장치에 있어서,제1 촬상각을 갖는 제1 카메라;상기 제1 촬상각보다 큰 제2 촬상각을 갖는 제2 카메라; 및상기 제1 카메라로부터 획득된 제1 촬상 이미지 또는 상기 제2 카메라로부터 획득된 제2 촬상 이미지에서 타겟오브젝트의 일 부분이 식별되고 상기 타겟 오브젝트의 나머지 일 부분에 오버랩되는 장애물 오브젝트가 식별되면, 상기 식별된 장애물 오브젝트의 위치 정보를 획득하고, 상기 획득된 장애물 오브젝트의 위치 정보에 기초하여 상기 제2 촬상 이미지의 관심 영역을 식별하고,상기 제2 촬상 이미지의 관심 영역에 기초하여 상기 타겟 오브젝트의 나머지 일 부분을 식별하는 프로세서;를포함하는 전자 장치."}
{"patent_id": "10-2020-0152728", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 프로세서는,상기 제1 촬상 이미지에서 상기 타겟 오브젝트 및 상기 장애물 오브젝트가 포함된 영역 및 상기 제2 촬상 이미지의 관심 영역에 기초하여 상기 타겟 오브젝트의 전체 이미지를 포함하는 결합 이미지를 획득하고, 상기 획득된 결합 이미지에 기초하여 상기 타겟 오브젝트를 식별하는, 전자 장치."}
{"patent_id": "10-2020-0152728", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 제1 촬상 이미지는 제1 촬상 위치에서 상기 제1 카메라에 의해 촬상된 이미지이고, 상기 제2 촬상 이미지는 상기 제1 촬상 위치와 상이한 제2 촬상 위치에서 상기 제2 카메라에 의해 촬상된 이미지인, 전자 장치."}
{"patent_id": "10-2020-0152728", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서,상기 프로세서는,상기 제1 촬상 위치 및 상기 제2 촬상 위치와 상이한 제3 촬상 위치에서 상기 제2 카메라로부터 촬상된 제3 촬상 이미지를 획득하고,상기 식별된 장애물 오브젝트의 위치 정보에 기초하여 상기 제3 촬상 이미지의 관심 영역을 식별하고,상기 제2 촬상 이미지의 관심 영역 및 상기 제3 촬상 이미지의 관심 영역에 기초하여 상기 타겟 오브젝트의 나머지 일 부분을 식별하는, 전자 장치."}
{"patent_id": "10-2020-0152728", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서,상기 제2 촬상 위치는 상기 제1 촬상 위치를 기준으로 제1 방향에 위치하며, 상기 제3 촬상 위치는 상기 제1 촬상 위치를 기준으로 상기 제1 방향과 상이한 제2 방향에 위치하는, 전자공개특허 10-2022-0066559-3-장치."}
{"patent_id": "10-2020-0152728", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5항에 있어서,상기 프로세서는,상기 제2 촬상 이미지가 촬상된 방향 정보 및 상기 장애물 오브젝트의 위치 정보에 기초하여 상기 제2 촬상 이미지의 관심 영역을 식별하고,상기 제3 촬상 이미지가 촬상된 방향 정보 및 상기 장애물 오브젝트의 위치 정보에 기초하여 상기 제3 촬상 이미지의 관심 영역을 식별하는, 전자 장치."}
{"patent_id": "10-2020-0152728", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에 있어서,상기 프로세서는,상기 제1 촬상 이미지에서 식별된 상기 타겟 오브젝트의 일 부분에 기초하여 타겟 오브젝트의 제1 정보를 획득하고,상기 제2 촬상 이미지에서 식별된 상기 타겟 오브젝트의 나머지 일 부분에 기초하여 타겟 오브젝트의 제2 정보를 획득하는, 전자 장치."}
{"patent_id": "10-2020-0152728", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1항에 있어서,상기 프로세서는, 상기 제1 촬상 이미지에 기초하여 상기 장애물 오브젝트의 위치 정보 및 크기 정보를 식별하고,상기 식별된 장애물 오브젝트의 위치 정보 및 크기 정보에 기초하여 상기 제2 카메라의 촬상 위치를 식별하며, 상기 제2 촬상 이미지는, 상기 식별된 촬상 위치에서 촬상된 이미지인, 전자 장치."}
{"patent_id": "10-2020-0152728", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1항에 있어서,발광부;를 더 포함하고,상기 프로세서는,상기 제1 촬상 이미지의 관심 영역을 식별하고,상기 제1 촬상 이미지의 관심 영역 및 상기 제2 촬상 이미지의 관심 영역에 인접한 영역에 대응되는 위치를 식별하고, 상기 식별된 위치로 임계 세기 이상의 광을 조사하도록 상기 발광부를 제어하는, 전자 장치."}
{"patent_id": "10-2020-0152728", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제 9항에 있어서,상기 프로세서는,상기 식별된 위치로 상기 광이 조사되도록 상기 발광부의 발광 각도를 변경하는, 전자 장치."}
{"patent_id": "10-2020-0152728", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "전자 장치의 제어 방법에 있어서,제1 촬상각을 갖는 제1 카메라로부터 획득된 제1 촬상 이미지 또는 상기 제1 촬상각보다 큰 제2 촬상각을 가지공개특허 10-2022-0066559-4-는 제2 카메라로부터 획득된 제2 촬상 이미지에서 타겟 오브젝트의 일 부분이 식별되고 상기 타겟 오브젝트의나머지 일 부분에 오버랩되는 장애물 오브젝트가 식별되면, 상기 식별된 장애물 오브젝트의 위치 정보를 획득하는 단계;상기 획득된 장애물 오브젝트의 위치 정보에 기초하여 상기 제2 촬상 이미지의 관심 영역을 식별하는 단계; 및상기 제2 촬상 이미지의 관심 영역에 기초하여 상기 타겟 오브젝트의 나머지 일 부분을 식별하는 단계;를 포함하는 전자 장치의 제어 방법."}
{"patent_id": "10-2020-0152728", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항에 있어서,상기 제어 방법은,상기 제1 촬상 이미지에서 상기 타겟 오브젝트 및 상기 장애물 오브젝트가 포함된 영역 및 상기 제2 촬상 이미지의 관심 영역에 기초하여 상기 타겟 오브젝트의 전체 이미지를 포함하는 결합 이미지를 획득하는 단계; 및상기 획득된 결합 이미지에 기초하여 상기 타겟 오브젝트를 식별하는 단계;를 더 포함하는, 전자 장치의 제어방법."}
{"patent_id": "10-2020-0152728", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제11항에 있어서,상기 제1 촬상 이미지는 제1 촬상 위치에서 상기 제1 카메라에 의해 촬상된 이미지이고, 상기 제2 촬상 이미지는 상기 제1 촬상 위치와 상이한 제2 촬상 위치에서 상기 제2 카메라에 의해 촬상된 이미지인, 전자 장치의 제어 방법."}
{"patent_id": "10-2020-0152728", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제13항에 있어서,상기 제어 방법은,상기 제1 촬상 위치 및 상기 제2 촬상 위치와 상이한 제3 촬상 위치에서 상기 제2 카메라로부터 촬상된 제3 촬상 이미지를 획득하는 단계;상기 식별된 장애물 오브젝트의 위치 정보에 기초하여 상기 제3 촬상 이미지의 관심 영역을 식별하는 단계; 및상기 제2 촬상 이미지의 관심 영역 및 상기 제3 촬상 이미지의 관심 영역에 기초하여 상기 타겟 오브젝트의 나머지 일 부분을 식별하는 단계;를 더 포함하는, 전자 장치의 제어 방법."}
{"patent_id": "10-2020-0152728", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제14항에 있어서,상기 제2 촬상 위치는 상기 제1 촬상 위치를 기준으로 제1 방향에 위치하며, 상기 제3 촬상 위치는 상기 제1 촬상 위치를 기준으로 상기 제1 방향과 상이한 제2 방향에 위치하는, 전자 장치의 제어 방법."}
{"patent_id": "10-2020-0152728", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제15항에 있어서,상기 제2 촬상 이미지의 관심 영역을 식별하는 단계는,상기 제2 촬상 이미지가 촬상된 방향 정보 및 상기 장애물 오브젝트의 위치 정보에 기초하여 상기 제2 촬상 이미지의 관심 영역을 식별하고,상기 제3 촬상 이미지의 관심 영역을 식별하는 단계는,상기 제3 촬상 이미지가 촬상된 방향 정보 및 상기 장애물 오브젝트의 위치 정보에 기초하여 상기 제3 촬상 이공개특허 10-2022-0066559-5-미지의 관심 영역을 식별하는, 전자 장치의 제어 방법."}
{"patent_id": "10-2020-0152728", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제11항에 있어서,상기 제어 방법은,상기 제1 촬상 이미지에서 식별된 상기 타겟 오브젝트의 일 부분에 기초하여 타겟 오브젝트의 제1 정보를 획득하는 단계; 및상기 제2 촬상 이미지에서 식별된 상기 타겟 오브젝트의 나머지 일 부분에 기초하여 타겟 오브젝트의 제2 정보를 획득하는 단계;를 더 포함하는, 전자 장치의 제어 방법."}
{"patent_id": "10-2020-0152728", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제11항에 있어서,상기 제어 방법은,상기 제1 촬상 이미지에 기초하여 상기 장애물 오브젝트의 위치 정보 및 크기 정보를 식별하는 단계; 및상기 식별된 장애물 오브젝트의 위치 정보 및 크기 정보에 기초하여 상기 제2 카메라의 촬상 위치를 식별하는단계;를 더 포함하고,상기 제2 촬상 이미지는, 상기 식별된 촬상 위치에서 촬상된 이미지인, 전자 장치의 제어 방법."}
{"patent_id": "10-2020-0152728", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제11항에 있어서,상기 제어 방법은,상기 제1 촬상 이미지의 관심 영역을 식별하는 단계;상기 제1 촬상 이미지의 관심 영역 및 상기 제2 촬상 이미지의 관심 영역에 인접한 영역에 대응되는 위치를 식별하는 단계; 및상기 식별된 위치로 임계 세기 이상의 광을 조사하는 단계;를 더 포함하는, 전자 장치의 제어 방법."}
{"patent_id": "10-2020-0152728", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제19항에 있어서,상기 제어 방법은상기 식별된 위치로 상기 광이 조사되도록 발광 각도를 변경하는 단계;를 더 포함하는, 전자 장치의 제어 방법."}
{"patent_id": "10-2020-0152728", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "전자 장치가 개시된다. 본 전자 장치는 제1 촬상각을 갖는 제1 카메라, 제1 촬상각보다 큰 제2 촬상각을 갖는 제 2 카메라 및 제1 카메라로부터 획득된 제1 촬상 이미지 또는 제2 카메라로부터 획득된 제2 촬상 이미지 중 적어 도 하나로부터 타겟 오브젝트의 일 부분이 식별되고 타겟 오브젝트의 나머지 일 부분에 오버랩되는 장애물 오브 젝트가 식별되면, 식별된 장애물 오브젝트의 위치 정보를 획득하고, 획득된 장애물 오브젝트의 위치 정보에 기초 하여 제2 촬상 이미지의 관심 영역을 식별하고 제2 촬상 이미지의 관심 영역에 기초하여 타겟 오브젝트의 나머지 일 부분을 식별하는 프로세서를 포함한다."}
{"patent_id": "10-2020-0152728", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 전자 장치 및 그 제어방법에 관한 것으로, 더욱 상세하게는 장애물에 가려진 타겟 오브젝트를 식별하 는 전자 장치 및 그 제어방법에 대한 것이다."}
{"patent_id": "10-2020-0152728", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "다양한 제품에 대한 재고 파악 업무를 자동화하기 위하여 이동 로봇을 이용할 수 있다. 여기서, 이동 로봇을 카 메라를 포함하여 제품의 위치 및 수량 등을 파악할 수 있다. 다만, 모든 제품들이 카메라를 통해 쉽게 인식되도 록 배치되어 있지 않을 수 있다. 예를 들어, 하나의 제품과 다른 제품이 겹쳐져 있거나, 하나의 제품과 장애물 이 서로 겹쳐져 있는 경우 이동 로봇은 재고 파악에 어려움이 있을 수 있다. 또한, 이동 로봇을 플래시를 포함할 수 있다. 제품을 촬상함에 있어 실내 공간의 조명이 어둡거나 텍스트를 인 식하기 위하여 이미지가 더 밝은 상태로 획득해야 할 수 있다. 여기서, 제품 자체 또는 라벨 등은 빛이 쉽게 반 사되는 재질일 수 있다. 여기서, 플래시 등에 의해 빛이 많이 반사되는 경우, 이동 로봇이 촬상한 이미지는 다 소 인식률이 떨어지는 문제가 있을 수 있다."}
{"patent_id": "10-2020-0152728", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 개시는 상술한 문제를 개선하기 위해 고안된 것으로, 본 개시의 목적은 서로 다른 촬상각을 갖는 복수의 카 메라에서 획득된 이미지를 이용하여 장애물에 가려진 타겟을 식별하는 전자 장치 및 그의 제어 방법을 제공함에 있다."}
{"patent_id": "10-2020-0152728", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상술한 목적을 달성하기 위한 본 실시 예에 따른 전자 장치는 제1 촬상각을 갖는 제1 카메라, 상기 제1 촬상각 보다 큰 제2 촬상각을 갖는 제2 카메라 및 상기 제1 카메라로부터 획득된 제1 촬상 이미지 또는 상기 제2 카메 라로부터 획득된 제2 촬상 이미지에서 타겟 오브젝트의 일 부분이 식별되고 상기 타겟 오브젝트의 나머지 일 부 분에 오버랩되는 장애물 오브젝트가 식별되면, 상기 식별된 장애물 오브젝트의 위치 정보를 획득하고, 상기 획 득된 장애물 오브젝트의 위치 정보에 기초하여 상기 제2 촬상 이미지의 관심 영역을 식별하고 상기 제2 촬상 이 미지의 관심 영역에 기초하여 상기 타겟 오브젝트의 나머지 일 부분을 식별하는 프로세서를 포함한다. 한편, 상기 프로세서는 상기 제1 촬상 이미지에서 상기 타겟 오브젝트 및 상기 장애물 오브젝트가 포함된 영역 및 상기 제2 촬상 이미지의 관심 영역에 기초하여 상기 타겟 오브젝트의 전체 이미지를 포함하는 결합 이미지를 획득할 수 있고, 상기 획득된 결합 이미지에 기초하여 상기 타겟 오브젝트를 식별할 수 있다. 한편, 상기 제1 촬상 이미지는 제1 촬상 위치에서 상기 제1 카메라에 의해 촬상된 이미지이고, 상기 제2 촬상 이미지는 상기 제1 촬상 위치와 상이한 제2 촬상 위치에서 상기 제2 카메라에 의해 촬상된 이미지일 수 있다. 한편, 상기 프로세서는 상기 제1 촬상 위치 및 상기 제2 촬상 위치와 상이한 제3 촬상 위치에서 상기 제2 카메 라로부터 촬상된 제3 촬상 이미지를 획득할 수 있고, 상기 식별된 장애물 오브젝트의 위치 정보에 기초하여 상 기 제3 촬상 이미지의 관심 영역을 식별할 수 있고, 상기 제2 촬상 이미지의 관심 영역 및 상기 제3 촬상 이미 지의 관심 영역에 기초하여 상기 타겟 오브젝트의 나머지 일 부분을 식별할 수 있다. 한편, 상기 제2 촬상 위치는 상기 제1 촬상 위치를 기준으로 제1 방향에 위치할 수 있고, 상기 제3 촬상 위치는 상기 제1 촬상 위치를 기준으로 상기 제1 방향과 상이한 제2 방향에 위치할 수 있다. 한편, 상기 프로세서는 상기 제2 촬상 이미지가 촬상된 방향 정보 및 상기 장애물 오브젝트의 위치 정보에 기초 하여 상기 제2 촬상 이미지의 관심 영역을 식별할 수 있고, 상기 제3 촬상 이미지가 촬상된 방향 정보 및 상기 장애물 오브젝트의 위치 정보에 기초하여 상기 제3 촬상 이미지의 관심 영역을 식별할 수 있다. 한편, 상기 프로세서는 상기 제1 촬상 이미지에서 식별된 상기 타겟 오브젝트의 일 부분에 기초하여 타겟 오브 젝트의 제1 정보를 획득하고, 상기 제2 촬상 이미지에서 식별된 상기 타겟 오브젝트의 나머지 일 부분에 기초하 여 타겟 오브젝트의 제2 정보를 획득할 수 있다. 한편, 상기 프로세서는 상기 제1 촬상 이미지에 기초하여 상기 장애물 오브젝트의 위치 정보 및 크기 정보를 식 별할 수 있고, 상기 식별된 장애물 오브젝트의 위치 정보 및 크기 정보에 기초하여 상기 제2 카메라의 촬상 위 치를 식별할 수 있고, 상기 제2 촬상 이미지는 상기 식별된 촬상 위치에서 촬상된 이미지일 수 있다. 한편, 전자 장치는 발광부를 더 포함할 수 있고, 상기 프로세서는 상기 제1 촬상 이미지의 관심 영역을 식별할 수 있고, 상기 제1 촬상 이미지의 관심 영역 및 상기 제2 촬상 이미지의 관심 영역에 인접한 영역에 대응되는 위치를 식별할 수 있고, 상기 식별된 위치로 임계 세기 이상의 광을 조사하도록 상기 발광부를 제어할 수 있다. 한편, 상기 프로세서는 상기 식별된 위치로 상기 광이 조사되도록 상기 발광부의 발광 각도를 변경할 수 있다. 본 개시의 일 실시 예에 따른 전자 장치의 제어 방법은 제1 촬상각을 갖는 제1 카메라로부터 획득된 제1 촬상 이미지 또는 상기 제1 촬상각보다 큰 제2 촬상각을 가지는 제2 카메라로부터 획득된 제2 촬상 이미지 에서 타겟 오브젝트의 일 부분이 식별되고 상기 타겟 오브젝트의 나머지 일 부분에 오버랩되는 장애물 오브젝트가 식별되 면, 상기 식별된 장애물 오브젝트의 위치 정보를 획득하는 단계, 상기 획득된 장애물 오브젝트의 위치 정보에기초하여 상기 제2 촬상 이미지의 관심 영역에 기초하여 상기 타겟 오브젝트의 나머지 일 부분을 식별하는 단계 를 포함한다. 한편, 상기 제어 방법은 상기 제1 촬상 이미지에서 상기 타겟 오브젝트 및 상기 장애물 오브젝트가 포함된 영역 및 상기 제2 촬상 이미지의 관심 영역에 기초하여 상기 타겟 오브젝트의 전체 이미지를 포함하는 결합 이미지를 획득하는 단계 및 상기 획득된 결합 이미지에 기초하여 상기 타겟 오브젝트를 식별하는 단계를 더 포함할 수 있 다. 한편, 상기 제1 촬상 이미지는 제1 촬상 위치에서 상기 제1 카메라에 의해 촬상된 이미지이고, 상기 제2 촬상 이미지는 상기 제1 촬상 위치와 상이한 제2 촬상 위치에서 상기 제2 카메라에 의해 촬상된 이미지일 수 있다. 한편, 상기 제어 방법은 상기 제1 촬상 위치 및 상기 제2 촬상 위치와 상이한 제3 촬상 위치에서 상기 제2 카메 라로부터 촬상된 제3 촬상 이미지를 획득하는 단계, 상기 식별된 장애물 오브젝트의 위치 정보에 기초하여 상기 제3 촬상 이미지의 관심 영역을 식별하는 단계 및 상기 제2 촬상 이미지의 관심 영역 및 상기 제3 촬상 이미지 의 관심 영역에 기초하여 상기 타겟 오브젝트의 나머지 일 부분을 식별하는 단계를 더 포함할 수 있다. 한편, 상기 제2 촬상 위치는 상기 제1 촬상 위치를 기준으로 제1 방향에 위치할 수 있고, 상기 제3 촬상 위치는 상기 제1 촬상 위치를 기준으로 상기 제1 방향과 상이한 제2 방향에 위치할 수 있다. 한편, 상기 제2 촬상 이미지의 관심 영역을 식별하는 단계는 상기 제2 촬상 이미지가 촬상된 방향 정보 및 상기 장애물 오브젝트의 위치 정보에 기초하여 상기 제2 촬상 이미지의 관심 영역을 식별할 수 있고, 상기 제3 촬상 이미지의 관심 영역을 식별하는 단계는 상기 제3 촬상 이미지가 촬상된 방향 정보 및 상기 장애물 오브젝트의 위치 정보에 기초하여 상기 제3 촬상 이미지의 관심 영역을 식별할 수 있다. 한편, 상기 제어 방법은 상기 제1 촬상 이미지에서 식별된 상기 타겟 오브젝트의 일 부분에 기초하여 타겟 오브 젝트의 제1 정보를 획득하는 단계 및 상기 제2 촬상 이미지에서 식별된 상기 타겟 오브젝트의 나머지 일 부분에 기초하여 타겟 오브젝트의 제2 정보를 획득하는 단계를 더 포함할 수 있다. 한편, 상기 제어 방법은 상기 제1 촬상 이미지에 기초하여 상기 장애물 오브젝트의 위치 정보 및 크기 정보를 식별하는 단계 및 상기 식별된 장애물 오브젝트의 위치 정보 및 크기 정보에 기초하여 상기 제2 카메라의 촬상 위치를 식별하는 단계를 더 포함할 수 있고, 상기 제2 촬상 이미지는 상기 식별된 촬상 위치에서 촬상된 이미지 일 수 있다. 한편, 상기 제어 방법은 상기 제1 촬상 이미지의 관심 영역을 식별하는 단계, 상기 제1 촬상 이미지의 관심 영 역 및 상기 제2 촬상 이미지의 관심 영역에 인접한 영역에 대응되는 위치를 식별하는 단계 및 상기 식별된 위치 로 임계 세기 이상의 광을 조사하는 단계를 더 포함할 수 있다. 한편, 상기 제어 방법은 상기 식별된 위치로 상기 광이 조사되도록 발광 각도를 변경하는 단계를 더 포함할 수 있다."}
{"patent_id": "10-2020-0152728", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하에서는 첨부 도면을 참조하여 본 개시를 상세히 설명한다. 본 개시의 실시 예에서 사용되는 용어는 본 개시에서의 기능을 고려하면서 가능한 현재 널리 사용되는 일반적인 용어들을 선택하였으나, 이는 당 분야에 종사하는 기술자의 의도 또는 판례, 새로운 기술의 출현 등에 따라 달 라질 수 있다. 또한, 특정한 경우는 출원인이 임의로 선정한 용어도 있으며, 이 경우 해당되는 개시의 설명 부 분에서 상세히 그 의미를 기재할 것이다. 따라서 본 개시에서 사용되는 용어는 단순한 용어의 명칭이 아닌, 그 용어가 가지는 의미와 본 개시의 전반에 걸친 내용을 토대로 정의되어야 한다. 본 명세서에서, \"가진다,\" \"가질 수 있다,\" \"포함한다,\" 또는 \"포함할 수 있다\" 등의 표현은 해당 특징(예: 수 치, 기능, 동작, 또는 부품 등의 구성요소)의 존재를 가리키며, 추가적인 특징의 존재를 배제하지 않는다. A 또는/및 B 중 적어도 하나라는 표현은 \"A\" 또는 \"B\" 또는 \"A 및 B\" 중 어느 하나를 나타내는 것으로 이해되어 야 한다. 본 명세서에서 사용된 \"제1,\" \"제2,\" \"첫째,\" 또는 \"둘째,\"등의 표현들은 다양한 구성요소들을, 순서 및/또는 중요도에 상관없이 수식할 수 있고, 한 구성요소를 다른 구성요소와 구분하기 위해 사용될 뿐 해당 구성요소들 을 한정하지 않는다. 어떤 구성요소(예: 제1 구성요소)가 다른 구성요소(예: 제2 구성요소)에 \"(기능적으로 또는 통신적으로) 연결되 어((operatively or communicatively) coupled with/to)\" 있다거나 \"접속되어(connected to)\" 있다고 언급된 때에는, 어떤 구성요소가 다른 구성요소에 직접적으로 연결되거나, 다른 구성요소(예: 제3 구성요소)를 통하여 연결될 수 있다고 이해되어야 할 것이다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 출원에서, \"포함하다\" 또 는 \"구성되다\" 등의 용어는 명세서상에 기재된 특징, 숫자, 단계, 동작, 구성요소, 부품 또는 이들을 조합한 것 이 존재함을 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성요소, 부품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되어야 한다. 본 개시에서 \"모듈\" 혹은 \"부\"는 적어도 하나의 기능이나 동작을 수행하며, 하드웨어 또는 소프트웨어로 구현되 거나 하드웨어와 소프트웨어의 결합으로 구현될 수 있다. 또한, 복수의 \"모듈\" 혹은 복수의 \"부\"는 특정한 하드 웨어로 구현될 필요가 있는 \"모듈\" 혹은 \"부\"를 제외하고는 적어도 하나의 모듈로 일체화되어 적어도 하나의 프 로세서(미도시)로 구현될 수 있다.본 명세서에서, 사용자라는 용어는 전자 장치를 사용하는 사람 또는 전자 장치를 사용하는 장치(예: 인공지능 전자 장치)를 지칭할 수 있다. 이하 첨부된 도면들을 참조하여 본 개시의 일 실시 예를 보다 상세하게 설명한다. 도 1은 본 개시의 일 실시 예에 따른 전자 장치의 동작을 설명하기 위한 도면이다. 도 1을 참조하면, 전자 장치는 카메라를 통해 전방의 오브젝트를 촬상(또는 촬영)할 수 있다. 여기서, 전 자 장치는 카메라를 포함하는 이동형 기기를 의미할 수 있다. 예를 들어, 전자 장치는 카메라를 포함 하는 이동형 로봇일 수 있다. 전자 장치는 카메라를 통해 전방의 타겟 오브젝트를 촬상할 수 있다. 여기서, 타겟 오브젝트는 사용자가 촬상하고자 의도하는 물체를 의미할 수 있다. 예를 들어, 타겟 오브젝트는 라벨 또는 제품 그 자체를 의미할 수 있다. 전자 장치는 촬상된 이미지에 기초하여 타겟 오브젝트를 식별하고, 식별된 타겟 오브젝트에 기초하 여 타겟 오브젝트에 대응되는 정보를 획득할 수 있다. 전자 장치는 촬상된 이미지에서 라벨을 식별하고, 식별된 라벨에 기초하여 라벨에 포함된 텍스트 정보를 획득할 수 있다. 획득되는 텍스트 정보에는 제품 이름, 제품 번호, 제품, 종류, 제품 회사, 제품 수량, 제품 기 타 정보 중 적어도 하나가 포함될 수 있다. 전자 장치는 촬상된 이미지에서 제품을 식별하고, 식별된 제품에 기초하여 제품 이름, 제품 번호, 제품, 종류, 제품 회사, 제품 수량, 제품 기타 정보 중 적어도 하나가 포함될 수 있다. 이미지에 포함된 라벨에서 획득되는 정보는 촬상된 라벨 자체에서 획득되는 정보이며, 이미지에 포함된 제품에 서 획득되는 정보는 제품 이미지를 분석하여 획득되는 정보일 수 있다. 도 2는 본 개시의 일 실시 예에 따른 전자 장치를 도시한 블록도이다. 도 2를 참조하면, 전자 장치는 제1 카메라, 제2 카메라 및 프로세서로 구성될 수 있다. 제1 카메라는 협각 이미지를 촬상하는 카메라일 수 있다. 제2 카메라는 광각 이미지를 촬상하는 카메 라일 수 있다. 따라서, 제1 카메라는 제1 촬상각으로 촬상할 수 있으며, 제2 카메라는 제1 촬상각보 다 큰 제2 촬상각으로 촬상할 수 있다. 제1 카메라 및 제2 카메라는 피사체를 촬상하여 촬상 영상을 생성하기 위한 구성이며, 여기서 촬상 영상은 동영상과 정지 영상 모두를 포함하는 개념이다. 제1 카메라 및 제2 카메라는 적어도 하나의 외부 기기에 대한 이미지를 획득할 수 있으며, 카메라, 렌즈, 적외선 센서 등으로 구현될 수 있다. 제1 카메라 및 제2 카메라는 렌즈와 이미지 센서를 포함할 수 있다. 렌즈의 종류에는 일반적인 범용 렌즈, 광각 렌즈, 줌 렌즈 등이 있으며, 전자 장치의 종류, 특성, 사용 환경 등에 따라 결정될 수 있다. 이미지 센서로는 상보성 금속 산화물 반도체(Complementary Metal Oxide Semiconductor: CMOS)와 전하결합소자 (Charge Coupled Device: CCD) 등이 사용될 수 있다. 제1 카메라 및 제2 카메라는 입사된 빛을 영상 신호로 출력한다. 구체적으로, 제1 카메라 및 제 2 카메라는 렌즈, 화소 및 AD 컨버터를 구비할 수 있다. 렌즈는 피사체의 빛을 모아서 촬상 영역에 광학상 이 맺히게 하며, 화소는 렌즈를 통해 입상되는 빚을 아날로그 형태의 영상 신호로 출력할 수 있다. 그리고 AD 컨버터는 아날로그 형태의 영상 신호를 디지털 형태의 영상 신호로 변환하여 출력할 수 있다. 특히, 제1 카메라 및 제2 카메라는 전자 장치의 전면 방향을 촬상하도록 배치되어, 전자 장치의 전면에 존 재하는 사용자를 촬상하여 촬상 영상을 생성할 수 있다. 프로세서는 전자 장치의 전반적인 제어 동작을 수행할 수 있다. 구체적으로, 프로세서는 전자 장치의 전반적인 동작을 제어하는 기능을 한다. 프로세서는 디지털 신호를 처리하는 디지털 시그널 프로세서(digital signal processor(DSP), 마이크로 프 로세서(microprocessor), TCON(Time controller)으로 구현될 수 있다. 다만, 이에 한정되는 것은 아니며, 중앙 처리장치(central processing unit(CPU)), MCU(Micro Controller Unit), MPU(micro processing unit), 컨트롤 러(controller), 어플리케이션 프로세서(application processor(AP)), GPU(graphics-processing unit) 또는 커 뮤니케이션 프로세서(communication processor(CP)), ARM 프로세서 중 하나 또는 그 이상을 포함하거나, 해당 용어로 정의될 수 있다. 또한, 프로세서는 프로세싱 알고리즘이 내장된 SoC(System on Chip), LSI(largescale integration)로 구현될 수도 있고, FPGA(Field Programmable gate array) 형태로 구현될 수도 있다. 또 한, 프로세서는 메모리에 저장된 컴퓨터 실행가능 명령어(computer executable instructions)를 실행함으 로써 다양한 기능을 수행할 수 있다. 상술한 목적을 달성하기 위한 본 실시 예에 따른 전자 장치는 제1 촬상각을 갖는 제1 카메라, 제1 촬 상각보다 큰 제2 촬상각을 갖는 제2 카메라 및 제1 카메라로부터 획득된 제1 촬상 이미지 또는 제2 카메라로부터 획득된 제2 촬상 이미지에서 타겟 오브젝트의 일 부분(장애물 오브젝트에 가려져 있지 않은 영역)이 식별되고 타겟 오브젝트의 나머지 일 부분(장애물 오브젝트에 가려져 있는 영역)에 오버랩되는 장애물 오브젝트가 식별되면, 식별된 장애물 오브젝트의 위치 정보를 획득하고, 획득된 장애물 오브젝트의 위치 정보에 기초하여 제2 촬상 이미지의 관심 영역을 식별하고 제2 카메라로부터 획득된 제2 촬상 이미지의 관심 영역 에 기초하여 타겟 오브젝트의 나머지 일 부분을 식별하는 프로세서를 포함한다. 여기서, 제1 카메라는 협각 렌즈를 이용하여 제1 촬상각으로 촬상하는 협각 카메라일 수 있다. 여기서, 제 2 카메라는 광각 렌즈를 이용하여 제2 촬상각으로 촬상하는 광각 카메라일 수 있다. 따라서, 제2 카메라 는 광각 카메라에 해당하므로, 제2 촬상각은 제1 촬상각보다 클 수 있다. 본 개시의 촬상은 촬영으로 대체 될 수 있다. 프로세서는 제1 카메라를 통해 촬상된 제1 촬상 이미지를 획득할 수 있고, 제2 카메라를 통해 촬상된 제2 촬상 이미지를 획득할 수 있다. 여기서, 제1 카메라를 통해 획득한 이미지는 협각 이미지일 수 있고, 제2 카메라를 통해 획득한 이미지는 광각 이미지일 수 있다. 장애물 오브젝트를 식별하는 동작에 이용되는 제1 촬상 이미지와 관심 영역을 식별하는데 이용되는 제2 촬상 이 미지는 서로 다른 촬상 위치에서 촬상된 이미지일 수 있다. 일 예로, 제1 촬상 이미지는 장애물 오브젝트의 정 면에서 촬상된 협각 이미지일 수 있고, 제2 촬상 이미지는 장애물 오브젝트의 측면(또는 대각선 방향)에서 촬상 된 광각 이미지일 수 있다. 한편, 서로 다른 촬상 위치에서 획득되는 이미지들에 대한 설명은 도 5 내지 도 9에 서 후술한다. 따라서, 프로세서는 제1 촬상 이미지를 통해 식별하지 못한 타겟 오브젝트의 나머지 일 부분을 제2 촬상 이미지를 통해 식별할 수 있다. 프로세서는 이미지에 포함된 오브젝트가 타겟 오브젝트인지 여부를 판다하기 위하여 반드시 타겟 오브젝트 의 모든 영역이 필요한 것은 아니다. 예를 들어, 3cm * 4cm의 라벨을 타겟 오브젝트로 기 결정하였다고 가정한 다. 프로세서가 획득되는 이미지에서 3cm * 4cm의 라벨을 식별하기 위하여 라벨 전체가 이미지에 포함되어 야 하는 것은 아니다. 예를 들어, 라벨의 일부가 이미지에 포함되어 있는 경우에도 프로세서는 이미지에 라벨이 포함된 것으로 식별될 수 있다. 다만, 프로세서는 라벨이 장애물에 의해 가려져 있거나 라벨이 일 부만 촬상된 것으로 식별할 수 있다. 프로세서는 촬상된 제1 촬상 이미지 또는 제2 촬상 이미지 중 적어도 하나의 이미지로부터 타겟 오브젝트 의 일 부분(예를 들어, 라벨의 일부)을 식별할 수 있다. 여기서, 타겟 오브젝트(예를 들어, 라벨)는 사용자가 인식하고자 하는 오브젝트를 의미할 수 있다. 타겟 오브젝트는 기 결정된 형태(예를 들어, 3cm * 4cm)를 포함할 수 있다. 여기서, 기 결정된 형태는 기 결정된 크기를 갖는 사각형 모양일 수 있다. 프로세서는 획득된 이 미지에서 기 결정된 크기를 갖는 사각형 모양을 식별할 수 있다. 본 개시의 주요 실시 예는 타겟 오브젝트 앞에 장애물 오브젝트가 놓여져 있는 상황을 가정한다. 장애물 오브젝 트가 타겟 오브젝트를 가리는 경우, 촬상된 이미지에서 타겟 오브젝트는 일 부분만이 식별될 수 있다. 하지만, 프로세서는 일 부분만으로도 타겟 오브젝트인지 여부를 식별할 수 있다. 또한, 식별된 타겟 오브젝트의 일 부분 이외의 나머지 일 부분은 장애물 오브젝트에 의해 오버랩될 수 있다. 여 기서, 프로세서는 장애물 오브젝트를 식별할 수 있다. 그리고, 프로세서는 식별된 장애물 오브젝트의 위치 정보를 획득할 수 있다. 또한, 프로세서는 식별된 장애물 오브젝트의 위치 정보에 기초하여 제2 촬상 이미지의 관심 영역을 식별할 수 있다. 여기서, 관심 영역(Region of Interest)은 획득되는 전체 이미지 영역 중 사용자의 의도에 대응되는 일부 영역을 의미할 수 있다. 여기서, 관심 영역은, 타겟 오브젝트 또는 장애물 오브젝트 중 적어도 하나를 포 함하는 영역을 의미할 수 있다. 일 예로, 관심 영역은 타겟 오브젝트가 포함되는 영역일 수 있으며, 다른 예로, 타겟 오브젝트 및 장애물 오브젝트가 모두 포함되는 영역일 수 있다.관심 영역을 설정하는 경우 이미지 분석 및 이미지 처리에 있어 처리량 및 속도를 향상시킬 수 있다. 예를 들어, 장애물 오브젝트의 위치 정보가 전체 촬상 범위에서 우측에 있다고 가정한다. 프로세서는 장애물 오 브젝트의 위치 정보에 기초하여 제2 촬상 이미지에서 관심 영역을 우측 영역으로 설정할 수 있다. 프로세서는 제2 촬상 이미지의 관심 영역에 기초하여 타겟 오브젝트의 나머지 일 부분을 식별할 수 있다. 여기서, 나머지 일 부분은 제1 촬상 이미지에서 장애물 오브젝트에 의해 가려졌던 부분을 의미할 수 있다. 한편, 프로세서는 제1 촬상 이미지에서 타겟 오브젝트 및 장애물 오브젝트가 포함된 영역 및 제2 촬상 이 미지의 관심 영역에 기초하여 타겟 오브젝트의 전체 이미지를 포함하는 결합 이미지를 획득할 수 있고, 획득된 결합 이미지에 기초하여 타겟 오브젝트를 식별할 수 있다. 프로세서는 타겟 오브젝트에 대한 정보를 완전히 획득하기 위하여 제1 촬상 이미지뿐 아니라 제2 촬상 이 미지를 함께 이용해야 한다. 특히, 프로세서는 데이터 처리 속도를 빨리 하기 위하여 제2 촬상 이미지에서 관심 영역을 설정할 수 있다. 프로세서는 제1 촬상 이미지 및 제2 촬상 이미지를 결합하되 장애물 오브젝 트를 제거하여 결합 이미지를 생성할 수 있다. 여기서, 결합 이미지는 장애물 오브젝트가 제거되었다는 점에서 가상의 이미지를 의미할 수 있다. 결합 이미지 생성 동작은 도 10 내지 도 12에서 후술한다. 한편, 제1 촬상 이미지는 제1 촬상 위치에서 제1 카메라에 의해 촬상된 이미지이고, 제2 촬상 이미지는 제 1 촬상 위치와 상이한 제2 촬상 위치에서 제2 카메라에 의해 촬상된 이미지일 수 있다. 여기서, 제1 촬상 위치는 장애물 오브젝트의 정면에 대응되는 위치일 수 있다. 예를 들어, 제1 촬상 위치는 도 8의 제2 촬상 위치일 수 있다. 제2 촬상 위치는 장애물 오브젝트의 측면에 대응되는 위치일 수 있다. 예를 들어, 제2 촬상 위치는 도 7의 제1 촬상 위치 또는 도 9의 제3 촬상 위치일 수 있다. 2개의 촬상 이 미지에 따라 관심 영역을 설정하는 동작은 도 12에서 후술한다. 한편, 프로세서는 제1 촬상 위치 및 제2 촬상 위치와 상이한 제3 촬상 위치에서 제2 카메라로부터 촬 상된 제3 촬상 이미지를 획득할 수 있고, 식별된 장애물 오브젝트의 위치 정보에 기초하여 제3 촬상 이미지의 관심 영역을 식별할 수 있고, 제2 촬상 이미지의 관심 영역 및 제3 촬상 이미지의 관심 영역에 기초하여 타겟 오브젝트의 나머지 일 부분을 식별할 수 있다. 여기서, 제1 촬상 이미지는 제1 촬상 위치에서 획득된 것이고 제2 촬상 이미지는 제2 촬상 위치에서 획득된 것 이고, 제3 촬상 이미지는 제3 촬상 위치에서 획득된 것일 수 있다. 여기서, 제1 촬상 위치 내지 제3 촬상 위치 가 모두 상이할 수 있다. 프로세서는 제3 촬상 이미지에 대해서 관심 영역을 식별할 수 있다. 구체적으로, 프로세서는 제3 촬상 이미지에서 장애물 오브젝트를 식별하고, 식별된 장애물 오브젝트에 대응되는 영역을 관심 영역으로 식별할 수 있다. 그리고, 프로세서는 제2 촬상 이미지의 관심 영역 및 제3 촬상 이미지의 관심 영역에 기초하여 타겟 오브젝트의 나머지 일 부분(제1 촬상 이미지에서 장애물 오브젝트에 가려진 부분)을 식별할 수 있다. 또한, 프로세서는 타겟 오브젝트의 전체 부분을 식별하기 위하여 제1 촬상 이미지의 일 부분을 이용할 수 있다. 예를 들어, 프로세서는 제1 촬상 이미지의 일 부분(장애물 오브젝트에 의해 가려 지지 않은 부분)과 제2 촬상 이미지의 관심 영역 및 제3 촬상 이미지의 관심 영역을 모두 고려하여 타겟 오브젝 트의 나머지 일 부분을 식별할 수 있다. 3개의 촬상 이미지에 따라 관심 영역을 설정하는 동작은 도 11에서 후 술한다. 한편, 제2 촬상 위치는 제1 촬상 위치를 기준으로 제1 방향에 위치할 수 있고, 제3 촬상 위치는 제1 촬상 위치 를 기준으로 제1 방향과 상이한 제2 방향에 위치할 수 있다. 제1 촬상 위치는 제1 촬상 이미지인 협각 이미지가 획득되는 위치일 수 있으며 장애물 오브젝트의 정면에 해당 하는 위치일 수 있다. 제2 촬상 위치 및 제3 촬상 위치는 장애물 오브젝트를 기준으로 상이한 대각선 측면 방향 에 해당하는 위치일 수 있다. 예를 들어, 제2 촬상 위치는 제1 촬상 위치(장애물 오브젝트의 정면)에서 (전자 장치에서 장애물 오브젝트를 향하는 기준에서) 왼쪽에 해당하는 위치일 수 있다. 다만, 제3 촬상 위치는 제1 촬상 위치(장애물 오브젝트의 정면)에서 (전자 장치에서 장애물 오브젝트를 향하는 기준에서) 오른쪽 에 해당하는 위치일 수 있다. 한편, 프로세서는 제2 촬상 이미지가 촬상된 방향 정보 및 장애물 오브젝트의 위치 정보에 기초하여 제2 촬상 이미지의 관심 영역을 식별할 수 있고, 제3 촬상 이미지가 촬상된 방향 정보 및 장애물 오브젝트의 위치 정보에 기초하여 제3 촬상 이미지의 관심 영역을 식별할 수 있다. 여기서, 제2 촬상 이미지가 촬상된 방향 정보는 제1 촬상 위치를 기준으로 좌측에 해당한다. 또한, 제2 촬상 이 미지가 촬상된 방향 정보는 촬상 방향을 기준으로 우측 5도 내지 10도일 수 있다. 또한, 제3 촬상 이미지가 촬 상된 방향 정보는 제1 촬상 위치를 기준으로 우측에 해당할 수 있다. 또한, 제3 촬상 이미지가 촬상된 방향 정 보는 촬상 방향을 기준으로 좌측 5도 내지 10도일 수 있다. 예를 들어, 도 12에서 광각 이미지의 관심 영역은 전체 이미지 중 우측에 위치할 수 있으며, 광각 이미지의 관심 영역은 전체 이미지 중 좌측에 위치할 수 있다. 한편, 프로세서는 제1 촬상 이미지에서 식별된 타겟 오브젝트의 일 부분에 기초하여 타겟 오브젝트의 제1 정보(제1 촬상 이미지를 기준으로 장애물에 가려져 있지 않았던 영역에 대응되는 정보)를 획득할 수 있고, 제2 촬상 이미지에서 식별된 타겟 오브젝트의 나머지 일 부분에 기초하여 타겟 오브젝트의 제2 정보(제1 촬상 이미 지를 기준으로 장애물에 가려져 식별 할 수 없었던 정보)를 획득할 수 있다. 프로세서는 각각의 촬상 이미지에서 동일한 오브젝트를 식별함에도 불과하고 서로 다른 정보를 획득할 수 있다. 제1 촬상 이미지에 포함된 타겟 오브젝트가 일부 가려져 있기 때문이다. 따라서, 프로세서는 제1 카 메라를 통해 획득한 제1 촬상 이미지에서 타겟 오브젝트의 일부 정보(제1 정보)를 획득하고, 제2 카메라 를 통해 획득한 제2 촬상 이미지에서 타겟 오브젝트의 나머지 정보(제2 정보)를 획득할 수 있다. 한편, 프로세서는 제1 촬상 이미지에 기초하여 장애물 오브젝트의 위치 정보 및 크기 정보를 식별할 수 있 고, 식별된 장애물 오브젝트의 위치 정보 및 크기 정보에 기초하여 제2 카메라의 촬상 위치를 식별할 수 있고, 제2 촬상 이미지는 식별된 촬상 위치에서 촬상된 이미지일 수 있다. 프로세서는 장애물의 위치 정보 및 크기 정보에 기초하여 어느 위치에 대응되는 제2 촬상 이미지를 식별할 것인지 결정할 수 있다. 만약, 장애물 오브젝트의 크기가 커지면 제2 촬상 이미지가 식별되는 제2 촬상 위치는 제1 촬상 위치로부터 더 멀어질 수 있다. 만약, 장애물 오브젝트의 크기가 작아지면 제2 촬상 이미지가 식별되 는 제2 촬상 위치는 제1 촬상 위치로부터 더 가까워질 수 있다. 즉, 제1 촬상 위치 및 제2 촬상 위치 사이의 거 리는 장애물 오브젝트의 크기에 비례할 수 있다. 여기서, 프로세서는 전자 장치의 이동 및 카메라 모듈의 배치 구조에 기초하여 장애물의 위치 정보 및 크기 정보를 식별할 수 있다. 여기서, 카메라 모듈의 배치 구조는 제1 카메라 및 제2 카메라 간 지오메트리(geometry)를 의미할 수 있다. 한편, 전자 장치는 발광부를 더 포함할 수 있고, 프로세서는 제1 촬상 이미지의 관심 영역을 식 별할 수 있고, 제1 촬상 이미지의 관심 영역 및 제2 촬상 이미지의 관심 영역에 인접한 영역에 대응되는 위치를 식별할 수 있고, 식별된 위치로 임계 세기 이상의 광을 조사하도록 발광부를 제어할 수 있다. 발광부와 관련된 구체적인 동작은 도 14 내지 도 19에서 후술한다. 한편, 프로세서는 식별된 위치로 광이 조사되도록 발광부의 발광 각도를 변경할 수 있다. 일 실시 예에 따라, 조사 영역은 관심 영역에 따라 변경될 수 있다. 프로세서는 타겟 오브젝트 및 장애물 오브젝트에 기초하여 촬상 이미지에서 관심 영역을 식별할 수 있다. 따라서, 관심 영역이 변경되면 조사 영역도 변경될 수 있다. 프로세서는 변경되는 조사 영역에 빛을 조사하기 위하여 발광부의 발광 각도를 변경 할 수 있다. 다른 실시 예에 따라, 조사 영역은 기존에 저장된 데이터에 따라 결정되고, 프로세서는 결정된 조사 영역 에 빛이 조사되도록 발광부를 제어할 수 있다. 여기서, 하나의 운행 동작이 이루어지는 동안 조사 영역은 고정될 수 있다. 예를 들어, 프로세서는 제1 운행시 저장하였던 관심 영역의 기록들을 종합하여 가장 최적 의 조사 영역을 결정할 수 있고, 제2 운행시 결정된 조사 영역에 빛을 조사할 수 있다. 한편, 다른 실시 예에 따라, 발광부는 최적화된 각도로 광이 조사되도록 배치될 수 있다. 예를 들어, 사용 자가 다양한 데이터를 통하여 조사 영역을 결정할 수 있고, 조사 영역에 빛을 조사하기 위한 최적의 발광 각도 를 결정할 수 있다. 그리고, 발광부는 최적의 발광 각도로 조사되도록 배치될 수 있다. 예를 들어, 발광부 에 포함된 발광 모듈이 정면을 기준으로 좌측 5도를 향하도록 배치될 수 있다. 여기서, 좌측 5도는 최적의 발광 각도에 해당할 수 있으며, 사용자 설정에 따라 최적의 발광 각도는 변경될 수 있다. 한편, 본 개시의 일 실시 예에 따른 전자 장치는 협각 이미지를 통해 장애물 오브젝트를 식별하고, 협각 이미지를 통해 장애물 오브젝트가 식별되면 보조적으로 광각 이미지를 이용하여 타겟 오브젝트를 분석할 수 있 다. 특히, 협각 이미지는 제1 촬상 위치에서 획득된 것이며 광각 이미지는 제1 촬상 위치와 다른 제2 촬상 위치에서 획득된 것이므로 상호 보완적일 수 있다. 따라서, 전자 장치는 장애물 오브젝트에 가려진 타겟 오브 젝트를 분석할 수 있다. 한편, 본 개시의 일 실시 예에 따른 전자 장치는 관심 영역 사이의 공간을 조사 영역으로 결정하여 최대 세기의 빛을 조사할 수 있다. 관심 영역이 아닌 공간에 최대 세기의 빛을 조사함으로써 전자 장치는 오브 젝트에 반사되는 빛의 양을 최소한으로 줄일 수 있다. 따라서, 이미지에 포함된 타겟 오브젝트의 인식률을 높일 수 있다. 여기서, 최대 세기의 빛은 전자 장치가 현재 조사할 수 있는 빛에서 가장 밝은 빛을 의미할 수 있다. 또한, 최대 세기의 빛은 조명 피크(peak)에 해당할 수 있다. 다른 구현 예에 따라, 전자 장치는 적 정 세기의 빛을 조사 영역에 조사할 수 있다. 한편, 본 개시의 일 실시 예에 따른 전자 장치는 장애물 오브젝트에 의해 타겟 오브젝트의 정보를 정확히 식별하지 못하는 것을 하나의 이벤트로 식별할 수 있다. 따라서, 기 설정된 이벤트가 식별되면, 전자 장치(10 0)는 적절한 광각 이미지를 선택하여 스티칭 동작을 통한 결합 이미지를 생성할 수 있다. 여기서, 기 설정된 이 벤트는 타겟 오브젝트가 장애물 오브젝트에 가려져 있는 이벤트, 타겟 오브젝트의 정보가 식별되지 않는 이벤트, 바코드가 장애물 오브젝트에 가려져 있는 이벤트 등이 있을 수 있다. 한편, 기 설정된 임계 시간 동안 기 설정된 이벤트가 발생하지 않는 경우, 전자 장치는 메모리에 저 장된 복수의 이미지(다양한 위치에서 촬상된 이미지들)를 삭제할 수 있다. 계속하여 반복적으로 모든 위치에서 촬상된 이미지를 저장하는 것은 비효율일 수 있다. 따라서, 전자 장치는 프로세서를 통해 임계 시간 이상 기 설정된 이벤트가 발생하지 않는 경우, 저장된 복수의 이미지를 삭제할 수 있다. 다른 실시 예에 따라, 전자 장치는 이미지의 촬상 시간이 임계 시간이상 경과한 이미지를 삭제할 수 있다. 예를 들어, 전자 장치는 촬상된지 10초 이상 지난 이미지를 자동으로 삭제할 수 있다. 한편, 프로세서는 제1 카메라 또는 제2 카메라 중 적어도 하나의 카메라로부터 획득된 촬상 이 미지에 기초하여 타겟 오브젝트의 일 부분을 식별하면, 타겟 오브젝트의 나머지 일 부분(장애물 오브젝트에 가 려져 있는 영역)에 오버랩되는 장애물 오브젝트를 식별하기 위하여 촬상 이미지를 분석할 수 있다. 프로세서 는 획득되는 제1 촬상 이미지 또는 제2 촬상 이미지 중 적어도 하나의 촬상 이미지에서 타겟 오브젝트가 일부라도 식별된 경우에 한하여 장애물 오브젝트의 위치를 식별할 수 있다. 한편, 또 다른 구현 예에 따라, 타겟 오브젝트의 일부가 식별되지 않더라도 폴로노그램 또는 기존 선반 데이터 를 이용하여 장애물 오브젝트를 식별할 수 있다. 한편, 이상에서는 전자 장치를 구성하는 간단한 구성에 대해서만 도시하고 설명하였지만, 구현 시에는 다 양한 구성이 추가로 구비될 수 있다. 이에 대해서는 도 3을 참조하여 이하에서 설명한다. 도 3은 도 2의 전자 장치의 구체적인 구성을 설명하기 위한 블록도이다. 도 3을 참조하면, 전자 장치는 제1 카메라, 제2 카메라, 프로세서, 디스플레이, 통신 인터페이스, 메모리, 마이크 및 스피커로 구성될 수 있다. 한편, 제1 카메라, 제2 카메라 및 프로세서의 동작 중에서 앞서 설명한 것과 동일한 동작에 대 해서는 중복 설명은 생략한다. 제1 카메라 및 제2 카메라는 카메라 모듈에 포함될 수 있다. 카메라 모듈은 하나의 하드웨 어로 구성될 수 있으며, 제1 카메라 및 제2 카메라는 하나의 카메라 모듈에 나란히 배치된 형태 로 구현될 수 있다. 발광부는 기 결정된 영역 또는 기 결정된 방향으로 빛을 조사하는 모듈을 의미할 수 있다. 여기서, 발광부 는 촬상 동작에 이용되는 카메라 플래시를 의미할 수 있으며, 램프, 발광 다이오드 형태로 구현될 수 있다. 또한, 발광부는 조명 모듈로 표현될 수 있다. 디스플레이는 LCD(Liquid Crystal Display), OLED(Organic Light Emitting Diodes) 디스플레이, PDP(Plasma Display Panel) 등과 같은 다양한 형태의 디스플레이로 구현될 수 있다. 디스플레이내에는 a- si TFT, LTPS(low temperature poly silicon) TFT, OTFT(organic TFT) 등과 같은 형태로 구현될 수 있는 구동 회로, 백라이트 유닛 등도 함께 포함될 수 있다. 한편, 디스플레이는 터치 센서와 결합된 터치 스크린, 플 렉시블 디스플레이(flexible display), 3차원 디스플레이(3D display) 등으로 구현될 수 있다. 또한, 본 개시의 일 실시 예에 따른, 디스플레이는 영상을 출력하는 디스플레이 패널뿐만 아니라, 디스플 레이 패널을 하우징하는 베젤을 포함할 수 있다. 특히, 본 개시의 일 실시 예에 따른, 베젤은 사용자 인터렉션 을 감지하기 위한 터치 센서(미도시)를 포함할 수 있다. 통신 인터페이스는 다양한 유형의 통신 방식에 따라 다양한 유형의 외부 장치와 통신을 수행하는 구성이다. 통신 인터페이스는 와이파이 모듈, 블루투스 모듈, 적외선 통신 모듈 및 무선 통신 모듈 등을 포함한다. 여기서, 각 통신 모듈은 적어도 하나의 하드웨어 칩 형태로 구현될 수 있다. 와이파이 모듈, 블루투스 모듈은 각각 WiFi 방식, 블루투스 방식으로 통신을 수행한다. 와이파이 모듈이나 블루 투스 모듈을 이용하는 경우에는SSID 및 세션 키 등과 같은 각종 연결 정보를 먼저 송수신하여, 이를 이용하여 통신 연결한 후 각종 정보들을 송수신할 수 있다. 적외선 통신 모듈은 가시 광선과 밀리미터파 사이에 있는 적외선을 이용하여 근거리에 무선으로 데이터를 전송 하는 적외선 통신(IrDA, infrared Data Association)기술에 따라 통신을 수행한다. 무선 통신 모듈은 상술한 통신 방식 이외에 지그비(zigbee), 3G(3rd Generation), 3GPP(3rd Generation Partnership Project), LTE(Long Term Evolution), LTE-A(LTE Advanced), 4G(4th Generation), 5G(5th Generation)등과 같은 다양한 무선 통신 규격에 따라 통신을 수행하는 적어도 하나의 통신 칩을 포함할 수 있다. 그 밖에 통신 인터페이스는LAN(Local Area Network) 모듈, 이더넷 모듈, 페어 케이블, 동축 케이블, 광섬 유 케이블 또는 UWB(Ultra Wide-Band) 모듈 등을 이용하여 통신을 수행하는 유선 통신 모듈 중 적어도 하나를 포함할 수 있다. 일 예에 따라 통신 인터페이스는 리모컨과 같은 외부 장치 및 외부 서버와 통신하기 위해 동일한 통신 모 듈(예를 들어, Wi-Fi 모듈)을 이용할 수 있다. 다른 예에 따라 통신 인터페이스는 리모컨과 같은 외부 장치 및 외부 서버와 통신하기 위해 상이한 통신 모듈(예를 들어, Wi-Fi 모듈)을 이용할 수 있다. 예를 들어, 통신 인터페이스는 외부 서버와 통신하기 위 해 이더넷 모듈 또는 WiFi 모듈 중 적어도 하나를 이용할 수 있고, 리모컨과 같은 외부 장치와 통신하기 위해 BT 모듈을 이용할 수도 있다. 다만 이는 일 실시 예에 불과하며 통신 인터페이스는 복수의 외부 장치 또는 외부 서버와 통신하는 경우 다양한 통신 모듈 중 적어도 하나의 통신 모듈을 이용할 수 있다. 메모리는 프로세서에 포함된 롬(ROM)(예를 들어, EEPROM(electrically erasable programmable read- only memory)), 램(RAM) 등의 내부 메모리로 구현되거나, 프로세서와 별도의 메모리로 구현될 수도 있다. 이 경우, 메모리는 데이터 저장 용도에 따라 전자 장치에 임베디드된 메모리 형태로 구현되거나, 전 자 장치에 탈부착이 가능한 메모리 형태로 구현될 수도 있다. 예를 들어, 전자 장치의 구동을 위한 데이터의 경우 전자 장치에 임베디드된 메모리에 저장되고, 전자 장치의 확장 기능을 위한 데이터의 경우 전자 장치에 탈부착이 가능한 메모리에 저장될 수 있다. 한편, 전자 장치에 임베디드된 메모리의 경우 휘발성 메모리(예: DRAM(dynamic RAM), SRAM(static RAM), 또는 SDRAM(synchronous dynamic RAM) 등), 비휘발성 메모리(non-volatile Memory)(예: OTPROM(one time programmable ROM), PROM(programmable ROM), EPROM(erasable and programmable ROM), EEPROM(electrically erasable and programmable ROM), mask ROM, flash ROM, 플래시 메모리(예: NAND flash 또는 NOR flash 등), 하드 드라이브, 또는 솔리드 스테이트 드라이브(solid state drive(SSD)) 중 적어도 하나로 구현되고, 전자 장 치에 탈부착이 가능한 메모리의 경우 메모리 카드(예를 들어, CF(compact flash), SD(secure digital), Micro-SD(micro secure digital), Mini-SD(mini secure digital), xD(extreme digital), MMC(multi-media card) 등), USB 포트에 연결 가능한 외부 메모리(예를 들어, USB 메모리) 등과 같은 형태로 구현될 수 있다. 전자 장치는 마이크를 더 포함할 수 있다. 마이크는 사용자 음성이나 기타 소리를 입력받아 오디오 데이터로 변환하기 위한 구성이다. 마이크는 활성화 상태에서 사용자의 음성을 수신할 수 있다. 예를 들어, 마이크는 전자 장치의 상측이나 전면 방향, 측면 방향 등에 일체형으로 형성될 수 있다. 마이크는 아날로그 형태의 사용자 음성 을 수집하는 마이크, 수집된 사용자 음성을 증폭하는 앰프 회로, 증폭된 사용자 음성을 샘플링하여 디지털 신호 로 변환하는 A/D 변환회로, 변환된 디지털 신호로부터 노이즈 성분을 제거하는 필터 회로 등과 같은 다양한 구 성을 포함할 수 있다. 전자 장치는 스피커를 포함할 수 있다. 스피커는 입출력 인터페이스에서 처리된 각종 오디오 데 이터뿐만 아니라 각종 알림 음이나 음성 메시지 등을 출력하는 구성요소일 수 있다. 도 4는 본 개시의 일 실시 예에 따른 전자 장치에 포함된 카메라 모듈을 설명하기 위한 도면이다. 도 4를 참조하면, 전자 장치는 카메라 모듈을 포함할 수 있다. 그리고, 카메라 모듈은 제1 카메 라, 제2 카메라 및 발광부를 포함할 수 있다. 그리고, 전자 장치는 전자 장치의 하단 부에 바퀴를 포함할 수 있으며, 전자 장치는 바퀴를 이용하여 이동할 수 있다. 한편, 제1 카메라, 제2 카메라 및 발광부의 배치 위치는 구현 예에 따라 상이할 수 있다. 도 5는 전자 장치가 타겟 오브젝트 및 장애물 오브젝트를 식별하는 동작을 설명하기 위한 도면이다. 도 5를 참조하면, 전자 장치는 제1 카메라 및 제2 카메라를 이용하여 전방을 촬상할 수 있다. 여기서, 제1 카메라 및 제2 카메라는 카메라 모듈에 포함될 수 있다. 전자 장치의 전방에 A라벨, B라벨, C라벨이 있으며, A라벨에 대응되는 A제품, B라벨에 대응되는 B제품, C라벨에 대응되는 C제품이 존재한다고 가정한다. 여기서, A라벨 , B라벨, C라벨은 제1라벨, 제2라벨, 제3라벨로 표현될 수 있다. 또한, A제품, B제품 , C제품은 제1제품, 제2제품, 제3제품으로 표현될 수 있다. 여기서, 타겟 오브젝트는 사용자가 기 결정한 형태의 오브젝트를 의미할 수 있다. 일 예로, 타겟 오브젝트는 한 개일 수 있다. 사용자는 특정 크기의 사각형 형태의 라벨을 타겟 오브젝트로 설정할 수 있다. 예를 들어, 타겟 오브젝트는 A라벨, B라벨 및 C라벨일 수 있다. 다른 예로, 타겟 오브젝트는 복수 개일 수 있다. 사용자는 특정 크기의 사각형 형태의 라벨을 타겟 오브젝트로 설정하고 라벨로부터 임계 거리 이내에 있는 제품을 타겟 오브젝트로 설정할 수 있다. 예를 들어, 타겟 오브젝 트는 A라벨, B라벨, C라벨, A제품, B제품 및 C제품일 수 있다. 또 다른 예로, 전자 장치는 타겟 오브젝트를 그룹별로 인식할 수 있다. 전자 장치는 A라벨 및 A 제품을 포함하는 제1 그룹을 타겟 오브젝트로 인식하고, B라벨 및 B제품을 포함하는 제2 그룹을 타겟 오브젝트로 인식하고, C라벨 및 C제품을 포함하는 제3 그룹을 타겟 오브젝트로 인식할 수 있다. 한편, 타겟 오브젝트와 인접한 공간에 장애물 오브젝트가 존재하는 상황을 가정한다. 장애물 오브젝트 는 타겟 오브젝트의 일부를 가릴 수 있다. 따라서, 촬상된 이미지에서 B라벨, B제품의 전체 영 역이 식별되지 않고 일부 영역만 식별될 수 있다. 한편, 전자 장치는 제1 카메라 및 제2 카메라가 타겟 오브젝트를 바라보는 방향을 기준으로 좌 측에서 우측으로 이동할 수 있다. 이후 설명하는 도면에서는 전자 장치가 좌측에서 우측으로 이동하는 실 시 예를 기준으로 설명한다. 다만, 구현 예에 따라 이동 방향은 우측에서 좌측일 수 있다. 또한, 이동 방향은 타겟 오브젝트에 가까워지거나 멀어지는 방향일 수 있다. 도 6은 타겟 오브젝트의 전체 영역을 식별하는 동작을 설명하기 위한 흐름도이다. 도 6을 참조하면, 전자 장치는 제1 카메라로부터 복수의 협각 이미지를 획득할 수 있다 (S605). 또한, 전자 장치는 제2 카메라로부터 복수의 광각 이미지를 획득할 수 있다 (S610). 여기서, 전자 장 치는 복수의 협각 이미지 및 복수의 광각 이미지 중 적어도 하나의 이미지로부터 타겟 오브젝트의 일부분 을 식별할 수 있다 (S615). 여기서, 타겟 오브젝트의 일부분은 장애물 오브젝트에 가려지지 않고 이미지에서 식 별되는 영역을 의미할 수 있다. 전자 장치는 장애물에 가려지지 않고 식별되는 타겟 오브젝트의 일부분에 기초하여 해당 오브젝트가 타겟 오브젝트임을 식별할 수 있다. 또한, 전자 장치는 타겟 오브젝트의 나머지 일 부분에 오버랩되는 장애물 오브젝트를 식별할 수 있다 (S620). 또한, 전자 장치는 획득된 장애물 오브 젝트의 위치 정보를 획득할 수 있다 (S625). 또한, 전자 장치는 장애물 오브젝트의 위치 정보에 기초하여 복수의 광각 이미지 중 타겟 오브젝트의 가장 많은 부분이 식별되는 광각 이미지를 식별할 수 있다 (S630). 또 한, 전자 장치는 식별된 광각 이미지에 기초하여 타겟 오브젝트의 나머지 일 부분을 식별할 수 있다 (S635). 예를 들어, 전자 장치는 제1 카메라 또는 제2 카메라로부터 획득된 복수의 이미지 중 적어도 하 나의 이미지에 기초하여 B라벨의 일부분을 식별할 수 있다. 전자 장치는 전체가 아닌 B라벨의일부만 식별된 경우에도 해당 오브젝트가 타겟 오브젝트인 것으로 식별할 수 있다. 또한, 전자 장치는 B라 벨의 나머지 일 부분을 가리고 있는 장애물 오브젝트를 식별할 수 있으며, 장애물 오브젝트의 위치 정보를 식별할 수 있다. 또한, 전자 장치는 이동 과정에서 저장했던 복수의 광각 이미지에서 장애물 오브젝트에 가려서 식별되지 않은 B라벨 의 나머지 일부분이 가장 많이 식별되는 광각 이미지를 식별 할 수 있다. 그리고, 전자 장치는 식별된 광각 이미지에 기초하여 장애물 오브젝트 에 의해 가려져 있던 B 라벨의 나머지 일부분을 식별할 수 있다. 도 7은 제1 촬상 위치에서 촬상된 이미지를 설명하기 위한 도면이다. 도 7을 참조하면, 전자 장치는 제1 촬상 위치에서 전방을 촬상할 수 있다. 여기서, 제1 촬상 위치 는 A라벨 및 A제품의 정면일 수 있다. 전자 장치는 제1 카메라 및 제2 카메라 를 통해 동일 시점의 촬상 이미지들을 획득할 수 있다. 전자 장치는 제1 카메라를 통해 A라벨 및 A제품이 포함된 협각 이미지를 획득할 수 있다. 여기서, 협각 이미지는 협각 렌즈로 촬상된 협각 이미지일 수 있다. 또한, 전자 장치는 제2 카메라를 통해 A라벨, A제품, B라벨 및 B제품이 포함된 광각 이미지를 획득할 수 있다. 여기서, 광각 이미지는 광각 렌즈로 촬상된 광각 이미지일 수 있다. 그리고, 광각 이미지에 포함된 B라벨 및 B제품은 장애물 오브젝트와 일부 오버랩될 수 있 다. 도 8은 제2 촬상 위치에서 촬상된 이미지를 설명하기 위한 도면이다. 도 8을 참조하면, 전자 장치는 제2 촬상 위치에서 전방을 촬상할 수 있다. 여기서, 제2 촬상 위치 는 B라벨 및 B제품의 정면일 수 있다. 전자 장치는 제1 카메라 및 제2 카메라 를 통해 동일 시점의 촬상 이미지들을 획득할 수 있다. 전자 장치는 제1 카메라를 통해 B라벨 및 B제품이 포함된 협각 이미지를 획득할 수 있다. 여기서, 협각 이미지는 협각 렌즈로 촬상된 협각 이미지일 수 있다. 또한, 전자 장치는 제2 카메라를 통해 A라벨, A제품, B라벨, B제품, C라벨 및 C제품이 포함된 광각 이미지를 획득할 수 있다. 여기서, 광각 이미지는 광각 렌즈로 촬상된 광각 이미지일 수 있다. 그리고, 광각 이미지에 포함된 B라벨 및 B제품은 장애물 오브젝 트와 일부 오버랩될 수 있다. 여기서, A라벨, A제품, C라벨 및 C제품은 장애물 오브 젝트와 오버랩되지 않을 수 있다. 도 9는 제3 촬상 위치에서 촬상된 이미지를 설명하기 위한 도면이다. 도 9를 참조하면, 전자 장치는 제3 촬상 위치에서 전방을 촬상할 수 있다. 여기서, 제3 촬상 위치 는 C라벨 및 C제품의 정면일 수 있다. 전자 장치는 제1 카메라 및 제2 카메라 를 통해 동일 시점의 촬상 이미지들을 획득할 수 있다. 전자 장치는 제1 카메라를 통해 C라벨 및 C제품이 포함된 협각 이미지를 획득할 수 있다. 여기서, 협각 이미지는 협각 렌즈로 촬상된 협각 이미지일 수 있다. 또한, 전자 장치는 제2 카메라를 통해 B라벨, B제품, C라벨 및 C제품이 포함된 광각 이미지를 획득할 수 있다. 여기서, 광각 이미지는 광각 렌즈로 촬상된 광각 이미지일 수 있다. 그리고, 광각 이미지에 포함된 B라벨 및 B제품은 장애물 오브젝트와 일부 오버랩될 수 있 다. 도 10은 결합 이미지를 생성하는 동작을 설명하기 위한 흐름도이다. 도 10을 참조하면, 전자 장치는 다양한 위치에서 촬상된 복수의 협각 이미지 및 복수의 광각 이미지를 메 모리에 저장할 수 있다. 여기서, 전자 장치는 복수의 협각 이미지 중 장애물 오브젝트가 포함된 협각 이미지를 식별할 수 있다 (S1005). 여기서, 협각 이미지는 협각 렌즈를 포함하는 제1 카메라로부터 획득된 이미지를 의미할 수 있다. 따라서, 전자 장치는 협각 이미지인 협각 이미지에 기초하여 장애물 오브젝트를 식별할 수 있다. 여기서, 협각 이미지는 정면의 객체를 촬상하는 이미지일 수 있다. 또한, 전자 장치는 메모리에 저장된 복수의 광각 이미지 중 타겟 오브젝트의 가장 많은 부분이 식별 되는 광각 이미지를 식별할 수 있다 (S1010). S1005 단계를 통하여 전자 장치는 장애물 오브젝트가 전방에 위치한다는 것을 판단할 수 있다. 또한, 전자 장치는 다른 촬상 위치에서 촬상된 이미지를 통하여 장애물 에 가려져 있는 타겟 오브젝트의 일부 영역을 식별할 수 있다. 장애물에 가려져 있는 부분을 판단하기 위해서, 전자 장치는 광각이미지인 광각 이미지 중 타겟 오브젝트의 가장 많은 부분이 식별되는 이미지를 식별할 수 있다. 여기서, 전자 장치는 단순히 타겟 오브젝트의 가장 많은 부분이 식별되는 이미지를 찾는 것이 아 니며, 동시에 해당 부분에 대한 분석이 가능한 정도의 선명도를 갖는 이미지를 찾는 것일 수 있다. 또한, 전자 장치는 식별된 협각 이미지 또는 식별된 광각 이미지 중 적어도 하나의 이미지에 기초하여 결 합 이미지를 생성할 수 있다 (S1015). 여기서, 광각 이미지는 복수 개의 광각 이미지를 포함할 수 있다. 여기서, 결합 이미지는 장애물 오브젝트가 포함되지 않는 이미지일 수 있다. 즉, 타겟 오브젝트 앞에 장애물 오 브젝트가 있는 실시 예에서, 전자 장치는 가상의 이미지인 결합 이미지를 생성하여 장애물 오브젝트가 없 이 타겟 오브젝트만 존재하는 이미지를 획득할 수 있다. 예를 들어, B라벨 및 B제품 앞에 장애물 오브젝트가 존재하는 실시 예에서, 전자 장치는 제2 촬상 위치에서 협각 이미지를 획득할 수 있다. 그리고, 전자 장치는 협각 이미지에 기 초하여 장애물 오브젝트가 B라벨 및 B제품에 있는 것으로 식별할 수 있다. 전자 장치는 협 각 이미지를 통해 B라벨 및 B제품에 대한 완전한 정보를 획득할 수 없다. 협각 이미지에 포함된 B라벨 및 B제품은 장애물 오브젝트와 일부 오버랩되기 때문이다. 따라서, 전자 장치 는 다른 위치(또는 다른 각도)에서 촬상된 이미지를 추가적으로 이용할 수 있다. 구체적으로, 전자 장치 는 메모리에 저장된 복수의 광각 이미지에서 장애물 오브젝트와 오버랩되지 않고 B라벨 및 B제품이 식별 가능한 광각 이미지를 식별할 수 있다. 여기서, 식별된 광각 이미지는 제2 촬상 위치가 아닌 다른 위치에서 촬상된 광각 이미지일 수 있다. 식별된 광각 이미지는 제1 촬상 위치에서 촬상된 광각 이미지 또는 제3 촬상 위치에서 촬상된 광각 이미지 중 적어도 하나의 이미지일 수 있다. 전자 장치는 협각 이미지, 광각 이미지 또는 제3 촬상 위치 중 적어도 하나의 이미지에 기초하 여 결합 이미지를 생성할 수 있다. 여기서, 결합 이미지는 B라벨 및 B제품 앞에 장애물 오브젝트 가 없는 이미지일 수 있다. 도 11은 일 실시 예에 따른 결합 이미지 생성 동작을 설명하기 위한 도면이다. 도 11을 참조하면, 전자 장치는 제2 촬상 위치에서 촬상된 협각 이미지, 제1 촬상 위치에 서 촬상된 광각 이미지 및 제3 촬상 위치에서 촬상된 광각 이미지에 기초하여 결합 이미지 를 생성할 수 있다. 여기서, 협각 이미지는 협각 렌즈를 통해 촬상된 이미지일 수 있고, 광각 이미 지 및 광각 이미지는 광각 렌즈를 통해 촬상된 이미지일 수 있다. 여기서, 전자 장치는 각 촬상 이미지의 관심 영역에 기초하여 결합 이미지를 생성할 수 있다. 전자 장치 는 타겟 오브젝트 및 장애물 오브젝트에 기초하여 협각 이미지의 관심 영역을 식별할 수 있다. 그리고, 전자 장치는 광각 이미지의 관심 영역을 식별할 수 있다. 그리고, 전자 장치는 광각 이미지의 관심 영역을 식별할 수 있다. 또한, 결합 이미지는 장애물 오브젝트가 제거된 가상의 이미지일 수 있다. 사용자는 장애물 오브젝 트가 제거된 이미지를 통해 타겟 오브젝트의 전체 영역을 식별할 수 있으며, 타겟 오브젝트의 완전한 정보 를 획득할 수 있다. 여기서, 협각 이미지는 협각 이미지이고 광각 이미지 및 광각 이미지는 광각 이미지이므로 일부 비율이 상이할 수 있다. 따라서, 전자 장치는 광각 이미지를 협각 이미지에 대응되는 비율로 이미지를 변 환하고, 변환된 이미지에 기초하여 결합 이미지를 생성할 수 있다. 도 12는 다른 실시 예에 따른 결합 이미지 생성 동작을 설명하기 위한 도면이다. 도 12를 참조하면, 전자 장치는 광각 이미지 및 광각 이미지에 기초하여 결합 이미지를 생성할 수 있다. 여기서, 전자 장치는 타겟 오브젝트 및 장애물 오브젝트에 기초하여 광각 이미지의 관심 영역을 식별하고, 광각 이미지의 관심 영역을 식별할 수 있다. 그리고, 전자 장치 는 광각 이미지 각각의 관심 영역(1201, 1202)에 기초하여 결합 이미지를 생성할 수 있다. 여기서, 광각 이미지 및 광각 이미지는 광각 렌즈를 통해 촬상된 이미지일 수 있다. 여기서, 결합 이 미지는 장애물 오브젝트에 대응되는 이미지가 제거된 가상의 이미지일 수 있다.도 13은 협각 이미지의 관심 영역 및 광각 이미지의 관심 영역에 기초하여 발광부를 제어하는 동작을 설명하기 위한 흐름도이다. 도 13을 참조하면, 전자 장치는 제1 카메라를 통해 협각 이미지를 획득할 수 있다 (S1305). 한편, 전자 장치는 타겟 오브젝트에 기초하여 협각 이미지의 관심 영역을 식별할 수 있다 (S1310). 여기서, 관심 영역은 획득되는 전체 이미지의 전체 영역 중 사용자의 의도에 따라 분석 대상이 되는 영역을 의 미할 수 있다. 협각 이미지는 제1 카메라로부터 획득되고, 제1 카메라는 협각 카메라일 수 있다. 따 라서, 협각 이미지의 관심 영역은 협각 이미지 안에서의 관심 영역일 수 있다. 전방에 타겟 오브젝트가 있는 경 우, 협각 이미지의 관심 영역은 타겟 오브젝트가 식별되는 영역일 수 있다. 전방에 타겟 오브젝트가 전혀 식별 되지 않는 경우, 협각 이미지의 관심 영역은 기 설정된 영역일 수 있다. 여기서, 기 설정된 영역은 협각 이미지 의 중앙 영역일 수 있다. 한편, 전자 장치는 제2 카메라를 통해 광각 이미지를 획득할 수 있다 (S1315). 그리고, 전자 장치는 협각 이미지에서 장애물 오브젝트가 식별되는지 식별할 수 있다 (S1316). 협각 이미 지에서 장애물 오브젝트가 식별되면, 전자 장치는 장애물 오브젝트에 가장 인접한 타겟 오브젝트를 제외한 타겟 오브젝트에 기초하여 광각 이미지의 관심 영역을 식별할 수 있다 (S1317). 장애물 오브젝트에 가장 인접한 타겟 오브젝트는 장애물 오브젝트가 가리고 있는 타겟 오브젝트를 의미할 수 있다. 그리고, ‘장애물 오브젝트 에 가장 인접한 타겟 오브젝트’ 표현은 ‘장애물 오브젝트로부터 임계 거리 이내에 있는 타겟 오브젝트’로 대 체될 수 있다. 이와 관련된 구체적인 설명은 도 16 및 도 17에서 후술한다. 협각 이미지에서 장애물 오브젝트가 식별되지 않으면, 전자 장치는 장애물 오브젝트 및 장애물 오브젝트에 가장 인접한 타겟 오브젝트에 기초하여 광각 이미지의 관심 영역을 식별할 수 있다 (S1320). 여기서, 전자 장치 는 광각 이미지에서 장애물 오브젝트를 식별할 수 있다. 광각 이미지는 촬영 시점 및 촬영 위치에 따라 동 일한 오브젝트를 촬상함에도 장애물 오브젝트가 상이한 위치에서 식별될 수 있다. 따라서, 광각 이미지 각각의 관심 영역은 촬영 시점 및 촬영 위치에 따라 상이할 수 있다. 또한, S1320 동작에서 장애물 오브젝트가 식별되 지 않는 경우, 전자 장치는 협각 이미지에서 식별되지 않은 타겟 오브젝트에 기초하여 관심 영역을 식별할 수 있다. 즉, S1320 단계에서 이용되는 타겟 오브젝트와 S1310 단계에서 이용되는 타겟 오브젝트가 상이할 수 있다. 이와 관련된 구체적인 설명은 도 14, 도 15, 도 18 및 도 19에서 후술한다. 한편, 전자 장치는 협각 이미지의 관심 영역 및 광각 이미지의 관심 영역 모두에 인접한 영역을 식별할 수 있다 (S1325). 여기서, 인접한 영역은 임계 크기일 수 있다. 한편, 전자 장치는 S1325 단계에서 식별된 영역이 복수 개인지 판단할 수 있다 (S1330). 식별된 영역이 복 수 개가 아니라면, 전자 장치는 식별된 하나의 영역을 조사 영역으로 결정하고 결정된 조사 영역에 최대 세기의 빛을 조사할 수 있다 (S1335). 여기서, 조사 영역은 빛이 쏘여지는 영역일 수 있다. 이와 관련된 설명은 도 14, 도 15, 도 18 및 도 19에서 후술한다. 식별된 영역이 복수 개라면, 전자 장치는 식별된 복수의 영역 중 발광부에 가장 가까운 영역을 조사 영역으로 결정하고, 결정된 조사 영역에 최대 세기의 빛을 조사할 수 있다 (S1340). 이와 관련된 설명은 도 16 및 도 17에서 후술한다. 한편, 구현 예에 따라, 전자 장치는 협각 이미지의 관심 영역 및 광각 이미지의 관심 영역에서 가장 가까 운 포인트를 식별하고, 식별된 포인트들의 중앙값을 획득할 수 있다. 그리고, 전자 장치는 획득된 중앙값 에 기초하여 조사 포인트를 결정할 수 있다. 전자 장치는 결정된 조사 포인트에 최대 세기의 빛이 조사되 도록 발광부를 제어할 수 있다. 일 실시 예에 따라, 도 13의 동작들은 실시간으로 조사 영역을 결정하는 동작일 수 있다. 하지만, 다른 실시 예에 따라, 전자 장치는 이미 한번 모든 촬상 동작이 완료된 후 저장된 복수의 이미지 에 기초하여 조사 영역을 결정할 수 있다. 여기서, 결정된 조사 영역은 다음 촬상 동작에서 이용될 수 있다. 전 자 장치는 저장된 복수의 이미지를 분석하여 가장 적합한 조사 영역이 어디인지 결정할 수 있다. 다른 실 시 예에 따른 조사 영역 결정 방식을 위해서 전자 장치는 S1305 단계 대신에 ‘복수의 협각 이미지 중 타 겟 오브젝트가 포함된 적어도 하나의 협각 이미지를 식별’하는 동작을 수행할 수 있다. 구체적으로, 전자 장치 는 복수의 협각 이미지를 분석하여 타겟 오브젝트가 적어도 일부 식별되는 이미지를 식별할 수 있다. 여기 서, 식별되는 협각 이미지는 타겟 오브젝트의 전체 영역이 포함될 수 있으며, 타겟 오브젝트의 일부 영역만 포함될 수도 있다. 또한, 다른 실시 예에 따른 조사 영역 결정 방식을 위해서 전자 장치는 S1315 단계 대신에 ‘복수의 광각 이미지 중 장애물 오브젝트에 의해 오버랩되지 않고 타겟 오브젝트가 식별 가능한 광각 이미지를 식별’하는 동 작을 수행할 수 있다. 여기서, 광각 이미지는 광각 이미지이므로 복수의 타겟 오브젝트를 포함할 수 있다. 일부 타겟 오브젝트는 장애물과 전혀 오버랩되지 않고, 하나의 타겟 오브젝트는 장애물과 일부 오버랩될 수 있다. 장 애물과 전혀 오버랩되지 않는 타겟 오브젝트는 제1 카메라에서 획득되는 협각 이미지로부터 분석이 가능할 수 있다. 따라서, ‘장애물 오브젝트에 의해 오버랩되지 않고 타겟 오브젝트가 식별 가능한 광각 이미지’는 장 애물 오브젝트와 인접한 거리에 있는 타겟 오브젝트가 식별 가능한 광각 이미지를 의미할 수 있다. 도 14는 제1 촬상 위치에서 조사 영역을 식별하는 동작을 설명하기 위한 도면이다. 도 14를 참조하면, 전자 장치는 제1 촬상 위치에서 전방을 촬상할 수 있으며, 제1 카메라를 통 해 협각 이미지를 획득하고 제2 카메라를 통해 광각 이미지를 획득할 수 있다. 전자 장치는 타겟 오브젝트에 기초하여 협각 이미지의 관심 영역을 식별할 수 있다. 예를 들어, 협각 이미지의 관심 영역은 타겟 오브젝트인 A라벨 및 A제품이 식별되는 영역일 수 있다. 또한, 전자 장치는 협각 이미지에서 장애물 오브젝트가 식별되는지 여부를 판단할 수 있다. 협각 이 미지에서 장애물 오브젝트가 식별되지 않으면, 전자 장치는 장애물 오브젝트 및 타겟 오브젝트(장애 물 오브젝트에 가장 인접한 타겟 오브젝트)기초하여 광각 이미지의 관심 영역을 식별할 수 있다. 여 기서, 전자 장치는 광각 이미지는 장애물 오브젝트와 타겟 오브젝트가 모두 포함된 영역을 광각 이미 지의 관심 영역으로 설정할 수 있다. 여기서, 광각 이미지의 관심 영역을 식별하는데 이 용되는 타겟 오브젝트는 협각 이미지의 관심 영역을 식별하는데 이용되는 타겟 오브젝트와 상이할 수 있다. 예를 들어, 전자 장치는 광각 이미지에서 장애물 오브젝트의 적어도 일부를 식별할 수 있다. 그리고, 광각 이미지에 포함된 복수의 타겟 오브젝트 중 장애물 오브젝트와 가장 인접한 타겟 오브젝트인 B라벨 및 B제품을 식별할 수 있다. 그리고, 전자 장치는 장애물 오브젝트, B라 벨 및 B제품이 모두 포함된 영역을 광각 이미지의 관심 영역으로 식별할 수 있다. 전자 장치는 식별된 협각 이미지의 관심 영역과 식별된 광각 이미지의 관심 영역에 기초하여 관심 영역 및 관심 영역에 인접한 영역을 식별할 수 있다. 여기서, 전자 장치(10 0)는 전자 장치의 촬상 범위에서 관심 영역 및 관심 영역을 판단할 수 있다. 여기서, 협각 이미지와 광각 이미지는 객체를 표시하는 비율이 상이할 수 있다. 따라서, 전자 장치는 각 이미지가 동일한 비율로 객체를 표시하도록 적어도 하나의 이미지를 보정할 수 있다. 전자 장치는 촬상 범 위에서 관심 영역 및 관심 영역이 인접한 영역을 식별할 수 있다. 여기서, 인접한 영 역은 조사 영역 비 간섭 영역, 비 중첩 영역 중 하나로 표현될 수 있다. 이후 편의상 인접한 영역을 조사 영역으로 기재한다. 한편, 조사 영역을 따로 결정하는 이유는 빛의 반사로 인한 객체 인식률 저하를 해결하기 위함이다. 타겟 오브젝트 부분에 가장 강한 빛이 조사되는 경우, 빛의 반사로 인해 타겟 오브젝트 인식률이 저 하될 수 있으므로, 타겟 오브젝트가 식별되지 않는 영역에 가장 강한 세기의 빛을 조사할 수 있다. 도 15는 제1 촬상 위치에서 발광부를 제어하는 동작을 설명하기 위한 도면이다. 도 15를 참조하면, 전자 장치는 관심 협각 이미지의 관심 영역 및 광각 이미지의 관심 영 역 사이에 위치한 조사 영역을 결정할 수 있다. 그리고, 전자 장치는 결정된 조사 영역(140 3)에 기초하여 조사 영역에 대응되는 위치에 가장 밝은 빛을 조사하도록 발광부를 제어할 수 있다. 그래프를 참조하면, 전자 장치가 제1 촬상 위치에 있을 때, 조사 영역에 대응되는 위치 에 가장 밝은 빛이 조사될 수 있다. 조사 영역에 대응되는 위치에만 빛이 조사되는 것이 아니며 조 사 영역에 대응되는 위치에 가장 밝은 빛이 조사되도록 조사되는 것일 수 있다. 도 16은 제2 촬상 위치에서 조사 영역을 식별하는 동작을 설명하기 위한 도면이다. 도 16을 참조하면, 전자 장치는 제2 촬상 위치에서 전방을 촬상할 수 있으며, 제1 카메라를 통 해 협각 이미지를 획득하고 제2 카메라를 통해 광각 이미지를 획득할 수 있다. 전자 장치는 타겟 오브젝트에 기초하여 협각 이미지의 관심 영역을 식별할 수 있다. 예를 들어, 협각 이미지의 관심 영역은 타겟 오브젝트인 B라벨 및 B제품이 식별되는 영역일 수있다. 또한, 전자 장치는 협각 이미지에서 장애물 오브젝트가 식별되는지 판단할 수 있다. 협각 이미지 에서 장애물 오브젝트가 식별되면, 전자 장치는 장애물 오브젝트 및 장애물 오브젝트에 가장 인접한 타겟 오브젝트를 제외한 타겟 오브젝트에 기초하여 광각 이미지의 관심 영역(1602, 1603)을 식별할 수 있 다. 여기서, 장애물 오브젝트에 가장 인접한 타겟 오브젝트는 B라벨 및 B제품일 수 있고, 장애물 오 브젝트에 가장 인접한 타겟 오브젝트를 제외한 타겟 오브젝트는 A라벨, A제품, C라벨 및 C제품 일 수 있다. 여기서, 전자 장치는 A라벨, A제품을 포함하는 영역을 광각 이미지의 관 심 영역으로 식별할 수 있고, C라벨 및 C제품을 포함하는 영역을 광각 이미지의 관심 영 역으로 식별할 수 있다. 여기서, 광각 이미지의 관심 영역(1602, 1603)을 식별하는데 이용되는 타겟 오브젝트는 협각 이미지 의 관심 영역을 식별하는데 이용되는 타겟 오브젝트와 상이할 수 있다. 전자 장치는 식별된 협각 이미지의 관심 영역과 식별된 광각 이미지의 관심 영역(1602, 1603)에 기초하여 관심 영역 및 관심 영역(1602, 1603)에 인접한 영역(1604-1, 1604-2)을 식별할 수 있 다. 구체적으로, 협각 이미지의 관심 영역과 광각 이미지의 관심 영역에 인접한 영역 (1604-1)을 식별하고, 협각 이미지의 관심 영역과 광각 이미지의 관심 영역에 인접한 영 역(1604-2)을 식별할 수 있다. 여기서, 전자 장치는 전자 장치의 촬상 범위에서 협각 이미지의 관심 영역 및 광각 이미지의 관심 영역(1602, 1603)을 판단할 수 있다. 여기서, 협각 이미지와 광각 이미지는 객체 를 표시하는 비율이 상이할 수 있다. 따라서, 전자 장치는 각 이미지가 동일한 비율로 객체를 표시하도록 적어도 하나의 이미지를 보정할 수 있다. 전자 장치는 촬상 범위에서 관심 영역 및 관심 영역 (1602, 1603)이 인접한 영역(1604-1, 1604-2)을 식별할 수 있다. 여기서, 인접한 영역(1604-1, 1604-2)은 조사 영역 비 간섭 영역, 비 중첩 영역 중 하나로 표현될 수 있다. 이후 편의상 인접한 영역을 조사 영역으로 기재한 다. 도 17은 제2 촬상 위치에서 발광부를 제어하는 동작을 설명하기 위한 도면이다. 도 17을 참조하면, 협각 이미지의 관심 영역 및 광각 이미지의 관심 영역 사이에 위치한 조사 영역(1604-1) 및 협각 이미지의 관심 영역 및 광각 이미지의 관심 영역 사이에 위 치한 조사 영역(1604-2)을 결정할 수 있다. 그리고, 복수의 조사 영역이 식별되면, 그 중 하나의 조사 영역을 결정할 수 있다. 전자 장치는 복수의 조사 영역 중 발광부의 위치와 가까운 조사 영역을 결정하고, 결정된 조사 영역에 대응되는 위치에 가장 밝은 빛을 조사하도록 발광부를 제어할 수 있다. 구체적인 동작 은 도 13의 S1330 및 S1340 단계에서 전술하였다. 제2 촬상 위치를 기준으로 2개의 조사 영역(1604-1, 1604-2) 중 발광부에 가까운 조사 영역은 1604-2 영역일 수 있다. 그래프를 참조하면, 전자 장치가 제2 촬상 위치에 있을 때, 조사 영역(1604-2)에 대응되는 위 치에 가장 밝은 빛이 조사될 수 있다. 도 18은 제3 촬상 위치에서 조사 영역을 식별하는 동작을 설명하기 위한 도면이다. 도 18를 참조하면, 전자 장치는 제3 촬상 위치에서 전방을 촬상할 수 있으며, 제1 카메라를 통 해 협각 이미지를 획득하고 제2 카메라를 통해 광각 이미지를 획득할 수 있다. 전자 장치는 타겟 오브젝트에 기초하여 협각 이미지의 관심 영역을 식별할 수 있다. 예를 들어, 협각 이미지의 관심 영역은 타겟 오브젝트인 C라벨 및 C제품이 식별되는 영역일 수 있다. 또한, 전자 장치는 협각 이미지에서 장애물 오브젝트가 식별되는지 여부를 판단할 수 있다. 협각 이 미지에서 장애물 오브젝트가 식별되지 않으면, 전자 장치는 장애물 오브젝트 및 타겟 오브젝트(장애 물 오브젝트에 가장 인접한 타겟 오브젝트)기초하여 광각 이미지의 관심 영역을 식별할 수 있다. 여 기서, 전자 장치는 광각 이미지는 장애물 오브젝트와 타겟 오브젝트가 모두 포함된 영역을 광각 이미 지의 관심 영역으로 설정할 수 있다. 여기서, 광각 이미지의 관심 영역을 식별하는데 이 용되는 타겟 오브젝트는 협각 이미지의 관심 영역을 식별하는데 이용되는 타겟 오브젝트와 상이할 수 있다. 예를 들어, 전자 장치는 광각 이미지에서 장애물 오브젝트의 적어도 일부를 식별할 수있다. 그리고, 광각 이미지에 포함된 복수의 타겟 오브젝트 중 장애물 오브젝트와 가장 인접한 타겟 오브젝트인 B라벨 및 B제품을 식별할 수 있다. 그리고, 전자 장치는 장애물 오브젝트, B라 벨 및 B제품이 모두 포함된 영역을 광각 이미지의 관심 영역으로 식별할 수 있다. 전자 장치는 식별된 협각 이미지의 관심 영역과 식별된 광각 이미지의 관심 영역에 기초하여 관심 영역 및 관심 영역에 인접한 영역을 식별할 수 있다. 여기서, 전자 장치(10 0)는 전자 장치의 촬상 범위에서 관심 영역 및 관심 영역을 판단할 수 있다. 여기서, 협각 이미지와 광각 이미지는 객체를 표시하는 비율이 상이할 수 있다. 따라서, 전자 장치는 각 이미지가 동일한 비율로 객체를 표시하도록 적어도 하나의 이미지를 보정할 수 있다. 전자 장치는 촬상 범 위에서 관심 영역 및 관심 영역이 인접한 영역을 식별할 수 있다. 여기서, 인접한 영 역은 조사 영역 비 간섭 영역, 비 중첩 영역 중 하나로 표현될 수 있다. 이후 편의상 인접한 영역을 조사 영역으로 기재한다. 한편, 조사 영역을 따로 결정하는 이유는 빛의 반사로 인한 객체 인식률 저하를 해결하기 위함이다. 타겟 오브젝트 부분에 가장 강한 빛이 조사되는 경우, 빛의 반사로 인해 타겟 오브젝트 인식률이 저 하될 수 있으므로, 타겟 오브젝트가 식별되지 않는 영역에 가장 강한 세기의 빛을 조사할 수 있다. 도 19는 제3 촬상 위치에서 발광부를 제어하는 동작을 설명하기 위한 도면이다. 도 19를 참조하면, 전자 장치는 관심 협각 이미지의 관심 영역 및 광각 이미지의 관심 영 역 사이에 위치한 조사 영역을 결정할 수 있다. 그리고, 전자 장치는 결정된 조사 영역(180 3)에 기초하여 조사 영역에 대응되는 위치에 가장 밝은 빛을 조사하도록 발광부를 제어할 수 있다. 그래프를 참조하면, 전자 장치가 제3 촬상 위치에 있을 때, 조사 영역에 대응되는 위치 에 가장 밝은 빛이 조사될 수 있다. 조사 영역에 대응되는 위치에만 빛이 조사되는 것이 아니며 조 사 영역에 대응되는 위치에 가장 밝은 빛이 조사되도록 조사되는 것일 수 있다. 도 20은 복수의 카메라 모듈을 포함하는 전자 장치를 설명하기 위한 도면이다. 도 20을 참조하면, 전자 장치는 복수의 카메라 모듈을 포함할 수 있다. 제1 카메라 모듈은 제1 카메 라, 제2 카메라 및 발광부를 포함할 수 있다. 그리고, 제2 카메라 모듈(110-2)은 제1 카메라 와 동일한 촬상각을 갖는 제3 카메라(111-2), 제2 카메라와 동일한 촬상각을 갖는 제4 카메라(112-2) 및 발광부(130-2)를 포함할 수 있다. 그리고, 제3 카메라 모듈(110-3)은 제1 카메라와 동일한 촬상각을 갖 는 제5 카메라(111-3), 제2 카메라와 동일한 촬상각을 갖는 제6 카메라(112-3) 및 발광부(130-3)를 포함할 수 있다. 각 카메라 모듈은 협각 렌즈를 포함하는 카메라, 광각 렌즈를 포함하는 카메라 및 발광부를 포함할 수 있다. 각 카메라 모듈은 전자 장치에서 수직 방향으로 배치될 수 있다. 도 21은 복수의 카메라 모듈에 의해 획득된 이미지에 기초하여 결합 이미지를 생성하는 동작을 설명하기 위한 흐름도이다. 도 21을 참조하면, 전자 장치는 제1 카메라 모듈에 포함된 제1 카메라 및 제2 카메라로부 터 제1 협각 이미지 및 제2 광각 이미지를 획득할 수 있다 (S2105). 그리고, 전자 장치는 제2 카메라 모듈 (110-2)에 포함된 제3 카메라(111-2) 및 제4 카메라(112-2)로부터 제3 협각 이미지 및 제4 광각 이미지를 획득 할 수 있다. 여기서, 제1 협각 이미지는 제1 카메라로부터 획득한 협각 이미지이며, 제3 협각 이미지는 제 3 카메라(111-2)로부터 획득한 협각 이미지일 수 있다. 또한, 제2 광각 이미지는 제2 카메라로부터 획득한 광각 이미지이며, 제4 광각 이미지는 제4 카메라(112-2)로부터 획득한 광각 이미지일 수 있다. 전자 장치는 제1 협각 이미지 또는 제2 광각 이미지에서 장애물 오브젝트가 포함된 이미지를 식별할 수 있 다 (S2115). 그리고, 전자 장치는 제3 협각 이미지 또는 제4 광각 이미지에서 타겟 오브젝트(장애물 오브 젝트로부터 임계 거리 이내에 존재하는)의 가장 많은 부분이 식별되는 제2 광각 이미지를 식별할 수 있다 (S2120). 즉, 제1 카메라 모듈에서 획득한 제1 협각 이미지 및 제2 광각 이미지에서 장애물 오브젝트가 식 별되면, 제1 카메라 모듈과 다른 수직 높이에 위치한 제2 카메라 모듈(110-2)에서 획득한 제3 협각 이미지 및 제4 광각 이미지를 이용하여 장애물 오브젝트에 가려진 부분을 식별할 수 있다. 전자 장치는 제1 카메라 모듈에서 획득한 이미지 및 제2 카메라 모듈(110-2)에서 획득한 이미지에 기 초하여 결합 이미지를 생성할 수 있다 (S2125). 복수의 카메라 모듈에 의해 획득된 이미지에 기초하여 결합 이 미지를 생성하는 구체적인 동작은 도 22에서 후술한다.도 22는 복수의 카메라 모듈에 의해 획득된 이미지에 기초하여 생성된 결합 이미지를 설명하기 위한 도면이다. 도 22를 참조하면, 전자 장치는 복수의 카메라 모듈을 포함하고 있다고 가정한다. 도 20에서와 같이 전자 장치는 제1 카메라 모듈, 제2 카메라 모듈(110-2) 및 제3 카메라 모듈(110-3)을 포함하고 있다고 가 정한다. 전자 장치는 제1 카메라 모듈에 포함된 제1 카메라를 통해 제1 협각 이미지를 획득하고, 제2 카메라 모듈(110-2)에 포함된 제3 카메라(111-2)를 통해 제3 협각 이미지를 획득하고, 제3 카메라 모 듈(110-3)에 포함된 제5 카메라(111-3)를 통해 제5 협각 이미지를 획득할 수 있다. 제1 협각 이미지, 제3 협각 이미지, 제5 협각 이미지는 타겟 오브젝트 및 장애물 오브젝트를 포함할 수 있다. 다만, 각 촬상 이미지는 촬상 각도가 상이할 수 있다. 따라서, 장애물 오브젝트에 가려진 타겟 오브젝트의 부분 이 상이할 수 있다. 즉, 하나의 이미지에서 장애물 오브젝트에 가려졌던 부분이 다른 이미지에서는 장애물 오브 젝트에 가려지지 않을 수 있다. 전자 장치는 제1 협각 이미지, 제3 협각 이미지 및 제5 협각 이미지에 기초하여 결합 이미지를 생성할 수 있다. 여기서, 결합 이미지는 장애물 오브젝트가 제거된 이미지일 수 있다. 도 23은 본 개시의 일 실시 예에 따른 전자 장치의 제어 방법을 설명하기 위한 흐름도이다. 도 23을 참조하면, 전자 장치의 제어 방법은 제1 촬상각을 갖는 제1 카메라로부터 획득된 제1 촬상 이미지 또는 제1 촬상각보다 큰 제2 촬상각을 가지는 제2 카메라로부터 획득된 제2 촬상 이미지 중 적어도 하나로부터 타겟 오브젝트의 일 부분이 식별되고 타겟 오브젝트의 나머지 일 부분에 오버랩되는 장애물 오브젝트가 식별되 면, 식별된 장애물 오브젝트의 위치 정보를 획득하는 단계 (S2305), 획득된 장애물 오브젝트의 위치 정보에 기 초하여 제2 촬상 이미지의 관심 영역을 식별하는 단계 (S2310) 및 제2 촬상 이미지의 관심 영역에 기초하여 타 겟 오브젝트의 나머지 일 부분을 식별하는 단계 (S2315)를 포함한다. 한편, 제어 방법은 제1 촬상 이미지에서 타겟 오브젝트 및 장애물 오브젝트가 포함된 영역 및 제2 촬상 이미지 의 관심 영역에 기초하여 타겟 오브젝트의 전체 이미지를 포함하는 결합 이미지를 획득하는 단계 및 획득된 결 합 이미지에 기초하여 타겟 오브젝트를 식별하는 단계를 더 포함할 수 있다. 한편, 제1 촬상 이미지는 제1 촬상 위치에서 제1 카메라에 의해 촬상된 이미지이고, 제2 촬상 이미지는 제1 촬 상 위치와 상이한 제2 촬상 위치에서 제2 카메라에 의해 촬상된 이미지일 수 있다. 한편, 제어 방법은 제1 촬상 위치 및 제2 촬상 위치와 상이한 제3 촬상 위치에서 제2 카메라로부터 촬상된 제3 촬상 이미지를 획득하는 단계, 식별된 장애물 오브젝트의 위치 정보에 기초하여 제3 촬상 이미지의 관심 영역을 식별하는 단계 및 제2 촬상 이미지의 관심 영역 및 제3 촬상 이미지의 관심 영역에 기초하여 타겟 오브젝트의 나머지 일 부분을 식별하는 단계를 더 포함할 수 있다. 한편, 제2 촬상 위치는 제1 촬상 위치를 기준으로 제1 방향에 위치할 수 있고, 제3 촬상 위치는 제1 촬상 위치 를 기준으로 제1 방향과 상이한 제2 방향에 위치할 수 있다. 한편, 제2 촬상 이미지의 관심 영역을 식별하는 단계 (S2310)는 제2 촬상 이미지가 촬상된 방향 정보 및 장애물 오브젝트의 위치 정보에 기초하여 제2 촬상 이미지의 관심 영역을 식별할 수 있고, 제3 촬상 이미지의 관심 영 역을 식별하는 단계는 제3 촬상 이미지가 촬상된 방향 정보 및 장애물 오브젝트의 위치 정보에 기초하여 제3 촬 상 이미지의 관심 영역을 식별할 수 있다. 한편, 제어 방법은 제1 촬상 이미지에 기초하여 타겟 오브젝트의 일 부분 및 장애물 오브젝트를 식별하는 단계 및 제2 촬상 이미지의 관심 영역에 기초하여 타겟 오브젝트의 나머지 일 부분을 식별하는 단계를 더 포함할 수 있다. 한편, 제어 방법은 제1 촬상 이미지에 기초하여 장애물 오브젝트의 위치 정보 및 크기 정보를 식별하는 단계 및 식별된 장애물 오브젝트의 위치 정보 및 크기 정보에 기초하여 제2 카메라의 촬상 위치를 식별하는 단계를 더 포함할 수 있고, 제2 촬상 이미지는 식별된 촬상 위치에서 촬상된 이미지일 수 있다. 한편, 제어 방법은 제1 촬상 이미지의 관심 영역을 식별하는 단계, 제1 촬상 이미지의 관심 영역 및 제2 촬상 이미지의 관심 영역에 인접한 영역에 대응되는 위치를 식별하는 단계 및 식별된 위치로 임계 세기 이상의 광을 조사하는 단계를 더 포함할 수 있다.한편, 제어 방법은 식별된 위치로 광이 조사되도록 발광 각도를 변경하는 단계를 더 포함할 수 있다. 한편, 도 23과 같은 전자 장치의 제어 방법은 도 2 또는 도 3의 구성을 가지는 전자 장치 상에서 실행될 수 있 으며, 그 밖의 구성을 가지는 전자 장치 상에서도 실행될 수 있다. 한편, 상술한 본 개시의 다양한 실시 예들에 따른 방법들은, 기존 전자 장치에 설치 가능한 어플리케이션 형태 로 구현될 수 있다. 또한, 상술한 본 개시의 다양한 실시 예들에 따른 방법들은, 기존 전자 장치에 대한 소프트웨어 업그레이드, 또 는 하드웨어 업그레이드 만으로도 구현될 수 있다. 또한, 상술한 본 개시의 다양한 실시 예들은 전자 장치에 구비된 임베디드 서버, 또는 전자 장치 및 디스플레이 장치 중 적어도 하나의 외부 서버를 통해 수행되는 것도 가능하다. 한편, 본 개시의 일시 예에 따르면, 이상에서 설명된 다양한 실시 예들은 기기(machine)(예: 컴퓨터)로 읽을 수 있는 저장 매체(machine-readable storage media)에 저장된 명령어를 포함하는 소프트웨어로 구현될 수 있다. 기기는, 저장 매체로부터 저장된 명령어를 호출하고, 호출된 명령어에 따라 동작이 가능한 장치로서, 개시된 실 시 예들에 따른 전자 장치를 포함할 수 있다. 명령이 프로세서에 의해 실행될 경우, 프로세서가 직접, 또는 프 로세서의 제어 하에 다른 구성요소들을 이용하여 명령에 해당하는 기능을 수행할 수 있다. 명령은 컴파일러 또 는 인터프리터에 의해 생성 또는 실행되는 코드를 포함할 수 있다. 기기로 읽을 수 있는 저장매체는, 비일시적 (non-transitory) 저장매체의 형태로 제공될 수 있다. 여기서, '비일시적'은 저장매체가 신호(signal)를 포함하 지 않으며 실재(tangible)한다는 것을 의미할 뿐 데이터가 저장매체에 반영구적 또는 임시적으로 저장됨을 구분 하지 않는다. 또한, 본 개시의 일 실시 예에 따르면, 이상에서 설명된 다양한 실시 예들에 따른 방법은 컴퓨터 프로그램 제품 (computer program product)에 포함되어 제공될 수 있다. 컴퓨터 프로그램 제품은 상품으로서 판매자 및 구매자 간에 거래될 수 있다. 컴퓨터 프로그램 제품은 기기로 읽을 수 있는 저장 매체(예: compact disc read only memory (CD-ROM))의 형태로, 또는 어플리케이션 스토어(예: 플레이 스토어TM)를 통해 온라인으로 배포될 수 있 다. 온라인 배포의 경우에, 컴퓨터 프로그램 제품의 적어도 일부는 제조사의 서버, 어플리케이션 스토어의 서버, 또는 중계 서버의 메모리와 같은 저장 매체에 적어도 일시 저장되거나, 임시적으로 생성될 수 있다. 또한, 상술한 다양한 실시 예들에 따른 구성 요소(예: 모듈 또는 프로그램) 각각은 단수 또는 복수의 개체로 구 성될 수 있으며, 전술한 해당 서브 구성 요소들 중 일부 서브 구성 요소가 생략되거나, 또는 다른 서브 구성 요 소가 다양한 실시 예에 더 포함될 수 있다. 대체적으로 또는 추가적으로, 일부 구성 요소들(예: 모듈 또는 프로 그램)은 하나의 개체로 통합되어, 통합되기 이전의 각각의 해당 구성 요소에 의해 수행되는 기능을 동일 또는 유사하게 수행할 수 있다. 다양한 실시 예들에 따른, 모듈, 프로그램 또는 다른 구성 요소에 의해 수행되는 동 작들은 순차적, 병렬적, 반복적 또는 휴리스틱하게 실행되거나, 적어도 일부 동작이 다른 순서로 실행되거나, 생략되거나, 또는 다른 동작이 추가될 수 있다. 이상에서는 본 개시의 바람직한 실시 예에 대하여 도시하고 설명하였지만, 본 개시는 상술한 특정의 실시 예에"}
{"patent_id": "10-2020-0152728", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "한정되지 아니하며, 청구범위에서 청구하는 본 개시의 요지를 벗어남이 없이 당해 개시에 속하는 기술분야에서 통상의 지식을 가진 자에 의해 다양한 변형 실시가 가능한 것은 물론이고, 이러한 변형실시들은 본 개시의 기술 적 사상이나 전망으로부터 개별적으로 이해되어져서는 안될 것이다."}
{"patent_id": "10-2020-0152728", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 개시의 일 실시 예에 따른 전자 장치의 동작을 설명하기 위한 도면이다. 도 2는 본 개시의 일 실시 예에 따른 전자 장치를 도시한 블록도이다. 도 3은 도 2의 전자 장치의 구체적인 구성을 설명하기 위한 블록도이다. 도 4는 본 개시의 일 실시 예에 따른 전자 장치에 포함된 카메라 모듈을 설명하기 위한 도면이다. 도 5는 전자 장치가 타겟 오브젝트 및 장애물 오브젝트를 식별하는 동작을 설명하기 위한 도면이다. 도 6은 타겟 오브젝트의 전체 영역을 식별하는 동작을 설명하기 위한 흐름도이다. 도 7은 제1 촬상 위치에서 촬상된 이미지를 설명하기 위한 도면이다. 도 8은 제2 촬상 위치에서 촬상된 이미지를 설명하기 위한 도면이다. 도 9는 제3 촬상 위치에서 촬상된 이미지를 설명하기 위한 도면이다. 도 10은 결합 이미지를 생성하는 동작을 설명하기 위한 흐름도이다.도 11은 일 실시 예에 따른 결합 이미지 생성 동작을 설명하기 위한 도면이다. 도 12는 다른 실시 예에 따른 결합 이미지 생성 동작을 설명하기 위한 도면이다. 도 13은 협각 이미지의 관심 영역 및 광각 이미지의 관심 영역에 기초하여 발광부를 제어하는 동작을 설명하기 위한 흐름도이다. 도 14는 제1 촬상 위치에서 조사 영역을 식별하는 동작을 설명하기 위한 도면이다. 도 15는 제1 촬상 위치에서 발광부를 제어하는 동작을 설명하기 위한 도면이다. 도 16은 제2 촬상 위치에서 조사 영역을 식별하는 동작을 설명하기 위한 도면이다. 도 17은 제2 촬상 위치에서 발광부를 제어하는 동작을 설명하기 위한 도면이다. 도 18은 제3 촬상 위치에서 조사 영역을 식별하는 동작을 설명하기 위한 도면이다. 도 19는 제3 촬상 위치에서 발광부를 제어하는 동작을 설명하기 위한 도면이다. 도 20은 복수의 카메라 모듈을 포함하는 전자 장치를 설명하기 위한 도면이다. 도 21은 복수의 카메라 모듈에 의해 획득된 이미지에 기초하여 결합 이미지를 생성하는 동작을 설명하기 위한 흐름도이다. 도 22는 복수의 카메라 모듈에 의해 획득된 이미지에 기초하여 생성된 결합 이미지를 설명하기 위한 도면이다. 도 23은 본 개시의 일 실시 예에 따른 전자 장치의 제어 방법을 설명하기 위한 흐름도이다."}
