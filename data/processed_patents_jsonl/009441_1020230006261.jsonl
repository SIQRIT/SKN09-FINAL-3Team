{"patent_id": "10-2023-0006261", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0114171", "출원번호": "10-2023-0006261", "발명의 명칭": "전자 장치 및 그 영상 처리 방법", "출원인": "삼성전자주식회사", "발명자": "김범준"}}
{"patent_id": "10-2023-0006261", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "전자 장치에 있어서, 복수의 명암비 인핸스(enhance) 커브가 저장된 메모리; 및상기 메모리와 연결되어 상기 전자 장치를 제어하는 하나 이상의 프로세서;를 포함하며, 상기 하나 이상의 프로세서는,상기 복수의 명암비 인핸스 커브 각각을 입력 영상에 적용하여 획득된 복수의 후보 인핸스 영상을, 상기 입력영상과 비교하여 상기 복수의 후보 인핸스 영상 각각에 대응되는 영상 변화량 정보 및 인핸스 효과 정보를 식별하고, 상기 복수의 후보 인핸스 영상 각각에 대응되는 영상 변화량 정보 및 인핸스 효과 정보에 기초하여 상기 복수의후보 인핸스 영상 중 최종 인핸스 영상을 식별하고,상기 식별된 최종 인핸스 영상에 기초하여 상기 입력 영상에 대응되는 출력 영상을 획득하는, 전자 장치."}
{"patent_id": "10-2023-0006261", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 하나 이상의 프로세서는, 상기 복수의 후보 인핸스 영상 각각을 상기 입력 영상과 비교하여 상기 복수의 후보 인핸스 영상 각각에 대응되는 픽셀 구조 변화량, 노이즈 레벨 변화량 및 색상 변화량을 식별하고, 상기 픽셀 구조 변화량, 상기 노이즈 레벨 변화량 및 상기 색상 변화량에 기초하여 상기 복수의 후보 인핸스 영상 각각에 대응되는 영상 변화량 정보를 획득하는, 전자 장치."}
{"patent_id": "10-2023-0006261", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서, 상기 하나 이상의 프로세서는, 상기 복수의 후보 인핸스 영상 각각에 대응되는 픽셀 균일 분포 정보를 식별하고, 상기 픽셀 균일 분포 정보에 기초하여 상기 복수의 후보 인핸스 영상 각각에 대응되는 인핸스 효과 정보를 획득하는, 전자 장치."}
{"patent_id": "10-2023-0006261", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서, 상기 하나 이상의 프로세서는, 상기 픽셀 구조 변화량, 상기 노이즈 레벨 변화량 및 상기 색상 변화량 각각에 대응되는 기 설정된 가중치를 적용하여 영상 변화량 값을 획득하고, 상기 영상 변화량 값을 역으로 환산한 후 정규화하여 상기 영상 변화량 정보를 획득하는, 전자 장치."}
{"patent_id": "10-2023-0006261", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서, 상기 하나 이상의 프로세서는, 공개특허 10-2024-0114171-3-상기 복수의 후보 인핸스 영상 각각에 대응되는 히스토그램 정보에 기초하여 효과 식별 값을 획득하고, 상기 효과 식별 값을 정규화하여 상기 인핸스 효과 정보를 획득하고, 상기 영상 변화량 정보 및 상기 인핸스 효과 정보에 기 설정된 가중치를 적용하여 상기 복수의 후보 인핸스 영상 각각에 대응되는 최종 식별 값을 식별하고, 상기 식별된 최종 식별 값에 기초하여 상기 최종 인핸스 영상을 식별하는, 전자 장치."}
{"patent_id": "10-2023-0006261", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5항에 있어서, 디스플레이;를 더 포함하며, 상기 하나 이상의 프로세서는, 상기 출력 영상을 상기 디스플레이를 통해 표시하며,상기 기 설정된 가중치는, 상기 디스플레이의 패널 특성에 따라 상이하게 식별되는, 전자 장치."}
{"patent_id": "10-2023-0006261", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에 있어서, 상기 하나 이상의 프로세서는, 상기 복수의 후보 인핸스 영상 중 상기 영상 변화량 정보에 따른 영상 변화 값은 작고 상기 인핸스 효과 정보에따른 인핸스 효과 값은 큰 영상을 최종 인핸스 영상으로 식별하는, 전자 장치."}
{"patent_id": "10-2023-0006261", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1항에 있어서, 상기 하나 이상의 프로세서는, 상기 입력 영상으로부터 특징 정보를 획득하고, 상기 획득된 특징 정보를 학습된 제1 인공 지능 모델에 입력하여 상기 복수의 명암비 인핸스 커브 중 상기 입력영상에 대응되는 명암비 인핸스 커브를 획득하고, 상기 획득된 명암비 인핸스 커브에 기초하여 상기 입력 영상을 처리하여 상기 출력 영상을 획득하며, 상기 학습된 제1 인공 지능 모델은, 영상의 특징 정보가 입력되면 상기 영상에 복수의 명암비 인핸스 커브에 대응되는 영상 변화량 정보 및 인핸스효과 정보에 기초하여 상기 복수의 명암비 인핸스 커브 중 하나의 명암비 인핸스 커브에 대한 정보를 출력하도록 학습된, 전자 장치."}
{"patent_id": "10-2023-0006261", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1항에 있어서, 상기 하나 이상의 프로세서는, 상기 입력 영상으로부터 특징 정보를 획득하고, 상기 획득된 특징 정보를 학습된 제2 인공 지능 모델에 입력하여 상기 복수의 후보 인핸스 영상에 대응되는 영상 변화량 정보 및 인핸스 효과 정보를 획득하고, 상기 복수의 후보 인핸스 영상 각각에 대응되는 영상 변화량 정보 및 인핸스 효과 정보에 기초하여 상기 복수의후보 인핸스 영상 중 최종 인핸스 영상을 식별하며, 상기 학습된 제2 인공 지능 모델은, 공개특허 10-2024-0114171-4-영상의 특징 정보가 입력되면 상기 영상에 복수의 명암비 인핸스 커브를 적용하여 획득된 복수의 후보 인핸스영상에 대응되는 영상 변화량 정보 및 인핸스 효과 정보를 출력하도록 학습된, 전자 장치."}
{"patent_id": "10-2023-0006261", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제1항에 있어서, 상기 하나 이상의 프로세서는, 상기 입력 영상을 학습된 제3 인공 지능 모델에 입력하여 상기 출력 영상을 획득하며,상기 학습된 제3 인공 지능 모델은, 영상이 입력되면, 상기 영상에 복수의 명암비 인핸스 커브를 적용하여 획득된 복수의 후보 인핸스 영상에 대응되는 영상 변화량 정보 및 인핸스 효과 정보를 식별하고, 상기 식별된 영상 변화량 정보 및 인핸스 효과 정보에기초하여 상기 복수의 후보 인핸스 영상 중 최종 인핸스 영상을 식별하여 출력하도록 학습된, 전자 장치."}
{"patent_id": "10-2023-0006261", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "전자 장치의 영상 처리 방법에 있어서, 복수의 명암비 인핸스 커브 각각을 입력 영상에 적용하여 획득된 복수의 후보 인핸스 영상을, 상기 입력 영상과비교하여 상기 복수의 후보 인핸스 영상 각각에 대응되는 영상 변화량 정보 및 인핸스 효과 정보를 식별하는 단계; 상기 복수의 후보 인핸스 영상 각각에 대응되는 영상 변화량 정보 및 인핸스 효과 정보에 기초하여 상기 복수의후보 인핸스 영상 중 최종 인핸스 영상을 식별하는 단계; 및 상기 식별된 최종 인핸스 영상에 기초하여 상기 입력 영상에 대응되는 출력 영상을 획득하는 단계;를 포함하는영상 처리 방법."}
{"patent_id": "10-2023-0006261", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항에 있어서, 상기 영상 변화량 정보 및 인핸스 효과 정보를 식별하는 단계는, 상기 복수의 후보 인핸스 영상 각각을 상기 입력 영상과 비교하여 상기 복수의 후보 인핸스 영상 각각에 대응되는 픽셀 구조 변화량, 노이즈 레벨 변화량 및 색상 변화량을 식별하는 단계; 및 상기 픽셀 구조 변화량, 상기 노이즈 레벨 변화량 및 상기 색상 변화량에 기초하여 상기 복수의 후보 인핸스 영상 각각에 대응되는 영상 변화량 정보를 획득하는 단계;를 포함하는, 영상 처리 방법."}
{"patent_id": "10-2023-0006261", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제12항에 있어서, 상기 영상 변화량 정보 및 인핸스 효과 정보를 식별하는 단계는, 상기 복수의 후보 인핸스 영상 각각에 대응되는 픽셀 균일 분포 정보를 식별하는 단계; 및상기 픽셀 균일 분포 정보에 기초하여 상기 복수의 후보 인핸스 영상 각각에 대응되는 인핸스 효과 정보를 획득하는 단계;를 더 포함하는, 영상 처리 방법."}
{"patent_id": "10-2023-0006261", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제13항에 있어서, 상기 영상 변화량 정보를 획득하는 단계는, 상기 픽셀 구조 변화량, 상기 노이즈 레벨 변화량 및 상기 색상 변화량 각각에 대응되는 기 설정된 가중치를 적용하여 영상 변화량 값을 획득하는 단계; 및상기 영상 변화량 값을 역으로 환산한 후 정규화하여 상기 영상 변화량 정보를 획득하는 단계;를 포함하는, 영공개특허 10-2024-0114171-5-상 처리 방법."}
{"patent_id": "10-2023-0006261", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제14항에 있어서, 상기 인핸스 효과 정보를 획득하는 단계는, 상기 복수의 후보 인핸스 영상 각각에 대응되는 히스토그램 정보에 기초하여 효과 식별 값을 획득하는 단계; 및상기 효과 식별 값을 정규화하여 상기 인핸스 효과 정보를 획득하는 단계;를 포함함고, 상기 최종 인핸스 영상을 식별하는 단계는, 상기 영상 변화량 정보 및 상기 인핸스 효과 정보에 기 설정된 가중치를 적용하여 상기 복수의 후보 인핸스 영상 각각에 대응되는 최종 식별 값을 식별하는 단계; 및 상기 식별된 최종 식별 값에 기초하여 상기 최종 인핸스 영상을 식별하는 단계;를 포함하며, 상기 기 설정된 가중치는, 상기 디스플레이의 패널 특성에 따라 상이하게 식별되는, 영상 처리 방법."}
{"patent_id": "10-2023-0006261", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제11항에 있어서, 상기 최종 인핸스 영상을 식별하는 단계는, 상기 복수의 후보 인핸스 영상 중 상기 영상 변화량 정보에 따른 영상 변화 값은 작고 상기 인핸스 효과 정보에따른 인핸스 효과 값은 큰 영상을 최종 인핸스 영상으로 식별하는 단계;를 포함하는, 영상 처리 방법."}
{"patent_id": "10-2023-0006261", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제11항에 있어서, 상기 상기 영상 변화량 정보 및 인핸스 효과 정보를 식별하는 단계 및 상기 최종 인핸스 영상을 식별하는 단계는, 상기 입력 영상으로부터 특징 정보를 획득하는 단계; 및상기 획득된 특징 정보를 학습된 제1 인공 지능 모델에 입력하여 상기 복수의 명암비 인핸스 커브 중 상기 입력영상에 대응되는 명암비 인핸스 커브를 획득하는 단계;를 포함하고, 상기 출력 영상을 획득하는 단계는, 상기 획득된 명암비 인핸스 커브에 기초하여 상기 입력 영상을 처리하여 상기 출력 영상을 획득하는 단계;를 포함하며, 상기 학습된 제1 인공 지능 모델은, 영상의 특징 정보가 입력되면 상기 영상에 복수의 명암비 인핸스 커브에 대응되는 영상 변화량 정보 및 인핸스효과 정보에 기초하여 상기 복수의 명암비 인핸스 커브 중 하나의 명암비 인핸스 커브에 대한 정보를 출력하도록 학습된, 영상 처리 방법."}
{"patent_id": "10-2023-0006261", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제11항에 있어서, 상기 상기 영상 변화량 정보 및 인핸스 효과 정보를 식별하는 단계는, 상기 입력 영상으로부터 특징 정보를 획득하는 단계; 및상기 획득된 특징 정보를 학습된 제2 인공 지능 모델에 입력하여 상기 복수의 후보 인핸스 영상에 대응되는 영상 변화량 정보 및 인핸스 효과 정보를 획득하는 단계;를 포함하며, 공개특허 10-2024-0114171-6-상기 학습된 제2 인공 지능 모델은, 영상의 특징 정보가 입력되면 상기 영상에 복수의 명암비 인핸스 커브를 적용하여 획득된 복수의 후보 인핸스영상에 대응되는 영상 변화량 정보 및 인핸스 효과 정보를 출력하도록 학습된, 영상 처리 방법."}
{"patent_id": "10-2023-0006261", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제11항에 있어서, 상기 상기 영상 변화량 정보 및 인핸스 효과 정보를 식별하는 단계, 상기 최종 인핸스 영상을 식별하는 단계 및상기 출력 영상을 획득하는 단계는, 상기 입력 영상을 학습된 제3 인공 지능 모델에 입력하여 상기 출력 영상을 획득하는 단계;를 포함하며, 상기 학습된 제3 인공 지능 모델은, 영상이 입력되면, 상기 영상에 복수의 명암비 인핸스 커브를 적용하여 획득된 복수의 후보 인핸스 영상에 대응되는 영상 변화량 정보 및 인핸스 효과 정보를 식별하고, 상기 식별된 영상 변화량 정보 및 인핸스 효과 정보에기초하여 상기 복수의 후보 인핸스 영상 중 최종 인핸스 영상을 식별하여 출력하도록 학습된, 영상 처리 방법."}
{"patent_id": "10-2023-0006261", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "전자 장치의 프로세서에 의해 실행되는 경우 상기 전자 장치가 동작을 수행하도록 하는 컴퓨터 명령을 저장하는비일시적 컴퓨터 판독 가능 매체에 있어서,상기 동작은,복수의 명암비 인핸스 커브 각각을 입력 영상에 적용하여 획득된 복수의 후보 인핸스 영상을, 상기 입력 영상과비교하여 상기 복수의 후보 인핸스 영상 각각에 대응되는 영상 변화량 정보 및 인핸스 효과 정보를 식별하는 단계; 상기 복수의 후보 인핸스 영상 각각에 대응되는 영상 변화량 정보 및 인핸스 효과 정보에 기초하여 상기 복수의후보 인핸스 영상 중 최종 인핸스 영상을 식별하는 단계; 및 상기 식별된 최종 인핸스 영상에 기초하여 상기 입력 영상에 대응되는 출력 영상을 획득하는 단계;를 포함하는,비일시적 컴퓨터 판독 가능 매체."}
{"patent_id": "10-2023-0006261", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "전자 장치가 개시된다. 전자 장치는, 복수의 명암비 인핸스(enhance) 커브가 저장된 메모리 및 하나 이상의 프로 세서를 포함한다. 하나 이상의 프로세서는, 복수의 명암비 인핸스 커브 각각을 입력 영상에 적용하여 획득된 복 수의 후보 인핸스 영상을, 입력 영상과 비교하여 복수의 후보 인핸스 영상 각각에 대응되는 영상 변화량 정보 및 인핸스 효과 정보를 식별하고, 복수의 후보 인핸스 영상 각각에 대응되는 영상 변화량 정보 및 인핸스 효과 정보 에 기초하여 복수의 후보 인핸스 영상 중 최종 인핸스 영상을 식별하고, 식별된 최종 인핸스 영상에 기초하여 입 력 영상에 대응되는 출력 영상을 획득한다."}
{"patent_id": "10-2023-0006261", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 전자 장치 및 그 영상 처리 방법에 관한 것으로, 더욱 상세하게는 입력 영상에 대한 명암비 인핸스 처리를 수행하는 전자 장치 및 그 영상 처리 방법에 관한 것이다."}
{"patent_id": "10-2023-0006261", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "전자 기술의 발달에 힘입어 다양한 유형의 전자기기들이 개발 및 보급되고 있다. 특히, 티브이(TV)나 모바일 등 의 디스플레이 기기 들의 개발 및 보급이 활발하게 진행되고 있다. 사용자에게 좀더 좋은 화질의 영상을 제공하기 위하여 다양한 명암비 향상 기법이 연구되고 있다."}
{"patent_id": "10-2023-0006261", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "일 실시 예에 따르면, 전자 장치는, 복수의 명암비 인핸스(enhance) 커브가 저장된 메모리 및 상기 메모리와 연 결되어 상기 전자 장치를 제어하는 하나 이상의 프로세서를 포함하며, 상기 하나 이상의 프로세서는, 상기 복수 의 명암비 인핸스 커브 각각을 입력 영상에 적용하여 획득된 복수의 후보 인핸스 영상을, 상기 입력 영상과 비 교하여 상기 복수의 후보 인핸스 영상 각각에 대응되는 영상 변화량 정보 및 인핸스 효과 정보를 식별하고, 상 기 복수의 후보 인핸스 영상 각각에 대응되는 영상 변화량 정보 및 인핸스 효과 정보에 기초하여 상기 복수의 후보 인핸스 영상 중 최종 인핸스 영상을 식별하고, 상기 식별된 최종 인핸스 영상에 기초하여 상기 입력 영상에 대응되는 출력 영상을 획득할 수 있다. 일 예에 따르면, 상기 하나 이상의 프로세서는, 상기 복수의 후보 인핸스 영상 각각을 상기 입력 영상과 비교하 여 상기 복수의 후보 인핸스 영상 각각에 대응되는 픽셀 구조 변화량, 노이즈 레벨 변화량 및 색상 변화량을 식 별하고, 상기 픽셀 구조 변화량, 상기 노이즈 레벨 변화량 및 상기 색상 변화량에 기초하여 상기 복수의 후보 인핸스 영상 각각에 대응되는 영상 변화량 정보를 획득할 수 있다. 일 예에 따르면, 상기 하나 이상의 프로세서는, 상기 복수의 후보 인핸스 영상 각각에 대응되는 픽셀 균일 분포 정보를 식별하고, 상기 픽셀 균일 분포 정보에 기초하여 상기 복수의 후보 인핸스 영상 각각에 대응되는 인핸스 효과 정보를 획득할 수 있다. 일 예에 따르면, 상기 하나 이상의 프로세서는, 상기 픽셀 구조 변화량, 상기 노이즈 레벨 변화량 및 상기 색상 변화량 각각에 대응되는 기 설정된 가중치를 적용하여 영상 변화량 값을 획득하고, 상기 영상 변화량 값을 역으 로 환산한 후 정규화하여 상기 영상 변화량 정보를 획득할 수 있다. 일 예에 따르면, 상기 하나 이상의 프로세서는, 상기 복수의 후보 인핸스 영상 각각에 대응되는 히스토그램 정 보에 기초하여 효과 식별 값을 획득하고, 상기 효과 식별 값을 정규화하여 상기 인핸스 효과 정보를 획득하고, 상기 영상 변화량 정보 및 상기 인핸스 효과 정보에 기 설정된 가중치를 적용하여 상기 복수의 후보 인핸스 영 상 각각에 대응되는 최종 식별 값을 식별하고, 상기 식별된 최종 식별 값에 기초하여 상기 최종 인핸스 영상을 식별할 수 있다. 일 예에 따르면, 디스플레이를 더 포함하며, 상기 하나 이상의 프로세서는, 상기 출력 영상을 상기 디스플레이 를 통해 표시하며, 상기 기 설정된 가중치는, 상기 디스플레이의 패널 특성에 따라 상이하게 식별될 수 있다. 일 예에 따르면, 상기 하나 이상의 프로세서는, 상기 복수의 후보 인핸스 영상 중 상기 영상 변화량 정보에 따 른 영상 변화 값은 작고 상기 인핸스 효과 정보에 따른 인핸스 효과 값은 큰 영상을 최종 인핸스 영상으로 식별 할 수 있다. 일 예에 따르면, 상기 하나 이상의 프로세서는, 상기 입력 영상으로부터 특징 정보를 획득하고, 상기 획득된 특 징 정보를 학습된 제1 인공 지능 모델에 입력하여 상기 복수의 명암비 인핸스 커브 중 상기 입력 영상에 대응되 는 명암비 인핸스 커브를 획득하고, 상기 획득된 명암비 인핸스 커브에 기초하여 상기 입력 영상을 처리하여 상 기 출력 영상을 획득할 수 있다. 여기서, 상기 학습된 제1 인공 지능 모델은, 영상의 특징 정보가 입력되면 상 기 영상에 복수의 명암비 인핸스 커브에 대응되는 영상 변화량 정보 및 인핸스 효과 정보에 기초하여 상기 복수 의 명암비 인핸스 커브 중 하나의 명암비 인핸스 커브에 대한 정보를 출력하도록 학습될 수 있다. 일 예에 따르면, 상기 하나 이상의 프로세서는, 상기 입력 영상으로부터 특징 정보를 획득하고, 상기 획득된 특 징 정보를 학습된 제2 인공 지능 모델에 입력하여 상기 복수의 후보 인핸스 영상에 대응되는 영상 변화량 정보 및 인핸스 효과 정보를 획득하고, 상기 복수의 후보 인핸스 영상 각각에 대응되는 영상 변화량 정보 및 인핸스 효과 정보에 기초하여 상기 복수의 후보 인핸스 영상 중 최종 인핸스 영상을 식별할 수 있다. 여기서, 상기 학 습된 제2 인공 지능 모델은, 영상의 특징 정보가 입력되면 상기 영상에 복수의 명암비 인핸스 커브를 적용하여 획득된 복수의 후보 인핸스 영상에 대응되는 영상 변화량 정보 및 인핸스 효과 정보를 출력하도록 학습될 수 있 다. 일 예에 따르면, 상기 하나 이상의 프로세서는, 상기 입력 영상을 학습된 제3 인공 지능 모델에 입력하여 상기 출력 영상을 획득할 수 있다. 여기서, 상기 학습된 제3 인공 지능 모델은, 영상이 입력되면, 상기 영상에 복수 의 명암비 인핸스 커브를 적용하여 획득된 복수의 후보 인핸스 영상에 대응되는 영상 변화량 정보 및 인핸스 효 과 정보를 식별하고, 상기 식별된 영상 변화량 정보 및 인핸스 효과 정보에 기초하여 상기 복수의 후보 인핸스 영상 중 최종 인핸스 영상을 식별하여 출력하도록 학습될 수 있다. 일 실시 예에 따른 전자 장치의 영상 처리 방법은, 복수의 명암비 인핸스 커브 각각을 입력 영상에 적용하여 획 득된 복수의 후보 인핸스 영상을, 상기 입력 영상과 비교하여 상기 복수의 후보 인핸스 영상 각각에 대응되는 영상 변화량 정보 및 인핸스 효과 정보를 식별하는 단계, 상기 복수의 후보 인핸스 영상 각각에 대응되는 영상 변화량 정보 및 인핸스 효과 정보에 기초하여 상기 복수의 후보 인핸스 영상 중 최종 인핸스 영상을 식별하는 단계 및, 상기 식별된 최종 인핸스 영상에 기초하여 상기 입력 영상에 대응되는 출력 영상을 획득하는 단계를 포함할 수 있다. 일 실시 예에 따른 전자 장치의 프로세서에 의해 실행되는 경우 상기 전자 장치가 동작을 수행하도록 하는 컴퓨 터 명령을 저장하는 비일시적 컴퓨터 판독 가능 매체에 있어서, 상기 동작은, 복수의 명암비 인핸스 커브 각각 을 입력 영상에 적용하여 획득된 복수의 후보 인핸스 영상을, 상기 입력 영상과 비교하여 상기 복수의 후보 인 핸스 영상 각각에 대응되는 영상 변화량 정보 및 인핸스 효과 정보를 식별하는 단계, 상기 복수의 후보 인핸스 영상 각각에 대응되는 영상 변화량 정보 및 인핸스 효과 정보에 기초하여 상기 복수의 후보 인핸스 영상 중 최 종 인핸스 영상을 식별하는 단계 및, 상기 식별된 최종 인핸스 영상에 기초하여 상기 입력 영상에 대응되는 출 력 영상을 획득하는 단계를 포함할 수 있다."}
{"patent_id": "10-2023-0006261", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하에서는 첨부 도면을 참조하여 본 개시를 상세히 설명한다. 본 명세서에서 사용되는 용어에 대해 간략히 설명하고, 본 개시에 대해 구체적으로 설명하기로 한다. 본 개시의 실시 예에서 사용되는 용어는 본 개시에서의 기능을 고려하면서 가능한 현재 널리 사용되는 일반적인 용어들을 선택하였으나, 이는 당 분야에 종사하는 기술자의 의도 또는 판례, 새로운 기술의 출현 등에 따라 달 라질 수 있다. 또한, 특정한 경우는 출원인이 임의로 선정한 용어도 있으며, 이 경우 해당되는 개시의 설명 부 분에서 상세히 그 의미를 기재할 것이다. 따라서 본 개시에서 사용되는 용어는 단순한 용어의 명칭이 아닌, 그 용어가 가지는 의미와 본 개시의 전반에 걸친 내용을 토대로 정의되어야 한다. 본 명세서에서, \"가진다,\" \"가질 수 있다,\" \"포함한다,\" 또는 \"포함할 수 있다\" 등의 표현은 해당 특징(예: 수 치, 기능, 동작, 또는 부품 등의 구성요소)의 존재를 가리키며, 추가적인 특징의 존재를 배제하지 않는다. A 또는/및 B 중 적어도 하나라는 표현은 \"A\" 또는 \"B\" 또는 \"A 및 B\" 중 어느 하나를 나타내는 것으로 이해되어 야 한다. 본 명세서에서 사용된 \"제1,\" \"제2,\" \"첫째,\" 또는 \"둘째,\"등의 표현들은 다양한 구성요소들을, 순서 및/또는 중요도에 상관없이 수식할 수 있고, 한 구성요소를 다른 구성요소와 구분하기 위해 사용될 뿐 해당 구성요소들 을 한정하지 않는다. 어떤 구성요소(예: 제1 구성요소)가 다른 구성요소(예: 제2 구성요소)에 \"(기능적으로 또는 통신적으로) 연결되 어((operatively or communicatively) coupled with/to)\" 있다거나 \"접속되어(connected to)\" 있다고 언급된 때에는, 어떤 구성요소가 다른 구성요소에 직접적으로 연결되거나, 다른 구성요소(예: 제3 구성요소)를 통하여 연결될 수 있다고 이해되어야 할 것이다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 출원에서, \"포함하다\" 또 는 \"구성되다\" 등의 용어는 명세서상에 기재된 특징, 숫자, 단계, 동작, 구성요소, 부품 또는 이들을 조합한 것이 존재함을 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성요소, 부품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되어야 한다. 본 개시에서 \"모듈\" 혹은 \"부\"는 적어도 하나의 기능이나 동작을 수행하며, 하드웨어 또는 소프트웨어로 구현되 거나 하드웨어와 소프트웨어의 결합으로 구현될 수 있다. 또한, 복수의 \"모듈\" 혹은 복수의 \"부\"는 특정한 하드 웨어로 구현될 필요가 있는 \"모듈\" 혹은 \"부\"를 제외하고는 적어도 하나의 모듈로 일체화되어 적어도 하나의 프 로세서(미도시)로 구현될 수 있다. 이하 첨부된 도면들을 참조하여 본 개시의 일 실시 예를 보다 상세하게 설명한다. 도 1은 본 개시의 일 실시 예에 따른 전자 장치의 구현 예를 설명하기 위한 도면이다. 전자 장치는 도 1에 도시된 바와 같이 TV 또는 set-top box 로 구현될 수 있으나, 이에 한정되는 것은 아 니며 스마트 폰, 태블릿 PC, 노트북 PC, HMD(Head mounted Display), NED(Near Eye Display), LFD(large format display), Digital Signage(디지털 간판), DID(Digital Information Display), 비디오 월(video wall), 프로젝터 디스플레이, 카메라, 캠코더, 프린터 등과 같이 영상 처리 및/또는 디스플레이 기능을 갖춘 장 치라면 한정되지 않고 적용 가능하다. 전자 장치는 다양한 압축 영상 또는 다양한 해상도의 영상을 수신할 수 있다. 예를 들어, 전자 장치 는 MPEG(Moving Picture Experts Group)(예를 들어, MP2, MP4, MP7 등), JPEG(joint photographic coding experts group), AVC(Advanced Video Coding), H.264, H.265, HEVC(High Efficiency Video Codec) 등으로 압 축된 형태로 영상을 수신할 수 있다. 또는 전자 장치는 SD(Standard Definition), HD(High Definition), Full HD, Ultra HD 영상 또는 그 이상 해상도의 영상 중 어느 하나의 영상을 수신할 수 있다. 명암비 향상은 영상의 어두운 영역과 밝은 영역의 차이를 명확히 하는 것으로서, 영상내의 관심 영역을 선명하 게 하거나 명암 값을 재분배하여 화질을 개선시키는 낮은 단계 영상처리 기법이다. 명암비 향상은 화질 개선을 통하여 인간의 눈에 선명한 영상을 제공하거나 영상 시스템에서 상위 영상 처리를 위한 전처리 과정으로 사용된 다. 기존의 영상 내 톤을 조절하는 톤 맵핑 커브(Tone mapping curve)를 설계하는 방법은 영상의 픽셀 분포를 고려 하여 히스토그램을 분산시킬 수 있는 커브를 설계하여 명암비가 향상된 영상을 얻을 수 있다. 하지만, 기존의 방식에서 고려되는 영상 특성은 픽셀 분포 히스토그램과 같은 일부 특성에 국한되며, 어떤 영상에서는 명암비 향상 효과가 있으나 다른 영상에서는 부작용이 발생할 가능성이 존재한다. 특히 과도한 톤 맵핑 커브의 적용은 영상의 정보를 훼손하여 시인성을 감소시킬 수 있다. 이에 따라 이하에서는, 명암비 향상 효과와 함께 과도한 명암비로 인해 발생되는 영상의 정보 손실 및/또는 부 작용(노이즈 부각, 색상 변화)을 식별하고 이를 기반으로 최적의 명암비 처리를 구현하는 다양한 실시 예에 대 해 설명하도록 한다. 도 2a는 일 실시 예에 따른 전자 장치의 구성을 나타내는 블럭도이다. 도 2a에 따르면 전자 장치은 디스플레이, 메모리 및 하나 이상의 프로세서를 포함한다. 디스플레이는 자발광 소자를 포함하는 디스플레이 또는, 비자발광 소자 및 백라이트를 포함하는 디스플레 이로 구현될 수 있다. 예를 들어, LCD(Liquid Crystal Display), OLED(Organic Light Emitting Diodes) 디스플 레이, LED(Light Emitting Diodes), 마이크로 LED(micro LED), Mini LED, PDP(Plasma Display Panel), QD(Quantum dot) 디스플레이, QLED(Quantum dot light-emitting diodes) 등과 같은 다양한 형태의 디스플레이 로 구현될 수 있다. 디스플레이 내에는 a-si TFT, LTPS(low temperature poly silicon) TFT, OTFT(organic TFT) 등과 같은 형태로 구현될 수 있는 구동 회로, 백라이트 유닛 등도 함께 포함될 수 있다. 일 예에 따라 디스플레이는 평면(flat) 디스플레이, 커브드(curved) 디스플레이, 폴딩(folding) 또는/및 롤링 (rolling) 가능한 플렉서블 디스플레이 등으로 구현될 수 있다. 메모리는 다양한 실시 예를 위해 필요한 데이터를 저장할 수 있다. 메모리는 데이터 저장 용도에 따 라 전자 장치(100')에 임베디드된 메모리 형태로 구현되거나, 전자 장치에 탈부착이 가능한 메모리 형태로 구현될 수도 있다. 예를 들어,전자 장치의 구동을 위한 데이터의 경우 전자 장치(100')에 임베디드된 메모 리에 저장되고, 전자 장치의 확장 기능을 위한 데이터의 경우 전자 장치에 탈부착이 가능한 메모리에 저장될 수 있다. 한편, 전자 장치에 임베디드된 메모리의 경우 휘발성 메모리(예: DRAM(dynamic RAM), SRAM(static RAM), 또는 SDRAM(synchronous dynamic RAM) 등), 비휘발성 메모리(non-volatile Memory)(예:OTPROM(one time programmable ROM), PROM(programmable ROM), EPROM(erasable and programmable ROM), EEPROM(electrically erasable and programmable ROM), mask ROM, flash ROM, 플래시 메모리(예: NAND flash 또는 NOR flash 등), 하드 드라이브, 또는 솔리드 스테이트 드라이브(solid state drive(SSD)) 중 적어도 하나 로 구현될 수 있다. 또한, 전자 장치(100')에 탈부착이 가능한 메모리의 경우 메모리 카드(예를 들어, CF(compact flash), SD(secure digital), Micro-SD(micro secure digital), Mini-SD(mini secure digital), xD(extreme digital), MMC(multi-media card) 등), USB 포트에 연결가능한 외부 메모리(예를 들어, USB 메모리) 등과 같은 형태로 구현될 수 있다. 일 예에 따라 메모리는 복수의 명암비 인핸스(enhance) 커브를 저장할 수 있다. 예를 들어, 명암비 인핸스 커브는 톤 맵핑 커브(tone mapping curve)로 구현될 수 있다. 여기서, 톤 맵핑이란 영상의 오리지널 톤을 디스 플레이의 다이내믹 레인지에 맞추어 표현하는 방법으로 콘트라스트를 최적화하여 최적화된 색감을 제공할 수 있다. 하나 이상의 프로세서는 전자 장치의 동작을 전반적으로 제어한다. 구체적으로, 하나 이상의 프로세 서는 전자 장치의 각 구성과 연결되어 전자 장치의 동작을 전반적으로 제어할 수 있다. 예를 들 어, 하나 이상의 프로세서는 디스플레이 및 메모리와 전기적으로 연결되어 전자 장치의 전 반적인 동작을 제어할 수 있다. 하나 이상의 프로세서는 하나 또는 복수의 프로세서로 구성될 수 있다. 하나 이상의 프로세서는 메모리에 저장된 적어도 하나의 인스트럭션(instruction)을 실행함으로써, 다양한 실시 예에 따른 전자 장치의 동작을 수행할 수 있다. 본 개시에 따른 인공지능과 관련된 기능은 전자 장치의 프로세서와 메모리를 통해 동작된다. 하나 이상의 프로세서는 하나 또는 복수의 프로세서로 구성될 수 있다. 이때, 하나 또는 복수의 프로세서 는 CPU(Central Processing Unit), GPU(Graphic Processing Unit), NPU(Neural Processing Unit) 중 적어도 하나를 포함할 수 있으나 전술한 프로세서의 예시에 한정되지 않는다. CPU는 일반 연산뿐만 아니라 인공지능 연산을 수행할 수 있는 범용 프로세서로서, 다계층 캐시(Cache) 구조를 통해 복잡한 프로그램을 효율적으로 실행할 수 있다. CPU는 순차적인 계산을 통해 이전 계산 결과와 다음 계산 결과의 유기적인 연계가 가능하도록 하는 직렬 처리 방식에 유리하다. 범용 프로세서는 전술한 CPU로 명시한 경 우를 제외하고 전술한 예에 한정되지 않는다. GPU는 그래픽 처리에 이용되는 부동 소수점 연산 등과 같은 대량 연산을 위한 프로세서로서, 코어를 대량으로 집적하여 대규모 연산을 병렬로 수행할 수 있다. 특히, GPU는 CPU에 비해 컨볼루션(Convolution) 연산 등과 같 은 병렬 처리 방식에 유리할 수 있다. 또한, GPU는 CPU의 기능을 보완하기 위한 보조 프로세서(co-processor)로 이용될 수 있다. 대량 연산을 위한 프로세서는 전술한 GPU로 명시한 경우를 제외하고 전술한 예에 한정되지 않 는다. NPU는 인공 신경망을 이용한 인공지능 연산에 특화된 프로세서로서, 인공 신경망을 구성하는 각 레이어를 하드 웨어(예로, 실리콘)로 구현할 수 있다. 이때, NPU는 업체의 요구 사양에 따라 특화되어 설계되므로, CPU나 GPU 에 비해 자유도가 낮으나, 업체가 요구하기 위한 인공지능 연산을 효율적으로 처리할 수 있다. 한편, 인공지능 연산에 특화된 프로세서로, NPU는 TPU(Tensor Processing Unit), IPU(Intelligence Processing Unit), VPU(Vision processing unit) 등과 같은 다양한 형태로 구현 될 수 있다. 인공 지능 프로세서는 전술한 NPU로 명시한 경우를 제외하고 전술한 예에 한정되지 않는다. 또한, 하나 이상의 프로세서는 SoC(System on Chip)으로 구현될 수 있다. 이때, SoC에는 하나 이상의 프 로세서는 이외에 메모리, 및 프로세서와 메모리 사이의 데이터 통신을 위한 버스(Bus)등과 같은 네트워크 인터페이스를 더 포함할 수 있다. 전자 장치에 포함된 SoC(System on Chip)에 복수의 프로세서가 포함된 경우, 전자 장치는 복수의 프 로세서 중 일부 프로세서를 이용하여 인공지능과 관련된 연산(예를 들어, 인공 지능 모델의 학습(learning)이나 추론(inference)에 관련된 연산)을 수행할 수 있다. 예를 들어, 전자 장치는 복수의 프로세서 중 컨볼루션 연산, 행렬 곱 연산 등과 같은 인공지능 연산에 특화된 GPU, NPU, VPU, TPU, 하드웨어 가속기 중 적어도 하나를 이용하여 인공지능과 관련된 연산을 수행할 수 있다. 다만, 이는 일 실시예에 불과할 뿐, CPU 등과 범용 프로세 서를 이용하여 인공지능과 관련된 연산을 처리할 수 있음은 물론이다. 또한, 전자 장치는 하나의 프로세서에 포함된 멀티 코어(예를 들어, 듀얼 코어, 쿼드 코어 등)를 이용하여 인공지능과 관련된 기능에 대한 연산을 수행할 수 있다. 특히, 전자 장치는 프로세서에 포함된 멀티 코어를 이 용하여 병렬적으로 컨볼루션 연산, 행렬 곱 연산 등과 같은 인공 지능 연산을 수행할 수 있다. 하나 이상의 프로세서는, 메모리에 저장된 기정의된 동작 규칙 또는 인공 지능 모델에 따라, 입력 데 이터를 처리하도록 제어한다. 기정의된 동작 규칙 또는 인공 지능 모델은 학습을 통해 만들어진 것을 특징으로 한다. 여기서, 학습을 통해 만들어진다는 것은, 다수의 학습 데이터들에 학습 알고리즘을 적용함으로써, 원하는 특성 의 기정의된 동작 규칙 또는 인공 지능 모델이 만들어짐을 의미한다. 이러한 학습은 본 개시에 따른 인공지능이 수행되는 기기 자체에서 이루어질 수도 있고, 별도의 서버/시스템을 통해 이루어 질 수도 있다. 인공 지능 모델은, 복수의 신경망 레이어들로 구성될 수 있다. 적어도 하나의 레이어는 적어도 하나의 가중치 (weight values)을 갖고 있으며, 이전(previous) 레이어의 연산 결과와 적어도 하나의 정의된 연산을 통해 레이 어의 연산을 수행한다. 신경망의 예로는, CNN(Convolutional Neural Network), RNN(Recurrent Neural Network), DNN(Deep Neural Network), RBM(Restricted Boltzmann Machine), DBN(Deep Belief Network), BRDNN(Bidirectional Recurrent Deep Neural Network) 및 심층 Q-네트워크(Deep Q-Networks), Transformer가 있으며, 본 개시에서의 신경망은 명시한 경우를 제외하고 전술한 예에 한정되지 않는다. 학습 알고리즘은, 다수의 학습 데이터들을 이용하여 소정의 대상 기기(예컨대, 로봇)을 훈련시켜 소정의 대상 기기 스스로 결정을 내리거나 식별을 할 수 있도록 하는 방법이다. 학습 알고리즘의 예로는, 지도형 학습 (supervised learning), 비지도형 학습(unsupervised learning), 준지도형 학습(semi-supervised learning) 또 는 강화 학습(reinforcement learning)이 있으며, 본 개시에서의 학습 알고리즘은 명시한 경우를 제외하고 전술 한 예에 한정되지 않는다. 이하에서는 설명의 편의를 위하여 하나 이상의 프로세서를 프로세서로 명 명하도록 한다. 도 2b는 일 실시 예에 따른 디스플레이 장치의 구성을 구체적으로 나타내는 블럭도이다. 도 2b에 따르면, 전자 장치(100')은 디스플레이, 메모리, 하나 이상의 프로세서, 통신 인터페이 스, 사용자 인터페이스, 스피커 및 카메라를 포함할 수 있다. 도 2b에 도시된 구성 중 도 2a에 도시된 구성과 중복되는 구성에 대해서는 자세한 설명을 생략하도록 한다. 통신 인터페이스는 전자 장치(100')의 구현 예에 따라 다양한 통신 방식을 지원할 수 있다. 예를 들어 통 신 인터페이스는 블루투스(Bluetooth), AP 기반의 Wi-Fi(와이파이, Wireless LAN 네트워크), 지그비 (Zigbee), 유/무선 LAN(Local Area Network), WAN(Wide Area Network), 이더넷(Ethernet), IEEE 1394, HDMI(High-Definition Multimedia Interface), USB(Universal Serial Bus), MHL(Mobile High-Definition Link), AES/EBU(Audio Engineering Society/ European Broadcasting Union), 옵티컬(Optical), 코액셜 (Coaxial) 등과 같은 통신 방식을 통해 외부 장치, 외부 저장 매체(예를 들어, USB 메모리), 외부 서버(예를 들 어 클라우드 서버) 등과 통신을 수행할 수 있다. 사용자 인터페이스는 버튼, 터치 패드, 마우스 및 키보드와 같은 장치로 구현되거나, 상술한 디스플레이 기능 및 조작 입력 기능도 함께 수행 가능한 터치 스크린으로 구현될 수 있다. 일 실시 예에 따라 사용자 인터 페이스는 리모콘 송수신부로 구현되어 원격 제어 신호를 수신할 수 있다. 리모콘 송수신부는 적외선 통신, 블루투스 통신 또는 와이파이 통신 중 적어도 하나의 통신 방식을 통해 외부 원격 제어 장치로부터 리모콘 신호 를 수신하거나, 리모콘 신호를 송신할 수 있다. 스피커는 음향 신호를 출력한다. 예를 들어, 스피커는 프로세서에서 처리된 디지털 음향 신호를 아날로그 음향 신호로 변환하고 증폭하여 출력할 수 있다. 예를 들어, 스피커는 적어도 하나의 채널을 출 력할 수 있는, 적어도 하나의 스피커 유닛, D/A 컨버터, 오디오 앰프(audio amplifier) 등을 포함할 수 있다. 일 예에 따라 스피커는 다양한 멀티 채널 음향 신호를 출력하도록 구현될 수 있다. 이 경우, 프로세서 는 입력 영상의 인핸스 처리에 대응되도록 입력된 음향 신호를 인핸스 처리하여 출력하도록 스피커를 제어할 수 있다. 카메라는 기 설정된 이벤트에 따라 턴 온 되어 촬영을 수행할 수 있다. 카메라는 촬상된 영상을 전기 적인 신호로 변환하고 변환된 신호에 기초하여 영상 데이터를 생성할 수 있다. 예를 들어, 피사체는 반도체 광 학소자(CCD; Charge Coupled Device)를 통해 전기적인 영상 신호로 변환되고, 이와 같이 변환된 영상 신호는 증 폭 및 디지털 신호로 변환된 후 신호 처리될 수 있다. 그 밖에 전자 장치(100')는 구현 예에 따라 마이크(미도시), 센서(미도시), 튜너(미도시) 및 복조부(미도시) 등 을 포함할 수 있다. 마이크(미도시)는 사용자 음성이나 기타 소리를 입력받아 오디오 데이터로 변환하기 위한 구성이다. 다만, 다른 실시 예에 따라 전자 장치(100')는 외부 장치를 통해 입력된 사용자 음성을 통신 인터페이스를 통해 수신 할 수 있다. 센서(미도시)는 터치 센서, 근접 센서, 가속도 센서, 지자기 센서, 자이로 센서, 압력 센서, 위치 센서, 조도 센서 등과 같은 다양한 유형의 센서를 포함할 수 있다. 튜너(미도시)는 안테나를 통해 수신되는 RF(Radio Frequency) 방송 신호 중 사용자에 의해 선택된 채널 또는 기 저장된 모든 채널을 튜닝하여 RF 방송 신호를 수신할 수 있다. 복조부(미도시)는 튜너에서 변환된 디지털 IF 신호(DIF)를 수신하여 복조하고, 채널 복호화 등을 수행할 수도 있다. 도 3은 일 실시 예에 따른 전자 장치의 영상 처리 방법을 설명하기 위한 흐름도이다. 도 3에 도시된 일 실시 예에 따르면, 프로세서는 복수의 명암비 인핸스 커브 각각을 입력 영상에 적용하여 획득된 복수의 후보 인핸스 영상을, 입력 영상과 비교하여 복수의 후보 인핸스 영상 각각에 대응되는 영상 변화 량 정보(또는 과도함 정보) 및 명암비 인핸스 효과 정보(이하, 인핸스 효과 정보)를 식별(또는 예측)할 수 있다 (S310). 예를 들어, 명암비 인핸스 커브는 톤 맵핑 커브(tone mapping curve)로 구현될 수 있고, 톤 맵핑 커브 가 N 개인 경우 N 개의 후보 인핸스 영상이 획득될 수 있다. 다만, 영역 별로 별개의 명암비 인핸스 커브가 적 용되는 경우, 즉 하나의 프레임에 복수의 톤 맵핑 커브가 적용되는 경우, 톤 맵핑 커브들의 조합의 개수 만큼 후보 인핸스 영상이 획득될 수도 있다. 이어서, 프로세서는 복수의 후보 인핸스 영상 각각에 대응되는 영상 변화량 정보 및 인핸스 효과 정보에 기초하여 복수의 후보 인핸스 영상 중 최종 인핸스 영상을 식별할 수 있다(S320). 일 예에 따라 프로세서 는 복수의 후보 인핸스 영상 중 영상 변화량 정보에 따른 영상 변화 값은 작고 인핸스 효과 정보에 따른 인핸스 효과 값은 큰 영상을 최종 인핸스 영상으로 식별할 수 있다. 즉, 프로세서는 복수의 인핸스 영상 중 영상 의 구조는 가능한 유지되면서 명암비 향상 효과는 큰 영상을 최종 인핸스 영상으로 식별할 수 있다. 이 후, 프로세서는 식별된 최종 인핸스 영상에 기초하여 입력 영상에 대응되는 출력 영상을 획득할 수 있 다(S330). 예를 들어, 프로세서는 식별된 최종 인핸스 영상에 적용된 톤 맵핑 커브를 입력 영상에 적용하 여 출력 영상을 획득할 수 있다. 도 4는 일 실시 예에 따른 영상 처리 방법을 수행하기 위한 기능 모듈들의 구성을 설명하기 위한 도면이다. 도 4에 도시된 각 기능 모듈들은 적어도 하나의 하드웨어 또는/및 적어도 하나의 소프트웨어의 조합으로 이루어 질 수 있다. 후보 인핸스 영상 획득 모듈은 복수의 명암비 인핸스 커브 각각을 입력 영상에 적용하여 획득된 복수의 후 보 인핸스 영상을 획득할 수 있다. 예를 들어, 후보 인핸스 영상 획득 모듈은 영상 프레임 단위, 복수의 영상 프레임 단위 또는 씬 단위 중 적어도 하나에 기초하여 복수의 후보 인핸스 영상을 획득할 수 있다. 예를 들어, 후보 인핸스 영상 획득 모듈 은 N 개의 명암비 인핸스 커브 각각을 제1 영상 프레임에 적용하여 제1 영상 프레임에 대응되는 N 개의 제 1 후보 인핸스 영상을 획득할 수 있다. 또한, 후보 인핸스 영상 획득 모듈은 N 개의 명암비 인핸스 커브 각각을 제2 영상 프레임에 적용하여 제2 영상 프레임에 대응되는 N 개의 제2 후보 인핸스 영상을 획득할 수 있 다. 예측 모듈은 영상 변화량 예측 모듈 및 인핸스 효과 예측 모듈을 포함할 수 있다. 영상 변화량 예측 모듈은 복수의 후보 인핸스 영상 각각을 입력 영상과 비교하여 복수의 후보 인핸스 영상 각각에 대응되는 영상 변화량 정보(또는 과도함 정보)를 예측할 수 있다. 예를 들어, 영상 변화량 예측 모듈은 영상 프레임 단위, 복수의 영상 프레임 단위 또는 씬 단위 중 적어도 하나에 기초하여 영상 변화량 정보를 예측할 수 있다. 예를 들어, 영상 변화량 예측 모듈은 N 개의 제1 후 보 인핸스 영상을 제1 영상 프레임과 비교하여 N 개의 제1 후보 인핸스 영상 각각에 대응되는 제1 영상 변화량정보를 예측할 수 있다. 또한, 영상 변화량 예측 모듈은 N 개의 제2 후보 인핸스 영상을 제2 영상 프레임 과 비교하여 N 개의 제2 후보 인핸스 영상 각각에 대응되는 제2 영상 변화량 정보를 예측할 수 있다. 인핸스 효과 예측 모듈은 복수의 후보 인핸스 영상 각각을 상기 입력 영상과 비교하여 복수의 후보 인핸스 영상 각각에 대응되는 인핸스 효과 정보를 예측할 수 있다. 예를 들어, 인핸스 효과 예측 모듈은 영상 프레임 단위, 복수의 영상 프레임 단위 또는 씬 단위 중 적어도 하나에 기초하여 인핸스 효과 정보를 예측할 수 있다. 예를 들어, 인핸스 효과 예측 모듈은 N 개의 제1 후 보 인핸스 영상 각각의 픽셀 균일 분포 정보에 기초하여 N 개의 제1 후보 인핸스 영상 각각에 대응되는 제1 인 핸스 효과 정보를 예측할 수 있다. 또한, 인핸스 효과 예측 모듈은 N 개의 제2 후보 인핸스 영상 각각의 픽셀 균일 분포 정보에 기초하여 N 개의 제2 후보 인핸스 영상 각각에 대응되는 제2 인핸스 효과 정보를 예측할 수 있다. 명암비 인핸스 결정 모듈은 예측 모듈의 예측 결과에 기초하여 최종 명암비 인핸스 커브를 결정할 수 있다. 예를 들어, 명암비 인핸스 결정 모듈은 N 개의 제1 후보 인핸스 영상 각각에 대응되는 제1 영상 변화량 정 보 및 제1 인핸스 효과 정보의 가중 합 정보에 기초하여 제1 영상 프레임에 대응되는 최종 명암비 인핸스 커브 를 결정할 수 있다. 또한, 명암비 인핸스 결정 모듈은 N 개의 제2 후보 인핸스 영상 각각에 대응되는 제2 영상 변화량 정보 및 제2 인핸스 효과 정보의 가중 합 정보에 기초하여 제2 영상 프레임에 대응되는 최종 명암 비 인핸스 커브를 결정할 수 있다. 한편, 경우에 따라 객체 별(또는 영역 별)로 상이한 명암비 인핸스 커브가 적용될 수 있으나, 이 경우에도 상술 한 방법과 유사한 방법으로 객체 별(또는 영역 별) 최종 명암비 인핸스 커브가 결정될 수 있다. 예를 들어, 객 체 별로 상이한 명암비 인핸스 커브가 적용된 후보 인핸스 영상을 획득하고, 각 후보 인핸스 영상에 대해 영상 변화량 정보 및 인핸스 효과 정보를 획득하여 최종 명암비 인핸스 커브를 결정할 수 있다. 즉, 객체 별로 명암 비 인핸스 커브의 상이한 조합을 각각 적용하여 각 조합에 대응되는 후보 인핸스 영상을 획득할 수 있다. 도 5는 일 실시 예에 따른 영상 변화량 정보 및 인핸스 효과 정보를 예측하는 방법을 설명하기 위한 흐름도이다. 도 5에 도시된 실시 예에 따르면, 프로세서는 영상 변화량 정보를 획득하기 위하여, 복수의 후보 인핸스 영상 각각을 입력 영상과 비교하여 복수의 후보 인핸스 영상 각각에 대응되는 픽셀 구조 변화량, 노이즈 레벨 변화량 및 색상 변화량을 식별할 수 있다(S510). 픽셀 구조 변화량, 노이즈 레벨 변화량 및 색상 변화량은 영상 변화량을 획득하기 위한 예시들일 수 있으나 반드시 이에 한정되는 것은 아니다. 예를 들어, 픽셀 구조 변화량, 노이즈 레벨 변화량 및 색상 변화량 중 일부가 영상 변화량을 획득하는데 이용되지 않거나, 다른 추가 변화량이 영상 변화량을 획득하는데 추가될 수 있다. 일 예로, 영상의 타입, 원본 영상의 프레임율 등에 따라 영상 변화 량에 이용되는 예시가 달라질 수도 있다. 이어서, 프로세서는 픽셀 구조 변화량, 노이즈 레벨 변화량 및 색상 변화량에 기초하여 복수의 후보 인핸 스 영상 각각에 대응되는 영상 변화량 정보를 획득할 수 있다(S520). 일 예에 따라 프로세서는 픽셀 구조 변화량, 노이즈 레벨 변화량 및 색상 변화량 각각에 대응되는 기 설정된 가중치를 적용하여 영상 변화량 값을 획득할 수 있다. 이 경우 프로세서는 영상 변화량 값을 역으로 환산하여 영상 변화량 정보를 획득할 수 있 다. 예를 들어, 프로세서는 영상 변화량 값을 역으로 환산한 후 정규화하여 영상 변화량 정보를 획득할 수 있다. 이는 프로세서는 추후 영상 변화량 정보와 인핸스 효과 정보와의 통합 정보를 획득하기 위하여 역의 관계에 있는 정보를 동일한 기준으로 변환하기 위함이다. 또한, 프로세서는 명암비 인핸스 효과 정보를 획득하기 위하여, 복수의 후보 인핸스 영상 각각에 대응되는 픽셀 균일 분포 정보를 식별할 수 있다(S530). 일 예에 따라 프로세서는 복수의 후보 인핸스 영상 각각에 대응되는 히스토그램 정보에 기초하여 효과 식별 값을 획득할 수 있다. 이어서, 프로세서는 복수의 후보 인핸스 영상 각각에 대응되는 픽셀 균일 분포 정보에 기초하여 복수의 후 보 인핸스 영상 각각에 대응되는 인핸스 효과 정보를 획득할 수 있다. 일 예에 따라 프로세서는 복수의 후 보 인핸스 영상 각각에 대응되는 효과 식별 값을 정규화하여 복수의 후보 인핸스 영상 각각에 대응되는 인핸스 효과 정보를 획득할 수 있다. 이 후, 프로세서는 영상 변화량 정보 및 인핸스 효과 정보에 기 설정된 가중치를 적용하여 복수의 후보 인 핸스 영상 각각에 대응되는 최종 식별 값을 식별하고, 식별된 최종 식별 값에 기초하여 최종 인핸스 영상을 식 별할 수 있다. 한편, 도 5에서는 S510, S520 단계가 S530, S540 단계보다 먼저 수행되는 것으로 도시/설명 되었으나, 영상 변 화량 정보 및 인핸스 효과 정보는 개별적으로 획득될 수 있으므로 순서에 한정되지 않음은 물론이다. 이하에서는 도면 및 수학식을 참고하여 본 개시의 일 실시 예에 대해 좀더 자세히 설명하도록 한다. 도 6a 및 도 6b는 일 예시에 따른 영상 처리 방법을 설명하기 위한 도면들이다. 일 예에 따라 프로세서는 도 6a에 도시된 바와 같이 입력 영상에 대해 N 개의 명암비 인핸스 커브를 적용 하여 N 개의 후보 인핸스 영상을 획득할 수 있다. 여기서, N 개의 명암비 인핸스 커브는 글로벌 커브 명암비 향 상, 로컬 커브 명암비 향상, 객체 단위 명암비 향상 및 이러한 방법들의 조합에 기초한 다양한 커브일 수 있다. 예를 들어, 프로세서는 하기 수학식 1과 같은 후보 인핸스 영상 IE(x)를 획득할 수 있다. 수학식 1"}
{"patent_id": "10-2023-0006261", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "여기서, IE(x)는 후보 인핸스 영상, fx는 명암비 인핸스 커브, Io는 입력 영상을 의미할 수 있다. 예를 들어, 도 6b에 도시된 바와 같이 입력 영상(Io)에 대해 f1, f2, ,,, fN의 명암비 인핸스 커브를 적용하 여 후보 인핸스 영상 IE, IE, ... IE(N)를 획득할 수 있다. 일 예에 따라 프로세서는 과도한 명암비 향상에 따른 픽셀 구조 변화량(예를 들어, 에지(edge) 손실 및 텍 스처(texture) 변화량), 노이즈 레벨 변화량, 색상 변화량에 기초하여 영상 변화량 즉, 과도함을 예측할 수 있 다. 예를 들어, 입력 영상과 후보 인핸스 영상 간의 픽셀 구조 변화량, 노이즈 레벨 변화량, 색상 변화량을 산 출하여 변화량이 크면 클수록 과도함이 심하다고 판단할 수 있다. 일 예에 따라 수학식 2와 같이 입력 영상과 후보 인핸스 영상 간의 픽셀 구조 변화량, 노이즈 레벨 변화량, 색 상 변화량을 산출하여 영상 변화량 예측 값(또는 과도함 예측 값)(OM)을 산출할 수 있다. 수학식 2"}
{"patent_id": "10-2023-0006261", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "여기서, ΔST는 픽셀 구조 변화량, ΔNL은 노이즈 레벨 변화량, ΔColor은 색상 변화량을 의미할 수 있다. wST, wNL 및 wCOLOR는 각 항에 대항 가중치를 의미할 수 있다. wST, wNL 및 wCOLOR는 학습에 의해 결정되거나, 제조사에 의 해 기 설정되거나, 사용자에 의해 설정/변경 될 수 있다. 픽셀 구조 변화량(ΔST)은 에지 영역 또는 텍스처 영역의 구조적 변화량을 예측하는 것으로 값이 클수록 구조적 변화가 심하여 명암비 향상 결과가 과도하다고 판단될 수 있다. 또한, 노이즈 레벨 변화량(ΔNL)은 명암비 향상 에 의해 부각되는 노이즈 레벨의 변화량을 나타내는 것으로 변화량이 클수록 입력 영상 대비 노이즈가 많이 부 각되는 것을 의미할 수 있다. 또한, 색상 변화량(ΔColor)은 명암비 향상에 의해 색상(Hue)이 틀어지는 정도를 나타내는 것으로 값이 클수록 색이 많이 틀어지는 부작용이 발생된다고 판단될 수 있다. 한편, 프로세서는 인핸스 효과 정보와의 통합 연산을 위하여 하기 수학식 3과 같이 영상 변화량 예측 값을 역으로 환산하고 정규화하여 최종 영상 변화량 예측 값(OMfinal)을 산출할 수 있다. 즉, 최종 영상 변화량 예측 값은 클수록 변화량이 과도하지 않다고 판단될 수 있다. 수학식 3"}
{"patent_id": "10-2023-0006261", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "여기에서, OMmax는 최대 영상 변화량 값, OMmin는 최소 영상 변화량 값, k는 정규화 범위를 의미할 수 있다. 한편, 프로세서는 후보 인핸스 영상에서 픽셀의 균일 분포 정도를 산출하여 인핸스 효과 정보를 획득할 수 있다. 예를 들어, 특정 픽셀 값에 집중되어 있지 않고 균등하게 분포될수록 인핸스 효과 예측 값은 커지고, 이 는 명암비 향상 효과가 좋다고 판단할 수 있다. 하기 수학식 4는 히스토그램을 이용하여 픽셀의 균일 분포 정도를 산출하는 수식의 예시를 나타낸다. 수학식 4"}
{"patent_id": "10-2023-0006261", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "여기에서 TP는 영상의 전체 픽셀 수를 의미하고, R은 Gray-level의 표현 범위(예를 들면, 10bit 표현시 1024계 조)를 의미할 수 있다. 또한, 프로세서는 영상 변화량 예측 값과의 통합 연산을 위하여 하기 수학식 5와 같이 정규화를 수행하여 최종 인핸스 효과 예측 값(EMfinal)을 산출할 수 있다. 수학식 5"}
{"patent_id": "10-2023-0006261", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "여기에서 k는 정규화 범위를 의미한다. 이 후, 프로세서는 영상 변화량 예측 값 및 인핸스 효과 예측 값에 기초하여 최종 예측값을 산출할 수 있 다. 예를 들어, 프로세서는 도 6a에 도시된 바와 같이 N 개의 후보 인핸스 영상에 대한 최종 명암비 예측 값을 스코어로 산출할 수 있다. 수학식 6은 최종 예측값을 산출하는 수식의 예시를 나타낸다. 수학식 6"}
{"patent_id": "10-2023-0006261", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 7, "content": "여기에서 wOM 및 wEM은 영상 변화량 예측 값 및 인핸스 효과 예측 값에 대한 가중치를 디스플레이의 패널 특성, 영상의 해상도, 영상의 원본 프레임 율, 영상 타입 등에 따라 상이하게 결정될 수 있다. 예를 들어, 밝기 도 낮고 명암비 특성도 좋지 않은 패널이라면 인핸스 효과 예측 값에 대한 가중치(wEM)를 영상 변화량 예측 값에 대한 가중치(wOM) 대비 상대적으로 크게 설정할 수 있다. 이 후, 프로세서는 N 개의 최종 예측 값 중 가장 큰 값 즉, 스코어가 가장 큰 값을 인덱스(Index)로 선택 하고, 해당 인덱스에 대응되는 후보 인핸스 영상을 최종 출력 영상 IE(Index)으로 결정할 수 있다. 여기서, N개의 최종 예측 값 중 가장 큰 값은 인핸스 효과는 최대이고, 부작용과 관련된 과도함은 최소가 되는 값일 수 있다. 하기 수학식 7은 최종 명암비 인핸스 영상을 결정하는 수식의 예시를 나타낸다. 수학식 7"}
{"patent_id": "10-2023-0006261", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 8, "content": "예를 들어, 도 6b에 도시된 바와 같이 후보 인핸스 영상 IE, IE, ... IE(N) 중 최종 출력 영상 IE(Index) 이 선택될 수 있다. 한편, 일 실시 예에 따르면, 프로세서는 학습된 인공 지능 모델을 이용하여 상술한 영상 처리 동작들 중 적어도 일부를 수행할 수 있다. 도 7a 및 도 7b는 일 실시 예에 따른 학습된 인공 지능 모델을 이용하는 영상 처리 방법을 설명하기 위한 도면 들이다. 일 실시 예에 따르면, 도 4에 도시된 예측 모듈 및 명암비 인핸스 결정 모듈의 동작을 인공 지능 모 델을 통해 학습시켜 해당 동작을 구현할 수 있다. 예를 들어, 도 7a에 도시된 바와 같이 프로세서는 입력 영상으로부터 영상의 특징 정보를 획득(또는 추출)하고, 획득된 특징 정보를 학습된 제1 인공 지능 모델로 입력하여 입력 영상에 대응되는 명암비 인핸스 커브 #2를 획득할 수 있다. 즉, 학습된 제1 인공 지능 모델은 N 개의 명암비 인핸스 커브 중 입력 영상에 대응되는 명암비 인핸스 커브 #2에 대한 식별 정보를 출력할 수 있다. 여기서, 학습된 제1 인공 지 능 모델은 학습 기반 분류기로 구현될 수 있으나 반드시 이에 한정되는 것은 아니다. 일 예에 따라 영상의 특징 정보는 영상의 에지 정보, 텍스처 정보, 노이즈 정보, 히스토그램 정보 등과 같이 영상 변화량 및 인핸스 효과와 관련된 특징 정보일 수 있다. 일 예에 따라 학습된 제1 인공 지능 모델은 영상의 특징 정보가 입력되면 복수의 명암비 인핸스 커브에 대 응되는 영상 변화량 정보 및 인핸스 효과 정보에 기초하여 복수의 명암비 인핸스 커브 중 하나의 명암비 인핸스 커브에 대한 정보를 출력하도록 학습될 수 있다. 제1 인공 지능 모델의 학습시 Ground Truth는 도 3 내지 도 6b에서 설명한 방식에 따라 획득한 데이터를 이용할 수 있다. 일 실시 예에 따르면, 프로세서는 입력 영상으로부터 영상의 특징 정보를 획득하고, 획득된 특징 정보 를 학습된 제1 인공 지능 모델로 입력하여 선택기를 통해 선택된 명암비 인핸스 커브 #2가 입력 영상 에 적용되도록 할 수 있다. 예를 들어, 도 7b에 도시된 바와 같이 입력 영상이 선택기로 제공되고, 선택기 를 통해 선택된 명암비 인핸스 커브 #2가 입력 영상에 적용되어 출력 영상이 획득될 수 있다. 이와 같 이 입력 영상에서 출력 영상을 획득하는 과정이 도 7b에 도시된 바와 같은 로직으로 진행될 수 있다. 도 8은 일 실시 예에 따른 학습된 인공 지능 모델을 이용하는 영상 처리 방법을 설명하기 위한 도면이다. 일 실시 예에 따르면, 도 4에 도시된 예측 모듈의 동작을 인공 지능 모델을 통해 학습시켜 해당 동작을 구 현할 수 있다. 예를 들어, 도 8에 도시된 바와 같이 프로세서는 입력 영상으로부터 영상의 특징 정보를 획득(또는 추 출)하고, 획득된 특징 정보를 학습된 제2 인공 지능 모델로 입력하여 복수의 후보 인핸스 영상에 대응되는 영상 변화량 정보 및 인핸스 효과 정보를 획득할 수 있다. 즉, 학습된 제2 인공 지능 모델은 N 개의 명암 비 인핸스 커브 각각에 대응되는 영상 변화량 정보 및 인핸스 효과 정보를 출력할 수 있다. 여기서, 학습된 제2 인공 지능 모델은 학습 기반 분류기로 구현될 수 있으나 반드시 이에 한정되는 것은 아니다. 일 예에 따라 영상의 특징 정보는 영상의 에지 정보, 텍스처 정보, 노이즈 정보, 히스토그램 정보 등과 같이 영상 변화량 및 인핸스 효과와 관련된 특징 정보일 수 있다. 일 예에 따라 학습된 제2 인공 지능 모델은 영상의 특징 정보가 입력되면 영상에 복수의 명암비 인핸스 커 브를 적용하여 획득된 복수의 후보 인핸스 영상에 대응되는 영상 변화량 정보 및 인핸스 효과 정보를 출력하도 록 학습될 수 있다. 제2 인공 지능 모델의 학습시 Ground Truth는 도 3 내지 도 6b에서 설명한 방식에 따라 획득한 데이터를 이용할 수 있다. 이 경우, 프로세서는 복수의 후보 인핸스 영상 각각에 대응되는 영상 변화량 정보 및 인핸스 효과 정보에 기초하여 복수의 후보 인핸스 영상 중 최종 인핸스 영상을 식별할 수 있다. 즉, 프로세서는 최종 인핸스 영상에 대응되는 명암비 인핸스 커브를 식별하고, 식별된 명암비 인핸스 커브에 기초하여 입력 영상을 처리 할 수 있다. 도 9는 일 실시 예에 따른 학습된 인공 지능 모델을 이용하는 영상 처리 방법을 설명하기 위한 도면이다. 일 실시 예에 따르면, 도 4에 도시된 후보 인핸스 영상 획득 모듈, 예측 모듈 및 명암비 인핸스 결정 모듈의 동작을 인공 지능 모델을 통해 학습시켜 해당 동작을 구현할 수 있다. 예를 들어, 도 9에 도시된 바와 같이 프로세서는 입력 영상을 학습된 제3 인공 지능 모델에 입력 하여 출력 영상을 획득할 수 있다. 일 예에 따라 제3 인공 지능 모델은 픽셀 단위의 CNN(Convolutional Neural Network) 딥러닝 네트워크로 구현될 수 있으나, 이에 한정되는 것은 아니다. 일 예에 따라 학습된 제3 인공 지능 모델은 영상이 입력되면, 영상에 복수의 명암비 인핸스 커브를 적용하 여 획득된 복수의 후보 인핸스 영상에 대응되는 영상 변화량 정보 및 인핸스 효과 정보를 식별하고, 식별된 영 상 변화량 정보 및 인핸스 효과 정보에 기초하여 복수의 후보 인핸스 영상 중 최종 인핸스 영상을 식별하여 출 력하도록 학습될 수 있다. 제3 인공 지능 모델의 학습시 Ground Truth는 도 3 내지 도 6b에서 설명한 방식 에 따라 획득한 데이터를 이용할 수 있다. 도 10은 일 실시 예에 따른 학습된 인공 지능 모델을 이용하는 영상 처리 방법을 설명하기 위한 도면이다. 일 실시 예에 따르면, 도 4에 도시된 후보 인핸스 영상 획득 모듈, 예측 모듈 및 명암비 인핸스 결정 모듈의 동작을 인공 지능 모델을 통해 학습시켜 해당 동작을 구현할 수 있다. 예를 들어, 도 10에 도시된 바와 같이 프로세서는 입력 영상을 학습된 제4 인공 지능 모델에 입 력하여 입력 영상에 대응되는 명암비 인핸스 커브 #2를 획득할 수 있다. 일 예에 따라 제4 인공 지능 모델 은 픽셀 단위의 CNN(Convolutional Neural Network) 딥러닝 네트워크로 구현될 수 있으나, 이에 한정되 는 것은 아니다. 일 예에 따라 학습된 제4 인공 지능 모델은 영상이 입력되면, 복수의 명암비 인핸스 커브에 대응되는 영 상 변화량 정보 및 인핸스 효과 정보에 기초하여 복수의 명암비 인핸스 커브 중 하나의 명암비 인핸스 커브에 대한 정보를 출력하도록 학습될 수 있다. 제4 인공 지능 모델의 학습시 Ground Truth는 도 3 내지 도 6b 에서 설명한 방식에 따라 획득한 데이터를 이용할 수 있다. 이 경우, 프로세서는 제4 인공 지능 모델을 이용하여 식별된 명암비 인핸스 커브(예를 들어, 명암비 인핸스 커브 #2)에 기초하여 입력 영상을 처리할 수 있다. 상술한 다양한 실시 예들에 따르면, 명암비 향상 효과 예측 뿐만 아니라 부작용과 관련된 과도함을 예측하여 에 지 및 텍스처의 디테일 손실이 최소화되고 노이즈가 덜 부각되면서 색상 변화가 적은 최적의 명암비 향상 처리 를 제공할 수 잇게 된다. 한편, 상술한 본 개시의 다양한 실시 예들에 따른 방법들은, 기존 전자 장치에 대한 소프트웨어 업그레이드, 또 는 하드웨어 업그레이드 만으로도 구현될 수 있다. 또한, 상술한 본 개시의 다양한 실시 예들은 전자 장치에 구비된 임베디드 서버, 또는 전자 장치의 외부 서버를 통해 수행되는 것도 가능하다. 한편, 본 개시의 일시 예에 따르면, 이상에서 설명된 다양한 실시 예들은 기기(machine)(예: 컴퓨터)로 읽을 수 있는 저장 매체(machine-readable storage media)에 저장된 명령어를 포함하는 소프트웨어로 구현될 수 있다. 기기는, 저장 매체로부터 저장된 명령어를 호출하고, 호출된 명령어에 따라 동작이 가능한 장치로서, 개시된 실 시 예들에 따른 전자 장치(예: 전자 장치(A))를 포함할 수 있다. 명령이 프로세서에 의해 실행될 경우, 프로세 서가 직접, 또는 프로세서의 제어 하에 다른 구성요소들을 이용하여 명령에 해당하는 기능을 수행할 수 있다. 명령은 컴파일러 또는 인터프리터에 의해 생성 또는 실행되는 코드를 포함할 수 있다. 기기로 읽을 수 있는 저 장 매체는, 비일시적(non-transitory) 저장매체의 형태로 제공될 수 있다. 여기서, '비일시적'은 저장매체가 신 호(signal)를 포함하지 않으며 실재(tangible)한다는 것을 의미할 뿐 데이터가 저장매체에 반영구적 또는 임시 적으로 저장됨을 구분하지 않는다.또한, 본 개시의 일 실시 예에 따르면, 이상에서 설명된 다양한 실시 예들에 따른 방법은 컴퓨터 프로그램 제품 (computer program product)에 포함되어 제공될 수 있다. 컴퓨터 프로그램 제품은 상품으로서 판매자 및 구매자 간에 거래될 수 있다. 컴퓨터 프로그램 제품은 기기로 읽을 수 있는 저장 매체(예: compact disc read only memory (CD-ROM))의 형태로, 또는 어플리케이션 스토어(예: 플레이 스토어TM)를 통해 온라인으로 배포될 수 있 다. 온라인 배포의 경우에, 컴퓨터 프로그램 제품의 적어도 일부는 제조사의 서버, 어플리케이션 스토어의 서버, 또는 중계 서버의 메모리와 같은 저장 매체에 적어도 일시 저장되거나, 임시적으로 생성될 수 있다. 또한, 상술한 다양한 실시 예들에 따른 구성 요소(예: 모듈 또는 프로그램) 각각은 단수 또는 복수의 개체로 구 성될 수 있으며, 전술한 해당 서브 구성 요소들 중 일부 서브 구성 요소가 생략되거나, 또는 다른 서브 구성 요 소가 다양한 실시 예에 더 포함될 수 있다. 대체적으로 또는 추가적으로, 일부 구성 요소들(예: 모듈 또는 프로 그램)은 하나의 개체로 통합되어, 통합되기 이전의 각각의 해당 구성 요소에 의해 수행되는 기능을 동일 또는 유사하게 수행할 수 있다. 다양한 실시 예들에 따른, 모듈, 프로그램 또는 다른 구성 요소에 의해 수행되는 동 작들은 순차적, 병렬적, 반복적 또는 휴리스틱하게 실행되거나, 적어도 일부 동작이 다른 순서로 실행되거나, 생략되거나, 또는 다른 동작이 추가될 수 있다. 이상에서는 본 개시의 바람직한 실시 예에 대하여 도시하고 설명하였지만, 본 개시는 상술한 특정의 실시 예에"}
{"patent_id": "10-2023-0006261", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 9, "content": "한정되지 아니하며, 청구범위에서 청구하는 본 개시의 요지를 벗어남이 없이 당해 개시에 속하는 기술분야에서 통상의 지식을 가진 자에 의해 다양한 변형실시가 가능한 것은 물론이고, 이러한 변형실시들은 본 개시의 기술 적 사상이나 전망으로부터 개별적으로 이해되어서는 안될 것이다."}
{"patent_id": "10-2023-0006261", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 개시의 일 실시 예에 따른 전자 장치의 구현 예를 설명하기 위한 도면이다. 도 2a는 일 실시 예에 따른 전자 장치의 구성을 나타내는 블럭도이다. 도 2b는 일 실시 예에 따른 디스플레이 장치의 구성을 구체적으로 나타내는 블럭도이다. 도 3은 일 실시 예에 따른 전자 장치의 영상 처리 방법을 설명하기 위한 흐름도이다. 도 4는 일 실시 예에 따른 영상 처리 방법을 수행하기 위한 기능 모듈들의 구성을 설명하기 위한 도면이다. 도 5는 일 실시 예에 따른 영상 변화량 정보 및 인핸스 효과 정보를 예측하는 방법을 설명하기 위한 흐름도이다. 도 6a 및 도 6b는 일 예시에 따른 영상 처리 방법을 설명하기 위한 도면들이다. 도 7a 및 도 7b는 일 실시 예에 따른 학습된 인공 지능 모델을 이용하는 영상 처리 방법을 설명하기 위한 도면 들이다. 도 8은 일 실시 예에 따른 학습된 인공 지능 모델을 이용하는 영상 처리 방법을 설명하기 위한 도면이다. 도 9는 일 실시 예에 따른 학습된 인공 지능 모델을 이용하는 영상 처리 방법을 설명하기 위한 도면이다. 도 10은 일 실시 예에 따른 학습된 인공 지능 모델을 이용하는 영상 처리 방법을 설명하기 위한 도면이다."}
