{"patent_id": "10-2023-0028493", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0135519", "출원번호": "10-2023-0028493", "발명의 명칭": "마이 무비 서비스를 지원하는 마이 무비 시스템 및 방법", "출원인": "대전대학교 산학협력단", "발명자": "정한일"}}
{"patent_id": "10-2023-0028493", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "사용자로부터 수집되는 시나리오에 근거하여, 메타버스(metaverse) 상의 아바타에 모션을 부여하여, 3D 영상 컨텐츠를 제작하는 마이 무비 서비스 지원부를 포함하고,상기 마이 무비 서비스 지원부는,씬(scene)에 대한 언어적 정보를 식별(Preparing linguistic data)하고, 상기 씬에 대응하는 3차원 공간을 생성(Building VR/AR space)하며, 상기 씬에 상응하여 디자인된 아바타를 등장(Summoning avatars)시키고, 상기씬의 서브 씬(sub-scene)에 대한 하위 세부 과정(For each sub-scene)을 수행 함으로써, 상기 시나리오를 구성하는 복수의 씬 각각에 대해 상기 아바타에게 부여할 모션을 정의하는마이 무비 서비스를 지원하는 마이 무비 시스템."}
{"patent_id": "10-2023-0028493", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 마이 무비 서비스 지원부는,Motion Generation Engine을 포함하고, 상기 Motion Generation Engine을 이용하여, 상기 아바타의 모션을 생성(Generating avatar motion)하고, 상기 언어적 정보를 상기 아바타의 모션과 연계(Mapping motion withlinguistic info.) 시킴으로써, 상기 서브 씬에서 등장하는 상기 아바타에 대해 하위 세부 과정을 수행(Foreach avatar)하며,상기 Motion Generation Engine은,사람의 모션을 3D Clip으로 변환하는 3D Motion Clip Conversion Module;상기 3D Clip을 저장하는 3D Motion Clip DB;상기 3D Motion Clip DB로부터, 씬에서 아바타가 행하여야 하는 모션에 대한 정보에 근거하여 특정의 3D Clip을탐색하는 Clip Search Module;상기 탐색된 3D Clip의 모션을 아바타에게 입히는 Motion Dressing Module; 및상기 아바타에게 입혀진 상기 3D Clip의 모션을 편집하는 Motion Editor를 포함하여 구성하는,마이 무비 서비스를 지원하는 마이 무비 시스템."}
{"patent_id": "10-2023-0028493", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 마이 무비 서비스 지원부는,Linguistic Info. Processing Engine을 포함하고, 상기 Linguistic Info. Processing Engine을 이용하여, 상기씬에서 나타나는 대사, 음성, 문자 중 적어도 하나를 포함하는 상기 언어적 정보를 식별하고,상기 Linguistic Info. Processing Engine은,음성 형태의 입력 데이터에 대해 음성 인식 기술을 적용하여 문자 형식의 데이터로 변환하는 Speech-TO-TextModule;문자 형태의 입력 데이터에 대해 음성 합성 기술을 적용하여 음성 형식의 데이터로 변환하는 Text-To-Speech공개특허 10-2024-0135519-3-Module;상기 음성 형태의 입력 데이터 또는 상기 문자 형태의 입력 데이터를, 씬 태그, 아바타 태그, 및 일련번호를 연관시켜 저장하는 Dialog DB; 및상기 음성 형태의 입력 데이터 및 상기 문자 형태의 입력 데이터를, 상호 분할 및 병합하여 동기화 처리하는Dialog Editor를 포함하여 구성하는,마이 무비 서비스를 지원하는 마이 무비 시스템."}
{"patent_id": "10-2023-0028493", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,상기 마이 무비 서비스 지원부는,VR/AR Space Building Engine을 포함하고, 상기 VR/AR Space Building Engine을 통해, 현재 작업 중인 씬에 해당하는 3차원 공간을 생성하며,상기 VR/AR Space Building Engine은,상기 가상 공간을 구성하는데 사용되는 객체들의 3D 모델을 저장하는 VR Space Elementary Repository(VR-SER);상기 객체들의 3D 모델을 조합하여 가상 공간을 구성하고, 상기 가상 공간을 저장하는 VR Space Repository(VR-SR);외부 개방형 플랫폼으로부터 입수된 특정 위치의 실제 3D 컨텐츠 정보를 상기 가상 공간에 디스플레이하는 RawData Processing Module;사용자로부터의 요청에 따라 신규 3D 객체를 생성하는 External 3D Modeling System과의 연계를 지원하는Interface Module; 및상기 신규 3D 객체의 생성과 연동하여 상기 가상 공간을 수정 함으로써, 상기 신규 3D 객체에 관한 3D 컨텐츠정보가 상기 가상 공간에서 디스플레이 되도록 하는 Space Editor를 포함하여 구성하는,마이 무비 서비스를 지원하는 마이 무비 시스템."}
{"patent_id": "10-2023-0028493", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서,상기 마이 무비 서비스 지원부는,Avatar Creation Engine을 포함하고, 상기 Avatar Creation Engine을 통해 디자인된 아바타를, 상기 씬에서의모션을 입히기 위하여 등장시키는 것을 포함하고,상기 Avatar Creation Engine은,얼굴을 포함한, 상기 아바타의 바디를 제작하는 Body Modeling;상기 아바타가 입고 있는 의상을 제작하는 Clothes Modeling;상기 아바타에게 뼈대와 관절에 관한 인체공학적 특징을 부여하는 Character Rigging;상기 바디의 제작, 상기 의상의 제작, 및 상기 인공공학적 특징의 부여에 따라, 상기 아바타를 디자인하고, 상기 씬에 대응하여 저장하는 Avatar DB; 및External Avatar Modeling System과 연결되어, 상기 디자인된 아바타를 교환하는 Interface Module를 포함하여 구성하는,공개특허 10-2024-0135519-4-마이 무비 서비스를 지원하는 마이 무비 시스템."}
{"patent_id": "10-2023-0028493", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "사용자로부터 수집되는 시나리오에 근거하여, 메타버스(metaverse) 상의 아바타에 모션을 부여하여, 3D 영상 컨텐츠를 제작하는 단계(Based on my scenario)로서,씬(scene)에 대한 언어적 정보를 식별(Preparing linguistic data)하고, 상기 씬에 대응하는 3차원 공간을 생성(Building VR/AR space)하며, 상기 씬에 상응하여 디자인된 아바타를 등장(Summoning avatars)시키고, 상기씬의 서브 씬(sub-scene)에 대한 하위 세부 과정(For each sub-scene)을 수행 함으로써, 상기 시나리오를 구성하는 복수의 씬 각각에 대해 상기 아바타에게 부여할 모션을 정의하는 단계(For each scene)를 포함하는, 마이 무비 서비스를 지원하는 마이 무비 방법."}
{"patent_id": "10-2023-0028493", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6항에 있어서,상기 씬의 서브 씬에 대한 하위 세부 과정(For each sub-scene)은,Motion Generation Engine을 이용하여, 상기 아바타의 모션을 생성(Generating avatar motion)하고, 상기 언어적 정보를 상기 아바타의 모션과 연계(Mapping motion with linguistic info.) 시킴으로써, 상기 서브 씬에서등장하는 상기 아바타에 대해 하위 세부 과정을 수행(For each avatar)하는 것을 포함하고,상기 Motion Generation Engine은,사람의 모션을 3D Clip으로 변환하는 3D Motion Clip Conversion Module;상기 3D Clip을 저장하는 3D Motion Clip DB;상기 3D Motion Clip DB로부터, 씬에서 아바타가 행하여야 하는 모션에 대한 정보에 근거하여 특정의 3D Clip을탐색하는 Clip Search Module;상기 탐색된 3D Clip의 모션을 아바타에게 입히는 Motion Dressing Module; 및상기 아바타에게 입혀진 상기 3D Clip의 모션을 편집하는 Motion Editor를 포함하여 구성하는,마이 무비 서비스를 지원하는 마이 무비 방법."}
{"patent_id": "10-2023-0028493", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제6항에 있어서,상기 씬(scene)에 대한 언어적 정보를 식별(Preparing linguistic data)하는 것은,Linguistic Info. Processing Engine을 이용하여, 상기 씬에서 나타나는 대사, 음성, 문자 중 적어도 하나를포함하는 상기 언어적 정보를 식별하는 것을 포함하고,상기 Linguistic Info. Processing Engine은,음성 형태의 입력 데이터에 대해 음성 인식 기술을 적용하여 문자 형식의 데이터로 변환하는 Speech-TO-TextModule;문자 형태의 입력 데이터에 대해 음성 합성 기술을 적용하여 음성 형식의 데이터로 변환하는 Text-To-SpeechModule;상기 음성 형태의 입력 데이터 또는 상기 문자 형태의 입력 데이터를, 씬 태그, 아바타 태그, 및 일련번호를 연관시켜 저장하는 Dialog DB; 및상기 음성 형태의 입력 데이터 및 상기 문자 형태의 입력 데이터를, 상호 분할 및 병합하여 동기화 처리하는Dialog Editor를 포함하여 구성하는,공개특허 10-2024-0135519-5-마이 무비 서비스를 지원하는 마이 무비 방법."}
{"patent_id": "10-2023-0028493", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제6항에 있어서,상기 씬에 대응하는 3차원 공간을 생성(Building VR/AR space)하는 것은,VR/AR Space Building Engine을 통해, 현재 작업 중인 씬에 해당하는 3차원 공간을 생성하는 것을 포함하고,상기 VR/AR Space Building Engine은,상기 가상 공간을 구성하는데 사용되는 객체들의 3D 모델을 저장하는 VR Space Elementary Repository(VR-SER);상기 객체들의 3D 모델을 조합하여 가상 공간을 구성하고, 상기 가상 공간을 저장하는 VR Space Repository(VR-SR);외부 개방형 플랫폼으로부터 입수된 특정 위치의 실제 3D 컨텐츠 정보를 상기 가상 공간에 디스플레이하는 RawData Processing Module;사용자로부터의 요청에 따라 신규 3D 객체를 생성하는 External 3D Modeling System과의 연계를 지원하는Interface Module; 및상기 신규 3D 객체의 생성과 연동하여 상기 가상 공간을 수정 함으로써, 상기 신규 3D 객체에 관한 3D 컨텐츠정보가 상기 가상 공간에서 디스플레이 되도록 하는 Space Editor를 포함하여 구성하는,마이 무비 서비스를 지원하는 마이 무비 방법."}
{"patent_id": "10-2023-0028493", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제6항에 있어서,상기 씬에 상응하여 디자인된 아바타를 등장(Summoning avatars)하는 것은,Avatar Creation Engine을 통해 디자인된 아바타를, 상기 씬에서의 모션을 입히기 위하여 등장시키는 것을 포함하고,상기 Avatar Creation Engine은,얼굴을 포함한, 상기 아바타의 바디를 제작하는 Body Modeling;상기 아바타가 입고 있는 의상을 제작하는 Clothes Modeling;상기 아바타에게 뼈대와 관절에 관한 인체공학적 특징을 부여하는 Character Rigging;상기 바디의 제작, 상기 의상의 제작, 및 상기 인공공학적 특징의 부여에 따라, 상기 아바타를 디자인하고, 상기 씬에 대응하여 저장하는 Avatar DB; 및External Avatar Modeling System과 연결되어, 상기 디자인된 아바타를 교환하는 Interface Module를 포함하여 구성하는,마이 무비 서비스를 지원하는 마이 무비 방법."}
{"patent_id": "10-2023-0028493", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제6항 내지 제10항 중 어느 한 항의 방법을 실행시키기 위한 프로그램을 기록한 컴퓨터 판독 가능한 기록매체."}
{"patent_id": "10-2023-0028493", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "마이 무비 서비스를 지원하는 마이 무비 시스템 및 방법이 개시된다. 본 발명에 따른 마이 무비 서비스를 지원 하는 마이 무비 시스템은, 사용자로부터 수집되는 시나리오에 근거하여, 메타버스(metaverse) 상의 아바타에 모 션을 부여하여, 3D 영상 컨텐츠를 제작하는 마이 무비 서비스 지원부를 포함하고, 상기 마이 무비 서비스 지원부 는, 씬(scene)에 대한 언어적 정보를 식별(Preparing linguistic data)하고, 상기 씬에 대응하는 3차원 공간을 생성(Building VR/AR space)하며, 상기 씬에 상응하여 디자인된 아바타를 등장(Summoning avatars)시키고, 상기 씬의 서브 씬(sub-scene)에 대한 하위 세부 과정(For each sub-scene)을 수행 함으로써, 상기 시나리오를 구성 하는 복수의 씬 각각에 대해 상기 아바타에게 부여할 모션을 정의 할 수 있다."}
{"patent_id": "10-2023-0028493", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은, 메타버스(metaverse) 내에서, 사용자의 아바타(avatar)를 활용한 시나리오의 구현을 지원하여, 3D 영상 컨텐츠를 제작하는, 마이 무비 서비스를 지원하는 마이 무비 시스템 및 방법을 제공한다."}
{"patent_id": "10-2023-0028493", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "한국 등록번호 10-1845535 (2018.03.29) : 3ｄ 아바타 기반 화자 변경형 스토리텔링 시스템 메타버스로 정의되는 시스템은, 수행되는 세부 기능의 흐름과 이들의 실행을 위한 시스템 구성 요소를 기준으로 설명될 수 있다. 한편, 메타버스의 세부 기능 구현을 위한 기술로는, ‘증강현실(AR/VR) 구현 기술’, ‘아바타(avatar) 생성을 위한 디자인 기술’, 그리고 ‘아바타 모션 제어를 위한 인공지능 기술’ 등을 예시할 수 있다. ‘증강현실(AR/VR) 구현 기술’ 및 ‘아바타(avatar) 생성을 위한 디자인 기술’은, 현재 실현 가능하게 구현되 고 있는 기술로서, 일반적으로 사용되는 기술을 접목하여도 문제의 발생이 적은 편에 속한다. 다만, ‘아바타 모션 제어를 위한 인공지능 기술’의 경우에는, 현재 학술적으로 일부 분야에 대한 연구가 다수 진행되고 있으나, 일반적으로 사용되는 기술에 직접적으로 적용될 수 있는 수준으로 구현되고 있지는 않고 있다. ‘아바타 모션 제어를 위한 인공지능 기술’은, ANN(Artificial Neural Network: 인공 지능 신경망)을 적용한 기술을 전제로 기술 구현을 시도하고 있는 상태이다. 따라서, 메타버스 내에서, 아바타의 모션을 제어하는 AI의 개선된 기술의 등장이 요구되고 있다."}
{"patent_id": "10-2023-0028493", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명의 실시예는, 일반 사용자가 메타버스에서 아바타를 활용하여 자신의 시나리오를 구현 함으로써 3D 영상 컨텐츠를 제작하는 서비스를 제공하는, 마이 무비 서비스를 지원하는 마이 무비 시스템 및 방법을 제공하는 것 을 목적으로 한다. 또한, 본 발명의 실시예는, 메타버스에서 증강현실 및 아바타 모션 생성(Motion Generation) 기술을 바탕으로 사용자 정의 시나리오에 대한 “나만의 영화 제작” 서비스를 제공하는 것을 목적으로 한다. 또한, 본 발명의 실시예는, 사용자가 자신의 시나리오를 바탕으로 아바타에 모션을 부여하여, 3D 영화와 같은 영상 제작 서비스를 제공하는 시스템을 지원하는 것을 목적으로 한다."}
{"patent_id": "10-2023-0028493", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명에 따른 마이 무비 서비스를 지원하는 마이 무비 시스템은, 사용자로부터 수집되는 시나리오에 근거하여, 메타버스(metaverse) 상의 아바타에 모션을 부여하여, 3D 영상 컨텐츠를 제작하는 마이 무비 서비스 지원부를 포함하고, 상기 마이 무비 서비스 지원부는, 씬(scene)에 대한 언어적 정보를 식별(Preparing linguistic data)하고, 상기 씬에 대응하는 3차원 공간을 생성(Building VR/AR space)하며, 상기 씬에 상응하 여 디자인된 아바타를 등장(Summoning avatars)시키고, 상기 씬의 서브 씬(sub-scene)에 대한 하위 세부 과정 (For each sub-scene)을 수행 함으로써, 상기 시나리오를 구성하는 복수의 씬 각각에 대해 상기 아바타에게 부 여할 모션을 정의 할 수 있다. 또한, 본 발명에 따른 마이 무비 서비스를 지원하는 마이 무비 방법은, 사용자로부터 수집되는 시나리오에 근거 하여, 메타버스(metaverse) 상의 아바타에 모션을 부여하여, 3D 영상 컨텐츠를 제작하는 단계(Based on my scenario)로서, 씬(scene)에 대한 언어적 정보를 식별(Preparing linguistic data)하고, 상기 씬에 대응하는 3 차원 공간을 생성(Building VR/AR space)하며, 상기 씬에 상응하여 디자인된 아바타를 등장(Summoning avatars)시키고, 상기 씬의 서브 씬(sub-scene)에 대한 하위 세부 과정(For each sub-scene)을 수행 함으로써, 상기 시나리오를 구성하는 복수의 씬 각각에 대해 상기 아바타에게 부여할 모션을 정의하는 단계(For each scene)를 포함하여 구성 할 수 있다."}
{"patent_id": "10-2023-0028493", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명에 따르면, 일반 사용자가 메타버스에서 아바타를 활용하여 자신의 시나리오를 구현 함으로써 3D 영상 컨텐츠를 제작하는 서비스를 제공하는, 마이 무비 서비스를 지원하는 마이 무비 시스템 및 방법을 제공할 수 있 다. 또한, 본 발명에 의해서는, 메타버스에서 증강현실 및 아바타 모션 생성 기술을 바탕으로 사용자 정의 시나리오 에 대한 “나만의 영화 제작” 서비스를 제공할 수 있다. 또한, 본 발명에 의해서는, 사용자가 자신의 시나리오를 바탕으로 아바타에 모션을 부여하여, 3D 영화와 같은 영상 제작 서비스를 제공하는 시스템을 지원할 수 있다."}
{"patent_id": "10-2023-0028493", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하에서, 첨부된 도면을 참조하여 실시예들을 상세하게 설명한다. 그러나, 실시예들에는 다양한 변경이 가해 질 수 있어서 특허출원의 권리 범위가 이러한 실시예들에 의해 제한되거나 한정되는 것은 아니다. 실시예들에 대한 모든 변경, 균등물 내지 대체물이 권리 범위에 포함되는 것으로 이해되어야 한다. 실시예에서 사용한 용어는 단지 설명을 목적으로 사용된 것으로, 한정하려는 의도로 해석되어서는 안된다. 단 수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 명세서에서, \"포함하다\" 또 는 \"가지다\" 등의 용어는 명세서 상에 기재된 특징, 숫자, 단계, 동작, 구성요소, 부품 또는 이들을 조합한 것 이 존재함을 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성요소, 부품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되어야 한다. 다르게 정의되지 않는 한, 기술적이거나 과학적인 용어를 포함해서 여기서 사용되는 모든 용어들은 실시예가 속 하는 기술 분야에서 통상의 지식을 가진 자에 의해 일반적으로 이해되는 것과 동일한 의미를 가지고 있다. 일 반적으로 사용되는 사전에 정의되어 있는 것과 같은 용어들은 관련 기술의 문맥 상 가지는 의미와 일치하는 의 미를 가지는 것으로 해석되어야 하며, 본 출원에서 명백하게 정의하지 않는 한, 이상적이거나 과도하게 형식적 인 의미로 해석되지 않는다. 또한, 첨부 도면을 참조하여 설명함에 있어, 도면 부호에 관계없이 동일한 구성 요소는 동일한 참조부호를 부여 하고 이에 대한 중복되는 설명은 생략하기로 한다. 실시예를 설명함에 있어서 관련된 공지 기술에 대한 구체적 인 설명이 실시예의 요지를 불필요하게 흐릴 수 있다고 판단되는 경우 그 상세한 설명을 생략한다. 도 1은 본 발명에 따른 마이 무비 서비스를 지원하는 마이 무비 시스템의 내부 구성을 도시한 블록도이다. 도 1을 참조하면, 본 발명에 따른 마이 무비 서비스를 지원하는 마이 무비 시스템(이하, '마이 무비 시스템'이 라 약칭함, 100)은, 마이 무비 서비스 지원부를 포함할 수 있다. 또한, 마이 무비 서비스 지원부는, Linguistic Info. Processing Engine, VR/AR Space Building Engine, Avatar Creation Engine, 및 Motion Generation Engine을 포함하여 구성할 수 있다. 우선, 마이 무비 서비스 지원부는 사용자로부터 수집되는 시나리오에 근거하여, 메타버스 상의 아바타에 모션을 부여하여, 3D 영상 컨텐츠를 제작한다. 즉, 마이 무비 서비스 지원부는, 사용자의 의사를 메타버 스 상에 구현하는 아바타를 이용하여, 사용자가 작성한 시나리오에 맞춰, 3D 영상 컨텐츠를 생성 함으로써, 마 이 무비 서비스를 지원하는 역할을 할 수 있다. 구체적으로, 마이 무비 서비스 지원부는, 씬(scene)에 대한 언어적 정보를 식별(Preparing linguistic data)할 수 있다. 즉, 마이 무비 서비스 지원부는, 시나리오 내 해당 씬에서의, 등장인물이 구사하는 대사, 음성, 문자 등의 언어적 정보를 데이터로 추출해 낼 수 있다. 또한, 마이 무비 서비스 지원부는, 상기 씬에 대응하는 3차원 공간을 생성(Building VR/AR space)할 수 있 다. 즉, 마이 무비 서비스 지원부는, 해당 씬에서의, 등장인물이 위치하고 움직이는 가상공간으로서의 3 차원 공간을 만들어 낼 수 있다. 또한, 마이 무비 서비스 지원부는, 상기 씬에 상응하여 디자인된 아바타를 등장(Summoning avatars)시킬 수 있다. 즉, 마이 무비 서비스 지원부는, 만들어진 가상공간으로, 해당 씬에서의 등장인물로서 아바타를 표현할 수 있다. 이때, 마이 무비 서비스 지원부는, 해당 씬의 스토리에 맞춰 등장하는 인물 수에 맞춰 등장시키는 아바타의 수를 결정할 수 있다. 또한, 마이 무비 서비스 지원부는, 상기 씬의 서브 씬(sub-scene)에 대한 하위 세부 과정(For each sub- scene)을 수행 함으로써, 상기 시나리오를 구성하는 복수의 씬 각각에 대해 상기 아바타에게 부여할 모션을 정 의할 수 있다. 즉, 마이 무비 서비스 지원부는, 가상공간에 등장한 아바타 각각에 대해 해당 씬에서 규정 한 각본에 따른 움직임을 제어하여, 해당 씬을 구성하는 복수의 세부적인 서브 씬을 구현할 수 있다. 상기 씬의 서브 씬에 대한 하위 세부 과정(For each sub-scene)의 수행은, Motion Generation Engine에 의해 구현될 수 있다. 마이 무비 서비스 지원부는, Motion Generation Engine을 포함하고, 상기 Motion Generation Engine을 이용하여, 상기 아바타의 모션을 생성(Generating avatar motion)하고, 상기 언어적 정보를 상 기 아바타의 모션과 연계(Mapping motion with linguistic info.) 시킴으로써, 상기 서브 씬에서 등장하는 상 기 아바타에 대해 하위 세부 과정을 수행(For each avatar)할 수 있다. Motion Generation Engine은, 아바타에 대해, 식별된 언어적 정보와 부여된 모션을 매칭하여, 하위 세부 과정을 수행할 수 있다. 식별된 언어적 정보와 부여된 모션과의 매칭을 위해, Motion Generation Engine은, 사람의 모션을 3D Clip으로 변환하는 3D Motion Clip Conversion Module, 상기 3D Clip을 저장하는 3D Motion Clip DB, 상기 3D Motion Clip DB로부터, 씬에서 아바타가 행하여야 하는 모션에 대한 정보에 근거하여 특정의 3D Clip을 탐색하 는 Clip Search Module, 상기 탐색된 3D Clip의 모션을 아바타에게 입히는 Motion Dressing Module, 및 상기 아바타에게 입혀진 상기 3D Clip의 모션을 편집하는 Motion Editor를 포함하여 구성할 수 있다. 상기 씬에 대한 언어적 정보를 식별(Preparing linguistic data)하는 것은, Linguistic Info. Processing Engine에 의해 구현될 수 있다. 마이 무비 서비스 지원부는, Linguistic Info. Processing Engine을 포함하고, 상기 Linguistic Info. Processing Engine을 이용하여, 상기 씬에서 나타나는 대사, 음성, 문자 중 적어도 하나를 포함하는 상기 언어적 정보를 식별할 수 있다. Linguistic Info. Processing Engine은, 음성 형태의 입력 데이터에 대해 음성 인식 기술을 적용하여 문 자 형식의 데이터로 변환하는 Speech-TO-Text Module, 문자 형태의 입력 데이터에 대해 음성 합성 기술을 적용 하여 음성 형식의 데이터로 변환하는 Text-To-Speech Module, 상기 음성 형태의 입력 데이터 또는 상기 문자 형 태의 입력 데이터를, 씬 태그, 아바타 태그, 및 일련번호를 연관시켜 저장하는 Dialog DB, 및 상기 음성 형태의 입력 데이터 및 상기 문자 형태의 입력 데이터를, 상호 분할 및 병합하여 동기화 처리하는 Dialog Editor를 포 함하여 구성할 수 있다. 상기 씬에 대응하는 3차원 공간을 생성(Building VR/AR space)하는 것은, VR/AR Space Building Engine에 의해 구현될 수 있다. 마이 무비 서비스 지원부는, VR/AR Space Building Engine을 포함하고, 상기 VR/AR Space Building Engine을 통해, 현재 작업 중인 씬에 해당하는 3차원 공간을 생성할 수 있다. VR/AR Space Building Engine은, 상기 가상 공간을 구성하는데 사용되는 객체들의 3D 모델을 저장하는 VR Space Elementary Repository(VR-SER), 상기 객체들의 3D 모델을 조합하여 가상 공간을 구성하고, 상기 가상 공간을 저장하는 VR Space Repository(VR-SR), 외부 개방형 플랫폼으로부터 입수된 특정 위치의 실제 3D 컨텐츠 정보를 상기 가상 공간에 디스플레이하는 Raw Data Processing Module, 사용자로부터의 요청에 따라 신규 3D 객 체를 생성하는 External 3D Modeling System과의 연계를 지원하는 Interface Module, 및 상기 신규 3D 객체의생성과 연동하여 상기 가상 공간을 수정 함으로써, 상기 신규 3D 객체에 관한 3D 컨텐츠 정보가 상기 가상 공간 에서 디스플레이 되도록 하는 Space Editor를 포함하여 구성할 수 있다. 상기 씬에 상응하여 디자인된 아바타를 등장(Summoning avatars)시키는 것은, Avatar Creation Engine에 의해 구현될 수 있다. 마이 무비 서비스 지원부는, Avatar Creation Engine을 포함하고, 상기 Avatar Creation Engine을 통해 디자인된 아바타를, 상기 씬에서의 모션을 입히기 위하여 등장시키는 것을 포함할 수 있다. Avatar Creation Engine은, 얼굴을 포함한, 상기 아바타의 바디를 제작하는 Body Modeling, 상기 아바타 가 입고 있는 의상을 제작하는 Clothes Modeling, 상기 아바타에게 뼈대와 관절에 관한 인체공학적 특징을 부여 하는 Character Rigging, 상기 바디의 제작, 상기 의상의 제작, 및 상기 인공공학적 특징의 부여에 따라, 상기 아바타를 디자인하고, 상기 씬에 대응하여 저장하는 Avatar DB, 및 External Avatar Modeling System과 연결되 어, 상기 디자인된 아바타를 교환하는 Interface Module를 포함하여 구성할 수 있다. 본 발명에 따르면, 일반 사용자가 메타버스에서 아바타를 활용하여 자신의 시나리오를 구현 함으로써 3D 영상 컨텐츠를 제작하는 서비스를 제공하는, 마이 무비 서비스를 지원하는 마이 무비 시스템 및 방법을 제공할 수 있 다. 또한, 본 발명에 의해서는, 메타버스에서 증강현실 및 아바타 모션 생성 기술을 바탕으로 사용자 정의 시나리오 에 대한 “나만의 영화 제작” 서비스를 제공할 수 있다. 또한, 본 발명에 의해서는, 사용자가 자신의 시나리오를 바탕으로 아바타에 모션을 부여하여, 3D 영화와 같은 영상 제작 서비스를 제공하는 시스템을 지원할 수 있다. 본 발명의 마이 무비 시스템은, 사용자가 자신의 ‘마이 무비’를 작성하기 위한 프로세스를 제공할 수 있 다. 마이 무비 시스템은, 사용자 프로세스에 맞춰 서비스를 지원할 시스템(MMS: My Movie System)의 엔진을 제 공할 수 있다. 마이 무비 시스템은, MMS의 구성 엔진의 작동 방식을 정의하여 제공할 수 있다. 도 2는 마이 무비 시스템의 구조, 기능 및 작동 방식을 설명하기 위한 도이다. 도 2에서는, ‘My Movie Service’를 제공하는 MMS을 통해 사용자가 3D 영상을 만드는 과정과, 각 세부 과정에 관계되는 MMS를 구성하는 engine을 나타낸다. 영상을 만드는 과정은 아래의 세부 과정으로 구성될 수 있다. Based on my scenario는, 사용자가 자신의 시나리오를 바탕으로 아래의 과정을 통해 3D 영상을 제작할 수 있음을 나타내며, 또한 시나리오 단위로 과정을 수행함을 나타낼 수 있다. For each scene은, 시나리오를 구성하는 각 씬(scene) 단위로 세부 과정을 수행함을 나타낼 수 있다. Preparing linguistic data는, MMS의 Engine 중 Linguistic Info. Processing Engine을 이용하 여, 해당 씬에서 나타나는 대사, 음성, 문자 등의 언어적 정보를 MMS에 탑재하는 것을 나타낼 수 있다. Building VR/AR space는, MMS의 Engine 중 VR/AR Space Building Engine을 통해, 지금 작업 중 인 씬에 해당하는 3차원 공간 모습을 생성하는 것을 나타낼 수 있다. Summoning avatars는, MMS의 Engine 중 Avatar Creation Engine을 통해, 디자인된 아바타에 대 해 해당 씬에서의 모션을 입히기 위하여 등장시키는 것을 나타낼 수 있다. For each sub-scene은, 각 씬에 대하여 상황의 연속성, 아바타 모션의 연속성 등에 의해 세분화된 sub- scene에 대해 하위 세부 과정을 수행함을 나타낼 수 있다. For each sub-scene은, Generating avatar motion와 Mapping motion with linguistic info.로 구성되는 For each avatar을 포함할 수 있다. For each avatar는, 해당 sub-scene에서 등장하는 각 아바타에 대해 하위 세부 과정을 수행함을 나타낼 수 있다.Generating avatar motion은, MMS의 Engine 중 Motion Generation Engine을 이용하여, 각 아바 타의 모션을 생성하는 것을 나타낼 수 있다. Mapping motion with linguistic info.는, Linguistic Info. Processing Engine와 연결되어, 'Loading linguistic information’을 통해 탑재된 언어적 정보를 아바타의 모션과 연계시키는 것을 나타낼 수 있다. MMS의 Engines은 핵심 엔진 4개를 포함하는 MMS를 나타낼 수 있다. Linguistic Info. Processing Engine은, 시나리오를 통해 제시되는 대사, 혼잣말, 생각 내용 등의 언어 적 정보를 사용자로부터 직접 또는 파일 형태의 입력을 받아, 각각이 지정된 씬의 아바타에 의해 지정된 형태로 출력될 수 있도록 사전 처리 기능을 수행할 수 있다. VR/AR Space Building Engine은, 사용자로부터 입력을 받아 시나리오에 제시된(또는 사용자가 구상하는) 3차원 무대 공간을 생성하는 기능을 수행할 수 있다. 세부적으로, VR/AR Space Building Engine은, VR Space Element Repository의 space element 활용, VR Space Repository의 기 정의된 space 활용, 그리고 digital twin 기술 등을 활용하여 실제 환경을 구현 등을 통해 3차원 무대 공간을 생성/수정/저장 등의 기능을 수행할 수 있다. Avatar Creation Engine은, 시나리오에 등장하는 인물(아바타)을 사용자가 정의하도록 지원하는 기능을 수행할 수 있다. 이러한 기능은, 현재 다양한 소프트웨어에 의해 지원되고 있는 기능으로, MMS를 위하여 별도 의 엔진을 정의하지 않고 대신 기존 소프트웨어를 접목하여 엔진 기능으로 대체할 수 있다. Motion Generation Engine은, 시나리오에 의해 아바타가 행하여야 하는 모션에 대한 특성 정보를 사용자 로부터 입력받아 인공신경망 기술을 적용하여 아바타의 모션을 생성하는 기능을 수행할 수 있다. 도 3은 Linguistic Info. Processing Engine을 상세히 설명하기 위한 도이다. 도 3에서는, 도 2에 제시된 MMS의 구성 엔진 중 Linguistic Info. Processing Engine의 작동 방식을 설 명한다. Linguistic Info. Processing Engine의 핵심 기능은 아래와 같다. Dialog DB는, 음성 또는 문자 형식의 입력을 상호 변환하여 연관된 씬과 아바타 및 일련번호를 저장한 데이터베이스를 나타낼 수 있다. Dialog DB는, 관계형 데이터베이스를 적용하며, Scene tag, Avatar tag, Serial Number, Voice content, Text content 등의 필드(데이터 항목)를 정의하여 관련 데이터를 저장할 수 있다. primary key(주키)는, Scene tag, Avatar tag, Serial Number 등의 복합키로 정의할 수 있다. Speech-TO-Text Module은, 음성 형태의 입력 데이터에 대해 음성 인식 기술을 적용하여, 문자 형식의 데 이터로 변환한 후, 씬 태그, 아바타 태그, 일련번호를 연관시켜 데이터베이스에 저장하는 기능을 수행할 수 있 다. Text-To-Speech Module은, 문자 형태의 입력 데이터에 대해 음성 합성 기술을 적용하여, 음성 형식의 데 이터로 변환한 후, 씬 태그, 아바타 태그, 일련번호를 연관시켜 데이터베이스에 저장하는 기능을 수행할 수 있 다. Dialog Editor는, voice data와 text data의 분할/병합 및 이에 따른 voice, text간 동기화 처리 등의 기능을 수행할 수 있다. 도 4은 VR/AR Space Building Engine을 상세히 설명하기 위한 도이다. 도 4에서는, 도 2에 제시된 MMS의 구성 엔진 중 VR/AR Space Building Engine의 작동 방식을 설명한다. VR/AR Space Building Engine의 핵심 기능은, 아래와 같다. VR Space Elementary Repository(VR-SER)는, 씬이 전개되는 가상 공간을 구성하는데 사용될 수 있는 다 양한 객체들의 3D 모델을 저장하는 공간을 나타낼 수 있다. 이들 객체에는, 거리에서 볼 수 있는 건물, 나무, 표지판 등이 포함될 수 있고, 아파트 거실, 주방 등의 특정 형태의 공간도 포함될 수 있으며, 건물 안에서 볼 수 있는 책상, 의자, 장식장, 소파 등이 포함될 수 있다. VR Space Repository(VR-SR)는, VR-SER의 element들을 조합한 결과로 일정 수준의 구성을 갖춘 가상 공 간을 저장하는 공간을 나타낼 수 있다. VR Space Repository(VR-SR)에서는, 예로서, ‘통창이 있고, TV, 소파, 테이블, 액자, 등의 갖춰진 가정집 거실’ 등이 VR-SR의 저장 단위가 될 수 있다. Raw Data Processing Module은, 3D 공간/지리 정보를 제공하는 외부 개방형 플랫폼에 요청하여 전송받 은 특정 위치(GPS 좌표)의 실제 3D 컨텐츠 정보(바닥, 건물, 기타 구조물 등의 정보)를 사용자가 정의하는 가상 공간에 display 하기 위하여 필요한 처리 과정을 수행하는 기능을 나타낼 수 있다. 여기에서는, meta file parsing, data file parsing, mesh generation, texture mapping, rendering 등이 포함될 수 있다. Interface Module은, 사용자가 새롭게 만들어야 하는 3D object가 필요할 경우, 이의 생성을 지원하는 외부 3D Modeling System과의 연계를 지원하는 기능을 나타낼 수 있다. Space Editor는, 입력으로 제공되는 씬의 배경이 되는 공간 정보를 바탕으로, VR-SER 및 VR-SR 데이터베 이스를 활용하고, 필요한 경우 Raw Data Processor 또는 Interface 기능을 통해 얻어진 3D 객체를 이용하여, 새 로운 가상 공간을 생성, 수정 및 저장하는 기능을 수행할 수 있다. 도 5은 Avatar Creation Engine을 상세히 설명하기 위한 도이다. 도 5에서는, 도 2에 제시된 MMS의 구성 엔진 중 Avatar Creation Engine의 작동 방식을 설명한다. Avatar Creation Engine에서 제공되는 기능은, 보편적으로 애니메이션을 목적으로 한 3D 모델 생성을 지 원하는 소프트웨어에서 제공되는 기능과 같을 수 있다. Body Modeling은, 아바타 바디(얼굴 포함) 제작, 바디에 대한 폴리곤 제작 및 LOD 최적화, 3D 표면의 2D 텍스처 이미지로의 변환을 나타내는 UV 작업 등의 기능을 수행할 수 있다. Clothes Modeling은, body modeling과 유사하게 의상 형태 제작, 관절 부분 등에 대한 엣지 흐름 정리, 세부 디테일 처리, 의상 UV 작업 등의 기능을 수행할 수 있다. Character Rigging은, Avatar에게 인체공학적 특징을 부여하는 과정으로의 뼈대와 관절 등에 대한 기본 적인 설정을 제공하는 기능을 수행할 수 있다. Interface Module은, External Avatar Modeling System과의 contents(avatar) 교환(import/export) 기 능을 수행할 수 있다. 도 6은 Motion Generation Engine을 상세히 설명하기 위한 도이다. 도 6에서는, 도 2에 제시된 MMS의 구성 엔진 중 Motion Generation Engine의 작동 방식을 설명한다. Motion Generation Engine의 핵심 기능은, 아래와 같다. 3D Motion Clip DB는, 일반적으로 참조될 수 있는 모션의 한 단위(예: 악수하기, 엎드리기 등)를 3D 객 체의 움직임으로 나타낸 것을 일컫는 3D Clip의 저장소를 나타낼 수 있다. Clip은, 3D 객체의 각 관절 기준점 에 대한 trajectory(이동 경로)를 포함하고 있으며, 이들 Clip은, avatar의 모션을 정의하기 위하여 참조되거나 새롭게 생성된 모션이 저장될 수 있다. 3D Motion Clip Conversion Module은, 모션 캡쳐 시스템에서 실제 사람의 움직임을 센서로 인식한 데이 터를 수신하여, 3D Motion Clip으로 변환하는 기능을 수행할 수 있다. Clip Search Module은, 씬에서 아바타가 행하여야 하는 모션에 대한 정보를 바탕으로, 3D Motion Clip DB로부터 가장 적절한 Clip을 탐색하는 기능을 수행할 수 있다. 기본적으로, Clip Search Module은, avatar ID(예: 주인공 A 등). motion name(예: 빨 때리기 등), purpose(예: 상대방 가격 등), feeling(예: 분노), speed(예: 엄청 빠른 속도 등), intensity(예: 최대 파워 등) 등의 모션 생성 파라미터를 입력받아, 가장 적절한 Clip을 탐색하여 제시할 수 있다. Clip Search Module은, 모션의 적합성 판별을 위하여 ANN(Artificial Neural Network: 인공지능신경망)을 적용할 수 있다. Motion Dressing Module은, 선택된 Clip의 모션을 아바타에게 입혀, 아바타로 하여금 클립에 나타난 모 션을 행하도록 만드는 기능을 수행할 수 있다. Motion Editor는, 아바타에 의한 Clip의 모션을 편집/저장 등의 기능을 수행할 수 있다. 3D 영상 컨텐츠 제작을 위해서는, 장비 뿐만 아니라 전문적인 기술이 함께 필요한데, 본 발명의 마이 무비 시스 템은, 일반 사용자가 엄두를 내기 어려운, 3D 영상 컨텐츠 제작을 지원할 수 있다. 마이 무비 시스템은, 영화산업과 연관성이 없는 일반 사용자도 자신의 시나리오를 3D 영상 컨텐츠 제작을 통해 검증받을 수 있어, 영화 산업 발전에 밑거름이 될 수 있다. 마이 무비 시스템은, 메타버스 플랫폼 사업과 접목함으로써 사용자 확충을 통한 경제적 성과 창출에 기여 할 수 있다. 도 7은 본 발명에 따른 마이 무비 서비스를 지원하는 마이 무비 방법의 순서를 도시한 흐름도이다. 본 실시예에 따른 마이 무비 서비스를 지원하는 마이 무비 방법은, 상술한 마이 무비 시스템에 의해 수행 될 수 있다. 마이 무비 시스템의 마이 무비 서비스 지원부에서, 사용자로부터 수집되는 시나리오에 근거하여, 메타버스 상의 아바타에 모션을 부여하여, 3D 영상 컨텐츠를 제작한다. 단계는 마이 무비 서비스 지원부에 의 해, 사용자의 의사를 메타버스 상에 구현하는 아바타를 이용하여, 사용자가 작성한 시나리오에 맞춰, 3D 영상 컨텐츠를 생성 함으로써, 마이 무비 서비스를 지원하는 과정일 수 있다. 구체적으로, 마이 무비 서비스 지원부는, 씬(scene)에 대한 언어적 정보를 식별(Preparing linguistic data)할 수 있다. 단계는, 마이 무비 서비스 지원부에 의해, 시나리오 내 해당 씬에서의, 등장인물이 구사하 는 대사, 음성, 문자 등의 언어적 정보를 데이터로 추출해 내는 과정일 수 있다. 또한, 마이 무비 서비스 지원부는, 상기 씬에 대응하는 3차원 공간을 생성(Building VR/AR space)할 수 있다 . 단계는 마이 무비 서비스 지원부에 의해, 해당 씬에서의, 등장인물이 위치하고 움직이는 가상공간 으로서의 3차원 공간을 만들어내는 과정일 수 있다. 또한, 마이 무비 서비스 지원부는, 상기 씬에 상응하여 디자인된 아바타를 등장(Summoning avatars)시킬 수 있 다. 단계는 마이 무비 서비스 지원부에서, 만들어진 가상공간으로, 해당 씬에서의 등장인물로서 아 바타를 표현하는 과정일 수 있다. 이때, 마이 무비 서비스 지원부는, 해당 씬의 스토리에 맞춰 등장하는 인물 수에 맞춰 등장시키는 아바타의 수를 결정할 수 있다. 또한, 마이 무비 서비스 지원부는, 상기 씬의 서브 씬(sub-scene)에 대한 하위 세부 과정(For each sub- scene)을 수행 함으로써, 상기 시나리오를 구성하는 복수의 씬 각각에 대해 상기 아바타에게 부여할 모션을 정 의할 수 있다. 단계는, 마이 무비 서비스 지원부에 의해, 가상공간에 등장한 아바타 각각에 대해 해 당 씬에서 규정한 각본에 따른 움직임을 제어하여, 해당 씬을 구성하는 복수의 세부적인 서브 씬을 구현하는 과 정일 수 있다. 상기 씬의 서브 씬에 대한 하위 세부 과정(For each sub-scene)의 수행은, Motion Generation Engine에 의해 구현될 수 있다. 마이 무비 서비스 지원부는, Motion Generation Engine을 포함하고, 상기 Motion Generation Engine을 이용하 여, 상기 아바타의 모션을 생성(Generating avatar motion)하고, 상기 언어적 정보를 상기 아바타의 모션과 연 계(Mapping motion with linguistic info.) 시킴으로써, 상기 서브 씬에서 등장하는 상기 아바타에 대해 하위 세부 과정을 수행(For each avatar)할 수 있다. Motion Generation Engine은, 아바타에 대해, 식별된 언어적 정보와 부여된 모션을 매칭하여, 하위 세부 과정을 수행할 수 있다. 식별된 언어적 정보와 부여된 모션과의 매칭을 위해, Motion Generation Engine은, 사람의 모션을 3D Clip으로 변환하는 3D Motion Clip Conversion Module, 상기 3D Clip을 저장하는 3D Motion Clip DB, 상기 3D Motion Clip DB로부터, 씬에서 아바타가 행하여야 하는 모션에 대한 정보에 근거하여 특정의 3D Clip을 탐색하는 Clip Search Module, 상기 탐색된 3D Clip의 모션을 아바타에게 입히는 Motion Dressing Module, 및 상기 아바타에 게 입혀진 상기 3D Clip의 모션을 편집하는 Motion Editor를 포함하여 구성할 수 있다. 상기 씬에 대한 언어적 정보를 식별(Preparing linguistic data)하는 것은, Linguistic Info. Processing Engine에 의해 구현될 수 있다. 마이 무비 서비스 지원부는, Linguistic Info. Processing Engine을 포함하고, 상기 Linguistic Info. Processing Engine을 이용하여, 상기 씬에서 나타나는 대사, 음성, 문자 중 적어도 하나를 포함하는 상기 언어 적 정보를 식별할 수 있다. Linguistic Info. Processing Engine은, 음성 형태의 입력 데이터에 대해 음성 인식 기술을 적용하여 문자 형 식의 데이터로 변환하는 Speech-TO-Text Module, 문자 형태의 입력 데이터에 대해 음성 합성 기술을 적용하여 음성 형식의 데이터로 변환하는 Text-To-Speech Module, 상기 음성 형태의 입력 데이터 또는 상기 문자 형태의 입력 데이터를, 씬 태그, 아바타 태그, 및 일련번호를 연관시켜 저장하는 Dialog DB, 및 상기 음성 형태의 입력 데이터 및 상기 문자 형태의 입력 데이터를, 상호 분할 및 병합하여 동기화 처리하는 Dialog Editor를 포함하여 구성할 수 있다. 상기 씬에 대응하는 3차원 공간을 생성(Building VR/AR space)하는 것은, VR/AR Space Building Engine에 의해 구현될 수 있다. 마이 무비 서비스 지원부는, VR/AR Space Building Engine을 포함하고, 상기 VR/AR Space Building Engine을 통해, 현재 작업 중인 씬에 해당하는 3차원 공간을 생성할 수 있다. VR/AR Space Building Engine은, 상기 가상 공간을 구성하는데 사용되는 객체들의 3D 모델을 저장하는 VR Space Elementary Repository(VR-SER), 상기 객체들의 3D 모델을 조합하여 가상 공간을 구성하고, 상기 가상 공간을 저장하는 VR Space Repository(VR-SR), 외부 개방형 플랫폼으로부터 입수된 특정 위치의 실제 3D 컨텐츠 정보를 상기 가상 공간에 디스플레이하는 Raw Data Processing Module, 사용자로부터의 요청에 따라 신규 3D 객 체를 생성하는 External 3D Modeling System과의 연계를 지원하는 Interface Module, 및 상기 신규 3D 객체의 생성과 연동하여 상기 가상 공간을 수정 함으로써, 상기 신규 3D 객체에 관한 3D 컨텐츠 정보가 상기 가상 공간 에서 디스플레이 되도록 하는 Space Editor를 포함하여 구성할 수 있다. 상기 씬에 상응하여 디자인된 아바타를 등장(Summoning avatars)시키는 것은, Avatar Creation Engine에 의해 구현될 수 있다. 마이 무비 서비스 지원부는, Avatar Creation Engine을 포함하고, 상기 Avatar Creation Engine을 통해 디자인 된 아바타를, 상기 씬에서의 모션을 입히기 위하여 등장시키는 것을 포함할 수 있다. Avatar Creation Engine은, 얼굴을 포함한, 상기 아바타의 바디를 제작하는 Body Modeling, 상기 아바타가 입 고 있는 의상을 제작하는 Clothes Modeling, 상기 아바타에게 뼈대와 관절에 관한 인체공학적 특징을 부여하는 Character Rigging, 상기 바디의 제작, 상기 의상의 제작, 및 상기 인공공학적 특징의 부여에 따라, 상기 아바 타를 디자인하고, 상기 씬에 대응하여 저장하는 Avatar DB, 및 External Avatar Modeling System과 연결되어, 상기 디자인된 아바타를 교환하는 Interface Module를 포함하여 구성할 수 있다. 본 발명에 따르면, 일반 사용자가 메타버스에서 아바타를 활용하여 자신의 시나리오를 구현 함으로써 3D 영상 컨텐츠를 제작하는 서비스를 제공하는, 마이 무비 서비스를 지원하는 마이 무비 시스템 및 방법을 제공할 수 있 다. 또한, 본 발명에 의해서는, 메타버스에서 증강현실 및 아바타 모션 생성 기술을 바탕으로 사용자 정의 시나리오 에 대한 “나만의 영화 제작” 서비스를 제공할 수 있다. 또한, 본 발명에 의해서는, 사용자가 자신의 시나리오를 바탕으로 아바타에 모션을 부여하여, 3D 영화와 같은 영상 제작 서비스를 제공하는 시스템을 지원할 수 있다. 실시예에 따른 방법은 다양한 컴퓨터 수단을 통하여 수행될 수 있는 프로그램 명령 형태로 구현되어 컴퓨터 판 독 가능 매체에 기록될 수 있다. 상기 컴퓨터 판독 가능 매체는 프로그램 명령, 데이터 파일, 데이터 구조 등 을 단독으로 또는 조합하여 포함할 수 있다. 상기 매체에 기록되는 프로그램 명령은 실시예를 위하여 특별히 설계되고 구성된 것들이거나 컴퓨터 소프트웨어 당업자에게 공지되어 사용 가능한 것일 수도 있다. 컴퓨터 판 독 가능 기록 매체의 예에는 하드 디스크, 플로피 디스크 및 자기 테이프와 같은 자기 매체(magnetic media), CD-ROM, DVD와 같은 광기록 매체(optical media), 플롭티컬 디스크(floptical disk)와 같은 자기-광 매체 (magneto-optical media), 및 롬(ROM), 램(RAM), 플래시 메모리 등과 같은 프로그램 명령을 저장하고 수행하도 록 특별히 구성된 하드웨어 장치가 포함된다. 프로그램 명령의 예에는 컴파일러에 의해 만들어지는 것과 같은 기계어 코드뿐만 아니라 인터프리터 등을 사용해서 컴퓨터에 의해서 실행될 수 있는 고급 언어 코드를 포함한다. 상기된 하드웨어 장치는 실시예의 동작을 수행하기 위해 하나 이상의 소프트웨어 모듈로서 작동하도 록 구성될 수 있으며, 그 역도 마찬가지이다.소프트웨어는 컴퓨터 프로그램(computer program), 코드(code), 명령(instruction), 또는 이들 중 하나 이상의 조합을 포함할 수 있으며, 원하는 대로 동작하도록 처리 장치를 구성하거나 독립적으로 또는 결합적으로 (collectively) 처리 장치를 명령할 수 있다. 소프트웨어 및/또는 데이터는, 처리 장치에 의하여 해석되거나 처리 장치에 명령 또는 데이터를 제공하기 위하여, 어떤 유형의 기계, 구성요소(component), 물리적 장치, 가상 장치(virtual equipment), 컴퓨터 저장 매체 또는 장치에 저장될 수 있다. 소프트웨어는 네트워크로 연결된 컴 퓨터 시스템 상에 분산되어서, 분산된 방법으로 저장되거나 실행될 수도 있다. 소프트웨어 및 데이터는 하나 이 상의 컴퓨터 판독 가능 기록 매체에 저장될 수 있다."}
{"patent_id": "10-2023-0028493", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "이상과 같이 실시예들이 비록 한정된 도면에 의해 설명되었으나, 해당 기술분야에서 통상의 지식을 가진 자라면 상기를 기초로 다양한 기술적 수정 및 변형을 적용할 수 있다. 예를 들어, 설명된 기술들이 설명된 방법과 다 른 순서로 수행되거나, 및/또는 설명된 시스템, 구조, 장치, 회로 등의 구성요소들이 설명된 방법과 다른 형태 로 결합 또는 조합되거나, 다른 구성요소 또는 균등물에 의하여 대치되거나 치환되더라도 적절한 결과가 달성될 수 있다. 그러므로, 다른 구현들, 다른 실시예들 및 특허청구범위와 균등한 것들도 후술하는 청구범위의 범위에 속한다."}
{"patent_id": "10-2023-0028493", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명에 따른 마이 무비 서비스를 지원하는 마이 무비 시스템의 내부 구성을 도시한 블록도이다. 도 2는 마이 무비 시스템의 구조, 기능 및 작동 방식을 설명하기 위한 도이다. 도 3은 Linguistic Info. Processing Engine을 상세히 설명하기 위한 도이다. 도 4은 VR/AR Space Building Engine을 상세히 설명하기 위한 도이다. 도 5은 Avatar Creation Engine을 상세히 설명하기 위한 도이다. 도 6은 Motion Generation Engine을 상세히 설명하기 위한 도이다. 도 7은 본 발명에 따른 마이 무비 서비스를 지원하는 마이 무비 방법의 순서를 도시한 흐름도이다."}
