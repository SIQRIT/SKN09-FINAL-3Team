{"patent_id": "10-2020-7037506", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2021-0149576", "출원번호": "10-2020-7037506", "발명의 명칭": "에지 컴퓨팅 배치에서 다중 엔티티 자원, 보안 및 서비스 관리", "출원인": "인텔 코포레이션", "발명자": "기임 버나트 프란체스코"}}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "에지 컴퓨팅 환경에서 수행되는 방법으로서,상기 에지 컴퓨팅 환경의 복수의 에지 노드를 조정 및 오케스트레이션하는 단계 - 상기 복수의 에지 노드는 다수의 테넌트 중에서 워크로드를 실행하도록 구성됨 -; 및상기 복수의 에지 노드의 자원 사이에서, 하나 이상의 에지 서비스 사이에서 각각의 워크로드의 실행을 위해,상기 에지 컴퓨팅 환경에서 자원 사용을 제어하는 단계를 포함하는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1 항에 있어서,상기 에지 컴퓨팅 환경의 제 1 도메인의 에지 노드에서, 상기 제 1 도메인의 특정 자원으로의 액세스 요청을 수신하는 단계 - 상기 요청은 상기 에지 컴퓨팅 환경의 제 2 도메인의 에지 노드로부터 발생하며, 상기 제 1 및제 2 도메인은 각각의 도메인 내의 자원으로의 액세스의 범위를 각각 정의함 -;상기 제 1 및 제 2 도메인 내의 자원으로의 액세스의 범위로부터, 상기 특정 자원에 대한 액세스 권한을 식별하는 단계; 및상기 특정 자원으로의 상기 식별된 액세스 권한에 따라, 상기 제 1 도메인의 상기 특정 자원으로의 상기 액세스를 실시 가능하게 하는 단계를 포함하는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 2 항에 있어서,상기 도메인은 상기 에지 노드의 각각의 테넌트에 의해 제어되는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 3 항에 있어서,상기 각각의 테넌트는 네트워크 사업자인에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제 2 항에 있어서,상기 워크로드는 다수의 서비스를 달성하기 위해 다수의 기능의 사용을 조정하는 다수의 애플리케이션으로 구성되는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제 2 항에 있어서,상기 도메인은 각각의 도메인 내의 자원으로부터 전달할 서비스의 레벨을 정의하는 각각의 서비스 레벨 협약공개특허 10-2021-0149576-4-(service level agreement)(SLA)과 연관되는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제 2 항에 있어서,상기 특정 자원으로의 상기 액세스 권한에 기초하여, 상기 에지 컴퓨팅 환경 내의 이차 관계를 식별하여 특정자원으로의 액세스 요청을 이행하는 단계를 더 포함하는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제 2 항에 있어서,각각의 도메인은 각각의 테넌트 또는 구독자에 의해 액세스 가능한 각각의 서비스에 대해, 각각의 테넌트 또는구독자에 대한 관계를 정의하는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제 2 항에 있어서,상기 특정 자원으로의 상기 식별된 액세스 권한은 허용된 권한과 상기 제 1 도메인 및 상기 제 2 도메인에 의해제공되는 대응하는 자원 유형으로의 허용된 액세스의 교차점으로부터 식별되는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제 2 항에 있어서,워크로드를 상기 워크로드의 우선 순위에 기초하여 에지 노드 사이에서 그리고 더 깊은 네트워크 계층으로 이동함으로써 협력 오케스트레이션(cooperative orchestration)을 수행하여, 자원이 액세스 가능한 에지 노드 사이에서 풀려나는 단계를 더 포함하는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제 10 항에 있어서,상기 협력 오케스트레이션은 상기 에지 컴퓨팅 시스템 내의 공유 큐(shared queue)로부터 수행되며, 상기 공유큐는 상기 에지 컴퓨팅 시스템의 상기 에지 노드 사이에서 작업 및 기능의 오케스트레이션된 실행을 조정하기위해 상기 에지 컴퓨팅 시스템 내에서 사용하도록 구성되는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제 1 항에 있어서,에지 노드에서 자원 풀(resource pool)을 생성하는 단계;상기 에지 노드의 지능형 네트워크 제어기(intelligent network controller)(iNIC)의 품질 제어 회로에 의해,서비스 당 요청 속도를 측정하는 단계;상기 품질 제어 회로에 의해, 상기 서비스에 대한 자원 할당을 넘어서는 임계적 서비스에 대한 가능성 있는 자원 요구를 결정하는 단계; 및상기 자원 풀로부터의 자원을 상기 임계적 서비스에 재 할당하여 상기 가능성 있는 자원 요구를 충족시키는 단공개특허 10-2021-0149576-5-계를 더 포함하는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제 12 항에 있어서,상기 에지 노드는 에지 게이트웨이인에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제 13 항에 있어서,상기 서비스는 상기 에지 게이트웨이에 의해 서빙되는 플랫폼상에서 실행되는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제 12 항에 있어서,상기 품질 제어 회로는 필드 프로그램 가능 게이트 어레이(field programmable gate array)인에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제 1 항에 있어서,상기 에지 도메인에 속하는 제 1 에지 위치에서 요청을 수신하는 단계; 상기 제 1 에지 위치에서, 상기 요청이 제 2 에지 위치의 가용 자원에 기초하여 상기 에지 도메인의 상기 제 2에지 위치에서 실행 가능하다고 결정하는 단계; 및상기 요청을 실행을 위해 상기 제 2 에지 위치로 포워딩하는 단계를 포함하는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제 16 항에 있어서,상기 요청이 상기 제 2 에지 위치에서 실행 가능하다고 결정하는 단계는 상기 제 2 에지 위치에서 상기 요청을실행하는 것이 상기 제 1 에지 위치에서 상기 요청을 실행하는 것보다 더 적은 컴퓨팅 자원을 필요로 하거나 더적은 시간을 필요로 한다고 결정하는 단계를 포함하는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제 17 항에 있어서,상기 제 2 에지 위치에서 상기 요청을 실행하는 것이 더 적은 컴퓨팅 자원을 필요로 하거나 더 적은 시간을 필요로 한다고 결정하는 단계는 일정 기간 동안 상기 제 1 에지 위치의 예측된 활용에 기초하는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제 17 항에 있어서,상기 제 2 에지 위치에서 상기 요청을 실행하는 것이 더 적은 컴퓨팅 자원을 필요로 하거나 더 적은 시간을 필요로 한다고 결정하는 단계는 상기 제 2 에지 위치로부터 상기 제 1 에지 위치까지의 거리에 기초하는공개특허 10-2021-0149576-6-에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제 17 항에 있어서,상기 제 2 에지 위치에서 상기 요청을 실행하는 것이 더 적은 컴퓨팅 자원을 필요로 하거나 더 적은 시간을 필요로 한다고 결정하는 단계는 머신 학습 요소를 사용하여 상기 제 1 에지 위치로 들어오는 요청을 예측하는 단계를 포함하는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_21", "content": "제 16 항에 있어서,상기 제 2 에지 위치의 태그를 사용하여 상기 제 2 에지 위치를 선택하는 단계를 더 포함하고, 상기 태그는 가용 자원 및 상기 에지 도메인의 상기 제 2 에지 위치의 멤버십을 나타내는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_22", "content": "제 16 항에 있어서,상기 제 1 에지 위치에서, 상기 제 2 에지 위치로부터 원격 측정 및 자원 활용 데이터를 수신하는 단계를 더 포함하는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_23", "content": "제 16 항에 있어서,상기 제 2 에지 위치는 에지 서비스를 제공하고, 상기 에지 서비스의 결과는 상기 에지 서비스에 제공되는 데이터의 소스의 검증 가능한 증명 및 상기 에지 서비스에 의해 생성되는 상기 데이터의 결과에 기초하여 증명될 수있는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_24", "content": "제 16 항에 있어서,워크로드를 상기 워크로드의 우선 순위에 기초하여 에지 노드 사이에서 그리고 더 깊은 네트워크 계층으로 이동함으로써 협력 오케스트레이션을 수행하는 단계를 더 포함하며, 그럼으로써 자원이 액세스 가능한 에지 노드 사이에서 풀리는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_25", "content": "제 24 항에 있어서,상기 협력 오케스트레이션은 상기 에지 컴퓨팅 시스템 내의 공유 큐로부터 수행되며, 상기 공유 큐는 상기 에지컴퓨팅 시스템의 상기 에지 노드 사이에서 작업 및 기능의 오케스트레이션된 실행을 조정하기 위해 상기 에지컴퓨팅 시스템 내에서 사용하도록 구성되는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_26", "content": "제 24 항에 있어서,공개특허 10-2021-0149576-7-상기 제 1 에지 위치는 제 1 에지 노드이고 상기 제 2 에지 위치는 제 2 에지 노드이며, 상기 제 1 및 제 2 에지 노드는 분산 에지 컴퓨팅 시스템(distributed edge computing system)의 계층에 있는 네트워크 피어(network peer)인에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_27", "content": "제 1 항에 있어서,게이트웨이에서, 상기 에지 컴퓨팅 환경에서 자원의 사용을 유발하는 테넌트로부터의 요청을 수신하는 단계 -상기 게이트웨이는 스위치 패브릭을 통해 노드의 하드웨어 플랫폼에 연결됨 -;상기 게이트웨이에서, 상기 테넌트로부터의 요청에 대한 전력 구성을 수신하는 단계;상기 하드웨어 플랫폼으로부터 하드웨어 플랫폼을 선택하여 상기 요청을 완료하는 단계; 및상기 요청을 하드웨어 플랫폼에 발송(dispatch)하는 단계를 더 포함하는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_28", "content": "제 27 항에 있어서,상기 게이트웨이는 인증자 회로(authenticator circuitry)를 포함하고, 상기 테넌트로부터 상기 요청을 수신하는 단계는 상기 요청을 인증하는 단계를 포함하는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_29", "content": "제 27 항에 있어서,상기 하드웨어 플랫폼으로부터 상기 하드웨어 플랫폼을 선택하는 단계는 상기 게이트웨이의 스위치를 통해 상기하드웨어 플랫폼 걸쳐 요청을 로드 밸런싱(load balancing)하는 단계를 포함하는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_30", "content": "제 27 항에 있어서,상기 스위치는 상기 게이트웨이의 원격 측정 회로로부터의 데이터를 통합하여 여러 플랫폼 중 어느 플랫폼이 상기 요청을 서비스하는 데 이용 가능한지를 결정하는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_31", "content": "제 27 항에 있어서,상기 전력 구성은 최대-최소 전력 범위, 최대 전력 소비 또는 전력 소비에 기초한 최대 금전적 가치 중 적어도하나를 포함하는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_32", "content": "제 27 항에 있어서,상기 요청은 서비스 레벨 협약(SLA) 요구 사항을 포함하고, 상기 하드웨어 플랫폼을 선택하는 단계는 상기 SLA요구 사항을 사용하여 상기 하드웨어 플랫폼을 선택하는 단계를 포함하는에지 컴퓨팅 환경에서 수행되는 방법.공개특허 10-2021-0149576-8-청구항 33 제 27 항에 있어서,상기 하드웨어 플랫폼은 에지 서비스를 동작시켜 상기 요청을 상기 자원으로 이행하고, 상기 에지 서비스의 결과는 상기 에지 서비스에 제공되는 데이터의 소스의 검증 가능한 증명 및 상기 에지 서비스에 의해 생성되는 상기 데이터의 결과에 기초하여 증명될 수 있는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_34", "content": "제 27 항에 있어서,워크로드를 상기 워크로드의 우선 순위에 기초하여 에지 노드 사이에서 그리고 더 깊은 네트워크 계층으로 이동함으로써 협력 오케스트레이션을 수행하는 단계를 더 포함하며, 그럼으로써 자원이 액세스 가능한 에지 노드 사이에서 풀려나는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_35", "content": "제 34 항에 있어서,상기 협력 오케스트레이션은 상기 에지 컴퓨팅 시스템 내의 공유 큐로부터 수행되며, 상기 공유 큐는 상기 에지컴퓨팅 시스템의 상기 에지 노드 사이에서 작업 및 기능의 오케스트레이션된 실행을 조정하기 위해 상기 에지컴퓨팅 시스템 내에서 사용하도록 구성되는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_36", "content": "제 34 항에 있어서,상기 에지 노드는 분산 에지 컴퓨팅 시스템의 계층에 있는 네트워크 피어인에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_37", "content": "제 1 항에 있어서, 상기 에지 컴퓨팅 환경의 상기 복수의 에지 노드상의 물리적 어드레스에 가상 어드레스를 매핑하도록 구성된에지 글로벌 서비스 페이지 테이블(edge global service page table)을 유지하는 단계; 상기 에지 글로벌 서비스 페이지 테이블에서 유지되는 가상 메모리 어드레스에 있는 자원으로의 액세스 요청을수신하는 단계; 상기 가상 메모리 어드레스와 연관된 물리적 어드레스 및 대응하는 에지 노드를 식별하는 단계; 및상기 물리적 어드레스에 저장된 자원으로의 액세스를 제공하는 단계를 더 포함하는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_38", "content": "제 37 항에 있어서,상기 자원으로의 액세스를 제공하는 단계는 상기 물리적 어드레스 및 상기 대응하는 에지 노드를 포함하는 정보를 요청 디바이스 또는 서비스에 전송하는 단계를 포함하는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_39", "content": "공개특허 10-2021-0149576-9-제 37 항에 있어서,상기 자원으로의 액세스를 제공하는 단계는 상기 대응하는 에지 노드로부터 요청 에지 노드로의 상기 자원의 복사 또는 이전을 용이하게 하는 단계를 포함하는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_40", "content": "제 37 항에 있어서,상기 자원으로의 액세스를 제공하는 단계에 앞서, 상기 에지 글로벌 서비스 페이지 테이블을 체크함으로써 요청디바이스가 상기 자원에 액세스할 인가를 갖고 있는지를 결정하는 단계를 더 포함하는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_41", "content": "제 37 항에 있어서,상기 방법은 상기 복수의 에지 노드의 에지 노드에 의해 수행되고, 상기 에지 글로벌 서비스 페이지 테이블은상기 에지 노드상에 로컬로 저장되는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_42", "content": "제 37 항에 있어서,상기 자원으로의 액세스를 제공하는 단계는 판독(read)을 원격 네트워크 인터페이스에 전송하여 상기 대응하는에지 노드에서 원격 메모리 액세스를 획득하는 단계를 포함하는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_43", "content": "제 37 항에 있어서,상기 자원으로의 액세스를 제공하는 단계는 상기 자원, 상기 대응하는 에지 노드, 또는 요청 디바이스의 보안요구 사항을 준수하는 단계를 포함하는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_44", "content": "에지 컴퓨팅 환경에서 수행되는 방법으로서,상기 에지 컴퓨팅 환경의 복수의 에지 노드 사이에서 보안 동작을 조정하는 단계 - 상기 복수의 에지 노드는 다수의 테넌트 중에서 워크로드를 실행하도록 구성됨 -; 및상기 복수의 에지 노드의 자원 사이에서, 하나 이상의 에지 서비스 사이에서 각각의 워크로드의 보안 실행을 위해, 상기 에지 컴퓨팅 환경에서 자원 사용량을 제어하는 단계를 포함하는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_45", "content": "제 44 항에 있어서,제 1 에지 노드에서, 제 2 에지 노드에 전달될 콘텐츠의 암호화를 위한 대칭 키를 생성하는 단계;상기 제 1 에지 노드에서, 상기 대칭 키를 암호화하는 단계;상기 제 1 에지 노드에서, 상기 대칭 키를 사용하여 상기 제 2 에지 노드에 전달될 상기 콘텐츠를 암호화하는단계; 및공개특허 10-2021-0149576-10-암호화된 보안 채널을 통해 에지 노드 서버로, 상기 암호화된 대칭 키 및 상기 전달될 암호화된 콘텐츠를 전달하는 단계를 더 포함하고, 상기 암호화된 대칭 키 및 상기 전달될 암호화된 콘텐츠는 나중에 상기 제 2 에지 노드에 의해 상기 에지 노드 서버로부터 획득되는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_46", "content": "제 45 항에 있어서,상기 암호화된 대칭 키 및 상기 전달될 암호화된 콘텐츠는 상기 제 2 에지 노드에 의해 상기 에지 노드 서버의보안 스토리지로부터 획득되는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_47", "content": "제 46 항에 있어서,상기 암호화된 대칭 키 및 상기 전달될 암호화된 콘텐츠는 상기 보안 스토리지에 액세스하고, 상기 대칭 키를사용하여 상기 암호화된 콘텐츠를 해독함으로써 상기 제 2 에지 노드에 의해 상기 에지 노드 서버로부터 획득되는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_48", "content": "제 46 항에 있어서,상기 보안 스토리지는 상기 에지 노드 서버에 의해 유지되는 보안 엔클레이브(secure enclave) 또는 보안 버퍼인에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_49", "content": "제 45 항에 있어서,상기 에지 노드 서버는 기지국이고, 상기 제 1 에지 노드 및 상기 제 2 에지 노드는 엔드포인트 클라이언트 디바이스인에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_50", "content": "제 45 항에 있어서,상기 암호화된 대칭 키 및 상기 전달될 암호화된 콘텐츠는 비동기 통신 세션을 사용하여 상기 제 2 에지 노드에의해 상기 에지 노드 서버로부터 획득되는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_51", "content": "제 45 항에 있어서,상기 대칭 키를 생성하고 상기 대칭 키 및 상기 전달될 콘텐츠를 암호화하는 상기 동작은 상기 제 1 에지 노드에서 신뢰성 있는 당사자에 의해 인증된 하드웨어를 사용하여 수행되는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_52", "content": "제 51 항에 있어서,공개특허 10-2021-0149576-11- 상기 암호화된 대칭 키 및 상기 암호화된 콘텐츠를 해독하는 동작은 상기 제 2 에지 노드에서 상기 신뢰성 있는 당사자에 의해 인증된 하드웨어를 사용하여 수행되는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_53", "content": "제 51 항에 있어서,상기 신뢰성 있는 당사자는 하드웨어 제조업체인에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_54", "content": "제 45 항에 있어서,상기 제 1 에지 노드는 콘텐츠를 공유할 에지 노드에 대한 한 세트의 공용 인증서(public certificate)를 유지하며, 상기 공용 인증서 세트는 상기 제 2 에지 노드로부터의 공용 인증서를 포함하는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_55", "content": "제 54 항에 있어서,상기 에지 노드는 분산 에지 컴퓨팅 시스템의 계층에 있는 네트워크 피어인에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_56", "content": "제 45 항에 있어서, 상기 복수의 에지 노드 사이에서 서비스로서의 보안 기능(security-as-a-service function)을 사용하여 신뢰성있는 암호화 동작을 생성 및 설정하는 단계를 더 포함하는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_57", "content": "제 44 항에 있어서,상기 에지 노드에서 그룹 통신 세션의 시작을 식별하는 단계;상기 그룹 통신 세션에 참여하는 한 세트의 그룹 멤버를 결정하는 단계;상기 그룹 통신 세션을 위한 보안 그룹 통신 채널을 생성하는 단계; 및상기 보안 그룹 통신 채널을 사용하여 보안 통신을 용이하게 하는 데 사용될 키를 상기 그룹 멤버 세트의 멤버에게 송신하는 단계를 더 포함하는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_58", "content": "제 57 항에 있어서,상기 통신 채널을 사용하여 상기 그룹 멤버 세트에 의해 완료될 작업과 연관된 역할을 결정하는 단계;상기 그룹 멤버 세트에 대한 기지국 세트를 식별하는 단계 - 상기 기지국 세트는 서비스를 상기 그룹 멤버 세트에 제공하는 기지국을 포함함 -; 및상기 기지국 세트의 하나 이상의 기지국 멤버의 역할을 활성화하는 단계를 더 포함하는에지 컴퓨팅 환경에서 수행되는 방법.공개특허 10-2021-0149576-12-청구항 59 제 58 항에 있어서,상기 역할은 오케스트레이터(orchestrator), 그룹 리더 또는 키 관리자에 의해 제공되는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_60", "content": "제 57 항에 있어서,상기 보안 통신 채널을 생성하는 단계는 상기 그룹 멤버 세트의 각 멤버와 키 교환을 수행하는 단계를 더 포함하며, 상기 키는 상기 키 교환이 성공적으로 완료되면 상기 멤버에게 송신되는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_61", "content": "제 57 항에 있어서,상기 그룹 통신 세션이 종료된 것을 결정하는 단계;상기 키를 폐지하는 단계; 및상기 보안 그룹 통신 채널을 파괴하는 단계를 더 포함하는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_62", "content": "제 57 항에 있어서,상기 그룹 통신 세션의 시작을 식별하는 단계는 협업 워크로드(collaborative workload)의 시작의 표시를 수신하는 단계를 더 포함하는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_63", "content": "제 62 항에 있어서,상기 그룹 통신 세션에 참여하는 상기 그룹 멤버 세트를 결정하는 단계는 상기 협업 워크로드에서 협업하도록지정된 하나 이상의 에지 노드의 표시를 수신하는 단계를 더 포함하는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_64", "content": "제 63 항에 있어서,상기 에지 노드는 분산 에지 컴퓨팅 시스템의 계층에 있는 네트워크 피어인에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_65", "content": "제 57 항에 있어서,상기 복수의 에지 노드 사이에서 서비스로서의 보안 기능(security-as-a-service function)을 사용하여 신뢰성있는 암호화 동작을 생성 및 설정하는 단계를 더 포함하는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_66", "content": "공개특허 10-2021-0149576-13-제 44 항에 있어서,소스 클라우드렛(source cloudlet)의 로컬 데이터 스토어(local data store) 내 워크로드에 대한 데이터를 암호화하여 암호화된 데이터를 생성하는 단계;상기 암호화된 데이터에 대한 키를 상기 소스 클라우드렛으로부터 목적지 클라우드렛으로 이전하는 단계;워크로드 마이그레이션 표시(workload migration indication)를 수신하는 단계; 및상기 워크로드 마이그레이션 표시에 응답하여, 상기 암호화된 데이터를 비 보안 채널을 통해 상기 목적지 클라우드렛으로 송신하는 단계를 더 포함하는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_67", "content": "제 66 항에 있어서,상기 암호화된 데이터는 암호화된 데이터로서 상기 로컬 데이터 저장소로부터 작업 메모리로 이전되는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_68", "content": "제 67 항에 있어서,상기 소스 클라우드렛은 상기 데이터가 상기 작업 메모리로부터 프로세서로 이전될 때 전체 메모리 암호화 회로를 사용하여 상기 암호화된 데이터를 해독하는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_69", "content": "제 66 항에 있어서,상기 암호화된 데이터의 일부는 상기 워크로드 마이그레이션의 일부로서 이전되지 않으며, 상기 일부는 상기 워크로드에 의한 데이터 사용을 프로파일링함으로써 결정되는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_70", "content": "제 66 항에 있어서,상기 복수의 에지 노드 사이에서 서비스로서의 보안 기능(security-as-a-service function)을 사용하여 신뢰성있는 암호화 동작을 생성 및 설정하는 단계를 더 포함하는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_71", "content": "제 44 항에 있어서,제 1 클라우드렛에서 클라우드렛 마이그레이션 신호를 수신하는 단계;상기 제 1 클라우드렛의 컴퓨테이션 컴포넌트를 분석하여 데이터 중력 메트릭(data gravity metric)을 생성하는단계; 상기 제 1 컴포넌트에 대한 제 1 데이터 중력 값이 임계치 미만인 것에 응답하여, 제 1 컴포넌트를 제 2 클라우드렛으로 이동하는 단계; 상기 제 2 컴포넌트에 대한 제 2 데이터 중력 값이 임계치 초과인 것에 응답하여, 제 2 컴포넌트를 상기 제 2클라우드렛으로 이동하는 것을 삼가는 단계; 및상기 제 2 컴포넌트에 대한 인터페이스를 상기 제 2 클라우드렛에 제공하는 단계를 더 포함하는공개특허 10-2021-0149576-14-에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_72", "content": "제 71 항에 있어서,상기 제 1 클라우드렛은 제 1 기지국에 있고, 상기 제 2 클라우드렛은 제 2 기지국에 있는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_73", "content": "제 72 항에 있어서,상기 클라우드렛 마이그레이션 신호는 상기 제 1 기지국으로부터 상기 제 2 기지국으로 사용자 장비의 핸드오프에 응답하며, 상기 사용자 장비는 상기 핸드오프 이전에 상기 제 1 클라우드렛의 서비스를 사용 중인에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_74", "content": "제 71 항에 있어서,상기 데이터 중력은 상기 제 2 컴포넌트에 의해 사용되는 데이터의 크기에 기초하는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_75", "content": "제 74 항에 있어서,상기 데이터 중력은 또한 상기 데이터 크기의 컴퓨테이션에 기초하며, 상기 컴퓨테이션은 상기 데이터를 상기제 2 클라우드렛으로 이동할 자원의 카운트 또는 상기 데이터를 상기 제 2 클라우드렛으로 이동할 비용 중 적어도 하나인에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_76", "content": "제 44 항에 있어서,에지 노드에서, 복수의 플랫폼으로부터 원격 측정 데이터를 수신하는 단계 - 상기 원격 측정 데이터는 상기 복수의 플랫폼의 각 플랫폼의 로컬 인증서로 서명됨 -; 상기 원격 측정 데이터를 상기 에지 노드에 저장하는 단계; 테넌트 디바이스로부터 에지 서비스에 대응하는 상기 원격 측정 데이터의 일부에 대한 요청을 수신하는 단계;및상기 에지 노드로부터 상기 테넌트 디바이스로, 대응하는 로컬 인증서를 비롯하여, 상기 에지 서비스에 대응하는 상기 원격 측정 데이터 상기 부분을 전송하는 단계를 더 포함하는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_77", "content": "제 76 항에 있어서,상기 에지 노드에서 에지 원격 측정 서비스를 실행하여 상기 원격 측정 데이터를 수신하는 단계를 더 포함하는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_78", "content": "제 76 항에 있어서,공개특허 10-2021-0149576-15-상기 테넌트 디바이스로부터, 상기 에지 노드에 의해 모니터링되는 에지 서비스에 대한 발견 요청(discoveryrequest)을 수신하고, 이에 응답하여 상기 에지 노드에 의해 모니터링되는 에지 서비스의 목록을 전송하는 단계를 더 포함하는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_79", "content": "제 76 항에 있어서,상기 에지 서비스에 대응하는 상기 원격 측정 데이터의 상기 부분은 상기 에지 서비스에 의해 서명되는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_80", "content": "제 76 항에 있어서,상기 에지 서비스로부터 서비스 원격 측정 데이터를 수신하는 단계를 더 포함하는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_81", "content": "제 76 항에 있어서,상기 원격 측정 데이터의 적어도 일부는 다른 에지 노드로부터 수신되는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_82", "content": "제 76 항에 있어서,상기 에지 노드는 한 지역의 복수의 분산 에지 노드 중 하나인에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_83", "content": "제 82 항에 있어서,상기 분산 에지 노드는 분산 에지 컴퓨팅 시스템의 계층에 있는 네트워크 피어인에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_84", "content": "제 44 항에 있어서,상기 에지 서비스의 결과는 상기 에지 서비스에 제공되는 데이터의 소스의 검증 가능한 증명 및 상기 에지 서비스에 의해 생성되는 상기 데이터의 결과에 기초하여 증명될 수 있는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_85", "content": "제 44 항에 있어서,상기 복수의 에지 노드 중 제 1 에지 노드에서 데이터 패킷을 디코딩하는 단계 - 상기 데이터 패킷은 상기 복수의 에지 노드 중 제 2 에지 노드로부터 수신되고, 상기 데이터 패킷은 데이터 페이로드 및 제 1 에지 핸들(edgehandle)을 포함하고, 상기 제 1 에지 핸들은 상기 데이터 페이로드와 연관된 소스 에지 노드 및 데이터 흐름 경로를 표시함 -;상기 소스 에지 노드 및 업데이트된 데이터 흐름 경로를 포함하도록 제 2 에지 핸들을 생성하는 단계 - 상기 업공개특허 10-2021-0149576-16-데이트된 데이터 흐름 경로는 상기 데이터 흐름 경로 및 상기 제 1 에지 노드의 노드 ID에 기초함 -; 및상기 복수의 에지 노드 중 제 3 에지 노드로 송신하기 위해 상기 제 2 에지 핸들 및 상기 데이터 페이로드를 인코딩하는 단계를 더 포함하는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_86", "content": "제 85 항에 있어서,상기 소스 에지 노드는 상기 데이터 페이로드의 통신을 시작하고, 상기 데이터 흐름 경로는 상기 데이터 페이로드를 통신하는 데 사용되는 상기 복수의 에지 노드의 서브세트를 표시하는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_87", "content": "제 86 항에 있어서,상기 데이터 흐름 경로를 사용하여 상기 복수의 에지 노드의 상기 서브세트 내 각각의 에지 노드의 노드 ID를결정하는 단계를 더 포함하는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_88", "content": "제 87 항에 있어서,상기 결정된 노드 ID 및 인증 룩업 테이블(authentication look-up table)에 기초하여 상기 데이터 흐름 경로에포함된 상기 복수의 에지 노드의 상기 서브세트를 인증하는 단계를 더 포함하는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_89", "content": "제 88 항에 있어서,상기 복수의 에지 노드의 상기 서브세트의 적어도 하나의 에지 노드가 상기 인증에 실패할 때 통지를 생성하는단계를 더 포함하는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_90", "content": "제 88 항에 있어서,서비스 조정 엔티티로부터 브로드캐스트 메시지를 디코딩하는 단계를 더 포함하고, 상기 브로드캐스트 메시지는상기 인증 룩업 테이블을 업데이트하는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_91", "content": "제 90 항에 있어서,상기 브로드캐스트 메시지는 상기 복수의 에지 노드 간의 보안 통신을 위한 적어도 하나의 인증 키를 더 포함하는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_92", "content": "제 91 항에 있어서,공개특허 10-2021-0149576-17- 상기 인코딩 및 상기 디코딩은 적어도 하나의 인증 키에 기초하는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_93", "content": "제 90 항에 있어서,상기 브로드캐스트 메시지 내의 클록 동기화 신호에 기초하여 상기 제 1 에지 노드의 클록을 동기화하는 단계를더 포함하는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_94", "content": "제 93 항에 있어서,상기 제 1 에지 노드의 타임스탬프를 더 포함하도록 상기 제 2 에지 핸들을 인코딩하는 단계를 더 포함하며, 상기 타임스탬프는 상기 데이터 페이로드가 상기 제 3 에지 노드로 송신되는 시간을 나타내는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_95", "content": "제 90 항에 있어서,상기 서비스 조정 엔티티는 컴퓨팅 서비스를 상기 서비스 조정 엔티티의 가상화 인프라스트럭처상에서 인스턴스화된 MEC 애플리케이션으로서 실행하는 다중 액세스 에지 컴퓨팅(Multi-Access Edge Computing)(MEC) 호스트인에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_96", "content": "제 95 항에 있어서,상기 MEC 호스트는 ETSI(European Telecommunications Standards Institute) MEC 표준 제품군의 표준에 따라동작하도록 구성되는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_97", "content": "제 85 항에 있어서,상기 에지 컴퓨팅 환경은 에지 서비스의 결과가 상기 에지 서비스에 제공되는 데이터의 소스의 검증 가능한 증명 및 상기 에지 서비스에 의해 생성되는 상기 데이터의 결과에 기초하여 증명될 수 있도록 동작 가능한에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_98", "content": "제 85 항에 있어서,상기 복수의 에지 노드 사이에서 서비스로서의 보안 기능(security-as-a-service function)을 사용하여 신뢰성있는 암호화 동작을 생성 및 설정하는 단계를 더 포함하는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_99", "content": "에지 컴퓨팅 환경에서 수행되는 방법으로서,상기 에지 컴퓨팅 환경의 복수의 에지 노드를 식별하는 단계 - 상기 복수의 에지 노드는 다수의 테넌트 중에서워크로드를 실행하도록 구성됨 -; 및공개특허 10-2021-0149576-18-상기 복수의 에지 노드의 자원 사이에서, 하나 이상의 에지 서비스 사이에서 각각의 워크로드의 실행을 위해,상기 에지 컴퓨팅 환경에서 오케스트레이션 동작을 제어하는 단계를 포함하는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_100", "content": "제 99 항에 있어서,서비스로서의 충돌 분석(conflict analysis as a service)(CAaaS)을 수행하는 에지 노드에서, 원격 측정 수집기로부터 복수의 에지 노드에 대한 원격 측정 정보를 수신하는 단계;상기 CAaaS를 사용하여, 상기 원격 측정 정보를 사용하여 액세스 맵을 생성하는 단계; 및상기 액세스 맵을 오케스트레이터에 제공하여 상기 액세스 맵에 따라 상기 복수의 에지 노드 사이에 테넌트를할당하는 단계를 더 포함하는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_101", "content": "제 100 항에 있어서,상기 액세스 맵은 서비스 레벨 협약(SLA)을 포함하는 사용자 컨텍스트에 기초하여 생성되는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_102", "content": "제 100 항에 있어서,상기 액세스 맵은 입력으로서 상기 원격 측정 정보를 사용하는 머신 학습 패턴 인식 엔진의 출력에 기초하여 생성되는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_103", "content": "제 100 항에 있어서,사용자 데이터, 상기 원격 측정 정보 및 상기 테넌트의 평판 데이터로부터의 관심 패턴을 비교하여 상기 맵을생성하는 충돌 분석 엔진을 구현하는 단계를 더 포함하는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_104", "content": "제 100 항에 있어서,상기 오케스트레이터는 충돌하는 테넌트를 상기 복수의 에지 노드의 물리적으로 상이한 에지 노드상에서 실행하도록 스케줄링하도록 구성되는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_105", "content": "제 100 항에 있어서,상기 액세스 맵은 다수의 충돌 레벨 및 연관된 격리 요구 사항을 포함하는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_106", "content": "제 100 항에 있어서,공개특허 10-2021-0149576-19-상기 원격 측정 정보는 사적 정보없이 외부에서 관찰 가능한 워크로드 거동 추세(workload behavioral trend)를포함하는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_107", "content": "제 100 항에 있어서,상기 액세스 맵은 RESTful API 액세스, 파일 액세스 허가 또는 바이너리 액세스 중 적어도 하나에 대한 권한 제한 사항을 포함하는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_108", "content": "제 100 항에 있어서,상기 액세스 맵은 격리 없음, 프로세스 격리, 가상 머신, 엔클레이브 또는 물리적 격리 중 적어도 하나를 포함하는 격리 레벨을 포함하는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_109", "content": "제 100 항에 있어서,상기 오케스트레이션은 제 1 오케스트레이터로부터 제 2 오케스트레이터로의 위임에 응답하여 발생하는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_110", "content": "제 109 항에 있어서,상기 오케스트레이션은 상기 제 1 오케스트레이터로부터 상기 제 2 오케스트레이터로 전달되는 오케스트레이션정책에 따라 발생하는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_111", "content": "제 100 항에 있어서,워크로드를 상기 워크로드의 우선 순위에 기초하여 에지 노드 사이에서 그리고 더 깊은 네트워크 계층으로 이동함으로써 상기 오케스트레이터로부터 협력 오케스트레이션을 시작하는 단계를 더 포함하며, 그럼으로써 자원이액세스 가능한 에지 노드 사이에서 풀려나는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_112", "content": "제 111 항에 있어서,상기 협력 오케스트레이션은 상기 에지 컴퓨팅 시스템 내의 공유 큐(shared queue)로부터 수행되며, 상기 공유큐는 상기 에지 컴퓨팅 시스템의 상기 에지 노드 사이에서 작업 및 기능의 오케스트레이션된 실행을 조정하기위해 상기 에지 컴퓨팅 시스템 내에서 사용하도록 구성되는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_113", "content": "제 111 항에 있어서,상기 에지 노드는 분산 에지 컴퓨팅 시스템의 계층에 있는 네트워크 피어인공개특허 10-2021-0149576-20-에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_114", "content": "제 99 항에 있어서,네트워크 인터페이스 디바이스 내에서 단일 루트 입력/출력 가상화(single root input/outputvirtualization)(SR-IOV)에 의해 야기된 네트워킹 기능 변경을 사용하여 에지 컴퓨팅 시스템 내에서 오케스트레이션을 구현하는 단계를 더 포함하며, 상기 네트워킹 기능은 가상적 및 물리적 네트워크 기능 사이의 변경을 포함하는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_115", "content": "제 99 항에 있어서,오케스트레이터를 다른 오케스트레이터와 상호작용하도록 동작하는 단계 - 상기 오케스트레이터는 상기 오케스트레이터에 대응하는 지역 내의 에지 노드 사이에서 자원을 조정함 -; 상기 지역 내에서 이용 가능하지 않은 자원 요청을 식별하는 단계; 상기 다른 오케스트레이터와 조정하여 상기 자원을 요청하는 단계; 및상기 다른 오케스트레이터 중 하나로부터 자원 할당을 수신하는 단계를 더 포함하는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_116", "content": "제 115 항에 있어서,상기 자원 요청을 식별하는 단계는 상기 지역 내의 가용 자원이 임계치 미만인 것을 결정하는 단계를 포함하는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_117", "content": "제 115 항에 있어서,상기 자원 요청을 식별하는 단계는 상기 지역 내의 노드의 서비스로부터 상기 요청을 수신하는 단계를 포함하는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_118", "content": "제 115 항에 있어서,상기 오케스트레이터 및 상기 다른 오케스트레이터는 도메인의 멤버인에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_119", "content": "제 118 항에 있어서,상기 도메인은 상기 오케스트레이터 및 상기 다른 오케스트레이터에 대응하는 지역 내의 에지의 근접성에 기초하여 선택되는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_120", "content": "제 118 항에 있어서,상기 도메인은 에지 노드 유형에 기초하여 선택되는공개특허 10-2021-0149576-21-에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_121", "content": "제 118 항에 있어서,상기 오케스트레이터로부터 상기 다른 오케스트레이터로, 상기 지역 내의 가용 자원을 브로드캐스팅하는 단계를더 포함하는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_122", "content": "제 118 항에 있어서,상기 지역 내에서 상기 자원의 사용이 완료될 때 상기 다른 오케스트레이터 중 하나에게 표시를 전송함으로써상기 자원을 반환하는 단계를 더 포함하는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_123", "content": "제 118 항에 있어서,워크로드를 상기 워크로드의 우선 순위에 기초하여 에지 노드 사이에서 그리고 더 깊은 네트워크 계층으로 이동함으로써 협력 오케스트레이션을 수행하는 단계를 더 포함하고, 그럼으로써 자원이 액세스 가능한 에지 노드 사이에서 풀리는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_124", "content": "제 123 항에 있어서,상기 에지 노드는 분산 에지 컴퓨팅 시스템의 계층에 있는 네트워크 피어인에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_125", "content": "에지 컴퓨팅 환경에서 수행되는 방법으로서,상기 에지 컴퓨팅 환경의 복수의 에지 노드를 식별하는 단계 - 상기 복수의 에지 노드는 다수의 테넌트 중에서워크로드를 실행하도록 구성됨 -; 및상기 복수의 에지 노드의 자원 사이에서, 하나 이상의 에지 서비스 사이에서 각각의 워크로드의 실행을 위해,상기 에지 컴퓨팅 환경에서 오케스트레이션 동작을 제어하는 단계를 포함하는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_126", "content": "제 125 항에 있어서,서비스로서의 충돌 분석(conflict analysis as a service)(CAaaS)을 수행하는 에지 노드에서, 원격 측정 수집기로부터 복수의 에지 노드에 대한 원격 측정 정보를 수신하는 단계;상기 CAaaS를 사용하여, 상기 원격 측정 정보를 사용하여 액세스 맵을 생성하는 단계; 및상기 액세스 맵을 오케스트레이터에 제공하여 상기 액세스 맵에 따라 상기 복수의 에지 노드 사이에 테넌트를할당하는 단계를 더 포함하는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_127", "content": "공개특허 10-2021-0149576-22-제 126 항에 있어서,상기 액세스 맵은 서비스 레벨 협약(SLA)을 포함하는 사용자 컨텍스트에 기초하여 생성되는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_128", "content": "제 126 항에 있어서,상기 액세스 맵은 입력으로서 상기 원격 측정 정보를 사용하는 머신 학습 패턴 인식 엔진의 출력에 기초하여 생성되는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_129", "content": "제 126 항에 있어서,사용자 데이터, 상기 원격 측정 정보 및 상기 테넌트의 평판 데이터로부터의 관심 패턴을 비교하여 상기 맵을생성하는 충돌 분석 엔진을 구현하는 단계를 더 포함하는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_130", "content": "제 126 항에 있어서,상기 오케스트레이터는 충돌하는 테넌트를 상기 복수의 에지 노드의 물리적으로 상이한 에지 노드상에서 실행하도록 스케줄링하도록 구성되는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_131", "content": "제 126 항에 있어서,상기 액세스 맵은 다수의 충돌 레벨 및 연관된 격리 요구 사항을 포함하는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_132", "content": "제 126 항에 있어서,상기 원격 측정 정보는 사적 정보없이 외부에서 관찰 가능한 워크로드 거동 추세(workload behavioral trend)를포함하는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_133", "content": "제 126 항에 있어서,상기 액세스 맵은 RESTful API 액세스, 파일 액세스 허가 또는 바이너리 액세스 중 적어도 하나에 대한 권한 제한 사항을 포함하는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_134", "content": "제 126 항에 있어서,상기 액세스 맵은 격리 없음, 프로세스 격리, 가상 머신, 엔클레이브 또는 물리적 격리 중 적어도 하나를 포함하는 격리 레벨을 포함하는공개특허 10-2021-0149576-23-에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_135", "content": "제 126 항에 있어서,상기 오케스트레이션은 제 1 오케스트레이터로부터 제 2 오케스트레이터로의 위임에 응답하여 발생하는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_136", "content": "제 135 항에 있어서,상기 오케스트레이션은 상기 제 1 오케스트레이터로부터 상기 제 2 오케스트레이터로 전달되는 오케스트레이션정책에 따라 발생하는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_137", "content": "제 126 항에 있어서,워크로드를 상기 워크로드의 우선 순위에 기초하여 에지 노드 사이에서 그리고 더 깊은 네트워크 계층으로 이동함으로써 상기 오케스트레이터로부터 협력 오케스트레이션을 시작하는 단계를 더 포함하며, 그럼으로써 자원이액세스 가능한 에지 노드 사이에서 풀려나는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_138", "content": "제 137 항에 있어서,상기 협력 오케스트레이션은 상기 에지 컴퓨팅 시스템 내의 공유 큐(shared queue)로부터 수행되며, 상기 공유큐는 상기 에지 컴퓨팅 시스템의 상기 에지 노드 사이에서 작업 및 기능의 오케스트레이션된 실행을 조정하기위해 상기 에지 컴퓨팅 시스템 내에서 사용하도록 구성되는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_139", "content": "제 137 항에 있어서,상기 에지 노드는 분산 에지 컴퓨팅 시스템의 계층에 있는 네트워크 피어인에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_140", "content": "제 125 항에 있어서,네트워크 인터페이스 디바이스 내에서 단일 루트 입력/출력 가상화(single root input/outputvirtualization)(SR-IOV)에 의해 야기된 네트워킹 기능 변경을 사용하여 에지 컴퓨팅 시스템 내에서 오케스트레이션을 구현하는 단계를 더 포함하며, 상기 네트워킹 기능은 가상적 및 물리적 네트워크 기능 사이의 변경을 포함하는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_141", "content": "제 125 항에 있어서,오케스트레이터를 다른 오케스트레이터와 상호작용하도록 동작하는 단계 - 상기 오케스트레이터는 상기 오케스트레이터에 대응하는 지역 내의 에지 노드 사이에서 자원을 조정함 -; 공개특허 10-2021-0149576-24-상기 지역 내에서 이용 가능하지 않은 자원 요청을 식별하는 단계; 상기 다른 오케스트레이터와 조정하여 상기 자원을 요청하는 단계; 및상기 다른 오케스트레이터 중 하나로부터 자원 할당을 수신하는 단계를 더 포함하는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_142", "content": "제 141 항에 있어서,상기 자원 요청을 식별하는 단계는 상기 지역 내의 가용 자원이 임계치 미만인 것을 결정하는 단계를 포함하는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_143", "content": "제 141 항에 있어서,상기 자원 요청을 식별하는 단계는 상기 지역 내의 노드의 서비스로부터 상기 요청을 수신하는 단계를 포함하는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_144", "content": "제 141 항에 있어서,상기 오케스트레이터 및 상기 다른 오케스트레이터는 도메인의 멤버인에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_145", "content": "제 144 항에 있어서,상기 도메인은 상기 오케스트레이터 및 상기 다른 오케스트레이터에 대응하는 지역 내의 에지의 근접성에 기초하여 선택되는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_146", "content": "제 144 항에 있어서,상기 도메인은 에지 노드 유형에 기초하여 선택되는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_147", "content": "제 144 항에 있어서,상기 오케스트레이터로부터 상기 다른 오케스트레이터로, 상기 지역 내의 가용 자원을 브로드캐스팅하는 단계를더 포함하는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_148", "content": "제 144 항에 있어서,상기 지역 내에서 상기 자원의 사용이 완료될 때 상기 다른 오케스트레이터 중 하나에게 표시를 전송함으로써상기 자원을 반환하는 단계를 더 포함하는에지 컴퓨팅 환경에서 수행되는 방법.공개특허 10-2021-0149576-25-청구항 149 제 144 항에 있어서,워크로드를 상기 워크로드의 우선 순위에 기초하여 에지 노드 사이에서 그리고 더 깊은 네트워크 계층으로 이동함으로써 협력 오케스트레이션을 수행하는 단계를 더 포함하고, 그럼으로써 자원이 액세스 가능한 에지 노드 사이에서 풀리는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_150", "content": "제 148 항에 있어서,상기 에지 노드는 분산 에지 컴퓨팅 시스템의 계층에 있는 네트워크 피어인에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_151", "content": "에지 컴퓨팅 환경에서 수행되는 방법으로서,상기 에지 컴퓨팅 환경의 복수의 에지 노드를 조정 및 오케스트레이션하는 단계 - 상기 에지 노드는 다수의 테넌트 중에서 워크로드를 실행하도록 구성됨 -; 및상기 복수의 에지 노드의 자원 사이에서, 하나 이상의 에지 서비스 사이에서 각각의 워크로드의 실행을 위해,상기 에지 컴퓨팅 환경에서 연결성 동작을 제어하는 단계를 포함하는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_152", "content": "제 151 항에 있어서,서비스 조정 엔티티를 구성하는 단계 - 상기 서비스 조정 엔티티는 상기 복수의 에지 노드와 통신하는 컴퓨팅서비스를 동작함 -;상기 서비스 조정 엔티티를 사용하여, 상기 복수의 에지 노드에 송신하기 위한 하트비트 구성 정보(heartbeatconfiguration information)를 인코딩하는 단계 - 상기 하트비트 구성 정보는 디바이스 하트비트 정보의 보고를구성함 -;상기 서비스 조정 엔티티를 사용하여, 상기 하트비트 구성 정보에 기초하여 상기 복수의 에지 노드로부터 수신된 상기 디바이스 하트비트 정보를 디코딩하는 단계;상기 서비스 조정 엔티티를 사용하여, 상기 디바이스 하트비트 정보에 기초하여 상기 컴퓨팅 서비스에 연결된상기 복수의 에지 노드의 에지 노드의 수를 결정하는 단계; 및상기 결정된 수의 에지 노드에 기초하여, 상기 컴퓨팅 서비스에 대한 디바이스 연결성을 나타내는 통지를 생성하는 단계를 더 포함하는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_153", "content": "제 152 항에 있어서,상기 컴퓨팅 서비스에 연결된 상기 에지 노드의 수가 임계 수 미만일 때 상기 통지를 생성하는 단계를 더 포함하는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_154", "content": "제 152 항에 있어서,공개특허 10-2021-0149576-26-상기 복수의 에지 노드 중 적어도 하나의 에지 노드로부터 수신된 상기 디바이스 하트비트 정보는 상기 데이터패킷이 상기 적어도 하나의 에지 노드에 의해 송신되는 송신 시간을 나타내는 데이터 패킷을 포함하는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_155", "content": "제 154 항에 있어서,송신 시간 및 상기 데이터 패킷이 상기 서비스 조정 엔티티에 의해 수신되는 시간에 기초하여 상기 적어도 하나의 에지 노드와 상기 서비스 조정 엔티티 사이의 통신 대기시간을 결정하는 단계; 및적어도 상기 결정된 통신 대기시간에 기초하여 상기 통지를 생성하는 단계를 더 포함하는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_156", "content": "제 152 항에 있어서,상기 디바이스 하트비트 정보는 상기 복수의 에지 노드 각각에 대한 디바이스 위치 정보를 포함하는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_157", "content": "제 156 항에 있어서,상기 디바이스 위치 정보는 상기 서비스 조정 엔티티에 관한 또는 상기 복수의 에지 노드 및 상기 서비스 조정엔티티와 통신 가능하게 결합된 기지국에 관한 위치 정보를 포함하는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_158", "content": "제 157 항에 있어서,상기 하트비트 구성 정보는 상기 디바이스 하트비트 정보를 보고하는 빈도를 구성하는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_159", "content": "제 156 항에 있어서,상기 컴퓨팅 서비스와 연관된 지오-펜스(geo-fence)를 구성하는 단계를 더 포함하는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_160", "content": "제 159 항에 있어서,상기 디바이스 하트비트 정보에 기초하여, 상기 구성된 지오-펜스 외부에 있는 상기 복수의 에지 노드의 에지노드의 수를 결정하는 단계; 및상기 구성된 지오-펜스 외부에 있는 적어도 상기 결정된 수의 에지 노드에 기초하여 상기 통지를 생성하는 단계를 더 포함하는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_161", "content": "제 152 항에 있어서,상기 서비스 조정 엔티티는 상기 컴퓨팅 서비스를 상기 서비스 조정 엔티티의 가상화 인프라스트럭처상에서 인공개특허 10-2021-0149576-27-스턴스화된 MEC 애플리케이션으로서 실행하는 다중 액세스 에지 컴퓨팅(Multi-Access Edge Computing)(MEC) 호스트인에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_162", "content": "제 161 항에 있어서,상기 MEC 호스트는 ETSI(European Telecommunications Standards Institute) MEC 표준 제품군의 표준에 따라동작하도록 구성되는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_163", "content": "제 152 항에 있어서,상기 에지 노드는 분산 에지 컴퓨팅 시스템의 계층에 있는 네트워크 피어인에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_164", "content": "제 151 항에 있어서,요청자 디바이스에 대한 위치 이동 정보를 획득하는 단계 - 상기 요청자 디바이스는 모바일 무선 네트워크의 제1 기지국을 통해 동작하는 에지 컴퓨팅 서비스에 연결됨 -;예측 모델을 사용하여, 상기 모바일 무선 네트워크의 하나 이상의 다른 기지국 사이에서 상기 요청자 디바이스의 추정된 위치 예측을 생성하는 단계 - 상기 하나 이상의 다른 기지국은 상기 에지 컴퓨팅 서비스를 동작할 수있음 -; 및상기 요청자 디바이스의 상기 추정된 위치 예측을 사용하여, 상기 에지 컴퓨팅 서비스의 데이터를 식별하고 상기 제 1 기지국으로부터 상기 하나 이상의 다른 기지국으로 포워딩하는 단계를 더 포함하는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_165", "content": "제 164 항에 있어서,상기 에지 컴퓨팅 서비스의 상기 데이터는 서비스 상태 데이터이며, 상기 서비스 상태 데이터는 상기 요청자 디바이스의 실제 이동 전에 상기 하나 이상의 다른 기지국에 제공되는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_166", "content": "제 164 항에 있어서,상기 예측 모델은 상기 요청자 디바이스의 이동 궤적, 상기 요청자 디바이스 또는 상기 에지 컴퓨팅 서비스와연관된 이전 이력, 또는 상기 요청자 디바이스 또는 상기 모바일 무선 네트워크와 연관된 매핑된 경로에 기초하여 상기 추정된 위치 예측을 추론하도록 훈련되는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_167", "content": "제 164 항에 있어서,상기 추정된 위치 예측은 상기 하나 이상의 다른 기지국 사이에서 예측된 이동 시퀀스를 포함하는에지 컴퓨팅 환경에서 수행되는 방법.공개특허 10-2021-0149576-28-청구항 168 제 167 항에 있어서,상기 추정된 위치 예측은 음의 확률(negative probability)에 기초하고, 상기 음의 확률은 상기 하나 이상의 다른 기지국 사이에서 상기 예측된 이동 시퀀스를 상기 요청자 디바이스가 따르지 않을 확률인에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_169", "content": "제 168 항에 있어서,상기 자원은 상기 음의 확률에 기초하여 상기 하나 이상의 다른 기지국 사이에서 풀리는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_170", "content": "제 164 항에 있어서,상기 추정된 위치 예측은 상기 하나 이상의 다른 기지국 사이에서 상기 요청자 디바이스의 상기 예측된 이동 시간을 표시하며, 상기 데이터의 상기 식별 및 포워딩은 상기 요청자 디바이스의 예측된 이동 시간에 기초하여 발생하는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_171", "content": "제 164 항에 있어서,상기 에지 컴퓨팅 서비스의 상기 데이터의 상기 식별 및 포워딩은 상기 요청자 디바이스의 이동에 앞서, 상기하나 이상의 다른 기지국 사이에 위치한 가속기 회로를 사전 프로그램하는 데 사용되는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_172", "content": "제 164 항에 있어서,상기 예측 모델은 궤적 벡터에 기초하여 훈련된 머신 학습 모델이며, 상기 궤적 벡터는 요청 디바이스 및 서비스 기지국으로부터의 훈련 데이터와 연관되는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_173", "content": "제 164 항에 있어서,상기 위치 이동 정보는 상기 제 1 기지국을 통해 동작하는 상기 에지 컴퓨팅 서비스의 사용량으로부터 생성된원격 측정 정보를 포함하는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_174", "content": "제 164 항에 있어서,상기 복수의 에지 노드 사이에서 서비스로서의 보안 기능(security-as-a-service function)을 사용하여 신뢰성있는 암호화 동작을 생성 및 설정하는 단계를 더 포함하는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_175", "content": "공개특허 10-2021-0149576-29-에지 컴퓨팅 환경에서 수행되는 방법으로서,상기 에지 컴퓨팅 환경의 복수의 에지 노드를 조정 및 오케스트레이션하는 단계 - 상기 복수의 에지 노드는 다수의 테넌트 중에서 워크로드를 실행하도록 구성됨 -; 및상기 복수의 에지 노드의 자원 사이에서, 하나 이상의 에지 서비스 사이에서 각각의 워크로드의 실행을 위해,상기 에지 컴퓨팅 환경에서 가속 동작을 제어하는 단계를 포함하는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_176", "content": "제 175 항에 있어서,가속 기능을 호출하는 워크로드를 수신하는 단계; 각각의 에지 컴퓨트 노드로, 상기 각각의 에지 컴퓨트 노드의 가속 기능에 의한 병렬 실행을 위해 워크로드의데이터를 분배하는 단계; 및상기 가속 기능에 의한 분산 실행의 결과를 수집하는 단계를 더 포함하는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_177", "content": "제 176 항에 있어서,상기 동일한 유형의 가속 기능이 각각의 에지 컴퓨트 노드의 상기 가속 기능에 의해 사용되는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_178", "content": "제 177 항에 있어서,상기 워크로드는 또한 적어도 하나의 다른 에지 컴퓨트 노드의 제 2 유형의 가속 기능에 의한 실행을 호출하는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_179", "content": "제 176 항에 있어서,상기 각각의 에지 컴퓨트 노드의 상기 가속 기능은, FPGA, ASIC, GPU 어레이, AI 가속기, 트랜스코딩 가속기 또는 암호화 가속기 하드웨어 중 적어도 하나에 의해 실행되는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_180", "content": "제 176 항에 있어서,상기 워크로드는 제 1 서비스로서의 기능을 호출하는 제 1 워크로드 및 제 2 서비스로서의 기능을 호출하는 제2 워크로드를 포함하는 워크로드 세트이고, 상기 제 1 및 제 2 서비스로서의 기능은 상기 각각의 에지 노드 사이에서 제공되는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_181", "content": "제 176 항에 있어서,상기 워크로드는 에지 클라이언트 노드로부터 수신되는에지 컴퓨팅 환경에서 수행되는 방법.공개특허 10-2021-0149576-30-청구항 182 제 181 항에 있어서,상기 에지 클라이언트 노드는 주어진 SLA 및 주어진 비용에 따라 실행될 상기 워크로드를 명시하는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_183", "content": "제 181 항에 있어서,상기 에지 클라이언트 노드로, 상기 가속 기능에 의한 상기 분산 실행의 수집된 결과를 제공하는 단계를 더 포함하는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_184", "content": "제 176 항에 있어서,상기 에지 컴퓨팅 시스템 내의 가속 기능은 각각의 가속 워크로드 설명 내에 표시되는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_185", "content": "제 176 항에 있어서,상기 방법은 에지 게이트웨이 노드에서 수행되는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_186", "content": "제 176 항에 있어서,워크로드를 상기 워크로드의 우선 순위에 기초하여 에지 노드 사이에서 그리고 더 깊은 네트워크 계층으로 이동함으로써 협력 오케스트레이션을 수행하는 단계를 더 포함하며, 그럼으로써 자원이 액세스 가능한 에지 노드 사이에서 풀려나는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_187", "content": "제 186 항에 있어서,상기 협력 오케스트레이션은 상기 에지 컴퓨팅 시스템 내의 공유 큐(shared queue)로부터 수행되고, 상기 공유큐는 상기 에지 컴퓨팅 시스템의 상기 에지 노드 사이에서 작업 및 기능의 오케스트레이션된 실행을 조정하기위해 상기 에지 컴퓨팅 시스템 내에서 사용하도록 구성되는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_188", "content": "제 187 항에 있어서,상기 에지 노드는 분산 에지 컴퓨팅 시스템의 계층에 있는 네트워크 피어인에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_189", "content": "에지 컴퓨팅 환경에서 수행되는 방법으로서,상기 에지 컴퓨팅 환경의 복수의 에지 노드 중 하나에서 호스팅되는 에지 서비스의 하나 이상의 특징을 식별하공개특허 10-2021-0149576-31-는 단계 - 상기 에지 노드는 다수의 테넌트 중에서 워크로드를 실행하도록 구성됨 -; 및상기 에지 서비스에 대해 실행된 하나 이상의 워크로드 또는 상기 에지 서비스에 대해 설정된 증명과 관련하여,상기 에지 서비스의 상기 특징과 함께 사용되는 하드웨어 자원을 관리하는 단계를 포함하는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_190", "content": "제 189 항에 있어서,에지 컴퓨팅 시스템의 노드의 네트워크 인터페이스 제어기(NIC)의 호스트 대면 인터페이스(host facinginterface)에서, 상기 노드에서 이용 가능한 인공 지능(artificial intelligence)(AI) 에지 서비스의 등록을수신하는 단계 - 상기 등록은 상기 서비스에 입력하기 위한 메모리 영역을 포함함 -;상기 NIC의 네트워크 대면 인터페이스에서, 상기 NIC의 상기 AI 서비스에 대한 요청을 수신하는 단계; 및상기 요청으로부터의 상기 입력 데이터를 상기 메모리 영역에 배치하는 단계를 더 포함하는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_191", "content": "제 190 항에 있어서,상기 요청으로부터의 상기 입력 데이터를 상기 메모리 영역에 배치하는 단계는 상기 AI 서비스를 호출하는 단계를 포함하는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_192", "content": "제 190 항에 있어서,상기 NIC에 의해, 다른 노드의 다른 NIC로부터 서비스의 카탈로그를 요청하는 단계; 및상기 NIC에 의해, 제 2 노드에서 상기 AI 서비스의 다른 인스턴스를 기록하는 단계를 더 포함하는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_193", "content": "제 192 항에 있어서,네트워크 대면 인터페이스의 상기 NIC에 의해, 상기 AI 서비스에 대한 제 2 요청을 수신하는 단계; 및상기 제 2 요청을 처리를 위해 제 2 노드로 포워딩하는 단계를 더 포함하는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_194", "content": "제 193 항에 있어서,상기 제 2 요청은 상기 제 2 노드에서 상기 요청의 예측 완료 시간에 기초하여 상기 제 2 노드로 포워딩되는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_195", "content": "제 190 항에 있어서,네트워크 보안 분석 및 모니터링을 위한 머신 학습 모델이 상기 에지 컴퓨팅 시스템의 각각의 노드의 네트워크장비 내의 패킷 처리 파이프라인의 데이터에 배치되는에지 컴퓨팅 환경에서 수행되는 방법.공개특허 10-2021-0149576-32-청구항 196 제 189 항에 있어서,지능형 네트워크 인터페이스 제어기(intelligent network interface controller)(iNIC)에서, 상기 에지 서비스와 관련하여 제공되는 생체측정 인증 요청을 수신하는 단계;상기 iNEC에 의해, 풀링된 스토리지 제어기(pooled storage controller)로부터, 상기 요청에 대응하는 생체측정데이터를 검색하는 단계;상기 iNIC에 의해, 상기 생체측정 데이터를 상기 요청 내의 데이터와 비교하여 생체측정 인증을 수행하는 단계;및상기 iNIC에 의해, 상기 생체측정 인증을 포함하는 상기 요청에 대한 응답을 송신하는 단계를 더 포함하는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_197", "content": "제 196 항에 있어서,상기 풀링된 스토리지 제어기로부터 상기 생체측정 데이터를 검색하는 단계는 상기 풀링된 스토리지 제어기에의해, 상기 생체측정 데이터에 대한 로컬 캐시를 검색하는 단계를 포함하며, 상기 로컬 캐싱은 상기 계층의 하위 레벨이 에지 노드에 더 가까운 캐시 계층의 일부인에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_198", "content": "제 197 항에 있어서,상기 생체측정 인증 요청은 상기 생체측정 데이터가 하위 레벨 디바이스의 로컬 캐싱에 없다는 것에 응답하여상기 계층의 상기 하위 레벨 디바이스로부터 수신되는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_199", "content": "제 198 항에 있어서,상기 생체측정 데이터를 상기 응답과 함께 상기 하위 레벨 디바이스로 송신하여 상기 하위 레벨 디바이스에서상기 생체측정 데이터를 캐싱할 수 있게 하는 단계를 더 포함하는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_200", "content": "제 189 항에 있어서,정의된 서비스 레벨 협약(SLA)에 따라 에지 컴퓨팅 시스템에서 워크로드를 처리하기 위한 에지 컴퓨트 자원의특성을 식별하는 단계;상기 SLA를 충족하는 데 필요한 호스팅 환경 속성 및 제약 조건을 상기 에지 컴퓨팅 시스템의 가용 호스팅 환경속성 및 제약 조건과 비교하는 단계 - 상기 속성 및 제약 조건은 상기 워크로드를 처리하기 위해 식별된 상기특성으로부터 획득됨 -; 및상기 비교에 기초하여, 상기 에지 컴퓨팅 시스템의 제 1 에지 노드로부터 제 2 에지 노드로 상기 워크로드의 마이그레이션을 수행하는 단계를 더 포함하며, 상기 비교는 상기 제 1 에지 노드가 상기 워크로드에 대한 상기SLA를 충족할 수 없다는 인식 또는 예측을 생성하는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_201", "content": "공개특허 10-2021-0149576-33-제 200 항에 있어서,상기 마이그레이션은 상기 에지 컴퓨팅 시스템의 네트워크 내에서, 상기 네트워크의 레벨에서 동-서(east-west)로 노드에서 노드로(node-to-node)의 이동에 기초하여 발생하는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_202", "content": "제 200 항에 있어서,상기 마이그레이션은 상기 에지 컴퓨팅 시스템의 네트워크 내에서, 상기 네트워크의 상이한 레벨에서 북-남(north-south)으로 노드에서 노드로의 이동에 기초하여 발생하는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_203", "content": "제 200 항에 있어서,상기 SLA를 상기 제 2 에지 노드의 특성에 동적으로 적응시키는 단계를 더 포함하며, 상기 제 2 에지 노드는 상기 워크로드에 대해 상기 적응된 SLA를 충족하도록 구성되는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_204", "content": "제 200 항에 있어서,상기 호스팅 환경 속성 및 제약 조건은 상기 워크로드를 활용하는 클라이언트 컴퓨팅 디바이스의 이동성으로 인해 변경되고, 상기 클라이언트 컴퓨팅 디바이스는 상기 에지 컴퓨팅 시스템 내의 컴퓨팅 노드의 상이한 지리적서비스 영역 사이에서 이동하는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_205", "content": "제 200 항에 있어서,상기 마이그레이션의 유형, 수량 또는 속도는 상기 워크로드에 의해 호출된 서비스 유형 또는 상기 워크로드의특성에 기초하는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_206", "content": "제 200 항에 있어서,상기 워크로드에 대한 상기 SLA는 글로벌 SLA의 서브세트이고, 상기 글로벌 SLA는 상기 에지 컴퓨팅 시스템의노드 사이에 분산된 복수의 워크로드에 대해 정의되는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_207", "content": "제 200 항에 있어서,외부 입력, 조건, 메트릭, 원격 측정 또는 에지 컴퓨팅 시스템 내 데이터에 기초하여, 상기 SLA 또는 상기 SLA의 하나 이상의 서비스 레벨 목표(service level objective)를 동적으로 조정하는 단계를 더 포함하는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_208", "content": "제 200 항에 있어서,공개특허 10-2021-0149576-34-상기 에지 컴퓨팅 시스템의 상기 노드 사이에서 상기 워크로드의 실행은 상기 노드 사이에서 전달되는 실행 토큰의 사용에 기초하고, 상기 실행 토큰은 특정 노드의 상기 워크로드의 적어도 일부를 조정하고 수행하는 데 사용되는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_209", "content": "제 200 항에 있어서,상기 에지 컴퓨팅 시스템의 각각의 에지 노드에 의해 처리하는 데 이용 가능한 컴퓨테이션 자원에 기초하여, 상기 SLA의 변경 및 상기 에지 컴퓨팅 시스템의 상기 각각의 에지 노드에 상기 SLA와 상기 워크로드의 추가 할당을 수행하는 단계를 더 포함하는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_210", "content": "제 209 항에 있어서,상기 에지 노드는 분산 에지 컴퓨팅 시스템의 계층에 있는 네트워크 피어인에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_211", "content": "제 189 항에 있어서,상기 에지 서비스와 연관된 테넌트 워크로드 환경에 대한 실행 컨텍스트를 획득하는 단계 - 상기 실행 컨텍스트는 서비스 레벨 협약(SLA) 파라미터에 의해 정의됨 -;상기 실행 컨텍스트에 대한 증명 키를 획득하는 단계;상기 테넌트 워크로드 환경 및 상기 증명 키를 사용하여 컴포넌트 디바이스 아이덴티티(component deviceidentity)(CDI)를 계산하는 단계;상기 테넌트 워크로드 환경에서 워크로드를 수행하여 결과를 생성하는 단계 - 상기 결과는 상기 SLA 파라미터의성능 메트릭을 포함함 -; 상기 결과를 상기 CDI로 서명하는 단계; 및상기 서명된 결과를 상기 워크로드의 요청자에게 전송하는 단계를 더 포함하는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_212", "content": "제 211 항에 있어서,상기 CDI는 상기 워크로드를 수행하는 계층과 상이한 계층에서 연산되는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_213", "content": "제 211 항에 있어서,상기 성능 메트릭은 상기 SLA 파라미터가 수신자에 의해 구별되는 것을 방지하기 위해 정규화되는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_214", "content": "제 211 항에 있어서,공개특허 10-2021-0149576-35-상기 테넌트 워크로드 환경은 신뢰성 있는 컴퓨팅 기반(trusted computing base)(TCB)인에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_215", "content": "제 211 항에 있어서,상기 테넌트 워크로드 환경에 의해 제공되는 에지 서비스의 각각의 결과는 상기 에지 서비스에 제공되는 데이터의 소스의 검증 가능한 증명 및 상기 에지 서비스에 의해 생성되는 상기 데이터의 결과에 기초하여 증명될 수있는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_216", "content": "제 189 항에 있어서,에지 네트워크의 오케스트레이터 노드로부터 서비스 레벨 협약(SLA), 비트스트림 및 워크로드를 수신하는 단계;상기 비트스트림을 상기 워크로드에 적용하여 출력을 생성하는 단계;상기 워크로드에 증명 기능을 적용하는 단계;상기 워크로드에 상기 증명 기능을 적용하는 것에 기초하여 상기 오케스트레이터 노드로 검증 요청을 전송하는단계; 및상기 오케스트레이터 노드로부터 긍정적인 검증 응답의 수신에 기초하여 상기 출력을 테넌트 노드로 송신하는단계를 더 포함하는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_217", "content": "제 216 항에 있어서,상기 증명 기능을 사용하여 상기 워크로드에 서명하는 단계를 더 포함하는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_218", "content": "제 216 항에 있어서,상기 비트스트림은 커리 함수인에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_219", "content": "제 216 항에 있어서,상기 증명 기능은 필드 프로그램 가능 게이트 어레이에 내장되는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_220", "content": "제 216 항에 있어서,상기 증명 기능은 비트스트림으로서 동적으로 로드되고 필드 프로그램 가능 게이트 어레이의 계층 아키텍처를사용하는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_221", "content": "공개특허 10-2021-0149576-36-제 216 항에 있어서, 상기 방법은 에지 서비스에 의해 수행되고, 상기 에지 서비스의 결과는 상기 에지 서비스에 제공되는 데이터의소스의 검증 가능한 증명 및 상기 에지 서비스에 의해 생성되는 상기 데이터의 결과에 기초하여 증명될 수 있는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_222", "content": "제 216 항에 있어서,상기 오케스트레이터 노드는 워크로드를 상기 워크로드의 우선 순위에 기초하여 에지 노드 사이에서 그리고 더깊은 네트워크 계층으로 이동함으로써 협력 오케스트레이션을 수행하고, 그럼으로써 자원이 액세스 가능한 에지노드 사이에 풀리는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_223", "content": "제 222 항에 있어서,상기 협력 오케스트레이션은 상기 에지 컴퓨팅 시스템 내의 공유 큐로부터 수행되고, 상기 공유 큐는 상기 에지컴퓨팅 시스템의 상기 에지 노드 사이에서 작업 및 기능의 오케스트레이션된 실행을 조정하기 위해 상기 에지컴퓨팅 시스템 내에서 사용하도록 구성되는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_224", "content": "제 216 항에 있어서,상기 에지 노드는 분산 에지 컴퓨팅 시스템의 계층에 있는 네트워크 피어인에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_225", "content": "제 189 항에 있어서,디바이스로부터, 에지 아키텍처의 에지 서비스에 관한 정보에 대한 쿼리를 수신하는 단계; 상기 쿼리에 응답하여, 마스터 에지 노드에서, 저장소(repository) 내의 에지 증명 네임 서비스(EdgeAttestation Name Service) 데이터에 액세스하는 단계; 및 상기 쿼리에 대한 응답을 상기 디바이스로 전송하는 단계를 더 포함하고, 상기 응답은 상기 서비스에 대한 증명데이터 및 상기 서비스를 제공하는 에지 노드의 어드레스 또는 네임 중 적어도 하나를 포함하는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_226", "content": "제 225 항에 있어서,상기 디바이스 및 상기 마스터 에지 노드는 상기 에지 아키텍처 내에서 레벨을 공유하는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_227", "content": "제 225 항에 있어서,상기 서비스를 제공하는 상기 에지 노드는 상기 에지 아키텍처 내의 상기 마스터 에지 노드와 상이한 가상 도메인에 있는에지 컴퓨팅 환경에서 수행되는 방법.공개특허 10-2021-0149576-37-청구항 228 제 227 항에 있어서,상기 EANS 데이터에 액세스하는 단계는 상기 에지 아키텍처의 하위 레벨상의 제 2 마스터 에지 노드를 식별하는단계를 포함하고, 상기 서비스에 대한 상기 증명 데이터 및 상기 제 2 마스터 에지 노드로부터의 상기 어드레스또는 상기 네임 중 적어도 하나를 수신하는 단계를 더 포함하는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_229", "content": "제 225 항에 있어서,상기 응답은 상기 서비스에 대한 모니터링된 정보의 인증 또는 전파를 포함하는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_230", "content": "제 225 항에 있어서,상기 응답은 상기 서비스를 제공하는 상기 에지 노드에 대한 위치 정보를 포함하는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_231", "content": "제 225 항에 있어서,상기 증명 데이터는 상기 마스터 에지 노드의 상기 저장소에 저장되는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_232", "content": "제 225 항에 있어서,상기 방법은 에지 게이트웨이 노드에서 또는 이를 대신하여 수행되는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_233", "content": "제 225 항에 있어서,상기 에지 서비스의 결과는 상기 에지 서비스에 제공되는 데이터의 소스의 검증 가능한 증명 및 상기 에지 서비스에 의해 생성되는 상기 데이터의 결과에 기초하여 증명될 수 있는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_234", "content": "제 225 항에 있어서,상기 방법은 오케스트레이터에서 또는 그를 대신하여 수행되며, 상기 오케스트레이터는 워크로드를 상기 워크로드의 우선 순위에 기초하여 에지 노드 사이에서 그리고 더 깊은 네트워크 계층으로 이동함으로써 협력 오케스트레이션을 수행하고, 그럼으로써 자원이 액세스 가능한 에지 노드 사이에서 풀리는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_235", "content": "제 234 항에 있어서,상기 협력 오케스트레이션은 상기 에지 컴퓨팅 시스템 내의 공유 큐로부터 수행되고, 상기 공유 큐는 상기 에지공개특허 10-2021-0149576-38-컴퓨팅 시스템의 상기 에지 노드 사이에서 작업 및 기능의 오케스트레이션된 실행을 조정하기 위해 상기 에지컴퓨팅 시스템 내에서 사용하도록 구성되는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_236", "content": "제 234 항에 있어서,상기 에지 노드는 분산 에지 컴퓨팅 시스템의 계층에 있는 네트워크 피어인에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_237", "content": "제 190 항에 있어서,에지 컴퓨팅 시스템의 에지 노드에서, 상기 에지 컴퓨팅 시스템 내의 자원을 로드 밸런싱하기 위해 사용되는 복수의 모드를 식별하는 단계;에지 노드에서, 오케스트레이터와 연관된 모드 구성기(mode configurator)로부터, 자원을 로드 밸런싱하기 위한상기 복수의 모드로부터 선택된 모드의 표시를 수신하는 단계; 및자원을 로드 밸런싱하기 위한 상기 선택된 모드에 기초하여, 상기 에지 노드에서 상기 자원 사용에 대한 변경사항을 구현하는 단계를 더 포함하는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_238", "content": "제 237 항에 있어서,상기 선택된 모드의 상기 표시는 상기 오케스트레이터로부터, 상기 에지 노드의 구성을 상기 선택된 모드로 스위칭하라는 커맨드에서 수신되는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_239", "content": "제 237 항에 있어서,상기 오케스트레이터로부터, 상기 복수의 모드에 대한 각각의 파라미터 및 시스템 구성을 수신하는 단계를 더포함하는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_240", "content": "제 237 항에 있어서,상기 선택된 모드의 상기 표시는 상기 오케스트레이터로부터 결정되고, 상기 오케스트레이터는 원격 측정 데이터에 대해 머신 학습을 활용하여 상기 복수의 모드 사이에서 사용하기 위한 타이밍을 예측하는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_241", "content": "제 237 항에 있어서,상기 에지 노드에서, 동작을 위해 상기 복수의 모드에 매핑되는 파라미터 및 시스템 구성을 식별하는 단계를 더포함하는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_242", "content": "공개특허 10-2021-0149576-39-제 237 항에 있어서,상기 에지 노드를 이전의 동작 모드로부터 동작을 위해 상기 선택된 모드로 동적으로 변경하는 단계를 더 포함하는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_243", "content": "제 242 항에 있어서,상기 동적 변경에 기초하여, 상기 에지 컴퓨팅 시스템의 제 1 부분은 자원을 로드 밸런싱하기 위해 상기 선택된모드를 활용하도록 적응되고, 상기 에지 컴퓨팅 시스템의 제 2 부분은 자원을 로드 밸런싱하기 위한 다른 모드를 활용하도록 적응되는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_244", "content": "제 237 항에 있어서,상기 모드는, 컴퓨트 노드와 가속기의 연결 또는 연결 해제, 코어의 사용, 에지 서비스에 대해 제공되는 인스턴스의 수, 또는 캐시 할당 파라미터 중 하나 이상에서의 변동을 명시하는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_245", "content": "제 237 항에 있어서,상기 모드는 정의된 대기시간 백분위수(latency percentile)에 따라 처리량에 대한 각각의 정의를 제공하는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_246", "content": "제 237 항에 있어서,상기 로드 밸런싱은 스위치, 플랫폼, 슬레드 또는 오케스트레이터 시스템에서 식별된 구성 정보에 기초하여 상기 에지 노드 내에서 구현되는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_247", "content": "제 237 항에 있어서,상기 오케스트레이터는 워크로드를 상기 워크로드의 우선 순위에 기초하여 에지 노드 사이에서 그리고 더 깊은네트워크 계층으로 이동함으로써 협력 오케스트레이션을 수행하고, 그럼으로써 자원이 액세스 가능한 에지 노드사이에서 풀리는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_248", "content": "제 237 항에 있어서,상기 오케스트레이터는 워크로드를 상기 워크로드의 우선 순위에 기초하여 에지 노드 사이에서 그리고 더 깊은네트워크 계층으로 이동함으로써 협력 오케스트레이션을 수행하고, 그럼으로써 자원이 액세스 가능한 에지 노드사이에서 풀리는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_249", "content": "공개특허 10-2021-0149576-40-제 248 항에 있어서,상기 에지 노드는 분산 에지 컴퓨팅 시스템의 계층에 있는 네트워크 피어인에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_250", "content": "에지 컴퓨팅 환경에서 수행되는 방법으로서, 상기 에지 컴퓨팅 환경의 복수의 에지 노드에 의해 실행될 다수의 테넌트 중에서 제공되는 워크로드에 대해, 하나 이상의 클라이언트 컴퓨팅 디바이스로부터 하나 이상의 워크로드를 식별하는 단계; 및상기 하나 이상의 클라이언트 컴퓨팅 디바이스로부터 상기 워크로드의 실행을 조정하는 단계를 포함하는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_251", "content": "제 250 항에 있어서,상기 에지 컴퓨팅 환경에서 에지 네트워크의 서비스 제공자와 통신 가능하게 결합된 클라이언트 컴퓨팅 디바이스로부터 컴퓨팅 자원 요청에 대한 승인 응답을 수신하는 단계;상기 승인을 수신할 때 상기 클라이언트 컴퓨팅 디바이스상에서 보안 소프트웨어 실행 모듈을 생성하는 단계;상기 서비스 제공자에 의해 수행될 워크로드를 식별하는 단계;상기 워크로드를 상기 보안 소프트웨어 실행 모듈상에서 실행을 위해 송신하는 단계; 및상기 실행의 결과를 상기 서비스 제공자의 에지 노드로 송신하는 단계를 더 포함하는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_252", "content": "제 251 항에 있어서,상기 보안 소프트웨어 실행 모듈을 소프트웨어 실행 모듈의 풀에 추가하는 단계; 상기 워크로드를 작업 유닛으로 분할하는 단계; 및상기 작업 유닛을 상기 소프트웨어 실행 모듈의 상기 풀의 각각의 소프트웨어 실행 모듈로 전송하는 단계를 더포함하고, 상기 보안 소프트웨어 실행 모듈상에서 실행을 위한 상기 워크로드를 송신하는 단계는 상기 작업 유닛의 제 1 작업 유닛을 상기 보안 소프트웨어 실행 모듈로 송신하는 단계를 포함하는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_253", "content": "제 251 항에 있어서,상기 보안 소프트웨어 실행 모듈을 사용하여 상기 워크로드의 실행을 위한 값을 계산하는 단계; 및상기 클라이언트 컴퓨팅 디바이스에 대응하는 사용자 계정에 상기 값을 적립하는 단계를 더 포함하는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_254", "content": "제 251 항에 있어서,상기 서비스 제공자에 의해 제공되고 상기 컴퓨팅 자원 요청에서 제공되는 서비스를 식별하는 단계; 및상기 워크로드 실행시 상기 클라이언트 컴퓨팅 디바이스에서 상기 서비스를 실시 가능하게 하는 단계를 더 포함하는공개특허 10-2021-0149576-41-에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_255", "content": "제 251 항에 있어서,상기 보안 소프트웨어 실행 모듈이 상기 워크로드를 실행하는 데 이용할 수 있는 시간 윈도우를 식별하는 단계;및상기 시간 윈도우 동안 상기 워크로드를 상기 보안 소프트웨어 실행 모듈로 송신하는 단계를 더 포함하는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_256", "content": "제 251 항에 있어서,상기 클라이언트 컴퓨팅 디바이스는 상기 에지 네트워크에 연결된 셀룰러 기지국을 통해 상기 서비스 제공자에통신 가능하게 결합되는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_257", "content": "제 251 항에 있어서,상기 클라이언트 컴퓨팅 디바이스는 상기 에지 네트워크에 연결된 네트워크 라우터를 통해 상기 서비스 제공자에 통신 가능하게 결합되는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_258", "content": "제 251 항에 있어서,상기 에지 컴퓨팅 시스템 내에서 서비스로서의 보안 기능(security-as-a-service function)을 사용하여 신뢰성있는 암호화 동작을 생성 및 설정하는 단계를 더 포함하는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_259", "content": "제 250 항에 있어서,상기 에지 노드에서, 복수의 모바일 클라이언트 컴퓨팅 디바이스로부터 데이터를 수신하는 단계;상기 수신된 데이터를 에지 노드의 집계 로직을 사용하여 집계하는 단계;상기 에지 노드에서 상기 집계된 데이터 및 집계 함수에 기초하여 값을 생성하는 단계; 및 상기 값을 클라우드 컴퓨팅 시스템으로 전송하는 단계를 더 포함하는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_260", "content": "제 259 항에 있어서,상기 수신된 데이터를 집계하는 단계는 상기 수신된 데이터를 간격에 걸쳐 집계하는 단계를 포함하는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_261", "content": "제 260 항에 있어서,공개특허 10-2021-0149576-42-상기 간격은 시간 간격, 수신될 데이터의 명시된 양, 또는 데이터를 수신할 명시된 수의 디바이스를 포함하는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_262", "content": "제 259 항에 있어서,상기 값은 나중에 수신된 데이터를 검증하는 데 사용되는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_263", "content": "제 259 항에 있어서,상기 값은 영역의 상세한 지도를 생성하는 데 사용되는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_264", "content": "제 259 항에 있어서,상기 값은 모바일 클라이언트 컴퓨팅 디바이스의 기능을 검증하는 데 사용되는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_265", "content": "제 259 항에 있어서,상기 값은 사용 데이터를 생성하거나, 피드백을 제공하거나 또는 보안 설정에서 사용되는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_266", "content": "제 259 항에 있어서,상기 수신된 데이터의 신뢰도 레벨(trustworthiness level)을 결정하는 단계를 더 포함하는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_267", "content": "제 266 항에 있어서,상기 값을 출력하는 단계를 더 포함하는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_268", "content": "제 267 항에 있어서,상기 값을 출력하는 단계는 상기 신뢰도 레벨을 출력하는 단계를 포함하는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_269", "content": "제 259 항에 있어서,상기 수신된 데이터를 집계하는 단계는 상기 수신된 데이터의 상기 신뢰도를 사용하는 단계를 포함하는에지 컴퓨팅 환경에서 수행되는 방법.공개특허 10-2021-0149576-43-청구항 270 제 250 항에 있어서,제 1 에지 노드의 서버 인스턴스에서 동작하는 서비스의 데이터를 캡처하는 단계 - 상기 데이터는 상기 서비스에 의해 소비되거나 생성되는 데이터와 관련됨 -;상기 서비스의 상기 데이터를 상기 제 1 에지 노드로부터 제 2 에지 노드의 서버 인스턴스로 복제하는 단계 -상기 제 2 에지 노드의 상기 서버 인스턴스는 비 실행 상태의 상기 서비스의 백업 인스턴스를 가짐 -; 및상기 제 1 에지 노드에서 안정성 문제(reliability issue)를 식별할 때, 상기 제 2 에지 노드상의 상기 서비스의 상기 백업 인스턴스에게 실행 상태에 진입하도록 지시하는 단계를 더 포함하고, 상기 실행 상태는 상기 복제된 데이터를 활용하는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_271", "content": "제 270 항에 있어서,상기 방법의 동작은 상기 제 1 에지 노드에서 동작하는 안정성 관리 유닛에 의해 수행되는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_272", "content": "제 271 항에 있어서,상기 안정성 관리 유닛은 네트워크 인터페이스 카드의 회로 또는 상기 제 1 에지 노드와의 통신을 제공하는 스위치에 의해 동작되는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_273", "content": "제 271 항에 있어서,상기 제 2 에지 노드상에서 상기 서비스를 제어하기 위한 동작은 상기 제 2 에지 노드에서 동작하는 제 2 안정성 관리 유닛에 의해 수행되고, 상기 제 2 안정성 관리 유닛은 상기 데이터를 상기 서비스의 상기 백업 인스턴스에 제공하고 상기 서비스 백업 인스턴스의 상기 실행 상태를 제어하는 데 사용되는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_274", "content": "제 271 항에 있어서,상기 안정성 관리 유닛은 에지 컴퓨팅 게이트웨이에서 동작하는 오케스트레이터의 제어 하에 있는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_275", "content": "제 274 항에 있어서,워크로드를 상기 워크로드의 우선 순위에 기초하여 에지 노드 사이에서 그리고 더 깊은 네트워크 계층으로 이동함으로써 협력 오케스트레이션을 수행하는 단계를 더 포함하고, 그럼으로써 자원이 액세스 가능한 에지 노드 사이에서 풀리는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_276", "content": "제 274 항에 있어서,공개특허 10-2021-0149576-44-상기 제 2 에지 노드에서 제 2 안정성 관리 유닛은 상기 복제된 데이터를 수신하도록 동작하는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_277", "content": "제 270 항에 있어서,상기 복제된 데이터는 시간 윈도우에 기초하여 유지되는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_278", "content": "제 270 항에 있어서,상기 제 1 에지 노드 및 상기 제 2 에지 노드는 분산 에지 컴퓨팅 시스템의 계층에 있는 네트워크 피어인에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_279", "content": "제 270 항에 있어서,상기 제 1 에지 노드 및 상기 제 2 에지 노드는 분산 에지 시스템 내의 컴퓨팅 파이프라인의 상이한 계층에 위치하는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_280", "content": "제 250 항에 있어서,에지 네트워크의 에지 노드상에서 실행될 워크로드에 대한 소스 플랫폼 정보를 수신하는 단계;상기 소스 플랫폼 정보에 기초하여 상기 워크로드를 실행하기 위한 타겟 에지 노드를 결정하는 단계;상기 에지 네트워크에 대한 변환 데이터 소스로부터 변환 함수를 획득하는 단계;상기 변환 함수 및 상기 워크로드에 대한 서비스 레벨 협약을 사용하여 상기 타겟 에지 노드의 파라미터를 구성하는 단계; 및상기 워크로드를 실행을 위해 상기 타겟 에지 위치로 송신하는 단계를 포함하는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_281", "content": "제 280 항에 있어서,상기 소스 플랫폼 정보는 소스 플랫폼 그룹의 적어도 하나의 멤버 또는 소스 자원 유형을 포함하는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_282", "content": "제 280 항에 있어서, 상기 서비스 레벨 협약은 서비스 레벨 목표를 포함하고, 상기 타겟 에지 노드의 상기 파라미터를 구성하는 단계는 상기 변환 함수를 상기 서비스 레벨 목표에 적용하여 상기 파라미터에 대한 값을 결정하는 단계를 포함하는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_283", "content": "공개특허 10-2021-0149576-45-제 280 항에 있어서,소스 에지 노드로부터 상기 타겟 에지 노드로 서비스를 마이그레이션하려는 요청을 수신하는 단계;상기 서비스에 대한 프로세스 어드레스 식별자를 결정하는 단계;상기 소스 에지 노드 및 상기 소스 에지 노드의 플랫폼 유형에 대한 자원의 목록 및 대응하는 서비스 레벨 협약을 식별하는 단계; 및상기 소스 에지 노드에 대한 상기 플랫폼 유형 및 상기 서비스 레벨 협약에 기초하여 상기 타겟 에지 노드를 구성하는 단계를 더 포함하는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_284", "content": "제 280 항에 있어서,상기 구성된 타겟 에지 노드를 상기 서비스에 등록하는 단계를 더 포함하는에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_285", "content": "제 280 항에 있어서,상기 소스 에지 노드 및 상기 타겟 에지 노드는 분산 에지 컴퓨팅 시스템의 계층에 있는 네트워크 피어인에지 컴퓨팅 환경에서 수행되는 방법."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_286", "content": "에지 컴퓨팅 시스템으로서, 복수의 에지 컴퓨팅 노드를 포함하되, 상기 복수의 에지 컴퓨팅 노드는 제 1 항 내지 제 285 항 중 어느 한 항의 방법을 수행하도록 구성되는에지 컴퓨팅 시스템."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_287", "content": "에지 컴퓨팅 시스템에서 동작 가능하고, 제 1 항 내지 제 285 항 중 어느 한 항의 방법을 구현하도록 구성된 처리 회로를 포함하는에지 컴퓨팅 노드."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_288", "content": "에지 컴퓨팅 시스템에서 서버로서 동작 가능하고, 제 1 항 내지 제 285 항 중 어느 한 항의 방법을 수행하도록구성된에지 컴퓨팅 노드."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_289", "content": "에지 컴퓨팅 시스템에서 클라이언트로서 동작 가능하고, 제 1 항 내지 제 285 항 중 어느 한 항의 방법을 수행하도록 구성된 처리 회로를 포함하는에지 컴퓨팅 노드."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_290", "content": "에지 컴퓨팅 네트워크의 계층에서, 제 1 항 내지 제 285 항 중 어느 한 항의 방법을 수행하도록 구성된, 집계노드, 네트워크 허브 노드, 게이트웨이 노드, 또는 코어 데이터 처리 노드로서 동작 가능한공개특허 10-2021-0149576-46-에지 컴퓨팅 노드."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_291", "content": "통신 네트워크를 제공하거나 동작하도록 구성된 네트워킹 및 처리 컴포넌트를 포함하여, 에지 컴퓨팅 시스템으로 하여금 제 1 항 내지 제 285 항 중 어느 한 항의 방법을 구현할 수 있게 하는에지 컴퓨팅 네트워크."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_292", "content": "통신 네트워크를 제공하거나 동작하도록 구성된 네트워킹 및 처리 컴포넌트를 포함하여, 에지 컴퓨팅 시스템으로 하여금 제 1 항 내지 제 285 항 중 어느 한 항의 방법을 구현할 수 있게 하는액세스 포인트."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_293", "content": "통신 네트워크를 제공하거나 동작하도록 구성된 네트워킹 및 처리 컴포넌트를 포함하여, 에지 컴퓨팅 시스템으로 하여금 제 1 항 내지 제 285 항 중 어느 한 항의 방법을 구현할 수 있게 하는기지국."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_294", "content": "통신 네트워크를 제공하거나 동작하도록 구성된 네트워킹 컴포넌트를 포함하여, 에지 컴퓨팅 시스템으로 하여금제 1 항 내지 제 285 항 중 어느 한 항의 방법을 구현할 수 있게 하는도로변 유닛."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_295", "content": "공용 에지 컴퓨팅 네트워크와는 별개인 사설 통신 네트워크에서 동작 가능한 온-프레미스 서버(on-premiseserver)로서, 에지 컴퓨팅 시스템으로 하여금 제 1 항 내지 제 285 항 중 어느 한 항의 방법을 구현할 수 있게 하도록 구성되는온-프레미스 서버."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_296", "content": "에지 컴퓨팅 시스템으로 하여금 제 1 항 내지 제 285 항 중 어느 한 항의 방법을 구현할 수 있게 하도록 구성된네트워킹 및 처리 컴포넌트를 포함하는3GPP 4G/LTE 모바일 무선 통신 시스템."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_297", "content": "에지 컴퓨팅 시스템으로 하여금 제 1 항 내지 제 285 항 중 어느 한 항의 방법을 구현할 수 있게 하도록 구성된네트워킹 및 처리 컴포넌트를 포함하는5G 네트워크 모바일 무선 통신 시스템."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_298", "content": "네트워킹 및 처리 컴포넌트를 포함하고, 제 1 항 내지 제 285 항 중 어느 한 항의 방법을 구현할 수 있도록 구성된 에지 컴퓨팅 시스템과 연결하도록 구성된사용자 장비 디바이스."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_299", "content": "공개특허 10-2021-0149576-47-클라이언트 컴퓨팅 디바이스로서, 처리 회로를 포함하고, 에지 컴퓨팅 시스템과 컴퓨트 동작을 조정하도록 구성되되, 상기 에지 컴퓨팅 시스템은제 1 항 내지 제 285 항 중 어느 한 항의 방법을 구현하도록 구성되는클라이언트 컴퓨팅 디바이스."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_300", "content": "에지 컴퓨팅 시스템에서 동작 가능하고, 제 1 항 내지 제 285 항 중 어느 한 항의 방법을 구현하도록 구성된에지 프로비저닝 노드."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_301", "content": "에지 컴퓨팅 시스템에서 동작 가능하고, 제 1 항 내지 제 285 항 중 어느 한 항의 방법을 구현하도록 구성된서비스 오케스트레이션 노드."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_302", "content": "에지 컴퓨팅 시스템에서 동작 가능하고, 제 1 항 내지 제 285 항 중 어느 한 항의 방법을 구현하도록 구성된애플리케이션 오케스트레이션 노드."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_303", "content": "에지 컴퓨팅 시스템에서 동작 가능하고, 제 1 항 내지 제 285 항 중 어느 한 항의 방법을 구현하도록 구성된다중 테넌트 관리 노드."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_304", "content": "처리 회로를 포함하는 에지 컴퓨팅 시스템으로서, 상기 에지 컴퓨팅 시스템은 제 1 항 내지 제 285 항 중 어느 한 항의 방법을 구현하는 하나 이상의 기능 및 서비스를 동작시키도록 구성되는에지 컴퓨팅 시스템."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_305", "content": "에지 컴퓨팅 시스템에서 동작 가능한, 네트워크 기능이 구현된 네트워킹 하드웨어로서, 상기 네트워크 기능은 제 1 항 내지 제 285 항 중 어느 한 항의 방법을 구현하도록 구성되는네트워크 기능이 구현된 네트워킹 하드웨어."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_306", "content": "에지 컴퓨팅 시스템에서 동작 가능한, 가속 기능이 구현된 가속 하드웨어로서, 상기 가속 기능은 제 1 항 내지 제 285 항 중 어느 한 항의 방법을 구현하도록 구성되는가속 기능이 구현된 가속 하드웨어."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_307", "content": "에지 컴퓨팅 시스템에서 동작 가능한, 스토리지 캐퍼빌리티가 구현된 스토리지 하드웨어로서, 상기 스토리지 하드웨어는 제 1 항 내지 제 285 항 중 어느 한 항의 방법을 구현하도록 구성되는스토리지 캐퍼빌리티가 구현된 스토리지 하드웨어."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_308", "content": "공개특허 10-2021-0149576-48-에지 컴퓨팅 시스템에서 동작 가능한, 컴퓨트 캐퍼빌리티가 구현된 컴퓨테이션 하드웨어로서, 상기 컴퓨테이션 하드웨어는 제 1 항 내지 제 285 항 중 어느 한 항의 방법을 구현하도록 구성되는컴퓨트 캐퍼빌리티가 구현된 컴퓨테이션 하드웨어."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_309", "content": "차량 대 차량(vehicle-to-vehicle)(V2V), 차량 대 사물(vehicle-to-everything)(V2X) 또는 차량 대 인프라스트럭처(vehicle-to-infrastructure)(V2I) 시나리오를 지원하도록 조정되고, 제 1 항 내지 제 285 항의 방법 중어느 한 항의 방법을 구현하도록 구성된에지 컴퓨팅 시스템."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_310", "content": "하나 이상의 ETSI(European Telecommunications Standards Institute) 다중 액세스 에지 컴퓨팅(Multi-AccessEdge Computing)(MEC) 사양에 따라 동작하도록 조정된 에지 컴퓨팅 시스템으로서, 상기 에지 컴퓨팅 시스템은 제 1 항 내지 제 285 항 중 어느 한 항의 방법 중 구성되는에지 컴퓨팅 시스템."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_311", "content": "다중 액세스 에지 컴퓨팅(Multi-Access Edge Computing)(MEC) 컴포넌트를 동작시키도록 조정된 에지 컴퓨팅 시스템으로서, 상기 MEC 컴포넌트는, ETSI(European Telecommunications Standards Institute) MEC 구성에 따라, MEC 프록시,MEC 애플리케이션 오케스트레이터, MEC 애플리케이션, MEC 플랫폼 또는 MEC 서비스 중 하나 이상으로부터 제공되고, 상기 MEC 컴포넌트는 제 1 항 내지 제 285 항 중 어느 하나의 방법을 구현하도록 구성되는에지 컴퓨팅 시스템."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_312", "content": "제 1 항 내지 제 285 항 중 어느 한 항의 방법을 구현하도록 구성된, 마이크로서비스 클러스터(microservicecluster), 사이드카를 가진 마이크로서비스 클러스터, 또는 사이드카를 가진 링크된 마이크로서비스 클러스터를구비하는에지 메시로서 구성된 에지 컴퓨팅 시스템."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_313", "content": "제 1 항 내지 제 285 항 중 어느 한 항의 방법을 구현하도록 구성된, 전용 하드웨어, 가상 머신, 컨테이너, 컨테이너상의 가상 머신 사이에 제공되는 하나 이상의 격리 환경을 구현하도록 구성된 회로를 포함하는에지 컴퓨팅 시스템."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_314", "content": "엔터프라이즈 서버, 도로변 서버(roadside server), 거리 캐비닛 서버(street cabinet server) 또는 통신 서버로서 동작하도록 구성되고, 제 1 항 내지 제 285 항 중 어느 한 항의 방법을 구현하도록 구성된에지 컴퓨팅 서버."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_315", "content": "컴퓨트 오프로드, 데이터 캐싱, 비디오 처리, 네트워크 기능 가상화, 무선 액세스 네트워크 관리, 증강 현실,가상 현실, 가상 현실, 자율 주행, 차량 지원, 차량 통신, 산업 자동화, 소매 서비스, 제조 동작, 스마트 빌딩,에너지 관리, 사물 인터넷 동작, 물체 검출, 음성 인식, 헬스케어 애플리케이션, 게임 애플리케이션 또는 가속화된 콘텐츠 처리 중 하나 이상으로부터 제공되는 유스 케이스로 제 1 항 내지 제 285 항 중 어느 하나의 방법공개특허 10-2021-0149576-49-을 구현하도록 구성된에지 컴퓨팅 시스템."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_316", "content": "제 1 항 내지 제 285 항 중 어느 한 항의 방법을 구현하도록 구성된, 상이한 지리적 위치에서 다수의 소유자에의해 운영되는 컴퓨팅 노드를 포함하는에지 컴퓨팅 시스템."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_317", "content": "클라우드 컴퓨팅 시스템으로서, 각각의 클라우드 서비스를 운영하는 데이터 서버를 포함하고, 상기 각각의 클라우드 서비스는 에지 컴퓨팅 시스템과 조정하여 제 1 항 내지 제 285 항 중 어느 한 항의 방법을 구현하도록 구성되는클라우드 컴퓨팅 시스템."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_318", "content": "클라우드렛(cloudlet), 에지렛(edgelet) 또는 애플릿 서비스(applet service)를 운영하는 하드웨어를 포함하는서버로서, 상기 서비스는 에지 컴퓨팅 시스템과 조정하여 제 1 항 내지 제 285 항 중 어느 한 항의 방법을 구현하도록 구성된서버."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_319", "content": "제 1 항 내지 제 285 항 중 어느 한 항의 방법을 구현하기 위해 적어도 하나의 프로세서 및 메모리를 갖는 하나이상의 디바이스를 포함하는에지 컴퓨팅 시스템의 에지 노드."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_320", "content": "에지 컴퓨팅 시스템의 에지 노드로서, 상기 에지 노드는, 관리 콘솔 서비스(management console service), 원격 측정 서비스, 프로비저닝 서비스, 애플리케이션 또는 서비스 오케스트레이션 서비스, 가상 머신 서비스, 컨테이너 서비스, 기능 배치 서비스 또는컴퓨트 배치 서비스, 또는 가속 관리 서비스 중에서 제공되는 하나 이상의 서비스를 운영하고,상기 하나 이상의 서비스는 제 1 항 내지 제 285 항 중 어느 한 항의 방법을 구현하도록 구성되는에지 컴퓨팅 시스템의 에지 노드."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_321", "content": "에지 컴퓨팅 시스템의 네트워크 계층 사이에 분산된 한 세트의 분산 에지 노드로서,상기 네트워크 계층은, 제 1 항 내지 제 285 항 중 어느 한 항의 방법을 구현하도록 구성된, 근접 에지(closeedge), 로컬 에지, 엔터프라이즈 에지, 온-프레미스 에지(on-premise edge), 인접 에지(near edge), 중간에지, 또는 원거리 에지(far edge) 네트워크 계층을 포함하는 한 세트의 분산 에지 노드."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_322", "content": "에지 컴퓨팅 시스템의 장치로서,하나 이상의 프로세서 및 명령어를 포함하는 하나 이상의 컴퓨터 판독 가능 매체를 포함하고, 상기 명령어는 상공개특허 10-2021-0149576-50-기 하나 이상의 프로세서에 의해 실행될 때, 상기 하나 이상의 프로세서로 하여금 제 1 항 내지 제 285 항 중어느 한 항의 방법을 수행하게 하는에지 컴퓨팅 시스템의 장치."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_323", "content": "명령어를 포함하는 하나 이상의 컴퓨터 판독 가능 저장 매체로서,상기 명령어는, 에지 컴퓨팅 시스템의 전자 디바이스로 하여금, 상기 전자 디바이스의 하나 이상의 프로세서에의한 명령어의 실행시, 제 1 항 내지 제 285 항 중 어느 한 항의 방법을 수행하게 하는하나 이상의 컴퓨터 판독 가능 저장 매체."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_324", "content": "제 1 항 내지 제 285 항 중 어느 한 항의 방법을 수행하도록 에지 컴퓨팅 시스템에서 전달되는통신 신호."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_325", "content": "제 1 항 내지 제 285 항 중 어느 한 항의 방법을 수행하도록 에지 컴퓨팅 시스템에서 전달되는 데이터구조로서, 상기 데이터 구조는 데이터그램, 패킷, 프레임, 세그먼트, 프로토콜 데이터 유닛(protocol data unit)(PDU) 또는 메시지를 포함하는데이터 구조."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_326", "content": "에지 컴퓨팅 시스템에서 전달되는 신호로서, 상기 신호는 제 1 항 내지 제 285 항 중 어느 한 항의 방법을 수행하도록 데이터그램, 패킷, 프레임, 세그먼트,프로토콜 데이터 유닛(PDU), 메시지 또는 데이터로 인코딩되는신호."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_327", "content": "에지 컴퓨팅 시스템에서 전달되는 전자기 신호로서, 상기 전자기 신호는 컴퓨터 판독 가능 명령어를 반송하며, 하나 이상의 프로세서에 의한 상기 컴퓨터 판독 가능명령어의 실행은 상기 하나 이상의 프로세서로 하여금 제 1 항 내지 제 285 항 중 어느 한 항의 방법을 수행하게 하는전자기 신호."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_328", "content": "에지 컴퓨팅 시스템에서 사용되는 컴퓨터 프로그램으로서, 상기 컴퓨터 프로그램은 명령어를 포함하며, 상기 에지 컴퓨팅 시스템의 처리 요소에 의한 상기 프로그램의 실행은 상기 처리 요소로 하여금 제 1 항 내지 제 285 항 중 어느 한 항의 방법을 수행하게 하는컴퓨터 프로그램."}
{"patent_id": "10-2020-7037506", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_329", "content": "제 1 항 내지 제 1285 항 중 어느 한 항의 방법을 수행하는 수단을 포함하는에지 컴퓨팅 시스템의 장치.공개특허 10-2021-0149576-51-청구항 330 제 1 항 내지 제 285 항 중 어느 한 항의 방법을 수행하는 로직, 모듈 또는 회로를 포함하는에지 컴퓨팅 시스템의 장치."}
{"patent_id": "10-2020-7037506", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "다중 엔티티(예를 들어, 다중 테넌트) 에지 컴퓨팅 배치를 위한 방법, 시스템 및 유스 케이스의 다양한 양태가 개시된다. 다른 예 중에서도, 다양한 구성 및 기능은 자원의 관리(예를 들어, 하드웨어, 네트워크, 처리 자원 사 용의 제어 및 오케스트레이션), 보안(예를 들어, 보안 실행 및 통신, 격리, 충돌) 및 서비스 관리(예를 들어, 오 케스트레이션, 연결성, 워크로드 조정)을, 에지 컴퓨팅 배치에서, 이를테면 다수의 테넌트 중에서 워크로드를 실 행하도록 구성된 에지 컴퓨팅 환경의 복수의 에지 노드에 의해, 실시 가능하게 한다."}
{"patent_id": "10-2020-7037506", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "우선권 주장 본 출원은, 2019년 4월 30일에 출원된 미국 가출원 No. 62/841,042; 2019년 9월 28일에 출원된 미국 가출원 No. 62/907,597; 및 2019년 11월 22일에 출원된 미국 가출원 No. 62/939,303에 대한 우선권의 이득을 주장하며; 이들 가출원 모두 그 전체 내용이 본 출원에서 참조로 포함된다. 배경 일반적인 레벨에서, 에지 컴퓨팅(edge computing)은 네트워크의 \"에지\" 또는 \"에지들\"의 모음에 더 가까운 위치 에서 컴퓨팅 및 자원의 구현, 조정(coordination) 및 사용을 말한다. 이러한 배열의 목적은 (특히 통상의 클라 우드 컴퓨팅에 비해) 총 소유 비용을 개선하고, 애플리케이션 및 네트워크 지연시간(latency)을 줄이고, 네트워 크 백홀 트래픽 및 연관된 에너지 소비를 줄이고, 서비스 캐퍼빌리티(service capability)를 개선하고, 보안 또 는 데이터 프라이버시(privacy) 요구 사항의 준수를 개선하는 것이다. 에지 컴퓨팅 동작을 수행할 수 있는 컴 포넌트(\"에지 노드\")는 시스템 아키텍처 또는 애드-혹(ad hoc) 서비스에 의해 필요한 모든 위치에서 (예를 들어, 고성능 컴퓨트 데이터 센터 또는 클라우드 설비; 지정된 에지 노드 서버, 엔터프라이즈 서버, 도로변 (roadside) 서버, 통신 중앙국(telecom central office); 또는 에지 서비스를 소비하는 서비스를 제공받는 로 컬 또는 피어 앳-더-에지(at-the-edge) 디바이스에서) 상주할 수 있다. 에지 컴퓨팅에 맞게 적응된 애플리케이션은 이것으로 제한되는 것은 아니지만 (예를 들어, 원격 통신 또는 인터 넷 서비스를 운영하기 위해) 전통적인 네트워크 기능의 가상화 및 (예를 들어, 5G 네트워크 서비스를 지원하기 위해) 차세대 특징 및 서비스의 도입을 포함한다. 에지 컴퓨팅을 광범위하게 활용할 것으로 예상되는 유스 케 이스는 많은 다른 네트워크 및 컴퓨트 집약적 서비스 중에서도, 커넥티드 자율 주행(connected self-driving) 자동차, 감시, 사물 인터넷(Internet of Things)(IoT) 디바이스 데이터 분석, 비디오 인코딩 및 분석, 위치 인 식 서비스, 스마트 시티의 디바이스 감지를 포함한다. 일부 시나리오에서, 에지 컴퓨팅은 클라우드와 유사한 분산 서비스를 제공하거나 호스팅하여 많은 유형의 스토 리지 및 컴퓨팅 자원 사이에서 애플리케이션 및 조정된 서비스 인스턴스에 대한 오케스트레이션(orchestration) 및 관리를 제공할 수 있다. 엔드포인트 디바이스, 클라이언트 및 게이트웨이가 네트워크 에지에 더 가까운 위 치에서 네트워크 자원 및 애플리케이션에 액세스하려고 시도함에 따라, 에지 컴퓨팅은 또한 IoT 및 포그(Fog)/ 분산 네트워킹 구성을 위해 개발된 기존의 유스 케이스 및 기술과 밀접하게 통합될 것으로 예상된다."}
{"patent_id": "10-2020-7037506", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "다음의 실시예는 일반적으로 데이터 처리, 서비스 관리, 자원 할당, 컴퓨트 관리, 네트워크 통신, 애플리케이션 파티셔닝 및 통신 시스템 구현에 관한 것이며, 특히 분산 에지 컴퓨팅 환경에서 다수의 엔티티(예를 들어, 다수 의 테넌트, 사용자, 이해 관계자, 서비스 인스턴스, 애플리케이션 등)를 동적으로 지원하도록 다양한 에지 컴퓨 팅 디바이스 및 엔티티를 적응시키기 위한 기술 및 구성에 관한 것이다. 다음의 설명에서, 에지 컴퓨팅 아키텍처 및 구현되는 에지 컴퓨팅 시스템의 구성 및 기능적 캐퍼빌리티의 다양 한 개선을 위한 방법, 구성 및 관련된 디바이스가 개시된다. 이러한 개선은, 시스템의 다수의 사용자, 시스템 상의 다수의 테넌트, 시스템과 상호작용하는 다수의 디바이스 또는 사용자 장비, 시스템으로부터 제공되는 다수 의 서비스, 시스템 내에서 이용 가능하거나 관리되는 다수의 자원, 시스템에 대해 노출되는 다수의 형태의 네트 워크 액세스, 시스템에 대한 다수의 운영 위치 등의 형태이든 아니든, 다양한 유스 케이스, 특히 에지 컴퓨팅 시스템의 다수의 이해 당사자가 연루되는 유스 케이스에서 이득이 될 수 있다. 이러한 다차원적 양태 및 고려 사항은 다중 테넌트 및 다중 서비스 에지 컴퓨팅 구성에서 관리되거나 조직되는 자원에 대해 구체적으로 논의하 면서, 본 명세서에서는 일반적으로 \"다중 엔티티\" 제약 조건으로 지칭된다. 아래에서 설명되는 예시적인 에지 네트워킹 시스템에 의하면, 컴퓨팅 및 스토리지 자원은 네트워크의 에지에 더 가깝게 (예를 들어, 클라이언트, 엔드포인트 디바이스 또는 \"사물\"에 더 가까이) 이동된다. 컴퓨팅 및 스토리 지 자원을 데이터를 생성하거나 사용하는 디바이스에 더 가까이 이동시킴으로써, 표준의 네트워크화된 (예를 들 어, 클라우드 컴퓨팅) 시스템에 비해 다양한 지연시간, 준수 및/또는 금전적 또는 자원 비용 제약 조건이 달성 될 수 있다. 그렇게 하기 위해, 일부 예에서, 컴퓨트, 메모리 및/또는 스토리지 자원의 풀(pool)이 로컬 서버, 라우터 및/또는 다른 네트워크 장비에 위치하거나, 그렇지 않으면 장착될 수 있다. 이러한 로컬 자원은 시스템 에 부과되는 제약 조건을 원활하게 충족시켜 준다. 예를 들어, 로컬 컴퓨트 및 스토리지 자원은 에지 시스템으 로 하여금, 자율 주행, 비디오 감시 및 모바일 미디어 소비와 같은 낮은 지연시간의 사용자 사례의 고려 사항일 수 있는 실시간으로 또는 거의 실시간으로 연산을 수행할 수 있게 한다. 또한, 이러한 자원은 로컬 SLA를 확장 및 달성하고, 계층별 서비스 요구 사항을 관리하고, 임시 또는 영구적으로 로컬 특징 및 기능을 가능하게 하는 역량을 제공하는 에지 시스템에서 서비스 관리를 통해 이득을 얻을 수 있다. 예시적인 에지 컴퓨팅 시스템은 각기 상이한 요구 사항 또는 제약 조건을 가질 수 있는 엔드포인트 디바이스(예 를 들어, 클라이언트 사용자 장비(user equipment)(UE))에 다양한 서비스를 지원 및/또는 제공할 수 있다. 예 를 들어, 일부 서비스에는 우선순위 또는 서비스 품질(quality-of-service)(QoS) 제약 조건(예를 들어, 자율 주 행 차량의 교통 데이터가 온도 센서 데이터보다 우선순위가 높을 수 있음), 안정성(reliability) 및 탄력성(예 를 들어, 교통 데이터에는 필수 불가결한(mission-critical) 안정성이 필요할 수 있지만, 온도 데이터에는 약간 의 오차 분산이 허용될 수 있음)뿐만 아니라, 전력, 냉각 및 폼 팩터 제약 조건이 있을 수 있다. 이러한 제약 조건 및 다른 기술적 제약 조건은 다중 이해 관계자(multi-stakeholder) 설정에 적용될 때 상당한 복잡성과 기 술적 문제를 제시할 수 있다. 다음에는 초기에 에지 컴퓨팅에 적용할 수 있는 용어의 개요가 제공된다(섹션 I). 그 다음에는 에지 컴퓨팅 기 술 및 구성에 대한 개요 및 다중 이해 관계자 서비스의 예시적인 유스 케이스(섹션 II)가 이어진다. 그 다음에 는 관련 기술 영역에 대한 논의 이외에, 유스 케이스(섹션 III.A)와 더불어, (a) 자원 할당 및 할당 해제(섹션 III.B), (b) 보안 및 프라이버시 보호(섹션 III.C), 및 (c) 오케스트레이션 및 서비스 레벨(섹션 III.B)에 관련 된 개선 사항을 비롯한, 다중 이해 관계자 서비스(섹션 III)에 대해 제시되는 유형의 기술적 개선 사항이 이어 진다. 그 다음에는 에지 컴퓨팅 시스템의 잠재적인 연결성 구성에 대한 결론적인 논의(섹션 IV) 및 본 명세서 에서 설명된 개선 사항을 구현하는 예시적인 구성 및 방법이 이어진다. I. 용어 본 명세서에서 사용되는 바와 같이, \"에지 컴퓨팅\"이라는 용어는 엔드포인트 사용자(클라이언트 디바이스, 사용 자 장비 등)의 지연시간을 줄이고 처리량을 늘리기 위한 노력의 일환으로, 클라우드 처리 활동으로서 또는 클라 우드 처리 자원에 의해 전형적으로 수행되는 것을 비롯한, 처리 활동 및 자원(예를 들어, 컴퓨트, 스토리지, 가 속 자원)을 네트워크의 \"에지\" 쪽으로 이동시키는 분산 컴퓨팅의 많은 구현을 망라한다. 전형적으로 이러한 에 지 컴퓨팅 구현은 클라우드와 유사한 서비스, 기능, 애플리케이션 및 서브시스템에서의 그러한 활동 및 자원을, 무선 네트워크를 통해 액세스 가능한 하나 또는 다수의 위치로부터 제공하는 것을 포함한다. 따라서, 본 명세 서에서 사용되는 네트워크, 클러스터, 도메인, 시스템 또는 컴퓨팅 배열의 \"에지\"라고 언급하는 것은 기능 분산 컴퓨트 요소의 그룹 또는 집단이며, 그래서 그래프 이론에서 사용되는 것과 같은 \"에지\"(링크 또는 연결)와는 일반적으로 관련이 없다.모바일 무선 네트워크(예를 들어, 셀룰러 및 Wi-Fi 데이터 네트워크)를 통해 액세스 가능한 에지 컴퓨팅 애플리 케이션 및 서비스의 특정 배열은 \"모바일 에지 컴퓨팅(mobile edge computing)\" 또는 \"다중 액세스 에지 컴퓨팅 (multi-access edge computing)\"으로 지칭될 수 있으며, 이것은 약어 \"MEC\"로 참조될 수 있다. 본 명세서에서 \"MEC\"의 사용은 또한 \"ETSI MEC\"라고 하는 ETSI(European Telecommunications Standards Institute)에 의해 반 포된 표준화된 구현을 의미할 수도 있다. ETSI MEC 사양에 의해 사용되는 용어는 본 명세서에서 제공되는 정의 또는 사용이 상충되지 않는 한, 일반적으로 본 명세서에서 참조로 포함된다. 본 명세서에서 사용되는 바와 같이, \"컴퓨트 노드(compute node)\" 또는 \"컴퓨트 디바이스(compute device)\"라는 용어는 더 큰 시스템의 일부이든, 시스템의 분산된 모음이든, 스탠드얼론 장치이든지 간에 에지 컴퓨팅 동작의 양태를 구현하는 식별 가능한 엔티티를 말한다. 일부 예에서, 컴퓨트 노드는 클라이언트, 서버 또는 중간 엔티 티로서 동작하는지에 관계없이 \"에지 노드\", \"에지 디바이스\", \"에지 시스템\"으로 지칭될 수 있다. 컴퓨트 노 드의 특정 구현은 서버, 기지국, 게이트웨이, 도로변 유닛, 온 프레미스 유닛(on premise unit), UE 또는 최종 소비 디바이스 등에 통합될 수 있다. 또한, 컴퓨트 노드 또는 컴퓨트 디바이스는 노드 또는 디바이스에 이용 가능한 자원(예를 들어, 전력, 컴퓨트, 공간, 온도 및 다른 운영 고려 사항 또는 제약 조건)에 기초한, 상이한 유형 또는 클래스의 하드웨어 또는 이러한 하드웨어의 구성을 포함할 수 있다. 따라서 하드웨어의 많은 변형은 컴퓨트 노드 또는 컴퓨트 디바이스에 포함되는 것으로 의도된다. 본 명세서에서 사용되는 바와 같이, \"기지국\"이라는 용어는 하나 이상의 셀의 무선 신호를 사용자 장비(UE)로 또는 사용자 장비로부터 송신 및 수신하는 것을 담당하는 4 세대(fourth-generation)(4G) 또는 5 세대(fifth- generation)(5G) 이동 통신 네트워크와 같은 무선 액세스 네트워크(radio access network)(RAN)의 네트워크 요 소를 말한다. 기지국은 통합 안테나를 가질 수 있거나 또는 피더 케이블(feeder cable)에 의해 안테나 어레이 에 연결될 수 있다. 기지국은 특화된 디지털 신호 처리 및 네트워크 기능 하드웨어를 사용한다. 일부 예에서, 기지국은 유연성, 금전적 또는 자원 비용 및 성능을 위해 소프트웨어에서 동작하는 다수의 기능 블록으로 분할 될 수 있다. 일부 예에서, 기지국은 진화된 노드-B(evolved node-B)(eNB) 또는 차세대 노드-B(next generation node-B)(gNB)를 포함할 수 있다. 일부 예에서, 기지국은 컴퓨트 노드로서 동작하도록 컴퓨트 하드 웨어를 동작 시키거나 포함할 수 있다. 그러나, 본 명세서에서 논의되는 많은 시나리오에서, RAN 기지국은 액 세스 포인트(예를 들어, 무선 네트워크 액세스 포인트) 또는 다른 네트워크 액세스 하드웨어로 대체될 수 있다. 본 명세서에서 사용되는 바와 같이, \"중앙국(central office)\"(또는 CO)이라는 용어는 액세스 가능한 또는 정의 된 지리적 영역 내의 원격 통신 인프라스트럭처의 집계 지점(aggregation point)을 나타내며, 이곳은 종종 원격 통신 서비스 제공자가 전통적으로 하나 또는 다수 유형의 액세스 네트워크용 스위칭 장비를 배치했던 곳이다. CO는 통신 인프라스트럭처 장비 또는 컴퓨트, 데이터 스토리지 및 네트워크 자원을 수용하도록 물리적으로 설계 될 수 있다. 그러나 CO는 원격 통신 서비스 제공자에 의한 지정된 위치에 있을 필요는 없다. CO는 에지 애플 리케이션 및 서비스 또는 심지어 클라우드와 유사한 서비스의 로컬 구현을 위한 컴퓨트 디바이스를 몇 개라도 호스팅할 수 있다. 본 명세서에서 사용되는 \"클라우드 서비스 제공자(cloud service provider)\"(또는 CSP)는 (예를 들어, 공공 클 라우드(public cloud)의 컨텍스트에서 사용되는 바와 같은) 중앙, 로컬 및 에지의 데이터 센터로 구성된 대규모 의 \"클라우드\" 자원을 전형적으로 운영하는 조직을 나타낸다. 다른 예에서, CSP는 클라우드 서비스 사업자 (Cloud Service Operator)(CSO)라고도 지칭될 수 있다. \"클라우드 컴퓨팅\"이라고 언급하는 것은 일반적으로 에 지 컴퓨팅에 비해 지연시간, 거리 또는 제약 조건이 적어도 약간 증가된 원격 위치에서 CSP 또는 CSO에 의해 제 공되는 컴퓨팅 자원 및 서비스를 말한다. 본 명세서에서 사용되는 바와 같이, \"데이터 센터\"라는 용어는 다수의 고성능 컴퓨트 및 데이터 스토리지 노드 를 수용하여 많은 양의 컴퓨트, 데이터 스토리지 및 네트워크 자원이 단일 위치에 존재하도록 의도된 목적에 맞 게 설계된 구조를 지칭한다. 이것은 종종 특화된 랙 및 인클로저 시스템, 적합한 난방, 냉각, 환기, 보안, 화 재 진압 및 전력 전달 시스템을 수반한다. 이 용어는 또한 일부 컨텍스트에서 컴퓨트 및 데이터 스토리지 노드 를 의미할 수도 있다. 데이터 센터는 (예를 들어, 가장 큰) 중앙 또는 클라우드 데이터 센터, 로컬 데이터 센 터 및 (가장 작은) 에지 데이터 센터 사이에서 규모가 다를 수 있다. 본 명세서에서 사용되는 바와 같이, 에지 네트워크의 \"계층\"이라고 언급하는 것은, \"근접 에지(close edge)\", \"로컬 에지(local edge)\", \"중간 에지(middle edge)\", \"원거리 에지(far edge)\"라고 하든 또는 구체적으로 명 명된 계층을 사용하든지 간에 지연시간, 타이밍, 또는 거리와 관련된 공통적 특성을 갖는 다양한 형태 또는 유 형의 에지 네트워크 및 에지 네트워킹 구성을 망라할 수 있다. 따라서, 계층이라고 언급하는 것은 전형적으로반드시 OSI 모델의 계층을 의미하는 것이 아니라 공통의 층 또는 한 세트의 특성을 가진 일부 네트워크 부분 또 는 세그먼트를 말할 것이다. 본 명세서에서 사용되는 바와 같이, \"액세스 에지 계층(access edge layer)\"은 최종 사용자 또는 디바이스에 가 장 가까운 인프라스트럭처 에지의 서브계층을 나타낸다. 예를 들어, 이러한 계층은 셀룰러 네트워크 사이트에 배치된 에지 데이터 센터에 의해 충족될 수 있다. 액세스 에지 계층은 인프라스트럭처 에지의 최전선으로서 기 능하며 계층에서 더 높은 통합 에지 계층(aggregation edge layer)에 연결할 수 있다. 본 명세서에서 또한 사 용되는 바와 같이, \"통합 에지 계층\"이라는 용어는 액세스 에지 계층으로부터 1 홉(hop) 떨어진 인프라스트럭처 에지의 계층을 나타낸다. 이러한 계층은 단일 위치에서 중간 규모 데이터 센터로서 존재하거나 또는 다수의 상 호 연결된 마이크로 데이터 센터로부터 형성되어 액세스 에지와 함께 계층 토폴로지를 형성하여 액세스 에지 단 독보다 더 큰 협업, 워크로드 장애 극복(failover) 및 확장성을 가능하게 할 수 있다. 본 명세서에서 사용되는 바와 같이, \"네트워크 기능 가상화(network function virtualization)\" (또는 NFV)는 독점 하드웨어 어플라이언스(hardware appliance) 내부의 임베디드 서비스로부터, 산업 표준 가상화 및 클라우 드 컴퓨팅 기술을 사용하는 (예를 들어, intel® Xeon™ 또는 AMD® Epyc™ 또는 Opteron™ 프로세서와 같은 표 준 x86® 및 ARM® 서버 내의) 표준화된 CPU 상에서 실행되는 소프트웨어 기반 가상화된 네트워크 기능(또는 VNF)으로 네트워크 기능을 마이그레이션하는 것을 나타낸다. 일부 양태에서, NFV 처리 및 데이터 저장은 인프 라스트럭처 에지 내에서, 로컬 셀룰러 사이트에 직접 연결된 에지 데이터 센터에서 발생할 것이다. 본 명세서에서 사용되는 바와 같이, \"가상화된 네트워크 기능\"(또는 VNF)은 전용의 물리적 장비를 대신하여 NFV 에 의해 사용되는 다기능, 다목적 컴퓨트 자원(예를 들어, x86, ARM 처리 아키텍처) 상에서 동작하는 소프트웨 어 기반 네트워크 기능을 나타낸다. 일부 양태에서, 여러 VNF는 인프라스트럭처 에지의 에지 데이터 센터에서 동작할 것이다. 본 명세서에서 사용되는 바와 같이, \"에지 컴퓨트 노드\"는 서버, 클라이언트, 엔드포인트 또는 피어 모드에서 동작하든, 그리고 네트워크의 \"에지\"에 있든 또는 네트워크 내에서 더 멀리 연결된 위치에 있는지 간에, 디바이 스, 게이트웨이, 브릿지, 시스템 또는 서브시스템, 컴포넌트의 형태의 실제, 논리적 또는 가상화된 컴퓨트 가능 요소의 구현을 말한다. 본 명세서에서 사용되는 \"노드\"라고 언급하는 것은 일반적으로 \"디바이스\", \"컴포넌트\" 및 \"서브시스템\"과 상호 교환 가능하며; 그러나 \"에지 컴퓨팅 시스템\"이라고 언급하는 것은 일반적으로 분산 아 키텍처, 조직 또는 다수의 노드 및 디바이스의 모음을 나타내며, 에지 컴퓨팅 환경에서 서비스 또는 자원의 일 부 양태를 달성하거나 제공하도록 구성된 것이다. 본 명세서에서 사용되는 바와 같이, \"클러스터\"라는 용어는 물리적 엔티티(예를 들어, 상이한 컴퓨팅 시스템, 네트워크 또는 네트워크 그룹), 논리 엔티티(예를 들어, 애플리케이션, 기능, 보안 구성, 컨테이너) 등의 형태 의 에지 컴퓨팅 시스템(또는 시스템들)의 일부로서 엔티티의 세트 또는 그룹을 말한다. 일부 위치에서, \"클러 스터\"는 \"그룹\" 또는 \"도메인\"이라고도 지칭된다. 클러스터의 멤버십은 동적 또는 특성 기반 멤버십, 네트워크 또는 시스템 관리 시나리오, 또는 엔티티를 클러스터에 추가, 수정 또는 제거할 수 있는 아래에서 논의되는 다 양한 예시적 기술을 비롯한, 조건 또는 기능에 기초하여 수정되거나 영향을 받을 수 있다. 클러스터는 또한 다 수의 계층, 레벨 또는 특성에 기초한 보안 특징 및 결과의 변형물을 비롯하여, 그러한 계층, 레벨 또는 특성을 포함하거나 이와 연관될 수 있다. 다음과 같은 예 중 많은 예가 4G/5G 3GPP 네트워크 컴포넌트(또는 예상되는 테라헤르츠 기반 6G/6G+ 기술)를 사 용하는 것을 비롯하여, 특정 셀룰러/모바일 네트워크 용어를 사용하여 제공되지만, 이러한 예는 (광학 네트워크 및 연관된 광섬유, 송수신기 등을 포함하는) 통합된 유선 네트워크뿐만 아니라 배치된 다른 많은 광역 및 로컬 무선 네트워크에 적용될 수 있다는 것이 이해될 것이다. 기술적으로 가능한 경우, 다양한 네트워크 연결은 본 명세서에 개시된 임의의 네트워크에서 유선 또는 무선일 수 있으며, 결과적인 시스템은 유선 및 무선 네트워크 기술 모두의 하이브리드 배치일 수 있다. 또한, 본 명세서에서 개시된 임의의 개시된 무선 네트워크 연결성 표 준은 시스템 또는 서브시스템 아키텍처적 요구 사항에 의해 개시된 기능을 달성하도록 사용될 수 있다. II. 에지 컴퓨팅 시스템의 예 도 1은 다음의 많은 예에서 \"에지 클라우드\"로 지칭되는 처리 계층을 포함하는 에지 컴퓨팅을 위한 구성의 개요 를 보여주는 블록도이다. 도시된 바와 같이, 에지 클라우드는 에지 위치에서, 이를테면 액세스 포인 트 또는 기지국, 로컬 처리 허브 또는 중앙국에서 함께 위치하며, 따라서 복수의 엔티티, 디바 이스 및 장비 인스턴스를 포함할 수 있다. 에지 클라우드는 클라우드 데이터 센터보다는 엔드포인트(소비자 및 생산자) 데이터 소스(예를 들어, 자율 주행 차량, 사용자 장비, 비즈니스 및 산업 장비, 비디오 캡처 디바이스, 드론, 스마트 시티 및 빌딩 디바이스, 센서 및 IoT 디바이스 등)에 훨씬 더 가까이 위치한다. 에지 클라우드의 에지에서 제공되는 컴퓨트, 메모리 및 스토리지 자원은 엔드포인트 데이터 소스에 의해 사용되는 서비스 및 기능에 대해 초저 지연시간의 응답 시간을 제 공하는데 매우 중요할 뿐만아니라, 에지 클라우드로부터 클라우드 데이터 센터를 향한 네트워크 백홀 트래픽을 줄임으로써 다른 이점 중에서도 에너지 소비와 전체 네트워크 사용을 개선한다. 컴퓨트, 메모리 및 저장소는 부족한 자원이며, 일반적으로 에지 위치에 따라 감소한다(예를 들어, 처리 자원은 중앙국에서보다는, 기지국에서 보다는, 소비자 엔드포인트 디바이스에서 더 적게 이용 가능하다). 그러나 에지 위치가 엔드포인트(예를 들어, UE)에 가까울수록, 종종 공간과 전력이 더 제한되는 일이 더 많다. 따라서 에지 컴퓨팅은 지리적인 면에서 그리고 네트워크 액세스 시간 면에서 둘 모두에 더 가까운 곳에 더 많은 자원을 분배 하여, 네트워크 서비스에 필요한 자원의 양을 줄이려고 시도한다. 이러한 방식으로, 적절한 경우 에지 컴퓨팅 은 컴퓨트 자원을 워크로드 데이터로 가져 오거나, 또는 워크로드 데이터를 컴퓨트 자원으로 가져 오려고 시도 한다. 다음에는 많은 잠재적인 배치를 다루고 일부 네트워크 사업자 또는 서비스 제공자가 자체의 인프라스트럭처에서 가질 수 있는 제한 사항을 해결하는 에지 클라우드 아키텍처의 양상을 설명한다. 이러한 양상은 (예를 들어, 다중 테넌트 시나리오에서 기지국 레벨의 에지는 성능과 캐퍼빌리티가 더 많이 제한될 수 있기 때문에) 에지 위 치에 기초한 구성의 변형; 에지 위치, 위치의 계층 또는 위치 그룹에 이용 가능한 컴퓨트, 메모리, 저장소, 패 브릭, 가속 또는 유사한 자원의 유형에 기초한 구성; 서비스, 보안, 및 관리와 오케스트레이션 캐퍼빌리티; 및 최종 서비스의 유용성과 성능을 달성할 관련 목표를 포함한다. 이러한 배치는 지연시간, 거리 및 타이밍 특성 에 따라, \"인접 에지(near edge)\", \"근접 에지\", \"로컬 에지\", \"중간 에지\" 또는 \"원거리 에지\" 계층으로 간주 될 수 있는 네트워크 계층에서 처리를 수행할 수 있다. 에지 컴퓨팅은 전형적으로 (예를 들어, \"로컬 에지\", \"근접 에지\" 또는 \"인접 에지\"에서) 데이터를 생성하고 소 비하는 엔드포인트 디바이스에 훨씬 더 가까운 기지국, 게이트웨이, 네트워크 라우터, 또는 다른 디바이스에서 구현된 컴퓨트 플랫폼(예를 들어, x86 또는 ARM 컴퓨트 하드웨어 아키텍처)을 사용함으로써, 네트워크의 \"에 지\"에서 또는 그에 더 가까이에서 컴퓨팅이 수행되는 개발 패러다임이다. 예를 들어, 에지 게이트웨이 서버는 연결된 클라이언트 디바이스에 대한 낮은 지연시간 유스 케이스(예를 들어, 자율 주행 또는 비디오 감시)를 위 해 실시간으로 컴퓨테이션을 수행할 메모리 및 스토리지 자원의 풀을 갖추고 있을 수 있다. 또는 한 예로서, 기지국은 백홀 네트워크를 통해 데이터를 추가로 통신하지 않고도, 연결된 사용자 장비의 서비스 워크로드를 직 접 처리할 컴퓨트 및 가속 자원으로 증강될 수 있다. 또는 또 다른 예로, 중앙국 네트워크 관리 하드웨어는 가 상화된 네트워크 기능을 수행하고 연결된 디바이스의 서비스 및 소비자 기능을 실행하기 위한 컴퓨트 자원을 제 공하는 표준화된 컴퓨트 하드웨어로 대체될 수 있다. 에지 컴퓨팅 네트워크 내에서, 컴퓨트 자원이 데이터 쪽 으로 \"이동\"되는 서비스 시나리오뿐만 아니라, 데이터가 컴퓨트 자원 쪽으로 \"이동\"되는 시나리오가 있을 수 있 다. 또는 한 예로서, 기지국 컴퓨트, 가속 및 네트워크 자원은 코너 케이스(corner case)인 응급 상황을 관리 하거나 또는 상당히 더 길게 구현된 수명주기(lifecycle) 동안 배치된 자원의 오랜 지속성(longevity)을 제공하 기 위해 휴면 용량(구독, 주문형 용량)을 활성화함으로써 필요에 따라 워크로드 수요에 맞게 조정하는 서비스를 제공할 수 있다. 도 2는 엔드포인트, 에지 클라우드 및 클라우드 컴퓨팅 환경 사이의 운영 계층을 도시한다. 구체적으로, 도 2 는 네트워크 컴퓨팅의 다수의 예시적인 계층 사이에서 에지 클라우드를 이용하는 컴퓨테이션 유스 케이스 의 예를 도시한다. 계층은 에지 클라우드에 액세스하여 데이터 생성, 분석 및 데이터 소비 활동을 수행하는 엔드포인트(디바이스 및 사물) 계층에서 시작된다. 에지 클라우드는 게이트웨이, 온-프레 미스 서버 또는 네트워크 장비(노드)가 물리적으로 근접한 에지 시스템에 위치하는 에지 디바이스 계층 ; 기지국, 무선 처리 유닛, 네트워크 허브, 지역 데이터 센터 또는 로컬 네트워크 장비(장비)를 망라 하는 네트워크 액세스 계층; 및 그 사이에 위치한 임의의 장비, 디바이스 또는 노드(계층에서, 자세 히 도시되지 않음)와 같은 다수의 네트워크 계층에 이어져 있을 수 있다. 에지 클라우드 내에서 그리고 다양한 계층 사이에서 네트워크 통신은 도 65 내지 도 83을 참조하여 논의되는 연결성 아키텍처 및 기술을 비롯 한, 임의의 수의 유선 또는 무선 매체를 통해 발생할 수 있다. 네트워크 통신 거리 및 처리 시간 제약 조건으로 말미암은 지연의 예는 엔드포인트 계층에서 발생할 때의 1 밀리 초(ms) 미만, 에지 디바이스 계층(예를 들어, \"인접 에지\" 또는 \"근접 에지\"계층)에서의 5 ms 미만 에서부터, 네트워크 액세스 계층(예를 들어, \"중간 에지\" 계층)에서 노드와 통신할 때의 심지어 10 내지40 ms 까지를 범위로 할 수 있다. 에지 클라우드를 넘어 코어 네트워크 계층 및 클라우드 데이터 센 터 계층이 있고, 각각 계층에서는 지연시간이 (예를 들어, 코어 네트워크 계층에서의 50 내지 60 ms, 클라우드 데이터 센터 계층에서의 100 ms 이상까지, 두 계층 모두 \"원거리 에지\" 계층으로 간주될 수 있음) 증 가한다. 결과적으로, 코어 네트워크 데이터 센터 또는 클라우드 데이터 센터에서의 동작은, 지연시 간이 적어도 50 내지 100 ms 이상이므로 유스 케이스의 많은 시간 임계적 기능을 달성할 수 없다. 각각의 이러한 지연시간 값은 설명과 대조의 목적으로 제공되며; 다른 액세스 네트워크 매체 및 기술을 사용하는 것이 지연시간을 더 줄일 수 있다는 것이 이해될 것이다. 다양한 유스 케이스는 에지 클라우드를 이용하는 다수의 서비스로 인해, 들어오는 스트림에서 발생하는 사 용 압력에 따라 자원에 액세스할 수 있다. 낮은 지연시간이라는 결과를 달성하기 위해, 에지 클라우드 내 에서 실행되는 서비스는, (a) 우선순위(처리량 또는 지연시간) 및 서비스 품질(QoS)(예를 들어, 자율 주행 차 량의 트래픽은 응답 시간 요구 사항의 측면에서 온도 센서보다 우선순위가 높을 수 있음; 또는 애플리케이션에 따라 컴퓨트/가속기, 메모리, 저장소 또는 네트워크 자원에서 성능 민감도/병목 현상이 존재할 수 있음); (b) 안정성 및 탄력성(예를 들어, 일부 입력 스트림은 필수 불가결한 안정성에 의거하여 작동해야 하고 트래픽은 필 수 불가결한 안정성으로 라우팅되어야 하는 반면, 일부 다른 입력 스트림은 애플리케이션에 따라 가끔 실패를 용인할 수 있음); 및 (c) 물리적 제약 조건(예를 들어, 전력, 냉각 및 폼 팩터)의 측면에서 다양한 요구 사항의 균형을 유지한다. 이러한 유스 케이스에 대한 엔드 투 엔드 서비스 관점은 서비스 흐름의 개념을 포함하고 트랜잭션과 연관된다. 트랜잭션은 서비스를 소비하는 엔티티에 대한 전체 서비스 요구 사항뿐만 아니라 자원, 워크로드, 워크플로우 (workflow), 및 비즈니스 기능적 및 비즈니스 레벨 요구 사항에 대한 연관된 서비스를 자세히 설명한다. 설명 된 \"조건\"이 붙은 채로 실행되는 서비스는 서비스 수명주기 동안 트랜잭션에 대한 실시간 및 런타임 계약 준수 를 보장하는 방식으로 각 계층에서 관리될 수 있다. 트랜잭션의 컴포넌트에 합의된 SLA가 누락되어 있을 때, 시스템 전체(트랜잭션의 컴포넌트)는 SLA 위반의 영향을 이해하고 시스템의 다른 컴포넌트를 늘려서 전 체 트랜잭션 SLA를 재개하며 개선 단계를 구현할 역량을 제공할 수 있다. 따라서 이러한 변형 및 서비스 기능을 염두에 두고, 에지 클라우드 내의 에지 컴퓨팅은 유스 케이스 (예를 들어, 물체 추적, 비디오 감시, 커넥티드 카 등)의 다수의 애플리케이션을 실시간 또는 거의 실시간으로 서빙하고 대응하는 역량을 제공할 수 있으며, 이러한 다수의 애플리케이션에 대한 초저 지연시간 요구 사항을 충족시킬 수 있다. 이러한 장점은 지연시간 또는 다른 제한으로 인해 통상의 클라우드 컴퓨팅을 적극 활용할 수 없는 완전히 새로운 등급의 애플리케이션(VNF, 서비스로서의 기능(Function as a Service)(FaaS), 표준 프로 세스 등)을 가능하게 한다. 그러나 에지 컴퓨팅의 장점과 함께 다음과 같은 주의 사항이 나온다. 에지에 위치한 디바이스는 종종 자원이 제한되며 그래서 에지 자원의 사용량에 대한 압력이 있다. 전형적으로, 이것은 다수의 사용자(테넌트) 및 디바 이스에 의해 사용하기 위한 메모리 및 스토리지 자원의 풀링(pooling)을 통해 해결된다. 에지는 전력 및 냉각 에 제약이 있을 수 있고 그래서 가장 많은 전력을 소비하는 애플리케이션에 의한 전력 사용량을 고려해야 한다. 자원 중 많은 자원은 더 많은 전력이 더 큰 메모리 대역폭을 필요로 하는 최근에 생겨난 메모리 기술을 사용할 가능성이 높기 때문에, 이러한 풀링된 메모리 자원에는 고유한 전력-성능 트레이드오프(tradeoff)가 있을 수 있 다. 마찬가지로, 에지 위치가 무인화될 수 있고 (예를 들어, 제 3자 위치에 수용되어 있을 때는) 인가 받은 액 세스가 필요할 수 조차도 있기 때문에, 하드웨어의 개선된 보안 및 신뢰성 있는 신뢰점(root of trust) 기능이 또한 필요한다. 이러한 문제는, 특히 네트워크 사용량이 동적으로 변동하고 다수의 이해 관계자, 유스 케이스 및 서비스의 구성이 변경됨에 따라, 많은 사용자에 의해 서비스 및 애플리케이션이 요청되는, 다중 테넌트, 다 중 소유자 또는 다중 액세스 설정의 에지 클라우드에서 확대된다. 보다 일반적인 레벨에서, 에지 컴퓨팅 시스템은 에지 클라우드에서 동작하는 앞에서 논의된, 클라이언트 및 분산 컴퓨팅 디바이스의 조정을 제공하는, 계층(네트워크 계층(200-240))에서 임의의 수의 배치를 포함하는 것으로 설명될 수 있다. 도 3은 설명 목적을 위해 에지 컴퓨팅 환경 사이에 배치된 분산 컴퓨트의 계층의 추상 화된 개요를 제공한다. 동일한(예를 들어, 피어 투 피어) 또는 상이한 계층에 있는 다양한 유형의 네트워크 링 크가 또한 도시된다. 일반적으로 도 3은 네트워크의 계층에 걸쳐 분산되어 있는 것처럼, 하나 이상의 클라이언트 컴퓨트 노드, 하나 이상의 에지 게이트웨이 노드, 하나 이상의 에지 집계 노드(edge aggregation node), 하나 이 상의 코어 데이터 센터 및 글로벌 네트워크 클라우드 사이에 분산된 다수의 이해 관계자 엔티티에 에지 서비스 및 애플리케이션을 제공하기 위한 에지 컴퓨팅 시스템을 도시한다. 에지 컴퓨팅 시스템의 구현은 원격 통신 서비스 제공자(\"통신사\" 또는 \"TSP\"), 사물 인터넷 서비스 제공자, 클라우드 서비스 제공자 (cloud service provider)(CSP), 엔터프라이즈 엔티티 또는 다른 임의의 수의 엔티티에서 또는 이를 대신하여 제공될 수 있다. 시스템의 다양한 구현 및 구성은 이를테면 서비스 목표를 충족하도록 조정될 때 동적으 로 제공될 수 있다. 에지 컴퓨팅 시스템의 개개의 노드 또는 디바이스는 계층(200, 210, 220, 230, 240)에 대응하는 특정 계층 에 위치한다. 예를 들어, 클라이언트 컴퓨트 노드는 엔드포인트 계층에 있는 반면, 에지 게이트웨이 노드는 에지 컴퓨팅 시스템의 에지 디바이스 계층(로컬 레벨)에 있다. 또한, 에지 집계 노드 (및/또는 포그 네트워킹 구성과 함께 또는 그 사이에서 배열되거나 동작되는 경우라면, 포그 디바이 스)는 네트워크 액세스 계층(중간 레벨)에 있다. 일반적으로 포그 컴퓨팅(또는 \"포깅(fogging)\")은 전형적으로 조정된 분산 또는 다중 노드 네트워크에서, 클라우드 컴퓨팅을 엔터프라이즈 네트워크의 에지로 확 장하는 것 또는 클라우드/에지 환경 전반에 걸쳐 트랜잭션을 관리하는 역량으로 확장하는 것을 말한다. 일부 형태의 포그 컴퓨팅은 클라우드 컴퓨팅 위치를 대신하여, 최종 디바이스와 클라우드 컴퓨팅 데이터 센터 사이에 서 컴퓨트, 저장소 및 네트워킹 서비스의 배치를 제공한다. 일부 형태의 포그 컴퓨팅은 또한, 전체 트랜잭션 측면에서, 전체 서비스 레벨 협약을 이행하는 역량에 기초하여 특정 워크로드를 에지 또는 클라우드 쪽으로 푸 시함으로써 워크로드/워크플로우 레벨 서비스를 관리하는 역량을 제공한다. 많은 시나리오에서 포그 컴퓨팅은 하나 이상의 에지 노드 디바이스와 협력함으로써 탈중앙집중화된 아키텍처를 제공하고 클라우드 컴퓨팅으로 확장하는 역할을 하여, 향후에 지역화되는 수량의 제어, 구성 및 관리 등을 최종 디바이스에 제공한다. 또한 포그 컴퓨팅은 컴퓨팅, 저장소 또는 연결성 관련 서비스를 완료하기 위해 단독으로 또는 클라우드 컴퓨팅과 함께 사용될 수 있는 에지-로컬 클라우드를 생성하기 위해 에지 자원이 유사한 자원을 식별하고 협업할 수 있는 역량을 제공한다. 포그 컴퓨팅은 또한 클라우드 기반 서비스가 디바이스의 네트워크 의 에지까지 도달 범위를 확장하여 에지 디바이스에 대해 로컬 및 더 빠른 접근성을 제공할 수 있다. 따라서, 일부 형태의 포그 컴퓨팅은 본 명세서에서 논의된 바와 같은 에지 컴퓨팅과 일치하는 동작을 제공하며; 본 명세 서에서 논의된 에지 컴퓨팅 양상은 포그 네트워크, 포깅 및 포그 구성에도 적용 가능한다. 또한, 본 명세서에 서 논의되는 에지 컴퓨팅 시스템의 양상은 포그로서 구성될 수 있거나, 또는 포그의 양태는 에지 컴퓨팅 아키텍 처에 통합될 수 있다. 코어 데이터 센터는 코어 네트워크 계층(로컬 또는 지리적 중심 레벨)에 위치하는 반면, 글로벌 네트 워크 클라우드는 클라우드 데이터 센터 계층(국가 또는 전 세계 계층)에 위치한다. \"코어\"의 사용은 다수의 에지 노드 또는 컴포넌트에 의해 액세스 가능한 중앙의 네트워크 위치 - 네트워크에서 더 깊은 곳 - 의 용어로서 제공되며; 그러나 \"코어\"가 반드시 \"중심\" 또는 네트워크의 가장 깊은 위치를 지정하는 것은 아니다. 따라서 코어 데이터 센터는 에지 클라우드 내부에, 그 곳에 또는 그 근처에 위치할 수 있다. 클라이 언트 컴퓨트 노드, 에지 게이트웨이 노드, 에지 집계 노드, 에지 코어 데이터 센터, 글로 벌 네트워크 클라우드의 예시적인 수가 도 3에 도시되어 있지만, 에지 컴퓨팅 시스템은 각 계층에서 추가 디바이스 또는 시스템을 포함할 수 있다는 것을 인식해야 한다. 임의의 계층에 있는 디바이스는 서로 피 어 노드로서 구성될 수 있으며, 이에 따라 협업 방식으로 작동하여 서비스 목표를 충족할 수 있다. 또한, 도 3 에 도시된 바와 같이, 각 계층(200, 210, 220, 230, 240)의 컴포넌트의 수는 일반적으로 각각의 더 낮은 레벨에 서(예를 들어, 엔드포인트에 더 가까이 이동될 때) 증가한다. 이와 같이, 하나의 에지 게이트웨이 노드는 다수의 클라이언트 컴퓨트 노드를 서비스할 수 있고, 하나의 에지 집계 노드는 다수의 에지 게이트웨 이 노드를 서비스할 수 있다. 본 명세서에서 제공되는 예와 일관하여, 클라이언트 컴퓨트 노드는 데이터의 생산자 또는 소비자로서 통신 할 수 있는 임의의 유형의 엔드포인트 컴포넌트, 디바이스, 어플라이언스 또는 다른 사물로서 구현될 수 있다. 또한, 에지 컴퓨팅 시스템에서 사용되는 \"노드\" 또는 \"디바이스\"이라는 레이블은 그러한 노드 또는 디바이 스가 반드시 클라이언트 또는 슬레이브 역할로 동작한다는 것을 의미하지는 않고; 오히려 에지 컴퓨팅 시스템 의 임의의 노드 또는 디바이스는 에지 클라우드를 용이하게 하거나 사용하는 개별 또는 연결된 하드 웨어 또는 소프트웨어 구성을 포함하는 개별 엔티티, 노드 또는 서브시스템을 지칭한다. 이와 같이, 에지 클라우드는 계층(210, 220)의 에지 게이트웨이 노드 및 에지 집계 노드에 의해 그리고 이러한 노드 내에서 각기 동작되는 네트워크 컴포넌트 및 기능적 특징으로부터 형성된다. 에지 클라우 드는 도 3에서 클라이언트 컴퓨트 노드로서 도시되는, 무선 액세스 네트워크(RAN) 가능 엔드포인트 디바이스(예를 들어, 모바일 컴퓨팅 디바이스, IoT 디바이스, 스마트 디바이스 등)에 근접하게 위치한 에지 컴퓨팅 및/또는 스토리지 자원을 제공하는 임의의 유형의 네트워크로서 구현될 수 있다. 다시 말해서, 에지 클라 우드는 엔드포인트 디바이스와 통상의 네트워크 액세스 포인트를 연결하는 - 모바일 캐리어 네트워크(예를 들어, 글로벌 모바일 통신 시스템(Global System for Mobile Communications)(GSM) 네트워크, 롱 텀 에볼루션 (Long-Term Evolution)(LTE) 네트워크, 5G/6G 네트워크 등)를 비롯한 서비스 제공자 코어 네트워크로의 진입 지 점(ingress point)으로서 역할을 하면서 저장소 및/또는 컴퓨트 캐퍼빌리티를 또한 제공하는 - \"에지\"로서 구상 될 수 있다. 다른 유형 및 형태의 네트워크 액세스(예를 들어, Wi-Fi, 광학 네트워크를 포함하는 장거리 무선, 유선 네트워크)가 또한 이러한 3GPP 캐리어 네트워크 대신에 또는 이와 결합하여 이용될 수 있다. 일부 예에서, 에지 클라우드는 특정 기능을 수행하도록 자원 및 서비스를 분배하는 시스템 레벨의 수평적 인 분산 아키텍처로서 구현될 수 있는, 포그 네트워킹 구성(예를 들어, 포그 디바이스의 네트워크, 상세히 도시되지 않음)의 일부를 형성하거나 그렇지 않으면 포그 네트워킹 구성으로의 진입 지점 또는 이를 가 로지르는 진입 지점을 제공할 수 있다. 예를 들어, 포그 디바이스의 조정되고 분산된 네트워크는 IoT 시 스템 배열의 컨텍스트에서 컴퓨팅, 저장, 제어 또는 네트워킹의 양상을 수행할 수 있다. 다른 네트워크화되고, 통합되고 분산된 기능이 코어 데이터 센터와 클라이언트 엔드포인트(예를 들어, 클라이언트 컴퓨트 노드 ) 사이의 에지 클라우드에서 존재할 수 있다. 이러한 기능 중 일부는 다수의 이해 관계자를 위해 조 정된 가상 에지 및 가상 서비스의 사용을 비롯한, 네트워크 기능 또는 서비스 가상화의 컨텍스트에서 다음 섹션 에서 논의된다. 아래에서 보다 상세히 논의되는 바와 같이, 에지 게이트웨이 노드는 및 에지 집계 노드는 다양한 에 지 서비스 및 보안을 클라이언트 컴퓨트 노드에 제공하기 위해 협력한다. 더욱이, 클라이언트 컴퓨트 노 드가 고정적 또는 이동적일 수 있기 때문에, 각자의 에지 게이트웨이 노드는 대응하는 클라이언트 컴 퓨트 노드가 지역 여기저기로 이동함에 따라 다른 에지 게이트웨이 디바이스와 협력하여 현재 제공되는 에지 서 비스, 관련 서비스 데이터 및 보안을 전파할 수 있다. 이를 위해, 에지 게이트웨이 노드 및/또는 에지 집 계 노드는 다수의 서비스 제공자, 소유자 및 다수의 소비자로부터의 (또는 이들을 위해 호스팅되는) 서비 스가 단일 또는 다수의 컴퓨트 디바이스에 걸쳐 지원되고 조정될 수 있는 다중 테넌시(multiple tenancy) 및 다 중 이해 관계자 구성을 지원할 수 있다. 에지 클라우드의 아키텍처 내에서 다양한 보안 접근 방식이 이용될 수 있다. 다중 이해 관계자 환경에서, 이해 관계자의 이익을 집행하는 정책을 프로비저닝하는데 사용되는 다수의 로드 가능 보안 모듈(loadable security module)(LSM)이 있을 수 있다. 시행 지점(enforcement point) 환경은 (예를 들어, 가장 많이 제약된 효과적인 정책이 적용되는 경우, 이를테면 A, B 또는 C 중 임의의 이해 관계자가 액세스를 제약하면, 액세스가 제약되는 경우) 로드된 LSM 정책의 조합을 적용하는 다수의 LSM을 지원할 수 있다. 에지 클라우드 내에서, 각각의 에지 엔티티는 에지 엔티티 이익을 집행하는 LSM을 프로비저닝할 수 있다. 클라우드 엔티티는 클라우드 엔티티 이익을 집행하는 LSM을 프로비저닝할 수 있다. 마찬가지로, 다양한 포그 및 IoT 네트워크 엔 티티는 포그 엔티티의 이익을 집행하는 LSM을 프로비저닝할 수 있다. 이러한 예에서, 서비스는 구성요소 레벨 또는 사람이 인지할 수 있는 레벨에서 고려되든지 간에, 한 세트의 계 약 또는 구성요소에 대해 수행되는 트랜잭션의 관점에서 고려될 수 있다. 따라서, 서비스 제공자와 서비스 협 약을 맺은 사용자는 SLA의 조건에 따라 서비스가 전달될 것으로 예상한다. 상세히 논의되지는 않았지만, 본 명 세서에서 논의된 에지 컴퓨팅 기술의 사용은 협약의 협상 및 협약 이행의 측정(시스템에 의해 서비스를 수행하 는 데 어떤 요소가 필요한 요소인지, 시스템이 서비스 조건 및 변경 등에 어떻게 대응할지 등을 식별하는) 동안 역할을 할 수 있다. \"서비스\"는 종종 다양한 컨텍스트에 적용되는 광범위한 용어이지만, 일반적으로는 한 엔티티가 다른 엔티티의 이익을 위해 작업을 제공하고 수행하는 두 엔티티 간의 관계를 말한다. 그러나 한 엔티티로부터 다른 엔티티로 전달되는 서비스는 엔티티 간의 신뢰를 보장하고 서비스 시작시, 서비스 중, 서비스의 종료시 제시된 계약 조건 및 사정에 따라 트랜잭션을 관리하는 특정 지침에 따라 수행되어야 한다. 에지 컴퓨팅 시스템에서 사용하기 위한 서비스 사이의 예시적인 관계가 도 4에 도시된다. 에지 컴퓨팅 시나리 오에서, 운영 중이고 서로 종속적인 여러 서비스 및 트랜잭션 계층 있다 - 이러한 서비스는 \"서비스 체인 (service chain)\"을 생성한다. 가장 낮은 레벨에 있는 구성요소가 시스템을 구성한다. 이러한 시스템(또는 자 원)은 서로에게뿐만 아니라 주변의 다른 영구적인 또는 일시적인 엔티티에게 다수의 서비스를 제공하기 위해 서 로 통신하고 협업한다. 차례로, 이러한 엔티티는 사람이 소비할 수 있는 서비스를 제공할 수 있다. 이러한 계 층을 통해, 각 계층에서 제공되는 서비스는 서비스를 제공하는 개별 컴포넌트(또는 서브엔티티)가 계약 상 합의된 목표 및 규격을 고수하도록 보장하기 위해 트랜잭션 방식으로 연결되어야 한다. 각 계층에서의 편차는 전체 서비스 체인에 전반적인 영향을 미치는 결과를 가져올 수 있다. 도 4에 도시된 계층 구조에서 제공될 수 있는 하나의 서비스 유형은 실리콘 레벨 서비스(Silicon Level Service)이다. 예를 들어, 소프트웨어 정의 실리콘(Software Defined Silicon)(SDSi) 유형의 하드웨어는 운영 서비스 레벨 협약의 전달을 인트라-스케일(intra-scale)하고, 관리하고 보장하는 역량을 통해 트랜잭션에 대해 낮은 레벨의 고수를 보장하는 역량을 제공한다. SDSi 및 유사한 하드웨어 제어를 사용하게 되면 시스템 내의 특징과 자원을 특정 테넌트에 연관시키고 그러한 자원에 대한 개별 타이틀(권한)을 관리하는 캐퍼빌리티가 제공 된다. 이러한 특징을 사용하는 것은 컴퓨트 자원을 워크로드에 동적으로 \"가져 오는\" 방법 중 하나이다. 예를 들어 운영 레벨 협약은 \"트랜잭션 처리량\" 또는 \"적시성(timeliness)\"을 정의할 수 있다 - SDSi의 경우, 시스템(또는 자원)은 서비스 레벨 협약(service level agreement)(SLA)의 특정 서비스 레벨 사양(service level specification)(SLS) 및 서비스 레벨 목표(service level objective)(SLO)를 보증하기 위해 계약할 수 있다. SDSi 하드웨어는 또한 인프라스트럭처 및 자원 소유자가 제품 특징에 액세스 및 관리(추가/제 거)하여 하드웨어 캐퍼빌리티 및 활용을 자유롭게 확장 및 축소하도록 실리콘 컴포넌트(예를 들어, 메트릭 원격 측정(metric telemetry)을 생성하는 구성된 시스템의 컴포넌트)에 권한을 부여할 수 있는 역량을 제 공한다. 또한, 이것은 테넌트별로 결정론적 특징 할당을 제공하는 역량을 제공한다. 이것은 또한 실행 중인 서비스, 클라이언트 동작을 중단시킬 필요 없이 또는 시스템을 재설정 또는 재부팅함으로써 결정론적 오케스트 레이션 및 서비스 관리를 특징의 동적(또는 구독 기반의) 활성화에 결부시키는 캐퍼빌리티를 제공한다. 최하위 계층에서, SDSi는 단일 자원이 시스템 내에서 제공해야 하는 계약 상 합의된 서비스 레벨 사양을 반드시 적극적으로 고수하도록 시스템에 서비스 및 보증을 제공할 수 있다. 또한, SDSi는 컴포넌트 당 하나 이상의 테 넌트의 계약 권한(타이틀), 사용량 및 연관된 재무를 관리하는, 또는 심지어 실리콘 레벨 특징(예를 들어, SKU 특징) 조차도 관리하는 역량을 제공한다. 실리콘 레벨 특징은 컴퓨트, 저장소 또는 네트워크 캐퍼빌리티, 성능, 결정성 또는 심지어는 보안, 암호화, 가속화 등에 대한 특징과도 연관될 수 있다. 이러한 캐퍼빌리티는 테넌트가 특정 서비스 레벨 협약을 달성할 수 있도록 하는 것뿐만 아니라 관리 및 데이터 수집을 지원할 수 있 도록 보장하며, 트랜잭션 및 계약 협약을 최저의 관리 가능한 컴포넌트 레벨에서 보장한다. 서비스 계층 구조의 상위 계층인 자원 레벨 서비스(Resource Level Service)는 SDSi를 통해 또는 개별적으로 어 드레싱 가능한 자원(컴퓨트, 스토리지 및 네트워크)의 구성을 통해 시스템 레벨 특징을 획득하고 가능하게 함으 로써 워크로드 수요를 충족하는 역량을 (완전히 또는 구성을 통해) 제공하는 시스템을 포함한다. 서비스 계층 구조의 상위 계층인 워크플로우 레벨 서비스(Workflow Level Service)는 서비스 체인에 워크플로우 레벨 요구 사항이 있을 수 있으므로 수평적이다. 워크플로우는 특정 서비스 레벨 목표 및 요구 사항을 엔드 투 엔드 서비스에 제공하기 위해 워크로드 간의 종속성을 설명한다. 이러한 서비스는 고 가용성(high- availability), 중복성, 복구, 내고장성(fault tolerance) 또는 로드-레벨링과 같은 특징 및 기능을 포함할 수 있다. 워크플로우 서비스는 자원과 시스템 간의 종속성 및 관계를 정의하고, 연관된 네트워크와 저장소에 관한 요구 사항을 설명하고, 뿐만 아니라 엔드 투 엔드 서비스를 보장하기 위해 트랜잭션 레벨 요구 사항 및 연관된 계약을 설명한다. 워크플로우 레벨 서비스는 보통 서비스 레벨 목표(Service Level Objective)에서 측정되며 필수 및 예상된 서비스 요구 사항을 갖는다. 서비스 계층 구조의 상위 계층인 비즈니스 기능 서비스(Business Functional Service)(BFS))가 운영 가능하며, 이러한 서비스는 서로 관계를 맺고 고객에게 특정 기능을 제공하는 서비스의 상이한 요소이다. 에지 컴퓨팅의 경우에 있어서 그리고 자율 주행의 예에서, 비즈니스 기능은 예를 들어 \"이벤트에 적시에 도착\"하는 서비스를 구성하는 것일 수 있다 - 이러한 서비스는 여러 비즈니스 기능이 함께 작동하고 협력하여 사용자 엔티티의 목적: GPS 안내, RSU(도로변 유닛)(Road Side Unit)의 지역 교통 상황 인식, 사용자 엔티티의 지불 내역, 사용 자 엔티티의 자원(들)에 대한 승인 등을 달성해야 할 것이다. 또한, 이러한 BFS는 다수의 엔티티에게 서비스를 제공하므로, 각각의 BFS는 자체 SLA를 관리하고 자체 자원(워크로드 및 워크플로우)에서 수요를 처리하는 역량 을 인식하고 있다. 요구 사항 및 수요가 증가함에 따라, 이것은 서비스 변경 요구 사항을 워크플로우 및 자원 레벨 서비스 엔티티에 전달하여, 이러한 엔티티가 차례로 이행 역량에 대한 통찰력을 제공할 수 있도록 한다. 이러한 단계는 전체 트랜잭션 및 서비스를 다음 계층으로 전달하는 데 도움이 된다. 서비스 계층 구조에서 최고의 서비스 계층인 비즈니스 레벨 서비스(Business Level Service)(BLS)는 제공되는 캐퍼빌리티와 결부된다. 이 레벨에서, 고객 또는 엔티티는 서비스가 어떻게 구성되어 있는지 또는 서비스(들) 를 제공하기 위해 어떤 구성요소가 사용되고, 관리되고, 추적되는지에 대해 신경 쓰지 않을 수 있다. 비즈니스레벨 서비스의 주요 목표는 합의된 금융 협약에서 고객과 제공자 사이에 설정된 전체 계약 조건 및 사정에 따라 고객에 의해 설정된 목적을 달성하는 것이다. BLS(들)는 여러 비즈니스 기능 서비스(BFS) 및 전체 SLA로 구성 된다. 본 명세서에서 설명된 이러한 배열 및 다른 서비스 관리 특징은 고유하고 복잡한 자원 및 서비스 상호작용을 통 해 에지 컴퓨팅의 다양한 요구 사항을 충족시키도록 설계된다. 이러한 서비스 관리 배열은 에이전트 또는 미들 웨어 캐퍼빌리티를 통하는 대신, 본래 자신의 프레임워크 내부에서 여러 자원 기본 서비스를 다루려 의도된다. 찾기, 발견하기, 어드레스 지정, 추적, 뒤쫓기, 식별, 등록과 같은 서비스는 자원이 프레임워크에 출현할 때 즉 시 시행될 수 있으며, 자원 또는 보안 도메인의 관리자 또는 소유자는 관리 규칙 및 정책을 사용하여 질서 정연 한 자원 발견, 등록 및 인증을 보장할 수 있다. 더욱이, 본 명세서에서 설명된 임의의 수의 에지 컴퓨팅 아키텍처는 서비스 관리 특징에 적응될 수 있다. 이러 한 특징은 시스템이 자원의 움직임, 벡터 및 방향에 대한 정보를 지속적으로 인식하고 기록할 수 있게 할뿐만 아니라 이러한 특징을 디바이스와 연관된 원격 측정 및 메타데이터로서 완전히 설명할 수 있게 할 수 있다. 이 러한 서비스 관리 특징은 보안 요소뿐만 아니라, 자원 관리, 과금 및 계량(metering)에 사용할 수 있다. 센서 와 같이 덜 지능적인 디바이스가 에지 게이트웨이와 같이 보다 관리 용이한 자원에 연결될 수 있는 관련 자원에 도 동일한 기능성이 또한 적용된다. 서비스 관리 프레임워크는 자원에 대한 보관 또는 캡슐화의 변경을 인식한 다. 노드 및 컴포넌트는 부모(parent) 또는 대체의 책임질 디바이스를 통해 짧은 지속기간 동안 또는 전체 수 명주기 동안 직접 액세스될 수 있거나 간접적으로 관리될 수 있으므로, 이러한 유형의 구조는 인터페이스를 통 해 서비스 프레임워크로 전달되고 외부의 쿼리 메커니즘에서 이용될 수 있다. 또한, 이러한 서비스 관리 프레임워크는 서비스를 인식하고 있으며 서비스 제공 요구 사항을 자원의 캐퍼빌리티 및 가용성, 데이터 분석 시스템에 업로드할 데이터에 액세스와 자연스럽게 균형을 유지한다. 네트워크 전송이 저하되거나, 실패하거나 또는 더 높은 비용 또는 더 낮은 대역폭 기능으로 변경되면, 서비스 정책 모니터링 기 능은 사용자의 프라이버시 또는 비용 제약 조건 내에서 대체 분석 및 서비스 전달 메커니즘을 제공한다. 이러 한 기능을 통해, 정책은 에지에서 분석 및 대시보드 서비스의 호출을 트리거하여 충실도(fidelity) 또는 세분화 (granularity)를 줄인 상태에서 지속적인 서비스 가용성을 보장할 수 있다. 네트워크 전송이 재설정되면, 정기 적인 데이터 수집, 업로드 및 분석 서비스가 재개될 수 있다. A. 에지 컴퓨팅 구성 및 배열 다중 이해 관계자 에지 컴퓨팅 시스템의 배치는 다수의 테넌트 및 서비스 제공자가 사용하도록 하기 위해, 다수 의 에지 노드 및 서브시스템 사이에서 다수의 서비스 및 가상 에지 인스턴스를 배치할 수 있도록 배열되고 조직 될 수 있다. 클라우드 서비스 제공자(CSP)에 적용 가능한 시스템 예에서, 에지 컴퓨팅 시스템의 배치는 에지 컴퓨팅 노드를 클라우드 컴퓨팅에 대한 보충 도구로서 도입하는 \"오버 더 톱(over-the-top)\" 접근 방식을 통해 제공될 수 있다. 원격 통신 서비스 제공자(telecommunications service provider)(TSP)에 적용 가능한 대조적 인 시스템의 예에서, 에지 컴퓨팅 시스템의 배치는 (상이한 유형의 데이터 액세스 네트워크로부터) 네트워크 액 세스가 집계되는 위치에 에지 컴퓨팅 노드를 도입하는 \"네트워크 집계(network-aggregation)\" 접근 방식을 통해 제공될 수 있다. 도 5 및 도 6은 각각의 에지 컴퓨팅 시스템에서 네트워킹 및 서비스에 대한 이러한 오버-더- 톱 및 네트워크 집계 접근 방식을 도시한다. 그러나 이러한 오버-더-톱 및 네트워크 집계 접근 방식은 이후의 예에서 제안된 바와 같이 하이브리드 또는 병합식 접근 방식 또는 구성에서 함께 구현될 수 있다. 도 5에서, (모바일 디바이스, 컴퓨터, 자율 주행 차량, 비즈니스 컴퓨팅 장비, 산업용 처리 장비의 형태의) 다 양한 클라이언트 엔드 포인트는 서비스 또는 데이터 트랜잭션에 대한 요청 및 서비스 또는 데이터 트 랜잭션에 대한 응답을, (예를 들어, 무선 또는 유선 네트워크를 통해) 에지 클라우드로 및 에지 클라우드로부터 제공한다. 에지 클라우드 내에서, CSP는 에지 콘텐츠 노드와 같은 다양한 컴퓨 트 및 스토리지 자원을 배치하여 분산 콘텐츠 전송 네트워크(distributed content delivery network)로부터 캐 싱된 콘텐츠를 제공할 수 있다. 에지 콘텐츠 노드에서 이용 가능한 다른 가용 컴퓨트 및 스토리지 자원은 다른 서비스를 실행하고 다른 워크로드를 실행하는 데 사용될 수 있다. 에지 클라우드의 에지 콘텐츠 노 드 및 다른 시스템은 백홀 네트워크를 사용하여 클라우드/데이터 센터로부터의 웹사이트, 애플리케이 션, 데이터베이스 서버 등에 대한 더 긴 지연시간의 요청을 이행하는 클라우드 또는 데이터 센터에 연결된 다. 도 6에서, (모바일 디바이스, 컴퓨터, 자율 주행 차량, 비즈니스 컴퓨팅 장비, 산업용 처리 장비의 형태의) 다 양한 클라이언트 엔드 포인트는 엔드 포인트 네트워크 집계의 유형에 특유한 요청과 응답을 교환한다. 예를 들어, 컴퓨터, 비즈니스 컴퓨팅 장비 및 산업용 처리 장비는 온-프레미스 네트워크 시스템을 통해 요청 과 응답을 교환함으로써 유선 광대역 네트워크를 통해 네트워크 액세스를 획득할 수 있다. 모바일 컴퓨팅 디바 이스는 셀룰러 네트워크 타워를 통해 요청과 응답을 교환함으로써 무선 광대역 네트워크를 통해 네트워크 액세스를 획득할 수 있다. 자율 주행 차량은 거리에 위치한 네트워크 시스템을 통하고 무선 차량 네트워 크를 통해 요청 및 응답의 네트워크 액세스를 획득할 수 있다. 그러나 네트워크 액세스의 유형에 관계없이, TSP는 에지 클라우드 내에 집계 지점(642, 644)을 배치하여 트래픽 및 요청을 집계할 수 있다. 따라서, 에지 클라우드 내에서, TSP는 에지 집계 노드와 같은 다양한 컴퓨트 및 스토리지 자원을 배치하여 요 청된 콘텐츠를 제공할 수 있다. 에지 클라우드의 에지 집계 노드 및 다른 시스템은 백홀 네트워크 를 사용하여 클라우드/데이터 센터로부터의 웹사이트, 애플리케이션, 데이터베이스 서버 등에 대한 더 긴 지연시간의 요청을 이행하는 클라우드 또는 데이터 센터에 연결된다. (단일 서버 프레임워크 상에 배치되 는 것을 비롯하여, 에지 집계 노드 및 집계 지점(642, 644)의 추가 또는 통합 인스턴스는 또한 에지 클라 우드 또는 TSP 인프라스트럭처의 다른 영역 내에 존재할 수 있다). CSP 또는 TSP 구성의 확장으로서, 도 7 및 도 8은 다수의 에지 노드와 다수의 테넌트 사이에서 동작하는 에지 컴퓨팅 시스템에 걸쳐 가상 에지 구성을 위한 배치 및 오케스트레이션을 도시한다. 구체적으로, 도 7은 다양한 가상 에지 인스턴스에 액세스하는 다양한 클라이언트 엔드포인트(예를 들어, 스마트 시티/빌딩 시스템, 모 바일 디바이스, 컴퓨팅 디바이스, 비즈니스/물류 시스템, 산업 시스템 등)에 대한 요청 및 응답을 이행하는 에 지 컴퓨팅 시스템의 제 1 에지 노드 및 제 2 에지 노드의 조정을 도시한다. 도 5 및 6의 예와 유사하게, 가상 에지 인스턴스는 웹 사이트, 애플리케이션, 데이터베이스 서버 등에 대해 더 긴 지연시간의 요 청을 위해 클라우드/데이터 센터로의 액세스를 통해, 에지 클라우드에서 에지 컴퓨팅 캐퍼빌리티 및 처리 를 제공한다. 그러나 에지 클라우드는 다수의 테넌트 또는 엔티티를 위한 다수의 에지 노드 사이에서 처리를 조정할 수 있게 한다. 도 7의 예에서, 이러한 가상 에지 인스턴스는: 에지 스토리지, 컴퓨팅 및 서비스의 제 1 조합을 제공하는, 제 1 테넌트(테넌트 1)에 제공되는 제 1 가상 에지; 및 에지 스토리지, 컴퓨팅 및 서비스의 제 2 조합을 제공하 는 제 2 가상 에지를 포함한다. 가상 에지 인스턴스(732, 734)는 에지 노드(722, 724) 사이에 분산되고, 요청 및 응답이 동일한 또는 상이한 에지 노드로부터 이행되는 시나리오를 포함할 수 있다. 분산되었지만 조정 된 방식으로 동작하는 에지 노드(722, 724)의 구성은 에지 프로비저닝 기능에 기초하여 발생한다. 다수의 테넌트 사이에서, 애플리케이션 및 서비스에 대해 조정된 동작을 제공하는 에지 노드(722, 724)의 기능성은 오 케스트레이션 기능에 기초하여 발생한다. 에서 디바이스 중 일부는 테넌트 1이 tenant1 '슬라이스' 내에서 기능할 수 있는 반면 테넌트 2가 tenant2 슬라이스 내에서 기능할 수 있는 다중 테넌트 디바이스라는 것을 이해해야 한다(그리고 추가 예에서, 추가 또는 서브테넌트가 존재할 수 있으며; 심지어 각각의 테넌트는 특정 하드웨어 특징에 대해 하루 종일 특정 세트의 특 징에 특별하게 권리를 가질 수 있고 트랜잭션 방식으로 결부될 수도 있다). 신뢰성 있는 다중 테넌트 디바이스 는 키와 슬라이스의 조합이 \"신뢰점(root of trust)(RoT)\" 또는 테넌트 특정 RoT로 간주될 수 있도록 테넌트 특 정 암호화 키를 더 포함할 수 있다. RoT는 또한 동적으로 구성된 디바이스 아이덴티티 구성 엔진(Device Identity Composition Engine)(DICE) 아키텍처를 사용하여 연산되어 단일 DICE 하드웨어 빌딩 블록이 (필드 프 로그램 가능 게이트 어레이(Field Programmable Gate Array)(FPGA)와 같은) 디바이스 캐퍼빌리티의 계층화를 위한 계층화된 신뢰성 있는 컴퓨팅 기반 컨텍스트를 구성하는 데 사용될 수 있도록 한다. RoT는 또한 다중 테 넌시를 지원하는 데 유용한 \"팬-아웃(fan-out)\"을 가능하게 하는 신뢰성 있는 컴퓨팅 컨텍스트에 사용될 수 있 다. 다중 테넌트 환경 내에서, 각각의 에지 노드(722, 724)는 노드 당 다중 테넌트에 할당된 로컬 자원에 대한 LSM 또는 보안 기능 시행 지점으로서 동작할 수 있다. 또한, (예를 들어, 인스턴스(732, 734)에서) 테넌트 런 타임 및 애플리케이션 실행은 어쩌면 다수의 물리적 호스팅 플랫폼에 이어져 있는 자원의 가상 에지 추상화를 생성하는 LSM 또는 다른 보안 특징에 대한 시행 지점으로서 역할을 할 수 있다. 마지막으로, 오케스트레이션 엔티티의 오케스트레이션 기능은 테넌트 경계를 따라 자원을 집결하기 위한 LSM 또는 보안 기능 시행 지점 으로서 동작할 수 있다. 에지 컴퓨팅 노드는 자원(메모리, CPU, GPU, 인터럽트 제어기, I/O 제어기, 메모리 제어기, 버스 제어기 등)을 분할할 수 있으며, 여기서 각각의 파티셔닝에는 RoT 캐퍼빌리티가 포함될 수 있고 DICE 모델에 따른 팬-아웃 및 계층화가 또한 에지 노드에 적용될 수 있다. 컨테이너, FaaS 엔진, 서브렛(Servlet), 서버 또는 다른 컴퓨테이 션 추상화로 구성된 클라우드 컴퓨팅 노드는 DICE 계층화 및 팬-아웃 구조에 따라 분할되어 각각에 RoT 컨텍스 트를 지원할 수 있다. 따라서, 디바이스(710, 722, 740)에 이어져 있는 각자의 RoT는 신뢰성 있는 분산 컴퓨팅기반(distributed trusted computing base)(DTCB)의 설정을 조정하여 모든 요소를 엔드 투 엔드로 연결하는 테 넌트 특정 신뢰성 있는 가상 보안 채널(tenant-specific virtual trusted secure channel)이 설정될 수 있도록 할 수 있다. 도 8의 예에서, 에지 컴퓨팅 시스템은 다중 소유자, 다중 테넌트 환경에서 컨테이너(container)(코드 및 필요한 종속성을 제공하는 내장된 배치 가능한 소프트웨어 유닛)를 사용하여 다중 애플리케이션의 오케스트레이 션을 제공하도록 확장된다. 다중 테넌트 오케스트레이터는 키 관리, 신뢰 앵커 관리 및 도 7의 신뢰성 있는 ' 슬라이스(slice)' 개념의 프로비저닝 및 수명주기와 관련된 다른 보안 기능을 수행하는 데 사용될 수 있다. 오 케스트레이터는 DICE 계층화 및 팬-아웃 구성을 사용하여 테넌트에 특유한 신뢰점 컨텍스트를 생성할 수 있다. 따라서, 아래에서 논의되는 오케스트레이터에 의해 제공되는 오케스트레이션 기능은 테넌트 특정 오케스트 레이션 제공자로서 참여할 수 있다. 도 7의 시나리오와 유사하게, 에지 컴퓨팅 시스템은 다수의 가상 에지 인스턴스로부터 (및 도시되지 않은 클라우드 또는 원격 데이터 센터로부터) 다양한 클라이언트 엔드포인트에 대한 요청 및 응답을 이행하도록 구성된다. 이러한 가상 에지 인스턴스의 사용은 다수의 테넌트 및 다수의 애플리케이션(예를 들어, 증강 현실 (augmented reality)(AR)/가상 현실(virtual reality)(VR), 엔터프라이즈 애플리케이션, 콘텐츠 전송, 게임, 컴퓨팅 오프로드)을 동시에 지원한다. 또한, 가상 에지 인스턴스 내에는 다수의 유형의 애플리케이션(예를 들 어, 보통의 애플리케이션; 지연시간에 민감한 애플리케이션; 지연시간이 임계적인 애플리케이션; 사용자 평면 애플리케이션; 네트워킹 애플리케이션 등)이 있을 수 있다. 가상 에지 인스턴스는 또한 상이한 지리적 위치에 서 (또는 다수의 소유자에 의해 공동 소유되거나 공동 관리되는 각자의 컴퓨팅 시스템 및 자원에서) 다수의 소 유자의 시스템에 이어져 있을 수 있다. 에지 클라우드 내에서, (제 1 소유자에 의해 동작되는) 제 1 에지 노드 및 (제 2 소유자에 의해 동작되는) 제 2 에지 노드는 각각 오케스트레이터를 동작하여 각자의 테넌트에 제공되는 가상 에지 인스턴스 내에서 다양한 애플리케이션의 실행을 조정한다. 에지 노드(820, 830)는 에지 프로비저닝 기능에 기초하여 조정 되는 반면, 다양한 애플리케이션의 동작은 오케스트레이션 기능과 조정된다. 또한, 오케스트레이터는 한 소유자에게 제공되지만 제2 소유자에게는 숨겨지는, 그러나 서비스가 소유자들의 SLA(들)에 따라 완료되도록 보 장하기 위해 소유권 경계를 넘어 제공되는, 특정 하드웨어 특징을 식별할 수 있다. 따라서, 가상 에지, 컨테이 너 오케스트레이터 및 서비스/앱 오케스트레이터는 특정 테넌트에 결부된 노드 특정 자원에 대해 LSM 또는 다른 보안 시행 지점을 제공할 수 있다. 도 9는 에지 컴퓨팅 시스템에 컨테이너를 배치하는 다양한 컴퓨트 배열을 도시한다. 간략화된 예로서, 시스템 배열(910, 920)은 컨테이너 관리자(예를 들어, 컨테이너 관리자(911, 921, 931))가 컴퓨트 노드(배열의 )를 통한 실행을 통해 컨테이너화된 포드(containerized pod), 기능 및 서비스로서의 기능 인스턴스 (functions-as-a-service instance)를 시작하도록 하거나 또는 컴퓨트 노드(배열의 )를 통한 실행을 통해 컨테이너화된 가상화된 네트워크 기능(containerized virtualized network function)을 별도로 실행하도 록 적응된 설정을 도시한다. 이러한 배열은 (컴퓨트 노드를 사용하여) 시스템 배열에서 다수의 테넌 트를 사용하기 위해 적응되며, 여기서 컨테이너화된 포드(예를 들어, 포드), 기능(예를 들어, 기능, VNF(922, 936)) 및 서비스로서의 기능 인스턴스(예를 들어, FaaS 인스턴스)는 (가상화된 네트워크 기능의 실행을 제외하고) 각각의 테넌트에 특유한 가상 머신(예를 들어, 테넌트(932, 933)에 대한 VM(934, 935)) 내에 서 시작된다. 이러한 배열은 또한 컨테이너 기반 오케스트레이션 시스템에 의해 조정되는 것으로, 컨테이 너(942, 943) 또는 다양한 기능, 애플리케이션 및 컴퓨트 노드 상의 기능의 실행을 제공하는 시스템 배열 에서 사용하기 위해 적응된다. 도 8 및 도 9에 도시된 시스템 배열은 애플리케이션 구성의 측면에서 VM, 컨테이너 및 기능을 동일하게 처리하 는 아키텍처를 제공한다(그리고 결과적인 애플리케이션은 이러한 세 개의 구성요소의 조합이다). 각각의 구성 요소는 하나 이상의 가속기(FPGA, ASIC) 컴포넌트를 로컬 백엔드(local backend)로서 사용하는 것을 포함할 수 있다. 이러한 방식으로, 애플리케이션은 오케스트레이터에 의해 조정되는 다수의 에지 소유자에 걸쳐 분할될 수 있다. 도 9의 컨텍스트에서, 컨테이너 관리자, 컨테이너 오케스트레이터 및 개별 노드는 LSM 또는 다른 보안 시행 지 점을 제공할 수 있다. 그러나 도 8 및 도 9의 구성 중 하나에서, 테넌트에 할당된 자원이 제 2 테넌트에 할당 된 자원과 구별되는 테넌트 격리가 오케스트레이션될 수 있지만, 에지 소유자는 자원 할당이 테넌트 경계를 넘 어 공유되지 않도록 보장하기 위해 협력한다. 또는, 자원 할당은, 테넌트가 구독 또는 트랜잭션/계약 기반을통해 \"사용\"할 수 있게 될 수도 있으므로, 테넌트 경계를 넘어 격리될 수 있다. 이러한 컨텍스트에서, 가상화, 컨테이너화, 엔클레이브(enclave) 및 하드웨어 파티셔닝 체계는 에지 소유자에 의해 테넌시를 시행하는 데 사용 될 수 있다. 다른 격리 환경은 베어 메탈(bare metal)(전용) 장비, 가상 머신, 컨테이너, 컨테이너상의 가상 머신 또는 이들의 조합을 포함할 수 있다. 아래에서 추가로 논의되는 FaaS 환경에서 제공되는 것과 같은 기능 은 임의의 이러한 격리 환경에서 실행되어 테넌트 경계를 시행할 수 있다. 도 10a 및 도 10b는 에지 컴퓨팅 시스템의 인스턴스에서 조정된 컴퓨트 기능 및 서비스를 사용하는 분산 에지 컴퓨트 배치를 도시한다. 에지 컴퓨팅 환경 내에서, 지역적으로 위치한 다수의 에지(예를 들어, (1011, 1013, 1014))는 분산 에지(씬 에지 인스턴스((thin edge instances) 또는 클라이언트 PC) 상의 컴 퓨트 자원에 대해 애플리케이션(예를 들어, ) 및 기능(예를 들어, )을 통한 서비스의 실행을 조정 하는 컨테이너 관리자(예를 들어, )를 포함한다. 에지 컴퓨팅 환경 내에서, 분산 에지(씬 에지 인 스턴스)는 추가 처리 캐퍼빌리티를 갖는 다른 분산 에지(대형/중형 에지 인스턴스)와 조정된다. 예를 들어, 특정 분산 에지 인스턴스(씬 에지)에서 동작하는 애플리케이션 또는 기능(예를 들어, (1022 또는 1023))은 (서비스로서의 GPU(GPU-as-a-service) 형태의) 에지 클라우드의 GPU 처리 캐퍼빌리티를 추가로 호출할 수 있고; 또는 다른 예로서, 클라이언트 컴퓨터(클라이언트 PC)에서의 애플리케이션 또는 기능(예를 들어, (1025, 1026))은 (대형/중형 에지 인스턴스에 의해 제공되는, 서비스로서의 암호화 (cryptography-as-a-service)의 형태의) 에지 클라우드의 처리 캐퍼빌리티를 추가로 호출할 수 있다. 다른 애플리케이션, 기능, 서비스로서의 기능 또는 서비스로서의 가속기(accelerator-as-a-service)(예를 들어, (1031, 1032, 1033, 1034))는 (예를 들어, 컴퓨트와 함께) 에지 클라우드에 의해 제공되거나, 조정되거나, 또는 에지 노드 등 사이에서 분산될 수 있다. 또한, 에지 컴퓨팅 아키텍처에서, 각각의 에지 노드, VM, 컨테이너 또는 심지어 베어 메탈 노드는 다른 노드가 서비스로서의 모델(-as-a-service model)에 사 용할 수 있는 한 세트의 제공물(offering)을 생성하기 위해 자체 설명, 자체 인식 및 자체 관리될 수 있다. 추가 예에서, 소프트웨어 정의된 또는 제어된 실리콘 하드웨어 및 다른 구성 가능한 하드웨어의 양태는 도 10a 및 도 10b의 애플리케이션, 기능 및 서비스 및 본 명세서에서 논의되는 다른 시나리오와 통합될 수 있다. 소프 트웨어 정의 실리콘은 (예를 들어, 업그레이드, 재구성 또는 하드웨어 구성 자체 내의 새로운 특징의 프로비저 닝에 의해) 자체의 일부 또는 워크로드를 해결하는 구성요소의 역량에 기초하여, 일부 자원 또는 하드웨어 구성 요소가 계약 또는 서비스 레벨 협약을 이행하는 역량을 보장하는 데 사용될 수 있다. 도 11은 다양한 형태의 에지 컴퓨팅 시스템을 제공하는 에지 메시 사이에서 조정된 에지 컴퓨팅의 구성을 도시 한다. 가장 간단한 예시적 배열은 에지 메시를 보여준다. 보다 고급 배열은 마이크로서비스 (microservice)를 가진 (\"MS\"로 표시되는 마이크로서비스를 가진) 에지 메시의 양태를 동작하는데 사용되는 (\"SC\"로 표시된 사이드 카를 가진) 사이드 카 로딩(side car loading)을 보여준다. 보다 고급 배열은 에지를 가로 질러 연결된 것처럼, 제 1 에지 메시(1130A)가 제 2 에지 메시(1130B)에 연결되어 있는 것을 보여준다. 이러한 환경 내에서, 에지 컴퓨팅 노드에 의해 제공되는 마이크로-서비스는 기능으로 취급될 수 있는 반면, 사 이드-카는 다른 기능과의 연결성을 지원하는 기능이다. 사이드-카의 중요한 특징은 이 특징이 쌍을 이룬 컨테이너 환경과 \"신뢰성 있는 경로\" 관계를 갖는 환경을, LSM 또는 다른 보안 정책 시행 지점에 제공한다는 것이다. 사이드카는 또한 데이터 및 상태를 공유할 수 있다. 사 이드카는 보안 엔클레이브가 신뢰성 있는 실행 환경으로 인식되는 것과 같은 정도로 \"신뢰성 있는\" 또는 \"신뢰 할 수 있는\" 것이 아닐 수 있다; 그러나 사이드카는 쌍을 이룬 컨테이너만큼 적어도 신뢰성 있다고 가정된다. 또한, 사이드카는 상이한 스테이징(staging) 및 필터링이 적용될 수 있는 샌드박스 환경을 제공하기 때문에 외 부 엔티티와의 상호작용을 중개하는 데 종종 사용된다. 이것은 쌍을 이룬 컨테이너에 특유한 애플리케이션 방 화벽과 유사한 기능성을 제공한다. 따라서, 사이드-카는 암호화 키 생성, 저장 및 사용과 같은 보안 기능을 지원하기 위한 신뢰성 있는 실행 환경 을 제공할 수 있다. 사이드-카는 또한 덜 강화된 메시 노드로부터 프라이버시, 지적 재산, 콘텐츠 또는 다른 정보 자산을 보호하는 보안에 민감한 컴퓨테이션을 가능하게 할 수 있다. 또한, 신뢰성 있는 컴퓨팅 캐퍼빌리 티를 갖춘 사이드-카는 마이크로서비스 구성을 피어 마이크로서비스 및 사이드카 노드에 증명할 수 있다. 마이 크로서비스/사이드카 메시 노드의 네스팅(nesting)은 네스팅 구조 또는 메시 구조를 증명하여 올바른/잘못된 구 조, 연결성 및 토폴로지에 대해 마이크로서비스 및 사이드카 노드의 구성이 평가될 수 있도록 할 수 있다. 배열(1110, 1120)에서 제공되는 메시 접근 방식은 기능의 네트워크(캐스케이드)가 존재할 수 있게 한다. 예를 들어, 복잡한 프로그램은 또한 내부-내부-내부 루프 등으로 구성될 수 있는 추가의 여러 내부-내부 루프인 최상단 레벨 '내부 루프'로 구성될 수 있다. 내부 루프의 각각의 네스팅은 가속기 오프로드에 의해 지원될 수 있다. 따라서, 복잡한 또는 조정된 많은 시나리오가 이러한 에지 컴퓨팅 배열을 통해 실시 가능해질 수 있다. 본 명세서에서 논의된 에지 컴퓨팅 시스템 및 배열은 다양한 솔루션, 서비스 및/또는 유스 케이스에 적용될 수 있다는 것을 인식해야 한다. 예로서, 도 12는 에지 클라우드를 구현하는 에지 컴퓨팅 시스템의 애 플리케이션으로의 모바일 액세스가 수반되는 간략화된 차량 컴퓨트 및 통신 유스 케이스를 도시한다. 이러한 유스 케이스에서, 각각의 클라이언트 컴퓨트 노드는 도로를 횡단하는 동안 에지 게이트웨이 노드와 통신하는 대응하는 차량에 위치한 차량 내 컴퓨팅 시스템(예를 들어, 차량 내 네비게이션 및/또는 인포테인먼트 시스템)으로서 구현될 수 있다. 예를 들어, 에지 게이트웨이 노드는 도로를 따라, 도로의 교차로에, 또 는 도로 인근의 다른 위치에 배치될 수 있는 다른 별도의 기계적 유틸리티를 갖는 구조에 내장된 도로변 캐비닛 또는 다른 인클로저에 위치할 수 있다. 각각의 차량이 도로를 따라 횡단함에 따라, 클라이언트 컴퓨트 노드 와 특정 에지 게이트웨이 디바이스 간의 연결이 전파되어 클라이언트 컴퓨트 노드에 대한 일 관된 연결 및 컨텍스트를 유지할 수 있다. 마찬가지로, 모바일 에지 노드는 우선순위가 높은 서비스에서 집계 될 수 있거나 또는 (예를 들어, 드론의 경우) 기본 서비스(들)에 대한 처리량 또는 지연시간 해결 요구 사항에 따라 집계될 수 있다. 각각의 에지 게이트웨이 디바이스는 처리 및 스토리지 캐퍼빌리티의 수량을 포함 하며, 이와 같이 클라이언트 컴퓨트 노드에 대한 데이터의 일부 처리 및/또는 저장은 하나 이상의 에지 게이트웨이 디바이스에서 수행될 수 있다. 에지 게이트웨이 디바이스는 통신 기지국(예를 들어, 셀룰러 네트워크의 기지국)에 위치하는 컴퓨 트 서버, 어플라이언스 또는 컴포넌트로서 예시적으로 구현되는 하나 이상의 에지 자원 노드와 통신할 수 있다. 위에서 논의된 바와 같이, 각각의 에지 자원 노드는 처리 및 스토리지 캐퍼빌리티의 수량을 포함 하며, 이와 같이 클라이언트 컴퓨트 노드에 대한 데이터의 일부 처리 및/또는 저장은 에지 자원 노드 에서 수행될 수 있다. 예를 들어, 긴급하거나 중요함이 덜 한 데이터의 처리는 에지 자원 노드에 의해 수행될 수 있는 반면, 더 높은 긴급성 또는 중요도가 더 높은 데이터 처리는 (예를 들어, 각 컴포넌트의 캐퍼빌리티 또는 긴급성 또는 중요도를 나타내는 요청 내 정보에 따라) 에지 게이트웨이 디바이스에 의해 수행될 수 있다. 데이터 액세스, 데이터 위치 또는 지연시간에 기초하여, 처리 활동 중에 처리 우선순위가 변 경될 때, 에지 자원 노드에서의 작업은 계속될 수 있다. 마찬가지로, 구성 가능한 시스템 또는 하드웨어 자원 자체는 (예를 들어, 로컬 오케스트레이터를 통해) 추가 자원을 제공하도록 활성화되어 새로운 수요를 충족시킬 수 있다(예를 들어, 컴퓨트 자원을 워크로드 데이터에 적응시킬 수 있다). 에지 자원 노드(들)는 또한 중앙 위치(예를 들어, 셀룰러 통신 네트워크의 중앙국)에 위치한 컴퓨트 서버, 어플라이언스 및/또는 다른 컴포넌트를 포함할 수 있는 코어 데이터 센터와 통신한다. 코어 데이 터 센터는 에지 자원 노드(들) 및 에지 게이트웨이 디바이스에 의해 형성된 에지 클라우드 동작을 위해 글로벌 네트워크 클라우드(예를 들어, 인터넷)에 게이트웨이를 제공할 수 있다. 또한, 일부 예에서, 코어 데이터 센터는 처리 및 스토리지 캐퍼빌리티의 수량을 포함할 수 있으며, 이와 같이 클라이언트 컴퓨트 디바이스에 대한 데이터의 일부 처리 및/또는 저장(예를 들어, 낮은 긴급성 또는 중요 도, 또는 높은 복잡성의 처리)은 코어 데이터 센터에서 수행될 수 있다. 에지 게이트웨이 노드 또는 에지 자원 노드는 스테이트풀 애플리케이션(stateful application) 및 지리적 분산 데이터베이스의 사용을 제공할 수 있다. 애플리케이션 및 데 이터베이스가 에지 클라우드의 계층에서 수평으로 분산되어 있는 것으로 도시되지만, 애플리케이션의 자 원, 서비스 또는 다른 컴포넌트는 (클라이언트 컴퓨트 노드에서 실행되는 애플리케이션의 일부, 에지 게 이트웨이 노드 또는 에지 자원 노드의 다른 부분을 비롯한) 에지 클라우드 전체에서 수직으로 분산 될 수 있다는 것이 이해될 것이다. 또한, 앞서 언급한 바와 같이, 서비스 목표 및 의무를 충족하기 위해 임의 의 레벨에서 피어 관계가 있을 수 있다. 또한, 특정 클라이언트 또는 애플리케이션의 데이터는 변동 조건에 기 초하여(예를 들어, 가속 자원 가용성에 기초하여, 자동차 이동 등에 따라) 에지로부터 에지로 이동할 수 있다. 예를 들어, 액세스의 \"감쇠율(rate of decay)\"에 기초하여, 예측은 계속할 다음 소유자를 식별하기 위해, 또는 데이터 또는 컴퓨테이션 액세스가 더 이상 실행 가능하지 않을 때 수행될 수 있다. 이러한 서비스와 다른 서비 스는 거래를 준수하고 무손실 상태로 유지하는 데 필요한 작업을 완료하는 데 이용될 수 있다. 추가 예에서, 도 12는 에지 노드가 그 에지 노드를 호스팅하는 플랫폼을 따라 다른 지리적 위치로 이동할 것이 므로, 차량(자동차/트럭/트램/기차) 또는 다른 모바일 유닛에 호스팅된 에지 노드와 같은 다양한 유형의 모바일 에지 노드를 이용할 수 있다. 차량 대 차량 통신에 의하면, 개개의 차량은 (예를 들어, 캐싱, 보고, 데이터 집 계 등을 수행하기 위해) 다른 자동차의 네트워크 에지 노드로서도 역할을 할 수 있다. 따라서, 다양한 에지 노드에서 제공되는 애플리케이션 컴포넌트를 비롯하여, 개별 엔드포인트 디바이스 또는 에지 게이트웨이 노드 에서의 일부 기능 또는 동작과, 에지 자원 노드에서의 일부 다른 기능 또는 동작과, 코어 데이터 센터 또는 글로벌 네트워크 클라우드에서의 다른 기능 또는 동작 간의 조정은 정적 또는 모바일 설 비에 분산될 수 있다는 것이 이해될 것이다. 추가 구성에서, 에지 컴퓨팅 시스템은 각각의 실행 가능한 애플리케이션 및 기능을 사용하여 FaaS 컴퓨팅 캐퍼 빌리티를 구현할 수 있다. 예에서, 개발자는 하나 이상의 컴퓨터 기능을 나타내는 기능 코드(예를 들어, 본 명 세서에서는 \"컴퓨터 코드\")를 작성하고, 기능 코드는 예를 들어, 에지 노드 또는 데이터 센터에 의해 제공되는 FaaS 플랫폼에 업로드된다. 예를 들어, 서비스 유스 케이스 또는 에지 처리 이벤트와 같은 트리거가 FaaS 플랫 폼에서 기능 코드의 실행을 시작한다. FaaS의 예에서, 컨테이너는 기능 코드가 실행되는 환경을 제공하는 데 사용된다. 컨테이너는 프로세스, 도커 (Docker) 또는 쿠버네티스(Kubernetes) 컨테이너, 가상 머신 등과 같은 임의의 격리된 실행 엔티티일 수 있다. 에지 컴퓨팅 시스템 내에서, 다양한 데이터센터, 에지 및 엔드포인트(모바일 포함) 디바이스는 수요에 따라 크 기 조정되는 기능을 \"스핀 업(spin-up)\"(예를 들어, 기능 작용을 활성화 및/또는 할당)하는 데 사용된다. 기능 코드는 물리적 인프라스트럭처(예를 들어, 에지 컴퓨팅 노드) 디바이스 및 기본적 가상화 컨테이너에서 실행된 다. 마지막으로, 컨테이너는 실행 완료에 대한 응답으로 인프라스트럭처에서 \"스핀 다운(spin down)\"(예를 들 어, 비활성화 및/또는 할당 해제)된다. FaaS의 추가 양태는 서비스로서의 에지(Edge-as-a-Service 또는 \"EaaS\")로서 에지 컴퓨팅 지원하는 각 기능의 지원을 비롯하여, 서비스 방식으로 에지 기능을 배치할 수 있게 할 수 있다. FaaS의 추가 기능은: 고객(예를 들어, 컴퓨터 코드 개발자)이 코드가 실행될 때만 지불할 수 있도록 하는 세분화된 과금 컴포넌트; 하나 이상의 기능에 의해 재사용하기 위한 데이터를 저장하는 공통 데이터 스토리지; 개별 기능 간의 오케스트레이션 및 관 리; 기능 실행 관리, 병렬성, 및 통합; 컨테이너 및 기능 메모리 공간의 관리; 기능에 이용 가능한 가속 자원의 조정; 및 (이미 배치되거나 동작 중인 \"웜(warm)\" 컨테이너와 이에 대비되는 초기화, 배치 또는 구성을 필요로 하는 \"콜드(cold)\"를 비롯한) 컨테이너 간의 기능의 배치를 포함할 수 있다. 추가 구성에서, 오케스트레이션의 양태는 \"서비스로서의 오케스트레이션(Orchestration as a Service)(OaaS)\" 배치의 서비스 양태를 통해 에지 컴퓨팅 시스템에서 구현될 수 있어, 많은 양태의 에지 오케스트레이션 및 다중 테넌시 사이에서 이해 당사자 탈중앙집중화를 가능하게 할 수 있다. 예에서, 에지 컴퓨팅 시스템 테넌트는 (부 트스트랩 캐퍼빌리티, 구성 마법사, 스토어프론트(storefront) 등의 일부로서 인에이블된) SLA 생성 프로세스의 일부로서 OaaS 공급자를 발견한다. 검색 및 사용을 지원하는 데 필요한 기술적 캐퍼빌리티는 제조업체에 의해 각각의 디바이스에 반영될 수 있으며, \"온보딩(onboarding)\" 유형의 절차는 테넌트가 에지 컴퓨팅 시스템 내에 서 선택하고 활용하는 각각의 OaaS와 함께 발생할 수 있다. 또한, SLA 생성 프로세스 동안, OaaS 제공자는 어 떤 자원, 요구 사항 또는 특징이 요청되는지와 이것이 풀에서 이용 가능한지를 대비하여 분리하며, 자원을 활용 하기 위해 특정 특징/기능에 대한 실시 가능성(enablement)/활성화 또는 구독을 위한 별도의 서비스 요청을 생 성할 수 있다. 다양한 유형의 하드웨어 개선 및 구성이 에지 컴퓨팅 디바이스 내에서 OaaS를 지원하기 위해 구현될 수 있다. 예를 들어, 하드웨어 캐퍼빌리티는 OaaS 신뢰 앵커(trust anchor)를 사전 프로비저닝하거나, 또는 하드웨어 제 조업체가 OaaS 도입을 중개하기 위한 신뢰성 있는 정보 센터로서 역할을 할 수 있게 하는 정보를 제공할 수 있 다. 본 명세서에 제안된 다른 유형의 소프트웨어 및 서비스 개선 및 구성이 또한 에지 컴퓨팅 시스템 내에서 OaaS의 특징을 지원하기 위해 구현될 수 있다. B. 워크로드 분산 및 관리 도 13은 운영 네트워크 계층 사이에서 에지 컴퓨팅에 대한 운영상 고려 사항의 비교를 도시한다. 구체적으로, 도 13은 상이한 컴퓨트 처리 위치에서 경험하는 트레이드오프의 정도와 유형을 도시한다. (예를 들어, 도 2의 네트워크 액세스 계층 및 코어 네트워크 계층 사이에 위치한 장비를 상세히 열거하는) 네트워크의 상 이한 계층에서, 이를테면 디바이스에 인접한 에지 클라우드(near-device edge cloud)의 에지 게이트웨이 (예를 들어, 기지국, 액세스 포인트) 및 에지 캐비닛(예를 들어 거리 또는 도로변 캐비닛, 온-프레미스 캐비닛), 중앙국에서의 집계 지점, 데이터 센터에서의 집계 지점 또는 인터넷 또는 오버-더-톱 서 비스에서의 클라우드 데이터 센터 사이에서, 다양한 서비스 특성(1302-1318)이 증가 또는 감소된다. 에 지 엔드 포인트에 더 가까워질 때, 새로운 유스 케이스(예를 들어, 분산되고 컨텍스트화된 AI, 실시간 FaaS), 줄어든 지연시간(예를 들어, 줄어든 응답 시간, 더 빠른 사용자 경험), 증가된 처리량(예를들어, 조정된 분산, 로드 밸런싱 등), (예를 들어, 개선된 엔드 포인트 또는 에지 필터링, 캐싱 등을 통한) 줄 어든 총 소유 비용 및 트래픽의 실시 가능성에서 증가를 경험할 것이다. 그러나 클라우드 데이터 센터에 가까워짐에 따라, (예를 들어, 개선된 격리, 데이터 보호를 통한) 보안, 증가된 물리적 제한 사항 (예를 들어, 전력, 공간, 보안 및 열 제약 조건), 줄어든 관리 유지보수, 유선 및 무선 인프라스트럭처에 대한 재사용 캐퍼빌리티 및 더 복잡한 오케스트레이션에서 개선 사항이 발견될 수 있다. 이러한 트레이드오프는 이동성의 특성과 상이한 유형의 통신 네트워크에 의해 확대된다. 도 14는 셀룰러(모바 일) 무선 네트워크에서 운영 네트워크 계층 간의 에지 컴퓨팅을 위한 운영 배치 및 지연시간을 도시한다. 구체 적으로, 도 14는 예시적인 국가 배치에서 각각의 모바일 네트워크 계층(1420-1470)에 발생하는 네트워크 지연시 간의 예를 도시하는 것으로, 로컬 계층까지의 왕복 타이밍(round trip timing)(예를 들어, 소형 셀 기지 국 또는 액세스 포인트까지 전형적으로 1 ms 미만이고, 로컬\" 또는 \"근접 에지\" 계층으로 간주될 수 있음), 온- 프레미스 계층(예를 들어, 온-프레미스 장비 또는 클라우드렛(cloudlet)/에지렛(edgelet)을 갖고, 전형적 으로 역시 1 ms 미만이고, 또한 \"엔터프라이즈 에지\", \"로컬 에지\" 또는 \"근접 에지\" 계층으로 간주될 수 있 음), 기지국 계층(예를 들어, 셀 타워 기지국 또는 다른 무선 네트워크 게이트웨이를 갖고, 전형적으로 1 내지 5 ms이고, \"인접 에지\" 계층으로 간주될 수 있음), 집계 계층(예를 들어, 다수의 집계 서버 또는 위 치를 갖고, 전형적으로 100 킬로미터(KM) 거리마다 5 ms더하기 추가 1-2 ms이고, \"중간 에지\" 계층으로 간주될 수 있음), 코어 네트워크 계층(예를 들어, 다수의 코어 네트워크 서버 또는 위치를 갖고, 현재 사용되는 원격 통신 기술에 기초하여, 전형적으로 400 KM 거리마다 5 ms 더하기 추가 5 ms 이고, \"원거리 에지\" 계층으로 간주될 수 있음); 및 클라우드 계층(예를 들어, 하나 이상의 클라우드 처리 위치를 갖고, 전형적으로는 60 ms를 초과함)의 예를 제공한다. 이러한 지연시간은 설명 목적으로 만 제공되며 (빛의 속도에 의해 제한되기 는 하지만) 연루된 통신 기술의 유형에 따라 달라질 수 있다. 에지 클라우드 시스템의 배치(예를 들어, 에지 클라우드의 구현)은 계층(1420-1450)을 참조하여 아래에서 논의된다. 최종 사용자에 의해 사용되거나 근처의 로컬 계층을 통해 액세스 가능한 엔드 포인트 디바이스는 \"원거리 에지\" 디바이스로 간주될 수 있다. 이러한 시나리오의 디바이스는 가능한 최저의 지연시간을 제공할 수 있다. 그러나 어떤 시점에서, 원거리 에지 디바이스는 연산이 제한되거나 또는 주어진 작업을 수행하는 데 필요한 만 큼 전력 효율적이지 않을 수 있다. 예를 들어, 네트워크 트래픽 부하의 어떤 지점에서, AR/VR 유스 케이스는 (디바이스 자체의 원거리 에지에서만 워크로드를 실행하는 것보다 더 나쁜 성능을 제공하는 지점까지도) 심각한 저하를 경험할 것이다. 온 프레미스 계층(엔터프라이즈 에지 계층이라고도 함)에서 온 프레미스 컴퓨팅은 낮은 지연시간 네트워 크 에지 아키텍처의 다음으로 잠재적인 계층이다. 온 프레미스는 (소형 폼 팩터 랙으로부터 다수의 랙으로) 특 정 양의 컴퓨트를 호스팅할 수 있는 위치(전형적으로 고객 댁내)를 말한다. 이러한 온-프레미스 컴퓨트 플랫폼 은 엔터프라이즈, 클라우드 서비스 제공자 또는 통신 서비스 제공자가 소유하고 운영할 수 있다. 기지국 계층(인접 또는 근접 에지 계층으로도 알려져 있을 수 있음)의 기지국에서의 컴퓨팅은 많은 경우 통신 서비스 제공자 관점에서 제 1 잠재적 에지로서 호스팅될 수 있는 다수의 안테나를 통합할 수 있다. 기지 국은 가상 무선 액세스 네트워크(virtual radio access network)(예를 들어, vRAN) 유형의 워크로드를 실행하 여 5G 무선 트래픽을 처리할 수 있다. 기지국상에서 다른 서비스를 실행하려는 주요 설계 도전과제는, 제 한된 공간; 더 많은 보안과 더 나은 열 솔루션을 필요로 하는 물리적 노출; 제한된 전력량; 그러한 고도로 분산된 컴퓨팅 환경을 관리하여 도출되는 운영 비용(operating expense)(OPEX) 또는 총 소유 비용(total monetary cost of ownership)(TCO)과 관련된다. 기지국에 서비스를 배치하는 것의 도전과제를 간략히 설명한 후에, 이러한 도전과제가 밀리 초 미만의 지연시간을 여전히 제공할 수 있는 인프라스트럭처의 고유한 요점 중 하나라는 것을 강조하는 것이 중요하다. 집계 계층(거리 및 지연시간에 따라 중간 에지 계층 또는 원거리 에지 계층이라고도 알려져 있을 수 있음)의 중앙국(CO)에서의 컴퓨팅은 로컬 영역 내에 있는 다수의 기지국의 집계 지점으로서 역할을 할 수 있다. 예를 들어, 하나의 CO는 약 30 개의 기지국으로부터의 트래픽을 집계할 수 있다. 이 숫자는 국가 및 인구 밀도 에 따라 다를 수 있다. 이러한 중앙국은 지역의 스위칭 사이트에 연결하기 전에 (예를 들어, 광학, 링크를 비 롯한 유선 링크를 이용하여) 지역적 프레즌스 포인트(Point of Presence)(POP)에 연결할 수 있다. CO는 또한 무선 및 유선 서비스를 통합할 수 있다. CO에 도달하는 지연시간은 에지 서비스를 배치하기에 바람직한 위치로 만들 수 있는 많은 에지 유스 케이스(예를 들어, 전력, 공간, 관리의 용이성)를 충족한다. 중앙국 또는 스위칭 사이트는 또한 다수의 중앙국 연결을 집계할 수 있다.도 15는 워크로드 배치 및 에지 컴퓨팅 시스템의 운영 계층(예를 들어, 계층(1420-1470)에 대응함)에의 매핑을 도시한다. 이러한 배열 내에서, 컴퓨트 자원을 워크로드 데이터로 가져다 주고, 워크로드 데이터를 컴 퓨트 자원으로 가져다 주는 다양한 조정이 수행되므로, 에지 컴퓨팅 시스템의 디바이스 사이에서 워크로 드 실행의 위치 및 유형에 대해 다수의 고려 사항 및 기능이 평가된다. 이러한 고려 사항은 다음과 같은 것을 포함할 수 있다: 각각의 위치의 제한 사항(예를 들어, 전력, 공간 및 플랫폼 보안)에 따라 (서비스 및 워크로드의 적절한 매 핑을 수행하는 것 이외에) 단기 및 장기 사용을 위한 올바른 플랫폼 아키텍처, 랙 설계 또는 다른 하드웨어 특 징 또는 구성을 선택하는 것. 상이한 옵션이 상이한 아키텍처 구성에 매핑될 수 있다. 네트워크 또는 서비스 사업자로부터 어떤 요구 사항이 발생하는지를 결정하면 아키텍처가 형태를 갖출 것이다. 이것은 사업자 요구 사항(예를 들어, 자본 비용 대 운영 비용, 폼 팩터, 보안 및 QoS)을 충족하는 플랫폼 아키텍처를 나타낼 수 있다. 에지 컴퓨팅 아키텍처를 관리, 모니터링 및 조정할 정확한 소프트웨어 아키텍처를 결정하는 것. 오케스트 레이션할 올바른 인터페이스가 없으면, 복잡한 분산 시나리오 클라우드 아키텍처는 작동하지 않을 것이다. 또 한, 적절한 추상화 및 인터페이스를 서비스에 노출하여 그 아래의 하드웨어 자원에 액세스하는 것은 동일한 임 계성 레벨에 있다. 이러한 결정 및 다른 결정에 기초하여, 다양한 워크로드 및 유스 케이스 모델은 워크로드 매핑 정의 에 따라 에지 컴퓨팅 시스템의 위치 사이에 먼저 매핑될 수 있다. 이러한 워크로드 매핑 정의 는 플랫폼 요구 사항 및 에지 컴퓨팅 시스템 사이에 배치될 수 있는 아키텍처 요소(예를 들 어, 저장소 또는 랙 스케일 설계 기술, 가속, 플랫폼, 패브릭 또는 네트워크, 스토리 지 또는 메모리)를 식별할 수 있다. 또한, 워크로드 매핑 정의는 보안, 물리적 제약 조건 , 관리, 비용(예를 들어, 금전적, 자원 또는 다른 재산 비용), 인프라스트럭처 제한 사항 및 캐퍼빌리티 등과 같은 양태를 다루는 요구 사항 매핑에 기초할 수 있다. 또한, 에지 컴퓨팅 시스템의 엔드-투-엔드 고려 사항은 정의(예를 들어, 고객 및 워크로드 요구 사 항에 대한 정의, 다중 계층 오케스트레이션에 대한 정의, 기지국, 중앙국 및 데이터 센터 위치에 대한 정의(1553, 1554, 1555) 또는 E2E QoS 또는 서비스 레벨 협약(service level agreement)(SLA) 구성에 대 한 정의)에서 제공되는 것으로서, 실시간 오케스트레이션, SLA 및 QoS 특성의 평가를 포함할 수 있다. 이러한 정의는 플랫폼 요구 사항 및 아키텍처 요소를 선택하고, 요구 사항 매핑의 순위를 매 기거나 우선순위를 지정하고, 궁극적으로 워크로드 매핑을 변경하는데 사용될 수 있다. 정의 또는 다른 곳에 기록된 이러한 고려 사항은 다음과 같은 특징을 반영할 수 있다: 1) 에지 서비스 위치에서 중요한 역할을 하는 제1 핵심 성과 지표(key performance indicator)(KPI)를 제공하 는 데 사용되는, 지연시간. 빛의 속도는 약 300,000 km/s이고 유선에서 전송 속도는 이것의 약 2/3이기 때문에 필요한 응답 지연시간은 디바이스가 에지로부터 얼마나 멀리 떨어져 있는지를 결정할 것이다. 예를 들어, 일부 서비스가 4 ms 미만의 응답 지연시간을 필요로 하면, 이러한 서비스는 디바이스로부터 ~150 km를 초과하여 멀리 있을 수 없다. 따라서 워크로드 중 일부(예를 들어, IoT 디바이스 데이터 처리)의 경우, 고유한 에지 정의는 기지국에 의해서만 소비될 수 있는 반면, 다른 것은 중앙국에 의해 소비될 수 있다. 2) 준수 여부를 결정하고 운용성을 검증하는 데 사용되는, 데이터 프라이버시, 주권 및 민감도. 이러한 고려 사항은 일부 서비스가 에지의 특정 위치에만 상주할 수 있다는 것을 적시할 수 있다. 예를 들어, 헬스케어 부 문에서, 일부 병원은 일부 서비스를 에지 클라우드에서 호스팅하고 공유하되 데이터가 인프라스트럭처의 특정 경계(예를 들어, 온 프레미스, 중앙국 등)를 넘지 않도록 하고 싶어할 수 있다. 3) 백홀 트래픽의 감소. 백홀 트래픽 데이터 절약은 OPEX/TCO(및 더 작은 대역폭이 백홀 네트워크에서 필요할 수 있으므로 CAPEX)를 줄이기 위해 네트워크의 상이한 에지에서 트래픽을 필터링함으로써 달성할 수 있다. 이 경우, 필터링은 인프라스트럭처의 상이한 잠재적 에지에서 발생할 수 있다. 예를 들어, 비디오 감시는 콘텐츠 전송 네트워크가 중앙국에 배치될 수 있는 동안 어떤 이미지가 클라우드 또는 중앙국으로 전송되는지를 식별하 기 위해 기지국에서 처리될 수 있다. 4) 새로운 에지 처리 유스 케이스의 실시 가능화: 예를 들어 생체측정 인증을 가능하게 하는 에지에서의 서비스. 또는, 안정성 요구 사항이 충족되는 한 결제를 음성 분석을 통해 실시간으로 이루어질 수 있게 하는 서비스.5) 자원 레벨 신뢰의 정의 및 사용, 이것은 플랫폼 및 자원에 걸쳐 캐퍼빌리티에 액세스하는 인가를 가능하게 한다. 특정 유스 케이스 또는 워크로드에 대해 실제 에지가 어디에 상주하는지를 정의하는 것은 특정 위치를 실제 에 지에 제공하는 KPI 또는 가치 제안과 직접적으로 관련된다. 예를 들어, 사업자 인프라스트럭처의 코어에서 IoT 또는 AR/VR 워크로드의 실행을 위한 에지 컴퓨트를 정의하는 것은 지연시간의 측면에서 KPI 요구 사항을 충족시 키는 것이 불가능할 수 있다. 따라서, 이러한 워크로드에 대한 에지 컴퓨트는 (기지국 또는 더 로컬 중앙국의, 인접 또는 중간 에지 계층의) 디바이스에 더 가깝게 위치한다. 반면에, 콘텐츠 분산 네트워크(content distribution network)(CDN)(\"콘텐츠 전송 네트워크(content delivery network)\" 또는 \"콘텐츠 정의 네트워크 (content defined network)\"라고도 알려져 있음) 워크로드에 대한 에지 컴퓨트는 기지국, 중앙국 또는 (중간 또 는 원거리 에지 계층의) 사업자 인프라스트럭처의 다른 중간 집계 지점(POA 또는 POP)에 위치할 수 있다. 이 경우, 가장 적합한 에지 위치가 어디인지를 정의하기 위해, 연관된 OPEX/TCO가 CDN 워크로드를 배치하는 데 가 장 양호한 위치가 어디인지를 도출할 수 있다. 추가 예에서, 고급 형태의 워크로드 매핑은 에지 컴퓨팅 시스템에서 특정 형태의 컴퓨트 활동을 특정 위치 및 시스템(또는 워크로드 데이터를 가용 컴퓨트 자원 쪽으로 보다 효율적으로 가져다 주는 시스템 유형 및 위치 캐 퍼빌리티)에 매핑하는 데 사용될 수 있다. 도 16은 각각 각자의 캐퍼빌리티가 있는 액세스 포인트 또는 소형 셀, 게이트웨이 또는 기지국 및 중앙국을 갖는 에지 컴퓨팅 시스템의 서비스 특징에 워크로 드 유형의 매핑을 도시한다. 소형 셀에서 컴퓨트의 사용을 통해, 로컬 또는 초저 지연시간 서비스(예를 들어, 증강 현실, IoT, FaaS) 의 실행에 역점을 두어 서비스 결과를 생성할 수 있는, 네트워크 기능과 서비스의 조합이 제 공될 수 있다. 기지국에서 컴퓨트의 사용을 통해, 네트워크 기능과 서비스의 유사한 조합이 제공될 수 있다; 기지국에서 가용 하드웨어 처리 자원의 양은 심지어 네트워크 기능의 양 및 복잡성이 증 가함에 따라서도 증가한다. 액세스 포인트/소형 셀 또는 게이트웨이/기지국에서 이용할 수 없는 추가의 컴퓨트 자원을 필요로 하는 서비스(예를 들어, 비디오 분석, 저장, 분석, FaaS)에 대해 더 깊은 계층의 네트워크 기능이 제공될 수 있다. 에지 위치(1620, 1640, 1660) 및 유사한 서브시스템 전체에 분산된 하드웨어의 위치 및 유형에 대한 고려 사항 중 일부는 다음과 같은 것을 포함할 수 있다: 워크로드 및 유스 케이스가 매핑되는 위치. 이러한 결정은 본 명세서에서 논의된 다른 기준 또는 가치 제 안을 사용하여 수행될 수 있다. 일단 매핑이 완료되면, 상이한 유스 케이스 또는 워크로드는 기반 블록 또는 기본 블록으로 분리되어야 한다. 기본 블록은 알고리즘 로직 유닛(예를 들어, 심층 신경망 또는 고속 푸리에 변환)에 의해 정의될 수 있다. 일단 에지의 상이한 계층에서 기본 블록의 매핑 및 분할이 이루어지면, 개선을 필요로 하는 특정 블록이 주어진 위치에서 식별될 수 있다. 따라서, 그 블록의 자원 요구 사항은 그 특정 위치 에서 얼마나 많은 자원이 필요한지를 추정하는 데 사용될 수 있다. 각 위치의 특성. 앞서 논의한 바와 같이, 위치(예를 들어, 기지국)는 각각 물리적 요구 사항(예를 들어, 폼 팩터, 전력, 온도 등)의 목록뿐만 아니라(예를 들어, 1 내지 4 K의 구독자를 범위로 할 수 있는 기지국에서) 예상 구독자 수를 갖고 있다. 물리적 요구 사항은 주어진 위치에 얼마나 많은 자원이 배치될 수 있는지를 의미 하며 구독자는 특정 워크로드 매핑 및 구독자의 마운트에 대해 얼마나 많은 컴퓨트가 필요한지를 의미한다. 따 라서, 인프라스트럭처 위치(예를 들어, 소형 셀, 기지국, CO)에 에지 컴퓨팅 처리 자원을 배치할 때 이러한 요 인과 다른 요인이 중요시 될 수 있다. 이러한 및 다른 에지 컴퓨팅 시나리오와 관련된 설계 포인트는 특히 다중 테넌시 및 다중 이해 관계자 유스 케 이스에서, 네트워킹 인프라스트럭처 서비스가 \"고갈\"되거나 실패할 수 없고, 지속적인 애플리케이션 및 서비스 에 의해 영향을 받지 않고 유지되어야 한다는 것이다. 네트워크 트래픽 및 네트워크 기능 워크로드는 결정성 (deterministic)을 유지해야할 필요가 있으며, 이와 같이 에지 클라우드 아키텍처의 설계는 VNF 및 네트워크 서 비스와 같은 우선순위가 높은 유스 케이스에 초점이 맞추어질 수 있다. 도 17은 에지 컴퓨팅 시스템의 실행 플랫폼에 워크로드 유형의 매핑을 도시한다. 도시된 바와 같이, 한 세트의 워크로드 유형(유형(1700, 1711, 1712, 1713, 1714)로 표시됨)은 (예를 들어, IoT 데이터 처리의) 최저 우선순위 및 워크로드의 지연시간 요구 사항을 표시하는 유형 분류에서부터 (예를 들어, AI 워크로드, 비디오 분석 워크로드, AR/VR 워크로드의) 중간 유형 분류를 가진 (예를 들어, 네트워크 통신 기능의) 최고 우선순위및 워크로드의 지연시간 요구사항을 표시하는 유형 분류까지 점진적으로 진전된다. 이러한 워크로드 유형 은 유형 분류에 따라 다중 이해 관계자, 다중 테넌트 에지 시스템에서 오케스트레이션될 수 있다. 각각의 유형 분류는, 사업자 요구 사항 또는 제약 조건(가용 플랫폼 수, 폼 팩터, 전력 등)과 비교하여, 특정 분류(예를 들어, 성능 요구 사항, 기능적 요구 사항)에 대한 워크로드 요구 사항을 명시할 수 있는 요구 사항 세트와 연관될 수 있다. 호출된 워크로드(들)에 대한 요구 사항의 결과로서, 워크로드 실행 플랫폼의 특정 구성의 선택이 이루어질 수 있다. 하드웨어(1732, 1734, 1736)로부터 제공되는, 워 크로드 실행 플랫폼에 대한 구성(예를 들어, 구성(1731, 1733, 1735))은 다수의 에지 노드(예를 들어, 플 랫폼 1 내지 N) 중에서 실행 플랫폼을 식별함으로써; 구성 가능한 랙 스케일 설계 시스템 내에서 실행 플랫폼을 재구성함으로써; 또는 하나 또는 다수의 플랫폼의 자원을 풀링하거나 결합하여 실행 플랫폼을 재구성함으로써 선택될 수 있다. 워크로드 유형의 매핑으로부터 제공되는 요구 사항 및 제약 조건 외에도, 다른 측정 또는 지표가 에지 실행 플 랫폼을 선택하거나 구성하는 데 사용될 수 있다. 예를 들어, 특정 실행 플랫폼상에서 서비스의 매핑은: KPI 성 능 이득 또는 사용자 경험 이득(예를 들어, 360도 비디오에 대해 좋은 사용자 경험을 제공하는데 필요한 지연시 간); (예를 들어, 예상 수익화 대비 특정 위치에 서비스를 배치하는 것으로부터 도출되는) OPEX/TCO; SLA 및 서 비스 레벨 목표(service level objective)(SLO) 정의 등을 고려할 수 있다. 이러한 고려 사항은 분산된 생태계 와 별개의 하드웨어 위치 사이에서 잠재적으로 높은 관리 비용(예를 들어, 높은 금전적 또는 높은 자원 비용)을 관리하는 사업자의 우려와 균형을 이룬다. 도 18은 에지 컴퓨팅 시스템에서 에지 컴퓨팅 하드웨어 구성의 다중 계층 사이에서 다중 테넌트에 대한 서비스의 동작을 도시한다. (예를 들어, 계층(1420-1470)에 대응하는) 에지 컴퓨팅 시스템의 다양한 운 영 계층에서, 하드웨어 가용성과 플랫폼 기능의 상이한 조합이 노출된다. 예를 들어, 로컬 계층에서 동 작하는 소형 셀은 제한된 하드웨어(예를 들어, 저전력 CPU)를 가질 수 있으며, 특화된 플랫폼 특징(소프트웨어 또는 하드웨어 특징)이 제한되거나 없을 수 있다. 온-프레미스 계층에서 동작하는 온-프레미스 클라우드 렛/에지렛/또는 다른 애플릿 머신은 추가의 또는 더 강력한 하드웨어를 호스팅하고 소프트웨어 또는 하드웨어 특징(예를 들어, AI 가속기, FPGA, GPU, 암호화 서비스 등)을 제공할 수 있다. 기지국 계층은 훨씬 더 많은 하드웨어 캐퍼빌리티(예를 들어, 고전력 CPU 또는 특화된 컴퓨트 아키텍처 처리 유닛) 또는 더 고급 플랫 폼 특징(고급 저장 메모리)을 가질 수 있고; (스마트 네트워킹 컴포넌트를 비롯한) 하드웨어 및 플랫폼 특징의 보다 고급 조합이 집계 계층 및 코어 네트워크 계층에서 제공될 수 있다. 시스템에서 도시된 상이한 유형의 하드웨어 캐퍼빌리티 및 특징은 다중 에지 FaaS 변형을 가능하게 할 수 있다. 구체적으로, 특정 서비스 또는 서비스 플랫폼(\"서비스 A\")이 계층(1420-1460) 중 임의의 계층에서 사용 또는 실행을 위해 가상으로 제공될 수 있기는 하지만, 계층 사이의 하드웨어와 소프트웨어의 상이한 조합은 상 이한 처리 결과 또는 작용을 가능하게 한다. 또한, 특정 테넌트 또는 사용자에 기초하여 서비스 사용 또는 실 행을 위해 하드웨어와 소프트웨어의 상이한 조합(또는 이러한 하드웨어 및 소프트웨어의 캐퍼빌리티)이 제공될 수 있다. 이러한 컨텍스트에서, 서비스 실행/런타임은 LSM 또는 다른 보안 정책 시행 지점이 될 수 있다. (마 찬가지로, 이러한 컨텍스트에서, 서비스 계층 아래의 하드웨어 추상화 계층 및 물리적 파티셔닝 또는 가상화를 가능하게 하는 플랫폼 캐퍼빌리티는 LSM 및 다른 보안 정책 시행 지점도 제공할 수 있다). 애플리케이션 관점에서, (이를테면, 애플리케이션의 컴포넌트가 클라우드에서 실행되고, 개개의 처리 컴포넌트 가 이를테면 계층적 에지를 따라 에지 클라우드의 에지에 있는 경우) 에지 네트워킹을 위해 특별히 설계된 애플 리케이션이 있을 수 있다. 따라서, 시스템에서 도시된 접근 방식은 동일하거나 상이한 애플리케이션의 일부로서, 초저 지연시간 FaaS 대 FaaS와 같은 다수의 FaaS 변형을 지원할 수 있다. 도 19는 하드웨어 플랫폼(1902-1908)(및 플랫폼 유형(1901-1909))을 에지 클라우드의 다양한 계층(1430- 1450)과 그 이상(도 4에 대해 위에서 논의된 운영 네트워크 계층 예의 확장)에 매핑하는 것에 기초하여, 에지 컴퓨팅 하드웨어 구성을 네트워크 계층의 운영 배치 및 지연시간에 추가 매핑하는 것을 도시한다. 예를 들어, 계층에서, 저전력 CPU와 다수의 특화된 가속기(하드웨어)의 조합은 온-프레미스 서비스(예를 들어, 클라우드렛/에지렛/또는 1 밀리 초 미만의 극히 낮은 지연시간을 필요로 하는 다른 애플릿)의 실행에 적합한 제 1 플랫폼 유형을 제공할 수 있다. 계층에서, 저전력 CPU와 특화된 가속기(하드웨어)의 유사한 조 합은 (예를 들어, 5 ms 미만의 낮은 지연시간을 필요로 하는) 다수의 유형의 디바이스에 대해 저전력 서비스 실 행에 적합한 제 2 플랫폼 유형을 제공할 수 있다. 네트워크로 더 깊이 들어갈 수록, 서버급 CPU와 특화된 GPU 및 가속기(하드웨어) 또는 스토리지(하드웨어)의 조합이 집계 계층에서 제공될 수 있다. 마지막으로, 에지 클라우드를 넘어, 멀티 코어 서버 CPU 및 스토리지(하드웨어)는 코어 네트워크 계층 에서 제공되어 서버급(클라우드) 처리의 가용성을 가능하게 할 수 있지만 더 높은 지연시간이라는 트레이 드오프가 있을 수 있다. 일부 시나리오에서 하드웨어 플랫폼 또는 구성은 수정 가능한 플랫폼에서 동작하여, 이를 테면 에지 클라우드의 상이한 계층에서 스왑 가능하거나 상호 교환 가능한 하드웨어 컴포넌트를 사용할 수 있게 할 수 있다는 것이 이해될 것이다. 이러한 방식으로, 서비스 제공자 또는 하드웨어 시스템 사업자는 더 새롭고/더 강력한 하드웨어(또는 더 비용 효율적인 하드웨어)로 에지 시스템의 배치를 업그레이드하면서, 필요 한 네트워크 지연시간에 에지 워크로드를 서비스할 수 있다. 도 20은 에지 컴퓨팅 하드웨어 구성의 운영 배치에 대한 유스 케이스 및 워크로드의 추가 매핑을 도시한다. 구 체적으로, 도 20은 각각 다양한 요구 사항, 애플리케이션 및 가치 제안을, 가진 에지 클라우드와 관련된 상이한 워크로드가 서비스 제공자에 의해 배치될 수 있는 방법을 도시한다. 다양한 유형의 유스 케이스 및 워크로드는 하드웨어 구성의 선택 또는 재구성에 기초하여 상이한 플랫폼 유형에 매핑될 수 있다. 예를 들면, 유연한 NFV 워크로드는 CPU 및 스토리지 자원을 제공하는 제 1 플랫폼 유형 에 매핑될 수 있고; 비디오 처리 또는 비디오 분석 워크로드는 저전력 CPU 및 특화된 GPU 및 FPGA 처리를 제공하는 제 2 플랫폼 유형에 매핑될 수 있고; AR/VR 및 게임 워크로드는 CPU 및 스토리지 자원을 제공하 는 제 3 플랫폼 유형에 매핑될 수 있고; 데이터 캐싱 및 저장소 게이트웨이 워크로드는 저전력 CPU 및 스 토리지 자원을 제공하는 제 4 플랫폼 유형에 매핑될 수 있고; 사물 인터넷 처리는 저전력 CPU 및 AI 가속 자원을 제공하는 제 5 플랫폼 유형에 매핑될 수 있고; 자율 차량 워크로드 및 서비스로서의 기능 워크로 드는 CPU, 스토리지 및 특화된 GPU 처리 자원을 제공하는 제 6 및 제 7 플랫폼 유형에 매핑될 수 있고; 음성 인식 워크로드는 CPU 및 스토리지 자원 및 특화된 GPU 처리를 갖는 N 번째 플랫폼 유형에 매핑될 수 있는 등으로 매핑될 수 있다. 그러므로, 두 컴퓨트 자원 모두 워크로드 데이터에 매핑되고 워크로드 데이터 인스턴스가 컴퓨트 자원에 매핑되 므로, 상이한 위치가 에지 클라우드에 걸쳐 서비스 관리를 수행하는 데 사용 가능할 수 있다. 고도로 분 산된 아키텍처에서, 특징은 기지국상의 매핑 서비스에 기초한다. 이 경우, 전력 및 공간의 측면에서 플랫폼의 물리적 요구 사항은 이러한 특정 에지 노드에 배치할 수 있는 하드웨어의 양을 대부분 제한한다. 또한, 더 많 은 서비스 밀도를 갖기 위해, 하드웨어 추론 가속과 같은 가속 체계가 이용될 수 있다. 중앙국 아키텍처에서, 중앙국의 캐퍼빌리티 및 서비스 위치에 따라, 아키텍처는 덜 분산되지만 전력 및 공간 제약이 적다. 이 경우, 공간 및 전력 제약 조건이 더 적어, 아키텍처 솔루션은 어느 정도의 성능 또는 서비스 밀도를 희생하는 대가로 더 동질적이 될 수 있다. 초기의 워크로드 매핑은 워크로드의 수명주기 동안 또는 워크플로우의 구성에서 런타임 활동에 효과적이지 않을 수 있다는 것을 이해해야 한다. 실시 가능해져야 하는 추가 서비스는 워크로드의 시간 경과 특성화에 기초하여 워크로드의 평가 및 재할당을 제공할 수 있는 서비스로서의 워크로드 평가이다. 이것에 기초하여, 아래의 예에 서 제안된 바와 같이, 워크로드는 워크로드 요구를 지원하기 위해 다른 위치 또는 다른 하드웨어 또는 시스템 구성으로 마이그레이션될 수 있다. 추가 예에서, 워크로드 및 에지 컴퓨팅 서비스를 일반적으로 구현할 소프트웨어(및 펌웨어 및 하드웨어 특징) 업데이트를 지원하기 위해 다양한 유형의 분산, 업그레이드 및 변경 아키텍처가 구현될 수 있다. 보통, 컴퓨팅 플랫폼의 공급 업체는 배치된 플랫폼에 적용하는 특징 변경 또는 보안 패치를 생성할 책임이 있다. 전형적으로 공급 업체는 다른 공급 체인 엔티티가 펌웨어 업데이트를 개발하고 및/또는 다른 엔티티가 이를 적용할 수 있도 록 하지 않는다. 이러한 시나리오는 에지 컴퓨팅 환경에도 적용될 수 있지만, 분산 컴퓨팅 환경은 새로운 소프 트웨어 분산 및 업그레이드 역학을 가능하게 할 수 있다. 워크로드가 나누어져서 다수의 플랫폼에 이어져 있는 자원의 '슬라이스' 또는 '플레이버(flavor)'에 걸쳐 분산되고 그래서 다수의 관리자 및 공급 업체에 걸쳐 분산 되어 있을 때, 사용자와 오케스트레이터가 어떤 버전의 어떤 소프트웨어/펌웨어를 충분히 제어할 수 있는지에 대해 고려될 수 있다. 예에서, 워크로드는 시뮬레이션 결과가 펌웨어, 소프트웨어 및 다른 구성 파라미터에 완전히 종속적일 수 있는 특정 구성 및 배치 '플레이버'에서 검증되거나 시뮬레이션될 수 있다. 일부의 경우, 하드웨어, 펌웨어 및 소프 트웨어의 보안 취약성은 워크로드 실행이 거동하는 방법을 예측하기도 한다. 그러나, 워크로드 실행을 검증 및 /또는 시뮬레이션하는 데 사용된 환경이 이것을 실행하는 실제 환경과 상이하면, 그 차이는 위험이 추가된다는 것을 나타낸다. 에지 컴퓨팅 생태계는 소프트웨어, 펌웨어 및 하드웨어 특징 업데이트를 관리하는 방법으로서 위험 격차를 최소 화하기 위해 최적화될 수 있다. 워크로드 배치에 대한 3 단계 접근 방식이 활용될 수 있다: 실행 환경 종 속성을 식별하는 워크로드 유효성 검사 환경을 설정한다. 이것은 어느 소프트웨어 모델이 워크로드 애플리케이 션을 처리하는 데 필요한지를 고려한다. 이러한 종속성 그래프는 유효성 검사 환경 설정의 일부로서 식별된다. 또한, 과도한 기능성은 런타임 실행 위험을 추가하는 증가된 공격 표면(attack surface)을 나타낸다. 이러한 비 종속성은 유효성 검사 환경으로부터 제거될 수 있다. 시뮬레이션은 워크로드를 처리하는 데 필요한 실 제 환경을 만든다. 이것은 시뮬레이션된 하드웨어, 가상화 또는 시뮬레이션된 성능 시나리오의 사용을 포함할 수 있다. 워크로드는 다른 워크로드, 오케스트레이션, 사용자, 협업 등과의 상호작용을 기대하면서 실행된다. 시뮬레이션은 운영상의 코너 케이스(corner cases)가 노출되도록 보장한다. 시뮬레이션은 또한 사용되는 하드 웨어, 소프트웨어 및 펌웨어의 버전을 명시할 수 있다. 이것들은 예상되는 실제 거동을 더 잘 이해하는 실제 하드웨어, 소프트웨어 및 펌웨어 자원일 수 있다. 시뮬레이션 환경은 실세계 배치에서 재현된다. 하드웨 어, 소프트웨어 및 펌웨어의 버전이 적절하게 조정된다. 아마도 이것은 역행 개정(backward revision)으로 이 동하거나 역행 개정을 무시하고 시뮬레이션 정의 환경에 따라 자원을 찾고 할당하는 것을 의미한다. 이것은 또 한 워크로드에 의해 사용되지 않는 하드웨어, 소프트웨어 및 펌웨어의 제거를 포함할 수 있다. C. 하드웨어 컴포넌트 도 21a는 에지 플랫폼(예를 들어, 컴퓨트 하드웨어(2111 및 2112), 네트워크 특징, 플랫폼 가속 특 징, 전력 관리 특징, 메모리 , 스토리지 등)의 다양한 아키텍처 양태를 특정 에지 플 랫폼 캐퍼빌리티(예를 들어, I/O 풀링, 가속 풀링, 메모리 풀링 , 가속 기술, 스토리지 캐퍼빌리티)에 매핑하는 제 1 에지 컴퓨팅 하드웨어 구성을 도시한다. 에지 클라우드 구성을 서비스의 전체 솔루션으로 제공하기 위해, 서비스 및 서비스 요구 사항/제약 조건(예를 들어, 네트워크 및 I/O, 플랫폼 가속, 전력)에 대한 워크로드 또는 기본 하드웨어 컴포넌트가 가용 아키텍처 양태(예를 들어, 풀링, 저 장 등)를 감안하여 고려된다. 에지 플랫폼 캐퍼빌리티 내에서, 서비스 밀도가 에지 클라우드에 걸쳐 충족되도록 보장하기 위해 특정 가 속 유형이 특징 내에서 구성되거나 식별될 수 있다. 구체적으로, 네 개의 기본 가속 유형이 에지 클라우드 구 성에 배치될 수 있다: 고속 푸리에 변환(Fast Fourier transform)(FFT), k-최근접 이웃 알고리즘(k- nearest neighbors algorithm)(KNN) 및 머신 학습 워크로드와 같은 기본 블록을 구현하는 일반 가속(예를 들어, FPGA); 이미지, 비디오 및 트랜스코딩 가속기; 추론 가속기; (이를 테면 Intel® QuickAssist™ 기술에서 구현된) 암호화 및 압축 관련 워크로드. 따라서, (예를 들어, 일반 가속, 추론 가속, 스토리지를 갖는) 에지 플랫폼 캐퍼빌리티의 특정 설계 또는 구성은 서비스 및 처리량 밀도뿐만 아니라 가용 전력을 수용하기 위해 선택되어야 하는 올바른 유형의 가속 및 플랫폼 제품 모델이 어떤 것인지를 고려할 수 있다. 도 21b는 (캐퍼빌리티(2141, 2142, 2143)를 갖는) 제 2 세트의 에지 플랫폼 캐퍼빌리티가 있고, 저전력이 지만 서비스 집약적인 솔루션에 배치 가능한 (예를 들어, 위에서 제안된 바와 같은 하드웨어(2131, 2132, 2133, 2134, 2135, 2136, 2137)를 갖는) 제 1 에지 플랫폼을 제공하는 제 2 에지 컴퓨팅 하드웨어 구성을 도시 한다. 이러한 접근 방식은 더 나은 서비스 밀도 또는 와트 당 서비스 처리량을 달성하기 위해 가속 체계를 사 용하는 저전력 솔루션을 정의하는 것을 목표로 한다. 이러한 주요 설계 트레이드오프는 동일한 작업을 와트 당 더 나은 성능 비율로 수행할 수 있는 특화된 하드웨어(예를 들어, FPGA, 추론 가속기)에 유리하게 일반 컴퓨트 로 희생하여 사용하는 플랫폼으로 이어진다. 이러한 예에서, \"서비스 밀도\" 솔루션은 플랫폼 당 및 와트 당 더 많은 서비스 작용을 가능하게 하거나 또는 와트 당 서비스 레벨에서 더 많은 처리량을 추진할 수 있다. 플랫폼 캐퍼빌리티는 물리적 공간의 측면에서뿐만 아니라 전력 엔벨로프의 측면에서도 유리하도록 설계될 수 있다. 결과적으로, 도 21b의 구성은 (예를 들어, 인접 또는 중간 에지 계층에서) 기지국 배치에 적합한 타 겟을 제공할 수 있다. 그러나, 플랫폼 캐퍼빌리티는 다음과 같은 것을 포함하는 트레이드오프가 있을 수 있다: 오케스트레이션, 유지보수 및 시스템 관리 측면에서의 요구 사항(이것은 OPEX/TCO 비용으로 변환될 수 있다); 모든 시스템 스택이 노출된 상이한 가속기와 함께 작동할 수 있게 하는 사업자 생태계의 필요. 그러나 이러한 단점은 개발된 소프트웨어 추상화 계층으로 경감될 수 있다. 도 21c는 (예를 들어, 캐퍼빌리티(2161, 2162, 2163)를 갖는) 제 3 세트의 에지 플랫폼 캐퍼빌리티가 있 고, 고전력이지만 동질적이고 일반적인 아키텍처를 제공하는, (예를 들어, 위에서 제안된 바와 같이 하드웨어 (2151, 2152, 2153, 2154, 2155, 2156, 2157)를 갖는) 제 3 에지 플랫폼을 제공하는 제 3 에지 컴퓨팅 하드웨어 구성을 도시한다. 도 21c는 사업자 또는 에지 소유자가 관리, 유지보수 및 오케스트레이션과 관련하여 처리해야 하는 상이한 유형의 자원에서 이질성이 감소된 플랫폼 아키텍처를 제공하도록, 도 21b와 비교하여 반대의 접근 방식을 제공한다. 그러나 동질성을 위해 가속기를 제거하면 플랫폼 레벨에서 와트 당 서비스 밀도 및 서비스 처리량이 더 적은 희생이 따른다. 추가 예에서, 에지 플랫폼 캐퍼빌리티는 (이를테면 FPGA의 형태의) 범용의 가속을 구현할 수 있다. 도 21a 내지 도 21c에 도시된 에지 플랫폼의 다른 파생 기능이 또한 적용될 수 있다. 플랫폼은 더 많은 서비스 와 처리량을 조밀하게 해주는 새로운 구성요소를 통합하기 위해 크기 조정되고 설계될 수 있지만, 예를 들어 사 업자가 원활하게 관리할 수있도록 하기 위해 가속기를 플랫폼 내부 또는 다이상에 포함시킴으로써 보다 동질적 으로 유지할 수 있다. 추가 예에서, 본 발명의 에지 컴퓨팅 시스템 및 환경을 참조하여 논의된 임의의 컴퓨팅 노드 또는 디바이스는 도 22a 및 도 22b에 도시된 컴포넌트에 기초하여 이행될 수 있다. 각각의 에지 컴퓨트 노드는 다른 에지, 네트 워킹 또는 엔드포인트 컴포넌트와 통신할 수 있는 디바이스, 어플라이언스, 컴퓨터 또는 다른 \"사물\"의 유형으 로서 구현될 수 있다. 예를 들어, 에지 컴퓨트 디바이스는 스마트 폰, 모바일 컴퓨트 디바이스, 스마트 어플라 이언스, 차량 내 컴퓨트 시스템(예를 들어, 내비게이션 시스템), 또는 설명된 기능을 수행할 수 있는 다른 디바 이스 또는 시스템으로 구현될 수 있다. 도 22a에 도시된 간략화된 예에서, 에지 컴퓨트 노드는 컴퓨트 엔진(본 명세서에서 \"컴퓨트 회로\"라고도 지칭됨), 입력/출력(input/output)(I/O) 서브시스템, 데이터 스토리지, 통신 회로 서브시스 템 및 선택적으로 하나 이상의 주변 디바이스를 포함한다. 다른 예에서, 각각의 컴퓨트 디바이스 는 컴퓨터(예를 들어, 디스플레이, 주변 디바이스 등)에서 전형적으로 발견되는 것과 같은 다른 또는 추가 컴포 넌트를 포함할 수 있다. 또한, 일부 예에서, 예시적인 컴포넌트 중 하나 이상이 다른 컴포넌트에 통합되거나 그렇지 않으면 그 일부를 형성할 수 있다. 컴퓨트 노드는 다양한 컴퓨트 기능을 수행할 수 있는 임의의 유형의 엔진, 디바이스 또는 디바이스의 모 음으로서 구현될 수 있다. 일부 예에서, 컴퓨트 노드는 집적 회로, 임베디드 시스템, 필드 프로그램 가 능 게이트 어레이(FPGA), 시스템 온 칩(system-on-a-chip)(SOC) 또는 다른 집적된 시스템 또는 디바이스와 같은 단일 디바이스로서 구현될 수 있다. 예시적인 예에서, 컴퓨트 노드는 프로세서 및 메모리를 포함하거나 이들로서 구현된다. 프로세서는 본 명세서에서 설명된 기능을 수행할 수 있는 (예를 들어, 애플리케이션을 실행하는) 임의의 유형의 프로세서로서 구현될 수 있다. 예를 들어, 프로세서는 멀티-코 어 프로세서(들), 마이크로컨트롤러, 또는 다른 프로세서 또는 처리/제어 회로로서 구현될 수 있다. 일부 예에 서, 프로세서는 FPGA, 주문형 집적 회로(application specific integrated circuit)(ASIC), 재구성 가능 한 하드웨어 또는 하드웨어 회로, 또는 본 명세서에서 설명된 기능의 성능을 용이하게 하는 다른 특화된 하드웨 어로서 구현되거나, 이를 포함되거나 또는 이에 결합될 수 있다. 메인 메모리는 본 명세서에서 설명된 기능을 수행할 수 있는 임의의 유형의 휘발성(예를 들어, 동적 랜덤 액세스 메모리(dynamic random access memory)(DRAM) 등) 또는 비 휘발성 메모리 또는 데이터 스토리지로서 구 현될 수 있다. 휘발성 메모리는 매체에 의해 저장된 데이터의 상태를 유지하기 위해 전력을 필요로 하는 저장 매체일 수 있다. 휘발성 메모리의 비 제한적인 예는 DRAM 또는 정적 랜덤 액세스 메모리(static random access memory)(SRAM)와 같은 다양한 유형의 랜덤 액세스 메모리(random access memory)(RAM)를 포함할 수 있다. 메 모리 모듈에 사용될 수 있는 하나의 특정 유형의 DRAM은 동기식 동적 랜덤 액세스 메모리(synchronous dynamic random access memory)(SDRAM)이다. 일 예에서, 메모리 디바이스는 NAND 또는 NOR 기술에 기초한 것과 같은 블록 어드레스 가능 메모리 디바이스이 다. 메모리 디바이스는 또한 3 차원 크로스포인트 메모리 디바이스(예를 들어, 인텔® 3D XPoint™메모리) 또 는 다른 바이트 어드레스 가능 라이트-인-플레이스(byte addressable write-in-place) 비휘발성 메모리 디바이 스를 포함할 수 있다. 메모리 디바이스는 다이 자체 및/또는 패키징된 메모리 제품을 말할 수 있다. 일부 예 에서, 3D 크로스포인트 메모리(예를 들어, 인텔® 3D XPoint™메모리)는 메모리 셀이 워드 라인과 비트 라인의 교차점에 있고 개별적으로 어드레스 가능 가능하며 그리고 비트 저장이 벌크 저항(bulk resistance)의 변화에 기초하는 트랜지스터 없는 스택형 크로스 포인트 아키텍처(transistor-less stackable cross point architecture)를 포함할 수 있다. 일부 예에서, 메인 메모리의 전부 또는 일부는 프로세서에 통합 될 수 있다. 메인 메모리는 하나 이상의 애플리케이션, 애플리케이션(들)에 의해 동작되는 데이터, 라이 브러리 및 드라이버와 같이 동작 중에 사용되는 다양한 소프트웨어 및 데이터를 저장할 수 있다. 컴퓨트 회로는 I/O 서브시스템을 통해 컴퓨트 노드의 다른 컴포넌트에 통신 가능하게 결합되 며, I/O 서브시스템은 컴퓨트 회로(예를 들어, 프로세서 및 메모리) 및 컴퓨트 회로 의 다른 컴포넌트와의 입력/출력 동작을 용이하게 하는 회로 및/또는 컴포넌트로서 구현될 수 있다. 예 를 들어, I/O 서브시스템은 메모리 제어기 허브, 입력/출력 제어 허브, 통합 센서 허브, 펌웨어 디바이스, 통신 링크(예를 들어, 포인트-투-포인트 링크, 버스 링크, 전선, 케이블, 광 가이드, 인쇄 회로 기판 트레이스 등) 및/또는 입력/출력 동작을 용이하게 하는 다른 컴포넌트 및 서브시스템으로서 구현되거나, 그렇지 않으면 이들을 포함할 수 있다. 일부 예에서, I/O 서브시스템은 시스템-온-칩(SoC)의 일부를 형성하며, 프로세서, 메인 메모리 및 컴퓨트 회로의 다른 컴포넌트 중 하나 이상과 함께 컴퓨트 회로 에 통합될 수 있다. 하나 이상의 예시적인 데이터 스토리지 디바이스는 예를 들어, 메모리 디바이스 및 회로, 메모리 카드, 하드 디스크 드라이브, 솔리드-스테이트 드라이브 또는 다른 데이터 스토리지 디바이스와 같은 데이터의 단기 또는 장기 저장을 위해 구성된 임의의 유형의 디바이스로서 구현될 수 있다. 개별 데이터 스토리지 디바이스 는 데이터 스토리지 디바이스에 데이터 및 펌웨어 코드를 저장하는 시스템 파티션을 포함할 수 있 다. 개별 데이터 스토리지 디바이스는 또한 예를 들어, 컴퓨트 노드의 유형에 따라 운영 체제용 데이터 파일 및 실행 파일을 저장하는 하나 이상의 운영 체제 파티션을 포함할 수 있다. 통신 회로는 컴퓨트 회로와 다른 컴퓨트 디바이스(예를 들어, 에지 컴퓨팅 시스템의 에지 게 이트웨이 노드) 사이에서 네트워크를 통한 통신을 가능하게 할 수 있는 임의의 통신 회로, 디바이스 또는 그의 모음으로서 구현될 수 있다. 통신 회로는 임의의 하나 이상의 통신 기술(예를 들어, 유선 또는 무 선 통신) 및 연관된 프로토콜(예를 들어, 3GPP 4G 또는 5G 표준과 같은 셀룰러 네트워킹 프로토콜, IEEE 802.11/Wi-Fi®와 같은 무선 근거리 통신 네트워크 프로토콜, 무선 광역 네트워크 프로토콜, 이더넷, 블루투스 ®, 블루투스 저 에너지(Bluetooth Low Energy), IEEE 802.15.4 또는 지그비®와 같은 IoT 프로토콜, 저전력 광역 네트워크(low-power wide-area network)(LPWAN) 또는 저전력 광역(low-power wide-area)(LPWA) 프로토콜 등)을 사용하여 그러한 통신을 실행하도록 구성될 수 있다. 예시적인 통신 회로는 호스트 패브릭 인터페이스(host fabric interface)(HFI)라고도 지칭될 수 있는 네 트워크 인터페이스 제어기(network interface controller)(NIC)를 포함한다. NIC는 하나 이상의 애드-인-보드(add-in-board), 도터 카드(daughter card), 네트워크 인터페이스 카드, 제어기 칩, 칩셋 또는 컴 퓨트 노드에 의해 다른 컴퓨트 디바이스(예를 들어, 에지 게이트웨이 노드)를 연결하는 데 사용될 수 있는 다른 디바이스로서 구현될 수 있다. 일부 예에서, NIC는 하나 이상의 프로세서를 포함하는 시스 템-온-칩(SoC)의 일부로서 구현되거나 또는 하나 이상의 프로세서를 또한 포함하는 멀티칩 패키지에 포함될 수 있다. 일부 예에서, NIC는 NIC에 대해 둘 모두 로컬인 로컬 프로세서(도시되지 않음) 및/또는 로 컬 메모리(도시되지 않음)를 포함할 수 있다. 이러한 예에서, NIC의 로컬 프로세서는 본 명세서에서 설 명된 컴퓨트 회로의 기능 중 하나 이상을 수행할 수 있다. 또한 또는 대안적으로, 이러한 예에서, NIC의 로컬 메모리는 보드 레벨, 소켓 레벨, 칩 레벨 및/또는 다른 레벨에서 클라이언트 컴퓨트 노드의 하나 이상의 컴포넌트에 통합될 수 있다. 또한, 일부 예에서, 각각의 컴퓨트 노드는 하나 이상의 주변 디바이스를 포함할 수 있다. 이러한 주변 디바이스는 컴퓨트 노드의 특정 유형에 따라, 오디오 입력 디바이스, 디스플레이, 다른 입력/ 출력 디바이스, 인터페이스 디바이스 및/또는 다른 주변 디바이스와 같은 컴퓨트 디바이스 또는 서버에서 발견 되는 임의의 유형의 주변 디바이스를 포함할 수 있다. 추가 예에서, 컴퓨트 노드는 에지 컴퓨팅 시스템 내의 각각의 에지 컴퓨트 노드(예를 들어, 클라이언트 컴퓨트 노드, 에지 게이트웨이 노드, 에지 집 계 노드) 또는 유사한 형태의 어플라이언스, 컴퓨터, 서브시스템, 회로, 또는 다른 컴포넌트에 의해 구현 될 수 있다. 더 상세한 예에서, 도 22b는 본 명세서에서 설명된 기술(예를 들어, 동작, 프로세스, 방법 및 방법론)을 구현하 기 위한 에지 컴퓨팅 노드에서 존재할 수 있는 컴포넌트의 예의 블록도를 도시한다. 이러한 에지 컴퓨팅 노드는 컴퓨팅 디바이스로서(예를 들어, 모바일 디바이스, 기지국, 서버, 게이트웨이 등으로서) 또는 그 일부로서 구현될 때 노드의 각각의 컴포넌트의 더 자세한 뷰를 제공한다. 에지 컴퓨팅 노드는 본 명세서에서 참조된 하드웨어 또는 논리 컴포넌트의 임의의 조합을 포함할 수 있으며, 에지 통신 네트워크 또는 이러한 네트워크의 조합과 함께 사용 가능한 임의의 디바이스를 포함하거나 임의의 디바이스와 결합할 수 있다. 컴포넌트는 IC, 그 일부, 개별 전자 디바이스, 또는 다른 모듈, 명령어 세트, 프로그램 가능 로직 또는 알고리 즘, 하드웨어, 하드웨어 가속기, 소프트웨어, 펌웨어, 또는 에지 컴퓨팅 노드에서 적응된 이들의 조합으로서, 또는 그와 달리 더 큰 시스템의 섀시 내에 통합된 컴포넌트로서 구현될 수 있다. 에지 컴퓨팅 디바이스는 마이크로프로세서, 멀티-코어 프로세서, 멀티쓰레드 프로세서, 초 저전압 프로세 서, 임베디드 프로세서, 또는 다른 알려진 처리 요소일 수 있는 프로세서 형태의 처리 회로를 포함할 수 있다. 프로세서는 프로세서 및 다른 컴포넌트가 단일 집적 회로 또는 캘리포니아 산타 클라라 소 재의 인텔 코포레이션의 Edison™또는 Galileo™SoC 보드와 같은 단일 패키지로 형성되는 시스템 온 칩(SoC)의 일부일 수 있다. 예로서, 프로세서는 Quark™Atom™또는 MCU 급 프로세서와 같은 Intel®Architecture Core™ 기반 CPU 프로세서 또는 Intel®로부터 입수 가능한 다른 그러한 프로세서를 포함할 수 있다. 그러나 이를 테면 캘리포니아 서니베일 소재의 Advanced Micro Devices, Inc. (AMD®캘리포니아 서니베일 소재의 MIPS Technologies, Inc.의 MIPS®기반 설계, ARM Holdings, Ltd. 로부터 라이센싱된 ARM® 기반 설계, 또는 그 고 객, 또는 사용권자 또는 채택자(adaptor)로부터 입수 가능한 임의의 수의 다른 프로세서가 사용될 수 있다. 프 로세서는 Apple®Inc.의 A5-A13 프로세서, Qualcomm®Technologies, Inc.의 Snapdragon™프로세서 또는 Texas Instruments, Inc.의 OMAP™프로세서와 같은 유닛을 포함할 수 있다. 프로세서 및 동반 회로는 제한된 하드웨어 구성 또는 도 22에 도시된 모든 요소보다 적은 수를 포함하는 구성을 비롯한, 단일 소켓 폼 팩터, 다 중 소켓 폼 팩터 또는 다양한 다른 포맷으로 제공될 수 있다. 프로세서는 상호 연결(예를 들어, 버스)을 통해 시스템 메모리와 통신할 수 있다. 임의의 수의 메모리 디바이스가 주어진 양의 시스템 메모리를 제공하기 위해 사용될 수 있다. 예로서, 메모리는 DDR 또는 모바일 DDR 표준(예를 들어, LPDDR, LPDDR2, LPDDR3 또는 LPDDR4)과 같은 JEDEC(Joint Electron Devices Engineering Council) 설계에 따른 랜덤 액세스 메모리(RAM)일 수 있다. 특정 예에서, 메모리 컴포넌트는 DDR SDRAM의 경우 JESD79F, DDR2 SDRAM의 경우 JESD79-2F, DDR3 SDRAM의 경우 JESD79-3F, DDR4 SDRAM의 경우 JESD79-4A, 저전력 DDR(Low Power DDR, LPDDR)의 경우 JESD209, LPDDR2의 경우 JESD209-2, LPDDR3의 경우 JESD209-3, 및 LPDDR4의 경우 JESD209-4와 같이 JEDEC에서 발표된 DRAM 표준을 준수할 수 있다. 이러한 표준 (및 유사 표준)은 DDR 기반 표준이라고 지칭될 수 있으며 이러한 표준을 구현하는 스토리지 디바이스의 통신 인 터페이스는 DDR 기반 인터페이스라고 지칭될 수 있다. 다양한 구현에서, 개별 메모리 디바이스는 단일 다이 패 키지(single die package)(SDP), 이중 다이 패키지(dual die package)(DDP) 또는 쿼드 다이 패키지(quad die package)(Q17P)와 같은 임의의 수의 상이한 패키지 유형을 가질 수 있다. 이러한 디바이스는, 일부 예에서, 마 더 보드에 직접 납땜되어 더 낮은 프로파일 솔루션을 제공할 수 있는 반면, 다른 예에서 디바이스는 주어진 커 넥터에 의해 차례로 마더 보드에 결합되는 하나 이상의 메모리 모듈로서 구성된다. 다른 유형의 메모리 모듈, 예를 들어 이것으로 제한되는 것은 아니지만 microDIMM 또는 MiniDIMM을 비롯한 여러 다양성의 듀얼 인라인 메 모리 모듈(dual inline memory modules)(DIMM)과 같은 임의의 수의 다른 메모리 구현이 사용될 수 있다. 데이터, 애플리케이션, 운영 체제 등과 같은 정보의 지속적인 저장을 제공하기 위해, 스토리지는 또한 상 호 연결를 통해 프로세서에 연결될 수 있다. 예에서, 스토리지는 솔리드 스테이트 디스크 드라이브(solid-state disk drive)(SSDD)를 통해 구현될 수 있다. 스토리지 용으로 사용될 수 있는 다 른 디바이스는 SD 카드, 마이크로SD 카드, XD 픽처 카드 등과 같은 플래시 메모리 카드, 및 USB 플래시 드라이 브를 포함한다. 예에서, 메모리 디바이스는 칼코게나이드 유리를 사용하는 메모리 디바이스, 다중 임계 레벨 NAND 플래시 메모리, NOR 플래시 메모리, 단일 또는 다중 레벨 상 변화 메모리(Phase Change Memory)(PCM), 저 항성 메모리, 나노와이어 메모리, 강유전성 트랜지스터 랜덤 액세스 메모리(ferroelectric transistor random access memory)(FeTRAM), 반 강유전성 메모리, 멤리스터 기술을 통합한 자기저항 랜덤 액세스 메모리 (magnetoresistive random access memory)(MRAM) 메모리, 금속 산화물 베이스를 포함하는 저항성 메모리, 산소 빈자리 베이스(oxygen vacancy base) 및 전도성 브리지 랜덤 액세스 메모리(conductive bridge Random Access Memory)(CB-RAM)) 또는 스핀 전달 토크(spin transfer torque)(STT)-MRAM, 스핀트로닉 자기 접합 메모리 기반 디바이스(spintronic magnetic junction memory based device), 자기 터널링 접합(magnetic tunneling junction)(MTJ) 기반 디바이스, DW(Domain Wall) 및 SOT(Spin Orbit Transfer) 기반 디바이스, 사이리스터 기 반 메모리 디바이스 또는 위의 임의의 조합 또는 다른 메모리일 수 있거나 이를 포함할 수 있다. 저전력 구현에서, 스토리지는 프로세서와 연관된 온-다이 메모리 또는 레지스터일 수 있다. 그러 나, 일부 예에서, 스토리지는 마이크로 하드 디스크 드라이브(hard disk drive)(HDD)를 사용하여 구현될 수 있다. 또한, 설명된 기술 이외에, 또는 그 대신에, 다른 것 중에서도, 이러한 저항 변화 메모리, 상 변화 메모리, 홀로그래픽 메모리, 또는 화학적 메모리와 같은 임의의 수의 새로운 기술이 스토리지에 사용될 수 있다. 컴포넌트는 상호 연결을 통해 통신할 수 있다. 상호 연결은 산업 표준 아키텍처(industry standard architecture)(ISA), 확장된 ISA(extended ISA)(EISA), 주변 컴포넌트 상호 연결(peripheral component interconnect)(PCI), 주변 컴포넌트 상호 연결 확장(peripheral component interconnect extended)(PCIx), PCI 익스프레스(PCIe) 또는 임의의 수의 다른 기술을 비롯한 임의의 수의 기술을 포함할 수 있다. 상호 연결은 예를 들어 SoC 기반 시스템에서 사용되는 독점 버스일 수 있다. 다른 것 중에서도, I2C 인터페이스, SPI 인터페이스, 포인트 투 포인트 인터페이스 및 전력 버스와 같은 다른 버스 시스템이 포함 될 수 있다. 상호 연결은 연결된 에지 디바이스와의 통신을 위해 프로세서를 송수신기에 결합할 수 있다. 송수신기는 다른 것 중에서도, 블루투스 ® Special Interest Group에 의해 정의된 바와 같은 블 루투스 ® 저전력(BLE) 표준 또는 지그비® 표준을 사용하는 IEEE 802.15.4 표준에 따른 2.4 기가헤르쯔 (Gigahertz)(GHz) 전송과 같은 임의의 수의 주파수 및 프로토콜을 사용할 수 있다. 특정 무선 통신 프로토콜 용으로 구성된 임의의 수의 무선 장치(radio)가 커넥티드 에지 디바이스와 연결을 위해 사용될 수 있다. 예를 들어, 무선 근거리 네트워크(WLAN) 유닛은 IEEE(Institute of Electrical and Electronics Engineers) 802.11 표준에 따라 Wi-Fi®통신을 구현하는 데 사용될 수 있다. 또한, 예를 들어 셀룰러 또는 다른 무선 광역 프로토콜에 따른 무선 광역 통신은 무선 광역 네트워크(wireless wide area network)(WWAN) 유닛을 통해 발생할 수 있다. 무선 네트워크 송수신기(또는 다중 송수신기)는 상이한 범위에서 통신을 위해 다중 표준 또는 무선 장치 를 사용하여 통신할 수 있다. 예를 들어, 에지 컴퓨팅 노드는 전력을 절약하기 위해 BLE에 기초한 로컬 송수신기 또는 다른 저전력 무선 장치를 사용하여, 예를 들어 약 10 미터 이내의 근접 디바이스와 통신할 수 있 다. 예를 들어, 약 50 미터 이내의 더 먼 커넥티드 에지 디바이스는 지그비® 또는 다른 중간 전력 무선 장치를 통해 도달될 수 있다. 두 통신 기술은 모두 상이한 전력 레벨에서 단일 무선 장치를 통해 발생하거나 또는 별도의 송수신기, 예를 들어 BLE를 사용하는 로컬 송수신기 및 지그비®를 사용하는 별도의 메시 송수신기 를 통해 발생할 수 있다. 근거리 또는 광역 네트워크 프로토콜을 통해 에지 클라우드 내의 디바이스 또는 서비스와 통신하는 무선 네트워크 송수신기(예를 들어, 무선 송수신기)가 포함될 수 있다. 무선 네트워크 송수신기는 다른 것 중에서도, IEEE 802.15.4 또는 IEEE 802.15.4g 표준을 따르는 LPWA 송수신기일 수 있다. 에지 컴퓨팅 노드 는 Semtech 및 LoRa Alliance에 의해 개발된 LoRaWAN™(Long Range Wide Area Network)을 사용하여 넓은 영역을 통해 통신할 수 있다. 본 명세서에서 설명된 기술은 이러한 기술로 제한되지 않고 Sigfox 및 다른 기술 과 같은 장거리 저 대역 통신을 구현하는 임의의 수의 다른 클라우드 송수신기와 함께 사용될 수 있다. 또한, IEEE 802.15.4e 사양에 설명된 시간 슬롯 채널 호핑(time-slotted channel hopping)과 같은 다른 통신 기술이 사용될 수 있다. 본 명세서에서 설명된 바와 같이, 무선 네트워크 송수신기에 대해 언급된 시스템에 추가하여 임의의 수의 다른 무선 통신 및 프로토콜이 사용될 수 있다. 예를 들어, 송수신기는 고속 통신을 구현하기 위해 확산 스펙트럼(spread spectrum)(SPA/SAS) 통신을 사용하는 셀룰러 송수신기를 포함할 수 있다. 또한, 중간 속도 통 신 및 네트워크 통신을 제공하기 위한 Wi-Fi®네트워크와 같은 임의의 수의 다른 프로토콜이 사용될 수 있다. 송수신기는 본 개시내용의 끝에서 더 자세히 논의되는, 롱 텀 에볼루션(Long Term Evolution)(LTE) 및 5G(5 세대) 통신 시스템과 같은 임의의 수의 3 세대 파트너십 프로젝트(Third Generation Partnership Project)(3GPP) 사양과 호환되는 무선 장치를 포함할 수 있다. 네트워크 인터페이스 제어기(NIC)는 에지 클라우드의 노드 또는 (예를 들어, 메시에서 동작하는) 커넥티드 에지 디바이스와 같은 다른 디바 이스에 유선 통신을 제공하기 위해 포함될 수 있다. 유선 통신은 이더넷 연결을 제공할 수 있거나 또는 많은 다른 것 중에서도, CAN(Controller Area Network), LIN(Local Interconnect Network), DeviceNet, ControlNet, Data Highway+, PROFIBUS 또는 PROFINET과 같은 다른 유형의 네트워크에 기초할 수 있다. 추가 NIC, 예를 들어, 이더넷을 통해 클라우드에 통신을 제공하는 제 1 NIC 및 다른 유형의 네트워크를 통해 다른 디바이스에 통신을 제공하는 제 2 NIC가 제 2 네트워크에 연결할 수 있도록 포함될 수 있다. 디바이스로부터 다른 컴포넌트 또는 네트워크로 적용 가능한 다양한 유형의 통신을 고려해 볼 때, 디바이스에 의해 사용되는 적용 가능한 통신 회로는 컴포넌트(2264, 2266, 2268 또는 2270) 중 임의의 하나 이상을 포함하 거나 또는 그에 의해 구현될 수 있다. 따라서, 다양한 예에서, 통신(예를 들어, 수신, 송신 등)을 위한 적용 가능한 수단은 이러한 통신 회로에 의해 구현될 수 있다. 에지 컴퓨팅 노드는 하나 이상의 AI 가속기, 신경 컴퓨트 스틱(neural compute stick), 뉴로모픽 하드웨 어(neuromorphic hardware), FPGA, GPU의 배열, 하나 이상의 SoC, 하나 이상의 CPU, 하나 이상의 디지털 신호 프로세서, 전용 ASIC 또는 하나 이상의 특화된 작업을 달성하도록 설계된 다른 형태의 특화된 프로세서 또는 회 로에 의해 구현될 수 있는 가속 회로를 포함하거나 또는 그에 결합될 수 있다. 이러한 작업은 (머신 학 습, 훈련, 추론 및 분류 동작을 포함하는) AI 처리, 시각적 데이터 처리, 네트워크 데이터 처리, 객체 검출, 규 칙 분석 등을 포함할 수 있다. 상호 연결은 프로세서를 추가 디바이스 또는 서브시스템을 연결하는 데 사용되는 센서 허브 또는 외부 인터페이스에 결합할 수 있다. 디바이스는 가속도계, 레벨 센서, 유동 센서, 광학 광 센서, 카메라 센서, 온도 센서, 글로벌 내비게이션 시스템(global navigation system)(예를 들어, GPS) 센서, 압력 센서, 기 압 센서 등과 같은 센서를 포함할 수 있다. 허브 또는 인터페이스는 또한 에지 컴퓨팅 노드(225 0)를 전력 스위치, 밸브 액추에이터, 가청 사운드 생성기, 시각적 경고 디바이스 등과 같은 액추에이터에 연결하는 데 사용될 수 있다. 일부 선택적 예에서, 다양한 입력/출력(I/O) 디바이스가 에지 컴퓨팅 노드 내에 존재하거나 이에 연결될 수 있다. 예를 들어, 디스플레이 또는 다른 출력 디바이스가 센서 판독 값 또는 액추에이터 위치와 같은 정보를 보여주기 위해 포함될 수 있다. 터치 스크린 또는 키패드와 같은 입력 디바이스가 입력을 받아들 이기 위해 포함될 수 있다. 출력 디바이스는 이진 상태 표시기(예를 들어, LED) 및 다중 문자 시각적 출 력과 같은 단순한 시각적 출력, 또는 디스플레이 스크린(예를 들어, LCD 스크린)과 같은 더 복잡한 출력을 비롯 한 임의의 수의 형태의 오디오 또는 시각적 디스플레이를 포함할 수 있으며, 문자, 그래픽, 멀티미디어 객체 등 의 출력이 에지 컴퓨팅 노드의 동작으로부터 생성되거나 발생된다. 본 시스템의 컨텍스트에서, 디스플레 이 또는 콘솔 하드웨어는 에지 컴퓨팅 시스템의 출력을 제공하고 입력을 수신하고; 에지 컴퓨팅 시스템의 컴포 넌트 또는 서비스를 관리하고; 에지 컴퓨팅 컴포넌트 또는 서비스의 상태를 식별하고; 또는 임의의 다른 수의 관리 또는 행정 기능 또는 서비스 유스 케이스를 수행하는 데 사용될 수 있다. 배터리는 에지 컴퓨팅 노드에 전력을 공급할 수 있지만, 에지 컴퓨팅 노드가 고정 위치에 장 착된 예에서는 전기 그리드에 결합된 전력 공급 디바이스를 가질 수 있고 또는 배터리는 백업으로서 또는 임시 기능을 위해 사용될 수 있다. 배터리는 리튬 이온 배터리 또는 아연-공기 배터리, 알루미늄-공기 배터리, 리튬-공기 배터리 등과 같은 금속-공기 배터리일 수 있다. 만약 포함된다면 에지 컴퓨팅 노드에서 배터리의 충전 상태(state of charge)(SoCh)를 추적하기 위 해 배터리 모니터/충전기가 포함될 수 있다. 배터리 모니터/충전기는 배터리의 다른 파라미 터를 모니터링하여 배터리의 건강 상태(state of health)(SoH) 및 기능 상태(state of function)(SoF)와 같은 고장 예측을 제공하는 데 사용될 수 있다. 배터리 모니터/충전기는 Linear Technologies의 LTC4020 또는 LTC2990, 페닉스 아리조나 소재의 ON Semiconductor의 ADT7488A, 텍사스 달라스 소재의 Texas Instruments의 UCD90xxx 제품군의 IC와 같은 배터리 모니터링 집적 회로를 포함할 수 있다. 배터리 모니터/충 전기는 상호 연결을 통해 배터리에 대한 정보를 프로세서에 전달할 수 있다. 배터리 모니터/충전기는 또한 프로세서가 배터리의 전압 또는 배터리로부터의 전류 흐름을 직 접 모니터링할 수 있게 하는 아날로그-디지털(analog-to-digital)(ADC) 변환기를 포함할 수 있다. 배터리 파라 미터는 송신 주파수, 메시 네트워크 동작, 감지 주파수 등과 같이 에지 컴퓨팅 노드가 수행할 수 있는 행 동을 결정하는 데 사용될 수 있다. 전력 블록 또는 그리드에 결합된 다른 전력 공급 장치가 배터리 모니터/충전기와 결합되어 배터리 를 충전할 수 있다. 일부 예에서, 전력 블록은 예를 들어, 에지 컴퓨팅 노드의 루프 안테나 를 통해 무선으로 전력을 획득하는 무선 전력 수신기로 대체될 수 있다. 다른 것 중에서도, 캘리포니아 밀피타 스 소재의 Linear Technologies로부터의 LTC4020 칩과 같은 무선 배터리 충전 회로가 배터리 모니터/충전기 에 포함될 수 있다. 특정 충전 회로가 배터리의 크기 및 필요한 전류에 기초하여 선택될 수 있다. 충전은 다른 것 중에서도, Airfuel Alliance에서 발표한 Airfuel 표준, Wireless Power Consortium에서 발표한 Qi 무선 충전 표준, 또는 Alliance for Wireless Power에서 발표한 Rezence 충전 표준을 사용하여 수행될 수 있다. 스토리지는 본 명세서에서 설명된 기술을 구현하는 소프트웨어, 펌웨어 또는 하드웨어 커맨드 형태의 명 령어를 포함할 수 있다. 이러한 명령어가 메모리 및 스토리지에 포함된 코드 블록으 로 도시되지만, 임의의 코드 블록은 예를 들어 주문형 집적 회로(ASIC)에 내장된 고정 배선 회로(hardwired circuit)로 대체될 수 있다는 것을 이해할 수 있다.예에서, 메모리, 스토리지 또는 프로세서를 통해 제공되는 명령어는 프로세서에 게 에지 컴퓨팅에서 전자적 동작을 수행하도록 지시하는 코드를 포함하는 비 일시적 머신 판독 가능 매체(226 0)로서 구현될 수 있다. 프로세서는 상호 연결을 통해 비 일시적 머신 판독 가능 매체에 액 세스할 수 있다. 예를 들어, 비 일시적 머신 판독 가능 매체는 스토리지에 대해 설명된 디바이스 에 의해 구현될 수 있거나 또는 광학 디스크, 플래시 드라이브 또는 임의의 수의 다른 하드웨어 디바이스와 같 은 특정 스토리지 유닛을 포함할 수 있다. 비 일시적 머신 판독 가능 매체는 프로세서에게, 예를 들어, 위에서 도시된 동작 및 기능성의 흐름도(들) 및 블록도(들)에 대해 설명된 바와 같은, 특정 시퀀스 또는 작용의 흐름을 수행하도록 지시하는 명령어를 포함할 수 있다. 본 명세서에서 사용된 바와 같이, \"머신 판독 가능 매체\" 및 \"컴퓨터 판독 가능 매체\"라는 용어는 상호 교환 가능하다. 추가 예에서, 머신 판독 가능 매체는 또한 머신에 의해 실행하기 위한 명령어를 저장, 인코딩 또는 전달할 수 있고, 머신으로 하여금 본 개시내용의 방법론 중 임의의 하나 이상을 수행하게 하거나 또는 이러한 명령어에 의 해 이용되거나 이와 연관된 데이터 구조를 저장, 인코딩 또는 전달할 수 있는 임의의 유형 매체(tangible medium)를 포함한다. 따라서 \"머신 판독 가능 매체\"는 이것으로 제한되는 것은 아니지만, 솔리드-스테이트 메 모리, 광학 및 자기 매체를 포함할 수 있다. 머신 판독 가능 매체의 특정 예는 이것으로 제한되는 것은 아니지 만, 예로서 반도체 메모리 디바이스(예를 들어, 전기적 프로그램 가능 판독 전용 메모리(electrical programmable read-only memory)(EPROM), 전기적 소거 가능 프로그램 가능 판독 전용 메모리(electrical erasable programmable read-only memory)(EEPROM) 및 플래시 메모리 디바이스; 내부 하드 디스크 및 착탈식 디스크와 같은 자기 디스크; 광자기 디스크; 및 CD-ROM 및 DVD-ROM 디스크를 포함하는 비 휘발성 메모리를 포함 한다. 머신 판독 가능 매체에 의해 구현된 명령어는 다수의 전송 프로토콜 중 어느 하나(예를 들어, HTTP) 를 이용하는 네트워크 인터페이스 디바이스를 통해 전송 매체를 사용하는 통신 네트워크를 통해 송신 또는 수신될 수 있다. 머신 판독 가능 매체는 데이터를 비 일시적 포맷으로 호스팅할 수 있는 스토리지 디바이스 또는 다른 장치에 의 해 제공될 수 있다. 예에서, 머신 판독 가능 매체에 저장되거나 그와 달리 제공된 정보는 명령어 자체 또는 명 령어가 도출될 수 있는 포맷과 같은 명령어를 나타낼 수 있다. 명령어가 도출될 수 있는 이러한 포맷은 소스 코드, (예를 들어, 압축된 또는 암호화된 형태의) 인코딩된 명령어, (예를 들어, 다수의 패키지로 분할된) 패키 지된 명령어 등을 포함할 수 있다. 머신 판독 가능 매체 내의 명령어를 나타내는 정보는 처리 회로에 의해 본 명세서에서 논의된 임의의 동작을 구현하는 명령어로 처리될 수 있다. 예를 들어, 정보로부터 명령어를 도출하 는 것(예를 들어, 처리 회로에 의해 처리하는 것)은: (예를 들어, 소스 코드, 객체 코드 등으로부터) 컴파일, 해석, 로딩, 구성(예를 들어, 동적 또는 정적으로 링크), 인코딩, 디코딩, 암호화, 암호화 해제, 패키징, 패키 징 해제, 또는 그렇지 않으면 정보를 명령어로 조작하는 것을 포함할 수 있다. 예에서, 명령어의 도출은 머신 판독 가능 매체에 의해 제공되는 일부 중간 또는 전처리된 포맷으로부터 명령어 를 생성하기 위해 (예를 들어, 처리 회로에 의해) 정보를 조립, 컴파일 또는 해석하는 것을 포함할 수 있다. 정보는 다수의 부분으로 제공될 때, 결합되고, 언패킹되고 수정되어 명령어를 생성할 수 있다. 예를 들어, 정 보는 하나 또는 여러 원격 서버상에서 다수의 압축된 소스 코드 패키지(또는 개체 코드 또는 바이너리 실행 코 드 등) 내에 있을 수 있다. 소스 코드 패키지는 네트워크를 통해 전송될 때 암호화되고 필요한 경우 해독되고, 압축 해제되고, 조립되고(예를 들어, 링크되고), 로컬 머신에서 (예를 들어, 라이브러리, 스탠드얼론 실행 파일 등)으로 컴파일 또는 해석되고, 로컬 머신에 의해 실행될 수 있다. 도 22c는 예시적인 모바일 디바이스 내의 통신 컴포넌트의 블록도이다. 이러한 모바일 디바이스는 사용자 장비 또는 사용자 장비의 컴포넌트로서 구현될 때 노드 또는 디바이스의 통신 처리 컴포넌 트의 더 자세한 뷰를 제공한다. 모바일 디바이스는 무선 프런트-엔드 모듈(front-end module)(FEM) 회로 , 무선 IC 회로 및 베이스밴드 처리 회로를 포함할 수 있다. 도시된 바와 같은 모바일 디바 이스는 디바이스의 양태는 그렇게 제한되는 것은 아니지만 무선 근거리 통신 네트워크(WLAN) 기능성 및 블루투스(Bluetooth)(BT) 기능성을 둘 모두 포함하며, 본 명세서에서 논의되는 다른 무선 기술은 유사한 회로에 의해 구현될 수 있다. FEM 회로는 예를 들어, WLAN 또는 Wi-Fi FEM 회로(2234A) 및 블루투스(BT) FEM 회로(2234B)를 포함할 수 있다. WLAN FEM 회로(2234A)는 하나 이상의 안테나(2231A)로부터 수신된 WLAN RF 신 호에 대해 동작하고, 수신된 신호를 증폭하고 증폭된 버전의 수신 신호를 추가 처리를 위해 WLAN 무선 IC 회로 (2236A)에 제공하도록 구성된 회로를 포함하는 수신 신호 경로를 포함할 수 있다. BT FEM 회로(2234B)는 하나 이상의 안테나(2231B)로부터 수신된 BT RF 신호에 대해 동작하고, 수신된 신호를 증폭하고 증폭된 버전의 수신 신호를 추가 처리를 위해 BT 무선 IC 회로(2236B)에 제공하도록 구성된 회로를 포함할 수 있는 수신 신호 경로를 포함할 수 있다. FEM 회로(2234A)는 또한 무선 IC 회로(2236A)에 의해 제공되는 WLAN 신호를 증폭하여 하나 이상의 안테나(2231A)에 의해 무선 송신하도록 구성된 회로를 포함할 수 있는 송신 신호 경로를 포함할 수 있다. 또한, FEM 회로(2234B)는 무선 IC 회로(2236B)에 의해 제공되는 BT 신호를 증폭하여 하나 이상의 안테나 (2231B)에 의해 무선 송신하도록 구성된 회로를 포함할 수 있는 송신 신호 경로를 또한 포함할 수 있다. 도 22c의 예에서, FEM(2234A) 및 FEM(2234B)가 서로 구별되는 것으로 도시되어 있지만, 본 개시내용의 양태는 그렇 게 제한되지 않고, 그 범위 내에서는 WLAN 및 BT 신호 둘 모두에 대한 송신 경로 및/또는 수신 경로를 포함하는 FEM(도시되지 않음)의 사용, 또는 FEM 회로 중 적어도 일부가 WLAN 및 BT 신호 둘 모두에 대한 송신 및/또는 수 신 신호 경로를 공유하는 하나 이상의 FEM 회로의 사용을 포함한다.. 도시된 바와 같은 무선 IC 회로는 WLAN 무선 IC 회로(2236A) 및 BT 무선 IC 회로(2236B)를 포함할 수 있 다. WLAN 무선 IC 회로(2236A)는 FEM 회로(2234A)로부터 수신된 WLAN RF 신호를 하향 변환하고 베이스밴드 신 호를 WLAN 베이스밴드 처리 회로(2238A)에 제공하는 회로를 포함할 수 있는 수신 신호 경로를 포함할 수 있다. BT 무선 IC 회로(2236B)는 차례로 FEM 회로(2234B)로부터 수신된 BT RF 신호를 하향 변환하고 베이스밴드 신호 를 BT 베이스밴드 처리 회로(2238B)에 제공하는 회로를 포함할 수 있는 수신 신호 경로를 포함할 수 있다. WLAN 무선 IC 회로(2236A)는 또한 WLAN 베이스밴드 처리 회로(2238A)에 의해 제공되는 WLAN 베이스밴드 신호를 상향 변환하고 WLAN RF 출력 신호를 FEM 회로(2234A)에 제공하여 하나 이상의 안테나(2231A)에 의한 후속 무선 송신을 위한 회로를 포함할 수 있는 송신 신호 경로를 포함할 수 있다. BT 무선 IC 회로(2236B)는 또한 BT 베 이스밴드 처리 회로(2238B)에 의해 제공되는 BT 베이스밴드 신호를 상향 변환하고 BT RF 출력 신호를 FEM 회로 (2234B)에 제공하여 하나이상의 안테나(2231B)에 의한 후속 무선 송신을 위한 회로를 포함할 수 있는 송신 신호 경로를 포함할 수 있다. 도 22c의 예에서, 무선 IC 회로(2236A 및 2236B)가 서로 구별되는 것으로 도시되어 있 지만, 본 개시내용의 양태는 그렇게 제한되지 않고, 그 범위 내에서는 WLAN 및 BT 신호 둘 모두에 대한 송신 신 호 경로 및/또는 수신 신호 경로를 포함하는 무선 IC 회로(도시되지 않음)의 사용, 또는 무선 IC 회로 중 적어 도 일부가 WLAN 및/또는 BT 신호 둘 모두에 대한 송신 및/또는 수신 신호 경로를 공유하는 하나 이상의 무선 IC 회로의 사용을 포함한다. 베이스밴드 처리 회로는 WLAN 베이스밴드 처리 회로(2238A) 및 BT 베이스밴드 처리 회로(2238B)를 포함할 수 있다. WLAN 베이스밴드 처리 회로(2238A)는 예를 들어, WLAN 베이스밴드 처리 회로(2238A)의 고속 푸리에 변환 또는 역 고속 푸리에 변환 블록(도시되지 않음) 내 한 세트의 RAM 어레이와 같은 메모리를 포함할 수 있다. WLAN 베이스밴드 회로(2238A) 및 BT 베이스밴드 회로(2238B) 각각은 무선 IC 회로의 대응하는 WLAN 또는 BT 수신 신호 경로로부터 수신된 신호를 처리하고, 또한 무선 IC 회로의 송신 신호 경로에 대 한 대응하는 WLAN또는 BT베이스밴드 신호를 생성하는 하나 이상의 프로세서 및 제어 로직을 더 포함할 수 있다. 베이스밴드 처리 회로(2238A 및 2238B) 각각은 물리 계층(physical layer)(PHY) 및 매체 액세스 제어 계층 (medium access control layer)(MAC)을 더 포함할 수 있고, 베이스밴드 신호의 생성 및 처리를 위한 그리고 무 선 IC 회로의 동작을 제어하기 위한 애플리케이션 프로세서(또는 다른 예에서는 프로세서 회로 )와의 인터페이스를 더 포함할 수 있다. 도 22c를 계속 참조하면, 도시된 양태에 따라, WLAN-BT 공존 회로(coexistence circuitry)는 WLAN 베이 스밴드 회로(2238A)와 BT 베이스밴드 회로(2238B) 사이에 인터페이스를 제공하여 WLAN 및 BT 공존을 요구하는 유스 케이스를 가능하게 하는 로직을 포함할 수 있다. 또한, 스위치가 WLAN FEM 회로(2234A)와 BT FEM 회로(2234B) 사이에 제공되어 애플리케이션 요구에 따라 WLAN과 BT 무선 장치 사이의 스위칭을 가능하게 할 수 있다. 또한, 안테나(2231A, 2231B)가 WLAN FEM 회로(2234A) 및 BT FEM 회로(2234B)에 각각 연결되는 것으로 도시되어 있지만, 본 개시내용의 양태는 그 범위 내에서 WLAN과 BT 사이에서처럼 하나 이상의 안테나의 공유 또 는 FEM(2234A) 또는 (2234B) 각각에 연결된 하나 초과의 안테나의 제공을 포함한다. 본 개시내용의 일부 양태에서, 프론트-엔드 모듈 회로, 무선 IC 회로 및 베이스밴드 처리 회로 는 단일 무선 카드 상에 제공될 수 있다. 다른 양태에서, 하나 이상의 안테나(2231A, 2231B), FEM 회로 및 무선 IC 회로는 단일 무선 카드 상에 제공될 수 있다. 본 개시내용의 일부 다른 양태에서, 무 선 IC 회로 및 베이스밴드 처리 회로는 단일 칩 또는 집적 회로(IC) 상에 제공될 수 있다. 또 다른 예에서, 컴퓨팅 노드의 컴퓨트 캐퍼빌리티는 컴퓨테이션 캐퍼빌리티(computational capability)으로 구 현되는 데이터 스토리지 솔루션을 지칭하는 컴퓨테이션 스토리지(computational storage) 또는 \"컴퓨트-인-스토 리지(compute-in-storage)\"로 구현될 수 있다. 다양한 예에서, 컴퓨트-인-스토리지는 블록 스토리지 디바이스 (block storage device)에서 컴퓨트 오프로딩(compute offloading)으로서 구현될 수 있고; 객체 기반 스토리지 디바이스에서 컴퓨팅 오프로딩을 사용하고; 분산 스토리지 시스템에서 컴퓨트 오프로딩을 사용하고; 또는 분리된 스토리지 환경 사이에 제공되는 컴퓨트 오프로딩을 사용하여 구현될 수 있다. 예시적인 컴퓨트-인-스토리지 시스템은 하나 이상의 스토리지 디바이스로부터 제공될 수 있으며, 여기서 각각의 스토리지 디바이스는 비 휘발 성 메모리 및 컴퓨팅 오프로드 제어기를 포함한다. 이 시스템에서 비 휘발성 메모리는 데이터를 저장하고 컴퓨 트 오프로드 제어기는 호스트 프로세서로부터의 컴퓨트 오프로드 명령어에 기초하여 데이터에 대해 컴퓨트 작업 을 수행한다. 다른 예 중에서도, 가속 캐퍼빌리티 및 기능은 이러한 컴퓨트-인-스토리지 구성을 사용하여 제공 될 수 있다. 도 22d는 서버의 일부 또는 에지 플랫폼 아키텍처의 다른 개별 컴퓨트 노드에 포함될 수 있는 랙 스케일 설계 (Rack Scale Design)(RSD) 컴포넌트를 도시한다. 이러한 배열은 (예를 들어, 서버 랙 내, 블레이드 내) 노드로 서 구현될 때 노드 또는 디바이스의 구성 가능한 처리 컴포넌트의 더 자세한 뷰를 제공한다. 이러 한 구성 가능한 아키텍처는 필드 프로그램 가능 게이트 어레이(FPGA), 비 휘발성 메모리 익스프레스(Non- Volatile Memory Express)(MVMe) 및 입력/출력(I/O) 풀링 자원을 분리함으로써 일부 다른 아키텍처와 다르다. FPGA 및 NVMe 자원은 비디오 또는 음성 분석과 같은 임의의 유형의 에지 서비스에 사용될 수 있는 요소를 제공 한다. I/O 풀링은 유연한 네트워크 기능을 제공하는 데 사용될 수 있다. 이러한 아키텍처는 특정 가상 네트워 크 기능(virtual network function)(VNF)에 대한 예상 데이터 레이트 또는 네트워크 로드에 따라 네트워크 인터 페이스를 확장하는 것을 가능하게 할 수 있다. 이러한 아키텍처는 또한 주어진 노드에서 발생하는 네트워크 처 리의 유형에 따라 컴퓨트 노드에 다른 네트워크 카드를 매핑하는 유연성을 가능하게 한다. 도시된 RSD 아키텍처는 전송 지점(Point of Delivery)(POD) 관리자를 포함한다. POD 관리자는 POD(예를 들어, 하나 이상의 랙) 내의 자원 - 컴퓨트 자원 및 분리된 자원을 포함함 - 을 관리하는 역할을 한다. POD 관리자는 구성된 노드를 생성, 관리 또는 파괴하기 위해 인터페이스를 오케스트레이터에 노출 한다. 구성된 노드를 관리하는 것은 특정 컴퓨트 슬 레드(compute sled)에 연결되는 풀링된 자원 의 양을 늘리거나 줄이는 특징을 포함한다. POD 관리자는 전형적으로 노드 제어기에서 실행된다. POD 관리자는 POD에서 자원의 검색, 자원의 구성 및 관리, 논리 서버의 구성을 담당한다. 예에서, POD 관리 자는 선택적인 별도의 컴포넌트이며 랙에 있을 필요가 없을 것이다. 그러나, 예에서, \"RSD 준수\"를 위해 랙은 인증된 POD 관리자에 의해 관리 가능하다. 다음은 POD 관리자의 몇 가지 예시적인 속성이다. 예를 들어, 랙은 에지 서비스 및 (예를 들어, 오케스 트레이션 또는 다른 시스템 서비스와 같은) 다른 관련 시스템 소프트웨어 스택을 실행하는 데 사용되는 한 세트 의 컴퓨트 슬레드를 포함할 수 있다. 컴퓨트 슬레드의 한 유형은 풀링된 자원 슬레드일 수 있다. 이러한 컴퓨트 슬레드는 한 세트의 분리된 자원을 관리할 수 있다. 여기서, 컴퓨트 슬레드는 풀링 된 시스템 관리 엔진 소프트웨어(pooled System Management Engine software)(PSME)를 포함할 수 있다. PSME는 드로어 레벨(drawer level)에서 모듈 또는 블레이드를 관리하는 관리 인터페이스를 제공한다. 예 에서, 랙은 하나 이상의 논리 PSME(들)를 포함한다. 예를 들어, 각각의 드로어는 PSME를 갖거나 또는 서버 드 로어는 PSME를 공유할 수 있거나 또는 PSME는 톱-오브-랙(Top-of-Rack)(TOR) 스위치 또는 별도의 호스트 에서 실행될 수 있다. 예에서, PSME 은 RSD API를 지원한다. 예에서, 컴퓨트 슬레드는 RSD 소프트웨어 스택을 실행하여 타겟 시스템으로서 작용하는 NVM-oF 또는 FPGA-oF를 구현하고 분리된 자원 세트를 관리하는 프로세서(예를 들어, CLX)를 포함할 수 있다. 예에서, 프로 세서는 PCIex16 분기 포트를 사용하여 타겟 자원(RSD의 FPGA 또는 NVME)로의 액세스를 제공하는 PCIe 스 위치에 연결된다. 다양한 RSD 에지로 구성된 노드 플레이버가 컴퓨트 슬레드에서 에지 서비스를 실행하는 데 사용될 수 있 다. 이러한 노드에서 실행되는 서비스는 클라이언트 소프트웨어 라이브러리 또는 드라이버를 사용하여 RSD의 분리된 FPGAS 및 NVME로의 투명한 액세스를 제공할 수 있다. 추가 예에서, 랙은 컴퓨트 슬레드 를 분리된 자원 세트(예를 들어, RSD)에 연결하는 하나 이상의 PCIE 스위치를 포함한다. 도 22a, 도 22b, 도 22c 및 도 22d의 블록도는 에지 컴퓨팅 노드의 다양한 디바이스, 서브시스템 또는 배열의 컴포넌트에 대한 상위 레벨 뷰를 도시하려 의도된다. 그러나, 도시된 컴포넌트 중 일부는 생략될 수 있고, 추 가 컴포넌트가 존재할 수 있으며, 도시된 컴포넌트의 상이한 배열이 다른 구현에서 발생할 수 있다는 것을 이해 할 것이다. 또한, 이러한 배열은 아래에서 논의되는 것(예를 들어, 다른 많은 예 중에서도, 스마트 시티 또는 스마트 공장을 위한 산업용 컴퓨트에서 모바일 UE)을 비롯한 다양한 유스 케이스 및 환경에서 사용 가능하다. 도 21a 내지 도 21c 및 도 22a 내지 도 22d의 각각의 컴퓨트 플랫폼은 단일 컴퓨트 플랫폼에서 실행되는 테넌트 컨테이너를 사용하여 다수의 에지 인스턴스(예를 들어, 에지 클러스터)를 지원할 수 있다. 마찬가지로, 다수의에지 노드는 동일한 컴퓨트 플랫폼 내의 테넌트상에서 실행되는 서브노드로서 존재할 수 있다. 따라서, 가용 자원 파티셔닝에 기초하여, 단일 시스템 또는 컴퓨트 플랫폼은 다수의 테넌트 및 에지 노드 인스턴스 - 그 각각 은 심지어 다수의 소유자에 의해 다수의 컴퓨트 플랫폼 인스턴스에서 잠재적으로 동작되거나 제어되면서도, 다 수의 서비스 및 기능을 지원할 수 있음 - 를 지원하는 것으로 분할되거나 나누어질 수 있다. 이러한 다양한 유 형의 파티션은 LSM을 사용하거나 또는 격리/보안 정책의 다른 구현을 통해 복잡한 다중 테넌시 및 많은 조합의 다중 이해 관계자를 지원할 수 있다. 따라서 이러한 보안 기능을 강화하거나 구현하는 LSM 및 보안 특징의 사 용에 대한 언급은 다음 섹션에서 설명된다. 마찬가지로, 이러한 다양한 유형의 다중 엔티티 파티션에서 운영하 는 서비스 및 기능은 필요한 서비스 목표 및 동작을 달성하기 위해 로드 밸런싱되고, 마이그레이션되고 오케스 트레이션될 수 있다. D. 에지 컴퓨팅 시스템의 유스 케이스 에지 컴퓨팅은 다중 시스템 컴퓨트 동작(다중 테넌트, 다중 사용자, 다중 이해 관계자, 다중 디바이스 등)을 수 반하는 많은 유형의 유스 케이스 및 배치를 위한 여러 가치 제안 및 핵심 성과 지표(KPI)를 충족한다. 이러한 가치 제안은 응답 지연시간을 개선하고 보안을 높이고, 백홀 트래픽을 낮출 수 있는 동시에, 새로운 유스 케이 스를 가능하게 할 수 있다. 특정 유스 케이스 또는 워크로드를 위한 실제 컴퓨팅 에지가 \"상주\"하는 위치를 정의하는 것은 특정 위치가 제 공하는 KPI 또는 가치 제안과 직접 관련이 있다. 예를 들어, 사업자 인프라스트럭처의 코어에서 IoT 또는 증강 현실/가상 현실(AR/VR) 워크로드를 위한 컴퓨트 에지를 정의하는 것은 지연시간 측면에서 KPI 요구 사항을 충족 하지 못한다. 따라서, 이러한 워크로드를 위한 컴퓨트 에지는 디바이스에 더 가깝게 위치한다(이를테면, 기지 국 또는 중앙국의 인접 에지 또는 중간 에지 계층에서, 컴퓨트 자원을 워크로드 데이터에 더 가깝게 가져온다). 한편, CDN 워크로드를 위한 컴퓨팅 에지는 기지국, 중앙국 또는 사업자 인프라스트럭처의 임의의 다른 중간 집 계 지점(POA 또는 POP)에서 호스팅될 수 있다. 최종 사용자에 의해 사용되는 디바이스(또는 디바이스의 메시)는 원거리 에지 디바이스로서 간주될 수 있지만, 많은 디바이스는 일부 컴퓨트 에지 캐퍼빌리티를 또한 제공한다. 이러한 시나리오의 디바이스는 가능한 가장 낮은 지연시간을 제공할 수 있으며 메시 또는 커넥티드 IoT 네트워크의 유형으로 서빙할 수 있다. 그러나 어떤 지점에서 최종 디바이스는 컴퓨트가 제한될 수 있거나 또는 주어진 작업을 수행하는 데 필요한 만큼 전력 효율 적이지 않을 수 있다. 예를 들어, 네트워크 트래픽 로드의 일부 지점에서, AR/VR 사용자는 (디바이스 자체의 원거리 에지에서 워크로드를 실행하는 것보다 더 나쁜 성능을 제공하는 지점까지도) 심각한 저하를 경험할 것이다. 다양한 네트워크 계층 중 에지 컴퓨팅의 최우선 순위는 중앙국(통신) 기능성, 주문형 비디오/콘텐츠 데이터 네 트워크 서빙, 미디어 분석, 라이브 스트리밍/트랜스코딩 및 온라인 게임을 포함하는 AV/VR을 포함한다. 중앙국 워크로드는 예를 들어, 수렴된 공간 및 새로운 서비스 모델을 위한 SDN/NFV를 포함할 수 있다. 주문형 비디오/ 콘텐츠 데이터 네트워크 워크로드는, 예를 들어 스트리밍, 감시, 경보 시스템, 빌딩 액세스 등을 포함할 수 있 다. 라이브 스트리밍/트랜스코딩은, 예를 들어 소셜 네트워킹 애플리케이션으로부터의 라이브 스트리밍과 같은 향상된 사용자 경험(user experience)(UX)을 포함할 수 있다. AR/VR 워크로드는, 예를 들어 실시간 소매 (real-time retail), 게임 네트워크 등을 포함할 수 있다. (오디오 및 비디오를 둘 모두 포함하는) 미디어 분 석은 또한 에지 배치 내에서 광범위하게 배치될 수 있다. 이러한 워크로드는 (예를 들어, 감시, AR 등과 같은) 앞서 언급한 많은 워크로드에서 사용되는 다른 중요한 부분이다. 이러한 우선순위 외에도, 에지 클라우드 내에서 다른 유스 케이스가 실시 가능해질 수 있다. 인-메모리 데이터 베이스(in-memory databases)(IMBD)는 에지 컴퓨팅 배치에 관한 설계에서 관련성이 더 많아지고 있다. 이들의 타겟 활용률은 온라인 트랜잭션 처리(online transaction processing)(OLTP, 소규모 판독 또는 기입과 같은 소 규모 트랜잭션 처리 요청을 처리하는 것) 및 온라인 분석 처리(online analytical processing)(OLAP, 더 큰 데 이터 세트 쿼리 및 컴퓨트 작업과 같은 대규모 분석 처리 요청을 처리하는 것)를 서빙하는 것이다. 이러한 두 유형의 워크로드는 주로 네트워크 분석에 매핑되어 인프라스트럭처 관리 또는 다른 유형의 분석 또는 (예를 들 어, IoT와 같은) 데이터 스토리지를 개선한다. 엔터프라이즈 및 정부의 유스 케이스가 또한 에지 클라우드 내에서 실시 가능해질 수 있다. 이 경우, 엔터프라 이즈 고객 중 일부는 자체 프로세스 중 일부를 개선할 잠재적인 방법으로서 잠재적인 에지 배치를 찾고 있다. 이것의 예는 씬 클라이언트(thin client)이다. 씬 클라이언트는 씬 클라이언트로의 짧은 지연시간 액세스를 제 공하기 위해 주어진 엔터프라이즈의 직원이 지리를 가로질러 이동할 때 에지 인프라스트럭처를 가로질러 이동할수 있다. 인더스트리 4.0 이니셔티브(Industry 4.0 initiative)와 관련된 유스 케이스가 또한 실시 가능해질 수 있다. 이것은 5G를 통한 매우 신뢰할 수 있는 낮은 지연시간 통신의 유스 케이스와 같은 제조업의 가상화에 의해 개선 될 수 있다. 이러한 통신은 TSP 제공자가 산업 워크로드 및 현지화된 5G 네트워킹 둘 모두에 대해 보다 완벽한 솔루션을 제공할 수 있게 할 수 있다. 헬스케어는 기술이 발전하고 보안 기술이 더 성숙해짐에 따라, 병원 및 다른 의료 기관이 에지 클라우드를 사용 하여 헬스케어 관련 데이터를 안전하게 저장하고 처리하는 또 다른 영역이다. 이러한 설정에서, 에지 클라우드 는 자원 공유를 용이하게 하고 CAPEX 및 OPEX/TCO 비용을 줄이는 데 도움이 될 것이다. 에지 클라우드를 통해 실시 가능해질 수 있는 다른 유스 케이스 영역은 V2V, V2X 및 다른 유형의 고급 운전자 지원 시스템(advanced driver assistance system)(ADAS) 워크로드를 포함한다. 자동차 기술이 더욱 성숙해짐 에 따라, 에지 클라우드는 디바이스 사이의 통신뿐만 아니라 에지 내부의 사용자가 에지 서비스(V2X)에 액세스 하기 위한 수단도 가능하게 할 것이다. 다음 섹션에서는 에지 클라우드와 관련된 많은 상이한 예시적인 워크로드 유스 케이스와 함께 제 3 자 서비스 제공자에 대한 요구 사항, 예시적인 애플리케이션 및 가치 제안을 설명한다. 이러한 섹션은 다음과 같은 영역: 데이터 캐싱, 비디오/비디오 분석, NFV, RAN, 증강 현실/가상 현실(AR/VR), 차량 운전 및 지원, 사물 인터넷 (IoT), 산업용 애플리케이션, 게임, 가속 브라우징 및 음성 분석으로 광범위하게 분류된다. 그러나 일부 에지 클라우드 유스 케이스 또는 아키텍처는 다수의 카테고리 또는 다른 카테고리와 관련이 있을 수 있다. 유스 케이스 - 데이터 캐싱(Data Caching) 데이터 캐싱은 사용자 장비에서 더 빠른 로드를 위해 에지에서 데이터를 캐싱하는 것을 말한다. 데이터 캐싱의 예는 인기있는 비디오를 더 빠른 액세스를 위해 지역에서 캐싱하는 것을 포함한다. 데이터 캐싱은 스토리지 및 컴퓨트 자원을 사용하며, 전형적으로 지연시간에 구속받지 않는다. 데이터 캐싱은 콘텐츠 전송 네트워크(CDN) 에서 사용된다. 전 세계의 모바일 데이터 트래픽이 꾸준히 증가하여, 비디오 데이터는 지금 모바일 네트워크 데이터 트래픽의 대부분을 차지하고 있다. 비디오 콘텐츠의 배포로 인해, 중복 콘텐츠가 페치(fetch)되어 동일 한 지역의 사용자에게 전달될 가능성이 높다. 이러한 시나리오에 기초하여, 에지 클라우드는 네트워크의 에지에서 콘텐츠를 캐시하기에 적합한 인프라스트럭 처가 되고, 이것은 백홀 트래픽을 크게 줄일 수 있다. 이것은 제 3 자 서비스 제공자(및 심지어 CSP 및 TSP)의 OPEX/TCO 비용을 절감하는 잠재력이 있다. 콘텐츠 캐싱은 비디오를 넘어 음악 및 문서와 같은 다른 영역으로 확장될 수 있다. 에지 클라우드 내에서, 다수의 방법이 콘텐츠 캐싱을 수행하는 데 사용될 수 있다: (a) 트래픽 학습에 기초한 콘텐츠 캐싱(content caching). 인기도 및 증가하는 요청/트래픽에 기초하여 특정 지역의 콘텐츠를 캐시한다. 이와 함께, 특정 인기 콘텐츠와 유사한 콘텐츠가 사전 예방적 전략으로 캐시될 수 있다. (b) 타겟팅된 콘텐츠 캐싱(targeted content caching). 타겟팅된 캐싱은 타겟 청중을 위해 에지에서 콘텐츠를 캐싱하는 것을 의미한다. 예를 들어, 경기장이나 모임의 청중을 위해. (c) 사용자 안내 캐싱(user guided caching). 사용자는 (서비스 요금 또는 사용자의 데이터 요금의 일부에 대 해) 캐시될 콘텐츠를 표시한다. 간단한 예는 사용자가 비디오 사이트에서 \"나중에 보기\"로서 추가하는 또는 스 트리밍 비디오 서비스의 즐겨 찾기 목록에 넣는 비디오가 캐싱 후보가 될 수 있다. 동일한 지역에 유사한 콘텐 츠 관심사를 가진 여러 사용자가 있을 수 있으므로, 이러한 콘텐츠를 캐싱하는 것은 백홀 트래픽 비용(금전 및 자원 비용)을 절약하는 상황을 조성한다. (d) 서비스 경험 캐싱(service experience caching). 이 특징은 사용자와 제공자 간의 거래 및 경험 계약 협 약에 기초한다. 예를 들어, 사용자가 4K 비디오 및 9.1 사운드 데이터를 얻고 싶어 하지만 원격 및 로컬 서비 스가 처리량, 지연시간 및 트랜스코딩 요구 사항을 처리할 수 없다면; 시스템은 콘텐츠를 예상된 QoS로 프리페 치(prefetch)되지만 가능한 지연 또는 대비책(예를 들어, 재생의 시작시 지연)을 협상해야 한다. 유스 케이스로서의 콘텐츠 캐싱에는 캐싱을 수행하기 위해 함께 실행할 수 있는 서로 다른 워크로드가 있다. 이러한 유스 케이스 중 일부는 콘텐츠 캐싱 알고리즘, 데이터 집계 절차, 머신 학습 코드, 콘텐츠 트래픽 분석,웹 서버 실행 등을 포함할 수 있다. 이러한 유스 케이스는 지연시간에 구속받지 않는다. 캐싱은 정상 시간보다 빠르게 요청을 서비스해주는 기회를 증가시키므로, 최종 사용자 경험은 긍정적일 것으로 예상된다. 이러한 유스 케이스는 캐싱을 가능하게 하기 위해 함께 작동하는 다양한 워크로드 세트를 사용할 수 있다. 그 러므로 자원 사용량 또한 가변할 수 있다. 콘텐츠 캐싱 알고리즘은 전통적으로 CPU에 최적화된다. 그러나 분 석에 도움을 주는 임의의 머신 학습 코드 또는 추론 코드는 FPGA를 사용할 수 있다. 가장 많이 사용되는 자원 은 스토리지 자원이며 풀링된 스토리지의 본래 사용자이다. 콘텐츠 캐싱의 이행은 많은 구성(이를테면 하나의 마스터 프로세스 및 여러 작업자 프로세스)을 통해 제공될 수 있다. 예를 들어, 작업자 프로세스는 요청을 실제로 처리하므로, 마스터 프로세스는 구성을 판독 및 평가하고, 작업자 프로세스를 유지하는 데 사용될 수 있다. 이것은 요청을 작업자 프로세스 사이에 효율적으로 분산하기 위해 비동기적 및 이벤트 기반 모델과 OS 종속 메커니즘을 사용하는 콘텐츠 서비스 제공자에 의해 구현될 수 있 다. 작업자 프로세스의 수는 구성 파일에서 정의되고 주어진 구성에 대해 고정되거나 또는 가용 CPU 코어의 수 에 맞게 자동으로 조정될 수 있다. 이것은 각각의 연결마다 별도의 프로세스를 적시하는 대신, 콘텐츠 서비스 제공자가 도시된 바와 같이 하나의 작업자 프로세스로부터 다수의 요청을 취급할 수 있다는 것을 의미한다. 콘텐츠 서비스 제공자는 다수의 프로토콜을 (예를 들어, HDS(Adobe의 HTTP 동적 스트리밍(HTTP dynamic streaming)), HLS(Apple의 HTTP 라이브 스트리밍(HTTP live streaming)) 및 MPEG-Dash(오픈 소스이고 YouTube 및 Netflix에서 사용됨)와 같은 HTTP를 통해)를 지원할 수 있다. 일반적으로, 이러한 프로토콜은 비디오 스트 림을 여러 청크로 잘라 메타 데이터 및 플레이리스트를 생성함으로써 작동한다. 클라이언트는 먼저 어떤 청크 가 전체 비디오를 구성하는지를 알기 위해 플레이리스트와 함께 메타 데이터를 다운로드한 다음 각각의 HTTP 요 청을 수행하여 각각의 청크를 얻는다. 주문형 비디오(VOD)와 라이브 스트리밍 간의 차이점은 청크와 플레이리 스트가 사전에 VOD 용으로 생성되는 반면에 라이브 스트리밍의 경우 (스트림으로부터 판독된 다음에) 새로운 청 크가 생성될 때 플레이리스트가 생성된다는 것이다. vCDN의 처리량은 CDN이 매끄러운 비디오 시청 경험을 위해 (예를 들어, 비디오가 플레이되는 중에 사용자가 콘 텐츠를 로드하는 동안 일시 중지를 보지 않도록) 주어진 하드웨어 및 네트워크 구성에서 지원할 수 있는 병렬 스트림의 수의 측면에서 표현될 수 있다. 다른 예에서, 소비 디바이스 또는 구독자 위치의 유형에 관계없이, 에지 클라우드 CDN은 케이블, 통신사 및 모 바일 네트워크 서비스 제공자가 사설 CDN을 구축하여 자신 또는 파트너의 관리된 콘텐츠를 브로드캐스트 TV와 같은 경험을 가진 구독자에게 분산할 수 있다. 에지 클라우드 CDN은 주문형 비디오(VoD), 라이브 이벤트 및 클 라우드 디지털 비디오 레코더(cloud digital video recorder)(CDVR)를 비롯한 TV 서비스의 스트리밍 전송을 지 원하도록 최적화되어 있다. 이것은 CDN의 다음과 같은 두 가지 주요 양태를 설정하는 콘텐츠 서비스 제공자에 의해 제공될 수 있다: (a) (예를 들면, 에지 위치에서 상용 하드웨어를 사용하여) CSP 소프트웨어 전달 노드를 배치; 및 (b) 노드를 CSP에 연결. 이것은 구성, 운영 및 성능을 관리하는 서비스 제공자의 클라우드 기반 대시 보드에 안전하게 액세스할 수 있도록 구성된 에지 클라우드를 사용할 때 발생할 수 있다. 예에서, 개별 CSP 에지 노드는 다음과 같은 세 개의 콘텐츠 전송 모드: (a) 오픈 캐싱(Open Caching): 위임을 통해 및 사양(예를 들어, Streaming Video Alliance에 의해 승인된 사양)을 사용하여 제 3 자 및 파트너 콘텐츠 인 HTTP 및 HTTPS 둘 모두를 전송; 투명한 캐싱(Transparent Caching): (예를 들어, 투명한 캐싱은 자율적으로 작동하여 네트워크 에지에서 인기있는 콘텐츠를 검출하고, 분류하고, 캐시하고 전송하고, 네트워크에 걸쳐 스트 리밍 콘텐츠를 최적화하는 것이므로) 투명한 캐싱을 통해 파트너, 오버-더-톱 및 서비스 제공자 소유의 HTTP 콘 텐츠를 전송; (c) 오픈 에지(Open Edge) CDN: 서비스 제공자 네트워크에 배치되고 클라우드 기반 동작에 의해 관리되는 에지 노드를 통해, 서비스 제공자 소유의 콘텐츠인 HTTP 및 HTTPS 둘 모두를 전송의 세 개의 콘텐츠 전송을 지원할 수 있다. 유스 케이스 - 비디오/비디오 분석(Video/Video Analytics) 비디오 분석은 사용자 디바이스에 제시하기 위해 에지에서 라이브 비디오 분석 및 비디오 전처리 또는 트랜스코 딩을 수행하는 것을 말한다. 트래픽 비디오 분석 및 경보 시스템은 에지에서 비디오 분석의 예이다. 스토리지 및 컴퓨트 자원은 이러한 유형의 사용에 달려 있다. 비디오 분석은 많은 분야에서 중요한 역할을 한다. 예를 들어, 교통 및 보안 카메라의 얼굴 인식은 이미 법과 질서에서 중요한 역할을 하고 있다. 물체 추적, 움직임 검출, 이벤트 검출, 불꽃 및 연기 검출, 라이브 스트림의 패턴 또는 비디오 아카이브의 AI 학습 등과 같은 비디오 콘텐츠에 대해 여러 다른 유형의 분석이 수행될 수 있다. 현재, 비디오 분석은 클라우드에서 수행되거나 또는 설정되어야 할 필요성과 기능에 따라 전용의 사적 서버에서 수행된다. 에지에서 비디오 분석을 수행하는 것은 여러 분야에서 기회이자 요구 사항이기도 하다. 예를 들면: 감시 및 공공 안전: 예를 들어, 에지에서 거의 즉각적으로 라이브 비디오 스트림을 처리하면 더 나은 감시 및 법과 질서의 시행으로 이어질 수 있다. 얼굴 검출 및 사고 식별과 트리거링은 에지에서 이루어질 수 있는 기능 중 일부이다. 이러한 기능을 통해 법 집행관은 사건과 관련하여 즉각적인 조치를 취할 수 있다. 커넥팅 카 및 자율 주행의 지원: 예를 들어, 자율 주행 자동차에서 볼 수 있는 장면의 실시간 스트림은 매우 짧 은 시간 내에 분석되어 자동차가 취할 조치를 결정할 수 있다. 자율 주행에는 장면을 즉시 처리할 수 있는 자 원이 이미 포함되어 있을 수 있다. 에지 비디오 분석은 더 멀리 있는 장면을 처리(또는 전처리)하기 위해 또는 지속적인 훈련 및 피드백을 위해 비디오 장면을 후 처리하는 데 제공될 수 있다. 스마트 시티 및 IoT의 실시 가능화: 에지에서 비디오 분석은 스마트 시티를 실시 가능하게 하는 데 중요한 요소 이다. 예를 들어, 트래픽 비디오 분석은 가장 효율적인 방법으로 트래픽을 라우팅하는 데 사용될 수 있다. 한 영역의 화재 또는 연기 검출은 즉시 식별될 수 있으며 특정 영역에서 커넥티드 차량은 물론 도시 인프라스트럭 처 둘 모두에 피드백을 보냄으로써 트래픽이 위험 지역을 향해 계속되지 않도록 보장한다. 향상된 인포테인먼트 서비스: 에지에서 비디오 분석은 스포츠, 콘서트 및 다른 쇼와 같은 이벤트 청중의 실제 경험을 향상시키는데 사용될 수 있다. 이벤트에서 카메라 각도가 상이한 비디오가 분석되어 AR/VR 기능으로 적 용할 수 있으며, 대형 스크린, 스마트 폰, VR 디바이스 등을 통해 라이브 청중에게 제시될 수 있다. 에지에서 비디오 분석을 위한 지연시간 및 반환 시간(turnaround time) 요구 사항은 상이한 시나리오마다 다르 다. 이것은 아래의 표 1에 설명된다. 표 1 지연시간 (컴퓨테이션 포함)참고 0 - 15 ms(디바이스에서 디바이스로) 자율 주행 차량의 비디오 처리와 같은 시간 임계 적 상황에 적합 15 - 50 ms(디바이스에서 다른 디바이스/경보로)트래픽 라우팅 작업, 연기/화재 검출 및 주변 디 바이스로 피드백 50 - 500 ms(디바이스에서 다른 디바이스로)이상적인 사고 식별 및 관련 당국에 보고 50 ms - 1 or 2 초 (디바이스에서 디바이스로)향상된 인포테인먼트 서비스 지연시간 구속받지 않음 아카이브 또는 클라우드에 저장하기 전에 비디오 전처리 TSP는 에지에서 제공되는 비디오 분석 서비스를 수익화하는 여러 방법을 가지고 있다.a. 개선된 감시 및 모니터 링은 민간 보안 회사뿐만 아니라 정부 기관에도 서비스로서 제공될 수 있다. b. 스마트 시티(및 그 특정 기능)에 대한 비디오 분석은 필요에 따라 정부 기관, IoT 디바이스 제공자 및 가정 모두에 서비스로 제공될 수 있다. c. 향상된 인포테인먼트를 위한 비디오 분석은 서비스로서 이벤트 청중 또는 (차례로 청중에게 제공하는) 주최 자에게 제공될 수 있다. 유스 케이스 - 네트워크 기능 가상화(NFV) 및 무선 액세스 네트워크 (RAN) 동작 유연한 NFV는 스토리지 및 컴퓨트 자원(예를 들어, CPU 또는 FPGA)에 크게 의존한다. 에지 클라우드 배치는 동 일한 플랫폼/동일한 위치에서 네트워크(NFV) 및 서비스 기능을 공동 호스팅함으로써 사용자 경험을 제어할 수 있다. 요청된 서비스를 실제로 제공하는 서비스와 가까운 곳에 로컬 브레이크아웃(local breakout)을 배치하는 역량은 인프라스트럭처 또는 데이터 센터를 통해 불필요한 트래픽을 줄임으로써 더 나은 응답 시간을 제공하고 OPEX/TCO를 줄일 수 있다. ETSI 사양 배치에 따라, 동일한 네트워크 배치에서 MEC 및 네트워크 기능 가상화(NFV)의 통합과 관련하여, MEC 및 NFV는 독립적으로 존재할 수 있는 보완적인 개념이다. MEC 아키텍처는 MEC 시스템의 다수의 상이한 배치 옵션이 가능한 방식으로 설계되었다. NFV와 관련하여, MEC 시스템은 동일한 네트워크에 있는 NFV 환경의 존재와 독립적으로 실현되거나 그와 공존할 수 있다. MEC와 NFV는 둘 모두 가상화 기술을 이용할 수 있으므로, MEC 애 플리케이션 및 NFV 가상화된 네트워크 기능은 동일한 가상화 인프라스트럭처 전체에서 부분적으로 또는 전체적 으로 인스턴스화될 수 있다. NFV 환경에서 MEC 참조 아키텍처는 NFV 프레임워크의 가상화된 인프라스트럭처 관리자(Virtualized Infrastructure Manager)와 유사한 약간의 향상이 있는 가상화 인프라스트럭처 관리자의 개념뿐만 아니라, NFV 사양에서 설명된 바와 같이 NFV 인프라스트럭처 포인트-오브-프레즌스(Point-of-Presence)(NFVI-PoP)에 대략적 으로 대응하는 가상화 인프라스트럭처의 개념을 재사용한다. 참조 아키텍처는 MEC와 NFV 사이의 추가 시너지가 달성될 수 있는 방식으로 설계되었다. 배치를 위한 다수의 시나리오가, 네트워크 및 마이그레이션 전략에 대한 사업자의 선호도에 따라 가능한데, 예 를 들면, 다중 테넌시 등과 같은 이차 양태를 고려하여, 두 기술 간의 통합 레벨이 서로 상이한 MEC가 먼저 배 치되거나 또는 NFV가 먼저 배치되는 완전 가상화된 환경 또는 혼합된 환경에 따라 가능하다. MEC 및 NFV 관리 및 오케스트레이션 컴포넌트가 서로 관련되는 방식(예를 들어, 통합, 상호연동, 공존)은 통합된 MEC-NFV 배치의 중요한 양태이다. RAN 유스 케이스는 (예를 들어, 에지에서) 탈중앙집중화된 RAN 및 UPF의 사용을 또한 포함한 다. 잘 이해하는 바와 같이, RAN은 스토리지 및 컴퓨트 자원(예를 들어, CPU 또는 FPGA)에 크게 의존한다. RAN 구성에 관한 자세한 논의는 아래의 5G 연결성의 예에서 제공된다. 유스 케이스 - 증강 현실/가상 현실(AR/VR) 증강 현실(AR) 유스 케이스에는 대부분 이미지 인식(얼굴, 물체 등) 및 이들에 대한 분석이 연루된다. AR(및 VR)의 사용은, 에지에 의해 지원되는 바와 같이, 서로 상호작용하는 엔드포인트를 비롯한 사용자 제어 엔드포인 트(user-controlled endpoint)에 집중될 것으로 예상된다. 단일 엔드포인트 디바이스, 디바이스의 그룹 또는 디바이스 대 디바이스 접근 방식이 연루되든지에 관계없이, 이와 같이 구상된 사용에는 종종 서비스 요구 사항 을 이행할 짧은 지연시간이 필요하다. AR과 연루된 클라이언트 디바이스는 전형적으로 카메라가 있는 웨어러블 또는 모바일 폰의 형태이다. 전형적인 사용 시나리오는 사용자가 카메라 디바이스를 물체에 향하게 하고 물체에 대한 유용한 주석을 보는 경우이다. ViewAR, Vivino, Augment 등과 같은 AR 서비스를 제공하는 스마트폰 앱이 이미 여러 개 있으며, 이러한 앱 또는 관련된 웨어러블은 AR을 특정 목적에 제공하도록 설계되었다. 예를 들어, Vivino는 와인 병의 라벨 사진이 캡 처되어 제공될 때 와인에 대한 유용한 정보를 제공한다. 유사하게, ViewAR은 3D 시각화를 통해 공간을 패키징 하고 계획하는 것을 도와준다. AR 시나리오는 전형적으로, (i) 디바이스로부터 캡처된 이미지를 전송하는 것, (ii) 이미지 인식 및 객체 식별, (iii) 분석을 수행하고 (인터넷, 객체 식별 등으로부터 발견된 유용한 정보에 관한 주석 형태의) 결과를 생성하 는 것의 세 단계로 이루어진다. 위의 단계에서, (ii) 및 (iii)은 일반적으로 가장 많은 시간을 소비하는 부분 이다. 특정 기능성에 전념되는 AR 서비스는 이미지 인식 서비스에 특정 타겟을 명시할 것이다. 이미지 인식 서비스는 이미지를 식별하고 이러한 타겟을 찾을 것이다. 그런 다음 AR 서비스는 결과를 사용하여 분석 또는 인터넷으로부터 더 많은 정보의 찾기와 같은 추가 동작을 수행할 것이다. 그런 다음 이러한 결과가 사용자에게 디스플레이된다. AR 서비스는 이미지 인식을 위해 다른 서비스를 사용하는 것이 일반적이다. 예를 들어, 위에서 언급한 많은 앱 은 Vuforia를 이미지 인식을 위한 주 엔진으로 사용한다. AR 서비스는 이미지 인식이 명시된 타겟을 찾을 수 있도록 API를 통해 Vuforia 엔진에게 타겟을 이미 명시하였을 것이다. 이미지 인식은 디바이스와 클라우드 둘 모두에서 수행될 수 있다. 온-디바이스 데이터베이스(on-device database)를 구비한 디바이스에서 이것을 수행 하는 것은 전력 효율적이지 않지만, 동일한 것을 클라우드는 더 오랜 시간이 걸려 수행한다. 다른 예는 Catchoom 클라우드 이미지 인식 서비스이다. 이 서비스는 AR 앱이 RESTful API를 통해 클라우드의 서비스에 요 청을 보내고 이미지 인식으로 응답할 수 있게 한다. AR 앱은 이미지가 인식된 후에 클라이언트 디바이스로부터 의 제 3 동작 - 이것은 인터넷에서 원하는 정보를 찾아 이를 사용자에게 제시하는 것임 - 을 수행할 수 있다. Vuforia 및 Catchoom과 같은 이미지 인식 서비스에는 이러한 서비스를 사용하는 여러 AR 앱이 있다. 이 서비스 는 단지 이러한 AR 앱이 더 많이 만들어지고 이러한 AR 앱의 사용자가 증가함에 따라 향후에 증가할 것으로 예 상될 수 있다. 이러한 서비스는 현재 클라우드에서 호스팅되기 때문에, 이미지 인식의 지연시간 및 반환 시간 이 상당히 높다. 예를 들어 Vivino를 통해 와인에 대한 정보를 찾는 데 몇 초가 걸린다. 이것은 웨어러블이연루되고 시간 임계적인 주석이 요구되며 실시간 움직임이 고려되어야 하는 시나리오에는 용납되지 않을 것이다. 그러므로 이미지 인식 서비스를 클라우드로부터 에지로 이동하면 반환 시간을 개선하여 사용자에게 원 활한 경험을 제공할 수 있다. 위에서 언급한 바와 같이, 현재의 솔루션은 사용자에게 제 1 주석 또는 제 1 출력을 생성하기 시작하는 데 몇 초를 필요로 한다. 이러한 지연은 \"응답 시간(response time)\"이라고 한다. 이것은 주로 클라우드에서 호스팅 되는 서비스 때문이다. 매끄러운 사용자 경험 및 미래의 시간 임계적인 AR 유스 케이스를 지원하기 위해, 반환"}
{"patent_id": "10-2020-7037506", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "시간 요구 사항은 매우 낮다. 아래의 표 2는 다양한 출처에 따라 이러한 요구 사항을 요약한 것이다. 표 2 반환 시간 (컴퓨테이션을 통한 왕복 시간(round trip time))참고 < 20 ms 웨어러블을 통한 매우 끊김없는 경험을 위함. 사용자가 디바이스를 이동할 때 객체 식별 및 적 어도 하나의 주석이 제시된다. 25-50 ms 인간에 민감하면서도 끊김없는 경험 50-100 ms 사용자는 갭을 약간 관찰할 수 있다. 그러나 이 것은 견딜 수 있으며 \"매끄러운\" 경험으로 간주 될 수 있다. 100-500ms 사용자는 물체를 가리키고 디바이스를 들고 있어 야 한다. 사용자는 디바이스를 빠르게 이동할 수 없다. 이미지 인식, 물체 추적 및 식별은 전체 AR 서비스에서 가장 컴퓨트 집약적인 부분이다. 가장 잘 알려진 이미 지 인식 알고리즘은 SURF, SIFT, FAST 및 BRIEF이다. Vuforia 및 Catchoom과 같은 서비스는 사용된 핵심 이미 지 인식 알고리즘과 그의 자원 요구 사항을 공개하지 않는다. 그러나 FPGA뿐만 아니라 CPU를 사용하는 임의의 이미지 인식 알고리즘이 구현될 수 있다. 이러한 서비스가 당면하는 요청량은 사용될 수 있는 CPU 또는 FPGA의 크기를 결정할 수 있다. 예를 들어, Vuforia에는 300개를 초과하는 앱이 등록되어 있고 Catchoom에서는 지금까 지 7 억 5 천만 개의 상호작용이 이루어졌으며, 이것은 2025 년까지 100 억 개가 될 것으로 예상된다. 그러므 로 요청량이 증가함에 따라, 시스템은 들어오는 요청을 충족시키는데 있어서 더 높은 병렬 처리를 요구하고 따 라서 더 많은 자원을 필요로 한다. 이러한 서비스는 또한 물체 매칭을 위해 이미지 저장소(repository)를 저장 하기 위한 스토리지를 사용하기도 한다. 이것은 또한 이미지 인식 및 물체 식별이 인터넷 연결성 없이 에지로 부터 직접 이루어지게 할 수 있는 에지에서 제공될 수 있다. 고급 시나리오로서, AR 서비스 앱은 또한 에지의 스토리지를 인터넷으로부터 캐시된 데이터를 저장하는 데 사용하여 이미지가 인식되자 마자 사용자에게 더 빠른 응답을 제공할 수 있다. 캐시된 데이터는 또한 인-메모리, NVRAM의 영구 메모리 또는 풀링된 SSD 스토리지와 같은 상이한 계층에 배치될 수 있다.제 3 자 서비스 제공자(third-party service provider)(TSP)는 에지에서 AR 서비스를 수익화할 수 있다. 에지는 AR 앱에 의해 사용될 수 있는 중앙 이미지 인식 및 물체 식별 서비스를 호스팅할 수 있다. AR 앱은 API를 통해 타겟을 명시하며 이 서비스는 입력 요청이 전송될 때 원하는 대로 물체 로 응답할 수 있다. 앱은 에지에서 자신의 서비스에 대한 비용을 지불할 것이다. 에지는 사용된 자원에 대해 비용을 지불하는 Vuforia 또는 Catchoom과 같은 이미지 인식 서비스를 호스팅할 수 있으며 이들의 서비스를 사용하는 앱과 별도의 비즈니스 모델을 가질 수 있다. 예를 들어 Catchoom SaaS는 에 지로부터 제공될 수 있다. 유스 케이스 - 차량 지원(Vehicle Assistance) 및 자율 주행(Autonomous Driving) 동작 에지 컴퓨트 노드는 자율 주행 차량 동작을 지원하는 데 사용될 수 있다. 유스 케이스의 예는, 이것으로 제한 되는 것은 아니지만 네비게이션, 차량 대 차량(vehicle-to-vehicle)(V2V) 통신, 차량 대 인프라스트럭처 (vehicle-to-infrastructure)(V2I) 통신 또는 차량 대 사물(vehicle-to-everything)(V2X) 통신을 포함한다. 지연시간은 자율 동작을 위한 거의 실시간 응답 시간을 보장하는 차량 지원 유스 케이스의 하나의 인자이다. ETSI MEC는 다중 공급 업체, 다중 네트워크 및 다중 액세스 환경에서 V2X 상호 운용성을 용이하게 하기 위해 V2X MEC 서비스를 개발하고 있다. 이것은 V2X 관련 정보 흐름, 필요한 정보 및 동작을 설명한다. MEC 사양은 필요한 API를 데이터 모델 및 데이터 포맷으로 정의하고 있다. ETSI MEC는 C-V2X 에지 클라우드 배치를 위한 표준화된 솔루션이며, 따라서 이것을 고려하여, MEC030 WI는 이후 \"V2X 정보 서비스(V2X InformationService)\"(VIS)라고 하는 새로운 MEC 서비스를 도입한다. 자동차 유스 케이스에는 다수의 이해 관계자: 상이한 자동차 제조사, OEM(Original Equipment Manufacturer) 공급자, 네트워크 인프라스트럭처 공급 업체, MEC 공급 업체, 애플리케이션/콘텐츠 제공자 및 다른 이해 관계자 가 연루된다. 더 자세히 설명하면, ETSI MEC의 요구 사항에 따라, 다중 액세스, 다중 네트워크 및 다중 사업자 시나리오는 V2X 서비스에 적용 가능한 시나리오를 비롯한, 이 영역에 대한 MEC 규범적 작업의 필요성을 동기부여하는 참조 가정이다. 예를 들어, 일부 V2X 서비스는 OEM(소위 \"차량 OEM 시나리오\")에 의해 관리될 수 있고, 이에 따라 이러한 서비스에 대해 단일 및 다중 사업자 시나리오를 둘 모두 고려하는 것이 합리적이다. V2X 서비스는 동일 한 국가 및/또는 상이한 국가의 상이한 네트워크 사업자에 의해 제공될 것으로 예상된다는 것을 주목해야 한다. 유사하게, 우리가 추가적으로 다른 차량 OEM에 서비스를 제공할 수 있는 \"ITS 사업자 시나리오\"를 고려할 때도 마찬가지이다. 지능형 교통 시스템(Intelligent Transportation System)(ITS) 사업자는 상이한 사업자 네트워 크를 활용하고(상이한 MEC 시스템을 배치하고) 이 서비스를 상이한 OEM에 속한 차량에 제공함으로써 전국적인 V2X 서비스를 제공할 필요가 있을 수 있다. 이 경우에도 V2X 서비스는 동일한 국가 및/또는 상이한 국가의 상 이한 네트워크 사업자에 의해 제공될 것으로 예상된다는 것을 주목해야 한다. 결과적으로, 모든 유스 케이스를 가능하게 하기 위해, 에지 클라우드에서 운영하는 VIS 서비스는 일반적인 시나 리오에서 구현된 C-V2X 시스템을 지원할 수 있다. 특히, 이러한 시나리오는 다수의 MEC 공급 업체의 존재와 이 러한 공급 업체 간의 상호 운용 가능한 데이터를 교환할 수 있게 할 필요성을 가정한다. 더욱이, 다중 사업자 상호 운용성은 V2X의 서비스 연속성을 보장하기 위한 고려 사항이다. 보다 구체적으로, 전형적인 다중 사업자 시나리오에서, (예를 들어, 로밍 상황에서) 무선 커버리지의 일시적인 부재와 관련된 많 은 시나리오가 있을 수 있다. 또한, 전통적인 V2X 시스템에서, 모바일 네트워크 사업자(Mobile Network Operator)(MNO) 간의 상호 연결은 원격 측에서 종료되어, 엔드-투-엔드(End-to-End)(E2E) 지연시간 측면에서 명 백한 단점이 있으며; 반면에, (MEC 시스템 간의 \"수평적 통신(horizontal communication)\"도 가능하게 하는) VIS 서비스의 활용 덕분에, MNO 간의 상호 연결은 낮은 E2E 지연시간으로 실현될 수 있다. V2X 서비스 연속성은 양쪽 사업자의 커버리 영역을 포함한 모든 영토에 걸쳐 보장되어야 할뿐만 아니라, 임의의 서비스 중단 없이 한 사업자의 커버리지 영역을 떠나 다른 사업자의 커버리지 영역으로 들어갈 때 그리고 E2E 성능을 보증할 때에도 보장되어야 한다. 그 목적을 위해, VIS는 특히 UE가 커버리지를 벗어났을 때, PC5 구성 파라미터에 대한 정보를 노출하고 다중 사업자 환경을 관리한다. MEC 배치는 \"에지\"의 정의에 따라 다르다. 특히 NFV 환경에서 MEC를 배치할 때 MNO에 필요한 자유도를 제공하 기 위해, MEC 표준에 의해 몇 개의 옵션이 허용된다(사실상 이 경우, MEC 엔티티는 가상화된 네트워크 기능 (VNF)으로 인스턴스화될 것이고, 이에 따라 사업자의 배치 측면에서 유연성이 높을 것이다). 따라서, 원칙적으 로, 에지 클라우드가 모든 곳에 노출되므로, MEC는 유스 케이스/버티컬 세그먼트(vertical segment)/처리될 정 보에 따라 유연하게 배치될 수 있다. 더욱이, MEC 시스템의 일부 컴포넌트는 시스템의 일부 요소와 함께 배치 된다면 더 잘 배치된다. 예로서, 특정 유스 케이스(예를 들어, 엔터프라이즈)에서, MEC 앱은 MEC 서비스를 로 컬로 소비해야 할 수 있으며, 그래서 필요한 API 세트를 갖춘 MEC 호스트를 로컬로 배치하는 것이 가치가 있을 수 있다. 다른 경우, MEC 서버를 (액세스 네트워크에서 멀리 떨어진) 데이터 센터에 배치하는 것은 (무선 기지 국으로부터의 무선 네트워크 정보를 수집하는) RNI API와 같은 일부 API를 호스팅할 필요가 없을 수 있다. 반 면에, RNI 정보는 정교하게 다듬어지고 집계 지점의 클라우드 RAN(Cloud RAN)(CRAN) 환경에서 이용할 수 있으므 로, 적합한 무선 인식 트래픽 관리 절차를 실행할 수 있게 할 수 있다. 일부 다른 경우에, 대역폭 관리 API는, 예를 들어 콘텐츠 전송 네트워크(CDN) 기반 서비스를 위한 전송 네트워크를 적절하게 설정하기 위해, 액세스 네 트워크 레벨에서 그리고 또한 더 먼 위치에서 존재하는 것이 타당할 수 있다. 유스 케이스 - 사물 인터넷(Internet of Things)(IoT) 사물 인터넷(IoT) 디바이스는 공장 자율화, 프로세스 자율화, 스마트 그리드, 스마트 소매, 소비자 디바이스, 자동차, 홈 자동화, 사무실 및 상업용, 보안, 군사 및 다른 애플리케이션과 같은 많은 분야에 있다. IoT는 통 신 응답 시간, 컴퓨트 자원 및 스토리지 자원에 크게 의존한다. 지연시간 요구 사항은 애플리케이션에 따라 다 르다. 예를 들어, 공장 자동화 설정에서는 0.25 ms 내지 10 ms의 왕복 지연시간이 필요할 수 있으며, 스마트 그리드 구현에서는 3-20 ms의 왕복 지연시간이 사용될 수 있으며, 프로세스 자동화 설정에서는 50-100 ms가 사 용될 수 있다. IoT 네트워크에서 사용되는 네트워크 토폴로지는 본 명세서에서 설명된 임의의 기술을 포함할수 있으며, 그 밖에도 블루투스 저에너지(BLE) 링크를 사용하여 제공되는 메시 네트워크; IEEE 802.11(Wi-Fi® 링크를 통해 IoT 디바이스와 통신하는 데 사용되는 무선 근거리 네트워크(WLAN) 네트워크; LTE/LTE-A(4G) 또는 5G 셀룰러 네트워크를 통해 IoT 디바이스와 통신하는 데 사용되는 셀룰러 네트워크; 또는 저전력 광역(low- power wide area)(LPWA) 네트워크, 예를 들어 LoRa 연합에서 발표한 LoRaWan 사양과 호환되는 LPWA 네트워크 또는 인터넷 엔지니어링 태스크 포스(Internet Engineering Task Force)(IEFT)에서 발표한 사양과 호환되는 IPv6 오버 저전력 광역 네트워크(IPv6 over Low Power Wide-Area Network)(LPWAN) 네트워크를 포함할 수 있다. 또한, 각각의 IoT 네트워크는 LTE 셀룰러 링크, LPWA 링크 또는 지그비®와 같은 IEEE 802.15.4 표준에 기반한 링크와 같은 임의의 수의 통신 링크를 사용하여 외부 네트워크 제공자(예를 들어, 계층 2 또는 계층 3 제공자와 통신할 수 있다. 각각의 IoT 네트워크는 또한 다양한 네트워크 및 제한적인 애플리케이션 프로토콜 (Constrained Application Protocol)(CoAP)과 같은 인터넷 애플리케이션 프로토콜을 사용하여 작동할 수도 있 다. 각각의 IoT 네트워크는 링크된 디바이스 및 네트워크의 클러스터 트리를 형성하는 링크의 체인을 제공하는 코디네이터 디바이스와 통합될 수도 있다. 사물 인터넷(IoT)은 데이터의 중요한 생산자이자 소비자가 될 것으로 예상된다. IoT 네트워크 노드는 노드 구 성을 피어 노드에 증명하는 (예를 들어, DICE 아키텍처 사용하는) 하드웨어 RoT를 포함할 수 있고, 피어 노드는 마찬가지로 집계 서브네트워크 및 토폴로지를 다음 계층의 증명 검증자에게 증명한다. 이러한 구조는 에지 서 버, FaaS, 메시 및 가상 테넌트 '슬라이스'의 네스팅 및 토폴로지 역학과 대략 매칭되고; 따라서, 최상단 레벨 에지-투-에지에서 보안을 평가하거나 또는 지역, 로컬 또는 다른 분할 체계로 세분하는 공통의 분산되고 일반화 된 증명 검증 및 분석 기능이 사용될 수 있다는 것을 이해할 수 있다. IoT 컴포넌트는 전형적으로 스마트 시티, 스마트 소매, 스마트 차량, 스마트 홈 등으로부터의 요소/디바이스를 포함한다. 어떤 의미에서, 비디오 분석 및 AR/VR과 같은 위에서 논의된 워크로드는 에지 디바이스가 이론상 IoT 디바이스인 것처럼 또한 IoT의 일부이다. 예를 들어, 얼굴 검출 워크로드는 스마트 시티 환경의 디바이스 를 위해 실행되거나, 또는 스마트 소매점의 체크 아웃을 위해 실행되거나, 또는 개인 사용자를 위한 AR의 일부 로서 실행될 수 있다. 그러므로 일반적으로 IoT 워크로드는 특정 데이터 포인트를 처리하는 측면에서 모든 AI 워크로드를 포함한다. 보다 특정한 IoT 관련 워크로드는 IoT 게이트웨이이다. IoT 디바이스는 가까운 미래에 매일 수조 기가 바이트 의 데이터를 생성할 것으로 예상된다. 이러한 모든 데이터는 다양한 목적을 위해 상이한 지연시간에서 상이하 게 처리되어야 한다. 이것은 또한 (다양한 지연시간 요구 사항을 이행하기 위해) 이러한 모든 데이터를 상이한 위치에서 처리하는 컴퓨트 캐퍼빌리티가 필요하다는 것을 의미한다. 에지 클라우드는 (a) 필터링, 포맷 변경 등과 같은 데이터 전처리(양방향); (b) 커넥티드 컴포넌트가 있는 지연시간 임계적 유스 케이스 및 시나리오를 위한 데이터 처리; 및 (c) 부분 데이터 처리 및 저장을 수행하기에 이상적인 위치이다. 데이터 구성 및 처리 역시 에지 클라우드에서의 동작이다. 기본적으로, 데이터 구성 엔티티는 데이터에 매우 빠른 액세스를 위해 설계된 간단한 키-값 스토어(key-value store)로부터 복잡한 분석 동작에 이르기까지 복잡 성이 광범위하다. 다음의 것은 에지 클라우드에서 실시 가능해질 수 있는 데이터 구성 및 처리 소프트웨어의 광범위한 분류이다: (a) NoSQL 키-값 스토어/캐시: 매우 빠른 조회 및 검색을 위해 데이터를 저장함. 데이터에 대해 아무런 처리도 수행하지 않음(예를 들어, Aerospike, Redis); (b) NoSQL 컬럼 스토어(Column store): 매 우 빠른 조회 및 검색을 위해 데이터를 저장하고, 범위 조회 등과 같은 일부 기본 동작을 수행함(예를 들어, HBase, Cassandra); (c) NoSQL 문서 스토어(Document store): 검색 및 인덱스 기반 조회와 같은 동작을 수행함 (예를 들어, MongoDB, Marklogic); (d) NoSQL 그래프 데이터베이스: 그래프 운행법(graph traversal)과 관련된 특화된 동작을 수행함. 예를 들어, Neo4j; (e) NewSQL/SQL 데이터베이스: 방대한 범위의 복잡한 데이터베이스 쿼리를 수행함; 및 (f) 분석 소프트웨어: 다양한 스토어로부터의 데이터에 대한 통계적 분석을 수행함. 전통적으로 클라우드 또는 엔터프라이즈 워크로드에 배치되던 일부 워크로드는 결국 에지 로케이션에도 배치되 게 될 수 있다. 이것은 다음과 같은 카테고리의 워크로드를 포함한다: 낮은 지연시간 또는 컨텍스트화된 데이터 분산: 이 경우, 클라우드에 배치되는 기존 워크로드 중 일부는 에지 위치에 배치되어, 데이터 액세스 측면에서 지터가 적은(통신사 인프라스트럭처로부터 아마도 에지에서 호스팅되 는 엔드 서버까지 다수의 계층을 통과할 필요가 없는) 보다 안전한 방식으로(다수의 보안 도메인을 통과할 필요 가 없이) 데이터로의 더 빠른 액세스를 제공할 수 있다. 제 1 예시적인 워크로드는 HANA 또는 Spark-SQL과 같 은 인-메모리 데이터베이스; 및 웹 서버와 같은 데이터 프론트-엔드이다. 일부 예에서 이러한 유스 케이스는 가속화된 웹 브라우징과 결합될 수 있다. 제 2 예시적인 워크로드는 에지에서 데이터 마이닝 또는 분석이다:이 경우, 기존 데이터 마이닝 워크로드는 실시간 또는 사후에 데이터 분석을 수행하기 위해 에지 위치에서 사용 될 수 있다. 유스 케이스에는 동적 또는 적응형 솔루션을 취하는 실시간 분석이 연루될 수 있다: 이것은 예를 들어 적응형 네트워크 기능 또는 동적 IoT 관리 체계에 사용될 수 있다. 에지 측면에서 이러한 유스 케이스의 주요 가치 제안은 실시간 의사 결정에서 지연시간이다. 유스 케이스에는 또한 의사 실시간 또는 사후 데이터 처리가 연루될 수 있다: 이것은 예를 들어 반드시 네트워크의 백홀에서 저장되고 처리되어야 할 필요가 없는 에 지를 향해 IoT 디바이스가 생성하는 모든 데이터를 처리하는 데 사용할 수 있다. 에지 측면에서 이러한 유스 케이스의 주요 가치 제안은 컴퓨트 분산뿐 아니라 백홀 트래픽 절감에 있다. 이러한 에지 클라우드 투영 전략(projection strategy)은 상이한 플랫폼, 제공되는 서비스 및 사용자 수에 맞추 어 에지 클라우드의 치수 기입(dimensioning)을 투영함으로써 플랫폼 정의를 지원할 수 있다. 이것은 에지에서 제공되는 상이한 서비스에 연루된 에지 클라우드 크기(노드의 수)를 투영하고; 상이한 서비스에 대해 FPGA와 같 은 가속기를 사용하거나 사용하지 않고 에지 클라우드의 치수 기입을 투영하며; 상이한 플랫폼의 전력 요구 사 항을 투영하는 효과를 가져올 것이다. 투영 모델은 이러한 목적에 이용될 수 있다. 예를 들어, 투영 모델은 각각의 서비스/유스 케이스를 나타내는 워크로드 특성을 분석함으로써 투영을 수행할 수 있다. 개별 워크로드 의 경우, 워크로드에 대한 짧은 설명, 모델링을 위해 만들어진 가정, 및 모델에 의해 사용되는 데이터 및 구성 이 투영 모델에 의해 고려될 수 있다. 평가에 사용되는 많은 AI 모델은 CNN 기반 심층 학습 추론의 개발 및 배치를 위한 툴킷인 OpenVINO 툴킷의 일부 이다. 이 툴킷은 CPU, GPU, FPGA 및 Movidius Neural Compute Stick과 같은 컴퓨터 비전 가속기 전반에 걸쳐 AI 모델의 이기종 실행을 지원하는 공통 소프트웨어 툴 및 최적화 라이브러리를 제공한다. OpenVINO 툴킷은 또 한 그 중 일부가 워크로드 평가 및 분석에 사용되는 기본 하드웨어에서 실행되도록 최적화된 사전 훈련된 AI 모 델 세트를 포함한다. 이 툴킷을 사용하면, 예를 들어, 시나리오에 따라 관련 AI 모델 또는 모델 조합을 사용함 으로써 비디오 분석이 수행될 수 있다. 유스 케이스 - 검출 IoT: 얼굴 검출 ADAS - 이것은 승객이 차량 안에 있는지를 관찰하거나 또는 실내 보행자 교통량을 계수하는 것 과 같은 다양한 목적으로 사용되는 표준 얼굴 검출 모델이다. 이것은 또한 주행 보조 경고 시스템에서 사용하 는 것이 발견된다. 예를 들어, 이것은 피로와 피곤의 징후에 대해 운전자를 지속적으로 스캔하고 필요한 경우 시각적 및 청각적 경보로 운전자에게 경고하여 도로로 주의를 되돌리는 데 사용될 수 있다. IoT: 얼굴 검출 - 이 모델은 전형적으로 알려진 가게 좀도둑의 식별, 반품 사기를 하는 사람의 식별 등과 같은 목적으로 소매 환경에서 사용된다. 뿐만 아니라, 이것은 또한 다음과 같은 소매 분석을 지원하는 모델과 결합 되거나 후속 조치를 취할 수 있다: (a) 연령 및 성별 인식(검출된 얼굴의 연령과 성별을 검출하는 데 사용되는 모델을 이용함. 얼굴 검출 모델로부터 검출된 얼굴이 이 모델에 입력으로 제공되어 사람의 연령과 성별을 추정 할 것임. 소매 도메인에서, 이것은 어느 카테고리의 사람들이 어떤 유형의 항목을 쳐다보고 구매하는지 등을 이해하는 것과 같은 분석에 사용할 수 있음. 이 모델은 또한 비디오 감시와 같은 다른 도메인에서도 사용될 수 있음); 및 (b) 머리 자세 추정(사람의 머리 위치를 검출하는 모델을 사용함). 소매 설정에서, 이것은 무엇이 사람의 관심을 끌었는지를 이해하는 데 사용될 수 있다. 이것은 또한 ADAS 또는 비디오 감시 도메인에서도 사 용할 수 있다. IoT: 사람 검출 - 사람 검출은 실내 및 실외 환경 둘 모두에서 더 높은 유리한 지점에 장착된 카메라로 사람을 검출하는 데 사용된다. 이것은 군중 수 세기(crowd counting), 비디오 감시 등과 같은 다양한 목적으로 사용될 수 있다. IoT: 사람, 차량 및 자전거 검출 - 이 모델은 사람과, 자전거 타는 사람과, 자전거 단독과, 차량 사이를 구별하 는 것과 같은 목적으로 실외 카메라의 비디오 분석에 사용된다. 이 모델에서 다양한 조명 조건은 일광, 어둠 및 날씨의 변화에서 정확도를 개선한다. 유스 케이스 - 헬스케어 산업 애플리케이션 산업용 애플리케이션은 헬스케어 분야, 제조, 소매 또는 다른 산업에 있을 수 있다. 헬스케어에서, 에지 컴퓨 팅은 연결성 및 분석을 통해 다양한 의료 어플라이언스를 구현하는 데 사용될 수 있다. 유스 케이스의 예는 의 사가 환자를 원격으로 수술할 수 있는 원격 수술이다. 이러한 유스 케이스는 높은 컴퓨트, 통신 및 스토리지 자원을 포함한다. 다른 컨텍스트에서, 비 전염성 질병(예를 들어, NCD, 암 및 당뇨병)으로 기인하는 사망과 부담이 더 많기에, 광 범위한 인구에 대해 정기적인 선별 검진 방법(screening method)을 고안하는 것이 중요하다. 많은 국가의 도시 에 비해 시골 지역에는 전문가가 더 적고 사람이 더 많다는 두 가지 문제를 고려하면, 이러한 문제를 확장하고 해결할 수 있는 솔루션을 찾는 것이 중요하다. 인공 지능(Artificial Intelligence)(AI) 기반 기술은 NCD/CD 의 선별 검진시 품질 측면에서 엄청난 성공을 거두었으며, 전 세계의 많은 국가가 이 기술을 채택하여 전문가를 증강하기 시작하였고 그럼으로써 대규모 배치를 다루고(예를 들어, UK) 시골 지역(예를 들어, 중국)에서 AI 지 원 원격 선별 검진을 통해 이러한 서비스에 대한 액세스를 제공하였다. AI 지원(원격) 선별 검진에 의하면, 그 렇지 않았더라면 임의의 국가의 중추 - 말하자면 인적 자원 - 을 파괴할 수 있는 많은 수의 NCD(및 CD)에 대해 조기 개입이 크게 향상될 수 있다. NCD/CD의 조기 선별 검진은 더 나은 치료 계획 및 치료 후에 더 나은 삶의 질을 제공하는 데 도움이 될 것이다. 그리고 이러한 서비스는 환자가 선별 검진을 위해 장거리를 이동하지 않 고도 시골 집의 원격 위치에서 이용 가능해질 수 있다. 이러한 AI 지원 질병 선별 검진은 이미징(X 선, 초음파, 펀더스(Fundus), OCT, PET, MRI, 적외선, CT) 및 비 이미징 방식(신장, 체중, BMI, 심장 박동수, ECG, 혈압, 혈당 등과 같은 생리학적 신체 파라미터)에 기초할 수 있다. 천천히 그리고 꾸준히 주목을 받고 있는 다른 차원은 병간호에서 헬스케어로 옮겨갈 필요성이다. 이것은 조기 경고 신호를 위해 모니터링 대상일 수 있는 잠재적으로 위험이 있는 사람에 대한 지속적인 실시간 분석을 필연 적으로 동반한다. 이것은 헬스케어 서비스 제공자에게 적시의 입력으로 경고하기 위해 특정 생리학적 파라미터 를 지속적으로 모니터링할 수 있는 웨어러블 헬스케어 디바이스를 통해 달성될 수 있다. 다른 사용은 조기 경 고 신호를 위해 모니터 대상일 수 있는 노인에 대한 지속적인 실시간 분석이다. 이러한 분석은 또한 웨어러블 디바이스를 통해 모니터링되는 생리학적 파라미터와는 별도로 시청각 데이터를 포함할 것이다. 마지막으로, 재 택 돌봄 또는 병원 내 돌봄으로 회복 중인 아픈 환자로부터 포착된 생리학적 파라미터에 대한 지속적인 실시간 분석을 중심으로 하는 사용이다. 최근 FDA가 특정 AI 기반 질병 진단 솔루션을 승인함에 따라, 고도로 보호되 는 헬스케어 도메인에서 AI 기술을 적용할 수 있는 물꼬가 열렸다. 에지에 배치 가능한 헬스케어 분석은 AI 기술의 적용을 위해 다음과 같은 세 개의 부분: (a) AI를 통한 질병 선 별 검진; (b) 정확한 진단 품질을 위해 AI를 통한 다중 모드 질병 진단; 및 (c) 개입의 영향을 개선하는 표적 치료를 위해 AI를 통한 정밀 의학 사이에서 분류될 수 있다. 헬스케어 분석 도메인에서 워크플로우에는 여러 양태가 있다. 새로운 증거 또는 사실에 기초하여 AI 모델을 업 데이트하는 범위 외에도, 선별 검진/진단의 품질이 가장 중요하다는 것을 보장하는 지속적인 노력이 있는데, 즉, 거짓 음성(false negative)이 0 이어야 하고 거짓 양성(false positive)이 0 이어야 한다. 이것은 추론할 수 있는 AI 엔진이 새로운 증거 또는 근거 사실에 기초하여 증분적 모델 업데이트(incremental model update) (재훈련)를 실행하는 성능을 가질 수도 있다는 의미이다. 추론의 지연시간은 임계적인 파라미터이다. AI 엔진의 성능은 전문가보다 훨씬 빠를 수 있으므로, 전문가는 최 종 진단을 위해 AI 엔진으로부터 적시의 입력을 얻을 수 있다. 많은 진단 모달리티(diagnostic modality)가 이미지를 기초로 하기 때문에, 중대한 질병 바이오마커의 손실없이 더 나은 이미지 압축이 필요하다. 또한, 헬스케어 데이터는 사용 측면에서 엄격하게 통제된다. 이것은 헬스케 어 데이터의 프라이버시/보호에 충분한 지원이 있어야 한다는 것을 요한다. 물체 검출 및 세그멘테이션과 같은 AI 기술은 방사선 전문의가 문제를 더 빠르고 더 정확하게 식별하는 데 도움 이 되는 독특한 가능성을 제공하여, 사례의 우선순위 매김을 더 잘 하고, 더 많은 환자에 대한 결과를 더 좋게 하고, 병원의 금전적 비용을 줄어들게 바꿀 수 있다. 그러나 의료 영상화를 위한 AI는 정보가 종종 고해상도이 고 다차원적이기 때문에 자주 어려움을 겪는다. 메모리 제약으로 인해 이미지를 낮은 해상도로 다운 샘플링하 면 바이오마커가 보존되지 않는 한 오진을 유발할 수 있다. 일단 AI 모델이 허용 가능한 레벨의 정확도로 훈련 되면, 이미징 모달리티 아키텍처에 통합될 필요가 있다. 전형적으로 방사선 이미지가 얼마나 큰지를 고려할 때, 방사선 전문의의 워크플로우를 늦추거나 모델의 정확도에 영향을 주지 않고 이러한 이미지를 효율적으로 처 리할 수 있는 것이 중요하다. 예를 들어, 뼈 연령 예측 모델은 환자의 성별과 함께 손목과 같은 인간 뼈의 X-선 이미지로부터 입력을 받는다. 그런 다음 추론 모델은 뼈 손실로 이어지는 의학적 조건을 식별하는 데 도움을 주기 위해, 뼈로부터 예상되는 연령을 결정한다. 예를 들어, 젊은 환자의 예상 연령이 실제 연령보다 적으면, 환자는 영양 실조로 고통 받는 중일 수 있다. 다른 예는 환자 가슴의 CT 스캔으로부터 폐를 식별한 다음, 검출된 장기 주변에 세그멘테이션 마스크 (segmentation mask)를 만드는 폐 세그멘테이션 모델이다. 결과는 예를 들어, 폐의 크기와 부피를 측정하는 데 사용되거나 또는 결핵 또는 기흉 검출을 위한 장기별 질병 선별 진단 모델을 로드하는 데 사용될 수 있다. 또 한, 이미지에서 폐를 분리함으로써, 방사선 전문의는 다른 구조로 인해 산만해지 않고 장기의 더 명확한 해부학 적 관점을 가질 수 있다. 유스 케이스 - 가속화된 브라우징(Accelerated Browsing) 가속화된 브라우징은 에지에서 페이지 또는 다른 콘텐츠를 준비하고 사용자 디바이스에 전송하는 웹 페이지 관 련 전처리를 말한다. 가속화된 브라우징의 예는 웹 페이지 렌더링, 광고 차단, 콘텐츠 평가 등을 포함한다. 가속화된 브라우징은 (예를 들어, CPU 및 FPGA 자원을 사용하는) 프로세서 자원 집약적이다. 에지 가속화된 웹(edge accelerated web)은 모든 스마트폰 사용자가 에지 클라우드 서비스를 사용할 수 있게 해 주는 유스 케이스이다. 페이지 로드 시간은 정상 네트워크의 서버보다 프론트-엔드 작업에 의해 더 많이 지배 된다. 브라우저는 콘텐츠 평가 및 렌더링과 같은 동작을 수행한다. 이것은 시간뿐만 아니라 전력도 소모하는 데, 이것은 모바일 폰과 같이 전력 임계적인 최종 디바이스에 중요하다. 에지에서 이러한 동작을 수행함으로써, 사용자는 정교한 브라우징 경험을 경험하고 디바이스에서 배터리 전력을 절약할 수도 있다. 동 작은 광고 차단, 렌더링, 콘텐츠 평가, 비디오 트랜스코딩 등을 포함할 수 있다. 이러한 유스 케이스는 지연시간에 구속 받지 않는다; 그러나 다양한 요구 사항으로 인해 에지 서버가 처리를 지 연시키지 않음으로써 웹 페이지 로드 시간이 느려질 수 있다. 특히, 에지 서버는 많은 수의 HTTP 요청을 처리 하고 개별 요청에 대해 정의된 QoS를 제공하도록 적응될 수 있다. 유스 케이스: 음성 분석 언어 사용자 인터페이스(language user interface)(LUI)가 사용자와 더 자연스러운 인터페이싱의 방법으로서 자 리 잡음에 따라, 우리 모두에게 관련될 음성 분석 애플리케이션이 더 많을 것이다. 챗봇이 그 예이다. 다음은 (에지) 클라우드(서버 사용)에서 음성 분석의 예를 제공한다. 예에서, 두 사람이 상이한 두 언어로 대화를 진행하고 있다. 이러한 대화 음성 사용에는 여러 음성 분석 컴포 넌트, 즉 소리를 한 언어의 텍스트로 변환하는 소리(또는 음성) 인식, 한 언어의 텍스트를 제 2 언어의 텍스트 로 변환하는 머신 번역, 및 텍스트를 제 2 언어의 음성으로 변환하는 음성 합성이 연루된다. 관련된 요구 사항 은 고품질, 실시간 성능 및 낮은 지연시간을 포함한다. 음성 분석은 여러 유스 케이스 도메인에 걸쳐 다양한 사용자 인터페이스에서 사용될 수 있다. 예를 들어, 음성 분석을 위한 여러 애플리케이션 도메인이 있다. 애플리케이션 도메인은 이것으로 제한되는 것은 아니지만 디지 털 비서, 가상 콜 센터, 헬스케어 및 (소셜) 미디어, 자동차 및 보안을 포함한다. 상이한 애플리케이션 도메인 에서, 몇 가지 가능한 사용이 있다. 다른 예로, 디지털 비서 도메인에는 음성 메시징, 음성 검색, 음성 다이얼링, 음성 메모, 음성 명령, 음성 네비 게이션 및 음성 메일이 있다. 다른 예로, 가상 콜센터 도메인에는 통신 부문, 금융 부문, 소매 부문, 건강 부문, 운송 부문, 전자 상거래 부 문, 접객 부문 및 음성 분석이 사용될 수 있는 다른 부문이 있다. 다른 예로, 헬스케어 도메인에는 의료 전사(medical transcription), 의료 보조(예를 들어, 챗봇), 의료 분석 (예를 들어, 텍스트, 차트 작성 등), 음성 인식 기능이 있는 전자 건강 기록 등이 있다. 다른 예로, (소셜) 미디어 애플리케이션 도메인에는 음성 채팅, (예를 들어, YOUTUBE®에서 수행되는 것과 같은) 자동 자막 생성, 콘텐츠 검색(음성 입력에 기반한 검색), 언어 번역, (가능한 비즈니스 방안으로서) 적절"}
{"patent_id": "10-2020-7037506", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "한 광고를 트리거할 미디어 트래픽에 대한 통찰력 및 미디어 요약이 있다. 다른 예로, 자동차 도메인에는 음성 명령, 음성 네비게이션 등이 있다. 다른 예로, 보안 도메인에는 음성 인식(예를 들어, 생체측정 보안), 음성 암호, 음성 제어 등이 있다. 본 명세서에서 논의된 애플리케이션 도메인별로 여러 사용이 있고 음성 분석을 위한 여러 애플리케이션 도메인 이 있지만, 음성 분석의 핵심 컴포넌트는 임의의 수의 도메인에 걸쳐 사용될 수 있다. 핵심 컴포넌트는: 1) 자 동 음성 인식(automatic speech recognition)(ASR), 2) 머신 번역(machine translation)(MT), 3) 텍스트 대 음 성(text to speech)(TTS), 4) 자연어 이해(natural language understanding)(NLU) 또는 자연어 처리(naturallanguage processing)(NLP)를 포함한다. 음성 분석에서 흔히 발생하는 일부의 사용은 음성 분석, 즉 ASR, MT, TTS, NLP 및 생체측정으로부터의 원초적인 것으로 구성된다. 이러한 사용은 요구 사항 측면에서 다를 수 있다. 이러한 사용에 대한 일반적인 요구 사항 중 일부는 처리량(주어진 하드웨어에 의해 처리될 수 있는 동시 발생 스트림의 수), (초 단위의) 지연시간 및 품질을 포함한다. 사용은 지연시간과 관련하여 매우 다양한 요구 사항을 가질 수 있는데, 즉 대화형 음성 분석 은 1/2초 이상의 엔드-투-엔드 지연을 허용할 수 없는 반면, 문장 필사에는 약 몇 초(2-4초)의 지연이 발생할 수 있다. 모든 사용에는 (음성 분석을 AI 지원으로 받아 들이기 위한) 최고 품질 및 (비용 효율적인 솔루션을 제공하기 위해) 최고 처리량을 요구하는 요구 사항이 있다. 처리량, 지연시간 및 품질 외에도, 몇 MB 내지 100 MB(현재 기술에 기초하지만, 크기가 증가할 가능성이 있음) 의 범위로 예상되는 모델 크기(어휘 크기로 변환), 지원되는 언어/대화/액센트, 데이터의 프라이버시/보안 요구 및 이미지/비디오/오디오/음성/텍스트 데이터의 공동 분석이 수행되는 혼합된 모달 분석과 관련된 요구 사항이 있을 수 있다. 또한 CPU에 가속기 사용을 추진할 수 있는 유연성 대 효율성과 관련된 요구 사항이 있으며, 여 기서 에지 클라우드는 낮은 어휘 크기 및 낮은 지연시간과 같은 특수 목적 요구에 응할 수 있고 그래서 가속으 로 생기는 이득을 받을 수 있다. 콘택트 센터(contact center)에서 AI 지원 음성 분석을 제공하기 위해, 솔루션 제공자는 금전적 또는 자원 비용 을 올리지 않고 고성능 및 확장성을 제공하는 AI 기반 솔루션을 유연한 플랫폼상에 배치하는 것이 중요하다. 가상 음성 비서(Virtual Voice Assistant)의 엔드-투-엔드 배치는 심층 신경 네트워크를 이용한 알고리즘, 전통 적인 음성 처리, 그래프 처리, 엔터프라이즈 소프트웨어 통합 등을 포함하는 다양한 솔루션 컴포넌트를 결합한 다. 이러한 배치를 위한 효율적인 플랫폼 아키텍처는 이러한 워크로드 유형 전반에 걸쳐 최고의 성능을 제공할 수 있고 처리량 대신 실시간 지연시간에 맞게 적응할 수 있다. 이러한 플랫폼 아키텍처는 AI 추론 배치에 사용 되는 확장 가능한 CPU(예를 들어, Intel®Xeon™ 확장 가능 CPU)에 의해 제공될 수 있는데, 이것은 성능 및 확 장성 이득이 배치 환경에 복잡성을 추가하지 않고도 AI 지원 음성 분석(AI enabled Speech Analytics) 워크로드 에 도입될 수 있기 때문이다. 음성 분석은 연속 음성 인식(Continuous Speech Recognition)(CSR), 자연어 처리(NLP), 음성 합성, (텍스트 대 음성), 음성 생체측정 등과 같은 기술을 포함한다. 전통적으로 음성 분석은 오프라인으로 적용되어 왔다. 예 를 들어, 관리자는 몇 가지 대화를 고르고, 검토한 다음, 좋은 에이전트가 회사 지침을 얼마나 잘 준수하는지를 추론하는 고객과의 상호작용을 기록하고 확인했다. AI 기반 음성 분석은 기업이 실시간으로 응답할 수 있게 한 다. 음성 인식은 음성 분석과 팀을 이루어 조직이 대화의 최대 100 %까지 더 많이 모니터링할 수 있게 한다. 앞을 내다보면, 이러한 지원 서비스는 숙련된 상담원에게 통화를 넘기기 전에, 제약없는 자연어 인터페이스로 고객에게 셀프 서비스를 제공하는 봇 비서 (Bot Assistant)를 위한 길을 열어 줄 수 있다. 음성 분석 유스 케이스는 스마트 스피커(Smart Speaker) 또는 모바일 기반 음성 도우미(Mobile-based voice assistant)와 같은 소비자 디바이스에서 발견되는 대화 인터페이스의 요구 사항을 밀접하게 따르기는 하지만, 일부 독특한 차이점도 있다. 콘택트 센터를 위한 음성 분석 솔루션은 매우 도메인 특정하고 범용성이 덜한 경 향이 있다. 대부분의 음성 분석 공급 업체는 산업 도메인에 기초하여 자신의 솔루션을 고객 맞춤 제작할 수 있 는 유연성을 통합하고 있다. 또한, 이러한 솔루션은 다수의 지역 언어를 지원해야 한다. 따라서, 배치된 알고 리즘의 다양성은 상당할 수 있다. III. 다중 이해 관계자 에지 컴퓨팅 시스템을 위한 자원 할당 및 할당 해제 개선 추가 예에서, 자원 할당 및 할당 해제의 고급 방법은 다양한 다중 이해 관계자 에지 컴퓨팅 설정으로 확장될 수 있다. 에지 하트비트(Edge Heartbeat)의 예 에지 배치에서 고려 사항 중 하나는 서비스 보증이다. 에지 컴퓨팅은 에지 서비스(예를 들어, 서비스 조정 엔 티티에서 실행되는 컴퓨팅 서비스)와 정보를 통신하는 수만 또는 수십만 개의 네트워크(또는 에지) 디바이스(예 를 들어, 드론, 센서, 사용자 장비(UE) 또는 다른 컴퓨팅 디바이스)가 있을 수 있다는 점에서 특유하다. 많은 수의 네트워크 디바이스가 있으면, 에지 배치 내에서 틀림없이 장애가 발생하기 마련이다. 예를 들어, 센서는 일정 비율로 고장날 수 있으며, 그러한 디바이스 고장은 에지 서비스가 네트워크 디바이스를 포함한 다수의 소 스로부터 데이터를 수집하는 동안, 에지 서비스 실행 가능성을 평가하기 위해 고려해야 할 필요가 있을 수 있다.다음의 하트비트 추적 기술은 하트비트, 비콘 및 추적의 특징을 사용하여, 서비스 보증을 용이하게 하는 것과 관련하여 에지 컴퓨팅 네트워크(예를 들어, 도 3 내지 도 22d에 도시된 에지 클라우드 및 에지 컴퓨팅 시 스템 구성) 내에서 복수의 에지 노드 또는 에지 디바이스(예를 들어, 노드(302, 312, 322))의 디바이스 연결성 을 관리하는 데 사용될 수 있다. 정상적으로, \"하트비트\"는 디바이스, 서비스 또는 애플리케이션이 다운되거나 지연시간 문제로 인해 응답하지 않을 때를 추적하는 데 적용된다. 위치 \"비콘\"은 디바이스, 타워, 서버 등이 위치를 브로드캐스트하고 수신자가 삼각 측량을 통해 또는 그와 다른 방식으로 위치를 결정할 수 있을 때 사용 된다. 위치 \"추적\"은 피어가 방문한 위치의 로그를 만들 수 있도록 위치 정보를 공유하는 (또는 제 3 자로부터 획득하는) 디바이스에 적용된다. 하트비트 서비스에 관한 다음의 논의에서는 이러한 유형의 보고 양태를 에지 컴퓨팅 환경에 적용할 수 있는 보다 강력한 버전의 하트비트로 통합한다. 보다 구체적으로, 컴퓨팅 서비스(예를 들어, 도 7 내지 도 12와 관련하여 도시되고 설명된 에지 서비스 및 기능)를 실행하는 서비스 조정 엔티티(예를 들어, 도 75 내지 도 78에 도시되고 설명된 다중 액세스 에지 컴퓨 팅(Multi-Access Edge Computing)(MEC) 아키텍처에 따라 구현된 것과 같은 MEC 호스트)는 다음과 같은 기능성 중 하나 이상을 수행하도록 구성된 에지 하트비트 컴포넌트를 포함할 수 있다: 충분한 수의 에지 디바이스가 활 성 상태이고 컴퓨팅 서비스와 통신하는지를 모니터링하고 보장하는 것; 에지 디바이스가 있는 위치를 결정하고 그러한 디바이스를 추적하는 것(예를 들어, 에지 디바이스가 턴 온 또는 턴 오프되어 있는지 여부, 에지 디바이 스가 컴퓨팅 서비스와의 통신과 관련하여 활성 또는 비활성 상태인지 여부, 에지 디바이스가 디바이스 위치, 지 연시간, 지오-펜싱(geo-fencing) 등에 기초한 컴퓨팅 서비스와 연관되어 있는지 여부 등); 및 컴퓨팅 서비스에 대한 서비스 보증을 관리하는 것과 관련하여 통지를 제공하는 것(예를 들어, 컴퓨팅 서비스에 통신 가능하게 결 합되거나 또는 컴퓨팅 서비스와 능동적으로 통신하는 다수의 에지 노드가 임계 수 미만 또는 임계 수를 초과할 때 통지를 제공하는 것). 이러한 통지는 메시지 및 메시징 교환, 저장된 데이터 값, 인터페이스 작 등의 형태 로 제공될 수 있다. 도 23은 일부 양태에 따라, 에지 하트비트 컴포넌트에 의한 통지에 기초한 에지 노드의 낮은 연결성 클러스터 및 연결성 조정을 도시한다. 도 23을 참조하면, 다이어그램은 낮은 연결성 구성의 복수의 에지 노 드를 도시한다. 보다 구체적으로, (도 23에서 점으로 도시된) 에지 노드는 서로 연결될 수 있을뿐만 아니라 기 존(또는 활성) 연결을 통한 서비스 조정 엔티티(예를 들어, 도 23에 도시되지 않은 MEC 호스트)에서 실행 되는 에지 서비스에도 연결될 수 있다. 도 23은 에지 노드 사이의 가능한 (또는 비활성) 연결을 더 도시 한다. 일부 양태에서, (예를 들어, 도 25와 관련하여 도시된 바와 같은) 에지 하트비트 컴포넌트는 에지 노드 자체 사 이의 연결뿐만 아니라 에지 노드와 에지 서비스 사이의 연결의 수를 모니터링하고 연결 수가 연결 임계치 아래 로 떨어질 때 통지를 발생하도록 구성된다. 도 23은 K=2이라는 예시적인 연결 임계치를 도시하며, 여기서 연결 임계치는 에지 노드 당 최대 활성 연결의 수 를 나타낸다. 낮은 연결성 구성은 자기끼리 또는 에지 서비스와의 단일 연결을 갖는 또는 활성 연결이 없는 (2310, 2312, 2314)와 같은 일부 에지 노드와 연관된다. 에지 서비스에 대해 낮은 연결성이라는 에지 하 트비트 컴포넌트 통지 후에, 연결성이 조정되며 에지 노드는 (2316, 2318, 2320)과 같은 각각의 네트워크 노드 가 에지 서비스 또는 다른 노드와 적어도 하나 또는 두 개의 활성 연결을 갖는 일반 연결 구성으로 전환 된다. 그러나 일반화된 증명 캐퍼빌리티는 하트비트 결과가 높은 정확성, 보안성, 신선함 등을 갖는 하트비트 와 같은 활성성 및 기타 피드백을 제공할 수 있다. 도 24는 일부 양태에 따라, 에지 하트비트 컴포넌트에 의한 통지에 기초한 에지 노드의 높은 연결성 클러스터 및 연결성 조정을 클러스터를 도시한다. 도 24를 참조하면, 다이어그램은 높은 연결성 구성의 복 수의 에지 노드를 도시한다. 보다 구체적으로, (도 23에서 점으로 도시된) (2310-2320)과 같은 에지 노드는 서 로 연결될 수 있을뿐만 아니라 기존(또는 활성) 연결을 통해 서비스 조정 엔티티(예를 들어, MEC 호스트, 도 24에 도시되지 않음)에서 실행되는 에지 서비스에도 연결될 수 있다. 도 24는 에지 노드 사이의 가능한 (또 는 비활성) 연결을 더 도시한다. 일부 양태에서, (예를 들어, 도 25와 관련하여 도시된 바와 같은) 에지 하트비트 컴포넌트는 에지 노드와 에지 서비스 사이의 연결(예를 들어, 네트워크 동작, 논리 동작)의 수뿐만 아니라 에지 노드 자체 사이의 연결을 모 니터링하고, 연결 수가 연결 임계치를 초과할 때 통지를 발생하도록 구성된다. 도 24는 K=2라는 예시적인 연결 임계치를 도시하며, 여기서 연결 임계치는 에지 노드 당 최대 활성 연결의 수를 나타낸다. 높은 연결성 구성은 자기끼리 또는 에지 서비스와 하나를 초과하는 활성 연결을 갖는 일부 에지 노드(도 24에 도시되지 않음)와 연관된다. 에지 서비스에 대해 높은 연결성이라는 에지 하트비트 컴포넌트 통지 후에, 연결성이 조정되며 에지 노드는 각각의 네트워크 노드가 에지 서비스 또는 다른 노드와 적어도 하나 또는 두 개의 활성 연결을 갖는 일반 연결성 구성으로 전환된다. 또 다른 예에서, 그러한 하트비트는 에 지 노드의 클러스터(예를 들어, 논리적 또는 물리적 그룹 또는 도메인) 내에 배치될 수 있다. 도 25는 일부 양태에 따라, 에지 호스트 내의 에지 하트비트 컴포넌트를 사용하는 예시적인 에지 배치를 도시한다. 도 25를 참조하면, 에지 배치는 복수의 기지국(2504, 2506, . . ., 2508)에 결합된 MEC 호스 트와 같은 서비스 조정 엔티티를 포함한다. 기지국은 (2510, . . ., 2512, 2514, . . ., 2516 및 251 8)과 같은 복수의 에지 디바이스에 결합될 수 있다(MEC 호스트가 도시되어 있지만, 개념은 고정 또는 비 모바일 에지 컴퓨트 노드에 동일하게 적용된다.) 일부 예에서, 각각의 에지 디바이스(2510, . . , 2512, 2514, . . , 2516 및 2518)는 직접 통신 링크(예를 들 어, 도 25에 도시된 점선)를 통해 MEC 호스트에 통신 가능하게 결합될 수 있거나 또는 대응하는 기지국을 통해 MEC 호스트에 통신 가능하게 결합될 수 있다. 일부 양태에서, 각각의 에지 디바이스는 복수의 통신 링크(예를 들어, 디바이스에 의해 사용되는 통신 링크)을 통해 MEC 서비스를 사용하는 하나 이상의 다른 에지 디바이스에 결합될 수 있다. 이와 관련하여, 하트비트 정보를 비롯한 정보는 MEC 호스트 로 다시 통신하기 위해 디바이스로부터 디바이스로 전달되어 에지 하트비트 컴포넌트에 의해 사용 될 수 있다. 일부 예에서, MEC 호스트는 MEC 서비스와 같은 에지 서비스를 실행하고 있다. MEC 서비스는 통신 가능하게 결합될 수 있고 기지국(2504, 2506, 2508)은 물론이고, 에지 디바이스(2510, . . , 2512, 2514, . . , 2516 및 2518) )와도 정보를 교환할 수 있다. MEC 호스트는 에지 하트비트 컴포넌트를 더 포함하고, 에지 하트비트 컴포넌트는 적합한 회로, 인터페이스 및/또는 명령어를 포함할 수 있고, 연결성 모니 터링 및 연결성 보증과 관련하여 본 명세서에서 논의된 하나 이상의 기능성을 수행하도록 구성된다. 이러한 기 능성은 디바이스 하트비트를 설정하는 것을 포함할 수 있으며, 여기서 디바이스 하트비트 또는 비콘은 MEC 서비 스와의 통신을 위한 디바이스 가용성을 나타내는 정보(예를 들어, 디바이스가 턴 온되어 있고 온라인 상 태인지/통신에 이용 가능한지 여부), 디바이스 위치를 나타내는 정보(예를 들어, 디바이스가 MEC 호스트 와 연관되거나 관련이 있는 기지국에 관한 위치), 또는 다른 디바이스 관련 정보; 하트비트 정보의 일부로서 수 신된 위치 정보(예를 들어, 디바이스와 연관된 대응하는 기지국에 대한 위치 정보)를 기지국(또는 다른 디바이 스)에 전파하는 것; 에지 디바이스가 다운되었는지 아닌지(예를 들어, 턴 오프되어 있거나 그렇지 않으면 통신 에 이용 가능하지 않은지)를 추적하는 것; MEC 서비스와의 통신에 이용 가능한 (또는 이용 가능하지 않은) 디바 이스를 추적하는 것; 지오-펜싱 메커니즘의 구현 등을 포함할 수 있다. 일부 양태에서, MEC 호스트는 에지 디바이스의 클러스터에 의해 (예를 들어, 하트비트 구성 정보를 통해) 하트비트 보고를 구현하도록 (예를 들어, 모바일 네트워크 사업자에 의해) 구성된다. 예에서, 각각의 클 러스터는 (예를 들어, 하트비트 구성 정보를 통해) 하트비트의 빈도, 하트비트 정보 사양 등으로 구성된 다. 일부 양태에서, 에지 하트비트 컴포넌트는 (예를 들어, 모바일 사업자에게) MEC 서비스가 과다 또는 과소 가입/사용되었다는 통지를 트리거할 시기를 결정하기 위해 하나 이상의 임계치 파라미터(예를 들어, 도 23 및 도 24와 관련하여 논의된 임계치 K)로 구성된다. MEC 호스트가 하트비트 구성 정보를 에지 디바이스에 전달한 후에, 하트비트 정보는 주기적으로 MEC 호스트에 다시 보고될 수 있다. 예를 들어, 에지 디바이스(2514, . . , 2516)는 대응하는 하트비트 정보 (2532, . . , 2534)를 보고할 수 있다. 일부 예에서, 각각의 에지 디바이스는 하트비트 보고 기능성, 지오-펜 싱 기능 등을 구현하는 (예를 들어, 네트워크 인터페이스 카드 내의) 하나 이상의 하드웨어 및/또는 소프트웨어 컴포넌트를 포함한다. 예를 들어, 에지 디바이스는 MEC 호스트에 의해 구성되는 바와 같이 하트비 트 정보를 보고하도록 구성된 하트비트 컴포넌트를 갖는 네트워크 인터페이스 카드를 포함한다. 일부 양태에서, MEC 호스트 내의 에지 하트비트 컴포넌트는 지오-펜스 구성 정보를 사용하여 하나 이상의 지오-펜스를 구성할 수 있다. 예를 들어, 에지 하트비트 컴포넌트는 지오-펜스 구성 정보 를 사용하여 기지국의 위치와 연관될 수 있는 제 1 지오-펜스를 구성하여, 지오-펜스 내에 있고 기지국과 연관된 디바이스 만이 MEC 서비스를 사용할 수 있도록 할 수 있다. 에지 하트 비트 컴포넌트는 다른 에지 디바이스(예를 들어, 기지국)의 위치에 기초할 수 있고 MEC 서비스 를 사용하도록 지오-펜스 내의 에지 디바이스를 구성하는 데 사용될 수 있는 지오-펜스와 같은 추 가의 지오-펜스를 구성할 수 있다. 일부 양태에서, 지오-펜스는 MEC 호스트와의 근접성 등과 같은 다른기준에 기초하여 구성될 수 있다. 또 다른 예에서, LSM 또는 다른 보안 정책은 지오-펜스 정책을 설명할 수 있 으며, 좌표 및 지오-펜스를 가진 MEC 호스트, 타워, 기지국 또는 다른 노드는 LSM 시행 지점 역할을 할 수 있다. 추가 예에서, 위치는 위치 센서의 RoT 캐퍼빌리티가 위치 좌표에서 더 큰 신뢰를 확립할 수 있도록 증명될 수 있다. 따라서, 위성이 또한 RoT 키 및 증명 신호를 포함하는 위성 신호에 글로벌 네비게이션(예를 들어, GPS) 좌표가 조건부이면, 증명된 위치 좌표가 보고되어 지오-펜스 액세스 시행 메커니즘에 더 큰 신뢰성과 탄력성을 줄 수 있다. 에지 하트비트 컴포넌트가 MEC 호스트 내에서 구현된 것으로 도시되어 있지만, 에지 하트비트 컴포 넌트가 하나 이상의 다른 에지 디바이스 내에서, 이를테면 도 25에 도시된 하나 이상의 기지국 내에서 구현될 수 있다는 점에서 본 개시내용은 이와 관련하여 제한되지 않는다. 일부 예에서, 각각의 기지국(2504, . . , 2508) 또는 MEC 호스트는 알람을 트리거하는 데 사용될 수 있는 임계치뿐만 아니라 보고의 빈도의 구성을 비롯한, 하트비트 또는 비콘을 에지 디바이스의 그룹에 구현하도록 구 성될 수 있다. 일부 예에서, 에지 하트비트 컴포넌트는 수신된 하트비트 정보를 사용하여 에지 배치 내의 에지 디 바이스와 연관된 다음과 같은 정보: 디바이스 ID, (식별된 디바이스와 연관된 기지국의) 기지국 ID, (식별된 디 바이스와 연관된 중앙국(CO)의) CO ID, 연결된 디바이스 ID 목록(예를 들어, 식별된 디바이스와 연결된 에지 디 바이스의 ID 목록) 등을 추적하도록 구성될 수 있다. 일부 양태에서, 에지 하트비트 컴포넌트는 하나 이 상의 블룸 필터(Bloom filter)(또는 다른 소프트웨어 또는 하드웨어 구조)를 사용하여 이러한 추적 메커니즘을 구현할뿐만 아니라 연결성 평가와 관련하여 하나 이상의 하트비트 처리 기능을 수행하는 것을 용이하게 할 수 있다. 일부 예에서, 본 명세서에 개시된 기술은 (예를 들어, 도 75 내지 도 78에 도시되고 설명된 MEC/5G 아키텍처에 따라 구현되는 것과 같은) 에지/MEC 환경 컨텍스트에 적용되어, 액세스 에지와 클라우드 에지 사이의 공백에 이 어져 있는 에지 노드의 시스템이 에지 간의 경로(또는 다중 경로)가 된다는 것을 보장하도록 할 수 있다. 이러 한 기능성은 에지 클라우드 인스턴스(예를 들어, 예를 들어, 도 3 내지 도 22d에 도시된 에지 클라우드 및 에지 컴퓨팅 시스템 구성)에서 서비스 중단 또는 자원 중단(예를 들어, 절전을 위해 부분적 전력 통제(brown- out))이 사전에 검출되지 않을 가능성을 방지한다. 일부 예에서, 하트비트 보고는 각각의 디바이스가 미리 결정된 빈도로 주기적으로 하트비트 정보를 보고하도록 구성될 수 있다. 일부 예에서, 각각의 기지국 또는 MEC 호스트(예를 들어, 에지 하트비트 컴포넌트로 구성된 디바이스 또는 디바이스들)는 에지 네트워크의 각각의 에지 디바이스로부터 하트비트 정보를 주기적으로 폴링 (poll)(또는 요청)할 수 있다. 추가 예에서, 에지 컴퓨팅 네트워크 내의 복수의 에지 노드의 디바이스 연결성을 관리하기 위한 기술의 방법은 에지 하트비트 컴포넌트를 사용하여 구현될 수 있다. 일부 양태에서, 방법은 에지 컴퓨팅 네트워크 내 복수의 에지 노드(예를 들어, (2510, . . ., 2518))와 통신하는 에지 서비스(예를 들어, MEC 서비스)를 실행하는 서비스 조정 엔티티(예를 들어, MEC 호스트)의 에지 하트비트 컴포넌트(예를 들어, )에 의해 수행 될 수 있다. 제 1 동작에서, 하트비트 구성 정보(예를 들어, )는 복수의 에지 노드로의 전송하기 위해 인코딩되고, 하트비트 구성 정보는 디바이스 하트비트 정보의 보고를 구성한다. 제 2 동작에서, 하트비트 구성 정보에 기초하여 복수의 에지 노드로부터 수신된 디바이스 하트비트 정보가 디코딩된다. 제 3 동작에서, 컴퓨 팅 서비스에 연결된 복수의 에지 노드 중 다수의 에지 노드가 디바이스 하트비트 정보에 기초하여 결정된다. 제 4 동작에서, 컴퓨팅 서비스에 대한 디바이스 연결성을 나타내는 통지가 결정된 수의 에지 노드에 기초하여 생성된다. 예를 들어, 에지 서비스를 사용하는 에지 노드의 수가 임계 수를 초과하는 것으로 결정되면 경고가 발생할 수 있다. 수신된 하트비트 정보에 기초하여 다른 유형의 경고 또는 통지가 또한 생성되어 에지 컴퓨팅 네트워크 내에서 디바이스 연결성을 관리하고 서비스 보증을 촉진할 수 있다. 에지 하트비트를 구현하기 위한 제 1 예시적인 방법(예 A1)은 에지 컴퓨팅 네트워크(예를 들어, 에지 클라우드 및 노드 또는 디바이스(2200, 2232, 2240 또는 2250)에서 구현되는 것과 같은 구현 시스템 및 디바이스) 내에서 복수의 에지 노드의 디바이스 연결성을 관리하기 위한 방법으로서, 방법은, 에지 컴퓨팅 네트워크 내의 복수의 에지 노드와 통신하는 컴퓨팅 서비스를 실행하는 서비스 조정 엔티티의 하나 이상의 프로세서에 의해, 복수의 에지 노드로 전송을 위해 하트비트 구성 정보를 인코딩하는 단계 - 하트비트 구성 정보는 디바이스 하트비트 정보의 보고를 구성함 -; 하트비트 구성 정보에 기초하여 복수의 에지 노드로부터 수신된 디바이스 하트비 트 정보를 디코딩하는 단계; 디바이스 하트비트 정보에 기초하여 컴퓨팅 서비스에 연결된 복수의 에지 노드의 에지 노드의 수를 결정하는 단계; 및 결정된 수의 에지 노드에 기초하여, 컴퓨팅 서비스에 대한 디바이스 연결 성을 나타내는 통지를 생성하는 단계를 포함한다. 제 2 예(예 A2)에서, 예 A1의 주제는, 서비스 조정 엔티티의 하나 이상의 프로세서에 의해: 컴퓨팅 서비스에 연 결된 에지 노드의 수가 임계 수 미만일 때 통지를 생성하는 것을 포함한다. 제 3 예(예 A3)에서, 예 A1-A2의 주제는, 디바이스 하트비트 정보가 복수의 에지 노드의 각 노드에 대한 디바이 스 위치 정보를 포함하는 것을 포함한다. 제 4 예(예 A4)에서, 예 A3의 주제는, 디바이스 위치 정보가 서비스 조정 엔티티에 관한 위치 정보 또는 복수의 에지 노드와 통신 가능하게 결합된 기지국 및 서비스 조정 엔티티에 관한 위치 정보를 포함하는 것을 포함한다. 제 5 예(예 A5)에서, 예 A4의 주제는, 하트비트 구성 정보가 디바이스 하트비트 정보를 보고하는 빈도를 구성하 는 것을 포함한다. 제 6 예(예 A6)에서, 예 A1-A5의 주제는, 복수의 에지 노드 중 적어도 하나의 에지 노드로부터 수신된 디바이스 하트비트 정보가 데이터 패킷이 적어도 하나의 에지 노드에 의해 송신되는 송신 시간을 나타내는 데이터 패킷을 포함하는 것을 포함한다. 제 7 예(예 A7)에서, 예 A6의 주제는, 서비스 조정 엔티티의 하나 이상의 프로세서에 의해, 송신 시간에 기초하 여 적어도 하나의 에지 노드와 서비스 조정 엔티티 사이의 통신 지연시간 및 데이터 패킷이 서비스 조정 엔티티 에 의해 수신된 시간을 결정하고; 결정된 통신 지연에 적어도 기초하여 통지를 생성하는 것을 포함한다. 제 8 예(예 A8)에서, 예 A3-A7의 주제는, 서비스 조정 엔티티의 하나 이상의 프로세서에 의해: 컴퓨팅 서비스와 연관된 지오-펜스를 구성하는 단계를 포함한다. 제 9 예(예 A9)에서, 예 A8의 주제는 서비스 조정 엔티티의 하나 이상의 프로세서에 의해: 디바이스 하트비트 정보에 기초하여, 복수의 에지 노드 중 구성된 지오-펜스 외부에 있는 에지 노드의 수를 결정하는 동작; 및 구 성된 지오-펜스 외부에 있는 결정된 에지 노드의 수에 적어도 기초하여 통지를 생성하는 동작을 포함한다. 제 10 예(예 A10)에서 예 A1-A9의 주제는, 서비스 조정 엔티티가, 다중 엑세스 에지 컴퓨팅(MEC) 호스트로서, 서비스 조정 엔티티의 가상화 인프라스트럭처에서 인스턴스화된 MEC 애플리케이션으로서 컴퓨팅 서비스를 실행 하는 것을 포함한다. 제 11 예(예 A11)에서, 예 A10의 주제는, MEC 호스트가 ETSI(European Telecommunications Standards Institute) MEC 표준 제품군의 표준에 따라 동작하도록 구성된 것을 포함한다. 다양한 설정에서, 예 A1-A11(및 이러한 에지 하트비트 유스 케이스의 다른 양태)은 하트비트의 사용을 정의하는 API 또는 사양; 하트비트의 사용을 정의하거나 포함하는 프로토콜; 및 다음의 예(예를 들면, 예 B1-AA11)에 따 른 하트비트의 다른 사용 및 구현의 결과로서 관찰되거나 모니터링될 수 있다. 예 A1-A11 및 하트비트의 다른 양태는 또한 (예를 들어, FaaS 또는 EaaS 설정 - 이러한 FaaS 또는 EaaS 요소는 에지 클러스터의 컴퓨트 요소에 서 실행되도록 설계된 또는 SLA의 목표 및 의무 또는 에지 클러스터의 다른 의무를 달성하도록 기능을 하는 에 지 클러스터와 통신하는 일부 컴퓨팅 요소에 의해 서비스 받도록 설계된 코드 요소로 구성됨 - 에서 호출되거나 동작되는 바와 같은) 서비스 동작 및 서비스 기능의 결과로서 관찰되거나 구현될 수 있다. 또한, 예 A1-A11의 방법은 에지 컴퓨팅 시스템에서 (예를 들어, 명령어가 실행될 때 방법을 수행하는 머신 판독 가능 매체와 함께) 구현된 명령어로서 또는 (예를 들어, 방법을 수행하거나 달성하는 구성을 포함하는 장치와 함께) 구현된 하드웨 어 구성으로서 제공될 수 있다. 따라서, 예 A1-A11(및 하트비트 서비스)의 특징은 시스템 오케스트레이터 또는 설계자에 의해 조정되거나 설계된 대로, 본 명세서의 임의의 다른 예와 결합되어 에지 클러스터 또는 에지 클라 우드 시스템을 구성할 수 있다. 추적 가능한 데이터 이동의 예 에지 배치에는 많은 양의 역동성이 있으며, 따라서 이러한 배치에서 고려 사항 중 하나는 서비스 보증 및 데이 터 증명이다. 에지 컴퓨팅은 에지 서비스(예를 들어, 도 7 내지 도 12와 관련하여 도시되고 설명된 에지 서비 스 및 기능에 대해 위에서 논의된 바와 같이, 서비스 조정 엔티티에서 실행되는 컴퓨팅 서비스)와 정보를 통신 하는 수만 또는 수십만 개의 네트워크(에지) 디바이스(예를 들어, 드론, 센서, 사용자 장비(UE), 또는 다른 컴퓨팅 디바이스)가 있을 수 있다는 점에서 특유하다. 다수의 네트워크 디바이스에 의하면, 어떤 인스턴스에서든 디바이스 사이에서 상이한 유형 및 양의 정보가 교환된다. 예를 들어, 센서는 상이한 유형의 정보를 지속적으 로 에지에 전송할 수 있다. 발생하는 핵심 도전과제는 신뢰라는 과제인데, 즉, 에지 인프라스트럭처가 정보를 전송하는 수천 개의 디바이스를 처리하면서, 에지 인프라스트럭처로 가는 도중에 여러 중간 홉을 통해 흐를 수 있는 데이터의 소스를 신뢰하는 수단을 어떻게 보존할 수 있는가 이다. 본 명세서에 개시된 기술은 에지 클라우드(예를 들어, 도 3 내지 도 22d에 도시된 에지 클라우드 및 에지 컴퓨팅 시스템 구성)에서 데이터 증명을 처리하기 위해 사용될 수 있다. 보다 구체적으로, 개시된 기술은 데이 터 전송에 연루된 이벤트의 흐름을 추적하는 데 필요한 후크(hook)를 에지 디바이스 및 인프라스트럭처에 제공 하는 데 사용될 수 있다. 예를 들어, 센서 A가 데이터를 게이트웨이 B, 허브 C, 에지 서버 D로 전송하는 동시 에, 여러 다른 그러한 스트림을 동시에 처리하는 (따라서 워크로드 데이터를 관련 컴퓨트 자원으로 동적으로 이 동시키는) 신뢰성 있는 메커니즘이 제공될 수 있다. 도 26은 일부 양태에 따른, 에지 노드(예를 들어, 노드(302, 312, 322)의 구현) 사이에서 예시적인 데이터 흐름 을 도시한다. 도 26을 참조하면, 에지 컴퓨팅 네트워크에서 복수의 에지 노드 사이의 데이터 통신 교환이 도시된다. 보다 구체적으로, (에지 네트워크 디바이스(A-I)를 포함할 수 있는) 에지 노드는 (에 지 노드 사이의 에지로서 도시된) 데이터 흐름 경로를 통해 데이터를 교환한다. 일부 양태에서, 에지 룩업 테이블은 에지 컴퓨팅 네트워크 내의 다수의 네트워크 목적지에서 캐싱될 수 있다. 도 27의 룩업 LUT와 동일할 수 있는 에지 룩업 테이블(look-up table)(LUT)은 인증 정보를 포함 할 수 있다. 예를 들어, LUT는 에지 컴퓨팅 네트워크 내의 인가된 에지 노드, 에지 노드의 각 노드에 대 한 인증 자격증명, 및 데이터 증명에 사용될 수 있는 다른 인증 정보를 열거할 수 있다. 일부 양태에서, LUT는 도 27에 도시된 (예를 들어, 도 75 내지 도 78에 도시되고 설명된 MEC 아키텍처에 따라 구현된) 바와 같이, MEC 호스트와 같은 서비스 조정 엔티티를 통해 에지 노드에 프로비저닝될 수 있다. 일부 양태에서, LUT는 정보가 각각의 데이터 통신 홉의 소스에 귀속되는 참조 메커니즘으로 사용될 수 있다. 예를 들어, 데이터가 에지 노드 사이에서 통신될 때, 데이터 패킷에는 예를 들어 데이터가 통과한 에지 노드를 명시하는 에지 핸들(edge handle)이 포함될 수 있다. 예를 들어, 데이터 볼륨에는 A-> B-> C-> D의 ID를 가진 에지 노드가 패킷을 전송했음을 표시하는 에지 핸들이 있을 수 있으며, LUT는 에지 핸들에 의해 명시된 하나 이 상의 에지 노드가 에지 컴퓨팅 네트워크 내에서 데이터 교환에 인증되었는지를 결정하는 데 사용할 수 있 다. 예를 들어, 흐름 경로에 있는 각각의 노드는 특히 흐름 지향 보안 정책 또는 보안 특징을 사용하여, LSM 또는 다른 보안 정책 시행 지점이 될 수 있다. 노드가 인가되지 않거나 에지 핸들에 의해 표시된 통신 교환에 대해 데이터 증명이 실패했다고 결정되면, 에지 컴퓨팅 네트워크 내에서 통지/경고가 생성되고 통신될 수 있다. 추가 예에서, 정보 중심 네트워킹(information centric networking)(ICN)의 특징이 에지 컴퓨팅 네트워크(2600 또는 2700) 내에서 사용하기 위해 연루되거나 적응될 수 있다. 도 27은 일부 양태에 따라, 에지 컴퓨팅 네트워크 내의 데이터를 증명하기 위한 기술을 도시한다. 도 27을 참 조하면, 에지 컴퓨팅 네트워크는 복수의 에지 노드(또는 에지 디바이스)(2704, 2706, 2708, . . , 2710) (예를 들면, 노드(302, 312, 322)의 구현)에 연결된 에지 컴퓨트 호스트(예를 들어, MEC 호스트)를 포함 한다. 일부 양태에서, 에지 컴퓨팅 네트워크는 에지 노드 사이에서 데이터가 전달될 때 하드웨어 또는 소프트웨 어 후크를 사용하는 것과 같은 신뢰성 있는 흐름 전송을 위한 메커니즘을 사용하여, 데이터가 함부로 변경되지 않았고 참여하는 에지 노드가 데이터 교환에 대해 인가되었다는 것을 보장할 수 있다. 일부 양태에서, 다수의 에지 사이 또는 에지 디바이스 사이의 통신을 비롯한, 데이터의 이동(예를 들어, 데이터 수신 또는 송신)과 연 관된 각각의 네트워크 위치(예를 들어, 에지 노드 2704, . . , 2710)에서, 데이터 페이로드는 해시될 수 있고 선택적인 타임스탬프가 포함될 수 있다. 예를 들어, 그리고 일부 양태에서, 에지 노드로부터 발생하는 데이터 패킷은 신뢰성 있는 네트워크 키(예를 들어, 에지 컴퓨팅 네트워크 내의 인가된 에지 노드 에 전달될 수 있는 신뢰성 있는 키)로 해시되거나 인코딩될 수 있다. 데이터 패킷이 다른 에지 디바이스(예를 들어, 2706, . . , 2710)로 넘어감에 따라, 각각의 에지 노드는 데이터를 디코딩하고 추가 정보를 추가하고(예 를 들어, 소스 에지 디바이스 ID, 데이터 흐름에 지금까지 참여하는 에지 디바이스의 디바이스 ID, 데이터가 각 각의 홉에서 수신 또는 송신될 때의 타임스탬프 정보, 및 데이터 패킷의 데이터 페이로드에 첨부된 에지 핸들에 대한 다른 정보를 추가하고), 데이터 패킷을 다시 인코딩하고, 다음 디바이스로 포워딩할 수 있다. 이와 관련하여, 데이터 패킷이 (예를 들어, 에지 컴퓨트 호스트에 의해 실행된) 에지 서비스 또는 타겟 목적지에 도착할 때, 각각의 홉의 수신 에지 노드는 데이터 패킷이 어디에서 왔고, 데이터 패킷이 데이터 흐름 경로의 각 디바이스에 의해 언제 수신 또는 전송되었고, 어떤 디바이스가 데이터 흐름 경로에 있는지 그리고 그러한 디바 이스가 에지 컴퓨팅 네트워크 내에서 통신하도록 인가되었는지는 물론, 데이터 증명을 위한 다른 인가 및 인증 처리 기능을 체크할 수 있다. 일부 양태에서, 각각의 데이터 패킷과 통신되는 데이터(예를 들어, 에지 핸 들)는 메시지가 포워딩될 때 디버깅 목적에 사용될 수 있다. 일부 양태에서 그리고 도 27에 도시된 바와 같이, 패킷이 발신(소스) 에지 디바이스로부터 목적지 디바이스로 넘어감에 따라, 에지 핸들이 데이터 페이로드에 추가되어 데이터 패킷을 형성할 수 있다. 예를 들어, 디바이스 B가 에지 디바이스 A에 의해 증명된 데이터를 수신하면, 디바이스 B는 자신을 인증하고 A를 데이터 소스로서 포 함시키고, 이 정보를 에지 핸들로 패키징하여 에지 디바이스 C로 전송되는 데이터 패킷을 형성한다. 그런 다음 에지 디바이스 C는 A에서부터 B, C 로의 흐름을 증명하고 업데이트된 에지 핸들을 생성한 다음, 데이터 패킷을 에지 디바이스 D로 포워딩한다. 일부 양태에서, 에지 디바이스의 증명/인증 프로세스는 블록체인 기술 또는 다른 유형의 추적 또는 인증 기술에 기초할 수 있다. 일부 양태에서, 각각의 에지 핸들은 소스 에지 디바이스 ID 및 데이터 흐름 경로(예를 들어, 데이터 패킷을 통신하는 데 참여했거나 참여 중인 각각의 디바이스의 디바이스 식별 정보)를 포함할 수 있다. 일부 양태에서, 타임스탬프가 또한 데이터 흐름 경로에 참여하는 하나 이상의 표시된 디바이스마다 포함될 수 있다(예를 들어, 타임스탬프는 데이터가 데이터 흐름 경로의 일부인 대응하는 에지 디바이스로부터 송신되거나 수신되는 시간을 표시한다). 도 27의 특정 예를 참조하면, 데이터 패킷은 소스 에지 노드로부터 유래하고 그에 의해 생성된다. 데이터 패킷는 데이터 페이로드에 첨부되어 데이터 패킷을 형성하는 에지 핸들을 포함한다. 에지 핸들(또는 EH1)은 발신(소스) 에지 디바이스의 에지 디바이스 ID(예를 들어, 데이터 패킷의 소스 디바이스인 에지 디바이스의 식별)뿐만 아니라 데이터 패킷의 현재 데이터 흐름 경로를 형성하는 에 지 디바이스의 디바이스 식별과 같은 정보를 포함할 수 있다. 디바이스가 소스 디바이스이기 때문에, 에 지 핸들 내의 데이터 경로는 노드의 식별 정보만을 포함한다. 데이터 패킷이 생성된 후에, 에지 노드는 에지 노드와 같이, 통신 경로에 있는 다음 디바이 스로 데이터 패킷을 송신한다. 패킷이 에지 노드에서 수신된 후에, 에지 노드는 에지 노드 의 식별 정보를 포함하도록 데이터 흐름 경로를 업데이트함으로써 에지 핸들을 (예를 들어, EH2로) 업데 이트한다. 예를 들어, 에지 핸들 EH2에서 데이터 흐름 경로는 \"A-B\"를 표시할 수 있고, 이것은 데이터 패킷이 에지 디바이스 A에서 유래되었고 에지 디바이스 B에서 수신된다는 것을 나타낸다. 에지 노드 가 에지 핸들을 업데이트하고 EH2를 생성한 후에, EH2는 데이터 페이로드에 첨부되어 새로운 데이터 패킷 을 형성하며, 새로운 데이터 패킷은 데이터 흐름 경로에 있는 노드와 같은 후속 에지 디바이스로 전달된다. 패킷이 에지 노드에서 수신된 후에, 노드는 에지 디바이스의 식별 정보를 포함하도록 데이터 흐름 경로를 업데이트함으로써 에지 핸들을 (예를 들어, EH3로) 업데이트한다. 예를 들어, 에지 핸들 EH3에서 데이터 흐름 경로는 \"A-C\"를 표시할 수 있고, 이것은 데이터 패킷이 에지 노드 A에서 유래되었고, 에지 노드 B에 의해 포워딩되었으며 에지 노드 C에서 수신된 것을 나타낸다. 에지 노드가 에지 핸들을 업데이트하고 EH3를 생성한 후에, EH3는 데이터 페이로드에 추가되어 새로운 데이터 패킷을 형성 하며, 새로운 데이터 패킷은 데이터 흐름 경로에 있는 디바이스와 같은 후속 에지 디바이스로 전달된다. 또한, 감사(auditor), 준수 엔티티 또는 제 3 자는 게시-구독 또는 다른 유사한 분산 메시징 시스템에 따라 EH 값을 구독하여 데이터 흐름, 증명 흐름 또는 다른 흐름 그래프 활동이 에지 원격 측정 또는 메타데이터로서 모 니터링되고, 분석되고 추론될 수 있도록 할 수 있다. 일부 예에서 그리고 위에서 언급된 바와 같이, 각각의 에지 디바이스가 에지 핸들을 업데이트함에 따라, 타임스 탬프 정보가 에지 핸들에도 포함될 수 있다. 에지 컴퓨팅 네트워크 내의 에지 디바이스 사이에서 동기화 된 클록 데이터를 보장하기 위해, 에지 컴퓨트 호스트는 동기화 컴포넌트로 구성될 수 있다. 동기 화 컴포넌트는 적합한 회로, 인터페이스 및/또는 명령어를 포함할 수 있고, 에지 디바이스 사이의 클록 동기화를 용이하게 하기 위해 동기화 신호를 (예를 들어, 브로드캐스트 메시지를 통해 에지 컴퓨팅 네트워크 내에서 통신하도록 인가된 모든 에지 디바이스에) 통신하도록 구성된다. 일부 예에서, 에지 컴퓨트 호스트는 에지 LUT 컴포넌트로 구성된다. 에지 LUT 컴포넌트는 적합한 회로, 인터페이스 및/또는 명령어를 포함할 수 있고 (예를 들어, 도 26과 관련하여 언급된 바와 같이) LUT를 생성하고 유지하도록 구성되며, LUT(예를 들어, LUT)는 (예를 들어, 브로드캐스트 메시지를 통해) 모든 에지 디바이스에 채워져서 에지 컴퓨팅 네트워크 내의 에지 디바이스가 디바이스 인증 및 데이터 증 명 목적을 위해 이러한 LUT를 사용할 수 있도록 할 수 있다. 추가 예에서, 데이터의 증명을 위한 기술을 구현하기 위한 방법이 에지 컴퓨팅 네트워크 내에서 구현될 수 있다. 이 기술은 에지 컴퓨팅 네트워크(예를 들어, 2700) 내의 복수의 에지 디바이스의 제 1 에지 디바이스(예 를 들어, )의 하나 이상의 프로세서에 의해 수행될 수 있다. 제 1 동작에서, 복수의 에지 디바이스 중 제 2 에지 디바이스(예를 들어, 2704)로부터 수신된 데이터 패킷(예를 들어, )이 디코딩된다. 데이터 패 킷은 데이터 페이로드 및 제 1 에지 핸들(예를 들어, EH1)을 포함한다. 제 1 에지 핸들은 소스 에지 디바이스 (예를 들어, 디바이스 또는 A) 및 데이터 페이로드와 연관된 데이터 흐름 경로를 표시한다. 제 2 동작 에서, 소스 에지 디바이스(예를 들어, A) 및 업데이트된 데이터 흐름 경로(예를 들어, 디바이스(2704 및 2706) 의 에지 디바이스 식별)를 포함하도록 제 2 에지 핸들(예를 들어, EH2)이 생성된다. 이와 관련하여, EH2의 업 데이트된 데이터 흐름 경로는 데이터 흐름 경로(예를 들어, EH1로 표시되는 데이터 흐름 경로, 디바이스 A 만 있음) 및 제 1 에지 디바이스(또는 디바이스 B)의 디바이스 ID에 기초 한다. 제 3 동작에서, 제 2 에지 핸들 및 데이터 페이로드는 복수의 에지 디바이스 중 제 3 에지 디바이스(예를 들어, )로의 전송을 위해 (예를 들어, 데이터 패킷으로서) 인코딩된다. 이러한 예에서 보여주는 바와 같이, 많은 데이터 제공자가 에지 클라우드 내에서, 데이터 제공자의 데이터에 대 해 변환을 수행하는 많은 에지 컴퓨트 서비스(예를 들어, 도 7 내지 도 12와 관련하여 도시되고 설명된 에지 서 비스 및 기능)와 함께 존재한다. 강력한 서비스 환경을 실시 가능하게 하기 위해, 엔드포인트 디바이스(및 에 지 노드)는 데이터 제공자 및 데이터를 처리하는 에지 서비스를 둘 모두 검증(증명)하는 캐퍼빌리티와 함께, 변 환된 데이터에 액세스해야 할 것이다. 예에서, 데이터 및 데이터 변환 증명은 에지 컴퓨팅 시스템 내에서 에지 컴퓨트 서비스의 결과 또는 사용에 대 해 실시 가능해진다. 예를 들어, 데이터 제공자가 인가된 데이터를 에지 서비스로 전송할 때, 에지 서비스는 그 데이터가 신뢰성 있는 소스에서 유래되었음을 증명할 수 있다. 에지 서비스가 (자신이 수행할 수 있고 수행 할 캐퍼빌리티 또는 권한이 있다는) 변환을 적용함에 따라, 에지 서비스의 결과는 인가된다. 결과적으로, 에지 서비스로부터 생성된 데이터는 데이터의 소스와 데이터의 변환을 둘 모두 입증하면서 엔드포인트 디바이스에 의 해 소비될 수 있다. 간단한 예로, 차량의 카메라가 이미지를 셀 타워 또는 다른 무선 액세스 포인트로 전송하고, 여기서 에지 서비 스가 낮은 지연시간 차량 또는 이미지에 대한 물체 검출 작업을 수행하는 시나리오를 고려한다. 이러한 데이터 의 사용자는 물체 검출 결과를 수신할 때, 이미지가 신뢰성 있는 카메라에 의해 제공되었고, 또한 물체 검출 분 석이 신뢰성 있는 엔티티에 의해 수행되었다고 입증할 수 있다. 일부 상황에서, 에지 컴퓨팅 시스템 내의 중간 처리 단계/노드에서 단순하게 데이터가 출현할 수 있기 때문에 카메라 또는 데이터가 어디로부터 온 것인지를 알 수 없다. 이러한 처리에는 중간 노드가 데이터에 알려지지 않은 (현재 노드 컨텍스트 이전의) 출처가 있다고 표시하기 때문에 증명 컨텍스트가 연루되어 있다. 그러므로 증명 정보는 시각적 데이터가 다수의 홉에 의해 트랜스코딩/변환되므로 엔드포인트와 엔드포인트를 연결하는 경 로의 조합을 포함할 수 있다. 데이터 및 데이터 변환 증명의 사용은 표준 또는 사양에 명시된 데이터를 비롯한 상호운용 가능한 증명 데이터 를 통해 실시 가능해질 수 있다. 임의의 증명 인프라스트럭처에서 중요한 것은 (예를 들어, 각각의 데이터 변 환 작용이 상이한 세트의 노드 및 변환 논리에 연루될 수 있기 때문에) 검증자(들)가 (직접뿐만 아니라) 간접적 으로 상호작용되는 자원을 발견하는 역량이다. 중간 작용의 증명은 기억되고 후속 쿼리에 이용될 수 있다. 예 를 들어, 데이터 및 코드 \"신뢰\"는 암호화 해시로서 나타낼 수 있다. 증명된 자원의 해시 트리는 선행하는 모 든 것의 현재 \"허용된\" 증명 값을 유지하는 데 사용될 수 있다. 중앙집중식 접근 방식은 해시 트리 업데이트를 유지하고 쿼리에 최적화된 복사본을 \"증명 캐시\"로서 복제할 수 있고; 분산 접근 방식은 블록체인을 활용할 수 있다. 데이터 및 데이터 변환 증명의 컨텍스트에서, \"증명 가능한 것\"과 속성에 대한 풍부한 사전이 정의될 수 있다. 이러한 사전 목록은 태그 이름이 증명 가능한 것을 식별하고 값이 \"측정치\"(예를 들어, 해시)인 한 세트의 태그 -값 쌍으로 간단한 것일 수 있다. 미리 정의된 목록은 이러한 값 중 일부를 포함할 수 있지만, 사용자 커뮤니 티는 증명을 요구하는 애플리케이션 특정 자원의 태그를 정의할 수도 있다. 예를 들어, 에지 컴퓨팅 시스템의이해 관계자에 의해 소유된 보안 카메라는 이미지에 대한 메타 데이터(예를 들어, EXIF)를 식별할 수 있는 반면, 카메라 제조사 또는 공급 업체는 카메라가 성공적으로 통과한 테스트 스위트(test suite)에 대한 정보를 담은 인증서를 발급할 수 있다. 데이터 추적에 사용되는 타임스탬프는 분산 시스템에서 도전과제가 될 수 있는 동기화된 클록을 필요로 할 수 있다. 그러나 추적 목적을 위해서는 이벤트의 타이밍이 아닌 이벤트의 시퀀스 만 캡처하는 것으로 충분할 수 있다. 블록체인은 블록체인이 주문을 부과하기 때문에 타이밍 없이 추적을 달성하는 방법이다(블록체인 주문은 실제 주문과 상이할 수 있겠지만, 유스 케이스는 실제적이고 정확한 주문을 필요로 하지 않을 수 있다). 주문 추적을 사용하면, 오케스트레이션 또는 워크플로우 계획은 의도된 주문을 설명하기 때문에 메트릭으로서 사용될 수 있다. 그러나 더 간단한 예에서, 유스 케이스의 초점이 (예를 들어, 분쟁을 해결하거나 또는 공격 병리를 특성화하는) 법의학 목적이면, (특히, 전제 조건이 충족된다면, 이를테면 로컬 클록에 대한 변경이 블록체인에 기록되고 플랫폼으로/플랫폼으로부터 데이터 흐름이 블록체인에 기록된다면) 로컬 플랫폼 클록을 사용하는 것으 로 충분할 수 있다. 추적 가능한 데이터 이동을 구현하기 위한 제 1 예시적인 방법(예 B1)은 에지 컴퓨팅 네트워크(예를 들어, 에지 클라우드, 및 노드 또는 디바이스(2200, 2232, 2240 및 2250)에서 구현되는 것과 같은 구현 시스템 및 디 바이스) 내에서 데이터 증명을 위한 방법으로서, 방법은, 에지 컴퓨팅 네트워크 내의 복수의 에지 디바이스 중 제 1 에지 디바이스의 하나 이상의 프로세서에 의해: 복수의 에지 디바이스 중 제 2 에지 디바이스로부터 수신 된 데이터 패킷을 디코딩 - 데이터 패킷은 데이터 페이로드 및 제 1 에지 핸들을 포함하고, 제 1 에지 핸들은 소스 에지 디바이스 및 데이터 페이로드와 연관된 데이터 흐름 경로를 표시함 - 하는 단계; 소스 에지 디바이스 및 업데이트된 데이터 흐름 경로를 포함하는 제 2 에지 핸들을 생성 - 업데이트된 데이터 흐름 경로는 데이터 흐름 경로 및 제 1 에지 디바이스의 디바이스 ID에 기초함 - 하는 단계; 및 복수의 에지 디바이스의 제 3 에지 디바이스로의 송신을 위해 제 2 에지 핸들 및 데이터 페이로드를 인코딩하는 단계를 포함한다. 제 2 예(예 B2)에서, 예 B1의 주제는, 소스 에지 디바이스가 데이터 페이로드의 통신을 개시하며, 및 데이터 흐 름 경로가 데이터 페이로드를 통신하는 데 사용되는 복수의 에지 디바이스의 서브세트를 나타내는 것을 포함한 다. 제 3 예(예 B3)에서, 예 B2의 주제는, 제 1 에지 디바이스의 하나 이상의 프로세서에 의해: 데이터 흐름 경로를 사용하여 복수의 에지 디바이스의 서브세트 내 각각의 에지 디바이스의 디바이스 ID를 결정하는 단계를 포함한 다. 제 4 예(예 B4)에서, 예 B3의 주제는, 제 1 에지 디바이스의 하나 이상의 프로세서에 의해: 결정된 디바이스 ID 및 디바이스 인증 룩업 테이블에 기초하여 데이터 흐름 경로에 포함되어 있는 복수의 에지 디바이스의 서브세트 를 인증하는 단계를 포함한다. 제 5 예(예 B5)에서, 예 B4의 주제는, 제 1 에지 디바이스의 하나 이상의 프로세서에 의해: 복수의 에지 디바이 스의 서브세트 중 적어도 하나의 에지 디바이스가 인증에 실패할 때 통지를 생성하는 단계를 포함한다. 제 6 예(예 B6)에서, 예 B4-B5의 주제는, 제 1 에지 디바이스의 하나 이상의 프로세서에 의해: 에지 컴퓨팅 네 트워크 내의 서비스 조정 엔티티로부터 디바이스 브로드캐스트 메시지를 디코딩하는 단계를 포함하며, 디바이스 브로드캐스트 메시지는 디바이스 인증 룩업 테이블을 업데이트한다. 제 7 예(예 B7)에서, 예 B6의 주제는, 디바이스 브로드캐스트 메시지가 에지 컴퓨팅 네트워크 내의 복수의 에지 디바이스 사이의 보안 통신을 위한 적어도 하나의 인증 키를 더 포함하는 것을 포함한다. 제 8 예(예 B8)에서, 예 B7의 주제는, 인코딩 및 디코딩은 적어도 하나의 인증 키에 기초하는 것을 포함한다. 제 9 예(예 B9)에서, 예 B6-B8의 주제는, 제 1 에지 디바이스의 하나 이상의 프로세서에 의해: 디바이스 브로드 캐스트 메시지 내의 클록 동기화 신호에 기초하여 제 1 에지 디바이스의 디바이스 클록을 동기화하는 단계를 포 함한다. 제 10 예(예 B10)에서, 예 B9의 주제는, 제 1 에지 디바이스의 하나 이상의 프로세서에 의해: 제 1 에지 디바이 스의 타임스탬프를 더 포함하도록 제 2 에지 핸들을 인코딩하는 단계를 포함하며, 타임스탬프는 데이터 페이로 드가 제 3 에지 디바이스로 송신되는 시간을 나타낸다. 제 11 예(예 B11)에서 예 B6-B10의 주제는, 서비스 조정 엔티티가 서비스 조정 엔티티의 가상화 인프라스트럭처 에서 인스턴스화된 MEC 애플리케이션으로서 컴퓨팅 서비스를 실행하는 다중 액세스 에지 컴퓨팅(MEC) 호스트인구성을 포함한다. 제 12 예(예 B12)에서, 예 B11의 주제는, MEC 호스트가 ETSI(European Telecommunications Standards Institute) MEC 표준 제품군의 표준에 따라 동작하도록 구성된 구성을 포함한다. 제 13 예(예 B13)에서, 예 B1-B12의 주제는, 에지 컴퓨팅 네트워크 내의 에지 서비스의 결과가 에지 서비스에 제공된 데이터 소스의 검증 가능한 증명 및 에지 서비스에 의해 생성된 데이터의 결과에 기초하여 증명될 수 있 도록 하는 구성을 포함한다. 다양한 설정에서, 예 B1-B13(및 이러한 추적 가능한 데이터 이동 유스 케이스의 다른 양태)은 데이터 추적 구성 의 사용을 정의하는 API 또는 사양; 데이터 추적 구성을 정의하거나 포함하는 프로토콜; 및 에지 컴퓨팅 환경 내에서 추적 가능한 데이터의 다른 사용 및 구현의 결과로서 관찰되거나 모니터링될 수 있다. 예 B1-B13 및 데 이터 추적의 다른 양태는 (예를 들어, FaaS 또는 EaaS 설정의 데이터 동작으로부터 호출되거나 동작되는) 서비 스 동작 및 서비스 기능에서 관찰되거나 구현된다. 또한, 예 B1-B13의 방법은 에지 컴퓨팅 시스템에서 (예를 들어, 명령어가 실행될 때 방법을 수행하는 머신 판독 가능 매체와 함께) 구현된 명령어로서 또는 (예를 들어, 방법을 수행하거나 달성하는 구성을 포함하는 장치와 함께) 구현된 하드웨어 구성으로서 제공될 수 있다. 따라 서, 예 B1-B13의 특징(및 추적 가능한 데이터 이동 관리의 다른 특징)은 시스템 오케스트레이터 또는 설계자에 의해 조정되거나 설계된 대로, 본 명세서의 임의의 다른 예와 결합되어 에지 클러스터 또는 에지 클라우드 시스 템을 구성할 수 있다. 전역적으로 공유된/구독 가능한 분산 에지 큐(distributed edge queue)의 예 다양한 형태의 처리 큐가 에지 컴퓨팅 플랫폼(예를 들어, 도 3 내지 도 22d에 도시된 에지 클라우드 및 에 지 컴퓨팅 시스템 구성) 내에서 사용되어 본 명세서에서 논의되는 오케스트레이션 및 서비스 동작을 조정하고 구성할 수 있다. 다양한 유형의 컴퓨팅 시스템은 실행될 작업 또는 기능을 저장하는 큐를 제공한다. 큐의 개 념은 다수의 에지 위치(예를 들어, 기지국 또는 다른 에지 게이트웨이 노드, 에지 집계 노드 등) 사 이에 공유되는 전역적인(예를 들어, 다중 에지 시스템) 큐 세트를 운영하는, 분산 에지 컴퓨팅 플랫폼에서 사용 하기 위해 확장될 수 있다. 예에서, 개별 큐는 상이한 에지 노드에 걸쳐 일관되게 보관되지만, 작업 정의(실행될 기능 또는 서비스, 페이로 드 및 잠재적으로는 데이터)는 요청이 제출된 에지 위치에 저장된다. 그런 다음, 에지 디바이스에 의해 서비스 요청 또는 기능이 요청되면, 디바이스가 연결된 에지 위치의 오케스트레이터가 실행될 작업을, 사용될 메타-데 이터(예를 들어, 작업 정의, 제출 에지 노드(submission edge node) 등)와 함께 큐에 (지속적으로) 추가할 것이다. 각각의 에지 위치에서 실행되는 상이한 오케스트레이션 엔티티는 로컬 에지 노드에서 실행될 작업을 고를 수 있다. 일단 작업이 수행되면, 작업(서비스 또는 FaaS)이 큐로부터 (지속적으로) 제거되고, 필요한 경우 데 이터 및 작업 정의가 이동되어 실행될 수 있다. 공유된 또는 구독 가능한 에지 큐의 사용은 분산 환경 내에서 워크로드 밸런싱의 관념에 도움을 줄 수 있다. 구조화된 방법이 큐의 사용을 위해 구상될 수 있는데, 여기서 로컬 큐의 세부 사항은 대응하는 오케스트레이터 (예를 들어, MEC 오케스트레이터, MEO)에게만 로컬로 알려지고, 큐 크기 만이 오케스트레이터(예를 들어, MEO) 사이에서 시간 간격을 두고 교환된다. 이러한 정보를 통해, 큐 오버플로우(및 동등하게는 작업 \"삭제(drop)\") 의 발생을 줄이려는 목표가 시도할 수 있다. 구독 가능하고 분산된 에지 큐의 다양한 디바이스 구현 예는 임의의 수의 에지 컴퓨팅 하드웨어, 회로, 노드 또 는 시스템 배열(예를 들어, 에지 클라우드 및 도 3 내지 도 22d에 도시된 에지 컴퓨팅 시스템 구성)에서 배치된 바와 같이, 서비스 오케스트레이션 및 실행 시스템 내에서 제공될 수 있다. 다양한 방법 예는 전역적으 로 액세스 가능한 큐로부터 정보를 추가, 조정 및 제거하고, 큐의 조정된 사용에 따라 작업(하나 이상의 서비스, 서비스 작용, 워크플로우 등)을 실행하는 것을 포함할 수 있다. 따라서, 에지 컴퓨팅 시스템 노드의 다양한 처리 회로에서 실행되는 방법은 에지 컴퓨팅 시스템 내에 공유 큐를 배치하고 사용하여 노드 사이에서 작업 및 기능의 오케스트레이션된 실행을 조정하는 것을 포함할 수 있다. 다양한 설정에서, 전역적으로 공유된 또는 구독 가능한 큐가 데이터 추적 구성의 사용을 정의하는 API 또는 사 양; 네트워크 내 트래픽 분석에 의한 관찰; 및 에지 컴퓨팅 환경 내의 큐 및 큐 데이터의 다른 용도 및 구현의 결과로서 관찰되거나 모니터링될 수 있다. 전역적으로 공유된 또는 구독 가능한 큐는 또한 (예를 들어, FaaS 또는 EaaS 설정의 서비스 사이에서 공유를 지원하는) 에지 컴퓨팅 시스템에서 서비스 동작 및 서비스 기능의 결 과로 호출되거나, 관찰되거나 또는 구현될 수 있다. 따라서, 전술한 예의 특징(및 분산 큐의 다른 특징)은, 시스템 오케스트레이터 또는 설계자에 의해 조정되거나 설계된 대로, 본 명세서의 임의의 다른 예와 결합되어 에 지 클러스터 또는 에지 클라우드 시스템을 구성할 수 있다. 자동적 에지 서비스 분산(Automatic Edge Service Distribution)의 예 위의 많은 예로 제안된 바와 같이, 에지 클라우드 아키텍처는 상이한 에지 협업 클러스터로 그룹화될 수 있는 다수의 에지(예를 들어, 소형 셀, 셀 타워 또는 상이한 집계 지점)로 구성된다. 예를 들어, 이들은 인프라스트 럭처 소유자에 의해 정의될 수 있다. 본 명세서 전체에서 설명된 일부의 다른 시스템 및 기술은 자원을 정의하 고, 검색하고, 보안 그룹화하여 다양한 목표를 달성하는 방법을 논의한다. 아래에서 논의되는 시스템 및 방법 은 이러한 그룹에 대한 서비스 분산을 제공할 수 있다. (예를 들어, 그룹 멤버에 걸쳐) 공통일 수 있는 속성 세트는 그룹 시맨틱을 설명하는 방법이다. 발견 프로세스는 협업 관련성을 결정하는 방법으로서 그룹의 속성을 쿼리하여 한 세트의 흥미로운 속성과의 겹침을 비교할 수 있다. 예에서, 속성은 상호운용 가능한, 의미적으로 풍부한 태그 집합으로서 캡처될 수 있다. 태그 네임스페이스(tag namespace)는 확장 가능하며, 협력 오케스트 레이션은 기술적으로는 상이하겠지만 의미적으로는 동일한 태그를 검출하는 데 사용될 수 있다. 태그는 또한 값을 가질 수 있다(예를 들어, CODEC은 태그일 수 있고 그 값은 지원되는 CODEC 알고리즘을 열거할 수 있다). 속성 태깅 아키텍처(attribute tagging architecture)는 다중 테넌트 협업 에지 아키텍처(예를 들어, 에지 클라 우드 및 도 3 내지 도 22d에 도시된 에지 컴퓨팅 시스템 구성)에 대해 확장 가능하다. 속성 태깅 아키텍 처는 빠른 전환 제공하고 (예를 들어, 자원이 실제로 필요한 때만 가능한 한 적게 사용되는 자원처럼) 총 소유 비용을 개선하는데 요구될 수 있는, 짧은 지연시간과 효율성을 제공하는 하드웨어를 사용하여 구현될 수 있다. 하드웨어 기반 구현은, 기지국에 에지 클라우드 솔루션이 배치되어 있을 때, 전력 및 열(thermal) 제한과 함께 제한된 공간에서 높은 컴퓨트 및 가속 밀도를 또한 제공할 수 있다. 전통적인 데이터 센터에 어울릴 수 있는 기존 솔루션은 이러한 환경에 어울리지 않는다. 그룹 아키텍처는 가속화된 기능 또는 기능 요청이 플랫폼에 의해 직접 처리되는 기존 플랫폼을 확장(또는 새로 운 플랫폼을 생성)할 수 있다. 따라서 소프트웨어가 필요하지 않을 수 있다. 이것은 유지 관리(많은 (예를 들 어, 10 만 개 이상의) 기지국이 배치되는 에지 시스템의 고려 사항) 더 적어지고, 컴퓨트 유효 밀도가 더 많아 지고(예를 들어, TCO가 더 나아지고), 또는 클라이언트로부터의 요청 처리를 가속화함으로써 응답 시간이 더 나 아지는 결과를 가져올 수 있다. 또한, 이러한 접근 방식은 워크로드 데이터가 또한 컴퓨터 자원에 오게 되므로 (예를 들어, 이동되고, 조정되고, 오케스트레이션되므로), 컴퓨트 자원을 워크로드 데이터에 가져다 주는(예를 들어, 이동하고, 조정하고, 오케스트레이션하는) 하나의 메커니즘을 제공할 수 있다. 에지 클라우드 아키텍처는 에지 네트워크 및 데이터 센터 아키텍처가 지금까지 가능하지 않았던 새로운 유스 케 이스를 실시 가능하게 할 기회를 가질 수 있는 잠재적 영역 중 하나로서 부상하고 있다. 이러한 컨텍스트에서, 도시된 바와 같이, 원격 통신 서비스 제공자(Telecommunication Service Provider)(TSP) 및 클라우드 서비스 제공자(Cloud Service Provider)(CSP)의 관련된 유스 케이스 중 하나는 서비스로서의 기능(FaaS)을 에지 디바이 스(예를 들어, 스마트폰 또는 IoT)에서 실행중인 애플리케이션에 노출(예를 들어, 이미지를 처리하고 물체를 반 환)하여 워크로드 및 애플리케이션을 가속화하는 것이다. 이러한 컨텍스트에서, (기능이 가속기에서 구현되고 실행되는 FaaS와 유사한) 서비스로서 가속 기능(Acceleration Functions as a Service)이 아래에서 설명되는 것처럼 사용될 수 있다. 위에서 에지 클라우드 배치의 개요에서 논의한 바와 같이, 낮은 지연시간을 노출하기 위해, FaaS 및 AFaaS(1- 10ms 지연시간) 가속기 및 컴퓨트가 (MEC 플랫폼 배열을 비롯하여) 기지국에 배치된다. 그러나 기지국에 프로 세서와 가속기를 배치하여 확장 가능한 에지 클라우드 FaaS 및 AFaaS를 구현하는 주요 도전과제 중 하나는 다음 과 같다: 물리적 공간 제한 사항; 클라이언트 요청/기능을 처리할 낮은 지연시간 및 확장 가능한 스케 줄링 솔루션; 높은 효과적인 컴퓨트 밀도 및 가속(시스템 소프트웨어 스택에 의한 것이 아닌 실제 컴퓨트에 사용되는 컴퓨트 및 가속). 본 명세서에서 설명된 시스템 및 방법은 CPE(고객 댁내 장비), 소형 셀 또는 셀 타워가 특정 서비스의 실행을 그 서비스의 QoS 또는 SLA를 유지하면서 활용도가 낮은 에지 아키텍처의 다른 에지로 넘길 수 있게 하는 (현재 시스템 및 아키텍처에 적용될 수 있는) 새로운 유형의 MEC 플랫폼 아키텍처를 포함한다. 도 28을 참조하면, 에지 아키텍처는 (예를 들어, 인프라스트럭처 소유자에 의해 정의될 수 있는) 상이한 에지 협업 클러스터로 그룹화된 다수의 에지(예를 들어, 소형 셀, 셀 타워 또는 상이한 통합 지점)로 구성된다. 클 러스터의 각각의 개인은 (예를 들어, 구성 가능한 간격으로) 다른 피어에게 브로드캐스트할 수 있다. 브로드캐스트는 상이한 유형의 자원(예를 들어, 스토리지, 메모리 등)의 현재 활용 또는 미래의 요구를 포함할 수 있다. 특정 에지 위치가 에지 디바이스(예를 들어, 스마트폰 또는 자동차)로부터 (예를 들면, 데드라인 및 자원 요구 사항 측면에서) 특정 서비스 레벨 협약을 맺은 주어진 서비스를 실행하라는 요청을 수신할 때, 특정 에지 위치는 요청을 또 다른 에지 위치로 포워딩할 것을 결정할 수 있다. 포워딩하는 결정은 (비 배타적인) 다음과 같은 요인 중 하나 이상에 기초할 수 있다. 또 다른 에지 위치는 (예를 들어, 지연시간에 있어서) 현재 에지로부터 다른 위치의 거리 및 가용 자원을 고려 하여 그 서비스를 실행할 수 있다. 현재 에지에서의 활용 또는 예상 활용. 예를 들어, 에지 위치는 에지 위치 로 들어오는 요청을 학습하고 예측하는 데 사용되는 소형 ML 또는 DL 훈련 컴퓨트 요소를 포함할 수 있다. 예 에서, 다른 위치를 선택하는 것은 상이한 방식(예를 들어, 라운드 로빈, 덜 활용되는 에지, 금전적 또는 자원 비용 고려 사항 등)을 사용하여 수행될 수 있다. 아키텍처는 포워더(forwarder)를 고르는 역할을 하고 각 인프 라스트럭처 소유자에 의해 구현될 수 있는 (예를 들어, FPGA에서 구현된) 프로그램 가능 로직 디바이스를 포함 할 수 있다. 포워딩 에지 아키텍처는 현재 기술에서 사용할 수 없는 한 세트의 새로운 서비스 및 비즈니스 유스 케이스를 포 함할 수 있다. 포워딩 에지 아키텍처는 매우 다양한 세그먼트 및 워크로드에 적용될 수 있다. 예를 들어, 도 20은 포워딩 에지 아키텍처에 적용될 수 있는 몇 가지 예를 도시한다. 도 28은 에지 서비스 분산을 위한 에지 컴퓨팅 아키텍처를 갖는 시스템 다이어그램을 보다 구체적으로 도 시한다. 도 28에 도시된 바와 같이, 아키텍처는 (예를 들어, 고객 댁내 장비, 과 같은 소형 셀, 과 같은 셀 타워 및 지역 중앙국과 같은 상이한 집계 지점으로부터의) 개별 에지 위치에서 (예를 들어, 로직 또는 코드를 통해 구현되는) 기능을 구현하는 명령어를 포함하고 실행할 수 있다. 명령어는 에지 게이트웨이 또는 플랫폼에서, 지능형 NIC(\"스마트 NIC\"라고도 함) 또는 임의의 다른 유형의 네트워크 카드를 통해 구현될 수 있는 엔티티에 제공될 수 있다. 이러한 기능은 아래에 설명된 것과 같은 요소 를 포함할 수 있다. 예에서, 기능은 값을 가질 수도 있는 상호운용 가능하고 의미적으로 풍부한 태그와 같은 태그 또는 태그들을 사용하여 적용될 수 있다. 기능은 인프라스트럭처 소유자가 동일한 협업 에지 클러스터에 속하는 하나 이상의 (또는 모든) 상이한 에지 피 어를 특정 에지에 등록할 수 있게 하는 새로운 대역 외 인터페이스 세트를 포함할 수 있다. 예에서, 에 지는 다수의 에지 클러스터에 속할 수 있다. 기능은 에지 피어 클러스터로 브로드캐스팅될 한 유형의 원격 측정 및 자원 활용 데이터를 포함하는 데이 터를 포함할 수 있다. 원격 측정은 각각의 에지 클러스터에서 상이할 수 있다. 기능은 에지가 원격 측정 및 자원 활용 데이터를 자신이 속한 에지 협업 클러스터로 브로드캐스트하는 빈도를 포함할 수 있다. 이러 한 원격 측정은 각각의 소유자, 테넌트 또는 서비스에 특유할 수 있다(또는 각각의 소유자, 테넌트 또는 서비스 사이에 공유될 수 있다). 기능은 (만일 있다면) 에지의 상이한 등록된 클러스터에서 상이한 에지 또는 에지들을 선택하는 역할을 하는 비 트 스트림(또는 가속 알고리즘이 구현되는 형태)을 포함할 수 있다. 등록된 클러스터는 서비스 요청이 존재하는 에지에 대응할 수 있다. 이러한 비트 스트림은 그러한 결정을 내리기 위해 원격 측정 데이터 테이블 에 액세스할 수 있다. 기능은 상이한 에지 피어로부터 오는 데이터를 저장하기 위한 원격 측정 데이터 구조를 포함할 수 있다. 예에 서, 데이터는 상이한 에지 협업 클러스터로 구성될 수 있다. 기능은 특정 에지에 도달하는 서비스 제출 유형에 대해 머신 학습을 사용하여 그 에지의 향후의 활용을 예측할 수 있다. 이러한 머신 학습 기술은 프로그램 가능 한 로직 디바이스에서도 구현될 수 있다. 기능은 개별 또는 다수의 에지 사용자, 테넌트 및 소유자로부터 오는 요청을 처리하는 역할을 할 수 있다. 요 청에는 실행될 서비스 또는 SLA 및 자원 요구 사항이 함께 따라올 수 있다. 요청은 전술한 비트-스트림에 의해 스케줄링될 수 있다. 예에서, 분산 원격 측정 데이터는 인프라스트럭처 소유자에 의해 구성된 원격 측정 데이 터 및 자원 활용을 수집하고 그 데이터가 등록된 상이한 클러스터에 그 데이터를 브로드캐스트하는 데 사용될 수 있다. 추가 예에서, 에지 서비스 분산을 위한 방법은 다음의 동작을 포함할 수 있다. 방법은 에지 클러스터에 속하는 제 1 에지 위치에서 요청을 수신하는 제 1 동작을 포함한다. 방법은 에지 클러스터의 제 2 에지 위치를 선택하 는 제 2 동작을 포함한다. 제 2 에지 위치를 선택하는 것은 제 2 에지 위치의 태그를 사용하는 것을 포함할 수있으며, 태그는 가용 자원 및 에지 클러스터에 있는 제 2 에지 위치의 멤버십을 표시한다. 방법은 제 1 에지 위치에서, 제 2 에지 위치의 가용 자원에 기초하여 에지 클러스터의 제 2 에지 위치에서 요청 이 실행 가능하다고 결정하는 제 3 동작을 포함한다. 예에서, 요청이 제 2 에지 위치에서 실행 가능하다고 결 정하는 것은 제 2 에지 위치에서 요청을 실행하는 것이 제 1 에지 위치에서 요청을 실행하는 것보다 더 적은 컴 퓨팅 자원을 필요로 하거나 더 적은 시간을 필요로 한다고 (예를 들어, 요청을 제 1 에지 위치보다 제 2 에지 위치에서 실행하는 것이 더 효율적이라고) 결정하는 것을 포함한다. 효율은 일정 기간 동안 제 1 에지 위치의 예측된 활용에 기초할 수 있거나 또는 제 2 에지 위치로부터 제 1 에지 위치까지의 거리에 기초할 수 있다. 효 율은 머신 학습 요소를 사용하여 결정되어 제 1 에지 위치로 오는 요청을 예측할 수 있다. 방법은 실행을 위해 요청을 제 2 에지 위치로 포워딩하는 제 4 동작을 제공한다. 방법은 제 1 에지 위치에서, 제 2 에지 위치로부터 원격 측정 및 자원 활용 데이터를 수신하는 단계를 더 포함할 수 있다. 에지 서비스 분산을 구현하기 위한 제 1 예시적인 방법(예 C1)은 처리 회로(예를 들어, 노드 또는 디바이스 (2200, 2232, 2240 또는 2250)의 처리 회로)를 사용하여 수행되는 방법으로서, 방법은, 에지 클러스터에 속하는 제 1 에지 위치에서 요청을 수신하는 단계; 제 1 에지 위치에서, 요청이 제 2 에지 위치의 가용 자원에 기초하 여 에지 클러스터의 제 2 에지 위치에서 실행 가능하다고 결정하는 단계; 및 실행을 위해 요청을 제 2 에지 위 치로 포워딩하는 단계를 포함한다. 제 2 예(예 C2)에서, 예 C1의 주제는, 제 2 에지 위치에서 요청을 실행하는 것이 제 1 에지 위치에서 요청을 실 행하는 것보다 더 적은 컴퓨팅 자원을 필요로 하거나 더 적은 시간을 필요로 한다고 결정함으로써 요청이 제 2 에지 위치에서 실행 가능하다고 결정하는 단계를 포함한다. 제 3 예(예 C3)에서, 예 C2의 주제는, 제 2 에지 위치에서 요청을 실행하는 것이 더 적은 컴퓨팅 자원을 필요로 하거나 더 적은 시간을 필요로 한다고 결정하는 것은 일정 기간 동안 제 1 에지 위치의 예측된 활용을 기초로 한다는 것을 포함한다. 제 4 예(예 C4)에서, 예 C2-C3의 주제는, 제 2 에지 위치에서 요청을 실행하는 것이 더 적은 컴퓨팅 자원을 필 요로 하거나 더 적은 시간을 필요로 한다고 결정하는 단계가 제 2 에지 위치로부터 제 1 에지 위치까지의 거리 에 기초하는 것을 포함한다. 제 5 예(예 C5)에서, 예 C2-C4의 주제는, 제 2 에지 위치에서 요청을 실행하는 것이 더 적은 컴퓨트 자원을 필 요로 하거나 더 적은 시간을 필요로 한다고 결정하는 단계가 머신 학습 요소를 사용하여 제 1 에지 위치로 오는 요청을 예측하는 단계를 포함하며, 여기서 머신 학습 요소는 이력 요청에 기초하여 훈련된다. 제 6 예(예 C6)에서, 예 C1-C5의 주제는, 제 2 에지 위치의 태그, 가용 자원을 표시하는 태그 및 에지 클러스터 의 제 2 에지 위치의 멤버십을 사용하여 제 2 에지 위치를 선택하는 단계를 포함한다. 제 7 예(예 C7)에서, 예 C1-C6의 주제는, 제 1 에지 위치에서, 제 2 에지 위치로부터 원격 측정 및 자원 활용 데이터를 수신하는 단계를 포함한다. 다양한 설정에서, 예 C1-C7(및 자동 에지 서비스 분산의 다른 양태)은 서비스 분산의 사용을 정의하는 API 또는 사양; 서비스 분산의 사용을 정의하거나 포함하는 프로토콜; 및 에지 컴퓨팅 환경 내 서비스의 다른 사용 및 구 현의 결과로서 관찰되거나 모니터링될 수 있다. 예 C1-C7 및 에지 서비스 분산의 다른 양태는 또한 (예를 들어, 조정된 서비스가 FaaS 또는 EaaS 설정에서 호출되거나 동작될 수 있도록 하는) 조정된 서비스 동작 및 서 비스 기능의 결과로서 관찰되거나 구현될 수 있다. 또한, 예 C1-C7의 방법은 에지 컴퓨팅 시스템에서 (예를 들 어, 명령어가 실행될 때 방법을 수행하는 머신 판독 가능 매체와 함께) 구현된 명령어로서 또는 (예를 들어, 방 법을 수행하거나 달성하는 구성을 포함하는 장치와 함께) 구현된 하드웨어 구성으로서 제공될 수 있다. 따라서, 예 C1-C7의 특징(및 자동 에지 서비스 분산의 다른 특징)은 시스템 오케스트레이터 또는 설계자에 의해 조정되거나 설계된 대로, 본 명세서의 임의의 다른 예와 결합되어 에지 클러스터 또는 에지 클라우드 시스템을 구성할 수 있다. 가속 실행 및 정의(Acceleration Execution and Definition)의 예 예에서, 에지 컴퓨팅 시나리오는 분산 컴퓨팅 환경 내에서 서비스 및 하드웨어에 대한 가속을 고려하고 동작하 도록 적응될 수 있다. 통상의 설정에서, 가속은 고정된 기능-가속기 매핑을 사용하여 전형적으로 로컬 머신 내 에 적용된다. 예를 들어, 통상의 접근 방식에 의하면, 특정 서비스 워크로드는 특정 가속기를 호출할 수 있고; (네트워크 액세스의 변경에 기초하여, 새로운 지연시간 조건을 충족하기 위해, 또는 다른 방식으로) 이러한 워크로드가 다른 위치로 마이그레이션하거나 전이해야 할 때, 워크로드는 재 구문 분석되고 잠재적으로 재 분석되 어야 할 수 있다. 에지 클라우드 아키텍처의 다음과 같은 적응(예를 들어, 에지 클라우드 및 도 3 내지 도 22d에 도시된 에 지 컴퓨팅 시스템 구성의 적응)은 상이한 호스트(예를 들어, 에지 컴퓨트 노드) 상에서 상이한 가속 기능을 조 정할 수 있도록 한다. 가속 워크로드를 직렬로 처리하는 대신, 병렬 분산 접근 방식이 워크로드와 기능 동작을 \"분할하고 극복\"하는데 사용된다. 이러한 병렬 분산 접근 방식은 동일한 또는 다수의 형태의 가속 하드웨어(예 를 들어, FPGA, GPU 어레이, AI 가속기) 및 동일한 또는 다수의 유형의 워크로드 및 호출된 기능의 사용 중에 적용될 수 있다. 가속 분산은 큰 데이터 청크(예를 들어, 10 GB 또는 디바이스 또는 네트워크 유형에 대해 약간 상당한 크기의 양)를 제공하는 워크로드에 따라 클라이언트 디바이스가 가속 기능을 실행하고자 하는 경우에 사용될 수 있다. 이러한 데이터 청크가 병렬 처리를 지원하면 - 데이터가 다수의 가속기를 병렬로 사용하여 실행되거나 분석될 수 있는 경우 - 가속 분산은 다수의 처리 노드 중에서 가속 결과를 배치하고 그로부터 가속 결과를 수집하는 데 사용될 수 있다. 다음과 같은 가속 분산 접근 방식은 또한, 워크로드를 보다 효율적으로 또는 시기 적절하게 이행하기 위해, 클라이언트 디바이스가 병렬로 실행될 수 있는 (예를 들어, 한 번에 100 개를 초과하는) 다수의 기능을 실행하고자 하는 경우에 사용될 수 있다. 클라이언트 디바이스는 주어진 SLA 및 주어진 자원 비용으로 실행될 데이터 및 워크로드 데이터를 전송한다. 워크로드는 다수의 처리 노드 중에서 분산되고, 조정되고 및 그로부터의 응답에서 수집되며, 각각의 처리 노드는 가속의 상이한 플레이버 또는 순열을 제공한다. 도 29는 에지 컴퓨팅 시스템 내에서 병렬로 데이터의 가속을 위한 아키텍처를 도시한다. 이 시스템에는 도시되지 않았지만, 특정 플레이버 구성을 식별하고 각각의 플레이버 서비스, FaaS 또는 다른 멤버십의 증명을 획득하며, 집계 증명 결과(예를 들어, \"플레이버 증명(flavor attestation)\")를 제공하는 데 사용되는 플레이버 게이트웨이가 존재할 수 있다. 추가 시나리오에서, 워크로드 오케스트레이터는 특정 플레이버 그룹의 워크로드 를 예약하는 전제 조건으로서 플레이버 증명을 요구할 수 있다. 추가 시나리오에서, 워크로드는 또한 병렬 에 지 배열에서 가속될 수 있다. 제 1 예에서, (SLA 또는 다른 서비스 접근 방식 하에서 동작하는) 워크로드 세트는 (예를 들어, 클라이언 트 모바일 디바이스에 제공될 때 에지 컴퓨팅 시스템에 의해 실행되는 서비스의 결과로서) 하나 이 상의 클라이언트 모바일 디바이스에 의해 에지 클라우드 내에서 처리하기 위해 제공된다. 이러한 워크로 드 세트는 에지 클라우드에 의한 실행을 위해 하나 이상의 가속 기능을 호출할 수 있다. 예를 들어, 워 크로드 세트는 제 1 워크로드 및 제 2 워크로드를 포함할 수 있다. 제 1 워크로드를 처리하는 데 필요한 가속은 제 1 서비스로서의 기능(FaaS-1)을 호출할 수 있고; 제 2 워크로드를 처리하는 데 필요한 가속은 제 2 서비스로서의 기능(FaaS-2)에 추가하여 제 1 서비스로서의 기능을 호출 할 수 있다. 워크로드 세트는 - N 개의 처리 노드가 동일하거나 상이한 가속 하드웨어 조합을 포함하므로 - N 개의 처 리 노드 사이에 병렬로 분산된다. 예를 들어, 제 1 노드가 제 1 기능의 실행을 지원하는 가속 하 드웨어(예를 들어, FPGA)를 포함하고, 반면에 제 2 노드 및 제 3 노드가 동일한 가속 하드웨어를 포함한다고 가정한다. 결과적으로, 이를테면 제 1 서비스로서의 기능에 의한 제 1 기능을 호출하는 요청 은 노드(2941, 2942, 2943) 중 제 1 기능으로 워크로드를 실행함으로써 이행될 수 있는 반면, 다른 기능은 노드 에서 실행될 수 있다. 예에서, 처리 노드 사이에 워크로드의 분산은 에지 게이트웨이, 오케스트레이터(도시되지 않음) 또는 다 른 중간 에지 클라우드 노드에 의해 조정될 수 있다. 예를 들어, 에지 게이트웨이는 데이터가 분산되어 야 하는 가속기의 수를 결정(또는 가속기에 의해 호출되는 기능을 결정)하고, 노드 또는 노드상의 가속기를 선 택하고, 데이터를 선택된 노드 및 가속기에 전송하는 역할을 할 수 있다. 가속기가 데이터의 처리를 완료하고 데이터를 반환할 때, 에지 게이트웨이는 감소 조항(reduction clause)을 적용(예를 들어, 모든 결과를 합 산)하거나 다른 처리를 수행할 수 있다. 페이로드를 제공하는 것 외에도, 클라이언트 디바이스는 또한 적용할 기능(또는 기능들) 및 감소 조항을 명시할 수 있다; 또는, 에지 게이트웨이는 기능(들) 및 감소 조항을 자동으로 식별할 수 있다. 워크로드는, 이를테면 다른 노드에 분산된 워크로드(제 2 기능(295 2))의 일부처럼, 에지 게이트웨이와 독립적으로 분산될 수 있다. 추가 예에서, 다수의 가속기 사이에 분산된 워크로드의 오케스트레이션 및 조정은 본 명세서에서 논의된 다른 기술을 사용하여, 로드 밸런싱, 모바일 액세스 예측 또는 원격 측정의 사용의 양태를 포함할 수 있다. 현재의또는 예측된 실행 상태에 기초하여 SLA/SLO를 충족할 가능성이 가장 높은 가속기가 선택되므로, 다수의 가속기 사이에 분산된 워크로드의 오케스트레이션 및 조정은 또한 SLA/SLO 기준 및 목표에 기초할 수 있다. 또한, 도 29의 환경에서, NIC는 LSM 또는 다른 보안 정책 시행 지점일 수 있다. 예를 들어 NIC는 제대로 구성 되지 않았거나, 바이러스를 포함하거나 또는 요구된 작용을 수행하지 않았으면, 노드가 네트워크에 액세스하지 못하게 할 수 있다. 이것은 산업용 네트워크 액세스 제어(Network Access Control)(NAC) 유스 케이스와 유사하 다. 또한, 이러한 설정에서, NIC가 정상적인 활동을 차단하면서 동시에 치료 트래픽을 가능하게 할 수 있으므 로, 오케스트레이터는 LSM 또는 다른 보안 정책을 NIC에 프로비저닝할 수 있다. 다양한 에지 시스템 구성에서, 가속 특징은 데이터 추상화된 가속 워크로드 설명(data-abstracted acceleration workload description)을 사용하여 더욱 향상될 수 있다. 이러한 가속 워크로드 설명은 XML과 같은 상위 레벨 포맷으로 정의된 균일한 워크로드 정의를 사용하여 에지 인프라스트럭처 내에서 실시 가능해질 수 있다. 이러 한 가속 워크로드 설명은 가속화된 자원으로의 균일한 액세스를 가능하게 하고, 에지 컴퓨팅 생태계의 상이한 노드 전체에서 가속의 향상된 사용을 가능하게 하는 데 활용될 수 있다. 예에서, 엔드포인트 디바이스가 인프라스트럭처의 상이한 에지 액세스 포인트 사이에서 이동할 때, 디바이스는 워크로드 정의를 에지 액세스 포인트에 제출하여 가속을 호출할 수 있다. 그러한 워크로드 정의는: 워크로드의 정의; 데이터 페이로드; 워크로드, 자원 비용 및 다른 파라미터에 대해 관련된 SLA/SLO의 표시를 포함할 수 있 다. 수신 에지 액세스 포인트(에지 컴퓨트 노드)는 적절한 가속기를 선택하고, 워크로드를 (가속기와 호환되는) 특정 비트스트림 정의로 변환하고, 워크로드를 실행한다. 가속 설명 접근 방식은 에지 컴퓨팅 시스템이 센서/액추에이터/제어기 노드가 공통 정보 모델 및 데이터 모델 (메타데이터)을 사용하여 설명된 표준화된 IoT 프레임워크(예를 들어, OCF(Open Connectivity Foundation), OPC(OLE Process Control), 사물-사물(Thing-Thing)) 내에서 제공되는 정의 이점을 활용할 수 있게 할 수 있다. 발견, 상호작용 및 결과 얻기의 동작은 또한 인터페이스 정의의 형태로 데이터 모델에 의해 캡처된다. 이러한 방식으로, 가속 자원이 있는 에지 인프라스트럭처가 유사하게 추상화할 수 있다. 이것은 최상위 계층이 아래 계층의 데이터 모델 추상화를 제시하는 \"계층적 서비스 계층\"의 형태를 제공한다. 그러나 IoT 프레임워크 추상화와 달리, 이러한 가속 정의는 \"서비스 호스팅\" 추상화를 제공한다. 서비스 호스팅은 호출될 서비스 또는 기능이 명시되지 않기 때문에 (예를 들어, UPNP와 같은 발견 접근 방식에 사용되는 것으로) \"서비스 제공자\" 추 상화와 상이하며; 오히려 가속 정의는 호스팅 환경 속성 및 제약 조건의 설명을 제공한다. 마지막으로, 가속 워크로드 설명의 사용은 환경의 보안 강화 속성이 발견 및 고려 사항을 위해 또한 노출되는 \"신뢰성 있는\" 호스팅 환경을 사용할 수 있도록 확장될 수 있다. 이것은 이를 테면 신뢰성 있는 (증명된) 가 속 자원의 선택을 통해, 에지 컴퓨팅 환경에서 증명을 사용할 수 있게 한다. 데이터 가상화된 가속을 구현하기 위한 제 1 예시적인 방법(예 D1)은 처리 회로(예를 들어, 노드 또는 디바이스 (2200, 2232, 2240 또는 2250)의 처리 회로)를 사용하여 수행되는 방법으로서, 방법은, 에지 게이트웨이 노드에 서, 가속 기능을 호출하는 워크로드를 수신하는 단계; 에지 게이트웨이 노드로부터 각각의 에지 컴퓨트 노드로, 각각의 에지 컴퓨트 노드의 가속 기능에 의한 병렬 실행을 위해 워크로드의 데이터를 분산하는 단계; 및 에지 게이트웨이 노드에서, 가속 기능에 의한 분산 실행의 결과를 수집하는 단계를 포함한다. 제 2 예(예 D2)에서, 예 D1의 주제는, 동일한 유형의 가속 기능이 각각의 에지 컴퓨트 노드의 가속 기능에 의해 사용되는 것을 포함한다. 제 3 예(예 D3)에서, 예 D2의 주제는, 워크로드가 또한 적어도 하나의 다른 에지 컴퓨트 노드에서 제 2 유형의 가속 기능에 의한 실행을 호출하는 것을 포함한다. 제 4 예(예 D4)에서, 예 D1-D3의 주제는, 각각의 에지 컴퓨트 노드의 가속 기능이 FPGA, ASIC, GPU 어레이, AI 가속기, 트랜스코딩 가속기, 또는 암호화 가속기 하드웨어 중 하나 이상에 의해 실행되는 것을 포함한다. 제 5 예(예 D5)에서 예 D1-D4의 주제는, 워크로드가 제 1 서비스로서의 기능을 호출하는 제 1 워크로드 및 제 2 서비스로서의 기능을 호출하는 제 2 워크로드를 포함하는 워크로드 세트인 것을 포함하며, 제 1 및 제 2 서비스 로서의 기능은 각각의 에지 컴퓨트 노드 사이에서 제공된다. 제 6 예(예 D6)에서 예 D1-D5의 주제는, 워크로드가 에지 클라이언트 노드로부터 수신되는 것을 포함한다. 제 7 예(예 D7)에서, 예 D6의 주제는, 에지 클라이언트 노드가 주어진 SLA 및 주어진 비용에 따라 실행될 워크 로드를 명시하는 것을 포함한다. 제 8 예(예 D8)에서, 예 D6-D7의 주제는, 에지 게이트웨이 노드로부터 에지 클라이언트 노드로, 가속 기능에 의 한 분산 실행의 수집된 결과를 제공하는 단계를 포함한다. 제 9 예(예 D9)에서, 예 D1-D8의 주제는, 에지 컴퓨팅 시스템 내의 가속 기능이 각각의 가속 워크로드 설명 내 에서 표시되는 구성을 포함한다. 다양한 설정에서, 예 D1-D9(및 가속 사용의 다른 양태)는 정의된 애플리케이션 프로그래밍 인터페이스 또는 인 터페이스 사양; 가속을 호출, 수신 또는 제어하는 프로토콜 또는 정의의 사용; 및 에지 컴퓨팅 환경 내에서 가 속의 다른 사용 및 구현의 결과로서 관찰되거나 모니터링될 수 있다. 예 D1-D9 및 가속 관리의 다른 양태는 또 한 (예를 들어, 가속 자원이 FaaS 또는 EaaS 설정 내의 서비스에서 호출되거나 동작되므로) 조정된 서비스 동작 및 서비스 기능의 결과로서 관찰되거나 구현될 수 있다. 또한, 예 D1-D9의 방법은 에지 컴퓨팅 시스템에서 (예 를 들어, 명령어가 실행될 때 방법을 수행하는 머신 판독 가능 매체와 함께) 구현된 명령어로서 또는 (예를 들 어, 방법을 수행하거나 달성하는 구성을 포함하는 장치와 함께) 구현된 하드웨어 구성으로서 제공될 수 있다. 따라서, 예 D1-D9의 특징(및 가속 관리의 다른 특징)은 시스템 오케스트레이터 또는 설계자에 의해 조정되거나 설계된 대로, 본 명세서의 임의의 다른 예와 결합되어 에지 클러스터 또는 에지 클라우드 시스템을 구성할 수 있다. 에지 디바이스 NIC 처리(Edge Device NIC Processing)의 예 다른 곳에서 언급한 바와 같이, 에지 컴퓨팅은 기지국, 셀 타워 등과 같이 사용자에게 더 가까이 있는 워크로드 를 처리하는 것을 말한다. - 스마트 시티, 스마트 교통 등과 같은 - 사물 인터넷(IoT) 디바이스가 많은 환경에 서, 인공 지능(AI) 추론은 점점 더 중요한 워크로드가 될 것이다. 이러한 추론 워크로드에서, 오케스트레이터 (예를 들어, 에지 게이트웨이)는 추론 요청을 다른 서비스 제공자 또는 인스턴스에 포워딩하여 추론을 수행할 수 있다. 따라서, 에지 오케스트레이터는 종종 요청을 지휘할 플랫폼을 선택하고 요청을 그 플랫폼에 전송할 것이다. 선택된 플랫폼(예를 들어, 그 플랫폼에서 실행되는 서비스)은 요청을 수신하고 처리하여 플랫폼을 반 환하는 결과를 생성한다. 여기에서, 오케스트레이터는 요청의 엔드-투-엔드 로드 밸런싱 및 추적을 제공한다. 그러나 에지 유스 케이스는 종종 매우 낮은 지연시간 처리 및 추론 허용 오차를 초래한다. 그러므로 로드 밸런 싱이 이러한 시간에 민감한 작업에 대한 차선책이 될 수 있으며, 이로 인해 하드웨어가 서비스 레벨 협약(SLA) 을 충족하기 위해 크기가 커질 수 있거나 또는 SLA가 누락될 수 있으므로 총 소유 비용(TCO)이 더 커질 수 있다. 이러한 시나리오는 추론 지연시간에 변동성이 있을 때 악화될 수 있다. 에지 워크로드의 실시간 추론 요구를 해결하기 위해, 하드웨어 지원 기술이 에지 컴퓨팅 시스템(예를 들어, 에 지 클라우드 및 도 3 내지 도 22d에 도시된 에지 컴퓨팅 시스템 구성)에서 사용되어 스마트 네트워크 인터 페이스 제어기(NIC)를 통한 오케스트레이터 로드 밸런싱 체계를 보완할 수 있다. 구체적으로, 이러한 지능형 NIC는 AI 서비스를 인식한다. 플랫폼의 NIC는 플랫폼에서 실행 중인 AI 서비스와 AI 서비스의 \"입력\"에 대응하 는 메모리 지역을 통지 받는다. AI 서비스 및 그 입력 메모리 버퍼는 서비스의 시작 중에 NIC에 등록되고 경량 데이터 구조(예를 들어, 테이블)로 유지된다. 또한, 플랫폼 NIC, 스위치 및 오케스트레이터 사이에서 동기화 프로토콜이 사용되어 플랫폼상의 AI 서비스 인식 NIC를 식별할 수 있다. 이러한 정보는 어떤 서비스 또는 모델 이 어떤 플랫폼에 배치되는지에 대한 글로벌 뷰를 구축하는 데 사용될 수 있다. AI 인식 NIC에 의하면, 플랫폼 지능형 NIC가 요청을 수신할 때, NIC는 더 빠른 처리를 위해 요청을 바로 서비스 제공자 또는 모델의 입력 메모 리 버퍼에 넣을 수 있다. 더욱이, 입력 메모리 버퍼의 크기를 측정하는 인터페이스를 이용하여, AI 인식 NIC는 또한 서비스에 의해 아직 처리할 입력의 양을 결정할 수 있다. 위에서 언급한 캐퍼빌리티는 여러 기술로 이어진다. 예를 들어, 오케스트레이터는 로드 밸런싱을 개선하기 위 해 플랫폼 NIC에 쿼리하여 서비스의 현재 입력 로드를 식별할 수 있다. 또한, 수신 플랫폼이 - 이를 테면 상이 한 공급 업체 또는 서비스 제공자로부터 - 실행 중인 AI 모델의 다수의 인스턴스를 가지고 있으면 그리고 (예를 들어, 보안 또는 용인된 공급 업체와 관련하여) 요청이 이들 중 하나에 매핑될 수 있으면, 오케스트레이터는 요 청을 간단히 플랫폼으로 포워딩하고 지능형 NIC는 입력 메모리 버퍼 상태에 기초하여 그 요청에 대해 적절한 (예를 들어, 최상의 매칭하는) 서비스 제공자를 선택할 수 있다. 이로 인해 시간을 절약하면서 오케스트레이터 의 미세 관리를 덜어주는 계층적 오케스트레이션이 가능해진다. MEC 설정에서, MEC 오케스트레이터(MEO)에 그 본질이 알려진 추론 작업에 관해서라면, MEO는 동일한 본질/문제/ 카테고리(예를 들어, 얼굴 인식)의 추론을 이미 수행한 MEC/에지 호스트에 작업을 위임하도록 선택할 수 있다.이렇게 하면, 추론 결과는 이미 작업의 \"심층 학습자(deep learner)\"인 호스트로부터 시작될 것이므로 더 많이 신뢰할 수 있을 것이다. AI 인식 또는 스마트 NIC는 랙 스위치와 함께 사용할 수 있다. 예를 들어, 랙 스위치는 랙에 의해 호스팅되는 플랫폼에서 실행되는 서비스의 목록을 획득할 수 있다. 이러한 스위치는 플랫폼 NIC에 쿼리하여 서비스 상태를 획득하는 것에 기초하여 또는 요청이 포워딩되고 반환되는 위치를 지속적으로 추적하는 것에 기초하여 목록을 사용하여 요청을 전송할 플랫폼을 식별할 수 있다. 예에서, 플랫폼 NIC는 요청을 수신할 때, 로컬 메모리 버퍼가 가득 차거나 과중하면 요청된 서비스 또는 모델을 실행하는 다른 플랫폼으로 요청을 포워딩할 수 있다. 이러한 특징은 오케스트레이터의 개입 없이 동적 로드 밸 런싱을 투명하게 실시 가능하게 한다. 예에서, 요청을 수락하는 플랫폼 NIC는 오케스트레이터에게 이전 중인 요청에 대해 알릴 수 있다. 예에서, 지능형 NIC는 시스템 원격 측정을 사용하여 예를 들어 현재 입력 버퍼 크기에 기초하여 요청을 처리하 는 데 얼마나 걸리는지를 예측할 수 있다. 그 다음에 이러한 예측은 예를 들어 전체 처리 지연시간을 줄이기 위해 여러 플랫폼 중 어떤 플랫폼으로 요청이 포워딩될 수 있을지를 결정하는 데 사용될 수 있다. AI 인식 NIC는 위에서 설명한 시나리오에서 표준 NIC에 여러 이점을 제공한다. 예를 들어, 오케스트레이션 및 로드 밸런싱 오버헤드가 감소한다. 이것은 에지에 배치되는 IoT 디바이스 및 서비스의 증가로 인해 이러한 오 버헤드가 중요해질 수 있으므로 중요할 수 있다. 도 30은 개선된 에지 클라우드 추론 처리를 위한 컴포넌트를 포함하는 에지 컴퓨팅 아키텍처의 예를 도시 한다. 도시된 바와 같이, 에지 게이트웨이는 서버 랙과 통신한다. 에지 게이트웨이는 (서 버 랙과 같은) 서버 노드 사이에서 동작 또는 구성을 오케스트레이션하도록 구성된 오케스트레이터(301 0)를 포함할 수 있으며, 인증 로직 및 이러한 동작 또는 구성을 지원하는 로드 밸런싱 로직을 실행 하도록 구성될 수 있다. 서버 랙은 상단 스위치(예를 들어, 랙 백 플레인(rack back plane) 또는 랙 내(inter-rack) 스위치 패브릭) 및 서버와 같은 하나 이상의 서버(예를 들어, 블레이드)를 포함한다. 상단 스위치는 서버의 지능형 NIC에서 존재하는 세 개의 컴포넌트: 서비스 레지스트리, 로드 밸런싱 컴포넌트 및 예측 컴포넌트를 포함한다. 다른 예에서, 스위치는 다른 (상단이 아닌) 위치에 위치할 수 있다. 서비스 레지스트리는 (예를 들어, 랙의) 서버 및 다른 노드상에 있을 때 현재 노드에서 실행 중인 서비스의 매핑을 유지하도록 배열된 회로이다. 서비스 레지스트리는 서버상의 플랫폼이 AI 서비스를 서버에 등록 및 등록 해제할 수 있는 인터페이스(도시되지 않음)를 포함한다. 등록 및 등록 해 제는, 다른 것 중에서도, (예를 들어, 에지 게이트웨이 상의) 오케스트레이터, 오케스트레이터 의 일부인 플랫폼상의 로컬 데몬(local demon), 플랫폼의 워치독 로컬 데몬(watchdog local demon), 또 는 AI 서비스 자체에 의해 개시될 수 있다. 예에서, 서비스 레지스트리는 (예를 들어, 다른 노드로부터 의 NIC 상의) 다른 서비스 레지스트리로부터 온 브로드캐스트를 시작하거나 수신하여 서비스 매핑을 업데이트하 도록 배열된다. 로드 밸런싱 컴포넌트는 AI 서비스로의 입력을 수신하고 그 입력을 대응하는 서비스의 입력 메모리 버퍼 로 송신하도록 배열된 회로이다. 로드 밸런싱 컴포넌트는 수신된 입력을 AI 서비스의 메모리 버퍼에 추 가할지 또는 다른 노드상의 AI 서비스의 다른 인스턴스로 송신할지를 결정하도록 배열된다. 이러한 결정은 현 재 메모리 버퍼의 상태 또는 예측 컴포넌트로부터의 입력과 같은 정책에 기초할 수 있다. 예에서, 로드 밸런싱 컴포넌트는 오케스트레이터로부터 입력 메모리 버퍼의 현재 상태에 관한 쿼리에 응답하도록 배열된다. 예측 컴포넌트는 시스템 원격 측정 및 선택적으로는 머신 학습을 사용하여 입력이 AI 서비스에 의해 처리 될 수 있는 시기를 이해하고 예측하도록 배열된 회로이다. 이를 위해, 예측 컴포넌트는 입력 메모리 버 퍼 상태를 모니터링하도록 배열된다. 이것은 입력으로서 머신 학습 시스템으로 제공되어 대략적인 처리 시간의 추정치를 제공한다. 이러한 출력은 로드 밸런싱 컴포넌트에 의해 서비스로의 입력이 수락되어야 하는지 또는 다른 노드로 포워딩되어야 하는지를 결정할 때 사용될 수 있다. 추가 예에서, 더 나은 예측을 수행하기 위해 상이한 에지 노드로부터의 메타 데이터가 사용될 수 있다. 예를 들어, 서비스 및 흐름에 의해 실행되는 최근의 요청은 예측 체계에 대한 글로벌 뷰를 제공하고 개선하는 데 사용될 수 있다. 또한, NIC의 포워더 컴포 넌트(또는 포워딩 기능성)는 보안 정책이 포워딩 동작을 제한하여 발병 병리학을 늦추거나 '형성'하는 LSM 또는다른 보안 정책 시행 지점일 수 있다. 추가 예에서, 에지 컴퓨팅 시스템 내에서 오케스트레이션의 적용은 네트워킹 디바이스 및 네트워크 어댑터 내의 고급 형태의 로직 및 프로그래밍에 의해 촉진되어, 네트워크 어댑터 및 다양한 형태의 물리적 기능 오프로드에 대한 소프트웨어 프로그램된 제어(software programmed control)를 가능하게 할 수 있다. 예를 들어, 이러한 네트워킹 디바이스 및 어댑터는 VNF 구성, 플랫폼 네트워크 장비 또는 다른 네트워크 동작 양태에 대해 만들어 진 변경 또는 업그레이드에 기초하여 네트워크 사업자로부터 프로그래밍을 수신하는 업그레이드 또는 변경 메커 니즘을 포함할 수 있다. 예에서, 그러한 프로그래밍은 소프트웨어 프로그램된(software-programmed) 단일 루트 입력/출력 가상화(single root input/output virtualization)(SR-IOV)를 사용하여 제공될 수 있다. SR-IOV는 (예를 들어, 본 문서 전체 에서 논의된) 다양한 에지 컴퓨팅 오케스트레이션 활동을 네트워크 동작과 조정될 수 있게 하는 가상 기능 (Virtual Function) 및 물리적 기능(Physical Function)을 수정하는 메커니즘을 제공할 수 있다. 이러한 가상 기능과 물리적 기능 사이의 통신 메커니즘은 디바이스에 따라 다르기 때문에, 각각의 네트워크 장비에서 SR-IOV 의 사용은 특정 디바이스와 에지 컴퓨트 및 네트워킹 배열 내에서 네트워크 처리를 고객 맞춤 제작할 수 있게 한다. NIC, 스위치 또는 다른 네트워킹 하드웨어 내에서 새로운 제어 특징을 실시 가능하게 하기 위해 적용 가능한 네 트워크 하드웨어의 SR-IOV 제어는 표준화되거나 조정될 수 있다. 이러한 제어는 예를 들어, 오케스트레이터 에 의해 즉석에서 수행될 수 있다. 또한, SR-IOV 제어 및 변경의 사용은, 이를테면 VNF가 임계적인 구성 이 네트워크 장비(예를 들어, NIC)에서 구현되게 해야 하는 새로운 다중 테넌트 VNF 시나리오를 실시 가능하게 할 수 있다. 이러한 구성 변경은 가상 기능의 권한이 낮은 시나리오에서 필요할 수 있으며, 적절한 서비스 동 작을 보장하기 위해 물리적 기능이 호출되어야 한다. SR-IOV 제어의 다양한 디바이스 예는 임의의 수의 에지 컴퓨팅 하드웨어, 회로, 노드 또는 시스템 배열에 배치 되는 것처럼, 네트워킹 하드웨어 내에 제공될 수 있다. 다양한 방법의 예는 네트워킹 하드웨어에 대한 SR-IOV 소프트웨어 변경에 기초한 가상적 및 물리적 네트워크 기능 사이의 변경을 비롯하여, 네트워킹 기능 변경에 기 초하여 에지 컴퓨팅 시스템 내에서 오케스트레이션을 수행하는 것을 포함할 수 있다. 에지 디바이스 NIC 처리를 구현하기 위한 제 1 예시적인 방법(예 E1)은 (예를 들어, 노드 또는 디바이스(2200, 2232, 2240 또는 2250)의) 처리 회로를 사용하여 수행되는 방법으로서, 방법은, 에지 컴퓨팅 시스템의 노드의 네트워크 인터페이스 제어기(NIC)의 호스트 대면 인터페이스(host facing interface)에서, 노드에서 이용 가능 한 인공 지능(AI) 서비스의 등록을 수신 - 등록은 서비스로의 입력을 위한 메모리 영역을 포함함 - 하는 단계; NIC의 네트워크 대면 인터페이스에서, NIC에서 AI 서비스에 대한 요청을 수신하는 단계; 및 요청으로부터의 입 력 데이터를 메모리 영역에 배치하는 단계를 포함한다. 제 2 예(예 E2)에서, 예 E1의 주제는, AI 서비스를 호출함으로써 요청으로부터의 입력 데이터를 메모리 영역에 배치하는 단계를 포함한다. 제 3 예(예 E3)에서, 예 E1-E2의 주제는, NIC에의해, 다른 노드의 다른 NIC로부터 서비스의 카탈로그를 요청하 는 단계; 및 NIC에 의해, 제 2 노드에서 AI 서비스의 다른 인스턴스를 기록하는 단계를 포함한다. 제 4 예(예 E4)에서, 예 E3의 주제는, 네트워크 대면 인터페이스에서의 NIC에 의해, AI 서비스에 대한 제 2 요 청을 수신하는 단계; 및 처리를 위해 제 2 요청을 제 2 노드로 포워딩하는 단계를 포함한다. 제 5 예(예 E5)에서, 예 E4의 주제는, 제 2 요청이 제 2 노드에서 요청의 예측 완료 시간에 기초하여 제 2 노드 로 포워딩되는 것을 포함한다. 제 6 예(예 E6)에서, 예 E1-E5의 주제는, 에지 컴퓨팅 시스템 내에서의 오케스트레이션이 네트워크 내 단일 루 트 입력/출력 가상화(SR-IOV)로 인해 야기된 네트워킹 기능 변경을 사용하여 구현되는 구성을 포함하며, 네트워 킹 기능 변경은 가상적 및 물리적 네트워크 기능 사이의 변경을 포함한다. 다른 예에서, (예 E1-E6 중 임의의 예를 비롯한) SR-IOV에 대해 위에서 논의된 기술은 다중 루트 IOV 설정(MR- IOV)에 적용될 수 있다. 다양한 설정에서, 예 E1-E6(및 NIC 처리의 다른 양태)은 정의된 애플리케이션 프로그래밍 인터페이스, 인터페이 스 또는 하드웨어 사양; IOV 또는 NIC 동작을 호출, 수신 또는 제어할 프로토콜 또는 정의의 사용; 서비스 및 서비스 인터페이스의 사용; 및 에지 컴퓨팅 환경 내에서 IOV 및 NIC의 다른 사용 및 구현의 결과로서 관찰되거나 모니터링될 수 있다. 또한, 예 E1-E6의 방법은 에지 컴퓨팅 시스템에서 (예를 들어, 명령어가 실행될 때 방 법을 수행하는 머신 판독 가능 매체와 함께) 구현된 명령어로서 또는 (예를 들어, 방법을 수행하거나 달성하는 구성을 포함하는 장치와 함께) 구현된 하드웨어 구성으로서 제공될 수 있다. 따라서, 예 E1-E6의 특징(및 지능 형 NIC 처리의 다른 특징)은 또는 설계자와 같은 시스템 오케스트레이터에 의해 조정되거나 설계된 대로, 본 명세서의 임의의 다른 예와 결합되어 에지 클러스터 또는 에지 클라우드 시스템을 구성할 수 있다. 글로벌 서비스 페이지 테이블(Global Service Page Table)의 예 데이터가 특정 서비스 또는 상이한 서비스를 소유한 테넌트마다 다수의 에지 위치에 걸쳐 분산되어 게시되는 분 산 아키텍처의 도전과제 중 하나는 이러한 서비스 세트가 특정 데이터 세트에 대해 갖는 권한을 관리하는 방법 이다. 데이터 세트의 이러한 세트는 데이터 레이크(data lake)(예를 들어, 구조화된 데이터 및 비 구조화된 데 이터의 대규모 스토어)로 알려진 곳에 저장될 수 있다. 예에서, 새로운 하드웨어 방법은 페이지 테이블(page table) 개념을 사용하여 (메모리에) 효율적이고 낮은 지연시간 데이터 분산 및 디바이스로의 액세스를 가능하게 한다. 기존의 솔루션은 분산된 저장을 위한 소프트웨어 스택에 기초한다. 이 경우 소프트웨어 스택은 서비스로부터 가상 어드레스 공간, 물리적 위치로의 변환 액세스를 수행하고 이러한 서비스가 그 특정 데이터 세트에 대해 갖 는 허가를 체크한다. 확장성은 소프트웨어 스택 사용의 주요한 제한 사항이다. 유사한 문제가 테넌트 및 디바 이스에 대한 서비스에서도 발생한다. 본 명세서에서 설명된 에지 컴퓨팅 시스템(예를 들어, 에지 클라우드 및 도 3 내지 도 22d에 도시된 에지 컴퓨팅 시스템 구성)은 에지 페이지 테이블의 구현으로 확장된다. 에지 페이지 테이블은 어떤 서비스가 어떤 데이터에 액세스할 수 있는지, 서비스로부터의 가상 어드레스가 어떻게 물리적 어드레스에 매핑되는지, 어드레 스 또는 데이터에 대한 허가가 무엇인지를 추적하는 데 사용된다. 예에서, 페이지 테이블은 서비스가 인스턴스 화되거나 또는 다수의 에지 위치에 걸쳐 마이그레이션될 수 있게 할 수 있다. 에지 페이지 테이블은 (테넌트, 서비스 또는 사용자 기반 데이터 암호화를 사용하여 페이지 테이블의 상이한 영역을 보호함으로써, 이것을 포함 하여) 엔드포인트 디바이스상의 보안 또는 테넌트 격리를 개선할 수 있다. 또한, 에지 페이지 테이블은 \"글로 벌\" 또는 전체 시스템/다중 시스템 기반으로 제공되어, 테넌트 특정 자원 컨텍스트 스위칭의 성능을 개선할 수 있다. 도 31은 에지 서비스 페이지 테이블을 구현하기 위한 시스템을 도시한다. 일부 예에서, 에지 서비 스 페이지 테이블은 에지 클라우드와 함께, 메모리 및 스토리지 제어기를 통해 (예를 들어, 디바이스를 비롯한) 에지 클라우드의 상이한 에지 노드 및 서비스에 걸쳐 메모리 페이지를 관 리하는 데 사용될 수 있다. 이러한 메모리 페이지는 다양한 또는 설정된 크기(예를 들어, 1 GB)를 가질 수 있 다. 예를 들어, 컴퓨트 디바이스 또는 에지 컴퓨팅 디바이스는 에지 디바이스에 의해 사용하기 위 한 데이터, 서비스 또는 다른 자원을 에지 클라우드에 저장할 수 있으며, 데이터, 서비스 또는 다른 자원 은 시스템 전체(\"글로벌\") 서비스 페이지 테이블을 사용하여 관리될 수 있다. 글로벌 서비스 페이지 테이블은 컴퓨트 디바이스 또는 에지 컴퓨팅 디바이스 및 에지 클라우드의 다른 위치에 (또는 코어 데 이터 센터에 액세스 가능한 분산 데이터베이스에서 구현되는 것과 같이, 에지 자원 노드와 같은 컴 퓨트 자원에) 저장될 수 있다. 예에서, 글로벌 서비스 페이지 테이블은 코어 데이터 센터의 디바이스 또 는 에지 클라우드의 디바이스(예를 들어, 클라우드 데이터 센터의 서버)에 저장될 수 있다. 페이지 테이블은 플랫폼 또는 CPU 레벨에서, 특정 메모리 페이지(예를 들어, )에 액세스하는 애플 리케이션의 권한을 식별하기 위해 사용된다. 페이지 테이블(또는 유사한 구조)은 에지 컨텍스트에서, 어떤 에 지 자원 또는 서비스가 주어진 사용자 또는 테넌트에 액세스할 수 있는지를 추적하는 데 사용될 수 있다. 각각 의 에지 위치는 (예를 들어, 포인터에서 시작하는) 다음과 같은 계층을 가진 트리 기반 구조를 가질 수 있다. 트리의 루트 ==> 서비스의 목록 ==> 제공자의 목록 ==> 서비스를 실행할 특권을 갖는 테넌트 또는 디바 이스의 목록. 추가 예에서, 제공자의 목록은 제공자에게 이용 가능한 워크로드를 강화하기 위한 구성 옵션을 포함할 수 있다. (예를 들어, VM, 보안(예를 들어, SGX) 엔클레이브, VM+Enclave, 컨테이너, 컨테이너 +엔클레 이브, VMM, VMM+엔클레이브, OS, FPGA, FPGA+AFU 등). 또한, Intel SGX(Software Guard Extensions) 또는 유 사한 기술(예를 들어, x86, ARM 또는 다른 아키텍처에 적용할 수 있는 다른 신뢰성 있는 실행 또는 신뢰성 있는 컴퓨팅 기술)을 포함하는 워크로드 조합이 강화된 보안 환경을 사용하여 예상된 조합을 체크하고 시행할 수 있 다. 신뢰성 있는 실행, CPU 또는 플랫폼 하드웨어의 다양한 적응 또는 수정이 어드레스 공간을 관리할 수 있도 록 활용될 수 있다.예에서, 페이지를 추적하기 위한 트리는 하드웨어 엔티티(예를 들어, FPGA)에 의해 관리되는 가상 트리일 수 있 다. 테넌트가 주어진 에지 서비스 제공자로부터의 서비스 A를 실행하고 싶을 때, 테넌트는 주어진 테넌트 자원, 디바이스, 스토리지, 컴퓨트의 유닛 또는 통신/네트워크의 유닛이 위치한 허가를 담은 리프(leaf)에 도달 할 때까지 트리 계층 구조를 탐색할 수 있다. 예에서, 자원(예를 들어, 이것은 가용 SLA 등과 같은 한 유형의 메타데이터를 포함할 수 있음)을 포함할 수 있는 테넌트 자원에 대해 프론트 엔드인 서비스가 있다. (PT의 프 로세스와 유사하게), 세 계층 중 임의의 계층에서 변환 참조 버퍼(translation lookaside buffer)(TLB) 룩업 미스가 있는 경우, (예를 들어, 네트워크의 중앙국 또는 코어와 함께) 점진적으로 중앙집중화된 저장소를 타겟으로 삼아 페이지 검색(page walk)이 수행되어 그 사용자에 대한 그 서비스(예를 들어, 서비스)의 특 정 허가를 검색할 수 있다. 예에서, 자원 할당도 수행될 수 있다. 페이지 테이블을 예로 사용하면, 페이지 테이블을 가지는 것은 다음의 세 가지 것: 합법적 어드레스와 불법적 어드레스 간의 차이(예를 들어, 유효성 결함 대 세그먼트 오류), 액세스 제어(예를 들어, R/W 및 PKEY와 같은 다른 비트) 및 필요할 때 이용 가능한 자원의 물질화 또는 생성(예를 들어, 결함 처리)을 포함할 수 있다. 세가지 모두 자원 관리 측면에서 유사점이 있는데, 예를 들어, 서비스는 특정 자원을 거부하고 다른 자원으로의 잠재적 액세스를 허용할 수 있고, 서비스는 실제로 서 비스가 액세스할 수 있는 자원의 다양한 부분을 제공할 수 있고, 따라서 이러한 다단계 검색의 탐색 또한 제어 지점이 될 수 있으며, 서비스는 실제로 필요할 때만 자원을 제공받을 수 있다. 이러한 접근 방식은 테넌트 액세스 특권이 코어 데이터 센터에 루트 캐시를 배치하고 기지국 또는 온-프레미스 에지 노드에서뿐만 아니라 그 사이의 지점에서 다수의 복사본을 배치하는 체계에 따라 계층적으로 캐시될 수 있 다는 점에서 (LDAP와 같은) 중앙집중화된 디렉터리 접근 방식과 상이하다. 테넌트 SLA/SLO 및 오케스트레이션 컨텍스트는 예상 위치, 협업 또는 워크로드에 기초하여 사전에 캐시를 예열 할 수 있다. 캐시에 대한 빈번한 히트는 후속 요청을 위해 캐시된 콘텐츠를 '웜 상태(warm)로' 유지한다. 엔드포인트 디바이스, 호스트 또는 서비스는 로컬 스토리지 자원을 사용하여 캐싱 체계에 참여할 수 있다. 예 를 들어, 로컬 액세스 요청은 로컬 플랫폼을 떠날 필요가 없다(이것은 네트워크 지연시간이 수반될 수 있다). 예에서, 액세스 컨텍스트는 특정 테넌트에 할당된 자원 세트 내에서 캐시될 수 있다. 예를 들어, 플랫폼이 메 모리 암호화(예를 들어, 인텔® MKTME™)를 지원하면, 암호화 사용자 키 자원은 그렇지 않았더라면 TLB 캐시 에 의해 캐시된 키를 간직하는 데 사용될 수 있다. 다른 테넌트 특정 자원 격리 체계가 플랫폼 별 또는 서비스 별 기준으로 적용될 수 있다. 예를 들어, 영구 스토리지, 기능 가속, CPU 할당, 메모리 파티셔닝, 가상 화, 주변 친화도 또는 IoT 디바이스 네트워크 파티셔닝은 테넌트 특정 파티셔닝 캐퍼빌리티를 가질 수 있다. 키의 해지 또는 추가 자원에 액세스하는 허가의 추가와 같은 액세스 정책에 대한 변경은 캐시된 컨텍스트가 오 래되었기 때문에 특권 상승 또는 서비스 거부에 취약할 수 있다. 시스템은 게시-구독 또는 정보 중심 네 트워킹(ICN) 구성을 사용하여 캐시가 테넌트 특정 컨텍스트 토픽의 구독자가 되는 정책에 기초하여 자원의 업데 이트가 캐시된 모든 복사본에 동시에 균일하게 적용될 수 있도록 한다. 예에서, 웜 캐시(warm cache)는 국부적 으로 발생하는 자원 액세스 요청에 대해 적시에 업데이트하도록 보장하는 높은 QoS 요구 사항으로 구독한다. 새로운 데이터 또는 새로운 디바이스가 에지 데이터-레이크에 추가될 때, 에지 서비스(예를 들어, 컴퓨트 를 사용하여 동작하는 서비스)에 대한 특정 액세스 제한이 적용될 수 있다. 이 정보는 데이터 또 는 디바이스의 동일한 데이터-레이크에 참여하는 에지 또는 에지들에게 멀티캐스트될 수 있다. 기존 데이터 또 는 디바이스에 관한 변경은 또 다른 에지 또는 데이터 또는 디바이스를 공유하는 다른 에지에게 멀티캐스트될 수 있다. 예에서, 특정 에지 위치(예를 들어, 시스템의 @X 위치)가 데이터 또는 특정 에지 디바이스 내 에서 호스팅되는 기능에 할당될 수 있다. 에지 TLB는 대응하는 서비스가 디바이스 또는 에지 디바 이스 내의 데이터 또는 위치에 액세스하는 권한이 있는지를 체크할 수 있다. 도 32는 에지 글로벌 서비스 페이지 테이블(edge global service page table)의 구현을 도시한다. 에지 글로벌 서비스 페이지 테이블은 가상 어드레스 및 대응하는 물리적 어드레스를 도시한다. 에지 글로벌 서비스 페이지 테이블의 물리적 어드레스는 에지 디바이스 및 그 특정 에지 디바이스 상의 메모리의 물리적 어드레스를 포함할 수 있다. 에지 글로벌 서비스 페이지 테이블은 로컬 메모리 어드레스 및 원격 메모리 어드레스를 둘 모두 포함한다. 에지 글로벌 서비스 페이지 테이블이 메모리 어드레스가 (예를 들어, 서비스를 운영하거나 테 넌트를 호스팅하는 에지 디바이스에) 로컬이 아니라고 표시할 때, 에지 글로벌 서비스 페이지 테이블은판독을 원격 네트워크 인터페이스로 전송하여 원격 디바이스의 원격 메모리 액세스를 획득할 수 있다. 원격 메 모리 액세스가 승인되는 것에 응답하여, 디바이스는 물리적 어드레스 또는 기입 액세스(write access)의 위치를 제공 받을 수 있다. 추가 예에서, 원격 노드가 다운되면, 요청이 다른 복제본에 전송되고, 그렇지 않았더라면 SW 스택에 오류가 발생되므로, 시스템은 (페이지 테이블에 포함된 데이터에 기초하여) 탄력성을 구현할 그 서비 스의 복제본을 포함할 수 있다. 예에서, 디바이스에 의한 보안 요구 사항과 같은 다른 속성이 원격 액세스 중에 고려될 수 있다. 이 예에서, 원래 플랫폼으로 다시 전송하려면 보안 방식으로 전송해야 할 수 있다. 다른 예시적인 속성은 (예를 들어, 원 격 메모리 데이터가 안전할 때) 원격 메모리의 인증 정보를 참조하는 것과 같이, 여벌의 데이터를 요청에 추가 해야 할 수 있다. 액세스 정책은 얼마나 많은 대역폭을 할당할지 또는 얼마나 많은 지연시간이 필요할지를 표 시하는 특성을 가진 메타데이터를 가질 수 있다. 원격 데이터가 로컬 노드에 반환될 때, 이러한 특성이 요구될 수 있다. 추가 예에서, 에지 글로벌 서비스 페이지 테이블을 구현하기 위한 방법은 (예를 들어, 노드 또는 디바이스 (2200, 2232, 2240 또는 2250)에서 또는 이에 의해 구현되는 것과 같은) 다음의 동작에 따라 구현될 수 있다. 방법은 가상 어드레스를 복수의 에지 노드상의 물리적 어드레스에 매핑하도록 구성된 에지 글로벌 서비스 페이지 테이블을 유지하는 제 1 동작을 포함한다. 방법은 에지 글로벌 서비스 페이지 테이블에서 유지 되는 가상 메모리 어드레스로의 액세스 요청을 수신하는 제 2 동작을 포함한다. 예에서, 가상 메모리 어드레스 는 에지 서비스에 대응한다. 방법은 물리적 어드레스 및 가상 메모리 어드레스와 연관된 에 지 노드를 식별하는 제 3 동작을 포함한다. 예에서, 에지 노드는 요청을 개시하는 로컬 노드로부터의 원격 에 지 노드이다. 방법은 에지 노드상의 물리적 어드레스에 대응하는 자원으로의 액세스를 제공하는 동작으 로 마무리된다. 예에서, 자원은 에지 노드상의 물리적 어드레스에 저장된 데이터, 에지 노드상의 물리적 어드 레스에서 동작하는 서비스, 또는 에지 노드상의 물리적 어드레스의 위치를 포함할 수 있다. 에지 서비스 페이지 테이블을 구현하기 위한 제 1 예(예 F1)는 디바이스로서, 처리 회로; 및 명령어가 구현되는 메모리를 포함하며, 여기서 명령어는, 처리 회로에 의해 실행될 때, 처리 회로가 에지 디바이스상의 자원을 관 리하기 위한 동작을 수행하도록 구성하며, 동작은, 가상 어드레스를 물리적 어드레스에 매핑하도록 구성된 에지 글로벌 서비스 페이지 테이블을 유지하는 것; 에지 글로벌 서비스 페이지 테이블에서 유지되는 가상 메모리 어 드레스의 자원으로의 액세스 요청을 수신하는 것; 물리적 어드레스 및 가상 메모리 어드레스와 연관된 대응하는 에지 노드를 식별하는 것; 물리적 어드레스에 저장된 자원으로의 액세스를 제공하는 것을 포함한다. 제 2 예(예 F2)에서, 예 F1의 주제는, 물리적 어드레스 및 대응하는 에지 노드를 포함하는 정보를 요청 디바이 스 또는 서비스로 전송함으로써 자원으로의 액세스를 제공하는 것을 포함한다. 제 3 예(예 F3)에서, 예 F1-F2의 주제는, 대응하는 에지 노드로부터 요청 에지 노드로 자원의 복사 또는 전송을 용이하게 함으로써 자원으로의 액세스를 제공하는 것을 포함한다. 제 4 예(예 F4)에서, 예 F1-F3의 주제는, 명령어가, 자원으로의 액세스를 제공하기 전에, 요청 디바이스가 에지 글로벌 서비스 페이지 테이블을 체크함으로써 자원에 액세스할 인가를 갖고 있는지를 결정하는 것을 포함하는 동작을 수행하도록 처리 회로를 구성하는 것을 포함한다. 제 5 예(예 F5)에서, 예 F1-F4의 주제는, 디바이스가 복수의 에지 노드의 에지 노드이고, 에지 글로벌 서비스 페이지 테이블이 에지 노드상에 국부적으로 저장되는 것을 포함한다. 제 6 예(예 F6)에서, 예 F1-F5의 주제는, 자원으로의 액세스를 제공하는 것이 원격 네트워크 인터페이스에 판독 을 전송하여 대응하는 에지 노드에서 원격 메모리 액세스를 획득하는 것을 포함한다. 제 7 예(예 F7)에서, 예 F1-F6의 주제는, 자원으로의 액세스를 제공하는 것이 자원, 대응하는 에지 노드 또는 요청 디바이스의 보안 요구 사항을 준수하는 것을 포함한다. 다양한 설정에서, 예 F1-F7(및 글로벌 페이지 테이블의 다른 양태)은 정의된 애플리케이션 프로그래밍 인터페이 스 또는 인터페이스 사양; 페이지 테이블을 호출하거나 수정할 프로토콜 또는 정의의 사용; 및 에지 컴퓨팅 환 경 내의 다수의 디바이스에 걸쳐 페이지 테이블의 다른 사용 및 구현의 결과로서 관찰되거나 모니터링될 수 있 다. 예 F1-F7 및 이러한 글로벌 페이지 구성의 다른 양태는 또한 (예를 들어, FaaS 또는 EaaS 설정에서 페이지 및 데이터 구조를 공유하는) 서비스 동작 및 서비스 기능의 결과로서 관찰되거나 구현될 수 있다. 또한, 예 F1-F7의 방법은 에지 컴퓨팅 시스템에서 (예를 들어, 명령어가 실행될 때 방법을 수행하는 머신 판독 가능 매체 와 함께) 구현된 명령어로서 또는 (예를 들어, 방법을 수행하거나 달성하는 구성을 포함하는 장치와 함께) 구현된 하드웨어 구성으로서 제공될 수 있다. 따라서, 예 F1-F7의 특징(및 글로벌 페이지 구성 및 사용의 다른 특 징)은 시스템 오케스트레이터 또는 설계자에 의해 조정되거나 설계된 대로, 본 명세서의 임의의 다른 예와 결합 되어 에지 클러스터 또는 에지 클라우드 시스템을 구성할 수 있다. 브로드캐스팅 자원 임대자(Broadcasting Resource Borrower)의 예 에지 클라우드 인프라스트럭처는 다수의 방법으로 생성되고 있다. 중앙국과 같은 일부 에지 클라우드 위치는 각각의 에지 클라우드 위치에서 오케스트레이션을 호스팅하기에 충분한 자원을 갖고 있을 수 있다. 반면에 거 리 캐비닛(street cabinet)과 같은 일부 다른 에지 클라우드 위치는 로컬 자원 관리자와의 원격 오케스트레이션 을 갖고 있을 수 있다. 이러한 에지 클라우드 그룹은 오늘날 클라우드에서 행해지는 것과 같은 전통적인 오케 스트레이션 및 자원 관리와는 반대로 혁신적인 방법으로 효율적으로 관리될 수 있다. 에지 클라우드는 시간이 변하는 요구 사항에 따라 서비스 요청을 많이 수집하는 것을 특징으로 한다. 상이한 위치에 물리적으로 존재하는 자원의 공동 할당(co-allocation)은 잘 알려진 개념이다. 체계는 보통 주 문형 할당(on-demand allocation) 또는 단순한 기준에 기초한 정적 할당(static allocation)을 기초로 한다. 특정 서비스에 대한 자원의 일반적인 공동 할당은 에지 클라우드에서 너무 비쌀 수 있다. 대신에, 본 명세서에 서 설명된 시스템 및 방법은 전체 서비스 할당 및 처리량을 개선하기 위해 효율적으로 사용될 에지 클라우드 그 룹을 구성한다. 예를 들어, 각각의 에지 클라우드는 한 세트의 컴퓨팅 자원을 관리하는 오케스트레이션 인스턴 스를 가질 수 있다. 에지 클라우드 그룹은 오케스트레이션 클러스터로 구성될 수 있다. 에지 컴퓨팅 시스템(예를 들어, 에지 클라우드 및 도 3 내지 도 22d에 도시된 에지 컴퓨팅 시스템 구성)에 서 제공되는 다음과 같은 기술은 한 세트의 컴퓨트 자원을 관리할 에지 그룹을 사용하는 방법의 예를 포함한다. 예를 들어, 각각의 에지 클라우드는 한 세트의 컴퓨팅 자원을 관리하는 작은 오케스트레이션 인스턴스를 갖는다. 에지 클라우드 그룹은 오케스트레이션 클러스터로서 구성될 수 있다. 일단 자원이 이용 가능하면, 에 지는 그 자원을 클러스터의 에지 오케스트레이션 피어에 자동으로 광고할 수 있다. 에지 오케스트레이션 피어 는 다른 자원 관리자/오케스트레이터에게 특정 양의 시간 동안 자원의 일부 또는 전부를 예약하도록 요청할 수 있다. 자원 관리자는 그 기간 동안 자원을 더 이상 이용할 수 없음을 브로드캐스트할 수 있다. 오케스트레이션은 제공자 대 제공자 모델 또는 제공자 대 서비스/고객 모델을 사용하여 제공될 수 있다. 제공 자 대 제공자(provider-to-provider)(P/P) 모델에서, 오케스트레이터는 부하의 증가, 특정 시간 동안 예상되는 부하의 증가 등과 같은 요인에 기초하여 다른 피어로부터 자원을 요청할 수 있다. 제공자-서비스/고객 (provider-to-service/customer)(P/S) 모델에서, 서비스는 오케스트레이터에게 추가 자원을 찾도록 또는 자원 대여를 통해 오케스트레이터가 만족할 수 있는 서비스의 다른 인스턴스를 시작하도록 요청할 수 있다. 이러한 기술은 서비스 가용성을 증가하거나, 효율적인 자원 활용으로 TCO를 개선하거나, 또는 특정 에지 또는 디바이스 에서 제공될 수 있고 제공되지 않을 수 있는 자원 측면에서 유연성을 제공할 수 있다. P/P 또는 P/S 모델, 또 는 다른 유사한 모델에서, 자원이 주어진 비용으로 공유되거나 노출될 수 있으므로 비용의 차원이 고려될 수 있 다. 예에서, ETSI MEC 표준은 사용될 주어진 서비스의 지역성 범위를 포함하도록 수정될 수 있다. 예를 들어 고정 된, 이를테면 사전에 합의된 양의 시간에 자원을 예약하는 것은 표준을 수정하는 데 사용될 수 있다. 도 33은 상이한 에지 클라우드 위치에서 오케스트레이터의 도메인 분리를 보여주는 시스템을 도시한다. 시스템 다이어그램은 오케스트레이터의 인스턴스를 갖는 상이한 에지 클라우드 내의 각각의 에지(클러스 터 내의 에지(3311, 3312, 3313) 및 클러스터 내의 에지(3221, 3322, 3323))를 갖는 두 개의 상이 한 에지 클라우드 위치를 포함한다. 에지 클라우드 위치는 또한 시스템 다이어그램에서 두 개의 상이한 클러스터(3310, 3320) 각각에서 형성되는 것으로 도시된다. 도 34는 에지 클라우드의 지역을 관리하는 에지 클라우드 오케스트레이터를 보여주는 시스템을 도시한다. 시스템 다이어그램과 대조적으로, 시스템 다이어그램은 한 지역 내 다수의 에지 위치(예를 들어, 지역 1 내 위치(3411, 3412, 3413) 및 지역 2 내 위치(3421, 3422, 3423))가 (예를 들어, 중앙국 내) 원격 오케스트레이터에 의해 관리되는 오케스트레이션 체계를 도시한다. 시스템 다이어그램에 도시 된 두 개의 지역(3410, 3420)은 함께 클러스터를 형성하여, 이를테면 지역에 걸쳐 자원이 대여될 수 있게 할 수 있다. 각각의 지역은 각각의 에지 위치가 자체 오케스트레이터를 갖는 것보다는, 단일 오케스트레이터(예를 들 어, (3411, 3421))를 가질 수 있다. 클러스터는 에지 위치 지역성(구역 지정) 또는 에지 클라우드 유형(예를 들어, 모든 거리 캐비닛이 한 클러스터에 있는데 반해 셀 타워는 다른 클러스터에 있을 수 있음)과 같은 다수의요인에 기초하여 생성될 수 있다. 지역 보안 정책은 허용 가능한 다중 지역 정책이 도메인 컨텍스트에 대해 결 정될 수 있는 도메인 컨텍스트에 동적으로 제공될 수 있다. 예를 들면, (예를 들어, 도메인 1의) 지역 1과 지 역 2의 결합은 최소한의 공통 액세스가 승인되도록 보장할 수 있다. 따라서, 이러한 배열은 도메인 컨텍스트의 동적 형성(뿐만 아니라 정적 형성)을 지원한다. 도 35는 자원 브로드캐스팅 및 대여의 예를 보여주는 세 개의 상이한 오케스트레이터 간의 흐름도을 도시 한다. 예에서, 흐름도의 세 개의 오케스트레이터는 상이한 에지 위치(예를 들어, 도 34의 지역)에 속할 수 있다. 오케스트레이터는 자원 가용성을 브로드캐스트하거나, 자원을 요청 또는 할당하거나 또는 브로드캐스 트를 통해 자원 가용성을 업데이트한 다음 대여한 자원을 해제하는 데 사용될 수 있다. 동작의 다른 변형 및 시퀀스가 이러한 프레임워크 내에서 적용될 수 있다는 것이 이해될 것이다. 예를 들어, 도 35의 오케스트레이터 1은 오케스트레이터 2와 오케스트레이터 3 둘 모두에게 자원 가용성을 브로드캐스팅하고, 이들은 차례로 자체의 가용성을 다른 오케스트레이터에게 브로드캐스트하는 것으로 도시된다. 자원은 오케스트레이터 사이에서 요청되고, 할당되고 반환될 수 있다. 자원 가용성은 할당 또는 요청 후에 그리고 반환 후에 재 브로드캐스트될 수 있다. 오케스트레이터는 요청을 받을 때 오케스트레이 터의 지역 내의 디바이스를 대신하여, 예를 들어, 오케스트레이터의 지역 내의 에지 위치에 대한 자원을 예약할 수 있다. 추가 예에서, 오케스트레이션 시퀀스의 실행이 모델링되거나 시뮬레이션될 수 있다. 예에서, (3511, 3512, 3513)과 같은 에지 오케스트레이터는 컴퓨트 자원의 대여-빌려줌을 용이하게 하는 것 외 에도, 그룹 차원의 승인 제어 정책을 구현할 수 있다. 자원이 유보됨에 따라, 오케스트레이터는, 요청의 새로 운 버스트가 트래픽 형태(또는 일부 거부된 서비스)가 될 수 있도록 승인 제어 정책을 구현함으로써, 새로운 클 라이언트를 받아들여 지터가 추가되거나 또는 기존의 SLA 보증을 훼손시킬 때와 같은 것을 보상할 수 있다. 오케스트레이션 클러스터는 자원 대여가 조절될 때 얼마나 많은 자원 대여가 수행될 수 있는지를 결정하기 위해 순방향 사용량 예측을 수행할 수 있다. 예를 들어, 에지 서버에는 CPU 헤드 룸(head room)이 있기 때문에 에지 서버는 추가 흐름을 받아들일 수 있다. 그러나, 에지 서버는 고성능 스토리지 풀로부터 용량을 예약하여 덜 임 계적이거나 현재 수면 상태의 메모리 호그(memory hog)를 교체하여 진행하기에 충분한 메모리 또는 스토리지 헤 드룸을 유지해야 할 수 있다. 이것을 효과적으로 (동요 없이) 수행하기 위해 오케스트레이터(3511, 3512, 3514)는 풀려나야 할 메모리의 양과 필수 교체에 필요한 IO 대역폭의 양을 예상할 수 있다. 예에서, 이러한 메 트릭에 도달하기 위해, 오케스트레이터(3511, 3512, 3514)는 워크로드 유형 또는 특성에 기초하여 이러한 요구 를 예측할 수 있는 모델을 사용할 수 있다. 또한, 오케스트레이터(3511, 3512, 3514)는 LSM을 시행 지점에 가 장 효율적으로 프로비저닝하기 위한 정책을 협상할 수 있다. 서비스는 이러한 에지 오케스트레이터(3511, 3512, 3514)에 등록할 수 있다. 서비스는 또한 모델 파라미터를 등록할 수 있으며, 오케스트레이터(3511, 3512, 3514)는 모델 파라미터를 에지 원격 측정과 함께 사용하여 얼마 를 대여하거나 해제할지 그리고 얼마나 오랜 기간일지를 평가할 수 있다. 상이한 에지 클라우드는 상이한 에너지 및 열 속성을 가질 수 있다는 점을 고려할 때, (3511, 3512 또는 3514) 와 같은 에지 오케스트레이터는 에지 클라우드의 활동을 줄이고 DC 열 헤드룸을 위한 자원을 해소하도록 선택할 수 있다. 이러한 서비스는 대여된 자원에서 실행될 수 있다. 추가 예에서, 자원을 브로드캐스팅하기 위한 방법은 다음의 동작 또는 그 변형 동작을 사용하여, 에지 지역에서 (예를 들어, 에지 클라우드의 일부분 내에서, 및 노드 또는 디바이스(2200, 2232, 2240 또는 2250)에서 또 는 그에 의해 구현되는 것과 같은 구현 시스템 및 디바이스 내에서) 오케스트레이션 기술을 구현할 수 있다. 방법은 다른 오케스트레이터(3511, 3513)와 상호작용하도록 오케스트레이터를 실행하는 제 1 동작을 포함 하며, 오케스트레이터는 오케스트레이터에 대응하는 지역 내의 에지 노드 사이에서 자원을 조정한 다. 예에서, 오케스트레이터 및 다른 오케스트레이터(3512, 3513)는 클러스터의 멤버이다. 클러스터는 오케스트레이터 및 다른 오케스트레이터에 대응하는 지역 내 에지의 근접성에 기초하여 선택될 수 있다. 다른 예에서, 클러스터는 (예를 들어, 거리 캐비닛을 거리 캐비닛과 조정하고 셀 타워를 셀 타워와 조정하는) 에지 디바이스 유형에 기초하여 선택될 수 있다. 방법은 지역 내에서 이용 가능하지 않은 자원에 대한 요청을 식별하는 제 2 동작을 더 포함한다. 이 동작은 지 역 내에서 가용 자원이 임계치 미만이라고 결정하는 것을 포함할 수 있다. 이 동작은 지역 내 노드의 서비스로 부터의 요청을 수신하는 것을 포함할 수 있다. 방법은 다른 오케스트레이터와 조정하여 자원을 요청하는 제 3 동작을 더 포함한다. 방법은 다른 오케스트레이 터 중 하나로부터 자원의 할당을 수신하는 제 4 동작을 더 포함한다. 추가 예에서, 방법은 오케스트레이터로부터 다른 오케스트레이터(3512, 3513)로, 지역 내의 가용 자원을 브로드캐스팅하는 단계를 포함할 수 있다. 예에서, 방법은 자원의 사용이 지역 내에서 완료될 때, 다른 오케스 트레이터(3512, 3513) 중 하나에 표시를 전송함으로써 자원을 반환하는 단계를 포함할 수 있다. 자원을 반환한 후에 다른 변경 또는 자원 해제/해체 동작이 발생할 수 있다. 자원 브로드캐스팅을 구현하기 위한 제 1 예시적인 방법(예제 G1)은 (예를 들어, 노드 또는 디바이스(2200, 2232, 2240 또는 2250)의) 처리 회로를 사용하여 수행되는 방법으로서, 방법은, 다른 오케스트레이터와 상호작 용할 오케스트레이터를 실행 - 오케스트레이터는 오케스트레이터에 대응하는 지역 내의 에지 노드 사이에서 자 원을 조정함 - 하는 단계; 지역 내에서 이용 가능하지 않은 자원에 대한 요청을 식별하는 단계; 다른 오케스트 레이터와 조정하여 자원을 요청하는 단계; 및 다른 오케스트레이터 중 하나로부터 자원 할당을 수신하는 단계를 포함한다. 제 2 예(예 G2)에서, 예 G1의 주제는, 자원에 대한 요청을 식별하는 단계가 지역 내에서 가용 자원이 임계치 미 만이라고 결정하는 단계를 포함하는 것을 포함한다. 제 3 예(예 G3)에서, 예 G1-G2의 주제는, 자원에 대한 요청을 식별하는 단계가 지역 내의 노드의 서비스로부터 요청을 수신하는 단계를 포함하는 것을 포함한다. 제 4 예(예 G4)에서 예 G1-G3의 주제는, 오케스트레이터와 다른 오케스트레이터가 클러스터의 멤버인 것을 포함 한다. 제 5 예(예 G5)에서, 예 G4의 주제는, 클러스터가 오케스트레이터 및 다른 오케스트레이터에 대응하는 지역 내 의 에지의 근접성에 기초하여 선택되는 것을 포함한다. 제 6 예(예제 G6)에서 예 G4-G5의 주제는, 클러스터가 에지 디바이스 유형에 기초하여 선택되는 것을 포함한다. 제 7 예(예제 G7)에서 예 G1-G6의 주제는, 오케스트레이터로부터 다른 오케스트레이터로, 지역 내의 가용 자원 을 브로드캐스트하는 단계를 포함한다. 제 8 예(예제 G8)에서 예 G1-G7의 주제는, 자원의 사용이 지역 내에서 완료될 때 다른 오케스트레이터 중 하나 에게 표시를 전송함으로써 자원을 반환하는 단계를 포함한다. 다양한 설정에서, 예 G1-G8(및 자원 대여자 정보를 브로드캐스팅하는 다른 양태)은 정의된 애플리케이션 프로그 래밍 인터페이스 또는 인터페이스 사양; 자원 동작을 호출, 수신 또는 제어할 프로토콜 또는 정의의 사용; 에지 소프트웨어 스택 구성 및 라이브러리; 및 에지 컴퓨팅 클러스터 또는 환경 내에서 오케스트레이터 엔티티에 의 해 추적되는 자원 정보의 다른 사용 및 구현의 결과로서 관찰되거나 모니터링될 수 있다. 예 G1-G8 및 이러한 자원 대여 동작의 다른 양태는 또한 (예를 들어, FaaS 또는 EaaS 설정에서 자원을 공유 또는 조정하는) 서비스 동작 및 서비스 기능의 결과로서 관찰되거나 구현될 수 있다. 또한, 예 G1-G8의 방법은 (예를 들어, 명령어가 실행될 때 방법을 수행하는 머신 판독 가능 매체와 함께) 구현된 명령어로서 또는 (예를 들어, 방법을 수행하거 나 달성하는 구성을 포함하는 장치와 함께) 구현된 하드웨어 구성으로서 제공될 수 있다. 따라서, 예 G1-G8의 특징(및 자원 관리의 다른 특징)은 시스템 오케스트레이터 또는 설계자에 의해 조정되거나 설계된 대로, 본 명 세서의 임의의 다른 예와 결합되어 에지 클러스터 또는 에지 클라우드 시스템을 구성할 수 있다. 데이터 집계 정책(Data Aggregation Policy)의 예 에지 클라우드 인프라스트럭처는 다수의 소스로부터의 데이터를 저장하는 데 사용될 수 있다. 데이터는 수집되 고 선택적으로 에지 디바이스에서 결합될 수 있다. 에지 위치에서 데이터 자원을 공유하는 것은 테넌트 또는 사용자 프라이버시 문제를 일으킬 수 있다. 다음의 예시적인 시스템 및 방법은 에지 컴퓨팅 시스템(예를 들어, 에지 클라우드 및 도 3 내지 도 22d에 도시된 에지 컴퓨팅 시스템 구성)의 데이터 공급 체인에서 이러한 문제 및 다른 문제, 특히 데이터를 집계할 수 있게 함으로써 프라이버시와 관련된 문제를 해결한다. 에지 디바 이스에서 데이터 집계 또는 처리는 저전력 디바이스(예를 들어, IoT 디바이스)에서 전력을 보존하거나 또는 컴 퓨트 역량이 없거나 컴퓨트 캐퍼빌리티가 없는 센서에 컴퓨팅을 제공하는 데 유용하다. 다음의 예는 에지 디바이스에서 다수의 유형의 데이터를 집계하는 것과 관련이 있다. IoT 디바이스, 자동차, 드론, 모바일 폰, 센서 등과 같은 디바이스는 종종 특정 목적을 위해 데이터를 생성한다. 이러한 데이터는 목 전의 목적 이상으로 유용할 수 있지만, 디바이스에서 데이터의 수집, 유지 관리 및 평가는 어려울 수 있다.예를 들어, 모바일 디바이스(예를 들어, 자율 주행 자동차, 드론, 전화 등)는 많은 센서 데이터를 수집할 수 있 지만 센서 데이터를 처리하는 컴퓨트 캐퍼빌리티가 제한될 수 있다. 모바일 디바이스는 (예를 들어, 자동차를 도로에 유지하기 위해) 특정 작업에 필요한 데이터를 수집할 수 있다. 데이터는, 이를테면 작업이 이행된 후에, 모바일 디바이스에서 쓸모 없어질 수 있다(예를 들어, 차량이 건널목을 통과할 때, 건널목에 관한 센서 데이터를 삭제할 수 있다). 에지 처리 노드(예를 들어, 기지국, 소형 셀 등)는 더 많은 컴퓨팅 역량을 가지며 이러한 모바일 디바이스를 비롯한 다수의 디바이스로부터 데이터를 수신할 수 있다. 에지 디바이스는 다수의 디바이스로부터 센서 데이터를 결합할 수 있다. 예를 들어, 에지 디바이스는 유사한 유형(예를 들어, 자동차)의 복수의 디바이스로부터 데이터를 수신하고 그 데이터를 집계할 수 있다. 다른 예에 서, 상이한 디바이스가 에지 디바이스에서 집계되는 데이터를 제공할 수 있다. 예를 들어, 에지 디바이스는 (예를 들어, 상이한 자동차 또는 드론 내) 다수의 카메라로부터의 비디오 촬영물을 결합함으로써 집계된 데이터 를 사용하여 영역의 3D 모델을 생성할 수 있다. 데이터의 집계는 개별 디바이스 데이터가 가진 문제를 피할 수 있다(예를 들어, 자동차 한 대가 바퀴에서 미끄러짐을 관찰할 때, 이것은 측정 오류일 수 있다). 예를 들어, 집계된 데이터를 사용하면, 여러 자동차가 동일한 위치에서 미끄러짐을 관찰할 수 있는데, 이것은 그 위치에서 도로가 미끄러운 것을 나타내는 것이다. 도 36은 일부 예에 따라 에지 디바이스에서 데이터를 집계하기 위한 아키텍처를 포함하는 시스템의 다이 어그램을 도시한다. 시스템은 데이터 제공자 디바이스로부터 데이터를 집계하는 데 사용되는 에지 아키텍처의 여러 가 지 요소를 포함한다. 시스템은 예를 들어, 데이터 관리자 컴포넌트 내에서 집계 기능의 저장 및 등록을 담당하는 명령어를 갖는 (예를 들어, 알고리즘, 로직 등을 구현하는) 플랫폼을 포함한다. 등록 인터페이스는 변환 기능을 등록할 수 있게 한다. 변환 기능은 디바이스의 유형 또는 기능이 적용되는 센 서를 포함할 수 있다(예를 들어, 센서 유형은 자동차에서 측정된 온도를 포함할 수 있다). 시스템은 집계 기능 자체를 포함할 수 있다. 예를 들어, 에지 디바이스로부터 데이터 세트의 목록 이 주어지면, 집계 기능은 컴퓨테이션을 수행하고 클라우드 데이터 제공자에 저장되거나 데이터 제 공자에 전송될 단일 값을 생성할 수 있다. 시스템은 집계 간격을 포함할 수 있다. 간격은 (예를 들어, 초, 분 등과 같은 시간 간격에 걸쳐) 컴퓨테이션을 수행하기 전에 집계기(aggregator)가 그 디바이스 유형 ID에 대한 데이터를 저장하는 데 얼 마의 시간 단위를 이용 가능한지를 표시한다. 다른 예에서, 집계 간격은 시간 단위 대신에 또는 그외에 데이터 가 수신되는 횟수를 포함할 수 있다. 시스템은 디바이스에 의해 데이터를 집계기로 전송하기 위해 사용되는 인터페이스를 포함한다. 집 계 로직은 인터페이스(예를 들어, 디바이스에 의해 데이터를 집계기로 전송하는 데 사용되는 인터페이스 또는 클라우드 데이터 제공자와의 인터페이스)를 구현하는 것을 담당할 수 있다. 집계 기능은 로컬 스토리지 메모리 가 집계를 사용하여 프라이버시 민감 콘텐츠를 보호/난독화하기 위한 보안 정책을 포함하는 또는 제공하 는 로컬 스토리지 메모리 시행 지점일 수 있다. (따라서, 사용자가 집계를 요청하지 않았더라도, 로컬 스토리 지 메모리는 프라이버시를 보호하기 위해 집계를 적용할 수 있다.) 컴퓨팅 컨텍스트(예를 들어, 센서 유형과 같은 컨텍스트, 동일한 소스 또는 비교 가능한 소스의 과거 추세 데이 터, 데이터 소스 비교 값, 또는 신뢰감을 표시할 수 있는 다른 값)는 수신된 데이터의 신뢰를 결정하는 데 사용 될 수 있다. 예를 들어, 감지되는 데이터에 \"가까이 있는\" 센서에 의해 공급되는 데이터는 덜 \"가까이 있는\" 센서로부터의 데이터보다 더 신뢰할 수 있거나 신뢰도가 있을 수 있다. 이러한 컨텍스트에서 \"가까이 있는\"이 라는 것은 물리적 속성일 수 있거나, 또는 연결성 속성(connectedness property)(예를 들어, 센서가 센서에 의 해 측정되는 데이터를 생성하는 시스템에 대해 검증되는지 아닌지) 일 수 있다. 데이터를 해석하는 기능에 \"가 까움\" 역시 신뢰도의 고려 사항이 될 수 있다. 지역성과 관련 있는 \"가까움\"은 데이터가 \"멀리 있는\" 지역성을 가진 어떤 장소로부터 도착한 경우보다 더 신뢰할 수 있다는 것을 의미한다. 추가 예에서, 가까움의 개념은 제 공자의 유형에 따라 거리가 달라지도록 확장될 수 있다(예를 들어, 제 1 조직과 연관된 제공자는 1 마일 = 1 마 일과 같은 제 1 메트릭으로 연산된 거리를 갖는 반면, 제 2 조직과 연관된 거리는 1 마일 = 2 마일과 같은 제 2 메트릭으로 연산된다). 에지 디바이스는 신뢰 테스트의 일부로서 데이터 지역성을 평가할 수 있다. 데이터가 유지되지만 원격 노드로 다시 전달될 때, 데이터는 신뢰성이 떨어지는 것으로 취급될 수 있다. 로컬 컴퓨테이션에 의해 (예를 들어, 원격 측정에 대해) 집계될 때, 노드는 이것을 무결성 값이 높은 것으로 간주할 수 있다. 이 예에서, 피어 노드는 자신의 지역성 테스트 및 신뢰 시맨틱(예를 들어, 제 1 노드의 신뢰도)에 기초하여 자신의 값을 낮출 수 있다. 추가 예에서, 에지 디바이스에서 데이터를 집계하기 위한 방법은 (예를 들어, 에지 클라우드의 시스템 및 디바이스에 의해 구현되는, 이를테면 노드 또는 디바이스(2200, 2232, 2240 또는 2250)에서 또는 그에 의해 구 현되는) 다음의 동작을 포함할 수 있다. 방법은 에지 노드에서 복수의 모바일 디바이스로부터 데이터를 수신하는 제 1 동작을 포함한다. 방법은 수신된 데이터를 에지 노드의 집계 로직을 사용하여 집계하는 제 2 동작을 포함한다. 예에서, 데이터는 명시된 양의 데이터(예를 들어, 다수의 전송 또는 패킷)가 수신될 때까지 또는 명시된 수량의 디바이스로부터 데이터가 수신될 때까지, 시간 간격과 같은 간격에 걸쳐 집계될 수 있다. 방법은 에지 노드에서 집계된 데이터 및 집계 기능에 기초하여 값을 생성하는 제 3 동작을 포함한다. 방법은 값을 클라우드 디바이스로 전송하는 제 4 동작을 포함한다. 예에서, 값은 나중에 수신된 데이터를 검증 하는 데 사용될 수 있다. 다른 예에서, 값은 영역의 상세한 지도를 생성하는 데 사용될 수 있다. 또 다른 예 에서, 값은 모바일 디바이스의 기능을 검증하는 데 사용될 수 있다. 또 다른 예에서, 값은 사용량 데이터를 생 성하거나, 피드백을 제공하거나, 또는 보안 설정에서 사용될 수 있다. 방법은 수신된 데이터의 신뢰도 레벨을 결정하는 제 5 동작을 포함한다. 신뢰도는 값과 함께 출력될 수 있다. 예에서, 데이터의 집계는 수신된 데이터의 신뢰도를 감안하는 것을 포함할 수 있으며, 예를 들어 값은 신뢰도에 기초하여 결정될 수 있다. 다중 에지 데이터 집계 정책을 구현하고 사용하기 위한 추가의 예시적인 방법(예 H1)은 (예를 들어, 노드 또는 디바이스(2200, 2232, 2240 또는 2250)의) 처리 회로를 사용하여 수행되는 방법으로서, 방법은, 에지 노드에서, 복수의 모바일 디바이스로부터 데이터를 수신하는 단계; 수신된 데이터를 에지 노드의 집계 로직을 사용하여 집 계하는 단계; 에지 노드에서 집계된 데이터 및 집계 기능에 기초하여 값을 생성하는 단계; 및 값을 클라우드 디 바이스로 전송하는 단계를 포함한다. 제 2 예(예 H2)에서, 예 H1의 주제는, 수신된 데이터를 간격에 걸쳐 집계함으로써 수신된 데이터를 집계하는 단 계를 포함한다. 제 3 예(예 H3)에서, 예 H2의 주제는, 간격이 시간 간격, 수신될 명시된 양의 데이터 또는 데이터를 수신할 명 시된 수의 디바이스를 포함하는 구성을 포함한다. 제 4 예(예 H4)에서, 예 H1-H3의 주제는, 값이 나중에 수신된 데이터를 검증하는 데 사용되는 구성을 포함한다. 제 5 예(예 H5)에서 예 H1-H4의 주제는, 값이 영역의 상세한 맵을 생성하는 데 사용되는 구성을 포함한다. 제 6 예(예 H6)에서, 예 H1-H5의 주제는, 값이 모바일 디바이스의 기능을 검증하는 데 사용되는 구성을 포함한 다. 제 7 예(예 H7)에서 예 H1-H6의 주제는, 값이 사용량 데이터를 생성하거나, 피드백을 제공하거나 또는 보안 설 정에서 사용되는 구성을 포함한다. 제 8 예(예 H8)에서 예 H1-H7의 주제는, 값이 수신된 데이터의 신뢰도 레벨을 결정하는 단계를 포함한다. 제 9 예(예 H9)에서, 예 H8의 주제는, 신뢰도 레벨을 출력함으로써 값을 출력하는 단계를 포함한다. 제 10 예(예 H10)에서, 예 H1-H9의 주제는, 수신된 데이터의 신뢰도를 사용함으로써 수신된 데이터를 집계하는 단계를 포함한다. 다양한 설정에서, 예제 H1-H10(및 데이터 집계 정책의 다른 양태)은 정의된 애플리케이션 프로그래밍 인터페이 스 또는 인터페이스 사양; 자원 동작을 호출, 수신 또는 제어할 프로토콜 또는 정의의 사용; 및 에지 컴퓨팅 환 경 내에서 (데이터 전송을 통해 전달되는 것으로서 이를 비롯한) 정책, 로직 및 맵의 다른 사용 및 구현의 결과 로서 관찰되거나 모니터링될 수 있다. 예 H1-H10에서 표현된 바와 같은 데이터 집계 정책은 또한 (예를 들어, FaaS 또는 EaaS의 일부로서 구현되거나 달성되는) 서비스 내에서 수행되는 동작 후에 또는 동작의 일부로서 구 현될 수 있다. 또한, 예시 H1-H10의 방법은 에지 컴퓨팅 시스템에서 (예를 들어, 명령어가 실행될 때 방법을 수행하는 머신 판독 가능 매체와 함께) 구현된 명령어로서 또는 (예를 들어, 방법을 수행하거나 달성하는 구성 을 포함하는 장치와 함께) 구현된 하드웨어 구성으로서 제공될 수 있다. 따라서, 예 H1-H10의 특징(및 데이터집계의 다른 특징)은 시스템 오케스트레이터 또는 설계자에 의해 조정되거나 설계된 대로, 본 명세서의 임의의 다른 예와 결합되어 에지 클러스터 또는 에지 클라우드 시스템을 구성할 수 있다. 자원을 펜싱하는 프리미엄 서비스 보장(Guaranteeing Premium Services with Resource Fencing)의 예 에지 컴퓨팅은 종종 네트워크의 에지에 위치하는 것처럼 모듈식 컴퓨팅 풀을 물리적으로 배치하는 것을 수반한 다. 이것은 일반적으로 예를 들어, 실시간 데이터 스트림을 처리할 때 지연시간에 민감한 다양한 사용을 지원 하기 위해 수행된다. 에지 컴퓨팅 설치는 다른 것 중에서도, 스마트 시티, 증강 또는 가상 현실, 보조 또는 자 율 주행, 공장 자동화 및 위협 검출과 같은 다양한 유스 케이스를 지원하기 위해 확장되고 있다. 일부 부각되 는 사용은 이벤트 트리거된 분산 기능(event triggered distributed function)과 같은 컴퓨테이션 또는 데이터 집약적 애플리케이션을 지원하는 것을 포함한다. 데이터를 생성하는 디바이스의 기지국 또는 네트워크 라우터 에 대한 근접성은 신속한 처리에 있어서 중요한 인자이다. 일부 예에서, 이러한 에지 설치는 백엔드 클라우드"}
{"patent_id": "10-2020-7037506", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "에서 추가 처리를 위해 높은 레벨의 요약(예를 들어, 집계) 또는 필터링을 수행하면서 실시간 컴퓨테이션을 달 성하는 메모리 또는 스토리지 자원 풀을 포함한다. 에지 아키텍처는 일반적으로 많은 디바이스의 분산 설치를 수반한다. 이러한 네트워크를 구축하는 것은 자본 집약적일 수 있다. 차세대 기지국 및 중앙국에서 고려되는 요소는 프리미엄 서비스를 위한 핵심 성과 지표 (KPI)를 잃지 않고 자본 지출(capital expenditure)(CAPEX)을 줄이는 것이다. 이러한 목적을 달성하기 위해, AR/VR과 같은 다수의 높은 자원 수요 서비스(high-resource demanding service)는 사업자의 핵심 비즈니스를 지원하는 셀룰러 가상 네트워크 기능(cellular virtual network function)(VNF)과 같은 높은 서비스 레벨 협약 (service level agreement)(SLA) 또는 수익 임계적 작업과 함께 배치될 수 있다. 수익 임계적 프리미엄 서비스를 지원하기 위해, 사업자 하드웨어는 중요한 워크로드에 할당된 컴퓨테이션 자원 을 모니터링하고 관리하여 품질 목표가 훼손되지 않도록 하면서 가치 처리를 위해 들어오는 트래픽을 받아들일 수 있어야 한다. 전통적으로, 자원은 서비스 품질(QoS)을 보장하기 위해 프리미엄 서비스 용도로 예약될 것이다. 이러한 예약된 자원은 가용성을 보장하기 위해 다른 작업에 이용할 수 없다. 그러나 이것으로 인해 비 프 리미엄 서비스가 덜 필수 불가결할지라도 유사한 자원(예를 들어, 고 대역폭, 전력 등)을 필요로 하기 때문에 단편화(fragmentation) 및 높은 자원 비용으로 이어진다. 따라서, 하드웨어 플랫폼에는 활용도가 낮은 중복 자 원이 많이 포함되는 경향이 있다. 이러한 방식으로 임계적인 동작을 분리하면 비용이 증가하고 효율성이 감소 할뿐만 아니라, 에지 클라우드의 탄력성이 감소하고 에지 클라우드 생태계에서 새로운 서비스, 사용 모델 및 수 익 기회의 빠른 성장을 받아들일 역량이 제한된다. 거듭하면, 비 프리미엄 서비스에도 유사한 자원 요구 사항이 있기 때문에 프리미엄 서비스에 대한 배타적인 예 약은 에지 데이터 센터에 많은 수의 자원을 설치해야 하는 필요성을 증가시킨다. 로드 밸런싱은 일반적으로 하 드웨어 가속 동작을 비롯하여 이 동작을 위한 유사한 컴퓨테이션을, 프리미엄 클라이언트의 서비스에도 있는지 아니면 없는지에 따라, 지속적으로 구별하는 데 필요하다. 따라서, 로드 밸런싱은 일반적으로 지연시간과 추가 전송 동작을 추가한다. 그러므로 이러한 방식으로 QoS를 보장하면 총 소유 비용(TCO) 및 자본 지출이 증가하면 서 또한 에지 데이터 센터가 단편화 오버헤드를 겪게 된다. 자원을 사일로에 넣는 것(예를 들어, 사일로에 넣 어두는 것) 또한 가용 인프로스트럭처를 프리미엄 QoS 또는 일반 QoS 중 어느 하나에 있을 수 있는 새로이 부상 하는 성장 기회에 전용할 유연성을 줄어들게 한다. 이러한 문제를 해결하기 위해, 자원이 풀링되고 가용 자원 풀이 프리미엄 및 비 프리미엄(예를 들어, 일반) 작 업 사이에 공유되는 탄력적인 접근 방식이 사용된다. 풀링된 자원은 필요에 따라 동적으로 원활하게 우선순위 가 더 높은 작업으로 옮겨가고, 그렇지 않았더라면 남아 있을 작업을 마음껏 처리할 수 있는 자원을 남긴다. 또한, 일부 예에서, 풀링된 자원은 에지 서버 또는 클러스터를 생성하는 다수의 에지 내에서 풀링될 수 있다. 이러한 풀링된 자원을 관리하는 것은 프리미엄 서비스에 대한 SLA 위반이 예측될 때까지 서비스가 공정하게 자 원에 액세스하는 것을 누리는 등급을 매긴 QoS를 제공한다. SLA 중단이 검출되거나 예측될 때, 자원은 임계적 서비스의 SLA를 유지하기 위해 신속하게 재 할당될 수 있다. 이러한 접근 방식은 프리미엄 서비스의 KPI가 항상 데드라인으로서 존재하는 것이 아니기 때문에 데드라인 기반 스케줄링과는 다르다. 예를 들어, 5 세대 셀룰러(5G) 회선 속도 요구 사항은 다수의 VNF에 걸쳐 분산되어 있다. 또한 전형적인 데드라인 스케줄링 절차는 한 번에 하나의 시스템 또는 자원에서 동작한다. 이러한 절차 는 너무 적거나 너무 늦을 수 있는데, 특히 다수의 - 종종 수백 개의 - 체인식 상호작용의 상이한 컴포넌트가 이어진 엔드-투-엔드 체인에서 한 번에 하나의 동작씩 지연시간을 완화함으로써 99 백분위수(percentile) 지연시간이 줄어들기 훨씬 더 어려운 환경에서 그럴 수 있다. 에지 컴퓨팅 시스템(예를 들어, 에지 클라우드 및 도 3 내지 도 22d에 도시된 에지 컴퓨팅 시스템 구성)에 적용 가능한 예에서, 에지 게이트웨이의 하드웨어 모니터는 VNF 거동을 관찰하는 데 사용된다. 즉, 자원 제공 을 받을 수 없는 일류 프리미엄 서비스는 공급 부족에 시달린다. 일부의 자원 정체(예를 들어, 메모리, 컴퓨트 등)로 인해 성능 저하를 경험할 때, 에지 게이트웨이는 예를 들어 VNF를 서비스하는 데 필요한 성능 레벨에 도 달할 때까지 비 임계적인 다른 서비스로부터의 자원을 자동으로 재 할당하도록 구성된다. 이러한 기술은, 예를 들어 HW 기반 자동 타임스탬핑을 사용하여, 시간 조정된 컴퓨팅에서 엔드-투-엔드 지연시 간을 줄이도록 동작한다. 따라서, 다수의 기지국 및 중앙국(CO) 환경에 걸쳐 분산되어 있고 높은 SLA 준수를 필요로 하는 동작 - 예를 들어, 다중 지점 감시, 원격 의료, 모바일 사무실에서 실시간 모바일 조정 등 - 은 사 일로 용량을 과도하게 프로비저닝하지 않고 버스트 도착시 시간에 맞추어 가속될 수 있다. 따라서, TCO 및 CAPEX는 상이한 서비스에 대한 배타적인 예약을 피함으로써 줄어들 수 있으며 SLA 위반이 발생할 것 같을 때 서 비스 사이에서 자원 할당의 신속한 리플로우를 가능하게 할 수 있다. 또한 자원 모니터링 및 재 할당은 에지 게이트웨이에 대한 하드웨어 확장으로 구현되기 때문에, 소프트웨어 레벨의 오버헤드가 완전히 회피된다. 사실, 많은 소프트웨어 레벨의 자원 모니터링 및 재 할당 시도는 서비스가 제 시간에 완료될 수 있게 하지 않을 것이다. 또한, 에지 클라우드 시나리오에서, SLA 및 QoS 협약은 동적이며 본질적으로 예측할 수 없다. 예를 들어, 하루 중 상이한 시점에서 특정 서비스마다 상이한 QoS 레벨이 요구될 수 있고, 또한 서비스 체인에서 지 나가는 상이한 서브기능 사이에서도 요구될 수 있다. 마찬가지로, QoS 협약은 또한 자주 변경될 수 있다. 이 러한 상황에서, 배타적인 예약은 일반적으로 소프트웨어 레벨 오케스트레이터에 의해 재 매핑되며, 많은 경우, 관리자 개입이 필요할 수 있다. 이것은 유지 보수 및 검증 비용을 증가시킨다. 도 37은 (예를 들어, 에지 클라우드의 구현을 제공하는) 에지 게이트웨이 아키텍처의 예를 도시한다. 에지 게이트웨이는 기지국 또는 중앙국에서 에지 아키텍처에 대한 확장으로서 동작할 수 있다. (예를 들어, 플랫폼의 마이크로컨트롤러를 통해 또는 다른 회로를 통해 구현되는) QoS 예측 회로는 에지 게이트웨이 및 에지 컴퓨팅 플랫폼(예를 들어, 에지 컴퓨팅 플랫폼(3732, 3734))의 지능형 네트워크 제어 기(intelligent network controller)(3702 및 3704)(iNIC)에 추가된다. 도시된 다른 요소는 패브릭 관리자 , 다양한 애플리케이션 - 이를테면 VNF(3705, 3706 및 3707) - 및 테이블과 같은 다양한 구성 테 이블을 포함한다. QoS 예측 회로는 VNF 자원에 대한 인터페이스를 노출하도록 구성된다. 예에서, VNF는 프로세스 어드레스 공간 식별자(process address space identifier)(PASID)에 의해 식별된다. QoS 예측 회로는 VNF와 통신하는 데 필요한 최소 대역폭을 위한 인터페이스를 노출하도록 구성된다. 이러한 인터페이스는 VNF를 실행함으로써 어떤 자원이 필요한지에 관한 정보를 QoS 예측 회로에 제공할 뿐만 아니라 VNF의 동작 파라미터를 자원에 제공한다. QoS 예측 회로는 이 정보를 사용하여 각 VNF에 (예를 들어, 다양한) KPI 타겟을 충족시키기에 충분한 플랫폼 자원이 있는지를 추적하도록 구성된다. QoS 예측 회로는 높은 우선순위 VNF를 대신하여 활용 임계치(예를 들어, 70 %)에 접근할 때 자원을 점진적으로 예약하도록 구성된다. QoS 예측 회로는 활용 데드라인이, 히스테리시스의 경우, 위로부터 제 2 임계치(예를 들 어, 60 %) 아래이면 자원을 해제하도록 구성된다. QoS 예측 회로에 의해 고려되는 자원은 플랫폼 자원(예를 들어, 메모리, CPU 사이클, 전력 등) 또는 상호연결 자원(예를 들어, 가용 NIC 또는 스위치 대역폭) 둘 모두일 수 있다. 스트레스가 낮을 때, QoS 예측 회로는 효 과적으로 높은 레벨의 공유를 지원할 것이다. 에지 게이트웨이는 QoS 예측 회로와 유사하게 확장되며, 또한 상이한 플랫폼의 VNF(PASID)에 의해 통신하 는 데 필요한 플랫폼 최소 대역폭의 양을 등록하기 위한 인터페이스를 노출한다. 에지 게이트웨이의 QoS 예측 회로는 또한 연속적으로 대역폭 활용 및 지연시간을 추적하도록 구성된다. 플랫폼에서와 마찬가지로, 에 지 게이트웨이에서의 상대 QoS+예측 로직은 활용 임계치에 기초하여 패브릭 크레딧을 예약하거나 해제한 다. 예약 및 해제하는 작용은 도 37에서 Rsr/Rel로 도시되어 있다. 그러나, 다른 값이 각각의 배치에서 활용 될 것이므로, 도 37에서 제공된 처리량 값 및 다른 속성은 설명의 목적으로 제공된다는 것을 이해할 것이다. 예에서, QoS 예측 회로는 각각의 VNF로 들어오는 요청 속도에 기초한 하드웨어 기반(예를 들어, 필드 프로그램 가능 게이트 어레이(Field Programmable Gate Array)(FPGA) 분석 및 예측을 포함한다. 정보는 이 정보를 사용 하여 예약시 공격성을 높이거나 낮추는 플랫폼으로 전파된다.에지 인프라스트럭처(예를 들어, 노드 또는 디바이스(2200, 2232, 2240 또는 2250)에서 또는 그에 의해 구현되 는 것과 같은 구현 에지 클라우드, 및 시스템 및 디바이스)에서 보장된 프리미엄 서비스를 효율적으로 구 현하기 위한 제 1 예시적인 방법(예 I1)은 처리 회로를 사용하여 수행되는 방법으로서, 방법은, 에지 노드에서 자원 풀을 생성하는 단계; 에지 노드의 지능형 네트워크 제어기(iNIC)의 품질 제어 회로에 의해, 서비스 당 요 청 속도를 측정하는 단계; 품질 제어 회로에 의해, 서비스로의 자원 할당을 넘어서는 임계적 서비스에 대해 있 을 것으로 예상되는 자원 요구를 결정하는 단계; 및 자원을 자원 풀로부터 임계적 서비스에 재 할당하여 있을 것으로 예상되는 자원 요구를 충족하는 단계를 포함한다. 제 2 예(예 I2)에서, 예 I1의 주제는, 에지 노드가 에지 게이트웨이인 구성을 포함한다. 제 3 예(예 I3)에서, 예 I2의 주제는, 서비스가 에지 게이트웨이에 의해 서빙되는 플랫폼에서 실행되는 구성을 포함한다. 제 4 예(예 I4)에서, 예 I1-I3의 주제는, 품질 제어 회로가 필드 프로그램 가능 게이트 어레이인 구성을 포함한 다. 다양한 설정에서, 예 I1-I4(및 프리미엄 서비스 동작의 다른 양태)는 정의된 애플리케이션 프로그래밍 인터페이 스 또는 인터페이스 사양; 프리미엄 서비스를 호출하거나 수정할 프로토콜 또는 정의 사용; 및 에지 컴퓨팅 환 경 내의 서비스에 대한 자원 펜싱 또는 다른 자원 할당의 다른 사용 및 구현의 결과로서 관찰되거나 모니터링될 수 있다. 예 I1-I4 및 이러한 프리미엄 서비스 기술의 다른 양태는 또한 (예를 들어, FaaS 또는 EaaS 설정에서 제공되는 서비스에 사용되는 자원을 재 할당하는) 다른 서비스 동작 및 서비스 기능의 결과로서 관찰되거나 구 현될 수 있다. 또한, 예 I1-I4의 방법은 에지 컴퓨팅 시스템에서 (예를 들어, 명령어가 실행될 때 방법을 수행 하는 머신 판독 가능 매체와 함께) 구현된 명령어로서 또는 (예를 들어, 방법을 수행하거나 달성하는 구성을 포 함하는 장치와 함께) 구현된 하드웨어 구성으로서 제공될 수 있다. 따라서, 예 I1-I4의 특징(및 자원 펜싱 및 자원 할당의 다른 특징)은 시스템 오케스트레이터 또는 설계자에 의해 조정되거나 설계된 대로, 본 명세서의 임 의의 다른 예와 결합되어 에지 클러스터 또는 에지 클라우드 시스템을 구성할 수 있다. 사전 프로비저닝된 핸드오프(Pre-provisioned Handoff)의 예 에지 클라우드 컴퓨팅 시스템은 종종 컴퓨테이션을 위한 자원(예를 들어, 중앙 처리 유닛(central processing unit)(CPU), 그래픽 처리 유닛(graphic processing unit)(GPU), 휘발성 작업 메모리, 비 휘발성 스토리지 등) 또는 통신을 위한 자원(예를 들어, 고 대역폭 링크)을 지나치게 할당하지 않고 실시간 (예를 들어, 지연시간에 민감한) 작업을 수행하기 위해 배치된다. 에지 클라우드는 종종 많은 이유로 워크로드에 과도한 자원 할당을 제한하려고 시도한다. 특히, 대규모 데이터 센터 클라우드와 달리, 에지 컴퓨팅 인프라스트럭처는 넓은 지리적 영역에 걸쳐 분산되는 경향이 있다. 결과적으로, 에지에서는 다양한 동작을 규모대로 실시간으로 수행하기 위 해 필요할 수 있는 머신 및 전력을 프로비저닝하는 자원이 일반적으로 많지 않다. 에지 클라우드에서 발생할 수 있는 문제의 다른 예는 데이터를 분배하는 데 걸리는 시간을 포함한다. 즉, 데이 터를 분배하는 데 시간이 걸리며, 그렇게 하는 데 걸리는 시간은 발생할 수 있는 네트워크 집약적 활동량에서 예측할 수 없는 변동을 겪게 된다. 에지 서비스에 대한 요청자는 인간으로부터 로봇 디바이스, 차량에 이르기 까지 다양할 수 있으며, 에지 서비스를 받는 동안 종종 하나의 물리적 위치로부터 다른 위치로 환승 중일 수 있 다. 이러한 동적 및 일시적 엔티티의 요구 사항을 들어주려면 최소한의 네트워크 홉으로 서비스를 실행해야 할 수 있다. 이것은 요청자를 대신하여 수행된 처리를 요청자에 의해 사용되는 통신 엔드 포인트에 물리적으로 가 장 가까운 지점(예를 들어, 에지 클라우드의 에지 노드)으로 이동함으로써 달성될 수 있다. 따라서, 여기서, 에지 서비스는 하나의 시간에서 하나의 기지국(BS1)으로부터 상이한 시간에서 다른 기지국(BS2)으로 이동할 것으로 예상될 수 있다. 실제로, 이러한 이동은 모바일 요청자의 통신 엔드 포인트가 BS1의 커버리지 영역으로부 터 BS2의 커버리지 영역으로 전이할 때, BS1에 가까운 하나의 마이크로 데이터센터로부터 BS2에 가까운 다른 마 이크로 데이터센터로의 이동일 수 있다. 이동하는 클라이언트(예를 들어, 서비스 요청자)를 따라 잡기 위해 워크로드를 하나의 물리적 에지 노드로부터 다른 물리적 에지 노드로 이동하는 데는 몇 개의 물류 장애물이 연루될 수 있다. 예를 들어, 에지 서비스를 이 동하는 프로세스는 일반적으로 그 에지 서비스와 연관된 상태를 한 위치의 한 호스트로부터 다른 위치의 다른 호스트로 이전하는 것을 포함한다. 실제 서비스 인스턴스와 그 세션은 이전된 상태를 사용하여 제 1 호스트에 서 종료(예를 들어, 퇴장, 정지 등)되고 제 2 호스트에서 개시(예를 들어, 시작, 부팅 등)될 수 있다. 이러한 프로세스는 보통 물리적 위치를 이동하는 지속적인 서비스로서 요청자에게 제공되기는 하지만, 요청자는 물리적위치가 실제로 이동하고 있다는 것을 알아챌 수 없을 수 있다. 연관된 상태가 이전 호스트로부터 다음 호스트 로 이동되고 있는 동안 서비스 실행에서 충분히 큰 중단이 있다면 연속 서비스라는 환상은 없어질 수 있다. 애플리케이션 정교화가 계속 증가함에 따라, 세션 상태로서 이전되는 정보의 볼륨 또한 증가한다. 따라서, 요 청자가 한 지점으로부터 다른 지점으로 이동함에 따라 에지 인프라스트럭처의 서로 다른 컴퓨테이션 지점에서 주어진 애플리케이션을 실행하기 위한 예측 가능하고 짧은 지연시간을 유지하는 것이 더 어려워질 수 있다. 점 차적으로, 엔드-투-엔드 상호작용(예를 들어, 실시간 통신) - 이것은 모바일 비디오 분석 플랫폼과 상호작용하 는 모바일 비디오 감시 디바이스와 같은 예에서 일반적인 것임 - 에서, 중간 기지국이 각각의 끝단에서 바뀔 수 있더라도, 서비스의 동작 기대치를 충족시키기 위해 상호작용의 양쪽 끝단에서 지연시간의 증가는 제한되어야 한다. 이러한 문제를 해결하기 위해 여러 접근 방식이 시도되었다. 클라우드 게임, 증강 현실(AR) 또는 가상 현실 (VR)과 같은 시각적 또는 몰입형 애플리케이션에서와 같은 - 일부 솔루션은 특수 목적 플랫폼과 솔루션 전달 지 점을 사용함으로써 실시간으로 끊김없는 고품질 경험의 환상을 달성한다. 예를 들어, 스트리밍 비디오 서비스 를 전달하는 데 사용되는 네트워크와 같은 콘텐츠 데이터 네트워크(content data network)(CDN)는 일반적으로 자원이 충분한 고객 댁내 에지(consumer premises edge)(CPE) 서버를 사용하여 인접한 에지에 대용량 처리 캐퍼 빌리티를 내장한다. 이러한 설계에 의하면, 이러한 서비스는 구독자가 연결된 기지국이 변경되더라도 컴퓨테이 션 또는 데이터 호스트를 거의 이동할 필요가 없다. 또한, 서비스를 이동해야 할 때일지라도, 이동은 잘 프로 비저닝된 데이터 센터 규모 자원을 통해 수행된다. 그러나 CPE 기반 처리를 사용하는 CDN과 유사한 솔루션은 제공자가 대량의 인프라스트럭처를 자신의 인접 에지 데이터센터에서 생성하고 유지할 역량이 부족한 부각 중인 많은 서비스에 일반화될 수 없는 경우가 많다. 이 문제를 해결하기 위해, 서비스 마이그레이션(service migration)을 위한 데이터 이전이 요청자의 움직임과 함께 수행될 수 있다. 여기서, 세션(예를 들어, 서비스 상태) 마이그레이션을 위해 모델 기반 예측 기술이 사용될 수 있다. 예를 들어, 모델은 특정 요청자가 하나 이상의 잠재적인 다음 기지국과 통신하고 있는 현재 기지국으 로부터 요청자가 이동할 가능성을 연산할 수 있다. 또한, 마이그레이션을 위해 고려되는 적용 가능한 서비스 정보는 서비스 상태, 서비스 동작 자체, 서비스 데이터 또는 잠재적으로는 사용자 세션을 포함할 수 있다. 에지 컴퓨팅 시스템(예를 들어, 에지 클라우드 및 도 3 내지 도 22d에 도시된 에지 컴퓨팅 시스템 구성)에 서 적용 가능한 예에서, 모델은 현재 궤적(예를 들어, 방향, 속도, 움직임의 연속성 등)에 기초하여 가장 가능 성이 높은 다음 기지국을 식별할 수 있다. 예에서, 예측은 하나 초과의 가능한 타겟 기지국을 식별할 수 있다. 여기서, 모델은 가장 가능성이 높은 후속(예를 들어, 다음, 그 다음) 기지국 또는 스테이션도 추가로 식별할 수 있다. 예에서, 모델은 요청자 움직임의 이전 이력, 요청자에 의해 수행된 검색 쿼리 또는 (예를 들어, 매핑 또 는 네비게이션 서비스 사용하여) 요청자에 의해 설정된 실제 경로에 기초하여 요청자가 이동할 가장 가능성 높 은 기지국의 순서를 식별함으로써 동작할 수 있다. 예에서, 모델은 요청자가 식별된 기지국 사이를 이동할 수 있는 가장 가능성이 높은 순간을 예측한다. 이러한 예측에 기초하여, 데이터는 요청자에게 근접한 하나의 지점으로부터 각각의 제 2 또는 후속 근접 지점으로 서비 스 세션을 이동시키기 위해 집결될 수 있다. 예에서, 데이터는 요청자의 실제 이동에 앞서 송신(예를 들어, 스 트리밍, 멀티캐스트 등)된다. 저스트-인-타임에 발효되는 이러한 데이터의 사전 전송은 요청자가 예측된 궤도 를 따라갈 때 발생해야 하는 실제 데이터 양을 감소시킨다. 이러한 방식으로, 컴퓨트 자원이 데이터 위치로 이 동하더라도, 적절한 워크로드 및 서비스 데이터가 컴퓨트 자원으로 이동될 수 있다. 예에서, 모델은 음의 확률(negative probability)을 평가하도록 구성된다. 여기서, 음의 확률은 요청자가 이전 에 예측된 기지국의 시퀀스를 따르지 않을 확률이다. 이러한 예측은 요청자가 연결할 가능성이 없는 기지국으 로 미리 전송되는 데이터가 더 이상 그 기지국에서 버퍼링될 필요가 없기 때문에 자원을 풀리게 할 수 있다. 이것은, 예를 들어 요청자가 따라가고 있는 궤적이 요청자의 이동 경로와 관련하여 의도의 변경을 강하게 시사 하는 식으로 이전에 예측되었던 궤적으로부터 멀어질 때 발생할 수 있다. 예측 모델은 서비스 상태 데이터가 초기 단계에서 이동되어 복잡한 데이터를 이전시킬 추가 시간을 제공할 수 있는 메커니즘을 제공한다. 따라서, 데이터를 전송하는 지연시간이 요청자에게 효과적으로 숨겨질 수 있다. 이러한 예측 모델은 또한 요청자 이동 패턴의 변화에 자연스럽게 적응한다. 예를 들어, 사고 또는 정체로 인해 고속도로에서 탈선이 있을 때, 모델은 그러한 관측에 반응하여 차량이 받아들일 가능성이 가장 높은 상이한 경 로로 예측을 동적으로 변경한다. 데이터 이전 지연시간을 줄이거나 없애는 것 외에도, 예측 모델은 서비스가 인스턴트화되어야 하는 시간에 앞서 인프라스트럭처가 요청자의 요구를 충족시키거나 초과하는 자원을 사전 오케스트레이션(예를 들어, 사전 프로비저닝)할 수 있는 가능성을 창출한다. 이러한 프로세스에서, 이것은 동적 최적화의 기회를 창출한다. 예를 들어, 모델은 노드의 시퀀스 중 예측된 다음 노드에서 가속기의 사전 할당을 가능하게 하고 가속기를 미리 프로그램하여 초기화 지연시간을 회피할 수 있다. 도 38은 사전 프로비저닝된 핸드오프를 위한 머신 학습 시스템을 훈련하고 사용하는 예를 도시한다. 도 시된 시스템은 예측 및 실행 서브시스템의 컨텍스트에서 동작하는 다음과 같은 컴포넌트: 궤적 캡처 및 연관 서브시스템, 궤적 누산기, 컨텍스트, 서비스 및 사용자 데이터베이스, 궤적 데이터베이스 , 훈련 서브시스템, 원격 측정 서브시스템을 포함한다. 궤적 누산기는 요청자의 디바이스와 요청자가 상호작용하는 기지국 사이의 거리 벡터를 연산하도록 구성 된다. 이러한 벡터는 기지국의 아이덴티티 및 타임스탬프와 함께 기록된다. 궤적 누산기는 다양한 기지 국에 들어가거나 나갈 때 요청자 디바이스에 의해 이동되는 경로를 인코딩하는 궤적 벡터를 연산하도록 구성된 다. 예에서, 디바이스에 의해 경로를 따라 발생된 평균 속도가 또한 (예를 들어, 연산된 궤적 벡터와 함께) 기 록된다. 이러한 정보는 에지 데이터베이스에 저장된다. 예에서, 데이터는 디바이스 자체에 캐시될 수 있다. 이러한 정보의 캡처는 디바이스 작용 또는 에지 클라우드에서 디바이스 프록시의 사용에 기초할 수 있다. 이러 한 정보의 정확성은 이 정보가 주로 예측에 사용되고 부정확한 예측의 결과가 종종 단순히 일부 효율성의 손실 이기 때문에 매우 정확할(예를 들어, 섬세할) 필요는 없다. 궤적 데이터베이스는 궤적 누산기에 의해 연산되거나 수집된 궤적을 저장하도록 구성된다. 데이터 베이스는 사용자(예를 들어, 인간 사용자), 궤적이 수집된 서비스 또는 애플리케이션, 또는 유연하게 정 의될 수 있는 다양한 의미있는 컨텍스트와 같은 데이터베이스의 컨텍스트 속성과 함께 저장된 궤적을 증 강하도록 구성될 수 있다. 컨텍스트의 예는 \"나의 쇼핑 여행\", \"집에서 직장까지 경로\" 등과 같은 경로의 이름 일 수 있다. 컨텍스트는 선택적으로 사용자에 의해 제공될 수 있고, 요청자 애플리케이션(예를 들어, 네비게이 션 애플리케이션) 등에 의해 프로그램 방식으로 인코딩될 수 있다. 훈련 서브시스템은 훈련, 평가 및 지속적인 개선을 기본 예측 모델에 제공하도록 구성된다. 이것은 지휘 된(directed), 지휘되지 않는(undirected) 또는 반 지휘된(semidirected) 머신 학습 기술을 통해 성취될 수 있 다. 궤적 정보와 컨텍스트 데이터가 수집되고 교차 연결됨에 따라, 주어진 사용자에 대한 빈번하고 빈번하지 않은 경로 시퀀스 및 많은 사용자가 따라가는 공통(예를 들어, 공유) 경로는 평가되고 예측 모델을 훈련하는 데 사용될 수 있다. 이러한 데이터는 또한 훈련 서브시스템에 의해 사용되어, 어떤 예측이 시간의 임계 퍼 센트를 초과하여 참(true)을 유지하지 못하는지를 기록함으로써, 이전에 훈련된 예측 모델을 개선할 수 있다. 일반적으로, 훈련은 감독되지 않을 수 있다; 그러나 훈련에 지휘된(예를 들어, 감독된) 또는 반 지휘된 교정 또 는 개선이 또한 사용될 수 있다. 예를 들어, 시스템은 인간에게 비정상적인 것으로 알려진 다양한 궤적(예를 들어, John Anderson이 일부 진행 중인 비상 활동이 있는 도로의 일부를 단지 뛰어 넘기 위해 따라갔던 색다른 궤적)을 제외할 수 있다. 모델 훈련 노드는 훈련 모델로부터 고위험 궤적이 필터링되어 (예를 들어, 옵트-아웃 방식(opt-out manner)의) 모델 조작의 대상이 되지 않도록 할 수 있는 LSM 시행 지점일 수 있다. 위의 훈련의 결과는 도 38에서 모델 3A로서 도시된 모델이다. 모델 3A는 현재 관찰된 궤적에 기초하여 궤적 예측을 생성한다. 따라서, 예를 들어, 모델 3A는 먼저 현재 관측된 궤적에 기초하여 최대 우도 종착지 (maximum likelihood end destination)를 예측한 다음 예측된 종착지 및 현재 관측된 궤적에 기초하여 가장 가 능성이 높은 전방 궤적을 예측할 수 있다. 원격 측정 서브시스템은 애플리케이션 지연시간 또는 데이터 강도와 같은 원격 측정 메트릭을 수집하고 저장하도록 구성된다. 애플리케이션은 한 기지국에서 다음 기지국으로 이전되어야 하는 다양한 정도의 데이터 의 양에 민감할 수 있다. 이전되어야 하는 데이터의 양이 매우 적다면, 예측 모델을 훈련하거나 최신 상태로 유지하는 데 많은 노력을 들이는 것은 특별히 도움이 되지 않는다. 이러한 감도는 애플리케이션마다 다를 수 있다. 예를 들어, 음성 전화 통화는 이전되는 정보의 양이 적고 작은 지터가 전화 통화의 인식 품질에 큰 영향 을 미치지 않을 수 있기 때문에 기지국 간의 상태 전송에 크게 민감하지 않을 수 있다. 그러나 고해상도 라이 브 비디오 프레젠테이션은 특히 민감할 수 있다. 이러한 애플리케이션 지연시간 민감도 및 데이터 강도 인자는 각각의 투영된 궤적에서 당면할 기지국의 시퀀스의 예측과 함께 사용되는 원격 측정 정보로서 캡처될 수 있다. 예에서, 주어진 애플리케이션과 그 사용 컨텍스트와 관련하여 수집된 원격 측정 데이터는 데이터베이스를 채우거나 히스토리 데이터 풀을 생성하는 데 사용될 수 있다. 예에서, 이러한 데이터 풀은 데이터를 훈련 서브 시스템에 제공하여 (모델 3B로서 도시된) 제 2 예측 모델을 생성할 수 있다. 이러한 제 2 모델은 애플리케이션의 데이터를 모델 3A에 의해 예측되는 하나 이상의 다음 기지국에 인접한 컴퓨트 노드로 사전 전송하는 것이 바람직한 시기를 예측한다. 예측 및 실행 서브시스템은 모델(예를 들어, 두 개의 훈련된 모델 3A 및 3B)을 호출하여 각각 (예를 들어, 모델 3A를 사용하여) 주어진 현재 궤적으로부터 전방 경로상의 목적지 및 (예를 들어, 모델 3B을 사용하여) 현재 원격 측정이 제공한 애플리케이션의 지연시간 민감도를 예측하도록 구성된다. 이러한 모 델 3A 및 3B의 출력에 기초하여, 예측 및 실행 서브시스템은 주어진 애플리케이션(예를 들어, 서비스)이 마이그레이션될 미래의 컴퓨트 노드로의 데이터 마이그레이션을 사전에 시작하도록 구성된다. 예에서, 궤적이 계속 업데이트됨에 따라, 모델 3A는 이제 이전에 예측된 미래 경로가 더 이상 이전에 투영된 것이 아니라고 예 측할 수 있다. 예에서, 예측 및 실행 서브시스템은 회수 컴포넌트를 포함한다. 회수 컴포넌트는 서비스가 더 이상 마이그레이션되지 않을 노드로 이전에 사전에 마이그레이션된 데이터가 삭제되거나, 그렇지 않으면 데이터 및 자원이 회수될 수 있다는 것을 전방 노드와 통신하도록 구성된다. 이것은 회수된 자원을 다 른 요구에 배치될 수 있게 한다. 핸드오프 및 보안 스토리지를 관리하기 위한 제 1 예시적인 방법(예 J1)은 (이를테면, 노드 또는 디바이스 (2200, 2232, 2240 또는 2250)에서 또는 이에 의해 구현되는) 처리 회로를 사용하여 수행되는 방법으로서, 방법 은, 요청자 디바이스의 위치 이동 정보를 획득 - 요청자 디바이스는 모바일 무선 네트워크의 제 1 기지국을 통 해 동작하는 에지 컴퓨팅 서비스에 연결되어 있음 - 하는 단계; 예측 모델을 사용하여, 모바일 무선 네트워크의 하나 이상의 다른 기지국 사이에서 요청자 디바이스의 추정된 위치 예측을 생성 - 하나 이상의 다른 기지국은 에지 컴퓨팅 서비스를 동작할 수 있음 - 하는 단계; 및 요청자 디바이스의 추정된 위치 예측을 사용하여, 에지 컴퓨팅 서비스의 데이터를 식별하고 제 1 기지국으로부터 하나 이상의 다른 기지국으로 포워딩하는 단계를 포함 한다. 제 2 예(예제 J2)에서, 예 J1의 주제는, 에지 컴퓨팅 서비스의 데이터가 서비스 상태 데이터인 구성을 포함하고, 여기서 서비스 상태 데이터는 요청자 디바이스의 실제 이동 전에 하나 이상의 다른 기지국에 제공된 다. 제 3 예(예 J3)에서, 예 J1-J2의 주제는, 예측 모델이 요청자 디바이스의 이동 궤적, 요청자 디바이스 또는 에 지 컴퓨팅 디바이스와 연관된 이전 이력, 또는 요청자 디바이스 또는 모바일 무선 네트워크와 연관된 매핑된 경 로에 기초하여 추정된 위치 예측을 추론하도록 훈련되는 구성을 포함한다. 제 4 예(예 J4)에서, 예 J1-J3의 주제는, 추정된 위치 예측이 하나 이상의 다른 기지국 사이에서 예측된 이동 시퀀스를 포함하는 것을 포함한다. 제 5 예(예 J5)에서, 예 J4의 주제는, 추정된 위치 예측이 음의 확률에 기초하는 것을 포함하며, 음의 확률은 하나 이상의 다른 기지국 사이에서 예측된 이동 시퀀스를 요청자 디바이스가 따라가지 않을 확률이다. 제 6 예(예 J6)에서, 예 J5의 주제는, 자원이 음의 확률에 기초하여 하나 이상의 다른 기지국 사이에 풀리는 것 을 포함한다. 제 7 예(예 J7)에서, 예 J1-J6의 주제는, 추정된 위치 예측이 하나 이상의 다른 기지국 사이에서 요청자 디바이 스의 예측된 이동 시간을 표시하는 것을 포함하고, 여기서 데이터의 식별 및 포워딩은 요청자 디바이스의 예측 된 이동 시간에 기초하여 발생한다. 제 8 예(예제 J8)에서, 예 J1-J7의 주제는, 에지 컴퓨팅 서비스의 데이터의 식별 및 포워딩은 요청자 디바이스 의 이동에 앞서, 하나 이상의 다른 기지국 사이에 위치한 가속기 회로를 미리 프로그램하는 데 사용되는 것을 포함한다. 제 9 예(예제 J9)에서, 예 J1-J8의 주제는, 예측 모델이 궤적 벡터에 기초하여 훈련되는 머신 학습 모델인 구성 을 포함하며, 궤적 벡터는 요청 디바이스 및 서비스 기지국으로부터의 훈련 데이터와 연관된다. 제 10 예(예 J10)에서, 예 J1-J9의 주제는, 위치 이동 정보가 제 1 기지국을 통해 동작하는 에지 컴퓨팅 서비스 의 사용량으로부터 생성된 원격 측정 정보를 포함하는 것을 포함한다. 다양한 설정에서, 예 J1-J10(및 데이터 또는 서비스 핸드오프의 다른 양태)은 정의된 애플리케이션 프로그래밍 인터페이스 또는 인터페이스 사양; 핸드오프 동작을 호출, 수신 또는 제어할 통신 프로토콜, 메시지 또는 정의 의 사용; 및 에지 컴퓨팅 환경 내에서 핸드오프를 위한 정책 및 로직의 다른 사용 및 구현의 결과로서 관찰되거 나 모니터링될 수 있다. 추가 예에서, 예 J1-J10은 데이터 또는 서비스 핸드오프를 위한 컨텍스트 데이터의 캡 처, 사용 또는 조작을 포함할 수 있다. 예 J1-J10 및 이러한 핸드오프 관리 기술의 다른 양태는 또한 (예를 들어, FaaS 또는 EaaS 설정에서 서비스 사이에서 핸드오프 및 자원 할당을 수행하는) 서비스 동작 및 서비스 기능 의 결과로서 관찰되거나 구현될 수 있다. 또한, 예 J1-J10의 방법은 에지 컴퓨팅 시스템에서 (예를 들어, 명령 어가 실행될 때 방법을 수행하는 머신 판독 가능 매체와 함께) 구현된 명령어로서 또는 (예를 들어, 방법을 수 행하거나 성취하는 구성을 포함하는 장치와 함께) 구현된 하드웨어 구성으로서 제공될 수 있다. 따라서, 예 J1-J10의 특징(및 핸드오프 및 자원 할당의 다른 특징)은 시스템 오케스트레이터 또는 설계자에 의해 조정되거 나 설계된 대로, 본 명세서의 임의의 다른 예와 결합되어 에지 클러스터 또는 에지 클라우드 시스템을 구성할 수 있다. 자동적 데이터 복제(Automatic Data Replication)의 예 에지 컴퓨팅 환경 내에서는 서비스 탄력성, 가용성 및 전반적인 안정성에 대한 다양한 요구 사항과 기대가 존재 한다. 예를 들어, 비디오 분석은 에지 클라우드 내에서 실행될 것으로 기대되는 상위 워크로드 중 하나이며, 특정 비디오 스트림에 대한 데이터 처리의 99 % 레벨의 탄력성 또는 안정성을 보장하는 일부 투영된 요구 사항 이 계획되어 있다. 일반적으로, 탄력성과 안정성은 클라우드 컴퓨팅 설정에서 서비스 복제 및 중앙 집중화를 통해 달성될 수 있다. 예를 들어, 서비스의 다수의 인스턴스는 동일한 클라우드 데이터 센터에서 백업 서비스 또는 특정 안정성 레벨 이 충족되지 않을 때 인스턴스화될 서비스를 사용하여 설정될 수 있다. 다른 클라우드 위치에서 만들어진, 모두 중앙 서비스 오케스트레이터에 의해 관리되는 백업 서비스 또는 데이터 집계기가 또한 있을 수도 있다. 그러나 에지 클라우드 인프라스트럭처에서, 상이한 유형과 크기의 데이터 센터가 단일 노드로부터 다수의 랙 서버에 이 르기까지 서로 다른 위치에서 존재한다. 또한, (MEC 배치를 비롯한) 많은 에지 클라우드 배치에서, 클라우드 컴퓨팅 서비스 관리의 사용은 적합하지 않을 수 있는데 왜냐하면 많은 유형의 에지 노드가 분산된 위치에서 이 용 가능하기 때문이다. 그러므로 에지 클라우드 인프라스트럭처는 고유한 속성을 사용하여 이러한 안정성을 보 장하는 자체의 방법이 필요하다. 분산 에지 클라우드 처리 시나리오에서, 서비스를 위한 자원은 에지 컴퓨팅 환경 내에서 광범위하게 이용 가능 하다; 그러나 개별 에지 노드 또는 서비스 조정자는 서비스를 실행하는 방법과 시기 또는 서비스를 실행할 위치 를 알지 못할 수 있다. 또한, 한 노드로부터 다른 노드로 서비스 마이그레이션이 발생할 때, 중단 및 컨텍스트 의 손실이 있을 수 있다. 다음은 이러한 문제를 해결하고 에지 컴퓨팅 환경에서 서비스의 안정성과 탄력성에 대한 개선을 가능하게 한다. 에지 컴퓨팅 시스템(예를 들어, 에지 클라우드 및 도 3 내지 도 22d에 도시된 에지 컴퓨팅 시스템 구성)에 서 적용 가능한 다음의 기술에 의하면, 에지 컴퓨트 노드에 걸쳐 서비스 데이터를 복제함으로써 탄력성이 획득 될 수 있다. 서비스를 복제하거나 복사하는 대신, 서비스에 의해 사용 및/또는 생성되는 데이터는 실시간으로 복제되고, 백업 서비스 시나리오에서 필요할 때 사용될 수 있다. 복제는 운영상의 필요에 따라, 사용 중이거나 현재 관련 있는 모든 데이터, 또는 서비스 전달 또는 서비스 탄력성에 필요한 일부 데이터 서브세트 또는 일부 로 구성될 수 있다. 예를 들어, 복제 프로세스는 소량의 복제로 시작하여, 필요성을 평가한 다음, 필요하다면 더 큰 복제가 뒤를 이을 수 있다. 이러한 형태의 복제를 통한 안정성은 두 가지 방법: (a) 다수의 에지에 걸쳐 데이터를 복제하는 방법; 또는 (b) 처리될 데이터를 에지 노드의 파이프 라인(예를 들어, 거리 캐비닛 -> 셀 타워 -> 중앙국)으로 복제하는 방법 중 하나의 방법으로 달성될 수 있다. 어느 하나의 접근 방식을 사용하여 데이터 복제를 구현하는 프로토콜은 에지 컴퓨팅 플랫폼에서, 또는 지능형 NIC 또는 다른 프로그램된 네트워킹 하드웨어를 사용하여 구현될 수 있다. 이와 같은 데이터 복제의 사용은 비용이 많이 들 수 있는 (또는 성능 트레이드오프의 대상이 될 수 있는) 동일한 에지 위치에서 서비스의 복제를 회피할 수 있다; 또한, 데이터를 복제함으로써, 복제된 데이터와 결과적인 임의의 백업 서비스는 통신 및 컴퓨테이션 부하에 기초하여 유연하게 재 할당되거나 적응될 수 있다. 또한, 이러한 데이터 복제는 각각의 에지 위치가 이력 데이터 및 데이터를 지속성 있게 만드는 역량에 기초하여 상이한 레벨의 신뢰 또는 안전성 인자를 가질 수 있다는 점을 고려할 수 있다. 다수의 에지 노드에 걸친 복제의 예에서, 중앙 에지 오케스트레이터는 에지 위치(예를 들어, 위치 A)에서 서비 스를 발생하고 다른 에지 위치(예를 들어, 위치 B)에서 최소 자원이 (비디오 피드와 같은) 처리된 데이터 만 복 제하는데 사용되는 최소 복제기 서비스를 발생할 수 있다. 실제 서비스는 실행되지 않는다. 데이터는 폐기되 기 전에 이동성 시간 윈도우(moving time window) 동안 위치 B에 저장된다. 위치 B는 데이터를 받고 메시지가 위치 A 또는 서비스 발생을 위한 오케스트레이터로부터 수신될 때 작동할 것이다.에지 노드의 파이프 라인에 걸친 데이터의 복제에는 지연시간을 희생하더라도, 복제를 위한 업스트림 위치를 선 택하는 것이 수반될 수 있다. 예를 들어, 거리 캐비닛은 비디오 스트림에 가장 가까운 낮은 지연시간 에지 호 스트일 수 있고, 셀 타워가 파이프 라인에서 다음 번이고, 그 뒤를 이어 중앙국이 있다. 에지 호스트로부터의 데이터는 이러한 안정성을 보장하기 위해 파이프 라인의 다음 에지 위치에서 복제될 수 있다(예를 들어, 셀 타 워로부터 중앙국으로 복제된다). 주 서버에 문제가 있는 경우, 파이프 라인에서 이용 가능한 다음 에지 노드가 인계 받을 수 있다. 이러한 파이프 라인 기반 복제는 제한된 자원 또는 제약 사항(이를테면, 태양 광 발전 장 비에 의한 전력 제약 사항)의 에지 컴퓨트 노드를 지원할 수 있으며 하드웨어와 소프트웨어의 조합에 의해 제어 될 수 있다. 도 39는 에지 컴퓨팅 서비스 배치의 컨텍스트 내에서, 다수의 에지에 걸쳐 데이터 복제가 어떻게 실현될 수 있는지에 대한 예를 도시한다. 다수의 테넌트 또는 엔티티 사이에서 서비스의 다수의 플레이버를 실행하는 데 적용 가능한, 다수의 서버 및 노드가 도시된다. 도시된 컨텍스트에서, 도 39는 (에지 게이트웨이에서 동작하는) 오케스트레이터에 의해 할당되고 제어되는 두 개의 상이한 에지 위치(에지 위치 1, 에지 위치 2) 사이에서 데이터 복제가 수행되는 서비스를 도시한다. 서비스의 실행을 위한 위치(서비스)가 식별되면, 오케스트레이터는 데이터 복제 서비스(서비스)를 발생한다. 그 다음에 각각의 에지 노드 위치 에 있는 안정성 관리 컴포넌트(3941, 3942)는: (데이터 복제를 사용하여) 데이터를 적절한 데이터 복제 서비스로 포워딩하고; 서비스에 대해 중단 또는 과부하가 예상되는 경우 서비스 복제를 활성화하거나 백업 서비 스를 시작하는 메시지를 전송하는 역할을 한다. 데이터 복제 서비스(서비스)는 제 2 에지 위치에서 실행되고 안전성 관리 컴포넌트(reliability management component)(RMU)에 의해 능동적으로 관리된다. 데이터 복제 서비스는 (동일한 서버 상에서 또는 제 2 에지 위치의 다른 서버 상에서) 백업 서비스에 의해 사용하기 위한 데이터를 복제한다; 백업 서비스는 필요할 때까지 아무 것도 하지 않지만 데이터를 계속 수신한다. 이러한 방식으로, 데이터는 서 비스 동작을 복제할 필요없는 방식으로 복제되지만, 서비스는 필요할 때 적절한 상태로 시작될 수 있기도 하다. 데이터 복제 서비스는 중요한 데이터가 복제될 수 있도록 이동성 시간 윈도우 시간프레임에서만 데이터를 수집하는 서비스로 정의될 수 있으며, 서비스는 장애 조치 또는 로드 문제 중에 필요에 따라 재 생성될 수 있다. 추가 예에서, RMU는 얼마나 많이 어떤 데이터가 복제되어야 하는지를 동적으로 결정하고; 한 번에 하나 초과의 서비스에 대해 이러한 동적 복제를 수행할 수 있다. RMU은 데이터를 백업 서비스(들)에 능동적으로 전송하고 서비스 불규칙성 또는 중단을 예측하는 역할을 한다. 이러한 예측은 다른 모니터링 컴포넌트로부터의 정보, 서비스 패턴을 추적하는 데 사용되는 머신 학습 알고리즘, 외부 상황 모니터링 센서, 애플리케이션과의 인터페이싱, 수집된 원격 측정 값 등과 같은 다양한 인 자에 기초할 수 있다. RMU 컴포넌트는 또한 다른 RMU로부터 메시지를 수신하고 백업 서비스의 가동 (spinning up)과 같은 요청에 따라 작동하는 역할을 한다. 또한, RMU는 에지 위치에서 이용 가능한 전반 적인 안정성 또는 캐퍼빌리티의 일부로서 데이터를 지속성 있게 만드는 중요한 역할을 하는, 연결성을 추적하는 기능을 한다. RMU는 (랙 서버가 배치될 수 있는 에지 위치의 경우) 랙 상단(Top of Rack)(ToR) 스위치 또는 (단일 또는 다중 서버 에지 설치의 경우) 플랫폼 NIC의 컴포넌트로서 구현될 수 있다. RMU는 또한 다른 하드웨어 컴 포넌트(서버 슬레드, 회로 등) 내에서도 구현될 수 있다. 에지 컴퓨팅 위치의 서버 인스턴스에는 데이터 복제 서비스를 할당할 필요가 없다. 추가 예에서, 데이터 복제 서비스는 플랫폼 NIC 또는 랙의 TOR 스위치 내에서 직접 실행될 수 있다. 예를 들어, RMU는 이동 성 시간 윈도우에 의해 필요한만큼 오래 데이터를 저장하거나 유지할 수 있으며, 일회분의 프레임에 대한 시간 윈도우가 완료될 때, 프레임은 폐기된다. 이것은 실시간 대응이 가능하므로, 서비스 장애가 발생하면 현재 상 태 데이터는 즉시 이용 가능하고, 백업 서비스는 현재 상태 데이터로 신속하게 가동될 수 있다. (예를 들어, 에지 클라우드 사이에서) 자동적 데이터 복제를 구현하기 위한 제 1 예시적인 방법(예 K1)은 (이를 테면 노드 또는 디바이스(2200, 2232, 2240 또는 2250)에 의해 구현되는) 처리 회로를 사용하여 수행되는 방법으로서, 방법은, 제 1 에지 컴퓨팅 노드의 서버 인스턴스에서 동작하는 서비스의 데이터를 캡처 - 데이터에 관련한 데이터는 서비스에 의해 소비되거나 생성됨 - 하는 단계; 서비스의 데이터를 제 1 에지 컴퓨팅 노드로부 터 제 2 에지 컴퓨팅 노드의 서버 인스턴스로 복제 - 제 2 에지 컴퓨팅 노드의 서버 인스턴스는 비 실행 상태의 서비스의 백업 인스턴스를 갖고 있음 - 하는 단계; 제 1 에지 컴퓨팅 노드에서 안정성 문제를 식별할 때, 제 2 에지 컴퓨팅 노드상의 서비스의 백업 인스턴스에게 실행 상태에 진입하도록 지시 - 실행 상태는 복제된 데이터를 활용함 - 하는 단계를 포함한다. 제 2 예(예 K2)에서, 예 K1의 주제는, 방법의 동작이 제 1 에지 컴퓨팅 노드에서 동작하는 안정성 관리 컴포넌 트에 의해 수행되는 것을 포함한다. 제 3 예(예 K3)에서, 예 K2의 주제는, 안정성 관리 컴포넌트가 에지 컴퓨팅 게이트웨이에서 동작하는 오케스트 레이터의 제어하에 있는 것을 포함한다. 제 4 예(예 K4)에서, 예 K3의 주제는, 제 2 에지 컴퓨팅 노드의 제 2 안정성 관리 컴포넌트가 복제된 데이터를 수신하도록 동작하는 것을 포함한다. 제 5 예(예 K5)에서, 예 K2-K4의 주제는, 안정성 관리 컴포넌트가 제 1 에지 컴퓨팅 노드와의 통신을 제공하는 네트워크 인터페이스 카드 또는 스위치의 회로에 의해 동작되는 것을 포함한다. 제 6 예(예 K6)에서, 예 K2-K5의 주제는, 제 2 에지 컴퓨팅 노드상의 서비스를 제어하기 위한 동작이 제 2 에지 컴퓨팅 노드에서 동작하는 제 2 안정성 관리 컴포넌트에 의해 수행되고, 제 2 안정성 관리 컴포넌트가 데이터를 서비스의 백업 인스턴스에 제공하고 서비스의 백업 인스턴스의 실행 상태를 제어하는 데 사용되는 것을 포함한 다. 제 7 예(예 K7)에서, 예 K1-K6의 주제는, 복제된 데이터가 시간 윈도우에 기초하여 유지되는 것을 포함한다. 제 8 예(예 K8)에서, 예 K1-K7의 주제는, 제 1 에지 컴퓨팅 노드 및 제 2 에지 컴퓨팅 노드가 분산 에지 컴퓨팅 시스템의 계층의 네트워크 피어인 것을 포함한다. 제 9 예(예 K9)에서, 예 K1-K8의 주제는, 제 1 에지 컴퓨팅 노드 및 제 2 에지 컴퓨팅 노드가 분산 에지 컴퓨팅 시스템 내의 컴퓨팅 파이프라인의 상이한 계층에 위치하는 것을 포함한다. 제 10 예(예 K10)에서, 예 K1-K9의 주제는, 안정성 관리 컴포넌트가 어떤 데이터를 동적으로 복제할지를 결정하 고, 복수의 서비스 사이에서 동적으로 복제를 수행하는 것을 포함한다. 다양한 설정에서, 예제 K1-K10(및 자동적 데이터 복제의 다른 양태)은 정의된 애플리케이션 프로그래밍 인터페 이스 또는 인터페이스 사양; 데이터 복제 동작을 호출, 수신 또는 제어할 통신 프로토콜, 메시지 또는 정의의 사용; 노드 연결 해제 상태; 및 에지 컴퓨팅 환경 내에서 데이터 복제를 위한 정책 및 로직의 다른 사용 및 구 현의 결과로서 관찰되거나 모니터링될 수 있다. 예 K1-K10 및 이러한 데이터 복제의 다른 양태는 또한 (예를 들어, FaaS 또는 EaaS 설정에서 다수의 서비스 사이에서 데이터를 복제하는) 서비스 동작 및 서비스 기능의 결 과로서 관찰되거나 구현될 수 있다. 또한, 예 K1-K10의 방법은 에지 컴퓨팅 시스템에서 (예를 들어, 명령어가 실행될 때 방법을 수행하는 머신 판독 가능 매체와 함께) 구현된 명령어로서 또는 (예를 들어, 방법을 수행하거 나 달성하는 구성을 포함하는 장치와 함께) 구현된 하드웨어 구성으로서 제공될 수 있다. 고객 댁내 장비 기반 실행 포워딩(Customer Premise Equipment-based Execution Forwarding)의 예 추가 예에서, 고객 댁내 장비는 에지 플랫폼이 인증되고 신뢰성 있는 방식으로 에지 서비스에 대한 원격 측정을 게시하고 활용하는 분산된 (그러나 조정된) 원격 측정 아키텍처를 실시 가능하게 할 수 있다. 에지 컴퓨팅 시 스템(예를 들어, 에지 클라우드 및 도 3 내지 도 22d에 도시된 에지 컴퓨팅 시스템 구성)의 에지 테넌트는 아키텍처에 걸쳐 분산된 서비스에 액세스하거나, 발견하거나 또는 모니터를 추가할 수 있다. 테넌트는 원격 측 정이 어떻게 언제 생성되는지를 입증할 수 있다. 아래에 설명된 원격 측정은 에지를 인식하고 조정된다. 원격 통신 서비스 제공자(Telecommunication Service Provider)(TSP)라는 용어는 연결성 및 콘텐츠를 제공할 수 있는 모든 공급 업체, 예를 들면 케이블 서비스 제공자, 전화/모바일 서비스 제공자, 인터넷 서비스 제공자, MEC 등 및 실제로 유선 및 라우터를 소유하지 않고도 서비스를 전달할 수 있는 Netflix와 같은 스패닝 콘텐츠 전송 네트워크(CDN) 제공자를 포괄하는 용어로 사용된다. 이러한 제공자는 정의된 양의 컴퓨테이션 또는 소프 트웨어 서비스를 고객에게 제공할 수 있는 Google, Amazon 등과 같은 클라우드 서비스 제공자(CSP)와는 다르다. CSP 서비스는 고객에 의해 지불 받거나 광고에 의해 지원될 수 있다. 오늘날 많은 TSP는 정보 스트리머로서의 핵심 캐퍼빌리티에 의거하여 에지에서 부가가치 서비스를 제공하기를 원한다. 그러나, 통상의 TSP 인프라스트 럭처는 CSP의 핵심 역량인 컴퓨팅 자원의 탄력성과 규모가 부족하다. 따라서 TSP는 충분한 컴퓨테이션 로드를 견딜 수 없고 주로 고객과 CSP 간의 파이프로서 기능을 한다. 전형적으로, TSP와 CSP 기반 컴퓨테이션 인프라스트럭처 간의 파이프는 확장 가능하지 않다. 파이프는 값 비싼 백홀 대역폭에 의해 제한되며 파이프는 물리적, 법적 또는 다른 장벽으로 인해 연결성이 제한되거나 또는 통신링크가 각각의 참가자에게 공유 자원으로서 이용 가능한 대역폭 할당이 제한되는 많은 지리적 지역을 가로 지를 수 있기 때문에 엔드 투 엔드 통신 인프라스트럭처를 점검하는 데 비용이 많이 든다. TSP는 CSP로부터 컴퓨팅 자원을 프로비저닝함으로써 자신이 제공하고 싶어할 수 있는 컴퓨테이션 집약적 서비스를 쉽고 저렴하게 찾을 수 없다. 이것은 컴퓨테이션 집약적 서비스가 자신이 제공할 준비가 된 데이터 집약적 서비스와 분리될 수 없 기 때문에 TSP를 향해 문제를 제기한다. 또한, 에지와 클라우드 간의 통신이 중요한 문제가 아닌 경우에도, TSP는 경제, 비즈니스 또는 고객 제어의 이 유로 CSP와 파트너가 되기를 꺼릴 수 있는데 왜냐하면 이차 서비스 제공자(예를 들어, 그저 약간의 이동자 (mover))의 역할로 강등되는 것을 원하지 않기 때문이다. 이것은 부분적으로 TSP가 에지 기반 인프라스트럭처 의 위치 접근성뿐만 아니라 애플리케이션/고객 데이터 및 컨텍스트의 위치 근접성에 의거하여 구축함으로써 서 비스를 전달하는 것이 대역폭 및 지연시간에 효율적이라고 보기 때문이다. TSP는 특히 빠르게 성장하는 경제 부문에서 사용자와의 근접성이 나타내는 가치가 동기가 될 수 있으며 소비자 기반의 더 많은 몫을 소유하기를 원할 수 있다. CSP와 동등한 역할을 달성하기 위해, TSP는 수요에 따라 탄력적으로 컴퓨트를 확장하거나 또는 다른 사람(예를 들어, CSP)에게 할증 요금을 지불하는 CSP와 유사한 역량을 구축해야 할 수 있다. CSP와 TSP는 둘 모두 수요에 따라 가격과 요금을 적응할 수 있으며, 판매 또는 입찰 정책을 더 잘 활용할 수 있다. CSP는 코로케이션 시설 (co-location facility)을 사용하여 서비스를 TSP의 고객 기반에 더 가깝게 이동하여 TSP 역할을 더욱 소외시킬 수 있다. 본 명세서에서 논의된 시스템 및 기술은 TSP가 자기의 통신 역량을 매칭하는 CSP의 컴퓨트 역량과 결 합할 수 있게 한다. 코로케이션(colocation)(CoLo) 서비스는 데이터 센터를 셀 타워 및 다른 근접 위치에 배치함으로써 클라우드 기 반 서비스로의 짧은 지연시간 액세스를 제공해 줄 수 있다. 클라우드 제공자는 또한 CDN 서비스 및 고객 댁내 장비(CPE) 서비스를 통해 자신의 에지 존재를 생성할 수도 있다. 반대로, CDN 콘텐츠는 에지 근처에 위치한 공 급 업체 소유의 특수 목적 데이터 센터에 의해 전달될 수 있지만, 제어 및 관리 평면은 공공 클라우드에서 구현 된다. TSP는 에지 컴퓨트 인프라스트럭처 제공자와 계약하거나, TPS가 클라우드 서비스 제공자에서 프로비저닝하는 인 프라스트럭처에 컴퓨테이션을 집어 넣거나, 또는 에지에/근처에 자체의 컴퓨트가 풍부한 데이터 센터를 구축하 여, 네트워크 기능 가상화(NFV), 소프트웨어 정의 네트워킹(SDN) 및 CDN 서비스에 있어서 핵심적인 통신 강점에 가까운 부가가치 서비스와 함께 데이터센터 경제성과 클라우드 민첩성을 달성할 수 있다. 이러한 컴퓨테이션의 금전적 또는 자원 비용은 실제 현재의 비용(또는 위에서 논의된 입찰 절차)을 따르도록 각각의 사용자의 프로필 에 매핑될 수 있다. 이전의 접근 방식은 TSP에게 별도의 자체 컴퓨팅 인프라스트럭처를 만들지 않고도 이미 에지에 근접해 있다는 고유한 기술적 이점을 기반으로 하는 일류 파트너로서 참여할 수 있는 역량을 제공하지 않는다. 이것은 TSP가 부가가치 데이터 서비스보다는 배관을 제공하는 결과를 초래한다. 소규모 TSP는 풍부한 컴퓨테이션 캐퍼빌리티 를 구축하고 유지하기 위해 증가된 투자 위험을 감수하거나 또는 자신의 수익의 일부를 포기하여 CoLo 인프라스 트럭처 제공자에게 지불해야 한다. TSP는 기지국 또는 CPE 인프라스트럭처로부터의 오케스트레이션을 이용하여 가정 및 소규모 기업 고객에서 호스 팅되는 가상 머신 또는 보안 컨테이너로부터 컴퓨테이션 인프라스트럭처를 구성한다. TSP는 CoLo 서비스 제공 자에 있는 TSP 소유 컴퓨터에 투자하는 대신, 자신의 직접적인 제어하의 무선 라우터 또는 다른 통신 중개자를 사용하여 TSP가 컴퓨테이션을 스케줄링하기 위해 필요한 동적이고 탄력적인 컴퓨테이션 평면을 함께 이어 붙일 수 있는 사설 네트워크에 덧씌운다. 시스템 및 기술은 베이스보드 관리 엔진과 같은 내장된 제어 지점을 비롯 한 원격 데이터 전송(remote data transmission)(RDT) 프로비저닝 및 보안 파티션을 하드웨어로 제공하여, 안정 적이고 보호된 공동 테넌시(co-tenancy)를 획득하고 물리적 제어의 대상이 아닌 컴퓨테이션 용량의 갑작스러운 손실 가능성을 줄이는 수단을 TSP에 제공한다. 이러한 접근 방식은 TSP가 수많은 데이터 근접성 및 대역폭 집약적 기회에 보조를 맞추기 위해 지속적으로 확장 되는 컴퓨테이션 사이클에 투자할 필요없이 고도로 확장 가능하고 탄력적인 협력 생태계를 창출하는 장점이 있 다. 그렇지 않았더라면 TSP 및 제 3 자 서비스 제공자를 손쉽게 주변적 역할로 제한할 수 있는 패권적 제 1 계 층 클라우드 서비스 제공자에 의해 지배되지 않는 다극화 시장이 창출된다. 에지는 가정, 소규모 비즈니스 및 온-보드 차량과 같은 모바일 장비에서 증가하는 컴퓨테이션 디바이스의 확산에 편승하는 고도로 확장 가능하고 컴퓨테이션하게 탄력적인 인프라스트럭처에 기초하여 형상화된다. 소유자는 TSP에 의해 사용될 수 있는 풀 및TSP의 기관에 의해 제공자에게 가교될 수 있는 서비스에 다양한 양의 컴퓨테이션을 약속할 수 있다. 본 명세서에서 사용되는 것으로, CSP는 고객 또는 광고가 다양한 서비스로서 모든것(anything-as-a-service)(X- aaS)이라는 제공물에 대해 비용을 지불하든 지불하지 않든, 서비스로서 인프라스트럭처(Infrastructure-as-a- Service)(IaaS), 서비스로서 플랫폼(Platform-as-a-Service)(PaaS), 서비스로서 소프트웨어(Software-as-a- Service)(SaaS), 서비스로서 기능(Function-as-a Service)(FaaS) 및 유사한 제공물을 고객에게 공급하는 공급 업체로서 정의된다. 일부의 경우, CSP가 일부 시장에서 자체의 통신 서비스를 창출할 때 TSP와 CSP는 동일한 기업일 수 있지만, TSP와 CSP 기반 컴퓨팅 인프라스트럭처 사이의 파이프가 고객과 TSP 사이의 라스트 마일 (last mile)에서 낮은 지연시간 및 높은 대역폭 자산으로 인해 에지에서 필요한 컴퓨트 수요의 증가에 따라 확 장 축소하여도 난조가 생기지 않는다면 본 명세서에서 논의된 시스템 및 기술은 방해받지 않는다. TSP는 고객과 신뢰 관계를 맺을 수 있다. 종종 이러한 관계 또는 서비스는 가입자 식별 모듈(subscriber identity module)(SIM) 카드, 고객의 홈/비즈니스 네트워크에 안전하게 통합된 라우터 등과 같은 하드웨어 요소 에 의해 고정된다. 이러한 신뢰 관계의 결과로서, TSP는 자신의 디바이스와 고객 디바이스에 안전하고 신뢰성 있는 소프트웨어 모듈을 설치할 수 있다. TSP는 신뢰성 있는 소프트웨어 모듈을 앵커 포인트 디바이스에 설치할 수 있으며, 고객의 사전동의(opt-in) 협 약에 따라 추가 모델을 고객 소유의 디바이스에 설치할 수도 있다. 따라서, 예를 들어, 유선/무선 서비스를 Jack과 Alice의 집에 도입하는 인터넷 서비스 제공자(ISP)(TSP)는 Jack과 Alice의 사전동의 협약에 따라 Jack의 가정용 컴퓨터와 Alice의 스마트 폰상의 \"ISP-파티션\" 소프트웨어 컴포넌트를 손에 넣을 수도 있다. 이러한 소 프트웨어 컴포넌트는 정부 또는 소비자 이익 단체와 같은 적절한 제 3 자에 의해 프라이버시와 보안이 보존되고 잘 가동되는 것으로 심사되고 인증된다. 이러한 컴포넌트는 고객 댁내 디바이스 또는 장비에 위치한 TSP의 \"경 량\" 오케스트레이터와 함께 작동하며 위에서 설명한 하드웨어 신뢰 루트에 완전히 통합된다. 이러한 경량 오케 스트레이터는 TSP에 의해 고객 댁내의 컴퓨팅 용량의 부분적이고 계량적이며 격리된 사용을 제공한다. 또한 경 량 오케스트레이터는 TSP가 TSP의 고객 기반에 걸쳐 동적으로 변하는 컴퓨트 용량을 집계하거나 풀링할 수 있도 록 한다. 따라서, 예를 들어, ISP에 의해 자신의 디바이스가 부분적으로 검침되고 격리된 사용을 받도록 사전동의한 다른 두 고객인 Bob과 Joanna는 자신의 디바이스를 유사하게 ISP에 의해 이용 가능하게 만들어 놓은 Jack과 Alice에 합류한다. TSP(예를 들어, ISP)는 이제 Jack, Alice, Bob, Joanna 등의 컴퓨트 사이클의 풀로부터 끌어올 수 있는 역량을 갖는다. TSP는 매우 많은 고객을 보유하고 있고 고객은 (예를 들어, IoT/스마트 디바이스의 확산 등으로 인해) 전형적으로 컴퓨트 디바이스의 수를 계속 증가시키기 때문에, TSP에게 이용 가능한 종합된 동적 컴퓨트 사이클은 TSP에 의한 임의의 주요 자원의 지출없이 구축된 고객 측 클라우드를 형성한다. TSP는 또한 경쟁사 CSP와 값 비싼 거래를 협상할 필요가 없다. ISP와 같은 하나의 TSP는 다른 TSP와 합쳐서 그러한 통합 및 유연성을 위한 훨씬 더 넓은 동적 풀을 얻을 수 있 다. TSP는 새로운 서비스를 제공하고, 서비스에 대해 고객이 지불하는 가격을 할인하고, 다른 캐퍼빌리티를 차 등제(sliding scale)로 제공하는 것 등을 행함으로써 이러한 컴퓨트 용량의 참여 또는 협력적 풀링을 우대조치 한다. TSP의 관리를 받는 라우터(TSP managed router)와 같은 TSP 제어 디바이스는 지속적으로 TSP에서 이용 가능하다는 것을 유의해야 한다. 제어(예를 들어, 허브)는 주로 라우팅 및 프로토콜 처리에 사용될 수 있다. 그럼에도 불구하고 이러한 제한된 컴퓨트 캐퍼빌리티는 거의 항상 켜져 있으며 TSP가 허브를 통해 네트워크로 연결된 고객의 컴퓨트 자원으로부터 TSP의 도메인으로 활용할 수 있는 부분적 컴퓨팅 역량을 오케스트레이션하 기에 충분한다. 고객이 자신의 디바이스를 소유하고 있고 이것을 언제든지 오프라인으로 전환할 수 있지만, 서비스 품질(QoS) 정의 또는 전체 SLA는 고객과 TSP 간에 협상될 수 있으며, 소프트웨어 컴포넌트에 의해 시행되어 TSP가 일부의 최소 시간 세분성(granularity)으로 이러한 디바이스의 가용성을 통해 다양하지만 매우 높을 정도의 예측 가능 성을 가능하게 한다(예를 들어, 디바이스는 1 초, 2 초 등의 최소 셧다운 기간 없이 오프라인으로 전환되지 않 을 것이다). QoS 협약은 모든 디바이스에서 충족되지 않을 수 있다. 예를 들어, 모바일 디바이스는 다양한 시 점에서 연락 불가하게 될 수 있다. 그러나 TSP는 최소 기간 동안 이용할 수 있고 연락 불가할 것으로 예상되는 다양한 고객 댁내의 디바이스에 대한 통계적 척도(예를 들어, 확률 분포 등)를 갖고 있다. 도 40에서, 부분 A는 CPE 기반 실행 포워딩을 위한 예시적인 광대역 기반 시스템의 블록도를 도시한다. 부분 A는 논리 컴퓨팅 파티션이 로컬 부하 QoS 정책 배열과 합동하여 가정 및 소규모 기업(디바이스 1- 4(4011, 4012, 4013, 4014))에서 생성되는 전형적인 모뎀 기반 광대역 서비스를 도시한다.도 40의 부분 B는 또한 CPE 기반 실행 포워딩을 위한 예시적인 무선 기반 시스템의 블록도를 도시한다. 부분 B는 원격 통신 제공자의 기지국/셀 타워 또는 제한된 에지 스테이션과 접촉하는 모바일/무선 커넥티드 호 스트(4061, 4062, 4063)상의 컴퓨팅 캐퍼빌리티를 위한 유사한 파티션의 생성을 도시한다. 도 41은 (메모리 및 CPU 사용의 비 제한적인 예의 목록을 비롯한) 예측 가능한 사용 및 CPE 기반 실행 포워딩을 위한 컴퓨트 용량의 할당을 달성하기 위한 정책 주도 접근 방식의 예시적인 기술의 흐름도를 도시한다. 도 41은 컴퓨팅 용량을 TSP 또는 이러한 컴퓨팅 용량을 필요로 하고 TSP에 의해 중개되는 제 3 자에게 할당하는 예측 가능한 수단을 달성하기 위한 테이블/정책 주도 접근 방식을 도시한다. 이 도면은 예를 들어, 고객 디바 이스의 네 개의 상이한 양의 컴퓨트 용량(4111, 4112, 4113, 4114)의 유연한 정책 또는 스케줄 기반 할당 (디바이스 대 TSP, 및 TSP에 제공된 메모리 파티셔닝의 대응하는 레벨)을 도시한다. 그러나 다른 양(또는 동일 한 양의 사용)도 존재할 수 있다. 도 42는 가속 제어 평면을 지원하기 위해, CPE 기반 실행 포워딩을 위한 원격 측정 및 컴퓨트 용량을 획 득하기 위한 예시적인 기술의 흐름도를 도시한다. 도 42는 다양한 규칙 또는 지원 특징에 기초하 여, TSP에 의해 획득되는 세밀한 원격 측정 및 컴퓨트 용량의 (예를 들어, 하드웨어, 소프트웨어 등의) 지원을 도시한다. TSP가 고객의 디바이스의 모음에서 갖고 있는 제어 지점을 사용하고 원격 측정 및 도 41 및 도 42에 도시된 고 객과 협상된 시간 정책을 사용하여, TSP는 도 40의 부분 A 및 B에 도시된 바와 같이 다양한 컴퓨트 조각을 할당 한다. TSP는 고객 또는 고객 디바이스상의 시스템 소프트웨어가 협상된 협약의 일시적인 중단을 주장할 수 있는 고객 디바이스에서 활성화되는 프록시 컴포넌트 내에서 추가 제어를 구현할 수 있다. 예를 들어, 고객은 다양한 시 간에 모든 가용 전력 또는 모든 가용 대역폭을 필요로 할 수 있고, 이 경우 고객은 인프라스트럭처의 조각을 일 시적으로 TSP에게 거부할 수 있다. 이것은 고객과 TSP가 고객과 TSP에게 투명하게 이용될 수 있는 원격 측정 및 로깅을 통해 협상되고 시행된/장려된 비즈니스 협약에서 파악된다. 하드웨어는 고객 디바이스상의 보안 제어 지점을 TSP의 프록시 컴포넌트에 제공할 수 있다. 이러한 제어는 엔 클레이브 및 다른 프로비저닝을 지원하여 CPE상에 자원 프로비저닝을 생성하는 다양한 레벨의 하드웨어에 통합 된 특정 기능의 형태일 수 있다. 이것은 고객으로부터 격리된 덧씌여진 컴퓨트 네트워크에서 유연한 집계를 위 한 고객 디바이스의 논리적 파티셔닝 캐퍼빌리티를 가능하게 한다. 이러한 보안 제어 지점은 또한 CPE의 스토 리지 또는 메모리로의 어떠한 액세스라도 엄격히 격리하는 것을 비롯하여 TSP에 약속되지 않은 남아 있는 고객 의 디바이스 용량에 잠재적으로 침입하는 것으로부터 고객을 보호한다. 따라서, 하드웨어 기반 무결성 및 격리 특징에 의해 지원되는 하이퍼바이저/OS 기반 캐퍼빌리티의 조합에 의해 보안 다중 테넌시가 제공된다. 원칙적 으로 이것은 CSP가 데이터 센터에서 CSP 인프라스트럭처의 다중 테넌트 공유를 위해 구현하는 격리와 유사하다. 일부 예에서, TSP는 피어 투 피어 컴퓨테이션 오프로드에 이용할 수 있는 24x7 개의 가용 하드웨어(예를 들어, 중소기업에 의해 상시 가동하는 것으로 설계된 컴퓨터, 가정/기업 기반 애플리케이션 서버, 파일 서버, 웹 서버 등)로부터 획득된 용량을 스케줄링하면서, 신뢰가 덜 한 가용 고객(예를 들어, 가정, 모바일 고객 등)으로부터 획득된 컴퓨테이션 용량을 사용하여 FaaS에 필요한 것과 같은 주로 짧은 버스트의 컴퓨팅 워크로드를 실행할 수 있다. 예에서, 고객은 외부 디바이스(예를 들어, 컴퓨팅 스틱 등)를 TSP가 소유한 라우터에 접속하여 외부 디바이스가 끌어 쓴 작은 전력 외에도 사용자에게 거의 영향을 미치지 않고 에지에서 항상 이용할 수 있는 다중 고객 클라 우드를 생성하는 데 동의할 수 있다. 이것은 TSP가 실제로 CoLo 제공자와 파트너 관계를 맺지 않고도 자체 CoLo 서비스를 창출할 수 있게 한다. CoLo 캐퍼빌리티는 고객 기반과 함께 성장하고 TSP가 어느 시점에서든 결 정할 수 있기에 업그레이드 가능하기 때문에 상당히 더 확장 가능하다. 예를 들어, TSP는 시간 경과에 따라 TSP가 고르지 않은 수요의 증가를 보게 되는 네트워크의 일부에서 선택적으로 컴퓨트 스틱의 차세대 컴퓨터로 진보할 수 있다. 이러한 경우, TSP는 무시할 수 있는 추가 가격으로 고객을 위한 로컬 CSP 역할을 할 수도 있 다. TSP는 최악의 경우 안전장치(backstop)로 지원되는 이러한 고객 기반 컴퓨트 컨테이너에서 새로운 컴퓨팅 작업 의 열망하는 스케줄링을 구현할 수 있다. 그러한 최악의 경우 안전장치는 고객의 컴퓨팅 디바이스가 오프라인 으로 진행될 때 중단되는 이러한 작업이 전해질 수 있는 다양한 기지국에서 제한된 양의 컴퓨팅 캐퍼빌리티로서 생성될 수 있다. 대안적으로, 이러한 작업은 TSP가 최악의 오프로딩을 위해 일부 용량을 프로비저닝할 수 있는백엔드 클라우드로 전송될 수 있다. 실행 포워딩의 이러한 양태 중 임의의 양태는 MEC 환경에 적용되어 보다 효율적인 애드혹 분산 컴퓨팅 작업 및 \"테더링\"의 형태를 가능하게 할 수 있다. 결과적으로, 특정 TSP에 등록된 디바이스는 주문형 처리 캐퍼빌리티 를 제공할 수 있고, 이에 따라 청구서 할인을 예상하여 MEC 서비스 커버리지를 확장할 수도 있다. 결과적으로, \"MEC 시스템\"의 개념은 이러한 실행 포워딩을 사용하여 크게 확장될 수 있다. 에지 컴퓨팅 시스템(예를 들어, 에지 클라우드 및 구현 시스템 및 디바이스)에서 실행 포워딩을 구현하기 위한 제 1 예시적인 방법(예 L1)은 (노드 또는 디바이스(2200, 2232, 2240 또는 2250)에서 또는 이에 의해 구현 되는) 처리 회로를 사용하여 수행되는 방법으로서, 방법은, 에지 네트워크의 서비스 제공자에 통신 가능하게 결 합된 디바이스로부터 컴퓨팅 자원 요청에 대한 승인 응답을 수신하는 단계; 승인의 수신시 디바이스상에서 보안 소프트웨어 실행 컴포넌트를 생성하는 단계; 서비스 제공자에 의해 수행될 워크로드를 식별하는 단계; 보안 소 프트웨어 실행 컴포넌트상에서 실행을 위한 워크로드를 송신하는 단계; 및 실행의 결과를 서비스 제공자의 노드 로 송신하는 단계를 포함한다. 제 2 예(예 L2)에서, 예 L1의 주제는, 보안 소프트웨어 실행 검포넌트를 소프트웨어 실행 컴포넌트의 풀에 추가 하는 단계; 워크로드를 작업 유닛으로 분할하는 단계; 및 작업 유닛을 소프트웨어 실행 컴포넌트의 풀의 각각의 소프트웨어 실행 컴포넌트로 송신하는 단계를 포함하고, 여기서 보안 소프트웨어 실행 컴포넌트상에서 실행을 위한 워크로드를 전송하는 단계는 작업 유닛의 제 1 작업 유닛을 보안 소프트웨어 실행 컴포넌트로 송신하는 단 계를 포함한다. 제 3 예(예 L3)에서, 예 L1-L2의 주제는, 보안 소프트웨어 실행 컴포넌트를 사용하여 워크로드의 실행을 위한 값을 연산하는 단계; 및 디바이스에 대응하는 사용자 계정에 값을 적립하는 단계를 포함한다. 제 4 예(예 L4)에서, 예 L1-L3의 주제는, 서비스 제공자에 의해 제공되고 컴퓨팅 자원에 대한 요청에서 제공되 는 서비스를 식별하는 단계; 및 워크로드의 실행시 디바이스상에서 서비스를 실시 가능하게 하는 단계를 포함한 다. 제 5 예(예 L5)에서, 예 L1-L4의 주제는, 보안 소프트웨어 실행 컴포넌트가 워크로드를 실행하는 데 이용할 수 있는 시간 윈도우를 식별하는 단계; 및 시간 윈도우 동안 워크로드를 보안 소프트웨어 실행 컴포넌트로 송신하 는 단계를 포함한다. 제 6 예(예 L6)에서, 예 L1-L5의 주제는, 디바이스가 에지 네트워크에 연결된 셀룰러 기지국을 통해 서비스 제 공자에 통신 가능하게 결합되는 것을 포함한다. 제 7 예(예 L7)에서, 예 L1-L6의 주제는, 디바이스가 에지 네트워크에 연결된 네트워크 라우터를 통해 서비스 제공자에 통신 가능하게 결합되는 것을 포함한다. 다양한 설정에서, 예 L1-L7(및 실행 포워딩의 다른 양태)은 정의된 애플리케이션 프로그래밍 인터페이스 또는 인터페이스 사양; 포워딩 동작을 호출, 수신 또는 제어할 통신 프로토콜, 원격 측정 포맷, 메시지 또는 정의의 사용; 및 (FaaS 또는 EaaS 아키텍처 내의 서비스를 비롯하여) 에지 컴퓨팅 환경 내에서 실행 포워딩에 대한 정 책 및 로직의 다른 사용 및 구현의 결과로서 관찰되거나 모니터링될 수 있다. 또한, 예 L1-L7의 방법은 에지 컴퓨팅 시스템에서 (예를 들어, 명령어가 실행될 때 방법을 수행하는 머신 판독 가능 매체와 함께) 구현된 명령 어로서 또는 (예를 들어, 방법을 수행하거나 달성하는 구성을 포함하는 장치와 함께) 구현된 하드웨어 구성으로 서 제공될 수 있다. 따라서, 예 L1-L7의 특징(및 실행 포워딩 및 실행 관리의 다른 특징)은 시스템 오케스트레 이터 또는 설계자에 의해 조정되거나 설계된 대로, 본 명세서의 임의의 다른 예와 결합되어 에지 클러스터 또는 에지 클라우드 시스템을 구성할 수 있다. IV. 다중 이해 관계자 에지 컴퓨팅 시스템을 위한 보안 및 프라이버시 개선 추가 예에서, 보안 및 프라이버시 절차의 고급 방법은 다양한 다중 이해 관계자 에지 컴퓨팅 설정으로 확장될 수 있다. 다중 테넌시 에지 설정에서 보안 정책 및 적응 컴퓨터 시스템 다중 테넌시의 컨텍스트에서, 격리는 한 테넌트의 데이터를 다른 테넌트로부터 완전히 분리하는 보안 및 프라이버시 접근 방식으로서 선택될 수 있다. 그러나 분산되고 자원이 제한된 에지 컴퓨팅 환경에서, 엄격한 격리는 실현 가능하지 않을 수 있다. 다음의 보안 및 프라이버시 접근 방식은 에지 컴퓨팅 시스템(예를들어, 에지 클라우드 및 도 3 내지 도 22d에 도시된 에지 컴퓨팅 시스템 구성)에서 새로운 형태의 액세스 제어, 보안 정책 및 보안 관리를 구현하기 위해 보다 동적인 접근 방식 및 구성을 고려한다. 특히, 본 명세서에서 설명된 에지 컴퓨팅 환경은 노드를 클러스터, 그룹 또는 다른 구성에 배치, 재배치 또는 추가하는 동안 테넌트 보안 그룹화 또는 보안 그룹의 변경을 도출할 수 있는 보안 양태 및 워크로드 유사성을 고려할 수 있다. 이러한 변경은 동일한 노드 내에서 동적으로 발생할 수 있으며 처리량을 높이기 위해 병렬 보 안 클러스터 및 그룹을 생성하여 보안이 더 낮은 워크로드와 동일한 노드에서 동작하는 신뢰성 있는 워크로드와 인터리브될 수 있다. 일 예로서, 부채널 위험을 최소화하고 테넌트 간의 이해 충돌을 해결하기 위한 아래의 접근 방식은 보안 정책이 부채널 분석의 가능성으로 인한 위험 관리의 기준을 설정하는 기술을 제공한다. (예를 들어, 서로를 염탐할 이 유가 있거나 염탐할 위험에 처한) 극적으로 대립하는 테넌트는 점점 더 강력한 격리 기술을 사용하여 서로 분리 되는 반면, 약간 대립하거나 우호적인 것으로 알려져 있지만 서로의 정보를 알아야 할 필요가 없는 다른 테넌트 는 적당한 격리 캐퍼빌리티를 필요로 한다. 이러한 상이한 레벨의 예방 조치 및 이러한 예방 조치로부터 확립 된 그룹은 동적의 적응적 보안 정책에 의해 추진될 수 있다. 추가 예로서, 다양한 형태의 보안 정책이 에지 컴퓨팅 설정 내에서 동적으로 생성되고 구현되어, 보안 동작 및 에지 컴퓨팅 시스템 자원의 사용 및 배치 방법을 제어할 수 있다. 이해 충돌에 기초하여 보안을 평가하면 한 유형의 보안 정책이 생성될 수 있다. 다중 레벨의 보안 분류(예를 들어, 일급 비밀, 기밀, 비기밀)에 기초하여 보안을 평가하면 다른 유형의 보안 정책이 생성될 수 있다. 이러한 평가는 에지 컴퓨팅 설정에서 확장되어 무 결성 대 기밀성, 타입 강제(type enforcement) 등을 또한 고려하는 동적 보안 정책을 생성할 수 있다. 다중 테넌트 격리는 모든 보안 정책 중 가장 강력한 (그리고 가장 엄격한) 보안 정책을 제공할 수 있지만 협업 의 가능성을 기대하지는 않는다. 다른 데이터 작업자의 존재는 숨겨져 있다. 다중 사용자 동작 시스템은 종종 이러한 방식으로 작동한다 - 실제로 다수의 사용자 사이에 공유 - 시간 분할 - 될 때, 사용자는 독점적으로 사 용할 수 있는 프로세서 또는 컴퓨팅 자원을 갖고 있다고 인식할 수 있다. 다중 레벨 보안 정책은 공유가 허용 될 때 기준을 정의함으로써 이러한 비 유연성을 제거한다(반면에 엄격한 다중 테넌시 정책은 공유를 전혀 기대 하지 않는다). 예에서, 로드 가능한 보안 모듈 또는 다른 보안 컴포넌트는 에지 컴퓨팅 시스템에서 다양한 형태로 제공될 수 있다. 이러한 로드 가능한 보안 모듈은 동적 보안 정책과 다른 보안 및 프라이버시 특징을 관리, 프로비저닝, 분산 및 적용할 수 있게 한다. 예를 들어, 본 명세서에서 논의된 에지 컴퓨팅 환경에서 동적 보안 정책을 사용 하면, 특히 자원의 더 세밀한 \"슬라이스\"가 테넌트, 애플리케이션 또는 서비스별로 함께 유지되고 조정되기 때 문에, 단순한 다중 테넌시보다 더 넓은 범위의 공유 및 협업 유스 케이스가 가능하게 된다. 일단 이러한 자원 그룹 또는 클러스터가 식별되면, 더 큰 공유 및 협업을 지원하는 다른 보안 정책 및 유스 케이스가 배치될 수 있다. 또한, 안전하고 신뢰성 있는 환경에서, 이러한 미세한 자원 슬라이스 조차도 관리되어 제어된 방식으로 슬라이스 간 상호작용을 가능하게 할 수 있다. 다른 형태의 보안 격리, 액세스 제어 및 프라이버시 관리가 로 드 가능한 보안 모듈 및 결과적인 플레이버, 슬라이스, 권한 및 다른 형태의 그룹화를 통해 가능해질 수 있다. 다음 예에서, 보안 정책 및 고려 사항에는 어떤 방식으로 자원을 공유하거나 상호작용하도록 인가된 클러스터 (그룹) 테넌트 또는 엔티티를 캡처하는 \"도메인\" 또는 유사한 보안 컨텍스트의 정의 및 사용이 수반될 수 있다. 이러한 도메인은 노드 또는 노드 자원의 배치, 재배치 또는 추가를 통해 동적으로 적응될 수 있다. 이러한 도 메인은 워크로드를 동일하거나 관련된 노드상에서 상호 동작할 수 있도록 할 수 있으며, 동일한 노드상에서 덜 안전한 워크로드로서 동작하는 둘 다 신뢰성 있는 워크로드와 인터리브된 자원 사용을 가능하도록 할 수 있다. 마찬가지로, 이러한 도메인은 (워크로드를 다수의 위치에 분산될 수 있도록) 병렬 그룹을 생성하여 처리량을 높 일 수 있도록 할 수 있다. 액세스 제한이 있는 다중 도메인 신뢰 확립(Multi-Domain Trust Establishment with Access Restrictions)의 예 에지 컴퓨팅은 에지 생태계 이해 관계자라고 지칭될 수 있는 다수의 사업자, 공급자, 서비스 제공자, 테넌트 및 호스팅 환경을 포함한다. 각각의 이해 관계자는 에지 생태계에 참여하기 위한 자기 이익을 추구하는 동기를 가 지고 있다. 때때로 자기 이익은 시너지 효과가 있으며 다수의 이해 관계자 사이에서 공통적이다. 다른 시기에, 자기 이익은 경쟁적, 적대적 또는 이해 충돌 관계를 드러낼 수 있다. 다중 테넌트 액세스 정책은 전형적으로 격리된(예를 들어, 중첩하지 않은) 테넌트 특정 자원을 찾는 데 중점을 둔다. 이러한 관행은 종종 테넌트가 에지 자원에 독점적으로 액세스할 수 있다는 환상을 준다. 그러나 이것은 부정확할 수 있어서, 테넌트 간의 자원 경합을 초래하여 에지 노드에서 열악한 자원 활용에 이르게 한다. 또한, 워크로드는 제어 평면, 데이터 평면 및 과금 또는 모니터링 서비스에 대해 상이한 가상 네트워크 기능 (VNF)을 조정하는 가상화된 진화된 패킷 코어(Virtualized Evolved Packet Core)(vEPC) 애플리케이션과 같은 다수의 공급 업체 요소로 구성될 수 있다. 갈수록 더 일반적인 에지 노드가 되고 있는 이러한 시나리오에서, 상이한 공급 업체 VNF는 테넌트 자원 독점 정책에 의해 좌절된 자원 공유를 가능하게 하는 공통된 자기 이익을 가질 수 있다. 즉, 자원 독점성 또는 자원 독점성에 대한 환상은 풍부한 협업 상호작용을 가능하게 하지 않는 다. 에지 컴퓨팅 시스템(예를 들어, 에지 클라우드 및 도 3 내지 도 22d에 도시된 에지 컴퓨팅 시스템 구성)에 서 풍부한 협업을 가능하게 하기 위해, 도메인의 관점과 관심에 비례하여 자기 이익 액세스 정책이 정의되는 도 메인(예를 들어, 에지 노드의 클러스터)이 설정될 수 있다. 여기서, 피어 또는 경쟁 도메인은 상이한 액세스 정책을 나타낼 수 있다. 이러한 도메인은 각각의 도메인 관점에 따라 액세스 권한을 평가하여 협업 상호작용에 이용할 수 있는 중첩된 자원 세트를 찾는다. 예에서, 에지 노드 자원은 자원을 담당하는 도메인(예를 들어, 자 원의 소유자)의 관점에서 표현되는 증명 가능한 아이덴티티를 갖고 있다. 예에서, 자원은 다른 도메인 특정 자 원 및 자원의 정의된 액세스 정책의 관점에서 표현된 액세스 권한을 갖는다. 여기서, 쌍별 도메인 정책의 교차 점은 허용 가능한 액세스 범위를 식별한다. 이러한 도메인을 통해, 개별 도메인 또는 제 3 자는 중앙집중화된 신뢰성 있는 제 3 자에 의존하지 않고 허용 가능한 액세스의 범위를 정확하고 독립적으로 연산할 수 있다. 따라서, 이해 관계자는 에지 커뮤니티의 서브세 트에 대한 신뢰 또는 오케스트레이션을 구현할 수 있다. 예를 들어, 국가 A의 통신사는 가입자 기반을 가질 수 있는 반면, 국가 B의 통신사는 상이한 가입자 기반을 가질 수 있다. 이러한 가입자 기반이 도메인이다. 에지 클라우드 생태계에서, 임의의 이해 당사자는 자신이 관리하는 구독자 기반을 가질 수 있고, 그래서 임의의 이해 당사자가 도메인이 될 수 있다. 도메인 A의 테넌트 A가 도메인 B의 테넌트 B와 상호작용하기를 원할 때, 도메 인 및 자원 액세스 정책은 가능하게는 애드-혹, 도메인-도메인 신뢰 연합, 또는 테넌트 A와 테넌트 B가 상호작 용하도록 권한을 부여하는 파라미터에 기초하여 상호작용의 규칙을 정의한다. 연합된 신뢰 파라미터는 자원으 로의 추가적인 액세스 제한을 사용한다. 또한 액세스의 세분성은 도메인 내 액세스보다 더 제한적일 수 있다. 예를 들어, 액세스는 액세스될 수 있는 특정 파일이나 워크플로우 또는 다른 자원을 식별할 수 있거나 또는 액 세스가 허용되는 기간에 더 엄격한 제한을 둘 수 있다. 도 43은 에지 생태계 도메인 아키텍처의 예를 도시한다. 도 43은 도메인, 즉 도메인 A 내지 도메인 E(4311, 4312, 4313, 4314, 4315)에 배열된 각각의 \"클러스터\"에 다섯 개의 도메인을 포함하는 에지 배치의 예 를 도시한다. 여기서, 클러스터는 인식된 도메인 소유자 및 하나 이상의 에지 서비스를 가지고 있다. 예에서, 하나 이상의 클러스터는 테넌트 또는 구독자 관계를 관리하여 서비스 레벨 협약(SLA) 또는 전달되는 서비스의 레벨을 설명하는 다른 성능 계약을 시행한다. 이러한 관리 클러스터는 필요에 따라 클러스터 간의 SLO 또는 유 사한 협약을 사용하여 이차(예를 들어, 부차적) 관계를 통해 SLA를 구현하여 SLA의 목표를 구현하는 역할을 할 수 있다. 도시된 바와 같이, 타원형은 (공급 업체와 같은) 소유자 엔티티를 식별하는 반면 직사각형은 도메인 E에서 (코어 서버와 같은) 제공된 서비스를 표시한다. 도메인 A 내지 도메인 E(4311, 4312, 4313, 4314, 4315) 각각은 도메인 A 내지 도메인 E(4311, 4312, 4313, 4314, 4315) 중, 다른 소유자 엔티티 또 는 서비스와 유사한 역할 또는 기능을 수행할 수 있는 다른 임의의 도메인과 동일하거나, 유사하거나 또는 상이 한 소유자 엔티티 또는 서비스를 가질 수 있다. 테넌트는 별도의 클러스터 지정을 필요로 하지 않을 수 있는 특수한 등급의 소유자이다. 이것은 테넌트가 호스팅 클러스터에 액세스할 수 있게 될 때 SLA가 일반적으로 합 의된 거동을 나타내기 때문에 발생할 수 있다. 예를 들어, 도시된 바와 같이, 테넌트 T1은 (예를 들어, 사업자 O1에 의해 심사된 후에) 도메인 A의 멤버가 될 재가를 받고 테넌트 T2는 (예를 들어, 사업자 O2에 의해 심사된 후에) 도메인 B의 멤버가 될 재가를 받는다. 공통 클러스터에서 테넌트 와 사업자 간의 관계는 \"공유된 도메인\" 컨텍스트로서 설명될 수 있다. 또한, 이러한 소유권 또는 관계 중 일 부는 일부 연관된 시간 유효성(일명 만료 데이터)을 가질 수 있다. 이것은 일부 속성이 영구적이지 않을 수 있 고 일부 요소가 연결성에 따라 업데이트되지 않을 수 있으므로 중요하다. 다른 이해 관계자는 각 클러스터의 소유자이다. 예를 들어, 계약자는 오케스트레이션 서비스를 포 함하고 있는 도메인 B의 소유자일 수 있다. 공급 업체는 코어 서버를 포함하고 있는 도메인 E의 소유자일 수 있다 - 예를 들어, 공급 업체는 코어 서버 하드웨어를 소유할 수 있으며 도메인 D의 계약자가 다른 유지 관리 작업을 소유할 수 있는 동안 펌웨어 업데이트 처리를 담당할 수 있다. 또한, 도메인 A의 사업자 O1은 코어 서버 등에 제공되는 공급 전력을 소유할 수 있다. 따라 서, 도메인 컨텍스트는 주어진 서비스 또는 자원에 대해 중첩되어 있을 수 있다. 그러나, 중첩하는 컨텍스트는 공유 도메인 컨텍스트와 동의어가 아닐 수 있다. 추가 예에서, (예를 들어, 도메인 C 내에서 도시된 바와 같은) 북-남(north-south) 상호작용은 도메인 내 트래픽(intra-domain traffic)뿐만 아니라 도메인 간 트래픽(inter-domain traffic)에 대한 LSM 및 보안 정책 에 의해 제어될 수 있다. 도메인 내 테넌트는 도메인 간 격리/공유 정책과 다른 격리/공유를 필요로 할 수 있 다. LSM은 도메인 특정 및 테넌트 특정 정책에 대해 계층화될 수 있다. 또한, 게이트웨이, 방화벽, 스위치, 라우터 및 다른 \"중간 박스\"는 LSM 및 보안 정책의 시행 지점일 수 있다. 또 다른 예에서, 각각의 도메인에는 제한되거나 차단된 액세스의 가능성이 있을 수 있는 상이한 도메인 특정 LSM이 적용될 수 있다. 도 44는 가상화된 다중 도메인 통신 아키텍처에 대한 모델의 예를 도시한다. 시나리오는 백엔드로 백홀 되지 않고 그 대신 안전하고 신뢰할 수 있는 방식으로 트래픽을 에지로부터 에지로(예를 들어, 도메인으 로부터 으로) 전송하는 것이 수반되는 다중 테넌트 트래픽에 대해 설명된다. 구체적으로, 에지 및 에지- 투-에지 로밍에 대한 동-서(east-west) 다중 테넌트 구독자 트래픽이 도시된다. 차세대 중앙국 컴퓨트 및 가속 기 랙이 있는 물리적 기지국 또는 기지국의 풀은 기업 및 네트워크 기능 외에도 계층 1, 계층 2 또는 계 층 3 트래픽을 위한 다수의 가상화된 기지국(Virtualized Base Station)(vBS)을 제공한다. 여기서, 테 넌트(예를 들어, 사업자)는 하나 이상의 VNF를 실행할 수 있고, VNF는 추가로 하나 이상의 VNF 컴포넌트 (VNF component)(VNFC)로 구성된다. 예에서, VNFC는 테넌트의 도메인 내에서 다른 VNFC 각각 내에서 도메인 컨 텍스트 또는 액세스 제어 공유 정책을 사용할 수 있는 상이한 독립 소프트웨어 공급 업체(Independent Software Vendor)(ISV)로부터의 것일 수 있다. 예에서, VNFC는 액세스 제어 정책 및 SLA에 의해 실시 가능해짐에 따라 다른 테넌트와 도메인 컨텍스트를 공유할 수 있다. 도 44의 컨텍스트에서, MEC 노드 또는 사업자 액세스 컴포넌트는 다른 LSM 시행 지점을 제공할 수 있다. 이 노드는 자원 풀, MEC 인프라스트럭처, 프록시 또는 다른 기술로의 액세스를 제한할 수 있다. 또한, 이러한 컨텍스트에서, 도메인 제어기 컨텍스트는 네트워크 기능을 호스팅하는 임의의 기술로부터 제공될 수 있다. 도메인 특정 LSM은 도메인 경계를 넘는(이를테면, VF#1 경계를 넘는) 임의의 테넌트 워크로드에 적용 될 수 있다. 도메인 내, 테넌트 간 상호작용은 범위가 제한된 제 2 LSM에 의해 제어될 수 있다. 소유자, 구독자, 테넌트, 공급 업체, 계약자, 사업자 등은 이들의 도메인 제휴(예를 들어, domain.owner)에 의 해 자격을 부여 받을 수 있다(예를 들어, 시스템 내에서 고유하게 식별될 수 있다). 자원, 서비스, 기능 등은 유사하게 자격을 부여 받을 수 있다(예를 들어, domain.resource). 완전히 자격 부여된 도메인 제휴는 이해 관 계자의 신뢰 컨텍스트를 모호하지 않게 하는데 사용될 수 있다. 예를 들어, 도메인은 (권한 또는 속성의 임의 의 만료 때까지) 한 세트의 기능 또는 서비스를 수행하거나 제공하도록 신뢰를 받는 자원, 펌웨어, 소프트웨어, 공급자, 계약자 등의 세트를 식별하는 신뢰 정책을 형성할 수 있다. 예에서, 정책은 피어 도메인 엔티티에 의한 인증, 인가 또는 증명의 조건으로서 도메인 자원으로의 액세스 또는 권한을 승인하는 액세스 정책의 형태로 실현될 수 있다. 예에서 액세스 정책은 다음과 같은 형식을 가질 수 있 다: <peer_domain>.<peer_owner_or_resource> : <local_domain>.<local_owner_or_resource>.<allowed_rights_or_access> 예에서, 동-서 다중 도메인 가상화 모델에서, 정책은 다음과 같은 형식을 취할 수 있다: <peer_domain>.<peer-sub-domain>.<peer_owner_or_resource> : <local_domain>.<local_owner_or_resource>.<allowed_rights_or_access> 신뢰 확립은 피어 엔티티가 그의 신뢰 속성, 아이덴티티, 캐퍼빌리티 또는 구성과 관련하여 로컬 엔티티에 인증 할 때 달성될 수 있다. 예에서, VNF는 로컬 엔티티에 자신을 인증한다. 그러나, 예에서, 모든 VNFC는 부모 (parent) VNF에서 인증된다. 여기서, VNFC의 신뢰는 부모 또는 소유 VNF 내에서 위임된다. 예에서, 도메인 아이덴티티는 모든 이해 관계자가 신뢰하는 중앙집중화된 조직(예를 들어, 인증 기관, 정부 또 는 금융 기관)이 존재하지 않을 수 있도록 자체 주권적일 수 있다. 예에서, 자체 주권 아이덴티티는 월드 와이 드 웹 컨소시엄(World Wide Web Consortium)(W3C) 탈중앙집중화된 식별(decentralized identification)(DID)정의를 따른다. 예에서, 허용된 권한과 액세스의 교차점을 찾음으로써 도메인 사이의 액세스가 상호 연산될 수 있다. 이것은 (다른 신택스가 가능하겠지만) 다음의 예에 따라 달성될 수 있다: 도메인 B는 도메인 A 액세스를 설명하는 액세스 정책을 형성한다: <Domain_A>.<Owner_O1>.<Rsrc_R1> : has access to: <Domain_B>.<Owner_O2>.<Rsrc_R2> :with: <permissions: P1, P2> 동일한 도메인 A 내의 서브도메인 1 및 서브도메인 1은 도메인 C 액세스를 설명하는 액세스 정책을 형성한다. <Domain_A>.<Sub-Domain 1>.<Owner_O1>.<Rsrc_R1> : has access to: <Domain_C>.<Sub-Domain 3>.<Owner_O2>.<Rsrc_R2> :with: <permissions: P1, P2> 마찬가지로 도메인 A는 도메인 B 액세스를 설명하는 정책을 형성한다: <Domain_B>.<Owner_O2>.<Rsrc_R2> :is accessible by: <Domain_A>.<Owner_O1>.<Rsrc_R1> :with: <permissions: P2, P3> 평가는 P2를 교차 허가라고 밝혀준다. 도메인 A와 B는 둘 모두 동일한 결론에 도달한다. 다중 도메인 신뢰 확립을 위한 본 기술은 다른 변형에 적용될 수 있다는 것을 이해할 것이다. 예를 들어, 이러 한 기술은 백엔드로 백홀되지 않는 다중 테넌트 트래픽에 적용될 수 있고, 안전하고 신뢰할 수 있는 방식으로 에지-투-에지에서 발생해야 하는 정책 전송에 적용될 수 있다. 따라서, 이러한 기술은 에지상의 동-서 다중 테 넌트(사업자) 구독자 트래픽에 대해, 그리고 에지-투-에지 로밍의 일부로서 적용될 수 있다. 에지 컴퓨팅 환경(예를 들어, 에지 클라우드 및 구현 시스템 및 디바이스)에서 다중 도메인 신뢰 확립을 위한 제 1 예시적인 방법(예 M1)은 (노드 또는 디바이스(2200, 2232, 2240 또는 2250)에서 또는 그에 의해 구현 되는) 처리 회로를 사용하여 수행되는 방법으로서, 방법은, 에지 컴퓨팅 환경의 제 1 클러스터의 에지 컴퓨팅 노드에서, 제 1 클러스터의 특정 자원으로의 액세스 요청을 수신 - 요청은 에지 컴퓨팅 환경의 제 2 클러스터의 에지 컴퓨팅 노드로부터 발생하고, 여기서 제 1 및 제 2 클러스터는 각기 각자의 클러스터 내의 자원으로의 액 세스의 범위를 정의함 - 하는 단계; 제 1 및 제 2 클러스터 내의 자원으로의 액세스의 범위로부터, 특정 자원으 로의 액세스 권한을 식별하는 단계; 및 특정 자원으로의 식별된 액세스 권한에 따라, 제 1 클러스터의 특정 자 원으로의 액세스를 실시 가능하게 하는 단계를 포함한다. 제 2 예(예 M2)에서, 예 M1의 주제는, 클러스터가 에지 컴퓨팅 노드상의 각각의 테넌트에 의해 제어되는 것을 포함한다. 제 3 예(예 M3)에서, 예 M2의 주제는, 각각의 테넌트가 네트워크 사업자인 것을 포함한다. 제 4 예(예 M4)에서, 예 M1-M3의 주제는, 워크로드가 다수의 서비스를 달성할 다수의 기능의 사용을 조정하는 다수의 애플리케이션으로 구성되는 것을 포함한다. 제 5 예(예 M5)에서, 예 M1-M4의 주제는, 클러스터가 각각의 클러스터 내의 자원으로부터 전달할 서비스 레벨을 정의하는 각각의 서비스 레벨 협약(SLA)과 연관되는 것을 포함한다. 제 6 예(예 M6)에서, 예 M1-M5의 주제는, 특정 자원으로의 액세스 권한에 기초하여, 에지 컴퓨팅 환경 내의 이 차 관계를 식별하여 특정 자원으로의 액세스 요청을 이행하는 단계를 포함한다. 제 7 예(예 M7)에서, 예 M1-M6의 주제는, 각각의 클러스터가 각각의 테넌트 또는 구독자에 의해 액세스 가능한 각각의 서비스마다, 각각의 테넌트 또는 가입자에 대한 관계를 정의하는 것을 포함한다. 제 8 예(예 M8)에서, 예 M1-M7의 주제는, 특정 자원으로의 식별된 액세스 권한이 허용된 권한과 제 1 클러스터 및 제 2 클러스터에 의해 제공되는 대응하는 자원 유형으로의 허용된 액세스의 교차점으로부터 식별되는 것을 포함한다. 다양한 설정에서, 예 M1-M8(및 다중 도메인 신뢰 확립의 다른 양태)은 정의된 애플리케이션 프로그래밍 인터페 이스 또는 인터페이스 사양; 통신 프로토콜, 메시지 포맷 또는 정의의 사용; 및 에지 컴퓨팅 환경 내에서 액세 스 제어 및 신뢰 메커니즘에 대한 정책 및 논리의 다른 사용 및 구현의 결과로서 관찰되거나 모니터링될 수 있 다. 예 M1-M8 및 이러한 신뢰 및 보안 관리 기술의 다른 양태는 또한 (예를 들어, FaaS 또는 EaaS 설정에서 동 작하는 서비스에 대한 보안 강화를 구현하는) 서비스 동작 및 서비스 기능의 결과로서 관찰되거나 구현될 수 있 다. 또한, 예 M1-M8의 방법은 에지 컴퓨팅 시스템에서 (예를 들어, 명령어가 실행될 때 방법을 수행하는 머신 판독 가능 매체와 함께) 구현된 명령어로서 또는 (예를 들어, 방법을 수행하거나 달성하는 구성을 포함하는 장 치와 함께) 구현된 하드웨어 구성으로서 제공될 수 있다. 따라서, 예 M1-M8의 특징(및 신뢰 및 보안 관리 기술 의 다른 특징)은 시스템 오케스트레이터 또는 설계자에 의해 조정되거나 설계된 대로, 본 명세서의 임의의 다른 예와 결합되어 에지 클러스터 또는 에지 클라우드 시스템을 구성할 수 있다. 디바이스 간 안전한 데이터 공유(Secure Data Sharing Between Device)의 예 예에서, 에지 컴퓨팅 시나리오(예를 들어, 에지 클라우드 및 도 3 내지 도 22d에 도시된 에지 컴퓨팅 시스 템 구성)는 다양한 형태의 안전한 데이터 공유 교환(secure data sharing exchange)을 가능하게 하는 디바이스 에 대한 시간적 페어링(temporal pairing)을 통합할 수 있다. 안전한 데이터 공유 교환은 다음의 시나리오에서 와 같이 많은 조합으로 발생한다: 최종 디바이스(예를 들어, 클라이언트 디바이스)는 동일한 테넌트에 속하거나 이와 연결되어 있고 연결에 동의하며, 에지 클라우드 환경을 통해 인증이 발생하여 보안 통신을 설정하고 수행 한다. 이 시나리오에서, 에지 기지국(또는 다른 유사한 에지 노드)은 대칭 암호화를 위한 임시 개인 키를 생성 한다. 비대칭 보안 연결을 사용하여, 임시 개인 키가 디바이스로 전송되어, 디바이스가 대칭 키를 사용하여 에 지 기지국상의 버퍼 위치를 안전하게 판독하고 기입할 수 있게 한다. 대칭 키의 사용을 통해, 각각의 디바이스 에 의해 액세스 가능한 에지 기지국의 메모리, 스토리지, 기능 및 다른 자원으로의 보안 액세스가 제공될 수 있 다. 이러한 접근 방식은 이를 테면 V2V 및 V2X 통신 등을 위한 (예를 들어, 지도 또는 펌웨어 업데이트를 위해) 동일한 회사의 차량 사이에서, 디바이스 대 디바이스 및 노드 대 노드 통신 설정에 광범위하게 적용될 수 있다. 예에서, 안전한 데이터 공유를 위한 아키텍처는 에지 클라이언트와 에지 플랫폼이 둘 모두 동적으로 안전하고 비동기적 데이터 교환을 수행할 수 있도록 한다. 도 45는 에지 클라이언트 A, 에지 클라이언트 B 및 보안 에지 서버 사이에서, 보안 데이터 동작을 실시 가능하게 하기 위한 시나리오를 도시한다. 이 시나리오에서, 에지 클라이언트(4510, 4520)는 다음과 같은 요소로 확장된다. 도시된 바와 같이, (다른 시퀀스 또는 동작의 변형이 가능할 수 있겠지만) 키 보안 동작의 시퀀스가 수행될 수 있다. 첫째, 에지 클라이언트(4510, 4520)는 클라이언트가 데이터를 공유하고 싶어하는 다른 에지 클라이언트 (이를테면, 반대쪽 클라이언트(4510, 4520))의 공개 인증서 세트를 소유하고 처리하는 구성(예를 들어, 명령어, 소프트웨어, 펌웨어, 구현된 로직)을 포함한다. 이러한 특징은 클라이언트 ID 또는 조직 ID(예를 들어, 다수의 디바이스가 동일한 개인 키를 공유하는 경우) 및 공용 인증서(public certificate)를 추적할 수 있다. 이 데이 터는 (예를 들어, N 시간 유닛 내에 액세스되지 않으면 만료되는) 일부 시간 특성을 포함하거나 이와 연관될 수 있다. 둘째, 에지 클라이언트(4510, 4520)는 각각의 클라이언트가 특정 데이터 세트를 특정 엔티티와 안전하게 공유하 기를 요청할 수 있게 하는 구성을 포함한다. 인터페이스는 클라이언트 ID 및 공유할 페이로드를 포함하거나 추 적할 수 있다. 일단 이 기능이 (예를 들어, 에지 클라이언트 A에서) 호출되면, 다음의 동작이 수행된다: 대칭 키를 생성하고; B(에지 클라이언트 B)의 대칭 키를 암호화하고; 대칭 키를 사용하여 B의 콘 텐츠를 암호화하고; 대칭 키 및 암호화된 콘텐츠를 커넥티드 에지 서버(예를 들어, 기지국일 수 있는 에지 서버)로 전송한다. 셋째, 에지 클라이언트(4510, 4520)는 이러한 특정 클라이언트에 대해 에지 서버(예를 들어, 에지 서버) 에 임의의 데이터가 저장되어 있는지를 각각의 클라이언트가 요청할 수 있도록 하는 구성 기능을 포함한다. 기 능은 안전한 방식으로 에지 서버에 연결하고 ID를 클라이언트에 제공할 것이다. 기능은 또한 다른 피어에 의해 게시된 데이터 세트의 목록을 검색하고 개인 키를 사용하여 데이터를 검색하여 데이터 세트를 암호 해제할 것이다. 에지 서버(예를 들어, 에지 서버)은 원래 에지 클라이언트에 의해 제공되는 데이터가 저장되는 (인텔® SGX™, ARM®TrustZone™ 또는 유사한 보안 스토리지/엔클레이브 기술을 통해 보호되는) 보호된 메모리 조각을 포함한다. 에지 서버는 정보를 추가로 최종 목적지(예를 들어, 에지 클라이언트 B)에 전달하기 위해, 발 신 에지 클라이언트와 유사한 역할로 동작할 수 있는 명령어를 더 포함한다. 이러한 방식으로, 전체적인 엔드- 투-엔드 보안 데이터 교환은 인증되고 안전한 채널 내에서 모두 에지 디바이스 대 기지국 대 기지국 간 통신의 시퀀스를 통해 실시 가능해질 수 있다. (테넌트는 주로 서비스 및 서비스 결과에 관심을 갖기 때문에) 테넌트는 종종 패킷 및 통신 보안을 자체 목표로 신경쓰지 않는다. 추가 예에서, 본 명세서에서 논의된 임의의 보안 메커니즘은 X-aaS로의 보안 액세스를 제공 하기 위해 사용될 수 있으며, 여기서 X는 MEC 또는 다른 에지 컴퓨트 노드에 의해 호스팅되는 보안 관련 서비스 또는 기능이다. 에지 환경 내에서 보안 기능을 호스팅하면 잠재적으로 순환성 문제가 발생한다; 예를 들어 TLS-aaS는 TLS를 사용하여 TLS-aaS 호스트로의 액세스를 보호한 다음 요청된 TLS 기능을 TLS 터널 내에서 수행 해야 함을 의미할 수 있다. 보안 메커니즘 및 접근 방식은 서비스로서의 암호화(Crypto-as-a-Service)와 같은, 에지 시스템 내에서 제공되 는 많은 형태의 상위 레벨 보안 서비스 추상화와 통합될 수 있다. 그러한 보안 메커니즘 및 보안 서비스로서 X(X-as-a-service) 추상화를 지원하기 위해, 에지 컴퓨팅 시스템은 메타데이터 세트와 연관된 액세스될 검색 가 능한 기능의 목록을 노출하거나 액세스하여 안정성의 레벨, 신뢰, 인증 기관 신뢰 엔티티의 목록 등을 정의할 수 있다. 이러한 보안 X-aaS 컴포넌트의 동작은 다중 테넌트 격리를 시행하고 보안 X-aaS가 동작하는 동안 테 넌트 간의 부채널의 위험을 줄이도록 구성될 수 있다. 보안 하드웨어 메커니즘은 에지 컴퓨트 환경에서 암호화 프리미티브를 제공할뿐만 아니라, 가용 하드웨어 및 배 치의 특성으로 완전히 프로그램 가능한 관련 암호화 서비스(예를 들어, TLS-aaS, DTLS-aaS)를 지원하는 데 사용 될 수 있다. Intel®SGX™와 같은 보안 특징은 이러한 워크로드를 엔클레이브/도메인에서 호스팅하고, 사용하 기 위한 네트워크 인터페이스를 노출함으로써 D/TLS-aaS의 보안을 개선하는 데 사용될 수 있다. 또한, 터널링 및 홉별(hop-by-hop) 보호가 적용되어 발신자가 D/TLS를 완전히 적용하여 X-aaS 상호작용에 대한 요청/응답을 보호할 수 있도록 할 수 있다. 이것은 OSCORE가 서비스일 수 있고 TLS가 노드로의 액세스를 보호하는 서비스로 서; 또는 노드가 TLS/OSCORE 터널을 통해 범용 암호화/복호화를 수행하기 위한 스마트카드/TPM 인터페이스를 노 출하는 구성으로서 보안 터널링을 통해 제공될 수 있다. 추가 예에서, 보안 기술(예를 들어, 인텔® MKTME™)은 둘 모두의 (다수의) 테넌트에 알려진 새로운 키(예를 들 어, MKTME 키)가 (예를 들어, 디피 헬먼법(Diffie-Hellman)을 사용하여) 협상되도록 \"공유 테넌트 컨텍스트 (shared tenant context)\"를 생성하는 데 사용된다. 공유 키는 공유 데이터를 보관하는 상이한 메모리 암호화 컨텍스트를 생성하는 데 사용된다. 따라서 워크로드 애플리케이션은 \"공유\" 데이터를 이것이다른 테넌트에 의 해 공유되기 때문에 덜 신뢰성 있는 데이터로 취급할 수 있다. 처리 노드(예를 들어, 셀 타워)는 공유 메모리, 공유 스토리지 디바이스, 멀티 캐스트를 위한 공유 네트워킹 어드레스 등과 같은 공유 컨텍스트를 제공할 수 있 다. 또한, 추가 예에서, 피어 엔드포인트에서의 신뢰는 에지 인프라스트럭처와 사전의 신뢰 컨텍스트가 있는 엔드포 인트에서 적극 활용될 수 있다. 인프라스트럭처는 애드-혹 협업 또는 연합을 용이하게 하기 위해 자원과 사용 자가 추가될 수 있는 도메인을 동적으로 생성할 수 있다. 에지 컴퓨팅 환경에서(예를 들어, 에지 클라우드 및 구현 시스템 및 디바이스에서) 디바이스 간의 안전한 데이터 공유를 구현하기 위한 제 1 예시적인 방법(예 N1)은 (예를 들어, 노드 또는 디바이스(2200, 2232, 2240 또는 2250)에서 또는 그에 의해 구현되는) 처리 회로를 사용하여 수행되는 방법으로서, 방법은, 제 1 에지 노드 에서, 제 2 에지 노드에 전달될 콘텐츠의 암호화를 위한 대칭 키를 생성하는 단계; 제 1 에지 노드에서, 대칭 키를 암호화하는 단계; 제 1 에지 노드에서, 대칭 키를 사용하여 제 2 에지 노드에 전달될 콘텐츠를 암호화하는단계; 암호화된 보안 채널을 통해, 전달될 암호화된 대칭 키 및 암호화된 콘텐츠를 에지 노드 서버에 전달하는 단계를 포함하며, 여기서 전달될 암호화된 대칭 키 및 암호화된 콘텐츠는 나중에 제 2 에지 노드에 의해 에지 노드 서버로부터 획득된다. 제 2 예(예 N2)에서, 예 N1의 주제는, 전달될 암호화된 대칭 키 및 암호화된 콘텐츠가 제 2 에지 노드에 의해 에지 노드 서버의 보안 스토리지로부터 획득되는 것을 포함한다. 제 3 예(예 N3)에서, 예 N2의 주제는, 전달될 암호화된 대칭 키 및 암호화된 콘텐츠가 보안 스토리지에 액세스 하고, 대칭 키를 사용하여 암호화된 콘텐츠를 해독함으로써 제 2 에지 노드에 의해 에지 노드 서버로부터 획득 되는 것을 포함한다. 제 4 예(예 N4)에서, 예 N2-N3의 주제는, 보안 스토리지가 보안 엔클레이브이거나 또는 에지 노드 서버에 의해 유지되는 보안 버퍼인 구성을 포함한다. 제 5 예(예 N5)에서, 예 N1-N4의 주제는, 에지 노드 서버가 기지국이고 제 1 에지 노드와 제 2 에지 노드가 엔 드포인트 클라이언트 디바이스인 구성을 포함한다. 제 6 예(예 N6)에서, 예 N1-N5의 주제는, 전달될 암호화된 대칭 키 및 암호화된 콘텐츠가 비동기 통신 세션을 사용하여 제 2 에지 노드에 의해 에지 노드 서버로부터 획득되는 것을 포함한다. 제 7 예(예 N7)에서, 예 N1-N6의 주제는, 대칭 키를 생성하는 동작 및 전달될 대칭 키 및 콘텐츠를 암호화하는 동작이 신뢰성 있는 당사자에 의해 인증된 하드웨어를 사용하여 제 1 에지 노드에서 수행되는 것을 포함한다. 제 8 예(예 N8)에서, 예 N7의 주제는, 암호화된 대칭 키 및 암호화된 콘텐츠를 해독하는 동작이 제2 에지 노드 에서 신뢰 당사자에 의해 인증된 하드웨어를 사용하여 제 2 에지 노드에서 수행되는 것을 포함한다. 제 9 예(예 N9)에서, 예 N7-N8의 주제는, 신뢰 당사자가 하드웨어 제조사인 구성을 포함한다. 제 10 예(예 N10)에서, 예 N1-N9의 주제는, 제 1 에지 노드가 콘텐츠를 공유할 에지 노드에 대한 한 세트의 공 용 인증서를 유지하는 구성을 포함하고, 공용 인증서 세트는 제 2 에지 노드로부터의 공용 인증서를 포함한다. 제 11 예(예 N11)에서, 예 N1-N10의 주제는, 에지 컴퓨팅 시스템 내에서 서비스로서의 보안 기능을 사용하여 신 뢰성 있는 암호화 동작을 생성 및 설정하는 것을 포함한다. 다양한 설정에서, 예 N1-N11(및 안전한 데이터 공유의 다른 양태)은 정의된 애플리케이션 프로그래밍 인터페이 스 또는 인터페이스 사양; 통신 프로토콜, 메시지 포맷 또는 정의의 사용; 및 에지 컴퓨팅 환경 내에서 안전한 데이터 공유를 위한 정책 및 로직의 다른 사용 및 구현의 결과로서 관찰되거나 모니터링될 수 있다. 예 N1-N11 및 이러한 데이터 공유 구성의 다른 양태는 또한 (예를 들어, FaaS 또는 EaaS 설정에서 서비스 또는 서비스 사 용자 사이에 데이터를 공유하는) 서비스 동작 및 서비스 기능의 결과로서 관찰되거나 구현될 수 있다. 또한, 예 N1-N11의 방법은 에지 컴퓨팅 시스템에서 (예를 들어, 명령어가 실행될 때 방법을 수행하는 머신 판독 가능 매체와 함께) 구현된 명령어로서 또는 (예를 들어, 방법을 수행하거나 달성하는 구성을 포함하는 장치와 함께) 구현된 하드웨어 구성으로서 제공될 수 있다. 따라서, 예 N1-N11의 특징(및 안전한 데이터 공유 및 관련 동작 의 다른 특징)은 시스템 오케스트레이터 또는 설계자에 의해 조정되거나 설계된 대로, 본 명세서의 임의의 다른 예와 결합되어 에지 클러스터 또는 에지 클라우드 시스템을 구성할 수 있다. 그룹 보안 통신(Group Secure Communication)의 예 분산 아키텍처에서 도전과제 중 하나는 워크로드 및 디바이스가 에지 전체에서 동적으로 이동할 수 있는 분산 에지 아키텍처에서 테넌트가 보유한 서비스와 관련하여 테넌트에 의해 언제라도 액세스될 수 있는 분산 에지 아 키텍처상의 협업 디바이스 간의 통신을 처리하고 보호하는 방법이다. 오늘날 정보 보안 및 프라이버시는 다음과 같은 일반적인 상황에서 나타나는 것처럼, 디바이스 또는 서비스가 엔드-투-엔드 보안 채널을 설정하는 포인트-투-포인트 기반으로 획득된다: 랩톱 또는 스마트폰이 도메인 제어기 와 가상 사설 네트워크(virtual private network)(VPN) 세션을 설정하고, 퍼스널 컴퓨터(예를 들어, 스마트폰, 노트북 등) 상의 브라우저가 웹 사이트(예를 들어, Google, Bing 등)와 하이퍼텍스트 전송 프로토콜 보안 (hypertext transfer protocol secure)(https) 세션을 설정하고, 스마트폰이 기지국 등에 연결한다 등등. 반 면에, 많은 유형의 통신은 회의와 같은 \"웹과 유사한\" 그룹 통신이다. 회의의 각 사람은 낮은 레벨의 그 사람 자신의 개인 채널(예를 들어, 전화 연결, 네트워크 스택 등)상에 있으며 이것은 그룹 통신 경험을 구현하는 \"애 플리케이션\" 또는 \"솔루션\"(예를 들어, 웹 회의 애플리케이션, 등)이다.다른 많은 통신(예를 들어, 스마트 폰과 다른 스마트폰 간의 통신, 엔드-투-엔드 통신 세션 등)에서, 통신이 발 생하는 피어-투-피어 엔드포인트의 세트는 고정되어 있지 않는다. 예를 들어 John은 기차를 타고 자기의 스마 트폰을 사용하여 웹 사이트를 탐색할 수 있으며 기차가 이동함에 따라 John과 그의 이동 통신사 간의 보안 채널 은 많은 상이한 기지국을 가로질러 갈 수 있다. 에지 컴퓨팅 시나리오(예를 들어, 에지 클라우드 및 구현 시스템 및 디바이스)에서 이동성이 제공됨에 따 라, 보안 통신 채널을 설정해야 할 필요성이 자주 발생한다. 에지 통신에서 네트워크 채널의 지배적인 사용은 이러한 요구로 인한 심각한 병목 현상을 겪지 않았지만, 더 새로운 최근에 생겨난 사용은 성능 및 확장성 도전 과제를 경험할 가능성이 높다. 하나의 기여 원인은 데이터 볼륨이 커지고 데이터가 점차 위태롭게 둘 수 없는 자산으로서 여겨짐에 따라 정보 보안에 가치를 두는 중요성이 커지고 있다는 점이다. 제 2 기여자는 근접성 기 반, 애드-혹 및 가능해지고 있는 자동화된 협업에 있어서 지속적인 상승 추세이다. 많은 경우에 있어서, 다수의 엔티티와 서비스가 공동 목표를 달성하기 위해 협업해야 할 수 있고; 협업/통신 엔 티티(예를 들어, 디바이스, 컴퓨터, 스위치, 허브 등) 사이에 많은 포인트-투-포인트 가상 보안 채널을 생성하 고 해체할 필요성을 우회하는 것이 매우 바람직하다. 또한, 모든 디바이스가 특화된 하드웨어를 사용하여 암호 화/복호화를 수행할 수 있는 것은 아니며; 참가자 수가 증가하고 그룹 내에서 피어-투-피어 통신에 사용되는 암 호화 키가 함께 증가함에 따라, 각각의 디바이스는 그룹의 각각의 멤버로부터 디바이스를 떠나거나 디바이스에 도달하는 각각의 메시지를 암호화/복호화하도록 강요 받는다. 다음의 접근 방식은 통상적인 포인트-투-포인트 및 애플리케이션 사용 그룹 통신에 대한 확장 가능한 대안을 제공한다. 보안 그룹 통신을 위한 통상의 솔루션은 단일 엔티티에 의해 유지되는 가속 디바이스 또는 사전 프로비저닝된 통신 비밀을 포함할 수 있다. 그러나 모든 디바이스가 가속 디바이스 또는 사전 프로비저닝된 통신 비밀을 포 함하는 것은 아니며 모든 통신 서비스 제공자가 원격 통신 제공자 엔티티인 것은 아니다. 그래서 통상의 솔루 션은 비효율적일 수 있으며 관행을 따르지 않는 디바이스(예를 들어, 가속기가 없는 디바이스 또는 사전 프로비 저닝되지 않은 비밀 등) 및 다른 서비스 제공자(예를 들어, 원격 통신 제공자 등이 아닌 것 등)가 통신에 연루 될 때 기능하지 않을 수 있다. 전용 하드웨어는 전화 또는 태블릿과 같은 최종 디바이스에 비실용적일 수 있다. 또한, 특화된 하드웨어가 기지국, 고객 댁내 장비(CPE) 등에서 구현될 수 있지만, 통신하는 디바이스의 증가 또는 설계되는 새로운 애플리케이션의 수의 증가에 따라 처리량이 증가하지는 않는다. 전통적으로 보안은 분산 에지 컴퓨팅이 등장하기 이전에 사용 시 설비에 구현될 때는 포인트-투-포인트 개념이 다. 예를 들어, 모바일 디바이스 X는 기지국과 보안 세션을 설정할 수 있으며, 기지국 사이에서 이동할 때는 한 기지국으로부터 다른 기지국으로 엔드 투 엔드 세션의 핸드 오버가 있을 수 있다. 예에서, 다수의 엔티티와 서비스는 공동 목표를 달성하기 위해 협업해야 할 수 있다. 협업에 연루된 당사자는 협업의 목적을 위해 공통 보안 자격증명(common security credential)을 설정할 수 있다. 공통 보안 자격증명은 또한 다수의 기지국에 걸쳐 동시에 활성화될 수 있다. 본 명세서에서 논의된 시스템 및 기술은 컴퓨팅 노드의 클러스터에 대한 에지 컴퓨트 시나리오에서 서명된 그룹 자격증명(및 연관된 키 자료)을 애드-혹 동적 기반으로 생성할 수 있게 함으로써 에지 컴퓨팅 시스템(예를 들어, 에지 클라우드 및 에지 컴퓨팅 시스템 구성)에서 그룹 통신을 개선한다. 이것은 통신 그룹의 모든 멤버가 포인트 투 포인트 데이터 암호화에 사용되는 키와 유사한 그 공통 키를 세션 암호화 키로서 사용할 수 있도록 한다. 그러나 이러한 공통 키는 그룹 세션에 걸쳐 있다. 통신 그룹에는 언제든 그룹 리더가 있고, 그 그룹 리더는, 그룹 세션에서 퇴장해야 하면, 임의로 대체 그룹 리 더를 선택하고 광고한다. 분산 시스템에서 합의 및 선출을 위한 프로토콜은 현재 그룹 리더가 연결 해제되는 이벤트에서 그룹 리더의 탄력적인 선택을 제공하는 데 사용될 수 있다 - 이것은 예외(예를 들어, 드문) 조건이 며 따라서 처리할 필요성으로 인해 성능 우려를 야기하지 않는다. 그러나 그룹 리더의 상실이라는 드문 경우의 최적화로서, 그룹은 (드물게) 영향을 받는 그룹 세션에 대해 전통적인 피어-투-피어 암호화 체계로 되돌아 갈 수 있다. 추가의 최적화는 예를 들어, 그룹의 크기가 정책 결정 동적 임계치(policy determined dynamic threshold)에 도달할 때까지 피어-투-피어 전송 암호화 키를 사용하는 것을 포함할 수 있다. 특정 카테고리의 세션은 정보 시스템 보안 기준에 기초하여, 그룹 키로 이동되지 않을 수 있다. 예를 들어, 데이터 지역화 요구 사항의 대상 이 되는 지역 사이에서 환승되는 통신은 지역별로 상이한 암호화 강도를 강요할 수 있고, 따라서 그룹 키 프로 토콜로 전환하지 않을 수 있다. 이것은 특히 멀티캐스트/브로드캐스트 채널 프로토콜을 통해 계층화될 수 있는통신에서 낮은 오버헤드, 민첩성 및 확장성을 제공한다. 다음의 시스템 및 방법은 작업의 완료시 조정되는 디바이스가 그의 그룹 사이에서 안전하게 통신할 수 있도록 하면서 그룹 멤버의 요구에 기초하여 에지 아키텍처 역할을 인프라스트럭처 주위로 이동할 수 있게 하는 동적 보안 통신 아키텍처를 제공한다. 사적인 통신은 비 그룹 통신이 다른 그룹 멤버에 의해 가로 채이는 것을 방지 하는 비 그룹 통신 용으로 유지된다. 도 46은 에지에서 그룹 보안 통신을 위한 시스템의 예의 블록도이다. 디바이스 A, B, C 및 D(예를 들어, 도 3 내지 도 22d에서 참조된 에지 컴퓨팅 디바이스)는 공통 작업(예를 들어, 작업 A 등)을 완료하기 위해 작업할 수 있다. 디바이스(4610-4616)는 상이한 기지국에 의해 서비 스될 수 있다; 예를 들어, A는 기지국 S1의 커버리지 영역에 있을 수 있고, B 및 C는 기지국 S2의 커버리지 영역에 있을 수 있고, D는 기지국 S3의 커버리지 영역에 있을 수 있다. 애플리케이션 서 비스 특정 허브(예를 들어, 협업 브리지 등)를 제공하는 대신, 그룹 통신 및 역할 관리자에 의해 적기에 생성된 보안 자격증명이 발생되어 작업 중인 모든 당사자 간의 실시간 정보 통신이 작업을 완료할 수 있게 한다. 이러한 예 및 다른 예에서, 역할 관리자는 역할 기반 액세스 제어(Role-Based Access Control)(RBAC) 정책이 적용되는 LSM 시행 지점일 수 있다. 예에서, 보안 자격증명은 특정 그룹 세션에 대해서만 유효할 수 있다. 따라서, 그룹 세션 외부의 각각의 디바 이스의 다른 모든 통신은 사적인 통신인 반면 그룹 세션 내의 통신은 공유되고 보안된다. 이것은 이동성이기에 상이한 시점에서 상이한 물리적 네트워크에 걸쳐 있는 가상 버스를 통해 끊김없이 이동하는 에지에서 애드-혹 멀티 캐스팅 그룹을 생성할 수 있는 역량을 제공할 수 있다. 예에서, 그룹은 직접 익명 증명(Direct Anonymous Attestation), 강화된 프라이버시 식별자(Enhanced Privacy Identifier)(EPID)와 같은 그룹 서명 체계 또는 포스트-퀀텀 EPID(Post-Quantum EPID)와 같은 포스트 퀀텀 안 전 그룹 체계를 사용하여 그룹 멤버 간의 메시지 교환을 인증하거나 또는 공유 대칭 키 또는 쌍별 공유 대칭 키 의 그룹 키 교환을 용이하게 할 수 있다. 그룹은 그룹 멤버십을 관리하는 마스터 노드(예를 들어, 오케 스트레이터 등)를 지명하고, 그룹 키 생성 방법을 사용하여 멤버를 그룹에 가입시키고, 멤버의 다양한 개인 키 를 사용하여 형성된 서명을 인증하는 데 사용될 수 있는 그룹 인증서를 발급한다. 서명된 디피-헬만법(DH)과 같은 대칭 키 교환 프로토콜은 대칭 키를 동적으로 설정하는 데 사용될 수 있고, 그룹 서명 키는 (예를 들어, 시그마 프로토콜(Sigma protocol) 등을 사용하여) DH 메시지를 인증한다. 실시간 또는 \"저스트-인-타임(just-in-time)\" 그룹 내 보안 통신(” intra-group secure communication)은 \"실 시간\" 또는 \"저스트-인-타임\" 동작 이전에 키 교환 동작의 발판을 마련함으로써 달성될 수 있다. 오케스트레이 터는 각 멤버를 대신하여 그룹 협업 서비스를 실행하도록 스케줄링함으로써 이러한 모드에서 RT 및 JIT 협업 워 크로드가 실행될 시기를 조정한 다음, 오케스트레이터는 RT 또는 JIT 모드로 천이할 그룹 협업 서비스를 시그널 링한다. 오케스트레이터는 키 교환 작업을 직접 수행하거나 키 교환 관리 서비스에 성능을 위임하기 때문에 키 교환 작업이 완료되는 때를 알고 있다. 멤버 노드가 이동성이고 상이한 기지국으로 로밍하면, 로밍 컨텍스트에는 멤버의 그룹 서명 키 및 그룹 대칭 키 가 포함될 수 있다. 그룹 대칭 키는 빈번히 만료될 수 있어 주기적인 재 발급을 필요로 한다. 제 1 대칭 키를 사용하여 보호된 콘텐츠는 제 2 대칭 키가 협상될 때 수송되는 중일 수 있다. 만료 기간은 제 1 대칭 키로 암 호화된 콘텐츠가 제 2 대칭 키를 사용하여 해독되고 재 암호화될 수 있는 중첩 시간 윈도우를 포함할 수 있다. 키 만료는 키 관리 트래픽 전용의 그룹 컨텍스트를 사용하여 네트워크 브로드캐스트를 통해 그룹 멤버에게 동적 으로 전달될 수 있다. 또한, 키 만료는 만료 시간/날짜를 포함하고 (예를 들어, 커버러스(Kerberos) 등을 사용 하는) 그룹 리더/오케스트레이터/키 관리자 서비스에 의해 서명된 티켓 또는 토큰 구조를 사용하여 전달될 수 있다. 오케스트레이션, 그룹 리더 및 키 관리 서비스 또한 기지국 사이에서 로밍할 수 있다. 이것은 서비스 검색 레 지스트리를 새로운 서비스 위치 정보로 업데이트함으로써 가능해진다. 사전적 로밍 정보는 애플리케이션 컨텍 스트 정보에 기초하여 서비스 위치를 예측할 것이다. 이러한 데이터는 로밍 제어기에게 어떤 서비스 검색 정보 를 등록할지에 대해 알려준다. 에지 컴퓨팅 시스템(예를 들어, 에지 클라우드 및 구현 시스템 및 디바이스)에서 그룹 보안 통신을 구현하 기 위한 제 1 예시적인 방법(예 O1)은 (노드 또는 디바이스(2200, 2232, 2240 또는 2250)에서 또는 그에 의해 구현되는) 처리 회로를 사용하여 수행되는 방법으로서, 방법은, 에지 컴퓨팅 노드의 클러스터로부터 정의된 그룹에 대해, 에지 노드에서 그룹 통신 세션의 시작을 식별하는 단계; 그룹 통신 세션에 참여하는 한 세트의 그룹 멤버를 결정하는 단계; 그룹 통신 세션을 위한 보안 그룹 통신 채널을 생성하는 단계; 및 보안 그룹 통신 채널 을 사용하여 보안 통신을 용이하게 하는 데 사용될 그룹 멤버 세트의 멤버에게 키를 송신하는 단계를 포함한다. 제 2 예(예 O2)에서, 예 O1의 주제는, 통신 채널을 사용하여 그룹 멤버 세트에 의해 완료될 작업과 연관된 역할 을 결정하는 단계; 그룹 멤버 세트에 대한 기지국 세트를 식별 - 기지국 세트는 서비스를 그룹 멤버 세트에 제 공함 - 하는 단계; 및 기지국 세트의 하나 이상의 멤버의 역할을 활성화하는 단계를 포함한다. 제 3 예(예 O3)에서, 예 O1-O2의 주제는, 역할이 오케스트레이터, 그룹 리더 또는 키 관리자로 구성된 그룹으로 부터 선택되는 것을 포함한다. 제 4 예(예 O4)에서, 예 O1-O3의 주제는, 그룹 멤버 세트의 각각의 멤버와 키 교환을 수행함으로써 보안 통신 채널을 생성하는 단계를 포함하며, 여기서 키는 키 교환이 성공적으로 완료되면 멤버에게 송신된다. 제 5 예(예 O5)에서, 예 O1-O4의 주제는, 그룹 통신 세션이 종료된 것을 결정하는 단계; 키를 폐지하는 단계; 및 보안 그룹 통신 채널을 파괴하는 단계를 포함한다. 제 6 예(예 O6)에서, 예 O1-O5의 주제는, 협업 워크로드의 시작의 표시를 수신함으로써 그룹 통신 세션의 시작 을 식별하는 단계를 포함한다. 제 7 예(예 O7)에서, 예 O6의 주제는, 협업 워크로드에서 협력하도록 지정된 하나 이상의 노드의 표시를 수신함 으로써 그룹 통신 세션에 참여하는 그룹 멤버 세트를 결정하는 단계를 포함한다. 제 8 예(예 O8)에서, 예 O1-O7의 주제는, 그룹이 에지 컴퓨팅 시스템의 임의의 수의 엔티티로부터의 멤버십을 포함하는 것을 포함한다. 다양한 설정에서, 예 O1-O8(및 보안 그룹 통신의 다른 양태)은 정의된 애플리케이션 프로그래밍 인터페이스 또 는 인터페이스 사양; 통신 프로토콜, 메시지 포맷 또는 정의의 사용; 및 에지 컴퓨팅 환경 내에서 그룹을 정의 하고 그룹 통신을 수행하기 위한 정책 및 로직의 다른 사용 및 구현의 결과로서 관찰되거나 모니터링될 수 있다. 예 O1-O8 및 이러한 보안 통신 기술의 다른 양태는 또한 (예를 들어, FaaS 또는 EaaS 설정에서 시작되거 나 제공된 서비스에 대한 데이터를 전달하는) 서비스 동작 및 서비스 기능의 결과로서 관찰되거나 구현될 수 있 다. 또한, 예 O1-O8의 방법은 에지 컴퓨팅 시스템에서 (예를 들어, 명령어가 실행될 때 방법을 수행하는 머신 판독 가능 매체와 함께) 구현된 명령어로서 또는 (예를 들어, 방법을 수행하거나 달성하는 구성을 포함하는 장 치와 함께) 구현된 하드웨어 구성으로서 제공될 수 있다. 따라서, 예 O1-O8의 특징(및 보안 통신의 다른 관리 및 구성)은 시스템 오케스트레이터 또는 설계자에 의해 조정되거나 설계된 대로, 본 명세서의 임의의 다른 예와 결합되어 에지 클러스터 또는 에지 클라우드 시스템을 구성할 수 있다. 부채널 위험 최소화(Minimizing Side-Channel Risk)의 예 이해 충돌이 있는 것으로 알려진 테넌트는 서로 부채널 공격에 가담할 위험이 더 높을 수 있다. 한 가지 예방 적 접근 방식은 관심사에 따라 테넌트를 분류한 다음, 분석을 수행하여 충돌을 찾는 것이다. 테넌트 호스팅 환 경은 발견된 충돌에 기초하여 구조화되어, 충돌이 심한 테넌트를 (예를 들어, 기존 테넌트 격리 기술을 추가로 사용하는 것을 포함할 수 있는) 상이한 노드에서 분리할 수 있다. 에지 서비스는 멀티 테넌트 지원을 위해 이용할 수 있으며, 이것은 테넌트에게 부채널 공격을 준비할 기회를 초 래할 수 있다. 더 스마트한 서비스 배치를 사용하면, 예를 들어, 다른 테넌트와 경쟁할 이유가 있는 것으로 알 려진 또는 그렇지 않았다면 다른 테넌트와 이해 충돌이 있는 것으로 알려진 테넌트가 상이한 서비스 클래스를 고수하는 (예를 들어, 다른 노드를 사용하는) 서비스 클래스를 정의함으로써, 부채널 공격 위험을 줄일 수 있다. 에지 컴퓨팅 시스템(예를 들어, 에지 클라우드 및 도 3 내지 도 22d에 도시된 에지 컴퓨팅 시스템 구성)에 적용 가능한 예에서, 오케스트레이터, 서비스 제공자 및 서버는 이해 충돌이 있는 테넌트가 에지에 함 께 배치될 가능성을 방지하기 위해 (예를 들어, 일반 테넌트 격리 외에도) 서비스 클래스 경계를 따라 분할될 수 있다. 이해 충돌 관리는 워크로드 및 테넌트에 관한 프라이버시 보존 정보를 수집한 다음 이것을 이해 충돌 보안 모델 에 따라 평가하는 서비스로서 에지 환경에서 사용될 수 있다. 충돌하는 것으로 밝혀진 워크로드와 테넌트는 오 케스트레이션에게 충돌하는 워크로드를 더 큰 격리로 호스팅하도록 알릴 수 있다. 이해 충돌 서비스는 테넌트 의 프라이버시와 그들의 이익을 보호하기 위해 신뢰성 있는 실행 환경에서 자체적으로 호스팅될 수 있다. 이러 한 목적으로 수집되는 모든 네트워크, 플랫폼 또는 워크로드 거동(예를 들어, 상태 전환) 원격 측정은 또한 프라이버시 보호의 대상이 될 수 있으며 신뢰성 있는 실행 환경(trusted execution environment)(TEE) 내에서 수 행될 수 있다. 부채널 공격은 탑재하기가 쉽지 않고 채널(예를 들어, 캐시, 메모리, 시그널링 방법 등)에 불확실성을 도입하여 매우 어렵게 만들 수 있기 때문에, 본 명세서에서 설명된 인프라스트럭처는 당사자의 알 수 없는 속성으로 인해 충돌 분석이 불가능할 수 있을 때 선택적으로 다양한 섭동 소스를 도입할 수 있다. 즉, 어떤 이유로 충돌 분석 이 결정적이지 않다면, 인프라스트럭처는 드물지만 가능한 부채널 공격을 수행하기 어렵게 만드는 무작위 섭동 을 도입할 수 있다. 또한, 이러한 섭동은 애플리케이션의 성능에 영향을 주지 않는 것으로 알려진 자원에 추가 될 수 있다. (예를 들어, 메모리 채널 1이 전혀 이용되지 않으면, 이 채널은 섭동으로서 사용될 수 있다. 그 러나 이러한 채널의 사용은 전력 및 기타 자원 측면에서 금전적 또는 자원 비용에 대해 고려될 수 있다). 에지 생태계에는 이해 충돌이 있는 테넌트 또는 이해 관계자가 포함될 수 있다. 오케스트레이션의 일부로서 에 지/MEC 자원에 대한 충돌 분석을 사용함으로써, 에지는 부적절한 활동과 관련된 시나리오를 검출할 수 있다(그 리고 방지할 수 있다). 또한, 충돌 분석은 어떤 다른 테넌트가 위협을 가할 가능성이 가장 높은지를 알고 싶어 하는 테넌트에게 서비스(CAaaS)로서 제공될 수 있으며 - 따라서 더 강력한 완화 솔루션을 위한 시장에 내놓을 수 있다. 도 47은 서비스로서 충돌 분석(Conflict-Analysis-as-a-Service)(CAaaS) 제공자를 포함하는 에지 시스템 의 개요를 보여주는 시스템 다이어그램을 도시한다. 이해 충돌이 있는 것으로 알려진 테넌트는 서로 부 채널 공격에 참여할 위험이 더 높을 수 있다. 이해 관계에 따라 테넌트를 분류한 다음 분석을 수행하여 가능한 이해 충돌을 식별하는 것이 에지 아키텍처 내에서 이해 충돌 서비스를 구현하는 데 사용될 수 있다. 예에서, CAaaS 서비스 제공자는 에지 노드(4711, 4712)의 이러한 테넌트 인스턴스(4708, 4710, 4714, 4716) 중에서, 테넌트 충돌에 민감한 더 스마트한 워크로드 스케줄링 할당을 만들기 위해 에지 오케스트레이션 (예를 들어, 오케스트레이터)에 알릴 수 있다. 테넌트 호스팅 환경은 일반적으로 테넌트 격리 캐퍼빌리 티를 갖는 것으로 예상된다. 예를 들어, 오케스트레이터는 어떤 테넌트 격리 기술(예를 들어, SGX, 가상화, 신 뢰영역(TrustZone), FPGA 등)이 이용 가능한지를 보고하는 에지 노드 증명을 요구할 수 있다. 그러나 이러한 테넌트는 여전히 자원(예를 들어, CPU 코어, 캐시, PCIe 버스 등)을 공유할 수 있다. 이해 충돌 정도가 높은 것으로 발견된 테넌트는 부채널 악용의 가능성을 최소화하기 위해 추가 격리가 필요할 수 있다. 예를 들어, 오 케스트레이터는 충돌하는 테넌트를 (예를 들어, 지역화된 테넌트 격리 기술을 적용하는 것 외에도) 물리적으로 다른 에지 노드에서 실행하도록 스케줄링할 수 있다. 도 47에서, 테넌트 T1 및 테넌트 T3는 이해 충돌이 높은 반면 테넌트 T1 및 테넌트 T2는 이해 충돌이 낮다. 테넌트 T1 및 테넌트 T3 워크로드는 상이한 에지 노드에서 실행되도록 스케줄링되는 반면 테넌트 T1 및 테넌트 T2 워크로드는 로컬로 스케줄링될 수 있다. 예에서, \"프라이버시 필터\"는 수집기와 CAaaS 제공자 사이에서 구현될 수 있다. 예를 들어, 실제 원격 측정 데 이터는 결코 전송되지 않고, 대신에 외부에서 관찰 가능한 워크로드 거동 경향이 전송된다. 테넌트 컨테이너는 VM, 프로세스, 워크로드 이미지 등을 포함할 수 있다. CAaaS는 테넌트에게 프라이버시를 제공할 수 있다. 예 를 들어, 데이터는 선택적으로, 추가 세부 사항 없이, 제한 사항(예를 들어, 노드에서 T1이 아니라 T3과 함께)만 포함할 수 있는 이해 충돌 맵을 이외에는 CAaaS 외부에 노출되지 않는다. 예에서, CAaaS는 테넌트 워크로드에 의해 보호되지 않는 네트워크 메타데이터(예를 들어, IP 헤더, IP QoS, 터 널/TLS 협상 파라미터 등)의 주위에 적용될 수 있다. 추가 예에서, 원격 측정 수집기는 보안 또는 프라이버시 정책에 따라 원격 측정 필터를 조정하는 LSM 시 행 지점일 수 있다. LSM 정책은 테넌트 특정, 도메인 특정 또는 에지 인프라스트럭처 특정일 수 있다. 마찬가 지로, 도 47의 컨텍스트에서, 오케스트레이터는 LSM 정책/사용자 레벨 협약을 협상할 수 있고 원격 측정 수집기 및 테넌트 호스팅 환경과 같은 다른 시행 지점에 따라 LSM을 프로비저닝할 수 있다. 도 48은 CAaaS 제공자 컴포넌트를 보여주는 시스템을 도시한다. CAaaS 제공자는 이해 충돌 집행 맵에 기초한 벽(wall)을 구성하는 여러 동작을 수행한다. 이러한 맵은 차례로 (예를 들어, 관련 코드, 로직 또 는 알고리즘을 구현할 수 있는) 워크로드 스케줄링 프로세스에 적용하는 과 같은 오케스트레이터에 의해 소모된다. CAaaS 제공자의 컴포넌트는 아래에서 설명되는 컴포넌트를 포함할 수 있다. 머신 학습 패턴 인식 엔진은 원격 측정 수집 집중기(concentrator)로부터 원시(raw) 원격 측정을 수집한 다. 패턴 인식 엔진은 잠재적인 이해 충돌 지능 아티팩트를 식별하도록 훈련된 머신 학습 분류기를 사용하여 원시 원격 측정을 분석한다. 아티팩트는 엔티티 주체(예를 들어, 사용자, 사용자의 연결 네트워크에 있는 사람, 조직, 그룹, 시민권, 제휴 또는 사용자와 연관된 비즈니스 벤처) 또는 엔티티 속성(예를 들어, 데이터, 컨텍스트, 트랜잭션, 메타데이터 또는 주체를 연결하는데 사용되는 다른 정보)을 식별하는데 사용되는 임의의 유형의 정보를 포함할 수 있다. ML 또는 DL 분류기는 원칙과 속성 간의 관계를 보여주는 관심 패턴을 생성한다. 예를 들어, (예를 들어, 회사 제휴에 의해 식별된) 6 개의 주체: 회사 A 내지 회사; 및 특정 분야의 회사, 소송 이력이 있는 회사, 명시된 수 초과의 직원을 보유한 회사 등과 같은 5 개의 속성이 주어지면, 주체와 속성을 연 결하는 관계는 매트릭스로 표현될 수 있다: R| a b c d e --|------------ 1| - + + + + 2|+ 0 - - - 3| + - - - 0 4| 0 - - 0 - 5| + - - - - 6| 0 + - 0 + 여기서 (+)는 우호적인 연관, (-)는 적대적인 연관, 은 중립적인 연관을 의미한다. 연관 및 관계의 변동 또 는 레벨을 나타내는 다른 축척된 또는 숫자 값도 또한 추적될 수 있다. 에지 노드의 배치에 대한 추가 분석은 테넌트 원점 또는 실제 에지 위치가 기본적으로 배치되는 위치에 기초하 여 적용될 수 있는 법률의 유형을 포함할 수 있다. 예를 들어, 두 가지 유형의 고려 사항은 다음과 같은 것을 포함한다: 1. 플랫폼의 물리적 위치. 패턴 인식 엔진은 현재 국가에서 적용되는 잠재적인 규칙을 식별하기 위해 지 리적 위치를 사용할 수 있다. 예에서, 에지 노드가 이동 중일 수 있다. 2. 서비스를 실행하는 테넌트의 출처. 에지 로케이션과 마찬가지로,, 테넌트는 국가와 같이, 자신의 위치에 관 계없이 테넌트와 함께 갈 수 있는, 위치에 기초한 정책을 가질 수 있다. 예에서, 및 에 의해 부과될 수 있는 규칙은 패턴 인식 엔진에 의해 분석된 파트너에도 종속적일 수 있다. 예를 들어, 프라이버시 또는 보안 정책은 특정 버스가 다중 테넌트와 공유되는 경우에만 적용할 수 있다. 관심 패턴은 충돌 분석 엔진(CAE)에 의해 소비될 수 있다. CAE는 특히 LSM이 이해 충돌 정책을 공급하는 LSM 시행 지점일 수 있다. 다른 시스템 컴포넌트는 서비스 레벨 협약(SLA) 분석기 엔진(SAE)이다. SAE는 CAaaS 제공자를 사용하는 오케스트레이터에 의해 잠재적으로 스케줄링된 각각의 테넌트로부터의 SLA 입력(예를 들어, 사용자 지능 의 사용자 컨텍스트)을 받아들인다. SAE는 SAE가 상호 상관될 수 있는 주체 및 속성을 찾는 SLA를 스캔할 수 있다는 점에서 패턴 인식 엔진과 유사한 기능을 수행한다. SAE는 SLA 구조를 파싱하고 워크로드 처리의 시맨틱을 이해할 수 있기 때문에 ML 또는 DL 분류기를 사용할 필요가 없다. 다른 예에서, SAE는 프라이버시 고 려 사항으로 인해 실제 워크로드 데이터 및 알고리즘 콘텐츠에 대한 당사자가 아닐 수 있다. CAaaS 시스템은 보다 정확한 관심 패턴을 구축하기 위해 워크로드 이미지를 심층 분석할 수 있게 하는 테넌트 인센티브를 제공 할 수 있다. SAE는 워크로드 분석을 위해 ML 또는 DL 분류기를 활용할 수 있다. 관심 패턴은 추가 처리를 위 해 CAE에 전달된다. SAE가 상관 또는 분류를 개선하기 위해 사용할 수 있는 하나의 양태는 워크로드 자체에 의해 활용되는 자원에 내재된 상이한 특성을 상관시키는 것이다. 상이한 CPU 및 플랫폼 자원은 분류 또는 데이터 필터링을 개선하기 위해 SAE에 의해 사용될 수 있는 상이한 레벨의 격리 또는 보안 특성을 가질 수 있다. 분류는 다음과 같은 것 을 사용하는 것을 포함할 수 있다.1. 잠재적 충돌을 완전히 제거할 수 있는 보안 엔클레이브 또는 메모리 암호화와 같은 특징을 포함할 수 있는 플랫폼 보안 및 다중 테넌트 암호화. 다른 예에서 SAE는 시스템이 충돌이 없음(또는 제한된 충돌)을 인증하기 위해 이러한 특징 중 어느 특징이 특정 워크로드에서 실제로 이용되는지를 검증해야 한다. 2. 자원 격리는 이해 충돌 매핑을 변경할 수 있다. 자원 격리에서, 상이한 자원 또는 플랫폼 특징은 특정 SLA 의 관점을 변경할 수 있다. 예를 들어, SAE는 자원이 테넌트별로 분할된 하드웨어인지 또는 자원이 다중 테넌 트에서 공유되지 않을 것인지를 체크할 수 있다. 예에서, 분석 및 의 목표는 SLA가 깨질 수 있는지 또는 플랫폼 또는 CPU 특징의 상이한 조합에 대해 개선 될 수 있는지를 확인하는 것이다. 예에서, 컴포넌트는 워크로드 평판 제공자를 포함한다. 워크로드가 분산되고 각각의 하위 컴포넌트 사이 에서 더 많이 통신함에 따라, 그들의 I/O 거동을 관찰함으로써 상당한 양의 추가 정보가 학습될 수 있다. 예를 들어, 제어, 데이터 및 관리 평면을 위한 다수의 FaaS가 있는 vPGW와 같은 네트워킹 워크로드, 및 전체적인 기 능을 전달할 이러한 FaaS 간의 상호 통신. 예에서, 네트워크 서비스 제공자 또는 ISV는 (예를 들어, 비 사적인 데이터에 기초하여) 제공자에서 워크로드 평판 프로파일의 데이터베이스를 개발할 수 있다. 이러한 데이 터는 이제 다수의 비즈니스 목적 - 시장 지능, 제품 가격 책정, 고용 등 - 에 점점 더 사용되고 있다. 일 예에 서, 워크로드 평판에 관한 유사한 정보가 CAaaS 제공자로의 입력으로서 사용되어 보다 결정적이고 효과적 인 결과를 지원할 수 있다. 추가 시스템 컴포넌트는 충돌 분석 엔진(conflict analysis engine)(CAE)을 포함한다. CAE는 충 돌 관계를 더욱 개선하기 위해 필요할 때 \"퍼지(fuzzy)\" 관심 패턴에 가중치를 적용한다. 비즈니스 중심의 충 돌 관계는 비즈니스 경쟁자가 비례적인 이해 충돌을 갖고 있다고 결정할 수 있다. 예를 들어, 다음의 차트는 대응하는 시장 점유율 정보가 있는 5 개의 상점과 4 개의 비즈니스 라인을 보여준다. 다른 예에서 이것들은 임 의의 규제 정의 파라미터(유럽 연합 일반 데이터 보호 규정(General Data Protection Regulation)(GDPR)과 같 은 지역 특정 규정), 상호 신뢰하지 않는 조직(예를 들어, 은행, 카지노, 감사 회사 등), 알려진 충돌 등일 수 있다. Shops | e-Card| e-Stock| e-Chat| e-Purchase ----------------|----------|----------|----------|------------- eshop1.com| 0.21 | -1 | -1 | 0.47 eshop2.com| 0.03 | 0.08 | 0.24 | -1 eshop3.com| 0.75 | 0.00 | 0.35 | 0.16 eshop4.com| -1 | 0.90 | 0.35 | 0.31 eshop5.com| 0.01 | 0.02 | 0.05 | 0.06 충돌이 비즈니스의 라인에만 특유하지 않고 오히려 비즈니스-투-비즈니스(business-to-business)(B2B) 관계로 표현될 필요가 있도록 가중치 인자가 적용될 수 있다. eshop1| 0.00 0.00 0.49 0.20 0.00 eshop2| 0.00 0.00 0.15 0.15 0.00 eshop3| 0.40 0.15 0.00 0.29 0.00 eshop4| 0.20 0.15 0.29 0.00 0.00 eshop5| 0.00 0.00 0.00 0.00 0.00 ------------------------------------------------------------------ eshop1 eshop2 eshop3 eshop4 eshop5 이러한 관계는 이해 충돌이 중요하다고 생각될 때 임계치를 적용함으로써 이진 관계로 전환될 수 있다. 예를 들어, 40% 시장 점유율 임계치가 선택되었다면, eshop1 및 eshop3 만이 상당한 이해 충돌이 있는 것으로 인식된 다. 충돌 관계의 결과는 격리 정책 모듈(isolation policy module(IPM))에 입력될 수 있는 CI 관계 맵이라고 알려져 있을 수 있다. IPM 컴포넌트는 CI 맵과 함께 사용되어 시행 맵이라고 호칭하는 격리 시행 정책(예를 들어, \"중국 벽(Chinese wall)\" 시행 정책)을 알릴 수 있다. 시행 맵은 한 세트의 원칙(P), 한 세트의 객체(O), P와 O에 관련된 행렬 N 및 R(Pi, Oj)가 승인된 액세스 권한인 R로 표시된 액세스 레벨을 관련시키는 4-튜플(tuple)을 포함할 수 있다. 예를 들어, 액세스는 RESTful API 액세스(생성, 판독, 업데이트, 삭제, 통지) 또는 파일 액세스 허가(판독, 기 입, 실행) 또는 단순히 바이너리 액세스의 측면에서 설명될 수 있다. 또한, 액세스는 구역 0이 격리가 필요하 지 않음을 의미하는 코로케이션 구역의 관점에서 설명될 수 있다. 구역 1은 프로세스 격리가 필요하다는 것을 의미하고, 구역 2는 가상 머신, 구역 3은 (이를테면 Intel®SGX 보안 엔클레이브에 의해 제공되는) 보안 엔클레 이브 및 구역 4는 물리적 격리를 의미한다. 시행 맵은 오케스트레이터 또는 테넌트 격리 및 액세스의 시 행을 맡은 에지 생태계의 다른 엔티티로 전달된다. 예를 들어, 워크로드를 처리할 수 있는 다수의 서비스에 걸쳐 사용될 수 있는 액세스 토큰을 생성하는 OAuth 서 버에 액세스 맵이 제공될 수 있다. 액세스 토큰은 주체 및 그 각각의 액세스 권한 또는 격리 구역(또는 이들의 조합)의 표현을 포함할 수 있다. 예에서, OAuth 토큰에는 OAuth 서버에 인증된 주체의 ID가 포함된다. 아이덴 티티는 자원 서버에 의해 사용되어 그 서버의 주체에 적절한 레벨의 액세스를 수용하고 있는 로컬 액세스 제어 정책을 참조한다. IPM은 오케스트레이션 안내 정보를 포함하도록 OAuth 토큰의 시맨틱을 수정할 수 있다. IPM 은 주체가 OAuth 토큰을 인증하고 획득할 때 OAuth 서버에 제공된다. 그런 다음 주체는 워크로드 및 OAuth 토 큰을 제공하는 오케스트레이션 서비스를 요청할 수 있다. 오케스트레이터는 토큰을 파싱하여 IPM 콘텐츠를 찾 는다. 제 2 주체는 제 1 주체와 유사한 일련의 동작을 수행한다. 오케스트레이터는 IPM 정책이 이해 충돌을 드러낼 때 주체 P1 및 주체 P2에 대한 IPM 정책을 준수한다. 오케스트레이터는 각각의 서비스 호스트에서 이를 적절하 게 스케줄링한다. 토큰은 워크로드와 함께 호스팅 서버로 포워딩될 수 있고, 토큰에는 호스트 서버와 연관된 자원에 대한 (r-w-x와 같은) 추가 액세스 제어 권한이 포함되어 있을 수 있다. 추가 예에서, 부채널 위험을 최소화하기 위한 방법은 테넌트(예를 들어, 노드 또는 디바이스(2200, 2232, 2240 또는 2250)에서 또는 그에 의해 구현된 테넌트 인스턴스) 간의 이해 충돌을 해결하는 기술을 구현할 수 있다. 기술은 서비스로서의 충돌 분석(conflict analysis as a service)(CAaaS)을 수행하는 프로세서에서, 원격 측정 수집기로부터 복수의 에지 노드에 대한 원격 측정 정보를 수신하는 제 1 동작을 포함한다. 예에서, 원격 측정 정보는 사적 정보 없이 외부에서 관찰 가능한 워크로드 거동 추세(workload behavioral trend)를 포함한다. 기술은 CAaaS를 수행하는 프로세서를 사용하여, 원격 측정 정보를 사용하여 액세스 맵을 생성하는 제 2 동작을 포함한다. 액세스 맵을 생성하는 것은 프로세서를 사용하여 충돌 분석 엔진을 구현하여 사용자 데이터, 원격 측정 정보 및 테넌트의 평판 데이터로부터 관심 패턴을 비교하여 맵을 생성할 수 있다. 예에서, 액세스 맵은 서비스 레벨 협약(SLA)의 속성과 같은 사용자 컨텍스트에 기초하여 생성된다. 다른 예에 서, 액세스 맵은 원격 측정 정보를 입력으로서 사용하는 머신 학습 패턴 인식 엔진으로부터의 출력에 기초하여 생성된다. 액세스 맵은 다수의 충돌 레벨 및 연관된 격리 요구 사항을 포함할 수 있다. 액세스 맵은 RESTful API 액세스, 파일 액세스 허가 또는 바이너리 액세스 중 적어도 하나에 대한 권한 제한 사항을 포함할 수 있다. 액세스 맵은 격리 없음, 프로세스 격리, 가상 머신, 엔클레이브 또는 물리적 격리 중 적어도 하나를 포함하는 격리 레벨을 포함할 수 있다. 기술은 오케스트레이터에 액세스 맵을 제공하여 액세스 맵에 따라 복수의 에지 노드 사이에 테넌트를 할당하는 제 3 동작을 포함한다. 예에서, 오케스트레이터는 충돌하는 테넌트를 복수의 에지 노드 중 물리적으로 상이한 에지 노드에서 실행시키도록 스케줄링하도록 구성된다. 에지 컴퓨팅 시스템(예를 들어, 도 7 내지 도 12와 관련하여 도시되고 설명된 에지 서비스와 기능 사이의 에지 클라우드)에서 부채널 위험을 최소화 하기 위한 시스템 구성을 구현하기 위한 제 1 예시적인 방법(예 P1) 은 (예를 들어, 노드 또는 디바이스(2200, 2232, 2240 또는 2250)에 의해 구현되는) 처리 회로를 사용하여 수행 되는 것으로서, 방법은, 서비스로서의 충돌 분석(conflict analysis as a service)(CAaaS)을 수행하는 프로세 서에서, 원격 측정 수집기로부터, 복수의 에지 노드에 대한 원격 측정 정보를 수신하는 단계; CAaaS를 수행하는 프로세서를 사용하여, 원격 측정 정보를 사용하여 액세스 맵을 생성하는 단계; 및 오케스트레이터에게 액세스 맵을 제공하여 액세스 맵에 따라 복수의 에지 노드 사이에 테넌트를 할당하는 단계를 포함한다. 제 2 예(예 P2)에서, 예 P1의 주제는 서비스 레벨 협약)(SLA)에 정의된 속성을 포함하는 사용자 컨텍스트에 기 초하여 액세스 맵이 생성되는 구성을 포함한다. 제 3 예(예 P3)에서, 예 P1-P2의 주제는 원격 측정 정보를 입력으로서 사용하는 머신 학습 패턴 인식 엔진의 출 력에 기초하여 액세스 맵이 생성되는 구성을 포함한다. 제 4 예(예 P4)에서, 예 P1-P3의 주제는, 프로세서가 충돌 분석 엔진을 구현하여 사용자 데이터로부터의 관심 패턴, 원격 측정 정보 및 테넌트의 평판 데이터를 비교하여 맵을 생성하는 것을 포함한다. 제 5 예(예 P5)에서, 예 P1-P4의 주제는, 오케스트레이터가 충돌하는 테넌트를 복수의 에지 노드 중 물리적으로 상이한 에지 노드에서 실행시키도록 예약하도록 구성되는 것을 포함한다. 제 6 예(예 P6)에서, 예 P1-P5의 주제는, 액세스 맵이 다수의 충돌 레벨 및 연관된 격리 요구 사항을 포함하는 구성을 포함한다. 제 7 예(예 P7)에서, 예 P1-P6의 주제는, 원격 측정 정보가 사적 정보 없이 외부에서 관찰 가능한 워크로드 거 동 추세를 포함하는 것을 포함한다. 제 8 예(예 P8)에서, 예 P1-P7의 주제는, 액세스 맵이 RESTful API 액세스, 파일 액세스 권한 또는 바이너리 액 세스 중 적어도 하나에 대한 권한 제한 사항을 포함하는 구성을 포함한다. 제 9 예(예 P9)에서, 예 P1-P8의 주제는, 액세스 맵이 격리 없음, 프로세스 격리, 가상 머신, 엔클레이브 또는 물리적 격리 중 적어도 하나를 포함하는 격리 레벨을 포함하는 구성을 포함한다. 다양한 설정에서, 예 P1-P9(및 충돌 분석 및 오케스트레이션 액세스 관리의 다른 양태)는 통신 프로토콜, 메시 지 포맷 또는 정의에 대한 사용 및 모니터링; 오케스트레이션 구성; 및 에지 컴퓨팅 환경 내에서 액세스 제어, 격리 및 신뢰 메커니즘에 대한 정책 및 로직의 다른 사용 및 구현의 결과로서 관찰되거나 모니터링될 수 있다. 예 P1-P9 및 이러한 액세스 관리 기술의 다른 양태는 또한 (예를 들어, FaaS 또는 EaaS 설정에서 보안 격리 및 정책 구현을 구현하는) 서비스 동작 및 서비스 기능의 결과로서 관찰되거나 구현될 수도 있다. 또한, 예 P1-P9 의 방법은 에지 컴퓨팅 시스템에서 (예를 들어, 명령어가 실행될 때 방법을 수행하는 머신 판독 가능 매체와 함 께) 구현된 명령어 또는 (예를 들어, 방법을 수행하거나 달성하기 위한 장치와 함께) 구현된 하드웨어 구성으로 서 제공될 수 있다. 따라서, 예시 P1-P9의 특징(및 충돌 분석 및 보안 정책 구현의 다른 특징)은 시스템 오케 스트레이터 또는 설계자에 의해 조정되거나 설계된 대로, 본 명세서의 임의의 다른 예와 결합되어 에지 클러스 터 또는 에지 클라우드 시스템을 구성할 수 있다. 암시적 증명(Implicit Attestation)의 예 서비스 레벨 협약(SLA) 또는 테넌트 SLA와 같은 성능 협약은 종종 서비스가 어떻게 제공될지 또는 테넌트(예를 들어, 구독자) 데이터가 어떻게 보호될 것인지에 관한 요구 사항 - 법적 또는 재정적 영향을 포함할 수 있음 - 이 만들어지는 가정을 포함한다. 다중 이해 당사자 에지 환경(예를 들어, 에지 클라우드 및 도 3 내지 도 22d에 도시된 에지 컴퓨팅 시스템 구성)은 여럿의 그리고 균등하게 원격으로 연관된 이해 당사자를 가질 수 있 다. 암시적 증명은 에지 이해 당사자에 의해 사용되어 이러한 그리고 다른 관련된 서비스 공급자 SLA 조건을 증명할 수 있다. 다음의 예에서, 암시적 증명은 디바이스 식별자 구성 엔진(Device Identifier Composition Engine)(DICE) 아키 텍처를 사용하여 달성될 수 있다. 여기서, 예를 들어, 증명 프로파일에서 SLA 조건을 포함하는 워크로드 특정 서명 키가 도출될 수 있다. DICE 서명 키 도출은 에지 배치가 다중 테넌트 호스팅뿐만 아니라 캐퍼빌리티의 확 장할 수 있도록 하는데 특히 유용할 수 있다. SLA에 따른 서비스 완료에 대한 제 3 자의 검증 가능한 주장은 과금, 네트워크 모니터링, 서비스 품질(QoS) 평가 등과 같은 이러한 다자간 상호작용에서 중요한 요소가 될 수 있다. SLA 프로필을 사용하여 암시적 증명을 구현하기 위해, 워크로드는 신뢰성 있는 컴퓨팅 기반(trusted computing base)(TCB) 또는 다른 신뢰성 있는 컴퓨팅 하드웨어 배열에서 구현할 수 있는, 테넌트 엔클레이브, 컨테이너 또 는 다른 테넌트 격리 환경에서 실행될 수 있다. 호스팅 환경은 워크로드 특정 증명 키를 도출할 수 있다. 이러 한 도출의 일부는 복합 디바이스 아이덴티티(compound device identity)(CDI)를 연산하는 것을 포함한다. 예에 서, CDI 계산은 SLA로부터 가져온 예상된 신뢰도 파라미터를 포함한다. 예를 들어, 에지 컨소시엄 및 테스트 시설은 보안, 안전 또는 프라이버시 보호 캐퍼빌리티에 대해 호스팅 플랫폼을 검사하고, 검사에 기초하여 준수 선언문을 발행할 수 있다. SLA는 명시된 준수 레벨을 요구할 수 있거나 또는 그 준수 레벨이 워크로드 실행의 일부로서 증명 또는 검증을 필요로 한다는 것을 요구할 수 있다. 워크로드가 테넌트 환경에서 실행될 때, 테넌트 환경은 신뢰 루트(RoT) 또는 TCB 계층으로부터 워크로드 특정 증명 키를 요청할 수 있다. RoT 또는 TCB는 다음 계층 n의 키를 연산하고 여기서 n은 워크로드를 호스팅하는 테넌트 환경을 식별한다. 예에서, 계층 n CDI 는 현재 TCB 컨텍스트(current TCB context)(CTC)를 SLA에 의해 식별된 준수 증명서로 해싱함으로써 연산된다. 증명 키는 워크로드 결과(및 잠재적으로는 실행으로부터의 원격 측정)에 서명하는데 사용되고, 그럼으로써 워크 로드 실행의 준수 상태를 암시적으로 증명한다. 도 49는 DICE 계층(4901, 4902, 4903, 4904)와 관련하여 CDI 컴퓨테이션의 예를 예시한다. 도시된 바와 같이, 계층의 CTC(4911, 4912, 4913, 4914)는 증명 계층에 의해 연산되고 CDI(4921, 4922, 4923)로서 반환된다. 이것은 비대칭 키(5012, 5013, 5014)가 각각의 계층별로 CTC(4911, 4912, 4913, 4914)에 대해 연산 되는 컴퓨테이션을 도시하는 도 5와 대조된다. 도 50에서, CTC의 교차 계층 검증은 없다. 도 51은 워크로드 특정 증명 키를 생성하기 위해 DICE 계층화를 사용하는 SLA 파라미터의 암시적 증명을 사용하 는 에지 컴퓨팅 엔티티(예를 들어, 콘솔, 코어 서버, 오케스트레이터, 기지국, 테넌트)를 통한 데이터 흐름을 도시한다. 도 51에서, 특정 데이터 흐름 동작이 도시되지만, 이것 은 다른 변형 및 동작 시퀀스가 이러한 프레임워크 내에서 적용될 수 있다는 것을 이해할 것이다. 예에서, 코 어 서버 또는 기지국은 일반 프로세서 또는 다른 시스템-온-칩(SoC) 컴포넌트를 포함할 수 있다. 예에서, 이러한 엔티티는 또한 가속기 하드웨어를 포함할 수 있다. 예에서, 가속기는 플랫폼(예를 들어, SoC, 마더 보드 등)에 직접 설치되거나 또는 플랫폼 버스를 통해 액세스할 수 있다(예를 들어, 암호화, AI, 필드 프 로그램 가능 게이트 어레이(FPGA) 등을 위해 주변 컴포넌트 상호연결 익스프레스(peripheral component interconnect express)(PCIe) 카드에서 추가될 수 있다). 도 51의 컨텍스트에서, DICE 키는 LSM 시행 지점을 제공할 수 있다. DICE 키 생성은 LSM 특정 키만 존재 하도록 LSM 컨텍스트를 포함할 수 있다. LSM이 변경되면, 노드는 LSM 특정 키를 예상하는 다른 노드와 함께 참 여할 수 없다. 또한, 오케스트레이터(이를테면 오케스트레이터)는 증명 LSM을 증명 검증자에게 프로비저 닝할 수 있으며, 증명 검증자는 DICE-LSM 키 또는 다른 키에 결부되어 있는지에 관계없이 LSM 시행 지점으로서 동작한다. 예를 들어, LSM은 허용 가능한 또는 허용 가능하지 않은 증명 값을 설명할 수 있다 일부 시나리오에서, SLA의 특정 속성은 비밀이거나 모호할 수 있다. SLA 값이 워크로드 자체에 의해 드러내 보 이지 않으면, 워크로드는 예를 들어 입력-출력(I/O) 이더넷 대역폭의 30 기가비트(Gbps)의 SLA를 갖고 있다고 드러내 보이지 않아야 한다. 이러한 시나리오에서, 서명된 SLA는 등록된 SLA에 대해 정규화된 값을 제공할 수 있다. 예를 들어, 정규화된 값은 SLA가 충족되었다는 결정으로 이어진 메트릭 또는 측정을 보고하기 보다는, SLA가 충족되었음을 표시할 뿐이다. 예에서, 정규화된 값은 메트릭을 드러내 보이지 않는 방식으로 메트릭을 표시할 수 있다. 따라서, 예를 들어, 정규화된 값은 이를 테면 SLA가 110 %(예를 들어, 35 Gbps) 또는 90 %(예 를 들어, 28 Gbps)로 만족된다는 것을 보여주는, SLA 값의 퍼센트일 수 있다. 테넌트 워크로드가 하나 이상의 가속기 슬라이스, 가상 기능 또는 물리적 기능과 함께 컴퓨트 코어(들)에서 실 행되는 배치 시나리오에서, 워크로드 특정 증명 키 도출은 가속기 또는 기능의 특정 SLA 파라미터를 포함할 수 있다. 예를 들어, 스마트 네트워크 인터페이스 제어기(smart network interface controller)(SmartNIC)의 경 우, SLA 파라미터는 전달된 처리량, 가상 큐의 수, 보안 연결의 수 등을 포함할 수 있다. 인공 지능(AI) 가속 기의 경우, SLA 파라미터는 다른 것 중에서도, 모델 스토리지 크기, 실행 유닛 또는 전용 런타임 메모리를 포함 할 수 있다. 이러한 경우, CDI는 가속기 특정 파라미터를 사용하여 도출될 수 있다. 본 명세서에서 설명된 암시적 증명은 일반적인 또는 광범위한 유스 케이스 세트에 걸쳐 적용되는 SLA 파라미터 에 특히 유용할 수 있다. 이러한 유용성은 파라미터의 변경으로 인해 증명 키가 무효화되어, 디바이스 또는 서 비스를 재배치하거나 또는 재등록해야 하기 때문에 발생한다. 따라서, 컴포넌트 서비스 제공자(component service provider)(CSP)가 사업자에게 보안 프로토콜(예를 들어, 케르베로스(Cerberus))을 실행하도록 요구한다 면, 공격자가 SLA 요구 사항을 모두 달성하면서, 플랫폼을 수정하지 않고 DICE 키를 깰 수 없는 한 테넌트 환경 으로의 액세스는 거부된다. 또 다른 예에서, 암시적 증명의 예는 상이한 도메인 또는 신뢰 유형에 대해, 또는 상이한 수준의 필요한 신뢰의 사용을 위해 적용될 수 있다. 결과적으로, 데이터 또는 파생 속성에 대해 많은 증명 시나리오가 적용될 수 있 다. (예를 들어, 에지 클라우드에서 및 구현 시스템 및 디바이스 사이에서) 에지 노드의 암시적 증명을 구현 하기 위한 제 1 예시적인 방법(예 Q1)은 (예를 들어, 노드 또는 디바이스(2200, 2232, 2240 또는 2250)에 의해구현되는) 처리 회로를 사용하여 수행되는 방법으로서, 방법은, 서비스 레벨 협약(SLA) 파라미터에 의해 정의된 테넌트 워크로드 환경에 대한 실행 컨텍스트를 획득하는 단계; 실행 컨텍스트에 대한 증명 키를 획득하는 단계; 테넌트 워크로드 환경 및 증명 키를 사용하여 컴포넌트 디바이스 아이덴티티(CDI)를 연산하는 단계; 테넌트 워 크로드 환경에서 워크로드를 수행하여 SLA 파라미터의 성능 메트릭을 포함하는 결과를 생성하는 단계; 결과를 CDI로 서명하는 단계; 및 서명된 결과를 워크로드의 요청자에게 전송하는 단계를 포함한다. 제 2 예(예 Q2)에서, 예 Q1의 주제는, CDI는 워크로드를 수행하는 계층과 상이한 계층에서 연산되는 것을 포함 한다. 제 3 예(예 Q3)에서, 예 Q1-Q2의 주제는, 성능 메트릭이 SLA 파라미터가 수신자에 의해 식별되는 것을 방지하기 위해 정규화되는 것을 포함한다. 제 4 예(예 Q4)에서, 예 Q1-Q3의 주제는, 테넌트 워크로드 환경이 신뢰성 있는 컴퓨팅 기반(TCB)인 구성을 포함 한다. 다양한 설정에서, 예 Q1-Q4(및 암시적 증명 및 실행 관리의 다른 양태)는 정의된 애플리케이션 프로그래밍 인터 페이스 또는 인터페이스 사양; 특정 에지 구성 및 워크로드; 및 에지 컴퓨팅 환경 내에서 암시적 증명에 대한 정책 및 로직의 다른 사용 및 구현의 결과로서 관찰되거나 모니터링 될 수 있다. 예 Q1-Q4 및 암시적 증명 및 실행 관리의 다른 양태는 또한 (예를 들어, FaaS 또는 EaaS 설정에서 서비스의 증명 또는 관리를 제공하는) 조 정된 서비스 운영 및 서비스 기능의 결과로서 관찰되거나 구현될 수 있다. 또한, 예 Q1-Q4의 방법은 에지 컴퓨 팅 시스템에서 (예를 들어, 명령어가 실행될 때 방법을 수행하는 머신 판독 가능 매체와 함께) 구현된 명령어 또는 (예를 들어, 방법을 수행하거나 달성하기 위한 구성을 포함하는 장치와 함께) 구현된 하드웨어 구성으로서 제공될 수 있다. 따라서, 예 Q1-Q4의 특징(및 증명 및 실행 관리의 다른 특징)은 시스템 오케스트레이터 또는 설계자에 의해 조정되거나 설계된 대로, 본 명세서의 임의의 다른 예와 결합되어 에지 클러스터 또는 에지 클라 우드 시스템을 구성할 수 있다. 증명 에지 네임 서비스(Attestation Edge Name Service)의 예 에지 클라우드 인프라스트럭처는 전 세계에 걸쳐 증명 데이터를 확장하는 데 사용될 수 있다. 증명을 위한 이 전의 접근 방식은 소프트웨어 솔루션 및 다양한 소프트웨어 스택에 의해 노출되는 메커니즘의 발견에 기초하였 다. 이러한 이전의 접근 방식의 하나의 제한은 낮은 지연시간 검색 및 자원 선택 메커니즘이 필요할 때 일부 가속 체계 또는 인프라스트럭처 가속 체계가 필요하다는 것이다. 에지 컴퓨팅 시스템(예를 들어, 에지 클라우 드 및 도 3 내지 도 22d에 도시된 에지 컴퓨팅 시스템 구성)에 적용 가능한 다음의 기술은 자원을 발견하 거나 SLA를 제공하도록 네임 기반 액세스를 제공한다. 이러한 자원 또는 SLA는 각각의 계층적 도메인에 등록되 어 아키텍처 레벨에서 변화가 발생할 때 콜백을 수신할 수 있다. 예에서, 각각의 계층 및 자원 속성은 블록 체 인을 사용하는 에지 그룹에 의해 인증될 수 있다. 에지 증명(edge attestation)은 에지 아키텍처 내에서 서비스 배치를 발견하고 신뢰하는 최상의 방법을 결정하 는데 사용된다. 에지 증명 네임 서비스(Edge Attestation Name Service)(EANS) 기술이 수천 개의 서비스 제공 자 및 종속 자원이 위치할 수 있는 위치의 글로벌 뷰를 (이를테면, ICN의 경우 지형적으로, 지리적으로 또는 사 전 편집적으로) 구축하는 데 사용될 수 있다. 위치 정보는 예상되는 액세스 지연시간을 예측하는 데 사용될 수 있다. 다양한 예에서, 각각의 서비스는 에지의 상이한 엔티티가 어떻게 각각의 서비스에 대해 신뢰 값을 검증 하거나 제공하는지에 따라 상이한 레벨의 증명 또는 신뢰와 연관될 수 있다. 또한, 이러한 서비스는 서비스에 대한 증명 레벨을 제공하기 위해 전 세계적으로 신뢰받는 엔티티와 연관될 수 있다. 다음의 기술은 도메인 네임 서비스(Domain Name Service)(DNS)와 유사하지만 에지 아키텍처에 적용되도록 구성 된 등록 서비스를 제공한다. 예를 들어, 한 세트의 분산 원장(distributed ledger)은 각각의 분산 에지에 모니 터링 및 증명 소프트웨어 요소를 배치할 책임이 있다. 이러한 모니터링 요소는 이를 테면 특정 서비스가 실행 될 때 서비스를 추적하는 데 사용될 수 있다. 도 52는 에지 증명 네임 서비스(EANS) 아키텍처를 제공하는 시스템을 도시한다. EANS 아키텍처는 도 5에서 예시적인 노드, 레벨(5232, 5234), 연결 및 집계 지점(5252, 5254, 5256)을 구비하는 것으로 도시되지만, EANS는 (노드(302, 312, 322) 중 임의의 노드, 및 도 3 내지 도 22d에 도시된 시스템 구성으 로부터 논의된 다른 시스템 구현을 비롯하여) 다른 아키텍처, 셋업 또는 컴포넌트와도 함께 사용할 수 있다. EANS 아키텍처는 노드, EANS 제공자, 디바이스 등을 설명할 수 있다. 예를 들어, 마스터 EANS 노드는 하 위 EANS 노드의 신뢰를 조사하기 위한 시작 지점일 수 있다. 이 계층은 EANS 시스템의 동적 또는 탄력적 배치를 지원하는 데 사용될 수 있다. EANS는 에지 액세스 네트워크 또는 에지 코어 네트워크를 통해 액세스 가능한 하드웨어 또는 소프트웨어 컴퓨팅 자원을 모니터링하고 증명할 한 세트의 분산 원장 서비스를 제공할 수 있다. EANS 제공자는 에지 네트워크 내 에서 실행되는 각각의 서비스를 추적할 책임이 있을 수 있다. 추적되는 정보는 컴퓨팅 자원의 개별 또는 특정 세트, 컴퓨팅 자원에 배치되거나 실행되는 펌웨어 또는 소프트웨어, 특정 SLA 세트 또는 그 위치를 갖는 워크로 드, 테넌트(예를 들어, 구독자) 아이덴티티(예를 들어, 인증에 사용되는 암호화 키) 또는 그 위치, 추적된 자원 에 귀속되는 본질적인 신뢰도 속성, 다른 정책 제한 등을 포함할 수 있다. EANS 모니터링 요소는 모니터링 되는 정보의 인증 또는 계층적 정보 시스템으로의 전파를 담당할 수 있다. 예 를 들어, 시스템은 에지 아키텍처의 북-남 계층 구조를 따라 계층적으로 구성된다. 예에서, 에지 시스템 아키 텍처에서 무언가를 실행하기를 원하는 디바이스 또는 에지 시스템(예를 들어, 플랫폼)은 특정 상황 하에 서 특정 서비스 제공자에 의해 제공될 수 있는 특정 서비스에 대한 특정 쿼리를 만들 수 있으며, 선택적으로 전 체 에지 시스템에 의해 입증된 실제 예상 성능과 서비스 품질을 검증할 수 있다. 특정 쿼리에는 EANS 어드레스 또는 네임이 포함될 수 있다. 예에서, EANS 아키텍처는 디렉토리 인프라스트럭처 유형 정보보다 더 많은 정보를 포함할 수 있다(예를 들어, 정보는 또한 증명 가능한 청구(claim)를 포함할 수 있다). 예를 들어, EANS 아키텍처는 원격 측정, 자원, IP 어드레스 등과 같은 데이터를 포함할 수 있다. 이 정보는 쿼리에 응답하여 전달될 수 있거나 또는 선택된 정보가 예를 들어 쿼리의 파라미터에 따라 전달될 수 있다. 예에서, 가상 도메인은 예를 들어, 계층 내에서 동적으로 생성될 수 있다. 다른 예에서, 가상 도메인은 도 52 에 도시된 계층과 상이한 토폴로지를 사용할 수 있다. 가상 도메인은 도메인에서 변경된 임의의 자원 데이터 (예를 들어, 새 자원, 상태 변경 등)를 증명하거나 검증할 책임이 있는 신뢰성 있는 한 세트의 엔티티를 포함할 수 있다. 새로운 데이터가 증명될 때, 데이터는 현재 도메인에 가입한 경우 피어로 콜백을 수행할 책임이 있는 마스터 EANS로 전파될 수 있다. 다른 예에서, 마스터 EANS는 메타 데이터의 로컬 저장소를 업데이트할 수 있다. 예에서, 저장소에 포함된 데이터 또는 속성은 증명된 데이터일 수 있다. 다른 예에서, 데이터는 정확한 것으로 알려져 있을 수 있고 그 유효성 및 관련성을 결정하기 위해 증명된 데이터와 비교될 수 있다. EANS 아키텍처 지원을 위한 추가 기술은 다음의 동작을 포함할 수 있다. 기술은 예를 들어, 마스터 에지 디바 이스에서, 디바이스로부터, 에지 아키텍처의 서비스에 관한 정보에 대한 쿼리를 수신하는 제 1 동작을 포함한다. 기술은 쿼리에 응답하여, 저장소 내 에지 증명 네임 서비스(EANS) 데이터에 (예를 들어, 마스터 에 지 디바이스에서) 액세스하는 제 2 동작을 포함한다. 기술은 예를 들어 마스터 에지 디바이스로부터 디바이스로, 쿼리에 대한 응답을 전송하는 제 3 동작을 포함하고, 응답은 서비스에 대한 증명 데이터 및 에지의 서비스를 제공하는 에지 디바이스의 어드레스 또는 네 임 중 적어도 하나를 포함한다. 응답은 서비스에 대해 모니터링된 정보의 인증 또는 전파를 포함할 수 있다. 응답은 서비스를 제공하는 에지 디바이스에 대한(예를 들어, 지연시간에 대한) 위치 정보를 포함할 수 있다. 위치 정보는 어드레스를 포함할 수 있거나 또는 추가 정보(예를 들어, 최단 경로 시간)를 포함할 수 있다. 예 에서, 증명 데이터는 마스터 에지 디바이스의 저장소에 저장된다. 예에서, 디바이스 및 마스터 에지 디바이스는 에지 아키텍처 내에서 레벨을 공유한다. 예에서, 서비스를 제공 하는 에지 디바이스는 에지 아키텍처 내의 마스터 에지 디바이스와 상이한 가상 도메인에 있다. 이 예에서, 동 작은 에지 아키텍처의 하위 레벨에서 제 2 마스터 에지 디바이스를 식별하는 것을 포함할 수 있다. 기술은 서 비스에 대한 증명 데이터 및 제 2 마스터 에지 디바이스로부터 어드레스 또는 네임 중 적어도 하나를 수신하는 단계를 더 포함할 수 있다. (예를 들어, 에지 클라우드 및 구현 시스템 및 디바이스에서) 에지 증명 네임 서비스를 구현하기 위한 제 1 예시적인 방법(예 R1)은 (예를 들어, 노드 또는 디바이스(2200, 2232, 2240 또는 2250)에서 또는 그에 의해 구현되는) 처리 회로를 사용하여 수행되는 방법으로서, 방법은, 마스터 에지 디바이스에서, 디바이스로부터, 에 지 아키텍처에서의 서비스에 관한 정보에 대한 쿼리를 수신하는 단계; 쿼리에 응답하여, 마스터 에지 디바이스 에서, 저장소 내 에지 증명 네임 서비스(EANS) 데이터에 액세스하는 단계; 및 디바이스에, 쿼리에 대한 응답을 전송하는 단계를 포함하고, 응답은 서비스에 대한 증명 데이터 및 서비스를 제공하는 에지 디바이스의 어드레스 또는 네임 중 적어도 하나를 포함한다.제 2 예(예 R2)에서, 예 R1의 주제는, 디바이스와 마스터 에지 디바이스가 에지 아키텍처 내에서 레벨을 공유하 는 구성을 포함한다. 제 3 예(예 R3)에서, 예 R1-R2의 주제는, 서비스를 제공하는 에지 디바이스가 에지 아키텍처 내의 마스터 에지 디바이스와 상이한 가상 도메인에 있는 구성을 포함한다. 제 4 예(예 R4)에서, 예 R3의 주제는, 에지 아키텍처의 하위 레벨에서 제 2 마스터 에지 디바이스를 식별함으로 써 EANS 데이터에 액세스하는 단계를 포함하고, 서비스에 대한 증명 데이터 및 제 2 마스터 에지 디바이스의 어 드레스 또는 네임 중 하나 이상을 수신하는 단계를 더 포함한다. 제 5 예(예 R5)에서, 예 R1-R4의 주제는, 응답이 서비스에 대해 모니터링된 정보의 인증 또는 전파를 포함하는 것을 포함한다. 제 6 예(예 R6)에서, 예 R1-R5의 주제는, 응답은 서비스를 제공하는 에지 디바이스에 대한 위치 정보를 포함하 는 것을 포함한다. 제 7 예(예 R7)에서, 예 R1-R6의 주제는, 증명 데이터가 마스터 에지 디바이스의 저장소에 저장되는 구성을 포 함한다. 다양한 설정에서, 예 R1-R7(및 증명 네임 서비스의 다른 양태)은 정의된 애플리케이션 프로그래밍 인터페이스 또는 인터페이스 사양; 통신 프로토콜, 메시지 포맷 또는 정의의 사용; 및 에지 컴퓨팅 환경 내에서 증명 및 신 뢰 메커니즘에 대한 정책 및 로직의 다른 사용 및 구현의 결과로서 관찰되거나 모니터링 될 수 있다. 예 R1-R7 및 이러한 증명 서비스 기술의 다른 양태는 또한 (예를 들면, FaaS 또는 EaaS 설정의 서비스 내에서 네임 지정 및 어드레스 지정을 지원하는) 서비스 운영 및 서비스 기능의 결과로서 관찰되거나 구현될 수 있다. 또한, 예 R1-R7의 방법은 에지 컴퓨팅 시스템에서 (예를 들어, 명령어가 실행될 때 방법을 수행하는 머신 판독 가능 매체 와 함께) 구현된 명령어 또는 (예를 들어, 방법을 수행하거나 달성하기 위한 구성을 포함하는 장치와 함께) 구 현된 하드웨어 구성으로서 제공될 수 있다. 따라서, 예 R1-R7의 특징(및 증명 서비스 및 증명 데이터 관리의 다른 특징)은 시스템 오케스트레이터 또는 설계자에 의해 조정되거나 설계된 대로, 본 명세서의 임의의 다른 예 와 결합되어 에지 클러스터 또는 에지 클라우드 시스템을 구성할 수 있다. 가속을 사용한 증명 인식 SLA(Attestation-aware SLAs using Acceleration) 분산 아키텍처(예를 들어, 에지 클라우드 및 도 3 내지 도 22d에 도시된 에지 컴퓨팅 시스템 구성)의 도전 과제 중 하나는 자원이 제한될 수 있는 다양한 하드웨어에 대한 증명 및 서비스 레벨 합의 작업과 같은 관리 작 업을 수행하는 방법이다. 예를 들어, 필드 프로그램 가능 게이트 어레이(FPGA)는 특정 처리 작업을 수행하도록 구성될 수 있으며 관리 작업을 효율적으로 수행하는 전통적인 처리 컴포넌트를 포함하고 있지 않을 수 있다. 그러나, FPGA는 관리 작업을 수행하기에 가장 좋은 위치에 있을 수 있다. 다음의 구성 및 기술은 증가된 효율 성으로 로컬에서 관리 작업을 수행하는 데 필요한 명령어 세트를 (예를 들어, 명령어 세트 아키텍처 (instruction set architecture)(ISA) 등을 통해) FPGA에 제공한다. 에지 설정에서(예를 들어, 에지 서비스 및 도 7 내지 도 12와 관련하여 도시되고 설명된 기능 내에서) SLA 및 증명 절차는 정적이 아닌 동적 기능 또는 보다 일반적으로는 충족되어야 하는 실제 제약 조건을 정의하도록 실 행되어야 하는 \"코드\"일 수 있다. 범용 프로세서(예를 들어, 중앙 처리 유닛(central processing unit)(CP U))의 경우, 이것은 코드를 실행한다는 것이 CPU가 그렇게 하도록 설계된 것이기 때문에 문제가 되지 않을 수 있다. 보통 정책 표현을 실행하는 것은 정책에 의해 관리되는 기능을 수행하는데 걸리는 전체 시간의 작은 부 분이다. 그러나 FPGA는 특정 처리 작업을 위해 구성될 수 있으며 SLA 및 증명 오버헤드는 FPGA에 부담을 주고 효율성을 감소시킬 수 있다. FPGA에 부담을 주는 SLA 및 증명 작업의 문제를 방지하기 위해, 마이크로 명령어 세트 아키텍처(ISA) 에뮬레이터가 CPU를 시뮬레이션하도록 구현되고, SLA 평가 및 증명 프로토콜을 나타내는 합 당한 커리 기능 세트를 수행하기 위한 에뮬레이터(예를 들어, 매우 제한적이지만 범용 명령어 실행 유닛)에서 임의의 SLA 또는 증명 프로세스를 수행할 수 있다. FPGA의 주요 처리 흐름에서 SLA 작업을 오프로드하기에는 작은 ISA이면 충분하다. 도 53은 (예를 들어, 비트 스트림으로 표시된) 커리 함수뿐 아니라, 비트스트림 및 증명 요구 사항을 설명하는 서비스 레벨 협약)(SLA)을 사용하여 실행하는 워크로드를 수용하는 필드 프로그램 가능 게이트 어레이(FPGA) 가 속기를 포함하는 에지 아키텍처를 위한 시스템을 도시한다. 다른 예에서, 다른 유형의 하드웨어 가속기가 이러한 기술과 함께 이용될 수 있다.예시적인 프로세스 시퀀스에서, 테넌트는 프로세스에서 오케스트레이터로부터 (예를 들어, 기지 국 또는 다른 에지 노드를 통해) 워크로드를 요청할 수 있다. 오케스트레이터는 프로세스에서 SLA, 커리 기능(들) 및 워크로드를 제공할 수 있다. FPGA는 프로세스에서 비트스트림/커리 함수 (curry function)를 설치할 수 있고 워크로드를 처리할 수 있다. FPGA는 프로세스에서 예를 들어, 워크로드에 서명하는 증명 커리 함수를 적용할 수 있다. 예에서, FPGA는 비트 스트림을 검 증할 수 있는 신뢰성 있는 서버로 가는 대역 외 연결을 갖고 있을 수 있다. 이것은 FPGA가 비트스트림 자체를 검증할 수 없는 상황에서 유용할 수 있다. 오케스트레이터는 프로세스에서 SLA 요구 사항에 따라 증명을 검증한다. 워크로드 결과는 프로세스에서 테넌트에게 반환된다. 추가 예에서, SLA를 검증하는 엔티티는 오케스트레이터 또는 다른 관리 엔티티일 수 있다. 이것은 다수의 오케스트레 이터가 동일한 에지 어플라이언스(Edge Appliance)에 속하고 (에지 기기가 다수의 테넌트에 대해 분할되는) 상 황에서 발생할 수 있다. 다른 예에서, 프로세스 시퀀스 및 동작의 시퀀스 또는 유형은 변경될 수 있다. FPGA는 수용 가능하거나 수용 불가능한 커리 함수; 워크로드 컨텍스트; 또는 테넌트 컨텍스트를 설명하는 LSM을 획득함으로써 LSM 시행 지점이 될 수 있다. 마찬가지로, 오케스트레이터는 LSM을 LSM 시행 지점에 동적으로 프로비저닝 할 수 있다. 예에서, 증명 기능은 FPGA에 내장되거나 또는 동적으로 비트스트림으로서 로드될 수 있다. 증명 기능이 동적으로 로드되면, 계층화 아키텍처(예를 들면, 디바이스 식별자 구성 엔진(Device Identifier Composition Engine)(DICE) 등)이 적용되어 FPGA에 내장된 계층으로서 기존에 존재하는 신뢰를 동적으로 확장할 수 있 다. 내장된 계층이 계층 1이면, 동적 증명 비트스트림이 계층 2에 연결될 수 있다. 계층 2 증명 키가 생성될 수 있다. 커리 함수/비트스트림은 계층 3으로서 동적으로 추가될 수 있다. 계층 2 증명 컴포넌트는 계층 2 디 바이스 id(예를 들어, 복합 디바이스 식별자(composite device identifier)(CDI) 등) 컴퓨테이션의 일부로서 계층 3 비트스트림을 해시할 수 있다. 계층 2는 증명 키를 연산하고 계층 2로 전달되는 계층 3 결과에 서명할 수 있다. 또는 계층 3은 증명 키를 연산하고 결과에 직접 서명할 수 있다. 어떤 이유로 FPGA가 증명을 수행하기에 충분한 정보를 가지고 있지 않을 가능성이 있다. 그러한 경우, 아키텍처는 증명을 수행하고 그 결과를 커리 함수(예를 들어, 위임된 커리 함수 등)에 제공할 수 있는 신뢰성 있는 서버와의 대역 외 보안 연결을 가짐으로써 확장될 수 있다. 따라서, 증명 키는 증명 비트스트림 제공자에 게만 알려진 보호 기술을 사용하여 보호될 수 있다. 계층 3 비트스트림 제공자는 추가 라이선스 비용이 연루될 수 있기 때문에 증명 기능을 통합하기를 바라지 않을 수 있다. SLA는 (예를 들어, 이러한 파라미터 내에서 이 비트스트림을 실행하고 결과를 출력하는 등) FPGA에 처리 명령어를 제공하는 애플릿(applet) 또는 커리 함수처럼 기능할 수 있다. 증명 인식 SLA는 증명 매니페스트 (attestation manifest)를 확인할 수 있다. SLA는 비트스트림 이미지를 설치할 수 있으며 이미지로의 액세스가 필요할 수 있다. SLA는 증명 및 워크로드 처리를 위해 커리 함수를 수용하는 방법을 내장한 계층 1 시스템에 설명하는데 사용될 수 있다. 증명된 비트 스트림 또는 바이너리가 고유한 인스턴스를 참조하고 항상 참조될 수 있도록 하는 것을 보장하기 위해, 각각의 비트스트림은 UUID를 포함하거나 이와 연관될 수 있다. SLA가 커리 함수를 수용하기 위해 사용되는 방식은 그 자체로 증명 가능한 주장에 기여할 수 있다. 예를 들어, 계층 1 CDI는 계층 2에 공급되는 SLA의 해시를 포함할 수 있다. 따라서, FPGA는 범용 처리 기능성의 필 요 없이도 증명 및 SLA 관련 작업을 수행하는 기능성을 갖추고 있을 수 있다. 추가 예에서, 증명 데이터는 증명이 수행될 때를 증명하는 데 사용될 수 있는 타임스탬프를 포함한다. 이것은 증명이 위조되거나 과거로부터 재사용되지 않았음을 보장하기 위해, 난수에 연결된 타임스탬프의 사용을 포함할 수 있다. 에지 컴퓨팅 환경(예를 들어, 에지 클라우드 및 구현 시스템 및 디바이스)에서 증명 인식 SLA를 구현하기 위한 제 1 예(예 S1)는 (예를 들어, 노드 또는 디바이스(2200, 2232, 2240 또는 2250)에서 또는 그에 의해 구현 되는) 처리 회로를 사용하여 수행되는 방법으로서, 방법은, 에지 네트워크의 오케스트레이터 노드로부터 서비스 레벨 협약)(SLA), 비트스트림 및 워크로드를 수신하는 단계; 비트스트림을 워크로드에 적용하여 출력을 생성하 는 단계; 워크로드에 증명 기능을 적용하는 단계; 워크로드에 증명 기능울 적용하는 것에 기초하여 오케스트레 이터로 검증 요청을 전송하는 단계; 및 오케스트레이터로부터 긍정적인 검증 응답의 수신에 기초하여 출력을 테 넌트 노드로 송신하는 단계를 포함한다. 제 2 예(예 S2)에서, 예 S1의 주제는, 증명 기능을 사용하여 워크로드에 서명하는 단계를 포함한다. 제 3 예(예 S3)에서, 예 S1-S2의 주제는, 비트스트림이 커리 함수인 것을 포함한다. 제 4 예(예 S4)에서, 예 S1-S3의 주제는, 증명 기능이 필드 프로그램 가능 게이트 어레이에 내장되는 것을 포함 한다. 제 5 예(예 S5)에서, 예 S1-S4의 주제는, 증명 기능이 동적으로 비트스트림으로서 로드되고 필드 프로그램 가능 게이트 어레이의 계층 구조를 사용하는 것을 포함한다. 다양한 설정에서, 예 S1-S5(및 증명 인식 SLA의 다른 양태)는 정의된 애플리케이션 프로그래밍 인터페이스 또는 인터페이스 사양; 통신 프로토콜, 메시지 포맷 또는 정의의 사용; 및 에지 컴퓨팅 환경 내에서 증명 기능에 대 한 정책 및 로직의 다른 사용 및 구현의 결과로서 관찰되거나 모니터링 될 수 있다. 예 S1-S5 및 SLA 증명의 다른 양태는 또한 (예를 들어, FaaS 또는 EaaS 설정에서 SLA를 구현하거나 사용하는 서비스를 위한) SLA를 사용 하는 서비스 동작 및 서비스 기능의 결과로서 관찰되거나 구현될 수 있다. 또한, 예 S1-S5의 방법은 에지 컴퓨 팅 시스템에서 (예를 들어, 명령어가 실행될 때 방법을 수행하는 머신 판독 가능 매체와 함께) 구현된 명령어 또는 (예를 들어, 방법을 수행하거나 달성하기 위한 구성을 포함하는 장치와 함께) 구현된 하드웨어 구성으로서 제공될 수 있다. 따라서, 예 S1-S5의 특징(및 증명 서비스 계약의 다른 특징)은, 이전의 암시적 증명 또는 증 명 에지 네임 서비스 특징과 별도로 또는 이와 결합하여, 시스템 오케스트레이터 또는 설계자에 의해 조정되거 나 설계된 대로, 본 명세서의 임의의 다른 예와 결합되어 에지 클러스터 또는 에지 클라우드 시스템을 구성할 수 있다. 네트워크 보안을 위한 효율적인 딥 러닝 분석(Efficient Deep Learning Analysis for Network Security)의 예 에지 컴퓨팅 시스템(예를 들어, 에지 클라우드 및 도 3 내지 도 22d에 도시된 에지 컴퓨팅 시스템 구성)이 트래픽을 소비하고 전달하도록 배치됨에 따라, 모든 트래픽을 분석을 위해 (딥 러닝(deep learning)(DL) 추론 서버와 같은) 중앙집중화된 AI 컴퓨트 위치에 전송하는 것이 빠르게 불가능해 진다. 그러나 네트워크 동작을 지원하는 컴퓨트를 제공하는 에지 컴퓨팅 시스템 내에서, 이를테면 컨텍스트 기반 에지 네트워크 보안 분석의 사용과 함께, 진행중인 네트워크 동작에 대한 보안 분석을 수행할 필요성이 크다. 지능형 지속적 위협, 맬웨어 (malware), DDoS 및 유사 공격을 검출하는데 도움이 되는 이러한 네트워크 설정에서 새로운 DL 및 AI 메커니즘 이 이용 가능할 것으로 예상된다. 이러한 메커니즘은 네트워크 사업자를 위한 기본적인 운영 보안 메커니즘이 될 것으로 예상되지만, 지금까지는 중앙집중화된 서버 처리 설정으로 제한되었다. 예에서, 네트워크 보안 분석 및 모니터링은 (예를 들어, 부분적 오프로드 모델의) 데이터 평면 개발 키트(data plane development kit)(DPDK)로부터 또는 NIC에서, 또는 이들의 조합에서 패킷 처리 파이프라인의 일부로서 에 지 컴퓨팅 시스템 내에서 배치 가능하다. 예를 들어, 패킷 처리 파이프라인은 패킷 처리 파이프라인으로부터 직접 수집된 네트워크 트래픽 및 원격 측정을 처리하도록 동적으로 한 세트의 DL 네트워크 모델로 프로비저닝될 수 있다. 이러한 원격 측정은 네트워크 카드 또는 다른 네트워크 장비에 의해 수행되는 HW 패킷 처리에 대해 참조될 수 있다. 기존의 접근 방식은 IPFIX를 사용하여 분석 시스템에 흐름 원격 측정 메타데이터를 제공하는데 의존하는 경우가 많고, 이어서 네트워크 관리 시스템은 (NETconf 또는 유사한 툴을 사용하여) 일부 재구성을 초래할 더 높은 레 벨의 결정을 내린다. 패킷 처리 파이프라인을 통한 네트워크 보안 분석 및 모니터링을 사용하면 에지 플랫폼 패킷 파이프라인 내에서 처리 '탭'(예를 들어, 관찰 지점)을 유지하지만, AI 모델 구축, 훈련 및 추론을 로컬 smartNIC/로컬 플랫폼의 캐퍼빌리티 쪽으로 이동시킨다. 이러한 개선된 접근 방식은 데이터를 중앙집중화된 소 스로 다시 전달하지 않고 다수의 AL/ML 모델을 로컬 플랫폼에서 동시에 실행할 수 있게 한다. 네트워크 보안 분석 및 모니터링 모델은 (예를 들어, 무감독 학습(unsupervised learning)을 사용하여) 선택된 트래픽에 대해 패턴/이상을 검출하고 강화 방법(예를 들어, MDP, Q-Learning) 또는 미리 구성된 보상 기능을 사 용하여 흐름 패턴에 대한 플랫폼 자원을 자동으로 조정하는 데 사용될 수 있다. 분석 시스템/관리 시스템 및 netconf(또는 유사한 툴)에 의해 정상적으로 수행되는 수정 조치는 각각의 학습 모델 계층(L3-L7), VNF 유형, 인터페이스 유형 등에 기초하여, 무슨 행위가 플랫폼에서 취해질 수 있는 지를 선택하는 미리 구성된 정책에 기 초한 AI/ML 모델에 의해 동적으로 수행될 수 있다. 예를 들어, 적용 가능한 정책은 정책 기반 라우팅(policy- based routing)(PBR) 정의와 유사한 방식으로, ML 로컬 분석을 위한 새로운 세트의 정책 기반 규칙으로서 표현 될 수 있다. 이러한 모니터링 및 훈련 접근 방식의 사용을 통해, 에지 컴퓨팅 시스템 내에서 학습된 지식이 피어 전체에 동 적으로 전파될 수 있다. 이러한 접근 방식은 테넌트별로 훈련된 모델의 사용을 비롯하여, 다중 테넌시 모델에서 상당한 이점을 가질 수 있다. 이러한 접근 방식은 (훈련할 수 없는 DL 컴포넌트를 처리하기 위해) 이상 검 출을 위한 IDS/IPS와 같은 다른 보안 특징, 및 (예를 들면, 가용 NIC 알고리즘에 기초하여) 무슨 트래픽이 분석 할 수 있거나 분석될 수 없는지를 결정하는 고급 규칙과 통합될 수 있다. 모델을 훈련시키기 위해 (적대적 훈련 또는 계층적 학습을 비롯한) 다양한 형태의 훈련이 계획되거나 조정될 수 있다. 추가 예에서, 네트워크 보안 분석을 위해 지역화된 작업 특정 원격 측정 수집 아키텍처가 이용될 수 있 다. 이러한 아키텍처에서, 각각의 작업은 개별적으로 훈련될 수 있으며, 훈련된 템플릿은 SW 업데이트를 프로 비저닝하는 것과 유사한 방식으로 동일한 작업의 다수의 인스턴스에 활용될 수 있다. 이러한 훈련의 양태는 시 스템이 분할될 수 있다는 점을 고려하여, 테넌트에 의해 관련되거나 분리될 수 있다. 이러한 고려 사항은 상이 한 학습 체계가 상이한 테넌트 또는 파티션 소유자에게 적용될 수 있도록 할 수 있다. 또 다른 예에서, 작업 시퀀스는 개별적으로 훈련될 수 있고 컴퓨트 패브릭의 상이한 계층에서 적용될 수 있다. 그러나, 시스템이 그라운드 트루스(ground truth)를 이해하거나 개별 작업으로부터 유용한 훈련 데이터를 획득 할 수 있을 만큼 안정적이지 않은 경우에, 일부 특정 작업의 조합이 활용될 수 있다. 따라서, 다양한 예에서, 다양한 방법 및 디바이스는 네트워크 보안 분석 및 모니터링을 위해 AI(ML/DL) 모델을 활용하여, 에지 컴퓨팅 시스템의 각각의 노드의 네트워크 장비 내의 패킷 처리 파이프라인의 데이터에 이러한 모델을 배치할 수 있다. 다양한 설정에서, 이전의 딥 러닝 및 분석 예는 정의된 애플리케이션 프로그래밍 인터페이스 또는 인터페이스 사양; 통신 프로토콜, 메시지 포맷 또는 정의의 사용; 및 에지 컴퓨팅 환경 내에서 네트워크 보안을 위한 정책 및 로직의 다른 사용 및 구현으로서 관찰되거나 모니터링될 수 있다. V. 다중 이해 관계자 에지 컴퓨팅 시스템을 위한 오케스트레이션/서비스 레벨 관리 추가 예에서, 오케스트레이션 및 서비스 레벨 관리는 다양한 다중 이해 관계자 에지 컴퓨팅 설정으로 확장될 수 있다. 동적 기준에 기초한 다중 테넌트 전력 관리의 예 본 명세서에서 채택된 임의의 수의 에지 클라우드 아키텍처(예를 들어, 에지 클라우드 및 도 3 내지 도 22d에 도시된 에지 컴퓨팅 시스템 구성)는 엔드포인트 디바이스(예를 들어, 스마트 폰 또는 IoT 디바이스)에서 실행되는 애플리케이션에 의한 액세스를 위해 TSP 또는 CSP에 의한 FaaS를 실시 가능하도록 구성될 수 있다. 이러한 FaaS는 에지 애플리케이션 워크로드를 가속화하는 데 사용될 수 있다. 다양한 예에서, 가속 FaaS(Acceleration FaaS)(AFaaS) - 하드웨어 가속기에서 기능이 구현되고 실행되는 FaaS 구현 - 는 에지 FaaS 캐퍼빌리티를 더 개선하는 데 사용될 수 있다. 낮은 지연시간 FaaS 및 AFaaS를 실시 가능하게 하기 위해, 가속기 및 컴퓨트(예를 들어, 프로세서)는 기지국 또 는 게이트웨이 계층(예를 들어, 1-5 ms 지연시간을 달성하기 위해, 계층의 모바일 에지 컴퓨팅(Mobile Edge Computing)(MEC) 노드에 위치되거나, 또는 (예를 들어, 6-7 ms 지연시간을 달성하기 위해 코어 네트워크 계층에서) 중앙국 내에 위치될 수 있다. 에지 노드로부터 FaaS 및 AFaaS를 실행하면 지연시간 이점을 갖 지만, 이러한 목적으로 에지 노드 하드웨어를 할당하는 것은 어려울 수 있다. 이러한 어려움은 다음 중 하나 이상: 물리적 공간 제한 사항; 테넌트 요청(예를 들어, 기능)을 처리할 낮은 지연시간 및 확장 가능한 스케줄링 솔루션의 부족; 매우 효과적인 컴퓨트 밀도 및 가속(예를 들어, 시스템 소프트웨어 스택에 의한 것이 아닌 FaaS 또는 AFaaS를 위해 사용되는 컴퓨트 및 가속화)의 누락; 또는 상이한 세분화 레벨에서 자동 전력 관리 및 과금 정책의 부재로부터 발생할 수 있다. 이러한 문제 중, 전력 관리는 에지 클라우드 아키텍처의 설계 및 과금에서 중요한 양상이다. 기지국과 중앙국이 일반적으로 운영하는 전력 제한 사항을 감안할 때, 공급자(예를 들어, 사 업자)는 에지 아키텍처를 배치하고 운영하는 비용을 개선하기 위해 동적 및 지능적 테넌트 별 전력 관리를 필요 로 한다. FaaS 및 AFaaS에 대한 다중 테넌트 전력 관리, 인스턴스별 또는 테넌트별 하드웨어 지원을 해결하기 위해, 전력 관리가 에지 노드에 추가된다. 전력 관리 정책에 대한 이러한 하드웨어 지원은 지연시간을 증가시키거나 또는 공간 제약된 에지 노드 등(예를 들어, 기지국)으로부터 컴퓨트 사이클을 빼앗을 수 있는 소프트웨어 기반 전력 관리를 방지한다. 대신에, 하드웨어 기반 정책 관리는 가속화된 기능 또는 기능 요청이 하드웨어 플랫폼에 의 해 직접 핸들링되도록 기존 플랫폼 또는 랙 설계를 확대한다. 소프트웨어가 요구되지 않기 때문에, 이러한 솔 루션에는 배치시 많은 디바이스 카운트에 중요할 수 있는 더 적은 유지 관리(예를 들어, 소프트웨어 구성 또는 업데이트); 더 나은 총 소유 비용으로 이어질 수 있는 보다 효과적인 컴퓨트 밀도; 자동 전력 스케일링; 다중테넌트 아키텍처에 기초한 측정 및 과금; 또는 가속화된 전력 및 과금 응답 시간이 수반된다. 에지 아키텍처에서 테넌트 전력 관리를 구현하기 위해, 한 세트의 익스텐션(extension) 및 프로토콜이 사용될 수 있다. 이러한 익스텐션 또는 프로토콜은 기지국/액세스 포인트와 함께 동작하여 테넌트에 의해 구성된 테넌 트에 대한 인터페이스를 노출하는 - 기지국, 중앙국, 데이터 센터 또는 다른 유형의 에지 어플라이언스 또는 노 드에 배치될 수 있는 - 게이트웨이에 추가될 수 있다. 구성은 (예를 들어, 와트의 측면에서 또는 금전의 측면 에서) 전력 예산을 설정하는 것을 포함할 수 있다. 구성은 (예를 들어, X 와트보다 적지 않은) 특정 전력 상태, 전력 상태 범위, 최소 전력 대비 성능 등과 같은 시간 경과에 따른 전력 정책을 설정하는 것을 포함할 수 있다. 예에서, 전력은 시간이 지남에 따라 비용이 달라질 수 있다. 예에서, 게이트웨이는 테넌트 요청에 대한 자동 로드 밸런서를 포함한다. 로드 밸런서는 FaaS 또는 AFaaS를 실 행하는 전력 예산 책정에 대한 테넌트 구성에 민감하다. 따라서, 전력 예산 구성이 저 전력 예산으로 저 성능 요구 사항을 명시하면, 로드 밸런서는 고 전력 컴퓨트 요소보다 저 전력 컴퓨트 요소를 선호할 수 있다. 예에 서, 게이트웨이는 서비스/AFaaS/FaaS, 과금 또는 다른 구성 가능한 요소를 관리하는 오케스트레이터 컴포넌트 (예를 들어, 클러스터 헤드 노드)와의 인터페이스를 또한 포함한다. 게이트웨이 외에도, 랙 및 플랫폼 전력 관리가 사용될 수 있다. 여기서, 랙 또는 플랫폼은 테넌트 당 할당되는 전력을 구성하도록 인터페이스를 노출한다. 성능 글라스 죠(performance glass jaw)(예를 들어, 예기치 않은 장애 또는 성능 저하)를 방지하기 위해, 플랫폼은 서비스, FaaS 또는 AFaaS 별로 자동 서비스 저하 예측 또는 모니터링을 제공한다. 예에서, 저하 또는 저하의 예측은 오케스트레이션 계층에 전달된다. 도 54는 (예를 들어, 도 7 내지 도 12와 관련하여 도시되고 설명된 것과 같은 에지 서비스 및 기능을 구현하는) 동적 SLA 및 과금 기준 기반 다중 테넌트 에지 클라우드 전력 관리를 위한 시스템을 도시한다. 도시된 바와 같 이, 게이트웨이는 인터페이스를 통해 테넌트로의 (예를 들어, 인증 및 과금) 액세스를 제공한다. 인터페 이스는 테넌트가 소프트웨어 스택을 통하지 않고 기지국에 의해 노출된 한 세트의 AFaaS 또는 FaaS를 발 견하거나 직접 액세스할 수 있도록 구성된다. 게이트웨이는 어떤 하드웨어 플랫폼이 FaaS, AFaaS 또는 테넌트에 의해 요청된 다른 서비스를 해줄 수 있는지를(예를 들어, 자원을 가지고 있는지를) 결정하는 회로를 포함한다. 예에서, 게이트웨이는 테넌트로부터 나오는 상이한 요청 중에서 - 예를 들어, 상이한 컴퓨트 및 가속 요 소로부터 나오는 원격 측정을 사용하여 - 로드 밸런싱을 수행하도록 구성된다. 예에서, 로드 밸런싱은 테넌트 에 의해 구성된 실행 전력 요구 사항에 기초한다. 예에서, 로드 밸런싱은 테넌트와 연관된 전력 예산에 기초한 다. 예에서, 로드 밸런싱은 에지 노드(예를 들어, 기지국)의 상이한 자원에서 이용 가능한 전력 또는 성 능에 기초한다. 예에서, 로드 밸런싱은 서비스와 연관된 전력 요구 사항에 기초한다. 예에서, 예상 이상의 성 능 저하가 검출되거나 예측되면, 시스템 소프트웨어 스택은 예를 들어 인터럽트를 통해 통지될 수 있다. 예에서, 테넌트 요청은 실행될 서비스(예를 들어, 기능)의 페이로드 및 식별을 포함한다. 예에서, 요청은 또한 SLA도 포함한다. 예에서, 게이트웨이는 몇몇 가용 가속기 또는 컴퓨트 요소(예를 들어, 프로세서) 중 하 나를 선택하여 (예를 들어, 도 19 내지 도 21c를 참조하여 논의된 가용 에지 컴퓨팅 하드웨어 배열에 기초하여) 테넌트 요청을 실행하도록 구성된다. 도 54에 도시된 바와 같이, 게이트웨이는 기지국에 포함된다. 게이트웨이는 테넌트(예를 들 어, 사용자 워크로드)를 인증하고 다수의 랙 실행 인스턴스(5401A, 5401B, 5401C)(예를 들어, 도 22d에 도시된 서버 랙의 인스턴스) 사이에서의 사용을 (예를 들어, 과금 목적으로) 추적하도록 구성된 회로를 포함한다. 게 이트웨이 추적 컴포넌트는 요청을 인증하고 인증된 요청을 (예를 들어, 대역 외 패브릭을 통해) 중앙국에 송신 하도록 구성된다. 이러한 송신은 주어진 서비스, 예를 들어, 테넌트 명시된 SLA 레벨에 기초하여 테넌트에 요 금을 부과하기 위해 중앙국에 의해 사용될 수 있는 정보를 포함한다. 추적 컴포넌트는 자원 사용을 모니터링하 고, 이러한 사용을, 시간, 전력, 돈 등의 측면에서 정의되든 말든, 테넌트에 구성된 예산에 맞춘다. 따라서, 예를 들어, 테넌트 인스턴스에 의해 전력이 소비될 때, 추적 컴포넌트는 그에 따라 특정 시점에서의 전력의 비 용으로 예산을 줄인다. 예에서, 게이트웨이는 (스위칭의 다른 특징, 클라이언트 인터페이스의 제공 및 다른 묘사된 기능 사이의) 자원 관리 회로를 포함한다. 자원 관리 회로는 (예를 들어, 인스턴스(5401A, 5401B, 5401C) 내의) 다른 노드, 랙, 블레이드, 프로세서 또는 하드웨어 가속기와 같은 - 어떤 플랫폼이 FaaS 또는 AFaaS 세트를 제공하는지를 추적하도록 구성된다. 자원 관리 회로는 이러한 플랫폼에 현재 이용 가능한 전력량 또는 플랫폼 내의 자원이얼마나 많은지를 추적하도록 구성된다. 예에서, 자원 관리 회로는 (예를 들어, 스케줄러에 의해 사용하기 위한) 성능 메트릭 또는 다른 메타데이터를 검출하고 유지하도록 구성된다. 도시된 바와 같이, 게이트웨이는 오케스트레이터와 같은 시스템 소프트웨어 스택과의 인터페이스를 노출 하도록 구성된 관리 인터페이스를 포함한다. 이러한 인터페이스는 소프트웨어 스택이 게이트웨이 동작 또는 게이트웨이를 통한 플랫폼 동작을 구성 또는 관리할 수 있게 한다. 다른 곳에서 언급한 바와 같이, 구성은 특정 시점에서의 전력 비용, 고객 또는 테넌트 제한 사항 당 전력 데이터, 정책 등을 설정하는 것을 포 함할 수 있다. 예에서, 인터페이스는 소프트웨어 스택이 플랫폼 서비스의 원격 측정 또는 사용을 가능하게 한 다. 게이트웨이는 원격 측정 회로를 포함한다. 원격 측정 회로는 서비스의 실행을 추적하도록 구성된다. 예 에서, 이러한 추적은 레벨 컴퓨트 또는 가속기 활용을 추적하는 것을 포함한다. 원격 측정 회로는 이 정보를 시스템 소프트웨어 스택에 노출하는 인터페이스를 포함할 수 있다. 예에서, 원격 측정 회로는 원격 측정 모델 을 구현하도록 구성된다. 이 모델은 원격 측정 데이터를 입력으로서 받아들이고 예를 들어 게이트웨이에 의해 수신되는 요청의 수로 인한 서비스 저하를 검출 또는 예측한다. 예에서, 원격 측정 회로는 현재 가용 전 력 또는 전력 특성에 기초하여 요청을 거절할 것을 테넌트 인터페이스에 통지하도록 구성된다. 예에서, 이러한 거절은 또한 서비스 또는 기능 유형에도 기초할 수 있다. 또한, 다른 형태의 데이터(예를 들어, 로드 데이터 등)가 다른 기지국에 의해 제공될 수 있고 모델에 의해 추가 저하를 예측하는 데 사용될 수 있다. 게이트웨이는 (도시되지 않았지만, 도 21a 내지 도 22d를 참조하여 논의된 메모리 컴포넌트에 따라 구현 가능한) 메모리를 포함한다. 메모리는 페이로드, 상태, 메타데이터 등을 포함한 요청을 저장하도록 구성된다. 예에서, 메모리는 \"설명 페치하기(fetch)\" 및 \"페이로드 페치하기\"의 호출을 포함하는 인터페이스를 통해 가속 기 또는 컴퓨트 요소에 의해 액세스된다. 게이트웨이는 로드 밸런서를 구현하는 스위치를 포함한다. 스위치는 인증된 요청을 수락하고 인증된 요 청을 가속기 또는 컴퓨트 컴포넌트에 발송(dispatch)하도록 구성된다. 발송을 선택하기 위해, 스위치는 원격 측정 회로에 의해 제공되는 정보를 사용하도록 구성된다. 예에서, 스위치는 또한 발송 결정에 다음 중 하나 이 상: 다른 것 중에서도, 현재 요청과 연관된 전력 요구 사항, 연관된 테넌트에 이용 가능한 예산, 전력의 현재 비용, 서비스를 실행하는 데 적합한 가용 플랫폼 자원, 실행을 위한 전력 요구 사항을 제공하기 위해 노출된 가 용 전력 및 캐퍼빌리티(예를 들어, 전력 위상, 전력 최대-최소, 등)을 고려할 수도 있다. 예에서, 게이트웨이 및 기지국 내의 상이한 프로세서 또는 가속기는 안전한 고속 링크 또는 상호연 결을 통해 연결된다. 예에서, 프로세서 또는 가속기를 호스팅하는 플랫폼은 게이트웨이에 의해 전송된 요청을 수락하도록 구성된 요청 회로를 포함한다. 요청 회로는 테넌트에 의해 제공되는 전력 요구 사항을 제어 하고 서비스 실행 결과를 제공하도록 구성된다. 이러한 컴포넌트에 대한 예시적인 데이터 흐름은 다음을 포함할 수 있다. 요청이 게이트웨이에 도착한다. 이 예에서 요청은 페이로드, function_ID, tenant_ID, 서비스 파라미터, SLA 또는 서비스 품질 (QoS) 요구 사항(예를 들어, 지연시간 기한), 인증 및 전력 요구 사항을 포함한다. 예에서, 전력 요구 사항은 전력 사용에 기초한 실행의 최대-최소 전력, 전력 위상, 최대-최소 비용 중 하나 이상을 포함한다. 일단 수신되면, 인증 회로는 요청을 인증한다. 인증이 통과되면, 요청은 게이트웨이 메모리에 저장된다. 또한, 게이트웨이에 의해 수락된 모든 요청을 추적하는 테이블에 새로운 엔트리가 생성된다. 또한 테이 블은 요청에 대응하는 상태를 추적하도록 구성된다. 상태는 요청이 메모리에 저장되는 위치, 상태, 또는 어떤 플랫폼이 기능을 실행하고 있는지와 같은 것을 포함할 수 있다. 인증이 통과되면, 인증된 요청은 로드 밸런싱을 위해 스위치에 송신된다. 여기서, 스위치는 어떤 기지국(541 0)의 플랫폼이 요청된 기능의 인스턴스를 노출하는지를 식별하고, 다음과 같은 기준 중 하나에 기초하여 인스턴 스 중 하나를 선택한다: AFaaS가 호출되면, 이용 가능한 가속된 기능 중 적어도 하나를 갖는 가속기 중 하나를 선택한다 - 이것은 다수의 가속기가 자신으로의 액세스를 노출하고 있으면, 라운드 로빈 선택을 구현할 수 있다 -; FaaS가 호출되면, 부하가 적은 이러한 기능으로의 액세스를 제공하는 프로세서 중 하나를 선택한다. 어느 경우든, 스케줄러는 전력 기준을 사용하여 어떤 자원을 선택하는지를 결정한다. 다수의 가속기가 AFaaS를 제공 하거나 다수의 프로세서가 FaaS를 제공하면, 스위치는 제공된 SLA/QoS를 충족하는 가속기를 선택한다. 그 다음에 스위치는 요청을 선택된 플랫폼으로 송신한다. 스위치는 요청 ID와 기능의 설명을 포함하고 있는 게 이트웨이 메모리를 가리키는 포인터를 송신한다. 예에서, 플랫폼은 서비스 실행을 수행하기 위해 메모리로부터의 기능 정의에 액세스한다. 기능이 완료되면, 결과가 저장되는 메모리 위치를 가리키는 포인터를 사용 하여 게이트웨이를 콜백한다. 게이트웨이는 응답을 테넌트에게 다시 전송하고 과금 또는 다른 추적을 수행하기 위해 대응하는 실행과 함께 중앙국 시스템에 연락한다. 그 다음에 게이트웨이는 대응하는 요청과 연관된 할당된 엔트리를 해제 한다. SLA에는 테넌트가 시간 윈도우 및 전력 비용에 기초하여 여러 선택 사항을 제공하는 협상이 수반될 수 있다. 추가 예에서, SLA 오케스트레이터는 몇몇 인자(예를 들어, 워크로드를 스케줄링하는 시간, 실행 시간, 결과 보 고 시간, 하루 단위의 호스트 당 와트 당 전력 비용, CPU 효율성 엔벨로프 - 특히 사이클 당 전력 비용이 GHz 변화에 따라 선형적이지 않을 수 있기 때문)에 기초하여 옵션을 컴퓨트할 수 있다. 테넌트에게는 워크로드 스 케줄링의 다양한 조정 가능한 파라미터에 기초한 다수의 \"견적(quote)\" 또는 옵션이 제공된다. 그 다음에 테넌 트(또는 테넌트와 연관된 사람)는 견적을 선택하고 SLA에 약정하는 반면, SLA는 향후의 SLA 협상에서 더 스마트 한 견적을 작성하기 위해 테넌트 선택의 이력을 유지할 수 있다. (예를 들어, 에지 클라우드 및 구현 시스템 및 디바이스의) 다중 테넌트 에지 클라우드 전력 관리를 위한 제 1 예시적인 방법(예 T1)은 (예를 들어, 노드 또는 디바이스(2200, 2232, 2240 또는 2250)에서 또는 그에 의 해 구현되는) 처리 회로를 사용하여 수행되는 방법으로서, 방법은, 게이트웨이에서, 테넌트로부터 요청을 수신 - 게이트웨이는 스위치 패브릭을 통해 노드의 하드웨어 플랫폼에 연결됨 - 하는 단계; 게이트웨이에서, 테넌트 로부터의 요청에 대한 전력 구성을 수신하는 단계; 하드웨어 플랫폼으로부터 하드웨어 플랫폼을 선택하여 요청 을 완료하는 단계; 및 요청을 하드웨어 플랫폼에 발송하는 단계를 포함한다. 제 2 예(예 T2)에서, 예 T1의 주제는, 게이트웨이가 인증자 회로(authenticator circuit)를 포함하는 것을 포함 하며, 여기서 테넌트로부터 요청을 수신하는 단계는 요청을 인증하는 단계를 포함한다. 제 3 예(예 T3)에서, 예 T1-T2의 주제는, 하드웨어 플랫폼으로부터, 게이트웨이의 스위치를 통해 하드웨어 플랫 폼에 걸친 로드 밸런싱 요청을 포함하는 하드웨어 플랫폼을 선택하는 단계를 포함한다. 제 4 예(예 T4)에서, 예 T3의 주제는, 스위치가 게이트웨이의 원격 측정 회로로부터의 데이터를 통합하여 여러 플랫폼 중 어느 것이 요청을 서비스하는데 이용 가능한지를 결정하는 것을 포함한다. 제 5 예(예 T5)에서, 예 T1-T4의 주제는, 전력 구성이 최대-최소 전력 범위, 최대 전력 소비, 또는 전력 소비에 기초한 최대 금전적 가치 중 적어도 하나를 포함하는 것을 포함한다. 제 6 예(예 T6)에서, 예 T1-T5의 주제는, 요청이 서비스 레벨 협약(SLA) 요구 사항을 포함하는 것을 포함하며, 여기서 하드웨어 플랫폼을 선택하는 단계는 SLA 요구 사항을 사용하여 하드웨어 플랫폼을 선택하는 단계를 포함 한다. 다양한 설정에서, 예 T1-T6(및 다중 테넌트 전력 또는 자원 사용 관리의 다른 양태)은 정의된 애플리케이션 프 로그래밍 인터페이스 또는 인터페이스 사양; 메시지 포맷, 원격 측정 데이터 또는 정의의 사용; 및 에지 컴퓨팅 환경 내에서 자원 사용 모니터링 및 관리에 대한 정책 및 로직의 다른 사용 및 구현의 결과로서 관찰되거나 모 니터링될 수 있다. 예 T1-T6 및 이러한 전력 관리 기술의 다른 양태는 또한 (예를 들어, FaaS 또는 EaaS 설정 에서 서비스에 의해 호출된 자원을 할당하고 운영하는) 서비스 동작 및 서비스 기능의 결과로서 관찰되거나 구 현될 수 있다. 또한, 예 T1-T6의 방법은 에지 컴퓨팅 시스템에서 (예를 들어, 명령어가 실행될 때 방법을 수행 하는 머신 판독 가능 매체와 함께) 구현된 명령어로서 또는 (예를 들어, 방법을 수행하거나 달성하는 구성을 포 함하는 장치와 함께) 구현된 하드웨어 구성으로서 제공될 수 있다. 따라서, 예 T1-T6의 특징(및 전력 및 자원 사용 제어의 다른 특징)은 시스템 오케스트레이터 또는 설계자에 의해 조정되거나 설계된 대로, 본 명세서의 임 의의 다른 예와 조합되어 에지 클러스터 또는 에지 클라우드 시스템을 구성할 수 있다. 다중 테넌트 고 처리량 생체측정(Multi-Tenant High Throughput Biometry)의 예 도 55는 에지 클라우드 아키텍처(예를 들어, 에지 클라우드 및 도 3 내지 도 22d에 도시된 에지 컴퓨팅 시 스템 구성)에서 생체측정 처리의 예시적인 유스 케이스를 도시한다. 다른 곳에서와 마찬가지로, 에지 컴퓨팅은 다수의 애플리케이션(예를 들어, 물체 추적, 비디오 감시, 커넥티드 카 등)을 실시간으로 서비스하고 응답하는 역량 및 이러한 애플리케이션에 대해 초저 지연시간 요구 사항을 충족하는 역량과 같은 몇 가지 이점을 제공한 다. 하나의 이러한 애플리케이션 또는 유스 케이스는 생체측정이다. 생체측정은 새로운 비즈니스 모델을 가능 하게 하는 유스 케이스이다. 에지에서 분산되고 가속된 컴포넌트 및 연관된 낮은 지연시간의 유스 케이스도 또한 생체측정 검증을 위한 확장 가능한 아키텍처를 달성하는데 중요하다. 그러나, 생체측정에 대한 추가 고려 사항은 \"권한\" (예를 들어, 심사된, 승인된, 허가된 등) 에지 행위자만이 이러한 보안에 임계적인 애플리케이션 에 사용되도록 보장하는 것이다. 사용될 수 있는 에지 컴퓨팅 아키텍처 시나리오는 네트워킹 및 컴퓨트를 비롯한 엔드-투-엔드 인프라스트럭처를 제어하는 사업자를 포함한다. 이러한 시나리오에서, 사업자는 자기 소유의 플랫폼을 사용하여 서비스를 실행하 고 예비 플랫폼을 제 3 자와 잠재적으로 공유한다(예를 들어, 임대한다). 이것은 사업자의 관점에서 볼 때 매 력적이다. 그러나, 서비스 제공자는 보안, 프라이버시, 서비스 품질(QoS) 또는 지적 재산)(IP) 보호에 대해 염 려할 수 있다. 예에서, 세 가지 레벨의 에지 분할이 발생할 수 있다. 첫째, 인프라스트럭처를 제어하는 사업자는 컴퓨트 컴포 넌트를 다수의 파티션으로 분할할 수 있으며, 이들 중 어느 것이다른 사업자에게 임대될 수 있다. 이러한 모 델은 소규모 사업자가 대규모 사업자의 인프라스트럭처를 사용하는 영역에서 널리 퍼질 수 있다. 둘째, 인프라 스트럭처 사업자는 할당된 파티션을 동일한 유형의 세 개의 논리 파티션(예를 들어, 레벨 1): 제 3 자 서비스 제공자에게 임대될 수 있는 파티션; 네트워크 기능(예를 들어, 가상 광대역 네트워크 게이트웨이(virtual Broadband Network Gateway)(vBNG) 또는 가상 진화된 패킷 코어(virtual Evolved Packet Core)(vEPC))을 실행 하기 위한 파티션; 및 사업자가 자신의 고객(예를 들어, 사업자에게 가입된 사용자 장비(User Equipment)(UE)) 에게 제공하는 서비스를 호스팅하기 위한 파티션으로 분할할 수 있다. 예에서, 하위 레벨(예를 들어, 레벨 2 또는 서브레벨) 파티션은 또한 다수의 파티션으로 분할될 수 있으며, 일 부는 제 3 자에게 다시 사용(예를 들어, 다른 사람에게 임대)할 수 있다. 예에서, 이러한 파티션은 서비스 제 공자가 관리하고 가상으로 소유한다. 동시에, 이 파티션은 두 개의 파티션으로 분할할 수 있으며; 하나는 클라 우드 서비스 제공자(CSP) 워크로드를 실행하기 위한 것이다. 이것은 예를 들어, 제 3 자가 파티션을 임대하고 다른 사람의 사용을 위한 자기 소유의 서비스(예를 들어, 레벨 3 애플리케이션)를 노출할 수 있다. 생체측정의 경우, 에지 클라우드 하드웨어와 관련된 신뢰 문제는 측정을 수행하는 디바이스(예를 들어, 모바일 폰 또는 보안 도어락) 상에서 생체측정 워크로드를 유지하거나, 또는 생체측정 공급 업체에 의해 제어되는 클라 우드에서 워크로드를 실행하는 것을 선호하는 것으로 이어져 왔다. 이러한 접근 방식의 단점은 사용자 중심의 제한 사항을 포함한다. 즉, 디바이스는 일반적으로 디바이스가 생체측정 데이터를 저장하는 고정된 수의 사용 자를 인증하는 것으로 제한된다. 데이터를 클라우드에 저장하는 것도 제한 사항이 있다. 예를 들어, 데이터가 클라우드 데이터 센터 위치에 도달할 때까지 몇몇 네트워크를 통과하므로 보안이 우려될 수 있다. 또한, 데이 터가 클라우드에 전송되고 처리되고 응답이 생성되므로 지연시간이 우려될 수 있다. 또한, 네트워크 연결은 서 비스 자체 외에도 장애 지점을 제공하므로 안정성이 문제가 될 수 있다. (예를 들어, 에지 클라우드 및 구현 시스템 및 디바이스 내의) 에지 클라우드 환경에서, 추가적인 우려가 진화할 수 있다. 예를 들어, 많은 생체측정 기술은 생체측정 데이터에 대한 사전 지식을 필요로 하며 다른 사 람(예를 들어, 다른 테넌트)과 스토리지 및 생체측정 하드웨어 자원을 공유하는 것을 다루지 않는다. 이러한 기술은 에지 클라우드 컴퓨팅 아키텍처의 특수성을 가진 계층적 아키텍처 용으로 설계되지 않았다. 이러한 기 술은 기술이 실행되는 플랫폼에 대한 제한 사항을 가정하지 않으며 계층적 아키텍처로 간주하지 않는다. 에지 클라우드 아키텍처의 컨텍스트에서, 작업이 최종 디바이스로 더 많이 이동될수록, 워크로드에 대한 스토리지 공 간, 전력 및 컴퓨트에 대한 제한은 더 커진다. 또한, 이러한 기술은 일반적으로 엔드-투-엔드 물리적 보안 요 구 사항을 가정하지 않는다. 에지 클라우드의 경우에, 기지국은 물리적 감시가 보장되지 않을 수 있는 장소에 배치될 수 있다. 또한, 이러한 기술은 일반적으로 엔드-투-엔드 하드웨어 가속을 사용하지 않거나 또는 다중 계층 아키텍처에서 스토리지를 효과적으로 관리하지 않는다. 이러한 인자는 총 소유 비용(Total Cost of Ownership)(TCO) 감소가 추구될 때 임계적일 수 있다. 즉, 다중 계층 아키텍처가 해결되지 않는 한, 자원이 효 과적인 컴퓨팅을 위해 할당되는 것을 보장하기는 어려울 것이다. 에지 클라우드 아키텍처의 컨텍스트에서 이러한 생체측정 인증 문제를 해결하기 위해, 콘텐츠 데이터 네트워크 (CDN)와 유사하게, 에지의 생체측정 사용자 데이터를 자동으로 그리고 안전하게 관리할 수 있는 계층적 생체측 정 인증 아키텍처가 사용될 수 있다. 이것은 세 가지 레벨의 에지 제어, 예를 들어, 테넌트 단독, 테넌트와 CSP 호스팅 테넌트, 테넌트와 CSP 호스팅 테넌트와 CSPS를 호스팅하는 사업자에 의해 사용될 수 있는 새로운 데 이터 액세스 모델을 포함할 수 있다. 아키텍처는 상이한 레벨의 에지 계층에서 생체측정 인증 워크로드를 위한 테넌트 고객 맞춤 하드웨어 가속(tenant customizable hardware acceleration)을 포함할 수 있다. 예에서, 에지 계층(예를 들어, 중앙국, 기지국 등)은 하나 이상의 테넌트에 의해 사용되는 하나 이상의 생체측 정 메모리 또는 가속된 생체측정 하드웨어를 포함한다. 이러한 아키텍처는 테넌트가 생체측정 데이터를 등록 또는 제거할 수 있게 하거나 지능형 네트워크 인터페이스 제어기(iNIC)에 처리 비트스트림을 등록하여 에지 디 바이스로부터 나오는 생체 인증 요청을 처리할 수 있도록 하는 인터페이스와 같은 몇몇 컴포넌트를 포함할 수 있다. 아키텍처는 또한 보안 키를 관리하는 명령어(예를 들어, 회로에 구현된 로직 또는 코드)를 포함할 수 있다. 예 를 들어, 보안 키는 대역 외 메커니즘을 통해 등록된다. 명령어는 에지 디바이스로부터 나오는 요청을 인증하 여 워크로드가 위에서 설명한 세 레벨 중 어느 하나에서 권한 행위자에 의해 수행되는 것을 보장하도록 구성된 다. 아키텍처는 또한 생체측정 사용자 데이터를 관리하고 계층적 캐시의 레벨 간(예를 들어, 기지국 저장소로부터 중앙국 저장소까지)의 생체측정 사용자 데이터의 전송을 관리하는 명령어를 테넌트 단위로 구현하는 제어기를 또한 포함할 수 있다. 이러한 생체측정 데이터 관리 정책은 테넌트 기준(예를 들어, 데이터가 저장되는 위치, 신뢰할 수 있는 하드웨어 보안 레벨 등)을 기초로 할 수 있다. 예에서, 생체측정 데이터는 사업자 네트워크의 코어에서 호스팅되고 계층에서의 나머지 계층은 중간 캐싱 계층으로서 역할을 한다. 에지 디바이스에 가까울수 록, 캐싱 용량이 더 적어질 가능성이 높아, 적합한 생체측정 데이터 캐싱 정책의 구현을 통해 지연시간을 줄이 는 더 큰 효과가 관찰되는 결과를 가져온다. 또한, 위에서 논의된 바와 같이, 이러한 생체측정 데이터는 원격 측정 데이터를 자동으로 비활성화, 제거 또는 삭제하는데 사용될 수 있는 타임스탬프 또는 만료 데이터의 유형 을 포함할 수 있다. 아키텍처는 또한 랙 요소를 계층의 다른 레벨에 있는 요소에 연결하는 패브릭(예를 들어, 인트라 네트워킹 회로)을 포함할 수 있다. 이것은 랙의 상이한 스토리지 풀, 전력 도메인, 또는 요소에 데이터를 자동으로 복제 하여 패브릭 인프라스트럭처에 의해 관리되는 테넌트 요구 사항을 충족하는 안정성 회로와 결합될 수 있다. 예에서, iNIC는 에지 요청을 처리하여 주어진 사용자를 인증하는 생체측정 스케줄링 회로를 포함할 수 있다. 이것은 요청 엔티티가 인증 요청을 수행할 권한이 있다는 검증에 의해 보완될 수 있다. 이러한 생체측정 인증 은 생체측정 데이터 캐시에 액세스하여 인증을 받는 에지 사용자로부터 생체측정 참조 데이터를 획득하는 것을 포함할 수 있다. 예에서, 인증이 수행될 수 없으면(예를 들어, 실패한 경우), 요청은 계층의 상위 레벨로 라우 팅될 수 있다. 사용자로부터 수신된 생체측정 데이터와 에지 클라우드 참조 생체측정 데이터를 사용하여 iNIC에서 인증 생체측 정 비트 스트림을 실행하면 생체측정을 정확하고 빠르게 하는 결과를 가져올 수 있다. 즉, 이러한 솔루션은 예 를 들어, 시스템 스택 오버헤드를 발생시키지 않고 비 생체측정 요청에 컴퓨트를 사용함으로써 초저 지연시간 에지 집합, 끊김없는 위치 에지 디바이스 집합, 더 나은 시스템 TCO을 초래할 수 있다. 이러한 이점으로 인해 생체측정 워크로드를 위한 확장 가능하고 안전하고 자동화된 고객 맞춤형 솔루션이 초래된다. 도 55는 생체측정 계층 아키텍처의 예를 도시한다. 도시된 바와 같이, 아키텍처는 (통신사 배치의 컨텍스트에서 설명되지만 다른 네트워크 컨텍스트에도 동일하게 적용 가능한) 에지 디바이스, 소형 셀 , 기지국 및 중앙국(CO을 포함한다. 소형 셀, 기지국 및 CO는 각각 에 지 게이트웨이(5511, 5516, 5521)를 포함한다는 것을 알아야 한다. 이러한 에지 게이트웨이(5511, 5516, 5521)는 주어진 생체측정 페이로드가 사용자 식별(ID)에 대응한다는 것을 검증하는 인터페이스를 노출한다. 에 지 게이트웨이(5511, 5516, 5521)는 또한 특정 사용자 ID에 대한 생체측정 데이터가 캐시되었는지를 체크하는 캐시를 포함할 수 있다. 예에서, 캐시는 테넌트 별로 구성되고 크기가 지정된다. 따라서, 예에서, 각각의 테넌트는 예상되는 생체측정 처리량 또는 용량 요구 사항과 매칭하도록 더 많거나 더 적은 캐시 를 예약할 수 있다. 예에서, 에지 게이트웨이(5511, 5516, 5521)는 테넌트가 비트 스트림을 등록하여 각 시점에서 에지에서 어떤 생 체측정 데이터가 캐시되는지를 관리할 수 있게 하는 회로를 포함한다. 이 회로는 아키텍처의 하위 계층 으로부터 생체측정 데이터를 프리페치되도록 구성될 수 있다. 여기서, 최고 레벨은 CO이고 이 레벨은 에 지 디바이스 쪽으로 감소한다. 에지 게이트웨이(5511, 5516, 5521)는 인증 요청에 응답하여 캐시에 액세스하는 액세스 회로를 포함할 수 있다. 예에서, 캐시 히트시, 생체측정 데이터가 로컬 디스크로부터 검색되도록, 캐시 액세스가 관리된다. 예에서, 생 체측정 데이터는 생체측정 페이로드와 함께 생체측정 인증 설비(예를 들어, 하드웨어 또는 서비스)에 제공된다. 이러한 설비는 인증을 수행하고 결과를 다시 에지 디바이스로 전송할 수 있다. 예에서, 생체측정 데이터가 로컬로 캐시되지 않으면, 회로는 다음 레벨까지 (예를 들어, 기지국으로부터 CO로) 요청을 포워 딩한다. 이러한 포워드 메시지는 인증이 성공적이었는지를 표시하는 응답뿐아니라, 인증에 사용되고, 향후 인 증을 위해 로컬로 캐시할 생체측정 데이터로 응답하도록 응답될 수 있다. 예에서, 인증 요청이 CO(또는 계층에서 동등한 최상위 레벨)에 캐스케이드되면, 요청은 클라우드 서비스를 통해 어드레스 지정될 수 있다. 생체측정 페이로드가 처리되는 각각의 지점은 LSM 시행 지점이 될 수 있다. 이것은 사용자 프라이버시를 보호 하는 보안 정책을 사용하여 에지 인프라스트럭처 전체에서 프라이버시에 민감한 콘텐츠가 준수할 수 있게 할 수 있다. 예에서, 위에서 언급한 에지 게이트웨이 컴포넌트는 iNIC에서 구현될 수 있다. 따라서, iNIC는 생체측정 데이 터 및 대응하는 인증을 관리하는 회로를 포함한다. 이러한 인증은 예를 들어, 그러한 당사자 간의 인증을 위한 생체측정 데이터 보안을 보장하기 위해 테넌트 사이에서 분할될 수 있다. 여기서, iNIC는 소유자 ID(예를 들어, 테넌트 소프트웨어)가 iNIC에 처리 비트스트림을 등록 또는 등록 취소하여 상이한 생체측정 지원 기술을 처리할 수 있게 하는 인터페이스를 갖는다. 이러한 처리의 일부로서, iNIC는 에지 입안자를 인증하는데 사용되 는 보안 키를 등록 또는 등록 취소하도록 구성되고, 에지 입안자는 차례로 에지 사용자를 인증할 수 있다. 따 라서, iNIC는 들어오는 요청을 검증하고, 풀링된 스토리지 또는 메모리에 데이터를 안전하게 저장하고, 데이터 를 안전한 방식으로 상위 또는 하위 계층에 전송하도록 구성된다. 예에서, 보안 키를 관리하는 iNIC 회로는 대 역 외 등록 경로를 포함한다. 예에서, 에지 게이트웨이 컴포넌트는 풀링된 스토리지 제어기를 포함한다. 풀링된 스토리지 제어기는 생체측정 사용자 파일이 풀링된 스토리지에 저장되는 방법을 관리하고 계층적 캐시 구조를 구현하도록 구성된다. 예에서, 계층적 캐시 구조는 핫(hot), 웜(warm) 및 콜드(cold) 데이터와 같은 데이터 라벨링에 기초한다. 예에 서, 풀링된 스토리지 제어기는 두 개의 인터페이스를 포함한다. 제 1 인터페이스는 특정 어드레스 범위에 연관 된 파일 또는 데이터가 계층에서 승격 또는 강등되는 방법을 명시하는 - 소유자 ID 및 잠재적으로는 상이한 어 드레스 범위 또는 파일 세트 별과 같은 - 마커 별 비트 스트림의 인라인 등록 및 등록 취소를 가능하게 한다. 비트 스트림 자체는 캐시 계층 내 데이터의 승격 또는 강등을 관제하는데 사용되는 다양한 정보 조각을 수신할 수 있다. 예를 들어, 비트 스트림은 플랫폼 및 잠재적으로는 특정 소유자 ID 또는 범위 리스트와 연관된 자원 에 대한 원격 측정 정보에 대해 동작할 수 있다. 예에서, 비트 스트림은 특정 소유자 ID 또는 범위 리스트와 연관된 초당 입출력 동작(Input-Output Operations Per Second)(IOPS)과 같은 성능 정보에 대해 동작할 수 있 다. 예에서, 비트 스트림은 특정 데이터 또는 파일이 액세스되고 있고 어떤 모드에서 액세스되고 있는지를 표 시하는 정보에 대해 동작할 수 있다. 제 2 스토리지 제어기 인터페이스는 계층의 상위 계층이 계층+1로부터 현재 계층까지 연관된 파일 또는 데이터 를 강등할 수 있도록 구성된다. 이러한 인터페이스는 현재 소유자 ID가 요청된 데이터를 캐시하기에 충분한 공 간을 갖는지를 회로가 체크하도록 구현된다. 공간이 충분하지 않으면, 회로는 더 많은 자원을 추가하도록 구성 된다. 가용 자원이 더 이상 없으면, 회로는 오류를 예를 들어, 관리 엔티티 또는 오케스트레이터로 에스컬레이 트하도록 구성된다. 여지가 (예를 들어, 충분한 자원이) 있으면, 인터페이스 회로는 데이터를 대응하는 계층 +1로부터 현재 계층으로 마이그레이션한다. 유사한 방식으로, 인터페이스는 데이터를 현재 계층으로부터 계층-1로 강등하도록 구성된다. 예를 들어, 인터 페이스는 소유자 ID 및 잠재적으로는 어드레스 범위와 연관된 데이터에 액세스한다. 캐시 미스가 있을 때, 데 이터 관리자는 하위 계층에 요청을 송신하여 데이터를 페치한다. 여기서, 인터페이스는 현재 소유자 ID에 요청 된 데이터를 캐싱하기에 충분한 공간이 있는지를 체크하도록 구성된다. 그렇지 않으면, 더 많은 자원이 추가될 수 있다. 더 많은 자원이 없으면, 문제는 예를 들어, POD 관리자 또는 오케스트레이터로 에스컬레이트된다. 여지가 있으면, 인터페이스 회로는 데이터를 계층 1 노드로부터 현재 노드로 마이그레이션하도록 구성된다. 예에서, 각 소유자 ID(예를 들어, 테넌트)는 캐싱 계층 내에서 데이터를 승격할지 강등할지를 관제하는 하나 이 상의 비트 스트림을 가질 수 있다. 예에서, 테넌트는 에지 게이트웨이에 의해 제공되는 디폴트 데이터 캐싱 정 책을 선택할 수 있다. 따라서, 각각의 소유자 ID는 고객 맞춤형 비트 스트림 또는 일반 캐시 관리 정책을 구현 할 수 있다. 추가 예에서, 프라이버시 또는 법적 고려 사항은 위에서 설명된 방식으로 생체측정 이미지의 수집 및 분산을 방 지할 수 있다. 이러한 시나리오에서, 개인 디바이스에서, 스마트 쥬얼리에서 또는 암호화 키를 수용하는 일부 형태의 인증된 컴포넌트에서 생체측정 참조 템플릿을 유지하는 설계 원칙이 사용될 수 있다. 키는 사용된 것을인증하는데 사용되며, 이러한 키는 프라이버시 보호 규범을 위반하지 않고 필요에 따라 전파되고, 캐시되고 사 용될 수 있다. 키는 사용자를 키에 바인딩하는 것과 키를 보호하여 신뢰 레벨을 키와 연관시키는데 사용되는 보안 요소에 관한 증명 청구(attestation claim)를 포함할 수 있다. (예를 들어, 사용자는 네임-키 바인딩 (name-key binding)을 사용하여 상이한 네임을 등록할 수 있는 역량이 제공될 수 있으므로, 상이한 네임은 사용 자에 의해 변경될 수 없는 생체측정이 아닌 별칭 또는 애플리케이션 특정 네임 또는 계정에 의해 알려질 수 있 다). (예를 들어, 에지 클라우드 및 구현 시스템 및 디바이스 내의) 다중 테넌트 고 처리량 에지 생체측정 처리 를 위한 제 1 예시적인 방법(예 U1)은 (예를 들어, 노드 또는 디바이스(2200, 2232, 2240 또는 2250)에서 또는 그에 의해 구현되는) 처리 회로를 사용하여 수행되는 방법으로서, 방법은, 지능형 네트워크 인터페이스 제어기 (iNIC)에서, 생체측정 인증 요청을 수신하는 단계; iNIC에 의해, 요청에 대응하는 생체 데이터를 풀링된 스토리 지 제어기로부터 검색하는 단계; iNIC에 의해, 생체측정 데이터를 요청 내의 데이터와 비교하여 생체측정 인증 을 수행하는 단계; 및 iNIC에 의해, 생체측정 인증을 포함하는 요청에 대한 응답을 송신하는 단계를 포함한다. 제 2 예(예 U2)에서, 예 U1의 주제는, 풀링된 스토리지 제어기에 의해, 생체측정 데이터에 대한 로컬 캐시를 탐 색하는 것을 포함하는 풀링된 스토리지 제어기로부터 생체 데이터를 탐색하는 단계를 포함하며, 로컬 캐싱은 계 층의 하위 레벨이 에지 디바이스에 더 가까운 캐시 계층의 일부이다. 제 3 예(예 U3)에서, 예 U2의 주제는, 하위 레벨 디바이스의 로컬 캐싱에 생체측정 데이터가 없다는 것에 응답 하여, 생체측정 인증 요청이 계층의 하위 레벨 디바이스로부터 수신되는 것을 포함한다. 제 4 예(예 U4)에서, 예 U3의 주제는, 하위 레벨 디바이스에서 생체측정 데이터의 캐싱을 가능하게 하는 응답과 함께 생체측정 데이터를 하위 레벨 디바이스에 송신하는 단계를 포함한다. 다양한 설정에서, 예 U1-U4(및 다중 테넌트 생체측정 처리의 다른 양태)는 정의된 애플리케이션 프로그래밍 인 터페이스 또는 인터페이스 사양; 프로토콜, 메시지 포맷, 원격 측정 데이터 또는 정의의 사용; 및 에지 컴퓨팅 환경 내에서 생체측정 서비스에 대한 정책 및 로직의 다른 사용 및 구현의 결과로서 관찰되거나 모니터링될 수 있다. 예 U1-U4의 생체측정 서비스 및 위에서 논의된 다른 변형은 또한 (예를 들어, 서비스 메시징 및 FaaS 또 는 EaaS 설정에서 사용되는 데이터 통신으로부터) 다른 서비스 동작 및 서비스 기능이 호출되거나 그와 조정되 는 결과로서 관찰되거나 구현될 수 있다. 또한, 예 U1-U4의 방법은 에지 컴퓨팅 시스템에서 (예를 들어, 명령 어가 실행될 때 방법을 수행하는 머신 판독 가능 매체를 이용하는) 구현된 명령어 또는 (예를 들어, 방법을 수 행하거나 달성하는 구성을 포함하는 장치를 이용하는) 구현된 하드웨어 구성으로서 제공될 수 있다. 따라서, 예 U1-U4의 특징(및 생체측정 데이터 처리 및 관리의 다른 특징)은 시스템 오케스트레이터 또는 설계자에 의해 조정되거나 설계된 대로, 본 명세서의 임의의 다른 예와 조합되어 에지 클러스터 또는 에지 클라우드 시스템을 구성할 수 있다. SLA의 마이그레이션, 전파 및 적응(Migrating, Propagating, and Adapting SLA)의 예 예에서, 에지 컴퓨팅 시나리오는 다수의 테넌트 및 이해 관계자 간의 적절한 QoS 조건을 고려하고 적응하도록 구성될 수 있다. 특히 에지 클라우드 아키텍처는 특정 레벨의 QoS를 유지하거나 특정 SLA를 충족하는 동시에 플랫폼 당 서비스 밀도를 높이거나 최대화하는 방법에 어려움을 겪을 수 있다. 서비스 품질 속성 또는 서비스 레벨 계약의 측면에서, 세 가지 유형의 잠재적 모델이 적용될 수 있다: 특정 서비스에 대한 서비스 품질 정 의 또는 서비스 레벨 협약이 없음. 이것은 고정된 양의 프라이버시 또는 공유 자원이 첨부되어 있지 않음을 의 미할 수 있다; 소프트 서비스 레벨 협약. 관련 서비스는 서비스 양이 공유된 자원의 사용에 의해 제한되 는 경우에도, 서비스가 프라이버시 및 공유된 컴퓨트 자원의 양에 따라 사용자에게 처리량과 지연시간을 제공할 수 있도록 한 세트의 프라이버시 자원의 양(예를 들어, 코어 하드웨어 자원) 및 한 세트의 공유 자원(예를 들어, 최종 레벨 캐시 또는 메모리)의 할당을 갖는다. 이런 이유로, 이 시나리오에서, 서비스의 양 또는 복잡 성(및 플랫폼에 대한 압력)이 증가할 때 99 %의 보장된 지연시간은 불가능할 수 있다; 하드 서비스 레벨 협 약. 여기서, 서비스는 모든 자원을 사적 모드로 사용하고 있다. 이 경우, 예상되는 지터가 최소화되어야 한다. 이러한 SLA를 달성하기 위해, 두 개의 접근 방식: (a) 플랫폼이 서비스에 완전히 할당되게 하는 방식; (b) 모든 공유 자원을 하드 파티션하고 개인에게 할당하도록 구성하는 방식을 취할 수 있다. 어느 한 유형의 SLA를 달성하기 위해, 분산 에지 클라우드 아키텍처는 다수의 에지 노드 사이에서 워크로드 및 워크플로우를 분산하려고 시도할 수 있다. 그러나, 에지 컴퓨팅 시스템은 다수의 에지 노드 사이에서 서비스 동작을 제공하는 SLA를 배치하고 활용하려고 할 때 다수의 문제에 직면할 수 있다. 첫째, 다수의 컴퓨트 위치에서 SLA를 적응하고 활용할 수 있게 하는 쉽게 사용할 수 있는 메커니즘이 없다. 둘째, 다수의 컴퓨트 위치가 호출되고 서비스가 다른 노드로 이동함에 따라(예를 들어, 컴퓨트가 데이터에 대해 이동됨에 따라), 오케스트레 이터 및 서비스 코디네이터는 서비스가 인식되는 방식과 추가 노드를 호출할 필요가 있는지를 이해해야 한다. 셋째, 서비스가 SLA를 충족하는 다수의 에지 노드로 이동함에 따라, 이동이 실패하거나 새롭게 호출된 노드가 SLA를 충족할 수 없으면, 문제가 발생할 수 있다. 도 56은 에지 컴퓨팅 시스템(예를 들어, 에지 클라우드의 일부를 구현하도록 제공된 시스템, 또는 도 3 내지 도 22d에 도시된 에지 컴퓨팅 시스템 구성)의 다수의 에지 노드 사이에서 SLA의 마이그레이션을 위한 시나리오를 도시한다. 이 시나리오에서, 하나의 노드로부터 다른 노드로(예를 들어, 노드 1로부터 노드 2 대 노드 3으로) 기능 워크로드의 이전을 지원하는 SLA \"서비스 호스팅\" 추상화가 서비스 실행을 위해 설정된다. 추상화는 호출될 서비스 또는 기능을 명시하려고 하지 않기 때문에, 이러한 서비스 호스팅 추 상화는 (예를 들어, UPNP와 같은 접근 방식에 의해 제공되는) \"서비스 제공자\" 추상화와는 다르다. 오히려, 추 상화는 SLA를 충족하는데 필요한 호스팅 환경 속성 및 제약 조건을 설명하는데 사용된다. 제 1 예에서, SLA 하에서 동작하는 워크로드는 에지 노드를 가로 질러(예를 들어, 노드 1로 부터 노드 2 대 노드 3로) 마이그레이션될 수 있다. 이러한 마이그레이션 도중 및 이후에, 워크로 드가 도착한 위치 및 각각의 노드 사이에서 이러한 워크로드를 수행하는 가용성을 확인하여 SLA의 이행을 보장하는 데이터 추적성 접근 방식이 사용된다. 이해하는 바와 같이, 서비스의 일관성 및 연속성은, 특히 워크 로드 및 이러한 워크로드에 대한 서비스 가용성이 (예를 들어, 인스턴스(5651A, 5651B, 5651C)를 갖는) 인프라 스트럭처 주변으로 이동할 때, 추적 가능하고 검증 가능해야 한다. 이것은 서비스(및 SLA 목표)가 클라 이언트(예를 들어, UE)에 의해 인식되는 방식을 검증하는 단계를 포함한다. 또한, 보안 관점에서 볼 때, SLA는 보안 보호의 값과 그 애플리케이션에 대한 프레임워크를 설정할 수 있으므로, SLA는 LSM 사 용을 위한 유형 및 전략을 협상하는 수단이 될 수 있다. 상이한 노드에서 상이한 서비스(및 서비스 인스턴스)를 활용하기 위한 워크로드의 마이그레이션은 동-서(노드에 서 노드로) 이동, 북-남(클라이언트에서 서버로, 또는 엔드포인트에서 네트워크로 더 멀리) 이동 또는 둘 모두 의 접근 방식의 순서적인 조합을 사용하여 발생될 수 있다. 마이그레이션은 에지 노드가 SLA를 충족하는 문제에 직면하고 있고 도움이 필요하다는 인식 또는 예측에 기초하여(예를 들어, 자원 가용성이 있는 근처 노드 로부터, 서버 또는 게이트웨이로부터 네트워크로 더 멀리, 등) 트리거되거나 제어될 수 있다. 마이그레이션에는 제공된 서비스를 동적으로 적응시켜서 모바일 클라이언트 엔드포인트에 의해 설정된 SLA를 사 용하는 자원 선택 단계의 사용이 수반될 수 있다. 따라서, 사용자의 UE(예를 들어, UE)가 상이한 지리적 영역 또는 서비스 영역으로 이동하고 상이한 에지 컴퓨팅 자원과 접촉함에 따라, SLA는 UE와 함께 마이그레이션할 수 있다. 발생하는 특정 SLA 마이그레이션 동작은 SLA와 에지 컴퓨팅 시스템 간의 종속성뿐만 아니라, 호출된 서비 스 유형, 워크로드의 특성 등에 기초할 수 있다. 서비스는 두 개 이상의 카테고리로 그룹화될 수 있다. 우선 순위가 높거나 임계적인 서비스는 SLA를 충족하는 (예를 들어, 모든 상황에서 최소 레벨의 서비스가 보장되는) 사전적 마이그레이션이 필요할 수 있는 반면, 나머지 서비스는 SLA를 충족하는 (예를 들어, 비즈니스에 중요하 지만 높은 가용성을 위해 마이그레이션할 수 있는 서비스에 대해 메모리 용량의 5 % 또는 메모리 대역폭의 10 % 가 예비로 유지되는) 표준 마이그레이션 접근 방식이 주어진다. 추가 예에서, 특정 워크로드 또는 서비스를 위한 SLA는 다수의 워크로드를 포함하는 글로벌 (예를 들어, 시스템 전체, 다중 시스템 전체) SLA의 일부로서 에지 컴퓨팅 환경 내에서 취급될 수 있다. 따라서, 컴퓨트 노 드 중 하나가 특정 워크로드에 대해 SLA를 충족할 수 없는 시나리오에서, 마이그레이션 동작이 호출되어 SLA를 충족하도록 추가 자원이 활용되게 할 수 있다. 이 시나리오에서 SLA를 사용하는 것은 (노드로부터 노드 대 노드로 컴퓨트 활동을 위한 워크플로우 파이프라인을 형성하는 워크로드를 포함하는) 다수의 에지 사이 에 분리될 수 있는 워크로드의 사용을 통해 이익을 얻는다. 결과적으로, 자원이 워크로드의 임의의 항목에 대 해 충족될 수 없으면, 워크플로우에 대한 글로벌 SLA는 자원을 집결하고 워크로드 처리를 달성하도록 단계를 밟 을 것이다. 에지 컴퓨팅 시스템의 서비스 및 노드 중에서 SLA 추상화를 정의하고 마이그레이션하기 위한 이러한 개념은 워 크플로우 또는 서비스의 측정 가능한 목표를 위해 정의된 특정 SLO 추상화와 함께 사용하는 경우에도 적용할 수 있다. 또한, 추가 예에서, SLA 또는 SLO는 (예를 들어, 디바이스를 비롯하여, 에지 노드 자체 외부의) 외부 입력, 조건 또는 데이터에 기초하여 다수의 에지 노드 사이에서 적응될 수 있다. 결과적으로, 워크플로우또는 서비스에 대해 추상화된 우선순위 또는 SLA/SLO는 메트릭 또는 원격 측정(예를 들어, 에지 컴퓨트 서비스 의 사용 및 코디네이터를 제안하는 백홀 대역폭 메트릭)을 제공할 수 있는 다른 피어 또는 에지 디바이스로부터 의 입력에 따라 달라질 수 있다. 추가 예에서, SLA 추상화는 에지 컴퓨팅 서비스 내의 SLA의 적응, 수정 및 조정의 형태의 SLA \"힐링 (Healing)\"에 대한 개념과 연관될 수 있다. SLA 힐링을 위한 이러한 처리는 잠재적인 다른 에지(예를 들어, 서 비스를 제출할 새로운 컴퓨팅 위치)를 식별하는 것, 더 이상 작동하지 않는 SLA를 조정하기 위해 더 많은 자원 을 추가하는 방법을 식별하는 것 또는 유사한 변경을 구현하는 것을 포함할 수 있다. SLA 힐링은 잠재적인 중복성을 도입하여 워크로드를 어드레스 지정함으로써 글로벌 SLA 위반의 발생을 줄이는 데 사용될 수 있다. 예를 들어, 모든 호스트 또는 에지 노드에는 모든 워크로드 조각화와 관련된 명령어로의 액세스될 수 있다. 호스트가 SLA 요구 사항(예를 들어, 지연시간 요구 사항)을 충족할 수 없는 경우, 호스트는 \"실행 토큰(execution token)\"을 다른 호스트로 전달할 수 있다. 이러한 조정은 이벤트 중심적일 수 있으며 호 스트 간/오케스트레이터 간 통신을 사용하여 실시 가능해질 수 있다. SLA 추상화, SLA 마이그레이션 및 SLA 힐링의 배치는 다양한 유스 케이스에서 발생할 수 있으며, 다양한 오케스 트레이터 및 호스트 사이에 제공될 수 있다. 추가 예에서, 이러한 기술의 사용(및 SLA 또는 시스템 동작에 대 한 다른 적응)은 특정 유스 케이스 시나리오에 따라 달라질 수 있다. 예를 들어, 자동차 유스 케이스에서, 안 전 관련 특징은 그의 SLA를 손상시키지 않을 수 있지만, 인포테인먼트 특징은 MEC 환경(예를 들어, 배치, 로드 등)에 적응할 수 있다. 따라서, 분산 에지 컴퓨팅 시스템 내에서 SLA 적응은 다양한 형태를 취할 수 있다. 에지 컴퓨팅 시스템(예를 들어, 에지 클라우드 및 구현 시스템 및 디바이스)에서 SLA를 관리하기 위한 제 1 예시적인 방법(예 V1)은 (노드 또는 디바이스(2200, 2232, 2240 또는 2250)에 의해 구현되는) 처리 회로를 사 용하여 수행되는 방법으로서, 방법은, 정의된 서비스 레벨 협약(SLA)에 따라 에지 컴퓨팅 시스템에서 워크로드 를 처리하기 위한 에지 컴퓨팅 자원의 특성을 식별하는 단계; SLA를 충족하는데 필요한 호스팅 환경 속성 및 제 약 조건을 에지 컴퓨팅 시스템의 가용 호스팅 환경 속성 및 제약 조건과 비교 - 속성 및 제약 조건은 워크로드 를 처리하기 위해 식별된 특성으로부터 획득됨 - 하는 단계; 및 비교에 기초하여, 에지 컴퓨팅 시스템의 제 1 에지 노드로부터 제 2 에지 노드로 워크로드의 마이그레이션을 수행하는 단계를 포함하며, 여기서 비교는 제 1 에지 노드가 워크로드에 대한 SLA를 충족할 수 없다는 인식 또는 예측을 생성하고, 마이그레이션은 그 인식 또 는 예측에 응답하여 수행된다. 제 2 예(예 V2)에서, 예 V1의 주제는, 마이그레이션이 네트워크 레벨에서 동-서로 노드에서 노드로(node-to- node)의 이동에 기초하여 에지 컴퓨팅 시스템의 네트워크 내에서 발생하는 것을 포함한다. 제 3 예(예 V3)에서, 예 V1-V2의 주제는, 마이그레이션이 네트워크의 상이한 레벨에서 북-남, 노드에서 노드로 의 이동에 기초하여 에지 컴퓨팅 시스템의 네트워크 내에서 발생하는 것을 포함한다. 제 4 예(예 V4)에서, 예 V1-V3의 주제는, SLA를 제 2 에지 노드의 특성에 동적으로 적응시키는 단계를 포함하고, 제 2 에지 노드는 워크로드에 대한 적응된 SLA를 충족하도록 구성된다. 제 5 예(예 V5)에서, 예 V1-V4의 주제는, 호스팅 환경 속성 및 제약 조건이 워크로드를 활용하는 클라이언트 컴 퓨팅 디바이스의 이동성으로부터 변경되고, 클라이언트 컴퓨팅 디바이스는 에지 컴퓨팅 시스템 내 컴퓨팅 노드 의 상이한 지리적 서비스 영역 사이에서 이동하는 것을 포함한다. 제 6 예(예 V6)에서, 예 V1-V5의 주제는, 마이그레이션의 유형, 수량 또는 속도가 워크로드에 의해 호출된 서비 스 유형 또는 워크로드의 특성에 기초하는 것을 포함한다. 제 7 예(예 V7)에서, 예 V1-V6의 주제는, 워크로드에 대한 SLA가 글로벌 SLA의 서브세트이고, 글로벌 SLA가 에 지 컴퓨팅 시스템의 노드 사이에 분산된 복수의 워크로드에 대해 정의되는 것을 포함한다. 제 8 예(예 V8)에서, 예 V1-V7의 주제는, 외부 입력, 조건, 메트릭, 원격 측정, 또는 에지 컴퓨팅 시스템 내의 데이터에 기초하여, SLA 또는 SLA의 하나 이상의 서비스 레벨 목표(Service Level Objectives)(SLO)를 동적으 로 적응하는 단계를 포함한다. 제 9 예(예 V9)에서, 예 V1-V8의 주제는, 에지 컴퓨팅 시스템의 각각의 에지 노드에 의해 처리하기 위해 이용 가능한 컴퓨테이션 자원에 기초하여, SLA의 변경 및 에지 컴퓨팅 시스템의 각각의 에지 노드에 SLA와 워크로드 의 추가 할당을 수행하는 단계를 포함한다.제 10 예(예 V10)에서, 예 V1-V9의 주제는, 에지 컴퓨팅 시스템의 노드 사이에서 워크로드의 실행은 노드 사이 에서 통신되는 실행 토큰 및 특정 노드의 워크로드의 적어도 일부를 조정하고 수행하는데 사용되는 실행 토큰의 사용에 기초하는 것을 포함한다. 다양한 설정에서, 예 V1-V10(및 SLA 관리의 다른 양태)은 정의된 애플리케이션 프로그래밍 인터페이스 또는 인 터페이스 사양; 메시징, 프로토콜 및 정의 사용; 및 에지 컴퓨팅 환경 내에서 SLA 및 SLA 값을 마이그레이션하 고, 전파하고 적응하기 위한 로직 및 데이터 처리의 다른 사용 및 구현의 결과로서 관찰되거나 모니터링될 수 있다. 예 V1-V10 및 이러한 SLA 관리 동작의 다른 양태는 또한 (예를 들어, FaaS 또는 EaaS 설정의 서비스에서 워크로드가 제공되는) 서비스 동작 및 서비스 기능의 결과로서 관찰되거나 구현될 수도 있다. 또한, 예 V1-V10 의 방법은 에지 컴퓨팅 시스템에서 (예를 들어, 명령어가 실행될 때 방법을 수행하는 머신 판독 가능 매체와 함 께) 구현된 명령어로서 또는 (예를 들어, 방법을 수행하거나 달성하는 구성을 포함하는 장치와 함께) 구현된 하 드웨어 구성으로서 제공될 수 있다. 따라서, 예 V1-V10의 특징(및 서비스 레벨 협약 관리의 다른 예)은 시스템 오케스트레이터 또는 설계자에 의해 조정되거나 설계된 대로 본 명세서의 임의의 다른 예와 조합되어 에지 클러 스터 또는 에지 클라우드 시스템을 구성할 수 있다. 서비스 레벨 목표 변경(Changing Service Level Objective)의 예 분산 아키텍처의 도전과제 중 하나는 다양한 처리 유닛이 사용되어 워크로드를 실행할 수 있고 워크로드가 다양 한 위치로 시프트할 수 있는 분산 에지 아키텍처에서 테넌트가 갖는 서비스와 관련하여 언제든지 테넌트에 대해 서비스 레벨 협약(SLA) 및 대응하는 서비스 레벨 목표(service level objective)(SLO)가 충족되는 것을 보장해 주는 방법이다. 본 명세서에서 설명된 시스템 및 방법은 에지 플랫폼(예를 들어, 에지 클라우드 및 도 3 내지 도 22d에 도 시된 에지 컴퓨팅 시스템 구성)이 변환 정책, 등록 기능 및 서비스 품질(QoS) 시행 정책을 사용하여 변환 SLO 기능을 게시할 수 있는 분산된(그러나 조정된) 아키텍처를 사용한다. 에지 테넌트는 SLA가 유지되는 동안 서비 스를 획득하고 아키텍처 전반에 분산된 워크로드를 수행하거나 실행할 수 있다. 상이한 에지 위치를 갖는 상이한 에지 클라우드로 워크로드의 마이그레이션은 워크로드가 새로운 캐퍼빌리티를 갖는 새로운 하드웨어로 이동될 때 SLO와 매칭하도록 새로운 SLA를 자동으로 변환하는 기능이 필요할 수 있다. 예를 들어, SLA1은 A라는 SLO를 갖는 에지 위치 1에서 서비스 A에 필요할 수 있다. 워크로드가 에지 위치 2로 이동할 때, 새로운 위치(예를 들어, 에지 위치 2)에 기초하여 SLA를 업데이트하는 자동 방법이 필요할 수 있다. 도 57은 일부 예에 따른 서비스 레벨 목표를 향한 에지 기능 기반 변경을 위한 시스템을 도시한다. 도 57은 예시적인 플랫폼에서 확장될 수 있는 상이한 컴포넌트의 설명을 제공한다. 예에서, 플랫폼은 구성을 가능하게 하는 (예를 들어, 인터페이스 관리에 의해 관리되는) 한 세트의 인터페이스를 포함한다. 인터페이스는 SLO 기능에 대해 변환이 명시될 수 있게 하는 인터페이스를 포함할 수 있다. 명시될 수 있는 파라미터는 소스 플랫폼 유형, 소스 자원 유형 및 변환 기능을 포함할 수 있다. 소스 플랫폼 유형은 서비스가 마이그레이션되고 있는 소스를 표시할 수 있다. 이것은 특정 유형의 플랫폼 모델 또는 특정 유형의 기능성을 갖는 플랫폼 유형일 수 있다. 소스 자원 유형은 소 스 플랫폼에 대한 SLO가 잠재적으로 설정될 수 있는 자원의 유형을 표시할 수 있다. 변환 기능(예를 들 어, 기능 중 하나)은 현재 플랫폼의 특정 자원에 대한 구성을 생성하여 동일한 SLO 의미를 유지하는 원래 플랫폼의 서비스 레벨 협약에 대한 구성을 제공하기 위해 실행될 수 있다. 예를 들어, 서비스가 1 기가 바이트 의 메모리를 갖는 원래 시스템에서 실행 중일 수 있고 변환 기능은 새로운 시스템에서 동등한 1 기가 바 이트의 메모리의 SLA를 구현하기 위해 새로운 시스템의 메모리 제어기에서 레지스터 A1을 수정해야 한다고 컴퓨 트할 수 있다. 플랫폼은 새로운 서비스가 기존 SLA를 마이그레이션할 수 있게 하는 인터페이스를 또한 포함할 수 있다. 인터페이스는 예를 들어 시스템으로 마이그레이션된 새로운 서비스를 식별하는 처리 어드레스 공간 ID(Process Address Space ID)(PASID)의 사양, 원래 플랫폼의 자원 리스트 및 대응하는 SLA 리스트, 원래 자원의 플랫폼의 유형, 및 인터페이스를 실행하는 명령어 또는 코드를 허용할 수 있다. 명령어는, 변환 기능을 실행하고 등록 기능을 호출하여 필요한 플랫폼 구성 옵션을 구성하는 변환 정책을 포함할 수 있다. SLO 변 환 기능은 인터페이스를 사용하여 등록된 기능의 데이터베이스에 포함될 수 있다. 파라미터가 인터페이스를 통해 구성된 후에, 대응하는 SLA/SLO가 있는 워크로드가 제 1 위치의 하드웨어로부터 제 2 위치의 하드웨어로 이동되었다는 표시가 수신될 수 있다. 소스 하드웨어 정보 및 대응하는 SLA/SLO 정보가 분석될 수 있고 실행을 위해 변환 기능이 선택될 수 있다. 실행시, 변환 기능은 제 2 위치의 하드웨어가 SLA 요구 사항 내에서 동작하거나 SLO를 준수하도록 구성할 수 있다. 따라서, SLA는 워크로드가 에 지 네트워크 전체에서 이동하는 동안 충족될 수 있다. (이러한 워크로드는 서비스 상태, 데이터 및 실행과 관 련되고 일정 레벨의 SLA를 가질 수 있는 된 임의의 요소를 포함할 수 있다). 에지 컴퓨팅 환경(예를 들어, 에지 클라우드 및 구현 시스템 및 디바이스)에서 SLO를 변경하도록 에지 기 능을 구현하는 제 1 예시적인 방법(예 W1)은 (예를 들어, 노드 또는 디바이스(2200, 2232, 2240 또는 2250)에서 또는 그에 의해 구현되는) 처리 회로를 사용하여 수행되는 방법으로서, 방법은, 에지 네트워크 상에서 실행될 워크로드에 대한 소스 플랫폼 정보를 수신하는 단계; 소스 플랫폼 정보에 기초하여 워크로드의 실행을 위한 타 겟 컴퓨팅 노드를 결정하는 단계; 에지 네트워크에 대한 변환 데이터 소스로부터 변환 기능을 획득하는 단계; 변환 기능 및 워크로드에 대한 서비스 레벨 협약을 사용하여 타겟 컴퓨팅 노드의 파라미터를 구성하는 단계; 및 워크로드를 실행을 위해 타겟 컴퓨팅 노드에 송신하는 단계를 포함한다. 제 2 예(예 W2)에서, 예 W1의 주제는, 소스 플랫폼 정보가 소스 플랫폼 그룹의 적어도 하나의 멤버 또는 소스 자원을 포함하는 구성을 포함한다. 제 3 예(예 W3)에서, 예 W1-W2의 주제는, 서비스 레벨 협약이 서비스 레벨 목표를 포함하는 구성을 포함하고, 타겟 컴퓨팅 노드의 파라미터를 구성하는 단계가 변환 기능을 서비스 레벨 목표에 적용하여 파라미터에 대한 값 을 결정하는 단계를 포함한다. 제 4 예(예 W4)에서, 예 W1-W3의 주제는, 소스 컴퓨팅 노드로부터 타겟 컴퓨팅 노드로 서비스를 마이그레이션하 기 위한 요청을 수신하는 단계; 서비스에 대한 처리 어드레스 식별자를 결정하는 단계; 소스 컴퓨팅 노드에 대 한 자원 리스트 및 대응하는 서비스 레벨 협약 및 소스 컴퓨팅 노드의 플랫폼 유형을 식별하는 단계; 및 소스 컴퓨팅 노드의 플랫폼 유형 및 서비스 레벨 협약에 기초하여 타겟 컴퓨팅 노드를 구성하는 단계를 포함한다. 제 5 예(예 W5)에서, 예 W4의 주제는, 구성된 타겟 노드를 서비스에 등록하는 단계를 포함한다. 다양한 설정에서, 예 W1-W5(및 SLO 관리의 다른 양태)는 정의된 애플리케이션 프로그래밍 인터페이스 또는 인터 페이스 사양; 메시징, 원격 측정 데이터 포맷 또는 원격 측정 정의의 사용; 해석학; 및 에지 컴퓨팅 환경 내에 서 SLO를 마이그레이션하거나 구성하기 위한 정책 및 로직의 다른 사용 및 구현의 결과로서 관찰되거나 모니터 링될 수 있다. 예 W1-W5 및 이러한 서비스 레벨 변경 동작의 다른 양태는 또한 (예를 들어, FaaS 또는 EaaS 설 정의 서비스에 대해 정의된 SLO에서) 서비스 동작 및 서비스 기능의 결과로서 관찰되거나 구현될 수 있다. 또 한, 예 W1-W5의 방법은 에지 컴퓨팅 시스템에서 (예를 들어, 명령어가 실행될 때 방법을 수행하는 머신 판독 가 능 매체와 함께) 구현된 명령어로서 또는 (예를 들어, 방법을 수행하거나 달성하기 위한 구성을 포함하는 디바 이스와 함께) 구현된 하드웨어 구성으로서 제공될 수 있다. 따라서, 예 W1-W5의 특징(및 예 V1-V10에서 제안된 것을 비롯한 서비스 레벨 목표 또는 계약 관리의 다른 특징)은 시스템 오케스트레이터 또는 설계자에 의해 조정 되거나 설계된 대로, 본 명세서의 임의의 다른 예와 결합되어 에지 클러스터 또는 에지 클라우드 시스템을 구성 할 수 있다. 데이터 중심 오케스트레이션(Data-Centric Orchestration)의 예 예에서, 에지 컴퓨팅은 저 지연시간 또는 고 대역폭을 요구하는 실시간, 일반적으로 상호작용하는 네트워크 에 지 컴퓨테이션에 적응된 클라우드 컴퓨팅의 한 형태로 특징지을 수 있다. 이러한 요구를 충족하기 위해, 에지 컴퓨트 노드는 일반적으로 최종 디바이스(예를 들어, 자원이 데이터에 더 가깝게 이동되기 때문에, 에지 디바이 스, 에지 노드, 소비자 등)에 (예를 들어, 물리적으로, 적은 수의 네트워크 홉 등을 통해) 가깝게 위치된다. 최종 디바이스와의 이러한 분산된 근접성은 일반적으로 제한된 전력, 컴퓨트 속도, 스케일 또는 스토리지 용량 을 가진 에지 디바이스로 귀결된다. 하나의 예시적인 배치에서, 에지 노드는 \"에지렛(edgelet)\"이라고도 지칭 될 수 있는 \"박스 내 클라우드 서비스(cloud service in a box)\"의 유형인 클라우드렛의 특정 에지 기반 분산 실행을 가능하도록 적응될 수 있다. 이러한 컨텍스트에서, 클라우드렛은 전통적으로 클라우드에서 수행되지만 에지에 더 가깝게 이동하고 데이터 소 비자 또는 고객에게 더 로컬인 에지 환경에 배치되는 노드 또는 기능의 그룹이다. 추론은 일반적으로 에지 기 능으로 간주될 수 있는 에지 노드 또는 기능의 그룹이지만 클라우드 하드웨어에서 동작하거나 (위에서 논의된 에지 노드 배열과는 잠재적으로 다를 수 있는) 종래의 클라우드 컴퓨팅 요소를 사용할 수 있는 에지렛이다. 따 라서, 다음의 많은 예에서, 클라우드렛과 에지렛은 동일한 요소를 지칭하고, 특정 작업을 완료하거나 명시된 서 비스를 제공하도록 배열된 가용 기능의 정의된 서브세트인 동일한 일반 속성을 공유한다. 또한, 그룹화를 위해정의되고 달성된 기능은 클라우드렛 또는 에지렛 간의 명명법의 선택보다 더 관련성이 있다. 일반적으로, 클라우드렛의 목적은 에지에서, 전형적으로는 클라우드 또는 데이터 센터 환경의 에지에서, 고도의 상호작용 모바일 애플리케이션의 서비스에서, 이산 컴퓨팅 자원을 제공하는 것이다. 본 명세서에 사용되는 \"클 라우드렛\" 및 \"에지렛\"이라는 언급은 본 명세서에서 논의된 아키텍처 및 구성을 사용하여, 에지 컴퓨팅 설정에 서 (종종 CO에서 또는 에지 컴퓨팅 장치에서) 클라우드형 컴퓨팅 서비스의 제한된 규모의 구현을 지칭한다. 에지 컴퓨팅 시스템(예를 들어, 에지 클라우드 및 도 3 내지 도 22d에 도시된 에지 컴퓨팅 시스템 구성)에 적용 가능한 예에서, 클라우드렛은, 최하위 계층이 최종 디바이스이고, 그 다음이 클라우드렛이고, 그 다음이 계층의 최상위 레벨에 있는 클라우드인 3 단의 계층의 중간 계층에서 실행된다. 일반적으로, 모바일 디바이스 가 이동함에 따라, 컴퓨테이션 백엔드는 또한 (예를 들어, 더 나은 지역성을 위해) 워크로드를 제 1 기지국에 있는 클라우드렛으로부터 제 2 기지국에 있을 수 있는 다른 클라우드렛으로 이전함으로써 이동할 수도 있다. 이러한 시나리오에서, 클라우드 기반의 다음 계층 백엔드가 유지되고 지연시간에 덜 민감하지만 더 많은 컴퓨트 집약적인 작업을 지원할 수 있다. 따라서 클라우드렛은 전통적인 클라우드의 전형적인 통신 및 통합된 스케줄 링으로 인한 지연시간을 유발하지 않고 컴퓨테이션 요구 작업을 받아들인다. 모바일 애플리케이션을 서빙하는 클라우드렛에 있는 가상 머신(Virtual Machine)(VM) 또는 컨테이너는 모바일 디바이스가 제 1 에지 노드로부터 제 2 에지 노드로 (예를 들어, 제 1 기지국으로부터 제 2 기지국으로) 이동할 때 다음 에지 노드의 다른 클라우 드렛으로 마이그레이션되는 경우가 자주 있다. 클라우드렛 서비스를 이동하는 사용자 장비(UE)(예를 들어, 모바일 폰, 태블릿, 다른 최종 디바이스)에 근접하 게 유지하기 위해 클라우드렛 서비스 처리를 하나의 에지 노드 또는 중앙국(CO)으로부터 다른 노드로 마이그레 이션하면 지연시간이 감소될 수 있고, 이것은 또한 클라우드렛 계층 내에서 상당한 데이터 이동이 발생할 수도 있다. 데이터 이동과 함께, 에지 인프라스트럭처는 특히, 데이터 집결 및 입력-출력(IO) 오버헤드, 또는 (예를 들어, 마이그레이션이 단계별로 수행되는) 단계적 마이그레이션 동안 데이터의 분산된 일관성을 유지함으로써 도출되는 오버헤드와 같은 추가 불이익을 초래할 수 있다. 데이터 및 대응하는 오버헤드를 마이그레이션하면 통신 인프라스트럭처에 부담이 증가하여 베이스라인을 넘어 부하를 가할 수 있다. 이러한 영향은 이동성이 지 배적인 사용이 되고 에지 생태계에 새로운 데이터 집약적 서비스가 등장함에 따라 통신 인프라스트럭처를 구축 하고 확장하는 데 종종 많은 비용이 들기 때문에 중요할 수 있다. 데이터 센터 클라우드와 함께, 에지 클라우드는 종종 최신 마이크로 서비스 아키텍처를 수용하며 - 여기서 모놀 리식 애플리케이션 로직은 단순하고 느슨하게 결합된 마이크로 애플리케이션의 집합으로 리팩토링된다. 여기서, 클라우드렛의 빈번한 마이그레이션은 다수의 마이크로 서비스에 걸쳐 공유되고 일관되게 유지되는 상태 의 마이그레이션을 증폭시키는 결과를 가져올 수 있다. 이러한 공유가 하이퍼 컨버즈드 스토리지(hyper- converged storage) 또는 분산 데이터 관리 아키텍처에 의해 촉진되는 데이터 센터 클라우드와 달리, 에지 인프 라스트럭처는 클라우드렛 간의 상대적으로 제한된 대역폭에서 더 중요하고 비용이 많이 드는 통신 트래픽을 발 생시키는 경향이 있다. 포그와 같은 네트워크 및 서비스 설치의 출현에도 불구하고, 위의 문제는 현재 솔루션에서 대체로 해결되지 않 았다. 기지국 간의 UE 마이그레이션이 일반적인 반면, 일반적으로 마이그레이션되는 것은 많지 않다. 대신에 많은 네트워크 서비스는 서비스를 마이그레이션하는 역량을 제한하는 하드웨어 어플라이언스에 의해 전달되거나, 또는 네트워크 서비스는 클라우드 내에서만 유지되어 종종 지연시간이 증가한다. 비디오 스트리밍 서비스와 같은 일부 콘텐츠 데이터 네트워크(CDN)는 디바이스 근처에 데이터를 함께 배치하지만, 이러한 에지 서비스는 미디어 인코딩 또는 트랜스코딩 이상의 많은 양의 컴퓨트; 다른 활동성과 같이 하나의 에지 노드로부 터 다른 에지 노드로의 상태 전송에 의존하지 않는 활동성을 필요로 하지 않는다. 증강 현실(AR) 또는 가상 현 실(VR)과 같은 새로운 사용은 주어진 현재 아키텍처가 기량 발휘를 못하게 할 것 같다. 하드웨어 집약적인 네트워크 특화된 솔루션은 현재의 아키텍처에서 확장되지 않으며 생태계의 다른 요소와의 상 호운용성의 문제에 직면한다. 몰입형 데이터 집약적 컴퓨트의 제공자는 일반적으로 에지 자체를 데이터 생성 또는 소비 지점에 가깝게 이동하려고 하지만, 일반적인 사용에는 광범위한 고객 네트워크에 걸쳐 높은 대역폭의 지속적인 가용성이 필요하기 때문에, 유비쿼터스 배치를 위한 확장 가능 인프라스트럭처를 생성하는 복잡성과 비용으로 인해 실패하는 경우가 많다. 이러한 문제 중 일부를 해결하기 위해, 에지 컴퓨팅 시스템 사이의 클라우드렛 또는 분산된 유사 애플리케이션 및 서비스의 지능형 오케스트레이션을 위한 장치 및 기술이 설명된다. 이러한 요소는 상이한 에지 클라우드 기 반 애플리케이션(예를 들어, 마이크로 서비스 애플리케이션)의 상이한 민감도에 적응적이다. 예에서, 클라우드렛은 데이터 중력 메트릭(data gravity metric)에 따라 데이터 집약적 컴퓨트 동작을 유지하면서 디바이스 이동 에 따라 지연시간 민감성 사용자 인터페이스(User Interface)(UI) 상호작용을 마이그레이션하기 위해 다른 클라 우드렛을 프록시한다. 도 58은 최고 레벨의 클라우드 환경(예를 들어, 클라우드), 중간 레벨의 클라우드렛(예를 들어, (5820 또 는 5822)), 최저 레벨의 모바일 디바이스(예를 들어, 디바이스(5830 또는 5832))를 갖는 3 레벨의 계층을 도시한다. 전형적으로, 클라우드렛(5820, 5822)은 최종 디바이스(5830, 5832)로부터 낮은(예를 들어, 1 또는 2 홉) 지연시간을 위해 배치된다. 예에서, 클라우드렛(5820, 5822)은 디바이스가 기지국 A에 가까운 위치로부터 기지국 B에 가까운 제 2 위치로 이동하면 기지국 A로부터 다른 기지국 B로 마이그레이션할 수 있다. 도 59는 클라우드렛 서비스 마이그레이션의 예를 도시한다. 도시된 바와 같이, 기지국 A의 클라우드렛 및 기지국 B의 클라우드렛은 백엔드 클라우드 인프라스트럭처로부터 등거리에 있는 것으로 추정된다. 이것은 임의의 기지국의 클라우드렛이 클라우드로의 액세스의 큰 변동없이 동작(예를 들어, 컴퓨트, 데이터 요청 등)을 백엔드 클라우드로 에스컬레이션할 수 있으므로 확장 가능한 동작을 가능하게 할 수 있다. 도 60은 부분적인 클라우드렛 서비스 마이그레이션의 예를 도시한다. 도 59의 예에 이어서, 도 60은 모 바일 컴퓨트 동작을 위한 데이터 양(예를 들어, 데이터 중력)에 민감도가 있는 마이그레이션을 도시한다. 따라 서 데이터 중력이 높으면(예를 들어, 데이터의 양이 많으면), 클라우드렛을 기지국 A로부터 기지국 B(클 라우드렛)로 마이그레이션하거나 또는 데이터를 기지국 A으로부터 클라우드 백엔드(도시되지 않음)로 마 이그레이션하면, 높은 대역폭 사용 또는 요구 사항이 발생할 수 있지만 데이터 이전으로 인해 아마도 긴 지연시 간이 크게 늘어날 수 있다. 고 중력 데이터를 이전하는 대신에, 기지국 A는 데이터를 유지하면서 기지국 B의 마이그레이션된 클라우드렛은 데이터와의 상호작용을 프록시하도록 작동한다. 이것은 디바이스 이동에 따른 지 연시간에 민감한 UI 상호작용의 마이그레이션을 가능하게 하지만, 데이터 집약적인 컴퓨트 동작은 데이터 중력 에 따라 기지국에서 \"스티키(sticky)\"되는 경향이 있다. 도 61은 클라우드렛에서 수평 프록싱의 예를 도시한다. 여기에서, 피어-투-피어(예를 들어, 클라우드렛- 투-클라우드렛) 프록싱은 (예를 들어, 기지국 A의 클라우드렛으로부터 기지국 B의 클라우드렛으로 마이그레이션을 위해) 수평 및 수직 프록싱 둘 모두로 확장된다. 여기서, 수평 프록싱은 클라우드렛이 일부 동 작을 참여 디바이스에 미리 설치된 프록시에 다시 푸시할 수 있도록 함으로써 동작할 수 있다. 이 프록시는 클 라우드렛으로부터 동작을 수신하고 이러한 동작을 로컬에서 실행하도록 구성된다. 예를 들어, 충분히 가능한 기지국은 미리 설치된 딥 러닝 추론 스택뿐만아니라 UE로부터의 데이터를 가질 수 있다. UE는 로 컬 실행을 위해 UE에 다운로드된 기능 또는 과중한 데이터 서브세트를 포함할 수 있다. 여 기서, 클라우드렛은 음성 객체, 이미지 또는 비디오 객체 등과 같은 데이터 집약적 입력이 클라우드렛(5910, 5920)으로 이동될 필요가 없도록 다양한 추론 동작을 프록시에 푸시할 수 있다. 수직 프록시에 의하면, 데이터 집약적 동작은 클라우드렛(5910, 5920)에서 로컬로 실행되는 부분으로 분할되어 예를 들어, 데이터로부터 키 특징을 로컬로 추출한 다음 클라우드 백엔드로 키 기능을 전송할 수 있고, 이곳에 서 추출된 특징 또는 과거 컨텍스트 데이터에 대해 연산 집약적인 동작이 실행되어 정제된 추론을 생성할 수 있 다. 예를 들어, 클라우드렛(5910, 5920)은 문자 인식, 이미지 특징 인식 등을 수행할 수 있지만, 그런 다음에 는, 특히 다중 모드 추론 작업에서, 그의 특징을 다른 처리가 모호성을 줄이고 문자를 단어, 단어에서 문장으로 그리고 그 의미로 매핑하도록 수행될 수 있는 컴퓨테이션적으로 더 풍부한 클라우드 백엔드로 포워딩할 수 있다. (예를 들어, 도 58 내지 도 60에서 위의 오프로딩 및 마이그레이션 동작에서 논의된 바와 같이) 클라우드렛 (5910, 5920)에서 프록시할 동작과 피어 클라우드렛(5910, 5920)에서 수행하거나 백엔드 클라우드로 푸시할 동 작에 대한 동적 결정은 데이터 중력 정책에 의해 추진될 수 있다. 이러한 데이터 중력 정책은 동적일 수 있다. 예에서, 데이터 중력 정책은 클라우드렛(5910, 5920)을 지원하는 하드웨어 플랫폼의 스토리지 및 메모리 용량과 처리량에 기초한다. 예에서, 정책은 채널 보안에 기초한다. 예에서, 정책은 처리량 또는 지연시간에 기초한다. 예에서, 정책은 기지국 소유 또는 컴퓨테이션 및 통신 비용에 기초한다. 보안 컨텍스트에서, 도 58 내지 도 60를 참조하면, 인프라스트럭처 관리자는 모바일 디바이스 또는 테넌트 VM 격리 및 제어를 위한 LSM 시행 포인트를 제공할 수 있다. 클라우드 데이터 캐시는 클라우드 엔티티 특정 정책 을 포함하는 LSM에 의해 제공될 수 있다. 캐시된 클라우드 콘텐츠로의 액세스는 OS(또는 한쪽이 테넌트 지향 LSM 정책을 적용하고 다른 쪽이 클라우드 지향 LSM 정책을 적용하는 분기된 인프라스트럭처 관리자)에 의해 시행될 수 있다. 마이그레이션 및 정책 시행과 연루된 다른 컴포넌트도 또한 LSM 시행 포인트를 제공할 수 있다. 추가 예에서, 에지 컴퓨팅 시스템에서 오케스트레이션을 위한 다양한 유형의 결정은 다른 엔티티에 위임되고 오 프로드될 수 있거나, 또는 다른 엔티티로부터 이용 가능한 정보에 기초할 수 있다. 예를 들어, 오케스트레이터 A가 다른 시스템을 선택하여 워크로드 또는 다른 에지 처리 작업 또는 서비스를 오케스트레이션하는 제 1 시나 리오를 고려한다. 오케스트레이터 A는 정보를 수집하여 시스템을 선택하기 위해 한 세트의 에지 오케스트레이 터 시스템(또는 서브 시스템)에 연결한다. 그 다음, 오케스트레이터 A는 이 정보를 평가하고 오케스트레이션 작업을 위임하고 오프로드할 최적의 후보를 선택할 수 있다. 또한, 오케스트레이터 A가 다른 오케스트레이터(오케스트레이터 B)에 의해 관리되는 시스템(시스템 B)상의 작업 을 오케스트레이션하려는 제 2 시나리오를 고려한다. 여기서, 오케스트레이터 A는 시스템 B의 오케스트레이터 (오케스트레이터 B)에게 전송하여 특정 오케스트레이션 정책에 따라 작업 또는 서비스를 스케줄링할 것을 요청 한다. 오케스트레이터 A는 정책 및 (SLA, SLO 등과 같은) 다른 요구 사항을 제공할 수 있다. 이러한 오케스트레이션 위임은 또한 시스템 B의 자원을 사용하기 위해 시스템 A의 권한을 이전하는 방법을 사용 하여 구현될 수 있다. 예를 들어, 이러한 위임은 실행될 요청; 오케스트레이션 A가 서비스를 실행하기 위해 시 스템 B에 제공하는 특권; 및 서비스를 실행하는데 필요한 임의의 다른 정보에 대한 인증을 제공하는 시스템 B에 인증된 요청을 전송할 때 제공될 수 있다. 또 다른 예에서, 이러한 오케스트레이션 위임은 (예를 들어, ETSI MEC 사양과 호환되는 바와 같이) MEC 시스템 배치 내에서 구현될 수 있다. 그 정보는 (예를 들어, ETSI MEC 사양에서 정의된) MEO-대-MEO 참조 지점 (reference points)과 같은 다양한 MEC 참조 지점(인터페이스)를 사용하여 식별되고 교환된다. 데이터 중심 오케스트레이션을 구현하기 위한 제 1 예시적인 방법(예 X1)은 (예를 들어, 노드 또는 디바이스 (2200, 2232, 2240 또는 2250)에서 또는 그에 의해 구현된) 처리 회로를 사용하여 에지 컴퓨팅 시스템(예를 들 어, 에지 클라우드 및 구현 시스템 및 디바이스는)에서 수행되는 방법으로서, 방법은, 제 1 클라우드렛에 서 클라우드렛 마이그레이션 신호를 수신하는 단계; 제 1 클라우드렛의 컴퓨테이션 컴포넌트를 분석하여 데이터 중력 메트릭을 생성하고; 제 1 컴포넌트에 대한 제 1 데이터 중력 값이 임계치 미만인 것에 응답하여 제 1 컴포 넌트를 제 2 클라우드렛으로 이동시키는 단계; 제 2 컴포넌트에 대한 제 2 데이터 중력 값이 임계치 초과인 것 에 응답하여 제 2 컴포넌트를 제 2 클라우드렛으로 이동하는 것을 삼가는 단계; 및 제 2 컴포넌트에 대한 인터 페이스를 제 2 클라우드렛에 제공하는 단계를 포함한다. 제 2 예(예 X2)에서, 예 X1의 주제는 제 1 클라우드렛이 제 1 기지국에 있고, 제 2 클라우드렛이 제 2 기지국에 있는 구성을 포함한다. 제 3 예(예 X3)에서, 예 X2의 주제는 클라우드렛 마이그레이션 신호는 제 1 기지국으로부터 제 2 기지국으로의 사용자 장비의 핸드 오프에 응답하는 것을 포함하며, 여기서 사용자 장비는 핸드 오프 전에 제 1 클라우드렛의 서비스를 사용하고 있다. 제 4 예(예 X4)에서, 예 X1 내지 X3의 주제는, 데이터 중력이 제 2 컴포넌트에 의해 사용되는 데이터의 크기에 기초하는 것을 포함한다. 제 5 예(예 X5)에서, 예 X4의 주제는, 데이터 중력이 또한 데이터 크기의 컴퓨테이션에 기초하고, 컴퓨테이션이 데이터를 제 2 클라우드렛으로 이동할 자원의 카운트 또는 데이터를 제 2 클라우드렛으로 이동하는 비용 중 적 어도 하나인 것을 포함한다. 제 6 예(예 X6)에서, 예 X1-X5의 주제는, 에지 컴퓨팅 시스템 내의 오케스트레이션이 제 1 오케스트레이터로부 터 제 2 오케스트레이터로의 위임에 응답하여 발생하는 것을 포함한다. 제 7 예(예 X7)에서, 예 X6의 주제는, 오케스트레이션이 제 1 오케스트레이터로부터 제 2 오케스트레이터로 전 달된 오케스트레이션 정책에 따라 발생하는 것을 포함한다. 다양한 설정에서, 예 X1-X7(및 데이터 중심 오케스트레이션의 다른 양태)은 정의된 애플리케이션 프로그래밍 인 터페이스 또는 인터페이스 사양; 메시지 포맷, 원격 측정 데이터 또는 정의의 사용; 분석 및 테스트; 및 에지 컴퓨팅 환경 내에서 오케스트레이션에 대한 정책 및 논리의 다른 사용의 결과로서 관찰되거나 모니터링될 수 있 다. 예 X1-X7 및 이러한 오케스트레이션 기술의 다른 양태는 또한 (예를 들어, FaaS 또는 EaaS 설정에서 서비 스로서 제공되는 클라우드렛을 위한) 서비스 동작 및 서비스 기능의 결과로서 관찰되거나 구현될 수도 있다. 또한, 예 X1-X7의 방법은 에지 컴퓨팅 시스템에서 (예를 들어, 명령어가 실행될 때 방법을 수행하는 머신 판독가능 매체와 함께) 구현된 명령어 또는 (예를 들어, 방법을 수행하거나 달성하는 구성을 포함하는 장치와 함께) 구현된 하드웨어 구성으로서 제공될 수 있다. 보안 백엔드 데이터 공유(Secure Backend Data Sharing)의 예 위에서 논의된 바와 같이, 에지 컴퓨팅 시스템의 에지 컴퓨팅 노드(예를 들어, 에지 클라우드 및 도 3 내 지 도 22d에 도시된 에지 컴퓨팅 시스템 구성)는 클라우드렛(또는 에지렛)을 운영하도록 구성될 수 있으며, 클 라우드렛은 고도의 상호작용 모바일 애플리케이션의 서비스시 에지에 컴퓨팅 자원을 제공하도록 구성된다. 예 에서, 클라우드렛은 최하위 계층은 최종 디바이스이고, 그 다음에는 클라우드렛이고, 계층의 최상위 레벨에는 클라우드가 있는 3단 계층에서 중간 계층 역할을 한다. 일반적으로, 모바일 디바이스가 이동함에 따라, 컴퓨테 이션 백엔드는 (예를 들어, 더 나은 지역성을 위해) 워크로드를 제 1 기지국에 있는 클라우드렛으로부터 제 2 기지국에 있을 수 있는 다른 클라우드렛으로 이전함으로써 이동할 수도 있다. 이러한 시나리오에서, 클라우드 기반의 다음 계층 백엔드가 유지되고, 지연시간에 덜 민감하지만 컴퓨팅 집약적인 작업을 지원할 수 있다. 따 라서 클라우드렛은 종래의 클라우드에서 일반적인 통신 및 통합된 스케줄링으로 인한 지연시간을 유발하지 않고 컴퓨테이션을 요구하는 작업을 받아들인다. 모바일 디바이스가 제 1 기지국으로부터 제 2 기지국으로 이동할 때 모바일 애플리케이션을 서빙하는 클라우드렛에 있는 가상 머신(VM) 또는 컨테이너가 다음 기지국에 있는 다 른 클라우드렛으로 마이그레이션되는 경우가 빈번하다. 하나의 기지국으로부터 다른 기지국으로의 워크로드(예를 들어, 작업, 애플리케이션, 서비스, 가상 머신, 컨테 이너 등) 마이그레이션은 일반적으로 기지국 간에 데이터(예를 들어, 상태)를 이전하는 것을 포함한다. 마이그 레이션 데이터 이전은 항상 비공개 통신 채널(예를 들어, 클라우드렛의 사업자에 의해 제어되거나 보호되는 채 널)을 통해 발생하지 않을 수 있다. 이러한 경우, (예를 들어, 보안 소켓 계층(Secure Socket Layer)(SSL) 터 널 등을 통해) 암호화를 이용하여 데이터를 보호하는 것이 전형적이다. 일부 워크로드는 큰 정적 데이터 풋 프린트를 갖지만 더 적은 동적 데이터 풋 프린트를 갖는다. 이러한 경우, 동적 데이터에서 데이터 액세스의 패턴은 미리 알 수 없다. 이러한 조건은 지연시간 문제로 이어질 수 있다. 예를 들어, 데이터가 대량으로 이전되면, 마이그레이션 도중에 모든 데이터는 보안(예를 들어, 암호화 및 복호 화)되어야 한다. 이로 인해 전체 데이터에 대해 암호화를 수행하는 것이 더 효율적일지라도 마이그레이션된 워 크로드를 계속하는데 데이터의 일부 또는 대부분이 필요하지 않기 때문에 마이그레이션에 상당한 처리 및 시간 오버헤드가 발생할 수 있다. 그러나, 데이터가 필요에 따라 단편적으로 전송되면, 각 전송은 암호화 및 복호화 의 추가 지연시간을 초래하지만, 데이터가 새로운 기지국에서 마이그레이션된 워크로드 처리를 계속할 필요가 없다면 훨씬 더 적은 총 이전을 초래할 수 있다. 일부 인프라스트럭처에서, 데이터 암호화 및 복호화는 (예를 들어, 네트워크 인터페이스 제어기(NIC) 내의) 특화된 하드웨어로 오프로드될 수 있을지라도, 제공자는 비싼 하 드웨어를 피해 비용을 절약할 수 있기 때문에 이러한 전용 암호화 하드웨어는 보편적으로 이용 가능하지 않다. 이것은 추가 하드웨어가 클라우드렛 인프라스트럭처에서 비용 또는 전력 요구 사항을 증가시킬 때 악화될 수 있 다. 또한, 통신 및 암호화에 사용되는 네트워크 프로토콜은 시간이 지남에 따라 변경될 수 있고 특정 하드웨어 기반 암호화 방식을 사용하면 새로운 프로토콜을 적시에 채택하는데 방해가 될 수 있기 때문에, 많은 제공자는 특화된 복호화 회로를 사용하지 않을 수 있다. 발생할 수 있는 추가적인 복잡화는 이동될 데이터가 제 1 클라우드렛 상의 스토리지에서 그 자체로 암호화된 상 태에 있는 상황을 포함한다. 이것은 데이터가 클리어 상태(예를 들어, 암호화되지 않은 상태)로 저장되면 에지 위치가 데이터 도난 시도에 더 취약하기 때문에 증가하는 추세이다. 물리적 디바이스가 보안되는 종래의 데이 터 센터에서는 일반적으로 문제가 되지 않는다. 따라서, 데이터 이전의 오버헤드는 (예를 들어, 저장을 위해) 키를 사용하여 스토리지 인터페이스에서 복호화 및 암호화할 필요성에 의해 복잡해질 수 있다. 따라서, 스토리 지 보안과 이전 보안을 둘 모두 해결하기 위해 과도하게 암호화될 수 있다. 위에서 언급한 시나리오에서 발생할 수 있는 과도한 오버헤드를 해결하기 위해, 워크로드 데이터는 저장을 위해 암호화된 다음 네트워크 이전을 위해 다시 암호화되지 않는다. 이중 암호화는 필요하지 않으며 클라우드렛의 스토리지 및 네트워크 양상의 결과는 본질적으로 그러한 수고를 조정하지 않는다. 예에서, 워크로드에 대한 타 겟을 마이그레이션할 가능성이 있는 클라우드렛에 스토리지 암호화 키를 분산하기 위해 워크로드의 궤도가 측정 된다. 예를 들어, 데이터(예를 들어, 동적 데이터)가 또한 측정되어 \"핫 스팟(hot spot)\"을 결정한다. 여기서, 핫 스팟은 워크로드 실행 동안 자주 참조되는 데이터를 의미한다. 저스트 인 타임 컴파일러 기술이 사 용되어 핫 스팟을 식별할 수 있다. 식별되면, 핫 스팟은 타겟 클라우드렛을 유사하게 마이그레이션하도록 사전 에 송신될 수 있다. 예에서, 데이터는 지연시간을 더 줄이기 위해 타겟 클라우드렛에서 사전 복호화된다.이러한 솔루션은 몇몇 흥미로운 양태를 포함할 수 있다. 첫째, 예에서, 송신된 데이터는 네트워크 송신을 위해 제 2 암호화-복호화 동작을 사용하는 대신에 저장을 위해 암호화된다. 둘째, 예에서, (예를 들어, 데이터 저장 에 사용된) 암호화 키가 데이터 공유자 간에 안전하게 공유된다. 셋째, 예에서, 가까운 장래에 참조될 가능성 이 가장 높은 핫 데이터를 예측하는 데 도움이 되는 데이터 및 표시자의 핫 서브섹션이 식별된다. 이 데이터는 사전에 이동하거나 복호화되어 지연시간을 줄일 수 있다. 넷째, 예에서, 클라우드렛 플랫폼은 다중 키 총 메모 리 암호화(multi-key total memory encryption)와 같은 암호화된 메모리(예를 들어, 스토리지가 아닌 작업 메 모리) 기술을 사용한다. 이것은 블록 스토리지(예를 들어, 디스크)로부터 작업 메모리로 이전될 때 데이터를 변환(예를 들어, 암호화 또는 복호화)하지 않아도 된다. 다섯째, 예에서, 데이터 집약적인 기능은 데이터를 기 능에 이동하는 대신 데이터에 이동된다. 여기서, 데이터를 갖는 클라우드렛까지 장거리 원격 절차 호출의 지연 시간은 데이터를 더 로컬 클라우드렛 쪽으로 이전하는 것보다 적다. 이러한 특징은 몇 가지 이점을 제공한다. 예를 들어, SSL 터널 등을 피하여 연결 지연시간을 줄인다. 또한, 안전한 노드 간 통신을 위해 미사용 데이터(data-at-rest) 보호가 활용된다. 되풀이 하면, 이것은 보안을 희생 하지 않고 클라우드렛 간의 상호작용의 지연시간을 줄인다. 도 62는 워크로드 컴포넌트 유형에 기초하여 클라우드렛 워크로드를 다수의 포워드 클라우드렛(예를 들어, 클라 우드렛 또는 클라우드렛)으로 이동시키는 예시적인 시나리오를 도시한다. 도시된 바와 같이, 모바일 디바이스는 클라우드렛에서 워크로드를 가지며 모바일 디바이스를 포워드 클라 우드렛(6215 및 6220)으로 반송할 궤적을 갖고 있다. 궁극적으로, 이러한 클라우드렛(6210, 6215 및 6220)은 클라우드에 의해 지원된다. 위에서 언급한 바와 같이, 도시된 시스템은 클라우드렛 간에 워크로드를 안전하게 마이그레이션하면서 지연시간 을 줄인다. 따라서, 보안 마이그레이션을 용이하게 하기 위해, 워크로드가 현재 실행 중인 클라우드렛에 의해 몇몇 동작이 수행된다. 이를 위해, 클라우드렛은 워크로드 데이터를 로컬 스토리지에 암호화된 형 태로 유지하도록 구성된다. 예에서, 이러한 암호화 규칙은 클라우드렛의 작업 메모리로 전달된다. 따라 서, 이 예에서, 데이터는 작업 메모리(예를 들어, 랜덤 액세스 메모리(RAM) 또는 상주 프로세서를 지원하는 캐 시)로부터 프로세서로 (예를 들어, 도 21a 내지 도 22d에 도시된 처리 자원 사이에서) 송신될 때만 암호화되지 않는다. 이러한 동일한 키가 블록 스토리지 내의 레스트(rest)에 암호화된 데이터를 유지하는데 사용될 수 있 도록, 워크로드 데이터의 로컬 암호화 유지를 용이하게 하기 위해, 클라우드렛은 하드웨어 구현 메모리 내 암호화-복호화에 사용되는 메모리 암호화 키를 교환하기 위한 인터페이스를 구현할 수 있다. 이러한 공유로 인해 데이터에 대한 소프트웨어 지향 사전 암호화 또는 사전 복호화를 수행하는 것이 불필요해진다. 클라우드렛은 암호화된 - 그러나 가능하게는 메시지 무결성 보호된 - 채널을 통해 워크로드에 대한 데이 터를 클라우드렛(6215 또는 6220)으로 송신하도록 구성된다. 이것은 암호화 및 복호화 오버헤드를 없애준다. 데이터는 로컬 스토리지에 있을 때 암호화되기 때문에, 추가로 암호화된 터널을 생성할 필요가 없다. 암호화 또는 복호화는 집약적인 작업일 수 있으므로, 클라우드렛 간 통신의 이러한 양상을 없애면 상당한 자원 절감을 가져올 수 있다. 예에서, 데이터를 변경하려는 임의의 시도를 드러내는 해시(예를 들어, 시그니처)를 전송함으 로써 데이터가 환승 중에 악의적으로 변경되지 않도록 보호된다. 해시는 원본(예를 들어, 암호화되지 않은, 플 레인텍스트(plaintext) 등) 콘텐츠에 대해 미리 연산되고 블록 세분화되어, 전송되는 블록 해시에 대해 제 2 레 벨 해시를 연산하는 것이 더 효율적이도록 하거나, 또는 모든 중개자가 변조를 위해 해시와 암호화를 둘 모두 리버스 엔지니어링해야 하므로 변조 방지가 가능하도록 할 수 있다. 예에서, 클라우드렛은 클라우드렛(예를 들어, 포워드 클라우드렛 또는 클라우드렛) 사이에 스토리지 보안 키(예를 들어, 로컬 스토리지 내의 워크로드 데이터를 암호화 또는 복호화하는데 사용되는 키)를 공유하도록 구성된다. 이것은 이러한 클라우드렛이 워크로드 마이그레이션 중에 송신될 스토리지 암호화 포맷 의 데이터에 액세스할 수 있게 한다. 예에서, 키 전송 기술은 스토리지 보안 키가 에지 전체에서 강력하게 보 호되는 키-값 스토어(예를 들어, 신뢰성 있는 실행 환경(trusted execution environment)(TEE))을 통해 공유되 고 업데이트되도록 보장하는 준비를 갖춘 아키텍처를 통해 동작한다. 예에서, 클라우드렛은 워크로드의 컴포넌트를 분석하여 다양한 클라우드렛에서 사전 전송, 사전 요청 또 는 사전 캐시할 데이터 요소를 식별하도록 구성된다. 이러한 분석은 JIT 컴파일러의 분석을 반영하여, 워크로 드에서 자주 사용되는 핫 스팟, 데이터 유형 또는 실행 유형을 식별한다. 그러나, 여기서 코드 섹션을 컴파일 하는 대신에, 클라우드렛은 이러한 컴포넌트를 사전에 이전한다. 예에서, 이러한 컴포넌트는 지연시간을 더 줄이기 위해 (예를 들어, 메모리에서) 사전에 복호화될 수 있다.워크로드 컴포넌트의 유형을 추가로 탐색하기 위해, 워크로드에서 작은 동적 및 정적 풋 프린트 사이의 분할을 고려할 수 있다. 컴퓨트 집약적이지만 동적 데이터 풋 프린트가 적은 이러한 동작(예를 들어, 더 많은 프로세 서 작업이 필요하지만 많은 집계 데이터에 액세스할 필요가 없는 컴퓨테이션)은 워크로드(예를 들어, VM 또는 컨테이너)가 클라우드렛으로부터 목적지 클라우드렛(예를 들어, 클라우드렛)으로 마이그레이션할 때 목적지 클라우드렛에서 수행된다. 그러나, (예를 들어, 액세스 패턴이 랜덤하기 때문에, 그리고 바이트/OP 비율이 매우 높은 경우에) 많은 양의 데이터에 대해 작동하는 이러한 컴퓨테이션은 소스에서 다시 핸들링된다. 따라서, 워크로드가 클라우드렛으로 마이그레이션되면, 데이터 집약적 동작은 데이터와 함께 클라우드렛 에서 유지된다. 그 컴포넌트가 클라우드렛에서 호출(예를 들어, 참조)되면, 원격 절차 호출 등이 클라우드렛으로 다시 행해져서 결과를 얻는다. 따라서, 예에서, 자주 액세스되는 데이터세트는 많이 이 동되지 않으므로, 이것은 대역폭과 지연시간을 모두 절약한다. 암호화 키를 안전하게 공유하고 사용하는 것과 관련하여, 키를 로컬에 (예를 들어, 작업 메모리와 스토리지 간 에) 공유하고 클라우드렛 간에 키를 공유하는 두 개의 양상이 대두될 수 있다. 일반적으로 공유의 보안은 키를 공유하여 암호화 키가 데이터 변환을 위해 암호화 키의 사용을 공유하는 사람들에게 직접 공개되지 않도록 하는 것을 수반한다. 이것은 복제된 키 값 스토어에 있는 명명된 데이터의 분산된 블록에 걸쳐 암호화 키를 유지함 으로써 수행될 수 있다. 암호화 키는 소유자의 자격증명에 의해 래핑(wrapped)(예를 들어, 서명 및 암호화)될 수 있다. 송신 소유자가 수신 당사자와 일부 데이터를 공유할 필요가 있을 때, 송신 소유자는 수신 당사자에게 서명된 토큰을 제공한다. 예를 들어, 서명된 토큰에 의해 수신 당사자는 키 값 스토어로부터 래핑된 키를 검색 하고 키를 복호화하고, 그 키를 그들의 하드웨어 메모리 암호화 키 세트에 설치할 수 있다. 이러한 암호 복호 화 및 설치는 시스템 서비스, 보안 엔클레이브(예를 들어, TEE) 또는 하드웨어 명령어에 의해 수행될 수 있다. 이러한 방안은 상이한 보안 강도를 갖지만 그러한 방안 간의 성능 차이는 눈에 띄지 않는다. 키를 보호하는 요소의 이러한 구성은 사용될 수 있는 몇몇 구성 중 하나이다. 다른 가능성은 암호화 키를 서로 이전하기 위한 엔티티 간의 강력한 상호 인증 기반 보안 채널을 포함할 수 있다. 일반적으로, 이러한 이전은 소규모이며, 따라서 데이터가 암호화되지 않고 데이터를 보호하는 키만 암호화되기 때문에 컴퓨테이션 비용이 많이 들지 않는다. 예를 들어, 복제된 키-값 스토어를 구현하는 노드(예를 들어, 클라우드렛)는 암호화 키를 서로 이전하거나 보안 시스템 런타임을 통해 메모리 암호화 캐퍼빌리티에 설치를 완료하기 위한 SSL 채널을 통 해 서로 그리고 클라우드렛에 연결될 수 있다. 위의 특징은 다음과 같은 동작 흐름에 통합될 수 있다. 하나의 클라우드렛(예를 들어, 클라우드렛)이 워 크로드(예를 들어, 컨테이너 또는 VM)를 다른 클라우드렛(예를 들어, 클라우드렛)으로 마이그레이션하는 프로세스를 시작할 때, 클라우드렛은 키 또는 래핑된 키를 제 2 클라우드렛으로 전송하고, 그 다음 에 키는 목적지 클라우드렛에 설치된다. 예측 엔진은 히트 맵 또는 과거 히스토리 기반 예측자를 평가하도록 호출되어 실행 과정에서 가장 터치할 가능 성이 높은 워크로드에서 데이터 블록의 이전을 요청하기 시작할 수 있다. 소스 클라우드렛의 최근 데이터 액세 스 이력과 데이터에 대한 장기간 인기(예를 들어, 히트 맵)는 어떤 콘텐츠가 목적지로 스트리밍될 수 있는지를 결정하는데 사용할 수 있는 두 개의 기술이다. 데이터에 필요한 보안 레벨에 따라, 블록은 다소 강력한 (또는 상이한) 암호화 방식을 사용하여 암호화될 수 있다. 그 다음, 목적지 클라우드렛은 공유 저장 키를 사용하여 데이터를 사전 복호화하거나, 데이터로의 데이터 액세스 요청이 발생할 때까지 대기하도록 선택하거나, 또는 (이용 가능한 경우) 메모리 암호화 시스템 복호화에 의존할 수 있다. 목적지 클라우드렛은 실행 중인 워크로드에 대해 로컬에 캐시된 모든 데이터를 갖지 않을 때를 추적할 표 시자를 유지한다. 따라서, 목적지 클라우드렛은 수행하려고 할 수 있는 각각의 작업마다 그 작업이 작업 당 바이트 메트릭에서 높은 것으로 식별되는지를 참고한다. 그러하다면, 원래 클라우드렛에게 이러한 작 업을 실행하기 위해 필요한 데이터를 전송할 것을 요청하는 대신에 원래 클라우드렛에게 원격 실행 메시 지를 전송하도록 선택할 수 있다. 동작 당 바이트 메트릭이 작으면(예를 들어, 임계치보다 작으면), 목적지 클라우드렛은 사전 예측 기반 프리페치 또는 사전 전송의 결과로서 데이터가 아직 도착하지 않은 한 필요한 데이터를 요청한다. 예에서, 이 러한 동작의 일부 또는 전부는 데이터를 사전에 또는 필요에 따라 투명하게 예측 및 이동하고 필요하면 사전에 데이터를 복호화하거나 암호화하는 데이터 사이드카를 통해 구현될 수 있다. 여기서, 데이터 사이드카는 통신 프록시를 확장하여 스토리지 기반 암호화된 데이터를 예측하고 소스로부터 목적지로 마이그레이션하는 작업을포함한다. 데이터 사이드카는 또한, 다른(예를 들어, 원격) 엔드의 기능이 데이터 집약적이면, 로컬 엔드의 기 능을 실행하여 로컬 엔드가 필요로 하는 가져올 데이터를 요청하는 대신에, 다른 엔드에서의 기능을 투명하게 실행할 수 있다. 에지 컴퓨팅 환경(예를 들어, 에지 클라우드, 및 구현 시스템 및 디바이스)에서 보안 백엔드 데이터 공유 를 구현하기 위한 제 1 예시적인 방법(예시 Y1)은 (노드 또는 디바이스(2200, 2232, 2240 또는 2250)에서 또는 그에 의해 구현되는) 처리 회로를 사용하여 수행되는 방법으로서, 방법은, 소스 클라우드렛의 로컬 데이터 스토 어에 있는 워크로드에 대한 데이터를 암호화하여, 암호화된 데이터를 생성하는 단계; 암호화된 데이터에 대한 키를 소스 클라우드렛으로부터 목적지 클라우드렛으로 이전하는 단계; 워크로드 마이그레이션 표시를 수신하는 단계; 워크로드 마이그레이션 표시에 응답하여 비 보안 채널을 통해 암호화된 데이터를 목적지 클라우드렛으로 송신하는 단계를 포함한다. 제 2 예(예 Y2)에서, 예 Y1의 주제는, 암호화된 데이터가 암호화된 데이터로서 로컬 데이터 스토어로부터 작업 메모리로 이전되는 구성을 포함한다. 제 3 예(예 Y3)에서, 예 Y2의 주제는, 데이터가 작업 메모리로부터 프로세서로 이전될 때 소스 클라우드렛이 전 체 메모리 암호화 회로를 사용하여 암호화된 데이터를 복호화하는 구성을 포함한다. 제 4 예(예 Y4)에서, 예 Y1-Y3의 주제는, 암호화된 데이터의 일부분이 워크로드 마이그레이션의 일부로서 이전 되지 않는 구성을 포함하며, 그 일부는 워크로드에 의한 데이터 사용을 프로파일링함으로써 결정된다. 제 5 예(예 Y5)에서, 예 Y1-Y4의 주제는, 클라우드렛이 예 X1-X7 및 동반하는 데이터 중심 오케스트레이션 예에 따라 구성되는 것을 포함한다. 다양한 설정에서, 예 Y1-Y4(및 안전한 데이터 공유의 다른 양태)는 정의된 애플리케이션 프로그래밍 인터페이스 또는 클라우드렛 인터페이스 사양; 데이터 통신 포맷 또는 정의의 사용; 및 에지 컴퓨팅 환경 내에서 데이터 통 신 및 관리에 대한 정책 및 로직의 다른 사용의 결과로서 관찰되거나 모니터링될 수 있다. 예 Y1-Y4 및 데이터 공유의 다른 양태는 또한 (예를 들어, FaaS 또는 EaaS 설정에서 서비스 간 또는 서비스 내에서 데이터 공유를 위한) 조정된 서비스 동작 및 서비스 기능 환경의 결과로서 관찰되거나 구현될 수 있다. 또한, 예 Y1-Y4의 방 법은 에지 컴퓨팅 시스템에서 (예를 들어, 명령어가 실행될 때 방법을 수행하는 머신 판독 가능 매체와 함께) 구현된 명령어로서 또는 (예를 들어, 방법을 수행하거나 달성하는 구성을 포함하는 장치와 함께) 구현된 하드웨 어 구성으로서 제공될 수 있다. 따라서, 예 Y1-Y4의 특징(및 데이터 공유 관리 및 운영의 다른 양태)은 시스템 오케스트레이터 또는 설계자에 의해 조정되거나 설계된 대로, 본 명세서의 임의의 다른 예와 결합되어 에지 클 러스터 또는 에지 클라우드 시스템을 구성할 수 있다. 에지 원격 측정 민주화(Democratization of Edge Telemetry)의 예 분산 아키텍처의 도전과제 중 하나는 테넌트가 언제든지 액세스할 수 있는 분산 에지 아키텍처에서 원격 측정을 사용하는 방법이다. 이러한 원격 측정은 원격 측정이 실제로 어디서 왔는지 증명하고 검증하는 방법에서 상당 한 변화가 있는, 분산 에지 아키텍처에서 테넌트가 보유한 서비스와 관련하여 생성될 수 있다. 본 명세서에서 설명된 시스템 및 방법은 에지 플랫폼이 인증된 방식으로 에지 서비스에 대한 원격 측정을 게시 할 수 있는 에지 컴퓨팅 시스템(예를 들어, 에지 클라우드 및 도 3 내지 도 22d에 도시된 에지 컴퓨팅 시 스템 구성)에서 분산된(그러나 조정된) 원격 측정 아키텍처를 사용한다. 에지 테넌트는 아키텍처에 걸쳐 분산 된 자신의 서비스에 액세스하거나, 발견하거나 또는 모니터를 추가할 수 있다. 테넌트는 원격 측정이 생성되는 방법과 시기를 검증할 수 있다. 아래에 설명되는 원격 측정은 에지 인식되고 조정된다. 도 63은 조정된 에지 시스템에서 분산 원격 측정을 위한 시스템을 도시한다. 시스템 다이어그램의 에지 시스템은 본 명세서에서 설명된 임의의 에지 시스템일 수 있다. 에지 시스템은 복수의 에지 노드(6306, 6308, 6310), 플랫폼, 서비스, 센서, 디바이스(예를 들어, 디바이스 ), 다른 원격 측정 서비스 등으로부터 데이터를 수신하는 원격 측정 서비스를 포함한다. 예에서, 원격 측정 서비스는 에지 시스템의 에지 노드(6306, 6308, 6310) 상에서 실행될 수 있다. 원격 측정 서 비스는 에지 노드(6306, 6308, 6310) 상에 저장될 수 있는 원격 측정 데이터를 수신한다. 원격 측정 데 이터의 스토리지는 에지 노드(6306, 6308, 6310)에 걸쳐 분산될 수 있다. 예를 들어, 에지 시스템 내의 에지 노드(6306, 6308, 6310)의 일부분은 원격 측정 데이터 스토리지 노드로서 작동할 수 있다. 또한, 이러한 원격 측정 데이터는 다중 테넌트 및 다중 사용자 속성에 따라 구성되거나 인덱싱되는 데이터와 함께 다중 테넌트 및다중 사용자 정보의 양상을 포함할 수 있다. 에지 시스템의 분산 에지 노드(6306, 6308, 6310)의 세트는 각각의 분산 에지 플랫폼이 플랫폼에서 실행되는 각 각의 서비스와 연관된 원격 측정을 게시할 수 있는 조정된 에지 원격 측정 인스턴스일 수 있다. 한 세트의 상 이한 에지 위치(예를 들어, 10 개의 기지국, 동일한 영역 내의 모든 기지국 등)는 각각의 기지국 및 그 기지국 에 연결된 임의의 디바이스에 연관된 원격 측정 서비스를 가질 수 있다. 에지 어플라이언스는 (LLC 미스, 메모리 BW, 테넌트 서비스 데이터, 메타데이터, 서비스와 관련된 메트릭 등과 같은) 특정 서비스를 위한 플랫폼으로부터 원격 측정을 전송할 수 있다. 원격 측정은 플랫폼의 로컬 인증서로 (또는 오케스트레이터 또는 유사한 엔티티에 의해 테넌트 인스턴스에 대해 원격 측정이 생성되면, 플랫폼 인증 서 및 테넌트 인증서로) 서명될 수 있다. 원격 측정은 예에서, 원격 측정을 검증하는 서비스의 인스턴스에 의 해 서명될 수 있다. 서비스는 (원격 측정 서비스 또는 에지 노드에 대한 txt/s와 같은) 서비스 원격 측정을 전 송할 수 있다. 예에서, 테넌트는 에지 원격 측정 서비스에 등록된 원격 측정 서비스에 액세스할 수 있다. 예를 들어, 테넌트 는 (예를 들어, 발견 요청을 특정 에지 원격 측정 서비스를 유지하는 에지 노드(6306, 6308, 6310)에 전송함으 로써) 특정 에지 원격 측정 서비스에 의해 어떤 서비스가 모니터링되고 있는지를 발견할 수 있다. 모니터링 서 비스를 통해, 테넌트는 또한 다른 원격 측정 서비스에 대한 다른 에지 어플라이언스에 의해 호스트 정보를 발견 할 수 있다. 모니터링 서비스는 다른 서비스에 원격 측정을 등록할 수 있다. 테넌트는 플랫폼 인증서(예를 들어, 원격 측정을 생성하는 플랫폼)에 기초하여 원격 측정 시그니처를 증명할 수 있다. 예에서, 테넌트는 원격 측정 데이터에 대한 서비스 시그니처를 사용하여 원격 측정 시그니처를 증명할 수 있다. 다른 예에서, 서비스는 테넌트 쿼리에 응답하여 원격 측정을 검증할 수 있다. 보안 컨텍스트로부터, 원격 측정 서비스 및 에지 호스팅 환경은 LSM 시행 포인트를 서빙할 수 있다. 에지 디바 이스는 (이를테면, 사용자가 LSM을 부정 변조할 수 없다고 가정하는 경우에) LSM 시행 포인트 역할도 할 수 있 다. 에지 인프라스트럭처 LSM이 디바이스 사용자 부정 변조로부터 보호되고 디바이스 사용자 LSM이 에지 인프 라스트럭처 조작으로부터 보호되는 LSM 시행의 분기가 있을 수 있다. 추가 예에서, 분산 에지 원격 측정 액세스 또는 저장을 위한 기술은 동작의 방법 또는 시퀀스를 포함할 수 있다. 기술은 에지 노드에서 복수의 플랫폼으로부터 원격 측정 데이터를 수신하는 제 1 동작을 포함하고, 원격 측정 데이터는 복수의 플랫폼의 각각의 플랫폼의 로컬 인증서로 서명된다. 예에서, 원격 측정 데이터의 적어도 일부는 다른 에지 노드(6306, 6308, 6310)로부터 수신된다. 에지 노드(6306, 6308, 6310)는 지역에 대한 복수 의 분산 에지 노드 중 하나일 수 있다. 기술은 에지 노드에서 원격 측정 데이터를 저장하는 동작을 더 포함한다. 기술은 서비스에 대응하는 원격 측정 데이터의 일부에 대한 요청을 테넌트 디바이스로부터 수신하는 동작을 더 포함한다. 예에서, 서비스에 대응하 는 원격 측정 데이터의 일부는 서비스에 의해 서명된다. 예에서, 요청은 원격 측정 서비스 시스템에 대한 https 요청을 포함할 수 있다. 요청은 클라우드 서버로 전송될 수 있고, 클라우드 서버에서는 테넌트 디바이스 로부터의 시그니처가 검증되어 액세스할 수 있게 한다. 기술은 또한 대응하는 로컬 인증서를 포함하는, 서비스에 대응하는 원격 측정 데이터의 일부를, 에지 노드 (6306, 6308, 6310)로부터 테넌트 디바이스(예를 들어, 디바이스)로 전송하는 동작을 포함한다. 예에서, 원격 측정 데이터의 일부를 전송하기 전에, 에지 노드는 테넌트 디바이스가 원격 측정 데이터의 일부에 액세스 할 수 있는 적절한 자격증명이 있다고 검증할 수 있다. 예에서, 테넌트 디바이스에 대한 응답은 JSON 응답을 포함할 수 있다. 기술은 에지 노드(6306, 6308, 6310)에서 에지 원격 측정 서비스를 실행하여 원격 측정 데이터를 수신 또 는 관리하는 동작을 포함할 수 있다. 기술은 에지 노드(6306, 6308, 6310)에 의해 모니터링되는 서비스에 대한 발견 요청을 테넌트 디바이스(예를 들어, 6304)로부터 수신하는 동작을 포함할 수 있다. 이에 응답하여, 에지 노드(6306, 6308, 6310)는 에지 노드(6306, 6308, 6310)에 의해 모니터링되는 서비스의 목록을 전송할 수 있다. 기술은 서비스로부터 서비스 원격 측정 데이터를 수신하는 동작을 포함할 수 있다. 에지 컴퓨팅 시스템(예를 들어, 에지 클라우드 및 구현 시스템 및 디바이스)에서 에지 원격 측정 민주화를 구현하기 위한 제 1 예시적인 방법(예 Z1)은 처리 회로를 사용하여 수행되는 방법으로서, (노드 또는 디바이스 (2200, 2232, 2240 또는 2250)에서 또는 그에 의해 구현된) 처리 및 통신 회로에 의해 수행되는 방법은, 에지 노드에서, 복수의 플랫폼으로부터 원격 측정 데이터를 수신 - 원격 측정 데이터는 복수의 플랫폼의 각각의 플랫폼의 로컬 인증서로 서명됨 - 하는 단계; 원격 측정 데이터를 에지 노드에 저장하는 단계; 테넌트 디바이스로부 터 서비스에 대응하는 원격 측정 데이터의 일부에 대한 요청을 수신하는 단계; 및 대응하는 로컬 인증서를 포함 하는, 서비스에 대응하는 원격 측정 데이터의 일부분을 에지 노드로부터 테넌트 디바이스로 전송하는 단계를 포 함한다. 제 2 예(예 Z2)에서, 예 Z1의 주제는, 에지 노드에서 에지 원격 측정 서비스를 실행하여 원격 측정 데이터를 수 신하는 단계를 포함한다. 제 3 예(예 Z3)에서, 예 Z1-Z2의 주제는, 테넌트 디바이스로부터, 에지 노드에 의해 모니터링되는 서비스에 대 한 발견 요청을 수신하고, 이에 응답하여 에지 노드에 의해 모니터링되는 서비스의 목록을 전송하는 단계를 포 함한다. 제 4 예(예 Z4)에서, 예 Z1-Z3의 주제는, 서비스에 대응하는 원격 측정 데이터의 일부분이 서비스에 의해 서명 되는 구성을 포함한다. 제 5 예(예 Z5)에서, 예 Z1-Z4의 주제는, 서비스로부터 서비스 원격 측정 데이터를 수신하는 단계를 포함한다. 제 6 예(예 Z6)에서, 예 Z1-Z5의 주제는, 원격 측정 데이터의 적어도 일부가 다른 에지 노드로부터 수신되는 구 성을 포함한다. 제 7 예(예 Z7)에서, 예 Z1-Z6의 주제는, 에지 노드가 지역에 대한 복수의 분산 에지 노드 중 하나인 구성을 포 함한다. 다양한 설정에서, 예 Z1-Z7(및 에지 원격 측정 조정의 다른 양태)은 정의된 애플리케이션 프로그래밍 인터페이 스 또는 인터페이스 사양; 원격 측정 데이터 포맷, 메시징 또는 정의의 사용; 및 에지 컴퓨팅 환경 내에서 원격 측정 데이터를 수집하고 통신하기 위한 정책 및 로직의 다른 사용 및 구현의 결과로서 관찰되거나 모니터링될 수 있다. 예 Z1-Z7 및 이러한 에지 원격 측정 사용의 다른 양태는 또한 (예를 들어, FaaS 또는 EaaS 설정에서 제공되는 서비스와 관련하여 생성된 원격 측정에 대한) 서비스 동작 및 서비스 기능의 결과로서 관찰되거나 구 현될 수도 있다. 또한, 예 Z1-Z7의 방법은 에지 컴퓨팅 시스템에서 (예를 들어, 명령어가 실행될 때 방법을 수 행하는 머신 판독 가능 매체와 함께) 구현된 명령어 또는 (예를 들어, 방법을 수행하거나 달성하는 구성을 포함 하는 장치와 함께) 구현된 하드웨어 구성으로서 제공될 수 있다. 따라서, 예 Z1-Z7의 특징(및 에지 원격 측정 수집 및 사용 예의 다른 특징)은 시스템 오케스트레이터 또는 설계자에 의해 조정되거나 설계된 대로, 본 명세 서의 임의의 다른 예와 조합되어 에지 클러스터 또는 에지 클라우드 시스템을 구성할 수 있다. 오케스트레이션된 로드 밸런싱(Orchestrated Load Balancing)의 예 엔터프라이즈/데이터 센터 클라우드의 전형적인 로드 밸런싱 접근 방식은 일반적으로 가용 전력, 가용 I/O 또는 메모리 대역폭 등과 같은 제약 조건 내에서 프로세서 활용도를 보장하기 위해 작업을 분산하려고 시도한다. 데 이터 센터 클라우드에서, 지연시간이 임계적이거나 높은 QoS 워크로드의 발판을 마련하는 것은 또한 인프라스트 럭처의 전용 부분 내에서 수행될 수 있다. 이러한 접근 방식은 일반적으로 에지 클라우드 인프라스트럭처에서 사용할 수 없다 - 에지 클라우드는 상대적으로 기본적인 자원을 가질 수 없을 뿐만 아니라 에지 클라우드는 훨 씬 더 복잡하고 시간에 따라 변화하는 수요 프로파일에 직면할 수 있다. 에지 클라우드 시스템은 또한 - 들어 오는 요청 속도가 다양하고 범위가 높고, 지연시간 또는 지터 허용 오차의 변동폭이 넓고, 서비스의 민첩성에 대한 소비자 기반의 예상 감도의 편차가 높은 - 매우 다양하고 일반적으로 예측할 수 없는 들어오는 작업 스트 림을 수신할 가능성이 높다. 제한된 유형의 로드 밸런싱 체계는 계층적 로드 밸런싱을 시도했지만 순수한 소프트웨어 관리를 사용하였다. 다음의 예는 하드웨어 제어 내에서 로드 밸런싱 양태를 제정하면서, 에지 컴퓨팅 시스템을 활용하여 다수의 에 지 노드에 QoS 정책을 구현하기 위한 추가 접근 방식을 제공한다. 이러한 유형의 계층적 로드 밸런싱 및 관리 는 오케스트레이션 오버헤드를 줄이고 에지 처리 시스템의 처리량을 늘리는데 도움이 될 수 있다. 다음의 로드 밸런싱 체계는 컴퓨트 자원을 데이터로 이동하거나 또는 데이터를 컴퓨트 자원으로 이동하는 고려 사항을 균형 맞추기 위해 에지 컴퓨팅 시스템(예를 들어, 에지 클라우드 및 도 3 내지 도 22d에 도시된 에 지 컴퓨팅 시스템 구성)의 인프라스트럭처 컴포넌트 내의 자원 사용을 구체적으로 개선한다. 이러한 방식은 저 레벨 자원 관리의 시간 변화 및 적응적 특화를 통해 에지 클라우드 인프라스트럭처 자체를 유연하게 만들어 자 원 할당 문제를 단순화할 수 있다. 이러한 특수화는 플랫폼 레벨에서 더 간단하고 요청 스트림 적응적 자원 조 달 태세를 가능하게 하여, 로드 밸런서가 분할 정복 접근 방식(divide and conquer approach)을 통해 의사 결정을 단순화할 수 있다. 다음의 로드 밸런싱 접근 방식에 의하면, 각각의 클라우드렛 또는 다른 에지 워크로드는 주어진 시간에 처리하 도록 적응될 수 있으며, 워크로드 요청의 전체적인 혼합이 변함에 따라 에지 컴퓨팅 노드가 동작 모드를 적응할 수 있는 경우일지라도 특정 동작 모드에 특화될 수 있다. 따라서, 하나의 시간에 클라우드렛 또는 다른 에지 워크로드는 중간의 드롭 퍼센트로 높은 처리량에 맞게 적응될 수 있고; 다른 시간에, 그 워크로드는 낮은 드롭 퍼센트로 더 높은 보안성 및 기밀성을 위해 적응될 수 있는 등 이런 식으로 적응될 수 있다. 에지 클라우드는 어떤 오브젝트에 대해 얼마나 많은 클라우드렛 또는 워크로드가 구성되는지를 변경함으로써 전반적인 서비스 상 태를 변경할 수 있다. 이것은 가변 개수의 노드 또는 노드에서의 클라우드렛이 요청 모집단의 특정 지배적 부 분을 높은 효율성으로 핸들링하도록 특화되고; 일부 자원이 특화되더라도, 노드는 전반적인 전체 서비스 용량이 고르지 않은 서비스의 아일랜드로 조각나지 않도록 다른 요청 유형에 (약간 낮은 효율성으로) 할당할 수 있다. 예에서, 에지 게이트웨이(또는 에지 클라우드렛 노드, 다른 컴퓨트 실행 노드)는 다수의 모드 중 하나에서 동작 한다. 이러한 모드는 예를 들어 표준 모드 \"S\", 처리량 최적화 모드 \"T\", 저 지연시간 및 저 지터 모드 \"L\" 등 을 포함할 수 있다. 예를 들어, 이 시나리오에서, 각각의 모드에 대해 다음의 정의가 설정될 수 있다. \"S\" 표준 모드: 95 백분위수 지연시간 <= N ns 이도록 처리량을 최대화한다. \"T\" 처리량 모드: 80 백분위수 지연시간 <= N ns 및 95 백분위수 지연시간 <= 5N ns 이도록 처리량을 최대화한 다. \"L\" 저 지연시간/지터 모드: 중간 지연시간 <= N/10 ns, 95 백분위수 지연시간 <= N ns 및 99 백분위수 지연시 간 <= 2N ns 이도록 처리량을 최대화한다. \"X\" 높은 보안 모드: 화이트리스트된 워크로드에 대한 중간 지연시간이 N ns 미만이도록 화이트리스트된 워크로 드의 처리량을 최대화한다. 따라서, 각각의 모드 정의를 사용하여, 에지 컴퓨팅 시스템의 자원은 더 높은 우선순위 목표로서 처리량, 보안 등이 관리되는 것에 비해 속도가 관리될 수 있다. 이러한 정의를 사용하면 공명을 달성하는데 도움이 되어, 다 수의 에지 처리 시스템이 패킷 별 또는 플로우 별 우선순위 재지정에만 응답하는 것이 아니라, 유사한 목표를 향해 조정할 수 있게 한다. 추가 예에서, 적절한 파라미터(및 파라미터의 최적화 기능)가 각각의 워크로드에 사용되도록 보장하기 위해 강 화된 딥 러닝이 사용될 수 있다. 도 64는 선택한 모드에 따라 각각의 컴퓨팅 플랫폼에서 구성을 셋업하도록 함께 조정하는 (랙(6421, 6422), 플 랫폼(6441, 6442), 슬레드(6461, 6462) 및 오케스트레이터에서) 상이한 레벨의 구성기(6431, 6432, 6451, 6452, 6471, 6472)를 갖는 에지 컴퓨팅 시스템에서 위의 접근 방식의 구현을 도시한다. 오케스트 레이터는 (위에서 언급한 인자에 기초하여) 필요한 모드를 식별한 다음 랙(6421, 6422) 및 랙 컴포넌트 사이의 시스템 자원에 모드를 전파하는 역할을 하는 (에지 게이트웨이의) 모드 구성기(mode configurator)에 결합된다. 각각의 상단 랙(Top-of-Rack))(TOR) 스위치는 (가속기 연결/연결 해제와 같 은) 더 높은 세분성으로 필요한 변경을 수행할 수 있는 모드 구성기(6431, 6432)를 포함하며, 반면에 플랫폼 레 벨 모드 구성기(6431, 6432, 6451, 6452)는 (예를 들어, 캐시 할당 파라미터 및 코어 바인딩(core binding)의 설정과 같은) 낮은 세분성 동작을 수행할 수 있다. 예에서, (위에 나열된 모드와 같은) 모드는 상이한 세분성 범위에 이어져 있는 한 세트의 구성으로 표현될 수 있다. 예를 들어: (구성 1) 플랫폼의 서비스 밀도에 영향을 미치고 (이를 테면 랙 스케일 설계 또는 구성이 수 반되는) 구성 가능한 에지 클라우드 인프라스트럭처에 적용 가능한 컴퓨트 노드에/로부터 다수의 FPGA의 연결/ 연결 해제; (구성 2) 인스턴스 당 코어가 더 많은 인스턴스가 더 적을수록 지연시간이 낮아질 수 있지만 (낮은 지연시간 모드) 서비스 당 할당되는 코어가 더 적은 서비스의 더 많은 인스턴스가 더 높은 지연시간을 대가로 더 높은 처리량을 목표로 하기 때문에(높은 처리량 모드), 플랫폼에서 서비스에 의해 소비되는 코어의 양 및 서 비스 인스턴스 수의 변경; (구성 3) 처리량 및 지연시간 비율을 조정하기 위해 서비스에 이용할 수 있는 자원에 영향을 주는 캐시 할당 파라미터의 변경. 오케스트레이터는 특정 모드에 매핑되는 상이한 시스템 구성으로 구성될 수 있다. 오케스트레이터(641 4)는 또한 도달률 및 패턴, 과거 다운스트림 및 업스트림 정보, 큐 길이 등에 기초할 수 있는 모드 사이의 스위 칭을 위한 윈도우를 예측하기 위해 머신 학습을 사용할 수 있다.추가 예에서, 동적 모드 변경은 전체 에지 클라우드 시스템에 반드시 적용될 수 있는 것은 아니다. 에지 클라 우드는 상이한 모드의 파티션(예를 들어, 표준 모드 파티션, 높은 처리량 모드 파티션 등)으로 나눌 수 있으며 자원은 공통 자원 풀로부터 이러한 파티션으로 완전히 마이그레이션될 수 있다. 이로써, 상이한 퍼센티지의 에 지 클라우드는 상이한 모드에 있을 수 있다. 또한, 일부의 경우, 노드는 현재 동작 모드에서 고효율로 처리할 수 없는 특정 요청을 공통 작업 풀로 푸시 백하도록 설계될 수 있다. 이것은 실행 중에 특성이 분명해지고 저 레벨 작업 재 매퍼(low-level work re-mapper)로 다시 재순환해야 하는 것이 필요하다고 발견될 때 발생할 수 있으며; 저 레벨 재 매퍼(low-level re-mapper)는 에지 인프라스트럭처에서 표준 모드 클라우드렛으로의 이러한 재 매핑의 라운드 로빈 재 할당을 수행할 수 있다. 구현의 관점에서, 이러한 모드의 사용은 하나 또는 다수의 구현 방법을 사용하여 구현될 수 있다. 제 1 구현 방법에 의하면, 오케스트레이터는 상이한 모드에 대한 파라미터 및 시스템 구성으로 구성된다. 모드를 변경할 필요가 있을 때, 오케스트레이터는 이러한 시스템 구성을 설정하기 위한 특정 명령어를 트리거한다. 제 2 구현 방법에 의하면, 각각의 플랫폼은 (캐시 할당, 코어 바인딩과 관련하여) 각각의 모드에 매핑되는 \"모드 인식\" 및 파라미터를 구비한다. 오케스트레이터가 플랫폼에게 특정 모드로 변환하도록 지시할 때, 플랫폼은 알려진 파라 미터를 적용하고 시스템을 설정한다. 위의 예로부터 명백한 바와 같이, 에지 컴퓨팅 인프라스트럭처는 - 다른 이유 중에서도 이러한 시스템은 대규모 데이터 센터 클라우드의 완전한 탄력성을 갖지 않기 때문에 - 공유와 관련하여 더 많은 도전을 받는다. 이것은 에지 클라우드 및 서비스 제공자가 에지와 (네트워크에서 더 깊은) 내부 네트워크 처리 노드 사이에서 \"클라우 드버스트(cloudburst)\"해야 하는 도전과제를 제공한다. 내부 네트워크 위치에서 이러한 처리 노드는 일반적으 로 데이터를 에지 외부로 이전하는 데 발생하는 지연시간 또는 (예를 들어, 협상된 낮은 레이트로 계획된 사전 프로비저닝과 달리 저스트-인-타임 프로비저닝으로 인해 야기되는) 동적 비용에서 훨씬 높은 비용을 가질 수 있 다. 예에서, 에지 컴퓨팅 시스템 인프라스트럭처는, 에지 노드 위치를 사용하여 이러한 서비스를 프록시하는 동안, 성능이 덜 임계적인 서비스를 일시적으로 네트워크 쪽으로 더 깊이 내부 네트워크 노드 위치 쪽으로 셔플할 수 있다. 이것은 시스템이 에지에서 제한된 인프라스트럭처를 풀어주어 갑자기 발생하는 더 높은 우선순위 요구 또는 더 높은 임계성 서비스를 핸들링할 수 있도록 한다. 이러한 배열 내에서, 에지 인프라스트럭처는 동적 피어-투-피어 시프팅 및 갑작스러운 수요 증가의 밸런싱을 수 행하면서, 클러스터 별로 더 높은 계층으로 클라우드-버스트할 우선순위가 더 낮은 서비스를 식별할 수 있다. 예를 들어, 에지 노드 1은 (지연시간 또는 지리적 근접성에 기초하여) 에지 노드 1에 근접한 에지 노드 2로 일 부 작업을 시프트할 수 있고; 에지 노드 2는 차례로 자신의 작업의 일부를 인근 CSP에 시프트하여 에지 노드 1 로부터 자신 쪽으로 시프트된 작업을 위한 공간을 만든다. 이러한 시프팅 및 적응은 진행 중인 워크플로우 또 는 활동성의 컨텍스트에서 수행될 수 있다. 추가 예에서, 시프팅 및 적응은, 이를 테면 ETSI MEC 시스템 사양 또는 다른 조정된 접근 방식에 의해 표시되는, 네트워크 슬라이싱 및 연합된 에지 동작의 컨텍스트에서 발생할 수 있다. 또한, ETSI MEC 또는 다른 조정된 접근 방식의 컨텍스트에서, 협력 오케스트레이션 프레임워크는 에지 원격 클라우드 자원 임대 협상 모델 로부터 향상될 수 있으며; 이것은 차례로 서비스의 과금 및 요금 청구에 영향을 미친다. 에지 컴퓨팅 시스템(예를 들어, 에지 클라우드 및 구현 시스템 및 장치)에서 에지 로드 밸런싱 방식을 구 현하기 위한 제 1 예시적인 방법(예 AA1)은 (예를 들어, 노드 또는 디바이스(2200, 2232, 2240 또는 2250)에서 또는 그에 의해 구현되는) 처리 회로를 사용하여 수행되는 방법으로서, 방법은, 에지 컴퓨팅 시스템의 에지 컴 퓨팅 노드에서, 에지 컴퓨팅 시스템 내의 자원을 로드 밸런싱하는데 사용되는 복수의 모드를 식별하는 단계; 에 지 컴퓨트 노드에서, 오케스트레이터와 연관된 모드 구성기로부터, 자원을 로드 밸런싱하기 위한 복수의 모드로 부터 선택된 모드의 표시를 수신하는 단계; 및 자원을 로드 밸런싱하기 위해 선택한 모드에 기초하여, 에지 컴 퓨팅 노드에서 자원 사용량에 대한 변경을 구현하는 단계를 포함한다. 제 2 예(예 AA2)에서, 예 AA1의 주제는, 선택된 모드의 표시가 오케스트레이터로부터, 에지 컴퓨트 노드의 구성 을 선택된 모드로 전환하라는 커맨드에서 수신되는 것을 포함한다. 제 3 예(예 AA3)에서, 예 AA1-AA2의 주제는, 오케스트레이터로부터, 복수의 모드에 대한 각각의 파라미터 및 시 스템 구성을 수신하는 단계를 포함한다. 제 4 예(예 AA4)에서, 예 AA1-AA3의 주제는, 선택된 모드의 표시가 오케스트레이터로부터 결정되는 것을 포함하 며, 여기서 오케스트레이터는 원격 측정 데이터에 대해 머신 학습을 활용하여 복수의 모드 사이에 사용할 타이 밍을 예측한다. 제 5 예(예 AA5)에서, 예 AA1-4의 주제는, 에지 컴퓨트 노드에서, 복수의 동작 모드에 매핑되는 파라미터 및 시 스템 구성을 식별하는 단계를 포함한다. 제 6 예(예 AA6)에서, 예 AA1-AA5의 주제는, 에지 컴퓨트 노드를 이전 동작 모드로부터 선택된 동작 모드로 동 적으로 변경하는 단계를 포함한다. 제 7 예(예 AA7)에서, 예 AA6의 주제는, 동적 변경에 기초하여 에지 컴퓨팅 시스템의 제 1 부분이 자원을 로드 밸런싱하기 위해 선택된 모드를 활용하도록 적응되고, 에지 컴퓨팅 시스템의 제 2 부분이 자원을 로드 밸런싱하 기 위해 다른 모드를 활용하도록 적응되는 구성을 포함한다. 제 8 예(예 AA8)에서, 예 AA1-AA7의 주제는, 모드가 컴퓨팅 노드와의 가속기의 연결 또는 연결 해제, 코어의 사 용, 서비스에 제공되는 인스턴스의 수, 또는 캐시 할당 파라미터 중 하나 이상에서의 변동을 명시하는 구성을 포함한다. 제 9 예(예 AA9)에서, 예 AA1-AA8의 주제는, 정의된 지연시간 백분위수에 따라 모드가 처리량에 대한 각각의 정 의를 제공하는 구성을 포함한다. 제 10 예(예 AA10)에서 예 AA1-AA9의 주제는, 로드 밸런싱이 스위치, 플랫폼, 슬레드, 또는 오케스트레이터 시 스템에서 식별된 구성 정보에 기초하여 에지 컴퓨트 노드 내에서 구현되는 구성을 포함한다. 제 11 예(예 AA11)에서, 예 AA1-AA10의 주제는, 워크로드의 우선순위에 기초하여 워크로드를 에지 노드 사이 및 더 깊은 네트워크 계층 쪽으로 시프트함으로써 협력 우선순위 기반 오케스트레이션을 수행하는 단계를 포함하며, 그렇게 함으로써 자원은 액세스 가능한 에지 노드 사이에서 풀려난다. 다양한 설정에서, 예 AA1-AA11(및 오케스트레이션된 로드 밸런싱의 다른 양태)은 정의된 애플리케이션 프로그래 밍 인터페이스 또는 인터페이스 사양; 메시지 포맷, 정의 또는 기능의 사용; 및 에지 컴퓨팅 환경 내에서 로드 밸런싱을 검출하고 구현하기 위한 정책 및 로직의 다른 사용 및 구현의 결과로서 관찰되거나 모니터링될 수 있 다. 예 AA1-AA11 및 이러한 로드 밸런싱 동작의 다른 양태는 또한 (예를 들어, FaaS 또는 EaaS 설정에서 제공 되는 서비스 사이에서 자원의 로드 밸런싱에 대한) 서비스 동작 및 서비스 기능의 결과로서 관찰되거나 구현될 수 있다. 또한, 예 AA1-AA11의 방법은 에지 컴퓨팅 시스템에서 (예를 들어, 명령어가 실행될 때 방법을 수행하 는 머신 판독 가능 매체와 함께) 구현된 명령어 또는 (예를 들어, 방법을 수행하거나 달성하기 위한 구성을 포 함하는 장치와 함께) 구현된 하드웨어 구성으로서 제공될 수 있다. 따라서, 예 AA1-AA11의 특징(및 로드 밸런 싱 및 로드 오케스트레이션의 다른 양태)은 시스템 오케스트레이터 또는 설계자에 의해 조정되거나 설계된 대로, 본 명세서의 임의의 다른 예와 결합되어 에지 클러스터 또는 에지 클라우드 시스템을 구성할 수 있다. VI. 에지 컴퓨팅 구성을 위한 연결성 유스 케이스 및 구성 다음의 예는 MEC 및 5G 네트워크 구현 내에서 제공되는 에지 컴퓨팅 구성과 관련된 특정 예를 제공한다. 그러 나, 다른 많은 표준 및 네트워크 구현이 전체에서 논의된 에지 및 서비스 관리 개념에 적용 가능하다는 것을 이 해할 수 있을 것이다. 다중 액세스 에지 컴퓨팅(Multi-Access Edge Computing)(MEC) 네트워크 내에서의 연결성뿐만 아니라, 5G 네트 워크와 MEC 네트워크 간의 연결성은 네트워크의 에지에서 콘텐츠를 신속하게 처리함으로써 매우 빠른 서비스 경 험을 제공할 수 있게 한다. MEC는 낮은 지연시간 및 증가된 대역폭 효율성과 관련된 표시자를 비롯한, 5G 네트 워크의 요구되는 핵심 성과 표시자(KPI)를 충족하기 위한 핵심 요소 중 하나로서 인정된다. 그러나, 통신 네트 워크에서 MEC와 5G의 연결성은 요구되는 KPI에 대한 기술적인 인에이블러(enabler)일뿐만 아니라, 내부 MEC은 물론이고 MEC-5G 연결성을 개선하는 것은 원격 통신 비지니스의 변환에 중요한 역할을 하며, 원격 통신 네트워 크는 산업 및 다른 특정 고객 부분을 위한 다목적 서비스 플랫폼으로 변하고 있다. 솔루션 관점에서, 단일 에지 위치를 갖는 것은 필요한 유연성을 제공하지 않으며 에지 인프라스트럭처 내의 상 이한 위치에 배치될 수 있는 솔루션 및 제품 제공물뿐만 아니라 연결성 측면에서 사용자에게 제공할 수 있는 것 을 반영하지 않는다. 실제 에지가 상주하는 위치와 특정 유스 케이스 또는 워크로드에 이용할 수 있는 연결성 옵션을 정의하는 것은 특정 위치에서 제공하는 핵심 성과 표시자(KPI) 또는 가치 제안과 직접적으로 관련된다. 예를 들어, 사업자 인프라스트럭처의 코어에서 사물 인터넷(IoT) 또는 증강 현실(AR)/가상 현실(VR) 워크로드에 대한 에지 인프라스 트럭처를 정의하는 것은 지연시간 측면에서 KPI 요구 사항을 충족하지 못할 수 있다. 따라서, 이러한 워크로드 를 위한 에지는 디바이스(기지국 또는 중앙국)에 더 가까울 수 있다. 반면에, 콘텐츠 전송 네트워크(CDN) 워크 로드를 위한 에지는 기지국, 중앙국 또는 사업자 인프라스트럭처의 임의의 다른 중간 집계 포인트(POA 또는 POP)일 수 있다. 도 65는 무선 네트워크 아키텍처 내의 상이한 에지 컴퓨팅 노드 간의 연결을 도시한다. 도 65를 참조하면, 네 트워크 아키텍처는 컴퓨팅 디바이스(예를 들어, 사용자 디바이스), 에지 컴퓨팅 노드(6530-6544), 및 클라우드 네트워크(또는 \"클라우드\")를 포함한다. 에지 컴퓨팅 노드(6530-6544)는 에지 계층 및 개별 노드에 의해 수행되는 기능에 기초하여 세분화될 수 있다. 예를 들어, 소형 셀 및 온-프레미스 장비(또 는 에지렛/클라우드렛)는 RAN 및 네트워크 기능을 수행하는 소형 셀 및 로컬 브레이크 아웃 및 에지 서비스 실행 기능을 수행하는 온-프레미스 장비와 함께 소형 셀/온-프레미스 에지 계층 과 연관된다. 소형 셀/온-프레미스 에지 계층은 초저 지연시간 서비스 및 로컬 서비스와 연관될 수 있다. 일부 양태에서, 계층은 액세스 에지 계층일 수 있다. 기지국(6534, 6538) 및 캐비닛은 RAN 및 네트워크 기능을 수행하는 기지국 및 로컬 브레이크 아웃 및 에지 서비스 실행 기능을 수행하는 기지국과 함께, 기지국 에지 계층과 연관된다. 기지국 에지 계층은 시골 지역 또는 다른 위치를 위한 초저 지연시간 서비스 무선 연결성 서비스와 연관 될 수 있다. 일부 양태에서, 캐비닛은 컴퓨팅 디바이스와 로컬 CO 간의 유선 연결로 구성될 수 있다. 일부 양태에서, 기지국은 네트워크 기능과 연관된 데이터 평면 통신을 관리하도록 구성된 VNF 컴퓨팅 노 드이고, 기지국은 기지국으로부터 라우팅된 서비스 관련 요청을 처리하도록 구성된 서비스 컴퓨팅 노드이다. 일부 양태에서, 기지국(6534 및 6538)은 동일한 안테나 타워에 함께 위치될 수 있다. 로컬 중앙국(CO) 및 기지국 서비스 컴퓨팅 노드(6542 및 6544)는 네트워크 기능을 수행하는 로컬 CO 및 로컬 브레이크 아웃 및 에지 서비스 실행을 수행하는 기지국 서비스 컴퓨팅 노드(6542 및 6544)와 함께 중앙국 계층과 연관되어 있다. 일부 양태에서, 계층 및 계층은 집합 에지 계 층으로서 간주될 수 있다. 컴퓨팅 디바이스는 서비스 결과 전달 또는 D2D 통신뿐만 아니라 네트워크 기능 개시와 연관 된다. 클라우드는 오버 더 탑(Over-The-Top)(OTT) 미디어 서비스를 비롯한 클라우드 관련 기능과 연관된다. 도 65는 또한 에지 디바이스로부터 요청된 서비스를 제공하는 네트워크 노드로의 엔드-투-엔드 플로우의 기술적 분해를 도시한다. 일부 양태에서, 에지 위치(예를 들어, 계층(6502, 6504, 6506))는 인프라스트럭처에 연결하 는데 사용되는 물리적 매체에 종속적이다. 예를 들어, 무선 디바이스(예를 들어, 디바이스 중 하나)만이 인프라스트럭처가 관리되고 연결되는 방법에 따라 기지국 위치(예를 들어, 6534)에 액세스할 수 있다. 그러나, 인프라스트럭처가 변경됨에 따라, 사업자는 장기적으로는 잠재적인 에지 계층이 이동적 유형 및 고정적 유형의 연결 둘 모두에 대해 수렴될 수 있음을 암시할 수 있는 고정된 모바일 컨버전스(Fixed Mobile Convergence)(FMC)로 추세화되고 있다. 도 66은 원격 통신 서비스 제공자(TSP)와 클라우드 서비스 제공자(CSP) 사이의 에지 통신 상호작용을 도시한다. 도 66을 참조하면, 도 66이 통신 서비스 제공자 인프라스트럭처와 클라우드 서비스 제공자 인프라스트럭 처 사이의 연결성을 더 도시한다는 점을 제외하고, 네트워크 아키텍처는 네트워크 아키텍처 와 유사하다. (6602-6644)로서 참조되는 요소는 도 65에서 (6502-6544)로서 참조되는 요소에 대응한다. 도 66에 도시된 바와 같이, CSP 인프라스트럭처는 클라우드와 연관된 CSP의 하나 이상의 네 트워크 노드를 포함할 수 있다. 보다 구체적으로, 기지국 에지 계층은 에지 디바이스에 더 가까운 기지국 에지 계층 내의 클라우드에 의해 정상적으로 제공되는 클라우드 기능성을 제공할 수 있는 CSP 에지 데이터 센터를 포함할 수 있다. 이와 관련하여, 정상적으로 TSP 인프라스트럭처의 기지 국 에지 계층으로부터 CO 에지 계층 및 클라우드로 포워딩되는 네트워크 트래픽은 기지국 에 지 계층 내의 CSP 에지 데이터 센터로 라우팅되어, 더 빠르고 효율적인 연결성 링크를 초래한다. 유사하게, CO 에지 계층은 에지 디바이스에 더 가까운 CO 에지 계층 내의 클라우드에 의해 정상적으로 제공되는 클라우드 기능성을 제공할 수 있는 CSP CO를 포함할 수 있다. 이와 관련하여,정상적으로 TSP 인프라스트럭처의 CO 에지 계층으로부터 클라우드로 포워딩되는 네트워크 트 래픽은 CO 에지 계층 내의 CSP CO로 라우팅될 수 있다. 일단 잠재적인 서비스 매핑이 완료되면 에지 클라우드에서 발생하는 근본적인 질문 중 하나는 누가 이러한 서비 스를 제공하고 누가 구현하는 것인가이다. 이러한 컨텍스트에서, 사업자(또는 TSP)는 (컴퓨팅을 비롯한) 전체 인프라스트럭처를 소유하고 자기 소유의 구독자에게 자기 소유의 서비스를 제공하며 잠재적으로 다른 서비스 제 공자(예를 들어, Google)에게 컴퓨트를 임대하여 자기 소유의 소프트웨어 스택을 실행하려고 한다. 반면에, 클 라우드 서비스 제공자(또는 CSP)는 TSP에 의해 제공되는 하드웨어 상에서 (IP 보호, 보안 및 서비스 품질을 위 해) 자기의 소프트웨어 스택을 실행하는 것을 반드시 수락하는 것은 아니다. 이러한 양태에서, 도 66에 도시된 바와 같이, CSP는 TSP를 네트워크 인프라스트럭처 제공자로만 보고 있으며, 자기의 에지 위치에 자기 소유의 블 랙 박스(예를 들어, 폐쇄형 랙)를 배치하고 동작할 공간을 요구하고 있다. 일부 양태에서, 그리고 도 66에 도시된 바와 같이, 하드웨어 프로비저닝 및 서비스 호스팅과 관련하여 세 개의 잠재적 시나리오가 발생할 수 있다. TSP는 네트워킹 및 컴퓨트 자원을 포함하는 엔드-투-엔드 네트워크 인프라스트럭처를 소유한다. 이 시나리 오에서, TSP는 자기 소유의 플랫폼을 사용하여 자기 소유의 서비스를 실행하고 잠재적으로 예비 플랫폼을 제 3 자에게 임대한다. TSP는 네트워크 인프라스트럭처를 설계할 때 보안; 프라이버시; QoS; IP 보 호와 관련된 문제를 고려할 수 있다. 다음의 3 레벨의 자원 임대가 발생할 수 있다: a. 인프라스트럭처를 소유한 사업자는 컴퓨트 자원을 다수의 파티션으로 분할하고 각각의 파티션이 실제로 다른 사업자에게 임대된다. 이 모델은 소규모 사업자가 계층 1 사업자의 인프라스트럭처를 사용하고 있는 국가에서 적합할 수 있다. b. (만일 있다면) 특정 사업자에게 할당된 파티션은 동일한 유형의 세 개의 논리 파티션(레벨): 임대되거나 제 3 자 서비스 제공자인 파티션; (vBNG 또는 vEPC와 같은) 네트워크 기능을 실행하는데 사용되는 하나의 파티션; 사업자가 자기 소유의 고객에게 제공하는 서비스를 호스팅하는데 사용되는 하나의 파티션으로 분할 될 수 있다. c. (만일 있다면) 레벨 2 파티션은 Amazon 또는 Google과 같은 서비스 제공자(레벨 2)에게 임대할 다수의 파티 션으로 동시에 분할될 수 있다. 이러한 파티션 각각은 서비스 제공자에 의해 관리되고 가상으로 소유될 수 있 다. 예를 들어, 아마존 웹 서비스(Amazon Web Service)를 포함시켜 최종 사용자가 자기 소유의 서비스를 이러 한 파티션에서 실행할 수 있게 하거나 또는 아마존 그린 글라스(Amazon Green Grass)를 포함시켜 최종 사용자가 자기 소유의 서비스를 노출할 수 있게 하는 것이다. TSP는 자체 네트워크 기능과 서비스를 배치하는데 사용되는 네트워킹 인프라스트럭처, 데이터 센터 및 컴퓨 팅 자원을 소유한다. CSP는 원하는 자기 소유의 공간을 에지 위치(기지국, 중앙국 등)에 임대하고 자기 소유의 컴퓨팅 솔루션을 배치한다. 이러한 양태에서, TSP는 CSP에 대한 연결성 및 인프라스트럭처를 용이하게 하고 CSP는 크기와 아키텍처를 갖춘 솔루션을 배치하여 자기의 서비스를 배치하고 보안할 수 있다. 일부 CSP의 경우, 이러한 옵션은 데이터 프라이버시, IP 보호 및 필요한 성능을 보장하는데 더 적합하다. CSP는 TSP 네트워크 인프라스트럭처 외부에 배치되거나 호스팅되는 자기 소유의 데이터 센터를 관리한다. 이러한 양태에서, 특정 에지 위치(예를 들어, 기지국)는 그 특정 데이터 센터와의 유선 다이렉트 연결을 갖는다. 도 67은 5G-MEC 상호연결을 도시한다. 도 67을 참조하면, 다이어그램은 모바일 인터넷 네트워크와 같은 통신 네트워크를 통해 모두 상호연결될 수 있는 다양한 에지 클라우드(또는 에지 계층)(6710, 6712 및 6714)를 도시한다. 일부 양태에서, 에지 컴퓨팅(및 MEC)은 액세스 관용적이며 통신 링크는 3GPP LTE, 5G NR, Wi-Fi 또는 다른 RAT를 비롯한, 그리고 또한 자동차 및 다른 산업용 유스 케이스와 같은 많은 버티컬(vertica l)을 커버하는, 하나 이상의 무선 액세스 기술(Radio Access Technology)(RAT)을 통해 에지 클라우드 내의 MEC 노드와 다른 무선 노드 사이에 설정될 수 있다. 예를 들어, 에지 클라우드는 기지국을 통해 (예를 들어, 데이터 레이크 또는 데이터 웨어하우스로 부터 제공되는) 빅 데이터 네트워크와 연관된 하나 이상의 네트워크 노드에 애플리케이션 및 서비 스를 노출할 수 있다. 에지 클라우드는 기지국을 통해 애플리케이션 및 서비스(672 4)를 하나 이상의 IoT 센서 및 디바이스에 노출할 수 있다. 에지 클라우드는 기지국을 통해 애플리케이션 및 서비스를 하나 이상의 소셜 및 인터넷 데이터 소스에 노출할 수 있다. 일부 양태에서, 기지국(6728, 6730 및 6732)은 5G-NR을 포함하는 상이한 RAT와 연관될 수 있다. 일부 양태에서, 통신 네트워크는 하나 이상의 에지 클라우드(6710-6714) 내의 애플리케이션 및 서비스에 액세스하고 구성하기 위한 애플리케이션 프로그래밍 인터페이스(Application Programming Interface)(API)를 개발자 또는 고객 커뮤니티에 제공할 수 있다. 이러한 클라우드에서 실행되는 애플리케이션 또는 서비스와 관련하여 에지 클라우드(6710-6714)에서 수신된 네 트워크 트래픽은 클라우드로 라우팅될 수 있거나, 또는 데이터는 클라우드로부터, 네트워크 비무장 지대(Demilitarized Zone)(DMZ)를 통해 요청될 수 있다. DMZ는 클라우드뿐 아니라 사설 클 라우드에 추가 보안 계층을 추가하는 물리적 또는 논리적 서브네트워크인 경계 네트워크(perimeter network) 또는 스크리닝된 서브넷(screened subnet)이라고 할 수 있다. 도 68은 전체 5G 차세대(Next Generation)(NG) 시스템 아키텍처의 간략화된 다이어그램이다. 도 68을 참조하면, NG 시스템 아키텍처는 NG-RAN 및 5G 네트워크 코어(5GC)를 포함한다. NG- RAN은 차세대 노드-B(Next Generation Node-B)(gNB) 및 NG 진화된 노드-B(NG Evolved Node-B)(NG- eNB)와 같은 복수의 노드를 포함할 수 있다. 5GC는 액세스 및 이동성 기능(Access and Mobility Function)(AMF) 및/또는 사용자 평면 기능 (User Plane Function)(UPF)을 포함할 수 있다. AMF 및 UPF는 NG 인터페이스를 통해 gNB 및 NG-eNB에 통신 가능하게 결합될 수 있다. 보다 구체적으로, 일부 양태에서, gNB 및 NG-eNB는 NG-C 인터페이스에 의해 AMF에 연결될 수 있고, NG-U 인터페이스에 의해 UPF에 연 결될 수 있다. gNB 및 NG-eNB는 Xn 인터페이스를 통해 서로 결합될 수 있다. 일부 양태에서, gNB는 UE를 향해 뉴 라디오(New Radio)(NR) 사용자 평면 및 제어 평면 프로토콜 종료를 제공하는 노드를 포함할 수 있고 NG 인터페이스를 통해 5GC에 연결된다. 일부 양태에서, NG- eNB는 UE를 향해 진화된 범용 지상 무선 액세스(Evolved Universal Terrestrial Radio Access)(E- UTRA) 사용자 평면 및 제어 평면 프로토콜 종료를 제공하는 노드를 포함할 수 있고 NG 인터페이스를 통해 5GC에 연결된다. 일부 양태에서, NG 시스템 아키텍처는 3GPP 기술 사양(Technical Specification)(TS) 23.501(예를 들어, V15.4.0, 2018-12)에 의해 제공되는 다양한 노드 간의 참조 지점을 사용할 수 있다. 일부 양태에서, gNB 및 NG-eNB 각각은 기지국, 모바일 에지 서버(예를 들어, MEC 호스트), 소형 셀, 홈 eNB 등으로서 구현될 수 있다. 일부 양태에서, 5G 아키텍처에서 노드는 마스터 노드(MN)일 수 있고 노드는 이차 노드(secondary node)(SN)일 수 있다. MN은 NG-C 인터페이스를 통해 AMF에 연결되고 XN-C 인터페이스를 통해 SN에 연결될 수 있다. MN은 NG-U 인터페이스를 통해 UPF에 연결되고 XN-U 인터페이스를 통 해 SN에 연결될 수 있다. 도 69는 비 로밍 5G 시스템 아키텍처를 도시한다. 도 69를 참조하면, 참조 지점 표현으로 5G 시스템 아 키텍처가 예시된다. 보다 구체적으로, UE는 RAN 및 하나 이상의 다른 5G 코어(5G Core)(5GC) 네트워크 엔티티와 통신할 수 있다. 5G 시스템 아키텍처는 액세스 및 이동성 관리 기능 (Access and Mobility Management Function)(AMF), 세션 관리 기능(Session Management Function)(SMF), 정책 제어 기능(Policy Control Function)(PCF), 애플리케이션 기능(Application Function)(AF), 사용자 평면 기능(User Plane Function)(UPF), 네트워크 슬라이스 선택 기능 (Network Slice Selection Function)(NSSF), 인증 서버 기능(authentication server function)(AUSF) 및 통합 데이터 관리(unified data management)(UDM)/홈 가입자 서버(home subscriber server)(HSS)와 같은 복수의 네트워크 기능(network function)(NF)을 포함한다. UPF는 예를 들어 사업자 서비스, 인터넷 액세스, 또는 제 3 자 서비스를 포함할 수 있는 로컬 데이터 네 트워크(Data Network)(DN)와의 연결을 제공할 수 있다. AMF는 액세스 제어 및 이동성을 관리하는 데 사용할 수 있으며 네트워크 슬라이스 선택 기능성을 또한 포함할 수 있다. SMF는 네트워크 정책에 따 라 다양한 세션을 설정하고 관리하도록 구성할 수 있다. UPF는 원하는 서비스 유형에 따라 하나 이상의 구성으로 배치될 수 있다. PCF는 (4G 통신 시스템의 PCRF와 유사한) 네트워크 슬라이싱, 이동성 관리 및 로밍을 사용하여 정책 프레임워크를 제공하도록 구성할 수 있다. UDM은 (4G 통신 시스템의 HSS와유사한) 가입자 프로파일 및 데이터를 저장하도록 구성할 수 있다. 일부 양태에서, UPF는 N9 인터페이스를 통해 다른 UPF에 연결되고 N6 인터페이스를 통해 중앙 DN에 연결될 수 있다. 일부 양태에서, 5G 시스템 아키텍처는 통화 세션 제어 기능(Call Session Control Function)(CSCF)과 같 은 복수의 IP 멀티미디어 코어 네트워크 서브 시스템 엔티티뿐만 아니라 IP 멀티미디어 서브시스템(IP Multimedia Subsystem)(IMS)을 포함한다. 보다 구체적으로, IMS는 프록시 CSCF(proxy CSCF)(P- CSCF), 서빙 CSCF(serving CSCF) (S-CSCF), (도 69에 도시되지 않은) 긴급(emergency) CSCF(E- CSCF), 또는 질문(interrogating) CSCF(I-CSCF)로서 작동할 수 있는 CSCF를 포함한다. P-CSCF는 IMS 내의 UE에 대한 제 1 콘택트 포인트가 되도록 구성될 수 있다. S-CSCF는 네트워크의 세션 상태를 핸들링하도록 구성될 수 있으며 E-CSCF는 올바른 응급 센터 또는 PSAP로의 긴급 요청의 라우팅과 같은 긴급 세션의 특정 양상을 핸들링하도록 구성될 수 있다. I-CSCF는 네트워크 사업자의 가입자 또는 네트워크 사업자의 서비스 영역 내의 현재 위치한 로밍 가입자로 향하는 모든 IMS 연결에 대한 사업자 네트워크 내의 콘택트 포인트로서 기능하도록 구성될 수 있다. 일부 양태에서, I-CSCF는 다른 IP 멀티미디어 네트 워크, 예를 들어, 상이한 네트워크 사업자에 의해 운영되는 IMS에 연결될 수 있다. 일부 양태에서, UDM/HSS는 전화 통신 애플리케이션 서버(Telephony Application Server)(TAS) 또는 다른 애플리케이션 서버(Application Server)(AS)를 포함할 수 있는 애플리케이션 서버에 결합될 수 있다. AS는 S-CSCF 또는 I-CSCF를 통해 IMS에 결합될 수 있다. 일부 양태에서, 5G 시스템 아키텍처는 모든 네트워크에 걸쳐 공통인 액세스 카테고리의 최소 디폴트 세트 에 의해 분류될 수 있는 액세스 카테고리에 기초하여, 5G 액세스 제어 메커니즘 기술을 사용하도록 구성될 수 있다. 이러한 기능성은 방문 PLMN(visited PLMN)(VPLMN)과 같은 공용 육상 모바일 네트워크(Public Land Mobile Network)(PLMN)가 상이한 유형의 등록 시도에 맞서 네트워크를 보호하고, 로밍 가입자에 허용 가능한 서 비스를 실시 가능하게 할 수 있게 하고, VPLMN이 특정 기본 서비스 수신을 목표로 하는 액세스 시도를 제어할 수 있게 한다. 이것은 또한 사업자 특정 방식으로 구성되어 사용될 수 있는 한 세트의 액세스 카테고리를 제공 함으로써 개별 사업자에게 더 많은 옵션과 유연성을 제공한다. 참조 지점 표현은 대응하는 NF 서비스 간에 상호작용이 존재할 수 있음을 나타낸다. 예를 들어, 도 69는 다음 과 같은 참조 지점: N1(UE와 AMF 사이), N2(RAN과 AMF 사이), N3(RAN과 UPF 사이), N4(SMF와 UPF 사이), N5(PCF와 AF 사이), N6(UPF와 DN 사이), N7(SMF와 PCF 사이), N8(UDM과 AMF 사이), N9(UPF와 ) 사이), N10(UDM과 SMF 사이), N11(AMF와 SMF 사이), N12(AUSF와 AMF 사 이), N13(AUSF와 UDM 사이), N14(두 개의 AMF 사이), N15(비 로밍 시나리오의 경우 PCF와 AMF 사이, 또는 로밍 시나리오의 경우 방문 네트워크의 PCF와 AMF 사이), N16 (도시되지 않은 두 개의 SMF 사이), 및 N22(AMF와 NSSF 사이)를 도시한다. 도 69에 도시되 지 않은 다른 참조 지점 표현이 또한 사용될 수 있다. 도 70은 5G 서비스 기반 아키텍처 및 일반 MEC 아키텍처를 도시한다. 5G 시스템 아키텍처는 서비스 기반 표현으로 예시되고 도 69의 시스템 아키텍처와 실질적으로 유사(또는 동일)할 수 있다. 예 를 들어, 5G 시스템 아키텍처는 시스템 아키텍처에서도 나타내는 다음과 같은 엔티티: NSSF, PCF, UDM, AF, AUSF, AMF, SMF, UE, RAN, UPF 및 DN를 포함한다. 이러한 네트워크 엔티티 이외에, 5G 시스템 아키텍처는 또한 네트워크 노출 기능 (Network Exposure Function)(NEF) 및 네트워크 저장소 기능(Network Repository Function)(NRF)(702 0)을 포함한다. 일부 양태에서, 5G 시스템 아키텍처는 서비스 기반일 수 있고 네트워크 기능 간의 상호작용은 (도 70에 도시된) 대응하는 포인트-투-포인트 참조 지점 Ni에 의해 또는 (도 69에 도시된) 서비스 기반 인터페 이스로서 표현될 수 있다. 참조 지점 표현은 대응하는 NF 서비스 간에 상호작용이 존재할 수 있음을 나타낸다. 예를 들어, 5G 시스템 아 키텍처는 다음과 같은 참조 지점: N1(UE와 AMF 사이), N2(RAN와 AMF 사이), N3(RAN와 UPF 사이), N4(SMF와 UPF 사이), N5(PCF와 AF 사이; 도시되지 않음), N6(UPF와 DN 사이), N7(SMF와 PCF 사이; 도시되지 않음), N8(UDM와 AMF 사이; 도시되지 않음), N9(두 개의 UPF 사이), N10(UDM와 SMF 사이; 도시되지 않 음), N11(AMF와 SMF 사이; 도시되지 않음), N12(AUSF와 AMF 사이; 도시되지 않음),N13(AUSF와 UDM 사이; 도시되지 않음), N14(두 개의 AMF 사이; 도시되지 않음), N15(비 로 밍 시나리오의 경우 PCF와 AMF 사이, 또는 로밍 시나리오의 경우 방문 네트워크의 PCF와 AMF 사이; 도시되지 않음), N16(두 개의 SMF 사이; 도시되지 않음), 및 N22(AMF와 NSSF 사이)로 구성될 수 있다. 도 70에 도시되지 않은 다른 참조 지점 표현이 또한 사용될 수 있다. 일부 양태에서, 도 70에 도시된 바와 같이, 서비스 기반 표현은 다른 인증된 네트워크 기능이 자기의 서비스에 액세스할 수 있게 하는 제어 평면 내의 네트워크 기능을 나타내는데 사용될 수 있다. 이와 관련하여, 5G 시스 템 아키텍처는 다음과 같은 서비스 기반 인터페이스: Namf(AMF에 의해 표시되는 서비스 기반 인터페이스), Nsmf(SMF에 의해 표시되는 서비스 기반 인터페이스), Nnef(NEF에 의해 표시되는 서비스 기반 인터페이스), Npcf(PCF에 의해 표시되는 서비스 기반 인터페이스), Nudm(UDM에 의해 표시되는 서비스 기반 인터페이스), Naf(AF에 의해 표시되는 서비스 기반 인터페이스), Nnrf(NRF에 의해 표시되는 서비스 기반 인터페이스), Nnssf(NSSF 에 의해 표시되는 서비스 기반 인터페이스), Nausf(AUSF에 의해 표시되는 서비스 기반 인터페이 스)를 포함할 수 있다. 도 70에 도시되지 않은 다른 서비스 기반 인터페이스(예를 들어, Nudr, N5g-eir 및 Nudsf)가 또한 사용될 수 있다. 일부 양태에서, NEF는 RAN과의 무선 연결을 처리하는데 사용될 수 있는 MEC 시스템과 같은 MEC 시스템 내의 MEC 호스트에 인터페이스를 제공할 수 있다. MEC 시스템은 (시스템 레벨에서 동작하는) MEC 오케스트레이터뿐만 아니라 분산 호스트 레벨에서 동작하는 다음과 같은 MEC 엔티티: 하나 이상의 애플리케이션, 하나 이상의 서비스, 가상화 인프라 스트럭처, MEC 플랫폼, MEC 플랫폼 관리자를 포함할 수 있다. MEC 시스템의 컴포넌 트는 이하에서 더 상세히 논의된다. 도 71은 MEC 시스템의 일부 기능 엔티티가 5G 네트워크의 네트워크 기능과 상호작용하는, 5G 네트워크에 서 MEC 시스템의 통합된 MEC 배치를 도시한다. 도 71을 참조하면, MEC시스템은 도 70의 MEC 시스 템의 컴포넌트(7070-7080)와 유사한 컴포넌트(7170-7180)를 포함한다. 유사하게, 5G 네트워크는 도 70의 5G 네트워크의 컴포넌트(7002-7044)와 유사한 컴포넌트(7102-7144)를 포함한다. 일부 양태에서, 5G 네트워크에서 통합된 MEC 배치는 다음의 기술 중 하나 이상을 사용하여 구성될 수 있 다: 로컬 라우팅(Local Routing) 및 트래픽 조종(Traffic Steering): 5G 네트워크는 MEC 시스템의 일부일 수 있는 로컬 데이터 네트워크(예를 들어, )의 애플리케이션으로 라우팅될 트래픽을 선택하 도록 구성될 수 있다. 프로토콜 데이터 유닛(Protocol Data Unit)(PDU) 세션은 데이터 네트워크를 향하 는 다수의 N6 인터페이스를 가질 수 있다. 이러한 인터페이스를 종료하는 UPF(예를 들어, )는 PDU 세션 앵커 기능성을 지원하도록 구성될 수 있다. 일부 양태에서, UPF에 의한 트래픽 조종은 조종된 트래픽과 매칭하는 한 세트의 트래픽 필터에서 동작하는 업링크 분류자(Uplink Classifier)에 의해 또는 대안으로, 다수 의 IPv6 프리픽스가 해당 PDU 세션과 연관된 IPv6 다중 호밍(multi-homing)에 의해 지원되고 있다. 사업자의 정책에 따라 PCF를 통해 직접 또는 NEF를 통해 간접적으로 UPF (재)선택 및 트래픽 라우팅에 영향을 미치는 AF의 역량. UE 및 애플리케이션 이동성 시나리오를 위한 세션 및 서비스 연속성(Session and Service Continuity)(SSC) 모드. 애플리케이션이 배치된 특정 영역에서 LADN에 연결하는 지원을 제공함으로써 5G 네트워크에 의 한 근거리 데이터 네트워크(Local Area Data Network)(LADN)(예를 들어, )의 지원. LADN으로의 액세스는 UE의 서빙 PLMN에서 한 세트의 추적 영역으로서 정의된 특정 LADN 서비스 영역에서 이용 가능하다. 일부 양태에서, LADN은 UE의 서빙 PLMN에 의해 제공되는 서비스로서 구성될 수 있다. 5G 네트워크 내의 네트워크 기능과 이들 기능이 생성하는 서비스는 NRF에 등록되어 있는 반면, MEC 시스템에서 MEC 애플리케이션에 의해 생성되는 서비스는 MEC 플랫폼의 서비스 레지스트리에 등록된다. 일부 양태에서, 서비스 등록은 애플리케이션 실시 가능 기능성의 일부일 수 있다. 서비스를 사용하 기 위해, 인가되면, 네트워크 기능은 서비스를 생성하는 네트워크 기능과 직접 상호작용할 수 있다. 가용 MEC 서비스의 목록은 NRF에서 찾을 수 있다. 서비스 중 일부는 서비스에 액세스하기 위해 도메인 외부에 있 는 신뢰성 없는 엔티티에서도 이용 가능한 NEF를 통해 액세스할 수 있다. 환원하면, NEF는 서비스노출을 위한 중앙집중화된 지점으로서 기능할 수 있으며 또한 시스템의 외부로부터 발신하는 모든 액세스 요청 을 인가하는데 중요한 역할을 한다. 일부 양태에서, 인증과 관련된 절차는 인증 서버 기능(AUthentication Server Function)(AUSF)에 의해 서빙될 수 있다. 일부 양태에서, 5G 네트워크는 가용 네트워크 기능으로부터 상이한 서비스 또는 서비스를 사용하고 있는 테넌트로의 필요한 특징 및 자원의 할당을 가능하게 하는 네트워크 슬라이싱을 사용할 수 있다. 네트워크 슬라 이스 선택 기능(Network Slice Selection Function)(NSSF)은 사용자의 적합한 네트워크 슬라이스 인스턴 스의 선택 및 필요한 AMF의 할당을 보조하도록 구성될 수 있다. MEC 애플리케이션, 예를 들어, MEC 시스템의 분산 클라우드에 호스팅되는 애플리케이션은 5G 네트워크에 구성된 하나 이상의 네트 워크 슬라이스에 속할 수 있다. 일부 양태에서, 5G 네트워크의 정책 및 규칙은 PCF에 의해 핸들링된다. PCF는 또한 트래픽 조종 규칙에 영향을 주기 위해 MEC 플랫폼과 같은 AF의 요청을 서빙하는 기능이다. PCF는 AF가 신 뢰성 있는지에 따라 그리고 트래픽 조종의 경우에, 대응하는 PDU 세션이 요청시에 알려져 있는지에 따라 직접 또는 NEF를 통해 액세스할 수 있다. UDM 기능은 사용자 및 구독에 관련된 서비스를 담당한다. 예를 들어, UDM은 3GPP 인증 및 키 협약 (Authentication and Key Agreement)(AKA) 인증 자격증명을 생성하고, 사용자 식별 관련 정보를 핸들링하고, 액세스 인가(예를 들어, 로밍 제한 사항)을 관리하고, (AMF, SMF를 서빙하는) 사용자 서빙 NF를 등 록하고, SMF/데이터 네트워크 네임(Data Network Name)(DNN) 할당 기록을 유지하여 서비스 연속성을 지원하고, 콘택트 포인트 역할을 하여 아웃바운드 로밍에서의 차단 절차를 지원하고, 구독 관리 절차를 수행하도록 구성될 수 있다. UPF는 5G 네트워크에서 통합된 MEC 배치를 지원하도록 구성될 수 있다. 일부 양태에서, UPF는 MEC 시스템 관점에서 분산되고 구성 가능한 데이터 평면으로 간주될 수 있다. 트래픽 규칙 구성에서와 같이 그 데이터 평면의 제어는 NEF-PCF-SMF 통신 경로를 따라갈 수 있다. 결과적으로, 일부 양태에서, 로컬 UPF는 (도 71에 도시된 바와 같이) MEC 구현의 일부일 수 있다. 도 71을 참조하면, MEC 오케스트레이터는 AF의 역할을 하는 MEC 시스템 레벨 기능 엔티티로서, NEF(711 8)와 상호작용할 수 있거나 일부 시나리오에서는 타겟 5G 네트워크 기능(또는 NF)과 직접 상호작용할 수 있다. MEC 호스트 레벨에서, MEC 플랫폼은 다시 AF의 역할로 5G NF와 상호작용하도록 구성될 수 있다. 일부 양 태에서, MEC 호스트, 예를 들어, 호스트 레벨 기능 엔티티는 5G 시스템의 데이터 네트워크(예를 들어, ) 에 배치될 수 있다. 5G 코어 네트워크 기능으로서의 NEF는 유사한 NF와 함께 중앙에 배치된 시스템 레벨 엔티티이지만, 일부 양태에서 NEF의 인스턴스는 MEC 호스트로부터의 저 지연시간, 고 처리량 서비스 액세스를 가능하게 하도록 에지에 배치될 수도 있다. 일부 양태에서, MEC는 UPF의 N6 참조 지점 상에, 예를 들어 5G 시스템 외부의 데이터 네트워크(예 를 들어, 7108)에 배치될 수 있다. 이러한 기능성은 UPF를 배치하는 유연성에 의해 가능해질 수 있다. 일부 양태에서, 분산된 MEC 호스트는 MEC 앱과는 별개로, MEC 플랫폼 서비스로서의 메시지 브로커, 및 로컬 가속기로의 트랙픽을 조종하는 또 다른 MEC 플랫폼 서비스를 수용할 수 있다. 서비스를 MEC 앱 또는 플랫 폼 서비스로서 실행할 선택은 구현 별로 다를 수 있으며 서비스에 액세스하는데 필요한 공유 및 인증의 레벨을 고려할 수 있다. 메시지 브로커와 같은 MEC 서비스는 처음에 MEC 앱으로서 배치되고 그 다음에는 MEC 플 랫폼 서비스로서 이용 가능해질 수 있다. 일부 양태에서, AMF는 이동성 관련 절차를 핸들링하도록 구성된다. 또한, AMF는 RAN 제어 평면 및 비 액세스 계층(Non-Access Stratum)(NAS) 절차의 종료, 시그널링 무결성의 보호, 등록, 연결 및 도달 가능성의 관리, 액세스 및 이동성 이벤트에 대한 임의의 차단 기능과의 인터페이스, 액세스 계층에 대한 인증 및 인가의 제공, 및 보안 앵커 기능성(Security Anchor Functionality)(SEAF)의 호스팅을 담당한다. 일부 양태에서, AMF는 다른 NF에 통신 및 도달성 서비스를 제공하도록 구성될 수 있고, 구독이 이동성 이벤트에 관한 통 지를 수신할 수 있게 할 수 있다. 일부 양태에서, SMF는 세션 관리, IP 어드레스 할당 및 관리, 동적 호스트 구성 프로토콜(Dynamic Host Configuration Protocol)(DHCP) 서비스, UPF의 선택/재 선택 및 제어, UPF에 대한 트래픽 규칙의 구성, 세션 관리 이벤트의 차단, 요금 청구, 및 로밍의 지원을 포함하는 기능을 제공하도록 구성된다. MEC 서비스는 중앙 집중화된 클라우드와 에지 클라우드 둘 모두에 제공될 수 있으므로, SMF는 UPF를 선택 및 제어하는 것은물론 트래픽 조종을 위한 규칙을 구성하도록 구성할 수 있다. SMF는 또한 5G AF로서의 MEC가 PDU 세션을 관리하고, 정책 설정 및 트래픽 규칙을 제어하고, 세션 관리 이벤트에 관한 알림을 구독할 수 있게 하는 서비스 동작을 노출하도록 구성된다. 일부 양태에서, MEC 시스템의 MEC 호스트는 에지 또는 중앙 데이터 네트워크에 배치된다. UPF는 사용자 평면 트래픽을 관리하여 데이터 네트워크의 타겟으로 하는 MEC 애플리케이션 쪽으로 조종하도록 구성될 수 있다. 데이터 네트워크 및 UPF의 위치는 네트워크 사업자가 선택하며 네트워크 사업자는 가용 사이트 시설, 지원되는 애플리케이션 및 요구 사항, 측정되거나 예상된 사용자 로드와 같은 기술 및 비즈니스 파라미터에 기 초하여 물리적 컴퓨팅 자원을 배치하도록 선택할 수 있다. MEC 호스트 및 애플리케이션의 동작을 오케스트레이 션하는 MEC 관리 시스템은 MEC 애플리케이션을 배치할 위치를 동적으로 결정할 수 있다. MEC 호스트의 물리적 배치와 관련하여 다음과 같은 옵션이 상이한 양태에서 사용될 수 있다: MEC 호스트 및 로컬 UPF는 기지국 에지 계층의 기지국과 함께 위치한다; MEC 호스트는 로컬 UPF를 포함할 수 있는 송신 노드와 함께 위치한다; MEC 호스트 및 로컬 UPF는 네트워크 집계 지점과 함께 위치한다; 및 MEC 호스트는 (예를 들어, 동일한 데이터 센터 내의) 5G 코어 네트워크 기능과 함께 위치한다. 도 72는 모바일 에지 시스템 참조 아키텍처(또는 MEC 아키텍처)를 도시한다. 도 72는 ETSI GS MEC-003 사양에 따른 기능성을 제공하는 MEC 호스트(7202 및 7204)를 갖는 MEC 아키텍처를 구체적으로 도시한다. 일부 양태에서, MEC 플랫폼 및 MEC 플랫폼 관리자에 대한 향상은 MEC 아키텍처 내에서 슬라 이스 관리, 자원 관리 및 추적성 기능(traceability function)을 제공하기 위해 사용될 수 있다. 이것은 하나 이상의 네트워크 슬라이스의 프로비저닝, 네트워크 슬라이스에 의해 사용되는 자원의 동적 관리뿐만 아니라, MEC 아키텍처 내의 자원 추적성 기능을 포함할 수 있다. 도 72를 참조하면, MEC 네트워크 아키텍처는 MEC 호스트(7202 및 7204), 가상화 인프라스트럭처 관리자 (Virtualization Infrastructure Manager)(VIM), MEC 플랫폼 관리자, MEC 오케스트레이터, 동작 지원 시스템, 사용자 앱 프록시, UE 상에서 동작하는 UE 앱, 및 CFS 포털(721 6)을 포함할 수 있다. MEC 호스트는 필터링 규칙 제어 컴포넌트, DNS 핸들링 컴포넌트, 서 비스 레지스트리 및 MEC 서비스를 갖는 MEC 플랫폼을 포함할 수 있다. MEC 서비스는 가상화 인프라스트럭처 상에 MEC 앱(또는 NFV)(7226, 7227, 7228)을 인스턴스화하기 위한 자원을 선택하 는데 사용될 수 있는 적어도 하나의 스케줄러를 포함할 수 있다. MEC 앱(7226 및 7228)은 하나 이상의 무선 연 결(예를 들어, 하나 이상의 RAN 또는 텔레콤-코어 네트워크 엔티티와의 연결)과 연관된 상이한 유형의 네트워크 통신 트래픽을 처리하는 것을 포함할 수 있는 서비스(7230 및 7231)를 제공하도록 구성될 수 있다. MEC 호스트 내에서 인스턴스화된 MEC 앱은 MEC 호스트 내에서 인스턴스화된 MEC 앱(7226-7728)과 유사 할 수 있다. 가상화 인프라스트럭처는 MP2 인터페이스를 통해 MEC 플랫폼에 결합된 데이터 평면을 포함한다. MEC 아키텍처의 다양한 네트워크 엔티티 간의 추가 인터페이스가 도 72에 도시되어 있다. MEC 플랫폼 관리자는 MEC 플랫폼 요소 관리 컴포넌트, MEC 앱 규칙 및 요구 사항 관리 컴포넌트 , 및 MEC 앱 라이프 사이클 관리 컴포넌트를 포함할 수 있다. MEC 아키텍처 내의 다양한 엔 티티는 ETSI GS MEC-003 사양에 의해 개시된 바와 같은 기능성을 수행할 수 있다. 일부 양태에서, 원격 애플리케이션(또는 앱)은 MEC 오케스트레이터 및 MEC 플랫폼 관리자를 통해 (예를 들어, MEC 앱(7226-7728)을 갖는) MEC 호스트와 통신하도록 구성된다. 도 73은 상이한 에지 레벨에서 MEC 배치 옵션을 갖는 에지 네트워크를 도시한다. 도 73을 참조하면, 에 지 네트워크는 각각의 계층이 상이한 배치 규모로 구성된 에지 계층을 통해 원격 클라우드에 결합될 수 있는 컴퓨팅 디바이스를 포함한다. 예를 들어, 컴퓨팅 디바이스는 (배치 규모가 10000x 보다 클 수 있는) 액세스 레벨 에지, (배치 규모가 100x-1000x 일 수 있는) 로컬/지역 레벨 에지 및 (배치 규모가 10x-100x 일 수 있는) 국가 레벨 에지를 통해 (배치 규모가 1x-10x인 글로벌 레벨 에지 계층일 수 있는) 원격 클라우드에 결합된다. 액세스 레벨 에지는 각각 하나 이상의 API(7322, 7324 및 7326)를 사용하여 로컬/지역 레벨 에지와 통신할 수 있는, 매크로 기지국, 원격 라디오 헤드(Remote Radio Head)(RRH) 및 마이크로 기지국 을 포함할 수 있다. 로컬/지역 레벨 에지는 대응하는 애플리케이션(7332 및 7334)을 사용하여 국가 레벨 에지와 통신하 는 네트워크 노드(7328 및 7330)를 포함할 수 있다. 네트워크 노드(7328 및 7330)는 (예를 들어, CDN 서비스를위한) 송신 자원의 설정을 수행하도록 구성될 수 있다. 국가 레벨 에지는 글로벌 레벨 에지 내의 원격 클라우드에 액세스하기 위한 애플리케이션 을 사용할 수 있는 네트워크 노드를 포함할 수 있다. 네트워크 노드는 버티컬 세그먼트 관 리 및 SLA 준수를 위해 구성될 수 있다. 일부 양태에서, MEC 배치는 \"에지\"의 정의에 기초할 수 있다. 특히 (이 양태에서, MEC 엔티티가 가상화된 네트 워크 기능(VNF)으로서 인스턴스화될 수 있고, 그래서 사업자를 위한 배치 측면에서 높은 유연성을 갖는) NFV 환 경에서 MEC를 배치할 때, 모바일 네트워크 사업자(MNO)에게 필요한 자유도를 제공하기 위해, 몇몇 옵션이 MEC 표준에 의해 허용된다. 일부 양태에서, MEC는 처리될 유스 케이스/버티컬 세그먼트/정보에 따라 유연하게 배치될 수 있다. 더욱이, MEC 시스템의 일부 컴포넌트는 시스템의 다른 요소와 함께 위치될 수 있다. 예로서, 특정 유스 케이스(예를 들 어, 기업)에서, MEC 앱은 MEC 서비스를 로컬로 소비할 필요가 있을 수 있으며, 필요한 API 세트가 로컬로 구비 된 MEC 호스트를 배치하는 것이 효율적일 수 있다. 다른 양태에서, (액세스 네트워크로부터 멀리 떨어져 있을 수 있는) 데이터 센터에 MEC 서버를 배치하는 것은 무선 기지국으로부터 무선 네트워크 정보를 수집하기 위해 사용될 수 있는 무선 네트워크 정보(Radio Network Information)(RNI) API와 같은 일부 API를 호스팅할 필요가 없다. 한편, RNI 정보는 집계 지점에서 정교하게 만들어져 클라우드 RAN(CRAN) 환경에 이용 가능하고, 이에 따 라 적합한 무선 인식 트래픽 관리 알고리즘을 실행할 수 있다. 일부 다른 양태에서, 대역폭 관리 API는 (예를 들어, 콘텐츠 전송 네트워크(CDN) 기반 서비스를 위한) 송신 네트워크를 설정하기 위해, 액세스 레벨 에지 에서 그리고 또한 더 원격의 에지 위치 둘 모두에서 제공될 수 있다. 도 74는 5G 시스템 아키텍처에서 MEC 지원을 도시한다. 도 74를 참조하면, 5G 시스템 아키텍처는 도 69의 5G 시스템 아키텍처와 유사하다(도 74는 도 69의 5G 시스템 아키텍처에 의해 사용되는 네 트워크 기능의 서브세트만을 도시한다. 보다 구체적으로, 5G 시스템 아키텍처는 무선 액세스 네트워크 (RAN)에 결합된 UE를 포함한다. 5G 시스템 아키텍처는 AMF, SMF, UPF(7410, 7412 및 7416)를 더 포함한다. UPF는 데이터 네트워크에 결합되고 UPF는 데이터 네트워크 에 결합된다. 일부 양태에서, 5G 네트워크에서 MEC 지원을 제공하기 위해, 5G 네트워크는 UE에 가까운 UPF를 선택하고 N6 인 터페이스를 통해 UPF로부터 로컬 DN으로의 트래픽 조종을 실행할 수 있다. 5G 시스템에서 에지 컴퓨팅을 지원 하는 기능성은 로컬 라우팅(5G 코어 네트워크는 UPF를 선택하여 사용자 트래픽을 로컬 DN으로 라우팅함), 트래 픽 조종(5G 코어 네트워크는 로컬 DN의 애플리케이션으로 라우팅할 트래픽을 선택함), UE 및 애플리케이션 이동 성을 가능하게 하는 세션 및 서비스 연속성, 사용자 평면 선택 및 재선택(예를 들어, AF로부터의 입력에 기초하 여, AF는 UPF (재) 선택 및 트래픽 라우팅에 영향을 미침), 네트워크 캐퍼빌리티 노출(5G 코어 네트워크와 AF는 NEF를 통해 서로 정보를 제공할 수 있음), 서비스 품질(QoS) 및 요금 청구(PCF는 로컬 DN으로 라우팅되는 트래 픽에 대한 QoS 제어 및 과금에 대한 규칙을 제공하도록 구성될 수 있음), 및 로컬 영역 데이터 네트워크(Local Area Data Network)(LADN)의 지원(5G 코어 네트워크는 애플리케이션이 배치되는 특정 영역에서의 LADN에 연결하 는 지원을 제공함)을 포함한다. 일부 양태에서, 5G 네트워크 내의 통합된 MEC 배치는 로컬 라우팅 및 트래픽 조종을 사용하여 구성될 수 있다. 일부 양태에서, UPF는 업링크 분류기로서 구성될 수 있고, UPF(7412 및 7416)는 각각 DN(7414 및 7418)과의 통신(예를 들어, 두 개의 데이터 네트워크로의 동시 액세스)을 위한 PDU 세션 앵커로서 구성될 수 있 다. 업링크 분류기는 상이한 PDU 세션 앵커(예를 들어, (7412 및 7416))를 향한 업링크 트래픽의 포워딩 및 UE로의 다운링크 트래픽의 병합(예를 들어, UE를 향한 링크 상의 상이한 PDU 세션 앵커로부터의 트래픽의 병합)을 제공하도록 구성될 수 있다. 5G 네트워크는 MEC 시스템의 일부일 수 있는 로컬 데이터 네트워크(예를 들어, )의 애플리케이션으 로 라우팅될 트래픽을 선택하도록 구성될 수 있다. PDU 세션은 하나 이상의 데이터 네트워크(예를 들어, (7414 및 7418))를 향하는 다수의 N6 인터페이스를 가질 수 있다. 이러한 인터페이스를 종료하는 UPF(예를 들어, (7412 및 7416))는 PDU 세션 앵커 기능을 지원하도록 구성될 수 있다. 일부 양태에서, UPF에 의한 트래 픽 조종은 조종된 트래픽과 매칭하는 한 세트의 트래픽 필터에 대해 동작하는 업링크 분류기에 의해 지원되거나, 대안적으로 다수의 IPv6 프리픽스가 해당 PDU 세션과 연관되는 IPv6 다중 호밍에 의해 지원된다. 도 75, 도 76 및 도 77은 예에 따른 5G 시스템에서 MEC 매핑을 도시한다. 도 75를 참조하면, 도 72의 MEC 아키 텍처와 유사한 MEC 아키텍처가 도시된다. 보다 구체적으로, MEC 아키텍처의 네트워크 요소 (7502-7548)는 MEC 아키텍처의 네트워크 요소(7202-7748)에 대응한다. 도 75는 (도 69의 5G 네트워크 아키텍처와 같은) 예시적인 5G 네트워크의 UPF 및 MEC 아키텍처 에 UPF의 매핑을 또한 도시한다. UPF는 PDU 세션의 사용자 평면 경로를 핸들링한다. 또한, UPF는 데이터 네트워크와의 인터페이스를 제공하고 PDU 세션 앵커의 기능성을 지원한다. 이와 관련하여, 3GPP(예를 들어, 5G) 아키텍처에서 UPF는 MEC 데이터 평면에 대해 ETSI에서 정의된 기능성에 대응 할 수 있다. 도 76을 참조하면, 도 72의 MEC 아키텍처와 유사한 MEC 아키텍처가 도시된다. 보다 구체적으로, MEC 아키텍처의 네트워크 요소(7602-7648)는 MEC 아키텍처의 네트워크 요소(7202-7748)에 대응한 다. 도 76은 또한 (도 71의 5G 네트워크 아키텍처와 같은) 예시적인 5G 네트워크의 AF 및 MEC 아키텍처 로의 AF의 매핑을 도시한다. AF는 다음과 같은 고 레벨 기능성: 트래픽 라우팅에 미치는 애 플리케이션 영향, 액세스 네트워크 기능성 노출 및 정책 제어를 위한 정책 프레임워크와의 상호작용을 수행하도 록 구성된다. 이와 관련하여, 3GPP(예를 들어, 5G) 아키텍처의 AF은 MEC 플랫폼에 대해 ETSI에서 정의된 기능성에 대응할 수 있다. 도 77을 참조하면, 도 70의 5G 아키텍처와 유사한 5G 아키텍처가 도시된다. 보다 구체적으로, 5G 아키텍처의 네트워크 요소(7702-7744)는 5G 아키텍처의 네트워크 요소(7002-7044)에 대응한다. MEC 호스트는 5G 아키텍처(AF 및 UPF는 각각 MEC 플랫폼 및 MEC 데이터 평면에 각각 대응함)에서 AF 및 UPF에 연관(또는 매핑)될 수 있다. 또한, 3GPP 아키텍처에서 사용자 트래픽이 로컬 데이터 네트워크로 라우팅되기 때문에, MEC 앱은 DN에 위치한 바와 같이 5G 아키텍처에서 매핑될 수 있다. 도 78은 예에 따른 5G 시스템에서 MEC 배치를 도시한다. 보다 구체적으로, 도 78은 3GPP 기반 5G 시스템 아키 텍처 및 5G 시스템의 일부 컴포넌트(즉, AF 및 UPF)에 MEC 엔티티의 매핑의 예를 도시한다. 아키텍처 는 ETSI GS MEC-003 사양 및/또는 ETSI GR MEC-017 사양에 따른 기능성을 제공하도록 구성될 수 있다. 도 78을 참조하면, 5G 아키텍처는 UE, (VNF에 기초한 가상 RAN일 수 있는) RAN, UPF(7836 및 7818), SMF, PCF, AF, 로컬 DN, 중앙 DN 및 애플리케이션 서버를 포 함한다. UPF는 네트워크 기능 가상화 인프라스트럭처((Network Function Virtualization Infrastructure)(NFVI) 내에서 MEC 데이터 평면으로서 기능하도록 구성될 수 있다. AF는 MEC API(7824 및 7826), (예를 들어, ETSI GS MEC-011 사양에 따른) MEC 애플리케이션 실시 가능 기능성 및 (예를 들어, ETSI GS MEC-009 사양에 따른) API 원리 기능성을 갖는 MEC 플랫폼 VNF로서 구성될 수 있다. 로컬 DN은 VNF로서 인스턴스화된 MEC 앱(7832 및 7834)을 포함할 수 있다. 본 명세서에 개시된 기술은 MEC 아키텍처에서 5G 네트워크 슬라이싱을 효율적으로 지원하기 위해 사용될 수 있 다. 고려되는 5G 통신 시스템은 MEC 시스템 컴포넌트를 통합하며, 그 아키텍처는 5G 네트워크에 배치된 3GPP TS 23.501에 명시되고, 그 시스템 아키텍처는 ETSI GS MEC-003에 명시되어 있다. 모든 논리적 기능(예를 들어, 네트워크 기능(NF) 및 애플리케이션 기능(AF))을 가상화 기능으로서 간주하는 것으로 가정한다. MEC 엔 티티를 5G 시스템으로 매핑하는 것이 도 78에 도시되어 있다. 특히: MEC 플랫폼은 3GPP에서 특정 애플리케이션 기능(AF)으로서 구현되고; MEC 아키텍처의 데이터 평면은 3GPP의 사용자 평면 기능(UPF)에 대응하 고, MEC 앱(7832 및 7834)은 3GPP의 로컬 DN에 매핑된다. 일부 양태에서, 시작 지점은 엔드-투-엔드(End-to-End)(E2E) 5G 시스템 성능이 무선 액세스 네트워크(RAN) 및 텔레콤-코어 네트워크(Telecom-Core Network)(CN) 시스템 컴포넌트의 성능뿐만 아니라 MEC 기능 엔티티의 성능 에 따라 달라진다는 것을 고려한다. 예: (예를 들어, UE와 MEC 애플리케이션 사이의) E2E 지연시간은 (신뢰도 98 %로 UE와 UPF 사이의 E2E 지연으로 서 5G에서 정의되는) 패킷 지연 예산(Packet Delay Budget)(PDB) 및 UPF와 (MEC 앱이 위치한) 로컬 DN 사이의 추가 지연으로 구성된다. 이러한 제 2 지연시간 컴포넌트는 MEC 애플리케이션의 인스턴스화와 밀접하게 관련되 어 있기에 성능 최적화에 중요하겠지만, 3GPP에서 5G QoS 클래스 식별자(5G QoS Class Identifier)(5QI) 특성 에 의해 고려되지 않는다. 그 결과, 사용자 트래픽 종료 지점이 (DN에 위치한) MEC 앱에 있기 때문에, (PDB와 같은) 네트워크 슬라이스 관련 성능 메트릭은 전체 E2E 성능을 설명하기에 충분하지 않다. 대신에, 슬라이스 요구 사항에 따라, 전체 E2E 지연시간을 줄이기 위해 MEC 애플리케이션 인스턴스화 및 관련된 가상 머신(VM) 할당이 신중하게 고려된다. 일부 양태에서, 주어진 네트워크 슬라이스의 경우, MEC 시스템 배치를 통합하는 가상화된 5G 시스템의 E2E 성능 은 (예를 들어, UPF를 이용하여 종료하는, 3GPP에 의해 정의되는 바와 같이) 5G QoS 클래스 식별자(5QI) 특성 만으로 완전히 설명될 수 없지만, 사용자 트래픽이 MEC 앱 인스턴스에서 종료되기 때문에 MEC 시스템 성능에 따 라 달라지며; E2E 시스템 성능이 각 슬라이스의 요구 사항을 준수하기 위해, MEC 아키텍처 엔티티가 UE와 5G 가 상화된 네트워크 기능(VNF)에 둘 모두 연결되어야 하므로, 최적의 MEC 배치는 네트워크 슬라이스에 따라 다르다. 일부 양태에서, MEC 시스템은 슬라이스 인식 전략에 따라, 다수의 슬라이스를 수용하고 MEC 앱의 인스턴스화 및 에지 클라우드 전반에서 VM의 할당을 개선하기 위해, (완전 가상화된) 5G 시스템에 배치될 수 있다. 이러한 할 당의 목표는 (네트워크 사업자와 버티컬 산업 간의 서비스 레벨 협약(SLA)의 일부인 것으로 추정되는) 슬라이스 의 E2E 성능 요구 사항을 충족시키 것이다. 도전과제를 해결할 선행 기술: 5G 네트워크를 위한 3GPP 표준은 PDB(패킷 지연 예산)을 UE와 UPF 사이에서 패킷 이 지연될 수 있는 시간의 상한으로서 명시할 수 있고, 그래서 사용자 평면 트래픽 경로(예를 들어, 도 78에 도 시된 바와 같이, N6 인터페이스를 통해 UPF로부터 MEC 앱으로)의 최종 부분을 고려하지 않는다. 이와 관련하여, MEC 앱은 3GPP 네트워크 외부의 엔티티이므로, 3GPP에는 실제 총 E2E 성능을 보장하는 표준 수단/파 라미터가 아직 없다. 더욱이, 특정 네트워크 슬라이스를 인스턴스화할 때, 5G 네트워크 내에 배치될 MEC 시스 템과, 슬라이스 특정 VM 할당 및 MEC와 3GPP 관련 엔티티를 통한 핸드오프를 수행하고 슬라이스 성능 준수 이동 성 관리를 적용할 5G 네트워크 오케스트레이터 간의 (논리적) 인터페이스에 대한 표준 정의가 아직 없다. 도 79는 네트워크 슬라이싱과 관련하여 제어 유닛 제어 평면(Control Unit Control Plane)(CU-CP) - 제어 유닛 사용자 평면(Control Unit User plane)(CU-UP) 분리를 갖는 예시적인 5G-NR 아키텍처의 컴포넌트를 도시한다. 도 79를 참조하면, 5G-NR 아키텍처는 5G 코어(5G Core)(5GC) 및 NG-RAN을 포함할 수 있다. NG-RAN는 gNB(7908 및 7910)와 같은 하나 이상의 gNB를 포함할 수 있다. 일부 양태에서, NG- RAN의 네트워크 요소는 중앙 및 분산 유닛으로 분할될 수 있고, 상이한 중앙 및 분산 유닛, 또는 중앙 및 분산 유닛의 컴포넌트는 상이한 프로토콜 기능(예를 들어, 프로토콜 계층의 상이한 프로토콜 기능)을 수행하도 록 구성될 수 있다. 일부 양태에서, gNB는 gNB 중앙 유닛(gNB Central Unit)(gNB-CU) 및 gNB 분산 유닛(들)(gNB Distributed Unit)(gNB-DU)(7924, 7926) 중 하나 이상을 포함하거나 그 하나 이상으로 분할될 수 있다. 또한, gNB는 gNB-CU-제어 평면(gNB-CU-Control Plane)(gNB-CU-CP) 및 gNB-CU-사용자 평면(gNB-CU-User Plane)(gNB-CU-UP) 중 하나 이상을 포함하거나 그 하나 이상으로 분할될 수 있다. gNB-CU는 무선 자원 제어(Radio Resource Control)(RRC) 계층, 서비스 데이터 적응 프로토콜(Service Data Adaptation Protocol)(SDAP) 계층, 및 gNB 또는 RRC의 패킷 데이터 수렴 프로토콜 계층(Packet Data Convergence Protocol Layer)(PDCP) 프로토콜, 및 하나 이상의 gNB-DU의 작동을 제어하는 E-UTRA-NR gNB(en-gNB)의 PDCP 프로토콜을 호스팅하도록 구성된 논리적 노드이다. gNB-DU(예를 들어, 또는 )는 gNB의 무선 링크 제어 계층 (Radio Link Control layer)(RLC), 매체 액세스 제어 계층(Medium Access Control layer)(MAC) 및 물리 계층 (PHYsical layer)(PHY)을 호스팅하도록 구성된 논리적 노드이며 그 동작은 gNB-CU에 의해 적어도 부분적 으로 제어된다. 일부 양태에서, 하나의 gNB-DU(예를 들어, 7924)는 하나 또는 다수의 셀을 지원할 수 있다. gNB-CU-CP는 en-gNB 또는 gNB에 대한 gNB-CU의 PDCP 프로토콜의 제어 평면 부분 및 RRC를 호스팅 하도록 구성된 논리적 노드이다. gNB-CU-UP는 en-gNB에 대한 gNB-CU(7922E)의 PDCP 프로토콜의 사용자 평면 부분과, gNB에 대한 gNB-CU의 PDCP 프로토콜 및 SDAP 프로토콜의 사용자 평면 부분을 호스팅하도록 구성된 논리적(또는 물리적) 노드이다. gNB-CU와 gNB-DU(7924, 7926)는 F1 인터페이스를 통해 통신할 수 있으며, gNB는 Xn-C 인터페이스 를 통해 gNB-CU와 통신할 수 있다. gNB-CU-CP와 gNB-CU-UP는 E1 인터페이스(들)를 통해 통 신할 수 있다. 또한, gNB-CU-CP와 gNB-DU(7924, 7926)는 F1-C 인터페이스를 통해 통신할 수 있으며, gNB-DU(7924, 7926)와 gNB-CU-UP는 F1-U 인터페이스를 통해 통신할 수 있다. 일부 양태에서, gNB-CU는 gNB-DU(7924, 7926)와 연결된 F1 인터페이스를 종료하고, 다른 양태에서, gNB- DU(7924, 7926)는 gNB-CU와 연결된 F1 인터페이스를 종료한다. 일부 양태에서, gNB-CU-CP는 gNB- CU-UP와 연결된 E1 인터페이스 및 gNB-DU(7924, 7926)와 연결된 F1-C 인터페이스를 종료한다. 일부 양태에서, gNB-CU-UP는 gNB-CU-CP와 연결된 E1 인터페이스 및 gNB-DU(7924, 7926)와 연결된 F1-U 인 터페이스를 종료한다. 일부 양태에서, F1 인터페이스는 엔드포인트 사이의 포인트-투-포인트 인터페이스이고, 엔드포인트 사이의 시그 널링 정보의 교환 및 각각의 엔드 포인트로의 데이터 송신을 지원한다. F1 인터페이스는 제어 평면과 사용자 평면의 분리를 지원하고 무선 네트워크 계층과 전송 네트워크 계층을 분리할 수 있다. 일부 양태에서, E1 인터 페이스는 gNB-CU-CP와 gNB-CU-UP 사이의 포인트-투-포인트 인터페이스이고 엔드 포인트 사이의 시그널링 정보의 교환을 지원한다. E1 인터페이스는 무선 네트워크 계층과 전송 네트워크 계층을 분리할 수 있으며, 일부 양태 에서, E1 인터페이스는 사용자 데이터 포워딩에 사용되지 않는 제어 인터페이스일 수 있다. NG-RAN을 참조하면, NG-RAN의 gNB(7808, 7910)는 NG 인터페이스를 통해 5GC와 통신할 수 있 고, Xn 인터페이스를 통해 다른 gNB와 상호연결될 수 있다. 일부 양태에서, gNB(7808, 7910)는 FDD 모드, TDD 모드 또는 이중 모드 동작을 지원하도록 구성될 수 있다. 특정 양태에서, EN-DC의 경우, gNB-CU 및 gNB-DU로 구성된 gNB에 대한 S1-U 인터페이스 및 X2 인터페이스(예를 들어, X2-C 인터페이스)는 gNB-CU에서 종료될 수 있 다. 일부 양태에서, gNB는 CP/UP 분리를 지원하고 단일 CU-CP 엔티티, 다수의 CU-UP 엔티티 및 다수의 DU 엔티티(7924, ... 7926)을 포함하며, 모든 엔티티는 네트워크 슬라이스 동작을 위해 구성된다. 도 79에 도시된 바와 같이, 각각의 DU 엔티티(7924, …7926)는 F1-C 인터페이스를 통해 CU-CP과 단일 연결을 가질 수 있다. 각각의 DU 엔티티(7924,…7926)는 F1-U 인터페이스를 사용하여 다수의 CU-UP 엔티티에 연 결될 수 있다. CU-CP 엔티티는 E1 인터페이스를 통해 다수의 CU-UP 엔티티에 연결될 수 있다. 각 각의 DU 엔티티(7924,…7926)는 하나 이상의 UE에 연결될 수 있고, CU-UP 엔티티는 사용자 평면 기능 (UPF) 및 5G 코어에 연결될 수 있다. 일부 양태에서, gNB 내의 엔티티는 CP/UP의 분리를 가진 NG-RAN 내의 인터페이스 또는 무선 베어러 와 연관된 하나 이상의 절차를 수행할 수 있다. 예를 들어 NG-RAN은 5G 및 MEC 아키텍처 내의 동작과 관 련하여 네트워크 슬라이스 구성과 연관된 다음의 절차를 지원할 수 있다. E1 인터페이스 셋업: 이 절차는 E1 인터페이스를 설정할 수 있게 하며, 인터페이스 동작에 필요한 파라미터의 교환을 포함한다. E1 셋업은 CU-CP에 의해 개시된다; E1 인터페이스 리셋: 이 절차는 구성 파라미터의 변경을 비롯한, E1 인터페이스를 리셋할 수 있게 한다. E1 인 터페이스 리셋은 CU-CP 또는 CU-UP에 의해 개시된다; E1 오류 표시: 이 절차는 하나의 들어오는 메시지에서 검출된 오류를 보고할 수 있게 한다. E1 인터페이스 리 셋은 CU-CP 또는 CU-UP에 의해 개시된다; E1 로드 정보: 이 절차는 CU-UP가 CU-CP에 주기적으로 우세한 로드 조건을 알릴 수 있게 한다. 동 일한 절차가 오버로드 상태(시작/중지)를 갖는 CU-UP의 오버로드를 표시하는데 또한 사용될 수 있다; E1 구성 업데이트: 이 절차는 용량 변경과 같은 CU-UP 구성의 업데이트를 지원한다; 데이터 무선 베어러(Data Radio Bearer)(DRB) 셋업: 이 절차는 CU-CP가 보안 키 구성 및 DRB 매핑 구성 으로 서비스 품질(quality of service)(QoS) 흐름을 비롯하여, CU-CP에서 DRB를 리셋할 수 있게 한다; DRB 수정: 이 절차는 CU-CP가 보안 키 구성의 수정 및 DRB 매핑 구성으로 QoS 흐름의 수정을 비롯하여, CU-CP에서 DRB를 수정할 수 있게 한다; DRB 해제: 이 절차는 CU-CP가 CU-CP에서 DRB를 해제할 수 있게 한다; 그리고 다운링크 데이터 통지(Downlink Data Notification)(DDN): 이 절차는 CU-UP가 CU-CP에게 RRC 비활 성 상태를 지원하도록 페이징 절차를 트리거할 것을 요청할 수 있게 한다. 일부 양태에서, NG-RAN은 CU-UP로부터의 자원 가용성 표시, CU-UP에서 자원 관리, 및 CU- UP로부터 지연시간 표시를 포함하는 네트워크 슬라이싱을 위한 E1 인터페이스 관리 절차를 지원하도록 구 성될 수 있다. 일부 양태에서, NG-RAN은 DU 엔티티(7924,…8426)로부터 자원 가용성 표시, DU 엔티티(7924, …7926)에 서 자원 관리, 및 DU 엔티티(7924, …7926)로부터 지연시간 표시를 포함하는 네트워크 슬라이싱을 위한 F1-C 인터페이스 관리 절차를 지원하도록 구성될 수 있다. 일부 양태에서, NG-RAN은 F1-U 인터페이스를 통해 지연시간 측정을 지원하여 DU 엔티티(8424, …7926) 및 CU-UP 엔티티를 포함하는 UP 요소가 다른 인접한 UP 요소에 지연시간 정보를 통신할 수 있도록 구성될 수 있다. 이와 관련하여, 네트워크 슬라이싱은 CP/UP 분리를 갖는 NG-RAN에서 지원될 수 있다. 일부 양태 에서, 슬라이스 레벨 격리 및 개선된 자원 활용은 CU-CP의 중앙 RRM에 의해 제공될 수 있다. 일부 양태에서, 네트워크 슬라이싱과 연관된 절차는 E1 인터페이스, F1-C 인터페이스 및 F1-U 인터페이스를 통 한 동작 및 통신을 포함한다. 이러한 절차를 통해, CU-CP는 적절한 DU 및 CU-UP 엔티티를 선택하여 특정 서비스 레벨 협약(SLA)과 연관된 특정 네트워크 슬라이싱 요청을 서빙한다. 일부 양태에서, E1 인터페이스를 통한 절차는 CU-UP 엔티티로부터 정보 수집 및 CU-CP에서 자원 관 리를 포함할 수 있다. 구체적으로, 정보 수집은 자원 가용성 표시 및 지연시간 표시를 포함할 수 있는 반면, 자원 관리는 자원 할당 및 자원 해제를 포함할 수 있다. CU-CP는 CU-UP 엔티티로부터 정보를 주기 적으로 수집하거나 네트워크 슬라이스 요청에 기초하여 주문형 쿼리를 발행하도록 구성될 수 있다. 일부 양태 에서, 자원 가용성 표시 절차는 CU-UP 엔티티가 자원의 가용성을 CU-CP에 통지하여 네트워크 슬라 이싱 요청을 처리할 수 있게 할 수 있다. 예를 들어, 가용 자원의 표시는 특정 CU-UP가 특정 SLA와 연관된 특 정 네트워크 슬라이스 요청을 서빙할 수 있는지를 결정하도록 CU-CP를 보조할 수 있다. 일부 양태에서, 자원 할당 절차는 CU-CP가 특정 슬라이스와 연관된 CU-UP의 자원을 할당할 수 있게 한다. 네트워크 슬라이스 생성에 대한 요청을 수신하면, CU-CP는 표시된 SLA에 따라 CU-UP(예를 들어, CU-UP 엔티티 중 하나)를 선택하고 선택된 CU-UP의 자원을 네트워크 슬라이스에 할당할 수 있다. 일부 양태에서, 자원 해제 절차는 CU-CP가 설정된 네트워크 슬라이스에 할당된 CU-UP의 자원을 해제할 수 있게 한다. 슬라이스가 제거되면, CU-CP는 대응하는 CU-UP에게 제거된 네트워크 슬라이스에 의해 사용된 자원 을 해제할 것을 통지할 수 있다. 도 80은 예시적인 네트워크 슬라이스(8008 및 8010)를 갖는 다이어그램을 도시한다. RAN은 UE에 대해 미리 구성된 격리된 RAN 슬라이스(8008 및 8010) 간의 트래픽의 차별화된 핸드링을 지원할 수 있다. 이를 수행하는 방법은 구현에 맡길 수 있다. RAN 슬라이스의 선택은 디바이스 또는 텔레콤-코어 네트워 크에 의해 제공되는 (위에 정의된 슬라이스 서비스 유형 및 슬라이스 차별화 요소(differentiator)일 수 있는) ID에 기초할 것이다. RAN 슬라이스는 주어진 위치에서 이용 가능하거나 이용 가능하지 않을 수 있다. RAN은 텔레콤-코어 네트워크 슬라이스를 선택할 수 있다. RAN 슬라이스 내의 QoS 차별화도 지원될 것이다. 본 명세서에서 사용되는 것으로, \"네트워크 슬라이싱\"이라는 용어는 다양한 세트의 수직적 요구 사항을 충족하 도록 맞춤화된 다수의 가상 네트워크로 물리적 네트워크를 분할하는 것을 말한다. 네트워크 슬라이싱은 Rel.15 및 그 이상과 관련될 수 있으며, 관련 있는 3GPP 사양은 TS 23.501(5GS 아키텍처), TS 22.261(5G 요구 사항) 및 TS 28.531/28.532(5G 슬라이스 관리)를 포함한다. 도 80을 참조하면, 공통 네트워크 기능 내의 네트워크 슬라이스 선택 기능(Network Slice Selection Function)(NSSF)은 UE를 서빙하는 네트워크 슬라이스 인스턴스를 선택하는 것, 허용된 네트워크 슬라이스 선택 보조 정보(Network Slice Selection Assistance Information)(NSSAI)를 결정하는 것 및 UE를 서빙하는데 사용될 AMF 세트를 결정하는 것을 지원한다. NSSF는 EPC에서 존재하지 않는 새로운 기능성으로서 구성될 수 있 다. 네트워크 슬라이스 템플릿(Network Slice Template)(NST)은 네트워크 슬라이스 정보 객체 클래스 (Information Object Class)(IOC)의 인스턴스의 생성에 사용되는 속성 값의 서브세트로서 정의된다. NST의 컨 텐츠는 모바일 네트워크 사업자(MNO) 및 공급 업체에 의해 정의되고 있는 것과 같이, 3GPP에 의해 표준화되지 않을 수 있다. 일부 양태에서, 슬라이스 선택은 UE에 의해 전송된 보조 정보(NSSAI)가 를 갖는 네트워크 슬라이스 정책에 기초 하여 네트워크(AMF 또는 NSSF)에 의해 결정된다. 일부 양태에서, UE 당 최대 8 개의 네트워크 슬라이스가 사용 될 수 있다. 자동차의 예: 차량은 상이한 슬라이스/서비스 타입(Slice/Service Type)(SST)에 속하는 다수의 슬라이스 인스턴 스(8008 및 8010)에 동시에 연결되고 대응하는 데이터 네트워크(8012 및 8014)에 결합되어, 다수의 자동차 유스 케이스의 상이한 성능 요구 사항을 지원해야 할 수 있다. 예를 들어, 소프트웨어 업데이트 및 원격 운전 유스 케이스는 KPI 요구 사항에 기초하여 eMBB 슬라이스 및 URLLC 슬라이스와 각각 연관될 수 있다. 도 81은 슬라이스 관리, 자원 관리 및 추적성 기능을 지원하는 MEC 네트워크 아키텍처를 도시한다. 도 81은 구체적으로 ETSI GS MEC-003 사양에 따른 기능성을 제공하는 MEC 호스트(8102 및 8104)를 갖는 MEC 아키 텍처를 구체적으로 도시하여, 여기서 음영 블록은 슬라이스 관리, 자원 관리 및 추적성 기능과 관련하여 본 명세서에서 설명된 MEC 아키텍처 구성에 대한 처리 양태를 표시하는데 사용된다. 구체적으로, MEC 플랫폼 및 MEC 플랫폼 관리자에 대한 향상은 MEC 아키텍처 내의 슬라이스 관리, 자원 관리 및 추적 성 기능을 제공하는데 사용될 수 있다. 이것은 하나 이상의 네트워크 슬라이스 프로비저닝, 네트워크 슬라이스 에 의해 사용되는 자원의 동적 관리는 물론이고, MEC 아키텍처 내의 자원 추적성 기능을 포함할 수 있다. 제한 된 수의 MEC 컴포넌트(예를 들어, 서비스, 애플리케이션, 관리자)가 본 명세서 및 다른 도면에 도시되어 있지만, MEC 배치는 예시된 것보다 훨씬 더 많은 컴포넌트를 포함할 가능성이 있다. 추가 예에서, MEC 아키텍처의 모든 엔티티는 LSM 또는 다른 보안 정책을 로드하도록 설치될 수 있으며, 보안 동 작을 위한 시행 지점이 될 수 있다. 운영 및 관리 엔티티는 자원이 사용자, 워크로드, 테넌트, 도메인, u서비 스, 기능, 호스팅 환경에 할당되는 다양한 방식에 따라 LSM을 프로비저닝하는 작업을 부여받을 수 있다. 도 81을 참조하면, MEC 네트워크 아키텍처는 MEC 호스트(8102 및 8104), 가상화 인프라스트럭처 관리자 (VIM), MEC 플랫폼 관리자, MEC 오케스트레이터, 동작 지원 시스템, 사용자 앱 프록 시, UE 상에서 실행되는 UE 앱 및 CFS 포털을 포함할 수 있다. MEC 호스트는 필터링 규칙 제어 컴포넌트, DNS 핸들링 컴포넌트, 서비스 레지스트리 및 MEC 서비스 를 갖는 MEC 플랫폼을 포함할 수 있다. MEC 서비스는 가상화 인프라스트럭처에서 MEC 앱(또 는 NFV)(8126 및 8128)을 인스턴스화하기 위한 자원을 선택하는데 사용될 수 있는 적어도 하나의 스케줄러 를 포함할 수 있다. MEC 앱(8126 및 8128)은 하나 이상의 무선 연결(예를 들어, 하나 이상의 RAN 또는 텔레콤-코어 네트워크 엔티티와의 연결)과 연관된 상이한 유형의 네트워크 통신 트래픽을 처리하는 것을 포함할 수 있는 서비스(8130 및 8131)를 제공하도록 구성될 수 있다. MEC 플랫폼 관리자는 MEC 플랫폼 요소 관리 컴포넌트, MEC 앱 규칙 및 요구 사항 관리 컴포넌트 , 및 MEC 앱 라이프 사이클 관리 컴포넌트를 포함할 수 있다. MEC 아키텍처 내의 다양한 엔 티티는 ETSI GS MEC-003 사양에 의해 개시된 기능성을 수행할 수 있다. 일부 양태에서, UE는 네트워크 슬라이스 중 하나 이상을 통해 원격 통신 코어 네트워크 중 하나 이상과 통신하도록 구성될 수 있다. 일부 양태에서, 원격 통신 코어 네트워크는, 슬라이스를 UE에 동적으로 할당하는 것을 포함하여 슬라이스를 동적으로 구성하고, 슬라이스를 UE에 재할당하고, 슬라이스 의 하나 이상에 의해 사용된 (MEC 자원을 포함하는) 자원을 동적으로 할당 또는 재할당하는 (예를 들어, 슬라이스 관리 모듈 또는 SMM에 의해 제공되는) 슬라이스 관리 기능 또는 다른 슬라이스 관련 관리 기능 을 사용할 수 있다. 슬라이스 관리와 관련하여 수행되는 기능 중 하나 이상의 기능은 (예를 들어, UE를 통한) 사용자 요청 또는 서비스 제공자에 의한 요청에 기초하여 시작될 수 있다. 일부 양태에서, 네트워크 슬라이스 와 관련된 슬라이스 관리 기능은 MEC 호스트 또는 MEC 플랫폼 관리자 내의 (또는 다른 MEC 엔티티 내의) SMM에 의해 제공되는 MEC 가능 5G 배치를 위한 E2E 다중 슬라이스 지원 기능에 의해 용이해 질 수 있다. 일부 양태에서, SMM은 MEC 오케스트레이터에 결합될 수 있고 다른 MEC 엔티티에도 결합될 수 있는 NFV 오케스트레이터(NFV orchestrator)(NFVO) 내에 있을 수 있다. 도 82는 네트워크 기능 가상화(NFV) 환경에서 MEC 참조 아키텍처를 도시한다. MEC 아키텍처는 ETSI GR MEC-017 사양에 따른 기능성을 제공하도록 구성될 수 있다. 일부 양태에서, ETSI MEC는 도 82에 예시된 NFV 환경에 배치될 수 있다. MEC 참조 아키텍처는 모바일 에지 플랫폼, 모바일 에지 플랫폼 관리자, 데이터 평면, 네트워크 기능 가상화 인프라스트럭처(Network Function Virtualization Infrastructure)(NFVI), 가상 네트워크 기능 관리자(Virtual Network Function Manager)(VNFM)(8220 및 8222), 및 NFVO, 모바일 에지 애플리케이션 오케스트레이터(Mobile Edge Application Orchestrator)(MEAO), 동작 지원 시스템, 사용자 앱 LCM 프록시, UE 앱 및 CFS 포털을 포함한다. 모바일 에지 플랫폼 관리자 는 MEC 플랫폼 요소 관리 및 MEC 앱 규칙 및 요구 사항 관리를 포함할 수 있다. 일부 양태에서, 모바일 에지 플랫폼은 MP3 인터페이스를 통해 다른 모바일 에지 플랫폼에 연결될 수 있다. 일부 양태에서, MEC 플랫폼은 가상화된 네트워크 기능(VNF)으로서 배치된다. MEC 애플리케이션은 ETSI NFV 관리 및 오케스트레이션(MANO) 컴포넌트를 향하는 VNF처럼 나타날 수 있다. 이것은 ETSI NFV MANO 기능성을 재사용할 수 있게 한다. 일부 양태에서, MANO 기능성의 전체 세트는 사용되지 않을 수 있으며 특정 추 가 기능성이 필요할 수 있다. 이러한 특정 ME 애플리케이션은 본 명세서에서 논의되는 바와 같이 \"ME 앱 VNF\" 라는 명칭으로 표시된다. 일부 양태에서, 가상화 인프라스트럭처는 NFVI로서 배치되고 그의 가상화된 자원은 가상화된 인프라스트럭처 관리자(Virtualized Infrastructure Manager)(VIM)에 의해 관리된다. 그 목적 을 위해, ETSI NFV 인프라스트럭처 사양, 예를 들어, ETSI GS NFV-INF 003, ETSI GS NFV-INF 004 및 ETSI GS NFV-INF 005에 의해 정의된 절차 중 하나 이상이 사용될 수 있다. 일부 양태에서, ME 애플리케이션(또는 앱) VNF는 ETSI NFV MANO에 의해 정의된 바와 같이, MEC-in-NFV 배치가 특정 오케스트레이션 및 라이프 사이클 관리(Life Cycle Management)(LCM) 작업을 NFVO 및 VNFM 기능 블록(8220 및 8222)에 위임할 수 있게 하는 개별 VNF처럼 관리될 수 있다. 일부 양태에서, 모바일 에지 플랫폼 관리자(Mobile Edge Platform Manager)(MEPM)는 LCM 부분을 하나 이 상의 가상 네트워크 기능 관리자(들)(Virtual Network Function Manager(s))(VNFM(s))(8220 및 8222)에 위임하 는 \"모바일 에지 플랫폼 관리자-NFV\"(Mobile Edge Platform Manager-NFV)(MEPM-V)로 변환될 수 있다. MEC 참 조 아키텍처 ETSI GS MEC-003에서 정의된 모바일 에지 오케스트레이터(Mobile Edge Orchestrator)(MEO)는 자원 오케스트레이션 및 ME 앱 VNF 세트의 오케스트레이션을 위한 NFVO를 하나 이상의 NFV 네트워크 서비스 (Network Service)(NS)로서 사용하는 \"모바일 에지 애플리케이션 오케스트레이터\"(Mobile Edge Application Orchestrator)(MEAO)로 변환될 수 있다. 일부 양태에서, 모바일 에지 플랫폼 VNF, MEPM-V 및 VNFM(ME 플랫폼 LCM)은 3GPP TR 32.842의 앙상블 개 념에 따른 단일 패키지로 배치될 수 있거나, 또는 VNFM이 ETSI GS NFV-IFA 009에 따른 일반 VNFM이고 모바일 에 지 플랫폼 VNF 및 MEPM-V는 단일 공급 업체에 의해 제공된다. 일부 양태에서, ME 서비스를 제공하고 및/또는 소비하는 애플리케이션이 아닌 한, ME 애플리케이션과 ME 플랫폼 사이의 Mp1 참조 지점은 ME 애플리케이션에 선택 사항일 수 있다. 일부 양태에서, MEAO와 MEPM-V 사이의 Mm3* 참조 지점은 ETSI GS MEC-003에 의해 정의된 Mm3 참조 지점에 기초한다. MEPM-V와 VNFM(ME 애플리케이션 LCM) 간의 분할에 부응하기 위해 이러한 참조 지점에 대한 변경이 구성될 수 있다. 일부 양태에서, ETSI MEC 아키텍처와 ETSI NFV 아키텍처의 요소들 사이에 다음과 같은 새로운 참조 지점(Mv1, Mv2 및 Mv3)이 도입되어 ME 앱 VNF의 관리를 지원한다. 다음과 같은 참조 지점은 기존의 NFV 참조 지점과 관련 되지만, 기능성의 서브세트만이 ETSI MEC에 대해 사용될 수 있으며, 확장이 필요할 수 있다: Mv1(이 참조 지점 은 MEAO와 NFVO를 연결하며, 이것은 ETSI NFV에 정의된 Os-Ma-nfvo 참조 지점과 관련된다); Mv2(이 참조 지점 은 ME 앱 VNF의 LCM을 수행하는 VNF 관리자를 MEPM-V와 연결하여 LCM 관련 알림이 이들 엔티티 사이에서 교환될 수 있게 한다; 이것은 ETSI NFV에서 정의된 Ve-Vnfm-em 참조 지점과 관련되지만, 가능하게는 추가 사항을 포함 할 수 있으며, Ve-Vnfm-em에 의해 제공되는 모든 기능성을 사용하지 않을 수 있다); Mv3(이 참조 지점은 VNF 관 리자를 ME 앱 VNF 인스턴스와 연결하여 (예를 들어, ME 애플리케이션 LCM 또는 초기 배치 특정 구성에 관련된) 메시지의 교환을 가능하게 한다; 이것은 ETSI NFV에서 정의된 Ve-Vnfm-vnf 참조 지점과 관련되지만, 추가 사항 을 포함할 수 있으며, Ve-Vnfm-vnf에 의해 제공되는 모든 기능성을 사용하지 않을 수 있다). 일부 양태에서, 다음과 같은 참조 지점은 ETSI NFV에 의해 정의된 바와 같이 사용된다: Nf-Vn(이 참조 지점은 각각의 ME 앱 VNF를 NFVI와 연결한다); Nf-Vi(이 참조 지점은 NFVI와 VIM을 연결한다); Os-Ma-nfvo(이 참조 지 점은 OSS와 NFVO를 연결한다. 이것은 NS, 예를 들어, 서비스를 전달하기 위해 연결되고 오케스트레이션된 다수 의 VNF를 관리하는데 주로 사용된다); Or-Vnfm(이 참조 지점은 NFVO와 VNFM을 연결한다; 이것은 NFVO가 VNF LCM 동작을 호출하는데 주로 사용된다); Vi-Vnfm(이 참조 지점은 VIM과 VNFM을 연결한다; 이것은 VNFM에 의해, VNF가 필요로 하는 클라우드 자원을 관리할 자원 관리 동작을 호출하는데 주로 사용된다; 이것은 이 참조 지점 이 Mm6과 1:1로 대응하는 NFV 기반 MEC 배치에서 추정된다); 및 Or-Vi(이 참조 지점은 NFVO와 VIM을 연결한다; 이것은 NFVO에 의해 클라우드 자원 용량을 관리하는데 주로 사용된다). 도 83은 가상화된 네트워크 기능(VNF)으로서 MEC 플랫폼을 관리하는 것을 도시한다. 도 83을 참조하면, 다이어 그램은 NFV 환경에서 MEC 참조 아키텍처로부터의 관리 컴포넌트를 도시한다. 보다 구체적으로, 다 이어그램은 동작 지원 시스템, MEPM-V, 모바일 에지 플랫폼, NFVI, NFVO, VNFM 및 VIM을 도시한다. 일부 양태에서, MEPM-V는 ME 플랫폼 VNF의 요소 관리자(Element Manager)(EM)로서 기능하도록 구 성될 수 있다. 일부 양태에서, ETSI NFV에 따른 VNF 관리자(VNF Manager)(VNFM)(예를 들어, 특정 VNFM, 일반 VNFM)는 ME 플랫폼 VNF의 LCM을 수행하는데 사용된다. 다이어그램은 ETSI NFV에 의해 정의된 바와 같이, 관리 컴포넌트(8302-8314) 사이의 다음과 같은 참조 지 점 연결을 추가로 도시한다. Ve-Vnfm-em: 이 참조 지점은 ME 플랫폼의 라이프사이클을 관리하는 VNF 관리자(VNFM)를 모바일 에지 플랫폼 관 리자-NFV(Mobile Edge Platform Manager-NFV)(MEPM-V)와 연결한다. Ve-Vnfm-em 참조 지점은 ETSI NFV에 정의 된 바와 같을 수 있다. 모바일 에지 플랫폼 VNF는 네트워크 기능으로 간주되기 때문에, ETSI NFV에서 정의된 Ve-Vnfm-em 절차에 임의의 영향을 미칠 것으로 예상되지 않는다. Ve-Vnfm-vnf: 이 참조 지점은 ME 플랫폼의 라이프사이클을 관리하는 VNFM을 모바일 에지 플랫폼 VNF와 연결한다. Ve-Vnfm-vnf 참조 지점은 ETSI NFV에 정의된 바와 같을 수 있다. 모바일 에지 플랫폼 VNF는 네트워 크 기능으로 간주되기 때문에, ETSI NFV에 정의된 Ve-Vnfm-vnf 절차에 임의의 영향도 미칠 것으로 예상되지 않 는다. Nf-Vn: 이 참조 지점은 모바일 에지 플랫폼 VNF를 NFVI와 연결한다. Nf-Vi: 이 참조 지점은 NFVI와 VIM을 연결 한다. Os-Ma-nfvo: 이 참조 지점은 OSS와 NFVO를 연결한다. 이것은 NS, 예를 들어, 서비스를 제공하기 위해 연결되고 오케스트레이션된 다수의 VNF를 관리하는데 주로 사용된다. Or-Vnfm: 이 참조 지점은 ME 플랫폼의 라 이프사이클을 관리하는 NFVO와 VNFM을 연결한다. 이것은 NFVO가 VNF LCM 동작을 호출하는데 주로 사용된다. Vi-Vnfm: 이 참조 지점은 ME 플랫폼의 라이프사이클을 관리하는 VIM과 VNFM을 연결한다. 이것은 VNFM에 의해, VNF가 필요로 하는 클라우드 자원을 관리할 자원 관리 작업을 호출하는데 주로 사용된다. Or-Vi: 이 참조 지점 은 NFVO와 VIM을 연결한다. 이것은 NFVO에 의해 클라우드 자원 용량을 관리하는데 주로 사용된다. 일부 양태에서, 5G 채택은 공통 세트의 물리적(무선 및 유선) 네트워크 인프라스트럭처를 통해 다수의 가상 네 트워크를 프로비저닝, 관리, 조정 및 운영할 수 있는 캐퍼빌리티를 TSP에 제공하는 역량에 달려 있다. 엔드-투 -엔드 \"슬라이스\"는 물리적 컴퓨팅 및 네트워크 자원을 사용하여 가상 논리 네트워크를 개척한다. 각각의 슬라 이스는 용량, 보안 레벨, 지리적 커버리지 및 지연시간을 비롯하여 지원되는 서비스와 관련된 성능을 지원하도 록 구체적으로 구성될 수 있다. 슬라이스는 무선 액세스 네트워크(RAN)의 무선 라디오, 진화된 패킷 코어 (Evolved Packet Core)(EPC)를 포함한 원격 통신 시스템 코어 인프라스트럭처뿐만 아니라, 5G 모바일 애플리케 이션 및 콘텐츠가 호스팅될 수 있는 스위치 및 데이터 센터 서버를 분할하는 것이 포함된다. 또한, 5G EDGE 디 바이스는 서비스 지연시간 요구 사항에 따라 슬라이스에 포함될 수도 있다. 일부 양태에서, 5G 네트워크 슬라이스는 최선의 보안/추적성을 요구하는 (반)자율 주행 차량, 원격 건강 모니터 링 및 최초 응답자(first-responder) 애플리케이션으로부터 여벌 자원 추적성 없이도 괜찮을 수 있는 계층형 스 마트 폰 플랜 및 IoT 디바이스에 이르기까지 광범위한 애플리케이션을 지원할 것이다. 일부 양태에서, 개시된 상호작용을 수행하는데 필요한 정보 요소는 복잡하고 동적이며 액세스 제어되어야 한다. 이것은 (예를 들어, CPU, 메모리, 대역폭, I/O, 스토리지 시스템, 네트워크 노드를 시각화하는) 자원 그래프, 어떤 자원이 어떤 행위자에 의해 소유되어 있는지, 특정 서비스 인스턴스에 (자원의) 할당 상태로서 시각화될 수 있다. 그러나, 보안을 위해, 이 \"그래프\"의 모든 부분이 각각의 행위자에게 동등하게 시각화되는 것은 아니 다. 요소는 상이한 슬라이스에 저장되고: 슬라이스와 이에 따른 블록체인 간의 통신은 본질적으로 동적인 정책 및 권한 설정에 기초한다. 일부 양태에서, 본 명세서에 개시된 AI 기술은 자원조달의 이전 요청시 자원조달의 가격을 비롯하여, 네트워크 사업자 자원 및 엔터프라이즈 SLA에 미치는 SLA 영향을 추론/예측하는데 사용될 수 있다. 본 명세서에서 설명된 기능 유닛 또는 캐퍼빌리티는 그의 구현 독립성을 보다 구체적으로 강조하기 위해, 컴포 넌트 또는 모듈로서 지칭되거나 라벨링되었을 수 있다는 것을 이해해야 한다. 이러한 컴포넌트는 임의 수의 소 프트웨어 또는 하드웨어 포맷으로 구현될 수 있다. 예를 들어, 컴포넌트 또는 모듈은 맞춤형 대규모 집적 (Very-Large-Scale Integration)(VLSI) 회로 또는 게이트 어레이, 로직 칩, 트랜지스터 또는 다른 이산 컴포넌 트와 같은 기성품 반도체를 포함하는 하드웨어 회로로서 구현될 수 있다. 컴포넌트 또는 모듈은 또한 필드 프 로그램 가능 게이트 어레이, 프로그램 가능 어레이 로직, 프로그램 가능 로직 디바이스 등과 같은 프로그램 가 능 하드웨어 장치에서 구현될 수 있다. 컴포넌트 또는 모듈은 또한 다양한 유형의 프로세서에 의한 실행을 위 해 소프트웨어로 구현될 수 있다. 예를 들어, 실행 가능 코드의 식별된 컴포넌트 또는 모듈은 예를 들어 객체, 절차 또는 기능으로서 구성될 수 있는 컴퓨터 명령어의 하나 이상의 물리적 또는 논리적 블록을 포함할 수있다. 그럼에도 불구하고, 식별된 컴포넌트 또는 모듈의 실행 파일은 물리적으로 함께 위치할 필요는 없지만 논리적으로 함께 결합될 때 컴포넌트 또는 모듈을 구성하고 컴포넌트 또는 모듈에 대해 명시된 목적을 달성하는 상이한 위치에 저장된 개별 명령어를 포함할 수 있다. 실제로, 실행 가능한 코드의 컴포넌트 또는 모듈은 단일 명령어 또는 많은 명령어일 수 있으며, 몇몇 상이한 코 드 세그먼트에 걸쳐, 상이한 프로그램 사이에, 그리고 몇몇 메모리 디바이스 또는 처리 시스템에 걸쳐 분산될 수도 있다. 특히, (코드 재기입 및 코드 분석과 같은) 설명된 처리의 일부 양태는 코드가 (예를 들어, 센서 또 는 로봇에 내장된 컴퓨터에) 배치되는 그런 것보다 (예를 들어, 데이터 센터의 컴퓨터 내의) 상이한 처리 시스 템에서 이루어질 수 있다. 유사하게, 동작 데이터는 컴포넌트 또는 모듈 내에서 식별되고 본 명세서에 예시될 수 있으며, 임의의 적절한 형태로 구현되고 임의의 적절한 유형의 데이터 구조 내에서 구성될 수 있다. 동작 데이터는 단일 데이터 세트로서 수집되거나 또는 상이한 스토리지 디바이스를 포함하는 상이한 위치에 분산될 수 있으며, 적어도 부분적으로는 단지 시스템 또는 네트워크의 전자 신호로서 존재할 수 있다. 원하는 기능을 수행하도록 동작할 수 있는 에이전트를 비롯한 컴포넌트 또는 모듈은 수동적이거나 능동적일 수 있다. VII. 에지 컴퓨팅 구현의 예 현재 설명된 방법, 시스템 및 디바이스 실시 형태의 추가 예는 다음과 같은 비제한적인 구현을 포함한다. 다음 의 비제한적 예 각각은 그 자체로 존재할 수 있거나 또는 임의의 순열 또는 아래에 제공되거나 또는 본 개시내 용 전체에 걸쳐 제공된 임의의 하나 이상의 다른 예와의 조합으로 조합될 수 있다. 예시적인 구현은 예 A1-AA11의 동작 또는 본 명세서에서 설명된 다른 주제를 호출하거나 수행하는 각각의 에지 처리 디바이스 및 노드를 포함하는 에지 컴퓨팅 시스템이다. 다른 예시적인 구현은 예 A1-AA11의 동작 또는 본 명세서에서 설명된 다른 주제를 호출하거나 수행하도록 동작 할 수 있는 클라이언트 엔드 포인트 노드이다. 다른 예시적인 구현은 예 A1-AA11의 동작 또는 본 명세서에서 설명된 다른 주제를 호출하거나 수행하도록 동작 할 수 있는, 에지 컴퓨팅 시스템 내의 또는 그에 결합된 집계 노드, 네트워크 허브 노드, 게이트웨이 노드 또는 코어 데이터 처리 노드이다. 또 다른 예시적인 구현은 예 A1-AA11의 동작 또는 본 명세서에서 설명된 다른 주제를 호출하거나 수행하도록 동 작할 수 있는, 에지 컴퓨팅 시스템 내의 또는 그에 결합된 액세스 포인트, 기지국, 도로변 유닛, 노변 유닛 또 는 온-프레미스 유닛이다. 다른 예시적인 구현은 예 A1-AA11의 동작 또는 본 명세서에서 설명된 다른 주제를 호출하거나 수행하도록 동작 할 수 있는, 에지 컴퓨팅 시스템 내의 또는 그에 결합된 에지 프로비저닝 노드, 서비스 오케스트레이션 노드, 애플리케이션 오케스트레이션 노드 또는 다중 테넌트 관리 노드이다. 다른 예시적인 구현은 예 A1-AA11의 동작 또는 본 명세서에서 설명된 다른 주제를 호출하거나 수행하도록 동작 할 수 있는, 에지 컴퓨팅 시스템 내의 또는 그에 결합된 에지 프로비저닝 서비스, 애플리케이션 또는 서비스 오 케스트레이션 서비스, 가상 머신 배치, 컨테이너 배치, 기능 배치 및 컴퓨트 관리를 동작하는 에지 노드이다. 다른 예시적인 구현은 예 A1-AA11의 동작 또는 본 명세서에서 설명된 다른 주제를 호출하거나 수행하도록 동작 할 수 있는, 에지 메시로서, 사이드 카 로딩을 갖는 에지 메시로서, 또는 메시 대 메시 통신으로 동작 가능한 에지 컴퓨팅 시스템이다. 다른 예시적인 구현은 예 A1-AA11 또는 본 명세서에 개시된 다른 주제를 사용하여 본 명세서에서 논의된 유스 케이스를 호출하거나 수행하도록 동작할 수 있는, 네트워크 기능, 가속 기능, 가속 하드웨어, 저장 하드웨어, 또는 컴퓨테이션 하드웨어 자원의 양태를 포함하는 에지 컴퓨팅 시스템이다. 다른 예시적인 구현은 예 A1-AA11 또는 본 명세서에서 설명된 다른 주제를 사용하여, 본 명세서에서 논의된 유 스 케이스를 호출하거나 수행하도록 동작할 수 있는, 클라이언트 이동성, 차량 대 차량(V2V), 차량 대 사물 (V2X) 또는 차량 대 인프라스트럭처(V2I) 시나리오를 지원하고 ETSI MEC 사양에 따라 선택적으로 동작하는 에지 컴퓨팅 시스템이다. 다른 예시적인 구현은 예 A1-AA11 또는 본 명세서에 설명된 다른 주제를 사용하여 본 명세서에서 논의된 유스 케이스를 호출하거나 수행하도록 동작할 수 있는, 3GPP 4G/LTE 또는 5G 네트워크 캐퍼빌리티에 따른 구성을 포 함하는 모바일 무선 통신에 적합한 에지 컴퓨팅 시스템이다.다른 예시적인 구현은 에지 컴퓨팅 네트워크 또는 에지 컴퓨팅 시스템의 계층에서 집계 노드, 네트워크 허브 노 드, 게이트웨이 노드 또는 코어 데이터 처리 노드로서 동작할 수 있거나, 근거리 에지, 로컬 에지, 엔터프라이 즈 에지, 온-프레미스 에지, 인접 에지, 중간 에지, 또는 원거리 에지 네트워크 계층에서 동작할 수 있거나, 또 는 공통 지연시간, 타이밍 또는 거리 특성을 갖는 한 세트의 노드에서 동작할 수 있고, 예 A1-AA11 또는 본 명 세서에서 설명된 다른 주제를 사용하여 본 명세서에서 논의된 유스 케이스를 호출하거나 수행하도록 동작할 수 있는 에지 컴퓨팅 노드이다. 다른 예시적인 구현은 예 A1-AA11 또는 본 명세서에서 설명된 다른 주제를 사용하여, 에지 컴퓨팅 시스템에서 본 명세서에서 논의된 유스 케이스를 호출하거나 수행하도록 동작할 수 있는, 캐퍼빌리티가 구현된 네트워킹 하 드웨어, 가속 하드웨어, 저장 하드웨어, 또는 컴퓨팅 하드웨어이다. 다른 예시적인 구현은 예 A1-AA11 또는 본 명세서에서 설명된 다른 주제를 사용하여, 컴퓨트 오프로드, 데이터 캐싱, 비디오 처리, 네트워크 기능 가상화, 무선 액세스 네트워크 관리, 증강 현실, 가상 현실, 산업 자동화, 소매 서비스, 제조 동작, 스마트 빌딩, 에너지 관리, 자율 주행, 차량 보조, 차량 통신, 사물 인터넷 동작, 물 체 검출, 음성 인식, 헬스케어 애플리케이션, 게임 애플리케이션 또는 가속된 콘텐츠 처리 중 하나 이상으로부 터 제공된 유스 케이스를 수행하도록 구성된 에지 컴퓨팅 시스템이다. 다른 예시적인 구현은 하나 이상의 프로세서 및 하나 이상의 프로세서에 의해 실행될 때 하나 이상의 프로세서 가 예 A1-AA11 또는 본 명세서에서 설명된 다른 주제를 사용하여, 본 명세서에서 설명된 유스 케이스를 수행하 게 하는 명령어를 포함하는 하나 이상의 컴퓨터 판독 가능 매체를 포함하는 에지 컴퓨팅 시스템의 장치이다. 다른 예시적인 구현은 전자 디바이스의 하나 이상의 프로세서에 의한 명령어의 실행시, 에지 컴퓨팅 시스템의 전자 디바이스가 예 A1-AA11 또는 본 명세서에서 설명된 다른 주제를 사용하여, 본 명세서에서 논의된 유스 케 이스를 호출하거나 수행하게 하는 명령어를 포함하는 하나 이상의 컴퓨터 판독 가능 저장 매체이다. 다른 예시적인 구현은 예 A1-AA11 또는 본 명세서에서 설명된 다른 주제를 사용하여, 본 명세서에서 논의된 유 스 케이스를 호출하거나 수행하는 수단, 로직, 모듈 또는 회로를 포함하는 에지 컴퓨팅 시스템의 장치이다. 이러한 구현이 특정 예시적인 양태를 참조하여 설명되었지만, 본 개시내용의 더 넓은 범위를 벗어나지 않고 이 러한 양태에 대해 다양한 수정 및 변경이 이루어질 수 있음이 명백할 것이다. 본 명세서에서 설명된 많은 배열 및 처리는 더 큰 대역폭/처리량을 제공하고 서빙되는 에지 시스템에 이용 가능해질 수 있는 에지 서비스 선택을 지원하기 위해 조합하여 또는 병렬 구현으로 사용될 수 있다. 따라서, 명세서 및 도면은 제한적인 의미가 아닌 예시적인 의미로 간주되어야 한다. 본 명세서의 일부를 형성하는 첨부 도면은 주제가 실행될 수 있는 특정 양"}
{"patent_id": "10-2020-7037506", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "태를 제한이 아닌 예시로서 도시한다. 예시된 양태는 관련 기술분야의 통상의 기술자가 본 명세서에 개시된 교 시를 실시할 수 있도록 충분히 상세하게 설명된다. 본 개시내용의 범위를 벗어나지 않고 구조적 및 논리적 대 체 및 변경이 이루어질 수 있도록 다른 양태가 이용되고 그로부터 도출될 수 있다. 그러므로 이러한 상세한 설 명은 제한적인 의미로 받아들여지지 않고, 다양한 양태의 범위는 첨부된 청구 범위에 의해서만, 이러한 청구 범 위의 자격을 부여 받은 등가물의 전체 범위와 함께 정의된다. 본 발명 주제의 이러한 양태는 단지 편의를 위해 그리고 하나보다 많이 실제로 공개된다면 본 출원의 범위를 임 의의 단일 양태 또는 발명적 개념으로 자발적으로 제한하려는 의도없이 개별적으로 및/또는 집합적으로 본 명세 서에서 언급될 수 있다. 따라서, 특정 양태가 본 명세서에서 도시되고 설명되었지만, 동일한 목적을 달성하기 위해 연산된 임의의 배열이 도시된 특정 양태에 대체될 수 있다는 것을 이해해야 한다. 본 개시내용은 다양한 양태의 임의의 및 모든 적응 또는 변형을 포함하는 것으로 의도된다. 위의 양태 및 본 명세서에서 구체적으로"}
{"patent_id": "10-2020-7037506", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "설명되지 않은 다른 양태의 조합은 위의 설명을 검토할 때 관련 기술분야의 통상의 기술자에게 명백할 것이다.도면 도면1 도면2 도면3 도면4 도면5 도면6 도면7 도면8 도면9 도면10a 도면10b 도면11 도면12 도면13 도면14 도면15 도면16 도면17 도면18 도면19 도면20 도면21a 도면21b 도면21c 도면22a 도면22b 도면22c 도면22d 도면23 도면24 도면25 도면26 도면27 도면28 도면29 도면30 도면31 도면32 도면33 도면34 도면35 도면36 도면37 도면38 도면39 도면40 도면41 도면42 도면43 도면44 도면45 도면46 도면47 도면48 도면49 도면50 도면51 도면52 도면53 도면54 도면55 도면56 도면57 도면58 도면59 도면60 도면61 도면62 도면63 도면64 도면65 도면66 도면67 도면68 도면69 도면70 도면71 도면72 도면73 도면74 도면75 도면76 도면77 도면78 도면79 도면80 도면81 도면82 도면83"}
{"patent_id": "10-2020-7037506", "section": "도면", "subsection": "도면설명", "item": 1, "content": "반드시 일정한 비율대로 작성되지 않은 도면에서, 같은 숫자는 상이한 도면에서 유사한 컴포넌트를 설명할 수 있다. 상이한 문자의 접미사를 갖는 같은 숫자는 유사한 컴포넌트의 상이한 인스턴스를 나타낼 수 있다. 일부 실시예는 첨부 도면의 도면에서 제한이 아닌 예로서 도시된다. 도 1은 에지 컴퓨팅을 위한 에지 클라우드 구성의 개요를 도시한다. 도 2는 엔드포인트, 에지 클라우드 및 클라우드 컴퓨팅 환경 사이의 운영 계층을 도시한다. 도 3은 에지 컴퓨팅 시스템 사이에 배치된 분산 컴퓨트 계층의 개요를 제공한다.도 4는 에지 컴퓨팅 시스템 사이에 배치된 분산 컴퓨트 계층의 개요를 제공한다. 도 5 및 도 6은 에지 컴퓨팅 시스템에서 네트워킹 및 서비스에 대한 오버-더-톱(over-the-top) 및 네트워크-집 계(network-aggregation) 접근 방식을 도시한다. 도 7 및 도 8은 다수의 에지 노드와 다수의 테넌트(tenant) 사이에서 동작되는 에지 컴퓨팅 시스템에 걸쳐 가상 에지 구성을 위한 배치 및 오케스트레이션을 도시한다. 도 9는 에지 컴퓨팅 시스템에 컨테이너를 배치하는 다양한 컴퓨트 배열을 도시한다. 도 10a 및 도 10b는 에지 컴퓨팅 시스템에서 조정된 컴퓨트 기능 및 서비스를 사용하는 분산 에지 컴퓨트 배치 를 도시한다. 도 11은 에지 컴퓨팅 시스템을 제공하는 에지 메시(edge mesh) 사이에서 조정된 에지 컴퓨팅을 위한 구성을 도 시한다. 도 12는 에지 컴퓨팅 시스템에서 애플리케이션으로의 모바일 액세스가 수반되는 차량 컴퓨트 및 통신 유스 케이 스를 예시한다. 도 13은 운영 네트워크 계층 사이에서 에지 컴퓨팅에 대한 운영 고려 사항의 비교를 도시한다. 도 14는 운영 네트워크 계층 사이에서 에지 컴퓨팅에 대한 배치 및 지연시간을 도시한다. 도 15는 워크로드 배치 및 에지 컴퓨팅 시스템의 운영 계층에의 매핑을 도시한다. 도 16은 에지 컴퓨팅 시스템의 서비스 특징에 워크로드 유형의 매핑을 도시한다. 도 17은 에지 컴퓨팅 시스템에서 실행 플랫폼에 워크로드 유형의 매핑을 도시한다. 도 18은 에지 컴퓨팅 시스템에서 에지 컴퓨팅 하드웨어 구성의 다수의 계층 사이의 다수의 테넌트를 위한 서비 스의 동작을 도시한다. 도 19는 네트워크 계층의 운영 배치(operational deployment) 및 지연시간에 에지 컴퓨팅 하드웨어 구성의 추가 매핑을 도시한다. 도 20은 에지 컴퓨팅 하드웨어 구성의 운영 배치에 유스 케이스 및 워크로드의 추가 매핑을 도시한다. 도 21a 내지 도 21c는 운영 목표에 기초한 에지 컴퓨팅 하드웨어 구성의 추가 예를 도시한다. 도 22a는 에지 컴퓨팅 시스템의 컴퓨트 노드에 배치된 컴퓨트에 대한 예시적인 컴포넌트의 개요를 제공한다. 도 22b는 에지 컴퓨팅 시스템의 컴퓨팅 디바이스 내의 예시적인 컴포넌트의 추가 개요를 제공한다. 도 22c는 에지 컴퓨팅 시스템의 모바일 컴퓨팅 디바이스 내의 예시적인 컴포넌트의 추가 개요를 제공한다. 도 22d는 에지 컴퓨팅 시스템의 구성 가능한 서버 랙 내의 예시적인 컴포넌트의 추가 개요를 제공한다. 도 23은 에지 하트비트(edge heartbeat) 컴포넌트에 의한 통지에 기초한 에지 노드의 낮은 연결성 클러스터 (connectivity cluster) 및 연결성 조정(connectivity adjustment)을 도시한다. 도 24는 에지 하트비트 컴포넌트에 의한 통지에 기초한 에지 노드의 높은 연결성 클러스터 및 연결성 조정을 도 시한다. 도 25는 에지 호스트 내의 에지 하트비트 컴포넌트를 사용하는 예시적인 에지 배치를 도시한다. 도 26은 에지 노드 간의 예시적인 데이터 흐름을 도시한다. 도 27은 에지 컴퓨팅 네트워크 내 데이터의 증명을 위한 기술을 도시한다. 도 28은 에지 서비스 분산(edge service distribution)을 위한 아키텍처를 보여주는 시스템 다이어그램을 도시 한다. 도 29는 에지 컴퓨팅 시스템을 위한 병렬 데이터의 가속 시나리오를 도시한다. 도 30은 개선된 에지 클라우드 추론 처리(edge cloud inference processing)를 위한 컴포넌트를 포함하는 아키 텍처의 예를 도시한다.도 31은 에지 서비스 페이지 테이블(edge service page table)을 구현하기 위한 시스템 다이어그램을 도시한다. 도 32는 에지 서비스 페이지 테이블을 도시한다. 도 33은 다른 에지 클라우드 위치에서 오케스트레이터(orchestrator)의 도메인 분리를 보여주는 시스템 다이어 그램을 도시한다. 도 34는 에지 클라우드의 영역을 관리하는 에지 클라우드 오케스트레이터를 보여주는 시스템 다이어그램을 도시 한다. 도 35는 예시적인 자원 브로드캐스팅(broadcasting) 및 대여하기(borrowing)를 보여주기 위한 세 개의 상이한 오케스트레이터 사이의 흐름도를 도시한다. 도 36은 에지 디바이스에서 데이터를 집계하기 위한 아키텍처의 시스템 다이어그램을 도시한다. 도 37 은 에지 케이트웨이 아키텍처의 예를 도시한다. 도 38은 사전 프로비저닝된 핸드오프(pre-provisioned hand-off)를 위한 머신 학습 시스템을 훈련하고 사용하는 예를 도시한다. 도 39는 에지 컴퓨팅 노드 사이의 자동 서비스 복제(automatic service replication)의 예를 도시한다. 도 40은 고객 댁내 장비(customer-premise equipment)(CPE) 기반 실행 포워딩을 위한 예시적인 광대역 기반 및 무선 기반 시스템의 블록도를 도시한다. 도 41은 CPE 기반 실행 포워딩을 위한 예시적인 시스템의 블록도를 도시한다. 도 42는 CPE 기반 실행 포워딩을 위한 컴퓨트 용량을 배분하는 예측 가능한 수단을 달성하기 위한 정책 주도 접 근 방식(policy driven approach)에 대한 예시적 기술의 흐름을 도시한다. 도 43 은 에지 생태계 도메인 아키텍처(edge ecosystem domain architecture)의 예를 도시한다. 도 44는 가상화된 다중 도메인에 대한 모델의 예를 도시한다. 도 45는 에지 컴퓨팅 노드 사이에서 안전한 데이터 공유를 위한 시나리오를 도시한다. 도 46은 에지에서 그룹 보안 통신을 위한 시스템의 예의 블록도이다. 도 47은 서비스로서 충돌 분석(Conflict-Analysis-as-a-Service)(CAaaS) 제공자를 포함하는 에지 시스템의 개 요를 보여주는 시스템 다이어그램을 도시한다. 도 48은 CAaaS 제공자 컴포넌트를 보여주는 시스템 다이어그램을 도시한다. 도 49는 디바이스 식별자 구성 엔진(Device Identifier Composition Engine)(DICE) 계층화 및 복합 디바이스 아이덴티티(compound device identity)(CDI) 컴퓨테이션을 갖는 아키텍처의 예를 도시한다. 도 50은 비대칭 키 생성을 사용하는 DICE 계층화를 갖는 아키텍처의 예를 도시한다. 도 51은 워크로드 특정 증명 키(workload specific attestation key)를 생성하기 위해 DICE 계층화를 사용하는 SLA 파라미터의 암시적 증명을 위한 흐름의 예를 도시한다. 도 52는 에지 증명 네임 서비스(Edge Attestation Name Service)(EANS) 아키텍처를 제공하는 시스템을 도시한 다. 도 53은 커리 함수(curry function)(예를 들어, 비트스트림) 및 워크로드를 수용하는 가속기를 보여주는 에지 아키텍처에 대한 시스템 다이어그램을 도시한다. 도 54는 동적 SLA 및 과금 기준 기반 다중 테넌트 에지 클라우드 전력 관리를 위한 시스템을 도시한다. 도 55는 생체측정 계층 아키텍처(biometric hierarchical architecture)의 예를 도시한다. 도 56은 에지 컴퓨팅 시스템의 다수의 에지 노드 사이에서 SLA의 마이그레이션, 모니터링 및 전파를 위한 시나 리오를 도시한다. 도 57은 서비스 레벨 목표에 대한 에지 기능 기반 변경(edge function-based change)에 대한 시스템 다이어그램을 도시한다. 도 58은 클라우드, 에지 및 모바일 디바이스 위치 사이에서 에지 컴퓨팅 시스템의 3-레벨 계층 구조(three- level hierarchy)를 도시한다. 도 59는 에지 서비스 마이그레이션의 예를 도시한다. 도 60은 부분적 에지 서비스 마이그레이션의 예를 도시한다. 도 61은 에지 워크로노드에서 수평 프록싱(horizontal proxying)의 예를 도시한다. 도 62는 워크로드 컴포넌트 타입에 기초하여 에지 워크로드를 다수의 전방 에지 워크로드로 이동하는 예를 도시 한다. 도 63은 조정되고, 분산된 에지 원격 측정 서비스(edge telemetry service)를 위한 시스템 다이어그램을 도시한 다. 도 64는 에지 컴퓨팅 시스템 내에서 로드 밸런싱을 구현하도록 적응된 분산 시스템 사이의 구성자 (configurator)의 구현을 도시한다. 도 65는 상이한 에지 컴퓨팅 노드 사이의 예시적인 연결을 도시한다. 도 66은 원격 통신 서비스 제공자(telecommunication service provider)(TSP)와 클라우드 서비스 제공자(cloud service provider)(CSP) 사이의 예시적인 에지 통신 상호작용을 도시한다. 도 67은 예시적인 에지 컴퓨팅 시스템에 배치 가능한 5G-MEC(다중 액세스 에지 컴퓨팅(multi-access edge computing)) 상호 연결을 도시한다. 도 68은 예시적인 에지 컴퓨팅 시스템에 배치 가능한 전체 5G 차세대(next generation)(NG) 시스템 아키텍처의 간략화된 다이어그램이다. 도 69는 예시적인 에지 컴퓨팅 시스템에 배치 가능한 비-로밍(non-roaming) 5G 시스템 아키텍처를 도시한다. 도 70은 예시적인 에지 컴퓨팅 시스템에 배치 가능한 5G 서비스 기반 아키텍처 및 일반 MEC 아키텍처를 도시한 다. 도 71은 예시적인 에지 컴퓨팅 시스템과 함께 사용 가능한 5G 네트워크의 통합된 MEC 배치를 도시한다. 도 72는 예시적인 모바일 에지 시스템 참조 아키텍처(mobile edge system reference architecture)의 예를 도 시한다. 도 73은 상이한 에지 컴퓨팅 시스템 레벨의 예시적인 MEC 배치 옵션을 도시한다. 도 74는 예시적인 에지 컴퓨팅 시스템과 함께 사용 가능한 5G 시스템의 MEC 지원을 도시한다. 도 75, 도 76 및 도 77은 예시적인 에지 컴퓨팅 시스템과 함께 사용 가능한 5G 시스템의 MEC 매핑을 도시한다. 도 78은 예시적인 5G 시스템에서의 MEC 배치를 도시한다. 도 79는 에지 컴퓨팅 배치에서 사용 가능한, 네트워크 슬라이싱(network slicing)과 관련하여 제어 유닛 제어 평면(control unit control plane)(CU-CP) - 제어 유닛 사용자 평면(control unit user plane)(CU-UP)이 분리 된 예시적인 5G-NR 아키텍처의 컴포넌트를 도시한다. 도 80은 에지 컴퓨팅 배치에서 사용 가능한 예시적인 네트워크 슬라이스의 다이어그램을 도시한다. 도 81은 예시적인 에지 컴퓨팅 시스템으로부터 배치 가능한, 슬라이스 관리, 자원 관리 및 추적성 기능 (traceability function)을 지원하는 MEC 네트워크 아키텍처를 도시한다. 도 82는 예시적인 에지 컴퓨팅 시스템으로부터 배치 가능한 네트워크 기능 가상화(Network Function Virtualization)(NFV) 환경의 MEC 참조 아키텍처를 도시한다. 도 83은 예시적인 에지 컴퓨팅 시스템으로부터 배치 가능한 가상화된 네트워크 기능(virtualized network function)(VNF)으로서 MEC 플랫폼의 관리를 예시한다."}
