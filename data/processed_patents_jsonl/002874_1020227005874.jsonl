{"patent_id": "10-2022-7005874", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2022-0087429", "출원번호": "10-2022-7005874", "발명의 명칭": "차량용 내비게이션의 영상 제공 방법", "출원인": "엘지전자 주식회사", "발명자": "정두경"}}
{"patent_id": "10-2022-7005874", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "프로세서가, 안내 지점에 대한 정보 또는 차량의 속도 정보를 외부 서버로 전송하는 단계;상기 외부 서버가, 상기 안내 지점에 대한 정보 또는 상기 차량의 속도 정보에 기초하여, 후보 차량을 검색하는단계;상기 외부 서버가, 상기 프로세서에 의해 기 설정된 우선 순위에 따라 상기 후보 차량 중 영상 제공 차량을 선택하는 단계;상기 외부 서버가, 상기 영상 제공 차량으로부터 수신한 카메라 영상에 AR(augmented reality)을 이용하여 표시할 그래픽 객체를 생성하는 단계; 및상기 프로세서가, 상기 카메라 영상 및 상기 그래픽 객체를 포함하는 안내 지점에 대한 AR 영상 정보를 내비게이션 화면에 표시하는 단계;를 포함하는 차량용 내비게이션의 AR 영상 제공 방법."}
{"patent_id": "10-2022-7005874", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1 항에 있어서,상기 프로세서 및 상기 외부 서버는, 5G 통신을 통하여 상호 간 정보를 송수신하는, 차량용 내비게이션의 AR 영상 제공 방법."}
{"patent_id": "10-2022-7005874", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1 항에 있어서,상기 전송하는 단계는,상기 프로세서가,내비게이션이 안내하는 경로 상에서 사용자에 의해 입력된 선택 신호에 기초하여 상기 안내 지점을 선택하는 단계; 및상기 안내 지점에 대한 위치 정보 및 주행 방향 정보를 포함하는 상기 안내 지점에 대한 정보를 상기 외부 서버로 전송하는 단계;를 더 포함하는, 차량용 내비게이션의 AR 영상 제공 방법."}
{"patent_id": "10-2022-7005874", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1 항에 있어서,상기 검색하는 단계는,상기 외부 서버가,상기 안내 지점을 기준으로, 영상을 제공하는 제1 영역 및 기 설정된 추가 영역인 제2 영역을 포함하는 검색 영역을 설정하는 단계; 및상기 검색 영역에 위치하는 타 차량을 예측하는 단계;를 더 포함하는, 차량용 내비게이션의 AR 영상 제공 방법."}
{"patent_id": "10-2022-7005874", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4 항에 있어서,상기 예측하는 단계는,상기 외부 서버가, 상기 외부 서버와 통신하는 각 차량의 위치 정보와 속도 정보를 주기적으로 수신하고, 상기각 차량의 위치 정보와 속도 정보를 기초로, 상기 검색 영역에 위치하는 타 차량을 예측하는 단계;를 더 포함하는, 차량용 내비게이션의 AR 영상 제공 방법.공개특허 10-2022-0087429-3-청구항 6 제4 항에 있어서,상기 검색하는 단계는,상기 외부 서버가, 상기 검색 영역에 타 차량이 위치할 것으로 예측하면, 타 차량 각각에 대해서 상기 안내 지점을 지나가는지를 저장된 프로토콜에 의해 검증하는 단계;를 더 포함하는, 차량용 내비게이션의 AR 영상 제공방법."}
{"patent_id": "10-2022-7005874", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6 항에 있어서,상기 검색하는 단계는,상기 타 차량 중 상기 안내 지점을 지나가는 것으로 검증이 완료된 타 차량을 상기 후보 차량으로 선정하는 단계;를 더 포함하는, 차량용 내비게이션의 AR 영상 제공 방법."}
{"patent_id": "10-2022-7005874", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7 항에 있어서,상기 선택하는 단계는,상기 검색 영역 내의 상기 후보 차량의 수를 판단하는 단계;를 더 포함하고,상기 후보 차량의 수가 단수인 경우, 상기 선정된 후보 차량을 상기 영상 제공 차량으로 선택하고,상기 후보 차량의 수가 복수인 경우, 우선 순위에 따라 상기 영상 제공 차량을 선택하는, 차량용 내비게이션의AR 영상 제공 방법."}
{"patent_id": "10-2022-7005874", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8 항에 있어서,상기 선택하는 단계는,상기 외부 서버가, 상기 프로세서에 의해 선택된 우선 순위의 기준에 따라 제1 영상 제공 차량을 선택하는단계;를 더 포함하고, 상기 우선 순위의 기준은,상기 제1 영역 내에서, 상기 안내 지점과의 상대적 거리가 가까운 차량 기준 또는 상기 안내 지점과의 상대적거리가 먼 차량 기준을 포함하는, 차량용 내비게이션의 AR 영상 제공 방법."}
{"patent_id": "10-2022-7005874", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9 항에 있어서,상기 제1 영상 제공 차량이, 상기 제1 영역에 진입 시 상기 카메라 영상을 제공하는 단계;를 더 포함하고,상기 카메라 영상은,상기 제1 영상 제공 차량에 장착된 카메라로 촬영한 영상 또는 상기 제1 영상 제공 차량 내부의 이동 단말기에장착된 카메라로 촬영한 영상 중 적어도 어느 하나인, 차량용 내비게이션의 AR 영상 제공 방법."}
{"patent_id": "10-2022-7005874", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제10 항에 있어서,상기 제1 영상 제공 차량이, 상기 안내 지점을 통과하면 상기 카메라 영상의 제공을 종료하는 단계; 및상기 외부 서버가, 상기 후보 차량 중 상기 선택된 우선 순위의 기준에 따라 제2 영상 제공 차량을 선택하는 단계;를 더 포함하는, 차량용 내비게이션의 AR 영상 제공 방법.공개특허 10-2022-0087429-4-청구항 12 제11 항에 있어서,상기 제2 영상 제공 차량을 선택하는 단계는,상기 외부 서버가, 상기 제2 영상 제공 차량에 대해 상기 안내 지점을 지나가는지를 저장된 프로토콜에 의해 재검증하는 단계;를 더 포함하는, 차량용 내비게이션의 AR 영상 제공 방법."}
{"patent_id": "10-2022-7005874", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제12 항에 있어서,상기 제2 영상 제공 차량이 상기 안내 지점을 지나가는 것으로 재검증이 완료되면, 상기 제2 영상 제공 차량이,상기 제1 영역에 진입 시 상기 카메라 영상을 제공하는 단계; 더 포함하는, 차량용 내비게이션의 AR 영상 제공방법."}
{"patent_id": "10-2022-7005874", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제8 항에 있어서,상기 외부 서버는,상기 후보 차량의 수가 기 설정된 수 이상이면 상기 안내 지점의 주변 구간을 정체 구간으로 판단하고,상기 정체 구간의 시작 지점을 기준으로 상기 검색 영역을 재설정하는, 차량용 내비게이션의 AR 영상 제공방법."}
{"patent_id": "10-2022-7005874", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제14 항에 있어서,상기 외부 서버는, 상기 정체 구간 내의 각 차량으로부터 순간 촬영 이미지를 수신하고, 상기 순간 촬영 이미지를 연결하여 상기카메라 영상을 생성하는, 차량용 내비게이션의 AR 영상 제공 방법."}
{"patent_id": "10-2022-7005874", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제1 항에 있어서,상기 생성하는 단계는,상기 프로세서가, 저장된 캘리브레이션 파라미터 값을 상기 외부 서버로 전송하는 단계;상기 외부 서버가, 상기 캘리브레이션 파라미터 값을 기준으로 상기 카메라 영상의 캘리브레이션을 수행하는 단계; 및상기 캘리브레이션이 완료된 카메라 영상에 표시할 그래픽 객체를 생성하는 단계;를 포함하는, 차량용 내비게이션의 AR 영상 제공 방법."}
{"patent_id": "10-2022-7005874", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제16 항에 있어서,상기 그래픽 객체는,자차(ego vehicle)의 주행 경로를 안내하는 카펫, TBT(turn by turn) 또는 상기 안내 지점까지의 잔여 거리 표시 바(bar) 중 적어도 어느 하나를 포함하는, 차량용 내비게이션의 AR 영상 제공 방법."}
{"patent_id": "10-2022-7005874", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제17 항에 있어서,상기 표시하는 단계는,공개특허 10-2022-0087429-5-상기 프로세서가, 상기 외부 서버로부터 상기 카메라 영상 및 상기 그래픽 객체를 포함하는 안내 지점에 대한AR 영상 정보를 수신하는 단계; 및상기 프로세서가, 상기 카메라 영상에 상기 그래픽 객체를 중첩하여 상기 내비게이션 화면의 일 영역에 상기 AR영상 정보를 표시하는 단계;를 포함하는 차량용 내비게이션의 AR 영상 제공 방법."}
{"patent_id": "10-2022-7005874", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제1 항에 있어서,상기 외부 서버는,상기 안내 지점이 복수의 턴 안내가 필요한 지점으로 판단하면, 상기 안내 지점을 제1 지점 및 제2 지점으로 나누어 상기 제1 지점에 대한 제1 AR 영상 정보 및 상기 제2 지점에 대한 제2 AR 영상 정보를 생성하고,상기 프로세서는, 상기 제1 AR 영상 정보 및 상기 제2 AR 영상 정보를 상기 내비게이션 화면의 일 영역에 표시하는, 차량용 내비게이션의 AR 영상 제공 방법."}
{"patent_id": "10-2022-7005874", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제19 항에 있어서,상기 프로세서는,자차가 상기 제1 지점을 통과할 때까지 상기 제1 AR 영상 정보 및 상기 제2 AR 영상 정보를 표시하고,상기 자차가 상기 제1 지점을 통과하면, 상기 제2 지점을 통과할 때까지 상기 제1 AR 영상 정보를 표시하는, 차량용 내비게이션의 AR 영상 제공 방법."}
{"patent_id": "10-2022-7005874", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 프로세서가, 안내 지점에 대한 정보 또는 차량의 속도 정보를 외부 서버로 전송하는 단계; 외부 서버 가, 상기 안내 지점에 대한 정보 또는 상기 차량의 속도 정보에 기초하여, 후보 차량을 검색하는 단계; 외부 서 버가, 상기 프로세서에 의해 기 설정된 우선 순위에 따라 상기 후보 차량 중 영상 제공 차량을 선택하는 단계; 외부 서버가, 상기 영상 제공 차량으로부터 수신한 카메라 영상에 AR(augmented reality)을 이용하여 표시할 그 래픽 객체를 생성하는 단계; 및 프로세서가, 상기 카메라 영상 및 상기 그래픽 객체를 포함하는 안내 지점에 대 한 AR 영상 정보를 내비게이션 화면에 표시하는 단계;를 포함하는 차량용 내비게이션의 AR 영상 제공 방법에 관 한 것이다. 본 발명의 자율 주행 차량, 사용자 단말기 및 서버 중 하나 이상이 인공 지능(Artificial Intelligence) 모듈, 드론(Unmanned Aerial Vehicle, UAV), 로봇, 증강 현실(Augmented Reality, AR) 장치, 가 상 현실(virtual reality, VR), 5G 서비스와 관련된 장치 등과 연계 혹은 융복합될 수 있다. 공개특허10-2022-0087429 CPC특허분류 G01C 21/3602 (2019.08) G01C 21/3885 (2020.08) G06Q 50/30 (2015.01) G06T 19/006 (2013.01)명 세 서 청구범위 청구항 1 프로세서가, 안내 지점에 대한 정보 또는 차량의 속도 정보를 외부 서버로 전송하는 단계; 상기 외부 서버가, 상기 안내 지점에 대한 정보 또는 상기 차량의 속도 정보에 기초하여, 후보 차량을 검색하는 단계; 상기 외부 서버가, 상기 프로세서에 의해 기 설정된 우선 순위에 따라 상기 후보 차량 중 영상 제공 차량을 선 택하는 단계; 상기 외부 서버가, 상기 영상 제공 차량으로부터 수신한 카메라 영상에 AR(augmented reality)을 이용하여 표시 할 그래픽 객체를 생성하는 단계; 및 상기 프로세서가, 상기 카메라 영상 및 상기 그래픽 객체를 포함하는 안내 지점에 대한 AR 영상 정보를 내비게 이션 화면에 표시하는 단계;를 포함하는 차량용 내비게이션의 AR 영상 제공 방법. 청구항 2 제1 항에 있어서, 상기 프로세서 및 상기 외부 서버는, 5G 통신을 통하여 상호 간 정보를 송수신하는, 차량용 내비게이션의 AR 영 상 제공 방법. 청구항 3 제1 항에 있어서, 상기 전송하는 단계는, 상기 프로세서가, 내비게이션이 안내하는 경로 상에서 사용자에 의해 입력된 선택 신호에 기초하여 상기 안내 지점을 선택하는 단 계; 및 상기 안내 지점에 대한 위치 정보 및 주행 방향 정보를 포함하는 상기 안내 지점에 대한 정보를 상기 외부 서버 로 전송하는 단계;를 더 포함하는, 차량용 내비게이션의 AR 영상 제공 방법. 청구항 4 제1 항에 있어서, 상기 검색하는 단계는, 상기 외부 서버가, 상기 안내 지점을 기준으로, 영상을 제공하는 제1 영역 및 기 설정된 추가 영역인 제2 영역을 포함하는 검색 영 역을 설정하는 단계; 및 상기 검색 영역에 위치하는 타 차량을 예측하는 단계;를 더 포함하는, 차량용 내비게이션의 AR 영상 제공 방법. 청구항 5 제4 항에 있어서, 상기 예측하는 단계는, 상기 외부 서버가, 상기 외부 서버와 통신하는 각 차량의 위치 정보와 속도 정보를 주기적으로 수신하고, 상기 각 차량의 위치 정보와 속도 정보를 기초로, 상기 검색 영역에 위치하는 타 차량을 예측하는 단계;를 더 포함하 는, 차량용 내비게이션의 AR 영상 제공 방법.청구항 6 제4 항에 있어서, 상기 검색하는 단계는, 상기 외부 서버가, 상기 검색 영역에 타 차량이 위치할 것으로 예측하면, 타 차량 각각에 대해서 상기 안내 지 점을 지나가는지를 저장된 프로토콜에 의해 검증하는 단계;를 더 포함하는, 차량용 내비게이션의 AR 영상 제공 방법. 청구항 7 제6 항에 있어서, 상기 검색하는 단계는, 상기 타 차량 중 상기 안내 지점을 지나가는 것으로 검증이 완료된 타 차량을 상기 후보 차량으로 선정하는 단 계;를 더 포함하는, 차량용 내비게이션의 AR 영상 제공 방법. 청구항 8 제7 항에 있어서, 상기 선택하는 단계는, 상기 검색 영역 내의 상기 후보 차량의 수를 판단하는 단계;를 더 포함하고, 상기 후보 차량의 수가 단수인 경우, 상기 선정된 후보 차량을 상기 영상 제공 차량으로 선택하고, 상기 후보 차량의 수가 복수인 경우, 우선 순위에 따라 상기 영상 제공 차량을 선택하는, 차량용 내비게이션의 AR 영상 제공 방법. 청구항 9 제8 항에 있어서, 상기 선택하는 단계는, 상기 외부 서버가, 상기 프로세서에 의해 선택된 우선 순위의 기준에 따라 제1 영상 제공 차량을 선택하는 단계;를 더 포함하고, 상기 우선 순위의 기준은, 상기 제1 영역 내에서, 상기 안내 지점과의 상대적 거리가 가까운 차량 기준 또는 상기 안내 지점과의 상대적 거리가 먼 차량 기준을 포함하는, 차량용 내비게이션의 AR 영상 제공 방법. 청구항 10 제9 항에 있어서, 상기 제1 영상 제공 차량이, 상기 제1 영역에 진입 시 상기 카메라 영상을 제공하는 단계;를 더 포함하고, 상기 카메라 영상은, 상기 제1 영상 제공 차량에 장착된 카메라로 촬영한 영상 또는 상기 제1 영상 제공 차량 내부의 이동 단말기에 장착된 카메라로 촬영한 영상 중 적어도 어느 하나인, 차량용 내비게이션의 AR 영상 제공 방법. 청구항 11 제10 항에 있어서, 상기 제1 영상 제공 차량이, 상기 안내 지점을 통과하면 상기 카메라 영상의 제공을 종료하는 단계; 및 상기 외부 서버가, 상기 후보 차량 중 상기 선택된 우선 순위의 기준에 따라 제2 영상 제공 차량을 선택하는 단 계;를 더 포함하는, 차량용 내비게이션의 AR 영상 제공 방법.청구항 12 제11 항에 있어서, 상기 제2 영상 제공 차량을 선택하는 단계는, 상기 외부 서버가, 상기 제2 영상 제공 차량에 대해 상기 안내 지점을 지나가는지를 저장된 프로토콜에 의해 재 검증하는 단계;를 더 포함하는, 차량용 내비게이션의 AR 영상 제공 방법. 청구항 13 제12 항에 있어서, 상기 제2 영상 제공 차량이 상기 안내 지점을 지나가는 것으로 재검증이 완료되면, 상기 제2 영상 제공 차량이, 상기 제1 영역에 진입 시 상기 카메라 영상을 제공하는 단계; 더 포함하는, 차량용 내비게이션의 AR 영상 제공 방법. 청구항 14 제8 항에 있어서, 상기 외부 서버는, 상기 후보 차량의 수가 기 설정된 수 이상이면 상기 안내 지점의 주변 구간을 정체 구간으로 판단하고, 상기 정체 구간의 시작 지점을 기준으로 상기 검색 영역을 재설정하는, 차량용 내비게이션의 AR 영상 제공 방법. 청구항 15 제14 항에 있어서, 상기 외부 서버는, 상기 정체 구간 내의 각 차량으로부터 순간 촬영 이미지를 수신하고, 상기 순간 촬영 이미지를 연결하여 상기 카메라 영상을 생성하는, 차량용 내비게이션의 AR 영상 제공 방법. 청구항 16 제1 항에 있어서, 상기 생성하는 단계는, 상기 프로세서가, 저장된 캘리브레이션 파라미터 값을 상기 외부 서버로 전송하는 단계; 상기 외부 서버가, 상기 캘리브레이션 파라미터 값을 기준으로 상기 카메라 영상의 캘리브레이션을 수행하는 단 계; 및 상기 캘리브레이션이 완료된 카메라 영상에 표시할 그래픽 객체를 생성하는 단계;를 포함하는, 차량용 내비게이 션의 AR 영상 제공 방법. 청구항 17 제16 항에 있어서, 상기 그래픽 객체는, 자차(ego vehicle)의 주행 경로를 안내하는 카펫, TBT(turn by turn) 또는 상기 안내 지점까지의 잔여 거리 표 시 바(bar) 중 적어도 어느 하나를 포함하는, 차량용 내비게이션의 AR 영상 제공 방법. 청구항 18 제17 항에 있어서, 상기 표시하는 단계는,상기 프로세서가, 상기 외부 서버로부터 상기 카메라 영상 및 상기 그래픽 객체를 포함하는 안내 지점에 대한 AR 영상 정보를 수신하는 단계; 및 상기 프로세서가, 상기 카메라 영상에 상기 그래픽 객체를 중첩하여 상기 내비게이션 화면의 일 영역에 상기 AR 영상 정보를 표시하는 단계;를 포함하는 차량용 내비게이션의 AR 영상 제공 방법. 청구항 19 제1 항에 있어서, 상기 외부 서버는, 상기 안내 지점이 복수의 턴 안내가 필요한 지점으로 판단하면, 상기 안내 지점을 제1 지점 및 제2 지점으로 나 누어 상기 제1 지점에 대한 제1 AR 영상 정보 및 상기 제2 지점에 대한 제2 AR 영상 정보를 생성하고, 상기 프로세서는, 상기 제1 AR 영상 정보 및 상기 제2 AR 영상 정보를 상기 내비게이션 화면의 일 영역에 표시하는, 차량용 내비 게이션의 AR 영상 제공 방법. 청구항 20 제19 항에 있어서, 상기 프로세서는, 자차가 상기 제1 지점을 통과할 때까지 상기 제1 AR 영상 정보 및 상기 제2 AR 영상 정보를 표시하고, 상기 자차가 상기 제1 지점을 통과하면, 상기 제2 지점을 통과할 때까지 상기 제1 AR 영상 정보를 표시하는, 차 량용 내비게이션의 AR 영상 제공 방법. 발명의 설명"}
{"patent_id": "10-2022-7005874", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 차량용 내비게이션의 영상 제공 방법에 관한 것으로, 보다 상세하게는 안내 지점을 통과할 것으로 예 상되는 타차량으로부터 제공받은 영상에 증강 현실(augmented reality, AR) 컨텐츠를 표시하여 사용자에게 제공 하는 방법에 관한 발명이다."}
{"patent_id": "10-2022-7005874", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "차량은 탑승하는 사용자가 원하는 방향으로 이동시키는 장치이다. 대표적으로 자동차를 예를 들 수 있다. 자율 주행 차량은 인간의 운전 조작 없이 자동으로 주행할 수 있는 차량을 의미한다. 내비게이션은 현재 위치로부터 목적지까지의 거리 및 교통상황을 고려하여 선택한 최적의 경로를 따라 안내하는 도로 및 교통정보 제공 시스템으로, 다양한 편리성과 기능으로 인하여 수요가 높아져 보편화 되었다. 내비게이 션의 형태는 다양하나, 일반적으로 GPS 수신기에서 4개 이상의 위성으로부터 현재 자동차의 위치정보를 얻고, 그 위치정보와 미리 구축되어 있는 전자지도 데이터를 사용하고 맵 매칭 기술을 이용하여 2차원 지도 화면으로 보여주는 방식으로 구성되어 있다. 그러나 이러한 방식은 전자지도를 화면에 실시간으로 출력시 자동차가 실제로 이동하는 방향에 따른 정확한 시 야확보가 어렵고, 불필요한 정보도 보여주게 되며, 이동 속도에 맞춰 이미지 데이터가 화면에 적시에 로딩되지 않아 화면과 실제간의 불일치가 생기고, 실제 3차원 환경과 2차원 평면지도간의 상이함으로 인한 불편한 문제점 등이 있다. 이에 3차원 전자지도가 등장하였으나, 3차원 전자지도의 구현 및 수정이 용이하지 않으며, 제작비용이 높고, 2 차원 전자지도보다 지도 데이터 공간이 많이 요구되며, 위치 갱신과정에서 더 많은 정보처리가 요구되어 실제 환경과 3차원 이미지의 화면상 불일치가 발생하기 쉬운 문제점 등이 있다. 이에 증강 현실을 이용한 내비게이션 이 등장하였다. 증강 현실(augmented reality, AR) 기술은 현실의 환경에 가상 사물이나 정보를 합성하여, 가상 사물이나 정보가 현실의 환경에 존재하는 사물처럼 보이도록 하는 기술이다. ‘증강 현실 내비게이션’이란 차량에 부착된 카메라를 이용하여 현재 주행중인 도로 영상을 촬영하고, 그 도로 영상 화면 위에 가상의 경로선을 오버레이하는 증강현실 기법을 이용하여 구현한 내비게이션을 말한다. 즉, 카 메라를 통하여 보는 실사를 배경으로 목적지 또는 관심 있는 지점을 GPS 센서와 자기장 센서, 오리엔테이션 센 서 등을 기반으로 표현하는 시스템이다. 그러나 이또한, 카메라를 통하여 보는 실사가 전제가 되므로, 카메라가 찍은 영상은 카메라의 성능에 따라 일정 거리까지로 제한되어 있기 때문에 더 먼 거리의 주행 안내 정보를 확인할 수 없는 문제점이 있었다. 또한, 관심 있는 교차로에서의 교통 정보는 TPEG, XM, TMC 등을 이용하여 확인 가능하나, 일정 간격의 지연이 존재하고, 실 제 도로 영상은 볼 수 없었다. 도로 CCTV는 실제 도로 영상을 확인할 수 있으나, 지역이 제한되어 있고, 일정 간격의 지연이 존재하는 문제점이 있었다. 한편, 5G 통신은 최대속도가 20Gbps에 달하는 이동통신 서비스로, 전 세대인 LTE의 최대 속도(1Gbps)보다 20배 가량 빠르며 처리용량도 100배 많다. 초저지연성(지연시간 1ms)과 초연결성이 강점으로 꼽히며 이를 토대로 자 율주행 등을 구현할 수 있어 이에 대한 연구가 활발하게 이루어 지고 있다."}
{"patent_id": "10-2022-7005874", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 상기한 문제점을 해결하기 위하여, 5G 통신 기술을 사용하여 교차로를 지나가는 각 차량의 카메라로 부터 실시간 영상을 외부 서버로 전송하고, 상기 외부 서버에서 상기 실시간 영상을 요청한 차량으로 각 교차로 의 실시간 영상을 제공하는 영상 제공 방법을 제공하는데 목적이 있다. 또한, 각 교차로의 실시간 영상을 제공하면서, AR 컨텐츠를 함께 제공하는 AR 영상 제공 방법을 제공하는데 목 적이 있다. 또한, 본 발명은, 우회전 후 바로 좌회전 안내 등의 복합 안내의 경우 실시간 영상 및 AR 컨텐츠를 통해 바로 다음 안내를 대비할 수 있는 AR 영상 제공 방법을 제공하는데 목적이 있다. 본 발명의 과제들은 이상에서 언급한 과제들로 제한되지 않으며, 언급되지 않은 또 다른 과제들은 아래의 기재 로부터 당업자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2022-7005874", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기 과제를 달성하기 위하여, 본 발명에 따른 차량용 내비게이션의 AR 영상 제공 방법은, 프로세서가 안내 지 점에 대한 정보 및 차량의 속도 정보를 외부 서버로 전송하는 단계; 상기 외부 서버가 상기 안내 지점에 대한 정보 및 상기 차량의 속도 정보에 기초하여, 후보 차량을 검색하는 단계; 상기 외부 서버가 상기 프로세서에 의 해 기 설정된 우선 순위에 따라 상기 후보 차량 중 영상 제공 차량을 선택하는 단계; 상기 외부 서버가 상기 영 상 제공 차량으로부터 수신한 카메라 영상에 AR(augmented reality)을 이용하여 표시할 그래픽 객체를 생성하는 단계; 및 상기 프로세서가 상기 카메라 영상 및 상기 그래픽 객체를 포함하는 안내 지점에 대한 AR 영상 정보를 내비게이션 화면에 표시하는 단계;를 포함한다. 또한, 본 발명에 다른 차량용 내비게이션의 AR 영상 제공 방법은, 5G 통신을 통하여 프로세서 및 외부 서버 상 호 간 정보를 송수신하는 단계;를 포함한다. 또한, 본 발명에 다른 차량용 내비게이션의 AR 영상 제공 방법은, 외부 서버가 안내 지점을 복수의 턴 안내가 필요한 지점으로 판단하면, 안내 지점을 제1 지점 및 제2 지점으로 나누어 상기 제1 지점에 대한 제1 AR 영상 정보 및 상기 제2 지점에 대한 제2 AR 영상 정보를 생성하고, 각각에 대하여 디스플레이를 통해 표시하는 단 계;를 포함한다. 기타 본 발명의 구체적인 사항들은 상세한 설명 및 도면들에 포함되어 있다."}
{"patent_id": "10-2022-7005874", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명에 따르면 다음과 같은 효과가 하나 혹은 그 이상 있다. 첫째, 5G 통신을 통해 영상 제공 차량으로부터 안내 지점에 대한 영상을 제공받음으로써, 지연 없이 실시간으로 안내 지점에 대한 영상을 확인할 수 있는 효과가 있다.둘째, 안내 지점에 AR 영상 정보를 통해 안내 지점의 교통 상황을 시각적으로 확인하고, 교통 상황에 대해 유연 하게 대처할 수 있는 효과가 있다. 셋째, 사용자가 선택한 안내 지점에 대해서만 AR 영상을 제공함으로써, 데이터 사용량을 줄이고 사용자 친화적 인 내비게이션 기능을 제공할 수 있는 효과가 있다. 넷째, 안내 지점을 제1 지점 및 제2 지점으로 나누고 각각에 대해 AR 영상 정보를 생성함으로써, 안전하고 효율 적인 복합 안내를 제공할 수 있는 효과가 있다."}
{"patent_id": "10-2022-7005874", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 2, "content": "본 발명의 효과들은 이상에서 언급한 효과들로 제한되지 않으며, 언급되지 않은 또 다른 효과들은 청구범위의 기재로부터 당업자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2022-7005874", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 첨부된 도면을 참조하여 본 명세서에 개시된 실시 예를 상세히 설명하되, 도면 부호에 관계없이 동일하거 나 유사한 구성요소는 동일한 참조 번호를 부여하고 이에 대한 중복되는 설명은 생략하기로 한다. 이하의 설명 에서 사용되는 구성요소에 대한 접미사 \"모듈\" 및 \"부\"는 명세서 작성의 용이함만이 고려되어 부여되거나 혼용 되는 것으로서, 그 자체로 서로 구별되는 의미 또는 역할을 갖는 것은 아니다. 또한, 본 명세서에 개시된 실시 예를 설명함에 있어서 관련된 공지 기술에 대한 구체적인 설명이 본 명세서에 개시된 실시 예의 요지를 흐릴 수 있다고 판단되는 경우 그 상세한 설명을 생략한다. 또한, 첨부된 도면은 본 명세서에 개시된 실시 예를 쉽게 이 해할 수 있도록 하기 위한 것일 뿐, 첨부된 도면에 의해 본 명세서에 개시된 기술적 사상이 제한되지 않으며, 본 발명의 사상 및 기술 범위에 포함되는 모든 변경, 균등물 내지 대체물을 포함하는 것으로 이해되어야 한다. 제1, 제2 등과 같이 서수를 포함하는 용어는 다양한 구성요소들을 설명하는데 사용될 수 있지만, 상기 구성요소 들은 상기 용어들에 의해 한정되지는 않는다. 상기 용어들은 하나의 구성요소를 다른 구성요소로부터 구별하는 목적으로만 사용된다. 어떤 구성요소가 다른 구성요소에 \"연결되어\" 있다거나 \"접속되어\" 있다고 언급된 때에는, 그 다른 구성요소에 직접적으로 연결되어 있거나 또는 접속되어 있을 수도 있지만, 중간에 다른 구성요소가 존재할 수도 있다고 이 해되어야 할 것이다. 반면에, 어떤 구성요소가 다른 구성요소에 \"직접 연결되어\" 있다거나 \"직접 접속되어\" 있다고 언급된 때에는, 중간에 다른 구성요소가 존재하지 않는 것으로 이해되어야 할 것이다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 출원에서, \"포함한다\" 또는 \"가지다\" 등의 용어는 명세서상에 기재된 특징, 숫자, 단계, 동작, 구성요소, 부 품 또는 이들을 조합한 것이 존재함을 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성요소, 부품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되 어야 한다. 도 1은 본 발명의 실시예에 따른 차량용 내비게이션 시스템을 도시한 도면이다. 도 1을 참조하면, 본 발명의 실시예에 따른 차량용 내비게이션 시스템은, 차량, 외부 서버 또는 후 보 차량 중 적어도 어느 하나를 포함할 수 있다. 차량은, 외부 서버 또는 후보 차량과 5G 통신 을 통하여 정보를 송수신할 수 있다. 외부 서버는, 차량 또는 후보 차량과 5G 통신을 통하여 정보 를 송수신할 수 있다. 후보 차량은, 차량 또는 외부 서버와 5G 통신을 통하여 정보를 송수신할 수 있다. 차량은 도로나 선로 위를 달리는 수송 수단으로 정의된다. 차량은 자동차, 기차, 오토바이를 포함하는 개념이다. 차량은 동력원으로서 엔진을 구비하는 내연기관 차량, 동력원으로서 엔진과 전기 모터를 구비하 는 하이브리드 차량, 동력원으로서 전기 모터를 구비하는 전기 차량 등을 모두 포함하는 개념일 수 있다. 차량 은 공유형 차량일 수 있다. 차량은 자율 주행 차량일 수 있다. 외부 서버는 실시간 영상 정보를 제공하는 서버를 포함할 수 있다. 외부 서버는 증강 현실(augmented reality, AR) 컨텐츠를 제공하는 서버를 포함할 수 있다. 외부 서버는 실시간 교통 정보를 제공하는 서버를 포함할 수 있다. 외부 서버는 차량으로부터 안내 지점에 대한 정보 및 차량의 속도 정보를 수신할 수 있다. 외부 서버 는 안내 지점에 대한 정보 및 차량의 속도 정보에 기초하여, 후보 차량을 검색할 수 있다. 외부 서버 는 설정된 우선 순위에 따라 후보 차량 중 영상 제공 차량을 선택할 수 있다. 외부 서버는 영상 제공 차량으로부터 카메라 영상을 수신할 수 있다. 외부 서버는 수신한 카메라 영상 에 AR을 이용하여 표시할 그래픽 객체를 생성할 수 있다. 외부 서버는 카메라 영상 및 그래픽 객체를 포함 하는 AR 영상 정보 차량으로 송신할 수 있다. 후보 차량은 외부 서버에 의해 설정된 검색 영역 내에서 검증이 완료된 차량을 의미할 수 있다. 후보 차량은 영상 제공 차량을 포함할 수 있다. 영상 제공 차량은 설정된 우선 순위에 따라 제1 영상 제공 차량 또는 제2 영상 제공 차량을 포함할 수 있다. 이하 본 명세서에서 제2 영상 제공 차량으로 별도의 표시 를 하지 않은 영상 제공 차량은 제1 영상 제공 차량을 의미한다. 본 발명에서 차량 및 후보 차량은, 동일 지도 포맷의 내비게이션 어플리케이션을 사용한다. 차량 및 후보 차량은, 현재의 위치 정보, 지도상의 링크 ID 정보, 주행 방향 정보 또는 주행 속도 정보를 주기적 으로 외부 서버에 전송할 수 있다. 위치 정보는 지도와 매칭된 차량의 GPS 정보를 포함할 수 있다. 실시예 에 따라서, 위치 정보는 GPS 정보 및 링크 ID 정보를 포함할 수 있다. 링크 ID는 지도의 도로 데이터를 구성하 는 링크에 대한 ID를 의미할 수 있다. 주행 방향 정보는 링크 상에서의 주행 방향을 의미할 수 있다. 도 2는 본 발명의 실시예에 따른 차량의 제어 블록도이다. 도 2를 참조하면, 차량은 전자 장치, 사용자 인터페이스 장치, 오브젝트 검출 장치, 통신 장치, 운전 조작 장치, 메인 ECU, 차량 구동 장치, 주행 시스템, 센싱부 및 위 치 데이터 생성 장치를 포함할 수 있다. 전자 장치는, 내비게이션 동작을 수행하기 위한 전자 장치를 의미할 수 있다. 전자 장치는, 내비게이 션 동작 중 외부 서버로부터 제공받은 AR 영상 정보를 사용자 인터페이스 장치를 통해 표시하기 위한 전자 장치를 의미할 수 있다. 사용자 인터페이스 장치는, 차량과 사용자와의 소통을 위한 장치이다. 사용자 인터페이스 장치는, 사용자 입력을 수신하고, 사용자에게 차량에서 생성된 정보를 제공할 수 있다. 차량은, 사용자 인터페이스 장치를 통해, UI(User Interface) 또는 UX(User Experience)를 구현할 수 있다. 사용자 인터페이스 장치는, 전자 장치에 의해 안전하게 차량의 기능을 조작할 수 있는 UI를 구현 할 수 있다. 사용자 인터페이스 장치는, 입력부와 출력부를 포함할 수 있다. 입력부는, 사용자로부터 정보를 입력받기 위한 것으로, 입력부에서 수집한 데이터는 사용자의 제어 명령으로 처 리될 수 있다. 입력부는 음성 입력부, 제스쳐 입력부, 터치 입력부 및 기계식 입력부를 포함할 수 있다. 출력부는, 시각, 청각 또는 촉각 등과 관련된 출력을 발생시키기 위한 것으로 디스플레이부, 음향 출력부 및 햅 틱 출력부 중 적어도 어느 하나를 포함할 수 있다. 디스플레이부는, 다양한 정보에 대응되는 그래픽 객체를 표시할 수 있다. 디스플레이부는 액정 디스플레이 (liquid crystal display, LCD), 박막 트랜지스터 액정 디스플레이(thin film transistor-liquid crystal display, TFT LCD), 유기 발광 다이오드(organic light-emitting diode, OLED), 플렉서블 디스플레이(flexible display), 3차원 디스플레이(3D display), 전자잉크 디스플레이(e-ink display) 중에서 적어도 하나를 포함할 수 있다. 디스플레이부는, 터치 입력부와 상호 레이어 구조를 이루거나 일체형으로 형성됨으로써, 터치 스크린을 구현할 수 있다. 디스플레이부는, HUD(Head Up Display)로 구현될 수 있다. 이경우, 투사 모듈을 구비하여 윈드 쉴드 또는 윈도우에 투사되는 이미지를 통해 정보를 출력할 수 있다. 디스플레이부는, 투명 디스플레이를 포함할 수 있다. 투명 디스플레이는 윈드 쉴드 또는 윈도우에 부착될 수 있다. 디스플레이부는, 스티어링 휠의 일 영역, 인스투루먼트 패널의 일 영역, 시트의 일 영역, 각 필러의 일 영역, 도어의 일 영역, 센타 콘솔의 일 영역, 헤드 라이닝의 일 영역, 썬바이저의 일 영역에 배치되거나, 윈드 쉴드의 일영역, 윈도우의 일영역에 구현될 수 있다. 한편, 사용자 인터페이스 장치는, 복수의 디스플레이부를 포함할 수 있다. 음향 출력부는, 프로세서로부터 제공되는 전기 신호를 오디오 신호로 변환하여 출력한다. 이를 위해, 음향 출력부는 하나 이상의 스피커를 포함할 수 있다. 햅틱 출력부는, 촉각적인 출력을 발생시킨다. 예를 들면, 스티어링 휠, 안전 벨트, 시트를 진동시켜, 사용자가 출력을 인지할 수 있게 동작할 수 있다. 한편, 사용자 인터페이스 장치는, 차량용 디스플레이 장치로 명명될 수 있다. 오브젝트 검출 장치는, 차량 외부의 오브젝트를 검출할 수 있는 적어도 하나의 센서를 포함할 수 있다. 오브젝트 검출 장치는, 카메라, 레이다, 라이다, 초음파 센서 및 적외선 센서 중 적어도 하나를 포 함할 수 있다. 오브젝트 검출 장치는, 센서에서 생성되는 센싱 신호에 기초하여 생성된 오브젝트에 대한 데이터를 차량에 포함된 적어도 하나의 전자 장치에 제공할 수 있다. 오브젝트는 차량의 운행과 관련된 다양한 물체들일 수 있다. 예를 들면, 차선, 타 차량, 보행자, 이륜차, 교통 신호, 빛, 도로, 구조물, 과속 방지턱, 지형물, 동물 등을 포함할 수 있다. 한편, 오브젝트는 이동 오브젝트와 고정 오브젝트로 분류될 수 있다. 예를 들면, 이동 오브젝트는 타 차량, 보 행자를 포함하는 개념일 수 있고, 고정 오브젝트는 교통 신호, 도로, 구조물을 포함하는 개념일 수 있다. 카메라는, 영상을 이용하여 차량 외부의 오브젝트에 대한 정보를 생성할 수 있다. 카메라는, 적어도 하나의 렌즈, 적어도 하나의 이미지 센서 및 이미지 센서와 전기적으로 연결되어 수신되는 신호를 처리하고, 처리되는 신호에 기초하여 오브젝트에 대한 데이터를 생성하는 적어도 하나의 프로세서를 포함할 수 있다. 카메라는, 모노 카메라, 스테레오 카메라, AVM(Around View Monitoring) 카메라 중 적어도 어느 하나일 수 있다. 카메라는, 다양한 영상 처리 알고리즘을 이용하여, 오브젝트의 위치 정보, 오브젝트와의 거리 정보 또는 오브젝트와의 상대 속도 정보를 획득할 수 있다. 예를 들면, 카메라는 획득된 영상에서, 시간에 따른 오브젝트 크기의 변화를 기초로, 오브젝트와의 거리 정보 및 상대 속도 정보를 획득할 수 있다. 예를 들면, 카메라는 핀홀(pin hole) 모델, 노면 프로파일링 등을 통해, 오브젝트와의 거리 정보 및 상대 속도 정보를 획득할 수 있다. 예를 들면, 카메라는 스테레오 카메라에서 획득된 스테레오 영상에서 디스패러티(disparity) 정보를 기초로 오 브젝트와의 거리 정보 및 상대 속도 정보를 획득할 수 있다. 레이다는, 전파를 이용하여 차량 외부의 오브젝트에 대한 정보를 생성할 수 있다. 레이다는 전자파 송신부, 전자파 수신부 및 전자파 송신부 및 전자파 수신부와 전기적으로 연결되어, 수신되는 신호를 처리하고, 처리되 는 신호에 기초하여 오브젝트에 대한 데이터를 생성하는 적어도 하나의 프로세서를 포함할 수 있다. 레이다는, 전파 발사 원리상 펄스 레이다(Pulse Radar) 방식 또는 연속파 레이다(Continuous Wave Radar) 방식 으로 구현될 수 있다. 레이다는 연속파 레이다 방식 중에서 신호 파형에 따라 FMCW(Frequency Modulated Continuous Wave)방식 또는 FSK(Frequency Shift Keyong) 방식으로 구현될 수 있다. 레이다는 전자파를 매개로, TOF(Time of Flight) 방식 또는 페이즈 쉬프트(phase-shift) 방식에 기초하여, 오브젝트를 검출하고, 검출된 오브젝트의 위치, 검출된 오브젝트와의 거리 및 상대 속도를 검출할 수 있다. 라이다는, 레이저 광을 이용하여, 차량 외부의 오브젝트에 대한 정보를 생성할 수 있다. 라이다는, 광 송신 부, 광 수신부 및 광 송신부 및 광 수신부와 전기적으로 연결되어, 수신되는 신호를 처리하고, 처리된 신호에 기초하여 오브젝트에 대한 데이터를 생성하는 적어도 하나의 프로세서를 포함할 수 있다. 라이다는, TOF(Time of Flight) 방식 또는 페이즈 쉬프트(phase-shift) 방식으로 구현될 수 있다. 라이다는, 구동식 또는 비구동식으로 구현될 수 있다. 구동식으로 구현되는 경우, 라이다는 모터에 의해 회전되며, 차량 주변의 오브젝트를 검출할 수 있다. 비구동식으로 구현되는 경우, 라이다는 광 스티어링에 의해, 차량을 기준으로 소정 범위 내에 위치하는 오브젝트를 검출할 수 있다. 차량은, 복수의 비구동식 라이다를 포함할 수 있다. 라이다는 레이저 광 매개로, TOF(Time of Flight) 방식 또는 페이즈 쉬프트(phase-shift) 방식에 기초하여, 오브젝트를 검출하고, 검출된 오브젝트의 위치, 검출된 오 브젝트와의 거리 및 상대 속도를 검출할 수 있다. 통신 장치는, 차량 외부에 위치하는 디바이스와 신호를 교환할 수 있다. 통신 장치는, 인프라(예 를 들면, 서버, 방송국) 및 타 차량 중 적어도 어느 하나와 신호를 교환할 수 있다. 통신 장치는, 통신을 수행하기 위해 송신 안테나, 수신 안테나, 각종 통신 프로토콜이 구현 가능한 RF(Radio Frequency) 회로 및 RF 소자 중 적어도 어느 하나를 포함할 수 있다. 통신 장치는, 근거리 통신부, 위치 정보부, V2X 통신부, 광통신부, 방송 송수신부, ITS(Intelligent Transport Systems) 통신부를 포함할 수 있다. V2X 통신부는, 서버(V2I : Vehicle to Infra), 타 차량(V2V : Vehicle to Vehicle) 또는 보행자(V2P : Vehicle to Pedestrian)와의 무선 통신 수행을 위한 유닛이다. V2X 통신부는, 인프라와의 통신(V2I), 차량간 통신(V2V), 보행자와의 통신(V2P) 프로토콜이 구현 가능한 RF 회로를 포함할 수 있다. 한편, 통신 장치는, 사용자 인터페이스 장치와 함께 차량용 디스플레이 장치를 구현할 수 있다. 이경 우, 차량용 디스플레이 장치는 텔레 매틱스(telematics) 장치 또는 AVN(Audio Video Navigation) 장치로 명명 될 수 있다. 통신 장치는, 5G(예를 들면, 뉴 라디오(new radio, NR)) 방식을 이용하여, 차량 외부에 위치하는 디바 이스와 통신할 수 있다. 통신 장치는 5G 방식을 이용하여, V2X(V2V, V2D, V2P, V2N) 통신을 구현할 수 있 다. 운전 조작 장치는, 운전을 위한 사용자 입력을 수신하는 장치이다. 메뉴얼 모드인 경우, 차량은 운전 조작 장치에 의해 제공되는 신호에 기초하여 운행될 수 있다. 운전 조작 장치는, 조향 입력 장치(예 를 들면, 스티어링 휠), 가속 입력 장치(예를 들면, 가속 페달) 및 브레이크 입력 장치(예를 들면, 브레이크 페 달)를 포함할 수 있다. 메인 ECU는, 차량 내에 구비되는 적어도 하나의 전자 장치의 전반적인 동작을 제어할 수 있다. 차량 구동 장치는, 차량내 각종 구동 장치를 전기적으로 제어하는 장치이다. 차량 구동 장치는, 파워 트레인 구동 장치, 샤시 구동 장치, 도어/윈도우 구동 장치, 안전 장치 구동 장치, 램프 구동 장치 및 공 조 구동 장치를 포함할 수 있다. 파워 트레인 구동 장치는, 동력원 구동 장치 및 변속기 구동 장치를 포함할 수 있다. 샤시 구동 장치는, 조향 구동 장치, 브레이크 구동 장치 및 서스펜션 구동 장치를 포함할 수 있다. 차량 구동 장치는, 제어 ECU(Electronic Control Unit)로 명명될 수 있다. 주행 시스템은, 오브젝트 검출 장치에서 수신한 오브젝트에 대한 데이터에 기초하여, 차량의 움 직임을 제어하거나, 사용자에게 정보를 출력하기 위한 신호를 생성할 수 있다. 주행 시스템은, 생성된 신 호를, 사용자 인터페이스 장치, 메인 ECU 및 차량 구동 장치 중 적어도 어느 하나에 제공할 수 있다. 주행 시스템은, ADAS를 포함하는 개념일 수 있다. ADAS는, 적응형 크루즈 컨트롤 시스템(ACC : Adaptive Cruise Control), 자동 비상 제동 시스템(AEB : Autonomous Emergency Braking), 전방 충돌 알림 시 스템(FCW : Foward Collision Warning), 차선 유지 보조 시스템(LKA : Lane Keeping Assist), 차선 변경 보조 시스템(LCA : Lane Change Assist), 타겟 추종 보조 시스템(TFA : Target Following Assist), 사각 지대 감시 시스템(BSD : Blind Spot Detection), 적응형 하이빔 제어 시스템(HBA : High Beam Assist), 자동 주차 시스템 (APS : Auto Parking System), 보행자 충돌 알림 시스템(PD collision warning system), 교통 신호 검출 시스 템(TSR : Traffic Sign Recognition), 교통 신호 보조 시스템(TSA : Trafffic Sign Assist), 나이트 비전 시스 템(NV : Night Vision), 운전자 상태 모니터링 시스템(DSM : Driver Status Monitoring) 및 교통 정체 지원 시 스템(TJA : Traffic Jam Assist) 중 적어도 어느 하나를 구현할 수 있다. 주행 시스템은, 자율 주행 ECU(Electronic Control Unit)를 포함할 수 있다. 자율 주행 ECU는 차량 내 다른 전자 장치들 중 적어도 어느 하나로부터 수신되는 데이터에 기초하여, 자율 주행 경로를 설정할 수 있 다. 자율 주행 ECU는, 사용자 인터페이스 장치, 오브젝트 검출 장치, 통신 장치, 센싱부 및 위치 데이터 생성 장치 중 적어도 어느 하나로부터 수신되는 데이터에 기초하여, 자율 주행 경로를 설 정할 수 있다. 자율 주행 ECU는, 자율 주행 경로를 따라 차량이 주행하도록 제어 신호를 생성할 수 있다. 자율 주행 ECU에서 생성된 제어 신호는 메인 ECU 및 차량 구동 장치 중 적어도 어느 하나로 제공될 수 있다. 센싱부는, 차량의 상태를 센싱할 수 있다. 센싱부는, IMU(inertial navigation unit) 센서, 충돌 센 서, 휠 센서(wheel sensor), 속도 센서, 경사 센서, 중량 감지 센서, 헤딩 센서(heading sensor), 포지션 모듈 (position module), 차량 전진/후진 센서, 배터리 센서, 연료 센서, 타이어 센서, 핸들 회전에 의한 스티어링 센서, 차량 내부 온도 센서, 차량 내부 습도 센서, 초음파 센서, 조도 센서, 가속 페달 포지션 센서 및 브레이 크 페달 포지션 센서 중 적어도 어느 하나를 포함할 수 있다. 한편, IMU(inertial navigation unit) 센서는 가 속도 센서, 자이로 센서, 자기 센서 중 하나 이상을 포함할 수 있다. 센싱부는, 적어도 하나의 센서에서 생성되는 신호에 기초하여, 차량의 상태 데이터를 생성할 수 있다. 센 싱부는, 차량 자세 정보, 차량 모션 정보, 차량 요(yaw) 정보, 차량 롤(roll) 정보, 차량 피치(pitch) 정 보, 차량 충돌 정보, 차량 방향 정보, 차량 각도 정보, 차량 속도 정보, 차량 가속도 정보, 차량 기울기 정보, 차량 전진/후진 정보, 배터리 정보, 연료 정보, 타이어 정보, 차량 램프 정보, 차량 내부 온도 정보, 차량 내부 습도 정보, 스티어링 휠 회전 각도, 차량 외부 조도, 가속 페달에 가해지는 압력, 브레이크 페달에 가해지는 압 력 등에 대한 센싱 신호를 획득할 수 있다. 센싱부는 그 외, 가속페달센서, 압력센서, 엔진 회전 속도 센서(engine speed sensor), 공기 유량 센서 (AFS), 흡기 온도 센서(ATS), 수온 센서(WTS), 스로틀 위치 센서(TPS), TDC 센서, 크랭크각 센서(CAS), 등을 더 포함할 수 있다. 센싱부는, 센싱 데이터를 기초로, 차량 상태 정보를 생성할 수 있다. 차량 상태 정보는, 차량 내부에 구비 된 각종 센서에서 감지된 데이터를 기초로 생성된 정보일 수 있다. 예를 들면, 차량 상태 정보는, 차량의 자세 정보, 차량의 속도 정보, 차량의 기울기 정보, 차량의 중량 정보, 차량의 방향 정보, 차량의 배터리 정보, 차량의 연료 정보, 차량의 타이어 공기압 정보, 차량의 스티어링 정보, 차량 실내 온도 정보, 차량 실내 습도 정보, 페달 포지션 정보 및 차량 엔진 온도 정보 등을 포함할 수 있다. 한편, 센싱부는, 텐션 센서를 포함할 수 있다. 텐션 센서는 안전 벨트의 텐션 상태에 기초하여 센싱 신호를 생 성할 수 있다. 위치 데이터 생성 장치는, 차량의 위치 데이터를 생성할 수 있다. 위치 데이터 생성 장치는, GPS(Global Positioning System) 및 DGPS(Differential Global Positioning System) 중 적어도 어느 하나를 포 함할 수 있다. 위치 데이터 생성 장치는, GPS 및 DGPS 중 적어도 어느 하나에서 생성되는 신호에 기초하여 차량의 위치 데이터를 생성할 수 있다. 실시예에 따라, 위치 데이터 생성 장치는, 센싱부의 IMU(Inertial Measurement Unit) 및 오브젝트 검출 장치의 카메라 중 적어도 어느 하나에 기초하여 위치데이터를 보정할 수 있다. 위치 데이터 생성 장치는, 위치 측위 장치로 명명될 수 있다. 위치 데이터 생성 장치는, GNSS(Global Navigation Satellite System)로 명명될 수 있다. 차량은, 내부 통신 시스템을 포함할 수 있다. 차량에 포함되는 복수의 전자 장치는, 내부 통신 시 스템을 매개로 신호를 교환할 수 있다. 신호에는 데이터가 포함될 수 있다. 내부 통신 시스템은, 적어 도 하나의 통신 프로토콜(예를 들면, CAN, LIN, FlexRay, MOST, 이더넷)을 이용할 수 있다. 도 3은 본 발명의 실시예에 따른 전자 장치의 제어 블록도이다. 도 3을 참조하면, 전자 장치는, 메모리, 프로세서, 인터페이스부 및 전원 공급부를 포함할 수 있다. 메모리는, 프로세서와 전기적으로 연결된다. 메모리는, 유닛에 대한 기본데이터, 유닛의 동작제 어를 위한 제어데이터, 입출력되는 데이터를 저장할 수 있다. 메모리는 프로세서에서 처리된 데이터 를 저장할 수 있다. 메모리는 하드웨어적으로, ROM, RAM, EPROM, 플래시 드라이브, 하드 드라이브 중 적어 도 어느 하나로 구성될 수 있다. 메모리는, 프로세서의 처리 또는 제어를 위한 프로그램 등, 전자 장 치 전반의 동작을 위한 다양한 데이터를 저장할 수 있다. 메모리는, 프로세서와 일체형으로 구 현될 수 있다. 실시예에 따라, 메모리는 프로세서의 하위 구성으로 분류될 수 있다. 인터페이스부는, 차량 내에 구비되는 적어도 하나의 전자 장치와 유선 또는 무선으로 신호를 교환할 수 있다. 인터페이스부는, 오브젝트 검출 장치, 통신 장치, 운전 조작 장치, 메인 ECU, 차량 구동 장치, ADAS, 센싱부 및 위치 데이터 생성 장치 중 적어도 어느 하나 와 유선 또는 무선으로 신호를 교환할 수 있다. 인터페이스부는, 통신 모듈, 단자, 핀, 케이블, 포트, 회 로, 소자 및 장치 중 적어도 어느 하나로 구성될 수 있다. 인터페이스부는, 외부 서버 또는 외부 기기로부터 데이터를 전송받거나, 인터페이스 장치 내부의 데 이터가 외부 서버 또는 외부 기기로 전송할 수 있다. 이 경우, 인터페이스부는, 인증된 데이터베이스를 가 지는 외부 서버등과 통신을 수행하여 데이터를 획득할 수 있다. 인터페이스부는, 식별 모듈이 구비된 장치를 연결하는 포트를 포함할 수 있다. 식별 모듈은, 인터페이스 장치의 사용 권한을 인증하기 위한 각종 정보를 저장한 칩을 포함할 수 있다. 인터페이스부는, 위치 데이터 생성 장치로부터, 차량 위치 데이터를 수시할 수 있다. 인터페이스 부는, 센싱부로부터 주행 속도 데이터를 수신할 수 있다. 인터페이스부는, 오브젝트 검출 장치 로부터, 차량 주변 오브젝트 데이터를 수신할 수 있다. 전원 공급부는, 전자 장치에 전원을 공급할 수 있다. 전원 공급부는, 차량에 포함된 파워 소스(예를 들면, 배터리)로부터 전원을 공급받아, 전자 장치의 각 유닛에 전원을 공급할 수 있다. 전원 공 급부는, 메인 ECU로부터 제공되는 제어 신호에 따라 동작될 수 있다. 전원 공급부는, SMPS(switched-mode power supply)로 구현될 수 있다. 프로세서는, 메모리, 인터페이스부, 전원 공급부와 전기적으로 연결되어 신호를 교환할 수 있다. 프로세서는, ASICs (application specific integrated circuits), DSPs(digital signal processors), DSPDs(digital signal processing devices), PLDs(programmable logic devices), FPGAs(field programmable gate arrays), 프로세서(processors), 제어기(controllers), 마이크로 컨트롤러(micro- controllers), 마이크로 프로세서(microprocessors), 기타 기능 수행을 위한 전기적 유닛 중 적어도 하나를 이 용하여 구현될 수 있다. 프로세서는, 전원 공급부로부터 제공되는 전원에 의해 구동될 수 있다. 프로세서는, 전원 공급 부에 의해 전원이 공급되는 상태에서 데이터를 수신하고, 데이터를 처리하고, 신호를 생성하고, 신호를 제 공할 수 있다. 프로세서는, 인터페이스부를 통해, 차량 내 다른 전자 장치로부터 정보를 수신할 수 있다. 프로 세서는, 인터페이스부를 통해, 차량 내 다른 전자 장치로 제어 신호를 제공할 수 있다. 프로세서는 사용자 인터페이스 장치를 통해, 사용자가 입력한 신호를 수신할 수 있다. 예를 들면, 프로세 서는, 사용자 인터페이스 장치를 통해, 음성 입력, 제스쳐 입력, 터치 입력 및 기계식 입력 중 적어도 어느 하나를 수신할 수 있다. 프로세서는, 사용자에 의해 입력된 선택 신호에 기초하여 안내 지점을 선택할 수 있다. 안내 지점은 내비 게이션이 안내하는 차량의 주행 경로 상에 위치할 수 있다. 안내 지점은 교차로, 램프 구간의 진입 지점 또 는 진출 지점, 분기점 등 턴(turn) 안내가 필요한 지점을 포함할 수 있다. 프로세서는, 안내 지점에 대한 정보 외부 서버로 전송할 수 있다. 안내 지점에 대한 정보는, 안내 지 점의 위치 정보, 내비게이션이 안내하는 주행 경로를 따라 안내 지점으로 진입하기 전 링크 정보를 포함할 수 있다. 안내 지점의 위치 정보는 안내 지점의 GPS 정보를 포함할 수 있다. 링크 정보는 링크 ID 정보, 링크 길이 정보 또는 링크에 대한 주행 방향 정보 중 적어도 어느 하나를 포함할 수 있다. 프로세서는, 차량의 현재 속도 정보를 외부 서버로 전송할 수 있다. 센싱부는, 차량의 현재 속도 정보를 생성할 수 있다. 프로세서는, 센싱부에서 생성한 차량의 현재 속도 정보를 통 신 장치를 통해 외부 서버로 전송할 수 있다. 프로세서는, 사용자에 의해 입력된 선택 신호에 기초하여 우선 순위를 설정할 수 있다. 우선 순위의 기준 은, 영상 제공 영역 내에서, 안내 지점과의 상대적 거리가 가까운 차량 기준 또는 안내 지점과의 상대적 거리가 먼 차량 기준을 포함할 수 있다. 프로세서는, 외부 서버로부터 안내 지점에 대한 AR 영상 정보를 수신할 수 있다. AR 영상 정보는 캘리 브레이션이 완료된 카메라 영상 및 그래픽 객체를 포함할 수 있다. 프로세서는 저장된 캘리브레이션 결과 값을 외부 서버로 전송할 수 있다. 외부 서버는, 프로세서로부터 수신한 캘리브레이션 결과 값을 기준으로 카메라 영상의 캘리브레이션을 수행할 수 있다. 외부 서버는, 캘리브레이션이 완료된 카메라 영상 에 표시할 그래픽 객체를 생성할 수 있다. 프로세서는, 안내 지점에 대한 AR 영상 정보를 내비게이션 화면에 표시할 수 있다. 프로세서는, 카메 라 영상에 그래픽 객체를 중첩하여 내비게이션 화면의 일 영역에 AR 영상 정보를 표시할 수 있다. 안내 지점은 제1 지점 및 제2 지점을 포함할 수 있다. AR 영상 정보는 제1 지점에 대한 제1 AR 영상 정보 및 제 2 지점에 대한 제2 AR 영상 정보를 포함할 수 있다. 이 경우, 프로세서는, 차량이 제1 지점을 통과할 때까지 제1 AR 영상 정보 및 제2 AR 영상 정보를 표시할 수 있다. 또한, 프로세서는, 차량이 제1 지점 을 통과하면, 제2 지점을 통과할 때까지 제1 AR 영상 정보를 표시하고 제2 AR 영상 정보는 표시하지 않을 수 있 다. 전자 장치는 적어도 하나의 인쇄 회로 기판(printed circuit board, PCB)을 포함할 수 있다. 메모리 , 인터페이스부, 전원 공급부 및 프로세서는, 인쇄 회로 기판에 전기적으로 연결될 수 있 다. 이하 본 명세서에서 차량의 동작은 전자 장치의 동작 또는 프로세서의 동작으로도 설명될 수 있 다. 도 4는 본 발명의 실시예에 따른 AR 영상 제공 방법의 플로우 차트이다. 도 4를 참조하면, 차량, 외부 서버 및 영상 제공 차량은, 서로 간의 정보를 송수신함으로써 AR 영 상을 제공할 수 있다. 최종적으로 차량은, 내비게이션 화면을 통해 AR 영상을 제공할 수 있다. 본 발명의 AR 영상은, 타 차량이 촬영한 안내 지점에 대한 영상에 자차의 주행 경로를 포함한 AR 컨텐츠를 증강 현실을 이 용하여 표시한 영상을 의미한다. 차량용 내비게이션의 AR 영상 제공 방법은, 경로 설정 및 안내 단계(S400), 안내 지점 선택 단계(S405), 데이터 전송 단계(S410), 후보 차량 검색 단계(S415), 영상 제공 차량 선택 단계(S420), 카메라 영상 요청 및 전송 단 계, AR 영상 정보 생성 단계(S435), AR 영상 정보 전송 단계(S440) 및 내비게이션 화면에 표시 단계(S445)를 포 함할 수 있다. 경로 설정 및 안내 단계(S400)는, 차량이 사용자의 입력 신호에 의해 목적지를 입력하고, 내비게이션이 목 적지까지의 경로 설정 및 안내를 제공하는 단계를 포함할 수 있다. 안내 지점 선택 단계(S405)는, 차량이 사용자가 입력한 선택 신호에 의해 안내 지점을 선택하는 단계를 포 함할 수 있다. 안내 지점은 내비게이션이 안내하는 경로 상에 존재할 수 있다. 안내 지점은 교차로, 램프 구간 의 진입 지점 또는 진출 지점, 분기점 등 턴(turn) 안내가 필요한 지점을 포함할 수 있다.데이터 전송 단계(S410)는, 차량이 외부 서버로 AR 영상 정보를 생성하기 위한 데이터를 전송하는 단계 를 포함할 수 있다. 차량이 전송하는 데이터는, 안내 지점에 대한 정보, 차량의 현재 위치 정보 또는 차량의 현재 속도 정보 중 적어도 어느 하나를 포함할 수 있다. 또한, 차량이 전송하는 데이터는, 차량 에 저장된 캘리브레이션 결과 값을 포함할 수 있다. 안내 지점에 대한 정보는, 안내 지점의 위치 정보, 내비게이션이 안내하는 주행 경로를 따라 안내 지점으로 진 입하기 전 링크 정보를 포함할 수 있다. 안내 지점의 위치 정보는 안내 지점의 GPS 정보를 포함할 수 있다. 링 크 정보는 링크 ID 정보, 링크 길이 정보 또는 링크에 대한 주행 방향 정보 중 적어도 어느 하나를 포함할 수 있다. 후보 차량 검색 단계(S415)는, 외부 서버가 차량으로부터 수신한 안내 지점에 대한 정보 또는 차량 속 도 정보에 기초하여 검색 영역을 설정하고, 검색 영역 내에서 후보 차량을 검색하는 단계를 포함할 수 있다. 후보 차량은 안내 지점을 통과할 것으로 예측되는 차량 중 검증을 완료한 차량을 의미할 수 있다. 이 하 상세한 설명은 도 7을 통해 후술한다. 영상 제공 차량 선택 단계(S420)는, 외부 서버가 기 설정된 우선 순위에 따라 후보 차량 중 영상을 제공할 영상 제공 차량을 선택하는 단계를 포함할 수 있다. 우선 순위는 사용자의 선택 신호에 기초하여 차량 에 의해 설정될 수 있다. 우선 순위의 기준은, 영상 제공 영역 내에서, 안내 지점과의 상대적 거리가 가까운 차 량 기준 또는 안내 지점과의 상대적 거리가 먼 차량 기준을 포함할 수 있다. 이하 상세한 설명은 도 7을 통해 후술한다. 카메라 영상 요청 및 전송 단계는, 외부 서버가 영상 제공 차량에게 카메라 영상을 요청(S425)하고, 영 상 제공 차량이 외부 서버에게 카메라 영상을 전송(S430)하는 단계를 포함할 수 있다. 카메라 영상은 영상 제공 차량에 장착된 카메라가 촬영한 영상을 포함할 수 있다. 카메라 영상은 영상 제공 차량 내부 에 위치하는 이동 단말기에 장착된 카메라가 촬영한 영상을 포함할 수 있다. 이 경우, 이동 단말기는 차량용 내 비게이션과 동일 지도 포맷의 내비게이션 어플리케이션을 사용할 수 있다. 영상 제공 차량은, 제1 영역에 진입 시 카메라 영상을 제공하고, 안내 지점을 통과하면 카메라 영상의 제공 을 종료할 수 있다. 제1 영역은, 영상 제공 영역으로서, 도로 종류 또는 교통 상황에 따라 달라질 수 있다. 이 하 제1 영역에 관한 상세한 설명은 도 8을 통해 후술한다. 외부 서버는, 영상 제공 차량의 영상 제공이 종료되면, 후보 차량 중 우선 순위에 따라 제2 영상 제공 차량을 선택할 수 있다. 외부 서버는, 저장된 프로토콜에 의해 제2 영상 제공 차량을 재검증 할 수 있다. 외부 서버는, 제2 영상 제공 차량에 대해 안내 지점을 지나가는지를 확인함으로써 재검증 할 수 있다. 재검증은 저장된 프로토콜에 의해 수행될 수 있다. 제2 영상 제공 차량은 재검증 완료 후, 제1 영역에 진입하면 외부 서버에게 카메라 영상을 제공할 수 있다. AR 영상 정보 생성 단계(S435)는, 외부 서버가 차량으로부터 수신한 캘리브레이션 결과 값을 기준으로 카메라 영상의 캘리브레이션을 수행하는 단계를 포함할 수 있다. 캘리브레이션 결과 값은, 차량에 저장된 빌트인 카메라의 캘리브레이션 파라미터와 projection matrix를 포함할 수 있다. 외부 서버는 영상 제공 차량으로부터 카메라 영상을 수신하고, 캘리브레이션 결과 값을 기준으로 카메 라 영상의 캘리브레이션을 수행할 수 있다. 외부 서버는 캘리브레이션이 완료된 카메라 영상에 표시할 그래 픽 객체를 생성할 수 있다. 그래픽 객체는, 자차(ego vehicle)의 주행 경로를 안내하는 카펫, TBT(turn by turn), 주행 안내 정보 또는 안내 지점까지의 잔여 거리 표시 바(bar) 중 적어도 어느 하나를 포함할 수 있다. TBT는, 주행 경로를 표시한 화살표 이미지일 수 있다. 예를 들면, TBT는 교차로 또는 분기점에서의 주행 경로를 표시하는 좌측, 우측, 직진 또는 유턴 화살표 이미지일 수 있다. TBT는, 차량이 교차로 또는 분기점으로부 터 기 설정 거리 이내에 위치할 때부터 표시될 수 있다. 외부 서버는 캘리브레이션이 완료된 카메라 영상에 표시할 TBT 정보를 생성할 수 있다. 주행 안내 정보는 현재 주행 차선 정보, 진행 방향 방면 정보, 목적 차선 정보, 목적지까지의 거리 정보, TBT 정보 중 적어도 하나 이상의 정보를 포함한다. 주행 안내 정보는 영상 제공 차량이 제공하는 카메라 영상과 분리되어 표시될 수 있다. 안내 지점까지의 잔여 거리 표시 바(bar)는 영상 제공 차량과 안내 지점과의 잔여 거리를 바 형태로 나타낸 이미지일 수 있다. 잔여 거리 표시 바는 영상 제공 차량이 영상을 제공하고부터 줄어들고 안내 지점에 도착 시 사라질 수 있다. AR 영상 정보 전송 단계(S440)는, 외부 서버가 차량에게 AR 영상 정보를 전송하는 단계를 의미할 수 있 다. AR 영상 정보는, 캘리브래이션이 완료된 카메라 영상 및 그래픽 객체를 포함할 수 있다. 내비게이션 화면에 표시 단계(S445)는, 차량이 외부 서버로부터 카메라 영상 및 그래픽 객체를 포함하 는 안내 지점에 대한 AR 영상 정보를 수신하는 단계 및 카메라 영상에 그래픽 객체를 중첩하여 내비게이션 화면 의 일 영역에 AR 영상 정보를 표시하는 단계를 포함할 수 있다. 도 5는 본 발명의 실시예에 따른 안내 지점을 설명하는데 참조되는 도면이다. 도 5를 참조하면, 안내 지점은 목적지까지의 주행 경로 상에 복수개가 존재할 수 있다. 안내 지점은 교차로, 램 프 구간의 진입 지점 또는 진출 지점, 분기점 등 턴(turn) 안내가 필요한 지점을 의미할 수 있다. 안내 지점은 제1 안내 지점 또는 제2 안내 지점을 포함할 수 있다. 사용자는 제1 안내 지점 또 는 제2 안내 지점 중 어느 하나의 안내 지점을 선택할 수 있다. 사용자가 안내 지점을 선택하면, 차량(1 0)은 안내 지점에 대한 정보를 외부 서버로 전송할 수 있다. 안내 지점에 대한 정보는, 안내 지점의 위치 정보 또는 링크 정보를 포함할 수 있다. 링크 정보는 내비게이션이 안내하는 주행 경로를 따라 안내 지점으로 진입하기 전의 링크 정보를 의미할 수 있다. 링크 정보는 링크 ID 정 보, 링크 길이 정보 또는 링크에 대한 주행 방향 정보 중 적어도 어느 하나를 포함할 수 있다. 안내 지점의 위 치 정보는 안내 지점의 GPS 정보를 포함할 수 있다. 예를 들어, 제1 안내 지점에 대한 정보는 표 1, 제2 안내 지점에 대한 정보는 표 2와 같이 제공될 수 있다. 안내 지점에 대한 정보는 내비게이션 어플리게이션에 저장된 맵 데이터로부터 획득할 수 있다. 사용자가 제1 안내 지점 또는 제2 안내 지점을 선택하면, 차량은 표 1 또는 표 2의 정보를 외부 서버 로 전송할 수 있다. 표 1"}
{"patent_id": "10-2022-7005874", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "표 2 도 6은 본 발명의 실시예에 검색 영역을 설명하는데 참조되는 도면이다. 도 6을 참조하면, 검색 영역은 제1 영역 및 제2 영역을 포함할 수 있다. 도 6에 따른 실시예에서, 안 내 지점은 사용자에 의해 선택되었고, 교차로의 교차점이다. 제1 영역은, 안내 지점을 기준으로 차량이 위치하는 방향으로 설정될 수 있다. 제1 영역은, 도로 종류 또는 교통 상황에 따라 달라질 수 있다. 제1 영역은 영상 제공 거리(S)에 비례할 수 있다. 영상 제공 거리(S)는 제1 영역이 속한 도로의 법정 제한 속도(L)와 영상 제공 시간(T)의 곱으로 계산될 수 있다. 제2 영역은, 제1 영역이 끝나는 점을 기준으로 차량이 위치하는 방향으로 설정될 수 있다. 제2 영역은, 추가 이동 거리(D)에 비례할 수 있다. 추가 이동 거리(D)는 제1 영역이 속한 도로의 법정 제한 속 도(L)와 외부 서버가 후보 차량 검색을 위해 소요되는 시간(I)의 곱으로 계산될 수 있다. 외부 서버 는 검색 영역에서 후보 차량을 선정하지 못하였을 경우, 제2 영역을 확대하여 후보 차량을 검색할 수 있다. 검색 영역은 제1 영역 및 제2 영역을 포함할 수 있다. 검색 영역은 검색 거리(C)에 비례할 수 있다. 검색 거리(C)는 영상 제공 거리(S)와 추가 이동 거리(D)의 합으로 계산될 수 있다. 외부 서버는, 검색 영역을 설정하고, 검색 영역에 위치하는 타 차량을 예측할 수 있다. 외부 서 버는 동일한 내비게이션 어플리케이션을 사용하고 있는 타 차량으로부터 주기적으로 위치 정보 및 속도 정 보를 수신할 수 있다. 위치 정보는 GPS 정보 또는 링크 정보 중 적어도 어느 하나를 포함할 수 있다. 외부 서버는, 타 차량으로부터 주기적으로 전송받는 위치 정보 및 속도 정보에 기초하여, 후보 차량의 검색 요청이 온 시점을 기준으로 검색 영역에 위치하는 타 차량을 예측할 수 있다. 예를 들어, 외부 서버는, t초 에 타 차량의 위치 정보와 속도 정보를 수신하고, t+1초에 차량의 후보 차량에 대한 검색 요청을 받았다면, t+1초 기준 타 차량의 위치를 계산하고, 타 차량이 검색 영역에 속해있는지를 판단할 수 있다. 도 6을 참조하면, t+1 초 기준으로 차량 1대가 검색 영역에 위치할 것으로 예측되며, 검증을 완료하면 상 기 차량 1대는 후보 차량으로 선정될 수 있다. 후보 차량이 하나뿐이므로, 상기 차량 1대는 영상 제공 차량으로 자동 선택될 수 있다. 영상 제공 차량은, 제1 영역에 진입하면서 영상 제공 차량에 장착된 카메라로 촬영한 카메라 영상을 외부 서버로 전송할 수 있다. 도 7은 본 발명의 실시예에 따른 후보 차량을 검색하는 단계 및 영상 제공 차량을 선택하는 단계에 대한 플로우 차트이다. 도 7을 참조하면, 후보 차량 검색 단계(S415)는, 제1 영역 설정 단계(S700), 제2 영역 설정 단계(S705), 검색 영역에 위치하는 타 차량을 예측하는 단계(S710), 타차량이 하나 이상인지를 판단하는 단계(S715), 검색 영역을 확대하는 단계(S720), 검증 단계(S725) 및 후보 차량 선정 단계(S730)를 포함할 수 있다. 또한, 영상 제공 차량을 선택하는 단계(S420)는, 후보 차량의 수가 복수인지 여부를 판단하는 단계(S735), 우선 순위에 따라 영상 제공 차량을 선택하는 단계(S740), 및 선정된 후보 차량을 영상 제공 차량으로 선택 하는 단계(S745)를 포함할 수 있다. 제1 영역 설정 단계(S700)는, 외부 서버가 안내 지점을 기준으로, 영상을 제공하는 제1 영역을 설정하는 단 계를 포함할 수 있다. 제1 영역은, 안내 지점을 기준으로 차량이 위치하는 방향으로 설정될 수 있다. 제1 영역은, 도로 종류 또는 교통 상황에 따라 달라질 수 있다. 제1 영역은 영상 제공 거리(S)와 비례할 수 있다. 영상 제공 거리(S)는 제1 영역이 속한 도로의 법정 제한 속도 (L)와 영상 제공 시간(T)의 곱으로 계산될 수 있다. 제2 영역 설정 단계(S705)는, 외부 서버가 제1 영역이 끝나는 점을 기준으로, 기 설정된 추가 영역인 제2 영역을 설정하는 단계를 포함할 수 있다. 제2 영역은, 제1 영역을 기준으로 차량이 위치하는 방향으로 설정 될 수 있다. 제2 영역은, 추가 이동 거리(D)와 비례할 수 있다. 추가 이동 거리(D)는 제1영역이 속한 도로의 법정 제한 속도 (L)와 외부 서버가 후보 차량 검색을 위해 소요되는 시간(I)의 곱으로 계산될 수 있다. 검색 영역에 위치하는 타 차량을 예측하는 단계(S710)는, 제1 영역 및 제2 영역을 포함하는 검색 영역을 설정하 는 단계 및 검색 영역에 위치하는 타 차량을 예측하는 단계를 포함할 수 있다. 검색 영역은 제1 영역 및 제2 영 역의 합으로 계산될 수 있다. 타 차량을 예측하는 단계는 외부 서버가 주기적으로 전송받는 타 차량의 위치 정보 및 속도 정보에 기초하여, 후보 차량의 검색 요청이 온 시점을 기준으로 검색 영역에 위치하는 타 차량을 예측하는 단계를 포함할 수 있다. 타 차량이 하나 이상인지를 판단하는 단계(S715)는, 검색 영역에 위치하는 타 차량이 하나 이상인지를 판단하는 단계를 포함할 수 있다. 외부 서버는, 타 차량이 하나도 검색되지 않은 경우, 검색 영역을 확대할 수 있다. 외부 서버는, 타 차량이 하나 이상 검색된 경우, 검증 단계(S725)로 넘어갈 수 있다. 검색 영역을 확대하는 단계(S720)는, S715 단계에서 타 차량이 하나도 검색되지 않은 경우, 안내 지점 기준으로 검색 영역을 확대하는 단계를 포함할 수 있다. 제1 영역은 도로 종류 또는 교통 상황에 의해 결정되는 영역이고, 제2 영역은 추가되는 영역이므로, 검색 영역을 확대하는 것은 제2 영역을 확대하는 것을 의미할 수 있다. 외부 서버는, 검색 영역을 확대하여 검색 영역 내 타 차량이 하나 이상 존재하는지 여부를 반복적으 로 판단할 수 있다. 검증 단계(S725)는, S715 단계에서 타 차량이 하나 이상 검색된 경우, 타 차량 각각에 대해서 안내 지점을 지나 가는지를 확인하는 단계를 포함할 수 있다. 외부 서버는, 검색 영역에 타 차량이 위치할 것으로 예측하면, 타 차량에게 저장된 프로토콜을 통해 안내 지점을 지나갈 것이지에 대한 검증을 수행할 수 있다. 외부 서버는, 검색 영역에 위치할 것으로 예측된 타 차량 각각에 대해서 검증을 수행하고, 안내 지점을 지 나가지 않는 것으로 검증된 타 차량은 후보 차량에 포함시키지 않고, 해당 목록에서 삭제할 수 있다. 후보 차량 선정 단계(S730)는, 검증 단계(S725)를 통해 안내 지점을 지나가는 것으로 검증이 완료된 타 차량을 후보 차량으로 선정하는 단계를 포함할 수 있다. 외부 서버는, 안내 지점을 지나가는 것으로 검증 완료된 타 차량이 없는 경우, 검색 영역 확대할 수 있다. 후보 차량의 수가 복수인지 여부를 판단하는 단계(S735)는, 검색 영역 내의 후보 차량의 수를 판단하는 단계를 포함할 수 있다. 외부 서버는 후보 차량의 수가 단수인 경우, 선정된 후보 차량을 영상 제공 차량으로 선택할 수 있다. 외부 서버는 후보 차량의 수가 복수인 경우, 우선 순위에 따라 영상 제공 차량을 선택 할 수 있다. 우선 순위에 따라 영상 제공 차량을 선택하는 단계(S740)는, 외부 서버가, 우선 순위의 기준에 따라 제 1 영상 제공 차량을 선택하는 단계를 포함할 수 있다. 우선 순위의 기준은 차량 또는 프로세서에 의해 선택될 수 있다. 우선 순위의 기준은 제1 영역 내에서, 안내 지점과의 상대적 거리가 가까운 차량 기준(제 1 기준) 또는 안내 지점과의 상대적 거리가 먼 차량 기준(제2 기준)을 포함할 수 있다. 차량 또는 프로세서는, 사용자가 입력한 선택 신호에 의해, 제1 기준 또는 제2 기준 중 어느 하나의 기준을 선택할 수 있다. 차량 또는 프로세서는, 선택된 우선 순위의 기준에 대한 정보를 외부 서버 로 전송할 수 있다. 외부 서버는, 선택된 우선 순위의 기준에 따라, 1순위의 제1 영상 제공 차량, 2순위의 제2 영상 제공 차량, 3순위의 제3 영상 제공 차량을 선택할 수 있다. 외부 서버는, 제2 영상 제공 차량 또는 제3 영상 제공 차량을 선택하는 경우, 안내 지점을 지나가 는지를 재검증할 수 있다. 재검증은 우선 순위에 따른 후순위 차량에게 저장된 프로토콜에 의해 안내 지점을 지 나가는지를 확인하는 단계를 포함할 수 있다. 외부 서버는 제2 영상 제공 차량이 안내 지점을 지나가는 것으로 재검증이 완료되면, 제2 영상 제공 차 량이 제1 영역에 진입 시 카메라 영상을 제공받을 수 있다. 외부 서버는 제3 영상 제공 차량이 안 내 지점을 지나가는 것으로 재검증이 완료되면, 제3 영상 제공 차량이 제1 영역에 진입 시 카메라 영상을 제공받을 수 있다. 선정된 후보 차량을 영상 제공 차량으로 선택하는 단계(S745)는, 후보 차량의 수가 단수인 경우, 상기 후보 차량을 영상 제공 차량으로 선택하는 단계를 의미할 수 있다. 외부 서버는 하나의 후보 차량을 영상 제 공 차량으로 선택하고, 영상 제공 차량에게 카메라 영상을 요청할 수 있다. 도 8은 본 발명의 실시예에 영상 제공 거리를 표시하는 도면이다. 도 8을 참조하면, 영상 제공 거리는 100m 경우, 200m 경우 또는 500m 경우 등이 존재할 수 있 다. 이것은 도로 종류, 교통 상황 또는 사용자 설정에 따라 달라질 수 있다.영상 제공 거리는 도로 종류 또는 교통 상황에 따라 변화할 수 있다. 도로 종류는 어플리케이션에 저장된 맵 데 이터로 판단할 수 있고, 교통 상황은 교통 안내 서버와의 통신을 통해 판단할 수 있다. 영상 제공 거리는 영상 제공 영역을 결정하는 요소로, 영상 제공 차량이 카메라 영상을 제공하는 거리를 의미할 수 있다. 영상 제공 거리는 영상 제공 시간과 제1 영역이 속한 도로의 법정 제한 속도의 곱으로 계산될 수 있다. 영상 제공 거리는 도로 종류에 따라 결정될 수 있다. 도로 종류는 일반 도로, 자동차 전용 도로 및 고속 도로를 포함할 수 있다. 또한, 도로 종료는 편도 1차로 도로 및 편도 2차로 이상의 도로를 포함할 수 있다. 프로세서는 영상 제공 거리 또는 영상 제공 시간을 설정할 수 있다. 예를 들어, 편도 1차로의 일반 도로에 서의 법정 제한 속도는 60km/h이고, 영상 제공 거리를 100m로 설정한다면, 영상 제공 시간은 6초로 계산될 수 있다. 또한, 편도 2차로의 고속 도로에서의 법정 제한 속도는 100km/h이고, 영상 제공 거리를 1km로 설정한다면, 영상 제공 시간은 36초로 계산될 수 있다. 영상 제공 거리는 교통 상황에 따라 결정될 수 있다. 교통 상황은 원할, 서행, 지체 및 정체로 나누어질 수 있 다. 외부 서버는, 교통 상황에 따라 영상 제공 거리를 결정하는 경우, 법정 제한 속도에 교통 상황에 따른 가중치를 조절할 수 있다. 즉, 외부 서버는, 법정 제한 속도 및 교통 상황에 따른 가중치에 기초하여 영상 제공 영역을 결정할 수 있다. 예를 들어, 교통 상황이 원할인 경우 가중치는 100%, 교통 상황이 서행인 경우 가중치는 70%, 교통 상황이 지체 인 경우 가중치는 50%, 교통 상황이 정체인 경우 가중치는 30%로 계산하여, 법정 제한 속도에 변화를 줄 수 있 다. 고속도로 기준 법정 제한 속도가 100km/h인 도로에서 교통 상황이 지체인 경우, 가중치 50%를 계산하여, 영 상 제공 거리를 계산하기 위한 법정 제한 속도는 50km/h가 될 수 있다. 이경우, 프로세서가 영상 제공 시 간을 36초로 설정한다면, 영상 제공 거리는 500m로 계산될 수 있다. 또한, 고속도로 기준 법정 제한 속도가 100km/h인 도로에서 교통 상황이 정체인 경우, 가중치 30%를 계산하여, 영상 제공 거리를 계산하기 위한 법정 제한 속도는 30km/h가 될 수 있다. 이경우, 프로세서가 영상 제공 시간을 36초로 설정한다면, 영상 제공 거리는 300m로 계산될 수 있다. 도 9 내지 도 11b는 본 발명의 실시예에 따른 우선 순위에 의한 영상 제공 차량을 선택하는 단계를 설명하는데 참조되는 도면이다. 외부 서버는 검증 완료된 후보 차량의 수가 복수인 경우, 우선 순위에 따라 영상 제공 차량을 선택할 수 있다. 외부 서버는 우선 순위의 기준에 따라 제1 영상 제공 차량을 선택할 수 있다. 우선 순위의 기 준은 차량 또는 프로세서에 의해 선택될 수 있다. 우선 순위의 기준은 사용자가 입력한 선택 신호에 의해 결정될 수 있다. 우선 순위의 기준은 제1 영역 내에서, 안내 지점과의 상대적 거리가 가까운 차량 기준(제1 기준) 또는 안내 지 점과의 상대적 거리가 먼 차량 기준(제2 기준)을 포함할 수 있다. 제1 기준은 영상 제공 차량이 제공하는 카메라 영상을 통해 안내 지점을 더 가까운 거리에서 확인할 수 있 는 장점이 있다. 그러나 제1 기준은 영상 제공 차량이 안내 지점으로부터 가까운 지점에 위치하기 때문에, 카메라 영상의 길이가 짧은 단점이 있다. 즉, 제1 기준은 차량이 안내 지점에 도착할 때까지, 다수의 영상 제공 차량으로부터 카메라 영상을 제공받을 필요가 있다. 도 9는, 우선 순위의 기준을 제1 기준으로 선택한 경우, 영상 제공 차량이 선택되는 방법을 나타낼 수 있다. 외 부 서버는, 제1 영역 내의 제1 기준에 따른 1순위 차량(A)을 제1 영상 제공 차량으로 선택할 수 있다. 외부 서버는, 제1 영상 제공 차량이 안내 지점을 통과한 경우, 제1 기준에 따른 2순위 차량(B)을 제2 영상 제공 차량으로 선택할 수 있다. 외부 서버는, 제2 영상 제공 차량이 안내 지점을 통과한 경우, 제1 기준에 따른 3순위 차량(C)을 제3 영상 제공 차량으로 선택할 수 있다. 도 11a를 참조하면, 제1 기준에 의한 영상 제공 차량 선택 방법은, 안내 지점으로부터 가까운 위치에서의 카메라 영상을 제공받아 안내 지점에 대해 빠른 상황 판단을 가져갈 수 있지만, 다수의 영상 제공 차량을 선택해야한다. 제2 기준은 영상 제공 차량이 제공하는 카메라 영상을 통해 안내 지점을 먼 거리에서부터 확인하는 단점이 있다. 그러나 제2 기준은 영상 제공 차량이 안내 지점으로부터 먼 지점에 위치하기 때문에, 카메라 영상의길이가 긴 장점이 있다. 즉, 제1 기준은 차량이 안내 지점에 도착할 때까지, 소수의 영상 제공 차량으 로부터 카메라 영상을 제공받을 수 있다. 도 10은, 우선 순위의 기준을 제2 기준으로 선택한 경우, 영상 제공 차량이 선택되는 방법을 나타낼 수 있다. 외부 서버는, 제1 영역 내의 제2 기준에 따른 1순위 차량(A)을 제1 영상 제공 차량으로 선택할 수 있다. 외부 서버는, 제1 영상 제공 차량이 안내 지점을 통과한 경우, 제2 기준에 따른 2순위 차량(E)을 제2 영상 제공 차량으로 선택할 수 있다. 외부 서버는, 제2 영상 제공 차량이 안내 지점을 통과한 경우, 제2 기준에 따른 3순위 차량(I)을 제3 영상 제공 차량으로 선택할 수 있다. 도 11b를 참조하면, 제2 기준에 의한 영상 제공 차량 선택 방법은, 안내 지점으로부터 먼 위치에서의 카메 라 영상을 제공받아 안내 지점에 대한 빠른 상황 판단은 힘들지만, 소수의 영상 제공 차량으로부터 긴 카 메라 영상을 확인할 수 있다. 차량 또는 프로세서는, 사용자가 입력한 선택 신호에 의해, 제1 기준 또는 제2 기준 중 어느 하나의 기준을 선택할 수 있다. 차량 또는 프로세서는, 선택된 우선 순위의 기준에 대한 정보를 외부 서버 로 전송할 수 있다. 외부 서버는, 선택된 우선 순위의 기준에 따라, 1순위의 제1 영상 제공 차량, 2순위의 제2 영상 제공 차량, 3순위의 제3 영상 제공 차량을 선택할 수 있다. 도 12는 본 발명의 실시예에 따른 정체 구간에서의 AR 영상 제공 방법을 설명하는데 참조되는 도면이다. 도 12를 참조하면, 외부 서버는 카메라 영상으로부터 안내 지점 주변 구간이 정체 구간인지를 판단할 수 있다. 안내 지점의 주변 구간은 안내 지점을 기준으로 차량이 위치하는 방향으로 설정된 일정 구간을 의 미할 수 있다. 외부 서버는 제1 영역의 영상 제공 차량으로부터 수신한 카메라 영상에서 후보 차량의 수가 기 설정된 수 이상이면 안내 지점의 주변 구간을 정체 구간으로 판단할 수 있다. 또는 외부 서버는, 교통 안내 서버와의 통신을 통해 안내 지점의 주변 구간을 정체 구간으로 판단할 수 있다. 예를 들어, 안내 지점의 주변 구간에서 차량의 평균 속도가 10km/h인 경우, 정체 구간으로 판단할 수 있다. 외부 서버는, 안내 지점의 주변 구간을 정체 구간으로 판단하면, 카메라 영상을 통해 안내 지점에서 부터 역방향으로 탐색하면서 정체 구간의 길이를 계산할 수 있다. 이경우. 외부 서버는, 정체 구간 내의 각 차량으로부터 순간 촬영 이미지를 수신할 수 있다. 외부 서버는, 순간 촬영 이미지를 연결 하여 카메라 영상을 생성할 수 있다. 외부 서버는, 순간 촬영 이미지를 연결한 카메라 영상을 차량에게 제공할 수 있다. 외부 서버는, 카메라 영상을 통해 정체 구간의 길이를 계산하고, 정체 구간의 시작 지점을 판 단할 수 있다. 외부 서버는, 정체 구간의 시작 지점을 기준으로 검색 영역을 재설정할 수 있다. 검색 영역의 재설정은 정체 구간의 시작 지점을 기준으로 차량이 위치하는 방향으로 제1 영역 및 제2 영역을 재설정하는 것을 포함할 수 있다. 제1 영역 재설정 방법 및 제2 영역 재설정 방법은 도 7의 S700 및 S705 단계와 동일할 수 있다. 외부 서버는, 정체 구간에서의 순간 촬영 이미지를 연결한 카메라 영상을 긴급 상황에 활용할 수 있 다. 긴급 차량이 정체 구간을 통과하는 경우, 외부 서버로부터 순간 촬영 이미지를 연결한 카메라 영 상을 수신할 수 있다. 외부 서버는, 카메라 영상을 통해 긴급 차량이 정체구간 내에서 위치할 빈 공간을 검 출할 수 있다. 외부 서버는, 빈 공간에 대한 정보 및 이를 기초로 생성한 주행 경로를 긴급 차량에 전송할 수 있다. 외부 서버는, 정체 구간 내의 차량들에게 긴급 차량에 대한 정보 및 빈 공간에 대한 정보를 전송함으로써, 긴급 차량은 정체 구간을 효율적으로 통과할 수 있다. 도 13은 본 발명의 실시예에 따른 AR 영상 정보 생성하는 단계에 대한 플로우 차트이다. 도 13을 참조하면, AR 영상 정보를 생성하는 단계(S435)는, 제1 캘리브레이션 파라미터 값을 수신하는 단계 (S1301), 제2 캘리브레이션 파라미터 값을 계산하는 단계(S1302), 비교 단계(S1303), projection matrix를 도 출하는 단계(S1304) 및 그래픽 객체를 생성하는 단계(S1305)를 포함할 수 있다. 제1 캘리브레이션 파라미터 값을 수신하는 단계(S1301)는, 외부 서버가 차량에 저장된 캘리브레이션 파 라미터 값을 수신하는 단계를 포함할 수 있다. 도 14를 참조하면, 제1 캘리브레이션 파라미터 값은 캘리브레이션 수행 시 필요한 파라미터 값으로, 프로 세서가 차량내 장착된 카메라가 촬영한 영상에서 가상의 기준선에 기초하여 생성될 수 있다. 가상의 기준선은 소실선(vanishing line, 1301)을 포함할 수 있다. 가상의 기준선은 보닛선(bonnet line, 1302) 또는 중심선(center line, 1303)중 적어도 어느 하나를 더 포함할 수 있다. 소실선은 차량내 장착된 카메라가 촬영한 영상에서 소실점을 기준으로 수평방향으로 형성된 가상의 선을 의미할 수 있다. 보닛선 은 차량내 장착된 카메라가 촬영한 영상에서 차량의 보닛의 상단을 기준으로 수평방향으로 형성 된 가상의 선을 의미할 수 있다. 중심선은 차량내 장착된 카메라가 촬영한 영상에서 차량의 전폭 중심을 기준으로 수직방향으로 형성된 가상의 선을 의미할 수 있다. 제1 캘리브레이션 파라미터 값은 롤, 피치, 요, X, Y, Z 파라미터로 구성될 수 있다. 제2 캘리브레이션 파라미터 값을 계산하는 단계(S1302)는, 외부 서버가, 제1 캘리브레이션 파라미터 값 을 기준으로 카메라 영상의 제2 캘리브레이션 파라미터 값을 계산하는 단계를 포함할 수 있다. 도 15를 참조하면, 제2 캘리브레이션 파라미터 값은 캘리브레이션 수행 시 필요한 파라미터 값으로, 외부 서버가 영상 제공 차량으로부터 수신한 카메라 영상에서 가상의 기준선에 기초하여 생성할 수 있다. 외부 서버는, 카메라 영상을 영상 제공 차량의 가상의 기준선인 소실선(V’, 1401), 보닛선(B’, 1402) 또는 중심선(C’, 1403) 중 적어도 어느 하나를 기준으로 제2 캘리브레이션 파라미터 값을 계산할 수 있 다. 소실선은 영상 제공 차량내 장착된 카메라가 촬영한 영상에서 소실점을 기준으로 수평방향으로 형성된 가상의 선을 의미할 수 있다. 보닛선은 영상 제공 차량내 장착된 카메라가 촬영한 영상에서 영상 제공 차량의 보닛의 상단을 기준으로 수평방향으로 형성된 가상의 선을 의미할 수 있다. 중심선(140 3)은 영상 제공 차량내 장착된 카메라가 촬영한 영상에서 영상 제공 차량의 전폭 중심을 기준으로 수직 방향으로 형성된 가상의 선을 의미할 수 있다. 제2 캘리브레이션 파라미터 값은 롤, 피치, 요, X, Y, Z 파라미터로 구성될 수 있다. 비교 단계(S1303) 및 projection matrix 도출 단계(S1304)는, 외부 서버가 제1 캘리브레이션 파라미터 값 에 기초하여 카메라 영상의 제2 캘리브레이션 파라미터 값을 비교하고, projection matrix를 도출 하는 단계를 포함할 수 있다. 도 15를 참조하면, 제2 캘리브레이션 파라미터 값은 제1 캘리브레이션 파라미터 값에 기초하여 + 하거나 -하여 계산할 수 있다. 외부 서버는 제1 캘리브레이션 파라미터 값에 기초하여 제2 캘리브레 이션 파라미터 값과 좌표계 변화 행렬인 projection matrix를 도출할 수 있다. Projection matrix는 제1 캘리브레이션 파라미터 값 및 제2 캘리브레이션 파라미터 값에 기초하여 차량 내 장착된 카메라를 위한 좌표계 변환 행렬로 정의할 수 있다. 외부 서버는 projection matrix를 도출할 수 있고, projection matrix를 포함하는 캘리브레이션 결과 값을 차량으로 전송할 수 있다. 그래픽 객체를 생성하는 단계(S1305)는, 외부 서버가 캘리브레이션이 완료된 카메라 영상에 표시할 그래픽 객체를 생성하는 단계를 포함할 수 있다. 그래픽 객체는, 차량의 주행 경로를 안내하는 카펫, TBT(turn by turn) 또는 안내 지점까지의 잔여 거리 표 시 바(bar) 중 적어도 어느 하나를 포함할 수 있다. 그래픽 객체는 주행 안내 정보를 표시하는 이미지를 더 포 함할 수 있다. 도 16은 본 발명의 실시예에 따른 AR 영상 정보를 표시한 화면을 나타내는 도면이다. 도 16을 참조하면, 차량 내비게이션에 표시되는 AR 영상 정보는, 카펫, TBT, 잔여 거리 표시 바 또는 주행 안내 정보 중 적어도 어느 하나를 포함할 수 있다. 카펫은, 차량의 주행 경로를 표시하는 이미지를 의미할 수 있다. 카펫은, 차량 내비게이션 이 안내하는 목적지까지의 주행 경로를 의미할 수 있다. 외부 서버는, 카펫을 통해 차량의 주행 경로를 영상 제공 차량의 카메라 영상에 표시할 수 있다. TBT는, 주행 경로를 표시한 화살표 이미지를 의미할 수 있다. 예를 들면, TBT는 교차로 또는 분기 점에서의 주행 경로를 표시하는 좌측, 우측, 직진 또는 유턴 화살표 이미지일 수 있다. TBT는, 차량 이 교차로 또는 분기점으로부터 기 설정 거리 이내에 위치할 때부터 표시될 수 있다. 외부 서버는 캘리브레 이션이 완료된 카메라 영상에 표시할 TBT 정보를 생성할 수 있다.안내 지점까지의 잔여 거리 표시 바는 영상 제공 차량과 안내 지점과의 잔여 거리를 바 형태로 나타 낸 이미지일 수 있다. 잔여 거리 표시 바는 영상 제공 차량이 영상을 제공하고부터 줄어들고 안내 지 점에 도착 시 사라질 수 있다. 주행 안내 정보는 현재 주행 차선 정보, 진행 방향 방면 정보, 목적 차선 정보, 목적지까지의 거리 정보, TBT 정보 중 적어도 하나 이상의 정보를 포함한다. 주행 안내 정보는 영상 제공 차량이 제공하는 카 메라 영상과 분리되어 표시될 수 있다. 차량은, 외부 서버로부터 카메라 영상 및 그래픽 객체를 포함하는 안내 지점에 대한 AR 영상 정보를 수 신할 수 있다. 차량은 카메라 영상에 그래픽 객체를 중첩하여 내비게이션 화면의 일 영역에 AR 영상 정보를 표시할 수 있다. 차량은 복수 대의 영상 제공 차량으로부터 카메라 영상을 수신하고, 내비게이션 화면에 표 시할 수 있다. 도 17은 본 발명의 실시예에 따른 복합 안내 지점을 설명하는데 참조되는 도면이다. 도 17을 참조하면, 차량은 복합 안내 지점에서 제1 AR 영상 정보 및 제2 AR 영상 정보를 표시 할 수 있다. 복합 안내 지점은, 사용자가 선택한 안내 지점을 기준으로 일정 거리 내에서 두번 이상의 턴(turn) 안내가 필요한 지점을 의미할 수 있다. 외부 서버는, 사용자가 선택한 안내 지점을 기준으로 상기 안내 지 점이 복수의 턴 안내가 필요한 지점인지를 판단할 수 있다. 외부 서버는, 내비게이션 어플리게이션에 저장된 맵 데이터로부터 안내 지점에 대한 정보를 획득할 수 있다. 외부 서버는 맵 데이터로부터 사용자가 선택한 안내 지점이 복합 안내 지점인지를 판단할 수 있다. 외부 서버는, 사용자가 선택한 안내 지점에 대한 AR 영상 정보가 복수의 TBT를 포함한다면, 상기 안내 지점 을 복합 안내 지점으로 판단할 수 있다. 예를 들어, 외부 서버는 사용자가 선택한 안내 지점에서의 경로 안내가 ‘우회전 후 50m 전방에서 좌회전’ 인 경우, 상기 안내 지점을 복합 안내 지점으로 판단할 수 있다. 외부 서버는, 사용자가 선택한 안내 지점이 복수의 턴 안내가 필요한 복합 안내 지점으로 판단하면, 상기 안내 지점을 제1 지점 및 제2 지점으로 나눌 수 있다. 제1 지점은은 상기 안내 지점에서 첫 번째 턴 안내가 필요한 지점을 의미할 수 있다. 제2 지점은 상기 안내 지점에서 두번째 턴 안내가 필요한 지점을 의미할 수 있다. 외부 서버는, 세번의 턴 안내가 필요하면, 제1 지점, 제2 지점 및 제3 지점으로 나 눌 수 있다. 외부 서버는, 제1 지점 및 제2 지점에 대해 각각 AR 영상 정보를 생성할 수 있다. 즉, 외부 서 버는 제1 지점에 대한 제1 AR 영상 정보 및 제2 지점에 대한 제2 AR 영상 정보를 생성할 수 있다. 제1 AR 영상 정보는, 제1 지점에 대해 검색 영역을 설정하는 단계, 우선 순위에 따른 영상 제공 차 량을 선택하는 단계 및 제1 지점에 대한 카메라 영상에 AR 그래픽 객체를 표시하는 단계를 통해 생성될 수 있다. 제1 AR 영상 정보는, 카펫, TBT, 잔여 거리 표시 바 또는 주행 안내 정보 중 적어도 어느 하나 를 포함할 수 있다. 제2 AR 영상 정보는, 제2 지점에 대해 검색 영역을 설정하는 단계, 우선 순위에 따른 영상 제공 차 량을 선택하는 단계 및 제2 지점에 대한 카메라 영상에 AR 그래픽 객체를 표시하는 단계를 통해 생성될 수 있다. 제2 AR 영상 정보는, 카펫, TBT, 잔여 거리 표시 바 또는 주행 안내 정보 중 적어도 어느 하나 를 포함할 수 있다. 차량은 외부 서버로부터 제1 AR 영상 정보 및 제2 AR 영상 정보를 수신할 수 있다. 차량 은 차량에 장차된 카메라가 촬영하는 영상과 함께 제1 AR 영상 정보 및 제2 AR 영상 정보 를 내비게이션 화면의 일 영역에 표시할 수 있다. 차량은 자차가 제1 지점을 통과할 때까지 제1 AR 영상 정보 및 제2 AR 영상 정보를 표시 할 수 있다. 차량은 자차가 제1 지점을 통과하면, 제2 지점을 통과할 때까지 제1 AR 영상 정보 를 표시할 수 있다. 차량은 자차가 제1 지점을 통과하면, 제2 AR 영상 정보를 삭제할 수 있다. 차량이 제1 지점을 통과하면 제1 AR 영상 정보만을 표시함으로써, 동일한 구간에 대해 중복된 영상 공급을 피할 수 있다.본 발명의 자율 주행 차량, 사용자 단말기 및 서버 중 하나 이상이 인공 지능(Artificial Inteligence) 모 듈, 드론(Unmanned Aerial Vehicle, UAV), 로봇, 증강 현실(Augmented Reality, AR) 장치, 가상 현실(virtual reality, VR), 5G 서비스와 관련된 장치 등과 연계 혹은 융복합될 수 있다. 예를 들어, 자율 주행 차량은 차량에 포함된 적어도 하나의 인공지능 모듈, 로봇과 연계되어 동작할 수 있다. 예를 들어, 차량은, 적어도 하나의 로봇(robot)과 상호 작용할 수 있다. 로봇은, 자력으로 주행이 가능한 이동 로봇(Autonomous Mobile Robot, AMR)일 수 있다. 이동 로봇은, 스스로 이동이 가능하여 이동이 자유롭고, 주행 중 장애물 등을 피하기 위한 다수의 센서가 구비되어 장애물을 피해 주행할 수 있다. 이동 로봇은, 비행 장치를 구비하는 비행형 로봇(예를 들면, 드론)일 수 있다. 이동 로봇은, 적어도 하나의 바퀴를 구비하고, 바퀴 의 회전을 통해 이동되는 바퀴형 로봇일 수 있다. 이동 로봇은, 적어도 하나의 다리를 구비하고, 다리를 이용해 이동되는 다리식 로봇일 수 있다. 로봇은 차량 사용자의 편의를 보완하는 장치로 기능할 수 있다. 예를 들면, 로봇은, 차량에 적재된 짐을 사 용자의 최종 목적지까지 이동하는 기능을 수행할 수 있다. 예를 들면, 로봇은, 차량에서 하차한 사용자에게 최종 목적지까지 길을 안내하는 기능을 수행할 수 있다. 예를 들면, 로봇은, 차량에서 하차한 사용자를 최 종 목적지까지 수송하는 기능을 수행할 수 있다. 차량에 포함되는 적어도 하나의 전자 장치는, 통신 장치를 통해, 로봇과 통신을 수행할 수 있다. 차량에 포함되는 적어도 하나의 전자 장치는, 로봇에 차량에 포함되는 적어도 하나의 전자 장치에서 처 리한 데이터를 제공할 수 있다. 예를 들면, 차량에 포함되는 적어도 하나의 전자 장치는, 차량 주변의 오브젝트를 지시하는 오브젝트 데이터, 맵 데이터(map data), 차량 상태 데이터, 차량 위치 데이터 및 드라이빙 플랜 데이터(driving plan data) 중 적어도 어느 하나를 로봇에 제공할 수 있다. 차량에 포함되는 적어도 하나의 전자 장치는, 로봇으로부터, 로봇에서 처리된 데이터를 수신할 수 있다. 차 량에 포함되는 적어도 하나의 전자 장치는, 로봇에서 생성된 센싱 데이터, 오브젝트 데이터, 로봇 상태 데 이터, 로봇 위치 데이터 및 로봇의 이동 플랜 데이터 중 적어도 어느 하나를 수신할 수 있다. 차량에 포함되는 적어도 하나의 전자 장치는, 로봇으로부터 수신된 데이터에 더 기초하여, 제어 신호를 생 성할 수 있다. 예를 들면, 차량에 포함되는 적어도 하나의 전자 장치는, 오브젝트 검출 장치에 생성된 오브 젝트에 대한 정보와 로봇에 의해 생성된 오브젝트에 대한 정보를 비교하고, 비교 결과에 기초하여, 제어 신호를 생성할 수 있다. 차량에 포함되는 적어도 하나의 전자 장치는, 차량의 이동 경로와 로봇의 이동 경로간 의 간섭이 발생되지 않도록, 제어 신호를 생성할 수 있다. 차량에 포함되는 적어도 하나의 전자 장치는, 인공 지능(artificial intelligence, AI)를 구현하는 소프트 웨어 모듈 또는 하드웨어 모듈(이하, 인공 지능 모듈)을 포함할 수 있다. 차량에 포함되는 적어도 하나의 전자 장치는, 획득되는 데이터를 인공 지능 모듈에 입력(input)하고, 인공 지능 모듈에서 출력(output)되는 데 이터를 이용할 수 있다. 인공 지능 모듈은, 적어도 하나의 인공 신경망(artificial neural network, ANN)을 이용하여, 입력되는 데이터 에 대한 기계 학습(machine learning)을 수행할 수 있다. 인공 지능 모듈은, 입력되는 데이터에 대한 기계 학습 을 통해, 드라이빙 플랜 데이터를 출력할 수 있다. 차량에 포함되는 적어도 하나의 전자 장치는, 인공 지능 모듈에서 출력되는 데이터에 기초하여, 제어 신호 를 생성할 수 있다. 실시예에 따라, 차량에 포함되는 적어도 하나의 전자 장치는, 통신 장치를 통해, 외부 장치로부터, 인 공 지능에 의해 처리된 데이터를 수신할 수 있다. 차량에 포함되는 적어도 하나의 전자 장치는, 인공 지능 에 의해 처리된 데이터에 기초하여, 제어 신호를 생성할 수 있다. 전술한 본 발명은 프로그램이 기록된 매체에 컴퓨터가 읽을 수 있는 코드로서 구현하는 것이 가능하다. 컴퓨터 가 읽을 수 있는 매체는, 컴퓨터 시스템에 의하여 읽혀질 수 있는 데이터가 저장되는 모든 종류의 기록장치를 포함한다. 컴퓨터가 읽을 수 있는 매체의 예로는, HDD(Hard Disk Drive), SSD(Solid State Disk), SDD(Silicon Disk Drive), ROM, RAM, CD-ROM, 자기 테이프, 플로피 디스크, 광 데이터 저장 장치 등이 있으며, 또한 캐리어 웨이브(예를 들어, 인터넷을 통한 전송)의 형태로 구현되는 것도 포함한다. 또한, 상기 컴퓨터는 프로세서 또는 제어부를 포함할 수도 있다. 따라서, 상기의 상세한 설명은 모든 면에서 제한적으로 해석되어서는 아니되고 예시적인 것으로 고려되어야 한다. 본 발명의 범위는 첨부된 청구항의 합리적 해석에 의해 결정되어야 하고, 본 발명의 등가적 범위 내에서의 모든 변경은 본 발명의 범위에 포함된다."}
{"patent_id": "10-2022-7005874", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 실시예에 따른 차량용 내비게이션 시스템을 도시한 도면이다. 도 2는 본 발명의 실시예에 따른 차량의 제어 블록도이다. 도 3은 본 발명의 실시예에 따른 전자 장치의 제어 블록도이다. 도 4는 본 발명의 실시예에 따른 AR 영상 제공 방법의 플로우 차트이다. 도 5는 본 발명의 실시예에 따른 안내 지점을 설명하는데 참조되는 도면이다. 도 6은 본 발명의 실시예에 검색 영역을 설명하는데 참조되는 도면이다. 도 7은 본 발명의 실시예에 따른 후보 차량을 검색하는 단계 및 영상 제공 차량을 선택하는 단계에 대한 플로우 차트이다. 도 8은 본 발명의 실시예에 영상 제공 거리를 표시하는 도면이다. 도 9 내지 도 11b는 본 발명의 실시예에 따른 우선 순위에 의한 영상 제공 차량을 선택하는 단계를 설명하는데 참조되는 도면이다. 도 12는 본 발명의 실시예에 따른 정체 구간에서의 AR 영상 제공 방법을 설명하는데 참조되는 도면이다. 도 13은 본 발명의 실시예에 따른 AR 영상 정보 생성하는 단계에 대한 플로우 차트이다. 도 14 내지 15는 본 발명의 실시예에 따른 캘리브레이션 과정을 설명하는데 참조되는 도면이다. 도 16은 본 발명의 실시예에 따른 AR 영상 정보를 표시한 화면을 나타내는 도면이다. 도 17은 본 발명의 실시예에 따른 복합 안내 구간을 설명하는데 참조되는 도면이다."}
