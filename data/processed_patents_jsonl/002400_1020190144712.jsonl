{"patent_id": "10-2019-0144712", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2021-0057925", "출원번호": "10-2019-0144712", "발명의 명칭": "스트리밍 서버 및 이를 이용한 다시점 동영상에서의 객체 처리 방법", "출원인": "한국광기술원", "발명자": "전성국"}}
{"patent_id": "10-2019-0144712", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "스트리밍 서버에 의해 수행되는 다시점 동영상에서의 객체 처리 방법에 있어서,a) 콘텐츠 제작 단말로부터 전방향으로 배열된 하나 이상의 카메라를 이용하여 촬영된 시점별 영상 데이터를 실시간 수신하는 단계;b) 상기 시점별 영상 데이터에 대한 영상 스티칭 및 색상 톤 보정을 수행하는 영상 보정 알고리즘을 수행하여하나의 다시점 영상으로 병합하는 단계;b) 상기 병합된 다시점 영상에서 사용자의 시야각을 기준으로 관심 영역을 설정하고, 인공 지능 기반의 객체 검출 모델을 이용하여 상기 관심 영역에서 하나 이상의 객체 영상을 추출한 후 상기 추출된 객체 영상에 대한 메타 데이터를 저장하는 단계;c) 상기 객체 영상에 상응하는 증강현실(Augmented Reality, AR) 콘텐츠를 생성하고, 상기 다시점 영상에 상기객체 영상, AR 콘텐츠 및 메타데이터를 통합하여 360도 스트리밍 영상을 생성하여 저장하는 단계; 및d) 사용자 단말의 요청에 따라 상기 360도 스트리밍 영상을 상기 사용자 단말에 제공하고, 상기 360도 스트리밍영상이 재생되는 도중에 상기 사용자 단말에 의해 관심 객체가 선택되면, 상기 관심 객체에 포함된 AR 콘텐츠를실시간 출력하는 단계를 포함하되,상기 인공 지능 기반의 객체 검출 모델은,네트워크를 통해 복수의 360도 스트리밍 영상을 수집하여 학습 영상으로 저장하고, 상기 학습 영상들 중 객체영상에 대한 레이블링 작업을 수행하여 레이블링 데이터를 데이터베이스에 저장하며, 상기 데이터베이스에 저장된 학습 영상에 기초하여 상기 레이블링 데이터를 학습하는 것인, 다시점 동영상에서의 객체 처리 방법."}
{"patent_id": "10-2019-0144712", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1 항에 있어서,상기 b) 단계는, 상기 시점별 영상 데이터에서 하나 이상의 특징점을 검출하는 단계;상기 시점별 영상 데이터의 특징점들을 비교하여 서로 이웃한 시점의 영상 데이터들 간에 동일한 특징점들을 동일점으로 매칭하여 대응쌍들을 생성하는 단계; 및상기 대응 쌍들로부터 각 시점별 영상 데이터들 간의 변환행렬을 계산하고, 상기 변환 행렬을 통해 영상 스티칭을 수행하는 단계를 포함하는 것인, 다시점 동영상에서의 객체 처리 방법."}
{"patent_id": "10-2019-0144712", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 2 항에 있어서,상기 시점별 영상 데이터에서 하나 이상의 특징점을 검출하는 단계는, SIFT(Scale Invariant Feature Transform) 알고리즘과 SURF(Speeded Up Robust Feature) 알고리즘 중 어느 하나의 알고리즘을 이용하여 특징점을 검출하는 것인, 다시점 동영상에서의 객체 처리 방법."}
{"patent_id": "10-2019-0144712", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 2 항에 있어서,상기 b) 단계는,상기 매칭된 대응 쌍들간의 변환 관계를 RANSAC(RANdom SAmple Consensus) 알고리즘을 사용하여 하기 수학식 1의 동차형(Homogeneous)으로 표현된 변환 행렬을 통해 회전 행렬 및 이동 벡터를 계산하는 것인, 다시점 동영상공개특허 10-2021-0057925-3-에서의 객체 처리 방법.[수학식 1]"}
{"patent_id": "10-2019-0144712", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제 1 항에 있어서,상기 b) 단계는,상기 영상 스티칭을 통해 병합된 서로 이웃한 시점의 영상 데이터들간에 중첩되는 영역에서의 색상 보정을 위한색상 변형 가중치를 계산하고, 상기 색상 변형 가중치를 이용하여 전체 영상 데이터의 색상 톤을 보정하는것인, 다시점 동영상에서의 객체 처리 방법."}
{"patent_id": "10-2019-0144712", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제 5 항에 있어서,상기 b) 단계는, 하기 수학식 2를 이용하여 상기 색상 변형 가중치의 최소값을 계산하고, 상기 색상 변형 가중치의 최소값을 전체 영상 데이터에 적용하는 것인, 다시점 동영상에서의 객체 처리 방법.[수학식 2] ra, ga, ba: 중첩되는 영역 A의 각 화소 색상 값rb, gb, bb: 중첩되는 영역 B의 각 화소 색상 값w: 색상 변형 가중치n: 중첩되는 영역의 화소수"}
{"patent_id": "10-2019-0144712", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제 1 항에 있어서,상기 메타데이터는 상기 객체 영상에 대한 객체의 종류, 객체 위치 정보 및 크기 정보를 포함하는 것인, 다시점동영상에서의 객체 처리 방법."}
{"patent_id": "10-2019-0144712", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "다시점 동영상에서의 객체 처리를 위한 스트리밍 서버에 있어서,다시점 동영상에서의 객체 처리 방법을 수행하기 위한 프로그램이 기록된 메모리; 및상기 프로그램을 실행하기 위한 프로세서를 포함하며,상기 프로세서는, 상기 프로그램의 실행에 의해, 콘텐츠 제작 단말로부터 전방향으로 배열된 하나 이상의 카메라를 이용하여 촬영된 시점별 영상 데이터를 실시간 수신하여, 상기 시점별 영상 데이터에 대한 영상 스티칭 및 색상 톤 보정을 수행하는 영상 보정 알고리즘을수행하여 하나의 다시점 영상으로 병합하고, 상기 병합된 다시점 영상에서 사용자의 시야각을 기준으로 관심 영역을 설정하고, 인공 지능 기반의 객체 검출모델을 이용하여 상기 관심 영역에서 하나 이상의 객체 영상을 추출한 후 상기 추출된 객체 영상에 대한 메타공개특허 10-2021-0057925-4-데이터를 저장하며, 상기 객체 영상에 상응하는 증강현실(Augmented Reality, AR) 콘텐츠를 생성하고, 상기 다시점 영상에 상기 객체 영상, AR 콘텐츠 및 메타데이터를 통합하여 360도 스트리밍 영상을 생성하여 저장하고, 사용자 단말의 요청에 따라 상기 360도 스트리밍 영상을 상기 사용자 단말에 제공하고, 상기 360도 스트리밍 영상이 재생되는 도중에 상기 사용자 단말에 의해 관심 객체가 선택되면, 상기 관심 객체에 포함된 AR 콘텐츠를실시간 출력하되,상기 인공 지능 기반의 객체 검출 모델은,네트워크를 통해 복수의 360도 스트리밍 영상을 수집하여 학습 영상으로 저장하고, 상기 학습 영상들 중 객체영상에 대한 레이블링 작업을 수행하여 레이블링 데이터를 데이터베이스에 저장하며, 상기 데이터베이스에 저장된 학습 영상에 기초하여 상기 레이블링 데이터를 학습하는 것인, 스트리밍 서버."}
{"patent_id": "10-2019-0144712", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제 8 항에 있어서,상기 프로세서는, 상기 시점별 영상 데이터에서 하나 이상의 특징점을 검출한 후, 상기 시점별 영상 데이터의 특징점들을 비교하여 서로 이웃한 시점의 영상 데이터들 간에 동일한 특징점들을 동일점으로 매칭하여 대응쌍들을 생성하고, 상기대응 쌍들로부터 각 시점별 영상 데이터들 간의 변환행렬을 계산하고, 상기 변환 행렬을 통해 영상 스티칭을 수행하는 것인, 스트리밍 서버."}
{"patent_id": "10-2019-0144712", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제 8 항에 있어서,상기 프로세서는,상기 영상 스티칭을 통해 병합된 서로 이웃한 시점의 영상 데이터들간에 중첩되는 영역에서의 색상 보정을 위한색상 변형 가중치를 계산하고, 상기 색상 변형 가중치를 이용하여 전체 영상 데이터의 색상 톤을 보정하는것인, 스트리밍 서버."}
{"patent_id": "10-2019-0144712", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "다시점 동영상에서의 객체 처리 방법을 수행하는 프로그램을 기록한 컴퓨터 판독 가능한 저장매체로서,상기 프로그램은,콘텐츠 제작 단말로부터 전방향으로 배열된 하나 이상의 카메라를 이용하여 촬영된 시점별 영상 데이터를 실시간 수신하여, 상기 시점별 영상 데이터에 대한 영상 스티칭 및 색상 톤 보정을 수행하는 영상 보정 알고리즘을수행하여 하나의 다시점 영상으로 병합하고, 상기 병합된 다시점 영상에서 사용자의 시야각을 기준으로 관심 영역을 설정하고, 인공 지능 기반의 객체 검출모델을 이용하여 상기 관심 영역에서 하나 이상의 객체 영상을 추출한 후 상기 추출된 객체 영상에 대한 메타데이터를 저장하며, 상기 객체 영상에 상응하는 증강현실(Augmented Reality, AR) 콘텐츠를 생성하고, 상기 다시점 영상에 상기 객체 영상, AR 콘텐츠 및 메타데이터를 통합하여 360도 스트리밍 영상을 생성하여 저장하고, 사용자 단말의 요청에 따라 상기 360도 스트리밍 영상을 상기 사용자 단말에 제공하고, 상기 360도 스트리밍 영상이 재생되는 도중에 상기 사용자 단말에 의해 관심 객체가 선택되면, 상기 관심 객체에 포함된 AR 콘텐츠를실시간 출력하되,상기 인공 지능 기반의 객체 검출 모델은,네트워크를 통해 복수의 360도 스트리밍 영상을 수집하여 학습 영상으로 저장하고, 상기 학습 영상들 중 객체영상에 대한 레이블링 작업을 수행하여 레이블링 데이터를 데이터베이스에 저장하며, 상기 데이터베이스에 저장된 학습 영상에 기초하여 상기 레이블링 데이터를 학습하는 것을 특징으로 하는 다시점 동영상에서의 객체 처리공개특허 10-2021-0057925-5-방법을 수행하는 프로그램이 기록된 컴퓨터 판독가능 기록매체."}
{"patent_id": "10-2019-0144712", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 스트리밍 서버 및 이를 이용한 다시점 동영상에서의 객체 처리 방법에 관한 것으로서, 특히 스트리밍 서버에 의해 수행되는 다시점 동영상에서의 객체 처리 방법에 있어서, a) 콘텐츠 제작 단말로부터 전방향으로 배 열된 하나 이상의 카메라를 이용하여 촬영된 시점별 영상 데이터를 실시간 수신하는 단계; b) 상기 시점별 영상 (뒷면에 계속)"}
{"patent_id": "10-2019-0144712", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 360도 촬영된 영상을 이용하여 인터랙티브 콘텐츠 서비스를 제공하는 스트리밍 서버 및 이를 이용한 다시점 동영상에서의 객체 처리 방법에 관한 것이다."}
{"patent_id": "10-2019-0144712", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "이 부분에 기술된 내용은 단순히 본 실시예에 대한 배경 정보를 제공할 뿐 종래기술을 구성하는 것은 아니다. 인터넷 사용자의 확산과 영상처리 및 편집 기술의 발달은 인터넷 이용자들의 고급 정보에 대한 자연스러운 욕구 증대와 함께 파노라믹(panoramic) 및 다시점(multi-view) 동영상 기술의 발전을 가져왔다. 일반적으로, 다시점 동영상은 다수 개의 카메라를 이용하여 영상을 획득하고 이를 이용하여 영상처리를 하는 기 술을 의미한다. 다시점 3차원 동영상은 다시점 동영상의 하나의 서브셋(sub-set)으로서, 3차원 동영상을 지원하 는 동영상 형태이다. 이를 위해서는 카메라 배치가 상당히 조밀해야 다시점 동영상 보다 사용자들에게 보여주는 관찰범위가 다소 줄어들게 된다. 이러한 다시점 동영상에 관한 처리 요소 기술로는, 영상 획득 기술, 모델링/렌더링 기술, 부호화 및 전송 기술 등이 있다. 정보 통신 기술 발달로 다양한 멀티미디어 콘텐츠를 사용자에게 제공할 수 있게 되었고, 3차원 TV와 같은 멀티 미디어 시스템의 발달로 인하여 실감 미디어 콘텐츠에 대한 수요가 급증하고 있다. 3차원 영상에 대한 다양한 사용자의 요구를 충족시킬 수 있는 대안으로 주목받고 있는 다시점 동영상은 여러 개 의 카메라로 하나의 3차원 장면을 360도 촬영한 동영상의 집합으로 사용자에게 임의 시점을 제공하며, 여러 시 점의 영상을 합성하여 보다 넓은 화면을 제공할 수 있다. 이와 같이 다시점 3차원 동영상이 비록 많은 응용분야에서 사용되고 있지만, 영상의 획득, 처리, 데이터 양, 동 기화 및 디스플레이 방법에 있어 기존 2차원 동영상 보다 많은 어려운 점을 가지고 있는 실정이다. 또한, 가상 현실 및 증강 현실로 대표되는 공간 정보 기반의 실감형 콘텐츠에 대한 관심이 증대되면서 객체 인 식 등의 지능형 공간 인지 기술에 대한 연구가 활발히 진행되고 있다. 특히, 영상 시각화 장치의 발달과 5G 통 신 기술의 출현으로 인해 실시간 대용량 영상 정보의 송수신 및 가시화 처리 기술의 기반이 구축됨에 따라 다시 점 3차원 동영상에 대한 지능형 공간 인지 기술의 필요성이 증대되고 있다. 그러나, 딥러닝 기반의 객체 인식 기술의 경우에, 대부분 일반적인 3차원 동영상에 대한 처리를 다루고 있어, 파노라마 영상이나 360도 스트리밍 영상에 대한 객체 인식에 대한 연구가 미비한 실정이다. 선행기술문헌 특허문헌 (특허문헌 0001) 대한민국 공개특허 제 10-2019-0038134호(발명의 명칭: 360 영상 라이브 스트리밍 서비스 방법 및 서버장치)"}
{"patent_id": "10-2019-0144712", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 전술한 문제점을 해결하기 위하여, 본 발명의 일 실시예에 따라 여러 대의 360도 카메라로 촬영된 각 시점의 영상 데이터들에 대한 실시간 스트리밍 서비스를 제공하면서 360도 스트리밍 영상에서 사용자가 시청하 는 시청 영역을 중심으로 객체를 인식하여 시각화할 수 있도록 하는 것에 목적이 있다. 다만, 본 실시예가 이루고자 하는 기술적 과제는 상기된 바와 같은 기술적 과제로 한정되지 않으며, 또 다른 기 술적 과제들이 존재할 수 있다."}
{"patent_id": "10-2019-0144712", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기한 기술적 과제를 달성하기 위한 기술적 수단으로서 본 발명의 일 실시예에 따른 스트리밍 서버에 의해 수 행되는 다시점 동영상에서의 객체 처리 방법에 있어서, a) 콘텐츠 제작 단말로부터 전방향으로 배열된 하나 이 상의 카메라를 이용하여 촬영된 시점별 영상 데이터를 실시간 수신하는 단계; b) 상기 시점별 영상 데이터에 대 한 영상 스티칭 및 색상 톤 보정을 수행하는 영상 보정 알고리즘을 수행하여 하나의 다시점 영상으로 병합하는 단계; c) 상기 병합된 다시점 영상에서 사용자의 시야각을 기준으로 관심 영역을 설정하고, 인공 지능 기반의 객체 검출 모델을 이용하여 상기 관심 영역에서 하나 이상의 객체 영상을 추출한 후 상기 추출된 객체 영상에 대한 메타 데이터를 저장하는 단계; d) 상기 객체 영상에 상응하는 증강현실(Augmented Reality, AR) 콘텐츠를 생성하고, 상기 다시점 영상에 상기 객체 영상, AR 콘텐츠 및 메타데이터를 통합하여 360도 스트리밍 영상을 생 성하여 저장하는 단계; 및 e) 사용자 단말의 요청에 따라 상기 360도 스트리밍 영상을 상기 사용자 단말에 제공 하고, 상기 360도 스트리밍 영상이 재생되는 도중에 상기 사용자 단말에 의해 관심 객체가 선택되면, 상기 관심 객체에 포함된 AR 콘텐츠를 실시간 출력하는 단계를 포함하되, 상기 인공 지능 기반의 객체 검출 모델은, 네트 워크를 통해 복수의 360도 스트리밍 영상을 수집하여 학습 영상으로 저장하고, 상기 학습 영상들 중 객체 영상 에 대한 레이블링 작업을 수행하여 레이블링 데이터를 데이터베이스에 저장하며, 상기 데이터베이스에 저장된 학습 영상에 기초하여 상기 레이블링 데이터를 학습하는 것이다. 상기 b) 단계는, 상기 시점별 영상 데이터에서 하나 이상의 특징점을 검출하는 단계; 상기 시점별 영상 데이터 의 특징점들을 비교하여 서로 이웃한 시점의 영상 데이터들 간에 동일한 특징점들을 동일점으로 매칭하여 대응 쌍들을 생성하는 단계; 및 상기 대응 쌍들로부터 각 시점별 영상 데이터들 간의 변환행렬을 계산하고, 상기 변 환 행렬을 통해 영상 스티칭을 수행하는 단계를 포함할 수 있다. 상기 시점별 영상 데이터에서 하나 이상의 특징점을 검출하는 단계는, SIFT(Scale Invariant Feature Transform) 알고리즘과 SURF(Speeded Up Robust Feature) 알고리즘 중 어느 하나의 알고리즘을 이용하여 특징 점을 검출할 수 있다. 상기 b) 단계는, 상기 매칭된 대응 쌍들간의 변환 관계를 RANSAC(RANdom SAmple Consensus) 알고리즘을 사용하 여 하기 수학식 1의 동차형(Homogeneous)으로 표현된 변환 행렬을 통해 회전 행렬 및 이동 벡터를 계산할 수 있 다. 또한, 상기 b) 단계는, 상기 영상 스티칭을 통해 병합된 서로 이웃한 시점의 영상 데이터들간에 중첩되는 영역 에서의 색상 보정을 위한 색상 변형 가중치를 계산하고, 상기 색상 변형 가중치를 이용하여 전체 영상 데이터의 색상 톤을 보정할 수 있다. 여기서, 상기 b) 단계는, 하기 수학식 2를 이용하여 상기 색상 변형 가중치의 최소 값을 계산하고, 상기 색상 변형 가중치의 최소값을 전체 영상 데이터에 적용할 수 있다. 상기 메타데이터는 상기 객체 영상에 대한 객체의 종류, 객체 위치 정보 및 크기 정보를 포함할 수 있다. 한편, 본 발명의 다른 일 실시예에 따른 다시점 동영상에서의 객체 처리를 위한 스트리밍 서버에 있어서, 다시 점 동영상에서의 객체 처리 방법을 수행하기 위한 프로그램이 기록된 메모리; 및 상기 프로그램을 실행하기 위 한 프로세서를 포함하며, 상기 프로세서는, 상기 프로그램의 실행에 의해, 콘텐츠 제작 단말로부터 전방향으로 배열된 하나 이상의 카메라를 이용하여 촬영된 시점별 영상 데이터를 실시간 수신하여, 상기 시점별 영상 데이 터에 대한 영상 스티칭 및 색상 톤 보정을 수행하는 영상 보정 알고리즘을 수행하여 하나의 다시점 영상으로 병 합하고, 상기 병합된 다시점 영상에서 사용자의 시야각을 기준으로 관심 영역을 설정하고, 인공 지능 기반의 객 체 검출 모델을 이용하여 상기 관심 영역에서 하나 이상의 객체 영상을 추출한 후 상기 추출된 객체 영상에 대 한 메타 데이터를 저장하며, 상기 객체 영상에 상응하는 증강현실(Augmented Reality, AR) 콘텐츠를 생성하고, 상기 다시점 영상에 상기 객체 영상, AR 콘텐츠 및 메타데이터를 통합하여 360도 스트리밍 영상을 생성하여 저 장하고, 사용자 단말의 요청에 따라 상기 360도 스트리밍 영상을 상기 사용자 단말에 제공하고, 상기 360도 스 트리밍 영상이 재생되는 도중에 상기 사용자 단말에 의해 관심 객체가 선택되면, 상기 관심 객체에 포함된 AR 콘텐츠를 실시간 출력하되, 상기 인공 지능 기반의 객체 검출 모델은, 네트워크를 통해 복수의 360도 스트리밍 영상을 수집하여 학습 영상으로 저장하고, 상기 학습 영상들 중 객체 영상에 대한 레이블링 작업을 수행하여 레 이블링 데이터를 데이터베이스에 저장하며, 상기 데이터베이스에 저장된 학습 영상에 기초하여 상기 레이블링 데이터를 학습하는 것이다. 상기 프로세서는, 상기 시점별 영상 데이터에서 하나 이상의 특징점을 검출한 후, 상기 시점별 영상 데이터의 특징점들을 비교하여 서로 이웃한 시점의 영상 데이터들 간에 동일한 특징점들을 동일점으로 매칭하여 대응쌍들 을 생성하고, 상기 대응 쌍들로부터 각 시점별 영상 데이터들 간의 변환행렬을 계산하고, 상기 변환 행렬을 통 해 영상 스티칭을 수행하는 것이다. 또한, 상기 프로세서는, 상기 영상 스티칭을 통해 병합된 서로 이웃한 시점의 영상 데이터들간에 중첩되는 영역 에서의 색상 보정을 위한 색상 변형 가중치를 계산하고, 상기 색상 변형 가중치를 이용하여 전체 영상 데이터의 색상 톤을 보정할 수 있다."}
{"patent_id": "10-2019-0144712", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "전술한 본 발명의 과제 해결 수단에 의하면, 여러 대의 360도 카메라로 촬영된 각 시점의 영상 데이터들에 대한 실시간 스트리밍 서비스를 제공할 수 있고, 각 카메라마다 특성 및 위치가 상이하고 영상 왜곡 정도와 색상이 동일하지 않으므로 각 시점의 영상 데이터들에 대한 영상 스티칭과 색상 톤 보정을 수행함으로써 콘텐츠 제작 단말이 쉽게 양질의 360도 스트리밍 영상을 제작할 수 있도록 한다. 또한, 본 발명은 인공 지능 기반의 객체 검출 모델을 통해 360도 스트리밍 영상 내의 객체 영상을 학습하고, 학 습된 객체 검출 모델을 통해 실시간 객체 영상을 검출하되, 영상의 전체 영역이 아니라 관심 영역에 대한 객체 인식을 수행하여 서버의 영상 처리 능력이 향상될 수 있고, 객체 영상에 광고 정보, 상품 판매 정보, 게임 정보 등의 AR 콘텐츠를 포함함으로써 개인 방송 미디어 등의 실시간 콘텐츠에 광고, 커머스, 게임 등의 AR 콘텐츠와 연계하여 다양한 360도 스트리밍 영상을 제공할 수 있다."}
{"patent_id": "10-2019-0144712", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "아래에서는 첨부한 도면을 참조하여 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자가 용이하게 실시할 수 있도록 본 발명의 실시예를 상세히 설명한다. 그러나 본 발명은 여러 가지 상이한 형태로 구현될 수 있으며 여기에서 설명하는 실시예에 한정되지 않는다. 그리고 도면에서 본 발명을 명확하게 설명하기 위해서 설명과 관 계없는 부분은 생략하였으며, 명세서 전체를 통하여 유사한 부분에 대해서는 유사한 도면 부호를 붙였다. 명세서 전체에서, 어떤 부분이 다른 부분과 \"연결\"되어 있다고 할 때, 이는 \"직접적으로 연결\"되어 있는 경우뿐 아니라, 그 중간에 다른 소자를 사이에 두고 \"전기적으로 연결\"되어 있는 경우도 포함한다. 또한 어떤 부분이 어떤 구성요소를 \"포함\"한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다른 구성요소를 제외하는 것이 아 니라 다른 구성요소를 더 포함할 수 있는 것을 의미하며, 하나 또는 그 이상의 다른 특징이나 숫자, 단계, 동작, 구성요소, 부분품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해 되어야 한다. 본 명세서에서 '단말'은 휴대성 및 이동성이 보장된 무선 통신 장치일 수 있으며, 예를 들어 스마트 폰, 태블릿 PC 또는 노트북 등과 같은 모든 종류의 핸드헬드(Handheld) 기반의 무선 통신 장치일 수 있다. 또한, '단말'은 네트워크를 통해 다른 단말 또는 서버 등에 접속할 수 있는 PC 등의 유선 통신 장치인 것도 가능하다. 또한, 네트워크는 단말들 및 서버들과 같은 각각의 노드 상호 간에 정보 교환이 가능한 연결 구조를 의미하는 것으로, 근거리 통신망(LAN: Local Area Network), 광역 통신망(WAN: Wide Area Network), 인터넷 (WWW: World Wide Web), 유무선 데이터 통신망, 전화망, 유무선 텔레비전 통신망 등을 포함한다. 무선 데이터 통신망의 일례에는 3G, 4G, 5G, 3GPP(3rd Generation Partnership Project), LTE(Long Term Evolution), WIMAX(World Interoperability for Microwave Access), 와이파이(Wi-Fi), 블루투스 통신, 적외선 통신, 초음파 통신, 가시광 통신(VLC: Visible Light Communication), 라이파이(LiFi) 등이 포함되나 이에 한 정되지는 않는다. 이하의 실시예는 본 발명의 이해를 돕기 위한 상세한 설명이며, 본 발명의 권리 범위를 제한하는 것이 아니다. 따라서 본 발명과 동일한 기능을 수행하는 동일 범위의 발명 역시 본 발명의 권리 범위에 속할 것이다. 이하 첨부된 도면을 참고하여 본 발명의 일 실시예를 상세히 설명하기로 한다. 도 1은 본 발명의 일 실시예에 따른 다시점 동영상에서의 객체 처리를 위한 스트리밍 서버의 구성을 나타낸 도 면이다. 도 1을 참조하면, 스트리밍 서버는 통신 모듈, 메모리, 프로세서 및 데이터베이스를 포함한다. 상세히, 통신 모듈은 통신망과 연동하여 스트리밍 서버와 콘텐츠 제작 단말, 사용자 단말 간의 송수신 신호를 패킷 데이터 형태로 제공하는 데 필요한 통신 인터페이스를 제공한다. 여기서, 통신 모듈 은 다른 네트워크 장치와 유무선 연결을 통해 제어 신호 또는 데이터 신호와 같은 신호를 송수신하기 위해 필요한 하드웨어 및 소프트웨어를 포함하는 장치일 수 있다. 메모리는 다시점 동영상에서의 객체 처리 방법을 수행하기 위한 프로그램이 기록된다. 또한, 프로세서 가 처리하는 데이터를 일시적 또는 영구적으로 저장하는 기능을 수행한다. 여기서, 메모리는 휘발성 저장 매체(volatile storage media) 또는 비휘발성 저장 매체(non-volatile storage media)를 포함할 수 있으 나, 본 발명의 범위가 이에 한정되는 것은 아니다. 프로세서는 다시점 동영상에서의 객체 처리 방법을 제공하는 전체 과정을 제어하는 것으로서, 인공 지능 기반의 객체 검출 모델을 통해 360도 스트리밍 영상에서 객체 영상을 검출하고, 검출한 객체 영상에 대한 AR 콘 텐츠를 시각화하여 사용자 단말에 제공할 수 있다. 이러한 프로세서가 수행하는 각각의 동작에 대해 서는 추후 보다 상세히 살펴보기로 한다. 여기서, 프로세서는 프로세서(processor)와 같이 데이터를 처리할 수 있는 모든 종류의 장치를 포함할 수 있다. 여기서, '프로세서(processor)'는, 예를 들어 프로그램 내에 포함된 코드 또는 명령으로 표현된 기능을 수행하기 위해 물리적으로 구조화된 회로를 갖는, 하드웨어에 내장된 데이터 처리 장치를 의미할 수 있다. 이와 같이 하드웨어에 내장된 데이터 처리 장치의 일 예로써, 마이크로프로세서(microprocessor), 중앙처리장치 (central processing unit: CPU), 프로세서 코어(processor core), 멀티프로세서(multiprocessor), ASIC(application-specific integrated circuit), FPGA(field programmable gate array) 등의 처리 장치를 망 라할 수 있으나, 본 발명의 범위가 이에 한정되는 것은 아니다. 데이터베이스는 다시점 동영상에서의 객체 처리 방법을 수행하면서 누적되는 데이터가 저장된다. 예컨대, 데이터베이스에는 콘텐츠 제작 단말별 영상 데이터, 객체 검출 모델의 학습 데이터, 실시간360도 스트리밍 영상, 객체 영상, 메타 데이터, AR 콘텐츠 등이 저장될 수 있다. 도 2는 본 발명의 일 실시예에 따른 다시점 동영상에서의 객체 처리 방법을 나타낸 동작 흐름도이고, 도 3은 본 발명의 일 실시예에 따른 영상 보정 알고리즘 중 영상 스티칭 과정을 설명하는 예시도이며, 도 4는 본 발명의 일 실시예에 따른 영상 보정 알고리즘 중 색상 톤 보정 과정을 설명하는 예시도이다. 도 5는 본 발명의 일 실시 예에 따른 관심 영역을 설명하는 도면이고, 도 6은 본 발명의 일 실시예에 따른 인공 지능 기반의 객체 검출 모 델을 설명하는 도면이다. 도 2를 참조하면, 스트리밍 서버는 콘텐츠 제작 단말로부터 전방향으로 배열된 하나 이상의 360도 카 메라를 이용하여 촬영된 시점별 영상 데이터를 실시간 수신한다(S1). 스트리밍 서버는 시점별 영상 데이터에 대한 영상 스티칭 및 색상 톤 보정을 수행하는 영상 보정 알고리즘 을 수행하여 시점별 영상 데이터들을 하나의 다시점 영상으로 병합한다(S2). 도 3에 도시된 바와 같이, 스트리밍 서버는 콘텐츠 제작 단말로부터 실시간 전송되는 시점별 영상 데 이터에서 SIFT(Scale Invariant Feature Transform) 알고리즘과 SURF(Speeded Up Robust Feature) 알고리즘 중 어느 하나의 알고리즘을 이용하여 특징점들을 검출하고(S31), 시점별 영상 데이터의 특징점들을 서로 비교하여 서로 이웃한 시점의 영상 데이터들 간에 동일한 특징점들을 동일점으로 매칭하여 대응쌍들을 생성한다(S32) 스 트리밍 서버는 대응 쌍들로부터 각 시점별 영상 데이터들 간의 변환행렬을 계산하고(S33), 변환 행렬을 통 해 영상 스티칭을 수행한다(S34). 이때, 스트리밍 서버는 매칭된 대응 쌍들간의 변환 관계를 RANSAC(RANdom SAmple Consensus) 알고리즘을 사용하여 하기 수학식 1의 동차형(Homogeneous)으로 표현된 변환 행렬을 통해 회전 행렬 및 이동 벡터를 계산한 다. [수학식 1]"}
{"patent_id": "10-2019-0144712", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "한편, 도 4에 도시된 바와 같이, 스트리밍 서버는 상이한 영상 데이터 간에 색상 톤을 일치시키기 위해, 영상 스티칭을 통해 병합된 서로 이웃한 시점의 영상 데이터들간에 중첩되는 영역에서의 색상 보정을 위한 색상 변형 가중치를 하기 수학식 2를 이용하여 계산한다. [수학식 2]"}
{"patent_id": "10-2019-0144712", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "수학식 2에서, ra, ga, ba는 중첩되는 영역 A의 각 화소 색상 값이고, rb, gb, bb는 중첩되는 영역 B의 각 화소 색상 값이며, w는 색상 변형 가중치이고, n은 중첩되는 영역의 화소수를 각각 의미한다. 스트리밍 서버는 색상 변형 가중치의 최소값을 계산하고, 이 최소값을 전체 영상 데이터에 적용함으로써 전체 영상 데이터의 색 상 톤을 보정한다. 다시 도 2를 설명하면, 스트리밍 서버는 영상 스티칭과 색상 톤 보정을 통해 병합된 다시점 영상에서 사용 자의 시야각, 즉 도 5에 도시된 바와 같이 시청 영역을 기준으로 관심 영역(ROI)을 설정한다(S3). 이때, 스트리밍 서버는 사용자 단말의 화면 크기에 따라 기설정된 시야각 범위를 추출한 후 추출된 시야각 범위에 근거하여 설정된 시청 영역을 ROI로 설정한다. 일례로, 유투브의 경우에 유투브의 360도 영상을 HMD(Head Mounted Display)가 아닌 스마트 폰으로 시청하면 HMD와 마찬가지로 스마트폰에 내장되어 있는 자이로 센서 또는 IMU(Inertial Measurement Unit) 센서를 통해 추정된 스마트폰의 자세 데이터 또는 회전 데이터를 기 반으로 시청자가 스마트폰을 돌리는 방향에 있는 360도 영상의 일부분만을 시청하도록 한다. 이와 동일한 원리로, 스트리밍 서버는 스마트폰, 태블릿 PC 등의 사용자 단말에 내장된 센서와 단말 별 스펙 정보, 기기정보 등을 이용하여 사용자의 시청 영역을 알 수 있고, 이를 토대로 ROI를 설정하는 것이다. 스트리밍 서버는 인공 지능 기반의 객체 검출 모델을 이용하여 관심 영역에서 하나 이상의 객체 영상을 추 출한 후 추출된 객체 영상에 대한 메타 데이터를 데이터베이스에 저장한다(S4). 이때, 메타데이터는 객체 영상에 대한 객체의 종류, 영상 내에서의 객체 위치 정보, 객체의 크기 정보를 포함한다. 스트리밍 서버는 네트워크를 통해 복수의 360도 스트리밍 영상을 수집하여 학습 영상으로 데이터베이스 에 저장하고, 학습 영상들 중 객체 영상에 대한 레이블링 작업을 수행하여 레이블링 데이터를 데이터베이 스에 저장한다. 도 6에 도시된 바와 같이, 인공 지능 기반의 객체 검출 모델은 데이터베이스에 저장 된 학습 영상에 기초하여 레이블링 데이터를 학습한다. 이때, 객체 검출 모델은 객체를 학습시키기 위해서는 학습할 영상과 파라미터 파일들, 가중치 파일이 필요하며, 학습을 완료하면 학습시킨 객체들을 인식하는 가중치 파일이 생성된다. 다크넷의 YOLO(You Only Look Once) 모 델의 경우, 파라미터 파일은 컨볼루션 레이어(convolutional), 학습 횟수, 영상 사이즈(height, width), 그래픽 카드 사용량, 출력층 필터 등의 신경망의 설정들을 조정할 수 있고, 이 파일의 값들을 잘 조정하면 객체 인식의 성능을 높일 수 있다. 객체 검출 모델은 기계 학습 중 YOLO(You Only Look Once), R-CNN, FAST R-CNN, FASTER R-CNN, SSD(Single Shot Multibox Detector) 등의 딥 러닝에 기반하여 구축되지만, 딥러닝 이외에 Random Forest, Support Vector Machine 등의 여러 기계 학습을 이용하여 구축될 수 있다. 기계 학습은 크게 지도학습, 비지도 학습, 강화 학습 으로 분류될 수 있고, 특히 강화학습은 딥러닝, 큐러닝(Q-Learning), 딥러닝과 큐러닝이 결합한 DQN(Deep-Q- Network) 알고리즘이 대표적으로 사용된다. 딥러닝을 포함한 기계학습(machine learning)에서 지도학습 (supervised learning)은 입력값과 출력값이 포함된 레이블링 데이터(labeling data)를 학습하며, 데이터가 충 분할 경우에 다양하게 활용될 수 있어 가장 활발히 연구되고 있는 분야이다. 스트리밍 서버는 객체 영상에 상응하는 증강현실(Augmented Reality, AR) 콘텐츠를 생성하고, 다시점 영상 에 객체 영상, AR 콘텐츠 및 메타데이터를 통합하여 360도 스트리밍 영상을 생성하여 저장한다(S5). 사용자 단말이 360도 스트리밍 영상을 요청하면(S6), 스트리밍 서버는 해당 360도 스트리밍 영상을 사용자 단말에 제공하여 메타데이터가 시각화되도록 한다(S7). 스트리밍 서버는 사용자 단말에서360도 스트리밍 영상이 재생되는 도중에 관심 객체가 선택되면(S8), 관심 객체에 포함된 AR 콘텐츠를 실시간 출력한다(S9). 하나 이상의 360도 카메라를 이용하여 실시간으로 획득된 시점별 영상 데이터들은 각 카메라의 특성 및 위치가 상이하므로 영상 왜곡 정도 및 색상이 동일하지 않다. 따라서, 콘텐츠 제작 단말은 특정 콘텐츠에 대해 시 점별 영상 데이터의 촬영이 종료될 때까지 스트리밍 서비스를 위해 각 시점마다 획득된 영상 데이터를 스트리밍 서버에 전송한다(S10, S11). 스트리밍 서버는 시점별 영상 데이터를 영상 스티칭 및 색상 톤 보정을 통해 하나의 다시점 영상으로 병합 하고, 전체 영역에 대한 객체 검출을 수행하지 않고, 현재 사용자가 보고 있는 관심 영역만 객체 검출을 수행하 면서 360도 스트리밍 영상을 사용자 단말에 제공한다. 한편 도 2의 단계 S1 내지 S11은 본 발명의 구현예에 따라서 추가적인 단계들로 분할되거나, 더 적은 단계들로 조합될 수 있다. 또한, 일부 단계는 필요에 따라 생략될 수도 있고, 단계간의 순서가 변경될 수도 있다. 도 7은 본 발명의 일시시예에 따른 360도 스트리밍 영상의 생성 과정을 설명하는 도면이고, 도 8은 본 발명의 일 실시예에 따른 다시점 동영상에서의 객체 처리 방법에 의해 AR 콘텐츠의 증강 과정을 설명하는 도면이며, 도 9는 도 8의 360도 스트리밍 영상에서 관심 객체의 AR 콘텐츠 증강 화면을 설명하는 예시도이다. 도 7 내지 도 8을 참조하면, 콘텐츠 제작 단말은 여러 대의 360도 카메라로 촬영된 각 시점의 영상 데이터를 실시간 스트리밍 서버로 전송한다(도 7의 (a) 참조). 스트리밍 서버는 각 시점의 영상 데이터를 영상 스티칭 및 색상 톤 보정을 통해 하나의 다시점 영상으로 병합하고(도 7의 (b) 참조), 객체 검출 모델을 통해 와인, 책 사람, 일회용 컵(disposable cup) 등의 객체 영상 을 검출하고, 각 객체의 종류, 위치 및 크기 정보를 포함한 메타데이터를 객체 영상과 함께 저장한다(도 7의 (c)). 스트리밍 서버는 사용자 단말의 요청에 따라 360도 스트리밍 영상을 제공하고, 사용자 단말에 의해 관심 객체가 선택되는 경우에 데이터베이스에 관심 객체와 함께 저장되어 있는 AR 콘텐츠를 구현한다. 이때, AR 콘텐츠는 관심 객체에 대한 광고 정보, 판매 정보, 게임 정보 등이 될 수 있다. 이상에서 설명한 본 발명의 실시예에 따른 다시점 동영상에서의 객체 처리 방법은, 컴퓨터에 의해 실행되는 프 로그램 모듈과 같은 컴퓨터에 의해 실행 가능한 명령어를 포함하는 기록 매체의 형태로도 구현될 수 있다. 이 러한 기록 매체는 컴퓨터 판독 가능 매체를 포함하며, 컴퓨터 판독 가능 매체는 컴퓨터에 의해 액세스될 수 있 는 임의의 가용 매체일 수 있고, 휘발성 및 비휘발성 매체, 분리형 및 비분리형 매체를 모두 포함한다. 또한, 컴퓨터 판독가능 매체는 컴퓨터 저장 매체를 포함하며, 컴퓨터 저장 매체는 컴퓨터 판독가능 명령어, 데이터 구 조, 프로그램 모듈 또는 기타 데이터와 같은 정보의 저장을 위한 임의의 방법 또는 기술로 구현된 휘발성 및 비휘발성, 분리형 및 비분리형 매체를 모두 포함한다."}
{"patent_id": "10-2019-0144712", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "전술한 본 발명의 설명은 예시를 위한 것이며, 본 발명이 속하는 기술분야의 통상의 지식을 가진 자는 본 발명 의 기술적 사상이나 필수적인 특징을 변경하지 않고서 다른 구체적인 형태로 쉽게 변형이 가능하다는 것을 이해 할 수 있을 것이다. 그러므로 이상에서 기술한 실시예들은 모든 면에서 예시적인 것이며 한정적이 아닌 것으로 이해해야만 한다. 예를 들어, 단일형으로 설명되어 있는 각 구성 요소는 분산되어 실시될 수도 있으며, 마찬가 지로 분산된 것으로 설명되어 있는 구성 요소들도 결합된 형태로 실시될 수 있다. 본 발명의 범위는 상기 상세한 설명보다는 후술하는 특허청구범위에 의하여 나타내어지며, 특허청구범위의 의미 및 범위 그리고 그 균등 개념으로부터 도출되는 모든 변경 또는 변형된 형태가 본 발명의 범위에 포함되는 것으 로 해석되어야 한다."}
{"patent_id": "10-2019-0144712", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일 실시예에 따른 다시점 동영상에서의 객체 처리를 위한 스트리밍 서버의 구성을 나타낸 도 면이다. 도 2는 본 발명의 일 실시예에 따른 다시점 동영상에서의 객체 처리 방법을 나타낸 동작 흐름도이다. 도 3은 본 발명의 일 실시예에 따른 영상 보정 알고리즘 중 영상 스티칭 과정을 설명하는 예시도이다. 도 4는 본 발명의 일 실시예에 따른 영상 보정 알고리즘 중 색상 톤 보정 과정을 설명하는 예시도이다. 도 5는 본 발명의 일 실시예에 따른 관심 영역을 설명하는 도면이다. 도 6은 본 발명의 일 실시예에 따른 인공 지능 기반의 객체 검출 모델을 설명하는 도면이다. 도 7은 본 발명의 일시시예에 따른 360도 스트리밍 영상의 생성 과정을 설명하는 도면이다. 도 8은 본 발명의 일 실시예에 따른 다시점 동영상에서의 객체 처리 방법에 의해 AR 콘텐츠의 증강 과정을 설명 하는 도면이다. 도 9는 도 8의 360도 스트리밍 영상에서 관심 객체의 AR 콘텐츠 증강 화면을 설명하는 예시도이다."}
