{"patent_id": "10-2024-0201166", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2025-0010572", "출원번호": "10-2024-0201166", "발명의 명칭": "청소 로봇 및 그의 태스크 수행 방법", "출원인": "삼성전자주식회사", "발명자": "홍순혁"}}
{"patent_id": "10-2024-0201166", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "청소 로봇의 제어 방법에 있어서,맵 정보를 기반으로 상기 청소 로봇이 주행하는 동안 오브젝트를 포함하는 영상을 촬영하는 동작; 적어도 하나 이상의 인공 지능 모델을 이용하여 상기 촬영된 영상에 포함된 상기 오브젝트에 대한 오브젝트 인식 정보를 획득하는 동작, 복수 개의 태스크를 포함하는 태스크 목록과 상기 촬영된 영상이 사용자 단말 장치에 표시되도록, 상기 오브젝트 인식 정보에 기반하여 상기 촬영된 영상에 대한 정보를 상기 사용자 단말 장치에 전송하는 동작; 상기 촬영된 영상에 포함된 상기 오브젝트 인식 정보와 상기 촬영된 영상에 기반하여 상기 적어도 하나 이상의인공지능 모델을 업데이트하는 동작; 및상기 사용자 단말 장치로부터 수신된 선택된 태스크, 상기 맵 정보, 업데이트된 상기 적어도 하나 이상의 인공지능 모델에 따라 상기 청소 로봇을 제어하는 동작;을 포함하는,청소 로봇의 제어 방법."}
{"patent_id": "10-2024-0201166", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1 항에 있어서. 상기 선택된 태스크는 상기 오브젝트 인식 정보에 따라 상기 청소 로봇의 로컬 주행 계획을 업데이트하는 태스크를 포함하는청소 로봇의 제어 방법."}
{"patent_id": "10-2024-0201166", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 선택된 태스크는 상기 오브젝트를 완전 회피하면서 청소를 수행하는 태스크를 포함하는,청소 로봇의 제어 방법."}
{"patent_id": "10-2024-0201166", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3 항에 있어서. 상기 오브젝트를 완전 회피하면서 청소를 수행하는 태스크는상기 청소 로봇이 상기 오브젝트와 일정 거리만큼 떨어져 회피하면서 주행하는 동작을 포함하는,청소 로봇의 제어 방법."}
{"patent_id": "10-2024-0201166", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4 항에 있어서. 상기 청소 로봇은 상기 오브젝트의 위치가 이동하는 경우, 상기 오브젝트가 위치했던 바닥면을 주행하면서 청소공개특허 10-2025-0010572-3-하는,청소 로봇의 제어 방법."}
{"patent_id": "10-2024-0201166", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서,상기 선택된 태스크는 상기 오브젝트를 밀어내면서 청소를 수행하는 태스크를 포함하는,청소 로봇의 제어 방법."}
{"patent_id": "10-2024-0201166", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6 항에 있어서. 상기 오브젝트를 밀어내면서 청소를 수행하는 태스크는, 상기 청소 로봇은 상기 오브젝트가 위치했던 영역을 주행하며 청소하는 동작을 포함하는,청소 로봇의 제어 방법."}
{"patent_id": "10-2024-0201166", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "청소 로봇에 있어서,카메라;구동부; 통신부; 하나 이상의 프로그램이 저장된 메모리; 및적어도 하나 이상의 인공 지능 모델을 포함하는 학습부 및 인식부를 구비하고, 상기 하나 이상의 프로그램에 포함된 컴퓨터 실행 가능한 인스트럭션에 의해 청소 로봇을 제어하는 프로세서;를 포함하며,상기 프로세서는 맵 정보를 기반으로 상기 청소 로봇이 주행하는 동안 오브젝트를 포함하는 영상을 촬영하도록 상기 카메라를 제어하고,적어도 하나 이상의 인공 지능 모델을 이용하여 상기 촬영된 영상에 포함된 상기 오브젝트에 대한 오브젝트 인식 정보를 획득하도록 상기 인식부를 제어하고;복수 개의 태스크를 포함하는 태스크 목록과 상기 촬영된 영상이 사용자 단말 장치에 표시되도록, 상기 오브젝트 인식 정보에 기반하여 상기 촬영된 영상에 대한 정보를 상기 사용자 단말 장치에 전송하도록 상기 통신부를제어하고, 상기 촬영된 영상에 포함된 상기 오브젝트 인식 정보와 상기 촬영된 영상에 기반하여 상기 적어도 하나 이상의인공지능 모델을 업데이트하도록 상기 학습부를 제어하고,상기 사용자 단말 장치로부터 수신된 선택된 태스크, 상기 맵 정보, 업데이트된 상기 적어도 하나 이상의 인공지능 모델에 따라 상기 구동부룰 제어하는,청소 로봇."}
{"patent_id": "10-2024-0201166", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "공개특허 10-2025-0010572-4-제8 항에 있어서. 상기 프로세서에 의해 실행되는 상기 하나 이상의 프로그램은 상기 오브젝트 인식 정보에 따라 상기 청소 로봇의 로컬 주행 계획을 업데이트하는 동작을 포함하도록 상기 학습부를 제어하는 인스트럭션을 더 포함하는청소 로봇."}
{"patent_id": "10-2024-0201166", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제8 항에 있어서,상기 선택된 태스크는 상기 오브젝트를 완전 회피하면서 청소를 수행하는 태스크를 포함하는,청소 로봇."}
{"patent_id": "10-2024-0201166", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제10 항에 있어서. 상기 프로세서에 의해 실행되는 상기 하나 이상의 프로그램은상기 오브젝트를 완전 회피하면서 청소를 수행하는 태스크에서, 상기 청소 로봇이 상기 오브젝트와 일정 거리만큼 떨어져 회피하면서 주행하도록 상기 구동부를 제어하는 인스트럭션을 더 포함하는,청소 로봇."}
{"patent_id": "10-2024-0201166", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11 항에 있어서. 상기 청소 로봇은 상기 오브젝트의 위치가 이동하는 경우, 상기 프로세서에 의해 실행되는 상기 하나 이상의 프로그램은상기 오브젝트가 위치했던 바닥면을 주행하면서 청소하 하도록 상기 구동부를 제어하는 인스트럭션을 더 포함하는,청소 로봇."}
{"patent_id": "10-2024-0201166", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제8 항에 있어서,상기 선택된 태스크는 상기 오브젝트를 밀어내면서 청소를 수행하는 태스크를 포함하는,청소 로봇."}
{"patent_id": "10-2024-0201166", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제13 항에 있어서. 상기 프로세서에 의해 실행되는 상기 하나 이상의 프로그램은상기 오브젝트를 밀어내면서 청소를 수행하는 태스크에서, 상기 청소 로봇은 상기 오브젝트가 위치했던 영역을주행하며 청소하도록 상기 구동부를 제어하는 인스트럭션을 더 포함하는,공개특허 10-2025-0010572-5-청소 로봇."}
{"patent_id": "10-2024-0201166", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "컴퓨터 판독 가능한 비일시적 판독 가능 저장 매체로서, 프로세서가 개별적으로 또는 집합적으로 실행하면서 청소 로봇이 작업을 수행하도록 하는 컴퓨터 실행 가능 인스트럭션을 저장하며, 해당 작업은 청소 로봇의 제어 방법에 있어서,맵 정보를 기반으로 상기 청소 로봇이 주행하는 동안 오브젝트를 포함하는 영상을 촬영하는 동작; 적어도 하나 이상의 인공 지능 모델을 이용하여 상기 촬영된 영상에 포함된 상기 오브젝트에 대한 오브젝트 인식 정보를 획득하는 동작, 복수 개의 태스크를 포함하는 태스크 목록과 상기 촬영된 영상이 사용자 단말 장치에 표시되도록, 상기 오브젝트 인식 정보에 기반하여 상기 촬영된 영상에 대한 정보를 상기 사용자 단말 장치에 전송하는 동작; 상기 촬영된 영상에 포함된 상기 오브젝트 인식 정보와 상기 촬영된 영상에 기반하여 상기 적어도 하나 이상의인공지능 모델을 업데이트하는 동작; 및상기 사용자 단말 장치로부터 수신된 선택된 태스크, 상기 맵 정보, 업데이트된 상기 적어도 하나 이상의 인공지능 모델에 따라 상기 청소 로봇을 제어하는 동작;을 포함하는,컴퓨터 판독 가능한 비일시적 판독 가능 저장 매체."}
{"patent_id": "10-2024-0201166", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 개시에 따른 청소 로봇의 태스크 수행 방법은, 상기 청소 로봇 주변의 오브젝트를 촬영하는 동작, 상기 촬영 된 영상을 학습된 적어도 하나의 인공 지능 모델에 적용하여, 상기 청소 로봇이 수행할 태스크를 결정하는 동작, 상기 결정된 태스크에 따라 상기 청소 로봇의 개구부의 전방에서 바닥 면으로 가드부가 하강되도록 제어하는 동 작, 및 상기 하강된 가드부에 의하여 상기 오브젝트가 이동되도록, 상기 오브젝트를 향하여 주행하는 동작을 포 함할 수 있다."}
{"patent_id": "10-2024-0201166", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 청소 로봇 및 청소 로봇의 태스크 방법에 관한 것으로, 구체적으로는, 청소 로봇 주변의 오브젝트(예 로, 장애물)에 대한 정보를 이용하여 적합한 태스크를 제공할 수 있는 로봇 및 그의 제어 방법에 관한 것이다."}
{"patent_id": "10-2024-0201166", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "로봇 기술의 발전에 따라 전문화된 학술 분야 또는 대규모의 노동력을 요하는 산업 분야뿐만 아니라 일반적인 가정에도 로봇의 공급이 보편화 되고 있다. 사용자에게 가사 서비스를 제공하는 서비스 로봇, 청소 로봇, 애완 용 로봇 등이 많이 보급되고 있다. 특히, 청소 로봇과 같은 경우, 청소 로봇 주변의 이물질, 구조물, 장애물 등의 오브젝트와 관련된 정보를 구체 적으로 판단하고, 각각의 오브젝트에 대해 적합한 태스크를 수행하는 것이 매우 중요하다. 종래의 청소 로봇은 제한된 센서 조합으로 인해 오브젝트의 구체적인 정보를 획득하는 것에 제한이 있다. 즉, 종래의 청소 로봇은 오브젝트가 어떤 오브젝트인지에 대한 정보가 없이 센서의 센싱 능력에만 의존하여 모두 동일한 패턴의 회피 주 행만을 수행하였다. 이에, 청소 로봇 주변의 오브젝트를 고려하여 최적의 청소 로봇의 태스크를 결정하고, 나아가 주행 및 회피 방 법을 차별화할 필요성이 요구된다."}
{"patent_id": "10-2024-0201166", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 개시는 상술한 필요성에 따른 것으로, 본 개시의 목적은, 청소 로봇 주변의 오브젝트를 고려하여 최적의 태 스크를 수행하는 청소 로봇 및 그의 태스크 수행 방법을 제공함에 있다. 특히, 본 개시의 목적은 청소 로봇 주 변의 오브젝트를 인식하고, 인식된 오브젝트의 속성을 고려하여, 최적의 태스크를 수행하는 청소 로봇 및 그의 태스크 수행 방법을 제공함에 있다."}
{"patent_id": "10-2024-0201166", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상술한 서비스를 제공하기 위한 본 개시의 일 실시 예에 따른, 청소 로봇의 태스크 수행 방법은, 상기 청소 로 봇 주변의 오브젝트를 촬영하는 동작, 상기 촬영된 영상을 학습된 적어도 하나의 인공 지능 모델에 적용하여, 상기 청소 로봇이 수행할 태스크를 결정하는 동작, 상기 결정된 태스크에 따라 상기 청소 로봇의 개구부의 전방 에서 바닥 면으로 가드부가 하강되도록 제어하는 동작; 및 상기 하강된 가드부에 의하여 상기 오브젝트가 이동 되도록, 상기 오브젝트를 향하여 주행하는 동작을 포함한다. 상술한 서비스를 제공하기 위한 본 개시의 일 실시 예에 따른, 청소 로봇은, 카메라, 구동부, 상기 청소 로봇의 개구부의 전방에 마련된 가드부, 및 프로세서를 포함한다. 프로세서는, 상기 청소 로봇 주변의 오브젝트를 촬영 하도록 상기 카메라를 제어하고, 상기 촬영된 영상을 학습된 적어도 하나의 인공 지능 모델에 적용하여, 상기 청소 로봇이 수행할 태스크를 결정하고, 상기 결정된 태스크에 따라 상기 개구부의 전방에서 바닥 면으로 가드 부가 하강되도록 제어하고, 상기 하강된 가드부에 의하여 상기 오브젝트를 이동시키기 위하여, 상기 청소 로봇 이 상기 오브젝트를 향하여 주행하도록 상기 구동부를 제어한다."}
{"patent_id": "10-2024-0201166", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "상술한 바와 같은 본 개시의 일 실시예에 따르면, 청소 로봇은 오브젝트가 촬영된 영상을 인식하여, 오브젝트를 회피하거나 이동시키는 등의 최적의 태스크를 수행할 수 있다. 또한, 본 개시의 일 실시예에 따르면, 청소 로봇이 가드부를 이용하여 오브젝트를 이동시키는 것이 가능하여, 청소와 함께 오브젝트의 정리가 가능해지고, 오브젝트에 의하여 청소 로봇이 걸리는 상황이 최소화될 수 있다. 또한, 본 개시의 일 실시예에 따르면, 오브젝트를 이동시킨 후 오브젝트가 위치했던 바닥 면을 청소하는 것이 가능하여, 댁 내의 최대한 많은 영역의 청소가 가능해진다. 또한, 본 개시의 일 실시예에 따르면, 오브젝트가 촬영된 영상 및 사용자가 선택한 사용자 태스크를 학습 데이 터로서 이용하여, 청소 로봇이 오브젝트를 고려한 최적의 태스크를 제공할 확률이 증가할 수 있다. 또한, 본 개시의 일 실시예에 따르면, 오브젝트를 이동시킨 후에 청소 로봇이 주행할 로컬 주행 계획의 업데이 트가 가능하여, 청소 로봇의 효율적인 주행이 가능하게 된다."}
{"patent_id": "10-2024-0201166", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 본 문서의 다양한 실시예가 첨부된 도면을 참조하여 기재된다. 그러나, 이는 본 문서에 기재된 기술을 특 정한 실시 형태에 대해 한정하려는 것이 아니며, 본 문서의 실시예의 다양한 변경(modifications), 균등물 (equivalents), 및/또는 대체물(alternatives)을 포함하는 것으로 이해되어야 한다. 도면의 설명과 관련하여, 유사한 구성요소에 대해서는 유사한 참조 부호가 사용될 수 있다. 또한, 본 문서에서 사용된 \"제 1,\" \"제 2,\" 등의 표현들은 다양한 구성요소들을, 순서 및/또는 중요도에 상관없 이 수식할 수 있고, 한 구성요소를 다른 구성요소와 구분하기 위해 사용될 뿐 해당 구성요소들을 한정하지 않는다. 예를 들면, 제 1 사용자 기기와 제 2 사용자 기기는, 순서 또는 중요도와 무관하게, 서로 다른 사용자 기기 를 나타낼 수 있다. 예를 들면, 본 문서에 기재된 권리 범위를 벗어나지 않으면서 제 1 구성요소는 제 2 구성요 소로 명명될 수 있고, 유사하게 제 2 구성요소도 제 1 구성요소로 바꾸어 명명될 수 있다. 어떤 구성요소(예: 제 1 구성요소)가 다른 구성요소(예: 제 2 구성요소)에 \"(기능적으로 또는 통신적으로) 연결 되어((operatively or communicatively) coupled with/to)\" 있다거나 \"접속되어(connected to)\" 있다고 언급된 때에는, 상기 어떤 구성요소가 상기 다른 구성요소에 직접적으로 연결되거나, 다른 구성요소(예: 제 3 구성요소)를 통하여 연결될 수 있다고 이해되어야 할 것이다. 반면에, 어떤 구성요소(예: 제 1 구성요소)가 다 른 구성요소(예: 제 2 구성요소)에 \"직접 연결되어\" 있다거나 \"직접 접속되어\" 있다고 언급된 때에는, 상기 어 떤 구성요소와 상기 다른 구성요소 사이에 다른 구성요소(예: 제 3 구성요소)가 존재하지 않는 것으로 이해될 수 있다. 본 문서에서 사용된 용어들은 단지 특정한 실시예를 설명하기 위해 사용된 것으로, 다른 실시예의 범위를 한정 하려는 의도가 아닐 수 있다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함할 수 있다. 기술적이거나 과학적인 용어를 포함해서 여기서 사용되는 용어들은 본 문서에 기재된 기술 분야에서 통상 의 지식을 가진 자에 의해 일반적으로 이해되는 것과 동일한 의미를 가질 수 있다. 본 문서에 사용된 용어들 중 일반적인 사전에 정의된 용어들은, 관련 기술의 문맥상 가지는 의미와 동일 또는 유사한 의미로 해석될 수 있으 며, 본 문서에서 명백하게 정의되지 않는 한, 이상적이거나 과도하게 형식적인 의미로 해석되지 않는다. 경우에 따라서, 본 문서에서 정의된 용어일지라도 본 문서의 실시예들을 배제하도록 해석될 수 없다. 이하에서, 첨부된 도면을 이용하여 본 발명의 다양한 실시 예들에 대하여 구체적으로 설명한다. 도 1 내지 도 4는 본 개시의 일 실시 예에 따른 청소 로봇의 구조를 나타내는 도면들이다. 청소 로봇은 스스로 이동하며 사용자에게 청소 서비스를 제공하는 장치로서, 가정용 청소 로봇, 대형 건물 용 청소 로봇 또는 공항용 청소 로봇 등을 포함할 수 있다. 또한, 청소 로봇은 목적에 따라 원기둥 형태, 직육면체 형태 등 다양한 형태를 가질 수 있다. 일 실시예에 따르면, 청소 로봇은 바닥의 이물질을 단순히 제거하는 태스크를 수행할 뿐만 아니라, 물체를 옮기는 태스크도 수행할 수 있다 도 1a는 가드부가 상승되었을 때의 청소 로봇의 사시도이고, 도 1b는 가드부가 하강되었을 때의 청소 로봇 의 사시도이다. 도 1a 및 도 1b를 참조하면, 청소 로봇은 본체와, 본체에 결합되는 먼지통을 포함할 수 있다. 먼지통은 본체로부터 분리될 수 있다. 청소 로봇은 바닥 면을 따라 이동하면서, 바닥 면의 먼지를 공기와 함께 흡입하도록 마련될 수 있다. 청소 로봇은 흡입된 공기 중의 먼지를 분리 및 저장하고, 먼지가 제거된 공기를 배출할 수 있다. 먼지통은 먼지를 분리 및 저장하도록 마련될 수 있다. 사용자가 먼지통 내부의 먼지를 제거할 수 있도록 먼지통 은 본체에 분리 가능하게 결합될 수 있다. 청소 로봇은 가드부(또는, 가압부)를 포함할 수 있다. 가드부는 z 축을 기준으로 바닥면을 향하여 하강되거나, 바닥면의 반대 방향으로 상승될 수 있다. 가드부는 오브젝트가 밀리도록 가압할 수 있다. 예로, 청소 로봇이 걸릴 수 있는 오브젝트를 감지하는 경우, 청소 로봇은 가드부를 바닥면을 향하 여 하강시키고, 가드부에 의하여 오브젝트가 밀리도록 오브젝트를 향하여 주행할 수 있다. 도 2는 청소 로봇의 내부 구성의 일부를 도시하는 사시도이다. 도 2에서, 청소 로봇은 구동 모터에 동력이 전달되도록 제어하여 가드부를 상승 또는 하강시킬 수 있다. 이를 위해, 청소 로봇에는 구동 모터와 피니언 기어를 연결하는 회전축이 마련될 수 있다. 또 한, 청소 로봇의 가드부는 피니언 기어의 회전에 따라 가드부의 이동 경로를 가이드하는 가이 드부, 및 회전축을 통하여 전달되는 회전 운동을 직선운동으로 바꿀 수 있는 랙기어를 포함할 수 있다.구동 모터에 동력이 전달되는 경우, 회전축은 시계 방향 또는 반시계향으로 회전되고, 회전력에 의하여 피니언 기어가 회전될 수 있다. 피니언 기어가 랙기어와 맞물려서 회전되면 가이드부는 가드부 가 상승 또는 하강되도록 가드부의 이동 경로를 가이드할 수 있다. 일 실시예로, 구동 모터와 피니언 기어 사이에는 동력을 전달하는 하나 이상의 동력 전달 기어가 마련 될 수 있으며, 동력 전달 기어의 개수 또는 기어의 톱니 수에 따라 피니언 기어의 회전 수, 회전 방향, 회 전 속도 등이 제어될 수 있다. 일 실시예로, 회전축 또는 기어 대신에 하나 이상의 팬 밸트(fan belt)가 이 용될 수도 있다. 도 3a 은 가드부가 상승되었을 때의 청소 로봇의 측면도이고, 도 3b는 가드부가 하강되었을 때의 청소 로봇 의 측면도이다. 도 3a 및 도 3b에서, 가드부는 z 축을 따라 하강 또는 상승할 수 있다. 예로, 피니언 기어가 시계 방향 으로 회전하는 경우, 가드부는 도 3a와 같이 피니언 기어와 맞물린 랙기어 및 가이드부의 직선 운동에 의하여 상승할 수 있다. 반면에, 피니언 기어가 반시계 방향으로 회전하는 경우, 가드부는 도 3b와 같이 피니언 기어와 맞물린 랙기어 및 가이드부의 직선 운동에 의하여 하강될 수 있다. 도 4a 은 가드부가 상승되었을 때의 청소 로봇의 측면도의 내부이고, 도 4b는 가드부가 하강되었을 때의 청 소 로봇의 측면도의 내부이다. 도 4a 및 도 4b에서, 가드부는 개구부의 전방에 위치할 수 있다. 개구부는 흡입구 또는 흡입구의 전방에 위치한 함몰부를 포함할 수 있다. 도 4a 및 도 4b에서, 가드부는 함몰부의 전방에 위치하여 z 축 방향을 따라 이동할 수 있다. 보통의 상 황에서, 청소 로봇은 도 4a와 같이 가드부가 상승된 상태에서 주행하면서 바닥 면의 먼지를 흡입할 수 있다. 청소 로봇이 주행 도중에 오브젝트를 밀어야 할 상황이 발생되면, 청소 로봇은 도 4b와 같이, 가 드부를 하강시키고 오브젝트를 향하여 주행할 수 있다. 이 때, 청소 로봇은 바닥 면의 먼지를 흡입하는 동작을 함께 수행할 수도 있다. 도 4a 및 도 4b에서는, 가드부가 함몰부의 전방에 위치한 실시예를 나타내나, 일 실시예로, 가드부(1 2)는 흡입구의 전방에 위치할 수도 있다. 이 경우, 청소 로봇은 오브젝트로서, 흡입 높이에 대응되는 일정 높이(예: 약 1cm) 보다 낮은 크기를 가지거나, 일정 높이 이하의 지점에 무게 중심이 위치한 오브젝트를 대상으로 밀어내는 동작을 수행할 수 있다. 청소 로봇이 주변의 오브젝트에 따라 가드부를 상승 또는 하강시켜 태스크를 수행하는 과정은 이하 상 세히 후술될 예정이다. 도 5를 참조하면, 청소 로봇은 주변의 오브젝트를 인식할 수 있다. 예로, 청소 로봇은 일정 거리 이상(d1)(예: 15cm 이상)에서 카메라를 통해 적어도 하나의 오브젝트를 촬영할 수 있다. 청소 로봇은 주행 시작 전에 오브젝트를 촬영할 수도 있고, 주행하면서 일정 주기(예: 0.1sec 또는 3cm 이동)마다 오브 젝트를 촬영할 수 있다. 청소 로봇은 촬영된 영상에 기반하여 청소 로봇이 수행할 태스크를 결정할 수 있다. 일 실시예로, 청소 로봇은 오브젝트가 촬영된 영상을 학습된 적어도 하나의 인공 지능 모델에 적용하여 청소 로봇이 수행할 태스크를 결정할 수 있다. 이 때, 청소 로봇은 오브젝트에 대한 바운딩 박스 를 판단하고, 촬영된 영상으로서 바운딩 박스 내의 영상을 선택할 수 있다. 그리고, 청소 로봇은 바운딩 박스 내의 영상을 학습된 적어도 하나의 인공 지능 모델에 적용하여 청소 로봇이 수행할 태스 크를 결정할 수 있다. 학습된 적어도 하나의 인공 지능 모델은 청소 로봇이 수행할 태스크를 결정하도록 설정된 인공 지능 모델로 서, {오브젝트가 포함된 영상, 청소 로봇이 수행할 태스크}를 학습 데이터 세트로 이용하여 학습된 모델일 수있다. 일 실시예로, 청소 로봇은 오브젝트가 촬영된 영상을 제1 인공 지능 모델에 적용하여 오브젝트의 인식 정보를 획득할 수 있다. 제1 인공 지능 모델은 사물을 인식하도록 설정된 인공 지능 모델로서, {오브젝트가 포 함된 영상, 오브젝트의 인식 정보}를 학습 데이터 세트로 이용하여 학습된 모델일 수 있다. 오브젝트의 인식 정 보는, 예로, 오브젝트의 종류, 오브젝트의 크기(예로, 오브젝트의 높이, 오브젝트의 폭, 오브젝트의 깊이 등) 또는 오브젝트의 특징(예로, 오브젝트의 색, 오브젝트의 재질 등) 중 적어도 하나를 획득할 수 있으나 전술한 예에 제한되지는 않는다. 오브젝트의 인식 정보가 획득되면, 청소 로봇은 획득된 오브젝트의 인식 정보를 제2 인공 지능 모델에 적용하여 청소 로봇이 수행할 태스크를 결정할 수 있다. 제2 인공 지능 모델은 청소 로봇이 수행할 태스크를 결정하도록 설정된 인공 지능 모델로서, {오브젝트의 인식 정보, 청소 로봇이 수행 할 태스크}를 학습 데이터 세트로 이용하여 학습된 모델일 수 있다. 일 실시예로, 청소 로봇은 오브젝트가 촬영된 영상을 제1 인공 지능 모델에 적용하여 오브젝트의 인식 정보를 획득할 수 있다. 제1 인공 지능 모델은 사물을 인식하도록 설정된 인공 지능 모델로서, {오브젝트가 포 함된 영상, 오브젝트의 인식 정보}를 학습 데이터 세트로 이용하여 학습된 모델일 수 있다. 오브젝트의 인식 정보가 획득되면, 청소 로봇은 오브젝트의 인식 정보를 룰 기반 모델(rule-based model)(또는, 수학적 모델 (mathematical model))에 적용하여 청소 로봇이 수행할 태스크를 결정할 수 있다. 예로, 청소 로봇은 오브젝트의 종류 별로 청소 로봇이 수행할 태스크가 연결된 매칭 테이블을 저장 중일 수 있다. 이 경우, 청 소 로봇은 매칭 테이블을 이용하여 오브젝트의 인식 정보에 대응되는 청소 로봇의 태스크를 결정할 수 있다. 상기 실시예들에서, 오브젝트가 촬영된 영상을 이용하여 청소 로봇이 수행할 태스크를 결정하도록 설정된 인공 지능 모델, 오브젝트의 인식 정보를 획득하도록 설정된 제1 인공 지능 모델, 및 오브젝트의 인식 정보를 이용하여 청소 로봇이 수행할 태스크를 결정하도록 설정된 제2 인공 지능 모델은, 청소 로봇에 포함되 어 있을 수도 있고, 외부 서버(미도시)에 포함되어 있을 수도 있다. 이러한 인공 지능 모델들은, 예로, 인공 지 능 알고리즘에 기초한 지도 학습(supervised learning) 방식 또는 비지도 학습(unsupervised learning) 방식에 따라 학습된 모델일 수 있다. 인공 지능 모델의 예로, 신경망 모델은 가중치를 가지는 복수의 네트워크 노드들 이 포함되도록 구성될 수 있으며, 복수의 네트워크 노드들은 서로 다른 깊이(또는, 레이어)에 위치하면서 컨볼 루션(convolution) 연결 관계에 따라 데이터를 주고 받을 수 있다. 예컨대, DNN(Deep Neural Network), RNN(Recurrent Neural Network), BRDNN(Bidirectional Recurrent Deep Neural Network) 등이 신경망 모델로서 사용될 수 있으나, 이에 한정되지 않는다. 도 5에 따르면, 오브젝트의 촬영에 기반하여 결정되는 청소 로봇의 태스크의 종류에는 제1 태스크 내지 제6 태스크 중 하나가 될 수 있으나, 다양한 실시예에 따르면, 전술한 태스크들을 포함하여 더 많은 태스크 또는 더 세분화된 태스크를 대상으로 청소 로봇의 태스크가 결정될 수도 있고, 또는 전술한 태스크 의 일부를 대상으로 청소 로봇의 태스크가 결정될 수도 있다. 제1 태스크는 청소 로봇이 오브젝트를 근접 회피하면서 청소를 수행하는 태스크일 수 있다. 근접 회피 주행은, 청소 로봇이 오브젝트와 밀착하여 주행하거나, 오브젝트와 가까운 거리(또는, 임계 값 미만)(예: 1cm 미만) 를 유지하면서 주행하는 것을 의미할 수 있다. 이 경우, 오브젝트는 일 영역에 고정되어 있거나, 이동이 어려운 속성을 가질 수 있다. 예로, 오브젝트는 벽, 소파, 식탁 또는 침대 등이 될 수 있다. 도 6a는 청소 로봇이 오브젝트를 근접 회피하는 태스크의 수행 과정을 나타낸다. 도 6a를 참조하면, 청 소 로봇은 오브젝트와 밀착하여 오브젝트를 회피하면서 주행할 수 있다. 예로, 청소 로봇은 네 비게이션 맵에 포함된 2-D 라인에 기반하여, 오브젝트와 밀착하여 주행할 수 있다. 또는, 청소 로봇은 라이다 센서, 초음파 센서 또는 PSD 센서를 이용하여, 오브젝트까지의 거리 정보를 실시간으로 측정하면서, 오브젝트와 밀착하여 주행할 수 있다. 제2 태스크는 청소 로봇이 오브젝트를 완전 회피하면서 청소를 수행하는 태스크일 수 있다. 완전 회피 주행은, 청소 로봇이 오브젝트와 일정 거리(예: 1cm 이상 15cm 이하)만큼 떨어져 회피하면서 주 행하는 것을 의미할 수 있다. 이 경우, 오브젝트는 깨지기 쉬운 속성을 가질 수 있다. 예로, 오브젝트는 유리컵, 그릇, 병 또는 꽃병 등일 수 있다. 또는, 오브젝트는 가치 있는(valuable) 속성을 가질 수 있다. 예로, 오브젝트는 핸드폰, 귀금속, 시계 또 는 안경 등일 수 있다. 또는, 오브젝트는 오염 가능한 속성을 가질 수 있다. 예로, 오브젝트는 애완동물의 배설 물 또는 음식물 등일 수 있다. 도 6b는 청소 로봇이 오브젝트를 회피하는 태스크의 수행 과정을 나타낸다. 도 6b를 참조하면, 청소 로 봇은 오브젝트와 일정 거리(d2)(예: 1cm 이상 15cm 이하)만큼 떨어져 회피하면서 주행할 수 있다. 이 때, 청소 로봇은 오브젝트의 근처에서 감속하고 오브젝트를 회피하면서 주행할 수 있다. 청소 로봇 은 거리 센서(예: 깊이 센서, 라이다 센서, 초음파 센서, 또는 IR 스테레오 센서 등)를 이용하여 오브젝트 가 위치하는 공간 및 오브젝트까지의 거리 정보를 획득할 수 있다. 청소 로봇은 오브젝트가 위 치하는 공간 및 오브젝트까지의 거리 정보를 실시간으로 측정하면서, 오브젝트로부터 일정 간격만큼 이 격하여 주행할 수 있다. 다른 예로, 청소 로봇은 오브젝트의 주위에 일정 간격만큼 가상의 벽을 셋팅할 수 있다. 그리고, 청소 로봇은 근접 회피를 수행하는 방식으로 가상의 벽에 밀착하여 주행할 수 있다. 제3 태스크는 청소 로봇이 인터랙션을 수행 후에 오브젝트를 회피하면서 청소를 수행하는 태스크일 수 있다. 이 경우, 오브젝트는 인터랙션에 반응할 수 있는 속성을 가질 수 있다. 예로, 오브젝트는 사람의 전신, 사 람의 신체 부위, 동물 또는 센싱 장치 등일 수 있다. 도 6c는, 청소 로봇이 인터렉션 후 오브젝트를 회피하는 태스크의 수행 과정을 나타낸다. 도 6c를 참조하면, 청소 로봇은 오브젝트를 향하여 인터랙션을 수행할 수 있다. 예로, 청소 로봇은 '비켜주 세요'라고 음성을 출력할 수 있다. 청소 로봇의 인터랙션에 반응하여 오브젝트가 이동하면, 청소 로봇 은 거리 센서(예: 깊이 센서, 라이다 센서, 초음파 센서, 또는 IR 스테레오 센서 등)를 이용하여 이동된 오 브젝트가 위치하는 공간 및 오브젝트까지의 거리 정보를 획득할 수 있다. 청소 로봇은 이동된 오브 젝트가 위치하는 공간 및 오브젝트까지의 거리 정보에 기반하여 오브젝트로부터 일정 간격(d3)만큼 떨어져 회피하면서 주행할 수 있다. 제4 태스크는 청소 로봇이 오브젝트를 밀어내면서 청소를 수행하는 태스크일 수 있다. 이 경우, 오브젝트는 청소 로봇이 흡입하지 않고 밀어내야 할 속성을 가질 수 있다. 예로, 오브젝트는 흡입 높이에 대응되는 일정 높이(예: 약 1cm) 보다 높은 크기를 가지거나, 일정 높이 이상의 지점에 무게 중심이 위 치할 수 있다. 오브젝트는 예로, 상자, 인형 또는 쿠션 등이 될 수 있다. 도 6d는 청소 로봇이 오브젝트를 밀어내면서(또는, 가압하면서) 청소하는 태스크의 수행 과정을 나타낸다. 도 6d를 참조하면, 청소 로봇은 오브젝트를 인식하고 오브젝트를 주행 방향으로 이동시킬 수 있다. 청소 로봇은 오브젝트가 위치했던 영역을 청소할 수 있다. 즉, 오브젝트를 이동시키면서 주행 중인 동안에, 청소 로봇은 흡입구를 통하여 주행 중인 바닥면의 먼지를 흡입할 수 있다. 또는, 청소 로봇은 오브젝트를 이동시킨 후에, 오브젝트가 위치했던 바닥 면을 주행하면서 청소할 수 있다. 한편, 바닥 면 의 청소가 완료되면, 청소 로봇은 오브젝트를 원래의 위치로 이동시킬 수도 있다. 이 경우, 청소 로봇 은 오브젝트를 다시 인식하고, 오브젝트를 밀어냈던 방향과 반대 방향으로 오브젝트를 밀어내 어 원래의 위치로 이동시킬 수도 있다. 제5 태스크는 청소 로봇이 오브젝트를 밀어낸 후에, 청소를 수행하는 태스크일 수 있다. 이 경우, 오브젝트는 청소 로봇이 주행 중에 걸릴 수 있는 속성을 가질 수 있다. 오브젝트는, 예로, 전선, 양말 또는 수건 등이 될 수 있다. 또는, 오브젝트는 청소 로봇이 흡입하지 않고 밀어내야 할 속성을 가질 수 있다. 오브젝트는 예로, 장난감 레고, 메모지 또는 알약 등이 될 수 있다. 이 때의, 오브젝트는 흡입 높이에 대응되는 일정 높이(예: 약 1cm) 보다 낮은 크기를 가지거나, 일정 높이 이하의 지점에 무게 중심이 위치할 수 있다. 또는, 오브젝트는 청소 로봇이 주행 중에 걸릴 수 있는 속성을 가질 수 있다. 오브젝트는, 예로, 전선, 양말 또는 수건 등이 될 수 있다. 도 6e 및 도 6f는 청소 로봇이 오브젝트를 밀어낸 후에 청소하는 태스크의 수행 과정을 나타낸다. 일 실시예로, 도 6e의 (a)를 참조하면, 청소 로봇은 오브젝트를 인식하고 청소 로봇에 마련된 가드 부가 하강되도록 제어할 수 있다. 예로, 청소 로봇은 도 1b, 3b 및 도4b와 같이, 가드부가 바닥면 으로 하강되도록 제어할 수 있다. 다음으로, 도 6e의 (b)와 같이, 청소 로봇은 가드부에 의하여 오브젝 트가 이동되도록(또는, 밀리도록) 오브젝트를 향하여 주행할 수 있다. 오브젝트가 이동될 지정된 영역이 존재하는 경우, 청소 로봇은 오브젝트를 지정된 영역까지 이동시킬 수 있다. 지정된 영역은, 예 로, 사용자에 의하여 기 지정된 영역일 수도 있고, 오브젝트로부터 일정 거리만큼 이격된 영역일 수도 있고, 오브젝트 주변의 벽면 또는 거대 구조물일 수도 있다. 청소 로봇이 지정된 영역을 결정하는 예는, 도 7 및 도 8에서 더욱 상세히 설명할 예정이다. 오브젝트가 이동되면, 도 6e의 (c)와 같이, 청소 로봇은 가드부가 다시 상승되도록 제어할 수 있다. 다음으로, 청소 로봇은 가드부가 상승된 상태에서 오브젝트가 위치했던 바닥 면을 주행하면 서 청소할 수 있다. 예로, 청소 로봇은 오브젝트를 가압한 방향의 반대 방향으로 회전 후에, 오브젝트 가 위치했던 영역을 향하여 주행하면서 바닥 면을 청소할 수 있다. 한편, 바닥 면의 청소가 완료되면, 청소 로봇은 오브젝트를 원래의 위치로 이동시킬 수도 있다. 이 경 우, 청소 로봇은 마련된 가드부가 다시 하강되도록 제어하고, 오브젝트를 밀어냈던 방향과 반대 방 향으로 오브젝트를 밀어내어 원래의 위치로 이동시킬 수도 있다. 다른 실시예로, 도 6f의 (a)를 참조하면, 청소 로봇은 오브젝트를 인식하고 청소 로봇에 마련된 가 드부가 하강되도록 제어할 수 있다. 다음으로, 청소 로봇은 오브젝트를 이동시키는 경로를 결정할 수 있다. 먼저, 청소 로봇은 밀기 주행의 시작 위치를 결정할 수 있다. 예로, 청소 로봇은 카메라로 오브 젝트를 촬영한 영상 또는 거리 센서(예: 깊이 센서, 라이다 센서, 초음파 센서 또는 IR 스테레오 센서 등) 를 이용하여 오브젝트의 끝 부분(예: 전선의 끝부분, 오브젝트의 측면 등)의 바로 앞을 시작 위치로서 결정 할 수 있다. 시작 위치가 결정되면, 도 6f의 (b)와 같이, 청소 로봇은 시작 위치로 이동할 수 있다. 다음으 로, 청소 로봇은 오브젝트를 이동시키는 방향을 결정할 수 있다. 예로, 청소 로봇은 청소에 방해가 되 지 않는 방향(또는, 청소 영역이 확보가 되는 방향)으로 오브젝트를 이동시키도록 경로를 결정할 수 있다. 예로, 청소 로봇은 오브젝트의 크기가 최소가 되거나, 오브젝트의 폭이 최소가 되거나, 또는 오브 젝트가 벽에 최대한 밀착하도록 오브젝트를 이동시키는 방향을 결정할 수 있다. 오브젝트를 이동시 키는 경로가 결정되면, 도 6f의 (c)와 같이, 청소 로봇은 결정된 경로를 따라 오브젝트를 향하여 주행 할 수 있다. 오브젝트가 벽에 밀착되면, 도 6f의 (d)와 같이, 청소 로봇은 가드부를 다시 상승시키 고, 가드부가 상승된 상태에서 오브젝트가 위치했던 바닥 면을 주행하면서 청소할 수 있다. 예로, 청소 로봇은 오브젝트를 밀어낸 경로의 반대 경로로 회전 후에, 가드부를 상승시키고 오브젝트가 위 치했던 영역을 향하여 주행하면서 바닥 면을 청소할 수 있다. 제6 테스크는 청소 로봇이 사용자에게 확인을 요청하는 태스크일 수 있다. 이 때, 청소 로봇은 사용자에게 확인 받기 위하여 사용자가 소지한 사용자 단말 장치와 상호 간 통신을 수행할 수 있다. 청소 로봇과 사용자 단말 장치가 상호 간에 통신을 수행한다는 것은, 근거리 통신 기 술로 직접 연결되거나 또는 제3 중계기를 통하여 통신 연결되는 것을 포함할 수 있다. 제3 중계기는, 예로, 기 지국, 허브, 엑세스 포인트, 게이트웨이, 스위치 또는 중계 서버 등을 포함할 수 있다. 도 6g에서, 청소 로봇은 오브젝트를 촬영하고, 촬영된 영상을 학습된 적어도 하나의 인공 지능 모델에 적용할 수 있다. 이 경우, 청소 로봇이 수행할 태스크가 결정될 수 없거나, 청소 로봇이 수행할 태스크 가 복수 개로 결정되거나, 청소 로봇이 수행할 태스크의 컨피던스 값(confidence value)(또는, 확률 값)이 일정 값 이하일 수 있다. 이 경우, 청소 로봇은 청소 로봇이 수행할 태스크를 요청하는 태스크 요청 메 시지를 사용자 단말 장치에게 전송할 수 있다. 태스크 요청 메시지에는 오브젝트가 촬영된 영상에 대 한 정보가 포함될 수 있다. 태스크 확인 메시지를 수신한 사용자 단말 장치는 사용자로부터 태스크를 확인 받기 위한 화면을 표시할 수 있다. 화면에는 청소 로봇에 의하여 촬영된 오브젝트를 포함하는 영상 및 청소 로봇이 수행 가능한 태스크의 목록이 포함될 수 있다. 태스크 목록에는 청소 로봇이 수행 가능한 모든 태스크 들이 포함되거나, 또는 일정 컨피던스 값 이상을 갖는 복수 개의 태스크들이 포함될 수 있다. 태스크의 목록에서 사용자가 일 태스크를 선택하면, 사용자 단말 장치는 선택된 사용자 태스크에 대한 정보를 청소 로봇에게 전송할 수 있다. 청소 로봇은 수신된 정보에 포함된 사용자 태스크를 청소 로봇이 수행할 태스크로서 결정할 수 있다. 청소 로봇은 결정된 태스크에 따라 청소를 수행할 수 있다. 사용자 태스크에 대한 정보를 수신한 청소 로봇은 오브젝트를 촬영한 영상 및 수신된 사용자 태스크를 학습 데이터 세트로 이용하여, 청소 로봇이 수행할 태스크를 결정하도록 설정된 적어도 하나의 인공 지능 모델을 업데이트할 수 있다. 또는, 청소 로봇이 수행할 태스크를 결정하도록 설정된 적어도 하나의 인공 지 능 모델이 서버(미도시)에 위치하는 경우, 청소 로봇은 오브젝트를 촬영한 영상 및 사용자 태스크를 상 기 서버에게 전송할 수 있다. 상기 서버는, 오브젝트를 촬영한 영상 및 수신된 사용자 태스크를 학습 데이 터 세트로 이용하여, 상기 서버에 위치한 청소 로봇이 수행할 태스크를 결정하도록 설정된 적어도 하나의 인공 지능 모델을 업데이트할 수 있다. 이후, 청소 로봇은 촬영된 영상을 적어도 하나의 업데이트된 인공 지능 모델에 적용하여, 청소 로봇이 수행할 태스크를 결정할 수 있다. 예로, 청소 로봇은 도 6g의 오브젝트와 동일 또는 유사한 모양의 오 브젝트를 인식하는 경우, 사용자의 의하여 오브젝트를 대상으로 결정되었던 태스크에 기반하여 청소를 수행 할 수 있다. 일 실시예로, 청소 로봇은 오브젝트가 촬영된 영상에 대응되는 청소 로봇의 태스크가 기 결정된 경우에 도 사용자에게 알리기 위하여, 촬영된 영상을 사용자 단말 장치에게 전송할 수도 있다. 예로, 촬영된 오브 젝트가 계속 방치 시에 위험을 초래하거나, 파손될 수 있거나, 오염물로 판단되는 경우, 청소 로봇은 촬영 된 영상을 사용자 단말 장치에게 제공할 수 있다. 사용자는 촬영된 영상에 기반하여, 오브젝트를 직접 처리 할 수도 있고, 사용자 단말 장치를 통하여 청소 로봇이 오브젝트를 회피하여 주행하거나, 청소 로봇 이 오브젝트를 이동시키도록 제어하는 명령을 청소 로봇에게 제공할 수도 있다. 일 실시예로, 청소 로봇은 오브젝트를 촬영한 정보뿐만 아니라, 적어도 하나의 센서(예: 라이다 센서, 초음 파 센서, IR 스테레오 센서 또는 PSD 센서 등)에서 감지된 센싱 정보를 이용하여 청소 로봇이 수행할 태스 크를 결정할 수 있다. 예로, 청소 로봇은 오브젝트를 촬영한 정보와 상기 감지 정보를 적어도 하나의 인공 지능 모델에 적용하여 청소 로봇이 수행할 태스크를 결정할 수 있다. 또는, 청소 로봇은 오브젝트를 촬영한 정보, 오브젝트의 주변을 촬영한 정보, 오브젝트를 감지한 정보 또는 오브젝트의 주변을 감지한 정보 중 적어도 하나를 이용하여 청소 로봇이 오브젝트를 대상으로 밀기 주행을 시작하는 위치, 이동시키는 경로, 밀기 주 행을 종료하는 위치 등을 결정할 수도 있다. 도 7 및 도 8은 일 실시예에 따른 오브젝트가 이동될 지정 영역을 결정하는 과정을 나타내는 도면이다. 도 7에서, 청소 로봇은 오브젝트를 촬영하고, 촬영된 영상에 따라 청소 로봇이 수행할 태스크를 결 정할 수 있다. 청소 로봇이 수행할 태스크가 도 5의 제4 태스크 또는 제5 태스크와 같이 오브젝 트를 이동시키는 동작을 포함하는 경우, 청소 로봇은 오브젝트가 이동될 영역을 지정할 수 있다. 예로, 청소 로봇은 카메라 또는 거리 센서(예: (예: 깊이 센서, 라이다 센서, 초음파 센서, 또는 IR 스테레 오 센서 등)를 이용하여 오브젝트의 주변 환경을 인식할 수 있다. 오브젝트의 주변 환경에 인식에 따라, 청소 로봇은 오브젝트부터 각각의 구조물들(예: 벽면, 문, 소파와 같은 큰 구조물 등)까지의 거 리 정보 등을 획득할 수 있다. 또는, 청소 로봇은 청소 로봇에 저장된 네비게이션 맵을 이용하여 오브 젝트의 주변의 구조물을 인식하고, 오브젝트부터 각각의 구조물들까지의 거리 정보를 획득할 수 있다. 예로, 청소 로봇은 오브젝트로부터 상하좌우 방향에 위치한 구조물들까지의 최단 거리 정보를 획득할 수 있다. 자세하게, 청소 로봇은 오브젝트부터 상 방향에 위치한 소파까지의 거리 정보, 오브젝트 부터 좌 방향에 위치한 벽면까지의 거리 정보, 오브젝트로부터 우 방향에 위치한 문까지의거리 정보, 오브젝트로부터 하 방향에 위치한 벽면까지의 거리 정보를 획득할 수 있다. 청소 로봇는 획득된 거리 정보들에 기반하여, 오브젝트와 가장 가까운 위치의 구조물을 결정할 수 있다. 도 7에서, 청소 로봇은 오브젝트와 가장 가까운 위치의 구조물로 소파를 선택할 수 있다. 가장 가까운 위치의 구조물이 결정되면, 청소 로봇은 오브젝트를 소파의 전방으로 이동시킬 수 있 다. 도 8에서, 오브젝트가 이동될 지정 영역을 사용자가 직접 지시할 수도 있다. 도 8에서, 청소 로봇은 오브젝트가 이동될 영역을 사용자가 지정하기를 요청하는 영역 지정 요청 메시 지를 사용자 단말 장치에게 전송할 수 있다. 영역 지정 메시지에는 오브젝트가 촬영된 영상에 대 한 정보, 및 맵에 대한 정보를 사용자 단말 장치에게 전송할 수 있다. 맵에 대한 정보는, 예로, 청소 로봇 에 저장된 네비게이션 맵에 대한 정보 또는 시맨틱 맵에 대한 정보를 포함할 수 있다. 영역 지정 요청 메시지를 수신한 사용자 단말 장치는 사용자로부터 영역 지정을 요청 받기 위한 화면을 표 시할 수 있다. 화면에는 청소 로봇에 의하여 촬영된 오브젝트를 포함하는 영상, 오브젝트가 위치한 영역을 포함하는 댁 내의 적어도 일부를 나타내는 맵, 상기 맵 상에서 오브젝트의 위치 를 표시할 수 있다. 이 경우, 맵 상에서 일 영역을 지정하는 사용자 입력이 수신되면, 사용자 단말 장치는 지정된 영 역에 대한 정보를 청소 로봇에게 전송할 수 있다. 청소 로봇은 사용자 단말 장치로부터 수신 된 지정된 영역에 대한 정보에 기반하여, 오브젝트를 사용자에 의해 지정된 영역으로 이동시킬 수 있다 . 도 9a 내지 도 9c는, 일 실시예에 따른 청소 로봇의 주행 계획을 업데이트하는 과정을 나타내는 도면이다. 청소 로봇은, 도 9a와 같이, 댁 내를 대상으로 태스크를 수행하기 위한 주행 경로를 계획하는 글로벌 주행 계획을 설정할 수 있다. 또한, 청소 로봇은, 도 9b 및 도 9c와 같이, 댁 내의 영역 별로 태스크를 수행하기 위한 주행 경로를 계획 하는 로컬 주행 계획을 설정할 수 있다. 글로벌 주행 계획 또는 로컬 주행 계획은, 예로, 청소 로봇의 회전(또는, 턴(turn)) 횟수 또는 이동 거리가 최소화되도록 계획될 수 있다. 예로, 청소 로봇은 주행 방향의 가로 길이 및 세로 길이를 비교하여, 길이가 긴 방향을 우선하여 주행하도록 주행 계획을 설정할 수 있다. 일 실시예로, 도 9b와 같이, 청소 로봇은 댁 내의 일 영역을 대상으로 오브젝트들이 존재하는 상황에서 의 로컬 주행 계획을 설정하여 저장할 수 있다. 상기 상황에서, 청소 로봇은 오브젝트들을 이동시키는 태스크를 수행할 수 있다. 예로, 전술한 도 5의 제4 태스크 또는 제5 태스크와 같이 오브젝트를 이동시키는 태스크를 수행할 수 있다. 오브젝트들이 밀려서 오브젝트들의 위치가 변경되면, 청소 로봇은 로컬 주행 계획을 업데이트할 수 있다. 예로, 청소 로봇은 세로 길이를 우선하여 주행할 때와 가로 길이를 우선할 때의 청소 로봇의 회 전 횟수 또는 이동 거리를 비교하여, 청소 로봇의 회전 횟수 또는 이동 거리가 최소화되도록 로컬 주행 계 획을 업데이트할 수 있다. 예로, 청소 로봇은, 오브젝트들의 위치가 변경되기 전에는 세로 길이를 우선하여 주행하도록 로컬 주행 계획을 설정하였으나, 오브젝트들의 위치가 변경된 후에는, 도 9c와 같이, 가로 길이를 우선하여 주행하도 록 로컬 주행 계획을 설정할 수 있다."}
{"patent_id": "10-2024-0201166", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "item": 2, "content": "도 10a 및 도 10b는 본 개시의 일 실시 예에 따른, 청소 로봇의 구성을 설명하기 위한 간단한 블록도이다. 도 10a 및 도 10b를 참조하면, 청소 로봇은 가드부, 카메라, 메모리, 프로세서 및 구동부로 구성될 수 있다. 가드부의 구성 및 동작은 도 1a 내지 도 4b에서 전술하여 중복되는 설명은 생략한다. 카메라는 청소 로봇의 주변 영상을 다양한 방면으로 촬영할 수 있다. 특히, 카메라는 RGB 카메 라를 통해 청소 로봇의 전면 영상을 촬영할 수도 있고, 주행 방향과 다른 방향에 대한 영상을 촬영할 수도 있다. 카메라는 청소 로봇에 독립적으로 마련될 수도 있고, 사물 인식 센서의 일부로서 사물 인식 센 서에 포함된 카메라가 될 수도 있다. 카메라는 복수의 카메라를 포함하는 구성일 수 있다. 특히 카메라는 청소 로봇의 상방 및 전방 에 모두 설치되어 있을 수도 있고, 상방 및 전방 중 적어도 하나에만 설치되어 있을 수도 있다. 메모리는 카메라가 촬영한 영상 및 촬영 당시의 청소 로봇의 이동 상태 정보 및 촬영 방향정보 를 저장할 수 있다. 또한 메모리는 청소 로봇이 태스크를 수행하기 위한 장소에 대한 맵에 대한 정보 를 저장할 수 있다. 맵에 대한 정보는, 예로, 네비게이션 맵 또는 시맨틱 맵에 대한 정보를 포함할 수 있다. 예로, 청소 로봇은 IR 스테레오 센서, 초음파 센서, 라이다(LIDAR) 센서, PSD 센서 또는 이미지 센서 중 적 어도 하나를 이용하여 태스크 영역을 감지할 수 있다. 청소 로봇은 태스크 영역을 감지한 결과를 이용하여 청소 로봇의 주행을 위한 네비게이션 맵을 생성할 수 있다. 바람직하게는, 청소 로봇은 라이다 센서를 이용하여 2-D(dimension) 형태의 네비게이션 맵을 생성할 수 있다. 네비게이션 맵은, 예로, 하나 이상의 2-D 라인(line) 으로 구획된 댁 내의 영역들을 포함할 수 있다. 다른 예로, 청소 로봇은 오브젝트를 촬영 또는 감지한 결과를 이용하여 오브젝트의 인식 정보를 획득할 수 있다. 청소 로봇은 오브젝트의 인식 정보로서 오브젝트의 명칭, 오브젝트의 종류 또는 오브젝트의 속성 등 을 획득할 수 있다. 청소 로봇은 네비게이션 맵에서 포함된 오브젝트의 영역과 오브젝트의 인식 정보를 매 핑하여, 청소 로봇이 작업을 수행하는 태스크 영역의 환경을 나타내는 시맨틱 맵을 생성할 수 있다. 시맨틱 맵의 오브젝트가 위치한 영역에는 오브젝트의 인식 정보가 텍스트(예: 오브젝트의 명칭) 또는 아이콘으로 표시 될 수 있다. 또는, 시맨틱 맵의 오브젝트가 위치한 영역에는 오브젝트의 인식 정보가 참조 형태로 표시될 수 있 다. 구체적으로, 오브젝트가 위치한 영역을 지시하는 지시선에 대하여 오브젝트의 인식 정보가 표시되거나, 오 브젝트의 영역이 색으로 구분되어 구분된 색을 대상으로 오브젝트의 인식 정보가 표시될 수 있다. 시맨틱 맵에 는, 오브젝트의 인식 정보가, 예로, 태스크 영역의 구조가 반영된 3-D(dimension) 맵 또는 네비게이션 맵(예로: 라이다맵) 중 적어도 하나를 배경으로 표시될 수 있다. 또 다른 예로, 청소 로봇은 태스크 영역을 감지한 결과를 이용하여 태스크 영역의 각 장소들의 인식 정보를 획득할 수 있다. 청소 로봇은 장소의 인식 정보로서 장소의 명칭을 획득할 수 있다. 예로, 청소 로봇은 문이 가장 많이 인식되고, 가장 넓은 구조를 가진 영역을 거실로 인식하고, 차 순위로 넓은 구조를 가진 영역을 침실로 인식할 수 있다. 청소 로봇은 태스크 영역의 각 장소에 위치한 오브젝트의 인식 정보를 이용하여 태 스크 영역의 각 장소들의 인식 정보를 획득할 수도 있다. 예로, 청소 로봇은 식탁이 인식된 영역은 부엌으 로 결정하고, 침대가 인식된 영역은 침실로 인식하고, TV 또는 소파가 인식된 영역은 거실로 인식할 수 있다. 각 장소들의 인식 정보가 획득되면, 청소 로봇은 네비게이션 맵 및 획득된 각 장소들의 인식 정보를 이용하 여 태스크 영역의 환경을 나타내는 시맨틱 맵을 생성할 수 있다. 메모리는 청소 로봇에서 구동되는 다수의 응용 프로그램(application program 또는 애플리케이션 (application)), 청소 로봇의 동작을 위한 데이터들, 인스트럭션들을 저장할 수 있다. 이러한 응용 프로그 램 중 적어도 일부는, 무선 통신을 통해 외부 서버로부터 다운로드 될 수 있다. 또한 이러한 응용 프로그램 중 적어도 일부는, 청소 로봇의 기본적인 기능을 위하여 출고 당시부터 청소 로봇 상에 존재할 수 있다. 응용 프로그램은, 메모리에 저장되고, 프로세서에 의하여 청소 로봇의 동작(또는 기능)을 수행 하도록 구동될 수 있다. 메모리는 비휘발성 메모리, 휘발성 메모리, 플래시메모리(flash-memory), 하드디스크 드라이브(HDD) 또는 솔리드 스테이트 드라이브(SSD) 등으로 구현될 수 있다. 메모리는 프로세서에 의해 액세스 되며, 프로세서에 의한 데이터의 독취/기록/수정/삭제/갱신 등이 수행될 수 있다. 본 개시에서 메모리라는 용어 는 메모리, 프로세서 내 ROM(미도시), RAM(미도시) 또는 청소 로봇 에 장착되는 메모리 카드 (미도시)(예를 들어, micro SD 카드, 메모리 스틱)를 포함할 수 있다. 일 실시예로, 메모리는 프로세서가, 청소 로봇 주변의 오브젝트를 촬영하도록 카메라를 제어하고, 촬영된 영상을 학습된 적어도 하나의 인공 지능 모델에 적용하여 청소 로봇이 수행할 태스크를 결정하고, 결정된 태스크에 따라 청소 로봇의 개구부의 전방에서 바닥 면으로 가드부가 하강되도록 제어하 고, 상기 하강된 가드부에 의하여 상기 오브젝트가 이동되도록, 상기 오브젝트를 향하여 주행하도록 설정된 적 어도 하나의 인스트럭션을 저장할 수 있다. 프로세서는 청소 로봇의 전반적인 구성을 제어할 수 있다. 예를 들어, 프로세서는 청소 로봇 주변의 영상을 촬영하도록 카메라를 제어할 수 있다. 또한, 프로세서는 CPU, 램(RAM), 롬 (ROM), 시스템 버스를 포함할 수 있다. 롬은 시스템 부팅을 위한 인스트럭션 세트가 저장되는 구성이고, CPU는 롬에 저장된 인스트럭션에 따라 청소 로봇의 메모리에 저장된 운영체제를 램에 복사하고, O/S를 실행시켜 시스템을 부팅시킬 수 있다. 부팅이 완료되면, CPU는 메모리에 저장된 각종 애플리케이션을 램에 복사하 고, 실행시켜 각종 동작을 수행할 수 있다. 일 실시예로, 도 10b와 같이, 프로세서은 복수 개의 서브 프로세서들(1041,1042)로 구성될 수도 있다. 복 수 개의 서브 프로세서들(1041,1042)은 CPU(central processing unit) 및 NPU(Neural Processing Unit)를 포함할 수 있다. NPU는 학습된 인공지능 모델을 이용하여 오브젝트를 인식하도록 최적화된 전용 프로세서일 수 있다. 그 밖에, 프로세서는 디지털 신호를 처리하는 디지털 시그널 프로세서(digital signal processor(DSP), 마이크로 프로세서(microprocessor), TCON(Time controller), MCU(Micro Controller Unit), MPU(micro processing unit), 어플리케이션 프로세서(application processor(AP)), 또는 커뮤니케이션 프로세서(communication processor(CP)), ARM 프로세서 중 하나 또는 그 이상을 포함하거나, 해당 용어로 정의 될 수 있다. 프로세서는 프로세싱 알고리즘이 내장된 SoC(System on Chip), LSI(large scale integration)로 구현될 수도 있고, FPGA(Field Programmable gate array) 형태로 구현될 수도 있다. 일 실시예로, 프로세서는 청소 로봇 주변의 오브젝트를 촬영하도록 카메라를 제어할 수 있다. 프로세서는 촬영된 영상을 학습된 적어도 하나의 인공 지능 모델에 적용하여, 청소 로봇이 수행할 태 스크를 결정할 수 있다. 프로세서는 결정된 태스크에 따라 개구부의 전방에서 바닥 면으로 가드부가 하강되도록 구동부를 제어할 수 있다. 가드부가 하강되면, 프로세서는 하강된 가드부에 의하여 촬영된 오브젝트를 이동시키기 위하여 오브젝트를 향하여 주행하도록 구동부를 제어할 수 있다. 일 실시예로, 프로세서는 오브젝트를 이동시키는 경로를 결정하고, 결정된 경로를 따라 청소 로봇이 오브젝트를 향하여 주행하도록 구동부를 제어할 수 있다. 일 실시예로, 프로세서는 오브젝트가 이동된 후에, 가드부가 상승되도록 제어할 수 있다. 그리고, 프로세 서는 오브젝트를 이동시키기 전에, 오브젝트가 위치했던 바닥 면을 주행하도록 구동부를 제어할 수 있다. 일 실시예로, 프로세서는 오브젝트가 촬영된 영상에 대한 정보가 사용자 단말 장치에게 전송되도록 통신부를 제어할 수 있다. 프로세서는 사용자 단말 장치로부터 사용자에 의하여 선택된 사용자 태스크에 대한 정보의 수신에 기반하여, 사용자 태스크를 청소 로봇이 수행할 태스크로서 결정할 수 있다. 이 경우, 프로세서는 오브젝트가 촬영된 영상 및 사용자 단말 장치로부터 수신된 사용자 태스크를 학 습 데이터 세트로서, 적어도 하나의 인공 지능 모델에 적용할 수 있다. 일 실시예로, 프로세서는 오브젝트가 지정된 영역으로 이동되도록 구동부를 제어할 수 있다. 예로, 프로세서는 오브젝트 주변의 복수 개의 구조물들 중에서 오브젝트가 가장 가까운 위치의 구조물을 결정하 고, 오브젝트가 결정된 구조물의 전방으로 이동되도록 구동부를 제어할 수 있다. 또는, 프로세서는 촬영된 영상에 대한 정보, 및 맵에 대한 정보가 사용자 단말 장치에게 전송되도록 통신부를 제어할 수 있다. 사용자 단말 장치로부터 지정된 영역에 대한 정보의 수신에 기반하여, 프로세서는 오브젝트 가 상기 지정된 영역으로 이동되도록 구동부를 제어할 수 있다. 도 11은 본 개시의 일 실시 예에 따른, 청소 로봇의 구성을 설명하기 위한 상세 블록도이다. 도 11을 참조하면, 청소 로봇은 가드부, 센싱부, 카메라, 메모리, 통신부, 집진부, 구동부, 전원부 및 상술한 구성들과 전기적으로 연결되어 제어하는 프로세서 로 구성될 수 있다.가드부, 카메라, 메모리, 프로세서 및 구동부에 대하여는 도 10a 및 도 10b를 대 상으로 이미 설명하였으므로, 중복되는 설명은 생략하도록 한다. 센싱부는 다양한 종류의 센서를 포함할 수 있다. 구체적으로 센싱부는 IR 스테레오 센서, 라이다 (LIDAR) 센서, 초음파 센서 등을 포함할 수 있다. 각각의 IR 스테레오 센서, 라이다(LIDAR) 센서, 초음파 센서 들은 하나의 센서로 구현될 수도 있으나, 각각 별도의 센서로 구현될 수도 있다. IR 스테레오 센서는 오브젝트의 3차원의 형상 및 거리 정보를 센싱할 수 있다. 특히, IR 스테레오 센서는 오브 젝트의 3D depth 정보를 획득할 수 있다. 다만, IR 스테레오 센서는 검정색, 투명색 또는 금속에 대한 센싱이 불가하다는 단점이 있다. 청소 로봇은 라이다(LIDAR) 센서를 이용하여 오브젝트에 대한 2D line 형상 및 거리 정보를 획득할 수 있다. 이를 통해 오브젝트에 대한 공간 및 주변 물체의 거리 정보가 획득될 수 있다. 다만, 라이다 센서는 검정 색, 투명색 또는 금속에 대한 센싱이 어려운 단점이 있다. 초음파 센서는 장애물에 대한 거리정보를 획득할 수 있다. 초음파 센서는 센싱 범위가 상대적으로 제한된다는 단점이 있으나, 검정색, 투명, 금속에 대한 감지가 가능하다는 장점이 있다. 이 외에도 센싱부는 먼지 센서, 냄새 센서, 레이저 센서, UWB 센서, 이미지 센서, 장애물 센서 등과 같은 주변탐지를 위한 센서 및 자이로 센서, GPS 센서 등과 같은 이동상태를 감지하기 위한 센서 등을 포함할 수 있 다. 이때, 주변탐지를 위한 센서와 청소 로봇의 이동상태를 감지하기 위한 센서는 상이한 구성으로 구현될 수도 있고, 하나의 구성으로 구현될 수도 있다. 또한, 센싱부의 각각의 센서는 별도의 구성으로 구현될 수 있 다. 센싱부는 이외에도 다양한 종류의 센서를 더 포함할 수 있으며, 청소 로봇이 수행할 태스크에 따 라 도시된 센서 중 일부는 포함하지 않을 수도 있다. 통신부는 외부 장치와 데이터, 제어 커맨드 등을 송수신할 수 있다. 예를 들어, 통신부는 외부 장 치로부터 청소 로봇이 동작할 공간에 대한 위치 정보를 포함하는 맵에 대한 정보를 수신할 수 있다. 또한, 통신부는 외부 장치로 맵에 대한 정보를 갱신하기 위한 정보를 송신할 수 있다. 다른 예로, 통신부(105 0)는 사용자가 원격제어장치를 이용하여 송신한 청소 로봇을 제어하기 위한 신호를 수신할 수 있다. 이때 원격제어장치는 리모컨, 사용자 단말 장치 등 다양한 형태로 구현될 수 있다. 또한 통신부는 외부 서버(미도시)와 데이터 등을 송수신할 수 있다. 예를 들어 외부 서버에 인공 지능 모 델이 저장되어 있는 경우, 통신부는 외부 서버로 카메라를 통해 촬영된 영상을 송신할 수 있고, 외 부 서버로부터 인공 지능 모델을 이용하여 인식된 촬영된 영상에 포함된 오브젝트의 인식 정보를 수신할 수 있 다. 이는 일 실시 예에 불과하며, 통신부는 외부 서버로부터 청소 로봇이 태스크를 수행할 공간에 대 한 이동 가능 영역에 대한 정보를 수신할 수도 있다. 한편, 통신부는 루투스, WiFi direct 또는 IrDA(infrared data association) 같은 근거리 통신 네트워크, 또는 셀룰러 네트워크, 인터넷, 또는 컴퓨터 네트워크(예: LAN 또는 WAN)와 같은 원거리 통신 네트워 크를 통하여 외부 전자 장치와 통신할 수 있다. 집진부는 먼지를 집진하기 위한 구성이다. 구체적으로, 집진부는 공기를 흡입하고, 흡입된 공기 중 의 먼지를 집진할 수 있다. 예를 들어, 집진부는 흡입구에서 배출구까지 이어지는 가이드 배관을 통해 공 기를 통과시키는 모터와 흡입된 공기 중의 먼지를 거르는 필터 및 걸려진 먼지를 담는 먼지통 등을 포함할 수 있다. 구동부는 청소 로봇을 구동시킬 수 있다. 예를 들어, 구동부는 프로세서의 제어에 의해 태스크를 수행할 위치로 청소 로봇을 이동시킬 수 있다. 이러한 경우에, 구동부는 바닥면과 접촉하는 적어도 하나의 바퀴, 바퀴에 동력을 제공하는 모터 및 모터를 제어할 드라이버를 포함할 수 있다. 다른 예로, 구동부는 태스크를 수행하기 위한 동작을 구현할 수 있다. 예로, 구동부는 가드가 상향 또는 하향되도록 동력을 전달하기 위한 모터 및 회전 축을 포함할 수 있다. 예로, 구동부는 프로세서의 제어 커맨드에 따라 모터를 제어하여 가드를 상향 또는 하향시킬 수 있다. 제어 커맨드는 예로, 모터의 회 전 방향, 회전 속도, 인가 전력에 관한 정보 등을 포함할 수 있다.전원부는 청소 로봇의 구동에 필요한 전원을 공급한다. 예를 들어, 전원부는 충방전이 가능한 배 터리로 구현될 수 있다. 프로세서는 청소 로봇의 잔여 전원이 기설정된 레벨 이하로 떨어진 경우, 또 는 태스크를 완료한 경우에 충전 스테이션으로 이동하도록 구동부를 제어할 수 있다. 전원부의 충 전 방식은 접촉식 및 비접촉식 충전이 모두 가능하다. 도 12a 및 도 12b는, 일 실시예에 따른 학습부 및 인식부를 나타내는 블록도이다. 도 12a를 참조하면, 프로세서는 학습부 및 인식부 중 적어도 하나를 포함할 수 있다. 도 12a 의 프로세서는 도 10a, 도 10b및 도 11의 청소 로봇의 프로세서에 대응될 수도 있고, 또는 청 소 로봇과 통신 가능한 외부의 서버(미도시)의 프로세서에 대응될 수 있다. 학습부는 소정의 상황 판단을 위한 기준을 갖는 인공 지능 모델을 생성 또는 학습시킬 수 있다. 학습부 는 수집된 학습 데이터를 이용하여 판단 기준을 갖는 인공 지능 모델을 생성할 수 있다. 일 예로, 학습부 는 오브젝트가 포함된 영상을 학습 데이터로서 이용하여 영상에 포함된 오브젝트가 어떤 것인지 판단하는 기준을 갖는 인공 지능 모델을 생성, 학습 또는 갱신시킬 수 있다. 또 다른 예로, 학습부는 오브젝트가 포함된 화면에 포함된 주변 정보를 학습 데이터로서 이용하여 영상에 포함된 오브젝트 주변에 다양한 추가 정보 를 판단하는 기준을 갖는 인공 지능 모델을 생성, 학습 또는 갱신시킬 수 있다. 또 다른 예로, 학습부는 카메라에 의해 촬영된 영상을 학습 데이터로서 이용하여 영상에 포함된 오브젝트를 판단하는 기준을 갖는 인공 지능 모델을 생성, 학습 또는 갱신시킬 수 있다. 또 다른 예로, 학습부는 {오브젝트가 포함된 영상, 오브 젝트의 인식 정보}를 학습 데이터 세트으로 이용하여 사물을 인식하도록 설정된 인공 지능 모델을 생성, 학습 또는 갱신시킬 수 있다. 또 다른 예로, 학습부는 {오브젝트의 인식 정보, 청소 로봇이 수행할 태스크}를 학습 데이터 세트로 이용하여 청소 로봇이 수행할 태스크를 결정하도록 설정된 인공 지능 모델을 생성, 학 습 또는 갱신시킬 수 있다. 또 다른 예로, 학습부는 {오브젝트가 포함된 영상, 청소 로봇이 수행할 태스 크}를 학습 데이터 세트로 이용하여 청소 로봇이 수행할 태스크를 결정하도록 설정된 인공 지능 모델을 생 성, 학습 또는 갱신시킬 수 있다. 인식부는 소정의 데이터를 학습된 인공 지능 모델의 입력 데이터로 사용하여, 소정의 데이터에 포함된 인 식 대상을 추정할 수 있다. 일 예로, 인식부는 오브젝트가 포함된 오브젝트 영상을 학습된 인공 지능 모델의 입력 데이터로 사용하여 영상에 포함된 오브젝트에 대한 오브젝트 인식 정보를 획득(또는, 추정, 추론)할 수 있다. 또 다른 예로, 인식 부는 오브젝트가 촬영된 영상을 학습된 적어도 하나의 인공 지능 모델에 적용하여 청소 로봇이 수행 할 태스크를 결정할 수 있다. 또 다른 예로, 인식부는, 오브젝트의 인식 정보를 적어도 하나의 인공 지능 모델에 적용하여 청소 로봇이 수행할 태스크를 결정할 수 있다. 학습부의 적어도 일부 및 인식부의 적어도 일부는, 소프트웨어 모듈로 구현되거나 적어도 하나의 하드웨어 칩 형태로 제작되어 전자 장치에 탑재될 수 있다. 예를 들어, 학습부 및 인식부 중 적어 도 하나는 인공 지능(AI; artificial intelligence)을 위한 전용 하드웨어 칩 형태로 제작될 수도 있고, 또는 기존의 범용 프로세서(예: CPU 또는 application processor) 또는 그래픽 전용 프로세서(예: GPU)의 일부로 제 작되어 전술한 청소 로봇에 탑재될 수도 있다. 이 때, 인공 지능을 위한 전용 하드웨어 칩은 확률 연산에 특화된 전용 프로세서로서, 기존의 범용 프로세서보다 병렬처리 성능이 높아 기계 학습과 같은 인공 지능 분야 의 연산 작업을 빠르게 처리할 수 있다. 학습부 및 인식부가 소프트웨어 모듈(또는, 인스트럭션 (instruction) 포함하는 프로그램 모듈)로 구현되는 경우, 소프트웨어 모듈은 컴퓨터로 읽을 수 있는 판독 가능 한 비일시적 판독 가능 기록매체(non-transitory computer readable media)에 저장될 수 있다. 이 경우, 소프 트웨어 모듈은 OS(Operating System)에 의해 제공되거나, 소정의 애플리케이션에 의해 제공될 수 있다. 또는, 소프트웨어 모듈 중 일부는 OS(Operating System)에 의해 제공되고, 나머지 일부는 소정의 애플리케이션에 의해 제공될 수 있다. 이 경우, 학습부 및 인식부는 하나의 전자 장치에 탑재될 수도 있으며, 또는 별개의 전자 장치들 에 각각 탑재될 수도 있다. 예를 들어, 학습부 및 인식부 중 하나는 청소 로봇에 포함되고, 나 머지 하나는 외부의 서버에 포함될 수 있다. 또한, 학습부 및 인식부는 유선 또는 무선으로 통하여, 학습부가 구축한 모델 정보를 인식부로 제공할 수도 있고, 인식부로 입력된 데이터가 추가 학습 데이터로서 학습부로 제공될 수도 있다. 도 12b는, 일 실시예에 따른 학습부 및 인식부의 블록도이다. 도 12b의 (a)를 참조하면, 일부 실시예에 따른 학습부는 학습 데이터 획득부(1110-1) 및 모델 학습부 (1110-4)를 포함할 수 있다. 또한, 학습부는 학습 데이터 전처리부(1110-2), 학습 데이터 선택부(1110-3) 및 모델 평가부(1110-5) 중 적어도 하나를 선택적으로 더 포함할 수 있다. 학습 데이터 획득부(1110-1)는 인식 대상을 추론하기 위한 인공 지능 모델에 필요한 학습 데이터를 획득할 수 있다. 본 문서의 실시예로, 학습 데이터 획득부(1110-1)는 오브젝트를 포함하는 전체 영상, 오브젝트에 대응되 는 영역에 대응하는 영상 등을 학습 데이터로서 획득할 수 있다. 학습 데이터는 학습부 또는 학습부 의 제조사가 수집 또는 테스트한 데이터가 될 수도 있다. 모델 학습부(1110-4)는 학습 데이터를 이용하여, 인공 지능 모델이 소정의 인식 대상을 어떻게 판단할 지에 관 한 판단 기준을 갖도록 학습시킬 수 있다. 예로, 모델 학습부(1110-4)는 학습 데이터 중 적어도 일부를 판단 기 준으로 이용하는 지도 학습(supervised learning)을 통하여, 인공 지능 모델을 학습시킬 수 있다. 또는, 모델 학습부(1110-4)는, 예를 들어, 별다른 지도 없이 학습 데이터를 이용하여 스스로 학습함으로써, 상황의 판단을 위한 판단 기준을 발견하는 비지도 학습(unsupervised learning)을 통하여, 인공 지능 모델을 학습시킬 수 있다. 또한, 모델 학습부(1110-4)는, 예를 들어, 학습에 따른 상황 판단의 결과가 올바른 지에 대한 피드백을 이용하는 강화 학습(reinforcement learning)을 통하여, 인공 지능 모델을 학습시킬 수 있다. 또한, 모델 학습 부(1110-4)는, 예를 들어, 오류 역전파법(error back-propagation) 또는 경사 하강법(gradient descent)을 포 함하는 학습 알고리즘 등을 이용하여 인공 지능 모델을 학습시킬 수 있다 또한, 모델 학습부(1110-4)는 입력 데이터를 이용하여 인식 대상을 추정하기 위하여 어떤 학습 데이터를 이용해 야 하는 지에 대한 선별 기준을 학습할 수도 있다. 모델 학습부(1110-4)는 미리 구축된 인공 지능 모델이 복수 개가 존재하는 경우, 입력된 학습 데이터와 기본 학 습 데이터의 관련성이 큰 인공 지능 모델을 학습할 인공 지능 모델로 결정할 수 있다. 이 경우, 기본 학습 데이 터는 데이터의 타입 별로 기 분류되어 있을 수 있으며, 인공 지능 모델은 데이터의 타입 별로 미리 구축되어 있 을 수 있다. 예를 들어, 기본 학습 데이터는 학습 데이터가 생성된 지역, 학습 데이터가 생성된 시간, 학습 데 이터의 크기, 학습 데이터의 장르, 학습 데이터의 생성자, 학습 데이터 내의 오브젝트의 종류 등과 같은 다양한 기준으로 기 분류되어 있을 수 있다. 인공 지능 모델이 학습되면, 모델 학습부(1110-4)는 학습된 인공 지능 모델을 저장할 수 있다. 이 경우, 모델 학습부(1110-4)는 학습된 인공 지능 모델을 청소 로봇의 메모리에 저장할 수 있다. 또는, 모델 학습부 (1110-4)는 학습된 인공 지능 모델을 청소 로봇와 유선 또는 무선 네트워크로 연결되는 서버의 메모리에 저 장할 수도 있다. 학습부는 인공 지능 모델의 분석 결과를 향상시키거나, 인공 지능 모델의 생성에 필요한 자원 또는 시간 을 절약하기 위하여, 학습 데이터 전처리부(1110-2) 및 학습 데이터 선택부(1110-3)를 더 포함할 수도 있다. 학습 데이터 전처리부(1110-2)는 상황 판단을 위한 학습에 획득된 데이터가 이용될 수 있도록, 획득된 데이터를 전처리할 수 있다. 학습 데이터 전처리부(1110-2)는 모델 학습부(1110-4)가 상황 판단을 위한 학습을 위하여 획 득된 데이터를 이용할 수 있도록, 획득된 데이터를 기 설정된 포맷으로 가공할 수 있다. 학습 데이터 선택부(1110-3)는 학습 데이터 획득부(1110-1)에서 획득된 데이터 또는 학습 데이터 전처리부 (1110-2)에서 전처리된 데이터 중에서 학습에 필요한 데이터를 선택할 수 있다. 선택된 학습 데이터는 모델 학 습부(1110-4)에 제공될 수 있다. 학습 데이터 선택부(1110-3)는 기 설정된 선별 기준에 따라, 획득되거나 전처 리된 데이터 중에서 학습에 필요한 학습 데이터를 선택할 수 있다. 또한, 학습 데이터 선택부(1110-3)는 모델 학습부(1110-4)에 의한 학습에 의해 기 설정된 선별 기준에 따라 학습 데이터를 선택할 수도 있다. 학습부는 데이터 인공 지능 모델의 분석 결과를 향상시키기 위하여, 모델 평가부(1110-5)를 더 포함할 수 도 있다. 모델 평가부(1110-5)는 인공 지능 모델에 평가 데이터를 입력하고, 평가 데이터로부터 출력되는 분석 결과가 소 정 기준을 만족하지 못하는 경우, 모델 학습부(1110-4)로 하여금 다시 학습하도록 할 수 있다. 이 경우, 평가데이터는 인공 지능 모델을 평가하기 위한 기 정의된 데이터일 수 있다. 예를 들어, 모델 평가부(1110-5)는 평가 데이터에 대한 학습된 인공 지능 모델의 분석 결과 중에서, 분석 결과 가 정확하지 않은 평가 데이터의 개수 또는 비율이 미리 설정된 임계치를 초과하는 경우 소정 기준을 만족하지 못한 것으로 평가할 수 있다. 한편, 학습된 인공 지능 모델이 복수 개가 존재하는 경우, 모델 평가부(1110-5)는 각각의 학습된 인공 지능 모 델에 대하여 소정 기준을 만족하는지를 평가하고, 소정 기준을 만족하는 모델을 최종 인공 지능 모델로서 결정 할 수 있다. 이 경우, 소정 기준을 만족하는 모델이 복수 개인 경우, 모델 평가부(1110-5)는 평가 점수가 높은 순으로 미리 설정된 어느 하나 또는 소정 개수의 모델을 최종 인공 지능 모델로서 결정할 수 있다. 도 12b의 (b)를 참조하면, 일부 실시예에 따른 인식부는 인식 데이터 획득부(1120-1) 및 인식 결과 제공 부(1120-4)를 포함할 수 있다. 또한, 인식부는 인식 데이터 전처리부(1120-2), 인식 데이터 선택부(1120-3) 및 모델 갱신부(1120-5) 중 적어도 하나를 선택적으로 더 포함할 수 있다. 인식 데이터 획득부(1120-1)는 상황 판단에 필요한 데이터를 획득할 수 있다. 인식 결과 제공부(1120-4)는 인식 데이터 획득부(1120-1)에서 획득된 데이터를 입력 값으로 학습된 인공 지능 모델에 적용하여 상황을 판단할 수 있다. 인식 결과 제공부(1120-4)는 데이터의 분석 목적에 따른 분석 결과를 제공할 수 있다. 인식 결과 제공부 (1120-4)는 후술할 인식 데이터 전처리부(1120-2) 또는 인식 데이터 선택부(1120-3)에 의해 선택된 데이터를 입 력 값으로 인공 지능 모델에 적용하여 분석 결과를 획득할 수 있다. 분석 결과는 인공 지능 모델에 의해 결정될 수 있다. 일 예로, 인식 결과 제공부(1120-4)는 인식 데이터 획득부(1120-1)에서 획득한 오브젝트가 촬영된 영상을 학습 된 적어도 하나의 인공 지능 모델 적용하여 오브젝트의 인식 정보를 획득(또는, 추정)할 수 있다. 다른 예로, 인식 결과 제공부(1120-4)는 인식 데이터 획득부(1120-1)에서 획득한 오브젝트가 촬영된 영상을 학습된 적어도 하나의 인공 지능 모델에 적용하여 청소 로봇이 수행할 태스크를 결정할 수 있다. 또 다른 예로, 인식 결과 제공부(1120-4)는 인식 데이터 획득부(1120-1)에서 획득한 오브젝트의 인식 정보를 적어도 하나의 인공 지능 모 델에 적용하여 청소 로봇이 수행할 태스크를 결정할 수 있다. 인식부는 인공 지능 모델의 분석 결과를 향상시키거나, 분석 결과의 제공을 위한 자원 또는 시간을 절약 하기 위하여, 인식 데이터 전처리부(1120-2) 및 인식 데이터 선택부(1120-3)를 더 포함할 수도 있다. 인식 데이터 전처리부(1120-2)는 상황 판단을 위해 획득된 데이터가 이용될 수 있도록, 획득된 데이터를 전처리 할 수 있다. 인식 데이터 전처리부(1120-2)는 인식 결과 제공부(1120-4)가 상황 판단을 위하여 획득된 데이터를 이용할 수 있도록, 획득된 데이터를 기 정의된 포맷으로 가공할 수 있다. 인식 데이터 선택부(1120-3)는 인식 데이터 획득부(1120-1)에서 획득된 데이터 또는 인식 데이터 전처리부 (1120-2)에서 전처리된 데이터 중에서 상황 판단에 필요한 데이터를 선택할 수 있다. 선택된 데이터는 인식 결 과 제공부(1120-4)에게 제공될 수 있다. 인식 데이터 선택부(1120-3)는 상황 판단을 위한 기 설정된 선별 기준 에 따라, 획득되거나 전처리된 데이터 중에서 일부 또는 전부를 선택할 수 있다. 또한, 인식 데이터 선택부 (1120-3)는 모델 학습부(1110-4)에 의한 학습에 의해 기 설정된 선별 기준에 따라 데이터를 선택할 수도 있다. 모델 갱신부(1120-5)는 인식 결과 제공부(1120-4)에 의해 제공되는 분석 결과에 대한 평가에 기초하여, 인공 지 능 모델이 갱신되도록 제어할 수 있다. 예를 들어, 모델 갱신부(1120-5)는 인식 결과 제공부(1120-4)에 의해 제 공되는 분석 결과를 모델 학습부(1110-4)에게 제공함으로써, 모델 학습부(1110-4)가 인공 지능 모델을 추가 학 습 또는 갱신하도록 요청할 수 있다. 일 실시예로, 학습부는 서버(미도시)에 위치하고 인식부는 청소 로봇에 위치할 수 있다. 이 경 우, 청소 로봇 및 서버가 서로 연동함으로써 데이터를 학습하고 인식할 수 있다. 예로, 서버는 상황 판단을 위한 기준을 학습할 수 있으며, 청소 로봇는 서버에 의한 학습 결과에 기초하여 상황을 판단할 수 있다. 이 경우, 서버의 모델 학습부(1110-4)는 소정의 상황을 판단하기 위하여 어떤 오브젝트 영상을 이용할 지, 상기 데이터를 이용하여 상황을 어떻게 판단할 지에 관한 기준을 학습할 수 있다. 또한, 청소 로봇의 인식 결과 제공부(1120-4)는 인식 데이터 선택부(1120-3)에 의해 선택된 데이터를 서버 에서 생성된 인공 지능 모델에 적용하여 오브젝트 인식 정보 또는 청소 로봇이 수행할 태스크를 결정할 수 있다. 또는, 청소 로봇의 인식 결과 제공부(1120-4)는 서버에 의해 생성된 인공 지능 모델을 서버로부터 수 신하고, 수신된 인공 지능 모델을 이용하여 상황을 판단할 수 있다. 이 경우, 청소 로봇의 인식 결과 제공 부(1120-4)는 인식 데이터 선택부(1120-3)에 의해 선택된 오브젝트 영상을 서버로부터 수신된 인공 지능 모델에 적용하여, 오브젝트 인식 정보 또는 청소 로봇이 수행할 태스크를 결정할 수 있다. 도 13은 본 개시의 일 실시예에 따른 청소 로봇이 태스크를 수행하는 흐름도이다. 먼저, 청소 로봇은 청소 로봇 주변의 오브젝트를 촬영할 수 있다. 청소 로봇은 촬영된 영상을 학습된 적어도 하나의 인공 지능 모델에 적용하여, 청소 로봇이 수행할 태 스크를 결정할 수 있다. 예로, 청소 로봇은 촬영된 영상을 학습된 제1 인공 지능 모델에 적용하여, 오브젝트의 인식 정보를 획득할 수 잇다. 청소 로봇은 획득된 오브젝트의 인식 정보를 제2 인공 지능 모델 에 적용하여 청소 로봇이 수행할 태스크를 결정할 수 있다. 태스크가 결정되면, 청소 로봇은 결정된 태스크에 따라 청소 로봇의 개구부의 전방에서 바닥 면으로 가 드부가 하강되도록 제어할 수 있다. 가드부가 하강되면, 청소 로봇은 하강된 가드부에 의하여 오브젝트가 이동되도록, 오브젝트를 향하여 주행 할 수 있다. 일 실시예로, 청소 로봇은 오브젝트를 이동시키는 경로를 결정할 수 있다. 청소 로봇은 결정된 경로를 따라 오브젝트를 향하여 주행할 수 있다. 일 실시예로, 청소 로봇은 오브젝트가 이동된 후에, 가드부가 상승되도록 제어할 수 있다. 그리고, 청소 로 봇은 오브젝트가 이동되기 전에, 오브젝트가 위치했던 바닥 면을 주행할 수 있다. 일 실시예로, 청소 로봇은 오브젝트가 촬영된 영상에 대한 정보를 사용자 단말 장치에게 전송할 수 있 다. 사용자 단말 장치로부터 사용자에 의하여 선택된 사용자 태스크에 대한 정보를 수신되면, 청소 로봇 은 사용자 태스크를 청소 로봇이 수행할 태스크로서 결정할 수 있다. 이 경우, 청소 로봇은 오브젝 트가 촬영된 영상 및 사용자 단말 장치로부터 수신된 사용자 태스크를 학습 데이터 세트로서, 적어도 하나의 인 공 지능 모델에 적용할 수 있다. 일 실시예로, 청소 로봇은 오브젝트를 지정된 영역으로 이동시킬 수 있다. 일 예로, 청소 로봇은 오브 젝트의 주변의 복수 개의 구조물들 중에서 오브젝트와 가장 가까운 위치의 구조물을 결정할 수 있다. 청소 로봇 은 오브젝트를 결정된 구조물의 전방으로 이동시킬 수 있다. 다른 예로, 청소 로봇은 촬영된 영상에 대 한 정보 및 맵에 대한 정보를 사용자 단말 장치에게 전송할 수 있다. 이에 대한 응답으로, 청소 로봇은 사용자 단말 장치로부터 지정된 영역에 대한 정보를 수신할 수 있다. 지정된 영역에 대한 정보를 수신한 청 소 로봇은 오브젝트를 지정된 영역으로 이동시킬 수 있다. 일 실시예로, 청소 로봇은 오브젝트가 위치한 영역에 대하여 청소 로봇이 주행할 로컬 주행 계획을 저 장할 수 있다. 오브젝트가 이동된 후에, 청소 로봇은 로컬 주행 계획을 업데이트할 수 있다. 본 개시의 다양한 실시예들은, 이동 장치에서도 구현될 수 있다. 이동 장치는, 예로, 공공 장소용 서비스 로봇, 생산 현장에서의 반송 로봇, 작업자 지원 로봇, 가사용 로봇, 보안 로봇 또는 자율주행 차량 등 다양한 형태가 가능할 수 있다. 본 개시에서 사용된 용어 \"모듈\"은 하드웨어, 소프트웨어 또는 펌웨어로 구현된 유닛을 포함할 수 있으며, 예를 들면, 로직, 논리 블록, 부품, 또는 회로 등의 용어와 상호 호환적으로 사용될 수 있다. 모듈은, 일체로 구성된 부품 또는 하나 또는 그 이상의 기능을 수행하는, 상기 부품의 최소 단위 또는 그 일부가 될 수 있다. 예를 들 면, 일 실시예에 따르면, 모듈은 ASIC(application-specific integrated circuit)의 형태로 구현될 수 있다. 본 개시의 다양한 실시예들은 기기(machine)(예: 청소 로봇, 청소 로봇과 통신 가능한 서버(미도시))에 의해 읽을 수 있는 저장 매체(storage medium)(예: 메모리, 서버의 메모리(미도시))에 저장된 하나 이상의 인스트럭션(instruction)들을 포함하는 소프트웨어(예: 프로그램)로서 구현될 수 있다. 예를 들면, 기기의 프로세서(예: 프로세서, 서버의 프로세서(미도시))는, 저장 매체로부터 저장된 하나 이상의 인스트럭션들 중 적어도 하나의 명령을 호출하고, 그것을 실행할 수 있다. 이것은 기기가 상기 호출된 적어도 하나의 인스트 럭션에 따라 적어도 하나의 기능을 수행하도록 운영되는 것을 가능하게 한다. 상기 하나 이상의 인스트럭션들은 컴파일러에 의해 생성된 코드 또는 인터프리터에 의해 실행될 수 있는 코드를 포함할 수 있다. 기기로 읽을 수 있는 저장매체는, 비일시적(non-transitory) 저장매체의 형태로 제공될 수 있다. 여기서, '비일시적'은 저장매 체가 실재(tangible)하는 장치이고, 신호(signal)(예: 전자기파)를 포함하지 않는다는 것을 의미할 뿐이며, 이 용어는 데이터가 저장매체에 반영구적으로 저장되는 경우와 임시적으로 저장되는 경우를 구분하지 않는다. 일 실시예에 따르면, 본 개시에 개시된 다양한 실시예들에 따른 방법은 컴퓨터 프로그램 제품(computer program product)에 포함되어 제공될 수 있다. 컴퓨터 프로그램 제품은 상품으로서 판매자 및 구매자 간에 거래될 수 있 다. 컴퓨터 프로그램 제품은 기기로 읽을 수 있는 저장 매체(예: compact disc read only memory (CD-ROM))의 형태로 배포되거나, 또는 어플리케이션 스토어(예: 플레이 스토어TM)를 통해 또는 두 개의 사용자 장치들(예: 스마트폰들) 간에 직접, 온라인으로 배포(예: 다운로드 또는 업로드)될 수 있다. 온라인 배포의 경우에, 컴퓨터 프로그램 제품의 적어도 일부는 제조사의 서버, 어플리케이션 스토어의 서버, 또는 중계 서버의 메모리와 같은 기기로 읽을 수 있는 저장 매체에 적어도 일시 저장되거나, 임시적으로 생성될 수 있다. 다양한 실시예들에 따르면, 상기 기술한 구성요소들의 각각의 구성요소(예: 모듈 또는 프로그램)는 단수 또는 복수의 개체를 포함할 수 있다. 다양한 실시예들에 따르면, 전술한 해당 구성요소들 중 하나 이상의 구성요소들 또는 동작들이 생략되거나, 또는 하나 이상의 다른 구성요소들 또는 동작들이 추가될 수 있다. 대체적으로 또는 추가적으로, 복수의 구성요소들(예: 모듈 또는 프로그램)은 하나의 구성요소로 통합될 수 있다. 이런 경우, 통 합된 구성요소는 상기 복수의 구성요소들 각각의 구성요소의 하나 이상의 기능들을 상기 통합 이전에 상기 복수 의 구성요소들 중 해당 구성요소에 의해 수행되는 것과 동일 또는 유사하게 수행할 수 있다. 다양한 실시예들에 따르면, 모듈, 프로그램 또는 다른 구성요소에 의해 수행되는 동작들은 순차적으로, 병렬적으로, 반복적으로, 또는 휴리스틱하게 실행되거나, 상기 동작들 중 하나 이상이 다른 순서로 실행되거나, 생략되거나, 또는 하나 이상의 다른 동작들이 추가될 수 있다."}
{"patent_id": "10-2024-0201166", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1a 내지 도 4b는 본 개시의 일 실시예에 따른 청소 로봇의 구조를 나타내는 도면들이다. 도 5는 본 개시의 일 실시예에 따른, 청소 로봇이 오브젝트를 인식하여 태스크를 결정하는 과정을 나타내는 도 면이다. 도 6a 내지 도 6g는 본 개시의 일 실시예에 따른 청소 로봇이 태스크를 수행하는 과정을 나타내는 도면들이다. 도 7 및 도 8은 일 실시예에 따른 오브젝트가 이동될 지정 영역을 결정하는 과정을 나타내는 도면이다. 도 9a 내지 도 9c는, 본 개시의 일 실시예에 따른 청소 로봇의 주행 계획을 업데이트하는 과정을 나타내는 도면 이다. 도 10a 및 도 10b는 본 개시의 일 실시예에 따른, 청소 로봇의 구성을 설명하기 위한 간단한 블록도들이다. 도 11은 본 개시의 일 실시 예에 따른, 청소 로봇의 구성을 설명하기 위한 상세 블록도이다. 도 12a 및 도 12b는, 본 개시의 일 실시예에 따른 학습부 및 인식부를 나타내는 블록도들이다. 도 13은 본 개시의 일 실시예에 따른 청소 로봇이 태스크를 수행하는 흐름도이다."}
