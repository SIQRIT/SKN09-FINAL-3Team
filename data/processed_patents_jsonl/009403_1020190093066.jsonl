{"patent_id": "10-2019-0093066", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2021-0014949", "출원번호": "10-2019-0093066", "발명의 명칭": "음성 인식을 위한 인공신경망에서의 디코딩 방법 및 장치", "출원인": "삼성전자주식회사", "발명자": "이민중"}}
{"patent_id": "10-2019-0093066", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "음성 인식(speech recognition)을 위한 인공신경망에서의 디코딩 방법에 있어서,상기 인공신경망에 포함된 공유 디코딩 레이어(shared decoding layer)를 이용하여, 음성 정보를 내포하는 특징및 현재까지 인식된 적어도 하나의 토큰을 디코딩하는 제1 디코딩 태스크를 수행하는 단계;상기 공유 디코딩 레이어를 이용하여, 상기 적어도 하나의 토큰을 디코딩하는 제2 디코딩 태스크를 수행하는 단계; 및상기 제1 디코딩 태스크의 결과 및 상기 제2 디코딩 태스크의 결과에 기초하여, 상기 적어도 하나의 토큰 이후로 인식되는 출력 토큰을 결정하는 단계를 포함하는 디코딩 방법."}
{"patent_id": "10-2019-0093066", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 제1 디코딩 태스크를 수행하는 단계는상기 특징에 대응하는 뉴런과 상기 공유 디코딩 레이어를 연결하는 시냅스(synapse)의 가중치를 제1 값으로 조절하는 단계를 포함하고,상기 제2 디코딩 태스크를 수행하는 단계는상기 시냅스의 가중치를 제2 값으로 조절하는 단계를 포함하는, 디코딩 방법."}
{"patent_id": "10-2019-0093066", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,제1 디코딩 태스크를 수행하는 단계는상기 특징 및 상기 현재까지 인식된 적어도 하나의 토큰을 상기 공유 디코딩 레이어에 입력하여 상기 제1 디코딩 태스크를 수행하는 단계를 포함하고,상기 제2 디코딩 태스크를 수행하는 단계는상기 현재까지 인식된 적어도 하나의 토큰을 상기 공유 디코딩 레이어에 입력하여 상기 제2 디코딩 태스크를 수행하는 단계를 포함하는, 디코딩 방법."}
{"patent_id": "10-2019-0093066", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,공개특허 10-2021-0014949-3-제1 디코딩 태스크를 수행하는 단계는상기 특징 및 상기 현재까지 인식된 적어도 하나의 토큰을 제1 프리 디코딩 레이어에 입력하는 단계; 및상기 제1 프리 디코딩 레이어의 출력을 상기 공유 디코딩 레이어에 입력하여 상기 제1 디코딩 태스크를 수행하는 단계를 포함하고,상기 제2 디코딩 태스크를 수행하는 단계는상기 현재까지 인식된 적어도 하나의 토큰을 제2 프리 디코딩 레이어에 입력하는 단계; 및상기 제2 프리 디코딩 레이어의 출력을 상기 공유 디코딩 레이어에 입력하여 상기 제2 디코딩 태스크를 수행하는 단계를 포함하는, 디코딩 방법."}
{"patent_id": "10-2019-0093066", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서,제1 디코딩 태스크를 수행하는 단계는상기 특징 및 상기 현재까지 인식된 적어도 하나의 토큰을 상기 공유 디코딩 레이어에 입력하는 단계; 및상기 공유 디코딩 레이어의 출력을 제1 포스트 디코딩 레이어에 입력하여 상기 제1 디코딩 태스크를 수행하는단계를 포함하고,상기 제2 디코딩 태스크를 수행하는 단계는상기 현재까지 인식된 적어도 하나의 토큰을 상기 공유 디코딩 레이어에 입력하는 단계; 및상기 공유 디코딩 레이어의 출력을 제2 포스트 디코딩 레이어에 입력하여 상기 제2 디코딩 태스크를 수행하는단계를 포함하는, 디코딩 방법."}
{"patent_id": "10-2019-0093066", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서,상기 제1 디코딩 태스크의 결과는 상기 출력 토큰의 후보들의 제1 확률들을 포함하고, 상기 제2 디코딩 태스크의 결과는 상기 출력 토큰의 후보들의 제2 확률들을 포함하는, 디코딩 방법."}
{"patent_id": "10-2019-0093066", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6항에 있어서,상기 출력 토큰을 결정하는 단계는상기 제1 확률들 및 상기 제2 확률들의 가중합을 계산하는 단계; 및상기 후보들 중 최대 가중합에 대응하는 후보를 상기 출력 토큰으로 결정하는 단계를 포함하는, 디코딩 방법.공개특허 10-2021-0014949-4-청구항 8 제1항에 있어서,상기 출력 토큰을 다음 입력 토큰으로 결정하는 단계를 더 포함하는, 디코딩 방법."}
{"patent_id": "10-2019-0093066", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1항에 있어서,상기 특징은 상기 음성 정보의 진행 정도(progress)에 따른 시퀀스 벡터들에 기초한 어텐션(attention) 네트워크를 이용하여결정되는, 디코딩 방법."}
{"patent_id": "10-2019-0093066", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제1항에 있어서,상기 인공신경망에 포함된 인코딩 레이어를 이용하여, 상기 음성 정보를 인코딩함으로써, 상기 특징을 생성하는단계를 더 포함하는, 디코딩 방법."}
{"patent_id": "10-2019-0093066", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "음성 인식을 위한 인공신경망의 학습 방법에 있어서,음성과 상기 음성에 대응하는 텍스트의 쌍(pair)으로 구성된 제1 트레이닝 세트, 텍스트로 구성된 제2 트레이닝세트를 포함하는 배치(batch)로부터 적어도 하나의 샘플을 선택하는 단계;상기 샘플이 상기 제1 트레이닝 세트로부터 선택되는 경우, 상기 샘플에 기초하여 상기 인공신경망에 포함된 인코딩 레이어 및 공유 디코딩 레이어를 학습시키는 단계; 및상기 샘플이 상기 제2 트레이닝 세트로부터 선택되는 경우, 상기 샘플에 기초하여 상기 공유 디코딩 레이어를학습시키는 단계를 포함하는 학습 방법."}
{"patent_id": "10-2019-0093066", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항에 있어서,상기 인코딩 레이어 및 상기 공유 디코딩 레이어를 학습시키는 단계는상기 인코딩 레이어를 이용하여 상기 샘플에 포함된 음성으로부터 특징을 추출하는 단계;상기 공유 디코딩 레이어를 이용하여, 상기 특징 및 적어도 하나의 토큰에 기초하여 상기 적어도 하나의 토큰이후로 인식되는 출력 토큰을 추정하는 단계; 및상기 추정된 출력 토큰 및 상기 샘플에 포함된 음성에 대응하는 텍스트의 적어도 일부에 기초하여, 상기 인코딩레이어 및 상기 공유 디코딩 레이어를 학습시키는 단계를 포함하는, 학습 방법.공개특허 10-2021-0014949-5-청구항 13 제11항에 있어서,상기 공유 디코딩 레이어를 학습시키는 단계는상기 공유 디코딩 레이어를 이용하여, 적어도 하나의 토큰에 기초하여 상기 적어도 하나의 토큰 이후로 인식되는 출력 토큰을 추정하는 단계; 및상기 추정된 출력 토큰 및 상기 샘플에 포함된 텍스트의 적어도 일부에 기초하여, 상기 공유 디코딩 레이어를학습시키는 단계를 포함하는, 학습 방법."}
{"patent_id": "10-2019-0093066", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제11항에 있어서,상기 샘플을 상기 제1 트레이닝 세트에서 선택하는 단계;상기 인코딩 레이어를 이용하여 상기 샘플에 포함된 음성으로부터 특징을 추출하는 단계;상기 공유 디코딩 레이어를 이용하여, 상기 특징 및 적어도 하나의 토큰에 기초하여 상기 적어도 하나의 토큰이후로 인식되는 출력 토큰의 후보들의 제1 확률들을 추정하는 단계;상기 공유 디코딩 레이어를 이용하여, 상기 적어도 하나의 토큰에 기초하여 상기 적어도 하나의 토큰 이후로 인식되는 상기 출력 토큰의 후보들의 제2 확률들을 추정하는 단계;상기 제1 확률들 및 상기 제2 확률들 사이의 가중치에 기초하여 상기 출력 토큰을 추정하는 단계; 및상기 샘플에 포함된 음성에 대응하는 텍스트의 적어도 일부에 기초하여, 상기 가중치를 학습시키는 단계를 포함하는, 학습 방법."}
{"patent_id": "10-2019-0093066", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "하드웨어와 결합되어 제1항 내지 제14항 중 어느 하나의 항의 방법을 실행시키기 위하여 매체에 저장된 컴퓨터프로그램."}
{"patent_id": "10-2019-0093066", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "음성 정보로부터 특징을 생성하는 인코더; 및공유 디코딩 레이어를 이용하여, 상기 특징 및 현재까지 인식된 적어도 하나의 토큰을 디코딩하는 제1 디코딩태스크를 수행하고, 상기 공유 디코딩 레이어를 이용하여, 상기 현재까지 인식된 적어도 하나의 토큰을 디코딩하는 제2 디코딩 태스크를 수행하며, 상기 제1 디코딩 태스크의 결과 및 상기 제2 디코딩 태스크의 결과에 기초하여, 상기 적어도 하나의 토큰 이후로 인식되는 출력 토큰을 결정하는 디코더를 포함하는 음성 인식 장치."}
{"patent_id": "10-2019-0093066", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제16항에 있어서,상기 음성 정보에서 음성 특징 벡터를 추출하는 음성 전처리 모듈을 더 포함하고,공개특허 10-2021-0014949-6-상기 인코더는상기 음성 특징 벡터에 기초하여 상기 특징을 생성하는, 음성 인식 장치."}
{"patent_id": "10-2019-0093066", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제16항에 있어서,상기 디코더는상기 특징에 대응하는 뉴런과 상기 공유 디코딩 레이어를 연결하는 시냅스(synapse)의 가중치를 제1 값으로 조절하여 상기 제1 디코딩 태스크를 수행하고, 상기 시냅스의 가중치를 제2 값으로 조절하여 상기 제2 디코딩 태스크를 수행하는, 음성 인식 장치."}
{"patent_id": "10-2019-0093066", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제16항에 있어서,상기 디코더는상기 공유 디코딩 레이어를 통해 상기 특징 및 상기 현재까지 인식된 적어도 하나의 토큰을 입력 받아 상기 제1디코딩 태스크를 수행하고, 상기 공유 디코딩 레이어를 통해 상기 현재까지 인식된 적어도 하나의 토큰을 입력받아 상기 제2 디코딩 태스크를 수행하는, 음성 인식 장치."}
{"patent_id": "10-2019-0093066", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제16항에 있어서,상기 디코더는제1 프리 디코딩 레이어를 통해 상기 특징 및 상기 현재까지 인식된 적어도 하나의 토큰을 입력 받고, 상기 공유 디코딩 레이어를 통해 상기 제1 프리 디코딩 레이어의 출력을 입력 받아 상기 제1 디코딩 태스크를수행하고,제2 프리 디코딩 레이어를 통해 상기 현재까지 인식된 적어도 하나의 토큰을 입력 받고, 상기 공유 디코딩 레이어를 통해 상기 제2 프리 디코딩 레이어의 출력을 입력 받아 상기 제2 디코딩 태스크를 수행하는, 음성 인식 장치."}
{"patent_id": "10-2019-0093066", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_21", "content": "제16항에 있어서,상기 디코더는상기 공유 디코딩 레이어를 통해 상기 특징 및 상기 현재까지 인식된 적어도 하나의 토큰을 입력 받고, 제1 포스트 디코딩 레이어를 통해 상기 공유 디코딩 레이어의 출력을 입력 받아 상기 제1 디코딩 태스크를 수행하고,상기 공유 디코딩 레이어를 통해 상기 현재까지 인식된 적어도 하나의 토큰을 입력 받고, 제2 포스트 디코딩 레이어를 통해 상기 공유 디코딩 레이어의 출력을 입력 받아 상기 제2 디코딩 태스크를 수행하는, 음성 인식장치."}
{"patent_id": "10-2019-0093066", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_22", "content": "제16항에 있어서,공개특허 10-2021-0014949-7-상기 제1 디코딩 태스크의 결과는 상기 출력 토큰의 후보들의 제1 확률들을 포함하고, 상기 제2 디코딩 태스크의 결과는 상기 출력 토큰의 후보들의 제2 확률들을 포함하는, 음성 인식 장치."}
{"patent_id": "10-2019-0093066", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_23", "content": "제22항에 있어서,상기 디코더는상기 제1 확률들 및 상기 제2 확률들의 가중합을 계산하고, 상기 후보들 중 최대 가중합에 대응하는 후보를 상기 출력 토큰으로 결정하는, 음성 인식 장치."}
{"patent_id": "10-2019-0093066", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_24", "content": "제16항에 있어서,상기 디코더는상기 출력 토큰을 다음 입력 토큰으로 결정하는, 음성 인식 장치."}
{"patent_id": "10-2019-0093066", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_25", "content": "제16항에 있어서,상기 특징은상기 음성 정보의 진행 정도(progress)에 따른 시퀀스 벡터들에 기초한 어텐션(attention) 네트워크를 이용하여결정되는, 음성 인식 장치."}
{"patent_id": "10-2019-0093066", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "음성 인식을 위한 인공신경망에서의 디코딩 방법 및 장치가 개시된다. 일 실시예에 따른 음성 인식을 위한 인공 신경망에서의 디코딩 방법은 인공신경망에 포함된 공유 디코딩 레이어(shared decoding layer)를 이용하여, 음성 정보를 내포하는 특징 및 현재까지 인식된 적어도 하나의 토큰을 디코딩하는 제1 디코딩 태스크를 수행하는 단계, 공유 디코딩 레이어를 이용하여, 적어도 하나의 토큰을 디코딩하는 제2 디코딩 태스크를 수행하는 단계 및 제1 디코딩 태스크의 결과 및 제2 디코딩 태스크의 결과에 기초하여, 적어도 하나의 토큰 이후로 인식되는 출력 토큰을 결정하는 단계를 포함한다."}
{"patent_id": "10-2019-0093066", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "아래 실시예들은 음성 인식을 위한 인공신경망에서의 디코딩 방법 및 장치에 관한 것이다."}
{"patent_id": "10-2019-0093066", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "음성 인식(speech recognition) 기술이란 인간이 발화한 음성과 같은 음향학적 신호(acoustic speech signal) 를 컴퓨팅 장치의 분석을 통해 인식 또는 이해하는 기술을 의미한다. 종래에는, 음성 데이터에서 추출된 주파 수 특징 등을 이용하여 음성을 인식하는 방식이 주로 이용되었고, 여기에 은닉 마르코프 모델(Hidden Markov Model; HMM)이 주로 이용되었다. 이러한 은닉 마르코프 모델 기반의 음성 인식 방식은 음성 데이터로부터 발음 을 분석하고, 분석된 발음에 기초하여 단어나 문장을 조합하는 과정을 통해 음성을 인식하게 된다. 최근에는, 딥 러닝(deep learning) 기반의 기계 학습(machine learning) 기술이 성숙됨에 따라, 인공신경망 (artificial neural network)으로 구성된 음향 모델을 이용하여, 음성 데이터로부터 발음을 분석하는 과정을 거 치지 않고 음성 데이터에서 단어나 문장 등의 텍스트를 직접 인식하는 단대단(End-to-End) 음성 인식 기술에 대 한 연구가 활발하게 진행되고 있다."}
{"patent_id": "10-2019-0093066", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 2, "content": "발명의 내용"}
{"patent_id": "10-2019-0093066", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "일 실시예에 따른 음성 인식(speech recognition)을 위한 인공신경망에서의 디코딩 방법은 상기 인공신경망에 포함된 공유 디코딩 레이어(shared decoding layer)를 이용하여, 음성 정보를 내포하는 특징 및 현재까지 인식 된 적어도 하나의 토큰을 디코딩하는 제1 디코딩 태스크를 수행하는 단계; 상기 공유 디코딩 레이어를 이용하여, 상기 적어도 하나의 토큰을 디코딩하는 제2 디코딩 태스크를 수행하는 단계; 및 상기 제1 디코딩 태 스크의 결과 및 상기 제2 디코딩 태스크의 결과에 기초하여, 상기 적어도 하나의 토큰 이후로 인식되는 출력 토 큰을 결정하는 단계를 포함한다. 상기 제1 디코딩 태스크를 수행하는 단계는 상기 특징에 대응하는 뉴런과 상기 공유 디코딩 레이어를 연결하는 시냅스(synapse)의 가중치를 제1 값으로 조절하는 단계를 포함하고, 상기 제2 디코딩 태스크를 수행하는 단계는 상기 시냅스의 가중치를 제2 값으로 조절하는 단계를 포함할 수 있다. 제1 디코딩 태스크를 수행하는 단계는 상기 특징 및 상기 현재까지 인식된 적어도 하나의 토큰을 상기 공유 디 코딩 레이어에 입력하여 상기 제1 디코딩 태스크를 수행하는 단계를 포함하고, 상기 제2 디코딩 태스크를 수행 하는 단계는 상기 현재까지 인식된 적어도 하나의 토큰을 상기 공유 디코딩 레이어에 입력하여 상기 제2 디코딩 태스크를 수행하는 단계를 포함할 수 있다. 제1 디코딩 태스크를 수행하는 단계는 상기 특징 및 상기 현재까지 인식된 적어도 하나의 토큰을 제1 프리 디코 딩 레이어에 입력하는 단계; 및 상기 제1 프리 디코딩 레이어의 출력을 상기 공유 디코딩 레이어에 입력하여 상 기 제1 디코딩 태스크를 수행하는 단계를 포함하고, 상기 제2 디코딩 태스크를 수행하는 단계는 상기 현재까지 인식된 적어도 하나의 토큰을 제2 프리 디코딩 레이어에 입력하는 단계; 및 상기 제2 프리 디코딩 레이어의 출 력을 상기 공유 디코딩 레이어에 입력하여 상기 제2 디코딩 태스크를 수행하는 단계를 포함할 수 있다. 제1 디코딩 태스크를 수행하는 단계는 상기 특징 및 상기 현재까지 인식된 적어도 하나의 토큰을 상기 공유 디 코딩 레이어에 입력하는 단계; 및 상기 공유 디코딩 레이어의 출력을 제1 포스트 디코딩 레이어에 입력하여 상 기 제1 디코딩 태스크를 수행하는 단계를 포함하고, 상기 제2 디코딩 태스크를 수행하는 단계는 상기 현재까지 인식된 적어도 하나의 토큰을 상기 공유 디코딩 레이어에 입력하는 단계; 및 상기 공유 디코딩 레이어의 출력을 제2 포스트 디코딩 레이어에 입력하여 상기 제2 디코딩 태스크를 수행하는 단계를 포함할 수 있다. 상기 제1 디코딩 태스크의 결과는 상기 출력 토큰의 후보들의 제1 확률들을 포함하고, 상기 제2 디코딩 태스크 의 결과는 상기 출력 토큰의 후보들의 제2 확률들을 포함할 수 있다. 상기 출력 토큰을 결정하는 단계는 상기 제1 확률들 및 상기 제2 확률들의 가중합을 계산하는 단계; 및 상기 후 보들 중 최대 가중합에 대응하는 후보를 상기 출력 토큰으로 결정하는 단계를 포함할 수 있다. 일 실시예에 따른 디코딩 방법은 상기 출력 토큰을 다음 입력 토큰으로 결정하는 단계를 더 포함할 수 있다. 상기 특징은 상기 음성 정보의 진행 정도(progress)에 따른 시퀀스 벡터들에 기초한 어텐션(attention) 네트워 크를 이용하여 결정될 수 있다. 일 실시예에 따른 디코딩 방법은 상기 인공신경망에 포함된 인코딩 레이어를 이용하여, 상기 음성 정보를 인코 딩함으로써, 상기 특징을 생성하는 단계를 더 포함할 수 있다. 일 실시예에 따른 음성 인식을 위한 인공신경망의 학습 방법은 음성과 상기 음성에 대응하는 텍스트의 쌍(pai r)으로 구성된 제1 트레이닝 세트, 텍스트로 구성된 제2 트레이닝 세트를 포함하는 배치(batch)로부터 적어도 하나의 샘플을 선택하는 단계; 상기 샘플이 상기 제1 트레이닝 세트로부터 선택되는 경우, 상기 샘플에 기초하 여 상기 인공신경망에 포함된 인코딩 레이어 및 공유 디코딩 레이어를 학습시키는 단계; 및 상기 샘플이 상기 제2 트레이닝 세트로부터 선택되는 경우, 상기 샘플에 기초하여 상기 공유 디코딩 레이어를 학습시키는 단계를 포함한다. 상기 인코딩 레이어 및 상기 공유 디코딩 레이어를 학습시키는 단계는 상기 인코딩 레이어를 이용하여 상기 샘 플에 포함된 음성으로부터 특징을 추출하는 단계; 상기 공유 디코딩 레이어를 이용하여, 상기 특징 및 적어도 하나의 토큰에 기초하여 상기 적어도 하나의 토큰 이후로 인식되는 출력 토큰을 추정하는 단계; 및 상기 추정된출력 토큰 및 상기 샘플에 포함된 음성에 대응하는 텍스트의 적어도 일부에 기초하여, 상기 인코딩 레이어 및 상기 공유 디코딩 레이어를 학습시키는 단계를 포함할 수 있다. 상기 공유 디코딩 레이어를 학습시키는 단계는 상기 공유 디코딩 레이어를 이용하여, 적어도 하나의 토큰에 기 초하여 상기 적어도 하나의 토큰 이후로 인식되는 출력 토큰을 추정하는 단계; 및 상기 추정된 출력 토큰 및 상 기 샘플에 포함된 텍스트의 적어도 일부에 기초하여, 상기 공유 디코딩 레이어를 학습시키는 단계를 포함할 수 있다. 상기 샘플을 상기 제1 트레이닝 세트에서 선택하는 단계; 상기 인코딩 레이어를 이용하여 상기 샘플에 포함된 음성으로부터 특징을 추출하는 단계; 상기 공유 디코딩 레이어를 이용하여, 상기 특징 및 적어도 하나의 토큰에 기초하여 상기 적어도 하나의 토큰 이후로 인식되는 출력 토큰의 후보들의 제1 확률들을 추정하는 단계; 상기 공유 디코딩 레이어를 이용하여, 상기 적어도 하나의 토큰에 기초하여 상기 적어도 하나의 토큰 이후로 인식되 는 상기 출력 토큰의 후보들의 제2 확률들을 추정하는 단계; 상기 제1 확률들 및 상기 제2 확률들 상이의 가중 치에 기초하여 상기 출력 토큰을 추정하는 단계; 및 상기 샘플에 포함된 음성에 대응하는 텍스트의 적어도 일부 에 기초하여, 상기 가중치를 학습시키는 단계를 포함할 수 있다. 일 실시예에 따른 음성 인식 장치는 음성 정보로부터 특징을 생성하는 인코더; 및 공유 디코딩 레이어를 이용하 여, 상기 특징 및 현재까지 인식된 적어도 하나의 토큰을 디코딩하는 제1 디코딩 태스크를 수행하고, 상기 공유 디코딩 레이어를 이용하여, 상기 현재까지 인식된 적어도 하나의 토큰을 디코딩하는 제2 디코딩 태스크를 수행 하며, 상기 제1 디코딩 태스크의 결과 및 상기 제2 디코딩 태스크의 결과에 기초하여, 상기 적어도 하나의 토큰 이후로 인식되는 출력 토큰을 결정하는 디코더를 포함한다. 일 실시예에 따른 음성 인식 장치는 상기 음성 정보에서 음성 특징 벡터를 추출하는 음성 전처리 모듈을 더 포 함하고, 상기 인코더는 상기 음성 특징 벡터에 기초하여 상기 특징을 생성할 수 있다. 상기 디코더는 상기 특징에 대응하는 뉴런과 상기 공유 디코딩 레이어를 연결하는 시냅스(synapse)의 가중치를 제1 값으로 조절하여 상기 제1 디코딩 태스크를 수행하고, 상기 시냅스의 가중치를 제2 값으로 조절하여 상기 제2 디코딩 태스크를 수행할 수 있다. 상기 디코더는 상기 공유 디코딩 레이어를 통해 상기 특징 및 상기 현재까지 인식된 적어도 하나의 토큰을 입력 받아 상기 제1 디코딩 태스크를 수행하고, 상기 공유 디코딩 레이어를 통해 상기 현재까지 인식된 적어도 하나 의 토큰을 입력 받아 상기 제2 디코딩 태스크를 수행할 수 있다. 상기 디코더는 제1 프리 디코딩 레이어를 통해 상기 특징 및 상기 현재까지 인식된 적어도 하나의 토큰을 입력 받고, 상기 공유 디코딩 레이어를 통해 상기 제1 프리 디코딩 레이어의 출력을 입력 받아 상기 제1 디코딩 태스 크를 수행하고, 제2 프리 디코딩 레이어를 통해 상기 현재까지 인식된 적어도 하나의 토큰을 입력 받고, 상기 공유 디코딩 레이어를 통해 상기 제2 프리 디코딩 레이어의 출력을 입력 받아 상기 제2 디코딩 태스크를 수행할 수 있다. 상기 디코더는 상기 공유 디코딩 레이어를 통해 상기 특징 및 상기 현재까지 인식된 적어도 하나의 토큰을 입력 받고, 제1 포스트 디코딩 레이어를 통해 상기 공유 디코딩 레이어의 출력을 입력 받아 상기 제1 디코딩 태스크 를 수행하고, 상기 공유 디코딩 레이어를 통해 상기 현재까지 인식된 적어도 하나의 토큰을 입력 받고, 제2 포 스트 디코딩 레이어를 통해 상기 공유 디코딩 레이어의 출력을 입력 받아 상기 제2 디코딩 태스크를 수행할 수 있다. 상기 제1 디코딩 태스크의 결과는 상기 출력 토큰의 후보들의 제1 확률들을 포함하고, 상기 제2 디코딩 태스크 의 결과는 상기 출력 토큰의 후보들의 제2 확률들을 포함할 수 있다. 상기 디코더는 상기 제1 확률들 및 상기 제2 확률들의 가중합을 계산하고, 상기 후보들 중 최대 가중합에 대응 하는 후보를 상기 출력 토큰으로 결정할 수 있다. 상기 디코더는 상기 출력 토큰을 다음 입력 토큰으로 결정할 수 있다. 상기 특징은 상기 음성 정보의 진행 정도(progress)에 따른 시퀀스 벡터들에 기초한 어텐션(attention) 네트워 크를 이용하여 결정될 수 있다."}
{"patent_id": "10-2019-0093066", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 명세서에 개시되어 있는 본 발명의 개념에 따른 실시예들에 대해서 특정한 구조적 또는 기능적 설명들은 단 지 본 발명의 개념에 따른 실시예들을 설명하기 위한 목적으로 예시된 것으로서, 본 발명의 개념에 따른 실시예 들은 다양한 형태로 실시될 수 있으며 본 명세서에 설명된 실시예들에 한정되지 않는다. 본 발명의 개념에 따른 실시예들은 다양한 변경들을 가할 수 있고 여러 가지 형태들을 가질 수 있으므로 실시예 들을 도면에 예시하고 본 명세서에 상세하게 설명하고자 한다. 그러나, 이는 본 발명의 개념에 따른 실시예들 을 특정한 개시형태들에 대해 한정하려는 것이 아니며, 본 발명의 사상 및 기술 범위에 포함되는 변경, 균등물, 또는 대체물을 포함한다. 제1 또는 제2 등의 용어를 다양한 구성요소들을 설명하는데 사용될 수 있지만, 상기 구성요소들은 상기 용어들 에 의해 한정되어서는 안 된다. 상기 용어들은 하나의 구성요소를 다른 구성요소로부터 구별하는 목적으로만, 예를 들어 본 발명의 개념에 따른 권리 범위로부터 이탈되지 않은 채, 제1 구성요소는 제2 구성요소로 명명될 수 있고, 유사하게 제2 구성요소는 제1 구성요소로도 명명될 수 있다. 어떤 구성요소가 다른 구성요소에 “연결되어” 있다거나 “접속되어” 있다고 언급된 때에는, 그 다른 구성요 소에 직접적으로 연결되어 있거나 또는 접속되어 있을 수도 있지만, 중간에 다른 구성요소가 존재할 수도 있다 고 이해되어야 할 것이다. 반면에, 어떤 구성요소가 다른 구성요소에 “직접 연결되어” 있다거나 “직접 접속 되어” 있다고 언급된 때에는, 중간에 다른 구성요소가 존재하지 않는 것으로 이해되어야 할 것이다. 구성요소 들 간의 관계를 설명하는 표현들, 예를 들어 “~사이에”와 “바로~사이에” 또는 “~에 직접 이웃하는” 등도 마찬가지로 해석되어야 한다. 본 명세서에서 사용한 용어는 단지 특정한 실시예들을 설명하기 위해 사용된 것으로, 본 발명을 한정하려는 의 도가 아니다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 명세서에 서, “포함하다” 또는 “가지다” 등의 용어는 설시된 특징, 숫자, 단계, 동작, 구성요소, 부분품 또는 이들을 조합한 것이 존재함으로 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성요소, 부분품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되어야 한다. 다르게 정의되지 않는 한, 기술적이거나 과학적인 용어를 포함해서 여기서 사용되는 모든 용어들은 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자에 의해 일반적으로 이해되는 것과 동일한 의미를 가진다. 일반적 으로 사용되는 사전에 정의되어 있는 것과 같은 용어들은 관련 기술의 문맥상 가지는 의미와 일치하는 의미를 갖는 것으로 해석되어야 하며, 본 명세서에서 명백하게 정의하지 않는 한, 이상적이거나 과도하게 형식적인 의 미로 해석되지 않는다. 이하, 실시예들을 첨부된 도면을 참조하여 상세하게 설명한다. 각 도면에 제시된 동일한 참조 부호는 동일한 부재를 나타낸다.도 1은 일 실시예에 따른 음성 인식(speech recognition)을 위한 인공신경망의 동작 방법을 설명하기 위한 도면 이다. 도 1을 참조하면, 일 실시예에 따른 음성 인식을 위한 인공신경망은 시퀀스 투 시퀀스(sequence-to- sequence) 모델로 구현될 수 있다. 시퀀스 투 시퀀스 모델은 입력된 시퀀스로부터 다른 도메인의 시퀀스를 출 력할 수 있다. 예를 들어, 음성 인식을 위해 시퀀스 투 시퀀스 구조로 구현된 인공신경망은 입력 음성으 로부터 입력 음성에 대응하는 인식 결과, 예를 들어 입력 음성에 대응하는 텍스트를 직접 생성할 수 있다. 인 공신경망은 입력 시퀀스로부터 인식 결과의 시퀀스를 생성하도록 미리 학습될 수 있다. 예를 들어, 인공 신경망은 음성과 음성에 대응하는 텍스트로 구성된 학습 데이터를 이용하여, 음성과 텍스트의 상관성을 높 일 수 있도록 학습될 수 있다. 시퀀스 투 시퀀스 모델은 인코더와 디코더를 포함할 수 있다. 인코더는 음성 정보를 직접 수신하여 처리하지 않고, 음성 정보에 대응되는 벡터 형태로 변환된 음성 특징 벡터를 입력 받을 수 있다. 인코더는 음성 특징 벡터를 순차적으로 입력 받은 뒤에 마지막에 모든 음성 정보들을 압축해 서 하나의 벡터로 만드는데, 이를 컨텍스트 벡터(context vector)라고 할 수 있다. 컨텍스트 벡터는 음성 정보를 내포하는 특징 또는 인코딩된 특징으로 지칭될 수도 있다. 시간의 흐름에 따른 음성 정보가 하나의 컨텍스트 벡터로 모두 압축되면, 인코더는 컨텍스트 벡터를 디코더로 전송할 수 있다. 디코더는 컨텍스트 벡터를 받아서 음성 인식된 단어를 한 개씩 순차적으로 출력할 수 있다. 일 실시예에 따른 인코더와 디코더는 뉴럴 네트워크로 구현되며, 예를 들어 순환 신경망(RNN; recurrent neural network) 아키텍처일 수 있다. 인코더는 시퀀스(예를 들어, 음성)를 입력 받는 순환 신경망, 디코더는 시퀀스(예를 들어, 음성 인식 결과인 텍스트)를 출력하는 순환 신경망일 수 있다. 인코 더와 디코더는 순환 신경망 이외에도 DNN(Deep Neural Network), 및 RDNN(Recurrent Deep Neural Network) 등으로 구현될 수 있다. 디코더는 오토 리그레시브(auto-regressive) 디코딩을 수행할 수 있다. 오토 리그레시브 디코딩은 토큰 (token)별로 이전 스텝까지 인식되었던 토큰들에 기초하여 출력 토큰을 결정하는 디코딩 방법으로, 정해지지 않 은 길이의 출력을 인공신경망으로 계산하기 위해서 사용될 수 있다. 컨텍스트 벡터를 수신한 디코더는 초기 입력으로 문장의 시작을 의미하는 시작 토큰(SOS; Start-of- sentence)을 수신할 수 있다. 시작 토큰(SOS)을 수신한 디코더는 다음에 등장할 확률이 높은 토큰을 예측할 수 있다. 토큰은 한 시퀀스를 구성하는 단위로, 예를 들어 단어(word), 부분 단어(subword), 글 자(character) 단위일 수 있다. 이하에서, 설명의 편의를 위하여 토큰은 단어 단위인 것으로 설명한다. 첫번 째 시점(time step)에서, 디코더는 다음에 등장할 단어로 'Hi'를 예측할 수 있다. 즉, 디코더(12 0)는 'Hi'를 출력 토큰으로 결정하여 음성 인식 결과로 출력할 수 있다. 'Hi'를 출력 토큰으로 결정 한 디코더는 'Hi'를 다음 시점의 입력으로 입력할 수 있다. 두번째 시점에서, 디코더는 입력된 단어 'Hi'로부터 다시 다음에 올 단어인 'Bixby' 를 예측할 수 있다. 디코더는 또 다시 'Bixby'를 다음 시점의 입력으로 입력할 수 있다. 디코더는 이런 식으로 다음에 올 단어를 예측하고, 그 예측한 단 어를 다음 시점의 입력으로 넣는 행위를 반복할 수 있다. 이 행위는 문장의 끝을 의미하는 종료 토큰(EOS; End-of-sentence)이 다음 단어로 예측될 때까지 반복될 수 있다. 디코더는 매 스텝 인코더로부터 계산된 정보를 바탕으로 출력 토큰을 구하는데, 이때 이전 스텝까지 선택 되었던 입력 토큰들에 종속되어 구할 수 있다. 예를 들어, 토큰1을 입력 받은 디코더는 토큰1에 기초하여 출력 토큰의 후보들의 확률들을 예측할 수 있고, 확률들에 기초하여 최종 출력 토큰을 결정할 수 있다. 예를 들어, 디코더는 후보들 중 확률이 가장 높은 토큰을 출력 토큰으로 선택할 수 있다. 스텝 i 에서 토큰 후보 ti가 갖는 조건부 확률은 수학식 1과 같이 표현 할 수 있다. 수학식 1"}
{"patent_id": "10-2019-0093066", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "He는 인코더의 히든 리프리젠테이션(hidden representation)으로 컨텍스트 벡터에 해당할 수 있다. t1 내 지 ti-1은 지금까지 인식되었던 토큰들일 수 있다. 디코더는 컨텍스트 벡터 및 지금까지 인식되었던 토큰들에 기초하여 이후 출력 토큰을 결정할 수 있다. 컨텍스트 벡터는 음성 정보의 진행 정도 (progress)에 따른 음성 특징 벡터들에 기초한 어텐션(attention) 네트워크를 이용하여 결정될 수 있다. 디코더가 출력 토큰을 결정할 때 각 단어가 필요한 정보가 다르기 때문에, 매 시점에 동일한 컨텍스트 벡 터를 이용하는 것은 음성 인식 성능을 저하시킬 수 있다. 어텐션 네트워크를 이용하면, 디코더가 출력 토큰 ti를 결정할 때에 인코더의 히든 스테이트 벡터 (hidden state vector) h1, h2, ... , hn의 조합으로 ti마다 다른 컨텍스트 벡터를 이용할 수 있다. 디코더 가 출력 토큰 ti를 결정할 때에 인코더의 히든 스테이트 벡터(hidden state vector) hj를 얼마나 이 용할지를 어텐션 가중치 aij로 정의할 수 있고, 출력 토큰 ti의 컨텍스트 벡터는 ∑aijhj로 정의될 수 있다. 음성 인식을 위한 인공신경망은 음성 정보를 입력 받아 컨텍스트 벡터를 출력하는 인코더 및 컨텍스트 벡터를 입력 받아 인식 결과인 텍스트(단어 시퀀스)를 출력하는 디코더에 단어의 시퀀스 의 확률을 예측하는 언어 모델 인공신경망을 추가로 활용하여 음성 인식 성능을 높일 수 있다. 언어 모델 인공신경망은 문장 전체의 확률을 예측하는 일을 하며, 또한 이 일을 하기 위해서 이전 단어들이 주 어졌을 때, 다음 단어가 등장할 확률을 예측할 수 있다. 언어 모델 인공신경망은 인코더 없이 디코더만으로 구 성될 수 있고, 텍스트만을 이용하여 학습이 가능할 수 있다. 언어 모델 인공신경망은 발음이 비슷한 단어들이 존재할 경우, 보다 정확한 인식을 가능케할 수 있다. 예를 들 어, ‘Minchul’이라는 단어와 ‘feels’라는 단어가 주어진 경우, 언어 모델 인공신경망은 다음 단어로 ‘ habit’보다 ‘happy’가 올 확률이 높다고 판단할 수 있다. 아래에서, 기존의 음성 인식을 위한 인공신경망 의 디코더가 수행하는 동작과 언어 모델 인공신경망이 수행하는 동작을 구분하기 위하여, 기존의 음 성 인식을 위한 인공신경망의 디코더가 디코딩을 수행하는 동작을 '음성 인식 태스크' 또는 '제1 디 코딩 태스크'로, 언어 모델 인공신경망이 디코딩을 수행하는 동작을 '언어 모델 태스크' 또는 '제2 디코딩 태스 크'로 지칭한다. 음성 인식 태스크는 음성의 신호적인 특성과 언어 요소 사이의 관계를 처리할 수 있는데, 예를 들어 음성 신호 의 발음을 추정하는 태스크이고, 언어 모델 태스크는 단어 또는 문장이 문법적으로나 의미적으로 어느 정도 올 바른지를 추정하는 태스크일 수 있다. 기존의 음성 인식을 위한 인공신경망에 언어 모델 인공신경망을 추가로 결합하는 경우, 음성 인식 성능을 향상시킬 수 있다. 또한, 기존의 음성 인식을 위한 인공신경망은 학습을 위해 음성 및 음성에 대응하는 텍스트 쌍이 필요하나, 이는 쉽게 구할 수 있는 텍스트보다 그 양이 절대적으로 작기 때문에 텍스트만으로 학습 이 가능한 언어 모델 인공신경망을 추가로 학습하여 음성 인식 성능을 보완할 수 있다. 아래에서, 기존의 음성 인식을 위한 인공신경망에 언어 모델 인공신경망과 결합하여 음성 인식의 성능을 향상시키면서, 메모리 대 역폭(bandwidth)의 증가 및 소비 전력 증가를 방지할 수 있는 방법을 설명한다. 도 2a와 도 2b는 일 실시예에 따른 인공신경망에 언어 모델 인공신경망을 결합하는 방법을 설명하기 위한 도면 이다. 일 실시예에 따른 디코더를 공유하는 방법을 설명하기에 앞서, 도 2a를 참조하여 기존의 방법에 따라 인 공신경망에 외부 언어 모델 인공신경망을 결합하는 방법을 간략하게 설명한다. 도 2a를 참조하면, 일 실시예에 따른 인공신경망은 인코더, 디코더 및 외부 언어 모델 인공신경망 을 포함하고, 인코더 및 디코더는 도 1을 참조하여 설명한 인코더 및 디코더일 수 있다. 인공신경망은 디코더와 외부 언어 모델 인공신경망의 조합에 기초하여 음성 인식을 수행할 수 있다. 구체적으로, 디코더와 외부 언어 모델 인공신경망은 토큰 단위로 각각의 인식 결과를 출력할 수 있고, 각각의 인식 결과를 가중치에 따라 조합하여 최종 인식 결과를 생성할 수 있다. 예를 들어, 디코더(22 0)는 컨텍스트 벡터와 현재까지 인식된 적어도 하나의 토큰에 기초하여 출력 토큰의 후보들을 결정할 수 있고, 외부 언어 모델 인공신경망은 현재까지 인식된 적어도 하나의 토큰에 기초하여 출력 토큰의 후보들을 결정 할 수 있으며, 각각의 출력 토큰의 후보들을 가중치에 따라 조합하여, 최종 출력 토큰을 결정할 수 있다. 일상에서의 음성 인식 활용을 위해서는 사생활 보호에 적합하고 네트워크 연결에 관계없이 손안의 기기에서 음 성 인식이 수행되는 것이 필요할 수 있다. 예를 들어, 대규모의 서버가 아닌 디바이스 단에서 음성 인식을 수 행하는 온디바이스(on device) 환경에 따르면, 음성 인식이 사용자의 디바이스에서 돌아가기 때문에 데이터의 외부 유출이 없어 사생활 보호가 가능할 수 있다. 나아가, 온디바이스 환경에서는 네트워크에 연결되지 않은 상태에서도 음성 인식 과정에서 지연이 발생하지 않고 실시간으로 처리할 수 있다. 디바이스는 스마트폰, 스마 트 TV, 인공지능 스피커, 네비게이션, DTV, 웨어러블 디바이스, 전장, 로봇 등과 같이 메모리 수단을 구비하고 마이크로 프로세서를 탑재하여 연산 능력을 갖춘 디지털 기기를 모두 포함하는 개념일 수 있다. 외부 언어 모델 인공신경망을 사용하는 것은 온디바이스 환경에 적합하지 않을 수 있다. 외부 언어 모델 인공신경망을 사용하는 경우 음성 인식의 성능을 향상시킬 수 있지만, 외부 언어 모델 인공신경망이 추가됨에 따라 전체 시스템의 크기가 증가되고, 외부 언어 모델 인공신경망의 구동 시간 증가로 인한 전체 음성 인식 시간이 증가되며, 별도로 학습된 두 모델을 적절히 통합하기 위해 사람이 결정해야 하는 파라미터가 증가되는 문제가 있을 수 있다. 디바이스 단에서 음성 인식을 수행하는 경우에는, 디바이스의 메모리에 인공신경망의 파라미터를 올려야 하는데, 외부 언어 모델 인공신경망을 추가하는 경우 메모리에 파라미터를 읽고 쓰는 대역폭이 증가될 수 있고, 메모리를 읽고 쓰기 시에 발생하는 전력 소모가 증가될 수 있다. 나아가, 외부 언어 모델 인공신경망 을 기존의 인공신경망과 별도로 학습해야 하는 단점이 있을 수 있다. 도 2b를 참조하면, 일 실시예에 따른 다중 태스크 인공신경망은 인코더와 디코더를 포함할 수 있고, 음성 인식 태스크와 언어 모델 태스크는 하나의 디코더에서 수행될 수 있다. 다중 태스크 인공신경망은 별도의 외부 언어 모델 인공신경망을 사용하지 않고, 하나의 디코더를 공유하여 음성 인식 태스크와 언어 모델 태스크를 수행할 수 있다. 하나의 디코더를 공유하여 다중 태스크 인공신경망을 구성하게 되면 언어 모델 인공신경망을 위한 별도의 파라미터(예를 들어, 가중치)를 저장하지 않아도 되기 때문에 전체 시스템의 크기를 줄일 수 있다. 또한, 다중 태스크 인공신경망을 사용하면, 디코딩 수행 시 한번 로드(load)한 디코더의 파라미터를 음성 인식 태스크와 언 어 모델 태스크에 두 번 사용함으로써 파라미터 재사용률이 상승하게 될 수 있다. 이는 계산에 바운드(bound) 가 되지 않고 메모리 읽기 쓰기에 바운드되는 것이 일반적인 시퀀스 생성(sequence generation) 모델에 큰 장점 이 될 수 있다. 특히 한번에 로드할 수 있는 메모리의 양과 그 대역폭이 제한적인 디바이스에서 음성인식을 수 행할 때에는 그 효과가 더 클 수 있다. 아래에서, 도 3 내지 도 6을 참조하여 디코딩 방법을, 도 7 내지 도 8 을 참조하여 학습 방법을 상세히 설명한다. 도 3은 일 실시예에 따른 음성 인식 장치를 도시한 블록도이다. 도 3을 참조하면, 일 실시예에 따른 음성 인식 장치는 인공신경망, 음성 전처리 모듈 및 텍스트 처리 모듈을 포함하고, 인공신경망은 인코더 및 공유 디코더를 포함할 수 있다. 인공신경망 , 인코더 및 공유 디코더는 각각 도 2b를 참조하여 설명한 다중 태스크 인공신경망, 인코더 및 디코더일 수 있다. 음성 전처리 모듈은 인공신경망의 입력을 전처리하는 모듈로, 예를 들어 음성 정보에 포함된 노이즈를 제 거하거나, 음성 정보를 인공신경망에 입력하기 적합한 형태로 가공할 수 있다. 음성 전처리 모듈은 음성 정보에서 음성 특징 벡터를 추출할 수 있다. 보다 구체적으로, 음성 전처리 모듈은 음성을 특정 단위(예 를 들어, 25ms)로 나누고, 일부(예를 들어, 15ms)가 겹치도록 슬라이딩 하면서 1개의 프레임(frame)을 구성해 피쳐(feature)를 추출할 수 있다. 이후 음성 전처리 모듈은 특정 개수(예를 들어, 3개)의 피쳐 프레임(feature frame)을 붙여서 인코더의 입력이 될 음성 특징 벡터를 만들 수 있다. 텍스트 처리 모듈은 공유 디코더에 현재까지 인식된 적어도 하나의 토큰을 입력할 수 있다."}
{"patent_id": "10-2019-0093066", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "이러한 도 3은 발명의 설명을 위한 일례로, 한정된 도면에 의해 설명되었으나, 해당 기술분야에서 통상의 지식 을 가진 자라면 도 3을 기초로 다양한 기술적 수정 및 변형을 적용할 수 있다. 예를 들어, 디코더는 텍스 트 처리 모듈을 포함하는 넓은 개념일 수 있다. 도 4는 일 실시예에 따른 디코딩 방법을 설명하기 위한 순서도이다. 도 4를 참조하면, 일 실시예에 따른 단계들(410 내지 430)은 도 3을 참조하여 전술된 공유 디코더에 의해 수행될 수 있다. 공유 디코더는 하나 또는 그 이상의 하드웨어 모듈, 하나 또는 그 이상의 소프트웨어 모 듈, 또는 이들의 다양한 조합에 의하여 구현될 수 있다. 단계에서, 공유 디코더는 공유 디코딩 레이어(shared decoding layer)를 이용하여, 음성 정보를 내포하는 특징(컨텍스트 벡터) 및 현재까지 인식된 적어도 하나의 토큰을 디코딩하는 제1 디코딩 태스크를 수행한다. 공 유 디코더는 뉴럴 네트워크로 구성되는 바 복수의 레이어들을 포함할 수 있고, 복수의 레이어들 중 음성 인식 태스크와 언어 모델 태스크에 공통으로 사용되는 레이어(들)를 공유 디코딩 레이어라고 지칭할 수 있다. 공유 디코더는 전체가 공유 디코딩 레이어로 구성될 수도 있고, 일부만 공유 디코딩 레이어로 구성될 수도 있다. 단계에서, 공유 디코더는 공유 디코딩 레이어를 이용하여, 현재까지 인식된 적어도 하나의 토큰을 디코딩 하는 제2 디코딩 태스크를 수행한다. 공유 디코더는 단계에서 제1 디코딩 태스크를 수행한 공유 디코딩 레이어를 이용하여, 동일한 파라미터로 언어 모델 태스크를 수행할 수 있다. 공유 디코더는 인코더로부터 수신한 컨텍스트 벡터와 현재까지 인식된 적어도 하나의 토큰을 입력으로 출력 토 큰을 예측하는 기존의 인공신경망의 디코더의 역할과 동시에 음성 정보로부터 계산된 컨텍스트 벡터를 고려하지 않고 현재까지 인식된 적어도 하나의 토큰만을 입력으로 출력 토큰을 예측하는 언어 모델 인공신경망의 역할도 수행하게 된다. 공유 디코더는 컨텍스트 벡터 및 현재까지 인식된 적어도 하나의 토큰에 기초하여, 출력 토큰의 후보들의 제1 확률들을 결정할 수 있고, 현재까지 인식된 적어도 하나의 토큰에 기초하여 출력 토큰의 후보들의 제2 확률들을 결정할 수 있다. 제1 확률들은 전술한 바와 같이 수학식 1에 의해 결정될 수 있다. 제2 확률들은 수학식 2에 의해 결정될 수 있다. 수학식 2"}
{"patent_id": "10-2019-0093066", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "공유 디코더는 컨텍스트 벡터에 대응하는 뉴런과 공유 디코딩 레이어를 연결하는 시냅스(synapse)의 가중치 조 절을 통해 하나의 디코더로 다중 태스크(제1 디코딩 태스크 및 제2 디코딩 태스크)를 수행할 수 있다. 공유 디 코더는 제1 디코딩 태스크를 수행 시, 컨텍스트 벡터에 대응하는 뉴런과 공유 디코딩 레이어를 연결하는 시냅스 의 가중치를 제1 값으로 조절할 수 있고, 제2 디코딩 태스크를 수행 시, 컨텍스트 벡터에 대응하는 뉴런과 공유 디코딩 레이어를 연결하는 시냅스의 가중치를 제2 값으로 조절할 수 있다. 제1 디코딩 태스크를 수행 시에는 컨텍스트 벡터를 고려하여 출력 토큰의 후보들의 제1 확률들을 결정하기 때문 에, 공유 디코더는 컨텍스트 벡터에 대응하는 뉴런과 공유 디코딩 레이어를 연결하는 시냅스의 가중치를 미리 설정된 임계값 이상으로 조절할 수 있다. 예를 들어, 공유 디코더는 컨텍스트 벡터에 대응하는 뉴런과 공유 디 코딩 레이어를 연결하는 시냅스의 가중치를 컨텍스트 벡터가 디코더에 입력될 수 있을 정도(예를 들어 '1')로 조절할 수 있다. 제2 디코딩 태스크를 수행 시에는 컨텍스트 벡터를 고려하지 않고 출력 토큰의 후보들의 제2 확률들을 결정하기 때문에, 공유 디코더는 컨텍스트 벡터에 대응하는 뉴런과 공유 디코딩 레이어를 연결하는 시냅스의 가중치를 미 리 설정된 임계값 미만으로 조절할 수 있다. 예를 들어, 공유 디코더는 컨텍스트 벡터에 대응하는 뉴런과 공유 디코딩 레이어를 연결하는 시냅스의 가중치를 컨텍스트 벡터가 디코더에 영향을 주지 않을 정도(예를 들어 '0')로 조절할 수 있다. 단계에서, 공유 디코더는 제1 디코딩 태스크의 결과 및 제2 디코딩 태스크의 결과에 기초하여, 적어도 하 나의 토큰 이후로 인식되는 출력 토큰을 결정한다. 공유 디코더는 제1 확률들 및 제2 확률들의 가중합을 계산 할 수 있고, 출력 토큰의 후보들 중 최대 가중합에 대응하는 후보를 출력 토큰으로 결정할 수 있다. 예를 들어, 제1 디코딩 태스크의 결과, 출력 토큰의 후보들 'Bixby', 'Vixby'의 제1 확률이 각각 0.79, 0.81일 수 있 고, 제2 디코딩 태스크의 결과, 출력 토큰의 후보들 'Bixby', 'Vixby'의 제2 확률이 각각 0.85, 0.12일 수 있고, 제1 확률과 제2 확률의 가중치는 1:0.2 일 수 있다. 이 경우, 출력 토큰의 후보들 'Bixby', 'Vixby'의 가중합은 각각 0.96, 0.834일 수 있다. 따라서, 공유 디코더는 최대 가중합에 대응하는 'Bixby'를 출력 토큰으 로 결정할 수 있다. 제1 확률과 제2 확률 사이의 가중치는 사전에 정의된 값일 수 있고, 또는 게이트(gate)를 통해 학습될 수도 있다. 가중치를 학습하는 방법은 아래에서 도 7을 참조하여 상세히 설명된다. 도 5는 일 실시예에 따른 음성 인식 방법을 설명하기 위한 순서도이다. 도 5를 참조하면, 일 실시예에 따른 단계들(510 내지 590)은 도 3을 참조하여 전술된 음성 인식 장치에 의해 수 행될 수 있다. 단계에서, 음성 인식 장치는 음성을 입력 받을 수 있다. 사용자는 음성을 발화할 수 있고, 음성 인식 장 치는 사용자가 발화한 음성을 입력 받을 수 있으며, 음성 인식 장치가 수신한 음성을 음성 정보 또는 음성 신호 로 지칭할 수 있다. 단계에서, 음성 인식 장치는 음성 정보를 인코딩하여 컨텍스트 벡터를 생성할 수 있다. 단계에서, 음성 인식 장치는 시점 i를 초기화하고, 시점의 초기 입력으로 문장의 시작을 의미하는 시작 토 큰(SOS)을 설정할 수 있다. 단계에서, 음성 인식 장치는 제1 디코딩 태스크를 수행할 수 있다. 음성 인식 장치는 컨텍스트 벡터 및 현재까지 인식된 적어도 하나의 토큰을 디코딩할 수 있다. 단계에서, 음성 인식 장치는 제2 디코딩 태스크를 수행할 수 있다. 음성 인식 장치는 현재까지 인식된 적 어도 하나의 토큰을 디코딩할 수 있다. 단계에서, 음성 인식 장치는 제1 디코딩 태스크의 결과 및 제2 디코딩 태스크의 결과에 기초하여, 음성 인 식 장치는 출력 토큰의 후보들의 제1 확률들 및 제2 확률들의 가중합을 계산할 수 있다. 단계에서, 음성 인식 장치는 가중합에 기초하여, 해당 시점 i에서의 출력 토큰을 결정할 수 있다. 전술한 바와 같이, 음성 인식 장치는 출력 토큰의 후보들 중 최대 가중합에 대응하는 후보를 출력 토큰으로 결정할 수 있다. 단계(580, 590)에서, 음성 인식 장치는 시점 i에서의 출력 토큰이 문장의 끝을 의미하는 토큰인 'EOS' 토큰이 다음 단어로 예측될 때까지 시점을 1 더하고, 단계(540 내지 570)들을 반복할 수 있다. 도 6은 일 실시예에 따른 디코딩 레이어를 일부만 공유하는 디코더를 포함하는 음성 인식 장치를 도시한 블록도 이다. 도 6을 참조하면, 일 실시예에 따른 음성 인식 장치는 인공신경망, 음성 전처리 모듈 및 텍스트 처리 모듈을 포함하고, 인공신경망은 인코더 및 디코더를 포함할 수 있다. 인코더, 음성 전처리 모듈 및 텍스트 처리 모듈은 각각 도 3을 참조하여 설명한 인코더 음성 전처리 모듈 및 텍스트 처리 모듈일 수 있다. 일 실시예에 따른 디코더는 복수의 레이어들 중 일부만 공유 디코딩 레이어로 사용할 수 있다. 예를 들어, 디코더는 인코더로부터 컨텍스트 벡터를 입력 받는 디코더 전단 부분과 또는 인식 결과를 출력하는 디코더 후단 부분에 음성 인식 태스크를 위한 디코딩 레이어와 언어 모델 태스크를 위한 디코딩 레이어를 별도 로 갖을 수 있다. 보다 구체적으로, 디코더는 컨텍스트 벡터 및 현재까지 인식된 적어도 하나의 토큰을 음성 인식 태스크를 위한 제1 프리 디코딩 레이어에 입력하고, 제1 프리 디코딩 레이어의 출력을 공유 디코딩 레이어에 입력하여 제1 디코딩 태스크를 수행할 수 있다. 또한, 디코더는 현재까지 인식된 적어도 하나의 토큰을 언어 모델 태스크를 위한 제2 프리 디코딩 레이어에 입력하고, 제2 프리 디코딩 레이어의 출 력을 공유 디코딩 레이어에 입력하여 제2 디코딩 태스크를 수행할 수 있다. 또는, 디코더는 컨텍스트 벡터 및 현재까지 인식된 적어도 하나의 토큰을 공유 디코딩 레이어에 입력 하고, 공유 디코딩 레이어의 출력을 음성 인식 태스크를 위한 제1 포스트 디코딩 레이어에 입력하여 제1 디코딩 태스크를 수행할 수 있다. 또한, 디코더는 현재까지 인식된 적어도 하나의 토큰을 공유 디코 딩 레이어에 입력하고, 공유 디코딩 레이어의 출력을 언어 모델 태스크를 위한 제2 포스트 디코딩 레 이어에 입력하여 제2 디코딩 태스크를 수행할 수 있다 또는, 디코더는 컨텍스트 벡터 및 현재까지 인식된 적어도 하나의 토큰을 음성 인식 태스크를 위한 제1 프 리 디코딩 레이어에 입력하고, 제1 프리 디코딩 레이어의 출력을 공유 디코딩 레이어에 입력하 고, 공유 디코딩 레이어의 출력을 제1 포스트 디코딩 레이어에 입력하여 제1 디코딩 태스크를 수행할 수 있다. 또한, 디코더는 현재까지 인식된 적어도 하나의 토큰을 언어 모델 태스크를 위한 제2 프리 디코 딩 레이어에 입력하고, 제2 프리 디코딩 레이어의 출력을 공유 디코딩 레이어에 입력하고, 공유 디코딩 레이어의 출력을 제2 포스트 디코딩 레이어에 입력하여 제2 디코딩 태스크를 수행할 수 있다 복수의 레이어들 중 일부만 공유 디코딩 레이어로 사용하는 경우, 공유 디코딩 레이어 영역(part)이 줄어 들지만, 일부 차이가 있는 다른 두 태스크 각각을 위한 영역이 존재하기 때문에, 모델 사이즈를 일부 희생하고 성능을 더 끌어 올릴 수 있다. 도 7과 도 8은 일 실시예에 따른 음성 인식을 위한 인공신경망의 학습 방법을 설명하기 위한 도면이다. 도 7을 참조하면, 일 실시예에 따른 단계들(710 내지 730)은 음성 인식 학습 장치에 의해 수행될 수 있다. 단계에서, 음성 인식 학습 장치는 음성과 음성에 대응하는 텍스트의 쌍(pair)으로 구성된 제1 트레이닝 세 트, 텍스트로 구성된 제2 트레이닝 세트를 포함하는 배치(batch)로부터 적어도 하나의 샘플을 선택한다. 배치 에는 제1 트레이닝 세트와 제2 트레이닝 세트가 미리 정해진 비율로 섞여 있을 수 있다. 샘플은 음성 인식을 위한 인공신경망을 학습시키기 위한 데이터로서, 트레이닝 샘플로 지칭되기도 한다. 제1 트레이닝 세트를 구성하는 음성은 음성 정보(또는, 음성 신호), 음성 정보를 전처리한 데이터, 음성 정보의 특 징 또는 특징 벡터, 음성 정보의 프레임 별 단음(phone)(또는 senone) 등 다양한 형태로 구현될 수 있으며, 실 시예는 샘플의 유형을 제한하지 않는다. 음성 정보의 샘플은 단어, 음소, 형태소, 발음 기호 단위, 구, 절, 문 장 및 문단 등 설계 의도에 따라 다양한 형태로 정의 또는 설계될 수 있고, 실시예는 샘플이 함축하는 정보의 유형을 제한하지 않는다. 단계에서, 음성 인식 학습 장치는 샘플이 제1 트레이닝 세트로부터 선택되는 경우, 샘플에 기초하여 인공 신경망에 포함된 인코딩 레이어 및 공유 디코딩 레이어를 학습시킬 수 있다. 구체적으로, 음성 인식 학습 장치 는 인코딩 레이어를 이용하여 샘플에 포함된 음성으로부터 특징을 추출하고, 공유 디코딩 레이어를 이용하여, 특징 및 적어도 하나의 토큰에 기초하여 적어도 하나의 토큰 이후로 인식되는 출력 토큰을 추정하며, 추정된 출 력 토큰 및 샘플에 포함된 음성에 대응하는 텍스트의 적어도 일부에 기초하여, 인코딩 레이어 및 공유 디코딩 레이어를 학습시킬 수 있다. 예를 들어, 음성 인식 학습 장치는 추정된 출력 토큰과 샘플에 포함된 음성에 대 응하는 텍스트의 적어도 일부의 상관성을 높일 수 있도록 학습시킬 수 있다. 단계에서, 음성 인식 학습 장치는 샘플이 제2 트레이닝 세트로부터 선택되는 경우, 샘플에 기초하여 공유 디코딩 레이어를 학습시킬 수 있다. 구체적으로, 음성 인식 학습 장치는 디코딩 레이어를 이용하여, 적어도 하 나의 토큰에 기초하여 적어도 하나의 토큰 이후로 인식되는 출력 토큰을 추정하고, 추정된 출력 토큰 및 샘플에 포함된 텍스트의 적어도 일부에 기초하여, 공유 디코딩 레이어를 학습시킬 수 있다. 도 8을 참조하면, 텍스트로만 구성된 제2 트레이닝 세트에서 샘플이 선택되는 경우, 음성 인식 학습 장치는 인 코더 쪽으로는 그래디언트(gradient)가 흐르지 않게 하여 디코더에 포함된 디코딩 레이어만 학습시킬 수 있다. 샘플이 제1 트레이닝 세트로부터 선택되는 경우, 음성 인식 학습 장치는 음성과 음성에 대응하는 텍스트의 쌍 중에서 텍스트 만으로 인코더 쪽으로는 그래디언트가 흐르지 않게 하여 디코딩 레이어만 한번 더 학습시킬 수있다. 음성 인식 학습 장치는 그래디언트를 어느 쪽으로 얼마나 흐르게 할지 게이트(gate)를 구비할 수 있고, 게이트 를 학습시킬 수 있다. 또한, 음성 인식 학습 장치는 어텐션 가중치를 학습시킬 수 있다. 나아가, 음성 인식 학습 장치는 제1 확률들 및 제2 확률들 사이의 가중치를 학습시킬 수 있다. 음성 인식 학습 장치는 샘플을 제1 트레이닝 세트에서 선택하고, 인코딩 레이어를 이용하여 샘플에 포함된 음성으로부터 특징을 추출하고, 공유 디코딩 레이어를 이용하여, 특징 및 적어도 하나의 토큰에 기초하여 적어도 하나의 토큰 이후로 인식되는 출력 토큰의 후보들의 제1 확률들을 추정하고, 공유 디코딩 레이어를 이용하여, 상기 적어도 하나의 토큰에 기초하여 적어도 하나의 토큰 이후로 인식되는 출력 토큰의 후보들의 제2 확률들을 추정하고, 제1 확률 들 및 제2 확률들 사이의 가중치에 기초하여 출력 토큰을 추정하고, 샘플에 포함된 음성에 대응하는 텍스트의 적어도 일부에 기초하여, 가중치를 학습시킬 수 있다. 도 9은 일 실시예에 따른 음성 인식 장치의 블록도이다. 도 9을 참조하면, 일 실시예에 따른 음성 인식 장치는 센서(들), 프로세서, 및 통신 인터페이스 를 포함한다. 음성 인식 장치는 메모리, 및 디스플레이를 더 포함할 수 있다. 센서 (들), 프로세서, 메모리, 통신 인터페이스, 및 디스플레이는 통신 버스를 통해 서로 통신할 수 있다. 센서(들)는 예를 들어, 마이크 센서, 음성 센서를 포함할 수 있다. 프로세서는 도 1 내지 도 6을 통해 전술한 적어도 하나의 방법 또는 적어도 하나의 방법에 대응되는 알고 리즘을 수행할 수 있다. 프로세서는 프로그램을 실행하고, 음성 인식 장치를 제어할 수 있다. 프로세서 에 의하여 실행되는 프로그램 코드는 메모리에 저장될 수 있다. 프로세서는 예를 들어, CPU(Central Processing Unit) 또는 GPU(Graphics Processing Unit)으로 구성될 수 있다. 프로세서는 음성 정보로부터 특징을 생성하고, 특징 및 현재까지 인식된 적어도 하나의 토큰을 디코딩하는 제1 디코딩 태스크를 수행하고, 현재까지 인식된 적어도 하나의 토큰을 디코딩하는 제2 디코딩 태스크를 수행하 며, 제1 디코딩 태스크의 결과 및 제2 디코딩 태스크의 결과에 기초하여, 적어도 하나의 토큰 이후로 인식되는 출력 토큰을 결정할 수 있다. 메모리는 프로세서가 처리한 데이터를 저장한다. 예를 들어, 메모리는 프로그램을 저장할 수 있다. 저장되는 프로그램은 음성 인식을 수행할 수 있도록 코딩되어 프로세서에 의해 실행 가능한 신텍스 (syntax)들의 집합일 수 있다. 메모리는 휘발성 메모리 또는 비 휘발성 메모리일 수 있다. 통신 인터페이스는 센서(들), 프로세서 및 메모리와 연결되어 데이터를 송수신할 수 있다. 통신 인터페이스는 외부의 다른 장치와 연결되어 데이터를 송수신할 수 있다. 이하에서 \"A\"를 송수신한다 라는 표현은 \"A를 나타내는 정보(information) 또는 데이터\"를 송수신하는 것을 나타낼 수 있다. 통신 인터페이스는 음성 인식 장치 내의 회로망(circuitry)으로 구현될 수 있다. 예를 들어, 통신 인터페이스는 내부 버스(internal bus) 및 외부 버스(external bus)를 포함할 수 있다. 다른 예로, 통신 인터페이스는 음성 인식 장치와 외부의 장치를 연결하는 요소일 수 있다. 통신 인터페이스는 외부의 장치로부터 데이터를 수신하여, 프로세서 및 메모리에 데이터를 전송할 수 있다. 디스플레이는 디코딩된 결과를 표시할 수 있다. 예를 들어, 음성 인식 결과가 디스플레이에 표시될 수 있다. 도시하지는 않았지만, 일 실시예에 따른 음성 인식 학습 장치는 센서(들), 프로세서, 및 통신 인터페이스를 포 함한다. 음성 인식 학습 장치는 메모리, 및 디스플레이를 더 포함할 수 있다. 센서(들), 프로세서, 메모리, 통 신 인터페이스, 및 디스플레이는 통신 버스를 통해 서로 통신할 수 있다. 센서(들)는 예를 들어, 마이크 센서, 음성 센서를 포함할 수 있다. 프로세서는 도 7 내지 도 8을 통해 전술한 적어도 하나의 방법 또는 적어도 하나의 방법에 대응되는 알고리즘을 수행할 수 있다. 프로세서는 프로그램을 실행하고, 인공신경망에서의 음성 인식 학습 장치를 제어할 수 있다. 프로세서에 의하여 실행되는 프로그램 코드는 메모리에 저장될 수 있다. 프로세서는 예를 들어, CPU(Central Processing Unit) 또는 GPU(Graphics Processing Unit)으로 구성될 수 있 다. 프로세서는 음성과 음성에 대응하는 텍스트의 쌍(pair)으로 구성된 제1 트레이닝 세트, 텍스트로 구성된 제2 트 레이닝 세트를 포함하는 배치(batch)로부터 적어도 하나의 샘플을 선택하고, 샘플이 제1 트레이닝 세트로부터 선택되는 경우, 샘플에 기초하여 인공신경망에 포함된 인코딩 레이어 및 공유 디코딩 레이어를 학습시키고, 샘 플이 제2 트레이닝 세트로부터 선택되는 경우, 샘플에 기초하여 공유 디코딩 레이어를 학습시킬 수 있다. 메모리는 프로세서가 처리한 데이터를 저장한다. 예를 들어, 메모리는 프로그램을 저장할 수 있다. 저장되는 프로그램은 음성 인식을 수행할 수 있도록 코딩되어 프로세서에 의해 실행 가능한 신텍스(syntax)들의 집합일 수 있다. 메모리는 휘발성 메모리 또는 비 휘발성 메모리일 수 있다. 통신 인터페이스는 센서(들), 프로세서 및 메모리와 연결되어 데이터를 송수신할 수 있다. 통신 인터페이스는 외부의 다른 장치와 연결되어 데이터를 송수신할 수 있다. 통신 인터페이스는 음성 인식 학습 장치 내의 회로망(circuitry)으로 구현될 수 있다. 예를 들어, 통신 인터페이스는 내부 버스(internal bus) 및 외부 버스(external bus)를 포함할 수 있다. 다른 예로, 통신 인터 페이스는 음성 인식 학습 장치와 외부의 장치를 연결하는 요소일 수 있다. 통신 인터페이스는 외부의 장 치로부터 데이터를 수신하여, 프로세서 및 메모리에 데이터를 전송할 수 있다. 이상에서 설명된 실시예들은 하드웨어 구성요소, 소프트웨어 구성요소, 및/또는 하드웨어 구성요소 및 소프트웨 어 구성요소의 조합으로 구현될 수 있다. 예를 들어, 실시예들에서 설명된 장치, 방법 및 구성요소는, 예를 들 어, 프로세서, 콘트롤러, ALU(arithmetic logic unit), 디지털 신호 프로세서(digital signal processor), 마 이크로컴퓨터, FPGA(field programmable gate array), PLU(programmable logic unit), 마이크로프로세서, 또는 명령(instruction)을 실행하고 응답할 수 있는 다른 어떠한 장치와 같이, 하나 이상의 범용 컴퓨터 또는 특수 목적 컴퓨터를 이용하여 구현될 수 있다. 처리 장치는 운영 체제(OS) 및 상기 운영 체제 상에서 수행되는 하나 이상의 소프트웨어 애플리케이션을 수행할 수 있다. 또한, 처리 장치는 소프트웨어의 실행에 응답하여, 데이터 를 접근, 저장, 조작, 처리 및 생성할 수도 있다. 이해의 편의를 위하여, 처리 장치는 하나가 사용되는 것으로"}
{"patent_id": "10-2019-0093066", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "설명된 경우도 있지만, 해당 기술분야에서 통상의 지식을 가진 자는, 처리 장치가 복수 개의 처리 요소 (processing element) 및/또는 복수 유형의 처리 요소를 포함할 수 있음을 알 수 있다. 예를 들어, 처리 장치 는 복수 개의 프로세서 또는 하나의 프로세서 및 하나의 콘트롤러를 포함할 수 있다. 또한, 병렬 프로세서 (parallel processor)와 같은, 다른 처리 구성(processing configuration)도 가능하다. 소프트웨어는 컴퓨터 프로그램(computer program), 코드(code), 명령(instruction), 또는 이들 중 하나 이상의 조합을 포함할 수 있으며, 원하는 대로 동작하도록 처리 장치를 구성하거나 독립적으로 또는 결합적으로 (collectively) 처리 장치를 명령할 수 있다. 소프트웨어 및/또는 데이터는, 처리 장치에 의하여 해석되거나 처리 장치에 명령 또는 데이터를 제공하기 위하여, 어떤 유형의 기계, 구성요소(component), 물리적 장치, 가상 장치(virtual equipment), 컴퓨터 저장 매체 또는 장치, 또는 전송되는 신호 파(signal wave)에 영구적으로, 또는 일시적으로 구체화(embody)될 수 있다. 소프트웨어는 네트워크로 연결된 컴퓨터 시스템 상에 분산되어서, 분산된 방법으로 저장되거나 실행될 수도 있다. 소프트웨어 및 데이터는 하나 이상의 컴퓨터 판독 가능 기록 매 체에 저장될 수 있다. 실시예에 따른 방법은 다양한 컴퓨터 수단을 통하여 수행될 수 있는 프로그램 명령 형태로 구현되어 컴퓨터 판 독 가능 매체에 기록될 수 있다. 상기 컴퓨터 판독 가능 매체는 프로그램 명령, 데이터 파일, 데이터 구조 등 을 단독으로 또는 조합하여 포함할 수 있다. 상기 매체에 기록되는 프로그램 명령은 실시예를 위하여 특별히 설계되고 구성된 것들이거나 컴퓨터 소프트웨어 당업자에게 공지되어 사용 가능한 것일 수도 있다. 컴퓨터 판 독 가능 기록 매체의 예에는 하드 디스크, 플로피 디스크 및 자기 테이프와 같은 자기 매체(magnetic media), CD-ROM, DVD와 같은 광기록 매체(optical media), 플롭티컬 디스크(floptical disk)와 같은 자기-광 매체 (magneto-optical media), 및 롬(ROM), 램(RAM), 플래시 메모리 등과 같은 프로그램 명령을 저장하고 수행하도 록 특별히 구성된 하드웨어 장치가 포함된다. 프로그램 명령의 예에는 컴파일러에 의해 만들어지는 것과 같은 기계어 코드뿐만 아니라 인터프리터 등을 사용해서 컴퓨터에 의해서 실행될 수 있는 고급 언어 코드를포함한다. 상기된 하드웨어 장치는 실시예의 동작을 수행하기 위해 하나 이상의 소프트웨어 모듈로서 작동하도 록 구성될 수 있으며, 그 역도 마찬가지이다."}
{"patent_id": "10-2019-0093066", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "이상과 같이 실시예들이 비록 한정된 도면에 의해 설명되었으나, 해당 기술분야에서 통상의 지식을 가진 자라면 상기를 기초로 다양한 기술적 수정 및 변형을 적용할 수 있다. 예를 들어, 설명된 기술들이 설명된 방법과 다 른 순서로 수행되거나, 및/또는 설명된 시스템, 구조, 장치, 회로 등의 구성요소들이 설명된 방법과 다른 형태 로 결합 또는 조합되거나, 다른 구성요소 또는 균등물에 의하여 대치되거나 치환되더라도 적절한 결과가 달성될 수 있다. 그러므로, 다른 구현들, 다른 실시예들 및 특허청구범위와 균등한 것들도 후술하는 특허청구범위의 범위에 속한 다."}
{"patent_id": "10-2019-0093066", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 일 실시예에 따른 음성 인식(speech recognition)을 위한 인공신경망의 동작 방법을 설명하기 위한 도면 이다. 도 2a와 도 2b는 일 실시예에 따른 인공신경망에 언어 모델 인공신경망을 결합하는 방법을 설명하기 위한 도면 이다. 도 3은 일 실시예에 따른 음성 인식 장치를 도시한 블록도이다. 도 4는 일 실시예에 따른 디코딩 방법을 설명하기 위한 순서도이다. 도 5는 일 실시예에 따른 음성 인식 방법을 설명하기 위한 순서도이다. 도 6은 일 실시예에 따른 디코딩 레이어를 일부만 공유하는 디코더를 포함하는 음성 인식 장치를 도시한 블록도 이다. 도 7과 도 8은 일 실시예에 따른 음성 인식을 위한 인공신경망의 학습 방법을 설명하기 위한 도면이다. 도 9은 일 실시예에 따른 음성 인식 장치의 블록도이다."}
