{"patent_id": "10-2024-0049800", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0152764", "출원번호": "10-2024-0049800", "발명의 명칭": "AI 서비스 제공 플랫폼에서의 GPU 자원 스케줄링 방법 및 그 장치", "출원인": "주식회사 케이티", "발명자": "전하영"}}
{"patent_id": "10-2024-0049800", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "인공지능(AI) 서비스 제공 플랫폼에서의 GPU(Graphic Processing Unit) 자원 스케줄링 방법에 있어서,AI 서비스 배포 요청 시, 상기 AI 서비스와 관련된 데이터와 클러스터에 포함된 GPU 자원과 관련된 데이터를 획득하는 단계;상기 획득된 데이터를 미리 학습된 GPU 예측모델에 입력하여 상기 클러스터에 포함된 GPU 노드 별로 GPU 자원사용량 정보 및 AI 서비스 성능 정보를 예측하는 단계;상기 예측된 GPU 자원 사용량 정보와 AI 서비스 성능 정보를 기반으로 GPU 노드별 스코어를 산출하는 단계; 및상기 산출된 GPU 노드별 스코어를 기반으로 상기 AI 서비스를 배포할 GPU 노드를 선택하는 단계를 포함하는 GPU자원 스케줄링 방법."}
{"patent_id": "10-2024-0049800", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 획득된 데이터는, AI 모델 스펙 정보, AI 서비스 요구사항 정보 및 GPU 모델 스펙 정보를 포함하는 것을특징으로 하는 GPU 자원 스케줄링 방법."}
{"patent_id": "10-2024-0049800", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서, 미리 결정된 지도학습 알고리즘을 이용하여 상기 GPU 예측모델을 생성하는 단계를 더 포함하는 GPU 자원 스케줄링 방법."}
{"patent_id": "10-2024-0049800", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서, 상기 지도학습 알고리즘은, 심층 신경망(Deep Neural Network, DNN) 알고리즘임을 특징으로 하는 GPU 자원 스케줄링 방법."}
{"patent_id": "10-2024-0049800", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제3항에 있어서, 상기 GPU 예측모델의 학습 데이터는, AI 모델 스펙 정보, GPU 모델 스펙 정보, AI 서비스 요구사항 정보, GPU자원 사용량 정보, AI 서비스 성능 정보를 포함하는 것을 특징으로 하는 GPU 자원 스케줄링 방법."}
{"patent_id": "10-2024-0049800", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서, 상기 GPU 자원 사용량 정보는 GPU 메모리 사용량을 포함하고,상기 AI 서비스 성능 정보는 상기 AI 서비스의 쓰루풋(throughput) 값과 레이턴시(latency) 값을 포함하는 것을특징으로 하는 GPU 자원 스케줄링 방법."}
{"patent_id": "10-2024-0049800", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에 있어서, 상기 산출 단계는, 아래 수학식을 이용하여 GPU 노드별 스코어를 산출하는 것을 특징으로 하는 GPU 자원 스케줄링 방법.공개특허 10-2024-0152764-3-[수학식]여기서, A는 GPU 메모리 사용량, B는 AI 서비스의 Throughput 값, C는 AI 서비스의 레이턴시 값, 는 A의 가중치, 는 B의 가중치, 는 C의 가중치임."}
{"patent_id": "10-2024-0049800", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1항에 있어서, 상기 선택 단계는, 가장 높은 스코어를 갖는 GPU 노드를 검출하고, 상기 검출된 GPU 노드를 상기 AI 서비스를 배포할 GPU 노드로선택하는 것을 특징으로 하는 GPU 자원 스케줄링 방법."}
{"patent_id": "10-2024-0049800", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1항에 있어서, 상기 선택된 GPU 노드에 컨테이너(container)를 생성하는 단계를 더 포함하는 GPU 자원 스케줄링 방법."}
{"patent_id": "10-2024-0049800", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "하나 이상의 프로세서들을 포함하는 GPU(Graphic Processing Unit) 자원 스케줄링 장치에 있어서,상기 하나 이상의 프로세서들은:AI 서비스 배포 요청 시, 상기 AI 서비스와 관련된 데이터와 클러스터에 포함된 GPU 자원과 관련된 데이터를 획득하는 것;상기 획득된 데이터를 미리 학습된 GPU 예측모델에 입력하여 상기 클러스터에 포함된 GPU 노드 별로 GPU 자원사용량 정보 및 AI 서비스 성능 정보를 예측하는 것;상기 예측된 GPU 자원 사용량 정보와 AI 서비스 성능 정보를 기반으로 GPU 노드별 스코어를 산출하는 것; 및상기 산출된 GPU 노드별 스코어를 기반으로 상기 AI 서비스를 배포할 GPU 노드를 선택하는 것을, 수행하는 GPU자원 스케줄링 장치."}
{"patent_id": "10-2024-0049800", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제10항에 있어서, 상기 획득된 데이터는, AI 모델 스펙 정보, AI 서비스 요구사항 정보 및 GPU 모델 스펙 정보를 포함하는 것을특징으로 하는 GPU 자원 스케줄링 장치."}
{"patent_id": "10-2024-0049800", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제10항에 있어서, 상기 GPU 예측모델은, 지도학습 기반의 심층 신경망(DNN) 모델임을 특징으로 하는 GPU 자원 스케줄링 장치."}
{"patent_id": "10-2024-0049800", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제10항에 있어서, 상기 GPU 자원 사용량 정보는 GPU 메모리 사용량을 포함하고,상기 AI 서비스 성능 정보는 상기 AI 서비스의 쓰루풋(throughput) 값과 레이턴시(latency) 값을 포함하는 것을특징으로 하는 GPU 자원 스케줄링 장치."}
{"patent_id": "10-2024-0049800", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제10항에 있어서,상기 하나 이상의 프로세서들은, 아래 수학식을 이용하여 GPU 노드별 스코어를 산출하는 것을 특징으로 하는공개특허 10-2024-0152764-4-GPU 자원 스케줄링 장치.[수학식]여기서, A는 GPU 메모리 사용량, B는 AI 서비스의 Throughput 값, C는 AI 서비스의 레이턴시 값, 는 A의 가중치, 는 B의 가중치, 는 C의 가중치임."}
{"patent_id": "10-2024-0049800", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제10항에 있어서, 상기 하나 이상의 프로세서들은, 가장 높은 스코어를 갖는 GPU 노드를 검출하고, 상기 검출된 GPU 노드를 상기 AI 서비스를 배포할 GPU 노드로선택하는 것을 특징으로 하는 GPU 자원 스케줄링 장치."}
{"patent_id": "10-2024-0049800", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제10항에 있어서, 상기 하나 이상의 프로세서들은,상기 선택된 GPU 노드에 컨테이너(container)를 생성하는 것을, 더 수행하는 GPU 자원 스케줄링 장치."}
{"patent_id": "10-2024-0049800", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "인공지능(AI) 서비스 제공 플랫폼에서의 GPU(Graphic Processing Unit) 자원 스케줄링 방법에 있어서,AI 서비스 배포 요청 시, 클러스터에 포함된 복수의 GPU 노드들 중에서 상기 AI 서비스의 배포가 가능한 GPU 노드들을 검출하는 단계;상기 검출된 GPU 노드들에 컨테이너를 일괄적으로 배포하는 단계;상기 컨테이너가 배포된 GPU 노드들의 자원 사용량 정보와 AI 서비스 성능 정보를 기반으로 GPU 노드별 스코어를 산출하는 단계; 및상기 산출된 GPU 노드별 스코어를 기반으로 상기 AI 서비스를 배포할 GPU 노드를 선택하는 단계를 포함하는 GPU자원 스케줄링 방법."}
{"patent_id": "10-2024-0049800", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "하나 이상의 프로세서들을 포함하는 GPU(Graphic Processing Unit) 자원 스케줄링 장치에 있어서,상기 하나 이상의 프로세서들은:AI 서비스 배포 요청 시, 클러스터에 포함된 복수의 GPU 노드들 중에서 상기 AI 서비스의 배포가 가능한 GPU 노드들을 검출하는 것;상기 검출된 GPU 노드들에 컨테이너를 일괄적으로 배포하는 것;상기 컨테이너가 배포된 GPU 노드들의 자원 사용량 정보와 AI 서비스 성능 정보를 기반으로 GPU 노드별 스코어를 산출하는 것; 및상기 산출된 GPU 노드별 스코어를 기반으로 상기 AI 서비스를 배포할 GPU 노드를 선택하는 것을, 수행하는 GPU자원 스케줄링 장치."}
{"patent_id": "10-2024-0049800", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 AI 서비스 제공 플랫폼에서의 GPU 자원 스케줄링 방법에 관한 것으로, AI 서비스 배포 요청 시, 상기 AI 서비스와 관련된 데이터와 클러스터에 포함된 GPU 자원과 관련된 데이터를 획득하는 단계; 상기 획득된 데이 터를 미리 학습된 GPU 예측모델에 입력하여 상기 클러스터에 포함된 GPU 노드 별로 GPU 자원 사용량 정보 및 AI 서비스 성능 정보를 예측하는 단계; 상기 예측된 GPU 자원 사용량 정보와 AI 서비스 성능 정보를 기반으로 GPU 노드별 스코어를 산출하는 단계; 및 상기 산출된 GPU 노드별 스코어를 기반으로 상기 AI 서비스를 배포할 GPU 노 드를 선택하는 단계를 포함한다."}
{"patent_id": "10-2024-0049800", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 다수의 GPU 노드들로 이루어진 AI 서비스 제공 플랫폼에 관한 것으로서, 보다 구체적으로는 초거대 AI 모델을 활용한 AI 서비스를 제공하기 위해 필요한 GPU 자원을 효율적으로 스케줄링하는 AI 서비스 제공 플랫 폼에 관한 것이다."}
{"patent_id": "10-2024-0049800", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "최근 들어, GPT-3 등과 같은 초거대 AI(Artificial Intelligence) 모델의 등장으로 인해 AI 성능이 급격히 향 상됨에 따라 초거대 AI 모델을 활용한 초거대 AI 서비스가 상용화되고 있으며, 초거대 AI 서비스를 제공할 수 있는 인프라에 대한 관심도 증가하고 있다. 특히, 막대한 자원량을 필요로 하는 초거대 AI 서비스를 제공하기 위해서는 GPU(Graphic Processing Unit) 자원의 비용을 최적화하기 위한 AI 서비스 제공 플랫폼을 구성하는 것 이 중요하다. 다수의 GPU들로 이루어진 AI 서비스 제공 플랫폼에서는 초거대 AI 서비스를 제공하기 위해 필요한 GPU 자원량에 대한 예측이 필요하다. 즉, 멀티 GPU 환경에서 GPU 자원을 예측하는 기술이 요구된다. 하지만, 종래의 예측 기 술은 단일 GPU 환경에서 GPU 자원을 예측하는 연구들이 대부분이다. 또한, 기존의 GPU 자원 스케줄링 기법은 주로 정적 스케줄링 방식으로 진행되었다. 하지만, 정적 스케줄링 방식 은 많은 양의 GPU 자원 확보가 사전에 필요한 초거대 AI 서비스에 대해서는 적용하기 어려운 측면이 있다. 특히, 적은 메모리의 GPU 사용 시 OOM(Out Of Memory) 에러가 발생하여 AI 서비스가 중단될 우려가 있기 때문에, 기존의 정적 스케줄링 방식은 AI 서비스의 품질을 저하시키는 문제가 있다. 따라서, 기존 정적 스케줄링 방식의 문제점을 해소하고, 초거대 AI 서비스를 제공하는 멀티 GPU 환경에서 GPU 자원을 효율적으로 스케줄링할 수 있는 방안이 필요하다. 선행기술문헌 특허문헌 (특허문헌 0001) KR 10-2023-006948 A (특허문헌 0002) KR 10-2023-0135923 A"}
{"patent_id": "10-2024-0049800", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 전술한 문제 및 다른 문제를 해결하는 것을 목적으로 한다. 또 다른 목적은 AI 서비스의 배포가 가능 한 복수의 GPU 노드들에 컨테이너를 일괄적으로 생성하여 상기 GPU 노드들의 자원 사용량 정보 및 AI 서비스 성 능 정보를 획득하고, 상기 획득된 정보를 기반으로 GPU 노드별 스코어를 산출하여 상기 AI 서비스를 배포할 최 적의 GPU 노드를 스케줄링하는 방법 및 그 장치를 제공함에 있다. 또 다른 목적은 미리 학습된 GPU 예측모델을 이용하여 클러스터에 포함된 GPU 노드 별로 GPU 자원 사용량 정보 및 AI 서비스 성능 정보를 예측하고, 상기 예측된 정보를 기반으로 GPU 노드별 스코어를 산출하여 AI 서비스를 배포할 최적의 GPU 노드를 스케줄링하는 방법 및 그 장치를 제공함에 있다."}
{"patent_id": "10-2024-0049800", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기 또는 다른 목적을 달성하기 위해 본 발명의 일 측면에 따르면, AI 서비스 배포 요청 시, 상기 AI 서비스와 관련된 데이터와 클러스터에 포함된 GPU 자원과 관련된 데이터를 획득하는 단계; 상기 획득된 데이터를 미리 학 습된 GPU 예측모델에 입력하여 상기 클러스터에 포함된 GPU 노드 별로 GPU 자원 사용량 정보 및 AI 서비스 성능 정보를 예측하는 단계; 상기 예측된 GPU 자원 사용량 정보와 AI 서비스 성능 정보를 기반으로 GPU 노드별 스코 어를 산출하는 단계; 및 상기 산출된 GPU 노드별 스코어를 기반으로 상기 AI 서비스를 배포할 GPU 노드를 선택 하는 단계를 포함하는 AI 서비스 제공 플랫폼에서의 GPU 자원 스케줄링 방법을 제공한다. 본 발명의 다른 측면에 따르면, 하나 이상의 프로세서들을 포함하는 GPU 자원 스케줄링 장치에 있어서, 상기 하 나 이상의 프로세서들은: AI 서비스 배포 요청 시, 상기 AI 서비스와 관련된 데이터와 클러스터에 포함된 GPU 자원과 관련된 데이터를 획득하는 것; 상기 획득된 데이터를 미리 학습된 GPU 예측모델에 입력하여 상기 클러스터에 포함된 GPU 노드 별로 GPU 자원 사용량 정보 및 AI 서비스 성능 정보를 예측하는 것; 상기 예측된 GPU 자 원 사용량 정보와 AI 서비스 성능 정보를 기반으로 GPU 노드별 스코어를 산출하는 것; 및 상기 산출된 GPU 노드 별 스코어를 기반으로 상기 AI 서비스를 배포할 GPU 노드를 선택하는 것을, 수행하는 GPU 자원 스케줄링 장치를 제공한다. 본 발명의 또 다른 측면에 따르면, AI 서비스 배포 요청 시, 클러스터에 포함된 복수의 GPU 노드들 중에서 상기 AI 서비스의 배포가 가능한 GPU 노드들을 검출하는 단계; 상기 검출된 GPU 노드들에 컨테이너를 일괄적으로 배 포하는 단계; 상기 컨테이너가 배포된 GPU 노드들의 자원 사용량 정보와 AI 서비스 성능 정보를 기반으로 GPU 노드별 스코어를 산출하는 단계; 및 상기 산출된 GPU 노드별 스코어를 기반으로 상기 AI 서비스를 배포할 GPU 노드를 선택하는 단계를 포함하는 AI 서비스 제공 플랫폼에서의 GPU 자원 스케줄링 방법을 제공한다. 본 발명의 또 다른 측면에 따르면, 하나 이상의 프로세서들을 포함하는 GPU 자원 스케줄링 장치에 있어서, 상기 하나 이상의 프로세서들은: AI 서비스 배포 요청 시, 클러스터에 포함된 복수의 GPU 노드들 중에서 상기 AI 서 비스의 배포가 가능한 GPU 노드들을 검출하는 것; 상기 검출된 GPU 노드들에 컨테이너를 일괄적으로 배포하는 것; 상기 컨테이너가 배포된 GPU 노드들의 자원 사용량 정보와 AI 서비스 성능 정보를 기반으로 GPU 노드별 스 코어를 산출하는 것; 및 상기 산출된 GPU 노드별 스코어를 기반으로 상기 AI 서비스를 배포할 GPU 노드를 선택 하는 것을, 수행하는 GPU 자원 스케줄링 장치를 제공한다."}
{"patent_id": "10-2024-0049800", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명의 실시 예들에 따른 GPU 자원 스케줄링 방법 및 그 장치의 효과에 대해 설명하면 다음과 같다. 본 발명의 실시 예들 중 적어도 하나에 의하면, AI 서비스 제공 플랫폼의 상태에 따라 동적 스케줄링 방식 또는 예측모델 기반 스케줄링 방식을 사용하여 AI 서비스를 배포할 최적의 GPU 노드를 효과적으로 스케줄링할 수 있 다는 장점이 있다. 또한, 본 발명의 실시 예들 중 적어도 하나에 의하면, 동적 스케줄링 방식을 이용하여 AI 서비스를 배포할 최적 의 GPU 노드를 선택함으로써, 상기 AI 서비스의 품질을 향상시킬 수 있을 뿐만 아니라 GPU 자원의 비용을 최적 화할 수 있다는 장점이 있다. 또한, 본 발명의 실시 예들 중 적어도 하나에 의하면, 미리 학습된 GPU 예측모델을 이용하여 AI 서비스를 배포 할 최적의 GPU 노드를 선택함으로써, 상기 AI 서비스의 품질을 향상시킬 수 있을 뿐만 아니라 GPU 자원의 비용 을 최적화할 수 있다는 장점이 있다. 다만, 본 발명의 실시 예들에 따른 GPU 자원 스케줄링 방법 및 그 장치가 달성할 수 있는 효과는 이상에서 언급"}
{"patent_id": "10-2024-0049800", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 2, "content": "한 것들로 제한되지 않으며, 언급하지 않은 또 다른 효과들은 아래의 기재로부터 본 발명이 속하는 기술분야에 서 통상의 지식을 가진 자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2024-0049800", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 첨부된 도면을 참조하여 본 명세서에 개시된 실시 예를 상세히 설명하되, 도면 부호에 관계없이 동일하거 나 유사한 구성요소는 동일한 참조 번호를 부여하고 이에 대한 중복되는 설명은 생략하기로 한다. 이하의 설명 에서 사용되는 구성요소에 대한 접미사 \"모듈\" 및 \"부\"는 명세서 작성의 용이함만이 고려되어 부여되거나 혼용 되는 것으로서, 그 자체로 서로 구별되는 의미 또는 역할을 갖는 것은 아니다. 즉, 본 발명에서 사용되는 '부' 라는 용어는 소프트웨어, FPGA 또는 ASIC과 같은 하드웨어 구성요소를 의미하며, '부'는 어떤 역할들을 수행한 다. 그렇지만 '부'는 소프트웨어 또는 하드웨어에 한정되는 의미는 아니다. '부'는 어드레싱할 수 있는 저장 매 체에 있도록 구성될 수도 있고 하나 또는 그 이상의 프로세서들을 재생시키도록 구성될 수도 있다. 따라서, 일 예로서 '부'는 소프트웨어 구성요소들, 객체지향 소프트웨어 구성요소들, 클래스 구성요소들 및 태스크 구성요 소들과 같은 구성요소들과, 프로세스들, 함수들, 속성들, 프로시저들, 서브루틴들, 프로그램 코드의 세그먼트들, 드라이버들, 펌웨어, 마이크로 코드, 회로, 데이터, 데이터베이스, 데이터 구조들, 테이블들, 어레 이들 및 변수들을 포함한다. 구성요소들과 '부'들 안에서 제공되는 기능은 더 작은 수의 구성요소들 및 '부'들 로 결합되거나 추가적인 구성요소들과 '부'들로 더 분리될 수 있다. 또한, 본 명세서에 개시된 실시 예를 설명함에 있어서 관련된 공지 기술에 대한 구체적인 설명이 본 명세서에 개시된 실시 예의 요지를 흐릴 수 있다고 판단되는 경우 그 상세한 설명을 생략한다. 또한, 첨부된 도면은 본 명세서에 개시된 실시 예를 쉽게 이해할 수 있도록 하기 위한 것일 뿐, 첨부된 도면에 의해 본 명세서에 개시된 기술적 사상이 제한되지 않으며, 본 발명의 사상 및 기술 범위에 포함되는 모든 변경, 균등물 내지 대체물을 포 함하는 것으로 이해되어야 한다. 본 발명은 AI 서비스의 배포가 가능한 복수의 GPU 노드들에 컨테이너를 일괄적으로 생성하여 상기 GPU 노드들의 자원 사용량 정보 및 AI 서비스 성능 정보를 획득하고, 상기 획득된 정보를 기반으로 GPU 노드별 스코어를 산출 하여 상기 AI 서비스를 배포할 최적의 GPU 노드를 스케줄링하는 방법 및 그 장치를 제안한다. 또한, 본 발명은 미리 학습된 GPU 예측모델을 이용하여 클러스터에 포함된 GPU 노드 별로 GPU 자원 사용량 정보 및 AI 서비스 성 능 정보를 예측하고, 상기 예측된 정보를 기반으로 GPU 노드별 스코어를 산출하여 AI 서비스를 배포할 최적의 GPU 노드를 스케줄링하는 방법 및 그 장치를 제안한다. 이하에서는, 본 발명의 다양한 실시 예들에 대하여, 도면을 참조하여 상세히 설명한다. 도 1은 본 발명과 관련된 AI 서비스 제공 플랫폼의 백엔드 아키텍처를 나타내는 도면이다. 도 1을 참조하면, 본 발명과 관련된 AI 서비스 제공 플랫폼의 백엔드 아키텍처는 AI 서비스 개발 서버 , 클러스터 서버, 모니터링 서버 및 CI/CD 서버를 포함할 수 있다. AI 서비스 개발 서버는 복수의 AI 모델 엔진을 포함할 수 있다. 여기서, 복수의 AI 모델 엔진은 초거대 AI 모델 엔진을 포함할 수 있다. 또한, 복수의 AI 모델 엔진은 음성 AI 모델 엔진, 거대언어모델(Large Language Model, LLM) 엔진, 비전 AI 모델 엔진 등을 포함할 수 있다. 각각의 AI 모델 엔진은 클러스터 서버(또는 클러스터 환경, 120)의 자원을 이용하여 AI 서비스를 제공할 수 있 다. 상기 AI 모델 엔진은 하나 이상의 파드(Pod) 또는 컨테이너(container)로 구동될 수 있다. 상기 파드 또는 컨테이너는 마스터 노드의 스케줄러를 통해 복수의 워커 노드들 중 적어도 하나로 배포될 수 있다. 클러스터 서버는 하나 이상의 마스터 노드와 복수의 워커 노드들을 포함할 수 있다. 여기서, 마스터 노드 는 클러스터 전체를 제어하는 역할을 수행하는 노드이고, 워커 노드는 마스터 노드의 제어 명령에 따라 파드 또 는 컨테이너가 생성되는 가상 머신 또는 물리적인 서버이다. 복수의 워커 노드들은 서로 다른 스펙의 GPU 모델을 포함할 수 있다. 상기 워커 노드에 설치 가능한 GPU 모델로 는 엔비디아(NVIDIA)의 GPU A100 모델, A30 모델, A40 모델, A6000 모델, V100 모델, P100 모델 등이 있으며 반드시 이에 제한되지는 않는다. 모니터링 서버는 컨테이너가 배포된 복수의 워커 노드들을 모니터링하여 워커 노드별 자원 사용량 정보와 AI 서비스 성능 정보(가령, throughput 값, latency 값 등)를 실시간으로 수집하는 데이터 수집부(가령, Prometheus)와 상기 수집된 데이터를 그래픽 등으로 시각화하는 데이터 시각화부(가령, Grafana)를 포함할 수 있다. CI/CD 서버는 지속적인 통합(Continuous Integration, CI) 기능을 수행하는 CI 모듈과 지속적인 배포 (Continuous Deployment, CD) 기능을 수행하는 CD 모듈을 포함할 수 있다. 도 2는 본 발명의 일 실시 예에 따른 AI 서비스 제공 플랫폼의 구성 블록도이다. 도 2를 참조하면, 본 발명의 일 실시 예에 따른 AI 서비스 제공 플랫폼은 AI 서비스 개발 서버, 클러 스터 서버, 모니터링 서버 및 GPU 스케줄링 장치를 포함할 수 있다. AI 서비스 개발 서버는 복수의 AI 모델 엔진을 포함할 수 있다. 여기서, 각각의 AI 모델 엔진은 하나 이상 의 파드 또는 컨테이너로 구동될 수 있다. 상기 파드 또는 컨테이너는 복수의 워커 노드들 중 적어도 하나로 배 포될 수 있다. 클러스터 서버는 하나 이상의 마스터 노드와 복수의 워커 노드들을 포함할 수 있다. 여기서, 복수의 워커 노드들은 서로 다른 스펙의 GPU 모델을 포함할 수 있다. 본 발명에서는 클러스터에 포함된 각각의 워커 노드를 GPU 자원의 종류에 따라 구분하고, AI 서비스를 배포할 GPU를 선택하기 위해 각 워커 노드에 GPU 모델의 종류를 식별하기 위한 값(value)을 갖는 키(key)를 설정할 수 있다. 해당 키가 설정된 워커 노드에는 해당 키 값과 동일한 값을 갖는 컨테이너만이 배포될 수 있다. 해당 방 법의 구체적인 예시로는 쿠버네티스의 테인트(Taint)/톨러레이션(Toleration) 기법이 있다. 본 실시 예에서, 쿠 버네티스 테인트의 NoSchedule 규칙은 워커 노드에 설정된 키 값과 동일한 값을 톨러레이션으로 설정하지 않은 컨테이너에 대해서는 해당 노드에 스케줄되지 않는 규칙이다. 이하, 본 실시 예에서는, 설명의 편의상, GPU 모 델의 종류를 지시하는 키 값이 설정된 워커 노드를 'GPU 노드'라 지칭하도록 한다. 모니터링 서버는 컨테이너가 배포된 복수의 GPU 노드들을 모니터링하여 GPU 노드별 자원 사용량 정보(가령, GPU 메모리 사용량)과 AI 서비스 성능 정보(가령, throughput 값, latency 값 등)를 실시간으로 수 집할 수 있다. 모니터링 서버는 수집된 정보를 GPU 스케줄링 장치로 제공할 수 있다. GPU 스케줄링 장치는 클러스터에 포함된 복수의 GPU 노드들 중에서 AI 서비스(즉, 컨테이너)를 배포할 최 적의 GPU 노드를 스케줄링할 수 있다. 이때, GPU 스케줄링 장치는 AI 서비스 제공 플랫폼의 상태에 따라 제1 GPU 자원 스케줄링 방식 또는 제2 GPU 자원 스케줄링 방식을 이용하여 AI 서비스를 배포할 최적의 GPU 노드 를 선택할 수 있다. 여기서, 제1 GPU 자원 스케줄링 방식은 동적 스케줄링 방식이다. 해당 방식의 경우, GPU 스케줄링 장치는 AI 서비스의 배포가 가능한 복수의 GPU 노드들에 컨테이너를 일괄적으로 생성하여 상기 GPU 노드들의 자원 사용 량 정보 및 AI 서비스 성능 정보를 획득하고, 상기 획득된 정보를 기반으로 GPU 노드별 스코어를 산출하며, 상 기 산출된 스코어를 기반으로 상기 AI 서비스를 배포할 최적의 GPU 노드를 스케줄링할 수 있다. 제2 GPU 자원 스케줄링 방식은 예측모델 기반 스케줄링 방식이다. 해당 방식의 경우, GPU 스케줄링 장치는 미리 학습된 GPU 예측모델을 이용하여 클러스터에 포함된 GPU 노드 별로 GPU 자원 사용량 정보 및 AI 서비스 성 능 정보를 예측하고, 상기 예측된 정보를 기반으로 GPU 노드별 스코어를 산출하며, 상기 산출된 스코어를 기반 으로 AI 서비스를 배포할 최적의 GPU 노드를 스케줄링할 수 있다. 이때, 상기 GPU 예측모델은 동적 스케줄링 방 식을 통해 획득한 학습 데이터 셋을 기반으로 생성될 수 있다. GPU 스케줄링 장치는, GPU 예측모델이 생성되기 전까지, 제1 GPU 자원 스케줄링 방식을 이용하여 AI 서비 스를 배포할 최적의 GPU 노드를 스케줄링할 수 있다. 한편, 상기 GPU 예측모델이 생성된 이후에, GPU 스케줄링 장치는 제2 GPU 자원 스케줄링 방식을 이용하여 AI 서비스를 배포할 최적의 GPU 노드를 스케줄링할 수 있 다. 도 3은 본 발명의 일 실시 예에 따른 GPU 스케줄링 장치의 구성 블록도이다. 도 3을 참조하면, 본 발명의 일 실시 예에 따른 GPU 스케줄링 장치는 동적 스케줄링부, 학습데이터 구축부, 예측모델 학습부, 예측기반 스케줄링부 및 데이터베이스를 포함할 수 있다. 도 3 에 도시된 구성요소들은 GPU 스케줄링 장치를 구현하는데 있어서 필수적인 것은 아니어서, 본 명세서 상에서 설 명되는 GPU 스케줄링 장치는 위에서 열거된 구성요소들 보다 많거나 또는 적은 구성요소들을 가질 수 있다. 동적 스케줄링부는, AI 서비스 배포 요청 시, 동적 스케줄링 방식을 이용하여 상기 AI 서비스를 배포할 최 적의 GPU 노드를 실시간으로 스케줄링할 수 있다.좀 더 구체적으로, 동적 스케줄링부는 클러스터에 포함된 복수의 GPU 노드들 중에서 AI 서비스의 배포가 가능한 GPU 노드들을 검출하고, 상기 검출된 GPU 노드들에 소정의 컨테이너를 일괄적으로 생성할 수 있다. 이때, 동적 스케줄링부는 각 GPU 노드에 설정된 키 값을 각 GPU 노드에 대응하는 컨테이너에 설정할 수 있 다. 동적 스케줄링부는 컨테이너가 배포된 GPU 노드들의 자원 사용량 정보 및 AI 서비스 성능 정보를 획득하고, 상기 획득된 정보를 기반으로 GPU 노드별 스코어를 산출할 수 있다. 여기서, 자원 사용량 정보는 GPU 메모리 사용량을 포함할 수 있다. 또한, AI 서비스 성능 정보는 AI 서비스의 throughput 값(RPS: Requests per second, TPS: Tokens per second 등) 및 latency 값(P95 latency: 95th percentile latency 등)을 포함할 수 있다. 일 예로, 동적 스케줄링부는 아래 수학식 1을 이용하여 GPU 노드별 스코어를 산출할 수 있다. 수학식 1"}
{"patent_id": "10-2024-0049800", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "여기서, A는 GPU 메모리 사용량(%) * 1/100, B는 Throughput(RPS)에 대한 표준 정규분포 값, C는 1 - Latency/Max Latency(if Latency > Max Latency, C=0), 는 A의 가중치, 는 B의 가중치, 는 C의 가중치 임. 동적 스케줄링부는 산출된 GPU 노드별 스코어를 기반으로 AI 서비스를 배포할 최적의 GPU 노드를 선택할 수 있다. 즉, 동적 스케줄링부는 가장 높은 스코어를 갖는 GPU 노드를 AI 서비스를 배포할 최적의 GPU 노 드로 선택할 수 있다. 일 예로, 동적 스케줄링부는 쿠버네티스 테인트의 NoExecute 규칙을 적용하여 스케줄링을 수행할 수 있다. 즉, 동적 스케줄링부는 가장 높은 스코어를 갖는 GPU 노드의 키 값을 그대로 유지하는 반면, 상기 가장 높 은 스코어를 갖는 GPU 노드를 제외한 나머지 노드들의 키 값을 다른 값으로 변경함으로써, 해당 키 값을 갖지 않는 컨테이너를 해당 GPU 노드로부터 축출(제거)할 수 있다. 학습데이터 구축부는 지도학습 기반의 GPU 예측모델을 생성하기 위한 학습 데이터 셋을 구축할 수 있다. 학습 데이터 셋은, AI 모델 스펙 정보, GPU 모델 스펙 정보, AI 서비스 요구사항 정보, GPU 자원 사용량 정보 (가령, GPU 메모리 사용량), AI 서비스 성능 정보(가령, Throughput 값, Latency 값)를 포함할 수 있다. 여기 서, AI 모델 스펙 정보는 모델 종류(가령, transformer 계열 등), 모델 파라미터 크기, 배치 크기, 모델 하이퍼 파라미터 등을 포함할 수 있다. AI 서비스 요구사항 정보는 입출력 데이터 평균 사이즈 정보, P95 Latency 제약 사항 등을 포함할 수 있다. GPU 모델 스펙 정보는 GPU 아키텍처, 메모리 사이즈 등을 포함할 수 있다. GPU 모델 스펙 정보는 여러 개의 GPU 모델들을 조합한 멀티 GPU 모델에 관한 정보를 포함할 수 있다. 학습데이터 구축부는 상술한 동적 스케줄링 프로세스를 통해 학습 데이터 셋을 구축할 수 있다. 즉, 학습 데이터 구축부는, 동적 스케줄링 프로세스가 실행될 때, AI 서비스의 요구사항, AI 모델 스펙, GPU 모델 스펙, GPU 메모리 사용량 및 AI 서비스 성능 정보 등을 매칭시켜 학습 데이터 셋을 구축할 수 있다. 예측모델 학습부는 지도학습 알고리즘을 이용하여 미리 구축된 학습 데이터 셋을 기반으로 GPU 예측모델을 생성할 수 있다. 상기 지도학습 알고리즘으로는 심층 신경망(Deep Neural Network, DNN) 알고리즘과 같은 딥러 닝(deep learning) 알고리즘이 사용될 수 있으며 반드시 이에 제한되지는 않는다. 이러한 GPU 예측모델은 AI 모델 스펙 정보, GPU 모델 스펙 정보 및 AI 서비스 요구사항 정보 중 적어도 하나를 포함하는 입력 데이터를 기반으로 GPU 자원 사용량 정보와 AI 서비스 성능 정보를 포함하는 출력 데이터를 예측 할 수 있다. 상기 GPU 예측모델은 AI 서비스를 배포할 최적의 GPU 자원을 스케줄링하기 위해 사용될 수 있다. 또한, 상기 GPU 예측모델은, 신규 AI 서비스 배포 시, 해당 서비스를 제공하기 위해 필요한 GPU 자원의 비용을 최적화하기 위한 인프라를 구성하기 위해 사용될 수 있다. 예측기반 스케줄링부는, AI 서비스 배포 요청 시, 예측모델 기반 스케줄링 방식을 이용하여 상기 AI 서비 스를 배포할 최적의 GPU 노드를 스케줄링할 수 있다.좀 더 구체적으로, 예측기반 스케줄링부는 미리 학습된 GPU 예측모델을 이용하여 클러스터에 포함된 GPU 노드 별로 GPU 자원 사용량 정보 및 AI 서비스 성능 정보를 예측할 수 있다. 예측기반 스케줄링부는 상기 예측된 정보를 기반으로 GPU 노드별 스코어를 산출할 수 있다. 이때, 예측기 반 스케줄링부는 상술한 수학식 1을 이용하여 GPU 노드별 스코어를 산출할 수 있다. 예측기반 스케줄링부는 산출된 GPU 노드별 스코어를 기반으로 AI 서비스를 배포할 최적의 GPU 노드를 선택 할 수 있다. 한편, 예측기반 스케줄링부는, 신규 AI 서비스 배포 시, 미리 학습된 GPU 예측모델을 이용하여 GPU 자원 사용량 정보 및 AI 서비스 성능 정보를 예측하고, 상기 예측된 정보를 기반으로 GPU 자원의 비용을 최적화하기 위한 인프라를 구성할 수 있다. 데이터베이스는 AI 서비스 제공 플랫폼에서의 GPU 자원 스케줄링과 관련된 데이터를 저장할 수 있다. 또한, 데이터베이스는 GPU 예측모델을 생성하기 위한 학습 데이터를 저장할 수 있다. 이상 상술한 바와 같이, 본 발명의 일 실시 예에 따른 GPU 스케줄링 장치는 AI 서비스 제공 플랫폼의 상태에 따 라 동적 스케줄링 방식 또는 예측모델 기반 스케줄링 방식을 사용하여 AI 서비스를 배포할 최적의 GPU 노드를 효과적으로 스케줄링할 수 있다. 도 4는 본 발명의 일 실시 예에 따른 GPU 자원 스케줄링 방법을 설명하는 흐름도이다. 상기 GPU 자원 스케줄링 방법은 GPU 스케줄링 장치에 의해 수행될 수 있다. 도시된 흐름도에서는 GPU 자원 스케줄링 방법을 복수 개의 단계로 나누어 기재하였으나, 적어도 일부의 단계들은 순서를 바꾸어 수행되거나, 다른 단계와 결합되어 함께 수행되거나, 생략되거나, 세부 단계들로 나뉘어 수행되거나, 또는 도시되지 않은 하나 이상의 단계가 부가 되어 수행될 수 있다. 도 4를 참조하면, 본 발명에 따른 GPU 스케줄링 장치는 AI 서비스 배포 요청 신호가 수신되는지 여부를 확 인할 수 있다(S410). 상기 410 단계의 확인 결과, AI 서비스 배포 요청 신호가 수신되는 경우, GPU 스케줄링 장치는 클러스터에 포함된 복수의 GPU 노드들 중에서 AI 서비스의 배포가 가능한 GPU 노드들을 검출할 수 있다(S420). GPU 스케줄링 장치는 상기 검출된 GPU 노드들에 소정의 컨테이너를 일괄적으로 생성할 수 있다(S430). 이 때, GPU 스케줄링 장치는 각 GPU 노드에 설정된 키 값을 각 GPU 노드에 대응하는 컨테이너에 설정할 수 있 다. 상기 GPU 노드에 설정된 키 값은 GPU 모델의 종류를 식별하는 값이다. GPU 스케줄링 장치는 소정의 컨테이너가 배포(생성)된 GPU 노드들의 자원 사용량 정보를 모니터링 서버 로부터 획득할 수 있다(S440). 여기서, 상기 자원 사용량 정보는 GPU 메모리 사용량에 관한 정보를 포함할 수 있다. GPU 스케줄링 장치는 소정의 컨테이너가 배포된 GPU 노드들의 AI 서비스 성능 정보를 모니터링 서버 로부터 획득할 수 있다(S450). 여기서, 상기 AI 서비스 성능 정보는 AI 서비스의 throughput 값 및 latency 값 을 포함할 수 있다. GPU 스케줄링 장치는 GPU 노드별 자원 사용량 정보 및 AI 서비스 성능 정보를 기반으로 GPU 노드별 스코어 를 산출할 수 있다(S460). 일 예로, GPU 스케줄링 장치는 상술한 수학식 1을 이용하여 GPU 노드별 스코어 를 산출할 수 있다. GPU 스케줄링 장치는 산출된 GPU 노드별 스코어를 기반으로 AI 서비스를 배포할 최적의 GPU 노드를 선택할 수 있다(S470). 즉, GPU 스케줄링 장치는 가장 높은 스코어를 갖는 GPU 노드를 AI 서비스를 배포할 최적의 GPU 노드로 선택할 수 있다. 일 예로, GPU 스케줄링 장치는 쿠버네티스 테인트의 NoExecute 규칙을 적용하여 스케줄링을 수행할 수 있 다. 즉, GPU 스케줄링 장치는 가장 높은 스코어를 갖는 GPU 노드의 키 값을 그대로 유지하는 반면, 상기 가장 높은 스코어를 갖는 GPU 노드를 제외한 나머지 노드들의 키 값을 다른 값으로 변경함으로써, 해당 키 값을 갖지 않는 컨테이너를 해당 GPU 노드로부터 축출(제거)할 수 있다. 이후, 컨테이너 배포가 완료되면, GPU 스케 줄링 장치는 가장 높은 스코어를 갖는 GPU 노드를 제외한 나머지 GPU 노드들의 키 값을 초기값으로 복원시킬 수 있다. 이상 상술한 바와 같이, 본 발명의 일 실시 예에 따른 GPU 자원 스케줄링 방법은, AI 서비스 배포 요청 시, 상 기 AI 서비스의 배포가 가능한 복수의 GPU 노드들에 컨테이너를 일괄적으로 생성하여 상기 GPU 노드들의 자원 사용량 정보 및 AI 서비스 성능 정보를 획득하고, 상기 획득된 정보를 기반으로 GPU 노드별 스코어를 산출하여 상기 AI 서비스를 배포할 최적의 GPU 노드를 스케줄링할 수 있다. 또한, GPU 자원 스케줄링 방법은 동적 스케줄 링 방식을 이용하여 AI 서비스를 배포할 최적의 GPU 노드를 선택함으로써, 상기 AI 서비스의 품질을 향상시킬 수 있을 뿐만 아니라 GPU 자원의 비용을 최적화할 수 있다. 또한, GPU 자원 스케줄링 방법은 메모리 부족으로 인한 OOM(Out Of Memory) 에러 현상을 사전에 방지할 수 있다. 도 5는 본 발명의 일 실시 예에 따른 GPU 예측모델 학습 방법을 설명하는 흐름도이다. 상기 GPU 예측모델 학습 방법은 GPU 스케줄링 장치에 의해 수행될 수 있다. 도시된 흐름도에서는 GPU 예측모델 학습 방법을 복수 개의 단계로 나누어 기재하였으나, 적어도 일부의 단계들은 순서를 바꾸어 수행되거나, 다른 단계와 결합되어 함께 수행되거나, 생략되거나, 세부 단계들로 나뉘어 수행되거나, 또는 도시되지 않은 하나 이상의 단계가 부가 되어 수행될 수 있다. 도 5를 참조하면, 본 발명에 따른 GPU 스케줄링 장치는 GPU 자원 사용량 및 AI 서비스 성능을 예측하기 위 한 모델을 학습하기 위해 필요한 데이터를 수집할 수 있다(S510). 여기서, 수집 대상 데이터는 AI 모델 스펙 정 보, GPU 모델 스펙 정보, AI 서비스 요구사항 정보, GPU 자원 사용량 정보(가령, GPU 메모리 사용량), AI 서비 스 성능 정보(가령, Throughput 값, Latency 값) 등을 포함할 수 있다. 상기 GPU 모델 스펙 정보는 여러 개의 GPU 모델들을 조합한 멀티 GPU 모델에 관한 정보를 포함할 수 있다. GPU 스케줄링 장치는 상기 수집된 데이터를 기반으로 지도학습 알고리즘의 변수를 결정할 수 있다(S520). 일 예로, 도 6에 도시된 바와 같이, GPU 스케줄링 장치는 미리 수집된 데이터들 중 AI 모델 스펙 정보, GPU 모델 스펙 정보 및 AI 서비스 요구사항 정보를 지도학습 알고리즘의 종속 변수로 결정할 수 있고, 상 기 종속 변수를 제외한 나머지 데이터들, 즉 GPU 자원 사용량 정보 및 AI 서비스 성능 정보를 해당 알고리즘의 독립 변수로 결정할 수 있다. GPU 스케줄링 장치는 독립 변수 및 종속 변수로 결정된 학습 데이터를 전 처리하는 동작을 수행할 수 있다 (S530). 일 예로, 상기 GPU 스케줄링 장치는 학습 데이터의 결측치 및 이상치를 검출하고, 상기 검출된 결 측치 및 이상치를 미리 결정된 전 처리 방식에 따라 보정할 수 있다. GPU 스케줄링 장치는 전 처리된 학습 데이터를 훈련 데이터 셋(training data set)과 시험 데이터 셋(test data set)으로 분류할 수 있다(S540). 여기서, 훈련 데이터 셋은 지도학습 모델을 생성하기 위해 사용될 수 있 고, 시험 데이터 셋은 지도학습 모델을 검증하기 위해 사용될 수 있다. GPU 스케줄링 장치는 훈련 데이터 셋을 기반으로 미리 결정된 지도학습 알고리즘을 수행할 수 있다(S550). 가령, 도 6에 도시된 바와 같이, 상기 지도학습 알고리즘으로는 대표적인 딥러닝 알고리즘 중 하나인 심층 신경 망(DNN) 알고리즘이 사용될 수 있으며 반드시 이에 제한되지는 않는다. GPU 스케줄링 장치는, 지도학습 알고리즘의 종속 변수에 관한 예측 정확도가 기준치 이상이 될 때까지, 해 당 지도학습 알고리즘을 반복적으로 수행할 수 있다(S560). 상기 종속 변수에 관한 예측 정확도가 기준치 이상인 경우, GPU 스케줄링 장치는 상술한 지도학습 과정을 통해 GPU 자원 사용량 및 AI 서비스 성능을 예측하기 위한 GPU 예측모델을 생성할 수 있다(S570). GPU 스케줄링 장치는 시험 데이터 셋을 기반으로 GPU 예측모델의 성능을 검증할 수 있다(S580). 이러한 GPU 예측모델은 독립 변수에 해당하는 입력 데이터를 기반으로 종속 변수에 해당하는 출력 데이터를 예 측(또는 추론)할 수 있다. 상기 GPU 예측모델은 AI 서비스 제공 플랫폼에서 AI 서비스를 배포할 최적의 GPU 자 원을 스케줄링하기 위해 사용될 수 있다. 또한, 상기 GPU 예측모델은, 신규 AI 서비스 배포 시, 해당 서비스를 제공하기 위해 필요한 GPU 자원의 비용을 최적화하기 위한 인프라를 구성하기 위해 사용될 수 있다. 도 7은 본 발명의 다른 실시 예에 따른 GPU 자원 스케줄링 방법을 설명하는 흐름도이다. 상기 GPU 자원 스케줄 링 방법은 GPU 스케줄링 장치에 의해 수행될 수 있다. 도시된 흐름도에서는 GPU 자원 스케줄링 방법을 복 수 개의 단계로 나누어 기재하였으나, 적어도 일부의 단계들은 순서를 바꾸어 수행되거나, 다른 단계와 결합되 어 함께 수행되거나, 생략되거나, 세부 단계들로 나뉘어 수행되거나, 또는 도시되지 않은 하나 이상의 단계가 부가되어 수행될 수 있다. 도 7을 참조하면, 본 발명에 따른 GPU 스케줄링 장치는 AI 서비스 배포 요청 신호가 수신되는지 여부를 확 인할 수 있다(S710). 상기 710 단계의 확인 결과, AI 서비스 배포 요청 신호가 수신되는 경우, GPU 스케줄링 장치는 AI 서비스 및 GPU 자원과 관련된 입력 데이터를 획득할 수 있다(S720). 여기서, 상기 입력 데이터는, GPU 예측모델에 입력 되는 데이터로서, GPU 모델 스펙 정보, AI 서비스의 모델 스펙 정보, AI 서비스의 요구사항 정보 중 적어도 하 나를 포함할 수 있다. 상기 GPU 모델 스펙 정보는 워커 노드에 설치된 GPU 모델의 스펙 정보를 포함할 수 있다. 또한, 상기 GPU 모델 스펙 정보는 여러 개의 GPU 모델을 조합한 멀티 GPU 모델에 관한 정보를 포함할 수 있다. GPU 스케줄링 장치는 미리 학습된 GPU 예측모델을 호출할 수 있다(S730). GPU 스케줄링 장치는 미리 학습된 GPU 예측모델을 이용하여 입력 데이터를 기반으로 GPU 자원 사용량 정보 (가령, GPU 메모리 사용량) 및 AI 서비스 성능 정보(가령, throughput 값, latency 값)을 예측할 수 있다 (S740). 가령, 도 8에 도시된 바와 같이, GPU 스케줄링 장치는 AI 모델 스펙 정보, GPU 모델 스펙 정보 및 AI 서비 스 요구사항 정보를 포함하는 입력 데이터를 GPU 예측모델에 입력하여 GPU 메모리 사용량, AI 서비스 의 throughput 값, AI 서비스의 latency 값을 포함하는 출력 데이터를 예측할 수 있다. GPU 스케줄링 장치는, 클러스터에 포함된 모든 GPU 노드에 대해, 상술한 720 단계 내지 740 단계를 반복적 으로 수행할 수 있다(S750). 즉, GPU 스케줄링 장치는 미리 학습된 GPU 예측모델을 이용하여 클러스터에 포함된 GPU 노드 별로 GPU 자원 사용량 정보 및 AI 서비스 성능 정보를 예측할 수 있다. 클러스터에 포함된 모든 GPU 노드에 대한 예측이 완료되면, GPU 스케줄링 장치는 상기 예측된 GPU 자원 사 용량 정보 및 AI 서비스 성능 정보를 기반으로 GPU 노드별 스코어를 산출할 수 있다(S760). 이때, GPU 스케줄링 장치는 상술한 수학식 1을 이용하여 GPU 노드별 스코어를 산출할 수 있다. GPU 스케줄링 장치는 산출된 GPU 노드별 스코어를 기반으로 AI 서비스를 배포할 최적의 GPU 노드를 선택할 수 있다(S770). 즉, GPU 스케줄링 장치는 가장 높은 스코어를 갖는 GPU 노드를 검출하고, 상기 검출된 GPU 노드를 AI 서비스를 배포할 최적의 GPU 노드로 선택할 수 있다. GPU 스케줄링 장치는 선택된 GPU 노드에 컨테이너를 생성할 수 있다. 이상 상술한 바와 같이, GPU 스케줄링 장치는 미리 학습된 GPU 예측모델을 이용하여 클러스터에 포함된 GPU 노드 별로 GPU 자원 사용량 정보 및 AI 서비스 성능 정보 예측하고, 상기 예측된 정보를 기반으로 GPU 노드 별 스코어를 산출하여 AI 서비스를 배포할 최적의 GPU 노드를 스케줄링할 수 있다. 또한, GPU 자원 스케줄링 방 법은 미리 학습된 GPU 예측모델을 이용하여 AI 서비스를 배포할 최적의 GPU 노드를 선택함으로써, 상기 AI 서비 스의 품질을 향상시킬 수 있을 뿐만 아니라 GPU 자원의 비용을 최적화할 수 있다. 또한, GPU 스케줄링 장치 는 GPU 예측모델의 입력 데이터로 들어가는 GPU 모델 스펙 정보를 여러 개의 GPU 모델 조합으로 사용함으 로써, 멀티 GPU 등 보다 확장성 있는 스케줄링을 수행할 수 있다. 또한, GPU 스케줄링 장치는 GPU 예측모 델을 이용하여 GPU 메모리 사용량 및 AI 서비스 성능을 미리 예측함으로써, 추후 신규 AI 서비스 배포 시, 해당 서비스를 제공하기 위해 필요한 GPU 자원의 비용이 최적화된 인프라를 구성할 수 있다. 도 9는 본 발명의 일 실시 예에 따른 컴퓨팅 장치의 구성 블록도이다. 도 9를 참조하면, 본 발명의 일 실시 예에 따른 컴퓨팅 장치는 적어도 하나의 프로세서, 컴퓨터 판독 가능 저장 매체 및 통신 버스를 포함한다. 상기 컴퓨팅 장치는 상술한 GPU 스케줄링 장치 또는 상기 GPU 스케줄링 장치를 구성하는 요소들(310~340)을 구현할 수 있다. 프로세서는 컴퓨팅 장치로 하여금 앞서 언급된 예시적인 실시 예에 따라 동작하도록 할 수 있다. 예 컨대, 프로세서는 컴퓨터 판독 가능 저장 매체에 저장된 하나 이상의 프로그램들을 실행할 수 있다. 상기 하나 이상의 프로그램들은 하나 이상의 컴퓨터 실행 가능 명령어를 포함할 수 있으며, 상기 컴퓨터실행 가능 명령어는 프로세서에 의해 실행되는 경우 컴퓨팅 장치로 하여금 예시적인 실시 예에 따른 동작들을 수행하도록 구성될 수 있다. 컴퓨터 판독 가능 저장 매체는 컴퓨터 실행 가능 명령어 내지 프로그램 코드, 프로그램 데이터 및/또는 다 른 적합한 형태의 정보를 저장하도록 구성된다. 컴퓨터 판독 가능 저장 매체에 저장된 프로그램은 프 로세서에 의해 실행 가능한 명령어의 집합을 포함한다. 일 실시 예에서, 컴퓨터 판독 가능 저장 매체(92 0)는 메모리(랜덤 액세스 메모리와 같은 휘발성 메모리, 비휘발성 메모리, 또는 이들의 적절한 조합), 하나 이 상의 자기 디스크 저장 디바이스들, 광학 디스크 저장 디바이스들, 플래시 메모리 디바이스들, 그 밖에 컴퓨팅 장치에 의해 액세스되고 원하는 정보를 저장할 수 있는 다른 형태의 저장 매체, 또는 이들의 적합한 조합 일 수 있다. 통신 버스는 프로세서, 컴퓨터 판독 가능 저장 매체를 포함하여 컴퓨팅 장치의 다른 다양 한 컴포넌트들을 상호 연결한다. 컴퓨팅 장치는 또한 하나 이상의 입출력 장치를 위한 인터페이스를 제공하는 하나 이상의 입출력 인 터페이스 및 하나 이상의 네트워크 통신 인터페이스를 포함할 수 있다. 입출력 인터페이스 및 네트워크 통신 인터페이스는 통신 버스에 연결된다. 입출력 장치는 입출력 인터페이스를 통해 컴퓨팅 장치의 다른 컴포넌트들에 연결될 수 있다. 예 시적인 입출력 장치는 포인팅 장치(마우스 또는 트랙패드 등), 키보드, 터치 입력 장치(터치패드 또는 터 치스크린 등), 음성 또는 소리 입력 장치, 다양한 종류의 센서 장치 및/또는 촬영 장치와 같은 입력 장치, 및/ 또는 디스플레이 장치, 프린터, 스피커 및/또는 네트워크 카드와 같은 출력 장치를 포함할 수 있다. 예시적인 입출력 장치는 컴퓨팅 장치를 구성하는 일 컴포넌트로서 컴퓨팅 장치의 내부에 포함될 수도 있 고, 컴퓨팅 장치와는 구별되는 별개의 장치로 컴퓨팅 장치와 연결될 수도 있다. 전술한 본 발명은, 프로그램이 기록된 매체에 컴퓨터가 읽을 수 있는 코드로서 구현하는 것이 가능하다. 컴퓨터 가 읽을 수 있는 매체는, 컴퓨터로 실행 가능한 프로그램을 계속 저장하거나, 실행 또는 다운로드를 위해 임시 저장하는 것일 수도 있다. 또한, 매체는 단일 또는 수개 하드웨어가 결합된 형태의 다양한 기록수단 또는 저장 수단일 수 있는데, 어떤 컴퓨터 시스템에 직접 접속되는 매체에 한정되지 않고, 네트워크 상에 분산 존재하는 것일 수도 있다. 매체의 예시로는, 하드 디스크, 플로피 디스크 및 자기 테이프와 같은 자기 매체, CD-ROM 및 DVD와 같은 광기록 매체, 플롭티컬 디스크(floptical disk)와 같은 자기-광 매체(magneto-optical medium), 및 ROM, RAM, 플래시 메모리 등을 포함하여 프로그램 명령어가 저장되도록 구성된 것이 있을 수 있다. 또한, 다른 매체의 예시로, 애플리케이션을 유통하는 앱 스토어나 기타 다양한 소프트웨어를 공급 내지 유통하는 사이트, 서버 등에서 관리하는 기록매체 내지 저장매체도 들 수 있다. 따라서, 상기의 상세한 설명은 모든 면에서 제한 적으로 해석되어서는 아니되고 예시적인 것으로 고려되어야 한다. 본 발명의 범위는 첨부된 청구항의 합리적 해 석에 의해 결정되어야 하고, 본 발명의 등가적 범위 내에서의 모든 변경은 본 발명의 범위에 포함된다."}
{"patent_id": "10-2024-0049800", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명과 관련된 AI 서비스 제공 플랫폼의 백엔드 아키텍처를 나타내는 도면; 도 2는 본 발명의 일 실시 예에 따른 AI 서비스 제공 플랫폼의 구성 블록도; 도 3은 본 발명의 일 실시 예에 따른 GPU 스케줄링 장치의 구성 블록도; 도 4는 본 발명의 일 실시 예에 따른 GPU 자원 스케줄링 방법을 설명하는 흐름도; 도 5는 본 발명의 일 실시 예에 따른 GPU 예측모델 학습 방법을 설명하는 흐름도; 도 6은 도 5의 GPU 예측모델 학습 방법을 설명하기 위해 참조되는 도면; 도 7은 본 발명의 다른 실시 예에 따른 GPU 자원 스케줄링 방법을 설명하는 흐름도; 도 8은 도 7의 GPU 스케줄링 방법을 설명하기 위해 참조되는 도면; 도 9는 본 발명의 일 실시 예에 따른 컴퓨팅 장치의 구성 블록도."}
