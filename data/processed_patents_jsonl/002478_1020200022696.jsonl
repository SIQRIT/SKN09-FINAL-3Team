{"patent_id": "10-2020-0022696", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2021-0108027", "출원번호": "10-2020-0022696", "발명의 명칭": "전자 장치 및 그 제어 방법", "출원인": "삼성전자주식회사", "발명자": "임형준"}}
{"patent_id": "10-2020-0022696", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "전자 장치에 있어서,다운스케일링(downscaling)을 위한 복수의 필터 정보가 저장된 메모리; 및 입력 영상의 에지 정보에 기초하여 상기 저장된 복수의 필터 정보 중 하나를 획득하고, 상기 획득된 필터 정보에 기초하여 상기 입력 영상을 다운스케일링하여 출력 영상을 획득하는 프로세서;를 포함하며, 상기 복수의 필터 정보는,영상을 인공 지능 모델에 입력하여 획득된 인핸스(enhance) 영상 및 상기 인핸스 영상을 다운스케일링하여 획득된 타겟 영상에 기초하여 학습되는, 전자 장치."}
{"patent_id": "10-2020-0022696", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 인공 지능 모델은, 초해상도 처리(super resolution)를 수행하도록 학습된 인공 지능 모델이며,상기 인핸스 영상은, 상기 인공 지능 모델에 포함된 복수의 레이어 중 디테일 향상 처리를 위한 일부 레이어에 기초하여 디테일이 향상된 영상인, 전자 장치."}
{"patent_id": "10-2020-0022696", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 복수의 필터 정보는, 상이한 에지 정보에 따라 구분된 복수의 클래스 각각에 대응되는 필터 정보를 포함하며, 상기 복수의 클래스 각각에 대응되는 필터 정보는, 상기 복수의 클래스 각각에 대응되는 에지 정보를 포함하는 인핸스 영상 및 상기 인핸스 영상에 대응되는 타겟영상에 기초하여 학습되는, 전자 장치."}
{"patent_id": "10-2020-0022696", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서,상기 프로세서는, 상기 인핸스 영상을 복수의 픽셀 영역으로 구분하고, 각 픽셀 영역에 포함된 에지 정보에 기초하여 각 픽셀 영역을 상기 복수의 클래스 중 하나로 구분하고,상기 각 픽셀 영역이 속한 클래스의 필터 정보를 상기 각 픽셀 영역 및 상기 각 픽셀 영역에 대응되는 인핸스영상의 픽셀 영역에 기초하여 학습시키는, 전자 장치."}
{"patent_id": "10-2020-0022696", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서,상기 프로세서는, 공개특허 10-2021-0108027-3-상기 각 픽셀 영역에 상기 각 픽셀 영역이 속한 클래스의 필터 정보를 곱한 값과 상기 각 픽셀 영역에 대응되는인핸스 영상의 픽셀 영역의 값의 차이가 최소가 되도록 상기 필터 정보를 학습시키는, 전자 장치."}
{"patent_id": "10-2020-0022696", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제3항에 있어서,상기 복수의 필터 정보는, 상이한 에지 정보 및 스케일링 팩터에 따라 구분된 복수의 클래스 각각에 대응되는 필터 정보를 포함하며, 상기 스케일링 팩터는 다운스케일링 비율 또는 다운스케일링 방향 중 적어도 하나를 포함하는, 전자 장치."}
{"patent_id": "10-2020-0022696", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제3항에 있어서,상기 상이한 에지 정보는,영상의 에지 강도, 에지 방향 또는 콘트라스트 중 적어도 하나가 상이한, 전자 장치."}
{"patent_id": "10-2020-0022696", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서,상기 프로세서는, 상기 영상의 에지 강도에 기초하여 스무스 영역, 텍스처 영역 및 에지 영역으로 구분하고,상기 텍스처 영역 및 상기 에지 영역 각각을 상기 콘트라스트에 기초하여 저콘트라스트 영역 및 고 콘트라스트영역으로 구분하고, 상기 저 콘트라스트 영역 및 상기 고 콘트라스트 영역을 상기 에지 방향에 기초하여 복수의 에지 방향 영역으로구분하고, 상기 구분된 각 영역들을 상기 복수의 클래스로 분류하는, 전자 장치."}
{"patent_id": "10-2020-0022696", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1항에 있어서,상기 타겟 영상은, 상기 인핸스 영상을 저역 통과 필터를 이용하여 필터링한 후 상기 필터링된 영상에 대한 anti-aliasing 보간을수행하여 상기 인핸스 영상을 다운스케일링함으로써 획득되는, 전자 장치."}
{"patent_id": "10-2020-0022696", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제1항에 있어서,상기 복수의 필터 정보는,상기 전자 장치 또는 외부 장치에서 학습되는, 전자 장치."}
{"patent_id": "10-2020-0022696", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "다운스케일링(downscaling)을 위한 복수의 필터 정보를 저장하는 전자 장치의 제어 방법에 있어서, 입력 영상의 에지 정보에 기초하여 상기 복수의 필터 정보 중 하나를 획득하는 단계; 및 상기 획득된 필터 정보에 기초하여 상기 입력 영상을 다운스케일링하여 출력 영상을 획득하는 단계;를포함하며, 상기 복수의 필터 정보는,영상을 인공 지능 모델에 입력하여 획득된 인핸스(enhance) 영상 및 상기 인핸스 영상을 다운스케일링하여 획득공개특허 10-2021-0108027-4-된 타겟 영상에 기초하여 학습되는, 제어 방법."}
{"patent_id": "10-2020-0022696", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항에 있어서,상기 인공 지능 모델은, 초해상도 처리(super resolution)를 수행하도록 학습된 인공 지능 모델이며,상기 인핸스 영상은, 상기 인공 지능 모델에 포함된 복수의 레이어 중 디테일 향상 처리를 위한 일부 레이어에 기초하여 디테일이 향상된 영상인, 제어 방법."}
{"patent_id": "10-2020-0022696", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제11항에 있어서,상기 복수의 필터 정보는, 상이한 에지 정보에 따라 구분된 복수의 클래스 각각에 대응되는 필터 정보를 포함하며, 상기 복수의 클래스 각각에 대응되는 필터 정보는, 상기 복수의 클래스 각각에 대응되는 에지 정보를 포함하는 인핸스 영상 및 상기 인핸스 영상에 대응되는 타겟영상에 기초하여 학습되는, 제어 방법."}
{"patent_id": "10-2020-0022696", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제13항에 있어서,상기 인핸스 영상을 복수의 픽셀 영역으로 구분하는 단계;각 픽셀 영역에 포함된 에지 정보에 기초하여 각 픽셀 영역을 상기 복수의 클래스 중 하나로 구분하는 단계; 및 상기 각 픽셀 영역이 속한 클래스의 필터 정보를, 상기 각 픽셀 영역 및 상기 각 픽셀 영역에 대응되는 인핸스영상의 픽셀 영역에 기초하여 학습시키는 단계;를 더 포함하는 제어 방법."}
{"patent_id": "10-2020-0022696", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제14항에 있어서,상기 학습시키는 단계는, 상기 각 픽셀 영역에 상기 각 픽셀 영역이 속한 클래스의 필터 정보를 곱한 값과 상기 각 픽셀 영역에 대응되는인핸스 영상의 픽셀 영역의 값의 차이가 최소가 되도록 상기 필터 정보를 학습시키는, 제어 방법."}
{"patent_id": "10-2020-0022696", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제13항에 있어서,상기 복수의 필터 정보는, 상이한 에지 정보 및 스케일링 팩터에 따라 구분된 복수의 클래스 각각에 대응되는 필터 정보를 포함하며, 상기 스케일링 팩터는 다운스케일링 비율 또는 다운스케일링 방향 중 적어도 하나를 포함하는, 제어 방법."}
{"patent_id": "10-2020-0022696", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제13항에 있어서,상기 상이한 에지 정보는,영상의 에지 강도, 에지 방향 또는 콘트라스트 중 적어도 하나가 상이한, 제어 방법.공개특허 10-2021-0108027-5-청구항 18 제17항에 있어서,상기 영상의 에지 강도에 기초하여 스무스 영역, 텍스처 영역 및 에지 영역으로 구분하는 단계;상기 텍스처 영역 및 상기 에지 영역 각각을 상기 콘트라스트에 기초하여 저콘트라스트 영역 및 고 콘트라스트영역으로 구분하는 단계;상기 저 콘트라스트 영역 및 상기 고 콘트라스트 영역을 상기 에지 방향에 기초하여 복수의 에지 방향 영역으로구분하는 단계; 및 상기 구분된 각 영역들을 상기 복수의 클래스로 분류하는 단계;를 더 포함하는, 제어 방법."}
{"patent_id": "10-2020-0022696", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제11항에 있어서,상기 타겟 영상은, 상기 인핸스 영상을 저역 통과 필터를 이용하여 필터링한 후 상기 필터링된 영상에 대한 anti-aliasing 보간을수행하여 상기 인핸스 영상을 다운스케일링함으로써 획득되는, 제어 방법."}
{"patent_id": "10-2020-0022696", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "다운스케일링(downscaling)을 위한 복수의 필터 정보를 저장하는 전자 장치의 프로세서에 의해 실행되는 경우상기 전자 장치가 동작을 수행하도록 하는 컴퓨터 명령을 저장하는 비일시적 컴퓨터 판독 가능 매체에 있어서,상기 동작은, 입력 영상의 에지 정보에 기초하여 상기 복수의 필터 정보 중 하나를 획득하는 단계; 및 상기 획득된 필터 정보에 기초하여 상기 입력 영상을 다운스케일링하여 출력 영상을 획득하는 단계;를포함하며, 상기 복수의 필터 정보는,영상을 인공 지능 모델에 입력하여 획득된 인핸스(enhance) 영상 및 상기 인핸스 영상을 다운스케일링하여 획득된 타겟 영상에 기초하여 학습되는, 비일시적 컴퓨터 판독 가능 매체."}
{"patent_id": "10-2020-0022696", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "전자 장치가 개시된다. 전자 장치는, 다운스케일링(downscaling)을 위한 복수의 필터 정보가 저장된 메모리 및 입력 영상의 에지 정보에 기초하여 저장된 복수의 필터 정보 중 하나를 획득하고, 획득된 필터 정보에 기초하여 입력 영상을 다운스케일링하여 출력 영상을 획득하는 프로세서를 포함할 수 있다. 여기서, 복수의 필터 정보는, 영상을 인공 지능 모델에 입력하여 획득된 인핸스(enhance) 영상 및 인핸스 영상을 다운스케일링하여 획득된 타 겟 영상에 기초하여 학습될 수 있다."}
{"patent_id": "10-2020-0022696", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 전자 장치 및 그 제어 방법에 관한 것으로, 더욱 상세하게는 인공 지능 모델을 이용하여 영상 처리를 수행하는 전자 장치 및 그 제어 방법에 관한 것이다."}
{"patent_id": "10-2020-0022696", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "전자 기술의 발달에 힘입어 다양한 유형의 전자 기기가 개발 및 보급되고 있다. 특히, 가정, 사무실, 공공 장소 등 다양한 장소에서 이용되는 디스플레이 장치는 최근 수년 간 지속적으로 발전하고 있다. 최근에는 고해상도 영상 서비스에 대한 요구가 크게 증가하고 있다. 이에 따라 방송사 등 컨텐츠 제공사에서 제 공되는 영상이 점차 고화질이 되어가고 있다. 하지만, TV, 비디오 월 등와 같은 디스플레이는 다양한 해상도를 가지게 되면서 고해상도 영상을 다운스케일링할 필요가 점차 증가하고 있다. 기존의 다운스케일링 방법으로는 입력 영상에서 특정 픽셀 만을 추출하는 subsampling, bilateral interpolation, bicubic interpolation 등이 존재한다. 다만, 이들 방법의 경우 aliasing, 선명도 저하 등을 발생시킨다는 문제점이 있었다."}
{"patent_id": "10-2020-0022696", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 개시는 상술한 필요성에 따른 것으로, 본 개시의 목적은 학습된 필터를 통해 선명한 다운스케일 영상을 획득 할 수 있는 전자 장치 및 그 제어 방법을 제공함에 있다."}
{"patent_id": "10-2020-0022696", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "이상과 같은 목적을 달성하기 위한 일 실시 예에 따른 전자 장치는, 다운스케일링(downscaling)을 위한 복수의 필터 정보가 저장된 메모리 및 입력 영상의 에지 정보에 기초하여 상기 저장된 복수의 필터 정보 중 하나를 획 득하고, 상기 획득된 필터 정보에 기초하여 상기 입력 영상을 다운스케일링하여 출력 영상을 획득하는 프로세서 를 포함하며, 상기 복수의 필터 정보는, 영상을 인공 지능 모델에 입력하여 획득된 인핸스(enhance) 영상 및 상 기 인핸스 영상을 다운스케일링하여 획득된 타겟 영상에 기초하여 학습될 수 있다. 이 경우, 상기 인공 지능 모델은, 초해상도 처리(super resolution)를 수행하도록 학습된 인공 지능 모델이며, 상기 인핸스 영상은, 상기 인공 지능 모델에 포함된 복수의 레이어 중 디테일 향상 처리를 위한 일부 레이어에 기초하여 디테일이 향상된 영상일 수 있다. 또한, 상기 복수의 필터 정보는, 상이한 에지 정보에 따라 구분된 복수의 클래스 각각에 대응되는 필터 정보를 포함하며, 상기 복수의 클래스 각각에 대응되는 필터 정보는, 상기 복수의 클래스 각각에 대응되는 에지 정보를 포함하는 인핸스 영상 및 상기 인핸스 영상에 대응되는 타겟 영상에 기초하여 학습될 수 있다. 또한, 상기 프로세서는, 상기 인핸스 영상을 복수의 픽셀 영역으로 구분하고, 각 픽셀 영역에 포함된 에지 정보 에 기초하여 각 픽셀 영역을 상기 복수의 클래스 중 하나로 구분하고, 상기 각 픽셀 영역이 속한 클래스의 필터 정보를 상기 각 픽셀 영역 및 상기 각 픽셀 영역에 대응되는 인핸스 영상의 픽셀 영역에 기초하여 학습시킬 수 있다. 또한, 상기 프로세서는, 상기 각 픽셀 영역에 상기 각 픽셀 영역이 속한 클래스의 필터 정보를 곱한 값과 상기 각 픽셀 영역에 대응되는 인핸스 영상의 픽셀 영역의 값의 차이가 최소가 되도록 상기 필터 정보를 학습시킬 수 있다. 또한, 상기 복수의 필터 정보는, 상이한 에지 정보 및 스케일링 팩터에 따라 구분된 복수의 클래스 각각에 대응 되는 필터 정보를 포함하며, 상기 스케일링 팩터는 다운스케일링 비율 또는 다운스케일링 방향 중 적어도 하나 를 포함할 수 있다. 또한, 상기 상이한 에지 정보는, 영상의 에지 강도, 에지 방향 또는 콘트라스트 중 적어도 하나가 상이한 것일 수 있다. 또한, 상기 프로세서는, 상기 영상의 에지 강도에 기초하여 스무스 영역, 텍스처 영역 및 에지 영역으로 구분하 고, 상기 텍스처 영역 및 상기 에지 영역 각각을 상기 콘트라스트에 기초하여 저콘트라스트 영역 및 고 콘트라 스트 영역으로 구분하고, 상기 저 콘트라스트 영역 및 상기 고 콘트라스트 영역을 상기 에지 방향에 기초하여 복수의 에지 방향 영역으로 구분하고, 상기 구분된 각 영역들을 상기 복수의 클래스로 분류할 수 있다. 또한, 상기 타겟 영상은, 상기 인핸스 영상을 저역 통과 필터를 이용하여 필터링한 후 상기 필터링된 영상에 대 한 anti-aliasing 보간을 수행하여 상기 인핸스 영상을 다운스케일링함으로써 획득될 수 있다. 또한, 상기 복수의 필터 정보는, 상기 전자 장치 또는 외부 장치에서 학습될 수 있다. 한편, 본 개시의 일 실시 예에 따른 다운스케일링(downscaling)을 위한 복수의 필터 정보를 저장하는 전자 장치 의 제어 방법은, 입력 영상의 에지 정보에 기초하여 상기 복수의 필터 정보 중 하나를 획득하는 단계 및, 상기 획득된 필터 정보에 기초하여 상기 입력 영상을 다운스케일링하여 출력 영상을 획득하는 단계를 포함하며, 상기 복수의 필터 정보는, 영상을 인공 지능 모델에 입력하여 획득된 인핸스(enhance) 영상 및 상기 인핸스 영상을 다운스케일링하여 획득된 타겟 영상에 기초하여 학습될 수 있다. 이 경우, 상기 인공 지능 모델은, 초해상도 처리(super resolution)를 수행하도록 학습된 인공 지능 모델이며, 상기 인핸스 영상은, 상기 인공 지능 모델에 포함된 복수의 레이어 중 디테일 향상 처리를 위한 일부 레이어에 기초하여 디테일이 향상된 영상일 수 있다. 또한, 상기 복수의 필터 정보는, 상이한 에지 정보에 따라 구분된 복수의 클래스 각각에 대응되는 필터 정보를 포함하며, 상기 복수의 클래스 각각에 대응되는 필터 정보는, 상기 복수의 클래스 각각에 대응되는 에지 정보를 포함하는 인핸스 영상 및 상기 인핸스 영상에 대응되는 타겟 영상에 기초하여 학습될 수 있다. 또한, 상기 제어 방법은, 상기 인핸스 영상을 복수의 픽셀 영역으로 구분하는 단계, 각 픽셀 영역에 포함된 에 지 정보에 기초하여 각 픽셀 영역을 상기 복수의 클래스 중 하나로 구분하는 단계, 및 상기 각 픽셀 영역이 속 한 클래스의 필터 정보를, 상기 각 픽셀 영역 및 상기 각 픽셀 영역에 대응되는 인핸스 영상의 픽셀 영역에 기 초하여 학습시키는 단계를 더 포함할 수 있다. 또한, 상기 학습시키는 단계는, 상기 각 픽셀 영역에 상기 각 픽셀 영역이 속한 클래스의 필터 정보를 곱한 값 과 상기 각 픽셀 영역에 대응되는 인핸스 영상의 픽셀 영역의 값이 최소가 되도록 상기 필터 정보를 학습시킬 수 있다. 또한, 상기 복수의 필터 정보는, 상이한 에지 정보 및 스케일링 팩터에 따라 구분된 복수의 클래스 각각에 대응 되는 필터 정보를 포함하며, 상기 스케일링 팩터는 다운스케일링 비율 또는 다운스케일링 방향 중 적어도 하나 를 포함할 수 있다. 또한, 상기 상이한 에지 정보는, 영상의 에지 강도, 에지 방향 또는 콘트라스트 중 적어도 하나가 상이한 것일 수 있다. 또한, 상기 제어 방법은, 상기 영상의 에지 강도에 기초하여 스무스 영역, 텍스처 영역 및 에지 영역으로 구분 하는 단계, 상기 텍스처 영역 및 상기 에지 영역 각각을 상기 콘트라스트에 기초하여 저콘트라스트 영역 및 고 콘트라스트 영역으로 구분하는 단계, 상기 저 콘트라스트 영역 및 상기 고 콘트라스트 영역을 상기 에지 방향에 기초하여 복수의 에지 방향 영역으로 구분하는 단계 및, 상기 구분된 각 영역들을 상기 복수의 클래스로 분류하 는 단계를 더 포함할 수 있다. 또한, 상기 타겟 영상은, 상기 인핸스 영상을 저역 통과 필터를 이용하여 필터링한 후 상기 필터링된 영상에 대 한 anti-aliasing 보간을 수행하여 상기 인핸스 영상을 다운스케일링함으로써 획득될 수 있다. 또한, 본 개시의 일 실시 예에 따른 다운스케일링(downscaling)을 위한 복수의 필터 정보를 저장하는 전자 장치 의 프로세서에 의해 실행되는 경우 상기 전자 장치가 동작을 수행하도록 하는 컴퓨터 명령을 저장하는 비일시적 컴퓨터 판독 가능 매체에 있어서, 상기 동작은, 입력 영상의 에지 정보에 기초하여 상기 복수의 필터 정보 중 하나를 획득하는 단계 및, 상기 획득된 필터 정보에 기초하여 상기 입력 영상을 다운스케일링하여 출력 영상을 획득하는 단계를 포함하며, 상기 복수의 필터 정보는, 영상을 인공 지능 모델에 입력하여 획득된 인핸스 (enhance) 영상 및 상기 인핸스 영상을 다운스케일링하여 획득된 타겟 영상에 기초하여 학습될 수 있다."}
{"patent_id": "10-2020-0022696", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "상술한 바와 같은 다양한 실시 예에 따르면, 초해상도 네트워크를 이용하여 좀더 선명한 다운스케일링 영상을 획득할 수 있게 된다. 또한, 필터 정보는 기 학습되어 메모리에 저장되므로, 로직 혹은 메모리 이용량의 변화없 이 선명한 다운스케일링 영상을 획득할 수 있게 된다. 또한, 필터 정보의 학습을 통해 다양한 스케일링 팩터를 지원할 수 있게 된다."}
{"patent_id": "10-2020-0022696", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하에서는 첨부 도면을 참조하여 본 개시를 상세히 설명한다. 본 명세서에서 사용되는 용어에 대해 간략히 설명하고, 본 개시에 대해 구체적으로 설명하기로 한다. 본 개시의 실시 예에서 사용되는 용어는 본 개시에서의 기능을 고려하면서 가능한 현재 널리 사용되는 일반적인 용어들을 선택하였으나, 이는 당 분야에 종사하는 기술자의 의도 또는 판례, 새로운 기술의 출현 등에 따라 달 라질 수 있다. 또한, 특정한 경우는 출원인이 임의로 선정한 용어도 있으며, 이 경우 해당되는 개시의 설명 부 분에서 상세히 그 의미를 기재할 것이다. 따라서 본 개시에서 사용되는 용어는 단순한 용어의 명칭이 아닌, 그 용어가 본 개시의 전반에 걸친 내용을 토대로 정의되어야 한다. 제1, 제2 등의 용어는 다양한 구성요소들을 설명하는데 사용될 수 있지만, 구성요소들은 용어들에 의해 한정되 어서는 안 된다. 용어들은 하나의 구성요소를 다른 구성요소로부터 구별하는 목적으로만 사용된다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 출원에서, \"포함하다\" 또 는 \"구성되다\" 등의 용어는 명세서상에 기재된 특징, 숫자, 단계, 동작, 구성요소, 부품 또는 이들을 조합한 것 이 존재함을 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성요소, 부품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되어야 한다. A 또는 B 중 적어도 하나라는 표현은 \"A\" 또는 \"B\" 또는 \"A 및 B\" 중 어느 하나를 나타내는 것으로 이해되어야 한다. 본 개시에서 \"모듈\" 혹은 \"부\"는 적어도 하나의 기능이나 동작을 수행하며, 하드웨어 또는 소프트웨어로 구현되 거나 하드웨어와 소프트웨어의 결합으로 구현될 수 있다. 또한, 복수의 \"모듈\" 혹은 복수의 \"부\"는 특정한 하드 웨어로 구현될 필요가 있는 \"모듈\" 혹은 \"부\"를 제외하고는 적어도 하나의 모듈로 일체화되어 적어도 하나의 프 로세서(미도시)로 구현될 수 있다. 아래에서는 첨부한 도면을 참고하여 본 개시의 실시 예에 대하여 본 개시가 속하는 기술 분야에서 통상의 지식 을 가진 자가 용이하게 실시할 수 있도록 상세히 설명한다. 그러나 본 개시는 여러 가지 상이한 형태로 구현될 수 있으며 여기에서 설명하는 실시 예에 한정되지 않는다. 그리고 도면에서 본 개시를 명확하게 설명하기 위해 서 설명과 관계없는 부분은 생략하였으며, 명세서 전체를 통하여 유사한 부분에 대해서는 유사한 도면 부호를 붙였다. 도 1은 일 실시 예에 따른 전자 장치의 다운스케일링 동작을 설명하기 위한 도면이다. 전자 장치는 TV 또는 set-top box 로 구현될 수 있으나, 이에 한정되는 것은 아니며 스마트 폰, 태블릿 PC, 노트북 PC, HMD(Head mounted Display), NED(Near Eye Display), LFD(large format display), Digital Signage(디지털 간판), DID(Digital Information Display), 비디오 월(video wall), 프로젝터 디스플레이, 카 메라, 캠코더, 프린터, 서버 등으로 구현될 수 있다. 또는 전자 장치는 클라우딩 컴퓨팅 환경이 구축된 시 스템 자체일 수도 있다. 이에 한정되는 것은 아니며, 인공 지능 모델을 이용하여 데이터를 처리하는 장치라면 한정되지 않고 적용 가능하다. 일 예에 따라 전자 장치는 다양한 해상도의 영상, 다양한 압축 영상을 수신할 수 있다. 예를 들어, 전자 장치는 SD(Standard Definition), HD(High Definition), FHD, UHD 영상, UHD 이상의 해상도 영상 중 적어 도 하나의 영상을 수신할 수 있다. 또한, 전자 장치는 MPEG(Moving Picture Experts Group)(예를 들어, MP2, MP4, MP7 등), JPEG(joint photographic coding experts group), AVC(Advanced Video Coding), H.264, H.265, HEVC(High Efficiency Video Codec), VC-1, VP8, VP9 및 AV1(AOMedia Video 1) 등으로 압축된 형태로 영상을 수신할 수 있다. 일 실시 예에 따르면, 전자 장치는 컨텐츠 제공자(예를 들어, 방송사 등)로부터 제공된 영상을 출력 디스 플레이에 맞는 해상도로 리사징(resizing)할 수 있다. 예를 들어, 컨텐츠 제공자로부터 제공되는 영상이 출력 디스플레이보다 고화질인 경우 영상을 다운스케일링하여 제공하여야 한다. 일 실시 예에 따르면, 전자 장치는 입력 영상이 수신되면, 입력 영상에 포함된 에지 정보에 기초 하여 필터 정보를 선택하고, 선택된 필터 정보를 입력 영상에 적용하여 다운스케일링된 영상을 획득할 수 있다. 이 경우, 일 실시 예에 따르면 필터 정보는 학습에 의해 획득될 수 있는데, 이하에서는 필터 정보를 학습하는 본 개시의 다양한 실시 예에 대해 설명하도록 한다. 도 2는 일 실시 예에 따른 전자 장치의 구성을 나타내는 블럭도이다. 도 2에 따르면, 전자 장치는 메모리 및 프로세서를 포함한다. 메모리는 본 개시의 다양한 실시 예를 위해 필요한 데이터를 저장할 수 있다. 메모리는 데이터 저장 용도에 따라 전자 장치에 임베디드된 메모리 형태로 구현되거나, 전자 장치에 탈부착이 가능한 메모 리 형태로 구현될 수도 있다. 예를 들어, 전자 장치의 구동을 위한 데이터의 경우 전자 장치에 임베 디드된 메모리에 저장되고, 전자 장치의 확장 기능을 위한 데이터의 경우 전자 장치에 탈부착이 가능 한 메모리에 저장될 수 있다. 한편, 전자 장치에 임베디드된 메모리의 경우 휘발성 메모리(예: DRAM(dynamic RAM), SRAM(static RAM), 또는 SDRAM(synchronous dynamic RAM) 등), 비휘발성 메모리(non- volatile Memory)(예: OTPROM(one time programmable ROM), PROM(programmable ROM), EPROM(erasable and programmable ROM), EEPROM(electrically erasable and programmable ROM), mask ROM, flash ROM, 플래시 메 모리(예: NAND flash 또는 NOR flash 등), 하드 드라이브, 또는 솔리드 스테이트 드라이브(solid state drive(SSD)) 중 적어도 하나로 구현될 수 있다. 또한, 전자 장치에 탈부착이 가능한 메모리의 경우 메모리 카드(예를 들어, CF(compact flash), SD(secure digital), Micro-SD(micro secure digital), Mini-SD(mini secure digital), xD(extreme digital), MMC(multi-media card) 등), USB 포트에 연결가능한 외부 메모리(예를 들어, USB 메모리) 등과 같은 형태로 구현될 수 있다. 일 예에 따라 메모리는 전자 장치를 제어하기 위한 적어도 하나의 인스트럭션(instruction) 또는 인 스트럭션들을 포함하는 컴퓨터 프로그램을 저장할 수 있다. 다른 예에 따라, 메모리는 복수의 레이어를 포함하는 인공 지능 모델에 관한 정보를 저장할 수 있다. 여기 서, 인공 지능 모델에 관한 정보를 저장한다는 것은 인공 지능 모델의 동작과 관련된 다양한 정보, 예를 들어 인공 지능 모델에 포함된 복수의 레이어에 대한 정보, 복수의 레이어 각각에서 이용되는 파라미터(예를 들어, 필터 계수, 바이어스 등)에 대한 정보 등을 저장한다는 것을 의미할 수 있다. 예를 들어, 메모리는 일 실 시 예에 따라 입력 영상의 업스케일링 정보를 획득하도록 학습된 인공 지능 모델에 대한 정보를 저장할 수 있다. 여기서, 업스케일링 처리는 예를 들어, 초해상도(super resolution) 처리를 포함할 수 있다. 다만, 프로 세서가 인공 지능 모델 전용 하드웨어로 구현되는 경우, 인공 지능 모델에 관한 정보는 프로세서 내 부 메모리에 저장될 수도 있다. 또 다른 예에 따라, 메모리는 외부 장치(예를 들어, 소스 장치), 외부 저장 매체(예를 들어, USB), 외부 서버(예를 들어 웹 하드) 등으로부터 수신된 영상을 저장할 수 있다. 여기서, 영상은 디지털 동영상이 될 수 있 으나 이에 한정되는 것은 아니다. 또 다른 예에 따라, 메모리는 화질 처리에 필요한 다양한 정보, 예를 들어 Noise Reduction, Detail Enhancement, Tone Mapping, Contrast Enhancement, Color Enhancement 또는 Frame rate Conversion 중 적어 도 하나를 수행하기 위한 정보, 알고리즘, 화질 파라미터 등을 저장할 수 있다. 또한, 메모리는 영상 처리 에 의해 생성된 최종 출력 영상을 저장할 수도 있다. 일 실시 예에 따르면, 메모리는 본 개시에 따른 다양한 동작들에서 생성되는 데이터를 저장하는 단일 메모 리로 구현될 수 있다. 다만, 다른 실시 예에 따르면, 메모리는 상이한 타입의 데이터를 각각 저장하거나, 상이한 단계에서 생성되는 데이터를 각각 저장하는 복수의 메모리를 포함하도록 구현될 수도 있다. 상술한 실시 예에서는 다양한 데이터가 프로세서의 외부 메모리에 저장되는 것으로 설명하였으나, 상 술한 데이터 중 적어도 일부는 전자 장치 또는 프로세서 중 적어도 하나의 구현 예에 따라 프로세서 내부 메모리에 저장될 수도 있다. 프로세서는 메모리와 전기적으로 연결되어 전자 장치의 전반적인 동작을 제어한다. 프로세서 는 하나 또는 복수의 프로세서로 구성될 수 있다. 구체적으로, 프로세서는 메모리에 저장된 적 어도 하나의 인스트럭션(instruction)을 실행함으로써, 본 개시의 다양한 실시 예에 따른 전자 장치의 동작을 수행할 수 있다. 일 실시 예에 따라 프로세서는 디지털 영상 신호를 처리하는 디지털 시그널 프로세서(digital signal processor(DSP), 마이크로 프로세서(microprocessor), GPU(Graphics Processing Unit), AI(Artificial Intelligence) 프로세서, NPU (Neural Processing Unit), TCON(Time controller)으로 구현될 수 있다. 다만, 이에 한정되는 것은 아니며, 중앙처리장치(central processing unit(CPU)), MCU(Micro Controller Unit), MPU(micro processing unit), 컨트롤러(controller), 어플리케이션 프로세서(application processor(AP)), 또 는 커뮤니케이션 프로세서(communication processor(CP)), ARM 프로세서 중 하나 또는 그 이상을 포함하거나, 해당 용어로 정의될 수 있다. 또한, 프로세서는 프로세싱 알고리즘이 내장된 SoC(System on Chip), LSI(large scale integration)로 구현될 수도 있고, ASIC(application specific integrated circuit), FPGA(Field Programmable gate array) 형태로 구현될 수도 있다. 또한, 일 실시 예에 따른 인공 지능 모델을 실행하기 위한 프로세서는 CPU, AP, DSP(Digital Signal Processor) 등과 같은 범용 프로세서, GPU, VPU(Vision Processing Unit)와 같은 그래픽 전용 프로세서 또는 NPU와 같은 인공 지능 전용 프로세서과 소프트웨어의 조합을 통해 구현될 수 있다. 프로세서는, 메모리 에 저장된 기 정의된 동작 규칙 또는 인공 지능 모델에 따라, 입력 데이터를 처리하도록 제어할 수 있다. 또는, 프로세서가 전용 프로세서(또는 인공 지능 전용 프로세서)인 경우, 특정 인공 지능 모델의 처리에 특화된 하드웨어 구조로 설계될 수 있다. 예를 들어, 특정 인공 지능 모델의 처리에 특화된 하드웨어는 ASIC, FPGA 등의 하드웨어 칩으로 설계될 수 있다. 프로세서가 전용 프로세서로 구현되는 경우, 본 개시의 실시 예를 구현하기 위한 메모리를 포함하도록 구현되거나, 외부 메모리를 이용하기 위한 메모리 처리 기능을 포함하 도록 구현될 수 있다. 프로세서는 입력 영상을 영상 처리하여 출력 영상을 획득한다. 여기서, 입력 영상 또는 출력 영상은 정지 영상, 복수의 연속된 정지 영상(또는 프레임), 또는 비디오를 포함할 수 있다. 영상 처리는 영상 개선(image enhancement), 영상 복원(image restoration), 영상 변환(image transformation), 영상 분석(image analysis), 영상 인식(image understanding) 또는 영상 압축(image compression) 중 적어도 하나를 포함하는 디지털 영상 처리가 될 수 있다. 일 예에 따라 입력 영상이 압축 영상인 경우 프로세서는 압축 영상을 디코딩한 후 영 상 처리할 수 있다. 일 실시 예에 따라, 프로세서는 인공 지능 모델을 이용하여 입력 영상을 영상 처리할 수 있다. 예를 들어, 프로세서는 인공 지능 모델을 이용하기 위하여, 메모리, 예를 들어 DRAM과 같은 외부 메모리에 저장된 인공 지능 모델 관련 정보를 로딩하여 이용할 수 있다. 도 3은 일 실시 예에 따른 프로세서의 동작을 설명하기 위한 흐름도이다. 일 실시 예에 따르면, 프로세서는 입력 영상이 수신되면, 입력 영상에 포함된 에지 정보에 기초하 여 복수의 클래스 중 입력 영상에 대응되는 클래스를 식별(S310)할 수 있다. 여기서, 복수의 클래스는 상이 한 에지 정보에 따라 구분된 클래스일 수 있으며, 복수의 클래스 각각에는 적어도 하나의 필터에 대한 정보가 맵핑되어 있을 수 있다. 예를 들어, 메모리에 복수의 클래스 각각에 맵핑된 필터에 대한 정보가 룩업 테이 블 형태로 저장되어 있을 수 있다. 프로세서는 입력 영상에 대응되는 클래스가 식별되면, 해당 클래스에 대응되는 필터 정보를 획득할 수 있다(S320). 예를 들어, 프로세서는 메모리에 저장된 룩업 테이블로부터 식별된 클래스에 대응되는 필터 정보를 로딩할 수 있다. 이어서, 프로세서는 획득된 필터 정보에 기초하여 입력 영상을 필터링하여(S330) 다운스케일링된 영상 을 획득할 수 있다. 여기서, 입력 영상을 필터링한다는 것은 입력 영상에 필터 정보를 가중합(weighted sum)하는 것을 의미할 수 있다. 일 실시 예에 따르면, 하나의 프로세서가 S310, S320, S330 단계의 동작을 모두 수행할 수도 있으나, 적 어도 일부 단계의 적어도 일부 동작은 적어도 하나의 다른 프로세서에 의해 수행될 수도 있다. 일 실시 예에 따라, 메모리에 복수의 클래스 각각에 대응되는 필터 정보는 학습에 의해 획득될 수 있다. 구체적으로, 복수의 클래스 각각에 대응되는 필터 정보는, 복수의 클래스 각각에 대응되는 에지 정보를 포함하 는 인핸스 영상 및 인핸스 영상에 대응되는 타겟 영상에 기초하여 학습될 수 있다. 이 경우, 필터 정보의 학습 은 전자 장치 또는 외부 장치(미도시)에 의해 수행될 수 있다. 다만, 이하에서는 설명의 편의를 위하여 필 터 정보의 학습이 전자 장치에 의해 수행되는 것으로 설명하도록 한다. 도 4는 일 실시 예에 따른 필터 정보의 학습 방법을 설명하기 위한 흐름도이다. 도 4에서는 필터 정보의 학습이 전자 장치의 프로세서에 의해 수행되는 것으로 가정하였다. 도 4에 따르면 프로세서는 영상(예를 들어, 원본 영상)을 기설정된 크기의 픽셀 영역으로 구분하여 로 컬 패치를 획득할 수 있다(S410). 여기서, 로컬 패치는 n*n 형태가 될 수 있다. 예를 들어, 로컬 패치의 크기는 5*5 가 될 수 있으나, 이에 한정되는 것은 아니며, 3*3, 4*4 등 다양한 크기로 구현 가능하다. 프로세서는 각 로컬 패치의 에지 정보에 기초하여 로컬 패치를 클러스터링하고, 클러스터링을 통해 복수의 클래스를 생성할 수 있다(S420). 예를 들어, 프로세서는 영상에 1차 또는 2차 에지 검출 필터를 적용하여 에지 강도, 에지 방향(그래디언트에 수직 방향) 등과 같은 에지 정보를 포함하는 필터링된 신호를 획득할 수 있 다. 여기서, 1차 에지 검출 필터란 1차 미분 신호에 기초하여 에지를 검출하는 필터를 의미하고, 2차 에지 검출 필터란 2차 미분 신호에 기초하여 에지를 검출하는 필터를 의미한다. 에지는 공간적으로 인접한 픽셀 값들이 급 격하게 변하는 영역을 의미할 수 있다. 예를 들어, 에지는 영상의 밝기가 낮은 값에서 높은 값으로 또는 높은 값에서 낮은 값으로 급격하게 변화하는 영역이 될 수 있다. 프로세서는 각 로컬 패치의 에지 정보에 기초하여 유사한 에지 정보를 가지는 로컬 패치들을 클러스터링하 여 상이한 에지 정보에 대응되는 복수의 클래스를 생성할 수 있다. 한편, 프로세서는 영상을 부스팅(boosting)하여 인핸스 영상을 획득할 수 있다(S430). 예를 들어, 프로세서는 영상을 인공 지능 모델에 입력하여 인핸스 영상을 획득할 수 있다. 여기서, 인공 지능 모 델은 초해상도 처리(super resolution)를 수행하도록 학습된 인공 지능 모델이 될 수 있다. 예를 들어, 인공 지 능 모델은 도 5에 도시된 바와 같이 CNN 기반의 VDSR(Very Deep uper-Resolution) 네트워크로 구현될 수 있으 나, 반드시 이에 한정되는 것이며 CEDSR(Enhanced Deep Residual Networks for Single Image Super- Resolution), DRCN(Deeply-Recursive Convolutional Network for Image Super-Resolution.”Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2016.), MDSR(Multi-scale deep super- resolution system) 등이 이용될 수도 있다. 일 실시 예에 따라, 인핸스 영상은, 인공 지능 모델에 포함된 복수의 레이어 중 디테일 향상 처리를 위한 적어 도 일부 레이어에 기초하여 디테일이 향상된 영상이 될 수 있다. 일반적으로, 초해상도 네트워크의 경우 저해상 도 영상을 보간 처리를 통해 고해상도 영상으로 변환 즉, 업스케일링한 후 디테일을 향상시키도록 구현될 수 있 다. 다만, 본 실시 예에서는 초해상도 네트워크에 포함된 복수의 레이어 중 업스케일링을 위한 레이어는 이용하 지 않고, 디테일 향상을 위한 레이어 만을 이용하여 영상의 해상도는 유지되면서 디테일이 향상된 인핸스 영상을 획득할 수 있다. 또는, scale factor를 1로 고정시키고, 초해상도 네트워크를 통과시키는 경우 영상(2 0)의 해상도는 유지되면서 디테일이 향상되고 정보량이 증대된 인핸스 영상을 획득할 수 있다. 이어서, 프로세서는 인핸스 영상을 다운스케일링하여 타겟 영상을 획득할 수 있다. 일 실시 예에 따라 프로세서는 인핸스 영상을 필터링한 후 필터링된 영상에 대한 보간을 수행하여 인핸스 영상을 다 운스케일링함으로써 타겟 영상을 획득할 수 있다. 일 실시에 따라 프로세서는 인핸스 영상을 저역 통과 필터를 이용하여 필터링한 후 필터링된 영상에 대한 anti-aliasing 보간을 수행하여 인핸스 영상을 다운스케일링함으로써 타겟 영상을 획득할 수 있다. 일 예에 따라 프로세서는 가우시안 필터를 이용하여 인핸스 영상을 필터링할 수 있다. 예를 들어, 가 우시안 분포는 x축의 0은 가중치가 크고, +/- 부분로 갈수록 가중치가 적어지는 형태가 될 수 있고, 이러한 가 우시안 분포를 n*n 형태의 마스크에 적용하면 마스크 중심은 가중치가 크고, 마스크의 가장자리로 갈수록 가중 치가 적어지는 형태가 될 수 있다. 프로세서는 가우시안 필터를 인핸스 영상에 적용하여 인핸스 영상을 블 러링 처리할 수 있다. 일 예에 따라 프로세서는 필터링된 영상을 anti-aliasing 보간 처리하여 타겟 영상을 획득할 수 있다. 예 를 들어 보간 기법으로 bilinear interpolation, nearest neighbor interpolation, bicubic interpolation, deconvolution interpolation, subpixel convolution interpolation, polyphase interpolation, trilinear interpolation, linear interpolation 중 적어도 하나의 보간 기법이 이용될 수 있다. 이어서, 프로세서는 인핸스 영상 및 타겟 영상에 기초하여 필터 정보를 학습시킬 수 있다(S450). 구체적으로, 프로세서는 S420 단계에서 생성된 복수의 클래스 각각에 대응되는 필터 정보를 학습시킬 수 있다. 일 예에 따라 프로세서는 인핸스 영상을 복수의 픽셀 영역으로 구분하고, 각 픽셀 영역에 포함된 에지 정보에 기초하여 각 픽셀 영역을 복수의 클래스 중 하나로 구분하고, 각 픽셀 영역이 속한 클래스의 필터 정보 를 각 픽셀 영역 및 각 픽셀 영역에 대응되는 인핸스 영상의 픽셀 영역에 기초하여 학습시킬 수 있다. 이 경우, 프로세서는 각 픽셀 영역에 각 픽셀 영역이 속한 클래스(즉, 대응되는 클래스)의 필터 정보를 곱 한 값과 각 픽셀 영역에 대응되는 인핸스 영상의 픽셀 영역의 값의 차이가 최소가 되도록 필터 정보를 학습시킬 수 있다. 예를 들어, 프로세서는 인핸스 영상을 복수의 로컬 패치로 구분하고, 각 로컬 패치의 에지 정보에 기 초하여 각 로컬 패치를 복수의 클래스 중 하나로 구분할 수 있다. 프로세서는 로컬 패치에 대응되는 필터 정보를, 인핸스 영상에서 획득된 로컬 패치 및 대응되는 타겟 영상에서 획득된 로컬 패치에 기초하여 학습시킬 수 있다. 도 6 및 도 7은 일 실시 예에 따라 로컬 패치에 기초하여 각 클래스 별 필터 정보를 학습시키는 방법을 설명하 기 위한 도면들이다. 도 6의 상측에 도시된 바와 같이 프로세서는 제1 인핸스 영상에서 획득된 로컬 패치 및 제1 인핸스 영상에 대응되는 제1 타겟 영상에서 획득된 로컬 패치, 제2 인핸스 영상에서 획득된 로컬 패치 및 제 2 인핸스 영상에 대응되는 제2 타겟 영상에서 획득된 로컬 패치, ..., 제n 인핸스 영상에서 획득된 로컬 패치 및 제n 인핸스 영상에 대응되는 제n 타겟 영상에서 획득된 로컬 패치에 기초하여 제1 클래스에 대응되는 필터 정보를 학습시킬 수 있다. 여기서, 학습에 이용되는 각 인핸스 영상에서 획득된 로컬 패치는 제1 클래스에 대응되는 에지 정보를 가지는 로컬 패치들이고, 이에 따라 각 타겟 영상에서 획득된 로컬 패치 또한, 제1 클래스에 대응되는 에지 정보를 가질 수 있다. 또한, 도 6의 하측에 도시된 바와 같이 프로세서는 제1 인핸스 영상에서 획득된 로컬 패치 및 제1 인 핸스 영상에 대응되는 제1 타겟 영상에서 획득된 로컬 패치, 제2 인핸스 영상에서 획득된 로컬 패치 및 제2 인핸스 영상에 대응되는 제2 타겟 영상에서 획득된 로컬 패치, ..., 제n 인핸스 영상에서 획득된 로컬 패치 및 제n 인핸스 영상에 대응되는 제n 타겟 영상에서 획득된 로컬 패치에 기초하여 제1 클래 스에 대응되는 필터 정보를 학습시킬 수 있다. 여기서, 학습에 이용되는 각 인핸스 영상에서 획득된 로컬 패치 는 제2 클래스에 대응되는 에지 정보를 가지는 로컬 패치들이고, 이에 따라 각 타겟 영상에서 획득된 로컬 패치 또한, 제2 클래스에 대응되는 에지 정보를 가질 수 있다. 이 경우 프로세서는 도 7에 도시된 바와 같이 각 클래스 별로 인핸스 영상에서 획득된 인핸스 로컬 패치 (Y_c) 및 타겟 영상에서 획득된 타겟 로컬 패치를 페어(pair)로 묶고 해당 pair에 맞는 filter kernel(M_c)을 정의할 수 있다. 이어서, 프로세서는 하기와 같은 수학식 1에 기초하여 filter kernel(M_c)이 최적화되도록 학습시킬 수 있 다. 수학식 1은 학습을 통해 목적 함수를 도출하는 함수의 일 예인 L2_norm 함수를 나타낸다. 수학식 1"}
{"patent_id": "10-2020-0022696", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "여기서, ∥M∥은 Mc 값의 발산을 방지하기 위한 factor이고, λ는 regularization factor이다. 이 경우, 목적 함수를 최적화하는 Mc는 하기의 수학식 2와 같은 행렬 연산으로 구해질 수 있다. 수학식 2 여기서, λ는 regularization factor이다. 도 8은 일 실시 예에 따른 학습시 로컬 패치를 분류하는 방법을 설명하기 위한 도면이다. 프로세서는 영상을 로컬 패치 단위로 나누고, 각 로컬 패치의 에지 정보에 기초하여 로컬 패치들을 클러스 터링할 수 있다. 여기서, 영상은 훈련을 위한 원본 영상이 될 수 있으나, 반드시 이에 한정되는 것은 아니다. 일 예에 따라 프로세서는 로컬 패치들의 에지 정보에 기초하여 클래스를 계단식(hierarchical)으로 도출할 수 있다. 프로세서는 로컬 패치에 포함된 에지 강도 정보에 기초하여 클래스를 스무스 영역(smooth region)(또는 평 탄(flat) 영역), 텍스처 영역(texture region) 및 에지 영역(edge region)으로 구분할 수 있다. 예를 들어, 프 로세서는 로컬 패치 내 에지 변환(edge transition)의 수치가 임계 값 이상인 경우 텍스처 영역으로, 임계 값 미만 인 경우 에지 영역으로 구분할 수 있다. 이어서, 프로세서는 텍스처 영역 및 에지 영역 각각을 콘트라스트에 기초하여 저 콘트라스트 영역(또는 non-text region) 및 고 콘트라스트 영역(또는 text region)으로 구분할 수 있다. 예를 들어, 프로세서는 로컬 패치 내 최대/최소 픽셀 값이 각각 임계 값보다 크고/작을 경우에 고 콘트라스트 영역(또는 text region) 으로, 나머지 경우는 저 콘트라스트 영역(또는 non-text region)으로 구분할 수 있다. 이어서, 프로세서는 저 콘트라스트 영역 및 고 콘트라스트 영역을 에지 방향에 기초하여 복수의 에지 방향 영역으로 구분할 수 있다. 예를 들어, 프로세서는 저 콘트라스트 영역 및 고 콘트라스트 영역을 4개(예를 들어, 180도, 45도, 90도, 135도)의 에지 방향에 기초하여 각 방향 영역으로 구분할 수 있다. 다만, 이는 일 예 일 뿐이며, 에지 방향의 개수는 반드시 이에 한정되는 것은 아니다. 일 예에 따라 상술한 방식으로 클래스를 구분하게 되면, 클래스의 개수는 총 17개가 될 수 있다. 다만, 클래스 의 개수는 스케일링 팩터(scaling factor)에 기초하여 추가로 분류될 수 있다. 예를 들어, 스케일링 팩터의 개 수가 21개인 경우, 21*17=297개의 클래스로 구분될 수 있다. 여기서, 스케일링 팩터는 다운스케일링 비율 또는 다운스케일링 방향 중 적어도 하나에 기초하여 결정될 수 있다. 예를 들어 스케일링 팩터는 다양한 비정수배의 스케일링 팩터 예를 들어 0.5~1을 포함할 수 있고, 수평/수직 방향의 비정형 스케일링에 대응되는 스케일링 팩 터를 포함할 NT 있다. 도 9는 도 8의 도시된 방법에 따라 분류된 로컬 패치의 예시를 나타내는 도면이다. 도 9의 (a)는 도 8에 도시된 클래스 1 즉, 스무스 영역의 대표 로컬 패치(또는 에지 정보)를 나타내고, (b)는 클래스 2, 즉, 에지 영역-저 콘트라스트 영역-180도 영역의 대표 로컬 패치(또는 에지 정보)를 나타내고, (c)는 클래스 3, 즉, 에지 영역-저 콘트라스트 영역-45도 영역의 대표 로컬 패치(또는 에지 정보)를 나타내고, (d)는 클래스 4, 즉, 에지 영역-저 콘트라스트 영역-90도 영역의 대표 로컬 패치(또는 에지 정보)를 나타내고, (e)는 클래스 5, 즉, 에지 영역-저 콘트라스트 영역-135도 영역의 대표 로컬 패치(또는 에지 정보)를 나타낸다. 또한, (f), (g), (h), (i)는 각각 에지 영역-고 콘트라스트 영역의 180도, 45도, 90도, 35도 영역의 대표 로컬 패치 (또는 에지 정보)를 나타내고, (j), (k), (l), (m)은 각각 텍스처 영역-저 콘트라스트 영역의 180도, 45도, 90 도, 35도 영역의 대표 로컬 패치(또는 에지 정보)를 나타내고, (n), (o), (p), (q)는 각각 텍스처 영역-고 콘트 라스트 영역의 180도, 45도, 90도, 35도 영역의 대표 로컬 패치(또는 에지 정보)를 나타낸다. 상술한 바와 같이 인핸스 영상을 이용하여 필터 정보를 학습하게 되면, 초해상도(super resolution) 네트워크가 유도하고자 하는 디테일 효과를 필터 정보에 반영할 수 있게 된다. 즉, 해당 필터 정보를 이용하여 영상을 다운 스케일링하게 되면, 다운스케일링된 영상의 고주파수 영역에서 보다 선명도가 향상될 수 있게 된다. 다만, 상술한 실시 예에서는 필터 정보의 학습과 관련된 다양한 동작이 전자 장치의 프로세서에 의해 수행되는 것으로 설명하였지만, 필터 정보의 학습과 관련된 다양한 동작은 외부 장치(미도시)에 의해 수행되고 이에 기초하여 획득된 필터 정보가 전자 장치의 메모리에 저장될 수 있음은 물론이다. 도 10 및, 11a 내지 도 11d는 일 실시 예에 따른 초해상도 네트워크를 이용한 부스팅 효과를 설명하기 위한 도 면들이다. 도 10은 기존의 antialiasing을 기반으로 한 bicubic interpolation에서의 커널 형태를 나타내는 것으로, antialiasing을 적용하게 되면 antialiasing을 적용하지 않은 경우와 비교하여 커널의 형상이 넓어지며 중앙 부 분의 높이가 저하되는 것을 볼 수 있다.도 11a는 일 실시 예에 따른 초해상도 네트워크를 이용한 부스팅 적용 이전의 이미지에 기초한 필터 커널을 2D 형태로 나타낸 도면이고, 도 11b는 도 11a를 3D 형태로 나타낸 도면이다. 도 11c는 일 실시 예에 따른 초해상도 네트워크를 이용한 부스팅 적용 이후의 인핸스 이미지에 기초한 필터 커 널을 2D 형태로 나타낸 도면이고, 도 11d는 도 11c를 3D 형태로 나타낸 도면이다. 도 11a 및 11b를 비교하면, 도 11a에 도시된 바와 같은 sinc function 형태의 기본적인 필터 커널이 인핸스 이 미지를 기초로 학습하게 되면, 중앙 인근의 weight 값이 증대 되면서 인접 영역의 변화를 더 크게 반영할 수 있 는 형태로 변화한다는 것을 확인할 수 있다. 이에 따라 해당 필터 커널을 영상에 적용하여 다운스케일링을 수행 하게 되면 다운스케일링된 영상의 선명도가 향상될 수 있게 된다. 도 12는 일 실시 예에 따른 전자 장치의 일 구현 예를 나타내는 도면이다. 도 12에 따르면, 전자 장치(100')는 메모리, 프로세서, 입력부, 디스플레이, 출력부 및 사용자 인터페이스를 포함한다. 도 12에 도시된 구성 중 도 2에 도시된 구성과 중복되는 구성에 대해서 는 자세한 설명을 생략하도록 한다. 입력부는 다양한 타입의 컨텐츠를 입력받는다. 예를 들어 입력부는 AP 기반의 Wi-Fi(와이파이, Wireless LAN 네트워크), 블루투스(Bluetooth), 지그비(Zigbee), 유/무선 LAN(Local Area Network), WAN(Wide Area Network), 이더넷(Ethernet), IEEE 1394, HDMI(High-Definition Multimedia Interface), USB(Universal Serial Bus), MHL(Mobile High-Definition Link), AES/EBU(Audio Engineering Society/ European Broadcasting Union), 옵티컬(Optical), 코액셜(Coaxial) 등과 같은 통신 방식을 통해 외부 장치(예를 들어, 소스 장치), 외부 저장 매체(예를 들어, USB 메모리), 외부 서버(예를 들어 웹 하드) 등으로부터 스트리밍 또는 다운로드 방식으로 영상 신호를 입력받을 수 있다. 여기서, 영상 신호는 SD(Standard Definition), HD(High Definition), Full HD 또는 Ultra HD 영상 중 어느 하나의 디지털 영상 신호가 될 수 있으나 이에 한정되는 것 은 아니다. 디스플레이는 자발광 소자를 포함하는 디스플레이 또는, 비자발광 소자 및 백라이트를 포함하는 디스플레 이로 구현될 수 있다. 예를 들어, LCD(Liquid Crystal Display), OLED(Organic Light Emitting Diodes) 디스플 레이, LED(Light Emitting Diodes), 마이크로 LED(micro LED), Mini LED, PDP(Plasma Display Panel), QD(Quantum dot) 디스플레이, QLED(Quantum dot light-emitting diodes) 등과 같은 다양한 형태의 디스플레이 로 구현될 수 있다. 디스플레이 내에는 a-si TFT, LTPS(low temperature poly silicon) TFT, OTFT(organic TFT) 등과 같은 형태로 구현될 수 있는 구동 회로, 백라이트 유닛 등도 함께 포함될 수 있다. 한 편, 디스플레이는 터치 센서와 결합된 터치 스크린, 플렉시블 디스플레이(flexible display), 롤러블 디스 플레이(rollable display), 3차원 디스플레이(3D display), 복수의 디스플레이 모듈이 물리적으로 연결된 디스 플레이 등으로 구현될 수 있다. 프로세서는 상술한 다양한 실시 예에 따라 획득된 출력 영상을 출력하도록 디스플레이를 제어할 수 있다. 여기서, 출력 영상은, 4K 또는 8K 이상의 고해상도 영상일 수 있다. 출력부는 음향 신호를 출력한다. 예를 들어, 출력부는 프로세서에서 처리된 디지털 음향 신호를 아날로그 음향 신호로 변환하고 증폭하여 출력할 수 있다. 예를 들어, 출력부는 적어도 하나의 채널을 출 력할 수 있는, 적어도 하나의 스피커 유닛, D/A 컨버터, 오디오 앰프(audio amplifier) 등을 포함할 수 있다. 일 예에 따라 출력부는 다양한 멀티 채널 음향 신호를 출력하도록 구현될 수 있다. 이 경우, 프로세서 는 입력 영상의 인핸스 처리에 대응되도록 입력된 음향 신호를 인핸스 처리하여 출력하도록 출력부를 제어할 수 있다. 예를 들어, 프로세서는 입력된 2채널 음향 신호를 가상의 멀티 채널(예를 들어, 5.1 채널) 음향 신호로 변환하거나, 전자 장치(100\")가 놓인 위치를 인식해 공간에 최적화된 입체 음향 신호로 처리 하거나, 입력 영상의 타입(예를 들어 컨텐츠 장르)에 따라 최적화된 음향 신호를 제공할 수 있다. 사용자 인터페이스는 버튼, 터치 패드, 마우스 및 키보드와 같은 장치로 구현되거나, 상술한 디스플레이 기능 및 조작 입력 기능도 함께 수행 가능한 터치 스크린, 리모콘 송수신부 등으로 구현될 수 있다. 리모콘 송 수신부는 적외선 통신, 블루투스 통신 또는 와이파이 통신 중 적어도 하나의 통신 방식을 통해 외부 원격 제어 장치로부터 리모콘 신호를 수신하거나, 리모콘 신호를 송신할 수 있다. 전자 장치 (100')는 구현 예에 따라 튜너 및 복조부를 추가적으로 포함할 수 있다. 튜너(미도시)는 안테나를 통 해 수신되는 RF(Radio Frequency) 방송 신호 중 사용자에 의해 선택된 채널 또는 기 저장된 모든 채널을 튜닝하 여 RF 방송 신호를 수신할 수 있다. 복조부(미도시)는 튜너에서 변환된 디지털 IF 신호(DIF)를 수신하여 복조하 고, 채널 복호화 등을 수행할 수도 있다. 일 실시 예에 따라 튜너를 통해 수신된 입력 영상은 복조부(미도시)를통해 처리된 후, 일 실시 예에 따른 영상 처리를 위해 프로세서로 제공될 수 있다. 도 13은 일 실시 예에 따른 전자 장치의 제어 방법을 설명하기 위한 흐름도이다. 도 13에 도시된 다운스케일링(downscaling)을 위한 복수의 필터 정보를 저전자 장치의 제어 방법에 따르면, 입 력 영상의 에지 정보에 기초하여 상기 복수의 필터 정보 중 하나를 획득한다(S1310). 이어서, 획득된 필터 정보에 기초하여 입력 영상을 다운스케일링하여 출력 영상을 획득한다(S1320). 여기서, 복수의 필터 정보는, 영상을 인공 지능 모델에 입력하여 획득된 인핸스(enhance) 영상 및 인핸스 영상 을 다운스케일링하여 획득된 타겟 영상에 기초하여 학습될 수 있다. 이 경우, 복수의 필터 정보는, 전자 장치 또는 외부 장치에서 학습될 수 있다. 이 경우, 인공 지능 모델은, 초해상도 처리(super resolution)를 수행하도록 학습된 인공 지능 모델이며, 인핸 스 영상은, 인공 지능 모델에 포함된 복수의 레이어 중 디테일 향상 처리를 위한 일부 레이어에 기초하여 디테 일이 향상된 영상일 수 있다. 여기서, 타겟 영상은, 인핸스 영상을 저역 통과 필터를 이용하여 필터링한 후 필터링된 영상에 대한 anti- aliasing 보간을 수행하여 인핸스 영상을 다운스케일링함으로써 획득될 수 있다. 여기서, 복수의 필터 정보는, 상이한 에지 정보에 따라 구분된 복수의 클래스 각각에 대응되는 필터 정보를 포 함할 수 있다. 이 경우, 복수의 클래스 각각에 대응되는 필터 정보는, 복수의 클래스 각각에 대응되는 에지 정 보를 포함하는 인핸스 영상 및 인핸스 영상에 대응되는 타겟 영상에 기초하여 학습될 수 있다. 또한, 제어 방법은, 인핸스 영상을 복수의 픽셀 영역으로 구분하는 단계, 각 픽셀 영역에 포함된 에지 정보에 기초하여 각 픽셀 영역을 복수의 클래스 중 하나로 구분하는 단계 및, 각 픽셀 영역이 속한 클래스의 필터 정보 를, 각 픽셀 영역 및 각 픽셀 영역에 대응되는 인핸스 영상의 픽셀 영역에 기초하여 학습시키는 단계를 포함할 수 있다. 이 경우, 각 픽셀 영역에 상기 각 픽셀 영역이 속한 클래스의 필터 정보를 곱한 값과 각 픽셀 영역에 대응되는 인핸스 영상의 픽셀 영역의 값의 차이가 최소가 되도록 필터 정보를 학습시킬 수 있다. 또는, 복수의 필터 정보는, 상이한 에지 정보 및 스케일링 팩터에 따라 구분된 복수의 클래스 각각에 대응되는 필터 정보를 포함하며, 스케일링 팩터는 다운스케일링 비율 또는 다운스케일링 방향 중 적어도 하나를 포함할 수 있다. 또한, 상이한 에지 정보는, 영상의 에지 강도, 에지 방향 또는 콘트라스트 중 적어도 하나가 상이한 것일 수 있 다. 또한, 제어 방법은, 영상의 에지 강도에 기초하여 스무스 영역, 텍스처 영역 및 에지 영역으로 구분하는 단계, 텍스처 영역 및 에지 영역 각각을 콘트라스트에 기초하여 저콘트라스트 영역 및 고 콘트라스트 영역으로 구분하 는 단계, 저 콘트라스트 영역 및 고 콘트라스트 영역을 에지 방향에 기초하여 복수의 에지 방향 영역으로 구분 하는 단계 및, 구분된 각 영역들을 복수의 클래스로 분류하는 단계를 포함할 수 있다. 상술한 바와 같은 다양한 실시 예에 따르면, 초해상도 네트워크를 이용하여 좀더 선명한 다운스케일링 영상을 획득할 수 있게 된다. 또한, 필터 정보는 기 학습되어 메모리에 저장되므로, 로직 혹은 메모리 이용량의 변화없 이 선명한 다운스케일링 영상을 획득할 수 있게 된다. 또한, 필터 정보의 학습을 통해 다양한 스케일링 팩터를 지원할 수 있게 된다. 본 개시의 다양한 실시 예들은 디스플레이 장치 뿐 아니라, 셋탑 박스와 같은 영상 수신 장치, 영상 처리 장치 등 영상 처리가 가능한 모든 전자 장치에 적용될 수 있음은 물론이다. 또한, 상술한 본 개시의 다양한 실시 예 들은 전자 장치에 구비된 임베디드 서버, 또는 영상 처리 장치의 외부 서버를 통해 수행되는 것도 가능하다. 한편, 상술한 본 개시의 다양한 실시 예들에 따른 방법들은, 기존 전자 장치에 설치 가능한 어플리케이션 또는 소프트웨어 형태로 구현될 수 있다. 또한, 상술한 본 개시의 다양한 실시 예들에 따른 방법들은, 기존 전자 장치에 대한 소프트웨어 업그레이드, 또 는 하드웨어 업그레이드 만으로도 구현될 수 있다. 한편, 상술한 본 개시의 실시예들은 컴퓨터에서 실행될 수 있는 프로그램 또는 인스트럭션으로 작성가능하고, 작성된 프로그램 또는 인스트럭션은 매체에 저장될 수 있다. 매체는 컴퓨터로 실행 가능한 프로그램 또는 인스트럭션을 계속 저장하거나, 실행 또는 다운로드를 위해 임시 저장하는 것일 수도 있다. 또한, 매체는 단일 또는 수개 하드웨어가 결합된 형태의 다양한 기록수단 또는 저장 수단일 수 있는데, 어떤 컴퓨터 시스템에 직접 접속되는 매체에 한정되지 않고, 네트워크 상에 분산 존재하는 것일 수도 있다. 매체의 예시로는, 하드 디스크, 플로피 디스크 및 자기 테이프와 같은 자기 매체, CD-ROM 및 DVD와 같은 광기록 매체, 플롭티컬 디스크(floptical disk)와 같은 자기-광 매체(magneto-optical medium), 및 ROM, RAM, 플래시 메모리 등을 포함하여 프로그램 명령어가 저장되도록 구성된 것이 있을 수 있다. 또한, 다른 매체의 예시로, 애플리케이션을 유통하는 앱 스토어나 기타 다양한 소프트웨어를 공급 내지 유통하는 사이트, 서버 등에서 관리하는 기록매체 내지 저장매체도 들 수 있다. 또한, 일 실시 예에 따르면, 이상에서 설명된 다양한 실시 예들에 따른 방법은 컴퓨터 프로그램 제품(computer program product)에 포함되어 제공될 수 있다. 컴퓨터 프로그램 제품은 상품으로서 판매자 및 구매자 간에 거래 될 수 있다. 컴퓨터 프로그램 제품은 기기로 읽을 수 있는 저장 매체(예: compact disc read only memory (CD- ROM))의 형태로, 또는 어플리케이션 스토어(예: 플레이 스토어TM)를 통해 온라인으로 배포될 수 있다. 온라인 배포의 경우에, 컴퓨터 프로그램 제품의 적어도 일부는 제조사의 서버, 어플리케이션 스토어의 서버, 또는 중계 서버의 메모리와 같은 저장 매체에 적어도 일시 저장되거나, 임시적으로 생성될 수 있다. 한편, 상술한 인공 지능 모델은, 소프트웨어 모듈로 구현될 수 있다. 소프트웨어 모듈(예를 들어, 명령어 (instruction)를 포함하는 프로그램 모듈)로 구현되는 경우, 인공 지능 모델은 컴퓨터로 읽을 수 있는 판독 가 능한 기록매체에 저장될 수 있다. 또한, 인공 지능 모델은 다운로드 가능한 소프트웨어 형태로 제공될 수도 있다. 컴퓨터 프로그램 제품은 제조사 또는 전자 마켓을 통해 전자적으로 배포되는 소프트웨어 프로그램 형태의 상품(예를 들어, 다운로드 가능한 애 플리케이션)을 포함할 수 있다. 전자적 배포를 위하여, 소프트웨어 프로그램의 적어도 일부는 저장 매체에 저장 되거나, 임시적으로 생성될 수 있다. 이 경우, 저장 매체는 제조사 또는 전자 마켓의 서버, 또는 중계 서버의 저장매체가 될 수 있다. 또한, 상술한 다양한 실시 예들에 따른 구성 요소(예: 모듈 또는 프로그램) 각각은 단수 또는 복수의 개체로 구 성될 수 있으며, 전술한 해당 서브 구성 요소들 중 일부 서브 구성 요소가 생략되거나, 또는 다른 서브 구성 요 소가 다양한 실시 예에 더 포함될 수 있다. 대체적으로 또는 추가적으로, 일부 구성 요소들(예: 모듈 또는 프로 그램)은 하나의 개체로 통합되어, 통합되기 이전의 각각의 해당 구성 요소에 의해 수행되는 기능을 동일 또는 유사하게 수행할 수 있다. 다양한 실시 예들에 따른, 모듈, 프로그램 또는 다른 구성 요소에 의해 수행되는 동 작들은 순차적, 병렬적, 반복적 또는 휴리스틱하게 실행되거나, 적어도 일부 동작이 다른 순서로 실행되거나, 생략되거나, 또는 다른 동작이 추가될 수 있다. 이상에서는 본 개시의 바람직한 실시 예에 대하여 도시하고 설명하였지만, 본 개시는 상술한 특정의 실시 예에"}
{"patent_id": "10-2020-0022696", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "한정되지 아니하며, 청구범위에서 청구하는 본 개시의 요지를 벗어남이 없이 당해 개시에 속하는 기술분야에서 통상의 지식을 가진 자에 의해 다양한 변형실시가 가능한 것은 물론이고, 이러한 변형실시들은 본 개시의 기술 적 사상이나 전망으로부터 개별적으로 이해되어서는 안될 것이다."}
{"patent_id": "10-2020-0022696", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 일 실시 예에 따른 전자 장치의 다운스케일링 동작을 설명하기 위한 도면이다. 도 2는 일 실시 예에 따른 전자 장치의 구성을 나타내는 블럭도이다. 도 3은 일 실시 예에 따른 프로세서의 동작을 설명하기 위한 흐름도이다. 도 4는 일 실시 예에 따른 필터 정보의 학습 방법을 설명하기 위한 흐름도이다. 도 5는 일 실시 예에 따른 초해상도 네트워크의 구현 예를 나타내는 도면이다. 도 6 및 도 7은 일 실시 예에 따라 로컬 패치에 기초하여 각 클래스 별 필터 정보를 학습시키는 방법을 설명하 기 위한 도면들이다. 도 8은 일 실시 예에 따른 학습시 로컬 패치를 분류하는 방법을 설명하기 위한 도면이다. 도 9는 도 8의 도시된 방법에 따라 분류된 로컬 패치의 예시를 나타내는 도면이다. 도 10 및, 11a 내지 도 11d는 일 실시 예에 따른 초해상도 네트워크를 이용한 부스팅 효과를 설명하기 위한 도 면들이다. 도 12는 일 실시 예에 따른 전자 장치의 일 구현 예를 나타내는 도면이다. 도 13은 일 실시 예에 따른 전자 장치의 제어 방법을 설명하기 위한 흐름도이다."}
