{"patent_id": "10-2021-0015144", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2022-0111857", "출원번호": "10-2021-0015144", "발명의 명칭": "이미지 적대적 공격에 대비하기 위한 이미지 학습 장치 및 방법", "출원인": "한양대학교 산학협력단", "발명자": "정기석"}}
{"patent_id": "10-2021-0015144", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "정상적인 이미지를 입력받아 신경망 연산을 통해 상기 정상적인 이미지에 대한 제1 픽셀별 필터 가중치를 설정하는 제1 학습부;상기 제1 학습부와는 독립적으로 학습되며, 상기 정상적인 이미지에 적대적 공격에 의해 노이즈를 부가한 이미지를 입력받아 신경망 연산을 통해 제2 픽셀별 필터 가중치를 설정하는 제2 학습부;상기 제1 픽셀별 필터 가중치로부터 상기 제2 픽셀별 필터 가중치를 픽셀별로 차감하여 제3 픽셀별 필터 가중치를 생성하는 차감부를 포함하는 것을 특징으로 하는 적대적 공격에 대비하기 위한 이미지 학습 장치."}
{"patent_id": "10-2021-0015144", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 제3 픽셀별 필터 가중치 중 음의 값을 가지는 가중치를 0으로 조정하는 가중치 조정부를 더 포함하는 것을특징으로 하는 적대적 공격에 대비하기 위한 이미지 학습 장치."}
{"patent_id": "10-2021-0015144", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서, 제1 학습부 및 제2 학습부는 클래스 인식을 학습하는 네트워크이며, 상기 제1 학습부 및 상기 제2 학습부는 동일한 신경망 구조 및 동일한 신경망 파라미터를 가지는 것을 특징으로 하는 적대적 공격에 대비하기 위한 이미지 학습 장치."}
{"patent_id": "10-2021-0015144", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서, 상기 제1 학습부 및 상기 제2 학습부 각각은신경망 연상을 통해 특징맵을 생성하는 특징맵 생성 네트워크;상기 생성된 특징맵에 대한 신경망 연산을 통해 클래스별 확률 정보를 생성하는 FC 네트워크; 및상기 FC 네트워크의 출력을 정답 라벨과 비교하여 손실을 역전파하는 손실 역전파부를 포함하고, 상기 제1 픽셀별 필터 가중치 및 상기 제2 픽셀별 필터 가중치는 상기 특징맵 생성 네트워크의 가중치인 것을특징으로 하는 적대적 공격에 대비하기 위한 이미지 학습 장치."}
{"patent_id": "10-2021-0015144", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "정상적인 이미지를 입력받아 제1 학습부의 신경망 연산을 통해 상기 정상적인 이미지에 대한 제1 픽셀별 필터가중치를 설정하는 단계(a);상기 정상적인 이미지에 적대적 공격에 의해 노이즈를 부가한 이미지를 입력받아 상기 제1 학습부와는 독립적으로 학습되는 제2 학습부의 신경망 연산을 통해 제2 픽셀별 필터 가중치를 설정하는 단게(b);상기 제1 픽셀별 필터 가중치로부터 상기 제2 픽셀별 필터 가중치를 픽셀별로 차감하여 제3 픽셀별 필터 가중치공개특허 10-2022-0111857-3-를 생성하는 단게(c)를 포함하는 것을 특징으로 하는 적대적 공격에 대비하기 위한 이미지 학습 방법."}
{"patent_id": "10-2021-0015144", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5항에 있어서, 상기 제3 픽셀별 필터 가중치 중 음의 값을 가지는 가중치를 0으로 조정하는 단게(d)를 더 포함하는 것을 특징으로 하는 적대적 공격에 대비하기 위한 이미지 학습 방법."}
{"patent_id": "10-2021-0015144", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제5항에 있어서, 제1 학습부 및 제2 학습부는 클래스 인식을 학습하는 네트워크이며, 상기 제1 학습부 및 상기 제2 학습부는 동일한 신경망 구조 및 동일한 신경망 파라미터를 가지는 것을 특징으로 하는 적대적 공격에 대비하기 위한 이미지 학습 방법."}
{"patent_id": "10-2021-0015144", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서, 상기 제1 학습부 및 상기 제2 학습부 각각은신경망 연상을 통해 특징맵을 생성하는 특징맵 생성 네트워크;상기 생성된 특징맵에 대한 신경망 연산을 통해 클래스별 확률 정보를 생성하는 FC 네트워크; 및상기 FC 네트워크의 출력을 정답 라벨과 비교하여 손실을 역전파하는 손실 역전파부를 포함하고, 상기 제1 픽셀별 필터 가중치 및 상기 제2 픽셀별 필터 가중치는 상기 특징맵 생성 네트워크의 가중치인 것을특징으로 하는 적대적 공격에 대비하기 위한 이미지 학습 방법."}
{"patent_id": "10-2021-0015144", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "이미지 적대적 공격에 대비하기 위한 이미지 학습 장치 및 방법이 개시된다. 개시된 장치는, 정상적인 이미지를 입력받아 신경망 연산을 통해 상기 정상적인 이미지에 대한 제1 픽셀별 필터 가중치를 설정하는 제1 학습부; 상 기 제1 학습부와는 독립적으로 학습되며, 상기 정상적인 이미지에 적대적 공격에 의해 노이즈를 부가한 이미지를 입력받아 신경망 연산을 통해 제2 픽셀별 필터 가중치를 설정하는 제2 학습부; 상기 제1 픽셀별 필터 가중치로부 터 상기 제2 픽셀별 필터 가중치를 픽셀별로 차감하여 제3 픽셀별 필터 가중치를 생성하는 차감부를 포함한다. 개시된 장치 및 방법에 의하면, 이미지의 특징에 기반하여 인공 신경망의 필터 가중치 조절을 통해 이미지의 적 대적 공격에 대해 효율적으로 대비할 수 있는 장점이 있다."}
{"patent_id": "10-2021-0015144", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 이미지 학습 장치 및 방법에 관한 것으로서, 더욱 상세하게는 이미지의 적대적 공격에 대비하기 위한 이미지 학습 장치 및 방법에 관한 것이다."}
{"patent_id": "10-2021-0015144", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "근래에 들어 딥 러닝 네트워크 및 콘볼루션 신경망 등 인공 신경망을 활용한 인공 지능에 대한 연구가 활발히 이루어지고 있다. 특히, 콘볼루션 신경망을 이용한 이미지 처리에 대해서는 급속한 발전이 이루어지고 있으며, 인공 신경망에 의한 이미지 처리는 기존의 알고리즘에 의한 이미지 처리에 비해 뛰어난 성능을 보여주고 있다. 인공 신경망에 대한 발전과 함께 인공 신경망의 성능을 저하시키는 적대적 공격이 대두되었다. 적대적 공격은 신경망 입력 대상 이미지에 의도적인 잡음을 부가하여 인공 신경망의 오작동을 유발하는 공격이다. 인공 신경망은 자율 주행 및 보안과 같이 안전과 직결되는 분야에도 활용될 수 있는데, 이와 같이 안전과 직결 되는 분야에서 인공 신경망의 오작동은 심각한 피해를 초래할 수 있다. 이에 따라 인공 신경망의 적대적 공격에 대응하기 위한 다양한 방법들이 논의되고 있다. 종래에 있어서, 적대적 공격은 인공 신경망과 선형성과 관련된 문제로 인식되었다. 그러나, 이러한 인식 논리만으로는 인공 신경망의"}
{"patent_id": "10-2021-0015144", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 2, "content": "적대적 공격에 효율적으로 대처할 수 없는 문제점이 있었다. 발명의 내용"}
{"patent_id": "10-2021-0015144", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명의 목적은 효율적으로 적대적 이미지 공격에 대응할 수 있는 이미지 학습 장치 및 방법을 제안하는 것이다. 본 발명의 다른 목적은 이미지의 특징에 기반하여 인공 신경망의 필터 가중치 조절을 통해 적대적 공격에 대비 하는 이미지 학습 장치 및 방법을 제안하는 것이다."}
{"patent_id": "10-2021-0015144", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기 목적을 달성하기 위한 본 발명의 일 측면에 따르면, 정상적인 이미지를 입력받아 신경망 연산을 통해 상기 정상적인 이미지에 대한 제1 픽셀별 필터 가중치를 설정하는 제1 학습부; 상기 제1 학습부와는 독립적으로 학습 되며, 상기 정상적인 이미지에 적대적 공격에 의해 노이즈를 부가한 이미지를 입력받아 신경망 연산을 통해 제2 픽셀별 필터 가중치를 설정하는 제2 학습부; 상기 제1 픽셀별 필터 가중치로부터 상기 제2 픽셀별 필터 가중치 를 픽셀별로 차감하여 제3 픽셀별 필터 가중치를 생성하는 차감부를 포함하는 적대적 공격에 대비하기 위한 이 미지 학습 장치가 제공된다. 상기 이미지 학습 장치는 상기 제3 픽셀별 필터 가중치 중 음의 값을 가지는 가중치를 0으로 조정하는 가중치 조정부를 더 포함한다. 제1 학습부 및 제2 학습부는 클래스 인식을 학습하는 네트워크이며, 상기 제1 학습부 및 상기 제2 학습부는 동 일한 신경망 구조 및 동일한 신경망 파라미터를 가진다. 상기 제1 학습부 및 상기 제2 학습부 각각은 신경망 연상을 통해 특징맵을 생성하는 특징맵 생성 네트워크; 상 기 생성된 특징맵에 대한 신경망 연산을 통해 클래스별 확률 정보를 생성하는 FC 네트워크; 및 상기 FC 네트워 크의 출력을 정답 라벨과 비교하여 손실을 역전파하는 손실 역전파부를 포함하고, 상기 제1 픽셀별 필터 가중치 및 상기 제2 픽셀별 필터 가중치는 상기 특징맵 생성 네트워크의 가중치인 것을 특징으로 하는 적대적 공격에 대비하기 위한 이미지 학습 장치. 본 발명의 다른 측면에 따르면, 정상적인 이미지를 입력받아 제1 학습부의 신경망 연산을 통해 상기 정상적인 이미지에 대한 제1 픽셀별 필터 가중치를 설정하는 단계(a); 상기 정상적인 이미지에 적대적 공격에 의해 노이 즈를 부가한 이미지를 입력받아 상기 제1 학습부와는 독립적으로 학습되는 제2 학습부의 신경망 연산을 통해 제 2 픽셀별 필터 가중치를 설정하는 단게(b); 상기 제1 픽셀별 필터 가중치로부터 상기 제2 픽셀별 필터 가중치를 픽셀별로 차감하여 제3 픽셀별 필터 가중치를 생성하는 단게(c)를 포함하는 적대적 공격에 대비하기 위한 이미 지 학습 방법이 제공된다."}
{"patent_id": "10-2021-0015144", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명에 의하면, 이미지의 특징에 기반하여 인공 신경망의 필터 가중치 조절을 통해 이미지의 적대적 공격에 대해 효율적으로 대비할 수 있는 장점이 있다."}
{"patent_id": "10-2021-0015144", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명과 본 발명의 동작상의 이점 및 본 발명의 실시에 의하여 달성되는 목적을 충분히 이해하기 위해서는 본 발명의 바람직한 실시예를 예시하는 첨부 도면 및 첨부 도면에 기재된 내용을 참조하여야만 한다. 이하, 첨부한 도면을 참조하여 본 발명의 바람직한 실시예를 설명함으로써, 본 발명을 상세히 설명한다. 그러 나, 본 발명은 여러 가지 상이한 형태로 구현될 수 있으며, 설명하는 실시예에 한정되는 것이 아니다. 그리고, 본 발명을 명확하게 설명하기 위하여 설명과 관계없는 부분은 생략되며, 도면의 동일한 참조부호는 동일한 부재 임을 나타낸다. 명세서 전체에서, 어떤 부분이 어떤 구성요소를 “포함”한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다른 구성요소를 제외하는 것이 아니라, 다른 구성요소를 더 포함할 수 있는 것을 의미한다. 또한, 명세서에 기재된 “...부”, “...기”, “모듈”, “블록” 등의 용어는 적어도 하나의 기능이나 동작을 처리하는 단위 를 의미하며, 이는 하드웨어나 소프트웨어 또는 하드웨어 및 소프트웨어의 결합으로 구현될 수 있다. 도 1은 인공 신경망의 적대적 공격의 예시를 나타낸 도면이다. 인공 신경망에서의 적대적 공격은 인간의 육안으로는 구별하기 어려운 노이즈를 이미지를 부가하여 인공 신경망 학습 모델의 오작동을 유발시키는 인공 신경망 공격 중 하나이다. 대표적인 적대적 공격으로는 FGSM(Fast Gradient Sign Method)가 있다. FGSM은 다음의 수학식 1과 같이 정의될 수 있다. 수학식 1"}
{"patent_id": "10-2021-0015144", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "위 수학식 1에서, ε은 미리 설정되는 상수이고, x는 입력 이미지, y는 입력 이미지의 정답 라벨이며, θ는 신 경망의 파라미터를 의미한다. 도 1을 참조하면, 원본 이미지, 적대적 공격 노이즈 및 적대적 공격에 의해 노이즈가 부가된 이미지가 각각 도 시되어 있다. 도 1을 참조하면, 적대적 공격에 의해 노이즈가 부가되었으나 육안으로는 이미지의 변화를 식별하 기 어려운 점을 확인할 수 있다. 적대적 공격은 인공 신경망에 대한 학습이 이루어질 때 수학식 1에 따른 노이즈를 역전파를 통해 이미지에 더해 주는 방식으로 이루어지며, 육안으로 식별하기 어렵기에 적대적 공격이 이루어졌는지 여부를 판단하기는 매우 어렵다. 적대적 공격은 MNST 데이터 셋에 대해 1.6%의 오류율을 보이는 학습 모델에서 99%의 오류율이 나타나도록 학습 모델의 심각한 오작동을 유발할 수 있게 된다. 기존의 연구에서는 적대적 공격은 인공 신경망의 선형성과 관련되어 발생하는 문제라고 생각되었다. 본 발명의 발명자의 연구에 의하면 이미지의 특징에 따라 적대적 공격에 의한 오작동의 영향이 다르며, 이러한 연구 결과 에 기초하여 본 발명은 적대적 공격에 대한 영향을 최소화할 수 있는 학습 장치 및 학습 방법을 제안한다. 이미지의 특징은 강인한(Robust) 특징과 강인하지 않은 특징으로 구분된다. 강인한 특징은 사람이 인식할 수 있 는 이미지의 특징이다. 예를 들어, 이미지가 고양이일 경우, 귀의 모양, 털의 색상, 꼬리의 길이 등은 고양이를 다른 객체와 구분할 수 있도록 하는 특징으로서 강인한 특징에 해당된다. 반대로, 강인하지 않은 특징은 해당 객체를 인식하는데 있어 큰 영향을 주지 못하는 특징을 의미하며, 강인하지 않은 특징은 사람은 인식하지 못하지만 인경 신경망에서는 인식되는 특징이다. 본 발명은 인공 신경망의 학습 결과를 이용하여 이미지에서 강인한 특징 부분의 픽셀과 강인하지 않은 특징 부 분의 픽셀을 구분하여 인공 신경망의 필터 가중치를 결정하는 방법을 제안한다. 본 발명의 발명자에 연구에 의하면, 적대적 공격에 노출되지 않은 이미지를 이용하여 학습을 수행할 경우 강인 한 부분 픽셀들의 필터 가중치는 상대적으로 큰 값을 갖도록 학습이 이루어진다. 예를 들어, 고양이를 포함하는 이미지의 경우, 고양이의 꼬리 영역, 귀 영역 등의 픽셀들에 대한 필터 가중치는 다른 영역에 비해 상대적으로 큰 값을 갖도록 학습이 이루어지며, 이러한 학습 결과를 통해 이미지에서 강인한 특징 부분을 판단할 수 있다. 반면에, 강인하지 않은 부분 픽셀들의 필터 가중치는 상대적으로 작은 값을 갖도록 학습이 이루어진다. 예를 들 어, 고양이를 포함하는 이미지에서 고양이의 주변 영역, 고양이의 다리 영역 등의 픽셀들의 필터 가중치는 다른 영역에 비해 상대적으로 작은 값을 갖도록 학습이 이루어지며, 이러한 학습 결과를 통해 이미지에서 강인하지 않은 특징 부분이 판단될 수 있다. 이하에서는 적대적 공격의 대비하기 위한 학습 장치 및 방법의 구조에 대해 도2 내지 도 8를 참조하여 더욱 상 세히 설명한다. 도 2는 본 발명의 일 실시예에 따른 이미지 적대적 공격에 대비하기 위한 학습 장치의 구조를 나타낸 블록도이 다. 도 2를 참조하면, 본 발명의 일 실시예에 따른 이미지 적대적 공격에 대비하기 위한 학습 장치는 제1 학습부 , 제2 학습부, 차감부 및 가중치 조정부를 포함한다. 제1 학습부는 정상적인 이미지를 입력받아 학습을 수행한다. 일례로, 제1 학습부는 클래스를 인식하 는 학습을 수행하는 학습 모듈일 수 있다. 도 3은 본 발명의 일 실시예에 따른 제1 학습부의 구조를 나타낸 블록도이다. 도 3을 참조하면, 본 발명의 일 실시예에 따른 제1 학습부는 제1 특징맵 생성 네트워크, 제1 FC(Fully Connected) 네트워크 및 제1 손실 역전파부를 포함한다. 앞서 설명한 바와 같이, 제1 학습부로는 정상적인 이미지가 입력되며, 정상적인 이미지는 1차적으로 특징 맵 생성 네트워크에 입력되어 신경망 연산이 이루어진다. 제1 특징맵 생성 네트워크는 현재 설정된 필터의 가중치를 각 픽셀별로 적용하여 신경망 연산을 수행함으로써 제1 특징맵을 생성한다. 제1 특징맵 생성 네트워크는 다수의 레이어로 이루어질 수 있으며, 일부 또는 전부의 레이어에서는 이미지의 사이즈를 축소 (풀링)하면서 제1 특징맵을 생성할 수 있다. 제1 특징맵 생성 네트워크를 통해 생성되는 제1 특징맵은 3차원 볼륨(X, Y, Z) 구조를 가지며, 채널축(Z) 에 각 픽셀별 특징 정보를 포함하고 있다. 특징맵 생성 과정에서 풀링이 이루어졌을 경우 특징맵의 X, Y 사이즈 는 입력된 이미지에 비해 작을 수 있다. 제1 특징맵 생성 네트워크는 인코더 네트워크만으로 이루어질 수도 있으며, 인코더 네트워크와 디코더 네 트워크를 모두 포함하는 네트워크일 수도 있다. 제1 FC 네트워크는 제1 특징맵 생성 네트워크에 의해 생성된 제1 특징맵에 대해 추가적인 신경망 연 산을 수행하여, 미리 설정된 N개의 클래스에 대한 확률 정보를 생성한다. 여기서 클래스는 인식하고자 하는 객 체를 의미한다. 예를 들어, 개, 고양이, 독수리, 소를 이미지로부터 인식하고자 하는 네트워크일 경우, 개, 고 양이, 독수리, 소가 각 클래스에 해당된다. 제1 FC 네트워크는 신경망 연산을 통해 각 클래스별 확률 정보를 생성하며, 이중 가장 높은 확률을 가지는 클래스를 입력된 이미지에 포함된 객체라고 판단한다. 앞서 설명한 예에서, 개, 고양이, 독수리, 소가 클래스이 고, 고양이에 대한 클래스 확률값이 가장 높은 것으로 제1 FC 네트워크에서 출력될 경우 이미지에 포함된 객체는 고양이라고 판단하는 것이다. 손실 역전파부는 제1 FC 네트워크를 통해 생성되는 클래스별 확률값과 정답 라벨을 비교하고, 손실을 역전파하는 기능을 한다. 예를 들어, 개 고양이, 독수리, 소를 인식하는 네트워크에서, 입력된 이미지가 고양이 일 경우, 제1 FC 네트워크의 출력은 고양이일 확률이 1이고, 다른 객체일 확률이 0인 것이 가장 이상적이다. 그러나, 학습이 완벽히 완료되지 않은 신경망은 이와 같은 정답을 출력하지는 아니하며, 손실 역전파부는 제1 FC 네트워크의 출력과 정답 라벨 사이의 차를 제1 FC 네트워크 및 제1 특징맵 생성 네트워크에 역전파하는 것이다. 손실 역전파부에 의해 역전파되는 손실을 줄이는 방향으로 제1 FC 네트워크 및 제1 특징맵 생성 네트 워크의 필터 가중치는 갱신된다. 위에서 설명한 바와 같은 학습은 다수의 학습 이미지를 가지고 반복적으로 이루어지며, 손실이 미리 설정된 임 계값 이하로 수렴할 때까지 학습이 이루어진다. 도 4는 본 발명의 일 실시예에 따른 제1 학습부에 의해 학습되는 픽셀별 필터 가중치의 일례를 나타낸 도면이다. 도 4에는 이미지를 다수의 그리드로 구분한 도면이 도시되어 있으며, 다수의 그리드 각각은 픽셀을 의미한다. 도 4에서, 진한 색으로 표시된 픽셀은 상대적으로 큰 필터 가중치가 적용되는 픽셀이며, 상대적으로 연한 색으 로 표시된 픽셀은 상대적으로 작은 필터 가중치가 적용되는 픽셀이다. 본 발명의 발명자의 연구에 의하면, 진한 색으로 표시된 픽셀(상대적으로 큰 필터 가중치가 적용되는 픽셀) 영 역은 강인한 특징 부분이고, 연한 색으로 표시된 픽셀(상대적으로 작은 필터 가중치가 적용되는 픽셀) 영역은 강인하지 않은 특징 부분이다. 한편, 여기서 필터 가중치는 이미지 픽셀에 대해 신경망 연산을 수행하는 제1 특징맵 생성 네트워크의 필 터 가중치를 의미하며, 제1 FC 네트워크는 스칼라 값인 확률 정보를 생성하는 네트워크이므로 제1 FC 네트 워크의 가중치는 본 발명에서 정의하는 필터 가중치에 포함되지 않는다. 다시 도 2를 참조하면, 제2 학습부로는 제1 학습부에 입력되는 정상적인 이미지에 대해 적대적 공격 에 의해 노이즈가 부가된 이미지가 입력된다. 제1 학습부에는 정상적인 이미지가 입력되어 학습되나, 제2 학습부에서는 적대적 공격에 의해 노이즈가 부가된 이미지를 이용하여 학습을 수행하는 것이다. 제1 학습부에서의 학습과 제2 학습부에서의 학습은 독립적으로 이루어진다. 도 5는 본 발명의 일 실시예에 따른 제2 학습부의 구조를 나타낸 블록도이다. 도 5를 참조하면, 본 발명의 일 실시예에 따른 제2 학습부는 제2 특징맵 생성 네트워크, 제2 FC(Fully Connected) 네트워크 및 제1 손실 역전파부를 포함한다. 제2 학습부의 구성은 제1 학습부의 구성과 동일하다. 제2 학습부는 개념적인 구성뿐만 아니라 신경망 파라미터 역시 제1 학습부와 동일하다. 예를 들어, 신경망의 레이어의 수, 각 레이어에서 픽셀에 적용되는 필터의 사이즈는 동일하게 형성된다. 결국, 입력되는 이미지만 상이할 뿐 제1 학습부와 제2 학습부는 동일한 신경망 파라미터를 가진 신경망인 것이다. 제2 특징맵 생성 네트워크에서는 신경망 연산을 수행하여 제2 특징맵을 생성하고, 제2 FC 네트워크는 신경망 연산을 통해 각 클래스별 확률 정보를 생성한다. 제2 학습부는 제2 손실 역전파부가 정답 라벨과 클래스별 확률 정보 사이의 차를 손실로 제2 FC 네트워크 및 제2 특징맵 생성 네트워크에 역전파하여 필터 가중치에 대한 업데이트가 이루어지는 방식으로 학습이 된다. 제2 학습부는 적대적 공격에 의하 노이즈를 부가한 이미지로 학습이 이루어지기에 제2 학습부 신경망 (구체적으로는 제2 특징맵 생성 네트워크)의 필터 가중치는 제1 학습부와는 다른 값을 가지게 된다. 도 6은 본 발명의 일 실시예에 따른 제2 학습부에 의해 학습되는 픽셀별 필터 가중치의 일례를 나타낸 도면이다. 도 6에서, 진한 색으로 표시된 픽셀은 상대적으로 큰 필터 가중치가 적용되는 픽셀이며, 상대적으로 연한 색으 로 표시된 픽셀은 상대적으로 작은 필터 가중치가 적용되는 픽셀이다. 제2 학습부는 적대적 공격에 의한 노이즈가 부가된 이미지로 학습이 이루어지게 되므로, 본 발명의 발명자 의 연구에 의하면, 진한 색으로 표시된 픽셀(상대적으로 큰 필터 가중치가 적용되는 픽셀) 영역은 강인하지 않 은 특징 부분이고, 연한 색으로 표시된 픽셀(상대적으로 작은 필터 가중치가 적용되는 픽셀) 영역은 강인한 특징 부분이다. 다시 도 2를 참조하면, 차감부는 학습이 완료된 제1 학습부의 픽셀별 필터 가중치와 학습이 완료된 제2 학습부의 픽셀별 필터 가중치를 입력받으며, 각 픽셀별로 제1 학습부의 필터 가중치로부터 제2 학습부의 필터 가중치를 차감한다. 강인한 특징 부분의 픽셀의 경우, 제1 학습부는 상대적으로 큰 필터 가중치를 가지고, 제2 학습부는 상대적으로 작은 필터 가중치를 가지게 되므로 큰 값에서 작은 값을 차감하는 연산이 차감부에서 이루어진 다. 강인하지 않은 특징 부분의 픽셀의 경우 제1 학습부는 상대적으로 작은 필터 가중치를 가지고, 제2 학습부 는 상대적으로 큰 필터 가중치를 가지게 되므로 작은 값에서 큰 값을 차감하는 연산이 차감부에서 이 루어진다. 결국, 차감부에서의 차감 연산에 의해 강인한 부분의 픽셀들의 필터 가중치와 강인하지 않은 부분의 픽셀 들의 필터 가중치간 차이는 더욱 커지게 된다. 특히, 차감부에서의 차감 연산에 의해 강인하지 않은 특징 부분의 픽셀들의 필터 가중치는 사실상 음의 값을 가지게 된다. 일반적으로 신경망의 필터 가중치는 손실을 역전파하여 손실을 최소화하는 방향으로만 갱신된다. 그러나, 본 발 명은 독립적으로 학습된 제1 학습부의 픽셀별 필터 가중치에서 독립적으로 학습된 제2 학습부의 픽셀 별 필터 가중치를 인위적으로 차감하여 최종적인 필터 가중치를 생성하도록 한다. 도 7은 본 발명의 일 실시예에 따른 차감부의 동작을 개념적으로 나타낸 도면이다. 도 7에 도시된 바와 같이, 차감부는 픽셀별로 제1 학습부의 필터 가중치에서 제2 학습부의 필터 가중치를 차감하도록 동작한다. 이러한 차감에 의해, 강인하지 않은 특징 부분의 픽셀은 사실상 음의 값을 가지게 되며, 이로 인해 강인하지 않은 특징 부분의 픽셀은 신경망 연산에 영향을 미치지 않게 된다. 도 2를 참조하면, 가중치 조정부는 차감부에 의해 변환된 픽셀별 필터 가중치를 조정하는 기능을 한 다. 가중치 조정부는 본 발명의 필수적인 구성 요소는 아니며, 신경망에서 사용되는 활성화 함수 (Activation Function)에 따라 사용되거나 사용되지 않을 수 있다. 가중치 조정부는 차감부의 차감에 의해 변환된 가중치들 중 음의 값을 가지는 가중치들을 0으로 변환 한다. 신경망 연산에서 음의 가중치는 예측하지 못한 결과를 초래할 수 있으므로 음의 가중치를 0의 값으로 조 정하는 것이다. 그러나, 신경망의 활성화 함수 중 Relu 함수와 같은 함수는 자동적으로 음의 값을 0으로 적용하여 연산을 수행 하므로 가중치 조정부에 의한 가중치 조정이 필수적이지 않다. 본 발명의 적대적 공격에 대비하기 위한 학습 장치는 동일한 이미지에 대해 정상적인 이미지와 적대적 공격에 의한 노이즈를 부가한 이미지를 독립적으로 학습시킨 후 픽셀별 가중치를 차감하기에 강이하지 않은 특징 부분 의 필터 가중치를 실질적으로 0으로 만들 수 있다. 이로 인해 이미지가 적대적 공격에 의해 노이즈에 노출되더 라도 해당 노이즈에 의한 영향을 최소화하여 적대적 공격에 의한 신경망 연산 오류를 방지할 수 있다. 도 8은 본 발명의 일 실시예에 따른 이미지 적대적 공격에 대비하기 위한 학습 방법의 전체적인 흐름을 나타낸 순서도이다. 정상적인 이미지를 준비하고, 정상적인 이미지를 신경망인 제1 학습부에 입력하여 학습시킨다(단계 800). 학습 은 클래스 인식을 위한 학습이며, 정답 레벨과 제1 학습부의 신경망 연산 결과에 따른 손실을 역전파하면서 이 루어지며, 학습에 의해 제1 학습부의 픽셀별 필터 가중치가 결정된다. 정상적인 이미지와 동일한 이미지에 대해 적대적 공격에 의해 노이즈가 부가된 이미지를 준비하고, 적대적 공격 에 의해 노이즈가 부가된 이미지를 신경망인 제2 학습부에 입력하여 학습시킨다(단계 802). 제2 학습부의 학습 역시 클래스 인식을 위한 학습이며, 정답 레벨과 제2 학습부의 신경망 연산 결과에 따른 손실을 역전파하여 이 루어지며, 학습에 의해 제2 학습부의 픽셀별 필터 가중치가 결정된다. 제1 학습부 및 제2 학습부의 학습이 완료되면 제1 학습부의 픽셀별 필터 가중치로부터 제2 학습부의 픽셀별 필 터 가중치를 픽셀별로 차감하여 새로운 필터 가중치를 생성한다(단계 804). 앞서 설명한 바와 같이, 제1 학습부 의 필터 가중치는 강인한 특징 부분의 필터 가중치가 상대적으로 큰 값을 가지고 제2 학습부의 필터 가중치는강인하지 않은 특징 부분의 필터 가중치가 상대적으로 큰 값을 가지므로, 차감에 의해 강인하지 않은 특징 부분 의 가중치는 실질적으로 음의 값을 가지게 된다. 차감 연산이 이루어진 후, 음의 값을 가지는 필터 가중치를 '0'으로 조정한다(단계 806). 앞서 설명한 바와 같 이, 이러한 조정이 필요 없는 활성화 함수가 신경망에서 사용될 경우 가중치 조정은 수행되지 않아도 무방하다. 본 발명에 따른 방법은 컴퓨터에서 실행 시키기 위한 매체에 저장된 컴퓨터 프로그램으로 구현될 수 있다. 여 기서 컴퓨터 판독가능 매체는 컴퓨터에 의해 액세스 될 수 있는 임의의 가용 매체일 수 있고, 또한 컴퓨터 저장 매체를 모두 포함할 수 있다. 컴퓨터 저장 매체는 컴퓨터 판독가능 명령어, 데이터 구조, 프로그램 모듈 또는 기타 데이터와 같은 정보의 저장을 위한 임의의 방법 또는 기술로 구현된 휘발성 및 비휘발성, 분리형 및 비분 리형 매체를 모두 포함하며, ROM(판독 전용 메모리), RAM(랜덤 액세스 메모리), CD(컴팩트 디스크)-ROM, DVD(디 지털 비디오 디스크)-ROM, 자기 테이프, 플로피 디스크, 광데이터 저장장치 등을 포함할 수 있다. 본 발명은 도면에 도시된 실시예를 참고로 설명되었으나 이는 예시적인 것에 불과하며, 본 기술 분야의 통상의 지식을 가진 자라면 이로부터 다양한 변형 및 균등한 타 실시예가 가능하다는 점을 이해할 것이다. 따라서, 본 발명의 진정한 기술적 보호 범위는 첨부된 청구범위의 기술적 사상에 의해 정해져야 할 것이다."}
{"patent_id": "10-2021-0015144", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 인공 신경망의 적대적 공격의 예시를 나타낸 도면. 도 2는 본 발명의 일 실시예에 따른 이미지 적대적 공격에 대비하기 위한 학습 장치의 구조를 나타낸 블록도. 도 3은 본 발명의 일 실시예에 따른 제1 학습부의 구조를 나타낸 블록도. 도 4는 본 발명의 일 실시예에 따른 제1 학습부에 의해 학습되는 픽셀별 필터 가중치의 일례를 나타낸 도면.도 5는 본 발명의 일 실시예에 따른 제2 학습부의 구조를 나타낸 블록도. 도 6은 본 발명의 일 실시예에 따른 제2 학습부에 의해 학습되는 픽셀별 필터 가중치의 일례를 나타낸 도면. 도 7은 본 발명의 일 실시예에 따른 차감부의 동작을 개념적으로 나타낸 도면. 도 8은 본 발명의 일 실시예에 따른 이미지 적대적 공격에 대비하기 위한 학습 방법의 전체적인 흐름을 나타낸 순서도."}
