{"patent_id": "10-2022-0123978", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0044673", "출원번호": "10-2022-0123978", "발명의 명칭": "독순술 네트워크 지원을 위한 엣지용 ＳｏＣ", "출원인": "주식회사 뮤링크", "발명자": "이동훈"}}
{"patent_id": "10-2022-0123978", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "마이크로폰으로부터 출력되는 전기적인 신호로부터 화자의 음성의 음소에 대한 데이터를 추출하는 음성음소추출부;카메라에 의해 획득되는 화자의 입술 이미지로부터 음소 각각을 추출하는 입술음소추출부;상기 입술음소추출부에 의해 추출한 음소 각각에 매칭되는 데이터를 획득하는 AI독순술모델부;상기 음성음소추출부에 의해 추출한 음소 각각에 대한 데이터 중에서 음소 판독이 안되는 데이터를 상기 AI독순술모델부에서 획득하는 데이터 중에서, 해당하는 음소의 데이터로 교체하는 웨이브폼필터부; 및상기 웨이브폼필터부에 의해 음소의 데이터가 교체된 음소 전체의 데이터를 이어서 정렬시키는 웨이브폼재정렬부;를 포함하고SoC(System on Chip)로 이루어지고, 상기 웨이브폼재정렬부에 의해 정렬된 음성 데이터를 외부의 음성인식분석서버에 제공하도록 함으로써, 상기 음성인식분석서버에 대한 데이터망의 병목 현상을 줄이도록 하는, 독순술 네트워크 지원을 위한 엣지용 SoC."}
{"patent_id": "10-2022-0123978", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "청구항 1에 있어서,상기 카메라로부터 획득되는 화자의 이미지로부터 등록된 화자인지를 판단하고, 등록된 화자인 경우에 한해서음성 인식 절차를 수행하도록 제어하는 화자인식부를 더 포함하는, 독순술 네트워크 지원을 위한 엣지용 SoC."}
{"patent_id": "10-2022-0123978", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "청구항 2에 있어서,사용자의 조작신호에 의해 학습모드를 설정 및 설정 해제하도록 하고, 상기 학습모드의 설정 여부에 무관하게상기 화자인식부에 의해 판단된 화자가 등록된 화자인 경우에 한해서 음성 인식 절차를 수행하도록 하되, 상기학습모드가 설정된 경우, 상기 화자인식부에 의해 판단된 화자가 등록된 화자가 아닌 경우, 등록된 화자가 아닌화자의 음성에 대하여 상기 웨이브폼재정렬부로부터 출력되는 음소와 이의 데이터를 기계 학습에 사용되기 위하여 데이터베이스화하는 학습모드설정부; 및 상기 학습모드설정부에 의해 데이터베이스화된 데이터를 저장하는 데이터베이스부;를 포함하는, 독순술 네트워크 지원을 위한 엣지용 SoC."}
{"patent_id": "10-2022-0123978", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "청구항 3에 있어서,상기 데이터베이스부는,상기 등록된 화자가 아닌 화자의 음성에서 음소별로 데이터베이스화하는 음소모델부;상기 등록된 화자가 아닌 화자의 음성에서 음소의 집합체인 단어별로 데이터베이스화하는 단어모델부; 및상기 등록된 화자가 아닌 화자의 음성에서 단어의 집합체인 문장별로 데이터베이스화하는 문장모델부;를 포함하고,상기 웨이브폼재정렬부에 의해 처리된 데이터를 전송받아 인식된 음성을 분석하여 해당하거나 연관되는 데이터를 제공하도록 하는 음성인식분석서버에 제공하는, 독순술 네트워크 지원을 위한 엣지용 SoC."}
{"patent_id": "10-2022-0123978", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "공개특허 10-2024-0044673-3-청구항 2에 있어서,마이크로폰으로부터 출력되는 전기적인 신호로부터 추출되는 소음이 정해진 크기 이하일 때, 상기 마이크로폰으로부터 출력되는 화자의 음성에 대한 전기적인 신호를 상기 웨이브폼필터부 및 상기 웨이브폼재정렬부에 의한프로세스를 생략한 상태로 상기 음성인식분석서버에 바로 제공하도록 하고, 이 경우 상기 음성인식분석서버로부터 음성 인식에 대한 결과물이 만족하지 않는 것으로 조작신호를 입력받으면, 상기 화자의 음성에 대한 전기적인 신호를 상기 웨이브폼필터부 및 상기 웨이브폼재정렬부에 의한 프로세스를 거쳐서 정렬된 음성 데이터를 외부의 음성인식분석서버에 제공하도록 하며, 상기 음성 인식에 대한 결과물이 만족하지 않는 것으로 조작신호를입력한 화자를 상기 화자인식부에 의해 확인하여, 확인된 화자가 이후 음성 인식 절차를 수행시, 상기 웨이브폼필터부 및 상기 웨이브폼재정렬부에 의한 프로세스를 반드시 거치도록 제어하는 소음검출기능선택부를 더 포함하는, 독순술 네트워크 지원을 위한 엣지용 SoC."}
{"patent_id": "10-2022-0123978", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 마이크로폰으로부터 출력되는 전기적인 신호로부터 화자의 음성의 음소에 대한 데이터를 추출하는 음 성음소추출부; 카메라에 의해 획득되는 화자의 입술 이미지로부터 음소 각각을 추출하는 입술음소추출부; 상기 입술음소추출부에 의해 추출한 음소 각각에 매칭되는 데이터를 획득하는 AI독순술모델부; 상기 음성음소추출부에 (뒷면에 계속)"}
{"patent_id": "10-2022-0123978", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 독순술 네트워크 지원을 위한 엣지용 SoC에 관한 것으로서, 보다 상세하게는 스마트 가전 및 AI 음성 비서 등 음성 명령 단말기기의 필수 기능 소자로 대규모 영상 및 음성 네트워크 병목 현상을 일으키는 데이터 센터의 과부하를 해결하는 독순술 네트워크 지원을 위한 엣지용 SoC에 관한 것이다."}
{"patent_id": "10-2022-0123978", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "일반적으로, 음성 인식을 이용한 시스템, 예컨대, 알렉사 등과 같은 비서 시스템의 경우, 집이나 사무실 등에서 사용이 보편화되고 있는데, 오동작으로 인해 사회적, 물질적 피해와 시간이 낭비되고 있다. 이러한 음성 인식 시스템의 문제 원인은 현재 97% 이상의 음성인식률의 문제가 아니고, 음성 인식 시스템이 자 기한테 명령을 누가 하는지를 확인하지 못하는 경우가 주원인으로 발생하고 있다. 예를 들면, 아마존의 알렉사 등은 현재 음성인식이 잘못되어 상품의 자동 주문에 문제가 발생하고, 피해를 복구하는데 많은 시간과 노력이 투자되고 있으나, 음성인식만으로는 주인이 누구인지 판단하는 기술이 부족하여, 향후 현재 문제점들을 해결하 는데 막대한 비용이 소요될 것으로 판단하고 있다. 특히, TV 등은 가정에서 계속해서 말소리가 나오는 시스템으로 혼동의 주원인을 제공하는 소스이고, 자체 음성 인식 명령을 사용하는데 문제가 있으며, 아이들이 떠드는 소리 등 생활잡음의 혼선 등으로 인해, 편리한 기능을 탑재함에도, 실제 생활 환경에서 제품 자체 기능을 사용하지 않는 문제로 번지고 있다. 이와 같은 음성 인식 시스템과 관련되는 종래 기술로서, 한국공개특허 제10-1817-002708호의 \" 음성 인식 및 대 화가 가능한 음식 주문용 스마트 스피커 및 이를 이용한 음식 주문 서비스 플랫폼\"이 제시된 바 있는데, 이는 사용자의 음식 추천 요청 또는 음식 주문 요청에 대한 음성을 인식하는 음성 인식부; 인식된 음성의 패턴을 분 석하는 패턴 분석부; 유무선 네트워크 통신 기술을 통해 통합 서버와 연결되며, 상기 패턴에 상응하는 음식 추 천 데이터의 검색을 요청 및 검색 결과를 수신하는 통신부; 수신된 상기 검색 결과를 사용자에게 출력하는 출력 부; 및 상기 음식 주문 요청을 토대로, 상기 음식 추천 데이터에 대한 음식 주문 데이터를 생성하여 주문 및 결 제를 진행하는 주문 진행부;를 포함한다. 최근에는 음성 인식에 대해서 인식률 향상에 한계를 가짐으로써, 독순술 기능을 이용한 음성 인식에 대한 기술 이 개발되고 있다. 그러나, 독순술 기능을 이용한 음성 인식을 제공하기 위한 시스템의 경우, 대규모 계산량과 학습데이터의 요구 로 데이터 센터에서 서비스되는 경우, 사생활 프라이버시 문제와 이미지 데이터량의 폭주로 인해 서비스에 문제 가 발생하며, AI 독순술이 현재 생활 소음 내에서 자체 이미지 성능으로는 54%의 낮은 성능을 가지게 되는 문제 점이 있었다."}
{"patent_id": "10-2022-0123978", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "상기한 바와 같은 종래 기술의 문제점을 해결하기 위하여, 본 발명은 직접 아날로그 음소 파형의 보완으로 경량 화 구현 및 기존 통신 방식을 유지하여, 기존의 별도 알고리즘(입술인식, 음성인식) 통합 효과로 독순술 복잡도를 회피하고, 사생활 프라이버시 문제와 제기된 사회 문제 해결에 기여하며, 단순 DNN(Deep Neural Network) 기 능 활용으로 인공지능 SoC(System on Chip) 구현이 용이하고, 자체 학습 기능으로 대용량의 학습 데이터 세트 개발 최소화를 실현하여, 음성 활동 탐지기 및 소음 추정기를 필요로 하지 않으며, 스마트 가전 및 AI 음성비서 등 음성 명령 단말기기의 필수 기능 소자로 대규모 영상 및 음성 네트워크 병목 현상을 일으키는 데이터 센터의 과부하를 해결하는데 목적이 있다. 본 발명의 다른 목적들은 이하의 실시례에 대한 설명을 통해 쉽게 이해될 수 있을 것이다."}
{"patent_id": "10-2022-0123978", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기한 바와 같은 목적을 달성하기 위해, 본 발명의 일측면에 따르면, 마이크로폰으로부터 출력되는 전기적인 신호로부터 화자의 음성의 음소에 대한 데이터를 추출하는 음성음소추출부; 카메라에 의해 획득되는 화자의 입 술 이미지로부터 음소 각각을 추출하는 입술음소추출부; 상기 입술음소추출부에 의해 추출한 음소 각각에 매칭 되는 데이터를 획득하는 AI독순술모델부; 상기 음성음소추출부에 의해 추출한 음소 각각에 대한 데이터 중에서 음소 판독이 안되는 데이터를 상기 AI독순술모델부에서 획득하는 데이터 중에서, 해당하는 음소의 데이터로 교 체하는 웨이브폼필터부; 및 상기 웨이브폼필터부에 의해 음소의 데이터가 교체된 음소 전체의 데이터를 이어서 정렬시키는 웨이브폼재정렬부;를 포함하고 SoC(System on Chip)로 이루어지고, 상기 웨이브폼재정렬부에 의해 정렬된 음성 데이터를 외부의 음성인식분석서버에 제공하도록 함으로써, 상기 음성인식분석서버에 대한 데이터 망의 병목 현상을 줄이도록 하는, 독순술 네트워크 지원을 위한 엣지용 SoC가 제공된다. 상기 카메라로부터 획득되는 화자의 이미지로부터 등록된 화자인지를 판단하고, 등록된 화자인 경우에 한해서 음성 인식 절차를 수행하도록 제어하는 화자인식부를 더 포함할 수 있다. 사용자의 조작신호에 의해 학습모드를 설정 및 설정 해제하도록 하고, 상기 학습모드의 설정 여부에 무관하게 상기 화자인식부에 의해 판단된 화자가 등록된 화자인 경우에 한해서 음성 인식 절차를 수행하도록 하되, 상기 학습모드가 설정된 경우, 상기 화자인식부에 의해 판단된 화자가 등록된 화자가 아닌 경우, 등록된 화자가 아닌 화자의 음성에 대하여 상기 웨이브폼재정렬부로부터 출력되는 음소와 이의 데이터를 기계 학습에 사용되기 위하 여 데이터베이스화하는 학습모드설정부; 및 상기 학습모드설정부에 의해 데이터베이스화된 데이터를 저장하는 데이터베이스부;를 더 포함할 수 있다. 상기 데이터베이스부는, 상기 등록된 화자가 아닌 화자의 음성에서 음소별로 데이터베이스화하는 음소모델부; 상기 등록된 화자가 아닌 화자의 음성에서 음소의 집합체인 단어별로 데이터베이스화하는 단어모델부; 및 상기 등록된 화자가 아닌 화자의 음성에서 단어의 집합체인 문장별로 데이터베이스화하는 문장모델부;를 포함하고, 상기 웨이브폼재정렬부에 의해 처리된 데이터를 전송받아 인식된 음성을 분석하여 해당하거나 연관되는 데이터 를 제공하도록 하는 음성인식분석서버에 제공할 수 있다. 마이크로폰으로부터 출력되는 전기적인 신호로부터 추출되는 소음이 정해진 크기 이하일 때, 상기 마이크로폰으 로부터 출력되는 화자의 음성에 대한 전기적인 신호를 상기 웨이브폼필터부 및 상기 웨이브폼재정렬부에 의한 프로세스를 생략한 상태로 상기 음성인식분석서버에 바로 제공하도록 하고, 이 경우 상기 음성인식분석서버로부 터 음성 인식에 대한 결과물이 만족하지 않는 것으로 조작신호를 입력받으면, 상기 화자의 음성에 대한 전기적 인 신호를 상기 웨이브폼필터부 및 상기 웨이브폼재정렬부에 의한 프로세스를 거쳐서 정렬된 음성 데이터를 외 부의 음성인식분석서버에 제공하도록 하며, 상기 음성 인식에 대한 결과물이 만족하지 않는 것으로 조작신호를 입력한 화자를 상기 화자인식부에 의해 확인하여, 확인된 화자가 이후 음성 인식 절차를 수행시, 상기 웨이브폼 필터부 및 상기 웨이브폼재정렬부에 의한 프로세스를 반드시 거치도록 제어하는 소음검출기능선택부를 더 포함 할 수 있다."}
{"patent_id": "10-2022-0123978", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명에 따른 독순술 네트워크 지원을 위한 엣지용 SoC에 의하면, 직접 아날로그 음소 파형의 보완으로 경량 화 구현 및 기존 통신 방식을 유지하여, 기존의 별도 알고리즘(입술인식, 음성인식) 통합 효과로 독순술 복잡도 를 회피할 수 있고, 사생활 프라이버시 문제와 제기된 사회 문제 해결에 기여할 수 있으며, 단순 DNN(Deep Neural Network) 기능 활용으로 인공지능 SoC(System on Chip) 구현이 용이할 수 있고, 자체 학습 기능으로 대 용량의 학습 데이터 세트 개발 최소화를 실현하여, 음성 활동 탐지기 및 소음 추정기를 필요로 하지 않도록 할 수 있으며, 스마트 가전 및 AI 음성비서 등 음성 명령 단말기기의 필수 기능 소자로 대규모 영상 및 음성 네트 워크 병목 현상을 일으키는 데이터 센터의 과부하를 해결하도록 하는 효과를 가진다."}
{"patent_id": "10-2022-0123978", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명은 다양한 변경을 가할 수 있고, 여러 가지 실시례를 가질 수 있는 바, 특정 실시례들을 도면에 예시하 고, 상세하게 설명하고자 한다. 그러나, 이는 본 발명을 특정한 실시 형태에 대해 한정하려는 것이 아니고, 본 발명의 기술 사상 및 기술 범위에 포함되는 모든 변경, 균등물 내지 대체물을 포함하는 식으로 이해되어야 하고, 여러 가지 다른 형태로 변형될 수 있으며, 본 발명의 범위가 하기 실시례에 한정되는 것은 아니다. 이하, 첨부된 도면을 참조하여 본 발명에 따른 실시례를 상세히 설명하며, 도면 부호에 관계없이 동일하거나 대 응하는 구성요소에 대해서는 동일한 참조 번호를 부여하고, 이에 대해 중복되는 설명을 생략하기로 한다. 도 1은 본 발명의 일 실시례에 따른 독순술 네트워크 지원을 위한 엣지용 SoC는 도시한 구성도이다. 도 1을 참조하면, 본 발명의 일 실시례에 따른 독순술 네트워크 지원을 위한 엣지용 SoC는 음성음소추출부 , 입술음소추출부, AI독순술모델부, 웨이브폼필터부 및 웨이브폼재정렬부를 포함할 수 있 고, SoC(System on Chip)로 이루어지며, 웨이브폼재정렬부에 의해 정렬된 음성 데이터를 외부의 음성인식분 석서버(도 2 참조)에 제공하도록 함으로써, 음성인식분석서버에 대한 데이터망의 병목 현상을 줄이도록 할 수 있다. 음성음소추출부는 마이크로폰으로부터 출력되는 전기적인 신호로부터 음성의 음소에 대한 데이터를 추출 하도록 한다. 여기서, 음소에 대한 데이터는 음소별 시간적으로 대응되는 주파수 및 진폭 등의 오디오 파형이나 스펙트로그램(spectrogram) 등일 수 있고, 이 밖에도 음소를 특정할 수 있는 다양한 방식의 각종 데이터가 적용 될 수 있다. 마이크로폰은 화자의 음성을 수집하여 전기적 신호로 출력하도록 한다. 입술음소추출부는 카메라에 의해 획득되는 입술 이미지로부터 음소 각각을 추출하도록 한다. 입술음소추 출부는 카메라에 의해 획득되는 이미지에서 입술 이미지를 추출하여, 추출된 입술 이미지를 이미지 프로 세싱에 의해, 입술 이미지를 나타내는 음소를 추출하도록 할 수 있다. 이때, 음소별 입술의 특징을 매칭시킨 데 이터를 음소 추출을 위한 기본 데이터로서 제공받거나 미리 저장받아 사용할 수 있다. 카메라는 화자의 입술 에 대한 이미지를 마이크로폰에 의한 음성의 수집과 동시에 획득하도록 구성될 수 있다. AI독순술모델부는 입술음소추출부에 의해 추출한 음소 각각에 매칭되는 데이터를 획득하도록 하는데, 이는 예컨대 데이터베이스부에 미리 저장된 음소별 데이터로부터 입술음소추출부에 의해 추출한 음소 각각에 해당하는 데이터를 획득하도록 한다. 여기서, 데이터는 후술하게 될 음성인식분석서버에서 요구하는 형 태의 데이터로서, 음소를 특정하는 각종 데이터가 적용될 수 있다. AI독순술모델부는 일례로 HMM(Hidden Markov Model) 방식을 이용할 수 있는데, HMM은 관측 불가능한 프로세 스를 관측 가능한 다른 프로세스를 통해 추정하는 이중 확률처리 방법으로서, 음성 인식의 최소단위(음소)를 모 델링해서, 이를 이용해 음성인식 기술을 구성할 수 있다. 이에 따라 HMM의 장점은 인식률이 높고, 딥러닝 및 분 석 음향 모델링(필터링 기반 접근방식)의 보완적 장점 활용 설계와 시각적으로 파생된 음성 모델(입술 읽기)을사용하여, 깨끗한 오디오 특징(feature) 추정이 가능하며, 향상된 시각적 파생 Wiener 필터에 추정된 깨끗한 오 디오 특징을 적용할 수 있다. 도 3을 참조하면, 독순술 회귀 모델에 기반한 누적된 장기 단기 기억 구조와 LSTM 네트워크는 입력 계층, 두 개의 LSTM 계층 및 출력 조밀 계층 구성이 가능한데, 5개의 이전 시각 프레임의 예로 서, 현재 시각 프레임 tk와 이전 시각 프레임 tk-1, tk-2, tk3, tk4, tk5가 시간 인스턴스 tk, tk-1, ..., tk- 5(k는 현재 시간 인스턴스이고, 5는 이전 비주얼 프레임의 수)의 시각적 특징이 스택된 LSTM 레이어에 공급된다. 하위 LSTM 계층에는 250개의 셀이 있으며, 입력을 인코딩하고, 숨겨진 상태를 300개의 셀이 있는 두 번째 LSTM 계층으로 전달하며, 두 번째 LSTM 계층의 출력은 선형 활성화 기능을 가진 총 23개의 뉴런이 있는 완 전 연결(밀집) 계층으로 공급하고, MSE 비용 함수 C(aestimated, aclean)는 아래의 수학식 1과 같이 작성된다. 수학식 1"}
{"patent_id": "10-2022-0123978", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "여기서, aestimated 및 aclean은 각각 추정 및 깨끗한 오디오 특징이다. 웨이브폼필터부는 음성음소추출부에 의해 추출한 음소 각각에 대한 데이터 중에서 음소 판독이 안되는 데이터를 AI독순술모델부에서 획득하는 데이터 중에서, 해당하는 음소의 데이터로 교체하도록 한다. 즉 웨 이브폼필터부는 음성음소추출부에 의해 추출한 음소 각각의 데이터 중에서 주변의 소음 등으로 인해 노 이즈가 포함됨으로써 판독이 불가능한 경우, 이러한 판독이 불가능한 음소의 데이터를 AI독순술모델부에서 획득하는 데이터로부터 해당하는 음소의 데이터를 추출하고, 추출한 음소의 데이터를 판독이 불가능한 음소의 데이터로 대체하게 된다. 이러한 웨이브폼필터부에 의해, 음성음소추출부에 의해 추출한 음소 각각에 대한 데이터의 오류를 입술 이미지를 통한 독순술을 이용하여 보정하는 역할을 수행하도록 할 수 있다. 웨이브폼필터부의 설계를 위하여, 새로운 딥 러닝 기반 입술 읽기 회귀 모델을 활용할 수 있고, 신호 처리 에서 Wiener 필터는 관찰된 잡음이 있는 오디오 신호의 선형시, 불변 linear time-invariant(LTI) 필터링을 통 해 깨끗한 오디오 신호의 추정치를 생성하도록 하는 필터를 이용할 수 있다. 성공적인 Wiener 필터링을 위해서 는 잡음 없는 오디오 파워 스펙트럼 획득이 요구되며, 깨끗한 오디오 파워 스펙트럼은 딥 러닝 입술 읽기 기반 의 음성 모델을 사용하여 계산될 수 있다. 깨끗한 오디오 전력 스펙트럼 추정을 위해 향상된 시각적 파생 Wiener 필터(EVWF)를 사용하여 입술 판독에 가까운 깨끗한 오디오 기능을 활용할 수 있고, LSTM 기반 필터 뱅크 추정 및 오디오 전력 스펙트럼 추정을 위한 역 필터 뱅크 변환을 적용할 수 있으며, 성공적인 필터링을 위한 깨 끗한 오디오 파워 스펙트럼을 획득할 수 있는 구조를 제시하여, 최첨단 VWF의 전력 스펙트럼 추정 및 일반화 문 제를 모두 해결하고, 음성 활동 탐지기 및 소음 추정기의 필요성을 대체할 수 있다. 또한 웨이브폼필터부의 설계를 위하여, 이 작업에 사용된 오디오 특징은 거친 스펙트럼 표현을 제공하기 위 하여, 채널의 지각 간격이 있는 필터 뱅크를 사용하고, 보간을 사용하여, 필터 뱅크가 Wiener 필터에 대한 전력 스펙트럼 표현으로 변환될 수 있으며, 그 품질이 필터 뱅크 채널 수와 관련된다. 필터 뱅크 설계는 ETSI Aurora 분산 음성 인식(DSR) 표준 [11]에 지정된 설계를 광범위하게 따른다. 오디오는 초당 100 프레임의 속도로 20ms 프레임으로 분할되어 입력된다. 도 4를 참조하면, 필터 뱅크를 계산하는 마지막 단계는 주파수 대역을 추출하기 위해 전력 스펙트럼에 Mel-scale에서 일반적으로 40개의 필터, nfilt = 40인 삼각 필터를 적용하는 것이다. Mel-scale은 낮은 주파수에서 더 차별적이고, 높은 주파수에서 덜 차별적으로 소리에 대한 비선형 인간의 귀 인 식을 모방하는 것을 목표로 한다. 아래의 수학식 2 및 3을 사용하여 Hertz(ff)와 Mel(mm)간의 변환이 가능해진 다. 수학식 2 수학식 3"}
{"patent_id": "10-2022-0123978", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "필터 뱅크의 각 필터는 중심 주파수에서 1의 응답을 갖는 삼각형이며, 응답이 0인 두 개의 인접한 필터의 중심 주파수에 도달할 때까지 0을 향해 선형적으로 감소한다. 필터 뱅크를 계산하는 식은 아래의 수학식 4와 같다. 수학식 4"}
{"patent_id": "10-2022-0123978", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "item": 4, "content": "도 5는 신호의 파워 스펙트럼(주기도)에 필터 뱅크를 적용한 후 다음 스펙트로그램 확보를 나타낸다. 또한, 도 6은 모델로 생성된 문자 출력과 오디오 신호간의 정렬을 나타낸다. 웨이브폼재정렬부는 웨이브폼필터부에 의해 음소의 데이터가 교체된 음소 전체의 데이터를 이어서 정렬 시키도록 한다. 웨이브폼정렬부는 음소의 데이터 중에서 교체되는 부분으로 인한 끊어짐이나 불연속성을 바 로 잡아 정상적인 음소의 데이터 배열 상태가 되도록 복원하는 역할을 하게 된다. 이렇게 웨이브폼재정렬부(1 5)에 의해 정렬된 데이터는 음성인식분석서버에 제공됨으로써, 음성인식분석서버는 제공된 데이터에 해당하는 각종 정보나 컨텐츠를 정해진 기기에 전송하여 외부로 출력하도록 정해진 동작을 수행하도록 구성되거나, 원하 는 동작 수행을 위한 명령을 정해진 기기에 전송하여 해당 명령을 수행하도록 구성될 수 있다. 도 7에서와 같이, 필터 뱅크는 음성의 대역분할 부호화(sub-band coder)나 시분할 다중화 데이터(time-division multiplexed data)를 주파수 분할 다중화 데이터(frequency-division multiplexed data)로 바꾸어 주는 장치인 트랜스멀티플렉서(transmultiplexers)에 자주 사용되던 컨벌루션(convolution) 구조를 가지고 있다. 필터 뱅크 는 분석 필터, 다운샘플러(downsampler), 업샘플러(upsampler) 그리고 합성 필터의 조합을 이용하여, 이산 신호 x[n]을 N개의 채널(channels; subbands)로 분해한다. 근본적인 문제는 완전 복원(perfect reconstruction) 필 터 뱅크(즉, x[n] = y[n])를 갖도록 Hi and Gi를 선택하는 것이다. 본 발명에서는 필요한 변환을 위하여, LSTM(Long-short-term Momory: 특히 음성의 특징을 긴시간과 짧은 시간으로 음소의 특징을 추출하여 가지고 있 는 메모리) 기반 필터 뱅크 추정 및 역오디오 전력 스펙트럼 추정을 위한 필터 뱅크 변환을 사용할 수 있다. 본 발명의 일 실시례에 따른 독순술을 이용한 음성 인식 시스템은 화자인식부, 학습모드설정부 및 데이터베이스부를 더 포함할 수 있고, 나아가서, 소음검출기능선택부를 더 포함할 수 있다. 화자인식부는 카메라로부터 획득되는 화자의 이미지로부터 등록된 화자인지를 판단하고, 등록된 화자인 경우에 한해서 음성 인식 절차를 수행하도록 제어하도록 한다. 화자인식부에 의한 등록된 화자인지 여부는 안면 인식 또는 얼굴의 특정부위, 예컨대 홍채, 입술 등의 인식 등의 방법이 적용될 수 있다. 학습모드설정부는 사용자의 조작신호, 예컨대, 터치패널이나 스위치 등의 다양한 조작부의 조작신호에 의해 학습모드를 설정 및 설정 해제하도록 하고, 학습모드의 설정 여부에 무관하게 화자인식부에 의해 판단된 화 자가 등록된 화자인 경우에 한해서 음성 인식 절차를 수행하도록 하되, 학습모드가 설정된 경우, 화자인식부 에 의해 판단된 화자가 등록된 화자가 아닌 경우, 등록된 화자가 아닌 화자의 음성에 대하여 웨이브폼재정 렬부로부터 출력되는 음소와 이의 데이터를 기계 학습에 사용되기 위하여 데이터베이스화할 수 있다.데이터베이스부는 학습모드설정부에 의해 데이터베이스화된 데이터를 저장하도록 하는데, 이에 반드시 한하는 것은 아니며, 동작에 필요한 각종 데이터 및 프로그램을 저장할 수 있다. 데이터베이스부는 등록된 화자가 아닌 화자의 음성에서 음소별로 데이터베이스화하는 음소모델부(18a)와, 등록된 화자가 아닌 화자의 음성에서 음소의 집합체인 단어별로 데이터베이스화하는 단어모델부(18b)와, 등록된 화자가 아닌 화자의 음성에서 단어의 집합체인 문장별로 데이터베이스화하는 문장모델부(18c)를 포함할 수 있다. 데이터베이스부는 웨이브폼재정렬부에 의해 처리된 데이터를 전송받아 인식된 음성을 분석하여 해당하 거나, 연관되는 데이터를 제공하도록 하는 음성인식분석서버(미도시)에 제공할 수 있다. 음성인식분석서버는 데 이터베이스부에 저장된 데이터를 제공받아 기계 학습 등을 비롯한 각종 분석이나 정보 또는 명령의 제공을 위해 사용될 수 있다. 소음검출기능선택부는 마이크로폰으로부터 출력되는 전기적인 신호로부터 추출되는 소음이 정해진 크기 이하일 때, 마이크로폰으로부터 출력되는 화자의 음성에 대한 전기적인 신호를 웨이브폼필터부 및 웨이 브폼재정렬부에 의한 프로세스를 생략한 상태로 음성인식분석서버에 바로 제공하도록 할 수 있고, 이 경우 음성인식분석서버로부터 음성 인식에 대한 결과물이 만족하지 않는 것으로 조작신호를 입력받으면, 화자의 음성 에 대한 전기적인 신호를 웨이브폼필터부 및 웨이브폼재정렬부에 의한 프로세스를 거쳐서 정렬된 음성 데이터를 외부의 음성인식분석서버에 제공하도록 할 수 있으며, 음성 인식에 대한 결과물이 만족하지 않는 것으 로 조작신호를 입력한 화자를 화자인식부에 의해 확인하여, 확인된 화자가 이후 음성 인식 절차를 수행시, 웨이브폼필터부 및 웨이브폼재정렬부에 의한 프로세스를 반드시 거치도록 제어할 수 있다. 여기서, 소 음의 정해진 크기는 음성 인식에 방해가 되는 최소한의 소음 세기일 수 있고, 예컨대 20 ~ 50 dB일 수 있다. 또 한 조작신호는 화자가 단말기를 통해 입력되는 신호이거나 해당 기기에 마련되는 입력부에 대한 입력 신호일 수 있다. 본 발명의 일 실시례에 따른 독순술을 이용한 음성 인식 시스템은 음성음소추출부, 입술음소추출부 , AI독순술모델부, 웨이브폼필터부, 웨이브폼재정렬부 및 데이터베이스부, 그리고, 나아가 서, 화자인식부 및 학습모드설정부, 또한 소음검출기능선택부 등이 IC화하여 SoC(System On Chip) 의 반도체 형태로 구현된다. 이와 같은 구성을 가지는 본 발명의 일 실시례에 따른 독순술 네트워크 지원을 위한 엣지용 SoC에 대한 동작을 설명하면 다음과 같다. 먼저, 마이크로폰을 통해서 화자의 음성을 수집하고, 동시에 카메라를 통해서 화자의 입술에 대한 이미지 를 획득한다. 그런 다음, 카메라로부터 획득되는 화자의 이미지를 화자인식부에 의해 인식하여, 등록된 화자인지를 판단한다. 화자인식부에 의한 인식에 의하여, 화자가 등록된 화자인 경우, 음성음소추출부가 마이크로폰으로부 터 출력되는 전기적인 신호로부터 음성의 음소에 대한 데이터를 추출하고, 입술음소추출부가 카메라에 의해 획득되는 입술 이미지로부터 음소 각각을 추출하며, AI독순술모델부가 입술음소추출부에 의해 추 출한 음소 각각에 매칭되는 데이터를 획득하고, 웨이브폼필터부가 음성음소추출부에 의해 추출한 음소 각각에 대한 데이터 중에서 음소 판독이 안되는 데이터를 AI독순술모델부에서 획득하는 데이터 중에서, 해 당하는 음소의 데이터로 교체하며, 웨이브폼재정렬부가 웨이퍼폼필터부에 의해 음소의 데이터가 교체된 음소 전체의 데이터를 이어서 정렬시킴으로써 음성 인식 처리한다. 음성 인식의 처리를 마치면, 음성 인식 처리를 마친 데이터를 음성인식분석서버에 전송한다. 음성인식분석서버 는 음성 인식 처리를 마친 데이터를 오디오 파형의 디지털 신호나 텍스화된 데이터 또는 그 밖에 음성을 식별할 수 있는 다양한 신호로서 제공받고, 이에 따른 명령을 수행하도록 필요한 명령신호를 수행하거나, 요구되거나 연관되는 각종 정보나 컨텐츠 등을 출력하도록 수행할 수 있다, 이러한 제공받은 명령신호, 정보 또는 컨텐츠 등은 홈오토메이션에 제어신호로서 사용되거나, 디스플레이부나 오디어 출력장치 등을 통해 외부로 출력되도록 할 수 있다. 한편, 등록된 화자인지를 판단시, 화자가 등록된 화자가 아닌 경우, 학습모드설정부에 의해, 학습모드로 설정되 었는지를 판단하고, 학습모드로 설정된 경우, 음성 인식 처리하는 과정 및 음성인식분석서버에 전송하는 과정을 수행하고, 음성인식분석서버로부터 제공되는 음성의 텍스트와 음성 인식 처리에 의해 획득되는 음소를 비교하여, 데이터베이스화하여 데이터베이스부에 저장되도록 할 수 있다. 이렇게 저장된 데이터들은 음성인식분석서버에 제공되어 기계 학습을 위하여 사용될 수 있다. 이와 같은 본 발명에 따른 독순술 네트워크 지원을 위한 엣지용 SoC에 따르면, 직접 아날로그 음소 파형의 보완 으로 경량화 구현 및 기존 통신 방식을 유지하여, 기존의 별도 알고리즘(입술인식, 음성인식) 통합 효과로 독순 술 복잡도를 회피할 수 있고, 사생활 프라이버시 문제와 제기된 사회 문제 해결에 기여할 수 있다. 또한 본 발명에 따르면, 단순 DNN(Deep Neural Network) 기능 활용으로 인공지능 SoC(System on Chip) 구현이 용이할 수 있고, 자체 학습 기능으로 대용량의 학습 데이터 세트 개발 최소화를 실현하여, 음성 활동 탐지기 및 소음 추정기를 필요로 하지 않도록 할 수 있다. 또한 본 발명에 따르면, 스마트 가전 및 AI 음성비서 등 음성 명령 단말기기의 필수 기능 소자로 대규모 영상 및 음성 네트워크 병목 현상을 일으키는 데이터 센터의 과부하를 해결하도록 한다. 이와 같이 본 발명에 대해서 첨부된 도면을 참조하여 설명하였으나, 본 발명의 기술적 사상을 벗어나지 않는 범 위 내에서 다양한 수정 및 변형이 이루어질 수 있음은 물론이다. 그러므로, 본 발명의 범위는 설명된 실시례에 한정되어서는 아니되며, 후술하는 특허청구범위뿐만 아니라 이러한 특허청구범위와 균등한 것들에 의해 정해져 야 한다."}
{"patent_id": "10-2022-0123978", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일 실시례에 따른 독순술 네트워크 지원을 위한 엣지용 SoC는 도시한 구성도이다. 도 2는 본 발명의 일 실시례에 따른 독순술 네트워크 지원을 위한 엣지용 SoC의 응용을 설명하기 위한 구성도이 다. 도 3은 본 발명의 일 실시례에 따른 독순술 네트워크 지원을 위한 엣지용 SoC에서 독순술 중심의 딥러닝 프레임 워크를 나타낸다. 도 4는 본 발명의 일 실시례에 따른 독순술 네트워크 지원을 위한 엣지용 SoC에서 Mel-scale의 필터 뱅크를 설 명하기 위한 그래프이다. 도 5는 본 발명의 일 실시례에 따른 독순술 네트워크 지원을 위한 엣지용 SoC에서 신호의 스펙트럼을 나타낸다. 도 6은 본 발명의 일 실시례에 따른 독순술 네트워크 지원을 위한 엣지용 SoC에서 모델로 생성된 문자 출력과 오디오 신호간의 정렬을 나타낸다. 도 7은 본 발명의 일 실시례에 따른 독순술 네트워크 지원을 위한 엣지용 SoC에서, LSTM(Long Short-Term Memory) 기반 필터 뱅크 추정 및 역오디오 전력 스펙트럼 추정을 위한 필터 뱅크 변환의 구성도이다."}
