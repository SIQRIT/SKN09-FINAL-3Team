{"patent_id": "10-2023-0102824", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2025-0021767", "출원번호": "10-2023-0102824", "발명의 명칭": "잡음 환경에 강인한 음성질환 진단방법 및 장치", "출원인": "에스케이텔레콤 주식회사", "발명자": "이상재"}}
{"patent_id": "10-2023-0102824", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "잡음 환경에 강인한 음성질환 진단을 위한 컴퓨터 구현 방법으로서,배경잡음을 포함하는 잡음 음성신호에서, 음성이 존재하지 않는 하나 이상의 무음성 시간구간들을 추정하는 과정;상기 잡음 음성신호로부터 상기 하나 이상의 무음성 시간구간에 대응하는 하나 이상의 무음성 신호들을 추출하여, 상기 음성을 포함하지 않는 무음성 배경잡음신호를 생성하는 과정; 및인공지능 모델을 이용하여, 상기 잡음 음성신호 및 상기 무음성 배경잡음신호로부터 적어도 하나의 음성질환에대한 확률을 산출하는 과정을 포함하는, 방법."}
{"patent_id": "10-2023-0102824", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 추정하는 과정은, 상기 잡음 음성신호를 상기 음성이 존재하는 하나 이상의 음성 시간구간들과 상기 음성이 존재하지 않는 복수의 무음성 시간구간들로 구분하고, 상기 생성하는 과정은,상기 잡음 음성신호로부터 상기 복수의 무음성 시간구간들에 각각 대응하는 복수의 무음성 신호들을 추출하는과정; 및상기 복수의 무음성 신호들을 연결(concatenate)하여 상기 무음성 배경잡음신호를 생성하는 과정을 포함하는,방법."}
{"patent_id": "10-2023-0102824", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,상기 추출하는 과정 이후에,상기 복수의 무음성 신호들 중에서 기설정된 길이보다 짧은 길이를 갖는 무음성 신호를 제거하는 과정을 더 포함하는, 방법."}
{"patent_id": "10-2023-0102824", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,상기 생성하는 과정은,상기 하나 이상의 무음성 신호들의 각각에 대해서, 상기 잡음 음성신호 내의 음성이 존재하는 시간구간과 인접한 영역을 잘라내는 과정을 포함하는, 방법."}
{"patent_id": "10-2023-0102824", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서,상기 생성하는 과정은,상기 하나 이상의 무음성 신호들의 각각에 윈도우 함수를 적용하는 과정 - 상기 윈도우 함수는, 윈도우의 중심부분에 비해 상기 윈도우의 끝 부분에서 상대적으로 작은 가중치를 가짐 - 을 포함하는, 방법."}
{"patent_id": "10-2023-0102824", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서,공개특허 10-2025-0021767-3-상기 생성하는 과정은,상기 무음성 배경잡음신호에 대해 반복 패딩(repeat padding), 반사 패딩(reflect padding), 및 순환 패딩(circular padding) 중 적어도 하나를 적용하여 하여, 상기 무음성 배경잡음신호가 기설정된 길이를 갖도록 조정하는 과정을 포함하는, 방법."}
{"patent_id": "10-2023-0102824", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에 있어서,상기 산출하는 과정은,상기 잡음 음성신호 및 상기 무음성 배경잡음신호로부터 각각 피처를 추출하는 과정; 및상기 추출된 피처를 합성(fusion)하여 상기 인공지능 모델에 입력하는 과정을 포함하는, 방법."}
{"patent_id": "10-2023-0102824", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "명령어가 저장된, 컴퓨터로 읽을 수 있는 기록매체로서, 상기 명령어는 상기 컴퓨터에 의해 실행될 때 상기 컴퓨터로 하여금, 제1항 내지 제7항 중 어느 한 항에 따른 방법이 포함하는 각 과정을 실행하도록 하는, 컴퓨터로읽을 수 있는 기록매체."}
{"patent_id": "10-2023-0102824", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "명령어들을 저장하는 메모리; 및 적어도 하나의 프로세서를 포함하되,상기 적어도 하나의 프로세서는 상기 명령어들을 실행함으로써,배경잡음을 포함하는 잡음 음성신호에서, 음성이 존재하지 않는 하나 이상의 무음성 시간구간들을 추정하고,상기 잡음 음성신호로부터 상기 하나 이상의 무음성 시간구간에 대응하는 하나 이상의 무음성 신호들을 추출하여, 상기 음성을 포함하지 않는 무음성 배경잡음신호를 생성하고,인공지능 모델을 이용하여, 상기 잡음 음성신호 및 상기 무음성 배경잡음신호로부터 적어도 하나의 음성질환에대한 확률을 산출하는, 장치."}
{"patent_id": "10-2023-0102824", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "잡음이 있는 환경에 강인한 음성질환 진단방법 및 장치를 개시한다. 본 개시의 일 측면에 의하면, 잡음 환경에 강인한 음성질환 진단을 위한 컴퓨터 구현 방법으로서, 배경잡음을 포 함하는 잡음 음성신호에서, 음성이 존재하지 않는 하나 이상의 무음성 시간구간들을 추정하는 과정; 상기 잡음 음성신호로부터 상기 하나 이상의 무음성 시간구간에 대응하는 하나 이상의 무음성 신호들을 추출하여, 상기 음 성을 포함하지 않는 무음성 배경잡음신호를 생성하는 과정; 및 인공지능 모델을 이용하여, 상기 잡음 음성신호 및 상기 무음성 배경잡음신호로부터 적어도 하나의 음성질환에 대한 확률을 산출하는 과정을 포함하는, 방법을 제공한다."}
{"patent_id": "10-2023-0102824", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 잡음이 있는 환경에 강인한 음성질환 진단방법 및 장치에 관한 것이다."}
{"patent_id": "10-2023-0102824", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "이하에 기술되는 내용은 단순히 본 실시예와 관련되는 배경 정보만을 제공할 뿐 종래기술을 구성하는 것이 아니 다. 최근 인공지능과 오디오 신호처리 기술의 향상에 의하여 음성이 녹음된 오디오 신호로부터 음성질환을 진단하는 기술이 개발되고 있다. 또한, 원격 의료에 대한 관심도 향상과 스마트 기기의 발전은 원격 음성질환 진단의 가 능성을 열어주고 있다. 음성질환 진단은, 음성인식이나 음성합성 등으로 대표되는 자연어 처리 알고리즘과는 상당수의 차이가 존재한다. 자연어 처리에서는 시간의 인과관계를 활용하여 사람이 발화하는 소리로부터 의미를 추출하는데 집중 한다. 이를 위해 수집된 오디오 신호로부터 잡음을 제거(noise remove)하거나 음성을 향상(voice enhancement) 시키는 방식이 적용되기도 한다. 반면, 음성질환 진단에서는 인체가 생성하는 근원의 발성, 즉 성대에서 생성되 는 음파에 집중한다. 이는 전체적인 음성의 미세한 부분에 해당하기 때문에, 잡음에 매우 민감하다. 음성질환자 의 음성에서 나타나는 질환 특징은 잡음과 그 특징이 유사하기도 하기 때문에, 오디오 신호로부터 잡음을 제거 하거나 음성을 재생성하는 경우에 질환 특징이 함께 사라질 수 있다. 따라서, 이상적으로는, 음성질환 진단을 위한 인공지능 모델의 학습 및/또는 추론용 음성은, 방음시설과 전문 녹음장비가 구비된 청지각 검사실과 같이 잡음이 통제된 환경에서 녹음되어야 한다. 그러나 전문 연구기관이 아닌 일반 병원 등에서는, 잡음 통제된 환경에서의 음성 녹음이 어려운 실정이다. 또한, 스마트 기기를 활용한 원 격 진료 상황 등을 고려하면, 음성 녹음 환경을 완벽하게 통제하는 것은 불가능에 가깝다."}
{"patent_id": "10-2023-0102824", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 개시는, 다양한 배경잡음이 존재하는 환경에서도 음성질환을 정확하게 진단할 수 있는 방법 및 장치를 제공 하는 데 일 목적이 있다. 본 발명이 해결하고자 하는 과제들은 이상에서 언급한 과제들로 제한되지 않으며, 언급되지 않은 또 다른 과제 들은 아래의 기재로부터 통상의 기술자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2023-0102824", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 개시의 일 측면에 의하면, 잡음 환경에 강인한 음성질환 진단을 위한 컴퓨터 구현 방법으로서, 배경잡음을 포함하는 잡음 음성신호에서, 음성이 존재하지 않는 하나 이상의 무음성 시간구간들을 추정하는 과정; 상기 잡 음 음성신호로부터 상기 하나 이상의 무음성 시간구간에 대응하는 하나 이상의 무음성 신호들을 추출하여, 상기 음성을 포함하지 않는 무음성 배경잡음신호를 생성하는 과정; 및 인공지능 모델을 이용하여, 상기 잡음 음성신 호 및 상기 무음성 배경잡음신호로부터 적어도 하나의 음성질환에 대한 확률을 산출하는 과정을 포함하는, 방법 을 제공한다. 본 개시의 다른 측면에 의하면, 명령어들을 저장하는 메모리; 및 적어도 하나의 프로세서를 포함하되, 상기 적 어도 하나의 프로세서는 상기 명령어들을 실행함으로써, 배경잡음을 포함하는 잡음 음성신호에서, 음성이 존재 하지 않는 하나 이상의 무음성 시간구간들을 추정하고, 상기 잡음 음성신호로부터 상기 하나 이상의 무음성 시 간구간에 대응하는 하나 이상의 무음성 신호들을 추출하여, 상기 음성을 포함하지 않는 무음성 배경잡음신호를 생성하고, 인공지능 모델을 이용하여, 상기 잡음 음성신호 및 상기 무음성 배경잡음신호로부터 적어도 하나의 음성질환에 대한 확률을 산출하는, 장치를 제공한다. 본 개시의 또 다른 측면에 의하면, 명령어가 저장된, 컴퓨터로 읽을 수 있는 기록매체로서, 상기 명령어는 상기 컴퓨터에 의해 실행될 때 상기 컴퓨터로 하여금, 전술한 방법이 포함하는 각 과정을 실행하도록 하는, 컴퓨터로 읽을 수 있는 기록매체를 제공한다."}
{"patent_id": "10-2023-0102824", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 개시의 실시예에 의하면, 다양한 배경잡음이 존재하는 환경에서도 정확하게 음성질환을 진단할 수 있다. 본 개시의 실시예에 의하면, 음성신호에 섞여 있는 배경잡음에 대한 추정치를 음성신호와 함께 인공지능 모델에 입력해줌으로써, 인공지능 모델 내에서 음성과 배경잡음을 분리하여 처리하도록 유도할 수 있다. 이에 따라, 음 성을 녹음하는 환경을 통제하지 않고도 음성질환 진단의 정확도를 높일 수 있다. 본 개시의 실시예에 의하면, 오디오 신호로부터 잡음을 제거하거나 음성을 향상(또는 재생성)하는 대신에, 잡음 과 함께 학습(learning with noise)하는 방식을 취함으로써, 오디오 신호에서 질환 특징이 제거되는 문제를 방 지할 수 있다. 본 개시의 효과들은 이상에서 언급한 효과들로 제한되지 않으며, 언급되지 않은 또 다른 효과들은 아래의 기재 로부터 통상의 기술자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2023-0102824", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 본 개시의 일부 실시예들을 예시적인 도면을 이용해 상세하게 설명한다. 각 도면의 구성 요소들에 참조 부호를 부가함에 있어서, 동일한 구성 요소들에 대해서는 비록 다른 도면 상에 표시되더라도 가능한 한 동일한 부호를 가지도록 하고 있음에 유의해야 한다. 또한, 본 개시를 설명함에 있어, 관련된 공지 구성 또는 기능에 대한 구체적인 설명이 본 개시의 요지를 흐릴 수 있다고 판단되는 경우에는 그 상세한 설명은 생략한다. 본 개시에 따른 실시예의 구성요소를 설명하는 데 있어서, 제1, 제2, i), ii), a), b) 등의 부호를 사용할 수 있다. 이러한 부호는 그 구성요소를 다른 구성 요소와 구별하기 위한 것일 뿐, 그 부호에 의해 해당 구성요소의 본질 또는 차례나 순서 등이 한정되지 않는다. 명세서에서 어떤 부분이 어떤 구성요소를 '포함' 또는 '구비'한 다고 할 때, 이는 명시적으로 반대되는 기재가 없는 한 다른 구성요소를 제외하는 것이 아니라 다른 구성요소를 더 포함할 수 있는 것을 의미한다. 첨부된 도면과 함께 이하에 개시될 상세한 설명은 본 개시의 예시적인 실시형태를 설명하고자 하는 것이며, 본 개시가 실시될 수 있는 유일한 실시형태를 나타내고자 하는 것이 아니다. 도 1은 본 개시의 일 실시예에 따른 진단장치를 개략적으로 나타낸 블록구성도이다. 진단장치는 오디오 신호에 녹음된 음성을 기반으로, 진단 대상자의 음성질환을 비침습적으로 진단하는 장치 이다. 진단장치는 인공지능 모델을 이용하여, 임의의 오디오 신호로부터 진단 대상자의 음성질환 유무 및/또는 음성질환의 유형을 진단할 수 있다. 음성질환은, 음성장애 또는 해당 음성장애를 일으키는 후두부 질환 으로서, 예컨대, 성대결절(Vocal Fold Nodules), 성대용종(Vocal Fold Polyps), 후두암(Laryngeal Cancer) 및/ 또는 발성장애(Spasmodic Dysphonia) 등을 포함할 수 있으나, 이러한 예시에 한정되는 것은 아니다. 진단장치는 수집부, 전처리부 및 진단부의 전부 또는 일부 포함할 수 있다. 도 1에 도시된 모든 블록이 필수 구성요소인 것은 아니며, 다른 실시예에 포함된 일부 블록이 추가, 변경 또는 삭제될 수 있다. 한편, 도 1에 도시된 구성요소들은 기능적으로 구분되는 요소들을 나타낸 것으로서, 적어도 하나의 구성 요소가 실제 물리적 환경에서는 서로 통합되는 형태로 구현될 수도 있다. 수집부는 마이크 또는 외부 기기를 통해 음성이 녹음된 오디오 신호를 획득할 수 있다. 오디오 신호는 진 단 대상자의 발성 또는 발화를 기록한 음성신호를 포함할 수 있다. 음성신호는 모음연장발성(sustained vowels) 및/또는 연속 발화(continuous speech)를 기록한 것일 수 있다. 모음연장발성의 예로서, 음성신호는, 진단 대상 자가 /아(a)/와 같은 모음을 길게 발성한 것을 기록한 것일 수 있다. 연속 발화 형태의 예로서, 음성신호는 진 단 대상자가 주어진 문장(예컨대, 산문시 '가을' 등)을 낭독한 것을 기록한 것일 수 있다. 음성신호에는 배경잡 음(background noise)이 섞여 있을 수 있다. 본 개시에서 배경잡음이 섞여 있는 음성신호는 잡음 음성신호라 지 칭될 수 있다. 수집부는 하나 이상의 오디오 신호들로부터 잡음 음성신호 및 무음성 배경잡음신호의 세트를 생성할 수 있 다. 무음성 배경잡음신호는, 음성을 포함하지 않고 배경잡음만을 포함하는 신호일 수 있다. 바람직하게는, 무음 성 배경잡음신호는 잡음 음성신호 내에 존재하는 배경잡음에 대한 근사 추정치를 포함할 수 있다. 일 예로, 잡 음 음성신호와 무음성 배경잡음신호는, 동일한 환경조건하에서 최소한의 시간차를 두고 연속적으로 녹음된 것일 수 있다. 환경조건은, 녹음 기기 및/또는 녹음 장소 등을 포함할 수 있으나, 이에 한정되는 것은 아니다. 다른 예로, 무음성 배경잡음신호는, 잡음 음성신호로부터 추출된 일부 구간의 조합일 수 있다. 잡음 음성신호 및 무 음성 배경잡음신호의 세트를 생성하기 위한 구체적인 방법은, 도 2 내지 도 4를 참조하여 후술하도록 한다. 전처리부는 잡음 음성신호 및 무음성 배경잡음신호에 대해 기본적인 전처리를 수행할 수 있다. 전처리부 는 신호들을 인공지능 모델에서 처리하기에 적합한 형태로 가공할 수 있다. 전처리부는 신호마 다 다를 수 있는 규격을 정형화할 수 있다. 일 예로, 전처리부는 각 신호를 소정의 샘플링 주파수로 재샘플링(re-sampling)할 수 있다. 다른 예로, 전처리부는 각 신호에 소정의 주파수 대역만을 통과하도록 구성 된 대역 통과필터(band pass filter)를 적용할 수 있다. 또 다른 예로, 전처리부는 각 신호의 음량을 조절 할 수 있다. 또 다른 예로, 전처리부는 각 신호를 소정의 길이로 규격화하기 위해, 패딩(padding) 및/또는 자르기(truncate)를 수행할 수 있다. 예컨대, 전처리부는 잡음 음성신호 및 무음성 배경잡음신호를 각각 4 초 길이로 조정할 수 있다. 전처리부에 의해 수행되는 동작은 전술한 예시에 한정되지 않으며, 전처리부 는 오디오를 규격화하는 다양한 변환(transform)을 수행할 수 있다. 진단부는 전처리된 잡음 음성신호 및 전처리된 무음성 배경잡음신호를 기초로 진단 대상자에 대한 음성질 환 진단을 수행할 수 있다. 진단부는 인공지능 모델을 이용하여, 전처리된 잡음 음성신호 및 전처리 된 무음성 배경잡음신호로부터 음성질환 진단을 위한 정보를 획득할 수 있다. 예를 들어, 진단부는 인공지 능 모델로부터 적어도 하나의 음성질환 유형에 대한 확률 값을 획득할 수 있다. 진단부는 음성질환 유형별 확률 값을 진단결과로서 출력할 수 있다. 다른 예로, 진단부는 가장 높은 확률 값을 갖는 음성질환 의 유형을 진단 대상자의 음성질환 유형으로 진단하고, 해당 유형을 나타내는 식별자 및/또는 이의 확률 값을 출력할 수도 있다. 본 개시의 일 실시예에 따르면, 잡음 음성신호와 무음성 배경잡음신호에 대한 정보를 인공지능 모델에 함 께 입력하기 위해, 각 신호를 피처 레벨(feature level)에서 합성하는 레이트 퓨전(late fusion) 기법이 적용될 수 있다. 진단부는 전처리된 잡음 음성신호 및 전처리된 무음성 배경잡음신호로부터 피처를 각각 추출하고, 추출된 피처들을 합성(fusion)하여 인공지능 모델에 입력할 수 있다. 일 예로, 진단부는 각 신호를 시간-주파수 도메인으로 변환하여, 2차원 데이터로 표현된 피처(예컨대, 스펙트로그램, 또는 멜-스펙 트로그램 등)를 추출할 수 있다. 여기서, 진단부는 단시간 푸리에 변환(STFT, Short Time Fourier Transform)을 이용하여 전처리된 신호들을 각각 시간-주파수 도메인으로 변환할 수 있으나, 이에 한정되는 것은 아니다. 다른 예로, 진단부는 시계열(time series) 데이터를 직접 처리할 수 있도록 설계된 신경망 기반의 인코딩 레이어(encoding layer)에 각 신호를 입력하여, 1차원 데이터로 표현되는 피처를 추출할 수도 있다. 인 코딩 레이어는, 예컨대, 하나 이상의 1차원 컨볼루션 레이어들(convolutional layers)의 조합으로 구성될 수 있 으나, 이에 한정되는 것은 아니다. 인공지능 모델은 적어도 하나의 음성질환에 대한 이진분류 또는 다중분류를 수행하도록 훈련된 신경망 구 조의 모델일 수 있다. 인공지능 모델은, 특징 추출기(feature extractor) 및 분류기(classifier)를 포함할 수 있다. 특징 추출기 및 분류기는 하나 이상의 컨볼루션 레이어들 및/또는 하나 이상의 완전연결 레이어들(fully connected layers)을 포함할 수 있다. 일 예로, 각 신호로부터 추출된 피처가 2차원 데이터로 표현되는 경우, 특징 추출기는 하나 이상의 2차원 컨볼루션 레이어들을 포함할 수 있다. 다른 예로, 각 신호로부터 추출된 피처 가 1차원 데이터로 표현되는 경우, 특징 추출기는 하나 이상의 1차원 컨볼루션 레이어들을 포함할 수 있다. 분 류기는 하나 이상의 완전연결 레이어들을 포함할 수 있다. 도 2는 본 개시의 일 실시예에 따라, 잡음 음성신호 및 무음성 배경잡음신호의 세트를 생성하는 과정을 나타낸 흐름도이다. 수집부는 오디오 신호를 처리하기 위한 동작 모드를 선택받을 수 있다(S200). 예를 들어, 수집부는 GUI(graphic user interface)를 통해 신규 오디오 신호를 녹음하는 것인지, 또는 기녹음된 오디오 신호를 가공 하는 것인지 여부를 입력받을 수 있다. 신규 녹음이 선택된 경우, 수집부는 음성 없이 배경잡음만을 녹음한 무음성 배경잡음신호를 수집할 수 있 다(S220). 예를 들어, 수집부는 진단 대상자에게 발성 및/또는 발화하지 않을 것을 안내한 이후에 미리 정 해진 시간동안 녹음된 오디오 신호를 무음성 배경잡음신호로서 수집할 수 있다. 무음성 배경잡음신호와 잡음 음 성신호의 길이를 동일하게 맞추기 위해, 무음성 배경잡음신호는 2초 내지 4초 사이의 길이를 가질 수 있다. 수집부는 진단 대상자의 음성을 녹음한 잡음 음성신호를 수집할 수 있다(S222). 수집부는 무음성 배 경잡음신호의 녹음이 완료된 이후에, 진단 대상자에게 특정한 소리를 발성하고/거나 특정한 문장을 발화하도록 안내할 수 있다. 예를 들어, 수집부는 진단 대상자에게 단모음을 일정 시간(예컨대, 2초 내지 4초) 동안 연장 발성하도록 안내한 이후에 녹음된 오디오 신호를 잡음 음성신호로서 수집할 수 있다. 부가적으로 또는 대 안적으로, 수집부는 진단 대상자에게 미리 정해진 문장을 낭독하도록 안내한 후에 녹음된 오디오 신호를 잡음 음성신호로서 수집할 수 있다. 동일한 환경조건하에서 무음성 배경잡음신호와 잡음 음성신호의 녹음이 진 행되었고 두 신호의 녹음 시점이 충분히 인접한 경우(예컨대, 수초 이하의 시간 차를 두고 녹음을 진행한 경 우), 무음성 배경잡음신호는 잡음 음성신호 내의 배경잡음과 거의 유사한 배경잡음을 포함하는 것으로 간주할수 있다. 이상에서는 배경잡음을 먼저 녹음한 이후에 음성을 녹음하는 예를 설명하였으나, 다른 예에서 음성을 먼저 녹음한 이후에 배경잡음이 녹음될 수도 있다. 한편, 기녹음된 오디오 신호의 가공이 선택된 경우, 수집부는 기녹음된 오디오 신호를 잡음 음성신호로서 입력받을 수 있다(S240). 수집부는 잡음 음성신호로부터 무음성 배경잡음신호를 추출할 수 있다(S242). 과거에 녹음된 오디오 신호 를 잡음 음성신호로 이용하는 경우, 동일한 환경조건 및 인접한 시점에 녹음된 무음성 배경잡음신호가 존재하지 않는다. 따라서, 수집부는 별도로 녹음된 무음성 배경잡음을 수집하는 대신, 잡음 음성신호 내에 존재하는 무음성 시간구간을 탐지하고 해당 시간구간의 신호들을 추출하여 이어붙임으로써, 무음성 배경잡음신호를 생성 할 수 있다. 도 3은 본 개시의 일 실시예에 따라, 잡음 음성신호로부터 무음성 배경잡음신호를 추출하는 과정을 나타낸 흐름 도이다. 도 4는 본 개시의 일 실시예에 따른 잡음 음성신호 및 이로부터 추출되는 무음성 신호의 예를 보여주는 예시도이다. 수집부는 잡음 음성신호에서 음성 시간구간과 무음성 시간구간을 추정할 수 있다(S300). 여기서, 음성 시 간구간은 음성이 존재하는 것으로 추정되는 시간구간을 나타내고, 무음성 시간구간은 음성이 존재하지 않는 것으로 추정되는 시간구간을 나타낸다. 수집부는 음성 활성도 검출(VAD, Voice Activity Detection) 알고리 즘을 이용하여, 음성 시간구간과 무음성 시간구간을 추정할 수 있다. 예를 들어, 도 4를 참조하면, 수집부(10 0)는 제1 내지 제4 시간구간(400 내지 406)을 무음성 시간구간으로 추정할 수 있다. 수집부는 다양한 규칙 기반 및/또는 학습기반의 음성 활성도 검출 알고리즘을 활용할 수 있으며 본 개시에서는 이에 대해 특별한 방식 으로 한정하지 않는다. 수집부는 잡음 음성신호에서 무음성 시간 구간에 해당하는 신호(이하, 무음성 신호)를 추출할 수 있다 (S310). 예를 들어, 도 4를 참조하면, 수집부는 제1 내지 제4 시간구간(400 내지 406) 내의 신호들을 각각 추출할 수 있다. 수집부는 추출된 무음성 신호들 중에서, 기설정된 최소 길이보다 짧은 길이를 갖는 무음성 신호를 제거할 수 있다(S320). 기설정된 최소 길이는 예컨대, 2초일 수 있다. 예를 들어, 도 4를 참조하면, 수집부는 제1 시간구간 및 제3 시간구간에서 추출된 신호들을 제거할 수 있다. 이와 같이 소정의 최소 길이보다 짧 은 시간구간은 실제 무음성 구간이 아니라, 기식성이 포함된 호흡구간일 수 있다. 수집부는 최소 길이보다 짧은 시간구간 내의 신호들을 처리 대상에서 제외함으로써, 무음성 구간으로 잘못 추정된 호흡구간을 필터링할 수 있다. 이에 따라, 호흡에 의한 음성신호가 무음성 배경잡음신호에 추가되는 것을 방지할 수 있다. 다른 예에 서, 과정 S310 및 과정 S320이 병합되어 처리될 수도 있다. 예컨대, 수집부는 개별 무음성 구간의 길이를 확인하여, 2초 이상의 길이를 갖는 무음성 구간들의 신호만을 추출할 수도 있다. 수집부는 무음성 신호에서 음성 시간구간에 인접한 영역을 가공할 수 있다(S330). 무음성 신호에서 음성 시간구간과 인접한 부분은, 음성 발음에 영향을 받을 수 있다. 따라서, 무음성 신호의 양 끝단을 적절한 방법으 로 처리해 주어야 한다. 일 예로, 수집부는 무음성 신호에서 음성 시간구간에 인접한 영역을 잘라낼 수 있 다. 예를 들어, 수집부는 무음성 신호의 양 끝단을 0.05 초 만큼씩 잘라낼 수 있다. 즉, 무음성 신호의 시 작점으로부터 0.05초 만큼의 길이 및 끝점으로부터 0.05초 만큼의 길이를 각각 잘라서 버리고, 중간 부분만을 이용할 수 있다. 다른 예로, 수집부는 무음성 신호에 윈도우 함수를 적용하여, 음성 시간구간에 인접한 영 역의 영향도를 낮추어 줄 수 있다. 여기서, 윈도우 함수는, 무음성 신호와 동일한 길이를 갖되, 윈도우의 중심 부분에 비해 윈도우의 끝 부분에서 상대적으로 작은 가중치를 가지는 함수일 수 있다. 예컨대, 윈도우 함수는, 핸 윈도우 함수(hann window function)일 수 있으나, 이에 한정되는 것은 아니다. 여기서, 무음성 신호 및 윈도 우 함수가 적용된 무음성 함수는 각각 수학식 1 및 수학식 2와 같이 표현될 수 있다. 수학식 1 수학식 2"}
{"patent_id": "10-2023-0102824", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "여기서, Vk 는 잡음 음성신호 x(t)로부터 추출된 k번째 무음성 신호를 나타내고, wk는 k번째 무음성 신호에 윈도 우 함수 W(·)를 적용한 결과를 나타낸다. 수집부는 가공된 무음성 신호들을 연결(concatenate)할 수 있다(S340). 수집부는 연결된 무음성 신호들의 길이를 조정하여 무음성 배경잡음신호를 생성할 수 있다(S350). 예를 들 어, 수집부는 무음성 배경잡음신호가 기설정된 길이(예컨대, 예컨대 4초)를 갖도록, 연결된 무음성 신호에 대해 패딩 및/또는 자르기를 수행할 수 있다. 예를 들어, 수집부는 연결된 무음성 신호가 기설정된 길이보 다 짧은 경우, 해당 신호에 대해 패딩을 적용할 수 있다. 이때, 패딩 기법으로는, 신호의 끝단의 값을 반복적으 로 추가하는 반복 패딩(repeat padding), 시간 방향에 수직인 축을 기준으로 신호를 반전시켜 원 신호의 끝단에 추가하는 반사 패딩(reflect padding), 및 신호를 순환 반복하는 순환 패딩(circular padding) 중 적어도 하나 가 적용될 수 있으나, 이에 한정되는 것은 아니다. 도 5는 본 개시의 일 실시예에 따른 인공지능 모델의 학습과정을 개략적으로 나타낸 도면이다. 본 개시의 일 실시예에 따른 인공지능 모델의 학습과정은, 학습장치에 의해 실행되고, 학습장치는 컴퓨팅 디바이스 상에서 실행될 수 있다. 학습장치는, 컴퓨팅 디바이스가 가용할 수 있는 하나 이상의 프로세서 에 의해 각 기능을 수행하고, 이러한 프로세서와 연결되어 내부에 저장된 명령어들을 가지는 컴퓨터 판독가능 스토리지를 포함할 수 있으나, 이에 한정되는 것은 아니다. 학습장치는 리파지토리로부터 임의의 훈련샘플을 추출할 수 있다. 훈련 샘플은 잡음 음성신호와 무음 성 배경잡음신호의 세트를 포함할 수 있다. 훈련 샘플에는, 발화자의 음성질환 유무 및/또는 음성질환의 유형을 나타내는 음성질환 레이블이 부여되어 있을 수 있다. 리파지토리 내의 잡음 음성신호와 무음성 배경잡음신 호의 세트들은 도 2 내지 도 4에서 전술한 방법에 의해 생성된 것일 수 있다. 일 예로, 신규 오디오 신호의 녹 음이 가능한 경우, 학습장치는 최소한의 시간차를 두고, 잡음 음성신호와 무음성 배경잡음신호를 각각 녹음 할 수 있다. 다른 예로, 과거에 녹음된 오디오 신호를 이용하는 경우에는, 학습장치는 오디오 신호를 잡음 음성신호로 이용하고, 이로부터 무음성 배경잡음신호를 추출해낼 수 있다. 학습장치는 잡음 음성신호와 무음성 배경잡음신호 각각에 대해 전처리를 수행할 수 있다. 학습장치에 의해 수행되는 전처리는, 전술한 전처리부의 동작과 동일하거나 상응할 수 있으므로, 자세한 내용은 생략 하도록 한다. 학습장치는 전처리된 잡음 음성신호와 전처리된 무음성 배경잡음신호를 각각 인코딩하여, 각 신호에 대한 피처를 추출할 수 있다. 학습장치에 의해 수행되는 인코딩은, 전술한 진단부에 의해 수행되는 피처 추 출 동작과 동일하거나 상응할 수 있으므로, 자세한 내용은 생략하도록 한다. 학습장치는 각 신호로부터 추출된 피처를 합성(fusion)할 수 있다. 예컨대, 학습장치는, 잡음 음성신호 의 피처와 무음성 배경잡음신호의 피처를 채널, 너비, 및 높이 중 어느 한 방향으로 연결(concatenate)할 수 있 다. 학습장치는 합성된 피처를 인공지능 모델에 입력하여, 적어도 하나의 음성질환에 대한 확률을 획득할 수 있다. 학습장치는 적어도 하나의 음성질환에 대한 확률과 음성질환 레이블을 기초로 손실을 산출할 수 있다. 손실 을 산출하기 위한 함수로는, 교차 엔트로피가 이용될 수 있으나, 이에 한정되는 것은 아니다. 학습장치는 손실이 최소화되는 방향으로 인공지능 모델의 파라미터를 갱신할 수 있다. 구현예에 따라, 전술한 인코딩 레이어의 파라미터가 인공지능 모델의 파라미터와 함께 갱신될 수도 있다. 예를 들어, 학습장치는 역 전파 알고리즘을 기초로, 분류기, 특징 추출기 및 인코딩 레이어의 순으로 각 구성들에 포함된 레이어들의 가중 치를 갱신할 수 있다. 도 6a 내지 도 6d는 비교 예 및 본 개시의 일 실시예에 따른 신경망에 입력되는 데이터를 나타낸 예시도이다. 도 6a 내지 도 6d에서, x(t) 및 s(t)는 각각 시점 t에서 주어진 음성 및 배경잡음 나타내고, h_1 내지 h_n은 신 경망의 은닉 노드(hidden node)를 나타낸다. 도 6a는 노이즈가 없는 상황을 가정한 모델의 개념도를 보여준다. 노이즈를 고려하지 않았기 때문에, 신경망은 입력 음성 x(t)만을 기반으로 학습된다. 이러한 신경망을 다양한 배경잡음이 존재하는 실세계 환경에 적용시, 추정 정확도가 떨어지게 된다. 도 6b는 노이즈가 포함된 입력 X(t|s)가 신경망으로 입력되는 예를 보여준다. 도 6b에 따른 구조에서는, 신경망 의 은닉 노드에서 s(t)를 별도로 파악하지 못하기 때문에, 신경망을 거쳐도 음성 x(t)만을 따로 추출할 수 없다. 신경망은 단지 기존의 정상인들의 음성과 유사한 음성 x'(t)를 추정할 뿐이며, 이마저도 훈련에 사용된 음성 데이터가 노이즈를 포함하고 있다면 정확한 추정이 어렵다. 도 6c는 가우시안 노이즈 g를 신경망의 입력으로 추가하는 방식(additive Noise)의 예를 보여준다. 신경망의 학 습 데이터에 가우시안 노이즈를 추가하면, 데이터 증분(data augmentation) 효과로써 신경망이 범용적인 특징을 갖도록 도움을 줄 수 있다. 그러나, 도 6c에 도시된 신경망에는 배경잡음을 제거할 수 있는 정보는 주어지지 않 고, 별도의 가우시안 노이즈 g 만이 추가되므로 노이즈에 민감한 음성질환 분류 태스크에는 적합하지 않다. 도 6d는 본 개시의 일 실시예에 따른 신경망의 개념도를 보여준다. 본 개시의 일 실시예에 따르면, 이상적인 배 경잡음 s(t)와 근사한 S'(t)를 함께 입력하여, 모델이 학습하도록 유도할 수 있다. 즉, 신경망의 입력으로 s (t)에 관한 정보를 직접 입력하여, 신경망 내부에서 배경잡음 s(t)와 음성 x(t)를 분리하여 처리하도록 유도할 수 있다. 배경잡음은 시점에 따라서 변화하므로 배경잡음 s(t)과 동일한 배경잡음을 신경망에 입력해주는 것은 이론적으로 불가능하다. 따라서, 본 개시에 따른 방법 및 장치에서는, 배경잡음 s(t)와 근사한 S'(t)를 생성하 여, 신경망에 함께 입력한다. 시점 t에서 근사 배경잡음 S'(t)는 수학식 3과 같이 표현될 수 있다. 수학식 3"}
{"patent_id": "10-2023-0102824", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "배경잡음과 근사 배경잡음 사이의 에러가 무시할 수 있을 만큼 작다고 가정하면, 신경망의 입력 X(t|s)은 수학 식 4와 같이 표현될 수 있다. 수학식 4"}
{"patent_id": "10-2023-0102824", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "신경망의 k번째 레이어에서 추출되는 특징을 fk라 할 때, 입력 X(t|s)가 q 개의 레이어를 거친 결과는 수학식 5 와 같이 표현될 수 있다. 수학식 5"}
{"patent_id": "10-2023-0102824", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "여기서, a, b, c 및 d는 학습에 의해 결정되는 가중치이다. 데이터에 의하여 에러가 최소화되도록 학습되는 신 경망의 학습 방식에 따라, b와 c는 서로 상쇄될 수 있고, d는 0에 가까운 값을 가질 수 있다. 본 개시의 일 실시예에 따르면, 잡음음성신호에 포함된 배경잡음과 최소한의 에러를 갖는 무음성 배경잡음신호 (또는 이로부터 추출되는 피처)를 잡음음성신호(또는 이로부터 추출되는 피처)와 함께 입력받도록 신경망 기반 의 인공지능 모델을 아키텍처링함으로써, 다양한 배경잡음이 존재하는 환경에 강인한 인공지능 모델 을 구축할 수 있다. 도 7은 본 개시의 일 실시예에 따른 음성질환 진단을 위한 방법을 개략적으로 나타낸 흐름도이다. 진단장치는 배경잡음을 포함하는 잡음 음성신호에서, 음성이 존재하지 않는 하나 이상의 무음성 시간구간들 을 추정할 수 있다(S700). 예를 들어, 진단장치는 잡음 음성신호에서, 음성이 존재하는 하나 이상의 음성 시간구간들과 음성이 존재하지 않는 하나 이상의 무음성 시간구간들을 추정할 수 있다. 일부 실시예들에서, 진 단장치는 잡음 음성신호에서 복수개의 무음성 시간구간들을 추정할 수 있다, 진단장치는 잡음 음성신호로부터 상기 하나 이상의 무음성 시간구간에 대응하는 하나 이상의 무음성 신호들 을 추출하여, 음성을 포함하지 않는 무음성 배경잡음신호를 생성할 수 있다(S720). 예컨대, 잡음 음성신호로부 터 추정된 무음성 시간구간들이 복수개인 경우, 진단장치는 복수의 무음성 시간구간들에 각각 대응하는 복 수의 무음성 신호들을 추출하고, 복수의 무음성 신호들을 연결(concatenate)함으로써 무음성 배경잡음신호를 생 성할 수 있다. 일부 실시예에서, 진단장치는, 추출된 복수의 무음성 신호들을 연결하기에 앞서, 복수의 무 음성 신호들 중에서 기설정된 길이보다 짧은 길이를 갖는 무음성 신호를 제거할 수 있다. 일부 실시예에서, 진 단장치는 하나 이상의 무음성 신호들 각각에 대해, 음성 시간구간에 인접한 구간의 영향도를 낮출 수 있다. 일 예로, 진단장치는 하나 이상의 무음성 신호들의 각각으로부터 음성 시간구간에 인접한 영역을 잘라낼 수 있다. 다른 예로, 진단장치는 하나 이상의 무음성 신호들의 각각에 윈도우 함수를 적용할 수 있다. 여기서, 윈도우 함수는, 윈도우의 중심 부분에 비해 윈도우의 끝 부분에서 상대적으로 작은 가중치를 가질 수 있다. 일 부 실시예에서, 진단장치는, 무음성 배경잡음신호에 대해 반복 패딩, 반사 패딩, 및 순환 패딩 중 적어도 하나를 적용하여 하여, 무음성 배경잡음신호가 기설정된 길이를 갖도록 조정할 수 있다. 진단장치는 인공지능 모델을 이용하여, 잡음 음성신호 및 무음성 배경잡음신호로부터 적어도 하나의 음성질환에 대한 확률을 산출할 수 있다(S740). 이를 위해, 진단장치는 신호들 및/또는 신호들로부터 추출 된 피처들을 합성하여 인공지능 모델에 입력할 수 있다. 예를 들어, 진단장치는 잡음 음성신호 및 무 음성 배경잡음신호로부터 피처를 각각 추출하고, 추출된 피처들을 합성하여 인공지능 모델에 입력할 수 있 다. 한편, 이상에서는, 진단장치가 학습이 완료된 인공지능 모델을 이용하여 추론을 수행하기 위해 도 7의 방법을 수행하는 것을 가정하였으나 본 개시가 이에 한정되는 것은 아니다. 다른 예에서, 학습장치가 인공 지능 모델을 학습시키기 위해 도 7의 방법을 수행할 수도 있다. 이 경우, 방법은 확률과 잡음 음성신호 및 /또는 무음성 배경잡음신호에 대해 부여된 음성질환 레이블 간의 손실을 기초로 인공지능 모델의 파라미터 를 갱신하는 과정을 더 포함할 수 있다. 도 8은 본 개시에서 설명된 장치 및 방법들을 구현하기 위해 사용될 수 있는 예시적인 컴퓨팅 장치를 개략적으 로 나타낸 블록구성도이다. 컴퓨팅 장치는 메모리, 프로세서, 스토리지, 입출력 인터페이스 및 통신 인터페이스 중 일부 또는 전부를 포함할 수 있다. 컴퓨팅 장치는 진단장치 및/또는 학습장치의 적어도 일부를 구조적 및/또는 기능적으로 포함할 수 있다. 컴퓨팅 장치는 데스크탑 컴퓨터, 서버, AI 가속기 등과 같은 고정형(stationary) 컴퓨팅 장치뿐만 아니라, 랩탑 컴퓨터, 스마트 폰 등과 같은 휴대용(mobile) 컴퓨팅 장치일 수도 있다. 메모리는 프로세서로 하여금 본 개시의 다양한 실시예에 따른 방법 또는 동작을 수행하도록 하는 프 로그램을 저장할 수 있다. 예를 들면, 프로그램은 프로세서에 의해서 실행 가능한(executable) 복수의 명 령어들을 포함할 수 있고, 복수의 명령어들이 프로세서에 의해서 실행됨으로써 도 2, 도 3 또는 도 7에 도 시된 과정들이 수행될 수 있다. 메모리는 단일 메모리 또는 복수의 메모리들일 수 있다. 이 경우, 본 개시 의 다양한 실시예에 따른 방법 또는 동작을 수행하기 위해 필요한 정보는 단일 메모리에 저장되거나 복수의 메 모리들에 나뉘어 저장될 수 있다. 메모리가 복수의 메모리들로 구성된 경우, 복수의 메모리들은 물리적으 로 분리될 수 있다. 메모리는 휘발성 메모리 및 비휘발성 메모리 중 적어도 하나를 포함할 수 있다. 휘발 성 메모리는 SRAM(Static Random Access Memory) 또는 DRAM(Dynamic Random Access Memory) 등을 포함하고, 비 휘발성 메모리는 플래시 메모리(flash memory) 등을 포함한다. 프로세서는 적어도 하나의 명령어들을 실행할 수 있는 적어도 하나의 코어를 포함할 수 있다. 프로세서 는 메모리에 저장된 명령어들을 실행할 수 있다. 프로세서는 단일 프로세서 또는 복수의 프로세 서들일 수 있다. 스토리지는 컴퓨팅 장치에 공급되는 전력이 차단되더라도 저장된 데이터를 유지한다. 예를 들면, 스토 리지는 비휘발성 메모리를 포함할 수도 있고, 자기 테이프, 광학 디스크, 자기 디스크와 같은 저장 매체를포함할 수도 있다. 스토리지에 저장된 프로그램은 프로세서에 의해서 실행되기 이전에 메모리로 로딩될 수 있다. 스토리지는 프로그램 언어로 작성된 파일을 저장할 수 있고, 파일로부터 컴파일러 등에 의해서 생성된 프로그램은 메모리로 로딩될 수 있다. 스토리지는 프로세서에 의해서 처리될 데이터 및/또는 프로세서에 의해서 처리된 데이터를 저장 할 수 있다. 일 예로, 스토리지는 하나 이상의 오디오 신호들 및/또는 이로부터 생성되는 잡음 음성신호와 무음성 배경잡음신호의 세트를 저장할 수 있다. 다른 예로, 스토리지는 인코딩 레이어 및/또는 인공지능 모델의 가중치들을 저장할 수 있다. 입출력 인터페이스는 마이크, 키보드, 마우스 등과 같은 입력 장치를 포함할 수 있고, 디스플레이 장치, 프린터 등과 같은 출력 장치를 포함할 수 있다. 사용자는 입출력 인터페이스를 통해 프로세서에 의한 프로그램의 실행을 트리거하고/거나 프로세서의 처리 결과를 확인할 수 있다. 예컨대, 컴퓨팅 장치는 마이크를 통해 진단 대상자의 음성을 녹음한 오디오 신호를 입력받을 수 있으며, 디스플레이 장치를 통해 진단 결과를 진단 대상자 및/또는 의료인에게 제공할 수 있다. 통신 인터페이스는 외부 네트워크에 대한 액세스를 제공할 수 있다. 컴퓨팅 장치는 통신 인터페이스 를 통해 다른 장치들과 통신할 수 있다. 예를 들면, 컴퓨팅 장치는 통신 인터페이스를 통해 다른 장치로부터 훈련된 신경망 모델을 배포 받거나, 오디오 신호를 수신할 수 있다. 본 발명에 따른 장치 또는 방법의 각 구성요소는 하드웨어 또는 소프트웨어로 구현되거나, 하드웨어 및 소프트 웨어의 결합으로 구현될 수 있다. 또한, 각 구성요소의 기능이 소프트웨어로 구현되고 마이크로프로세서가 각 구성요소에 대응하는 소프트웨어의 기능을 실행하도록 구현될 수도 있다. 본 명세서에 설명되는 시스템들 및 기법들의 다양한 구현예들은, 디지털 전자 회로, 집적회로, FPGA(field programmable gate array), ASIC(application specific integrated circuit), 컴퓨터 하드웨어, 펌웨어, 소프 트웨어, 및/또는 이들의 조합으로 실현될 수 있다. 이러한 다양한 구현예들은 프로그래밍가능 시스템 상에서 실 행 가능한 하나 이상의 컴퓨터 프로그램들로 구현되는 것을 포함할 수 있다. 프로그래밍가능 시스템은, 저장 시 스템, 적어도 하나의 입력 디바이스, 그리고 적어도 하나의 출력 디바이스로부터 데이터 및 명령들을 수신하고 이들에게 데이터 및 명령들을 전송하도록 결합되는 적어도 하나의 프로그래밍가능 프로세서(이것은 특수 목적 프로세서일 수 있거나 혹은 범용 프로세서일 수 있음)를 포함한다. 컴퓨터 프로그램들(이것은 또한 프로그램들, 소프트웨어, 소프트웨어 애플리케이션들 혹은 코드로서 알려져 있음)은 프로그래밍가능 프로세서에 대한 명령어 들을 포함하며 \"컴퓨터가 읽을 수 있는 기록매체\"에 저장된다. 컴퓨터가 읽을 수 있는 기록매체는, 컴퓨터 시스템에 의하여 읽혀질 수 있는 데이터가 저장되는 모든 종류의 기 록장치를 포함한다. 이러한 컴퓨터가 읽을 수 있는 기록매체는 ROM, CD-ROM, 자기 테이프, 플로피디스크, 메모 리 카드, 하드 디스크, 광자기 디스크, 스토리지 디바이스 등의 비휘발성(non-volatile) 또는 비일시적인(non- transitory) 매체일 수 있으며, 또한 데이터 전송 매체(data transmission medium)와 같은 일시적인 (transitory) 매체를 더 포함할 수도 있다. 또한, 컴퓨터가 읽을 수 있는 기록매체는 네트워크로 연결된 컴퓨터 시스템에 분산되어, 분산방식으로 컴퓨터가 읽을 수 있는 코드가 저장되고 실행될 수도 있다. 본 명세서의 흐름도/타이밍도에서는 각 과정들을 순차적으로 실행하는 것으로 기재하고 있으나, 이는 본 개시의 일 실시예의 기술 사상을 예시적으로 설명한 것에 불과한 것이다. 다시 말해, 본 개시의 일 실시예가 속하는 기 술 분야에서 통상의 지식을 가진 자라면 본 개시의 일 실시예의 본질적인 특성에서 벗어나지 않는 범위에서 흐 름도/타이밍도에 기재된 순서를 변경하여 실행하거나 각 과정들 중 하나 이상의 과정을 병렬적으로 실행하는 것으로 다양하게 수정 및 변형하여 적용 가능할 것이므로, 흐름도/타이밍도는 시계열적인 순서로 한정되는 것은 아니다. 이상의 설명은 본 실시예의 기술 사상을 예시적으로 설명한 것에 불과한 것으로서, 본 실시예가 속하는 기술 분 야에서 통상의 지식을 가진 자라면 본 실시예의 본질적인 특성에서 벗어나지 않는 범위에서 다양한 수정 및 변 형이 가능할 것이다. 따라서, 본 실시예들은 본 실시예의 기술 사상을 한정하기 위한 것이 아니라 설명하기 위 한 것이고, 이러한 실시예에 의하여 본 실시예의 기술 사상의 범위가 한정되는 것은 아니다. 본 실시예의 보호 범위는 아래의 청구범위에 의하여 해석되어야 하며, 그와 동등한 범위 내에 있는 모든 기술 사상은 본 실시예의 권리범위에 포함되는 것으로 해석되어야 할 것이다. 부호의 설명10: 진단장치"}
{"patent_id": "10-2023-0102824", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 개시의 일 실시예에 따른 진단장치를 개략적으로 나타낸 블록구성도이다. 도 2는 본 개시의 일 실시예에 따라, 잡음 음성신호 및 무음성 배경잡음신호의 세트를 생성하는 과정을 나타낸 흐름도이다. 도 3은 본 개시의 일 실시예에 따라, 잡음 음성신호로부터 무음성 배경잡음신호를 추출하는 과정을 나타낸 흐름 도이다. 도 4는 본 개시의 일 실시예에 따른 잡음 음성신호 및 이로부터 추출되는 무음성 신호의 예를 보여주는 예시도이다. 도 5는 본 개시의 일 실시예에 따른 인공지능 모델의 학습과정을 개략적으로 나타낸 도면이다. 도 6a 내지 도 6d는 비교 예 및 본 개시의 일 실시예에 따른 신경망에 입력되는 데이터를 나타낸 예시도이다. 도 7은 본 개시의 일 실시예에 따른 음성질환 진단을 위한 방법을 개략적으로 나타낸 흐름도이다. 도 8은 본 개시에서 설명된 장치 및 방법들을 구현하기 위해 사용될 수 있는 예시적인 컴퓨팅 장치를 개략적으 로 나타낸 블록구성도이다."}
