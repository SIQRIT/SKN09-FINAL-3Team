{"patent_id": "10-2021-0029661", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2021-0126490", "출원번호": "10-2021-0029661", "발명의 명칭": "이미지 및 포즈 변화에 기반한 깊이맵 재투사 방법 및 XR 표시 장치", "출원인": "삼성전자주식회사", "발명자": "페리 크리스토퍼 안토니"}}
{"patent_id": "10-2021-0029661", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "이미지 및 포즈 변화에 기반한 깊이맵 재투사 방법에 있어서,XR 표시 장치와 연관된 외부 전자 장치로부터 수신된 현재 이미지 프레임을 렌더링하되, 상기 현재 이미지 프레임은 상기 XR 표시 장치의 현재 포즈(pose)와 연관되는 단계;상기 외부 전자 장치로부터 업데이트된 이미지 프레임을 수신하는 단계;상기 업데이트된 이미지 프레임의 하나 이상의 특성(characteristic)에 기반하여 업데이트된 포즈를 계산하는단계;상기 업데이트된 포즈가 상기 현재 포즈에 대한 포즈 범위(pose range) 내에 있는지 여부를 결정하는 단계; 및상기 업데이트된 포즈가 상기 포즈 범위 내에 있는지 여부에 기반하여, 상기 현재 이미지 프레임을 상기 XR 표시 장치의 하나 이상의 디스플레이 상에 재렌더링하는(re-rendering) 단계를 포함하는, 방법."}
{"patent_id": "10-2021-0029661", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 하나 이상의 특성은, 이미지 콘텐트 범위(image content range), 깊이 밀도(depth density), 이미지 콘텐트 깊이(image content depth), 또는 깊이 연속성(depth continuity) 중 하나 이상을 포함하는, 방법."}
{"patent_id": "10-2021-0029661", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 업데이트된 포즈가 상기 현재 포즈에 대한 상기 포즈 범위 내에 있는지 여부를 결정하기에 앞서, 상기 현재 포즈에 대한 상기 포즈 범위를 목표 이미지 품질(target image quality)에 기반하여 계산하는 단계를 더 포함하는, 방법."}
{"patent_id": "10-2021-0029661", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,상기 외부 전자 장치로부터 제2 업데이트된 이미지 프레임의 수신에 대해 모니터링하는 단계; 및상기 외부 전자 장치로부터 상기 제2 업데이트된 이미지 프레임을 수신하는 단계를 더 포함하는, 방법."}
{"patent_id": "10-2021-0029661", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서,제2 업데이트된 이미지 프레임을 수신함에 응답하여,상기 제2 업데이트된 이미지 프레임의 하나 이상의 특성에 기반하여 제2 업데이트된 포즈를 계산하는 단계;상기 제2 업데이트된 포즈가 상기 현재 포즈에 대한 상기 포즈 범위 내에 있는지 여부를 결정하는 단계; 및상기 제2 업데이트된 포즈가 상기 현재 포즈에 대한 상기 포즈 범위 내에 있지 않다고 결정함에 응답하여, 상기제2 업데이트된 포즈에 대응하는 하나 이상의 앵커(anchor)가 상기 XR 표시 장치에 저장되어 있는지 여부를 결정하는 단계를 더 포함하는, 방법."}
{"patent_id": "10-2021-0029661", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5항에 있어서,공개특허 10-2021-0126490-3-상기 제2 업데이트된 포즈에 대응하는 상기 하나 이상의 앵커가 상기 XR 표시 장치에 저장되어 있다고 결정함에응답하여, 상기 하나 이상의 앵커에 대응하는 이미지 데이터 또는 깊이 데이터를 액세스하는 단계를 더 포함하는, 방법."}
{"patent_id": "10-2021-0029661", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6항에 있어서,상기 제2 업데이트된 포즈가 상기 하나 이상의 앵커에 대응하는 업데이트된 포즈 범위 내에 있는지 여부를 결정하는 단계; 및상기 제2 업데이트된 포즈가 상기 업데이트된 포즈 범위 내에 있다고 결정하는 경우, 상기 제2 업데이트된 이미지 프레임을 상기 XR 표시 장치의 상기 하나 이상의 디스플레이 상에 렌더링하는 단계를 더 포함하는, 방법."}
{"patent_id": "10-2021-0029661", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1항에 있어서,상기 현재 이미지 프레임을 상기 XR 표시 장치의 상기 하나 이상의 디스플레이 상에 재렌더링하는 단계는, 상기업데이트된 포즈에서 상기 현재 이미지 프레임을 재렌더링하는 단계를 포함하는, 방법."}
{"patent_id": "10-2021-0029661", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "이미지 및 포즈 변화에 기반하여 깊이맵을 재투사하는 확장 현실(XR) 표시 장치에 있어서,하나 이상의 디스플레이;명령어들(instructions)을 포함하고 컴퓨터 판독 가능한 하나 이상의 저장 매체; 및상기 하나 이상의 저장 매체에 결합되는 하나 이상의 프로세서를 포함하고,상기 하나 이상의 프로세서는 상기 명령어들을 실행함으로써,연관된 외부 전자 장치로부터 수신된 현재 이미지 프레임을 렌더링하되, 상기 현재 이미지 프레임은 현재 포즈(pose)와 연관되고,상기 외부 전자 장치로부터 업데이트된 이미지 프레임을 수신하고,상기 업데이트된 이미지 프레임의 하나 이상의 특성(characteristic)에 기반하여 업데이트된 포즈를 계산하고,상기 업데이트된 포즈가 상기 현재 포즈에 대한 포즈 범위(pose range) 내에 있는지 여부를 결정하고,상기 업데이트된 포즈가 상기 포즈 범위 내에 있는지 여부에 기반하여, 상기 현재 이미지 프레임을 상기 하나이상의 디스플레이 상에 재렌더링하는(re-rendering), XR 표시 장치."}
{"patent_id": "10-2021-0029661", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9항에 있어서,상기 하나 이상의 특성은, 이미지 콘텐트 범위(image content range), 깊이 밀도(depth density), 이미지 콘텐트 깊이(image content depth), 또는 깊이 연속성(depth continuity) 중 하나 이상을 포함하는, XR 표시 장치."}
{"patent_id": "10-2021-0029661", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제9항에 있어서,상기 하나 이상의 프로세서는 상기 명령어들을 실행함으로써,상기 업데이트된 포즈가 상기 현재 포즈에 대한 상기 포즈 범위 내에 있는지 여부를 결정하기에 앞서, 상기 현재 포즈에 대한 상기 포즈 범위를 목표 이미지 품질(target image quality)에 기반하여 계산하는, XR 표시장치."}
{"patent_id": "10-2021-0029661", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "공개특허 10-2021-0126490-4-제9항에 있어서,상기 하나 이상의 프로세서는 상기 명령어들을 실행함으로써,상기 외부 전자 장치로부터 제2 업데이트된 이미지 프레임의 수신에 대해 모니터링하고,상기 외부 전자 장치로부터 상기 제2 업데이트된 이미지 프레임을 수신하는, XR 표시 장치."}
{"patent_id": "10-2021-0029661", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제12항에 있어서,상기 하나 이상의 프로세서는 상기 명령어들을 실행함으로써,제2 업데이트된 이미지 프레임을 수신함에 응답하여,상기 제2 업데이트된 이미지 프레임의 하나 이상의 특성들에 기반하여 제2 업데이트된 포즈를 계산하고,상기 제2 업데이트된 포즈가 상기 현재 포즈에 대한 상기 포즈 범위 내에 있는지 여부를 결정하고,상기 제2 업데이트된 포즈가 상기 현재 포즈에 대한 상기 포즈 범위 내에 있지 않다고 결정함에 응답하여, 상기제2 업데이트된 포즈에 대응하는 하나 이상의 앵커(anchor)가 저장되어 있는지 여부를 결정하는, XR 표시 장치."}
{"patent_id": "10-2021-0029661", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제13항에 있어서,상기 하나 이상의 프로세서는 상기 명령어들을 실행함으로써,상기 제2 업데이트된 포즈에 대응하는 상기 하나 이상의 앵커가 저장되어 있다고 결정함에 응답하여, 상기 하나이상의 앵커에 대응하는 이미지 데이터 또는 깊이 데이터를 액세스하는, XR 표시 장치."}
{"patent_id": "10-2021-0029661", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제14항에 있어서,상기 하나 이상의 프로세서는 상기 명령어들을 실행함으로써,상기 제2 업데이트된 포즈가 상기 하나 이상의 앵커에 대응하는 업데이트된 포즈 범위 내에 있는지 여부를 결정하고,상기 제2 업데이트된 포즈가 상기 업데이트된 포즈 범위 내에 있다고 결정하는 경우, 상기 제2 업데이트된 이미지 프레임을 상기 하나 이상의 디스플레이 상에 렌더링하는, XR 표시 장치."}
{"patent_id": "10-2021-0029661", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제9항에 있어서,상기 하나 이상의 프로세서는 상기 명령어들을 실행함으로써,상기 업데이트된 포즈에서 상기 현재 이미지 프레임을 상기 하나 이상의 디스플레이 상에 재렌더링하는, XR 표시 장치."}
{"patent_id": "10-2021-0029661", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제1항 내지 제8항 중 어느 한 항의 방법을 컴퓨터에서 실행시키기 위한 프로그램을 기록한 컴퓨터로 읽을 수 있는 기록매체."}
{"patent_id": "10-2021-0029661", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "이미지 및 포즈 변화에 기반하여 깊이맵을 재투사하는 XR 표시 장치 및 그 방법이 제공된다. 방법은, XR 표시 장 치와 연관된 외부 전자 장치로부터 수신된, XR 표시 장치의 현재 포즈(pose)와 연관되는 현재 이미지 프레임을 렌더링하는 단계, 외부 전자 장치로부터 업데이트된 이미지 프레임을 수신하는 단계, 업데이트된 이미지 프레임 의 하나 이상의 특성(characteristic)에 기반하여 업데이트된 포즈를 계산하는 단계, 업데이트된 포즈가 현재 포 즈에 대한 포즈 범위(pose range) 내에 있는지 여부를 결정하는 단계, 및 업데이트된 포즈가 포즈 범위 내에 있 는지 여부에 기반하여, 현재 이미지 프레임을 XR 표시 장치의 하나 이상의 디스플레이 상에 재렌더링하는(re- rendering) 단계를 포함할 수 있다."}
{"patent_id": "10-2021-0029661", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 깊이맵(depth map) 재투사 방법 및 XR 표시 장치에 관한 것이며, 보다 구체적으로, 이미지 및 포즈 업데이트에 기반하여 깊이맵을 재투사(re-projection)하는 방법 및 XR 표시 장치에 관한 것이다."}
{"patent_id": "10-2021-0029661", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "확장 현실(extended reality, XR) 시스템은 일반적으로, 적어도 일부의 XR 아티팩트들(artifacts)을 포함하는, 컴퓨터로 생성된(computer-generated) 환경 또는 실제(real-world) 환경을 포함할 수 있다. XR 시스템 또는 세 계, 및 연관된 XR 아티팩트들은 전형적으로, 사용자들이 컴퓨터로 생성된 표현(예를 들어, 아바타(avatar))의 형태로 그들의 존재를 조작함으로써 이러한 XR 아티팩트들을 이용할 수 있도록 하는, 다양한 애플리케이션들(예 를 들어, 비디오 게임들)을 포함할 수 있다. 전형적인 XR 시스템들에서, 이미지 데이터는, 예를 들어, 이미지 데이터의 생성을 담당하는 기본 그래픽 생성 장치(base graphics generation device)에 물리적 유선 연결을 통 해 결합될 수 있는, 견고한 헤드 마운트 디스플레이(head-mounted display, HMD) 상에 렌더링될 수 있다. XR 시스템, 특히 무선으로 연결된 다른 장치를 갖는 AR HMD는 점점 크기가 작아지고 있다. 견고한(robust) 헤드 셋 장치들과 달리, HMD가 경량의 XR 안경을 포함하는 경우, XR 안경은 비교적 처리 전력(processing power)이 감소된 저해상/저비용 카메라들 및 상대적으로 단순한 추적 광학계(tracking optics)를 포함하게 된다. 또한, XR 안경 등의 작은 XR 표시 장치들은, 작은 구조적 면적(architectural area)으로 인해 전력 관리 능력(예를 들 어, 컴퓨팅 전력, 배터리 크기 등) 및 열 관리 능력(예를 들어, 냉각팬, 히트 싱크(heat sinks) 여부 또는 크기)이 저하된 전자 장치들을 포함할 수도 있다. 한편, XR 시스템에서는 시야(field of view, FOV)가 점점 넓어지고, 해상도가 점점 증가하고 있다. 따라서, 경 량의 소형 XR 표시 장치에서는, 폼팩터를 작게 만들면서(배터리 크기, 배터리량을 줄이면서) 성능을 유지하거나 증가시켜야 하는 어려운 과제를 갖는다. 이에 따라, 작은 경량의 XR 표시 장치에서 배터리 및 발열을 줄이기 위 해 전력 소비를 줄일 수 있는 기술이 요구된다."}
{"patent_id": "10-2021-0029661", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 개시의 일 실시예는, 이미 표시되고 있던 이미지를 계속해서 재렌더링(또는 재투사)하거나, 저장된 앵커들에 기반하여 표시될 현재 이미지 프레임을 조정함으로써, 전력 소비의 중요한 부분을 차지하는 무선 데이터 전송의 네트워크 트래픽을 줄일 수 있고, 나아가 XR 표시 장치에서 소비되는 전력을 줄일 수 있는, 방법 및 그 XR 표시 장치를 제공할 수 있다. 본 개시의 일 실시예는, 다음에 표시할 이미지가, 이미 표시되고 있는 이미지 또는 XR 표시 장치에 기 저장된 이미지와 동일 범위에 있는 경우, 외부 전자 장치에 갱신된 데이터의 제공을 요청하지 않음으로써, 갱신된 데이 터의 획득을 위해 외부 전자 장치에 불필요하게 의존하지 않을 수 있고, XR 표시 장치와 외부 전자 장치 간의 네트워크 트래픽을 감소시킬 수 있는, 방법 및 그 XR 표시 장치를 제공할 수 있다."}
{"patent_id": "10-2021-0029661", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상술한 기술적 과제를 달성하기 위한 기술적 수단으로서 개시된, 이미지 및 포즈 변화에 기반한 깊이맵 재투사 방법은, XR 표시 장치와 연관된 외부 전자 장치로부터 수신된 현재 이미지 프레임을 렌더링하되, 현재 이미지 프레임은 XR 표시 장치의 현재 포즈(pose)와 연관되는 단계, 외부 전자 장치로부터 업데이트된 이미지 프레임을 수신하는 단계, 업데이트된 이미지 프레임의 하나 이상의 특성(characteristic)에 기반하여 업데이트된 포즈를 계산하는 단계, 업데이트된 포즈가 현재 포즈에 대한 포즈 범위(pose range) 내에 있는지 여부를 결정하는 단계, 및 업데이트된 포즈가 포즈 범위 내에 있는지 여부에 기반하여, 현재 이미지 프레임을 XR 표시 장치의 하 나 이상의 디스플레이 상에 재렌더링하는(re-rendering) 단계를 포함할 수 있다. 상술한 기술적 과제를 달성하기 위한 기술적 수단으로서 개시된, 이미지 및 포즈 변화에 기반하여 깊이맵을 재 투사하는 XR 표시 장치는, 하나 이상의 디스플레이, 명령어들(instructions)을 포함하고 컴퓨터 판독 가능한 하 나 이상의 저장 매체, 및 하나 이상의 저장 매체에 결합되는 하나 이상의 프로세서를 포함할 수 있다. 하나 이 상의 프로세서는 명령어들을 실행함으로써, 연관된 외부 전자 장치로부터 수신된 현재 이미지 프레임을 렌더링 하되, 현재 이미지 프레임은 현재 포즈(pose)와 연관되고, 외부 전자 장치로부터 업데이트된 이미지 프레임을 수신하고, 업데이트된 이미지 프레임의 하나 이상의 특성(characteristic)에 기반하여 업데이트된 포즈를 계산 하고, 업데이트된 포즈가 현재 포즈에 대한 포즈 범위(pose range) 내에 있는지 여부를 결정하고, 업데이트된 포즈가 포즈 범위 내에 있는지 여부에 기반하여, 현재 이미지 프레임을 하나 이상의 디스플레이 상에 재렌더링 할 수 있다.상술한 기술적 과제를 달성하기 위한 기술적 수단으로서, 컴퓨터 판독 가능한 매체는, 명령어들(instructions) 을 포함할 수 있다. 명령어들은, 확장 현실(XR) 표시 장치에 포함된 하나 이상의 프로세서에 의해 실행될 경우, 하나 이상의 프로세서로 하여금, XR 표시 장치와 연관된 외부 전자 장치로부터 수신된 현재 이미지 프레임을 렌 더링하되, 현재 이미지 프레임은 XR 표시 장치의 현재 포즈와 연관되고, 외부 전자 장치로부터 업데이트된 이미 지 프레임을 수신하고, 업데이트된 이미지 프레임의 하나 이상의 특성(characteristic)에 기반하여 업데이트된 포즈를 계산하고, 업데이트된 포즈가 현재 포즈에 대한 포즈 범위 내에 있는지 여부를 결정하고, 업데이트된 포 즈가 포즈 범위 내에 있는지 여부에 기반하여, 현재 이미지 프레임을 XR 표시 장치의 하나 이상의 디스플레이 상에 재렌더링(re-rendering)하도록 할 수 있다."}
{"patent_id": "10-2021-0029661", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "아래에서는 첨부한 도면을 참조하여 본 개시가 속하는 기술 분야에서 통상의 지식을 가진 자가 용이하게 실시할 수 있도록 본 개시의 실시예를 상세히 설명한다. 그러나 본 개시는 여러 가지 상이한 형태로 구현될 수 있으며 여기에서 설명하는 실시예에 한정되지 않는다. 그리고 도면에서 본 개시를 명확하게 설명하기 위해서 설명과 관 계없는 부분은 생략하였으며, 명세서 전체를 통하여 유사한 부분에 대해서는 유사한 도면 부호를 붙였다. 본 개시의 실시예들에서 사용되는 용어는 본 개시의 기능을 고려하면서 가능한 현재 널리 사용되는 일반적인 용 어들을 선택하였으나, 이는 당 분야에 종사하는 기술자의 의도 또는 판례, 새로운 기술의 출현 등에 따라 달라 질 수 있다. 또한, 특정한 경우는 출원인이 임의로 선정한 용어도 있으며, 이 경우 해당되는 실시예의 설명 부 분에서 상세히 그 의미를 기재할 것이다. 따라서 본 명세서에서 사용되는 용어는 단순한 용어의 명칭이 아닌, 그 용어가 가지는 의미와 본 개시의 전반에 걸친 내용을 토대로 정의되어야 한다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함할 수 있다. 기술적이거나 과학적인 용어를 포함해서 여기서 사용되는 용어들은 본 명세서에 기재된 기술 분야에서 통상의 지식을 가진 자에 의해 일반적으로 이해되는 것과 동일한 의미를 가질 수 있다. 본 개시 전체에서 어떤 부분이 어떤 구성요소를 \"포함\"한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다 른 구성요소를 제외하는 것이 아니라 다른 구성요소를 더 포함할 수 있음을 의미한다. 또한, 본 명세서에 기재 된 \"..부\", \"..모듈\" 등의 용어는 적어도 하나의 기능이나 동작을 처리하는 단위를 의미하며, 이는 하드웨어 또 는 소프트웨어로 구현되거나 하드웨어와 소프트웨어의 결합으로 구현될 수 있다. 명세서 전체에서, 어떤 부분이 다른 부분과 \"연결\"되어 있다고 할 때, 이는 \"직접적으로 연결\"되어 있는 경우뿐 아니라, 그 중간에 다른 소자를 사이에 두고 \"전기적으로 연결\"되어 있는 경우도 포함한다. 또한 어떤 부분이 어떤 구성요소를 \"포함\"한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다른 구성요소를 제외하는 것이 아 니라 다른 구성요소를 더 포함할 수 있는 것을 의미한다. 본 개시에 따른 인공지능과 관련된 기능은 프로세서와 메모리를 통해 동작될 수 있다. 프로세서는 하나 또는 복 수의 프로세서로 구성될 수 있다. 이때, 하나 또는 복수의 프로세서는 CPU, AP, DSP(Digital Signal Processor) 등과 같은 범용 프로세서, GPU, VPU(Vision Processing Unit)와 같은 그래픽 전용 프로세서 또는 NPU와 같은 인공지능 전용 프로세서일 수 있다. 하나 또는 복수의 프로세서는, 메모리에 저장된 기 정의된 동작 규칙 또는 인공지능 모델에 따라, 입력 데이터를 처리하도록 제어한다. 또는, 하나 또는 복수의 프로세서가 인 공지능 전용 프로세서인 경우, 인공지능 전용 프로세서는, 특정 인공지능 모델의 처리에 특화된 하드웨어 구조 로 설계될 수 있다.기 정의된 동작 규칙 또는 인공지능 모델은 학습을 통해 만들어진 것을 특징으로 한다. 여기서, 학습을 통해 만 들어진다는 것은, 기본 인공지능 모델이 학습 알고리즘에 의하여 다수의 학습 데이터들을 이용하여 학습됨으로 써, 원하는 특성(또는, 목적)을 수행하도록 설정된 기 정의된 동작 규칙 또는 인공지능 모델이 만들어짐을 의미 한다. 이러한 학습은 본 개시에 따른 인공지능이 수행되는 기기 자체에서 이루어질 수도 있고, 별도의 서버 또 는 시스템을 통해 이루어 질 수도 있다. 학습 알고리즘의 예로는, 지도형 학습(supervised learning), 비지도형 학습(unsupervised learning), 준지도형 학습(semi-supervised learning) 또는 강화 학습(reinforcement learning)이 있으나, 전술한 예에 한정되지 않는다. 인공지능 모델은, 복수의 신경망 레이어들로 구성될 수 있다. 복수의 신경망 레이어들 각각은 복수의 가중치들 (weight values)을 갖고 있으며, 이전(previous) 레이어의 연산 결과와 복수의 가중치들 간의 연산을 통해 신경 망 연산을 수행한다. 복수의 신경망 레이어들이 갖고 있는 복수의 가중치들은 인공지능 모델의 학습 결과에 의 해 최적화될 수 있다. 예를 들어, 학습 과정 동안 인공지능 모델에서 획득한 로스(loss) 값 또는 코스트(cost) 값이 감소 또는 최소화되도록 복수의 가중치들이 갱신될 수 있다. 인공 신경망은 심층 신경망(Deep Neural Network, DNN)를 포함할 수 있으며, 예를 들어, CNN (Convolutional Neural Network), DNN (Deep Neural Network), RNN (Recurrent Neural Network), RBM (Restricted Boltzmann Machine), DBN (Deep Belief Network), BRDNN(Bidirectional Recurrent Deep Neural Network) 또는 심층 Q-네트워크 (Deep Q-Networks) 등 이 있으나, 전술한 예에 한정되지 않는다. 본 개시의 실시예들은 이미지, 및 깊이 데이터 및 포즈(pose) 데이터의 업데이트에 기반하여 깊이맵(depth ma p)을 선택적으로 재투사하는 기법에 관한 것이다. 일 실시예에서, 확장 현실(extended reality, XR) 표시 장치 는 XR 표시 장치와 연관된 외부 전자 장치로부터 수신된 현재 이미지 프레임을 렌더링할 수 있다. 일 실시예에 서, 현재 이미지 프레임은 XR 표시 장치의 현재 포즈와 연관될 수 있다. 일 실시예에서, 이후, XR 표시 장치는 외부 전자 장치로부터 업데이트된 이미지 프레임을 수신할 수 있다. 일 실시예에서, 이후, XR 표시 장치는, 업 데이트된 이미지 프레임의 하나 이상의 이미지 또는 깊이 특성(depth characteristic)들에 기반하여, 업데이트 된 포즈를 계산할 수 있다. 예를 들어, 일 실시예에서, 하나 이상의 이미지 또는 깊이 특성들은 이미지 콘텐트 범위(image content range), 깊이 밀도(depth density), 이미지 콘텐트 깊이(image content depth), 또는 깊이 연속성(depth continuity) 중 하나 이상을 포함할 수 있다. 일 실시예에서, 이후, XR 표시 장치는 업데이트된 포즈가 현재 이미지 프레임과 연관된 현재 포즈에 대한 포즈 범위 내에 있는지 여부를 결정할 수 있다. 예를 들 어, 일 실시예에서, 업데이트된 포즈가 현재 포즈에 대한 포즈 범위 내에 있는지 여부를 결정하기 전에, XR 표 시 장치는 현재 포즈에 대한 적절한 포즈 범위를 계산할 수 있으며, 적절한 포즈 범위는 목표 이미지 품질 (target image quality)에 기반하여 결정될 수 있다. 일 실시예에서, 이후, XR 표시 장치는, 업데이트된 포즈가 포즈 범위 내에 있는지 여부에 기반하여, 현재 이미지 프레임을 XR 표시 장치의 하나 이상의 디스플레이들 상에 재렌더링(re-rendering)할 수 있다. 일 실시예에서, 이후 XR 표시 장치는 외부 전자 장치로부터의 제2 업데이트된 이미지 프레임의 수신에 대해 지 속적으로 모니터링할 수 있다. 일 실시예에서, 이후 제2 업데이트된 이미지 프레임을 수신함에 응답하여, XR 표 시 장치는 제2 업데이트된 이미지 프레임의 하나 이상의 이미지 또는 깊이 특성들에 기반하여 제2 업데이트된 포즈를 계산할 수 있다. 예를 들어, 앞서 논의한 바와 같이, 일 실시예에서, 하나 이상의 이미지 또는 깊이 특 성들은 이미지 콘텐트 범위, 깊이 밀도, 이미지 콘텐트 깊이, 또는 깊이 연속성 중 하나 이상을 포함할 수 있다. 일 실시예에서, 이후, 제2 업데이트된 포즈가 현재 포즈에 대한 계산된 포즈 범위 내에 있지 않다고 결정 함에 응답하여, XR 표시 장치는 제2 업데이트된 포즈에 대응하는 하나 이상의 앵커들(anchors)이 XR 표시 장치 에 저장되어 있는지 여부를 결정할 수 있다. 예를 들어, 일 실시예에서, XR 표시 장치는 시간에 따라 여러 앵커 들을 저장할 수 있으며, 앵커들 각각은, 연관된 이미지 및 깊이 데이터세트(dataset)와 함께 저장된 특정 포즈 를 포함하는, 데이터 요소(data element), 객체 인스턴스(object instance), 또는 경계 박스(bounding box)를 포함할 수 있다. 일 실시예에서, 제2 업데이트된 포즈에 대응하는 하나 이상의 앵커들이 XR 표시 장치에 저장되 어 있다고 결정함에 응답하여, XR 표시 장치는 하나 이상의 앵커들에 대응하는 이미지 데이터 또는 깊이 데이터 를 액세스할 수 있다. 일 실시예에서, 이후, XR 표시 장치는 제2 업데이트된 포즈가 하나 이상의 앵커들에 대응 하는 업데이트된 포즈 범위 내에 있는지 여부를 결정할 수 있다. 이후, 제2 업데이트된 포즈가 업데이트된 포즈 범위 내에 있다고 결정하는 경우, XR 표시 장치는 업데이트된 이미지 프레임을 XR 표시 장치의 하나 이상의 디 스플레이들 상에 렌더링할 수 있다. 따라서, 본 개시의 일 실시예에 따르면, XR 표시 장치와 외부 전자 장치 간의 네트워크 트래픽을 감소시키기 위 해, 그리고, 더 나아가, XR 표시 장치의 전력 소모 및 열 출력을 감소시키기 위해, 현재 이미지 프레임과 연관된 포즈가 적절한 포즈 범위 내에 있는지 여부에 기반하여, XR 표시 장치는, XR 표시 장치의 하나 이상의 디스 플레이 상에, 현재 이미지 프레임을 렌더링하지 않고 대신에 이전 이미지 프레임을 재렌더링(re-rendering)할 수 있다. 일 실시예에서, 현재 이미지 프레임과 연관된 포즈가 적절한 포즈 범위 내에 있지 않은 경우에도, XR 표시 장치는, 현재 이미지 프레임과 연관된 포즈에 대응하는 하나 이상의 저장된 앵커들에 대응하는, 이미지 데 이터 또는 깊이 데이터를 액세스하고 이에 기반하여 현재 이미지 프레임 및 적절한 포즈 범위를 조정할 수 있다. 본 개시의 일 실시예에 따르면, XR 표시 장치는 XR 표시 장치의 하나 이상의 디스플레이들에 의해 이미 표시되 고 있었던 2D 또는 3D 이미지를 계속해서 재렌더링(또는 재투사(re-project))하거나 또는 저장된 앵커들에 기반 하여 표시될 현재 이미지 프레임을 조정할 수 있으며, 이에 따라, XR 표시 장치는, XR 표시 장치에 의해 이미 표시되고 있거나 또는 다음으로 표시될 2D 또는 3D 이미지들과 동일하거나 거의 동일한 이미지 콘텐트 또는 깊 이 콘텐트를 포함할 이미지 데이터 또는 깊이 데이터의 갱신 업데이트(refresh updates)의 제공을 위해, 외부 전자 장치에 불필요하게 의존하지 않을 수 있다. 따라서, 본 개시에 따르면, XR 표시 장치가 전력 관리 능력(예 를 들어, 배터리, 배터리 크기) 및 열 관리 능력(예를 들어, 냉각팬, 히트 싱크(heat sinks) 여부)이 저하된 전 자 장치들을 포함하는 경우라 하더라도, XR 표시 장치는 전력 소모 및 열 출력을 감소시키면서 사용자들에게 요 구되는 수준의 XR 경험을 제공할 수 있다. 본 개시에서, \"확장 현실(extended reality)\"은, 예를 들어, 가상현실(virtual reality, VR), 증강현실 (augmented reality, AR), 혼합 현실(mixed reality, MR), 하이브리드 현실(hybrid reality), 모사 현실 (simulated reality), 몰입 현실(immersive reality), 홀로그래피(holography), 또는 이들의 어떤 조합을 포함 하는, 사용자에게 제시하기 전에 어떤 방식으로 조작된 전자 기반 현실(electronic-based reality)의 형태를 의 미할 수 있다. 예를 들어, \"확장 현실\" 콘텐트는 전적으로 컴퓨터로 생성된(completely computer-generated) 콘텐트, 또는 캡쳐된 콘텐트(예를 들어, 실제 이미지들)와 조합된 부분적으로 컴퓨터로 생성된(partially computer-generated) 콘텐트를 포함할 수 있다. 일 실시예에서, \"확장 현실\" 콘텐트는 비디오, 오디오, 햅틱 피 드백(haptic feedback), 또는 이들의 어떤 조합을 포함할 수 있으며, 이들 중 어떤 것이든 단일 채널로 또는 다 중 채널로(예를 들어, 시청자에게 3차원(three-dimensional, 3D) 효과를 제공하는 스테레오 비디오) 제시될 수 있다. 또한, 본 개시에서, \"확장 현실\"은, 예를 들어, 확장 현실에서 콘텐트를 생성하는 데 이용되거나, 확장 현실 내에서 예를 들어, 활동들(activities)을 수행하는 데 이용될 수 있는, 애플리케이션들, 제품들 (products), 액세서리들, 서비스들, 또는 이들의 조합과 연관될 수 있다. 따라서, \"확장 현실\" 콘텐트는, 호스 트 컴퓨터 시스템에 연결된 머리-장착형 장치(head-mounted device, HMD), 독립형 HMD, 모바일 장치, 컴퓨팅 시 스템, 또는 한 명 이상의 시청자들에게 확장 현실 콘텐트를 제공할 수 있는 플랫폼을 포함하는, 다양한 플랫폼 들에서 구현될 수 있다. 본 개시에서, \"현재 이미지 프레임(current image frame)\"은, 이미지 또는 깊이 처리 및 분석을 위해, 컴퓨팅 플랫폼으로부터 XR 표시 장치에 전송(푸시(push))되거나 또는 XR 표시 장치에 의해 컴퓨팅 플랫폼으로부터 요청 또는 로딩(풀(pull))될 수 있는, 가장 최근의 이미지 프레임 또는 가장 최근의 이미지 프레임 세트를 의미할 수 있다. 예를 들어, \"현재 이미지 프레임\"은 단순히, XR 표시 장치에 푸시(push)되거나 또는 XR 표시 장치에 의해 풀(pull)될 수 있는, (컴퓨팅 플랫폼에 의해 렌더링되고 있는 RGBD 이미지 프레임의 N 세트 중) 최신(latest) 이미지 프레임에 대응될 수 있다. 일 실시예에서, RGBD 이미지 프레임의 N 세트의 이미지 프레임들이 모두 컴퓨 팅 플랫폼으로부터 XR 표시 장치로 제공되는 것은 아닐 수 있으며, 따라서, \"현재 이미지 프레임\"은 컴퓨팅 플 랫폼으로부터 XR 표시 장치로 실제로(indeed) 전송되는 가장 최근의 이미지를 의미할 수 있다. 도 1은 본 개시의 일 실시예에 따른 확장 현실(extended reality, XR) 시스템을 도시하는 도면이다. 도 1을 참조하면, 이미지 및 깊이 데이터 및 포즈 데이터 업데이트들에 기반하여 깊이맵들을 선택적으로 재투사 하는, 확장 현실(XR) 시스템이 도시 된다. 일 실시예에서, XR 시스템은 XR 표시 장치, 네트워크 , 및 컴퓨팅 플랫폼을 포함할 수 있다. XR 표시 장치는 확장 현실(XR)을 디스플레이할 수 있는 장치로서, 일반적으로 사용자가 안면부에 착용하는 안경 형상의 XR 안경(XR glasses), 두부에 착용하는 헤드 마운트 디스플레이(head mounted display, HMD), 가 상 현실 헤드셋(virtual reality headset, VRH), 또는 XR 헬멧(XR helmet) 등을 포함할 수 있다. 헤드 마운트 형 장치의 경우, 사용자의 눈 앞에 디스플레이를 배치함으로써, 사용자에게 초대형 화면을 제공할 수 있고, 사 용자의 움직임에 따라 화면이 움직이므로 사실적인 가상 세계를 제공할 수 있다. 일 실시예에서, 사용자는 시각적 확장 현실 콘텐트를 표시할 수 있는, XR 표시 장치를 착용할 수 있다. XR 표시 장치는 오디오 확장 현실 콘텐트를 사용자에게 제공할 수 있는 오디오 모듈을 포함할 수 있다. 일 실 시예에서, XR 표시 장치는 환경의 이미지 및 비디오를 캡쳐할 수 있는 하나 이상의 카메라를 포함할 수 있 다. XR 표시 장치는 사용자의 수렴 거리(vergence distance)를 결정하기 위해 시선 추적(eye tracking) 시스템을 포함할 수 있다. 일 실시예에서, XR 표시 장치는 경량의 머리 착용형 디스플레이(HMD)(예를 들어, 고글(goggles), 안경, 바이저(visor) 등)를 포함할 수 있다. 일 실시예에서, XR 표시 장치는 경량의 휴대용 표시 장치 또는 하나 이상의 레이저 투사 안경(예를 들어, 사용자에게 이미지 또는 깊이 콘텐트를 투사 및 표시하기 위해 사용자의 망막 상에 저전력 레이저(low-powered laser)를 투사할 수 있는 안경)과 같은, 비- HMD 장치를 포함할 수 있다. 일 실시예에서, XR 표시 장치는 사용자의 시야(field of view, FOV)로 판단되는 영역에 적어도 하나의 가 상 객체가 겹쳐 보이도록 출력하는 XR 서비스를 제공할 수 있다. 예를 들어, 사용자의 시야로 판단되는 영역은 XR 표시 장치를 착용한 사용자가 XR 표시 장치를 통해 인지할 수 있다고 판단되는 영역으로, XR 표시 장치의 디스플레이의 전체 또는 적어도 일부를 포함하는 영역일 수 있다. 일 실시예에서, XR 표시 장치 는 사용자의 양안 각각에 대응하는 복수개의 투명 부재를 포함할 수 있다. 일 실시예에서, XR 표시 장치는 디스플레이, 카메라, 오디오 출력부, 및 지지부를 포함할 수 있다. 카메라는 사용자의 시야에 대응되는 영상을 촬영하거나 객체와의 거리를 측정할 수 있다. 일 실시예에서, 카메 라는 헤드 트래킹(head tracking) 및 공간 인식을 위해 사용될 수 있다. 또한, 카메라는 사용자의 움직임을 인 식할 수도 있다. 일 실시예에서, 카메라는 사용자의 시야에 대응되는 영상, 즉 객체의 움직임을 검출하거나, 공간 인식을 위해 사용되는 카메라 이외에 'ET(eye tracking) 카메라'를 더 포함할 수도 있다. 일 실시예에서, ET 카메라는 사용 자의 눈동자를 검출하고 추적하는 용도로 사용될 수 있다. ET 카메라는 XR 표시 장치에 투영되는 가상 영 상의 중심이, XR 표시 장치를 착용하는 사용자의 눈동자가 응시하는 방향에 따라 위치하도록 조절하기 위 한 용도로 사용될 수 있다. 예를 들어, ET 카메라에는 눈동자(pupil)를 검출하고 빠른 눈동자 움직임을 지연 없 이 추적할 수 있도록 GS(Global shutter) 카메라가 이용될 수 있다. ET 카메라는 좌안용 카메라 및 우안용 카메 라를 별도로 포함할 수도 있다. 일 실시예에서 디스플레이를 통해 출력되는 가상 객체는 XR 표시 장치에서 실행되는 애플리케이션 프로그 램과 관련된 정보 또는 사용자의 시야로 판단되는 영역에 대응하는 실제 공간에 위치한 외부 객체와 관련된 정 보를 포함할 수 있다. 예를 들어, XR 표시 장치는 카메라를 통해 획득한 실제 공간과 관련된 영상 정보 중 사용자의 시야로 판단되는 영역에 대응하는 적어도 일부에 포함되는 외부 객체를 확인할 수 있다. XR 표시 장치 는 적어도 일부에서 확인한 외부 객체와 관련된 가상 객체를 XR 표시 장치의 표시 영역 중 사용자의 시야로 판단되는 영역을 통해 출력할 수 있다. 외부 객체는 실제 공간에 존재하는 사물을 포함할 수 있다. 일 실시예에서, 디스플레이는 투명 부재에 집광 렌즈 또는 웨이브가이드(waveguide, 도파관 또는 도파로)를 포 함할 수 있다. 예를 들어, 투명 부재는 글래스 플레이트, 플라스틱 플레이트, 또는 폴리머로 형성될 수 있고, 완전히 투명하거나 반투명하게 제작될 수 있다. 일 실시예에서, 투명 부재는 XR 표시 장치를 착용한 사용 자의 우안에 대면하는 제1 투명 부재 및 사용자의 좌안에 대면하는 제2 투명 부재를 포함할 수 있다. 디스플레 이가 투명인 경우, 사용자의 눈과 대면하는 위치에 배치되어 화면을 표시할 수 있다. 웨이브가이드는 디스플레이의 광원에서 생성된 빛을 사용자의 눈으로 전달할 수 있다. 예를 들어, 웨이브가이드 는 투명 부재의 일부에 적어도 부분적으로 위치할 수 있다. 일 실시예에 따르면, 디스플레이에서 방출된 광은 웨이브가이드의 일단으로 입사될 수 있고, 입사된 광이 웨이브가이드(waveguide) 내에서 내부 전반사를 통해 사 용자 눈으로 전달될 수 있다. 웨이브가이드는 유리, 플라스틱, 또는 폴리머등 투명한 소재로 제작될 수 있으며, 내부 또는 외부의 일 표면에 형성된 나노 패턴, 예를 들어, 다각형 또는 곡면 형상의 격자 구조(grating structure)를 포함할 수 있다. 일 실시예에서, 입광된 광은 나노 패턴에 의해 웨이브가이드 내부에서 전파 또는 반사되어 사용자의 눈으로 제공될 수 있다. 일 실시예에서, 웨이브가이드(waveguide)는 적어도 하나의 회절요소 (예를 들어, DOE(diffractive optical element), HOE(holographic optical element)) 또는 반사요소(예를 들어, 거울) 중 적어도 하나를 포함할 수 있다. 일 실시예에서, 웨이브가이드는 적어도 하나의 회절요소 또는 반사요소를 이용하여 광원부로부터 방출된 디스플레이 광을 사용자의 눈으로 유도할 수 있다. 일 실시예에서, 디스플레이는 디스플레이 패널 또는 렌즈(예를 들어, 글라스)를 포함할 수 있다. 예를 들어, 디 스플레이 패널은 유리 또는 플라스틱과 같은 투명한 재질을 포함할 수 있다. 일 실시예에서, 디스플레이는 투명소자로 구성될 수 있고, 사용자가 디스플레이를 투과하여, 디스플레이 후면의 실제 공간을 인지할 수도 있다. 디스플레이는 사용자에게 실제 공간의 적어도 일부에 가상 객체가 덧붙여진 것으로 보여지도록 투명 소자의 적 어도 일부 영역에 가상 객체를 표시할 수 있다. 일 실시예에서, 지지부는 XR 표시 장치의 각 구성요소에 전기적 신호를 전달하기 위한 인쇄 회로 기판 (printed circuit board, PCB), 오디오 신호를 출력하기 위한 스피커, 또는 전력을 공급하기 위한 배터리를 포 함할 수 있다. 예를 들어, 안경 타입의 XR 표시 장치에서, 지지부는 안경 다리부에 배치될 수 있다. 스피 커는 사용자의 좌측 귀에 오디오 신호를 전달하기 위한 제1 스피커 및 사용자의 우측 귀에 오디오 신호를 전달 하기 위한 제2 스피커를 포함할 수 있다. 일 실시예에서, 네트워크는, XR 표시 장치를 컴퓨팅 플랫폼과 통신 가능하도록 (communicatively) 결합할 수 있는 다양한 무선 통신 네트워크들(예를 들어, WLAN, WAN, PAN, 셀룰러 (cellular), WMN, WiMAX, GAN, 6LowPAN 등) 중 하나 이상을 포함할 수 있다. 일 실시예에서, 컴퓨팅 플랫폼은, 예를 들어, 독립형 호스트 컴퓨팅 시스템, XR 표시 장치와 통합된 온보드(on-board) 컴퓨터 시스템, 모바일 장치, 또는 XR 표시 장치에 확장 현실 콘텐트를 제공할 수 있는 다양한 하드웨어 플랫폼을 포함할 수 있다. 예를 들어, 컴퓨팅 플랫폼은, XR 표시 장치 상에서 실행 되는 XR 애플리케이션 또는 경험(experience)을 호스팅(hosting) 및 서비스하는 데 적합한 클라우드 기반 컴퓨 팅 아키텍처(하나 이상의 서버들 및 데이터 저장소들(data stores)을 포함함)를 포함할 수 있다. 예 를 들어, 컴퓨팅 플랫폼은 서비스로서의 플랫폼(Platform as a Service, PaaS) 아키텍처, 서비스로서의 소 프트웨어(Software as a Service, SaaS) 아키텍처, 및 서비스로서의 인프라(Infrastructure as a Service, IaaS), 또는 기타 유사한 클라우드 기반 컴퓨팅 아키텍처를 포함할 수 있다. XR 표시 장치가, 고글, 안경, 및 바이저 등과 같은, 경량의 장치들을 포함하는 실시예에서, XR 표시 장치 는, 작은 아키텍처 면적(architectural area)으로 인해, 전력 관리 능력(예를 들어, 배터리, 배터리 크기) 및 열 관리 능력(예를 들어, 냉각팬, 히트 싱크(heat sinks) 여부)이 저하된 전자 장치들을 포함할 수 있다. 도 2는 본 개시의 일 실시예에 따른 이미지, 및 깊이 데이터 및 포즈(pose) 데이터의 업데이트에 기반하여 깊이 맵을 선택적으로 재투사하는 방법의 작업흐름도이다. 일 실시예에서, 방법은, 예를 들어, 전술한 도 1의 XR 표시 장치 및 컴퓨팅 플랫폼에 대응될 수 있고 이들에 의해 수행될 수 있다. 단계 202에서, 컴퓨팅 플랫폼은, 컴퓨팅 플랫폼 또는 XR 표시 장치에 의해 렌더링되고 있는 2D 또는 3D 이미지에 대한 업데이트된 적색(R), 청색(B), 녹색(G) 색상 값 및 깊이(D) 값을 액세스할 수 있다. 예 를 들어, 컴퓨팅 플랫폼은, 하나 이상의 마지막으로 알려진 머리 포즈에 기반하여, RGB 이미지 데이터, 또 는 RGBD 이미지 및 깊이 데이터 모두를 렌더링할 수 있다. 단계 204에서, 컴퓨팅 플랫폼은 RGB 이미지 데이터가 변경되었는지 여부를 결정할 수 있다. 예를 들어, 머 리 포즈는 XR 표시 장치 등에 의해 트리거(trigger)되지 않는 한 업데이트되지 않을 수 있으므로, 컴퓨팅 플랫폼은 RGB 이미지 데이터의 변화를 검출할 수 있다. 일 실시예에서, RGB 이미지 데이터의 하나 이상의 변화들을 결정함에 응답하여, 컴퓨팅 플랫폼은 RGB 이미 지 데이터, 또는 RGBD 이미지 및 깊이 데이터 업데이트들을 XR 표시 장치에 제공하고, XR 표시 장치 는 컴퓨팅 플랫폼이 제공할 RGB 이미지 데이터, 또는 RGBD 이미지 및 깊이 데이터를 가지고 있는지 여부에 대해 지속적으로 또는 주기적으로 모니터링할 수 있다(예를 들어, 단계 224 참조). 예를 들어, XR 표시 장치 는, XR 표시 장치에 의해 후속적으로 렌더링될 RGB 이미지 데이터, 또는 RGBD 이미지 및 깊이 데이터 업데이트들이 있는지 여부를 결정하기 위해, 지속적인 또는 주기적인 체크(check)를 수행할 수 있다. 일 실시예에서, RGB 이미지 데이터, 또는 RGBD 이미지 및 깊이 데이터 업데이트가 있는 경우, 하나 이상의 현재 이미지 프레임은, XR 표시 장치에 의해 (예를 들어, 네트워크를 통해) 컴퓨팅 플랫폼으로부터 요청될 수도 있고(예를 들어, 단계 224에서 단계 206으로), 또는 컴퓨팅 플랫폼에 의해 (예를 들어, 네트 워크를 통해) XR 표시 장치로 자동으로 전송될 수도 있다(예를 들어, 단계 204에서 단계 206으로). 일 실시예에서, XR 표시 장치는 요청과 함께 최신의 머리 포즈 데이터를 컴퓨팅 플랫폼에 제공할 수 도 있다. 한편, RGB 이미지 데이터, 또는 RGBD 이미지 및 깊이 데이터 업데이트들이 없는 경우, XR 표시 장치는, 예 를 들어, 컴퓨팅 플랫폼으로부터 RGB 이미지 데이터, 또는 RGBD 이미지 및 깊이 데이터 업데이트들을 다시 요청하기 전에 개발자-결정(developer-determined) 또는 사용자-결정(user-determined) 시간(예를 들어, 5ms(milliseconds), 10ms, 12ms, 16ms, 20ms 등) 동안 일시 정지(pause)될 수 있다. 단계 208에서, XR 표시 장치는 적절한 포즈 범위를 계산할 수 있다. 일 실시예에서, XR 표시 장치는, 이전에 렌더링된 이미지 프레임을 XR 표시 장치 상에 재렌더링(re-rendering)하기에 적합하다고 (예를 들 어, 하나 이상의 개발자-결정 또는 사용자-결정 이미지 품질 선호도(preference) 또는 메트릭(metric)에 기반하 여) 결정될 수 있는, 신체 모션(예를 들어, 머리 모션, 제스처 모션 등)의 범위를 계산할 수 있다. 예를 들어, XR 표시 장치는, 하나 이상의 이전에 렌더링된 이미지 프레임들을 재렌더링하기 위한 적절한 포즈 범위를, 이미지 품질을 지원할 수 있는 머리 포즈 평행이동(translation) 및 회전(rotation)의 양에 기반하여 계산할 수 있다. 일 실시예에서, 적절한 포즈 범위는 아래의 수학식 1로 표현될 수 있다. 수학식 1"}
{"patent_id": "10-2021-0029661", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "이후, 단계 210, 212, 214, 및 216에서, XR 표시 장치는 하나 이상의 이미지 또는 깊이 특성들에 기반하여 하나 이상의 이미지 품질 기준(criteria)을 수행할 수 있다. 일 실시예에서, 하나 이상의 이미지 또는 깊이 특 성들은, 예를 들어, 이미지 콘텐트 범위(단계 210 참조), 깊이 밀도(단계 212 참조), 이미지 콘텐트 깊이(단계 214 참조)(예를 들어, 근시야(near-field) 또는 원시야(far-field) 이미지 콘텐트 깊이), 또는 깊이 연속성(단 계 216 참조)을 포함할 수 있다. 일 실시예에서, 단계 210, 212, 214, 및 216에서 하나 이상의 이미지 또는 깊 이 특성에 기반한 이미지 품질 기준은, 단계 210, 212, 214, 및 216에서 이미지 또는 깊이 특성 중 어느 하나만 이 미리 결정된 임계 범위 내에 있는 경우, 단계 210, 212, 214, 및 216에서 이미지 또는 깊이 특성 모두가 미 리 결정된 임계 범위 내에 있는 경우, 또는 단계 210, 212, 214, 및 216에서 이미지 또는 깊이 특성들 중 대다 수(예를 들어, 4개 중 3개)가 미리 결정된 임계 범위 내에 있는 경우 만족될 수 있는, 개발자-결정 또는 사용자 -결정의 기준일 수 있다. 단계 210에서, XR 표시 장치는, 이미지 콘텐트 또는 깊이 콘텐트가 미리 결정된 임계 범위 내에 있는지 또 는 XR 표시 장치의 POV에 과도하게 가까운지 여부를 결정할 수 있다. 단계 212에서, XR 표시 장치는, 이미지 깊이 밀도 콘텐트가 미리 결정된 레벨 내에 있는지 여부(예를 들어, 충분한 깊이 값들이 존재하는지 여부)를 결정할 수 있다. 단계 214에서, XR 표시 장치는 근시야 깊이 콘텐트 또는 원시야 깊이 콘텐트가 미리 결정된 임계 범위 내 에 있는지 여부(예를 들어, 깊이 콘텐트가 근시야점(near-field point) 에서 원시야점(far-field point)까지의 총 깊이를 갖는지 여부)를 결정할 수 있다. 단계 216에서, XR 표시 장치는, 이미지 깊이 연속성이 미리 결정된 임계 범위 내에 있는지 여부를 결정(예 를 들어, 깊이점에서 깊이점으로의 변화가 미리 결정된 비(ratio)를 초과하는지 여부를 결정)할 수 있다. 예를 들어, XR 표시 장치는, 각각의 깊이점에 대해, 특정 깊이점과 N개의 주변 깊이점들 간의 깊이 차이를 각각 계산함으로써 깊이 연속성을 결정할 수 있고 평균 깊이점 변화가 1 또는 미리 결정된 임계 값을 초과하는지 여 부를 결정할 수 있다. 이후, 하나 이상의 이미지 품질 기준을 만족시킴에 기반하여, 방법은 단계 217로 진행될 수 있다. 단계 217에서, XR 표시 장치는, 이전에 렌더링된 이미지 프레임을 재투사(re-project) 및 표시(display)하고, 단계 206 또는 단계 224에서 프로세스를 다시 재개할 수 있다. 일 실시예에서, 하나 이상의 이미지 품질 기준을 만족시키지 못함에 기반하여, 방법은, 단계 218로 진행될 수 있다. XR 표시 장치는, 단계 218에서, 현재 이미지 프레임과 연관된 업데이트된 머리 포즈(head pose) 를 계산하고, 단계 220에서, 업데이트된 머리 포즈가 계산된 포즈 범위 내에 있는지 여부를 결정할 수 있다. 예 를 들어, XR 표시 장치는, 계산된 포즈 범위에 대한 곱(product): range(rotation r, translation t)*(tolerance) 에 기반하여, 업데이트된 머리 포즈가 계산된 포즈 범위 내에 있는지 여부를 결정할 수 있다. 일 실시예에서, 단계 220에서 업데이트된 머리 포즈가 계산된 포즈 범위 내에 있다고 결정함에 응답하여, 단계 222에서, XR 표시 장치는 이전 이미지 프레임을 재투사 및 표시(예를 들어, 재렌더링)하고, 단계 224에서, XR 표시 장치는 컴퓨팅 플랫폼이 제공할 RGB 이미지 데이터, 또는 RGBD 이미지 및 깊이 데이터 업데 이트들을 갖는지 여부에 대해 지속적으로 또는 주기적으로 모니터링할 수 있다. 일 실시예에서, XR 표시 장치는, 예를 들어, 하나 이상의 스프린트 애니메이션(sprint animation)이 존재 하는지 여부를 결정할 수 있고 이에 기반하여 이전 이미지 프레임을 재투사 및 표시할지 또는 현재 이미지 프레 임을 렌더링할지 여부를 더 결정할 수 있다. 일 실시예에서, XR 표시 장치가 컴퓨팅 플랫폼으로부터 제공될 또는 요청될 RGB 이미지 데이터, 또는 RGBD 이미지 및 깊이 데이터 업데이트들이 현재 존재하지 않는다 고 결정하는 경우, 단계 226에서, XR 표시 장치는, 업데이트된 머리 포즈를 액세스하고(예를 들어, 사용자 가 하나 이상의 신체 모션들을 취하는지 여부에 기반하여), 업데이트된 머리 포즈를 계산된 포즈 범위와 계속해 서 비교하고(예를 들어, 단계 220 참조), 업데이트된 머리 포즈가 계산된 머리 포즈 범위 내에서 유지되는 동안 이전 이미지 프레임을 재투사 및 표시할 수 있다(예를 들어, 단계 222 참조). 일 실시예에서, XR 표시 장치 는 또한, XR 표시 장치가 언제 컴퓨팅 플랫폼으로부터 현재 프레임 업데이트들을 요청할 것인지 에 대한 하나 이상의 시간 한계(time limit) 또는 이미지 프레임 한계(image frame limit)를 정의할 수 있다. 단계 220에서, 업데이트된 머리 포즈가 계산된 포즈 범위 내에 있지 않다고 결정함에 응답하여, XR 표시 장치 는, 단계 228에서, 업데이트된 머리 포즈에 대응하는 하나 이상의 앵커(anchor)들이 XR 표시 장치에 저장되어 있는지 여부를 결정할 수 있다. 일 실시예에서, XR 표시 장치는 시간에 따라 여러 앵커들을 저장 할 수 있으며, 앵커들 각각은, 예를 들어, 연관된 이미지 및 깊이 데이터세트(dataset)와 함께 저장된 특정 포 즈를 포함하는, 데이터 요소(data element), 객체 인스턴스(object instance), 또는 경계 박스(bounding box) 를 포함할 수 있다. 일 실시예에서, XR 표시 장치는 업데이트된 머리 포즈에 대응하는 하나 이상의 앵커가 XR 표시 장치에 저장되어 있는지 여부를 결정할 수 있으며, 현재 이미지 프레임 내의 특정 위치의 이미지 콘텐트 또는 깊이 콘텐트는 하나 이상의 저장된 앵커에 기반하여 업데이트될 수 있다. 예를 들어, 하나 이상의 저장된 앵커들은, 컴퓨팅 플랫폼으로부터 RGB 이미지 데이터, 또는 RGBD 이미지 및 깊이 데이터 업데이트 를 요청하지 않고도, 사용자가 보다 큰 범위의 신체 모션(예를 들어, 머리 모션, 제스처 모션)을 갖도록 할 수 있다. 단계 230에서, XR 표시 장치는, 업데이트된 머리 포즈에 대응하는 하나 이상의 앵커가 XR 표시 장치 에 저장되어 있다고 결정함에 응답하여, 하나 이상의 앵커들에 대응하는 이미지 데이터 또는 깊이 데이터를 액 세스할 수 있다. 일 실시예에서, XR 표시 장치는, 새롭게 업데이트된 포즈가 하나 이상의 앵커에 대응하는 업데이트된 포즈 범위 내에 있는지 여부를 결정할 수 있다. 이후, XR 표시 장치는, 업데이트된 머리 포즈 가 업데이트된 포즈 범위 내에 있다고 결정하는 경우, 업데이트된 이미지 프레임을 XR 표시 장치의 하나 이상의 디스플레이 상에 렌더링할 수 있다. 일 실시예에서, XR 표시 장치에 저장된 앵커들은 어떤 특정한 머리 포즈 범위로 제한되는 것은 아니다. 예를 들어, 하나 이상의 앵커 또는 하나 이상의 앵커 세트는, 각각이 대응되는 머리 포즈 범위와 연관된 하나 이상의 업데이트된 머리 포즈를 설정하는 것에 이용될 수 있다. 일 실 시예에서, 하나 이상의 앵커에 기반한 현재 이미지 프레임 업데이트 시, 사용된 앵커들은 폐기될 수 있다. 한편, 업데이트된 머리 포즈에 대응하는 하나 이상의 앵커가 XR 표시 장치에 저장되어 있지 않다고 결정함 에 응답하여, 방법은 단계 206에서 재 시작될 수 있다. 이 때, 하나 이상의 현재 이미지 프레임이, XR 표 시 장치에 의해 컴퓨팅 플랫폼으로부터 (예를 들어, 네트워크를 통해) 요청되거나(예를 들어, 단계 224에서 단계 206으로), 컴퓨팅 플랫폼에 의해 XR 표시 장치로 자동적으로 (예를 들어, 네트워 크를 통해) 전송될 수 있다(예를 들어, 단계 204에서 단계 206으로). 따라서, 본 개시의 일 실시예에 따르면, XR 표시 장치와 컴퓨팅 플랫폼 간의 네트워크 트래픽을 감소 시키기 위해, 그리고, 더 나아가, XR 표시 장치의 전력 소모 및 열 출력을 감소시키기 위해, XR 표시 장치 는, 현재 이미지 프레임과 연관된 포즈가 적절한 포즈 범위 내에 있는지 여부에 기반하여, XR 표시 장치 의 하나 이상의 디스플레이들 상에 현재 이미지 프레임을 렌더링하지 않고 대신에 이전 이미지 프레임을 재렌더링할 수 있다. 일 실시예에서, XR 표시 장치는, 현재 이미지 프레임과 연관된 포즈가 적절한 포즈 범위 내에 있지 않은 경우에도, 현재 이미지 프레임과 연관된 포즈에 대응되는 하나 이상의 저장된 앵커들에 대 응하는, 이미지 데이터 또는 깊이 데이터를 액세스하고 이에 기반하여 현재 이미지 프레임 및 적절한 포즈 범위 를 조정할 수 있다. 본 개시의 일 실시예에 따르면, XR 표시 장치는 하나 이상의 디스플레이들에 의해 이미 표시되고 있던 2D 또는 3D 이미지를 계속해서 재렌더링(또는 재투사)하거나 또는 저장된 앵커들에 기반하여 표시될 현재 이미지프레임을 조정할 수 있다. 이에 따라, XR 표시 장치는, 이미 표시되고 있거나 또는 다음으로 표시될 2D 또 는 3D 이미지들과 동일 또는 거의 동일한 이미지 콘텐트 또는 깊이 콘텐트를 포함할 이미지 데이터 또는 깊이 데이터 갱신 업데이트의 제공을 위해, 컴퓨팅 플랫폼에 불필요하게 의존하지 않을 수 있다. 따라서, 본 개 시에 따르면, XR 표시 장치가 전력 관리 능력(예를 들어, 배터리, 배터리 크기) 및 열 관리 능력(예를 들 어, 냉각팬, 히트 싱크(heat sinks) 여부)이 저하된 전자 장치들을 포함하는 경우라 하더라도, XR 표시 장치 는 전력 소모 및 열 출력을 감소시키면서 사용자들에게 요구되는 수준의 XR 경험을 제공할 수 있다. 도 3은 본 개시의 일 실시예에 따른 이미지, 및 깊이 데이터 및 포즈 데이터의 업데이트에 기반하여 깊이맵을 선택적으로 재투사하는 방법의 흐름도이다. 일 실시예에서, 방법은, 하드웨어(예를 들어, 범용 프로세서, GPU(graphic processing unit), ASIC(application-specific integrated circuit), SoC(system-on-chip), 마이크로컨트롤러, FPGA(field- programmable gate array), 중앙 처리 장치(central processing unit, CPU), 애플리케이션 프로세서 (application processor, AP), 비주얼 처리 장치(visual processing unit, VPU), 신경망 처리 장치(neural processing unit, NPU), NDP(neural decision processor), 또는 2D 및 3D 이미지 데이터를 처리하는 것에 적합 한 다양한 처리 장치), 소프트웨어(예를 들어, 하나 이상의 프로세서에서 실행되는 명령어들(instructions)), 펌웨어(예를 들어, 마이크로코드(microcode)), 또는 이들의 다양한 조합을 포함하는 하나 이상의 처리 장치(예 를 들어, XR 표시 장치)를 이용하여 수행될 수 있다. 단계 302에서, 하나 이상의 처리 장치(예를 들어, XR 표시 장치)는, XR 표시 장치와 연관된 외부 전자 장 치로부터 수신된 현재 이미지 프레임을 렌더링할 수 있다. 일 실시예에서, 현재 이미지 프레임은 XR 표시 장치 의 현재 포즈와 연관될 수 있다. 단계 304에서, 하나 이상의 처리 장치(예를 들어, XR 표시 장치)는, 외부 전자 장치로부터 업데이트된 이미지 프레임을 수신할 수 있다. 단계 306에서, 하나 이상의 처리 장치(예를 들어, XR 표시 장치)는, 업데이트된 이미지 프레임의 하나 이상의 이미지 또는 깊이 특성들에 기반하여, 업데이트된 포즈를 계산할 수 있다. 단계 308에서, 하나 이상의 처리 장치(예를 들어, XR 표시 장치)는, 업데이트된 포즈가 현재 이미지 프레임과 연관된 현재 포즈에 대한 포즈 범위 내에 있는지 여부를 결정할 수 있 다. 예를 들어, 업데이트된 포즈가 현재 포즈에 대한 포즈 범위 내에 있는지 여부를 결정하기 전에, XR 표시 장 치는 현재 포즈에 대한 적절한 포즈 범위를 계산할 수 있으며, 적절한 포즈 범위는 목표 이미지 품질에 기반하 여 결정될 수 있다. 이후, 단계 310에서, 하나 이상의 처리 장치(예를 들어, XR 표시 장치)는, 업데이트된 포즈가 포즈 범위 내에 있는지 여부에 기반하여, 현재 이미지 프레임을 XR 표시 장치의 하나 이상의 디스플레이 들 상에 재렌더링(re-rendering)할 수 있다. 이와 같이, 본 개시의 일 실시예에 따르면, 이미 표시되고 있던 이미지를 계속해서 재렌더링(또는 재투사)하거 나, 저장된 앵커들에 기반하여 표시될 현재 이미지 프레임을 조정함으로써, 전력 소비의 중요한 부분을 차지하 는 무선 데이터 전송의 네트워크 트래픽을 줄일 수 있고, 나아가 XR 표시 장치에서 소비되는 전력을 줄일 수 있다. 또한, 다음에 표시할 이미지가 이미 표시되고 있는 이미지 또는 XR 표시 장치에 기 저장된 이미지와 동일 범위에 있는 경우, 외부 전자 장치(컴퓨팅 플랫폼)에 갱신된 데이터의 제공을 요청하지 않 음으로써, 갱신된 데이터의 획득을 위해 외부 전자 장치(컴퓨팅 플랫폼)에 불필요하게 의존하지 않을 수 있고, XR 표시 장치와 외부 전자 장치(컴퓨팅 플랫폼) 간의 네트워크 트래픽을 감소시킬 수 있 다. 예를 들어, 깊이 맵의 밀도, 장면의 복잡성 및 HMD의 동작 범위에 따라 기존 RGB 및 깊이 데이터를 재사용하여 새로운 이미지 프레임을 재투사 할 수 있다. 따라서, 외부 전자 장치 컴퓨팅 플랫폼) 또는 클라우드 서버 로부터의 이미지 업데이트 없이도 연속적인 이미지 투사가 가능하다. 일 실시예에서, 특정 머리 포즈와, 연관된 이미지 및 깊이 데이터 세트에 대한 앵커가 XR 표시 장치에 저장될 수 있다. 이에 따라, XR 표시 장치 를 착용한 사용자는, 더 넓은 범위에서 움직여도, 끊김 없는 XR 서비스를 제공받을 수 있고, 무선 통신 유 닛에서의 전력 소비를 줄일 수 있다. 도 4는 본 개시의 일 실시예에 따른 컴퓨터 시스템을 도시하는 도면이다. 일 실시예에서, 컴퓨터 시스템은, 캡쳐된 이미지 프레임들의 실시간 또는 준-실시간(near real-time) 지능 -기반 편집(intelligence-based editing) 및 큐레이팅(curating)을 수행하는 데 이용될 수 있다. 일 실시예에 서, 하나 이상의 컴퓨터 시스템은 본 개시의 다양한 방법들의 하나 이상의 단계(step)를 수행할 수 있다. 일 실시예에서, 컴퓨터 시스템은 본 개시의 다양한 기능(functionality)을 제공할 수 있다. 일 실시예에서, 컴퓨터 시스템에서 실행되는 소프트웨어는 본 개시의 다양한 방법들의 하나 이상의 단계를 수행하거나, 본 개시의 다양한 기능을 제공할 수 있다. 예를 들어, 컴퓨터 시스템은 하나 이상의 부분 (portion)을 포함할 수 있다. 본 개시에서, '컴퓨터 시스템'은 컴퓨팅 장치(computing device)를 포함할 수 있고, '컴퓨팅 장치'는 컴퓨터 시스템을 포함할 수 있다. 또한, 컴퓨터 시스템은 하나 이상의 컴 퓨터 시스템을 포함할 수 있다. 본 개시의 일 실시예에서, 컴퓨터 시스템의 개수는 한정되지 않는다. 본 개시에서, 컴퓨터 시스템은 다양한 물리적 형태를 취할 수 있다. 일 실시예에서, 컴퓨터 시스템은, 내장형(embedded) 컴퓨터 시스템, 시스템-온-칩(SoC), 단일-보드 컴퓨터 시스템(single-board computer system, SBC)(예를 들어, 컴퓨터-온-모듈 (computer-on-module, COM) 또는 시스템-온-모듈(system-on-module, SOM)), 데스크탑 컴퓨터 시스템, 랩탑 또 는 노트북 컴퓨터 시스템, 대화형 키오스크(interactive kiosk), 메인프레임(mainframe), 컴퓨터 시스템들의 메 쉬(mesh), 모바일 전화, 개인 휴대 정보 단말기(personal digital assistant, PDA), 서버, 태블릿 컴퓨터 시스 템, 증강/가상 현실 장치, 또는 이들의 조합일 수 있다. 일 실시예에서, 컴퓨터 시스템은 하나 이상의 컴 퓨터 시스템을 포함하거나, 단일형(unitary) 또는 분산형(distributed)이거나, 다수의 장소들에 걸쳐 있거나, 다수의 머신들(machines)에 걸쳐 있거나, 다수의 데이터 센터들에 걸쳐 있거나, 또는 하나 이상의 네트워크에서 하나 이상의 클라우드 구성요소를 포함하는 클라우드에 상주할 수 있다. 일 실시예에서, 하나 이상의 컴퓨터 시스템은, 실질적인 공간적 또는 시간적 제한 없이, 본 개시의 다양한 방법들의 하나 이상의 단계를 수행할 수 있다. 예를 들어, 컴퓨터 시스템은, 실시간으로 또는 배치 모드 (batch mode)로, 본 개시의 다양한 방법들의 하나 이상의 단계를 수행할 수 있다. 하나 이상의 컴퓨터 시스템 은, 예를 들어, 상이한 시간들에 또는 상이한 장소들에서, 본 개시의 다양한 방법들의 하나 이상의 단계를 수행할 수 있다. 도 4를 참조하면, 일 실시예에서, 컴퓨터 시스템은 프로세서, 메모리, 저장부(storage), 입/출력(input/output, I/O) 인터페이스, 통신 인터페이스, 및 버스를 포함할 수 있다. 본 개 시에서는 특정 배치를 갖는 특정한 수의 구성요소들을 포함하는 컴퓨터 시스템을 예시적으로 설명하고 있 지만, 본 개시의 일 실시예에 따른 컴퓨터 시스템은 다양한 배치를 갖는 다양한 수의 구성요소들을 포함할 수 있다. 일 실시예에서, 프로세서는 컴퓨터 프로그램을 구성하는 등의 명령어들(instructions)을 실행하기 위한 하 드웨어를 포함할 수 있다. 예를 들어, 명령어들을 실행하기 위해, 프로세서는 내부 레지스터(internal register), 내부 캐시(internal cache), 메모리, 또는 저장부로부터 명령어들을 검색(또는 페치 (fetch))하고, 명령어들을 디코딩 및 실행하고, 하나 이상의 결과를 내부 레지스터, 내부 캐시, 메모리, 또는 저장부에 기입할(write) 수 있다. 일 실시예에서, 프로세서는 데이터, 명령어들, 또는 어드레스 들(addresses)을 위한 하나 이상의 내부 캐시를 포함할 수 있다. 본 개시의 일 실시예에서, 프로세서는 다 양한 수의 다양한 내부 캐시들을 포함할 수 있다. 예를 들어, 프로세서는 하나 이상의 명령어 캐시, 하나 이상의 데이터 캐시, 및 하나 이상의 변환 색인 버퍼(translation lookaside buffer, TLB)를 포함할 수 있다. 명령어 캐시 내의 명령어들은 메모리 또는 저장부 내의 명령어들의 복사본일 수 있고, 명령어 캐시는 프로세서의 명령어 검색(retrieval) 속도를 높일 수 있다. 데이터 캐시(data cache) 내의 데이터는 프로세서에서 실행되는 명령어들이 작용할 메모리 또는 저장 부 내의 데이터의 복사본, 프로세서에서 실행되는 후속 명령어들의 액세스를 위한 또는 메모리 또는 저장부에 기입하기 위한 프로세서에서 실행된 이전 명령어들의 결과, 또는 기타 적절한 데이터 일 수 있다. 데이터 캐시는 프로세서에 의한 독출(read) 또는 기입(write) 동작들의 속도를 높일 수 있다. TLB들은 프로세서에 대한 가상 어드레스 변환(virtual-address translation)의 속도를 높일 수 있다. 일 실시예에서, 프로세서는 데이터, 명령어들, 또는 어드레스들을 위한 하나 이상의 내부 레지스터(registe r)를 포함할 수 있다. 본 개시의 일 실시예에서, 프로세서는 다양한 수의 다양한 내부 레지스터를 포함할 수 있다. 일 실시예에서, 프로세서는 하나 이상의 산술 논리 장치(arithmetic logic unit, ALU)를 포함하 거나, 다중-코어(multi-core) 프로세서이거나, 또는 하나 이상의 프로세서를 포함할 수 있다. 한편, 본 개시의 일 실시예에 따른 프로세서는 전술한 실시예들에 제한되지 않는다. 일 실시예에서, 메모리는 프로세서가 실행할 명령어들 또는 프로세서가 작용할 데이터를 저장하 는 메인 메모리를 포함할 수 있다. 예를 들어, 컴퓨터 시스템은 저장부 또는 다른 소스(예를 들어, 다른 컴퓨터 시스템)로부터 메모리로 명령어들을 로딩할 수 있다. 이후, 프로세서는 메모리로부 터 내부 레지스터 또는 내부 캐시로 명령어들을 로딩할 수 있다. 명령어들을 실행하기 위해, 프로세서는내부 레지스터 또는 내부 캐시로부터 명령어들을 검색하고 이들을 디코딩할 수 있다. 명령어들의 실행 중 또는 실행 후에, 프로세서는 하나 이상의 결과(중간 또는 최종 결과일 수 있음)를 내부 레지스터 또는 내부 캐 시에 기입(write)할 수 있다. 이후, 프로세서는 결과들 중 하나 이상을 메모리에 기입할 수 있다. 일 실시예에서, 프로세서는 하나 이상의 내부 레지스터 또는 내부 캐시 내의 명령어들 또는 메모리(저장 부가 아닌) 내의 명령어들만 실행하고, 하나 이상의 내부 레지스터 또는 내부 캐시 내의 데이터 또는 메모 리(저장부가 아닌) 내의 데이터에만 작용할 수 있다. 도 4를 참조하면, 하나 이상의 메모리 버스(각각의 메모리 버스는 어드레스 버스 및 데이터 버스를 포함할 수 있다)는 프로세서를 메모리에 결합할 수 있다. 버스는, 후술하는 바와 같이, 하나 이상의 메모 리 버스를 포함할 수 있다. 일 실시예에서, 하나 이상의 메모리 관리 장치(memory management unit, MMU)는 프 로세서와 메모리 사이에 배치되어 프로세서에 의해 요청되는 메모리에 대한 액세스를 용이 하게 할 수 있다. 일 실시예에서, 메모리는 랜덤 액세스 메모리(random access memory, RAM)를 포함할 수 있다. RAM은, 예를 들어, 휘발성 메모리(volatile memory)일 수 있다. 일 실시예에서, RAM은 동적 RAM(dynamic RAM, DRAM) 또는 정적 RAM(static RAM, SRAM)일 수 있다. 또한, 예를 들어, RAM은 단일-포트(single-ported) 또는 다중-포트(multi-ported) RAM일 수 있다. 본 개시의 일 실시예에서, RAM은 다양한 형태로 구성될 수 있다. 메모리는, 예를 들어, 하나 이상의 메모리 장치를 포함할 수 있다. 한편, 본 개시의 일 실시예에 따른 메 모리는 전술한 실시예들에 제한되지 않는다. 일 실시예에서, 저장부는 데이터 또는 명령어들을 위한 대용량 저장소(mass storage)를 포함할 수 있다. 예를 들어, 저장부는 하드 디스크 드라이브(hard disk drive, HDD), 플로피 디스크 드라이브, 플래시 메모 리, 광디스크, 광자기(magneto-optical) 디스크, 자기 테이프, 범용 직렬 버스(Universal Serial Bus, USB) 드 라이브, 또는 이들의 조합을 포함할 수 있다. 저장부는, 예를 들어, 탈착식(removable) 또는 비탈착식 (non-removable)(또는 고정식(fixed)) 매체(media)를 포함할 수 있다. 저장부는, 예를 들어, 컴퓨터 시스 템의 내부 또는 외부에 있을 수 있다. 일 실시예에서, 저장부는 비휘발성(non-volatile), 고체상태 (solid-state) 메모리일 수 있다. 일 실시예에서, 저장부는 읽기 전용 메모리(read-only memory, ROM)를 포함할 수 있다. 예를 들어, ROM은 마스크-프로그램된(mask-programmed) ROM, 프로그램 가능 ROM(programmable ROM, PROM), 소거 가능 PROM(erasable PROM, EPROM), 전기적 소거 가능 PROM(electrically erasable PROM, EEPROM), 전기적 변경 가능 ROM(electrically alterable ROM, EAROM), 플래시 메모리, 또는 이들의 조합일 수 있다. 본 개시의 일 실시예에서, 대용량 저장부는 다양한 물리적 형태로 구성될 수 있다. 저장부는, 예를 들어, 프로세서와 저장부 간의 통신을 용이하게 하는 하나 이상의 저장부 제어 장치(storage control unit)를 포함할 수 있다. 일 실시예에서, 저장부는 하나 이상의 저장소를 포함할 수 있다. 한편, 본 개시의 일 실시예에 따른 저장부는 전술한 실시예들에 제한되지 않는다. 일 실시예에서, I/O 인터페이스는, 컴퓨터 시스템과 하나 이상의 I/O 장치들 간의 통신을 위한 하나 이상의 인터페이스를 제공하는, 하드웨어, 소프트웨어, 또는 두가지 모두를 포함할 수 있다. 컴퓨터 시스템 은, 예를 들어, 하나 이상의 I/O 장치를 포함할 수 있다. I/O 장치들 중 하나 이상은 사람과 컴퓨터 시스 템 간의 통신을 가능하도록 할 수 있다. 예를 들어, I/O 장치는 키보드, 키패드, 마이크(microphone), 모 니터, 마우스, 프린터, 스캐너, 스피커, 스틸 카메라(still camera), 스타일러스(stylus), 태블릿, 터치 스크린, 트랙볼(trackball), 비디오 카메라, 기타 적절한 I/O 장치, 또는 이들의 조합을 포함할 수 있다. I/O 장치는 하나 이상의 센서를 포함할 수 있다. 일 실시예에서, 컴퓨터 시스템은 다양한 I/O 장치들을 지원하 기 위한 다양한 I/O 인터페이스를 포함할 수 있다. 예를 들어, I/O 인터페이스는, 프로세서가 다양한 I/O 장치들 중 하나 이상을 구동할 수 있도록 하는, 하나 이상의 장치 또는 소프트웨어 드라이버를 포함 할 수 있다. 일 실시예에서, I/O 인터페이스는 하나 이상의 I/O 인터페이스를 포함할 수 있다. 한편, 본 개시의 일 실시예에 따른, I/O 인터페이스는 전술한 실시예들에 제한되지 않는다. 일 실시예에서, 통신 인터페이스는, 컴퓨터 시스템과 하나 이상의 다른 컴퓨터 시스템 또는 하나 이 상의 네트워크 간의 통신(예를 들어, 패킷-기반 통신)을 위한 하나 이상의 인터페이스를 제공하는, 하드웨어, 소프트웨어, 또는 두가지 모두를 포함할 수 있다. 일 실시예에서, 통신 인터페이스는 이더넷(Ethernet) 또 는 기타 유선-기반 네트워크와 통신하기 위한 네트워크 인터페이스 컨트롤러(network interface controller, NIC) 또는 네트워크 어댑터, 또는 WI-FI 네트워크와 같은 무선 네트워크와 통신하기 위한 무선 NIC(wireless NIC, WNIC) 또는 무선 어댑터를 포함할 수 있다. 본 개시의 일 실시예에 따른 컴퓨터 시스템은 다양한 네 트워크를 지원하기 위한 다양한 통신 인터페이스를 포함할 수 있다. 예를 들어, 컴퓨터 시스템은 애드혹(ad hoc) 네트워크, 개인 영역 네트워크(personal area network, PAN), 로컬 영역 네트워크(local area network, LAN), 광역 네트워크(wide area network, WAN), 대도시 영역 네트워크(metropolitan area network, MAN), 인터넷의 적어도 일부, 또는 이들의 조합과 통신할 수 있다. 다양 한 네트워크들의 적어도 일부는 유선 또는 무선일 수 있다. 예를 들어, 컴퓨터 시스템은 무선 PAN(wireless PAN, WPAN)(예를 들어, 블루투스 WPAN), WI-FI 네트워크, WI-MAX 네트워크, 셀룰러 전화 네트워 크(예를 들어, 이동 통신을 위한 글로벌 시스템(Global System for Mobile Communications, GSM) 네트워크), 기타 적절한 무선 네트워크, 또는 이들의 조합과 통신할 수 있다. 일 실시예에서, 컴퓨터 시스템은, 다양 한 네트워크들을 위한 다양한 통신 인터페이스를 포함할 수 있다. 일 실시예에서, 통신 인터페이스는 하나 이상의 통신 인터페이스를 포함할 수 있다. 한편, 본 개시의 일 실시예에 따른, 통신 인터페이스는 전술한 실시예들에 제한되지 않는다. 일 실시예에서, 버스는, 컴퓨터 시스템의 구성요소들을 서로 결합시키는, 하드웨어, 소프트웨어, 또 는 두가지 모두를 포함할 수 있다. 예를 들어, 버스는 AGP(Accelerated Graphics Port) 또는 기타 그래픽 버스, EISA(Enhanced Industry Standard Architecture) 버스, FSB(front-side bus), HYPERTRANSPORT(HT) 인터 커넥트(interconnect), ISA(Industry Standard Architecture) 버스, INFINIBAND 인터커넥트, LPC(low-pin- count) 버스, 메모리 버스, MCA(Micro Channel Architecture) 버스, PCI(Peripheral Component Interconnect) 버스, PCI-익스프레스(PCI-Express, PCIe) 버스, SATA(serial advanced technology attachment) 버스, VLB(Video Electronics Standards Association local) 버스, 기타 적절한 버스, 또는 이들의 조합을 포함할 수 있다. 일 실시예에서, 버스는 하나 이상의 버스를 포함할 수 있다. 한편, 본 개시의 일 실시예에 따른, 버 스 또는 인터커넥트는 전술한 실시예들에 제한되지 않는다. 도 5는 본 개시의 일 실시예에 따른 인공지능(artificial intelligence, AI) 구조(architecture)를 도시 하는 도면이다. 본 개시의 일 실시예에 따른, 인공지능 구조는, 데이터 공동클러스터링(co-clustering)을 위한 CI-GAN(co- informatic generative adversarial network)를 제공하는 것에 이용될 수 있다. 일 실시예에서, AI 구조 는, 예를 들어, 하드웨어(예를 들어, 범용 프로세서, 그래픽 처리 장치(GPU), ASIC(application-specific integrated circuit), SoC(system-on-chip), 마이크로컨트롤러, FPGA(field-programmable gate array), 중앙 처리 장치(CPU), 애플리케이션 프로세서(AP), 비주얼 처리 장치(VPU), NPU(neural processing unit), NDP(neural decision processor), 또는 다양한 데이터를 처리하고 이에 기반하여 하나 이상의 결정을 내리는 것 에 적합한 기타 처리 장치), 소프트웨어(예를 들어, 하나 이상의 처리 장치에서 실행되는 명령어들), 펌웨어(예 를 들어, 마이크로코드(microcode)), 또는 이들의 조합을 포함하는 하나 이상의 처리 장치를 이용하여 구현될 수 있다. 도 5를 참조하면, AI 구조는 기계 학습(machine leaning, ML) 알고리즘 및 함수, 자연 언어 처리 (natural language processing, NLP) 알고리즘 및 함수, 전문가 시스템, 컴퓨터-기반 비전 (vision) 알고리즘 및 함수, 음성 인식(speech recognition) 알고리즘 및 함수, 플래닝 (planning) 알고리즘 및 함수, 및 로봇공학 알고리즘 및 함수를 포함할 수 있다. 일 실시예에서, 기계 학습(ML) 알고리즘 및 함수는, 많은 양의 데이터(예를 들어, 사용자 클릭 데이터 또 는 기타 사용자 상호작용(interaction), 텍스트 데이터, 이미지 데이터, 비디오 데이터, 오디오 데이터, 음성 데이터, 수치 데이터 등의 \"빅 데이터(Big Data)\")에 걸쳐 패턴을 찾는 것에 적합한 다양한 통계-기반 알고리즘 을 포함할 수 있다. 예를 들어, 기계 학습(ML) 알고리즘 및 함수는 딥러닝(deep learning) 알고리즘, 지도 학습(supervised learning) 알고리즘, 및 비지도 학습(unsupervised learning) 알고리즘을 포 함할 수 있다. 일 실시예에서, 딥러닝 알고리즘은, 많은 양의 데이터로부터 심층적 수준의 표현(representations) 및 관 념(abstractions)을 학습하는 것에 이용될 수 있는 다양한 인공 신경망(artificial neural network, ANN)을 포 함할 수 있다. 예를 들어, 딥러닝 알고리즘은, MPL(multilayer perceptron), 오토인코더(autoencoder, AE), 컨볼루션 신경망(convolution neural network, CNN), 순환 신경망(recurrent neural network, RNN), LSTM(long short term memory), 게이트 순환 유닛(gated recurrent unit, GRU), RBM(restricted Boltzmann Machine), DBN(deep belief network), 양방향 순환 심층 신경망(bidirectional recurrent deep neural network, BRDNN), GAN(generative adversarial network), 심층 Q-네트워크, NADE(neural autoregressive distribution estimation), AN(adversarial network), AM(attentional model), 또는 심층 강화 학습(deep reinforcement learning) 등의 다양한 인공 신경망 알고리즘을 포함할 수 있다.일 실시예에서, 지도 학습 알고리즘은, 미래의 이벤트를 예측하기 위해 라벨링된(labeled) 예들을 이용하 여 과거에 학습된 것을 새로운 데이터에 적용하는 것에 이용될 수 있는 다양한 알고리즘을 포함할 수 있다. 예 를 들어, 지도 학습 알고리즘은, 알려진 훈련 데이터세트(training dataset)의 분석에서 시작하여 출력 값 에 대해 예측하기 위해 추론된 함수(inferred function)를 생성할 수 있다. 지도 학습 알고리즘은 예측된 출력을 정확한 의도된 출력(correct and intended output)과 비교하고, 지도 학습 알고리즘을 수정하기 위 해 오류(error)를 찾을 수 있다. 한편, 비지도 학습 알고리즘은, 예를 들어, 비지도 학습 알고리즘을 훈련시키는 것에 이용되는 데이터가 분류되거나(classified) 라벨링되지 않은 경우 적용될 수 있는 다양한 알고 리즘을 포함할 수 있다. 예를 들어, 비지도 학습 알고리즘은 라벨링되지 않은(unlabeled) 데이터로부터 숨 겨진 구조를 기술하기 위한 함수를 시스템들이 어떻게 추론할 수 있는지 연구 및 분석할 수 있다. 일 실시예에서, NLP 알고리즘 및 함수는, 음성 또는 텍스트 등의 자연 언어를 자동적으로 처리하는 데 적 합한 다양한 알고리즘 또는 함수를 포함할 수 있다. 예를 들어, NLP 알고리즘 및 함수는 콘텐트 추출 (content extraction) 알고리즘 및 함수, 분류(classification) 알고리즘 및 함수, 기계 번역 (machine translation) 알고리즘 및 함수, 질의 응답(question answering, QA) 알고리즘 및 함수, 및 텍스트 생성(text generation) 알고리즘 및 함수를 포함할 수 있다. 일 실시예에서, 콘텐트 추출 알고리즘 및 함수는, 다른 애플리케이션들에서 이용될 수 있도록 전자 문서들 (예를 들어, 웹페이지, 텍스트 편집기 문서 등)로부터 텍스트 또는 이미지를 추출하는 수단을 포함할 수 있다. 일 실시예에서, 분류 알고리즘 및 함수는, 지도 학습 모델(예를 들어, 로지스틱 회귀(logistic regression), 나이브 베이즈(naive Bayes), SGD(stochastic gradient descent), k-최근접 이웃법(k-nearest neighbors), 결정 트리법(decision trees), 랜덤 포레스트법(random forests), 서포트 벡터 머신(support vector machine, SVM) 등)을 이용하여 지도 학습 모델에 입력되는 데이터로부터 학습하고 이에 기반하여 새로운 관찰(observations)이나 분류를 수행할 수 있는, 다양한 알고리즘을 포함할 수 있다. 기계 번역 알고리즘 및 함수는, 하나의 언어로 된 소스 텍스트를 다른 언어의 텍스트로 자동적으로 변환하는 것에 적합한 다양한 알 고리즘 또는 함수를 포함할 수 있다. QA 알고리즘 및 함수는, 사람이 제기한 질문을, 예를 들어, 음성-제 어 개인 비서 장치(voice-controlled personal assistant device)에 의해 수행되는 것과 같이, 자연 언어로 자 동적으로 답변하는 것에 적합한 다양한 알고리즘 또는 함수를 포함할 수 있다. 텍스트 생성 알고리즘 및 함수는 자연 언어 텍스트를 자동적으로 생성하는 것에 적합한 다양한 알고리즘 또는 함수를 포함할 수 있다. 일 실시예에서, 전문가 시스템은, 특정 분야(예를 들어, 주식 거래, 의학, 스포츠 통계 등)에 전문 지식 및 경험을 가진 사람 또는 조직(organization)의 판단(judgment) 및 거동(behavior)을 시뮬레이션하는 것에 적 합한 다양한 알고리즘 또는 함수를 포함할 수 있다. 일 실시예에서, 컴퓨터-기반의 비전 알고리즘 및 함수는, 이미지들(예를 들어, 사진 이미지, 비디오 이미 지)로부터 정보를 자동적으로 추출하는 것에 적합한 다양한 알고리즘 또는 함수를 포함할 수 있다. 도 5를 참조 하면, 예를 들어, 컴퓨터-기반의 비전 알고리즘 및 함수는 이미지 인식(image recognition) 알고리즘 및 머신 비전(machine vision) 알고리즘을 포함할 수 있다. 이미지 인식 알고리즘은, 예를 들어, 하 나 이상의 이미지 프레임 또는 기타 디스플레이된 데이터에 포함될 수 있는, 객체, 장소, 사람 등을 자동적으로 식별 또는 분류하는 것에 적합한 다양한 알고리즘을 포함할 수 있다. 머신 비전 알고리즘은, 컴퓨터들이 이미지를 \"볼(see)\" 수 있도록, 예를 들어, 특수 광학계를 가진 카메라의 이미지 센서에 의존하여 이미지를 획 득할 수 있도록 하는 것에 적합한 다양한 알고리즘을 포함할 수 있다. 획득된 이미지는 의사 결정을 위해 처리, 분석되거나, 다양한 데이터 특성이 측정될 수 있다. 일 실시예에서, 음성 인식 알고리즘 및 함수는, 컴퓨터가 한 명 이상의 사용자와 음성으로 통신할 수 있도 록, 자동 음성 인식(automatic speech recognition, ASR), 컴퓨터 음성 인식, 음성-텍스트 변환(speech-to- text, STT), 또는 텍스트-음성 변환(text-to-speech, TTS) 등을 통해, 발화된 언어를 인식하고 텍스 트로 번역하는 것에 적합한 다양한 알고리즘 또는 함수를 포함할 수 있다. 일 실시예에서, 플래닝 알고리즘 및 함수는, 일련의 행위들(actions)을 생성하는 것에 적합한 다양한 알고 리즘 또는 함수를 포함할 수 있고, 각각의 행위는 해당 행위를 수행하기 전에 충족되어야 할 전제 조건 (precondition) 세트를 포함할 수 있다. AI 플래닝의 예시로는 전통적(classical) 플래닝, 다른 문제로의 감축 법, 시간적(temporal) 플래닝, 확률론적(probabilistic) 플래닝, 선호도-기반(preference-based)의 플래닝, 조 건부(conditional) 플래닝 등이 포함될 수 있다. 일 실시예에서, 로봇공학 알고리즘 및 함수는, 하나 이상의 장치로 하여금, 모션, 제스처, 수행 과제 (performance tasks), 의사 결정(decision-making), 감정 등을 통해 인간 거동을 복제하도록 하는 다양한 알고 리즘, 함수, 또는 시스템을 포함할 수 있다. 본 개시의 일 실시예는 컴퓨터에 의해 실행되는 프로그램 모듈과 같은 컴퓨터에 의해 실행 가능한 명령어를 포 함하는 기록 매체의 형태로도 구현될 수 있다. 컴퓨터 판독 가능 매체는, 예를 들어, 반도체-기반 또는 기타 집 적 회로(integrated circuit, IC)(예를 들어, FPGA(field-programmable gate arrays) 또는 ASIC(application- specific IC)), HDD(hard disk drive), HHD(hybrid hard drive), 광디스크, 광디스크 드라이브(optical disc drive, ODD), 광자기 디스크, 광자기 드라이브, 플로피 디스켓, 플로디 디스크 드라이브(floppy disk drive, FDD), 자기 테이프, SSD(solid-state drive), RAM-드라이브, SD(SECURE DIGITAL) 카드/드라이브, 기타 컴퓨터 판독 가능 저장 매체, 또는 이들의 조합을 포함할 수 있다. 컴퓨터 판독 가능 매체는 컴퓨터에 의해 액세스될 수 있는 임의의 가용 매체일 수 있고, 휘발성 및 비휘발성 매체, 분리형 및 비분리형 매체를 모두 포함할 수 있 다. 컴퓨터 판독 가능 매체는 컴퓨터 저장 매체 및 통신 매체를 포함할 수 있다. 컴퓨터 저장 매체는 컴퓨터 판독 가능 명령어, 데이터 구조, 프로그램 모듈 또는 기타 데이터와 같은 정보의 저장을 위한 임의의 방법 또는 기술 로 구현된 휘발성 및 비휘발성, 분리형 및 비분리형 매체를 모두 포함한다. 통신 매체는 전형적으로 컴퓨터 판 독 가능 명령어, 데이터 구조, 또는 프로그램 모듈과 같은 변조된 데이터 신호의 기타 데이터를 포함할 수 있다. 또한, 컴퓨터에 의해 읽을 수 있는 저장 매체는, 비일시적(non-transitory) 저장매체의 형태로 제공될 수 있다. 여기서, ‘비일시적 저장 매체'는 실재(tangible)하는 장치이고, 신호(signal)(예를 들어, 전자기파)를 포함하 지 않는다는 것을 의미할 뿐이며, 이 용어는 데이터가 저장매체에 반영구적으로 저장되는 경우와 임시적으로 저 장되는 경우를 구분하지 않는다. 예로, '비일시적 저장 매체'는 데이터가 임시적으로 저장되는 버퍼를 포함할 수 있다. 일 실시예에 따르면, 본 문서에 개시된 다양한 실시예들에 따른 방법은 컴퓨터 프로그램 제품(computer program product)에 포함되어 제공될 수 있다. 컴퓨터 프로그램 제품은 상품으로서 판매자 및 구매자 간에 거래될 수 있 다. 컴퓨터 프로그램 제품은 기기로 읽을 수 있는 저장 매체(예를 들어, compact disc read only memory (CD- ROM))의 형태로 배포되거나, 또는 어플리케이션 스토어(예를 들어, 플레이 스토어TM)를 통해 또는 두 개의 사용 자 장치들(예를 들어, 스마트폰들) 간에 직접, 온라인으로 배포(예를 들어, 다운로드 또는 업로드)될 수 있다. 온라인 배포의 경우에, 컴퓨터 프로그램 제품(예를 들어, 다운로더블 앱(downloadable app))의 적어도 일부는 제조사의 서버, 어플리케이션 스토어의 서버, 또는 중계 서버의 메모리와 같은 기기로 읽을 수 있는 저장 매체 에 적어도 일시 저장되거나, 임시적으로 생성될 수 있다. 본 개시 전체에서, 특별히 반대되는 기재가 없는 한 \"또는(or)\"은 포괄적(inclusive)이며 배타적(exclusive)이 지 않다. 따라서, 명백히 달리 표시되거나 문맥상 달리 표시되지 않는 한, \"A 또는 B\"는 \"A, B, 또는 둘 모두\" 를 나타낼 수 있다. 또한, 특별히 반대되는 기재가 없는 한 \"및(and)\"은 공동적(joint)이고 개별적(several)이 다. 따라서, 명백히 달리 표시되거나 문맥상 달리 표시되지 않는 한, \"A 및 B\"는 \"공동으로 또는 개별적으로, A 및 B\"를 나타낼 수 있다. 본 개시에서, 명백히 달리 표시되거나 문맥상 달리 표시되지 않는 한, \"자동으로(자동적으로)(automatically)\" 및 그 파생어들은 \"인간의 개입 없이\"를 나타낼 수 있다."}
{"patent_id": "10-2021-0029661", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "전술한 본 개시의 설명은 예시를 위한 것이며, 본 개시가 속하는 기술분야의 통상의 지식을 가진 자는 본 개시 의 기술적 사상이나 필수적인 특징을 변경하지 않고서 다른 구체적인 형태로 쉽게 변형이 가능하다는 것을 이해 할 수 있을 것이다. 그러므로 이상에서 기술한 실시예들은 모든 면에서 예시적인 것이며 한정적이 아닌 것으로 이해해야만 한다. 예를 들어, 단일형으로 설명되어 있는 각 구성요소는 분산되어 실시될 수도 있으며, 마찬가지 로 분산된 것으로 설명되어 있는 구성요소들도 결합된 형태로 실시될 수 있다. 본 개시의 범위는 상기 상세한 설명보다는 후술하는 특허청구범위에 의하여 나타내어질 수 있다. 본 개시의 하 나의 청구항 카테고리(claim category)에서(예를 들어, 방법 청구항에서) 언급된 다양한 특징(feature)들은 다 른 청구항 카테고리에서도(예를 들어, 시스템 청구항에서도) 청구될 수 있다. 또한, 본 개시의 일 실시예는 첨 부된 청구범위에 명시된 특징들의 조합뿐만 아니라 청구범위 내의 개별 특징들의 다양한 조합들 또한 포함될 수 있다. 본 개시의 범위는 특허청구범위의 의미 및 범위 그리고 그 균등 개념으로부터 도출되는 모든 변경 또는 변형된 형태가 본 개시의 범위에 포함되는 것으로 해석되어야 한다.도면 도면1 도면2 도면3 도면4 도면5"}
{"patent_id": "10-2021-0029661", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 개시의 일 실시예에 따른 확장 현실(extended reality, XR) 시스템을 도시하는 도면이다. 도 2는 본 개시의 일 실시예에 따른 이미지, 및 깊이 데이터 및 포즈(pose) 데이터의 업데이트에 기반하여 깊이 맵을 선택적으로 재투사하는 동작의 작업흐름도이다. 도 3은 본 개시의 일 실시예에 따른 이미지, 및 깊이 데이터 및 포즈 데이터의 업데이트에 기반하여 깊이맵을 선택적으로 재투사하는 방법의 흐름도이다. 도 4는 본 개시의 일 실시예에 따른 컴퓨터 시스템을 도시하는 도면이다. 도 5는 본 개시의 일 실시예에 따른 인공지능(artificial intelligence, AI) 구조를 도시하는 도면이다."}
