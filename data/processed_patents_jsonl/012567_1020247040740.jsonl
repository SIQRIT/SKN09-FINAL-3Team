{"patent_id": "10-2024-7040740", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2025-0004123", "출원번호": "10-2024-7040740", "발명의 명칭": "다단자 논리 게이트로 형성된 다층을 구비한 심층 신경망", "출원인": "멤컴퓨팅, 인크.", "발명자": "트라베르사 파비오 로렌조"}}
{"patent_id": "10-2024-7040740", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "신경망 회로(neural network circuit)에 있어서,복수의 층으로 배열되며, 복수의 입력 및 출력을 각각 구비하는 복수의 논리 게이트; 및인접한 층들의 각 쌍 사이에 배열된 복수의 논리 연결자로서, 상기 논리 연결자의 각각은 제1 논리 게이트의 출력과 제2 논리 게이트의 복수의 입력 중 하나와의 관계를 결정하며, 상기 논리 연결자의 각각은 복수의 서로 다른 논리 연결 상태 중 하나를 갖는 것인, 상기 복수의 논리 연결자를 포함하고,상기 신경망 회로는 상기 신경망 회로가 함수를 구현하도록 하기 위해, 상기 논리 연결자에 대한 상기 논리 연결자 상태의 세트를 찾음으로써 상기 함수를 구현하게끔 학습되도록 구성되는, 신경망 회로."}
{"patent_id": "10-2024-7040740", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 논리 연결자 상태는 상기 제1 논리 게이트의 출력이 NOT 게이트를 통해 상기 제2 논리 게이트의 입력에 연결되는 제1 상태 및 상기 제1 논리 게이트의 출력이 단락 회로를 통해 상기 제2 논리 게이트의입력에 연결되는 제2 상태를 포함하는, 신경망 회로."}
{"patent_id": "10-2024-7040740", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서, 상기 논리 연결자 상태는 상기 제1 논리 게이트의 출력이 개방 회로를 통해 상기 제2 논리 게이트의 입력에 연결되는 제3 상태를 더 포함하는, 신경망 회로."}
{"patent_id": "10-2024-7040740", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서, 상기 논리 게이트 및 상기 논리 연결자는 상보성 금속 산화물 반도체(CMOS) 기술로 구현되는,신경망 회로."}
{"patent_id": "10-2024-7040740", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서, 상기 신경망 회로는 단일 칩 상에 형성되는, 신경망 회로."}
{"patent_id": "10-2024-7040740", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서, 상기 논리 연결자의 각각은,입력;상기 입력에 연결된 단락 회로;상기 단락 회로와 병렬로 배열되고 상기 입력에 연결된 인버터;출력; 및상기 단락 회로 및 상기 인버터 중 하나를 상기 출력에 연결하도록 구성된 적어도 하나의 스위치를 포함하는,신경망 회로."}
{"patent_id": "10-2024-7040740", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6항에 있어서, 상기 논리 연결자의 각각은 추가로,상기 입력에 연결된 개방 회로를 포함하며,상기 적어도 하나의 스위치는 상기 단락 회로, 상기 인버터 및 상기 개방 회로 중 하나를 상기 출력에 연결하도록 구성되는, 신경망 회로.공개특허 10-2025-0004123-2-청구항 8 제6항에 있어서,상기 적어도 하나의 스위치는 직렬로 연결된 제1 스위치 및 제2 스위치를 포함하며,상기 제1 스위치는 상기 단락 회로 및 상기 인버터 중 하나에 전기적으로 연결되도록 구성되며,상기 제2 스위치는 개방 회로 또는 단락 회로 상태로 동작하도록 구성되는, 신경망 회로."}
{"patent_id": "10-2024-7040740", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1항에 있어서,상기 논리 연결자의 각각은 단락 회로 또는 인버터 중 적어도 하나를 포함하며,상기 논리 연결자의 각각은 이전 층의 논리 게이트의 출력을 현재 층의 논리 게이트의 입력에 연결하는, 신경망회로."}
{"patent_id": "10-2024-7040740", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제1항에 있어서, 상기 논리 게이트의 각각은 다단자 NOR 게이트를 포함하는, 신경망 회로."}
{"patent_id": "10-2024-7040740", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제1항에 있어서, 상기 논리 연결자 상태의 세트를 생성하도록 구성된 학습 회로를 더 포함하는, 신경망 회로."}
{"patent_id": "10-2024-7040740", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제1항에 있어서, 상기 논리 연결자의 각각은 상기 논리 연결자 상태의 고정된 하나를 가지는, 신경망 회로."}
{"patent_id": "10-2024-7040740", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제12항에 있어서, 상기 논리 연결자의 각각은 상기 논리 연결자 상태의 고정된 하나에 대응하는 단락 회로, 인버터 및 개방 회로 중 단일의 하나를 포함하는, 신경망 회로."}
{"patent_id": "10-2024-7040740", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "신경망 회로를 사용하여 함수를 연산하는 방법에 있어서,복수의 층으로 배열되며, 복수의 입력 및 출력을 각각 구비하는 복수의 논리 게이트, 및 인접한 층들의 각 쌍사이에 배열된 논리 연결자의 세트를 포함하는 복수의 논리 연결자로서, 상기 논리 연결자의 각각은 복수의 서로 다른 논리 연결자 상태 중 하나를 가지며, 상기 복수의 논리 연결자는 함수를 구현하도록 프로그래밍되는 것인, 상기 복수의 논리 연결자를 포함하는 신경망 회로를 제공하는 단계; 및상기 신경망을 사용하여 입력 신호에 대한 상기 함수를 연산하는 단계를 포함하는, 방법."}
{"patent_id": "10-2024-7040740", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제14항에 있어서, 상기 신경망 회로가 상기 함수를 구현하도록 상기 복수의 논리 연결자에 대한 상기 논리 연결자 상태의 세트를 찾는 단계를 더 포함하는, 방법."}
{"patent_id": "10-2024-7040740", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제15항에 있어서,상기 함수에 기초하여 정수 선형 계획법(ILP) 문제의 세트를 생성하는 단계; 및상기 논리 연결자 상태의 세트를 생성하기 위해 상기 ILP 문제의 세트를 해결하는 단계를 더 포함하는, 방법."}
{"patent_id": "10-2024-7040740", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제16항에 있어서,공개특허 10-2025-0004123-3-상기 논리 연결자의 상태를 설명하는 부등식 세트를 결정하는 단계; 및상기 부등식 세트를 통해 이전 층으로부터의 출력을 후속 층의 입력에 연결하는 단계를 더 포함하며,상기 ILP 문제의 생성은 상기 부등식 세트를 통한 상기 이전 층으로부터의 출력과 상기 후속 층의 입력의 연결에 기초하는, 방법."}
{"patent_id": "10-2024-7040740", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제14항에 있어서, 상기 논리 연결자 상태는 상기 제1 논리 게이트의 출력이 NOT 게이트를 통해 상기 제2 논리게이트의 입력에 연결되는 제1 상태 및 상기 제1 논리 게이트의 출력이 단락 회로를 통해 상기 제2 논리 게이트의 입력에 연결되는 제2 상태를 포함하는, 방법."}
{"patent_id": "10-2024-7040740", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "단일 칩에 있어서,신경망 회로의 복수의 층으로 배열된 복수의 논리 게이트로서, 상기 논리 게이트의 각각은 복수의 입력 및 출력을 구비하는 것인, 상기 복수의 논리 게이트;인접한 층들의 각 쌍의 논리 게이트들 사이에 배열된 복수의 논리 연결자로서, 상기 논리 연결자의 각각은 제1논리 게이트의 출력과 제2 논리 게이트의 복수의 입력 중 하나와의 관계를 결정하며, 상기 논리 연결자의 각각은 복수의 서로 다른 논리 연결자 상태 중 하나를 가지는 것인, 상기 복수의 논리 연결자;복수의 입력 단자; 및적어도 하나의 출력 단자를 포함하며,상기 칩은 상기 입력 단자와 상기 출력 단자 사이의 함수를 연산하도록 구성되는, 단일 칩."}
{"patent_id": "10-2024-7040740", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제19항에 있어서, 상기 칩은 10개 이하의 클럭 사이클에서 상기 입력 단자에 제공된 주어진 입력에 대한 상기함수를 연산하도록 구성되는, 단일 칩."}
{"patent_id": "10-2024-7040740", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "다단자 논리 게이트로 형성된 다층을 구비한 심층 신경망 회로가 제공된다. 일 측면에서, 상기 신경망 회로는 복 수의 층으로 배열된 복수의 논리 게이트 및 인접한 층들의 각 쌍 사이에 배열된 복수의 논리 연결자를 포함한다. 상기 논리 연결자의 각각은 제1 논리 게이트의 출력을 제2 논리 게이트의 입력에 연결하며 상기 논리 연결자의 각각은 복수의 서로 다른 논리 연결자 상태 중 하나를 가진다. 상기 신경망 회로는 상기 신경망 회로가 함수를 구현하도록 하기 위해, 상기 논리 연결자에 대한 상기 논리 연결자 상태의 세트를 찾음으로써 상기 함수를 구현 하게끔 학습되도록 구성된다."}
{"patent_id": "10-2024-7040740", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 출원은 2022년 5월 9일 출원된 \"다단자 논리 게이트로 형성된 다층을 구비한 심층 신경망\"이라는 명칭의 미 국 가출원 제63/364,405호의 우선권 이익을 주장하며, 상기 출원의 개시 내용 전체를 모든 목적을 위해 참조로 포함한다. 본 개시는 일반적으로 신경망에 관한 것이다. 더욱 구체적으로, 본 개시는 다단자 논리 게이트를 사용하여 구현 되는 다층을 이용한 심층 신경망에 관한 것이다."}
{"patent_id": "10-2024-7040740", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "신경망은 중앙 처리 장치(CPU) 및 필드 프로그래머블 게이트 어레이(FPGA)와 같은 다양한 유형의 하드웨어뿐만 아니라, 그래픽 처리 장치(GPU) 또는 텐서 처리 유닛(TPU)과 같은 분산 아키텍처와 같은 신경망용으로 설계된 특수 하드웨어 상에서 구현될 수 있다."}
{"patent_id": "10-2024-7040740", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "현재의 프로세서 아키텍처는 상대적으로 작은 데이터 세트에는 적절하나, 특정 연산 집약적 애플리케이션에서 실시간으로 요구되는 증가하는 정보량을 수용하지 못할 수 있다. 예를 들어, 차량은 수신되는 센서 데이터를 해 석하고 신속하게 중요한 실시간 결정을 내리기 위해 더 많은 컴퓨팅 용량으로부터 큰 이점을 얻을 수 있다. 본 개시의 양태는 차량 데이터 처리 능력의 미래 공백을 해결하는 것을 포함하여, 다양한 애플리케이션에 대한 컴퓨팅 용량을 개선할 수 있는 비용 효율적이고 확장 가능한 컴퓨팅 시스템 및 방법에 관한 것이다. 중앙 처리 장치(CPU), 그래픽 처리 장치(GPU) 및 필드 프로그래머블 게이트 어레이(FPGA)에 기반한 현재의 엣지 프로세서는 특정 컴퓨팅 목표를 충족시키기에 충분히 효율적으로 특정 대용량 센서 데이터 스트림(예: 차량의 데이터 스트림)에 대한 알고리즘을 실행할 수 없다. 데이터 이동은 특정 컴퓨팅 아키텍처에서 가장 중요한 제한 사항 중 하나를 나타낸다. 이러한 제한은 폰 노이만 병목 현상이라 불리며, 두 가지 주요 의미를 가진다: 연산 처리량을 제한하고 메모리와 처리 장치 사이에서 데이터를 이동시키는 데 상당한 에너지가 소요된다. 신경망과 같은 기계 학습 및 인공지능(AI) 기술의 증가하는 채택은 더 큰 데이터 세트에 대한 처리 능력을 개선 하고 자동화를 가능하게 하고자 한다. 그러나, 많은 경우에 이러한 기술들은 여전히 그들의 기본적인 폰 노이만 아키텍처에 의해 제한된다. 구체적으로, 신경망의 실시간 평가/추론을 위한 초저전력 전자 아키텍처를 실현하는 과제가 있다. 이는 신경망의 비선형(인공 뉴런 활성화 함수는 시그모이드, 정류된 선형 유닛(ReLU) 등일 수 있 음) 및 심층(순차적으로 평가되어야 하는 여러 층)적 특성이 불가피한 연산 순서를 수반할 수 있기 때문에 여전 히 해결되지 않은 문제이며, 따라서 GPU나 텐서 처리 유닛(TPU)과 같은 가장 진보된 분산 아키텍처에서도 여러 불가피한 클럭 사이클을 포함한다. 이는 많은 애플리케이션(예: 자율 주행 차량)에서 허용할 수 없을 정도로 높 은 평가/추론 시간으로 변환된다. 이 문제에 대한 완화책을 제안하기 위한 노력에도 불구하고, 현대 신경망 설 계의 물리적 및 연산적 한계로 인해 디지털 아키텍처(GPU, CPU, TPU)로는 근본적인 문제가 해결되지 않을 수 있 다."}
{"patent_id": "10-2024-7040740", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "청구항에 기재된 혁신은 각각 여러 가지 양태를 가지며, 어느 한 양태만으로 바람직한 특성이 결정되는 것은 아 니다. 청구항의 범위를 제한하지 않고, 본 개시의 주요 특징들을 이하 간단히 설명한다. 일 발명의 양태는 신경망 회로로서, 복수의 층으로 배열되며, 복수의 입력 및 출력을 각각 구비하는 복수의 논 리 게이트; 및 인접한 층들의 각 쌍 사이에 배열된 복수의 논리 연결자로서, 상기 논리 연결자의 각각은 제1 논 리 게이트의 출력과 제2 논리 게이트의 복수의 입력 중 하나와의 관계를 결정하며, 상기 논리 연결자의 각각은 복수의 서로 다른 논리 연결자 상태 중 하나를 갖는 것인, 상기 복수의 논리 연결자를 포함하고, 상기 신경망 회로는 상기 신경망 회로가 함수를 구현하도록 하기 위해, 상기 논리 연결자에 대한 상기 논리 연결자 상태의 세트를 찾음으로써 상기 함수를 구현하게끔 학습되도록 구성되는 것을 특징으로 한다. 일부 구현예에서, 상기 논리 연결자 상태는 상기 제1 논리 게이트의 출력이 NOT 게이트를 통해 상기 제2 논리 게이트의 입력에 연결되는 제1 상태 및 상기 제1 논리 게이트의 출력이 단락 회로를 통해 상기 제2 논리 게이트 의 입력에 연결되는 제2 상태를 포함한다. 일부 구현예에서, 상기 논리 연결자 상태는 추가로 상기 제1 논리 게이트의 출력이 개방 회로를 통해 상기 제2 논리 게이트의 입력에 연결되는 제3 상태를 포함한다. 일부 구현예에서, 상기 논리 게이트 및 상기 논리 연결자는 상보성 금속 산화물 반도체(CMOS) 기술로 구현된다. 일부 구현예에서, 상기 신경망 회로는 단일 칩 상에 형성된다. 일부 구현예에서, 상기 논리 연결자의 각각은 입력; 상기 입력에 연결된 단락 회로; 상기 단락 회로와 병렬로 배열되고 상기 입력에 연결된 인버터; 출력; 및 상기 단락 회로 및 상기 인버터 중 하나를 상기 출력에 연결하 도록 구성된 적어도 하나의 스위치를 포함한다. 일부 구현예에서, 상기 논리 연결자의 각각은 추가로 상기 입력에 연결된 개방 회로를 포함하며, 상기 적어도 하나의 스위치는 상기 단락 회로, 상기 인버터 및 상기 개방 회로 중 하나를 상기 출력에 연결하도록 구성된다. 일부 구현예에서, 상기 적어도 하나의 스위치는 직렬로 연결된 제1 스위치 및 제2 스위치를 포함하며, 상기 제1 스위치는 상기 단락 회로 및 상기 인버터 중 하나에 전기적으로 연결되도록 구성되며, 상기 제2 스위치는 개방 회로 또는 단락 회로 상태로 동작하도록 구성된다. 일부 구현예에서, 상기 논리 연결자의 각각은 단락 회로 또는 인버터 중 적어도 하나를 포함하며, 상기 논리 연 결자의 각각은 이전 층의 논리 게이트의 출력을 현재 층의 논리 게이트의 입력에 연결한다. 일부 구현예에서, 상기 논리 게이트의 각각은 다단자 NOR 게이트를 포함한다. 일부 구현예에서, 상기 신경망은 추가로 상기 논리 연결자 상태의 세트를 생성하도록 구성된 학습 회로를 포함 한다. 일부 구현예에서, 상기 논리 연결자의 각각은 상기 논리 연결자 상태의 고정된 하나를 가진다. 일부 구현예에서, 상기 논리 연결자의 각각은 상기 고정된 하나의 논리 연결자 상태에 대응하는 단락 회로, 인 버터 및 개방 회로 중 단일의 하나를 포함한다. 다른 양태는 신경망 회로를 사용하여 함수를 연산하는 방법으로서, 복수의 층으로 배열되며, 복수의 입력 및 출 력을 각각 구비하는 복수의 논리 게이트; 및 인접한 층들의 각 쌍 사이에 배열된 논리 연결자의 세트를 포함하 는 복수의 논리 연결자로서, 상기 논리 연결자의 각각은 복수의 서로 다른 논리 연결자 상태 중 하나를 가지며, 상기 복수의 논리 연결자는 함수를 구현하도록 프로그래밍되는 것인, 상기 복수의 논리 연결자를 포함하는 신경 망 회로를 제공하는 단계; 및 상기 신경망을 사용하여 입력 신호에 대한 상기 함수를 연산하는 단계를 포함한다. 일부 구현예에서, 상기 방법은 추가로 상기 신경망 회로가 상기 함수를 구현하도록 상기 복수의 논리 연결자에 대한 상기 논리 연결자 상태의 세트를 찾는 단계를 포함한다. 일부 구현예에서, 상기 방법은 추가로 상기 함수에 기초하여 정수 선형 계획법(ILP) 문제의 세트를 생성하는 단 계; 및 상기 논리 연결자 상태의 세트를 생성하기 위해 상기 ILP 문제의 세트를 해결하는 단계를 포함한다. 일부 구현예에서, 상기 방법은 추가로 상기 논리 연결자의 상태를 설명하는 부등식 세트를 결정하는 단계; 및 상기 부등식 세트를 통해 이전 층으로부터의 출력을 후속 층의 입력에 연결하는 단계를 포함하며, 상기 ILP 문 제의 생성은 상기 부등식 세트를 통한 상기 이전 층으로부터의 출력과 상기 후속 층의 입력의 연결에 기초한다. 일부 구현예에서, 상기 논리 연결자 상태는 상기 제1 논리 게이트의 출력이 NOT 게이트를 통해 상기 제2 논리 게이트의 입력에 연결되는 제1 상태 및 상기 제1 논리 게이트의 출력이 단락 회로를 통해 상기 제2 논리 게이트 의 입력에 연결되는 제2 상태를 포함한다. 또 다른 양태는 단일 칩으로서, 복수의 입력 및 출력을 각각 구비하는 신경망 회로의 복수의 층으로 배열된 복 수의 논리 게이트; 인접한 층들의 각 쌍의 논리 게이트들 사이에 배열된 복수의 논리 연결자로서, 상기 논리 연 결자의 각각은 제1 논리 게이트의 출력과 제2 논리 게이트의 복수의 입력 중 하나와의 관계를 결정하며, 상기 논리 연결자의 각각은 복수의 서로 다른 논리 연결자 상태 중 하나를 가지는, 상기 복수의 논리 연결자; 복수의 입력 단자; 및 적어도 하나의 출력 단자를 포함하며, 상기 칩은 상기 입력 단자와 상기 출력 단자 사이의 함수 를 연산하도록 구성된다. 일부 구현예에서, 상기 칩은 10개 이하의 클럭 사이클에서 상기 입력 단자에 제공된 주어진 입력에 대한 상기 함수를 연산하도록 구성된다."}
{"patent_id": "10-2024-7040740", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 2, "content": "본 개시의 요약을 위해, 혁신의 특정 양태, 이점 및 신규한 특징이 여기에 기술되었다. 반드시 모든 이러한 이 점이 특정 구현예에 따라 달성될 수 있는 것은 아니라는 점을 이해해야 한다. 따라서, 본 혁신은 여기에서 교시 되거나 제안된 다른 이점을 반드시 달성하지 않고도, 여기에서 교시된 하나의 이점 또는 이점 군을 달성하거나 최적화하는 방식으로 구현되거나 수행될 수 있다."}
{"patent_id": "10-2024-7040740", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 개시의 양태는 멤컴퓨팅 신경망(MEMC-NN) 또는 더 일반적으로 디지털 신경망이라 불릴 수 있는 개선된 신경 망 설계에 관한 것이다. 여기에 개시된 디지털 신경망은 회로로 구현될 수 있다. 특정 구현예에서, 개시된 신경 망은 논리 게이트, 스위치 및/또는 선택기만을 사용하여 칩 상에 쉽게 통합될 수 있다. 본 개시의 양태는 상기 기술된 제한 사항의 일부 또는 전부를 부분적으로 또는 완전히 해결할 수 있으며, 이를 통해 무시할 만한 전력 을 사용하면서 실시간 신경망 평가/추론을 제공할 수 있다. 여기에 제공된 신경망 솔루션은 서버와 클라우드에 서부터 스마트 워치와 안경과 같은 더 작은 장치, 또는 여기에 기술된 것과 같은 사물인터넷(IOT) 및 엣지 컴퓨 팅에 이르기까지 시스템의 모든 수준에서 사실상 통합될 수 있다. 유리하게도, 본 개시의 양태는 크기, 무게 및 전력; 환경; 및 비용 목표를 준수하는 전례 없는 AI 처리 능력을 제공할 잠재력을 가진다. 여기에 개시된 디지 털 신경망 시스템 및 방법은 다른 적절한 애플리케이션에 적용되거나 다른 적절한 목표를 충족시킬 수 있다."}
{"patent_id": "10-2024-7040740", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "특정 구현예에 대한 다음의 설명은 특정 구현예에 대한 다양한 설명을 제시한다. 그러나, 여기에 기술된 혁신은 예를 들어, 청구항에 의해 정의되고 포함되는 바와 같이 다양한 방식으로 구현될 수 있다. 본 설명에서는 동일 하거나 기능적으로 유사한 요소를 나타내는 유사한 참조 부호가 사용되는 도면이 참조된다. 도면에 도시된 요소 들이 반드시 축척대로 도시된 것은 아니라는 점을 이해해야 한다. 또한, 특정 구현예는 도면에 도시된 것보다 더 많은 요소를 포함할 수 있고/있거나 도면에 도시된 요소의 부분집합을 포함할 수 있다는 점을 이해해야 한다. 더 나아가, 일부 구현예는 두 개 이상의 도면으로부터의 특징들의 적절한 조합을 포함할 수 있다. 여기에 제공된 제목은 단지 편의를 위한 것이며 반드시 청구항의 범위 또는 의미에 영향을 미치지는 않는다. 현재의 프로세서 아키텍처는 상대적으로 작은 데이터 세트에는 적절하나, 특정 연산 집약적 애플리케이션에서 실시간으로 요구되는 증가하는 정보량을 수용하지 못할 수 있다. 예를 들어, 차량은 수신되는 센서 데이터를 해 석하고 신속하게 중요한 실시간 결정을 내리기 위해 더 많은 컴퓨팅 용량으로부터 큰 이점을 얻을 수 있다. 본 개시의 양태는 차량 데이터 처리 능력의 미래 공백을 해결하는 것을 포함하여, 다양한 애플리케이션에 대한 컴 퓨팅 용량을 개선할 수 있는 비용 효율적이고 확장 가능한 컴퓨팅 시스템 및 방법에 관한 것이다. 중앙 처리 장치(CPU), 그래픽 처리 장치(GPU) 및 필드 프로그래머블 게이트 어레이(FPGA)에 기반한 현재의 엣지 프로세서는 특정 컴퓨팅 목표를 충족시키기에 충분히 효율적으로 특정 대용량 센서 데이터 스트림(예: 차량의 데이터 스트림)에 대한 알고리즘을 실행할 수 없다. 데이터 이동은 특정 컴퓨팅 아키텍처에서 가장 중요한 제한 사항 중 하나를 나타낸다. 이러한 제한은 폰 노이만 병목 현상이라 불리며, 두 가지 주요 의미를 가진다: 연산 처리량을 제한하고 메모리와 처리 장치 사이에서 데이터를 이동시키는 데 상당한 에너지가 소요된다. 신경망과 같은 기계 학습 및 인공지능(AI) 기술의 증가하는 채택은 더 큰 데이터 세트에 대한 처리 능력을 개선 하고 자동화를 가능하게 하고자 한다. 그러나, 많은 경우에 이러한 기술들은 여전히 그들의 기본적인 폰 노이만 아키텍처에 의해 제한된다. 구체적으로, 신경망의 실시간 평가/추론을 위한 초저전력 전자 아키텍처를 실현하는 과제가 있다. 이는 신경망의 비선형(인공 뉴런 활성화 함수는 시그모이드, 정류된 선형 유닛(ReLU) 등일 수 있 음) 및 심층(순차적으로 평가되어야 하는 여러 층)적 특성이 불가피한 연산 순서를 수반할 수 있기 때문에 여전 히 해결되지 않은 문제이며, 따라서 GPU나 텐서 처리 유닛(TPU)과 같은 가장 진보된 분산 아키텍처에서도 여러 불가피한 클럭 사이클을 포함한다. 이는 많은 애플리케이션(예: 자율 주행 차량)에서 허용할 수 없을 정도로 높 은 평가/추론 시간으로 변환된다. 이 문제에 대한 완화책을 제안하기 위한 노력에도 불구하고, 현대 신경망 설 계의 물리적 및 연산적 한계로 인해 디지털 아키텍처(GPU, CPU, TPU)로는 근본적인 문제가 해결되지 않을 수 있 다. 본 개시의 양태는 멤컴퓨팅 신경망(MEMC-NN) 또는 더 일반적으로 디지털 신경망이라 불릴 수 있는 개선된 신경 망 설계에 관한 것이다. 여기에 개시된 디지털 신경망은 회로로 구현될 수 있다. 특정 구현예에서, 개시된 신경 망은 논리 게이트, 스위치 및/또는 선택기만을 사용하여 칩 상에 쉽게 통합될 수 있다. 본 개시의 양태는 상기 기술된 제한 사항의 일부 또는 전부를 부분적으로 또는 완전히 해결할 수 있으며, 이를 통해 무시할 만한 전력 을 사용하면서 실시간 신경망 평가/추론을 제공할 수 있다. 여기에 제공된 신경망 솔루션은 서버와 클라우드에 서부터 스마트 워치와 안경과 같은 더 작은 장치, 또는 여기에 기술된 것과 같은 사물인터넷(IOT) 및 엣지 컴퓨 팅에 이르기까지 시스템의 모든 수준에서 사실상 통합될 수 있다. 유리하게도, 본 개시의 양태는 크기, 무게 및 전력; 환경; 및 비용 목표를 준수하는 전례 없는 AI 처리 능력을 제공할 잠재력을 가진다. 여기에 개시된 디지 털 신경망 시스템 및 방법은 다른 적절한 애플리케이션에 적용되거나 다른 적절한 목표를 충족시킬 수 있다.디지털 신경망 설계의 구현예 도 1은 본 개시의 양태에 따른 디지털 신경망을 도시하는 회로도이다. 상기 디지털 신경망은 단일 칩 상에 형성된 회로로 구현될 수 있다. 상기 디지털 신경망은 복수의 입력, 복수의 층, 복수의 출 력 및 선택적인 학습 회로를 포함하는 심층 신경망이다. 각 층은 복수의 다단자 논리 게이트 (또한 \"논리 게이트\"라고도 함)를 포함한다. 각 다단자 논리 게이트는 이전 층의 하나 이상의 다단자 논리 게이트와 논리적으로 연관될 수 있다. 예를 들어, 두 다단자 논리 게이트 사이의 논리적 연관은 이전 층의 다단자 논리 게이트의 출력에 논리 연산을 적용하여 그 결과를 현재 층의 다 단자 논리 게이트에 제공할 수 있다. 이러한 논리적 연관은 논리 연결자(또한 \"논리 연산자\", \"이진 논리 연산자\" 또는 \"논리 회로\"라고도 함)에 의해 구현될 수 있다. 각 논리 연결자는 한 쌍의 다단자 논리 게이트 사이의 관계를 정의하도록 구성된다. 상기 논리 연결 자는 항상 물리적으로 논리 게이트를 연결하지는 않을 수 있다. 예를 들어, 상기 논리 연결자는 두 다단자 논리 게이트 사이에 개방 회로를 구현할 수 있다. 도 2 및 도 3에 도시되고 아래에서 더 자세히 논 의되는 바와 같이, 두 다단자 논리 게이트 사이의 관계는 논리적 NOT(예: 인버터를 통해 구현됨), 개 방 회로 및/또는 단락 회로를 포함할 수 있지만, 다른 관계도 가능하다. 특정 구현예에서, 상기 논리 연결자는 단일 입력을 수신하여 단일 출력을 출력할 수 있다. 특정 구현예에 서, 상기 논리 연결자에 의해 구현된 연결성의 토폴로지는 디지털 신경망의 네트워크 층을 정의한다 (예: 완전 연결, 컨볼루션, 풀링 등). 선택적인 학습 회로는 디지털 신경망을 학습시키는 데 사용될 수 있다. 구현예에 따라, 선택적인 학 습 회로는 디지털 신경망과 동일한 칩의 일부로 포함되거나 별도의 칩에 구현될 수 있다. 상기 디지 털 신경망은 여기에 개시된 바와 같이 함수를 구현하도록 학습될 수 있다. 상기 디지털 신경망이 학 습된 후에는, 단일 클럭 사이클, 몇 개의 클럭 사이클, 한 자리 수의 클럭 사이클에서 주어진 입력에 대한 함수 를 연산할 수 있다. 예를 들어, 상기 디지털 신경망은 구현에 따라 2, 3, 4, 5, 6, 7, 8, 9 또는 10 클럭 사이클 미만 또는 몇 개의 클럭 사이클에서 함수를 연산하도록 구성될 수 있다. 도 2는 본 개시의 양태에 따른 다단자 논리 게이트 및 이에 연결된 복수의 논리 연결자의 구현예를 도시한다. 도시된 구현예에서, 각 논리 연결자는 입력, 출력, 스위치 및 입력과 출력 사이의 복수의 대체 병렬 경로를 포함한다. 도 2에 도시된 상부 논리 연결자에서, 상기 병렬 경로는 인버터(예: NOT 게이트), 개방 회로 및 단락 회로를 포함한다. 상기 스위치는 인버터 , 개방 회로 및 단락 회로 중 하나를 통해 논리 연결자의 입력과 출력 사이의 논리적 관계를 정의함으로써 논리 연결자의 상태(또한 \"논리 상태\"라고도 함)를 정의하도록 구성된다. 도 2는 스위치가 선택할 수 있는 별도의 경로로 개방 회로을 보여주지만, 특정 구현에서는 개방 회로 에 대한 물리적인 경로가 없을 수 있다. 예를 들어, 개방 회로를 선택할 때 스위치는 인버터와 단락 회로 각각에서 분리될 수 있다. 그 결과, 주어진 논리 연결자에 의해 수행되는 논리적 연산은 논리 연결자의 입력과 출력를 연결하는 경로(예: 인버터, 개방 회로, 및 단락 회로 )에 따라 달라질 수 있다. 일부 논리 연결자는 인버터와 단락 회로와 같은 두 개의 대체 병렬 경로를 포함할 수 있다. 도 2에서 아래 쪽의 두 논리 연결자가 이러한 연결자를 나타낸다. 구현에 따라 디지 털 신경망은 실질적으로 동일한 구조를 가진 논리 연결자를 포함할 수도 있고, 도 2에 도시된 논리 연결자와 같이 다양한 구조를 가진 복수의 논리 연결자를 포함할 수도 있다. 따라서 다양한 구현에서 는 특정 응용을 위한 논리 연결자가 동질적이거나 이질적일 수 있다. 또한, 도 2의 예에서, 상기 다단자 논리 게이트는 다단자 OR 게이트로 구현된다. 그러나, 본 개시의 양태 는 이에 한정되지 않으며, 구현에 따라 상기 다단자 논리 게이트는 다른 유형의 다단자 논리 게이트 를 사용하여 구현될 수 있다. 여기에 더 자세히 설명된 바와 같이, 상기 논리 연결자의 상태는 전통적인 신경망의 가중치와 유사할 수 있다. 일부 다른 구현예에서, 각 논리 연결자는 여기에 설명된 바와 같이 논 리 연결자의 학습된 상태를 나타내는 스위치 없이 단일 경로(예: 인버터, 개방 회로 및 단 락 회로 중 하나)만을 사용하여 구현될 수 있다. 도 3은 본 개시의 양태에 따른 다단자 논리 게이트 및 이에 연결된 복수의 논리 연결자의 다른 구현 예를 도시한다. 도 3의 구현예는 논리 연결자가 개방 회로 경로를 포함하지 않는다는 점을 제외하고 는 도 2의 구현예와 유사하다. 도 2 및 도 3이 논리 연결자의 예시적 구현예를 제공하지만, 본 개시의 양 태는 이에 한정되지 않으며, 상기 논리 연결자는 하나 이상의 서로 다른 논리 연산을 구현하는 더 많은 수의 논리 상태를 포함할 수 있다. 디지털 신경망의 범용성 여기서 사용되는 바와 같이, 신경망은 튜링의 의미에서 계산 가능한 모든 함수를 계산할 수 있는 경우 범용 기 계로서 기능할 수 있다. 계산 가능한 함수는 튜링 기계에 의해 계산될 수 있는 함수로 정의될 수 있다. 도 1 내 지 3에 구현된 디지털 신경망은 범용 기계를 생성하는 데 사용될 수 있다. 실제로, OR 게이트와 NOT 게이 트(예: 인버터)는 모든 불린 함수가 OR 및 NOT 게이트의 집합으로 작성될 수 있다는 점에서 완전한 기저를 형성 할 수 있다. 여기에 설명된 디지털 신경망이 도 1 내지 3에 도시된 구성에 한정되지는 않지만, 도 1 내지 3의 디지털 신경망은 큰 유연성을 허용하는 층을 생성하기 위해 불린 함수의 임의의 기저 또는 이들의 혼합을 사용할 수 있다. 여기에 설명된 디지털 신경망의 범용성은 또한 조작적 관점에서 볼 수 있다. N개의 입력 단자와 M개의 출력 단자가 주어진 경우, 길이가 N인 임의의 입력 x에 대해 그리고 길이가 M인 이진 출력 y에 대해 임의 의 가능한 함수 y = f(x)의 계산을 허용하는 최소 층의 수(연결성의 토폴로지에 의존함)가 존재한다. 상기 논리 연결자의 상태는 함수 f를 구현하는 데 사용될 수 있다. 다시 말해, 각 함수 f에 대해 디지털 신경망(10 0)이 함수 f를 정확히 평가하도록 구성하는 논리 연결자의 상태의 적어도 하나의 세트가 존재한다. 디지털 신경망의 학습 여기서 사용되는 바와 같이, 디지털 신경망을 학습시키는 것은 일반적으로 함수 f를 디지털 신경망에 매핑하는 논리 연결자의 논리적 상태 구성을 찾는 것을 의미한다. 이러한 학습은 함수 f에 대한 분석적 지 식이나 모든 가능한 입력 x에 대한 출력 y 없이도 수행될 수 있다. 일반적으로, 주어진 입력 x(학습 세트)에 대 한 데이터 출력 y(레이블)의 세트가 학습에 사용 가능하다. 학습 회로는 디지털 신경망을 학습시키기 위한 학습을 수행할 수 있다. 전통적인 신경망의 경우, 함수 f의 양호한 표현을 가능하게 하는 가중치의 구성을 찾기 위해 기울기 하강 기반 기법이 사용될 수 있다. 그러나, 논리 연결자에 대해 사용 가능한 상태의 수가 정수이므로 논리 연결자 에 대한 기울기를 정의하는 것이 불가능할 수 있기 때문에, 이러한 기법은 여기에 설명된 디지털 신경망 을 학습시키는 데 적용할 수 없을 수 있다. 이는 완전 디지털 신경망을 구현하기 어려웠던 이유 중 하나이 다. 신경망을 위한 다양한 일반적인 학습 방법은 디지털 회로를 학습시키는 데 있어 기술적 과제에 직면할 수 있다. 이러한 일반적인 학습 방법에서는 연속적인 파라미터가 학습에 사용된다. 그러나, 디지털 회로는 연속적인 파라 미터가 아닌 이진값에 기초하여 기능할 수 있다. 연속적인 파라미터 값에 대해 작동하는 방법은 일반적으로 이 진값을 사용하는 디지털 회로에 적합하지 않다. 여기에 개시된 디지털 신경망을 학습시키는 것은 신경망의 서로 다른 층의 논리 게이트 사이의 연관(예: 디지털 신경망에 의해 정의된 바와 같은)을 결정하는 것을 포함할 수 있다. 예를 들어, 이는 서 로 다른 층의 논리 게이트를 단락 회로를 통해 연결할지 또는 인버터를 통해 연결할지를 결정하 는 것을 포함할 수 있다. 다른 예로서, 학습은 서로 다른 층의 논리 게이트를 단락 회로를 통해 연결 할지, 인버터를 통해 연결할지, 또는 두 논리 게이트를 연결하지 않을지(예: 논리 게이트 중 하 나의 입력에 개방 회로를 연결함으로써)를 결정하는 것을 포함할 수 있다. 여기에 개시된 신경망을 학습시키기 위한 한 가지 기법은 정수 선형 계획법(ILP)을 사용하여 학습 문제를 표현하는 것을 포함한다. 예를 들어, 각 입력 x에 대해, 논리 연결자의 상태를 나타내는 이진 변수가 미지 수인 선형 부등식의 세트를 정의하여 입력 x가 신경망을 통해 전파되는 것을 나타낼 수 있다. 따라서, 디 지털 신경망의 학습은 ILP 문제를 해결하는 것으로 변환될 수 있다. 그러나, ILP를 해결하는 것은 단순한 작업이 아닐 수 있다. ILP는 그 난해성으로 악명 높은 비결정적 다항식 (NP) 문제로도 알려진 조합적 문제의 부류에 속한다. 본 개시는 가상 멤컴퓨팅 머신(VMM)과 관련되어 있으며, 여기서 비일시적 컴퓨터 판독 가능 저장소는 하나 이상의 프로세서에 의해 실행될 때 새로운 컴퓨팅 아키텍처를 에뮬레이트하고 대규모 ILP 문제를 매우 효율적으로 해결하는 명령어를 저장한다. VMM은 디지털 신경망의 학습과 관련된 ILP 문제를 해결하고 함수 f를 나타내는 논리 연결자 상태에 대한 구성을 제공하는 데 사용 될 수 있다. VMM은 디지털 신경망의 학습 솔루션으로 사용될 수 있는 자기 조직화 대수 게이트(SOAG)의 소 프트웨어 에뮬레이션일 수 있다.여기에 개시된 신경망과 관련된 문제(예: ILP 문제)를 해결하기 위해 2022년 12월 22일 출원된 국제특허출원 제 PCT/US2022/053781호 및/또는 2016년 7월 12일 출원되어 국제공개번호 WO 2017/011463호로 공개된 국제특허출 원 제PCT/US2016/041909호에 개시된 적절한 원리 및 이점이 사용될 수 있으며, 이들 특허출원의 개시 내용 전체 를 모든 목적을 위해 참조로 포함한다. 예를 들어, 학습 회로는 이들 국제특허출원에 개시된 적절한 원리 및 이점에 따라 구현될 수 있다. 다른 적절한 학습 방법이 여기에 개시된 디지털 신경망에 적용될 수 있다. 여기에 개시된 디지털 신경망은 서로 다른 함수를 연산하도록 여러 번 학습될 수 있다. 특정 애플리케이션에서, 여기에 개시된 디지털 신경망은 한 번만 학습될 수 있다. 이는 사물인터넷 장치와 같은 특정 애플리케이션에 유 용할 수 있다. 활성화 함수로서의 NOR 게이트 설계 특정 구현예에서, NOR 게이트는 디지털 신경망의 다단자 논리 게이트를 구현하는 데 사용될 수 있다. 다단자 NOR 게이트는 다음과 같은 일반적인 관계를 가지는 임계값으로 정의될 수 있다: 수학식 1"}
{"patent_id": "10-2024-7040740", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "수학식 1에서, o는 출력이고 ij는 NOR 게이트의 j번째 입력이며 th는 임계값이다. 특정 구현에서, NOR 게이트는 상보성 금속 산화물 반도체(CMOS) 기술에서 쉽게 구현될 수 있기 때문에 OR 게이트 대신 다단자 논리 게이트 를 구현하는 데 사용될 수 있다. 그러나, 본 개시의 양태는 이에 한정되지 않는다. OR 게이트를 얻기 위해 서는 NOR 게이트 후에 NOT 게이트를 추가할 수 있다. 그러나, 여기에 설명된 디지털 신경망의 특정 구현예 에서 사용될 때, OR 및 NOR 게이트는 다단자 논리 게이트의 입력 단자가 인버터 또는 단락 회로 (예: 도 3에 도시된 바와 같이)를 선택할 수 있는 스위치를 포함하는 논리 연결자에 결합될 수 있기 때문에 완전히 상호 교환 가능할 수 있다. 도 4는 본 개시의 양태에 따른 다단자 NOR 게이트의 구현예를 도시한다. 도 5는 본 개시의 양태에 따른 임 계값을 가지는 다단자 NOR 게이트의 구현예를 도시한다. 다단자 NOR 게이트 및 의 각각은 CMOS 기술로 구현될 수 있다. 도 4를 참조하면, 다단자 NOR 게이트는 복수의 입력 i1, i2, ... in, 출력 o, 제1 전원 단자 VDD, 제2 전원 단자 GND, 및 복수의 트랜지스터를 포함한다. 상기 트랜지스터는 NOR 함수를 구현하도록 배열된다. 도 5에서, 다단자 NOR 게이트는 복수의 입력 스위치 i1, i2, ... in, 출력 o, 제1 전원 단자 VDD, 두 개의 제2 전원 단자 GND, 한 쌍의 트랜지스터, 각각의 입력 스위치 i1, i2, ... in과 직렬로 연결된 복수의 제1 저항기 R, 및 임계값 저항기 Rth를 포함한다. 임계값 저항기 Rth가 R/2 또는 그보다 큰 값으로 설정될 때, 도 5 의 다단자 NOR 게이트의 기능은 도 4의 다단자 NOR 게이트의 기능과 실질적으로 동일할 수 있다. NOR 게이트의 동작 원리는 다음과 같을 수 있다. 저항기 Rth는 th보다 엄격하게 큰 수의 스위치가 닫혀 있는 경 우 출력 전압 o가 0으로 설정되고, 그렇지 않은 경우 VDD로 설정되도록 크기가 조정될 수 있다. 따라서, NOR 게 이트는 스위치의 상태가 입력 ij이고 출력 o가 노드 o에서의 전압인 수학식 1을 구현한다. 도 5의 다단자 NOR 게이트는 CMOS 기술로 완전히 구현된 경우에도 디지털 및 아날로그 회로 요소의 조합을 사용하여 구현될 수 있다. 이는 여기에서 논의된 바와 같이, 예를 들어 완전히 디지털로 구현된 것에 비해 특정 애플리케이션에서 특정한 이점을 제공할 수 있다. 도 5의 다단자 NOR 게이트를 계속 참조하면, 입력은 입력 스위치 i1, i2, ... in을 개방하거나 닫도록 구성 된다. 상기 입력 스위치 i1, i2, ... in은 입력 스위치 i1, i2, ... in을 구현하는 데 사용되는 각각의 트랜지스 터(예: CMOS 구성요소의 게이트)의 제어 단자에 전압을 인가함으로써 개방되거나 닫히도록 구성된다. 따라서,상기 입력 스위치 i1, i2, ... in은 다른 NOR 게이트 또는 다른 일반적인 CMOS 기반 논리 게이트의 출력에 의해 직접 제어될 수 있다. 도 5의 구현은 임계값을 가진 NOR 게이트의 가장 간단한 구현 중 하나일 수 있다. 예를 들어, 도 5의 구현은 n이 입력의 수인 경우 3(n+1)개의 최소 트랜지스터를 사용할 수 있다. 완전히 디지털 로 구현하는 경우에는 본질적으로 입력의 합을 수행하고 그 합을 임계값과 비교하는 더 복잡한 디지털 회로가 필요할 수 있다. 구현에 따라, 저항기 Rth의 저항 크기 또는 R/Rth의 비율은 NOR 게이트의 원하는 기능을 구현하는 데 중요 한 설계 고려사항이 될 수 있다. 예를 들어, 표준 CMOS 트랜지스터는 VDD/2에서 차단 게이트 전압을 가질 수 있 다. 이 경우, NOR 게이트가 적절히 기능하도록 하기 위해 비율은 R/Rth = 1/2 + th가 되도록 구성될 수 있 다. 한 예에서, th 스위치가 닫혀 있는 경우 전압 v는 v = (4th)/(4th + 1)(VDD/2) < VDD/2이며, th + 1 스위치 가 닫혀 있는 경우에는 v = (4th + 4)/(4th + 3)(VDD/2) > VDD/2이다. 도 6은 본 개시의 양태에 따라 th 및 th+1 스위치가 닫힌 상태에서 평가된 v/VDD의 그래프이다. 여기서, th는 다단자 NOR 게이트를 특징짓는 매개변수 일 수 있다. th는 다단자 NOR 게이트의 출력이 논리 1이 되기 위해 논리 1 상태로 주장될 수 있는 입력의 임계값 수일 수 있다. 예를 들어, th는 수학식 1에 정의된 바와 같이 다단자 NOR 게이트를 특징지을 수 있 다: th 이하의 입력이 1(예: th 이하의 스위치가 닫힘)인 경우 출력은 1이다. 그렇지 않고 th+1 이상의 입력이 1(예: th+1 이상의 스위치가 닫힘)인 경우 출력은 0이다. 따라서, 매개변수 th를 가진 다단자 NOR 게이트 는 다단자 NOR 게이트의 일반화일 수 있다. 표준 다단자 NOR 게이트는 th = 0으로 설정함으로써 얻을 수 있다. 그러나, CMOS 기술로 구현될 때, 저항에서 변동성이 있을 수 있으며 NOR 게이트는 완벽한 계단 함수를 따 르지 않을 수 있다. 도 6에 도시된 바와 같이, 임계값이 작은 경우(th ≤ 2), 갭 (v(th + 1) - v(th))/VDD는 약 10%이며, 이는 언급된 변동성을 처리하기에 충분하다. 이 관계는 NOR 게이트의 입력 수에 의존하지 않을 수 있다. 그러나, 임계값이 더 높은 경우, 변동성은 NOR 게이트의 본질적인 측면일 수 있으며, 이는 디지 털 신경망의 학습에서 다른 방식으로 해결될 수 있다. NOR 게이트의 ILP 공식 본 개시의 양태에 따라, 논리 게이트 및/또는 임계값 논리 게이트를 포함하는 디지털 신경망은 ILP 공식을 사용하여 학습될 수 있다. 위의 출력 o에 대한 수학식 1에서 시작하여, 임계값을 가진 다단자 NOR 게이트의 ILP 공식은 다음 형태의 한 쌍의 부등식으로 작성될 수 있다: 수학식 2"}
{"patent_id": "10-2024-7040740", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "수학식 2에서, ij는 n개의 입력이고, o는 출력이며 th는 임계값이다. 이 두 부등식은 ILP 형식으로 임계값을 가 진 다단자 NOR 게이트를 완전히 설명하는 데 사용될 수 있다. 이러한 다단자 NOR 게이트의 CMOS 구현 에서 발생할 수 있는 변동성을 해결하기 위해, NOR 관계는 v/VDD 비율 위로 δ+의 추가 갭과 아래로 δ-의 추가 갭으로 구현될 수 있다. ILP 공식 측면에서 이는 수학식 2를 다음과 같이 변경한다: 수학식 3 수학식 3은 가 th - δ < ≤ th + δ가 되는 것을 금지하여 임계값 th 위로 δ의 갭과 아래로 δ의 갭을 생성한다. 이는 적절히 크기가 조정되어 CMOS 구현에 의해 도입된 변동성을 보상하는 데 사용될 수 있다. 학습 문제의 ILP 공식 도 7은 본 개시의 양태에 따른 디지털 신경망의 예를 도시한다. 도 7의 디지털 신경망은 디지털 신경 망의 크기와 토폴로지에 적용될 수 있는 학습 문제의 ILP 공식의 양태를 설명하고 파악하기 위해 간단하고 작은 토폴로지를 가진 예로 제공된다. 도시된 바와 같이, 신경망은 복수의 층으로 배열된 복수의 다 단자 논리 게이트를 포함한다. 신경망은 또한 복수의 입력 i1,1, i1,2, ..., i1,12 및 출력 o3,1을 포함 한다. 신경망은 또한 인접한 층 사이의 관계나 연결을 정의하는 상태를 가진 복수의 논리 연결자 를 추가로 포함한다. 또한 내부 출력 o1,1, o1,2, ... o2,3, 다단자 논리 게이트에 대한 내부 입력 i2,1, i2,2, ..., i3,3, 및 각 층을 인접한 층에 연결하는 논리 연결자에 대한 내부 입력 i'2,1, i'2,2, ..., i'3,3이 도시되어 있다. 상기 신경망은 추가로 선택적인 학습 회로를 포함할 수 있다. 도 8A 및 도 8B는 본 개시의 양태에 따른 논리 연결자의 구현예를 도시한다. 특히, 도 8A의 논리 연결자는 도 2에 도시된 논리 연결자와 실질적으로 유사하다. 논리 연결자는 스위치, 인버터, 개방 회로 및 단락 회로를 포함한다. 도 8B의 논리 연결자는 대체 설계로 도 8A의 논리 연결자와 동일한 기능을 구현한다. 특히, 논리 연 결자는 인버터, 단락 회로, 제1 스위치 및 제2 스위치를 포함한다. 제1 스위치(31 4)는 인버터 및 단락 회로 중 하나를 선택하도록(예: 연결하도록) 구성되는 반면, 제2 스위치는 개방 회로 또는 단락 회로 상태로 동작하도록 구성된다. 따라서, 제1 스위치와 제2 스위치의 조합은 논리 연결자에 대해 세 가지 서로 다른 상태(예: 개방 회로, 단락 회로 또는 반전)를 구현할 수 있다. 신경망을 학습시키는 데 있어 한 가지 중요한 측면은 ILP 문제의 변수를 식별하는 것이다. 학습은 입력 세 트 {I}에 대해 신경망이 출력 {Τ}를 반환하도록 각 다단자 논리 게이트의 입력 단자에서 논리 연결 자의 상태 세트를 찾는 것을 포함한다. 따라서, 각 I ∈ {I}에 대해, 입력 I를 신경망을 통해 전파하 는 것은 논리 연결자의 상태를 통해 I를 Τ ∈ {Τ}에 연결하는 부등식의 세트에 의해 정의될 수 있다. 다 음 논의는 다단자 논리 게이트가 NOR 게이트로 구현되는 구현예에 적용된다. 그러나, 이 논의의 원리 및 이점은 OR 게이트 구현예 또는 다단자 논리 게이트의 다른 적절한 구현에 동일하게 적용되도록 수정될 수 있다. 예를 들어, 이진 변수 xl,j ∈{0,1}는 층 l의 j번째 논리 연결자의 부분 상태를 설명할 수 있다. xl,j = 1인 경우, 논리 연결자는 제1 상태에 있다(예: 제1 스위치가 인버터에 연결됨). xl,j = 0인 경우, 논 리 연결자는 제2 상태에 있다(예: 제1 스위치가 단락 회로에 연결됨). 층 l의 j번째 논리 연결 자의 상보적 부분 상태를 설명하는 이진 변수 yl,j ∈{0,1}의 경우, yl,j = 1이면 논리 연결자는 제3 상태를 가진다(예: 제2 스위치가 개방 회로를 구현함). yl,j = 0이면 논리 연결자는 xl,j에 의존하는 상태를 가진다(예: 제1 스위치의 상태에 의존함). 따라서, 다단자 논리 게이트의 입력 단자에서의 논리 연결 자의 상태는 다음과 같은 부등식 세트를 만족해야 한다: 수학식 4"}
{"patent_id": "10-2024-7040740", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "수학식 4에서, il,j는 다단자 논리 게이트의 입력 단자에 적용되는 입력이고 i'l,j는 논리 연결자에 적 용되는 입력이다. 수학식 4의 부등식 세트는 신경망에서 논리 연결자의 상태를 완전히 설명할 수 있 다. ILP를 통한 학습 프로세스는 수학식 4의 부등식 세트를 기반으로 설명될 수 있다. 예를 들어, I ∈ {I}에 대해, 입력 i1,1,...,i1,12는 I의 구성요소와 같게 설정된다. 이어서 제1 층의 출력 o1,1, ...., o1,4가 평가된다. 제1 층 의 입력 i1,1,...,i1,12 및 출력 o1,1, ...., o1,4는 논리 연결자를 포함하지 않으므로, 입력 i1,1,...,i1,12 및 출력 o1,1, ...., o1,4는 다음 방정식에 들어갈 매개변수이다. 제2 층에서, 나머지 다단자 논리 게이트가 유사하게 동작하므로 첫 번째 다단자 게이트를 자세히 설명할 것이다. 입력 i'2,1,...,i'2,4는 입력 i'2,1,...,i'2,4가 출력 o1,1,...,o1,4에 직접 연결되어 있으므로 o1,1,...,o1,4로 설정될 수 있다. 입력 i'2,1,...,i'2,4는 논리 연결자의 상태 x2,1,...,x2,4 및 y2,1,...,y2,4를 통해 수학식 4의 부등식을 사용하여 입력 i2,1,...,i2,4에 연결될 수 있다. 다단자 게이트의 출력 o2,1은 수학식 3을 사용하여 입력 i2,1,...,i2,4와 다음과 같이 연결될 수 있다: 수학식 5"}
{"patent_id": "10-2024-7040740", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "마지막 다단자 게이트에 대해서도 유사한 프로세스가 사용될 수 있으며, 여기서 제2 층의 출력 o2,1,...,o2,3은 논리 연결자의 입력 i'3,1,...,i'3,3에 연결되고, 이는 다시 수학식 4의 부등식을 통해 다단 자 게이트의 입력 i3,1,...,i3,3에 연결되며, 마지막으로 다단자 게이트의 입력은 수학식 4의 부등식을 통해 출력 o3,1에 연결될 수 있다. 출력 o3,1은 입력 I ∈{I}에 대응하는 Τ ∈ {Τ}로 설정된다. 따라서, 각 쌍 (I, Τ)에 대해, 학습 프로세스는 입력을 신경망을 통해 전파하고 동시에 출력을 신경망 을 통해 역전파하는 ILP 부등식의 세트를 생성하는 것을 포함할 수 있다. 예를 들어, 신경망의 층 이 부등식에 의해 연결되어 있기 때문에, 이전 층의 출력과 후속 층의 입력 모두가 현재 층 을 이전 및 후속 층에 연결하는 논리 연결자의 상태에 영향을 미칠 것이다. 따라서, 모든 쌍 (I, Τ)에 대한 ILP를 동시에 해결함으로써, 학습 프로세스는 함수 Τ = Τ(I)를 재현하는 논리 연결자의 구성을 반환할 것이다. 대규모 신경망의 경우, 극도로 큰 ILP 문제를 생성하는 대신, 무작위로 추출된 쌍 (I, Τ)의 부분집합을 해결하고 학습 프로세스가 임계 정확도에 도달할 때까지 여러 에포크에서 이 프로세스를 반복하는 미니배치 방법이 사용될 수 있다. 애플리케이션 데이터 마이닝, 이미지 인식 및 신호 인식 등의 애플리케이션을 위한 신경망의 채택은 변수와 패턴 간의 복잡한 비선형 관계를 검출할 필요성이 있기 때문에 신경망 시장의 이러한 성장을 주도하고 있다. 실제로, 현재 및 미 래의 컴퓨팅 노력을 지원하기 위해 더 효율적이고 더 낮은 에너지의 디지털 신경망 아키텍처에 대한 큰 필요성 이 있다. 다양한 산업(예: 핀테크, IT, 생명과학, 제조, 정부 및 국방, 운송 물류) 전반에 걸쳐 큰 상업적 응용이 있다. 생성된 데이터의 쉬운 유지보수, 비용 효율성, 확장성 및 효과적인 관리와 같은 이점으로 인해 디지털 신경망 솔루션의 클라우드 기반 학습 및 엣지 배포의 채택이 증가할 것으로 예상된다. 여기에 설명된 디지털 신경망은 이 시장을 혁신할 수 있는 심각한 잠재력을 가지고 있으며 초기 채택자에게 전략적 경쟁 우위를 제공할 수 있다. 디지털 신경망의 평가 함수 f를 디지털 신경망에 매핑하는 논리 연결자의 구성을 찾기 위한 학습을 사용하여, 디지털 신경 망은 스위치의 상태가 학습 결과를 따르도록 프로그래밍될 수 있다. 디지털 신경망이 재학습될 수 있는 구현에서, 디지털 신경망의 학습 업데이트는 단순히 스위치의 상태를 재프로그래밍함으로써구현될 수 있다. 이는 예를 들어, 더 많은 레이블된 데이터를 사용할 수 있는 경우 오프라인 학습을 허용하고 업데이트를 구현하기 위한 스위치의 간단한 재구성을 가능하게 한다. 스위치가 설정되면, 디지털 신 경망은 가능한 모든 입력 x에 대해 평가될 준비가 된다. 설계에 의해, 디지털 신경망의 평가는 단일 클럭 사이클에서 수행될 수 있다. 더욱이, 다단자 논리 게이트를 설계하기 위해 CMOS 기술을 사용함으로써, 평가를 위한 전력과 에너지는 현재의 신경망보다 몇 차수 더 작다. 실제로, 메모리로부터 처리 유닛(예: 디지털 신경망)으로의 데이터 이동이 없기 때문에(단지 입력을 가져오고 출력을 반환하는 것만), CMOS 기술은 극도로 낮은 전력의 다단자 논리 게이트 구현을 가능하게 한다. 디지털 신경망의 이론적 측면과 실제 성능은 확립된 벤치마크에 대해 분석될 수 있다. 특정 응용(예: 분류, 예측 분석, 이미지 인식 등)에 대한 게이트, 트랜지스터 및 상호 연결 복잡성 측면에서의 크기가 정량화 될 수 있다. 이를 위해, 주어진 토폴로지와 입력 및 출력 크기에 대해, 범용성을 달성 및/또는 보장하기 위한 최소 층의 수가 결정될 수 있다. 확립된 벤치마크에서 측정된 정확도 측면에서의 학습 효율성이 평가될 수 있다. 디지털 신경망을 효율적으로 학습시키기 위해, 가상 멤컴퓨팅 머신이 사용될 수 있다. 일부 구현예 에서, 학습은 전체 학습 세트로 수행될 수 있으며, 또한 미니배치를 사용하여 해결될 ILP의 크기를 줄일 수 있 는데, 이는 특정 조건에서 학습의 속도 향상을 가능하게 할 수 있기 때문이다. 에너지/전력 및 속도 측면에서의 성능이 평가될 수 있다. 이는 CMOS 기술의 구현을 고려하여 평가될 수 있다. 학습된 디지털 신경망 여기에서 논의된 바와 같이, 디지털 신경망은 함수 f1을 디지털 신경망에 매핑하는 논리 연결자(11 0)의 제1 상태 세트를 결정하기 위해 제1 ILP 문제 세트를 해결함으로써 학습될 수 있다. 디지털 신경망은 또한 제2 함수 f2에 대응하는 제2 ILP 문제 세트를 해결함으로써 논리 연결자의 제2 상태 세트를 결정하여 제2 함수 f2를 디지털 신경망에 매핑하도록 재학습될 수 있다. 따라서, 디지털 신경망은 대응하는 ILP 문제 세트를 생성함으로써 실질적으로 임의의 함수 f를 구현하도록 재학습될 수 있다. 그러나, 특정 애플리케이션의 경우 디지털 신경망을 재학습할 필요가 없을 수 있다. 예를 들어, 디지털 신 경망이 단일 함수 f를 구현하도록 설계된 경우, 디지털 신경망을 재학습할 필요가 전혀 없을 수 있다. 따라서, 각 논리 연결자에 병렬 경로(예: 도 2의 인버터, 개방 회로 및 단락 회로) 또는 스위치 각각을 포함할 필요는 없다. 예를 들어, 주어진 논리 연결자의 학습된 상태가 인버터 경로인 경우, 상기 논리 연결자는 다른 구성요소 없이 인버터만을 포함할 수 있다. 논리 연결 자의 학습된 상태에 대응하는 구성요소만으로 논리 연결자를 구현함으로써, 디지털 신경망은 현 저히 적은 수의 구성요소로 구현될 수 있다. 특정 구현에서, 디지털 신경망은 예를 들어 특정 장치(예: 자율 주행 차량)에 통합될 때 단일 칩 상에 구 현될 수 있다. 디지털 신경망이 전적으로 CMOS 기술로 구현될 수 있기 때문에, 디지털 신경망은 폰 노이만 아키텍처에 의존하는 다른 신경망보다 칩 상에 더 쉽게 구현될 수 있다. 유리하게도, 이는 디지털 신경 망이 전통적인 신경망에 비해 다양한 서로 다른 애플리케이션에 더 쉽게 채택될 수 있게 한다. 여기에 개시된 디지털 신경망은 빠른 연산을 제공할 수 있다. 디지털 신경망은 단일 칩 상에 구현될 수 있다. 특정 경우에, 입력이 로드되고, 디지털 신경망이 단일 클럭 사이클에서 함수를 연산한 다음, 출력이 읽혀질 수 있다. 이는 특정 기존 신경망 함수 연산에 비해 속도면에서 상당한 개선이다. 여기에 개시된 디지털 신경망은 또한 특정 기존 신경망 연산에 비해 적은 에너지를 사용할 수 있다. 결론 전술한 개시 내용은 본 개시를 정확한 형태나 특정 사용 분야로 제한하려는 의도가 아니다. 따라서, 본 개시의 다양한 대체 구현예 및/또는 수정이 여기에서 명시적으로 설명되었거나 암시되었는지 여부와 관계없이, 본 개시 의 관점에서 가능하다고 고려된다. 이와 같이 본 개시의 구현예를 설명하였으므로, 당업자는 형태와 세부사항의 변경이 본 개시의 범위를 벗어나지 않고 이루어질 수 있음을 인식할 것이다. 따라서, 본 개시는 청구항에 의해 서만 제한된다. 전술한 명세서에서, 본 개시는 특정 구현예를 참조하여 설명되었다. 그러나, 당업자가 이해하듯이, 여기에 개시 된 다양한 구현예는 본 개시의 정신과 범위를 벗어나지 않고 다양한 다른 방식으로 수정되거나 달리 구현될 수 있다. 따라서, 이 설명은 예시적인 것으로 간주되어야 하며 여기에 교시된 이점을 가진 당업자에게 다양한 구현 예를 만들고 사용하는 방식을 가르치기 위한 것이다. 여기에서 보여지고 설명된 개시 형태들은 대표적인 구현예로 간주되어야 한다. 여기에서 대표적으로 도시되고 설명된 것들에 대해 동등한 요소, 재료, 공정 또는 단계 가 대체될 수 있음을 이해해야 한다. 더욱이, 본 개시의 특정 특징은 다른 특징의 사용과 독립적으로 활용될 수 있으며, 이는 모두 당업자가 본 개시의 설명의 이점을 가진 후에 명백할 것이다. 본 개시를 설명하고 청구하는 데 사용된 '포함하는(including, comprising)', '통합하는(incorporating)', '로 구성된(consisting of)', '갖 는(having)', '인(is)'과 같은 표현들은 비배타적인 방식으로 해석되어야 한다. 즉, 명시적으로 설명되지 않은 아이템, 구성성분 또는 요소들도 포함될 수 있음을 허용하는 것이다. 또한, 단수형에 대한 언급은 복수형을 포 함하는 것으로 해석되어야 한다. 또한, 여기에 개시된 다양한 구현예는 예시적이고 설명적인 의미로 받아들여져야 하며, 어떤 방식으로도 본 개 시를 제한하는 것으로 해석되어서는 안 된다. 모든 결합 참조(예: 부착된, 고정된, 결합된, 연결된 등)는 단지 본 개시의 이해를 돕기 위해서만 사용되며, 제한을 생성하지 않을 수 있으며, 특히 여기에 개시된 시스템 및/또 는 방법의 위치, 방향 또는 사용에 관한 제한을 생성하지 않는다. 따라서, 결합 참조가 있는 경우, 이는 광범위 하게 해석되어야 한다. 더욱이, 그러한 결합 참조가 반드시 두 요소가 서로 직접 연결되어 있음을 의미하는 것 은 아니다. 추가로, \"제1\", \"제2\", \"제3\", \"주요\", \"보조\", \"주\", 또는 다른 모든 수치 용어와 같은 모든 수치 용어는 또한 단지 식별자로서만 취급되어야 하며, 다른 요소, 구현예, 변형 및/또는 수정에 대한 특정 요소, 구 현예, 변형 및/또는 수정의 순서, 또는 선호도에 대해 어떠한 제한도 생성하지 않는다. 또한, 도면/도에 도시된 요소 중 하나 이상이 특정 애플리케이션에 따라 유용한 대로 더 분리되거나 통합된 방 식으로 구현되거나, 심지어 제거되거나 작동 불가능하게 만들어질 수 있음을 이해할 것이다."}
{"patent_id": "10-2024-7040740", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 개시의 양태에 따른 디지털 신경망을 도시하는 회로도이다. 도 2는 본 개시의 양태에 따른 다단자 논리 게이트 및 이에 연결된 복수의 논리 연결자의 구현예를 도시한다. 도 3은 본 개시의 양태에 따른 다단자 논리 게이트 및 이에 연결된 복수의 논리 연결자의 다른 구현예를 도시한 다. 도 4는 본 개시의 양태에 따른 다단자 NOR 게이트의 구현예를 도시한다. 도 5는 본 개시의 양태에 따른 임계값을 가지는 다단자 NOR 게이트의 구현예를 도시한다. 도 6은 본 개시의 양태에 따라 th 및 th+1 스위치가 폐쇄된 상태에서 평가된 v/VDD의 그래프이다. 도 7은 본 개시의 양태에 따른 예시적인 신경망을 도시한다. 도 8A 및 도 8B는 본 개시의 양태에 따른 논리 연결자의 구현예들을 도시한다."}
