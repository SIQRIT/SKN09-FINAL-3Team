{"patent_id": "10-2024-7018268", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0096625", "출원번호": "10-2024-7018268", "발명의 명칭": "AR 디바이스 및 AR 디바이스 제어 방법", "출원인": "엘지전자 주식회사", "발명자": "장성권"}}
{"patent_id": "10-2024-7018268", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "문자 입력을 확인하는 보이스 픽업 센서; 카메라를 통하여 눈동자 움직임을 감지하는 아이 트래킹부; 상기 문자를 유추하는 입술 모양 트래킹부; 및상기 유추된 문자에 기초하여 단어를 완성하는 자동 완성부를 포함하는 것을 특징으로 하는, AR 디바이스."}
{"patent_id": "10-2024-7018268", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1 항에 있어서, 상기 보이스 픽업 센서는 사용자의 턱 관절의 움직임(Bone Conduction)에 기초하여 상기 문자 입력을 확인하는것을 특징으로 하는 AR 디바이스."}
{"patent_id": "10-2024-7018268", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 2 항에 있어서, 상기 입술 모양 트래킹부는 IR 카메라 및 IR 일루미네이터를 통하여 상기 문자를 유추하는 것을 특징으로 하는AR 디바이스."}
{"patent_id": "10-2024-7018268", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 3 항에 있어서, 상기 입술 모양 트래킹부는 상기 아이 트래킹부가 상기 눈동자 움직임을 감지하는 시간에 기초하여 상기 문자를유추하는 것을 특징으로 하는 AR 디바이스."}
{"patent_id": "10-2024-7018268", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제 4 항에 있어서, 상기 IR 카메라 및 상기 IR 일루미네이터는 상기 사용자의 입술을 기 설정된 각도에서 촬영하도록 배치되는 것을 특징으로 하는 AR 디바이스."}
{"patent_id": "10-2024-7018268", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제 5 항에 있어서, 상기 AR 디바이스는 디스플레이부를 더 포함하고, 상기 디스플레이부는 문자 입력기를 출력하고, 상기 감지된 눈동자 움직임에 기초하여 상기 문자 입력기 상에 포인터를 더 출력하는것을 특징으로 하는 AR 디바이스."}
{"patent_id": "10-2024-7018268", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제 6 항에 있어서, 상기 디스플레이부는 상기 자동 완성부를 통하여 완성된 단어를 출력하는 것을 특징으로 하는, AR 디바이스."}
{"patent_id": "10-2024-7018268", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제 1 항에 있어서, 공개특허 10-2024-0096625-3-상기 AR 디바이스는 입력부를 더 포함하고, 상기 입력부를 통하여 수신되는 제어 신호에 기초하여 상기 보이스 픽업 센서가 문자 입력 확인을 시작하는 것을 특징으로 하는 AR 디바이스."}
{"patent_id": "10-2024-7018268", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제 1 항에 있어서, 상기 AR 디바이스는 메모리 유닛을 더 포함하고, 상기 입술 모양 트래킹부는 상기 메모리 유닛에 포함된 데이터베이스에 기초하여 상기 문자를 유추하는 것을 특징으로 하는 AR 디바이스."}
{"patent_id": "10-2024-7018268", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제 1 항에 있어서, 상기 입술 모양 트래킹부는 인공지능을 이용하여 상기 문자를 유추하는 것을 특징으로 하는 AR 디바이스."}
{"patent_id": "10-2024-7018268", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "사용자의 턱 관절의 움직임에 기초하여 문자 입력을 확인하는 단계; 카메라를 통하여 눈동자 움직임을 감지하는 단계; IR 카메라 및 IR 일루미네이터를 통하여 상기 문자를 유추하는 단계; 및 상기 유추된 문자에 기초하여 단어를 완성하는 단계를 포함하는, AR 디바이스의 제어 방법."}
{"patent_id": "10-2024-7018268", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 문자 입력을 확인하는 보이스 픽업 센서; 카메라를 통하여 눈동자 움직임을 감지하는 아이 트래킹부; 상기 문자를 유추하는 입술 모양 트래킹부; 및 상기 유추된 문자에 기초하여 단어를 완성하는 자동 완성부를 포 함하는 것을 특징으로 하는, AR 디바이스를 제공한다."}
{"patent_id": "10-2024-7018268", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 AR 디바이스 및 AR 디바이스의 제어 방법에 관한 것이다."}
{"patent_id": "10-2024-7018268", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "메타버스란 가상을 의미하는 메타(meta)와 현실 세계를 의미하는 유니버스(universe)의 합성어로, 현실 세계와 같은 사회/경제/문화 활동이 이뤄지는 3차원 가상세계를 일컫는 말이다. 메타버스에서는 사용자들이 자신만의 아바타를 만들어 다른 사용자와 소통하고, 경제 활동을 벌이는 등 일상 생 활이 가상 세계에서 구현될 수 있다. 기존 게임 서비스의 경우, 약관상 게임 내 아이템 소유권이 콘텐츠 회사에 있는 것과는 달리 블록 체인에 기반 한 메타버스는 가상 세계 속 아이템에 대체불가능토큰(Non-Fungible Token, NFT)과 암호 화폐 등으로 구현될 수 있다. 즉, 실제 콘텐츠 소유권을 유저가 갖게 된다. 현재 게임사들은 블록 체인 기반의 메타버스 구축에 적극 나서고 있다. 실제로 최근 뉴욕 증시에 상장한 미국 메타버스 게임기업 로블록스가 가상 화폐 도입을 결정하면서 많은 이들의 이목을 집중시킨 바 있다. 현재, 로블 록스는 전 세계 4억명 이상의 이용자를 확보한 상태다. 최근 메타버스가 모바일 디바이스에 도입됨에 따라 스마트폰 및 테블릿 등에 구비된 디스플레이를 기반으로 사 용자와 가상 공간 내 아바타를 통한 상호 인터랙션 뿐만 아니라 메타버스 유저 간 가상 공간에서 자신의 아바타 를 통해 상호 커뮤니케이션을 제공할 수 있게 되었다. 이러한 아바타 간 상호 인터랙션을 위하여 사용자는 빠르고 정확한 문자를 손쉽게 입력할 필요가 있다. 이에 따라, 메타버스에 접속하는 디바이스로서 선명하고 가벼운 광학계로 구성됨과 동시에 오피스 환경이나 SNS 에 적합한 인터랙션 등이 가능한 제품의 개발 필요성이 높아지고 있다."}
{"patent_id": "10-2024-7018268", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 2, "content": "발명의 내용"}
{"patent_id": "10-2024-7018268", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 전술한 문제 및 다른 문제를 해결하는 것을 목적으로 한다. 본 발명은 AR 디바이스 및 AR 디바이스의 제어 방법을 통하여 문자 입력 시 보다 정확하고 정교한 문자 입력 인 터페이스를 제공하는 것을 목적으로 한다."}
{"patent_id": "10-2024-7018268", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 일 측면에 따르면, 문자 입력을 확인하는 보이스 픽업 센서; 카메라를 통하여 눈동자 움직임을 감지 하는 아이 트래킹부; 상기 문자를 유추하는 입술 모양 트래킹부; 및 상기 유추된 문자에 기초하여 단어를 완성 하는 자동 완성부를 포함하는 것을 특징으로 하는, AR 디바이스를 제공한다. 본 발명의 일 측면에 따르면, 상기 보이스 픽업 센서는 사용자의 턱 관절의 움직임(Bone Conduction)에 기초하 여 상기 문자 입력을 확인하는 것을 특징으로 한다. 본 발명의 일 측면에 따르면, 상기 입술 모양 트래킹부는 IR 카메라 및 IR 일루미네이터를 통하여 상기 문자를 유추하는 것을 특징으로 한다. 본 발명의 일 측면에 따르면, 상기 입술 모양 트래킹부는 상기 아이 트래킹부가 상기 눈동자 움직임을 감지하는 시간에 기초하여 상기 문자를 유추하는 것을 특징으로 한다. 본 발명의 일 측면에 따르면, 상기 IR 카메라 및 상기 IR 일루미네이터는 상기 사용자의 입술을 기 설정된 각도 에서 촬영하도록 배치되는 것을 특징으로 한다. 본 발명의 일 측면에 따르면, 상기 AR 디바이스는 디스플레이부를 더 포함하고, 상기 디스플레이부는 문자 입력 기를 출력하고, 상기 감지된 눈동자 움직임에 기초하여 상기 문자 입력기 상에 포인터를 더 출력하는 것을 특징 으로 한다. 본 발명의 일 측면에 따르면, 상기 디스플레이부는 상기 자동 완성부를 통하여 완성된 단어를 출력하는 것을 특 징으로 한다. 본 발명의 일 측면에 따르면, 상기 AR 디바이스는 입력부를 더 포함하고, 상기 입력부를 통하여 수신되는 제어 신호에 기초하여 상기 보이스 픽업 센서가 문자 입력 확인을 시작하는 것 을 특징으로 한다. 본 발명의 일 측면에 따르면, 상기 AR 디바이스는 메모리 유닛을 더 포함하고, 상기 입술 모양 트래킹부는 상기 메모리 유닛에 포함된 데이터베이스에 기초하여 상기 문자를 유추하는 것을 특 징으로 한다. 본 발명의 일 측면에 따르면, 상기 입술 모양 트래킹부는 인공지능을 이용하여 상기 문자를 유추하는 것을 특징 으로 한다. 본 발명의 일 측면에 따르면, 사용자의 턱 관절의 움직임에 기초하여 문자 입력을 확인하는 단계; 카메라를 통 하여 눈동자 움직임을 감지하는 단계; IR 카메라 및 IR 일루미네이터를 통하여 상기 문자를 유추하는 단계; 및 상기 유추된 문자에 기초하여 단어를 완성하는 단계를 포함하는, AR 디바이스의 제어 방법을 제공한다."}
{"patent_id": "10-2024-7018268", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명에 따른 AR 디바이스 및 그 제어 방법의 효과에 대해 설명하면 다음과 같다. 본 발명의 실시 예들 중 적어도 하나에 의하면, 정숙을 요구하는 환경에서 문자를 정교하게 입력할 수 있다는 장점이 있다. 본 발명의 실시 예들 중 적어도 하나에 의하면, 오류 수정 및 자동 완성으로 인해 문자 및 문장 입력 시간을 단 축할 수 있다는 장점이 있다. 본 발명의 적용 가능성의 추가적인 범위는 이하의 상세한 설명으로부터 명백해질 것이다. 그러나 본 발명의 사상 및 범위 내에서 다양한 변경 및 수정은 당업자에게 명확하게 이해될 수 있으므로, 상세 한 설명 및 본 발명의 바람직한 실시 예와 같은 특정 실시 예는 단지 예시로 주어진 것으로 이해되어야 한다."}
{"patent_id": "10-2024-7018268", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 첨부된 도면을 참조하여 본 명세서에 개시된 실시 예를 상세히 설명하되, 도면 부호에 관계없이 동일하거 나 유사한 구성요소는 동일한 참조 번호를 부여하고 이에 대한 중복되는 설명은 생략하기로 한다. 이하의 설명 에서 사용되는 구성요소에 대한 접미사 \"모듈\" 및 \"부\"는 명세서 작성의 용이함만이 고려되어 부여되거나 혼용 되는 것으로서, 그 자체로 서로 구별되는 의미 또는 역할을 갖는 것은 아니다. 또한, 본 명세서에 개시된 실시 예를 설명함에 있어서 관련된 공지 기술에 대한 구체적인 설명이 본 명세서에 개시된 실시 예의 요지를 흐릴 수 있다고 판단되는 경우 그 상세한 설명을 생략한다. 또한, 첨부된 도면은 본 명세서에 개시된 실시 예를 쉽게 이 해할 수 있도록 하기 위한 것일 뿐, 첨부된 도면에 의해 본 명세서에 개시된 기술적 사상이 제한되지 않으며, 본 발명의 사상 및 기술 범위에 포함되는 모든 변경, 균등물 내지 대체물을 포함하는 것으로 이해되어야 한다. 제1, 제2 등과 같이 서수를 포함하는 용어는 다양한 구성요소들을 설명하는데 사용될 수 있지만, 상기 구성요소 들은 상기 용어들에 의해 한정되지는 않는다. 상기 용어들은 하나의 구성요소를 다른 구성요소로부터 구별하는 목적으로만 사용된다. 어떤 구성요소가 다른 구성요소에 \"연결되어\" 있다거나 \"접속되어\" 있다고 언급된 때에는, 그 다른 구성요소에 직접적으로 연결되어 있거나 또는 접속되어 있을 수도 있지만, 중간에 다른 구성요소가 존재할 수도 있다고 이 해되어야 할 것이다. 반면에, 어떤 구성요소가 다른 구성요소에 \"직접 연결되어\" 있다거나 \"직접 접속되어\" 있 다고 언급된 때에는, 중간에 다른 구성요소가 존재하지 않는 것으로 이해되어야 할 것이다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 출원에서, \"포함한다\" 또는 \"가지다\" 등의 용어는 명세서상에 기재된 특징, 숫자, 단계, 동작, 구성요소, 부 품 또는 이들을 조합한 것이 존재함을 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성요소, 부품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되 어야 한다. 도 1은 본 발명의 일 실시예에 따른 AR 디바이스를 HMD 타입으로 구현한 실시예를 도시하고 있다. 도 1에 도시된 HMD 타입의 AR 디바이스(100a)는, 커뮤니케이션 유닛, 컨트롤 유닛, 메모리 유닛 , I/O 유닛(140a), 센서 유닛(140b), 그리고 파워 공급 유닛(140c) 등을 포함한다. 여기에서, 커뮤니케이션 유닛은 유무선 통신 기술을 이용하여 다른 AR 디바이스나 AR 서버 등의 외부 장치 들과 데이터를 송수신할 수 있다. 예컨대, 커뮤니케이션 유닛는 외부 장치들과 센서 정보, 사용자 입력, 학습 모델, 제어 신호 등을 송수신할 수 있다. 이때, 커뮤니케이션 유닛가 이용하는 통신 기술에는 GSM(Global System for Mobile communication), CDMA(Code Division Multi Access), LTE(Long Term Evolution), WLAN(Wireless LAN), Wi-Fi(Wireless-Fidelity), 블루투스(Bluetooth™RFID(Radio Frequency Identification), 적외선 통신(Infrared Data Association; IrDA), ZigBee, NFC(Near Field Communication) 등이 있다. 특히, XR 디바이스(10a)내 커뮤니케이션 유닛은 이동 단말기(100b)와 유무선 통신이 이루어 진 다. 컨트롤 유닛은 상기 응용 프로그램과 관련된 동작 외에도, 통상적으로 AR 디바이스(100a)의 전반적인 동작 을 제어한다. 컨트롤 유닛은 AR 디바이스(100a)의 구성요소들을 통해 입력 또는 출력되는 신호, 데이터, 정보 등을 처리하거나 메모리 유닛에 저장된 응용 프로그램을 구동함으로써, 사용자에게 적절한 정보 또는 기능을 제공 또는 처리할 수 있다. 또한, AR 디바이스(100a)의 컨트롤 유닛은 기본적인 제어 기능을 수행 하는 모듈로 배터리 소모가 크거나 처리해야할 양이 방대한 경우 연결되어 있는 외부 이동 단말기(100b)를 통하 여 수행할 수 있다. 이에 대하여는 이하, 도 3a 및 도 3b를 통하여 상세히 설명하도록 한다. 메모리 유닛은 AR디바이스(100a)의 다양한 기능을 지원하는 데이터를 저장한다. 메모리 유닛는 AR디 바이스(100a)에서 구동되는 다수의 응용 프로그램(application program 또는 애플리케이션(application)), 이 동 단말기의 동작을 위한 데이터들, 명령어들을 저장할 수 있다. 이러한 응용 프로그램 중 적어도 일부는, 무선 통신을 통해 외부 서버로부터 다운로드 될 수 있다. 또한 이러한 응용 프로그램 중 적어도 일부는, AR디바 이스(100a)의 기본적인 기능을 위하여 출고 당시부터 AR디바이스(100a)상에 존재할 수 있다. 한편, 응용 프로그 램은, 메모리 유닛에 저장되고, AR디바이스(100a) 상에 설치되어, 컨트롤 유닛에 의하여 상기 이동 단말기의 동작(또는 기능)을 수행하도록 구동될 수 있다. I/O 유닛(140a)은 Input 유닛과 Output 유닛의 결합으로 입력부와 출력부를 모두 포함할 수 있다. 여기에서, 입 력부는, 영상 신호 입력을 위한 카메라 또는 영상 입력부, 오디오 신호 입력을 위한 마이크로폰, 또는 오디오 입력부, 사용자로부터 정보를 입력받기 위한 사용자 입력부(예를 들어, 터치키(touch key), 푸시키(mechanical key) 등)를 포함할 수 있다. 입력부에서 수집한 음성 데이터나 이미지 데이터는 분석되어 사용자의 제어명령으 로 처리될 수 있다. 카메라는 화상 통화모드 또는 촬영 모드에서 이미지 센서에 의해 얻어지는 정지영상 또는 동영상 등의 화상 프 레임을 처리한다. 처리된 화상 프레임은 디스플레이부에 표시되거나 메모리 유닛에 저장될 수 있다. 한편, 복수의 카메라는 매트릭스 구조를 이루도록 배치될 수 있으며, 이와 같이 매트릭스 구조를 이루는 카메라를 통 하여, AR 디바이스(100a)에는 다양한 각도 또는 초점을 갖는 복수의 영상정보가 입력될 수 있다. 또한, 복수의 카메라는 입체영상을 구현하기 위한 좌 영상 및 우 영상을 획득하도록, 스트레오 구조로 배치될 수 있다. 마이크로폰은 외부의 음향 신호를 전기적인 음성 데이터로 처리한다. 처리된 음성 데이터는 AR 디바이스(100a) 에서 수행 중인 기능(또는 실행 중인 응용 프로그램)에 따라 다양하게 활용될 수 있다. 한편, 마이크로폰에는 외부의 음향 신호를 입력 받는 과정에서 발생되는 잡음(noise)을 제거하기 위한 다양한 잡음 제거 알고리즘이 구현될 수 있다. 사용자 입력부는 사용자로부터 정보를 입력받기 위한 것으로서, 사용자 입력부를 통해 정보가 입력되면, 컨트롤 유닛는 입력된 정보에 대응되도록 AR 디바이스(100a) 의 동작을 제어할 수 있다. 이러한, 사용자 입력부는 기계식 (mechanical) 입력수단(또는, 메커니컬 키, 예를 들어, AR 디바이스(100a)의 전·후면 또는 측면에 위치 하는 버튼, 돔 스위치 (dome switch), 조그 휠, 조그 스위치 등) 및 터치식 입력수단을 포함할 수 있다. 일 예 로서, 터치식 입력수단은, 소프트웨어적인 처리를 통해 터치스크린에 표시되는 가상 키(virtual key), 소프트 키(soft key) 또는 비주얼 키(visual key)로 이루어지거나, 상기 터치스크린 이외의 부분에 배치되는 터치 키 (touch key)로 이루어질 수 있다. 한편, 상기 가상키 또는 비주얼 키는, 다양한 형태를 가지면서 터치스크린 상 에 표시되는 것이 가능하며, 예를 들어, 그래픽(graphic), 텍스트(text), 아이콘(icon), 비디오(video) 또는 이 들의 조합으로 이루어질 수 있다. 출력부는 시각, 청각 또는 촉각 등과 관련된 출력을 발생시키기 위한 것으로, 디스플레이부, 음향 출력부, 햅팁 모듈, 광 출력부 중 적어도 하나를 포함할 수 있다. 디스플레이부는 터치 센서와 상호 레이어 구조를 이루거나일체형으로 형성됨으로써, 터치 스크린을 구현할 수 있다. 이러한 터치 스크린은, AR디바이스(100a)와 사용자 사이의 입력 인터페이스를 제공하는 사용자 입력부로써 기능함과 동시에, AR디바이스(100a)와 사용자 사이의 출 력 인터페이스를 제공할 수 있다. 음향 출력부는 호신호 수신, 통화모드 또는 녹음 모드, 음성인식 모드, 방송수신 모드 등에서 무선 통신부로부 터 수신되거나 메모리 유닛에 저장된 오디오 데이터를 출력할 수 있다. 음향 출력부는 AR디바이스(100a)에 서 수행되는 기능(예를 들어, 호신호 수신음, 메시지 수신음 등)과 관련된 음향 신호를 출력하기도 한다. 이러 한 음향 출력부에는 리시버(receiver), 스피커(speaker), 버저(buzzer) 등이 포함될 수 있다. 햅틱 모듈(haptic module) 은 사용자가 느낄 수 있는 다양한 촉각 효과를 발생시킨다. 햅틱 모듈이 발생시키는 촉각 효과의 대표적인 예로는 진동이 될 수 있다. 햅틱 모듈에서 발생하는 진동의 세기와 패턴 등은 사용자의 선택 또는 컨트롤 유닛의 설정에 의해 제어될 수 있다. 예를 들어, 상기 햅틱 모듈은 서로 다른 진동을 합 성하여 출력하거나 순차적으로 출력할 수도 있다. 광출력부는 AR디바이스(100a)의 광원의 빛을 이용하여 이벤트 발생을 알리기 위한 신호를 출력한다. AR디바이스 (100a)에서 발생 되는 이벤트의 예로는 메시지 수신, 호 신호 수신, 부재중 전화, 알람, 일정 알림, 이메일 수 신, 애플리케이션을 통한 정보 수신 등이 될 수 있다. 센서 유닛(140b)은 AR 디바이스(100a) 내 정보, AR 디바이스(100a)를 둘러싼 주변 환경 정보 및 사용자 정보 중 적어도 하나를 센싱하기 위한 하나 이상의 센서를 포함할 수 있다. 예를 들어, 센싱 유닛(140b)는 근접센서 (proximity sensor), 조도 센서(illumination sensor), 터치 센서(touch sensor), 가속도 센서(acceleration sensor), 자기 센서(magnetic sensor), 중력 센서(G-sensor), 자이로스코프 센서(gyroscope sensor), 모션 센 서(motion sensor), RGB 센서, 적외선 센서(IR 센서: infrared sensor), 지문인식 센서(finger scan sensor), 초음파 센서(ultrasonic sensor), 광 센서(optical sensor, 예를 들어, 카메라), 마이크로폰(microphone), 배 터리 게이지(battery gauge), 환경 센서(예를 들어, 기압계, 습도계, 온도계, 방사능 감지 센서, 열 감지 센서, 가스 감지 센서 등), 화학 센서(예를 들어, 전자 코, 헬스케어 센서, 생체 인식 센서 등) 중 적어도 하나를 포 함할 수 있다. 한편, 본 명세서에 개시된 이동 단말기는, 이러한 센서들 중 적어도 둘 이상의 센서에서 센싱되 는 정보들을 조합하여 활용할 수 있다. 파워 공급 유닛(140c)은 컨트롤 유닛의 제어 하에서, 외부의 전원, 내부의 전원을 인가 받아 AR디바이스 (100a)에 포함된 각 구성요소들에 전원을 공급한다. 이러한 파워 공급 유닛(140c)는 배터리를 포함하며, 상기 배터리는 내장형 배터리 또는 교체 가능한 형태의 배터리가 될 수 있다. 상기 각 구성요소들 중 적어도 일부는, 이하에서 설명되는 다양한 실시예들에 따른 AR디바이스(100a)의 동작, 제어, 또는 제어 방법을 구현하기 위하여 서로 협력하여 동작할 수 있다. 또한, 상기 이동 단말기의 동작, 제어, 또는 제어방법은 상기 메모리 유닛에 저장된 적어도 하나의 응용 프로그램의 구동에 의하여 AR디바 이스(100a) 상에서 구현될 수 있다. 도 2는 본 발명의 일 실시예에 따른 AR 디바이스를 AR 글래스 타입으로 구현한 실시예를 도시하고 있다. 도 2에 도시된 바와 같이, AR 글래스는 프레임, 제어부 및 광학 디스플레이부를 포함할 수 있다. 여 기에서, 제어부는 도 1에서 상술한 컨트롤 유닛에 대응할 수 있고, 광학 디스플레이부는 도 1에 서 상술한 I/O 유닛(140a)의 하나의 모듈에 대응할 수 있다. 프레임은 도 2에 도시된 바와 같이, 사용자의 신체 중 안면에 착용되는 안경 형태를 가질 수 있으나, 이에 반드시 한정되는 것은 아니고, 사용자의 안면에 밀착되어 착용되는 고글 등의 형태를 가질 수도 있다. 이와 같은 프레임은 전면 프레임과 제1, 2 측면 프레임을 포함할 수 있다. 전면 프레임은 적어도 하나의 개구부를 구비하고, 제1 수평 방향(x)으로 연장될 수 있으며, 제1, 2 측면 프레임은 전면 프레임과 교차하는 제2 수평 방향(y)으로 연장되어 서로 나란하게 연장될 수 있다. 제어부는 사용자에게 보여질 이미지 또는 이미지가 연속되는 영상을 생성할 수 있다. 이와 같은 제어 부에는 이미지를 발생시키는 이미지 소스와 이미지 소스에서 발생된 빛을 확산 및 수렴하는 복수의 렌즈 등을 포함할 수 있다. 이와 같이 제어부에서 생성되는 이미지는 제어부와 광학 디스플레이부 사이에 위치하는 가이드 렌즈(P200)을 통해 광학 디스플레이부로 출사될 수 있다. 이와 같은 제어부는 제1, 2 측면 프레임 중 어느 하나의 측면 프레임에 고정될 수 있다. 일례로, 제어부 는 어느 하나의 측면 프레임 내측 또는 외측에 고정되거나, 어느 하나의 측면 프레임의 내부에 내장되어 일체로 형성될 수 있다. 광학 디스플레이부는 제어부에서 생성된 이미지가 사용자에게 보여지도록 하는 역할을 수행할 수 있으며, 이미지가 사용자에게 보여지도록 하면서, 개구부를 통하여 외부 환경을 볼 수 있도록 하기 위하여, 반투명 재질로 형성될 수 있다. 이와 같은 광학 디스플레이부는 전면 프레임에 포함된 개구부에 삽입되어 고정되거나, 개부구의 배면 [즉 개구부와 사용자 사이]에 위치하여, 전면 프레임에 고정되어 구비될 수 있다. 본 발명에서는 일례 로, 광학 디스플레이부가 개구부의 배면에 위치하여, 전면 프레임에 고정된 경우를 일예로 도시하였 다. 이와 같은 AR 디바이스는 도 2에 도시된 바와 같이, 제어부에서 이미지에 대한 이미지를 광학 디스플레이 부의 입사 영역(S1)으로 입사시키면, 이미지광이 광학 디스플레이부를 통하여, 광학 디스플레이부 의 출사 영역(S2)으로 출사되어, 제어부에서 생성된 이미지를 사용자에게 보여지도록 할 수 있다. 이에 따라, 사용자는 프레임의 개구부를 통하여 외부 환경을 보면서 동시에 제어부에서 생성된 이미지를 함께 볼 수 있다. 도 3a 및 도 3b는 본 발명의 일 실시예에 따른 AR 디바이스의 개념도를 설명하는 도면이다. 도 3a를 참조하면, 본 발명의 일 실시예에 따른 AR 디바이스는 다양한 구조를 가질 수 있다. 예를 들어, AR 디 바이스는 마이크로폰과 스피커를 포함하는 넥밴드와 디스플레이부와 프로세싱부를 포함하는 글래스를 포함할 수 있다. 이때, AR 디바이스의 내부 입력은 글래스의 버튼을 통하여, 외부 입력은 와치 형태 또는 피젯 스피너 형태의 컨트롤러를 통하여 수행될 수 있다. 또한, 도면에 도시되어 있지는 않으나 AR디바이스 는 LTE 모뎀 및 공간 인식 기술 내재화를 위하여 배터리 분리 구조를 가질 수 있다. 이 경우, AR 디바이스는 배 터리를 분리함으로써 보다 가벼운 글래스를 구현할 수 있다. 다만, 이러한 AR 디바이스의 경우, 프로세싱부가 글래스에 포함되어 있기 때문에 여전히 글래스의 무 게의 경량화가 이루어질 수 없게 된다. 이러한 점을 보완하기 위하여 도 3b를 참조하면, 본 발명의 일 실시예에 따른 AR 디바이스는 이동 단말기(100 b)의 프로세싱부를 이용하고, AR 디바이스는 단순히 디스플레이부를 제공하는 글래스로 구현될 수 있다. 이때, AR 디바이스의 내부 입력은 글래스의 버튼을 통하여, 외부 입력은 링 형태의 컨트롤러를 통하 여 수행될 수 있다. AR 디바이스는 서비스에 따라 종류, 속도, 양과 정확도를 고려하여 입력 장치와 기술을 선택해야 한다. 구체적 으로, AR 디바이스가 제공하는 서비스가 게임인 경우, 인터랙션의 입력은 방향 키, 뮤트 On/Off 선택 키, 화면 스크롤 키가 필요하며, 장치로는 조이스틱과 스마트폰을 사용할 수 있다. 즉, 인체에 맞는 게임 키(key)를 설계 해야 하며, 스마트폰으로 간편하게 키를 입력할 수 있어야 한다. 따라서, 제한된 종류로 빠른 속도 및 적은 양 의 입력이 요구된다. 반면, AR 디바이스가 제공하는 서비스가 영화 또는 유튜브와 같은 동영상 재생 서비스인 경우, 인터랙션의 입력 은 방향 키, 플레이 백(재생, 이동) 키, 뮤트 On/Off 선택 키, 화면 스크롤 키가 필요하며, 장치로는 글래스, 외부 컨트롤러, 스마트 워치 등을 사용할 수 있다. 즉, 콘텐츠 선택을 위한 방향 키, 재생, 멈춤, 볼륨 조정 키 를 입력할 수 있어야 한다. 따라서, 제한된 종류로 보통 속도 및 적은 양의 입력이 요구된다. 또 다른 예로, AR 디바이스가 제공하는 서비스가 드론(drone)인 경우, 인터랙션의 입력은 드론 조정용 방향 키, 특수 기능 On/Off 키, 화면 제어 키가 필요하며, 장치로는 전용 컨트롤러 및 스마트폰을 사용할 수 있다. 즉, 조정 모드와, 좌(스로틀, 러더), 우(피치, 에일러론) 등을 특징으로 하며, 제한된 종류, 보통 속도 및 보통 양 의 입력이 요구된다. 마지막으로, AR 디바이스가 제공하는 서비스가 메타버스, 오피스 및 SNS인 경우, 인터랙션의 입력은 언어별 다 양한 문자(영문, 한글, 한자, 아랍어 등)가 필요하며, 장치로는 가상 키보드 및 외장 키보드를 사용할 수 있다. 또한, 발광 방식의 가상 키보드는 입력의 정확도가 떨어지고 느리며, 외장 키보드는 화면에 가려 보이지 않기 때문에 손가락의 감각으로 입력해야만 한다. 즉, 다양한 언어 종류를 제공해야 하며 빠른 속도, 많은 양과 정확한 입력이 요구된다. 이에 따라, 본 발명에서는 AR 디바이스가 제공하는 서비스가 메타버스인 경우에 문자 입력 방안에 대하여 상세 히 설명하도록 한다. 도 4a 및 도 4b는 종래의 AR 디바이스의 입력 방식의 문제점을 설명하는 도면이다. 도 4a의 (a)를 참조하면, AR 디바이스가 제공하는 가상 키보드를 실제 손가락으로 입력하는 상황을 설명한다. 이러한 혼합 현실 환경 입력의 경우, 단순 컨트롤은 이용이 가능하나 키보드 문자 입력과 같은 정교한 입력은 불가능한 수준이다. 즉, 키보드 자판을 완벽하게 외우고 있지 않은 사용자의 경우에는 사용이 제한적이다. AR 디바이스가 제공하는 가상 키보드를 실제 손가락으로 입력하는 경우 수렴-조절 불일치(vergence- accommodation conflict) 문제가 발생한다. 즉, 실제 3차원 공간의 눈의 초점이 실상과 허상이 안 맞게 된다. 이때, AR 디바이스는 정확한 입력을 위하여 사용자가 눈알을 얼마나 굴렸는지 정확히 판단해야 하고, 사용자가 보는 것이 정확히 인식되었는지 처리해야 한다. 도 4a의 (b)와 같이 AR 디바이스가 제공하는 가상 키보드를 아이 트래킹(eye tracking)을 통하여 입력하는 경우 에도 문제점이 존재한다. 매 음절 간의 분리의 어려움이 있고, 사용자마다 IPD(Inter Pupil Distance)가 다르기 때문에 자판의 경계가 모호해져 시선 처리로 인한 오입력 가능성이 높다. 도 4b의 (a)를 참조하면, 시판되는 대부분의 AR 글래스 형태의 AR 디바이스는 디자인이나 광학계의 소모 전류를 줄이기 위해 보통 투과율 20% 이하의 틴트(Tint)가 적용되어 가상 컨텐츠 위에 실상을 보기가 어렵다. 예를 들 어, 2020년에 iLab에서 개발한 NTT DCM 글래스 프로토 타입의 경우 0.4%~16%대의 투과율이 적용된 것을 알 수 있다. 즉, 단일 초점을 가지는 AR 글래스 형태의 AR 디바이스는 보통 원거리(2.5m 이상)를 기준으로 초점이 맞추어져 있기 때문에 원거리 가상 컨텐츠와 40cm 정도의 실상 키보드를 번갈아 보며 타이핑해야하는 불편함이 있다. 도 4b의 (b)를 참조하면, 실상 키보드의 포커스와 가상 키보드의 포커스에 차이가 생겨 어지럼증을 유발할 수 있다. 이에 따라, 본 발명에서는 AR 디바이스를 이용하여 문자를 정확하게 입력할 수 있는 방안에 대하여 자세히 설명 하도록 한다. 도 5는 본 발명의 일 실시예에 따른 AR 디바이스의 구성 모듈을 설명하는 도면이다. 도 5를 참조하면, AR 디바이스는 보이스 픽업 센서, 아이 트래킹부, 입술 모양 트래킹부 및 자동 완성부를 포함할 수 있다. 도 5에 도시된 구성 요소들은 AR 디바이스를 구현하는데 있어서 필수적인 것은 아니어서, 본 명세서 상에서 설명되는 AR 디바이스는 위에서 열거된 구성 요소들 보다 많거 나, 또는 적은 구성 요소들을 가질 수 있다. 또한, 앞서 언급된 구성요소들이 모두 첨부된 도면들에서 상세하게 도시되지는 않으며, 중요한 일부 구성요소들만이 첨부된 도면들에서 도시될 수 있다. 그러나, 비록 모두 도시되 지는 않지만, 청각 보조 장치로서의 기능을 구현하기 위해, 적어도 도 5의 구성요소들이 AR 디바이스에 포 함될 수 있음을 당업자는 이해 가능하다. 도 5를 참조하면, AR 디바이스는 도 1 에서 상술한 AR 디바이스(100a)의 기본 구성 요소를 모두 포함함과 동시에 후술하는 보이스 픽업 센서, 아이 트래킹부, 입술 모양 트래킹부 및 자동 완성부를 특징으로 할 수 있다. 보이스 픽업 센서는 문자 입력을 확인할 수 있다. 이때, 보이스 픽업 센서는 사용자의 턱 관절의 움 직임(Bone Conduction)에 기초하여 하나의 문자 입력을 확인할 수 있다. 즉, 보이스 픽업 센서는 골 전도 센서를 이용해 보이스 없이 한 글자를 얘기하고 있다는 사용자의 의도를 파악할 수 있다. 보이스 픽업 센서 에 대하여는 도 6에서 자세히 설명하도록 한다. 아이 트래킹부는 카메라를 통하여 눈동자의 움직임을 감지할 수 있다. 사용자는 입력하기 원하는 낱 글자 를 가상 키보드 상에서 순차적으로 응시할 수 있다. 입술 모양 트래킹부는 문자를 유추할 수 있다. 입술 모양 트래킹부는 문자의 범위를 인식할 수 있다. 이때, 입술 모양 트래킹부는 IR 카메라 및 IR 일루미네이터를 통하여 문자를 유추할 수 있다. 여기에서, IR 카메라 및 IR 일루미네이터는 사용자의 입술을 기 설정된 각도에서 촬영하도록 배치될 수 있다. 이에 대하여 는 도 7및 도 8에서 자세히 설명하도록 한다. 또한, 입술 모양 트래킹부는 아이 트래킹부가 눈동자를감지하는 시간에 기초하여 문자를 유추할 수 있다. 이때, 한 글자가 완성될 때까지 입술 모양이 유지될 필요가 있다. 또한, 입술 모양 트래킹부는 인공지능을 이용하여 문자를 유추할 수 있다. 즉, AR 디바이스가 외부 서버와 연결되어 있는 경우, 인공지능 서버로부터 유추 가능한 문자를 수신할 수 있고, 입술 모양 트래킹 부가 인식하는 문자와 결합하여 문자를 유추할 수 있다. 또한, 이러한 기능을 통하여 AR 디바이스는 메타버스 가상 환경에서 나의 아바타의 입 모양과 표정을 제공할 수 있다. 자동 완성부는 유추된 문자에 기초하여 단어를 완성할 수 있다. 또한, 자동 완성부는 단어뿐만이 아 니라 문장도 자동 완성할 수 있다. 자동 완성부는 초기 몇 문자나 몇 단어가 입력되면 수정 또는 완성된 단어나 문장 후보를 추천할 수 있다. 이때, 자동 완성부는 AR 디바이스에 설치된 OS 및 애플리케이션 의 자동 완성 기능을 활용할 수 있다. 또한, 본 발명의 일 실시예에서, AR 디바이스는 아이 트래킹부를 주 입력 수단으로 설정하고, 입술 모양 트래킹부를 보조 입력 수단으로, 자동 완성부를 추가 입력 수단으로 설정할 수 있다. 이는, 입 술 모양을 통해서는 자음과 모음의 움직임, 자음 상태로 머물고 있는지 여부 등을 파악할 수 있으나 입술 모양 만으로는 동순이음어 때문에 문자를 완벽하게 파악하는 것이 불가능하다. 이러한 점을 보완하기 위하여 AR 디바 이스는 아이 트래킹부를 주 입력수단으로 설정할 수 있다. 또한, 도면에 도시되지는 않았으나 AR 디바이스는 디스플레이부를 더 포함할 수 있다. 디스플레이부는 도 1에서 상술한 내용을 참조할 수 있다. 본 발명의 일 실시예에서, 디스플레이부는 문자 입력기(IME)를 출력할 수 있고, 아이 트래킹부를 통하여 감지된 눈동자 움직임에 기초하여 문자 입력기 상에 포인터를 출력할 수 있다. 또한, 디스플레이부는 자동 완성 부를 통하여 완성된 단어 또는 문장을 출력할 수 있다. 이에 대하여는 도 11, 도 12a 및 도 12b에서 자세 히 설명하도록 한다. 또한, 도면에 도시되지는 않았으나 AR 디바이스는 입력부를 더 포함할 수 있다. 입력부는 도 1에서 상술한 내용을 참조할 수 있다. 본 발명의 일 실시예에서, 보이스 픽업 센서는 입력부를 통하여 수신되는 제어 신 호에 기초하여 문자 입력 확인을 시작할 수 있다. 예를 들어, 입력부를 통하여 물리적인 버튼 또는 가상 버튼에 의해 제어 신호가 수신되는 경우, 보이스 픽업 센서는 문자 입력 확인을 시작할 수 있다. 또한, 도면에 도시되지는 않았으나 AR 디바이스는 메모리 유닛을 더 포함할 수 있다. 메모리 유닛은 도 1 에서 상술한 내용을 참조할 수 있다. 본 발명의 일 실시예에서, 입술 모양 트래킹부는 메모리 유닛에 포함 된 데이터베이스에 기초하여 문자를 유추할 수 있다. 이를 통하여 실상 외장형 키보드, 컨트롤러 없이 편리하게 정교한 문자 입력이 가능하다. 즉, 실외나 정숙을 요구하는 환경에서 AR 디바이스는 글래스 멀티 센싱을 이용해 문자를 정교하게 입력할 수 있 다. AR 디바이스를 착용했을 때 실상인 외장형 키보드는 사용이 쉽지 않다. 가상 컨텐츠를 눈앞에 띄우면 실상인 외 장형 키보드는 거의 보이지 않다. 또한, 문자 입력 수단이 가상 키보드인 경우에는 아이 트래킹만을 사용하기 때문에 문자 인식의 정확도가 현저히 낮아지게 된다. 이러한 점을 보완하기 위하여 본 발명의 AR 디바이스는 듣 고(listen), 보고(watch), 읽고(read), 쓰고(write), 수정하는(correction) 멀티 센싱 기술을 제공할 수 있다. 입력 받는 멀티 센싱 기술의 조합으로 아이 트래킹만 사용하는 문자 입력 대비 정확도가 크게 향상되고 입력 시 간은 줄어들게 된다. 부가 기능으로 아바타의 표정 생성 등으로 메타버스 세계에 활용이 가능하다. 특히, 다른 사람의 시선을 신경써야 하는 다양한 공공 장소(버스나 지하철) 내 문자 입력, 가상 오피스 환경에서 대화면 이 나 세컨드 디스플레이를 이용한 이메일 및 문서 작업시, 메타버스 시장(나의 입모양을 반영하여 아바타에 표정 을 제공 및 가상 공간에서 소셜 형성), 음성이나 손 입력 활용이 불가능한 청각 및 지체 장애인 이용, 향후 랩 탑이나 스마트 기기에 적용이 가능하다. 도 6은 본 발명의 일 실시예에 따른 보이스 픽업 센서를 설명하는 도면이다. 도 6의 (a)를 참조하면, 보이스 픽업 센서가 사용자의 귀 안에 삽입된 경우, 보이스 픽업 센서는 사용자의 턱 관절(skull and jaw)의 움직임(bone conduction)을 감지하여 문자 입력 및 자간을 확인할 수 있다. 도 6의 (b)를 참조하면, “가나다라마바사”를 음성으로 발음한 경우의 파형과, “가나다라마바사”를 입 모양 만 발음한 경우의 파형을 나타낸다. 즉, 보이스 픽업 센서가 턱 관절의 움직임을 통하여 감지한 파형과 실제 음성 파형이 거의 유사함을 알 수 있다. 즉, 보이스 픽업 센서는 실제 음성을 감지하지 못하더라도 턱 관절의 움직임을 감지하여 문자 입력 및 자간을 확인할 수 있다. 이를 통하여 시끄러운 환경에서 일반 마이크만 사용하는 경우와 비교하여 50~80%까지 더 정확 하게 문자 입력 및 자간을 판단할 수 있다. 도 7은 본 발명의 일 실시예에 따른 AR 디바이스 내에 센서 배치를 설명하는 도면이다. 도 7을 참조하면, 보이스 픽업 센서는 골 전도의 울림을 확인하기 위하여 사용자가 AR 디바이스를 착용했 을 때, AR 디바이스의 측면에 위치할 수 있다. 또한, 입술 모양 트래킹부의 카메라(702, 703)는 사용자의 입술을 기 설정된 각도(예를 들어, 30도)에서 촬영하 도록 배치될 수 있다. 특히, 입술 모양 트래킹부의 카메라(702, 703)는 도 8에서 후술하듯이 입술 모양만을 파 악하면 되기 때문에 입술과의 각도만 정확하면 해상도가 낮은 카메라를 사용해도 무방하다. 또한, IR 카메라와 IR 일루미네이터의 위치는 선택적으로 배치될 수 있다. 마지막으로, 아이 트래킹부의 카메라(704, 705, 706, 707)는 사용자의 눈동자 움직임을 파악하기 위해 사용자의 양 눈의 좌우 방향으로 배치될 수 있다. 아이 트래킹부의 각 카메라가 눈동자 움직임을 파악하는 실시예는 도 9 및 도 10에서 자세히 설명하도록 한다. 도 8은 본 발명의 일 실시예에 따른 입술 트래킹부의 트래킹 결과를 설명하는 도면이다. 도 8을 참조하면, 입술 트래킹부가 입술 모양을 트래킹한 결과를 알 수 있다. 즉, 상술한 IR 카메라 및 IR 일루 미네이터를 통하여 사람 입술 모양에 대한 개략적인 모양을 식별할 수 있다. 이때, 입술 트래킹부는 화질이 높 은 카메라를 사용할 필요가 없으며 단순히 입술 모양을 식별할 수 있도록 최외곽 경계점(801, 802, 803, 804, 805, 806)을 생성하고, 이들을 잇기 위한 중간 경계점(807, 808, 809, 810)을 생성하고, 이들을 잇는 선을 생성 할 수 있다. 이를 통하여, 입술 트래킹부는 각 문자에 대한 입술 모양을 식별할 수 있다. 도 9는 본 발명의 일 실시예에 따른 아이 트래킹부의 동작을 설명하는 도면이다. 도 9의 (a)를 참조하면, 아이 트래킹부의 적외선 카메라(Infrared camera)는 사용자의 눈동자의 동공 및 각막 반사(902, corneal reflection)를 구별하여 식별할 수 있다. 도 9의 (b)를 참조하면, 아이 트래킹부는 IR 소스를 눈알(eye boll)로 출력하여, 눈알의 동공의 중심 및 각만 반사 사이의 벡터를 통하여 시선의 방향을 인지할 수 있다. 도 9의 (c)를 참조하면, 상술한 방법을 통하여 아이 트래킹부는 사용자의 눈동자가 정면을 응시하는지, 카메라 의 오른쪽 아래를 보는지, 카메라의 위쪽을 보는지 판단할 수 있다. 도 10은 본 발명의 일 실시예에 따른 아이 트래킹부의 정확도를 설명하는 도면이다. 도 10의 (a)를 참조하면, 사용자가 AR 디바이스를 착용한 후 화면에 있는 점을 응시할 때의 아이 트래킹 결과를 확인하기 위하여, 화면에 있는 점과 사용자와의 거리가 멀어지는 경우에 대한 실험을 나타낸다. 도 10의 (b)를 참조하면, 화면에 있는 점과 사용자와의 거리가 0.5m에서 한 점의 포인트에 대한 표준 편차는 0.91cm 내고, 화면에 있는 점과 사용자와의 거리가 2m에서 한 점의 포인트에 대한 표준 편차는 2.85cm인 것을 알 수 있다. 즉, 가상 키보드를 사용자로부터 50cm 앞에 놓여져 있다고 가정하는 경우, 한 점의 포인트에 대한 표준 편차가 0.91cm 이내이기 때문에 보다 정확한 문자 입력이 가능할 것으로 예상된다. 도 11은 본 발명의 일 실시예에 따른 AR 디바이스의 문자 입력 환경을 설명하는 도면이다. 도 11을 참조하면, AR 디바이스를 착용한 사용자가 볼 수 있는 가상 컨텐츠의 전체 화면 사이즈가 14.3인치(가 로 31cm, 세로 18cm)이고, 사용자로부터 50cm 앞에 떨어진 가상 키보드의 사이즈는 11.7인치(가로 28cm, 세로 10cm)에 대응할 수 있다. 이때, 상술한 카메라의 시야각(FOV)은 40도, 해상도는 FHD로 가정할 수 있다. 이 경우, AR 디바이스는 최초로 사용자의 눈동자 움직임에 대한 인식이 정확한지 판단하기 위하여 예시로 3개의 점(1101, 1102, 1103)에 대한 교정(calibration) 작업을 진행할 수 있다. 이후, 교정 작업이 완료되면, AR 디 바이스는 아이 트래킹을 통하여 문자 입력을 수신할 수 있다. 도 12a 및 도 12b는 본 발명의 일 실시예에 따른 AR 디바이스에서 문자 입력 결과를 나타내는 도면이다. 도 12a 는 가상 키보드로 천지인 자판을 출력하는 실시예를 나타내고, 도 12b는 가상 키보드로 쿼티 자판을 출력하는 실시예를 나타낸다. 도 12a를 참조하면, AR 디바이스의 디스플레이부는 천지인 자판을 출력할 수 있다. 이후, 문자 입력이 시작되면, 보이스 픽업 센서는 사용자의 턱 관절 움직임에 기초하여 하나의 글자 단위를 인식할 수 있다. 이와 동시에 입술 모양 트래킹부는 카메라를 통하여 인식되는 사용자의 인식 모양을 분석하여 문자를 유추할 수 있다. 또한, 이와 동시에 아이 트래킹부는 카메라를 통하여 감지된 눈동자의 움직임에 기초하여 인식되는 포인 터를 천지인 자판상에 출력할 수 있다. 도 12a의 예를 들어 설명하면, 사용자가 “ㄷ”을 발음하고, 천지 인 자판에서 “ㄷ”을 응시하는 경우, AR 디바이스는 천지인 자판상에 “ㄷ”의 위치에 포인터를 출력할 수 있다. 본 발명의 일 실시예에서, 실제로 디스플레이부를 통해 사용자에게 보여지는 화면은 가상 천지인 자판 과 포인터에 대응할 수 있다. 도 12a의 예를 들어 설명하면, 사용자가 “동해ㅁ”을 입 모양을 통해 발음하는 경우, AR 디바이스는 보이스 픽 업 센서, 입술 모양 트래킹부 및 아이 트래킹부를 통하여 “동해ㅁ”을 감지할 수 있다. 이후, AR 디바이스는 자동 완성부를 통하여 “동해물과”를 출력할 수 있다. AR 디바이스는 아이 트래킹부를 통하여 사용자의 눈동자 움직임이 이후 자동 완성 단어인 “백두산이”를 응시하는 경우, “동해물과 백두산이”라는 완성된 문장을 출 력할 수 있다. 마찬가지로, 도 12b를 참조하면, AR 디바이스의 디스플레이부는 쿼티 자판을 출력할 수 있다. 이후, 문자 입력 이 시작되면, 보이스 픽업 센서는 사용자의 턱 관절 움직임에 기초하여 하나의 글자 단위를 인식할 수 있다. 이 와 동시에 입술 모양 트래킹부는 카메라를 통하여 인식되는 사용자의 인식 모양을 분석하여 문자를 유추할 수 있다. 또한, 이와 동시에 아이 트래킹부는 카메라를 통하여 감지된 눈동자의 움직임에 기초하여 인식되는 포인 터를 쿼티 자판상에 출력할 수 있다. 도 12b의 예를 들어 설명하면, 사용자가 “ㄷ”을 발음하고, 쿼티 자판에서 “ㄷ”을 응시하는 경우, AR 디바이스는 쿼티 자판상에 “ㄷ”의 위치에 포인터를 출력할 수 있 다. 본 발명의 일 실시예에서, 실제로 디스플레이부를 통해 사용자에게 보여지는 화면은 가상 쿼티 자판과 포인 터에 대응할 수 있다. 또한, AR 디바이스가 자동 완성부를 통하여 단어 또는 문장을 완성하는 실시예는 도 12a에서 상술한 내용과 동 일하다. 즉, 기존에는 가상 키보드 이용 시 “ㄴ”과 “ㄹ”을 구분하기 위하여 일정 시간 기다리거나(딜레이 발생) 사 용자로부터 추가로 선택을 받았는데, 본 발명에서는 아이 트래킹 및 입술 모양 트래킹을 동시에 수행하여 빠르 게 문자를 구분할 수 있다. 도 13은 본 발명의 일 실시예에 따른 AR 디바이스에서 문자 입력에 대한 인식률을 예측한 표를 나타내는 도면이 다. 도 13을 참조하면, 표의 세로 목차는 AR 디바이스의 구성 모듈을 나타내고, 표의 가로 목차는 수행하는 기능에 대하여 설명한다. 보다 상세하게는, 보이스 픽업 센서는 최초로 문자 입력 상황을 확인할 수 있다. 즉, 보이스 픽업 센서를 통하 여 사용자가 문자를 입력하고자 하는 의도를 파악할 수 있다. 즉, 보이스 픽업 센서를 통하여 사용자의 턱 관절 움직임이 발생하면, AR 디바이스는 아이 트래킹부 및 입술 모양 트래킹부를 통하여 문자 인식을 시작할 수 있다. 보이스 픽업 센서는 골 전도를 이용할 수 있으며, 한문자 단위로 입력되는지 여부를 확인할 수 있다. 이 를 통하여, 문자 입력을 확인할 수 있는 수준은 95%로 예측될 수 있다. 또한, 정숙을 요구하지 않는 독립된 공 간에서는 골 전도가 아닌 음성으로 인식이 가능하다. 입술 모양 트래킹부는 대략적인 문자 인식이 가능하다. 다만, 입술 모양 트래킹부는 동일한 입 모양에 다른 소 리인 동순이의어에 취약하다. 따라서, 아이 트래킹과 함께 문자를 인식할 필요가 있다. 입술 모양 트래킹부를 통하여 문자 인식이 시작되면, 문자 입력을 확인할 수 있는 수준은 100%로 예측될 수 있다. 아이 트래킹부는 정밀한 문자 인식이 가능하다. 즉, 입술 모양 트래킹부를 통하여 인식된 대략적인 문자에 아이 트래킹부를 통하여 인식된 내용을 결합하여 보다 정확한 문자 인식이 가능하다. 특히, 아이 트래킹부는 최적의 위치에서 정확도가 향상되기 때문에 도 11에서 상술한 바와 같이 예시 점을 제공하여 교정 작업을 수행할 수 있 다. 아이 트래킹부를 통하여 인식된 문자의 인식률은 95%로 예측될 수 있다. 자동 완성부는 아이 트래킹부와 입술 모양 트래킹부를 통하여 인식된 문자에 대한 수정 및 자동 완성 기능을 제 공할 수 있다. 자동 완성부를 통하여 수정 및 자동 완성 기능이 제공된 이후 문자의 인식률은 99%로 향상시키며 입력 시간을 30% 감소시킬 수 있다. 도 14는 본 발명의 일 실시예에 따른 AR 디바이스의 제어 방법을 설명하는 순서도이다. 도 14를 참조하면, 단계(S1401)에서, 사용자의 턱 관절의 움직임에 기초하여 문자 입력을 확인할 수 있다. 이때, 보이스 픽업 센서를 통하여 사용자의 턱 관절의 움직임에 기초하여 문자 입력을 확인할 수 있다. 이때, 한 문자를 기준으로 문자 입력을 확인할 수 있다. 이때, 입력부를 통하여 수신되는 제어 신호에 기초하여 보이 스 픽업 센서가 활성화될 수 있다. 단계(S1402)에서, 카메라를 통하여 눈동자의 움직임을 감지할 수 있다. 단계(S1403)에서, IR 카메라 및 IR 일루미네이터를 통하여 문자를 유추할 수 있다. 이때, 눈동자 움직임을 감지 하는 시간에 기초하여 문자를 유추할 수 있다. 또한, IR 카메라 및 IR 일루미네이터는 사용자의 입술을 기 설정 된 각도(예를 들어, 30도 내지 40도 사이)에서 촬영하도록 배치될 수 있다. 또한, IR 카메라 및 IR 일루미네이 터를 통하여 인식된 문자에 더불어 데이터베이스 및 인공지능을 적용하여 문자를 유추할 수 있다. 단계(S1404)에서, 유추된 문자에 기초하여 단어를 완성할 수 있다. 이후, 디스플레이부를 통하여 완성된 단어를 출력할 수 있다. 본 발명의 일 실시예에 따라, AR 디바이스의 최대 과제인 문자 입력에 대한 불편을 해소할 수 있다. 특히, 멀티 센싱을 통해 정교한 입력이 가능하기 때문에 메타버스 AR 글래스 환경에서는 더욱 필요한 기술이 될 것이다. 전술한 본 발명은, 프로그램이 기록된 매체에 컴퓨터가 읽을 수 있는 코드로서 구현하는 것이 가능하다. 컴퓨터 가 읽을 수 있는 매체는, 컴퓨터 시스템에 의하여 읽혀질 수 있는 데이터가 저장되는 모든 종류의 기록장치를 포함한다. 컴퓨터가 읽을 수 있는 매체의 예로는, HDD(Hard Disk Drive), SSD(Solid State Disk), SDD(Silicon Disk Drive), ROM, RAM, CD-ROM, 자기 테이프, 플로피 디스크, 광 데이터 저장 장치 등이 있으며, 또한 캐리어 웨이브(예를 들어, 인터넷을 통한 전송)의 형태로 구현되는 것도 포함한다. 또한, 상기 컴퓨터는 영상 편집 장 치의 제어부를 포함할 수도 있다. 따라서, 상기의 상세한 설명은 모든 면에서 제한적으로 해석되어서는 아 니되고 예시적인 것으로 고려되어야 한다. 본 발명의 범위는 첨부된 청구항의 합리적 해석에 의해 결정되어야 하고, 본 발명의 등가적 범위 내에서의 모든 변경은 본 발명의 범위에 포함된다. 산업상 이용가능성 본 발명의 실시예들은 AR 디바이스 및 AR 디바이스의 제어 방법에 있어서 반복적으로 실시 가능하기 때문에 산 업상 이용가능성이 있다. 도면 도면1 도면2 도면3a 도면3b 도면4a 도면4b 도면5 도면6 도면7 도면8 도면9 도면10 도면11 도면12a 도면12b 도면13 도면14"}
{"patent_id": "10-2024-7018268", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일 실시예에 따른 AR 디바이스를 HMD 타입으로 구현한 실시예를 도시하고 있다. 도 2는 본 발명의 일 실시예에 따른 AR 디바이스를 AR 글래스 타입으로 구현한 실시예를 도시하고 있다. 도 3a 및 도 3b는 본 발명의 일 실시예에 따른 AR 디바이스의 개념도를 설명하는 도면이다. 도 4a 및 도 4b는 종래의 AR 디바이스의 입력 방식의 문제점을 설명하는 도면이다. 도 5는 본 발명의 일 실시예에 따른 AR 디바이스의 구성 모듈을 설명하는 도면이다. 도 6은 본 발명의 일 실시예에 따른 보이스 픽업 센서를 설명하는 도면이다. 도 7은 본 발명의 일 실시예에 따른 AR 디바이스 내에 센서 배치를 설명하는 도면이다. 도 8은 본 발명의 일 실시예에 따른 입술 트래킹부의 트래킹 결과를 설명하는 도면이다. 도 9는 본 발명의 일 실시예에 따른 아이 트래킹부의 동작을 설명하는 도면이다. 도 10은 본 발명의 일 실시예에 따른 아이 트래킹부의 정확도를 설명하는 도면이다. 도 11은 본 발명의 일 실시예에 따른 AR 디바이스의 문자 입력 환경을 설명하는 도면이다. 도 12a 및 도 12b는 본 발명의 일 실시예에 따른 AR 디바이스에서 문자 입력 결과를 나타내는 도면이다. 도 13은 본 발명의 일 실시예에 따른 AR 디바이스에서 문자 입력에 대한 인식률을 예측한 표를 나타내는 도면이 다. 도 14는 본 발명의 일 실시예에 따른 AR 디바이스의 제어 방법을 설명하는 순서도이다."}
