{"patent_id": "10-2014-0040342", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2015-0115385", "출원번호": "10-2014-0040342", "발명의 명칭": "레코딩 지원 전자장치 및 방법", "출원인": "삼성전자주식회사", "발명자": "장성운"}}
{"patent_id": "10-2014-0040342", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "음원데이터를 포함한 멀티미디어 데이터를 입력받고, 상기 음원데이터에서 음성데이터를 검출하는오디오처리부;상기 음성데이터에서 적어도 하나의 단위 음성데이터를 확인하여 레코딩하고, 상기 단위 음성데이터에 대응되는적어도 하나의 텍스트데이터를 생성하는 제어부;상기 단위 음성데이터에 대응되는 텍스트데이터를 출력하는 표시부;를 포함하는 전자장치."}
{"patent_id": "10-2014-0040342", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 제어부는 상기 음성데이터에서 주파수의 특정 파형이 시작된 시점부터 임계시간 이상 종료된 시점까지를 상기 단위 음성데이터로 확인하는 전자장치."}
{"patent_id": "10-2014-0040342", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,상기 제어부는상기 주파수의 특정 파형이 시작된 시점과 임계시간 이상 종료된 시점에 대한 타임스탬프 정보를 확인하는 전자장치."}
{"patent_id": "10-2014-0040342", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서,상기 제어부는상기 단위 음성데이터에 해당하는 언어로 제1 텍스트데이터를 생성하고, 상기 제1 텍스트데이터를 번역하여 타언어에 대한 제2 텍스트데이터를 생성하는 전자장치."}
{"patent_id": "10-2014-0040342", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제3항에 있어서,상기 제어부는상기 확인된 타임스탬프 정보로 상기 단위 음성데이터와 상기 텍스트데이터의 싱크를 맞추는 전자장치."}
{"patent_id": "10-2014-0040342", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서,상기 제어부는선택신호에 따라 상기 단위 음성데이터와 상기 단위 음성데이터에 대응되는 텍스트데이터를 저장하는 저장부;를 더 포함하는 전자장치."}
{"patent_id": "10-2014-0040342", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "공개특허 10-2015-0115385-2-제3항에 있어서,상기 제어부는상기 멀티미디어 데이터에 동영상데이터가 포함된 경우, 상기 동영상데이터의 획득이 시작된 시점부터 획득이종료된 시점까지의 타임스탬프 정보를 확인하고, 상기 단위 음성데이터의 타임스탬프 정보를 확인하여 상기 단위 음성데이터와 상기 동영상데이터의 싱크를 맞추는 전자장치."}
{"patent_id": "10-2014-0040342", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "음원데이터를 포함하는 멀티미디어 데이터를 획득하는 동작;상기 음원데이터에서 음성데이터를 검출하는 동작;상기 음성데이터에서 적어도 하나의 단위 음성데이터를 확인하여 레코딩하는 동작;상기 단위 음성데이터에 대응되는 적어도 하나의 텍스트데이터를 생성하는 동작;상기 단위 음성데이터에 대응되는 텍스트데이터를 출력하는 동작;을 포함하는 레코딩 지원 방법."}
{"patent_id": "10-2014-0040342", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서,상기 레코딩하는 동작 이후에 상기 레코딩된 단위 음성데이터에 해당하는 언어로 제1 텍스트데이터로 생성하고, 상기 제1 텍스트데이터를 번역하여 타 언어에 대한 제2 텍스트데이터를 생성하는 동작;을 더 포함하는 레코딩 지원 방법."}
{"patent_id": "10-2014-0040342", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9항에 있어서,상기 텍스트데이터를 출력하는 동작은상기 단위 음성데이터의 타임스탬프 정보를 확인하고, 상기 확인된 타임스탬프 정보로 상기 단위 음성데이터와상기 텍스트데이터의 싱크를 맞추어 출력하는 동작인 레코딩 지원 방법."}
{"patent_id": "10-2014-0040342", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제8항에 있어서,상기 텍스트데이터를 출력하는 동작 이후에 선택신호를 수신하는 동작;상기 선택신호에 따라 상기 단위 음성데이터와 상기 단위 음성데이터에 대응되는 텍스트데이터를 저장하는동작;을 더 포함하는 레코딩 지원 방법."}
{"patent_id": "10-2014-0040342", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제10항에 있어서, 상기 멀티미디어 데이터를 획득하는 동작은 동영상데이터가 포함된 멀티미디어 데이터를 획득하는 동작인 레코딩 지원 방법."}
{"patent_id": "10-2014-0040342", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제12항에 있어서, 공개특허 10-2015-0115385-3-상기 텍스트데이터를 출력하는 동작은상기 동영상데이터의 획득이 시작된 시점부터 획득이 종료된 시점까지의 타임스탬프 정보를 확인하고, 상기 단위 음성데이터의 타임스탬프 정보를 확인하여 상기 단위 음성데이터와 상기 동영상데이터의 싱크를 맞추는동작;을 더 포함하고, 상기 단위 음성데이터와 상기 동영상데이터에 상기 텍스트데이터의 싱크를 맞추어 출력하는 동작인 레코딩 지원방법."}
{"patent_id": "10-2014-0040342", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 음원데이터를 포함한 멀티미디어 데이터를 입력받고, 음원데이터에서 음성데이터를 검출하는 오디오처 리부, 음성데이터에서 적어도 하나의 단위 음성데이터를 확인하여 레코딩하고, 단위 음성데이터에 대응되는 적어 도 하나의 텍스트데이터를 생성하는 제어부, 단위 음성데이터에 대응되는 텍스트데이터를 출력하는 표시부를 제 공하고, 다른 실시예로도 적용이 가능하다."}
{"patent_id": "10-2014-0040342", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명의 다양한 실시 예는 음성데이터를 포함하는 멀티미디어 데이터를 레코딩하는 레코딩 지원 전자장치 및 방법에 관한 것이다."}
{"patent_id": "10-2014-0040342", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "일반적인 전자장치는 음성데이터를 포함하는 멀티미디어 데이터를 레코딩 할 때, 전자장치의 사용자로부터 레코 딩 시작 이벤트가 발생된 시점부터 레코딩 종료 이벤트가 발생된 시점까지를 레코딩할 수 있다."}
{"patent_id": "10-2014-0040342", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "상기와 같이 전자장치에서 멀티미디어 데이터를 레코딩 할 때 레코딩 시작 시점부터 레코딩 종료 시점까지 하나 의 데이터로 레코딩하므로 전자장치 사용자가 레코딩 파일에서 필요한 부분을 찾을 때, 불필요한 부분까지 확인 하면서 필요한 부분을 검색해야 하는 문제점이 발생한다. 이러한 종래의 문제점을 해결하기 위한 본 발명의 다양한 실시 예들은 녹음, 녹화, 음성통화, 영상통화 시에 발 생되는 음성데이터를 포함하는 멀티미디어 데이터 레코딩 시, 언어의 구성요소로 레코딩의 시작 시점과 종료 시 점을 설정하여 레코딩을 수행하는 레코딩 지원 전자장치 및 방법을 제공하는 것이다. 또한, 본 발명의 다양한 실시 예들은 제1 언어에 대한 음성데이터를 포함하는 멀티미디어 데이터를 언어의 구성 단위로 레코딩하여 상기 음성데이터를 제1 텍스트데이터로 변환하는 레코딩 지원 전자장치 및 방법을 제공하는 것이다."}
{"patent_id": "10-2014-0040342", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 일 실시 예에 따른 레코딩 지원 전자장치는 음원데이터를 포함한 멀티미디어 데이터를 입력받고, 상 기 음원데이터에서 음성데이터를 검출하는 오디오처리부, 상기 음성데이터에서 적어도 하나의 단위 음성데이터 를 확인하여 레코딩하고, 상기 단위 음성데이터에 대응되는 적어도 하나의 텍스트데이터를 생성하는 제어부, 상 기 단위 음성데이터에 대응되는 텍스트데이터를 출력하는 표시부를 포함할 수 있다. 또한, 본 발명의 일 실시 예에 따른 레코딩 지원 방법은 음원데이터를 포함하는 멀티미디어 데이터를 획득하는 동작, 상기 음원데이터에서 음성데이터를 검출하는 동작, 상기 음성데이터에서 적어도 하나의 단위 음성데이터 를 확인하여 레코딩하는 동작, 상기 단위 음성데이터에 대응되는 적어도 하나의 텍스트데이터를 생성하는 동작, 상기 단위 음성데이터에 대응되는 텍스트데이터를 출력하는 동작을 포함할 수 있다."}
{"patent_id": "10-2014-0040342", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "상술한 바와 같이 본 발명의 다양한 실시 예들에 따른 레코딩 지원 전자장치 및 방법은 녹음, 녹화, 음성통화, 영상통화 시에 발생되는 음성데이터를 포함하는 멀티미디어 데이터 레코딩 시, 음성데이터에서 확인되는 언어의 구성요소를 기준으로 레코딩을 수행함으로써, 레코딩 파일에서 필요한 부분을 따로 검색하는 불편함을 해소할 수 있다. 또한, 본 발명의 다양한 실시 예들에 따른 레코딩 지원 전자장치 및 방법은 제1 언어에 대한 음성데이터를 포함 하는 멀티미디어 데이터를 언어의 구성요소를 기준으로 레코딩하고, 상기 음성데이터를 제1 텍스트데이터로 변 환하여 출력함으로써, 사용자에게 음성데이터를 텍스트데이터로 제공할 수 있다. 또한, 본 발명의 다양한 실시 예들에 따른 레코딩 지원 전자장치 및 방법은 제1 텍스트데이터를 제2 언어에 대 한 제2 텍스트데이터로 번역하고 레코딩 시의 타임스탬프 정보를 이용하여 출력함으로써, 음성데이터와 텍스트 데이터의 싱크를 용이하게 수행할 수 있다."}
{"patent_id": "10-2014-0040342", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 첨부된 도면을 참조하며 본 발명을 설명한다. 본 발명은 다양한 변경을 가할 수 있고 여러 가지 실시 예 를 가질 수 있는 바, 특정 실시 예들이 도면에 예시되고 관련된 상세한 설명이 기재되어 있다. 그러나, 이는 본 발명을 특정한 실시 형태에 대해 한정하려는 것이 아니며, 본 발명의 사상 및 기술 범위에 포함되는 모든 변경 및/또는 균등물 내지 대체물을 포함하는 것으로 이해되어야 한다. 도면의 설명과 관련하여, 유사한 구성요소에 대해서는 유사한 참조 부호가 사용되었다. 본 발명 가운데 사용될 수 있는 “포함한다” 또는 “포함할 수 있다” 등의 표현은 개시된 해당 기능, 동작 또 는 구성요소 등의 존재를 가리키며, 추가적인 하나 이상의 기능, 동작 또는 구성요소 등을 제한하지 않는다. 또 한, 본 발명에서 “포함하다” 또는 “가지다” 등의 용어는 명세서상에 기재된 특징, 숫자, 단계, 동작, 구성 요소, 부품 또는 이들을 조합한 것이 존재함을 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성요소, 부품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되어야 한다. 본 발명에서 “또는” 등의 표현은 함께 나열된 단어들의 어떠한, 그리고 모든 조합을 포함한다. 예를 들어, “ A 또는 B”는 A를 포함할 수도, B를 포함할 수도, 또는 A와 B 모두를 포함할 수도 있다. 어떤 구성요소가 다른 구성요소에 “연결되어” 있다거나 “접속되어” 있다고 언급된 때에는, 그 다른 구성요 소에 직접적으로 연결되어 있거나 또는 접속되어 있을 수도 있지만, 중간에 다른 구성요소가 존재할 수도 있다 고 이해되어야 할 것이다. 반면에, 어떤 구성요소가 다른 구성요소에 “직접 연결되어” 있다거나 “직접 접속 되어” 있다고 언급된 때에는, 중간에 다른 구성요소가 존재하지 않는 것으로 이해될 수 있어야 할 것이다. 본 발명에서 사용한 용어는 단지 특정한 실시예를 설명하기 위해 사용된 것으로, 본 발명을 한정하려는 의도가 아니다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 다르게 정의되지 않는 한, 기술적이거나 과학적인 용어를 포함해서 여기서 사용되는 모든 용어들은 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자에 의해 일반적으로 이해되는 것과 동일한 의미를 가지고 있다. 일 반적으로 사용되는 사전에 정의되어 있는 것과 같은 용어들은 관련 기술의 문맥 상 가지는 의미와 일치하는 의 미를 가지는 것으로 해석되어야 하며, 본 발명에서 명백하게 정의하지 않는 한, 이상적이거나 과도하게 형식적 인 의미로 해석되지 않는다.본 발명에 따른 전자장치는 통신기능이 포함된 장치일 수 있다. 예를 들면, 전자장치는 스마트 폰(smart phone), 태블릿 PC(tablet personal reader), 이동전화기(mobile phone), PDA(personal digital assistant), MP3 플레이어, 웨어러블 장치(wearable device, 예; 전자 안경과 같은 head-mounted-device(HMD)), 카메라 (camera), 스마트 워치(smart watch) 등 무선 통신이 가능한 장치일 수 있다. 이하, 첨부된 도면을 참조하여 다양한 실시예에 따른 전자장치에 대해서 살펴본다. 다양한 실시 예에서 이용되 는 사용자라는 용어는 전자장치를 사용하는 사람 또는 전자장치를 사용하는 장치(예; 인공지능 전자장치)를 지 칭할 수 있다. 도 1은 본 발명의 다양한 실시 예에 따른 레코딩 지원 전자장치의 주요 구성을 나타내는 블록도이다. 도 1을 참조하면, 본 발명에 따른 전자장치는 통신부, 입력부, 오디오처리부, 카메라부 , 표시부, 저장부 및 제어부를 포함할 수 있다. 전자장치는 음원데이터를 포함하는 멀티미디어 데이터를 획득하고, 음원데이터의 주파수 정보 등으로부터 제1 언어에 대한 음성데이터를 확인하여 레코딩할 수 있다. 전자장치는 음원데이터와 동영상데이터를 포함 하는 멀티미디어 데이터가 획득되면, 음성데이터와 동영상데이터를 레코딩할 수 있다. 전자장치는 레코딩 된 음성데이터를 분석하여 제1 언어에 대한 제1 텍스트데이터를 생성하여 출력할 수 있다. 전자장치는 제1 텍스트데이터를 제2 언어에 대한 제2 텍스트데이터로 번역하여 출력할 수 있다. 전자장치는 음원데이터와 동영상데이터를 포함하는 멀티미디어 데이터가 획득된 경우, 상기 텍스트데이터 를 동영상데이터에 자막형태로 출력할 수 있다. 이때, 멀티미디어 데이터는 전자장치와 타 전자장치(미도 시)의 음성 및 영상 통화 시에 획득될 수 있다. 멀티미디어 데이터는 전자장치의 외부환경에 대한 녹화 또 는 녹음에 의해 획득될 수 있고, 전자장치가 외부장치(타 전자장치 또는 서버장치(미도시))로부터 수신함 으로써 획득될 수 있다. 음성데이터는 음원데이터에서 음성으로 분류되는 데이터이며, 언어의 구성요소를 기준 으로 형성될 수 있다. 본 발명의 실시 예에서 음성데이터는 언어의 구성요소 인 문장을 기준으로 형성되는 것을 예로 설명하고 있으나, 반드시 이에 한정되는 것은 아니며, 음절, 형태소, 단어, 어절, 구절 등 언어의 다양한 구성요소 중 어느 하나를 기준으로 형성될 수 있다. 통신부는 전자장치와 외부장치(타 전자장치(미도시) 또는 서버장치(미도시))간의 통신을 연결할 수 있다. 예컨대, 통신부는 무선 통신 또는 유선 통신을 통해서 외부 장치와 통신할 수 있다. 무선 통신은 예 를 들어, Wifi(Wireless fidelity), BT(Bluetooth), NFC(Near Field Communication) 또는 cellular통신(예: LTE, LTE-A, CDMA, WCDMA, UMTS, WiBro 또는 GSM 등)을 포함할 수 있다. 상기 유선 통신은 예를 들어, USB(Universal Serial Bus), HDMI(High Definition Multimedia Interface), RS-232(Recommended Standard 232) 또는 POTS(Plain Old Telephone Service)를 포함할 수 있다. 또한, 통신부는 cellular통신을 이용하여 음성통화, 영상통화, 채팅 메시지, 문자메시지 서비스, 멀티미디 어 메시지 서비스 또는 인터넷 서비스를 제공할 수 있다. 통신부는 무선 통신 또는 유선 통신을 이용하여 외부장치로부터 멀티미디어 데이터를 수신할 수 있다. 통신부는 획득된 멀티미디어 데이터에 포함된 음원 데이터와 동영상데이터 중 적어도 하나의 데이터를 외부장치로 전송할 수 있다. 통신부는 음원데이터에서 분류되는 음성데이터에 대한 제1 텍스트데이터 및 제2 텍스트데이터를 외부장치로 전송할 수 있다. 입력부는 외부로부터의 입력에 따라 전자장치를 동작시키기 위한 동작신호를 생성하여 제어부로 제공할 수 있다. 입력부는 외부로부터의 입력에 따라 레코딩 기능으로의 진입신호를 생성할 수 있다. 입력 부는 외부로부터의 입력에 따라 번역여부를 미리 설정하기 위한 설정신호, 번역하고자 하는 구간을 선택하 기 위한 선택신호, 번역이 완료된 최종파일을 저장하기 위한 저장신호를 생성할 수 있다. 입력부는 저장된 최종파일을 재생시키기 위한 재생신호를 생성할 수 있다. 입력부는 키버튼, 키보드, 키패드, 터치패드, 터 치스크린, 전자 펜을 포함하는 입력장치로 형성될 수 있다. 오디오처리부는 아날로그 음원 신호 취득 기능과, 아날로그 음원 신호 출력 기능을 지원할 수 있다. 오디 오처리부는 마이크와 스피커 등을 포함할 수 있다. 오디오처리부는 음원 신호를 획득하여 PCM(Pulse Code Modulation) 형태의 음원데이터로 변환할 수 있다. 오디오처리부는 음성통화 또는 영상통화 중일 때 의 음원 신호를 수집할 수 있고, 녹음 또는 녹화 중일 때의 음원 신호를 수집할 수 있다. 오디오처리부는 음원데이터를 분석하여 음원데이터에서 음성데이터를 확인하여 검출할 수 있다. 오디오처 리부는 검출된 음성데이터를 제어부로 제공할 수 있다. 오디오처리부는 음원데이터를 분석하여 주파수의 특정 파형이 감지되는 부분을 음성데이터로 검출할 수 있다. 오디오처리부는 음원데이터가 획득 되는 시점부터 타임스탬프 정보를 생성할 수 있다. 오디오처리부는 제어부로부터 제공된 아날로그 음원 신호를 스피커를 통해 출력할 수 있다. 카메라부는 제어부의 제어에 의해 특정 피사체에 대한 예컨대, 카메라부가 주시한 피사체에 대 한 동영상데이터를 획득하여 제어부로 제공할 수 있다. 카메라부는 사용자가 상대방과 영상 통화 시 에 사용자에 대한 동영상데이터를 획득할 수 있다. 상기 동영상데이터에는 영상통화의 레코딩 또는 녹화가 시작 되는 시점부터 타임스탬프 정보가 생성될 수 있다. 카메라부는 전자장치의 전면과 후면에 구비될 수 있고, 하나 이상의 이미지 센서(전면 센서 또는 후면 센서), 렌즈(미도시), ISP(Image Signal Processor, 미도 시) 또는 플래쉬(Flash)(예; LED 또는 xenonlamp)를 포함할 수 있다. 표시부는 제어부의 제어에 따라 동작되는 실행화면을 표시할 수 있다. 이를 위해, 표시부는 LCD(Liquid Crystal Display), 터치스크린 등으로 형성될 수 있고, 터치스크린으로 형성된 경우, 표시부는 입력부의 역할을 동시에 실행할 수 있다. 표시부가 터치스크린으로 형성된 경우, 표시부는 레코 딩 기능의 진입을 위한 아이콘, 번역여부를 미리 설정하기 위한 가상의 버튼 등을 표시할 수 있다. 표시부(15 0)는 번역하고자 하는 구간을 선택하기 위한 체크박스, 번역이 완료된 최종파일을 저장하기 위한 가상의 버튼 등을 표시할 수 있다. 표시부는 제어부의 제어에 의해 음성데이터에 대한 제1 텍스트데이터 및 제2 텍스트데이터를 표시할 수 있다. 저장부는 전자장치를 동작시키기 위한 프로그램 또는 어플리케이션 등을 저장할 수 있다. 또한, 저장 부는 번역 설정과 관련한 설정정보, 멀티미디어 데이터와 타임스탬프 정보를 실시간으로 임시 또는 반영구적으로 저장하기 위한 버퍼를 포함할 수 있다. 버퍼에는 단위 음성데이터가 저장될 수 있다. 단위 음성데이터는 언어의 구성요소를 기준으로 음성데이터에서 추출된 데이터일 수 있다. 예컨대, 음성데이터 는 문장을 기준으로 형성될 수 있으며, 음절, 형태소, 단어, 어절, 구절 등 언어의 다양한 구성요소 중 어느 하 나를 기준으로 형성될 수 있다. 단위 음성데이터는 음원데이터를 포함한 멀티미디어 데이터로부터 도출된 것이 므로, 타임스탬프 정보를 포함할 수 있다. 저장부는 적어도 하나의 단위 음성데이터를 분석하여 음성데이터의 제1 언어에 대한 제1 텍스트데이터를 생성하고, 제1 텍스트데이터를 제2 언어로 번역하여 제2 텍스트데이터를 생성하기 위한 번역정보를 포함할 수 있다. 저장부는 번역이 완료된 이후에 단위 음성데이터 및 단위 음성데이터와 싱크가 맞춰진 동영상데 이터 중 적어도 어느 하나의 데이터와, 제1 텍스트데이터와 제2 텍스트데이터 중 적어도 어느 하나의 데이터로 생성된 최종파일을 저장하기 위한 최종파일을 포함할 수 있다. 제어부는 오디오처리부에서 검출된 음성데이터에서 적어도 하나의 단위 음성데이터를 확인하여 레코 딩할 수 있다. 제어부는 확인된 단위 음성데이터에 대응되는 적어도 하나의 텍스트데이터를 생성할 수 있 다. 이를 위해, 제어부는 설정관리부, 레코딩관리부, 번역관리부, 싱크관리부 및 파 일관리부를 포함할 수 있다. 설정관리부는 입력부로부터 음성데이터에 대한 번역여부 설정과 관련한 설정신호를 수신할 수 있다. 설정관리부는 설정신호에 따라 음성데이터에 대한 번역여부를 설정하고, 이를 설정정보에 저장할 수 있다. 이때, 설정신호는 오디오처리부를 통해 수신되는 음성데이터 전체를 실시간으로 번역할 것인지, 사 용자로부터 선택되는 단위 음성데이터만을 번역할 것인지를 설정하기 위한 신호일 수 있다. 레코딩관리부는 입력부로부터 레코딩 기능으로의 진입신호를 수신할 수 있다. 레코딩관리부는 상기 진입신호에 의거하여 음성 또는 영상 통화내역, 외부장치로부터 수신되는 멀티미디어 데이터, 전자장치 의 외부 환경에 대한 멀티미디어 데이터를 레코딩할 수 있다. 레코딩관리부는 오디오처리부에서 검출된 음성데이터 전체를 레코딩하거나, 음성데이터에서 적어도 하나의 단위 음성데이터를 확인하여 레코딩할 수 있다. 단위 음성데이터는 언어의 구성요소를 기준으로 형성될 수 있다. 예컨대, 단위 음성데이터는 문장을 기준으로 형성될 수 있으며, 음절, 형태소, 단어, 어절, 구절 등 언어의 다양한 구성요소 중 어느 하나를 기준으로 형성될 수 있다. 레코딩관리부는 검출된 음성데이터 중 에서 음성데이터가 확인된 시점부터 음성데이터가 종료된 시점까지를 단위 음성데이터로 확인하여 레코딩할 수 있다. 이때, 레코딩관리부는 음성데이터가 확인되는 시점보다 임계시간 이전의 시점부터 음성데이터의 확 인이 종료되는 시점보다 임계시간 이후의 시점까지를 단위 음성데이터로 확인하여 레코딩할 수도 있다. 단위 음성데이터는 음원데이터에서 검출된 음성데이터로부터 확인되는 데이터이므로, 음원데이터에 포함된 타임스탬프 정보로부터 단위 음성데이터의 시작과 종료시점을 확인할 수 있다. 레코딩관리부는 레코딩된 멀티미디어 데이터의 종류에 따라 단위 음성데이터, 동영상데이터를 실시간으로 버퍼에 임시 또는 반영구적으로 저장할 수 있다. 레코딩관리부는 단위 음성데이터를 번역관리부(17 3)로 제공할 수 있다. 번역관리부는 번역정보를 참조하여 버퍼에 저장된 적어도 하나의 단위 음성데이터의 번역을 수 행할 수 있다. 이때, 번역관리부는 단위 음성데이터를 이용하여 제1 텍스트데이터를 생성할 수 있다. 번역 관리부는 생성된 제1 텍스트데이터를 타 언어에 대한 제2 텍스트데이터로 생성하여 단위 음성데이터의 번 역을 수행할 수 있다. 이때, 번역관리부는 단위 음성데이터에 해당하는 타임스탬프 정보를 제1 및 제2 텍 스트데이터에 반영할 수 있다. 번역관리부는 단위 음성데이터와 제1 텍스트데이터 및 제2 텍스트데이터를 싱크관리부로 제공할 수 있다. 번역관리부는 설정신호에 따라 레코딩관리부에서 수신되는 단위 음성데이터 전부를 번역하거나, 선택된 단위 음성데이터를 번역할 수 있다. 번역관리부는 단위 음성데이터 번역 시 문장 단위로 번역할 수 있고, 언어의 종류에 따라 음절, 형태소, 단어, 어절, 구절 중 어느 하나의 단 위로 번역될 수 있다. 싱크관리부는 번역관리부에서 제공된 단위 음성데이터, 제1 및 제2 텍스트데이터의 타임스탬프 정보 를 확인하여 각 데이터의 싱크를 맞출 수 있다. 상기 단위 음성데이터가 동영상데이터에 포함된 음성데이터이면 싱크관리부는 동영상데이터와 단위 음성데이터의 타임스탬프를 확인하여 싱크를 맞춘 후에 제1 텍스트데이 터 및 제2 텍스트데이터와의 싱크를 맞출 수 있다. 싱크관리부는 싱크가 완료되면 상기 데이터들을 파일관 리부로 제공할 수 있다. 이때, 싱크를 맞추어야 하는 데이터가 영상통화 시에 획득된 동영상데이터 및 음 성데이터이면, 싱크관리부는 버퍼에 저장된 동영상데이터를 확인할 수 있다. 버퍼에 상대방 영 상과 사용자 영상이 하나의 동영상데이터로 저장된 상태이면 싱크관리부는 동영상데이터와 단위 음성데이 터의 싱크를 맞춘 후에 제1 및 제2 텍스트데이터와의 싱크를 맞출 수 있다. 버퍼에 상대방 영상과 사용자 영상이 각각의 동영상데이터로 저장된 상태이면 각각의 동영상데이터와 단위 음성데이터의 싱크를 맞춘 후에 제 1 및 제2 텍스트데이터와의 싱크를 맞출 수 있다. 파일관리부는 레코딩관리부에서 녹음 또는 음성통화 시의 단위 음성데이터에 대한 레코딩이 수행되었 으면, 단위 음성데이터와 제1 및 제2 텍스트데이터 중 적어도 하나의 텍스트데이터를 하나의 최종파일로 생성할 수 있다. 또한, 파일관리부는 녹화 또는 영상통화 시에 동영상데이터가 레코딩되고, 단위 음성데이터가 레 코딩 되었으면, 제1 및 제2 텍스트데이터 중 적어도 하나의 텍스트데이터와 싱크가 맞춰진 동영상데이터 및 단 위 음성데이터를 하나의 최종파일로 생성할 수 있다. 파일관리부는 생성된 최종파일을 최종파일에 저 장할 수 있다. 파일관리부는 입력부에서 최종파일을 재생시키기 위한 재생신호가 수신되면, 최종파일에서 수신 된 재생신호에 해당하는 파일을 추출하여 오디오처리부의 스피커를 통해 출력할 수 있다. 재생신호에 해당 하는 파일이 녹음 및 음성통화 레코딩을 통해 생성된 최종파일이면, 파일관리부는 오디오처리부의 스 피커와 표시부를 통해 각각 단위 음성데이터와 제1 및 제2 텍스트데이터 중 어느 하나의 텍스트데이터를 출력할 수 있다. 재생신호에 해당하는 파일이 녹화 및 영상통화 레코딩을 통해 생성된 최종파일이면, 파일관리 부는 오디오처리부의 스피커와 표시부를 통해 동영상파일을 출력할 수 있다. 도 2는 본 발명의 다양한 실시 예에 따른 단위 음성데이터를 레코딩하는 방법을 설명하는 순서도이다. 도 1 및 도 2를 참조하면, 11동작에서 제어부는 입력부로부터 레코딩 기능으로의 진입신호가 수신되 면, 13동작을 수행할 수 있다. 레코딩 기능으로의 진입신호가 수신되지 않으면 제어부는 17동작을 수행하 여 대기상태를 유지하거나, 수행 중이던 기능을 지속적으로 수행할 수 있다. 13동작에서 제어부는 오디오처리부로부터 음성데이터를 수신할 수 있다. 오디오처리부는 마이크 에서 획득된 음원데이터를 분석하여 주파수의 특정 파형이 감지되는 부분을 음성데이터로 검출할 수 있다. 이때, 음원데이터는 녹음 또는 음성통화 시에 마이크에서 획득될 수 있고, 녹화 또는 영상통화 시에 마이크에서 획득될 수 있다. 녹화 또는 영상통화 시에 제어부는 음성데이터를 수신할 수 있고, 카메라부에서 획 득된 동영상데이터를 수신할 수 있다. 15동작에서 제어부는 수신된 음성데이터에서 적어도 하나의 단위 음성데이터를 확인하여 실시간으로 레코 딩할 수 있다. 이때, 레코딩은 제어부가 단위 음성데이터 또는 동영상데이터를 저장부에 임시 또는 반영구적으로 저장하는 것을 의미할 수 있다. 제어부는 음성데이터에서 적어도 하나의 단위 음성데이터를 확인할 수 있다. 단위 음성데이터는 언어의 구 성요소를 기준으로 형성될 수 있다. 예컨대, 단위 음성데이터는 문장을 기준으로 형성될 수 있으며, 음절, 형태 소, 단어, 어절, 구절 등 언어의 다양한 구성요소 중 어느 하나를 기준으로 형성될 수 있다. 제어부는 검 출된 음성데이터 중에서 음성데이터가 확인된 시점부터 음성데이터가 종료된 시점까지를 단위 음성데이터로 확 인하여 레코딩할 수 있다. 이때, 제어부는 음성데이터가 확인되는 시점보다 임계시간 이전의 시점부터 음 성데이터의 확인이 종료되는 시점보다 임계시간 이후의 시점까지를 단위 음성데이터로 확인하여 레코딩할 수도 있다. 단위 음성데이터는 음원데이터에서 검출된 음성데이터로부터 확인되는 데이터이므로, 음원데이터에 포함 된 타임스탬프 정보로부터 단위 음성데이터의 시작과 종료시점을 확인할 수 있다. 아울러, 동영상데이터에는 영 상통화의 레코딩 또는 녹화가 시작되는 시점부터 타임스탬프 정보가 생성될 수 있다. 도 3은 본 발명의 다양한 실시 예에 따른 단위 음성데이터를 번역하는 방법을 설명하는 순서도이다. 도 1 내지 도 3을 참조하면, 21동작에서 제어부는 도 2의 15동작에서 저장부에 실시간으로 저장되고 있는 단위 음성데이터를 번역하기 위한 번역모드를 수행할 수 있다. 23동작에서 제어부는 단위 음성데이터 의 번역 설정이 실시간 자동 설정인지 확인할 수 있다. 확인결과, 단위 음성데이터의 번역이 실시간 자동번역 설정이면 제어부는 37동작을 수행하여 실시간으로 저장되고 있는 단위 음성데이터 번역을 수행할 수 있다. 37동작에서 제어부는 제1 언어로 형성된 단위 음성데이터를 분석하여 제1 텍스트데이터를 생성할 수 있다. 제어부는 변환된 제1 텍스트데이터로 제2 언어의 제2 텍스트데이터를 생성하여 단위 음성데이터를 번역할 수 있다. 제어부는 39동작을 수행하여 제1 및 제2 텍스트데이터를 표시부에 표시할 수 있다. 제어부 는 제1 텍스트데이터 또는 제2 텍스트데이터만을 표시부에 표시할 수 있다. 제어부는 표시부 에 텍스트데이터들을 표시하고 33동작을 수행할 수 있다. 또한, 39동작에서 제어부는 도 2에서 획득되는 데이터가 단위 음성데이터를 포함하는 동영상데이터이면 제 어부는 동영상데이터를 표시부에 표시하고, 단위 음성데이터를 번역하여 제1 텍스트데이터와 제2 텍 스트데이터 중 적어도 하나의 텍스트데이터를 동영상데이터에 오버레이하여 표시할 수 있다. 제어부는 표 시부에 텍스트데이터들을 표시하고 33동작을 수행할 수 있다. 단위 음성데이터의 실시간 자동 번역 설정이 아니면 제어부는 25동작을 수행할 수 있다. 25동작에서 제어 부는 제1 언어로 형성된 단위 음성데이터를 분석하여 제1 텍스트데이터를 생성할 수 있다. 제어부는 생성된 제1 텍스트데이터를 표시부에 표시할 수 있다. 27동작에서 제어부는 입력부로부터 번역 을 위한 번역 구간 선택신호가 수신되지 않으면 41동작을 수행할 수 있다. 41동작에서 제어부는 입력부 로부터 번역모드를 종료하기 위한 종료신호가 수신되면 상기 번역모드를 종료할 수 있다. 41동작에서 제어 부는 입력부로부터 종료신호가 수신되지 않으면 25동작으로 회귀하여 상기의 동작을 재수행할 수 있 다. 27동작에서 제어부는 입력부로부터 번역을 위한 번역 구간 선택신호가 수신되면 29동작을 수행할 수 있다. 29동작에서 제어부는 선택신호에 해당하는 단위 음성데이터를 번역할 수 있다. 제어부는 25동 작에서 표시부에 표시되는 제1 텍스트 데이터로 제2 언어의 제2 텍스트데이터를 생성하여 단위 음성데이터 의 번역을 수행할 수 있다. 또한, 제어부는 획득되는 데이터가 음원데이터를 포함하는 동영상데이터이면 제어부는 동영상데이터 를 표시부에 표시할 수 있다. 제어부는 음원데이터에 포함된 단위 음성데이터로 제1 텍스트데이터를 생성하고, 제1 텍스트데이터로 제2 텍스트데이터를 생성할 수 있다. 제어부는 동영상데이터와 단위 음성데 이터의 싱크를 맞추어 표시부에 표시할 수 있다. 제어부는 제1 텍스트데이터 및 제2 텍스트데이터 중 적어도 하나의 텍스트데이터를 동영상데이터에 오버레이하여 표시하거나, 표시부를 분할하여 동영상데이터 가 표시된 영역과 별도의 영역에 표시할 수 있다. 이후, 제어부는 33동작을 수행할 수 있다. 33동작에서 제어부는 입력부로부터 저장메뉴 선택신호가 수신되면 35동작을 수행할 수 있다. 35동작 에서 제어부는 선택신호에 해당하는 단위 음성데이터, 제1 텍스트데이터 및 제2 텍스트데이터의 싱크를 맞 춰 최종파일을 생성하여 저장부에 저장할 수 있다. 또한, 제어부는 동영상데이터, 단위 음성데이터에 포함된 타임스탬프 정보를 확인할 수 있다. 제어부는 동영상데이터, 단위 음성데이터, 제1 텍스트데이터및 제2 텍스트데이터의 싱크를 맞춰 최종파일을 생성한 후 저장부에 저장할 수 있다. 반대로, 33동작에서 제어부는 입력부로부터 저장메뉴에 대한 선택신호가 수신되지 않으면 41동작을 수행할 수 있다. 35과 정에서 저장된 최종파일을 실행할 때에 제어부는 저장된 최종파일의 종류에 따라 단위 음성데이터와 동영 상데이터 중 적어도 하나의 데이터와 제1 텍스트데이터와 제2 텍스트데이터 중 적어도 하나의 텍스트데이터를 동시에 출력할 수 있다. 도 4는 본 발명의 다양한 실시 예 중 일 예에 따른 단위 음성데이터를 번역하는 방법을 설명하기 위한 화면예시 도이다. 도 1 및 도 4를 참조하면, 도 4(a)에서와 같이 전자장치의 사용자가 음성데이터 레코딩을 위한 아이콘(도 면부호 411)를 선택하면, 마이크가 활성화되어 사용자의 음성에 대한 아날로그 음원 신호가 수집될 수 있다. 수 집된 아날로그 음원 신호는 PCM 형태의 음원데이터로 변환되어 도 4(b)의 도면부호 412에서와 같이 표시부(15 0)에 표시될 수 있다. 도면부호 412는 음원데이터에서 분류된 음성데이터의 주파수 정보일 수 있다. 주파수 정 보에서 도면부호 a, b, c, d에 해당하는 영역은 음성데이터가 확인되지 않는 구간이거나, 잡음만 존재하는 구간 일 수 있다. 전자장치는 주파수 정보가 특정 파형을 갖는 것으로 확인된 시점부터 주파수 정보가 특정 파형을 갖는 것으로 확인되지 않는 시점까지를 단위 음성데이터로 획득할 수 있다. 전자장치는 음원데이터에서 음성데이 터를 검출한 이후에 음성데이터에서 적어도 하나의 단위 음성데이터를 확인할 수 있다. 단위 음성데이터는 적어 도 하나의 어절로 이루어진 문장(도면부호 A 또는 B)으로 형성될 수 있다. 문장(예컨대, 도면부호 A)과 문장(예 컨대, 도면부호 B) 사이에서는 임계시간(예컨대, 도면부호 c) 동안 특정 파형이 확인되지 않을 수 있다. 이때, 도면부호 b는 <여러분>과 <안녕하세요> 사이의 구간, 도면부호 d는 <오늘은>과 <바흐에> 사이의 구간일 수 있다. 도면부호 b와 d는 어절과 어절 사이 또는 단어와 단어 사이 등 문장을 형성하는 구성요소 사이에 발화가 잠시 멈춰지는 구간을 나타낼 수 있다. 단위 음성데이터의 실시간 자동 번역이 설정된 상태가 아니면 전자장치는 도 4(b)와 같이 단위 음성데이터 (도면부호 A와 B)를 제1 텍스트데이터로 실시간 변환하여 순차적으로 표시부에 표시할 수 있다. 이때, 제 어부는 도면부호 413a, 414a, 413b, 414b와 같은 체크박스를 표시할 수 있다. 이때, 413a, 413b는 제1 텍 스트데이터를 제2 텍스트데이터로 번역하기 위한 선택신호를 생성하는 체크박스일 수 있고, 414a, 414b는 선택 된 구간에 해당하는 최종파일을 저장하기 위한 체크박스일 수 있다. 표시부에 <여러분, 안녕하세요>라는 제1 텍스트데이터가 표시되고 난 이후에 사용자가 413a을 선택하면 제 어부는 <여러분, 안녕하세요>에 해당하는 제1 텍스트데이터를 제2 언어의 제2 텍스트데이터로 생성하여 <Hello, Guys>와 같이 표시부에 표시할 수 있다. 이때, 제어부는 제2 텍스트데이터의 생성이 완료되 어 표시부에 표시되면 도면부호 415와 같이 제1 및 제2 텍스트데이터가 표시된 영역의 색상을 변경할 수 있다. 표시부에 <오늘은 바흐에 대해서 얘기해볼게요>라고 제1 텍스트데이터가 표시되고 난 이후에, 사용 자가 413b을 선택하면 제어부는 제1 텍스트데이터를 제2 텍스트데이터로 생성할 수 있다. 제2 텍스트데이 터의 생성이 완료되지 않으면 표시부에는 도면부호 416에서와 같이 제2 텍스트데이터로 번역 중임을 알리 는 말줄임표 등을 표시할 수 있다. 제어부는 번역이 완료되면 제2 텍스트데이터를 <오늘은 바흐에 대해서 얘기해볼게요>의 하단에 표시할 수 있고, 도면부호 416의 색상을 변경할 수 있다. 사용자가 414b를 선택하면 제 어부는 <오늘은 바흐에 대해서 얘기해볼게요>에 해당하는 단위 음성데이터, 제1 텍스트데이터 및 제2 텍스 트데이터를 최종파일로 생성하여 저장할 수 있다. 이때, 제어부는 사용자의 선택에 따라 단위 음성데이터 와 제1 텍스트데이터만을 최종파일로 생성할 수 있고, 단위 음성데이터와 제2 텍스트데이터만을 최종파일로 생 성할 수도 있다. 최종파일의 생성이 완료된 이후에, 사용자가 최종파일을 확인하기 위한 메뉴선택 또는 아이콘 선택을 수행하면, 표시부에는 도 4(c)와 같이 저장된 최종파일의 목록이 표시된다. 최종파일 목록은 제1 텍스트데이터의 형 태로 표시될 수 있다. 저장된 최종파일들은 도 4(b)에서 도면부호 414a 또는 414b에 선택신호가 제공된 구간에 대한 최종파일들일 수 있다. 도 4(c)에서 사용자가 도면부호 417과 같이 최종파일 목록 중 어느 하나의 항목을 선택하면, 표시부에는 도 4(d)와 같은 화면이 표시된다. 사용자가 선택한 제1 텍스트데이터에 해당하는 제 2 텍스트데이터를 도면부호 418과 같이 표시하고, 제1 텍스트데이터에 해당하는 단위 음성데이터를 출력할 수 있다. 전자장치는 도 4(d)에서 사용자로부터 도면부호 419가 선택되면 제2 텍스트데이터를 TTS(Text To Speech)로 변환하여 출력할 수 있다. 본 발명의 실시 예에서는 도 4(b)에서 번역을 위한 체크박스를 선택하였을 때, 제2 텍스트데이터로 번역하는 것으로 설명하고 있으나, 반드시 이에 한정되는 것은 아니다. 실시 예에 따르면, 도 4(c)에서와 같이 저장된 최종 파일에서 어느 한 항목에 대한 제1 텍스트데이터가 선택되면, 제1 텍스트데이터가 선택되었을 때에 제2 텍스트 데이터를 생성하여 도 4(d)에서와 같이 표시부에 표시할 수도 있다. 도 5는 본 발명의 다양한 실시 예 중 일 예에 따른 음성통화 시에 단위 음성데이터를 번역하는 방법을 설명하기 위한 화면예시도이다. 도 1, 도 4 및 도 5를 참조하면, 사용자가 상대방과 음성통화 중에 도 5(a)에서와 같이 도면부호 511에 해당하 는 레코딩 버튼을 선택하면, 전자장치는 통화내용에 해당하는 음원데이터에서 검출된 음성데이터를 실시간 으로 레코딩할 수 있다. 전자장치는 통신부를 통해 전송되는 음원데이터에서 검출된 음성데이터를 실 시간으로 레코딩할 수 있다. 전자장치는 음원데이터에서 음성데이터를 검출하고, 검출된 음성데이터에서 적어도 하나의 단위 음성데이터를 추출할 수 있다. 추출된 단위 음성데이터는 도 5(b)의 도면부호 512, 515와 같이 제1 텍스트데이터로 표시할 수 있다. 단위 음성데이터의 실시간 자동 번역이 설정된 상태가 아니면 전자장치는 도 5(b)에서와 같이 단위 음성데 이터를 제1 텍스트데이터로 실시간 변환하여 순차적으로 표시부에 표시할 수 있다. 이때, 제어부는 제1 텍스트데이터에 513a, 513b, 514a, 514b와 같은 체크박스를 표시할 수 있다. 이때, 513a, 513b는 제1 텍스 트데이터를 제2 텍스트데이터로 번역하기 위한 선택신호를 생성하는 체크박스일 수 있고, 513b, 514b는 선택된 구간에 해당하는 최종파일을 저장하기 위한 체크박스일 수 있다. 표시부에 <So, Do you want to go watch a movie?>라는 제1 텍스트데이터가 표시되고 난 이후에 사용자가 513a를 선택하면 제어부는 <So, Do you want to go watch a movie?>에 해당하는 제1 텍스트데이터를 제2 텍스트데이터로 생성하여 <그래서 오늘 영화보러 갈거야?>와 같이 표시부에 표시할 수 있다. 이때, 제어부 는 생성이 완료된 제2 텍스트데이터가 표시부에 표시되면 도면부호 512와 같이 제1 및 제2 텍스트데 이터가 표시된 영역의 색상을 변경할 수 있다. 이때, 사용자가 도면부호 514b를 선택하면 전자장치는 <So, Do you want to go watch a movie?>에 해당하는 단위 음성데이터, 제1 텍스트데이터, 제2 텍스트데이터를 하나 의 최종파일로 생성하여 저장할 수 있다. 전자장치는 최종파일 생성 시에 단위 음성데이터의 타임스탬프를 확인하여 제1 텍스트데이터 및 제2 텍스트데이터와의 싱크를 맞출 수 있다. 이때, 전자장치는 단위 음성데 이터가 변환되어 제1 텍스트데이터가 생성될 때, 단위 음성데이터의 타임스탬프를 확인하여 제1 텍스트데이터에 타임스탬프를 생성할 수 있다. 제1 텍스트데이터를 제2 텍스트데이터로 변환할 때, 제1 텍스트데이터에 생성된 타임스탬프를 제2 텍스트데이터에 타임스탬프로 생성할 수 있다. 전자장치는 단위 음성데이터, 제1 텍스트 데이터 및 제2 텍스트데이터의 타임스탬프를 이용하여 싱크를 맞출 수 있다. 그 이후에, 표시부에 <응>이라는 제1 텍스트데이터가 표시되고 난 이후에 사용자가 513a를 선택하지 않으 면 전자장치는 제2 텍스트데이터를 제외한 제1 텍스트데이터만을 표시부에 표시할 수 있다. 저장된 최종파일을 선택하여 확인하는 방법은 도 4(c)와 도4(d)에서 설명하였으므로 상세한 설명은 생략한다. 이와 같 이, 본 발명은 타 언어를 사용하는 상대방과의 통화 시에 상대방 발화의 번역을 수행하여 대화진행을 매끄럽게 수행할 수 있다. 또한, 본 발명은 문장 단위로 레코딩을 수행하고, 레코딩 파일에서 필요한 부분을 따로 번역하 여 사용자의 편의성을 향상시킬 수 있다. 본 발명은 1:1 음성통화를 하는 기술에 대하여 설명하고 있으나, 반드 시 이에 한정되는 것은 아니며 다양한 언어를 사용하는 사용자들이 음성회의 등을 하는 상황에도 적용될 수 있 다. 도 6은 본 발명의 다양한 실시 예 중 일 예에 따른 영상 통화 시에 단위 음성데이터를 번역하는 방법을 설명하 기 위한 화면예시도이다. 도 1, 도 4 및 도 6을 참조하면, 사용자가 상대방과 영상통화 중에 도 6(a)에서와 같이 도면부호 611에 해당하 는 레코딩 버튼을 선택하면, 전자장치는 통화내용에 해당하는 동영상데이터 및 음원데이터에서 검출된 음 성데이터를 실시간으로 레코딩할 수 있다. 이때, 전자장치는 통신부를 통해 전송되는 동영상데이터 및 음원데이터에서 검출된 음성데이터를 실시간으로 레코딩할 수 있다. 전자장치는 음원데이터에서 추출된 음성데이터에서 단위 음성데이터를 추출할 수 있다. 전자장치는 도 6(a)에서와 같이 표시되는 사용자의 영 상데이터와 상대방의 영상데이터를 하나의 동영상데이터로 레코딩할 수 있고, 각각의 동영상데이터로 레코딩할수 있다. 추출된 단위 음성데이터는 도 6(b)의 도면부호 612, 615와 같이 표시되고, 도 6(b)에서와 같이 사용자 및 통화 상대방에 대한 동영상데이터를 표시부에 지속적으로 출력할 수 있다. 단위 음성데이터의 실시간 자동 번역이 설정된 상태가 아니면 전자장치는 도 6(b)에서와 같이 단위 음성데 이터를 제1 텍스트데이터로 실시간 변환하여 순차적으로 표시부에 표시할 수 있다. 이때, 제어부는 제1 텍스트데이터에 613a, 613b, 614a, 614b와 같은 체크박스를 표시할 수 있다. 이때, 613a, 613b는 제1 텍스 트데이터를 제2 텍스트데이터로 번역하기 위한 선택신호를 생성하는 체크박스일 수 있고, 613b, 14b는 선택된 구간에 해당하는 최종파일을 저장하기 위한 체크박스일 수 있다. 도면부호 612에 대한 설명은 도 5(b)에 기재한 512의 설명과 유사하므로 상세한 설명을 생략한다. <So, Do you want to go watch a movie?>라는 제1 텍스트데이터가 표시된 이후에 표시부에 <응>이라는 제1 텍스트데이 터가 표시될 수 있다. 이때, 사용자가 613a를 선택하면, 제어부는 <응>에 해당하는 제1 텍스트데이터를 제 2 텍스트데이터로 생성하여 <yes>와 같이 표시부에 표시할 수 있다. 제어부는 생성이 완료된 제2 텍 스트데이터가 표시부에 표시되면 도면부호 615와 같이 제1 및 제2 텍스트데이터가 표시된 영역의 색상을 변경할 수 있다. 이때, 사용자가 도면부호 614b를 선택하면 전자장치는 <응>에 해당하는 단위 음성데이터, 동영상데이터, 제1 텍스트데이터, 제2 텍스트데이터를 하나의 최종파일로 생성하여 저장할 수 있다. 전자장치 는 최종파일 생성 시에 단위 음성데이터와 동영상데이터의 타임스탬프를 확인하여 제1 텍스트데이터 및 제 2 텍스트데이터와의 싱크를 맞출 수 있다. 저장된 최종파일을 선택하여 확인하는 방법은 도 4(c)와 도4(d)에서 설명하였으므로 상세한 설명은 생략한다. 본 발명은 타 언어를 사용하는 상대방과의 통화 시에 상대방 발화의 번역을 수행하여 대화진행을 매끄럽게 수행할 수 있다. 또한, 본 발명은 문장 단위로 레코딩을 수행하고, 레코 딩 파일에서 필요한 부분을 따로 번역하여 사용자의 편의성을 향상시킬 수 있다. 본 발명은 1:1 영상통화를 하 는 기술에 대하여 설명하고 있으나, 반드시 이에 한정되는 것은 아니며 다양한 언어를 사용하는 사용자들이 화 상회의 등을 하는 상황에도 적용될 수 있다. 도 7은 본 발명의 다양한 실시 예 중 일 예에 따른 동영상 녹화 시에 단위 음성데이터를 번역하는 방법을 설명 하기 위한 화면예시도이다. 도 1, 도 4 및 도 7을 참조하면, 사용자가 도 7(a)에서와 같이 도면부호 711에 해당하는 레코딩 버튼을 선택하 면, 전자장치는 카메라부와 마이크를 통해 각각 동영상데이터와 음원데이터에서 검출된 음성데이터를 실시간으로 레코딩할 수 있다. 이때, 동영상데이터와 음원데이터는 각각 카메라부와 마이크를 통해 획득될 수 있지만, 통신부를 통해 타 전자장치 또는 서버장치로부터 수신될 수 있다. 전자장치는 음원데이터에서 음성데이터를 검출하고, 검출된 음성데이터에서 적어도 하나의 단위 음성데이 터를 추출할 수 있다. 전자장치는 단위 음성데이터를 분석하여 도 7(b)의 도면부호 712와 같이 제1 텍스트 데이터를 표시할 수 있다. 전자장치는 제1 텍스트데이터로 제2 언어에 대한 제2 텍스트데이터를 생성하여 표시할 수 있다. 단위 음성데이터의 실시간 자동 번역이 설정된 상태이면 전자장치는 사용자로부터 번역을 위한 선택신호 없이 도 7(b)에서와 같이 제1 텍스트데이터와 제2 텍스트데이터를 표시할 수 있다. 예컨대, 레코딩의 대상인 화 자(도면부호 714)가 <여러분, 안녕하세요.>, <오늘은 바흐에 대해서 얘기해볼게요.>라고 발화할 수 있다. 이때, 전자장치는 발화로부터 획득된 단위 음성데이터를 분석하여 제1 텍스트데이터를 생성할 수 있다. 전자장치 는 생성된 제1 텍스트데이터를 번역하여 제2 텍스트데이터를 생성하고, 생성된 제2 텍스트데이터를 표시부 에 표시할 수 있다. 전자장치는 사용자로부터 도면부호 713a, 713b가 선택되면 선택된 구간을 저장할 수 있다. 이때, 전자장치 는 <여러분, 안녕하세요.>와 <오늘은 바흐에 대해서 얘기해볼게요.>에 해당하는 단위 음성데이터, 동영상 데이터, 제1 텍스트데이터, 제2 텍스트데이터를 하나의 최종파일로 생성하여 저장할 수 있다. 전자장치는 최종파일 생성 시에 단위 음성데이터와 동영상데이터의 타임스탬프를 확인하여 제1 텍스트데이터 및 제2 텍스트 데이터와의 싱크를 맞출 수 있다. 저장된 최종파일을 선택하여 확인하는 방법은 도 4(c)와 도4(d)에서 설명하였 으므로 상세한 설명은 생략한다. 본 발명은 강의, 영화, 비디오 등 음성데이터가 포함된 동영상데이터에서 단위 음성데이터에 해당하는 텍스트데이터를 생성하고, 동영상데이터와 단위 음성데이터 및 텍스트데이터의 싱크를 맞춰 자막 생성을 용이하게 할 수 있다. 도 8은 다양한 일 실시 예들에 따른 전자장치를 도시한 블록도이다. 도 8을 참조하면, 본 개시에 따른 전자장치는 예를 들면, 도 1에 도시된 전자장치의 전체 또는 일부 를 구성할 수 있다. 전자장치는 하나 이상의 어플리케이션 프로세서(810, AP: application processor), 통신 모듈, SIM(subscriber identification module) 카드, 메모리, 센서 모듈, 입력 장치 , 디스플레이, 인터페이스, 오디오 모듈, 카메라 모듈, 전력관리 모듈, 배터리 , 인디케이터 및 모터를 포함할 수 있다. AP는 예를 들면, 도 1에 도시된 제어부는 운영체제 또는 응용 프로그램을 구동하여 AP에 연결된 다수의 하드웨어 또는 소프트웨어 구성요소들을 제어할 수 있고, 멀티미디어 데이터를 포함한 각종 데이터 처리 및 연산을 수행할 수 있다. AP는, 예를 들면, SoC(system on chip) 로 구현될 수 있다. 한 실시 예에 따 르면, AP는 GPU(graphic processing unit, 미도시)를 더 포함할 수 있다. 통신 모듈은 예를 들면, 도 1에 도시된 통신부은 전자장치(예: 전자장치 100)와 네트워크를 통 해 연결된 다른 전자장치들 간의 통신에서 데이터 송수신을 수행할 수 있다. 한 실시 예에 따르면, 통신 모듈 은 셀룰러 모듈, Wifi 모듈, BT 모듈, GPS 모듈, NFC 모듈 및 RF(radio frequency) 모듈를 포함할 수 있다. 셀룰러 모듈은 통신망(예: LTE, LTE-A, CDMA, WCDMA, UMTS, WiBro 또는 GSM 등)을 통해서 음성 통화, 영 상 통화, 문자 서비스 또는 인터넷 서비스 등을 제공할 수 있다. 또한, 셀룰러 모듈은, 예를 들면, 가입자 식별 모듈(예: SIM 카드)을 이용하여 통신 네트워크 내에서 전자장치의 구별 및 인증을 수행할 수 있다. 한 실시 예에 따르면, 셀룰러 모듈은 AP가 제공할 수 있는 기능 중 적어도 일부 기능을 수행할 수 있 다. 예를 들면, 셀룰러 모듈은 멀티 미디어 제어 기능의 적어도 일부를 수행할 수 있다. 한 실시 예에 따르면, 셀룰러 모듈은 커뮤니케이션 프로세서(CP: communication processor)를 포함할 수 있다. 또한, 셀룰러 모듈은, 예를 들면, SoC로 구현될 수 있다. 도 8에서는 셀룰러 모듈(예: 커뮤니 케이션 프로세서), 메모리 또는 전력관리 모듈 등의 구성요소들이 AP와 별개의 구성요소로 도시 되어 있으나, 한 실시 예에 따르면, AP가 전술한 구성요소들의 적어도 일부(예: 셀룰러 모듈)를 포함 하도록 구현될 수 있다. 한 실시 예에 따르면, AP 또는 셀룰러 모듈(예: 커뮤니케이션 프로세서)은 각각에 연결된 비휘발성 메모리 또는 다른 구성요소 중 적어도 하나로부터 수신한 명령 또는 데이터를 휘발성 메모리에 로드(load)하여 처리할 수 있다. 또한, AP 또는 셀룰러 모듈은 다른 구성요소 중 적어도 하나로부터 수신하거나 다른 구성요소 중 적어도 하나에 의해 생성된 데이터를 비휘발성 메모리에 저장(store)할 수 있다. Wifi 모듈, BT 모듈, GPS 모듈 또는 NFC 모듈 각각은, 예를 들면, 해당하는 모듈을 통해 서 송수신되는 데이터를 처리하기 위한 프로세서를 포함할 수 있다. 도 8에서는 셀룰러 모듈, Wifi 모듈 , BT 모듈, GPS 모듈 또는 NFC 모듈이 각각 별개의 블록으로 도시되었으나, 한 실시 예에 따르면, 셀룰러 모듈, Wifi 모듈, BT 모듈, GPS 모듈 또는 NFC 모듈 중 적어도 일부 (예: 두 개 이상)는 하나의 integrated chip(IC) 또는 IC 패키지 내에 포함될 수 있다. 예를 들면, 셀룰러 모듈 , Wifi 모듈, BT 모듈, GPS 모듈 또는 NFC 모듈 각각에 대응하는 프로세서들 중 적 어도 일부(예: 셀룰러 모듈에 대응하는 커뮤니케이션 프로세서 및 Wifi 모듈에 대응하는 Wifi 프로세 서)는 하나의 SoC로 구현될 수 있다. RF 모듈는 데이터의 송수신, 예를 들면, RF 신호의 송수신을 할 수 있다. RF 모듈는, 도시되지는 않 았으나, 예를 들면, 트랜시버(transceiver), PAM(power amp module), 주파수 필터(frequency filter) 또는 LNA(low noise amplifier) 등을 포함할 수 있다. 또한, RF 모듈는 무선 통신에서 자유 공간상의 전자파를 송수신하기 위한 부품, 예를 들면, 도체 또는 도선 등을 더 포함할 수 있다. 도 8에서는 셀룰러 모듈, Wifi 모듈, BT 모듈, GPS 모듈 및 NFC 모듈이 하나의 RF 모듈을 서로 공유하는 것으 로 도시되어 있으나, 한 실시 예에 따르면, 셀룰러 모듈, Wifi 모듈, BT 모듈, GPS 모듈 또는 NFC 모듈 중 적어도 하나는 별개의 RF 모듈을 통하여 RF 신호의 송수신을 수행할 수 있다. SIM 카드는 가입자 식별 모듈을 포함하는 카드일 수 있으며, 전자장치의 특정 위치에 형성된 슬롯에 삽입 될 수 있다. SIM 카드는 고유한 식별 정보(예: ICCID(integrated circuit card identifier)) 또는 가입 자 정보(예: IMSI(international mobile subscriber identity))를 포함할 수 있다. 메모리는 예를 들면, 도 1의 저장부은 내장 메모리 또는 외장 메모리를 포함할 수 있다. 내장 메모리는, 예를 들면, 휘발성 메모리(예를 들면, DRAM(dynamic RAM), SRAM(static RAM), SDRAM(synchronous dynamic RAM) 등) 또는 비휘발성 메모리(non-volatile Memory, 예를 들면, OTPROM(one time programmable ROM), PROM(programmable ROM), EPROM(erasable and programmable ROM), EEPROM(electrically erasable and programmable ROM), mask ROM, flash ROM, NAND flash memory, NOR flash memory 등) 중 적어도 하나를 포함할 수 있다. 한 실시 예에 따르면, 내장 메모리는 Solid State Drive (SSD)일 수 있다. 외장 메모리는 flash drive, 예를 들면, CF(compact flash), SD(secure digital), Micro-SD(micro secure digital), Mini-SD(mini secure digital), xD(extreme digital) 또는 Memory Stick 등을 더 포함할 수 있다. 외장 메모리는 다양 한 인터페이스를 통하여 전자장치과 기능적으로 연결될 수 있다. 한 실시 예에 따르면, 전자장치는 하드 드라이브와 같은 저장 장치(또는 저장 매체)를 더 포함할 수 있다. 센서 모듈은 물리량을 계측하거나 전자장치의 작동 상태를 감지하여, 계측 또는 감지된 정보를 전기 신호로 변환할 수 있다. 센서 모듈은, 예를 들면, 제스처 센서(840A), 자이로 센서(840B), 기압 센서 (840C), 마그네틱 센서(840D), 가속도 센서(840E), 그립 센서(840F), 근접 센서(840G), color 센서(840H(예: RGB(red, green, blue) 센서), 생체 센서(840I), 온/습도 센서(840J), 조도 센서(840K) 또는 UV(ultra violet) 센서(840M) 중의 적어도 하나를 포함할 수 있다. 추가적으로 또는 대체적으로, 센서 모듈은, 예를 들면, 후각 센서(E-nose sensor, 미도시), EMG 센서(electromyography sensor, 미도시), EEG 센서 (electroencephalogram sensor, 미도시), ECG 센서(electrocardiogram sensor, 미도시), IR(infra red) 센서 (미도시), 홍채 센서(미도시) 또는 지문 센서(미도시) 등을 포함할 수 있다. 센서 모듈은 그 안에 속한 적어도 하나 이상의 센서들을 제어하기 위한 제어 회로를 더 포함할 수 있다. 입력 장치는 예를 들면, 도 1의 입력부은 터치 패널(touch panel), (디지털) 펜 센서(pen sensor), 키(key) 또는 초음파(ultrasonic) 입력 장치를 포함할 수 있다. 터치 패널(예: 표시부는, 예를 들면, 정전식, 감압식, 적외선 방식 또는 초음파 방식 중 적어도 하나의 방식으로 터치 입 력을 인식할 수 있다. 또한, 터치 패널은 제어 회로를 더 포함할 수도 있다. 정전식의 경우, 물리적 접촉 또는 근접 인식이 가능하다. 터치 패널은 택타일 레이어(tactile layer)를 더 포함할 수도 있다. 이 경우, 터치 패널은 사용자에게 촉각 반응을 제공할 수 있다. (디지털) 펜 센서는, 예를 들면, 사용자의 터치 입력을 받는 것과 동일 또는 유사한 방법 또는 별도의 인 식용 쉬트(sheet)를 이용하여 구현될 수 있다. 키(예: 입력부는, 예를 들면, 물리적인 버튼, 광학식 키 또는 키패드를 포함할 수 있다. 초음파(ultrasonic) 입력 장치는 초음파 신호를 발생하는 입력 도구를 통해, 전자장치에서 마이크로 음파를 감지하여 데이터를 확인할 수 있는 장치로서, 무선 인식이 가능하다. 한 실시 예에 따르면, 전자장치는 통신 모듈를 이용하여 이와 연결된 외부 장치(예: 컴퓨터 또는 서 버)로부터 사용자 입력을 수신할 수도 있다. 디스플레이는 예를 들면, 도 1의 표시부는 패널, 홀로그램 장치 또는 프로젝터을 포 함할 수 있다. 패널은, 예를 들면, LCD(liquid-crystal display) 또는 AM-OLED(active-matrix organic light-emitting diode) 등일 수 있다. 패널은, 예를 들면, 유연하게(flexible), 투명하게(transparent) 또는 착용할 수 있게(wearable) 구현될 수 있다. 패널은 터치 패널과 하나의 모듈로 구성될 수도 있 다. 홀로그램 장치은 빛의 간섭을 이용하여 입체 영상을 허공에 보여줄 수 있다. 프로젝터는 스크 린에 빛을 투사하여 영상을 표시할 수 있다. 스크린은, 예를 들면, 전자장치의 내부 또는 외부에 위치할 수 있다. 한 실시 예에 따르면, 디스플레이은 패널, 홀로그램 장치, 또는 프로젝터를 제어 하기 위한 제어 회로를 더 포함할 수 있다. 인터페이스는, 예를 들면, HDMI(high-definition multimedia interface), USB(universal serial bus), 광 인터페이스(optical interface) 또는 D-sub(D-subminiature)를 포함할 수 있다. 추 가적으로 또는 대체적으로, 인터페이스는, 예를 들면, MHL(mobile high-definition link) 인터페이스, SD(secure Digital) 카드/MMC(multi-media card) 인터페이스 또는 IrDA(infrared data association) 규격 인터 페이스를 포함할 수 있다. 오디오 모듈 예를 들면, 도 1의 오디오처리부는 소리(sound)와 전기신호를 쌍방향으로 변환시킬 수 있다. 오디오 모듈은, 예를 들면, 스피커, 리시버, 이어폰 또는 마이크 등을 통해입력 또는 출력되는 소리 정보를 처리할 수 있다. 카메라 모듈 예를 들면, 도 1의 카메라부는 정지 영상 및 동영상을 촬영할 수 있는 장치로서, 한 실 시 예에 따르면, 하나 이상의 이미지 센서(예: 전면 센서 또는 후면 센서), 렌즈(미도시), ISP(image signal processor, 미도시) 또는 플래쉬 (flash, 미도시)(예: LED 또는 xenon lamp)를 포함할 수 있다. 전력 관리 모듈은 전자장치의 전력을 관리할 수 있다. 도시하지는 않았으나, 전력 관리 모듈은, 예를 들면, PMIC(power management integrated circuit), 충전 IC(charger integrated circuit) 또는 배터리 또는 연료 게이지(battery or fuel gauge)를 포함할 수 있다. PMIC는, 예를 들면, 집적회로 또는 SoC 반도체 내에 탑재될 수 있다. 충전 방식은 유선과 무선으로 구분될 수 있다. 충전 IC는 배터리를 충전시킬 수 있으며, 충전기로부터의 과전압 또는 과전류 유입을 방지할 수 있다. 한 실시 예에 따르면, 충전 IC는 유선 충전 방식 또는 무선 충전 방식 중 적어도 하나를 위한 충전 IC를 포함할 수 있다. 무선 충전 방식으로는, 예를 들면, 자기공명 방식, 자기유도 방식 또는 전자기파 방식 등이 있으며, 무선 충전을 위한 부가적인 회로, 예를 들면, 코일 루프, 공진 회로 또는 정류기 등의 회로가 추가될 수 있다. 배터리 게이지는, 예를 들면, 배터리의 잔량, 충전 중 전압, 전류 또는 온도를 측정할 수 있다. 배터리 는 전기를 저장 또는 생성할 수 있고, 그 저장 또는 생성된 전기를 이용하여 전자장치에 전원을 공급 할 수 있다. 배터리는, 예를 들면, 충전식 전지(rechargeable battery) 또는 태양 전지(solar battery) 를 포함할 수 있다. 인디케이터는 전자장치 혹은 그 일부(예: AP)의 특정 상태, 예를 들면, 부팅 상태, 메시지 상태 또는 충전 상태 등을 표시할 수 있다. 모터는 전기적 신호를 기계적 진동으로 변환할 수 있다. 도시되지 는 않았으나, 전자장치는 모바일 TV 지원을 위한 처리 장치(예: GPU)를 포함할 수 있다. 모바일 TV지원을 위한 처리 장치는, 예를 들면, DMB(digital multimedia broadcasting), DVB(digital video broadcasting) 또는 미디어플로우(media flow) 등의 규격에 따른 미디어 데이터를 처리할 수 있다. 본 개시에 따른 전자장치의 전술한 구성요소들 각각은 하나 또는 그 이상의 부품(component)으로 구성될 수 있 으며, 해당 구성 요소의 명칭은 전자장치의 종류에 따라서 달라질 수 있다. 본 개시에 따른 전자장치는 전술한 구성요소 중 적어도 하나를 포함하여 구성될 수 있으며, 일부 구성요소가 생략되거나 또는 추가적인 다른 구성 요소를 더 포함할 수 있다. 또한, 본 개시에 따른 전자장치의 구성 요소들 중 일부가 결합되어 하나의 개체 (entity)로 구성됨으로써, 결합되기 이전의 해당 구성 요소들의 기능을 동일하게 수행할 수 있다. 본 개시에 사용된 용어 “모듈”은, 예를 들어, 하드웨어, 소프트웨어 또는 펌웨어(firmware) 중 하나 또는 둘 이상의 조합을 포함하는 단위(unit)를 의미할 수 있다. “모듈”은 예를 들어, 유닛(unit), 로직(logic), 논리 블록(logical block), 부품(component) 또는 회로(circuit) 등의 용어와 바꾸어 사용(interchangeably use)될 수 있다. “모듈”은, 일체로 구성된 부품의 최소 단위 또는 그 일부가 될 수 있다. “모듈”은 하나 또는 그 이상의 기능을 수행하는 최소 단위 또는 그 일부가 될 수도 있다. “모듈”은 기계적으로 또는 전자적으로 구현 될 수 있다. 예를 들면, 본 개시에 따른 “모듈”은, 알려졌거나 앞으로 개발될, 어떤 동작들을 수행하는 ASIC(application-specific integrated circuit) 칩, FPGAs(field-programmable gate arrays) 또는 프로그램 가능 논리 장치(programmable-logic device) 중 적어도 하나를 포함할 수 있다. 다양한 실시 예에 따르면, 본 개시에 따른 장치(예: 모듈들 또는 그 기능들) 또는 방법(예: 동작들)의 적어도 일부는, 예컨대, 프로그래밍 모듈의 형태로 컴퓨터로 읽을 수 있는 저장매체(computer-readable storage medi a)에 저장된 명령어로 구현될 수 있다. 명령어는, 하나 이상의 프로세서에 의해 실행될 경우, 하나 이상의 프로 세서가 명령어에 해당하는 기능을 수행할 수 있다. 컴퓨터로 읽을 수 있는 저장매체는, 예를 들면, 메모리가 될 수 있다. 프로그래밍 모듈의 적어도 일부는, 예를 들면, 프로세서에 의해 구현(implement)(예: 실행)될 수 있다. 프로그래밍 모듈 의 적어도 일부는 하나 이상의 기능을 수행하기 위한, 예를 들면, 모듈, 프로그램, 루틴, 명령어 세트 (sets of instructions) 또는 프로세스 등을 포함할 수 있다. 컴퓨터로 판독 가능한 기록 매체에는 하드디스크, 플로피디스크 및 자기 테이프와 같은 마그네틱 매체(Magnetic Media)와, CD-ROM(Compact Disc Read Only Memory), DVD(Digital Versatile Disc)와 같은 광기록 매체 (Optical Media)와, 플롭티컬 디스크(Floptical Disk)와 같은 자기-광 매체(Magneto-Optical Media)와, 그리고 ROM(Read Only Memory), RAM(Random Access Memory), 플래시 메모리 등과 같은 프로그램 명령(예: 프로그래밍 모듈)을 저장하고 수행하도록 특별히 구성된 하드웨어 장치가 포함될 수 있다. 또한, 프로그램 명령에는 컴파일 러에 의해 만들어지는 것과 같은 기계어 코드뿐만 아니라 인터프리터 등을 사용해서 컴퓨터에 의해서 실행될 수있는 고급 언어 코드를 포함할 수 있다. 상술한 하드웨어 장치는 본 개시의 동작을 수행하기 위해 하나 이상의 소프트웨어 모듈로서 작동하도록 구성될 수 있으며, 그 역도 마찬가지다. 본 개시에 따른 모듈 또는 프로그래밍 모듈은 전술한 구성요소들 중 적어도 하나 이상을 포함하거나, 일부가 생 략되거나, 또는 추가적인 다른 구성요소를 더 포함할 수 있다. 본 개시에 따른 모듈, 프로그래밍 모듈 또는 다 른 구성요소에 의해 수행되는 동작들은 순차적, 병렬적, 반복적 또는 휴리스틱(heuristic)한 방법으로 실행될 수 있다. 또한, 일부 동작은 다른 순서로 실행되거나, 생략되거나, 또는 다른 동작이 추가될 수 있다. 그리고 본 명세서와 도면에 개시된 본 개시의 실시 예들은 본 개시의 기술 내용을 쉽게 설명하고 본 개시의 이 해를 돕기 위해 특정 예를 제시한 것일 뿐이며, 본 개시의 범위를 한정하고자 하는 것은 아니다. 따라서 본 개 시의 범위는 여기에 개시된 실시 예들 이외에도 본 개시의 기술적 사상을 바탕으로 도출되는 모든 변경 또는 변 형된 형태가 본 개시의 범위에 포함되는 것으로 해석되어야 한다."}
{"patent_id": "10-2014-0040342", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 다양한 실시 예에 따른 레코딩 지원 전자장치의 주요 구성을 나타내는 블록도이다. 도 2는 본 발명의 다양한 실시 예에 따른 단위 음성데이터를 레코딩하는 방법을 설명하는 순서도이다. 도 3은 본 발명의 다양한 실시 예에 따른 단위 음성데이터를 번역하는 방법을 설명하는 순서도이다. 도 4는 본 발명의 다양한 실시 예 중 일 예에 따른 단위 음성데이터를 번역하는 방법을 설명하기 위한 화면예시 도이다. 도 5는 본 발명의 다양한 실시 예 중 일 예에 따른 음성통화 시에 단위 음성데이터를 번역하는 방법을 설명하기 위한 화면예시도이다. 도 6은 본 발명의 다양한 실시 예 중 일 예에 따른 영상 통화 시에 단위 음성데이터를 번역하는 방법을 설명하 기 위한 화면예시도이다. 도 7은 본 발명의 다양한 실시 예 중 일 예에 따른 동영상 녹화 시에 단위 음성데이터를 번역하는 방법을 설명 하기 위한 화면예시도이다. 도 8은 다양한 일 실시 예들에 따른 전자장치를 도시한 블록도이다."}
