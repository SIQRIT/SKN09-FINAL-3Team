{"patent_id": "10-2019-0060413", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2019-0134513", "출원번호": "10-2019-0060413", "발명의 명칭": "현실 세계를 대표하는 실시간 3D 가상 세계 내에서 실시간 3D 가상 객체의 양방향 실시간 대", "출원인": "티엠알더블유 파운데이션 아이피 앤드 홀딩 에스", "발명자": "옐리 체밧"}}
{"patent_id": "10-2019-0060413", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "실시간 3D 가상 복제물 및 실제 물체의 양방향 대화형 조작을 가능하게 하는 시스템으로서, 적어도 하나의 대응하는 실제 물체의 적어도 하나의 실시간 3D 가상 복제물이 표현되어 있는 데이터 구조를 포함하는 영구 가상 세계 시스템으로서, 메모리 및 적어도 하나의 프로세서를 포함하는 서버 상에서 저장 및 계산되는 것인 상기 영구 가상 세계 시스템;상기 서버 상에서 저장 및 계산되는 상기 영구 가상 세계 시스템을 통해 네트워크를 통해 상기 적어도 하나의실시간 3D 가상 복제물에 통신 가능하게 그리고 영구적으로 연결된 적어도 하나의 대응하는 실제 물체; 및상기 서버 상에서 저장 및 계산되는 상기 영구 가상 세계 시스템을 통해 상기 네트워크를 통해 상기 적어도 하나의 대응하는 실제 물체에 통신 가능하게 그리고 영구적으로 연결된 적어도 하나의 사용자 디바이스를 포함하고,상기 적어도 하나의 실시간 3D 가상 복제물은 상기 적어도 하나의 실제 물체와 상기 적어도 하나의 대응하는 실시간 3D 가상 복제물 사이에서 공유되는 복수의 데이터 포인트를 제공하는 복수의 센싱 메커니즘을 통해 상기적어도 하나의 대응하는 실제 물체와 동기화되고, 그리고 상기 적어도 하나의 실시간 3D 가상 복제물의 가상 물리 속성 및 가상 세계 좌표는 상기 적어도 하나의 대응하는 실제 물체의 물리 속성 및 현실 세계 좌표에 대응하는 것을 특징으로 하는 실시간 3D 가상 복제물 및 실제 물체의 양방향 대화형 조작을 가능하게 하는 시스템."}
{"patent_id": "10-2019-0060413", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1 항에 있어서, 실시간 3D 가상 복제물을 가상적으로 선택한 후 상기 적어도 하나의 사용자 디바이스를 통해상기 실시간 3D 가상 복제물 상에 하나 이상의 변경을 유효화하는 것은 상기 적어도 하나의 대응하는 실제 물체상에 실시간 대응 효과를 야기하는 것을 특징으로 하는 실시간 3D 가상 복제물 및 실제 물체의 양방향 대화형조작을 가능하게 하는 시스템."}
{"patent_id": "10-2019-0060413", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 1 항에 있어서, 상기 적어도 하나의 대응하는 실제 물체 상에 하나 이상의 변경을 유효화하는 것은 상기 대응하는 실시간 3D 가상 복제물 상에 실시간 대응 효과를 야기하는 것을 특징으로 하는 실시간 3D 가상 복제물및 실제 물체의 양방향 대화형 조작을 가능하게 하는 시스템."}
{"patent_id": "10-2019-0060413", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 1 항에 있어서, 상기 적어도 하나의 실시간 3D 가상 복제물 또는 상기 대응하는 적어도 하나의 실제 물체를조작하는 것은 가상-실제 쌍에 영향을 미치는 컨텍스트 데이터의 변화를 생성하는 것을 특징으로 하는 실시간3D 가상 복제물 및 실제 물체의 양방향 대화형 조작을 가능하게 하는 시스템."}
{"patent_id": "10-2019-0060413", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제 1 항에 있어서, 상기 영구 가상 세계 시스템은 네트워크를 통해 2 이상의 사용자에 의해 공유되는 것을 특징으로 하는 실시간 3D 가상 복제물 및 실제 물체의 양방향 대화형 조작을 가능하게 하는 시스템."}
{"patent_id": "10-2019-0060413", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제 1 항에 있어서, 상기 동기화는 상기 실시간 3D 가상 복제물을 보강하고 상기 대응하는 실제 물체의 추가 물리 속성을 제공하기 위해 상기 실시간 3D 가상 복제물에 피드백을 제공하는 것을 포함하고, 상기 동기화는 또한가상 센서, 가상 리소스, 또는 이들의 조합들을 이용함으로써 상기 대응하는 실시간 3D 가상 복제물을 통한 상기 하나 이상의 실제 물체의 보강을 가능하게 하는 것을 특징으로 하는 실시간 3D 가상 복제물 및 실제 물체의양방향 대화형 조작을 가능하게 하는 시스템."}
{"patent_id": "10-2019-0060413", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "공개특허 10-2019-0134513-3-제 1 항에 있어서, 상기 실시간 3D 가상 복제물 또는 상기 실제 물체 중 하나에 대하여 유효화되는 변경은 회전운동, 병진 운동, 하나 이상의 행동의 선택, 하나 이상의 행동의 프로그래밍 또는 하나 이상의 파라미터의설정, 또는 이들의 조합을 포함하는 것을 특징으로 하는 실시간 3D 가상 복제물 및 실제 물체의 양방향 대화형조작을 가능하게 하는 시스템."}
{"patent_id": "10-2019-0060413", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제 1 항에 있어서, 상기 서버는 일제히 그리고 자율적으로 관리하기 위해, 또는 상기 대응하는 실제 물체를 관리하기 위하여 사용자가 복수의 실시간 3D 가상 복제물을 관리하는 것을 돕기 위해 인공 지능 알고리즘 및 그룹분석을 사용하도록 더 구성되어 있고, 상기 인공 지능 알고리즘은 또한 상기 대응하는 실제 물체들 간의 대응하는 협력을 생성하는 하나 이상의 목표에 기초하여 상기 실시간 3D 가상 복제물 간의 협력 및 상호작용을 가능하게 하는 것을 특징으로 하는 실시간 3D 가상 복제물 및 실제 물체의 양방향 대화형 조작을 가능하게 하는 시스템."}
{"patent_id": "10-2019-0060413", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제 1 항에 있어서, 상기 메모리는 상기 영구 가상 세계 시스템에서의 이벤트를 저장하도록 더 구성되고, 이벤트로부터의 데이터는 추후 리뷰를 위해 이벤트를 탐지하고 재생하기 위해 사건 탐지 모듈에 의해 사용되는 것을특징으로 하는 실시간 3D 가상 복제물 및 실제 물체의 양방향 대화형 조작을 가능하게 하는 시스템."}
{"patent_id": "10-2019-0060413", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "실시간 3D 가상 복제물 및 실제 물체의 양방향 대화형 조작을 가능하게 하는 방법으로서,서버 상에, 적어도 하나의 대응하는 실제 물체의 적어도 하나의 실시간 3D 가상 복제물이 표현되어 있는 데이터구조를 포함하는 영구 가상 세계 시스템을 제공하는 단계로서, 상기 적어도 하나의 실시간 3D 가상 복제물의 가상 물리 속성 및 가상 세계 좌표는 상기 적어도 하나의 대응하는 실제 물체의 물리 속성 및 현실 세계 좌표에대응하는 것인 상기 영구 가상 세계 시스템을 제공하는 단계; 센싱 메커니즘들의 조합을 통해 상기 실시간 3D 가상 복제물을 상기 적어도 하나의 대응하는 실제 물체와 동기화시키는 단계로서, 각각의 메커니즘은 상기 적어도 하나의 대응하는 실제 물체와 상기 실시간 3D 가상 복제물간에 공유되는 복수의 데이터 포인트를 제공하는 것인 상기 동기화시키는 단계; 상기 적어도 하나의 대응하는 실제 물체 또는 사용자 디바이스 상의 하나 이상의 인터페이스를 통해 입력되는선택 및/또는 조작 명령을 수신하는 단계로서, 상기 선택 및/또는 조작 명령은 복수의 공유된 데이터 포인트에대한 수정사항을 포함하며, 상기 명령들은 상기 서버 상에서 저장 및 계산되는 상기 영구 가상 세계 시스템을통해 네트워크를 통해 전송되는 것인 상기 수신하는 단계; 상기 선택 및/또는 조작 명령들을 처리하는 단계; 및적어도 하나의 업데이트된 실시간 3D 가상 복제물을 포함하는 상기 영구 가상 세계 시스템을 업데이트하는 단계를 포함하는 것을 특징으로 하는 실시간 3D 가상 복제물 및 실제 물체의 양방향 대화형 조작을 가능하게 하는방법."}
{"patent_id": "10-2019-0060413", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제 10 항에 있어서, 실시간 3D 가상 복제물을 가상적으로 선택한 후 상기 적어도 하나의 사용자 디바이스를 통해 상기 실시간 3D 가상 복제물 상에 하나 이상의 변경을 유효화하는 것은 상기 적어도 하나의 대응하는 실제물체 상에 실시간 대응 효과를 야기하는 것을 특징으로 하는 실시간 3D 가상 복제물 및 실제 물체의 양방향 대화형 조작을 가능하게 하는 방법."}
{"patent_id": "10-2019-0060413", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제 10 항에 있어서, 상기 적어도 하나의 대응하는 실제 물체 상에 하나 이상의 변경을 유효화하는 것은 상기 실시간 3D 가상 복제물 상에 실시간 대응 효과를 야기하는 것을 특징으로 하는 실시간 3D 가상 복제물 및 실제 물체의 양방향 대화형 조작을 가능하게 하는 방법."}
{"patent_id": "10-2019-0060413", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "공개특허 10-2019-0134513-4-제 10 항에 있어서, 상기 적어도 하나의 실시간 3D 가상 복제물 또는 상기 대응하는 실제 물체를 조작하는 것은실시간 3D 가상 복제물 간의 관계에 영향을 미치는, 상기 실제 물체의 컨텍스트 데이터의 변화를 발생시키는 것을 특징으로 하는 실시간 3D 가상 복제물 및 실제 물체의 양방향 대화형 조작을 가능하게 하는 방법."}
{"patent_id": "10-2019-0060413", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제 12 항에 있어서, 상기 영구 가상 세계 시스템은 네트워크를 통해 2 이상의 사용자에 의해 공유되는 것을 특징으로 하는 실시간 3D 가상 복제물 및 실제 물체의 양방향 대화형 조작을 가능하게 하는 방법."}
{"patent_id": "10-2019-0060413", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제 14 항에 있어서, 상기 사용자는 인간 또는 인공 지능 사용자인 것을 특징으로 하는 실시간 3D 가상 복제물및 실제 물체의 양방향 대화형 조작을 가능하게 하는 방법."}
{"patent_id": "10-2019-0060413", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제 10 항에 있어서, 상기 실시간 3D 가상 복제물 또는 상기 실제 물체 중 하나 상에 하나 이상의 변경을 유효화하는 단계를 더 포함하고, 상기 하나 이상의 변경은 회전 운동, 병진 운동, 하나 이상의 행동의 선택, 하나 이상의 행동의 프로그래밍 또는 하나 이상의 파라미터의 설정, 또는 이들의 조합을 포함하는 것을 특징으로 하는실시간 3D 가상 복제물 및 실제 물체의 양방향 대화형 조작을 가능하게 하는 방법."}
{"patent_id": "10-2019-0060413", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제 10 항에 있어서, 상기 동기화는 또한 가상 센서, 가상 리소스, 또는 이들의 조합들을 이용함으로써 상기 대응하는 실시간 3D 가상 복제물을 통해 상기 하나 이상의 실제 물체를 보강하는 것을 특징으로 하는 실시간 3D가상 복제물 및 실제 물체의 양방향 대화형 조작을 가능하게 하는 방법."}
{"patent_id": "10-2019-0060413", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제 12 항에 있어서, 상기 적어도 하나의 대응하는 실제 물체는 공장 기계 또는 운송 수단인 것을 특징으로 하는실시간 3D 가상 복제물 및 실제 물체의 양방향 대화형 조작을 가능하게 하는 방법."}
{"patent_id": "10-2019-0060413", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제 12 항에 있어서, 일제히 그리고 자율적으로 관리하기 위해, 또는 상기 대응하는 실제 물체를 관리하기 위하여 사용자가 복수의 실시간 3D 가상 복제물을 관리하는 것을 돕기 위해 인공 지능 알고리즘 및 그룹 분석을 이용하는 단계를 더 포함하고, 상기 인공 지능 알고리즘은 또한 상기 대응하는 실제 물체들 간의 대응하는 협력을생성하는 하나 이상의 목표에 기초하여 상기 실시간 3D 가상 복제물 간의 협력 및 상호 작용을 가능하게 하는것을 특징으로 하는 실시간 3D 가상 복제물 및 실제 물체의 양방향 대화형 조작을 가능하게 하는 방법."}
{"patent_id": "10-2019-0060413", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제 10 항에 있어서, 상기 가상 세계 시스템에서의 이벤트를 상기 서버의 메모리에 저장하는 단계를 더포함하고, 상기 이벤트로부터의 데이터는 추가 리뷰를 위해 이벤트들을 탐지하고 재생하기 위해 사건 탐지 모듈에 의해 사용되는 것을 특징으로 하는 실시간 3D 가상 복제물 및 실제 물체의 양방향 대화형 조작을 가능하게하는 방법."}
{"patent_id": "10-2019-0060413", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "실시간 3D 가상 복제물 및 실제 객체의 양방향 대화형 오퍼레이션을 가능하게 하는 시스템 및 방법이 설명된다. 이 시스템은 실제 객체의 적어도 하나의 실시간 3D 가상 복제물이 표현되어 있고, 서버 상에서 저장되고 계산되 는 데이터 구조를 포함하는 지속적 가상 세계 시스템; 서버 상에서 저장되고 계산되는 지속적 가상 세계 시스템 을 통해 네트워크를 통해 실시간 3D 가상 복제물에 연결된 적어도 하나의 대응하는 실제 객체; 및 서버 상에서 저장되고 계산되는 가상 세계 시스템을 통해 네트워크를 통해 실제 객체에 연결된 적어도 하나의 사용자 장치를 포함한다. 실시간 3D 가상 복제물 상의 변경사항을 가상으로 선택한 후 유효화하면, 실제 객체 상에 실시간으로 대응하는 효과가 일어난다. 마찬가지로, 실제 개체에 하나 이상의 변경사항을 유효화하면, 실시간 3D 가상 복제 물에 실시간으로 대응하는 효과가 일어난다. 공개특허10-2019-0134513 CPC특허분류 G06F 2217/04 (2013.01)명 세 서 청구범위 청구항 1 실시간 3D 가상 복제물 및 실제 물체의 양방향 대화형 조작을 가능하게 하는 시스템으로서, 적어도 하나의 대응하는 실제 물체의 적어도 하나의 실시간 3D 가상 복제물이 표현되어 있는 데이터 구조를 포 함하는 영구 가상 세계 시스템으로서, 메모리 및 적어도 하나의 프로세서를 포함하는 서버 상에서 저장 및 계산 되는 것인 상기 영구 가상 세계 시스템; 상기 서버 상에서 저장 및 계산되는 상기 영구 가상 세계 시스템을 통해 네트워크를 통해 상기 적어도 하나의 실시간 3D 가상 복제물에 통신 가능하게 그리고 영구적으로 연결된 적어도 하나의 대응하는 실제 물체; 및 상기 서버 상에서 저장 및 계산되는 상기 영구 가상 세계 시스템을 통해 상기 네트워크를 통해 상기 적어도 하 나의 대응하는 실제 물체에 통신 가능하게 그리고 영구적으로 연결된 적어도 하나의 사용자 디바이스를 포함하 고, 상기 적어도 하나의 실시간 3D 가상 복제물은 상기 적어도 하나의 실제 물체와 상기 적어도 하나의 대응하는 실 시간 3D 가상 복제물 사이에서 공유되는 복수의 데이터 포인트를 제공하는 복수의 센싱 메커니즘을 통해 상기 적어도 하나의 대응하는 실제 물체와 동기화되고, 그리고 상기 적어도 하나의 실시간 3D 가상 복제물의 가상 물 리 속성 및 가상 세계 좌표는 상기 적어도 하나의 대응하는 실제 물체의 물리 속성 및 현실 세계 좌표에 대응하 는 것을 특징으로 하는 실시간 3D 가상 복제물 및 실제 물체의 양방향 대화형 조작을 가능하게 하는 시스템. 청구항 2 제 1 항에 있어서, 실시간 3D 가상 복제물을 가상적으로 선택한 후 상기 적어도 하나의 사용자 디바이스를 통해 상기 실시간 3D 가상 복제물 상에 하나 이상의 변경을 유효화하는 것은 상기 적어도 하나의 대응하는 실제 물체 상에 실시간 대응 효과를 야기하는 것을 특징으로 하는 실시간 3D 가상 복제물 및 실제 물체의 양방향 대화형 조작을 가능하게 하는 시스템. 청구항 3 제 1 항에 있어서, 상기 적어도 하나의 대응하는 실제 물체 상에 하나 이상의 변경을 유효화하는 것은 상기 대 응하는 실시간 3D 가상 복제물 상에 실시간 대응 효과를 야기하는 것을 특징으로 하는 실시간 3D 가상 복제물 및 실제 물체의 양방향 대화형 조작을 가능하게 하는 시스템. 청구항 4 제 1 항에 있어서, 상기 적어도 하나의 실시간 3D 가상 복제물 또는 상기 대응하는 적어도 하나의 실제 물체를 조작하는 것은 가상-실제 쌍에 영향을 미치는 컨텍스트 데이터의 변화를 생성하는 것을 특징으로 하는 실시간 3D 가상 복제물 및 실제 물체의 양방향 대화형 조작을 가능하게 하는 시스템. 청구항 5 제 1 항에 있어서, 상기 영구 가상 세계 시스템은 네트워크를 통해 2 이상의 사용자에 의해 공유되는 것을 특징 으로 하는 실시간 3D 가상 복제물 및 실제 물체의 양방향 대화형 조작을 가능하게 하는 시스템. 청구항 6 제 1 항에 있어서, 상기 동기화는 상기 실시간 3D 가상 복제물을 보강하고 상기 대응하는 실제 물체의 추가 물 리 속성을 제공하기 위해 상기 실시간 3D 가상 복제물에 피드백을 제공하는 것을 포함하고, 상기 동기화는 또한 가상 센서, 가상 리소스, 또는 이들의 조합들을 이용함으로써 상기 대응하는 실시간 3D 가상 복제물을 통한 상 기 하나 이상의 실제 물체의 보강을 가능하게 하는 것을 특징으로 하는 실시간 3D 가상 복제물 및 실제 물체의 양방향 대화형 조작을 가능하게 하는 시스템. 청구항 7 제 1 항에 있어서, 상기 실시간 3D 가상 복제물 또는 상기 실제 물체 중 하나에 대하여 유효화되는 변경은 회전 운동, 병진 운동, 하나 이상의 행동의 선택, 하나 이상의 행동의 프로그래밍 또는 하나 이상의 파라미터의 설정, 또는 이들의 조합을 포함하는 것을 특징으로 하는 실시간 3D 가상 복제물 및 실제 물체의 양방향 대화형 조작을 가능하게 하는 시스템. 청구항 8 제 1 항에 있어서, 상기 서버는 일제히 그리고 자율적으로 관리하기 위해, 또는 상기 대응하는 실제 물체를 관 리하기 위하여 사용자가 복수의 실시간 3D 가상 복제물을 관리하는 것을 돕기 위해 인공 지능 알고리즘 및 그룹 분석을 사용하도록 더 구성되어 있고, 상기 인공 지능 알고리즘은 또한 상기 대응하는 실제 물체들 간의 대응하 는 협력을 생성하는 하나 이상의 목표에 기초하여 상기 실시간 3D 가상 복제물 간의 협력 및 상호작용을 가능하 게 하는 것을 특징으로 하는 실시간 3D 가상 복제물 및 실제 물체의 양방향 대화형 조작을 가능하게 하는 시스 템. 청구항 9 제 1 항에 있어서, 상기 메모리는 상기 영구 가상 세계 시스템에서의 이벤트를 저장하도록 더 구성되고, 이벤트 로부터의 데이터는 추후 리뷰를 위해 이벤트를 탐지하고 재생하기 위해 사건 탐지 모듈에 의해 사용되는 것을 특징으로 하는 실시간 3D 가상 복제물 및 실제 물체의 양방향 대화형 조작을 가능하게 하는 시스템. 청구항 10 실시간 3D 가상 복제물 및 실제 물체의 양방향 대화형 조작을 가능하게 하는 방법으로서, 서버 상에, 적어도 하나의 대응하는 실제 물체의 적어도 하나의 실시간 3D 가상 복제물이 표현되어 있는 데이터 구조를 포함하는 영구 가상 세계 시스템을 제공하는 단계로서, 상기 적어도 하나의 실시간 3D 가상 복제물의 가 상 물리 속성 및 가상 세계 좌표는 상기 적어도 하나의 대응하는 실제 물체의 물리 속성 및 현실 세계 좌표에 대응하는 것인 상기 영구 가상 세계 시스템을 제공하는 단계; 센싱 메커니즘들의 조합을 통해 상기 실시간 3D 가상 복제물을 상기 적어도 하나의 대응하는 실제 물체와 동기 화시키는 단계로서, 각각의 메커니즘은 상기 적어도 하나의 대응하는 실제 물체와 상기 실시간 3D 가상 복제물 간에 공유되는 복수의 데이터 포인트를 제공하는 것인 상기 동기화시키는 단계; 상기 적어도 하나의 대응하는 실제 물체 또는 사용자 디바이스 상의 하나 이상의 인터페이스를 통해 입력되는 선택 및/또는 조작 명령을 수신하는 단계로서, 상기 선택 및/또는 조작 명령은 복수의 공유된 데이터 포인트에 대한 수정사항을 포함하며, 상기 명령들은 상기 서버 상에서 저장 및 계산되는 상기 영구 가상 세계 시스템을 통해 네트워크를 통해 전송되는 것인 상기 수신하는 단계; 상기 선택 및/또는 조작 명령들을 처리하는 단계; 및 적어도 하나의 업데이트된 실시간 3D 가상 복제물을 포함하는 상기 영구 가상 세계 시스템을 업데이트하는 단계 를 포함하는 것을 특징으로 하는 실시간 3D 가상 복제물 및 실제 물체의 양방향 대화형 조작을 가능하게 하는 방법. 청구항 11 제 10 항에 있어서, 실시간 3D 가상 복제물을 가상적으로 선택한 후 상기 적어도 하나의 사용자 디바이스를 통 해 상기 실시간 3D 가상 복제물 상에 하나 이상의 변경을 유효화하는 것은 상기 적어도 하나의 대응하는 실제 물체 상에 실시간 대응 효과를 야기하는 것을 특징으로 하는 실시간 3D 가상 복제물 및 실제 물체의 양방향 대 화형 조작을 가능하게 하는 방법. 청구항 12 제 10 항에 있어서, 상기 적어도 하나의 대응하는 실제 물체 상에 하나 이상의 변경을 유효화하는 것은 상기 실 시간 3D 가상 복제물 상에 실시간 대응 효과를 야기하는 것을 특징으로 하는 실시간 3D 가상 복제물 및 실제 물 체의 양방향 대화형 조작을 가능하게 하는 방법. 청구항 13 제 10 항에 있어서, 상기 적어도 하나의 실시간 3D 가상 복제물 또는 상기 대응하는 실제 물체를 조작하는 것은 실시간 3D 가상 복제물 간의 관계에 영향을 미치는, 상기 실제 물체의 컨텍스트 데이터의 변화를 발생시키는 것 을 특징으로 하는 실시간 3D 가상 복제물 및 실제 물체의 양방향 대화형 조작을 가능하게 하는 방법. 청구항 14 제 12 항에 있어서, 상기 영구 가상 세계 시스템은 네트워크를 통해 2 이상의 사용자에 의해 공유되는 것을 특 징으로 하는 실시간 3D 가상 복제물 및 실제 물체의 양방향 대화형 조작을 가능하게 하는 방법. 청구항 15 제 14 항에 있어서, 상기 사용자는 인간 또는 인공 지능 사용자인 것을 특징으로 하는 실시간 3D 가상 복제물 및 실제 물체의 양방향 대화형 조작을 가능하게 하는 방법. 청구항 16 제 10 항에 있어서, 상기 실시간 3D 가상 복제물 또는 상기 실제 물체 중 하나 상에 하나 이상의 변경을 유효화 하는 단계를 더 포함하고, 상기 하나 이상의 변경은 회전 운동, 병진 운동, 하나 이상의 행동의 선택, 하나 이 상의 행동의 프로그래밍 또는 하나 이상의 파라미터의 설정, 또는 이들의 조합을 포함하는 것을 특징으로 하는 실시간 3D 가상 복제물 및 실제 물체의 양방향 대화형 조작을 가능하게 하는 방법. 청구항 17 제 10 항에 있어서, 상기 동기화는 또한 가상 센서, 가상 리소스, 또는 이들의 조합들을 이용함으로써 상기 대 응하는 실시간 3D 가상 복제물을 통해 상기 하나 이상의 실제 물체를 보강하는 것을 특징으로 하는 실시간 3D 가상 복제물 및 실제 물체의 양방향 대화형 조작을 가능하게 하는 방법. 청구항 18 제 12 항에 있어서, 상기 적어도 하나의 대응하는 실제 물체는 공장 기계 또는 운송 수단인 것을 특징으로 하는 실시간 3D 가상 복제물 및 실제 물체의 양방향 대화형 조작을 가능하게 하는 방법. 청구항 19 제 12 항에 있어서, 일제히 그리고 자율적으로 관리하기 위해, 또는 상기 대응하는 실제 물체를 관리하기 위하 여 사용자가 복수의 실시간 3D 가상 복제물을 관리하는 것을 돕기 위해 인공 지능 알고리즘 및 그룹 분석을 이 용하는 단계를 더 포함하고, 상기 인공 지능 알고리즘은 또한 상기 대응하는 실제 물체들 간의 대응하는 협력을 생성하는 하나 이상의 목표에 기초하여 상기 실시간 3D 가상 복제물 간의 협력 및 상호 작용을 가능하게 하는 것을 특징으로 하는 실시간 3D 가상 복제물 및 실제 물체의 양방향 대화형 조작을 가능하게 하는 방법. 청구항 20 제 10 항에 있어서, 상기 가상 세계 시스템에서의 이벤트를 상기 서버의 메모리에 저장하는 단계를 더 포함하고, 상기 이벤트로부터의 데이터는 추가 리뷰를 위해 이벤트들을 탐지하고 재생하기 위해 사건 탐지 모듈 에 의해 사용되는 것을 특징으로 하는 실시간 3D 가상 복제물 및 실제 물체의 양방향 대화형 조작을 가능하게 하는 방법. 발명의 설명"}
{"patent_id": "10-2019-0060413", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시물의 양태는 일반적으로 컴퓨터 시스템에 관한 것이며, 더 구체적으로는 실시간 3D 가상 복제물 및 실제 물체의 양방향 대화형 오퍼레이션을 가능하게 하는 시스템 및 방법에 관한 것이다."}
{"patent_id": "10-2019-0060413", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "현재 제조, 군대 및 자동차와 같은 산업은 제어 기술을 활용하여 관련된 다양한 물체의 수동 및 능동 관리와 함 께 모니터링을 가능하게 하는 제어 기술로부터 이점을 누린다. 예를 들어, 제조 공정 내의 다양한 물체들은 대 개 워크스테이션의 컴퓨터를 통해 원격으로 관리된다. 이 워크스테이션은 최근에 고정식 컴퓨터로부터, 보다사용자 친화적이고 유연한 휴먼 머신 인터페이스(HMI)를 제공하는 모바일 장치로 업그레이드되었다. 그럼에도 불구하고, 대부분의 관심 물체가 워크스테이션에서 표시되고 관리 가능할 수 있으나, 이러한 물체와의 상호 작용은 여전히 자연스러운 방식으로 수행되지 않을 수 있다. 예를 들어, 사용자 경험(UX)은 사용자가 물 체를 조작할 수 있게 해주는 수 개의 버튼을 포함할 수 있는데, 이는 많은 수의 제어 버튼이 포함되어 있을 때 번거로워지는 경향이 있다. 또한 실제 관심 물체에 대한 변경은 효과적인 모니터링 및 관리를 위해 필요할 수 있는 대부분의 세부 정보를 포함하도록 완전히 동기화되지 않을 수 있다. 다양한 요소 들간의 협력은 일반적으 로 소수의 물체로 제한되며, 많은 경우에 엄청난 양의 사람의 상호 작용이 필요하다. 또한 제어 기술이 필요한 애플리케이션에 대한 기회를 제공하는 증강 현실 및 가상 현실과 같은 디지털 현실 기술은 효율적인 관리를 용 이하게 하기 위해 완전히 활용되지 못하고 있다. 따라서, 실제 물체간의 그리고 실제 물체와의 더 동기화된 통신 및 상호 작용을 가능하게 하는 시스템 및 방법 을 개발할 필요성이 존재한다."}
{"patent_id": "10-2019-0060413", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 설명은 아래의 상세한 설명에 더 설명되는 간단한 형태의 개념 선택을 소개하기 위해 제공된 것이다. 본 설 명은 청구된 주제의 주요 특징을 식별하기 위한 것이 아니며 청구된 주제의 범위를 결정하는 데 도움을 주기 위 한 것이 아니다. 본 개시물은 실제 물체의 정확한 가상 복제물을 통한 인터페이스를 통해 실제 물체 간의 및 실체 물체와의 자연 스러운 제어 및 실시간 3D 기반 상호 작용을 가능하게 하는 시스템 및 방법을 제공하며, 실제 물체의 직접적인 제어를 통해 가상 복제의 동기화 된 제어를 제공한다. 본 개시물 설명에서, \"실제 물체\"라는 용어는 네트워크 에 연결될 수 있고 몇몇 물리적 방법으로 원격 제어, 수정 또는 설정될 수 있는 임의의 물리적 물체, 장치 또는 기계를 의미한다. 일부 실시예에서, 실제 물체는 복수의 소스로부터 센서 정보를 수신한다. 일부 실시예에서, 실제 물체는 사물 인터넷(IOT) 배치에서 네트워크를 통해 서로 또는 다른 디바이스와 통신 가능하게 접속될 수 있으며, 그러한 배치에서 그러한 디바이스들은 IoT 디바이스로 지칭된다. 정확한 가상 복제물은 실제 물체의 실시간 3D 가상 복제물을 참조할 수 있으며, 실제 물체와 동기화되어 동일하거나 거의 동일한 물리적 특성 및 공유 데이터를 통해 실제 위치 및 방향을 포함한 실제 좌표를 포함할 수 있다. 예를 들어, 실시간 3D 가상 복 제물의 직접 조작은 실시간으로 복수의 산업 기계 또는 차량을 원격으로 관리하는 데 유용할 수 있다. 유사하 게, 예를 들어, 산업 기계의 직접 조작은 프로세스 관리자 또는 기계 조작자가 시스템의 모든 물체를 표시하고 관리하는 실시간으로 지속적으로 업데이트되는 모델을 필요로 할 때 유용할 수 있다. 실제 물체 및 실시간 3D 가상 복제물의 쌍은 본 명세서에서 가상 트윈, 가상-실제 쌍 또는 실제-가상 쌍으로 지칭될 수 있다. 개시된 시스템 및 방법의 추가 애플리케이션은 증강 현실, 가상 현실 또는 혼합 현실과 같은 현실 세계와 관련하여 사 용자의 인식을 변화시킬 수 있는 디지털 현실을 통해 제공되는 실시간 3D 가상 복제물에 의해 가능해질 수 있다. 본 개시물의 시스템 및 방법은 공장 또는 가정, 이웃, 도시, 국가 및 그 이상과 같이 상이한 복잡성 수 준에서의 운영 관리에 적합 할 수 있다. 본 발명의 상세한 설명 및 이하의 상세한 설명에서 설명된 다른 실시 예들에서, 본 개시물의 추가적인 용도 및 이점이 명백해질 수 있다. 본 개시물의 실제 물체 및 3D 실시간 가상 복제물의 양방향 실시간 3D 대화형 조작을 가능하게 하는 시스템은 적어도 하나의 대응하는 실제 물체의 하나의 실시간 3D 가상 복제물이 표현되어 있는 데이터 구조를 포함하며 서버 상에서 저장 및 계산되는 영구 가상 세계 시스템; 서버 상에서 저장 및 계산되는 영구 가상 세계 시스템을 통해 네트워크를 통해 적어도 하나의 실시간 3D 가상 복제물에 통신 가능하고 영구적으로 연결된 적어도 하나의 대응하는 실제 물체; 및 서버 상에서 저장 및 계산되는 영구 가상 세계 시스템을 통해 상기 네트워크를 통해 상 기 하나 이상의 실제 물체들에 통신 가능하고 영구적으로 연결된 적어도 하나의 사용자 디바이스를 포함한다. 적어도 하나의 실시간 3D 가상 복제물은 적어도 하나의 실제 물체와 적어도 하나의 실시간 3D 가상 복제물 간에 공유되는 복수의 데이터 포인트를 제공하는 복수의 센싱 메커니즘을 통해 적어도 하나의 대응하는 실제 물체와 동기화된다. 또한, 적어도 하나의 실시간 3D 가상 복제물의 가상 물리 속성 및 가상 세계 좌표는 대응하는 하 나 이상의 실제 물체의 물리 속성 및 실제 좌표에 대응한다. 복수의 센싱 메카니즘은 가상-실제 쌍 사이에서공유되는 복수의 데이터 포인트를 제공하는 IoT 센싱 메카니즘의 조합일 수 있다. 적합한 인터페이스를 통해 적어도 하나의 실시간 3D 가상 복제물 또는 대응하는 실제 물체 중 하나에서 하나 이 상의 변경을 유효화하면, 서버는 실시간 또는 비 실시간으로 조작 명령을 처리하여 가상 세계를 통한 현실 세계 의 관리를 가능하게 한다. 그 후, 서버는 이들 처리된 명령을 각각의 타겟 실제 물체 또는 각각의 실시간 3D 가상 복제물으로 전송할 수 있다. 보다 구체적으로, 실시간 3D 가상 복제물을 가상으로 선택하고 그 후 적어도 하나의 사용자 디바이스를 통해 실시간 3D 가상 복제물에 대한 하나 이상의 변경을 수행하면 대응 실제 물체에 실시간으로 대응 효과가 발생한다. 마찬가지로 실제 물체에 하나 이상의 변경을 적용하면 실시간 3D 가상 복제 물에 실시간으로 대응하는 결과가 발생한다. 본 개시물의 일 양태에 따르면, 실제 물체 및 실시간 3D 가상 복제물의 조작 방향은 양방향이다. 예를 들어, 조작은 대응하는 실제 물체를 제어하기 위해, 또는 적어도 하나의 물체 조작자와의 상호작용으로부터 적어도 하 나의 실시간 3D 가상 복제물과 사용자의 상호작용으로부터 생성된 데이터 및 명령으로서 생성될 수 있고, 적어 도 하나의 실제 물체는 대응하는 실시간 3D 가상 복제물에 직접적인 영향을 미친다. 그러나, 인공 지능, 그룹 분석, 시뮬레이션 및 컨텍스트 계산의 결과로서 드론, 자율 주행 차량, 로봇, 도시의 건물(예컨대, 서로 통신하 는 가상 건물 관리자), 기계 및 컴퓨터 비전 애플리케이션, 개인 비서, 비디오 게임, 등과 같은, 실제 물체 간 의 협력이 필요한 경우 실시간 3D 가상 복제물 자체 간의 상호작용이 발생할 수 있다. 일 실시예에 따르면, 적 어도 하나의 실시간 3D 가상 복제물 또는 대응하는 적어도 하나의 실제 물체를 조작하는 것은 가상-실제 쌍에 영향을 주는 컨텍스트 데이터에 대한 변경을 발생시키며, 컨텍스트 데이터의 이러한 변경은 적어도 하나의 실제 물체에 대응하는 실시간 3D 가상 복제물 간의 관계에 영향을 줄 수 있다. 본 개시물에서 사용되는 용어 \"컨텍 스트\"또는 \"컨텍스트 데이터\"는 실시간 3D 가상 복제물 및 대응 실제 물체의 직접적 또는 간접적 환경에 관련된 데이터를 말하며, 실제 물체의 환경에 있는 다른 물체를 포함한다. 본 개시물에서, 컨텍스트는 마이크로-컨텍 스트와 매크로-컨텍스트로 더 분류될 수 있다. \"마이크로 컨텍스트\"라는 용어는 현실 세계 요소에 직접 영향을 줄 수 있는 임의의 사람, 개체 또는 조건과 같 이 실제 물체 바로 옆 주변 컨텍스트를 나타낸다. 마이크로 컨텍스트는, 예를 들어, 실제 물체 바로 옆 그리고 실제 물체에 영향을 주는 환경의, 여러 가지 중에서도 특히, 3D 이미지 데이터, 3D 기하학적 형상, 3D 엔티티, 3D 센서 데이터, 3D 동적 물체, 비디오 데이터, 오디오 데이터, 텍스트 데이터, 시간 데이터, 메타 데이터, 우 선 순위 데이터, 보안 데이터, 위치 데이터, 조명 데이터, 온도 데이터 및 서비스 품질(QOS, Quality of Service)과 같은 정보를 포함할 수 있다. \"매크로 컨텍스트\"이라는 용어는 실제 물체를 둘러싸고 있는 간접적 이거나 먼 컨텍스트를 의미한다. 매크로 컨텍스트는 다수의 마이크로 컨텍스트로부터 서버에 의해 도출될 수 있으며, 이는 제조 플랜트의 현재 효율, 대기질, 기후 변화 수준, 회사 효율, 트래픽 수준, 도시 효율성, 국가 효율성 등과 같은, 시스템의 많은 전체론적인 정보를 발생시킨다. 매크로 컨텍스트는 로컬 수준(예컨대, 사무 실 또는 제조 공장), 인접 수준, 도시 수준, 국가 수준 또는 심지어 행성 수준을 포함하여, 지정된 기계 학습 기능 및 목표에 따라 다양한 수준에서 고려되고 계산될 수 있다. 따라서, 특정 기계 학습 기능 및 목표에 따라, 동일한 현실 세계 요소 데이터 및 마이크로 컨텍스트 데이터가 다양한 유형의 매크로 컨텍스트를 도출할 수 있다. 일부 실시예에서, 네트워크는, 예를 들어, 셀룰러 네트워크일 수 있고, EDGE(enhanced data rates for global evolution), GPRS(general packet radio service), GSM(global system for mobile communications), IMS(Internet protocol multimedia subsystem), UMTS(universal mobile telecommunications system), 등, 임 의의 다른 적절한 무선 매체, 예컨대, WiMAX(microwave access), LTE(Long Term Evolution) 네트워크, CDMA(code division multiple access), WCDMA(wideband code division multiple access), WiFi(wireless fidelity), 및 MANET(satellite, mobile ad-hoc network) 등을 포함하는 다양한 기술을 이용할 수 있다. 일 실시예에 따르면, 네트워크는 실제 물체 간의 그리고 서버와의 이동 통신을 가능하게 하 는 라디오파를 송신 및 수신하도록 구성된 안테나를 포함할 수 있다. 안테나는 유선 또는 무선 수단을 통해 컴퓨팅 센터에 연결될 수 있다. 다른 실시예에서, 안테나는 컴퓨팅 센터 및/또는 컴퓨팅 센터 근처의 영역 내에 제공된다. 일부 실시예 에서, 사용자 디바이스 및/또는 실외에 위치하는 실제 물체를 서비스하기 위해, 안테나는 밀리미터 파(mmW) 기 반 안테나 시스템 또는 mmW 기반 안테나 및 서브-6GHz 안테나 시스템의 조합(본 명세서에서는 5G 안테나라고 분 류도고 지칭됨)을 포함할 수 있다. 다른 실시예에서, 안테나는 4G 안테나와 같은 다른 유형의 안테나를 포함할 수 있거나 또는 5G 안테나 시스템을 위한 지원 안테나로서 사용될 수 있다. 실내에 위치하는 실시간 3D 기반 상호 작용 장치를 서비스하기 위해 안테나가 사용되는 실시예에서, 안테나는 제한하는 것은 아니지만 바람직하 게는 16 GHz로 데이터를 제공하는 Wi-Fi를 사용할 수 있다. 다른 실시예에서, GPS, BDS, 글로나스(Glonass), QZSS, 갈릴레오(Galileo), 및 IRNSS와 같은 복수의 위성-기반 내비게이션 시스템을 통칭하는 GNSS(global navigation satellite systems)이 장치의 위치 파악을 가능하게 하 기 위해 사용될 수 있다. GNSS는 삼각법 및 삼각측량법과 같은 기술 및 충분한 수의 위성으로부터의 신호를 사 용하여 장치의 위치, 속도, 고도 및 시간을 계산할 수 있다. 바람직한 실시예에서, 외부 포지셔닝 시스템은 기 존 셀룰러 통신 네트워크의 아키텍처를 통해 AGNSS(assisted GNSS)에 의해 증강되는데, 여기서 기존 아키텍처는 5G를 포함한다. 다른 실시예에서, AGNSS 추적 시스템은 4G 셀룰러 통신 네트워크에 의해 추가적으로 지원된다. 실내 실시예에서, GNSS는 제한하는 것은 아니지만 바람직하게는 16 GHz에서 데이터를 제공하는 Wi-Fi와 같은 라 디오 무선 근거리 통신망을 통해 추가로 증강된다. 대안적인 실시예에서, GNSS는 DGPS(differential GPS), 위 성 기반 증강 시스템(SBAS), RTK(real-time kinematic) 시스템 등을 통해 당업계에 공지된 다른 기술을 통해 증 강된다. 일부 실시예에서, 장치의 추적은 장치 내의 AGNSS 및 관성 센서의 조합에 의해 구현된다. 일 실시예에 따르면, 서버는 적어도 프로세서 및 메모리를 포함하는 하드웨어 및 소프트웨어로서 제공될 수 있 으며, 프로세서는 서버에 결합된 메모리에 포함 된 명령을 실행하도록 구성될 수 있으며, 메모리는 명령 및 데 이터를 저장하도록 구성된다. 예를 들어, 프로세서는 대응하는 실시간 3D 가상 복제물, 실제 물체의 시뮬레이 션, 3D 구조 처리, 컨텍스트 계산, 그룹 분석, 렌더링을 통한 적어도 하나의 실제 물체의 관리 및 실시간 3D 가 상 복제물을 통한 실제 대응부의 가상 보강 또는 가상 보상의 구현을 위한 인공 지능 알고리즘을 구현하도록 구 성될 수 있다. 일부 실시예에서, 프로세서는 또한 가상 및 실제 쌍의 움직임을 동기화하기 위해 조작 명령에 대한 운동학적 계산을 수행함으로써 실제 물체 및 실시간 3D 가상 복제물의 쌍방향 상호작용 동작을 가능하게 한다. 일 실시예에서, 서버 프로세서에 의한 조작 명령들의 프로세싱은 자신의 프로세서를 통해 하나 이상의 실제 물체에 의해 수행되는 프로세싱의 보완이며, 이는 어떤 무거운 태스크 처리를 수행하기 위한 실제 물체들 에 대한 지원으로서 작용한다. 다른 실시예에서, 프로세서는 또한 사용자에게 전송되는 비디오 및 오디오 스트 림을 포함하는 미디어 콘텐츠의 렌더링을 수행한다. 프로세서는 또한 사용자가 보는 위치, 방향 및/또는 시야 각에 기초하여 사용자 디바이스로 전달될 2 이상의 미디어 스트림을 결정할 수 있다. 메모리는 현실 세계 물체의 위치, 방향, 규모 및 치수, 물리 속성 및 실시간 3D 가상 복제물의 형태의 실제 물 체 각각의 3D 구조와 같은, 현실 세계 좌표를 표함하는, 현실 세계의 디지털 버전을 포함하는 영구 가상 세계 시스템을 저장할 수 있다. 또한, 메모리는 사용자가 실제 물체의 실시간 3D 가상 복제물을 생성하고 편집할 수 있게 하도록 구성된 컨텐츠 또는 가상 복제물 편집기를 포함할 수 있다. 그러나, 영구 가상 세계 시스템은 순 수 가상 물체와 같이 현실 세계에 존재하지 않을 수도 있는 컴퓨터 생성 가상 물체를 더 포함할 수 있다. 일부 실시예에서, 영구 가상 세계 시스템은 2 명 이상의 사용자에 의해 공유되며, 이는 영구 가상 세계 시스템 내의 하나 이상의 실시간 3D 가상 복제물의 임의의 변화가 2 명 이상의 사용자에게 보여질 수 있음을 의미한다. 본 개시물에서, 용어 \"영구\"는 연속적으로 실행되는 프로세스 또는 네트워크 연결없이 계속 존재할 수 있는 시스템 의 상태를 특징짓는데 사용된다. 예를 들어, \"영구\"이라는 용어는 실시간 3D 가상 복제물을 생성하기 위해 사 용되는 프로세스가 중단된 후에 그리고 가상 세계 시스템에 사용자가 연결되어 있는지 여부와 무관하게, 가상 세계 시스템 및 그 안에 포함 된 모든 실시간 3D 가상 복제물이 계속 존재하는 가상 세계 시스템을 특징짓는데 사용될 수 있다. 따라서 가상 세계 시스템은 서버의 비휘발성 저장 위치에 저장된다. 이러한 방식으로 실시간 3D 가상 복제물은 사용자가 서버에 연결되어 있지 않아도 특정 목표를 달성하도록 구성될 때 서로 상호 작용하 고 협업할 수 있다. 일부 실시예에서, 메모리는 영구 가상 세계 시스템에 이벤트를 더 저장할 수 있다. 이벤트를 저장하면, 예를 들어, 사건 탐지 모듈이 추가 리뷰를 위해 이벤트를 탐지하고 재생할 수 있다. 사건은 일반적인 이벤트 흐름의 붕괴를 나타낸다. 일반적인 이벤트 흐름은 파라미터 범위 또는 특성 내에서 결정될 수 있다. 다른 실시예에서, 사건은 서버에 구현된 규칙 기반 시스템을 통해 식별된다. 다른 실시예에서, 사건은 서버에 구현 된 기계 학습 알고리즘을 통해 식별된다. 메모리는 컴퓨터 판독 가능 매체, 또는 하드 드라이브, 메모리 카드, 플래시 드라이브, ROM, RAM, DVD 또는 다 른 광학 디스크 뿐만 아니라 다른 기록 가능 및 판독 전용 메모리 등과 같은 전자 장치의 도움을 받아 판독될 수 있는 데이터를 저장하는 다른 매체를 포함하여, 프로세서에 의해 액세스 가능한 정보를 저장할 수 있는 임의 의 적합한 유형일 수 있다. 메모리에는 영구 저장소 외에 임시 저장소가 포함될 수 있다. 명령은 프로세서에 의해 직접(예를 들어, 기계 코드) 또는 간접적으로(예를 들어, 스크립트들) 실행될 수 있다. 명령은 프로세서 에 의한 직접 처리를 위한 목적 코드 포맷으로 저장될 수도 있고, 또는 요구에 따라 해석되거나 사전에 컴파일 될 수 있는 독립 소스 코드 모듈의 스크립트 또는 콜렉션을 포함하는 임의의 다른 컴퓨터 언어로 저장될 수도 있다. 데이터는 명령에 따라 프로세서에 의해 검색, 저장 또는 수정될 수 있다. 데이터는, 예를 들어, 컴퓨터레지스터에, 관계형 데이터베이스에 복수의 상이한 필드 및 레코드를 같는 테이블, XML 문서 또는 플랫 파일로 서 저장될 수 있다. 데이터는 임의의 컴퓨터 판독 가능한 포맷으로 포맷팅될 수도 있다. 프로세서는 단일 전 용 프로세서, 단일 공유 프로세서 또는 그 중 일부가 공유될 수 있는 복수의 개별 프로세서를 지칭할 수 있다. 또한, \"프로세서\"라는 용어 명백한 사용은 소프트웨어를 실행할 수 있는 하드웨어만을 지칭하는 것으로 해석되 어서는 안되며, 제한하는 것은 아니지만 암시적으로 DSP(digital signal processor) 하드웨어, 네트워크 프로세 서, 주문형 반도체(ASIC: application specific integrated circuit), 현장 프로그래밍 가능한 게이트 어레이 (FPGA: field programmable gate array), 마이크로 프로세서, 마이크로 제어기 등을 포함할 수 있다. 일 실시예에 따르면, 서버의 메모리에 저장된 복제물 편집기는 사용자가 실제 물체의 실시간 3D 가상 복제물을 모델링하고 편집할 수 있도록 구성된 소프트웨어 및 하드웨어를 포함한다. 복제물 편집기는, 예를 들어, 가상 복제물을 입력 및 편집하는데 필요한 데이터 및 지시를 저장할 수 있는 CAD(computer-aided drawing) 소프트웨 어 애플리케이션일 수 있다. 복제물 편집기는 모양, 위치, 위치 및 방향, 물리적 특성, 3D 구조 및 전체적으로 실시간 3D 가상 복제물 및 영구 가상 세계 시스템의 예상 기능 및 영향을 설명하는 데이터 및 명령을 나타내는, 각각의 디지털 복제물과 관련된 명시적인 데이터 및 명령의 입력을 가능하게 할 수 있다. 일반적으로, 명시적 데이터는 센싱 메커니즘으로는 얻을 수 없지만 건물 자재, 벽 두께, 전기 설비 및 회로, 수도관, 소화기, 비상 구, 창문 위치, 기계 성능 파라미터, 기계 센서 및 밸브 위치 등과 같은, 복제물 편집기를 통해 디지털 방식으 로 입력될 필요가 있는 데이터를 포함할 수 있다. 본 명세서에서 사용된 \"명령\"은 프로세서에 의해 이해되고 실시간 3D 가상 복제물에서 현실 세계 요소의 행동을 나타내는 코드(예를 들어, 2 진 코드)를 지칭한다. 실제 물체를 명시적인 데이터 및 명령을 통해 실시간 3D 가상 복제물으로 변환하고 영구 가상 세계 시스템에서 사용할 수 있도록 만드는 모델링 기법은 실제 물체의 쉽게 사용 가능한 CAD 모델을 기반으로 할 수 있다. 예를 들어, 기계 소유자는 영구 가상 세계 시스템의 관리자에게 자신의 기계의 기존 디지털 CAD 모델을 제공하거나 입력할 수 있다. 이와 유사하게, 건물 소유주는 서버의 영구 가상 세계 시스템에 저장될 건물 세부 정보와 함 께 건물 정보 모델(BIM)을 제공할 수 있으며, 이 정보는 센싱 메커니즘을 통해 보이지 않거나 쉽게 얻을 수 없 는 정보를 포함할 수 있다. 이러한 실시예에서, 이들 실제 물체의 소유자는, 예를 들어, 인센티브 시스템 또는 법적 요건을 통해 달성될 수 있는, 각각의 실시간 3D 가상 복제물을 영구 가상 세계 시스템에 추가할 책임을 질 수 있다. 일부 실시예에서, 영구 가상 시스템의 관리자, 공무원 또는 다른 관련 기관은 실시간 3D 가상 복제물 을 영구 가상 세계 시스템에 입력하기 위해 실제 물체 소유자와 협력할 수 있고, 그로 인해 서버 내에 영구 가 상 세계 시스템을 생성하는 것을 더 빠르고 철저하게 실현할 수 있다. 다른 실시예에서, 합성 개구 레이더, 실 -개구 레이더, LIDAR(Light Detection and Ranging ), 역 개구 레이다, 모노펄스 레이더, 및 다른 유형의 이미 징 기술과 같은 레이더 이미징이 실제 물체를 영구 가상 세계 시스템에 통합하기 전에 실제 물체를 맵핑하고 모 델링하는데 사용될 수 있다. 가상 복제물을 만드는 데 사용되는 모델링 기술과는 별도로, 각각의 가상 복제물 의 정보는 각각의 대응하는 현실 세계 요소에 대한 충분한 세부 정보를 제공해야하며, 그로 인해 각각의 현실 세계 물체의 매우 정확한 실시간 3D 가상 복제물이 사용 가능해진다. 가능할 때마다, 실시간 3D 가상 복제물은 다중 소스 센서 데이터를 통해 풍부해지고 동기화된다. 따라서, 일부 실시예에서, 실시간 3D 가상 복제물은 복 제 편집기를 통한 명시적 데이터 및 명령 입력 및 복수의 IoT 센싱 메커니즘을 통한 다중 소스 센서 데이터 입 력을 포함한다. 일 실시예에 따르면, 실제 물체 및 사용자 디바이스에 장착된 다수의 IoT 센싱 메카니즘은 하나 이상의 온도 센 서, 근접 센서, 관성 센서, 적외선 센서, 오염 센서(예컨대, 가스 센서), 압력 센서, 광 센서, 초음파 센서, 연 기 센서, 터치 센서, 색채 센서, 습도 센서, 수분 센서, 전기 센서 또는 이들의 조합을 포함할 수 있다. 현실 세계로부터 데이터를 끊임없이 캡처하는 센서 메커니즘을 갖는 복수의 접속된 요소를 제공함으로써, 서버에 저 장된 영구 가상 세계 시스템 및 각각의 실시간 3D 가상 복제물은 실시간 멀티 소스 센서 데이터를 통해 현실 세 계의 상황을 반영하는 갱신된 상태로 유지된다 일 실시예에 따르면, 실제 물체에 부착되거나 또는 실제 물체에 근접하게 구성된 센싱 메커니즘은 광학 센서 및 관성 센서 또는 이들의 조합을 포함하는 동작 캡처 센서를 포함할 수 있다. 광학 추적 센싱 메커니즘은 마커 추적 또는 마커리스 추적을 사용할 수 있다. 마커 추적에서, 실제 물체에는 마커가 적용된다. 마커는 능동 및 수동 적외선 광원일 수 있다. 능동 적외선 광은 적외선 광을 주기적으로 또는 지속적으로 방출할 수 있는 적외 선 광원을 통해 생성될 수 있다. 수동 적외선 광은 적외선 광을 소스로 되반사하는 적외선 역 반사기를 나타낼 수 있다. 하나 이상의 카메라가 지속적으로 마커를 찾도록 구성되고, 서버는 알고리즘을 사용하여 마커로부터 실제 물체 및 다양한 부분의 위치를 추출할 수 있다. 알고리즘은 하나 이상의 마커가 카메라 시야 바깥에 있거 나 일시적으로 가려지는 경우 누락된 데이터를 해결할 필요가 있을 수 있다. 마커리스 추적에서, 카메라는 계속해서 실제 개체의 이미지를 검색하여 서버 상에서 저장 및 계산되는 실시간 3D 가상 복제물의 이미지와 비교 한다. 관성 추적 센싱 메커니즘은 관성 측정 장치(IMU)에 통합 될 수 있는 가속도계 및 자이로스코프와 같은 장치를 사용할 수 있다. 가속도계는 선형 가속도를 측정하고, 이것은 속도를 구하기 위해 적분될 수 있으며, 그 후 다시 적분하여 초기 지점에 대한 위치를 구한다. 자이로스코프는 각속도를 측정하고, 이것 또한 초기 지 점에 대한 각 위치를 결정하기 위해 적분될 수 있다. 다수의 데이터 포인트의 추적 정확성을 높이기 위해, 광 학 및 관성 추적 센서 및 알고리즘의 조합을 사용하는 센서 융합 기술이 사용될 수 있다. 또 다른 실시예에서, 하나 이상의 송수신기가 통신 신호를 안테나로부터 수신하고 안테나로 송신하도록 구현될 수 있다. 바람직하게는, 송수신기는 mmW 송수신기이다. 5G 안테나가 사용되는 실시예에서, mmW 송수신기는 안 테나로부터 mmW 신호를 수신하고 데이터를 안테나로 다시 송신하도록 구성된다. 따라서, 센서 융합 기술의 다 른 실시예에서, 광학 센서, 관성 센서, mmW 송수신기에 의해 제공되는 위치 추적, 및 mmW 기반 안테나에 의해 제공되는 정확한 추적, 저 지연 및 높은 QOS 기능은 서브 센티미터 또는 서브 밀리미터의 위치 및 방향 추적을 가능하게 할 수 있고, 이는 실제 물체의 실시간 위치 및 방향을 추적 할 때 정확도를 높일 수 있다. 이러한 센 싱 융합 기술을 가능하게 하는데 필요한 센싱 메커니즘 및 소프트웨어는 본 명세서에서 추적 모듈로 지칭될 수 있다. 사용자 디바이스는 또한 하나 이상의 IMU 및 mmW 송수신기로부터의 관성 추적을 융합하는 추적 모듈을 포함할 수 있다. 다른 실시예에서, 센서 융합은 GNSS 추적 신호로부터 위치 데이터를 수신하고 정확한 위치 및 방향을 제공하기 위해 mmW 신호 및 관성 추적을 통해 이 데이터를 보강하는 것을 가능하게 한다. 일부 실시예 에서, 추적은 도달 시간(TOA), 도달 각(AOA), 또는 당업계에 공지된 다른 추적 기술(예를 들어, 시각적 이미징, 레이더 기술 등)과 같은 당업계에 공지된 여러 기술을 이용하여 수행될 수 있다. 일부 실시예에서, 네트워크를 통해 서버에 연결된 센싱 메커니즘을 통해 실제 물체를 실시간 3D 가상 복제물과 동기화시키는 것은 실시간 3D 가상 복제물을 보강하고 대응하는 실제 물체의 추가 물리적 특성을 제공하기 위해 실시간 3D 가상 복제물에 피드백을 제공한다. 다른 실시예에서, 이러한 동기화는 또한 실제 물체 대응부에 대 한 가상 보강 또는 가상 보상의 구현을 가능하게 한다. 일부 실시예에서, 가상 고방 또는 보상은 서버에서 이 용 가능하고 가상 머신의 구현을 통해 네트워크를 통해 실제 물체와 공유될 수 있는 저장 및 컴퓨팅 기능을 나 타내는 가상 리소스를 통해 가능해진다. 다른 실시예에서, 가상 보강 또는 보상은 가상 센서를 통해 가능해지 며, 가상 센서는 누락된 실제 데이터를 보상하는데 사용될 수 있는 가상으로 이용 가능한 데이터를 이용한다. 가상 센서는 가상 세계의 3D 구조 및 현실 세계를 나타내는 각각의 실시간 3D 가상 복제물의 사용을 추가로 활 용할 수 있어, 실제 물체는 현실 세계의 다른 물체를, 현실 세계에서 그러한 물체 인식을 할 필요없이, 그것들 의 실시간 3D 가상 대응부를 통해 인식할 수 있게 된다. 예를 들어, 한 곳에서 다른 곳으로 자재를 이송하도록 구성된 공장 로봇 시나리오에서, 물리적인 시각 센서(예 컨데, 카메라 또는 광 센서)가 고장나거나 로봇에서 누락된 경우, 로봇은 벽, 테이블, 또는 다른 실제 물체와 같은, 영구 가상 세계 시스템 내에 이미 배치된 장애물을 탐지하고 그에 따라 회피하기 위해 각 항목의 3D 좌표 및 3D 구조를 포함하는 공장의 가상 지도를 사용함으로써 가상 시각 센서를 이용할 수 있다. 또 다른 예로, 피 자 배달 드론은 도시의 가상 모델을 사용하여 원하는 목적지를 찾을 수 있으며, 영구 가상 세계 시스템에 존재 하지 않을 수도 있는 장애물을 탐지하고 회피하기 위해서만 실제 시각 센서를 사용할 수 있다. 의학적 애플리 케이션의 예에서, 의사는 가상 현실 또는 증강 현실에서 원격으로 수술실의 실제 대응부를 갖는 수술 장치의 실 시간 3D 가상 복제물을 조작할 수 있다. 다른 스탭(예를 들어, 의사, 간호사 등)은 수술을 수행하는 의사의 가 상 아바타를 볼 수 있으며, 필요할 때 그를 도울 수 있다. 정확도를 높이기 위해, 카메라는 실제 환자 및 수술 실을 캡처하여 원격 의사에게 표시되는 가상 세계 버전에 통합됨으로써 그는 수술실의 상황을 실시간으로 볼 수 있다. 다른 예에서, 실제 물체는 특정 태스크에 대한 계산 또는 저장 용량의 부족을 겪을 수 있고, 그것의 요 청을 서버에 전송할 수 있고, 서버는 요청된 계산 및 저장을 실제 물체에 전송할 수 있다. 다른 예에서 실제 개체는 감시 카메라, 신호등, 건물, 거리, 기차 트랙, 가전 제품 또는 네트워크에 연결될 수 있는 임의의 다른 장치를 포함하는, 상술된 것과 다른 IoT 장치를 나타낸다. 일 실시예에서, 적어도 하나의 실시간 3D 가상 복제물의 사용자는 인간 사용자, 인공 지능 사용자, 또는 이들의 조합이다. 다른 실시예에서, 물체 조작자는 인간 물체 조작자, 인공 지능 물체 조작자 또는 이들의 조합이다. 이들 실시예에서, 실시간 3D 가상 복제물은 사용자 또는 물체 조작자의 가상 봇 및 가상 아바타를 더 포함할 수 있다. 인간 아바타는 인간 사용자의 물리적 특성을 표시하도록구성 될 수 있거나 상이한 시각적 양태 및 특성 을 갖도록 구성될 수 있다. 일부 실시예에서, 서버는 일제히 그리고 자율적으로 관리하거나 복수의 실시간 3D 가상 복제물의 관리를 지원하 기 위해 인공 지능 알고리즘 및 그룹 분석을 사용하도록 구성될 수 있고, 이는 하나 이상의 실제 물체의 대응하 는 관리를 유도한다. 관리는 서버상에서 저장 및 계산되는 가상 봇에 의해 수행될 수 있는데, 이 가상 봇은 현 실 세계에서의 물리적 봇에 연결될 수도 있고 연결되지 않을 수도 있다. 다른 실시예에서, 로봇은 하나 이상의 실제 물체를 관리하도록 구성 될 수 있으며, 이에 따라 관리 또는 조작 명령은 서버상에서 저장 및 계산되는 가 상 세계 시스템을 통해 실제 물체의 대응하는 실시간 3D 가상 복제물에 실시간으로 전송된다. 이들 실시예에서, 서버는 복수의 실시간 3D 가상 복제물이 하나 이상의 목표에 기초하여 서로 협력하고 상호 작용할 수 있게 하기 위해 인공 지능 알고리즘을 이용하도록 더 구성될 수 있다. 따라서, 실제 물체가 현실 세계에서 제한된 통신을 가질지라도, 복수의 실시간 3D 가상 복제물은 가상 세계에서 긴밀하게 협력하고 상호 작용할 수 있어, 현실 세계에서 대응하는 상호 작용 및 협력을 유도할 수 있다. 일 실시예에 따르면, 실시간 3D 가상 복제물 통해 실제 물체와의 자연스러운 인터페이스 및 향상된 경험을 가능 하게 하기 위해, 실시간 3D 가상 복제물의 물리 속성 및 현실 세계 좌표는 실제 물체의 것에 대응하도록 구성된 다. 물리 속성은 제한하는 것은 아니지만 치수, 질감, 질량, 부피, 굴절률, 경도, 색상, 압력 및 온도를 포함 할 수 있다. 각각의 실시간 3D 가상 복제물의 데이터는 정확한 데이터 구조로 배열될 수 있다. 현실 세계 좌 표는 실제 물체의 현재 위치(예컨대, 3 차원 좌표) 및 방향 데이터(예컨대, 3 차원의 각도)를 포함할 수 있다. 실제 물체를 기반으로 실시간 3D 가상 복제물의 물리 속성과 현실 세계 좌표를 구성하면, 사용자에게 표시되는 물체의 현실감을 높이는 것뿐만 아니라 실제 물체의 각각의 부분이 실시간 3D 가상 복제물에 정밀하게 표현될 수 있으므로 6 자유도로의 그 물체의 정밀한 제어를 용이하게 할 수 있다. 공간 데이터의 표현은 컴퓨터 그래픽의 렌더링 및 디스플레이, 시각화, 솔리드 모델링 및 관련 영역을 포함하여, 영구 가상 세계 시스템의 프로그래밍에 있어서 중요한 이슈이다. 영구 가상 세계 시스템 및 각각의 실시간 3D 가상 복제물을 나타내는데 사용되는 데이터 구조는 제한하는 것은 아니지만, 하나 이상의 옥트리(octree), 쿼드 트리(quadtree), BSP 트리, 스파스 복셀 옥트리, 3D 어레이, kD 트리, 포인트 클라우드, 와이어-프레임, 경계-표현(B-Rep), CSG 트리(constructive solid geometry tree), 빈 트리(bintree) 및 육각형 구조를 포함한다. 일 실시예에 따르면, 실시간 3D 가상 복제물을 통해 실제 물체 상에 하나 이상의 변경을 유효화하는 것 또는 실 제 물체를 통해 실시간 3D 가상 복제물 상에 하나 이상의 변경을 유효화하는 것은 가상 및 실제 쌍 간에 공유되 는 복수의 데이터 포인트 상에 변경사항을 적용하는 것을 포함한다. 일부 실시예에서, 복수의 데이터 포인트에 적용된 변경사항은 하나 이상의 회전 운동, 병진 운동, 하나 이상의 행동의 선택, 하나 이상의 행동의 프로그래 밍, 하나 이상의 파라미터의 설정, 또는 이들의 조합 중 하나 이상을 포함한다. 변경사항은 실시간 3D 가상 복 제물에 실시간, 지상 진실 경험 효과(ground truth experience effect)를 발생시키기 위해 실제 물체에 직접 적 용될 수 있다. 이와 유사하게, 변경사항은 실제 물체에 실시간, 지상 진실 경험 효과를 발생시키기 위해 실시 간 3D 가상 복제물에 직접 적용될 수 있다. 일부 실시예에서, 실시간 3D 가상 복제물를 통해 적어도 하나의 실제 물체를 조작하는 것은 3D 사용자 인터페이 스를 통해 활성화된 실시간 3D 가상 복제물의 이전 가상 선택을 필요로 하며, 선택된 실시간 3D 가상 복제물 및 대응하는 실제 물체로 선택 명령을 전송하는 것을 필요로 한다. 일부 실시예에서, 실시간 3D 가상 복제물을 통 해 실제 물체에 변화를 유효화하기 위한 가상 선택 및 조작 명령은 사용자 디바이스에 의해 제공된 자연스러운 사용자 인터페이스(NUI)를 통해 제공될 수 있다. 예를 들어, 사용자는 음성 인식, 터치 인식, 안면 인식, 스타일러스 인식, 에어 제스처(예컨대, 손 포즈 및 동 작 및 기타 신체/부속 운동/포즈), 머리 및 안구 추적, 보이스 및 음성 발화(utterance), 및 예컨대, 시각, 보 이스, 포즈 및/또는 터치 데이터와 관련된 관련 기계 학습과 같은, 마우스, 키보드, 리모콘 등 등과 같은 입력 장치에 의해 부과된 인위적인 제약으로부터 자유로운 NUI를 통해 실시간 3D 가상 복제물과 상호 작용할 수 있다. 다른 실시예에서, 실시간 3D 가상 복제물을 통해 실제 물체에 대한 변경을 유효화하기 위한 조작 명령은 마우스, 키보드, 리모콘 등과 같은 인위적인 제한을 부과하는 일반적인 사용자 인터페이스를 통해 제공될 수도 있다. 어떤 경우든, 실시간 3D 가상 복제물와의 사용자 실시간 3D 기반 상호 작용은 여러가지 중에서도 특히 이동 전화, 랩탑, 모바일 게임 콘솔, 헤드 장착 디스플레이, 크로스 콕핏 시준 디스플레이, 헤드 업 디스플레이 및 스마트 콘택트 렌즈와 같은 하나 이상의 사용자 디바이스를 통해 제공될 수 있다. 또한, 사용자 인터페이스 를 통한 실시간 3D 기반 상호 작용은 증강 현실, 가상 현실, 복합 현실 또는 이들의 조합 중 하나 이상에서 제 공될 수 있다. 일부 실시예에서, 사용자 디바이스 및 실제 물체는 동일한 디바이스를 지칭 할 수 있다. 예를 들어, 육상 차량 은 실제 또는 인공 지능 사용자가 제어할 수 있는 실제 물체를 나타낼 수 있다. 그러나, 차량은 사용자가 차량 과 상호 작용하고, 자가 운전 인공 지능 시스템에 커맨드를 전송하고, 또는 심지어 그러한 인터페이스를 통해 차량 자체를 제어하는 것을 허용할 수 있고 그러므로 자동차가 사용자 디바이스로 작동할 수 있게 하는(예컨대, 윈드쉴드 또는 창문 상의) 증강 현실 사용자 인터페이스를 포함할 수 있다 예시적인 실시예에서, 실제 물체는(예를 들어, 인쇄 회로 기판용) 페인팅, 용접, 어셈블링, 패키징, 라벨링, 픽 앤드 플레이스 등에 사용되는 하나 이상의 산업용 로봇과 같은 공장 기계를 지칭할 수 있다. 다른 예시적인 실 시예에서, 실제 물체는 항공기(예를 들어, 비행기, 드론, 헬리콥터 등), 육상 차량(예를 들어, 자동차, 모터 바 이크, 트럭 등) 및 해양 운송 수단(예컨대, 보트, 화물선, 잠수함 등)을 포함하는 운송 수단을 지칭할 수 있다. 산업 기계의 양방향 실시간 3D 기반의 상호작용 및 관리는 제조 플랜트의 임의의 부분에서 일어나는 변화를 모 니터링할 수 있는 동시에 실시간으로 복수의 산업 기계를 원격으로 관리하는 데 유용할 수 있다. 예를 들어, 구급차가 과중한 교통량을 거쳐야 할 필요가 있을 사고 또는 자연 재해 시와 같이, 어떤 방식으로 이동하기 위 한 차량을 필요로 하는 경우에, 달리는 차량의 더 우수한 제어를 가지기 위한, 예컨대, 정부 기관에게 차량의 양방향 실시간 3D 기반 상호작용 및 관리가 유용할 수 있다. 실시간 3D 가상 복제물 및 실제 물체의 양방향 대화형 조작을 가능하게 하는 방법은 적어도 하나의 실제 물체의 적어도 하나의 실시간 3D 가상 복제물이 표현되어 있는 구조를 포함하는 영구 가상 세계 시스템을 제공하는 단 계; 실시간 3D 가상 복제물 모델을 보강 및 업데이트하기 위해 실시간 3D 가상 복제물으로 다시 피드백을 보내 는(IoT) 센싱 메커니즘을 통해 적어도 하나의 실시간 3D 가상 복제물을 대응하는 적어도 하나의 실제 물체와 동 기화시키는 단계; 동기화를 기초로 하여 실시간 3D 가상 복제물에 정확성을 높이고 어떤 물리 속성을 제공하는 단계; 실제 물체 또는 사용자 디바이스를 통해 입력되는 선택 및/또는 조작 명령을 수신하는 단계; 선택 및/또 는 조작 명령들을 처리 및 실행하는 단계; 및 적어도 하나의 수정된 실시간 3D 가상 복제물로 영구 가상 세계 시스템을 업데이트하고, 업데이트된 모델을 대응하는 사용자 디바이스로 전송하는 단계를 포함한다. 일부 실시 예에서, 프로로셍 중 일부는 실제 물체에 의해 국부적으로 수행되는 프로세싱을 지원하는데 사용될 수 있다. 상기 설명은 본 개시물의 모든 양태의 포괄적인 목록을 포함하지 않는다. 본 개시물은 앞서 설명된 다양한 양 태의 모든 적합한 조합 뿐만 아니라 아래의 상세한 설명에 개시되고 특히 출원과 함께 청구된 청구 범위에서 지 적될 수 있는 모든 시스템 및 방법을 포함하는 것으로 고려된다. 이러한 조합은 상기 설명에 구체적으로 언급 되지 않은 특별한 이점을 갖는다. 다른 특징 및 이점은 첨부된 도면 및 이하의 상세한 설명으로부터 명백해질 것이다."}
{"patent_id": "10-2019-0060413", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "다음의 설명에서, 예시로서 다양한 실시예들을 보여주는 도면들이 참조된다. 또한, 다양한 실시예들이 몇몇 예 를 참조하여 아래에서 설명될 것이다. 실시예들은 청구된 주제의 범위를 벗어나지 않으면서 설계 및 구조의 변 경을 포함할 수 있음을 이해해야 한다. 도 1a-1b는 본 발명의 일 실시예에 따른, 실시간 3D 가상 복제물 및 실제 물체의 양방향 조작을 가능하게 하는 시스템(100a-b)의 개략도이다. 도 1a에서, 실제 물체는 서버 상에 저장되고 계산되며 사용자 디바이 스로부터 사용자 인터페이스를 통해 디스플레이되는 실시간 3D 가상 복제물에 통신 가능하고 지 속적으로 연결되고 완전히 동기화된다. 실제 물체, 서버 및 사용자 디바이스는 네트워크 를 통해 통신 가능하게 접속된다. 도 1a의 시스템(100a)의 예시적인 실시예에서, 사용자는 실시간 3D 가상 복제물을 통해 실제 물체 의 실시간 및 저지연의 원격 가상 선택 및 조종을 가능하게 하기 위해 사용자 디바이스을 이용할 수 있다. 사용자는 인간 사용자(예를 들어, 원격 제조 공장 운영자 또는 관리자, 원격 차량 운전자, 주택 소 유자, 도시 관리자 등) 또는 인공 지능(AI) 사용자(예를 들어, 실제 물체에 대한 변경을 유효화하기 위해 실시간 3D 가상 복제물를 자율적으로 조작하기 위해 인공 지능 알고리즘을 통해 적응되고 훈련된 소프트웨 어 및/또는 하드웨어)를 포함할 수 있다. 실시간 3D 가상 복제물상의 하나 이상의 변경을 선택하고 유효 화하면, 사용자 디바이스는 선택 및 조작 명령을 서버에 전송하며, 서버는 실시간으로 선택 및 조작 명령을 처리하고 실제 물체의 각각의 액츄에이터로 명령을 전송하여 작용기에 대한 원하는 효과를 생 성한다. 작용기는 로봇의 다리, 바퀴, 팔 또는 손가락과 같은 실제 물체의 환경에 영향을 미치는 임의의 장치를 지칭한다. 액츄에이터는 작용기가 작동을 수행할 수 있게 해주는 메커니즘이며, 전기 모터, 유압 실린 더, 공압 실린더 또는 이들의 조합을 포함할 수 있다. 예를 들어, 실제 물체가 다수의 관절로 인해 많은 자유도를 가질 때, 하나의 액추에이터는 관절당 원하는 자유도를 제공할 수 있는 필요한 회전 및 병진 운동을 가능하게 하기 위해 실제 물체의 각 관절에 배치될 필요가 있을 수 있다. 또한, 처리된 명령은 사용자 디 바이스 상에 업데이트 된 실시간 3D 가상 복제물을 적절하게 표현하는데 필요한 미디어 컨텐츠에 대 한 경량 오퍼레이션만 수행할 필요가 있는 사용자 디바이스로 전송된다. 도 1a의 시스템(100a)의 다른 예시적인 실시예에서, 물체 조작자(예를 들어, 산업 기계 운전자)는 서버 상에서 저장 및 계산되는 실시간 3D 가상 복제물의 실시간 및 저지연 원격 업데이트를 가능하게 하기 위 해 실제 물체를 직접 조작할 수 있다. 물체 조작자는 인간 물체 조작자 또는 AI 물체 조작자일 수 있다. 실제 물체의 직접 조작을 가능하게 하는 사용자 인터페이스는 실제 물체의 특성에 의존할 수 있으며, 하나 이상의 스크린, 버튼, 페달 또는 다른 제어 메커니즘을 포함할 수 있다. 실제 물체에 대한 하나 이상의 변경을 유효화한 후, 실제 물체는 실시간으로 서버와 명령을 공유한다. 실제 물체(10 2)는 동시에 명령들을 처리하고 실행한다. 그 다음, 서버는 실시간으로, 실제 물체에 의해 수행되는 액션과 동일한 방식으로 실시간 3D 가상 복제물을 업데이트하는데 필요한 조작 명령을 처리할 수 있다. 일부 실시예에서, 서버에 의해 수행되는 프로세싱은 실제 물체에 의해 수행되는 프로세싱의 보완이며, 이 는 특정한 무거운 태스크 프로세싱을 수행하기 위해 실제 물체에 대한 지원 역할을 한다. 따라서, 서버 는 실시간 3D 가상 복제물을 갱신하고 갱신된 실시간 3D 가상 복제물을 사용자 디바이스에 전송할 수 있다. 일부 실시예에서, 대부분의 중-부하 프로세싱은 서버에서 수행되므로, 사용자 디바이스 는 업데이트된 실시간 3D 가상 복제물을 사용자 디바이스 상에 표현하는데 필요한 경량 오퍼레 이션을 수행하면 된다. 일 실시예에 따르면, 실시간 3D 가상 복제물이 서버 상에 생성, 저장 및 계산 된 후에, 실시간 3D 가 상 복제물은 실제 물체에 부착되거나, 실제 물체 부근에 위치하거나 또는 이들의 조합인 센싱 메커니즘들의 조합을 통해 실제 물체와 동기화될 수 있다. 일부 센싱 메커니즘은 실제 물체의 작용 기, 조인트, 커넥터 및 액츄에이터에 부착될 수 있다. 센싱 메커니즘의 조합은 네트워크를 통해 실시간 물체와 실시간 3D 가상 복제물간에 공유 될 수 있는 복수의 데이터 포인트를 제공할 수 있다. 공유 된 데이터 포인트는 실제 물체의 정확한 추적과 함께 실제 물체와 실시간 3D 가상 복제물 사이 의 정확한 동기화를 가능하게 할 수 있다. 일 실시예에 따르면, 실시간 3D 가상 복제물을 통해 자연스러운 사용자 인터페이스 및 실제 물체 와의 향상된 경험을 가능하게 하기 위해, 실시간 3D 가상 현실 복제물의 실세계 위치 및 방위 데이터 및 물리적 특성들은 공유 데이터 포인트를 통해 실제 물체의 것과 대응하도록 구성된다.실제 물체에 기초하여 실시간 3D 가상 복제물의 물리 속성 및 실제 위치 및 방향 데이터를 구성하는 것은 사용자에게 표시되는 물체의 현실감을 증가시키는 것 뿐만 아니라, 실시간 3D 가상 복제물을 통해 실 시간 3D 가상 복제물을 통해 실제 물체의 실물과 똑같은 조작으로서 반영될 수 있는 6 자유도로 물체의 정밀 제 어를 가능하게 하는 역할을 할 수 있다. 일 실시예에 따르면, 실시간 3D 가상 복제물을 통해 실제 물체에 대한 또는 실시간 3D 가상 복제물을 통해 실제 물체에 대한 하나 이상의 변경을 유효화하는 것은 실시간 3D 가상 복제물과 실제 물체 사이에서 공유된 복수의 데이터 포인트 상에 변경사항을 적용하는 것을 포함한다. 일부 실시예에서, 복 수의 데이터 포인트에 적용된 변경사항은 하나 이상의 회전 동작, 병진 운동, 하나 이상의 행동의 선택, 하나 이상의 행동의 프로그래밍, 하나 이상의 파라미터의 설정, 또는 이들의 조합을 더 포함한다. 수정은 실시간 3D 가상 복제물에 실시간, 지상 검증 경험(ground truth experience) 효과를 야기하기 위해 실제 물체 에 직접 적용될 수 있다. 이와 유사하게, 수정은 실시간 3D 가상 복제물 상에 직접 적용되어 실제 물체 에 실시간, 지상 검증 경험 효과를 야기할 수 있다. 일부 실시예들에서, 적어도 하나의 실시간 3D 가상 복제물 또는 대응하는 적어도 하나의 실제 물체를 조작하는 것은 가상-실제 쌍에 영향을 주는 컨텍스 트 데이터에 대한 변경을 발생시키며, 컨텍스트 데이터에서의 이러한 변경은 실시간 3D 가상 복제물과 대 응하는 적어도 하나의 실제 물체 간의 관계에 영향을 줄 수 있다. 예를 들어, 실제 물체 또는 그것 의 가상 대응부를 통해 공기 조절기의 온도를 조절하는 것은 공기 조절기 주변 온도에 뿐만 아니라 그 환경 내 의 실제 물체에 직접적인 영향을 미친다. 다른 예를 들어, 한 지역에서 다른 지역으로 무거운 짐을 운송 하도록 공장의 리프트 트럭에 지시하면, 그 길 위의 다른 물체를 리프트 트럭의 길을 비워주도록 트리거할 수 있다. 또 다른 예로, 가로등이 녹색으로 바뀌면, 가로등의 관점에서 컨텍스트의 일부인 다른 차량이 조명 변경 의 결과로 자동으로 움직이기 시작할 수 있다. 일부 실시예에서, 실시간 3D 가상 복제물을 통해 적어도 하나의 실제 물체를 조작하는 것은 3D 사용 자 인터페이스를 통해 활성화된 실시간 3D 가상 복제물의 이전의 가상 선택을 요구하고, 실시간 3D 가상 복제물 및 대응하는 실제 물체에 선택 명령을 전송한다. 일부 실시예에서, 실시간 3D 가상 복제물 을 통해 실제 물체에 대한 변경을 유효화하기 위한 가상 선택 및 조작 명령은 사용자 디바이스 에 구현된 자연스러운 사용자 인터페이스(NUI)를 통해 제공될 수 있다. 예를 들어, 사용자는 음성 인식, 터치 인식, 얼굴 인식, 스타일러스 인식, 에어 제스처(예컨대, 손 포즈 및 동작 및 기타 신체/부속 동작/자세), 머리 및 눈 추적, 보이스 및 음성 발화(utterance), 및, 예컨대, 시각, 음성, 보이스, 포즈 및/또는 터치 데이 터에 관한 기계 학습과 같은, 마우스, 키보드 및 리모콘 등과 같은 입력 장치에 의해 부과되는 인공적인 제약으 로부터 자유로운 NUI를 통해 실시간 3D 가상 복제물과 상호작용할 수 있다. 다른 실시예에서, 실시간 3D 가상 복제물을 통해 실제 물체에 대한 변경을 유효화하기 위한 조작 명령은 또한 마우스, 키보드 및 리모콘 등과 같은 인공적인 제약을 부과하는 일반적인 사용자 인터페이스를 통해 제공될 수도 있다. 어떤 경우 든, 실시간 3D 가상 복제물과의 사용자 실시간 3D 기반 상호 작용은 여러 가지 중에서도 이동 전화, 랩탑, 모바일 게임 콘솔, 헤드 장착형 디스플레이, 크로스 조종석 시준 디스플레이, 헤드업 디스플레이 및 스마트 컨 택트 렌즈를 포함하는 하나 이상의 사용자 디바이스를 통해 제공될 수 있다. 또한, 사용자 인터페이스 를 통한 실시간 3D 기반 상호 작용은 증강 현실, 가상 현실, 혼합 현실 또는 이들의 조합 중 하나 이상에 서 제공될 수 있다. 일 실시예에 따르면, 실시간 3D 가상 복제물은 서버 상에서 저장 및 계산되는 보다 넓은 영구 가상 세계 시스템의 일부이고, 영구 가상 월드 시스템은 복수의 다른 실시간 3D 가상 복제물이 표현 되어 있는 데이터 구조를 포함한다. 따라서, 실시간 물체와 실시간 3D 가상 복제물 사이, 또는 실시 간 3D 가상 복제물과 실제 물체 사이의 임의의 양방향 커맨드들이 영구 가상 세계 시스템을 거 친다. 영구 가상 세계 시스템 및 각각의 실시간 3D 가상 복제물을 나타내는 데 사용되는 데이터 구조는 제 한없이, 하나 이상의 옥트리(octree), 쿼드트리(quadtrees), BSP 트리, 스파스 보셀 옥트리, 3D 어레이, kD 트 리, 포인트 클라우드, 와이어-프레임, 비렙(B-Rep: boundary representations), CSG 트리(constructive solid geometry tree), 비트리(bintree) 및 육각형 구조를 포함한다. 데이터 구조는 영구 가상 세계 시스템에서 가상 물체의 각 기하학적 형상의 데이터를 정확하고 효율적으로 표현하는 기능을 수행한다. 데이터 구조의 올바른 선택은 데이터의 출처, 렌더링 중 찾는 기하학적 형상의 정밀도; 렌더링이 실시간으로 수행되는지 또는 사전 렌 더링되는지 여부; 렌더링이 클라우드 서버를 통해, 사용자 디바이스를 통해, 또는 이들의 조합을 통해 수행되는 지 여부; 영구 가상 세계 시스템이 사용되는 특정 애플리케이션(예를 들어, 의료 또는 과학 애플리케이션에서다른 유형의 애플리케이션보다 높은 정의 수준이 필요할 수 있다); 서버 및 사용자 디바이스들로부터의 메모리 용량 및 그에 따른 희망 메모리 소모량 등에 의존한다. 일부 실시예에서, 네트워크는, 예를 들어, 셀룰러 네트워크 일 수 있으며, EDGE(enhanced data rates for global evolution), GPRS(general packet radio service), GSM(global communication system for mobile communications), IMS(Internet protocol multimedia subsystem), UMTS(universal mobile telecommunications system) 등 뿐만 아니라 임의의 다른 적합한 무선 매체, 예컨대, WiMAX(microwave access), LTE(Long Term Evolution) 네트워크, CDMA(code division multiple access), WCDMA(wideband code division multiple access), WiFi(wireless fidelity), 위성, MANET(mobile ad-hoc network) 등을 포함하는 다양한 기술을 이용할 수 있다. 일 실시예에 따르면, 네트워크는 실제 물체와 서버 간의 이동 통신을 가능하게 하는 전파를 송신 및 수신하도록 구성된 안테나를 포함할 수 있다. 안테나는 유선 또는 무선 수단을 통해 컴퓨팅 센터에 연결될 수 있다. 다른 실시예에서, 안테나는 컴퓨팅 센터 및/또는 컴퓨팅 센터 근처의 영역 내에 제공된다. 일부 실시예 에서, 옥외에 배치 된 사용자 디바이스 및/또는 실제 물체를 서비스하기 위해, 안테나는 밀리미터 파 (mmW) 기반 안테나 시스템 또는 mmW 기반 안테나 및 서브-6GHz 안테나 시스템의 조합을 포함하며, 이들은 통칭 하여 5G 안테나라고도 불린다. 다른 실시예에서, 안테나는 4G 안테나와 같은 다른 유형의 안테나를 포함할 수 있거나 5G 안테나 시스템을위한 지원 안테나로서 사용될 수 있다. 옥내에 위치된 사용자 디바이스를 서비 스하기 위해 안테나가 사용되는 실시예에서, 바람직하게는 안테나는 제한하는 것은 아니지만 16 GHz로 데이터를 제공하는 Wi-Fi를 사용할 수 있다. 다른 실시예에서, GPS, BDS, 글로나스(Glonass), QZSS, 갈릴레오(Galileo) 및 IRNSS와 같은 GNSS(global navigation satellite systems)이 사용자 디바이스의 위치 결정에 사용될 수 있다. 충분한 수의 위성으 로부터의 신호 및 삼각법 및 삼각 측량과 같은 기술을 사용하여, GNSS는 사용자 디바이스의 위치, 속도, 고도 및 시간을 계산할 수 있다. 바람직한 실시예에서, 외부 위치 확인 시스템은 위치 확인 시스템에서 사용하 기 위한 기존의 셀룰러 통신 네트워크의 아키텍처를 통해 AGNSS(assisted GNSS)에 의해 증강되고, 여기서 기존 의 아키텍처는 5G를 포함한다. 다른 실시예에서, AGNSS 추적 시스템은 4G 셀룰러 통신 네트워크 위치 확인 시 스템에 의해 추가적으로 지원된다. 실내 실시예에서, GNSS는 바람직하게는 제한하는 것은 아니지만 16 GHz로 데이터를 제공하는 Wi-Fi와 같은 무선 무선 로컬 영역 네트워크를 통해 추가로 보강된다. 대안적인 실시예에서, GNSS는 DGPS(differential GPS), SBAS(satellite-based augmentation systems), RTK(real-time kinematic) 시스템 등을 통해 당업계에 공지된 다른 기술을 통해 증대된다. 일부 실시예에서, 사용자 디바이스 의 추적은 사용자 디바이스 내의 AGNSS 및 관성 센서의 조합에 의해 구현된다. 도 1b는 인간 조작자(116a), 인공 지능(AI) 조작자(116b) 또는 이들의 조합을 포함하는 복수의 물체 조작자 가 하나 이상의 육상 물체(102a)(예를 들어, 차량), 또는 비행 물체(102b)(예를 들어, 드론 또는 비행기) 와 같은 적어도 하나의 실제 물체를 조작하는 시스템(100b)의 예시적인 실시예를 도시한다. 적어도 하나 의 실제 물체를 동작시키는 물체 조작자는 실제 물체상의 적절한 인터페이스를 이용하여 상기 실제 물체에 조작 명령을 전송한다. 조작 명령은 연속적으로 및 실시간으로 업데이트되는 각각의 하나 이상의 실시간 3D 가상 복제물을 지속적으로 그리고 실시간으로 업데이트하는 그리고 적용 가능하다면(예를 들어, 다른 실시간 3D 가상 복제물에 영향 을 주는 변화 또는 이벤트를 트리거하는) 각각의 하나 이상의 실시간 3D 가상 복제물 주위 컨텍스트 데이 터의 변화를 생성할 수 있는, 영구 가상 월드 시스템을 통해 네트워크를 통해 상기 각각의 하나 이상 의 실시간 3D 가상 복제물로 전송된다. 인간 사용자(114a), AI 사용자(114b), 또는 이들의 조합을 포함하 는 사용자는 네트워크를 통해 영구 가상 세계 시스템에 연결된 사용자 디바이스를 통해 각각의 하나 이상의 실시간 3D 가상 복제물의 지속적이고 실시간인 업데이트를 관찰 할 수 있다. 마찬가지로, 사용자는 사용자 디바이스를 통해 하나 이상의 실시간 3D 가상 복제물을 조작할 수 있다. 조작 명령은 영구 가상 월드 시스템을 통해 네트워크를 통해 대응하는 하나 이상의 실제 물체 에 실시간으로 개별적으로 전송될 수 있다. 물체 조작자는 실제 물체의 동작의 연속적인 실시 간 업데이트를 관찰할 수 있다. 도 1b에 도시된 바와 같이, 복수의 사용자는 제한없이 VR/AR 헤드 장착 디스플레이(110a), 이동 전화기(110b), 랩탑(110c), 스마트 콘택트 렌즈(110d) 및 스마트 차량(110e)을 포함하 는 몇몇 사용자 디바이스를 통해 실시간 3D 가상 복제물의 변화를 동시에 볼 수 있다. 예를 들어, 인간 조작자(116a)는 영구 가상 월드 시스템을 통해 네트워크를 통해 차량의 각각의 실시 간 3D 가상 복제물에 커맨드를 전송하는, 차량(예를 들면, 육상 물체(102a))을 조종할 수 있다. 영구 가 상 세계 시스템의 하나 이상의 사용자는 각각의 하나 이상의 실시간 3D 가상 복제물를 통해 일 어나는 변화를 볼 수 있다. 일부 실시예에서, 적어도 하나의 실시간 3D 가상 복제물은 가상 봇 및 사용자 의 아바타를 더 포함할 수 있다. 가상 봇들은 복수의 실시간 3D 가상 복제물을 동시에 자율적으로 관리하 기 위해 요구되는 인공 지능 알고리즘 및 그룹 분석을 사용함으로써 인간 또는 인간과 유사한 행동으로 자동화 된 에이전트로서 응답하기 위한 AI 사용자(114b)로서 구성 될 수 있으며, 여기서 하나 이상의 실시간 3D 가상 복제물은 대응하는 실제 물체의 대응 관리를 이끌어낸다. 가상 봇은 현실 세계의 물리적 로봇과 연 결될 수도 있고, 연결되지 않을 수도 있다. 인간 아바타는 인간 사용자의 물리적 특성을 표시하도록 구성될 수 있고 또는 상이한 시각적 양태 및 특성을 갖도록 구성될 수도 있다. 다른 실시예에서, 로봇 또는 기계와 같은 인공 지능 장치 또는 인공 지능 프로그램은 AI 물체 조작자(116b)로서 구성되어 하나 이상의 실제 물체를 관리할 수 있으며, 이에 의해 관리 또는 조작 명령은 영구 가상 세계 시스템을 통해 실제 물체의 대 응하는 실시간 3D 가상 복제물으로 실시간으로 전송된다. 따라서, 인공 지능 장치 또는 프로그램은 하나 이상의 실제 물체의 AI 물체 조작자(116b)로서 역할할 수 있다. 일부 실시예에서, 스마트 차량(110e)의 예와 함께 도시된 바와 같이, 사용자 디바이스 및 실제 물체 는 경우에 따라 동일한 장치를 지칭 할 수 있다. 예를 들어, 스마트 차량(110e)은 실제 또는 인공 지능 사용자 에 의해 제어 될 수 있는 실제 물체를 지칭할 수도 있다. 그러나, 스마트 차량(110e)은 사용자가 차량과 상호 작용하거나, 자가-운전 인공 지능 시스템에 커맨드를 보내거나, 심지어 인터페이스를 통해 차량 자체를 제 어하는 것을 가능하게 하는 증강 현실 사용자 인터페이스를(예를 들어, 윈드 실드 또는 창문 상에) 포함할 수 있으며, 따라서 스마트 차량(110e)을 사용자 디바이스로서 역할하게 만든다. 일부 실시예에서, 복수의 실시간 3D 가상 복제물은 하나 이상의 목표에 기초하여 서로 협력하고 상호작용 하기 위해 인공 지능 알고리즘을 사용할 수 있다. 따라서, 실제 물체가 실세계에서 서로 제한된 통신을 가질지라도, 복수의 실시간 3D 가상 복제물은 영구 가상 세계 시스템에서 긴밀히 협력 및 상호 작용 할 수 있고, 이는 현실 세계에서의 대응하는 상호 작용 및 협력을 초래할 수 있다. 도 2a 및 도 2b는 현실 세계와 가상 세계 시스템 사이의 관계의 표현을 상세히 보여주는, 본 개시물의 일 실시 예에 따른 시스템(200a-b)의 개략도를 나타낸다. 도 2a-2b의 일부 요소는 도 1a-1b의 요소와 유사 할 수 있으 며, 따라서 동일하거나 유사한 참조 번호가 이용 될 수 있다. 도 2a의 시스템(200a)을 참조하면, 하나 이상의 서버는 적어도 프로세서 및 메모리를 포함하는 하드웨어 및 소프트웨어로서 제공될 수 있다. 프로세서는 메모리에 포함된 명령들을 실행하도록 구 성 될 수 있고, 메모리는 명령 및 데이터를 저장하도록 더 구성된다. 프로세서는 실제 물체 또는 사용자 디바이스 중 하나로부터 오는 조작 명령의 실시간 처리를 포 함하여, 메모리에 포함 된 명령 및 데이터를 액세스하고 실행하도록 구성될 수 있다. 예를 들어, 프로세 서는 대응하는 실시간 3D 가상 복제물, 실제 물체의 시뮬레이션, 3D 구조 처리, 그룹 분석, 렌 더링 및 실시간 3D 가상 복제물을 통한 실제 물체의 가상 보강 또는 가상 보상의 구현을 통해, 적어 도 하나의 실제 물체의 관리를 위한 인공 지능 알고리즘을 구현하도록 구성될 수 있다. 프로세서는 또한 조작 명령들에 대한 운동학적(kinematic) 계산을 수행함으로써 실제 물체와 실시간 3D 가상 복제물 의 쌍방향 대화형 동작을 가능하게 할 수 있다. 일 실시예에서, 프로세서에 의한 조작 명령의 처리 는 어떤 과중한 작업 처리 동작을 수행하기 위한 실제 물체에 대한 지원으로서 역할하는 실제 물체에 의해 수행되는 처리에 대한 보완이다. 다른 실시예에서, 프로세서는 사용자에게 전송되는 비디오 및 오디 오 스트림을 포함하는 미디어 콘텐츠의 렌더링을 더 수행한다. 프로세서는 또한 사용자의 보는 위치, 방 향 및/또는 시야각에 기초하여 사용자 디바이스로 전달될 둘 이상의 미디어 스트림을 결정할 수 있다. 프로세 서는 단일 전용 프로세서, 단일 공유 프로세서, 또는 일부가 공유 될 수 있는 복수의 개별 프로세서를 지 칭할 수 있다. 또한, 용어 \"프로세서\"의 명백한 사용은 소프트웨어를 실행할 수 있는 하드웨어만을 독접적으로 지칭하는 것으로 해석되어서는 안되며, 암시적으로 DSP(digital signal processor) 하드웨어, 네트워크 프로세 서, 주문형 반도체(ASIC: application specific integrated circuit), 필드 프로그래머블 게이트 어레이(FPGA: field programmable gate array), 마이크로 프로세서, 마이크로 제어기 등을 포함할 수 있다. 메모리는 프로세서에 의해 실행될 수 있는 명령 및 데이터를 포함하여 프로세서에 의해 액세스 가능한 정보를 저장할 수 있다. 메모리는 컴퓨터 판독 가능 매체 또는 하드 드라이브, 메모리 카드, 플래 시 드라이브, ROM, RAM, DVD 또는 다른 광학 디스크 뿐만 아니라 다른 기록 가능 및 판독 전용 메모리와 같은,전자 장치의 도움을 받아 판독될 수 있는 데이터를 저장하는 다른 매체를 포함하여, 프로세서에 의해 액세 스 가능한 정보를 저장할 수 있는 임의의 적합한 유형일 수 있다. 메모리는 영구 저장 장치와 더불어 임 시 저장 장치를 포함할 수 있다. 명령들은 프로세서에 의해 직접(예를 들어, 기계 코드) 또는 간접적으로 (예를 들어, 스크립트들) 실행될 수 있다. 명령은 프로세서에 의한 직접 처리를위한 목적 코드 포맷으로 저장 될 수 있거나, 필요에 따라 해석되거나 미리 컴파일 될 수 있는 독립 소스 코드 모듈의 스크립트 또는 콜 렉션을 포함하는 임의의 다른 컴퓨터 언어로 저장될 수 있다. 데이터는 명령에 따라 프로세서에 의해 검 색, 저장 또는 수정될 수 있다. 데이터는, 예를 들어, 컴퓨터 레지스터에, 관계형 데이터베이스에 복수의 상이 한 필드 및 레코드, XML 문서 또는 플랫 파일을 갖는 테이블로서 저장될 수 있다. 데이터는 컴퓨터 판독 가능 한 형식으로 포맷팅될 수도 있다. 메모리는 콘텐츠 편집기 및 영구 가상 세계 시스템을 저장할 수 있다. 컨텐츠 편집기는 사용자가 실제 물체의 실시간 3D 가상 복제물 뿐만 아니라 영구 가 상 월드 시스템에 포함될 수 있는 다른 물체, 예를 들어, 실제 물체 주변에 위치할 수 있는 물체(예 컨대, 다른 기계, 테이블, 벽 등)를 생성 및 편집하는 것을 가능하게 해준다. 또한, 실시간 3D 가상 복제물 은 영구 가상 월드 시스템에 저장되어 다른 실제 물체에 대한 위치 및 방향을 포함하는 현실 세 계 위치에서 그것들이 이용 가능하게 할 수 있다. 영구 가상 세계 시스템은 현실 세계의 위치 및 방향, 스케일, 차원, 물리적 특성 및 실제 물체의 3D 구조를 포함하는 현실 세계의 가상 버전을 포함할 수 있다. 그 러나, 영구 가상 세계 시스템은 또한 순수 가상 물체와 같이 현실 세계에 존재하지 않을 수 있는 컴퓨터 생성 가상 물체를 포함할 수 있다. 일부 실시예에서, 메모리는 영구 가상 세계 시스템에 이벤트를 더 저장할 수 있다. 이벤트를 저장하 는 것은, 예를 들어, 사건 탐지 모듈(도시되지 않음)이 추후 리뷰를 위해 이벤트를 검출하고 재생하는 것을 가 능하게 해준다. 사건은 일반적인 이벤트 흐름의 붕괴를 나타낸다. 일반적인 이벤트 흐름은 파라미터 범위 또 는 특성 내에서 결정될 수 있다. 다른 실시예에서, 사건은 서버에 구현된 룰 기반 시스템을 통해 식별된 다. 다른 실시예에서, 사건은 서버에 구현 된 기계 학습 알고리즘을 통해 식별된다. 예를 들어, 사건은 차량 충돌을 지칭 할 수 있으므로, 지속 가상 월드 시스템은 나중에, 예를 들어, 사법 조사를 돕기 위해 재생될 수 있는 실제 물체에서 일어나는 충돌을 즉시 검출할 수 있다. 적어도 하나의 실시간 3D 가상 복제물은 실제 물체의 위치 및 방향 데이터를 포함하는 데이터 포인트와 함께 실제 물체의 물리 속성을 포함하는 실제 물체와 공유되는 복수의 데이터 포 인트를 포함할 수 있다. 데이터 포인트는 실제-가상 쌍 중 어떤 것에서 발생할 수 있는 임의의 변화 의, 적어도 하나의 실제 물체 또는 적어도 하나의 대응하는 실시간 3D 가상 복제물을 통해 전송된 조 작 명령들의 일정한 추적 및 동기화를 가능하게 한다. 데이터 포인트는 적어도 하나의 실제 물체 상 에 또는 그에 부근에 장착된 하드웨어 및 소프트웨어를 포함하는 센싱 메카니즘을 통해 결정될 수 있다. 영구 가상 세계 시스템의 실시간 3D 가상 복제물의 물리적 특성은 치수, 형상, 질감, 질량, 체 적, 굴절률, 경도, 색상, 압력 및 온도를 제한없이 포함할 수 있다. 물리적 특성은 CAD(omputer-aided drawing) 소프트웨어 애플리케이션 일 수 있는 콘텐츠 편집기를 통해 편집될 수 있다. 실제 물체 또 는 다른 물체와 같은 현실 세계 물체를 3 차원 물체로 변환하기 위한 모델링 기술은 당업계에 공지된 기술에 기 초할 수 있다. 예를 들어, 기계 제조자는 영구 가상 세계 시스템에 통합 될 수 있는 머신의 이미 존재하 는 디지털 CAD 모델을 제공할 수 있다. 다른 실시예에서, 합성 개구 레이더, 실-개구 레이더, LIDAR(Light Detection and Ranging), 역 개구 레이다, 모노펄스 레이더, 및 다른 유형의 이미징 기술과 같은 레이더 이미징 이 실세계 물체를 영구 가상 세계 시스템에 통합하기 전에 실세계 물체를 맵핑 및 모델링하기 위해 사용될 수 있다. 다른 실시예에서, 치수, 형상, 텍스처, 체적, 온도 및 컬러와 같은 실제 물체의 하나 이상의 물 리적 특성은 센싱 메커니즘을 통해 직접 얻어 질 수 있고 컨텐츠 편집기를 통해 편집될 수 있다. 프로세서에 의해 수행되는 실시간 프로세싱은 실시간 3D 가상 복제물을 통해 실제 물체를 조작할 때 수신된 조작 명령에 대한 그리고 실제 물체를 통해 실시간 3D 가상 복제물을 조작할 때 수신된 조작 명령 에 대한 운동학적 계산을 포함한다. 예를 들어, 적절한 인터페이스를 통해 기계적 팔을 움직일 때, 실시간 3D 가상 복제물을 업데이트하는데 사용될 수 있는 실제 물체로부터 수신된 조작 명령을 처리 할 때, 운 동학적 계산과 결합된 모션 캡쳐 기술이 실시간 3D 가상 복제물에서 실제 물체의 움직임을 재현한다. 모션 캡쳐 기술은 다양한 광학 센싱 메커니즘, 관성 센싱 메커니즘 또는 이들의 조합을 사용한다. 광학 추적 센싱 메커니즘은 마커 추적 또는 마커리스 추적을 사용할 수 있다. 마커 추적에서, 실제 물체는 마커를 구비한다. 마커는 능동 및 수동 적외선 광원일 수 있다. 능동 적외선 광은 적외선 광 플래시를 주기적으로 또 는 지속적으로 방출할 수 있는 적외선 광원을 통해 생성될 수 있다. 수동 적외선 광은 적외선 광을 소스로 되반사시키는 적외선 역반사기를 지칭할 수 있다. 하나 이상의 카메라는 지속적으로 마커를 찾도록 구성되며, 프 로세서는 알고리즘을 사용하여 마커로부터 실제 물체 및 다양한 부분의 위치를 추출할 수 있다. 알 고리즘은 하나 이상의 마커가 카메라 시야 바깥에 있거나 일시적으로 가려진 경우의 데이터 누락을 해결할 필요 가 있을 수 있다. 마커리스 추적에서, 카메라는 연속적으로 실제 물체와 같은 타겟의 이미지를 검색하고 서버에 포함 된 실시간 3D 가상 복제의 이미지와 비교한다. 관성 추적 센싱 메커니즘은 관성 측정 장치(IMU)에 통합 될 수 있는 가속도계 및 자이로스코프와 같은 장치를 사용할 수 있다. 가속도계는 선형 가속 도를 측정하는데, 이것을 적분하여 속도를 구한 후, 다시 적분하여 초기 지점에 대한 위치를 찾는다. 자이로스 코프는 각속도를 측정하는데, 이것 또한 적분하여 초기 지점에 대한 각 위치를 판정한다. 일부 실시예에서, 서버를 통해 실시간 물체를 실시간 3D 가상 복제물과 동기화시키는 것은 실제 물체(10 2)의 가상 보강 또는 가상 보상의 프로세서에 의한 구현을 가능하게 한다. 일부 실시예에서, 가상 보강 또는 보상은 서버에서 이용 가능하고 가상 기계의 구현을 통해 네트워크를 통해 실제 물체와 공 유 될 수 있는 저장 및 컴퓨팅 기능을 나타내는 가상 리소스를 통해 가능해진다. 다른 실시예에서, 가상 보강 또는 보상은 가상 센서를 통해 활성화되며, 이는 누락된 실제 데이터를 보상하는데 사용될 수 있는 가상으로 이 용 가능한 데이터를 이용하는 것을 나타낸다. 가상 센서는 가상 세계의 3D 구조 및 현실 세계를 나타내는 각각 의 실시간 3D 가상 복제물의 사용을 더 이용할 수 있어서, 실제 물체는 현실 세계에서 이러한 물체 인식을 필요로 하지 않고도 그들의 실시간 3D 가상 복제물을 통해 현실 세계 내의 다른 물체를 인식할 수 있다. 일 실시예에서, 복수의 데이터 포인트의 추적의 정확도를 높이기 위해, 광학 및 관성 추적 센서 및 알고리즘의 조합을 사용하는 센서 융합 기술이 사용될 수 있다. 또 다른 실시예에서, 하나 이상의 송수신기는 안테나로부터 통신 신호를 수신하고 안테나로 전송하도록 구현될 수 있다. 바람직하게는, 송수신기는 mmW 송수 신기이다. mmW 안테나가 사용되는 실시예에서, mmW 송수신기는 안테나로부터 mmW 신호를 수신하고 데이터를 안 테나로 다시 송신하도록 구성된다. 따라서, 센서 융합 기술의 다른 실시예에서, mmW 송수신기에 의해 제공되는 광학 센서, 관성 센서, 및 위치 추적과 mmW 안테나에 의해 제공되는 정밀 추적, 저지연 및 하이 QOS 기능은 서 브-센티미터 또는 서브-밀리미터 위치 및 방향 추적을 가능하게 할 수 있고, 이는 실제 물체의 실시간 위 치 및 방향을 추적할 때 정확도를 증가시킬 수 있다. 다른 실시예에서, 센서 융합은 또한 GNSS 추적 신호로부 터 위치 데이터를 수신하고 정확한 위치 및 방향을 제공하기 위해 mmW 신호 및 관성 추적과 함께 이 데이터를 보강하는 것을 가능하게 한다. 일부 실시예에서, 추적은 도달 시간(TOA), 도달각(AOA), 또는 당업계에 공지된 다른 추적 기술(예를 들어, 시각적 이미징, 레이더 기술 등)과 같은, 당업계에 공지된 여러 기술을 이용하여 수 행될 수 있다. 실시간 물체를 통해 실시간 3D 가상 복제물을 조작할 때, 프로세서에 의해 수행되는 처리는 실 제 물체로부터의 입력을 가능하게 하고, 서버 내의 실시간 3D 가상 복제물을 갱신하고, 그 입력을 출 력 비디오 및 선택적으로 오디오 스트림으로 변환하고, 이들은 그 후 업데이트된 실시간 3D 가상 복제물을 표시하기 위해 사용자 디바이스에 스트리밍된다. 실제 물체에서 수행 된 조작으로부터 입력을 수신 할 때, 프로세서는 사운드 및 비디오 압축 및 어셈블링을 포함하는 미디어 콘텐츠의 전처리 동작을 수행 할 수 있다. 사운드 및 비디오 압축은 각각 오디오 코덱 및 비디오 코덱을 사용하여 수행 할 수 있으며, 이들 은 이후에 컨테이너 비트 스트림에 어셈블링 된다. 오디오 코덱은 오디오 출력을 수신하고, WMA, AAC 또는 보 비스(Vorbis)와 같은 오디오 데이터 스트림을 생성할 수 있는 임의의 인코딩 기술일 수 있다. 일부 실시예에서, 오디오 코덱은 오디오 스트림의 암호화를 지원할 수 있다. 유사하게, 비디오 코덱은 비디오 출력 을 수신하고 WMV 또는 MPEG-4와 같은 비디오 데이터 스트림을 생성할 수 있는 임의의 인코딩 기술일 수 있다. 일부 실시예에서, 비디오 코덱은 비디오 스트림의 암호화를 지원할 수 있다. 바람직하게는 관련 입력 데이터 스트림의 암호화를 지원하거나 결과 오디오 또는 비디오 스트림 또는 다른 방식에 대한 임의의 스트림의 후속 암호화를 허용하는 오디오 또는 비디오 스트림을 생성하는 다른 코덱 또는 다른 방식을 위한 임의의 스트림이 또한 사용될 수 있다. 컨테이너 비트 스트림은 ASF 또는 ISMA와 같은 하나 이상의 데이터 스트림을 수용하도록 구성된 임의의 적합한 비트 스트림 일 수 있다. 그러나, 다른 적합한 컨테이너 비트 스트림이 또한 사용될 수 있으며, 바람직하게는 결과 컨테이너 비트 스트림의 후속 암호화를 허용한다. 프로세서는 사용자 디바이스가 보는 위치, 방향, 및/또는 시야각에 기초하여 사용자 디바이스로 전달될 2 이상의 미디어 스트림을 추가적으로 결정할 수 있고; 그리고 미디어 스트림의 렌더링 작업을 수행할 수 있다. 2 이상의 미디어 스트림을 결정한 후에, 프로세서는 사용자 디바이스가 처리된 미디어 콘 텐트를 사용자에게 적절하게 표현하기 위해 처리된 미디어 콘텐트에 대해 경량의 계산 작업만 수행하면 되는 방 식으로 미디어 렌더링을 수행할 수 있다.미디어 콘텐트의 렌더링은 실제 물체를 나타내는 미디어의 2 이상의 포토리얼리스틱 3D 미디어 스트림을 형성할 수 있는 다양한 렌더링 기술을 포함할 수 있으며, 여기에는 2 이상의 미디어 스트림의 워핑(warping), 스티칭(stitching) 및 보간이 포함되나, 이에 한정되지 않는다. 렌더링은 입력 스트림 데이터에 기초하여 보다 복잡한 재구성 프로세스를 포함할 수 있다. 예를 들어, 렌더링은 스티칭, 워핑, 보간 및 외삽과 같은 표준 이 미지 재구성 기술의 조합에 의존할 수 있다. 예를 들어, 미디어 데이터의 공백이나 구멍을 메우기 위해, 사용 가능한 미디어 스트림을 기반으로 사용할 수 있는(시각적) 정보가 없거나 제한된 영역에서는 외삽 법이 필요할 수 있다. 그러나, 재구성 프로세스는 컴퓨터 비전 기술에 국한되지 않고, 임의의 조합으로, 캡쳐 된 장면에서 의 빛의 흐름 등에 상응할 수 있는 재구성된 3 차원 기하 정보, 재료에 관한 파라미터 및 광 필드 중 하나 이상 을 포함할 수 있는 장면에 대한 공간 데이터를 더 고려할 수 있음을 이해해야 한다. 공간 데이터는 3D 렌더링 기술로 캡처된 장면을 다시 렌더링하는 데 사용될 수 있다. 하나 이상의 실시예들에서, 출력 스트림의 렌더링 은, 상이한 관점에서 얻어진 동일한 장면의 미디어 스트림의 일련의 이미지 또는프레임으로부터 출력 스트림의 이미지 또는 프레임을 재생성하기 위해 적용될 수 있는 딥 러닝 기술 및/또는 뉴럴 네트워크를 사용하는 것을 포함할 수 있다. 이는 장면의 적어도 일부가 완전하게 또는 완전히 상세하게 캡처되지 않더라도 출력 스트림의 복잡한 재구성 및 생성을 가능하게 할 수 있다. 일부 실시예에서, 프로세서는 애플리케이션으로부터의 2차원 시각 출력 데이터에 제한되지 않고, 예를 들 어, 애플리케이션 및 관련 커맨드의 입체적인 출력을 수신하고, 2개의 비디오 스트림 또는 하나의 인터레이스드 (interlaced) 비디오 스트림을 생성할 수 있으며, 사용자의 각각의 눈에 대한 시각적 데이터를 전송한다. 유사 하게, 프로세서는 또한 다른 다차원 멀티-모드 데이터에 대한 데이터 스트림 뿐만 아니라 공간 사운드 데 이터를 운반하는 오디오 스트림을 생성할 수 있다. 일 실시예에서, 복수의 미디어 스트림은 출력 스트림의 품 질이 결정된 시선 방향에 기초하여 또는 프레임의 중심에서와 같이 뷰어가 실제로 보고 있는 위치에 집중되도록 추가 처리될 수 있다. 또한, 예측된 움직임 재구성을 가능하게 하거나, 뷰어가 다음에 볼 위치의 예측 및 그 영역을 미리 재구성하는 것을 포함하여 미디어 스트림을 외삽하기 위해 미디어 스트림이 처리될 수 있다. 또한, 출력 스트림의 품질 및 충실도를 더 향상시키기 위해 눈의 초점 거리(예를 들어, 동공의 상대 위치 및 방 향에 의해 결정됨)를 고려한 부가적인 처리가 적용될 수 있다. 비 제한적인 예는 초점 거리 의존 시프트 및 시 차 효과 뿐만 아니라 뷰어에게 초점이 맞지 않는 것으로 판정될 수 있는 장면의 이러한 부분의 디포커스 블러링 (blurring)이다. 실제 물체를 조작하기 위해 사용자 디바이스를 통해 실시간 3D 가상 복제물으로부터 수신된 조작 명 령을 처리할 때, 프로세서는 실제 물체의 성질에 의존하여 이용 가능한 액션들에 기초하여 다수의 사 전 정의 된 프로세싱 명령들을 액세스할 수 있고, 관련 프로세싱 명령과 조작 명령을 일치시킬 수 있고, 그리고 복수의 작용기에 영향을 주기 위해 각각의 기계 액추에이터에 실행 명령을 전송할 수 있다. 조작 명령은 하나 이상의 회전 운동, 병진 운동, 하나 이상의 행동의 선택, 하나 이상의 행동의 프로그래밍, 하나 이상의 파라미 터의 설정, 또는 이들의 조합을 포함할 수 있다. 또한, 실시간 물체의 물리적 특성이 서버에 저장되 고 동기화되기 때문에, 실시간 3D 가상 복제물의 기계적 팔의 특정 부분의 이동 속도 및 느낌은 실제 물체(10 2)의 능력을 기초로 시뮬레이션되고 따라서 실제 생활 능력으로 제한된다. 조작 명령이 병진 운동 또는 회전 운동만을 포함하는 실시예에서, 프로세서는 리버스 키네매틱 계산을 사용하여 명령을 처리 할 수 있다. 리버스 키네매틱스는 일반적으로 원하는 위치를 기반으로 각각의 작용기에 대해 원하는 위치를 제공하는 조인트 파라미터를 결정하는 데 사용된다. 조작 명령이 복수의 순차적 단계(예를 들어, 로봇 착석, 기립, 펀칭, 장애 물 피하기 또는 픽-앤-드롭(pick-and-drop) 동작을 수행하는 기계적 팔)를 포함하여 보다 복잡한 동작을 포함하 는 실시예에서, 처리 명령은 포워드 키네매틱스 및 리버스 키네매틱스의 통합된 조합을 이용할 수 있다. 포워 드 키네매틱스는 방정식을 사용하여 조인트 파라미터에 대하여 지정된 값으로부터 말단 작용기의 위치를 계산한 다. 예시적인 실시예에서, 실제 물체는(예를 들어, 인쇄 회로 기판 용의) 페인팅, 용접, 어셈블링, 패키징, 라 벨링, 픽업 및 배치 등에 사용되는 하나 이상의 산업용 로봇과 같은 공장 기계를 지칭할 수 있다. 다른 예시적 인 실시예에서, 실제 물체는 항공기(예를 들어, 비행기, 드론, 헬리콥터 등), 육상 차량(예를 들어, 자동차, 모 터 바이크, 트럭 등) 및 해양 운송 수단(예를 들어, 보트, 화물선, 잠수함 등)을 포함하는 운송 수단을 지칭할 수 있다. 산업 기계의 양방향 관리는 제조 플랜트의 임의의 부분에서 일어나는 변화를 모니터링할 수 있는 동 시에 실시간으로 복수의 산업 기계를 원격으로 관리하는 데 유용할 수 있다. 예를 들어, 구급차가 과중한 교 통량을 거쳐야할 필요가 있을 사고 또는 자연 재해 시와 같이, 어떤 방식으로 이동하기 위한 차량을 필요로 하 는 경우에, 달리는 차량의 더 우수한 제어를 가지기 위한, 예컨대, 정부 기관에게 양방향 차량 관리가 유용할수 있다. 예를 들어, 기계적 팔에 하나 이상의 동작을 수행하도록 지시하는 것은 기계적 팔이 위치하는 작업 공간에서 사 용 가능한 모든 또는 대부분의 물체를 포함하는 공간 내의 기계적 팔의 실시간 3D 가상 복제물을 모바일 장치 또는 VR/AR 안경 또는 다른 헤드 장착 디스플레이를 통해 사용자가 보는 것을 포함할 수 있다. 사용자는 메모리로부터 다수의 옵션들을 추출하고 표시될 옵션을 사용자 디바이스를 통해 사용자에게 전송하기 위해 서버의 프로세서를 프롬프팅하는, 실시간 3D 가상 복제물을 통한 기계적 팔을 원격으로 그 리고 가상으로 선택하기 위해 기계 암의 실시간 3D 가상 복제물을 터치할 수 있다. 옵션은, 예를 들어, 이동, 회전 및 픽-앤-드랍 작업 수행이 포함될 수 있다. 사용자가 어떤 옵션을 선택하느냐에 따라, 프로세서 는 조작 명령과 미리 프로그램 된 실행 명령과의 비교를 진행할 수 있다. 병진 또는 회전 운동만을 포함 하는 간단한 이동 태스크의 경우, 실시간 3D 가상 복제물 사용자는 사용자 인터페이스상의 기계적 팔을 (예를 들어, 터치, 에어 제스처, 마우스 또는 버튼 등에 의해) 선택할 수 있으며, 기계적 팔을 원하는 위치와 방향으로 움직여 원하는 동작을 수행할 수 있다. 다른 예에서, 프로세서는 보다 무거운 컴퓨팅 오퍼레이 션을 요구하는 태스크와 같은, 조작 명령에 대한 소정의 프로세싱 태스크를 수행할 수 있고, 사전 처리된 명령 을 기계적 팔로 보낼 수 있다. 기계적 팔의 프로세서는 이후에 명령을 실행하기 전에 다른 처리 작업을 수행할 수 있다. 보다 복잡한 작업은 사용자가 기계적 팔의 환경과 상호 작용할 수 있도록 하는 것과 같이 하나 이상 의 물체에 대한 작업을 포함할 수 있다. 예를 들어 픽-앤-드롭 동작의 경우 사용자는 먼저 기계 팔을 터치하고 픽-앤-드롭 동작을 선택하고 대상 물체를 선택한 다음 그 물체를 드롭해야 하는 목표 위치를 선택할 수 있다. 이어서, 프로세서는 조작 명령을 이용 가능한 처리 명령과 비교하고, 논리적 순서로 명령을 처리하고, 기 계 팔 상에서의 실행을 위해 처리된 명령의 전송을 진행한다. 기계적 팔은 일부 처리 명령을 수행할 수도 있다. 다른 예에서, 사용자는 실시간 3D 가상 복제물을 조작하여 기계 팔을 회전시킬 수 있다. 사용자는 기계 팔을 터치하여 실시간 3D 가상 복제물을 통해 기계 팔을 가상적으로 선택하고 이어서 기계 팔을 회전시킬 수 있다. 프로세서는 명령을 처리 할 수 있고 대응하는 액추에이터에 각각의 명령을 전송함으로써 기계 팔을 실시간으로 회전시킬 수 있다. 그러나, 실시간 3D 가상 복제물을 통해 기계 팔이 회전 될 수 있는 속도는 기계 팔이 안전 계수를 고려하여 도달 할 수 있는 속도로 제한 될 수 있다. 도 2b는 현실 세계와 가상 세계 시스템 사이의 관계를 더 보여주는 시스템(200b)을 나타낸다. 현실 세계는 하나 이상의 사용자 디바이스를 사용하는, 인간 사용자(114a) 또는 AI 사용자(114b) 일 수 있 는 복수의 사용자를 포함하는 섹션; 및 하나 이상의 실제 물체를 조작하는, 물체 조작자(116a) 또는 AI 물체 조작자(116b) 일 수 있는 물체 조작자를 포함하는 섹션을 포함한다. 섹션 및 섹 션의 요소는, 현실 세계의 데이터 포인트가 영구 가상 세계 시스템의 데이터 포인트 에 대응하도록 물리 속성 및 위치 및 방향을 포함하는 영구 가상 세계 시스템과 데이터 포인트 를 공유한다. 현실 세계는 하나 이상의 복수의 기술(예를 들어, 스캐닝, 모델링, 카메라를 통한 검 출)을 통해 그들이 서버에 입력되었을 때 영구 가상 세계 시스템에 그래픽으로 포함되어 있으나(예컨대, IoT 센서와 같은 센싱 메커니즘이 그들 상에 설치되어 있지 않기 때문에) 영구 가상 월드 시스템과 실시간 으로 데이터 포인트를 공유하지 않는 요소와 같은, 섹션 및 섹션에 포함되지 않은 다른 요소(도시되 지 않음)를 더 포함할 수 있다 영구 가상 세계 시스템은 사용자 및/또는 다른 물체 조작자 가상 복제물, 실제 물체 가상 복제물 , 및 다른 물체에 대응하는 다른 가상 복제물을 포함하는 현실 세계 내의 요소의 실시간 3D 가 상 복제물을 3D 구조로 배열한다. 사용자 디바이스로부터 실제 물체로 전송된 임의의 유형의 조작 명령은 영구 가상 월드 시스템 을 통해 공유 데이터 포인트를 통해 실제 물체에 공유되며, 각각의 실시간 3D 가상 복제물 및 적용 가능하다면 가상 복제물 및 각각의 실제 물체의 컨텍스트를 실시간으로 업데이트한다. 마찬가지로, 실제 물체를 통해 전송된 조작 명령은 각각의 사용자 디바이스를 통해 하나 이상의 사용자(114a)가 볼 수 있는 공유된 데이터 포인트를 통해 실시간 3D 가상 복제물을 실시간으로 업데이트하는 역할을 하며, 적용 가능하다면 가상 복제물 및 각각의 실제 물체의 컨텍스트를 업데이트한다. 도 3은 사용자 디바이스의 동작 구성 요소의 표현을 상술하게 보여주는, 본 개시물의 일 실시예에 따른 시 스템의 개략도를 도시한다. 동작 구성 요소는 모두 프로세서에 동작 가능하게 연결된 입력/출력(I/O) 모 듈, 전원, 메모리, 센서, 송수신기 및 네트워크 인터페이스를 포함할 수 있다.I/O 모듈은 사용자와 상호 작용하고 사용자 입력 데이터를 하나 이상의 다른 시스템 구성 요소에 제공하도 록 구성된 컴퓨팅 하드웨어 및 소프트웨어로서 구현된다. 예를 들어, I/O 모듈은 실시간 3D 기반 상호 작 용에 기초하여 사용자 입력 데이터를 생성하고 서버와 같은 네트워크를 통해 다른 처리 시스템으로 전송되기 전에 사용자 입력 데이터를 프로세서에 제공하도록 구성될 수 있다. 다른 예에서, I/O 모듈 은 외부 컴퓨팅 포인팅 장치(예컨대, 터치 스크린, 마우스, 3D 제어, 조이스틱, 게임 패드 등) 및/또는 텍 스트 입력 장치(예를 들어, 키보드, 툴 등)을 포함할 수 있다. 또 다른 실시예에서, I/O 모듈은 전술 한 기능 보다 많은 기능, 적은 기능 또는 상이한 기능을 제공할 수 있다. 전원은 사용자 디바이스에 전력을 제공하도록 구성된 컴퓨팅 하드웨어로서 구현된다. 일 실시예에서, 전원은 배터리일 수 있다. 전원은 장치에 내장되거나 장치로부터 제거 될 수 있으며 충 전식 또는 비 충전식일 수 있다. 일 실시예에서, 장치들은 하나의 전원을 또 다른 전원으로 대체함 으로써 재공급될 수 있다. 다른 실시예에서, 전원은 퍼스널 컴퓨터에 부착 된 USB(universal serial bus), 파이어와이어, 이더넷, 썬더볼트, 헤드폰 케이블과 같은 충전 소스에 부착 된 케이블에 의해 재충전될 수 있다. 또 다른 실시예에서, 전원은 유도 충전에 의해 재충전될 수 있는데, 여기서 전자기장은 유도 충전 기로부터 전원으로 에너지를 전달하는데 사용되며, 이 때 유도 충전기와 전원은 다른 케이블을 통해 서로 플러깅될 필요없이 근헙하게 놓이기만 하면 된다. 다른 실시예에서, 충전을 용이하게 하기 위해 도킹 스테이션 이 사용될 수 있다. 메모리는 애플리케이션 프로그램 명령을 저장하고 센서에 의해 캡쳐된 장치들의 원격 측정 메타 데이 터를 저장하도록 적응된 컴퓨팅 소프트웨어 및 하드웨어로서 구현될 수 있다. 메모리는 컴퓨터 판독 가능 매체, 또는 하드 드라이브, 메모리 카드, 플래시 드라이브, ROM, RAM, DVD 또는 다른 광학 디스크 뿐만 아니라 다른 기록 가능 및 판독 전용 메모리와 같은, 전자 장치의 도움으로 판독될 수 있는 데이터를 저장하는 다른 매 체를 포함하여, 프로세서에 의해 액세스 가능한 정보를 저장할 수 있는 임의의 적합한 유형일 수 있다. 메모리는 영구 저장 장치와 더불어 임시 저장 장치를 포함할 수 있다. 센서는 사용자로부터 다양한 원격 측정 메타 데이터를 획득하고 그들의 움직임과 함께 사용자의 위치 및 방향을 결정/추적하도록 적응 된 컴퓨팅 소프트웨어 및 하드웨어로서 구현될 수 있다. 센서는, 예를 들면, 관성 측정 유닛(IMU), 가속도계, 자이로스코프, 광 센서, 햅틱 센서, 카메라, 안구 추적 센서 및 마이크 로폰 중 하나 이상을 포함할 수 있다. IMU는 가속도계 및 자이로스코프의 조합을 사용하여 속도, 가속도, 각 운동량, 벙진운동 속도, 회전 속도 및 사용자 디바이스의 다른 원격 측정 메타 데이터를 측정 및 보고하도 록 구성된다. IMU 내의 가속도계는 지구의 중력장으로 인한 가속도를 포함하여, 실시간 3D 기반 상호 작용 디 바이스의 가속도를 측정하도록 구성될 수 있다. 일 실시예에서, IMU 내의 가속도계는 3 개의 직교 방향으로 가 속도를 측정할 수 있는 3 축 가속도계를 포함할 수 있다. 조명 센서, 햅틱 센서, 카메라, 안구 추적 센서 및 마이크는 실시간 3D 가상 복제물을 직접 조작할 때마다 사용자 및 사용자의 환경으로부터의 입력 세부정보를 캡 처하는데 사용할 수 있으며, 이러한 정보는 음성 및 햅틱 관련 실시간 3D 기반 상호작용 뿐만 아니라 조명 및 사운드와 같은 환경적 요인 및 사용자가 보는 위치 및 방향에 의존하여 사용자 디바이스로 전달될 하나 이 상의 미디어 스트림을 결정하기 위해 서버로 전송될 수 있다. 송수신기는 장치가 안테나로부터 무선 라디오 파를 수신하고 안테나로 데이터를 다시 전송할 수 있도록 구 성된 컴퓨팅 소프트웨어 및 하드웨어로서 구현될 수 있다. 일부 실시예에서, 몰입형(immersive) 컨텐츠와 상호 작용할 때 안테나로부터 mmW 파 신호를 수신하고 안테나로 데이터를 다시 보내도록 구성된 mmW 송수신기가 사용 될 수 있다. 송수신기는 양방향 통신 송수신기 일 수 있다. 일 실시예에서, 추적 모듈은 IMU, 가속도계 및 자이로스코프의 성능을 송수신기에 의해 제공되는 위 치 추적, 및 mmW 기반 안테나에 의해 제공되는 정확한 추적, 저지연 및 하이 QOS 기능과 결합함으로써 구현될 수 있으며, 이는 서브-센티미터 또는 서브 밀리미터 위치 및 방향 추적을 가능하게 하고, 이는 사용자 디바이스 의 실시간 위치 및 방향을 추적할 때 정확성을 증가시킬 수 있다. 추가 실시예에서, 추적 모듈은 GNSS 추적 신호로부터 위치 데이터를 수신하고 정확한 위치 및 방향을 제공하기 위해 mmW 신호 및 관성 추적으 로 이 데이터를 보강하는 것을 가능하게 한다. 일부 실시예에서, 추적은 도달 시간(TOA), 도달 각(AOA), 또는 당업계에 공지된 다른 추적 기술(예를 들어, 시각적 이미징, 레이더 기술 등)과 같은 당업계에 공지된 여러 기 술을 이용하여 수행될 수 있다. 네트워크 인터페이스는 네트워크에 통신 가능하게 접속하고, 서버에 의해 전송되는 네트워크 로부터의 컴퓨터 판독 가능 프로그램 명령을 수신하고, 프로세서에 의한 실행을 위해 사용자 디바이스의 메모리에 저장하기 위해 컴퓨터 판독 가능 프로그램 명령을 전송하기 위한 컴퓨팅 소프트웨어 및 하드웨어로서 구현될 수 있다. 프로세서는 사용자 입력 데이터를 수신하고 처리하도록 구성된 컴퓨팅 하드웨어 및 소프트웨어로서 구현될 수 있다. 예를 들어, 프로세서는 이미징 요청을 제공하고, 이미징 데이터를 수신하고, 환경 또는 이미징 데이터를 다른 데이터로 처리하고, 사용자 입력 데이터 및/또는 이미징 데이터를 처리하여 사용자 실시간 3D 기 반 상호 작용 데이터를 생성하고, 서버 요청을 수신하고, 서버 응답을 수신하고 및/또는 사용자 실시 간 3D 기반 상호 작용 데이터, 환경 데이터 및 콘텐츠 물체 데이터를 하나 이상의 다른 시스템 컴포넌트에 제공 하도록 구성될 수 있다. 예를 들어, 프로세서는 I/O 모듈로부터 사용자 입력 데이터를 수신할 수 있 고 메모리에 저장된 애플리케이션 프로그램을 각각 구현할 수 있다. 다른 예에서, 프로세서는 센서 로부터, 송수신기로부터, 또는 이들의 조합으로부터 위치, 포지션 또는 다른 원격 측정 메타 데이터 (예를 들어, 사용자의 손 움직임, 제어기 조작, 주행 궤적 등에 관한 정보)를 수신 할 수 있다. 또한, 프로세 서는 원시공 데이터 감축 또는 필터링과 같은 아날로그 또는 디지털 신호 처리 알고리즘을 구현할 수 있다. 특정 실시예에서, 프로세서는 사용자 디바이스상에 실시간 3D 가상 복제물을 정확하게 표현하 기 위해 요구되는 계산과 같이, 서버로부터 수신된 미디어 콘텐츠에 경량의 연산 작업을 수행하도록 구성 될 수 있다. 도 4는 실제 물체의 다양한 동작 컴포넌트의 표현을 상술하게 보여주는, 본 개시물의 일 실시예에 따른 시 스템의 개략도를 도시한다. 동작 컴포넌트는 입/출력(I/O) 모듈, 전원, 메모리, 액추에이터 및 이팩터에 부착 된 센서, 송수신기, 및 네트워크 인터페이스를 포함하며, 이들 모 두는 프로세서에 동작 가능하게 연결된다. I/O 모듈은 오브젝트 조작자와 상호 작용하고 오브젝트 조작자 사용자 입력 데이터를 하나 이상의 다른 시 스템 구성 요소에 제공하도록 구성된 컴퓨팅 하드웨어 및 소프트웨어로서 구현된다. 예를 들어, I/O 모듈(40 2)은 실시간 3D 기반 상호 작용에 기초하여 물체 조작자와 상호 작용하고, 사용자 입력 데이터를 생성하고, 서 버와 같은 네트워크를 통해 다른 처리 시스템으로 전송하기 전에 사용자 입력 데이터를 프로세서 에 제공하도록 구성될 수 있다. 다른 예에서, I/O 모듈은 물체 및 옵션을 선택하기 위한 외부 컴퓨 팅 포인팅 장치(예를 들어, 터치 스크린, 마우스, 3D 제어, 조이스틱, 레버, 스티어링 휠, 게임 패드 등) 및/또 는 실제 물체와 상호 작용하도록 구성된 조작 명령을 입력하기 위한 텍스트 입력 장치(예를 들어, 키보드, 버튼, 받아쓰기 도구 등)로서 구현될 수 있다. 또 다른 실시예에서, I/O 모듈은 전술 한 기능에 보다 많 은 기능, 적은 기능 또는 상이한 기능을 제공할 수 있다. 전원은 실제 물체에 전력을 제공하도록 구성된 컴퓨팅 하드웨어로서 구현되며, 도 3에 설명 된 것과 유사한 설명을 따를 수 있다. 메모리는 애플리케이션 프로그램 명령 및 데이터를 저장하도록 적응 된 컴퓨팅 소프트웨어 및 하드웨어로 서 구현될 수 있으며, 도 3에 설명 된 것과 유사한 설명을 따를 수 있다. 센서는, 예를 들어, 서버와 동기화 및 공유될 수 있는 데이터 포인트를 제공하기 위해 그리고 실제 물체의 하나 이상의 물리 속성에 대한 데이터 표현을 서버에 제공하기 위해 실제 물체의 복수의 액츄에이터 및 작용기의 위치 및 방향을 결정하고 추적하도록 적응될 수 있다. 일부 실시예에서, 센 서는 실제 물체의 다른 영역 또는 실제 물체를 둘러싸는 영역에서 구현될 수 있다. 예를 들어, 센서는 실제 물체의 복수의 조인트 및 커넥터 상에 배치될 수 있다. 센서는 예를 들어,도 2를 참조하여 기술 된 광학 센서, 관성 센서 또는 이들의 조합을 포함하는 모션 캡쳐 장비를 포함할 수 있다. 다른 실시예에서, 실제 물체의 특성 및 기능에 따라 온도계, 압력 센서, 습도 센서 등과 같은 실제 물체의 다른 특징의 데이터 표현을 제공할 수 있는 다른 센서가 또한 포함될 수 있다. 송수신기는 실제 물체가 안테나들로부터 무선 라디오 파를 수신하고 데이터를 안테나들로 다시 전송 할 수 있게 하도록 구성된 컴퓨팅 소프트웨어 및 하드웨어로서 구현될 수 있다. 일부 실시예에서, 몰입형 컨텐 츠와 상호 작용할 때 안테나로부터 mmW 파 신호를 수신하고 안테나로 데이터를 다시 보내도록 구성될 수 있는 mmW 송수신기가 사용될 수 있다. 송수신기는 양방향 통신 송수신기일 수 있다. 일 실시예에서, 추적 모듈은 IMU, 가속도계 및 자이로스코프의 성능을 송수신기에 의해 제공된 위치 추적 및 mmW 기반 안테나에 의해 제공되는 정확한 추적, 저 지연 및 높은 QOS 기능과 결합함으로써 구현될 수 있으며, 이는 서브 센티미터 또는 서브 밀리미터 위치 및 방향 추적을 가능하게 할 수 있고, 이는 실제 물체의 실시간 위치 및 방위를 추적할 때 정확도를 증가시킬 수 있다. 다른 실시예에서, 추적 모듈은 GNSS 추적 신호로부터 위치 데이터를 수신하고 정확한 위치 및 방향을 제공하기 위해 mmW 신호 및 관성 추적으 로 이 데이터를 보강하는 것을 가능하게 한다. 일부 실시예에서, 추적은 도달 시간(TOA), 도달 각(AOA), 또는 당업계에 공지된 다른 추적 기술(예를 들어, 시각적 이미징, 레이더 기술 등)과 같은 당업계에 공지된 여러 기 술을 이용하여 수행될 수 있다. 네트워크 인터페이스는 네트워크에 통신 가능하게 접속하고, 서버에 의해 전송되는 네트워크 로부터의 컴퓨터 판독 가능 프로그램 명령을 수신하고, 프로세서에 의한 실행을 위해 장치의 메모리 에 저장하기 위해 컴퓨터 판독 가능 프로그램 명령을 전송하기 위한 컴퓨팅 소프트웨어 및 하드웨어로서 구현될 수 있다. 프로세서는 I/O 모듈을 통해 직접 입력되거나 서버로부터 오는 조작 명령을 처리하고, 작용기 의 필요한 동작을 수행하기 위해 액츄에이터에 처리된 명령을 전송하도록 구성 될 수 있다. 예를 들 어, 프로세서는 I/O 모듈로부터 사용자 입력 데이터를 수신 할 수 있고 메모리에 저장된 애플리 케이션 프로그램을 각각 구현할 수 있다. 다른 예에서, 프로세서는 센서, 트랜스시버 또는 이 들의 조합으로부터 위치, 포지션 또는 다른 원격 측정 메타 데이터를 수신하고, 그 정보를 실시간 3D 가상 복제 물을 업데이트하기 위해 서버에 전송할 수 있다. 프로세서는 또한 원시 데이터 감축 또는 필터링과 같은 아날로그 또는 디지털 신호 처리 알고리즘을 구현할 수 있다. 일부 실시예에서, 프로세서는 서버 와의 일부 계산 태스크를 공유할 수 있다. 도 5는 일 실시예에 따른, 실제 물체의 직접 조작을 통한 실시간 3D 가상 복제물의 조작을 상술히 보 여주는, 본 발명의 일 실시예에 따른 방법의 흐름도를 도시한다. 방법은, 예를 들어, 도 1a 내지 도 4와 관련하여 서술한 시스템들과 같은, 본 개시물의 일 실시예에 따른 시스템에 의해 실행될 수 있다. 방법은 블록에서 볼 수 있는 바와 같이, 적어도 하나의 실제 물체의 적어도 하나의 실시간 3D 가상 복제물이 표현되어 있는 데이터 구조를 포함하는 영구 가상 월드 시스템을 서버에 제공함 으로써 시작한다. 실제 물체의 실시간 3D 가상 복제물을 제공하는 것은 물리 속성 및 실제 물체 의 3 차원의 현실 세계 좌표를 포함하는, 실시간 3D 가상 복제물을 그래픽으로 생성 및/또는 편집하 기 위해, 서버에 저장되고 계산되는, 컨텐츠 편집기를 사용하는 것을 포함할 수 있다. 실시간 3D 가상 복 제물은 사용자 디바이스로부터 적절한 사용자 인터페이스를 통해 사용자에 의해 액세스 될 수 있다. 그 다음, 방법은 블록에서 볼 수 있는 바와 같이, 실시간 3D 가상 복제물을 실제 물체와 동기화함으로써 계속되며, 이는 액추에이터, 작용기, 조인트 및 커넥터와 같은 실제 물체의 다앙한 부분 상의, 또는 실제 물체 주위의 영역 내의 복수의 센서(예를 들어, 실제 물체에 부근에 배치된 카메 라)로부터 데이터를 획득하는 것을 포함할 수 있다. 복수의 센서는 서버에 통신되고 실시간 3D 가상 복제 물과 공유되는 복수의 데이터 포인트를 생성 할 수 있다. 일부 실시예에서, 실제 물체에 연결된 센 서는 또한 점선으로 표시된 실시간 3D 가상 복제물으로의 피드백을 제공한다. 피드백 데이터는 실시 간 3D 가상 복제물을 보강하고 실제 물체에 대한 실시간 3D 가상 복제물의 정확성을 증가시키기 위해 실제 물체의 추가 물리적 특성을 더 제공할 수 있다. 실시간 3D 가상 복제물을 실제 물체(10 2)와 동기화 할 때, 서버는 동기화 된 실시간 3D 가상 복제물을 영구 물체 가상 세계 시스템을 통해 네트워크를 통해 실제 물체 및 사용자 디바이스로 전송한다. 실시간 3D 가상 복제물을 실 제 물체 및 사용자 디바이스와 동기화 한 후에, 실제 물체 또는 실시간 3D 가상 복제물에 대해 수행 된 동작은 가상 또는 실제의 대응부에 직접적인 효과를 가진다는 것을 이해해야 하다. 프로세스를 계속하여, 블록에서 보여지는 바와 같이, 오브젝트 조작자는 실제 물체의 직접 조작 을 진행할 수 있다. 블록에서, 실제 물체는 조작 명령의 처리를 진행할 수 있다. 예를 들어,도 4를 참조하면, 물체 조작자는 적절한 I/O 모듈을 통해 프로세서로 전송될 수 있는 조작 명령을 입력 할 수 있다. 프로세서는 메모리 내의 프로세싱 명령 및 데이터에 액세스 할 수 있고, 물체 조작자로 부터의 조작 명령의 처리를 진행할 수 있다. 프로세서는 또한 작용기가 태스크를 수행하기 위해 어떤 조 인트가 이동되어야 하는지를 결정하는데 필요한 운동학적 계산을 수행 할 수 있다. 이어서, 방법은 블록 에서 보여지는 바와 같이, 실제 물체가 조작 명령을 실행함으로써 진행한다. 명령을 실행하는 것은 실제 물체에 의해 원하는 작업을 수행하는 데 필요한 작용기를 이동시키는 활성화를 위한 복수의 액추에이 터에 전기 신호를 전송하는 것을 포함할 수 있다.시스템이 동기화되어 있으므로, 블록에서 실제 물체를 조작하는 것은 조작 명령을 서버에 보낸 다. 조작 명령을 수신 한 후에, 서버는 또한 블록에서 보여지는 바와 같이, 실시간 3D 가상 복제물 에서의 실제 물체의 움직임을 재생성하기 위해, 뿐만 아니라 비디오 및 오디오 스트림을 사용자 디바 이스로 전송하기 위해 태스크를 렌더링하기 위해 사용되는 운동학적 계산과 같은 명령에 대한 처리 작업을 수행 할 수 있다. 서버에 의한 조작 명령을 처리하는 것은 실제 물체를 통한 물체 조작자의 위치 및 방향, 및 사용자 디바이스를 통한 사용자의 위치 및 방향을 수신 및 처리하는 것을 더 포함할 수 있 다. 일부 실시예에서, 서버에서 수행되는 프로세싱은 실제 물체에서 수행되는 프로세싱을 보완한다. 따라서, 실제 물체는 처리 명령의 일부를 수행할 수 있고 반면, 서버는 보다 무거운 태스크 계산을 수행함으로써 실제 물체를 지원할 수 있다. 서버가 블록에서 조작 명령을 처리 한 후에, 방법은 블록에서 보여지는 바와 같이, 서버 사용자 디바이스에서 동기화되어 있는 적어도 하나의 수정 된 실시간 3D 가상 복제물으로 영구 가상 세계 시스템을 업데이트함으로써 계속된다. 단계에서, 사용자 디바이스는 변경을 겪었을 수 있 는 실시간 3D 가상 복제물을 포함하는 갱신된 영구 가상 세계 시스템을 출력함으로써 계속되고, 이는 업데이트 된 실시간 3D 가상 복제물을 적절하게 디스플레이하기 위해 수신된 미디어 스트림에 대한 경량 오퍼레이션을 수행하는 것을 포함한다. 이어서, 방법은 실제 물체로부터 오는 조작 명령이 더 있는 지의 여부를 체크하며, 이 경우 방법은 물체 조작자가 실제 물체를 조작함으로써 블록 으로 되돌아 간다. 더 이상 지시가 없으면, 종결부에서 보여지는 바와 같이, 프로세스는 종료될 수 있다. 도 6은 실시간 3D 가상 복제물의 직접 조작을 통한 실제 물체의 조작을 상세하게 보여주는, 본 발명 의 일 실시예에 따른 방법의 흐름도를 도시한다. 방법은 예를 들어, 도 1a 내지 도 4와 관련하여 서 술한 시스템들과 같은 본 개시물의 일 실시예에 따른 시스템에 의해 실행될 수 있다. 도 6에 도시 된 일부 단 계들은 도 5에 도시된 단계들에 대응하고, 도면들에서 유사한 도면 부호들 및 설명들은 도 6에서 사용될 수 있 다. 방법의 초기 부분은 방법의 초기 부분과 동일하다. 따라서, 방법은 블록(502 및 504) 뿐만 아 니라 점선을 방법과 공유한다. 방법은 블럭에서 보여지는 바와 같이, 사용자 디바이스 로부터 적절한 사용자 인터페이스를 통해 실시간 3D 가상 복제물을 가상적으로 선택하고, 이어 서 선택된 실시간 3D 가상 복제물 및 대응하는 실제 물체에 선택 명령을 전송함으로써 계속된다. 일 부 실시예에서, 사용자 디바이스에 의해 서버로 보내진 선택 명령은 하나 이상의 사용자의 위치 및 방향 데이터를 포함한다. 서버 및 실제 물체는 선택 명령들의 처리를 블록들(604 및 606)에서 각 각 진행할 수 있다. 방법은 블럭에서 보여지는 바와 같이, 사용자가 실시간 3D 가상 복제물 을 조작하고, 이어서 서버 및 실제 물체가 블럭(610 및 612)에서 각각 조작 명령을 처리함으로 써 진행한다. 일부 실시예에서, 서버에서 수행되는 프로세싱은 실제 물체에서 수행되는 프로세스의 보완이며, 그러므로 더 무거운 작업 계산을 수행함으로써 실제 물체를 지원할 수 있다. 이어서, 실제 물체는 블록에서 실제 물체에 대한 명령의 실행을 진행한다. 동시에, 서버 는 블록에서 보여지는 바와 같이, 적어도 하나의 수정 된 실시간 3D 가상 복제물으로 영구 가상 세계 시스템을 업데이트할 수 있다. 사용자 디바이스는 변경을 겪었을 수 있는 실시간 3D 가상 복제물을 포함하는 업데이트된 영구 가상 세계 시스템의 출력을 진행할 수 있으며, 이는 블록에서 보여지는 바 와 같이, 사용자 디바이스상에 업데이트된 실시간 3D 가상 복제물를 적절하게 디스플레이하기 위해 수신된 미디어 스트림에 대한 경량 오퍼레이션을 수행하는 것을 포함할 수 있다. 그 다음, 방법은, 검사 에서, 사용자 디바이스로부터 오는 조작 명령이 더 있는지 여부를 검사하고, 그 후 방법은 사용 자가 실시간 3D 가상 복제물을 사용자 디바이스를 통해 계속 조작함으로써 블록으로 되돌 아간다. 더 이상 지시가 없으면, 종단부에서 보여지는 바와 같이, 프로세스가 종료 될 수 있다. 도 7은 본 발명의 일 실시예에 따른, 실시간 3D 가상 복제물 및 실제 물체의 양방향 조작을 가능하게 하는 본 발명의 일 실시예에 따른 서버 구현 방법의 흐름도를 도시한다. 방법은, 예를 들어, 도 5에 도시 된 실제 물체의 직접 조작을 통한 실시간 3D 가상 복제물을 조작하는 방법 및 도 6에 묘사된 실시간 3D 가상 복제물의 직접 조작을 통한 실제 물체를 조작하는 방법을 통합할 수 있다. 일부 실시예에서, 방법은 도 1a 내지도 4와 관련하여 서술된 시스템과 같은 본 개시의 일 실시예에 따른 시스템에 의해 실행될 수 있다. 방법은 적어도 하나의 실제 물체의 적어도 하나의 실시간 3D 가상 복제물이 표현되어 있는 구조를 포함하 는 영구 가상 월드 시스템을 제공함으로써 단계(702 및 704)에서 시작될 수 있다. 그 다음, 블록에서, 방 법은 적어도 하나의 실시간 3D 가상 복제물을, 실시간 3D 가상 복제물을 보강하기 위한 실시간 3D 가상 복 제물로 피드백을 다시 전송하는, 적어도 하나의 대응하는 실제 물체와 동기화하고, 실제 물체에 대한 실시간 3D 가상 복제물의 정확도를 높이고, 동기화를 기반으로 실시간 3D 가상 복제물에 특정 물리 속성을 제공함으로써 블록에서 계속된다. 방법은 블록에서 실제 물체 또는 사용자 디바이스 중 하나를 통해 입력 된 선택 및/또는 조작 명령의 수신을 진행하고, 이어서 단계에서 각각의 실제 물체 및 실시간 3D 가상 복제물에 대한 선택 및/또는 조작 명령의 처리 및 실행을 진행한다. 일부 실시예에서, 서버에 의한 일부 프로세싱은 실제 물체에 의해 국부적으 로 수행되는 프로세싱을 지원하는데 사용될 수 있다. 방법은 단계에서 보여지는 바와 같이, 서버 상 에 저장 및 계산된 수정된 하나 이상의 실시간 3D 가상 복제물으로 가상 세계 시스템을 업데이트하고, 업데이트 된 모델을 컴퓨팅 장치로 전송함으로써 계속된다. 그 다음, 방법은, 검사에서, 더 많은 명령들이 있는지 여부를 검사하고, 그러한 경우 방법은 블록으로 되돌아 간다. 그렇지 않으면, 방법은 종단부 에서 종료될 수 있다. 특정 실시예가 첨부된 도면에 도시되고 설명되었지만, 그러한 실시예는 당업자에게 다양한 다른 변형이 발생할 수 있으므로 단지 본 발명의 예시일 뿐 본 발명을 제한하지 않으며, 본 발명은 도시되고 기술된 특정 구조 및 배열에 제한되지 않는다. 따라서, 본 설명은 제한이 아니라 예시적인 것으로 간주되어야 한다."}
{"patent_id": "10-2019-0060413", "section": "도면", "subsection": "도면설명", "item": 1, "content": "첨부된 도면과 함께 아래의 상세한 설명을 참조함으로써, 전술한 양태 및 다수의 수반하는 이점들이 더 잘 이해 될 것이다. 도 1a-1b는 본 발명의 일 실시예에 따른, 실시간 3D 가상 복제물 및 실제 물체의 양방향 조작을 가능하게 하는 시스템의 개략도를 도시한다. 도 2a 및 도 2b는 현실 세계와 가상 세계 시스템 사이의 관계의 표현을 상세하게 보여주는, 본 발명의 일 실시 예에 따른 시스템의 개략도를 도시한다. 도 3은 사용자 디바이스의 다양한 동작 컴포넌트의 표현을 상세하게 보여주는, 본 발명의 일 실시예에 따른 시 스템의 개략도를 도시한다. 도 4는 실제 물체의 다양한 동작 컴포넌트의 표현을 상세하게 보여주는, 본 발명의 일 실시예에 따른 시스템의 개략도를 도시한다. 도 5는 본 발명의 일 실시예에 따른, 실제 물체의 직접 조작을 통해 실시간 3D 가상 복제물을 조작할 때 실시간 3D 가상 복제물 및 실제 물체의 양방향 조작을 가능하게 하는 방법의 흐름도를 도시한다. 도 6은 본 발명의 일 실시예에 따른, 실시간 3D 가상 복제물의 조작을 통해 실제 물체를 조작할 때 실시간 3D 가상 복제물 및 실제 물체의 양방향 조작을 가능하게 하는 방법의 흐름도를 도시한다. 도 7은 일 실시예에 따른, 실시간 3D 가상 복제물 및 실제 물체의 양방향 조작을 상세하게 보여주는, 본 발명의 일 실시예에 따른 서버 구현 방법의 흐름도를 도시한다."}
