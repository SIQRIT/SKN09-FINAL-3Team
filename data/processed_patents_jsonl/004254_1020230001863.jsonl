{"patent_id": "10-2023-0001863", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0109831", "출원번호": "10-2023-0001863", "발명의 명칭": "관심 영역 자동 설정 방법 및 이를 위한 영상 분석 장치", "출원인": "주식회사 엘지유플러스", "발명자": "주진선"}}
{"patent_id": "10-2023-0001863", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "영상 분석을 위한 영상을 입력 받는 단계;상기 영상 내에서 적어도 하나의 객체 영역을 감지하는 단계;상기 적어도 하나의 객체 영역의 내부와 외부를 구분하도록 상기 적어도 하나의 객체 영역을 포함하는 피처 영상을 설정하되, 상기 피처 영상에 소정 시간 동안 상기 적어도 하나의 객체 영역이 누적되는 단계; 및상기 피처 영상에 누적된 객체 영역을 기반으로 객체 이벤트 감지를 위한 관심 영역을 설정하는 단계;를 포함하는 관심 영역 자동 설정 방법."}
{"patent_id": "10-2023-0001863", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1 항에 있어서, 상기 객체 영역은, 인공지능 추론에 따른 객체 블랍 또는 객체 실루엣으로 감지되는 것을 특징으로 하는 관심영역 자동 설정 방법."}
{"patent_id": "10-2023-0001863", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 2 항에 있어서,상기 객체 영역의 타입에 따라서 상기 객체 영역을 소팅하는 단계를 더욱 포함하는 것을 특징으로 하는 관심 영역 자동 설정 방법."}
{"patent_id": "10-2023-0001863", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 1 항에 있어서, 상기 영상의 일정 시간의 동안의 복수의 프레임을 누적하여 평균하여 배경 모델을 설정하는 단계; 및상기 영상과 배경 모델을 비교하여 전경 피처 영상을 설정하고, 상기 전경 피처 영상의 움직임 영역을 상기 객체 영역으로 감지하는 단계;를 더욱 포함하는 것을 특징으로 하는 관심 영역 자동 설정 방법."}
{"patent_id": "10-2023-0001863", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제 4 항에 있어서, 상기 전경 피처 영상에 대해 컴퓨터 비전 분석을 수행하여 상기 객체 영역을 소팅하는 단계;를 더욱 포함하는것을 특징으로 하는 관심 영역 자동 설정 방법."}
{"patent_id": "10-2023-0001863", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제 1 항에 있어서, 상기 객체 영역은 시간이 지남에 따라 상기 관심 영역 설정의 기여도가 낮아지도록 상기 피처 영상에 누적되는것을 특징으로 하는 관심 영역 자동 설정 방법."}
{"patent_id": "10-2023-0001863", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제 6 항에 있어서, 상기 피처 영상의 현재 프레임 및 소정 개수의 과거 프레임들이 링 버퍼에 시간 순서에 따라 입력되는 단계; 및상기 객체 영역의 상기 관심 영역 설정에 대한 기여도가 달라지도록 하기 위해, 상기 현재 프레임 및 상기 소정개수의 과거 프레임들 각각에 프레임의 설정 시점에 따라 다른 가중치가 부여되는 단계;를 포함하는 것을 특징공개특허 10-2024-0109831-3-으로 하는 관심 영역 자동 설정 방법."}
{"patent_id": "10-2023-0001863", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제 6 항에 있어서, 상기 피처 영상의 현재 프레임 및 소정 시간 이내의 과거 프레임들이 실루엣 히스토리 이미지 수식에 입력되는단계; 및상기 객체 영역의 상기 관심 영역 설정에 대한 기여도가 달라지도록 하기 위해, 상기 현재 프레임 및 상기 소정개수의 과거 프레임들 각각에 프레임의 설정 시점에 따라 다른 가중치가 부여되는 단계;를 포함하는 것을 특징으로 하는 관심 영역 자동 설정 방법."}
{"patent_id": "10-2023-0001863", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제 1 항에 있어서, 상기 이벤트 감지는, 상기 피처 영상에 누적된 상기 객체 영역을 기반으로 설정된 상기 관심 영역 전체 또는 일부에 대해 수행되는 것을 특징으로 하는 관심 영역 자동 설정 방법."}
{"patent_id": "10-2023-0001863", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제 1 항에 있어서, 상기 영상은, 실시간으로 입력되는 동영상 또는 녹화되어 재생되는 동영상인 것을 특징으로 하는 관심 영역 자동 설정 방법."}
{"patent_id": "10-2023-0001863", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "영상 분석을 위한 영상을 입력 받기 위한 카메라; 및상기 영상 내에서 적어도 하나의 객체 영역을 감지하고,상기 적어도 하나의 객체 영역의 내부와 외부를 구분하도록 상기 적어도 하나의 객체 영역을 포함하는 피처 영상을 설정하되, 상기 피처 영상에 소정 시간 동안 상기 적어도 하나의 객체 영역이 누적되고,상기 피처 영상에 누적된 객체 영역을 기반으로 객체 이벤트 감지를 위한 관심 영역을 설정하도록 제어하는 제어부;를 포함하는 영상 분석 장치."}
{"patent_id": "10-2023-0001863", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제 11 항에 있어서, 상기 객체 영역은, 인공지능 추론에 따른 객체 블랍 또는 객체 실루엣으로 감지되는 것을 특징으로 하는 영상분석 장치."}
{"patent_id": "10-2023-0001863", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제 12 항에 있어서, 상기 제어부는,상기 객체 영역의 타입에 따라서 상기 객체 영역을 소팅하도록 더욱 제어하는 것을 특징으로 하는 영상 분석 장치."}
{"patent_id": "10-2023-0001863", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제 11 항에 있어서, 상기 제어부는,상기 영상의 일정 시간의 동안의 복수의 프레임을 누적하여 평균하여 배경 모델을 설정하고,상기 영상과 배경 모델을 비교하여 전경 피처 영상을 설정하고, 상기 전경 피처 영상의 움직임 영역을 상기 객체 영역으로 감지하도록 더욱 제어하는 것을 특징으로 하는 영상 분석 장치."}
{"patent_id": "10-2023-0001863", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "공개특허 10-2024-0109831-4-제 14 항에 있어서, 상기 제어부는,상기 전경 피처 영상에 대해 컴퓨터 비전 분석을 수행하여 상기 객체 영역을 소팅하도록 더욱 제어하는 것을 특징으로 하는 영상 분석 장치."}
{"patent_id": "10-2023-0001863", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제 11 항에 있어서, 상기 객체 영역은 시간이 지남에 따라 상기 관심 영역 설정의 기여도가 낮아지도록 상기 피처 영상에 누적되는것을 특징으로 하는 영상 분석 장치."}
{"patent_id": "10-2023-0001863", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제 16 항에 있어서, 상기 제어부는,상기 피처 영상의 현재 프레임 및 소정 개수의 과거 프레임들을 링 버퍼에 시간 순서에 따라 입력하고,상기 객체 영역의 상기 관심 영역 설정에 대한 기여도가 달라지도록 하기 위해, 상기 현재 프레임 및 상기 소정개수의 과거 프레임들 각각에 프레임의 설정 시점에 따라 다른 가중치를 부여하도록 더욱 제어하는 것을 특징으로 하는 영상 분석 장치."}
{"patent_id": "10-2023-0001863", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제 16 항에 있어서, 상기 제어부는,상기 피처 영상의 현재 프레임 및 소정 시간 이내의 과거 프레임들을 실루엣 히스토리 이미지 수식에 입력하고,상기 객체 영역의 상기 관심 영역 설정에 대한 기여도가 달라지도록 하기 위해, 상기 현재 프레임 및 상기 소정개수의 과거 프레임들 각각에 프레임의 설정 시점에 따라 다른 가중치를 부여하도록 더욱 제어하는 것을 특징으로 하는 영상 분석 장치."}
{"patent_id": "10-2023-0001863", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제 11 항에 있어서, 상기 이벤트 감지는, 상기 피처 영상에 누적된 객체 영역을 기반으로 설정된 상기 관심 영역 전체 또는 일부에대해 수행되는 것을 특징으로 하는 영상 분석 장치."}
{"patent_id": "10-2023-0001863", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제 11 항에 있어서, 상기 영상은, 실시간으로 입력되는 동영상 또는 녹화되어 재생되는 동영상인 것을 특징으로 하는 영상 분석 장치."}
{"patent_id": "10-2023-0001863", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_21", "content": "영상 분석을 위한 영상을 입력 받기 위한 명령어;상기 영상 내에서 적어도 하나의 객체 영역을 감지하기 위한 명령어;상기 적어도 하나의 객체 영역의 내부와 외부를 구분하도록 상기 적어도 하나의 객체 영역을 포함하는 피처 영상을 설정하되, 상기 피처 영상에 소정 시간 동안 상기 적어도 하나의 객체 영역이 누적되도록 하기 위한 명령어; 및상기 피처 영상에 누적된 상기 객체 영역을 기반으로 객체 이벤트 감지를 위한 관심 영역을 설정하기 위한 명령어;를 포함하는, 관심 영역 자동 설정을 위해 컴퓨터에 의해 실행되도록 구성된 프로그램을 저장하는 기록매체."}
{"patent_id": "10-2023-0001863", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은, 관리자(즉, 사람)의 수동 작업을 줄이고 조명의 변화에도 강건하게 이벤트를 탐지할 수 있으며, 카메 라 설치 위치 또는 촬영 방향 변경, 카메라 영상의 확대 또는 축소 시에도 관심 영역의 재설정이 자동으로 이루 어질 수 있는 관심 영역 자동 설정 방법 및 이를 위한 영상 분석 장치로서, 영상 분석을 위한 영상을 입력 받는 단계, 상기 영상 내에서 적어도 하나의 객체 영역을 감지하는 단계, 상기 적어도 하나의 객체 영역의 내부와 외 부를 구분하도록 상기 적어도 하나의 객체 영역을 포함하는 피처 영상을 설정하되, 상기 피처 영상에 소정 시간 동안 누적적으로 상기 적어도 하나의 객체 영역이 표시되는 단계, 및 상기 피처 영상에 상기 누적적으로 표시된 객체 영역을 기반으로 객체 이벤트 감지를 위한 관심 영역을 설정하는 단계를 포함하는 관심 영역 자동 설정 방 법을 제공할 수 있다."}
{"patent_id": "10-2023-0001863", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 지능형 영성 분석에 관한 것으로서, 카메라 영상과 같은 입력 영상에서 이벤트 검출을 위해 관심 영 역을 자동으로 설정하거나 생성할 수 있도록 하는 관심 영역 자동 설정 방법 및 이를 위한 영상 분석 장치에 관 한 것이다."}
{"patent_id": "10-2023-0001863", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "사용자 단말기는 이동 가능여부에 따라 이동 단말기(mobile/portable terminal) 및 고정 단말기(stationary terminal)으로 나뉠 수 있다. 다시 이동 단말기는 사용자의 직접 휴대 가능 여부에 따라 휴대(형) 단말기 (handheld terminal) 및 거치형 단말기(vehicle mounted terminal)로 나뉠 수 있다. 사용자 단말기의 기능은 다양화 되고 있다. 예를 들면, 데이터와 음성통신, 카메라를 통한 사진촬영 및 비디오 촬영, 음성녹음, 스피커 시스템을 통한 음악파일 재생 그리고 디스플레이부에 이미지나 비디오를 출력하는 기능 이 있다. 일부 단말기는 전자게임 플레이 기능이 추가되거나, 멀티미디어 플레이어 기능을 수행한다. 특히 최근 의 이동 단말기는 방송과 비디오나 텔레비전 프로그램과 같은 시각적 컨텐츠를 제공하는 멀티캐스트 신호를 수 신할 수 있다. 이와 같은 사용자 단말기는 기능이 다양화됨에 따라 예를 들어, 사진이나 동영상의 촬영, 음악이나 동영상 파일 의 재생, 게임, 방송의 수신 등의 복합적인 기능들을 갖춘 멀티미디어 기기(Multimedia player) 형태로 구현되 고 있다. 최근 CCTV(Closed Circuit Television)의 설치가 증가하면서 효율적인 모니터링을 위해, 지능형 영상분석 기술 (Intelligent video analytics)에 대한 관심이 높아지고 있다. 상기 사용자 단말기는 지능형 영상 분석 장치로 도 활용될 수 있다. 지능형 영상분석 기술은 영상의 정보를 분석하여 사전에 정의된 이벤트를 감지하여 자동으로 관리자에게 경보를 전송하는 기술이다. 지능형 영상 분석에서 검출 혹은 탐지하는 이벤트로는, 침입 탐지, 출입 탐지, 객체 계수를 예로 들 수 있다. 지능형 영상 분석은, 예를 들어, 배경 영역 분리, 객체 검출, 객체 추적 및 이벤트 탐지 과정으로 이루어지며, 이러한 과정을 통해서 사전에 정의된 이벤트를 탐지할 수 있다. 여기서, 배경 영역 분리는, 입력된 영상에서 관심 있는 전경 영역과 배경 영역을 구분하는 과정이고, 객체 검출 은, 전경 영역에서 객체의 위치, 크기, 모양 등을 검출하는 과정이고, 객체 추적은 연속되는 영상에서 검출된 객체의 이동 경로를 찾는 과정이며, 이벤트 탐지는 객체의 특징 정보와 이동 정보를 바탕으로 사전에 정의된 규 칙을 위반하는 지 혹은 만족하는 지를 판단하는 과정이다. 이러한 영상 분석 과정에서, 이벤트 룰은, 영상에 설정된 경계선으로 정의될 수 있으며, 이러한 이벤트 룰에 따 라서 객체 검출 혹은 추적을 수행하는 영상의 영역을 관심 영역(Region of interest)이라 한다. 그런데 기존의 영상 분석 장치에 있어서, 상기 관심 영역은, 이벤트 모니터링을 위한 카메라 영상에서 관리자에 의해 임의로 수동으로 설정되거나, 관리자가 관심 영역을 지정하지 않는 경우 카메라 영상의 전체 영역이 관심 영역으로 된다. 이로 인해 불필요한 영상 분석이 이루어질 수 있으며, 그 결과 컴퓨터 자원 낭비 및 처리 시간 증가를 초래하게 된다. 또한, 관심 영역이 적절히 설정되지 못할 경우, 영상 분석 장치에서 이벤트를 검출하지 못하는 오동작을 일으킬 수 있으므로, 카메라의 촬영 방향 또는 영역이 변경되는 경우 관심 영역 또한 계속 수동으로 변경되어야 되어야 한다는 문제점이 있었다. 한편, 기존의 영상 분석 장치에 있어서 카메라 영상의 색상 정보만으로 이벤트를 검출하기도 하였다. 그러나, 이 경우, 조명의 변화 및/또는 그림자의 영향으로 이벤트의 오검출이 빈번하게 발생된다는 문제점이 있었다."}
{"patent_id": "10-2023-0001863", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은, 관리자(즉, 사람)의 수동 작업을 줄이고 조명의 변화에도 강건하게 이벤트를 탐지할 수 있으며, 카 메라 설치 위치 또는 촬영 방향 변경, 카메라 영상의 확대 또는 축소 시에도 관심 영역의 재설정이 자동으로 이 루어질 수 있는 관심 영역 자동 설정 방법 및 이를 위한 영상 분석 장치를 제공하는 것을 그 목적으로 한다."}
{"patent_id": "10-2023-0001863", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기와 같은 목적을 달성하기 위해 본 발명의 일 측면에 따르면, 영상 분석을 위한 영상을 입력 받는 단계, 상 기 영상 내에서 적어도 하나의 객체 영역을 감지하는 단계, 상기 적어도 하나의 객체 영역의 내부와 외부를 구 분하도록 상기 적어도 하나의 객체 영역을 포함하는 피처 영상을 설정하되, 상기 피처 영상에 소정 시간 동안 상기 적어도 하나의 객체 영역이 누적되는 단계, 및 상기 피처 영상에 누적된 객체 영역을 기반으로 객체 이벤 트 감지를 위한 관심 영역을 설정하는 단계를 포함하는 관심 영역 자동 설정 방법을 제공할 수 있다. 상기 객체 영역은, 인공지능 추론에 따른 객체 블랍 또는 객체 실루엣으로 감지될 수 있다. 상기 관심 영역 자동 설정 방법은, 상기 객체 영역의 타입에 따라서 상기 객체 영역을 소팅하는 단계를 더욱 포 함할 수 있다. 상기 관심 영역 자동 설정 방법은, 상기 영상의 일정 시간의 동안의 복수의 프레임을 누적하여 평균하여 배경 모델을 설정하는 단계, 및 상기 영상과 배경 모델을 비교하여 전경 피처 영상을 설정하고, 상기 전경 피처 영상 의 움직임 영역을 상기 객체 영역으로 감지하는 단계를 더욱 포함할 수 있다. 상기 관심 영역 자동 설정 방법은, 상기 전경 피처 영상에 대해 컴퓨터 비전 분석을 수행하여 상기 객체 영역을 소팅하는 단계를 더욱 포함할 수 있다. 상기 객체 영역은 시간이 지남에 따라 상기 관심 영역 설정의 기여도가 낮아지도록 상기 피처 영상에 누적될 수 있다. 상기 관심 영역 자동 설정 방법은, 상기 피처 영상의 현재 프레임 및 소정 개수의 과거 프레임들이 링 버퍼에 시간 순서에 따라 입력되는 단계, 및 상기 객체 영역의 상기 관심 영역 설정에 대한 기여도가 달라지도록 하기 위해, 상기 현재 프레임 및 상기 소정 개수의 과거 프레임들 각각에 프레임의 설정 시점에 따라 다른 가중치가 부여되는 단계를 포함할 수 있다. 상기 관심 영역 자동 설정 방법은, 상기 피처 영상의 현재 프레임 및 소정 시간 이내의 과거 프레임들이 상기 실루엣 히스토리 이미지 수식에 입력되는 단계, 및 상기 객체 영역의 상기 관심 영역 설정에 대한 기여도가 달 라지도록 하기 위해, 상기 현재 프레임 및 상기 소정 개수의 과거 프레임들 각각에 프레임의 설정 시점에 따라 다른 가중치가 부여되는 단계를 더욱 포함할 수 있다. 상기 이벤트 감지는, 상기 피처 영상에 누적된 상기 객체 영역을 기반으로 설정된 상기 관심 영역 전체 또는 일 부에 대해 수행될 수 있다. 상기 영상은, 실시간으로 입력되는 동영상 또는 녹화되어 재생되는 동영상일 수 있다. 또한, 본 발명의 일 측면에 따르면, 영상 분석을 위한 영상을 입력 받기 위한 카메라, 및 상기 영상 내에서 적 어도 하나의 객체 영역을 감지하고, 상기 적어도 하나의 객체 영역의 내부와 외부를 구분하도록 상기 적어도 하 나의 객체 영역을 포함하는 피처 영상을 설정하되, 상기 피처 영상에 소정 시간 동안 상기 적어도 하나의 객체 영역이 누적되고, 상기 피처 영상에 누적된 상기 객체 영역을 기반으로 객체 이벤트 감지를 위한 관심 영역을 설정하도록 제어하는 제어부를 포함하는 영상 분석 장치를 제공할 수 있다. 또한, 본 발명의 일 측면에 따르면, 영상 분석을 위한 영상을 입력 받기 위한 명령어, 상기 영상 내에서 적어도 하나의 객체 영역을 감지하기 위한 명령어, 상기 적어도 하나의 객체 영역의 내부와 외부를 구분하도록 상기 적 어도 하나의 객체 영역을 포함하는 피처 영상을 설정하되, 상기 피처 영상에 소정 시간 동안 상기 적어도 하나 의 객체 영역이 누적되도록 하기 위한 명령어, 및 상기 피처 영상에 누적된 상기 객체 영역을 기반으로 객체 이 벤트 감지를 위한 관심 영역을 설정하기 위한 명령어를 포함하는, 관심 영역 자동 설정을 위해 컴퓨터에 의해 실행되도록 구성된 프로그램을 저장하는 기록 매체를 제공할 수 있다."}
{"patent_id": "10-2023-0001863", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명에 따른 관심 영역 자동 설정 방법 및 이를 위한 영상 분석 장치의 효과에 대해 설명하면 다음과 같다. 본 발명의 실시 예들 중 적어도 하나에 의하면, 관리자(즉, 사람)의 수동 작업을 줄이고 조명의 변화에도 강건 하게 이벤트를 탐지할 수 있으며, 카메라 설치 위치 또는 촬영 방향 변경, 카메라 영상의 확대 또는 축소 시에 도 관심 영역의 재설정이 자동으로 이루어질 수 있다는 장점이 있다."}
{"patent_id": "10-2023-0001863", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 첨부된 도면을 참조하여 본 명세서에 개시된 실시 예를 상세히 설명하되, 도면 부호에 관계없이 동일하거 나 유사한 구성요소는 동일한 참조 번호를 부여하고 이에 대한 중복되는 설명은 생략하기로 한다. 이하의 설명 에서 사용되는 구성요소에 대한 접미사 \"모듈\" 및 \"부\"는 명세서 작성의 용이함만이 고려되어 부여되거나 혼용 되는 것으로서, 그 자체로 서로 구별되는 의미 또는 역할을 갖는 것은 아니다. 또한, 본 명세서에 개시된 실시 예를 설명함에 있어서 관련된 공지 기술에 대한 구체적인 설명이 본 명세서에 개시된 실시 예의 요지를 흐릴 수 있다고 판단되는 경우 그 상세한 설명을 생략한다. 또한, 첨부된 도면은 본 명세서에 개시된 실시 예를 쉽게 이 해할 수 있도록 하기 위한 것일 뿐, 첨부된 도면에 의해 본 명세서에 개시된 기술적 사상이 제한되지 않으며, 본 발명의 사상 및 기술 범위에 포함되는 모든 변경, 균등물 내지 대체물을 포함하는 것으로 이해되어야 한다. 이들 각 구성요소는 별도의 개별 하드웨어 모듈로 구성되거나 둘 이상의 하드웨어 모듈로 구현될 수도 있고, 둘 이상의 구성요소들이 하나의 하드웨어 모듈로 구현될 수도 있으며, 경우에 따라서는 소프트웨어로도 구현될 수 있음은 물론이다. 제1, 제2 등과 같이 서수를 포함하는 용어는 다양한 구성요소들을 설명하는데 사용될 수 있지만, 상기 구성요소 들은 상기 용어들에 의해 한정되지는 않는다. 상기 용어들은 하나의 구성요소를 다른 구성요소로부터 구별하는 목적으로만 사용된다. 어떤 구성요소가 다른 구성요소에 \"연결되어\" 있다거나 \"접속되어\" 있다고 언급된 때에는, 그 다른 구성요소에 직접적으로 연결되어 있거나 또는 접속되어 있을 수도 있지만, 중간에 다른 구성요소가 존재할 수도 있다고 이 해되어야 할 것이다. 반면에, 어떤 구성요소가 다른 구성요소에 \"직접 연결되어\" 있다거나 \"직접 접속되어\" 있 다고 언급된 때에는, 중간에 다른 구성요소가 존재하지 않는 것으로 이해되어야 할 것이다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 출원에서, \"포함한다\" 또는 \"가지다\" 등의 용어는 명세서상에 기재된 특징, 숫자, 단계, 동작, 구성요소, 부 품 또는 이들을 조합한 것이 존재함을 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성요소, 부품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되 어야 한다. 본 명세서에서 설명되는 영상 분석 장치 또는 단말기에는 휴대폰, 스마트 폰(smart phone), 노트북 컴퓨터 (laptop computer), 디지털방송용 단말기, PDA(personal digital assistants), PMP(portable multimedia player), 네비게이션, 슬레이트 PC(slate PC), 태블릿 PC(tablet PC), 울트라북(ultrabook) 등이 포함될 수 있 다. 도 1을 참조하면, 도 1은 본 발명과 관련된 영상 분석 장치를 설명하기 위한 블록도이다. 상기 영상 분석 장치는 무선 통신부, 입력부, 러닝 프로세서, 출력부, 인터페이스부 , 메모리, 제어부, 및 전원 공급부 등을 포함할 수 있다. 도 1에 도시된 모든 구성요소들 이 사용자 단말기를 구현하는데 있어서 필수적인 것은 아니어서, 본 명세서 상에서 설명되는 사용자 단말기는 위에서 열거된 구성요소들 보다 많거나, 또는 적은 구성요소들을 가질 수 있다. 도 1의 각 구성요소는 실제 구 현되는 영상 분석 장치의 사양에 따라 통합, 추가, 또는 생략될 수 있다. 즉, 필요에 따라 2 이상의 구성 요소가 하나의 구성요소로 합쳐지거나, 혹은 하나의 구성요소가 2 이상의 구성요소로 세분되어 구성될 수 있다. 보다 구체적으로, 상기 구성요소들 중 무선 통신부는, 영상 분석 장치와 무선 통신 시스템 사이, 영 상 분석 장치와 다른 영상 분석 장치 사이, 또는 영상 분석 장치와 외부서버 사이의 무선 통신 을 가능하게 하는 하나 이상의 모듈을 포함할 수 있다. 또한, 상기 무선 통신부는, 영상 분석 장치를 하나 이상의 네트워크에 연결하는 하나 이상의 모듈을 포함할 수 있다. 상기 무선 통신부는, 방송 채널을 통하여 외부의 방송 관리 서버로부터 방송 신호 및/또는 방송 관련된 정보를 수신하기 위한 방송 수신 모듈, 이동통신을 위한 기술표준들 또는 통신방식(예를 들어, LTE(Long Term Evolution), LTE-A(Long Term Evolution-Advanced), 5G 등)에 따라 구축된 이동 통신망 상에서 기지국, 외부의 단말, 서버 중 적어도 하나와 무선 신호를 송수신하기 위한 이동통신 모듈, 무선 인터넷 접속을 위한 무선 인터 넷 모듈, 근거리 통신(예를 들어, 블루투스(Bluetooth™), 적외선 통신(Infrared Data Association; IrDA), NFC(Near Field Communication), Wi-Fi(Wireless-Fidelity) 등)을 위한 근거리 통신 모듈, 및 영상 분석 장치 의 위치(또는 현재 위치)를 획득하기 위한 모듈 위치정보 모듈 (예를 들면, GPS(Global Positioning System) 모듈) 중 적어도 하나를 포함할 수 있다. 입력부는, 영상 신호 입력을 위한 카메라 또는 영상 입력부, 오디오 신호 입력을 위한 마이크로폰 (microphone, 122) 또는 오디오 입력부, 사용자로부터 정보를 입력받기 위한 사용자 입력부(123, 예를 들어, 터 치키(touch key), 푸시키(mechanical key) 등)를 포함할 수 있다. 입력부에서 수집한 음성 데이터나 이미 지 데이터는 분석되어 사용자의 제어명령으로 처리될 수 있다. 러닝 프로세서는 학습 데이터를 이용하여 인공 신경망으로 구성된 모델을 학습시킬 수 있다. 여기서, 학습 된 인공 신경망을 학습 모델이라 칭할 수 있다. 학습 모델은 학습 데이터가 아닌 새로운 입력 데이터에 대하여 결과 값을 추론해 내는데 사용될 수 있고, 추론된 값은 어떠한 동작을 수행하기 위한 판단의 기초로 이용될 수 있다. 출력부는 시각, 청각 등과 관련된 출력을 발생시키기 위한 것으로, 디스플레이부, 음향 출력부 중 적어도 하나를 포함할 수 있다. 디스플레이부는 터치 센서와 상호 레이어 구조를 이루거나 일체형으로 형성됨으로써, 터치 스크린을 구현할 수 있다. 이러한 터치 스크린은, 영상 분석 장치와 사용자 사이의 입 력 인터페이스를 제공하는 사용자 입력부로서 기능함과 동시에, 영상 분석 장치와 사용자 사이의 출 력 인터페이스를 제공할 수 있다. 인터페이스부는 영상 분석 장치에 연결되는 다양한 종류의 외부 기기와의 통로 역할을 수행한다. 이 러한 인터페이스부는, 유/무선 헤드셋 포트(port), 외부 충전기 포트(port), 유/무선 데이터 포트(port), 메모리 카드(memory card) 포트, 식별 모듈이 구비된 장치를 연결하는 포트(port), 오디오 I/O(Input/Output) 포트(port), 비디오 I/O(Input/Output) 포트(port), 이어폰 포트(port) 중 적어도 하나를 포함할 수 있다. 영 상 분석 장치에서는, 상기 인터페이스부에 외부 기기가 연결되는 것에 대응하여, 연결된 외부 기기와 관련된 적절할 제어를 수행할 수 있다. 또한, 메모리는 영상 분석 장치의 다양한 기능을 지원하는 데이터를 저장한다. 메모리는 영상 분석 장치에서 구동되는 다수의 응용 프로그램(application program 또는 애플리케이션(application)), 영상 분석 장치의 동작을 위한 데이터들, 명령어들을 저장할 수 있다. 메모리는 모델 저장부를 포함할 수 있다. 모델 저장부는 러닝 프로세서을 통하여 학습 중 인 또는 학습된 모델(또는 인공 신경망, 231a)을 저장할 수 있다. 제어부는 상기 응용 프로그램과 관련된 동작 외에도, 통상적으로 영상 분석 장치의 전반적인 동작을 제어한다. 제어부는 위에서 살펴본 구성요소들을 통해 입력 또는 출력되는 신호, 데이터, 정보 등을 처리 하거나 메모리에 저장된 응용 프로그램을 구동함으로써, 사용자에게 적절한 정보 또는 기능을 제공 또는 처리할 수 있다. 또한, 제어부는 메모리에 저장된 응용 프로그램을 구동하기 위하여, 도 1와 함께 살펴본 구성요소들 중 적어도 일부를 제어할 수 있다. 나아가, 제어부는 상기 응용 프로그램의 구동을 위하여, 영상 분석 장치에 포함된 구성요소들 중 적어도 둘 이상을 서로 조합하여 동작시킬 수 있다. 전원공급부는 제어부의 제어 하에서, 외부의 전원, 내부의 전원을 인가 받아 영상 분석 장치에 포함된 각 구성요소들에 전원을 공급한다. 이러한 전원공급부는 배터리를 포함하며, 상기 배터리는 내장형 배터리 또는 교체가능한 형태의 배터리가 될 수 있다. 상기 각 구성요소들 중 적어도 일부는, 이하에서 설명되는 다양한 실시 예들에 따른 영상 분석 장치의 동작, 제 어, 또는 제어방법을 구현하기 위하여 서로 협력하여 동작할 수 있다. 또한, 상기 영상 분석 장치의 동작, 제어, 또는 제어방법은 상기 메모리에 저장된 적어도 하나의 응용 프로그램의 구동에 의하여 영상 분석 장 치 상에서 구현될 수 있다. 한편, 이하에서 다양한 실시 예는 예를 들어, 소프트웨어, 하드웨어 또는 이들의 조합된 것을 이용하여 컴퓨터 또는 이와 유사한 장치로 읽을 수 있는 기록매체 내에서 구현될 수 있다. 본 명세서에 따른 인공지능과 관련된 기능을 위해 상기 제어부는 하나 또는 복수의 프로세서를 포함할 수 있다. 이때, 하나 또는 복수의 프로세서는 CPU(Central Processing Unit), AP(Application Processor), DSP(Digital Signal Processor) 등과 같은 범용 프로세서, GPU(Graphic Processing Unit), VPU(Vision Processing Unit)와 같은 그래픽 전용 프로세서 또는 NPU(Neural Processing Unit)와 같은 인공지능 전용 프로 세서일 수 있다. 하나 또는 복수의 프로세서는, 메모리에 저장된 기 정의된 동작 규칙 또는 인공지능 모델에 따 라, 입력 데이터를 처리하도록 제어할 수 있다. 또는, 하나 또는 복수의 프로세서가 인공지능 전용 프로세서인 경우, 인공지능 전용 프로세서는, 특정 인공지능 모델의 처리에 특화된 하드웨어 구조로 설계될 수 있다. 영상 또는 음성 등과 같은 데이터의 분석에 필요한 인공지능 모델은 학습을 통해 만들어질 수 있다. 여기서, 학 습을 통해 만들어진다는 것은, 기본 인공지능 모델이 학습 알고리즘에 의하여 다수의 학습 데이터들을 이용하여 학습됨으로써, 원하는 특성(또는, 목적)을 수행하도록 설정된 기 정의된 동작 규칙 또는 인공지능 모델이 만들 어짐을 의미한다. 이러한 학습은 본 명세서에 따른 인공지능이 수행되는 기기 자체에서 이루어질 수도 있고, 별 도의 서버 및/또는 시스템을 통해 이루어 질 수도 있다. 학습 알고리즘의 예로는, 지도형 학습(supervised learning), 비지도형 학습(unsupervised learning), 준지도형 학습(semi-supervised learning) 또는 강화 학습 (reinforcement learning)이 있으나, 전술한 예에 한정되지 않는다. 인공지능 모델은, 복수의 신경망 레이어들로 구성될 수 있다. 복수의 신경망 레이어들 각각은 복수의 가중치들 (weight values)을 갖고 있으며, 이전(previous) 레이어의 연산 결과와 복수의 가중치들 간의 연산을 통해 신경 망 연산을 수행할 수 있다. 복수의 신경망 레이어들이 갖고 있는 복수의 가중치들은 인공지능 모델의 학습 결과 에 의해 최적화될 수 있다. 예를 들어, 학습 과정 동안 인공지능 모델에서 획득한 로스(loss) 값 또는 코스트 (cost) 값이 감소 또는 최소화되도록 복수의 가중치들이 갱신될 수 있다. 인공 신경망은 심층 신경망(DNN:Deep Neural Network)를 포함할 수 있으며, 예를 들어, CNN (Convolutional Neural Network), DNN (Deep Neural Network), RNN (Recurrent Neural Network), RBM (Restricted Boltzmann Machine), DBN (Deep Belief Network), BRDNN(Bidirectional Recurrent Deep Neural Network) 또는 심층 Q-네트워크 (Deep Q-Networks) 등 이 있으나, 전술한 예에 한정되지 않는다. 이하, 도 2 및 도 3을 참조하여, 상기 영상 분석 장치를 통해 관심 영역을 자동 설정하는(또는 생성하는) 방법 대해 설명하겠다. 도 2는 본 발명의 일실시예에 따른 관심 영역 자동 설정에 대한 순서도이고, 도 3은 도 2의 관심 영역 자동 설정 방법에 따라 프로세싱되는 영상을 도시한다. 상기 영상 분석 장치의 상기 제어부는 상기 카메라를 통해 도 3의 (3-1)에 도시된 바와 같은 영 상 분석을 위한 영상을 입력 받을 수 있도록 제어할 수 있다[S21]. 또는, 상기 제어부는 상기 무선 통신부 또는 상기 인터페이스부를 통해 도 3의 (3-1)에 도시된 바와 같은 영상 분석을 위한 영상 을 외부 기기(미도시)로부터 입력 받을 수 있도록 제어할 수 있다. 상기 영상는 실시간으로 입력되 는 동영상 또는 녹화되어 재생되는 동영상일 수 있다. 상기 제어부는, 도 3의 (3-2)에 도시된 바와 같이, 상기 인공지능 모델을 이용한 인공지능 추론을 통해 상 기 영상 내의 적어도 하나의 객체 블랍(1011 내지 1017)을 감지할 수 있다[S22]. 이를 위한 인공지능 모델로서 다크넷(Darknet) 기반의 YOLO v2 내지 v7 등이 사용될 수 있으나, 이에 한정되는 것은 아니다. 블랍(Blob: Binary Large Object)는, 어떤 이미지 내에서 같은 성질을 가지는 픽셀들의 집합을 의미한다. 상기 객체 블랍은, 상기 영상 내에 사람 및/또는 사물(예를 들면 자동차)와 같은 객체가 존재할 것으로 추론되는 영역에 해당하는 픽셀 집합을 의미하는 것으로서, 사전 설정된 형상으로 감지될 수 있다. 도 3에서는 상기 객체 블랍이사각형 형상으로 감지되는 것으로 예시되어 있으나, 다른 형상(예를 들면 원형 또는 다각형)으로 감지될 수도 있음은 물론이다. 상기 객체 블랍은 객체 영역의 일종으로 이해될 수 있다. 상기 제어부는 상기 인공지능 추론을 통해 상기 적어도 하나의 객체 블랍(1011 내지 1017)을 그 대상 (또 는 타입) 기준으로 필터링 및 소팅할 수 있다[S23]. 즉, 상기 제어부는 상기 적어도 하나의 객체 블랍 (1011 내지 1017)이 사물에 관한 것인지 또는 사람에 관한 것인지를 기준으로 상기 적어도 하나의 객체 블랍 (1011 내지 1017)을 소팅(또는 분류)할 수 있다. 이 때, 상기 적어도 하나의 객체 블랍(1011 내지 1017) 중에서 그 크기가 너무 작거나 큰 것은 필터링되어 무시될 수 있다. 도 3의 (3-2)에서는 제 1 블랍 및 제 2 블랍는 사람에 관한 것으로 추론되는 사람 블랍이고, 제 3 블랍 내지 제 7 블랍(1013 내지 1017)은 사물(예를 들면 자동차)에 관한 것으로 추론되는 사물 블랍인 것이 예 시되어 있다. 그 다음, 도 3의 (3-3) 및 (3-4)에 도시된 바와 같이, 상기 제어부는 각 대상에 따른 객체 피처(feature) 영상을 설정할 수 있다. 상기 피처 영상은 상기 객체 블랍의 내부 및 외부를 구분하기 위해 내부와 외부를 서로 다른 단색으로 채워 넣은 영상(또는 내부와 외부에 서로 다른 데이터 값을 갖는 영상)을 의미한다. 도 3에서는 상기 객체 블랍의 내부에는 화이트로 채워지고 상기 객체 블랍의 외부에는 블랙으로 채워진 것이 예시되어 있다. 도 3의 (3-3)은 사람 피처 영상을 나타내고, 도 3의 (3-4)는 사물 피처 영상을 나타낸다. 먼저 상기 객체 블랍의 대상이 사람인 경우에 대해 먼저 살펴보겠다. 상기 제어부는 상기 사람 피처 영상에 상기 검출된 사람 블랍(예를 들면, 제 1 블랍 및 제 2 블랍)을 소정 시간 동안 (또는 소정 개수의 프레임에 걸쳐) 누적적으로 표시할 수 있다[S24]. 즉, 상기 사람 피처 영상에 상기 검출된 사람 블랍(예를 들면, 제 1 블랍 및 제 2 블랍)이 소정 시간 동안 또는 소정 개수의 프레임에 걸쳐 누적될 수 있다. 상기 소정 시간은 각 사람 블랍이 검출된 시점부터 카운 트될 수 있다. 즉, 상기 소정 시간의 시작 시점과 종료 시점은 사람 블랍 마다 다를 수 있다. 각 검출된 사람 블랍이 상기 소정 시간 동안 상기 사람 피처 영상 내에 누적적으로 표시됨에 있어서, 시간이 흐름에 따라 상기 사람 블랍 내의 화이트의 밝기가 점점 어두워져서 상기 소정 시간의 경과된 시점 이후에는 블랙으로 표시 됨으로서 상기 사람 블랍이 사라질 수 있다. 즉, 상기 화이트 밝기는 해당 블랍의 레벨을 의미할 수 있다. 상기 레벨은 향후 상기 관심 영역 설정에 있어 상기 해당 블랍의 기여도를 의미할 수 있다. 상기 제어부는 상기 사람 피처 영상에서 상기 소정 시간 동안 누적적으로 표시된 상기 사람 블랍을 사람 관심 영역으로 정의할 수 있다[S25]. 상기 제어부는 상기 영상에서 상기 사람 관심 영역을 기준으로 사람 관련 이벤트 발생 여부를 감지 할 수 있다[S26]. 그 다음, 상기 객체 블랍의 대상이 사물인 경우에 대해 먼저 살펴보겠다. 상기 제어부는 상기 사물 피처 영상에 상기 검출된 사물 블랍 (예를 들면, 제 3 블랍 내지 제 7 블 랍(1013 내지 1017))을 소정 시간 동안 (또는 소정 개수의 프레임에 걸쳐) 누적적으로 표시할 수 있다[S27]. 상 기 사물 피처 영상에 상기 검출된 사물 블랍 (예를 들면, 제 3 블랍 내지 제 7 블랍(1013 내지 1017))이 소정 시간 동안 (또는 소정 개수의 프레임에 걸쳐) 누적될 수 있다. 상기 소정 시간은 각 사물 블랍이 검출된 시점부터 카운트될 수 있다. 즉, 상기 소정 시간의 시작 시점과 종료 시점은 사물 블랍 마다 다를 수 있다. 각 검출된 사물 블랍이 상기 소정 시간 동안 상기 사물 피처 영상 내에 누적적으로 표시됨에 있어서, 시간이 흐름에 따라 상기 사물 블랍 내의 화이트의 밝기가 점점 어두워져서 상기 소정 시간의 경과된 시점 이후에는 블 랙으로 표시됨으로서 상기 사물 블랍이 사라질 수 있다. 즉, 상기 화이트 밝기는 해당 블랍의 레벨을 의미할 수 있다. 상기 레벨은 향후 상기 관심 영역 설정에 있어 상기 해당 블랍의 기여도를 의미할 수 있다. 상기 제어부는 상기 사물 피처 영상에서 상기 소정 시간 동작 누적적으로 표시된 상기 사물 블랍을 사물 관심 영역으로 정의할 수 있다[S28]. 상기 제어부는 상기 영상에서 상기 사물 관심 영역을 기준으로 사물 관련 이벤트 발생 여부를 감지 할 수 있다[S29]. 상기 S24 내지 상기 S29 단계에 대해서는 나중에 다시 설명된다. 이상에서는 상기 영상 내의 적어도 하나의 객체 블랍을 감지함으로써 관심 영역이 설정되는 것에 대해 설 명되었다. 이하에서는, 도 4 및 도 5를 참조하여, 상기 영상 내의 적어도 하나의 객체 실루엣을 감지함으 로써 관심 영역이 설정되는 것에 대해 설명하겠다. 도 4는 본 발명의 일실시예에 따른 관심 영역 자동 설정에 대한 순서도이고, 도 5은 도 4의 관심 영역 자동 설 정 방법에 따라 프로세싱되는 영상을 도시한다. 상기 영상 분석 장치의 상기 제어부는 상기 카메라를 통해 도 5의 (5-1)에 도시된 바와 같은 영 상 분석을 위한 영상을 입력 받을 수 있도록 제어할 수 있다[S41]. 또는, 상기 제어부는 상기 무선 통신부 또는 상기 인터페이스부를 통해 도 5의 (5-1)에 도시된 바와 같은 영상 분석을 위한 영상 을 외부 기기(미도시)로부터 입력 받을 수 있도록 제어할 수 있다. 상기 영상는 실시간으로 입력되 는 동영상 또는 녹화되어 재생되는 동영상일 수 있다. 상기 제어부는, 도 5의 (5-2)에 도시된 바와 같이, 상기 인공지능 모델을 이용한 인공지능 추론을 통해 상 기 영상 내의 적어도 하나의 객체 실루엣(1021 내지 1027)을 영상 분할 방식으로 감지할 수 있다[S42]. 이를 위 해 딥러닝 기반의 인공지능 모델이 사용될 수 있으나, 이에 한정되는 것은 아니다. 상기 객체 실루엣은, 상기 영상 내의 사람 및/또는 사물(예를 들면 자동차)와 같은 객체의 실루엣을 의미하는 것일 수 있다. 상기 객체 실 루엣은 상기 객체 블랍과 마찬가지로 상기 객체 영역의 일종으로 이해될 수 있다. 상기 제어부는 상기 인공지능 추론을 통해 상기 적어도 하나의 객체 실루엣(1021 내지 1027)을 그 대상 기 준으로 필터링 및 소팅할 수 있다[S43]. 즉, 상기 제어부는 상기 적어도 하나의 객체 실루엣(1021 내지 1027)이 사물에 관한 것인지 또는 사람에 관한 것인지를 기준으로 상기 적어도 하나의 객체 실루엣(1021 내지 1027)을 소팅할 수 있다. 이 때, 상기 적어도 하나의 객체 실루엣(1021 내지 1027) 중에서 그 크기가 너무 작거 나 큰 것은 무시될 수 있다. 도 5의 (5-2)에서는 제 1 객체 실루엣 및 제 2 객체 실루엣는 사람에 관한 것으로 추론되고, 제 3 객체 실루엣 내지 제 7 객체 실루엣(1023 내지 1027)은 사물(예를 들면 자동차)에 관한 것으로 추론되는 것이 예시되어 있다. 그 다음, 도 5의 (5-3) 및 (5-4)에 도시된 바와 같이, 상기 제어부는 각 대상에 따른 피처(feature) 영상 을 설정할 수 (또는 생성할 수) 있다. 상기 피처 영상은 상기 객체 실루엣의 내부 및 외부를 구분하기 위해 내 부와 외부를 서로 다른 단색으로 채워 넣은 영상을 의미한다. 도 5에서는 상기 객체 실루엣의 내부 영역에는 화 이트로 채워지고 상기 객체 실루엣의 외부 영역에는 블랙으로 채워진 것이 예시되어 있다. 도 5의 (5-3)은 사람 피처 영상을 나타내고, 도 5의 (5-4)는 사물 피처 영상을 나타낸다. 먼저 상기 객체 실루엣의 대상이 사람인 경우에 대해 먼저 살펴보겠다. 상기 제어부는 상기 사람 피처 영상에 각 검출된 사람 실루엣(예를 들면, 제 1 실루엣 및 제 2 실루엣)을 소정 시간 동안 (또는 소정 개수의 프레임에 걸쳐) 누적적으로 표시할 수 있다[S44]. 즉, 상 기 사람 피처 영상에 각 검출된 사람 실루엣(예를 들면, 제 1 실루엣 및 제 2 실루엣)이 소 정 시간 동안 (또는 소정 개수의 프레임에 걸쳐) 누적될 수 있다. 상기 소정 시간은 각 사람 실루엣이 검출된 시점부터 카운트될 수 있다. 즉, 상기 소정 시간의 시작 시점과 종료 시점은 사람 실루엣마다 다를 수 있다. 상 기 검출된 사람 실루엣이 상기 소정 시간 동안 상기 사람 피처 영상 내에 누적적으로 표시됨에 있어서, 시간이 흐름에 따라 상기 사람 실루엣 내의 화이트의 밝기가 점점 어두워져서 상기 소정 시간의 경과된 시점 이 후에는 블랙으로 표시됨으로써 상기 사람 실루엣이 사라질 수 있다. 즉, 상기 화이트 밝기는 해당 실루엤의 레 벨을 의미할 수 있다. 상기 레벨은 향후 상기 관심 영역 설정에 있어 상기 해당 실루엣의 기여도를 의미할 수 있다. 상기 제어부는 상기 사람 피처 영상에서 상기 소정 시간 동안 누적적으로 표시된 상기 사람 실루엣 을 사람 관심 영역으로 정의할 수 있다[S45]. 상기 제어부는 상기 영상에서 상기 사람 관심 영역을 기준으로 사람 관련 이벤트 발생 여부를 감지 할 수 있다[S46]. 그 다음, 상기 객체 실루엣의 대상이 사물인 경우에 대해 먼저 살펴보겠다. 상기 제어부는 상기 사물 피처 영상에 각 검출된 사물 실루엣 (예를 들면, 제 3 실루엣 내지 제 7 실루엣(1023 내지 1027))을 소정 시간 동안 (또는 소정 개수의 프레임에 걸쳐) 누적적으로 표시할 수 있다 [S47]. 상기 사물 피처 영상에 각 검출된 사물 실루엣 (예를 들면, 제 3 실루엣 내지 제 7 실루엣(1023내지 1027))이 소정 시간 동안 (또는 소정 개수의 프레임에 걸쳐) 누적될 수 있다. 상기 소정 시간은 각 사물 실루엣이 검출된 시점부터 카운트될 수 있다. 즉, 상기 소정 시간의 시작 시점과 종료 시점은 사물 실루엣마다 다를 수 있다. 상기 검출된 사물 실루엣이 상기 소정 시간 동안 상기 사물 피처 영상 내에 누적적으로 표시됨에 있어서, 시간이 흐름에 따라 상기 사물 실루엣 내의 화이트의 밝기가 점점 어두워져서 상기 소정 시간 의 경과된 시점 이후에는 블랙으로 표시됨으로써 상기 사물 실루엣이 사라질 수 있다. 즉, 상기 화이트 밝기는 해당 실루엣의 레벨을 의미할 수 있다. 상기 레벨은 향후 상기 관심 영역 설정에 있어 상기 해당 실루엣의 기여 도를 의미할 수 있다. 상기 제어부는 상기 사물 피처 영상에서 상기 소정 시간 동작 누적적으로 표시된 상기 사물 실루엣 을 사물 관심 영역으로 정의할 수 있다[S48]. 상기 제어부는 상기 영상에서 상기 사물 관심 영역을 기준으로 사물 관련 이벤트 발생 여부를 감지 할 수 있다[S49]. 상기 S44 내지 상기 S49 단계에 대해서는 나중에 다시 설명된다. 이상에서는 인공지능 모델을 통해 관심 영역이 설정되는 것에 대해 설명되었다. 이하에서는 도 6 및 도 7을 참 조하여 인공지능 모델을 이용함 없이 상기 영상 내에서 관심 영역이 설정되는 것에 대해 설명하겠다. 도 6는 본 발명의 일실시예에 따른 관심 영역 자동 설정에 대한 순서도이고, 도 7은 도 6의 관심 영역 자동 설 정 방법에 따라 프로세싱되는 영상을 도시한다. 상기 영상 분석 장치의 상기 제어부는 상기 카메라를 통해 도 7의 (7-1)에 도시된 바와 같은 영 상 분석을 위한 영상을 입력 받을 수 있도록 제어할 수 있다[S61]. 또는, 상기 제어부는 상기 무선 통신부 또는 상기 인터페이스부를 통해 도 6의 (6-1)에 도시된 바와 같은 영상 분석을 위한 영상 을 외부 기기(미도시)로부터 입력 받을 수 있도록 제어할 수 있다. 상기 영상는 실시간으로 입력되 는 동영상 또는 녹화되어 재생되는 동영상일 수 있다. 상기 제어부는 상기 영상을 일정 시간만큼에 해당하는 프레임을 누적한 뒤 평균을 내는 방식 또는 가우시안 믹스체 모델을 이용하여 도 7의 (7-2)에 도시된 바와 같은 상기 영상의 배경 모델을 설정할 수 (또는 생성할 수) 있다[S62]. 상기 제어부는 상기 설정된 배경 모델을 상기 영상과 비교할 수 있다[S63]. 상기 제어부는 상기 영상에서 상기 배경 모델와의 차이가 일정 값 미만인 부분을 배경 (background) 피처 영상으로 감지할 수 있다[S64]. 상기 배경 피처 영상은 상기 배경 모델 설정 단계(S62)로 피 드백되어 상기 배경 모델 설정에 활용될 수 있다. 한편, 상기 제어부는 상기 영상에서 상기 배경 모델와의 차이가 일정 값 이상인 부분을, 도 7 의 (7-3)에 도시된 바와 같은 전경(foreground) 피처 영상으로 감지할 수 있다[S65]. 상기 전경 피처 영 상에서 상기 배경 모델과 차이가 나는 영역(1031, 1032) (즉, 상기 영상 내에서 객체의 움직 임이 감지되는 영역(1031, 1032))이 예컨대 화이트로 표시될 수 있다. 상기 움직임이 감지되는 영역, 즉 움직임 영역은 상기 객체 블랍 및 상기 객체 실루엣과 마찬가지로 상기 객체 영역의 일종으로 이해될 수 있다. 상기 움 직임 영역의 형상은 상기 객체 블랍보다는 상기 객체 실루엣에 좀더 유사할 수 있다. 상기 제어부는 상기 전경 피처 영상에 상기 검출된 움직임 영역을 소정 시간 동안 (또는 소정 개수 의 프레임에 걸쳐) 누적적으로 표시할 수 있다[S66]. 상기 전경 피처 영상에 상기 검출된 움직임 영역이 소정 시간 동안 (또는 소정 개수의 프레임에 걸쳐) 누적될 수 있다. 상기 소정 시간은 각 움직임 영역이 검출된 시점부터 카운트될 수 있다. 즉, 상기 소정 시간의 시작 시점과 종료 시점은 움직임 영역마다 다를 수 있다. 각 검출된 움직임 영역이 상기 소정 시간 동안 상기 전경 피처 영상 내에 누적적으로 표시됨에 있어서, 시간이 흐름에 따라 상기 움직임 영역 내의 화이트의 밝기가 점점 어두워져서 상기 소정 시간의 경과된 시점 이 후에는 블랙으로 표시됨으로서 상기 움직임 영역이 사라질 수 있다. 즉, 상기 화이트 밝기는 해당 움직임의 레 벨을 의미할 수 있다. 상기 레벨은 향후 상기 관심 영역 설정에 있어 상기 해당 움직임의 기여도를 의미할 수 있다. 상기 제어부는 상기 전경 피처 영상 내에서 상기 소정 시간 동안 누적적으로 표시된 상기 움직임 영 역을 관심 영역으로 정의할 수 있다[S67]. 상기 제어부는 상기 영상에서 상기 관심 영역을 기준으로 객체 이벤트 발생 여부를 감지할 수 있다 [S68]. 도 6의 관심 영역 자동 설정에 따르면, 도 2 및 도 4의 관심 영역 자송 설정과는 달리 객체 별(즉, 사람 별, 사 물 별) 관심 영역 설정은 할 수 없다. 다만, 상기 전영 피처 영상에 대해 MLP(Multilayer Perceptron) 방식의 인공지능 추론이 추가로 행해지거나, AdaBoost, Hog와 같은 특징 추출 알고리즘의 컴퓨터 비전 분석이 추가로 행해짐으로써 객체를 구분한다면 객체 별 관심 영역 설정이 가능할 수 있다. 상기 S66 내지 상기 S68 단계에 대해서는 나중에 다시 설명된다. 이하, 도 3, 도 5, 및 도 7에서 설명된 각 피처 영상(1100, 1200, 1300, 1400, 1600)에서 해당 객체 영역(1011 내지 1017, 1021 내지 1027, 1031, 1032)이 누적적으로 표시되는 것에 대해 도 8을 더욱 참조하여 설명하겠다. 도 8은 본 발명의 일실시예에 따라 피처 영상에서 객체 영역이 누적되는 프로세싱을 예시한다. 먼저, 도 8의 (8-1)에 도시된 바와 같이, 각 피처 영상에서 해당 객체 영역이 누적적으로 표시됨에 있어서 링 버퍼가 사용될 수 있다. 즉, 상기 제어부는 상기 피처 영상의 현재 프레임 및 소정 개수의 과거 프레임들 을 상기 링 버퍼에 시간 순서에 따라 입력하고, 해당 객체 영역의 화이트 부분의 픽셀 밝기(또는 레벨)를 누적 하고 상기 링 버퍼의 인덱스 번호로 나누어 평균 피처 영상을 설정할 수(또는 생성할 수) 있다[S24, S27, S44, S47, S66]. 상기 화이트 부분의 픽셀 밝기에는 가중치가 부여될 수 있다. 즉, 현재 프레임에는 최대 가중치가 부여되고, 과거 프레임일수록 낮은 가중치가 부여될 수 있다. 따라서, 최근 프레임일수록 해당 객체 영역 내의 화이트의 밝기가 밝아지고 과거 프레임일수록 해당 객체 영역 내의 화이트의 밝기가 어두어지고 (즉, 그레이로 되고), 상기 소정 개수 이상의 과거 프레임의 경우에는 해당 객체 영역 내가 블랙으로 표시됨으로써 상기 피처 영상 내에서 해당 객체 영역이 사라질 수 있다. 이로써, 상기 평균 피처 영상에 현재 프레임이 가장 큰 영향을 미치고 과거 프레임일수록 낮은 영향을 미치도록 할 수 있다. 한편, 피처 영상에서 해당 객체 영역이 누적적으로 표시됨에 있어서, 상기 링 버퍼 대신에 도 8의 (8-2)에 도시 된 바와 같은 실루엣 히스토리 이미지 수식이 사용될 수 있다. H는 실루엣 히스토리 이미지, f는 객체/전경 이 미지(흰색 픽셀), x 및 y는 영상의 가로 및 세로 좌표, t는 시간을 나타낸다. 상기 실루엣 히스토리 이미지는 1 채널로 0~255의 픽셀 값을 가지며 과거의 움직임일수록 0에 가까운 픽셀 값 (어두운 색상 또는 낮은 레벨)가지 고 최근의 움직임은 255에 가까운 픽셀 값 (밝은 색상 또는 높은 레벨)을 가진다. 이렇게 생성된 단계적 차이 (Gradation)는 이벤트 판단 시 가중치로서 활용 가능하다. 왜냐하면 레벨이 높을수록 이벤트 발생 확률이 높고 레벨이 낮을수록 이벤트가 발생할 확률이 줄어들기 때문이다. 상기 제어부는 상기 피처 영상의 현재 프레임 및 소정 시간 이내의 과거 프레임들을 상기 실루엣 히스토리 이미지 수식에 입력함으로써, 상기 현재 프레임 및 상기 과거 프레임들이 누적되도록 할 수 있다[S24, S27, S44, S47, S66]. 이 때, 상기 화이트 부분의 픽셀 밝기에 가중치가 부여될 수 있다. 즉, 현재 프레임에는 최대 가중치가 부여되고, 과거 프레임일수록 낮은 가중치가 부여될 수 있다. 따라서, 최근 프레임일수록 해당 객체 영역 내의 화이트의 밝기가 밝아지고 과거 프레임일수록 해당 객체 영역 내의 화이트의 밝기가 어두어지고, 상 기 소정 시간이 경과한 과거 프레임의 경우에는 해당 객체 영역 내가 블랙으로 표시됨으로써 상기 피처 영상 내 에서 해당 객체 영역이 사라질 수 있다. 이로써, 상기 누적된 피처 영상에 현재 프레임이 가장 큰 영향을 미치 고 과거 프레임일수록 낮은 영향을 미치도록 할 수 있다. 위와 같은 방법으로 설정된 관심 영역이 사용되는 이유는, 각 객체에서 발생하는 이벤트는 객체가 최근 움직였 던 영역 내에서만 발생할 확률이 높기 때문이다. 예를 들어 사람의 쓰러짐 이벤트의 경우, 사람에 의해 발생하 는 것으로 인공지능 또는 전경 검출 결과를 활용하여 최근 사람의 움직임 영역을 알람 발생이 가능한 관심 영역 으로 자동 설정하는 것이 가능하다. 기존 지능형 영상분석에서는 영상 내에서 알람이 발생할 수 있는 영역을 사 람이 수동으로 지정해야 하며 카메라가 틀어져 감시영역이 변경되는 경우 관심 영역을 재설정해야 하는 번거로 움이 있다. 또한 수동으로 관심 영역을 지정할 때는 감지 가능한 모든 공간을 영역으로 지정하기 때문에 조명의 변화, 그림자, 노이즈 등에 의해 오보가 발생하기도 한다. 본 발명에서는 객체가 최근 움직인 영역만을 궤적 (trajectory)로 만들어 관심 영역으로 사용함으로써 자동으로 관심 영역을 설정하여 사람의 노동을 줄이고 관련 객체가 움직인 영역에서만 알람 발생이 가능하도록 관심 영역을 설정함으로써 그림자 및 조명변화, 노이즈 등에 의한 오보를 막을 수 있다. 즉, 본 발명은 사람이 수동으로 설정하여 항상 고정되어 있는 관심 영역 아닌 최근 N초 또는 N프레임동안 객체 가 등장했던 영역만을 관심 영역으로 설정한다. 검출 객체와 관련된 이벤트는 그 객체가 최근 움직였던 영역에서만 이벤트가 발생하므로 객체 별로 관심 영역을 상시 업데이트할 수 있다. 따라서 본 발명에서 제안하는 관심 영역이 사용되는 경우 객체가 등장하지 않은 영역은 이벤트 감지 영역에서 제외되므로 오탐지를 줄일 수 있다 이하, 각 피처 영상(1100, 1200, 1300, 1400, 1600)에서 누적적으로 표시되는 해당 객체 영역(1011 내지 1017, 1021 내지 1027, 1031, 1032)에 기반하여 관심 영역이 설정되어 상기 설정된 관심 영역 내에서 객체 관련 이벤 트가 감지될 수 있도록 하는 것에 대해 도 9을 더욱 참조하여 설명하겠다. 도 9은 본 발명의 일실시예에 따라 피처 영상에서 설정되는 관심 영역의 예시를 도시한다. 도 9에서 상기 객체 영역은 객체 블랍인 것으로 가정하 겠다. 상기 영상 분석 장치는 영상 분석을 위한 동영상을 입력 받을 수 있다. 도 9에서는 상기 동영상 의 시간대 별로 영상 프레임(2000-1 내지 2000-4)이 예시되어 있다. 즉, 제 1 시점(t1)에서의 제 1 영상 프레임(2000-1), 제 2 시점(t2)에서의 제 2 영상 프레임(2000-2), 제 3 시점(t3)에서의 제 3 영상 프레임 (2000-3), 제 4 시점(t4)에서의 제 4 영상 프레임(2000-4)이 예시되어 있다. 그리고, 상기 각 영상 프레임 내 에는 시간이 흐름에 따라 하나의 동일한 객체(2011-1 내지 2011-4)가 움직이고 있는 것이 예시되어 있다. 상기 제어부는 상기 동영상으로부터 앞서 설명된 바와 같이 객체 피처 영상을 설정할 수 있다. 도 9에서는 상기 동영상의 시간대 별로 객체 피처 영상 프레임(2100-1 내지 2100-4)이 예시되어 있 다. 즉, 제 1 시점(t1)에서의 제 1 객체 피처 영상 프레임(2100-1), 제 2 시점(t2)에서의 제 2 객체 피처 영상 프레임(2100-2), 제 3 시점(t3)에서의 제 3 객체 피처 영상 프레임(2100-3), 제 4 시점(t4)에서의 제 4 객체 피처 영상 프레임(2100-4)이 예시되어 있다. 그리고, 상기 각 객체 피처 영상 프레임 내에는 시간이 흐름에 따 라 상기 움직이는 객체(2011-1 내지 2011-4)에 대응되도록 객체 블랍(2021-1 내지 2021-4)이 이동하고 있는 것 이 예시되어 있다. 상기 제어부는 상기 객체 블랍(2021-1 내지 2021-4)를 누적하거나 또는 객체 피처 영상 프레임들을 누적하 여 관심 영역을 정의할 수 있다. 도 9에서는 각 피처 영상 프레임에 이전 시간의 과거 피처 영상 프레임 또는 그 안의 객체 블랍이 누적됨으로써 형성되는 객체 블랍 누적 영역(2031-1, 2031-2, 2031-3, 2031-4)이 상기 관 심 영역으로 정의되는 것이 예시되어 있다. 상기 객체 블랍 누적 영역(2031-1, 2031-2, 2031-3, 2031-4) 전체가 상기 관심 영역으로 정의될 수 있고, 상기 객체 블랍 누적 영역(2031-1, 2031-2, 2031-3, 2031-4) 중 일정 누적 밝기 이상(즉, 일정 누적 레벨 이상)의 영역만이 상기 관심 영역으로 정의될 수 있다. 상기 제어부는 상기 관심 영역 내에서 객체 관련 이벤트 발생 여부를 감지할 수 있다. 이 때 상기 제어부 는 상기 관심 영역 내의 각 부분의 레벨에 비례하여 각 부분에 대한 이벤트 감지 민감도가 높아지도록 제 어할 수도 있다. 이하, 각 피처 영상(1100, 1200, 1300, 1400, 1600)에서 누적적으로 표시되는 해당 객체 영역(1011 내지 1017, 1021 내지 1027, 1031, 1032)에 기반하여 관심 영역이 설정되어 상기 설정된 관심 영역 내에서 객체 관련 이벤 트가 감지될 수 있도록 하는 것에 대해 도 10를 더욱 참조하여 설명하겠다. 도 10는 본 발명의 일실시예에 따라 피처 영상에서 설정되는 관심 영역의 예시를 도시한다. 도 10에서 상기 객체 영역은 객체 실루엣 또는 움직임 영역인 것으로 가정하겠다. 상기 영상 분석 장치는 영상 분석을 위한 동영상을 입력 받을 수 있다. 도 10에서는 상기 동영상 의 시간대 별로 영상 프레임(2000-1 내지 2000-4)이 예시되어 있다. 즉, 제 1 시점(t1)에서의 제 1 영상 프레임(2000-1), 제 2 시점(t2)에서의 제 2 영상 프레임(2000-2), 제 3 시점(t3)에서의 제 3 영상 프레임 (2000-3), 제 4 시점(t4)에서의 제 4 영상 프레임(2000-4)이 예시되어 있다. 그리고, 상기 각 영상 프레임 내 에는 시간이 흐름에 따라 하나의 동일한 객체(2011-1 내지 2011-4)가 움직이고 있는 것이 예시되어 있다. 상기 제어부는 상기 동영상으로부터 앞서 설명된 바와 같이 객체 피처 영상을 설정할 수 있다. 도 10에서는 상기 동영상의 시간대 별로 객체 피처 영상 프레임(2300-1 내지 2300-4)이 예시되어 있다. 즉, 제 1 시점(t1)에서의 제 1 객체 피처 영상 프레임(2300-1), 제 2 시점(t2)에서의 제 2 객체 피처 영 상 프레임(2300-2), 제 3 시점(t3)에서의 제 3 객체 피처 영상 프레임(2300-3), 제 4 시점(t4)에서의 제 4 객 체 피처 영상 프레임(2300-4)이 예시되어 있다. 그리고, 상기 각 객체 피처 영상 프레임 내에는 시간이 흐름에 따라 상기 움직이는 객체(2011-1 내지 2011-4)에 대응되도록 객체 영역(2041-1 내지 2041-4)이 이동하고 있는 것이 예시되어 있다. 상기 제어부는 상기 객체 영역(2041-1 내지 2041-4)를 누적하거나 또는 객체 피처 영상 프레임들을 누적하 여 관심 영역을 정의할 수 있다. 도 10에서는 각 피처 영상 프레임에 이전 시간의 과거 피처 영상 프레임 또는 그 안의 객체 영역이 누적됨으로써 형성되는 객체 누적 영역(2051-1, 2051-2, 2051-3, 2051-4)이 상기 관심 영 역으로 정의되는 것이 예시되어 있다. 상기 객체 누적 영역(2051-1, 2051-2, 2051-3, 2051-4) 전체가 상기 관심 영역으로 정의될 수 있고, 상기 객체 누적 영역(2051-1, 2051-2, 2051-3, 2051-4) 중 일정 누적 밝기 이상(즉, 일정 누적 레벨 이상)의 영역만이 상 기 관심 영역으로 정의될 수 있다. 상기 제어부는 상기 관심 영역 내에서 객체 관련 이벤트 발생 여부를 감지할 수 있다. 이 때 상기 제어부 는 상기 관심 영역 내의 각 부분의 레벨에 비례하여 각 부분에 대한 이벤트 감지 민감도가 높아지도록 제 어할 수도 있다. 이상에서 설명된 바와 같이, 인공지능 기반의 객체 감지를 위한 의 블랍 정보나 인스턴스 세그멘테이션 (Instance Segmentation) 결과인 실루엣을 활용할 수도 있으며 이 외에 컴퓨터 비전 인식을 기반으로 하는 배경 모델을 통한 전경 검출 결과 및/또는 프레임 디퍼런스(frame difference)를 이용한 움직임 검출 결과 등을 이용 하여 본 발명이 구현될 수 있다. 본 발명에서는 각각의 방법으로 검출된 결과를 활용하여 N초/N프레임 이상 객체 별로 결과를 누적하여 궤적 (Trajectory) 영상을 설정할 수 (또는 생성할 수) 있다. 궤적 설정을 위해 영상을 일정 시간동안 누적 평균 내 는 방법 또는 실루엣 히스토리 이미지를 설정(또는 생성)하는 방법이 적용될 수 있다. 설정된 결과는 이벤트를 판단하기 전에 이벤트에 해당하는 객체 좌표 우 하단이나 중심점이 궤적 영역 내에 포함되면 최종 이벤트로서 발보할 수 있다. 본 발명을 적용하면 객체 별로 다른 객체 영역을 설정(또는 생성)할 수 있다. 객체의 등장 빈도와 움직임에 따 라 관심 영역이 지속적으로 업데이트되는데 이러한 특징으로 감지가 필요한 영역만을 관심 영역으로 지정할 수 있고 객체 별로 각기 다른 관심 영역을 설정(또는 생성)함으로써 오탐을 줄이고 정확도를 향상시킬 수 있다. 차 도에서 사람과 관련된 이벤트(침입/배회/쓰러짐/달리기 등) 오탐이 발생하지 않을 수 있으며 만약 차도에 사람 이 등장했다고 하더라도 사람이 등장했던 영역에서만 사람과 관련된 이벤트 발보가 가능하다. 전술한 본 발명은, 프로그램이 기록된 매체에 컴퓨터가 읽을 수 있는 코드로서 구현하는 것이 가능하다. 컴퓨터 가 읽을 수 있는 매체는, 컴퓨터 시스템에 의하여 읽혀질 수 있는 데이터가 저장되는 모든 종류의 기록장치를 포함한다. 컴퓨터가 읽을 수 있는 매체의 예로는, HDD(Hard Disk Drive), SSD(Solid State Disk), SDD(Silicon Disk Drive), ROM, RAM, CD-ROM, 자기 테이프, 플로피 디스크, 광 데이터 저장 장치 등이 있으며, 또한 캐리어 웨이브(예를 들어, 인터넷을 통한 전송)의 형태로 구현되는 것도 포함한다. 또한, 상기 컴퓨터는 이미지 디스플 레이 장치의 제어부 및 원격제어장치의 제어부를 포함할 수도 있다. 따라서, 상기의 상세한 설명은 모든 면에서 제한적으로 해석되어서는 아니되고 예시적인 것으로 고려되어야 한다. 본 발명의 범위는 첨부된 청 구항의 합리적 해석에 의해 결정되어야 하고, 본 발명의 등가적 범위 내에서의 모든 변경은 본 발명의 범위에 포함된다."}
{"patent_id": "10-2023-0001863", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일실시예에 따른 영상 분석 장치의 개략적 블록도이다. 도 2는 본 발명의 일실시예에 따른 관심 영역 자동 설정에 대한 순서도이다. 도 3은 도 2의 관심 영역 자동 설정 방법에 따라 프로세싱되는 영상을 도시한다. 도 4는 본 발명의 일실시예에 따른 관심 영역 자동 설정에 대한 순서도이다. 도 5은 도 4의 관심 영역 자동 설정 방법에 따라 프로세싱되는 영상을 도시한다. 도 6는 본 발명의 일실시예에 따른 관심 영역 자동 설정에 대한 순서도이다. 도 7은 도 6의 관심 영역 자동 설정 방법에 따라 프로세싱되는 영상을 도시한다. 도 8은 본 발명의 일실시예에 따라 피처 영상에서 객체 영역이 누적되는 프로세싱을 예시한다. 도 9 및 도 10은 본 발명의 일실시예에 따라 피처 영상에서 설정되는 관심 영역의 예시를 도시한다."}
