{"patent_id": "10-2023-0107223", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2025-0024435", "출원번호": "10-2023-0107223", "발명의 명칭": "목적물의 이상 여부를 탐지하기 위한 서버, 방법, 및 시스템", "출원인": "삼성전자주식회사", "발명자": "이재길"}}
{"patent_id": "10-2023-0107223", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "목적물의 이상 여부를 탐지하기 위한 방법에 있어서,상기 목적물의 특성들에 대응되는 다차원의 벡터를 포함하는 원본 데이터(original data)를 수신하는 단계;인코더 신경망 및 디코더 신경망을 포함하는 복수의 인공지능 생성 모델들 중에서 상기 원본 데이터에 호환 가능한(compatible with) 적어도 하나의 인공지능 생성 모델을 이용하여, 상기 원본 데이터와 상기 원본 데이터의복원 데이터(reconstruction data) 간의 복원 정도에 대응하는 이상치 점수(anomaly score)를 연산하는 단계;및상기 이상치 점수와 기준 점수를 기초로, 상기 목적물의 이상 여부를 나타내는 탐지 결과 데이터를 출력하는 단계를 포함하는, 방법."}
{"patent_id": "10-2023-0107223", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1 항에 있어서,상기 이상치 점수를 연산하는 단계는,상기 원본 데이터를 상기 적어도 하나의 인공지능 생성 모델의 인코더 신경망에 입력하는 단계;상기 적어도 하나의 인공지능 생성 모델의 디코더 신경망을 통해 상기 복원 데이터를 출력하는 단계;상기 복원 데이터와 상기 원본 데이터 간의 차이에 대응되는 상기 이상치 점수를 계산하는 단계; 및상기 이상치 점수를 저장하는 단계를 포함하는 것을 특징으로 하는, 방법."}
{"patent_id": "10-2023-0107223", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1 항에 있어서,상기 이상치 점수를 연산하는 단계는,상기 적어도 하나의 인공지능 생성 모델에 기 학습된 데이터 셋의 적어도 하나의 제1 이상치 점수와, 상기 원본데이터의 제2 이상치 점수를 기초로, 상기 원본 데이터와 상기 적어도 하나의 인공지능 생성 모델 간의 호환성에 대응되는 적어도 하나의 제1 신뢰도를 계산하는 단계; 및상기 적어도 하나의 제1 신뢰도와 제1 기준 값을 기초로, 상기 복수의 인공지능 생성 모델들 중에서 상기 원본데이터에 호환 가능한 인공지능 생성 모델을 적어도 하나 선택하는 단계를 포함하는 것을 특징으로 하는, 방법."}
{"patent_id": "10-2023-0107223", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1 항에 있어서,상기 이상치 점수를 연산하는 단계는,각 인공지능 생성 모델에 기 학습된 데이터 셋의 이상치 점수와 상기 원본 데이터의 이상치 점수를 기초로, 상기 원본 데이터와 상기 각 인공지능 생성 모델 간의 호환성에 대응되는 신뢰도를 계산하는 단계; 및상기 복수의 인공지능 생성 모델들의 복수의 신뢰도들을 기초로, 상기 복수의 인공지능 생성 모델들을 포함하는모델 풀을 업데이트하는 단계를 포함하는 것을 특징으로 하는, 방법."}
{"patent_id": "10-2023-0107223", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1 항에 있어서,상기 이상치 점수를 연산하는 단계는,공개특허 10-2025-0024435-3-상기 원본 데이터를 학습 데이터로 학습한 새로운 인공지능 생성 모델을 생성함으로써, 상기 복수의 인공지능생성 모델들을 포함하는 모델 풀을 업데이트하는 단계;상기 새로운 인공지능 생성 모델 및 상기 복수의 인공지능 생성 모델들 각각으로부터, 상기 인코더 신경망이 입력된 상기 원본 데이터를 이용하여 출력하는 레이턴트 벡터(latent vector)를 획득하는 단계; 및상기 새로운 인공지능 생성 모델의 제1 레이턴트 벡터 및 상기 복수의 인공지능 생성 모델들의 레이턴트 벡터들을 기초로, 상기 새로운 인공지능 생성 모델과 유사한 하나 이상의 인공지능 생성 모델을 상기 새로운 인공지능생성 모델과 병합(merge)하는 단계를 포함하는 것을 특징으로 하는, 방법."}
{"patent_id": "10-2023-0107223", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "인코더 신경망 및 디코더 신경망을 포함하는 복수의 인공지능 생성 모델들에 대한 모델 풀 데이터를 저장하도록구성된 메모리; 및상기 목적물의 특성들에 대응되는 다차원의 벡터를 포함하는 원본 데이터를 수신하도록 구성되고, 상기 복수의인공지능 생성 모델들 중에서 상기 원본 데이터에 호환 가능한 적어도 하나의 인공지능 생성 모델을 이용하여,상기 원본 데이터와 상기 원본 데이터의 복원 데이터 간의 복원 정도에 대응하는 이상치 점수를 계산하도록 구성되고, 상기 이상치 점수와 기준 점수를 기초로, 상기 목적물의 이상 여부를 나타내는 탐지 결과 데이터를 출력하도록 구성된 프로세서를 포함하는, 서버."}
{"patent_id": "10-2023-0107223", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6 항에 있어서,상기 프로세서는,상기 원본 데이터를 상기 적어도 하나의 인공지능 생성 모델의 인코더 신경망에 입력하고,상기 적어도 하나의 인공지능 생성 모델의 디코더 신경망으로부터 출력되는 상기 복원 데이터를 획득하고,상기 복원 데이터와 상기 원본 데이터 간의 차이에 대응되는 상기 이상치 점수를 계산하고,상기 이상치 점수를 상기 메모리에 저장하는 것을 특징으로 하는, 서버."}
{"patent_id": "10-2023-0107223", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제6 항에 있어서,상기 프로세서는,상기 적어도 하나의 인공지능 생성 모델에 기 학습된 데이터 셋의 적어도 하나의 제1 이상치 점수와, 상기 원본데이터의 제2 이상치 점수를 기초로, 상기 원본 데이터와 상기 적어도 하나의 인공지능 생성 모델 간의 호환성에 대응되는 적어도 하나의 제1 신뢰도를 계산하고,상기 적어도 하나의 제1 신뢰도와 제1 기준 값을 기초로, 상기 복수의 인공지능 생성 모델들 중에서 상기 원본데이터에 호환 가능한 인공지능 생성 모델을 적어도 하나 선택하는 것을 특징으로 하는, 서버."}
{"patent_id": "10-2023-0107223", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제6 항에 있어서,상기 프로세서는,각 인공지능 생성 모델에 기 학습된 데이터 셋의 이상치 점수와 상기 원본 데이터의 이상치 점수를 기초로, 상기 원본 데이터와 상기 각 인공지능 생성 모델 간의 호환성에 대응되는 신뢰도를 계산하고,상기 복수의 인공지능 생성 모델들의 복수의 신뢰도들을 기초로, 상기 복수의 인공지능 생성 모델들을 포함하는모델 풀을 업데이트하는 것을 특징으로 하는, 서버."}
{"patent_id": "10-2023-0107223", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "목적물의 특성들에 대응되는 다차원의 벡터를 포함하는 원본 데이터를 생성하도록 구성된 측정 장비; 및공개특허 10-2025-0024435-4-상기 원본 데이터를 수신하도록 구성되고, 복수의 인공지능 생성 모델들 중에서 상기 원본 데이터에 호환 가능한 적어도 하나의 인공지능 생성 모델을 이용하여, 상기 원본 데이터와 상기 원본 데이터의 복원 데이터 간의복원 정도에 대응하는 이상치 점수를 계산하도록 구성되고, 상기 이상치 점수와 기준 점수를 기초로, 상기 목적물의 이상 여부를 나타내는 탐지 결과 데이터를 출력하도록 구성된 서버를 포함하는, 시스템."}
{"patent_id": "10-2023-0107223", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "목적물의 이상 여부를 탐지하기 위한 서버, 방법, 및 시스템이 개시된다. 본 개시의 기술적 사상에 따른 서버는, 메모리, 및 복수의 인공지능 생성 모델들 중에서 원본 데이터에 호환 가능한 적어도 하나의 인공지능 생성 모델 을 이용하여, 원본 데이터와 복원 데이터 간의 복원 정도에 대응하는 이상치 점수를 계산하고, 이상치 점수를 이 용하여 목적물의 이상 여부를 탐지하는 프로세서를 포함한다."}
{"patent_id": "10-2023-0107223", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시의 기술적 사상은 전자 장치에 관한 것이며, 구체적으로는 위한 목적물의 이상 여부를 탐지하기 위한 서 버, 방법, 및 시스템에 관한 것이다."}
{"patent_id": "10-2023-0107223", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "최근 머신 러닝을 이용하여 데이터로부터 목적물의 이상치를 탐지하는 기술이 연구되고 있다. 일 예로, 거리/밀 도 기반의 이상치를 탐지하는 방법(distance/density-based outlier)이 있다. 한편, 데이터의 차원이 증가하면 데이터를 분석하는 것이 어려울 수 있다. 또한, 데이터의 분포가 변화함에 불구하고 강건하게 대응하는 것이 어 려울 수 있다. 따라서, 고차원 데이터의 분포가 변화함에도 불구하고, 분포 변화에 강건하고 데이터에 적합한 탐지 방법을 연구할 필요가 있다."}
{"patent_id": "10-2023-0107223", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 개시의 기술적 사상은, 고차원 데이터의 분포 변화에 강건하고 고차원 데이터에 적합하기 위해, 목적물의 이 상 여부를 탐지하는 서버, 방법, 및 시스템을 제공하는 것이다."}
{"patent_id": "10-2023-0107223", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 개시의 기술적 사상에 따른 방법은, 목적물의 특성들에 대응되는 다차원의 벡터를 포함하는 원본 데이터를 수신하는 단계, 인코더 신경망 및 디코더 신경망을 포함하는 복수의 인공지능 생성 모델들 중에서 원본 데이터 에 호환 가능한 적어도 하나의 인공지능 생성 모델을 이용하여, 원본 데이터와 원본 데이터의 복원 데이터 간의 복원 정도에 대응하는 이상치 점수를 연산하는 단계, 및 이상치 점수와 기준 점수를 기초로, 목적물의 이상 여 부를 나타내는 탐지 결과 데이터를 출력하는 단계를 포함한다. 또한, 본 개시의 기술적 사상에 따른 서버는, 인코더 신경망 및 디코더 신경망을 포함하는 복수의 인공지능 생 성 모델들에 대한 모델 풀 데이터를 저장하도록 구성된 메모리, 및 목적물의 특성들에 대응되는 다차원의 벡터 를 포함하는 원본 데이터를 수신하도록 구성되고, 복수의 인공지능 생성 모델들 중에서 원본 데이터에 호환 가 능한 적어도 하나의 인공지능 생성 모델을 이용하여, 원본 데이터와 원본 데이터의 복원 데이터 간의 복원 정도 에 대응하는 이상치 점수를 계산하도록 구성되고, 이상치 점수와 기준 점수를 기초로, 목적물의 이상 여부를 나 타내는 탐지 결과 데이터를 출력하도록 구성된 프로세서를 포함한다. 또한, 본 개시의 기술적 사상에 따른 시스템은, 목적물의 특성들에 대응되는 다차원의 벡터를 포함하는 원본 데 이터를 생성하도록 구성된 측정 장비, 및 원본 데이터를 수신하도록 구성되고, 복수의 인공지능 생성 모델들 중 에서 원본 데이터에 호환 가능한 적어도 하나의 인공지능 생성 모델을 이용하여, 원본 데이터와 원본 데이터의 복원 데이터 간의 복원 정도에 대응하는 이상치 점수를 계산하도록 구성되고, 이상치 점수와 기준 점수를 기초 로, 목적물의 이상 여부를 나타내는 탐지 결과 데이터를 출력하도록 구성된 서버를 포함한다."}
{"patent_id": "10-2023-0107223", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 개시의 기술적 사상에 의하면, 고차원 데이터의 분포 변화에 강건하고 고차원 데이터에 적합할 수 있는 효과 가 있다. 본 개시의 실시예들에서 얻을 수 있는 효과는 이상에서 언급한 효과들로 제한되지 아니하며, 언급되지 아니한"}
{"patent_id": "10-2023-0107223", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 2, "content": "다른 효과들은 이하의 기재로부터 본 개시의 실시예들이 속하는 기술분야에서 통상의 지식을 가진 자에게 명확 하게 도출되고 이해될 수 있다. 즉, 본 개시의 실시예들을 실시함에 따른 의도하지 아니한 효과들 역시 본 개시"}
{"patent_id": "10-2023-0107223", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 3, "content": "의 실시예들로부터 당해 기술분야의 통상의 지식을 가진 자에 의해 도출될 수 있다."}
{"patent_id": "10-2023-0107223", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 첨부한 도면을 참조하여 본 개시의 실시예에 대해 상세히 설명한다. 도 1은 본 개시의 예시적인 실시예들에 따른 목적물의 이상 여부를 탐지하기 위한 시스템을 나타낸 블록도이다. 도 1을 참조하면, 시스템은 목적물, 측정 장비, 및 서버를 포함할 수 있다. 목적물은, 예를 들면, 제조 시설, 제조 설비, 출하 전의 제품, 제조 공정 상에서 발생하는 중간 제품, 제조 시설이나 제조 공정에 이용되는 부품 등을 포함할 수 있다. 목적물은 하나 이상의 특성을 가질 수 있다. 예 를 들면, 목적물의 특성은, 제조 설비 내의 온도, 압력, 및/또는 습도 등을 포함할 수 있다. 다른 예를 들 면, 목적물의 특성은, 제품의 내부 온도, 압력, 탄성, 강도, 내구성 등을 포함할 수 있다. 하지만, 이에 한 정되는 것은 아니다. 측정 장비는 목적물의 특성들을 측정할 수 있다. 측정 장비는, 목적물의 특성들에 대응되는 다 차원의 벡터를 포함하는 원본 데이터를 생성하고, 원본 데이터를 서버에 전송할 수 있다. 벡터의 차원은 측 정하고자 하는 목적물의 특성의 개수에 대응될 수 있다. 예를 들면, 목적물의 특성의 개수가 증가할수 록, 데이터의 차원 또는 벡터의 차원의 개수도 증가할 수 있다. 데이터의 차원이 증가됨으로 인해 데이터를 분 석하는 데에 어려운 성질은, 데이터(또는 데이터 스트림)의 복잡성으로 지칭될 수 있다. 공정에 이용되는 부품 이 교체되거나 제조 설비가 교체되는 등 목적물의 특성이 변경될 수 있다. 이에 따라, 목적물의 특성들 을 각각 나타내기 위한 벡터의 분포가 변화될 수 있다. 데이터의 분포 또는 벡터의 분포가 변화되는 성질은, 데 이터(또는 데이터 스트림)의 변동성으로 지칭될 수 있다. 일부 실시예들에서, 측정 장비는 목적물의 특성들을 실시간으로 측정하고, 원본 데이터를 실시간으로 서버에 전송할 수 있다. 측정 장비는, 목적물의 특성들을 측정하고 원본 데이터를 전송하기 위해, 입력 모듈과, 센서와 통신 모듈 및 제어 모듈 등을 포함할 수 있다. 서버는 최적의 인공지능 생성 모델을 이용하여 원본 데이터로부터 목적물의 이상 여부를 탐지할 수 있 다. 서버는 목적물의 이상 여부를 탐지하기 위한 다양한 장치들을 지칭할 수 있다. 서버는 제조 공 정 중에 목적물의 이상 여부를 실시간으로 탐지할 수 있다. 서버는, 컴퓨터, 서버 장치 및 휴대용 단말 기를 모두 포함하거나, 또는 어느 하나의 형태가 될 수 있다. 여기에서, 컴퓨터는 예를 들어, 웹 브라우저(WEB Browser)가 탑재된 노트북, 데스크톱(desktop) 등을 포함할 수 있다. 서버 장치는 외부 장치와 통신을 수행하여 정보를 처리할 수 있으며, 애플리케이션 서버, 컴퓨팅 서버, 데이터베이스 서버, 파일 서버, 및 웹 서버 등을 포함할 수 있다. 휴대용 단말기는 예를 들어, 휴대성과 이동성이 보장되는 무선 통신 장치일 수 있다. 휴대용 단말기는 PCS(Personal Communication System), GSM(Global System for Mobile communications), 스마트 폰 (Smart Phone) 등과 같은 모든 종류의 핸드헬드(Handheld) 기반의 장치와, 시계, 반지, 팔찌, 발찌, 목걸이, 안 경, 콘택트 렌즈, 또는 머리 착용형 장치(head-mounted-device(HMD) 등과 같은 웨어러블 장치를 포함할 수 있다. 서버는 프로세서, 메모리, 데이터베이스, 및 통신기를 포함할 수 있다. 프로세서는 통신기를 통해 원본 데이터를 수신할 수 있다. 그리고, 프로세서는, 복수의 인공지 능 생성 모델들 중에서 원본 데이터에 호환 가능한 적어도 하나의 인공지능 생성 모델을 이용할 수 있다. 그리 고, 프로세서는, 이용되는 인공지능 생성 모델을 통해, 원본 데이터와 원본 데이터의 복원 데이터 간의 복 원 정도에 대응하는 이상치 점수를 계산할 수 있다. 그리고, 프로세서는 이상치 점수와 기준 점수를 기초 로, 목적물의 이상 여부를 나타내는 탐지 결과 데이터를 출력할 수 있다. 본 개시에 따른 인공지능과 관련된 기능은 프로세서와 메모리를 통해 동작된다. 적어도 하나의 프로 세서는 CPU(Central Processing Unit), AP(Application Processor), DSP(Digital Signal Processor) 등 과 같은 범용 프로세서, GPU(Graphics Processing Unit), VPU(Vision Processing Unit)와 같은 그래픽 전용 프 로세서 또는 NPU(Neural Processing Unit)와 같은 인공지능 전용 프로세서일 수 있다. 적어도 하나의 프로세서는 메모리에 저장된 기 정의된 동작 규칙 또는 인공지능 모델에 따라, 입력 데이터를 처리하도록 제어할 수 있다. 적어도 하나의 프로세서가 인공지능 전용 프로세서인 경우, 인공지 능 전용 프로세서는, 특정 인공지능 모델의 처리에 특화된 하드웨어 구조로 설계될 수 있다. 기 정의된 동작 규칙 또는 인공지능 모델은 학습을 통해 만들어진 것일 수 있다. 여기서, 학습을 통해 만들어진 것은, 학습된 인공지능 모델이 원하는 특성(또는, 목적)을 수행하도록, 기본 인공지능 모델이 학습 알고리즘을 통해 학습 데이터 셋을 학습하는 것일 수 있다. 이러한 학습은 본 개시에 따른 인공지능이 수행되는 서버 자체에서 이루어지거나, 서버 이외에 별도의 장치, 서버 및/또는 시스템을 통해 이루어질 수도 있다. 학습 알고리즘의 예로는, 지도형 학습(supervised learning), 비지도 형 학습(unsupervised learning), 준지도형 학 습(semi-supervised learning) 또는 강화 학습(reinforcement learning)이 있으나, 전술한 예에 한정되지 않는 다. 인공지능 모델은 복수의 신경망 레이어들로 구성될 수 있다. 복수의 신경망 레이어들 각각은 복수의 가중치들 (weight values)을 가질 수 있다. 복수의 신경망 레이어들 각각은 이전(previous) 레이어의 연산 결과와 복수의 가중치들 간의 연산을 통해 신경망 연산을 수행할 수 있다. 복수의 가중치들은 인공지능 모델의 학습 결과에 의 해 최적화될 수 있다. 예를 들어, 학습 과정 동안 인공지능 모델에서 획득한 로스(loss)의 값 또는 코스트 (cost)의 값이 감소 또는 최소화되도록 복수의 가중치들이 갱신될 수 있다. 인공 신경망은, 예를 들어, CNN (Convolutional Neural Network), DNN (Deep Neural Network), RNN (Recurrent Neural Network), RBM (Restricted Boltzmann Machine), DBN (Deep Belief Network), BRDNN(Bidirectional Recurrent Deep Neural Network) 또는 심층 Q-네트워크 (Deep Q-Networks) 등을 포함할 수 있으나, 전술한 예에 한정되지 않는다. 본 개시의 예시적인 실시예에 따르면, 프로세서는 인공지능을 구현할 수 있다. 인공지능이란 사람의 신경 세포(biological neuron)를 모사하여 기계가 학습하도록 하는 인공신경망(Artificial Neural Network) 기반의 기계 학습법을 의미한다. 인공지능의 방법론에는 학습 방식에 따라 지도학습, 비지도학습, 및 강화학습으로 구 분될 수 있다. 또한, 인공지능의 방법론은 학습 모델의 구조인 아키텍처에 따라 CNN, RNN, 트랜스포머 (Transformer), 생성적 대립 신경망(GAN; generative adversarial networks) 등으로 구분될 수 있다. 프로세서는 적어도 하나의 인공지능 모델을 구현할 수 있다. 인공지능 모델은 뉴럴 네트워크로 구성될 수 있으며, 기계학습과 인지과학에서 생물학의 신경을 모방한 통계학적 학습 알고리즘을 포함할 수 있다. 뉴럴 네 트워크는 시냅스의 결합으로 네트워크를 형성한 인공 뉴런(노드)이 학습을 통해 시냅스의 결합 세기를 변화시켜, 문제 해결 능력을 가지는 모델 전반을 의미할 수 있다. 뉴럴 네트워크의 뉴런은 가중치 또는 바이어 스의 조합을 포함할 수 있다. 뉴럴 네트워크는 하나 이상의 뉴런 또는 노드로 구성된 하나 이상의 레이어 (layer)를 포함할 수 있다. 예시적으로, 장치는 입력 레이어(input layer), 히든 레이어(hidden layer), 출력 레이어(output layer)를 포함할 수 있다. 뉴럴 네트워크는 뉴런의 가중치를 학습을 통해 변화시킴으로써 임의의 입력(input)으로부터 예측하고자 하는 결과(output)를 추론할 수 있다. 프로세서는 뉴럴 네트워크를 생성하거나, 뉴럴 네트워크를 훈련(train, 또는 학습(learn)하거나, 수신되는 입력 데이터를 기초로 연산을 수행하고 수행 결과를 기초로 정보 신호(information signal)를 생성하거나, 뉴럴 네트워크를 재훈련(retrain)할 수 있다. 뉴럴 네트워크의 모델들은 GoogleNet, AlexNet, VGG Network 등과 같 은 CNN, R-CNN(Region with CNN), RPN(Region Proposal Network), RNN, S-DNN(Stacking-based DNN), S- SDNN(State-Space Dynamic Neural Network), Deconvolution Network, DBN, RBM(Restrcted Boltzman Machine), Fully Convolutional Network, LSTM(Long Short-Term Memory) Network, Classification Networ, Generative Modeling, eXplainable AI, Continual AI, Representation Learning, AI for Material Design, 자연어 처리를 위한 BERT, SP-BERT, MRC/QA, Text Analysis, Dialog System, GPT-3, GPT-4, 비전 처리를 위한 Visual Analytics, Visual Understanding, Video Synthesis, ResNet 데이터 지능을 위한 Anomaly Detection, Prediction, Time-Series Forecasting, Optimization, Recommendation, Data Creation 등 다양한 종류의 모델 들을 포함할 수 있으나 이에 제한되지는 않는다. 메모리와 프로세서는 각각 별개의 칩으로 구현되거나 단일 칩으로 구현될 수도 있다. 이러한, 메모리 는 플래시 메모리 타입(flash memory type), 하드디스크 타입(hard disk type), SSD 타입(Solid State Disk type), SDD 타입(Silicon Disk Drive type), 멀티미디어 카드 마이크로 타입(multimedia card micro type), 카드 타입의 메모리(예를 들어 SD 또는 XD 메모리 등), 램(random access memory; RAM), SRAM(static random access memory), 롬(read-only memory; ROM), EEPROM(electrically erasable programmable read-only memory), PROM(programmable read-only memory), 자기 메모리, 자기 디스크 및 광디스크 중 적어도 하나의 타 입의 저장매체를 포함할 수 있다. 메모리는 서버 내의 구성요소들의 동작을 제어하기 위한 알고리즘 또는 알고리즘을 재현한 프로그램에 대한 데이터를 저장할 수 있다. 메모리는 서버의 다양한 기능을 지원하는 데이터와, 프로세서의 동작을 위한 프로그램을 저장할 수 있고, 입/출력되는 데이터들을 저장할 수 있고, 서버에서 구동되는 다수 의 응용 프로그램(application program 또는 애플리케이션(application)), 서버의 동작을 위한 데이터들, 명령어들을 저장할 수 있다. 이러한 응용 프로그램 중 적어도 일부는, 무선 통신을 통해 외부 서버로부터 다운 로드 될 수 있다. 메모리는 모델 풀 데이터를 저장할 수 있다. 모델 풀 데이터는, 모델 풀을 포함할 수 있다. 모델 풀은 하 나 이상의 인공지능 생성 모델을 포함할 수 있다. 인공지능 생성 모델은 인코더 신경망 및 디코더 신경망을 포 함할 수 있다. 인공지능 생성 모델은 전술한 인공지능 모델에 대응될 수 있다. 데이터베이스는 학습 데이터 셋을 저장할 수 있다. 또한, 데이터베이스는 측정 장비로부터 제공 된 원본 데이터를 학습 데이터로서 저장할 수 있다. 통신기는 측정 장비와 통신을 수행할 수 있다. 예를 들면, 통신기는 와이파이(Wifi) 모듈, 와이 브로(Wireless broadband) 모듈, GSM(global System for Mobile Communication), LTE(Long Term Evolution), 4G, 5G, 6G 등 다양한 무선 통신 방식을 지원하는 무선 통신 모듈을 포함할 수 있다. 전술한 바에 의하면, 본 개시는, 고차원적 데이터에 호환되는 인공지능 생성 모델을 이용함으로써, 고차원의 데 이터를 용이하게 분석할 수 있고, 데이터의 분포 변화에도 불구하고 데이터를 정확하게 분석할 수 있다. 즉, 본 개시는 데이터의 복잡성 및 데이터의 변동성에 효과적으로 대응할 수 있다. 도 2는 본 개시의 예시적인 실시예들에 따른 데이터 스트림, 뱃치, 및 이상치 스코어를 나타낸 도면이다. 도 2를 참조하면, 프로세서는 모델 풀(MP)을 구현할 수 있다. 모델 풀(MP)은 복수의 인공지능 생성 모델들 (M1, M2, M3, ..., Mk)을 포함할 수 있다. 도 2에서 인공지능 생성 모델의 개수는 k인 것으로 도시되어 있으나, 이에 한정되는 것은 아니다. k는 2 이상의 자연수일 수 있다. 복수의 인공지능 생성 모델들(M1, M2, M3, ..., Mk) 각각은, 데이터 스트림(DS)의 분포 변화에 강건하게 대응하기 위하여, 각기 다른 특성을 지닐 수 있다. 이에 따르면, 본 개시는, 데이터 스트림(DS)에서 변화된 분포에 알맞은 인공지능 생성 모델을 적응적으로 이용함 으로써, 데이터 스트림(DS)의 변동성에 적절하게 대응할 수 있다. 데이터 스트림(DS)이 프로세서에 실시간으로 제공될 수 있다. 예를 들면, 데이터 스트림(DS)에 포함된 각 원본 데이터가 프로세서에 순차적으로 입력될 수 있다. 프로세서는, 데이터 스트림(DS)에 포함된 각 원본 데이터에 호환 가능한 인공지능 생성 모델을 이용할 수 있다. 각 원본 데이터에 호환 가능한 인공지능 생 성 모델은 하나 이상일 수 있다. 프로세서는 인공지능 생성 모델을 이용하여 각 원본 데이터에 대한 이상 치 점수를 산출할 수 있다. 예를 들면, 프로세서는, 모델 풀(MP)에서 제1 원본 데이터(OD1)에 호환 가능한 인공지능 생성 모델을 이용하여, 제1 원본 데이터(OD1)에 대한 제1 이상치 점수(ASf1)를 산출할 수 있다. 다른 예를 들면, 프로세서는, 모델 풀(MP)에서 제2 원본 데이터(OD2)에 호환 가능한 인공지능 생성 모델을 이용 하여, 제2 원본 데이터(OD2)에 대한 제2 이상치 점수(ASf2)를 산출할 수 있다. 프로세서는, 산출된 이상치 점수와 기준 점수를 기초로, 목적물의 이상 여부를 탐지할 수 있다. 일부 실시예들에서, 프로세서는 데이터 스트림(DS)에서 뱃치(batch) 단위로 데이터를 처리할 수 있다. 각 뱃치는 뱃치 사이즈를 가질 수 있다. 뱃치 사이즈는 원본 데이터의 개수에 대응될 수 있다. 예를 들면, 뱃치 사 이즈는 i이면(i는 2 이상의 정수), 제1 뱃치(B1)는 제1 내지 제i 원본 데이터(OD1, OD2, ..., ODi)를 포함하고, 제2 뱃치(B2)는 제i+1 내지 제2i 원본 데이터(ODi+1, ODi+2, ..., ODi)를 포함할 수 있다. 하지만, 이에 한정되는 것은 아니다. 프로세서는 모델 풀(MP)에서 각 뱃치에 호환 가능한 적어도 하나의 인공지능 생성 모델을 이용하여, 각 뱃치에 대한 이상치 점수를 산출할 수 있다. 예를 들면, 프로세서는, 모델 풀 (MP)에서 제1 뱃치(B1)에 호환 가능한 인공지능 생성 모델을 이용하여, 제1 뱃치(B1)에 대한 제1 이상치 점수 (ASf1)를 산출할 수 있다. 다른 예를 들면, 프로세서는, 모델 풀(MP)에서 제2 뱃치(B2)에 호환 가능한 인 공지능 생성 모델을 이용하여, 제2 뱃치(B2)에 대한 제2 이상치 점수(ASf2)를 산출할 수 있다. 다른 실시예들에서, 프로세서는 모델 풀(MP)에서 각 뱃치에 호환 가능한 적어도 하나의 인공지능 생성 모 델을 이용하여, 각 뱃치에 포함된 원본 데이터들의 이상치 점수들을 산출하며, 이상치 점수들 및 기준 점수 간 의 비교 결과를 기초로 목적물의 이상 여부를 탐지할 수 있다. 한편, 프로세서는 각 뱃치의 이상치 점수들 의 분포를 포함하는 분포 데이터를 생성할 수도 있다. 이상치 점수들의 분포는, 도 4a 내지 도 4c를 참조하여 후술하는 바와 같이 각 인공지능 생성 모델의 신뢰도를 계산하는 데 이용될 수 있다. 각 뱃치에 호환 가능한 인공지능 생성 모델은, 프로세서에 입력된 시점의 원본 데이터의 분포(또는 데이터 스트림(DS)의 분포)를 가장 잘 설명하는 인공지능 생성 모델을 의미할 수 있다. 데이터 스트림(DS)의 분포가 변화하였을 때, 변화된 분포에 알맞은 인공지능 생성 모델을 적응적으로 이용함으 로써, 변화된 분포에 적절하게 대응할 수 있는 효과가 있다. 즉, 데이터 스트림(DS)의 변동성에 강건하게 대응 할 수 있는 효과가 있다. 도 3은 본 개시의 예시적인 실시예들에 따른 인공지능 생성 모델을 설명하기 위한 도면이다. 도 3을 참조하면, 본 개시의 예시적인 실시예들에 따른 인공지능 생성 모델은 도 2의 모델 풀(MP)에 포함되는 복수의 인공지능 생성 모델들(M1, M2, M3, ..., Mk) 중 어느 하나일 수 있다. 본 개시의 예시적인 실시예들에 따른 인공지능 생성 모델은, 입력을 출력으로 복사하기 위해, 인코더 신경망 (ENCODER NEURAL NETWORK), 히든 레이어(HIDDEN LAYER), 및 디코더 신경망(DECODER NEURAL NETWORK)을 포함할 수 있다. 일부 실시예들에서, 인공지능 생성 모델은 오토인코더로 구현될 수 있다. 하지만, 이에 한정되는 것은 아니다. 인코더 신경망(ENCODER NEURAL NETWORK)은 하나 이상의 레이어를 포함할 수 있다. 인코더 신경망(ENCODER NEURAL NETWORK)에 포함된 하나의 레이어는 입력 레이어(INPUT)로 구현될 수 있다. 인공지능 생성 모델에서 입 력 레이어(INPUT)의 뉴런의 개수는 히든 레이어(HIDDEN LAYER)의 뉴런의 개수보다 많을 수 있다. 이에 따르면, 입력 데이터(x)가 압축될 수 있다. 입력 데이터(x)는 전술한 원본 데이터일 수 있다. 입력 데이터(x)가 압축된 다는 것은 데이터의 차원을 축소하는 것일 수 있다. 인코더 신경망(ENCODER NEURAL NETWORK)은 인코더로 지칭될 수 있다. 디코더 신경망(DECODER NEURAL NETWORK)은 하나 이상의 레이어를 포함할 수 있다. 디코더 신경망(DECODER NEURAL NETWORK)에 포함된 하나의 레이어는 출력 레이어(OUTPUT)로 구현될 수 있다. 인공지능 생성 모델에서 출 력 레이어(OUTPUT)의 뉴런의 개수는 히든 레이어(HIDDEN LAYER)의 뉴런의 개수보다 많을 수 있다. 이에 따르면, 입력 데이터에 노이즈(noise)가 추가된 후 입력 데이터(x)가 복원됨으로써, 출력 데이터(y)가 출력될 수 있다.출력 데이터(y)는 복원 데이터일 수 있다. 복원 데이터는, 입력 데이터(x)로서 입력된 원본 데이터가 복원된 데 이터일 수 있다. 디코더 신경망(DECODER NEURAL NETWORK)은 디코더로 지칭될 수 있다. 히든 레이어(HIDDEN LAYER)에서 코드 데이터(z)가 획득될 수 있다. 코드 데이터(z)는 레이턴트 벡터를 포함할 수 있다. 레이턴트 벡터는 입력 데이터(x)의 차원에서 축소된 차원의 벡터일 수 있다. 레이턴트 벡터(latent vector)는 인코더 신경망(ENCODER NEURAL NETWORK)에 입력된 원본 데이터를 통해 획득될 수 있다. 프로세서는 원본 데이터를 입력 데이터(x)로서 인공지능 생성 모델의 인코더 신경망(ENCODER NEURAL NETWORK)에 입력할 수 있다. 그리고, 프로세서는 인공지능 생성 모델의 디코더 신경망(DECODER NEURAL NETWORK)으로부터 출력 데이터(y)로서 출력되는 복원 데이터를 획득할 수 있다. 그리고, 프로세서는 복원 데이터와 원본 데이터 간의 차이에 대응되는 이상치 점수를 계산할 수 있다. 복원 데이터와 원본 데이터 간의 차이는, 예를 들면, 로스(loss)일 수 있다. 프로세서는 계산된 이상치 점수를 메모리에 저장할 수 있 다. 예를 들면, 프로세서는 기 학습된 데이터(또는 기 학습된 데이터 셋)에 대해서 계산된 이상치 점수를 메모리에 저장할 수 있다. 다른 예를 들면, 프로세서는 가장 최근에 계산된 이상치 점수를 메모리 에 저장할 수 있다. 일부 실시예들에서, 프로세서는 인공지능 생성 모델을 이용해 각 뱃치에 대한 이상치 점수들을 계산하고, 이상치 점수들의 분포를 포함하는 분포 데이터를 메모리에 저장할 수도 있다. 예를 들면, 프로세서는 기 학습된 데이터 셋에 대해서 계산된 이상치 점수들의 분포 및/또는 가장 최근에 계산된 뱃치의 이상치 점수들 의 분포를 메모리에 저장할 수 있다. 다른 예를 들면, 프로세서는 가장 최근에 계산된 이상치 점수를 메모리에 저장할 수 있다. 본 개시에서 이상치 점수는 저차원의 기저 공간에서 원본 공간으로의 복원력(reconstruction ability)에 대응될 수 있다. 비정상적인(또는 이상 있는) 데이터의 복원력이 정상적인 데이터의 복원력에 비하여 낮다는 성질이 있 다. 이러한 성질에 따를 때, 복원력이 상대적으로 낮은 데이터는 비정상적인 목적물로부터 측정된 데이터인 것으로 간주될 수 있다. 본 개시의 예시적인 실시예에 따른 복원력 기반의 이상치 점수를 이용하여 목적물 의 이상 여부를 탐지하는 방법은, 거리/밀도 기반의 이상치 탐지(distance/density-based outlier)에 비하여, 고차원의 데이터에 효과적일 수 있다. 따라서, 본 개시는 데이터 차원 증가로 인한 데이터 분석의 어려움(즉, 데이터 스트림(DS)의 복잡성)에 대해 효과적으로 대응할 수 있다. 프로세서는, 현재 입력되는 원본 데이터(또는 현재 입력되는 뱃치)에 대한 각 인공지능 생성 모델의 신뢰 도를 기반으로, 원본 데이터와 인공지능 생성 모델 간의 호환성을 판단할 수 있다. 이하에서 원본 데이터와 인 공지능 생성 모델 간의 호환성을 판단하기 위한, 인공지능 생성 모델의 신뢰도를 계산하는 실시예들이 설명된다. 도 4a, 도 4b, 및 도 4c는 본 개시의 신뢰도를 계산하는 예시적인 실시예들을 설명하기 위한 도면이다. 도 4a는 제1 뱃치(B1)에 대한 각 인공지능 생성 모델의 신뢰도를 예시적으로 도시한 것이고, 도 4b는 제1 뱃치(B1) 이후 의 제2 뱃치(B2)에 대한 각 인공지능 생성 모델의 신뢰도를 예시적으로 도시한 것이며, 도 4c는 제2 뱃치(B2) 이후의 제3 뱃치(B3)에 대한 각 인공지능 생성 모델의 신뢰도를 예시적으로 도시한 것이다. 일부 실시예들에서, 프로세서는 제1 이상치 점수와 제2 이상치 점수를 기초로, 제1 신뢰도를 계산할 수 있 다. 제1 이상치 점수는, 하나의 인공지능 생성 모델에 기 학습된 데이터(또는 데이터 셋)의 이상치 점수일 수 있다. 제1 이상치 점수의 개수는 모델 풀(MP)에 포함된 인공지능 생성 모델의 개수에 따를 수 있다. 제2 이상치 점수는, 현재 입력되는 원본 데이터에 대한 이상치 점수일 수 있다. 제1 신뢰도는, 현재 입력되는 원본 데이터 와 특정 인공지능 생성 모델 간의 호환성에 대응되는 값일 수 있다. 프로세서는 제1 신뢰도와 제1 기준 값 (TH1)을 기초로, 복수의 인공지능 생성 모델들(M1, M2, ..., Mk) 중에서 원본 데이터에 호환 가능한 인공지능 생성 모델을 선택할 수 있다. 도 4a를 참조하여 예를 들면, 제1 원본 데이터(OD1)가 현재 프로세서에 입력된 것으로 가정한다. 프로세서 는 제1 인공지능 생성 모델(M1)을 이용하여 제1 원본 데이터(OD1)에 대한 제2 이상치 점수를 계산할 수 있 다. 프로세서는 제1 인공지능 생성 모델(M1)에 기 학습된 데이터에 대한 제1 이상치 점수를 메모리에 서 로드할 수 있다. 프로세서는 제1 이상치 점수와 제2 이상치 점수 간의 차이를 계산할 수 있다. 프로세 서는 계산된 차이를 제1 원본 데이터(OD1)에 대한 제1 인공지능 생성 모델(M1)의 제1 신뢰도로 획득할 수 있다. 이와 유사하게, 프로세서는 제2 인공지능 생성 모델(M2)을 이용하여 제1 원본 데이터(OD1)에 대한 제2 이상치 점수를 계산할 수 있다. 프로세서는, 제2 인공지능 생성 모델(M2)의 제1 이상치 점수와 제1 원본 데이터(OD1)의 제2 이상치 점수 간의 차이를 계산함으로써, 제1 원본 데이터(OD1)에 대한 제2 인공지능 생성 모델(M2)의 제1 신뢰도로 획득할 수 있다. 이와 마찬가지로 모델 풀(MP)에 포함된 다른 인공지능 생성 모델들 각각에 대한 제1 신뢰도가 도 4a에 도시된 바와 같이 예시적으로 계산될 수 있다. 제1 인공지능 생성 모델(M1) 및 제n 인공지능 생성 모델(Mn)이 제1 기준 값(TH1)보다 큰 제1 신뢰도를 갖는 것으로 가정하면, 제1 인공지능 생성 모델(M1) 및 제n 인공지능 생성 모델(Mn)이 제1 원본 데이터(OD1)에 호환 가능하며, 프로세서에 의해 선택될 수 있다. 제1 원본 데이터(OD1)가 입력되는 경우, 프로세서는 제1 인공지능 생성 모델(M1) 및 제n 인공지능 생성 모델(Mn)을 이용하여 제1 원본 데이터(OD1)에 대한 최종적인 이상치 점수를 계산할 수 있다. 제1 원본 데이터(OD1)와 호환 가능한 인공지능 생성 모델을 찾는 실시예와 동일하게, 제2 원본 데이터(OD2) 내지 제 i 원본 데이터(ODi) 각각에 호환 가능한 적어도 하나의 인공지능 생성 모델이 검색될 수 있다. 다른 일부 실시예들에서, 프로세서는 기 학습된 데이터의 제1 이상치 점수들의 분포와 각 뱃치의 제2 이상 치 점수들의 분포를 기초로, 제1 신뢰도를 계산할 수 있다. 제1 이상치 점수들의 분포는, 하나의 인공지능 생성 모델에 기 학습된 데이터 셋의 이상치 점수들을 포함할 수 있다. 제2 이상치 점수들의 분포는 현재 입력되는 뱃 치의 원본 데이터들의 이상치 점수들을 포함할 수 있다. 프로세서는 제1 신뢰도와 제1 기준 값(TH1)을 기 초로, 복수의 인공지능 생성 모델들(M1, M2, ..., Mk) 중에서 원본 데이터에 호환 가능한 인공지능 생성 모델을 선택할 수 있다. 도 4a를 참조하여 예를 들면, 제1 뱃치(B1)가 현재 프로세서에 입력되면, 프로세서는 제1 인공지능 생성 모델(M1)을 이용하여 제1 내지 제i 원본 데이터(OD1, OD2, ..., ODi)에 대한 제2 이상치 점수들을 계산할 수 있다. 프로세서는 제1 인공지능 생성 모델(M1)에 기 학습된 데이터 셋의 제1 이상치 점수들을 메모리 에서 로드할 수 있다. 프로세서는 제1 이상치 점수들의 분포와 제2 이상치 점수들의 분포 간의 차이 를 계산할 수 있다. 프로세서는 계산된 차이를 제1 뱃치(B1)에 대한 제1 인공지능 생성 모델(M1)의 제1 신 뢰도로 획득할 수 있다. 이와 유사하게, 도 4a에 도시된 바와 같이, 프로세서는 제1 뱃치(B1)에 대한 제2 인공지능 생성 모델(M2) 내지 제k 인공지능 생성 모델(Mk) 각각의 제1 신뢰도를 계산할 수 있다. 도 4b를 참조하면, 프로세서는 각 인공지능 생성 모델의 제1 이상치 점수와 제2 뱃치(B2)에 포함된 각 원 본 데이터의 제2 이상치 점수를 기초로, 제1 신뢰도를 계산할 수 있다. 또는 프로세서는 각 인공지능 생성 모델의 제1 이상치 점수들의 분포와 제2 뱃치(B2)의 제2 이상치 점수들의 분포를 기초로, 제1 신뢰도를 계산할 수 있다. 제2 뱃치(B2)(또는 제2 뱃치(B2)에 포함된 각 원본 데이터)에 대한 제1 내지 제k 인공지능 생성 모델 (M1, M2, ..., Mn, ..., Mk)의 제1 신뢰도가 도 4b와 같이 예시적으로 계산될 수 있다. 도 4b에서 제n 인공지 능 생성 모델(Mn)의 제1 신뢰도가 제1 기준 값(TH1)보다 크므로, 제n 인공지능 생성 모델(Mn)이 제2 뱃치(B2) (또는 제2 뱃치(B2)에 포함된 특정 원본 데이터)에 호환 가능한 인공지능 생성 모델일 수 있다. 도 4c를 참조하면, 프로세서는 각 인공지능 생성 모델의 제1 이상치 점수들의 분포와 제3 뱃치(B3)의 제2 이상치 점수들의 분포를 기초로, 제1 신뢰도를 계산할 수 있다. 제3 뱃치(B3)에 대한 제1 내지 제k 인공지능 생 성 모델(M1, M2, ..., Mn, ..., Mk)의 제1 신뢰도가 도 4c와 같이 예시적으로 계산될 수 있다. 도 4c에서 제1 내지 제k 인공지능 생성 모델(M1, M2, ..., Mn, ..., Mk)의 제1 신뢰도가 모두 제1 기준 값(TH1)보다 작은 경 우, 제3 뱃치(B3)에 호환 가능한 인공지능 생성 모델이 모델 풀(MP)에 존재하지 않을 수 있다. 이 경우, 새로운 인공지능 생성 모델이 모델 풀(MP)에 추가될 필요가 있다. 도 5a 및 도 5b는 인공지능 생성 모델을 업데이트하는 예시적인 실시예를 설명하기 위한 도면들이다. 도 5a 및 도 5b를 참조하면, 프로세서는, 복수의 인공지능 생성 모델들(M1, M2, M3, ..., Mn, ..., Mk)의 복수의 신뢰도들을 기초로, 모델 풀(MP)을 업데이트할 수 있다. 모델 풀(MP)을 업데이트할 때, 복수의 신뢰도들 을 이용하는 예시적인 실시예들은 도 14 및 도 15를 참조하여 후술된다. 일부 실시예들에서, 모델 풀(MP)을 업데이트하는 것은, 현재 입력된 뱃치를 학습 데이터로서 모델 풀(MP)에 포 함된 기존의 인공지능 생성 모델에 학습시키는 것일 수 있다. 도 4a 및 도 5a를 참조하여 예를 들면, 모델 풀 (MP)에서 제1 뱃치(B1)에 호환 가능한 인공지능 생성 모델은, 제1 인공지능 생성 모델(M1) 및 제n 인공지능 생 성 모델(Mn)일 수 있다. 따라서, 제1 뱃치(B1)에 대한 제1 이상치 점수(ASf1)가 산출되고, 제1 인공지능 생성 모델(M1) 및 제n 인공지능 생성 모델(Mn)은 제1 뱃치(B1)를 학습함으로써 업데이트될 수 있다. 제1 인공지능 생 성 모델(M1')은 업데이트된 제1 인공지능 생성 모델(M1)에 대응될 수 있다. 제n 인공지능 생성 모델(Mn')은 업 데이트된 제n 인공지능 생성 모델(Mn)에 대응될 수 있다. 다른 일부 실시예들에서, 모델 풀(MP)을 업데이트하는 것은, 현재 입력된 뱃치를 학습한 새로운 인공지능 생성 모델을 모델 풀(MP)에 추가하는 것일 수 있다. 도 4c 및 도 5b를 참조하여 예를 들면, 제3 뱃치(B3)에 호환 가 능한 인공지능 생성 모델이 현재 모델 풀(MP)에 존재하지 않을 수 있다. 따라서, 제k+1 인공지능 생성 모델 (Mk+1)이 생성되고 모델 풀(MP)에 추가될 수 있다. 제k+1 인공지능 생성 모델(Mk+1)은 제3 뱃치(B3)를 학습한 새로운 인공지능 생성 모델일 수 있다. 한편, 프로세서는 제k+1 인공지능 생성 모델(Mk+1)을 이용하여 제3 뱃치(B3)의 제3 이상치 점수(ASf3)를 산출할 수 있다. 다른 일부 실시예들에 따라 새로운 인공지능 생성 모델이 모델 풀(MP)에 추가되면, 프로세서 내부의 저장 용량 및/또는 메모리의 저장 용량이 부족할 수 있다. 이를 위해 서로 유사한 인공지능 생성 모델을 병합할 필요가 있다. 도 6은 인공지능 생성 모델을 병합하는 예시적인 실시예를 설명하기 위한 도면이다. 도 6을 참조하면, 프로세서는, 원본 데이터를 학습 데이터로 학습한 새로운 인공지능 생성 모델(예, 제k+1 인공지능 생성 모델(Mk+1))을 생성함으로써, 모델 풀(MP)을 업데이트할 수 있다. 이 경우, 프로세서는, 모 델 풀(MP)에서 제k+1 인공지능 생성 모델(Mk+1)과 유사한 인공지능 생성 모델을 검색할 수 있다. 제k+1 인공지 능 생성 모델(Mk+1)과 유사한 인공지능 생성 모델은 제1 인공지능 생성 모델(M1) 및 제3 인공지능 생성 모델 (M3)인 것으로 가정한다. 프로세서는, 제1 인공지능 생성 모델(M1), 제3 인공지능 생성 모델(M3), 및 제 k+1 인공지능 생성 모델(Mk+1)을 병합함으로써, 병합된 제k+1 인공지능 생성 모델(Mk+1')을 생성할 수 있다. 인 공지능 생성 모델을 병합한다는 것은, 병합될 인공지능 생성 모델들 중 어느 하나의 인공지능 생성 모델을 유지 하고 나머지 인공지능 생성 모델을 삭제하는 것일 수 있다. 또는, 인공지능 생성 모델을 병합한다는 것은, 병합 될 인공지능 생성 모델들의 특성을 모두 갖는 새로운 인공지능 생성 모델을 생성하고 병합될 인공지능 생성 모 델들을 삭제하는 것일 수도 있다. 전술한 바에 의하면, 프로세서 및/또는 메모리의 저장 공간을 효율적으로 관리할 수 있는 효과가 있 다. 도 7은 본 개시의 예시적인 실시예들에 따른 목적물의 이상 여부를 탐지하기 위한 방법을 설명하기 위한 흐름도 이다. 도 7을 참조하면, 본 개시의 방법은, 도 1의 서버에 의해 수행될 수 있다. 원본 데이터를 수신하는 단계가 수행된다(S10). 원본 데이터는 목적물의 특성들에 대응되는 다차원의 벡터 를 포함할 수 있다. 복수의 인공지능 생성 모델들(M1, M2, ...,Mk) 중에서 원본 데이터에 호환 가능한 적어도 하나의 인공지능 생성 모델을 이용하여, 이상치 점수(anomaly score)를 연산하는 단계가 수행된다(S20). 하나의 인공지능 생성 모델은 인코더 신경망(ENCODER NEURAL NETWORK) 및 디코더 신경망(DECODER NEURAL NETWORK)을 포함할 수 있다. 이상치 점수는 원본 데이터와 원본 데이터의 복원 데이터 간의 복원 정도(또는 복원력)에 대응할 수 있다. 이상치 점수와 기준 점수를 기초로 탐지 결과 데이터를 출력하는 단계가 수행된다(S30). 탐지 결과 데이터는 목 적물의 이상 여부를 나타내는 결과를 포함할 수 있다. 전술한 바에 의하면, 고차원의 데이터 스트림(DS0에 대해 목적물의 이상 여부를 효율적이며 탐지할 수 있는 효과가 있다. 도 8은 뱃치 별 이상치 점수들의 분포를 계산하는 예시적인 실시예를 설명하기 위한 흐름도이다. 도 8을 참조하면, 단계 S10은 단계 S100 및 단계 S110을 포함할 수 있다. 데이터 스트림(DS)을 실시간으로 수신 하는 단계가 수행된다(S100). 데이터 스트림(DS)에서 뱃치 단위로 원본 데이터 세트를 그룹화하는 단계가 수행 된다(S110). 도 2를 참조하여 예를 들면, 뱃치 사이즈가 i이면, 제1 원본 데이터(OD1) 내지 제i 원본 데이터 (ODi)를 포함하는 원본 데이터 세트가 제1 뱃치(B1)로 그룹화되고, 제i+1 원본 데이터(ODi+1) 내지 제2i 원본 데이터(OD2i)를 포함하는 원본 데이터 세트가 제2 뱃치(B2)로 그룹화될 수 있다. 단계 S20은 단계 S210 및 단계 S211을 포함할 수 있다. 뱃치마다, 뱃치의 이상치 점수들을 계산하는 단계가 수 행된다(S210). 목적물의 이상 여부를 탐지하기 위한 이상치 점수들의 분포를 포함하는 분포 데이터를 제공하는 단계가 수행된다(S211). 도 2를 참조하여 예를 들면, 제1 뱃치(B1)의 이상치 점수들이 계산되고, 제2 뱃치(B2) 의 이상치 점수들이 계산될 수 있다. 그리고, 제1 뱃치(B1)의 이상치 점수들의 분포를 포함하는 분포 데이터가 생성되고, 제2 뱃치(B2)의 이상치 점수들의 분포를 포함하는 분포 데이터가 생성될 수 있다.도 9는 인공지능 생성 모델을 이용해 이상치 점수를 계산하는 예시적인 실시예를 설명하기 위한 흐름도이다. 도 9를 참조하면, 도 9의 단계들(S220, S221, S222, S223)은 도 7의 단계 S20에 포함될 수 있다. 도 9의 단계 들(S220, S221, S222, S223)은 도 3을 참조하여 전술한 실시예와 동일할 수 있다. 원본 데이터를 적어도 하나의 인공지능 생성 모델의 인코더 신경망(ENCODER NEURAL NETWORK)에 입력하는 단계가 수행된다(S220). 적어도 하나의 인공지능 생성 모델의 디코더 신경망(DECODER NEURAL NETWORK)을 통해 복원 데 이터를 출력하는 단계가 수행된다(S221). 복원 데이터와 원본 데이터 간의 차이에 대응되는 이상치 점수를 계산 하는 단계가 수행된다(S222). 이상치 점수를 저장하는 단계가 수행된다(S223). 도 10은 원본 데이터와 호환 가능한 인공지능 생성 모델을 찾는 예시적인 실시예를 설명하기 위한 흐름도이다. 도 10을 참조하면, 도 10의 단계들(S230, S231)은 도 7의 단계 S20에 포함될 수 있다. 도 10의 단계들(S230, S231)은 도 4a, 도 4b, 및 도 4c를 참조하여 전술한 실시예와 동일할 수 있다. 적어도 하나의 제1 이상치 점수와 제2 이상치 점수를 기초로 적어도 하나의 제1 신뢰도를 계산하는 단계가 수행 된다(S230). 제1 이상치 점수는, 하나의 인공지능 생성 모델에 기 학습된 데이터 셋의 이상치 점수일 수 있다. 인공지능 생성 모델이 2 이상이면, 제1 이상치 점수의 개수 및 제1 신뢰도의 개수도 2 이상일 수 있다. 제1 신 뢰도는 원본 데이터와 하나의 인공지능 생성 모델 간의 호환성에 대응될 수 있다. 적어도 하나의 제1 신뢰도와 제1 기준 값을 기초로, 복수의 인공지능 생성 모델들에서 원본 데이터에 호환 가 능한 인공지능 생성 모델을 적어도 하나 선택하는 단계가 수행된다(S231). 도 11은 인공지능 생성 모델의 신뢰도를 기반으로 최종적인 이상치 점수를 계산하는 예시적인 실시예를 설명하 기 위한 흐름도이다. 도 11을 참조하면, 도 11의 단계 S230는 단계 S240 및 단계 S241을 포함할 수 있다. 하나의 인공지능 생성 모델 에 대응되는 하나의 제1 이상치 점수를 로드하는 단계가 수행된다(S240). 하나의 제1 이상치 점수와 제2 이상치 점수 간의 차이를 계산함으로써, 하나의 인공지능 생성 모델에 대응되는 하나의 제1 신뢰도를 계산하는 단계가 수행된다(S241). 예를 들면, 프로세서는 제1 인공지능 생성 모델(MP1)을 이용하여 제2 이상치 점수를 계산 할 수 있다. 프로세서는 제1 인공지능 생성 모델(MP1)의 제1 이상치 점수를 메모리로부터 로드할 수 있다. 프로세서는 제1 이상치 점수 및 제2 이상치 점수 간의 차이를 계산함으로써, 제1 인공지능 생성 모 델(MP1)의 제1 신뢰도를 획득할 수 있다. 제2 인공지능 생성 모델(MP2) 내지 제k 인공지능 생성 모델(Mk)에 대 해서도, 전술한 단계 S240 및 단계 S241이 수행된다. 도 11의 단계 S231는 단계 S242 및 단계 S243을 포함할 수 있다. 적어도 하나의 제1 신뢰도와 제1 기준 값(TH 1)을 비교하는 단계가 수행된다(S242). 비교 결과에 응답하여 최종적인 이상치 점수를 계산하는 단계가 수행된 다(S243). 도 12는 도 11의 단계 S231의 일부 실시예들을 설명하기 위한 흐름도이다. 도 12를 참조하면, 제1 신뢰도가 제1 기준 값(TH1)보다 큰 지 판단하는 비교하는 단계가 수행된다(S250). 제1 신뢰도가 제1 기준 값(TH1)보다 크면(S250, 예), 현재 사용되는 적어도 하나의 인공지능 생성 모델을 유지 하고, 제2 이상치 점수를 최종적인 이상치 점수로 계산하는 단계가 수행된다(S251). 예를 들면, 현재 사용되는 인공지능 생성 모델이 제1 인공지능 생성 모델(M1)이고 제1 뱃치(B1)가 현재 프로세서에 입력되는 것으로 가정한다. 프로세서는 제1 인공지능 생성 모델(M1)을 이용하여 제1 뱃치(B1)의 제2 이상치 점수를 계산한 다. 그리고, 제1 인공지능 생성 모델(M1)의 제1 신뢰도가 제1 기준 값(TH1)보다 크면, 프로세서는 제1 뱃 치(B1)의 제2 이상치 점수를 최종적인 이상치 점수로 산출한다. 그리고, 프로세서는 제1 인공지능 생성 모 델(M1)을 이용하여 후속 뱃치(예를 들어, 제2 뱃치(B2))의 제2 이상치 점수를 계산할 수 있다. 다른 예를 들면, 현재 사용되는 인공지능 생성 모델이 제1 인공지능 생성 모델(M1), 제2 인공지능 생성 모델(M2), 및 제3 인공지 능 생성 모델(M3)인 것으로 가정한다. 제1 뱃치(B1)의 제2 이상치 점수는, 제1 인공지능 생성 모델(M1), 제2 인 공지능 생성 모델(M2), 및 제3 인공지능 생성 모델(M3) 각각에 의해 출력된 이상치 점수의 조합에 의해 계산될 수 있다. 제1 인공지능 생성 모델(M1), 제2 인공지능 생성 모델(M2), 및 제3 인공지능 생성 모델(M3) 각각의 제 1 신뢰도가 제1 기준 값(TH1)보다 크면, 제1 뱃치(B1)의 제2 이상치 점수가 최종적인 이상치 점수로 산출될 수 있다. 제1 신뢰도가 제1 기준 값(TH1)보다 작거나 같으면(S250, 아니오), 제2 이상치 점수보다 더 정확한 이상치 점수 가 필요하다. 따라서, 복수의 인공지능 생성 모델들(M1, M2, ..., Mk) 중 적어도 하나의 인공지능 생성 모델을 제외한 다른 적어도 하나의 인공지능 생성 모델을 이용하여, 원본 데이터의 제3 이상치 점수를 계산하는 단계가 수행된다(S252). 예를 들면, 현재 사용되는 인공지능 생성 모델이 제1 인공지능 생성 모델(M1)이고 제1 인공지 능 생성 모델(M1)의 제1 신뢰도가 제1 기준 값(TH1)보다 작을 수 있다. 이 경우, 프로세서는, 제2 인공지 능 생성 모델(M2)부터 제k 인공지능 생성 모델(Mk)까지 인공지능 생성 모델들 중 적어도 하나의 인공지능 생성 모델을 이용하여, 현재 입력된 원본 데이터(또는 현재 입력된 뱃치)의 제3 이상치 점수를 계산할 수 있다. 한편, 적어도 하나의 제1 이상치 점수 및 제3 이상치 점수를 기초로, 적어도 하나의 제2 신뢰도를 계산하는 단 계가 수행된다(S252). 제2 신뢰도는 원본 데이터와, 전술한 다른 적어도 하나의 인공지능 생성 모델 간의 호환 성에 대응되는 값일 수 있다. 도 13은 모델 풀을 업데이트하는 예시적인 실시예를 설명하기 위한 흐름도이다. 도 13을 참조하면, 도 13의 단계들(S260, S261)은 도 7의 단계 S20에 포함될 수 있다. 도 13의 단계들(S260, S261)은 도 4a, 도 4b, 도 4c, 도 5a, 및 도 5b를 참조하여 전술한 실시예와 동일할 수 있다. 각 인공지능 생성 모델에 기 학습된 데이터 셋의 이상치 점수와 원본 데이터의 이상치 점수를 기초로, 원본 데 이터와 각 인공지능 생성 모델 간의 호환성에 대응되는 신뢰도를 계산하는 단계가 수행된다(S260). 복수의 인공지능 생성 모델들의 복수의 신뢰도들을 기초로, 복수의 인공지능 생성 모델들을 포함하는 모델 풀 을 업데이트하는 단계가 수행된다(S261). 도 14는 도 13의 단계 S261의 일부 실시예들을 설명하기 위한 흐름도이다. 도 14를 참조하면, 전체 신뢰도가 제2 기준 값보다 큰지 판단하는 단계가 수행된다(S270a). 전체 신뢰도는 모델 풀(MP)의 신뢰도일 수 있다. 예를 들면, 프로세서는 복수의 신뢰도들을 기초로 모델 풀(MP)의 전체 신뢰도 를 계산할 수 있다. 예를 들면, 모델 풀(MP)의 전체 신뢰도( )는 아래의 [수학식 1]에 따라 계산될 수 있다. [수학식 1]"}
{"patent_id": "10-2023-0107223", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "여기서, 는 모델 풀(MP)의 임의의 인공지능 생성 모델의 신뢰도일 수 있다. 전체 신뢰도가 제2 기준 값보다 크면(S270a, 예), 현재 입력된 원본 데이터(또는 현재 입력된 뱃치)를, 현재 이 용되는 적어도 하나의 인공지능 생성 모델에 학습시키는 단계가 수행된다(S271a). 현재 이용되는 인공지능 생성 모델이 학습됨으로써, 모델 풀(MP)이 업데이트될 수 있다. 즉, 현재 입력되는 데이터와 호환되는 인공지능 생성 모델이 모델 풀(MP) 내에 존재하는 경우, 해당 인공지능 생성 모델만이 업데이트될 수 있다. 전체 신뢰도가 제2 기준 값보다 작거나 같으면(S270a, 아니오), 현재 입력된 원본 데이터를(또는 현재 입력된 뱃치를) 학습 데이터로 학습한 새로운 인공지능 생성 모델을 생성하는 단계가 수행된다(S272a). 새로운 인공지 능 생성 모델이 모델 풀(MP)에 추가됨으로써, 모델 풀(MP)이 업데이트될 수 있다. 즉, 모델 풀(MP) 내에 존재하 는 어떤 인공지능 생성 모델도, 현재 입력된 데이터와 호환되지 않는 경우, 현재 입력 데이터를 학습하는 새로 운 인공지능 생성 모델이 생성될 수 있다. 도 15는 도 13의 단계 S261의 다른 일부 실시예들을 설명하기 위한 흐름도이다. 도 15를 참조하면, 복수의 신뢰도들이 모두 제3 기준 값보다 큰지 판단하는 단계가 수행된다(S270b). 복수의 신 뢰도들은 모델 풀(MP)에 포함된 복수의 인공지능 생성 모델들(M1, M2, ..., Mk)의 신뢰도들일 수 있다. 예를 들 면, 프로세서는 복수의 신뢰도들 각각이 제3 기준 값보다 큰지 여부를 판단할 수 있다. 복수의 신뢰도들 중 적어도 하나의 신뢰도가 제3 기준 값보다 크면(S270b, 예), 복수의 신뢰도들 중 제3 기준 값보다 큰 신뢰도를 갖는 인공지능 생성 모델에 원본 데이터를 학습시키는 단계가 수행된다(S271b). 복수의 신뢰도들이 제3 기준 값보다 작거나 같으면(S270b, 아니오), 원본 데이터를 학습 데이터로 학습한 새로 운 인공지능 생성 모델을 생성하는 단계가 수행된다(S272b). 도 16은 인공지능 생성 모델을 병합하는 예시적인 실시예를 설명하기 위한 흐름도이다. 도 16을 참조하면, 도 16의 단계들(S280, S281, S282)은 도 7의 단계 S20에 포함될 수 있다. 도 16의 단계들 (S280, S281, S282)은 도 3 및 6을 참조하여 전술한 실시예와 동일할 수 있다. 원본 데이터를 학습 데이터로 학습한 새로운 인공지능 생성 모델(예, 제k+1 인공지능 생성 모델(Mk+1))을 생성 함으로써, 복수의 인공지능 생성 모델들(M1, M2, ..., Mk)을 포함하는 모델 풀(MP)을 업데이트하는 단계가 수행 된다(S280). 새로운 인공지능 생성 모델 및 복수의 인공지능 생성 모델들(M1, M2, ..., Mk) 각각으로부터, 레이턴트 벡터를 획득하는 단계가 수행된다(S281). 레이턴트 벡터는 인코더 신경망(ENCODER NEURAL NETWORK)으로부터 출력되는 코드(예, 코드 데이터(z))일 수 있다. 예를 들면, 새로운 인공지능 생성 모델의 제1 레이턴트 벡터가 획득될 수 있고, 모델 풀(MP)에 포함된 각 인공지능 생성 모델의 레이턴트 벡터가 획득될 수 있다. 새로운 인공지능 생성 모델의 제1 레이턴트 벡터 및 복수의 인공지능 생성 모델들의 레이턴트 벡터들을 기초로, 새로운 인공지능 생성 모델과 유사한 하나 이상의 인공지능 생성 모델을 새로운 인공지능 생성 모델과 병합하는 단계가 수행된다(S282). 전술한 실시예에 의하면, 모델 풀(MP)에 포함된 인공지능 생성 모델의 수를 조절함으로써, 모델 풀을 효율적으 로 운용하는 효과가 있다. 도 17은 도 16의 단계 S282의 일부 실시예들을 설명하기 위한 흐름도이다. 도 17을 참조하면, 제1 레이턴트 벡터와 각 인공지능 생성 모델의 레이턴트 벡터 간의 차이를 기초로, 새로운 인공지능 생성 모델(예, 제k+1 인공지능 생성 모델(Mk+1))에 대한 각 인공지능 생성 모델의 유사도를 계산하는 단계가 수행된다(S290). 예를 들면, 프로세서는 제k+1 인공지능 생성 모델(Mk+1)의 제1 레이턴트 벡터와 제1 인공지능 생성 모델(M1)의 레이턴트 벡터 간의 차이를 계산하고, 이러한 차이를 기반으로 제1 인공지능 생 성 모델(M1)과 제k+1 인공지능 생성 모델(Mk+1) 간의 유사도를 계산할 수 있다. 이와 마찬가지로, 제2 인공지능 생성 모델(M2)과 제k+1 인공지능 생성 모델(Mk+1) 간의 유사도가 계산될 수 있고, 모델 풀(MP)에 있는 나머지 인공지능 생성 모델(M3, ..., Mn, ..., Mk) 각각의 유사도가 계산될 수 있다. 복수의 인공지능 생성 모델들 각각의 복수의 유사도들 및 기준 유사도를 기초로, 새로운 인공지능 생성 모델과 유사한 하나 이상의 인공지능 생성 모델을 새로운 인공지능 생성 모델과 병합하는 단계가 수행된다(S291). 도 18은 최종적 이상치 점수를 산출하는 예시적인 실시예를 설명하기 위한 도면이다. 도 18을 참조하면, 적어도 하나의 인공지능 생성 모델을 이용하는 일부 실시예에서, 프로세서는 각 인공지 능 생성 모델을 이용해 계산된 이상치 점수에 가중치를 신뢰도에 따라 부여할 수 있다. 이에 따르면, 신뢰도가 상대적으로 높은 인공지능 생성 모델이 이상치 점수를 계산하는데 더 많이 기여할 수 있다. 원본 데이터(OD)가 모델 풀(MP)의 복수의 인공지능 생성 모델들(M1, M2, ..., Mk)에 입력되고, 복수의 인공지능 생성 모델들(M1, M2, ..., Mk) 각각으로부터 복수의 복원 데이터들(RD1, RD2, ..., RDk)이 출력될 수 있다. 복수의 복원 데이터들(RD1, RD2, ..., RDk) 각각과 원본 데이터(OD) 간의 차이에 대응되는 이상치 점수에 가중 치가 반영될 수 있다. 예를 들면, 원본 데이터(OD)와 제1 복원 데이터(RD1) 간의 차이에 대응되는 이상치 점수 가 계산되고, 제1 인공지능 생성 모델(M1)의 신뢰도에 따른 제1 가중치(W1)가 해당 이상치 점수에 반영됨으로써, 제1 이상치 점수(AS1)가 계산될 수 있다. 마찬가지로, 제2 인공지능 생성 모델(M2)의 신뢰도에 따른 제2 가중치(W2)가 반영된 제2 이상치 점수(AS2)가 계산될 수 있으며, 제k 인공지능 생성 모델(Mk)의 신뢰 도에 따른 제k 가중치(Wk)가 반영된 제k 이상치 점수(ASk)가 계산될 수 있다. 제1 내지 제k 이상치 점수(AS1, AS2, ..., ASk)의 조합에 대응되는 최종 이상치 점수(ASf)가 산출될 수 있다. 전술한 이상치 점수를 계산하는데 이용되는 제1 내지 제k 가중치(W1, W2, ..., Wk)는, 대응하는 인공지능 생성 모델의 신뢰도에 따라 변경될 수 있다. 본 개시의 범위 또는 기술적 사상을 벗어나지 않고 본 개시의 구조가 다양하게 수정되거나 변경될 수 있음은 이 분야에 숙련된 자들에게 자명하다. 상술한 내용을 고려하여 볼 때, 만약 본 개시의 수정 및 변경이 아래의 청구 항들 및 동등물의 범주 내에 속한다면, 본 개시가 이 발명의 변경 및 수정을 포함하는 것으로 여겨진다. 이상과 같이 도면과 명세서에서 예시적인 실시예들이 개시되었다. 본 명세서에서 특정한 용어를 사용하여 실시 예들을 설명되었으나, 이는 단지 본 개시의 기술적 사상을 설명하기 위한 목적에서 사용된 것이지 의미 한정이"}
{"patent_id": "10-2023-0107223", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "나 특허청구범위에 기재된 본 개시의 범위를 제한하기 위하여 사용된 것은 아니다. 그러므로 본 기술분야의 통상의 지식을 가진 자라면 이로부터 다양한 변형 및 균등한 타 실시예가 가능하다는 점을 이해할 것이다. 따라서, 본 개시의 진정한 기술적 보호범위는 첨부된 특허청구범위의 기술적 사상에 의해 정해져야 할 것이다."}
{"patent_id": "10-2023-0107223", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 개시의 예시적인 실시예들에 따른 목적물의 이상 여부를 탐지하기 위한 시스템을 나타낸 블록도이다. 도 2는 본 개시의 예시적인 실시예들에 따른 데이터 스트림, 뱃치, 및 이상치 스코어를 나타낸 도면이다. 도 3은 본 개시의 예시적인 실시예들에 따른 인공지능 생성 모델을 설명하기 위한 도면이다. 도 4a, 도 4b, 및 도 4c는 신뢰도를 계산하는 예시적인 실시예들을 설명하기 위한 도면이다. 도 5a 및 도 5b는 인공지능 생성 모델을 업데이트하는 예시적인 실시예를 설명하기 위한 도면들이다. 도 6은 인공지능 생성 모델을 병합하는 예시적인 실시예를 설명하기 위한 도면이다. 도 7은 본 개시의 예시적인 실시예들에 따른 목적물의 이상 여부를 탐지하기 위한 방법을 설명하기 위한 흐름도 이다. 도 8은 뱃치 별 이상치 점수들의 분포를 계산하는 예시적인 실시예를 설명하기 위한 흐름도이다. 도 9는 인공지능 생성 모델을 이용해 이상치 점수를 계산하는 예시적인 실시예를 설명하기 위한 흐름도이다. 도 10은 원본 데이터와 호환 가능한 인공지능 생성 모델을 찾는 예시적인 실시예를 설명하기 위한 흐름도이다. 도 11은 인공지능 생성 모델의 신뢰도를 기반으로 최종적인 이상치 점수를 계산하는 예시적인 실시예를 설명하 기 위한 흐름도이다. 도 12는 도 11의 단계 S231의 일부 실시예들을 설명하기 위한 흐름도이다. 도 13은 모델 풀을 업데이트하는 예시적인 실시예를 설명하기 위한 흐름도이다. 도 14는 도 13의 단계 S261의 일부 실시예들을 설명하기 위한 흐름도이다. 도 15는 도 13의 단계 S261의 다른 일부 실시예들을 설명하기 위한 흐름도이다. 도 16은 인공지능 생성 모델을 병합하는 예시적인 실시예를 설명하기 위한 흐름도이다. 도 17은 도 16의 단계 S282의 일부 실시예들을 설명하기 위한 흐름도이다. 도 18은 최종적 이상치 점수를 산출하는 예시적인 실시예를 설명하기 위한 도면이다."}
