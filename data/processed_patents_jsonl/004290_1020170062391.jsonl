{"patent_id": "10-2017-0062391", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2018-0127065", "출원번호": "10-2017-0062391", "발명의 명칭": "키워드 오인식을 방지하는 음성 제어 장치 및 이의 동작 방법", "출원인": "네이버 주식회사", "발명자": "김병열"}}
{"patent_id": "10-2017-0062391", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "주변 소리에 대응하는 오디오 신호를 수신하여, 오디오 스트림 데이터를 생성하는 오디오 처리부;상기 오디오 스트림 데이터로부터 미리 정의된 키워드에 대응하는 후보 키워드를 검출하고, 상기 오디오 스트림데이터에서 상기 후보 키워드가 검출된 제1 오디오 데이터에 해당하는 제1 구간의 시점과 종점을 결정하는 키워드 검출부;상기 제1 오디오 데이터에 대한 제1 화자 특징 벡터를 추출하고, 상기 오디오 스트림 데이터에서 상기 제1 구간의 시점을 종점으로 하는 제2 구간에 해당하는 제2 오디오 데이터에 대한 제2 화자 특징 벡터를 추출하는 화자특징 벡터 추출부; 및상기 제1 화자 특징 벡터와 상기 제2 화자 특징 벡터의 유사도를 기초로 상기 제1 오디오 데이터에 상기 키워드가 포함되었는지의 여부를 판단하는 웨이크업 판단부를 포함하는 음성 제어 장치."}
{"patent_id": "10-2017-0062391", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 웨이크업 판단부는 상기 제1 화자 특징 벡터와 상기 제2 화자 특징 벡터 간의 유사도가 미리 설정한 기준치 이하인 경우에 상기 제1 오디오 데이터에 상기 키워드가 포함되었다고 판단하는 것을 특징으로 하는 음성 제어 장치."}
{"patent_id": "10-2017-0062391", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 미리 정의된 키워드를 포함하는 복수의 키워드들을 저장하는 키워드 저장소를 더 포함하고,상기 키워드들 각각은 웨이크업 키워드 또는 단독 명령 키워드인 것을 특징으로 하는 음성 제어 장치."}
{"patent_id": "10-2017-0062391", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서,상기 키워드 검출부에 의해 상기 오디오 스트림 데이터에서 상기 단독 명령 키워드에 대응하는 상기 후보 키워드가 검출된 경우,상기 화자 특징 벡터 추출부는 상기 오디오 스트림 데이터에서 상기 제1 구간의 종점을 시점으로 하는 제3 구간에 해당하는 제3 오디오 데이터를 수신하고, 상기 제3 오디오 데이터의 제3 화자 특징 벡터를 추출하고,상기 웨이크업 판단부는 상기 제1 화자 특징 벡터와 상기 제2 화자 특징 벡터 간의 유사도 및 상기 제1 화자 특징 벡터와 상기 제3 화자 특징 벡터 간의 유사도를 기초로, 상기 제1 오디오 데이터에 상기 단독 명령 키워드가포함되었는지의 여부를 판단하는 것을 특징으로 하는 음성 제어 장치."}
{"patent_id": "10-2017-0062391", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서,상기 웨이크업 판단부는 상기 제1 화자 특징 벡터와 상기 제2 화자 특징 벡터 간의 유사도가 미리 설정한 기준치 이하이고 상기 제1 화자 특징 벡터와 상기 제3 화자 특징 벡터 간의 유사도가 미리 설정한 기준치 이하인 경우에 상기 제1 오디오 데이터에 상기 단독 명령 키워드가 포함되었다고 판단하는 것을 특징으로 음성 제어장치."}
{"patent_id": "10-2017-0062391", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "공개특허 10-2018-0127065-3-제3항에 있어서,상기 키워드 검출부에 의해 상기 오디오 스트림 데이터에서 상기 웨이크업 키워드에 대응하는 상기 후보 키워드가 검출된 경우,상기 웨이크업 판단부에 의한 상기 제1 오디오 데이터에 상기 웨이크업 키워드가 포함되었다는 판단에응답하여, 웨이크업 되고, 상기 오디오 스트림 데이터에서 상기 제1 구간의 종점을 시점으로 하는 제3 구간에해당하는 제3 오디오 데이터를 수신하고, 상기 제3 오디오 데이터를 음성 인식하거나 상기 제3 오디오 데이터가음성 인식되도록 외부에 전송하는 음성 인식부를 더 포함하는 것을 특징으로 하는 음성 제어 장치."}
{"patent_id": "10-2017-0062391", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6항에 있어서,상기 제2 구간은 상기 웨이크업 키워드에 따라 가변적으로 결정되는 것을 특징으로 하는 음성 제어 장치."}
{"patent_id": "10-2017-0062391", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1항에 있어서,상기 화자 특징 벡터 추출부는,상기 제1 오디오 데이터의 각 프레임마다 제1 프레임 특징 벡터를 추출하고, 추출된 상기 제1 프레임 특징 벡터들을 정규화 및 평균화하여 상기 제1 오디오 데이터를 대표하는 상기 제1 화자 특징 벡터를 추출하고,상기 제2 오디오 데이터의 각 프레임마다 제2 프레임 특징 벡터를 추출하고, 추출된 상기 제2 프레임 특징 벡터들을 정규화 및 평균화하여 상기 제2 오디오 데이터를 대표하는 상기 제2 화자 특징 벡터를 추출하는 것을 특징으로 하는 음성 제어 장치."}
{"patent_id": "10-2017-0062391", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1항에 있어서,상기 키워드 검출부는 상기 오디오 스트림 데이터의 각 프레임마다 사람 음성일 제1 확률과 배경음일 제2 확률을 계산하고, 상기 제1 확률이 상기 제2 확률보다 미리 설정된 기준치보다 높은 프레임을 음성 프레임으로 결정하고,상기 화자 특징 벡터 추출부는,상기 제1 오디오 데이터 내의 프레임들 중에서 음성 프레임으로 결정된 프레임들 각각에 대하여 제1 프레임 특징 벡터를 추출하고, 추출된 상기 제1 프레임 특징 벡터들을 정규화 및 평균화하여 상기 제1 오디오 데이터를대표하는 상기 제1 화자 특징 벡터를 추출하고,상기 제2 오디오 데이터 내의 프레임들 중에서 음성 프레임으로 결정된 프레임들 각각에 대하여 제2 프레임 특징 벡터를 추출하고, 추출된 상기 제2 프레임 특징 벡터들을 정규화 및 평균화하여 상기 제2 오디오 데이터를대표하는 상기 제2 화자 특징 벡터를 추출하는 것을 특징으로 하는 음성 제어 장치."}
{"patent_id": "10-2017-0062391", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제1항에 있어서,상기 화자 특징 벡터 추출부는 상기 키워드 검출부에 의한 상기 후보 키워드의 검출에 응답하여 웨이크업 되는것을 특징으로 하는 음성 제어 장치."}
{"patent_id": "10-2017-0062391", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "주변 소리에 대응하는 오디오 신호를 수신하여, 오디오 스트림 데이터를 생성하는 단계;상기 오디오 스트림 데이터로부터 미리 정의된 키워드에 대응하는 후보 키워드를 검출하고, 상기 오디오 스트림데이터에서 상기 후보 키워드가 검출된 제1 오디오 데이터에 해당하는 제1 구간의 시점과 종점을 결정하는단계;공개특허 10-2018-0127065-4-상기 제1 오디오 데이터에 대한 제1 화자 특징 벡터를 추출하는 단계;상기 오디오 스트림 데이터에서 상기 제1 구간의 시점을 종점으로 하는 제2 구간에 해당하는 제2 오디오 데이터에 대한 제2 화자 특징 벡터를 추출하는 단계; 및상기 제1 화자 특징 벡터와 상기 제2 화자 특징 벡터의 유사도를 기초로 상기 제1 오디오 데이터에 상기 키워드가 포함되었는지의 여부를 판단하고, 웨이크업 여부를 결정하는 단계를 포함하는 음성 제어 장치의 동작 방법."}
{"patent_id": "10-2017-0062391", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항에 있어서,상기 웨이크업 여부를 결정하는 단계는, 상기 제1 화자 특징 벡터와 상기 제2 화자 특징 벡터 간의 유사도가 미리 설정한 기준치와 비교하는 단계;상기 유사도가 상기 미리 설정한 기준치 이하인 경우에 상기 제1 오디오 데이터에 상기 키워드가 포함되었다고판단하고 웨이크업 하는 단계; 및 상기 유사도가 상기 미리 설정한 기준치를 초과하는 경우에 상기 제1 오디오 데이터에 상기 키워드가 포함되지않았다고 판단하고 웨이크업을 하지 않는 단계를 포함하는 음성 제어 장치의 동작 방법."}
{"patent_id": "10-2017-0062391", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제11항에 있어서,상기 검출된 후보 키워드가 단독 명령 키워드에 대응하는 상기 후보 키워드인 경우,상기 오디오 스트림 데이터에서 상기 제1 구간의 종점을 시점으로 하는 제3 구간에 해당하는 제3 오디오 데이터를 수신하는 단계;상기 제3 오디오 데이터의 제3 화자 특징 벡터를 추출하는 단계;상기 제1 화자 특징 벡터와 상기 제2 화자 특징 벡터 간의 유사도가 미리 설정한 기준치 이하이고 상기 제1 화자 특징 벡터와 상기 제3 화자 특징 벡터 간의 유사도가 미리 설정한 기준치 이하인 경우에, 상기 제1 오디오데이터에 상기 단독 명령 키워드가 포함되었다고 판단하는 단계를 더 포함하는 음성 제어 장치의 동작 방법."}
{"patent_id": "10-2017-0062391", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제13항에 있어서,상기 제1 오디오 데이터에 상기 단독 명령 키워드가 포함되었다는 판단에 응답하여, 상기 단독 명령 키워드에대응하는 기능을 수행하는 단계를 더 포함하는 음성 제어 장치의 동작 방법."}
{"patent_id": "10-2017-0062391", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제11항에 있어서,상기 검출된 키워드가 웨이크업 키워드에 대응하는 상기 후보 키워드인 경우,상기 제1 오디오 데이터에 상기 웨이크업 키워드가 포함되었다는 판단에 응답하여, 상기 오디오 스트림 데이터에서 상기 제1 구간의 종점을 시점으로 하는 제3 구간에 해당하는 제3 오디오 데이터를 수신하는 단계; 및 상기 제3 오디오 데이터를 음성 인식하거나 상기 제3 오디오 데이터가 음성 인식되도록 외부에 전송하는 단계를더 포함하는 음성 제어 장치의 동작 방법."}
{"patent_id": "10-2017-0062391", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제11항에 있어서,상기 제1 화자 특징 벡터와 상기 제2 화자 특징 벡터를 추출하는 단계는,상기 제1 오디오 데이터의 각 프레임마다 제1 프레임 특징 벡터를 추출하는 단계;추출된 상기 제1 프레임 특징 벡터들을 정규화 및 평균화하여 상기 제1 오디오 데이터를 대표하는 상기 제1 화공개특허 10-2018-0127065-5-자 특징 벡터를 추출하는 단계;상기 제2 오디오 데이터의 각 프레임마다 제2 프레임 특징 벡터를 추출하는 단계; 및 추출된 상기 제2 프레임 특징 벡터들을 정규화 및 평균화하여 상기 제2 오디오 데이터를 대표하는 상기 제2 화자 특징 벡터를 추출하는 단계를 포함하는 것을 특징으로 하는 음성 제어 장치의 동작 방법."}
{"patent_id": "10-2017-0062391", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제11항에 있어서,상기 오디오 스트림 데이터의 각 프레임마다 사람 음성일 제1 확률과 배경음일 제2 확률을 계산하고, 상기 제1확률이 상기 제2 확률보다 미리 설정된 기준치보다 높은 프레임을 음성 프레임으로 결정하는 단계를 더 포함하고,상기 제1 화자 특징 벡터와 상기 제2 화자 특징 벡터를 추출하는 단계는,상기 제1 오디오 데이터 내의 프레임들 중에서 음성 프레임으로 결정된 프레임들 각각에 대하여 제1 프레임 특징 벡터를 추출하는 단계; 추출된 상기 제1 프레임 특징 벡터들을 정규화 및 평균화하여 상기 제1 오디오 데이터를 대표하는 상기 제1 화자 특징 벡터를 추출하는 단계;상기 제2 오디오 데이터 내의 프레임들 중에서 음성 프레임으로 결정된 프레임들 각각에 대하여 제2 프레임 특징 벡터를 추출하는 단계; 및 추출된 상기 제2 프레임 특징 벡터들을 정규화 및 평균화하여 상기 제2 오디오 데이터를 대표하는 상기 제2 화자 특징 벡터를 추출하는 단계를 포함하는 것을 특징으로 하는 음성 제어 장치의 동작 방법."}
{"patent_id": "10-2017-0062391", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "음성 제어 장치의 프로세서가 제11항 내지 제18항 중 어느 한 항의 동작 방법을 실행하도록 하는 명령어들을 포함하는 하나 이상의 프로그램이 기록된 컴퓨터로 읽을 수 있는 기록 매체."}
{"patent_id": "10-2017-0062391", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "키워드 오인식을 방지할 수 있는 음성 제어 장치 및 이의 동작 방법이 제공된다. 상기 동작 방법은, 주변 소리 에 대응하는 오디오 신호를 수신하여, 오디오 스트림 데이터를 생성하는 단계; 상기 오디오 스트림 데이터로부터 미리 정의된 키워드에 대응하는 후보 키워드를 검출하고, 상기 오디오 스트림 데이터에서 상기 후보 키워드가 검 출된 제1 오디오 데이터에 해당하는 제1 구간의 시점과 종점을 결정하는 단계; 상기 제1 오디오 데이터에 대한 제1 화자 특징 벡터를 추출하는 단계; 상기 오디오 스트림 데이터에서 상기 제1 구간의 시점을 종점으로 하는 제 2 구간에 해당하는 제2 오디오 데이터에 대한 제2 화자 특징 벡터를 추출하는 단계; 및 상기 제1 화자 특징 벡터 와 상기 제2 화자 특징 벡터의 유사도를 기초로 상기 제1 오디오 데이터에 상기 키워드가 포함되었는지의 여부를 판단하고, 웨이크업 여부를 결정하는 단계를 포함한다."}
{"patent_id": "10-2017-0062391", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 음성 제어 장치에 관한 것으로서, 보다 상세하게는 키워드를 잘못 인식하는 것을 방지할 수 있는 음 성 제어 장치 및 이의 동작 방법에 관한 것이다."}
{"patent_id": "10-2017-0062391", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "휴대용 통신 장치, 데스크톱, 태블릿, 및 엔터테인먼트 시스템들과 같은 컴퓨팅 장치들의 성능이 고도화면서, 조작성을 향상시키기 위하여 음성 인식 기능이 탑재되어 음성에 의해 제어되는 전자 기기들이 출시되고 있다. 음성 인식 기능은 별도의 버튼 조작 또는 터치 모듈의 접촉에 의하지 않고 사용자의 음성을 인식함으로써 장치 를 손쉽게 제어할 수 있는 장점을 가진다. 이러한 음성 인식 기능에 의하면, 예를 들어 스마트 폰과 같은 휴대용 통신 장치에서는 별도의 버튼을 누르는 조작 없이 통화 기능을 수행하거나 문자 메시지를 작성할 수 있으며, 길찾기, 인터넷 검색, 알람 설정 등 다양 한 기능을 손쉽게 설정할 수 있다. 그러나, 이러한 음성 제어 장치가 사용자의 음성을 오인식하여 의도하지 않 은 동작을 수행하는 문제가 발생할 수 있다."}
{"patent_id": "10-2017-0062391", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "일 실시예는 키워드를 오인식하는 것을 방지할 수 있는 음성 제어 장치 및 이의 동작 방법을 제공할 수 있다."}
{"patent_id": "10-2017-0062391", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상술한 기술적 과제를 달성하기 위한 기술적 수단으로서, 본 개시의 제1 측면은, 주변 소리에 대응하는 오디오 신호를 수신하여, 오디오 스트림 데이터를 생성하는 오디오 처리부; 상기 오디오 스트림 데이터로부터 미리 정 의된 키워드에 대응하는 후보 키워드를 검출하고, 상기 오디오 스트림 데이터에서 상기 후보 키워드가 검출된 제1 오디오 데이터에 해당하는 제1 구간의 시점과 종점을 결정하는 키워드 검출부; 상기 제1 오디오 데이터에 대한 제1 화자 특징 벡터를 추출하고, 상기 오디오 스트림 데이터에서 상기 제1 구간의 시점을 종점으로 하는 제2 구간에 해당하는 제2 오디오 데이터에 대한 제2 화자 특징 벡터를 추출하는 화자 특징 벡터 추출부; 및 상 기 제1 화자 특징 벡터와 상기 제2 화자 특징 벡터의 유사도를 기초로 상기 제1 오디오 데이터에 상기 키워드가 포함되었는지의 여부를 판단하는 웨이크업 판단부를 포함하는 음성 제어 장치를 제공할 수 있다. 또한, 본 개시의 제2 측면은, 주변 소리에 대응하는 오디오 신호를 수신하여, 오디오 스트림 데이터를 생성하는 단계; 상기 오디오 스트림 데이터로부터 미리 정의된 키워드에 대응하는 후보 키워드를 검출하고, 상기 오디오 스트림 데이터에서 상기 후보 키워드가 검출된 제1 오디오 데이터에 해당하는 제1 구간의 시점과 종점을 결정하 는 단계; 상기 제1 오디오 데이터에 대한 제1 화자 특징 벡터를 추출하는 단계; 상기 오디오 스트림 데이터에서 상기 제1 구간의 시점을 종점으로 하는 제2 구간에 해당하는 제2 오디오 데이터에 대한 제2 화자 특징 벡터를 추출하는 단계; 및 상기 제1 화자 특징 벡터와 상기 제2 화자 특징 벡터의 유사도를 기초로 상기 제1 오디오 데 이터에 상기 키워드가 포함되었는지의 여부를 판단하고, 웨이크업 여부를 결정하는 단계를 포함하는 음성 제어 장치의 동작 방법을 제공할 수 있다. 또한, 본 개시의 제3 측면은, 음성 제어 장치의 프로세서가 제2 측면에 따른 동작 방법을 실행하도록 하는 명령 어들을 포함하는 하나 이상의 프로그램이 기록된 컴퓨터로 읽을 수 있는 기록 매체를 제공할 수 있다."}
{"patent_id": "10-2017-0062391", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 개시의 다양한 실시예들에 따르면, 키워드를 오인식할 가능성이 감소되므로 음성 제어 장치의 오동작이 방지 될 수 있다."}
{"patent_id": "10-2017-0062391", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "아래에서는 첨부한 도면을 참조하여 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자가 용이하게 실시할 수 있도록 본 발명의 실시예를 상세히 설명한다. 그러나 본 발명은 여러 가지 상이한 형태로 구현될 수 있으며 여기에서 설명하는 실시예에 한정되지 않는다. 그리고 도면에서 본 발명을 명확하게 설명하기 위해서 설명과 관계없는 부분은 생략하였으며, 명세서 전체를 통하여 유사한 부분에 대해서는 유사한 도면 부호를 붙였다. 명세서 전체에서, 어떤 부분이 다른 부분과 \"연결\"되어 있다고 할 때, 이는 \"직접적으로 연결\"되어 있는 경우뿐 아니라, 그 중간에 다른 소자를 사이에 두고 \"전기적으로 연결\"되어 있는 경우도 포함한다. 또한 어떤 부분이 어떤 구성요소를 \"포함\"한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다른 구성요소를 제외하는 것이 아 니라 다른 구성요소를 더 포함할 수 있는 것을 의미한다. 본 명세서에서 다양한 곳에 등장하는 \"일부 실시예에서\" 또는 \"일 실시예에서\" 등의 어구는 반드시 모두 동일한 실시예를 가리키는 것은 아니다. 일부 실시예는 기능적인 블럭 구성들 및 다양한 처리 단계들로 나타내어질 수 있다. 이러한 기능 블럭들의 일 부 또는 전부는, 특정 기능들을 실행하는 다양한 개수의 하드웨어 및/또는 소프트웨어 구성들로 구현될 수 있다. 예를 들어, 본 개시의 기능 블럭들은 하나 이상의 마이크로프로세서들에 의해 구현되거나, 소정의 기능 을 위한 회로 구성들에 의해 구현될 수 있다. 또한, 예를 들어, 본 개시의 기능 블럭들은 다양한 프로그래밍 또는 스크립팅 언어로 구현될 수 있다. 기능 블럭들은 하나 이상의 프로세서들에서 실행되는 알고리즘으로 구 현될 수 있다. 또한, 본 개시는 전자적인 환경 설정, 신호 처리, 및/또는 데이터 처리 등을 위하여 종래 기술 을 채용할 수 있다. “모듈” 및 “구성”등과 같은 용어는 넓게 사용될 수 있으며, 기계적이고 물리적인 구성 들로서 한정되는 것은 아니다. 또한, 도면에 도시된 구성 요소들 간의 연결 선 또는 연결 부재들은 기능적인 연결 및/또는 물리적 또는 회로적 연결들을 예시적으로 나타낸 것일 뿐이다. 실제 장치에서는 대체 가능하거나 추가된 다양한 기능적인 연결, 물 리적인 연결, 또는 회로 연결들에 의해 구성 요소들 간의 연결이 나타내어질 수 있다. 본 개시에서 키워드는 음성 제어 장치의 특정 기능을 웨이크업 할 수 있는 음성 정보를 말한다. 키워드는 사용 자의 음성 신호에 기초하며, 단독 명령 키워드일 수도 있고, 웨이크업 키워드일 수 있다. 웨이크업 키워드는 슬립 모드 상태의 음성 제어 장치를 웨이크업 모드로 전환할 수 있는 음성 기반 키워드로서, 예컨대, “클로바 ”, “하이 컴퓨터” 등과 같은 음성 키워드일 수 있다. 사용자는 웨이크업 키워드를 발화한 후, 음성 제어 장 치가 수행하길 원하는 기능이나 동작을 지시하기 위한 명령을 자연어 형태로 발화할 수 있다. 이 경우, 음성 제어 장치는 자연어 형태의 음성 명령을 음성 인식하고, 음성 인식된 결과에 대응하는 기능 또는 동작을 수행할 수 있다. 단독 명령 키워드는 예컨대 음악이 재생 중인 경우 “중지”와 같이 음성 제어 장치의 동작을 직접 제어할 수 있는 음성 키워드일 수 있다. 본 개시에서 언급되는 웨이크업 키워드는 웨이크업 워드, 핫워드, 트 리거 워드 등과 같은 용어로 지칭될 수 있다. 본 개시에서 후보 키워드는 키워드와 발음이 유사한 워드들을 포함한다. 예컨대, 키워드가 “클로바”인 경우, 후보 키워드는 “클로버”, “글로벌”, “클럽” 등일 수 있다. 후보 키워드는 음성 제어 장치의 키워드 검출 부가 오디오 데이터에서 키워드로서 검출한 것으로 정의될 수 있다. 후보 키워드는 키워드와 동일할 수도 있지 만, 키워드와 유사한 발음을 갖는 다른 워드일 수도 있다. 일반적으로 음성 제어 장치는 사용자가 후보 키워드 에 해당하는 용어가 포함된 문장을 발화하는 경우에도 해당 키워드로 오인식하여 웨이크업 할 수 있다. 본 개 시에 따른 음성 제어 장치는 음성 신호에서 위와 같은 후보 키워드가 검출되는 경우에도 반응하지만, 후보 키워 드에 의해 웨이크업 되는 것을 방지할 수 있다. 본 개시에서 음성 인식 기능은 사용자의 음성 신호를 문자열(또는 텍스트)로 변환하는 것을 말한다. 사용자의 음성 신호는 음성 명령을 포함할 수 있다. 음성 명령은 음성 제어 장치의 특정 기능을 실행할 수 있다. 본 개시에서 음성 제어 장치는 음성 제어 기능이 탑재된 전자 기기를 말한다. 음성 제어 기능이 탑재된 전자 기기는 스마트 스피커 또는 인공 지능 스피커와 같은 독립된 전자 기기일 수 있다. 또한, 음성 제어 기능이 탑 재된 전자 기기는 음성 제어 기능이 탑재된 컴퓨팅 장치, 예컨대, 데스크톱, 노트북 등일 수 있을 뿐만 아니라, 휴대가 가능한 컴퓨터 장치, 예컨대, 스마트 폰 등일 수 있다. 이 경우, 컴퓨팅 장치에는 음성 제어 기능을 실 행하기 위한 프로그램 또는 애플리케이션이 설치될 수 있다. 또한, 음성 제어 기능이 탑재된 전자 기기는 특정 기능을 주로 수행하는 전자 제품, 예컨대, 스마트 텔레비전, 스마트 냉장고, 스마트 에어컨, 스마트 네비게이션 등일 수 있으며, 자동차의 인포테인먼트 시스템일 수도 있다. 뿐만 아니라, 음성에 의해 제어될 수 있는 사물 인터넷 장치도 이에 해당할 수 있다. 본 개시에서 음성 제어 장치의 특정 기능은, 예를 들어, 음성 제어 장치에 설치된 애플리케이션을 실행하는 것 을 포함할 수 있으나 이로 제한되지 않는다. 예를 들어, 음성 제어 장치가 스마트 스피커인 경우, 음성 제어 장치의 특정 기능은 음악 재생, 인터넷 쇼핑, 음성 정보 제공, 스마트 스피커에 접속된 전자 또는 기계 장치의 제어 등을 포함할 수 있다. 예를 들어, 음성 제어 장치가 스마트 폰인 경우에, 애플리케이션을 실행하는 것은 전화 걸기, 길 찾기, 인터넷 검색, 또는 알람 설정 등을 포함할 수 있다. 예를 들어, 음성 제어 장치가 스마트텔레비전인 경우에, 애플리케이션을 실행하는 것은 프로그램 검색, 또는 채널 검색 등을 포함할 수 있다. 음성 제어 장치가 스마트 오븐인 경우에, 애플리케이션을 실행하는 것은 요리 방법 검색 등을 포함할 수 있다. 음성 제어 장치가 스마트 냉장고인 경우에, 애플리케이션을 실행하는 것은 냉장 및 냉동 상태 점검, 또는 온도 설정 등을 포함할 수 있다. 음성 제어 장치가 스마트 자동차인 경우에, 애플리케이션을 실행하는 것은 자동 시동, 자율 주행, 자동 주차 등을 포함할 수 있다. 본 개시에서 애플리케이션을 실행하는 것은 상술한 바로 제한되지 않는다. 본 개시에서 키워드는 워드 형태를 갖거나, 구 형태를 가질 수 있다. 본 개시에서, 웨이크업 키워드 이후에 발 화되는 음성 명령은 자연어 형태의 문장 형태, 워드 형태, 또는 구 형태를 가질 수 있다. 이하 첨부된 도면을 참고하여 본 개시를 상세히 설명하기로 한다. 도 1은 일 실시예에 따른 네트워크 환경의 예를 도시한 도면이다. 도 1에 도시된 네트워크 환경은 복수의 전자 기기들(100a-100f), 서버 및 네트워크를 포함하는 것으 로 예시적으로 도시된다. 전자 기기들(100a-100f)은 음성으로 제어될 수 있는 예시적인 전자 기기들이다. 전자 기기들(100a-100f) 각각 은 음성 인식 기능 외에 특정 기능을 실행할 수 있다. 전자 기기들(100a-100f)의 예를 들면, 스마트 또는 인공 지능 스피커, 스마트 폰(smart phone), 휴대폰, 네비게이션, 컴퓨터, 노트북, 디지털방송용 단말, PDA(Personal Digital Assistants), PMP(Portable Multimedia Player), 태블릿 PC, 스마트 전자 제품 등이 있다. 전자 기 기들(100a-100f)은 무선 또는 유선 통신 방식을 이용하여 네트워크를 통해 서버 및/또는 다른 전자 기기들(100a-100f)과 통신할 수 있다. 그러나, 이에 한정되지 않으며, 전자 기기들(100a-100f) 각각은 네트워 크에 연결되지 않고 독립적으로 동작할 수도 있다. 전자 기기들(100a-100f)은 전자 기기로 통칭될 수 있다. 네트워크의 통신 방식은 제한되지 않으며, 네트워크가 포함할 수 있는 통신망(일례로, 이동통신망, 유선 인터넷, 무선 인터넷, 방송망)을 활용하는 통신 방식뿐만 아니라, 전자 기기들(100a-100f) 간의 근거리 무 선 통신이 포함될 수 있다. 예를 들어, 네트워크는, PAN(personal area network), LAN(local area network), CAN(campus area network), MAN(metropolitan area network), WAN(wide area network), BBN(broadband network), 인터넷 등의 네트워크 중 하나 이상의 임의의 네트워크를 포함할 수 있다. 또한, 네 트워크는 버스 네트워크, 스타 네트워크, 링 네트워크, 메쉬 네트워크, 스타-버스 네트워크, 트리 또는 계 층적(hierarchical) 네트워크 등을 포함하는 네트워크 토폴로지 중 임의의 하나 이상을 포함할 수 있으나, 이에 제한되지 않는다. 서버는 네트워크를 통해 전자 기기들(100a-100f)과 통신하며, 음성 인식 기능을 수행하는 컴퓨터 장 치 또는 복수의 컴퓨터 장치들로 구현될 수 있다. 서버는 클라우드 형태로 분산될 수 있으며, 명령, 코드, 파일, 컨텐츠 등을 제공할 수 있다. 예를 들면, 서버는 전자 기기들(100a-100f)로부터 제공되는 오디오 파일을 수신하여 오디오 파일 내의 음 성 신호를 문자열(또는 텍스트)로 변환하고, 변환된 문자열(또는 텍스트)를 전자 기기들(100a-100f)로 제공할 수 있다. 또한, 서버는 네트워크를 통해 접속한 전자 기기들(100a-100f)에게 음성 제어 기능을 수행 하기 위한 어플리케이션의 설치를 위한 파일을 제공할 수 있다. 예컨대, 제2 전자 기기(100b)는 서버로부 터 제공된 파일을 이용하여 어플리케이션을 설치할 수 있다. 제2 전자 기기(100b)는 설치된 운영체제 (Operating System, OS) 및/또는 적어도 하나의 프로그램(예컨대, 설치된 음성 제어 어플리케이션)의 제어에 따 라 서버에 접속하여 서버가 제공하는 음성 인식 서비스를 제공받을 수 있다. 도 2는 일 실시예에 따라서 전자 기기 및 서버의 내부 구성을 설명하기 위한 블럭도이다. 전자 기기는 도 1의 전자 기기들(100a-100f) 중 하나이며, 전자 기기들(100a-100f)은 적어도 도 2에 도시 된 내부 구성을 가질 수 있다. 전자 기기는 네트워크를 통해 음성 인식 기능을 수행하는 서버 에 접속되는 것으로 도시되어 있지만, 이는 예시적이며, 전자 기기는 독립적으로 음성 인식 기능을 수행할 수도 있다. 전자 기기는 음성에 의해 제어될 수 있는 전자 기기로서, 음성 제어 장치로 지칭될 수 있다. 음성 제어 장치는 스마트 또는 인공지능 스피커, 컴퓨팅 장치, 휴대용 컴퓨팅 장치, 스마트 가전 제품 등에 포함되거나, 이들에 유선 및/또는 무선으로 연결되도록 구현될 수 있다. 전자 기기와 서버는 메모리(110, 210), 프로세서(120, 220), 통신 모듈(130, 230), 및 입출력 인터 페이스(140, 240)를 포함할 수 있다. 메모리(110, 210)는 컴퓨터에서 판독 가능한 기록 매체로서, RAM(random access memory), ROM(read only memory) 및 디스크 드라이브와 같은 비소멸성 대용량 기록장치(permanent mass storage device)를 포함할 수 있다. 또한, 메모리(110, 210)에는 운영체제와 적어도 하나의 프로그램 코드(예 컨대, 전자 기기에 설치되어 구동되는 음성 제어 어플리케이션, 음성 인식 어플리케이션 등을 위한 코드) 가 저장될 수 있다. 이러한 소프트웨어 구성요소들은 컴퓨터에서 판독 가능한 기록 매체가 아닌 통신 모듈 (130, 230)을 통해 메모리(110, 210)에 로딩될 수도 있다. 예를 들어, 적어도 하나의 프로그램은 개발자들 또 는 어플리케이션의 설치 파일을 배포하는 파일 배포 시스템이 네트워크를 통해 제공하는 파일들에 의해 설 치되는 프로그램에 기반하여 메모리(110, 210)에 로딩될 수 있다. 프로세서(120, 220)는 기본적인 산술, 로직 및 입출력 연산을 수행함으로써, 컴퓨터 프로그램의 명령을 처리하 도록 구성될 수 있다. 명령은 메모리(110, 210) 또는 통신 모듈(130, 230)에 의해 프로세서(120, 220)로 제공 될 수 있다. 예를 들어 프로세서(120, 220)는 메모리(110, 210)와 같은 기록 장치에 저장된 프로그램 코드에 따라 수신되는 명령을 실행하도록 구성될 수 있다. 통신 모듈(130, 230)은 네트워크를 통해 전자 기기와 서버가 서로 통신하기 위한 기능을 제공할 수 있으며, 다른 전자 기기(100b-100f)와 통신하기 위한 기능을 제공할 수 있다. 일례로, 전자 기기의 프 로세서가 메모리와 같은 기록 장치에 저장된 프로그램 코드에 따라 생성한 요청(일례로 음성 인식 서 비스 요청)이 통신 모듈의 제어에 따라 네트워크를 통해 서버로 전달될 수 있다. 역으로, 서버 의 프로세서의 제어에 따라 제공되는 음성 인식 결과인 문자열(텍스트) 등이 통신 모듈과 네트 워크를 거쳐 전자 기기의 통신 모듈을 통해 전자 기기로 수신될 수 있다. 예를 들어 통신 모듈을 통해 수신된 서버의 음성 인식 결과는 프로세서나 메모리로 전달될 수 있다. 서버 는 제어 신호나 명령, 컨텐츠, 파일 등을 전자 기기로 송신할 수 있으며, 통신 모듈을 통해 수 신된 제어 신호나 명령 등은 프로세서나 메모리로 전달되고, 컨텐츠나 파일 등은 전자 기기가 더 포함할 수 있는 별도의 저장 매체로 저장될 수 있다. 입출력 인터페이스(140, 240)는 입출력 장치들과의 인터페이스를 위한 수단일 수 있다. 예를 들어, 입력 장치는 마이크뿐만 아니라, 키보드 또는 마우스 등의 장치를 포함할 수 있으며, 출력 장치는 스피커 뿐만 아니라, 상태를 나타내는 상태 표시 LED(Light Emitting Diode), 어플리케이션의 통신 세션을 표시하기 위 한 디스플레이와 같은 장치를 포함할 수 있다. 다른 예로서, 입출력 장치들은 터치스크린과 같이 입력과 출력을 위한 기능이 하나로 통합된 장치를 포함할 수 있다. 마이크는 주변 소리를 전기적인 오디오 신호로 변환할 수 있다. 마이크는 전자 기기 내에 직접 장착되지 않고, 통신 가능하게 연결되는 외부 장치(예컨대, 스마트 시계)에 장착되고, 생성된 외부 신호는 통신 으로 전자 기기에 전송될 수 있다. 도 2에는, 마이크가 전자 기기의 내부에 포함되는 것으로 도시되었으나, 다른 일 실시예에 따르면, 마이크는 별도의 장치 내에 포함되고, 전자 기기와는 유선 또는 무선 통신으로 연결되는 형태로 구현될 수 있다. 다른 실시예들에서 전자 기기 및 서버는 도 2의 구성요소들보다 더 많은 구성요소들을 포함할 수도 있다. 예를 들어, 전자 기기는 전술한 입출력 장치들 중 적어도 일부를 포함하도록 구성되거나, 트 랜시버(transceiver), GPS(Global Positioning System) 모듈, 카메라, 각종 센서, 데이터베이스 등과 같은 다 른 구성요소들을 더 포함할 수도 있다. 도 3은 일 실시예에 따른 음성 제어 장치의 프로세서가 포함할 수 있는 기능 블럭들의 예를 도시한 도면이고, 도 4는 일 실시예에 따라서 음성 제어 장치가 수행할 수 있는 동작 방법의 예를 도시한 흐름도이다. 도 3에 도시된 바와 같이, 음성 제어 장치의 프로세서는 오디오 처리부, 키워드 검출부, 화자 특징 벡터 추출부, 웨이크업 판단부, 음성 인식부 및 기능부를 포함할 수 있다. 이 러한 프로세서 및 기능 블럭들(121-126) 중 적어도 일부는 도 4에 도시된 동작 방법이 포함하는 단계들 (S110 내지 S190)을 수행하도록 음성 제어 장치를 제어할 수 있다. 예를 들면, 프로세서 및 프로세 서의 기능 블럭들(121-126) 중 적어도 일부는 음성 제어 장치의 메모리가 포함하는 운영체제의 코드와 적어도 하나의 프로그램 코드에 따른 명령을 실행하도록 구현될 수 있다. 도 3에 도시된 기능 블럭들(121-126)의 일부 또는 전부는, 특정 기능을 실행하는 하드웨어 및/또는 소프트웨어 구성들로 구현될 수 있다. 도 3에 도시된 기능 블럭들(121-126)이 수행하는 기능들은, 하나 이상의 마이크로프 로세서에 의해 구현되거나, 해당 기능을 위한 회로 구성들에 의해 구현될 수 있다. 도 3에 도시된 기능 블럭들(121-126)의 일부 또는 전부는 프로세서에서 실행되는 다양한 프로그래밍 언어 또는 스크립트 언어로 구성 된 소프트웨어 모듈일 수 있다. 예를 들면, 오디오 처리부와 키워드 검출부는 디지털 신호 처리기 (DSP)로 구현되고, 화자 특징 벡터 추출부, 웨이크업 판단부 및 음성 인식부는 소프트웨어 모듈 로 구현될 수 있다. 오디오 처리부는 주변 소리에 대응하는 오디오 신호를 수신하여, 오디오 스트림 데이터를 생성한다. 오디 오 처리부는 마이크와 같은 입력장치로부터 주변 소리에 대응하는 오디오 신호를 수신할 수 있다. 마이크는 음성 제어 장치에 통신으로 연결되는 주변 장치에 포함되고, 오디오 처리부는 마이크 에서 생성된 오디오 신호를 통신으로 수신할 수 있다. 주변 소리는 사용자가 발화한 음성뿐만 아니라, 배 경음을 포함한다. 따라서, 오디오 신호에는 음성 신호뿐만 아니라 배경음 신호도 포함된다. 배경음 신호는 키 워드 검출 및 음성 인식에서 노이즈에 해당할 수 있다. 오디오 처리부는 연속적으로 수신되는 오디오 신호에 대응하는 오디오 스트림 데이터를 생성할 수 있다. 오디오 처리부는 오디오 신호를 필터링하고 디지털화하여 오디오 스트림 데이터를 생성할 수 있다. 오디 오 처리부는 오디오 신호를 필터링하여 노이즈 신호를 제거하고 배경음 신호에 비해 음성 신호를 증폭할 수 있다. 또한, 오디오 처리부는 오디오 신호에서 음성 신호의 에코를 제거할 수도 있다. 오디오 처리부는 음성 제어 장치가 슬립 모드로 동작할 때에도 오디오 신호를 수신하기 위해 항상 동 작할 수 있다. 오디오 처리부는 음성 제어 장치가 슬립 모드로 동작할 때 낮은 동작 주파수로 동작 하고, 음성 제어 장치가 정상 모드로 동작할 때에는 높은 동작 주파수로 동작할 수 있다. 메모리는 오디오 처리부에서 생성된 오디오 스트림 데이터를 일시적으로 저장할 수 있다. 오디오 처 리부는 메모리를 이용하여 오디오 스트림 데이터를 버퍼링할 수 있다. 메모리에는 키워드를 포 함하는 오디오 데이터뿐만 아니라 키워드가 검출되기 전의 오디오 데이터가 함께 저장된다. 최근의 오디오 데이 터를 메모리에 저장하기 위해, 메모리에 가장 오래 전에 저장된 오디오 데이터가 삭제될 수 있다. 메모리에 할당한 크기가 동일하다면, 언제나 동일한 기간의 오디오 데이터가 저장될 수 있다. 메모리 에 저장된 오디오 데이터에 해당하는 상기 기간은 키워드를 발성하는 시간보다 긴 것이 바람직하다. 본 발명의 또다른 실시예에 따르면, 메모리는 오디오 처리부에서 생성된 오디오 스트림에 대한 화자 특징 벡터를 추출하여 저장할 수 있다. 이 때 화자 특징 벡터는 특정 길이의 오디오 스트림에 대하여 추출하여 저장될 수 있다. 앞서 설명한 바와 같이, 최근에 생성된 오디오 스트림에 대한 화자 특징 벡터를 저장하기 위 하여 가장 오래 저장된 화자 특징 벡터가 삭제될 수 있다. 키워드 검출부는 오디오 처리부에서 생성된 오디오 스트림 데이터로부터 미리 정의된 키워드에 대응 하는 후보 키워드를 검출한다. 키워드 검출부는 메모리에 일시적으로 저장된 오디오 스트림 데이터 로부터 미리 정의된 키워드에 대응하는 후보 키워드를 검출할 수 있다. 미리 정의된 키워드는 복수일 수 있으 며, 복수의 미리 정의된 키워드들은 키워드 저장소(110a)에 저장될 수 있다. 키워드 저장소(110a)는 메모리 에 포함될 수 있다. 후보 키워드는 키워드 검출부에서 오디오 스트림 데이터 중에서 키워드로서 검출한 것을 의미한다. 후보 키워드는 키워드와 동일할 수도 있고, 키워드와 유사하게 발음되는 다른 단어일 수 있다. 예컨대, 키워드가 “ 클로바”인 경우, 후보 키워드는 “글로벌”일 수 있다. 즉, 사용자가 “글로벌”을 포함한 문장을 발성한 경 우, 키워드 검출부는 오디오 스트림 데이터에서 “글로벌”을 “클로바”로 오인하여 검출할 수 있다. 이 렇게 검출된 “글로벌”은 후보 키워드에 해당한다. 키워드 검출부는 오디오 스트림 데이터를 알려진 키워드 데이터와 비교하여, 오디오 스트림 데이터 내에 키워드에 대응하는 음성이 포함될 가능성을 계산할 수 있다. 키워드 검출부는 오디오 스트림 데이터로부 터 필터뱅크 에너지(Filter Bank Energy) 또는 멜 주파수 켑스트럼 계수(Mel-Frequency Cepstral Coefficients)와 같은 오디오 특징들을 추출할 수 있다. 키워드 검출부는 분류 윈도우(classifying window)들을 이용하여, 예를 들어 서포트 벡터 머신(support vector machine) 또는 신경망(neural network)을 이용하여 이러한 오디오 특징들을 처리할 수 있다. 오디오 특징들의 처리에 기초하여, 키워드 검출부는 오디오 스트림 데이터 내에 키워드가 포함될 가능성을 계산할 수 있다. 키워드 검출부는 상기 가능성이 미리 설정한 기준치보다 높은 경우, 오디오 스트림 데이터 내에 키워드가 포함되어 있다고 판단함으로써 후보 키워드를 검출할 수 있다. 키워드 검출부는 키워드 데이터에 대응하는 음성 샘플들을 이용하여 인공 신경망을 생성하고, 생성된 신경 망을 이용하여 오디오 스트림 데이터에서 키워드를 검출하도록 트레이닝 될 수 있다. 키워드 검출부는 오 디오 스트림 데이터 내의 프레임마다 각 각 키워드를 구성하는 음소의 확률 또는 키워드의 전체적인 확률을 계 산할 수 있다. 키워드 검출부는 오디오 스트림 데이터로부터 각 음소들에 해당할 확률 시퀀스 또는 키워 드 자체의 확률을 출력할 수 있다. 이 시퀀스 또는 확률을 기초로 키워드 검출부는 오디오 스트림 데이터 내에 키워드가 포함될 가능성을 계산할 수 있으며, 그 가능성이 미리 설정된 기준치 이상인 경우에 후보 키워드 가 검출된 것으로 판단할 수 있다. 전술한 방식은 예시적이며, 키워드 검출부의 동작은 다양한 방식을 통 해 구현될 수 있다. 또한, 키워드 검출부는 오디오 스트림 데이터 내의 프레임마다 오디오 특징들을 추출함으로써 해당 프레임 의 오디오 데이터가 사람의 음성에 해당할 가능성과 배경음에 해당할 가능성을 산출할 수 있다. 키워드 검출부 는 사람의 음성에 해당할 가능성과 배경음에 해당할 가능성을 비교하여, 해당 프레임의 오디오 데이터가 사람의 음성에 해당한다고 판단할 수 있다. 예컨대, 키워드 검출부는 해당 프레임의 오디오 데이터가 사 람의 음성에 해당할 가능성이 배경음에 해당할 가능성보다 미리 설정한 기준치보다 높은 경우에, 해당 프레임의 오디오 데이터가 사람의 음성에 대응한다고 판단할 수 있다. 키워드 검출부는 오디오 스트림 데이터에서 후보 키워드가 검출된 구간을 특정할 수 있으며, 후보 키워드 가 검출된 구간의 시점과 종점을 결정할 수 있다. 오디오 스트림 데이터에서 후보 키워드가 검출된 구간은 키 워드 검출 구간, 현재 구간, 또는 제1 구간으로 지칭될 수 있다. 오디오 스트림 데이터에서 제1 구간에 해당하 는 오디오 데이터는 제1 오디오 데이터로 지칭한다. 키워드 검출부는 후보 키워드가 검출된 구간의 끝을 종점으로 결정할 수 있다. 다른 예에 따르면, 키워드 검출부는 후보 키워드가 검출된 후 미리 설정한 시 간(예컨대, 0.5초) 동안의 묵음이 발생할 때까지 기다린 후, 제1 구간에 묵음 구간이 포함되도록 제1 구간의 종 점을 결정하거나 묵음 기간이 포함되지 않도록 제1 구간의 종점을 결정할 수 있다. 화자 특징 벡터 추출부는 메모리에 일시적으로 저장된 오디오 스트림 데이터에서 제2 구간에 해당하 는 제2 오디오 데이터를 메모리로부터 독출한다. 제2 구간은 제1 구간의 이전 구간으로서, 제2 구간의 종 점은 제1 구간의 시점과 동일할 수 있다. 제2 구간은 이전 구간으로 지칭될 수 있다. 제2 구간의 길이는 검출 된 후보 키워드에 대응하는 키워드에 따라 가변적으로 설정될 수 있다. 다른 예에 따르면, 제2 구간의 길이는 고정적으로 설정될 수 있다. 또 다른 예에 따르면, 제2 구간의 길이는 키워드 검출 성능이 최적화되도록 적응 적으로 가변될 수 있다. 예를 들면, 마이크가 출력하는 오디오 신호가 “네잎 클로버”이고, 후보 키워드 가 “클로버”인 경우, 제2 오디오 데이터는 “네잎”이라는 음성에 대응할 수 있다. 화자 특징 벡터 추출부는 제1 구간에 해당하는 제1 오디오 데이터의 제1 화자 특징 벡터와 제2 구간에 해 당하는 제2 오디오 데이터의 제2 화자 특징 벡터를 추출한다. 화자 특징 벡터 추출부는 화자 인식에 강인 한 화자 특징 벡터를 오디오 데이터로부터 추출할 수 있다. 화자 특징 벡터 추출부는 시간 도메인(time domain) 기반의 음성 신호를 주파수 도메인(frequency domain) 상의 신호로 변환하고, 변환된 신호의 주파수 에 너지를 서로 다르게 변형함으로써 화자 특징 벡터를 추출할 수 있다. 예컨대, 화자 특징 벡터는 멜 주파수 켑 스트럼 계수(Mel-Frequency Cepstral Coefficients) 또는 필터뱅크 에너지(Filter Bank Energy)를 기초로 추출 될 수 있으나, 이에 한정되는 것은 아니며 다양한 방식으로 오디오 데이터로부터 화자 특징 벡터를 추출할 수 있다. 화자 특징 벡터 추출부는 일반적으로 슬립 모드로 동작할 수 있다. 키워드 검출부는 오디오 스트림 데이터에서 후보 키워드를 검출하면 화자 특징 벡터 추출부를 웨이크업 할 수 있다. 키워드 검출부 는 오디오 스트림 데이터에서 후보 키워드를 검출하면 화자 특징 벡터 추출부에 웨이크업 신호를 송신할 수 있다. 화자 특징 벡터 추출부는 키워드 검출부에서 후보 키워드가 검출되었다는 것을 나타내는 웨이크업 신호에 응답하여 웨이크업 될 수 있다. 일 실시예에 따르면, 화자 특징 벡터 추출부는 오디오 데이터의 각 프레임마다 프레임 특징 벡터를 추출하 고, 추출된 프레임 특징 벡터들을 정규화 및 평균화하여 오디오 데이터를 대표하는 화자 특징 벡터를 추출할 수 있다. 추출된 프레임 특징 벡터들을 정규화하는데 L2-정규화가 사용될 수 있다. 추출된 프레임 특징 벡터들의 평균화는 오디오 데이터 내의 모든 프레임들 각각에 대해 추출된 프레임 특징 벡터들을 정규화하여 생성되는 정 규화된 프레임 특징 벡터들의 평균을 산출함으로써 달성될 수 있다. 예를 들면, 화자 특징 벡터 추출부는 제1 오디오 데이터의 각 프레임마다 제1 프레임 특징 벡터를 추출하 고, 추출된 제1 프레임 특징 벡터들을 정규화 및 평균화하여 제1 오디오 데이터를 대표하는 상기 제1 화자 특징 벡터를 추출할 수 있다. 또한, 화자 특징 벡터 추출부는 제2 오디오 데이터의 각 프레임마다 제2 프레임특징 벡터를 추출하고, 추출된 제2 프레임 특징 벡터들을 정규화 및 평균화하여 제2 오디오 데이터를 대표하는 제2 화자 특징 벡터를 추출할 수 있다. 다른 실시예에 따르면, 화자 특징 벡터 추출부는 오디오 데이터 내의 모든 프레임에 대하여 프레임 특징 벡터를 각각 추출하는 것이 아니라, 오디오 데이터 내의 일부 프레임에 대하여 프레임 특징 벡터를 각각 추출할 수 있다. 상기 일부 프레임은 해당 프레임의 오디오 데이터가 사용자의 음성 데이터일 가능성이 높은 프레임으 로 음성 프레임으로서 선택될 수 있다. 이러한 음성 프레임의 선택은 키워드 검출부에 의해 수행될 수 있 다. 키워드 검출부는 오디오 스트림 데이터의 각 프레임마다 사람 음성일 제1 확률과 배경음일 제2 확률 을 계산할 수 있다. 키워드 검출부는 각 프레임의 오디오 데이터가 사람 음성일 제1 확률이 배경음일 제2 확률보다 미리 설정된 기준치보다 높은 프레임을 음성 프레임으로 결정할 수 있다. 키워드 검출부는 해당 프레임이 음성 프레임인지의 여부를 나타내는 플래그 또는 비트를 오디오 스트림 데이터의 각 프레임 관련지어 메모리에 저장할 수 있다. 화자 특징 벡터 추출부는 제1 및 제2 오디오 데이터를 메모리로부터 독출할 때, 플래그 또는 비트를 함께 독출함으로써, 해당 프레임이 음성 프레임인지의 여부를 알 수 있다. 화자 특징 벡터 추출부는 오디오 데이터 내의 프레임들 중에서 음성 프레임으로 결정된 프레임들 각각에 대하여 프레임 특징 벡터를 추출하고, 추출된 제1 프레임 특징 벡터들을 정규화 및 평균화하여 오디오 데이터를 대표하는 화자 특징 벡터를 추출할 수 있다. 예를 들면, 화자 특징 벡터 추출부는 제1 오디오 데이터 내 의 프레임들 중에서 음성 프레임으로 결정된 프레임들 각각에 대하여 제1 프레임 특징 벡터를 추출하고, 추출된 제1 프레임 특징 벡터들을 정규화 및 평균화하여 제1 오디오 데이터를 대표하는 상기 제1 화자 특징 벡터를 추 출할 수 있다. 또한, 화자 특징 벡터 추출부는 제2 오디오 데이터 내의 프레임들 중에서 음성 프레임으로 결정된 프레임들 각각에 대하여 제2 프레임 특징 벡터를 추출하고, 추출된 제2 프레임 특징 벡터들을 정규화 및 평균화하여 제2 오디오 데이터를 대표하는 제2 화자 특징 벡터를 추출할 수 있다. 웨이크업 판단부는 화자 특징 벡터 추출부에서 추출된 제1 화자 특징 벡터와 제2 화자 특징 벡터의 유사도를 기초로, 제1 오디오 데이터에 해당 키워드가 포함되었는지의 여부, 즉, 제1 구간의 오디오 신호에 해 당 키워드가 포함되었는지의 여부를 판단한다. 웨이크업 판단부는 제1 화자 특징 벡터와 제2 화자 특징 벡터 간의 유사도를 미리 설정한 기준치와 비교하여, 유사도가 기준치 이하인 경우에, 제1 구간의 제1 오디오 데이터에 해당 키워드가 포함되었다고 판단할 수 있다. 음성 제어 장치가 키워드를 오인식하는 대표적인 경우는 사용자의 음성 중에 키워드와 유사한 발음의 단어 가 음성 중간에 위치는 경우이다. 예를 들면, 키워드가 “클로바”인 경우, 사용자가 다른 사람에게 “네잎 클 로버를 어떻게 찾을 수 있어”라고 말하는 경우에도 음성 제어 장치는 “클로버”에 반응하여 웨이크업 할 수 있으며, 사용자가 의도하지 않은 동작을 수행할 수 있다. 심지어, 텔레비전 뉴스에서 아나운서가 “제이엔 글로벌의 시가총액은 ...”이라고 말하는 경우에도, 음성 제어 장치는 “글로벌”에 반응하여 웨이크업 할 수 있다. 이와 같이 키워드 오인식이 발생하는 것을 방지하기 위하여, 일 실시예에 다르면, 키워드와 유사한 발음의 단어는 음성의 맨 앞에 위치하는 경우에만 음성 제어 장치가 반응할 수 있다. 또한, 주변 배경 소 음이 많은 환경이나, 다른 사람들이 대화를 하고 있는 환경에서는 사용자가 키워드에 해당하는 음성을 맨 앞에 발성하더라도 주변 배경 소음이나 다른 사람들의 대화로 인하여 사용자가 키워드에 해당하는 음성을 맨 앞에 발 성하였다는 것이 감지되지 않을 수 있다. 일 실시예에 따르면, 음성 제어 장치는 후보 키워드가 검출된 구간의 제1 화자 특징 벡터와 이전 구간의 제2 화자 특징 벡터를 추출하고, 제1 화자 특징 벡터와 제2 화자 특 징 벡터가 서로 상이할 경우에는 사용자가 키워드에 해당하는 음성을 맨 앞에 발성하였다고 판단할 수 있다. 이러한 판단을 위하여, 웨이크업 판단부는 제1 화자 특징 벡터와 제2 화자 특징 벡터 간의 유사도가 미리 설정한 기준치 이하인 경우에는, 사용자가 키워드에 해당하는 음성을 맨 앞에 발성하였다고 판단할 수 있다. 즉, 웨이크업 판단부는 제1 구간의 제1 오디오 데이터에 해당 키워드가 포함되었다고 판단할 수 있으며, 음성 제어 장치의 일부 기능을 웨이크업 할 수 있다. 제1 화자 특징 벡터와 제2 화자 특징 벡터 간의 유 사도가 높다는 것은 제1 오디오 데이터에 대응하는 음성을 말한 사람과 제2 오디오 데이터에 대응하는 음성을 말한 사람이 동일할 가능성이 높다는 것이다. 제2 오디오 데이터가 묵음에 해당할 경우, 화자 특징 벡터 추출부는 제2 오디오 데이터로부터 묵음에 해당 하는 제2 화자 특징 벡터를 추출할 수 있다. 화자 특징 벡터 추출부는 제1 오디오 데이터로부터 사용자의 음성에 해당하는 제1 화자 특징 벡터를 추출할 것이므로, 제1 화자 특징 벡터와 제2 화자 특징 벡터 간의 유사 도는 낮을 수 있다.음성 인식부는 오디오 처리부에서 생성된 오디오 스트림 데이터에서 제3 구간에 해당하는 제3 오디오 데이터를 수신하고, 제3 오디오 데이터를 음성 인식할 수 있다. 다른 예에 따르면, 음성 인식부는 제3 오 디오 데이터가 외부(예컨대, 서버)에서 음성 인식되도록 제3 오디오 데이터를 외부에 전송하고, 음성 인식 결과를 수신할 수 있다. 기능부는 키워드에 대응하는 기능을 수행할 수 있다. 예컨대, 음성 제어 장치가 스마트 스피커인 경 우, 기능부는 음악 재생부, 음성 정보 제공부, 주변 기기 제어부 등을 포함할 수 있으며, 검출된 키워드에 대응하는 기능을 수행할 수 있다. 음성 제어 장치가 스마트 폰인 경우, 기능부는 전화 연결부, 문자 송수신부, 인터넷 검색부 등을 포함할 수 있으며, 검출된 키워드에 대응하는 기능을 수행할 수 있다. 기능부 는 음성 제어 장치의 종류에 따라 다양하게 구성될 수 있다. 기능부는 음성 제어 장치가 실행할 수 있는 다양한 기능들을 수행하기 위한 기능 블럭들을 포괄적으로 나타낸 것이다. 도 3에 도시된 음성 제어 장치는 음성 인식부를 포함하는 것으로 도시되어 있지만, 이는 예시적이며, 음성 제어 장치는 음성 인식부를 포함하지 않고, 도 2에 도시된 서버가 음성 인식 기능을 대신 수행할 수 있다. 이 경우, 도 1에 도시된 바와 같이 음성 제어 장치는 네트워크를 통해 음성 인식 기능을 수행하는 서버에 접속될 수 있다. 음성 제어 장치는 음성 인식이 필요한 음성 신호를 포함하 는 음성 파일을 서버에 제공할 수 있으며, 서버는 음성 파일 내의 음성 신호에 대하여 음성 인식을 수행하여 음성 신호에 대응하는 문자열을 생성할 수 있다. 서버는 생성된 문자열을 네트워크를 통해 음성 제어 장치에 송신할 수 있다. 그러나, 아래에서는 음성 제어 장치가 음성 인식 기능을 수행하 는 음성 인식부를 포함하는 것으로 가정하고 설명한다. 프로세서는 동작 방법을 위한 프로그램 파일에 저장된 프로그램 코드를 메모리에 로딩할 수 있다. 예를 들면, 음성 제어 장치에는 프로그램 파일에 따라 프로그램이 설치(install)될 수 있다. 이때 음성 제어 장치에 설치된 프로그램이 실행되는 경우, 프로세서는 프로그램 코드를 메모리에 로딩할 수 있다. 이때, 프로세서가 포함하는 오디오 처리부, 키워드 검출부, 화자 특징 벡터 추출부 , 웨이크업 판단부, 음성 인식부 및 기능부 중 적어도 일부의 각각은 메모리에 로딩 된 프로그램 코드 중 대응하는 코드에 따른 명령을 실행하여 도 4의 단계들(S110 내지 S190)을 실행하도록 구현 될 수 있다. 이후에서 프로세서의 기능 블럭들(121-126)이 음성 제어 장치를 제어하는 것은 프로세서가 음성 제어 장치의 다른 구성요소들을 제어하는 것으로 이해될 수 있다. 예를 들어, 프로세서는 음성 제어 장치가 포함하는 통신 모듈을 제어하여 음성 제어 장치가 예컨대 서버와 통신하도록 음성 제어 장치를 제어할 수 있다. 단계(S110)에서 프로세서, 예컨대, 오디오 처리부는 주변 소리에 대응하는 오디오 신호를 수신한다. 오디오 처리부는 지속적으로 주변 소리에 대응하는 오디오 신호를 수신할 수 있다. 오디오 신호는 마이크 와 같은 입력 장치가 주변 소리에 대응하여 생성한 전기 신호일 수 있다. 단계(S120)에서 프로세서, 예컨대, 오디오 처리부는 마이크로부터의 오디오 신호를 기초로 오디 오 스트림 데이터를 생성한다. 오디오 스트림 데이터는 지속적으로 수신되는 오디오 신호에 대응한 것이다. 오디오 스트림 데이터는 오디오 신호를 필터링하고 디지털화함으로써 생성되는 데이터일 수 있다. 단계(S130)에서 프로세서, 예컨대, 오디오 처리부는 단계(S120)에서 생성되는 오디오 스트림 데이터 를 메모리에 일시적으로 저장한다. 메모리는 한정된 크기를 가지며, 현재로부터 최근 일정 시간 동 안의 오디오 신호에 대응하는 오디오 스트림 데이터의 일부가 메모리에 일시적으로 저장될 수 있다. 새로 운 오디오 스트림 데이터가 생성되면, 메모리에 저장된 오디오 스트림 데이터 중에서 가장 오래된 데이터 가 삭제되고, 메모리 내의 삭제에 의해 비게 된 공간에 새로운 오디오 스트림 데이터가 저장될 수 있다. 단계(S140)에서 프로세서, 예컨대, 키워드 검출부는 단계(S120)에서 생성되는 오디오 스트림 데이터 로부터 미리 정의된 키워드에 대응하는 후보 키워드를 검출한다. 후보 키워드는 미리 정의된 키워드와 유사한 발음을 갖는 단어로서, 단계(S140)에서 키워드 검출부에서 키워드로서 검출된 워드를 지칭한다. 단계(S150)에서 프로세서, 예컨대, 키워드 검출부는 오디오 스트림 데이터에서 후보 키워드가 검출된 키워드 검출 구간을 식별하고, 키워드 검출 구간의 시점과 종점을 결정한다. 키워드 검출 구간은 현재 구간으 로 지칭될 수 있다. 오디오 스트림 데이터에서 현재 구간에 대응하는 데이터는 제1 오디오 데이터로 지칭될 수 있다.단계(S160)에서 프로세서, 예컨대, 화자 특징 벡터 추출부는 메모리로부터 이전 구간에 해당하 는 제2 오디오 데이터를 독출한다. 이전 구간은 현재 구간의 바로 직전 구간으로서, 이전 구간의 종점은 현재 구간의 시점과 동일할 수 있다. 화자 특징 벡터 추출부는 메모리로부터 제1 오디오 데이터도 함께 독출할 수 있다. 단계(S170)에서 프로세서, 예컨대, 화자 특징 벡터 추출부는 제1 오디오 데이터로부터 제1 화자 특징 벡터를 추출하고, 제2 오디오 데이터로부터 제2 화자 특징 벡터를 추출한다. 제1 화자 특징 벡터는 제1 오디오 데이터에 대응하는 음성의 화자를 식별하기 위한 지표이고, 제2 화자 특징 벡터는 제2 오디오 데이터에 대응하 는 음성의 화자를 식별하기 위한 지표이다. 프로세서, 예컨대, 웨이크업 판단부는 제1 화자 특징 벡 터와 제2 화자 특징 벡터 간의 유사도를 기초로 제1 오디오 데이터에 키워드가 포함되었는지의 여부를 판단할 수 있다. 웨이크업 판단부는 제1 오디오 데이터에 키워드가 포함되었다고 판단할 경우, 음성 제어 장치 의 일부 구성요소들을 웨이크업 할 수 있다. 단계(S180)에서 프로세서, 예컨대, 웨이크업 판단부는 제1 화자 특징 벡터와 제2 화자 특징 벡터 간 의 유사도를 미리 설정된 기준치와 비교한다. 웨이크업 판단부는 제1 화자 특징 벡터와 제2 화자 특징 벡터 간의 유사도가 미리 설정된 기준치 이하인 경우, 현재 구간의 제1 오디오 데이터의 화자와 이전 구간의 제2 오디오 데이터의 화자가 서로 상이하다는 것이 므로, 제1 오디오 데이터에 키워드가 포함되었다고 판단할 수 있다. 이 경우, 단계(S190)에서와 같이 프로세서 , 예컨대, 웨이크업 판단부는 음성 제어 장치의 일부 구성요소들을 웨이크업 할 수 있다. 그러나, 웨이크업 판단부는 제1 화자 특징 벡터와 제2 화자 특징 벡터 간의 유사도가 미리 설정된 기준치 보다 큰 경우, 현재 구간의 제1 오디오 데이터의 화자와 이전 구간의 제2 오디오 데이터의 화자가 서로 동일하 다는 것이므로, 제1 오디오 데이터에 키워드가 포함되지 않았다고 판단하여, 웨이크업을 진행하지 않을 수 있다. 이 경우, 단계(S110)로 진행하여 주변 소리에 대응하는 오디오 신호를 수신한다. 단계(S110)에서 오디 오 신호의 수신은 단계들(S120-S190)을 수행할 때에도 계속된다. 도 3의 키워드 저장소(110a)에는 미리 정의된 복수의 키워드들이 저장될 수 있다. 이러한 키워드들은 웨이크업 키워드이거나 단독 명령 키워드일 수 있다. 웨이크업 키워드는 음성 제어 장치의 일부 기능을 웨이크업 하기 위한 것이다. 일반적으로 사용자는 웨이크업 키워드를 발화한 후 원하는 자연어 음성 명령을 발화한다. 음성 제어 장치는 자연어 음성 명령을 음성 인식하고, 자연어 음성 명령에 대응하는 동작 및 기능을 수행 할 수 있다. 단독 명령 키워드는 음성 제어 장치가 특정 동작 또는 기능을 직접 수행하기 위한 것으로서, 예컨대, “재 생”, “중지” 등과 같이 미리 정의된 간단한 단어일 수 있다. 음성 제어 장치는 단독 명령 키워드가 수 신되면, 단독 명령 키워드에 해당하는 기능을 웨이크업하고, 해당 기능을 수행할 수 있다. 아래에서는 오디오 스트림 데이터로부터 단독 명령 키워드에 대응하는 후보 키워드를 검출한 경우와 오디오 스 트림 데이터로부터 웨이크업 키워드에 대응하는 후보 키워드를 검출한 경우 각각에 대하여 설명한다. 도 5는 다른 실시예에 따라서 음성 제어 장치가 수행할 수 있는 동작 방법의 예를 도시한 흐름도이다. 도 6a는 일 실시예에 따른 음성 제어 장치가 도 5의 동작 방법을 실행하는 경우에 단독 명령 키워드가 발화되는 예를 도시하고, 도 6b는 일 실시예에 따른 음성 제어 장치가 도 5의 동작 방법을 실행하는 경우에 일반 대화 음 성이 발화되는 예를 도시한다. 도 5의 동작 방법은 도 4의 동작 방법과 실질적으로 동일한 단계들을 포함한다. 도 5의 단계들 중에서 도 4의 단계들과 실질적으로 동일한 단계들에 대해서는 자세히 설명하지 않는다. 도 6a와 도 6b에는 오디오 스트림 데 이터에 대응하는 오디오 신호들과 오디오 신호들에 대응하는 사용자의 음성이 도시된다. 도 6a에는 음성 “중 지”에 대응하는 오디오 신호들이 도시되고, 도 6b에는 음성 “여기서 정지해”에 대응하는 오디오 신호들이 도 시된다. 도 6a 및 도 6b와 함께 도 5를 참조하면, 단계(S210)에서 프로세서, 예컨대, 오디오 처리부는 주변 소리에 대응하는 오디오 신호를 수신한다. 단계(S220)에서 프로세서, 예컨대, 오디오 처리부는 마이크로부터의 오디오 신호를 기초로 오디 오 스트림 데이터를 생성한다.단계(S230)에서 프로세서, 예컨대, 오디오 처리부는 단계(S220)에서 생성되는 오디오 스트림 데이터 를 메모리에 일시적으로 저장한다. 단계(S240)에서 프로세서, 예컨대, 키워드 검출부는 단계(S220)에서 생성되는 오디오 스트림 데이터 로부터 미리 정의된 단독 명령 키워드에 대응하는 후보 키워드를 검출한다. 단독 명령 키워드는 음성 제어 장 치의 동작을 직접 제어할 수 있는 음성 키워드일 수 있다. 예컨대, 단독 명령 키워드는 도 6a에 도시된 바와 같이 “중지”와 같은 단어일 수 있다. 이 경우, 음성 제어 장치는 예컨대 음악이나 동영상을 재생 하고 있을 수 있다. 도 6a의 예에서, 키워드 검출부는 오디오 신호들에서 “중지”라는 후보 키워드를 검출할 수 있다. 도 6b 의 예에서, 키워드 검출부는 오디오 신호들에서 “중지”라는 키워드와 유사한 발음을 갖는 단어인 “정지 ”라는 후보 키워드를 검출할 수 있다. 단계(S250)에서 프로세서, 예컨대, 키워드 검출부는 오디오 스트림 데이터에서 후보 키워드가 검출된 키워드 검출 구간을 식별하고, 키워드 검출 구간의 시점과 종점을 결정한다. 키워드 검출 구간은 현재 구간으 로 지칭될 수 있다. 오디오 스트림 데이터에서 현재 구간에 대응하는 데이터는 제1 오디오 데이터로 지칭될 수 있다. 도 6a의 예에서, 키워드 검출부는 “중지”라는 후보 키워드를 검출한 구간을 현재 구간으로 식별하고, 현 재 구간의 시점과 종점을 결정할 수 있다. 상기 현재 구간에 대응하는 오디오 데이터는 제1 오디오 데이터 (AD1)로 지칭될 수 있다. 도 6b의 예에서, 키워드 검출부는 “정지”라는 후보 키워드를 검출한 구간을 현재 구간으로 식별하고, 현 재 구간의 시점과 종점을 결정할 수 있다. 상기 현재 구간에 대응하는 오디오 데이터는 제1 오디오 데이터 (AD1)로 지칭될 수 있다. 또한, 단계(S250)에서 프로세서, 예컨대, 키워드 검출부는 검출된 후보 키워드가 웨이크업 키워드와 단독 명령 키워드 중 어떤 키워드에 대응하는 후보 키워드인지를 판단할 수 있다. 도 6a와 도 6b의 예에서, 키 워드 검출부는 검출된 후보 키워드, 즉, “중지” 및 “정지”가 단독 명령 키워드에 대응하는 후보 키워 드라는 것을 판단할 수 있다. 단계(S260)에서 프로세서, 예컨대, 화자 특징 벡터 추출부는 메모리로부터 이전 구간에 해당하 는 제2 오디오 데이터를 독출한다. 이전 구간은 현재 구간의 바로 직전 구간으로서, 이전 구간의 종점은 현재 구간의 시점과 동일할 수 있다. 화자 특징 벡터 추출부는 메모리로부터 제1 오디오 데이터도 함께 독출할 수 있다. 도 6a의 예에서, 화자 특징 벡터 추출부는 현재 구간의 바로 직전 구간인 이전 구간에 대응하는 제2 오디 오 데이터(AD2)를 메모리로부터 독출할 수 있다. 도 6b의 예에서, 화자 특징 벡터 추출부는 현재 구 간의 바로 직전 구간인 이전 구간에 대응하는 제2 오디오 데이터(AD2)를 메모리로부터 독출할 수 있다. 도 6b의 예에서, 제2 오디오 데이터(AD2)는 “기서”라는 음성에 대응할 수 있다. 이전 구간의 길이는 검출된 후보 키워드에 따라 가변적으로 설정될 수 있다. 단계(S270)에서 프로세서, 예컨대, 화자 특징 벡터 추출부는 오디오 처리부로부터 현재 구간 이 후의 다음 구간에 해당하는 제3 오디오 데이터를 수신한다. 다음 구간은 현재 구간의 바로 다음 구간으로서, 다음 구간의 시점은 현재 구간의 종점과 동일할 수 있다. 도 6a의 예에서, 화자 특징 벡터 추출부는 현재 구간 직후의 다음 구간에 대응하는 제3 오디오 데이터 (AD3)를 오디오 처리부로부터 수신할 수 있다. 도 6b의 예에서, 화자 특징 벡터 추출부는 현재 구간 직후의 다음 구간에 대응하는 제3 오디오 데이터(AD3)를 오디오 처리부로부터 수신할 수 있다. 도 6b의 예에서, 제3 오디오 데이터(AD3)는 “해”라는 음성에 대응할 수 있다. 다음 구간의 길이는 검출된 후보 키워 드에 따라 가변적으로 설정될 수 있다. 단계(S280)에서 프로세서, 예컨대, 화자 특징 벡터 추출부는 제1 내지 제3 오디오 데이터로부터 제1 내지 제3 화자 특징 벡터들을 각각 추출한다. 제1 내지 제3 화자 특징 벡터들 각각은 제1 내지 제3 오디오 데 이터에 대응하는 음성의 화자를 식별하기 위한 지표들이다. 프로세서, 예컨대, 웨이크업 판단부는 제1 화자 특징 벡터와 제2 화자 특징 벡터 간의 유사도, 및 제1 화자 특징 벡터와 제3 화자 특징 벡터 간의 유 사도를 기초로 제1 오디오 데이터에 단독 명령 키워드가 포함되었는지의 여부를 판단할 수 있다. 웨이크업 판단부는 제1 오디오 데이터에 단독 명령 키워드가 포함되었다고 판단할 경우, 음성 제어 장치의 일부 구성요소들을 웨이크업 할 수 있다. 도 6a의 예에서, 제1 오디오 데이터(AD1)에 대응하는 제1 화자 특징 벡터는 “중지”라는 음성을 발성한 화자를 식별하기 위한 지표이다. 제2 오디오 데이터(AD2)와 제3 오디오 데이터(AD3)는 실질적으로 묵음이므로, 제2 및 제3 화자 특징 벡터는 묵음에 대응하는 벡터를 가질 수 있다. 따라서, 제1 화자 특징 벡터와 제2 및 제3 화자 특징 벡터들 간의 유사도는 낮을 수 있다. 다른 예로서, 이전 구간과 다음 구간에 “중지”라는 음성을 발성한 화자가 아닌 다른 사람이 음성을 발성하는 경우, 제2 및 제3 화자 특징 벡터는 상기 다른 사람에 대응한 벡터를 가질 것이므로, 제1 화자 특징 벡터와 제2 및 제3 화자 특징 벡터들 간의 유사도는 낮을 수 있다. 도 6b의 예에서는 한 사람이 “여기서 정지해”라고 발성하였다. 따라서, “정지”에 대응하는 제1 오디오 데 이터(AD1)로부터 추출되는 제1 화자 특징 벡터, “기서”에 대응하는 제2 오디오 데이터(AD2)로부터 추출되는 제2 화자 특징 벡터, 및 “해”에 대응하는 제3 오디오 데이터(AD3)로부터 추출되는 제3 화자 특징 벡터는 모두 실질적으로 동일한 화자를 식별하기 위한 벡터이므로, 제1 내지 제3 화자 특징 벡터들 간의 유사도는 높을 수 있다. 단계(S290)에서 프로세서, 예컨대, 웨이크업 판단부는 제1 화자 특징 벡터와 제2 화자 특징 벡터 간 의 유사도를 미리 설정된 기준치와 비교하고, 제1 화자 특징 벡터와 제3 화자 특징 벡터 간의 유사도를 미리 설 정된 기준치와 비교한다. 웨이크업 판단부는 제1 화자 특징 벡터와 제2 화자 특징 벡터 간의 유사도가 미 리 설정된 기준치 이하이고 제1 화자 특징 벡터와 제3 화자 특징 벡터 간의 유사도가 미리 설정된 기준치 이하 인 경우, 현재 구간의 제1 오디오 데이터의 화자는 이전 구간의 제2 오디오 데이터의 화자 및 다음 구간의 제3 오디오 데이터의 화자로부터 상이하다는 것이므로, 제1 오디오 데이터에 단독 명령 키워드가 포함되었다고 판단 할 수 있다. 이 경우, 단계(S300)에서와 같이 프로세서, 예컨대, 웨이크업 판단부는 단독 명령 키워 드를 기능부에 제공하고, 기능부는 웨이크업 판단부에 의한 제1 오디오 데이터에 단독 명령 키 워드가 포함되었다는 판단에 응답하여 단독 명령 키워드에 대응하는 기능을 수행할 수 있다. 도 6a의 예에서, 제1 화자 특징 벡터는 “중지”라고 발성한 화자에 대응하는 벡터이고, 제2 및 제3 화자 특징 벡터들은 묵음에 대응한 벡터이므로, 제1 화자 특징 벡터와 제2 및 제3 화자 특징 벡터들 간의 유사도들은 미리 설정된 기준치보다 낮을 수 있다. 이 경우, 웨이크업 판단부는 제1 오디오 데이터(AD1)에 “중지”라는 단독 명령 키워드가 포함되었다고 판단할 수 있다. 이 경우, 기능부는 상기 판단에 응답하여 웨이크업 될 수 있으며, “중지”라는 단독 명령 키워드에 대응하는 동작 또는 기능을 수행할 수 있다. 예컨대, 음성 제어 장치가 음악을 재생 중이었다면, 기능부는 “중지”라는 단독 명령 키워드에 대응하여 음악 재생을 중지시킬 수 있다. 그러나, 웨이크업 판단부는 제1 화자 특징 벡터와 제2 화자 특징 벡터 간의 유사도가 미리 설정된 기준치 보다 크거나, 제1 화자 특징 벡터와 제3 화자 특징 벡터 간의 유사도가 미리 설정된 기준치보다 큰 경우, 현재 구간의 제1 오디오 데이터의 화자가 이전 구간의 제2 오디오 데이터의 화자 또는 다음 구간의 제3 오디오 데이 터의 화자와 동일하다는 것이므로, 제1 오디오 데이터에 키워드가 포함되지 않았다고 판단하여, 웨이크업을 진 행하지 않을 수 있다. 이 경우, 단계(S210)로 진행하여 주변 소리에 대응하는 오디오 신호를 수신한다. 도 6b의 예에서, 한 사람이 “여기서 정지해”라고 발성하였으므로, 제1 내지 제3 화자 특징 벡터들 간의 유사 도는 높을 것이다. 도 6b의 예에서의 발성인 “여기에 정지해”에는 음성 제어 장치를 제어하거나 웨이크업 하 기 위한 키워드가 포함되지 않았으므로, 웨이크업 판단부는 제1 오디오 데이터(AD1)에 단독 명령 키워드가 포함되지 않았다고 판단하고, 기능부가 “정지” 또는 “중지”에 해당하는 기능이나 동작을 수행하지 않 도록 할 수 있다. 일반적인 기술에 따르면, 음성 제어 장치는 “여기서 정지해”라는 발성 중 “정지”라는 음성을 검출하여, “ 정지”에 해당하는 기능이나 동작을 수행할 수 있다. 이러한 기능이나 동작은 사용자가 의도하지 않은 것으로 서, 사용자는 음성 제어 장치를 사용할 때 불편함을 느낄 수 있다. 그러나, 일 실시예에 따르면, 음성 제어 장 치는 사용자의 음성으로부터 단독 명령 키워드를 정확히 인식할 수 있기 때문에, 일반적인 기술과는 달리 오동작을 수행하지 않을 수 있다. 도 7은 또 다른 실시예에 따라서 음성 제어 장치가 수행할 수 있는 동작 방법의 예를 도시한 흐름도이다. 도 8a는 일 실시예에 따른 음성 제어 장치가 도 7의 동작 방법을 실행하는 경우에 웨이크업 키워드와 자연어 음 성 명령이 발화되는 예를 도시하고, 도 8b는 일 실시예에 따른 음성 제어 장치가 도 7의 동작 방법을 실행하는 경우에 일반 대화 음성이 발화되는 예를 도시한다. 도 7의 동작 방법은 도 4의 동작 방법과 실질적으로 동일한 단계들을 포함한다. 도 7의 단계들 중에서 도 4의 단계들과 실질적으로 동일한 단계들에 대해서는 자세히 설명하지 않는다. 도 6a와 도 6b에는 오디오 스트림 데 이터에 대응하는 오디오 신호들과 오디오 신호들에 대응하는 사용자의 음성이 도시된다. 도 8a에는 웨이크업 키워드 “클로바”와 자연어 음성 명령 “내일 날씨를 알려줘”에 대응하는 오디오 신호들이 도시되고, 도 6b에 는 “네잎 클로바를 어떻게 찾을 수 있어”라는 대화 음성에 대응하는 오디오 신호들이 도시된다. 도 8a 및 도 8b와 함께 도 7를 참조하면, 단계(S410)에서 프로세서, 예컨대, 오디오 처리부는 주변 소리에 대응하는 오디오 신호를 수신한다. 단계(S420)에서 프로세서, 예컨대, 오디오 처리부는 마이 크로부터의 오디오 신호를 기초로 오디오 스트림 데이터를 생성한다. 단계(S430)에서 프로세서, 예 컨대, 오디오 처리부는 단계(S120)에서 생성되는 오디오 스트림 데이터를 메모리에 일시적으로 저장 한다. 단계(S440)에서 프로세서, 예컨대, 키워드 검출부는 단계(S420)에서 생성되는 오디오 스트림 데이터 로부터 미리 정의된 웨이크업 키워드에 대응하는 후보 키워드를 검출한다. 웨이크업 키워드는 슬립 모드 상태 의 음성 제어 장치를 웨이크업 모드로 전환할 수 있는 음성 기반 키워드이다. 예컨대, 웨이크업 키워드는 “클 로바”, “하이 컴퓨터” 등과 같은 음성 키워드일 수 있다. 도 8a의 예에서, 키워드 검출부는 오디오 신호들에서 “클로바”라는 후보 키워드를 검출할 수 있다. 도 6b의 예에서, 키워드 검출부는 오디오 신호들에서 “클로바”라는 키워드와 유사한 발음을 갖는 단어인 “ 클로버”라는 후보 키워드를 검출할 수 있다. 단계(S450)에서 프로세서, 예컨대, 키워드 검출부는 오디오 스트림 데이터에서 후보 키워드가 검출된 키워드 검출 구간을 식별하고, 키워드 검출 구간의 시점과 종점을 결정한다. 키워드 검출 구간은 현재 구간으 로 지칭될 수 있다. 오디오 스트림 데이터에서 현재 구간에 대응하는 데이터는 제1 오디오 데이터로 지칭될 수 있다. 도 8a의 예에서, 키워드 검출부는 “클로바”라는 후보 키워드를 검출한 구간을 현재 구간으로 식별하고, 현재 구간의 시점과 종점을 결정할 수 있다. 상기 현재 구간에 대응하는 오디오 데이터는 제1 오디오 데이터 (AD1)로 지칭될 수 있다. 도 8b의 예에서, 키워드 검출부는 “클로버”라는 후보 키워드를 검출한 구간을 현재 구간으로 식별하고, 현재 구간의 시점과 종점을 결정할 수 있다. 상기 현재 구간에 대응하는 오디오 데이 터는 제1 오디오 데이터(AD1)로 지칭될 수 있다. 또한, 단계(S450)에서 프로세서, 예컨대, 키워드 검출부는 검출된 후보 키워드가 웨이크업 키워드와 단독 명령 키워드 중 어떤 키워드에 대응하는 후보 키워드인지를 판단할 수 있다. 도 8a와 도 8b의 예에서, 키 워드 검출부는 검출된 후보 키워드, 즉, “클로바” 및 “클로버”가 웨이크업 키워드에 대응하는 후보 키 워드라는 것을 판단할 수 있다. 단계(S460)에서 프로세서, 예컨대, 화자 특징 벡터 추출부는 메모리로부터 이전 구간에 해당하 는 제2 오디오 데이터를 독출한다. 이전 구간은 현재 구간의 바로 직전 구간으로서, 이전 구간의 종점은 현재 구간의 시점과 동일할 수 있다. 화자 특징 벡터 추출부는 메모리로부터 제1 오디오 데이터도 함께 독출할 수 있다. 도 8a의 예에서, 화자 특징 벡터 추출부는 현재 구간의 바로 직전 구간인 이전 구간에 대응하는 제2 오디 오 데이터(AD2)를 메모리로부터 독출할 수 있다. 도 8b의 예에서, 화자 특징 벡터 추출부는 현재 구 간의 바로 직전 구간인 이전 구간에 대응하는 제2 오디오 데이터(AD2)를 메모리로부터 독출할 수 있다. 도 8b의 예에서, 제2 오디오 데이터(AD2)는 “네잎”이라는 음성에 대응할 수 있다. 이전 구간의 길이는 검출 된 후보 키워드에 따라 가변적으로 설정될 수 있다. 단계(S470)에서 프로세서, 예컨대, 화자 특징 벡터 추출부는 제1 및 제2 오디오 데이터로부터 제1 및 제2 화자 특징 벡터들을 각각 추출한다. 프로세서, 예컨대, 웨이크업 판단부는 제1 화자 특징 벡터 와 제2 화자 특징 벡터 간의 유사도를 기초로 제1 오디오 데이터에 웨이크업 키워드가 포함되었는지의 여부를 판단할 수 있다. 웨이크업 판단부는 제1 오디오 데이터에 웨이크업 키워드가 포함되었다고 판단할 경우, 음성 제어 장치의 일부 구성요소들을 웨이크업 할 수 있다.도 8a의 예에서, 제1 오디오 데이터(AD1)에 대응하는 제1 화자 특징 벡터는 “클로바”라는 음성을 발성한 화자 를 식별하기 위한 지표이다. 제2 오디오 데이터(AD2)는 실질적으로 묵음이므로, 제2 화자 특징 벡터는 묵음에 대응하는 벡터를 가질 수 있다. 따라서, 제1 화자 특징 벡터와 제2 화자 특징 벡터 간의 유사도는 낮을 수 있 다. 다른 예로서, 이전 구간에 “클로바”라는 음성을 발성한 화자가 아닌 다른 사람이 음성을 발성하는 경우, 제2 화자 특징 벡터는 상기 다른 사람에 대응한 벡터를 가질 것이므로, 제1 화자 특징 벡터와 제2 화자 특징 벡터들 간의 유사도는 낮을 수 있다. 도 8b의 예에서는 한 사람이 “네잎 클로버를 어떻게 찾을 수 있어”라고 발성하였다. 따라서, “클로버”에 대응하는 제1 오디오 데이터(AD1)로부터 추출되는 제1 화자 특징 벡터와 “네잎”에 대응하는 제2 오디오 데이 터(AD2)로부터 추출되는 제2 화자 특징 벡터는 모두 실질적으로 동일한 화자를 식별하기 위한 벡터이므로, 제1 및 제2 화자 특징 벡터들 간의 유사도는 높을 수 있다. 단계(S480)에서 프로세서, 예컨대, 웨이크업 판단부는 제1 및 제2 화자 특징 벡터들 간의 유사도를 미리 설정된 기준치와 비교한다. 웨이크업 판단부는 제1 및 제2 화자 특징 벡터들 간의 유사도가 미리 설 정된 기준치보다 큰 경우, 현재 구간의 제1 오디오 데이터의 화자와 이전 구간의 제2 오디오 데이터의 화자가 서로 동일하다는 것이므로, 제1 오디오 데이터에 키워드가 포함되지 않았다고 판단하여, 웨이크업을 진행하지 않을 수 있다. 이 경우, 단계(S410)로 진행하며, 프로세서, 예컨대, 오디오 처리부는 주변 소리에 대응하는 오디오 신호를 수신한다. 도 8b의 예에서, 한 사람이 “네잎 클로버...”라고 발성하였으므로, 제1 및 제2 화자 특징 벡터들 간의 유사도 는 높을 것이다. 도 8b의 예에서, “네잎 클로버”라고 발성한 사람은 음성 제어 장치를 웨이크업 하려는 의도가 없다고 판단하고, 웨이크업 판단부는 제1 오디오 데이터(AD1)에 웨이크업 키워드가 포함되지 않았 다고 판단하고, 음성 제어 장치를 웨이크업 하지 않을 수 있다. 웨이크업 판단부는 제1 및 제2 화자 특징 벡터들 간의 유사도가 미리 설정된 기준치 이하인 경우, 현재 구 간의 제1 오디오 데이터의 화자와 이전 구간의 제2 오디오 데이터의 화자가 서로 상이하다는 것이므로, 제1 오 디오 데이터에 키워드가 포함되었다고 판단할 수 있다. 이 경우, 웨이크업 판단부는 음성 제어 장치(10 0)의 일부 구성요소들을 웨이크업 할 수 있다. 예컨대, 웨이크업 판단부는 음성 인식부를 웨이크업 할 수 있다. 도 8a의 예에서, 제1 화자 특징 벡터는 “클로바”라고 발성한 화자에 대응하는 벡터이고, 제2 화자 특징 벡터 는 묵음에 대응한 벡터이므로, 제1 및 제2 화자 특징 벡터들 간의 유사도는 미리 설정된 기준치보다 낮을 수 있 다. 이 경우, 웨이크업 판단부는 제1 오디오 데이터(AD1)에 “클로바”라는 웨이크업 키워드가 포함되었 다고 판단할 수 있다. 이 경우, 음성 인식부는 자연어 음성 명령을 인식하기 위해 웨이크업 할 수 있다. 단계(S490)에서 프로세서, 예컨대, 음성 인식부는 오디오 처리부로부터 현재 구간 이후의 다음 구간에 해당하는 제3 오디오 데이터를 수신한다. 다음 구간은 현재 구간의 바로 다음 구간으로서, 다음 구간의 시점은 현재 구간의 종점과 동일할 수 있다. 음성 인식부는 제3 오디오 데이터에서 미리 설정한 길이의 묵음이 검출될 때 다음 구간의 종점을 결정할 수 있다. 음성 인식부는 제3 오디오 데이터를 음성 인식할 수 있다. 음성 인식부는 다양한 방식으 로 제3 오디오 데이터를 음성 인식할 수 있다. 다른 예에 따르면, 음성 인식부는 제3 오디오 데이터의 음 성 인식 결과를 얻기 위해, 외부 장치, 예컨대, 도 2에 도시되는 음성 인식 기능을 갖는 서버로 제3 오디 오 데이터를 전송할 수 있다. 서버는 제3 오디오 데이터를 수신하고, 제3 오디오 데이터를 음성 인식함으 로써 제3 오디오 데이터에 대응하는 문자열(텍스트)를 생성하고, 생성된 문자열(텍스트)를 음성 인식 결과로서 음성 인식부로 전송할 수 있다. 도 8a의 예에서, 다음 구간의 제3 오디오 데이터는 “내일 날씨를 알려줘”와 같은 자연어 음성 명령이다. 음 성 인식부는 제3 오디오 데이터를 직접 음성 인식하여 음성 인식 결과를 생성하거나, 제3 오디오 데이터가 음성 인식되도록 외부(예컨대, 서버)에 전송할 수 있다. 단계(S500)에서 프로세서, 예컨대, 기능부는 제3 오디오 데이터의 음성 인식 결과에 대응하는 기능을 수행할 수 있다. 도 8a의 예에서, 기능부는 내일 날씨를 검색하여 결과를 제공하는 음성 정보 제공부일 수 있으며, 기능부는 인터넷을 이용하여 내일 날씨를 검색하고, 그 결과를 사용자에게 제공할 수 있다.기능부는 내일 날씨의 검색 결과를 스피커를 이용하여 음성으로 제공할 수도 있다. 기능부는 제3 오디오 데이터의 음성 인식 결과에 응답하여 웨이크업 될 수 있다. 이상 설명된 본 발명에 따른 실시예는 컴퓨터 상에서 다양한 구성요소를 통하여 실행될 수 있는 컴퓨터 프로그 램의 형태로 구현될 수 있으며, 이와 같은 컴퓨터 프로그램은 컴퓨터로 판독 가능한 매체에 기록될 수 있다. 이때, 매체는 컴퓨터로 실행 가능한 프로그램을 계속 저장하거나, 실행 또는 다운로드를 위해 임시 저장하는 것 일 수도 있다. 또한, 매체는 단일 또는 수개 하드웨어가 결합된 형태의 다양한 기록수단 또는 저장수단일 수 있는데, 어떤 컴퓨터 시스템에 직접 접속되는 매체에 한정되지 않고, 네트워크 상에 분산 존재하는 것일 수도 있다. 매체의 예시로는, 하드 디스크, 플로피 디스크 및 자기 테이프와 같은 자기 매체, CD-ROM 및 DVD와 같은 광기록 매체, 플롭티컬 디스크(floptical disk)와 같은 자기-광 매체(magneto-optical medium), 및 ROM, RAM, 플래시 메모리 등을 포함하여 프로그램 명령어가 저장되도록 구성된 것이 있을 수 있다. 또한, 다른 매체의 예 시로, 애플리케이션을 유통하는 앱 스토어나 기타 다양한 소프트웨어를 공급 내지 유통하는 사이트, 서버 등에 서 관리하는 기록매체 내지 저장매체도 들 수 있다. 본 명세서에서, \"부\", \"모듈\" 등은 프로세서 또는 회로와 같은 하드웨어 구성(hardware component), 및/또는 프 로세서와 같은 하드웨어 구성에 의해 실행되는 소프트웨어 구성(software component)일 수 있다. 예를 들면, \"부\", \"모듈\" 등은 소프트웨어 구성 요소들, 객체 지향 소프트웨어 구성 요소들, 클래스 구성 요소들 및 태스 크 구성 요소들과 같은 구성 요소들과, 프로세스들, 함수들, 속성들, 프로시저들, 서브루틴들, 프로그램 코드의 세그먼트들, 드라이버들, 펌웨어, 마이크로 코드, 회로, 데이터, 데이터베이스, 데이터 구조들, 테이블들, 어레 이들 및 변수들에 의해 구현될 수 있다."}
{"patent_id": "10-2017-0062391", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "전술한 본 발명의 설명은 예시를 위한 것이며, 본 발명이 속하는 기술분야의 통상의 지식을 가진 자는 본 발명 의 기술적 사상이나 필수적인 특징을 변경하지 않고서 다른 구체적인 형태로 쉽게 변형이 가능하다는 것을 이해 할 수 있을 것이다. 그러므로 이상에서 기술한 실시예들은 모든 면에서 예시적인 것이며 한정적이 아닌 것으로 이해해야만 한다. 예를 들어, 단일형으로 설명되어 있는 각 구성 요소는 분산되어 실시될 수도 있으며, 마찬가 지로 분산된 것으로 설명되어 있는 구성 요소들도 결합된 형태로 실시될 수 있다. 본 발명의 범위는 상기 상세한 설명보다는 후술하는 특허청구범위에 의하여 나타내어지며, 특허청구범위의 의미 및 범위 그리고 그 균등 개념으로부터 도출되는 모든 변경 또는 변형된 형태가 본 발명의 범위에 포함되는 것으 로 해석되어야 한다."}
{"patent_id": "10-2017-0062391", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 일 실시예에 따른 네트워크 환경의 예를 도시한 도면이다. 도 2는 일 실시예에 따라서 전자 기기 및 서버의 내부 구성을 설명하기 위한 블럭도이다. 도 3은 일 실시예에 따른 음성 제어 장치의 프로세서가 포함할 수 있는 기능 블럭들의 예를 도시한 도면이다. 도 4는 일 실시예에 따라서 음성 제어 장치가 수행할 수 있는 동작 방법의 예를 도시한 흐름도이다. 도 5는 다른 실시예에 따라서 음성 제어 장치가 수행할 수 있는 동작 방법의 예를 도시한 흐름도이다. 도 6a는 일 실시예에 따른 음성 제어 장치가 도 5의 동작 방법을 실행하는 경우에 단독 명령 키워드가 발화되는 예를 도시한다. 도 6b는 일 실시예에 따른 음성 제어 장치가 도 6의 동작 방법을 실행하는 경우에 일반 대화 음성이 발화되는 예를 도시한다. 도 7는 또 다른 실시예에 따라서 음성 제어 장치가 수행할 수 있는 동작 방법의 예를 도시한 흐름도이다. 도 8a는 일 실시예에 따른 음성 제어 장치가 도 7의 동작 방법을 실행하는 경우에 웨이크업 키워드와 자연어 음 성 명령이 발화되는 예를 도시한다. 도 8b는 일 실시예에 따른 음성 제어 장치가 도 7의 동작 방법을 실행하는 경우에 일반 대화 음성이 발화되는 예를 도시한다."}
