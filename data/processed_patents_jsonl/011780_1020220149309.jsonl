{"patent_id": "10-2022-0149309", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0068176", "출원번호": "10-2022-0149309", "발명의 명칭": "증강현실을 이용한 이미지 정합 기반 의료영상 생성장치 및 이의 동작 방법", "출원인": "재단법인 아산사회복지재단", "발명자": "최종우"}}
{"patent_id": "10-2022-0149309", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "증강현실(Augmented Reality; AR)을 이용한 의료영상 처리장치의 동작 방법에 있어서,제1 외부장치로부터 단층촬영에 따른 혈관정보 및 골조직정보를 포함하는 제1 이미지를 획득하는 단계;제2 외부장치로부터 3차원촬영에 따른 안면구조 및 안면굴곡을 포함하는 제2 이미지를 획득하는 단계;상기 혈관정보, 상기 골조직정보, 상기 안면구조, 상기 안면굴곡을 포함하는 안면 고유정보로부터 안면 특징점을 추출하는 단계;상기 안면 특징점에 기반해 상기 제2 이미지에 상기 제1 이미지를 정합하는 단계;상기 제2 이미지와 정합된 제1 이미지를 3D 모델링함으로써 합성이미지를 생성하는 단계;상기 합성이미지를 환자 안면에 투영하는 단계; 및투영 이미지 상에 상기 혈관정보에 상응하는 제1 레이어 및 상기 골조직정보를 포함하는 제2 레이어를 표시하는단계를 포함하는, 의료영상 처리장치의 동작 방법."}
{"patent_id": "10-2022-0149309", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 안면 고유정보로부터 안면 특징점을 추출하는 단계는,상기 제1 이미지로부터 골조직 및 혈관에 상응하는 적어도 하나의 제1 특징점을 추출하는 단계; 및상기 제2 이미지로부터 해부학적 특징에 기반해 인체의 눈, 코, 입, 및 귀에 대한 피부 영역에 상응하는 적어도하나의 제2 특징점을 추출하는 단계; 상기 제1 특징점 및 상기 제2 특징점을 기반으로 상기 안면 특징점을 추출하는 단계를 포함하는 것을 특징으로하는, 의료영상 처리장치의 동작 방법."}
{"patent_id": "10-2022-0149309", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,상기 안면 특징점에 기반해 상기 제2 이미지에 상기 제1 이미지를 정합하는 단계는,상기 안면 특징점을 상기 제2 이미지로부터 도출된 피부 표면에 기반해 정합하는 단계를 포함하는 것을 특징으로 하는, 의료영상 처리장치의 동작 방법."}
{"patent_id": "10-2022-0149309", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제2항에 있어서,상기 적어도 하나의 제2 특징점을 추출하는 단계는,변형이 적은 안면 내 안정특징점을 추출하는 단계; 및안정특징점의 좌표 및 윤곽에 기반하여 상기 제2 특징점을 조정하는 단계를 포함하는 것을 특징으로 하는, 의료영상 처리장치의 동작 방법."}
{"patent_id": "10-2022-0149309", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서, 상기 안정특징점은,공개특허 10-2024-0068176-3-양안의 얼굴 윤곽 전체에 대한 위치 및 크기인 것을 특징으로 하는, 의료영상 처리장치의 동작 방법."}
{"patent_id": "10-2022-0149309", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서, 상기 안면 특징점은, 이미지 정합에 이용되는 마커(Marker)로 기능하는 것을 특징으로 하는, 의료영상 처리장치의 동작 방법."}
{"patent_id": "10-2022-0149309", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에 있어서,상기 합성이미지를 환자 안면에 투영하는 단계는,상기 제2 외부장치로부터 실시간 환자안면이미지를 획득하는 단계;상기 실시간 환자안면이미지로부터 상기 안면 특징점을 탐색하는 단계; 및상기 실시간 환자안면이미지의 변동에 따라 상기 합성이미지와 상기 안면 특징점의 정합을 지속적으로 계산하는단계를 포함하는 것을 특징으로 하는, 의료영상 처리장치의 동작 방법."}
{"patent_id": "10-2022-0149309", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서,상기 실시간 환자안면이미지의 변동에 따라 상기 합성이미지와 상기 안면 특징점의 정합을 지속적으로 계산하는단계는,양안 위치에 대응되는 부분에 기초하여 상기 합성이미지와 상기 실시간 환자안면이미지를 1차 정합하는 단계;및상기 1차 정합을 수행한 후, 양안 위치 외의 안면에 대응되는 부분에 기초하여 상기 합성이미지와 상기 실시간환자안면이미지를 2차 정합하는 단계를 포함하는 것을 특징으로 하는, 의료영상 처리장치의 동작 방법."}
{"patent_id": "10-2022-0149309", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1항에 있어서,상기 안면 특징점에 기반해 상기 제2 이미지에 상기 제1 이미지를 정합하는 단계는,제1 정합 알고리즘에 기초하여 골조직 및 혈관에 상응하는 적어도 하나의 제1 특징점과, 상기 제2 이미지로부터인체의 눈, 코, 입, 및 귀에 대한 피부 영역에 상응하는 적어도 하나의 제2 특징점의 근사 위치를 계산하는 단계; 및제2 정합 알고리즘에 기초하여 상기 적어도 하나의 제1 특징점과 상기 적어도 하나의 제2 특징점의 정밀 위치를계산하는 단계를 포함하는 것을 특징으로 하는, 의료영상 처리장치의 동작 방법."}
{"patent_id": "10-2022-0149309", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제1항에 있어서,투영 이미지 상에 상기 혈관정보에 상응하는 제1 레이어 및 상기 골조직정보를 포함하는 제2 레이어를 표시하는단계는,상기 제1 레이어를 표시하는 단계; 및상기 제2 레이어를, 상기 제1 레이어가 표시되지 않는 시점 또는 영역에 분리하여 표시하는 단계를 포함하는 것을 특징으로 하는, 의료영상 처리장치의 동작 방법."}
{"patent_id": "10-2022-0149309", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "컴퓨터와 결합되어, 제1항 내지 제10항 중 어느 한 항에 따른 의료영상 처리장치의 동작 방법을 실행시키는 프공개특허 10-2024-0068176-4-로그램이 저장된 컴퓨터 판독 가능한 기록매체."}
{"patent_id": "10-2022-0149309", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "증강현실(Augmented Reality; AR)을 이용한 의료영상 처리장치로서, 이미지로부터 특징부룰 추출하도록 구성된 특징 추출모듈, 적어도 두 개의 이미지를 정합하도록 구성된 이미지정합모듈, 이미지를 구성하는 데이터를 미리 정의된 연산에 따라 이미지 프로세싱하도록 구성된 이미지 처리모듈, 및 처리된 이미지를 증강현실로 구현 및 표시하도록 구성된 증강현실 처리모듈을 저장하는 메모리;하나 이상의 코어를 포함하고, 상기 특징 추출모듈, 상기 이미지 정합모듈, 상기 이미지 처리모듈, 및 상기 증강현실 처리모듈의 동작을 제어하는 프로세서를 포함하고,상기 메모리는, 외부장치로부터 혈관정보 및 골조직정보를 포함하는 제1 이미지, 및 안면구조 및 안면굴곡을 포함하는 제2 이미지를 획득하고,상기 프로세서는,상기 혈관정보, 상기 골조직정보, 상기 안면구조, 상기 안면굴곡을 포함하는 안면 고유정보로부터 안면 특징점을 추출하고, 상기 안면 특징점에 기반해 상기 제2 이미지에 상기 제1 이미지를 정합하고, 상기 제2 이미지와정합된 제1 이미지를 3D 모델링함으로써 합성이미지를 생성하고, 상기 합성이미지를 환자 안면에 투영하고, 투영 이미지 상에 상기 혈관정보에 상응하는 제1 레이어 및 상기 골조직정보를 포함하는 제2 레이어를 표시하는것을 특징으로 하는, 의료영상 처리장치."}
{"patent_id": "10-2022-0149309", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제12항에 있어서,상기 프로세서는, 상기 안면 특징점을 추출 시에,상기 제1 이미지로부터 골조직 및 혈관에 상응하는 적어도 하나의 제1 특징점을 추출하고, 상기 제2 이미지로부터 해부학적 특징에 기반해 인체의 눈, 코, 입, 및 귀에 대한 피부영역에 상응하는적어도하나의 제2 특징점을 추출하며, 상기 제1 특징점 및 상기 제2 특징점을 기반으로 상기 안면 특징점을 추출하는 것을 특징으로 하는, 의료영상처리장치."}
{"patent_id": "10-2022-0149309", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제13항에 있어서,상기 프로세서는, 상기 안면 특징점에 기반해 상기 제2 이미지에 상기 제1 이미지를 정합 시에,상기 안면 특징점을 상기 제2 이미지로부터 도출된 피부 표면에 기반해 정합하는 것을 특징으로 하는, 의료영상처리장치."}
{"patent_id": "10-2022-0149309", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제13항에 있어서,상기 프로세서는, 상기 적어도 하나의 제2 특징점을 추출 시에,변형이 적은 안면 내 안정특징점을 추출하고, 안정특징점의 좌표 및 윤곽에 기반하여 상기 제2 특징점을 조정하는 것을 특징으로 하는, 의료영상 처리장치."}
{"patent_id": "10-2022-0149309", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제15항에 있어서,상기 안정특징점은, 공개특허 10-2024-0068176-5-양안의 얼굴 윤곽 전체에 대한 위치 및 크기인 것을 특징으로 하는, 의료영상 처리장치."}
{"patent_id": "10-2022-0149309", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제12항에 있어서,상기 안면 특징점은, 이미지 정합에 이용되는 마커(Marker)로 기능하는 것을 특징으로 하는, 의료영상 처리장치."}
{"patent_id": "10-2022-0149309", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제12항에 있어서,상기 메모리는,상기 외부장치로부터 실시간 환자안면이미지를 더 획득하고,상기 프로세서는, 상기 합성 이미지를 환자 안명에 투영 시에,상기 실시간 환자안면이미지로부터 상기 안면 특징점을 탐색하고, 상기 실시간 환자안면이미지의 변동에 따라 상기 합성이미지와 상기 안면 특징점의 정합을 지속적으로 계산하는것을 특징으로 하는, 의료영상 처리장치."}
{"patent_id": "10-2022-0149309", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제12항에 있어서,상기 프로세서는, 상기 제2 이미지에 상기 제1 이미지를 정합 시에,제1 정합 알고리즘에 기초하여 골조직 및 혈관에 상응하는 적어도 하나의 제1 특징점과, 상기 제2 이미지로부터인체의 눈, 코, 입, 및 귀에 대한 피부 영역에 상응하는 적어도 하나의 제2 특징점의 근사 위치를 계산하고,제2 정합 알고리즘에 기초하여 상기 적어도 하나의 제1 특징점과 상기 적어도 하나의 제2 특징점의 정밀 위치를계산하는 것을 특징으로 하는, 의료영상 처리장치."}
{"patent_id": "10-2022-0149309", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "컴퓨터 판독가능 저장 매체 저장된 컴퓨터 프로그램으로서, 상기 컴퓨터 프로그램은 하나 이상의 프로세서에서실행되는 경우, 증강현실(Augmented Reality; AR)을 이용한 의료영상 처리장치의 동작 방법을 수행하기 위한 이하의 동작들을 수행하도록 하며, 상기 동작들은:각기 상이한 외부장치로부터 획득된 혈관정보 및 골조직정보를 포함하는 제1 이미지, 및 안면구조 및 안면굴곡을 포함하는 제2 이미지로부터 각각 안면 특징점을 추출하는 단계;상기 안면 특징점에 기반해 상기 제2 이미지에 상기 제1 이미지를 정합하는 단계;상기 제2 이미지와 정합된 제1 이미지를 3D 모델링함으로써 합성이미지를 생성하는 단계;상기 합성이미지를 환자 안면에 투영하는 단계; 및투영 이미지 상에 상기 혈관정보에 상응하는 제1 레이어 및 상기 골조직정보를 포함하는 제2 레이어를 표시하는단계을 포함하는 것을 특징으로 하는 컴퓨터 판독가능 저장매체에 저장된 컴퓨터 프로그램."}
{"patent_id": "10-2022-0149309", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 개시의 예시적인 실시예에 따른 증강현실(Augmented Reality; AR)을 이용한 의료영상 처리장치의 동작 방법은, 제1 외부장치로부터 단층촬영에 따른 혈관정보 및 골조직정보를 포함하는 제1 이미지를 획득하는 단계. 제2 외부장치로부터 3차원촬영에 따른 안면구조 및 안면굴곡을 포함하는 제2 이미지를 획득하는 단계, 상기 혈관 정보, 상기 골조직정보, 상기 안면구조, 상기 안면굴곡을 포함하는 안면 고유정보로부터 안면 특징점을 추출하는 단계, 상기 안면 특징점에 기반해 상기 제2 이미지에 상기 제1 이미지를 정합하는 단계, 상기 제2 이미지와 정합 된 제1 이미지를 3D 모델링함으로써 합성이미지를 생성하는 단계, 상기 합성이미지를 환자 안면에 투영하는 단계 및 투영 이미지 상에 상기 혈관정보에 상응하는 제1 레이어 및 상기 골조직정보를 포함하는 제2 레이어를 표시하 는 단계를 포함한다."}
{"patent_id": "10-2022-0149309", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 의료영상 생성장치 및 이의 동작 방법에 관한 것이다. 보다 상세하게는, 본 개시는 증강현실을 이용 한 이미지 정합 기반 의료영상 생성장치 및 이의 동작 방법에 관한 것이다."}
{"patent_id": "10-2022-0149309", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "증강 현실(Augmented Reality, AR)은 현실의 이미지나 배경에 3차원 가상 이미지를 겹쳐서 하나의 영상으로 보 여주는 기술이다. 최근 의료 분야에 증강 현실 기술을 접목시키고자 하는 시도가 있다. 종래 기술로서, 수술 전 촬영된 영상(CT/MRI)을 이용하여 강체 정합(Rigid Registration) 결과를 AR 기술을 통 해 단순히 가시화하는 증강 현실 기반 네비게이션 기술들이 있다. 증강 현실 네비게이션 기술은 환자의 신체와 3D 오브젝트들 간의 좌표계의 정합이 필수적이고, 이에 따라 종래의 증강 현실 네비게이션 기술은 현실 세계의 정보로서 마커(marker)를 활용하여 좌표계의 정합을 수행한다. 마커기반 AR은 마커만을 기준으로 의료 영상의 정합이 결정되기 때문에 마커를 정교하게 설치해야하는 난점이 존재한다. 따라서, 증강현실을 이용하되, 마커를 설치하지 않거나, 마커가 설치된 이후에 환자 신체와 마커의 상대위치를 유지하는 모든 과정에서 휴먼 에러의 발생을 억제할 수 있는 새로운 기술이 요구되는 실정이다. 선행기술문헌 (특허문헌 1) 등록특허공보 10-1767005 B1(2017.08.03.)"}
{"patent_id": "10-2022-0149309", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 개시에 개시된 실시예는 증강현실(Augmented Reality; AR)을 이용한 의료영상 처리장치 및 이의 동작 방법을 제공하는데 그 목적이 있다. 본 개시가 해결하고자 하는 과제들은 이상에서 언급된 과제로 제한되지 않으며, 언급되지 않은 또 다른 과제들 은 아래의 기재로부터 통상의 기술자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2022-0149309", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상술한 기술적 과제를 달성하기 위한 본 개시의 예시적인 실시예에 따른 증강현실(Augmented Reality; AR)을 이 용한 의료영상 처리장치의 동작 방법은, 제1 외부장치로부터 단층촬영에 따른 혈관정보 및 골조직정보를 포함하 는 제1 이미지를 획득하는 단계. 제2 외부장치로부터 3차원촬영에 따른 안면구조 및 안면굴곡을 포함하는 제2 이미지를 획득하는 단계, 상기 혈관정보, 상기 골조직정보, 상기 안면구조, 상기 안면굴곡을 포함하는 안면 고 유정보로부터 안면 특징점을 추출하는 단계, 상기 안면 특징점에 기반해 상기 제2 이미지에 상기 제1 이미지를 정합하는 단계, 상기 제2 이미지와 정합된 제1 이미지를 3D 모델링함으로써 합성이미지를 생성하는 단계, 상기 합성이미지를 환자 안면에 투영하는 단계 및 투영 이미지 상에 상기 혈관정보에 상응하는 제1 레이어 및 상기 골조직정보를 포함하는 제2 레이어를 표시하는 단계를 포함할 수 있다. 또한, 본 개시의 예시적인 실시예에 따른 의료영상 처리장치는, 이미지로부터 특징부룰 추출하도록 구성된 특징 추출모듈, 적어도 두 개의 이미지를 정합하도록 구성된 이미지 정합모듈, 이미지를 구성하는 데이터를 미리 정 의된 연산에 따라 이미지 프로세싱하도록 구성된 이미지 처리모듈, 및 처리된 이미지를 증강현실로 구현 및 표 시하도록 구성된 증강현실 처리모듈을 저장하는 메모리, 하나 이상의 코어를 포함하고, 상기 특징 추출모듈, 상 기 이미지 정합모듈, 상기 이미지 처리모듈, 및 상기 증강현실 처리모듈의 동작을 제어하는 프로세서를 포함하 고, 상기 메모리는, 외부장치로부터 혈관정보 및 골조직정보를 포함하는 제1 이미지, 및 안면구조 및 안면굴곡 을 포함하는 제2 이미지를 획득하고, 상기 프로세서는, 상기 혈관정보, 상기 골조직정보, 상기 안면구조, 상기 안면굴곡을 포함하는 안면 고유정보로부터 안면 특징점을 추출하고, 상기 안면 특징점에 기반해 상기 제2 이미 지에 상기 제1 이미지를 정합하고, 상기 제2 이미지와 정합된 제1 이미지를 3D 모델링함으로써 합성이미지를 생 성하고, 상기 합성이미지를 환자 안면에 투영하고, 투영 이미지 상에 상기 혈관정보에 상응하는 제1 레이어 및 상기 골조직정보를 포함하는 제2 레이어를 표시하는 것을 특징으로 할 수 있다. 이 외에도, 본 개시를 구현하기 위한 실행하기 위한 컴퓨터 판독 가능한 기록 매체에 저장된 컴퓨터 프로그램이 더 제공될 수 있다. 본 개시의 예시적인 실시예에 따른 컴퓨터 판독가능 저장 매체 저장된 컴퓨터 프로그램은 하나 이상의 프로세서에서 실행되는 경우, 증강현실(Augmented Reality; AR)을 이용한 의료영상 처리장치의 동 작 방법을 수행하기 위한 이하의 동작들을 수행하도록 하며, 상기 동작들은 외부장치로부터 획득된 혈관정보, 골조직정보, 안면구조, 안면굴곡을 포함하는 안면 고유정보로부터 안면 특징점을 추출하는 단계, 상기 안면 특 징점에 기반해 상기 제2 이미지에 상기 제1 이미지를 정합하는 단계, 상기 제2 이미지와 정합된 제1 이미지를 3D 모델링함으로써 합성이미지를 생성하는 단계, 상기 합성이미지를 환자 안면에 투영하는 단계 및 투영 이미지 상에 상기 혈관정보에 상응하는 제1 레이어 및 상기 골조직정보를 포함하는 제2 레이어를 표시하는 단계을 포함하는 것을 특징으로 할 수 있다. 이 외에도, 본 개시를 구현하기 위한 방법을 실행하기 위한 컴퓨터 프로그램을 기록하는 컴퓨터 판독 가능한 기 록 매체가 더 제공될 수 있다."}
{"patent_id": "10-2022-0149309", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 개시의 전술한 과제 해결 수단에 의하면, 안면부을 중심으로 한 증강기술을 통해 안면부의 복잡하고 섬세한 구조를 고려하여 오차를 최소화한 안면부 증강기술이 제공될 수 있다. 본 개시의 전술한 과제 해결 수단에 의하면, 비마커 기반의 좌표계 정합을 통해 좌표계 정합의 정확도를 높일 수 있는 증강 현실 기반의 의료영상 처리 장치, 방법 및 컴퓨터 프로그램이 제공될 수 있다 본 개시의 전술한 과제 해결 수단에 의하면, 증강현실을 이용하되, 마커가 설치될 필요가 없거나, 마커가 설치 된 이후에 환자 신체와 마커의 상대위치를 유지하는 모든 과정에서 휴먼 에러의 발생이 억제될 수 있는 효과가 있다. 본 발명에 따르면, 3D 영상이 CT 영상과 정합된 이미지가 환자의 안면부에 투영되므로, 안면부 내부에 위치한 골조직 및 혈관조직의 위치 및 깊이가 시각적으로 표시될 수 있고 이로써 정확하고 안전한 안면부 수술이 달성 될 수 있다. 본 개시의 효과들은 이상에서 언급된 효과로 제한되지 않으며, 언급되지 않은 또 다른 효과들은 아래의 기재로 부터 통상의 기술자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2022-0149309", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 개시 전체에 걸쳐 동일 참조 부호는 동일 구성요소를 지칭한다. 본 개시가 실시예들의 모든 요소들을 설명"}
{"patent_id": "10-2022-0149309", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "하는 것은 아니며, 본 개시가 속하는 기술분야에서 일반적인 내용 또는 실시예들 간에 중복되는 내용은 생략한 다. 명세서에서 사용되는 '부, 모듈, 부재, 블록'이라는 용어는 소프트웨어 또는 하드웨어로 구현될 수 있으며, 실시예들에 따라 복수의 '부, 모듈, 부재, 블록'이 하나의 구성요소로 구현되거나, 하나의 '부, 모듈, 부재, 블 록'이 복수의 구성요소들을 포함하는 것도 가능하다. 명세서 전체에서, 어떤 부분이 다른 부분과 \"연결\"되어 있다고 할 때, 이는 직접적으로 연결되어 있는 경우 뿐 아니라, 간접적으로 연결되어 있는 경우를 포함하고, 간접적인 연결은 무선 통신망을 통해 연결되는 것을 포함 한다. 또한 어떤 부분이 어떤 구성요소를 \"포함\"한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다른 구성요소를 제외하는 것이 아니라 다른 구성요소를 더 포함할 수 있는 것을 의미한다. 명세서 전체에서, 어떤 부재가 다른 부재 \"상에\" 위치하고 있다고 할 때, 이는 어떤 부재가 다른 부재에 접해 있는 경우뿐 아니라 두 부재 사이에 또 다른 부재가 존재하는 경우도 포함한다. 제1, 제2 등의 용어는 하나의 구성요소를 다른 구성요소로부터 구별하기 위해 사용되는 것으로, 구성요소가 전 술된 용어들에 의해 제한되는 것은 아니다. 단수의 표현은 문맥상 명백하게 예외가 있지 않는 한, 복수의 표현을 포함한다. 각 단계들에 있어 식별부호는 설명의 편의를 위하여 사용되는 것으로 식별부호는 각 단계들의 순서를 설명하는 것이 아니며, 각 단계들은 문맥상 명백하게 특정 순서를 기재하지 않는 이상 명기된 순서와 다르게 실시될 수 있다. 이하 첨부된 도면들을 참고하여 본 개시의 작용 원리 및 실시예들에 대해 설명한다. 본 명세서에서 '의료영상 처리장치'는 연산처리를 수행하여 사용자에게 결과를 제공할 수 있는 다양한 장치들이 모두 포함된다. 예를 들어, 본 개시에 따른 의료영상 처리장치는, 컴퓨터, 서버 장치 및 휴대용 단말기를 모두 포함하거나, 또는 어느 하나의 형태가 될 수 있다. 여기에서, 컴퓨터는 예를 들어, 웹 브라우저(WEB Browser)가 탑재된 노트북, 데스크톱(desktop), 랩톱(laptop), 태블릿 PC, 슬레이트 PC 등을 포함할 수 있다. 서버 장치는 외부 장치와 통신을 수행하여 정보를 처리하는 서버로써, 애플리케이션 서버, 컴퓨팅 서버, 데이터 베이스 서버, 파일 서버, 게임 서버, 메일 서버, 프록시 서버 및 웹 서버 등을 포함할 수 있다. 휴대용 단말기는 예를 들어, 휴대성과 이동성이 보장되는 무선 통신 장치로서, PCS(Personal Communication System), GSM(Global System for Mobile communications), PDC(Personal Digital Cellular), PHS(Personal Handyphone System), PDA(Personal Digital Assistant), IMT(International Mobile Telecommunication)-2000, CDMA(Code Division Multiple Access)-2000, W-CDMA(W-Code Division Multiple Access), WiBro(Wireless Broadband Internet) 단말, 스마트 폰(Smart Phone) 등과 같은 모든 종류의 핸드헬드(Handheld) 기반의 무선 통신 장치와 시계, 반지, 팔찌, 발찌, 목걸이, 안경, 콘택트 렌즈, 또는 머리 착용형 장치(head-mounted- device(HMD) 등과 같은 웨어러블 장치를 포함할 수 있다. 증강 현실(Augmented Reality, AR)은 현실의 이미지나 배경에 3차원 가상 이미지를 겹쳐서 하나의 영상으로 보 여주는 기술이다. 이러한 증강 현실 기술은 다양한 스마트 기기를 통해 게임, 헬스, 지도 서비스 등의 다양한 분야에 적용되고 있으며, 최근에는 의료 분야에 증강 현실 기술이 이용된다. 외과수술 중 증강현실의 장점이 강조되는 수술은 두경부 (Head and Neck) 및 안면부 (Facial) 수술이다. 두경부 및 안면부의 복잡하고 섬세한 구조 때문에 정확한 해부학적 정보가 필요했던 수술에서 증강현실이 활용됨으로써 의료진들은 직관적으로 의료영상을 확인할 수 있게 되었다. 특히 안면부는 다른 신체 부분들에 비해 해부학적 랜드마크(Landmark)가 명확하고 많기 때문에, 수술 타겟의 위치와 주요 랜드마크와의 거리를 파악하는데 증강현 실 기술이 큰 도움이 된다. 의료영역에서 가장 많이 쓰이는 증강현실 구현 방식은 '마커 기반 AR (Marker-based AR)' 방식으로서 의료영상 투영의 기준이 되는 인공 마커(Fiducial Marker)를 강체에 견고하게 설치할 필요가 있다. 정형외과 수술에서는 주로 뼈가 수술 타겟이기 때문에 뼈에 마커를 설치할 수 있다. 그러나 두경부 및 안면부 수술에서는 뇌 또는 피부와 같이 연조직이 타겟인 경우가 많고, 안면골절 수술의 경우 에도 두개골에 마커를 설치하기가 힘들다. 뼈와 표피층이 가깝고 지방층이 거의 없는 이마에 마커를 설치하더라 도, 마커 설치 과정에서 휴먼 에러(Human Error)로 인한 오차가 발생할 여지가 존재한다. 마커기반 AR은 마커만 을 기준으로 의료 영상의 정합이 결정되기 때문에 마커를 정교하게 설치해야하는 난점이 존재한다. 따라서, 증 강현실을 이용하되, 마커를 설치하지 않거나, 마커가 설치된 이후에 환자 신체와 마커의 상대위치를 유지하는 모든 과정에서 휴먼 에러의 발생을 억제할 수 있는 새로운 기술이 요구되는 실정이다. 도 1은 본 개시의 예시적 실시예에 따른 의료영상 처리 시스템을 도시하는 블록도이다. 도 1을 참조하면, 의료영상 처리 시스템은 의료영상 처리장치, 단층촬영장치, 및 3D촬영장치를 포함할 수 있다. 의료영상 처리 시스템은 환자의 수술 또는 시술 전 의료정보를 획득하고, 획득된 의료정보로부터 시술에 필 요한 특징 데이터들을 추출하여, 수술 또는 시술에 필요한 데이터로 가공할 수 있다. 예시적인 실시예에 따르면, 단층촬영장치는 컴퓨터 단층촬영(Computed Tomography; CT), 을 통해 인체를 엑스선 또는 초음파를 이용한 결과를 컴퓨터로 재구성해 인체 내부 단면을 이미지로 처리할 수 있다. 본 개시에서는 설명의 편의를 위 해 CT 촬영이 예시되었으나, 단층촬영장치는 컴퓨터단층촬영(CT: Computed Tomography), 자기공명영상(MRI:Magnetic Resonance Imaging) 및 양전자 단층촬영(PET: Positron Emission Tomography)을 통한 인체 내부 영상 의 촬영을 의미할 수 있다.. 예시적인 실시예에 따르면, 3D촬영장치는 스테레오 카메라, 및/또는 깊이 카메라를 이용해 객체에 대한 3차 원 이미지 정보를 획득할 수 있다. 본 개시의 예시적인 실시예에 따르면, 의료영상 처리 시스템은 의료영상을 추출하기 위한 인공적인 마커의 물리적 설치 없이, 단층촬영장치로부터의 단층촬영이미지 및 3D촬영장치로부터의 3D이미지를 획득한 의 료영상 처리장치의 데이터 분석을 통해 마커리스(marker-less) 기반의 의료영상 처리를 수행할 수 있다. 이 로써, 의료영상 처리 시스템은 마커가 설치될 필요가 없거나, 마커가 설치된 이후에 환자 신체와 마커의 상 대위치를 유지하는 모든 과정에서 휴먼 에러의 발생이 억제될 수 있는 효과가 있다. 본 개시의 예시적인 실시예에서 의료영상 처리 시스템은 증강현실 기술을 이용하여 마커리스 기반 의료영상 을 환자의 안면부에 투영할 수 있다. 이로써 의료영상 처리 시스템은 안면부 내부에 위치한 골조직 및 혈관 조직의 위치 및 깊이를 시각적으로 표시할 수 있고, 의료진은 의료영상 처리 시스템을 이용하여 정확하고 안 전한 안면부 수술을 달성할 수 있다. 의료영상 처리장치는 입력 인터페이스(Interface; I/F), 특징 추출모듈, 이미지 정합모듈, 이미지 처리모듈, 증강현실 처리모듈, 출력 인터페이스, 및 데이터베이스를 포함할 수 있 다. 도 1의 의료영상 처리장치는 본 발명의 일 실시예에 불과하므로 도 1을 통해 본 발명이 한정 해석되는 것은 아니다. 입력 인터페이스는 영상 정보(또는 신호), 오디오 정보(또는 신호), 데이터, 또는 사용자로부터 입력되는 정보의 입력을 위한 것으로서, 적어도 하나의 카메라, 적어도 하나의 마이크로폰 및 사용자 입력 인터페이스 중 적어도 하나를 포함할 수 있다. 입력 인터페이스에서 수집한 음성 데이터나 이미지 데이터는 분 석되어 사용자의 제어명령으로 처리될 수 있다. 본 개시의 예시적인 실시예에서, 입력 인터페이스는 인터페이스부는 본 장치에 연결되는 다양한 종류의 외 부 기기와의 통로 역할을 수행한다. 이러한 인터페이스부는 유/무선 헤드셋 포트(port), 외부 충전기 포트 (port), 유/무선 데이터 포트(port), 메모리 카드(memory card) 포트, 식별 모듈(SIM)이 구비된 장치를 연결하 는 포트(port), 오디오 I/O(Input/Output) 포트(port), 비디오 I/O(Input/Output) 포트(port), 이어폰 포트 (port) 중 적어도 하나를 포함할 수 있다. 본 장치에서는, 상기 인터페이스부에 연결된 외부 기기와 관련된 적 절한 제어를 수행할 수 있다. 카메라는 촬영 모드에서 이미지 센서에 의해 얻어지는 정지영상 또는 동영상 등의 화상 프레임을 처리한다. 처 리된 화상 프레임은 디스플레이부를 통해 표시되거나, 또는 환자의 안면부에 광신호로서 직접 투사되거나 메모 리에 저장될 수 있다. 한편, 상기 카메라가 복수개일 경우, 매트릭스 구조를 이루도록 배치될 수 있으며, 이와 같이 매트릭스 구조를 이루는 카메라들을 통해 다양한 각도 또는 초점을 갖는 복수의 영상정보가 입력될 수 있고, 또한 상기 카메라들 은 3차원의 입체영상을 구현하기 위한 좌 영상 및 우 영상을 획득하도록, 스트레오 구조로 배치될 수도 있다. 사용자 입력 인터페이스는 사용자로부터 정보를 입력받기 위한 것으로서, 사용자 입력 인터페이스를 통해 정보가 입력되면, 제어부는 입력된 정보에 대응되도록 본 장치의 동작을 제어할 수 있다. 이러한, 사용자 입력 인터페이스는 하드웨어식 물리 키(예를 들어, 본 장치의 전면, 후면 및 측면 중 적어도 하나에 위치 하는 버튼, 돔 스위치 (dome switch), 조그 휠, 조그 스위치 등) 및 소프트웨어식 터치 키를 포함할 수 있다. 일 예로서, 터치 키는, 소프트웨어적인 처리를 통해 터치스크린 타입의 디스플레이부 상에 표시되는 가상 키 (virtual key), 소프트 키(soft key) 또는 비주얼 키(visual key)로 이루어지거나, 상기 터치스크린 이외의 부 분에 배치되는 터치 키(touch key)로 이루어질 수 있다. 한편, 상기 가상키 또는 비주얼 키는, 다양한 형태를 가지면서 터치스크린 상에 표시되는 것이 가능하며, 예를 들어, 그래픽(graphic), 텍스트(text), 아이콘(icon), 비디오(video) 또는 이들의 조합으로 이루어질 수 있다. 센싱부는 본 장치의 내 정보, 본 장치를 둘러싼 주변 환경 정보 및 사용자 정보 중 적어도 하나를 센싱하고, 이 에 대응하는 센싱 신호를 발생시킨다. 제어부는 이러한 센싱 신호에 기초하여, 본 장치의 구동 또는 동작을 제 어하거나, 본 장치에 설치된 응용 프로그램과 관련된 데이터 처리, 기능 또는 동작을 수행 할 수 있다. 상기와 같은, 센싱부는 근접센서(proximity sensor), 조도 센서(illumination sensor), 터치 센서(touch sensor), 가속도 센서(acceleration sensor), 자기 센서(magnetic sensor), 중력 센서(G-sensor), 자이로스코 프 센서(gyroscope sensor), 모션 센서(motion sensor), RGB 센서, 적외선 센서(IR 센서: infrared sensor), 지문인식 센서(finger scan sensor), 초음파 센서(ultrasonic sensor), 광 센서(optical sensor, 예를 들어, 카메라), 마이크로폰, 환경 센서(예를 들어, 기압계, 습도계, 온도계, 방사능 감지 센서, 열 감지 센서, 가스 감지 센서 중 적어도 하나를 포함함), 화학 센서(예를 들어, 헬스케어 센서, 생체 인식 센서 등) 중 적어도 하 나를 포함할 수 있다. 한편, 본 장치는, 이러한 센서들 중 적어도 둘 이상의 센서에서 센싱되는 정보들을 조합 하여 활용할 수 있다. 본 개시의 예시적인 실시예에 따르면, 입력 인터페이스는 외부 장치로부터 환자 안면에 대한 의료정보 이 미지를 수신할 수 있다. 예를 들어, 외부 장치 중 카메라는 환자가 위치하는 공간의 정보를 포함하는 실시간 영 상을 획득할 수 있다. 예를 들어, 카메라는 환자 안면부에 대한 실시간 영상을 획득할 수 있다. 예를 들어, 카 메라는 안면 이미지로부터 적어도 하나의 특징점을 추출하고, 깊이 카메라의 위치 및 방향을 지속적으로 계산할 수 있다. 카메라의 위치 및 방향은 후술하는 바와 같이 증강 현실 기반의 의료영상을 추적하는데 사용될 수 있 다. 특징 추출모듈은 이미지로부터 특징부룰 추출하도록 구성될 수 있다. 예시적인 실시예에 따르면, 특징 추 출모듈은 의료영상 이미지 내의 혈관, 골조직, 안면굴곡, 각종 뼈 등 특징 또는 기준이 되는 신체 조직 또 는 신체 부위로부터 특징점을 추출할 수 있다. 본 개시에서, 특징점의 정보는 3차원 공간 상의 3차원 위치 정 보를 포함할 수 있고, 특징점의 3차원 위치 정보는 마커(Marker)로서 기능할 수 있다. 이미지 정합모듈은 적어도 두 개의 이미지를 정합하도록 구성될 수 있다. 예시적인 실시예에 따르면, 이미 지 정합모듈은 둘 이상의 이미지에서 추출된 적어도 하나의 특징점(feature point)들을 서로 정합(또는, 매칭; matching)시킬 수 있다. 이미지 정합모듈은 널리 알려진 이미지 정합 알고리즘을 사용하거나, 이미 지 정합을 위해 스테레오 변환 등에 필요한 룩업테이블을 미리 저장하고 연산 결과값들을 필요할 때마다 로딩할 수 있다. 예시적인 실시예에 따르면, 이미지 정합모듈은 제1 특징점을 다운사이즈 샘플링(downsize sampling)한 후, 두 점(Point Pair)을 선택하여 이 두 점의 차로서 위치와 방향(즉, 위치와 normal vector)을 양자화해 색인될 수 있도록 구성하고 룩업테이블에 저장할 수 있다. 본 개시의 예시적인 실시예에 따르면 이미지 정합모듈은 특징점에 기초하여 3D이미지와 단층촬영영상을 정 합할 수 있다. 이로써, 이미지 정합모듈은 인위적인 마커를 이용하지 않는 비마커 기반으로 좌표계의 정합 을 수행하며, 구체적으로, 안면 내 특징점을 마커로서 기능하도록 설정하여 좌표계의 정합을 수행한다. 본 개시의 예시적인 실시예에 따르면 이미지 정합모듈은 실시간 환자안면이미지의 변동에 따라 상기 합성 이미지와 상기 안면 특징점의 정합을 지속적으로 계산할 수 있다. 일반적으로 수술 또는 시술 동안 환자는 마취 상태이므로 변동상태가 크지 않지만, 의료진의 수술 또는 시술에 따라 안면부가 손 또는 의료기기에 의해 접촉 됨으로써 미세한 위치 및 각도 변동이 발생할 수 있다. 이미지 정합모듈은 실시간 환자안면이미지의 변동 에 따라 상기 합성이미지와 상기 안면 특징점의 정합을 지속적으로 계산함으로써 정확한 이미지 투영을 달성할 수 있다. 예시적인 실시예에서, 이미지 정합모듈은 양안 위치에 대응되는 부분에 기초하여 상기 합성이미지와 상기 실시간 환자안면이미지를 1차 정합할 수 있다. 예시적인 실시예에서, 이미지 정합모듈은 정합의 정확도를 더욱 높이기 위해 1차 정합을 수행한 후, 양안 위치 외의 안면에 대응되는 부분에 기초하여 상기 합성이미지와 상기 실시간 환자안면이미지를 2차 정합할 수 있다. 즉, 이미지 정합모듈은 비교적 변형이 잘 이루어지지 않는 기준점(예를 들어, 양안)에 대한 정보에 기초하여 1차 정합을 먼저 수행함으로써, 정합의 정확도를 높일 수 있다. 예시적인 실시예에서, 이미지 정합모듈은 제1 정합 알고리즘 및 제2 정합 알고리즘을 이용하여 정합을 수 행할 수 있다. 예를 들어, 이미지 정합모듈은 제1 정합 알고리즘에 기초하여 안면 CT 기반 혈관 및 골조직 을 포함한 제1 이미지로부터의 제1 특징점과, 안면 3D 촬상 기반 제2 이미지로부터의 제2 특징점의 근사 위치를 계산할 수 있다. 여기서, 근사 위치는 위치와 방향을 의미할 수 있다. 이미지 정합모듈은 제1 정합 알고리즘으로서 예를 들어, PPF(Point Pair Feature) 알고리즘을 이용하여 제1 특징점과 제2 특징점의 근사 위치를 계산할 수 있다. 구체적으로, 이미지 정합모듈은 특징점을 다운사 이즈 샘플링(downsize sampling)한 후, 두 점(Point Pair)을 선택할 수 있다. 이후, 이미지 정합모듈은 선택된 두 점을 양자화(연속적이지 않고, 일정 구간의 정보가 하나의 정보로 병합)하여 룩업테이블에서 동일 또는 유사한 두 점을 선택할 수 있다. 예를 들어, 이미지 정합모듈은 양자화된 두 점과의 유사도가 가장 높 은 점수를 얻은 후보군을 뽑고, 이에 기초하여 제1 특징점과 제2 특징점의 근사 위치를 계산할 수 있다. 예시적 인 실시예에서, PPF 알고리즘은 양자화(연속적이지 않고, 일정 구간의 정보가 하나의 정보로 병합)되어 이용되 므로 정확도 개선이 필요하다. 이에, 본 발명에서는 PPF 알고리즘과 함께 후술하는 제2 알고리즘을 추가적으로 이용하여 정합의 정확도를 높인다. 이미지 정합모듈은 제1 특징점과 제2 특징점의 근사 위치를 계산한 후, 제2 정합 알고리즘에 기초하여 기 준 피부에 대응하는 복수의 제1 특징점과 기준 피부에 대응하는 복수의 제2 특징점의 정밀 위치를 계산할 수 있 다. 이미지 정합모듈은 상술한 근사 위치를 시작점으로 제2 정합 알고리즘으로서 예를 들어, ICP(Iterative Closest Point) 알고리즘을 이용하여 복수의 제1 특징점과 복수의 제2 특징점의 정밀 위치를 계 산할 수 있다. 여기서, 정밀 위치는 이동 및 회전을 의미할 수 있다. 즉, 이미지 정합모듈은 PPF 알고리즘을 통해 근사 위치로서 위치와 방향을 검출하고, ICP 알고리즘을 통 해 정밀 위치로서 이동 및 회전을 검출하여 점들간의 거리가 더욱 가까워지도록 한다. 이와 같이, 본 발명은 PPF 알고리즘을 이용하여 근사한 위치를 찾고 이를 시작점으로 ICP 알고리즘을 통한 정합을 수행함으로써 정합 의 정확도를 높일 수 있다. 다른 실시예로서, 이미지 정합모듈은 제2 정합 알고리즘만을 이용하여 정합을 수행할 수 있다. 예를 들어, 이미지 정합모듈은 기설정된 복수의 지점에서 사전 정합을 실시하여 초기값을 설정할 수 있다. 여 기서, 사전 정합은 ICP 알고리즘을 통해 수행될 수 있다. 이미지 정합모듈은 예를 들어, 실시간 영상에 대응하는 경계 박스(Scene bounding box)의 상면 중앙 및 제2 경계 박스의 중앙에서 사전 정합을 실시할 수 있 다. 이후, 이미지 정합모듈은 사전 정합의 결과 중 잔여 오류(residual error)가 최소인 지점의 위치 및 방향을 초기값으로 설정할 수 있다. 이어서, 이미지 정합모듈은 초기값에서부터 ICP 알고리즘을 적용하여 복수의 제1 특징점과 복수의 제2 특징점의 정밀 위치를 계산함으로써 정합을 수행할 수 있다. 이미지 처리모듈은 이미지를 구성하는 데이터를 미리 정의된 연산에 따라 이미지 프로세싱하도록 구성된 이미지 처리를 수행할 수 있다. 예시적인 실시예에서, 이미지 처리모듈은 비등방성 확산 필터(ADF: Anisotropic Diffusion Filter)를 이 용하여 의료영상의 노이즈를 제거할 수 있다. 비등방성 확산 필터는 일반적으로 사용되는 잡음 제거 필터들과 달리 영상의 정보를 분석하여 경계선(Edge) 정보는 유지하면서 노이즈를 효과적으로 제거한다. 의료 영상의 노 이즈를 제거함으로써 안면 이미지로부터 특징점 추출 시, 노이즈에 따른 안면 특징점 정보의 오차를 최소화할 수 있다. 예시적인 실시예에서, 이미지 처리모듈은 오츠 메소드(Otsu's Method)를 이용하여 의료영상에서 배경과 환 자 영역을 구분할 수 있다. 오츠 메소드는 입력 영상의 밝기 분포의 분석을 통한 영역 구분을 위해 입력 영상 에 대한 적응적 임계 값을 자동으로 찾아 주는 기법이다. 이러한 오츠 메소드를 이용한 쓰레드홀딩 (Thresholding) 기법은 영상의 밝기값만을 이용한 기법으로, 영상의 토폴로지(Topology)는 고려하지 않는다. 따 라서, 이미지 처리모듈은 영상의 토폴로지 정보를 고려하고 오분할된 영역을 제거하기 위해 SRG(Seeded Region Growing) 연산과 모폴로지(Morphology) 연산을 순차적으로 수행할 수 있다. SRG는 씨앗(Seed)을 기준으 로 조건을 만족하는 인접 화소들을 추적하여 확장하며 찾아나가는 과정을 이용한 기법이다. 모폴로지 연산은 침 식(erode)과 팽창(dilate)을 반복적으로 수행함으로써 분할 결과에 대하여 오분할된 노이즈 제거와 빈공간 (Empty space) 제거 등을 수행한다. 예시적인 실시예에서, 이미지 처리모듈은 의료영상의 슬라이스(slice) 단위로 환자 영역 분할을 수행할 수 있다. 분할된 전체 영상은 스킨 메쉬(Skin Mesh) 생성을 위한 볼륨 데이터(Volume Data)로써 활용된다. 예시적 인 실시예에서, 의료영상 중 일부는 스킨 메쉬(mesh) 형태로 3D 모델링된 데이터일 수 있다. 예를 들어, 3D 모 델링된 의료영상은 3차원 버텍스(vertex) 정보, 이들의 연결 정보 및 이로 인해 생성된 면 정보를 포함하는 3D 메쉬 정보일 수 있다. 예시적인 실시예에서, 이미지 처리모듈은 마칭 큐브(Marching Cube) 기법을 활용하여 스킨 메쉬를 생 성할 수 있다. 이미지 처리모듈은 는 스킨 메쉬를 생성할 때, 가우시안 필터(Gaussian Filter)를 3차원 상 에 적용하여 볼륨 데이터를 평활화(Smoothing)할 수 있다. 이로 인해, 마칭 큐브를 통해 생성될 메쉬에 평활화 를 적용한 것과 같은 효과를 줄 수 있다. 이미지 처리모듈은 Fast-Quadric Mesh Simplification 알고리즘을 이용하여 메쉬 단순화를 수행할 수 있 다. 메쉬 단순화를 수행함으로써 연산량, 메모리를 줄이는 것이 가능하다. 증강현실 처리모듈은 처리된 이미지를 증강현실로 구현 및 표시하도록 구성될 수 있다. 증강현실 처리모듈은 환자의 안면 특징점에 기초하여, 실시간 영상에서 환자의 신체(특히 안면) 상에 의료 정보가 출력되도록 하는 증강 현실 기반의 의료 영상을 생성할 수 있다. 예시적인 실시예에서, 증강현실 처리모듈은 실시간 영상에서의 환자의 신체 모델링의 투명도 및 콘트라스 트(Contrast) 를 조절함으로써 의사가 정합의 정확도를 확인할 수 있도록 할 수 있다. 또한, 실시간 영상에서 병변 및 관심조직을 좀 더 용이하게 식별하기 위해 밝기(brightness)를 조절할 수 있다. 예시적인 실시예에서, 증강현실 처리모듈은 실시간 영상에서의 환자의 신체 상에 의료 정보로서 예를 들어, CT plane, 병변, 병변과 가장 가까운 피부의 위치 정보, 병변과 해부학적인 축(anatomical axis) 방향 피 부의 위치 정보, 병변과 피부 사이의 거리 측정을 위한 눈금 중 적어도 하나를 출력할 수 있다. 본 개시의 예시적인 실시예에서, 증강현실 처리모듈은 환자 안면에 투영되는 투영 이미지 상에 혈관정보에 상응하는 제1 레이어 및 골조직정보를 포함하는 제2 레이어를 분리해 표시할 수 있다. 예를 들어, 제1 레이어로 서 혈관 정보가 환자의 안면 상에 증강현실 형태로 투영된 경우, 제2 레이어에 해당하는 골조직정보는 제1 레이 어가 표시되지 않는 시점, 또는 표시되지 않는 영역에 구분되어 표시될 수 있다. 실시예에 따라, 제1 및 제2 레 이어는 동시에 표시될 수도 있다. 본 개시의 예시적인 실시예에서, 증강현실 처리모듈은 의사가 특정 CT 슬라이스를 선택하면, 실시간 영상 에서의 환자의 신체 상에 해당 CT 슬라이스의 위치에 대응하는 위치(환자의 몸통 내부)에 해당 특정 CT 슬라이 스를 배치할 수 있다. 본 개시의 예시적인 실시예에서, 증강현실 처리모듈은 CT 슬라이스들을 적층해 3차원으로 데이터를 구성하고 이 데이터에서 원하는 방향으로의 단면(anatomical plane) 이미지를 생성하여 이를 표현할 수 있다. 본 개시의 예시적인 실시예에서, 증강현실 처리모듈은 단면 이미지 내에서 병변 부위의 제1 색(예를 들어, 붉은 색)을 변경하여 표현할 수 있다. 본 개시의 예시적인 실시예에서, 증강현실 처리모듈은 의사의 입력에 따라 실시간 영상에서의 환자의 신체 상에 선, 도형, 텍스트 등을 표현할 수 있다. 본 개시의 예시적인 실시예에서, 증강현실 처리모듈은 의사가 실시간 영상에서의 환자의 신체 상에 선, 도 형, 텍스트 등을 입력할 때, 화면에 표시된 적어도 하나의 요소(병변, 크기 및 위치 확인용 원반)의 투명도를 실시간으로 조절할 수 있다. 이로 인해 의사가 실시간 영상에서의 환자의 신체 상에 선, 도형, 텍스트 등을 쉽 게 확인할 수 있다. 본 개시의 예시적인 실시예에서, 증강현실 처리모듈은 깊이 카메라의 위치 및 방향에 기초하여 공간의 정 보를 추적하여 증강 현실 기반의 의료 영상을 지속적으로 출력할 수 있다. 즉 증강현실 처리모듈은 3D 모 델링된 의료영상 데이터와 실시간 영상을 최소 1회만을 정합한 후, 제3 알고리즘을 이용하여 매 프레임의 공간 정보를 추적함으로써, 3D 모델링 데이터와 실시간 영상의 정합을 지속적으로 유지한다. 여기서, 제3 알고리즘은 SLAM (Simultaneous localization and mapping) 알고리즘일 수 있다. 이와 달리, 실시간 추적(후술하는 깊이 카메라의 위치 및 방향의 변화를 감지)을 위해서 실시간 영상을 매 프레임마다 정합할 수도 있다. 이에 따라, 매 프레임마다 3D 모델링 데이터와 실시간 영상을 정합함에 따른 계산량이 증가하는 문제점을 해결할 수 있다. 본 개시의 예시적인 실시예에서, 증강현실 처리모듈은 공간의 영상 정보(RGB 정보 또는 깊이 정보)에 기초 하여 공간을 3차원 데이터로 구성하고, 3차원 데이터로부터 깊이 카메라의 위치 및 방향을 결정할 수 있다. 예 를 들어, 본 개시의 예시적인 실시예에서, 증강현실 처리모듈은 깊이 이미지로부터 3차원 공간의 점 정보 를 획득하거나 RGB의 특징점을 추출한 후, 이로부터 프레임간의 이동을 분석하여 깊이 카메라의 위치 및 방향 을 결정할 수 있다. 특징 추출모듈, 이미지 정합모듈, 이미지 처리모듈, 및 증강현실 처리모듈은 각각 동작을 제어하기 위한 알고리즘 또는 알고리즘을 재현한 프로그램으로 구현될 수 있다. 이 경우, 각 프로그램을 저장 하는 메모리, 및 메모리에 저장된 데이터를 이용하여 전술한 동작을 수행하는 적어도 하나의 프로세서(미도시) 로 각 프로그램이 컴퓨터 상에서 구현될 수 있다. 이때, 메모리와 프로세서는 각각 별개의 칩으로 구현될 수 있 다. 또는, 메모리와 프로세서는 단일 칩으로 구현될 수도 있다.프로세서는 의료영상 처리장치의 제어에 필요한 하나 이상의 명령을 처리하고, 명령에 따른 연산하고, 프로 그램 로직에 따른 판단을 수행하는 등 전자 장치의 각종 기능부의 유기적인 동작을 전반적으로 제어하도록 구성된다. 프로세서는 입출력 인터페이스 또는 각종 처리모듈(120 내지 150)을 통해 입력 또는 출력되는 신호, 데이터, 정보 등을 처리하거나 데이터베이스에 저장된 응용 프로그램을 구동함으로써, 사용자에게 적절한 정보 또는 기능을 제공 또는 처리할 수 있다. 처리된 데이터는 메모리에 저장되거나 데이터베이스 를 구축하는데 이용되거나, 입출력 인터페이스 또는 각종 처리모듈(120 내지 150)을 통해 외부에 전송될 수 있다. 이와 같은 프로세서는 범용 프로세서, 전용 프로세서 또는 애플리케이션 프로세서(application processor) 등으로 구현될 수 있다. 예시적인 실시예에서, 프로세서는 전용 논리 회로(예컨대, FPGA(Field Programmable Gate Array), ASICs(Application Specific Integrated Circuits) 등)를 포함하는 연산 프로세서 (예를 들어, CPU(Central Processing Unit), GPU(Graphic Processing Unit), AP(Application Processor) 등) 로 구현될 수 있으나 이에 제한되지 않는다. 예시적인 실시예에서, 프로세서는 아날로그 신호를 디지털로 변환 해 고속 처리할 수 있는 DSP(Digital Signal Processor), MCU(Micro Controller Unit), 또는 인공신경망을 처 리하는데 특화된 NPU(Neural Processing Unit) 등으로 구현됨을 배제하지 않는다. 프로세서는 이하의 도 2 내지 도 7에서 설명되는 본 개시에 따른 다양한 실시 예들을 본 장치 상에서 구현하기 위하여, 위에서 살펴본 구성요소들을 중 어느 하나 또는 복수를 조합하여 제어할 수 있다. 출력 인터페이스(I/F)는 시각, 청각 또는 촉각 등과 관련된 출력을 발생시키기 위한 것으로, 디스플레이부, 음향 출력 인터페이스, 햅팁 모듈 및 광 출력 인터페이스 중 적어도 하나를 포함할 수 있다. 디 스플레이부는 터치 센서와 상호 레이어 구조를 이루거나 일체형으로 형성됨으로써, 터치 스크린을 구현할 수 있 다. 이러한 터치 스크린은, 본 장치와 사용자 사이의 입력 인터페이스를 제공하는 사용자 입력부로써 기능함과 동시에, 본 장치와 사용자 간에 출력 인터페이스를 제공할 수 있다. 디스플레이부는 본 장치에서 처리되는 정보를 표시(출력)한다. 예를 들어, 디스플레이부는 본 장치에서 구동되 는 응용 프로그램(일 예로, 어플리케이션)의 실행화면 정보, 또는 이러한 실행화면 정보에 따른 UI(User Interface), GUI(Graphic User Interface) 정보를 표시할 수 있다. 음향 출력 인터페이스는 통신부를 통해 수신되거나 또는 메모리에 저장된 오디오 데이터를 출력하거나, 본 장치 에서 수행되는 기능과 관련된 음향 신호를 출력할 수 있다. 이러한 음향 출력 인터페이스에는 리시버 (receiver), 스피커(speaker), 버저(buzzer) 등이 포함될 수 있다. 햅틱 모듈(haptic module)은 사용자가 느낄 수 있는 다양한 촉각 효과를 발생시킨다. 햅틱 모듈이 발생시키는 촉각 효과의 대표적인 예로는 진동이 될 수 있다. 햅틱 모듈에서 발생하는 진동의 세기와 패턴 등은 사용자의 선택 또는 제어부의 설정에 의해 제어될 수 있다. 또한, 햅틱 모듈은 진동 외에도, 접촉 피부면에 대해 수직 운 동하는 핀 배열, 분사구나 흡입구를 통한 공기의 분사력이나 흡입력, 피부 표면에 대한 스침, 전극(electrode) 의 접촉, 정전기력 등의 자극에 의한 효과와, 흡열이나 발열 가능한 소자를 이용한 냉온감 재현에 의한 효과 등 다양한 촉각 효과를 발생시킬 수 있다. 햅틱 모듈은 직접적인 접촉을 통해 촉각 효과를 전달할 수 있을 뿐만 아니라, 사용자가 손가락이나 팔 등의 근 감각을 통해 촉각 효과를 느낄 수 있도록 구현할 수도 있다. 햅틱 모듈은 본 장치의 구성 태양에 따라 2개 이상 이 구비될 수 있다. 광출력 인터페이스는 본 장치의 광원의 빛을 이용하여 이벤트 발생을 알리기 위한 신호를 출력하거나 또는 프로젝터와 같이 영상과 같은 미디어를 외부 스크린 상에 표시되도록 출력할 수 있다. 예시적인 실시예에서, 광출력 인터페이스는 이미지를 증강현실 상에 표현하기 위해 오브젝트에 상이 입체적으로 투영되도록 광의 파장과 크기, 투상위치를 조절할 수 있다. 출력 인터페이스는 본 장치에 연결되는 다양한 종류의 외부 기기와의 통로 역할을 수행한다. 이러한 인터 페이스부는 유/무선 헤드셋 포트(port), 외부 충전기 포트(port), 유/무선 데이터 포트(port), 메모리 카드 (memory card) 포트, 식별 모듈(SIM)이 구비된 장치를 연결하는 포트(port), 오디오 I/O(Input/Output) 포트 (port), 비디오 I/O(Input/Output) 포트(port), 이어폰 포트(port) 중 적어도 하나를 포함할 수 있다. 데이터베이스는 각종 정보를 저장함으로써 공유되어 사용될 목적으로 통합 관리되는 데이터의 집합을 의미 한다. 데이터베이스는 데이터를 임시적으로 또는 반영구적으로 저장할 수 있다. 예를 들어, 데이터베이스 에는 적어도 하나의 디바이스를 구동하기 위한 운영 프로그램(OS: Operating System), 웹 사이트를 호스팅 하기 위한 데이터나 또는 애플리케이션(예를 들어, 웹 애플리케이션)에 관한 데이터 등이 저장될 수 있다. 또,데이터베이스는 상술한 바와 같이 모듈들을 컴퓨터 코드 형태로 저장할 수 있다. 데이터베이스는 응용 프 로그램과 별개인 미들웨어(Middle ware)를 통해 관리된다. 데이터베이스는 관계형 데이터베이스(RDB; relational database), 키-값형 데이터베이스, 객체형 데이터베 이스, 문서형 데이터베이스, 메모리 데이터베이스 등을 포함한다. 데이터베이스는 본 장치의 다양한 기능을 지원하는 데이터와, 제어부의 동작을 위한 프로그램을 저장할 수 있고, 입/출력되는 데이터들(예를 들어, 음악 파일, 정지영상, 동영상 등)을 저장할 있고, 본 장치에서 구동되 는 다수의 응용 프로그램(application program 또는 애플리케이션(application)), 본 장치의 동작을 위한 데이 터들, 명령어들을 저장할 수 있다. 이러한 응용 프로그램 중 적어도 일부는, 무선 통신을 통해 외부 서버로부터 다운로드 될 수 있다. 데이터베이스는 본 장치와는 분리되거나, 유선 또는 무선으로 연결된 메모리로 구현될 수 있다. 이 때 메 모리는 플래시 메모리 타입(flash memory type), 하드디스크 타입(hard disk type), SSD 타입(Solid State Disk type), SDD 타입(Silicon Disk Drive type), 멀티미디어 카드 마이크로 타입(multimedia card micro type), 카드 타입의 메모리(예를 들어 SD 또는 XD 메모리 등), 램(random access memory; RAM), SRAM(static random access memory), 롬(read-only memory; ROM), EEPROM(electrically erasable programmable read-only memory), PROM(programmable read-only memory), 자기 메모리, 자기 디스크 및 광디스크 중 적어도 하나의 타 입의 저장매체를 포함할 수 있다. 도 2는 본 개시의 예시적 실시예에 따른 의료영상 처리장치(도 1, 10)의 동작 방법을 나타내는 흐름도이다. 도 2에 도시된 일 실시예에 따른 증강 현실 기반의 의료영상 처리 방법은 도 1에 도시된 의료영상 처리장치(1 0)에서 시계열적, 또는 병렬적으로 처리되는 단계들을 포함하며, 의료영상 처리장치의 동작방법으로 지칭된다. 단계 S110에서, 의료영상 처리장치는 제1 외부장치로부터 단층촬영에 따른 혈관정보 및 골조직정보를 포함 하는 제1 이미지를 획득할 수 있다. 예시적인 실시예에서, 제1 외부장치는 단층촬영장치(도 1, 20)일 수 있다. 본 개시에서는 설명의 편의를 위해 CT 촬영이 예시되었으나, 단층촬영장치는 컴퓨터단층촬영(CT: Computed Tomography), 자기공명영상(MRI: Magnetic Resonance Imaging) 및 양전자 단층촬영(PET: Positron Emission Tomography)을 통한 인체 내부 영상의 촬영을 의미할 수 있다. 본 개시의 예시적인 실시예에 따르면, 의료영상 처리장치는 제1 이미지로부터 제1 안면 특징점을 추출할 수 있다. 제1 안면 특징점은 안면부에 분포된 혈관의 위치, 종류, 크기, 분포정도에 대한 정보를 포함하는 혈관정 보, 및 안면부를 구성하는 골조직의 위치, 종류, 크기, 분포정보에 대한 정보를 포함하는 골조직정보로부터 도 출될 수 있다. 단계 S120에서, 의료영상 처리장치는 제2 외부장치로부터 3차원촬영에 따른 안면구조 및 안면굴곡을 포함하 는 제2 이미지를 획득할 수 있다. 예시적인 실시예에 따르면, 3D촬영장치는 스테레오 카메라, 및/또는 깊이 카메라일 수 있고, 의료영상 처리장치는 스테레오 카메라, 및/또는 깊이 카메라의 촬영 결과를 이용해 객체 에 대한 3차원 이미지 정보를 획득할 수 있다. 본 개시의 예시적인 실시예에 따르면, 의료영상 처리장치는 제2 이미지로부터 제2 안면 특징점을 추출할 수 있다. 제2 안면 특징점은 안면부를 구성하는 안면구조 및 안면굴곡을 포함하며, 골의 형상과 구조는 물론 골을 덮고 있는 피부의 결과 분포, 피하지방과 근육, 및 표피와 진피를 포함하는 피부상태로부터 도출될 수 있다. 단계 S130에서, 의료영상 처리장치는 안면 특징점에 기반해 제2 이미지에 제1 이미지를 정합시킬 수 있다. 예시적인 실시예에 따르면, 의료영상 처리장치는 제1 안면 특징점 및 제2 안면 특징점에 기초하여 안면 특 징점을 추출할 수 있다. 예시적인 실시예에 따르면, 의료영상 처리장치는 혈관정보, 골조직정보, 안면구조, 안면굴곡을 포함하는 안면 고유정보로부터 안면 특징점을 추출할 수 있다. 예시적인 실시예에 따르면, 의료영상 처리장치는 안면 특징점에 기반해 제2 이미지에 제1 이미지를 정합할 수 있다. 예시적인 실시예에서, 의료영상 처리장치는 제1 정합 알고리즘 및 제2 정합 알고리즘을 이용하여 정합을 수 행할 수 있다. 예를 들어, 의료영상 처리장치는 제1 정합 알고리즘에 기초하여 안면 CT 기반 혈관 및 골조 직을 포함한 제1 이미지로부터의 제1 특징점과, 안면 3D 촬상 기반 안면의 눈, 코 입, 귀, 얼굴 뼈의 형상 및 골격, 안면구조를 포함하는 제2 이미지로부터의 제2 특징점의 위치와 방향을 의미하는 근사 위치를 계산할 수 있다. 예시적인 실시예에서, 의료영상 처리장치는 PPF(Point Pair Feature) 알고리즘을 이용해 특징점을 다 운사이즈 샘플링(downsize sampling)한 후, 두 점(Point Pair)을 선택 및 양자화해 룩업테이블에서 동일 유사한두점을 유사도에 기반해 근사위치를 연산할 수 있다. 예시적인 실시예에서, 의료영상 처리장치는 ICP(Iterative Closest Point) 알고리즘을 이용하여 복수의 제1 특징점과 복수의 제2 특징점의 정밀 위치를 계 산할 수 있다. 단계 S140에서, 의료영상 처리장치는 제2 이미지와 정합된 제1 이미지를 3D 모델링함으로써 합성이미지를 생성할 수 있다. 예시적인 실시예에서, 의료영상 처리장치는 단층촬영 기반의 제1 이미지와 3D촬영 기반의 제2 이미지를 정합시킨 결과로서, 환자의 실제 얼굴에 증강현실로서 투영할 대상인 합성이미지를 생성할 수 있 다. 단계 S130 및 단계 S140에 따른 이미지 처리 결과에 대하여는 도 5에서 보다 상세히 설명될 것이다. 단계 S150에서, 의료영상 처리장치는 합성이미지를 환자 안면에 투영할 수 있다. 예시적인 실시예에 따르면, 의료영상 처리장치는 외부장치로부터 실시간 환자안면이미지를 획득할 수 있다. 예시적인 실시예에 따르면, 의료영상 처리장치는 실시간 환자안면이미지로부터 안면 특징점을 탐색할 수 있다. 예시적인 실시 예에 따르면, 의료영상 처리장치는 실시간 환자안면이미지의 변동에 따라 합성이미지와 안면 특징점의 정합 을 지속적으로 계산할 수 있다. 예시적인 실시예에 따르면, 의료영상 처리장치는 실시간 환자안면이미지의 변동에 따라 합성이미지와 안면 특징점의 정합을 지속적으로 계산하는 단계로서, 양안 위치에 대응되는 부분에 기초하여 합성이미지와 실시간 환자안면이미지를 1차 정합할 수 있다. 예시적인 실시예에 따르면, 의료영상 처리장치는 1차 정합을 수행한 후, 양안 위치 외의 안면에 대응되는 부분에 기초하여 합성이미지와 실시간 환자안면이미지를 2차 정합할 수 있다. 예시적인 실시예에서, 의료영상 처리장치는 양안 위치에 대응되는 부분에 기초하여 합성이미지와 실시간 환 자안면이미지를 1차 정합할 수 있다. 예시적인 실시예에서, 이미지 정합모듈은 정합의 정확도를 더욱 높이 기 위해 1차 정합을 수행한 후, 양안 위치 외의 안면에 대응되는 부분에 기초하여 합성이미지와 실시간 환자안 면이미지를 2차 정합할 수 있다. 즉, 이미지 정합모듈은 비교적 변형이 잘 이루어지지 않는 기준점(예를 들어, 양안)에 대한 정보에 기초하여 1차 정합을 먼저 수행함으로써, 정합의 정확도를 높일 수 있다. 단계 S160에서, 의료영상 처리장치는 투영 이미지 상에 혈관정보에 상응하는 제1 레이어 및 골조직정보를 포함하는 제2 레이어를 표시할 수 있다. 예시적인 실시예에 따르면, 의료영상 처리장치는 제1 레이어를 표 시할 수 있다. 예시적인 실시예에 따르면, 의료영상 처리장치는 제2 레이어를, 제1 레이어가 표시되지 않는 시점 또는 영역에 분리하여 표시할 수 있다. 단계 S150 및 단계 S160에 관하여는 도 6 및 도 7에서 보다 상세히 설명될 것이다. 도 2에 도시된 구성 요소들의 성능에 대응하여 적어도 하나의 구성요소가 추가되거나 삭제될 수 있다. 또한, 구 성 요소들의 상호 위치는 시스템의 성능 또는 구조에 대응하여 변경될 수 있다는 것은 당해 기술 분야에서 통상 의 지식을 가진 자에게 용이하게 이해될 것이다. 한편, 도 2에서 도시된 각각의 구성요소는 소프트웨어 및/또는 Field Programmable Gate Array(FPGA) 및 주문 형 반도체(ASIC, Application Specific Integrated Circuit)와 같은 하드웨어 구성요소를 의미한다. 본 개시의 전술한 과제 해결 수단에 의하면, 안면부을 중심으로 한 증강기술을 통해 안면부의 복잡하고 섬세한 구조를 고려하여 오차를 최소화한 안면부 증강기술이 제공될 수 있다. 본 개시의 전술한 과제 해결 수단에 의하면, 비마커 기반의 좌표계 정합을 통해 좌표계 정합의 정확도를 높일 수 있는 증강 현실 기반의 의료영상 처리 장치, 방법 및 컴퓨터 프로그램이 제공될 수 있다. 본 개시의 전술한 과제 해결 수단에 의하면, 증강현실을 이용하되, 마커가 설치될 필요가 없거나, 마커가 설치 된 이후에 환자 신체와 마커의 상대위치를 유지하는 모든 과정에서 휴먼 에러의 발생이 억제될 수 있는 효과가 있다. 본 발명에 따르면, 3D 영상이 CT 영상과 정합된 이미지가 환자의 안면부에 투영되므로, 안면부 내부에 위치한 골조직 및 혈관조직의 위치 및 깊이가 시각적으로 표시될 수 있고 이로써 정확하고 안전한 안면부 수술이 달성 될 수 있다. 도 3은 본 개시의 예시적 실시예에 따른 의료영상 처리장치(도 1, 10)의 동작 방법 중 단계 S130의 세부 흐름도 이다. 단계 S120에 수행된 후, 단계 S210에서, 의료영상 처리장치는 제1 이미지로부터 골조직 및 혈관에 상응하는 적어도 하나의 제1 특징점을 추출할 수 있다. 예시적인 실시예에 따르면, 의료영상 처리장치는 외부장치로 부터 단층촬영에 따른 혈관정보 및 골조직정보를 포함하는 제1 이미지로부터 제1 특징점을 추출할 수 있다. 단계 S230에서, 의료영상 처리장치는 해부학적 특징에 기반해 인체의 눈, 코 입, 귀에 대한 피부 영역에 상 응하는 적어도 하나의 제2 특징점을 추출할 수 있다. 예시적인 실시예에 따르면, 의료영상 처리장치는 외부 장치로부터 3차원촬영에 따른 안면구조 및 안면굴곡을 포함하는 제2 이미지를 획득할 수 있으며, 3D촬영장치 는 스테레오 카메라, 및/또는 깊이 카메라일 수 있다. 의료영상 처리장치는 스테레오 카메라, 및/또는 깊이 카메라의 촬영 결과를 이용해 객체에 대한 3차원 이미지 정보를 획득한 결과에 대해 해부학적 특징에 기반 해 두개골 뼈, 코뼈, 귓볼 및 턱뼈를 포함하는 적어도 하나의 제2 특징점을 도출할 수 있다. 두개골 뼈, 코뼈, 귓볼 및 턱뼈는 안면굴곡 및 안면구조를 결정할 수 있는 요소이며, 제2 특징점은 골의 형상과 구조는 물론 골을 덮고 있는 피부의 결과 분포, 피하지방과 근육, 및 표피와 진피를 포함하는 피부상태로부터 도출될 수 있다. 제 2 특징점은 이미지의 특성에서 도출될 수 있거나, 비전 기반 인공지능 학습모델(예컨대, CNN(Convolutional Neural Network))의 특징 추출(Feature Extraction)을 통해 히든 레이어를 거친 결과 데이터로서 추출될 수 있 다. 본 개시의 예시적인 실시예에 따르면, 의료영상 처리장치는 제1 이미지로부터 제2 특징점을 추출할 수 있다. 제2 특징점은 안면부에 분포된 혈관의 위치, 종류, 크기, 분포정도에 대한 정보를 포함하는 혈관정보, 및 안면부를 구성하는 골조직의 위치, 종류, 크기, 분포정보에 대한 정보를 포함하는 골조직정보로부터 도출될 수 있다. 단계 S250에서, 의료영상 처리장치는 제1 특징점 및 제2 특징점들을 기반으로 안면 특징점을 추출할 수 있 다. 예시적인 실시예에 따르면, 의료영상 처리장치는 안면 특징점을 제2 이미지로부터 도출된 피부 표면에 기반해 정합할 수 있다. 예시적인 실시예에 따르면, 의료영상 처리장치는 제1 정합 알고리즘에 기초하여 해 부학적 특징에 기반해 두개골 뼈, 코뼈, 귓볼 및 턱뼈를 포함하는 적어도 하나의 제2 특징점과 골조직 및 혈관 을 포함하는 적어도 하나의 제1 특징점의 근사 위치를 계산할 수 있다. 예시적인 실시예에 따르면, 의료영상 처 리장치는 제2 정합 알고리즘에 기초하여 적어도 하나의 제1 특징점과 적어도 하나의 제2 특징점의 정밀 위 치를 계산할 수 있다. 제1 및 제2 정합 알고리즘에 관하여는 도 1 및 도 2에서 상세히 설명되었으므로 중복되는 설명은 생략한다. 도 4는 본 개시의 예시적 실시예에 따른 의료영상 처리장치의 동작 방법 중 단계 S230의 세부 흐름도이다. 단계 S231에서, 의료영상 처리장치는 변형이 적은 안면 내 안정특징점을 추출할 수 있다. 예시적인 실시예 에 따르면, 일반적으로 수술 또는 시술 동안 환자는 마취상태이므로 변동상태가 크지 않지만, 의료진의 수술 또 는 시술에 따라 안면부가 손 또는 의료기기에 의해 접촉됨으로써 미세한 위치 및 각도 변동이 발생할 수 있다. 의료영상 처리장치는 움직임 또는 변동이 발생하더라도 변형이 적고 탐색이 쉬운 양안(eyes)을 기준점으로 설정할 수 있고, 얀안의 위치 및 안면전체와의 크기 비율로부터 안정특징점을 추출할 수 있다. 본 개시에서는 설명의 편의를 위해 양안만이 예시되었으나, 안면 상부에서 관측되었을 때 쉽게 탐색이 가능하고 변화 또는 변 동 정도가 크지 않은 다양한 신체 내 조직, 혈관, 근육, 구조 등이 안정특징점으로 이용될 수 있다. 단계 S233에서, 의료영상 처리장치는 안정특징점의 좌표 및 윤곽에 기반하여 제2 특징점을 조정할 수 있다. 예시적인 실시예에 따르면, 안정특징점은 양안의 얼굴 윤곽 전체에 대한 위치 및 크기일 수 있다. 도 5는 본 개시의 예시적 실시예에 따른 의료영상 처리장치의 이미지 정합 동작에 따른 단층촬영이미지와 3D 이 미지의 합성을 나타내는 도면이다. 도 2를 함께 참조하면, 단계 S130에서, 의료영상 처리장치는 안면 특징점에 기반해 제2 이미지에 제1 이미 지 정합할 수 있다. 예시적인 실시예에 따르면, 의료영상 처리장치는 혈관정보, 골조직정보, 안면구조, 안 면굴곡을 포함하는 안면 고유정보로부터 안면 특징점을 추출할 수 있다. 예시적인 실시예에 따르면, 의료영상 처리장치는 안면 특징점에 기반해 제2 이미지에 제1 이미지를 정합할 수 있다. 단계 S140에서, 의료영상 처 리장치는 제2 이미지와 정합된 제1 이미지를 3D 모델링함으로써 합성이미지를 생성할 수 있다. 단계 S150에 서, 의료영상 처리장치는 합성이미지를 환자 안면에 투영할 수 있다. 예시적인 실시예에서 의료영상 처리장치는 외부장치로부터 실시간 환자안면이미지를 획득할 수 있고, 실시 간 환자안면이미지로부터 안면 특징점을 탐색할 수 있다. 의료영상 처리장치는 실시간 환자안면이미지의 변 동에 따라 합성이미지와 안면 특징점의 정합을 지속적으로 계산할 수 있다. 예시적인 실시예에서 의료영상 처리장치는 양안 위치에 대응되는 부분에 기초하여 합성이미지와 실시간 환 자안면이미지를 1차 정합을 수행한 후, 양안 위치 외의 안면에 대응되는 부분에 기초하여 합성이미지와 실시간 환자안면이미지를 2차 정합할 수 있다. 예시적인 실시예에서 의료영상 처리장치는 SLAM(Simultaneous localization and mapping) 알고리즘을 이용 하여 합성이미지를 증강현실로서 환자의 실제 안면부에 투영시킬 수 있다. 도 6은 본 개시의 예시적 실시예에 따른 의료영상 처리장치의 이미지 합성 동작에 따른 골조직 레이어의 투 영을 나타내는 도면이고, 도 7은 본 개시의 예시적 실시예에 따른 의료영상 처리장치의 이미지 합성 동작에 따 른 혈관 레이어의 투영을 나타내는 도면이다. 의료영상 처리장치는 투영 이미지 상에 혈관정보에 상응하는 제1 레이어 및 골조직정보를 포함하는 제2 레 이어를 표시하는 단계로서, 제1 레이어를 표시할 수 있다. 예시적인 실시예에서 의료영상 처리장치는 제2 레이어를, 제1 레이어가 표시되지 않는 시점 또는 영역에 분리하여 표시할 수 있다. 예시적인 실시예에서의료영 상 처리장치는 제2 외부장치로부터 실시간 환자안면이미지를 획득할 수 있다. 도 6을 참조하면, 의료영상 처리장치는 제2 레이어를 표시함으로써 환자로부터 촬영된 골조직 및/또는 안면 구조를 구성하는 안면부 골격을 환자의 실제 얼굴에 상응하는 위치에 투영시킬 수 있다. 도 7을 참조하면, 의료영상 처리장치는 제1 레이어를 표시함으로써 환자로부터 촬영된 실제 혈관조직을 환 자의 실제 얼굴에 상응하는 위치에 투영시킬 수 있다. 한편, 개시된 실시예들은 컴퓨터에 의해 실행 가능한 명령어를 저장하는 기록매체의 형태로 구현될 수 있다. 명 령어는 프로그램 코드의 형태로 저장될 수 있으며, 프로세서에 의해 실행되었을 때, 프로그램 모듈을 생성하여 개시된 실시예들의 동작을 수행할 수 있다. 기록매체는 컴퓨터로 읽을 수 있는 기록매체로 구현될 수 있다. 컴퓨터가 읽을 수 있는 기록매체로는 컴퓨터에 의하여 해독될 수 있는 명령어가 저장된 모든 종류의 기록 매체 를 포함한다. 예를 들어, ROM(Read Only Memory), RAM(Random Access Memory), 자기 테이프, 자기 디스크, 플 래쉬 메모리, 광 데이터 저장장치 등이 있을 수 있다."}
{"patent_id": "10-2022-0149309", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "이상에서와 같이 첨부된 도면을 참조하여 개시된 실시예들을 설명하였다. 본 개시가 속하는 기술분야에서 통상 의 지식을 가진 자는 본 개시의 기술적 사상이나 필수적인 특징을 변경하지 않고도, 개시된 실시예들과 다른 형 태로 본 개시가 실시될 수 있음을 이해할 것이다. 개시된 실시예들은 예시적인 것이며, 한정적으로 해석되어서 는 안 된다."}
{"patent_id": "10-2022-0149309", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 개시의 예시적 실시예에 따른 의료영상 처리 시스템을 도시하는 블록도이다. 도 2는 본 개시의 예시적 실시예에 따른 의료영상 처리장치의 동작 방법을 나타내는 흐름도이다. 도 3은 본 개시의 예시적 실시예에 따른 의료영상 처리장치의 동작 방법을 나타내는 세부 흐름도이다. 도 4는 본 개시의 예시적 실시예에 따른 의료영상 처리장치의 동작 방법을 나타내는 세부 흐름도이다. 도 5는 본 개시의 예시적 실시예에 따른 의료영상 처리장치의 이미지 정합 동작에 따른 단층촬영이미지와 3D 이 미지의 합성을 나타내는 도면이다. 도 6은 본 개시의 예시적 실시예에 따른 의료영상 처리장치의 이미지 합성 동작에 따른 골조직 레이어의 투영을 나타내는 도면이다. 도 7은 본 개시의 예시적 실시예에 따른 의료영상 처리장치의 이미지 합성 동작에 따른 혈관 레이어의 투영을 나타내는 도면이다."}
