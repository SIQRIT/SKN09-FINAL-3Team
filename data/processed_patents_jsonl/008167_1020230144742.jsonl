{"patent_id": "10-2023-0144742", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0153342", "출원번호": "10-2023-0144742", "발명의 명칭": "이동체의 이동 속성 획득 방법 및 이를 수행하는 장치", "출원인": "씨드로닉스", "발명자": "박별터"}}
{"patent_id": "10-2023-0144742", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "선박에 설치된 카메라를 이용하여 타겟 객체의 이동에 관한 정보를 획득하는 방법에 있어서,상기 카메라로부터 제1 시점에 대응하는 제1 이미지를 획득하는 단계;상기 제1 이미지를 인공신경망을 통해 처리하여 제1 세그멘테이션 이미지를 획득하는 단계- 이때, 상기 제1 세그멘테이션 이미지는 타겟 객체에 대응되는 제1 복수의 픽셀들을 포함하며,상기 제1 복수의 픽셀들 각각은 상기 타겟 객체를 반영하는 상기 제1 이미지에 포함된 제1 타겟 픽셀들로부터선택된 적어도 하나에 대응되며,상기 제1 복수의 픽셀들 각각은 상기 타겟 객체의 종류 정보를 반영하는 픽셀값을 가지며, 상기 인공신경망은 학습 이미지 및 상기 학습 이미지에 나타나는 객체의 종류 정보를 반영하는 라벨링 데이터에기초하여 학습됨 -;자세 측정 장치로부터 상기 제1 시점에 대응하는 상기 선박의 제1 자세 정보를 획득하는 단계;상기 카메라로부터 상기 제1 시점 보다 이후의 제2 시점에 대응하는 제2 이미지를 획득하는 단계;상기 제2 이미지를 인공신경망을 통해 처리하여 제2 세그멘테이션 이미지를 획득하는 단계- 이때, 상기 제2 세그멘테이션 이미지는 상기 타겟 객체에 대응되는 제2 복수의 픽셀들을 포함하며,상기 제2 복수의 픽셀들 각각은 상기 타겟 객체를 반영하는 상기 제2 이미지에 포함된 제2 타겟 픽셀들로부터선택된 적어도 하나에 대응되며,상기 제2 복수의 픽셀들 각각은 상기 타겟 객체의 종류 정보를 반영하는 픽셀값을 가짐 -; 상기 자세 측정 장치로부터 상기 제2 시점에 대응하는 상기 선박의 제2 자세 정보를 획득하는 단계;상기 제1 자세 정보 및 상기 제2 자세 정보에 기초하여 상기 제1 복수의 픽셀들 및 상기 제2 복수의 픽셀들 사이의 관계를 결정하는 단계; 및상기 결정된 관계에 기초하여, 상기 제1 시점 및 상기 제2 시점 사이의 상기 타겟 객체에 대한 이동 속성에 관한 정보를 획득하는 단계;를 포함하는,타겟 객체의 이동에 관한 정보를 획득하는 방법."}
{"patent_id": "10-2023-0144742", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1 항에 있어서,상기 이동 속성에 관한 정보는 이동 방향에 관한 정보 및 이동 속도에 관한 정보를 포함하는,타겟 객체의 이동에 관한 정보를 획득하는 방법."}
{"patent_id": "10-2023-0144742", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2 항에 있어서,상기 이동 방향에 관한 정보는 상기 카메라의 위치에 대한 상대적인 이동 방향에 관한 정보인,타겟 객체의 이동에 관한 정보를 획득하는 방법."}
{"patent_id": "10-2023-0144742", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제2 항에 있어서,공개특허 10-2023-0153342-3-상기 이동 속도에 관한 정보는 상기 카메라의 위치에 대한 상대적인 이동 속도에 관한 정보인,타겟 객체의 이동에 관한 정보를 획득하는 방법."}
{"patent_id": "10-2023-0144742", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제2 항에 있어서,상기 이동 방향에 관한 정보는 미리 정해진 복수의 클래스들 중에서 선택되는 적어도 하나인,타겟 객체의 이동에 관한 정보를 획득하는 방법."}
{"patent_id": "10-2023-0144742", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5 항에 있어서,상기 복수의 클래스들은 좌로 향하는 방향, 우로 향하는 방향, 가까워지는 방향, 멀어지는 방향을 포함하는,타겟 객체의 이동에 관한 정보를 획득하는 방법."}
{"patent_id": "10-2023-0144742", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제2 항에 있어서,상기 이동 속도에 관한 정보는 미리 정해진 복수의 클래스들 중에서 선택되는 하나인,타겟 객체의 이동에 관한 정보를 획득하는 방법."}
{"patent_id": "10-2023-0144742", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7 항에 있어서,상기 복수의 클래스들은 빠름(fast), 보통(normal), 느림(slow)을 포함하는,타겟 객체의 이동에 관한 정보를 획득하는 방법."}
{"patent_id": "10-2023-0144742", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1 항에 있어서,상기 제1 복수의 픽셀들 및 상기 제2 복수의 픽셀들 사이의 관계를 결정하는 단계는,상기 제1 자세 정보 및 상기 제2 자세 정보에 기초하여 상기 제1 복수의 픽셀들의 위치 및 상기 제2 복수의 픽셀들의 위치를 고려하여 결정되는,타겟 객체의 이동에 관한 정보를 획득하는 방법."}
{"patent_id": "10-2023-0144742", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제1 항에 있어서,상기 제1 복수의 픽셀들 및 상기 제2 복수의 픽셀들 사이의 관계를 결정하는 단계는,상기 제1 자세 정보 및 상기 제2 자세 정보에 기초하여 상기 제1 복수의 픽셀들 각각의 위치들 및 상기 제2 복수의 픽셀들의 각각의 위치들을 고려하여 결정되는,타겟 객체의 이동에 관한 정보를 획득하는 방법."}
{"patent_id": "10-2023-0144742", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제1 항에 있어서,상기 제1 복수의 픽셀들 및 상기 제2 복수의 픽셀들 사이의 관계를 결정하는 단계는,상기 제1 자세 정보 및 상기 제2 자세 정보에 기초하여 상기 제1 복수의 픽셀들 중 적어도 일부의 위치 및 상기제2 복수의 픽셀들 중 적어도 일부의 위치를 고려하여 결정되는,공개특허 10-2023-0153342-4-타겟 객체의 이동에 관한 정보를 획득하는 방법."}
{"patent_id": "10-2023-0144742", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제1 항에 있어서,상기 제1 복수의 픽셀들 및 상기 제2 복수의 픽셀들 사이의 관계를 결정하는 단계는,상기 제1 자세 정보 및 상기 제2 자세 정보에 기초하여 상기 제1 복수의 픽셀들의 개수 및 상기 제2 복수의 픽셀들의 개수를 고려하여 결정되는,타겟 객체의 이동에 관한 정보를 획득하는 방법."}
{"patent_id": "10-2023-0144742", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제1 항 내지 제12 항 중 어느 하나의 항에 기재된 방법을 실행할 수 있는 프로그램을 기록한 컴퓨터로 읽을 수있는 기록매체."}
{"patent_id": "10-2023-0144742", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "선박에 설치되고 이미지를 획득하는 카메라; 자세 측정 장치; 및상기 카메라 및 상기 자세 측정 장치로부터 수신된 정보들에 기초하여 상기 이미지에 반영된 타겟 객체의 이동속성을 산출하는 프로세서;를 포함하며,상기 프로세서는,상기 카메라로부터 제1 시점에 대응하는 제1 이미지를 획득하고,상기 제1 이미지를 인공신경망을 통해 처리하여 제1 세그멘테이션 이미지를 획득하고,- 이때, 상기 제1 세그멘테이션 이미지는 타겟 객체에 대응되는 제1 복수의 픽셀들을 포함하며,상기 제1 복수의 픽셀들 각각은 상기 타겟 객체를 반영하는 상기 제1 이미지에 포함된 제1 타겟 픽셀들로부터선택된 적어도 하나에 대응되며,상기 제1 복수의 픽셀들 각각은 상기 타겟 객체의 종류 정보를 반영하는 픽셀 값을 가지며,상기 인공신경망은 학습 이미지 및 상기 학습 이미지에 나타나는 객체의 종류 정보를 반영하는 라벨링 데이터에기초하여 학습됨 -,상기 자세 측정 장치로부터 상기 제1 시점에 대응하는 상기 선박의 제1 자세 정보를 획득하고,상기 카메라로부터 상기 제1 시점 보다 이후의 제2 시점에 대응하는 제2 이미지를 획득하고,상기 제2 이미지를 인공신경망을 통해 처리하여 제2 세그멘테이션 이미지를 획득하고,- 이때, 상기 제2 세그멘테이션 이미지는 상기 타겟 객체에 대응되는 제2 복수의 픽셀들을 포함하며,상기 제2 복수의 픽셀들 각각은 상기 타겟 객체를 반영하는 상기 제2 이미지에 포함된 제2 타겟 픽셀들로부터선택된 적어도 하나에 대응되며,상기 제2 복수의 픽셀들 각각은 상기 타겟 객체의 종류 정보를 반영하는 픽셀 값을 가짐 -,상기 자세 측정 장치로부터 상기 제2 시점에 대응하는 상기 선박의 제2 자세 정보를 획득하고,상기 제1 자세 정보 및 상기 제2 자세 정보에 기초하여 상기 제1 복수의 픽셀들 및 상기 제2 복수의 픽셀들 사이의 관계를 결정하고,상기 결정된 관계에 기초하여, 상기 제1 시점 및 상기 제2 시점 사이의 상기 타겟 객체에 대한 이동 속성에 관한 정보를 획득하는,타겟 객체의 이동에 관한 정보를 획득하는 시스템.공개특허 10-2023-0153342-5-청구항 15 제14 항에 있어서,상기 이동 속성에 관한 정보는 이동 방향에 관한 정보 및 이동 속도에 관한 정보를 포함하는,타겟 객체의 이동에 관한 정보를 획득하는 시스템."}
{"patent_id": "10-2023-0144742", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제15 항에 있어서,상기 이동 방향에 관한 정보는 상기 카메라의 위치에 대한 상대적인 이동 방향에 관한 정보인,타겟 객체의 이동에 관한 정보를 획득하는 시스템."}
{"patent_id": "10-2023-0144742", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제15 항에 있어서,상기 이동 속도에 관한 정보는 상기 카메라의 위치에 대한 상대적인 이동 속도에 관한 정보인,타겟 객체의 이동에 관한 정보를 획득하는 시스템."}
{"patent_id": "10-2023-0144742", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제15 항에 있어서,상기 이동 방향에 관한 정보는 미리 정해진 복수의 클래스들 중에서 선택되는 적어도 하나인,타겟 객체의 이동에 관한 정보를 획득하는 시스템."}
{"patent_id": "10-2023-0144742", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제18 항에 있어서,상기 복수의 클래스들은 좌로 향하는 방향, 우로 향하는 방향, 가까워지는 방향, 멀어지는 방향을 포함하는,타겟 객체의 이동에 관한 정보를 획득하는 시스템."}
{"patent_id": "10-2023-0144742", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제15 항에 있어서,상기 이동 속도에 관한 정보는 미리 정해진 복수의 클래스들 중에서 선택되는 하나인,타겟 객체의 이동에 관한 정보를 획득하는 시스템."}
{"patent_id": "10-2023-0144742", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_21", "content": "제20 항에 있어서,상기 복수의 클래스들은 빠름(fast), 보통(normal), 느림(slow)을 포함하는,타겟 객체의 이동에 관한 정보를 획득하는 시스템."}
{"patent_id": "10-2023-0144742", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_22", "content": "제14 항에 있어서,상기 프로세서는, 상기 제1 자세 정보 및 상기 제2 자세 정보에 기초하여 상기 제1 복수의 픽셀들의 위치 및 상기 제2 복수의 픽셀들의 위치를 고려하여 상기 제1 복수의 픽셀들 및 상기 제2 복수의 픽셀들 사이의 관계를 결정하는,타겟 객체의 이동에 관한 정보를 획득하는 시스템.공개특허 10-2023-0153342-6-청구항 23 제14 항에 있어서,상기 프로세서는, 상기 제1 자세 정보 및 상기 제2 자세 정보에 기초하여 상기 제1 복수의 픽셀들 각각의 위치들 및 상기 제2 복수의 픽셀들의 각각의 위치들을 고려하여 상기 제1 복수의 픽셀들 및 상기 제2 복수의 픽셀들 사이의 관계를 결정하는,타겟 객체의 이동에 관한 정보를 획득하는 시스템."}
{"patent_id": "10-2023-0144742", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_24", "content": "제14 항에 있어서,상기 프로세서는, 상기 제1 자세 정보 및 상기 제2 자세 정보에 기초하여 상기 제1 복수의 픽셀들 중 적어도 일부의 위치 및 상기제2 복수의 픽셀들 중 적어도 일부의 위치를 고려하여, 상기 제1 복수의 픽셀들 및 상기 제2 복수의 픽셀들 사이의 관계를 결정하는,타겟 객체의 이동에 관한 정보를 획득하는 시스템."}
{"patent_id": "10-2023-0144742", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_25", "content": "제14 항에 있어서,상기 프로세서는, 상기 제1 자세 정보 및 상기 제2 자세 정보에 기초하여 상기 제1 복수의 픽셀들의 개수 및 상기 제2 복수의 픽셀들의 개수를 고려하여 상기 제1 복수의 픽셀들 및 상기 제2 복수의 픽셀들 사이의 관계를 결정하는,타겟 객체의 이동에 관한 정보를 획득하는 시스템."}
{"patent_id": "10-2023-0144742", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_26", "content": "제14항 내지 제25항 중 어느 한 항에 기재된 타겟 객체의 이동에 관한 정보를 획득하는 시스템을 가지는이동체."}
{"patent_id": "10-2023-0144742", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 선박에 설치된 카메라가 촬상한 이미지 및 인공신경망을 이용하여 이동체의 이동 속성을 획득하는 방 법으로, 해상을 촬상한 제1 이미지 및 상기 제1 이미지의 후속 프레임인 제2 이미지를 포함하는 복수의 이미지를 획득하는 단계; 상기 이미지로부터 상기 이미지에 포함된 객체 정보를 출력하도록, 상기 객체의 종류 정보가 반 (뒷면에 계속)"}
{"patent_id": "10-2023-0144742", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 이동체의 이동 속성을 획득하는 방법에 관한 것이다. 보다 상세하게, 본 발명은 학습된 인공신경망을 이용하여 촬상된 이미지에 포함된 이동체의 이동 속성을 획득하는 방법에 관한 것이다."}
{"patent_id": "10-2023-0144742", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "바야흐로 인공지능(AI: Artificial Intelligence)의 시대이다. 알파고(AlphaGo)가 화제가 된 이후로 인공지능 을 다양한 산업 분야에 적용하려는 시도가 활발히 진행되고 있다. 근래에, 인공지능은 주로 이미지 인식, 분석, 생성, 합성 등 이미지 처리 기술에 활발히 사용되어 오다가 최근 에는 자동차, 선박, 드론 등에 탑재되어 주변 장애물 인식, 경로계획 등에 사용되고있다. 한편, 인공지능이 선박 또는 자동차에 사용되어 주변 장애물에 대한 정보를 획득하는 경우, 움직이는 장애물에 대한 이동 속성을 획득하는 것이 중요하다."}
{"patent_id": "10-2023-0144742", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "일 실시예에 따른 해결하고자 하는 과제는 이미지 세그멘테이션(segmentation)을 수행하는 인공신경망을 이용하 여 주변 환경의 객체 정보를 획득하는 것이다. 다른 일 실시예에 따른 해결하고자 하는 과제는 인공신경망으로부터 출력되는 객체 정보를 이용하여 이동체의 이동 속성을 획득하는 것이다. 또 다른 일 실시예에 따른 해결하고자 하는 과제는 이동체의 이동 속성을 이용하여 선박 및 자동차의 조종신호 를 생성하는 것이다. 본 발명의 해결하고자 하는 과제는 상술한 과제들로 제한되는 것은 아니며, 언급되지 아니한 과제들은 본 명세"}
{"patent_id": "10-2023-0144742", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 2, "content": "서 및 첨부된 도면으로부터 본 발명이 속하는 기술분야에서 통상의 지식을 가진 자에게 명확하게 이해될 수 있 을 것이다."}
{"patent_id": "10-2023-0144742", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "일 실시예에 따르면, 선박에 설치된 카메라가 촬상한 이미지 및 인공신경망을 이용하여 이동체의 이동 속성을 획득하는 방법으로, 해상을 촬상한 제1 이미지 및 상기 제1 이미지의 후속 프레임인 제2 이미지를 포함하는 복 수의 이미지를 획득하는 단계; 상기 이미지로부터 상기 이미지에 포함된 객체 정보를 출력하도록, 상기 객체의 종류 정보가 반영된 제1 분류값 - 이 때, 상기 제1 분류값은 바다에 대응됨 - 및 상기 객체의 거리 정보 및 종 류 정보가 반영된 제2 분류값 - 이 때, 상기 제2 분류값은 장애물에 대응됨 - 을 포함하는 출력 데이터 및 상기 출력 데이터에 대응되는 라벨링 데이터에 기초하여 학습된 인공신경망을 이용하여 상기 제1 이미지로부터 제1 객체 정보를 획득하고, 상기 제2 이미지로부터 제2 객체 정보를 획득하는 객체 정보 획득 단계; 및 상기 제1 객 체 정보 및 상기 제2 객체 정보를 비교하여 상기 촬상된 해상에 포함된 이동체의 이동 방향을 산출하는 단계;를 포함하는 이동체의 이동 속성 획득 방법이 제공될 수 있다. 다른 일 실시예에 따르면, 인공신경망을 이용하여 이동체의 이동 방향을 산출하는 방법으로, 제1 촬상 이미지 및 상기 제1 촬상 이미지의 후속 프레임인 제2 촬상 이미지를 포함하는 복수의 촬상 이미지를 획득하는 단계; 상기 촬상 이미지로부터 상기 촬상 이미지에 포함된 객체 정보를 출력하도록, 상기 객체의 종류 정보가 반영된 제1 분류값 - 이 때, 상기 제1 분류값은 바다에 대응됨 - 및 상기 객체의 거리 정보 및 종류 정보가 반영된 제2 분류값 - 이 때, 상기 제2 분류값은 장애물에 대응됨 - 을 포함하는 출력 데이터 및 상기 출력 데이터에 대응되 는 라벨링 데이터에 기초하여 학습된 인공신경망을 이용하여 상기 제1 촬상 이미지로부터 제1 객체 정보를 획득 하고, 상기 제2 촬상 이미지로부터 제2 객체 정보를 획득하는 단계; 및 상기 제1 객체 정보 및 상기 제2 객체 정보를 비교하여 상기 복수의 촬상 이미지에 포함된 이동체 중 적어도 일부의 이동 방향을 산출하는 단계;를 포 함하는 이동체의 이동 속성 획득 방법이 제공될 수 있다. 또 다른 일 실시예에 따르면, 선박에 설치되어 해상을 촬상하는 카메라; 및 상기 카메라가 촬상한 제1 이미지 및 상기 제1 이미지의 후속 프레임인 제2 이미지를 포함하는 복수의 이미지를 획득하고, 상기 이미지로부터 상 기 이미지에 포함된 객체 정보를 출력하도록, 상기 객체의 종류 정보가 반영된 제1 분류값 - 이 때, 상기 제1 분류값은 바다에 대응됨 - 및 상기 객체의 거리 정보 및 종류 정보가 반영된 제2 분류값 - 이 때, 상기 제2 분 류값은 장애물에 대응됨 - 을 포함하는 출력 데이터 및 상기 출력 데이터에 대응되는 라벨링 데이터에 기초하여 학습된 인공신경망을 이용하여 상기 제1 이미지로부터 제1 객체 정보를 획득하고, 상기 제2 이미지로부터 제2 객체 정보를 획득하고, 상기 제1 객체 정보 및 상기 제2 객체 정보를 비교하여 상기 촬상된 해상에 포함된 이동 체의 이동 방향을 산출하는 제어부;를 포함하는 이동체의 이동 속성 획득 장치가 제공될 수 있다."}
{"patent_id": "10-2023-0144742", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 2, "content": "본 발명의 과제의 해결 수단이 상술한 해결 수단들로 제한되는 것은 아니며, 언급되지 아니한 해결 수단들은 본"}
{"patent_id": "10-2023-0144742", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 3, "content": "명세서 및 첨부된 도면으로부터 본 발명이 속하는 기술분야에서 통상의 지식을 가진 자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2023-0144742", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "일 실시예에 따르면, 이미지 세그멘테이션(segmentation)을 수행하는 인공신경망을 이용하여 주변 환경의 객체 정보를 획득할 수 있다. 다른 일 실시예에 따르면, 인공신경망으로부터 출력되는 객체 정보를 이용하여 이동체의 이동 속성을 획득할 수 있다. 또 다른 일 실시예에 따르면, 이동체의 이동 속성을 이용하여 선박 및 자동차의 조종신호를 생성할 수 있다."}
{"patent_id": "10-2023-0144742", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 2, "content": "본 발명의 효과가 상술한 효과들로 제한되는 것은 아니며, 언급되지 아니한 효과들은 본 명세서 및 첨부된 도면 으로부터 본 발명이 속하는 기술분야에서 통상의 지식을 가진 자에게 명확히 이해될 수 있을 것이다."}
{"patent_id": "10-2023-0144742", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명의 상술한 목적, 특징들 및 장점은 첨부된 도면과 관련된 다음의 상세한 설명을 통해 보다 분명해질 것 이다. 다만, 본 발명은 다양한 변경을 가할 수 있고 여러 가지 실시예들을 가질 수 있는 바, 이하에서는 특정 실시예들을 도면에 예시하고 이를 상세히 설명하고자 한다. 도면들에 있어서, 층 및 영역들의 두께는 명확성을 기하기 위하여 과장된 것이며, 또한, 구성요소(element) 또 는 층이 다른 구성요소 또는 층의 \"위(on)\" 또는 \"상(on)\"으로 지칭되는 것은 다른 구성요소 또는 층의 바로 위 뿐만 아니라 중간에 다른 층 또는 다른 구성요소를 개재한 경우를 모두 포함한다. 명세서 전체에 걸쳐서 동일한 참조번호들은 원칙적으로 동일한 구성요소들을 나타낸다. 또한, 각 실시예의 도면에 나타나는 동일한 사상의 범 위 내의 기능이 동일한 구성요소는 동일한 참조부호를 사용하여 설명한다. 본 발명과 관련된 공지 기능 혹은 구성에 대한 구체적인 설명이 본 발명의 요지를 불필요하게 흐릴 수 있다고 판단되는 경우 그 상세한 설명을 생략한다. 또한, 본 명세서의 설명 과정에서 이용되는 숫자(예를 들어, 제1, 제2 등)는 하나의 구성요소를 다른 구성요소와 구분하기 위한 식별기호에 불과하다. 또한, 이하의 설명에서 사용되는 구성요소에 대한 접미사 \"모듈\" 및 \"부\"는 명세서 작성의 용이함만이 고려되어 부여되거나 혼용되는 것으로서, 그 자체로 서로 구별되는 의미 또는 역할을 갖는 것은 아니다. 일 실시예에 따르면, 선박에 설치된 카메라가 촬상한 이미지 및 인공신경망을 이용하여 이동체의 이동 속성을 획득하는 방법으로, 해상을 촬상한 제1 이미지 및 상기 제1 이미지의 후속 프레임인 제2 이미지를 포함하는 복 수의 이미지를 획득하는 단계; 상기 이미지로부터 상기 이미지에 포함된 객체 정보를 출력하도록, 상기 객체의 종류 정보가 반영된 제1 분류값 - 이 때, 상기 제1 분류값은 바다에 대응됨 - 및 상기 객체의 거리 정보 및 종 류 정보가 반영된 제2 분류값 - 이 때, 상기 제2 분류값은 장애물에 대응됨 - 을 포함하는 출력 데이터 및 상기 출력 데이터에 대응되는 라벨링 데이터에 기초하여 학습된 인공신경망을 이용하여 상기 제1 이미지로부터 제1 객체 정보를 획득하고, 상기 제2 이미지로부터 제2 객체 정보를 획득하는 객체 정보 획득 단계; 및 상기 제1 객 체 정보 및 상기 제2 객체 정보를 비교하여 상기 촬상된 해상에 포함된 이동체의 이동 방향을 산출하는 단계;를 포함하는 이동체의 이동 속성 획득 방법이 제공될 수 있다. 다른 일 실시예에서, 상기 제1 객체 정보 및 상기 제2 객체 정보는 영상 분할 동작을 통해 획득되는 세그멘테이 션 이미지(segmentation image)일 수 있다.또 다른 일 실시예에서, 상기 제1 객체 정보는 상기 제1 이미지에 포함된 객체가 그 거리 정보 및 종류 정보 중 적어도 하나에 관한 객체 정보가 반영된 분류값에 대응되는 색상값을 갖는 이미지이고, 상기 제2 객체 정보는 상기 제2 이미지에 포함된 객체가 그 거리 정보 및 종류 정보 중 적어도 하나에 관한 객체 정보가 반영된 분류 값에 대응되는 색상값을 갖는 이미지일 수 있다. 또 다른 일 실시예에서, 상기 제1 객체 정보 및 상기 제2 객체 정보는 N×M 행렬일 수 있다. 또 다른 일 실시예에서, 상기 제1 객체 정보는 상기 제1 이미지에 포함된 이동체에 관한 분류값만을 포함하고, 상기 제2 객체 정보는 상기 제2 이미지에 포함된 이동체에 관한 분류값만을 포함할 수 있다. 또 다른 일 실시예에서, 상기 제1 객체 정보 및 상기 제2 객체 정보는 상기 제1 분류값을 포함하지 않을 수 있 다. 또 다른 일 실시예에서, 상기 산출하는 단계는 상기 카메라로부터 제1 거리만큼 이격된 제1 이동체에 대응되는 제1 이동체 분류값 - 이 때, 상기 제1 이동체 분류값은 상기 제1 이동체의 거리 정보 및 종류 정보를 포함함 - 만을 포함하는 복수의 제1 이동체 객체 정보를 제1 시간 간격으로 비교하여 상기 제1 이동체의 이동 방향을 산 출하는 제1 이동 방향 산출 단계, 및 상기 카메라로부터 상기 제1 거리보다 큰 제2 거리만큼 이격된 제2 이동체 에 대응되는 제2 이동체 분류값 - 이 때, 상기 제2 이동체 분류값은 상기 제2 이동체의 거리 정보 및 종류 정보 를 포함함 - 만을 포함하는 복수의 제2 이동체 객체 정보를 상기 제1 시간 간격보다 큰 제2 시간 간격으로 비교 하여 상기 제2 이동체의 이동 방향을 산출하는 제2 이동 방향 산출 단계를 포함할 수 있다. 또 다른 일 실시예에서, 상기 제1 이동체 객체 정보 및 상기 제2 이동체 객체 정보는 2차원 행렬일 수 있다. 또 다른 일 실시예에서, 상기 객체 정보 획득 단계는 상기 제2 객체 정보를 획득하기 전 상기 선박의 자세 정보 를 고려하여 상기 제1 이미지 및 상기 제2 이미지를 정합하는 단계를 포함할 수 있다. 또 다른 일 실시예에서, 상기 객체 정보 획득 단계는 상기 제1 객체 정보 및 상기 제2 객체 정보에 포함된 이동 체에 대응되는 분류값 및 상기 선박의 자세 정보를 이용하여 상기 제1 객체 정보 및 상기 제2 객체 정보를 정합 하는 단계를 포함할 수 있다. 또 다른 일 실시예에서, 상기 산출하는 단계는 상기 이동체가 수평축 방향을 따라 이동하는 경우, 상기 제1 객 체 정보에 따른 제1 위치 및 상기 제2 객체 정보에 따른 제2 위치를 비교하여 상기 이동체의 이동 방향을 산출 하는 단계를 포함할 수 있다. 또 다른 일 실시예에서, 상기 산출하는 단계는 상기 이동체가 수직축 방향을 따라 이동하는 경우, 상기 제1 객 체 정보에 포함된 상기 이동체에 대응되는 성분의 개수 및 상기 제2 객체 정보에 포함된 상기 이동체에 대응되 는 성분의 개수를 비교하여 상기 이동체의 이동 방향을 산출하는 단계를 포함할 수 있다. 또 다른 일 실시예에서, 상기 제1 객체 정보 및 상기 제2 객체 정보는 각각 세그멘테이션 이미지(segmentation image)이고, 상기 성분의 개수는 상기 세그멘테이션 이미지의 픽셀의 개수일 수 있다. 또 다른 일 실시예에서, 상기 성분의 개수의 증가는 상기 선박으로부터 상기 이동체까지의 거리의 감소를 지시 하고, 상기 성분의 개수의 감소는 상기 선박으로부터 상기 이동체까지의 거리의 증가를 지시할 수 있다. 또 다른 일 실시예에서, 상기 산출하는 단계는 상기 제1 객체 정보에 따른 제1 위치 및 상기 제2 객체 정보에 따른 제2 위치를 비교하여 상기 이동 방향의 수평 성분을 산출하고, 상기 제1 객체 정보에 포함된 상기 이동체 에 대응되는 픽셀의 개수 및 상기 제2 객체 정보에 포함된 상기 이동체에 대응되는 픽셀의 개수를 비교하여 상 기 이동 방향의 수직 성분을 산출하는 단계를 포함할 수 있다. 또 다른 일 실시예에서, 상기 산출하는 단계는 상기 제1 이미지와 상기 제2 이미지 간의 시간 간격, 상기 선박 의 속도 정보 및 상기 선박의 자세 정보에 기초하여 상기 이동체의 절대 속도를 획득하는 단계를 포함할 수 있 다. 또 다른 일 실시예에 따르면, 상기 이동체의 이동 속성 획득 방법은 상기 산출되는 이동체의 이동 방향에 기초 하여 상기 선박의 조종신호를 생성하는 단계;를 더 포함할 수 있다. 또 다른 일 실시예에 따르면, 인공신경망을 이용하여 이동체의 이동 방향을 산출하는 방법으로, 제1 촬상 이미 지 및 상기 제1 촬상 이미지의 후속 프레임인 제2 촬상 이미지를 포함하는 복수의 촬상 이미지를 획득하는 단계; 상기 촬상 이미지로부터 상기 촬상 이미지에 포함된 객체 정보를 출력하도록, 상기 객체의 종류 정보가반영된 제1 분류값 - 이 때, 상기 제1 분류값은 운행 가능 영역에 대응됨 - 및 상기 객체의 거리 정보 및 종류 정보가 반영된 제2 분류값 - 이 때, 상기 제2 분류값은 장애물에 대응됨 - 을 포함하는 출력 데이터 및 상기 출 력 데이터에 대응되는 라벨링 데이터에 기초하여 학습된 인공신경망을 이용하여 상기 제1 촬상 이미지로부터 제 1 객체 정보를 획득하고, 상기 제2 촬상 이미지로부터 제2 객체 정보를 획득하는 객체 정보 획득 단계; 및 상기 제1 객체 정보 및 상기 제2 객체 정보를 비교하여 상기 복수의 촬상 이미지에 포함된 이동체 중 적어도 일부의 이동 방향을 산출하는 단계;를 포함하는 이동체의 이동 속성 획득 방법이 제공될 수 있다. 또 다른 일 실시예에서, 상기 운행 가능 영역은, 상기 인공신경망이 선박에 이용되는 경우 수상에 해당하고, 상 기 인공신경망이 차량에 이용되는 경우 도로에 해당할 수 있다. 또 다른 일 실시예에 따르면, 선박에 설치되어 해상을 촬상하는 카메라; 및 상기 카메라가 촬상한 제1 이미지 및 상기 제1 이미지의 후속 프레임인 제2 이미지를 포함하는 복수의 이미지를 획득하고, 상기 이미지로부터 상 기 이미지에 포함된 객체 정보를 출력하도록, 상기 객체의 종류 정보가 반영된 제1 분류값 - 이 때, 상기 제1 분류값은 바다에 대응됨 - 및 상기 객체의 거리 정보 및 종류 정보가 반영된 제2 분류값 - 이 때, 상기 제2 분 류값은 장애물에 대응됨 - 을 포함하는 출력 데이터 및 상기 출력 데이터에 대응되는 라벨링 데이터에 기초하여 학습된 인공신경망을 이용하여 상기 제1 이미지로부터 제1 객체 정보를 획득하고, 상기 제2 이미지로부터 제2 객체 정보를 획득하고, 상기 제1 객체 정보 및 상기 제2 객체 정보를 비교하여 상기 촬상된 해상에 포함된 이동 체의 이동 방향을 산출하는 제어부;를 포함하는 이동체의 이동 속성 획득 장치가 제공될 수 있다. 또 다른 일 실시예에 따르면, 상술한 이동체의 이동 속성 획득 방법 중 어느 하나의 방법을 수행하기 위한 프로 그램이 기록된 기록매체가 제공될 수 있다. 인공신경망(ANN: Artificial Neural Network)이란 인간의 뇌의 학습방법을 수학적으로 모델링한 알고리즘의 일 종이다. 인공신경망은 인공 뉴런(neuron)인 복수의 노드(node) 및 상기 복수의 노드를 연결하는 시냅스(synapse)를 포함 할 수 있다. 인공신경망은 적어도 하나 이상의 노드(node)를 포함하는 층(layer)을 포함할 수 있다. 예를 들어, 인공신경망은 입력층(input layer), 은닉층(hidden layer) 및 출력층(output layer)을 포함할 수 있다. 입력층은 인공신경망 외부로부터 입력 데이터를 입력 받아 인공신경망 내부로 상기 입력 데이터를 전송할 수 있 다. 은닉층은 상기 입력층으로부터 전송되는 입력 데이터 및 시냅스의 결합세기에 기초하여 산출되는 데이터를 출력 층으로 전송할 수 있다. 출력층은 상기 은닉층으로부터 전송되는 데이터 및 시냅스의 결합세기에 기초하여 출력 데이터를 산출할 수 있다. 인공신경망은 다양한 신경망을 포함할 수 있다. 예컨대, 인공신경망은 필터를 이용해 특징을 추출하는 합성곱신 경망(CNN: Convolution Neural Network)을 포함할 수 있다. 또는, 인공신경망은 노드의 출력이 다시 입력으로 피드백되는 구조를 갖는 순환인공신경망(RNN: Recurrent Neural Network)을 포함할 수 있다. 그 외에도, 인공신 경망은 제한된 볼츠만 머신(RBM: Restricted Boltzmann Machine), 심층신뢰신경망(DBN: Deep Belief Network), 생성대립신경망(GAN: Generative Adversarial Network), 관계형 네트워크(RN: Relation Networks) 등 다양한 종류의 신경망을 포함할 수 있다. 한편, 인공신경망은 다양한 방법으로 학습(learning)될 수 있다. 예를 들어, 인공신경망은 지도 학습 (supervised learning), 비지도 학습(unsupervised learning), 강화 학습(reinforcement learning), 모방 학습 (imitation learning)을 포함할 수 있다. 그 외에도, 인공신경망은 다양한 종류의 학습 방법을 통해 학습될 수 있다. 도 1은 일 실시예에 따른 인공신경망의 학습 방법이 도시된 블록도이다. 구체적으로, 도 1은 일 실시예에 따른 지도 학습을 나타낼 수 있다. 도 1을 참조하면, 인공신경망은 학습 데이터(training data)를 입력 받아 출력 데이터를 출력할 수 있다. 인공 신경망은 출력 데이터와 라벨링 데이터(labeling data)의 비교에 기초하여 산출되는 오차의 역전파를 통해 학습 될 수 있다. 상기 라벨링 데이터는 상기 학습 데이터와 관련될 수 있다. 예를 들어, 상기 라벨링 데이터는 상기 학습 데이터 를 기초로 산출된 데이터를 포함할 수 있다.상기 라벨링 데이터는 실측 자료(ground truth)를 포함할 수 있다. 또는, 상기 라벨링 데이터는 사용자 또는 프 로그램을 통하여 생성된 자료일 수 있다. 도 2는 일 실시예에 따른 인공신경망의 추론 단계에 관한 블록도이다. 도 2를 참조하면, 학습된 인공신경망은 입력 데이터를 입력 받아 출력 데이터를 출력할 수 있다. 상기 입력 데이터는 다양한 형태의 데이터를 포함할 수 있다. 예를 들어, 상기 입력 데이터는 이미지 데이터, 오디오 데이터 및 텍스트 데이터를 포함할 수 있다. 상기 출력 데이터는 다양한 형태의 데이터를 포함할 수 있다. 예를 들어, 상기 출력 데이터는 이미지 데이터, 오디오 데이터 및 텍스트 데이터를 포함할 수 있다. 상기 학습된 인공신경망의 학습 정도에 따라 출력 데이터의 정확성이 달라질 수 있다. 구체적으로, 상기 학습 정도가 높을수록 상기 출력 데이터의 정확성이 증가할 수 있다. 이하에서는 인공신경망을 이용하여 주변 장애물에 관한 정보를 획득하는 방법에 대해 설명한다. 도 3은 일 실시예에 따른 인공신경망을 이용한 객체 정보 획득 방법이 도시된 도면이다. 도 3을 참조하면, 인공신경망은 입력 데이터를 입력 받아 출력 데이터를 출력할 수 있다. 예를 들어, 상기 인공 신경망은 제1 이미지 데이터를 입력 받아 제2 이미지 데이터를 출력할 수 있다. 상기 제1 이미지 데이터는 카메라로부터 촬상된 이미지일 수 있다. 상기 제2 이미지 데이터는 상기 제1 이미지 데이터를 기초로 생성된 데이터일 수 있다. 예를 들어, 상기 제2 이미지 데이터는 상기 제1 이미지 데이터에 포함되는 장애물의 종류 정보 및 거리 정보 중 적어도 하나를 포함하는 객체 정보를 포함할 수 있다. 상기 인공신경망은 제1 이미지 데이터를 입력 받아 이미지 세그멘테이션 동작을 수행할 수 있다. 상기 이미지 세그멘테이션(image segmentation) 동작이란 영상 분할 동작으로, 속성별로 이미지의 영역을 분할 하는 동작을 의미할 수 있다. 상기 이미지 세그멘테이션 동작은 이미지의 각 픽셀별로 소정의 속성값을 할당하 는 과정을 포함할 수 있다. 예컨대, 상기 속성은 상기 이미지에 포함되는 객체의 종류를 의미할 수 있다. 즉, 상기 이미지 세그멘테이션 동작은 이미지에 포함되는 객체를 픽셀별로 분할하는 과정을 포함할 수 있다. 또는, 상기 이미지 세그멘테이션 동작은 특정 픽셀이 어떤 객체에 대응되는 픽셀인지 나타내는 것을 의미할 수 있다. 상기 속성값은 다양한 방식으로 표현될 수 있다. 예를 들어, 상기 속성값은 색상으로 표현될 수 있다. 상기 이미지 세그멘테이션 동작은 복수의 인공신경망에 의해 수행될 수 있다. 예를 들어, 상기 복수의 인공신경 망은 각각 상기 이미지 세그멘테이션 동작을 수행하고, 그 수행 결과를 조합함으로써 객체 정보를 획득할 수 있 다. 한편, 상기 인공신경망은 다양한 구조를 가질 수 있다. 예컨대, 상기 인공신경망은 ENet 구조를 가질 수 있다. 한편, 상기 제1 이미지 데이터는 다양한 형태로 제공될 수 있다. 예를 들어, 도 3에 도시된 바와 같이 제 1 이미지 데이터는 이미지로 제공될 수 있다. 또는, 상기 제1 이미지 데이터는 픽셀 데이터로 제공 될 수 있다. 도 4는 일 실시예에 따른 인공신경망의 이미지 세그멘테이션 동작을 설명하기 위한 도면이다. 도 4를 참조하면, 인공신경망은 제1 이미지를 입력 받아 제1 출력 데이터를 출력할 수 있다. 상기 제1 출력 데이터는 N×M 행렬일 수 있다. 이 때, 상기 N과 상기 M은 같을 수 있다. 상기 행렬의 원소의 개수는 상기 제1 이미지의 픽셀의 개수와 동일할 수 있다. 즉, 제1 이미지는 N×M 픽셀을 포함할 수 있다. 제1 이미지의 각 픽셀은 상기 행렬의 각 원소에 대응될 수 있다. 예를 들어, 제1 이미지의 각 픽셀 은 상기 행렬의 각 원소와 일대일 대응될 수 있다. 또는, 제1 이미지의 복수의 픽셀의 집합은 상기 행렬의 각 원소와 대응될 수 있다. 상기 제1 출력 데이터는 다양한 정보를 포함할 수 있다. 예를 들어, 상기 제1 출력 데이터는 상기 제1 이미지에 포함되는 객체의 거리 정보를 포함할 수 있다. 또는, 상기 제1 출력 데이터는 상기 객체의 종류 정보를 포함할 수 있다. 한편, 상기 행렬의 각 원소는 소정의 분류값을 가질 수 있다. 여기서, 상기 분류값이란 제1 이미지의 각 픽셀에 포함되는 객체 정보가 반영된 값일 수 있다. 따라서, 상기 행렬의 각 원소는 제1 이미지의 각 픽 셀에 대응되는 객체 정보를 포함할 수 있다. 상기 분류값은 다양한 객체 정보에 의해 정해질 수 있다. 예를 들어, 상기 분류값은 객체의 거리 정보 및 종류 정보에 의해 정해질 수 있다. 도 5는 일 실시예에 따른 분류값이 도시된 표이다. 도 5를 참조하면, 분류값은 객체 정보를 포함할 수 있다. 예를 들어, 상기 분류값은 객체의 거리 정보 및 종류 정보를 포함할 수 있다. 한편, 상기 거리 정보는 미터 단위의 특정 거리 값을 가질 수 있다. 예를 들어, 상기 거리 정보는 10m와 같은 거리 값을 가질 수 있다. 또는, 상기 거리 정보는 소정의 범위를 갖는 카테고리로 분류될 수 있다. 예를 들어, 상기 카테고리는 객체의 거리에 따라 근거리, 중거리 및 원거리를 포함할 수 있다. 구체적으로, 0~10m는 근거리, 10~20m는 중거리, 20~30m는 원거리로 분류될 수 있다. 상기 종류 정보는 객체의 종류에 관한 데이터를 포함할 수 있다. 예를 들어, 상기 객체는 그 종류에 따라 지형, 고정 장애물, 동적 장애물 및 기타로 분류될 수 있다. 상기 지형 은 산을 포함할 수 있다. 상기 고정 장애물은 섬, 암초 등을 포함할 수 있다. 상기 동적 장애물은 선박을 포함 할 수 있다. 한편, 상기 분류값은 상기 거리 정보 및 상기 종류 정보에 기초하여 정해질 수 있다. 예를 들어, 제1 분류값은 객체가 근거리에 위치한 지형인 경우를 지시할 수 있다. 한편, 상기 분류값 중 적어도 일부는 거리 정보를 포함하지 않을 수 있다. 예를 들어, 바다에 대응되는 제1 분 류값은 거리 정보를 포함하지 않을 수 있다. 즉, 분류값이 반드시 거리 정보 및 종류 정보 모두에 기초하여 정해져야 하는 것은 아니다. 예컨대, 상기 분류 값은 종류 정보에만 기초하여 정해질 수도 있다. 또한, 상기 분류값은 상기 거리 정보 및 상기 종류 정보뿐만 아니라 추가 정보에 기초하여 정해질 수 있다. 예 를 들어, 상기 추가 정보는 객체의 방향 정보, 속도 정보, 항로 표지 등을 포함할 수 있다. 한편, 상기 인공신경망으로부터 출력되는 출력 데이터는 이미지 데이터가 될 수 있다. 예를 들어, 상기 이미지 데이터는 상기 분류값에 대응되는 RGB 데이터를 포함할 수 있다. 다시 도 3을 참조하면, 상기 인공신경망은 제1 이미지 데이터를 입력받아 제2 이미지 데이터를 출 력할 수 있다. 상기 제2 이미지 데이터의 각 픽셀은 상기 제1 이미지 데이터에 포함되는 객체 정보 를 포함할 수 있다. 상기 제2 이미지 데이터의 각 픽셀은 상기 객체 정보가 반영된 분류값에 대응되는 RGB 데이터를 포함할 수 있다. 예를 들어, 제1 객체는 근거리에 위치한 동적 장애물로, 도 5의 분류값 7에 대응될 수 있다. 또한, 제2 객 체는 원거리에 위치한 지형으로, 도 5의 분류값 3에 대응될 수 있다. 상기 분류값 7은 제7 색상에 대응될 수 있다. 상기 분류값 3은 제3 색상에 대응될 수 있다. 따라서, 제1 객체는 상기 제7 색상으로 표현될 수 있다. 제2 객체는 상기 제3 색상으로 표현될 수 있 다. 한편, 상기 인공신경망은 상기 이미지 세그멘테이션 동작을 수행하기 전에 전처리 동작을 수행할 수 있다. 예를 들어, 상기 인공신경망은 복수의 이미지를 입력받아 상기 복수의 이미지 중 일부를 선별하는 동작을 수행 할 수 있다. 구체적으로, 상기 인공신경망은 복수의 이미지 중 조도가 가장 높은 제1 이미지 및 조도가 가장 낮은 제2 이미 지를 합성함으로써 제3 이미지를 생성할 수 있다. 상기 인공신경망은 상기 제3 이미지를 기초로 상기 이미지 세 그멘테이션 동작을 수행함으로써 출력 데이터를 획득할 수 있다. 상기 선별 동작을 통해 상기 인공신경망으로부터 획득되는 출력 데이터의 정확도가 향상될 수 있다. 또한, 상기 인공신경망은 복수의 이미지 중 하나의 이미지를 샘플링할 수 있다. 예를 들어, 상기 인공신경망은 상기 복수의 이미지 중 초점 값(또는 초점 척도, focus measure)이 가장 크고 조도값이 미리 정해진 값에 가장 근사한 이미지를 샘플링할 수 있다. 상기 인공신경망은 상기 샘플링 된 이미지에 기초하여 상기 이미지 세그멘 테이션 동작을 수행할 수 있다. 이에 따라, 상기 이미지 세그멘테이션 동작을 통해 산출되는 출력 데이터의 정 확도는 향상될 수 있다. 상기 전처리 동작의 다른 예로, 상기 인공신경망은 RGB 정규화 동작을 수행할 수 있다. 한편, 상기 인공신경망은 다양한 방법으로 학습될 수 있다. *예를 들어, 인공신경망은 학습 데이터를 입력받아 출력 데이터를 출력할 수 있다. 상기 출력 데이터 및 상기 학습 데이터와 관련된 라벨링 데이터의 차이에 기초하여 산출되는 오차가 상기 인공신경망으로 역전파됨에 따라 상기 인공신경망은 학습될 수 있다. 상기 학습 데이터는 이미지 데이터가 될 수 있다. 상기 이미지 데이터는 해상을 촬상하여 획득되는 해상 이미지 를 포함할 수 있다. 상기 학습 데이터는 임의의 이미지로부터 데이터 확장(data augmentation)을 통해 획득되는 복수의 이미지 데이 터를 포함할 수 있다. 도 6은 일 실시예에 따른 데이터 확장을 설명하기 위한 도면이다. 도 6을 참조하면, 원본 이미지로부터 복수의 생성 이미지가 생성될 수 있다. 다양한 기상 조건 또는 환경 노이즈가 반영되어 원본 이미지로부 터 복수의 생성 이미지가 생성될 수 있다. 예를 들어, 제1 생성 이미지는 원본 이미지에 안개가 추가된 이미지일 수 있다. 또는, 제1 생성 이 미지의 안개 정도는 원본 이미지의 안개 정도보다 클 수 있다. 제2 생성 이미지는 원본 이미 지에 비가 추가된 이미지일 수 있다. 제1 생성 이미지는 원본 이미지에 안개 및 비가 추가된 이미지일 수 있다. 상기 인공신경망은 제1 생성 이미지, 제2 생성 이미지 및 제3 생성 이미지를 기초로 학습될 수 있다. 이에 따라, 상기 인공신경망의 학습 효율은 향상될 수 있다. 한편, 인공신경망은 다양한 라벨링 데이터를 기초로 학습될 수 있다. 일 예로, 상기 인공신경망이 입력 이미지 에 포함되는 객체에 대응되는 분류값을 출력하는 경우, 상기 인공신경망은 상기 객체에 관한 분류값을 포함하는 라벨링 데이터를 기초로 학습될 수 있다. 다른 일 예로, 상기 인공신경망이 입력 이미지에 포함되는 객체에 대응되는 분류값에 대응되는 RGB 데이터를 출 력하는 경우, 상기 인공신경망은 상기 객체에 관한 분류값에 대응되는 RGB 데이터를 기초로 학습될 수 있다. 상기 인공신경망의 학습 단계에서 상기 전처리 동작이 수행될 수 있다. 이에 따라, 상기 인공신경망의 학습 효 율이 향상될 수 있다.이상에서는, 이미지 세그멘테이션을 수행하는 인공신경망을 통해 장애물의 객체 정보를 획득하는 방법에 대하여 설명하였다. 이하에서는 장애물의 이동 속성을 획득하는 방법에 대하여 설명한다. 도 7은 일 실시예에 따른 이동체의 이동 속성을 획득하는 방법을 나타내는 도면이다. 도 7을 참조하면, 제1 프레임의 이미지 및 상기 제1 프레임의 이미지의 후속 프레임인 제2 프레임 의 이미지의 비교에 기초하여 이동 속성 데이터가 획득될 수 있다. 예를 들어, 제어부는 제1 프레임의 이미지의 픽셀값 및 제2 프레임의 이미지의 픽셀값을 비교함 으로써 이동체의 이동 방향을 획득할 수 있다. 도 7에서, 이동체는 좌측으로부터 우측으로 이동하고있 음을 알 수 있다. 이 때, 제어부는 Inter-frame subtraction 동작을 수행함으로써 이동체의 이동 방향을 획득할 수 있다. 또한, 제어부는 상기 픽셀값 및 프레임 간격에 기초하여 이동체의 이동 속도를 획득할 수 있다. 제어부는 이동 속성 데이터를 획득할 수 있다. 이동 속성 데이터는 상기 이동체의 이동 방 향 및 이동 속도를 포함할 수 있다. 이동 속성 데이터는 도 7과 같은 이미지 데이터일 수 있으나, 이에 한정되는 것은 아니며, 다양한 형태의 데이터일 수 있다. 한편, 본 명세서 상에서, 제어부가 이동체의 이동 속성을 획득하는 일련의 동작들은 제어부의 이동 속성 획득 동작으로 지칭될 수 있다. 도 8은 다른 일 실시예에 따른 이동체의 이동 속성을 획득하는 방법이 도시된 순서도이다. 도 8을 참조하면, 일 실시예에 따른 이동체의 이동 속성 획득 방법은, 해상을 촬상한 제1 이미지 및 제2 이미지 를 획득하는 단계(S1000), 인공신경망을 이용하여 상기 제1 이미지 및 상기 제2 이미지로부터 각각 제1 객체 정 보 및 제2 객체 정보를 획득하는 단계(S2000) 및 상기 제1 객체 정보 및 상기 제2 객체 정보를 비교하여 상기 촬상된 해상에 포함된 이동체의 이동 속성을 획득하는 단계(S3000)를 포함할 수 있다. 이하에서는 각 단계에 대하여 상세히 설명한다. 먼저, 제어부는 해상을 촬상한 제1 이미지 및 제2 이미지를 포함하는 복수의 이미지를 획득할 수 있다 (S1000). 상기 제1 이미지 및 상기 제2 이미지는 서로 다른 프레임의 이미지일 수 있다. 예를 들어, 상기 제2 이미지는 상기 제1 이미지의 후속 프레임의 이미지일 수 있다. 상기 제1 이미지 및 상기 제2 이미지는 각각 복수의 객체를 포함할 수 있다. 예를 들어, 상기 복수의 객체는 바 다, 선박, 부표 등 다양한 객체를 포함할 수 있다. 제어부는 인공신경망을 이용하여 상기 제1 이미지 및 상기 제2 이미지로부터 각각 제1 객체 정보 및 제2 객 체 정보를 획득할 수 있다(S2000). 상기 인공신경망은 도 1 내지 도 6에서 설명한 인공신경망을 의미할 수 있다. 예를 들어, 상기 인공신경망은 임 의의 입력 이미지를 입력 받아, 상기 입력 이미지에 포함된 객체 정보를 출력할 수 있다. 구체적으로, 상기 인 공신경망은 상기 영상 분할 동작을 수행함으로써 상기 입력 이미지에 포함된 장애물의 거리 정보 및 종류 정보 를 출력할 수 있다. 또한, 상기 인공신경망은 상기 전처리 동작을 수행할 수 있다. 상기 제1 객체 정보 및 상기 제2 객체 정보는 상술한 상기 영상 분할 동작을 통해 획득되는 객체 정보를 의미할 수 있다. 예를 들어, 상기 제1 객체 정보 및 상기 제2 객체 정보는 각각 상기 제1 이미지 및 상기 제2 이미지에 포함된 객체에 관한 거리 정보 및 종류 정보를 의미할 수 있다. 상기 제1 객체 정보 및 상기 제2 객체 정보는 N×M 행렬로 제공될 수 있다. 상기 행렬의 원소는 상기 제1 이미 지 및 상기 제2 이미지의 픽셀에 대응될 수 있다.제어부는 상기 제1 객체 정보 및 상기 제2 객체 정보를 비교하여 상기 촬상된 해상에 포함된 이동체의 이동 속성을 획득할 수 있다(S3000). 예를 들어, 제어부는 상기 제1 객체 정보 및 상기 제2 객체 정보를 비교하여 상기 이동체의 이동 방향을 획 득할 수 있다. 제어부는 상기 제1 객체 정보에 포함된 원소 및 상기 제2 객체 정보에 포함된 원소를 비교하여 상기 이동체 의 이동 방향을 획득할 수 있다. 상기 원소는 상기 제1 이미지 및 상기 제2 이미지에 포함된 객체에 관한 거리 정보 및 종류 정보가 반영된 분류값을 포함할 수 있다. 한편, 상기 이동 방향은 상기 복수의 이미지를 촬상한 카메라의 설치 위치를 기준으로한 상대 이동 방향을 의미 할 수 있다. *제어부는 상기 제1 이미지 및 상기 제2 이미지에 포함된 객체의 종류 정보를 고려하여 상기 객체의 이동 방 향을 산출할 수 있다. 예를 들어, 제어부는 상기 객체가 동적 장애물인 경우에만, 상기 객체의 이동 방향을 산출할 수 있다. 즉, 제어부는 상기 객체가 지형 또는 고정 장애물에 해당하는 경우, 상기 객체에 대한 이동 방향은 산출하지 않을 수 있다. 또는, 상기 객체의 종류에 따라 제어부의 이동 방향 산출 동작의 주기가 달라질 수 있다. 예를 들어, 상기 객체가 동적 장애물인 경우 상기 객체가 고정 장애물인 경우보다 상기 이동 방향 산출 동작의 주기가 작을 수 있다. 제어부는 상기 제1 이미지 및 상기 제2 이미지에 포함된 객체의 거리 정보를 고려하여 상기 객체의 이동 방 향을 산출할 수 있다. 예를 들어, 상기 객체가 근거리에 위치한 경우 상기 객체가 원거리에 위치한 경우보다 제 어부의 상기 이동 방향 산출 동작의 주기가 작을 수 있다. 제어부는 상기 제1 객체 정보 및 상기 제2 객체 정보를 비교하여 상기 이동체의 이동 속도를 획득할 수 있다. 예를 들어, 제어부는 상기 제1 이미지 및 상기 제2 이미지의 프레임 간격, 및 상기 제1 객체 정보 및 상기 제2 객체 정보를 이용하여 상기 이동체의 이동 속도를 획득할 수 있다. 이 때, 제어부는 상기 제1 객체 정보에 포함된 객체의 거리 정보 및 상기 제2 객체 정보에 포함된 객체의 거 리 정보를 고려하여 상기 이동 속도를 획득할 수 있다. 예를 들어, 상기 거리 정보 및 상기 제1 객체 정보 및 상기 제2 객체 정보의 원소값의 변화에 기초하여 상기 이동 속도를 획득할 수 있다. 한편, 상기 이동 속도는 상기 복수의 이미지를 촬상한 카메라의 설치 위치를 기준으로한 상대 이동 속도를 의미 할 수 있다. 제어부는 상기 이동 속도에 기초하여 상기 이동체의 절대 속도를 산출할 수 있다. 예를 들어, 제어부는 상기 카메라가 설치된 선박의 GPS 정보를 고려하여 상기 절대 속도를 산출할 수 있다. 한편, 제어부는 상기 카메라가 설치된 선박의 자세 정보를 고려하여 상기 이동 속성 획득 동작을 수행할 수 있다. 예를 들어, 제어부는 상기 선박에 탑재된 IMU로부터 획득된 상기 선박의 자세 정보를 고려하여 상기 이동 속성 획득 동작을 수행할 수 있다. 상기 자세 정보는 상기 선박의 선수방향(heading 또는 yaw), 피치 (pitch), 롤(roll) 등을 포함할 수 있다. 구체적으로, 제어부는 상기 자세 정보를 고려하여 상기 제1 이미지 및 상기 제2 이미지를 정합할 수 있다. 예를 들어, 상기 선박의 피치를 고려하여 상기 제1 이미지 및 상기 제2 이미지의 위치를 정합할 수 있다. 이 때, 제어부는 미리 정해진 기준 위치를 기초로 상기 제1 이미지 및 상기 제2 이미지를 정합할 수 있다. 예를 들어, 상기 단계 S2000 및 상기 단계 S3000는 상기 이미지 정합 단계를 포함할 수 있다. 도 9는 일 실시예에 따른 이동체의 이동 속성을 획득하는 방법이 도시된 도면이다. 도 9를 참조하면, 제어부는 제1 이미지로부터 획득된 제1 객체 정보 및 상기 제1 이미지의 후속 프레 임인 제2 이미지로부터 획득된 제2 객체 정보의 비교에 기초하여, 제1 이동 속성 데이터를 획득할 수 있다. 제1 객체 정보 및 제2 객체 정보는 이동체에 관한 거리 정보 및 종류 정보를 포함할 수 있다. 제어부는 제1 객체 정보 및 제2 객체 정보를 비교함으로써 이동체의 이동 속성을 획득할 수 있다. 예를 들어, 제어부는 제1 객체 정보에 따른 이동체의 위치 및 제2 객체 정보에 따른 이동체 의 위치를 비교함으로써 이동체의 이동 방향을 획득할 수 있다. 구체적으로, 제어부는 이동체에 대응되는 분류값이 속한 행렬내의 위치 변화를 기초로 이동체의 이동 방향을 획득할 수 있다. 제어부는 상기 제1 이미지 및 상기 제2 이미지의 프레임 간격 및 이동체의 거리 정보를 이용하여 이동체 의 이동 속도를 획득할 수 있다. 제1 객체 정보 및 제2 객체 정보는 다양한 형태의 데이터로 제공될 수 있다. 예를 들어, 제1 객체 정보 및 제2 객체 정보는 이미지 형태로 제공될 수 있다. 또는 제1 객체 정보 및 제2 객체 정보는 2차원 행렬로 제공될 수 있다. 한편, 이동체의 이동 속성은 분류화될 수 있다. 도 10은 일 실시예에 따른 이동 속성에 관한 분류값이 도시된 표이다. 도 10을 참조하면, 각각의 이동 속성에 따라 분류값이 할당될 수 있다. 이동 속성은 이동 방향 및 이동 속도를 포함할 수 있다. 예를 들어, 이동 방향은 정지(NOT MOVING), 전방(FORWARD), 후방(BACKWARD), 좌측(LEFT), 우측(RIGHT) 등으로 분류될 수 있다. 다만, 이에 한정되는 것은 아니며 이동 방향은 다양한 방법으로 분류될 수 있다. 예를 들어, 이동 방향은 동, 서, 남, 북, 북동, 남동, 남서, 북서와 같이 8방위로 분류될 수도 있다. 한편, 상기 이동 방향은 산기 카메라가 설치된 위치를 기준으로 한 방향을 지시할 수 있다. 예를 들어, 복수의 카메라가 선박에 설치되는 경우, 카메라의 설치 위치에 따라 각각의 이동 방향이 지시하는 방향이 상이할 수 있 다. 또는, 상기 이동 방향은 상기 카메라가 설치된 선박의 진행 방향을 기준으로 한 방향을 지시할 수 있다. 예를 들어, 상기 전방(FORWARD)은 상기 선박의 이동 방향과 같은 방향을 지시할 수 있다. 또한, 상기 후방(BACKWAR D)은 상기 선박의 이동 방향의 반대 방향을 지시할 수 있다. 이동 속도는 소정의 범위를 기준으로 저속(SLOW), 중속(NORMAL), 고속(FAST)의 3 종류로 분류될 수 있다. 다만, 이에 한정되는 것은 아니며, 이동 속도는 이동 속도는 속도에 따라 다양한 개수로 분류될 수 있다. 도 11은 또 다른 일 실시예에 따른 이동체의 이동 속성을 획득하는 방법이 도시된 도면이다. 도 11을 참조하면, 제어부는 제3 객체 정보 및 제4 객체 정보에 기초하여 제2 이동 속성 데이터 를 획득할 수 있다. 제3 객체 정보는 상기 제1 이미지로부터 상기 인공신경망을 통해 출력될 수 있 다. 제4 객체 정보는 상기 제2 이미지로부터 상기 인공신경망을 통해 출력될 수 있다. 한편, 제어부는 도 7 내지 도 9에서 설명한 이동 속성 획득 동작과 동일하게 이동체의 이동 속성 획득 동작을 수행할 수 있다. 예를 들어, 제어부는 제3 객체 정보 및 제4 객체 정보를 비교함으로써 이동체의 이동 방향 및 이동 속도를 획득할 수 있다. 따라서, 이에 대한 상세한 설명은 생략하고, 전술한 이동 속성 획득 동작과의 차별점을 중심으로 설명한다. 제어부는 미리 정해진 분류값을 갖는 객체에 대하여만 이동 속성 획득 동작을 수행할 수 있다. 예를 들어, 제어부는 제3 객체 정보 및 제4 객체 정보에 동적 장애물에 대응되는 분류값이 포함된 경우에만 상기 동적 장애물의 이동 속성을 획득할 수 있다. 제어부는 미리 정해진 분류값을 갖는 객체를 선별하는 동작을 수행할 수 있다. 예를 들어, 제어부는 동적 장애물을 선별하는 동작을 수행할 수 있다. 제어부는 제3 객체 정보 및 제4 객체 정보에서 상기 선별된 객체를 제외한 나머지 정보를 폐기 하는 동작을 수행할 수 있다. 예를 들어, 제어부는 제3 객체 정보에서 상기 선별된 객체에 대응되는 원소를 제외한 나머지 원소들의 값을 0으로 조절할 수 있다. 제어부는 제4 객체 정보에서 상기 선별된 객체에 대응되는 원소를 제외한 나머지 원소들의 값을 0으로 조절할 수 있다. 예를 들어, 제어부는 제1 객체 정보로부터 제1 객체 정보에서 이동체에 관한 객체 정보를 제외한 나머지 정보가 제거된 제3 객체 정보를 생성할 수 있다. 즉, 제3 객체 정보는 제1 객체 정 보의 이동체에 관한 객체 정보만을 포함할 수 있다. 마찬가지로, 제어부는 제2 객체 정보로부터 제2 객체 정보에서 이동체에 관한 객체 정보를 제외한 나머지 정보가 제거된 제4 객체 정보를 생성할 수 있다. 즉, 제4 객체 정보는 제2 객체 정 보의 이동체에 관한 객체 정보만을 포함할 수 있다. 제어부는 제3 객체 정보 및 제4 객체 정보를 비교함으로써 이동체에 관한 이동 속성을 획득 할 수 있다. 예를 들어, 제어부는 이동체에 대응되는 분류값의 행렬 내의 위치의 변화를 기초로 이동체 의 이동 방향 및 이동 속도를 획득할 수 있다. 이에 따라, 이동체의 이동 속성을 획득하는 제어부의 전체 연산량이 감소할 수 있다. 즉, 제어부가 미리 정해진 객체에 관한 정보만을 포함하는 선별된 객체 정보를 기초로 이동 속성을 획득함으로써, 제어부의 데 이터 연산량이 감소할 수 있다. 한편, 이동체의 거리 정보에 따라 제어부가 수행하는 이동 속성 획득 동작의 수행 주기가 달라질 수 있다. 예를 들어, 상기 제1 이미지에 근거리의 동적 장애물이 포함된 경우, 제어부는 제1 시간 간격으로 상기 동적 장애물의 이동 속성을 획득할 수 있다. 반면에, 상기 제1 이미지에 원거리의 동적 장애물이 포함된 경우, 제어 부는 제1 시간 간격보다 큰 제2 시간 간격으로 상기 동적 장애물의 이동 속성을 획득할 수 있다. 도 12는 일 실시예에 따른 이동체의 이동 속성 획득 방법을 설명하기 위한 도면이다. 도 12를 참조하면, 해상을 촬상한 복수의 이미지로부터 상기 인공신경망은 상기 복수의 이미지에 대응되는 복수 의 객체 정보를 출력할 수 있다. 예를 들어, 상기 촬상된 해상에 제1 이동체가 포함된 경우, 제어부는 N frame 마다 상기 이동 속성 획득 동작을 수행할 수 있다. 반면에, 상기 촬상된 해상에 제2 이동체가 포함된 경우, 제어부는 상기 N보다 큰 M frame 마다 상기 이동 속성 획득 동작을 수행할 수 있다. 상기 제2 이동체는 상기 제1 이동체보다 상기 해상을 촬상한 카메라로부터 멀리 위치할 수 있다. 즉, 이동체로부터 상기 카메라까지의 거리가 가까울수 록 제어부의 상기 이동 속성 획득 동작은 자주 수행될 수 있다. 이는, 카메라로부터 가까운 이동체일수록, 이미지 내의 위치가 빠르게 변동될 수 있기 때문이다. 또는, 카메라 로부터 가까운 이동체일수록, 객체 정보 내 원소값의 변화가 빠르게 변동될 수 있기 때문이다. 한편, 이동체의 이동 방향에 따라, 제어부의 이동 속성 획득 방법이 달라질 수 있다. 예컨대, 이동체가 수평 방향을 따라 이동하는 경우, 제어부는 상술한 바와 같이 상기 이동체에 대응되는 분류값의 위치의 변화를 기 초로 상기 이동체의 이동 속성을 획득할 수 있다. 반면에, 이동체가 수직 방향을 따라 이동하는 경우, 제어부 는 상기 이동체에 대응되는 픽셀 개수의 변화를 기초로 상기 이동체의 이동 속성을 획득할 수 있다. 도 13은 일 실시예에 따른 이동체의 이동 속성 획득 방법을 설명하기 위한 도면이다. 도 13을 참조하면, 제어부는 제5 객체 정보 및 제6 객체 정보에 기초하여 제3 이동 속성 데이터 를 획득할 수 있다. 제5 객체 정보는 상기 제1 이미지로부터 상기 인공신경망을 통해 출력될 수 있 다. 제6 객체 정보는 상기 제2 이미지로부터 상기 인공신경망을 통해 출력될 수 있다. 따라서, 제6 객체 정보는 제5 객체 정보의 후속 프레임의 이미지에 관한 정보일 수 있다. 이동체는 수직 방향을 따라 이동할 수 있다. 여기서, 상기 수직 방향이란 상기 카메라의 수직축 방향을 의 미할 수 있다. 구체적으로, 상기 수직 방향은 상기 카메라로부터 멀어지거나 가까워지는 방향을 의미할 수 있다. 또는, 상기 수직 방향은 도 10의 FORWARD 또는 BACKWARD 방향을 의미할 수 있다. 이동체가 수직 방향을 따라 이동하는 경우, 제어부는 상기 제1 제1 이미지 및 상기 제2 이미지에 포함된 이동체에 대응되는 픽셀 개수의 변화를 기초로 이동체의 이동 속성을 획득할 수 있다. 또는, 제어부는 제5 객체 정보 및 제6 객체 정보에 포함된 이동체에 대응되는 분류값의 개 수 변화를 기초로 이동체의 이동 속성을 획득할 수 있다. 상기 분류값의 개수는 제5 객체 정보 및 제 6 객체 정보에 포함된 상기 분류값을 갖는 원소의 개수를 의미할 수 있다. 예를 들어, 제6 객체 정보에 포함된 이동체에 대응되는 분류값의 개수가 제5 객체 정보에 포함 된 이동체에 대응되는 분류값의 개수보다 큰 경우, 즉, 시간에 따라 상기 분류값의 개수가 증가하는 경우, 이동체가 상기 카메라와 가까워짐을 의미할 수 있다. 또는, 이동체가 상기 선박과 가까워짐을 의미할 수 있다. 반대로, 제6 객체 정보에 포함된 이동체에 대응되는 분류값의 개수가 제5 객체 정보에 포함된 이동체에 대응되는 분류값의 개수보다 작은 경우, 즉, 시간에 따라 상기 분류값의 개수가 감소하는 경우, 이동체가 상기 카메라와 멀어짐을 의미할 수 있다. 또는, 이동체가 상기 선박과 멀어짐을 의미할 수 있 다. 한편, 제어부는 도 7 내지 도 11에서 설명한 이동 속성 획득 동작과 동일하게 이동체의 이동 속성 획득 동작을 수행할 수 있음은 물론이다. 예를 들어, 제어부는 제5 객체 정보 및 제6 객체 정보에 포 함된 이동체의 위치 변화를 기초로 이동체의 이동 방향 및 이동 속도를 획득할 수 있다. 이 때, 제어부는 상기 카메라가 설치된 선박의 자세 정보를 고려하여 이동체의 이동 속성을 획득할 수 있다. 예를 들어, 상기 선박의 선수방향(heading 또는 yaw), 피치(pitch), 롤(roll) 등을 고려하여 상기 이동 속성을 획득할 수 있다. 한편, 상기 분류값의 개수 변화를 기초로 획득된 이동체의 이동 속성은, 상기 위치 변화를 기초로 획득된 이동체의 이동 속성보다 정확할 수 있다. 예를 들어, 상기 분류값의 개수는 상기 위치보다 상기 선박의 자 세 변화에 영향을 적게 받을 수 있다. 구체적으로, 상기 위치는 상기 선박의 자세가 변함에 따라 변할 수 있는 반면, 상기 분류값의 개수는 상기 선박의 자세가 변하더라도 그대로 유지될 수 있다. 또는, 상기 위치는 상기 선박의 자세가 변함에 따라 상대적으로 크게 변할 수 있는 반면, 상기 분류값의 개수는 상기 선박의 자세가 변 하더라도 상대적으로 적게 변할 수 있다. 제어부는 이동체의 이동 속성에 기초하여 상기 선박의 조종신호를 생성할 수 있다. 예를 들어, 제어부 는 이동체가 상기 선박으로 접근하는 경우, 이동체를 회피하는 조종신호를 생성할 수 있다. 또는, 제어부는 이동체가 상기 선박을 기초로 미리 설정된 위험 영역으로 진입하는 경우, 상기 선박이 이동체 를 회피하도록 조종신호를 생성할 수 있다. 한편, 이상에서는 제어부가 선박에 설치된 카메라가 촬상한 해상 이미지로부터 상기 해상 이미지에 포함된 이동체의 이동 속성을 획득하는 것으로 설명하였으나, 제어부는 다양한 이미지로부터 이동체의 이동 속성을 획득할 수 있다. 예컨대, 제어부는 자동차에 설치된 카메라가 촬상한 촬상 이미지로부터 상기 촬상 이미지에 포함된 이동체의 이동 속성을 획득할 수 있다. 또는, 제어부는 드론에 설치된 카메라로부터 촬상되는 이미지 로부터 상기 이미지에 포함된 이동체의 이동 속성을 획득할 수 있다. 또한, 제어부는 상기 이동 속성에 기초 하여 자동차 또는 드론을 제어하는 조종신호를 생성할 수 있다. 실시예에 따른 방법은 다양한 컴퓨터 수단을 통하여 수행될 수 있는 프로그램 명령 형태로 구현되어 컴퓨터 판 독 가능 매체에 기록될 수 있다. 상기 컴퓨터 판독 가능 매체는 프로그램 명령, 데이터 파일, 데이터 구조 등 을 단독으로 또는 조합하여 포함할 수 있다. 상기 매체에 기록되는 프로그램 명령은 실시예를 위하여 특별히 설계되고 구성된 것들이거나 컴퓨터 소프트웨어 당업자에게 공지되어 사용 가능한 것일 수도 있다. 컴퓨터 판 독 가능 기록 매체의 예에는 하드 디스크, 플로피 디스크 및 자기 테이프와 같은 자기 매체(magnetic media), CD-ROM, DVD와 같은 광기록 매체(optical media), 플롭티컬 디스크(floptical disk)와 같은 자기-광 매체 (magneto-optical media), 및 롬(ROM), 램(RAM), 플래시 메모리 등과 같은 프로그램 명령을 저장하고 수행하도 록 특별히 구성된 하드웨어 장치가 포함된다. 프로그램 명령의 예에는 컴파일러에 의해 만들어지는 것과 같은 기계어 코드뿐만 아니라 인터프리터 등을 사용해서 컴퓨터에 의해서 실행될 수 있는 고급 언어 코드를 포함한다. 상기된 하드웨어 장치는 실시예의 동작을 수행하기 위해 하나 이상의 소프트웨어 모듈로서 작동하도"}
{"patent_id": "10-2023-0144742", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "록 구성될 수 있으며, 그 역도 마찬가지이다.이상과 같이 실시예들이 비록 한정된 실시예와 도면에 의해 설명되었으나, 해당 기술분야에서 통상의 지식을 가 진 자라면 상기의 기재로부터 다양한 수정 및 변형이 가능하다. 예를 들어, 설명된 기술들이 설명된 방법과 다 른 순서로 수행되거나, 및/또는 설명된 시스템, 구조, 장치, 회로 등의 구성요소들이 설명된 방법과 다른 형태 로 결합 또는 조합되거나, 다른 구성요소 또는 균등물에 의하여 대치되거나 치환되더라도 적절한 결과가 달성될 수 있다. 그러므로, 다른 구현들, 다른 실시예들 및 특허청구범위와 균등한 것들도 후술하는 특허청구범위의 범위에 속한 다."}
{"patent_id": "10-2023-0144742", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 일 실시예에 따른 인공신경망의 학습 방법이 도시된 블록도이다. 도 2는 일 실시예에 따른 인공신경망의 추론 단계에 관한 블록도이다. 도 3은 일 실시예에 따른 인공신경망을 이용한 객체 정보 획득 방법이 도시된 도면이다. 도 4는 일 실시예에 따른 인공신경망의 영상 분할 동작을 설명하기 위한 도면이다. 도 5는 일 실시예에 따른 분류값이 도시된 표이다. 도 6은 일 실시예에 따른 데이터 확장을 설명하기 위한 도면이다. 도 7은 일 실시예에 따른 이동체의 이동 속성 획득 방법을 설명하기 위한 도면이다. 도 8은 다른 일 실시예에 따른 이동체의 이동 속성 획득 방법이 도시된 순서도이다. 도 9는 또 다른 일 실시예에 따른 이동체의 이동 속성 획득 방법을 설명하기 위한 도면이다. 도 10은 일 실시예에 따른 객체의 분류값 및 이동 속성에 관한 표이다. 도 11은 또 다른 일 실시예에 따른 이동체의 이동 속성 획득 방법을 설명하기 위한 도면이다. 도 12는 또 다른 일 실시예에 따른 이동체의 이동 속성 획득 방법을 설명하기 위한 도면이다. 도 13은 또 다른 일 실시예에 따른 이동체의 이동 속성 획득 방법을 설명하기 위한 도면이다."}
