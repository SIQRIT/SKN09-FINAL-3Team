{"patent_id": "10-2023-0105407", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2025-0024214", "출원번호": "10-2023-0105407", "발명의 명칭": "번역 자막 정보의 실시간 공유가 가능한 실시간 번역 자막 제공시스템", "출원인": "(주)에어사운드", "발명자": "백민호"}}
{"patent_id": "10-2023-0105407", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "자막 제공 요청 정보가 수신된 화자의 음성 정보 또는 동영상 데이터의 음성 정보를 수신받아 해당 음성 정보의언어인 제 1 언어에 대해 STT(Speech-To-Text) 변환을 통해 텍스트 형태의 제 1 자막 정보를 생성하고, 생성된제 1 자막 정보를 요청된 제 2 언어로 학습된 인공지능 기반의 번역을 수행하여 텍스트 형태의 제 2 자막 정보를 생성하는 관리 서버; 상기 관리 서버로 데이터 통신 가능하도록 연결되어 특정 화자의 음성 정보 또는 특정 동영상 데이터의 음성 정보를 전송하여 자막 제공 요청을 수행하고, 상기 관리 서버로부터 생성된 상기 제 1 자막 정보 및 제 2 자막 정보를 수신받으며, 수신받은 상기 제 1 자막 정보 및 제 2 자막 정보에 대해 선택적으로 자막 공유 요청 정보를상기 관리 서버로 전송하여 상기 제 1 자막 정보 및 제 2 자막 정보를 제공받기 위한 공유 Web 연결 정보를 상기 관리 서버로부터 수신받는 호스트 단말기; 및 상기 호스트 단말기로부터 상기 공유 Web 연결 정보를 수신받아 상기 관리 서버에 데이터 통신 가능하도록 접속되고, 상기 관리 서버로부터 상기 제 1 자막 정보 및 제 2 자막 정보를 제공받는 클라이언트 단말기;를 포함하는, 실시간 번역 자막 제공시스템."}
{"patent_id": "10-2023-0105407", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 호스트 단말기는, 상기 자막 제공 요청 정보가 수신된 음성 정보가 동영상 데이터인 경우, 상기 관리 서버로부터 수신한 제 1 자막 정보 및 제 2 자막 언어 중 적어도 하나를 상기 동영상 데이터의 출력 화면 상에 오버레이시켜 출력하는,실시간 번역 자막 제공시스템."}
{"patent_id": "10-2023-0105407", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서, 상기 공유 Web 연결 정보는, 상기 관리 서버에서 생성한 웹 페이지의 URL(Uniform Resource Locator) 정보 또는 QR 코드 정보이고, 상기 관리 서버는 상기 상기 공유 Web 연결 정보를 통해 웹 페이지에 접속한 클라이언트 단말기로 상기 제 1 자막 정보 및 제 2자막 정보를 전송하고, 상기 호스트 단말기와 적어도 하나의 클라이언트 단말기로부터 각각 대화 정보를 수신하여 상기 웹 페이지 상에 출력함에 따라 양방향 커뮤니케이션이 가능하도록 하는 공유 관리부가 포함되되, 상기 공유 관리부는 상기 클라이언트 단말기로부터 각각 수신된 대화 정보를 상기 호스트 단말기로 제공 시에 상기 호스트 단말기가설정한 언어로 번역을 수행하여 제공하는, 실시간 번역 자막 제공시스템. 공개특허 10-2025-0024214-3-청구항 4 제1항에 있어서, 상기 호스트 단말기는화자의 음성 정보 또는 동영상 데이터의 음성 정보를 수신받아 해당 음성 정보의 언어인 제 1 언어에 대해STT(Speech-To-Text) 변환을 수행하여 텍스트 형태의 제 1 자막 정보를 생성하는 호스트 변환부 및 상기 호스트변환부로부터 생성된 제 1 자막 정보를 학습된 인공지능 기반의 번역을 수행하되 사전에 설정된 제 2 언어로 번역을 수행하여 텍스트 형태의 제 2 자막 정보를 생성하는 호스트 번역부를 더 포함하는, 실시간 번역 자막 제공시스템."}
{"patent_id": "10-2023-0105407", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서, 상기 호스트 단말기의 통역 요청에 따라 상기 관리 서버와 데이터 통신 가능하도록 접속되어 요청된 특정 화자의 음성 정보 또는 동영상 데이터의 음성 정보 및 제 1 자막 정보를 상기 관리 서버로부터 수신받으며, 해당 음성 정보 및 제 1 자막 정보에 대해 통역 요청 시 설정된 제 2 언어로 통역을 수행한 실시간 통역 음성 정보를상기 관리 서버로 제공하는 통역사 단말기;가 더 포함되는, 실시간 번역 자막 제공시스템."}
{"patent_id": "10-2023-0105407", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5항에 있어서, 상기 관리 서버는, 상기 통역사 단말기로부터 수신된 실시간 통역 음성 정보를 STT 변환을 수행하여 제 2 자막 정보를 생성하고,생성된 제 2 자막 정보를 상기 제 1 자막 정보와 함께 요청한 상기 호스트 단말기에 제공하되 자막 공유 기능이수행 중인 경우 상기 공유 Web 연결 정보를 통해 접속된 클라이언트 단말기로 상기 제 1 자막 정보 및 제 2 자막 정보를 함께 제공하는, 실시간 번역 자막 제공시스템."}
{"patent_id": "10-2023-0105407", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에 있어서, 상기 호스트 단말기의 속기 요청에 따라 상기 관리 서버와 데이터 통신 가능하도록 접속되어 요청된 특정 화자의 음성 정보 또는 동영상 데이터의 음성 정보를 상기 관리 서버로부터 수신받으며, 해당 음성 정보에 대한 텍스트 형태의 실시간 속기 정보를 상기 관리 서버로 제공하는 속기사 단말기;가 더 포함되고, 상기 관리 서버는, 상기 속기사 단말기로부터 수신된 실시간 속기 정보를 인공지능 기반의 번역을 수행하여 제 2 자막 정보를 생성하고, 속기 요청한 상기 호스트 단말기로 해당 실시간 속기 정보 및 제 2 자막 정보를 제공하되, 자막 공유 기능이 수행 중인 경우 상기 공유 Web 연결 정보를 통해 접속된 클라이언트 단말기로 해당 실시간 속기 정보 및제 2 자막 정보를 함께 제공하는, 실시간 번역 자막 제공시스템."}
{"patent_id": "10-2023-0105407", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 번역 자막 정보의 실시간 공유가 가능한 실시간 번역 자막 제공시스템에 관한 것으로서 더욱 상세하게 는 국제 회의장 또는 실시간 동영상 스트리밍 환경에서 화자의 음성 정보 또는 동영상 내 음성 정보를 관리 서버 가 수신 받아 STT 변환 및 요청한 언어로 번역을 수행하여 요청한 사용자에게 자막 정보를 제공하되, 사용자의 (뒷면에 계속)"}
{"patent_id": "10-2023-0105407", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 번역 자막 정보의 실시간 공유가 가능한 실시간 번역 자막 제공시스템에 관한 것으로서 더욱 상세하 게는 국제 회의장 또는 실시간 동영상 스트리밍 환경에서 화자의 음성 정보 또는 동영상 내 음성 정보를 관리 서버가 수신 받아 STT 변환 및 요청한 언어로 번역을 수행하여 요청한 사용자에게 자막 정보를 제공하되, 사용 자의 요청에 따라 다른 사용자에게 해당 자막 정보를 제공하여 번역 자막 정보가 실시간으로 공유될 수 있는 실 시간 번역 자막 제공시스템에 관한 것이다."}
{"patent_id": "10-2023-0105407", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "일반적으로, 외국어를 잘 못하는 사람이 국제 회의장이나 동영상 시청을 할 때 외국인이 화자인 경우 의사 소통 이 잘되지 않아 불편함과 어려움을 겪는 경우가 많다. 그렇지만 외국어를 잘 아는 다른 사람의 도움 없이는 스스로 사전 또는 회화책자 등을 찾아가며 외국인과 의사 소통을 해야하나 이는 실시간 대응이 어렵고 제대로 의사 소통을 하기가 어려웠다. 최근 들어 스마트폰 기술의 발달로 자동 번역기가 개발되어, 언어 체계가 비슷한 한국어와 일본어인 경우 그 신 뢰성이 높아 실용화되어 있으며, 영어인 경우 한국어와 언어 체계가 달라 일본어의 경우보다는 번역의 신뢰성이 떨어지나 단문이나 간단한 복문 등은 실용적으로 이용할 수 있는 정도의 번역기 및 그 번역 프로그램들이 널리 알려져 있다. 한편, 사람의 음성을 기계가 인식하기 위한 음성인식에 대해서 많은 연구 노력을 기울이고 있는 분야이며, 샘플 링 기술의 발달과 신경회로망을 이용한 자기 학습기능 등의 발달로 음성의 자동 인식율이 높아지고 일부 분야에 서 실용화되고 있다. 또한, 문자를 음성으로 출력하는 기술은 각 문자의 발음 조합이나 기타 단어의 발음 및 문장의 발음 등을 데이 터베이스(DB)화하여 이를 음성으로 출력하는 음성 출력장치도 이미 널리 이용되고 있다. 또한, 현대 사람들이 항상 소지하고 다니는 스마트폰(Smart Phone)을 이용하여 사용자들에게 다른 나라 언어를 자국어로 변환하여 제공하는 통역 서비스를 제공하고 있다. 그러나, 기존에 다양한 형태로 제공되고 있는 번역 시스템은 1 대 N 간의 대화에 적합하지 않고, 별도의 네트워 크 등이 사전에 마련되어야 어느 정도 원활한 번역 정보를 제공받을 수 있는 문제가 있다. 따라서 국제 회의장이나 컨퍼런스 등에서 연설하는 화자나 실시간 동영상 스트리밍이 이루어지는 동영상 데이터 의 음성 정보를 실시간으로 번역하여 많은 사용자에게 동시에 제공할 수 있음은 물론 많은 사용자들이 신속하고 용이하게 번역 정보를 제공받을 수 있는 시스템의 개선이 요구된다. 선행기술문헌 특허문헌 (특허문헌 0001) 한국등록특허 제10-1753649호"}
{"patent_id": "10-2023-0105407", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 상기의 문제점을 해결하기 위해 안출된 것으로서 국제 회의장 또는 실시간 동영상 스트리밍 환경에서 화자의 음성 정보 또는 동영상 내 음성 정보를 관리 서버가 수신 받아 STT 변환 및 요청한 언어로 번역을 수행 하여 요청한 사용자에게 자막 정보를 제공하되, 사용자의 요청에 따라 다른 사용자에게 해당 자막 정보를 제공 하여 번역 자막 정보가 실시간으로 공유될 수 있는 실시간 번역 자막 제공시스템을 제공함에 그 목적이 있다."}
{"patent_id": "10-2023-0105407", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명은 상기의 목적을 달성하기 위해 아래와 같은 특징을 갖는다. 본 발명은 자막 제공 요청 정보가 수신된 화자의 음성 정보 또는 동영상 데이터의 음성 정보를 수신받아 해당 음성 정보의 언어인 제 1 언어에 대해 STT(Speech-To-Text) 변환을 통해 텍스트 형태의 제 1 자막 정보를 생성 하고, 생성된 제 1 자막 정보를 요청된 제 2 언어로 학습된 인공지능 기반의 번역을 수행하여 텍스트 형태의 제 2 자막 정보를 생성하는 관리 서버; 상기 관리 서버로 데이터 통신 가능하도록 연결되어 특정 화자의 음성 정보 또는 특정 동영상 데이터의 음성 정보를 전송하여 자막 제공 요청을 수행하고, 상기 관리 서버로부터 생성된 상 기 제 1 자막 정보 및 제 2 자막 정보를 수신받으며, 수신받은 상기 제 1 자막 정보 및 제 2 자막 정보에 대해 선택적으로 자막 공유 요청 정보를 상기 관리 서버로 전송하여 상기 제 1 자막 정보 및 제 2 자막 정보를 제공 받기 위한 공유 Web 연결 정보를 상기 관리 서버로부터 수신받는 호스트 단말기; 및 상기 호스트 단말기로부터 상기 공유 Web 연결 정보를 수신받아 상기 관리 서버에 데이터 통신 가능하도록 접속되고, 상기 관리 서버로부 터 상기 제 1 자막 정보 및 제 2 자막 정보를 제공받는 클라이언트 단말기;를 포함한다. 여기서 상기 호스트 단말기는, 상기 자막 제공 요청 정보가 수신된 음성 정보가 동영상 데이터인 경우, 상기 관 리 서버로부터 수신한 제 1 자막 정보 및 제 2 자막 언어 중 적어도 하나를 상기 동영상 데이터의 출력 화면 상 에 오버레이시켜 출력한다. 또한 상기 공유 Web 연결 정보는, 상기 관리 서버에서 생성한 웹 페이지의 URL(Uniform Resource Locator) 정 보 또는 QR 코드 정보이고, 상기 관리 서버는 상기 상기 공유 Web 연결 정보를 통해 웹 페이지에 접속한 클라이 언트 단말기로 상기 제 1 자막 정보 및 제 2 자막 정보를 전송하고, 상기 호스트 단말기와 적어도 하나의 클라 이언트 단말기로부터 각각 대화 정보를 수신하여 상기 웹 페이지 상에 출력함에 따라 양방향 커뮤니케이션이 가 능하도록 하는 공유 관리부가 포함되되, 상기 공유 관리부는 상기 클라이언트 단말기로부터 각각 수신된 대화 정보를 상기 호스트 단말기로 제공 시에 상기 호스트 단말기가 설정한 언어로 번역을 수행하여 제공한다. 아울러 상기 호스트 단말기는 화자의 음성 정보 또는 동영상 데이터의 음성 정보를 수신받아 해당 음성 정보의 언어인 제 1 언어에 대해 STT(Speech-To-Text) 변환을 수행하여 텍스트 형태의 제 1 자막 정보를 생성하는 호스 트 변환부 및 상기 호스트 변환부로부터 생성된 제 1 자막 정보를 학습된 인공지능 기반의 번역을 수행하되 사 전에 설정된 제 2 언어로 번역을 수행하여 텍스트 형태의 제 2 자막 정보를 생성하는 호스트 번역부를 더 포함 한다. 또한 상기 호스트 단말기의 통역 요청에 따라 상기 관리 서버와 데이터 통신 가능하도록 접속되어 요청된 특정 화자의 음성 정보 또는 동영상 데이터의 음성 정보 및 제 1 자막 정보를 상기 관리 서버로부터 수신받으며, 해 당 음성 정보 및 제 1 자막 정보에 대해 통역 요청 시 설정된 제 2 언어로 통역을 수행한 실시간 통역 음성 정 보를 상기 관리 서버로 제공하는 통역사 단말기;가 더 포함된다. 아울러 상기 관리 서버는, 상기 통역사 단말기로부터 수신된 실시간 통역 음성 정보를 STT 변환을 수행하여 제 2 자막 정보를 생성하고, 생성된 제 2 자막 정보를 상기 제 1 자막 정보와 함께 요청한 상기 호스트 단말기에 제공하되 자막 공유 기능이 수행 중인 경우 상기 공유 Web 연결 정보를 통해 접속된 클라이언트 단말기로 상기 제 1 자막 정보 및 제 2 자막 정보를 함께 제공한다. 또한 상기 호스트 단말기의 속기 요청에 따라 상기 관리 서버와 데이터 통신 가능하도록 접속되어 요청된 특정 화자의 음성 정보 또는 동영상 데이터의 음성 정보를 상기 관리 서버로부터 수신받으며, 해당 음성 정보에 대한 텍스트 형태의 실시간 속기 정보를 상기 관리 서버로 제공하는 속기사 단말기;가 더 포함되고, 상기 관리 서버 는, 상기 속기사 단말기로부터 수신된 실시간 속기 정보를 인공지능 기반의 번역을 수행하여 제 2 자막 정보를 생성하고, 속기 요청한 상기 호스트 단말기로 해당 실시간 속기 정보 및 제 2 자막 정보를 제공하되, 자막 공유 기능이 수행 중인 경우 상기 공유 Web 연결 정보를 통해 접속된 클라이언트 단말기로 해당 실시간 속기 정보 및 제 2 자막 정보를 함께 제공한다."}
{"patent_id": "10-2023-0105407", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명에 따르면 화자의 음성 정보 또는 실시간 스트리밍 동영상 데이터의 음성 정보에 대한 번역 정보를 실시 간으로 제공받을 수 있으며, 호스트 단말기의 공유 요청에 따라 다른 많은 수의 사용자들이 별도의 어플리케이 션 설치 과정이나 로그인 과정 없이 신속하고 용이하게 실시간 번역 정보를 제공받을 수 있는 효과가 있다."}
{"patent_id": "10-2023-0105407", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명과 본 발명의 동작상의 이점 및 본 발명의 실시에 의하여 달성되는 목적을 설명하기 위하여 이하에서는 본 발명의 바람직한 실시예를 예시하고 이를 참조하여 살펴본다. 먼저, 본 출원에서 사용한 용어는 단지 특정한 실시예를 설명하기 위해 사용된 것으로서, 본 발명을 한정하려는 의도가 아니며, 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함할 수 있다. 또한 본 출원에서, \"포함하다\" 또는 \"가지다\" 등의 용어는 명세서 상에 기재된 특징, 숫자, 단계, 동작, 구성요소, 부품 또는 이들을 조합한 것이 존재함을 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성요소, 부품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되 어야 한다. 본 발명을 설명함에 있어서, 관련된 공지 구성 또는 기능에 대한 구체적인 설명이 본 발명의 요지를 흐릴 수 있 다고 판단되는 경우에는 그 상세한 설명은 생략한다. 도 1은 본 발명의 일실시예에 따른 실시간 번역 자막 제공시스템의 개략적인 구성을 나타내는 도면이고, 도 2는 본 발명의 일실시예에 따른 실시간 번역 자막 제공시스템의 내부 구성을 나타내는 도면이며, 도 3은 본 발명의 다른 실시예에 따른 호스트 단말기의 내부 구성을 나타내는 도면이고, 도 4는 본 발명의 일실시예에 따른 호스 트 단말기의 전용 어플리케이션에서 메인 표시 화면을 나타내는 도면이다. 또한, 도 5는 본 발명의 일실시예에 따른 호스트 단말기에서 제 1 자막 정보 또는 제 2 자막 정보가 동영상 데 이터에 오버레이되어 출력되는 모습을 나타내는 도면이며, 도 6 및 도 7은 본 발명의 일실시예에 따른 호스트 단말기의 전용 어플리케이션에서 자막 공유 요청 화면을 나타내는 도면이고, 도 8은 본 발명의 일실시예에 따른 클라이언트 단말기의 웹 페이지 표시 화면을 나타내는 도면이다. 도면을 참조하면 본 발명의 일실시예에 따른 실시간 통역 서비스시스템은 본 발명은 자막 제공 요청 정보 가 수신된 화자의 음성 정보 또는 동영상 데이터의 음성 정보를 수신받아 해당 음성 정보의 언어인 제 1 언어에 대해 STT(Speech-To-Text) 변환을 통해 텍스트 형태의 제 1 자막 정보를 생성하고, 생성된 제 1 자막 정보를 요 청된 제 2 언어로 학습된 인공지능 기반의 번역을 수행하여 텍스트 형태의 제 2 자막 정보를 생성하는 관리 서 버와, 상기 관리 서버로 데이터 통신 가능하도록 연결되어 특정 화자의 음성 정보 또는 특정 동영상 데이터의 음성 정보를 전송하여 자막 제공 요청을 수행하고, 상기 관리 서버로부터 생성된 상기 제 1 자막 정보 및 제 2 자막 정보를 수신받으며, 수신받은 상기 제 1 자막 정보 및 제 2 자막 정보에 대해 선택적으로 자 막 공유 요청 정보를 상기 관리 서버로 전송하여 상기 제 1 자막 정보 및 제 2 자막 정보를 제공받기 위한 공유 Web 연결 정보를 상기 관리 서버로부터 수신받는 호스트 단말기 및 상기 호스트 단말기로부터 상기 공유 Web 연결 정보를 수신받아 상기 관리 서버에 데이터 통신 가능하도록 접속되고, 상기 관리 서버 로부터 상기 제 1 자막 정보 및 제 2 자막 정보를 제공받는 클라이언트 단말기로 구성된다. 여기서 상기 관리 서버는 호스트 단말기가 요청한 특정 화자의 음성 정보 또는 동영상 데이터의 음성 정보를 수신하여 실시간으로 해당 음성 정보를 STT(Speech-To-Text) 변환을 수행하고, 수행된 결과로서 텍스트 형태의 제 1 자막 정보를 생성하며, 생성된 제 1 자막 정보를 기초로 하여 인공지능 기반의 번역이 수행된 텍스트 형태의 제 2 자막 정보를 생성한다. 이에 따라 생성된 제 1 자막 정보 및 제 2 자막 정보는 실시간으로 자막 제공 요청이 있는 호스트 단말기 로 전송하게 된다. 이를 위해 상기 관리 서버는 상기 호스트 단말기 및 상기 클라이언트 단말기와 데이터 통신 가 능하도록 하는 서버 통신부 및 상기 서버 통신부를 통해 상기 호스트 단말기의 자막 제공 요청 이 있는 경우, 상기 호스트 단말기가 전송하는 특정 화자의 음성 정보 또는 동영상 데이터의 음성 정보를 기초로 실시간으로 상기 제 1 자막 정보 및 제 2 자막 정보를 생성하는 자막 관리부로 구성된다. 여기서 상기 자막 관리부는 상기 호스트 단말기가 자막 제공 요청한 해당 음성 정보의 언어인 제 1 언어로 STT(Speech-To-Text) 변환을 수행하여 텍스트 형태의 제 1 자막 정보를 생성하는 STT 변환부 및 생 성된 제 1 자막 정보를 기초로 인공지능 기반의 번역을 수행하여 텍스트 형태의 제 2 자막 정보를 생성하는 인 공지능 번역부를 포함하여 구성된다. 물론 상기 자막 관리부는 상기 STT 변환부 및 인공지능 번역부로부터 생성된 제 1 자막 정보와 제 2 자막 정보를 상기 서버 통신부를 통해 자막 제공 요청한 호스트 단말기로 실시간 전송하게 된다. 아울러 상기 관리 서버에는 상기 호스트 단말기가 서버 통신부로 자막 공유 요청을 수행한 경우, 자막 공유를 위한 웹 페이지를 생성하고, 해당 웹 페이지에 접속하도록 하는 공유 Web 연결 정보를 호스 트 단말기로 전송하며, 해당 웹 페이지에 접속되는 적어도 하나의 클라이언트 단말기로 상기 제 1 자 막 정보 및 제 2 자막 정보를 전송하는 공유 관리부가 포함된다. 이때 공유 Web 연결 정보는 해당 웹 페이지에 접속하기 위한 URL(Uniform Resource Locator) 정보 또는 QR 코 드 정보임이 바람직하다. 또한 상기 공유 관리부는 상기 호스트 단말기와 클라이언트 단말기로부터 각각 대화 정보를 수 신하여 상기 웹 페이지 상에 출력함에 따라 호스트 단말기의 사용자와 클라이언트 단말기의 사용자 간 채팅 기능을 제공하도록 구성될 수 있다. 이때 상기 공유 관리부는 상기 클라이언트 단말기로부터 각각 수신된 대화 정보를 상기 호스트 단말 기로 제공 시에 상기 호스트 단말기가 설정한 언어로 번역을 수행하여 제공하도록 구성됨이 바람직하 다. 아울러 상기 공유 관리부에는 호스트 단말기 또는 클라이언트 단말기의 요청에 따라 각 사용자 가 사전에 설정한 제 2 언어로 번역된 제 2 자막 정보를 기초로 하여 음성 합성을 통해 음성 정보로 출력하는 TTS(Text-to-Speech) 변환부(도면 미표시)가 더 포함될 수 있다. 이에 따라 호스트 단말기 또는 클라이언트 단말기에서 음성 출력 요청이 있는 관리 서버의 공유 관리부는 제 1 자막 정보, 제 2 자막 정보 및 제 2 자막 정보에 대해 음성 합성을 수행한 제 2 자막 음성 정보를 모두 호스트 단말기 또는 클라이언트 단말기로 제공하게 된다. 아울러 상기 관리 서버의 STT 변환부 및 인공지능 번역부는 이들이 각각 생성하는 제 1 자막 정 보 및 제 2 자막 정보에 대해 전체 구절 또는 문장 단위로 각각 정확 여부를 판단하도록 구성할 수 있다. 이에 따라 해당 정확 여부를 기초로 특정 구절 또는 문장에 대해 제 1 자막 정보 및 제 2 자막 정보를 생성하지 않거나 생성된 제 1 자막 정보 및 제 2 자막 정보에 대해 별도의 구별 처리를 수행하여 호스트 단말기 또 는 클라이언트 단말기로 전송하도록 구성할 수 있다. 즉, 정확도가 사전에 설정된 기준에 따라 너무 낮은 것으로 판단되는 경우에는 제 1 자막 정보 및 제 2 자막 정 보를 생성하지 않고, 정확도가 사전에 설정된 기준에 따라 너무 낮지는 않지만 높지도 않는 것으로 판단되는 경 우 제 1 자막 정보 및 제 2 자막 정보를 생성하지만 해당 제 1 자막 정보 및 제 2 자막 정보에 대해 별도의 구 별 처리를 하여 이를 전송 받는 호스트 단말기 또는 클라이언트 단말기의 사용자가 정확도가 낮은 구 절임을 알 수 있도록 하는 것이다. 이와 함께 상기 STT 변환부 및 인공지능 번역부는 STT 변환 시 또는 번역 시에 각 구절 또는 각 문장 에 대해 복수의 제 1 자막 정보 및 제 2 자막 정보를 생성하도록 구성할 수 있다. 이는 상기 STT 변환부 및 인공지능 번역부가 음식 인식 또는 번역 시에 하나의 구절 또는 하나의 문 장으로 제 1 자막 정보 또는 제 2 자막 정보가 생성될 수 있고, 경우에 따라 복수개로 음성 인식 가능한, 또는 번역 가능한 구절 또는 문장이 생성될 수 있기 때문이다. 이 경우, 상기 STT 변환부 및 인공지능 번역부는 정확도를 기준으로 우선 순위를 판단하여 높은 순위 순으로 해당 구절 또는 문장을 특정하고, 가장 높은 순위의 해당 구절 또는 문장을 상기 호스트 단말기 또 는 클라이언트 단말기로 보내되, 별도의 구별 처리를 하여 전송한다. 이에 따라 상기 호스트 단말기 또는 클라이언트 단말기가 해당 구별 처리가 된 제 1 자막 정보 또는 제 2 자막 정보를 수신 받을 때, 관리 서버로 이보다 낮은 순위의 해당 구절 또는 문장에 대한 제 1 자막 정보 또는 제 2 자막 정보를 요청할 수 있으며, 만일 상기 호스트 단말기 또는 클라이언트 단말기의 요청이 있는 경우, 상기 STT 변환부 및 인공지능 번역부는 해당 구절 또는 해당 문장에 대한 가장 높 은 순위를 제외한 제 1 자막 정보 및 제 2 자막 정보를 순위별로 특정하여 상기 호스트 단말기 또는 클라 이언트 단말기로 전송한다. 아울러 이를 수신 받은 호스트 단말기 또는 클라이언트 단말기로부터 해당 구절 또는 해당 문장에 대 한 사용자의 선택 정보를 받도록 구성될 수 있는데, 이와 같은 선택 정보는 음성 인식 또는 번역이 상기 STT 변 환부 및 인공지능 번역부가 판단한 가장 높은 순위의 제 1 자막 정보 또는 제 2 자막 정보 보다 낮은 순위의 제 1 자막 정보 또는 제 2 자막 정보가 보다 정확한 것으로 호스트 단말기 또는 클라이언트 단말기 의 사용자가 판단한 정보이다. 이를 상기 STT 변환부 및 인공지능 번역부가 수신하게 되면, 이와 같은 데이터를 학습 데이터로 활용 하여 보다 높은 양질의 인공 지능 모델이 생성될 수 있게 된다. 한편 상기 호스트 단말기는 상기 관리 서버로 특정 화자의 음성 정보 또는 특정 동영상 데이터의 음 성 정보를 전송하여 자막 제공 요청을 수행하고, 상기 관리 서버로부터 생성된 상기 제 1 자막 정보 및 제 2 자막 정보를 수신받도록 구비된다. 이러한 호스트 단말기의 사용자는 강의나 발표를 수행하는 화자가 될 수 있으며, 이외에 다른 사람이 될 수 있다. 이와 같은 호스트 단말기는 상기 관리 서버 및 클라이언트 단말기와 데이터 통신 가능하도록 하 는 호스트 통신부와, 사용자로부터 입력 정보를 수신받는 사용자 입력부와, 사용자에게 출력 정보를 제공하는 화면 관리부 및 상기 사용자 입력부로부터 자막 제공 요청을 전달받으면 상기 관리 서버 로 호스트 통신부를 통해 특정 화자의 음성 정보 또는 특정 동영상 데이터의 음성 정보를 전송하고, 상기 관리 서버로부터 제 1 자막 정보 및 제 2 자막 정보를 수신받아 화면 관리부를 통해 사용자에게 제공하는 호스트 제어부를 포함하여 구성된다. 여기서 상기 호스트 제어부는 도 6 및 도 7에 도시된 바와 같이 상기 사용자 입력부로부터 자막 공유 요청을 전달받는 경우, 자막 공유 요청 정보를 호스트 통신부를 통해 상기 관리 서버로 전송하고, 관 리 서버로부터 공유 Web 연결 정보를 수신받는다. 이에 따라 사용자 입력부로부터 요청된 클라이언트 단말기로 해당 공유 Web 연결 정보를 호스트 통신 부를 통해 전송하도록 구성된다. 또한 상기 화면 관리부는 도 4에 도시된 바와 같이 제 1 자막 정보가 표시되는 제 1 자막 표시부와, 제 2 자막 정보가 표시되는 제 2 자막 표시부 및 제 1 언어 및 제 2 언어를 설정하는 언어 설정부와, 자막 공유 요청을 설정하기 위한 자막 공유 설정부를 포함하여 구성된다. 아울러 상기 화면 관리부는 도 5에 도시된 바와 같이 자막 제공 요청 정보가 수신된 음성 정보가 동영상 데이터이고, 사용자 입력부로부터 오버레이 선택 정보가 수신되면, 상기 관리 서버로부터 수신한 제 1 자막 정보 및 제 2 자막 언어 중 적어도 하나를 상기 동영상 데이터의 출력 화면 상에 오버레이시켜 출력할 수 있다. 또한 본 발명의 일예에 따라 상기 호스트 단말기는 화자의 음성 정보 또는 동영상 데이터의 음성 정보를 수신받아 해당 음성 정보의 언어인 제 1 언어에 대해 STT(Speech-To-Text) 변환을 수행하여 텍스트 형태의 제 1 자막 정보를 생성하는 호스트 변환부 및 상기 호스트 변환부로부터 생성된 제 1 자막 정보를 학습된 인공지능 기반의 번역을 수행하되 사전에 설정된 제 2 언어로 번역을 수행하여 텍스트 형태의 제 2 자막 정보를생성하는 호스트 번역부가 더 포함될 수 있다. 이러한 호스트 변환부 및 호스트 번역부는 통신 환경의 불량으로 상기 관리 서버와의 데이터 통 신이 어려운 경우 호스트 단말기에서 직접 화자 또는 동영상 데이터의 음성 정보를 음성 인식하여 STT 변 환을 수행하고, 이를 기초로 인공지능 기반의 번역을 수행함으로써 제 1 자막 정보 및 제 2 자막 정보를 생성할 수 있다. 한편 상기 클라이언트 단말기는 상기 호스트 단말기로부터 상기 공유 Web 연결 정보를 수신받아 상기 관리 서버에 데이터 통신 가능하도록 접속되고, 상기 관리 서버로부터 상기 제 1 자막 정보 및 제 2 자막 정보를 제공받도록 구비된다. 이러한 상기 클라이언트 단말기는 상기 관리 서버 및 호스트 단말기와 데이터 통신 가능하도록 하는 클라이언트 통신부와, 사용자로부터 입력 정보를 수신받는 사용자 입력부와, 사용자에게 출력 정보를 제공하는 화면 관리부 및 상기 호스트 단말기로부터 상기 공유 Web 연결 정보를 수신받으며, 사용자 입력부로부터 상기 공유 Web 연결 정보의 연결 선택 정보를 전달받으면, 해당 웹 페이지를 통해 상 기 관리 서버와 접속하여 관리 서버로부터 제 1 자막 정보 및 제 2 자막 정보를 수신받아 화면 관리 부를 통해 사용자에게 제공하는 클라이언트 제어부를 포함하여 구성된다. 이에 따라 상기 클라이언트 제어부가 상기 호스트 단말기로부터 공유 Web 연결 정보를 전달받은 경우, 해당 공유 Web 연결 정보에 대응되는 웹 페이지로 접속하게 되면 도 8에 도시된 바와 같이 관리 서버 와 연결되어 제 1 자막 정보 및 제 2 자막 정보가 화면 관리부에 의해 사용자에게 제공되게 된다. 도 8에 도시된 바와 같이 클라이언트 단말기의 사용자는 다른 클라이언트 단말기 사용자 또는 호스트 단말 기 사용자와의 채팅 기능이 제공되고, 제 1 자막 정보 및 제 2 자막 정보의 동시 출력 또는 제 2 자막 정보만을 표시하도록 설정하는 기능이 제공될 수 있다. 이와 같이 본 발명의 일실시예에 따른 실시간 번역 자막 제공시스템은 호스트 단말기에 자막 공유 설정이 가능하여 다른 복수의 클라이언트 단말기가 별도의 로그인 절차나 전용 어플리케이션의 설치 과정 없이 신 속하고 용이하게 특정 화자의 음성 정보 또는 실시간 스트리밍 동영상 데이터의 음성 정보에 대한 제 1 자막 정 보 및 제 2 자막 정보를 제공받을 수 있게 된다. 도 9는 본 발명의 다른 실시예에 따른 실시간 번역 자막 제공시스템의 내부 구성을 나타내는 도면이다. 도면을 참조하면, 본 실시예에 따른 실시간 번역 자막 제공시스템은 호스트 단말기의 통역 요청에 따라 상기 관리 서버와 데이터 통신 가능하도록 접속되어 요청된 특정 화자의 음성 정보 또는 동영상 데이 터의 음성 정보 및 제 1 자막 정보를 상기 관리 서버로부터 수신받으며, 해당 음성 정보 및 제 1 자막 정 보에 대해 통역 요청 시 설정된 제 2 언어로 통역을 수행한 실시간 통역 음성 정보를 상기 관리 서버로 제 공하는 통역사 단말기가 더 포함된다. 이에 따라 상기 관리 서버는, 상기 통역사 단말기로부터 수신된 실시간 통역 음성 정보를 STT 변환을 수행하여 제 2 자막 정보를 생성하고, 생성된 제 2 자막 정보를 통역 서비스를 요청한 상기 호스트 단말기(10 0)에 상기 제 1 자막 정보와 함께 제공한다. 아울러 상기 관리 서버는 전술한 실시간 번역 자막 제공시스템에 설명한 바와 같이, 현재 호스트 단 말기의 요청에 따라 자막 공유 기능이 수행 중인 경우 상기 공유 Web 연결 정보를 통해 접속된 클라이언트 단말기로 상기 제 1 자막 정보 및 제 2 자막 정보를 함께 제공하게 된다. 도 10은 본 발명의 또 다른 실시예에 따른 실시간 번역 자막 제공시스템의 내부 구성을 나타내는 도면이다. 도면을 참조하면, 본 실시예에 따른 실시간 번역 자막 제공시스템은 아울러 상기 호스트 단말기의 속기 요청에 따라 상기 관리 서버와 데이터 통신 가능하도록 접속되어 요청된 특정 화자의 음성 정보 또는 동영상 데이터의 음성 정보를 상기 관리 서버로부터 수신받으며, 해당 음성 정보에 대한 텍스트 형태의 실 시간 속기 정보를 상기 관리 서버로 제공하는 속기사 단말기가 더 포함된다. 이에 따라 상기 관리 서버는, 상기 속기사 단말기로부터 수신된 실시간 속기 정보를 인공지능 기반의 번역을 수행하여 제 2 자막 정보를 생성하고, 속기 요청한 상기 호스트 단말기로 해당 실시간 속기 정보 및 제 2 자막 정보를 제공한다. 아울러 상기 관리 서버는 전술한 실시간 번역 자막 제공시스템에 설명한 바와 같이, 현재 호스트 단 말기의 요청에 따라 자막 공유 기능이 수행 중인 경우 상기 공유 Web 연결 정보를 통해 접속된 클라이언트 단말기로 해당 실시간 속기 정보 및 제 2 자막 정보를 함께 제공할 수 있다. 또한 전술한 실시예에서의 통역사 단말기가 본 실시예에 더 포함되어 호스트 단말기의 통역 요청 및 속기 요청이 동시에 있는 경우 통역사 단말기를 통한 통역과 속기사 단말기를 통한 속기가 동시에 이 루어지도록 구성될 수 있다. 도 11은 본 발명의 또 다른 실시예에 따른 실시간 번역 자막 제공시스템의 내부 구성을 나타내는 도면이다. 도면을 참조하면, 본 실시예에 따른 실시간 번역 자막 제공시스템은 호스트 단말기의 요청이 있거나 사전 설정에 따라 관리 서버의 STT 변환부 및 인공지능 번역부 중 적어도 하나에서 출력되는 결 과 정보 즉, 제 1 자막 정보 또는 제 2 자막 정보에 대해 검수를 수행하여 보정할 부분이 있는 경우, 이를 보정 하여 상기 관리 서버로 보정 정보를 전송하는 검수자 단말기가 더 포함될 수 있다. 이때 상기 STT 변환부는 음성 인식 시 생성되는 결과 정보에 대해 사전에 설정된 적합 여부를 판단하게 되 는데, 만일 적합 여부에 대해 사전에 설정된 제 1 적합 기준의 임계값을 초과하지 않을 경우에는 음성 인식이 불가능한 것으로 판단하여 해당 구절 또는 문장에 대해 제 1 자막 정보를 생성하지 않는다. 아울러 제 1 적합 기준을 초과하더라도 사전에 설정된 제 2 적합 기준의 임계값을 초과하지 않는 경우에는 음성 인식의 정확성이 낮은 것으로 판단하여 해당 구절 또는 문장에 대해 별도의 구별 처리를 하여 제 1 자막 정보를 전송하도록 구성될 수 있다. 이에 따라 상기 검수자 단말기는 상기 STT 변환부에서 제 1 적합 기준의 임계값을 초과하지 못해 제 1 자막 정보로 생성되지 않은 해당 구절 또는 문장이 있거나, 제 2 적합 기준의 임계값을 초과하지 못해 제 1 자막 정보로 생성되되 별도의 구별 처리가 된 해당 구절 또는 문장이 있는 경우, 이에 대한 보정 정보를 생성하 여 관리 서버로 실시간 전송한다. 이에 따라 관리 서버는 상기 검수자 단말기로부터 보정 정보를 수신 받는 경우, 이를 호스트 단말기 또는 클라이언트 단말기로 이미 제공한 제 1 자막 정보에 대해 보정 정보를 전송하여 기존 해당 구 절 또는 문장에 대한 제 1 자막 정보를 대체하도록 구성된다. 이와 같이 본 발명은 도면에 도시된 일실시예를 참고로 설명되었으나, 이는 예시적인 것에 불과하며, 본 기술 분야의 통상의 지식을 가진 자라면 이로부터 다양한 변형 및 균등한 타 실시예가 가능하다는 점을 이해할 것이다. 따라서, 본 발명의 진정한 기술적 보호범위는 첨부된 특허청구범위의 기술적 사상에 의해 정해져야 할 것이다."}
{"patent_id": "10-2023-0105407", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일실시예에 따른 실시간 번역 자막 제공시스템의 개략적인 구성을 나타내는 도면이다. 도 2는 본 발명의 일실시예에 따른 실시간 번역 자막 제공시스템의 내부 구성을 나타내는 도면이다. 도 3은 본 발명의 다른 실시예에 따른 호스트 단말기의 내부 구성을 나타내는 도면이다. 도 4는 본 발명의 일실시예에 따른 호스트 단말기의 전용 어플리케이션에서 메인 표시 화면을 나타내는 도면이 다. 도 5는 본 발명의 일실시예에 따른 호스트 단말기에서 제 1 자막 정보 또는 제 2 자막 정보가 동영상 데이터에 오버레이되어 출력되는 모습을 나타내는 도면이다. 도 6 및 도 7은 본 발명의 일실시예에 따른 호스트 단말기의 전용 어플리케이션에서 자막 공유 요청 화면을 나 타내는 도면이다. 도 8은 본 발명의 일실시예에 따른 클라이언트 단말기의 웹 페이지 표시 화면을 나타내는 도면이다. 도 9는 본 발명의 다른 실시예에 따른 실시간 번역 자막 제공시스템의 내부 구성을 나타내는 도면이다. 도 10은 본 발명의 또 다른 실시예에 따른 실시간 번역 자막 제공시스템의 내부 구성을 나타내는 도면이다. 도 11은 본 발명의 또 다른 실시예에 따른 실시간 번역 자막 제공시스템의 내부 구성을 나타내는 도면이다."}
