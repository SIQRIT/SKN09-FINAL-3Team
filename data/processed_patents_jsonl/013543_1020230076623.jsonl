{"patent_id": "10-2023-0076623", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0176842", "출원번호": "10-2023-0076623", "발명의 명칭": "사물 인터넷을 접목한 스마트 안대, 그 동작 제어 방법 및 시스템", "출원인": "가톨릭대학교 산학협력단", "발명자": "신혜영"}}
{"patent_id": "10-2023-0076623", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "사물 인터넷이 접목된 스마트 안대에 있어서,통신모듈;사용자의 적어도 하나의 안구를 덮도록 소정 형상으로 형성된 안구 보호부; 및상기 안구 보호부가 상기 사용자의 신체에 고정되도록 지지하는 지지부를 포함하되,상기 안구 보호부는, 적어도 하나의 발광부와 적어도 하나의 센서를 포함하는,스마트 안대."}
{"patent_id": "10-2023-0076623", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "청구항 1에 있어서,상기 적어도 하나의 발광부와 적어도 하나의 센서는,상기 안구 보호부의 일단에 부착된,스마트 안대."}
{"patent_id": "10-2023-0076623", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "청구항 2에 있어서,상기 안구 보호부의 일단은,상기 사용자의 관자놀이 부위에 상응하는 위치까지 연장된,스마트 안대."}
{"patent_id": "10-2023-0076623", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "청구항 2에 있어서,상기 안구 보호부의 일단은,상기 사용자의 눈썹 위쪽 부위에 상응하는 위치까지 연장된,스마트 안대."}
{"patent_id": "10-2023-0076623", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "청구항 2에 있어서,상기 적어도 하나의 발광부는, LED 소자 또는 LED 어레이로 형성된,스마트 안대."}
{"patent_id": "10-2023-0076623", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "청구항 2에 있어서,상기 적어도 하나의 센서부는,공개특허 10-2024-0176842-3-상기 사용자의 터치 입력을 센싱하는 터치 센서를 포함하는,스마트 안대."}
{"patent_id": "10-2023-0076623", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "청구항 1에 있어서,상기 안구 보호부는,상기 사용자의 안면 형상을 스캔하고, 스캔된 안면 형상 데이터에 기반하여 3D 프린터에 의해 제작된,스마트 안대."}
{"patent_id": "10-2023-0076623", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "발광부와 센서가 포함된 스마트 안대와 통신하는 단말기에 있어서,통신 모듈;상기 스마트 안대로부터 신호를 수신하는 수신부;상기 수신된 스마트 안대의 신호를 처리하고 분석하는 분석부; 및상기 분석부에서 분석된 내용에 따라 상기 스마트 안대의 동작을 제어하는 제어부를 포함하는,단말기."}
{"patent_id": "10-2023-0076623", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "청구항 8에 있어서,상기 수신되는 스마트 안대의 신호는,상기 센서를 통해 센싱되는 정보를 포함하는,단말기."}
{"patent_id": "10-2023-0076623", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "청구항 9에 있어서,상기 제어부는,상기 스마트 안대의 신호로부터 사용자의 안약 투약 로그 데이터를 추출하는,단말기."}
{"patent_id": "10-2023-0076623", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "에 있어서,상기 제어부는,상기 추출한 사용자의 안약 투약 로그 데이터에 기초하여 다음 안약 투약 시간을 도과한 경우에는, 상기 스마트안대의 출력부에서 사운드를 출력하도록 제어하는,단말기."}
{"patent_id": "10-2023-0076623", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "청구항 11에 있어서,상기 제어부는,상기 추출한 사용자의 안약 투약 로그 데이터에 기초하여 다음 안약 투약 시간을 도과한 경우에는, 상기 스마트안대의 발광부가 제1 컬러로 발광하도록 제어하는,단말기.공개특허 10-2024-0176842-4-청구항 13"}
{"patent_id": "10-2023-0076623", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "청구항 12에 있어서,상기 제어부는,상기 추출한 사용자의 안약 투약 로그 데이터에 기초하여 다음 안약 투약 시간을 도과한 경우에는, 상기 발광부의 제1 컬러 발광과 함께 상기 스마트 안대의 출력부에서 사운드를 출력하도록 제어하는,단말기."}
{"patent_id": "10-2023-0076623", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "청구항 11에 있어서,상기 제어부는,상기 추출한 사용자의 안약 투약 로그 데이터에 기초하여 다음 안약 투약 시간을 도과하진 않았으나 제1 임계시간 미만이 남은 경우에는, 상기 스마트 안대의 발광부에서 제2 컬러를 출력하도록 제어하는,단말기."}
{"patent_id": "10-2023-0076623", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "청구항 15에 있어서,상기 제어부는,상기 추출한 사용자의 안약 투약 로그 데이터에 기초하여 다음 안약 투약 시간까지 제1 임계 시간 이상 제2 임계 시간 미만이 남은 경우에는, 상기 스마트 안대의 발광부에서 제3 컬러를 출력하도록 제어하는,단말기."}
{"patent_id": "10-2023-0076623", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "발광부와 센서가 포함된 스마트 안대와 통신하여 상기 스마트 안대를 제어하는 단말기의 동작 제어 방법에 있어서,상기 스마트 안대로부터 사용자의 안약 투약 로그 정보를 획득하는 단계;상기 획득한 사용자의 안약 투약 로그 정보를 분석하는 단계;상기 분석 결과 다음 안약 투약 시간이 도과하였는지 판단하는 단계; 및상기 판단 결과에 기초하여 사용자의 안약 투약 안내 신호를 생성 및 상기 스마트 안대로 전송하여 상기 스마트안대의 동작을 제어하는 단계를 포함하는,동작 제어 방법."}
{"patent_id": "10-2023-0076623", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "청구항 17에 있어서,상기 스마트 안대의 동작을 제어하는 단계는,공개특허 10-2024-0176842-5-상기 판단 결과 상기 사용자의 안약 투약 시간이 도과한 경우에는,상기 스마트 안대에 포함된 발광부가 제1 컬러로 발광되도록 제어하는,동작 제어 방법."}
{"patent_id": "10-2023-0076623", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "청구항 18에 있어서,상기 스마트 안대의 동작을 제어하는 단계는,상기 판단 결과 상기 사용자의 안약 투약 시간이 도과한 경우에는,상기 스마트 안대에서 사운드를 출력하도록 제어하는,동작 제어 방법."}
{"patent_id": "10-2023-0076623", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "청구항 17에 있어서,상기 분석 결과 다음 안약 투약 시간이 도과하지 않은 경우, 다음 안약 투약 시간까지 제1 임계 시간 미만의 시간이 남았는지 판단하는 단계를 더 포함하는,동작 제어 방법."}
{"patent_id": "10-2023-0076623", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_21", "content": "청구항 20에 있어서,상기 판단 결과 다음 안약 투약 시간까지 제1 임계 시간 미만의 시간이 남은 경우에는, 상기 스마트 안대의 발광부가 제2 컬러로 발광하도록 제어하는,동작 제어 방법."}
{"patent_id": "10-2023-0076623", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_22", "content": "청구항 21에 있어서,상기 분석 결과 다음 안약 투약 시간이 도과하지 않았으나 다음 안약 투약 시간까지 제1 임계 시간 이상 제2 임계 시간 미만의 시간이 남았는지 판단하는 단계를 더 포함하는,동작 제어 방법."}
{"patent_id": "10-2023-0076623", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_23", "content": "청구항 22에 있어서,상기 분석 결과 다음 안약 투약 시간이 도과하지 않았으나 다음 안약 투약 시간까지 제1 임계 시간 이상 제2 임계 시간 미만의 시간이 남은 경우에는, 상기 스마트 안대의 발광부가 제3 컬러로 발광하도록 제어하는,동작 제어 방법."}
{"patent_id": "10-2023-0076623", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_24", "content": "통신모듈, 발광부, 센서 및 출력부를 포함하여 사용자의 적어도 하나의 안구를 보호하는 스마트 안대; 및상기 스마트 안대와 통신하여 상기 센서에 의해 센싱된 사용자의 안약 투약 로그 정보를 획득하고, 획득된 사용자의 안약 투약 로그 정보에 기초하여 상기 스마트 안대의 동작을 제어하는 단말기를 포함하는,시스템."}
{"patent_id": "10-2023-0076623", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "사물 인터넷을 접목한 스마트 안대, 그 동작 제어 방법 및 시스템이 개시된다. 본 개시의 다양한 실시예들 중 적 어도 하나에 따른 발광부와 센서가 포함된 스마트 안대와 통신하는 단말기는, 통신 모듈; 디스플레이; 상기 스마 트 안대로부터 신호를 수신하는 수신부; 상기 수신된 스마트 안대의 신호를 처리하고 분석하는 분석부; 및 상기 분석부에서 분석된 내용에 따라 상기 스마트 안대의 동작을 제어하는 제어부를 포함할 수 있다."}
{"patent_id": "10-2023-0076623", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 스마트 안대에 관한 것으로, 보다 상세하게는 사물 인터넷을 접목한 스마트 안대, 그 동작 제어 방법 및 시스템에 관한 것이다."}
{"patent_id": "10-2023-0076623", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "종래 안대는 단순히 눈, 즉 안구를 보호하는 기능만이 있었다. 최근 미용이나 생활의 불편함 해소 목적으로 라식이나 라섹과 같은 시력 교정술에 대한 수요가 지속적으로 증가 하고 있다. 또한, 대기 환경의 변화 등뿐만 아니라 노령 인구가 늘어남에 따라 백내장, 녹내장과 같은 다양한 안과 질환이 증가하고, 안과 수술에 대한 수요도 함께 증가하고 있다. 이러한 이유로 안대의 착용은 시술이나 수술 이후에 안구의 보호를 포함하여 수술 후 관리를 위해 그 수요가 늘 어나고 있다. 선행기술문헌 특허문헌 (특허문헌 0001) 한국 등록실용신안 제20-0458777호 (등록일: 2012.02.13.)"}
{"patent_id": "10-2023-0076623", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 개시에서는 스마트 안대와 단말기의 어플리케이션을 연동하여, 사용자에게 안약의 점안 시점에 대한 정보를 제공하고 가이드하여 그를 통한 안과 치료 효과를 높이고자 하는 것이다. 본 개시에서는 사물 인터넷을 접목한 스마트 안대, 그 동작 제어 방법 및 시스템을 제공하는 것이다."}
{"patent_id": "10-2023-0076623", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 개시의 다양한 실시예들 중 적어도 하나에 따른 사물 인터넷이 접목된 스마트 안대는, 통신모듈; 사용자의 적어도 하나의 안구를 덮도록 소정 형상으로 형성된 안구 보호부; 및 상기 안구 보호부가 상기 사용자의 신체에 고정되도록 지지하는 지지부를 포함하되, 상기 안구 보호부는, 적어도 하나의 발광부와 적어도 하나의 센서를 포함할 수 있다. 본 개시의 다양한 실시예들 중 적어도 하나에 따르면, 상기 적어도 하나의 발광부와 적어도 하나의 센서는, 상 기 안구 보호부의 일단에 부착될 수 있다. 본 개시의 다양한 실시예들 중 적어도 하나에 따르면, 상기 안구 보호부의 일단은, 상기 사용자의 관자놀이 부 위에 상응하는 위치까지 연장될 수 있다. 본 개시의 다양한 실시예들 중 적어도 하나에 따르면, 상기 안구 보호부의 일단은, 상기 사용자의 눈썹 위쪽 부 위에 상응하는 위치까지 연장될 수 있다. 본 개시의 다양한 실시예들 중 적어도 하나에 따르면, 상기 적어도 하나의 발광부는, LED 소자 또는 LED 어레이 로 형성될 수 있다. 본 개시의 다양한 실시예들 중 적어도 하나에 따르면, 상기 적어도 하나의 센서부는, 상기 사용자의 터치 입력 을 센싱하는 터치 센서를 포함할 수 있다. 본 개시의 다양한 실시예들 중 적어도 하나에 따르면, 상기 안구 보호부는, 상기 사용자의 안면 형상을 스캔하 고, 스캔된 안면 형상 데이터에 기반하여 3D 프린터에 의해 제작될 수 있다. 본 개시의 다양한 실시예들 중 적어도 하나에 따른 발광부와 센서가 포함된 스마트 안대와 통신하는 단말기는, 통신 모듈; 상기 스마트 안대로부터 신호를 수신하는 수신부; 상기 수신된 스마트 안대의 신호를 처리하고 분석 하는 분석부; 및 상기 분석부에서 분석된 내용에 따라 상기 스마트 안대의 동작을 제어하는 제어부를 포함할 수 있다. 본 개시의 다양한 실시예들 중 적어도 하나에 따르면, 상기 수신되는 스마트 안대의 신호는, 상기 센서를 통해 센싱되는 정보를 포함할 수 있다. 본 개시의 다양한 실시예들 중 적어도 하나에 따르면, 상기 제어부는, 상기 스마트 안대의 신호로부터 사용자의 안약 투약 로그 데이터를 추출할 수 있다. 본 개시의 다양한 실시예들 중 적어도 하나에 따르면, 상기 제어부는, 상기 추출한 사용자의 안약 투약 로그 데 이터에 기초하여 상기 발광부의 동작을 제어할 수 있다. 본 개시의 다양한 실시예들 중 적어도 하나에 따르면, 상기 제어부는, 상기 추출한 사용자의 안약 투약 로그 데 이터에 기초하여 다음 안약 투약 시간을 도과한 경우에는, 상기 스마트 안대의 발광부가 제1 컬러로 발광하도록 제어할 수 있다. 본 개시의 다양한 실시예들 중 적어도 하나에 따르면, 상기 제어부는, 상기 추출한 사용자의 안약 투약 로그 데 이터에 기초하여 다음 안약 투약 시간을 도과한 경우에는, 상기 스마트 안대의 출력부에서 사운드를 출력하도록 제어할 수 있다. 본 개시의 다양한 실시예들 중 적어도 하나에 따르면, 상기 제어부는, 상기 추출한 사용자의 안약 투약 로그 데 이터에 기초하여 다음 안약 투약 시간을 도과한 경우에는, 상기 발광부의 제1 컬러 발광과 함께 상기 스마트 안 대의 출력부에서 사운드를 출력하도록 제어할 수 있다. 본 개시의 다양한 실시예들 중 적어도 하나에 따르면, 상기 제어부는, 상기 추출한 사용자의 안약 투약 로그 데 이터에 기초하여 다음 안약 투약 시간을 도과하진 않았으나 제1 임계 시간 미만이 남은 경우에는, 상기 스마트 안대의 발광부에서 제2 컬러를 출력하도록 제어할 수 있다. 본 개시의 다양한 실시예들 중 적어도 하나에 따르면, 상기 제어부는, 상기 추출한 사용자의 안약 투약 로그 데 이터에 기초하여 다음 안약 투약 시간까지 제1 임계 시간 이상 제2 임계 시간 미만이 남은 경우에는, 상기 스마 트 안대의 발광부에서 제3 컬러를 출력하도록 제어할 수 있다. 본 개시의 다양한 실시예들 중 적어도 하나에 따른, 발광부와 센서가 포함된 스마트 안대와 통신하여 상기 스마 트 안대를 제어하는 단말기의 동작 방법은, 상기 스마트 안대로부터 사용자의 안약 투약 로그 정보를 획득하는 단계; 상기 획득한 사용자의 안약 투약 로그 정보를 분석하는 단계; 상기 분석 결과 다음 안약 투약 시간이 도 과하였는지 판단하는 단계; 및 상기 판단 결과에 기초하여 사용자의 안약 투약 안내 신호를 생성 및 상기 스마 트 안대로 전송하여 상기 스마트 안대의 동작을 제어하는 단계를 포함할 수 있다. 본 개시의 다양한 실시예들 중 적어도 하나에 따르면, 상기 스마트 안대의 동작을 제어하는 단계는, 상기 판단 결과 상기 사용자의 안약 투약 시간이 도과한 경우에는, 상기 스마트 안대에 포함된 발광부가 제1 컬러로 발광 되도록 제어할 수 있다. 본 개시의 다양한 실시예들 중 적어도 하나에 따르면, 상기 스마트 안대의 동작을 제어하는 단계는, 상기 판단 결과 상기 사용자의 안약 투약 시간이 도과한 경우에는, 상기 스마트 안대에서 사운드를 출력하도록 제어할 수 있다. 본 개시의 다양한 실시예들 중 적어도 하나에 따르면, 상기 분석 결과 다음 안약 투약 시간이 도과하지 않은 경 우, 다음 안약 투약 시간까지 제1 임계 시간 미만의 시간이 남았는지 판단하는 단계를 더 포함할 수 있다. 본 개시의 다양한 실시예들 중 적어도 하나에 따르면, 상기 판단 결과 다음 안약 투약 시간까지 제1 임계 시간 미만의 시간이 남은 경우에는, 상기 스마트 안대의 발광부가 제2 컬러로 발광하도록 제어할 수 있다. 본 개시의 다양한 실시예들 중 적어도 하나에 따르면, 상기 분석 결과 다음 안약 투약 시간이 도과하지 않았으 나 다음 안약 투약 시간까지 제1 임계 시간 이상 제2 임계 시간 미만의 시간이 남았는지 판단하는 단계를 더 포 함할 수 있다. 본 개시의 다양한 실시예들 중 적어도 하나에 따르면, 상기 분석 결과 다음 안약 투약 시간이 도과하지 않았으 나 다음 안약 투약 시간까지 제1 임계 시간 이상 제2 임계 시간 미만의 시간이 남은 경우에는, 상기 스마트 안대의 발광부가 제3 컬러로 발광하도록 제어할 수 있다. 본 개시의 다양한 실시예들 중 적어도 하나에 따른 시스템은, 통신모듈, 발광부, 센서 및 출력부를 포함하여 사 용자의 적어도 하나의 안구를 보호하는 스마트 안대; 및 상기 스마트 안대와 통신하여 상기 센서에 의해 센싱된 사용자의 안약 투약 로그 정보를 획득하고, 획득된 사용자의 안약 투약 로그 정보에 기초하여 상기 스마트 안대 의 동작을 제어하는 단말기를 포함할 수 있다."}
{"patent_id": "10-2023-0076623", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 개시의 다양한 실시예들 중 적어도 하나에 따르면, 첫째, 사용자가 보다 정확하게 안약을 사용하도록 유도하여 치료 효과를 높일 수 있는 효과가 있다. 둘째, 사물 인터넷을 접목한 스마트 안대, 그 동작 제어 방법 및 시스템을 제공할 수 있다."}
{"patent_id": "10-2023-0076623", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 개시 전체에 걸쳐 동일 참조 부호는 동일 구성요소를 지칭한다. 본 개시가 실시예들의 모든 요소들을 설명하"}
{"patent_id": "10-2023-0076623", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "는 것은 아니며, 본 개시가 속하는 기술분야에서 일반적인 내용 또는 실시예들 간에 중복되는 내용은 생략한다. 명세서에서 사용되는 ‘부, 모듈, 부재, 블록’이라는 용어는 소프트웨어 또는 하드웨어로 구현될 수 있으며, 실시예들에 따라 복수의 '부, 모듈, 부재, 블록'이 하나의 구성요소로 구현되거나, 하나의 '부, 모듈, 부재, 블 록'이 복수의 구성요소들을 포함하는 것도 가능하다. 명세서 전체에서, 어떤 부분이 다른 부분과 \"연결\"되어 있다고 할 때, 이는 직접적으로 연결되어 있는 경우뿐 아니라, 간접적으로 연결되어 있는 경우를 포함하고, 간접적인 연결은 무선 통신망을 통해 연결되는 것을 포함 한다. 또한 어떤 부분이 어떤 구성요소를 \"포함\"한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다른 구성요소를 제외하는 것이 아니라 다른 구성요소를 더 포함할 수 있는 것을 의미한다. 명세서 전체에서, 어떤 부재가 다른 부재 \"상에\" 위치하고 있다고 할 때, 이는 어떤 부재가 다른 부재에 접해 있는 경우뿐 아니라 두 부재 사이에 또 다른 부재가 존재하는 경우도 포함한다. 제1, 제2 등의 용어는 하나의 구성요소를 다른 구성요소로부터 구별하기 위해 사용되는 것으로, 구성요소가 전 술된 용어들에 의해 제한되는 것은 아니다. 단수의 표현은 문맥상 명백하게 예외가 있지 않는 한, 복수의 표현을 포함한다. 각 단계들에 있어 식별부호는 설명의 편의를 위하여 사용되는 것으로 식별부호는 각 단계들의 순서를 설명하는 것이 아니며, 각 단계들은 문맥상 명백하게 특정 순서를 기재하지 않는 이상 명기된 순서와 다르게 실시될 수 있다. 이하 첨부된 도면들을 참고하여 본 개시의 작용 원리 및 실시예들에 대해 설명한다. 본 명세서에서 '본 개시에 따른 장치'는 연산 처리를 수행하여 사용자에게 결과를 제공할 수 있는 다양한 장치 들이 모두 포함된다. 예를 들어, 본 개시에 따른 장치는, 컴퓨터, 서버 장치 및 휴대용 단말기를 모두 포함하거 나, 또는 어느 하나의 형태가 될 수 있다.여기에서, 상기 컴퓨터는 예를 들어, 웹 브라우저(WEB Browser)가 탑재된 노트북, 데스크톱(desktop), 랩톱 (laptop), 태블릿 PC, 슬레이트 PC 등을 포함할 수 있다. 상기 서버 장치는 외부 장치와 통신을 수행하여 정보를 처리하는 서버로써, 애플리케이션 서버, 컴퓨팅 서버, 데이터베이스 서버, 파일 서버, 게임 서버, 메일 서버, 프록시 서버, 웹 서버 등을 포함할 수 있다. 상기 휴대용 단말기는 예를 들어, 휴대성과 이동성이 보장되는 무선 통신 장치로서, PCS(Personal Communication System), GSM(Global System for Mobile communications), PDC(Personal Digital Cellular), PHS(Personal Handyphone System), PDA(Personal Digital Assistant), IMT(International Mobile Telecommunication)-2000, CDMA(Code Division Multiple Access)-2000, W-CDMA(W-Code Division Multiple Access), WiBro(Wireless Broadband Internet) 단말, 스마트 폰(Smart Phone) 등과 같은 모든 종류의 핸드헬드 (Handheld) 기반의 무선 통신 장치와 시계, 반지, 팔찌, 발찌, 목걸이, 안경, 콘택트 렌즈, 또는 머리 착용형 장치(HMD: head-mounted device) 등과 같은 웨어러블 장치를 포함할 수 있다. 본 개시에 따른 인공지능과 관련된 기능은 프로세서와 메모리를 통해 동작된다. 프로세서는 하나 또는 복수의 프로세서로 구성될 수 있다. 이때, 하나 또는 복수의 프로세서는 CPU, AP, DSP(Digital Signal Processor) 등 과 같은 범용 프로세서, GPU, VPU(Vision Processing Unit)와 같은 그래픽 전용 프로세서 또는 NPU와 같은 인 공지능 전용 프로세서일 수 있다. 하나 또는 복수의 프로세서는, 메모리에 저장된 기 정의된 동작 규칙 또는 인 공지능 모델에 따라, 입력 데이터를 처리하도록 제어한다. 또는, 하나 또는 복수의 프로세서가 인공지능 전용 프로세서인 경우, 인공지능 전용 프로세서는, 특정 인공지능 모델의 처리에 특화된 하드웨어 구조로 설계될 수 있다. 기 정의된 동작 규칙 또는 인공지능 모델은 학습을 통해 만들어진 것을 특징으로 한다. 여기서, 학습을 통해 만 들어진다는 것은, 기본 인공지능 모델이 학습 알고리즘에 의하여 다수의 학습 데이터들을 이용하여 학습됨으로 써, 원하는 특성(또는, 목적)을 수행하도록 설정된 기 정의된 동작 규칙 또는 인공지능 모델이 만들어짐을 의미 한다. 이러한 학습은 본 개시에 따른 인공지능이 수행되는 기기 자체에서 이루어질 수도 있고, 별도의 서버 및/ 또는 시스템을 통해 이루어질 수도 있다. 학습 알고리즘의 예로는, 지도형 학습(supervised learning), 비지도 형 학습(unsupervised learning), 준지도형 학습(semi-supervised learning) 또는 강화 학습(reinforcement learning)이 있으나, 전술한 예에 한정되지 않는다. 인공지능 모델은, 복수의 신경망 레이어들로 구성될 수 있다. 복수의 신경망 레이어들 각각은 복수의 가중치들 (weight values)을 갖고 있으며, 이전(previous) 레이어의 연산 결과와 복수의 가중치들 간의 연산을 통해 신경 망 연산을 수행한다. 복수의 신경망 레이어들이 갖고 있는 복수의 가중치들은 인공지능 모델의 학습 결과에 의 해 최적화될 수 있다. 예를 들어, 학습 과정 동안 인공지능 모델에서 획득한 로스(loss) 값 또는 코스트(cost) 값이 감소 또는 최소화되도록 복수의 가중치들이 갱신될 수 있다. 인공 신경망은 심층 신경망(DNN: Deep Neural Network)를 포함할 수 있으며, 예를 들어, CNN(Convolutional Neural Network), DNN(Deep Neural Network), RNN(Recurrent Neural Network), RBM(Restricted Boltzmann Machine), DBN(Deep Belief Network), BRDNN(Bidirectional Recurrent Deep Neural Network) 또는 심층 Q-네트워크(Deep Q-Networks) 등이 있으나, 전술한 예에 한정되지 않는다. 본 개시의 예시적인 실시예에 따르면, 프로세서는 인공지능을 구현할 수 있다. 인공지능이란 사람의 신경세포 (biological neuron)를 모사하여 기계가 학습하도록 하는 인공신경망(Artificial Neural Network) 기반의 기계 학습법을 의미한다. 인공지능의 방법론에는 학습 방식에 따라 훈련 데이터로서 입력 데이터와 출력 데이터가 같 이 제공됨으로써 문제(입력 데이터)의 해답(출력데이터)이 정해져 있는 지도학습(supervised learning), 및 출 력 데이터 없이 입력데이터만 제공되어 문제(입력 데이터)의 해답(출력 데이터)이 정해지지 않는 비지도학습 (unsupervised learning), 및 현재의 상태(State)에서 어떤 행동(Action)을 취할 때마다 외부 환경에서 보상 (Reward)이 주어지는데, 이러한 보상을 최대화하는 방향으로 학습을 진행하는 강화학습(reinforcement learning)으로 구분될 수 있다. 또한, 인공지능의 방법론은 학습 모델의 구조인 아키텍처에 따라 구분될 수도 있는데, 널리 이용되는 딥러닝 기술의 아키텍처는, 합성곱신경망(CNN; Convolutional Neural Network), 순환신 경망(RNN; Recurrent Neural Network), 트랜스포머(Transformer), 생성적 대립 신경망(GAN; generative adversarial networks) 등으로 구분될 수 있다. 본 장치와 시스템은 인공지능 모델을 포함할 수 있다. 인공지능 모델은 하나의 인공지능 모델일 수 있고, 복수 의 인공지능 모델로 구현될 수도 있다. 인공지능 모델은 뉴럴 네트워크(또는 인공 신경망)로 구성될 수 있으며, 기계학습과 인지과학에서 생물학의 신경을 모방한 통계학적 학습 알고리즘을 포함할 수 있다. 뉴럴 네트워크는시냅스의 결합으로 네트워크를 형성한 인공 뉴런(노드)이 학습을 통해 시냅스의 결합 세기를 변화시켜, 문제 해 결 능력을 가지는 모델 전반을 의미할 수 있다. 뉴럴 네트워크의 뉴런은 가중치 또는 바이어스의 조합을 포함할 수 있다. 뉴럴 네트워크는 하나 이상의 뉴런 또는 노드로 구성된 하나 이상의 레이어(layer)를 포함할 수 있다. 예시적으로, 장치는 input layer, hidden layer, output layer를 포함할 수 있다. 장치를 구성하는 뉴럴 네트 워크는 뉴런의 가중치를 학습을 통해 변화시킴으로써 임의의 입력(input)으로부터 예측하고자 하는 결과 (output)를 추론할 수 있다. 프로세서는 뉴럴 네트워크를 생성하거나, 뉴럴 네트워크를 훈련(train, 또는 학습(learn)하거나, 수신되는 입력 데이터를 기초로 연산을 수행하고, 수행 결과를 기초로 정보 신호(information signal)를 생성하거나, 뉴럴 네 트워크를 재훈련(retrain)할 수 있다. 뉴럴 네트워크의 모델들은 GoogleNet, AlexNet, VGG Network 등과 같은 CNN(Convolution Neural Network), R-CNN(Region with Convolution Neural Network), RPN(Region Proposal Network), RNN(Recurrent Neural Network), S-DNN(Stacking-based deep Neural Network), S-SDNN(State-Space Dynamic Neural Network), Deconvolution Network, DBN(Deep Belief Network), RBM(Restrcted Boltzman Machine), Fully Convolutional Network, LSTM(Long Short-Term Memory) Network, Classification Network 등 다양한 종류의 모델들을 포함할 수 있으나 이에 제한되지는 않는다. 프로세서는 뉴럴 네트워크의 모델들에 따른 연산을 수행하기 위한 하나 이상의 프로세서를 포함할 수 있다. 예를 들어 뉴럴 네트워크는 심층 뉴럴 네트워크 (Deep Neural Network)를 포함할 수 있다. 뉴럴 네트워크는 CNN(Convolutional Neural Network), RNN(Recurrent Neural Network), 퍼셉트론(perceptron), 다층 퍼셉트론(multilayer perceptron), FF(Feed Forward), RBF(Radial Basis Network), DFF(Deep Feed Forward), LSTM(Long Short Term Memory), GRU(Gated Recurrent Unit), AE(Auto Encoder), VAE(Variational Auto Encoder), DAE(Denoising Auto Encoder), SAE(Sparse Auto Encoder), MC(Markov Chain), HN(Hopfield Network), BM(Boltzmann Machine), RBM(Restricted Boltzmann Machine), DBN(Depp Belief Network), DCN(Deep Convolutional Network), DN(Deconvolutional Network), DCIGN(Deep Convolutional Inverse Graphics Network), GAN(Generative Adversarial Network), LSM(Liquid State Machine), ELM(Extreme Learning Machine), ESN(Echo State Network), DRN(Deep Residual Network), DNC(Differentiable Neural Computer), NTM(Neural Turning Machine), CN(Capsule Network), KN(Kohonen Network) 및 AN(Attention Network)를 포함 할 수 있으나 이에 한정되는 것이 아닌 임의의 뉴럴 네트워크를 포함할 수 있음은 통상의 기술자가 이해할 것이다. 본 개시의 예시적인 실시예에 따르면, 프로세서는 GoogleNet, AlexNet, VGG Network 등과 같은 CNN(Convolution Neural Network), R-CNN(Region with Convolution Neural Network), RPN(Region Proposal Network), RNN(Recurrent Neural Network), S-DNN(Stacking-based deep Neural Network), S-SDNN(State-Space Dynamic Neural Network), Deconvolution Network, DBN(Deep Belief Network), RBM(Restrcted Boltzman Machine), Fully Convolutional Network, LSTM(Long Short-Term Memory) Network, Classification Network, Generative Modeling, eXplainable AI, Continual AI, Representation Learning, AI for Material Design, 자 연어 처리를 위한 BERT, SP-BERT, MRC/QA, Text Analysis, Dialog System, GPT-3, GPT-4, 비전 처리를 위한 Visual Analytics, Visual Understanding, Video Synthesis, ResNet 데이터 지능을 위한 Anomaly Detection, Prediction, Time-Series Forecasting, Optimization, Recommendation, Data Creation 등 다양한 인공지능 구 조 및 알고리즘을 이용할 수 있으며, 이에 제한되지 않는다. 이하, 첨부된 도면을 참조하여 본 개시의 실시예를 상세하게 설명한다. 본 개시에서 스마트 안대는 다양한 전자 기구를 부착하거나 내장하여 디지털 기술을 통해 사용자(예를 들어, 환 자)에게 치료약의 점안에 관한 정보를 제공하거나 가이드하여 치료 효과를 높이거나 문제가 발생하지 않도록 신 호 처리하는 모든 형태의 전자 장치를 나타낼 수 있다. 한편, 이러한 스마트 안대는 부착 또는 내장되는 전자 기구를 제외한 부분은 전통적인 안대일 수도 있고, 본 개시에 따른 스마트 안대를 위해 별도 고안된 기구 형태 일 수도 있으나, 이에 한정되는 것은 아니다. 도 1은 본 개시의 일실시예에 따른 사물 인터넷이 접목된 스마트 안대가 포함된 서비스 시스템의 개략도이다. 도 2는 도 1의 단말기의 구성 블록도이다. 도 3은 도 1의 스마트 안대의 구성 블록도이다. 본 개시의 다양한 실시예들 중 적어도 하나에 따른 서비스 시스템은, 통신모듈, 발광부, 센서 및 출력부를 포함하여 사용자의 적어도 하나의 안구를 보호하는 스마트 안대, 및 스마트 안대와 통신하여 센서에 의해 센싱 된 사용자의 안약 투약 로그 정보를 획득하고, 획득된 사용자의 안약 투약 로그 정보에 기초하여 스마트 안대의 동작을 제어하는 단말기를 포함할 수 있다. 도 1을 참조하면, 본 개시의 일 실시예에 따른 서비스 시스템은, 단말기와 스마트 안대를 포함하 여 구현될 수 있다. 이 때, 서비스 시스템은 단말기와 스마트 안대 중 적어도 하나와 연결되는 서 버를 더 포함하여 구현될 수 있다. 단말기는 스마트 안대와 데이터 커뮤니케이션을 수행하여, 스마트 안대의 동작을 제어할 수 있 다. 본 개시에 따르면, 상기 데이터 커뮤니케이션을 어플리케이션을 통해 이루어질 수 있다. 도 2를 참조하면, 단말기는 메모리와 프로세서를 포함할 수 있다. 프로세서는 통신모듈, 데이터수신부, 데이터추출부, 데이터처리부, 및 제어부를 포함 할 수 있다. 통신모듈은 통신 인터페이스 환경을 제공하여, 단말기가 스마트 안대와 데이터를 주고받을 수 있도록 지원할 수 있다. 통신모듈은 필요에 따라 통신 인터페이스 환경을 제공하여, 단말기가 서버와 데이터를 주고받을 수 있도록 지원할 수 있다. 데이터수신부는 통신모듈을 통해 스마트 안대로부터 데이터를 수신할 수 있다. 데이터수신부는 통신모듈을 통해 서버로부터 데이터를 수신할 수 있다. 데이터추출부는 데이터수신부를 통해 수신되는 스마트 안대 및/또는 서버의 데이터로부터 정보를 추출할 수 있다. 데이터처리부는 데이터수신부를 통해 수신되는 스마트 안대 및/또는 서버의 데이터를 처리 하거나 데이터추출부를 통해 추출된 데이터를 처리할 수 있다. 데이터처리부는 처리한 데이터에 기초하여 필요한 제어 신호를 생성할 수 있다. 제어부는 프로세서 나아가 단말기의 각 구성요소의 전반적인 동작을 제어할 수 있다. 메모리는 다양한 정보를 미리 내장하거나 내장된 정보를 업데이트할 수 있다. 메모리는 단말기 의 각 구성요소에 의해 처리된 데이터나 정보를 일시 저장할 수 있다. 메모리는 필요에 따라 스마트 안대로부터 수신되는 데이터의 처리, 분석 등을 위하여 필요한 프로그 램 등 소프트웨어나 관련 처리 엔진 등을 저장할 수 있다. 메모리는 인공지능 학습 엔진에 관한 정보를 저 장할 수 있다. 이러한 엔진은 제어부 내에 구현될 수도 있다. 제어부는 수신된 스마트 안대의 신호를 처리하고 분석하는 분석부(미도시)를 포함할 수 있다. 제어부는 분석부를 통해 분석된 내용에 따라 스마트 안대의 동작을 제어할 수 있다. 제어부는 스마트 안대의 신호로부터 사용자의 안약 투약 로그 데이터(Log data)를 추출할 수 있다. 제어부는 추출한 사용자의 안약 투약 로그 데이터에 기초하여 스마트 안대에 부착되거나 내장된 일 구성의 동작을 제어할 수 있다. 제어부는 추출한 사용자의 안약 투약 로그 데이터에 기초하여, 다음 안약 투약 시간 경과 여부를 판단하고, 그에 따라 스마트 안대를 통한 안약 투약 시점에 대한 정보 제공 내지 가이드를 할 수 있다. 이 에 대한 구체적인 알고리즘은 도 6 내지 7에서 상세히 설명한다. 다음으로, 스마트 안대는 사용자의 적어도 하나의 안구를 보호하며, 디지털 기술을 접목하여 단지 사용자 의 안구 보호에 그치지 않고, 관리 기능을 수행할 수 있다. 여기서, 관리 기능이란 예를 들어, 사용자의 안구나 시력 등을 보호하기 위한 다양한 기능을 포함하는 의미일 수 있다. 편의상, 본 개시에서는 관리 기능으로 사용 자가 안약을 점안하여야 하는 상황을 가정하여, 안약 점안에 관한 관리를 예로 하여 설명한다. 다만, 이에 한정 되는 것은 아니다.상기에서, 스마트 안대에 접목되는 디지털 기술에는 사물 인터넷(Internet of Things) 기술, 다양한 유/무 선 통신 기술 등을 예로 할 수 있다. 다만, 이에 한정되는 것은 아니다. 본 개시의 일 실시예에 따른 스마트 안대는 적어도 하나의 인디케이터(indicator), 적어도 하나의 센서, 출력부 등 중 적어도 하나를 장착, 내장 또는 그와 연결되어, 사용자의 안약 점안 제어 동작을 수행할 수 있다. 도 1 및 3을 참조하면, 스마트 안대는 메모리와 프로세서를 포함하여 구성될 수 있다. 프로세서는 통신모듈, 센서부, 발광부, 출력부 및 제어부를 포함하여 구성될 수 있다. 통신모듈은 통신 인터페이스 환경을 제공하여, 스마트 안대가 단말기와 데이터를 주고받을 수 있도록 지원할 수 있다. 통신모듈은 필요에 따라 통신 인터페이스 환경을 제공하여, 스마트 안대가 서버와 데이터를 주 고받을 수 있도록 지원할 수 있다. 센서부는 적어도 하나 이상의 센서를 포함하여, 사용자의 입력을 감지할 수 있다. 사용자의 입력이 터치 입력인 경우, 센서부를 구성하는 적어도 하나의 센서는 터치 센서일 수 있다. 센서부는 사용자의 신체 정보를 센싱하여 획득할 수 있다. 여기서, 사용자의 신체 정보에는 안구, 혈압이 나 심장 박동 등 다양한 정보가 포함될 수 있다. 신체 정보에 따라 센서부는 이미지 센서나 각종 측정 센서 등이 포함될 수 있다. 예를 들어, 이미지 센서 는 사용자의 안구나 안구 주변 등의 이미지를 촬영할 수 있다. 이렇게 촬영된 사용자의 안구나 안구 주변 등으 이미지는, 단말기나 서버로 전송되어, 모니터링이나 분석 용도로 사용될 수 있다. 관련하여, 이러한 이미지는 예를 들어, 단말기가 의료 기관의 단말기인 경우에는, 의료기관에서 분석하여 안구의 상태에 따른 사용자의 안약 점안 시점과 관련된 스마트 안대의 동작을 제어할 수 있다. 예를 들어, 의료기관은 스마트 안대를 통해 미리 설정된 안약 투약 시점을 조절할 수 있다. 발광부는 단말기나 서버의 동작 제어 신호에 따라 동작할 수 있다. 발광부는 전술한 인디케이터 기능을 수행하기 위한 구성요소로서, 스마트 안대를 착용한 사용자의 안 약 투약 시점과 관련하여 상태를 인디케이팅하도록 발광할 수 있다. 발광부는 특정 컬러의 LED(Light Emitting Diode) 소자나 LED 어레이(array) 형태로 구현될 수 있다. 발광부는 소정 간격으로 배치되고 외부에서 바라볼 때 제3자가 발광 내용이 식별 가능하도록 소정 형상으 로 배치될 수 있다. 발광부는 단말기나 서버의 제어 신호에 따라 사용자의 안약 투약 상황에 따라 특정 컬러의 소자 만 발광할 수 있다. 발광부는 단말기나 서버의 제어 신호에 따라 사용자의 안약 투약 상황에 따라 특정 패턴으로 발 광할 수 있다. 발광부는 단말기나 서버의 제어 신호에 따라 사용자의 안약 투약 상황에 따라 특정 컬러의 소자 가 특정 패턴으로 발광할 수도 있다. 발광부는 단말기나 서버의 제어 신호에 따라 사용자의 안약 투약 상황에 따라 특정 패턴으로 발 광하도록 각 컬러의 소자가 순서에 따라 발광할 수도 있다. 출력부는 이미지를 출력할 수 있는 디스플레이나 사운드를 출력할 수 있는 스피커 중 적어도 하나를 포함 할 수 있다. 편의상, 본 개시에서 출력부는 스피커를 예로 하여 설명한다. 한편, 출력부는 반드시 필수적인 구성은 아니어서, 연동하여 사운드를 출력할 수 있는 외부 기기로 대체되 거나 함께 동작할 수 있다. 이러한 외부 기기에는 인공지능 스피커, 외부 스피커, 사용자의 스마트폰과 같은 단 말기 등이 포함될 수 있다. 제어부는 프로세서의 각 구성요소의 동작을 제어할 수 있다. 제어부는 사용자의 상태를 센싱하기 위해 필요한 인공지능 엔진(미도시)를 더 포함할 수 있다. 도 2 내지 3에서, 메모리(160, 260)는 플래시 메모리 타입(flash memory type), 하드디스크 타입(hard disk type), SSD 타입(Solid State Disk type), SDD 타입(Silicon Disk Drive type), 멀티미디어 카드 마이크로 타 입(multimedia card micro type), 카드 타입의 메모리(예를 들어 SD 또는 XD 메모리 등), 램(random access memory; RAM), SRAM(static random access memory), 롬(read-only memory; ROM), EEPROM(electrically erasable programmable read-only memory), PROM(programmable read-only memory), 자기 메모리, 자기 디스크 및 광디스크 중 적어도 하나의 타입의 저장매체를 포함할 수 있다. 도 2 내지 3에서, 메모리(160, 260)는 편의상 1개만 도시하였으나, 이에 한정되는 것은 아니며, 복수 개일 수 있다. 도 2 내지 3에서, 메모리(160, 260)는 편의상 단말기와 스마트 안대에 내장된 형태로 도시하고 설명 하였으나, 이에 한정되는 것은 아니다. 예컨대, 도 2 내지 3에서, 메모리(160, 260)는 외부 또는 원격에 위치한 서버 형태로 구현될 수도 있다. 도 2 내지 도 3에서 메모리와 프로세서는 각각 별개의 칩으로 구현될 수 있다. 또는, 메모리와 프로세서는 단일 칩으로 구현될 수도 있다. 도 2 내지 도 3에 도시된 구성 요소들의 성능에 대응하여 적어도 하나의 구성요소가 추가되거나 삭제될 수 있다. 또한, 구성 요소들의 상호 위치는 시스템의 성능 또는 구조에 대응하여 변경될 수 있다는 것은 당해 기술 분야에서 통상의 지식을 가진 자에게 용이하게 이해될 것이다. 한편, 도 2 내지 도 3에서 도시된 각각의 구성요소는 소프트웨어 및/또는 Field Programmable Gate Array (FPGA) 및 주문형 반도체(ASIC, Application Specific Integrated Circuit)와 같은 하드웨어 구성요소를 의미 한다. 도 4는 본 개시의 일실시예에 따른 적어도 하나의 활성화 영역이 포함된 스마트 센서를 설명하기 위해 도시한 도면이다. 도 5는 도 4의 각 활성화 영역의 구성을 설명하기 위해 도시한 도면이다. 도 4를 참조하면, 본 개시에 따른 스마트 안대는, 안구 보호부와 지지부로 구성될 수 있다. 안구 보호부는 사용자의 적어도 하나의 안구를 덮도록 소정 형상으로 형성될 수 있다. 여기서, 소정 형상은 통 상 안경 형태처럼 원형이나 타원형, 다각형 형태일 수 있으나, 이에 한정되는 것은 아니다. 안구 보호부는 사용자의 안구 전면에 위치한 내면의 적어도 일부에는 면과 같은 소재로 구성된 덮개가 구비될 수 있다. 지지부는 안구 보호부가 제 기능을 수행할 수 있도록 지지할 수 있다. 지지부는 안구 보호부가 사용자의 신체에 부착되거나 소정 이격 거리에서 고정되도록 지지하는 구조를 가질 수 있다. 이를 위해 지지부는 스트랩(strap), 밴드(band) 등 다양한 형태일 수 있다. 본 개시에 따른 지지부는 전통적인 지지부와 같이 사용자의 신체 일부, 즉 귀에 감기어 스마트 안대가 안 구의 전면에 위치하여 안구를 보호하도록 지지한다. 편의상, 도 4에서는 복수의 활성화 영역(active area)을 표시하였다. 활성화 영역이란 본 개시에 따른 스마트 안대의 센서부, 발광부 및 출력부 중 적어도 하나가 위치할 수 있 는 피지컬 영역을 나타낼 수 있다. 도 4를 참조하면, 제1 영역(410, 420)은 스마트 안대의 최외곽 일단에 위치할 수 있다. 제1 영역(410, 420)은 스마트 안대의 최외곽 일단에서 각각 연장된 영역을 타낼 수 있다. 제1 영역(410, 420)은 사용자가 스마트 안대를 착용하는 경우에, 사용자의 관자놀이나 눈썹 윗 부분에 해 당할 수 있다. 제1 영역(410, 420)은 스마트 안대의 최외곽 라인을 따라서 위치가 이동될 수 있다. 제2 영역은 사용자의 신체부위, 즉 코의 상부에 해당하는 영역일 수 있다. 제3 영역(440, 450)은 전면에서 바라볼 때, 사용자의 안구가 위치한 영역에 상응하는 위치의 영역을 나타낼 수 있다. 도 5를 참조하면, 각 활성화 영역의 일 구성 내지 조합이 개시되었다. 설명의 편의상, 도 5에서는 하나의 활성화 영역에는 발광부, 센서부 및 출력부가 모두 구비되는 것을 예로 하여 설명하였다. 다만, 본 개시가 이에 한정되는 것은 아니다. 실시 예에 따라서, 출력부는 제1 영역(410, 420)에, 센서부는 제2 영역에, 그리고 발광부는 제3 영역(440, 450)에 각각 분산되어 배치될 수도 있다. 안구 보호부는, 사용자의 안면 형상을 스캔하고, 스캔된 안면 형상 데이터에 기반하여 도 2의 안대 제조 장치 에 의해 제작될 수 있다. 이러한 안대 제조 장치는 3D 프린터일 수 있다. 안구 보호부의 형상, 두께 등은 스캔된 사용자의 안면 형상 데이터에 의해 결정될 수 있다. 안구 보호부에 장착되는 센서부, 발광부, 및 출력부 중 적어도 하나의 개수, 위치, 그 조합 등은 안구 보호부의 형상이나 두께 또는 스캔된 사용자의 안면 형상 데이터에 의해 결정될 수 있다. 도 4 및 5를 참조하면, 스마트 안대는 안약 점안 상황을 사용자(환자) 및 보호자에게 함께 안내할 수 있다. 이 때, 스마트 안대는 안내를 위해 청각 정보와 시각 정보를 함께 활용할 수 있다. 예를 들어, 스마트 안대는 출력부를 통해 안약 점안 알림을 사운드로 출력할 수 있다. 한편, 스마트 안대는 발광부를 통해 소정 발광 패턴 출력을 통해 안약 점안 알림을 인지할 수 있도록 제공할 수 있 다. 또한, 스마트 안대가 제공하는 사운드와 발광 패턴은 서로 연동되며 상황에 따라 변동될 수 있다. 예를 들 어, 안약 점안 알림 횟수가 증가하거나 안약 점안 시점이 임박할수록 사운드의 강도가 세지거나 발광 패턴이 달 라질 수 있다. 이를 통해, 사용자와 보호자는 즉각적이고 직관적으로 안약 점안 상황을 인지할 수 있어, 안약 점안 누락 등이 최소화될 수 있다. 한편, 스마트 안대와 통신하는 단말기에서 실행되는 어플리케이션은 텍스트, 오디오, 이미지, 동영상 형태로 안약 점안 알림이나 상황을 고지하거나 사운드 패턴이나 진동 패턴을 통해 안약 점안 알림이나 상황을 고지할 수도 있다. 이를 통해, 사용자(환자)와 보호자 모두 안약 점안 상황을 인지할 수도 있다. 전술한 도 2의 단말기의 스마트 안대에 대한 구체적인 동작 제어 내용을 도 6 내지 7을 참조하여, 상 세하게 설명한다. 도 6과 7은 본 개시에 따른 스마트 안대 동작 제어 방법을 설명하기 위해 도시한 순서도이다. S110 동작에서, 단말기는 스마트 안대로부터 사용자의 투약 로그 정보를 획득할 수 있다. S120 동작에서, 단말기는 획득한 스마트 안대의 사용자 투약 로그 정보를 분석할 수 있다. S130 동작에서, 단말기는 S120 동작에서 분석한 사용자의 투약 로그 정보에 기초하여, 다음 투약 시간이 도달 여부를 판단할 수 있다. S140 동작에서, 단말기는 S130 동작에서 판단 결과에 따라 사용자의 다음 투약 시간이 도달하였으면, 투약 안내 신호를 생성하여 스마트 안대로 전송할 수 있다. 반면, 단말기는 S130 동작에서 판단 결과에 따라 사용자의 다음 투약 시간이 도달하지 않았으면, 도 7과 같이 동작하거나 새로운 투약 로그 정보를 획득할 수 있다. 도 7은 도 6의 상세 프로세스일 수도 있고, 별개의 프로세스일 수도 있다. 도 7에서 S110-S140 동작은 전술한 도 6과 동일한 바, 해당 내용을 원용하고 여기서 중복 설명은 생략한다. 단말기는 S130 동작에서 판단 결과 만약 다음 투약 시간 도달한 것으로 판단되면, 전술한 바와 같이 투약 안내 신호를 생성하여 스마트 안대로 전송할 수 있다(S140, 도 7). 반면, 단말기는 S130 동작에서 판단 결과 만약 다음 투약 시간이 미도래한 것으로 판단되면, 다음과 같은 프로세스를 수행할 수 있다. S210 동작에서, 단말기는 다음 투약 시간이 아직 도래하진 않았으나 그 때까지 남은 시간이 제1 임계 시간 이내인지 판단할 수 있다. S220 동작에서, 단말기는 S210 동작 판단 결과 만약, 다음 투약 시간이 아직 도래하진 않았으나 그 때까지 남은 시간이 제1 임계 시간 이내이면, 제1 투약 안내 신호를 생성하여 스마트 안대로 전송할 수 있다. S230 동작에서, 단말기는 S210 동작 판단 결과 만약, 다음 투약 시간이 아직 도래하진 않았으나 그 때까지 남은 시간이 제1 임계 시간 이내가 아니면, 다시 제n 임계 시간 이내인지 판단할 수 있다. S240 동작에서, 단말기는 S230 동작 판단 결과 만약, 다음 투약 시간이 아직 도래하진 않았으나 그 때까지 남은 시간이 제n 임계 시간 이내로 판단되면, 제n 투약 안내 신호를 생성하여 스마트 안대로 전송할 수 있 다. 단말기는 S230 동작 판단 결과 만약, 다음 투약 시간이 아직 도래하진 않았으나 그 때까지 남은 시간이 제 n 임계 시간 이내가 아닌 것으로 판단되는 경우에는, 새로운 투약 로그 정보를 획득할 수 있다. 투약 안내 신호의 구분을 위하여, 도 7에 도시된 바와 달리, S140 동작의 투약 안내 신호를 제1 투약 안내 신호, S220 동작의 투약 안내 신호를 제2 투약 안내 신호 등으로 표현할 수도 있다. 이하에서는, 투약 안내 신호 내지 가이드에 대해 보다 상세히 설명한다. 본 개시에서 단말기에서 스마트 안대의 동작을 제어하는 단계는, 판단 결과 사용자의 안약 투약 시간 이 도과 여부에 따라 크게 구분될 수 있다. 단말기에서 스마트 안대의 동작을 제어하는 단계는, 판단 결과 사용자의 안약 투약 시간이 도과한 경 우에는, 스마트 안대에 포함된 발광부가 제1 컬러로 발광되도록 제어할 수 있다. 단말기에서 스마트 안대의 동작을 제어하는 단계는, 판단 결과 사용자의 안약 투약 시간이 도과한 경 우에는, 스마트 안대에서 사운드를 출력하도록 제어할 수 있다. 단말기에서 스마트 안대의 동작을 제어하는 단계는, 판단 또는 분석 결과 사용자의 안약 투약 시간이 도과 다음 안약 투약 시간이 도과하지 않은 경우, 다음 안약 투약 시간까지 제1 임계 시간 미만의 시간이 남았 는지 판단하는 동작을 더 수행할 수 있다. 판단 결과, 다음 안약 투약 시간까지 제1 임계 시간 미만의 시간이 남은 경우에는, 스마트 안대의 발광부 가 제2 컬러로 발광하도록 제어할 수 있다. 분석 결과 다음 안약 투약 시간이 도과하지 않았으나 다음 안약 투약 시간까지 제1 임계 시간 이상 제2 임계 시 간 미만의 시간이 남았는지 판단하는 동작을 더 수행할 수 있다. 분석 결과 다음 안약 투약 시간이 도과하지 않았으나 다음 안약 투약 시간까지 제1 임계 시간 이상 제2 임계 시 간 미만의 시간이 남은 경우에는, 단말기는 스마트 안대의 발광부가 제3 컬러로 발광하도록 제어할 수 있다. 상기에서, 제1 컬러는 빨강(RG), 제2 컬러는 파랑(B) 그리고 제3 컬러는 녹색(G)일 수 있다. 다만, 이에 한정되 는 것은 아니다. 본 개시에서, 사용자의 투약 로그 정보는 기본적으로 사용자가 안약 점안 후에 스마트 안대를 착용하고 터 치 센서를 터치함으로써 획득될 수 있다. 사용자가 터치 센서 터치를 깜빡할 수도 있다. 따라서, 단말기는 사용자가 스마트 안대를 착용한 것 이 감지되면, 투약 여부에 대한 정보 입력 즉, 터치 센서 터치 유무에 대한 안내 내지 가이드 정보를 제공할 수 있다. 이러한 안내 내지 가이드 정보는 컬러나 사운드와 같은 형태로 스마트 안대를 통해 출력될 수 있다. 따라서, 스마트 안대는 사용자가 착용한 것이 감지되면, 투약 여부에 대한 정보 입력 즉, 터치 센서 터치 유무에 대한 안내 내지 가이드 정보를 제공할 수 있다. 이러한 안내 내지 가이드 정보는 컬러나 사운드와 같은 형태로 제공될 수 있다. 단말기 및/또는 스마트 안대는 사용자의 안약 투약 시점을 기본적으로 사용자가 터치 센서를 터치한 시점으로 판단할 수 있다. 다만, 사용자의 안약 투약 시점과 터치 센서 터치 시점에는 시간 차가 발생할 수 있다. 따라서, 이러한 시간 차를 고려하여, 전술한 임계 시간의 간격이나 길이를 결정할 수 있다. 사용자의 안약 투약에 따른 터치 센서 터치 시점이 매번 일정한 간격이면, 그대로 투약 시점으로 허용할 수 있 다. 이 경우, 일정한 간격이라 함은 미리 정한 시간 이내의 범위도 포함할 수 있다. 다만, 사용자의 안약 투약에 따른 터치 센서 터치 시점이 매번 일정한 간격이 아닌 경우에는, 단말기 및/ 또는 스마트 안대는 전술한 투약 안내 신호의 정보의 강도를 다르게 제어할 수 있다. 예를 들어, 사운드를 더 크게하거나 투약 안내 또는 가이드의 횟수를 증가시킬 수도 있다. 단말기 및/또는 스마트 안대는 만약 사용자가 터치 센서가 구비된 활성화 영역 이외의 비활성화 영역 을 터치하는 것이 감지되면, 다음 투약 시간까지 남은 시간을 산출할 수 있다. 이는 비활성화 영역을 예를 들어, 터치하는 것이 스마트 안대의 착용 해제일 수 있기 때문에, 다음 투약 시간에 대한 가이드를 제공하 기 위함일 수 있다. 단말기 및/또는 스마트 안대는 산출된 다음 투약 시간까지 남은 시간에 따라서, 적절한 투약 시간 안 내 가이드를 제공하거나 예정된 투약 안내 가이드의 내용을 상이하게 제어할 수 있다. 단말기 및/또는 스마트 안대는 사용자가 투약 예상 시간 경과에도 불구 안대를 착용하지 않는 경우에 는, 스마트 안대 및 사용자의 등록된 단말기(미도시)를 통해 스마트 안대의 착용 가이드를 제공할 수 있다. 단말기 및/또는 스마트 안대는 사용자가 스마트 안대를 착용하는 중에 이벤트 발생 신호가 감지 되면, 감지된 이벤트에 따라 다음 투약 시간 안내 가이드를 제공할 수 있다. 이 때, 이벤트 발생 신호에는 예를 들어, 스마트 안대 내부 또는 외부에 이물질이 감지되는 경우 등이 포함될 수 있다. 단말기 및/또는 스마트 안대는 스마트 안대를 착용한 사용자가 위치한 공간에 따라 투약 안내 가이드를 상이하게 제어할 수 있다. 예를 들어, 스마트 안대를 착용한 사용자가 위치한 공간이 집과 같은 프라이빗한 공간에 해당하는 경우에는, 안내 가이드의 레벨을 최대로 할 수 있다. 그렇지 않은 경우에는, 식별 되는 공간의 종류 내지 타입에 따라서 레벨을 결정(중간 또는 최하)하여, 그에 따라 안내 가이드의 레벨을 조절 되도록 제어할 수 있다. 한편, 단말기 및/또는 스마트 안대는 스마트 안대를 착용한 사용자가 위치한 공간에 따라 투약 안내 가이드를 출력하는 방식을 상이하게 제어할 수 있다. 예를 들어, 전술한 바와 같이, 프라이빗 공간에 사용 자 위치한 경우에는, 반드시 스마트 안대에 한정되지 않고 연동 가능한 다양한 외부 기기(예를 들어, TV, 외부 스피커 등)을 통하거나 그와 함께 투약 안내 가이드를 제공할 수 있다. 단말기 및/또는 스마트 안대는 현재 시각 정보에 기초하여 투약 안내 가이드를 상이하게 제어할 수 있다. 예를 들어, 현재 시각이 낮 시간인 경우와 밤 늦은 시간에 투약 안내 가이드를 동일한 정도로 제공하는 경우, 사용자 뿐만 아니라 제3 자에게도 불편함을 줄 수 있으므로, 가이드 레벨을 조절하여 제공하는 것이 바람 직할 수 있다. 본 개시는 전술한 둘 이상의 실시예들의 조합된 형태로도 투약 안내 가이드를 제공할 수 있다. 한편, 개시된 실시예들은 컴퓨터에 의해 실행 가능한 명령어를 저장하는 기록매체의 형태로 구현될 수 있다. 명 령어는 프로그램 코드의 형태로 저장될 수 있으며, 프로세서에 의해 실행되었을 때, 프로그램 모듈을 생성하여 개시된 실시예들의 동작을 수행할 수 있다. 기록매체는 컴퓨터로 읽을 수 있는 기록매체로 구현될 수 있다. 컴퓨터가 읽을 수 있는 기록매체로는 컴퓨터에 의하여 해독될 수 있는 명령어가 저장된 모든 종류의 기록 매체 를 포함한다. 예를 들어, ROM(Read Only Memory), RAM(Random Access Memory), 자기 테이프, 자기 디스크, 플 래쉬 메모리, 광 데이터 저장장치 등이 있을 수 있다."}
{"patent_id": "10-2023-0076623", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "이상에서와 같이 첨부된 도면을 참조하여 개시된 실시예들을 설명하였다. 본 개시가 속하는 기술분야에서 통상 의 지식을 가진 자는 본 개시의 기술적 사상이나 필수적인 특징을 변경하지 않고도, 개시된 실시예들과 다른 형 태로 본 개시가 실시될 수 있음을 이해할 것이다. 개시된 실시예들은 예시적인 것이며, 한정적으로 해석되어서 는 안 된다."}
{"patent_id": "10-2023-0076623", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 개시의 일실시예에 따른 사물 인터넷이 접목된 스마트 안대가 포함된 서비스 시스템의 개략도이다. 도 2는 도 1의 단말기의 구성 블록도이다. 도 3은 도 1의 스마트 안대의 구성 블록도이다. 도 4는 본 개시의 일실시예에 따른 적어도 하나의 활성화 영역이 포함된 스마트 센서를 설명하기 위해 도시한 도면이다. 도 5는 도 4의 각 활성화 영역의 구성을 설명하기 위해 도시한 도면이다. 도 6과 7은 본 개시에 따른 병리 슬라이드 건조 최적화 방법을 설명하기 위해 도시한 순서도이다."}
