{"patent_id": "10-2021-0167756", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2022-0005416", "출원번호": "10-2021-0167756", "발명의 명칭": "다항 관계 생성 모델의 트레이닝 방법, 장치, 전자 기기 및 매체", "출원인": "베이징 바이두 넷컴 사이언스 테크놀로지 컴퍼니", "발명자": "왕, 취엔"}}
{"patent_id": "10-2021-0167756", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "다항 관계 생성 모델의 트레이닝 방법에 있어서,복수의 지식 엔트리 텍스트를 획득하는 단계;상기 지식 엔트리 텍스트에 대해 의미 분석을 수행하여, 대응되는 복수의 엔티티 및 의미 정보를 획득하는단계;상기 엔티티 및 상기 의미 정보에 따라 이종 그래프를 구축하는 단계; 및,상기 이종 그래프에 따라 초기 인공 지능 네트워크 모델을 트레이닝하여, 다항 관계 생성 모델을 획득하는단계;를 포함하는,것을 특징으로 하는 다항 관계 생성 모델의 트레이닝 방법."}
{"patent_id": "10-2021-0167756", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 지식 엔트리 텍스트에 대해 의미 분석을 수행하여, 대응되는 복수의 엔티티 및 의미 정보를 획득하는 단계는,상기 지식 엔트리 텍스트에 대해 의미 분석을 수행하여, 상기 지식 엔트리 텍스트 중 상기 복수의 엔티티를 획득하는 단계;상기 복수의 엔티티로부터 메인 속성 및 보조 속성을 결정하는 단계;상기 메인 속성에 대응하는 메인 콘텐츠와, 상기 보조 속성에 대응하는 보조 콘텐츠를 결정하는 단계; 및,상기 메인 콘텐츠 및 상기 보조 콘텐츠를 상기 의미 정보로 하는 단계;를 포함하는,것을 특징으로 하는 다항 관계 생성 모델의 트레이닝 방법."}
{"patent_id": "10-2021-0167756", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,상기 엔티티 및 상기 의미 정보에 따라 이종 그래프를 구축하는 단계는,상기 엔티티, 상기 메인 속성, 상기 보조 속성, 상기 메인 콘텐츠, 및 상기 보조 콘텐츠를 각각 대응되는 노드에 매핑하는 단계;상기 엔티티, 상기 메인 속성, 상기 보조 속성, 상기 메인 콘텐츠, 및 상기 보조 콘텐츠의 품사를 각각 사용하여, 대응 노드의 품사를 설명하는 단계;대응 관계를 가진 노드 사이에 에지를 구축하는 단계;상기 에지로 연결된 노드에 대응하는 품사에 따라, 상기 에지의 품사 유형을 형성하는 단계; 및,상기 품사 유형으로 상기 에지에 라벨링하여, 상기 노드, 상기 에지, 및 상기 에지의 라벨링에 따라 상기 이종그래프를 구축하는 단계;를 포함하는,것을 특징으로 하는 다항 관계 생성 모델의 트레이닝 방법."}
{"patent_id": "10-2021-0167756", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서,상기 초기 인공 지능 네트워크 모델은 입력 표현 계층, 그래프 주의 계층, 및 선형 예측 계층을 포함하되, 상기공개특허 10-2022-0005416-3-이종 그래프에 따라 초기 인공 지능 네트워크 모델을 트레이닝하여, 다항 관계 생성 모델을 획득하는 단계는,상기 이종 그래프를 상기 입력 표현 계층에 입력하여, 상기 입력 표현 계층에 의해 출력된 상기 노드에 대응하는 벡터 표현을 획득하는 단계 - 상기 벡터 표현은 상기 노드에 대응하는 콘텐츠 사이의 의미 관계를 설명함 -;상기 이종 그래프를 상기 그래프 주의 계층에 입력하여, 상기 그래프 주의 계층에 의해 출력된 상기 에지의 품사 유형에 대응하는 적응 인자를 획득하는 단계;상기 벡터 표현 및 상기 적응 인자에 따라 상기 선형 예측 계층에 입력하여, 상기 선형 예측 계층에 의해 출력된 예측 다항 관계를 획득하는 단계; 및,상기 예측 다항 관계 및 라벨링 다항 관계에 따라 상기 초기 인공 지능 네트워크 모델을 트레이닝하여, 다항 관계 생성 모델을 획득하는 단계;를 포함하는,것을 특징으로 하는 다항 관계 생성 모델의 트레이닝 방법."}
{"patent_id": "10-2021-0167756", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서,상기 이종 그래프를 상기 그래프 주의 계층에 입력하여, 상기 그래프 주의 계층에 의해 출력된 상기 에지의 품사 유형에 대응하는 적응 인자를 획득하는 단계 이후에,상기 적응 인자에 따라 상기 그래프 주의 계층의 주의 강도 값을 조정하는 단계;를 더 포함하는,것을 특징으로 하는 다항 관계 생성 모델의 트레이닝 방법."}
{"patent_id": "10-2021-0167756", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제4항에 있어서,상기 예측 다항 관계 및 라벨링 다항 관계에 따라 상기 초기 인공 지능 네트워크 모델을 트레이닝하여, 다항 관계 생성 모델을 획득하는 단계는,상기 예측 다항 관계와 라벨링 다항 관계 사이의 손실값을 결정하는 단계; 및,상기 손실값이 설정된 손실 임계값을 만족할 경우, 트레이닝하여 획득한 인공 지능 네트워크 모델을 상기 다항관계 생성 모델로 하는 단계;를 포함하는,것을 특징으로 하는 다항 관계 생성 모델의 트레이닝 방법."}
{"patent_id": "10-2021-0167756", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "다항 관계 생성 모델의 트레이닝 장치에 있어서,복수의 지식 엔트리 텍스트를 획득하는 획득 모듈;상기 지식 엔트리 텍스트에 대해 의미 분석을 수행하여, 대응되는 복수의 엔티티 및 의미 정보를 획득하는 해석모듈;상기 엔티티 및 상기 의미 정보에 따라 이종 그래프를 구축하는 구축 모듈; 및,상기 이종 그래프에 따라 초기 인공 지능 네트워크 모델을 트레이닝하여, 다항 관계 생성 모델을 획득하는 트레이닝 모듈;을 포함하는,것을 특징으로 하는 다항 관계 생성 모델의 트레이닝 장치."}
{"patent_id": "10-2021-0167756", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서,상기 해석 모듈은 구체적으로,상기 지식 엔트리 텍스트에 대해 의미 분석을 수행하여, 상기 지식 엔트리 텍스트 중 상기 복수의 엔티티를 획공개특허 10-2022-0005416-4-득하고;상기 복수의 엔티티로부터 메인 속성 및 보조 속성을 결정하며;상기 메인 속성에 대응하는 메인 콘텐츠와, 상기 보조 속성에 대응하는 보조 콘텐츠를 결정하고;상기 메인 콘텐츠 및 상기 보조 콘텐츠를 상기 의미 정보로 하는,것을 특징으로 하는 다항 관계 생성 모델의 트레이닝 장치."}
{"patent_id": "10-2021-0167756", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서,상기 구축 모듈은,상기 엔티티, 상기 메인 속성, 상기 보조 속성, 상기 메인 콘텐츠, 및 사기 보조 콘텐츠를 각각 대응되는 노드에 매핑하고, 상기 엔티티, 상기 메인 속성, 상기 보조 속성, 상기 메인 콘텐츠, 및 상기 보조 콘텐츠의 품사를각각 사용하여 해당하는 노드의 품사를 설명하는 매핑 서브 모듈;대응 관계를 가진 노드 사이에 에지를 구축하는 제1 구축 서브 모듈;상기 에지에 연결되는 노드에 대응하는 품사에 따라, 상기 에지의 품사 유형을 형성하는 생성 서브 모듈; 및,상기 품사 유형을 사용하여 상기 에지에 대해 라벨링하여, 상기 노드, 상기 에지, 및 상기 에지의 라벨링에 따라 상기 이종 그래프를 구축하는 제2 구축 서브 모듈을 포함하는,것을 특징으로 하는 다항 관계 생성 모델의 트레이닝 장치."}
{"patent_id": "10-2021-0167756", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9항에 있어서,상기 초기 인공 지능 네트워크 모델은 입력 표현 계층, 그래프 주의 계층, 및 선형 예측 계층을 포함하되, 상기트레이닝 모듈은 구체적으로,상기 이종 그래프를 상기 입력 표현 계층에 입력하여, 상기 입력 표현 계층에 의해 출력된 상기 노드에 대응하는 벡터 표현을 획득하되, 상기 벡터 표현은 상기 노드에 대응하는 콘텐츠 사이의 의미 관계를 설명하고;상기 이종 그래프를 상기 그래프 주의 계층에 입력하여, 상기 그래프 주의 계층에 의해 출력된 상기 에지의 품사 유형에 대응하는 적응 인자를 획득하며;상기 벡터 표현 및 상기 적응 인자에 따라 상기 선형 예측 계층에 입력하여, 상기 선형 예측 계층에 의해 출력된 예측 다항 관계를 획득하고;상기 예측 다항 관계 및 라벨링 다항 관계에 따라 상기 초기 인공 지능 네트워크 모델을 트레이닝하여, 다항 관계 생성 모델을 획득하는,것을 특징으로 하는 다항 관계 생성 모델의 트레이닝 장치."}
{"patent_id": "10-2021-0167756", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제10항에 있어서,상기 트레이닝 모듈은 구체적으로,상기 적응 인자에 따라 상기 그래프 주의 계층의 주의 강도 값을 조정하는,것을 특징으로 하는 다항 관계 생성 모델의 트레이닝 장치."}
{"patent_id": "10-2021-0167756", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제10항에 있어서,상기 트레이닝 모듈은 구체적으로,공개특허 10-2022-0005416-5-상기 예측 다항 관계와 라벨링 다항 관계 사이의 손실값을 결정하고; 상기 손실값이 설정된 손실 임계값을 만족할 경우, 트레이닝하여 획득한 인공 지능 네트워크 모델을 상기 다항관계 생성 모델로 하는,것을 특징으로 하는 다항 관계 생성 모델의 트레이닝 장치."}
{"patent_id": "10-2021-0167756", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "전자 기기에 있어서,적어도 하나의 프로세서; 및, 상기 적어도 하나의 프로세서와 통신 가능하게 연결되는 메모리;를 포함하되,상기 메모리에는 상기 적어도 하나의 프로세서에 의해 실행 가능한 명령이 저장되어 있고, 상기 명령은 상기 적어도 하나의 프로세서에 의해 실행되어, 상기 적어도 하나의 프로세서가 제1항 내지 제6항 중 어느 한 항에 따른 방법을 수행하도록 하는,것을 특징으로 하는 전자 기기."}
{"patent_id": "10-2021-0167756", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "컴퓨터 명령이 저장되어 있는 비일시적 컴퓨터 판독 가능 저장 매체에 있어서, 상기 컴퓨터 명령은 상기 컴퓨터가 제1항 내지 제6항 중 어느 한 항에 따른 방법을 수행하도록 하는,것을 특징으로 하는 비일시적 컴퓨터 판독 가능 저장 매체."}
{"patent_id": "10-2021-0167756", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "컴퓨터 판독 가능 저장 매체에 저장되어 있는 컴퓨터 프로그램에 있어서,상기 컴퓨터 프로그램중의 명령이 실행될 경우, 제1항 내지 제6항 중 어느 한 항에 따른 방법이 실행되는, 것을 특징으로 하는 컴퓨터 판독 가능 저장 매체에 저장되어 있는 컴퓨터 프로그램."}
{"patent_id": "10-2021-0167756", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 출원은 다항 관계 생성 모델의 트레이닝 방법, 장치, 전자 기기 및 매체를 개시하며, 컴퓨터"}
{"patent_id": "10-2021-0167756", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "에 관 한 것으로, 구체적으로 자연어 처리, 딥 러닝, 지식 그래프 등 인공 지능 기술 분야에 관한 것이다. 구체적인 구 현 방식은, 복수의 지식 엔트리 텍스트를 획득하고; 지식 엔트리 텍스트에 대해 의미 분석을 수행하여, 대응되는 복수의 엔티티 및 의미 정보를 획득하며; 엔티티 및 의미 정보에 따라 이종 그래프를 구축하고; 이종 그래프에 따라 초기 인공 지능 네트워크 모델을 트레이닝하여, 다항 관계 생성 모델을 획득하여, 다항 지식 엔트리의 의미 완전성을 더 많이 학습할 수 있음으로써, 다항 관계 생성 모듈의 다항 관계 표현의 정확성을 효과적으로 향상시 키고, 보다 더 정확한 다항 지식 추론을 구현한다. 대 표 도 - 도1"}
{"patent_id": "10-2021-0167756", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 2, "content": "공개특허10-2022-0005416 CPC특허분류 G06F 40/30 (2020.01) G06N 5/022 (2019.01) 발명자 류, 야쮜엔 중국, 베이징 100085, 하이뎬 디스트릭트, 샹디 1 0번가, 10, 바이두 캠퍼스 2층주, 용 중국, 베이징 100085, 하이뎬 디스트릭트, 샹디 1 0번가, 10, 바이두 캠퍼스 2층명 세 서 청구범위 청구항 1 다항 관계 생성 모델의 트레이닝 방법에 있어서, 복수의 지식 엔트리 텍스트를 획득하는 단계; 상기 지식 엔트리 텍스트에 대해 의미 분석을 수행하여, 대응되는 복수의 엔티티 및 의미 정보를 획득하는 단계; 상기 엔티티 및 상기 의미 정보에 따라 이종 그래프를 구축하는 단계; 및, 상기 이종 그래프에 따라 초기 인공 지능 네트워크 모델을 트레이닝하여, 다항 관계 생성 모델을 획득하는 단계;를 포함하는, 것을 특징으로 하는 다항 관계 생성 모델의 트레이닝 방법. 청구항 2 제1항에 있어서, 상기 지식 엔트리 텍스트에 대해 의미 분석을 수행하여, 대응되는 복수의 엔티티 및 의미 정보를 획득하는 단계 는, 상기 지식 엔트리 텍스트에 대해 의미 분석을 수행하여, 상기 지식 엔트리 텍스트 중 상기 복수의 엔티티를 획 득하는 단계; 상기 복수의 엔티티로부터 메인 속성 및 보조 속성을 결정하는 단계; 상기 메인 속성에 대응하는 메인 콘텐츠와, 상기 보조 속성에 대응하는 보조 콘텐츠를 결정하는 단계; 및, 상기 메인 콘텐츠 및 상기 보조 콘텐츠를 상기 의미 정보로 하는 단계;를 포함하는, 것을 특징으로 하는 다항 관계 생성 모델의 트레이닝 방법. 청구항 3 제2항에 있어서, 상기 엔티티 및 상기 의미 정보에 따라 이종 그래프를 구축하는 단계는, 상기 엔티티, 상기 메인 속성, 상기 보조 속성, 상기 메인 콘텐츠, 및 상기 보조 콘텐츠를 각각 대응되는 노드 에 매핑하는 단계; 상기 엔티티, 상기 메인 속성, 상기 보조 속성, 상기 메인 콘텐츠, 및 상기 보조 콘텐츠의 품사를 각각 사용하 여, 대응 노드의 품사를 설명하는 단계; 대응 관계를 가진 노드 사이에 에지를 구축하는 단계; 상기 에지로 연결된 노드에 대응하는 품사에 따라, 상기 에지의 품사 유형을 형성하는 단계; 및, 상기 품사 유형으로 상기 에지에 라벨링하여, 상기 노드, 상기 에지, 및 상기 에지의 라벨링에 따라 상기 이종 그래프를 구축하는 단계;를 포함하는, 것을 특징으로 하는 다항 관계 생성 모델의 트레이닝 방법. 청구항 4 제3항에 있어서, 상기 초기 인공 지능 네트워크 모델은 입력 표현 계층, 그래프 주의 계층, 및 선형 예측 계층을 포함하되, 상기이종 그래프에 따라 초기 인공 지능 네트워크 모델을 트레이닝하여, 다항 관계 생성 모델을 획득하는 단계는, 상기 이종 그래프를 상기 입력 표현 계층에 입력하여, 상기 입력 표현 계층에 의해 출력된 상기 노드에 대응하 는 벡터 표현을 획득하는 단계 - 상기 벡터 표현은 상기 노드에 대응하는 콘텐츠 사이의 의미 관계를 설명함 - ; 상기 이종 그래프를 상기 그래프 주의 계층에 입력하여, 상기 그래프 주의 계층에 의해 출력된 상기 에지의 품 사 유형에 대응하는 적응 인자를 획득하는 단계; 상기 벡터 표현 및 상기 적응 인자에 따라 상기 선형 예측 계층에 입력하여, 상기 선형 예측 계층에 의해 출력 된 예측 다항 관계를 획득하는 단계; 및, 상기 예측 다항 관계 및 라벨링 다항 관계에 따라 상기 초기 인공 지능 네트워크 모델을 트레이닝하여, 다항 관 계 생성 모델을 획득하는 단계;를 포함하는, 것을 특징으로 하는 다항 관계 생성 모델의 트레이닝 방법. 청구항 5 제4항에 있어서, 상기 이종 그래프를 상기 그래프 주의 계층에 입력하여, 상기 그래프 주의 계층에 의해 출력된 상기 에지의 품 사 유형에 대응하는 적응 인자를 획득하는 단계 이후에, 상기 적응 인자에 따라 상기 그래프 주의 계층의 주의 강도 값을 조정하는 단계;를 더 포함하는, 것을 특징으로 하는 다항 관계 생성 모델의 트레이닝 방법. 청구항 6 제4항에 있어서, 상기 예측 다항 관계 및 라벨링 다항 관계에 따라 상기 초기 인공 지능 네트워크 모델을 트레이닝하여, 다항 관 계 생성 모델을 획득하는 단계는, 상기 예측 다항 관계와 라벨링 다항 관계 사이의 손실값을 결정하는 단계; 및, 상기 손실값이 설정된 손실 임계값을 만족할 경우, 트레이닝하여 획득한 인공 지능 네트워크 모델을 상기 다항 관계 생성 모델로 하는 단계;를 포함하는, 것을 특징으로 하는 다항 관계 생성 모델의 트레이닝 방법. 청구항 7 다항 관계 생성 모델의 트레이닝 장치에 있어서, 복수의 지식 엔트리 텍스트를 획득하는 획득 모듈; 상기 지식 엔트리 텍스트에 대해 의미 분석을 수행하여, 대응되는 복수의 엔티티 및 의미 정보를 획득하는 해석 모듈; 상기 엔티티 및 상기 의미 정보에 따라 이종 그래프를 구축하는 구축 모듈; 및, 상기 이종 그래프에 따라 초기 인공 지능 네트워크 모델을 트레이닝하여, 다항 관계 생성 모델을 획득하는 트레 이닝 모듈;을 포함하는, 것을 특징으로 하는 다항 관계 생성 모델의 트레이닝 장치. 청구항 8 제7항에 있어서, 상기 해석 모듈은 구체적으로, 상기 지식 엔트리 텍스트에 대해 의미 분석을 수행하여, 상기 지식 엔트리 텍스트 중 상기 복수의 엔티티를 획득하고; 상기 복수의 엔티티로부터 메인 속성 및 보조 속성을 결정하며; 상기 메인 속성에 대응하는 메인 콘텐츠와, 상기 보조 속성에 대응하는 보조 콘텐츠를 결정하고; 상기 메인 콘텐츠 및 상기 보조 콘텐츠를 상기 의미 정보로 하는, 것을 특징으로 하는 다항 관계 생성 모델의 트레이닝 장치. 청구항 9 제8항에 있어서, 상기 구축 모듈은, 상기 엔티티, 상기 메인 속성, 상기 보조 속성, 상기 메인 콘텐츠, 및 사기 보조 콘텐츠를 각각 대응되는 노드 에 매핑하고, 상기 엔티티, 상기 메인 속성, 상기 보조 속성, 상기 메인 콘텐츠, 및 상기 보조 콘텐츠의 품사를 각각 사용하여 해당하는 노드의 품사를 설명하는 매핑 서브 모듈; 대응 관계를 가진 노드 사이에 에지를 구축하는 제1 구축 서브 모듈; 상기 에지에 연결되는 노드에 대응하는 품사에 따라, 상기 에지의 품사 유형을 형성하는 생성 서브 모듈; 및, 상기 품사 유형을 사용하여 상기 에지에 대해 라벨링하여, 상기 노드, 상기 에지, 및 상기 에지의 라벨링에 따 라 상기 이종 그래프를 구축하는 제2 구축 서브 모듈을 포함하는, 것을 특징으로 하는 다항 관계 생성 모델의 트레이닝 장치. 청구항 10 제9항에 있어서, 상기 초기 인공 지능 네트워크 모델은 입력 표현 계층, 그래프 주의 계층, 및 선형 예측 계층을 포함하되, 상기 트레이닝 모듈은 구체적으로, 상기 이종 그래프를 상기 입력 표현 계층에 입력하여, 상기 입력 표현 계층에 의해 출력된 상기 노드에 대응하 는 벡터 표현을 획득하되, 상기 벡터 표현은 상기 노드에 대응하는 콘텐츠 사이의 의미 관계를 설명하고; 상기 이종 그래프를 상기 그래프 주의 계층에 입력하여, 상기 그래프 주의 계층에 의해 출력된 상기 에지의 품 사 유형에 대응하는 적응 인자를 획득하며; 상기 벡터 표현 및 상기 적응 인자에 따라 상기 선형 예측 계층에 입력하여, 상기 선형 예측 계층에 의해 출력 된 예측 다항 관계를 획득하고; 상기 예측 다항 관계 및 라벨링 다항 관계에 따라 상기 초기 인공 지능 네트워크 모델을 트레이닝하여, 다항 관 계 생성 모델을 획득하는, 것을 특징으로 하는 다항 관계 생성 모델의 트레이닝 장치. 청구항 11 제10항에 있어서, 상기 트레이닝 모듈은 구체적으로, 상기 적응 인자에 따라 상기 그래프 주의 계층의 주의 강도 값을 조정하는, 것을 특징으로 하는 다항 관계 생성 모델의 트레이닝 장치. 청구항 12 제10항에 있어서, 상기 트레이닝 모듈은 구체적으로,상기 예측 다항 관계와 라벨링 다항 관계 사이의 손실값을 결정하고; 상기 손실값이 설정된 손실 임계값을 만족할 경우, 트레이닝하여 획득한 인공 지능 네트워크 모델을 상기 다항 관계 생성 모델로 하는, 것을 특징으로 하는 다항 관계 생성 모델의 트레이닝 장치. 청구항 13 전자 기기에 있어서, 적어도 하나의 프로세서; 및, 상기 적어도 하나의 프로세서와 통신 가능하게 연결되는 메모리;를 포함하되, 상기 메모리에는 상기 적어도 하나의 프로세서에 의해 실행 가능한 명령이 저장되어 있고, 상기 명령은 상기 적 어도 하나의 프로세서에 의해 실행되어, 상기 적어도 하나의 프로세서가 제1항 내지 제6항 중 어느 한 항에 따 른 방법을 수행하도록 하는, 것을 특징으로 하는 전자 기기. 청구항 14 컴퓨터 명령이 저장되어 있는 비일시적 컴퓨터 판독 가능 저장 매체에 있어서, 상기 컴퓨터 명령은 상기 컴퓨터가 제1항 내지 제6항 중 어느 한 항에 따른 방법을 수행하도록 하는, 것을 특징으로 하는 비일시적 컴퓨터 판독 가능 저장 매체. 청구항 15 컴퓨터 판독 가능 저장 매체에 저장되어 있는 컴퓨터 프로그램에 있어서, 상기 컴퓨터 프로그램중의 명령이 실행될 경우, 제1항 내지 제6항 중 어느 한 항에 따른 방법이 실행되는, 것을 특징으로 하는 컴퓨터 판독 가능 저장 매체에 저장되어 있는 컴퓨터 프로그램. 발명의 설명 기 술 분 야 본 출원은 컴퓨터 기술 분야에 관한 것으로, 구체적으로 자연어 처리, 딥 러닝, 지식 그래프 등 인공 지능 기술 분야에 관한 것이며, 특히 다항 관계 생성 모델의 트레이닝 방법, 장치, 전자 기기 및 매체에 관한 것이다."}
{"patent_id": "10-2021-0167756", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "인공 지능이란 인간의 특정된 사고 과정과 지능적 행동(예를 들어, 학습, 추론, 사고, 계획 등)을 컴퓨터로 시 뮬레이션하도록 하는 것을를 연구하는 학과이며, 하드웨어 수준의 기술과 소프트웨어 수준의 기술을 모두 가지 고 있다. 인공 지능 하드웨어 기술은 일반적으로 센서, 전용 인공 지능 칩, 클라우드 컴퓨팅, 분산 스토리지 및 빅 데이터 처리와 같은 기술을 포함하고; 인공 지능 소프트웨어 기술은 주로 컴퓨터 비전 기술, 음성 인식 기술, 자연어 처리 기술 및 기계 학습/딥 러닝, 빅 데이터 처리 기술, 지식 그래프 기술 등 몇 가지 주요 방향 을 포함한다. 지식 그래프는 엔티티와 관계로 구성되고, 세계, 분야 및 언어 지식의 구조화된 지식베이스를 설명하는데 사용 되며, 일반적으로 지식 그래프는 엔티티 사이의 2항 관계를 포함하고, 지식 엔트리를 (마리 퀴리, 수상, 노벨 물리학상)과 같은 (주어, 술어, 목적어) 형태의 3항 그룹 표현으로 처리한다. 다항 관계 생성 모델의 트레이닝 방법, 장치, 전자 기기, 저장 매체 및 컴퓨터 프로그램 제품을 제공한다. 제1 양태에 따르면, 다항 관계 생성 모델의 트레이닝 방법을 제공하는바, 복수의 지식 엔트리 텍스트를 획득하 는 단계; 상기 지식 엔트리 텍스트에 대해 의미 분석을 수행하여, 대응되는 복수의 엔티티 및 의미 정보를 획득하는 단계; 상기 엔티티 및 상기 의미 정보에 따라 이종 그래프를 구축하는 단계; 및, 상기 이종 그래프에 따라 초기 인공 지능 네트워크 모델을 트레이닝하여, 다항 관계 생성 모델을 획득하는 단계;를 포함한다. 제2 양태에 따르면, 다항 관계 생성 모델의 트레이닝 장치를 제공하는바, 복수의 지식 엔트리 텍스트를 획득하 는 획득 모듈; 상기 지식 엔트리 텍스트에 대해 의미 분석을 수행하여, 대응되는 복수의 엔티티 및 의미 정보를 획득하는 해석 모듈; 상기 엔티티 및 상기 의미 정보에 따라 이종 그래프를 구축하는 구축 모듈; 및, 상기 이종 그래프에 따라 초기 인공 지능 네트워크 모델을 트레이닝하여, 다항 관계 생성 모델을 획득하는 트레이닝 모 듈;을 포함한다. 제3 양태에 따르면, 전자 기기를 제공하는바, 적어도 하나의 프로세서; 및, 상기 적어도 하나의 프로세서와 통 신 가능하게 연결되는 메모리;를 포함하되, 상기 메모리에는 상기 적어도 하나의 프로세서에 의해 실행 가능한 명령이 저장되어 있고, 상기 명령은 상기 적어도 하나의 프로세서에 의해 실행되어, 상기 적어도 하나의 프로세 서가 본 출원의 실시예에 따른 다항 관계 생성 모델의 트레이닝 방법을 수행하도록 한다. 제4 양태에 따르면, 컴퓨터 명령이 저장되어 있는 비일시적 컴퓨터 판독 가능 저장 매체를 제공하는바, 상기 컴 퓨터 명령은 상기 컴퓨터가 본 출원의 실시예에 따른 다항 관계 생성 모델의 트레이닝 방법을 수행하도록 한다. 제5 양태에 따르면, 컴퓨터 프로그램을 포함하는 컴퓨터 프로그램 제품을 제공하는바, 상기 컴퓨터 프로그램은 프로세서에 의해 실행될 경우, 본 출원의 실시예에 의해 개시된 다항 관계 생성 모델의 트레이닝 방법을 구현한 다. 제6 양태에 따르면, 컴퓨터 판독 가능 매체에 저장되어 있는 컴퓨터 프로그램을 더 제공하는바, 상기 컴퓨터 프 로그램중의 명령이 실행될 경우, 본 출원의 실시예에 따른 다항 관계 생성 모델의 트레이닝 방법이 실행된다. 본 부분에서 설명된 내용은 본 출원의 실시예의 핵심 또는 중요한 특징을 식별하기 위한 것이 아니며, 본 출원 의 범위를 한정하려는 의도도 아님을 이해해야 할 것이다. 본 출원의 다른 특징은 아래 명세서에 의해 쉽게 이 해될 것이다."}
{"patent_id": "10-2021-0167756", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "아래 첨부 도면을 결부하여 본 출원의 예시적인 실시예에 대해 설명하되, 여기에는 이해를 돕기 위한 본 출원의 실시예의 다양한 세부 사항이 포함되며, 이들은 단지 예시적인 것으로 간주되어야 한다. 따라서, 본 분야의 통 상적인 지식을 가진 자라면, 본 출원의 범위와 정신을 벗어나지 않으면서 여기에 설명되는 실시예에 대해 다양 한 변경과 수정이 이루어질 수 있음을 이해하여야 한다. 마찬가지로, 명확성과 간결성을 위하여, 공지된 기능 및 구조에 대한 설명은 아래의 설명에서 생략된다. 도 1은 본 출원의 제1 실시예에 따른 개략도이다. 설명해야 할 것은, 본 실시예의 다항 관계 생성 모델의 트레이닝 방법의 수행 주체는 다항 관계 생성 모델의 트 레이닝 장치이고, 상기 장치는 소프트웨어 및/또는 하드웨어의 방식으로 구현될 수 있으며, 상기 장치는 전자 기기에 구성될 수 있고, 전자 기기는 단말기, 서버단 등을 포함할 수 있지만 이에 한정되지 않는다.본 출원의 실시예는 자연어 처리, 딥 러닝, 지식 그래프 등 인공 지능 기술 분야에 관한 것이다. 인공 지능(Artificial Intelligence)의 영문 약어는 AI이다. 인간 지능을 시뮬레이션하고 연장 및 확장하기 위 한 이론, 방법, 기술 및 응용 시스템을 연구하고 개발하는 하나의 새로운 기술 과학이다. 딥 러닝은 샘플 데이터의 내재적 법칙과 표현 수준을 학습하는 것으로, 이러한 학습 과정에서 획득한 정보는 문 자, 이미지 및 소리 등과 같은 데이터의 해석에 대해 매우 큰 도움을 준다. 딥 러닝의 최종 목표는 기계가 인간 처럼 학습 분석 기능을 구비하여 문자, 이미지 및 소리와 같은 데이터를 인식할 수 있도록 하는 것이다. 딥 러 닝은 하나의 복잡한 기계 학습 알고리즘으로, 음성 및 이미지 인식 분야에서 달성한 효과는 종래의 관련 기술을 훨씬 능가한다. 자연어 처리(Natural Language Processing, NLP)는 자연어로 인간과 컴퓨터 간의 효과적인 통신을 수행하는 다 양한 이론 및 방법을 구현할 수 있다. 딥 러닝은 샘플 데이터의 내재적 법칙과 표현 수준을 학습하는 것으로, 이러한 학습 과정에서 획득한 정보는 문자, 이미지 및 소리 등과 같은 데이터의 해석에 대해 매우 큰 도움을 준 다. 딥 러닝의 최종 목표는 기계가 인간처럼 학습 분석 기능을 구비하여 문자, 이미지 및 소리와 같은 데이터를 인식할 수 있도록 하는 것이다. 지식 그래프는 응용 수학, 그래픽, 정보 시각화 기술, 정보 과학 등 학과의 이론과 방법을 계량학 인용 분석, 동시 발생 분석 등 방법과 결합하고, 시각화의 그래프를 사용하여 학과의 핵심 구조, 발전 이력, 프론티어 분야 및 전체 지식 아키텍처가 다학과 융합 목적에 달성하도록 하는 현대 이론을 생생하게 표시하는 것이다. 도 1에 도시된 바와 같이, 상기 다항 관계 생성 모델의 트레이닝 방법은 하기와 같은 단계를 포함한다. 단계 S101에서, 복수의 지식 엔트리 텍스트를 획득한다. [마리 퀴리는 1903년에 피에르 퀴리, 앙리 베크렐과 함께 노벨 물리학상을 수상함]과 같은 지식 엔트리 텍스트 는 5항 관계로 표현되는 지식 엔트리 텍스트이거나, 지식 엔트리 텍스트는 임의의 수의 항 관계 표현을 포함할 수 있는바, 예를 들어 3항 관계 표현, 4항 관계 표현, 6항 관계 표현 등이고, 이에 한정되지 않는다. 본 출원의 실시예에서 상기 각각의 지식 엔트리 텍스트 중 항 관계 표현은 임의의 수일 수 있으므로, 복수의 지 식 엔트리 텍스트를 트레이닝용 데이터로 할 경우, 트레이닝용 데이터의 특징 차원을 효과적으로 확장하고, 모 델 트레이닝의 정확성을 보장할 수 있다. 단계 S102에서, 지식 엔트리 텍스트에 대해 의미 분석을 수행하여, 대응되는 복수의 엔티티 및 의미 정보를 획 득한다. 상기 복수의 지식 엔트리 텍스트를 획득한 이후, 각각의 지식 엔트리 텍스트에 대해 의미 분석을 수행하여, 이 로부터 각각의 엔티티, 및 상기 지식 엔트리 텍스트의 의미 정보를 획득할 수 있다. [마리 퀴리는 1903년에 피에르 퀴리, 앙리 베크렐과 함께 노벨 물리학상을 수상함 ( )]과 같은 상기 지식 엔트리 텍스트를 예로 들면, 엔티티는 예를 들어, “마리 퀴리 ( )”“수상 항목( )”“수상 시간( )”“공동 수상자( )”“공 동 수상자( )”일 수 있고, 대응하게, 의미 정보는 상기 지식 엔트리 텍스트에 대응하는 의미를 설명하는데 사용될 수 있거나, 상기 각각의 엔티티에 대응하는 실제 의미 콘텐츠를 설명하는데 사용될 수 있는 바, 예를 들어, “1903년( )”“노벨 물리학상( )”“피에르 퀴리 ( )”“앙리 베크렐( )” 등이며, 이에 대해 한정하지 않는다. 일부 실시예에서, 여기서 지식 엔트리 텍스트에 대해 의미 분석을 수행하여, 대응되는 복수의 엔티티 및 의미 정보를 획득하는 단계는, 지식 엔트리 텍스트에 대해 의미 분석을 수행하여, 지식 엔트리 텍스트 중의 복수의 엔티티를 획득하는 단계; 복수의 엔티티로부터 메인 속성 및 보조 속성을 결정하는 단계; 메인 속성에 대응하는 메인 콘텐츠와, 보조 속성에 대응하는 보조 콘텐츠를 결정하는 단계; 및, 메인 콘텐츠 및 보조 콘텐츠를 의미정보로 하는 단계;일 수 있다. 예를 들면, [마리 퀴리는 1903년에 피에르 퀴리, 앙리 베크렐과 함께 노벨 물리학상을 수상함]과 같은 상기 지 식 엔트리 텍스트를 예로 들면, 엔티티는 예를 들어 “마리 퀴리”“수상 항목”“수상 시간”“공동 수상자” “공동 수상자”일 수 있고, 대응하게, 메인 속성은 “수상 항목”일 수 있으며, 보조 속성은 “수상 시간”“ 공동 수상자”“공동 수상자”일 수 있고, 대응하게, 메인 속성 “수상 항목”에 대응하는 “노벨 물리학상”은 메인 콘텐츠로 지칭될 수 있으며, 보조 속성 “수상 시간”에 대응하는 “1903년에”, 및 보조 속성 “공동 수 상자”에 대응하는 “피에르 퀴리”“앙리 베크렐”은 보조 콘텐츠로 지칭될 수 있다. 다시 말해서, 본 출원의 실시예에서, 우선 각각의 다항 지식 엔트리 텍스트를 핵심 3항 그룹(상기 핵심 3항 그 룹에는 적어도 일부의 엔티티, 및 엔티티에 대응하는 콘텐츠가 포함됨) 및 보조 속성-값 쌍의 조합으로 표현할 수 있으며, 구체적으로 예를 들면, [마리 퀴리는 1903년에 피에르 퀴리, 앙리 베크렐과 함께 노벨 물리학상을 수상함]이고, 상기 5항 지식 엔트리 텍스트는 하기와 같이 표현될 수 있다. (마리 퀴리, 수상 항목, 노벨 물리학상) |―수상 시간: 1903년; |―공동 수상자: 피에르 퀴리; |―공동 수상자: 앙리 베크렐. (마리 퀴리, 수상 항목, 노벨 물리학상) （ ）은 핵심 3항 그 룹이고, “수상 시간: 1903년”, “공동 수상자：피에르 퀴리”, “공동 수상자：앙리 베크렐”은 3 그룹의 보 조 속성-값 쌍으로, 핵심 3항 그룹을 보충한다. 본 출원의 실시예에서, 상기 핵심 3항 그룹 중 마리 퀴리, 수상 항목을 해당하는 엔티티로 추상할 수 있고, 3항 그룹 중 마리 퀴리, 수상 항목을 메인 속성으로 하여, 상기 보조 속성과 조합하거나, 다른 임의의 가능한 조합 방식일 수도 있으며 이에 한정되지 않는다. 상기 지식 엔트리 텍스트에 대해 의미 분석을 수행하여, 지식 엔트리 텍스트 중의 복수의 엔티티를 획득하고; 복수의 엔티티로부터 메인 속성 및 보조 속성을 결정하며; 메인 속성에 대응하는 메인 콘텐츠와, 보조 속성에 대응하는 보조 콘텐츠를 결정하고; 메인 콘텐츠 및 보조 콘텐츠를 의미 정보로 함으로써 트레이닝용 데이터의 특징 차원을 효과적으로 확장하고, 모델 트레이닝의 정확성을 보장하여, 트레이닝하여 획득한 다항 관계 생성 모델이 다항 지식 엔트리의 의미 완전성을 더 크게 학습할 수 있도록 한다. 다른 일부 실시예에서, 또한 다른 임의의 가능한 방식을 사용하여 지식 엔트리 텍스트에 대해 의미 분석을 수행 하여, 대응되는 복수의 엔티티 및 의미 정보를 획득할 수 있는바, 예를 들어, 수학 방식, 공학 방식 등이며, 이 에 한정되지 않는다. 단계 S103에서, 엔티티 및 의미 정보에 따라 이종 그래프를 구축한다. 상기 지식 엔트리 텍스트에 대해 의미 분석을 수행하여, 대응되는 복수의 엔티티 및 의미 정보를 획득한 이후, 엔티티 및 의미 정보에 따라 이종 그래프를 구축할 수 있다. 이종 그래프는 그래프 모델로서, 그래프 모델은 딥 러닝에서의 그래프 모델이거나, 인공 지능 기술 분야에서 다 른 임의의 가능한 아키텍처 형태의 그래프 모델일 수 있으며, 이에 한정되지 않고, 이종 그래프에는 하나의 노 드 및 에지만 존재할 수 있는 것이 아니며, 상이한 유형의 노드가 상이한 차원의 특징 또는 속성을 소유하도록 허용하고, 다시 말해서, 본 출원에서는 엔티티 및 의미 정보에 따라 이종 그래프를 구축하되, 상기 이종 그래프 중의 노드의 유형은 동일하거나 상이할 수 있고, 상기 이종 그래프는 지식 엔트리 텍스트와 관련된 상이한 차원 의 특징 또는 속성을 가질 수 있다. 선택적으로, 일부 실시예에서, 엔티티 및 의미 정보에 따라 이종 그래프를 구축하는 단계는, 엔티티, 메인 속성, 보조 속성, 메인 콘텐츠, 및 보조 콘텐츠를 각각 대응되는 노드에 매핑하는 단계; 엔티티, 메인 속성, 보 조 속성, 메인 콘텐츠, 및 보조 콘텐츠의 품사를 각각 사용하여, 대응 노드의 품사를 설명하는 단계; 대응 관계 를 가진 노드 사이에 에지를 구축하는 단계; 에지로 연결된 노드에 대응하는 품사에 따라, 에지의 품사 유형을 형성하는 단계; 및, 품사 유형으로 에지에 라벨링하여, 노드, 에지, 및 에지의 라벨링에 따라 이종 그래프를 구 축하는 단계;일 수 있다.그 중의 품사는 예를 들어, 주어, 술어, 목적어이고, 하나의 에지는 2개의 노드를 연결할 수 있으며, 2개의 노 드에 대응하는 품사가 각각 주어, 술어이면, 해당하는 상기 에지의 품사 유형은 주어-술어 유형이다. 예를 들면 하기와 같다. 각각의 다항 지식 엔트리 텍스트는 핵심 3항 그룹 및 보조 속성-값 쌍"}
{"patent_id": "10-2021-0167756", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "의 조합, 즉 으로 표현될 수 있고, 여기서 은 보조 속성-값 쌍의 수이며, 본 출원 의 실시예에서, 와 같은 형태의 다항 지식 엔트리 텍스트를 하나의 이종 그래프 로 완전하게 표현할수 있고, 도 2에 도시된 바와 같이, 도 2는 본 출원의 실시예 중 이종 그래프의 개략도이며, 도 2에서, 상이한 형태의 에지는 하나의 품사 유형에 대응하고, 는 그래프의 노드 집합이며, 해당 하는 다항 지식 엔트리 텍스트 중 모든 엔티티(값)와 관계(속성)를 포함하는바, 즉 이다. 는 그래프의 에지의 집합으로, 4가지 품사 유형인 총계 개의 에 지를 포함하는바, 즉 하기와 같다. 주어-술어형 에지 , 총 1개; 목적어-술어형 에지 , 총 1개; 술어-속성형 에지 , 총 m개; 속성-값 형 에지 , 총 m개. 본 출원의 실시예에서 이종 그래프에서, 이의 노드와 연결 에지는 대응하는 품사 유형을 가지며, 노드는 엔티티 및 관계(관계는 메인 속성, 보조 속성, 메인 콘텐츠, 및 보조 콘텐츠를 포함함) 2가지 유형으로 나뉘고, 연결 에지의 품사 유형은 주어-술어, 목적어-술어, 술어-속성, 속성-값 4가지 유형일 수 있으며, 본 출원의 실시예에 서, 엔티티 및 의미 정보에 따라 이종 그래프를 구축하여, 의미 정보가 손실되지 않는 전제 하에 지식 엔트리의 전체성을 크게 보류하여, 상기 이종 그래프가 다항 지식 엔트리 텍스트의 의미 정보를 완전하게 보류하도록 함 으로써, 다항 관계 생성 모델의 모델링 효과를 향상시키는데 효과적으로 보조할 수 있다. 단계 S104에서, 이종 그래프에 따라 초기 인공 지능 네트워크 모델을 트레이닝하여, 다항 관계 생성 모델을 획 득한다. 상기 엔티티 및 의미 정보에 따라 이종 그래프를 구축한 이후, 이종 그래프에 따라 초기 인공 지능 네트워크 모 델을 트레이닝하여, 다항 관계 생성 모델을 획득할 수 있으며, 예를 들어, 초기 인공 지능 네트워크 모델이 수 렴될 때까지, 이종 그래프 중 각각의 노드와 에지, 및 노드와 에지가 가지는 다양한 차원의 특징 또는 속성을 초기 인공 지능 네트워크 모델에 입력할 수 있으며, 트레이닝하여 획득한 인공 지능 네트워크 모델을 다항 관계 생성 모델로 한다. 상기 인공 지능 네트워크 모델은 예를 들어 신경망 모델, 기계 학습 모델 등일 수 있고, 본 출원의 실시예에서, 그래프 신경망 모델을 사용하여 다항 관계 생성 모델을 얻기 위해 트레이닝할 수 있고, 그래프 신경망 기술을 이용하여 상기 이종 그래프에 대해 모델링을 수행하여, 다항 지식 엔트리 텍스트 중 각각의 요소(엔티티, 메인 속성, 보조 속성 및 이에 대응하는 콘텐츠) 사이의 잠재적 연관성을 충분히 포획할 수 있다. 본 실시예에서, 복수의 지식 엔트리 텍스트를 획득하고, 지식 엔트리 텍스트에 대해 의미 분석을 수행하여, 대 응되는 복수의 엔티티 및 의미 정보를 획득하며, 엔티티 및 의미 정보에 따라 이종 그래프를 구축하고, 이종 그 래프에 따라 초기 인공 지능 네트워크 모델을 트레이닝하여, 다항 관계 생성 모델을 획득하며, 다항 지식 엔트 리의 의미 완전성을 더 많이 학습할 수 있음으로써, 다항 관계 생성 모듈의 다항 관계 표현의 정확성을 효과적 으로 향상시키고, 보다 더 정확한 다항 지식 추론을 구현한다. 도 3은 본 출원의 제2 실시예에 따른 개략도이다. 도 3에 도시된 바와 같이, 상기 다항 관계 생성 모델의 트레이닝 방법은 하기와 같은 단계를 포함한다. 단계 S301에서, 복수의 지식 엔트리 텍스트를 획득한다. 단계 S302에서, 지식 엔트리 텍스트에 대해 의미 분석을 수행하여, 대응되는 복수의 엔티티 및 의미 정보를 획 득한다. 단계 S303에서, 엔티티 및 의미 정보에 따라 이종 그래프를 구축한다. 단계 S301 내지 단계 S303의 설명은 구체적으로 상기 실시예를 참조할 수 있으며, 여기서 더이상 반복하지 않는 다. 단계 S304에서, 이종 그래프를 입력 표현 계층에 입력하여, 입력 표현 계층에 의해 출력된 노드에 대응하는 벡 터 표현을 획득하되, 벡터 표현은 노드에 대응하는 콘텐츠 사이의 의미 관계를 설명한다. 다시 말해서, 본 출원의 실시예에서의 초기 인공 지능 네트워크 모델은 입력 표현 계층, 그래프 주의 계층(상기 그래프 주의 계층의 수는 다수일 수 있는바, 예를 들어 L층이고, 각 층의 그래프 주의 계층은 순서대로 배열 됨), 및 선형 예측 계층을 포함한다. 도 4에 도시된 바와 같이, 도 4는 본 출원의 실시예 중 인공 지능 네트워크 모델의 개략도이고, 입력 표현 계층, L층 그래프 주의 계층, 및 선형 예측 계층을 포함한다. 상기 엔티티 및 의미 정보에 따라 이종 그래프를 구축한 이후에, 이종 그래프를 입력 표현 계층에 입력하여 입 력 표현 계층에 의해 출력된 노드에 대응하는 벡터 표현을 획득하여, 벡터 표현이 노드에 대응하는 콘텐츠 사이 의 의미 관계를 설명할 수 있도록 함으로써, 이종 그래프와 인공 지능 네트워크 모델을 효과적으로 융합하여, 인공 지능 네트워크 모델이 노드에 대응하는 콘텐츠 사이의 의미 관계를 빠르게 학습하도록 한다. 단계 S305에서, 이종 그래프를 그래프 주의 계층에 입력하여, 그래프 주의 계층에 의해 출력된 에지의 품사 유 형에 대응하는 적응 인자를 획득한다. 상기 이종 그래프를 입력 표현 계층에 입력하여 입력 표현 계층에 의해 출력된 노드에 대응하는 벡터 표현을 획 득한 이후, 또한, 입력 표현 계층에 의해 출력된 벡터 표현을 이종 그래프의 노드의 라벨로 할 수 있고, 라벨링 된 이종 그래프를 그래프 주의 계층에 입력하여 그래프 주의 계층에 의해 출력된 에지의 품사 유형에 대응하는 적응 인자를 획득하며, 상기 적응 인자의 형태는 구체적으로 하나의 벡터일 수 있고, 적응 인자는 이에 대응하 는 에지의 품사 유형이 전체 지식 엔트리 텍스트에서 차지하는 비중을 설명하는데 사용될 수 있다. 이종 그래프를 그래프 주의 계층에 입력하여, 그래프 주의 계층에 의해 출력된 에지의 품사 유형에 대응하는 적 응 인자를 획득한 이후, 또한 적응 인자에 따라 그래프 주의 계층의 주의 강도 값을 조정함으로써, 연결 에지 인식의 보다 정확한 자기 주의 메커니즘을 형성하여, 그래프의 이질성에 대한 빠르고, 정확한 모델링을 구현한 다. 단계 S306에서, 벡터 표현 및 적응 인자에 따라 선형 예측 계층에 입력하여, 선형 예측 계층에 의해 출력된 예 측 다항 관계를 획득한다. 상기 이종 그래프를 입력 표현 계층에 입력하여 입력 표현 계층에 의해 출력된 노드에 대응하는 벡터 표현을 획 득하고, 이종 그래프를 그래프 주의 계층에 입력하여, 그래프 주의 계층에 의해 출력된 에지의 품사 유형에 대 응하는 적응 인자를 획득한 이후, 벡터 표현 및 적응 인자에 따라 선형 예측 계층에 입력하여, 선형 예측 계층 에 의해 출력된 예측 다항 관계를 획득할 수 있다. 다시 말해서, 트레이닝 과정에서, 복수의 지식 엔트리 텍스트를 사용하여 초기 인공 지능 네트워크 모델을 트레 이닝하고, 즉 초기 인공 지능 네트워크 모델을 사용하여 각각의 지식 엔트리 텍스트에 대응하는 다항 관계를 예 측하며, 상기 예측에 의해 얻어진 다항 관계는 예측 다항 관계로 지칭될 수 있고, 이후 예측 다항 관계에 따라 인공 지능 네트워크 모델 수렴을 판정할 때까지, 예측 다항 관계에 대해 대응하게 판정한다. 예를 들어, 다항 지식 추론을 이종 그래프 상의 노드 예측 문제로 전환하여, 다항 지식 엔트리 중의 주어 를 예측하는 것을 예(예측하여 획득한 다항 관계, 즉 예측 다항 관계로 지칭될 수 있음)로 들면, 인공 지능 네트워크 모델의 입력은 노드가 결실된 이종 그래프 이고, 출력은 예측 다항 관계(예측하여 획득한 타깃 노드 주어 )여야 함을 예측한 다. 단계 S307에서, 예측 다항 관계 및 라벨링 다항 관계에 따라 초기 인공 지능 네트워크 모델을 트레이닝하여, 다 항 관계 생성 모델을 획득한다. 선택적으로, 일부 실시예에서, 예측 다항 관계 및 라벨링 다항 관계에 따라 초기 인공 지능 네트워크 모델을 트 레이닝하여, 다항 관계 생성 모델을 획득하는 단계는 예측 다항 관계와 라벨링 다항 관계 사이의 손실값을 결정 하는 단계일 수 있고; 손실값이 설정된 손실 임계값을 만족할 경우, 트레이닝하여 획득한 인공 지능 네트워크 모델을 다항 관계 생성 모델로 하여 양호한 모델 트레이닝 효과를 구현한다. 상기 손실값은 초기 인공 지능 네트워크 모델에 대응하는 손실 함수를 계산하여 얻어진 것일 수 있고, 응용에서, 손실 함수는 일반적으로 학습 준칙으로 최적화 문제와 연관되며, 즉 손실 함수 솔루션 및 평가 모델 을 최소화함으로써, 본 출원의 실시예에서 예측 다항 관계와 라벨링 다항 관계 사이의 손실값을 결정할 수 있고, 이후 상기 손실값을 사용하여 트레이닝 과정을 지도한다. 상기 예측 다항 관계와 라벨링 다항 관계 사이의 손실값을 결정한 이후, 손실값이 설정된 손실 임계값(상기 설 정된 손실 임계값은 미리 보정된 것으로, 인공 지능 네트워크 모델 수렴을 판정하는 손실값의 문턱값일 수 있음)을 만족하는지 여부를 실시간으로 결정할 수 있고, 손실값이 설정된 손실 임계값을 만족할 경우, 트레이닝 하여 획득한 인공 지능 네트워크 모델을 다항 관계 생성 모델로 하며, 즉 모델의 트레이닝이 완료되고, 이때 다 항 관계 생성 모델은 미리 설정된 수렴 조건을 만족한다. 본 실시예에서, 복수의 지식 엔트리 텍스트를 획득하고, 지식 엔트리 텍스트에 대해 의미 분석을 수행하여, 대 응되는 복수의 엔티티 및 의미 정보를 획득하며, 엔티티 및 의미 정보에 따라 이종 그래프를 구축하고, 이종 그 래프에 따라 초기 인공 지능 네트워크 모델을 트레이닝하여, 다항 관계 생성 모델을 획득하며, 다항 지식 엔트 리의 의미 완전성을 더 많이 학습할 수 있음으로써, 다항 관계 생성 모듈의 다항 관계 표현의 정확성을 효과적 으로 향상시키고, 보다 더 정확한 다항 지식 추론을 구현한다. 엔티티 및 의미 정보에 따라 이종 그래프를 구축 한 이후, 이종 그래프를 입력 표현 계층에 입력하여 입력 표현 계층에 의해 출력된 노드에 대응하는 벡터 표현 을 획득할 수 있고, 이종 그래프를 그래프 주의 계층에 입력하여, 그래프 주의 계층에 의해 출력된 에지의 품사 유형에 대응하는 적응 인자를 획득하며, 벡터 표현 및 적응 인자에 따라 선형 예측 계층에 입력하여, 선형 예측 계층에 의해 출력된 예측 다항 관계를 획득하여, 벡터 표현이 노드에 대응하는 콘텐츠 사이의 의미 관계를 설명 할 수 있도록 함으로써, 이종 그래프와 인공 지능 네트워크 모델을 효과적으로 융합하여, 인공 지능 네트워크 모델이 노드에 대응하는 콘텐츠 사이의 의미 관계를 빠르게 학습하도록 한다. 이종 그래프를 그래프 주의 계층 에 입력하여, 그래프 주의 계층에 의해 출력된 에지의 품사 유형에 대응하는 적응 인자를 획득한 이후, 또한 적 응 인자에 따라 그래프 주의 계층의 주의 강도 값을 조정함으로써, 에지 인식을 연결하는 보다 정확한 자기 주 의 메커니즘을 형성하여, 그래프의 이질성에 대한 빠르고, 정확한 모델링을 구현한다. 도 5는 본 출원의 제3 실시예에 따른 개략도이다. 도 5에 도시된 바와 같이, 상기 다항 관계 생성 모델의 트레이닝 장치는, 복수의 지식 엔트리 텍스트를 획득하는 획득 모듈; 지식 엔트리 텍스트에 대해 의미 분석을 수행하여, 대응되는 복수의 엔티티 및 의미 정보를 획득하는 해석 모듈 ; 엔티티 및 의미 정보에 따라 이종 그래프를 구축하는 구축 모듈; 및, 이종 그래프에 따라 초기 인공 지능 네트워크 모델을 트레이닝하여, 다항 관계 생성 모델을 획득하는 트레이닝 모듈;을 포함한다. 본 출원의 일부 실시예에서, 해석 모듈은 구체적으로, 지식 엔트리 텍스트에 대해 의미 분석을 수행하여, 지식 엔트리 텍스트 중의 복수의 엔티티를 획득하고; 복수의 엔티티로부터 메인 속성 및 보조 속성을 결정하며; 메인 속성에 대응하는 메인 콘텐츠와, 보조 속성에 대응하는 보조 콘텐츠를 결정하고; 메인 콘텐츠 및 보조 콘텐츠를 의미 정보로 한다. 본 출원의 일부 실시예에서, 도 6에 도시된 바와 같이, 도 6은 본 출원의 제4 실시예에 따른 개략도이고, 상기 다항 관계 생성 모델의 트레이닝 장치는 획득 모듈, 해석 모듈, 구축 모듈, 및 트레이닝 모 듈을 포함하되, 여기서 구축 모듈은,엔티티, 메인 속성, 보조 속성, 메인 콘텐츠, 및 보조 콘텐츠를 각각 대응되는 노드에 매핑하고, 엔티티, 메인 속성, 보조 속성, 메인 콘텐츠, 및 보조 콘텐츠의 품사를 각각 사용하여, 대응 노드의 품사를 설명하는 매핑 서 브 모듈; 대응 관계를 가진 노드 사이에 에지를 구축하는 제1 구축 서브 모듈; 에지로 연결된 노드에 대응하는 품사에 따라, 에지의 품사 유형을 형성하는 생성 서브 모듈; 및, 품사 유형으로 에지에 라벨링하여, 노드, 에지, 및 에지의 라벨링에 따라 이종 그래프를 구축하는 제2 구축 서 브 모듈;을 포함한다. 본 출원의 일부 실시예에서, 초기 인공 지능 네트워크 모델은 입력 표현 계층, 그래프 주의 계층, 및 선형 예측 계층을 포함하되, 여기서 트레이닝 모듈은 구체적으로, 이종 그래프를 입력 표현 계층에 입력하여, 입력 표현 계층에 의해 출력된 노드에 대응하는 벡터 표현을 획득하 되, 벡터 표현은 노드에 대응하는 콘텐츠 사이의 의미 관계를 설명하고; 이종 그래프를 그래프 주의 계층에 입력하여, 그래프 주의 계층에 의해 출력된 에지의 품사 유형에 대응하는 적 응 인자를 획득하며; 벡터 표현 및 적응 인자에 따라 선형 예측 계층에 입력하여, 선형 예측 계층에 의해 출력된 예측 다항 관계를 획득하고; 예측 다항 관계 및 라벨링 다항 관계에 따라 초기 인공 지능 네트워크 모델을 트레이닝하여, 다항 관계 생성 모 델을 획득한다. 본 출원의 일부 실시예에서, 여기서 트레이닝 모듈은 구체적으로, 적응 인자에 따라 그래프 주의 계층의 주의 강도 값을 조정한다. 본 출원의 일부 실시예에서, 여기서 트레이닝 모듈은 구체적으로, 예측 다항 관계와 라벨링 다항 관계 사이의 손실값을 결정하고; 손실값이 설정된 손실 임계값을 만족할 경우, 트레이닝하여 획득한 인공 지능 네트워크 모델을 다항 관계 생성 모델로 한다. 이해할 수 있는 것은, 본 실시예의 도 6에서의 다항 관계 생성 모델의 트레이닝 장치와 상기 실시예에서의 다항 관계 생성 모델의 트레이닝 장치, 획득 모듈과 상기 실시예에서의 획득 모듈, 해석 모듈 과 상기 실시예에서의 해석 모듈, 구축 모듈과 상기 실시예에서의 구축 모듈, 트레이닝 모 듈과 상기 실시예에서의 트레이닝 모듈은 동일한 기능 및 구조를 가질 수 있다. 설명해야 할 것은, 전술한 다항 관계 생성 모델의 트레이닝 방법의 해석 설명도 본 실시예의 다항 관계 생성 모 델의 트레이닝 장치에 적용되며, 여기서 더이상 반복하지 않는다. 본 실시예에서, 복수의 지식 엔트리 텍스트를 획득하고, 지식 엔트리 텍스트에 대해 의미 분석을 수행하여, 대 응되는 복수의 엔티티 및 의미 정보를 획득하며, 엔티티 및 의미 정보에 따라 이종 그래프를 구축하고, 이종 그 래프에 따라 초기 인공 지능 네트워크 모델을 트레이닝하여, 다항 관계 생성 모델을 획득하여, 다항 지식 엔트 리의 의미 완전성을 더 많이 학습할 수 있음으로써, 다항 관계 생성 모듈의 다항 관계 표현의 정확성을 효과적 으로 향상시키고, 보다 더 정확한 다항 지식 추론을 구현한다. 본 출원의 실시예에 따르면, 본 출원은 전자 기기, 판독 가능 저장 매체 및 컴퓨터 프로그램 제품을 더 제공한 다. 본 출원의 실시예에 따르면, 컴퓨터 판독 가능 매체에 저장되어 있는 컴퓨터 프로그램을 더 제공한다. 당해 컴퓨터 프로그램중의 명령이 실행될 경우, 상기 다항 관계 생성 모델의 트레이닝 방법이 실행된다. 도 7은 본 출원의 실시예에 따른 다항 관계 생성 모델의 트레이닝 방법을 구현하기 위한 전자 기기의 블록도이 다. 전자 기기는 랩톱 컴퓨터, 데스크톱 컴퓨터, 워크 벤치, 개인 정보 단말기, 서버, 블레이드 서버, 메인 프 레임 컴퓨터, 및 다른 적합한 컴퓨터와 같은 다양한 형태의 디지털 컴퓨터를 의미한다. 전자 기기는 개인 디지 털 처리, 셀룰러 폰, 스마트 폰, 웨어러블 기기 및 다른 유사한 컴퓨팅 장치와 같은 다양한 형태의 모바일 장치 를 나타낼 수도 있다. 본 명세서에 개시된 부재, 이들의 연결 및 관계, 및 그 기능은 단지 예시에 불과하며, 본 명세서에 기술되거나 청구된 본 출원의 구현을 한정하도록 의도되지 않는다.도 7에 도시된 바와 같이, 기기는 읽기 전용 메모리(702, ROM)에 저장된 컴퓨터 프로그램 또는 저장 유닛 으로부터 랜덤 액세스 메모리(703, RAM)에 로딩된 컴퓨터 프로그램에 따라 다양한 적절한 동작 및 처리를 수행할 수 있는 컴퓨팅 유닛을 포함한다. RAM에서, 또한 기기의 조작에 필요한 다양한 프로그램 과 데이터를 저장할 수 있다. 컴퓨팅 유닛, ROM 및 RAM 은 버스를 통해 서로 연결된다. 입 력/출력(I/O) 인터페이스도 버스에 연결된다. 키보드, 마우스 등과 같은 입력 유닛; 다양한 유형의 디스플레이, 스피커 등과 같은 출력 유닛; 자기 디스크, 광 디스크 등과 같은 저장 유닛; 및 네트워크 카드, 모뎀, 무선 통신 트랜시버 등과 같은 통신 유 닛을 포함하는 기기의 복수의 부재는 I/O 인터페이스에 연결된다. 통신 유닛은 기기 가 인터넷과 같은 컴퓨터 네트워크 및/또는 다양한 통신 네트워크를 통해 다른 기기와 정보/데이터를 교환하도 록 허용한다. 컴퓨팅 유닛은 처리 및 컴퓨팅 기능을 갖는 다양한 범용 및/또는 전용 처리 컴포넌트일 수 있다. 컴퓨팅 유닛의 일부 예시는 중앙 처리 유닛(CPU), 그래픽 처리 유닛(GPU), 다양한 전용 인공지능(AI) 컴퓨팅 칩, 기계 학습 모델 알고리즘을 실행하는 다양한 컴퓨팅 유닛, 디지털 신호 프로세서(DSP), 및 임의의 적절한 프로 세서, 컨트롤러, 마이크로 컨트롤러 등을 포함하지만 이에 한정되는 것은 아니다. 컴퓨팅 유닛은 다항 관 계 생성 모델의 트레이닝 방법과 같이 상술한 다양한 방법 및 처리를 수행한다. 예를 들어, 일부 실시예에서, 다항 관계 생성 모델의 트레이닝 방법은 저장 유닛과 같은 기계 판독 가능 매체에 유형적으로 포함되는 컴퓨터 소프트웨어 프로그램으로 구현될 수 있다. 일부 실시예에서, 컴퓨터 프로그 램의 부분 또는 전부는 ROM 및/또는 통신 유닛을 통해 기기에 로딩 및/또는 설치될 수 있다. 컴 퓨터 프로그램이 RAM에 로딩되어 컴퓨팅 유닛에 의해 실행될 경우, 상술한 다항 관계 생성 모델의 트 레이닝 방법의 하나 또는 복수의 단계를 수행할 수 있다. 대안적으로, 다른 실시예에서, 컴퓨팅 유닛은 다 른 임의의 적절한 방식(예를 들어, 펌웨어에 의함)을 통해 다항 관계 생성 모델의 트레이닝 방법을 수행하도록 구성될 수 있다. 본문에서 이상 서술된 시스템 및 기술의 다양한 실시형태는 디지털 전자 회로 시스템, 집적 회로 시스템, 필드 프로그래머블 어레이(FPGA), 전용 집적 회로(ASIC), 전용 표준 제품(ASSP), 시스템 온 칩(SOC), 복합 프로그래 머블 논리 소자(CPLD), 컴퓨터 하드웨어, 펌웨어, 소프트웨어, 및/또는 이들의 조합에서 구현될 수 있다. 이러 한 다양한 실시형태는 하나 또는 복수의 컴퓨터 프로그램에서 구현되는 것을 포함할 수 있고, 상기 하나 또는 복수의 컴퓨터 프로그램은 적어도 하나의 프로그래머블 프로세서를 포함하는 프로그래머블 시스템에서 실행 및/ 또는 해석될 수 있으며, 상기 프로그래머블 프로세서는 전용 또는 범용 프로그래머블 프로세서일 수 있고, 저장 시스템, 적어도 하나의 입력장치, 및 적어도 하나의 출력장치로부터 데이터와 명령을 수신하며, 데이터와 명령 을 상기 저장 시스템, 상기 적어도 하나의 입력장치, 및 상기 적어도 하나의 출력장치로 전송할 수 있다. 본 출원의 다항 관계 생성 모델의 트레이닝 방법을 실시하기 위한 프로그램 코드는 하나 또는 복수의 프로그래 밍 언어의 임의의 조합으로 작성될 수 있다. 이러한 프로그램 코드는 범용 컴퓨터, 전용 컴퓨터 또는 다른 프로 그래머블 데이터 처리 장치의 프로세서 또는 컨트롤러에 제공되어, 프로그램 코드가 프로세서 또는 컨트롤러에 의해 실행될 경우 흐름도 및/또는 블록도에서 규정하는 기능/동작이 실시될 수 있도록 한다. 프로그램 코드는 완전히 기계에서 실행되거나, 부분적으로 기계에서 실행될 수 있으며, 독립형 소프트웨어 패키지로서 부분적으 로 기계에서 실행되고 부분적으로 원격 기계에서 실행되거나 완전히 원격 기계 또는 서버에서 실행될 수도 있다. 본 출원의 컨텍스트에서, 기계 판독 가능 매체는 명령 실행 시스템, 장치 또는 기기에 의해 사용되거나 명령 실 행 시스템, 장치 또는 기기와 결합되어 사용되는 프로그램을 포함하거나 저장할 수 있는 유형 매체일 수 있다. 기계 판독 가능 매체는 기계 판독 가능 신호 매체이거나 기계 판독 가능 저장 매체일 수 있다. 기계 판독 가능 매체는 전자적, 자기적, 광학적, 전자기적, 적외선, 또는 반도체 시스템, 장치 또는 기기, 또는 상술한 내용의 임의의 적절한 조합을 포함할 수 있지만 이에 한정되는 것은 아니다. 기계 판독 가능 저장 매체의 더 구체적인 예시는 하나 또는 복수의 와이어를 기반으로 하는 전기적 연결, 휴대형 컴퓨터 디스크, 하드 디스크, 랜덤 액세 스 메모리(RAM), 읽기 전용 메모리(ROM), 소거 가능 및 프로그래머블 읽기 전용 메모리(EPROM 또는 플래쉬 메모 리), 광섬유, 휴대용 컴팩트 읽기 전용 메모리(CD-ROM), 광학 저장 기기, 자기 저장 기기, 또는 상술한 내용의 임의의 적절한 조합을 포함한다. 사용자와의 인터랙션을 제공하기 위해, 컴퓨터에서 여기에 설명된 시스템 및 기술을 구현할 수 있고, 상기 컴퓨 터는 사용자에게 정보를 표시하기 위한 디스플레이 장치(예를 들어, CRT(cathode ray tube) 또는 LCD(liquidcrystal display) 모니터)와 키보드 및 포인팅 장치(예를 들어, 마우스 또는 트랙볼)를 구비하며, 사용자는 상 기 키보드 및 상기 포인팅 장치를 통해 입력하여 컴퓨터에 제공할 수 있다. 다른 종류의 장치를 사용하여 사용 자와의 인터랙션을 제공할 수도 있는데 예를 들어, 사용자에게 제공되는 피드백은 임의의 형태의 센싱 피드백 (예를 들어, 시각적 피드백, 청각적 피드백, 또는 촉각적 피드백)일 수 있고; 임의의 형태(사운드 입력, 음성 입력 또는 촉각 입력을 포함함)를 통해 사용자로부터의 입력을 수신할 수 있다. 여기에 설명되는 시스템과 기술은 백엔드 부재를 포함하는 컴퓨팅 시스템(예를 들어, 데이터 서버로 됨), 또는 미들웨어 부재를 포함하는 컴퓨팅 시스템(예를 들어, 애플리케이션 서버), 또는 프론트 엔드 부재를 포함하는 컴퓨팅 시스템(예를 들어, 그래픽 유저 인터페이스 또는 인터넷 브라우저를 구비하는 사용자 컴퓨터이고, 사용 자는 상기 그래픽 유저 인터페이스 또는 상기 웹 브라우저를 통해 여기에 설명되는 시스템 및 기술의 실시형태 와 인터랙션할 수 있음), 또는 이러한 백엔드 부재, 미들웨어 부재, 또는 프론트 엔드 부재의 임의의 조합을 포 함하는 컴퓨팅 시스템에서 구현될 수 있다. 시스템의 부재는 임의의 형태 또는 매체의 디지털 데이터 통신(예를 들어, 통신 네트워크)에 의해 상호 연결될 수 있다. 통신 네트워크의 예로는 근거리 통신망(LAN), 광역 통신망 (WAN), 인터넷 및 블록 체인 네트워크가 포함된다. 컴퓨터 시스템은 클라이언트 및 서버를 포함할 수 있다. 클라이언트와 서버는 일반적으로 서로 멀리 떨어져 있 으며, 일반적으로 통신 네트워크를 통해 인터랙션한다. 해당 컴퓨터에서 실행되며 서로 클라이언트-서버 관계를 가지는 컴퓨터 프로그램을 통해 클라이언트와 서버의 관계를 생성한다. 서버는 클라우드 컴퓨팅 서버 또는 클라 우드 호스트로도 지칭되는 클라우드 서버일 수 있고, 클라우드 컴퓨팅 서비스 시스템 중의 일 호스트 제품으로 서, 기존의 물리 호스트와 VPS 서비스(“Virtual Private Server”, 또는 “VPS”로 약칭)에서 존재하는 관리 상의 어려움이 크고, 서비스 확장이 약한 결함을 해결한다. 서버는 분산형 시스템의 서버, 또는 블록 체인이 결 합된 서버일 수도 있다. 상술한 다양한 형태의 프로세스를 사용하여 단계를 재정렬, 추가 또는 삭제할 수 있다는 것을 이해해야 한다. 예를 들어, 본 출원에 설명된 각 단계들은 병렬, 순차적 또는 상이한 순서로 수행될 수 있고, 본 출원에 개시된 기술적 해결수단이 원하는 결과를 달성할 수만 있으면, 별도로 한정하지 않는다. 상기 구체적인 실시형태는 본 출원의 보호범위에 대한 한정으로 구성되지 않는다. 당업자는 설계 요건 및 기타 요인에 따라, 다양한 수정, 조합, 서브 조합 및 대체가 이루어질 수 있다는 것을 이해해야 한다. 본 출원의 정 신과 원칙 내에서 이루어진 모든 수정, 동등한 대체 및 개선은 모두 본 출원의 보호 범위에 포함되어야 한다.도면 도면1 도면2 도면3 도면4 도면5 도면6 도면7"}
{"patent_id": "10-2021-0167756", "section": "도면", "subsection": "도면설명", "item": 1, "content": "첨부 도면은 본 해결수단을 더 잘 이해하기 위한 것으로서, 본 출원에 대해 한정하는 것으로 구성되지 않는다. 여기서, 도 1은 본 출원의 제1 실시예에 따른 개략도이다. 도 2는 본 출원의 실시예 중 이종 그래프의 개략도이다. 도 3은 본 출원의 제2 실시예에 따른 개략도이다. 도 4는 본 출원의 실시예 중 인공 지능 네트워크 모델의 개략도이다. 도 5는 본 출원의 제3 실시예에 따른 개략도이다. 도 6은 본 출원의 제4 실시예에 따른 개략도이다. 도 7은 본 출원의 실시예에 따른 다항 관계 생성 모델의 트레이닝 방법을 구현하기 위한 전자 기기의 블록도이 다."}
