{"patent_id": "10-2021-0146277", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0061735", "출원번호": "10-2021-0146277", "발명의 명칭": "배경 음원 추천 및 결합 시스템 및 방법", "출원인": "주식회사 뮤즈블라썸", "발명자": "조정욱"}}
{"patent_id": "10-2021-0146277", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "배경 음원 추천 및 결합 시스템에서 수행되는 배경 음원 추천 및 결합 방법으로서,(a) 배경 음원 추천 및 결합 시스템이, 사용자로부터 입력된 동영상을 사전에 학습된 인공지능 모델에적용하여, 동영상에 포함된 각 장면들을 검출하는 단계;(b) 상기 배경 음원 추천 및 결합 시스템의 상기 인공지능 모델이 각 장면에 대해서 추천 음원을 선정하는단계;(c) 상기 배경 음원 추천 및 결합 시스템이 각 장면에 대한 추천 음원을, 해당 장면의 동영상과 함께 사용자에게 출력하고, 사용자로부터 승인 정보를 입력받는 단계;(d) 사용자가 승인하지 않은 장면에 대해서, 상기 배경 음원 추천 및 결합 시스템이 상기 (b) 단계로 진행하여다른 추천 음원을 선정하고 동영상과 함께 사용자에게 출력하는 단계; 및(e) 모든 장면에 대해서 음원 추천이 종료되면, 상기 배경 음원 추천 및 결합 시스템이, 각 장면마다 승인된 음원을 결합하여 음원이 결합된 동영상 파일을 생성하는 단계를 포함하는 것을 특징으로 하는 배경 음원 추천 및결합 방법."}
{"patent_id": "10-2021-0146277", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1 항에 있어서, 상기 (a) 단계는동영상에 포함된 각 프레임의 RGB 평균 픽셀 세기(Mean Pixel Intensity)를 구하고, 이전 프레임과 현재 프레임간의 RGB 평균 픽셀 세기의 차이가 사전에 정의된 임계치 이상이면 장면이 전환된 것으로 판단하여 동영상에 포함된 각 장면들을 검출하는 것을 특징으로 하는 배경 음원 추천 및 결합 방법."}
{"patent_id": "10-2021-0146277", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 1 항에 있어서, 상기 (b) 단계는 검출된 각 장면에 포함된 프레임들의 HSV(Hue Saturation Value) 데이터를 분석하여, 해당 장면의 주요 프레임이미지들을 저장하고, 주요 프레임 이미지에 포함된 인물들의 감정 리스트와 색 리스트를 생성하여 해당 프레임이미지를 대표하는 대표 감정 및 대표 색을 선정하고, 사전에 정의된 규칙에 따라서 대표 감정 및 대표 색에 대응되는 장르와 분위기를 갖는 음원을 추천하는 것을 특징으로 하는 배경 음원 추천 및 결합 방법."}
{"patent_id": "10-2021-0146277", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 3 항에 있어서, 상기 (b) 단계에서 상기 인공지능 모델은 상기 주요 프레임 이미지들에서 인물의 얼굴을 검출하고, 얼굴의 표정을 인식하여, 인물의 감정 리스트를 생성하는 것을 특징으로 하는 배경 음원 추천 및 결합 방법."}
{"patent_id": "10-2021-0146277", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제 4 항에 있어서, 상기 (b) 단계에서상기 인공지능 모델은 사전에 학습된 인물의 감정 항목(angry, disgusted, fearful, happy, neutral, sad,surprised)별로 상기 얼굴의 표정에서 인식된 점수를 부여하여 감정 리스트를 생성하고, 인식된 점수가 가장 높은 감정 항목을 해당 프레임 이미지의 대표 감정으로서 선정하는 것을 특징으로 하는 배경 음원 추천 및 결합방법."}
{"patent_id": "10-2021-0146277", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "공개특허 10-2023-0061735-3-제 5 항에 있어서, 상기 (b) 단계에서하나의 주요 프레임 이미지에서 복수 인물의 얼굴이 검출된 경우에, 상기 인공지능 모델은 복수 인물의 얼굴 각각에 대해서 감정 리스트를 생성하고,복수 인물의 감정 리스트의 각 항목별 평균을 계산하여, 평균 점수가 가장 높은 감정 항목을 해당 프레임 이미지의 대표 감정으로서 선정하는 것을 특징으로 하는 배경 음원 추천 및 결합 방법."}
{"patent_id": "10-2021-0146277", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "비일시적 저장매체에 저장되고, 프로세서를 포함하는 컴퓨터에서 실행되어, 상기 제 1 항 내지 제 6 항 중 어느한 항의 배경 음원 추천 및 결합 방법을 수행하는 컴퓨터 프로그램."}
{"patent_id": "10-2021-0146277", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "프로세서 및 소정의 명령어들을 저장하는 메모리를 포함하는 배경 음원 추천 및 결합 시스템으로서,상기 메모리에 저장된 명령어들을 실행한 상기 프로세서는 (a) 사용자로부터 입력된 동영상을 사전에 학습된 인공지능 모델에 적용하여, 동영상에 포함된 각 장면들을 검출하는 단계;(b) 상기 인공지능 모델을 이용하여 각 장면에 대해서 추천 음원을 선정하는 단계;(c) 각 장면에 대한 추천 음원을, 해당 장면의 동영상과 함께 사용자에게 출력하고, 사용자로부터 승인 정보를입력받는 단계;(d) 사용자가 승인하지 않은 장면에 대해서, 상기 (b) 단계로 진행하여 다른 추천 음원을 선정하고 사용자에게동영상과 함께 출력하는 단계; 및(e) 모든 장면에 대해서 음원 추천이 종료되면, 각 장면마다 승인된 음원을 결합하여 음원이 결합된 동영상 파일을 생성하는 단계를 수행하는 것을 특징으로 하는 배경 음원 추천 및 결합 시스템."}
{"patent_id": "10-2021-0146277", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제 8 항에 있어서, 상기 (a) 단계에서 상기 프로세서는,동영상에 포함된 각 프레임의 RGB 평균 픽셀 세기(Mean Pixel Intensity)를 구하고, 이전 프레임과 현재 프레임간의 RGB 평균 픽셀 세기의 차이가 사전에 정의된 임계치 이상이면 장면이 전환된 것으로 판단하여 동영상에 포함된 각 장면들을 검출하는 것을 특징으로 하는 배경 음원 추천 및 결합 시스템."}
{"patent_id": "10-2021-0146277", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제 8 항에 있어서, 상기 (b) 단계에서 상기 프로세서는 검출된 각 장면에 포함된 프레임들의 HSV(Hue Saturation Value) 데이터를 분석하여, 해당 장면의 주요 프레임이미지들을 저장하고, 주요 프레임 이미지에 포함된 인물들의 감정 리스트와 색 리스트를 생성하여 해당 프레임이미지를 대표하는 대표 감정 및 대표 색을 선정하고, 사전에 정의된 규칙에 따라서 대표 감정 및 대표 색에 대응되는 장르와 분위기를 갖는 음원을 추천하는 것을 특징으로 하는 배경 음원 추천 및 결합 시스템."}
{"patent_id": "10-2021-0146277", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제 10 항에 있어서, 상기 (b) 단계에서 상기 프로세서는상기 인공지능 모델을 이용하여 상기 주요 프레임 이미지들에서 인물의 얼굴을 검출하고, 얼굴의 표정을 인식하여, 인물의 감정 리스트를 생성하는 것을 특징으로 하는 배경 음원 추천 및 결합 시스템.공개특허 10-2023-0061735-4-청구항 12 제 11 항에 있어서, 상기 (b) 단계에서 상기 프로세서는상기 인공지능 모델을 이용하여 사전에 학습된 인물의 감정 항목(angry, disgusted, fearful, happy, neutral,sad, surprised)별로 상기 얼굴의 표정에서 인식된 점수를 부여하여 감정 리스트를 생성하고, 인식된 점수가 가장 높은 감정 항목을 해당 프레임 이미지의 대표 감정으로서 선정하는 것을 특징으로 하는 배경 음원 추천 및결합 시스템."}
{"patent_id": "10-2021-0146277", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제 12 항에 있어서, 상기 (b) 단계에서 상기 프로세서는하나의 주요 프레임 이미지에서 복수 인물의 얼굴이 검출된 경우에, 상기 인공지능 모델을 이용하여 복수 인물의 얼굴 각각에 대해서 감정 리스트를 생성하고,복수 인물의 감정 리스트의 각 항목별 평균을 계산하여, 평균 점수가 가장 높은 감정 항목을 해당 프레임 이미지의 대표 감정으로서 선정하는 것을 특징으로 하는 배경 음원 추천 및 결합 시스템."}
{"patent_id": "10-2021-0146277", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 배경 음원 추천 및 결합 시스템 및 방법을 공개한다. 본 발명은 사용자가 배경 음악 추천을 요청한 동 영상을 분석하여, 장면 단위로, 해당 장면에 포함된 인물들의 표정으로부터 인물들의 감정을 파악하여 해당 장면 의 대표 감정을 선정하고, 해당 장면의 색감을 파악하여 대표 색을 선정하며, 대표 감정과 대표 색에 따라서 적 합한 음원을 사용자에게 추천한 후, 사용자가 각 장면에 사용된 배경 음원의 결합을 승인하면, 동영상에 추천 음 원을 결합하고 동영상 파일로 생성하여 사용자에게 제공함으로써, 사용자의 개인적 취향에만 의존하지 않고, 동 영상의 특성에 적합한 다양한 음원을 동영상에 결합하여 제공할 수 있다."}
{"patent_id": "10-2021-0146277", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 음원 추천 시스템 및 방법에 관한 것으로서, 보다 구체적으로는 사용자가 입력한 동영상을 분석하여, 동영상에 적합한 음원을 추천하고 이를 동영상에 결합하여 제공하는 배경 음원 추천 및 결합 시스템 및 방법에 관한 것이다."}
{"patent_id": "10-2021-0146277", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "최근 유튜브, 인스타그램 등과 같은 동영상 플랫폼들이 활성화됨에 따라서 자신이 직접 생성한 동영상을 포스팅 하고, 이로부터 다양한 수익을 창출하고자 하는 시도들이 행해지고 있다. 이러한, 종래의 동영상 생성 방식들은 사용자가 스스로 카메라를 이용하여 동영상을 촬영하고, 동영상 편집 프 로그램을 이용하여 동영상의 장면들을 편집하며, 동영상 내부에 자막을 삽입하고, 음원 트랙에 사용자가 선택한 음악을 배경 음악으로 삽입하는 등의 작업을 거쳐서 하나의 동영상이 완성된다. 그러나, 이러한 방식은 사용자의 주관적인 선택에 의존하게 되고, 특히, 배경 음악의 선택은 동영상의 전체적인 분위기나 색감 등과 무관하게, 사용자가 선호하는 음악을 배경 음악으로 삽입하는 것이 일반적이다. 이러한 문제점으로 인해서, 사용자가 생성하는 동영상들에는 한정된 수의 배경음악이 반복적으로 사용되어, 사 용자가 운영하는 동영상 채널을 구독하거나 팔로우하는 다른 사용자들의 입장에서는 동영상의 참신함이 떨어지 고, 동영상 콘텐츠가 지루하게 느껴지며, 동영상을 생성하는 사용자의 입장에서는 이러한 문제점을 극복하기 위 해서, 배경 음악의 선정에 상당한 노력과 시간이 소요되어, 콘텐츠 생산 효율이 저하되는 문제점이 존재한다."}
{"patent_id": "10-2021-0146277", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명이 해결하고자 하는 과제는, 사용자가 배경 음악 추천을 요청한 동영상을 분석하여, 자연스러우면서도 동영상의 색감이나 인물들의 감정을 반영하는 배경 음원을 추천하고, 추천된 음원을 동영상에 결합하여 사용자 에게 제공할 수 있는, 배경 음원 추천 및 결합 시스템 및 방법을 제공하는 것이다."}
{"patent_id": "10-2021-0146277", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상술한 과제를 해결하기 위한 본 발명의 바람직한 실시예에 따른, 배경 음원 추천 및 결합 시스템에서 수행되는 배경 음원 추천 및 결합 방법은, (a) 배경 음원 추천 및 결합 시스템이, 사용자로부터 입력된 동영상을 사전에학습된 인공지능 모델에 적용하여, 동영상에 포함된 각 장면들을 검출하는 단계; (b) 상기 배경 음원 추천 및 결합 시스템의 상기 인공지능 모델이 각 장면에 대해서 추천 음원을 선정하는 단계; (c) 상기 배경 음원 추천 및 결합 시스템이 각 장면에 대한 추천 음원을, 해당 장면의 동영상과 함께 사용자에게 출력하고, 사용자로부터 승인 정보를 입력받는 단계; (d) 사용자가 승인하지 않은 장면에 대해서, 상기 배경 음원 추천 및 결합 시스템 이 상기 (b) 단계로 진행하여 다른 추천 음원을 선정하고 동영상과 함께 사용자에게 출력하는 단계; 및 (e) 모 든 장면에 대해서 음원 추천이 종료되면, 상기 배경 음원 추천 및 결합 시스템이, 각 장면마다 승인된 음원을 결합하여 음원이 결합된 동영상 파일을 생성하는 단계를 포함한다. 또한, 상기 (a) 단계는, 동영상에 포함된 각 프레임의 RGB 평균 픽셀 세기(Mean Pixel Intensity)를 구하고, 이 전 프레임과 현재 프레임간의 RGB 평균 픽셀 세기의 차이가 사전에 정의된 임계치 이상이면 장면이 전환된 것으 로 판단하여 동영상에 포함된 각 장면들을 검출할 수 있다. 또한, 상기 (b) 단계는, 검출된 각 장면에 포함된 프레임들의 HSV(Hue Saturation Value) 데이터를 분석하여, 해당 장면의 주요 프레임 이미지들을 저장하고, 주요 프레임 이미지에 포함된 인물들의 감정 리스트와 색 리스 트를 생성하여 해당 프레임 이미지를 대표하는 대표 감정 및 대표 색을 선정하고, 사전에 정의된 규칙에 따라서 대표 감정 및 대표 색에 대응되는 장르와 분위기를 갖는 음원을 추천할 수 있다. 또한, 상기 (b) 단계에서, 상기 인공지능 모델은 상기 주요 프레임 이미지들에서 인물의 얼굴을 검출하고, 얼굴 의 표정을 인식하여, 인물의 감정 리스트를 생성할 수 있다. 또한, 상기 (b) 단계에서, 상기 인공지능 모델은 사전에 학습된 인물의 감정 항목(angry, disgusted, fearful, happy, neutral, sad, surprised)별로 상기 얼굴의 표정에서 인식된 점수를 부여하여 감정 리스트를 생성하고, 인식된 점수가 가장 높은 감정 항목을 해당 프레임 이미지의 대표 감정으로서 선정할 수 있다. 또한, 상기 (b) 단계에서, 하나의 주요 프레임 이미지에서 복수 인물의 얼굴이 검출된 경우에, 상기 인공지능 모델은 복수 인물의 얼굴 각각에 대해서 감정 리스트를 생성하고, 복수 인물의 감정 리스트의 각 항목별 평균을 계산하여, 평균 점수가 가장 높은 감정 항목을 해당 프레임 이미지의 대표 감정으로서 선정할 수 있다. 한편, 상술한 과제를 해결하기 위한 본 발명의 바람직한 실시예에 따른 컴퓨터 프로그램은, 비일시적 저장매체 에 저장되고, 프로세서를 포함하는 컴퓨터에서 실행되어, 상기 배경 음원 추천 및 결합 방법을 수행한다. 한편, 상술한 과제를 해결하기 위한 본 발명의 바람직한 실시예에 따른 배경 음원 추천 및 결합 시스템은, 프로 세서 및 소정의 명령어들을 저장하는 메모리를 포함하는 배경 음원 추천 및 결합 시스템으로서, 상기 메모리에 저장된 명령어들을 실행한 상기 프로세서는 (a) 사용자로부터 입력된 동영상을 사전에 학습된 인공지능 모델에 적용하여, 동영상에 포함된 각 장면들을 검출하는 단계; (b) 상기 인공지능 모델을 이용하여 각 장면에 대해서 추천 음원을 선정하는 단계; (c) 각 장면에 대한 추천 음원을, 해당 장면의 동영상과 함께 사용자에게 출력하고, 사용자로부터 승인 정보를 입력받는 단계; (d) 사용자가 승인하지 않은 장면에 대해서, 상기 (b) 단 계로 진행하여 다른 추천 음원을 선정하고 사용자에게 동영상과 함께 출력하는 단계; 및 (e) 모든 장면에 대해 서 음원 추천이 종료되면, 각 장면마다 승인된 음원을 결합하여 음원이 결합된 동영상 파일을 생성하는 단계를 수행한다. 또한, 상기 (a) 단계에서 상기 프로세서는, 동영상에 포함된 각 프레임의 RGB 평균 픽셀 세기(Mean Pixel Intensity)를 구하고, 이전 프레임과 현재 프레임간의 RGB 평균 픽셀 세기의 차이가 사전에 정의된 임계치 이상 이면 장면이 전환된 것으로 판단하여 동영상에 포함된 각 장면들을 검출할 수 있다. 또한, 상기 (b) 단계에서, 상기 프로세서는, 검출된 각 장면에 포함된 프레임들의 HSV(Hue Saturation Value) 데이터를 분석하여, 해당 장면의 주요 프레임 이미지들을 저장하고, 주요 프레임 이미지에 포함된 인물들의 감 정 리스트와 색 리스트를 생성하여 해당 프레임 이미지를 대표하는 대표 감정 및 대표 색을 선정하고, 사전에 정의된 규칙에 따라서 대표 감정 및 대표 색에 대응되는 장르와 분위기를 갖는 음원을 추천할 수 있다. 또한, 상기 (b) 단계에서, 상기 프로세서는, 상기 인공지능 모델을 이용하여 상기 주요 프레임 이미지들에서 인 물의 얼굴을 검출하고, 얼굴의 표정을 인식하여, 인물의 감정 리스트를 생성할 수 있다. 또한, 상기 (b) 단계에서, 상기 프로세서는, 상기 인공지능 모델을 이용하여 사전에 학습된 인물의 감정 항목 (angry, disgusted, fearful, happy, neutral, sad, surprised)별로 상기 얼굴의 표정에서 인식된 점수를 부여 하여 감정 리스트를 생성하고, 인식된 점수가 가장 높은 감정 항목을 해당 프레임 이미지의 대표 감정으로서 선 정할 수 있다.또한, 상기 (b) 단계에서, 상기 프로세서는, 하나의 주요 프레임 이미지에서 복수 인물의 얼굴이 검출된 경우에, 상기 인공지능 모델을 이용하여 복수 인물의 얼굴 각각에 대해서 감정 리스트를 생성하고, 복수 인물의 감정 리스트의 각 항목별 평균을 계산하여, 평균 점수가 가장 높은 감정 항목을 해당 프레임 이미지의 대표 감 정으로서 선정할 수 있다."}
{"patent_id": "10-2021-0146277", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명은 사용자가 배경 음악 추천을 요청한 동영상을 분석하여, 장면 단위로, 해당 장면에 포함된 인물들의 표정으로부터 인물들의 감정을 파악하여 해당 장면의 대표 감정을 선정하고, 해당 장면의 색감을 파악하여 대표 색을 선정하며, 대표 감정과 대표 색에 따라서 적합한 음원을 사용자에게 추천한 후, 사용자가 각 장면에 사용 된 배경 음원의 결합을 승인하면, 원본 동영상에 추천 음원을 결합하여 동영상 파일로 생성한 후, 이를 사용자 에게 제공함으로써, 사용자의 개인적 취향에만 의존하지 않고, 동영상의 특성에 적합한 다양한 음원을 동영상에 결합하여 제공할 수 있다."}
{"patent_id": "10-2021-0146277", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 첨부된 도면들을 참고하여 본 발명의 바람직한 실시예를 설명한다. 여기서, 본 발명의 상술한 목적, 특징들 및 장점은 첨부된 도면과 관련된 다 음의 상세한 설명을 통해 보다 분 명해질 것이다. 다만, 본 발명은 다양한 변경을 가할 수 있고 여러가지 실시예들을 가질 수 있는 바, 이하에서 는 특정 실시예들을 도면에 예시하고 이를 상세히 설명하고자 한다. 도면들에 있어서, 층 및 영역들의 두께는 명확성을 기하기 위하여 과장되어진 것이며, 또한, 구성요소(element) 또는 층이 다른 구성요소 또는 층의 \"위(on)\" 또는 \"상(on)\"으로 지칭되는 것은 다른 구성요소 또는 층의 바로 위 뿐만 아니라 중간에 다른 층 또는 다른 구성요소를 개재한 경우를 모두 포함한다. 명세서 전체에 걸쳐서 동 일한 참조번호들은 원칙적으로 동일한 구성요소들을 나타낸다. 또한, 각 실시예의 도면에 나타나는 동일한 사상 의 범위 내의 기능이 동일한 구성요소는 동일한 참조부호를 사용하여 설명한다. 본 발명과 관련된 공지 기능 또는 구성에 대한 구체적인 설명이 본 발명의 요지를 불필요하게 흐릴 수 있다고 판단되는 경우 그 상세한 설명을 생략한다. 또한, 본 명세서의 설명 과정에서 이용되는 숫자(예를 들어, 제 1, 제 2 등)는 하나의 구성요소를 다른 구성요소와 구분하기 위한 식별기호에 불과하다. 도 1은 본 발명의 바람직한 실시예에 따른 배경 음원 추천 및 결합 시스템의 전체 구성을 도시하는 도면이 다. 도 1을 참조하면, 본 발명의 바람직한 실시예에 따른 배경 음원 추천 및 결합 시스템은 유무선 통신망을 통해서 복수의 사용자 단말들 및 음원 서버와 연결된다. 본 발명의 바람직한 실시예에 따른 배경 음원 추천 및 결합 시스템은 통신부, 프로세서, 메모리 및 음원 DB(DataBase)를 포함한다. 통신부는 유무선 통신망을 통해서 사용자 단말 및 음원 서버와 통신을 수행하여, 사용자 단말 로부터 음원을 결합할 원본 동영상을 수신하고, 본 발명에 따라서 음원이 결합된 동영상 파일을 사용자 단 말로 전송한다. 또한, 통신부는 음원 서버와 통신을 수행하여, 음원 서버로부터 동영상에 결합할 음원을 수신하여 음원 DBdp 저장할 수 있다. 또한, 통신부는 음원을 원본 동영상에 결합하기 전에, 실시간 스트리밍 방식으로, 사용자 단말로 동 영상을 재생 출력하는 동시에 추천 음원을 함께 재생 출력함으로써 사용자에게 추천 음원의 결합 여부에 대한 승인을 구할 수 있다. 음원 DB는 본 발명의 바람직한 실시예에 따라서 동영상에 삽입될 음원 데이터들을 저장하며, 메모리 와 물리적으로 통합되어 구현될 수도 있다. 또한, 본 발명의 바람직한 실시예에 따른 메모리는 프로세서에 의해 실행 가능한 명령어들, 및 프로 세서에 의해 실행되는 프로그램들을 저장할 수 있고, 입/출력되는 데이터들을 저장할 수도 있다. 여기서, 메모리는 음원 DB와 통합되어 물리적으로 구현될 수도 있다. 본 발명의 바람직한 실시예에 따른 프로세서는 메모리 저장된 명령어들을 실행함으로써, 도 2를 참조 하여 후술하는 배경 음원 추천 및 결합 방법의 각 단계를 수행한다. 메모리는 인터넷(internet)상에서 저 장 매체의 기능을 수행하는 웹 스토리지(web storage) 또는 클라우드 서버로 대체 운영될 수도 있다. 한편, 본 발명의 프로세서는 메모리에 저장된 본 발명의 배경 음원 추천 및 결합 방법을 실행하기 위 한 프로그램이 프로세서 내부로 로딩되어 실행되면, 기능적으로 인공지능 모델, 결합부 및 제어 부가 내부에 구현된다. 여기서, 인공지능 모델, 결합부 및 제어부는 하드웨어적인 물리적 구성이 아니라, 소프트웨어적으로 프로세서에 의해서 구현되는 기능적 구성임을 주의해야 한다. 인공지능 모델은 영상 처리에 특화된 CNN(Convolution Neural Network)로 구현되고, 사전에 학습되어 동 영상에서 장면들을 검출하고, 각 장면을 대표하는 주요 프레임 이미지를 메모리에 저장한다. 또한, 인공지 능 모델은 주요 프레임 이미지에서 인물들의 얼굴 표정을 인식하여 해당 장면에 포함된 인물들의 대표 감 정을 선정하고, 주요 프레임 이미지에서 대표 색을 선정하여, 대표 감정 및 대표 색에 대응되는 장르와 분위기 를 갖는 추천 음원을 선정한다. 결합부는 원본 동영상의 각 장면에 사용자가 승인한 음원을 결합하여 인코딩함으로써, 음원이 결합된 동영 상 파일을 생성하여, 통신부를 통해서 사용자 단말로 제공한다. 제어부는 배경 음원 추천 및 결합 시스템에 포함된 상기한 구성 요소들의 전반적인 기능을 제어한다. 도 2는 본 발명의 바람직한 실시예에 따른 배경 음원 추천 및 결합 방법을 설명하는 흐름도이고, 도 3은 도 2에 도시된 제 S200 단계를 상세하게 설명하는 흐름도이다. 도 2 및 도 3에 도시된 배경 음원 추천 및 결합 방법은, 도 1에 도시된 배경 음원 추천 및 결합 시스템에 서 수행되는 것으로서, 이하, 도 2 및 도 3을 더 참조하여, 본 발명의 바람직한 실시예에 따른 배경 음원 추천 및 결합 시스템 및 방법을 함께 더 구체적으로 설명한다. 도 2 및 도 3을 참조하면, 사용자 단말은, 본 발명의 서비스를 이용하여 음원을 추천받고, 추천 받은 음원 이 결합된 동영상을 제공받고자 하는 원본 동영상을 배경 음원 추천 및 결합 시스템으로 전송하고, 배경 음원 추천 및 결합 시스템의 통신부는 이를 수신하여 프로세서로 출력하고, 프로세서는 이 를 메모리에 저장한다(S100). 제 S100 단계에서, 원본 동영상은 USB 메모리(미도시 됨)에 저장된 상태에서 프로세서로 판독될 수도 있다. 프로세서는 수신된 동영상을 사전에 학습된 인공지능 모델에 적용하여 동영상에 포함된 각 장면들을 검출하고, 검출된 각 장면에 대해서 메모리에 저장되거나 음원 서버에 저장된 음원들 중 추천 음원을 선정한다(S200). 추천 음원을 선정하는 제 S200 단계에 대해서는, 도 3을 참조하여 후술한다. 각 장면에 대해서 추천 음원이 선정되면, 프로세서는 각 장면마다 추천 음원과 동영상을 함께 재생하여 사 용자 단말로 제공하고(S300), 사용자 단말로부터 각 장면에 추천된 음원을 결합할지 여부에 대해서 승인 정보를 수신한다(S400). 승인 정보를 수신한 결과, 프로세서는 사용자 단말이 모든 장면에 대해서 추천 음원의 결합을 승인하 였는지 여부를 확인하고(S500), 모든 장면에 대해서 승인한 경우에는, 장면마다 추천 음원을 동영상과 결합하여 인코딩함으로써 음원이 결합된 동영상 파일을 생성한다(S600). 그러나, 사용자가 불승인한 장면이 존재하면, 사용자가 승인하지 않은 장면에 대해서, 상기 S200 단계로 진행하 여, 다른 추천 음원을 선정하고(S200), 각 장면마다 추천된 음원과 동영상을 함께 재생하여 사용자 단말로 출력하고(S300), 사용자 단말로부터 해당 장면에 추천된 음원을 결합할지 여부에 대해서 승인 정보를 수신 한다(S400). 승인 정보를 수신한 결과, 사용자 단말이 모든 장면에 대해서 추천 음원의 결합을 승인하면(S500), 장면마 다 추천 음원을 동영상과 결합하여 인코딩함으로써 음원이 결합된 동영상 파일을 생성한다(S600).이 때, 사용자는 특정 장면에 대해서 음원을 결합하지 않을 것을 결정할 수 있고, 음원을 결합하지 않을 것으로 결정된 장면에 대해서는 상술한 제 S200 단계 내지 제 S600 단계가 수행되지 않을 수 있다. 한편, 도 3을 참조하여, 동영상의 각 장면마다 추천 음원을 선정하는 단계(S200)를 보다 상세하게 설명하면, 먼 저, 프로세서는 사용자 단말로부터 수신한 동영상을 인공지능 모델에 적용하여 동영상에 포함된 장면들을 검출한다(S210). 본 발명의 인공지능 모델은 학습된 다양한 방식에 따라서 동영상 내의 장면 변화를 검출할 수 있는데, 본 발명의 바람직한 실시예에서는 인공지능 모델이 동영상에 포함된 각 프레임마다 RGB 평균 픽셀 세기(Mean Pixel Intensity)를 구하고, 이전 프레임과 현재 프레임간의 RGB 평균 픽셀 세기의 차이가 사전에 정의된 임계 치 이상이면 장면이 전환된 것으로 판단하여 동영상에 포함된 각 장면들을 검출한다. 예컨대, 맑은 날에서 인물들이 대화하는 장면에서는 영상 프레임들의 RGB 평균 픽셀 세기(Mean Pixel Intensity)가 높은 값으로 나타나지만, 장면이 전환되어 어두운 밤에 인물들이 대화하는 장면에서는 영상 프레 임들의 RGB 평균 픽셀 세기(Mean Pixel Intensity)가 크게 떨어지게 된다. 따라서, 인공지능 모델은 영상 프레임간 RGB 평균 픽셀 세기(Mean Pixel Intensity)의 차이를 임계치와 비교하여 장면의 전환 여부를 확인하고, 동영상에 포함된 장면들을 검출할 수 있다. 그 후, 인공지능 모델은 각 장면마다 장면의 주요 프레임 이미지를 하나 이상 메모리에 저장한다 (S220). 주요 프레임 이미지를 선정하는 방식은 다양하게 적용될 수 있으나, 본 발명의 바람직한 실시예는, 각 장면에 포함된 프레임들의 HSV(Hue Saturation Value) 데이터를 분석하여 주요 프레임 이미지를 선정하였다. 즉, 각 장면에 포함되는 각 프레임마다 HSV 값을 구하고, 직전 프레임의 HSV 값과 비교하여 사전에 정의된 임계 치 이상의 변화가 발생하면, 해당 프레임을 주요 프레임 이미지로서 저장할 수 있다. 그 후, 인공지능 모델은 주요 프레임 이미지에 포함된 인물들의 감정 리스트와 색 리스트를 생성하여 해당 장면을 대표하는 대표 감정 및 대표 색을 선정한다(S). 이를 위해서, 인공지능 모델은 주요 프레임 이미지에서 인물들의 얼굴을 검출하고, 얼굴 표정을 인식하여, 인물의 감정 리스트를 생성한다. 인공지능 모델은 사전에 학습된 인물의 감정 항목(angry, disgusted, fearful, happy, neutral, sad, surprised)별로 상기 얼굴의 표정에서 인식된 점수를 부여하여 감정 리스트를 생성하고, 인식된 점수가 가장 높 은 감정 항목을 해당 프레임 이미지의 대표 감정으로서 선정한다. 예를 들어, 주요 프레임 이미지에서 검출된 얼굴 표정에 대해서 각 감정 항목별로 인식된 점수를 부여하였을 때, (angry, disgusted, fearful, happy, neutral, sad, surprised)=(0.1, 0.1, 0.2, 0.9, 0.4, 0.2, 0.3) 와 같이 감정 리스트가 생성되었다면, 인식 항목 점수가 가장 높은 0.9에 대응되는 happy가 해당 프레임 이미지를 대표하는 감정이 된다. 만약, 주요 프레임 이미지에서 검출된 인물의 얼굴이 복수개(예컨대 2개)라면, 각 인물의 얼굴에 대해서 표정을 인식하여 감정 리스트를 생성하고, 복수 인물의 감정 리스트의 각 항목별 평균을 계산하여, 평균 점수가 가장 높은 감정 항목을 해당 프레임 이미지의 대표 감정으로서 선정한다. 상기 예에서, 인물 1의 감정 리스트는 (angry, disgusted, fearful, happy, neutral, sad, surprised)=(0.1, 0.1, 0.2, 0.9, 0.4, 0.2, 0.3)와 같고, 인물 2의 감정 리스트는 (angry, disgusted, fearful, happy, neutral, sad, surprised)=(0.1, 0.1, 0.2, 0.5, 0.4, 0.2, 0.7)와 같다면, 인물들의 감정 리스트의 평균은 (angry, disgusted, fearful, happy, neutral, sad, surprised)=(0.1, 0.1, 0.2, 0.7, 0.4, 0.2, 0.5)와 같고, 따라서 평균값이 가장 큰 감정 항목 \"happy\"가 주요 프레임 이미지의 대표 감정이 되고, 해당 장면에 주 요 프레임 이미지가 하나인 경우에는, 해당 주요 프레임 이미지의 대표 감정이 해당 장면의 대표 감정이 된다. 동일한 방식으로, 하나의 장면에 복수의 주요 프레임 이미지가 존재하는 경우에는, 각 프레임 이미지별로 감정 리스트를 생성하고, 각 주요 프레임 이미지의 감정 리스트 항목별로 평균을 구하여, 평균 값이 가장 큰 감정 항 목을 해당 장면의 대표 감정으로서 선정한다. 한편, 인공지능 모델은 각 주요 프레임 이미지에서 색 리스트를 생성하여 주요 프레임 이미지의 색감을 나 타내는 대표 색을 추출한다. 이를 위해서, 인공지능 모델은 주요 프레임 이미지의 각 화소의 R,G,B값을 구 하고, 전체 화소에 대해서 R, G, B 별로 합산하여 가장 큰 값을 해당 주요 프레임 이미지의 대표 색으로 추출한 다. 이 때, 장면에 주요 프레임 이미지가 하나만 포함된 경우에는 해당 주요 프레임 이미지의 대표 색을 장면의대표 색으로서 선정하고, 장면에 주요 프레임 이미지가 복수개 포함된 경우에는, 각 주요 프레임 이미지의 전체 R, G, B 값을 합산하여, R, G, B 중 가장 큰 값을 나타내는 색을 장면의 대표 색으로서 선정한다. 상기한 과정을 통해서 장면의 대표 감정과 대표 색이 선정되면, 인공지능 모델은 장면의 길이에 따라서 1 차적으로 해당 장면에 추천될 복수의 음원들을 선별하고(S240), 선별된 음원들 중에서 대표 감정과 대표 색에 대응되는 장르와 분위기를 갖는 추천 음원을 최종적으로 선정한다(S250). 예를 들면, 장면의 대표 감정이 \"슬픔\"이고, 대표 색이 \"블루(B)\"인 경우에는, 단조(마이너)이면서, 느린 템포 를 갖는, 차가운 느낌의 음색을 갖는 음원을 추천 음원으로서 선정한다. 또한, 장면의 대표 감정이 \"기쁨\"이고, 대표 색이 \"레드(R)\"인 경우에는, 장조(메이저)이면서, 중간템포를 갖는 부드러운 느낌의 음색을 갖는 음원을 추천 음원으로서 선정할 수 있다. 이 때, 인공지능 모델은 음원 DB에 저장된 음원들 중에서 적합한 음원을 선정할 수 있고, 음원 DB에 적합한 음원이 없는 경우에는, 음원 서버에 저장된 음원들 중에서 적합한 음원을 선정하고, 선 정된 음원을 음원 서버로부터 다운로드할 수도 있다. 지금까지 설명한 본 발명의 바람직한 실시예에 따른, 배경 음원 추천 및 결합 방법은, 컴퓨터에서 실행가능한 명령어로 구현되어 비일시적 저장매체에 저장된 컴퓨터 프로그램으로 구현될 수 있다. 저장매체는 컴퓨터 시스템에 의하여 읽혀질 수 있는 데이터가 저장되는 모든 종류의 기록장치를 포함한다. 컴퓨터가 읽을 수 있는 저장매체의 예로는 ROM, RAM, CD-ROM, 자기 테이프, 플로피디스크, 광데이터 저장장치 등이 있다. 또한 컴퓨터가 읽을 수 있는 저장매체는 네트워크로 연결된 컴퓨터 시스템에 분산되어, 분산 방식으로 컴퓨터가 읽을 수 있는 코드가 저장되고 실행될 수 있다. 이제까지 본 발명에 대하여 그 바람직한 실시예들을 중심으로 살펴보았다. 본 발명이 속하는 기술 분야에서 통 상의 지식을 가진 자는 본 발명이 본 발명의 본질적인 특성에서 벗어나지 않는 범위에서 변형된 형태로 구현될 수 있음을 이해할 수 있을 것이다. 그러므로 개시된 실시예들은 한정적인 관점이 아니라 설명적인 관점에서 고 려되어야 한다. 본 발명의 범위는 전술한 설명이 아니라 특허청구범위에 나타나 있으며, 그와 동등한 범위 내 에 있는 모든 차이점은 본 발명에 포함된 것으로 해석되어야 할 것이다."}
{"patent_id": "10-2021-0146277", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 바람직한 실시예에 따른 배경 음원 추천 및 결합 시스템의 전체 구성을 도시하는 도면이다. 도 2는 본 발명의 바람직한 실시예에 따른 배경 음원 추천 및 결합 방법을 설명하는 흐름도이다. 도 3은 도 2에 도시된 제 S200 단계를 상세하게 설명하는 흐름도이다."}
