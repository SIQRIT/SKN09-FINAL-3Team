{"patent_id": "10-2021-0179783", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0090739", "출원번호": "10-2021-0179783", "발명의 명칭": "이철동음어 인식 시스템", "출원인": "콜넷코리아", "발명자": "유현재"}}
{"patent_id": "10-2021-0179783", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "이철동음어의 인식 시스템에 있어서,화자의 음성을 분석하여 상기 음성에 대하여 텍스트를 전사하는 이철동음어 전사부;이철동음발음 모델을 이용하여 상기 텍스트에 속하는 이철동음어를 인식하는 이철동음어 인식부;를 포함하는 이철동음어 인식 시스템."}
{"patent_id": "10-2021-0179783", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 이철동음어 인식 시스템은,이철동음발음 모델을 이용하여 상기 텍스트에 있는 상기 이철동음어를 문맥에 맞는 단어로 수정하는 이철동음어수정부를 더 포함하는 것인, 이철동음어 인식 시스템."}
{"patent_id": "10-2021-0179783", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 1항에 있어서,상기 이철동음어 전사부는,복수의 표제어 각각에 대응하는 용례를 수집하는 이철동음어 수집부를 포함하되,상기 이철동음어 수집부는 상기 이철동음어에 대응하는 상기 복수의 표제어를 추출하는 것인, 이철동음어 인식시스템."}
{"patent_id": "10-2021-0179783", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서,상기 이철동음어 수집부는,상기 표제어 각각을 한국어 문법 기초로 복수의 이철동음어 유형별로 나누되, 상기 용례를 수집하고, 화자의 단말 및 기 설정된 녹음 파일을 기반으로 상기 용례를 개별적으로 녹화하여 음성데이터베이스에 복수의음성데이터를 저장하는 것인, 이철동음어 인식 시스템."}
{"patent_id": "10-2021-0179783", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서,상기 이철동음어 전사부는,상기 음성데이터베이스에 저장된 상기 음성데이터로부터 상기 음성데이터의 각각으로 음성 특징에 관한 음성벡터 인자를 추출하는 음성데이터 추출부;기 훈련된 텍스트 전사 인공지능 모델을 이용하여 상기 음성데이터베이스에 저장된 상기 음성데이터를 상기 텍스트로 전사하는 텍스트 전사부,를 포함하는 이철동음어 인식 시스템."}
{"patent_id": "10-2021-0179783", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서,공개특허 10-2023-0090739-3-상기 이철동음어 인식부는,상기 텍스트를 복수의 원시문장으로서 전처리하여 기 훈련된 인공지능 유추단어 예측 모델이 학습하도록 상기원시문장을 전처리 하는 이철동음어 전처리부를 포함하는 것인, 이철동음어 인식 시스템."}
{"patent_id": "10-2021-0179783", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6항에 있어서,상기 이철동음어 전처리부는,한국어 발음사전을 이용하여 상기 원시문장의 각각에서 이철동음어 유무를 파악하되,상기 원시문장 내에 있는 상기 이철동음어를 유추단어로 치환하여 학습문장을 생성하는 것인, 이철동음어 인식시스템."}
{"patent_id": "10-2021-0179783", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서,상기 이철동음어 전처리부는,상기 학습문장의 각각에 대하여 문장의 시작하는 부분에 시작 시점과 문장이 끝나는 부분에 끝 시점을 표시하는것인, 이철동음어 인식 시스템."}
{"patent_id": "10-2021-0179783", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서,상기 이철동음어 전처리부는,상기 원시문장을 각각 어절 단위로 분리하되, 상기 어절 내에 있는 복수의 문자들을 각각 복수의 형태소로 분리하는 것인, 이철동음어 인식 시스템."}
{"patent_id": "10-2021-0179783", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9항에 있어서,상기 이철동음어 전처리부는,상기 형태소에서 첫번째 형태소는 그대로 두되, 두번째 형태소부터는 각각의 형태소 앞에 구분문자를 표시하는것인, 이철동음어 인식 시스템."}
{"patent_id": "10-2021-0179783", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제10항에 있어서,상기 이철동음어 전처리부는,문자의 개수 기반으로 시작 시점과 끝 시점 사이에 서 최대 문장 길이를 설정하는 것인, 이철동음어 인식 시스템."}
{"patent_id": "10-2021-0179783", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제1항에 있어서,상기 이철동음어 인식부는, 기 훈련된 유추단어 예측 모델에 복수의 방법으로 유추단어를 전처리한 학습문장을 기 훈련된 인공지능 유추단어 예측 모델에 학습시켜 이철동음발음 모델을 복수로 생성하는 이철동음어 학습부를 더 포함하는 것인, 이철동음어 인식 시스템."}
{"patent_id": "10-2021-0179783", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제12항에 있어서,공개특허 10-2023-0090739-4-상기 기 훈련된 인공지능 유추단어 예측 모델은 기 훈련된BERT인공지능 학습 모델 인 것인, 이철동음어 인식 시스템."}
{"patent_id": "10-2021-0179783", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제 4항에 있어서,상기 이철동음어 수집부는, 복수의 수집 용례에서 중복된 용례를 제거하는 전처리를 하는 것인, 이철동음어 인식 시스템."}
{"patent_id": "10-2021-0179783", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제4항에 있어서,텍스트 전사부는, 기 훈련된 텍스트 전사 인공지능 모델을 이용하여 음성데이터베이스에 저장된 복수의 음성데이터를 각각 텍스트로 전사하는 것인, 이철동음어 인식 시스템."}
{"patent_id": "10-2021-0179783", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "이철동음어의 인식 방법에 있어서,화자의 음성을 분석하여 상기 음성에 대하여 텍스트를 전사하는 단계;이철동음발음 모델을 이용하여 상기 텍스트에 속하는 이철동음어를 인식하는 단계;를 포함하는 이철동음어 인식 방법."}
{"patent_id": "10-2021-0179783", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제16항의 방법을 컴퓨터에서 실행하기 위한 프로그램을 기록한 컴퓨터에서 판독 가능한 기록 매체."}
{"patent_id": "10-2021-0179783", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "이철동음어의 인식 시스템에 있어서, 화자의 음성을 분석하여 상기 음성 기반으로 텍스트를 전사하는 이철동음어 전사부; 이철동음발음 모델을 이용하여 상기 텍스트에 속하는 이철동음어를 인식하는 이철동음어 인식부; 를 포 함하는 이철동음어 인식 시스템을 개시한다."}
{"patent_id": "10-2021-0179783", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본원은 이철동음어 인식 장치 및 방법에 관한 것이다."}
{"patent_id": "10-2021-0179783", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "음성인식의 관련 연구는 기존 음성인식 시스템의 이철동음어 인식에 다양한 방법을 제안하고 있다. 이철동음어 를 인식하는 방법은 통계적 기법과 신경망을 이용한 방법이 있다. 통계적 기법은 빈도수에 의존하는 방법으로 빈도수가 작거나 어휘사전에 등록되지 않은 단어는 인식률이 현저하 게 떨어지는 문제점이 있다. 또한, 기존 음성인식 시스템은 DNN-HMM 모델의 하이브리드 방법으로 n-gram 방식의 언어모델을 많이 사용한다. 언어모델 n-gram 방식은 단어의 출현 빈도수에 따라 후보 단어를 선택한다. 이러한 방식은 이철동음어를 인식하 는 방법에도 그대로 적용되어 출현 빈도수가 높은 단어를 우선 선택하는 결과를 보여준다. 따라서 출현 빈도수 가 적은 단어나 어휘사전에 등록되지 않은 단어는 음성인식 과정에서 잘못된 단어로 인식하는 결과를 낳는다. 발음 사전을 활용한 방법에 관한 연구로서 음운변동으로 인한 음성인식의 성능개선 노력에도 음운변동의 영향으 로 발생하는 이철동음어 인식률은 여전히 낮았다. 즉,\"열매도 많이 열리고 잎도 많이 자랐다\"라는 입력 문장에 대하여 \"열매도 많이 열리고 입도 많이 자랐다\"라고 출력하여 이철동음어 \"입\" 과 \"잎\"의 구별을 명확하게 인 식하지 못하는 문제가 있다. 본원의 배경이 되는 기술은 일본특허공개공보 2000-293189호에 개시되어 있다."}
{"patent_id": "10-2021-0179783", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 2, "content": "발명의 내용"}
{"patent_id": "10-2021-0179783", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본원은 전술한 종래 기술의 문제점을 해결하기 위한 것으로서, 음운변동의 영향으로 발생하는 낮은 이철동음어 인식율을 높이는 시스템 및 방법에 대한 제공을 목적으로 한다. 본원은 전술한 종래 기술의 문제점을 해결하기 위한 것으로서, 기존 통계기반 언어모델의 문제점을 개선하기 위 하여 통계에 의한 방법이 아닌 확률 함수를 이용하여 이철동음어를 인식하는 인공지능 학습법을 제공하는 것을 목적으로 한다. 본원은 전술한 종래 기술의 문제점을 해결하기 위한 것으로서, 인공지능 학습의 계산 비용이 많다는 단점을 해 결하기 위하여 이철동음어만 학습하는 모델을 생성하고 적용함으로써, 본원은 인공지능 학습의 단점을 보완하고 이철동음어 인식의 속도와 성능을 개선 하는 것을 목적으로 한다. 다만, 본원의 실시 예가 이루고자 하는 기술적 과제는 상기된 바와 같은 기술적 과제들도 한정되지 않으며, 또 다른 기술적 과제들이 존재할 수 있다."}
{"patent_id": "10-2021-0179783", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기한 기술적 과제를 달성하기 위한 기술적 수단으로서, 본원의 일 실시 예에 따른 이철동음어의 인식 시스템 은, 화자의 음성을 분석하여 상기 음성에 대하여 텍스트를 전사하는 이철동음어 전사부, 이철동음발음 모델을 이용하여 상기 텍스트에 속하는 이철동음어를 인식하는 이철동음어 인식부를 포함할 수 있다. 또한, 본원의 일 실시 예에 따르면, 상기 이철동음어 인식 시스템은 이철동음발음 모델을 이용하여 상기 텍스트 에 있는 상기 이철동음어를 문맥에 맞는 단어로 수정하는 이철동음어 수정부를 더 포함할 수 있다. 또한, 본원의 일 실시 예에 따르면, 상기 이철동음어 전사부는 복수의 표제어 각각에 대응하는 용례를 수집하는 이철동음어 수집부를 포함하되, 상기 이철동음어 수집부는 상기 이철동음어에 대응하는 상기 복수의 표제어를 추출할 수 있다. 또한, 본원의 일 실시 예에 따르면, 상기 이철동음어 수집부는 상기 표제어 각각을 한국어 문법 기초로 복수의 이철동음어 유형별로 나누되, 상기 용례를 수집하고, 화자의 단말 및 기 설정된 녹음 파일을 기반으로 상기 용 례를 개별적으로 녹화하여 음성데이터베이스에 복수의 음성데이터를 저장할 수 있다. 또한, 본원의 일 실시 예에 따르면, 상기 이철동음어 전사부는 상기 음성데이터베이스에 저장된 상기 음성데이 터로부터 상기 음성데이터의 각각으로 음성 특징에 관한 음성벡터 인자를 추출하는 음성데이터 추출부, 기 훈련 된 텍스트 전사 인공지능 모델을 이용하여 상기 음성데이터베이스에 저장된 상기 음성데이터를 상기 텍스트로 전사하는 텍스트 전사부를 포함할 수 있다. 또한, 본원의 일 실시 예에 따르면, 상기 이철동음어 인식부는 상기 텍스트를 복수의 원시문장으로서 전처리하 여 기 훈련된 인공지능 유추단어 예측 모델이 학습하도록 상기 원시문장을 전처리 하는 이철동음어 전처리부를 포함할 수 있다. 또한, 본원의 일 실시 예에 따르면, 상기 이철동음어 전처리부는 한국어 발음사전을 이용하여 상기 원시문장의 각각에서 이철동음어 유무를 파악하되, 상기 원시문장 내에 있는 상기 이철동음어를 유추단어로 치환하여 학습 문장을 생성할 수 있다. 또한, 본원의 일 실시 예에 따르면, 상기 이철동음어 전처리부는 상기 학습문장의 각각에 대하여 문장의 시작하 는 부분에 시작 시점과 문장이 끝나는 부분에 끝 시점을 표시할 수 있다. 또한, 본원의 일 실시 예에 따르면, 상기 이철동음어 전처리부는 상기 원시문장을 각각 어절 단위로 분리하되, 상기 어절 내에 있는 복수의 문자들을 각각 복수의 형태소로 분리할 수 있다. 또한, 본원의 일 실시 예에 따르면, 상기 이철동음어 전처리부는 상기 형태소에서 첫번째 형태소는 그대로 두되, 두번째 형태소부터는 각각의 형태소 앞에 구분문자를 표시할 수 있다. 또한, 본원의 일 실시 예에 따르면, 상기 이철동음어 전처리부는 문자의 개수 기반으로 시작 시점과 끝 시점 사이에 서 최대 문장 길이를 설정할 수 있다. 또한, 본원의 일 실시 예에 따르면, 상기 이철동음어 인식부는 기 훈련된 유추단어 예측 모델에 복수의 방법으 로 유추단어를 전처리한 학습문장을 기 훈련된 인공지능 유추단어 예측 모델에 학습시켜 이철동음발음 모델을복수로 생성하는 이철동음어 학습부를 더 포함할 수 있다. 또한, 본원의 일 실시 예에 따르면, 상기 기 훈련된 인공지능 유추단어 예측 모델은 기 훈련된BERT인공지능 학 습 모델일 수 있다. 또한, 본원의 일 실시 예에 따르면, 상기 이철동음어 수집부는 복수의 수집 용례에서 중복된 용례를 제거하는 전처리를 할 수 있다. 또한, 본원의 일 실시 예에 따르면, 텍스트 전사부는 기 훈련된 텍스트 전사 인공지능 모델을 이용하여 음성데 이터베이스에 저장된 복수의 음성데이터를 각각 텍스트로 전사할 수 있다. 또한, 본원의 일 실시 예에 따르면, 이철동음어의 인식 방법은 화자의 음성을 분석하여 상기 음성에 대하여 텍 스트를 전사하는 단계; 이철동음발음 모델을 이용하여 상기 텍스트에 속하는 이철동음어를 인식하는 단계; 를 포함할 수 있다. 상술한 과제 해결 수단은 단지 예시적인 것으로서, 본원을 제한하려는 의도로 해석되지 않아야 한다. 상술한 예시적인 실시 예 외에도, 도면 및 발명의 상세한 설명에 추가적인 실시 예가 존재할 수 있다."}
{"patent_id": "10-2021-0179783", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "전술한 본원의 과제 해결 수단에 의하면, 한국어 이철동음어의 음성인식 방법을 제공함으로써 한국어 음성인식 시스템의 성능을 개선시키는 효과가 있다. 다만, 본원에서 얻을 수 있는 효과는 상기된 바와 같은 효과들로 한정되지 않으며, 또 다른 효과들이 존재할 수 있다."}
{"patent_id": "10-2021-0179783", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "아래에서는 첨부한 도면을 참조하여 본원이 속하는 기술 분야에서 통상의 지식을 가진 자가 용이하게 실시할 수 있도록 본원의 실시예를 상세히 설명한다. 그러나 본원은 여러 가지 상이한 형태로 구현될 수 있으며 여기에서 설명하는 실시예에 한정되지 않는다. 그리고 도면에서 본원을 명확하게 설명하기 위해서 설명과 관계없는 부분 은 생략하였으며, 명세서 전체를 통하여 유사한 부분에 대해서는 유사한 도면 부호를 붙였다. 본원 명세서 전체에서, 어떤 부분이 다른 부분과 \"연결\"되어 있다고 할 때, 이는 \"직접적으로 연결\"되어 있는 경우뿐 아니라, 그 중간에 다른 소자를 사이에 두고 \"전기적으로 연결\"되어 있는 경우도 포함한다. 본원 명세서 전체에서, 어떤 부재가 다른 부재 \"상에\", \"상부에\", \"상단에\", \"하에\", \"하부에\", \"하단에\" 위치 하고 있다고 할 때, 이는 어떤 부재가 다른 부재에 접해 있는 경우뿐 아니라 두 부재 사이에 또 다른 부재가 존 재하는 경우도 포함한다. 본원 명세서 전체에서, 어떤 부분이 어떤 구성요소를 \"포함\" 한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다른 구성요소를 제외하는 것이 아니라 다른 구성 요소를 더 포함할 수 있는 것을 의미한다. 본원 명세서 전체에서, 인공지능 학습 모델은 입력층과 출력층을 포함할 수 있다. 또한, 인공지능 학습 모델은 입력층과 출력층 사이의 관계를 나타내는 네트워크 또는 네트워크 접점들을 포함할 수 있다. 본원의 일 실시 예에 따르면, 입력층과 출력층 사이의 관계는 은닉층이라고 표현할 수도 있다. 도 1은 본원의 일 실시 예에 따른 이철동음어 인식 시스템의 개략적인 장치를 나타낸 것이다. 도1을 참조하면, 본원의 일 실시 예에 따른 이철동음어 인식 시스템은 화자의 음성을 분석하여 화자의 음 성에 대하여 텍스트를 전사할 수 있다. 또한 이철동음어 인식 시스템은 이철동음발음 모델을 이용하여 텍 스트에 속하는 이철동음어를 인식할 수 있다. 이를 통해, 이철동음어 인식 시스템은 텍스트의 문맥의 특 성을 반영하여 인식한 이철동음어를 문맥에 맞는 단어로 수정할 수 있다. 이하에서는 도1을 참조하여, 이철동음어 인식 시스템의 각 구성에 대해 설명하도록 한다. 도1을 참조하면, 이철동음어 인식 시스템은 이철동음어 전사부, 이철동음어 인식부, 이철동음어 수정부를 포함한다. 다만, 도 1 의 이철동음어 인식 시스템은 본원의 일 예에 불과하므로, 본원의 다양한 실시 예 들에 따르면, 이철동음어 인식 시스템은 도 1 와 다르게 구성될 수도 있다. 이철동음어 전사부는 화자의 음성을 분석하여 화자의 음성 기반으로 텍스트를 전사할 수 있다. 예를 들어, 이철동음어 전사부는 음성데이터베이스(미도시)에 있는 음성신호로부터 기 훈련된 텍스트 전사 인공지능 모델을 이용하여 텍스트를 전사할 수 있다. 여기서 기 훈련된 텍스트 전사 인공지능 모델은 후술할 기 훈련된 인공지능 음향모델과 기 훈련된 인공지능 언어모델을 병합하여 생성된 것일 수 있다. 이철동음어 인식부는 이철동음발음 모델을 이용하여 텍스트에 속하는 이철동음어를 인식할 수 있다. 이때, 이철동음발음 모델은 기 훈련된 인공지능 유추단어 예측 모델이 이철동음어 학습문장 및 위치벡터 및 유사벡터 를 기반으로 학습할 수 있다. 이 때, 학습된 이철동음발음 모델은 텍스트 내에 이철동음어를 인식하는 인공지능 알고리즘일 수 있다. 이철동음발음 모델은 원시문장(raw sentence)를 전처리하여 생성된 인공지능 학습데이터를 이용하여 기 훈련된 인공지능 유추단어 예측 모델(Pre-traing)기반으로 학습된 인공지능 모델일 수 있다. 이철동음어 수정부는 이철동음발음 모델을 이용하여 텍스트에 있는 이철동음어를 문맥에 맞는 단어로 수정 할 수 있다. 다른 말로, 이철동음어 수정부는 이철동음발음 모델을 이용하여 유추단어를 정정단어로 수정 하여 정정문장을 생성할 수 있다. 구체적으로 이철동음어 수정부는 이철동음어를 이철동음발음 모델 기반 으로 이철동음어 그룹 내에 있는 단어들 중에서 가장 높은 확률 값에 있는 단어로 정정문장을 생성할 수 있다. 즉, 이철동음어 수정부는 이철동음발음 모델 기반으로 이철동음어를 이철동음어 그룹 내에 있는 문맥에 가 장 적절한 단어를 선택하여 정정문장을 생성할 수 있다. 여기서 확률 값은 이철동음어 그룹 내에 있는 이철동 음어 각각에 문맥에서 적절한 정도를 부여하는 수치일 수 있다. 이철동음어 수정부는 이철동음발음 모델을 이용하여 사용자의 발음 교정에 이용될 수 있다. 대표적인 예를 들어, 사용자가 분란을 [불란]이 아닌 [분란]으로 그대로 발음하였을 시, 이철동음어 수정부는 화자에게 정정하라는 잘못된 발음이라는 메시지를 보낼 수 있다. 구체적으로, 이철동음어 수정부는 화자의 잘못된 이철동음어 발음에 해당하는 음성 파형을 음소 단위로 표준 이철동음어 음성 파형과 비교를 기초로 교정 음소를 사용자에게 보낼 수 있다. 여기서 표준 이철동음어 음성 파형은 음성데이터 내에서 이철동음어에 대응하는 음성 파형일 수 있다. 이 때, 표준 이철동음어 음성 파형는 음성데이터에 기초하여 화자의 적어도 연령대, 성별 중 하나에 대응할 수 있다. 한편, 이철동음어 수정부는 1차적으로 표준 이철동음어 발음과 미리 정해진 횟수보다 화자의 이철동음어 발음이 다를시, 화자에게 화자의 이철동음어 음성 파형와 표준 이철동음어 음성 파형의 일치율을 보여줄 수 있 다. 또한, 이철동음어 수정부는 2차적으로 화자의 이철동음어 음성 파형과 표준 음성 파형의 일치율이 미 리 정한 일치율 보다 저조할 시, 이철동음어 수정부는 문맥에 적합한 이철동음어와 관련된 용례를 화자에 게 보낼 수 있다. 여기서 용례는 이철동음어 수집부 수집한 용례일 수 있다. 다른 말로, 이철동음어 수정부는 일치율 기준으로 화자에게 발음을 교정하는 프로그램을 제공할 수 있다. 이 때 이철동음어 수정부는 일치율 정도에 따라 화자의 난이도에 맞는 한국어 교정 프로그램을 제공할 수 있다. 즉, 본원은 이철동음발음 모델 기반으로 화자에게 이철동음어 관한 교육 및 교정하는 프로그램을 제공할 수 있다. 이에 한정되는 것은 아니다. 도 2는 본원의 일 실시 예에 따른 이철동음어 전사부를 개략적으로 나타낸 도면이다. 도2를 참조하면, 본원의 일 실시 예에 따른 이철동음어 전사부는 이철동음어 수집부, 음성데이터 추 출부, 텍스트 전사부, 음성데이터베이스(미도시)를 포함할 수 있다. 이철동음어 수집부는 이철동음어에 대응하는 복수의 표제어를 한국어 발음 데이터셋에서 추출할 수 있다. 다른 말로, 이철동음어 수집부는 복수의 이철동음어를 한국어 발음사전으로 기반으로 추출할 수 있다. 즉, 이철동음어 수집부는 한국어 발음사전 기반으로 생성된 한국어 발음 데이터셋에서 이철동음어에 대응하는복수의 표제어를 추출할 수 있다. 구체적으로, 이철동음어 수집부는 한국어 발음 데이터셋에서 한국어 발음 표기가 중복이 있는 표제어가 있 을 시, 한국어 발음 표기에 대응하는 복수의 표제어를 이철동음어로 추출할 수 있다. 여기서 이철동음어는 소리 는 같고 철자가 다른 단어일 수 있다. 대표적인 예로, 이철동음어 수집부는 이철동음어의 한국어 발음 단 어가 \"입\" 일시 표제어로서 인체에 있는 \"입\"과 나뭇잎에 있는 \"잎\"을 추출할 수 있다. 다르게 말하면, 발음 단 어\"입\"에 대응하는 표제어는 인체에 있는\"입\"과 나뭇잎에 있는 \"잎\"일 수 있다. 이철동음어 수집부는 복수의 표제어 각각을 한국어 문법 기초로 복수의 이철동음어 유형별로 나눌 수 있 다. 구체적으로 이철동음어 수집부는 복수의 이철동음어 각각을 한 글자씩 분할한 후 초성, 중성, 종성으 로 나누어, 각 글자의 종성과 초성을 한국어 문법에 비교하여 유형별로 나눌 수 있다. 이 때 이철동음어 수집부 는 한국어 발음 데이터셋에서 복수의 데이터셋으로 나눌 수 있다. 즉, 이철동음어 수집부는 복수의 표제어 각각에 대응하는 복수의 한국어 용례(문장)를 수집할 수 있다. 대표적인 예로, 이철동음어 수집부(11 1)는 [삵]을 [ㅅ+ㅏ + ㄺ]으로 나눈 후 한국어 문법 기초로 [삭]으로 바꾸는 음절의 끝소리 규칙 유형으로 나눌 수 있다. 여기서 이철동음어 유형은 적어도 대치, 탈락, 첨가, 축약, 도치 중 하나에 해당될 수 있다 이철동음어 수집부는 표제어 각각을 한국어 문법 기초로 복수의 이철동음어 유형별로 나누되, 표제어 각각 에 대응하는 용례를 수집할 수 있다. 즉, 이철동음어 수집부는 한국어 발음사전 내에서 한국어 발음 표기 에 관한 중복이 있는 표제어를 기반으로 이철동음어를 유형별로 분리하여 각각의 유형에 대응하는 복수의 표제 어에 대한 용례(문장)를 수집할 수 있다. 즉 이철동음어 수집부는 한국어 발음 표기에서 중복이 있는 표제 어를 기반으로 표제어를 적어도 한국어 문법에 해당하는 대치, 탈락, 첨가, 축약, 도치 중 하나에 해당하는 이 철동음어 유형을 분리하여 각각에 해당하는 용례를 수집할 수 있다. 이철동음어 수집부는 복수의 표제어 각각에 대응하는 용례를 수집할 수 있다. 이 때, 이철동음어 수집부 는 복수의 표제어 각각에 대응하는 수집 용례가 미리 정해진 수보다 적을 시, 웹 페이지에서 크롤링을 하 여 용례(문장)를 수집할 수 있다. 이 때, 이철동음어 수집부는 크롤링하여 수집된 용례(문장) 각각에 대응 하여 각각 녹화된 음성을 음성데이터베이스(미도시)에 저장할 수 있다. 이철동음어 수집부는 화자의 단말 및 기 설정된 녹음 파일을 기반으로 복수의 용례를 개별적으로 녹화하여 음성데이터베이스(미도시)에 할 수 있다. 다른 말로, 이철동음어 수집부는 복수의 용례 각각 한 문장씩 녹 음한 음성데이터를 음성데이터베이스(미도시)에 저장할 수 있다. 한편, 이철동음어 수집부는 복수의 표제어 중 수식어와 피수식어의 결합으로 발생하는 초어절에 해당하는 문자가 있을 시, 각각의 초어절에 해당하는 문자를 웹 크롤링하여 수집할 수 있다. 이때, 초어절은 후술할 기 훈련된 인공지능 음향모델에서 한국어 발음 텍스트 생성시 각 글자에 적어도 초성, 중성, 종성 중 하나가 앞 뒤 문자가 결합함으로써 발생할 수 있다. 구체적으로 이철동음어 수집부는 한국어 발음 텍스트 생성시 첫 번 째 문자의 종성과 두 번째 문자의 초성의 결합의 합으로 발생하는 제1초어절과 앞의 단어와 뒤에 단어 표제어를 합쳐 생기는 제2초어절에 해당하는 문자에 대응하는 용례를 수집할 수 있다. 예를 들어, \"그런 아이는[그러나이는]\"와 \"그러나 이는[그러나이는]\"에 해당하는 초어절이 발생 시, 이철동음어 수집부 제 1 초어절을 \"그런 아이는\"에 해당하는 문자를 웹크롤링하여 수집하고, 제2 초어절을 \"그러나 이 는\"에 해당하는 초어절에 해당하는 문자에 대응하는 용례를 웹크롤링하여 수집할 수 있다. 이철동음어 수집부는 복수의 수집 용례에서 중복된 용례를 제거하는 전처리를 할 수 있다. 예를 들어, 복 수의 수집 문장에서 적어도 한 개 이상의 중복 문장이 있을 경우, 중복 문장을 제거하여 하나의 문장만으로 생 성하는 전처리를 할 수 있다, 또한, 이철동음어 수집부는 복수의 수집 문장 중 특수 문자가 있을 시, 특수 문자가 있는 수집 문장에서 특수 문자를 제거하는 전처리를 할 수 있다. 여기서 특수 문자는 한국어의 자음, 모음, 온점을 제외한 문자를 의미할 수 있다. 이철동음어 수집부는 화자의 단말 및 기 설정된 녹음 파일을 기반으로 복수의 용례 각각을 녹화하여 음성 데이터베이스(미도시)에 복수의 음성데이터를 저장할 수 있다. 다른 말로, 이철동음어 수집부는 음성데이 터베이스(미도시)에 복수의 화자가 발화한 음성을 수신한 단말기로부터 저장할 수 있다. 다른 말로, 복수의 화 자가 복수의 화자 각각 단말에 발화하여 복수의 화자 각각의 음성데이터를 음성데이터베이스(미도시)에 저장할 수 있다. 이때, 단말은 화자의 음파를 받아 똑같은 파형의 음성 전류로 바꾸는 마이크일 수 있다. 또한, 상기 사용자 단말은, 스마트폰(Smartphone), 스마트패드(SmartPad), 태블릿 PC등과 PCS(Personal Communication System), GSM(Global System for Mobile communication), PDC(Personal Digital Cellular), PHS(Personal Handyphone System), PDA(Personal Digital Assistant), IMT(International Mobile Telecommunication)-2000, CDMA(Code Division Multiple Access)-2000, W-CDMA(W-Code Division Multiple Access), Wibro(Wireless Broadband Internet) 단말기 같은 모든 종류의 유/무선 통신 장치를 포함할 수 있다. 특히, 상기 사용자 단말은, 스마트 스피커(Smart Speaker), 스마트 카(Smart Car), 스마트 가전(Smart Appliances), 웨어러블 장치(Wearable Device) 증강현실 기기 (VR/MR) 등 새롭게 생겨나는 각종 통신기술을 이 용한 다양한 음향기기, 구동 기기 등을 포함할 수 있다. 또한, 음성데이터베이스(미도시)는 기존의 저장된 음성데이터와 화자가 새롭게 발화한 음성데이터를 합하여 저 장할 수 있다. 반면, 이철동음어 수집부는 복수의 음성데이터를 음성데이터베이스(미도시)에 각각 나누어 저장할 수 있다. 이 때 음성데이터는 한 문장 단위로 저장될 수 있다. 이철동음어 수집부는 음성데이터베이스(미도시)에서 전처리 단계로 음성의 잡음 신호를 제거하는 잡음 제 거부(미도시)를 포함할 수 있다. 여기서 잡음 제거부(미도시)는 음성신호에 잡음이 섞인 신호를 개선할 수 있다. 구체적으로 잡음 제거부(미도시)는 잡음 스펙트럼의 크기 성분만을 제거하는 스펙트럼 차감법을 이용할 수 있다. 예를 들어, 이철동음어 수집부는 초기 프레임에서 추정되는 비음성구간에서 추정되는 잡음 스펙 트럼을 음성 스펙트럼에서 차감함으로써 음성신호의 잡음을 제거 할 수 있다. 이 때, 잡음 제거부(미도시)는 음 성신호를 주파수대 영역대로 바꾸는 고속 푸리에 변환(FFT)을 이용하여 주파수 음성 스펙트럼으로 바꿀 수 있다. 여기서 고속 푸리에 변환(FFT)은 시간 영역대에 있는 음성신호를 주파수 영역대로 변환하는 기술을 의미 할 수 있다. 음성데이터 추출부는 음성데이터베이스(미도시)에 저장된 복수의 음성데이터로부터 각 음성데이터의 음성 특징에 관한 음성벡터 인자를 추출할 수 있다. 음성벡터 인자를 추출하는 방법은 적어도 선형 예측 코딩(Linear Predictive Coding: LPC) 분석, 멜 주파수 켑스트럴 계수(Mel Frequency Cepstrum Coefficients: MFCC) 분석, PLP(Perceptual Linear prediction) 분석을 이용할 수 있다. 여기서 멜 주파수 켑스트럴 계수는 인간이 사용하는 유사한 음성에서 음성에 관한 음성벡터 인자를 추출하는 동 시에 다른 모든 정보를 강조하지 않는 음성에 관한 음성벡터 인자를 추출하는 기술을 의미할 수 있다. PLP(Perceptual Linear prediction)는 음성의 관련 없는 정보를 버리고 음성 인식률을 높이는 기술일 수 있다. PLP는 스펙트럼 특성이 인간의 청각 시스템의 특성과 일치하도록 변형되었다는 점을 제외하면 선형 예측 코딩과 동일한 기술일 수 있다. 기 훈련된 인공지능 음향모델은 음성벡터 인자를 기초로 음성신호를 각각의 음소에 대응하는 문자로 변환할 수 있다. 이 때, 음소에 대응하는 문자는 한국어 발음 문자일 수 있다. 이를 위해, 기 훈련된 인공지능 음향모델 은 당해 기술 분야에서 널리 알려진 적어도 하나 이상의 음성 인식 인공지능 모델을 이용할 수 있다. 대표적인 예로, 음성 인식 인공지능 모델은 기법은 HMM-DNN 인공지능 알고리즘일 수 있다. HMM-DNN인공지능 알고리즘은 입력 음성 신호에서 각각에 대응하는 음소를 기반으로, 다음 음소를 확률적으로 예 측하는 제1인공지능 알고리즘일 수 있다. , 다른 말로, HMM-DNN인공지능 알고리즘은 음성신호에서 추출된 음성 벡터 인자를 기초로 미리 정해진 개수의 음소 단위로 확률적으로 다음 발음 문자를 예측하는 인공지능 알고리즘 일 수 있다. 이 때, HMM-DNN인공지능 알고리즘은 한국어 발음사전을 이용하여 확률적으로 예측할 수 있다. 즉, 기 훈련된 인공지능 음향모델은 음소 모델을 만들고 HMM으로 음소들의 연속적인 변화를 예측하는 모델일 수 있다. 다른 말로, 음향모델(미도시)은 추출된 음성벡터 인자 기반으로 음소에 대응하는 한국어 발음 텍스트를 생성할 수 있다. 여기서 HMM(hidden Markov model)은 은닉마르코프모델로 음성데이터와 같은 순차적 데이터를 상태들간의 전이가 특정한 확률값 통하여 예측하는 모델일 수 있다. HMM-DNN 인공지능 알고리즘은 음성 인식 과정으로 주어진 음성에 대한 탐색을 실시할 수 있다, HMM-DNN 인공지 능 알고리즘은 는 인식 대상 후보 단어들에 대한 미리 훈련하여 구축된 음향모델 기반으로 현재 입력된 음성의 특징들과의 차이를 비교하여 가장 유력한 후보 단어를 결정할 수 있다. 기 훈련된 인공지능 음향모델은 음성벡터 인자를 입력 받는 제1인공지능 알고리즘을 이용하여 문자를 예측하는 모델일 수 있다. 이로 인하여 기 훈련된 인공지능 음향모델은 연속되는 시간에 따라 변화하는 화자의 음성을 음 성의 특징을 추출하는 라이브러리를 이용하여 음성의 특징을 인식하는 기술일 수 있다. 여기서 음성파형의 특징을 추출하는 라이브러리는 MFCC(Mel Frequency Cepstral Coefficient) 또는 PLP(Perceptual Linear Predictive Coefficient)일 수 있다. 기 훈련된 인공지능 언어모델은 기 훈련된 인공지능 음향모델을 기반으로 출력된 복수의 문자를 한국어 발음사 전에 대응하는 단어로 출력할 수 있다. 한편, 기 훈련된 인공지능 언어모델은 일련의 연속으로 나열된 복수의 단어가 한국어 문법에 대응하지 않을시, 한국어 문법에 맞도록 한국어 문법사전에 대응하여 복수의 단어를 교정할 수 있다. 예를 들어, 기 훈련된 인공 지능 언어 모델은 주어 자리에서 앞에 오는 단어에 자음 종성의 유무에 따라 \"은/는\"을 선택하여 교정할 수 있 다. 또한, 기 훈련된 인공지능 언어모델은 출력된 이전의 나열된 단어을 분해하여, 상기 단어 기반으로 확률값이 가 장 큰 다음 단어를 예측할 수 있다. 즉, 기 훈련된 인공지능 언어모델은 출력된 이전의 단어의 열을 어절 단위 로 단어 뭉치로 만들어 확률적으로 가장 값이 큰 다음 단어를 예측할 수 있다. 이 때, 기 훈련된 인공지능 언어 모델은 어절 단위로 조절할 수 있다. 예를 들어, 기 훈련된 인공지능 언어모델은 제N 언어모델이라고 했을 때, 제 1언어모델은 단어 뭉치 내에 있는 어절의 개수가 1개, 제 2 언어모델은 단어 뭉치 내에 있는 어절의 개수가2 개일 수 있다. 즉, 기 훈련된 인공지능 언어모델은 단어 뭉치 내에 있는 어절의 개수를 기준으로 학습하여 확률 값이 가장 큰 다음 단어를 예측하는 모델일 수 있다. 이때 언어모델, 제 1 언어모델 및 제 2 언어모델 중 어느 하나의 일예는 n-gram일 수 있으나, 이에 한정되는 것은 아니다. 텍스트 전사부는 기 훈련된 텍스트 전사 인공지능 모델을 이용하여 음성데이터베이스(미도시)에 저장된 복 수의 음성데이터를 텍스트로 전사할 수 있다. 이 때, 기 훈련된 텍스트 전사 인공지능 모델은 음성데이터 추출 부에서 추출한 음성벡터 인자를 인용하여 텍스트를 전사할 수 있다. 텍스트 전사부는 기 훈련된 인공지능 음향모델 및 기 훈련된 인공지능 언어모델을 이용하여 복수의 음성데 이터 각각을 용례에 대응하는 복수의 원시문장(Raw sentence)으로 생성할 수 있다. 즉, 텍스트 전사부에서 전사된 텍스트는 이철동음어 전처리부에서 원시문장(Raw sentence)일 수 있다. 본원의 도3는 이철동음어 인식부를 개략적으로 나타낸 도면이다. 본원의 일 실시 예에 따르면, 이철동음어 인식부는 이철동음어 전처리부, 이철동음어 학습부를 포함할 수 있다. 이철동음어 인식부는 이철동음발음 모델을 이용하여 텍스트에 속하는 이철동음어를 인식할 수 있다. 다시 말하면, 이철동음어 인식부는 전처리 문장을 후술할 기 훈련된 인공지능 유추단어 예측 모델 기반으로 학 습된 이철동음발음 모델로 복수의 원시문장(Raw sentence) 각각에 속하는 문장에서 이철동음어를 인식할 수 있 다. 이철동음어 인식부는 이철동음어 전사부가 생성한 복수의 원시문장(Raw sentence)를 이철동음발 음 모델을 이용하여 이철동음어를 인식할 수 있다. 이와 관련하여, 기 훈련된 인공지능 유추단어 예측 모델은 기 훈련된BERT 인공지능 학습 모델일 수 있다. BERT 인공지능 학습 모델은 모든 네트워크에 대하여 양방향으로 사전 훈련하도록 설계된 인공지능 학습 모델일 수 있 다. 다른 말로, BERT인공지능 학습 모델은 양방향 비지도 학습으로 입력 문장에 대하여 특정 단어를 유추단어로 치환함으로써, 유추단어가 어떤 단어인지를 예측하는 학습을 할 수 있다. 특히, 기 훈련된 BERT인공지능 학습 모델은 단 하나의 출력 레이어 추가로 미세조정(Fine-tuning) 하여 다양한 작업의 최신 모델을 생성할 수 있다. 또한, 이철동음발음 모델은 기 훈련된 인공지능 유추단어 예측 모델 이용하여 위치벡터 및 유사벡터 기반으로 단어를 예측하도록 하는 확률 함수를 학습할 수 있다. 확률 함수는 이철동음어 그룹 내에 있는 단어들 각각에 문맥에 적절성에 관한 확률을 계산할 수 있다. 즉, 확률 함수는 이철동음어 그룹 내에서 단어들 중에서 높은 확 률의 값을 가진 단어를 선택하는 함수일 수 있다. 다른 말로, 높은 확률의 값을 가진 단어는 이철동음어 그룹 내에 있는 단어들 중에서 가장 문맥에 적절한 단어일 수 있다. 본원은 이철동음발음 모델의 학습하는 방법에 대하여 설명함으로써 이철동음발음 모델의 이철동음어의 인식 방 법을 설명하고자 한다. 이철동음어 전처리부는 텍스트를 복수의 원시문장(Raw sentence)으로서 전처리하여 기 훈련된 인공지능 유 추단어 예측 모델이 학습하도록 하는 복수의 이철동음어 학습문장을 생성할 수 있다. 즉, 이철동음어 전처리부 는 복수의 원시문장(Raw sentence)을 전처리함으로써 기 훈련된 인공지능 유추단어 예측 모델에 쓰이는 학 습데이터를 생성할 수 있다. 여기서 학습데이터는 복수의 이철동음어 학습문장일 수 있다. 이철동음어 전처리부는 한국어 발음사전을 이용하여 복수의 원시문장의 각각에서 이철동음어 유무를 파악 할 수 있다. 이철동음어 전처리부는 한국어 발음 텍스트 내에 있는 각각의 단어들을 한국어 발음사전에 대 응하여 이철동음어 유무를 알 수 있다. 이철동음어 전처리부는 복수의 원시문장 중 이철동음어가 인지 되지 않는 원시문장(Raw sentence)을 제거 하는 전처리를 할 수 있다. 즉, 이철동음어 전처리부는 이철동음어가 인지 되지않는 제1원시문장을 제거하 는 전처리를 할 수 있다. 또한, 이철동음어 전처리부는 제1원시문장에 대응하는 제1음성데이터를 제거하는 전처리를 할 수 있다. 즉, 이철동음어 전처리부는 후술할 이철동음어 학습부에서 불필요한 학습문장을 학습 하지 않도록 하 여 이철동음어 인식률을 높일 수 있다. 이철동음어 전처리부는 기 훈련된 인공지능 유추단어 예측 모델이 학습하도록 원시문장 내에 있는 이철동 음어를 유추단어로 치환하는 전처리를 하여 학습문장을 생성할 수 있다. 즉, 이철동음어 전처리부는 기 훈 련된 인공지능 유추단어 예측 모델에 학습시키도록 원시문장을 미세조정(Fine-tuning)하여 학습문장을 생성하는 전처리를 할 수 있다. 즉, 학습문장은 기 훈련된 인공지능 유추단어 예측 모델이 학습할 문장이다. 이철동음어 전처리부는 원시문장에 있는 이철동음어를 복수의 방법으로 전처리를 하여 학습문장을 생성 할 수 있다. 여기서 이철동음어 전처리부는 제1 방법으로 이철동음어를 유추단어로 치환하는 전처리를 하여 학습문장을 생성할 수 있는 반면, 이철동음어 전처리부는 제2방법으로 유추단어로 치환하되, 이철동음어 그룹에서 태깅(Tagging)하는 전처리를 하여 학습문장을 생성할 수 있다. 이 때 제1방법으로 인해 생성된 학습문 장은 제1 유형 학습문장이고, 제 2 방법으로 인해 생성된 학습문장은 제2 유형 학습문장일 수 있다. 여기서 이 철동음어 그룹은 한국어 발음사전에서 표제어의 발음 표기는 동일하되, 한국어 발음사전에서 표제어가 다른 단 어의 집합일 수 있다. 여기서 복수의 방법은 원시문장에 이철동음어 그룹을 태깅(Tagging) 및 이철동음어를 유 추단어로 전처리하는 것을 기반일 수 있다. 즉, 이철동음어 전처리부는 이철동음어 그룹을 태깅(Tagging) 및 이철동음어를 유추단어로 전처리를 함으로써 복수의 유형으로 이철동음발음 모델을 생성할 수 있다. 구체적으로, 이철동음어 전처리부는 제1방법으로 유추단어를 마스크[MASK]로 전처리한 제1 학습문장을 생 성할 수 있다. 여기서, 마스크[MASK]는 기 훈련된 인공지능 유추단어 예측 모델이 어떤 단어인지를 예측할 목표 단어일 수 있다. 다른 말로, 인공지능 유추단어 예측 모델이 마스크[MASK]가 어떤 단어인지를 예측할 수 있다. 즉, 이철동음어 전처리부는 이철동음어를 유추단어로서 이철동음어를 가려 기 훈련된 인공지능 유추단어 예측 모델이 이철동음어를 예측하도록 할 수 있다. 일 예로, 이철동음어 전처리부는 제1방법으로 이철동음어가 포함된 복수의 원시문장에서 한국어 발음사전 에 대응하는 이철동음어를 ??과 같이 유추단어로 치환하는 전처리를 할 수 있다. 일 예로, 이철동음어 전처리부 는 제1방법으로 \"나는 승규의 연락을 받고 번개같이 달려갔으나 이미 늦은 후였다\"를 \"나는 승규의 ??을 받고 번개같이 달려갔으나 이미 늦은 후였다\"로 전처리 할 수 있다. 또는 이철동음어 전처리부는 \"나는 승 규의 연락을 받고 번개같이 달려갔으나 이미 늦은 후였다\"에서 \"나는 승규의 [MASK]을 받고 번개같이 달려갔으 나 이미 늦은 후였다\"로 전처리 할 수 있다. 반면에, 이철동음어 전처리부는 제2 방법으로 이철동음어를 ??과 같이 유추단어로 치환하되, 이철동음어 그룹을 태깅(Tagging)하여 전처리한 학습문장을 생성 할 수 있다. 여기서, 이철동음어에 대응하는 이철동음어 그룹은 한국어 발음 표기가 같되, 표제어만 다른 복수의 단어 집합일 수 있다. 또한, 이철동음어 전처리부(12 1)는 제2방법에서 이철동음어 그룹을 원시문장보다 왼쪽에 배치할 수 있다. 다른 말로, 이철동음어 전처리부 는 이철동음어 그룹 내에 있는 나열된 단어들과 원시문장에서 이철동음어를 ??과 같이 처리한 문장을 병합 한 학습문장을 생성할 수 있다. 일 예로, 이철동음어 전처리부는 \"나는 승규의 연락을 받고 번개같이 달려갔으나 이미 늦은 후였다\"를 제2 방법으로 \"열락 연락 나는 승규의 ??을 받고 번개같이 달려갔으나 이미 늦은 후였다\"로 전처리 할 수 있다. 이 때, \"열락 연락\"은 연락에 대응하는 이철동음어 그룹을 태깅한 단어 집합일 수 있다. 또는 이철동음어 전처리 부는 \"나는 승규의 연락을 받고 번개같이 달려갔으나 이미 늦은 후였다\"를 제2 방법으로 \"열락 연락 나는 승규의 [MASK]를 받고 번개같이 달려갔으나 이미 늦은 후였다\"로 전처리를 할 수 있다. 이하에서는 기 훈련된 인공지능 유추단어 예측 모델 학습에 맞도록 하는 학습문장의 전처리를 설명하고자 한다. 이철동음어 전처리부는 학습문장의 각각에 대하여 문장의 시작하는 부분에 시작 시점과 문장이 끝나는 부 분에 끝 시점을 표시할 수 있다. 이철동음어 전처리부는 유추단어로 치환한 원시문장을 로딩할 때마다 각각에 대하여 시작 시점과 끝 시점을 표시할 수 있다. 이철동음어 전처리부는 복수의 원시문장 각각의 로딩 한 시점을 시작 시점과 로딩이 끝난 시점을 끝 시점으로 표시할 수 있다. 이철동음어 전처리부는 시작 시 점과 끝 시점을 표시함으로써 복수의 원시문장을 분류 할 수 있다. 즉, 이철동음어 전처리부는 복수의 원 시문장을 분류하도록 복수의 원시문장 각각에 시작 시점과 끝 시점을 표시할 수 있다. 예를 들어, 이철동음어 전처리부는 \"나는 승규의 연락을 받고 번개같이 달려갔으나 이미 늦은 후였다\"라는 학습문장을 [CLS] 나는 승규의 연락을 받고 번개같이 달려갔으나 이미 늦은 후였다. [SEP]로 전처리 할 수 있다. 여기서 [CLS]는 시작 시점이고, [SEP]는 끝 시점일 수 있다. 이철동음어 전처리부는 시작 시점을 표기함으로써 복수의 학습문장이 입력 되었을 때 후술할 이철동음어 학습부가 소프트맥스 레이어(Softmax Layer)를 이용하여 다중 문장으로 분류할 수 있는 효과가 있다. 이철 동음어 전처리부는 복수의 원시문장(Raw sentence)이 입력 되었을 때 이철동음어 학습부가 각각 한 문장으로 분류하도록 시작 시점을 표기 할 수 있다. 예를 들어, 이철동음어 학습부가 [CLS]를 입력으로 받는 소프트맥스 레이어(Softmax Layer)를 추가함으로써 문장을 다중으로 분류할 수 있다. 이철동음어 전처리부는 복수의 원시문장을 각각 어절 단위로 분리할 수 있다. 다른 말로, 이철동음어 전처 리부는 제1 유형의 제1 학습문장을 각각 어절 단위로 분리할 수 있다. 다시 말해, 이철동음어 전처리부 는 복수의 수집 문장을 각각 띄어쓰기 단위로 분리할 수 있다. 즉, 이철동음어 전처리부는 문장에서 공백과 공백 사이에 있는 나열된 문자들을 각각 하나의 단위로 분리할 수 있다. 이 때, 이철동음어 전처리부는 어절 내에 있는 복수의 문자들을 각각 복수의 형태소로 분리할 수 있다. 구체적으로, 이철동음어 전처리부는 어절 내에 있는 복수의 형태소 중 두 번째 형태소부터 형태소 앞에 특 수 기호를 입력할 수 있다. 또한, 이철동음어 전처리부는 어절 내에 있는 복수의 형태소에서 첫번째 형태소는 그대로 두되, 두 번째 형태소부터는 각각의 형태소 앞에 구분문자를 표시할 수 있다. 여기서 형태소는 적어도 자립 형태소, 의존 형태 소, 실질 형태소, 형식 형태소 중 하나가 될 수 있다. 이에 한정되는 것은 아니다. 예를 들어, 이철동음어 전처리부는 \"나는 승규의 연락을 받고 번개같이 달려갔으나 이미 늦은 후였다\" 라 는 문장을 '나는', '승', '##규', '##의', '?', '?', ' 을', '받고', '번', '##개', '##같', '##이', '달', '##려', '##갔', '##으나', '이미', '늦', '##은', '후', '##였다', '.'로 형태소 분리 및 어절 내에 있는 두 번째 형태소부터 형태소 바로 왼쪽에 특수기호를 표시하는 전처리를 할 수 있다. 이철동음어 전처리부는 학습문장 내에 있는 복수의 형태소 각각에 위치벡터를 표시할 수 있다. 즉, 이철동 음어 전처리부는 각각의 수집 문장 내에서 형태소 각각에 왼쪽에서 오른쪽으로 기준으로 하여 오름 및 내 림순으로 위치벡터를 결정할 수 있다. 이 때, 이철동음어 전처리부는 위치벡터를 0에서 1 사이의 실수 및 자연수로 복수의 형태소 각각에 표시할 수 있다. 다른 말로, 이철동음어 전처리부는 학습문장 내에 있는 각각의 형태소 내에 있는 위치를 나타내는 위치벡 터를 추출할 수 있다. 이철동음어 전처리부는 위치벡터를 추출함으로써 이철동음어 학습부가 문맥을 파악하는 학습을 하도록 할 수 있다. 또한, 이철동음어 전처리부는 문장에서 기 설정된 유사도 계산 라이브러리를 이용하여 각각의 형태소에서 이철동음어의 유사도를 나타낼 수 있는 유사벡터를 추출할 수 있다. 다른 말로, 이철동음어 전처리부는 학 습문장 내에서 기 설정된 유사도 계산 라이브러리를 이용하여 각각의 형태소에 이철동음어와 유사한 정도의 벡 터로 치환할 수 있다. 이철동음어 전처리부는 문자의 개수 기반으로 시작 시점과 끝 시점 사이에 서 최대 문장 길이를 설정할 수 있다. 이때, 이철동음어 전처리부는 학습문장에서 최대 문장 길이를 초과한 문자를 자를 수 있다. 다른 말 로, 이때, 이철동음어 전처리부는 제1 학습문장에서 최대 문장 길이를 초과한 문자를 자르는 전처리를 할 수 있다. 한편, 이철동음어 전처리부는 최대 문장 길이보다 적은 학습문장을 최대 문장 길이보다 적은 문자에 대하 여 패딩(Padding)하는 전처리를 할 수 있다. 즉, 한편, 이철동음어 전처리부는 최대 문장 길이보다 적은 제2 학습문장을 최대 문장 길이보다 적은 문자에 대하여 패딩(Padding)하는 전처리 할 수 있다. 여기서 패딩 (Padding)은 이철동음발음모델이 학습시 패딩한 형태소를 무시하도록 한 전처리일 수 있다. 일 예로 패딩 (Padding)은 형태소를 숫자0으로 처리한 제로패딩(zero padding)일 수 있다. 이와 관련하여, 이철동음어 전처리부는 패딩(Padding) 처리한 형태소를 어텐션 마스크(attention mask)를 0으로 처리할 수 있다. 한편, 이철동음어 전처리부는 패딩(Padding) 처리하지 않은 형태소를 어텐션 마스 크(attention mask)를 1로 처리할 수 있다. 여기서 기 훈련된 인공지능 유추단어 예측 모델은 어텐션 마스크의 유무로 복수의 형태소의 각각에 대한 학습에 대한 여부를 결정할 수 있다. 즉, 이철동음어 전처리부는 어 텐션 마스크가 0인 형태소에서 기 훈련된 인공지능 유추단어 예측 모델이 학습하지 않도록 할 수 있다. 이하에서는 이철동음발음 모델의 학습 과정을 설명하기로 한다. 이철동음어 학습부는 확률 네트워크를 이용하여 복수의 학습문장을 각각 단일 문장으로 분류할 수 있다. 즉, 이철동음어 학습부는 확률 네트워크를 이용하여 각 학습문장의 시작 시점에서 끝 시점까지를 한 문장 단위로 학습할 수 있다. 여기서 확률 네트워크는 소프트맥스 레이어(Softmax Layer)로 의미할 수 있다. 소프트 맥스 레이어(Softmax Layer)는 입력 받은 값을 출력으로 0과1사이의 값으로 모두 정규화할 수 있다. 이 때, 출 력 값들의 총합은 항상 1이 되는 특성을 가질 수 있다. 이철동음어 학습부는 기 훈련된 유추단어 예측 모델에 복수의 방법으로 유추단어를 전처리한 학습문장을 기 훈련된 인공지능 유추단어 예측 모델에 학습시켜 이철동음발음 모델을 복수로 생성할 수 있다. 예를 들어, 이철동음어 학습부는 기 훈련된 인공지능 유추단어 예측 모델이 제1 학습문장으로 학습하여 제1이철동음발 음 모델을 생성할 수 있다. 또한, 이철동음어 학습부는 기 훈련된 인공지능 유추단어 예측 모델이 제2 학 습문장으로 제2 이철동음발음 모델을 생성할 수 있다. 이에 한정되는 것은 아니다. 이철동음어 학습부는 이철동음어 유형 각각에 대응하도록 복수의 이철동음발음 모델을 생성할 수 있다. 즉, 이철동음어 학습부는 제1 학습문장 기반으로 이철동음발음 모델이 이철동음어 유형 각각에 대응하여 유추단어를 예측하는 훈련을 할 수 있다. 즉, 이철동음어 학습부는 이철동음어 유형 각각에 대하여 학습함 으로써 이철동음어 인식률을 높일 수 있다. 또한, 이철동음어 학습부는 제2 학습문장 기반으로 이철동음발 음 모델이 이철동음어 유형 각각에 대응하여 유추단어를 예측하는 훈련을 할 수 있다. 일 예로, 제 1이철동음발음 모델은 이철동음어 유형 중에서 대치에 속하는 이철동음어에 대응하도록 생성된 것 인 반면, 제2이철동음발음 모델은 이철동음어 유형에서 탈락에 속하는 이철동음어에 대응하도록 생성된 것인 반 면, 제3이철동음발음 모델은 이철동음어 유형에서 첨가에 속하는 이철동음어에 대응하도록 생성된 것인 반면, 제4이철동음발음 모델은 이철동음어 유형에서 축약에 속하는 이철동음어에 대응하도록 생성된 것인 반면, 제5이 철동음발음 모델은 이철동음어 유형에서 도치에 속하는 이철동음어에 대응하도록 생성된 것일 수 있다. 제6이철 동음발음 모델은 제1초어절에 대응하도록 생성되는 반면, 제7이철동음발음 모델은 제2초어절에 대응하도록 생성 된 것일 수 있다. 이철동음어 학습부는 학습문장을 기반으로 기 훈련된 인공지능 유추단어 예측 모델을 학습시켜 이철동음발 음 모델을 생성할 수 있다. 이 때, 학습문장은 이철동음어 전처리부에서 기 훈련된 인공지능 유추단어 예 측 모델의 입력 형식에 맞도록 전처리된 문장일 수 있다. 이철동음어 학습부는 기 훈련된 인공지능 유추단어 예측 모델에 복수의 방법으로 이철동음발음 모델을 학 습시켜 이철동음발음 모델을 복수로 생성할 수 있다. 다시 말하면, 복수의 이철동음발음 모델은 복수의 방법 각 각에 대응하여 생성된 이철동음어 예측하는 인공지능 알고리즘일 수 있다. 예를 들어, 이철동음어 학습부 는 제1방법으로 전처리된 이철동음어 학습문장에 대응하는 제1 이철동음발음 모델을 학습 및 제2방법으로 전처 리된 이철동음어 학습문장에 대응하는 제2 이철동음발음 모델을 학습할 수 있다. 이철동음어 학습부는 복수의 이철동음발음 모델 중 가장 인식률이 높은 이철동음발음 모델을 선택할 수 있 다. 즉, 본원은 제1 이철동음발음 모델의 이철동음어 인식률 및 제2이철동음발음 모델의 이철동음어 인식률을 비교하여 복수의 유형으로 이철동음발음 모델 중 인식률이 가장 높은 이철동음발음 모델을 선택할 수 있다. 일 예로, 본원의 제1 이철동음발음 모델은 제1 방법으로서 복수의 원시문장에서 각각에 이철동음어를 유추단어 로 치환하여 전처리한 복수의 학습문장을 학습할 수 있는 반면, 제2 이철동음발음 모델은 제2 방법으로서 이철 동음어 그룹에서 이철동음어를 태깅(Tagging) 및 복수의 원시문장에서 각각에 이철동음어를 유추단어로 치환하 여 전처리한 복수의 학습문장을 학습할 수 있다. 본원의 일 실시 예에 따르면, 도 4는 이철동음어를 이철동음어 인식 시스템으로써 이철동음어를 수정하는 과정을 설명하기 위한 도면이다. 본원의 일 실시예에 따른 이철동음어 인식 시스템에 의해, 파란색 박스 내에서 이철동음어 전사부가 화자의 음성을 분석하여 음성 기반으로 텍스트를 전사할 수 있고, 빨간색 박스 부분에서 이철동음어 인식부 가 이철동음발음 모델을 이용하여 텍스트 내에 이철동음어를 인식할 수 있다. 또한, 이철동음어 수정부 는 이철동음발음 모델을 이용하여 이철동음어를 문맥에 맞는 단어로 수정할 수 있다. 다른 말로, 이철동음 어 수정부는 인식된 문장 내의 이철동음어를 문맥에 맞는 단어로 조정할 수 있다. 여기서 인식된 텍스트는 인식된 문장일 수 있다. 도5은 본원의 일 실시 예에 따른 이철동음어 인식 방법의 동작 흐름도이다. 도5에 도시된 이철동음어 인식 방법은 앞서 설명된 이철동음어 인식 시스템에 의하여 수행될 수 있다. 따 라서, 이하 생략된 내용이라고 하더라도 이철동음어 인식 시스템에 대하여 설명된 내용은 도5에도 동일하 게 적용될 수 있다. 도 5을 참조하면, 단계 S11 에서 이철동음어 전사부는 화자의 음성을 분석하여 음성에 대하여 텍스트를 전 사할 수 있다. 다음으로, 단계 S12에서 이철동음어 인식부는 이철동음발음 모델을 이용하여 텍스트에 속하는 이철동음어 를 인식할 수 있다. 상술한 설명에서, 단계 S11 내지 단계 S12는 본원의 구현예에 따라서, 추가적인 단계들로 더 분할되거나, 더 적 은 단계들로 조합될 수 있다. 또한, 일부 단계는 필요에 따라 생략될 수도 있고, 단계 간의 순서가 변경될 수도 있다. 본원의 일 실시 예에 따른 전자문서 작성 방법은 다양한 컴퓨터 수단을 통하 여 수행될 수 있는 프로그램 명령 형태로 구현되어 컴퓨터 판독 가능 매체에 기록 될 수 있다. 상기 컴퓨터 판독 가능 매체는 프로그램 명령, 데 이터 파일, 데이터 구조 등을 단독으로 또는 조합하여 포함할 수 있다. 상기 매체에 기록되는 프로그 램 명령은 본 발명을 위하여 특별히 설계되고 구성된 것들이거나 컴퓨터 소프트웨 어 당업자에게 공지되어 사용 가능한 것 일 수도 있다. 컴퓨터 판독 가능 기록 매체 의 예에는 하드 디스크, 플로피 디스크 및 자기 테이프와 같은 자기 매체(magnetic media), CD-ROM, DVD와 같은 광기록 매체(optical media), 플롭티컬 디스 크(floptical disk)와 같은 자기-광 매체(magneto-optical media), 및 롬(ROM), 램(RAM), 플래시 메모리 등과 같은 프로그램 명령을 저장하고 수행하도록 특별히 구성된 하드웨어 장치가 포함된다. 프로그램 명령의 예에는 컴파일러에 의해 만들 어지는 것과 같은 기계어 코드뿐만 아니라 인터프리터 등을 사용해서 컴퓨터에 의 해서 실행될 수 있는 고급 언 어 코드를 포함한다. 상기된 하드웨어 장치는 본 발명 의 동작을 수행하기 위해 하나 이상의 소프트웨어 모듈로 서 작동하도록 구성될 수 있으며, 그 역도 마찬가지이다."}
{"patent_id": "10-2021-0179783", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "전술한 본원의 설명은 예시를 위한 것이며, 본원이 속하는 기술분야의 통상의 지식을 가진 자는 본원의 기술적 사상이나 필수적인 특징을 변경하지 않고서 다른 구체적인 형태로 쉽게 변형이 가능하다는 것을 이해할 수 있을 것이다. 그러므로 이상에서 기술한 실시예들은 모든 면에서 예시적인 것이며 한정적이 아닌 것으로 이해해야만 한다. 예를 들어, 단일형으로 설명되어 있는 각 구성 요소는 분산되어 실시될 수도 있으며, 마찬가지로 분산된 것으로 설명되어 있는 구성 요소들도 결합된 형태로 실시될 수 있다. 또한, 전술한 이철동음어 인식 방법은 기록 매체에 저장되는 컴퓨터에 의해 실 행되는 컴퓨터 프로그램 또는 애 플리케이션의 형태로도 구현될 수 있다 본원의 범위는 상기 상세한 설명보다는 후술하는 특허청구범위에 의하여 나타내어지며, 특허청구범위의 의미 및 범위 그리고 그 균등 개념으로부터 도출되는 모든 변경 또는 변형된 형태가 본원의 범위에 포함되는 것으로 해 석되어야 한다."}
{"patent_id": "10-2021-0179783", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본원의 일 실시 예에 따른 이철동음어 인식 시스템의 개략적인 장치를 나타낸 도면이다. 도 2는 본원의 일 실시 예에 따른 이철동음어 전사부를 개략적으로 나타낸 도면이다. 도 3은 본원의 일 실시 예에 따른 이철동음어 인식부를 개략적으로 나타낸 도면이다. 도4는 본원의 일 실시 예에 따른 이철동음어를 이철동음어 인식 시스템으로써 이철동음어를 수정하는 과정 을 설명하기 위한 도면이다. 도5는 본원의 일 실시 예에 따른 이철동음어 인식 방법의 동작 흐름도이다."}
