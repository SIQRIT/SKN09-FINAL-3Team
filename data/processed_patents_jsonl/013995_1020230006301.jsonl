{"patent_id": "10-2023-0006301", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0029493", "출원번호": "10-2023-0006301", "발명의 명칭": "이미지로부터 텍스트를 획득하는 방법 및 서버", "출원인": "삼성전자주식회사", "발명자": "김효상"}}
{"patent_id": "10-2023-0006301", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "서버가 이미지로부터 텍스트를 획득하는 방법에 있어서,제1 텍스트 및 상기 제1 텍스트와 오버랩 된 제2 텍스트를 포함하는 이미지를 획득하는 단계;상기 이미지로부터 상기 제1 텍스트에 대응하는 텍스트 영역을 분리하는 단계;상기 제1 텍스트의 상기 텍스트 영역에서 상기 제1 텍스트의 하나 이상의 문자들과 관련된 픽셀들을 추출하여,상기 제1 텍스트의 일부 영역이 손상된 상기 제1 텍스트의 이미지를 획득하는 단계; 및상기 제1 텍스트의 이미지 내에서 상기 제1 텍스트가 상기 제2 텍스트와 오버랩 되었던 영역을 인페인팅함으로써, 상기 제1 텍스트를 복원하는 단계를 포함하는, 방법."}
{"patent_id": "10-2023-0006301", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 이미지로부터 상기 제1 텍스트에 대응하는 텍스트 영역을 분리하는 단계는,상기 이미지 내의 텍스트를 복수의 문자 그룹들로 세그먼트함으로써 복수의 텍스트 영역들을 결정하는 단계; 및상기 복수의 텍스트 영역들 중에서 상기 제1 텍스트에 대응하는 텍스트 영역을 분리하는 단계를 포함하는,방법."}
{"patent_id": "10-2023-0006301", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,상기 복수의 텍스트 영역들을 결정하는 단계는,상기 이미지에 컬러 클러스터링 알고리즘을 적용하여, 인접한 컬러의 문자들이 그룹화되도록 함으로써 상기 텍스트 영역들을 결정하는 단계를 포함하는, 방법."}
{"patent_id": "10-2023-0006301", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서,상기 복수의 텍스트 영역들을 결정하는 단계는,상기 이미지 내 텍스트를 선택하는 사용자 입력을 수신하는 단계; 및상기 이미지 내 상기 사용자 입력에 대응하는 영역에 상기 컬러 클러스터링 알고리즘을 적용하는 단계를 포함하는, 방법."}
{"patent_id": "10-2023-0006301", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제3항에 있어서,상기 복수의 텍스트 영역들을 결정하는 단계는,상기 이미지에 기초하여, 상기 이미지 내에서 텍스트의 위치를 나타내는 텍스트 영역 맵을 획득하는 단계; 및공개특허 10-2024-0029493-3-상기 텍스트 영역 맵에 기초하여 상기 복수의 텍스트 영역들을 결정하는 단계를 포함하는, 방법."}
{"patent_id": "10-2023-0006301", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5항에 있어서,상기 복수의 텍스트 영역들을 결정하는 단계는,상기 텍스트 영역 맵에 기초하여 상기 컬러 클러스터링 알고리즘을 적용하는 것인, 방법."}
{"patent_id": "10-2023-0006301", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제2항 내지 제6항 중 어느 한 항에 있어서,상기 복수의 텍스트 영역들을 결정하는 단계는,상기 텍스트의 언어, 글씨체, 텍스트의 서식, 말뭉치(corpus) 및 로고 중 적어도 하나에 기초하여 상기 복수의텍스트 영역들을 결정하는 것인, 방법."}
{"patent_id": "10-2023-0006301", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1항 내지 제7항 중 어느 한 항에 있어서,상기 방법은,상기 제1 텍스트에 광학 문자 인식(Optical character recognition; OCR)을 적용하는 단계를 더 포함하는, 방법."}
{"patent_id": "10-2023-0006301", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1항 내지 제8항 중 어느 한 항에 있어서,상기 이미지는 식품과 관련된 라벨의 이미지를 포함하고,상기 제1 텍스트는 식품과 관련된 텍스트를 포함하고,상기 방법은,상기 제1 텍스트에 광학 문자 인식을 적용한 결과에 기초하여, 상기 식품과 관련된 정보를 제공하는 단계를 더포함하는, 방법."}
{"patent_id": "10-2023-0006301", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9항에 있어서,상기 방법은, 상기 식품과 관련된 정보를 외부 장치로 전송하는 단계를 더 포함하는, 방법."}
{"patent_id": "10-2023-0006301", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "이미지로부터 텍스트를 획득하는 서버에 있어서,통신 인터페이스;공개특허 10-2024-0029493-4-하나 이상의 인스트럭션을 저장하는 메모리;상기 메모리에 저장된 상기 하나 이상의 인스트럭션을 실행하는 적어도 하나의 프로세서를 포함하고,상기 적어도 하나의 프로세서는, 상기 하나 이상의 인스트럭션을 실행함으로써,제1 텍스트 및 상기 제1 텍스트와 오버랩 된 제2 텍스트를 포함하는 이미지를 획득하고,상기 이미지로부터 상기 제1 텍스트에 대응하는 텍스트 영역을 분리하고,상기 제1 텍스트의 상기 텍스트 영역에서 상기 제1 텍스트의 하나 이상의 문자들과 관련된 픽셀들을 추출하여,상기 제1 텍스트의 일부 영역이 손상된 상기 제1 텍스트의 이미지를 획득하고,상기 제1 텍스트의 이미지 내에서 상기 제1 텍스트가 상기 제2 텍스트와 오버랩 되었던 영역을 인페인팅함으로써, 상기 제1 텍스트를 복원하는, 서버."}
{"patent_id": "10-2023-0006301", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항에 있어서,상기 적어도 하나의 프로세서는, 상기 하나 이상의 인스트럭션을 실행함으로써,상기 이미지 내의 텍스트를 복수의 문자 그룹들로 세그먼트함으로써 복수의 텍스트 영역들을 결정하고,상기 복수의 텍스트 영역들 중에서 상기 제1 텍스트에 대응하는 텍스트 영역을 분리하는, 서버."}
{"patent_id": "10-2023-0006301", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제12항에 있어서,상기 적어도 하나의 프로세서는, 상기 하나 이상의 인스트럭션을 실행함으로써,상기 이미지에 컬러 클러스터링 알고리즘을 적용하여, 인접한 컬러의 문자들이 그룹화되도록 함으로써 상기 텍스트 영역들을 결정하는, 서버."}
{"patent_id": "10-2023-0006301", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제13항에 있어서,상기 적어도 하나의 프로세서는, 상기 하나 이상의 인스트럭션을 실행함으로써,상기 이미지 내 텍스트를 선택하는 사용자 입력을 수신하고,상기 이미지 내 상기 사용자 입력에 대응하는 영역에 상기 컬러 클러스터링 알고리즘을 적용하는, 서버."}
{"patent_id": "10-2023-0006301", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제13항에 있어서,상기 적어도 하나의 프로세서는, 상기 하나 이상의 인스트럭션을 실행함으로써,상기 이미지에 기초하여, 상기 이미지 내에서 텍스트의 위치를 나타내는 텍스트 영역 맵을 획득하고,상기 텍스트 영역 맵에 기초하여 상기 복수의 텍스트 영역들을 결정하는, 서버."}
{"patent_id": "10-2023-0006301", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "공개특허 10-2024-0029493-5-제15항에 있어서,상기 적어도 하나의 프로세서는, 상기 하나 이상의 인스트럭션을 실행함으로써,상기 텍스트 영역 맵에 기초하여 상기 컬러 클러스터링 알고리즘을 적용하는, 서버."}
{"patent_id": "10-2023-0006301", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제12항 내지 제 16항 중 어느 한 항에 있어서,상기 적어도 하나의 프로세서는, 상기 하나 이상의 인스트럭션을 실행함으로써,상기 텍스트의 언어, 글씨체, 텍스트의 서식, 말뭉치(corpus) 및 로고 중 적어도 하나에 기초하여 상기 복수의텍스트 영역들을 결정하는, 서버."}
{"patent_id": "10-2023-0006301", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제11항 내지 제 17항 중 어느 한 항에 있어서,상기 적어도 하나의 프로세서는, 상기 하나 이상의 인스트럭션을 실행함으로써,상기 제1 텍스트에 광학 문자 인식(Optical character recognition; OCR)을 적용하는, 서버."}
{"patent_id": "10-2023-0006301", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제11항 내지 제18항 중 어느 한 항에 있어서,상기 이미지는 식품과 관련된 라벨의 이미지를 포함하고,상기 제1 텍스트는 식품과 관련된 텍스트를 포함하고,상기 적어도 하나의 프로세서는, 상기 하나 이상의 인스트럭션을 실행함으로써,상기 제1 텍스트에 광학 문자 인식을 적용한 결과에 기초하여, 상기 식품과 관련된 정보를 제공하는, 서버."}
{"patent_id": "10-2023-0006301", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제1항 내지 제10항 중 어느 한 항의 방법을 컴퓨터에서 실행시키기 위한 프로그램을 기록한 컴퓨터로 읽을 수있는 기록매체."}
{"patent_id": "10-2023-0006301", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "서버가 이미지로부터 텍스트를 획득하는 방법이 제공된다. 상기 방법은, 제1 텍스트 및 상기 제1 텍스트와 오버 랩 된 제2 텍스트를 포함하는 이미지를 획득하는 단계; 상기 이미지로부터 상기 제1 텍스트에 대응하는 텍스트 영역을 분리하는 단계; 상기 제1 텍스트의 상기 텍스트 영역에서 상기 제1 텍스트의 하나 이상의 문자들과 관련 된 픽셀들을 추출하여, 상기 제1 텍스트의 일부 영역이 손상된 상기 제1 텍스트의 이미지를 획득하는 단계; 및 상기 제1 텍스트의 이미지 내에서 상기 제1 텍스트가 상기 제2 텍스트와 오버랩 되었던 영역을 인페인팅함으로써, 상기 제1 텍스트를 복원하는 단계를 포함할 수 있다."}
{"patent_id": "10-2023-0006301", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "텍스트 분리 네트워크를 이용하여, 이미지 내에서 오버랩 된 텍스트를 분리하고 추출 및 인식하는, 서버 및 그 동작 방법이 제공된다."}
{"patent_id": "10-2023-0006301", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "다양한 종류의 상품들에는 각각 상품을 설명하기 위한 텍스트가 존재한다. 텍스트가 있는 상품들은 상품의 표면, 라벨 스티커 등에 텍스트가 인쇄된 것이다. 시중에 유통되는 상품의 라벨들 중에는, 상품의 공통 정보가 미리 인쇄되어 있는 라벨의 템플릿 위에, 구체적인 상품의 정보를 추가로 인쇄하는 방식을 이용하는 라벨이 있 다. 이러한 라벨의 인쇄 과정에서, 오류(예를 들어, 인쇄 좌표의 오차 등)로 인해 오버랩 된 텍스트가 존재할 수 있다. 일반적인 텍스트 인식 방법을 이용하여 오버랩 된 텍스트를 인식하는 경우, 텍스트 인식 결과는 정확 하지 않을 수 있다. 텍스트를 인식할 때, 오버랩 된 텍스트를 분리하여 정확하게 인식하기 위한 알고리즘들이"}
{"patent_id": "10-2023-0006301", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 2, "content": "최근 사용되고 있다.발명의 내용"}
{"patent_id": "10-2023-0006301", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 개시의 일 측면에 따르면, 서버가 이미지로부터 텍스트를 획득하는 방법이 제공될 수 있다. 상기 방법은, 제 1 텍스트 및 상기 제1 텍스트와 오버랩 된 제2 텍스트를 포함하는 이미지를 획득하는 단계를 포함할 수 있다. 상기 방법은, 상기 이미지로부터 상기 제1 텍스트에 대응하는 텍스트 영역을 분리하는 단계를 포함할 수 있다. 상기 방법은, 상기 제1 텍스트의 상기 텍스트 영역에서 상기 제1 텍스트의 하나 이상의 문자들과 관련된 픽셀들 을 추출하여, 상기 제1 텍스트의 일부 영역이 손상된 상기 제1 텍스트의 이미지를 획득하는 단계를 포함할 수 있다. 상기 방법은, 상기 제1 텍스트의 이미지 내에서 상기 제1 텍스트가 상기 제2 텍스트와 오버랩 되었던 영 역을 인페인팅함으로써, 상기 제1 텍스트를 복원하는 단계를 포함할 수 있다. 본 개시의 일 측면에 따르면, 이미지로부터 텍스트를 획득하는 서버가 제공될 수 있다. 상기 서버는, 통신 인터 페이스; 하나 이상의 인스트럭션을 저장하는 메모리; 상기 메모리에 저장된 상기 하나 이상의 인스트럭션을 실 행하는 적어도 하나의 프로세서를 포함할 수 있다. 상기 적어도 하나의 프로세서는, 상기 하나 이상의 인스트럭 션을 실행함으로써, 제1 텍스트 및 상기 제1 텍스트와 오버랩 된 제2 텍스트를 포함하는 이미지를 획득할 수 있 다. 상기 적어도 하나의 프로세서는, 상기 하나 이상의 인스트럭션을 실행함으로써, 상기 이미지로부터 상기 제 1 텍스트에 대응하는 텍스트 영역을 분리할 수 있다. 상기 적어도 하나의 프로세서는, 상기 하나 이상의 인스트 럭션을 실행함으로써, 상기 제1 텍스트의 상기 텍스트 영역에서 상기 제1 텍스트의 하나 이상의 문자들과 관련 된 픽셀들을 추출하여, 상기 제1 텍스트의 일부 영역이 손상된 상기 제1 텍스트의 이미지를 획득할 수 있다. 상 기 적어도 하나의 프로세서는, 상기 하나 이상의 인스트럭션을 실행함으로써, 상기 제1 텍스트의 이미지 내에서 상기 제1 텍스트가 상기 제2 텍스트와 오버랩 되었던 영역을 인페인팅함으로써, 상기 제1 텍스트를 복원할 수 있다. 본 개시의 일 측면에 따르면, 서버가 이미지로부터 텍스트를 획득하는, 전술 및 후술하는 방법들 중 어느 하나 를 실행시키기 위한 프로그램이 기록된 컴퓨터 판독 가능 기록매체를 제공할 수 있다."}
{"patent_id": "10-2023-0006301", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 개시에서, \"a, b 또는 c 중 적어도 하나\" 표현은 \" a\", \" b\", \" c\", \"a 및 b\", \"a 및 c\", \"b 및 c\", \"a, b 및 c 모두\", 혹은 그 변형들을 지칭할 수 있다. 본 개시에서 사용되는 용어는 본 개시에서의 기능을 고려하면서 가능한 현재 널리 사용되는 일반적인 용어들을 선택하였으나, 이는 당 분야에 종사하는 기술자의 의도 또는 판례, 새로운 기술의 출현 등에 따라 달라질 수 있 다. 또한, 특정한 경우는 출원인이 임의로 선정한 용어도 있으며, 이 경우 해당되는 설명 부분에서 상세히 그 의미를 기재할 것이다. 따라서 본 개시에서 사용되는 용어는 단순한 용어의 명칭이 아닌, 그 용어가 가지는 의 미와 본 개시의 전반에 걸친 내용을 토대로 정의되어야 한다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함할 수 있다. 기술적이거나 과학적인 용어를 포함해서 여기서 사용되는 용어들은 본 명세서에 기재된 기술 분야에서 통상의 지식을 가진 자에 의해 일반적으로 이해되는 것과 동일한 의미를 가질 수 있다. 또한, 본 명세서에서 사용되는 '제1' 또는 '제2' 등과 같이 서수를 포함하는 용어는 다양한 구성 요소들을 설명하는데 사용할 수 있지만, 상기 구성 요소들은 상기 용 어들에 의해 한정되어서는 안 된다. 상기 용어들은 하나의 구성 요소를 다른 구성 요소로부터 구별하는 목적으 로만 사용된다. 명세서 전체에서 어떤 부분이 어떤 구성요소를 \"포함\"한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다른 구성요소를 제외하는 것이 아니라 다른 구성요소를 더 포함할 수 있음을 의미한다. 또한, 명세서에 기재된 \"부\", \"모듈\" 등의 용어는 적어도 하나의 기능이나 동작을 처리하는 단위를 의미하며, 이는 하드웨어 또는 소 프트웨어로 구현되거나 하드웨어와 소프트웨어의 결합으로 구현될 수 있다. 아래에서는 첨부한 도면을 참고하여 본 개시의 실시예에 대하여 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자가 용이하게 실시할 수 있도록 상세히 설명한다. 그러나 본 개시는 여러 가지 상이한 형태로 구현될 수 있으며 여기에서 설명하는 실시예에 한정되지 않는다. 그리고 도면에서 본 개시를 명확하게 설명하기 위해서 설 명과 관계없는 부분은 생략하였으며, 명세서 전체를 통하여 유사한 부분에 대해서는 유사한 도면 부호를 붙였다. 또한, 각각의 도면에서 사용된 도면 부호는 각각의 도면을 설명하기 위한 것일 뿐, 상이한 도면들 각각 에서 사용된 상이한 도면 부호가 상이한 요소를 나타내기 위한 것은 아니다. 이하 첨부된 도면을 참고하여 본 개시를 상세히 설명하기로 한다. 도 1은 본 개시의 일 실시예에 따른 서버가 이미지로부터 텍스트를 추출하는 것을 개략적으로 도시한 도면이다. 도 1을 참조하면, 일 실시예에 따른 서버는 이미지를 획득할 수 있다. 이 경우, 이미지는 텍스 트를 포함할 수 있으며, 이미지 내에서 서로 다른 텍스트가 서로 중첩되어 있을 수 있다. 예를 들어, 서버 가 획득한 이미지는 상품 라벨 이미지일 수 있다. 여기서 상품 라벨은, 기본적인 상품 라벨의 템플 릿 위에 상품의 세부 정보가 프린트된다. 이에 따라, 상품 라벨의 템플릿에 포함되는 텍스트(예를 들어, 상품 종류)와 상품 라벨의 템플릿 위에 인쇄되는 텍스트(예를 들어, 상품 명)가 오버랩 될 수 있다. 상품은 예를 들 어, 식품(육류 등), 와인, 의류, 섬유 세제 등일 수 있으나 이에 한정되는 것은 아니다. 서버는 이미지 내의 오버랩 된 텍스트를 분리 및 추출할 수 있다. 서버는 텍스트 분리 네트워 크를 이용하여, 오버랩 된 텍스트 각각을 분리 및 추출함으로써 글자, 단어, 말뭉치, 문장 등의 단위 텍스트 조 각들을 획득할 수 있다. 예를 들어, 이미지가 상품 라벨 이미지인 경우, 텍스트 조각들은 상품 과 관련된 정보를 나타낸다. 일 실시예에서, 서버는 이미지로부터 분리된 텍스트 조각들에 기초하여, 텍스트를 인식하고 상 품과 관련된 정보를 생성할 수 있다. 서버는 상품과 관련된 정보를 이용하여 가전 장치(예를 들어, 냉장 고, 오븐 등의 스마트 가전)를 제어하거나, 상품과 관련된 정보를 사용자의 전자 장치(예를 들어, 사용자의 스 마트폰)로 제공할 수 있다. 한편, 본 개시에서 서버가 수행하는 동작은, 사용자의 전자 장치에 의해서도 수행될 수 있다. 전자 장치 는 카메라를 통해 이미지(정지 이미지 및/또는 비디오)를 촬영하고, 디스플레이를 통해 이미지를 출력하는 장치 일 수 있다. 예를 들어, 전자 장치는 스마트 TV, 스마트 폰, 태블릿 PC, 랩탑 PC, 등을 포함할 수 있으나, 이에 한정되는 것은 아니다. 전자 장치는 카메라 및 디스플레이를 포함하는 다양한 종류 및 형태의 전자 장치로 구현 될 수 있다. 또한, 전자 장치는 오디오를 출력하기 위한 스피커를 포함할 수도 있다. 전자 장치는 전자 장치의 카메라를 이용하여 획득된 이미지로부터 직접 텍스트를 분리 및 추출할 수 있고, 이미지 를 서버로 전송하여 서버가 이미지로부터 텍스트를 분리 및 추출할 수 있도록 하게 할 수 있다. 이하에서는 예시적으로, 서버가 텍스트 분리 및 추출 동작을 수행하는 것을 후술하는 도면들을 참조하여 더 상세하게 기술하기로 한다. 도 2는 본 개시의 일 실시예에 따른 서버가 이미지로부터 텍스트를 획득하는 동작을 설명하기 위한 흐름도이다. 단계 S210에서, 서버는 제1 텍스트 및 제1 텍스트와 오버랩 된 제2 텍스트를 포함하는 이미지를 획득한다. 예를 들어, 서버는 사용자의 전자 장치(예를 들어, 스마트폰, PC 등)로부터 이미지를 수신할 수 있다. 예 를 들어, 서버는 서버 내 메모리에 저장된 이미지를 획득할 수 있다. 서버는 오버랩 된 텍스트를 포함하는 이미지를 획득할 수 있다. 본 개시에서는 이미지 내에 오버랩 된 텍 스트가 있는 경우, 분리 및 추출되는 텍스트를 제1 텍스트라고 지칭하고, 제1 텍스트와 오버랩 된 다른 텍스트 를 제2 텍스트라고 지칭할 것이다. 제1 텍스트와 제2 텍스트의 구별은 설명의 편의를 위한 것이며, 오버랩 된 텍스트 중 임의의 단위 텍스트가 제1 텍스트가 될 수 있다. 예를 들어, 텍스트 'ABC'와 텍스트 'DEF'가 오버랩 된 경우, 제1 텍스트는 'ABC', 제2 텍 스트는 'DEF'로 결정될 수 있으며, 후술하는 텍스트 분리 및 추출을 위한 동작들이 수행됨으로써 오버랩 된 텍 스트 중에서 제1 텍스트 'ABC'가 획득된다. 그러나 서버는 이미지 내 모든 텍스트를 분리/추출하기 때문 에, 이미지 내 모든 텍스트에 대하여 동일/유사한 동작을 수행한다. 즉, 서버는 동일/유사한 방식으로, 제1 텍스트를 'DEF', 제2 텍스트가 'ABC'로 구별하여, 오버랩 된 텍스트 중에서 제1 텍스트 'DEF'를 분리할 수 도 있다. 제1 텍스트와 오버랩 된 제2 텍스트는 하나 이상일 수 있다. 예를 들어, 제1 텍스트에 오버랩 된 하나의 단위 텍스트 조각을 제2 텍스트-A 라고 하면, 제1 텍스트에 오버랩 된 또다른 하나의 단위 텍스트 조각은 제2 텍스트 -B 라고 지칭될 수 있다. 단계 S220에서, 서버는 이미지로부터 제1 텍스트에 대응하는 텍스트 영역을 분리한다. 본 개시에서, 서버 가 제1 텍스트에 대응하는 텍스트 영역을 분리하기 위해 사용하는 소프트웨어 모듈은 세퍼레이터라고 지 칭한다. 서버는 세퍼레이터를 이용하여 텍스트 세그멘테이션을 할 수 있다. 서버는 이미지 내의 텍스트를 복수의 문자 그룹들로 세그멘트함으로써, 복수의 텍스트 영역들을 결정할 수 있다. 텍스트 영역이란, 이미지 내 에서, 같은 그룹으로 분류된 문자들을 포함하는 영역을 말한다. 세퍼레이터는 제1 세퍼레이터 및 제2 세퍼레이 터를 포함할 수 있다. 제1 세퍼레이터는 제2 세퍼레이터에 비해 상대적으로 가벼운 텍스트 분리 연산을 수행하 며, 제2 세퍼레이터는 제1 세퍼레이터에 비해 상대적으로 많은 연산을 수행하도록 구성될 수 있다. 이에 따라, 제1 세퍼레이터보다 제2 세퍼레이터의 텍스트 분리 정확도가 높을 수 있다. 일 실시예에서, 서버는 이미지 내에서 텍스트의 위치를 나타내는 텍스트 영역 맵을 획득하고, 텍스트 영 역 맵에 기초하여 복수의 텍스트 영역들을 결정할 수 있다. 서버는 텍스트의 언어, 글씨체, 말뭉치 (corpus)(예를 들어, 중량(g)) 및 로고 중 적어도 하나에 기초하여 복수의 텍스트 영역들을 결정할 수 있다. 일 실시예에서, 제1 세퍼레이터는 컬러 클러스터링 알고리즘을 적용하여, 인접한 컬러의 문자들이 그룹화되도록 함으로써 복수의 텍스트 영역들을 결정할 수 있다. 일 실시예에서, 제2 세퍼레이터는, 인공지능 모델로 구현될 수 있다. 세퍼레이터는, 텍스트를 포함하는 원본 이 미지를 입력 받아, 텍스트의 일 단위(예를 들어, 문자 그룹)를 포함하는 이미지를 출력하는, 심층 신경망 모델 일 수 있다. 세퍼레이터는 알려진 다양한 심층 신경망 아키텍처 및 알고리즘을 이용하거나, 알려진 다양한 심층 신경망 아키텍처 및 알고리즘의 변형을 통해 구현될 수 있다. 일 실시예에서, 서버가 제1 텍스트에 대응하는 텍스트 영역을 분리하면, 분리된 텍스트 영역에는 제1 텍 스트가 포함되며, 제1 텍스트와 오버랩 된 제2 텍스트의 전부 또는 일부가 포함된다. 단계 S230에서, 서버는 제1 텍스트의 텍스트 영역에서 제1 텍스트의 하나 이상의 문자들과 관련된 픽셀들 을 추출하여, 제1 텍스트의 일부 영역이 손상된 제1 텍스트의 이미지를 획득한다. 본 개시에서, 서버가 제1 텍스트의 문자들에 대응하는 픽셀들을 추출하기 위해 사용하는 소프트웨어 모듈은 익스트랙터라고 지칭한다. 서버는 단계 S220에서 분리한 텍스트 영역에서, 제1 텍스트의 하나 이상의 문자들에 대응하는 픽셀들을 레이블링할 수 있다. 예를 들어, 서버는 제1 텍스트의 하나 이상의 문자들에 대응하는 픽셀들을 레이블 값 1로 레이블링하고, 제1 텍스트와 오버랩 되어 있는 제2 텍스트의 문자들에 대응하는 픽셀들은 레이블링하지 않을 수 있다. 또는, 예를 들어, 서버는 제1 텍스트의 하나 이상의 문자들에 대응하는 픽셀들을 레이블 값 1로 레이블링하고, 제1 텍스트와 오버랩 되어 있는 제2 텍스트의 문자들에 대응하는 픽셀들은 레이블 값 2로 레이블링할 수 있다. 서버는 텍스트 영역에서 제1 텍스트의 문자들에 대응하는 픽셀들을 추출한, 제1 텍스트의 이미지를 획득 할 수 있다. 이 경우, 서버는 제1 텍스트와 오버랩 된 제2 텍스트의 문자들에 대응하는 픽셀들은 추출하 지 않으므로, 제1 텍스트의 문자들의 일부 픽셀이 손상되어 있을 수 있다. 단계 S240에서, 서버는 제1 텍스트의 이미지 내에서 제1 텍스트가 제2 텍스트와 오버랩 되었던 영역을 인 페인팅함으로써, 제1 텍스트를 복원한다. 본 개시에서, 서버가 제1 텍스트의 문자들에 대하여 손상된 픽 셀들을 복원하기 위해 사용하는 소프트웨어 모듈은 인페인터라고 지칭한다. 일 실시예에서, 손상된 픽셀들을 복원하는 인페인터는, 인공지능 모델로 구현될 수 있다. 인페인터는, 손상된 픽셀을 포함하는 이미지를 입력 받아, 손상된 픽셀들을 채워 넣은 이미지를 출력하는, 심층 신경망 모델일 수 있다. 인페인터는 알려진 다양한 심층 신경망 아키텍처 및 알고리즘을 이용하거나, 알려진 다양한 심층 신경망 아키텍처 및 알고리즘의 변형을 통해 구현될 수 있다. 이하, 도 3을 참조하여 오버랩 된 텍스트가 있는 이미지에 대하여 설명하기로 한다. 도 3은 본 개시의 일 실시예에 따른 서버가 획득하는, 오버랩 된 텍스트가 있는 이미지를 설명하기 위한 도면이 다. 일 실시예에서, 서버가 획득하는 오버랩 된 텍스트가 있는 이미지는 상품 라벨 이미지일 수 있다. 도 3을 참조하면, 한국어 텍스트가 포함되는 제1 이미지 및 영어 텍스트가 포함되는 제2 이미지가 예시로 도 시되어 있다. 제1 이미지는 한국어 텍스트를 포함하는 상품 라벨 이미지의 예시이다. 제1 이미지는 상품 라벨의 템 플릿 위에 상품의 세부 정보를 나타내는 텍스트들이 프린트 된 이미지일 수 있다. 이에 따라, 제1 상품 라벨 이 미지에는, 복수의 텍스트 오버랩 영역들이 포함될 수 있다. 예를 들어, 상품 라벨의 템플릿의 항목중 하나인 ‘가격(원)’의 한국어 텍스트 위에, 실제 가격 '9700' 숫자 텍스트가 프린트 될 수 있으며, 이 때, 인쇄 과정에서의 오차로 인해 오버랩 된 텍스트가 있는 텍스트 오버랩 영역이 존재할 수 있다. 또한, 상품 라벨의 템플릿 항목 중 하나인 '중량(g)'의 한국어 텍스트 위에, 실제 중량 '176'의 숫자 텍스트가 프린트 될 수 있으며, 이 때, 인쇄 과정에서의 오차로 인해 오버랩 된 텍스트가 있는 텍스트 오버랩 영역이 존재할 수 있다. 제2 이미지는 영어 텍스트를 포함하는 상품 라벨의 이미지의 예시이다. 제2 이미지는 상품 라벨의 템 플릿 위에 상품의 세부 정보를 나타내는 텍스트가 프린트 된 이미지일 수 있다. 예를 들어, 상품 라벨의 템플릿 에는, 상품 라벨의 템플릿의 항목들인 포장 날짜(PACK DATE), 판매 기한(SELL BY) 총 중량(NET WT.) 단위 가격 (UNIT PRICE), 총 가격(TOTAL PRICE) 등에 각각 상세 정보를 나타내는 텍스트가 프린트 될 수 있고, 상품을 판 매하는 마트의 이름/주소 등의 정보가 프린트 될 수 있다. 일 실시예에 따른 서버는 오버랩 된 텍스트가 있는 이미지를 획득하면, 텍스트를 인식하기 위해 오버랩 된 텍스트를 분리할 수 있다. 예를 들어, 텍스트 'ABC'와 텍스트 'DEF'가 오버랩 되어, 전술한 텍스트 오버랩 영역과 같이 되어 텍스트 인식이 불가능한 경우, 서버는 텍스트 'ABC'와 텍스트 'DEF'를 분리할 수 있다. 한편, 도 3을 포함하여 본 개시에서는, 오버랩 된 텍스트의 예시로 한국어, 영어, 숫자 등을 예시로 설명할 것 이다. 다만, 이는 설명의 편의를 위한 예시일 뿐, 텍스트의 언어가 이에 한정되는 것은 아니다. 도 4는 본 개시의 일 실시예에 따른 서버가 텍스트 분리를 위해 이미지를 전처리하는 동작을 설명하기 위한 도 면이다. 일 실시예에서, 서버는 오버랩 된 텍스트가 있는 이미지를 전처리할 수 있다. 도 4를 참조하면, 오버랩 된 텍스트가 있는 제1 이미지 및 오버랩 된 텍스트가 있는 제2 이미지가 예시로 도시되어 있다. 서버 는 이미지의 색상 채널 정보에 기초하여 이미지를 전처리할 수 있다. 일 실시예에서, 서버는 이미지 내에서 특정 색상을 지울 수 있다. 제1 이미지를 예로 들어 설명하면, 서버는 제1 이미지 내의 특정 색상의 로고를 지울 수 있다. 서버는 특정 색상 의 로고를 제거하기 위해, 로고의 색상을 식별할 수 있다. 서버는 로고의 색상에 기초하 여 제1 임계값 및 제2 임계값을 설정하고, 제1 임계값 및 제2 임계값 사이의 색상을 갖는 픽셀들을 지움으로써 전처리 된 제1 이미지를 획득할 수 있다. 일 실시예에서, 서버는 이미지 내에서 특정 색상만을 남길 수 있다. 제2 이미지를 예로 들어 설명하 면, 서버는 제2 이미지 내에서 검정 또는 무채색 색상만을 남기고 나머지 색상들을 지울 수 있다. 예를 들어, 서버는 HSV 색 공간에서, 채도(saturation)가 제1 임계값보다 작고, 명도(value)가 제2 임계 값보다 작은 픽셀들을 지움으로써 전처리 된 제2 이미지를 획득할 수 있다. 이 경우, 검정 색상 외 다른 색상을 갖는 요소들이 삭제될 수 있다. 다른 색상을 갖는 요소들은 예를 들어, 텍스트, 로고, 배경색 등을 포함할 수 있으나, 이에 한정되는 것은 아니다. 예를 들어, 서버는 RGB 색 공간에서, 무채색 만을 남길 수 있다. 서버는 기 설정된 임계 값에 기초 하여 R, G, B 색상의 비율이 소정 범위 이내인 픽셀들만을 남김으로써, 전처리 된 제2 이미지를 획득할 수 있다. 이 경우, 무채색 외 다른 색상을 갖는 요소들이 삭제될 수 있다. 다른 색상을 갖는 요소들은 예를 들어, 텍스트, 로고, 배경색 등을 포함할 수 있으나, 이에 한정되는 것은 아니다. 일 실시예에서, 서버는 오버랩 된 텍스트가 있는 이미지를 선택적으로 전처리 할 수 있다. 예를 들어, 서 버는 오버랩 된 텍스트가 있는 이미지를 전술한 예시에 따라 전처리하고, 전처리 된 이미지 내에서 오버 랩 된 텍스트를 분리할 수 있다. 또는, 예를 들어, 서버는 오버랩 된 텍스트가 있는 이미지에 대한 전처 리 없이, 직접적으로 오버랩 된 텍스트를 분리할 수 있다. 서버가 텍스트를 분리하는 동작은 이후의 도면들을 참조하여 더 기술한다. 이후의 모든 설명들에서, 서버 가 텍스트를 분리함에 있어서 전처리는 선택적으로 적용 가능하다. 도 5는 본 개시의 일 실시예에 따른 서버가 이용하는 텍스트 분리 네트워크를 설명하기 위한 도면이다. 도 5를 참조하면, 서버는 텍스트 분리 네트워크를 이용하여 원본 이미지로부터 텍스트를 분리 할 수 있다.일 실시예에서, 텍스트 분리 네트워크는 원본 이미지를 입력으로 받아, 원본 이미지 내에 있는 오버랩 된 텍스트를 분리할 수 있다. 텍스트 분리 네트워크는 원본 이미지를 처리하는 모듈인 세퍼레 이터, 익스트랙터 및 인페인터를 포함할 수 있다. 다만, 이는 텍스트 분리 네트워크의 세 부적인 동작들을 설명하기 위해 예시적으로 복수의 모듈들을 구별한 것일 뿐, 이에 한정되는 것은 아니다. 예를 들어, 텍스트 분리 네트워크에 포함되는 둘 이상의 모듈이 하나로 결합될 수 있고, 적어도 하나의 모듈이 생략될 수도 있다. 세퍼레이터는 원본 이미지를 처리하여 원본 이미지 내에 텍스트에 대응하는 텍스트 영역들을 분리한 다. 즉, 세퍼레이터는 이미지를 입력 받아, 복수의 텍스트 영역들을 결정할 수 있다. 복수의 텍스트 영역 들 각각은, 이미지 내에서 같은 그룹으로 분류된 문자들을 포함하는 영역일 수 있다. 예를 들어, 하나의 텍스트 영역은 같은 그룹으로 분류된 한글 문자들 '중량(g)'이 포함될 수 있다. 다만, 이는 복수의 텍스트 영역들 중 하나의 텍스트 영역만을 표시한 것이며, 세퍼레이터는 이미지 내에 존재하는 모든 텍스트를 텍스트 영 역들로 구별한다. 일 실시예에서, 세퍼레이터는 컬러 클러스터링 알고리즘을 이용하여 이미지 내에서 인접한 색상들을 클러 스터링하고, 클러스터링 결과에 기초하여 문자들을 그룹화하는 모듈일 수 있다. 세퍼레이터는 예를 들어, K-means 알고리즘을 이용하여 이미지 내 색상을 K개로 클러스터링 할 수 있으나, 이에 한정되는 것은 아니다. 일 실시예에서, 세퍼레이터는 하나 이상의 인공지능 모델을 포함할 수 있다. 세퍼레이터는 텍스트 검출 모델을 포함할 수 있다. 텍스트 검출 모델은 이미지를 입력 받아, 이미지 내에 서 텍스트의 위치들을 검출한 결과를 나타내는 텍스트 영역 맵을 출력하는 인공지능 모델일 수 있다. 텍스트 영 역 맵은 텍스트의 존재를 나타내는 2D 가우시안 스코어 데이터일 수 있으나, 이에 한정되는 것은 아니다. 또한, 텍스트 검출 모델은 이미지 내의 텍스트들의 문자들, 문자들의 연관 관계 등, 텍스트 검출을 위한 정답(ground truth)들의 주석(annotation)을 포함하는 트레이닝 데이터에 기초하여 훈련된 것일 수 있다. 텍스트 검출 모델 은 알려진 다양한 심층 신경망 아키텍처 및 알고리즘을 이용하거나, 알려진 다양한 심층 신경망 아키텍처 및 알 고리즘의 변형을 통해 구현될 수 있다. 세퍼레이터는 텍스트 분리 모델을 포함할 수 있다. 텍스트 분리 모델은 이미지를 입력 받아, 이미지 내에 서 텍스트들을 분리한 결과(예를 들어, 텍스트 영역 이미지 등)를 출력하는 인공지능 모델일 수 있다. 일 실시예에서, 텍스트 분리 모델은 텍스트의 언어, 글씨체, 말뭉치(corpus) 및 로고 중 적어도 하나를 포함하 는, 텍스트 분리를 위한 기준이 되는 정답들의 주석을 포함하는 트레이닝 데이터에 기초하여 훈련된 것일 수 있 다. 텍스트 분리 모델은 알려진 다양한 심층 신경망 아키텍처 및 알고리즘을 이용하거나, 알려진 다양한 심층 신경망 아키텍처 및 알고리즘의 변형을 통해 구현될 수 있다. 한편, 원본 이미지는 중첩된 텍스트가 있는 이미지이므로, 세퍼레이터에 의해 분리된 텍스트 영역에 는, 텍스트가 오버랩 되어 있을 수 있다. 예를 들어, 텍스트 영역에 포함되는 문자 그룹을 제1 텍스트라고 지칭 하면, 제1 텍스트 외에, 다른 문자 그룹으로 분류된 텍스트인 제2 텍스트의 일부가 분리된 텍스트 영역에 포함 될 수 있다. 일 실시예에서, 세퍼레이터는 제1 텍스트의 문자들에 대응하는 픽셀들을 레이블링할 수 있다. 예를 들어, 세퍼레이터는 제1 텍스트의 문자들에 대응하는 픽셀들을 소정 값으로 레이블링할 수 있다. 세퍼레이터 는 제1 텍스트와 오버랩 된 제2 텍스트의 문자들은 레이블링하지 않거나, 제1 텍스트와 다른 값으로 레이 블링할 수 있다. 익스트랙터는 텍스트 영역 내 제1 텍스트에 대응하는 픽셀들을 추출하여 제1 텍스트의 일부 영역이 손상된 이미지를 획득할 수 있다. 여기서, 제1 텍스트의 일부 영역이 손상되었다는 것은, 제1 텍스트에 오버랩 된 제2 텍스트에 대응하는 픽셀들을 제외하고, 제1 텍스트에만 대응하는 픽셀들이 추출된 것을 말한다. 일 실시예에서, 익스트랙터는 텍스트 영역 내에서 제1 텍스트에 대응하는 픽셀들의 레이블에 기초하여, 제 1 텍스트에 대응하는 픽셀들만을 추출함으로써, 제1 텍스트의 일부 영역이 손상된 제1 텍스트의 이미지를 획득할 수 있다. 인페인터는 제1 텍스트의 이미지 내에서 손상된 픽셀들을 복원할 수 있다. 인페인터는, 손상된 픽셀을 포함하는 이미지를 입력 받아, 손상된 픽셀들을 채워 넣은 이미지를 출력하는, 심층 신경망 모델로 구현 될 수 있다. 예를 들어, 인페인터는 손상된 제1 텍스트의 이미지를 입력 받아, 복원된 제1 텍스트의이미지를 출력할 수 있다. 인페인터는 손상되지 않은 정답 텍스트 및 정답 텍스트에 노이즈 텍스트를 오버랩시켜 획득된 트레이닝 데 이터에 기초하여 훈련된 것일 수 있다. 인페인터는 알려진 다양한 심층 신경망 아키텍처 및 알고리즘을 이 용하거나, 알려진 다양한 심층 신경망 아키텍처 및 알고리즘의 변형을 통해 구현될 수 있다. 일 실시예에 따른 서버가 텍스트 분리 네트워크 및 텍스트 분리 네트워크의 모듈들(세퍼레이터 , 익스트랙터, 인페인터를 이용하여 중첩된 텍스트들을 분리하는 동작을, 도 6 내지 도 11b를 참조하여 더 설명한다. 도 6은 본 개시의 일 실시예에 따른 서버가 이미지 내의 텍스트를 인식하는 동작을 설명하기 위한 도면이다. 일 실시예에서, 텍스트 분리 네트워크는 제1 세퍼레이터 및 제2 세퍼레이터를 포함할 수 있다. 제1 세퍼레이터는 컬러 클러스터링 알고리즘을 이용하여 이미지 내에서 인접한 색상들을 클러스터링하고, 클러스터링 결과에 기초하여 문자들을 그룹화하는 모듈일 수 있다. 제1 세퍼레이터는 예를 들어, K-means 알고리즘을 이용하여 이미지 내 색상을 K개로 클러스터링 할 수 있으나, 이에 한정되는 것은 아니다. 제1 세퍼 레이터는 그룹화된 문자들을 포함하는 텍스트 영역을 익스트랙터로 전달할 수 있다. 제2 세퍼레이터는 텍스트 분리 모델을 포함할 수 있다. 텍스트 분리 모델은 이미지를 입력 받아, 이미지 내에서 텍스트들을 분리한 결과(예를 들어, 그룹화된 문자들을 포함하는 텍스트 영역)를 출력하는 인공지능 모 델일 수 있다. 제2 세퍼레이터는 그룹화된 문자들을 포함하는 텍스트 영역을 익스트랙터로 전달할 수 있다. 제1 세퍼레이터는 제2 세퍼레이터에 비해 상대적으로 가벼운 텍스트 분리 연산을 수행하며, 제2 세퍼 레이터는 제1 세퍼레이터에 비해 상대적으로 많은 연산을 수행한다. 이에 따라, 제1 세퍼레이터(61 0)보다 제2 세퍼레이터의 텍스트 분리 정확도가 높을 수 있다. 서버는 기 설정된 조건에 기초하여, 텍스트 분리 네트워크의 제1 세퍼레이터 또는 제2 세퍼레 이터를 이용할 것을 결정할 수 있다. 이하에서, 제1 세퍼레이터 및 제2 세퍼레이터가 사용되는 기 설정된 조건들을 설명한다. 일 실시예에서, 서버는 입력 이미지를 획득할 수 있다. 입력 이미지에는 오버랩 된 텍스트가 포함될 수 있다. 서버는 이미지의 특정 영역을 지정하는 사용자 입력을 수신할 수 있다(S610). 예를 들어, 서버 는 이미지의 특정 영역을 지정하는 사용자 입력을 사용자의 전자 장치(예를 들어, 스마트폰, PC)로부터 수신할 수 있다. 사용자 입력은 이미지 내에서 오버랩 된 텍스트가 있는 텍스트 영역들을 지정하는 입력일 수 있다. 서버는 오버랩 된 텍스트가 있는 텍스트 영역들을 지정하는 사용자 입력에 기초하여, 텍스트 분리 작업을 수행할 수 있다. 일부 실시예에서, 서버는 입력 이미지에 대하여 먼저 텍스트 인식(예를 들어, OCR 등)을 수행할 수 있다. 서버는 텍스트 오버랩으로 인해 입력 이미지에 대한 텍스트 인식 결과가 획득 되지 않는 경우, 텍스트 인식 결과를 획득하기 위해 제1 세퍼레이터를 이용할 것으로 결정할 수 있다. 서 버가 최초로 텍스트 분리 네트워크를 이용하는 경우, 제1 세퍼레이터의 우선 순위가 제2 세퍼 레이터 보다 높게 설정되어 있을 수 있다. 서버는 제1 세퍼레이터를 이용하여 텍스트 분리 작업을 수행할 수 있다. 예를 들어, 서버는 제1 세퍼레이터를 이용하여 컬러 클러스터링을 수행하고, 컬러 클러스터에 기초하여 서로 다른 색상의 텍 스트를 분리할 수 있다. 예를 들어, 서버는 검정색 텍스트와 빨간색 텍스트를 분리할 수 있다. 서버는 사용자 입력이 없는 경우, 입력 이미지에 대하여 텍스트 영역 맵을 추출한다(S620). 서버는 텍스트 검출 모델을 이용하여 텍스트 영역 맵을 획득할 수 있다. 텍스트 검출 모델은 입력 이미지를 입력 받아, 이미지 내에서 텍스트의 위치들을 검출한 결과를 나타내는 텍스트 영역 맵을 출력하는 인공지능 모델일 수 있다. 서버는 텍스트 영역 맵에 기초하여, 이미지 내 텍스트 영역들에 컬러 클러스터링 알고리즘을 적용할 수 있다(S630). 서버는 텍스트 영역 맵에 기초하여, 이미지 내 존재하는 텍스트 영역들에 대한 컬러 클러스 터를 획득하고, 분류된 컬러 클러스터의 수가 기 설정된 수(예를 들어, 3개) 이상인지 여부에 기초하여 제1 세 퍼레이터 및 제2 세퍼레이터 중 어느 하나를 이용할 것을 결정할 수 있다. 서버는 컬러 클러스터의 수가 기 설정된 수 이상이면, 제1 세퍼레이터를 이용할 수 있다. 컬러 클러 스터의 수가 기 설정된 수 이상이라는 것은, 텍스트 영역 내에 서로 다른 색상을 갖는 텍스트가 3개 이상이라는 것을 의미한다. 이 경우, 서버는 제1 세퍼레이터를 이용하여, 색상을 기준으로 텍스트를 분리할 수 있다. 예를 들어, 제1 텍스트에 제2 텍스트가 오버랩 되어 있고, 제1 텍스트와 제2 텍스트의 색상이 상이하면, 서버는 제1 텍스트와 제2 텍스트를 분리할 수 있다. 서버는 익스트랙터를 이용하여, 제1 텍스 트의 문자들에 대응하는 픽셀들을 추출할 수 있다. 여기서, 제1 텍스트에 오버랩 되었던 제2 텍스트의 문자들에 대응하는 픽셀들은 추출되지 않으므로, 제1 텍스트의 일부 영역이 손상된 이미지가 획득될 수 있다. 서버(200 0)는 제1 텍스트의 일부 영역이 손상된 이미지를 인페인터를 이용하여 복원할 수 있다. 인페인터는 복원된 텍스트를 포함하는 이미지를 출력할 수 있다. 서버는 인페인터로부터 획득된, 복원된 이미지에 기초하여 텍스트 인식을 수행할 수 있다(S640). 예 를 들어, 서버는 광학 문자 인식(Optical character recognition; OCR) 모델을 이용하여, 이미지에 포함 되는 텍스트(예를 들어, 일반 문자, 특수 문자(special character) 및 기호(symbol) 등)를 인식할 수 있다. 서 버가 텍스트 인식을 통해 획득한 텍스트는, 상품에 관련된 정보를 포함할 수 있다. 예를 들어, 입력 이미 지가 상품 라벨의 이미지였던 경우, 서버는 상품 라벨에 포함되는 상품과 관련된 텍스트를 상품 정보로 획득할 수 있다. 일 실시예에서, 텍스트 인식은 서버와 연결된 외부 장치에서 수행될 수 있다. 예를 들어, 서버는, 텍스트 분리 네트워크를 통해 획득한, 텍스트를 포함하는 이미지를 사용자의 전자 장 치(예를 들어, 스마트폰 등)로 전송할 수 있다. 이 경우, 사용자의 전자 장치에서 OCR이 수행될 수 있다. 일 실시예에서, 서버는 텍스트 인식 결과의 유효성을 검증할 수 있다(S650). 예를 들어, 서버는 OCR 인식 결과에 포함되는 인식 신뢰도가 기 설정된 값 이상인지 여부에 기초하여 인식 결과의 유효성을 판단할 수 있다. 예를 들어, 서버는 기 설정된 기준에 기초하여 텍스트 인식 결과가 유효한지 여부를 판단할 수 있다. 구체적으로, 서버는 인식된 텍스트가 기 정의된 형태인, 상품을 식별하기 위한 식별 번호를 나타내 는 20자리의 숫자를 충족하는지 여부를 판단할 수 있다. 예를 들어, 서버는 인식된 텍스트 숫자, 말뭉치, 단어 등이 정확하게 인식되었는지 여부를 검증할 수 있다. 서버는 텍스트 인식 결과가 유효하지 않다고 판단되면, 보다 정밀한 텍스트 분리 및 인식 작업을 다시 수행하기 위해, 제2 세퍼레이터를 이용할 수 있 다. 서버는 컬러 클러스터의 수가 기 설정된 수 미만이면, 제2 세퍼레이터를 이용할 수 있다. 또한, 서 버는 전술한 것과 같이 텍스트 인식 결과의 유효성에 기초하여 제2 세퍼레이터를 이용할 수 있다. 서버는 제2 세퍼레이터를 이용하여, 텍스트의 언어, 글씨체, 말뭉치 및 로고 중 적어도 하나에 기초 하여 텍스트 영역들을 결정함으로써 텍스트를 분리할 수 있다. 제2 세퍼레이터는, 텍스트를 포함하는 원본 이미지를 입력 받아, 텍스트의 일 단위(예를 들어, 문자 그룹)을 포함하는 이미지를 출력하는, 인공지능 모델일 수 있다. 제2 세퍼레이터의 출력은 익스트랙터 및 인페인터로 순차적으로 전달되어, 제1 세퍼레 이터를 이용하여 텍스트를 분리 및 인식하는 것과 같은 방식의 연산이 다시 수행될 수 있다. 도 7a는 본 개시의 일 실시예에 따른 서버가 텍스트 분리를 위해 색상 정보를 이용하는 동작을 설명하기 위한 도면이다. 도 7a 및 도 7b에서 설명하는 세퍼레이터는, 도 6의 제1 세퍼레이터에 대응될 수 있다. 일 실시예에서, 서버는 컬러 클러스터링 알고리즘을 이용하여 이미지 내에서 텍스트가 아닌 다른 객체(예 를 들어, 배경, 로고 등)의 색상들을 필터링할 수 있다. 서버는 세퍼레이터를 이용하여 오버랩 된 텍스트 가 있는 원본 이미지 내에서 검정색을 강조하여 컬러 클러스터링을 할 수 있다. 일 실시예에서, 서버는 원본 이미지를 CYMK 색공간으로 변환할 수 있다. 서버는 원본 이미지 의 CYMK 색공간에서, 검정색을 나타내는 K 채널의 임계값을 기준으로 색상들을 필터링하여, 1차 필터링 된 이미지를 획득할 수 있다(step 1). 서버가 원본 이미지를 1차 필터링 한 결과, 원본 이미지로 부터 밝은 유채색 이미지(예를 들어, 노란색 등) 등이 제거될 수 있다. 일 실시예에서, 서버는 1차 필터링 된 이미지를 Lab 색공간으로 변환할 수 있다. 서버는 Lab 색공간에서 컬러 클러스터링을 수행하고, 색상 클러스터 중에서 검정색에 인접한 클러스터에 대한 정보를 추출 함으로써, 2차 필터링 된 이미지를 획득할 수 있다(step 2). 일 실시예에 따른 서버는, 2차 필터링 된 이미지에 대하여, 텍스트 및/또는 텍스트의 문자들에 대응 하는 픽셀들을 추출하고, 손상된 픽셀들을 복원할 수 있다.도 7b는 본 개시의 일 실시예에 따른 서버가 텍스트 분리를 위해 색상 정보를 이용하는 동작을 설명하기 위한 도면이다. 일 실시예에서, 서버는 컬러 클러스터링 알고리즘을 이용하여 이미지 내에서 텍스트가 아닌 다른 객체(예 를 들어, 배경, 로고 등)의 색상들을 필터링할 수 있다. 예를 들어, 서버는 오버랩 된 텍스트가 있는 원 본 이미지를 획득하고, 원본 이미지의 색 분포를 획득할 수 있다. 서버는 예를 들어, 색 상 분포 그래프, RGB 히스토그램 등을 획득할 수 있으나, 이에 한정되는 것은 아니다. 서버는 이미지 내 색상을 N개로 클러스터링하기 위해, 색 분포에 기초하여 타겟 수 N을 결정할 수 있다. 예를 들어, 서버 는 색 분포에 기초하여 이미지 내의 우세한 색상 N개를 결정하고 컬러 클러스터링을 수행할 수 있으나, 이에 한정되는 것은 아니다. 예를 들어, 서버는 타겟 수 N을 사용자로부터 입력 받을 수도 있다. 서버는 컬러 클러스터링을 반복 수행할 수 있다. 예를 들어, 서버는 원본 이미지에 첫번째 컬 러 클러스터링을 수행하여, 원본 이미지 내에서 색상 수를 감소시킨, 1차 필터링 된 이미지를 획득할 수 있다. 구체적으로, 서버는 원본 이미지 내 색상을 3개로 클러스터링하고, 클러스터 내 포함되지 않는 색상은 필터링할 수 잇다. 이후, 서버는 1차 필터링 된 이미지에 두번째 컬러 클러스터링을 수 행하여, 1차 필터링 된 이미지 내 색상을 정밀하게 필터링할 수 있다. 구체적으로, 서버는 1차 필터 링 된 이미지 내 색상을 3개로 클러스터링하고, 클러스터 내 포함되지 않는 색상을 필터링하여 2차 필터링 된 이미지를 획득할 수 있다. 일 실시예에 따른 서버는, 2차 필터링 된 이미지에 대하여, 텍스트 및/또는 텍스트의 문자들에 대응 하는 픽셀들을 추출하고, 손상된 픽셀들을 복원할 수 있다. 도 8은 본 개시의 일 실시예에 따른 서버가 이미지 내에서 텍스트 영역들을 검출하는 동작을 설명하기 위한 도 면이다. 일 실시예에서, 서버는 이미지 내에서 텍스트에 대응되는 영역들을 검출할 수 있다. 서버는 세퍼레 이터를 이용하여 텍스트를 검출할 수 있다. 텍스트 검출 모델은 입력 이미지를 입력 받아, 이미지 내에서 텍스트의 위치들을 검출한 결과를 나타내는 텍스트 영역 맵을 출력하는 인공지능 모델일 수 있다. 일 실시예에서, 서버는 훈련용 이미지들을 포함하는 훈련 데이터셋에 기초하여 텍스트 검출 모델을 훈련 시킬 수 있다. 훈련용 이미지는, 이미지 내 텍스트의 문자들에 문자 박스들이 레이블링 되어 있을 수 있다. 또 한, 훈련용 이미지는, 이미지 내 텍스트의 관련 문자들을 엮기 위한, 관련도 박스(affinity box)들이 레이블링 되어 있을 수 있다. 관련 문자들이란 하나의 단어, 하나의 문장을 구성하는 문자들일 수 있으나, 이에 한정되는 것은 아니다. 텍스트 검출 모델은 입력 이미지 내에 텍스트의 존재를 나타내는 2D 가우시안 스코어를 계산할 수 있다. 서버는 가우시안 스코어에 기초하여 입력 이미지 내에서 텍스트 존재 영역들을 나타내는 텍스트 영 역 맵을 출력할 수 있다. 일 실시예에서, 서버는 입력 이미지에 대하여 텍스트 영역 맵을 획득하고, 텍스트 영역 맵에 기초하여 세퍼레이터를 이용한 텍스트 분리 동작을 수행할 수 있다. 이 경우, 서버가 이용하는 세퍼레이 터는 입력 이미지 외에 텍스트 영역 맵을 더 입력 받을 수 있다. 일 실시예에서, 텍스트 검출 모델은 세퍼레이터에 포함될 수 있다. 예를 들어, 제1 세퍼레이터 및/또는 제2 세 퍼레이터가 텍스트 검출 모델을 포함하여, 텍스트 검출을 먼저 수행하고, 이후에 제1 세퍼레이터 및/또는 제2 세퍼레이터의 동작을 수행할 수 있다. 도 9는 본 개시의 일 실시예에 따른 서버가 이미지 내에서 텍스트 영역들을 분리하는 동작을 설명하기 위한 도 면이다. 도 9에서 설명하는 세퍼레이터는, 도 6의 제2 세퍼레이터에 대응될 수 있다. 일 실시예에서, 서버는 세퍼레이터를 이용하여 입력 이미지 내에서 복수의 텍스트 영역들을 분 리할 수 있다. 예를 들어, 서버는 입력 이미지로부터 제1 텍스트 영역을 획득할 수 있다. 제1 텍스트 영역 은 제1 텍스트 및 제2 텍스트를 포함할 수 있다. 여기서, 제1 텍스트는 하나의 문자 그룹(예를 들어, 단어, 문장, 말뭉치 등)에 대응하는 텍스트를 말하며, 제2 텍스트는 입력 이미지로부터 제1 텍스트 영역을분리함에 따라 함께 분리된 텍스트를 말한다. 제2 텍스트는 제1 텍스트와 오버랩 되어 있을 수 있다. 따라서, 제2 텍스트는 제1 텍스트에 대하여 노이즈로 간주된다. 예를 들어, 제2 텍스트의 적어도 일부가 제1 텍스트에 오버랩 되어 있을 수 있다. 서버는 제1 텍스트 영역에 있는 제1 텍스트를 인식하기 위해, 제1 텍스 트에 대응되는 픽셀들만을 추출하고, 제1 텍스트가 제2 텍스트와 오버랩 됨으로써 손실된 픽셀을 복원할 수 있 다. 서버는 입력 이미지 내에 포함되는 모든 텍스트에 대하여 각각, 텍스트 영역들을 분리한다. 예를 들 어, 서버는 제2 텍스트 영역을 획득할 수 있다. 제2 텍스트 영역에는 온전한 하나의 문자 그룹 에 대응되는 제1 텍스트가 포함되고, 제2 텍스트 영역 내의 제1 텍스트에 대하여 노이즈로 간주되는 제2 텍스트가 포함될 수 있다. 또한, 서버는 제3 텍스트 영역을 획득할 수 있다. 제3 텍스트 영역 에는 제1 텍스트 및 제2 텍스트가 포함될 수 있다. 일 실시예에 따른 서버는 세퍼레이터를 이용하여 복수의 텍스트 영역들을 분리할 때, 텍스트 영역에 포함되는 제1 텍스트 및 제2 텍스트를 구분할 수 있다. 예를 들어, 세퍼레이터는 제1 텍스트와 제2 텍스트 에 서로 다른 레이블을 부여하도록 훈련된 인공지능 모델일 수 있다. 일 실시예에서, 세퍼레이터는 텍스트의 언어를 구별하도록 훈련된 것일 수 있다. 예를 들어, 세퍼레이터 는 텍스트의 언어(예를 들어, 영어, 한국어 등)를 구별하여, 서로 다른 언어들을 기준으로 텍스트 영역을 분리할 수 있다. 일부 실시예에서, 서버는 언어 종류를 지정하는 사용자 입력을 획득할 수 있다. 이 경우, 세퍼레이터는 사용자 입력을 추가로 입력 데이터로 활용할 수 있다. 일 실시예에서, 세퍼레이터는 텍스트의 폰트를 구별하도록 훈련된 것일 수 있다. 예를 들어, 세퍼레이터 는 텍스트의 폰트를 구별하여, 서로 다른 폰트들을 기준으로 텍스트 영역을 분리할 수 있다. 일 실시예에서, 세퍼레이터는 텍스트의 말뭉치를 구별하도록 훈련된 것일 수 있다. 예를 들어, 세퍼레이터 는 텍스트의 말뭉치(예를 들어, 중량(g))를 구별하여, 말뭉치를 기준으로 텍스트 영역을 분리할 수 있다. 이 경우, 말뭉치에 포함되는 문자들이 서로 다른 언어의 문자들(예를 들어, 한글과 알파벳)이거나, 서로 다른 폰트를 갖더라도 하나의 말뭉치로 구별될 수 있다. 서버는, 세퍼레이터를 통해 텍스트의 언어, 글씨체, 말뭉치(corpus) 및 로고 등을 구별하기 위해서, 하나의 문자 그룹 내 문자들에 대응하는 픽셀들에 레이블이 주석된 훈련 데이터를 이용하여 세퍼레이터를 훈련시킬 수 있다. 일 실시예에 따른 서버는, 이미지 내에서 복수의 텍스트 영역들을 획득하고, 각각의 텍스트 영역에 대하 여 각각의 텍스트 영역에 포함되는 제1 텍스트를 추출 및/또는 복원할 수 있다. 도 10은 본 개시의 일 실시예에 따른 서버가 텍스트 영역 내에서 제1 텍스트를 추출하는 동작을 설명하기 위한 도면이다. 일 실시예에서, 서버가 세퍼레이터를 이용하여 텍스트를 분리하면, 텍스트 영역이 획득된다. 서버 는 단어, 문장, 말뭉치 등을 기준으로 문자들을 포함하는 문자 그룹을 결정하여 텍스트 영역을 결정한다. 서버 는 익스트랙터를 이용하여 텍스트 영역 내에서 텍스트에 대응하는 픽셀들을 추출할 수 있다. 도 10 에서는, 설명의 편의를 위해, 텍스트 영역의 문자 그룹 내 문자들 전체를 표시하지 않고, 하나의 문자만을 도시 하였다. 예를 들어, 영어 텍스트를 포함하는 제1 텍스트 영역에 제1 텍스트 및 제2 텍스트가 포함될 수 있다. 여기서, 제1 텍스트는 알파벳 문자 'A'이고, 제1 텍스트에 오버랩 된 제2 텍스트는 알파벳 문자 'L'일 수 있다. 제1 텍스트 영역은 제1 텍스트 및 제2 텍스트의 정보가 포함되어 있을 수 있다. 예를 들어, 제1 텍스트의 문자와 제2 텍스트의 문자에 각각 서로 다른 레 이블이 부여되어 있을 수 있다. 서버는 제1 텍스트 영역 및 제1 텍스트 영역에 포함되는 제1 텍스트 및 제2 텍스트 의 정보에 기초하여, 제1 텍스트 영역 내 제1 텍스트의 일부 영역이 손상된 이미지 를 획득할 수 있다. 같은 방식으로, 서버는 한국어 텍스트를 포함하는 제2 텍스트 영역을 획득할 수 있다. 제2 텍스트 영역에는 제1 텍스트 및 제2 텍스트가 포함될 수 있다. 또한, 서버는 제2 텍스트 영역 에 포함되는 제1 텍스트 및 제2 텍스트의 정보를 획득할 수 있다. 서버는 제2텍스트 영역 및/또는 제2 텍스트 영역에 포함되는 제1 텍스트 및 제2 텍스트의 정보 에 기초하여, 제2 텍스트 영역 내 제1 텍스트의 일부 영역이 손상된 이미지를 획득할 수 있다. 서버는 텍스트 영역 내 제1 텍스트의 일부 영역이 손상된 이미지를 인페인팅할 수 있다. 이를 도 11a 및 도 11b를 참조하여 더 설명한다. 도 11a는 본 개시의 일 실시예에 따른 서버가 손상된 텍스트를 포함하는 이미지를 인페인팅하는 동작을 설명하 기 위한 도면이다. 일 실시예에서, 서버는 인페인터를 이용하여 이미지 내 손상된 픽셀을 복원할 수 있다. 인페인터는 제1 텍스트가 제2 텍스트와 오버랩 되었던 영역을 인페인팅함으로써 제1 텍스트를 복원할 수 있다. 예를 들어, 도 10에서 설명한 예시와 같이, 제1 텍스트는 알파벳 문자 'A'이고, 제1 텍스트에 오버랩 된 제2 텍스트는 알파벳 문자 'L'일 수 있다. 이 경우, 인페인터는 제1 텍스트의 일부 영역이 손상된 이미지 를 입력 받아, 손상된 영역이 복원된, 인페인팅 된 이미지를 출력할 수 있다. 같은 방식으로, 서버는 한국어 텍스트를 복원할 수 있다. 서버는 제1 텍스트의 한글 문자의 일부 영역이 손상된 이미지를 인페인터에 입력하고, 손상된 영역이 복원된, 인페인팅 된 이미지를 획득할 수 있다. 일 실시예에서, 서버는 인페인터를 이용하여 손상된 영역을 포함하는 이미지를 복원하기 이전에, 전처리를 수행할 수 있다. 예를 들어, 서버는 손상된 영역을 포함하는 이미지를 그레이스케일로 변환하여 컬러 채널 수를 1개로 감소시킬 수 있다. 이에 따라, 컬러 채널 수를 감소시킴에 따라 연산의 복잡성을 감소시 킬 수 있다. 인페인터는 알려진 다양한 심층 신경망 아키텍처 및 알고리즘을 이용하거나, 알려진 다양한 심층 신경망 아키텍처 및 알고리즘의 변형을 통해 구현될 수 있다. 일 실시예에 따른 서버는 인페인터를 훈련시 키기 위한 훈련 데이터를 생성하고, 훈련 데이터셋을 이용하여 인페인터를 훈련시킬 수 있다. 이를 도 11b을 참조하여 더 설명한다. 도 11b는 본 개시의 일 실시예에 따른 서버가 인페인터의 훈련 데이터를 생성하는 동작을 설명하기 위한 도면이 다. 일 실시예에서, 서버는 인페인터를 훈련시키기 위한 훈련 데이터를 생성할 수 있다. 서버 는 정답 데이터 및 노이즈 데이터에 기초하여 훈련 데이터를 생성할 수 있다. 서버는 정답 데이터에 노이즈 데이터를 오버랩시킴으로써 훈련 데이터를 생성할 수 있 다. 예를 들어, 서버는 정답 데이터로부터 정답 데이터에 오버랩 된 노이즈 데이터의 픽셀들을 제거함으로써, 정답 데이터가 손상된, 훈련 데이터를 생성할 수 있다. 여기서, 정답 데이 터는 전술한 실시예의 제1 텍스트에 대응되며, 노이즈 데이터는 제2 텍스트에 대응된다. 일 실시예에서, 서버가 훈련 데이터를 생성할 때, 서버는 텍스트의 언어, 폰트, 말뭉치 중 적어도 하나에 기초하여 훈련 데이터를 생성할 수 있다. 서버는 오버랩 가능성이 높은 텍스트를 정 답 데이터 및 노이즈 데이터로 사용하여 훈련 데이터를 생성할 수 있다. 오버랩 가능성이 높 은 텍스트는 텍스트의 연관도에 기초하여 결정될 수 있다. 예를 들어, 오버랩 가능성이 높은 텍스트는 텍스트의 언어, 폰트, 말뭉치 중 적어도 하나에 기초하여 기 설정된 것일 수 있다. 예를 들어, 오버랩 가능성이 높은 텍 스트는 사용자 입력에 의해 오버랩 가능성이 높은 텍스트로 설정된 것일 수 있다. 구체적인 예를 들면, A 마트 에서 채끝 등심(SIRLOIN) 상품을 판매하고, 상품 라벨에 상호 'A 마트'와 상품명 'SIRLOIN'이 오버랩 되는 경우 가 있으면, 'SIRLOIN'과 'A-MART'가 오버랩 가능성이 높은 텍스트로 설정될 수 있다. 도 11b에서는 'SIRLOIN'을 정답 데이터, 'A-MART'를 노이즈 데이터로 하여 훈련 데이터를 생성하는 예시를 도시하였으 나, 'SIRLOIN'을 노이즈 데이터, 'A-MART'를 정답 데이터로 설정하여 훈련 데이터가 생성될 수도 있다. 같은 방식으로, 서버는 텍스트의 연관도에 기초하여 설정된, 한국어 텍스트의 정답 데이터 와 노이즈 데이터를 이용하여 훈련 데이터를 생성할 수도 있다. 도 12는 본 개시의 일 실시예에 따른 텍스트 분리 네트워크를 설명하기 위한 도면이다. 일 실시예에서, 텍스트 분리 네트워크는 제1 텍스트 분리 네트워크와 제2 텍스트 분리 네트워크로 구별될 수 있다. 제1 텍스트 분리 네트워크는 세퍼레이터, 익스트랙터 및 인페인터를 포함할 수 있다. 제1 세퍼레이터에 포함되는 세퍼레이터, 익스트랙터 및 인페인터에 관해서는, 이전의 도면들에 대한 설명에서 기술하였으므로 반복되는 설명은 생략한다. 제2 텍스트 분리 네트워크는 세퍼레이터 및 익스트랙터만을 포함할 수 있다. 제2 텍스트 분 리 네트워크에 포함되는 세퍼레이터 및 익스트랙터는 제1 텍스트 분리 네트워크의 세 퍼레이터 및 익스트랙터와 동일한 기능을 수행한다. 제2 텍스트 분리 네트워크는 인페인터 를 포함하지 않으므로, 제1 텍스트 분리 네트워크에 비해 텍스트 분리 연산의 연산량이 상대적으로 적다. 즉, 제2 텍스트 분리 네트워크는 제1 텍스트 분리 네트워크의 라이트(lite) 버전일 수 있다. 서버는 제1 텍스트 분리 네트워크 또는 제2 텍스트 분리 네트워크를 선택적으로 이용할 수 있다. 일 실시예에서, 서버는 제2 텍스트 분리 네트워크를 우선적으로 사용하고, 제1 텍스트 분리 네트워 크를 후순위로 사용할 수 있다. 서버는 제2 텍스트 분리 네트워크를 이용하여 분리된 텍스트 를 포함하는 이미지를 획득할 수 있다. 서버는 광학 문자 인식(Optical character recognition; OCR) 모 델을 이용하여, 이미지에 포함되는 텍스트(예를 들어, 일반 문자, 특수 문자(special character) 및 기호 (symbol) 등)를 인식할 수 있다. 서버는 OCR 인식 결과 인식 신뢰도가 기 설정된 값 이상인지 여부에 기 초하여 인식 결과의 유효성을 판단할 수 있다. 서버는 텍스트 인식 결과가 유효하지 않다고 판단되면, 보 다 정밀한 텍스트 분리 작업 및 텍스트 인식을 다시 수행하기 위해, 인페인터를 더 포함하는 제1 세퍼레 이터를 이용할 수 있다. 일 실시예에서, 서버는 보다 빠른 연산 결과 출력을 위해, 제1 텍스트 네트워크 대신 제2 텍스트 분리 네트워크를 이용하여 텍스트 분리를 수행할 수 있다. 이 경우, 서버는 인페인팅 되지 않은 텍 스트의 이미지를 사용자에게 제공하거나, 인페인팅 되지 않은 텍스트의 이미지에 기초하여 텍스트를 인식한 결 과를 사용자에게 제공할 수 있다. 일 실시예에서, 서버는 사용자 입력에 기초하여 제1 텍스트 분리 네트워크를 이용할 지 또는 제2 텍스트 분리 네트워크를 이용할 지 여부를 결정할 수 있다. 예를 들어, 사용자가 데이터를 적게 사용하기 위해 제2 텍스트 분리 네트워크를 이용할 것을 선택할 수 있다. 일 실시예에서, 서버는 사용자 정보에 기초하여 제1 텍스트 분리 네트워크를 이용할 지 또는 제2 텍스트 분리 네트워크를 이용할 지 여부를 결정할 수 있다. 예를 들어, 서버는 무료 사용자에게 체 험용 버전으로 제2 텍스트 분리 네트워크를 제공할 수 있다. 일 실시예에서, 텍스트 분리 및 인식 작업은 사용자의 전자 장치(예를 들어, 스마트폰)에 의해서 수행될 수도 있다. 사용자의 전자 장치는 서버에 비해 컴퓨팅 성능이 상대적으로 낮기 때문에, 사용자의 전자 장치는 제2 텍스트 분리 네트워크를 이용하여 텍스트 분리 및 인식 작업을 수행할 수 있다. 예를 들어, 사용자가 스마트폰을 이용하여 텍스트를 포함하는 라벨 등을 촬영하면, 스마트폰은 제2 텍스트 분리 네트워크를 이 용하여 오버랩 된 텍스트를 분리할 수 있다. 스마트폰은 텍스트가 분리되면 OCR을 이용하여 분리된 텍스트를 인 식할 수 있다. 도 13a는 본 개시의 일 실시예에 따른 서버가 가전 장치인 냉장고와 연계하여 동작하는 것을 설명하기 위한 도 면이다. 도 13a를 참조하면, 서버는 사용자의 전자 장치 및 냉장고와 데이터 통신을 수행할 수 있다. 일 실시예에서, 사용자는 전자 장치를 이용하여 상품 라벨을 촬영할 수 있다. 도 13a 내지 도 13c를 설명 함에 있어서, 사용자가 촬영하는 상품 라벨이 육류 상품의 라벨인 것을 예시로 설명할 것이나, 상품 종류는 이 에 한정되는 것은 아니다. 예를 들어, 상품은 식품일 수 있다. 서버는 사용자의 전자 장치로부터 상품 라벨의 이미지를 수신할 수 있다. 이 경우, 상품 라벨의 이미지에는 오버랩 된 텍스트가 있을 수 있다. 서버는 이미지 내 오버랩 된 텍스트들을 분리하고, 분리된 텍스트를 인식하여 상품과 관련된 정보를 생성 할 수 있다. 예를 들어, 서버는 육류 상품과 관련된 정보로, 상품명, 중량, 가격, 바코드, 상품 식별 번 호, 제조 일자, 제조사, 판매사, 유통기한 등의 정보를 생성할 수 있다. 서버는 상품과 관련된 정보를 사용자의 전자 장치 및/또는 냉장고로 전송할 수 있다. 서버는 상품과 관련된 정보에 기초하여 냉장고를 제어할 수 있다. 예를 들어, 서버는 냉장고 내에 고기가 보관될 위치를 입력 받거나 고기가 보관될 위치를 결정(예를 들어, 냉장고 내 빈 공 간으로 결정)할 수 있다. 서버는 결정된 보관 위치에 최적의 온도 등이 설정되도록하는, 고기 보관 모드 가 냉장고에서 실행되도록 할 수 있다. 도 13b는 서버가 가전 장치인 냉장고와 연계하여 동작하는 것을 더 설명하기 위한 도면이다. 일 실시예에서, 사용자는 전자 장치를 이용하여 육류 상품을 촬영하고 육류 상품의 라벨 이 미지를 획득할 수 있다. 서버는 전자 장치로부터 육류 상품의 라벨 이미지를 획득할 수 있다. 서버는 육류 상품의 라벨 이미지에 대한 텍스트 분리 및 텍스트 인식을 수행하여 육류 상품 과 관련된 정보를 전자 장치로 제공할 수 있다. 일 실시예에서, 사용자의 전자 장치는 홈 내 여러 가전들을 원격으로 관리할 수 있는 애플리케이션을 제 공할 수 있다. 애플리케이션은 예를 들어, 냉장고를 관리/제어할 수 있는 애플리케이션일 수 있으나, 이 에 한정되는 것은 아니다. 전자 장치에 설치된 애플리케이션의 제1 화면을 참조하면, 애플리케이션은 상품 라벨 인식을 위한 인터페이스를 포함할 수 있다. 예를 들어, 제1 화면에는 육류 라벨 스캔 버튼이 포함될 수 있으나, 이에 한정되는 것은 아니다. 전자 장치는 사용자가 육류 라벨 스캔 버튼을 선택함에 따라, 상품 라벨 인식을 수행할 수 있도록 하는 제2 화면을 표시할 수 있다. 예를 들어, 전자 장치는 제2 화면에 상품 라벨이 포함되도록 가 이드하는 사각 박스(다만, 사각형에 한정되지 않으며, 원형 등 유사한 기능을 할 수 있는 다른 형태를 포 함함)를 표시하고, '육류 라벨을 촬영하세요' 등의 가이드를 표시할 수 있다. 일부 실시예에서, 전자 장치 는 제2 화면에 표시되는 이미지로부터 객체가 인식되지 않는 경우, '카메라를 통해 상품을 비춰 주 세요' 등의 가이드를 표시할 수 있다. 전자 장치는 카메라로부터 획득되는 프리뷰 이미지를 화면에 표시 할 수 있다. 사용자는 제2 화면을 보면서, 상품의 라벨이 사각 박스 이미지 내에 완전히 포함되도 록 카메라의 시야를 조정할 수 있다. 전자 장치는 서버로 상품 라벨 이미지를 전송할 수 있다. 예를 들어, 전자 장치는 애플리케 이션을 통해서 육류 라벨 이미지를 서버로 전송할 수 있다. 전자 장치는, 상품 라벨 이미지에 기초 하여 서버에서 생성된 상품(예: 육류 상품)과 관련된 정보를 수신할 수 있다. 전자 장치는, 서버로부터 수신된 상품과 관련된 정보를 제3 화면에 표시할 수 있다. 예를 들어, 전자 장치(300 0)는 육류 종류, 원산지, 부위, 중량, 개체 이력 번호 등 육류 상품을 나타내는 정보를 표시할 수 있다. 예를 들어, 전자 장치는 육류 보관하기 등, 가전 장치의 제어와 관련된 액션 정보를 표시할 수 있다. 가전 장치는 예를 들어, 냉장고일 수 있으나, 이에 한정되는 것은 아니다. 전자 장치는 상품과 관련된 가전 장치의 액션 정보를 나타내는, 제4 화면을 표시할 수 있다. 예를 들어, 사용자가 냉장고에 육류를 보관하기 위해 제3 화면에서 '육류 보관하기'의 액션을 선택 하는 경우, 전자 장치는 육류 보관과 관련된 항목들을 포함하는 제4 화면을 표시할 수 있다. 제4 화면에는 예를 들어, 육류 사진, 상품명, 입고일, 보관 위치 등이 표시될 수 있으나, 이에 한정되는 것은 아니다. 또한, 제4 화면은 전자 장치 또는 서버가 냉장고를 제어하기 위한 인터페이스 를 포함할 수 있다. 예를 들어, 전자 장치는 제4 화면에 냉장고를 제어하기 위한 버튼 (예: '냉장고에 보관 시작')을 표시할 수 있으나, 이에 한정되는 것은 아니다. 전자 장치는 사용자가 냉장고를 제어하기 위한 버튼을 선택하면, 사용자에게 냉장고의 조작과 관련된 가이드를 제공할 수 있다. 예를 들어, 전자 장치는 제5 화면에서, 사용자가 냉장고에 육류를 보관할 수 있도록 하는 가이드(예: '냉장고 멀티팬트리에서 육류 보관 모드를 시 작했습니다. 고기를 넣어주세요')를 표시할 수 있다. 전자 장치는 냉장고가 멀티팬트리 칸을 육류 보관 모드로 동작하도록 하기 위해, 냉장고에 대한 제어 명령을 전송할 수 있다. 전자 장치는 냉장고에 대한 제어 명령을 서버를 통해 냉 장고로 전송할 수도 있고, 냉장고로 직접 전송할 수 있다. 도 13c는 서버와 연계하여 동작하는 가전 장치의 동작을 설명하기 위한 도면이다. 일 실시예에서, 서버는 도 13a 및 도 13b에서 전술한 것과 같이 냉장고와 연계하여 동작할 수 있다. 구체적으로, 서버는 상품과 관련된 정보를 냉장고로 전송할 수 있다. 이 경우, 상품과 관련 된 정보가 냉장고의 디스플레이에 표시될 수 있다. 예를 들어, 전술한 예시와 같이 상품 라벨이 육류 상품 라벨인 경우, 냉장고의 디스플레이에는 육 류 종류, 원산지, 부위, 중량, 개체 이력 번호 등 육류 상품을 나타내는 정보가 표시될 수 있다. 예를 들어, 인식된 육류 상품 라벨에 대응하는 육류를 사용자가 냉장고에 보관하는 경우, 냉장고의 디스 플레이에는 육류의 보관 위치, 보관 기간, 보관 온도, 동작 모드 등, 육류 상품과 관련된 정보가 표시될 수 있다. 또는, 냉장고의 디스플레이에는 육류 상품의 레시피를 나타내는 텍스트, 이미지 및 동영 상, 육류 요리 관련 식재료의 추천, 식재료 구매 링크 제공 등, 상품과 관련된 다양한 정보가 표시될 수 있다. 도 14a는 본 개시의 일 실시예에 따른 서버가 가전 장치인 오븐과 연계하여 동작하는 것을 설명하기 위한 도면 이다. 도 14a를 참조하면, 서버는 사용자의 전자 장치 및 오븐과 데이터 통신을 수행할 수 있다. 일 실시예에서, 사용자는 전자 장치를 이용하여 상품 라벨을 촬영할 수 있다. 도 14a 내지 도 14b를 설명 함에 있어서, 사용자가 촬영하는 상품 라벨이 육류 상품의 라벨인 것을 예시로 설명할 것이나, 상품 종류는 이 에 한정되는 것은 아니다. 예를 들어, 상품은 식품일 수 있다. 서버는 사용자의 전자 장치로부터 상품 라벨의 이미지를 수신할 수 있다. 이 경우, 상품 라벨의 이미지에는 오버랩 된 텍스트가 있을 수 있다. 서버는 이미지 내 오버랩 된 텍스트들을 분리하고, 분리된 텍스트를 인식하여 상품과 관련된 정보를 생성 할 수 있다. 예를 들어, 서버는 육류 상품과 관련된 정보로, 상품명, 중량, 가격, 바코드, 상품 식별 번 호, 제조 일자, 제조사, 판매사, 유통기한 등의 정보를 생성할 수 있다. 서버는 상품과 관련된 정보를 사 용자의 전자 장치 및/또는 오븐으로 전송할 수 있다. 서버는 상품과 관련된 정보에 기초하여 오븐을 제어할 수 있다. 예를 들어, 서버는 스테이크 조리를 위한 설정인 온도, 시간, 동작 모드(예를 들어, 예열 모드, 컨벡션 모드 등)를 결정할 수 있다. 서버 는 결정된 오븐의 제어 동작과 관련된 설정들을 오븐으로 전송하여, 스테이크 조리를 위한 설정들 이 오븐에서 자동으로 적용되도록 할 수 있다. 도 14b는 서버가 가전 장치인 오븐과 연계하여 동작하는 것을 더 설명하기 위한 도면이다. 일 실시예에서, 사용자는 전자 장치를 이용하여 육류 상품을 촬영하고 육류의 상품 라벨 이미지를 획득할 수 있다. 서버는 전자 장치로부터 상품 라벨의 이미지를 획득하고, 텍스트 분리 및 인식을 수행하여 상품과 관련된 정보를 전자 장치로 제공할 수 있다. 일 실시예에서, 사용자의 전자 장치는 애플리케이션은 홈 내 여러 가전들을 원격으로 관리할 수 있는 애 플리케이션을 제공할 수 있다. 애플리케이션은 예를 들어, 오븐을 관리/제어할 수 있는 애플리케이션일 수 있으나, 이에 한정되는 것은 아니다. 전자 장치에 설치된 애플리케이션의 제1 화면을 참조하면, 애플리케이션은 상품 라벨 인식을 위한 인터페이스를 포함할 수 있다. 예를 들어, 제1 화면에는 육류 라벨 스캔 버튼이 포함될 수 있으나, 이에 한정되는 것은 아니다. 전자 장치는 사용자가 육류 라벨 스캔 버튼을 선택함에 따라, 상품 라벨 인식을 수행할 수 있도록 하는 제2 화면을 표시할 수 있다. 예를 들어, 전자 장치는 제2 화면에 상품의 라벨이 포함되도록 가이드하는 사각 박스(다만, 사각형에 한정되지 않으며, 원형 등 유사한 기능을 할 수 있는 다른 형태를 포함함)를 표시하고, '육류 라벨을 촬영하세요' 등의 가이드를 표시할 수 있다. 일부 실시예에서, 전자 장치 는 제2 화면에 표시되는 이미지로부터 객체가 인식되지 않는 경우, '카메라를 통해 상품을 비춰 주 세요' 등의 가이드를 표시할 수 있다. 전자 장치는 카메라로부터 획득되는 프리뷰 이미지를 화면에 표시 할 수 있다. 사용자는 제2 화면을 보면서, 상품의 라벨이 이미지 내에 완전히 포함되도록 카메라의 시야 를 조정할 수 있다. 전자 장치는 서버로 상품 라벨 이미지를 전송하고, 서버로부터 상품과 관련된 정보를 제3 화 면에 표시할 수 있다. 예를 들어, 전자 장치는 육류 종류, 원산지, 부위, 중량, 개체 이력 번호 등 육류 상품을 나타내는 정보를 표시할 수 있다. 예를 들어, 전자 장치는 육류 해동하기, 요리하기,레시피 등 가전 장치를 제어와 관련된 액션 정보를 표시할 수 있다. 가전 장치는 예를 들어, 오븐 일 수 있으나, 이에 한정되는 것은 아니다. 전자 장치는 상품과 관련된 가전 장치의 액션 정보를 나타내는, 제4 화면을 표시할 수 있다. 예를 들어, 사용자가 육류로 스테이크 요리를 하기 위해 제3 화면에서 '요리하기'의 액션을 선택하는 경 우, 전자 장치는 스테이크 조리와 관련된 정보를 포함하는 제4 화면을 표시할 수 있다. 제4 화면 에는 예를 들어, 레시피, 요리를 위한 설정 및 준비사항 등이 표시될 수 있으나, 이에 한정되는 것은 아 니다. 또한, 제4 화면은 전자 장치 또는 서버가 오븐을 제어하기 위한 인터페이스를 포함할 수 있다. 예를 들어, 전자 장치는 제4 화면에 오븐을 제어하기 위한 버튼 '오 븐에서 조리 시작'을 표시할 수 있으나, 이에 한정되는 것은 아니다. 전자 장치는 사용자가 오븐을 제어하기 위한 버튼을 선택하면, 사용자에게 오븐의 조 작과 관련된 가이드를 제공할 수 있다. 예를 들어, 전자 장치는 제5 화면에서, 사용자가 스테이크 조리를 할 수 있도록 하는 가이드 '스테이크 조리를 위한 오븐 설정을 완료했습니다. 오븐에 고기를 넣어 주세요'를 표시할 수 있다. 전자 장치는 오븐의 조리 동작 모드 설정을 위해, 오븐에 대한 제어 명령을 서버 또는 오븐으로 전송할 수 있다. 도 15는 일 실시예에 따른 서버가 가전 장치와 연계하여 동작하는 것을 설명하기 위한 흐름도이다. 도 15를 참조하면, 일 실시예에 따른 서버는 전자 장치 및 가전 장치와 데이터 통신을 수행 할 수 있다. 전자 장치는 전술한 예시인 스마트 폰을 포함할 수 있으나, 이에 한정되는 것은 아니다. 가 전 장치는 전술한 예시인, 냉장고 및 오븐을 포함할 수 있으나, 이에 한정되는 것은 아니다. 단계 S1510에서, 전자 장치는 상품 라벨 이미지를 촬영할 수 있다. 전자 장치는 사용자의 카메라 조작에 의해 상품 라벨 이미지를 촬영할 수 있다. 이 경우, 상품 라벨 이미지에는 오버랩 된 텍스트가 포함될 수 있다. 단계 S1515에서, 전자 장치는 상품 이미지를 서버로 전송할 수 있다. 단계 S1520에서, 서버는 상품 라벨 이미지로부터 텍스트를 분리할 수 있다. 서버는 텍스트 분리 네 트워크를 이용하여, 상품 라벨 이미지 내에 오버랩 된 텍스트를 분리 및 추출할 수 있다. 서버는 세퍼레 이터, 익스트랙터 및 인페인터를 포함하는 제1 텍스트 분리 네트워크를 이용하여 텍스트를 분리할 수 있다. 서 버는 세퍼레이터 및 익스트랙터를 포함하는 제2 텍스트 분리 네트워크를 이용하여 텍스트를 분리할 수 있 다. 세퍼레이터는 컬러 클러스터링 알고리즘을 이용하는 제1 세퍼레이터 및 인공지능 모델인 텍스트 분리 모델 을 포함하는 제2 세퍼레이터를 포함할 수 있다. 서버는 텍스트를 인식할 수 있다. 서버는 인식된 텍스트에 기초하여 상품과 관련된 정보를 생성할 수 있다. 상품과 관련된 정보는 예를 들어, 상품명, 중량, 가 격, 바코드, 상품 식별 번호, 제조 일자, 제조사, 판매사, 유통기한 등을 포함할 수 있으나, 이에 한정되는 것 은 아니다. 단계 S1525에서, 서버는 상품과 관련된 정보를 전자 장치로 전송할 수 있다. 단계 S1530에서, 전자 장치는 상품과 관련된 정보를 표시할 수 있다. 전자 장치가 상품과 관련된 정보를 표시하는 것은 도 13b 및 도 14b에서 기술하였으므로, 반복되는 설명은 생략한다. 단계 S1532, S1534, S1536에서, 전자 장치 및/또는 서버는 가전 장치를 제어할 수 있다. 예 를 들어, 전자 장치는 가전 제어 요청을 서버로 전송하고(S1532), 서버가 가전 장치로 가전 제어 명령을 전송할 수 있다(S1534). 또는, 전자 장치가 가전 장치로 가전 제어 명령을 전송 할 수도 있다(S1536). 단계 S1540에서, 가전 장치는 제어 명령에 대응되는 동작을 수행할 수 있다. 예를 들어, 가전 장치(150 0)가 냉장고인 경우, 냉장고의 동작 모드에 따라 온도를 설정하고, 보관 위치에 보관 상품에 관련 된 정보를 저장할 수 있다. 예를 들어, 가전 장치가 오븐인 경우, 오븐의 동작 모드에 따라 온도 등 조리와 관련된 설정을 할 수 있다. 도 16은 본 개시의 일 실시예에 따른 서버의 블록도이다. 일 실시예에 따른 서버는 통신 인터페이스, 메모리 및 프로세서를 포함할 수 있다. 통신 인터페이스는 통신 회로를 포함할 수 있다. 통신 인터페이스는 예를 들어, 유선 랜, 무선 랜 (Wireless LAN), 와이파이(Wi-Fi), 블루투스(Bluetooth), 지그비(ZigBee), WFD(Wi-Fi Direct), 적외선 통신 (IrDA, infrared Data Association), BLE (Bluetooth Low Energy), NFC(Near Field Communication), 와이브로 (Wireless Broadband Internet, Wibro), 와이맥스(World Interoperability for Microwave Access, WiMAX), SWAP(Shared Wireless Access Protocol), 와이기그(Wireless Gigabit Alliances, WiGig) 및 RF 통신을 포함하 는 데이터 통신 방식 중 적어도 하나를 이용하여, 서버와 다른 디바이스들 간의 데이터 통신을 수행할 수 있는, 통신 회로를 포함할 수 있다. 통신 인터페이스는 서버의 동작을 수행하기 위한 데이터를 외부 전자 장치와 송수신할 수 있다. 예 를 들어, 서버는 통신 인터페이스를 통해 오버랩 된 텍스트가 있는 이미지를 외부의 전자 장치(예 를 들어, 사용자의 스마트폰 등)로부터 수신하고, 텍스트 분리 및 인식을 통해 생성된 상품과 관련된 정보를 외 부의 전자 장치로 송신할 수 있다. 또한, 서버는 통신 인터페이스를 통해 가전 장치를 제어하기 위 한 데이터를 가전 장치와 송수신할 수 있다. 메모리는 프로세서가 판독할 수 있는 명령어들, 데이터 구조, 및 프로그램 코드(program code)가 저장될 수 있다. 메모리는 하나 이상일 수 있다. 개시된 실시예들에서, 프로세서가 수행하는 동작 들은 메모리에 저장된 프로그램의 명령어들 또는 코드들을 실행함으로써 구현될 수 있다. 메모리는 ROM(Read-only memory)(예를 들어, PROM(Programmable read-only memory), EPROM(Erasable programmable read-only memory), EEPROM(Electrically erasable programmable read-only memory)), 플래시 메모리(Flash memory)(예를 들어, 메모리 카드, SSD(Solid-state drive)) 및 아날로그 기록 타입(예를 들어, HDD(Hard disk drive), 자기테이프, 광학 디스크)와 같은 비휘발성 메모리 및, RAM(random-access memory)(예 를 들어, DRAM(Dynamic random-access memory), SRAM(Static random-access memory))과 같은 휘발성 메모리를 포함할 수 있다. 메모리는 서버가 오버랩 된 텍스트를 분리 및 추출하기 위해 동작하도록 하는 하나 이상의 인스트 럭션 및 프로그램을 저장할 수 있다. 예를 들어, 메모리에는 세퍼레이터, 익스트랙터 및 인 페인터가 저장될 수 있다. 이전의 도면들에서 전술한 것과 같이, 제1 텍스트 분리 네트워크는 세퍼레이터 , 익스트랙터 및 인페인터를 포함할 수 있고, 제2 텍스트 분리 네트워크는 세퍼레이터 및 익스트랙터를 포함할 수 있다. 세퍼레이터는 컬러 클러스터링 알고리즘을 이용하는 제1 세퍼레 이터 및 인공지능 모델인 텍스트 분리 모델을 포함하는 제2 세퍼레이터를 포함할 수 있다. 프로세서는 서버의 전반적인 동작들을 제어할 수 있다. 예를 들어, 프로세서는 메모리(220 0)에 저장된 프로그램의 하나 이상의 명령어들(instructions)을 실행함으로써, 서버가 오버랩 된 텍스트 를 분리하고 인식하도록 하는 전반적인 동작들을 제어할 수 있다. 프로세서는 하나 이상일 수 있다. 하나 이상의 프로세서는 CPU (Central Processing Unit), GPU (Graphics Processing Unit), APU (Accelerated Processing Unit), MIC (Many Integrated Core), DSP (Digital Signal Processor), 및 NPU (Neural Processing Unit) 중 적어도 하나를 포함할 수 있다. 하나 이상의 프로세서는, 하나 이상의 전자 부품을 포함하는 집적된 시스템 온 칩(SoC) 형태로 구현될 수 있다. 하나 이상의 프로세서 각각은 별개의 하드 웨어(H/W)로 구현될 수도 있다. 프로세서는 세퍼레이터를 이용하여, 입력 이미지 내에서 복수의 텍스트 영역들을 분리할 수 있다. 프로세서는 단어, 문장, 말뭉치 등을 기준으로 문자들을 포함하는 문자 그룹을 결정하여 텍스트 영역을 결정할 수 있다. 이 경우, 입력 이미지 내에는 오버랩 된 텍스트가 있을 수 있다. 예를 들어, 제1 텍스트 위에 제2 텍스트가 오버랩 되어 있을 수 있다. 프로세서는 입력 이미지 내에 포함되는 모든 텍스트에 대하여 각각 텍스트 영역들을 분리함으로써, 오버랩 된 텍스트 각각에 대응하는 텍스트 영역들을 획득할 수 있다. 세퍼 레이터의 동작들과 관련된 설명은 전술한 도면들에서 이미 설명하였으므로, 간결함을 위해 반복되는 설명 은 생략한다. 프로세서는 익스트랙터를 이용하여, 텍스트 영역 내에서 텍스트에 대응하는 픽셀들을 추출할 수 있 다. 예를 들어, 프로세서는 제1 텍스트를 포함하는 제1 텍스트 영역에서, 제1 텍스트에 오버랩 된 제2 텍 스트는 제외하고, 제1 텍스트에 대응하는 픽셀들만을 추출할 수 있다. 이 경우, 제1 텍스트 영역에서 제1 텍스 트에 오버랩 되었던 제2 텍스트가 제거됨에 따라, 제1 텍스트의 일부 영역이 손상된 이미지가 획득될 수 있다. 익스트랙터의 동작들과 관련된 설명은 전술한 도면들에서 이미 설명하였으므로, 간결함을 위해 반복되는설명은 생략한다. 프로세서는 인페인터를 이용하여 이미지 내 손상된 픽셀을 복원할 수 있다. 프로세서는 인페 인터를 이용하여 제1 텍스트 영역에서 제1 텍스트가 제2 텍스트와 오버랩 되었던 영역을 인페인팅함으로 써 제1 텍스트를 복원할 수 있다. 인페인터의 동작들과 관련된 설명은 전술한 도면들에서 이미 설명하였 으므로, 간결함을 위해 반복되는 설명은 생략한다. 한편, 전술한 메모리에 저장되어 프로세서에 의해 실행되는 모듈들은, 설명의 편의를 위한 것이며 반드시 이에 한정되는 것은 아니다. 전술한 실시예들을 구현하기 위해 다른 모듈이 추가될 수 있으며, 하나의 모듈이 세부적인 기능들에 따라 구별되는 복수의 모듈들로 분할될 수 있고, 전술한 모듈들 중 일부의 모듈들이 합쳐져 하나의 모듈로 구현될 수도 있다. 예를 들어, 세퍼레이터, 익스트랙터 및 인페인터가 하나로 합쳐져 제1 텍스트 분리 네트워크로 지칭될 수 있으며, 세퍼레이터 및 익스트랙터가 하나로 합쳐져 제2 텍스트 분리 네트워크로 지칭될 수도 있으나, 이에 한정되는 것은 아니다. 본 개시의 일 실시예에 따른 방법이 복수의 동작을 포함하는 경우, 복수의 동작은 하나의 프로세서에 의해 수행 될 수도 있고, 복수의 프로세서에 의해 수행될 수도 있다. 예를 들어, 일 실시예에 따른 방법에 의해 제1 동작, 제2 동작, 제3 동작이 수행될 때, 제1 동작, 제2 동작, 및 제3 동작 모두 제1 프로세서에 의해 수행될 수도 있 고, 제1 동작 및 제2 동작은 제1 프로세서(예를 들어, 범용 프로세서)에 의해 수행되고 제3 동작은 제2 프로세 서(예를 들어, 인공지능 전용 프로세서)에 의해 수행될 수도 있다. 여기서, 제2 프로세서의 예시인 인공지능 전 용 프로세서는, 인공지능 모델의 훈련/추론을 위한 연산들이 수행될 수도 있다. 그러나, 본 개시의 실시예들이 이에 한정되는 것은 아니다. 본 개시에 따른 하나 이상의 프로세서는 싱글 코어 프로세서(single-core processor)로 구현될 수도 있고, 멀티 코어 프로세서(multi-core processor)로 구현될 수도 있다. 본 개시의 일 실시예에 따른 방법이 복수의 동작을 포함하는 경우, 복수의 동작은 하나의 코어에 의해 수행될 수도 있고, 하나 이상의 프로세서에 포함된 복수의 코어에 의해 수행될 수도 있다. 도 17은 본 개시의 일 실시예에 따른 전자 장치의 블록도이다. 일 실시예에서, 전술한 서버의 동작들은 전자 장치에서 수행될 수도 있다. 일 실시예에 따른 전자 장치는 통신 인터페이스, 디스플레이, 카메라, 메모리 및 프로세서를 포함할 수 있다. 전자 장치의 통신 인터페이스, 메모리 및 프로세서 는 도 16의 서버의 통신 인터페이스, 메모리 및 프로세서에 각각 대응되므로, 반복되는 설명은 생략한다. 디스플레이는 전자 장치에서 처리되는 정보를 출력할 수 있다. 한편, 디스플레이와 터치패드가 레 이어 구조를 이루어 터치 스크린으로 구성되는 경우, 디스플레이는 출력 장치 이외에 입력 장치로도 사용될 수 있다. 디스플레이는 액정 디스플레이(Liquid crystal display; LCD), 박막 트랜지스터 액정 디스플레이(Thin- film-transistor liquid crystal display; TFT LCD), 유기 발광 다이오드(Organic light-emitting diode; OLED), 플렉시블 디스플레이(Flexible display), 3차원 디스플레이(3D display), 마이크로 디스플레이(Micro display), 헤드 마운트 디스플레이(Head-mounted display; HMD) 중 적어도 하나를 포함할 수 있다. 전자 장치 는 상품 라벨의 인식을 통해 획득된 상품과 관련된 정보를 디스플레이에 표시할 수 있다. 카메라(들)는 객체를 촬영하여 비디오 및/또는 이미지를 획득할 수 있다. 카메라(들)는 하나 이상 일 수 있다. 카메라(들)는 예를 들어, RGB 카메라, 망원 카메라, 광각 카메라, 초광각 카메라 등을 포함 할 수 있으나, 이에 한정되는 것은 아니다. 카메라(들)는 복수의 프레임들을 포함하는 비디오를 획득할 수 있다. 카메라(들)의 구체적인 종류 및 세부 기능은 통상의 기술자가 명확하게 추론할 수 있으므로, 설 명을 생략한다. 도 17에는 도시 되지는 않았지만, 입출력 인터페이스를 더 포함할 수 있다. 입출력 인터페이스는 사용자의 입력 을 수신하는 입력 인터페이스 및 디스플레이에서 출력되는 영상/동영상 신호 외 다른 신호를 출력하는 출 력 인터페이스를 더 포함할 수 있다. 입력 인터페이스는, 사용자로부터의 입력을 수신하기 위한 것이다. 입력 인터페이스는, 키 패드(key pad), 돔 스위치 (dome switch), 터치 패드(접촉식 정전 용량 방식, 압력식 저항막 방식, 적외선 감지 방식, 표면 초음파 전도 방식, 적분식 장력 측정 방식, 피에조 효과 방식 등), 조그 휠, 조그 스위치 중 적어도 하나를 포함할 수있으나, 이에 한정되는 것은 아니다. 출력 인터페이스는 스피커를 포함할 수 있다. 스피커는 통신 인터페이스로부터 수신되거나 메모리 에 저장된 오디오 신호를 출력할 수 있다. 도 18은 본 개시의 일 실시예에 따른 냉장고의 블록도이다. 일 실시예에 따른 냉장고는 본체, 저장실, 도어, 냉기 공급 장치, 전력 모듈 , 프로세서, 메모리, 통신 모듈, 입력 인터페이스 및 출력 인터페이스를 포함할 수 있다. 본체는 내상과, 내상의 외측에 배치되는 외상과, 내상과 외상의 사이에 마련되는 단열재를 포함할 수 있 다. 내상은 저장실을 형성하는 케이스(case), 플레이트(plate), 패널(panel) 또는 라이너(liner) 중 적어도 하나를 포함할 수 있다. 내상은 하나의 몸체로 형성될 수도 있으며 또는 복수의 플레이트들이 조립되어 형성될 수 있다. 외상은 본체의 외관을 형성할 수 있으며, 내상과 외상의 사이에 단열재가 배치되도록 내상의 외 측에 결합될 수 있다. 단열재는 저장실 내부의 온도가 저장실 외부 환경에 의해 영향을 받지 않고 설정된 적정 온도로 유 지될 수 있도록 저장실 내부와 저장실 외부를 단열할 수 있다. 일 실시예에 따르면 단열재는 발포 단열재를 포함할 수 있다. 내상과 외상의 사이에 폴리우레탄과 발포제가 혼합된 우레탄폼을 주입 및 발포시킴으 로써 발포 단열재를 성형할 수 있다. 일 실시예에 따르면 단열재는 발포 단열재 이외에 추가로 진공 단열재를 포함하거나, 단열재는 발포 단열재 대 신 진공 단열재만으로 구성될 수도 있다. 진공 단열재는 심재와, 심재를 수용하고 내부를 진공 또는 진공에 가 까운 압력으로 밀봉하는 외피재를 포함할 수 있다. 다만, 단열재는 상기한 발포 단열재 또는 진공 단열재에 한 정되는 것은 아니고 단열을 위해 사용될 수 있는 다양한 소재를 포함할 수 있다. 저장실은 내상에 의해 한정되는 공간을 포함할 수 있다. 저장실은 저장실에 대응되는 공간을 한정하는 내상을 더 포함할 수 있다. 저장실에는 식품, 약품, 화장품 등 다양한 물품이 저장될 수 있으며, 저장실은 물품을 출납하기 위해 적어도 일측이 개방되도록 형성될 수 있다. 냉장고는 한 개 또는 그 이상의 저장실을 포함할 수 있다. 냉장고에 2 개 이상의 저장실 이 형성될 때 각각의 저장실은 서로 다른 용도를 가질 수 있으며 서로 다른 온도로 유지될 수 있다. 이를 위해 각각의 저장실은 단열재를 포함하는 격벽에 의해 서로 구획될 수 있다. 저장실은 용도에 따라 적정한 온도 범위에서 유지되도록 마련될 수 있으며, 그 용도 및/또는 온도 범위에 따라 구분되는 냉장실, 냉동실 또는 변온실을 포함할 수 있다. 냉장실은 물품을 냉장 보관하기에 적정한 온도로 유지될 수 있고, 냉동실은 물품을 냉동 보관하기에 적정한 온도로 유지될 수 있다. 냉장은 물품을 얼지 않는 한도에서 차갑게 냉각하는 것을 의미할 수 있으며, 일례로 냉장실은 섭씨 0도에서 섭씨 영상 7도 범위에서 유지될 수 있다. 냉동은 물품을 얼리거나 언 상태로 유지되도록 냉각하는 것을 의미할 수 있으며, 일례로 냉동실은 섭씨 영하 20도 내지 섭씨 영하 1도 범위에서 유지될 수 있다. 변온 실은 사용자의 선택 또는 이와 무관하게 냉장실 또는 냉동실 중 어느 하나로 사용될 수 있다. 저장실은 냉장실, 냉동실 및 변온실 등의 명칭 이외에도 야채실, 신선실, 쿨링실 및 제빙실 등 다양한 명칭으로 불릴 수 있으며, 이하에서 사용되는 냉장실, 냉동실 및 변온실 등의 용어는 각각 대응되는 용도 및 온도 범위를 갖는 저장실을 포괄하는 의미로 이해되어야 할 것이다. 일 실시예에 따르면 냉장고는 저장실의 개방된 일측을 개폐하도록 구성되는 적어도 하나의 도어 를 포함할 수 있다. 도어는 한 개 또는 그 이상의 저장실 각각을 개폐하도록 구비되거나, 도 어 하나가 복수의 저장실을 개폐하도록 구비될 수 있다. 도어는 본체의 전면에 회전 또는 슬라이딩 가능하게 설치될 수 있다. 도어는 도어가 닫힐 시에 저장실을 밀폐하도록 구성될 수 있다. 도어는 도어가 닫힐 시에 저장실을 단열하도록 본체와 마찬가지로 단열재를 포함할 수 있다. 일 실시예에 따르면 도어는 도어의 전면을 형성하는 도어 외판과, 도어의 후면을 형성하고 저장실을 마주보는 도어 내판과, 상부 캡과, 하부 캡 및 이들의 내부에 마련되는 도어 단열재를 포함할 수 있다. 도어 내판의 테두리에는 도어가 닫혔을 때 본체의 전면에 밀착됨으로써 저장실을 밀폐하는 가스켓이 마련될 수 있다. 도어 내판은 물품을 보관할 수 있는 도어 바스켓이 장착되도록 후방으로 돌출되는 다 이크(dyke)를 포함할 수 있다. 일 실시예에 따르면 도어는 도어 바디와, 도어 바디의 전측에 분리 가능하게 결합되고 도어의 전면 을 형성하는 전방 패널을 포함할 수 있다. 도어 바디는 도어 바디의 전면을 형성하는 도어 외판, 도어 바디의 후면을 형성하고 저장실을 마주보는 도어 내판, 상부 캡, 하부 캡 및 이들의 내부에 마련되는 도어 단열 재를 포함할 수 있다. 냉장고는 도어 및 저장실의 배치에 따라 프렌치 도어 타입(French Door Type), 사이드 바이 사이드 타입(Side-by-side Type), BMF(Bottom Mounted Freezer), TMF(Top Mounted Freezer) 또는 1도어 냉장고 등으로 구별될 수 있다. 일 실시예에 따르면 냉장고는 저장실에 냉기를 공급하도록 마련되는 냉기 공급 장치를 포함 할 수 있다. 냉기 공급 장치는 냉기를 생성하고 냉기를 안내하여 저장실을 냉각할 수 있는 기계, 기구, 전자 장 치 및/또는 이들을 조합한 시스템을 포함할 수 있다. 일 실시예에 따르면 냉기 공급 장치는 냉매의 압축, 응축, 팽창 및 증발 과정을 포함하는 냉동 사이클을 통해 냉기를 생성할 수 있다. 이를 위해 냉기 공급 장치는 냉동 사이클을 구동시킬 수 있는 압축기, 응축 기, 팽창 장치 및 증발기를 갖는 냉동 사이클 장치를 포함할 수 있다. 일 실시예에 따르면 냉기 공급 장치 는 열전 소자와 같은 반도체를 포함할 수 있다. 열전 소자는 펠티어 효과를 통한 발열 및 냉각 작용으로 저장실을 냉각할 수 있다. 일 실시예에 따르면 냉장고는 냉기 공급 장치에 속한 적어도 일부 부품들이 배치되도록 마련되는 기계실을 포함할 수 있다. 기계실은 기계실에 배치되는 부품에서 발생되는 열이 저장실에 전달되는 것을 방지하기 위해 저장실 과 구획 및 단열되도록 마련될 수 있다. 기계실 내부에 배치된 부품을 방열하도록 기계실 내부는 본체 의 외부와 연통되도록 구성될 수 있다. 일 실시예에 따르면 냉장고는 물 및/또는 얼음을 제공하도록 도어에 마련되는 디스펜서를 포함할 수 있다. 디스펜서는 사용자가 도어를 개방하지 않고 접근 가능하도록 도어에 마련될 수 있다. 일 실시예에 따르면 냉장고는 얼음을 생성하도록 마련되는 제빙 장치를 포함할 수 있다. 제빙 장치는 물 을 저수하는 제빙 트레이와, 제빙 트레이로부터 얼음을 분리시키는 이빙 장치와, 제빙 트레이에서 생성된 얼음 을 저장하는 아이스 버킷을 포함할 수 있다. 일 실시예에 따르면 냉장고는 냉장고를 제어하기 위한 제어부를 포함할 수 있다. 제어부는 냉장고를 제어하기 위한 프로그램 및/또는 데이터를 저장 또는 기억하는 메모리와, 메모 리에 기억된 프로그램 및/또는 데이터에 따라 냉기 공급 장치 등을 제어하기 위한 제어 신호를 출 력하는 프로세서를 포함할 수 있다. 메모리는 냉장고의 동작에 필요한 다양한 정보, 데이터, 명령어, 프로그램 등을 저장 또는 기록한 다. 메모리는 냉장고에 포함된 구성들을 제어하기 위한 제어 신호를 생성하는 중에 발생하는 임시 데이터를 기억할 수 있다. 메모리는 휘발성 메모리 또는 비휘발성 메모리 중 적어도 하나 또는 이들의 조 합을 포함할 수 있다. 프로세서는 냉장고 전반의 동작을 제어한다. 프로세서는 메모리에 저장된 프로그램을 실행하여, 냉장고의 구성 요소들을 제어할 수 있다. 프로세서는 인공지능 모델의 동작을 수행하는 별도의 NPU를 포함할 수 있다. 또한 프로세서는 중앙 처리부, 그래픽 전용 프로세서(GPU) 등을 포함할 수 있다. 프로세서는 냉기 공급 방치의 동작을 제어하기 위한 제어 신호를 생성할 수 있다. 예를 들어, 프로 세서는 온도 센서로부터 저장실의 온도 정보를 수신하고, 저장실의 온도 정보에 기초하여 냉 기 공급 장치의 동작을 제어하기 위한 냉각 제어 신호를 생성할 수 있다.또한, 프로세서는 메모리에 기억/저장된 프로그램 및/또는 데이터에 따라 사용자 인터페이스의 사 용자 입력을 처리하고, 사용자 인터페이스의 동작을 제어할 수 있다. 사용자 인터페이스는 입력 인터페이스 와 출력 인터페이스를 이용하여 제공될 수 있다. 프로세서는 사용자 인터페이스로부터 사용 자 입력을 수신할 수 있다. 또한, 프로세서는 사용자 입력에 응답하여 사용자 인터페이스에 영상을 표시 하기 위한 표시 제어 신호 및 영상 데이터를 사용자 인터페이스에 전달할 수 있다. 프로세서와 메모리는 일체로 마련되거나 또는 별도로 마련될 수 있다. 프로세서는 하나 이상 의 프로세서를 포함할 수 있다. 예를 들어, 프로세서는 메인 프로세서와 적어도 하나의 서브 프로세서를 포함할 수 있다. 메모리는 하나 이상의 메모리를 포함할 수 있다. 일 실시예에 따르면 냉장고는 냉장고에 포함된 구성들을 모두 제어하는 프로세서 및 메모리 를 포함하고 냉장고의 구성들을 개별 제어하는 복수의 프로세서들과 복수의 메모리들 을 포함할 수 있다. 예를 들어, 냉장고는 온도센서의 출력에 따라 냉기 공급 장치의 동작을 제어하 는 프로세서 및 메모리를 포함할 수 있다. 또한, 냉장고는 사용자 입력에 따라 사용자 인터 페이스의 동작을 제어하는 프로세서와 메모리를 별도로 구비할 수 있다. 통신 모듈은 주변의 접속 중계기(AP: Access Point)를 통해 서버, 모바일 장치, 다른 가전 기기 등의 외 부 장치와 통신할 수 있다. 접속 중계기(AP)는 냉장고 또는 사용자 기기가 연결된 지역 네트워크(LAN)를 서버가 연결된 광역 네트워크(WAN)에 연결시킬 수 있다. 냉장고 또는 사용자 기기는 광역 네트워크(WAN) 를 통해 서버에 연결될 수 있다. 입력 인터페이스는 키, 터치스크린, 마이크로폰 등을 포함할 수 있다. 입력 인터페이스 는 사용자 입력을 수신하여 프로세서로 전달할 수 있다. 출력 인터페이스는 디스플레이, 스피커 등을 포함할 수 있다. 출력 인터페이스는 프로 세서에서 생성된 다양한 알림, 메시지, 정보 등을 출력할 수 있다. 일 실시예에서, 세탁기는 서버 및/또는 전자 장치와 데이터 통신을 수행할 수 있다. 세탁기 는 서버 및/또는 전자 장치로부터 제어 동작과 관련된 데이터(예를 들어, 동작 모드 설정)를 수신하고, 수신된 데이터에 대응되는 기능을 세탁기에서 실행할 수 있다. 세탁기가 서버 및/또는 전자 장치에 의해 제어되는 것에 관한 설명은 전술하였으므로, 반복되는 설명은 생략한다. 도 19는 본 개시의 일 실시예에 따른 오븐의 블록도이다. 일 실시예에 따른 오븐은 프로세서, 구동부, 센서부, 통신 모듈, 사용자 인터페 이스, 조명 및 메모리를 포함할 수 있다. 프로세서는, 오븐의 동작을 전반적으로 제어할 수 있다. 프로세서는 메모리에 저장된 프로그램들을 실행함으로써, 구동부, 센서부, 통신 모듈, 사용자 인터페이스, 조명 , 메모리를 제어할 수 있다. 일 실시예에서, 오븐은 인공 지능(AI) 프로세서를 탑재한 스마트 오븐일 수 있다. 인공 지능(AI) 프로세 서는, 인공 지능(AI)을 위한 전용 하드웨어 칩 형태로 제작될 수도 있고, 기존의 범용 프로세서(예: CPU 또는 application processor) 또는 그래픽 전용 프로세서(예: GPU)의 일부로 제작되어 오븐에 탑재될 수도 있 다. 메모리는, 프로세서의 처리 및 제어를 위한 프로그램을 저장할 수도 있고, 입/출력되는 데이터들 (예컨대, 레시피 정보, 면적 테이블, 간격 테이블, 크롭 영역의 사이즈 정보, 왜곡 보정 값, 밝기 단계 테이블 등)을 저장할 수도 있다. 메모리는 인공지능 모델을 저장할 수도 있다. 예를 들어, 메모리는 객체 인식을 위한 인공지능 모델, 레시피 추천을 위한 인공지능 모델 등을 저장할 수도 있다. 메모리는 플래시 메모리 타입(flash memory type), 하드디스크 타입(hard disk type), 멀티미디어 카드 마이크로 타입(multimedia card micro type), 카드 타입의 메모리(예를 들어 SD 또는 XD 메모리 등), 램(RAM, Random Access Memory) SRAM(Static Random Access Memory), 롬(ROM, Read-Only Memory), EEPROM(Electrically Erasable Programmable Read-Only Memory), PROM(Programmable Read-Only Memory), 자기 메모리, 자기 디스크, 광디스크 중 적어도 하나의 타입의 저장매체를 포함할 수 있다. 또한, 오븐은 인터 넷(Internet)상에서 저장 기능을 수행하는 웹 스토리지(web storage) 또는 클라우드 서버와 연동할 수도 있다.구동부는, 히터, 순환팬, 냉각팬을 포함할 수 있으나, 이에 한정되는 것은 아니다. 구 동부는 오븐의 종류에 따라 변경될 수 있다. 오븐의 내부 공간(예컨대, 조리실)에는 음식을 가열시키는 히터가 마련될 수 있다. 히터는 전기 저항체를 포함하는 전기 히터 또는 가스를 연소시켜 열을 발생시키는 가스 히터일 수 있다. 내부 공간(조리실)의 후방에는 내부 공기를 순환시켜 음식이 골고루 가열되도록 하는 순환 팬과 순환 팬 을 구동시키는 순환 모터가 마련될 수 있다. 또한, 순환 팬의 전방에는 순환 팬을 커버하는 팬 커버가 마련될 수 있으며, 팬 커버에는 공기가 유동될 수 있도록 통공이 형성될 수 있다. 냉각팬은 공기를 상측에서 흡입하여 반경 방향으로 토출시키는 원심팬일 수 있다. 냉각팬은 냉각 유로에 배치될 수 있다. 냉각팬은, 편평하게 형성되는 회전판과, 회전판의 중심부에 형성되고 냉각 모터 의 회전축이 결합되는 허브와, 회전판의 중심부에서 테두리부로 형성되는 복수의 날개를 포함할 수 있다. 허브 는 하부로 갈수록 반경이 커지는 원추 형상으로 형성될 수 있고, 따라서, 상측에서 흡입된 공기를 하부 방향으 로 확산시킬 수 있다. 센서부는, 깊이 센서, 무게 감지 센서, 적외선 센서, 내부 공간의 습도를 센싱하는 습 도 센서, 내부 공간의 가스 정도를 센싱하는 가스 센서, 온도 센서를 포함할 수 있으나, 이 에 한정되는 것은 아니다. 각 센서들의 기능은 그 명칭으로부터 통상의 기술자가 직관적으로 추론할 수 있으므 로, 구체적인 설명은 생략하기로 한다. 통신 모듈은, 오븐과 서버 장치(미도시), 또는 오븐과 모바일 단말(미도시) 간의 통신을 하 게 하는 하나 이상의 구성요소를 포함할 수 있다. 예를 들어, 통신 모듈은, 근거리 통신모듈, 원거 리 통신모듈 등을 포함할 수 있다. 근거리 통신모듈, 블루투스, BLE(Bluetooth Low Energy), 근거리 무선 통신 (Near Field Communication; NFC), WLAN(와이파이), 지그비(Zigbee), 적외선(IrDA, infrared Data Association), WFD(Wi-Fi Direct), UWB(ultra wideband), Ant+ 등의 통신 기술을 이용하는 통신 모듈을 포함할 수 있으나, 이에 한정되는 것은 아 니다. 원거리 통신부는 오븐이 IoT(사물 인터넷) 환경에서 원격으로 서버 장치(미도시)에 의해 제 어되는 경우, 서버와 통신하는데 사용될 수 있다. 원거리 통신모듈은 인터넷, 컴퓨터 네트워크(예: LAN 또는 WAN), 이동 통신부를 포함할 수 있다. 이동 통신부는, 3G 모듈, 4G 모듈, 5G 모듈, LTE 모듈, NB-IoT 모듈, LTE-M 모듈 등을 포함할 수 있으나, 이에 한정되는 것은 아니다. 사용자 인터페이스는, 출력 인터페이스와 입력 인터페이스를 포함할 수 있다. 출력 인터페이 스는, 오디오 신호 또는 비디오 신호의 출력을 위한 것으로, 디스플레이부와 음향 출력부 등을 포함할 수 있다. 디스플레이부와 터치패드가 레이어 구조를 이루어 터치 스크린으로 구성되는 경우, 디스플레이부는 출력 인터페 이스 이외에 입력 인터페이스로도 사용될 수 있다. 디스플레이부는 액정 디스플레이(liquid crystal display), 박막 트랜지스터 액정 디스플레이(thin film transistor-liquid crystal display), 발광 다 이오드(LED, light-emitting diode), 유기 발광 다이오드(organic light-emitting diode), 플렉시블 디스플레 이(flexible display), 3차원 디스플레이(3D display), 전기영동 디스플레이(electrophoretic display) 중에서 적어도 하나를 포함할 수 있다. 그리고 오븐의 구현 형태에 따라 오븐은 디스플레이부를 2개 이상 포함할 수도 있다. 음향 출력부는 통신 모듈로부터 수신되거나 메모리에 저장된 오디오 데이터를 출력할 수 있다. 또 한, 음향 출력부는 오븐에서 수행되는 기능과 관련된 음향 신호를 출력할 수 있다. 음향 출력부는 스피커 (speaker), 부저(Buzzer) 등을 포함할 수 있다. 본 개시의 일 실시예에 의하면, 디스플레이부는 오븐의 내부 공간의 모니터링 영상을 출력하거나, 식재료 에 맞는 레시피 정보를 출력할 수 있다. 또한, 디스플레이부는 트레이가 삽입된 높이에 따라 결정된 조리 온도 의 보정 값을 출력할 수도 있다. 입력 인터페이스는, 사용자로부터의 입력을 수신하기 위한 것이다. 입력 인터페이스는, 키 패드 (key pad), 돔 스위치 (dome switch), 터치 패드(접촉식 정전 용량 방식, 압력식 저항막 방식, 적외선 감지 방 식, 표면 초음파 전도 방식, 적분식 장력 측정 방식, 피에조 효과 방식 등), 조그 휠, 조그 스위치 중 적어도 하나일 수 있으나, 이에 한정되는 것은 아니다.입력 인터페이스는, 음성 인식 모듈을 포함할 수 있다. 예를 들어, 오븐은 마이크로폰을 통해 아날 로그 신호인 음성 신호를 수신하고, ASR(Automatic Speech Recognition) 모델을 이용하여 음성 부분을 컴퓨터로 판독 가능한 텍스트로 변환할 수 있다. 오븐은 자연어 이해(Natural Language Understanding, NLU) 모델 을 이용하여 변환된 텍스트를 해석하여, 사용자의 발화 의도를 획득할 수 있다. 여기서 ASR 모델 또는 NLU 모델 은 인공지능 모델일 수 있다. 인공지능 모델은 인공지능 모델의 처리에 특화된 하드웨어 구조로 설계된 인공지 능 전용 프로세서에 의해 처리될 수 있다. 조명은, 오븐의 내부 공간의 일면에 배치될 수 있으며, 내부 조명으로 표현될 수 있다. 예를 들어, 조명은 천장에 배치될 수도 있고, 옆 면에 배치될 수도 있으나, 이에 한정되는 것은 아니다. 조명 은 오븐의 문이 개방되거나 오븐이 동작할 때 턴온될 수 있다. 조명은 유리 커버에 의해 보 호될 수 있다. 본 개시의 일 실시예에 의하면, 조명은 다양한 밝기 단계를 가질 수 있다. 예를 들어, 조명은 어두 운 단계부터 밝은 단계의 빛을 발광할 수 있다. 조명의 밝기는 프로세서에 의해 조절될 수 있다. 조명은 할로겐 조명일 수도 있고, LED 조명일 수도 있으나, 이에 한정되는 것은 아니다. 일 실시예에서, 오븐은 서버 및/또는 전자 장치와 데이터 통신을 수행할 수 있다. 오븐 은 서버 및/또는 전자 장치로부터 제어 동작과 관련된 데이터(예를 들어, 동작 모드 설정)를 수신하고, 수신된 데이터에 대응되는 기능을 오븐에서 실행할 수 있다. 오븐이 서버 및/또는 전자 장치에 의해 제어되는 것에 관한 설명은 전술하였으므로, 반복되는 설명은 생략한다. 본 개시는, 오버랩 된 텍스트가 있는 이미지에서 오버랩 된 텍스트를 분리하기 위해 텍스트 영역을 결정하고 텍 스트 영역에서 문자 그룹에 대응하는 픽셀들만을 추출한 후, 이를 복원하여 온전한 텍스트를 포함하는 이미지를 획득하는 방법 및 복원된 텍스트를 인식하여 정보를 생성하는 방법을 제시한다. 본 개시에서 이루고자 하는 기술적 과제는, 이상에서 언급한 것으로 제한되지 않으며, 언급되지 않은 또 다른"}
{"patent_id": "10-2023-0006301", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "기술적 과제들은 아래의 기재로부터 본 발명이 속하는 기술분야에서 통상의 지식을 가진 자에게 명확하게 이해 될 수 있을 것이다. 본 개시의 일 측면에 따르면, 서버가 이미지로부터 텍스트를 획득하는 방법이 제공될 수 있다. 상기 방법은, 제 1 텍스트 및 상기 제1 텍스트와 오버랩 된 제2 텍스트를 포함하는 이미지를 획득하는 단계를 포함할 수 있다. 상기 방법은, 상기 이미지로부터 상기 제1 텍스트에 대응하는 텍스트 영역을 분리하는 단계를 포함할 수 있다. 상기 방법은, 상기 제1 텍스트의 상기 텍스트 영역에서 상기 제1 텍스트의 하나 이상의 문자들과 관련된 픽셀들 을 추출하여, 상기 제1 텍스트의 일부 영역이 손상된 상기 제1 텍스트의 이미지를 획득하는 단계를 포함할 수 있다. 상기 방법은, 상기 제1 텍스트의 이미지 내에서 상기 제1 텍스트가 상기 제2 텍스트와 오버랩 되었던 영 역을 인페인팅함으로써, 상기 제1 텍스트를 복원하는 단계를 포함할 수 있다. 상기 이미지로부터 상기 제1 텍스트에 대응하는 텍스트 영역을 분리하는 단계는, 상기 이미지 내의 텍스트를 복 수의 문자 그룹들로 세그먼트함으로써 복수의 텍스트 영역들을 결정하는 단계를 포함할 수 있다. 상기 이미지로부터 상기 제1 텍스트에 대응하는 텍스트 영역을 분리하는 단계는, 상기 복수의 텍스트 영역들 중 에서 상기 제1 텍스트에 대응하는 텍스트 영역을 분리하는 단계를 포함할 수 있다. 상기 복수의 텍스트 영역들을 결정하는 단계는, 상기 이미지에 컬러 클러스터링 알고리즘을 적용하여, 인접한 컬러의 문자들이 그룹화되도록 함으로써 상기 텍스트 영역들을 결정하는 단계를 포함할 수 있다. 상기 복수의 텍스트 영역들을 결정하는 단계는, 상기 이미지 내 텍스트를 선택하는 사용자 입력을 수신하는 단 계를 포함할 수 있다. 상기 복수의 텍스트 영역들을 결정하는 단계는, 상기 이미지 내 상기 사용자 입력에 대응하는 영역에 상기 컬러 클러스터링 알고리즘을 적용하는 단계를 포함할 수 있다. 상기 복수의 텍스트 영역들을 결정하는 단계는, 상기 이미지에 기초하여, 상기 이미지 내에서 텍스트의 위치를 나타내는 텍스트 영역 맵을 획득하는 단계를 포함할 수 있다. 상기 복수의 텍스트 영역들을 결정하는 단계는, 상기 텍스트 영역 맵에 기초하여 상기 복수의 텍스트 영역들을 결정하는 단계를 포함할 수 있다. 상기 복수의 텍스트 영역들을 결정하는 단계는, 상기 텍스트 영역 맵에 기초하여 상기 컬러 클러스터링 알고리 즘을 적용하는 것일 수 있다. 상기 복수의 텍스트 영역들을 결정하는 단계는, 상기 텍스트의 언어, 글씨체, 텍스트의 서식, 말뭉치(corpus) 및 로고 중 적어도 하나에 기초하여 상기 복수의 텍스트 영역들을 결정하는 것일 수 있다. 상기 방법은, 상기 제1 텍스트에 광학 문자 인식(Optical character recognition; OCR)을 적용하는 단계를 포 함할 수 있다. 상기 이미지는 식품과 관련된 라벨의 이미지를 포함할 수 있다. 상기 제1 텍스트는 식품과 관련된 텍스트를 포함할 수 있다. 상기 방법은, 상기 제1 텍스트에 광학 문자 인식을 적용한 결과에 기초하여, 상기 식품과 관련된 정보를 제공하 는 단계를 포함할 수 있다. 상기 방법은, 식품과 관련된 정보를 외부 장치로 전송하는 단계를 포함할 수 있다. 본 개시의 일 측면에 따르면, 이미지로부터 텍스트를 획득하는 서버가 제공될 수 있다. 상기 서버는, 통신 인터 페이스; 하나 이상의 인스트럭션을 저장하는 메모리; 상기 메모리에 저장된 상기 하나 이상의 인스트럭션을 실 행하는 적어도 하나의 프로세서를 포함할 수 있다. 상기 적어도 하나의 프로세서는, 상기 하나 이상의 인스트럭션을 실행함으로써, 제1 텍스트 및 상기 제1 텍스트 와 오버랩 된 제2 텍스트를 포함하는 이미지를 획득할 수 있다. 상기 적어도 하나의 프로세서는, 상기 하나 이 상의 인스트럭션을 실행함으로써, 상기 이미지로부터 상기 제1 텍스트에 대응하는 텍스트 영역을 분리할 수 있 다. 상기 적어도 하나의 프로세서는, 상기 하나 이상의 인스트럭션을 실행함으로써, 상기 제1 텍스트의 상기 텍 스트 영역에서 상기 제1 텍스트의 하나 이상의 문자들과 관련된 픽셀들을 추출하여, 상기 제1 텍스트의 일부 영 역이 손상된 상기 제1 텍스트의 이미지를 획득할 수 있다. 상기 적어도 하나의 프로세서는, 상기 하나 이상의 인스트럭션을 실행함으로써, 상기 제1 텍스트의 이미지 내에서 상기 제1 텍스트가 상기 제2 텍스트와 오버랩 되 었던 영역을 인페인팅함으로써, 상기 제1 텍스트를 복원할 수 있다. 상기 적어도 하나의 프로세서는, 상기 하나 이상의 인스트럭션을 실행함으로써, 상기 이미지 내의 텍스트를 복 수의 문자 그룹들로 세그먼트함으로써 복수의 텍스트 영역들을 결정할 수 있다. 상기 적어도 하나의 프로세서는, 상기 하나 이상의 인스트럭션을 실행함으로써, 상기 복수의 텍스트 영역들 중 에서 상기 제1 텍스트에 대응하는 텍스트 영역을 분리할 수 있다. 상기 적어도 하나의 프로세서는, 상기 하나 이상의 인스트럭션을 실행함으로써, 상기 이미지에 컬러 클러스터링 알고리즘을 적용하여, 인접한 컬러의 문자들이 그룹화되도록 함으로써 상기 텍스트 영역들을 결정할 수 있다. 상기 적어도 하나의 프로세서는, 상기 하나 이상의 인스트럭션을 실행함으로써, 상기 이미지 내 텍스트를 선택 하는 사용자 입력을 수신할 수 있다. 상기 적어도 하나의 프로세서는, 상기 하나 이상의 인스트럭션을 실행함으로써, 상기 이미지 내 상기 사용자 입 력에 대응하는 영역에 상기 컬러 클러스터링 알고리즘을 적용할 수 있다. 상기 적어도 하나의 프로세서는, 상기 하나 이상의 인스트럭션을 실행함으로써, 상기 이미지에 기초하여, 상기 이미지 내에서 텍스트의 위치를 나타내는 텍스트 영역 맵을 획득할 수 있다. 상기 적어도 하나의 프로세서는, 상기 하나 이상의 인스트럭션을 실행함으로써, 상기 텍스트 영역 맵에 기초하 여 상기 복수의 텍스트 영역들을 결정할 수 있다. 상기 적어도 하나의 프로세서는, 상기 하나 이상의 인스트럭션을 실행함으로써, 상기 텍스트 영역 맵에 기초하 여 상기 컬러 클러스터링 알고리즘을 적용할 수 있다. 상기 적어도 하나의 프로세서는, 상기 하나 이상의 인스트럭션을 실행함으로써, 상기 텍스트의 언어, 글씨체, 텍스트의 서식, 말뭉치(corpus) 및 로고 중 적어도 하나에 기초하여 상기 복수의 텍스트 영역들을 결정할 수 있 다. 상기 적어도 하나의 프로세서는, 상기 하나 이상의 인스트럭션을 실행함으로써, 상기 제1 텍스트에 광학 문자 인식(Optical character recognition; OCR)을 적용할 수 있다. 상기 이미지는 식품과 관련된 라벨의 이미지를 포함할 수 있다. 상기 제1 텍스트는 식품과 관련된 텍스트를 포함할 수 있다. 상기 적어도 하나의 프로세서는, 상기 하나 이상의 인스트럭션을 실행함으로써, 상기 제1 텍스트에 광학 문자 인식을 적용한 결과에 기초하여, 상기 식품과 관련된 정보를 제공할 수 있다. 한편, 본 개시의 실시예들은 컴퓨터에 의해 실행되는 프로그램 모듈과 같은 컴퓨터에 의해 실행 가능한 명령어 를 포함하는 기록 매체의 형태로도 구현될 수 있다. 컴퓨터 판독 가능 매체는 컴퓨터에 의해 액세스 될 수 있는 임의의 가용 매체일 수 있고, 휘발성 및 비휘발성 매체, 분리형 및 비분리형 매체를 모두 포함한다. 또한, 컴퓨 터 판독 가능 매체는 컴퓨터 저장 매체 및 통신 매체를 포함할 수 있다. 컴퓨터 저장 매체는 컴퓨터 판독 가능 명령어, 데이터 구조, 프로그램 모듈 또는 기타 데이터와 같은 정보의 저장을 위한 임의의 방법 또는 기술로 구 현된 휘발성 및 비휘발성, 분리형 및 비분리형 매체를 모두 포함한다. 통신 매체는 전형적으로 컴퓨터 판독 가 능 명령어, 데이터 구조, 또는 프로그램 모듈과 같은 변조된 데이터 신호의 기타 데이터를 포함할 수 있다. 또한, 컴퓨터에 의해 읽을 수 있는 저장매체는, 비일시적(non-transitory) 저장매체의 형태로 제공될 수 있다. 여기서, '비일시적 저장매체'는 실재(tangible)하는 장치이고, 신호(signal)(예: 전자기파)를 포함하지 않는다 는 것을 의미할 뿐이며, 이 용어는 데이터가 저장매체에 반영구적으로 저장되는 경우와 임시적으로 저장되는 경 우를 구분하지 않는다. 예로, '비일시적 저장매체'는 데이터가 임시적으로 저장되는 버퍼를 포함할 수 있다. 일 실시예에 따르면, 본 문서에 개시된 다양한 실시예들에 따른 방법은 컴퓨터 프로그램 제품(computer program product)에 포함되어 제공될 수 있다. 컴퓨터 프로그램 제품은 상품으로서 판매자 및 구매자 간에 거래될 수 있 다. 컴퓨터 프로그램 제품은 기기로 읽을 수 있는 저장 매체(예: compact disc read only memory (CD-ROM))의 형태로 배포되거나, 또는 어플리케이션 스토어를 통해 또는 두개의 사용자 장치들(예: 스마트폰들) 간에 직접, 온라인으로 배포(예: 다운로드 또는 업로드)될 수 있다. 온라인 배포의 경우에, 컴퓨터 프로그램 제품(예: 다운 로더블 앱(downloadable app))의 적어도 일부는 제조사의 서버, 어플리케이션 스토어의 서버, 또는 중계 서버의 메모리와 같은 기기로 읽을 수 있는 저장 매체에 적어도 일시 저장되거나, 임시적으로 생성될 수 있다."}
{"patent_id": "10-2023-0006301", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "전술한 본 개시의 설명은 예시를 위한 것이며, 본 개시가 속하는 기술분야의 통상의 지식을 가진 자는 본 개시 의 기술적 사상이나 필수적인 특징을 변경하지 않고서 다른 구체적인 형태로 쉽게 변형이 가능하다는 것을 이해 할 수 있을 것이다. 그러므로 이상에서 기술한 실시예들은 모든 면에서 예시적인 것이며 한정적이 아닌 것으로 이해해야만 한다. 예를 들어, 단일형으로 설명되어 있는 각 구성 요소는 분산되어 실시될 수도 있으며, 마찬가 지로 분산된 것으로 설명되어 있는 구성 요소들도 결합된 형태로 실시될 수 있다. 본 개시의 범위는 상기 상세한 설명보다는 후술하는 특허청구범위에 의하여 나타내어지며, 특허청구범위의 의미 및 범위 그리고 그 균등 개념으로부터 도출되는 모든 변경 또는 변형된 형태가 본 개시의 범위에 포함되는 것으 로 해석되어야 한다.도면 도면1 도면2 도면3 도면4 도면5 도면6 도면7a 도면7b 도면8 도면9 도면10 도면11a 도면11b 도면12 도면13a 도면13b 도면13c 도면14a 도면14b 도면15 도면16 도면17 도면18 도면19"}
{"patent_id": "10-2023-0006301", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 개시의 일 실시예에 따른 서버가 이미지로부터 텍스트를 추출하는 것을 개략적으로 도시한 도면이다. 도 2는 본 개시의 일 실시예에 따른 서버가 이미지로부터 텍스트를 획득하는 동작을 설명하기 위한 흐름도이다. 도 3은 본 개시의 일 실시예에 따른 서버가 획득하는, 오버랩 된 텍스트가 있는 이미지를 설명하기 위한 도면이 다. 도 4는 본 개시의 일 실시예에 따른 서버가 텍스트 분리를 위해 이미지를 전처리하는 동작을 설명하기 위한 도 면이다. 도 5는 본 개시의 일 실시예에 따른 서버가 이용하는 텍스트 분리 네트워크를 설명하기 위한 도면이다. 도 6은 본 개시의 일 실시예에 따른 서버가 이미지 내의 텍스트를 인식하는 동작을 설명하기 위한 도면이다. 도 7a는 본 개시의 일 실시예에 따른 서버가 텍스트 분리를 위해 색상 정보를 이용하는 동작을 설명하기 위한 도면이다. 도 7b는 본 개시의 일 실시예에 따른 서버가 텍스트 분리를 위해 색상 정보를 이용하는 동작을 설명하기 위한 도면이다. 도 8은 본 개시의 일 실시예에 따른 서버가 이미지 내에서 텍스트 영역들을 검출하는 동작을 설명하기 위한 도 면이다. 도 9는 본 개시의 일 실시예에 따른 서버가 이미지 내에서 텍스트 영역들을 분리하는 동작을 설명하기 위한 도 면이다. 도 10은 본 개시의 일 실시예에 따른 서버가 텍스트 영역 내에서 제1 텍스트를 추출하는 동작을 설명하기 위한 도면이다. 도 11a는 본 개시의 일 실시예에 따른 서버가 손상된 텍스트를 포함하는 이미지를 인페인팅하는 동작을 설명하기 위한 도면이다. 도 11b는 본 개시의 일 실시예에 따른 서버가 인페인터의 훈련 데이터를 생성하는 동작을 설명하기 위한 도면이 다. 도 12는 본 개시의 일 실시예에 따른 텍스트 분리 네트워크를 설명하기 위한 도면이다. 도 13a는 본 개시의 일 실시예에 따른 서버가 가전 장치인 냉장고와 연계하여 동작하는 것을 설명하기 위한 도 면이다. 도 13b는 서버가 가전 장치인 냉장고와 연계하여 동작하는 것을 더 설명하기 위한 도면이다. 도 13c는 서버와 연계하여 동작하는 가전 장치의 동작을 설명하기 위한 도면이다. 도 14a는 본 개시의 일 실시예에 따른 서버가 가전 장치인 오븐과 연계하여 동작하는 것을 설명하기 위한 도면 이다. 도 14b는 서버가 가전 장치인 오븐과 연계하여 동작하는 것을 더 설명하기 위한 도면이다. 도 15는 일 실시예에 따른 서버가 가전 장치와 연계하여 동작하는 것을 설명하기 위한 흐름도이다. 도 16은 본 개시의 일 실시예에 따른 서버의 블록도이다. 도 17은 본 개시의 일 실시예에 따른 전자 장치의 블록도이다. 도 18은 본 개시의 일 실시예에 따른 냉장고의 블록도이다. 도 19는 본 개시의 일 실시예에 따른 오븐의 블록도이다."}
