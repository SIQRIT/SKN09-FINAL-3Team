{"patent_id": "10-2020-0040537", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2021-0123150", "출원번호": "10-2020-0040537", "발명의 명칭": "감정표현을 시각적으로 나타낼 수 있는 챗봇 시스템", "출원인": "한국과학기술연구원", "발명자": "김창환"}}
{"patent_id": "10-2020-0040537", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "사용자로부터 입력문장을 입력 받기 위한 입력부;상기 입력문장에 기초하여 사용자가 처한 상황 및 사용자의 감정을 분석하기 위한 상황 및 감정 분석부;상기 입력문장에 대응하여 사용자에게 공감을 표시하기 위한 제1 출력문장 및 상기 제1 출력문장에 후속하여 출력되며 사용자에게 조언을 제공하기 위한 제2 출력문장을 생성하도록 구성되는 출력문장 생성부;상기 제1 출력문장에 대응하는 제1 감정표현 및 상기 제2 출력문장에 대응하는 제2 감정표현을 결정하기 위한감정표현 결정부; 및상기 제1 출력문장 및 제1 감정표현을 동시에 출력하고, 후속하여 상기 제2 출력문장 및 제2 감정표현을 동시에출력하기 위한 출력부를 포함하는, 감정 표현을 시각적으로 나타낼 수 있는 챗봇 시스템."}
{"patent_id": "10-2020-0040537", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 상황 및 감정 분석부는, 상기 입력문장을 형태소 단위로 구분하기 위한 형태소 분석유닛;상기 입력문장을 구성하는 복수개의 형태소에 대해, 각 형태소의 중요도 및 관계정보에 기초하여 사용자가 처한상황을 분석하기 위한 상황 분석유닛; 및데이터베이스에 기초하여 상기 사용자가 처한 상황에 대응하는 사용자의 감정을 분석하기 위한 감정 분석유닛을포함하는 것을 특징으로 하는, 감정 표현을 시각적으로 나타낼 수 있는 챗봇 시스템."}
{"patent_id": "10-2020-0040537", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 출력문장 생성부는 데이터베이스에 기초하여 상기 입력문장에 대응하는 출력문장을 생성하도록 구성되고, 상기 데이터베이스에 저장된 입력문장과 대응하는 출력문장의 관계정보는 인공지능 학습모델을 이용하여 업데이트되는 것을 특징으로 하는, 감정 표현을 시각적으로 나타낼 수 있는 챗봇 시스템."}
{"patent_id": "10-2020-0040537", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,상기 감정표현 결정부는 데이터베이스에 기초하여 출력문장에 대응하는 감정표현을 결정하도록 구성되고,상기 제1 감정표현 및 상기 제2 감정표현은 인간의 얼굴 표정을 표현하는 이미지로 구성되는 것을 특징으로 하는, 감정 표현을 시각적으로 나타낼 수 있는 챗봇 시스템."}
{"patent_id": "10-2020-0040537", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서,공개특허 10-2021-0123150-3-상기 제1 감정표현은 상기 사용자의 감정과 동일하거나 유사한 감정을 시각적으로 나타내는 이미지이고, 상기제2 감정표현은 상기 사용자의 감정과 상반되는 감정을 시각적으로 나타내는 이미지인 것을 특징으로 하는, 감정 표현을 시각적으로 나타낼 수 있는 챗봇 시스템."}
{"patent_id": "10-2020-0040537", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서, 상기 출력부는 상기 제1 출력문장 및 제1 감정표현을 출력한 후 소정의 시간이 경과한 이후에 상기 제2 출력문장 및 제2 감정표현을 출력하도록 구성되는 것을 특징으로 하는, 감정 표현을 시각적으로 나타낼 수 있는 챗봇시스템."}
{"patent_id": "10-2020-0040537", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항 내지 제6항 중 어느 한 항에 따른 감정 표현을 시각적으로 나타낼 수 있는 챗봇 시스템을 구현하기 위한명령들로 구성된, 컴퓨터로 판독 가능한 기록매체에 저장된 컴퓨터 프로그램."}
{"patent_id": "10-2020-0040537", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 감정표현을 시각적으로 나타낼 수 있는 챗봇 시스템에 관한 것으로서, 일 실시예에 따른 챗봇 시스템 은 사용자로부터 입력문장을 입력 받기 위한 입력부; 상기 입력문장에 기초하여 사용자가 처한 상황 및 사용자의 감정을 분석하기 위한 상황 및 감정 분석부; 상기 입력문장에 대응하여 사용자에게 공감을 표시하기 위한 제1 출 (뒷면에 계속)"}
{"patent_id": "10-2020-0040537", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 감정표현을 시각적으로 나타낼 수 있는 챗봇 시스템에 관한 것으로서, 더욱 상세하게는 사용자와 챗 봇 간의 텍스트 기반 대화에 있어서 사용자가 입력한 문장으로부터 사용자의 감정을 분석하고 이에 대한 답변 및 감정표현을 이원화하여 보다 유연하고 효과적으로 상호작용할 수 있는 챗봇 시스템에 관한 것이다."}
{"patent_id": "10-2020-0040537", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "챗봇(chat-bot)이란 사용자가 컴퓨터와 문자 또는 음성을 통해 대화를 나누듯이 상호작용할 수 있도록 도와주는 컴퓨터 프로그램을 의미한다. 챗봇은 크게 인공지능형과 시나리오형으로 구분할 수 있는데, 시나리오형 챗봇은 데이터베이스에 미리 저장된 정보에 기초하여 사용자의 입력에 대응하여 미리 정해진 대답을 채팅의 형태로 출 력하도록 구성되며, 인공지능형 챗봇은 기계학습을 통해 데이터베이스를 지속적으로 업데이트하거나 데이터베이 스에 존재하지 않는 문장 또는 단어가 입력된 경우 사용자에게 질문하고 대답을 입력 받음으로써 스스로 학습할 수 있도록 구성된다. 인공지능형 챗봇은 미리 정해진 문장뿐만 아니라 새로운 질문이나 복잡한 질문에도 응답할 수 있으므로 사용자에게 보다 친숙하고 사람과 소통하는 느낌을 줄 수 있다. 최근에는 딥러닝 등 기계학습 기술의 발전과 이를 처리하기 위한 컴퓨터의 성능이 향상됨에 따라 다양한 산업분 야에서 챗봇이 활용되고 있다. 과거에는 주로 기업에서 고객을 응대하기 위해 FAQ 형태의 챗봇(자주 묻는 질문 에 대해 정해진 응답을 출력하는 애플리케이션이나 웹페이지)을 서비스하였으나, 최근에는 스마트폰 등 모바일 기기의 발달로 인해 사용자와 일반적인 문답을 주고 받거나(예를 들어, \"한국의 수도는 어디야?\"라고 물으면 \" 서울입니다\"라고 답변함) 개인감정을 공유할 수 있는(예를 들어, \"나 오늘 우울해\"라고 입력하면 \"힘내세요\"라 고 답변함) 일상대화형 챗봇이 대중화되어 가고 있다. 특히, 1인 가구의 증가 및 노인인구의 증가에 따라 타인과 감정을 공유하거나 해소할 수 있는 기회가 적어지고 있어서, 인공지능 기술을 이용해 가상의 대화를 나누고 감정을 공유할 수 있는 챗봇의 수요가 증가하고 있다. 이러한 감정 공유형 챗봇 기술에 있어서 가장 중요한 과제 중 하나는, 사용자의 질문에 대해 정해진 답변만을 기계적으로 출력하는 것이 아니라 사용자가 실제 사람과 자연스러운 대화를 나누는 듯한 느낌을 갖도록 하는 것 이다. 이를 위해 사용자의 입력에 대한 챗봇의 음성답변에 억양을 추가하는 기술 등이 개발되었으나 실제 표현 이 어색할 뿐만 아니라 텍스트 형태의 답변에는 감정표현을 적용하기 어렵다는 문제가 있었다. 선행기술문헌 특허문헌(특허문헌 0001) 대한민국 등록특허공보 제10-1980727호"}
{"patent_id": "10-2020-0040537", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "이에 본 발명은 상기한 종래기술의 과제를 해결하기 위해 착안되었다. 본 발명의 목적은 사용자가 입력한 문장 으로부터 사용자가 처한 상황 및 감정을 분석하고, 이에 대한 답변 및 감정표현을 이원화하여 사용자와 컴퓨터 사이의 보다 자연스러운 상호작용을 이끌어낼 수 있는 챗봇 시스템을 제공하는 것이다."}
{"patent_id": "10-2020-0040537", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기한 목적을 달성하기 위한 본 발명의 바람직한 실시예들이 다음과 같이 제공될 수 있다. 일 실시예에 따른 감정 표현을 시각적으로 나타낼 수 있는 챗봇 시스템은, 사용자로부터 입력문장을 입력 받기 위한 입력부; 상기 입력문장에 기초하여 사용자가 처한 상황 및 사용자의 감정을 분석하기 위한 상황 및 감정 분석부; 상기 입력문장에 대응하여 사용자에게 공감을 표시하기 위한 제1 출력문장 및 상기 제1 출력문장에 후 속하여 출력되며 사용자에게 조언을 제공하기 위한 제2 출력문장을 생성하도록 구성되는 출력문장 생성부; 상기 제1 출력문장에 대응하는 제1 감정표현 및 상기 제2 출력문장에 대응하는 제2 감정표현을 결정하기 위한 감정표 현 결정부; 및 상기 제1 출력문장 및 제1 감정표현을 동시에 출력하고, 후속하여 상기 제2 출력문장 및 제2 감 정표현을 동시에 출력하기 위한 출력부를 포함한다. 일 실시예에 따르면, 상기 상황 및 감정 분석부는, 상기 입력문장을 형태소 단위로 구분하기 위한 형태소 분석 유닛; 상기 입력문장을 구성하는 복수개의 형태소에 대해, 각 형태소의 중요도 및 관계정보에 기초하여 사용자 가 처한 상황을 분석하기 위한 상황 분석유닛; 및 데이터베이스에 기초하여 상기 사용자가 처한 상황에 대응하 는 사용자의 감정을 분석하기 위한 감정 분석유닛을 포함하라 수 있다. 일 실시예에 따르면, 상기 출력문장 생성부는 데이터베이스에 기초하여 상기 입력문장에 대응하는 출력문장을 생성하도록 구성되고, 상기 데이터베이스에 저장된 입력문장과 대응하는 출력문장의 관계정보는 인공지능 학습 모델을 이용하여 업데이트될 수 있다. 일 실시예에 따르면, 상기 감정표현 결정부는 데이터베이스에 기초하여 출력문장에 대응하는 감정표현을 결정하 도록 구성되고, 상기 제1 감정표현 및 상기 제2 감정표현은 인간의 얼굴 표정을 표현하는 이미지로 구성될 수 있다. 일 실시예에 따르면, 상기 제1 감정표현은 상기 사용자의 감정과 동일하거나 유사한 감정을 시각적으로 나타내 는 이미지이고, 상기 제2 감정표현은 상기 사용자의 감정과 상반되는 감정을 시각적으로 나타내는 이미지일 수 있다. 일 실시예에 따르면, 상기 출력부는 상기 제1 출력문장 및 제1 감정표현을 출력한 후 소정의 시간이 경과한 이 후에 상기 제2 출력문장 및 제2 감정표현을 출력하도록 구성될 수 있다. 실시예들에 따른 감정 표현을 시각적으로 나타낼 수 있는 챗봇 시스템을 구현하기 위한 명령들로 구성된, 컴퓨 터로 판독 가능한 기록매체에 저장된 컴퓨터 프로그램이 제공될 수 있다."}
{"patent_id": "10-2020-0040537", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명의 일 실시예에 따른 챗봇 시스템은 입력된 문장을 형태소 단위로 구분하여 분석하고, 입력에 대한 답변 을 감정 단위로 이원화하여 출력하도록 구성된다. 이에 따르면, 사용자가 입력한 문장으로부터 사용자가 처한 상황 및 감정을 분석하고 이에 대한 답변 및 감정표현을 이원화하여 종래기술에 비해 유연하고 효과적인 상호작 용을 유도할 수 있다. 종래의 텍스트 기반 챗봇 시스템에 의하면 감정표현 없이 정해진 텍스트 답변만을 출력하거나 하나의 입력에 대 해 단일 감정표현만을 출력하여 자연스러운 상호작용이 불가능하였으나, 본 발명의 실시예에 따르면 챗봇의 답 변 과정을 이원화하여 사용자가 처한 상황 및 감정에 대한 공감을 표현하기 위한 제1 답변 및 이를 시각적으로 표현하기 위한 이미지를 먼저 출력하고, 후속하여 사용자의 상황 및 감정을 개선하기 위한 조언에 관한 제2 답변 및 이를 시각적으로 표현하기 위한 이미지를 출력함으로써 종래의 챗봇에 비해 자연스러운 감정표현을 제공 한다."}
{"patent_id": "10-2020-0040537", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 명세서에서 사용되는 용어는 기능을 고려하면서 가능한 현재 널리 사용되는 일반적인 용어를 선택하였으나, 이는 당 분야에 종사하는 기술자의 의도 또는 관례 또는 새로운 기술의 출현 등에 따라 달라질 수 있다. 또한, 특정한 경우는 출원인이 임의로 선정한 용어도 있으며, 이 경우 해당되는 명세서의 설명 부분에서 그 의미를 기 재할 것이다. 따라서 본 명세서에서 사용되는 용어는, 단순한 용어의 명칭이 아닌 그 용어가 가지는 실질적인 의미와 본 명세서의 전반에 걸친 내용을 토대로 해석되어야 함을 밝혀두고자 한다. 또한, 본 명세서에 기술된 실시예는 전적으로 하드웨어이거나, 부분적으로 하드웨어이고 부분적으로 소프트웨어 이거나, 또는 전적으로 소프트웨어인 측면을 가질 수 있다. 본 명세서에서 \"부(unit)\", \"유닛(unit)\", \"장치 (device)\" 또는 \"시스템(system)\" 등은 하드웨어, 하드웨어와 소프트웨어의 조합, 또는 소프트웨어 등 컴퓨터 관련 엔티티(entity)를 지칭한다. 예를 들어, 부, 모듈, 장치, 서버 또는 시스템은 플랫폼(platform)의 일부 또 는 전부를 구성하는 하드웨어 및/또는 상기 하드웨어를 구동하기 위한 애플리케이션(application) 등의 소프트 웨어를 지칭하는 것일 수 있다. 이하 첨부 도면들 및 첨부 도면들에 기재된 내용들을 참조하여 실시예를 상세하게 설명하지만, 청구하고자 하는 범위는 실시예들에 의해 제한되거나 한정되는 것은 아니다. 도 1은 본 발명의 일 실시예에 따른 감정 표현을 시각적으로 나타낼 수 있는 챗봇 시스템의 구성을 나타낸 도면 이다. 도 1을 참조하면, 일 실시예에 따른 챗봇 시스템은 사용자로부터 입력문장을 입력 받기 위한 입력부, 상기 입력문장에 기초하여 사용자가 처한 상황 및 사용자의 감정을 분석하기 위한 상황 및 감정 분석부, 상기 입력문장에 대응하여 사용자에게 공감을 표시하기 위한 출력문장을 생성하도록 구성되는 출력문장 생성부 , 상기 출력문장에 대응하는 감정표현을 결정하기 위한 감정표현 결정부, 상기 출력문장 및 감정표현 을 출력하기 위한 출력부, 입력문장에 대응하는 출력문장 및 감정표현의 관계정보를 저장하기 위한 데이터 베이스 및 기계학습을 통해 상기 관계정보를 업데이트하기 위한 인공지능 학습모델을 포함할 수 있다. 이하에서는 챗봇 시스템을 구성하는 각 구성요소들의 기능과 역할, 이들의 결합관계에 대해 도면을 참조하여 상 세히 설명한다. 각 구성요소들은 간결한 설명을 위해 기능적으로 분리하여 표현된 것이므로 반드시 독립적인 프 로세서나 컴퓨터 장치에 의해 수행되는 것을 의미하지는 않는다. 입력부는 사용자 인터페이스를 통해 사용자로부터 입력문장을 입력 받도록 구성된다. 사용자 인터페이 스는 자연어를 이용하는 사용자가 기계어를 이용하는 컴퓨터와 정보를 주고받기 위해 상호작용할 수 있도록 구성되는 프로그램 및/또는 하드웨어 장치를 의미한다. 일 예시에서 사용자 인터페이스는 마우스, 키보드, 터치패드 등 사용자가 챗봇 시스템에 텍스트를 입력할 수 있도록 구성되는 하드웨어 장치 및 이러한 하드웨어 장치를 통해 입력된 문장을 기계어로 변환하는 컴퓨터 프로그램을 포함할 수 있다. 그러나 이러한 구성은 예시에 불과하며, 다른 예시에서 사용자 인터페이스는 음성 입력을 전기적인 신호로 변환해주는 마이크로폰 및 이러한 아날로그 전기신호를 디지털신호로 변환하는 컴퓨터 프로그램으로 구성될 수도 있다. 입력부는 사용자 인터페이스 등 외부 장치 및 프로그램을 통해 입력된 문장을 챗봇 시스템이 처리 할 수 있는 데이터로 가공하여 처리부(프로세서 등)에 전송하도록 구성된다. 상황 및 감정 분석부는 데이터베이스 및 인공지능 학습모델을 이용하여, 입력부를 통해 입 력된 문장을 분석하고 사용자가 처한 상황 및 사용자의 감정을 분석하도록 구성된다. 도 2는 일 실시예에 따른 챗봇 시스템의 상황 및 감정 분석부의 구성을 상세히 나타낸 도면이다. 도 2를 참조하 면 실시예에 따른 상황 및 감정 분석부는, 입력문장을 형태소 단위로 구분하기 위한 형태소 분석유닛 , 입력문장을 구성하는 복수개의 형태소에 대해 각 형태소의 중요도 및 관계정보에 기초하여 사용자가 처 한 상황을 분석하기 위한 상황 분석유닛, 및 데이터베이스에 기초하여 사용자가 처한 상황에 대응하는 사 용자의 감정을 분석하기 위한 감정 분석유닛을 포함할 수 있다. 형태소 분석유닛은 입력된 문장을 어절 단위로 먼저 분할하고 각 어절을 구성하는 형태소로 재분할한 후 각각의 형태소에 대응되는 품사를 분석한다. 여기서 형태소(形態素)란 '뜻을 가진 가장 작은 말의 단위'를 의미 한다. 품사란 '단어를 기능, 형태, 의미에 따라 나눈 갈래'를 의미하며, 품사정보는 각 형태소가 어떠한 품사 (예를 들어, 명사, 형용사, 부사 등)에 해당하는지 대한 분석 정보를 의미한다. 예컨대, 도 3의 입력문장인 \"오 늘 기분이 우울하네.\"를 형태소 단위로 분석하면 \"오늘\", \"기분+이\", \"우울+하+네+.\"와 같이 구분될 수 있다. 이와 같이 입력문장을 형태소 단위로 분석하는 이유는 챗봇 시스템으로 하여금 보다 정확도가 높은 답변을 하도 록 하여 사용자와 로봇 간의 자연스러운 대화가 이루어지도록 하기 위함이다. 예를 들어, \"이 영화 눈물 나도록 재미있어\"라는 문장이 입력된 경우 '눈물'이라는 형태소는 '재미있어'라는 구(phrase)를 수식하는 부사절인 \"눈 물 나도록\"의 구성 요소에 불과한데 이러한 품사정보를 고려하지 않으면 화자(사용자)의 현재 감정이 슬프다고 오해하는 상황이 발생할 수 있기 때문이다. 상황 분석유닛은 데이터베이스에 저장된 정보에 기초하여 입력문장을 구성하는 복수개의 형태소에 대 해 각 형태소의 중요도 및 관계정보를 고려하고 이에 따라 사용자가 처한 상황을 분석한다. 상기 예시를 통해 설명하면, \"이 영화 눈물 나도록 재미있어\"라는 문장이 입력된 경우 '눈물'이라는 형태소는 '재미있어'라는 구 를 수식하는 부사절 '눈물 나도록'의 일부로서, 문장에 담긴 감정을 분석하는 데 있어서 '재미'라는 형태소에 비해 중요도가 낮기 때문에 상황을 결정하기 위한 키워드(key-word)로 인식되지 않는다. 이러한 점들을 종합적 으로 고려할 때, 사용자가 처한 상황은 '특정 대상에 대한 호감을 표출하고 있는 상황'인 것으로 인식될 수 있 다. 감정 분석유닛은 데이터베이스에 기초하여 사용자가 처한 상황에 대응하는 사용자의 감정을 분석한다. 데이터베이스에는 각각의 형태소와 이에 대응하는 상황 및 감정에 대한 관계정보가 저장되어 있 을 수 있다. 상황 분석유닛이 이러한 관계정보에 기초하여 상황을 분석한 것과 유사하게, 감정 분석유닛 은 데이터베이스에 저장된 정보에 기초하여 사용자의 감정을 유추할 수 있다. 예를 들어, \"이 영화 눈물 나도록 재미있어\"라는 문장이 입력된 경우 사용자가 처한 상황은 '특정 대상에 대한 호감을 표출하고 있는 상황'이며, 이로부터 유추할 수 있는 사용자의 현재 감정은 '즐거움', '신남'과 같은 긍정적인 감정이다. 또 다른 예시에서, \"오늘 기분이 우울하네\"라는 문장이 입력된 경우, 데이터베이스 내에서 '우울'이라는 형태소 와 대응하는 상황 및 감정정보를 검색함으로써, 상황 및 감정 분석부(더 구체적으로는, 상황 분석유닛 및 감정 분석유닛)는 사용자의 현재 상황은 '자신의 부정적인 감정을 표출하고 있는 상황'이며, 현재 감정은 '우울함'과 같은 부정적인 감정인 것을 유추할 수 있다. 상황 및 감정 분석부를 통해 사용자가 현재 처한 상황 및 느끼고 있는 감정을 유추한 다음, 출력문장 생성 부는 입력문장에 대응하여 사용자에게 공감을 표시하고 사용자에게 조언을 제공하기 위한 출력문장을 생성 할 수 있다. 본 발명의 바람직한 실시예에 따르면, 출력문장은 사용자에게 공감을 표시하기 위한 제1 출력문장 및 상기 제1 출력문장에 후속하여 출력되며 사용자에게 조언을 제공하기 위한 제2 출력문장으로 이원화될 수 있다. 종래의 챗봇 시스템에서는 주로 하나의 입력문장에 대해 하나의 출력문장만이 생성되어 사용자와 로봇이 서로 자연스러 운 대화를 주고받기 어려웠다. 본 발명은 이러한 문제점을 해결하기 위해 착안된 것으로서, 사용자가 입력한 문 장에 대한 답변을 이원화하여 보다 유연하고 효과적으로 상호작용할 수 있도록 하는 것을 목적으로 한다. 도 3을 참조하면, 챗봇 시스템은 예를 들어 \"오늘 기분이 우울하네\"라는 입력문장에 대응하여, \"걱정되네요\"와 같은 공감표현을 나타내는 제1 출력문장을 먼저 출력하고, 소정의 시간이 경과한 후 \"신나는 음악은 어때요? 기 분이 좋아질 거예요\"와 같은 조언 및 위로를 위한 제2 출력문장을 출력할 수 있다. 감정표현 결정부는 각 출력문장에 대응하는 시각적인 감정표현, 예를 들어 인간의 얼굴 표정을 표현하는 이미지 파일을 저장장치 또는 서버로부터 불러올 수 있다. 출력문장과 감정표현의 대응관계에 관한 정보는 데이터베이스에 저장되어 있을 수 있다. 본 발명의 바람직한 실시예에 따르면, 제1 출력문장과 제2 출력문장을 이원화한 것과 마찬가지로 각각의 출력문 장에 대해 서로 다른 감정표현을 결합하여 출력할 수 있다. 전술한 바와 같이, 종래기술에 따른 챗봇 시스템에 서는 주로 하나의 입력문장에 대해 하나의 출력문장만이 생성되어 사용자와 로봇이 서로 자연스러운 대화를 주 고받기 어려웠으며, 컴퓨터의 답변에 감정표현을 포함시킨다 하여도 하나의 답변에 하나의 감정만이 표현되어 시시각각으로 변화할 수 있는 화자간의 감정을 섬세하게 반영하기 어려웠다. 본 발명은 이러한 문제점을 해결하 기 위해 착안된 것으로서, 사용자가 입력한 문장에 대한 답변뿐만 아니라 시각적인 감정표현을 이원화하여 보다 유연하고 효과적으로 상호작용할 수 있도록 하는 것을 목적으로 한다. 도 3을 참조하면, 챗봇 시스템은 사용자에게 공감을 표현하는 제1 출력문장에 대해서는 공감을 나타내는 제1 감 정표현(I1)을 결합하고, 조언과 위로를 표현하는 제2 출력문장에 대해서는 분위기를 전환하기 위한 제2 감정표현 (I2)를 결합하여 출력한다. 이와 같이 챗봇의 답변과 감정표현을 이원화함으로써 종래의 챗봇 시스템의 문제점을 해결할 수 있다. 만약 답변문장에 대해 하나의 감정표현만을 제시하게 되면, 사용자가 도 3의 예시와 같이 우울 한 감정을 느끼고 있음에도 불구하고 처음부터 웃는 표정의 이미지를 출력하게 되어 부자연스럽게 된다. 반대로 답변문장의 형태소마다 감정표현을 달리 구성하게 되면 전체적인 맥락을 반영하지 못해 어색한 표현이 될 수 있 다(예를 들어, 부정적인 단어가 반드시 부정적인 맥락에서만 사용되지 않음에도 불구하고, \"어제 슬픈 영화를 봤는데 너무 좋았어\"와 같은 문장에서 '슬픈'이라는 형태소에 대해 부정적인 감정표현을 하게 될 가능성이 있음). 또한, 형태소마다 감정을 표현하게 되면 연산이 복잡해지고 지나치게 많은 출력으로 인해 대화가 부자연 스러워질 수도 있다. 본 발명의 실시예에 따르면, 사용자의 입력에 대해 공감을 표시하는 제1 답변 및 감정표현을 출력하고(예컨대, 부정적인 상황 및 감정에 대해서는 사용자의 감정과 동일하거나 유사한 부정적인 감정을 나타내는 이미지를 출 력함), 일정 시간 경과 후에는 조언을 제공하거나 분위기를 전환시키기 위한 제2 답변 및 감정표현을 출력함으 로써(예컨대, 부정적인 이미지 출력 후에는 사용자의 감정과 상반되는 긍정적인 감정을 나타내는 이미지를 출력 함), 사용자가 챗봇과 자연스러운 대화를 주고 받는다는 느낌을 줄 수 있다. 출력부는 상기 결정된 출력문장 및 감정표현을 사용자 인터페이스를 통해 출력하도록 구성된다. 일 실 시예에 따르면, 출력부는 상기 제1 출력문장 및 제1 감정표현을 동시에 출력하고, 후속하여 상기 제2 출력 문장 및 제2 감정표현을 동시에 출력할 수 있다. 전술한 바와 같이, 출력부는 상기 제1 출력문장 및 제1 감정표 현(공감을 위한 표현)을 출력한 후 소정의 시간이 경과한 이후에 상기 제2 출력문장 및 제2 감정표현(조언 및 분위기 전환을 위한 표현)을 출력하도록 하여 자연스러운 대화의 흐름을 만들 수 있다. 사용자 인터페이스 는 예컨대 프로세서에 의해 연산된 기계어로 구성된 출력을 자연어로 변환하기 위한 프로그램 및 이를 사용자가 보거나 들을 수 있게 출력하는 디스플레이 또는 스피커 등의 장치로 구성될 수 있다. 일 실시예에서, 상기 데이터베이스에 저장된 입력문장과 대응하는 출력문장의 관계정보는 인공지능 학습모 델을 이용하여 업데이트될 수 있다. 인공지능 학습모델은 사전에 사용자가 입력한 훈련 데이터 세트 에 기초하여 입력문장의 형태소, 상황정보, 감정정보 및 출력문장(답변)의 대응관계정보를 학습하도록 구성되는 교사학습모델, 또는 사용자가 사전에 입력한 정보에 포함되지 않은(즉, 데이터베이스에 저장되지 않은) 형태소 가 입력될 경우 임의의 답변(\"~은 무슨 뜻인가요?\" 등)을 출력한 후 이에 대한 사용자의 입력을 피드백으로 하 여 데이터베이스를 스스로 업데이트하는 비교사학습모델로 구성될 수 있다. 상기한 실시예들에 따른 챗봇 시스템은 애플리케이션으로 구현되거나 다양한 컴퓨터 구성요소를 통하여 수행될 수 있는 프로그램 명령어에 의해 구현될 수 있으며, 이러한 프로그램 명령들은 컴퓨터로 판독 가능한 기록 매체 에 기록될 수 있다. 상기 컴퓨터 판독 가능한 기록 매체는 프로그램 명령어, 데이터 파일, 데이터 구조 등을 단 독으로 또는 조합하여 포함할 수 있다. 컴퓨터 판독 가능한 기록 매체의 예에는, 하드 디스크, 플로피 디스크 및 자기 테이프와 같은 자기 매체, CD- ROM, DVD와 같은 광기록 매체, 플롭티컬 디스크(floptical disk)와 같은 자기-광 매체(magneto-optical media), 및 ROM, RAM, 플래시 메모리 등과 같은 프로그램 명령어를 저장하고 수행하도록 특별히 구성된 하드웨 어 장치가 포함된다. 이상에서 설명한 감정 표현을 시각적으로 나타낼 수 있는 챗봇 시스템에 의하면, 사용자가 입력한 문장으로부터 사용자가 처한 상황 및 감정을 분석하고 이에 대한 답변 및 감정표현을 이원화하여 보다 유연하고 효과적으로 상호작용할 수 있는 챗봇 시스템이 제공된다. 실시예에 따르면, 입력된 문장을 형태소 단위로 구분하여 분석하고, 입력문장과 출력문장의 대응정보를 저장한 데이터베이스는 학습모델을 이용하여 업데이트되므로 적절한 답 변을 제공할 수 있다. 또한, 종래의 텍스트 기반 챗봇 시스템에 의하면 감정표현 없이 정해진 텍스트 답변만을 출력하거나 하나의 입 력에 대해 단일 감정표현만을 출력하여 자연스러운 상호작용이 불가능하였으나, 본 발명의 실시예에 따르면 챗 봇의 답변 과정을 이원화하여 사용자가 처한 상황 및 감정에 대한 공감을 표현하기 위한 제1 답변 및 이를 시각 적으로 표현하기 위한 이미지를 먼저 출력하고, 후속하여 사용자의 상황 및 감정을 개선하기 위한 조언에 관한 제2 답변 및 이를 시각적으로 표현하기 위한 이미지를 출력함으로써 사용자가 컴퓨터와 보다 자연스러운 상호작 용이 가능하도록 하였다. 이상에서는 실시예들을 참조하여 설명하였지만, 해당 기술 분야의 숙련된 당업자는 하기의 특허 청구의 범위에 기재된 본 발명의 사상 및 영역으로부터 벗어나지 않는 범위 내에서 본 발명을 다양하게 수정 및 변경시킬 수 있음을 이해할 수 있을 것이다."}
{"patent_id": "10-2020-0040537", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일 실시예에 따른 감정 표현을 시각적으로 나타낼 수 있는 챗봇 시스템의 구성을 나타낸 도면 이다. 도 2는 일 실시예에 따른 챗봇 시스템의 상황 및 감정 분석부의 구성을 상세히 나타낸 도면이다. 도 3은 일 실시예에 따른 챗봇 시스템을 이용한 채팅 상황을 예시적으로 나타낸 도면이다."}
