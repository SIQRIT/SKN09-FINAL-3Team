{"patent_id": "10-2019-0035593", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2020-0114230", "출원번호": "10-2019-0035593", "발명의 명칭": "사용자 감정 파악에 따른 응답을 생성하는 시스템 및 방법", "출원인": "서울대학교산학협력단", "발명자": "이준환"}}
{"patent_id": "10-2019-0035593", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "사용자 감정에 따라 응답을 생성하는 시스템에 있어서,사용자로부터 획득된 대화데이터를 저장하는 메모리; 및 상기 대화데이터를 기초로 상기 사용자의 감정이 반영된 대화데이터의 무드를 결정하고, 결정된 무드에 기초하여 상기 대화데이터에 대한 응답에 포함될 텍스트 및 구조 중 적어도 하나를 결정하여 상기 응답을 생성하는 제어부를 포함하는, 응답생성시스템."}
{"patent_id": "10-2019-0035593", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1 항에 있어서,상기 제어부는,상기 대화데이터로부터 감정을 나타내는 데이터인 텍스트를 추출하고, 추출된 텍스트에 대응되는 감정에 가중치를 부여하여 상기 무드를 결정하는, 응답생성시스템."}
{"patent_id": "10-2019-0035593", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 2 항에 있어서,상기 제어부는, 상기 대화데이터에 포함된 텍스트의 반복횟수, 텍스트의 표현강도 및 비속어 포함여부 중 적어도 하나에 기초하여 상기 가중치를 부여하는, 응답생성시스템."}
{"patent_id": "10-2019-0035593", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 3 항에 있어서,상기 제어부는,상기 대화데이터가 획득된 시간 및 상기 사용자의 위치 중 적어도 하나를 포함하는 환경데이터를 획득하고, 획득된 환경데이터를 상기 텍스트 형식으로 변환하는, 응답생성시스템."}
{"patent_id": "10-2019-0035593", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제 4 항에 있어서,상기 제어부는,변환된 환경데이터 및 상기 텍스트에 기초하여 상기 무드를 결정하고, 결정된 무드에 대응하여 선택된 텍스트및 이미지 중 적어도 하나를 배치하여 상기 응답을 생성하는, 응답생성시스템."}
{"patent_id": "10-2019-0035593", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "응답생성시스템이 사용자 감정에 따라 응답을 생성하는 방법에 있어서,사용자로부터 획득된 대화데이터를 획득하는 단계; 상기 대화데이터를 기초로 상기 사용자의 감정이 반영된 대화데이터의 무드를 결정하는 단계; 및결정된 무드에 기초하여 상기 대화데이터에 대한 응답에 포함된 텍스트 및 구조 중 적어도 하나를 결정하여 상기 응답을 생성하는 단계를 포함하는, 응답생성방법."}
{"patent_id": "10-2019-0035593", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "공개특허 10-2020-0114230-3-제 6 항에 있어서,상기 대화데이터의 무드를 결정하는 단계는,상기 텍스트로부터 감정에 대응되는 텍스트를 추출하는 단계; 및 추출된 텍스트에 대응되는 감정에 가중치를 부여하는 단계를 포함하는, 응답생성방법."}
{"patent_id": "10-2019-0035593", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제 7 항에 있어서,상기 가중치를 부여하는 단계는,상기 대화데이터에 포함된 텍스트의 반복횟수, 텍스트의 표현강도 및 비속어 포함여부 중 적어도 하나에 기초하여 상기 가중치를 부여하는 단계를 포함하는, 응답생성방법."}
{"patent_id": "10-2019-0035593", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제 8 항에 있어서,상기 응답생성방법은,상기 대화데이터가 획득된 시간 및 상기 사용자의 위치 중 적어도 하나를 포함하는 환경데이터를 획득하는단계; 및 획득된 환경데이터를 변환하여 상기 감정에 가중치를 부여하는 단계를 더 포함하는, 응답생성방법."}
{"patent_id": "10-2019-0035593", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제 9 항에 있어서,상기 응답을 생성하는 단계는,변환된 환경데이터 및 상기 텍스트에 기초하여 상기 무드를 결정하는 단계; 및 결정된 무드에 대응하여 선택된 텍스트 및 이미지 중 적어도 하나를 배치하여 상기 응답을 생성하는 단계를 포함하는, 응답생성방법."}
{"patent_id": "10-2019-0035593", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제 6 항에 기재된 방법을 수행하는 프로그램이 기록된 컴퓨터 판독 가능한 기록 매체."}
{"patent_id": "10-2019-0035593", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "응답생성시스템에 의해 수행되며, 제 6 항에 기재된 방법을 수행하기 위해 매체에 저장된 컴퓨터 프로그램."}
{"patent_id": "10-2019-0035593", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "사용자 감정에 따라 응답을 생성하는 시스템 및 방법을 제시하며, 사용자 감정에 따라 응답을 생성하는 시스템에 있어서, 사용자로부터 획득된 대화데이터를 저장하는 메모리 및 상기 대화데이터를 기초로 상기 사용자의 감정이 반영된 대화데이터의 무드를 결정하고, 결정된 무드에 기초하여 상기 대화데이터에 대한 응답에 포함될 단어 및 구조 중 적어도 하나를 결정하여 상기 응답을 생성하는 제어부를 포함할 수 있다."}
{"patent_id": "10-2019-0035593", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 명세서에서 개시되는 실시예들은 사용자 감정에 따라 응답을 생성하는 시스템 및 방법에 관한 것으로, 보다 상세하게는 사용자의 감정 상태를 결정하고, 사용자의 감정 상태에 적합한 챗봇 응답 분위기를 결정하여 이에 맞는 응답 문장을 제공하는 사용자 감정에 따라 응답을 생성하는 시스템 및 방법에 관한 것이다."}
{"patent_id": "10-2019-0035593", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "과거 챗봇은 사용자가 입력한 문장으로부터 사전에 정의된 키워드의 유무를 인식해 식별된 키워드에 대응되는 응답을 출력하는 단순 패턴매칭 방식을 통해 사용자의 문장에 응답을 하였다. 이때, 챗봇은 키워드가 포함되어 있는 문장의 문맥을 고려하여 특정 응답을 선택하는 것이 아닌 단순히 키워드 에 대응되는 응답을 조합하여 응답을 생성하기 때문에 사용자의 문장에 적합한 응답을 제공하지 못하는 경우가있다. 최근 인공지능 기술의 발전으로 머신러닝, 자연어 처리 등의 기술이 결합되면서 인간의 자연스러운 언어로 질 문이나 명령을 내리면 맥락을 파악하여 응답이 가능해지고 있다 특히, 인공지능 기술을 이용하는 경우, 챗봇과 사용자간의 대화가 축적될수록 챗봇 스스로 학습을 통해 사용자 대화에 대한 응답 정확도를 높일 수 있다. 하지만, 인공지능 기술을 이용하여도 사용자로부터 획득되는 대화에 대응되는 형식적인 응답을 제공할 수 있을 뿐, 사용자의 감정에 따라 적합한 응답을 제공하지 못한다는 문제점이 있다. 관련하여 선행기술 문헌인 한국특허공개번호 제 10-2019-0005137호에서는 회의일정을 스케줄링하는 챗봇 서버, 메신저 서버 및 방법에 관한 것으로 회의 일정을 스케줄링하는 챗봇 서버는 회의 주관자의 단말과 챗봇과의 채 팅방을 통해 회의 주관자로부터 회의 일정 스케줄링 요청 메시지를 수신하고, 회의 일정 스케줄링 요청 메시지 에 기초하여 관련 회의 이력을 도출하여 관련 회의 이력에 기초하여 회의 참석자, 회의 일정 및 회의 장소 중 적어도 하나를 결정하여 회의 일정에 대한 정보에 기초하여 회의 참석자의 단말 각각과 챗봇과의 개인 채팅방 및 회의 참석자의 단말간의 그룹 채팅방을 통해 회의와 관련된 정보를 제공할 수 있을 뿐, 사용자의 감정에 따 라 적합한 응답을 제공할 수 없다. 따라서 상술된 문제점을 해결하기 위한 기술이 필요하게 되었다."}
{"patent_id": "10-2019-0035593", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 2, "content": "한편, 전술한 배경기술은 발명자가 본 발명의 도출을 위해 보유하고 있었거나, 본 발명의 도출 과정에서 습득한 기술 정보로서, 반드시 본 발명의 출원 전에 일반 공중에게 공개된 공지기술이라 할 수는 없다."}
{"patent_id": "10-2019-0035593", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 명세서에서 개시되는 실시예들은, 사용자 감정에 따라 응답을 생성하는 시스템 및 방법을 제시하는데 목적이 있다. 본 명세서에서 개시되는 실시예들은, 사용자의 감정을 파악하기 위해 환경 데이터를 함께 분석하여 사용자 감정 에 따라 응답을 생성하는 시스템 및 방법을 제시하는데 목적이 있다. 본 명세서에서 개시되는 실시예들은, 텍스트 내의 사용자 주요 감정을 식별하여 사용자 감정에 따라 응답을 생 성하는 시스템 및 방법을 제시하는데 목적이 있다. 본 명세서에서 개시되는 실시예들은, 사용자의 무드에 따라 응답 발화의 경중 및 고저를 결정하는 사용자 감정 에 따라 응답을 생성하는 시스템 및 방법을 제시하는데 목적이 있다."}
{"patent_id": "10-2019-0035593", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상술한 기술적 과제를 달성하기 위한 기술적 수단으로서, 일 실시예에 따르면, 사용자 감정에 따라 응답을 생성 하는 시스템에 있어서, 사용자로부터 획득된 대화데이터를 저장하는 메모리 및 상기 대화데이터를 기초로 상기 사용자의 감정이 반영된 대화데이터의 무드를 결정하고, 결정된 무드에 기초하여 상기 대화데이터에 대한 응답 에 포함될 단어 및 구조 중 적어도 하나를 결정하여 상기 응답을 생성하는 제어부를 포함할 수 있다. 다른 실시예에 따르면, 응답생성시스템이 사용자 감정에 따라 응답을 생성하는 방법에 있어서, 사용자로부터 획 득된 대화데이터를 획득하는 단계, 상기 대화데이터를 기초로 상기 사용자의 감정이 반영된 대화데이터의 무드 를 결정하는 단계 및 결정된 무드에 기초하여 상기 대화데이터에 대한 응답에 포함된 단어 및 구조 중 적어도 하나를 결정하여 상기 응답을 생성하는 단계를 포함할 수 있다. 또 다른 실시예에 따르면, 응답생성방법을 수행하는 프로그램이 기록된 컴퓨터 판독이 가능한 기록매체로서, 상 기 응답생성방법은, 사용자로부터 획득된 대화데이터를 획득하는 단계, 상기 대화데이터를 기초로 상기 사용자 의 감정이 반영된 대화데이터의 무드를 결정하는 단계 및 결정된 무드에 기초하여 상기 대화데이터에 대한 응답 에 포함된 단어 및 구조 중 적어도 하나를 결정하여 상기 응답을 생성하는 단계를 포함할 수 있다. 다른 실시예에 따르면, 응답생성시스템에 의해 수행되며, 응답생성방법을 수행하기 위해 기록매체에 저장된 컴 퓨터프로그램으로서, 상기 응답생성방법은, 사용자로부터 획득된 대화데이터를 획득하는 단계, 상기 대화데이터 를 기초로 상기 사용자의 감정이 반영된 대화데이터의 무드를 결정하는 단계 및 결정된 무드에 기초하여 상기대화데이터에 대한 응답에 포함된 단어 및 구조 중 적어도 하나를 결정하여 상기 응답을 생성하는 단계를 포함 할 수 있다."}
{"patent_id": "10-2019-0035593", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "전술한 과제 해결 수단 중 어느 하나에 의하면, 사용자 감정에 따라 응답을 생성하는 시스템 및 방법을 제시할 수 있다. 전술한 과제 해결 수단 중 어느 하나에 의하면, 사용자의 감정을 파악하기 위해 환경 데이터를 함께 분석하여 사용자 감정에 따라 응답을 생성하는 시스템 및 방법을 제시할 수 있다. 전술한 과제 해결 수단 중 어느 하나에 의하면, 텍스트 내의 사용자 주요 감정을 식별하여 사용자 감정에 따라 응답을 생성하는 시스템 및 방법을 제시할 수 있다. 전술한 과제 해결 수단 중 어느 하나에 의하면, 사용자의 무드에 따라 응답 발화의 경중 및 고저를 결정하는 사 용자 감정에 따라 응답을 생성하는 시스템 및 방법을 제시할 수 있다. 개시되는 실시예들에서 얻을 수 있는 효과는 이상에서 언급한 효과들로 제한되지 않으며, 언급하지 않은 또 다"}
{"patent_id": "10-2019-0035593", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 2, "content": "른 효과들은 아래의 기재로부터 개시되는 실시예들이 속하는 기술분야에서 통상의 지식을 가진 자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2019-0035593", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "아래에서는 첨부한 도면을 참조하여 다양한 실시예들을 상세히 설명한다. 아래에서 설명되는 실시예들은 여러 가지 상이한 형태로 변형되어 실시될 수도 있다. 실시예들의 특징을 보다 명확히 설명하기 위하여, 이하의 실시"}
{"patent_id": "10-2019-0035593", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "예들이 속하는 기술분야에서 통상의 지식을 가진 자에게 널리 알려져 있는 사항들에 관해서 자세한 설명은 생략 하였다. 그리고, 도면에서 실시예들의 설명과 관계없는 부분은 생략하였으며, 명세서 전체를 통하여 유사한 부 분에 대해서는 유사한 도면 부호를 붙였다. 명세서 전체에서, 어떤 구성이 다른 구성과 \"연결\"되어 있다고 할 때, 이는 ‘직접적으로 연결’되어 있는 경우 뿐 아니라, ‘그 중간에 다른 구성을 사이에 두고 연결’되어 있는 경우도 포함한다. 또한, 어떤 구성이 어떤 구성을 \"포함\"한다고 할 때, 이는 특별히 반대되는 기재가 없는 한, 그 외 다른 구성을 제외하는 것이 아니라 다른 구성들을 더 포함할 수도 있음을 의미한다. 이하 첨부된 도면을 참고하여 실시예들을 상세히 설명하기로 한다. 다만 이를 설명하기에 앞서, 아래에서 사용되는 용어들의 의미를 먼저 정의한다. ‘대화데이터’는 사용자의 의사가 포함된 데이터로 예를 들어, 시각적으로 식별가능한 데이터인 텍스트, 이모 티콘 또는 이모지 등이 포함될 수 있다. ‘응답’은 사용자로부터 획득된 대화데이터에 대응하여 사용자에게 제공되는 데이터로 텍스트 또는 이미지가 포함될 수 있다. 그리고 ‘무드’는 텍스트의 표현강도, 문체가 반영되어 대화데이터를 통해 드러나는 대화 분위기이다. 위에 정의한 용어 이외에 설명이 필요한 용어는 아래에서 각각 따로 설명한다. 도 1은 일 실시예에 따른 응답생성시스템을 설명하기 위한 블럭도이다. 응답생성시스템은 네트워크(N)를 통해 원격지의 서버에 접속하거나, 타 단말 및 서버와 연결 가능한 컴퓨 터나 휴대용 단말기, 텔레비전, 웨어러블 디바이스(Wearable Device) 등으로 구현될 수 있다. 여기서, 컴퓨터는 예를 들어, 웹 브라우저(WEB Browser)가 탑재된 노트북, 데스크톱(desktop), 랩톱(laptop)등을 포함하고, 휴대 용 단말기는 예를 들어, 휴대성과 이동성이 보장되는 무선 통신 장치로서, PCS(Personal Communication System), PDC(Personal Digital Cellular), PHS(Personal Handyphone System), PDA(Personal DigitalAssistant), GSM(Global System for Mobile communications), IMT(International Mobile Telecommunication)- 2000, CDMA(Code Division Multiple Access)-2000, W-CDMA(W-Code Division Multiple Access), Wibro(Wireless Broadband Internet), 스마트폰(Smart Phone), 모바일 WiMAX(Mobile Worldwide Interoperability for Microwave Access) 등과 같은 모든 종류의 핸드헬드(Handheld) 기반의 무선 통신 장치를 포함할 수 있다. 또한, 텔레비전은 IPTV(Internet Protocol Television), 인터넷 TV(Internet Television), 지 상파 TV, 케이블 TV 등을 포함할 수 있다. 나아가 웨어러블 디바이스는 예를 들어, 시계, 안경, 액세서리, 의복, 신발 등 인체에 직접 착용 가능한 타입의 정보처리장치로서, 직접 또는 다른 정보처리장치를 통해 네트워 크를 경유하여 원격지의 서버에 접속하거나 타 단말과 연결될 수 있다. 도 1 을 참조하면, 응답생성시스템은 입출력부, 제어부, 통신부 및 메모리를 포함할 수 있다. 입출력부는 사용자로부터 입력을 수신하기 위한 입력부와, 작업의 수행 결과 또는 응답생성시스템의 상태 등의 정보를 표시하기 위한 출력부를 포함할 수 있다. 예를 들어, 입출력부는 사용자 입력을 수신하 는 조작 패널(operation panel) 및 화면을 표시하는 디스플레이 패널(display panel) 등을 포함할 수 있다. 구체적으로, 입력부는 키보드, 물리 버튼, 터치 스크린, 카메라 또는 마이크 등과 같이 다양한 형태의 사용자 입력을 수신할 수 있는 장치들을 포함할 수 있다. 또한, 출력부는 디스플레이 패널 또는 스피커 등을 포함할 수 있다. 다만, 이에 한정되지 않고 입출력부는 다양한 입출력을 지원하는 구성을 포함할 수 있다. 제어부는 응답생성시스템의 전체적인 동작을 제어하며, CPU 등과 같은 프로세서를 포함할 수 있다. 제어부는 입출력부를 통해 수신한 사용자 입력에 대응되는 동작을 수행하도록 응답생성시스템에 포함된 다른 구성들을 제어할 수 있다. 예를 들어, 제어부는 메모리에 저장된 프로그램을 실행시키거나, 메모리에 저장된 파일을 읽어 오거나, 새로운 파일을 메모리에 저장할 수도 있다. 이러한 제어부는 사용자로부터 획득된 대화데이터를 기초로 대화데이터의 무드를 결정할 수 있다. 이를 위해, 제어부는 대화데이터로부터 감정을 나타내는 데이터인 텍스트를 추출할 수 있다. 예를 들어, 제어부는 대화데이터에 포함된 텍스트인 “빨리 지금 병원 가는 길을 찾아줘!”에서 감정을 나 타내는 “빨리” 또는 “어서!” 등을 감정을 나타내는 텍스트로써 추출할 수 있으며, 추가적으로 대화데이터에 포함된 이모티콘을 추출할 수 있다. 그리고 제어부는 추출된 텍스트에 대응되는 감정에 대해 가중치를 부여할 수 있다. 즉, 제어부는 추출된 텍스트 중 동일한 텍스트의 반복 횟수, 텍스트의 표현강도, 이모티콘 또는 이모지의 사용여부 등에 기초하여 감정에 가중치를 부여할 수 있다. 예를 들어, 제어부는 대화데이터로부터 추출된 감정텍스트 중 “빨리”가 2회 이상 반복되는 경우, “빨리 ”에 대응되는 감정인 긴급에 대해 +2 가중치를 부여할 수 있다. 또는 예를 들어, 제어부는 대화데이터로부터 추출된 텍스트인 은어 또는 비속어가 문장당 사용빈도를 계산 할 수 있다. 즉, 대화데이터에 포함된 텍스트를 구분하는 단위인 문장별로 은어 또는 비속어의 사용빈도 차이가 기 설정된 범위 이내로 유사한 경우, 제어부는 은어 또는 비속어에 대해 가중치를 낮게 설정할 수 있다. 이와 달리 문장별로 은어 또는 비속어의 사용빈도 차이가 기 설정된 범위를 초과한 경우, 제어부는 은어 또는 비속어에 대응되는 감정에 대해 가중치를 부여할 수 있다. 예를 들어, 제어부는 이모티콘에 대응되는 감정에 대해 가중치를 부여하되 텍스트에 비해 높은 가중치를 부여할 수 있다. 또는 제어부는 대화데이터에 포함된 텍스트의 구조에 기초하여 추가적인 가중치를 감정에 부여할 수 있다. 예를 들어, 제어부는 대화데이터에 포함된 텍스트의 구조에서 품사 일부가 제거된 구조의 텍스트에 대응되 는 감정에 품사 일부가 제거 되지 않은 구조의 텍스트보다 높은 가중치를 부여할 수 있다. 실시예에 따라, 제어부는 대화데이터가 획득된 시간 및 사용자의 위치 중 적어도 하나를 포함하는 환경데 이터를 획득할 수 있으며, 획득된 환경데이터를 텍스트 형식으로 변환할 수 있고, 텍스트 형식으로 변환된 환경 데이터를 기초로 연관성이 높은 텍스트에 대응되는 감정에 추가적인 가중치를 부여할 수 있다. 이를 위해, 제어부는 환경데이터와 연관성이 높은 텍스트와의 관계를 인공지능을 이용하여 학습할 수 있다. 예를 들어, 제 어부는 장소 또는 시간대별로 감정에 대응되는 텍스트의 사용 빈도를 학습할 수 있다. 예를 들어, 제어부는 사용자의 단말로부터 대화데이터가 획득된 시간인 ‘저녁 10시’를 획득하고, 사용자 의 위치인 GPS 정보를 환경데이터로 획득할 수 있다. 그리고 제어부는 획득된 환경데이터를 ‘저녁 10시’ 와 GPS정보에 대응되는 장소인 ‘관악산’으로 변환할 수 있고, 연관성이 높은 텍스트에 대응되는 감정인 “긴 급”, “위기” 에 대해 추가적인 가중치를 부여할 수 있다. 또는 예를 들어 제어부는 사용자의 단말로부터 대화데이터가 획득된 시간인 ‘오전 10시’를 획득하고, 사 용자의 GPS정보를 획득할 수 있다. 그리고 제어부는 획득된 환경데이터인 ‘오전 10시’와 GPS정보에 대응 되는 장소인 ‘오피스빌딩’ 변환할 수 있고, 연관성이 높은 텍스트에 대응되는 감정인 “격식” 에 대해 추가 적인 가중치를 부여할 수 있다. 그리고 제어부는 변환된 환경데이터 및 텍스트에 기초하여 대화데이터의 무드를 결정할 수 있다. 즉, 제어부는 텍스트로 변환된 환경데이터와 대화데이터에서 추출된 텍스트를 조합하여 텍스트에 기초하여 감정별로 부여된 가중치를 기초로 대화데이터의 무드를 결정할 수 있다. 예를 들어, 제어부는 변환된 환경데이터인 ‘저녁 10시’, ‘관악산’과 대화데이터에서 추출된 텍스트인 “빨리 어서!!”를 기초로 가중치가 부여된 감정인 ‘긴급’, ‘위급’에 기초하여 현재 대화데이터의 무드가 긴급상황 대화임을 결정할 수 있다. 그리고 제어부는 대화데이터에 대한 응답에 포함될 단어 및 구조 중 적어도 하나를 결정하여 상기 응답을 생성할 수 있다. 실시예에 따라, 제어부는 선정된 무드에 대한 응답을 생성하기 위해, 무드에 맞는 구조(템플릿)를 선택할 수 있다. 예를 들어, 대화데이터의 무드가 긴급한 대화로 결정된 경우, 제어부는 텍스트 구조를 동사, 목적어로 구 성된 명령형을 선택할 수 있으며, 대화데이터의 무드가 사무적 대화로 결정된 경우, 제어부는 주어, 동사, 목적어 그리고 높임말로 구성된 사무형을 선택할 수 있다. 그리고 제어부는 무드에 대응되는 표현강도를 갖는 단어를 선택하여 대화데이터의 무드에 대응되는 문체를 생성할 수 있다. 예를 들어, 대화데이터의 무드가 긴급한 대화로 식별된 경우, 제어부는 명령형 구조에 포함될 단어에 대해 ‘빠른’, ‘긴급한’ 과 같이 형용사, 부사 등의 긴급함의 강도가 높은 단어를 선택하여 명령형의 문체를 생성 할 수 있다. 또는 예를 들어, 대화데이터의 무드가 사무적 대화로 식별된 경우, 제어부는 사무형 구조에 포함될 단어에 대해 형용사의 강도를 제일 낮추어 사무적인 문체를 생성할 수 있다. 또한, 제어부는 대화데이터의 무드에 따라 응답의 길이를 선정할 수 있다. 예를 들어, 대화데이터의 무드가 긴급한 대화로 식별된 경우, 제어부는 짧은 응답을 생성할 수 있으며, 대 화데이터의 무드가 사무적 대화로 식별된 경우, 제어부는 사용자의 대화데이터에 포함된 텍스트의 길에 대 응되는 길이로 응답을 생성할 수 있다. 통신부는 다른 디바이스 또는 네트워크와 유무선 통신을 수행할 수 있다. 이를 위해, 통신부는 다양 한 유무선 통신 방법 중 적어도 하나를 지원하는 통신 모듈을 포함할 수 있다. 예를 들어, 통신 모듈은 칩셋 (chipset)의 형태로 구현될 수 있다. 통신부가 지원하는 무선 통신은, 예를 들어 Wi-Fi(Wireless Fidelity), Wi-Fi Direct, 블루투스 (Bluetooth), UWB(Ultra Wide Band) 또는 NFC(Near Field Communication) 등일 수 있다. 또한, 통신부가 지원하는 유선 통신은, 예를 들어 USB 또는 HDMI(High Definition Multimedia Interface) 등일 수 있다. 메모리에는 파일, 어플리케이션 및 프로그램 등과 같은 다양한 종류의 데이터가 설치 및 저장될 수 있다. 제어부는 메모리에 저장된 데이터에 접근하여 이를 이용하거나, 또는 새로운 데이터를 메모리에 저장할 수도 있다. 또한, 제어부는 메모리에 설치된 프로그램을 실행할 수도 있다.이러한 메모리는 사용자로부터 획득한 대화데이터 및 환경데이터 중 적어도 하나를 저장할 수 있다. 도 2 는 일 실시예에 따른 응답생성방법을 설명하기 위한 순서도이다. 도 2 에 도시된 실시예에 따른 응답생성방법은 도 1 에 도시된 응답생성시스템에서 시계열적으로 처리되는 단계들을 포함한다. 따라서, 이하에서 생략된 내용이라고 하더라도 도 1 에 도시된 응답생성시스템에 관하 여 이상에서 기술한 내용은 도 2 에 도시된 실시예에 따른 응답생성방법에도 적용될 수 있다. 우선, 응답생성시스템은 사용자로부터 대화데이터를 획득할 수 있다(S2001). 예를 들어, 응답생성시스템은 사용자가 단말에 입력한 텍스트 또는 이모티콘을 대화데이터로 획득할 수 있 다. 이때, 실시예에 따라, 응답생성시스템은 대화데이터가 획득된 시간 및 사용자의 위치 중 적어도 하나를 포 함하는 환경데이터를 획득할 수 있다. 예를 들어, 응답생성시스템은 대화데이터가 획득된 시간인 ‘오전 11시’, 대화데이터가 획득될 당시 사용 자의 위치인 ‘강남 파이낸스 센터’ 를 환경데이터로 획득할 수 있다. 그리고 응답생성시스템은 대화데이터를 기초로 대화데이터의 무드를 결정할 수 있다(S2002). 이를 위해, 응답생성시스템은 대화데이터로부터 감정을 나타내는 텍스트 또는 이모티콘 등을 추출할 수 있 다. 예를 들어, 응답생성시스템은 대화데이터에 포함된 텍스트 중 감정을 나타내는 텍스트인 형용사, 감탄사, 부사 등을 추출하거나 이미지 데이터인 이모티콘 또는 이모지 등을 추출할 수 있다. 그리고 응답생성시스템은 S2001단계에서 획득된 환경데이터를 감정에 대응되도록 변환할 수 있다. 그리고 응답생성시스템은 대화데이터로부터 감정을 나타내는 텍스트를 추출할 수 있고, 추출된 텍스트에 대응되는 감정에 가중치를 부여할 수 있다. 예를 들어, 응답생성시스템은 대화데이터로부터 감정을 나타내는 텍스트를 추출하되, 대화데이터에 포함된 텍스트의 반복횟수, 텍스트의 표현강도 및 비속어 포함여부 등에 따라 텍스트에 대응되는 감정에 가중치를 부여 할 수 있다. 또한 실시예에 따라, 응답생성시스템은 환경데이터로 획득된 사용자의 GPS위치에 대응되는 장소로 환경데 이터를 텍스트로 변환할 수 있고, 변환된 장소의 용도 또는 성격을 기초로 연관성이 높은 텍스트에 대응되는 감 정에 추가 가중치를 부여할 수 있다. 예를 들어, 응답생성시스템은 환경데이터로 사용자의 단말로부터 GPS정보를 획득할 수 있고, 획득된 GPS 정보에 대응되는 장소명칭인 ‘종로’로 환경데이터를 변환할 수 있고, 대화데이터에서 변환된 환경데이터인 ‘ 종로’와 연관성있는 텍스트에 대응되는 감정에 추가적인 가중치를 부여할 수 있다. 이후, 응답생성시스템은 결정된 무드에 따라 대화데이터에 대한 응답에 포함된 단어 및 구조 중 적어도 하 나를 결정하여 응답을 생성할 수 있다(S2003). 이를 위해, 응답생성시스템은 변환된 환경데이터 및 텍스트에 기초하여 대화데이터의 무드를 결정할 수 있 다. 예를 들어, 응답생성시스템은 S2002단계에서 텍스트에 의해 가중치가 부여된 감정 중 기 설정된 가중치를 초과하는 감정인 ‘화남’, ‘급박’을 기초로 대화데이터의 무드를 결정할 수 있다. 그리고 응답생성시스템은 결정된 무드에 대응하여 텍스트 및 이미지 중 적어도 하나를 배치하여 응답을 생 성할 수 있다. 도 3 은 결정된 무드에 대응하여 응답을 생성하는 과정을 도시한 순서도이다. 이를 참조하면, 응답생성시스템 은 식별된 무드에 대응하여 응답에 포함될 텍스트의 구조를 설정할 수 있다(S3001). 예를 들어, 대화데이터의 무드가 긴급한 대화로 결정된 경우, 응답생성시스템은 최소 품사만이 포함되는 명령형 구조를 선택할 수 있다. 그리고 응답생성시스템은 설정된 구조에 포함될 텍스트의 표현강도를 설정할 수 있고(S3002), 선택된 표현 강도에 대응하여 문체를 적용하여 응답을 생성할 수 있다(S3003). 예를 들어, 응답생성시스템은 응답에 포함될 단어에 대해 ‘빠른’, ‘긴급한’ 과 같이 형용사, 부사 등 의 긴급함의 강도가 높은 텍스트를 선택하여 명령형의 문체를 갖는 응답을 생성할 수 있다. 그리고 응답생성시스템은 무드에 따라 응답의 길이를 설정할 수 있다(S3004). 예를 들어, 응답생성시스템은 명령형 응답을 생성하는 경우 응답의 길이를 매우 짧게 생성할 수 있으며 텍 스트 길이가 짧게 생성할 수 있으며, 격식있는 응답을 생성하는 경우에는 사용자의 대화데이터와 유사한 길이로 응답의 길이를 맞추어 응답을 생성할 수 있다. 이상의 실시예들에서 사용되는 '~부'라는 용어는 소프트웨어 또는 FPGA(field programmable gate array) 또는 ASIC 와 같은 하드웨어 구성요소를 의미하며, '~부'는 어떤 역할들을 수행한다. 그렇지만 '~부'는 소프트웨어 또는 하드웨어에 한정되는 의미는 아니다. '~부'는 어드레싱할 수 있는 저장 매체에 있도록 구성될 수도 있고 하나 또는 그 이상의 프로세서들을 재생시키도록 구성될 수도 있다. 따라서, 일 예로서 '~부'는 소프트웨어 구 성요소들, 객체지향 소프트웨어 구성요소들, 클래스 구성요소들 및 태스크 구성요소들과 같은 구성요소들과, 프 로세스들, 함수들, 속성들, 프로시저들, 서브루틴들, 프로그램특허 코드의 세그먼트들, 드라이버들, 펌웨어, 마 이크로코드, 회로, 데이터, 데이터베이스, 데이터 구조들, 테이블들, 어레이들, 및 변수들을 포함한다. 구성요소들과 '~부'들 안에서 제공되는 기능은 더 작은 수의 구성요소들 및 '~부'들로 결합되거나 추가적인 구 성요소들과 '~부'들로부터 분리될 수 있다. 뿐만 아니라, 구성요소들 및 '~부'들은 디바이스 또는 보안 멀티미디어카드 내의 하나 또는 그 이상의 CPU 들을 재생시키도록 구현될 수도 있다. 도 2 내지 도 3 을 통해 설명된 실시예에 따른 응답생성시스템은 컴퓨터에 의해 실행 가능한 명령어 및 데이터 를 저장하는, 컴퓨터로 판독 가능한 매체의 형태로도 구현될 수 있다. 이때, 명령어 및 데이터는 프로그램 코드 의 형태로 저장될 수 있으며, 프로세서에 의해 실행되었을 때, 소정의 프로그램 모듈을 생성하여 소정의 동작을 수행할 수 있다. 또한, 컴퓨터로 판독 가능한 매체는 컴퓨터에 의해 액세스될 수 있는 임의의 가용 매체일 수 있고, 휘발성 및 비휘발성 매체, 분리형 및 비분리형 매체를 모두 포함한다. 또한, 컴퓨터로 판독 가능한 매체 는 컴퓨터 기록 매체일 수 있는데, 컴퓨터 기록 매체는 컴퓨터 판독 가능 명령어, 데이터 구조, 프로그램 모듈 또는 기타 데이터와 같은 정보의 저장을 위한 임의의 방법 또는 기술로 구현된 휘발성 및 비휘발성, 분리형 및 비분리형 매체를 모두 포함할 수 있다.예를 들어, 컴퓨터 기록 매체는 HDD 및 SSD 등과 같은 마그네틱 저장 매 체, CD, DVD 및 블루레이 디스크 등과 같은 광학적 기록 매체, 또는 네트워크를 통해 접근 가능한 서버에 포함 되는 메모리일 수 있다. 또한 도2 내지 도 3 을 통해 설명된 실시예에 따른 응답생성방법은 컴퓨터에 의해 실행 가능한 명령어를 포함하 는 컴퓨터 프로그램(또는 컴퓨터 프로그램 제품)으로 구현될 수도 있다. 컴퓨터 프로그램은 프로세서에 의해 처 리되는 프로그래밍 가능한 기계 명령어를 포함하고, 고레벨 프로그래밍 언어(High-level Programming Language), 객체 지향 프로그래밍 언어(Object-oriented Programming Language), 어셈블리 언어 또는 기계 언 어 등으로 구현될 수 있다. 또한 컴퓨터 프로그램은 유형의 컴퓨터 판독가능 기록매체(예를 들어, 메모리, 하드 디스크, 자기/광학 매체 또는 SSD(Solid-State Drive) 등)에 기록될 수 있다. 따라서 도 2 내지 도 3 을 통해 설명된 실시예에 따른 응답생성방법은 상술한 바와 같은 컴퓨터 프로그램이 컴 퓨팅장치에 의해 실행됨으로써 구현될 수 있다. 컴퓨팅장치는 프로세서와, 메모리와, 저장 장치와, 메모리 및 고속 확장포트에 접속하고 있는 고속 인터페이스와, 저속 버스와 저장 장치에 접속하고 있는 저속 인터페이스 중 적어도 일부를 포함할 수 있다. 이러한 성분들 각각은 다양한 버스를 이용하여 서로 접속되어 있으며, 공통 머더보드에 탑재되거나 다른 적절한 방식으로 장착될 수 있다. 여기서 프로세서는 컴퓨팅장치 내에서 명령어를 처리할 수 있는데, 이런 명령어로는, 예컨대 고속 인터페이스에 접속된 디스플레이처럼 외부 입력, 출력 장치상에 GUI(Graphic User Interface)를 제공하기 위한 그래픽 정보를 표시하기 위해 메모리나 저장 장치에 저장된 명령어를 들 수 있다. 다른 실시예로서, 다수의 프로세서 및(또는) 다수의 버스가 적절히 다수의 메모리 및 메모리 형태와 함께 이용될 수 있다. 또한 프로세서는 독립적인 다수의 아날로그 및(또는) 디지털 프로세서를 포함하는 칩들이 이루는 칩셋으로 구현될 수 있다. 또한 메모리는 컴퓨팅장치 내에서 정보를 저장한다. 일례로, 메모리는 휘발성 메모리 유닛 또는 그들의 집합으 로 구성될 수 있다. 다른 예로, 메모리는 비휘발성 메모리 유닛 또는 그들의 집합으로 구성될 수 있다. 또한 메모리는 예컨대, 자기 혹은 광 디스크와 같이 다른 형태의 컴퓨터 판독 가능한 매체일 수도 있다. 그리고 저장장치는 컴퓨팅장치에게 대용량의 저장공간을 제공할 수 있다. 저장 장치는 컴퓨터 판독 가능한 매 체이거나 이런 매체를 포함하는 구성일 수 있으며, 예를 들어 SAN(Storage Area Network) 내의 장치들이나 다른 구성도 포함할 수 있고, 플로피 디스크 장치, 하드 디스크 장치, 광 디스크 장치, 혹은 테이프 장치, 플래시 메 모리, 그와 유사한 다른 반도체 메모리 장치 혹은 장치 어레이일 수 있다."}
{"patent_id": "10-2019-0035593", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "상술된 실시예들은 예시를 위한 것이며, 상술된 실시예들이 속하는 기술분야의 통상의 지식을 가진 자는 상술된 실시예들이 갖는 기술적 사상이나 필수적인 특징을 변경하지 않고서 다른 구체적인 형태로 쉽게 변형이 가능하 다는 것을 이해할 수 있을 것이다. 그러므로 상술된 실시예들은 모든 면에서 예시적인 것이며 한정적이 아닌 것으로 이해해야만 한다. 예를 들어, 단일형으로 설명되어 있는 각 구성 요소는 분산되어 실시될 수도 있으며, 마 찬가지로 분산된 것으로 설명되어 있는 구성 요소들도 결합된 형태로 실시될 수 있다. 본 명세서를 통해 보호 받고자 하는 범위는 상기 상세한 설명보다는 후술하는 특허청구범위에 의하여 나타내어 지며, 특허청구범위의 의미 및 범위 그리고 그 균등 개념으로부터 도출되는 모든 변경 또는 변형된 형태를 포함 하는 것으로 해석되어야 한다."}
{"patent_id": "10-2019-0035593", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1 는 일 실시예에 따른 응답생성장치를 도시한 블록도이다. 도 2 내지 도 3 은 일 실시예에 따른 응답생성방법을 설명하기 위한 순서도이다."}
