{"patent_id": "10-2020-0127386", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2022-0043694", "출원번호": "10-2020-0127386", "발명의 명칭": "영상을 처리하는 디바이스 및 그 동작 방법", "출원인": "삼성전자주식회사", "발명자": "김동찬"}}
{"patent_id": "10-2020-0127386", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "디바이스(device)가 영상을 처리(processing)하는 방법에 있어서, 영상으로부터 타겟 객체를 검출하기 위한 특징 맵(feature map)을 획득하는 단계; 상기 영상 및 상기 특징 맵을 기 학습된(pre-trained) 모델 파라미터로 구성된 심층 신경망 모델(Deep NeuralNetwork)에 입력함으로써, 상기 영상으로부터 타겟 객체를 정상적으로 인식하기 위한 압축률을 출력하는 단계;및 상기 출력된 압축률을 이용하여 상기 영상을 압축하고 부호화함으로써, 비트스트림(bitstream)을 생성하는단계; 를 포함하는, 방법."}
{"patent_id": "10-2020-0127386", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1 항에 있어서, 기획득된 복수의 원본 영상, 상기 복수의 원본 영상으로부터 추출된 복수의 특징 맵 및 상기 복수의 원본 영상각각으로부터 타겟 객체가 정상적으로 인식되는 최적의 압축률 값을 포함하는 학습 데이터를 생성하는 단계; 를 더 포함하는, 방법."}
{"patent_id": "10-2020-0127386", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2 항에 있어서, 상기 심층 신경망 모델은, 상기 복수의 원본 영상 및 상기 복수의 특징 맵을 입력으로 적용하고, 상기 최적의압축률 값을 정답값(groundtruth)으로 적용하는 학습(training)을 수행함으로써 획득되는 모델 파라미터로 구성되는, 방법."}
{"patent_id": "10-2020-0127386", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제2 항에 있어서, 상기 학습 데이터를 생성하는 단계는, 기획득된 원본 영상을 기 설정된 압축률로 압축하고, 부호화 및 복호화함으로써 복원 영상을 생성하는 단계;상기 원본 영상으로부터 타겟 객체(target object)를 검출(detect)하고, 상기 검출된 타겟 객체로부터 제1 특징벡터(feature vector)를 추출(extract)하는 단계;상기 복원 영상으로부터 상기 타겟 객체를 검출하고, 상기 검출된 타겟 객체로부터 제2 특징 벡터를 추출하는단계; 및상기 원본 영상으로부터 검출된 타겟 객체를 포함하는 제1 관심 영역과 상기 복원 영상으로부터 검출된 타겟 객체를 포함하는 제2 관심 영역 간의 중첩도 및 상기 제1 특징 벡터와 상기 제2 특징 벡터 간의 유사도에 기초하여, 상기 원본 영상으로부터 상기 타겟 객체를 정상적으로 인식하기 위한 최적의 압축률 값을 결정하는 단계; 공개특허 10-2022-0043694-3-를 포함하는, 방법."}
{"patent_id": "10-2020-0127386", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4 항에 있어서, 상기 최적의 압축률 값을 결정하는 단계는,상기 제1 관심 영역과 상기 제2 관심 영역 간의 중첩도를 산출하는 단계;상기 제1 특징 벡터와 상기 제2 특징 벡터 간의 유사도를 산출하는 단계; 및상기 산출된 중첩도를 기설정된 제1 임계치와 비교하고, 상기 산출된 유사도를 기설정된 제2 임계치와 비교하는단계; 를 포함하는, 방법."}
{"patent_id": "10-2020-0127386", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5 항에 있어서, 상기 최적의 압축률을 결정하는 단계는, 비교 결과, 상기 중첩도가 상기 제1 임계치 이하이거나, 또는 상기 유사도가 상기 제2 임계치 이하인 경우, 상기 압축률을 상기 기설정된 압축률 보다 낮은 값으로 변경하는 단계;를 포함하는, 방법."}
{"patent_id": "10-2020-0127386", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제5 항에 있어서, 상기 최적의 압축률 값을 결정하는 단계는, 상기 산출된 중첩도가 상기 제1 임계치를 초과하고, 상기 산출된 유사도가 상기 제2 임계치를 초과하는 경우,상기 복원 영상을 생성하는데 이용된 상기 압축률을 최종 압축률로 결정하는 단계;를 포함하는, 방법."}
{"patent_id": "10-2020-0127386", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제4 항에 있어서, 상기 학습 데이터를 생성하는 단계를 상기 복수의 원본 영상에 대하여 수행함으로써, 상기 복수의 타겟 맵 및상기 복수의 최소 압축률 값에 관한 정보를 획득하는 단계; 및 상기 복수의 원본 영상, 상기 복수의 타겟 맵, 및 상기 복수의 최소 압축률 값에 관한 정보를 데이터베이스에저장하는 단계;를 더 포함하는, 방법."}
{"patent_id": "10-2020-0127386", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1 항에 있어서, 상기 심층 신경망 모델의 출력으로부터 획득된 압축률 정보를, 상기 디바이스와 연결되는 네트워크의 대역폭 정보에 기초하여 결정된 제1 압축률 값 및 인코딩 모듈에 의해 기 설정된 초기 압축률인 제2 압축률 값과 비교하공개특허 10-2022-0043694-4-는 단계; 및비교 결과에 기초하여, 상기 영상으로부터 상기 타겟 객체를 정상적으로 인식하기 위한 최종 압축률 값을 결정하는 단계; 를 더 포함하고, 상기 비트스트림을 생성하는 단계는, 상기 결정된 최종 압축률 값에 기초하여 상기 영상을 압축하고 부호화함으로써 상기 비트스트림을 생성하는, 방법."}
{"patent_id": "10-2020-0127386", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9 항에 있어서, 상기 최종 압축률 값을 결정하는 단계는, 상기 획득된 압축률 값이 상기 제2 압축률 값 보다 작고, 상기 제1 압축률 값이 상기 제2 압축률 값 보다 큰 경우, 상기 영상에 포함되는 복수의 CTU(Coding Tree Unit) 중 상기 타겟 객체가 검출되지 않은 적어도 하나의CTU의 압축률을 조절하는(adjust) 단계;를 포함하는, 방법."}
{"patent_id": "10-2020-0127386", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "영상을 처리하는 디바이스에 있어서, 적어도 하나의 카메라; 서버 또는 타 디바이스와 유무선으로 연결되고, 데이터 통신을 수행하는 통신 인터페이스; 하나 이상의 명령어들(instructions)을 포함하는 프로그램을 저장하는 메모리; 및상기 메모리에 저장된 프로그램의 하나 이상의 명령어들을 실행하는 프로세서; 를 포함하고, 상기 프로세서는,상기 적어도 하나의 카메라 또는 상기 통신 인터페이스를 통해 영상을 입력받고, 상기 입력된 영상으로부터 타겟 객체를 검출하기 위한 특징 맵(feature map)을 획득하고, 상기 영상 및 상기 특징 맵을 기 학습된(pre-trained) 모델 파라미터로 구성된 심층 신경망 모델(Deep NeuralNetwork)에 입력함으로써, 상기 영상으로부터 타겟 객체를 정상적으로 인식하기 위한 압축률을 출력하고, 상기 출력된 압축률을 이용하여 상기 영상을 압축하고 부호화함으로써, 비트스트림(bitstream)을 생성하는, 디바이스."}
{"patent_id": "10-2020-0127386", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11 항에 있어서, 상기 프로세서는, 기획득된 복수의 원본 영상, 상기 복수의 원본 영상으로부터 추출된 복수의 특징 맵 및 상기 복수의 원본 영상각각으로부터 타겟 객체가 정상적으로 인식되는 최적의 압축률 값을 포함하는 학습 데이터를 생성하는, 디바이스. 공개특허 10-2022-0043694-5-청구항 13 제12 항에 있어서, 상기 심층 신경망 모델은, 상기 복수의 원본 영상 및 상기 복수의 특징 맵을 입력으로 적용하고, 상기 최적의압축률 값을 정답값(groundtruth)으로 적용하는 학습(training)을 수행함으로써 획득되는 모델 파라미터로 구성되는, 디바이스."}
{"patent_id": "10-2020-0127386", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제12 항에 있어서, 상기 프로세서는, 기획득된 원본 영상을 기 설정된 압축률로 압축하고, 부호화 및 복호화함으로써 생성된 복원 영상을 생성하고, 상기 원본 영상으로부터 타겟 객체(target object)를 검출(detect)하고, 상기 검출된 타겟 객체로부터 제1 특징벡터(feature vector)를 추출(extract)하고, 상기 복원 영상으로부터 상기 타겟 객체를 검출하고, 상기 검출된 타겟 객체로부터 제2 특징 벡터를 추출하고,상기 원본 영상으로부터 검출된 타겟 객체를 포함하는 제1 관심 영역과 상기 복원 영상으로부터 검출된 타겟 객체를 포함하는 제2 관심 영역 간의 중첩도 및 상기 제1 특징 벡터와 상기 제2 특징 벡터 간의 유사도에 기초하여, 상기 원본 영상으로부터 상기 타겟 객체를 정상적으로 인식하기 위한 최적의 압축률 값을 결정하는, 디바이스."}
{"patent_id": "10-2020-0127386", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제14 항에 있어서, 상기 프로세서는,상기 제1 관심 영역과 상기 제2 관심 영역 간의 중첩도를 산출하고,상기 제1 특징 벡터와 상기 제2 특징 벡터 간의 유사도를 산출하고,상기 산출된 중첩도를 기설정된 제1 임계치와 비교하고, 상기 산출된 유사도를 기설정된 제2 임계치와비교하는, 디바이스."}
{"patent_id": "10-2020-0127386", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제15 항에 있어서, 상기 프로세서는, 비교 결과, 상기 중첩도가 상기 제1 임계치 이하이거나, 또는 상기 유사도가 상기 제2 임계치 이하인 경우, 상기 압축률을 상기 기설정된 압축률 보다 낮은 값으로 변경하는, 디바이스."}
{"patent_id": "10-2020-0127386", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제15 항에 있어서, 상기 프로세서는, 상기 산출된 중첩도가 상기 제1 임계치를 초과하고, 상기 산출된 유사도가 상기 제2 임계치를 초과하는 경우,상기 복원 영상을 생성하는데 이용된 상기 압축률을 최종 압축률로 결정하는, 디바이스. 공개특허 10-2022-0043694-6-청구항 18 제11 항에 있어서, 상기 프로세서는, 상기 심층 신경망 모델의 출력으로부터 획득된 압축률 정보를, 상기 디바이스와 연결되는 네트워크의 대역폭 정보에 기초하여 결정된 제1 압축률 값 및 인코딩 모듈에 의해 기 설정된 초기 압축률인 제2 압축률 값과 비교하고, 비교 결과에 기초하여, 상기 영상으로부터 상기 타겟 객체를 정상적으로 인식하기 위한 최종 압축률 값을 결정하는, 디바이스."}
{"patent_id": "10-2020-0127386", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제18 항에 있어서, 상기 프로세서는, 상기 획득된 압축률 값이 상기 제2 압축률 값 보다 작고, 상기 제1 압축률 값이 상기 제2 압축률 값 보다 큰 경우, 상기 영상에 포함되는 복수의 CTU(Coding Tree Unit) 중 상기 타겟 객체가 검출되지 않은 적어도 하나의CTU의 압축률을 조절하는(adjust), 디바이스."}
{"patent_id": "10-2020-0127386", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제1 항의 방법을 컴퓨터에서 실행시키기 위한 프로그램을 기록한 컴퓨터로 읽을 수 있는 기록매체."}
{"patent_id": "10-2020-0127386", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "심층 신경망 모델(Deep Neural Network)을 이용하여 영상으로부터 타겟 객체를 인식하기 위한 압축률 정보를 획 득하고, 압축률 정보를 이용하여 영상을 압축하고 부호화하는 디바이스 및 그 동작 방법을 개시한다. 본 개시의 일 실시예는 적어도 하나의 카메라 또는 통신 인터페이스를 통해 영상을 입력받고, 입력된 영상으로부터 타겟 객체를 검출하기 위한 특징 맵(feature map)을 획득하고, 영상 및 특징 맵을 기 학습된(pre-trained) 모델 파라 미터로 구성된 심층 신경망 모델에 입력함으로써, 영상으로부터 타겟 객체를 정상적으로 인식하기 위한 압축률을 출력하고, 압축률을 이용하여 영상을 압축하고 부호화함으로써, 비트스트림(bitstream)을 생성하는 디바이스를 제공한다."}
{"patent_id": "10-2020-0127386", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 영상을 처리하는 디바이스 및 그 동작 방법에 관한 것이다. 보다 구체적으로는, 카메라를 이용하여 촬영되거나 또는 네트워크를 통해 획득한 영상으로부터 타겟 객체를 인식하기 위한 영상 처리를 수행하는 디바 이스에 관한 것이다."}
{"patent_id": "10-2020-0127386", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "일반적인 디바이스에서는, 저장 용량의 한계 또는 네트워크 대역폭의 제한 조건으로 인하여 영상 데이터를 전송 하거나, 저장하는 경우 표준 압축 기술(예를 들어, H.264/AVC, HEVC(H.265), 또는 JPEG)을 이용하여 압축하여 전송 또는 저장한다. 이 때 이로 손실 압축하여 전송/저장 한다. 이 경우, 압축률을 과도하게 높게 설정하여 인 코딩을 하는 경우 영상이 열화(degrading)되어 인식하여야 하는 사람의 얼굴, 헤어 스타일, 옷 차림, 등을 인식 할 수 없게 되는 문제점이 있다. 또한, 제한적인 네트워크 대역폭, 네트워크의 불안정성으로 인한 데이터 패킷 (packet) 손실, 인코딩 단계에서의 오류, 또는 UDP 환경에서 데이터 패킷 손실 등 예외 상황에서 디코딩된 영상 프레임이 열화되고, 열화된 영상 프레임으로부터 사람의 얼굴 등을 인식할 수 없는 문제점이 있다. 열화된 영상 프레임으로부터 사람의 얼굴을 정확하게 인식하지 못하는 경우, 다른 사람으로 오 인식되고, 비(非) 인가자를 추적하기 어려운 문제가 발생된다. 압축률을 낮게 설정하는 경우, 영상 데이터의 저장 용량 낭비가 심해지거나, 네트워크 전송이 지연되어 실시간 감시 등이 불가능해지는 문제점이 있다. 따라서, 영상으로부터 타겟 객체를 정확하게 인식하면서도 저장 용량의 한계 및 네트워크 대역폭의 제한 조건에 적합한 최적화된 압축률을 결정할 필요가 있다."}
{"patent_id": "10-2020-0127386", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 2, "content": "발명의 내용"}
{"patent_id": "10-2020-0127386", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 개시는 카메라를 이용한 촬영을 통해 획득하거나, 또는 네트워크를 통해 획득한 영상을 처리하는 디바이스 및 그 동작 방법에 관한 것으로서, 구체적으로는 기 학습된(pre-trained) 심층 신경망 모델을 이용하여 영상으 로부터 타겟 객체를 정상적으로 인식하기 위한 압축률을 획득하고, 획득된 압축률을 이용하여 영상을 압축하고 부호화하는 디바이스 및 그 동작 방법을 제공하는 것을 목적으로 한다."}
{"patent_id": "10-2020-0127386", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상술한 기술적 과제를 해결하기 위하여, 본 개시의 일 실시예는 디바이스(device)가 영상을 처리하는 방법을 제 공한다. 본 개시의 일 실시예에 따른 방법은, 영상으로부터 타겟 객체를 검출하기 위한 특징 맵(feature map)을 획득하는 단계, 상기 영상 및 상기 특징 맵을 기 학습된(pre-trained) 모델 파라미터로 구성된 심층 신경망 모 델(Deep Neural Network)에 입력함으로써, 상기 영상으로부터 타겟 객체를 정상적으로 인식하기 위한 압축률을 출력하는 단계, 및 상기 출력된 압축률을 이용하여 상기 영상을 압축하고 부호화함으로써, 비트스트림 (bitstream)을 생성하는 단계를 포함한다. 일 실시 예에서, 상기 방법은 기획득된 복수의 원본 영상, 상기 복수의 원본 영상으로부터 추출된 복수의 특징 맵 및 상기 복수의 원본 영상 각각으로부터 타겟 객체가 정상적으로 인식되는 최적의 압축률 값을 포함하는 학 습 데이터를 생성하는 단계를 더 포함할 수 있다. 일 실시 예에서, 상기 심층 신경망 모델은 상기 복수의 원본 영상 및 상기 복수의 특징 맵을 입력으로 적용하고, 상기 최적의 압축률 값을 정답값(groundtruth)으로 적용하는 학습(training)을 수행함으로써 획득되 는 모델 파라미터로 구성될 수 있다. 일 실시 예에서, 상기 학습 데이터를 생성하는 단계는, 기획득된 원본 영상을 기 설정된 압축률로 압축하고, 부 호화 및 복호화함으로써 복원 영상을 생성하는 단계, 상기 원본 영상으로부터 타겟 객체(target object)를 검출 (detect)하고, 상기 검출된 타겟 객체로부터 제1 특징 벡터(feature vector)를 추출(extract)하는 단계, 상기 복원 영상으로부터 상기 타겟 객체를 검출하고, 상기 검출된 타겟 객체로부터 제2 특징 벡터를 추출하는 단계, 및 상기 원본 영상으로부터 검출된 타겟 객체를 포함하는 제1 관심 영역과 상기 복원 영상으로부터 검출된 타겟 객체를 포함하는 제2 관심 영역 간의 중첩도 및 상기 제1 특징 벡터와 상기 제2 특징 벡터 간의 유사도에 기초 하여, 상기 원본 영상으로부터 상기 타겟 객체를 정상적으로 인식하기 위한 최적의 압축률 값을 결정하는 단계 를 포함할 수 있다. 일 실시 예에서, 상기 최적의 압축률 값을 결정하는 단계는, 상기 제1 관심 영역과 상기 제2 관심 영역 간의 중 첩도를 산출하는 단계, 상기 제1 특징 벡터와 상기 제2 특징 벡터 간의 유사도를 산출하는 단계, 및 상기 산출 된 중첩도를 기설정된 제1 임계치와 비교하고, 상기 산출된 유사도를 기설정된 제2 임계치와 비교하는 단계를 포함할 수 있다. 일 실시 예에서, 상기 최적의 압축률을 결정하는 단계는, 비교 결과, 상기 중첩도가 상기 제1 임계치 이하이거 나, 또는 상기 유사도가 상기 제2 임계치 이하인 경우, 상기 압축률을 상기 기설정된 압축률 보다 낮은 값으로 변경하는 단계를 포함할 수 있다. 일 실시 예에서, 상기 최적의 압축률 값을 결정하는 단계는, 상기 산출된 중첩도가 상기 제1 임계치를 초과하고, 상기 산출된 유사도가 상기 제2 임계치를 초과하는 경우, 상기 복원 영상을 생성하는데 이용된 상기 압축률을 최종 압축률로 결정하는 단계를 포함할 수 있다. 일 실시 예에서, 상기 방법은 학습 데이터를 생성하는 단계를 상기 복수의 원본 영상에 대하여 수행함으로써, 상기 복수의 타겟 맵 및 상기 복수의 최소 압축률 값에 관한 정보를 획득하는 단계 및 상기 복수의 원본 영상, 상기 복수의 타겟 맵, 및 상기 복수의 최소 압축률 값에 관한 정보를 데이터베이스에 저장하는 단계를 더 포함 할 수 있다. 일 실시 예에서, 상기 방법은 상기 심층 신경망 모델의 출력으로부터 획득된 압축률 정보를, 상기 디바이스와 연결되는 네트워크의 대역폭 정보에 기초하여 결정된 제1 압축률 값 및 인코딩 모듈에 의해 기 설정된 초기 압 축률인 제2 압축률 값과 비교하는 단계, 및 비교 결과에 기초하여, 상기 영상으로부터 상기 타겟 객체를 정상적 으로 인식하기 위한 최종 압축률 값을 결정하는 단계를 더 포함하고, 상기 비트스트림을 생성하는 단계는, 상기 결정된 최종 압축률 값에 기초하여 상기 영상을 압축하고 부호화함으로써 상기 비트스트림을 생성할 수 있다. 일 실시 예에서, 상기 최종 압축률 값을 결정하는 단계는, 상기 획득된 압축률 값이 상기 제2 압축률 값 보다 작고, 상기 제1 압축률 값이 상기 제2 압축률 값 보다 큰 경우, 상기 영상에 포함되는 복수의 CTU(Coding Tree Unit) 중 상기 타겟 객체가 검출되지 않은 적어도 하나의 CTU의 압축률을 조절하는(adjust) 단계를 포함할 수 있다. 상술한 기술적 과제를 해결하기 위하여, 본 개시의 일 실시예는 영상을 처리하는 디바이스를 제공한다. 본 개시 의 일 실시예에 따른 디바이스는 적어도 하나의 카메라, 서버 또는 타 디바이스와 유무선으로 연결되고, 데이터 통신을 수행하는 통신 인터페이스, 하나 이상의 명령어들(instructions)을 포함하는 프로그램을 저장하는 메모 리, 및 상기 메모리에 저장된 프로그램의 하나 이상의 명령어들을 실행하는 프로세서를 포함하고, 상기 프로세 서는 상기 적어도 하나의 카메라 또는 상기 통신 인터페이스를 통해 영상을 입력받고, 상기 입력된 영상으로부 터 타겟 객체를 검출하기 위한 특징 맵(feature map)을 획득하고, 상기 영상 및 상기 특징 맵을 기 학습된(pre- trained) 모델 파라미터로 구성된 심층 신경망 모델(Deep Neural Network)에 입력함으로써, 상기 영상으로부터 타겟 객체를 정상적으로 인식하기 위한 압축률을 출력하고, 상기 출력된 압축률을 이용하여 상기 영상을 압축하 고 부호화함으로써, 비트스트림(bitstream)을 생성한다. 일 실시 예에서, 상기 프로세서는 기획득된 복수의 원본 영상, 상기 복수의 원본 영상으로부터 추출된 복수의 특징 맵 및 상기 복수의 원본 영상 각각으로부터 타겟 객체가 정상적으로 인식되는 최적의 압축률 값을 포함하 는 학습 데이터를 생성할 수 있다. 일 실시 예에서, 상기 심층 신경망 모델은 상기 복수의 원본 영상 및 상기 복수의 특징 맵을 입력으로 적용하고, 상기 최적의 압축률 값을 정답값(groundtruth)으로 적용하는 학습(training)을 수행함으로써 획득되 는 모델 파라미터로 구성될 수 있다. 일 실시 예에서, 상기 프로세서는 기획득된 원본 영상을 기 설정된 압축률로 압축하고, 부호화 및 복호화함으로 써 생성된 복원 영상을 생성하고, 상기 원본 영상으로부터 타겟 객체(target object)를 검출(detect)하고, 상기 검출된 타겟 객체로부터 제1 특징 벡터(feature vector)를 추출(extract)하고, 상기 복원 영상으로부터 상기 타 겟 객체를 검출하고, 상기 검출된 타겟 객체로부터 제2 특징 벡터를 추출하고, 상기 원본 영상으로부터 검출된 타겟 객체를 포함하는 제1 관심 영역과 상기 복원 영상으로부터 검출된 타겟 객체를 포함하는 제2 관심 영역 간 의 중첩도 및 상기 제1 특징 벡터와 상기 제2 특징 벡터 간의 유사도에 기초하여, 상기 원본 영상으로부터 상기 타겟 객체를 정상적으로 인식하기 위한 최적의 압축률 값을 결정할 수 있다. 일 실시 예에서, 상기 프로세서는 상기 제1 관심 영역과 상기 제2 관심 영역 간의 중첩도를 산출하고, 상기 제1 특징 벡터와 상기 제2 특징 벡터 간의 유사도를 산출하고, 상기 산출된 중첩도를 기설정된 제1 임계치와 비교하 고, 상기 산출된 유사도를 기설정된 제2 임계치와 비교할 수 있다. 일 실시 예에서, 상기 프로세서는 비교 결과, 상기 중첩도가 상기 제1 임계치 이하이거나, 또는 상기 유사도가 상기 제2 임계치 이하인 경우, 상기 압축률을 상기 기설정된 압축률 보다 낮은 값으로 변경할 수 있다. 일 실시 예에서, 상기 프로세서는 상기 산출된 중첩도가 상기 제1 임계치를 초과하고, 상기 산출된 유사도가 상 기 제2 임계치를 초과하는 경우, 상기 복원 영상을 생성하는데 이용된 상기 압축률을 최종 압축률로 결정할 수 있다. 일 실시 예에서, 상기 프로세서는 상기 심층 신경망 모델의 출력으로부터 획득된 압축률 정보를, 상기 디바이스 와 연결되는 네트워크의 대역폭 정보에 기초하여 결정된 제1 압축률 값 및 인코딩 모듈에 의해 기 설정된 초기 압축률인 제2 압축률 값과 비교하고, 비교 결과에 기초하여, 상기 영상으로부터 상기 타겟 객체를 정상적으로 인식하기 위한 최종 압축률 값을 결정할 수 있다. 일 실시 예에서, 상기 프로세서는 상기 획득된 압축률 값이 상기 제2 압축률 값 보다 작고, 상기 제1 압축률 값 이 상기 제2 압축률 값 보다 큰 경우, 상기 영상에 포함되는 복수의 CTU(Coding Tree Unit) 중 상기 타겟 객체 가 검출되지 않은 적어도 하나의 CTU의 압축률을 조절(adjust)할 수 있다. 상술한 기술적 과제를 해결하기 위하여, 본 개시의 다른 실시예는 컴퓨터에서 실행시키기 위한 프로그램을 기록 한 컴퓨터로 읽을 수 있는 기록매체를 제공한다."}
{"patent_id": "10-2020-0127386", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 명세서의 실시예들에서 사용되는 용어는 본 개시의 기능을 고려하면서 가능한 현재 널리 사용되는 일반적인 용어들을 선택하였으나, 이는 당 분야에 종사하는 기술자의 의도 또는 판례, 새로운 기술의 출현 등에 따라 달 라질 수 있다. 또한, 특정한 경우는 출원인이 임의로 선정한 용어도 있으며, 이 경우 해당되는 실시예의 설명 부분에서 상세히 그 의미를 기재할 것이다. 따라서 본 명세서에서 사용되는 용어는 단순한 용어의 명칭이 아닌, 그 용어가 가지는 의미와 본 개시의 전반에 걸친 내용을 토대로 정의되어야 한다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함할 수 있다. 기술적이거나 과학적인 용어를 포함해서 여기서 사용되는 용어들은 본 명세서에 기재된 기술 분야에서 통상의 지식을 가진 자에 의해 일반적으로 이해되는 것과 동일한 의미를 가질 수 있다. 본 개시 전체에서 어떤 부분이 어떤 구성요소를 \"포함\"한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다 른 구성요소를 제외하는 것이 아니라 다른 구성요소를 더 포함할 수 있음을 의미한다. 또한, 본 명세서에 기재 된 \"...부\", \"...모듈\" 등의 용어는 적어도 하나의 기능이나 동작을 처리하는 단위를 의미하며, 이는 하드웨어 또는 소프트웨어로 구현되거나 하드웨어와 소프트웨어의 결합으로 구현될 수 있다. 본 명세서에서 사용된 표현 \"~하도록 구성된(또는 설정된)(configured to)\"은 상황에 따라, 예를 들면, \"~에 적 합한(suitable for)\", \"~하는 능력을 가지는(having the capacity to)\", \"~하도록 설계된(designed to)\", \"~하 도록 변경된(adapted to)\", \"~하도록 만들어진(made to)\", 또는 \"~를 할 수 있는(capable of)\"과 바꾸어 사용 될 수 있다. 용어 \"~하도록 구성된(또는 설정된)\"은 하드웨어적으로 \"특별히 설계된(specifically designed to)\" 것만을 반드시 의미하지 않을 수 있다. 대신, 어떤 상황에서는, \"~하도록 구성된 시스템\"이라는 표현은, 그 시스템이 다른 장치 또는 부품들과 함께 \"~할 수 있는\" 것을 의미할 수 있다. 예를 들면, 문구 \"A, B, 및 C 를 수행하도록 구성된(또는 설정된) 프로세서\"는 해당 동작을 수행하기 위한 전용 프로세서(예: 임베디드 프로 세서), 또는 메모리에 저장된 하나 이상의 소프트웨어 프로그램들을 실행함으로써, 해당 동작들을 수행할 수 있 는 범용 프로세서(generic-purpose processor)(예: CPU 또는 application processor)를 의미할 수 있다. 본 개시에서 '영상'은 단일 이미지 또는 적어도 하나의 프레임을 포함하는 동영상(video)를 의미한다. 예를 들 어, 영상은 카메라를 통한 촬영을 통해 획득하거나, 네트워크를 통해 획득될 수 있다. 본 개시에서 '원본 영상(Raw image)'은 카메라를 통해 촬영되거나 또는 네트워크를 통해 획득한 영상을 압축하 지 않은 비압축 영상 데이터이다. 본 개시에서 '압축률'은 표준 규격에 매칭되는 방법을 이용하여 원본 영상을 압축하기 위한 영상 압축 파라미터 를 나타낸다. 압축률은 표준 규격 마다 다양한 형태로 존재할 수 있다. 예를 들어, 정적 영상을 압축하는 표준 규격(예를 들어, JPEG(Joint Photographic Coding Experts Group), JPEG-2000, JPEG- XR, WebP 등)에서는 영상 의 압축률을 결정하기 위하여 양자화 테이블(Quantization Table)이 이용될 수 있다. 다른 예를 들어, 동적 영 상을 재생하기 위한 표준 규격(예를 들어, H. 264/AVC, HEVC(H.265) 등)에서는 양자화 파라미터(Quantization Parameter)에 기초하여 영상의 압축률이 결정될 수 있다. 본 개시에서 '양자화 파라미터'는 동적 영상의 압축과 관련된 표준 규격(예를 들어 H.264/AVC, 또는 HEVC(H.265))에서 정의되는 변환 계수를 양자화하는 정도를 나타내는 파라미터로서, 양자화 파라미터에 의해 영 상의 압축률이 결정될 수 있다. 일 실시예에서, 압축률은 양자화 파라미터의 값에 비례한다. 예를 들어, 양자화 파라미터의 값이 큰 경우, 압축률이 높고, 양자화 파라미터의 값이 작은 경우, 압축률이 낮다. 본 개시에서, '변환 계수(transform coefficient)'는 복수의 영상 프레임에서 공간적 상관 관계를 이용하는 인 트라(intra) 예측 또는 시간적 상관 관계를 이용하는 인터(inter) 예측을 통해 형성된 예측 영상 프레임(I- frame)과 원 영상의 차이값인 잔차 데이터(residual date)가 다양한 변환 기법을 이용하여 변환 영역(transform domain)으로 변환된 계수를 의미한다. H. 264/AVC에서 변환 계수가 변환되는 방법은, 예를 들어, 이산 코사인 변환(Discrete Cosine Transform, DCT), 하다마드 변환(Hadamard Transform) 등이 사용될 수 있다. 도 1은 본 개시의 일 실시예에 따른 디바이스에 의해 수행되는 영상 처리 동작들을 설명하기 위한 개념도이다. 도 1을 참조하면, 영상 처리 단계는 심층 신경망 모델을 이용하는 학습 단계(S100) 및 심층 신경망 모델 적용하여 압축률을 획득하는 단계(S200)를 포함할 수 있다. 심층 신경망 모델 학습 단계(S100)는 원본 영상(io)으로부터 학습 데이터를 생성하는 단계, 생성된 학습 데이터 를 학습 데이터 저장부에 저장하는 단계, 학습 데이터를 이용하여 심층 신경망 모델을 학습 (training)하는 단계 및 학습을 통해 획득된 심층 신경망 모델의 모델 파라미터를 모델 파라미터 저장부 에 저장하는 단계를 포함할 수 있다. 학습 데이터 생성 모듈은 원본 영상(io)을 입력받고, 원본 영상(io)으로부터 타겟 객체를 포함하는 관심 영역 이미지(io-R), 원본 영상(io)으로부터 타겟 객체를 검출하기 위한 특징 맵(if1, if2), 및 원본 영상(io)으로 부터 타겟 객체를 정상적으로 인식하기 위한 최적의 압축률 값(QP)을 출력하도록 구성될 수 있다. 여기서, '타 겟 객체(target object)'는 사용자가 영상으로부터 검출하고자 하는 관심있는 객체를 의미한다. 타겟 객체는 예 를 들어, 사람의 얼굴, 헤어, 옷, 및 포즈(posture) 중 적어도 하나를 포함할 수 있다. 특징 맵(if1, if2)은 원본 영상(io)으로부터 타겟 객체를 검출하기 위하여 추출되는 특징 벡터를 포함하는 이미지 이다. 특징 맵(if1, if2)은 하나 또는 복수 개일 수 있다. 특징 맵은 예를 들어, 엣지 맵(edge map), 블러 이미 지(blur image), 또는 원형 맵 중 적어도 하나를 포함할 수 있다. 특징 맵(if1, if2)은 공지의 이미지 처리 기술 (image processing) 또는 딥 러닝(Deep Learning) 기반의 신경망 모델(neural network)을 이용하는 학습을 통 해 획득될 수 있다. 일 실시예에서, 컨볼루션 신경망 모델을 이용하는 경우, 디바이스는 원본 영상(io)을 기설 정된 크기 및 채널(channel) 수를 갖는 필터(filter)를 통해 합성 곱(convolution)을 산출하고, 합성 곱을 통해 필터의 개수와 동일한 2차원 이미지 레이어(layer)를 추출하고, 2D 이미지 레이어로 구성된 특징 맵(if1, if2)을 획득할 수 있다. 학습 데이터 생성 모듈은 원본 영상(io) 및 원본 영상(io)을 기설정된 압축률로 압축하고, 부호화 및 복호 화함으로써 생성된 복원 영상으로부터 타겟 객체를 정상적으로 인식할 수 있는 최적의 압축률 값(QP)을 결정할 수 있다. '타겟 객체를 정상적으로 인식할 수 있는 최적의 압축률'은 타겟 객체의 인식 오류율(error rate)을 기 설정된 오류율 미만으로 유지할 수 있는 최소의 압축률 값을 의미한다. 일 실시예에서, 학습 데이터 생성 모 듈은 원본 영상(io) 및 복원 영상 각각으로부터 타겟 객체를 검출하고, 검출된 타겟 객체로부터 특징 벡 터를 추출하며, 원본 영상(io)으로부터 검출된 타겟 객체를 포함하는 제1 관심 영역과 복원 영상으로부터 검출된 타겟 객체를 포함하는 제2 관심 영역 간의 중첩도 및 원본 영상(io)으로부터 추출된 제1 특징 벡터와 복원 영상 으로부터 추출된 제2 특징 벡터 간의 유사도 정보를 이용하여, 원본 영상(io)으로부터 타겟 객체를 정상적으로 인식할 수 있는 최적의 압축률 값(QP)을 결정할 수 있다. 여기서, '압축률'은 원본 영상(io)을 표준 규격에 매칭되는 방법을 이용하여 인코딩하기 위한 영상 압축 파라미 터를 의미한다. 압축률은 표준 규격 마다 다양한 형태로 존재할 수 있다. 예를 들어, 정적 영상을 압축하는 표 준 규격(예를 들어, JPEG(Joint Photographic Coding Experts Group), JPEG-2000, JPEG- XR, WebP 등)에서는 영상의 압축 정도를 결정하기 위하여 양자화 테이블(Quantization Table)이 이용될 수 있다. 다른 예를 들어, 동적 영상을 재생하기 위한 표준 규격(예를 들어, H. 264/AVC, HEVC(H.265) 등)에서는 양자화 파라미터 (Quantization Parameter)에 기초하여 영상의 압축률이 결정될 수 있다. '양자화 파라미터'는 정적 영상의 압축과 관련된 표준 규격(예를 들어, JPEG) 또는 동적 영상의 압축과 관련된 표준 규격(예를 들어 H.264/AVC, 또는 HEVC(H.265))에서 정의되는 변환 계수를 양자화하는 정도를 나타내는 파 라미터로서, 양자화 파라미터에 의해 영상의 압축률이 결정될 수 있다. 일 실시예에서, 압축률은 양자화 파라미 터의 값에 비례한다. 예를 들어, 양자화 파라미터의 값이 큰 경우, 압축률이 높고, 양자화 파라미터의 값이 작 은 경우, 압축률이 낮다. '타겟 객체를 정상적으로 인식할 수 있는 최적의 압축률'은 타겟 객체의 검출 과정에서 오류 율(error rate)을 기 설정된 임계치 미만으로 발생시키기 위한 최적의 압축률 값을 의미한다. 도 1에 도시된 실시예에서, 원본 영 상(io)으로부터 타겟 객체를 정상적으로 인식하기 위한 압축률(QP)의 값은 36일 수 있다. 일 실시예에서, 학습 데이터 생성 모듈은 타겟 객체 검출 모듈(1321, 도 2 참조), 특징 벡터 추출 모듈 (1322, 도 2 참조), 중첩도 산출 모듈(1323, 도 2 참조), 유사도 산출 모듈(1324, 도 2 참조), 인식 결과 판단 모듈(1325, 도 2 참조), 및 압축률 조절 모듈(1326, 도 2 참조)을 포함할 수 있다. 학습 데이터 생성 모듈 이 원본 영상(io)으로부터 타겟 객체를 정상적으로 인식할 수 있는 최적의 압축률 값을 결정하는 구체적 인 실시예에 대해서는, 도 2에서 상세하게 설명하기로 한다. 학습 데이터 생성 모듈은 전술한 동작들을 기 획득된 복수의 원본 영상(io-1 내지 io-n)에 대하여 각각 수 행함으로써, 복수의 원본 영상(io-1 내지 io-n) 각각으로부터 타겟 객체를 정상적으로 인식하기 위한 압축률 값 (QP1 내지 QPn)을 결정할 수 있다. 일 실시예에서, 복수의 원본 영상(io-1 내지 io-n)은 타겟 객체를 포함하는 관 심 영역 이미지일 수 있다. 복수의 원본 영상(io-1 내지 io-n)과 학습 데이터 생성 모듈에 의해 획득된 복 수의 특징 맵(if-1 내지 if-n) 및 복수의 압축률 값(QP1 내지 QPn)은 학습 데이터 저장부에 저장될 수 있다. 일 실시예에서, 복수의 원본 영상(io-1 내지 io-n), 복수의 특징 맵(if-1 내지 if-n) 및 복수의 압축률 값(QP1 내지 QPn)은 키(key)-밸류(value) 타입으로 학습 데이터 저장부에 저장될 수 있다. 즉, 복수의 원본 영상(io-1 내지 io-n), 복수의 특징 맵(if-1 내지 if-n) 및 복수의 압축률 값(QP1 내지 QPn)은 관련되는 정보들끼리 쌍(pair) 을 형성하여 학습 데이터 저장부에 저장될 수 있다. 예를 들어, 제1 원본 영상(io-1) 및 제1 원본 영상(io- 1)으로부터 추출된 제1 특징 맵(if-1)은 키로서, 제1 원본 영상(io-1)로부터 결정된 제1 압축률 값(QP1)은 밸류로 서 페어링(pairing)되어 학습 데이터 저장부에 저장될 수 있다. 마찬가지로, 제2 원본 영상(io-2) 및 제2 원본 영상(io-2)으로부터 추출된 제2 특징 맵(if-2)은 키로서, 제2 원본 영상(io-2)로부터 결정된 제2 압축률 값 (QP2)은 밸류로서, 페어링(pairing)되어 학습 데이터 저장부에 저장될 수 있다. 심층 신경망 모델은 학습 데이터 저장부로부터 제공받은 학습 데이터를 이용하는 학습(training)을 수행하도록 구성되는 인공지능 모델이다. 일 실시예에서, 심층 신경망 모델은 학습 데이터 저장부 에 기 저장된 복수의 원본 영상(io-1 내지 io-n) 및 복수의 특징 맵(if-1 내지 if-n)을 입력으로 적용하고, 복수의 압축률 값(QP1 내지 QPn)에 관한 라벨(label)을 정답값(groundtruth)로 적용하는 지도 학습(supervised learning)을 수행할 수 있다. 일 실시예에서, 심층 신경망 모델은 연산을 수행하는 내부의 레이어(laye r)인 복수의 은닉 레이어(hidden layer)를 포함할 수 있다. 심층 신경망 모델은 예를 들어, 컨볼루션 신 경망 모델(Convolutional Neural Network; CNN), 순환 신경망 모델(Recurrent Neural Network; RNN), 제한 볼 츠만 머신(Restricted Boltzmann Machine; RBM), DBN(Deep Belief Network), BRDNN(Bidirectional Recurrent Deep Neural Network) 및 심층 Q-네트워크 (Deep Q-Networks) 중 적어도 하나를 포함할 수 있다. 그러나, 심층 신경망 모델이 전술한 예시로 한정되는 것은 아니고, 공지의 모든 딥 러닝(Deep Learning) 기반의 신경망 모델을 포함할 수 있다. 심층 신경망 모델이 컨볼루션 신경망 모델(CNN)로 구현되는 경우, 학습 단계(단계 S100)에서 기설정된 크 기 및 기설정된 채널 수를 갖는 필터(filter)을 이용하여 입력으로 적용된 복수의 원본 영상(io-1 내지 io-n)을 이동함(stride)으로써 특징 값들을 추출하고, 추출된 특징 값들을 포함하는 복수 개의 레이어(layer)를 획득하 며, 복수 개의 레이어에 가중치(weight)를 적용함으로써 특징 벡터 맵(feature vector map)을 획득할 수 있다. 상기 특징 벡터 맵을 획득하는 과정에서 정류 선형 유닛(ReLU) 모델이 이용되고, 효율을 향상시키기 위하여 드 롭 아웃(drop out)을 통해 학습 모델을 정칙화(regularization)하고, 풀링(pooling) 또는 맥스 풀링(max pooling)을 수행하는 동작들이 더 추가될 수 있다. 이어서, 풀링 또는 맥스 풀링을 통해 획득된 특징값들은 fully connected layer를 통해 통합되고, 소프트맥스(softmax), 시그모이드(sigmoid), 하이퍼볼릭 탄젠트 (hyperbolic tangent)를 포함하는 활성 함수(activation function)를 통해 압축률 값과 관련된 라벨을 출력하 도록 학습될 수 있다. 심층 신경망 모델은 학습을 통해, 모델 파라미터를 획득할 수 있다. 일 실시예에서, 심층 신경망 모델 이 컨볼루션 신경망 모델(CNN)로 구현되는 경우, 심층 신경망 모델은 지도 학습을 통해 복수의 레 이어 간 가중치(weight)(1420w) 및 편향(bias)(1420b)을 포함하는 모델 파라미터를 획득할 수 있다. 여기서, ' 가중치(1420w)'와 '편향(1420b)'은 입력 데이터(복수의 원본 영상 및 복수의 특징 맵)로부터 출력 라벨(압축률 값)을 추론하기 위한 매개 변수로서, 학습이 수행됨에 따라 값이 조정(adjust)될 수 있다. 심층 신경망 모델 의 학습을 통해 획득된 가중치(1420w) 및 편향(1420b)은 모델 파라미터 저장부에 저장될 수 있다. 심층 신경망 모델 이용하여 압축률 획득 단계(S200)에서, 디바이스는 카메라 또는 네트워크를 통해 영상 (i)을 입력받는 단계, 심층 신경망 모델을 이용하여 영상(i)으로부터 압축률을 출력하는 단계, 및 출력된 압축률을 이용하여 영상(i)을 압축하고 부호화함으로써 비트스트림을 생성하는 단계를 포함할 수 있다. 영상(i)은 전처리 모듈에 입력되고, 전처리 모듈은 입력된 영상(i)에 대하여 전처리(pre- processing)를 수행한다. 전처리 모듈은 입력된 영상(i)의 크기를 기 설정된 크기로 조절(resize)하고, 영상(i)의 밝기 및 대조도(contrast)를 정규화(normalize)하도록 구성될 수 있다. 전처리 모듈을 통해 전 처리가 완료된 영상은 타겟 객체 검출 모듈로 입력될 수 있다. 타겟 객체 검출 모듈은 영상으로부터 타겟 객체를 검출하도록 구성되는 모듈이다. 일 실시예에서, 타겟 객체 검출 모듈은 딥 러닝(Deep Learning)을 포함하는 인공 지능 모델을 이용하여 영상(i)으로부터 타겟 객체를 검출하도록 구성될 수 있다. 일 실시예에서, 타겟 객체 검출 모듈은 컨볼루션 신경망 모델(CNN)을 이용하여 학습을 수행함으로써 영상(i)으로부터 타겟 객체를 검출할 수 있다. 예를 들어, 타겟 객체가 얼굴인 경우, 타겟 객체 검출 모듈은 대규모의 데이터 셋, 예를 들어 CASIA-WebFace, VGGFace/VGGFace 2, 또는 MS-Celeb-1M을 통해 동적 영상으로부터 사람의 얼굴을 검출할 수 있다. 일 실시예에서, 타겟 객체 검출 모듈 은 VGGFace2 데이터 셋을 이용하여 얼굴 인식을 수행하도록 기 학습된 MobileNet을 포함할 수 있다. 타겟 객체 검출 모듈은 영상(i)으로부터 타겟 객체를 검출하는 과정에서 특징 맵(if)을 출력할 수 있다. '특징 맵(if)'은 영상(i)으로부터 타겟 객체를 검출하기 위하여 추출되는 특징 벡터를 포함하는 이미지로서, 예 를 들어, 엣지 맵(edge map), 블러 이미지(blur image), 또는 원형 맵 중 적어도 하나를 포함할 수 있다. 심층 신경망 모델은, 카메라 또는 네트워크를 통해 획득된 영상(i) 및 영상(i)으로부터 추출된 특징 맵 (if)을 입력으로 적용하는 학습(training)을 수행함으로써, 영상(i)으로부터 타겟 객체를 정상적으로 인식할 수 있는 압축률을 출력할 수 있다. 심층 신경망 모델은 모델 파라미터 저장부로부터 기 학습된(pre- trained) 모델 파라미터를 제공받고, 제공받은 모델 파라미터를 입력되는 영상(i) 및 특징 맵(if)에 적용함으로 써, 압축률 값을 출력할 수 있다. 도 1에 도시된 실시예에서, 영상(i)으로부터 타겟 객체를 정상적으로 인식하 기 위한 압축률의 값은 34일 수 있다. 심층 신경망 모델은 출력된 압축률 정보를 인코딩 모듈에 제 공할 수 있다. 인코딩 모듈은 입력된 영상(i)을 압축하고, 부호화함으로써, 부호화된 비트스트림을 생성하도록 구성된다. 일 실시예에서, 인코딩 모듈는 원본 영상으로부터 인터 예측 및 인트라 예측을 통해 예측 데이 터를 획득하고, 원본 영상으로부터 예측 데이터를 뺀 잔차 데이터(residual date)를 획득하고, 잔차 데이터에 대하여 변환 및 양자화를 수행함으로써 부호화된 영상 데이터를 획득할 수 있다. 예를 들어, 부호화된 영상 데 이터는 양자화된 변환 계수(transform coefficient)일 수 있다. 인코딩 모듈은 General code control 모듈(1312a) 및 변환, 스케일링 및 양자화 모듈(1312b)을 포함할 수 있다. General code control 모듈(1312a)은 인코딩할 데이터에 관한 인코딩 파라미터(encoding parameter) 를 설정하도록 구성되는 모듈이다. 변환, 스케일링 및 양자화 모듈(Transform, Scaling, Quantization)(1312 b)은 영상(i)에 포함되는 일정 크기의 블록(block)을 변환 계수(transform coefficient)를 이용하여 변환할 수 있다. 일 실시예에서, 변환, 스케일링 및 양자화 모듈(1312b)은 General code control 모듈(1312a)로부터 획득 한 정보에 기초하여 discrete cosine transform (DCT) 및 discrete sine transform (DST)를 사용하여 블록을 변환할 수 있다. 예를 들어, 블록의 크기는 4×4 내지 32×32 사이의 크기로 구성될 수 있다. 일 실시예에서, 변환, 스케일링 및 양자화 모듈(1312b)은 변환 계수(transform coefficient)의 정규화(normalization) 값을 1 보다 크게 설정하고, 이에 따라 인코딩된 영상의 값 크기를 스케일링할 수 있다. 일 실시예에서, 변환, 스케일 링 및 양자화 모듈(1312b)은 변환된 데이터를 압축률 값에 기초하여, 양자화할 수 있다. 일 실시예에서, 인코딩 모듈은 심층 신경망 모델로부터 출력된 압축률 정보(도 2의 실시예에서, 압 축률의 값은 34)를 이용하여 영상(i)을 압축하고, 부호화함으로써 비트스트림을 생성할 수 있다. 일 실시예에서, 생성된 비트스트림은 통신 인터페이스(1500, 도 3 참조)를 통해 외부 서버 또는 타 디바 이스로 전송될 수 있다. 일반적인 디바이스는 저장 용량 또는 네트워크 대역폭의 한계로 인하여 카메라를 이용하여 촬영된 영상 또는 비 디오를 표준 규격에 따른 압축 방법(예를 들어, JPEG, H.264/AVC, HEVC(H.265) 등)을 이용하여 압축하고, 부호 화함으로써 서버에 전송한다. 이 경우, 압축률을 과도하게 높게 설정하여 인코딩을 하는 경우 영상이 열 화(degrading)되어 인식하여야 하는 사람의 얼굴, 헤어 스타일, 옷 차림, 등을 인식할 수 없게 되는 문제점이 있다. 또한, 제한적인 네트워크 대역폭, 네트워크의 불안정성으로 인한 데이터 패킷(packet) 손실, 인코딩 단계 에서의 오류, 또는 UDP 환경에서 데이터 패킷 손실 등 예외 상황에서 디코딩된 영상 프레임이 열화되고, 열화된 영상 프레임으로부터 사람의 얼굴 등을 인식할 수 없는 문제점이 있다. 열화된 영상 프레임으로부터 사람의 얼 굴을 인식하지 못하는 경우, 다른 사람으로 오 인식되고, 비(非) 인가자를 추적하기 어려운 문제가 발생된다. 사람의 얼굴, 헤어 스타일, 옷 차림 등을 포함하는 타겟 객체를 오류없이 정확하게 인식하기 위해서는, 영상 또 는 비디오를 압축하기 위한 최적의 압축률을 결정할 필요가 있다. 그러나, 최적의 압축률을 결정하기 위해서는 서로 다른 압축률 값을 이용하여 영상 또는 비디오를 압축하고, 부호화한 이후, 복호화된 복원 영상으로부터 타 겟 객체가 인식되었는지, 또는 오류율은 얼마인지를 측정해야 하므로, 처리 시간(processing time)이 많이 소요 되고, 연산량도 많아서 효율이 저하되는 문제점이 있다. 도 1에 도시된 실시예에 따른 디바이스는 전술한 문제점, 즉 제한적인 네트워크 대역폭, 네트워의 불안정성, 인 코딩 단계에서의 오류, UDP 환경에서 데이터 패킷 손실 등의 예외 상황에서도 특정 타겟 객체(예를 들어, 얼굴, 헤어 스타일, 옷, 포즈 등)의 인식률을 높이기 위하여, 심층 신경망 모델을 이용하는 방법을 제공한다. 본 개시의 일 실시예에 따른 디바이스는 복수의 원본 영상(io-1 내지 io-n)과 복수의 원본 영상(io-1 내지 io-n)으 로부터 타겟 객체가 정상적으로 인식되는 압축률(QP1 내지 QPn) 정보를 이용하여 심층 신경망 모델을 학습 (training)시키고, 기 학습된 심층 신경망 모델을 이용하여 입력 영상(i)에 관한 타겟 객체의 인식에 최 적화된 압축률 값을 출력할 수 있다. 본 개시는 학습 단계(S100)를 통해 미리 학습된 심층 신경망 모델을 이용하는바, 불필요한 처리 시간을 감소시킬 수 있고, 디바이스의 프로세서에 의해 수행되는 연산량도 감소시킬 수 있다. 또한, 본 개시의 디바이스는, 타겟 객체, 예를 들어 사람의 얼굴의 인식률을 현저하게 향상시키고, 오 인식률을 감소시킬 수 있다. 도 2는 본 개시의 일 실시예에 따른 디바이스가 원본 영상으로부터 압축률을 결정하고, 원본 영상 및 결정된 압 축률 정보를 저장하는 방법을 도시한 도면이다. 도 2를 참조하면, 원본 영상(io)은 타겟 객체 검출 모듈 및 인코딩 모듈로 각각 입력될 수 있다. 원본 영상(io)은 카메라 또는 네트워크를 통해 획득될 수 있다. 원본 영상(io)은 타겟 객체 검출 모듈에 입력되고, 타겟 객체 검출 모듈은 원본 영상(io)으로부터 타겟 객체를 검출할 수 있다. 일 실시예에서, 타겟 객체는 사람의 얼굴, 헤어 스타일, 옷, 및 포즈(posture) 중 적어도 하나를 포함할 수 있으나, 이에 한정되지 않는다. 타겟 객체 검출 모듈은 원본 영상(io)로부터 타겟 객체를 검출하도록 구성된다. 일 실시예에서, 타겟 객 체 검출 모듈은 딥 러닝(Deep Learning)을 포함하는 인공 지능 모델을 이용하여 원본 영상(io)으로부터 타겟 객체를 검출하도록 구성될 수 있다. 일 실시예에서, 타겟 객체 검출 모듈은 컨볼루션 신경망 모델 (CNN)을 이용하여 학습을 수행함으로써 원본 영상(io)으로부터 타겟 객체를 검출할 수 있다. 예를 들어, 타겟 객체가 얼굴인 경우, 타겟 객체 검출 모듈은 대규모의 데이터 셋, 예를 들어 CASIA-WebFace, VGGFace/VGGFace 2, 또는 MS-Celeb-1M을 통해 동적 영상으로부터 사람의 얼굴을 검출할 수 있다. 일 실시예에서, 타겟 객체 검출 모듈은 VGGFace2 데이터 셋을 이용하여 얼굴 인식을 수행하도록 기 학습된 MobileNet을 포함할 수 있다. 타겟 객체 검출 모듈은 원본 영상(io)으로부터 타겟 객체를 검출하는 과정에서 적어도 하나의 특징 맵 (if1, if2)을 출력할 수 있다. '특징 맵(if1, if2)'은 원본 영상(io)으로부터 타겟 객체를 검출하기 위하여 추출되 는 특징 벡터를 포함하는 이미지로서, 예를 들어, 엣지 맵(edge map), 블러 이미지(blur image), 또는 원형 맵 중 적어도 하나를 포함할 수 있다. 타겟 객체 검출 모듈은 원본 영상(io)으로부터 검출된 타겟 객체를 포함하는 제1 관심 영역(R1)을 검출할 수 있다. 제1 관심 영역(R1)은 타겟 객체 이미지, 예를 들어 사람의 얼굴을 포함하는 바운딩 박스일 수 있다. 타겟 객체 검출 모듈은 검출된 제1 관심 영역(R1)의 이미지 및 검출된 적어도 하나의 특징 맵(if1, if2)을 학습 데이터 저장부에 제공할 수 있다. 학습 데이터 저장부는 제1 관심 영역(R1)의 이미지 및 적어 도 하나의 특징 맵(if1, if2)을 학습 데이터로서 저장할 수 있다. 원본 영상(io)으로부터 검출된 타겟 객체는 특징 벡터 추출 모듈에 입력되고, 특징 벡터 추출 모듈(132 2)은 타겟 객체 이미지로부터 제1 특징 벡터(f1)를 추출할 수 있다. 제1 특징 벡터(f1)는 예를 들어, 사람의 얼 굴의 눈, 코, 입과 같은 랜드마크에 대응되는 특징값들을 포함하는 벡터일 수 있다. 그러나, 이에 한정되는 것 은 아니고, 제1 특징 벡터(f1)는 사람의 헤어 스타일, 옷 차림, 또는 특정 자세로부터 추출된 적어도 하나의 키 포인트(key-points)에 대응되는 특징값들을 포함하는 벡터일 수 있다. 원본 영상(io)으로부터 검출된 제1 관심 영역(R1)의 이미지는 중첩도 산출 모듈에 입력되고, 타겟 객체로 부터 추출된 제1 특징 벡터(f1)는 유사도 산출 모듈에 입력될 수 있다. 원본 영상(io)이 인코딩 모듈에 입력되는 경우, 인코딩 모듈은 기설정된 압축률(QP0)을 이용하여 원 본 영상(io)를 압축하고, 부호화함으로써 부호화된 영상 데이터를 출력할 수 있다. 일 실시예에서, 부호화된 영 상 데이터는 양자화된 변환 계수일 수 있다. 부호화된 영상 데이터는 디코딩 모듈에 입력되고, 디코딩 모듈은 부호화된 영상 데이터를 역 양자 화 및 역 변환함으로써 잔차 데이터(residual data)를 복원하고, 복원된 잔차 데이터와 인터 예측 및 인트라 예 측을 통해 획득한 예측 데이터를 더함으로써 복원 영상(irecon)을 획득할 수 있다. 복원 영상(irecon)은 타겟 객체 검출 모듈에 입력되고, 타겟 객체 검출 모듈은 복원 영상(irecon)으로 부터 타겟 객체를 검출할 수 있다. 복원 영상(irecon)으로부터 검출된 타겟 객체는, 원본 영상(io)으로부터 검출 된 타겟 객체와 동일할 수 있으나, 타겟 객체의 이미지의 해상도, 선예도 등 이미지 품질은 원본 영상(io)으로부 터 검출된 타겟 객체 이미지 보다 낮을 수 있다. 타겟 객체 검출 모듈은 복원 영상(irecon)으로부터 검출된 타겟 객체를 포함하는 제2 관심 영역(R2)을 검출할 수 있다. 제2 관심 영역(R2)은 타겟 객체 이미지, 예를 들어 사람의 얼굴을 포함하는 바운딩 박스일 수 있다. 복원 영상(irecon)으로부터 검출된 타겟 객체는 특징 벡터 추출 모듈에 입력되고, 특징 벡터 추출 모듈 은 복원 영상(irecon)에서 검출된 타겟 객체 이미지로부터 제2 특징 벡터(f2)를 추출할 수 있다. 제2 특징 벡터(f2)는 복원 영상(irecon)에서 검출된 타겟 객체 이미지로부터 추출되었다는 점을 제외하고는 제1 특징 벡터 (f1)와 동일한 바, 중복되는 설명은 생략한다. 복원 영상(irecon)으로부터 검출된 제2 관심 영역(R2)의 이미지는 중첩도 산출 모듈에 입력되고, 타겟 객체 로부터 추출된 제2 특징 벡터(f2)는 유사도 산출 모듈에 입력될 수 있다. 중첩도 산출 모듈은 제1 관심 영역(R1)의 바운딩 박스 좌표값 정보 및 제2 관심 영역(R2)의 바운딩 박스 좌표값 정보에 기초하여, 제1 관심 영역(R1)과 제2 관심 영역(R2) 간의 중첩도를 산출할 수 있다. 일 실시예에서, 중첩도 산출 모듈은 IOU(Intersection Over Union) 방식을 이용하여 제1 관심 영역(R1)과 제 2 관심 영역(R2) 간의 중첩도를 계산할 수 있다. 중첩도 산출 모듈은 계산된 중첩도 값의 정보를 인식 결 과 판단 모듈에 제공할 수 있다. 유사도 산출 모듈은 제1 특징 벡터(f1)와 제2 특징 벡터(f2) 간의 유사도를 계산할 수 있다. 일 실시예에 서, 유사도 산출 모듈은 제1 특징 벡터(f1)와 제2 특징 벡터(f2) 간의 상관 관계(correlation)를 수치값 으로 나타내는 유사도를 계산하고, 계산된 유사도 값의 정보를 인식 결과 판단 모듈에 제공할 수 있다. 인식 결과 판단 모듈은 중첩도 산출 모듈로부터 입력된 중첩도(R1, R2) 및 유사도 산출 모듈(132 4)로부터 입력된 유사도(f1, f2) 값을 이용하여, 타겟 객체가 정상적으로 인식되었는지 판단하도록 구성된다. 일 실시예에서, 인식 결과 판단 모듈은 중첩도(R1, R2) 값을 제1 임계치와 비교하고, 유사도(f1, f2) 값을 제 2 임계치와 비교함으로써, 복원 영상(irecon)으로부터 타겟 객체가 정상적으로 인식되었는지 여부를 판단할 수 있 다. 예를 들어, 인식 결과 판단 모듈은 중첩도(R1, R2) 값이 제1 임계치 이하이거나, 또는 유사도(f1, f2) 값 이 제2 임계치 이하인 경우, 복원 영상(irecon)으로부터 타겟 객체가 정상적으로 인식되지 않았다고 판단한다. 이 경우, 인식 결과 판단 모듈은 타겟 객체 인식 여부에 관한 판단 결과를 압축률 조절 모듈에 제공한 다. 압축률 조절 모듈은 인식 결과 판단 모듈로부터 타겟 객체가 정상적으로 인식되지 않았다는 판단 결과가 입력되면, 압축률을 복원 영상(irecon)을 획득하는데 이용된 기설정된 압축률(QP0)의 값보다 낮은 제1 압축률(QP1)로 조절할 수 있다. 압축률 조절 모듈은 조절된 압축률인 제1 압축률(QP1)의 값에 관한 정보를 인코딩 모듈에 제공할 수 있다. 인코딩 모듈은 압축률 조절 모듈로부터 입력받은 제1 압축률(QP1) 값을 이용하여, 원본 영상(io)을 압축하고, 부호화함으로써 부호화된 영상 데이터를 획득할 수 있다. 디코딩 모듈, 타겟 객체 검출 모듈 , 특징 벡터 추출 모듈, 중첩도 산출 모듈, 유사도 산출 모듈, 인식 결과 판단 모듈 , 및 압축률 조절 모듈이 수행하는 동작들은 제1 압축률(QP1)을 통해 압축되고 부호화된 영상 데이 터가 입력됨에 따라 반복적으로 수행될 수 있다. 다른 예를 들어, 인식 결과 판단 모듈은 중첩도(R1, R2) 값이 제1 임계치를 초과하고, 유사도(f1, f2) 값 이 제2 임계치를 초과하는 경우, 복원 영상(irecon)으로부터 타겟 객체가 정상적으로 인식되었다고 판단한다. 이 경우, 인식 결과 판단 모듈은 압축률(QPk)의 값을 타겟 객체가 정상적으로 인식되는 최적의 압축률 값으 로 결정할 수 있다. 인식 결과 판단 모듈은 결정된 압축률(QPk) 값의 정보를 학습 데이터 저장부에 제공하고, 학습 데이터 저장부는 압축률(QPk) 값을 저장할 수 있다. 디바이스는 도 2에 도시된 방법을 기 획득된 복수의 원본 영상에 대하여 수행함으로써, 복수의 원본 영상, 복수 의 원본 영상으로부터 추출된 복수의 특징 맵, 및 복수의 원본 영상으로부터 타겟 객체를 정상적으로 인식하기 위한 최적의 압축률 값을 획득하고, 학습 데이터 저장부에 저장할 수 있다. 디바이스는 학습 데이터 저장부에 저장된 복수의 원본 영상 및 복수의 특징 맵을 심층 신경망 모델(1340, 도 1 참조)에 입력으로 적용하고, 복수의 압축률에 관한 라벨(label)을 정답값(groundtruth)으로 적용하는 학습 (training)을 수행할 수 있다. 도 3은 본 개시의 일 실시예에 따른 디바이스의 구성 요소를 도시한 블록도이다. 디바이스는 카메라 또는 통신 인터페이스를 통해 획득된 영상을 처리하고, 각종 연산을 수행 하는 전자 장치이다. 디바이스는 예를 들어, 스마트폰(smartphone), 태블릿 PC(tablet personal computer), 이동 전화기(mobile phone), 영상 전화기, 전자책 리더기(e-book reader), 데스크탑 PC(desktop personal computer), 랩탑 PC(laptop personal computer), 넷북 컴퓨터(netbook computer), 워크스테이션 (workstation), PDA(personal digital assistant), PMP(portable multimedia player), MP3 플레이어, 모바일 의료기기, 웨어러블 장치(wearable device), 또는 IP 카메라 중 적어도 하나일 수 있다. 도 3을 참조하면, 디바이스는 카메라, 프로세서, 메모리, 학습 데이터 저장부, 모델 파라미터 저장부, 및 통신 인터페이스를 포함할 수 있다. 카메라는 렌즈를 이용하여 대상 영역 또는 대상 객체를 촬영함으로써, 영상을 획득하도록 구성된다. 카메라는 렌즈 및 이미징 센서를 포함할 수 있다. 이미징 센서는 렌즈를 통해 촬영되는 대상 영역 또는 대상 객체에 관한 영상을 획득할 수 있다. 이 미징 센서를 통해 획득된 영상은 압축되지 않은 비압축 영상 데이터로서, 원본 영상(raw image)이다. 이 미징 센서는 광 다이오드 어레이를 포함할 수 있다. 이미징 센서는 예를 들어, CCD 모듈(Charge- coupled device) 또는 CMOS(Complementary Metal-Oxide-Semiconductor) 모듈로 구성될 수 있지만, 이에 한정되 는 것은 아니다. 도 3에는 이미징 센서가 하나로 도시되어 있지만, 이에 한정되는 것은 아니다. 일 실시 예에서, 이미징 센서는 하나 이상의 복수 개로 구성될 수도 있다. 프로세서는, 메모리에 저장된 프로그램의 하나 이상의 명령어들(instructions) 또는 프로그램 코드 (program code)를 실행할 수 있다. 프로세서는 산술, 로직 및 입출력 연산과 시그널 프로세싱을 수행하는 하드웨어 구성 요소로 구성될 수 있다. 프로세서는 예를 들어, 중앙 처리 장치(Central Processing Unit), 마이크로 프로세서(microprocessor), 그래픽 프로세서(Graphic Processing Unit), ASICs(Application Specific Integrated Circuits), DSPs(Digital Signal Processors), DSPDs(Digital Signal Processing Devices), PLDs(Programmable Logic Devices), 및 FPGAs(Field Programmable Gate Arrays) 중 적어도 하나로 구성될 수 있으나, 이에 한정되는 것은 아니다. 메모리는 예를 들어, 플래시 메모리 타입(flash memory type), 하드디스크 타입(hard disk type), 멀티 미디어 카드 마이크로 타입(multimedia card micro type), 카드 타입의 메모리(예를 들어 SD 또는 XD 메모리 등), 램(RAM, Random Access Memory) SRAM(Static Random Access Memory), 롬(ROM, Read-Only Memory), EEPROM(Electrically Erasable Programmable Read-Only Memory), PROM(Programmable Read-Only Memory), 자기 메모리, 자기 디스크, 광디스크 중 적어도 하나로 구성될 수 있다. 메모리에는 기 획득된 복수의 원본 영상으로부터 타겟 객체를 정상적으로 인식하기 위한 압축률을 결정하 고, 카메라 또는 통신 인터페이스를 통해 입력된 영상을 심층 신경망 모델에 입력함으로써 압축률을 출력하고, 출력된 압축률을 이용하여 영상을 압축하고 부호화하는 기능 또는 동작의 수행과 관련된 명 령어들(instruction)을 포함하는 프로그램이 저장될 수 있다. 메모리에는 프로세서가 판독할 수 있 는 명령어들, 알고리즘(algorithm), 데이터 구조, 및 프로그램 코드(program code) 중 적어도 하나가 저장될 수 있다. 메모리에 저장되는 명령어들, 알고리즘, 데이터 구조, 및 프로그램 코드는 예를 들어, C, C++, 자 바(Java), 어셈블러(assembler) 등과 같은 프로그래밍 또는 스크립팅 언어로 구현될 수 있다. 메모리는 인코더, 학습 데이터 생성 모듈, 전처리 모듈, 및 심층 신경망 모델을 포함할 수 있다. 메모리에 포함되는 복수의 '모듈'은 프로세서에 의해 수행되는 기능이나 동작을 처리하는 단위를 의미하고, 이는 명령어들 또는 프로그램 코드와 같은 소프트웨어로 구현될 수 있다. 이하의 실시예에서, 프로세서는 메모리에 저장된 프로그램의 명령어들 또는 프로그램 코드들을 실행함으 로써 구현될 수 있다. 인코더는 영상을 압축하고, 부호화 및 복호화함으로써 복원 영상을 생성하도록 구성된다. 일 실시예에서, 인코더는 JPEG, H.264/AVC 및 HEVC(H.265)를 포함하는 영상 압축 표준 규격 중 적어도 하나를 이용하여 원본 영상을 압축하고, 부호화 및 복호화함으로써 복원 영상을 생성할 수 있다. 인코더는 인코딩 모듈 및 디코딩 모듈을 포함할 수 있다. 인코딩 모듈은 입력된 영상, 즉 원본 영상을 기설정된 압축률을 이용하여 부호화하고, 원본 영상으로부터 부호화된 영상 데이터를 획득하도 록 구성될 수 있다. 일 실시예에서, 프로세서는 인코딩 모듈과 관련된 명령어들 또는 프로그램 코드를 실행함으로써, 입력 영상, 즉 원본 영상으로부터 인터 예측 및 인트라 예측을 통해 예측 데이터를 획득하 고, 원본 영상으로부터 예측 데이터를 뺀 잔차 데이터(residual date)를 획득하고, 잔차 데이터에 대하여 변환 및 양자화를 수행함으로써 부호화된 영상 데이터를 획득할 수 있다. 예를 들어, 부호화된 영상 데이터는 양자화 된 변환 계수(transform coefficient)일 수 있다. 디코딩 모듈은 부호화된 영상 데이터를 복호화함으로써, 복원 영상을 생성하도록 구성될 수 있다. 일 실 시예에서, 프로세서는 디코딩 모듈과 관련된 명령어들 또는 프로그램 코드를 실행함으로써, 부호화 된 영상 데이터, 즉 양자화된 변환 계수에 대하여 역 양자화 및 역변환을 수행함으로써 잔차 데이터를 복원하고, 복원된 잔차 데이터와 인터 예측 및 인트라 예측을 통해 획득한 예측 데이터를 더함으로써 복원 영상 을 획득할 수 있다. H.264/ACV 또는 HEVC(H.265)와 같은 영상 압축 표준 규격을 사용하는 경우, 인코더는 예를 들어, 인터 예 측 모듈, 인트라 예측 모듈, 디블록킹 모듈, 변환 모듈, 양자화 모듈, 역 변환 모듈, 역 양자화 모듈, 엔트로피 부호화 모듈을 포함할 수 있다. 이 경우, 상기 나열되는 모듈들은 인터 예측 및 인트라 예측을 수행하고, 부호 화 및 복호화를 수행하는바, 도 3에 도시된 바와 같이 인코딩 모듈과 디코딩 모듈로 완전히 구분되 지는 않는다. H.264/AVC 또는 HEVC(H.265)를 이용하여 복원 영상이 생성되는 경우, 복원 영상은 원본 영상을 기설정된 코딩 단위(예를 들어, CTU(Coding Tree Unit)) 에 따라 서로 다른 양자화 파라미터 값을 적용하여 압축, 부호화 및 복호화 될 수 있다. 이 경우, 원본 영상에 포함되는 영상 프레임 내의 복수의 CTU 중 타겟 객체(예를 들어, 사 람의 얼굴, 헤어 스타일, 옷, 포즈 등)가 검출된 특정 CTU에는 다른 CTU에 비하여 상대적으로 낮은 양자화 파라 미터 값이 적용되어 압축될 수 있다. 학습 데이터 생성 모듈은 원본 영상을 입력받고, 원본 영상으로부터 학습 데이터를 출력하도록 구성되는 모듈이다. 여기서, '학습 데이터'는 심층 신경망 모델을 이용하는 학습(training)을 수행하기 위하여 입 력 및 출력에 적용되는 데이터를 의미한다. 일 실시예에서, 학습 데이터는 기 획득된 복수의 원본 영상, 복수의 원본 영상 각각으로부터 추출된 복수의 특징 맵 및 복수의 원본 영상 각각으로부터 타겟 객체를 정상적으로 인 식하기 위한 최적의 압축률을 포함할 수 있다. 학습 데이터 생성 모듈은 타겟 객체 검출 모듈, 특징 벡터 추출 모듈, 중첩도 산출 모듈 , 유사도 산출 모듈, 인식 결과 판단 모듈, 및 압축률 조절 모듈을 포함할 수 있다. 타겟 객체 검출 모듈은 정적 영상(still image) 또는 동적 영상으로부터 타겟 객체를 인식하도록 구성되 는 모듈이다. 여기서, '타겟 객체(target object)'는 사용자가 영상으로부터 검출하고자 하는 관심있는 객체를 의미한다. 타겟 객체는 예를 들어, 사람의 얼굴, 헤어, 옷, 및 포즈(posture) 중 적어도 하나를 포함할 수 있다. 일 실시예에서, 타겟 객체 검출 모듈은 딥 러닝(Deep Learning)을 포함하는 인공 지능 모델을 이용 하여 입력되는 영상으로부터 타겟 객체를 검출하도록 구성될 수 있다. 일 실시예에서, 타겟 객체 검출 모듈 은 컨볼루션 신경망 모델(CNN)을 이용하여 학습을 수행함으로써 영상으로부터 타겟 객체를 검출할 수 있 다. 예를 들어, 타겟 객체가 얼굴인 경우, 타겟 객체 검출 모듈은 대규모의 데이터 셋, 예를 들어 CASIA- WebFace, VGGFace/VGGFace 2, 또는 MS-Celeb-1M을 통해 동적 영상으로부터 사람의 얼굴을 검출할 수 있다. 일 실시예에서, 타겟 객체 검출 모듈은 VGGFace2 데이터 셋을 이용하여 얼굴 인식을 수행하도록 기 학습된 MobileNet을 포함할 수 있다. 일 실시예에서, 프로세서는 타겟 객체 검출 모듈과 관련된 명령어들 또는 프로그램 코드를 실행함 으로써, 원본 영상 및 복원 영상 각각으로부터 타겟 객체를 검출할 수 있다. 예를 들어, 프로세서는 컨볼 루션 신경망 모델을 통해 기 학습된 모델 파라미터를 이용하여 학습(training)을 수행함으로써, 원본 영상 및 복원 영상 각각으로부터 사람의 얼굴을 검출할 수 있다. 그러나, 이에 한정되는 것은 아니고, 프로세서는 타겟 객체 검출 모듈에 포함된 기 학습된 모델 파라미터를 이용하여 학습을 수행함으로써, 원본 영상 및 복원 영상 각각으로부터 사람의 헤어 스타일, 옷, 및 포즈(posture) 중 적어도 하나를 검출할 수 있다. 그러나, 타겟 객체 검출 모듈이 전술한 방법을 이용하여 타겟 객체를 검출하는 것으로 한정되지는 않는다. 일 실시예에서, 타겟 객체 검출 모듈은 순환 신경망 모델(Recurrent Neural Network; RNN), SVM(Support Vector Machine), 선형 회귀(linear regression), 로지스틱 회귀(logistic regression), 나이브 베이즈 분류(Naive Bayes), 랜덤 포레스트(random forest), decision tree, 또는 k-nearest neighbor algorithm 중 적어도 하나를 포함하는 인공 지능 모델을 이용하여 동적 영상으로부터 타겟 객체를 인식하도록구성될 수 있다. 일 실시예에서, 프로세서는 타겟 객체 검출 모듈과 관련된 명령어들 또는 프로그램 코드를 실행함 으로써, 영상으로부터 타겟 객체를 검출할 수 있다. 프로세서는 타겟 객체를 검출하는 과정에서 적어도 하나의 특징 맵(feature map)을 출력할 수 있다. '특징 맵'은 영상으로부터 타겟 객체를 검출하기 위하여 추출 되는 특징 벡터를 포함하는 이미지로서, 예를 들어, 엣지 맵(edge map), 블러 이미지(blur image), 또는 원형 맵 중 적어도 하나를 포함할 수 있다. 일 실시예에서, 컨볼루션 신경망 모델을 이용하는 경우, 프로세서 는 원본 영상을 기설정된 크기 및 채널(channel) 수를 갖는 필터(filter)를 이용하여 합성 곱(convolution)을 산출하고, 합성 곱을 통해 필터의 개수와 동일한 2차원 이미지 레이어(layer)를 추출하고, 2D 이미지 레이어로 구성된 적어도 하나의 특징 맵을 획득할 수 있다. 일 실시예에서, 타겟 객체 검출 모듈은 동적 영상 상에서 검출된 타겟 객체의 바운딩 박스(bounding bo x)를 식별하고, 식별된 바운딩 박스의 위치 좌표값을 획득하도록 구성될 수 있다. 프로세서는 타겟 객체 검출 모듈과 관련된 명령어들 또는 프로그램 코드를 실행함으로써, 원본 영상으로부터 검출된 타겟 객체 의 바운딩 박스를 식별하고, 바운딩 박스 내에 포함된 영역을 제1 관심 영역(Region of Interest)으로 설정할 수 있다. 프로세서는 타겟 객체 검출 모듈과 관련된 명령어들 또는 프로그램 코드를 실행함으로써, 복원 영상으로부터 검출된 타겟 객체의 바운딩 박스를 식별하고, 바운딩 박스 내에 포함된 영역을 제2 관심 영 역으로 설정할 수 있다. 특징 벡터 추출 모듈은 검출된 타겟 객체의 이미지로부터 특징 벡터(feature vector)를 추출하도록 구성 되는 모듈이다. 특징 벡터 추출 모듈은 공지의 영상 처리 방법(image processing method) 또는 딥 러닝을 포함하는 인공 지능 모델을 이용하여 타겟 객체 이미지로부터 특징 벡터를 추출하도록 구성될 수 있다. 예를 들 어, 특징 벡터 추출 모듈은 ICA(Independent Component Analysis) 또는 PCA(Principle Component Analysis) 방법을 이용하여 타겟 객체 이미지로부터 특징 벡터를 추출하도록 구성될 수 있다. 예를 들어, 타겟 객체 이미지가 사람의 얼굴인 경우, 특징 벡터 추출 모듈은 얼굴의 눈, 코, 및 입(양쪽 입 끝)을 포함하는 랜드마크(landmark)를 식별하고, 식별된 랜드마크에 대응되는 특징값(예를 들어, 위치 좌표 값)을 획득하고, 획득된 특징값을 이용하여 특징 벡터를 추출할 수 있다. 다른 예를 들어, 타겟 객체 이미지가 사람의 헤어 스타일, 옷 차림, 또는 특정 자세(posture)인 경우, 특징 벡터 추출 모듈은 타겟 객체 이미 지로부터 적어도 하나의 키 포인트(key-points)를 식별하고, 식별된 키 포인트에 대응되는 특징값(예를 들어, 위치 좌표값)을 획득하고, 획득된 특징값을 이용하여 특징 벡터를 추출할 수 있다. 일 실시예에서, 프로세서는 특징 벡터 추출 모듈과 관련된 명령어들 또는 프로그램 코드를 실행함 으로써, 타겟 객체 이미지로부터 특징 벡터를 추출할 수 있다. 일 실시예에서, 프로세서는 원본 영상으로 부터 인식된 타겟 객체의 이미지로부터 제1 특징 벡터를 추출하고, 복원 영상으로부터 인식된 타겟 객체의 이미 지로부터 제2 특징 벡터를 추출할 수 있다. 중첩도 산출 모듈은 두 개 이상의 이미지 간의 중첩되는 정도를 계산하고, 결과값을 출력하도록 구성되는 모듈이다. 중첩도 산출 모듈은 두 개 이상의 이미지 각각의 바운딩 박스(bounding box)의 좌표값 정보를 획득하고, 바운딩 박스의 좌표값을 이용하여 두 개 이상의 이미지가 겹치는 정도를 비교함으로써, 중첩도를 산 출하도록 구성될 수 있다. 일 실시예에서, 중첩도 산출 모듈은 좌표값 정보를 이용하여 중첩도를 계산하는 IOU(Intersection Over Union) 방식을 이용하여 두 개 이상의 이미지 간의 중첩도를 계산할 수 있다. IOU 방식을 이용하는 중첩도 계산 에서, IOU 값이 1인 경우, 두 개의 이미지가 완전히 겹쳐지는 것을 의미하고, IOU 값이 0인 경우, 두 개의 이미 지가 전혀 겹쳐지지 않음을 의미한다. 예를 들어, IOU 값이 0.5 인 경우, 두 개의 이미지의 2/3 가 겹쳐지는 것 을 의미한다. 일 실시예에서, 중첩도 산출 모듈은 복수의 이미지 각각의 좌표값 사이의 오차의 합을 계산함으로써, 중 첩도를 산출할 수 있다. 예를 들어, 중첩도 산출 모듈은 하기 수식 1과 같이, 제1 이미지의 좌상단의 좌 표값(x11, y11)과 우하단 좌표값(x12, y12) 및 제2 이미지의 좌상단 좌표값(x21, y21), 우하단 좌표값(x22, y22)을 이용하여, 좌표값 오차를 계산할 수 있다.수학식 1"}
{"patent_id": "10-2020-0127386", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "그러나, IOU 방식 및 좌표값 오차 계산 방식은 중첩도 계산 방식의 일 예시이고, 중첩도 산출 모듈이 두 개 이상의 이미지 간의 중첩도를 계산하는 방식이 전술한 IOU 방식 및 좌표값 오차 계산 방식으로 한정되는 것 은 아니다. 프로세서는 중첩도 산출 모듈과 관련된 명령어들 또는 프로그램 코드를 실행함으로써, 원본 영상으 로부터 인식된 타겟 객체가 포함되는 제1 관심 영역의 바운딩 박스 좌표값 정보 및 복원 영상으로부터 인식된 타겟 객체가 포함되는 제2 관심 영역의 바운딩 박스 좌표값 정보에 기초하여, 제1 관심 영역과 제2 관심 영역 간의 중첩도를 산출할 수 있다. 일 실시예에서, 프로세서는 중첩도 산출 모듈로부터 제공되는 IOU 방식 또는 좌표값 오차 계산 방식을 이용하여 제1 관심 영역과 제2 관심 영역 간의 중첩도를 계산할 수 있다. 일 실시예에서, 프로세서는 제1 관심 영역의 바운딩 박스의 좌상단 좌표값 및 우하단 좌표값과 제2 관심 영역의 바운딩 박스의 좌상단 좌표값 및 우하단 좌표값을 이용하여, 제1 관심 영역과 제2 관심 영역 간의 좌표 값 오차를 계산하고, 계산된 좌표값 오차에 기초하여 중첩도를 계산할 수 있다. 유사도 산출 모듈은 두 개의 특징 벡터 간의 유사도를 수치값으로 산출하는 모듈이다. 일 실시예에서, 유 사도 산출 모듈은 두 개의 특징 벡터 간의 상관 관계(correlation)를 수치값으로 계산하도록 구성될 수 있다. 프로세서는 유사도 산출 모듈과 관련된 명령어들 또는 프로그램 코드를 실행함으로써, 원본 영상에 서 검출된 타겟 객체로부터 추출된 제1 특징 벡터와 복원 영상에서 검출된 타겟 객체로부터 추출된 제2 특징 벡 터 간의 유사도를 수치값으로 산출할 수 있다. 프로세서 예를 들어, 하기의 수식 2를 통해 제1 특징 벡터 와 제2 특징 벡터 간의 유사도를 계산할 수 있다. 수학식 2"}
{"patent_id": "10-2020-0127386", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "상기 수식 2에서 Forig 및 Fenc는 각각 원본 영상에서 검출된 타겟 객체로부터 추출된 제1 특징 벡터, 복원 영상에 서 검출된 타겟 객체로부터 추출된 제2 특징 벡터를 의미하고, N은 특징 벡터의 길이, μ는 특징 벡터의 평균값, σ는 특징 벡터의 표준 편차를 의미한다. 수식 2는 유사도를 계산하기 위한 일 예시이고, 프로세서가 유사도 산출 모듈을 이용하여 제1 특징 벡터와 제2 특징 벡터 간의 유사도를 계산하는 방식이 상기 수식 2로 한정되는 것은 아니다. 인식 결과 판단 모듈은, 원본 영상과 복원 영상 각각으로부터 검출된 관심 영역 간의 중첩도 및 원본 영 상과 복원 영상 각각으로부터 추출된 특징 벡터 간의 유사도에 기초하여, 복원 영상으로부터 타겟 객체가 정상 적으로 인식되었는지 여부를 판단하도록 구성되는 모듈이다. 인식 결과 판단 모듈은, 중첩도 산출 모듈 을 이용하여 산출된 제1 관심 영역과 제2 관심 영역 간의 중첩도를 기설정된 제1 임계치와 비교하고, 유 사도 산출 모듈을 이용하여 산출된 제1 특징 벡터와 제2 특징 벡터 간의 유사도를 기설정된 제2 임계치와 비교할 수 있다. 예를 들어, 제1 임계치는 0.8이고, 제2 임계치는 0.5일 수 있다. 그러나, 제1 임계치 및 제2 임계치의 수치가 전술한 바와 같이 한정되는 것은 아니다. 프로세서는 인식 결과 판단 모듈와 관련된 명령어들 또는 프로그램 코드를 실행함으로써, 제1 관심 영역과 제2 관심 영역 간의 중첩도를 제1 임계치와 비교하고, 제1 특징 벡터와 제2 특징 벡터 간의 유사도를 기 설정된 제2 임계치와 비교할 수 있다. 인식 결과 판단 모듈은 비교 결과에 관한 정보를 압축률 조절 모듈 에 제공할 수 있다. 압축률 조절 모듈은 인식 결과 판단 모듈에 의해 판단된 타겟 객체의 인식 여부에 기초하여, 원본 영상을 압축하여 복원 영상을 획득하기 위한 압축률을 결정하는 모듈이다. 여기서 '압축률'은 원본 영상을 표준 규격에 매칭되는 방법을 이용하여 인코딩하기 위한 영상 압축 파라미터를 의미한다. 압축률은 표준 규격 마다 다양한 형태로 존재할 수 있다. 예를 들어, 정적 이미지를 재생하기 위한 표준(예를 들면, JPEG(Joint Photographic Coding Experts Group), JPEG-2000, JPEG- XR, WebP 등)에서는 영상의 압축률을 결정하기 위하여 양자화 테이블(Quantization Table)이 이용될 수 있다. 다른 예를 들면 동적 이미지를 재생하기 위한 표준(예를 들면, H. 264, HEVC 등)에서는 양자화 파라미터(Quantization Parameter)를 이용하여 영상의 압축률이 결정될 수 있다. 일 실시예에서, 압축률 조절 모듈은 인식 결과 판단 모듈로부터 획득한 중첩도 및 유사도 의 기설정된 임계치와의 비교 결과에 기초하여 양자화 파라미터 값을 결정하도록 구성될 수 있다. '양자화 파라미터'는 동적 영상의 압축과 관련된 표준 규격, 예를 들어 H.264/AVC, 또는 HEVC(H.265)에서 정의 되는 변환 계수를 양자화하는 정도를 나타내는 파라미터로서, 양자화 파라미터에 의해 영상의 압축률이 결정될 수 있다. 일 실시예에서, 압축률은 양자화 파라미터의 값에 비례한다. 예를 들어, 양자화 파라미터의 값이 큰 경우, 압축률이 높고, 양자화 파라미터의 값이 작은 경우, 압축률이 낮다. 압축률 조절 모듈은, 인식 결과 판단 모듈로부터 제공받은 비교 결과에 기초하여, 압축률의 값을 조절하도록 구성될 수 있다. 일 실시예에서, 프로세서는 압축률 조절 모듈과 관련된 명령어들 또는 프로그램 코드를 실행함으로써, 제1 관심 영역과 제2 관심 영역 간의 중첩도와 제1 임계치와의 비교 결과, 및 제1 특징 벡터와 제2 특징 벡터 간의 유사도와 제2 임계치와의 비교 결과에 기초하여 양자화 파라미터의 값을 조절할 수 있다. 압축률 조절 모듈은 기설정된 단위만큼 압축률의 값을 변경할 수 있다. 일 실시예에서, 프로세서는 인식 결과 판단 모듈을 이용하여 비교한 결과, 중첩도가 제1 임계치 이 하이거나, 또는 유사도가 제2 임계치 이하인 경우, 압축률의 값을 변경할 수 있다. 이 경우, 프로세서는 압축률 값을 기존 복원 영상을 압축하고 부호화하는데 사용되었던 압축률 보다 더 낮은 값으로 변경할 수 있다. 일 실시예에서, 프로세서는 인식 결과 판단 모듈을 이용하여 비교한 결과, 중첩도가 제1 임계치를 초과하고, 유사도가 제2 임계치를 초과하는 경우, 복원 영상을 생성하는데 이용된 압축률을 최종 압축률로 결정 할 수 있다. 일 실시예에서, 프로세서는 중첩도가 제1 임계치 이하이거나, 또는 유사도가 제2 임계치 이하인 경우, 압 축률을 결정하는 동작들을 반복적으로 수행할 수 있다. 예를 들어, 프로세서는 압축률 조절 모듈을 통해 변경된 압축률을 이용하여 원본 영상을 압축하는 동작, 부호화 및 복호화 과정을 거쳐 복원 영상을 생성하 는 동작, 복원 영상으로부터 타겟 객체를 인식하고, 제2 특징 벡터를 추출하는 동작, 중첩도를 산출하는 동작, 유사도를 산출하는 동작, 타겟 객체가 정상적으로 인식되었는지 판단하는 동작, 및 압축률을 재조정(re- adjust)하는 동작들을 적어도 1회 이상 반복적으로 수행할 수 있다. 일 실시예에서, 프로세서는 중첩도가 제1 임계치를 초과하고, 유사도가 제2 임계치를 초과하는 경우, 최 종 압축률 값을 결정하고, 결정된 최종 압축률에 관한 정보를 학습 데이터 저장부에 저장할 수 있다. 프 로세서는 결정된 최종 압축률에 관한 정보와 함께, 원본 영상 및 원본 영상으로부터 추출된 적어도 하나 의 특징 맵을 학습 데이터 저장부에 저장할 수 있다. 일 실시예에서, 프로세서는 전술한 학습 데이 터 생성 동작을 기 획득된 복수의 원본 영상에 대하여 수행함으로써, 복수의 원본 영상, 복수의 특징 맵 및 복 수의 압축률 정보를 학습 데이터 저장부에 저장할 수 있다. 전처리 모듈은 입력된 영상에 대하여 전처리(pre-processing)를 수행하도록 구성되는 모듈이다. 전처리 모듈은 영상의 크기를 기 설정된 크기로 조절(resize)하고, 영상의 밝기 및 대조도(contrast)를 정규화 (normalize)할 수 있다. 프로세서는 카메라를 이용하는 촬영을 통해 획득되거나 또는 통신 인터페 이스를 통해 획득된 영상을 전처리 모듈에 입력함으로써, 영상의 크기를 조절하고, 영상의 밝기 및 대조도를 정규화할 수 있다. 프로세서는 전처리가 완료된 영상을 심층 신경망 모델에 입력할 수 있 다. 심층 신경망 모델은 학습 데이터 저장부에 기 저장된 학습 데이터를 이용하여 기계 학습(trainin g)을 수행하도록 구성되는 인공 지능 모델이다. 일 실시예에서, 프로세서는 학습 데이터 저장부에 기 저장된 복수의 원본 영상 및 복수의 특징 맵을 심층 신경망 모델에 입력으로 적용하고, 복수의 원본 영상 각각으로부터 타겟 객체를 정상적으로 인식하기 위한 최적의 압축률 값에 관한 라벨(label)을 심층 신경망 모델의 정답값(groundtruth)으로 적용하는 지도 학습(supervised learning)을 수행할 수 있다. 일 실시예에서, 심층 신경망 모델은 연산을 수행하는 내부의 레이어(layer)인 복수의 은닉 레이어(hidden layer)를 포함할 수 있다. 심층 신경망 모델은 예를 들어, 컨볼루션 신경망 모델(Convolutional Neural Network; CNN), 순환 신경망 모델(Recurrent Neural Network; RNN), 제한 볼츠만 머신(Restricted Boltzmann Machine; RBM), DBN(Deep Belief Network), BRDNN(Bidirectional Recurrent Deep Neural Network) 및 심층 Q- 네트워크 (Deep Q-Networks) 중 적어도 하나를 포함할 수 있다. 그러나, 심층 신경망 모델이 전술한 예시 로 한정되는 것은 아니고, 공지의 모든 딥 러닝(Deep Learning) 기반의 신경망 모델을 포함할 수 있다. 예를 들어, 심층 신경망 모델이 컨볼루션 신경망 모델(CNN)로 구현되는 경우, 프로세서는 학습 단 계에서 기설정된 크기 및 기설정된 채널 수를 갖는 필터(filter)을 이용하여 학습 데이터 저장부로부터 입력되는 복수의 원본 영상을 이동함(stride)으로써 특징 값들을 추출하고, 추출된 특징 값들을 포함하는 복수 개의 레이어(layer)를 획득하며, 복수 개의 레이어에 가중치(weight)를 적용함으로써 특징 벡터 맵(feature vector map)을 획득할 수 있다. 상기 특징 벡터 맵을 획득하는 과정에서 정류 선형 유닛(ReLU) 모델이 이용되고, 효율을 향상시키기 위하여 드롭 아웃(drop out)을 통해 학습 모델을 정칙화(regularization)하고, 풀 링(pooling) 또는 맥스 풀링(max pooling)을 수행하는 동작들이 더 추가될 수 있다. 이어서, 풀링 또는 맥스 풀 링을 통해 획득된 특징값들은 fully connected layer를 통해 통합되고, 소프트맥스(softmax), 시그모이드 (sigmoid), 하이퍼볼릭 탄젠트(hyperbolic tangent)를 포함하는 활성 함수(activation function)를 통해 압축 률 값과 관련된 라벨을 출력하도록 학습될 수 있다. 프로세서는 심층 신경망 모델을 이용하는 학습을 통해, 모델 파라미터를 획득할 수 있다. 일 실시 예에서, 심층 신경망 모델이 컨볼루션 신경망 모델(CNN)로 구현되는 경우, 프로세서는 심층 신경망 모델을 이용하는 지도 학습을 통해 복수의 레이어 간 가중치(weight) 및 편향(bias) 정보를 포함하는 모 델 파라미터를 획득할 수 있다. 여기서, '가중치(weight)'와 '편향(bias)'은 입력 데이터(복수의 원본 영상 및 복수의 특징 맵)로부터 출력 라벨(압축률 값)을 추론하기 위한 매개 변수로서, 학습이 수행됨에 따라 값이 조정 (adjust)될 수 있다. 프로세서는, 심층 신경망 모델의 학습을 통해 획득된 가중치 및 편향에 관한 정보를 모델 파라미터 저장부에 저장할 수 있다. 일 실시예에서, 프로세서는 전처리 모듈을 통해 전처리가 완료된 영상을 기 학습된 모델 파라미터 로 구성된 심층 신경망 모델에 입력함으로써, 영상으로부터 타겟 객체를 정상적으로 인식하기 위한 압축 률을 출력할 수 있다. 일 실시예에서, 프로세서는 영상으로부터 타겟 객체를 검출하는 과정에서 추출되는 적어도 하나의 특징 맵을 심층 신경망 모델에 입력할 수도 있다. 적어도 하나의 특징 맵을 심층 신경망 모델에 입력함으로써, 출력되는 압축률의 정확도가 더 향상될 수 있다. 출력되는 '압축률의 정확도'는 심 층 신경망 모델에 입력되는 영상으로부터 타겟 객체가 정확하게 인식되는 정도를 의미하고, 압축률의 정 확도는 타겟 객체 인식률과 비례한다. 심층 신경망 모델은 적어도 하나의 명령어들(instructions) 또는 프로그램 코드를 포함하는 소프트웨어 모듈로 구현될 수 있다. 이 경우, 심층 신경망 모델은 컴퓨터로 읽을 수 있는 판독 가능한 비일시적 판독 가능 기록매체(non-transitory computer readable media)에 저장될 수 있다. 또한, 심층 신경망 모델은 디바이스의 운영 체제(Operating System)에 의해 제공되거나, 소정의 애플리케이션을 통해 제공될 수도 있다. 도 3에서 심층 신경망 모델은 메모리 내에 저장되는 소프트웨어 모듈로 도시되고, 프로세서 에 의해 실행되는 것으로 설명되고 있지만, 이에 한정되는 것은 아니다. 일 실시예에서, 심층 신경망 모델 은 적어도 하나의 하드웨어 칩 형태로 제작되어 디바이스에 탑재될 수 있다. 예를 들어, 심층 신경 망 모델은 인공 지능(AI; artificial intelligence)을 위한 전용 하드웨어 칩 형태로 제작될 수도 있고, 또는 기존의 범용 프로세서(예: CPU 또는 application processor) 또는 그래픽 전용 프로세서(예: GPU)의 일부 로 제작되어 전술한 디바이스에 포함될 수도 있다. 또한, 심층 신경망 모델은 디바이스가 아닌, 별개의 장치에 탑재될 수도 있다. 예를 들어, 심층 신 경망 모델은 외부의 서버(2000, 도 1 참조)에 포함될 수 있다. 이 경우, 디바이스는 전처리 모듈 을 통해 전처리가 완료된 영상을 서버에 전송하고, 영상으로부터 타겟 객체를 정상적으로 인식하기 위한 압축률에 관한 정보를 서버로부터 수신할 수 있다. 프로세서는 심층 신경망 모델로부터 출력된 압축률에 관한 정보를 인코더에 제공할 수 있다. 인코더는 심층 신경망 모델로부터 입력받은 압축률을 이용하여 영상을 압축하고, 부호화함으로써 비트스트림(bitstream)을 생성할 수 있다. 프로세서는 통신 인터페이스를 이용하여, 비트스트림을 외부의 서버(2000, 도 1 참조) 또는 타 디바이스에 전송할 수 있다.일 실시예에서, 프로세서는 심층 신경망 모델의 출력으로부터 획득된 압축률 정보를, 통신 인터페 이스를 통해 연결되는 네트워크의 대역폭 정보에 기초하여 결정된 압축률 값 및 인코딩 모듈에 의 해 기 설정된 초기 압축률 값과 비교하고, 비교 결과에 기초하여 최종 압축률 값을 결정할 수 있다. 이에 대해 서는 도 10에서 상세하게 설명하기로 한다. 학습 데이터 저장부는 학습 데이터 생성 모듈에 의해 생성된 학습 데이터를 저장하는 데이터베이스 (database)이다. 일 실시예에서, 학습 데이터 저장부는 비휘발성 메모리로 구성될 수 있다. 비휘발성 메 모리(Non-volatile memory)는 전원이 공급되지 않은 상태에서도 정보를 저장 및 유지하고, 전원이 공급되면 다 시 저장된 정보를 사용할 수 있는 기억 매체를 의미한다. 학습 데이터 저장부는 예를 들어, 플래시 메모 리(flash memory), 하드디스크(hard disk), SSD(Solid State Drive), 멀티미디어 카드 마이크로 타입 (multimedia card micro type), 카드 타입의 메모리(예를 들어 SD 또는 XD 메모리 등), 롬(Read Only Memory; ROM), 자기 메모리, 자기 디스크, 광디스크 중 적어도 하나로 구성될 수 있다. 도 3에서 학습 데이터 저장부는 디바이스의 메모리가 아닌, 별개의 구성 요소로 도시되었지 만, 이에 한정되는 것은 아니다. 일 실시예에서, 학습 데이터 저장부는 메모리 내에 포함될 수도 있다. 또는 학습 데이터 저장부는 디바이스에 포함되지 않은 구성 요소로서 통신 인터페이스(150 0)를 통해 유무선 통신을 통해 연결될 수도 있다. 학습 데이터 저장부는 복수의 원본 영상, 학습 데이터 생성 모듈에 의해 출력된 복수의 특징 맵 및 복수의 압축률 값에 관한 정보를 포함할 수 있다. 일 실시예에서, 학습 데이터 저장부는 복수의 원본 영 상, 복수의 특징 맵 및 복수의 압축률 값은 키(key)-밸류(value) 타입으로 저장할 수 있다. 모델 파라미터 저장부는 심층 신경망 모델의 학습을 통해 획득된 모델 파라미터를 저장하는 데이터 베이스이다. 모델 파라미터는, 심층 신경망 모델의 타입에 따라 달라질 수 있다. 예를 들어, 심층 신경망 모델이 컨볼루션 신경망 모델(CNN)인 경우, 모델 파라미터 저장부는 복수의 레이어 간 가중치 (weight) 및 편향(bias)을 포함하는 모델 파라미터를 저장할 수 있다. 모델 파라미터 저장부는 비휘발성 메모리로 구성될 수 있다. 모델 파라미터 저장부는 예를 들어, 플래시 메모리(flash memory), 하드디스크(hard disk), SSD(Solid State Drive), 멀티미디어 카드 마이크로 타 입(multimedia card micro type), 카드 타입의 메모리(예를 들어 SD 또는 XD 메모리 등), 롬(Read Only Memory; ROM), 자기 메모리, 자기 디스크, 광디스크 중 적어도 하나로 구성될 수 있다. 도 3에서 모델 파라미터 저장부는 디바이스의 메모리가 아닌, 별개의 구성 요소로 도시되었 지만, 이에 한정되는 것은 아니다. 일 실시예에서, 모델 파라미터 저장부는 메모리 내에 포함될 수 도 있다. 또는 모델 파라미터 저장부는 디바이스에 포함되지 않은 구성 요소로서 통신 인터페이스 를 통해 유무선 통신을 통해 연결될 수도 있다. 통신 인터페이스는 디바이스와 서버 또는 타 디바이스 간 데이터 송수신을 수행하도록 구성된다. 통신 인터페이스는 예를 들어, 이더넷(Ethernet), 유무선 LAN(Local Area Network), 와이파이(Wi-Fi), WFD(Wi-Fi Direct), 및 와이기그(Wireless Gigabit Allicance, WiGig)를 포함하는 유무선 데이터 통신 방식 중 적어도 하나를 이용하여 서버 또는 타 디바이스와 데이터 통신을 수행할 수 있다. 도 4는 본 개시의 일 실시예에 따른 디바이스의 동작 방법을 도시한 흐름도이다. 단계 S410에서, 디바이스는 영상으로부터 타겟 객체를 검출하기 위한 특징 맵(feature map)을 획득한다. 디바이스는 카메라를 이용하여 대상체를 촬영하거나 또는 네트워크를 통해 영상을 획득할 수 있다. '영상'은 단일 프레임의 정적 이미지(still image) 또는 적어도 하나의 프레임을 포함하는 동적 영상(video)를 의미한다. 디바이스는 정적 영상 또는 동적 영상으로부터 타겟 객체를 검출하고, 타겟 객체의 검출 과정 에서 추출되는 특징 맵을 획득할 수 있다. 여기서, '타겟 객체(target object)'는 사용자가 영상으로부터 검출 하고자 하는 관심있는 객체를 의미한다. 타겟 객체는 예를 들어, 사람의 얼굴, 헤어, 옷, 및 포즈(posture) 중 적어도 하나를 포함할 수 있다. 일 실시예에서, 디바이스는 딥 러닝(Deep Learning)을 포함하는 인공 지능 모델을 이용하여, 영상으로부 터 타겟 객체를 검출할 수 있다. 일 실시예에서, 디바이스는 컨볼루션 신경망 모델(CNN)을 이용하여 학습 을 수행함으로써 영상으로부터 타겟 객체를 검출할 수 있다. 예를 들어, 타겟 객체가 얼굴인 경우, 디바이스 는 대규모의 데이터 셋, 예를 들어 CASIA-WebFace, VGGFace/VGGFace 2, 또는 MS-Celeb-1M을 통해 동적영상으로부터 사람의 얼굴을 검출할 수 있다. 일 실시예에서, 디바이스는 VGGFace2 데이터 셋을 이용하여 얼굴 인식을 수행하도록 기 학습된 MobileNet을 포함할 수 있다. 디바이스는 타겟 객체를 검출하는 과정에서 적어도 하나의 특징 맵(feature map)을 출력할 수 있다. '특 징 맵'은 영상으로부터 타겟 객체를 검출하기 위하여 추출되는 특징 벡터를 포함하는 이미지로서, 예를 들어, 엣지 맵(edge map), 블러 이미지(blur image), 또는 원형 맵 중 적어도 하나를 포함할 수 있다. 일 실시예에서, 컨볼루션 신경망 모델을 이용하는 경우, 디바이스는 원본 영상을 기설정된 크기 및 채널(channel) 수를 갖는 필터(filter)를 이용하여 합성 곱(convolution)을 산출하고, 합성 곱을 통해 필터의 개수와 동일한 2차원 이미지 레이어(layer)를 추출하고, 2D 이미지 레이어로 구성된 적어도 하나의 특징 맵을 획득할 수 있다. 도 4에는 도시되지 않았지만, 특징 맵을 획득하는 단계(S410) 이전에 영상을 전처리(preprocessing)하는 동작이 수행될 수 있다. 디바이스는 영상의 크기를 기 설정된 크기로 조절(resize)하고, 영상의 밝기 및 대조도 (contrast)를 정규화(normalize)하는 전처리 과정을 수행할 수 있다. 단계 S420에서, 디바이스는 영상 및 특징 맵을 기 학습된(pre-trained) 모델 파라미터로 구성된 심층 신 경망 모델(Deep Neural Network)에 입력함으로써, 영상으로부터 타겟 객체를 정상적으로 인식하기 위한 압축률 을 출력한다. 일 실시예에서, 디바이스는 영상 및 영상으로부터 추출된 특징 맵을 심층 신경망 모델에 입 력으로 적용하는 학습(training)을 수행함으로써, 영상으로부터 타겟 객체를 정상적으로 인식할 수 있는 압축률 을 출력할 수 있다. '타겟 객체를 정상적으로 인식할 수 있는 압축률'은 영상으로부터의 타겟 객체에 관한 인식 오류율(error rate)이 기 설정된 오류율 미만인 경우의 압축률을 의미한다. 심층 신경망 모델은 기 저장된 학습 데이터를 이용하여 학습(training)을 수행함으로써 획득되는 인공지능 모델 이다. 일 실시예에서, 심층 신경망 모델은 단계 S410, S420이 수행되기 이전에 수행된 학습을 통해 획득된 모델 파라미터를 포함할 수 있다. 여기서, '기 학습된 모델 파라미터'는 심층 신경망 모델에 포함되는 복수의 레이어 에 관한 가중치(weight) 및 편향(bias)을 포함할 수 있다. 기 학습된 모델 파라미터는 복수의 원본 영상 및 복 수의 특징 맵을 입력으로 적용하고, 복수의 압축률 값에 관한 라벨(label)을 정답값(groundtruth)로 적용하는 지도 학습(supervised learning)을 수행함으로써, 획득할 수 있다. 기 획득된 복수의 원본 영상 각각에 대하여 타겟 객체를 정상적으로 인식할 수 있는 압축률 값을 결정하는 구체적인 실시예에 대해서는 도 5 내지 도 7에서 상세하게 설명하기로 한다. 일 실시예에서, 심층 신경망 모델은 연산을 수행하는 내부의 레이어(layer)인 복수의 은닉 레이어(hidden layer)를 포함할 수 있다. 심층 신경망 모델은 예를 들어, 컨볼루션 신경망 모델(Convolutional Neural Network; CNN), 순환 신경망 모델(Recurrent Neural Network; RNN), 제한 볼츠만 머신(Restricted Boltzmann Machine; RBM), DBN(Deep Belief Network), BRDNN(Bidirectional Recurrent Deep Neural Network) 및 심층 Q- 네트워크 (Deep Q-Networks) 중 적어도 하나를 포함할 수 있다. 그러나, 심층 신경망 모델이 전술한 예시로 한 정되는 것은 아니고, 공지의 모든 딥 러닝(Deep Learning) 기반의 신경망 모델을 포함할 수 있다. 심층 신경망 모델이 컨볼루션 신경망 모델(CNN)로 구현되는 경우, 디바이스는 기 설정된 크기 및 기 설정 된 채널 수를 갖는 필터(filter)를 이용하여 입력으로 적용된 복수의 원본 영상을 이동함(stride)으로써 특징 값들을 추출하고, 추출된 특징 값들을 포함하는 복수 개의 레이어(layer)를 획득하며, 복수 개의 레이어에 가중 치(weight)를 적용함으로써 특징 벡터 맵(feature vector map)을 획득할 수 있다. 상기 특징 벡터 맵을 획득하 는 과정에서 정류 선형 유닛(ReLU) 모델이 이용되고, 효율을 향상시키기 위하여 드롭 아웃(drop out)을 통해 학 습 모델을 정칙화(regularization)하고, 풀링(pooling) 또는 맥스 풀링(max pooling)을 수행하는 동작들이 더 추가될 수 있다. 이어서, 풀링 또는 맥스 풀링을 통해 획득된 특징값들은 fully connected layer를 통해 통합되 고, 소프트맥스(softmax), 시그모이드(sigmoid), 하이퍼볼릭 탄젠트(hyperbolic tangent)를 포함하는 활성 함 수(activation function)를 통해 압축률 값과 관련된 라벨을 출력하도록 학습될 수 있다. 단계 S430에서, 디바이스는 출력된 압축률을 이용하여 영상을 압축하고 부호화함으로써, 비트스트림 (bitstream)을 생성한다. 일 실시예에서, 디바이스는 영상을 복수의 CTU(Coding Tree Unit)으로 분할 (split)하고, 복수의 CTU 중 타겟 객체가 검출된 CTU에 대해서는 단계 S420에서 출력된 압축률을 이용하여 압축 및 부호화하고, 타겟 객체가 검출되지 않은 CTU에 대해서는 초기에 설정된 압축률을 이용하여 압축 및 부호화할 수 있다. 이에 대해서는 도 8 및 도 9에서 상세하게 설명하기로 한다. 일 실시예에서, 디바이스는 단계 S420에서 출력된 압축률의 값을 디바이스와 연결된 네트워크의 대 역폭(bandwidth)에 따라 결정되는 네트워크 압축률 값 및 인코딩 모듈(1312, 도 3 참조)에 의해 설정된 초기 압축률 값과 비교함으로서, 영상을 압축할 최종 압축률을 결정할 수 있다. 이에 대해서는 도 10에서 상세하게 설 명하기로 한다. 도 5는 본 개시의 일 실시예에 따른 디바이스가 원본 영상으로부터 타겟 객체를 정상적으로 인식하기 위 한 압축률을 결정하는 방법을 도시한 흐름도이다. 도 5에 도시된 단계(S500)는 도 4의 단계 S410이 수행되기 이 전의 시점에 수행된다. 단계 S510에서, 디바이스는 기 획득된 원본 영상을 기 설정된 압축률로 압축하고 부호화 및 복호화함으로 써, 복원 영상을 생성한다. 여기서, '원본 영상(Raw image)'는 카메라를 통해 촬영된 영상 또는 네트워크를 통 해 획득한 영상으로서, 압축되지 않은 비압축 영상 데이터이다. 일 실시예에서, 원본 영상을 압축하기 위한 기 설정된 압축률은 인코딩 모듈(1312, 도 3 참조)에 의해 초기 설정된(initially set) 압축률을 의미할 수 있다. 일 실시예에서, 디바이스는 인코더(1310, 도 3 참조)를 이용하여 기 설정된 압축률로 원본 영상을 압축하 고, 부호화 및 복호화함으로써 복원 영상을 생성할 수 있다. 인코더는 예를 들어, H.264/AVC 및 HEVC(H.265)를 포함하는 동적 영상 압축 표준 규격 중 적어도 하나를 이용하여 상기 원본 영상을 압축하고, 부 호화 및 복호화를 수행함으로써 복원 영상을 생성할 수 있다. 다른 실시예에서, 인코더는 예를 들어, JPEG(Joint Photographic Coding Experts Group), JPEG-2000, JPEG- XR, WebP 등과 같은 정적 영상 압축 표준 규격 중 적어도 하나를 이용하여 원본 영상을 압축하고, 부호화 및 복호화를 수행함으로써 복원 영상을 생성할 수 있다. 단계 S520에서, 디바이스는 원본 영상으로부터 타겟 객체(target object)를 검출(detect)하고, 검출된 타 겟 객체로부터 제1 특징 벡터(feature vector)를 추출(extract)한다. '타겟 객체'는 예를 들어, 사람의 얼굴, 헤어 스타일, 옷, 및 포즈(posture) 중 적어도 하나를 포함할 수 있다. 일 실시예에서, 디바이스는 공지 의 영상 처리 기술 또는 딥 러닝을 포함하는 인공 지능 모델을 이용하여 원본 영상으로부터 타겟 객체를 인식하 고, 인식된 타겟 객체로부터 제1 특징 벡터를 추출할 수 있다. 일 실시예에서, 디바이스의 프로세서(1200, 도 3 참조)는 컨볼루션 신경망 모델(Convolution Neural Network; CNN)을 이용하여 학습을 수행함으로써 원본 영상으로부터 타겟 객체를 검출할 수 있다. 프로세서 는 컨볼루션 신경망 모델을 통해 기 학습된 모델 파라미터를 이용하여 원본 영상으로부터 타겟 객체를 검 출할 수 있다. 예를 들어, 타겟 객체가 얼굴인 경우, 프로세서은 대규모의 데이터 셋, 예를 들어 CASIA- WebFace, VGGFace/VGGFace 2, 또는 MS-Celeb-1M을 통해 원본 영상으로부터 사람의 얼굴을 검출할 수 있다. 일 실시예에서, 프로세서는 공지의 이미지 처리 기술 또는 딥 러닝을 포함하는 인공 지능 모델을 이용하 여, 타겟 객체의 이미지로부터 제1 특징 벡터를 추출할 수 있다. 예를 들어, 프로세서는 ICA(Independent Component Analysis) 또는 PCA(Principle Component Analysis) 방법을 이용하여 타겟 객체 이미지로부터 제1 특징 벡터를 추출할 수 있다. 제1 특징 벡터는 예를 들어, 사람의 얼굴의 눈, 코, 입과 같은 랜드마크에 대응되 는 특징값들을 포함하는 벡터일 수 있다. 그러나, 이에 한정되는 것은 아니고, 제1 특징 벡터는 사람의 헤어 스 타일, 옷 차림, 또는 특정 자세로부터 추출된 적어도 하나의 키 포인트(key-points)에 대응되는 특징값들을 포 함하는 벡터일 수 있다. 일 실시예에서, 프로세서는 컨볼루션 신경망 모델을 이용하여 타겟 객체 이미지로부터 제1 특징 벡터를 추출할 수 있다. 예를 들어, 프로세서는 기설정된 크기 및 기설정된 채널 수를 갖는 커널(kernel)을 이용 하여 타겟 객체 이미지 상을 이동함(stride)으로써 특징값들을 추출하고, 추출된 특징값들을 포함하는 복수 개 의 레이어(layer)를 획득하고, 복수 개의 레이어에 가중치(weight)를 적용함으로써 특징 벡터 맵(feature vector map)을 획득할 수 있다. 특징 벡터 값을 획득하는 과정에서 정류 선형 유닛(ReLU) 모델이 이용되고, 효 율을 향상시키기 위하여 드롭 아웃(drop out)을 통해 특징값들을 정칙화(regularization)하고, 풀링(pooling) 또는 맥스 풀링(max pooling)을 수행하는 동작들이 더 추가될 수 있다. 프로세서은 예를 들어, MobileNet v1/v2 과 같은 컨볼루션 신경망 모델을 이용하여 원본 영상에서 검출된 타겟 객체의 이미지로부터 제1 특징 벡 터를 추출할 수 있다. 단계 S530에서, 디바이스는 복원 영상으로부터 타겟 객체(target object)를 검출(detect)하고, 검출된 타 겟 객체로부터 제2 특징 벡터(feature vector)를 추출(extract)한다. 단계 S530은 원본 영상이 아닌 '복원 영상'으로부터 타겟 객체를 인식하고, 제2 특징 벡터를 추출하는바, 단계 S520과 비교하면 타겟 객체의 인식 대 상 및 제2 특징 벡터가 추출되는 대상이 되는 영상의 차이만 있을 뿐 동작 방법은 동일한다. 따라서, 단계 S520 과 중복되는 설명은 생략한다.단계 S540에서, 디바이스는 원본 영상으로부터 검출된 타겟 객체를 포함하는 제1 관심 영역과 복원 영상 으로부터 검출된 타겟 객체를 포함하는 제2 관심 영역 간의 중첩도 및 제1 특징 벡터와 제2 특징 벡터 간의 유 사도에 기초하여, 원본 영상으로부터 타겟 객체가 정상적으로 인식되었는지 여부를 판단한다. 일 실시예에서, 디바이스의 프로세서는 원본 영상으로부터 검출된 타겟 객체의 바운딩 박스(bounding box)를 식별 하고, 식별된 바운딩 박스 내에 포함된 영역을 제1 관심 영역(Region of Interest)으로 설정할 수 있다. 마찬가 지로, 프로세서는 복원 영상으로부터 검출된 타겟 객체의 바운딩 박스를 식별하고, 바운딩 박스 내에 포 함된 영역을 제2 관심 영역으로 설정할 수 있다. 프로세서는 제1 관심 영역과 제2 관심 영역 간의 중첩도를 산출하고, 제1 특징 벡터와 제2 특징 벡터 간 의 유사도를 산출할 수 있다. 일 실시예에서, 프로세서는 산출된 중첩도를 기 설정된 제1 임계치와 비교 하고, 산출된 유사도를 기 설정된 제2 임계치와 비교하며, 비교 결과에 기초하여 복원 영상으로부터 타겟 객체 가 정상적으로 인식되었는지 여부를 판단할 수 있다. 여기서 '압축률'은 원본 영상을 표준 규격에 매칭되는 방법을 이용하여 인코딩하기 위한 영상 압축 파라미터를 의미한다. 압축률은 표준 규격 마다 다양한 형태로 존재할 수 있다. 예를 들어, 정적 영상을 압축하는 표준 규 격(예를 들어, JPEG(Joint Photographic Coding Experts Group), JPEG-2000, JPEG- XR, WebP 등)에서는 영상의 압축률을 결정하기 위하여 양자화 테이블(Quantization Table)이 이용될 수 있다. 예를 들어, 동적 영상을 재생 하기 위한 표준 규격(예를 들어, H. 264/AVC, HEVC(H.265) 등)에서는 양자화 파라미터(Quantization Parameter)를 이용하여 영상의 압축률이 결정될 수 있다. '양자화 파라미터'는 동적 영상의 압축과 관련된 표준 규격, 예를 들어 H.264/AVC, 또는 HEVC(H.265)에서 정의 되는 변환 계수를 양자화하는 정도를 나타내는 파라미터로서, 양자화 파라미터에 의해 영상의 압축률이 결정될 수 있다. 일 실시예에서, 압축률은 양자화 파라미터의 값에 비례한다. 예를 들어, 양자화 파라미터의 값이 큰 경우, 압축률이 높고, 양자화 파라미터의 값이 작은 경우, 압축률이 낮다. 일 실시예에서, 프로세서는 중첩도가 제1 임계치 이하이거나, 또는 유사도가 제2 임계치 이하인 경우, 복 원 영상으로부터 타겟 객체가 정상적으로 인식되지 않았다고 판단할 수 있다. 일 실시예에서, 프로세서는 중첩도가 제1 임계치를 초과하고, 유사도가 제2 임계치를 초과하는 경우, 복 원 영상으로부터 타겟 객체가 정상적으로 인식되었다고 판단할 수 있다. 디바이스의 프로세서가 중첩도를 제1 임계치와 비교하고, 유사도를 제2 임계치와 비교함으로써 타 겟 객체가 정상적으로 인식되었는지 여부를 판단하는 구체적인 실시예는 도 6에서 상세하게 설명하기로 한다. 단계 S550에서, 디바이스는 타겟 객체의 인식 여부 판단 결과에 기초하여 압축률을 결정한다. 일 실시예 에서, 디바이스는 복원 영상으로부터 타겟 객체가 정상적으로 인식되지 않았다고 판단된 경우, 압축률의 값을 기존 복원 영상을 압축하고 부호화하는데 사용되었던 압축률 보다 더 낮은 값으로 변경할 수 있다. 일 실 시예에서, 디바이스는 복원 영상으로부터 타겟 객체가 정상적으로 인식되었다고 판단된 경우, 단계 S510 에서 수신된 복원 영상을 생성하는데 이용된 초기에 설정된 압축률을 최종 압축률로 결정할 수 있다. 디바이스 가 타겟 객체의 인식 여부 판단 결과에 기초하여 압축률을 변경하거나, 또는 최종 압축률로 결정하는 구 체적인 실시계에 대해서는 도 7에서 상세하게 설명하기로 한다. 일 실시예에서, 디바이스는 도 5에 도시된 단계 S510 내지 단계 S550을 포함하는 단계 S500을 기 획득된 복수의 원본 영상 각각에 대하여 수행함으로써, 복수의 원본 영상 각각으로부터 타겟 객체를 정상적으로 인식하 기 위한 압축률 정보를 획득할 수 있다. 일 실시예에서, 디바이스는 복수의 원본 영상으로부터 타겟 객체 를 검출하는 과정에서 추출되는 복수의 특징 맵 및 단계 S500을 통해 결정된 복수의 압축률 값에 관한 정보를 학습 데이터 저장부(1410, 도 3 참조)에 저장할 수 있다. 일 실시예에서, 디바이스는 학습 데이터 저장부 에 저장된 데이터, 즉 복수의 원본 영상, 복수의 특징 맵 및 복수의 압축률 값에 관한 데이터를 이용하여 심층 신경망 모델(1340, 도 3 참조)을 학습 할 수 있다. 도 6은 본 개시의 일 실시예에 따른 디바이스가 복원 영상에서의 타겟 객체 인식 여부를 판단하는 방법을 도시한 흐름도이다. 도 6에 도시된 단계 S610 내지 단계 S650은 도 5에 도시된 단계 S540을 구체화한 단계들이다. 도 6에 도시된 단 계 S610 및 단계 S620은 도 5에 도시된 단계 S530이 수행된 이후에 수행된다. 단계 S610에서, 디바이스는 제1 관심 영역과 제2 관심 영역 간의 중첩도를 산출한다. 일 실시예에서, 디 바이스는 원본 영상에서 검출된 타겟 객체가 포함되는 제1 관심 영역의 바운딩 박스(bounding box)의 위 치 좌표값 정보 및 복원 영상에서 검출된 타겟 객체가 포함되는 제2 관심 영역의 바운딩 박스의 위치 좌표값 정 보를 각각 획득하고, 획득된 위치 좌표값을 이용하여 제1 관심 영역과 제2 관심 영역이 겹치는 정도를 나타내는 중첩도를 산출할 수 있다. 일 실시예에서, 디바이스의 프로세서(1200, 도 3 참조)는 위치 좌표값 정보를 이용하여 중첩도를 계산하는 IOU(Intersection Over Union) 방식을 이용하여 제1 관심 영역과 제2 관심 영역 간 의 중첩도를 계산할 수 있다. 단계 S620에서, 디바이스는 제1 특징 벡터와 제2 특징 벡터 간의 유사도를 산출한다. 디바이스의 프로세서는 벡터 간의 상관 관계(correlation)를 계산하는 공지의 방법을 이용하여, 원본 영상에서 검출 된 타겟 객체의 이미지로부터 추출된 제1 특징 벡터와 복원 영상에서 검출된 타겟 객체의 이미지로부터 추출된 제2 특징 벡터 간의 유사도를 계산할 수 있다. 도 6에서, 단계 S610과 단계 S620은 동시에 독립적으로 수행될 수 있다. 그러나, 이에 한정되는 것은 아니고, 단계 S610이 단계 S620 보다 먼저 수행되거나, 또는 단계 S620이 단계 S610 보다 먼저 수행될 수도 있다. 단계 S630에서, 디바이스는 단계 S610에서 산출된 중첩도를 기 설정된 제1 임계치(α)와 비교하고, 단계 S620에서 산출된 유사도를 기 설정된 제2 임계치(β)와 비교할 수 있다. 예를 들어, 제1 임계치(α)의 값은 0.8 이고, 제2 임계치(β)의 값은 0.5일 수 있지만, 이에 한정되는 것은 아니다. 중첩도가 제1 임계치(α)를 초과하고, 유사도가 제2 임계치(β)를 초과하는 경우(단계 S640), 디바이스는 복원 영상으로부터 타겟 객체가 정상적으로 인식되었다고 판단한다. 복원 영상에서 타겟 객체가 정상적으로 인 식된 경우는 도 7의 ⓐ와 연결되고, 도 6의 단계 S640이 수행된 이후에는 도 7의 단계 S710이 수행될 수 있다. 중첩도가 제1 임계치(α) 이하 이거나, 또는 유사도가 제2 임계치(β) 이하인 경우(단계 S650), 디바이스(100 0)는 복원 영상으로부터 타겟 객체가 정상적으로 인식되지 않았다고 판단한다. 복원 영상에서 타겟 객체가 정상 적으로 인식되지 않은 경우는 도 7의 ⓑ와 연결되고, 도 6의 단계 S650이 수행된 이후에는 도 7의 단계 S720이 수행될 수 있다. 도 7은 본 개시의 일 실시예에 따른 디바이스가 타겟 객체의 인식 여부 판단 결과에 기초하여, 영상의 압 축률을 결정하는 방법을 도시한 흐름도이다. 도 7에 도시된 단계 S710 내지 단계 S730은 도 5에 도시된 단계 S550을 구체화한 단계들이다. 도 7에 도시된 단 계 S510 내지 S540은 도 5에 도시된 단계들과 동일하다. 단계 S710에서, 디바이스는 단계 S510에서 복원 영상을 생성하는데 이용되었던 압축률, 예를 들어 양자화 파라미터의 값을 최종 압축률로 결정할 수 있다. 단계 S710은 ⓐ를 통해 연결된 도 6의 단계 S640이 수행된 이 후에 수행될 수 있다. 단계 S720에서, 디바이스는 압축률을 낮은 값으로 변경한다. 단계 S720은 ⓑ를 통해 연결된 도 6의 단계 S650이 수행된 이후에 수행될 수 있다. 일 실시예에서, 디바이스는 단계 S510에서 복원 영상을 생성하는 데 이용되었던 압축률 보다 더 낮은 값으로 압축률을 조절할 수 있다. 예를 들어, 디바이스의 프로세서 (1200, 도 3 참조)는 복원 영상을 생성하는데 사용되었던 양자화 파라미터의 값을 더 낮은 값으로 변경할 수 있 다. 단계 S730에서, 디바이스는 변경된 압축률 정보를 인코딩 모듈(1312, 도 3 참조)에 제공한다. 단계 S730 이후, 디바이스는 단계 S510, 단계 S520, 단계 S530, 단계 S540, 및 단계 S550을 반복 수행한 다. 일 실시예에서, 디바이스는 인코딩 모듈과 관련된 명령어들 또는 프로그램 코드를 실행함으로 써, 변경된 압축률로 원본 영상을 압축하고, 부호화 및 복호화를 수행하고, 이를 통해 복원 영상을 생성할 수 있다. 디바이스는 복원 영상을 생성하는 동작(단계 S510), 원본 영상으로부터 타겟 객체를 인식하고, 제1 특징 벡터를 추출하는 동작(단계 S520), 복원 영상으로부터 타겟 객체를 인식하고, 제2 특징 벡터를 추출하는 동작(단계 S530), 및 중첩도 및 유사도에 기초하여 타겟 객체가 정상적으로 인식되었는지 여부를 판단하는 동작 (단계 S540), 및 압축률을 결절하는 동작(단계 S550)을 적어도 1회 이상 반복적으로 수행할 수 있다. 디바이스 는 중첩도가 제1 임계치(α)를 초과하고, 유사도가 제2 임계치(β)를 초과할 때까지 단계 S510, S520, S530, S540, 및 S550을 반복적으로 수행할 수 있다. 도 8은 본 개시의 일 실시예에 따른 디바이스가 CTU(Coding Tree Unit) 별로 서로 다른 압축률을 결정하 는 실시예를 도시한 도면이다. 도 8을 참조하면, 디바이스는 입력 영상을 기설정된 영상 크기인 CTU 단위로 분할(split)할 수 있다. 일 실시예에서, CTU는 기설정된 픽셀의 개수를 포함할 수 있다. 예를 들어, CTU는 16×16 또는 64×64의 픽셀 수로 구성될 수 있으나, 이에 한정되는 것은 아니다. 디바이스의 프로세서(1200, 도 3 참조)는 입력 영상이 복수의 CTU(800-1 내지 800-n)를 포함하도록 분할할 수 있다. 도 8에는 복수의 CTU(800-1 내지 800-n)이 모두 동일한 크기인 것으로 도시되었지만, 이에 한정되는 것은 아니다. 일 실시예에서, 복수의 CTU(800-1 내지 800-n) 각각은 서로 다른 개수의 픽셀을 포함하고, 서로 다른 크기로 형성될 수 있다. 디바이스는 입력 영상으로부터 타겟 객체를 검출할 수 있다. 일 실시예에서, 디바이스의 프로 세서는 타겟 객체 검출 모듈과 관련된 명령어들 또는 프로그램 코드를 실행함으로써, 입력 영상 으로부터 타겟 객체를 검출할 수 있다. '타겟 객체'는 예를 들어, 사람의 얼굴, 헤어 스타일, 옷, 및 포즈 중 적어도 하나를 포함할 수 있으나, 이에 한정되는 것은 아니다. 도 8에 도시된 실시예에서, 타겟 객체는 사람 의 얼굴이고, 프로세서는 타겟 객체 검출 모듈을 이용하여 입력 영상으로부터 적어도 하나의 타겟 객체(801, 802, 803)를 검출할 수 있다. 프로세서는 검출된 타겟 객체의 바운딩 박스(bounding box)를 식별하고, 식별된 바운딩 박스의 위치 좌표 값을 획득할 수 있다. 일 실시예에서, 프로세서는 적어도 하나의 타겟 객체(801, 802, 803) 각각으로부터 식별된 바운딩 박스를 적어도 하나의 관심 영역(R1, R2, R3)으로 설정할 수 있다. 프로세서는 복수의 CTU(800-1 내지 800-n) 중 타겟 객체가 검출된 적어도 하나의 CTU를 식별할 수 있다. 일 실시예에서, 프로세서는 중첩도 산출 모듈과 관련된 명령어들 또는 프로그램 코드를 실행하여, 적어도 하나의 관심 영역(R1, R2, R3) 각각의 좌표 정보를 이용하여 복수의 CTU(800-1 내지 800-n)와의 중첩도를 산출할 수 있다. 일 실시예에서, 프로세서는 좌표값 정보를 이용하여 중첩도를 계산하는 IOU(Intersection Over Union) 방식을 이용하여 적어도 하나의 관심 영역(R1, R2, R3)과 복수의 CTU(800-1 내지 800-n) 간의 중첩도를 계산할 수 있다. IOU 방식을 이용하는 중첩도 계산에서, IOU 값이 1인 경우, 두 개의 이 미지가 완전히 겹쳐지는 것을 의미하고, IOU 값이 0인 경우, 두 개의 이미지가 전혀 겹쳐지지 않음을 의미한다. 그러나, 이에 한정되는 것은 아니고, 프로세서는 좌표값 사이의 오차의 합을 계산함으로써, 중첩도를 산 출하는 오차 계산 방식을 이용할 수도 있다. 프로세서는 복수의 CTU(800-1 내지 800-n) 중 산출된 중첩도 값이 0 이상인 CTU, 즉 중첩이 되는 적어도 하나의 CTU를 식별함으로써, 타겟 객체가 포함되는 적어도 하나의 CTU를 식별할 수 있다. 도 8에 도시된 실시예 에서, 프로세서는 입력 영상에 포함되는 복수의 CTU(800-1 내지 800-n) 중 제1 관심 영역(R1)의 좌 표 정보(좌표 값 및 좌표 크기에 관한 정보 포함)에 기초하여 중첩되는 적어도 하나의 CTU(800-9, 800-10, 800- 17, 800-18)를 식별할 수 있다. 마찬가지로, 프로세서는 복수의 CTU(800-1 내지 800-n) 중 제2 관심 영 역(R2)의 좌표 정보에 기초하여 중첩되는 적어도 하나의 CTU(800-20, 800-21, 800-28, 800-29)를 식별하고, 제3 관심 영역(R3)의 좌표 정보에 기초하여 중첩되는 적어도 하나의 CTU(800-14, 800-15, 800-22, 800-23)를 식별할 수 있다. 프로세서는 복수의 CTU(800-1 내지 800-n) 중 타겟 객체가 검출된 적어도 하나의 CTU(도 8에 도시된 실시 예에서는 800-9, 800-10, 800-14, 800-15, 800-17, 800-18, 800-20, 800-21, 800-22, 800-23, 800-28, 800- 29)를 심층 신경망 모델에 입력하는 학습(training)을 수행함으로써, 타겟 객체를 정상적으로 인식할 수 있는 압축률을 획득할 수 있다. 타겟 객체가 검출된 적어도 하나의 CTU를 제1 CTU라고 하면, 도 8에 도시 된 실시예에서 디바이스는 제1 CTU에 적용되는 압축률(QP)을 심층 신경망 모델을 통해 출력된 압축률의 값, 예를 들어 20으로 결정할 수 있다. 프로세서는 복수의 CTU(800-1 내지 800-n) 중 타겟 객체가 검출되지 않은 적어도 하나의 CTU를 제2 CTU로 결정하고, 적어도 하나의 제2 CTU에 대해서는 심층 신경망 모델로부터 출력되는 압축률 이 아닌, 기 설정된 초기 압축률을 적용할 수 있다. 도 8에 도시된 실시예에서, 프로세서는 적어도 하나 의 제2 CTU에 대해서는 초기 설정된 압축률의 값(QP)인 30을 적용할 수 있다. 도 9는 본 개시의 일 실시예에 따른 디바이스가 CTU(Coding Tree Unit) 별로 서로 다른 압축률을 결정하 는 방법을 도시한 흐름도이다.단계 S910에서, 디바이스는 입력 영상으로부터 적어도 하나의 타겟 객체를 검출한다. '타겟 객체'는 예를 들어, 사람의 얼굴, 헤어 스타일, 옷, 및 포즈 중 적어도 하나를 포함할 수 있으나, 이에 한정되는 것은 아니다. 일 실시예에서, 디바이스는 공지의 영상 처리 기술 또는 딥 러닝을 포함하는 인공 지능 모델을 이용하여 입력 영상으로부터 타겟 객체를 검출할 수 있다. 일 실시예에서, 디바이스의 프로세서(1200, 도 3 참조)는 컨볼루션 신경망 모델(Convolution Neural Network; CNN)을 이용하여 학습을 수행함으로써 입력 영상으로부터 타겟 객체를 검출할 수 있다. 프로세서 는 컨볼루션 신경망 모델을 통해 기 학습된 모델 파라미터를 이용하여 입력 영상으로부터 타겟 객체를 검 출할 수 있다. 예를 들어, 타겟 객체가 얼굴인 경우, 프로세서은 대규모의 데이터 셋, 예를 들어 CASIA- WebFace, VGGFace/VGGFace 2, 또는 MS-Celeb-1M을 통해 입력 영상으로부터 사람의 얼굴을 검출할 수 있다. 단계 S912에서, 디바이스는 검출된 적어도 하나의 타겟 객체 각각의 좌표 정보를 획득한다. 일 실시예에 서, 디바이스는 입력 영상으로부터 검출된 적어도 하나의 타겟 객체의 바운딩 박스(bounding box)를 식별 하고, 식별된 바운딩 박스의 위치 좌표값 및 좌표 크기에 관한 정보를 획득할 수 있다. 일 실시예에서, 디바이스의 프로세서는 적어도 하나의 타겟 객체 각각으로부터 식별된 바운딩 박스 를 적어도 하나의 관심 영역으로 설정할 수 있다. 단계 S920에서, 디바이스는 입력 영상을 CTU(Coding Tree Unit) 단위로 분할(split)한다. 일 실시예에서, CTU는 기설정된 픽셀의 개수를 포함할 수 있다. 예를 들어, CTU는 16×16 또는 64×64의 픽셀 수로 구성될 수 있으나, 이에 한정되는 것은 아니다. 디바이스의 프로세서는 입력 영상이 복수의 CTU를 포함하도록 분할 수 있다. 복수의 CTU 각각은 동일한 크기일 수 있지만, 이에 한정되지 않는다. 일 실시예에서, 프로세서는 입력 영상을 서로 다른 크기의 복수의 CTU로 분할할 수 있다. 단계 S910과 단계 S920은 동시에 독립적으로 수행될 수 있다. 그러나, 이에 한정되는 것은 아니고, 단계 S910이 단계 S920 보다 먼저 수행되거나, 또는 단계 S920이 단계 S910 보다 먼저 수행될 수도 있다. 단계 S930에서, 디바이스는 적어도 하나의 타겟 객체의 바운딩 박스의 좌표 정보에 기초하여, 복수의 CTU 와의 중첩도를 산출한다. 일 실시예에서, 디바이스의 프로세서는 좌표값 정보를 이용하여 중첩도를 계산하는 IOU(Intersection Over Union) 방식을 이용하여 적어도 하나의 타겟 객체의 바운딩 박스와 복수의 CTU 간의 중첩도를 계산할 수 있다. 그러나, 이에 한정되는 것은 아니고, 프로세서는 좌표값 사이의 오차의 합을 계산함으로써, 중첩도를 산출하는 오차 계산 방식을 이용할 수도 있다. 오차 계산 방식을 이용하는 경우, 프로세서는 적어도 하나의 타겟 객체의 바운딩 박스 각각의 위치 좌표값과 복수의 CTU 각각의 위치 좌표 값 간의 오차를 계산하고, 오차의 제곱 합을 계산함으로써, 중첩도를 산출할 수 있다. 단계 S940에서, 디바이스는 산출된 중첩도가 0을 초과하였는지 확인한다. IOU(Intersection Over Union) 방식을 이용하여 중첩도를 산출하는 실시예에서, 산출된 중첩도의 값이 1인 경우, 두 개의 이미지가 완전히 겹 쳐지는 것을 의미하고, 중첩도의 값이 0인 경우, 두 개의 이미지가 전혀 겹쳐지지 않음을 의미한다. 예를 들어, 중첩도의 값이 0.5 인 경우, 두 개의 이미지의 2/3 가 겹쳐지는 것을 의미한다. 중첩도가 0을 초과하는 경우(단계 S950), 디바이스는 타겟 객체가 포함되는 적어도 하나의 제1 CTU를 식 별한다(identify). 일 실시예에서, 디바이스는 복수의 CTU 중 적어도 하나의 타겟 객체의 바운딩 박스와 중첩되는 적어도 하나의 제1 CTU를 식별할 수 있다. 적어도 하나의 제1 CTU는 적어도 하나의 타겟 객체가 검출 된 영역에 해당되는 CTU일 수 있다. 단계 S960에서, 디바이스는 기 획득된(pre-trained) 심층 신경망 모델에 적어도 하나의 제1 CTU를 입력함 으로써, 적어도 하나의 제1 CTU에 관한 압축률 값을 획득한다. 일 실시예에서, 디바이스의 프로세서 (1200, 도 3 참조)는 기 학습된 모델 파라미터로 구성된 심층 신경망 모델(1340, 도 3 참조)에 적어도 하나의 제1 CTU를 입력하고, 심층 신경망 모델을 통한 학습을 통해 적어도 하나의 제1 CTU로부터 타겟 객체를 정 상적으로 인식할 수 있는 압축률 값을 획득할 수 있다. 단계 S970에서, 디바이스는 획득된 압축률 값을 적어도 하나의 제1 CTU에 관한 압축률 값으로 결정한다. 중첩도가 0인 경우(단계 S952), 디바이스는 타겟 객체가 포함되지 않은 적어도 하나의 제2 CTU를 식별한 다(identify). 일 실시예에서, 디바이스는 복수의 CTU 중 적어도 하나의 타겟 객체의 바운딩 박스와 중첩 되지 않는 적어도 하나의 제2 CTU를 식별할 수 있다. 적어도 하나의 제2 CTU는 적어도 하나의 타겟 객체가 검출 되지 않은 영역에 해당되는 CTU일 수 있다. 예를 들어, 타겟 객체가 사람의 얼굴인 경우, 적어도 하나의 제2CTU는 사람의 몸, 팔, 다리 등 얼굴을 제외한 다른 신체 부위와 관련되거나, 또는 배경 이미지에 해당되는 영역 에 배치된 CTU일 수 있다. 단계 S972에서, 디바이스는 적어도 하나의 제2 CTU에 대하여 초기 설정된 압축률 값을 적용한다. 초기 설 정된 압축률 값은 인코딩 모듈(1312, 도 3 참조)에 의해 기 설정된 압축률 값을 의미한다. 일 실시예에서, 초기 설정된 압축률 값은 사용자 입력에 따라 결정될 수 있다. 단계 S980에서, 디바이스는 압축률 값을 이용하여 적어도 하나의 제1 CTU 및 적어도 하나의 제2 CTU에 관 하여 압축 및 부호화함으로써, 비트스트림을 생성한다. 일 실시예에서, 디바이스는 인코더(1310, 도 3 참 조)를 이용하여 영상을 압축하고, 부호화할 수 있다. 인코더는 예를 들어, H.264/AVC 및 HEVC(H.265)를 포함하는 동적 영상 압축 표준 규격 중 적어도 하나를 이용하여 상기 영상을 압축하고, 부호화함으로써 비트스 트림을 생성할 수 있다. 다른 실시예에서, 인코더는 예를 들어, JPEG(Joint Photographic Coding Experts Group), JPEG-2000, JPEG- XR, WebP 등과 같은 정적 영상 압축 표준 규격 중 적어도 하나를 이용하여 영상을 압축하고, 부호화할 수 있다. 디바이스는 적어도 하나의 제1 CTU에 대해서는 단계 S970에서 결정 된 압축률 값을 적용하여 압축하고, 적어도 하나의 제2 CTU에 대해서는 단계 S972에서 적용된 초기 설정된 압축 률 값을 이용하여 압축할 수 있다. 도 8 및 도 9에 도시된 실시예에서, 디바이스는 입력 영상(800, 도 8 참조)를 복수의 CTU(800-1 내지 800-n, 도 8 참조)으로 분할하고, 복수의 CTU(800-1 내지 800-n) 중 타겟 객체가 검출된 적어도 하나의 제1 CTU(810, 도 8 참조)에만 심층 신경망 모델(1340, 도 3 참조)을 통해 출력된 압축률을 적용하고, 타겟 객체가 검출되지 않은 적어도 하나의 제2 CTU(820, 도 8 참조)에는 초기 설정된 압축률을 적용함으로써, 타겟 객체의 인식 정확도를 향상시킬 수 있다. 또한, 복수의 CTU(800-1 내지 800-n) 중 타겟 객체가 검출되지 않은 적어도 하나의 제2 CTU의 경우, 상대적으로 중요도가 떨어지는 배경 이미지일 가능성이 높다. 따라서, 본 개시의 디바이스는 타겟 객체가 검출된 적어도 하나의 제1 CTU의 경우보다 더 높은 압축률로 압축함으로써 압축 후의 데이터 용량을 감소시킬 수 있을 뿐만 아니라, 압축 및 부호화의 연산량을 감소시키고, 처리 속도 (processing speed)를 향상시킬 수 있다. 도 10은 본 개시의 일 실시예에 따른 디바이스가 심층 신경망 모델을 통해 결정된 압축률 값을 네트워크 대역폭에 따른 압축률 값 및 초기 설정된 압축률 값과 비교하고, 비교 결과에 기초하여 최종 압축률 값을 결정 하는 방법을 도시한 흐름도이다. 도 10에 도시된 단계 S1010 내지 단계 S1070은 도 4에 도시된 단계 S420이 수행된 이후 수행되는 단계들이다. 단계 S1070이 수행된 이후에는 도 4에 도시된 단계 S430이 수행될 수 있다. 단계 S1010에서, 디바이스는 네트워크 대역폭에 기초하여 압축률 값 QPNW에 관한 정보를 획득한다. 일 실 시예에서, 압축률 값 QPNW은 디바이스와 연결된 네트워크 환경, 예를 들어 네트워크 대역폭에 따라 송수신 가능한 비트레이트(bitrate)에 기초하여 결정될 수 있다. 디바이스는, 디바이스와 연결된 네트워크 의 대역폭을 측정하고, 측정된 네트워크 대역폭에 따른 압축률 값 QPNW에 관한 정보를 획득할 수 있다. 단계 S1020에서, 디바이스는 심층 신경망 모델에 의해 결정된 압축률 값인 QPdet 및 초기 설정된 압축률 값인 QPinit을 네트워크 대역폭에 따라 결정되는 압축률 값인 QPNW과 비교한다. 일 실시예에서, 디바이스는 심층 신경망 모델(1340, 도 3 참조)에 영상을 입력함으로써, 출력된 압축률 값인 QPdet와 인코딩 모듈(1312, 도 3 참조)에 의해 초기 설정된 압축률 값인 QPinit을 단계 S1010에서 획득된 네트워크 대역폭에 따른 압축률 값인 QPNW과 비교할 수 있다. 단계 S1030에서, 디바이스는 심층 신경망 모델에 의해 결정된 압축률 값인 QPdet가 초기 설정된 압 축률 값인 QPinit 이상이고, 네트워크 대역폭에 따라 결정된 압축률 값인 QPNW가 QPinit 이하인지 여부를 확인한다 (identify). QPdet 값이 QPinit 이상이고, QPNW의 값이 QPinit 이하인 경우(단계 S1032), 디바이스는 심층 신경망 모델 을 통해 출력된 압축률 값인 QPdet를 영상을 압축하고 부호화할 최종 압축률 값으로 결정한다. 심층 신경 망 모델에 의해 결정된 압축률 값인 QPdet가 초기 설정된 압축률 값인 QPinit 보다 큰 경우, 영상으로부터타겟 객체를 정상적으로 인식할 수 있는 압축률 값(QPdet)이 초기 설정된 압축률 값(QPinit) 보다 크므로 타겟 객 체의 인식이 가능하고, 초기 설정된 압축률 값(QPinit)이 네트워크 대역폭에 따라 결정되는 압축률 값(QPNW) 보다 는 크므로, 네트워크를 통해 비트스트림을 전송하는데에도 문제가 없기 때문에, 디바이스는 심층 신경망 모델에 의해 결정된 압축률 값인 QPdet을 최종 압축률 값으로 결정할 수 있다. QPdet 값이 QPinit 이하이고, QPNW의 값이 QPinit을 초과하는 것으로 확인된 경우(단계 S1040), 디바이스는 심층 신경망 모델을 통해 출력된 압축률 값인 QPdet가 초기 설정된 압축률 값인 QPinit 이하인지 여부를 확 인한다. QPdet의 값이 QPinit 이하인 것으로 확인된 경우(단계 S1042), 디바이스는 영상에 포함되는 복수의 CTU 중 타겟 객체가 검출된 적어도 하나의 CTU에 관한 압축률의 값을 QPdet로 결정한다. QPdet의 값이 QPinit의 값을 초과하는 것으로 확인된 경우(단계 S1050), 디바이스는 네트워크 대역폭에 따 라 결정되는 압축률 값인 QPNW가 초기 설정된 압축률 값인 QPinit의 값을 초과하는지 여부를 확인한다. QPNW의 값이 QPinit을 초과하는 것으로 확인된 경우(단계 S1052), 디바이스는 네트워크 대역폭에 따라 결정 되는 압축률 값인 QPNW를 타겟 객체가 포함되는 적어도 하나의 CTU에 관한 압축률로 결정한다. QPNW가 초기 설정 된 압축률 값인 QPinit 보다 큰 경우, 네트워크를 통해 비트스트림을 전송하기 위해서는 네트워크 대역폭에 따른 압축률 값인 QPNW로 영상을 압축해야 하기 때문이다. 단계 S1060에서, 디바이스는 영상에 포함되는 복수의 CTU 중 타겟 객체가 검출되지 않은 적어도 하나의 CTU의 압축률의 값을 조정한다(adjust). 타겟 객체가 검출된 적어도 하나의 CTU에 관한 압축률이 단계 S1042에 서는 QPdet로 결정되고, 단계 S1052에서는 QPNW로 결정되었는바, 디바이스는 초기 설정된 압축률의 값인 QPinit로 영상을 압축하는 경우와 비교하여 증가된 비트레이트(bitrate)를 보상하기 위하여, 타겟 객체가 검출되 지 않은 적어도 하나의 CTU에 관한 압축률의 값을 조정할 수 있다. 일 실시예에서, 디바이스는 영상에 포 함되는 복수의 CTU 중 타겟 객체가 검출되지 않은 적어도 하나의 CTU에 적용되는 압축률의 값을 기존에 설정된 압축률의 값보다 높게 변경할 수 있다. QPNW의 값이 QPinit 이하인 경우(단계 S1060), 디바이스는 초기 압축률 값인 QPinit을 최종 압축률 값으로 결정한다. 단계 S430에서, 디바이스는 결정된 압축률 값으로 영상을 압축하고, 부호화함으로써, 비트스트림을 생성 한다. 도 10에 도시된 실시예에서, 디바이스는 심층 신경망 모델을 통해 출력된 압축률 값인 QPdet를 영상 을 압축하는 최종 압축률로 결정하는 것이 아니라, 네트워크 환경(예를 들어, 네트워크 대역폭 정보)에 따라 획 득된 압축률 값 QPNW 및 초기 설정된 압축률 값 QPinit을 고려하여 최종 압축률을 결정할 수 있다. 따라서, 본 개 시의 디바이스는 영상으로부터 타겟 객체를 인식할 수 있을 뿐 아니라, 네트워크 대역폭에 따라 송수신 가능한 비트레이트를 고려하여 영상의 압축률을 정할 수 있다. 본 개시를 통해 설명된 디바이스에 의해 실행되는 프로그램은 하드웨어 구성요소, 소프트웨어 구성요소, 및/또는 하드웨어 구성요소 및 소프트웨어 구성요소의 조합으로 구현될 수 있다. 프로그램은 컴퓨터로 읽을 수 있는 명령어들을 수행할 수 있는 모든 시스템에 의해 수행될 수 있다. 소프트웨어는 컴퓨터 프로그램(computer program), 코드(code), 명령어(instruction), 또는 이들 중 하나 이상 의 조합을 포함할 수 있으며, 원하는 대로 동작하도록 처리 장치를 구성하거나 독립적으로 또는 결합적으로 (collectively) 처리 장치를 명령할 수 있다. 소프트웨어는, 컴퓨터로 읽을 수 있는 저장 매체(computer-readable storage media)에 저장된 명령어를 포함하 는 컴퓨터 프로그램으로 구현될 수 있다. 컴퓨터가 읽을 수 있는 기록 매체로는, 예를 들어 마그네틱 저장 매체 (예컨대, ROM(read-only memory), RAM(random-access memory), 플로피 디스크, 하드 디스크 등) 및 광학적 판 독 매체(예컨대, 시디롬(CD-ROM), 디브이디(DVD: Digital Versatile Disc)) 등이 있다. 컴퓨터가 읽을 수 있는 기록 매체는 네트워크로 연결된 컴퓨터 시스템들에 분산되어, 분산 방식으로 컴퓨터가 판독 가능한 코드가 저장되고 실행될 수 있다. 매체는 컴퓨터에 의해 판독가능하며, 메모리에 저장되고, 프로세서에서 실행될 수 있다. 컴퓨터로 읽을 수 있는 저장매체는, 비일시적(non-transitory) 저장매체의 형태로 제공될 수 있다. 여기서, '비 일시적'은 저장매체가 신호(signal)를 포함하지 않으며 실재(tangible)한다는 것을 의미할 뿐 데이터가 저장매 체에 반영구적 또는 임시적으로 저장됨을 구분하지 않는다. 또한, 본 명세서에 개시된 실시예들에 따른 프로그램은 컴퓨터 프로그램 제품(computer program product)에 포 함되어 제공될 수 있다. 컴퓨터 프로그램 제품은 상품으로서 판매자 및 구매자 간에 거래될 수 있다. 컴퓨터 프로그램 제품은 소프트웨어 프로그램, 소프트웨어 프로그램이 저장된 컴퓨터로 읽을 수 있는 저장 매체 를 포함할 수 있다. 예를 들어, 컴퓨터 프로그램 제품은 디바이스의 제조사 또는 전자 마켓(예를 들어, 구글 플 레이 스토어, 앱 스토어)을 통해 전자적으로 배포되는 소프트웨어 프로그램 형태의 상품(예를 들어, 다운로드 가능한 애플리케이션(downloadable application))을 포함할 수 있다. 전자적 배포를 위하여, 소프트웨어 프로그 램의 적어도 일부는 저장 매체에 저장되거나, 임시적으로 생성될 수 있다. 이 경우, 저장 매체는 제조사의 서버, 전자 마켓의 서버, 또는 소프트웨어 프로그램을 임시적으로 저장하는 중계 서버의 저장매체가 될 수 있다. 컴퓨터 프로그램 제품은, 서버 및 디바이스로 구성되는 시스템에서, 서버의 저장매체 또는 디바이스의 저장매체 를 포함할 수 있다. 또는, 서버 또는 디바이스와 통신 연결되는 제3의 디바이스(예, 스마트폰)가 존재하는 경 우, 컴퓨터 프로그램 제품은 제3의 디바이스의 저장매체를 포함할 수 있다. 또는, 컴퓨터 프로그램 제품은 서버 로부터 디바이스 또는 제3 디바이스로 전송되거나, 제3 디바이스로부터 디바이스로 전송되는 소프트웨어 프로그 램 자체를 포함할 수 있다. 이 경우, 서버, 디바이스 및 제3 디바이스 중 하나가 컴퓨터 프로그램 제품을 실행하여 개시된 실시예들에 따른 방법을 수행할 수 있다. 또는, 서버, 디바이스 및 제3 디바이스 중 둘 이상이 컴퓨터 프로그램 제품을 실행하 여 개시된 실시예들에 따른 방법을 분산하여 실시할 수 있다. 예를 들면, 서버가 서버에 저장된 컴퓨터 프로그램 제품을 실행하여, 서버와 통신 연결된 디바이스가 개시된 실 시예들에 따른 방법을 수행하도록 제어할 수 있다. 또 다른 예로, 제3 디바이스가 컴퓨터 프로그램 제품을 실행하여, 제3 디바이스와 통신 연결된 디바이스가 개시 된 실시예에 따른 방법을 수행하도록 제어할 수 있다. 제3 디바이스가 컴퓨터 프로그램 제품을 실행하는 경우, 제3 디바이스는 서버로부터 컴퓨터 프로그램 제품을 다 운로드하고, 다운로드된 컴퓨터 프로그램 제품을 실행할 수 있다. 또는, 제3 디바이스는 프리로드(pre- loaded)된 상태로 제공된 컴퓨터 프로그램 제품을 실행하여 개시된 실시예들에 따른 방법을 수행할 수도 있다."}
{"patent_id": "10-2020-0127386", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "이상과 같이 실시예들이 비록 한정된 실시예와 도면에 의해 설명되었으나, 해당 기술분야에서 통상의 지식을 가 진 자라면 상기의 기재로부터 다양한 수정 및 변형이 가능하다. 예를 들어, 설명된 기술들이 설명된 방법과 다 른 순서로 수행되거나, 및/또는 설명된 컴퓨터 시스템 또는 모듈 등의 구성요소들이 설명된 방법과 다른 형태로 결합 또는 조합되거나, 다른 구성요소 또는 균등물에 의하여 대치되거나 치환되더라도 적절한 결과가 달성될 수 있다. 도면 도면1 도면2 도면3 도면4 도면5 도면6 도면7 도면8 도면9 도면10"}
{"patent_id": "10-2020-0127386", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 개시의 일 실시예에 따른 디바이스에 의해 수행되는 영상 처리 동작들을 설명하기 위한 개념도이다. 도 2는 본 개시의 일 실시예에 따른 디바이스가 원본 영상으로부터 압축률을 결정하고, 원본 영상 및 결정된 압 축률 정보를 저장하는 방법을 도시한 도면이다. 도 3은 본 개시의 일 실시예에 따른 디바이스의 구성을 도시한 블록도이다. 도 4는 본 개시의 일 실시예에 따른 디바이스의 동작 방법을 도시한 흐름도이다. 도 5는 본 개시의 일 실시예에 따른 디바이스가 원본 영상으로부터 타겟 객체를 정상적으로 인식하기 위한 압축 률을 결정하는 방법을 도시한 흐름도이다. 도 6은 본 개시의 일 실시예에 따른 디바이스가 복원 영상에서의 타겟 객체 인식 여부를 판단하는 방법을 도시 한 흐름도이다. 도 7은 본 개시의 일 실시예에 따른 디바이스가 타겟 객체의 인식 여부 판단 결과에 기초하여, 영상의 압축률을 결정하는 방법을 도시한 흐름도이다. 도 8은 본 개시의 일 실시예에 따른 디바이스가 CTU(Coding Tree Unit) 별로 서로 다른 압축률을 결정하는 실시 예를 도시한 도면이다. 도 9는 본 개시의 일 실시예에 따른 디바이스가 CTU(Coding Tree Unit) 별로 서로 다른 압축률을 결정하는 방법 을 도시한 흐름도이다. 도 10은 본 개시의 일 실시예에 따른 디바이스가 심층 신경망 모델을 통해 결정된 압축률 값을 네트워크 대역폭 에 따른 압축률 값 및 초기 설정된 압축률 값과 비교하고, 비교 결과에 기초하여 최종 압축률 값을 결정하는 방 법을 도시한 흐름도이다."}
