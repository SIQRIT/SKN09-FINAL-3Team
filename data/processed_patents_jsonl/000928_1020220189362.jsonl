{"patent_id": "10-2022-0189362", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0106485", "출원번호": "10-2022-0189362", "발명의 명칭": "유사 에피소드 샘플링을 이용하는 모델 기반 강화학습을 통해 최적 치료경로를 탐색하기 위한", "출원인": "한국전자통신연구원", "발명자": "김도현"}}
{"patent_id": "10-2022-0189362", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "대상 환자의 최적 치로경로를 탐색하기 위한 장치에 있어서,가상 전자 의무 기록(EMR) 에피소드를 입력 받고, 입력 받은 가상 EMR 에피소드에 대응하는 환자의 현재상태와, 복수의 EMR 에피소드들 각각에 대응하는 환자의 현재 상태의 유사도를 계산하고, 상기 복수의 EMR 에피소드들 중 상기 계산된 유사도가 가장 높은 EMR 에피소드를 추출하고, 상기 가상 EMR 에피소드 및 상기 추출된EMR 에피소드의 쌍을 출력하는 에피소드 샘플링 모듈;상기 가상 EMR 에피소드 및 상기 추출된 EMR 에피소드의 쌍에 기반하여, 상기 대상 환자의 현재 상태에 대해 특정 치료방법을 수행했을 때 보상의 기대값을 예측하는 상태 가치 평가 모듈;상기 대상 환자의 보상의 기대값을 최대화할 수 있는 최적 치료방법 및 최적 치료 시기를 예측하고, 상기 대상환자의 현재 상태 및 상기 치료방법을 외부의 예측 모델로 제공하여 상기 대상 환자의 다음 상태 및 보상을 획득하는 치료방법 선택 모듈; 및상기 치료방법, 상기 치료 시기, 상기 다음 상태, 및 상기 보상에 기반하여 새로운 가상 EMR 에피소드를 생성하는 가상 에피소드 생성 모듈을 포함하는 장치."}
{"patent_id": "10-2022-0189362", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1 항에 있어서,상기 에피소드 샘플링 모듈은 평균제곱오차(MSE) 유사도 또는 코사인 유사도 중 어느 하나를 사용하여 상기 유사도를 계산하는 장치."}
{"patent_id": "10-2022-0189362", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 1 항에 있어서,상기 상태 가치 평가 모듈은 수식 1에 따라 상기 보상의 기대값을 예측하기 위한 함수 Q를 학습시키는 장치.(수식 1)(상기 α는 조절될 수 있는 임의의 가중치이고, 상기 D는 복수의 가상 EMR 에피소드들을 포함하는미니배치이고, P는 상기 복수의 EMR 에피소드들을 포함하는 미니배치이고, S는 상기 입력 받은 가상 EMR 에피소드에 대응하는 환자의 현재 상태이고, 는 상기 S와 유사한 상기 추출된 EMR 에피소드에 대응하는 환자의 현재상태이고, 상기 a는 치료방법이고, 상기 μ와 상기 π는 각각 가상의 정책과 실제 의사의 정책이고, 상기는 벨만 방정식(Bellman equation))"}
{"patent_id": "10-2022-0189362", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 1 항에 있어서,상기 치료방법 학습 모듈은 상기 대상 환자의 현재 상태를 입력 받아 치료방법을 출력하는 실시간 치료방법 추천 네트워크를 포함하는 장치.공개특허 10-2024-0106485-3-청구항 5 제 4 항에 있어서,상기 치료방법 학습 모듈은:복수의 시점들에 대해 상기 현재 상태 및 상기 치료방법을 상기 환자 상태 예측 장치로 제공하여 상기 복수의시점들 각각에 대응하는 상기 대상 환자의 다음 상태를 획득하고, 상기 획득된 각 다음 상태 및 상기 치료방법에 기반하여 계산된 상기 보상의 기대값이 최대가 되는 시점을 상기 최적 치료 시기로서 예측하고, 그리고상기 보상의 기대값의 최대값에 기반하여 상기 실시간 치료방법 추천 네트워크를 업데이트하고, 업데이트된 네트워크에 상기 대상 환자의 현재 상태를 입력하여 출력된 치료방법을 상기 최적 치료방법으로서 예측하는 장치."}
{"patent_id": "10-2022-0189362", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제 4 항에 있어서,상기 실시간 치료방법 추천 네트워크는 복수의 치료방법들 중 상기 보상의 기대값을 최대화하는 치료방법을 선택하도록 업데이트되는 장치."}
{"patent_id": "10-2022-0189362", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "대상 환자의 최적 치료경로를 탐색하기 위한 방법에 있어서,입력 받은 가상 전자 의무 기록(EMR) 에피소드에 대응하는 환자의 현재 상태와, 복수의 EMR 에피소드들 각각에대응하는 환자의 현재 상태의 유사도를 계산하고, 상기 복수의 EMR 에피소드들 중 상기 계산된 유사도가 가장높은 EMR 에피소드를 추출하고, 상기 가상 EMR 에피소드 및 상기 추출된 EMR 에피소드의 쌍을 출력하는 단계;상기 가상 EMR 에피소드 및 상기 추출된 EMR 에피소드의 쌍에 기반하여, 상기 대상 환자의 현재 상태에 대해 특정 치료방법을 수행했을 때 보상의 기대값을 예측하는 단계;상기 대상 환자의 보상의 기대값을 최대화할 수 있는 최적 치료방법 및 최적 치료 시기를 예측하는 단계;상기 대상 환자의 현재 상태 및 상기 치료방법을 외부의 예측 모델로 제공하여 상기 대상 환자의 다음 상태 및보상을 획득하는 단계; 및상기 치료방법, 상기 치료 시기, 상기 다음 상태, 및 상기 보상에 기반하여 새로운 가상 EMR 에피소드를 생성하는 단계를 포함하는 방법."}
{"patent_id": "10-2022-0189362", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제 7 항에 있어서,상기 가상 EMR 에피소드 및 상기 추출된 EMR 에피소드의 쌍을 출력하는 단계는 평균제곱오차(MSE) 유사도 또는코사인 유사도 중 어느 하나를 사용하여 상기 유사도를 계산하는 단계를 포함하는 방법."}
{"patent_id": "10-2022-0189362", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제 7 항에 있어서,상기 보상의 기대값을 예측하는 단계는 수식 1에 따라 상기 보상의 기대값을 예측하기 위한 함수 Q를 학습시키는 단계를 포함하는 방법.(수식 1)(상기 α는 조절될 수 있는 임의의 가중치이고, 상기 D는 복수의 가상 EMR 에피소드들을 포함하는미니배치이고, P는 상기 복수의 EMR 에피소드들을 포함하는 미니배치이고, S는 상기 입력 받은 가상 EMR 에피소공개특허 10-2024-0106485-4-드에 대응하는 환자의 현재 상태이고, 는 상기 S와 유사한 상기 추출된 EMR 에피소드에 대응하는 환자의 현재상태이고, 상기 a는 치료방법이고, 상기 μ와 상기 π는 각각 가상의 정책과 실제 의사의 정책이고, 상기는 벨만 방정식(Bellman equation))"}
{"patent_id": "10-2022-0189362", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제 7 항에 있어서,상기 최적 치료방법 및 최적 치료 시기를 예측하는 단계는:상기 대상 환자의 현재 상태를 실시간 치료방법 추천 네트워크에 입력하여 치료방법을 출력하는 단계;복수의 시점들에 대해 상기 현재 상태 및 상기 치료방법을 상기 환자 상태 예측 장치로 제공하여 상기 복수의시점들 각각에 대응하는 상기 대상 환자의 다음 상태를 획득하는 단계;상기 획득된 각 다음 상태 및 상기 치료방법에 기반하여 계산된 상기 보상의 기대값이 최대가 되는 시점을 상기최적 치료 시기로서 예측하는 단계;상기 보상의 기대값의 최대값에 기반하여 상기 실시간 치료방법 추천 네트워크를 업데이트하는 단계; 및업데이트된 네트워크에 상기 대상 환자의 현재 상태를 입력하여 출력된 치료방법을 상기 최적 치료방법으로서예측하는 단계를 포함하는 방법."}
{"patent_id": "10-2022-0189362", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "전자 의무 기록(EMR) 에피소드에 기반하여 대상 환자에 대한 치료방법을 예측하는 치료경로 탐색 장치; 및상기 대상 환자의 현재 상태 및 치료방법을 입력 받아 상기 대상 환자의 다음 상태 및 보상을 출력하는 환자 상태 예측 장치를 포함하되,상기 치료경로 탐색 장치는:가상 전자 의무 기록(EMR) 에피소드를 입력 받고, 입력 받은 가상 EMR 에피소드에 대응하는 환자의 현재상태와, 복수의 EMR 에피소드들 각각에 대응하는 환자의 현재 상태의 유사도를 계산하고, 상기 복수의 EMR 에피소드들 중 상기 계산된 유사도가 가장 높은 EMR 에피소드를 추출하고, 상기 가상 EMR 에피소드 및 상기 추출된EMR 에피소드의 쌍을 출력하는 에피소드 샘플링 모듈;상기 가상 EMR 에피소드 및 상기 추출된 EMR 에피소드의 쌍에 기반하여, 상기 대상 환자의 현재 상태에 대해 특정 치료방법을 수행했을 때 보상의 기대값을 예측하는 상태 가치 평가 모듈;상기 대상 환자의 보상의 기대값을 최대화할 수 있는 최적 치료방법 및 최적 치료 시기를 예측하고, 상기 대상환자의 현재 상태 및 상기 치료방법을 상기 환자 상태 예측 장치로 제공하여 상기 대상 환자의 다음 상태 및 보상을 획득하는 치료방법 선택 모듈; 및상기 치료방법, 상기 치료 시기, 상기 다음 상태, 및 상기 보상에 기반하여 새로운 가상 EMR 에피소드를 생성하는 가상 에피소드 생성 모듈을 포함하는 최적 치료경로 탐색을 위한 시스템."}
{"patent_id": "10-2022-0189362", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 개시의 실시 예에 따른 대상 환자의 최적 치로경로를 탐색하기 위한 장치는 가상 전자 의무 기록(EMR) 에피소 드를 입력 받고, 입력 받은 가상 EMR 에피소드에 대응하는 환자의 현재 상태와, 복수의 EMR 에피소드들 각각에 대응하는 환자의 현재 상태의 유사도를 계산하고, 상기 복수의 EMR 에피소드들 중 상기 계산된 유사도가 가장 높 (뒷면에 계속)"}
{"patent_id": "10-2022-0189362", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 인공지능 장치에 관한 것으로, 좀 더 상세하게는 유사 에피소드 샘플링을 이용하는 모델 기반 강화학 습을 통해 최적 치료경로를 탐색하기 위한 장치 및 방법에 관한 것이다."}
{"patent_id": "10-2022-0189362", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "의료 인공지능 기술은 질병 유무 진단, 환자상태 예측, 그리고 치료방법 탐색의 순서로 발전하고 있다. 현재 일 반적인 의료 인공지능은 질병 유무 진단에 적용되고 있으며, 최근에는 지도(supervised) 또는 비지도 (unsupervised) 딥러닝 기술이 활용되고 있다. 특히 의료 인공지능 기술은 CT, X-ray, MRI 등과 같은 의료영상 에서 이상 부위를 탐지하거나, 연속적인 생체 신호를 분석하는 데 많이 활용되고 있으며, CNN(convolutionalneural network), 순환 신경망(recurrent neural network), LSTM(long short-term memory) 등의 인공지능 기술 이 주로 사용된다. 특히, 의료 인공지능 기술은 환자에게 가장 효과가 있는 치료방법이 무엇인지 찾는 치료방법 탐색에 적용될 수 있다. 치료방법 탐색의 목적은 환자를 최종적으로 가장 좋은 상태로 호전시키는 일련의 치료 경로를 탐색하는 것인데, 이를 위해 강화학습(reinforcement learning) 기술이 이용될 수 있다. 의료 환경의 특성상, 강화학습을 적용하는 데 있어 가장 큰 어려움은 에피소드 수집이다. 강화학습은 최적의 정 책을 학습하기 위해 수많은 에피소드를 필요로 하지만, 실제 환자에게 치료방법을 적용한 데이터를 수집하는 데 상당한 비용이 발생하기 때문에 충분한 수의 학습 데이터를 확보하기 어렵다. 또한, 최적의 치료경로를 탐색하 기 위해 동일한 상태의 환자에 대해 다양한 치료방법을 적용한 결과를 수집해야 하지만, 실질적으로 동일한 상 태의 환자는 존재하지 않기 때문에 시행착오에 어려움이 있다. 환경으로부터 시행착오를 통해 충분한 에피소드를 수집하기 어려운 상황에서 강화학습을 효과적으로 수행하기 위한 방법 중 하나는 모델 기반 강화학습이다. 모델 기반 강화학습의 경우, 실제 환경을 모사할 수 있는 모델을 구성하고, 강화학습이 모델과의 상호작용을 통해 가상 에피소드들을 수집하며, 수집된 에피소드들을 기반으로 강화학습의 정책을 학습한다. 모델이 환경을 정교하게 모사하는 경우, 에피소드를 수집하는 비용이 절감될 수 있고, 실제 환경에서 시도해보지 못한 행위에 대해서도 결과를 수집하여 학습할 수 있다. 그러나 부정확한 모델 이 구현된 경우 행위와 환경의 상호작용의 결과가 왜곡되는 결과가 발생하며, 이는 최적화된 정책으로의 학습을 방해할 수 있다. 반대로, 모델을 사용하지 않고 수집된 에피소드만을 가지고 학습하는 에피소드 기반 강화학습도 활용될 수 있다. 에피소드 기반 강화학습의 경우, 실제 환경에서 수집한 데이터를 기반으로 정책을 학습하기 때문에 부정 확한 모델로 인해 발생할 수 있는 왜곡은 없지만, 실제 수집한 데이터 외의 상황에 대해서는 학습의 방향을 알 수 없다. 특정 환경의 상황에 대한 특정 행위에 대한 보상이 있어야 해당 행위를 지향 또는 지양하도록 학습이 가능한데, 해당 데이터를 수집하지 못한 상황에 대해서는 해당 행위에 대한 가치를 정확하게 추정할 수 없어 최 적의 정책을 학습하는 데 큰 어려움이 있다. 한정된 의료 데이터에 대해 모델 기반 강화학습을 수행할 경우, 실제 환자에게 치료방법을 적용했을 때의 상태 변화를 정확하게 예측하기 어렵기 때문에, 구현된 모델로 에피소드들을 수집한 결과가 왜곡될 수 있다. 반면, 에피소드 기반 강화학습을 수행할 경우 동일한 상태의 환자에 대한 치료방법은 단 한 번만 적용되므로 다양한 치료방법에 대한 보상 및 효용을 알 수 없어 최적의 치료경로를 탐색하기 어려우며, 시도하지 않은 치료방법에 대한 가치가 높게 추정되는 보상 과추정 현상이 발생할 수 있다. 그러므로, 이러한 보상 과추정 방지를 위한 방 법에 대한 연구가 필요하다."}
{"patent_id": "10-2022-0189362", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 개시는 유사 에피소드 샘플링을 이용하는 모델 기반 강화학습을 통해 최적 치료경로를 탐색하기 위한 장치 및 방법을 제공한다."}
{"patent_id": "10-2022-0189362", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 개시의 실시 예에 따른 대상 환자의 최적 치로경로를 탐색하기 위한 장치는 가상 전자 의무 기록(EMR) 에피 소드를 입력 받고, 입력 받은 가상 EMR 에피소드에 대응하는 환자의 현재 상태와, 복수의 EMR 에피소드들 각각 에 대응하는 환자의 현재 상태의 유사도를 계산하고, 상기 복수의 EMR 에피소드들 중 상기 계산된 유사도가 가 장 높은 EMR 에피소드를 추출하고, 상기 가상 EMR 에피소드 및 상기 추출된 EMR 에피소드의 쌍을 출력하는 에피 소드 샘플링 모듈, 상기 가상 EMR 에피소드 및 상기 추출된 EMR 에피소드의 쌍에 기반하여, 상기 대상 환자의 현재 상태에 대해 특정 치료방법을 수행했을 때 보상의 기대값을 예측하는 상태 가치 평가 모듈, 상기 대상 환 자의 보상의 기대값을 최대화할 수 있는 최적 치료방법 및 최적 치료 시기를 예측하고, 상기 대상 환자의 현재 상태 및 상기 치료방법을 외부의 예측 모델로 제공하여 상기 대상 환자의 다음 상태 및 보상을 획득하는 치료방 법 선택 모듈, 및 상기 치료방법, 상기 치료 시기, 상기 다음 상태, 및 상기 보상에 기반하여 새로운 가상 EMR 에피소드를 생성하는 가상 에피소드 생성 모듈을 포함할 수 있다. 본 개시의 실시 예에 따른 대상 환자의 최적 치료경로를 탐색하기 위한 방법은 입력 받은 가상 전자 의무 기록 (EMR) 에피소드에 대응하는 환자의 현재 상태와, 복수의 EMR 에피소드들 각각에 대응하는 환자의 현재 상태의 유사도를 계산하고, 상기 복수의 EMR 에피소드들 중 상기 계산된 유사도가 가장 높은 EMR 에피소드를 추출하고,상기 가상 EMR 에피소드 및 상기 추출된 EMR 에피소드의 쌍을 출력하는 단계, 상기 가상 EMR 에피소드 및 상기 추출된 EMR 에피소드의 쌍에 기반하여, 상기 대상 환자의 현재 상태에 대해 특정 치료방법을 수행했을 때 보상 의 기대값을 예측하는 단계, 상기 대상 환자의 보상의 기대값을 최대화할 수 있는 최적 치료방법 및 최적 치료 시기를 예측하는 단계, 상기 대상 환자의 현재 상태 및 상기 치료방법을 외부의 예측 모델로 제공하여 상기 대 상 환자의 다음 상태 및 보상을 획득하는 단계, 및 상기 치료방법, 상기 치료 시기, 상기 다음 상태, 및 상기 보상에 기반하여 새로운 가상 EMR 에피소드를 생성하는 단계를 포함할 수 있다. 본 개시의 실시 예에 따른 최적 치료경로 탐색을 위한 시스템은 전자 의무 기록(EMR) 에피소드에 기반하여 대상 환자에 대한 치료방법을 예측하는 치료경로 탐색 장치, 및 상기 대상 환자의 현재 상태 및 치료방법을 입력 받 아 상기 대상 환자의 다음 상태 및 보상을 출력하는 환자 상태 예측 장치를 포함하되, 상기 치료경로 탐색 장치 는 가상 EMR 에피소드를 입력 받고, 입력 받은 가상 EMR 에피소드에 대응하는 환자의 현재 상태와, 복수의 EMR 에피소드들 각각에 대응하는 환자의 현재 상태의 유사도를 계산하고, 상기 복수의 EMR 에피소드들 중 상기 계산 된 유사도가 가장 높은 EMR 에피소드를 추출하고, 상기 가상 EMR 에피소드 및 상기 추출된 EMR 에피소드의 쌍을 출력하는 에피소드 샘플링 모듈, 상기 가상 EMR 에피소드 및 상기 추출된 EMR 에피소드의 쌍에 기반하여, 상기 대상 환자의 현재 상태에 대해 특정 치료방법을 수행했을 때 보상의 기대값을 예측하는 상태 가치 평가 모듈, 상기 대상 환자의 보상의 기대값을 최대화할 수 있는 최적 치료방법 및 최적 치료 시기를 예측하고, 상기 대상 환자의 현재 상태 및 상기 치료방법을 상기 환자 상태 예측 장치로 제공하여 상기 대상 환자의 다음 상태 및 보 상을 획득하는 치료방법 선택 모듈, 및 상기 치료방법, 상기 치료 시기, 상기 다음 상태, 및 상기 보상에 기반 하여 새로운 가상 EMR 에피소드를 생성하는 가상 에피소드 생성 모듈을 포함할 수 있다."}
{"patent_id": "10-2022-0189362", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 개시의 실시 예에 따르면, 의료 데이터에 대해 모델 기반 강화학습 및 에피소드 기반 강화학습을 함께 적용 할 수 있으며, 이와 같은 강화학습을 사용하면 가상 에피소드에 기반한 강화학습에 비해 실제 의사의 치료방법 을 참고한 정책을 학습하기에 용이할 수 있다. 나아가 본 개시의 실시 예에 따르면, 불규칙적인 시간 간격을 가지는 의료 데이터에 대해 치료 효용이 최대가 되는 치료 시기와 치료방법을 탐색할 수 있고, 강화학습에 시간 간격이 고려될 수 있다."}
{"patent_id": "10-2022-0189362", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "아래에서는, 본 개시의 기술 분야에서 통상의 지식을 가진 자가 본 개시를 쉽게 실시할 수 있을 정도로, 본 개 시의 실시 예들이 명확하고 상세하게 기재될 것이다. 상세한 설명에서 사용되는 부 또는 유닛(unit), 모듈(module), 블록(block), ~기(~or, ~er) 등의 용어들을 참 조하여 설명되는 구성 요소들 및 도면에 도시된 기능 블록들은 소프트웨어, 또는 하드웨어, 또는 그것들의 조합 의 형태로 구현될 수 있다. 예시적으로, 소프트웨어는 기계 코드, 펌웨어, 임베디드 코드, 및 애플리케이션 소 프트웨어일 수 있다. 예를 들어, 하드웨어는 전기 회로, 전자 회로, 프로세서, 컴퓨터, 집적 회로, 집적 회로 코어들, 압력 센서, 관성 센서, 멤즈 (microelectromechanical system; MEMS), 수동 소자, 또는 그것들의 조합 을 포함할 수 있다. 질병의 치료경로(treatment pathway)는 환자가 완치될 때까지 또는 사망할 때까지 환자상태의 검사 및 환자상태 를 개선하기 위한 의료 행위(본 명세서에서는 치료방법이라고 지칭함)를 반복하는 일련의 과정으로 정의될 수 있다. 인공지능 기술은 현재 환자상태와 비교하여 다음 환자상태를 가장 크게 개선시킬 수 있는 치료방법을 추 천할 수 있다. 그러나, 추천된 치료방법에 따라 다음 환자상태가 많이 개선될지라도, 후속적인 치료가 환자의 상태를 악화시킨다면 추천된 치료방법은 최적 치료방법이 아니다. 따라서, 최적의 치료방법은 당장의 개선 정도 를 최대화하는 치료가 아닌, 환자의 최종 상태를 최선의 상태로 만드는 치료방법이다. 환자의 최종 상태를 최선의 상태로 만들기 위해, 환자상태의 변화에 따라 단계적으로 수행될 수 있는 여러 치료 들의 연속적인 경로가 필요하며, 본 개시에서는 이러한 연속적인 경로를 환자에 대한 최적 치료경로라고 정의한 다. 최적 치료경로의 탐색은 누적 보상을 최대화하는 순차적 의사결정의 탐색에 대응할 수 있다. 즉, 최적 치 료경로 계획은 환자에 대해 치료방법을 적용할 때마다 발생하는 시행착오를 통해 치료방법을 교정하는 과정을 반복 학습함으로써 환자의 최종 상태를 최선의 상태로 만들 수 있는(즉, 누적 보상을 최대화할 수 있는) 연속적 인 치료방법들을 학습하는 것으로, 이를 위해 강화학습(reinforcement learning) 방법이 이용될 수 있다. 도 1은 본 개시의 실시 예에 따른 최적 치료경로를 탐색하기 위한 시스템의 구성을 나타내는 블록도이다. 도 1을 참조하면, 시스템은 치료경로 탐색 장치 및 환자 상태 예측 장치를 포함할 수 있다. 치 료경로 탐색 장치는 전자 의료 기록(electronic medical record; EMR) 데이터베이스로부터 환자들의 EMR을 수신할 수 있다. EMR은 의료기관을 방문한 모든 환자들의 검사 및 치료에 관한 기록들을 시간에 따라 시 계열 형태로 저장하며, 치료경로 탐색 장치는 이러한 EMR을 <환자 상태(S), 치료방법(A), 보상(R), 시간 (T), 환자의 다음 상태(S`)>의 형태를 갖는 시계열 에피소드로 변환할 수 있다. 이렇게 에피소드로 변환된 EMR 을 EMR 에피소드라고 지칭하기로 한다. 치료경로 탐색 장치는 EMR 에피소드에 기반하여 환자의 상태에 대응하는 치료방법을 예측할 수 있고, 최선 의 치료경로를 학습할 수 있다. 치료경로 탐색 장치는 환자의 현재 상태(S)에 대해 예측된 치료방법(A) 및 시간(T)을 환자 상태 예측 장치로 전달할 수 있다. 환자 상태 예측 장치는 수신한 치료방법 및 시간 에 기반하여 보상(R) 및 환자의 다음 상태(S`)를 예측할 수 있다. 치료경로 탐색 장치는 환자 상태 예측 장치로부터 예측된 보상 및 환자의 다음 상태를 수신하여, 앞서 예측한 치료방법 및 시간과 함께, <환자 상태(S), 예측된 치료방법(A), 예측된 보상(R), 예측된 시간(T), 예측된 환자의 다음 상태(S`)>의 형태를 갖는 가상 EMR 에피소드를 생성할 수 있다. 치료경로 탐색 장치는 EMR DB에 저장된 실제 EMR로부터 생성된 EMR 에피소드뿐만 아니라, 치료경로 탐색 장치와 환자 상태 예측 장치 사이의 상호작용을 통해 생성 된 가상 EMR 에피소드를 사용하여 상술한 치료방법의 예측 및 치료경로의 학습을 수행할 수 있다. 생성된 가상 EMR 에피소드는 치료경로 탐색 장치 내부의 임시 메모리 또는 스토리지 장치에 저장될 수 있다. 예를 들어, 치료경로 탐색 장치는 치료방법 및 시간을 예측하기 위한 인공지능 모델을 포함할 수 있고, 환 자 상태 예측 장치는 환자의 다음 상태 및 보상을 예측하기 위한 인공지능 모델(예를 들어, 시계열 확률분 포 모델)을 포함할 수 있다. 치료경로 탐색 장치 및 환자 상태 예측 장치의 기능들은, 임의의 유형의 메모리(예를 들어, NAND 플래시 메모리, 로우-레이턴시 NAND 플래시 메모리와 같은 플래시 메모리, 크로스-그리 드 불휘발성 메모리와 같은 PMEM(persistent memory), 대량 저항 변화가 있는 메모리, PCM(phase change memory) 등 또는 이들의 결합)에 저장된 명령들을 실행하는 결합 로직, 순차 로직, 하나 이상의 타이머들, 카운 터들, 레지스터들, 및/또는 상태 머신들, 하나 이상의 CPLD(complex programmable logic device), FPGA(field programmable gate array), ASIC(application specific integrated circuit), x86 프로세서들과 같은 CSIC(complex instruction set computer) 프로세서들 및/또는 ARM 프로세서들과 같은 RISC(reduced instruction set computer)과 같은 CPU(central processing unit), GPU(graphics processing unit), NPU(neural processing unit), TPU(tensor processing unit), APU(accelerated processing unit) 등 또는 이 들의 결합을 포함하는 하드웨어, 소프트웨어 또는 이들의 결합을 이용하여 구현될 수 있다. 또한 실시 예에 따라, 상술한 치료경로 탐색 장치 및 환자 상태 예측 장치의 동작들은 비일시적(non- transistory) 컴퓨터 판독 가능 매체에 저장되는 프로그램 코드로서 구현될 수도 있다. 예를 들어, 비일시적 컴 퓨터 판독 가능 매체는 자기 매체, 광학 매체, 또는 이들의 결합(예를 들어, CD-ROM, 하드 드라이브, 읽기 전용 메모리, 플래시 드라이브 등)을 포함할 수 있다. 도 2는 도 1의 치료경로 탐색 장치의 구성을 나타내는 블록도이다. 도 2를 참조하면, 치료경로 탐색 장치 는 에피소드 샘플링 모듈, 상태 가치 평가 모듈, 치료방법 선택 모듈, 및 가상 에피소드 생성 모듈을 포함할 수 있다. 에피소드 샘플링 모듈은 가상 EMR 에피소드를 입력 받을 수 있고, 입력 받은 가상 EMR 에피소드와 유사한 실제 EMR 에피소드를 추출한 후, 서로 유사한 실제 EMR 에피소드와 가상 EMR 에피소드의 쌍을 상태 가치 평가 모듈로 제공할 수 있다. 이와 같이 가상 EMR 에피소드와 유사한 실제 EMR 에피소드를 추출하는 과정을 유 사 에피소드 샘플링(similar episode sampling)이라고 지칭한다. 상태 가치 평가 모듈은 치료경로를 탐색하고자 하는 대상이 되는 환자의 현재 상태에서 특정 치료방법에 따라 치료를 수행했을 때 EMR 에피소드의 종료 시점까지 받을 수 있는 보상의 기대값(Q(S`, A)로 표현)을 예측 할 수 있다. 상태 가치 평가 모듈은 보상의 기대값을 정확하게 예측하도록 학습될 수 있으며, 학습이 완료 된 상태 가치 평가 모듈은 임의의 환자 상태 및 치료 방법을 입력 받아 보상의 기대값을 예측할 수 있다. 상태 가치 평가 모듈은 예측된 보상의 기대값을 치료방법 선택 모듈로 제공할 수 있다. 치료방법 선택 모듈은 현재의 환자 상태에 대해 보상을 최대화할 수 있는 치료방법(A)을 선택할 수 있고, 대응하는 치료 시기를 예측할 수 있다. 구체적으로, 치료방법 선택 모듈은 상태 가치 평가 모듈에서 예측된 보상의 기대값에 기반하여, 환자의 현재 상태에서 기대값을 최대화할 수 있는 치료방법을 선택하도록 학 습될 수 있다. 선택된 치료방법은 환자 상태 예측 장치(도 1의 120)으로 제공될 수 있다. 치료방법 선택 모듈 은 환자 상태 예측 장치(도 1의 120)로부터 예측된 보상(R) 및 환자의 다음 상태(S`)를 수신하여 선택된 치료방법(A)과 함께 가상 에피소드 생성 모듈로 제공할 수 있다. 가상 에피소드 생성 모듈은 예측된 보상, 환자의 다음 상태, 치료방법에 기반하여 가상 EMR 에피소드를 생 성할 수 있고, 에피소드 샘플링 모듈로 다시 제공할 수 있다. 생성된 가상 EMR 에피소드는 다시 상술한 상 태 가치 평가 모듈 및 치료방법 선택 모듈의 학습에 사용될 수 있다. 이하 도 3 내지 도 7을 참조하 여, 상술한 치료경로 탐색 장치의 구성 요소들의 동작이 상세히 설명된다. 도 3은 도 2의 치료경로 탐색 장치의 동작을 개념적으로 나타낸다. 도 2를 참조하여 설명한 바와 같이, 치 료경로 탐색 장치의 동작은 에피소드 샘플링 모듈, 상태 가치 평가 모듈, 치료방법 학습 모듈 , 가상 에피소드 생성 모듈과, 환자 상태 예측 장치의 상호작용에 의해 수행된다. 먼저, 에피소드 샘플링 모듈은 가상 EMR 에피소드가 저장된 임시 메모리 또는 가상 에피소드 생성 모듈 로부터 가상 EMR 에피소드를 입력받을 수 있고, 유사한 상태를 갖는 실제 EMR 에피소드들이 포함된 클러스 터들 중에서 입력 받은 가상 EMR 에피소드의 상태 S와 유사한 상태 를 갖는 실제 EMR 에피소드를 추출(유사 에 피소드 샘플링)할 수 있다. 그 후, 에피소드 샘플링 모듈은 서로 상태가 유사한 실제 EMR 에피소드와 가상 EMR 에피소드의 쌍을 상태 가치 평가 모듈로 제공할 수 있다. 상태 가치 평가 모듈은 수신한 에피소드의 쌍에 기반하여, 환자의 현재 상태(S) 및 치료방법(A)가 주어졌 을 때 보상의 기대값(Q(S`, A))을 예측(상태 가치 예측)할 수 있다. 이 때, 상태 가치 평가 모듈의 학습을 위해 가상 EMR 에피소드에 대해서는 강화학습 정책 평가와 벨만 방정식의 최적화가 수행될 수 있다. 나아가, 가 상 EMR 에피소드만 참조하여 보상의 기대값을 예측할 때 발생할 수 있는 오차를 최소화하기 위해, 실제 EMR 에 피소드에 대해서는 의사 정책 평가가 수행될 수 있다(상태 가치 평가 학습). 치료방법 학습 모듈은 실시간으로 주어진 환자의 상태 S에 대응하는 치료방법 A를 추천하기 위한 네트워크 를 포함하며(실시간 치료방법 추천 네트워크), 이는 상태 가치 평가 모듈에서 학습된 함수 Q를 사용하여 업데이트될 수 있다. 또한, 치료방법 학습 모듈은 보상의 기대값(Q(S`, A))에 기반하여 최적 치료 시기(T) 및 치료방법(A)을 선택하여 환자 상태 예측 장치로 제공하고, 환자 상태 예측 장치를 통해 예측된 환 자의 다음 상태(S`), 보상(R)을 가상 에피소드 생성 모듈로 제공할 수 있다. 가상 에피소드 생성 모듈 은 제공받은 값들에 기반하여 새로운 가상 EMR 에피소드를 생성하고, 에피소드 샘플링 모듈로 제공할 수 있고, 새로운 EMR 에피소드들의 쌍에 기반하여 상술한 동작들이 반복될 수 있다. 도 4는 도 3의 에피소드 샘플링 모듈의 동작을 개념적으로 나타낸다. 도 1을 참조하여 설명한 바와 같이, 치료경로 탐색 장치는 생성된 가상 EMR 에피소드를 저장할 수 있는 임시 메모리 또는 스토리지 장치를 포 함할 수 있으며, 에피소드 샘플링 모듈은 이러한 임시 메모리 또는 스토리지 장치로부터 가상 EMR 에피소 드를 입력 받거나, 가상 에피소드 생성 모듈에서 생성된 가상 EMR 에피소드를 입력 받을 수 있다. 또한, 에피소드 샘플링 모듈은 실제 EMR 에피소드들 중 환자의 현재 상태의 유사도가 높은(기하학적 거리가 가까 운) 에피소드들을 클러스터링할 수 있다. 예를 들어, 유사도는 평균제곱오차(mean square error; MSE) 유사도 또는 코사인 유사도 중 하나로 계산될 수 있고, 클러스터링은 K-평균 클러스터링을 통해 수행될 수 있으나, 본 개시는 이에 한정되지 않는다.에피소드 샘플링 모듈은 클러스터로부터 입력 받은 가상 EMR 에피소드에 대응하는 환자의 현재 상태 S와 유사한 현재 상태 를 갖는 실제 EMR 에피소드를 추출(유사 에피소드 샘플링)한 후, 입력 받은 가상 EMR 에피소 드와 매칭시킬 수 있다. 매칭된 실제 EMR 에피소드와 가상 EMR 에피소드의 쌍은 상태 가치 평가를 위해 상태 가 치 평가 모듈로 제공될 수 있다. 기존의 강화학습은 실제 에피소드 또는 가상 에피소드 중 어느 하나만을 사용하는 경우가 대부분이며, 실제 에 피소드와 가상 에피소드를 함께 사용하더라도 두 에피소드 사이의 연관성을 고려하지 않는 경우가 많다. 그러나 본 개시의 실시 예에 따른 에피소드 샘플링 모듈은 사용되는 가상 EMR 에피소드와 유사한 EMR 에피소드를 추출하여 학습에 활용할 수 있으며, 이로써 가상 EMR 에피소드의 사용으로 인해 발생할 수 있는 오차를 줄일 수 있다. 도 5는 도 3의 상태 가치 평가 모듈의 동작을 개념적으로 나타낸다. 상태 가치 평가 모듈은 에피소드 샘플링 모듈에서 매칭된 실제 EMR 에피소드와 가상 EMR 에피소드의 쌍을 수신하여, 주어진 환자의 상태 S 에서 치료방법 A를 선택한 경우의 미래 보상의 기대값(Q(S`, A))을 예측할 수 있다. 구체적으로, 실제 EMR 에피 소드는 실제 의사의 정책을 반영하여 상태 가치 평가를 위한 모델을 학습시키는 데 사용될 수 있고, 가상 EMR 에피소드는 강화학습 정책 평가와 벨만 방정식의 최적화를 통해 상태 가치 평가를 위한 모델을 학습시키는 데 사용될 수 있다. 여기서 상태 가치 평가를 위한 모델을 학습시키는 것은 상태 가치를 평가하기 위한 함수 Q를 학습시키는 것과 동일하며, 함수 Q는 아래의 수학식 1에 따라 최적화될 수 있다. 수학식 1"}
{"patent_id": "10-2022-0189362", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "여기서 α는 조절될 수 있는 임의의 가중치이고, D는 복수의 EMR 에피소드들을 포함하는 미니배치이고, P는 실 제 EMR 에피소드들 중 미니배치 M에 포함된 에피소드들과 유사한 에피소드들을 포함하는 미니배치이다. S는 환 자 상태 예측 모듈을 통해 예측된 환자 상태이고, 는 S와 유사한 환자 상태로서 실제 EMR 에피소드의 환자상태이다. 는 환자상태 S에 대해 치료방법 a를 시도했을 때 강화학습 Q를 통해 계산된 보상의 기대값이고, 는 환자상태 S와 유사한 실제 환자상태 에 대해 치료방법 a를 시도 했을 때 강화학습 Q를 통해 계산된 보상의 기대값이다. 예를 들어, 보상은 환자상태가 호전된 정도에 대응할 수 있다. μ와 π는 각각 학습된 의사의 정책과 실제 의사의 정책을 나타낸다. 상태 가치 평가 모듈은 가상 EMR 에피소드를 활용한 Q 함수의 기대값인 는 낮게 유도되도록, 그리고 실제 EMR 에피소드를 활용한 Q 함수의 기대값인 는 높게 유도되도록 Q 함수를 학습시킬 수 있다. 이로써, 가상 EMR 에피소드를 이용한 보상의 과추정이 방지될 수 있고, 실제 의사의 정책이 반영될 수 있 다. 즉, 는 강화학습 Q를 통한 환자상태 S 및 치료방 법 a에 대응하는 보상의 기대값에서, 유사한 환자상태 및 치료방법 a에 대응하는 보상의 기대값의 차이를 나타낸다. 강화학습 Q가 환자의 상태 S에 대해 치료방법 a를 계획했을 때, 실제 의료기관에서도 환자의 상태 에 대해 치료방법 a를 계획한 경우, 두 기대값의 차이가 최소화될 수 있어, 해당 강화학습 Q가 선택의 방향으로 강 화되도록 상태 가치 평가를 위한 모델의 파라미터들이 업데이트될 수 있다. 반대로 강화학습 Q가 S 상태에서 치 료방법 a를 계획하였지만, 실제 의료기관에서는 환자의 상태 에 대해 치료방법 a를 수행하지 않은 경우, 두 기대값의 차이는 증가할 수 있고, 해당 강화학습 Q는 선택되지 않는 방향으로 강화되도록 상태 가치 평가를 위 한 모델의 파라미터들이 업데이트될 수 있다. 는 일반적인 벨만 방정식(Bellman equation)에 해당한다. 따라서, 상술한 수학식 1에 따르면 가상의 환자 상태에 대해 치료방법을 계획했을 때 보상의 기대값과, 실제 환 자 상태에 대해 의료기관이 치료방법을 계획했을 때 보상의 기대값 차이가 최소화될 수 있는 강화학습 Q가 선택 될 수 있고(즉, 두 차이를 모두 최소화시킬 수 있는 Q를 선택하는 것, ), 일반적인 강화학습의 최적화 방법도 함께 사용될 수 있다. 이로써, 본 개시의 실시 예에 따르면 모델 기반 강화학습과 유사 에피소드 샘플링 을 통한 에피소드 기반 강화학습을 결합한 강화학습을 의료 데이터에 대해 적용할 수 있다. 학습된 함수 Q, 그 리고 학습된 Q를 사용하여 계산된 Q(S`, A) 값은 치료 방법 학습 모듈로 제공되어, 실시간 치료방법 추천 네트워크의 업데이트와, 최적 치료시기 탐색에 사용될 수 있다. 도 6은 도 3의 치료방법 학습 모듈의 동작을 개념적으로 나타낸다. 상술한 바와 같이, 치료방법 학습 모듈 은 실시간으로 환자의 상태에 적합한 치료방법을 추천하기 위한 실시간 치료방법 추천 네트워크(예를 들어, CNN, RNN 등의 뉴럴 네트워크 등으로 구현)를 포함할 수 있다. 실시간 치료방법 추천 네트워크의 여러 파 라미터들은 상태 가치 평가 모듈로부터 학습된 함수 Q에 기반하여 지속적으로 업데이트될 수 있다. 예를 들어, 실시간 치료방법 추천 네트워크의 파라미터들은 값을 최소화하도록 업데이 트될 수 있다. 여기서 는 정책 π의 미분 값에 해당한다. 이로써, 실시간 치료방법 추천 네트워크 는 Q(S, A) 값을 최대화하는 치료방법 A를 선택하도록 업데이트될 수 있다. 또한, 치료방법 학습 모듈은 최적의 치료 시기 및 치료방법을 선택하고 예측할 수 있다. 먼저 상술한 네트 워크를 통해 주어진 환자의 상태 S에 대해 치료방법 A를 예측할 수 있다. 최적의 치료 시기를 탐색하기 위해, 치료방법 학습 모듈은 균일한 시간 간격 T1~Tn에 대해 환자 상태 예측 장치에 환자 상태 S 및 예측된 치료방법 A를 입력시킬 수 있다(즉, (S, A, T1), (S, A, T2), …(S, A, Tn)). 환자 상태 예측 장치는 각 시점에 대응하는 환자의 다음 상태 S'를 반환할 수 있다(즉, (S`, A, T1), (S`, A, T2), …(S`, A, Tn)). 이와 같이 반환된 n개의 환자의 상태 S`와 치료방법 A는 다시 상태 가치 평가 모듈로 전달될 수 있고, 상태 가 치 평가 모듈은 n개의 Q(S`, A)를 계산할 수 있으며, 그 중 보상이 최대가 되는 값 Q(S`, A)를 구할 수 있 다. 이 때 보상이 최대가 되는 시점이 최적 치료 시기 T로서 출력될 수 있다. 최대가 되는 Q(S`, A)가 구해지면, 치료방법 학습 모듈은 다시 이를 활용하여 상술한 실시간 치료방법 추천 네트워크의 파라미터들 을 업데이트할 수 있다. 다시 업데이트된 치료방법 추천 네트워크를 통해, 최적의 치료방법 A가 출력될 수 있다. 이로써, 본 개시의 실시 예에 따르면 시간 간격을 고려한 강화학습이 가능할 수 있다. 도 7은 도 3의 가상 에피소드 생성 모듈의 동작을 개념적으로 나타낸다. 가상 에피소드 생성 모듈는 치료방법 학습 모듈로부터 수신한 최적 치료 시기 T, 치료 방법 A, 그리고 환자 상태 예측 장치가 예 측한 값들 중 최적 치료 시기 T에 대응하는 환자의 다음 상태 S` 및 보상 R을 포함하는 가상 EMR 에피소드를 생 성할 수 있다. 생성된 가상 EMR 에피소드는 치료경로 탐색 장치 내부의 임시 메모리 또는 스토리지 장치에 저장될 수 있고, 향후 에피소드 샘플링 모듈의 입력으로서 사용될 수 있다. 도 8은 본 개시의 실시 예에 따른 최적 치료경로를 탐색하기 위한 방법을 나타내는 흐름도이다. 이하 도 8과 함 께, 도 2를 참조하여 설명한다. 단계 S110에서, 에피소드 샘플링 모듈은 입력 받은 가상 EMR 에피소드와 유사한 실제 EMR 에피소드를 추출 하고 매칭하여, 실제 EMR 에피소드와 가상 EMR 에피소드의 쌍을 상태 가치 평가 모듈로 제공할 수 있다. 단계 S120에서, 상태 가치 평가 모듈은 환자의 현재 상태에서 특정 치료방법에 따라 치료를 수행했을 때보상의 기대값을 예측할 수 있고, 보상의 기대값을 구하기 위한 함수 Q를 학습시킬 수 있다. 단계 S130에서, 치료방법 학습 모듈은 환자 상태 예측 장치와의 상호작용을 통해, 환자의 현재 상태 에 대해 보상을 최대화할 수 있는 치료방법 및 최적의 치료 시기를 예측할 수 있다. 구체적으로, 치료방법 학습 모듈은 환자의 현재 상태 및 치료방법을 환자 상태 예측 장치로 제공하여 예측된 환자의 다음 상태 및 보상을 획득할 수 있다. 단계 S140에서, 가상 에피소드 생성 모듈은 예측된 보상, 환자의 다음 상태, 치료방법, 최적의 치료 시기에 기반하여 가상 EMR 에피소드를 생성할 수 있다. 생성된 가상 EMR 에피소드는 치 료경로 탐색 장치 내부의 임시 메모리 또는 스토리지 장치에 저장될 수 있고, 에피소드 샘플링 모듈 의 입력으로서 사용될 수 있다. 상술된 내용은 본 개시를 실시하기 위한 구체적인 실시 예들이다. 본 개시는 상술된 실시 예들뿐만 아니라, 단 순하게 설계 변경되거나 용이하게 변경할 수 있는 실시 예들 또한 포함할 것이다. 또한, 본 개시는 실시 예들을 이용하여 용이하게 변형하여 실시할 수 있는 기술들도 포함될 것이다. 따라서, 본 개시의 범위는 상술된 실시 예들에 국한되어 정해져서는 안 되며 후술하는 특허청구범위뿐만 아니라 본 개시의 특허청구범위와 균등한 것들 에 의해 정해져야 할 것이다."}
{"patent_id": "10-2022-0189362", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 개시의 실시 예에 따른 최적 치료경로를 탐색하기 위한 시스템의 구성을 나타내는 블록도이다. 도 2는 도 1의 치료경로 탐색 장치의 구성을 나타내는 블록도이다. 도 3은 도 2의 치료경로 탐색 장치의 동작을 개념적으로 나타낸다. 도 4는 도 3의 에피소드 샘플링 모듈의 동작을 개념적으로 나타낸다. 도 5는 도 3의 상태 가치 평가 모듈의 동작을 개념적으로 나타낸다. 도 6은 도 3의 치료방법 학습 모듈의 동작을 개념적으로 나타낸다. 도 7은 도 3의 가상 에피소드 생성 모듈의 동작을 개념적으로 나타낸다. 도 8은 본 개시의 실시 예에 따른 최적 치료경로를 탐색하기 위한 방법을 나타내는 흐름도이다."}
