{"patent_id": "10-2023-0019133", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0146437", "출원번호": "10-2023-0019133", "발명의 명칭": "동영상 데이터를 이용한 의료 인공지능 모델 학습 방법", "출원인": "주식회사 웨이센", "발명자": "오상일"}}
{"patent_id": "10-2023-0019133", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "동영상 데이터를 이용하여 실시간 검사 환경에서의 실시간 검사가 가능한 의료 인공지능 모델을 학습시키는 방법으로서,a) 상기 의료 인공지능 모델이 상기 동영상 데이터로서 인체 내부의 임의의 장기에 대한 연속된 비디오 프레임과, 키 프레임의 대상 영역 마스크를 입력받는 단계와;b) 상기 입력받은 연속된 비디오 프레임을 컨볼루션 레이어들(convolutional layers)로 정렬하고, 정렬된 컨볼루션 레이어들에서 각 프레임별 컨볼루션 레이어의 결과물을 출력하는 단계와;c) 상기 출력된 각 프레임별 컨볼루션 레이어의 결과물들을 입력된 시간 순서에 따라 3차원 방향으로 적층하여3차원 동영상의 특징 지도 데이터를 생성하는 단계와;d) 상기 생성된 3차원 동영상의 특징 지도 데이터를 시퀀스 네트워크(sequential network)에 적용하여 시계열정보로 처리하는 단계와;e) 상기 처리된 시계열 정보를 바탕으로 클래스별 최종 유사 확률을 구하고, 구해진 최종 확률과 비디오의 정답클래스를 토대로 분류 손실(LC)을 측정하는 단계와;f) 상기 단계 b)에서 출력된 각 프레임별 컨볼루션 레이어의 결과물들로부터 프레임별 활성화 지도(activationmap)를 추출하고, 추출된 활성화 지도의 활성화 영역과 상기 키 프레임의 대상 영역 마스크의 정답 영역 간의위치 유사도(LMF)를 측정하는 단계; 및g) 상기 단계 e)에서 측정된 분류 손실(LC)과 상기 단계 f)에서 측정된 위치 유사도(LMF)를 합산하여 학습 손실을 측정하는 단계를 포함하고,상기 단계 d)에서 상기 생성된 3차원 동영상의 특징 지도 데이터를 시퀀스 네트워크(sequential network)에 적용하여 시계열 정보로 처리함에 있어서, 상기 시퀀스 네트워크로서의 한 개 이상의 LSTM(Long Short-TermMemory)을 적용하여 상기 단계 c)에서의 적층된 순서에 따라 단일 시간의 컨볼루션 레이어의 결과물과 이전 시간의 단기 상태 및 장기 상태를 입력으로 취해 현재 단일 시간의 단기 상태와 장기 상태를 출력으로 하는 순환방식으로 시계열 정보로 처리하는 동영상 데이터를 이용한 의료 인공지능 모델 학습 방법."}
{"patent_id": "10-2023-0019133", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 단계 g) 이후에 상기 측정된 학습 손실 결과를 바탕으로 상기 의료 인공지능 모델의 학습 중단 조건을 만족하는지를 판별하는 단계와; 학습 중단 조건을 만족하지 않으면 프로세스 진행을 상기 단계 a)로 회귀시키고,학습 중단 조건을 만족하면 프로세스를 종료하는 단계를 더 포함하는 동영상 데이터를 이용한 의료 인공지능 모델 학습 방법."}
{"patent_id": "10-2023-0019133", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 단계 d)에서 상기 시퀀스 네트워크는 LSTM(Long Short-Term Memory), GRU(Gated Recurrent Unit)를 포함하는 것을 특징으로 하는 동영상 데이터를 이용한 의료 인공지능 모델 학습 방법.공개특허 10-2023-0146437-3-청구항 4 제1항에 있어서,상기 단계 e)에서 상기 분류 손실(LC)은 Crossentropy, Mean Squared error, Mean Absolute error, Root meansquare error 중 하나를 이용하여 측정하는 것을 특징으로 하는 동영상 데이터를 이용한 의료 인공지능 모델 학습 방법."}
{"patent_id": "10-2023-0019133", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서,상기 단계 f)에서 상기 프레임별 활성화 영역과 상기 정답 영역 간의 위치 유사도(LMF)는 2차원 데이터 유사도측정 방법을 이용하여 측정하는 것을 특징으로 하는 동영상 데이터를 이용한 의료 인공지능 모델 학습 방법."}
{"patent_id": "10-2023-0019133", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5항에 있어서,상기 2차원 데이터 유사도 측정 방법은 Dice coefficient, L1 loss, L2 loss를 포함하는 것을 특징으로 하는동영상 데이터를 이용한 의료 인공지능 모델 학습 방법."}
{"patent_id": "10-2023-0019133", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 동영상 데이터를 이용한 의료 인공지능 모델 학습 방법에 관한 것이다. 본 발명에 따른 동영상 데이터를 이용한 의료 인공지능 모델 학습 방법은, 의료 인공지능 모델이 동영상 데이터 로서 인체 내부의 임의의 장기에 대한 연속된 비디오 프레임과, 키 프레임의 대상 영역 마스크를 입력받는 단계; (뒷면에 계속)"}
{"patent_id": "10-2023-0019133", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 인공지능 모델 학습 방법에 관한 것으로서, 더 상세하게는 초음파 등 실시간 검사가 이루어지는 환경 에서 실시간 검사가 가능한 의료 인공지능 모델을 도입하여 학습시킴으로써, 실시간 검사 환경에서 발생하는 다 양한 위협 요소에도 능동적으로 대처할 수 있는 동영상 데이터를 이용한 의료 인공지능 모델 학습 방법에 관한 것이다."}
{"patent_id": "10-2023-0019133", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "CT(Computed Tomography) 및 MRI(Magnetic Resonance Imaging)와 같이 촬영 후 진단에 활용하는 환경과 달리, 내시경이나 초음파 등 실시간 검사가 이루어지는 환경에서는 실시간 검사가 가능한 인공지능 모델이 필요하다. 실시간 검사 환경(전향적 진단)에서는 초당 약 30 프레임의 이미지가 연속적으로 입력되며, 검사자의 움직임, 피검사자의 호흡 등에 의해 크고 작은 노이즈가 지속적으로 촬영된다. 따라서, 실시간 의료 진단 보조를 위한 내시경(또는 초음파 기기 등) 검사 환경에서 동작하는 인공지능 모델의 도입이 필요하다. 하지만, 현존하는 대부분의 의료 인공지능 모델의 경우 깨끗(선명)하게 촬영된 정지 영상을 수집하여 인공지능 모델의 학습에 활용하고 있으며, 이에 따라 실시간 검사 환경에서 발생하는 다양한 위협요소를 다루지 못하고 있다. 동영상 데이터를 활용한 대부분의 기존 방법은 수동 프레임 선택(manual frame selection) 과정을 통해 적용하는 수준이다. 정지영상으로 학습된 인공지능 모델이 정지영상에서 평가 시 높은 성능을 보이더라도, 실시 간 검사 환경과 동일한 동영상 데이터에서는 성능이 매우 떨어지는 문제점이 있다. 한편, 한국 공개특허공보 제10-2021-0072362호(특허문헌 1)에는 \"인공 지능 모델에 대한 학습 데이터를 생성하 는 인공 지능 장치 및 그 방법\"이 개시되어 있는 바, 이에 따른 학습 데이터를 생성하는 방법은 마이크로폰 또 는 카메라를 포함하는 입력부를 통해 입력 데이터를 수신하는 단계; 인공 지능 모델을 이용하여 상기 입력 데이 터에 대응하는 추론 결과를 생성하는 단계; 상기 추론 결과에 대응하는 피드백을 수신하는 단계; 상기 인공 지 능 모델의 갱신에 대한 상기 입력 데이터 및 상기 피드백의 적합성을 판단하는 단계; 및 상기 입력 데이터 및 상기 피드백이 상기 인공 지능 모델의 갱신에 적합한 것으로 판단된 경우에 상기 입력 데이터 및 상기 피드백에 기초하여 학습 데이터를 생성하는 단계를 포함하는 것을 특징으로 한다.이상과 같은 특허문헌 1의 경우, 우연히 또는 악의적으로 잘못된 데이터가 생성 및 수집된다 하더라도, 수집되 는 데이터가 인공 지능 모델의 갱신에 적합한 데이터인지 미리 판단하고, 인공 지능 모델의 갱신에 부적절한 데 이터를 배제함으로써, 인공 지능 모델이 부적절하게 갱신되는 상황을 방지할 수 있는 장점이 있기는 하나, 인공 지능 모델이 입력 데이터에 대응하는 추론 결과를 생성하고, 추론 결과에 대응하는 피드백을 수신하여 인공 지 능 모델의 갱신에 대한 입력 데이터 및 피드백의 적합성을 판단하는 등의 일련의 동작은 어떠한 일의 사후에 발 생한 데이터를 기반으로 하는 것이며, 따라서 내시경이나 초음파 등 실시간 검사가 이루어지는 환경에서 실시간 으로 적용하기 어려운 단점이 있다. 선행기술문헌 특허문헌 (특허문헌 0001) 한국 공개특허공보 제10-2021-0072362호(2021.06.17.)"}
{"patent_id": "10-2023-0019133", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 상기와 같은 사항을 종합적으로 감안하여 창출된 것으로서, 초음파 등 실시간 검사가 이루어지는 환 경에서 실시간 검사가 가능한 의료 인공지능 모델을 도입하여 학습시킴으로써, 실시간 검사 환경에서 발생하는 다양한 위협 요소에도 능동적으로 대처할 수 있는 동영상 데이터를 이용한 의료 인공지능 모델 학습 방법을 제 공함에 그 목적이 있다."}
{"patent_id": "10-2023-0019133", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기의 목적을 달성하기 위하여 본 발명에 따른 동영상 데이터를 이용한 의료 인공지능 모델 학습 방법은, 동영상 데이터를 이용하여 실시간 검사 환경에서의 실시간 검사가 가능한 의료 인공지능 모델을 학습시키는 방 법으로서, a) 상기 의료 인공지능 모델이 상기 동영상 데이터로서 인체 내부의 임의의 장기에 대한 연속된 비디오 프레임 과, 키 프레임의 대상 영역 마스크를 입력받는 단계와; b) 상기 입력받은 연속된 비디오 프레임을 컨볼루션 레이어들(convolutional layers)로 정렬하고, 정렬된 컨볼 루션 레이어들에서 각 프레임별 컨볼루션 레이어의 결과물을 출력하는 단계와; c) 상기 출력된 각 프레임별 컨볼루션 레이어의 결과물들을 입력된 시간 순서에 따라 3차원 방향으로 적층하여 3차원 동영상의 특징 지도 데이터를 생성하는 단계와; d) 상기 생성된 3차원 동영상의 특징 지도 데이터를 시퀀스 네트워크 (sequential network)에 적용하여 시계열 정보로 처리하는 단계와; e) 상기 처리된 시계열 정보를 바탕으로 클래스별 최종 유사 확률을 구하고, 구해진 최종 확률과 비디오 정답 클래스를 토대로 분류 손실(LC)을 측정하는 단계와; f) 상기 단계 b)에서 출력된 각 프레임별 컨볼루션 레이어의 결과물들로부터 프레임별 활성화 지도(activation map)를 추출하고, 추출된 활성화 지도의 활성화 영역과 상기 키 프레임의 대상 영역 마스크의 정답 영역 간의 위치 유사도(LMF)를 측정하는 단계; 및 g) 상기 단계 e)에서 측정된 분류 손실(LC)과 상기 단계 f)에서 측정된 위치 유사도(LMF)를 합산하여 학습 손실 을 측정하는 단계를 포함하고, 상기 단계 d)에서 상기 생성된 3차원 동영상의 특징 지도 데이터를 시퀀스 네트워크(sequential network)에 적 용하여 시계열 정보로 처리함에 있어서, 상기 시퀀스 네트워크로서의 한 개 이상의 LSTM(Long Short-Term Memory)을 적용하여 상기 단계 c)에서의 적층된 순서에 따라 단일 시간의 컨볼루션 레이어의 결과물과 이전 시간의 단기 상태 및 장기 상태를 입력으로 취해 현재 단일 시간의 단기 상태와 장기 상태를 출력으로 하는 순환 방식으로 시계열 정보로 처리하는 점에 그 특징이 있다. 여기서, 상기 단계 g) 이후에 상기 측정된 학습 손실 결과를 바탕으로 상기 의료 인공지능 모델의 학습 중단 조 건을 만족하는지를 판별하는 단계와; 학습 중단 조건을 만족하지 않으면 프로세스 진행을 상기 단계 a)로 회귀 시키고, 학습 중단 조건을 만족하면 프로세스를 종료하는 단계를 더 포함할 수 있다. 또한, 상기 단계 d)에서 상기 시퀀스 네트워크는 LSTM(Long Short-Term Memory), GRU(Gated Recurrent Unit) 등을 포함할 수 있다. 또한, 상기 단계 e)에서 상기 분류 손실(LC)은 Crossentropy(binary, categorigal 등), Mean Squared error, Mean Absolute error, Root mean square error 등을 이용하여 측정할 수 있다. 또한, 상기 단계 f)에서 상기 프레임별 활성화 영역과 상기 정답 영역 간의 위치 유사도(LMF)는 2차원 데이터 유 사도 측정 방법을 이용하여 측정할 수 있다. 이때, 상기 2차원 데이터 유사도 측정 방법은 Dice coefficient, L1 loss, L2 loss 등을 포함할 수 있다."}
{"patent_id": "10-2023-0019133", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "이와 같은 본 발명에 의하면, 초음파 등 실시간 검사가 이루어지는 환경에서 실시간 검사가 가능한 의료 인공지 능 모델을 도입하여 학습시킴으로써, 실시간 검사 환경에서 발생하는 다양한 위협 요소에도 능동적으로 대처할 수 있는 장점이 있다. 또한, 동영상 데이터 태깅에 요구되는 시간과 인력을 최소화 할 수 있고, 별도의 모듈 없이 실시간 진단 환경에 타겟 분류 및 병변 국소화가 가능하며, 실시간 검사 환경에서 안정적인 분류 결과를 표출함으로써 검사자에게 도움을 줄 수 있는 효과가 있다."}
{"patent_id": "10-2023-0019133", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 명세서 및 청구범위에 사용된 용어나 단어는 통상적이거나 사전적인 의미로 한정되어 해석되지 말아야 하며, 발명자는 그 자신의 발명을 가장 최선의 방법으로 설명하기 위해 용어의 개념을 적절하게 정의할 수 있다는 원 칙에 입각하여 본 발명의 기술적 사상에 부합하는 의미와 개념으로 해석되어야 한다. 명세서 전체에서, 어떤 부분이 어떤 구성요소를 \"포함\"한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다 른 구성요소를 제외하는 것이 아니라 다른 구성요소를 더 포함할 수 있다는 것을 의미한다. 또한, 명세서에 기 재된 \"…부\", \"…기\", \"모듈\", \"장치\" 등의 용어는 적어도 하나의 기능이나 동작을 처리하는 단위를 의미하며, 이는 하드웨어나 소프트웨어 또는 하드웨어 및 소프트웨어의 결합으로 구현될 수 있다. 이하 첨부된 도면을 참조하여 본 발명의 실시예를 상세히 설명한다. 도 1은 본 발명의 실시예에 따른 동영상 데이터를 이용한 의료 인공지능 모델 학습 방법의 실행 과정을 나타낸 흐름도이고, 도 2는 본 발명에 따른 동영상 데이터를 이용한 의료 인공지능 모델 학습 방법의 시퀀스 동작 과정 을 나타낸 도면이다. 도 1 및 도 2를 참조하면, 본 발명에 따른 동영상 데이터를 이용한 의료 인공지능 모델 학습 방법은, 동영상 데 이터를 이용하여 실시간 검사 환경에서의 실시간 검사가 가능한 의료 인공지능 모델을 학습시키는 방법으 로서, 먼저 상기 의료 인공지능 모델이 상기 동영상 데이터로서 인체 내부의 임의의 장기에 대한 연속된 비디오 프레임(예를 들면, 임의의 시간 t에서의 연속된 10 프레임또는 15 프레임 등)과, 키 프레임의 대상 영역 마스크를 입력받는다(단계 S101). 여기서, 상기 키 프레임의 대상 영역 마스크는 본 발명의 동 영상 데이터를 이용한 의료 인공지능 모델 학습 방법을 구현하기 위해 구축된 시스템(미도시)의 운용자 또는 의 료진, AI 등에 의해 태깅될 수 있다. 또한, 이와 같은 키 프레임의 대상 영역 마스크는 상기 연속된 비디 오 프레임들 중 임의의 프레임을 키 프레임으로 선택하여 지정될 수 있다. 이렇게 하여 연속된 비디오 프레임이 의료 인공지능 모델에 입력되면, 의료 인공지능 모델은 입 력받은 연속된 비디오 프레임을 컨볼루션 레이어들(convolutional layers)로 정렬하고, 정렬된 컨볼 루션 레이어들에서 각 프레임별 컨볼루션 레이어의 결과물을 출력한다(단계 S102). 그런 후, 출력된 각 프레임별 컨볼루션 레이어의 결과물들을 입력된 시간 순서에 따라 3차원 방향으로 적 층하여 3차원 동영상의 특징 지도 데이터를 생성한다(단계 S103). 여기서, 상기 출력된 각 프레임별 컨볼 루션 레이어의 결과물들을 적층하는(stacked) 방법 외에도 다른 방법이 사용될 수도 있다. 이후, 상기 생성된 3차원 동영상의 특징 지도 데이터를 시퀀스 네트워크(sequential network)에 적용하여 시계열 정보로 처리한다(단계 S104). 여기서, 이와 같은 시퀀스 네트워크는 입력과 출력을 시퀀스 단위(예 를 들면, 연속된 데이터, 시계열 데이터 등)로 처리하는 역할을 한다. 이때, 상기 시퀀스 네트워크는 LSTM(Long Short-Term Memory), GRU(Gated Recurrent Unit) 등을 포함할 수 있다. 여기서, 또한 상기 생성된 3 차원 동영상의 특징 지도 데이터를 시퀀스 네트워크(sequential network)에 적용하여 시계열 정보로 처리함에 있어서, 상기 시퀀스 네트워크로서의 한 개 이상의 LSTM(Long Short-Term Memory)을 적용하여 상기 단계 S103에 서의 적층된 순서에 따라 단일 시간의 컨볼루션 레이어의 결과물과 이전 시간의 단기 상태 및 장기 상태를 입력 으로 취해 현재 단일 시간의 단기 상태와 장기 상태를 출력으로 하는 순환 방식으로 시계열 정보로 처리할 수 있다. 이렇게 하여 3차원 동영상의 특징 지도 데이터를 시퀀스 네트워크에 적용하여 시계열 정보(혹은 연속된 정 보)로 처리가 완료되면, 그 처리된 시계열 정보를 바탕으로 클래스별 최종 유사 확률을 구하고, 구해진 최종 확 률과 비디오의 정답 클래스를 토대로 분류 손실(LC)을 측정한다(단계 S105). 여기서, 이와 같은 분류 손실(LC)은 입력된 연속 프레임의 분류 성능 측정을 위한 손실 함수로서 다음과 같은 수식 관계로 나타낼 수 있다. 수학식 1"}
{"patent_id": "10-2023-0019133", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "위의 수식에서 는 동영상 에 속하는 번째 프레임부터 번째 프레임 입력, 는 입력 연속 프레임의 네트워크 출력 확률, 는 학습 동영상 수, 는 동영상 의 전체 프레임 수, 는 입력으로 사용할 연속 프레임 수, 는 클래스, 는 번째 동영상의 정답 클래스를 각각 나타낸다. 여기서, 또한 이상과 같은 분류 손실(LC)은 Crossentropy(binary, categorigal 등), Mean Squared error, Mean Absolute error, Root mean square error 등을 이용하여 측정할 수 있다. 한편, 이상에 의해 입력된 연속 프레임에 대한 분류 손실(LC)을 측정하는 한편, 상기 단계 S102에서 출력된 각 프레임별 컨볼루션 레이어의 결과물들로부터 프레임별 활성화 지도(activation map)를 추출하고, 추출된 활성화 지도의 활성화 영역과 상기 키 프레임의 대상 영역 마스크의 정답 영역 간의 위치 유사도(LM F)를 측정한다(단계 S106). 여기서, 상기 프레임별 활성화 영역과 상기 정답 영역 간의 위치 유사도(LMF)는 2차 원 데이터 유사도 측정 방법을 이용하여 측정할 수 있다. 이때, 상기 2차원 데이터 유사도 측정 방법은 Dice coefficient, L1 loss, L2 loss 등을 포함할 수 있다. 여기서, 또한 상기 프레임별 활성화 영역과 상기 정답 영 역 간의 위치 유사도(LMF)는 입력된 연속 프레임의 활성화 지도와 키 프레임의 정답 마스크 사이의 유사도 측정 을 위한 손실 함수로서, 이는 적은 양의 학습 데이터에서 최대한 일반화된 분류 성능을 확보하기 위한 것이다. 이상과 같은 프레임별 활성화 영역과 상기 정답 영역 간의 위치 유사도(LMF)는 다음과 같은 수식 관계로 나타낼 수 있다. 수학식 2"}
{"patent_id": "10-2023-0019133", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "위의 수식에서 는 2D 비유사도(dissimilarity), 는 동영상 에 속하는 병변 영역이 태깅된 프레임"}
{"patent_id": "10-2023-0019133", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "중 번째 프레임과 가장 가까운 프레임 의 정답 마스크, 는 번째 프레임의 활성화 지도, 는 학습 동영상 수, 는 동영상 의 전체 프레임 수, 는 입력으로 사용할 연속 프레임 수를 각각 나타낸다. 이렇게 하여 프레임별 활성화 영역과 정답 영역 간의 위치 유사도(LMF)의 측정이 완료되면, 상기 단계 S105에서 측정된 분류 손실(LC)과 상기 측정된 위치 유사도(LMF)를 합산하여 학습 손실을 측정한다(단계 S107). 여기서, 이와 같은 학습 손실은 그 손실값이 작을수록 학습 결과(효과)가 양호하다고 할 수 있으며, 이는 곧 의료 인공 지능 모델의 성능이 우수함을 의미하는 것으로 볼 수 있다. 여기서, 또한 상기 단계 S107 이후에 상기 측정된 학습 손실 결과를 바탕으로 상기 의료 인공지능 모델의 학습 중단 조건을 만족하는지를 판별하는 단계와; 학습 중단 조건을 만족하지 않으면 프로세스 진행을 상기 단계 S101로 회귀시키고, 학습 중단 조건을 만족하면 프로세스를 종료하는 단계를 더 포함할 수 있다. 이하에서는 이상과 같은 본 발명에 따른 동영상 데이터를 이용한 의료 인공지능 모델 학습 방법과 관련하여 조 금 더 설명을 부가해 보기로 한다. 도 3은 본 발명에 따른 동영상 데이터를 이용한 의료 인공지능 모델 학습 방법에 있어서, 시퀀스 네트워크 적용 개념을 도식적으로 나타낸 도면이다. 도 3을 참조하면, (a)는 도 2에서의 참조 번호 205, 211, 212, 213까지의 순차적인 과정을 나타낸 것이다. 즉, 의료 인공지능 모델에 연속된 비디오 프레임이 입력되면, 의료 인공지능 모델은 입력받은 연속 된 비디오 프레임을 컨볼루션 레이어들(convolutional layers)로 정렬하고, 정렬된 컨볼루션 레이어 들에서 각 프레임별 컨볼루션 레이어의 결과물을 출력한다. 그런 후, 출력된 각 프레임별 컨볼루션 레이어의 결과물들을 입력된 시간 순서에 따라 3차원 방향으로 적층하여 3차원 동영상의 특징 지도 데이터를 생성한다. 이렇게 하여 3차원 동영상의 특징 지도 데이터가 생성되면, 그 생성된 3차원 동영상의 특징 지도 데이터를 시퀀 스 네트워크, 예를 들면, (b)와 같이 한 개 이상의 LSTM(311∼313)을 적용하여 적층된 순서에 따라 각 프레임별 컨볼루션 레이어의 결과물을 단일 시간 정보로 다루어 시계열 처리를 적용한다. 여기서 LSTM은 단일 시간의 컨 볼루션 레이어의 결과물과 이전 시간의 단기 상태 및 장기 상태를 입력으로 취해 현재 단일 시간의 단기 상태와 장기 상태를 출력으로 하는 순환 방식으로 시계열 정보로 처리한다. 이와 같이 입력된 동영상 연속 프레임의 특 정 지도 데이터를 시퀀스 네트워크를 통해 시계열 정보로 처리함으로써, 초음파 등 실시간 검사가 이루어지는 환경에서 발생하는 다양한 위협 요소에도 능동적으로 대처할 수 있게 된다. 도 4는 본 발명에 따른 동영상 데이터를 이용한 의료 인공지능 모델 학습 방법에 있어서, 활성화 영역과 정답 영역 간의 위치 유사도 측정 개요를 나타낸 도면이다. 도 4를 참조하면, 전술한 바와 같이 연속된 비디오 프레임이 입력되면, 의료 인공지능 모델은 입력받 은 연속된 비디오 프레임에 대해 키 프레임의 대상 영역 마스크의 병변 영역을 태깅하여 비디오 프레 임의 각 프레임별 컨볼루션 레이어의 결과물들로부터 프레임별 활성화 지도(activation map) 를 추출 하고, 추출된 활성화 지도의 활성화 영역과 상기 키 프레임의 대상 영역 마스크의 정답 영역 간의 위 치 유사도(LMF)를 측정한다. 이와 같은 프레임별 활성화 영역과 정답 영역 간의 위치 유사도(LMF)는 입력된 연속 프레임의 활성화 지도와 키프레임의 정답 마스크 사이의 유사도 측정을 위한 것으로서, 이를 통해 적은 양의 학 습 데이터에서 최대한 일반화된 분류 성능을 확보할 수 있게 된다. 도 5는 본 발명의 동영상 데이터를 이용한 의료 인공지능 모델 학습 방법에 따른 학습 과정을 나타낸 도면이다. 도 5를 참조하면, 이는 앞에서 도 2의 흐름도를 통해 설명한 본 발명의 동영상 데이터를 이용한 의료 인공지능 모델 학습 방법에 대해 프로세스(프로그램) 진행 과정을 보여주는 것이다. 도 5에 도시된 바와 같이, 연속된 비디오 프레임(도 2 참조)이 의료 인공지능 모델에 입력되면 (S501), 의료 인공지능 모델은 입력받은 연속된 비디오 프레임을 컨볼루션 레이어들로 정렬하고 (S502), 정렬된 컨볼루션 레이어들에서 각 프레임별 컨볼루션 레이어의 결과물을 출력한다(S503). 그런 후, 출력된 각 프레임별 컨볼루션 레이어의 결과물들을 입력된 시간 순서에 따라 3차원 방향으로 적층하여 (S504) 3차원 동영상의 특징 지도 데이터를 생성하고, 생성된 3차원 동영상의 특징 지도 데이터를 시퀀스 네트 워크에 적용하여(S505) 시계열 정보로 처리한다. 여기서, 상기 생성된 3차원 동영상의 특징 지도 데이터를 시퀀 스 네트워크에 적용하여 시계열 정보로 처리함에 있어서, 상기 시퀀스 네트워크로서의 한 개 이상의 LSTM(Long Short-Term Memory)을 적용하여 상기 단계 S504에서의 적층된 순서에 따라 단일 시간의 컨볼루션 레이어의 결과 물과 이전 시간의 단기 상태 및 장기 상태를 입력으로 취해 현재 단일 시간의 단기 상태와 장기 상태를 출력으 로 하는 순환 방식으로 시계열 정보로 처리할 수 있다. 그런 다음, 시계열 정보를 바탕으로 클래스별 최종 유사 확률을 구하고(S506), 구해진 최종 확률과 비디오의 정 답 클래스(S507)를 토대로 분류 손실(LC)을 측정한다(S508). 이때, 바람직하게는 분류 손실(LC)을 측정의 정확도 를 높이기 위해 비디오의 정답 클래스 데이터를 더 제공받아(S507) 분류 손실(LC)을 측정할 수 있다. 한편, S503에서 출력된 각 프레임별 컨볼루션 레이어의 결과물들로부터 프레임별 활성화 지도(activation map) 를 추출하고(S510), 추출된 활성화 지도의 활성화 영역과 키 프레임의 대상 영역 마스크(S509)의 정답 영역 간 의 위치 유사도(LMF)를 측정한다(S512). 여기서, 이와 같은 위치 유사도(LMF)의 측정을 위해 키 프레임의 대상 영역 마스크가 사전에 입력된다. 이렇게 하여 프레임별 활성화 영역과 정답 영역 간의 위치 유사도(LMF)의 측정이 완료되면, 상기 S508에서 측정 된 분류 손실(LC)과 위에서 측정된 위치 유사도(LMF)를 합산하여 학습 손실을 측정한다(S513). 이후에 상기 측정된 학습 손실 결과를 바탕으로 상기 의료 인공지능 모델의 학습 중단 조건을 만족하는지를 판 별한다(S514). 이 판별에서 학습 중단 조건을 만족하지 않으면 프로세스 진행을 S501로 회귀시키고, 학습 중단 조건을 만족하면 프로세스를 종료한다. 도 6은 본 발명의 방법에 채용되는 의료 인공지능 모델의 모의 실시간 검사 환경에서의 추론 과정을 나타낸 도 면이다. 도 6을 참조하면, 연속된 비디오 프레임(도 2 참조)이 의료 인공지능 모델에 입력되면(S601), 의료 인공지능 모델은 입력받은 연속된 비디오 프레임을 컨볼루션 레이어들로 정렬하고(S602), 정렬된 컨볼루션 레이어들에서 각 프레임별 컨볼루션 레이어의 결과물을 출력한다(S603). 그런 후, 출력된 각 프레임별 컨볼루션 레이어의 결과물들을 입력된 시간 순서에 따라 3차원 방향으로 적층하여 (S604) 3차원 동영상의 특징 지도 데이터를 생성하고, 생성된 3차원 동영상의 특징 지도 데이터를 시퀀스 네트 워크에 적용하여(S605) 시계열 정보로 처리한다. 여기서, 상기 생성된 3차원 동영상의 특징 지도 데이터를 시퀀 스 네트워크에 적용하여 시계열 정보로 처리함에 있어서, 상기 시퀀스 네트워크로서의 한 개 이상의 LSTM(Long Short-Term Memory)을 적용하여 상기 단계 S604에서의 적층된 순서에 따라 단일 시간의 컨볼루션 레이어의 결과 물과 이전 시간의 단기 상태 및 장기 상태를 입력으로 취해 현재 단일 시간의 단기 상태와 장기 상태를 출력으 로 하는 순환 방식으로 시계열 정보로 처리할 수 있다. 그런 다음, 시계열 정보를 바탕으로 클래스별 최종 유사 확률을 구한다(S606). 한편, S603에서 출력된 각 프레임별 컨볼루션 레이어의 결과물들로부터 활성화 지도를 추출하고(S607), 추출된 활성화 지도로부터 프레임별 활성화 지도(S608)를 출력한다. 그리고 출력된 프레임별 활성화 지도(S608)로부터 평균 활성화 지도를 구하여, 상기 클래스별 최종 유사 확률을 바탕으로 유사도 정도를 추론한다. 도 7은 종래 정지영상 분류기에 의한 검측 결과와 본 발명에 채용되는 동영상 분류기에 의한 검측 결과를 나타 낸 도면이다. 도 7을 참조하면, (a)는 종래 정지영상 분류기에 의한 검측 결과를 나타낸 것이고, (b)는 본 발명에 채용되는 동영상 분류기에 의한 검측 결과를 나타낸 것으로서, 동영상 데이터를 종래 정지영상 분류기와 본 발명에 채용 되는 동영상 분류기에 각각 입력했을 때, 출력 결과 그래프를 통해서도 알 수 있는 바와 같이, (a)의 종래 정지 영상 분류기에 의해서는 정답 1(SM)과 정답 2(M) 사이를 출력이 크게 진동하면서 변화하는 것을 볼 수 있고, (b)의 본 발명에 채용되는 동영상 분류기에 의해서는 출력이 약간 진동을 하기는 해도 일정한 허용범위 내에서 진동하면서 변화하는 것을 볼 수 있다. 이를 통해 본 발명의 방법이 적용될 경우, 실시간 검사 환경에서 안정적 인 분류 결과를 표출할 수 있게 됨을 알 수 있다. 이상의 설명과 같이, 본 발명에 따른 동영상 데이터를 이용한 의료 인공지능 모델 학습 방법은 초음파 등 실시 간 검사가 이루어지는 환경에서 실시간 검사가 가능한 인공지능 모델을 도입하여 학습시킴으로써, 실시간 검사 환경에서 발생하는 다양한 위협 요소에도 능동적으로 대처할 수 있는 장점이 있다. 또한, 동영상 데이터 태깅에 요구되는 시간과 인력을 최소화 할 수 있고, 별도의 모듈 없이 실시간 진단 환경에 타겟 분류 및 병변 국소화가 가능하며, 실시간 검사 환경에서 안정적인 분류 결과를 표출함으로써 검사자에게 도움을 줄 수 있는 효과가 있다. 이상, 바람직한 실시예를 통하여 본 발명에 관하여 상세히 설명하였으나, 본 발명은 이에 한정되는 것은"}
{"patent_id": "10-2023-0019133", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "아니며, 본 발명의 기술적 사상을 벗어나지 않는 범위 내에서 다양하게 변경, 응용될 수 있음은 당해 기술분야 의 통상의 기술자에게 자명하다. 따라서, 본 발명의 진정한 보호 범위는 다음의 청구범위에 의하여 해석되어야 하며, 그와 동등한 범위 내에 있는 모든 기술적 사상은 본 발명의 권리 범위에 포함되는 것으로 해석되어야 할 것이다."}
{"patent_id": "10-2023-0019133", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명에 따른 동영상 데이터를 이용한 의료 인공지능 모델 학습 방법의 실행 과정을 나타낸 흐름도이 다. 도 2는 본 발명에 따른 동영상 데이터를 이용한 의료 인공지능 모델 학습 방법의 시퀀스 동작 과정을 나타낸 도 면이다. 도 3은 본 발명에 따른 동영상 데이터를 이용한 의료 인공지능 모델 학습 방법에 있어서, 시퀀스 네트워크 적용 개념을 도식적으로 나타낸 도면이다. 도 4는 본 발명에 따른 동영상 데이터를 이용한 의료 인공지능 모델 학습 방법에 있어서, 활성화 영역과 정답 영역 간의 위치 유사도 측정 개요를 나타낸 도면이다. 도 5는 본 발명의 동영상 데이터를 이용한 의료 인공지능 모델 학습 방법에 따른 학습 과정을 나타낸 도면이다. 도 6은 본 발명의 방법에 채용되는 의료 인공지능 모델의 모의 실시간 검사 환경에서의 추론 과정을 나타낸 도 면이다. 도 7은 종래 정지영상 분류기에 의한 검측 결과와 본 발명에 채용되는 동영상 분류기에 의한 검측 결과를 나타 낸 도면이다."}
