{"patent_id": "10-2019-0057261", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2020-0132178", "출원번호": "10-2019-0057261", "발명의 명칭": "전자 장치 및 이의 제어 방법", "출원인": "삼성전자주식회사", "발명자": "권세중"}}
{"patent_id": "10-2019-0057261", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "전자 장치에 있어서, 메모리; 및 딥러닝 모델의 파라미터값들에 기초한 복수의 정방 행렬 중 어느 하나의 정방 행렬에 대해 행렬 분해(MatrixDecomposition)를 통한 로우 랭크 근사법(Low Rank Approximation)을 적용하여 상기 어느 하나의 정방 행렬에대한 근사된 제1 및 제2 행렬을 획득하고, 상기 어느 하나의 정방 행렬에 대한 근사된 제1 행렬에 기초하여 상기 복수의 정방 행렬 중 나머지 정방 행렬에대한 근사된 제2 행렬을 획득하며, 상기 어느 하나의 정방 행렬에 대한 근사된 제1 행렬 및 상기 복수의 정방 행렬에 대한 근사된 제2 행렬을 상기메모리에 저장하는 프로세서;를 포함하는 전자 장치."}
{"patent_id": "10-2019-0057261", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1 항에 있어서, 상기 프로세서는, 상기 어느 하나의 정방 행렬에 대해 특이값 분해(Singular Value Decomposition, SVD)를 통한 로우 랭크 근사법을 적용하여 상기 어느 하나의 정방 행렬에 대한 근사된 제1 및 제 2 행렬을 획득하는, 전자 장치."}
{"patent_id": "10-2019-0057261", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 2 항에 있어서, 상기 프로세서는, 상기 어느 하나의 정방 행렬에 상기 특이값 분해를 적용하여 제1 및 제2 행렬을 획득하고, 상기 제1 및 제2 행렬에 상기 로우 랭크 근사법을 적용하여 상기 어느 하나의 정방 행렬에 대한 근사된 제1 및 제2 행렬을 획득하는, 전자 장치."}
{"patent_id": "10-2019-0057261", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 3 항에 있어서, 상기 어느 하나의 정방 행렬에 대한 상기 근사된 제1 행렬은, 상기 어느 하나의 정방 행렬에 대한 근사된 오른쪽 특이값 벡터 행렬이고, 상기 복수의 정방 행렬 각각에 대한 근사된 제2 행렬은, 상기 복수의 정방 행렬 각각에 대한 근사된 왼쪽 특이값 벡터 행렬인, 전자 장치."}
{"patent_id": "10-2019-0057261", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제 3 항에 있어서, 상기 프로세서는, 상기 나머지 정방 행렬 각각에, 전치된 상기 제1 행렬의 역행렬을 곱하여 상기 나머지 정방 행렬 각각의 상기근사된 제2 행렬을 획득하는, 전자장치."}
{"patent_id": "10-2019-0057261", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제 1 항에 있어서, 공개특허 10-2020-0132178-2-상기 프로세서는,제2 정방 행렬과, 상기 제2 정방 행렬의 근사된 제2 행렬 및 상기 제1 정방 행렬의 근사된 제1 행렬의 곱의 차이를 최소화하는 연산(algorithm)을 통해 상기 제2 정방 행렬의 근사된 제2 행렬을 획득하며,상기 제1 정방 행렬은, 상기 어느 하나의 정방 행렬이고, 상기 제2 정방 행렬은, 상기 나머지 정방 행렬 중 어느 하나의 정방 행렬인, 전자 장치."}
{"patent_id": "10-2019-0057261", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "전자 장치에 있어서,압축된 딥러닝 모델을 구성하는, 근사된 제1 행렬 및 복수의 근사된 제2 행렬이 저장된 메모리; 및상기 메모리에 저장된 상기 압축된 딥러닝 모델을 로딩하고, 상기 압축된 딥러닝 모델에 기초하여 출력값을 획득하는 프로세서;를 포함하고, 상기 근사된 제1 행렬은, 딥러닝 모델의 파라미터 값들에 기초한 복수의 정방 행렬 중 어느 하나의 정방 행렬에 대해 행렬 분해를 통한로우 랭크 근사법이 적용되어 획득된 2 개의 행렬 중 어느 하나의 행렬이고, 상기 복수의 근사된 제2 행렬은, 상기 획득된 2 개의 행렬 중 다른 하나의 행렬과, 상기 근사된 제1 행렬 및 상기 복수의 정방 행렬 중 나머지정방 행렬에 기초하여 획득되는 행렬을 포함하는, 전자 장치."}
{"patent_id": "10-2019-0057261", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제 7 항에 있어서, 상기 근사된 제1 행렬은, 상기 어느 하나의 정방 행렬에 대해 특이값 분해를 통한 로우 랭크 근사법을 적용하여획득된 오른쪽 특이값 벡터 행렬이고, 상기 복수의 근사된 제2 행렬은, 상기 복수의 정방 행렬 각각에 대한 근사된 왼쪽 특이값 벡터 행렬인, 전자 장치."}
{"patent_id": "10-2019-0057261", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제 7 항에 있어서,상기 프로세서는, 연산부, 1차 캐시 메모리 및 2차 캐시 메모리를 더 포함하고, 상기 연산부는, 상기 메모리에 저장된 상기 근사된 제1 행렬을 상기 1차 캐시 메모리에 로딩하고, 상기 메모리에 저장된 상기복수의 근사된 제2 행렬 중 적어도 하나를 상기 2차 캐시 메모리에 로딩하고, 상기 1차 캐시 메모리 및 상기 2차 캐시 메모리에 로딩된 근사된 행렬에 기초하여 상기 출력 값을 획득하는, 전자 장치."}
{"patent_id": "10-2019-0057261", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제 9 항에 있어서,상기 연산부는, 입력 값 및 상기 1차 캐시 메모리에 로딩된 상기 근사된 제1 행렬에 기초하여 제1 연산을 수행하는 동안, 상기복수의 근사된 제2 행렬 중 적어도 하나의 근사된 제2 행렬을 상기 2차 캐시 메모리에 로딩하고, 상기 제1 연산결과 및 상기 2차 캐시 메모리에 로딩된 근사된 제2 행렬에 기초하여 제2 연산을 수행하는, 전자 장치."}
{"patent_id": "10-2019-0057261", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "전자 장치의 제어 방법에 있어서, 공개특허 10-2020-0132178-3-딥러닝 모델의 파라미터값들에 기초한 복수의 정방 행렬 중 어느 하나의 정방 행렬에 대해 행렬 분해(MatrixDecomposition)를 통한 로우 랭크 근사법(Low Rank Approximation)을 적용하여 상기 어느 하나의 정방 행렬에대한 근사된 제1 및 제2 행렬을 획득하는 단계; 상기 어느 하나의 정방 행렬에 대한 근사된 제1 행렬에 기초하여 상기 복수의 정방 행렬 중 나머지 정방 행렬에대한 근사된 제2 행렬을 획득하는 단계; 및 상기 어느 하나의 정방 행렬에 대한 근사된 제1 행렬 및 상기 복수의 정방 행렬에 대한 근사된 제2 행렬을 저장하는 단계;를 포함하는 제어 방법."}
{"patent_id": "10-2019-0057261", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제 11 항에 있어서, 상기 근사된 제1 및 제2 행렬을 획득하는 단계는, 상기 어느 하나의 정방 행렬에 대해 특이값 분해(Singular Value Decomposition, SVD)를 통한 로우 랭크 근사법을 적용하여 상기 어느 하나의 정방 행렬에 대한 근사된 제1 및 제 2 행렬을 획득하는, 제어 방법."}
{"patent_id": "10-2019-0057261", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제 12 항에 있어서, 상기 근사된 제1 및 제2 행렬을 획득하는 단계는, 상기 어느 하나의 정방 행렬에 상기 특이값 분해를 적용하여 제1 및 제2 행렬을 획득하고, 상기 제1 및 제2 행렬에 상기 로우 랭크 근사법을 적용하여 상기 어느 하나의 정방 행렬에 대한 근사된 제1 및 제2 행렬을 획득하는 단계를 포함하는, 제어 방법."}
{"patent_id": "10-2019-0057261", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제 13 항에 있어서, 상기 근사된 제1 행렬은, 상기 어느 하나의 정방 행렬에 대한 근사된 오른쪽 특이값 벡터 행렬이고, 상기 복수의 정방 행렬 각각에 대한 근사된 제2 행렬은, 상기 복수의 정방 행렬 각각에 대한 근사된 왼쪽 특이값 벡터 행렬인, 제어 방법."}
{"patent_id": "10-2019-0057261", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제 13 항에 있어서, 상기 나머지 정방 행렬에 대한 근사된 제2 행렬을 획득하는 단계는, 상기 나머지 정방 행렬 각각에, 전치된 상기 제1 행렬의 역행렬을 곱하여 상기 나머지 정방 행렬 각각의 상기근사된 제2 행렬을 획득하는, 제어 방법."}
{"patent_id": "10-2019-0057261", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제 11 항에 있어서, 상기 나머지 정방 행렬에 대한 근사된 제2 행렬을 획득하는 단계는, 제2 정방 행렬과, 상기 제2 정방 행렬의 근사된 제2 행렬 및 상기 제1 정방 행렬의 근사된 제1 행렬의 곱의 차이를 최소화하는 연산(algorithm)을 통해 상기 제2 정방 행렬의 근사된 제2 행렬을 획득하는 단계;를 포함하고, 상기 제1 정방 행렬은, 상기 어느 하나의 정방 행렬이고, 상기 제2 정방 행렬은, 상기 나머지 정방 행렬 중 어느 하나의 정방 행렬인, 제어 방법."}
{"patent_id": "10-2019-0057261", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "전자 장치의 제어 방법에 있어서,공개특허 10-2020-0132178-4-메모리에 저장된 압축된 딥러닝 모델을 로딩하는 단계; 및상기 압축된 딥러닝 모델에 기초하여 출력값을 획득하는 단계;를 포함하고, 상기 압축된 딥러닝 모델은, 근사된 제1 행렬 및 복수의 근사된 제2 행렬을 포함하고, 상기 근사된 제1 행렬은, 딥러닝 모델의 파라미터 값들에 기초한 복수의 정방 행렬 중 어느 하나의 정방 행렬에대해 행렬 분해를 통한 로우 랭크 근사법이 적용되어 획득된 2 개의 행렬 중 어느 하나의 행렬이고, 상기 복수의 근사된 제2 행렬은, 상기 획득된 2 개의 행렬 중 다른 하나의 행렬과, 상기 근사된 제1 행렬 및 상기 복수의 정방 행렬 중 나머지 정방 행렬에 기초하여 획득되는 행렬을 포함하는, 제어 방법."}
{"patent_id": "10-2019-0057261", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제 17 항에 있어서, 상기 근사된 제1 행렬은, 상기 어느 하나의 정방 행렬에 대해 특이값 분해를 통한 로우 랭크 근사법을 적용하여획득된 오른쪽 특이값 벡터 행렬이고, 상기 복수의 근사된 제2 행렬은, 상기 복수의 정방 행렬 각각에 대한 근사된 왼쪽 특이값 벡터 행렬인, 제어 방법."}
{"patent_id": "10-2019-0057261", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제 17 항에 있어서,상기 로딩하는 단계는, 상기 메모리에 저장된 상기 근사된 제1 행렬을 1차 캐시 메모리에 로딩하는 단계; 및 상기 메모리에 저장된 복수의 근사된 제2 행렬 중 적어도 하나를 2차 캐시 메모리에 로딩하는 단계;를포함하고, 상기 출력값을 획득하는 단계는, 상기 1차 캐시 메모리 및 상기 2차 캐시 메모리에 로딩된 근사된 행렬에 기초하여 상기 출력 값을 획득하는, 제어 방법."}
{"patent_id": "10-2019-0057261", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제 19 항에 있어서,상기 로딩하는 단계는, 입력 값 및 상기 1차 캐시 메모리에 로딩된 상기 근사된 제1 행렬에 기초하여 제1 연산이 수행되는 동안, 상기복수의 근사된 제2 행렬 중 적어도 하나의 근사된 제2 행렬을 상기 2차 캐시 메모리에 로딩하는 단계;를 포함하고, 상기 출력값을 획득하는 단계는, 상기 제1 연산 결과 및 상기 2차 캐시 메모리에 로딩된 근사된 제2 행렬에 기초하여 제2 연산을 수행하는 단계;를 포함하는, 제어 방법."}
{"patent_id": "10-2019-0057261", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "전자 장치가 개시된다. 본 전자 장치는, 메모리 및 딥러닝 모델의 파라미터값들에 기초한 복수의 정방 행렬 중 어느 하나의 정방 행렬에 대해 행렬 분해를 통한 로우 랭크 근사법을 적용하여 어느 하나의 정방 행렬에 대한 근 사된 제1 및 제2 행렬을 획득하고, 어느 하나의 정방 행렬에 대한 근사된 제1 행렬에 기초하여 복수의 정방 행렬 중 나머지 정방 행렬에 대한 근사된 제2 행렬을 획득하며, 어느 하나의 정방 행렬에 대한 근사된 제1 행렬 및 복 수의 정방 행렬에 대한 근사된 제2 행렬을 메모리에 저장하는 프로세서를 포함한다."}
{"patent_id": "10-2019-0057261", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 전자 장치 및 이의 제어 방법에 관한 것으로, 보다 상세하게는, 딥러닝 모델을 압축하고, 압축된 딥 러닝 모델을 실행하는 전자 장치 및 이의 제어 방법에 관한 것이다."}
{"patent_id": "10-2019-0057261", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "최근 인공지능 분야인 딥러닝 기술에 있어서, 딥러닝 모델을 성능 저하 없이 압축하는 기술이 각광을 받고 있다. 성능 저하 없이 압축이 효율적으로 진행될수록 기기 제작에 필요한 비용이 줄어들게 되는 것은 물론 딥 러닝 수행속도를 향상시킬 수 있어, 모바일 기기와 같이 작은 자원을 갖는 기기에서 딥러닝 모델을 이용할 수 있게 된다. 즉, 딥러닝 모델의 효율적인 압축이 가능해지면 필요한 메모리 사이즈가 줄어들고 응답 시간이 빨라지므로, 종 래에 필요한 메모리 사이즈가 너무 크거나 응답 시간이 너무 느려서 모바일 기기 등과 같이 작은 자원을 갖는 기기에 딥러닝 모델을 이용할 수 없었던 문제를 해결할 수 있다. 이와 관련하여, 종래 딥러닝 모델을 압축하기 위한 기술로, 특이값 분해(Singular Value Decomposition, SVD) 를 활용한 로우 랭크 근사법(Low-Rank Approximation, LRA)이 이용되고 있다. 기존의 특이값 분해를 사용한 압축 방법은 비교적인 연산이 간단하다는 장점이 있지만, 프루닝(pruning)이나 양 자화(quantization) 등의 방법에 비해 압축률이 낮은 문제가 있다. 한편, 특이값 분해는 통상적으로 정방 행렬에 가까울수록 좋은 압축률을 보인다. 따라서, 압축의 대상인 딥러닝 모델이, Fully-connected 레이어(layer)인 경우에는 크게 문제가 없지만, 예를 들어, 커널의 높이, 너비, 입력 채널의 개수 및 출력 채널의 개수로 이루어진 4차원 텐서인 경우라면, 단순히 2차원으로 변환했을 때 한쪽으로 긴 직사각형이 나올 가능성이 높아지므로, 딥러닝 모델의 압축률이나 정확도가 낮아지게 된다."}
{"patent_id": "10-2019-0057261", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 개시는 상술한 문제점에 따른 것으로, 본 개시의 목적은, 행렬 분해(Matrix Decomposition)을 통한 로우 랭 크 근사법을 적용하여 성능 저하 없이 딥러닝 모델의 압축률을 높일 수 있는 전자 장치 및 이의 제어 방법을 제 공함에 있다. 또한, 본 개시의 다른 목적은, 위와 같이 압축된 딥러닝 모델을 효율적으로 이용할 수 있는 전자 장치 및 이의 제어 방법을 제공함에 있다."}
{"patent_id": "10-2019-0057261", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "이상과 같은 목적을 달성하기 위한 본 개시의 일 실시 예에 따른 전자 장치는, 메모리 및 딥러닝 모델의 파라미 터값들에 기초한 복수의 정방 행렬 중 어느 하나의 정방 행렬에 대해 행렬 분해(Matrix Decomposition)를 통한 로우 랭크 근사법(Low Rank Approximation)을 적용하여 상기 어느 하나의 정방 행렬에 대한 근사된 제1 및 제2 행렬을 획득하고, 상기 어느 하나의 정방 행렬에 대한 근사된 제1 행렬에 기초하여 상기 복수의 정방 행렬 중 나머지 정방 행렬에 대한 근사된 제2 행렬을 획득하며, 상기 어느 하나의 정방 행렬에 대한 근사된 제1 행렬 및 상기 복수의 정방 행렬에 대한 근사된 제2 행렬을 상기 메모리에 저장하는 프로세서를 포함한다. 또한, 상기 프로세서는, 상기 어느 하나의 정방 행렬에 대해 특이값 분해(Singular Value Decomposition, SV D)를 통한 로우 랭크 근사법을 적용하여 상기 어느 하나의 정방 행렬에 대한 근사된 제1 및 제 2 행렬을 획득할 수 있다. 또한, 상기 프로세서는,상기 어느 하나의 정방 행렬에 상기 특이값 분해를 적용하여 제1 및 제2 행렬을 획득하 고, 상기 제1 및 제2 행렬에 상기 로우 랭크 근사법을 적용하여 상기 어느 하나의 정방 행렬에 대한 근사된 제1 및 제2 행렬을 획득할 수 있다. 또한, 상기 어느 하나의 정방 행렬에 대한 상기 근사된 제1 행렬은, 상기 어느 하나의 정방 행렬에 대한 근사된 오른쪽 특이값 벡터 행렬이고, 상기 복수의 정방 행렬 각각에 대한 근사된 제2 행렬은, 상기 복수의 정방 행렬 각각에 대한 근사된 왼쪽 특이값 벡터 행렬일 수 있다. 또한, 상기 프로세서는, 상기 나머지 정방 행렬 각각에, 전치된 상기 제1 행렬의 역행렬을 곱하여 상기 나머지 정방 행렬 각각의 상기 근사된 제2 행렬을 획득할 수 있다. 또한, 상기 프로세서는, 제2 정방 행렬과, 상기 제2 정방 행렬의 근사된 제2 행렬 및 상기 제1 정방 행렬의 근 사된 제1 행렬의 곱의 차이를 최소화하는 연산(algorithm)을 통해 상기 제2 정방 행렬의 근사된 제2 행렬을 획 득하며, 상기 제1 정방 행렬은, 상기 어느 하나의 정방 행렬이고, 상기 제2 정방 행렬은, 상기 나머지 정방 행렬 중 어느 하나의 정방 행렬일 수 있다. 한편, 본 개시의 다른 일 실시 예에 따른 전자 장치는, 압축된 딥러닝 모델을 구성하는, 근사된 제1 행렬 및 복 수의 근사된 제2 행렬이 저장된 메모리 및 상기 메모리에 저장된 상기 압축된 딥러닝 모델을 로딩하고, 상기 압 축된 딥러닝 모델에 기초하여 출력값을 획득하는 프로세서를 포함하고, 상기 근사된 제1 행렬은, 딥러닝 모델의 파라미터 값들에 기초한 복수의 정방 행렬 중 어느 하나의 정방 행렬에 대해 행렬 분해를 통한 로우 랭크 근사 법이 적용되어 획득된 2 개의 행렬 중 어느 하나의 행렬이고, 상기 복수의 근사된 제2 행렬은, 상기 획득된 2 개의 행렬 중 다른 하나의 행렬과, 상기 근사된 제1 행렬 및 상기 복수의 정방 행렬 중 나머지 정방 행렬에 기 초하여 획득되는 행렬을 포함할 수 있다. 또한, 상기 근사된 제1 행렬은, 상기 어느 하나의 정방 행렬에 대해 특이값 분해를 통한 로우 랭크 근사법을 적 용하여 획득된 오른쪽 특이값 벡터 행렬이고, 상기 복수의 근사된 제2 행렬은, 상기 복수의 정방 행렬 각각에 대한 근사된 왼쪽 특이값 벡터 행렬일 수 있다. 또한, 상기 프로세서는, 연산부, 1차 캐시 메모리 및 2차 캐시 메모리를 더 포함하고, 상기 연산부는, 상기 메 모리에 저장된 상기 근사된 제1 행렬을 상기 1차 캐시 메모리에 로딩하고, 상기 메모리에 저장된 상기 복수의 근사된 제2 행렬 중 적어도 하나를 상기 2차 캐시 메모리에 로딩하고, 상기 1차 캐시 메모리 및 상기 2차 캐시 메모리에 로딩된 근사된 행렬에 기초하여 상기 출력 값을 획득할 수 있다. 또한, 상기 연산부는, 입력 값 및 상기 1차 캐시 메모리에 로딩된 상기 근사된 제1 행렬에 기초하여 제1 연산을 수행하는 동안, 상기 복수의 근사된 제2 행렬 중 적어도 하나의 근사된 제2 행렬을 상기 2차 캐시 메모리에 로 딩하고, 상기 제1 연산 결과 및 상기 2차 캐시 메모리에 로딩된 근사된 제2 행렬에 기초하여 제2 연산을 수행할 수 있다. 한편, 본 개시의 일 실시 예에 따른 전자 장치의 제어 방법은, 딥러닝 모델의 파라미터값들에 기초한 복수의 정 방 행렬 중 어느 하나의 정방 행렬에 대해 행렬 분해(Matrix Decomposition)를 통한 로우 랭크 근사법(Low Rank Approximation)을 적용하여 상기 어느 하나의 정방 행렬에 대한 근사된 제1 및 제2 행렬을 획득하는 단계, 상기 어느 하나의 정방 행렬에 대한 근사된 제1 행렬에 기초하여 상기 복수의 정방 행렬 중 나머지 정방 행렬에 대한 근사된 제2 행렬을 획득하는 단계 및 상기 어느 하나의 정방 행렬에 대한 근사된 제1 행렬 및 상기 복수의 정방 행렬에 대한 근사된 제2 행렬을 저장하는 단계를 포함한다. 또한, 상기 근사된 제1 및 제2 행렬을 획득하는 단계는, 상기 어느 하나의 정방 행렬에 대해 특이값 분해 (Singular Value Decomposition, SVD)를 통한 로우 랭크 근사법을 적용하여 상기 어느 하나의 정방 행렬에 대 한 근사된 제1 및 제 2 행렬을 획득할 수 있다. 또한, 상기 근사된 제1 및 제2 행렬을 획득하는 단계는, 상기 어느 하나의 정방 행렬에 상기 특이값 분해를 적 용하여 제1 및 제2 행렬을 획득하고, 상기 제1 및 제2 행렬에 상기 로우 랭크 근사법을 적용하여 상기 어느 하 나의 정방 행렬에 대한 근사된 제1 및 제2 행렬을 획득하는 단계를 포함할 수 있다. 또한, 상기 근사된 제1 행렬은, 상기 어느 하나의 정방 행렬에 대한 근사된 오른쪽 특이값 벡터 행렬이고, 상기 복수의 정방 행렬 각각에 대한 근사된 제2 행렬은, 상기 복수의 정방 행렬 각각에 대한 근사된 왼쪽 특이값 벡 터 행렬일 수 있다. 또한, 상기 나머지 정방 행렬에 대한 근사된 제2 행렬을 획득하는 단계는, 상기 나머지 정방 행렬 각각에, 전치 된 상기 제1 행렬의 역행렬을 곱하여 상기 나머지 정방 행렬 각각의 상기 근사된 제2 행렬을 획득할 수 있다. 또한, 상기 나머지 정방 행렬에 대한 근사된 제2 행렬을 획득하는 단계는, 제2 정방 행렬과, 상기 제2 정방 행 렬의 근사된 제2 행렬 및 상기 제1 정방 행렬의 근사된 제1 행렬의 곱의 차이를 최소화하는 연산(algorithm)을 통해 상기 제2 정방 행렬의 근사된 제2 행렬을 획득하는 단계를 포함하고, 상기 제1 정방 행렬은, 상기 어느 하 나의 정방 행렬이고, 상기 제2 정방 행렬은, 상기 나머지 정방 행렬 중 어느 하나의 정방 행렬일 수 있다. 한편, 본 개시의 다른 일 실시 예에 따른 전자 장치의 제어 방법은, 메모리에 저장된 압축된 딥러닝 모델을 로 딩하는 단계 및 상기 압축된 딥러닝 모델에 기초하여 출력값을 획득하는 단계를 포함하고, 상기 압축된 딥러닝 모델은, 근사된 제1 행렬 및 복수의 근사된 제2 행렬을 포함하고, 상기 근사된 제1 행렬은, 딥러닝 모델의 파라 미터 값들에 기초한 복수의 정방 행렬 중 어느 하나의 정방 행렬에 대해 행렬 분해를 통한 로우 랭크 근사법이 적용되어 획득된 2 개의 행렬 중 어느 하나의 행렬이고, 상기 복수의 근사된 제2 행렬은, 상기 획득된 2 개의 행렬 중 다른 하나의 행렬과, 상기 근사된 제1 행렬 및 상기 복수의 정방 행렬 중 나머지 정방 행렬에 기초하여획득되는 행렬을 포함할 수 있다. 또한, 상기 근사된 제1 행렬은, 상기 어느 하나의 정방 행렬에 대해 특이값 분해를 통한 로우 랭크 근사법을 적 용하여 획득된 오른쪽 특이값 벡터 행렬이고, 상기 복수의 근사된 제2 행렬은, 상기 복수의 정방 행렬 각각에 대한 근사된 왼쪽 특이값 벡터 행렬일 수 있다. 또한, 상기 로딩하는 단계는, 상기 메모리에 저장된 상기 근사된 제1 행렬을 1차 캐시 메모리에 로딩하는 단계 및 상기 메모리에 저장된 복수의 근사된 제2 행렬 중 적어도 하나를 상기 2차 캐시 메모리에 로딩하는 단계를 포함하고, 상기 출력값을 획득하는 단계는, 상기 1차 캐시 메모리 및 상기 2차 캐시 메모리에 로딩된 근사된 행 렬에 기초하여 상기 출력 값을 획득할 수 있다. 또한, 상기 로딩하는 단계는, 입력 값 및 상기 1차 캐시 메모리에 로딩된 상기 근사된 제1 행렬에 기초하여 제1 연산이 수행되는 동안, 상기 복수의 근사된 제2 행렬 중 적어도 하나의 근사된 제2 행렬을 상기 2차 캐시 메모 리에 로딩하는 단계를 포함하고, 상기 출력값을 획득하는 단계는, 상기 제1 연산 결과 및 상기 2차 캐시 메모리 에 로딩된 근사된 제2 행렬에 기초하여 제2 연산을 수행하는 단계를 포함할 수 있다."}
{"patent_id": "10-2019-0057261", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "이상 설명한 바와 같이 본 개시의 다양한 실시 예에 따르면, 성능 저하 없이 딥러닝 모델의 압축률을 높일 수 있다. 또한, 압축된 딥러닝 모델을 활용하여 딥러닝 모델 실행 시 전력 소모를 줄이고, 응답 시간의 지연을 줄 일 수 있다."}
{"patent_id": "10-2019-0057261", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 본 개시의 다양한 실시 예가 첨부된 도면을 참조하여 기재된다. 그러나, 이는 본 개시에 기재된 기술을 특정한 실시 형태에 대해 한정하려는 것이 아니며, 본 개시의 실시 예의 다양한 변경(modifications), 균등물 (equivalents), 및/또는 대체물(alternatives)을 포함하는 것으로 이해되어야 한다. 도면의 설명과 관련하여, 유사한 구성요소에 대해서는 유사한 참조 부호가 사용될 수 있다. 본 개시에서, \"가진다,\" \"가질 수 있다,\" \"포함한다,\" 또는 \"포함할 수 있다\" 등의 표현은 해당 특징(예: 수치, 기능, 동작, 또는 부품 등의 구성요소)의 존재를 가리키며, 추가적인 특징의 존재를 배제하지 않는다. 본 개시에서, \"A 또는 B,\" \"A 또는/및 B 중 적어도 하나,\" 또는 \"A 또는/및 B 중 하나 또는 그 이상\"등의 표현 은 함께 나열된 항목들의 모든 가능한 조합을 포함할 수 있다. 예를 들면, \"A 또는 B,\" \"A 및 B 중 적어도 하나,\" 또는 \"A 또는 B 중 적어도 하나\"는, 적어도 하나의 A를 포함, 적어도 하나의 B를 포함, 또는 적어도 하나의 A 및 적어도 하나의 B 모두를 포함하는 경우를 모두 지칭할 수 있다. 본 개시에서 사용된 \"제1,\" \"제2,\" \"첫째,\" 또는 \"둘째,\"등의 표현들은 다양한 구성요소들을, 순서 및/또는 중 요도에 상관없이 수식할 수 있고, 한 구성요소를 다른 구성요소와 구분하기 위해 사용될 뿐 해당 구성요소들을 한정하지 않는다. 어떤 구성요소(예: 제1 구성요소)가 다른 구성요소(예: 제2 구성요소)에 \"(기능적으로 또는 통신적으로) 연결되 어((operatively or communicatively) coupled with/to)\" 있다거나 \"접속되어(connected to)\" 있다고 언급된 때에는, 상기 어떤 구성요소가 상기 다른 구성요소에 직접적으로 연결되거나, 다른 구성요소(예: 제3 구성요 소)를 통하여 연결될 수 있다고 이해되어야 할 것이다. 반면에, 어떤 구성요소(예: 제1 구성요소)가 다른 구성 요소(예: 제2 구성요소)에 \"직접 연결되어\" 있다거나 \"직접 접속되어\" 있다고 언급된 때에는, 상기 어떤 구성요 소와 상기 다른 구성요소 사이에 다른 구성요소(예: 제 3 구성요소)가 존재하지 않는 것으로 이해될 수 있다. 본 개시에서 사용된 표현 \"~하도록 구성된(또는 설정된)(configured to)\"은 상황에 따라, 예를 들면, \"~에 적합 한(suitable for),\" \"~하는 능력을 가지는(having the capacity to),\" \"~하도록 설계된(designed to),\" \"~하도 록 변경된(adapted to),\" \"~하도록 만들어진(made to),\" 또는 \"~를 할 수 있는(capable of)\"과 바꾸어 사용될 수 있다. 용어 \"~하도록 구성된(또는 설정된)\"은 하드웨어적으로 \"특별히 설계된(specifically designed to)\" 것만을 반드시 의미하지 않을 수 있다. 대신, 어떤 상황에서는, \"~하도록 구성된 장치\"라는 표현은, 그 장치가 다른 장치 또는 부품들과 함께 \"~할 수 있는\" 것을 의미할 수 있다. 예를 들면, 문구 \"A, B, 및 C를 수행하도록 구성된(또는 설정된) 프로세서\"는 해당 동작을 수행하기 위한 전용 프로세서(예: 임베디드 프로세서), 또는 메 모리 장치에 저장된 하나 이상의 소프트웨어 프로그램들을 실행함으로써, 해당 동작들을 수행할 수 있는 범용 프로세서(generic-purpose processor)(예: CPU 또는 application processor)를 의미할 수 있다. 도 1은 본 개시의 일 실시 예에 따른 딥 러닝 모델 시스템을 도시하고 있다. 도 1에 따르면, 딥러닝 모델 시스템은 네트워크를 통해 연결된 전자 장치 및 전자 장치를 포함할 수 있다. 이때, 네트워크는 WAN(Wide Area Network), MAN(Metropolitan Area Network), VAN(Value Area Network), ISDN(Integrated Services Digital Network), LAN(Local Area Network), ADSL(Asymmetric Digital Subscriber Line), 케이블 TV망, PAN(Personal Area Network)등을 포함할 수 있으며, 전자 장치와 전자 장치는 IEEE, 3G(3rd Generation), 3GPP(3rd Generation Partnership Project), LTE(Long Term Evolution), 5G(5th Generation Mobile Communication), Wi-Fi, Bluetooth, NFC, Zigbee 등과 같은 각종 통신 방식에 따라 네트워 크를 통해 서로 통신할 수 있으나, 이에 한정되는 것은 아니다. 한편, 도면에는 네트워크를 도시하였으나, 전자 장치과 전자 장치는 D2D(Device to Device) 통신 을 통해 직접 연결될 수도 있다. 본 개시의 일 실시 예에 따르면, 전자 장치는 딥러닝 모델을 압축하여 저장할 수 있다. 또한, 전자 장치 는 전자 장치에 의해 압축된 딥러닝 모델을 획득하여 실행할 수 있다. 이때, 딥러닝 모델의 종류에는 제한이 없다. 이 경우, 전자 장치는 압축된 딥러닝 모델을 생성하는 서버이고, 전자 장치는 압축된 딥러닝 모델을 실행하는 PC(Personal Computer), 휴대폰, 태블릿, 스마트 TV 등 과 같은 각종 단말 장치일 수 있으나, 실시 예 가 이에 한정되는 것은 아니다. 예를 들어, 전자 장치가 딥러닝 모델을 압축하여 저장할 수도 있고, 전자 장치가 압축된 딥러닝 모델을 실행할 수도 있다. 이하에서는, 설명의 편의를 위해, 전자 장치가 딥러닝 모델을 압축하는 서버이고, 전자 장치가 압축 된 딥러닝 모델을 활용하는 각종 단말 장치인 것을 예로 들어 설명한다. 도 2는 본 개시의 일 실시 예에 따른 전자 장치의 블럭도이다. 도 2에 도시된 바와 같이, 전자 장치 는 메모리 및 프로세서를 포함한다. 메모리는 각종 및 데이터를 저장할 수 있다. 특히, 메모리는 딥러닝 모델을 저장할 수 있다. 또한, 프로세서에 의해 압축된 딥러닝 모델을 저장할 수 있다. 이를 위해, 메모리는 휘발성 메모리(volatile memory) 또는 비휘발성(non-volatile memory) 중 하나 또는 그 이상을 포함할 수 있다. 여기서, 휘발성 메모리는 DRAM(dynamic random access memory), SRAM(static RAM), SDRAM(synchronous DRAM), PRAM(phase-change RAM), MRAM(magnetic RAM), RRAM(resistive RAM), FeRAM(ferroelectric RAM) 등을 포함할 수 있다. 비휘발성 메모리는 ROM(read only memory), PROM(programmable ROM), EPROM(electrically programmable ROM), EEPROM(electrically erasable programmable ROM), 플레시 메모리(flash memory) 등을 포함할 수 있다. 또한, 메모리는 하드 디스크 드 라이브(HDD, hard disk drive), 솔리드 스테이트 디스크(SSD, solid state disk), eMMC(embedded multi media card), UFS(universal flash storage)와 같은 비휘발성 매체(medium)를 포함할 수도 있다. 프로세서는 전자 장치의 전반적인 동작을 제어한다. 특히, 프로세서는 딥러닝 모델을 압축하고, 압축된 딥러닝 모델을 메모리에 저장할 수 있다. 딥러닝 모델은 복수의 레이어를 포함하며, 각 레이어는 복수의 파라미터 값 또는 가중치 값을 갖는다. 이때, 복 수의 파라미터 값 또는 가중치 값은 행렬로 표현될 수 있다. 프로세서는 딥러닝 모델의 파라미터 값들에 기초한 행렬을 조작하여 딥러닝 모델을 압축할 수 있다. 이하에서, 도 3 내지 도 5를 참조하여 프로세서가 딥러닝 모델을 압축하는 다양한 실시 예들을 구체적으로 설명한다. 도 3은 종래의 특이값 분해를 통한 딥러닝 모델의 압축 개념을 설명하기 위한 도면이다. 특이값 분해(Signular Value Decomposition, SVD)는 실수의 행렬로부터 고유값(eigenvalue)을 추출하여 왼쪽 특이값 벡터 행렬(left-singular vectors, U), 고유값 행렬(∑), 오른쪽 특이값 벡터 행렬(right-singular vectors, V)로 행렬을 분해하는 방법이다. 도 3의 위 도면을 참조하면, m×n의 크기를 같는 행렬(M)은, 특이값 분해를 통해 m×m 크기의 왼쪽 특이값 벡터 행렬(U), m×n 크기의 고유값 행렬(∑) 및 n×n 크기의 오른쪽 특이값 벡터 행렬(V)로 분해될 수 있다. 한편, 특이값 분해를 통한 로우 랭크 근사법(Low Rank Approximation, LRA)은, 고유값 행렬(∑)이 중요도에 따 라 정렬되어 있다는 특징을 이용한 근사 방법이다. 도 3의 아래 도면을 참조하면, 로우 랭크 근사법은, 랭크가 k인 경우(이때, k는 m이나 n보다 작다.), m×m 크기 의 왼쪽 특이값 벡터 행렬 U를 m×k로 자르고, m×n 크기의 고유값 행렬 ∑를 k×k로 자르며, n×n 크기의 오른 쪽 특이값 벡터 행렬 V를 k×n으로 자른다. 이 결과, m×n 크기의 행렬 M은 M'로 근사되어 더 작은 행렬의 곱(U'*∑'*V', 이하에서는, U'*∑'를 하나의 행 렬로 보고 U'로 표현함.)으로 표현될 수 있다. 즉, 행렬 M은 U'*V'로 근사될 수 있다. 이를 통해, 메모리에 저 장되는 딥러닝 모델의 데이터 양을 수학적으로 크게 줄일 수 있다. 따라서, 종래 특이값 분해를 통한 로우 랭크 근사법은, 온 디바이스 AI(Aritificial Intelligence)뿐만 아니라 대형 서버들을 사용하는 딥러닝에서도 폭넓게 사용된다. 또한, 이 방법에 따르면 하나의 행렬(M')이 더 작은 행렬 곱(U'*V')으로 표현되므로, y(출력) = M'*x(입력)의 형태로 이뤄지는 딥러닝 연산이 y=U'*V'*x의 형태로 분해된다. 이 경우, V'*x 연산 후 U를 곱하면 M'에 직접 x 를 곱하는 것보다 연산량이 줄어들고 성능이 향상되는 효과를 얻을 수 있다. 그러나, 전술한 바와 같이, 종래의 특이값 분해는 프루닝(pruning)이나 양자화(quantization) 등의 방법에 비해 압축률이 낮으며, 행렬이 정방 행렬이 아닌 경우 딥러닝 모델의 압축률이나 정확도가 낮아지는 문제점이 있다. 도 4는 본 개시의 일 실시 예에 따라 전자 장치가 압축된 딥러닝 모델을 생성하는 방법을 도시한 흐름도이 다. 도 4에 따르면, 프로세서는 먼저, 압축의 대상이 되는 적어도 하나의 텐서(tensor) 또는 행렬을 i개의 작 은 m×m 정방 행렬 M1...i로 리쉐이핑(또는 타일링)할 수 있다(S410). 도 5의 M1 내지 Mi는 이와 같이 리쉐이핑된 i개의 정방 행렬을 도시하고 있다. 전술한 바와 같이, 딥러닝 모델은 복수의 레이어를 포함하며, 각 레이어의 파라미터 값(또는 가중치 값)들은 텐 서 내지 행렬로 표현될 수 있다. 따라서, 딥러닝 모델의 파라미터값들로 구성된 텐서 내지 행렬이 위 압축의 대 상이 될 수 있다. 본 개시의 다양한 실시 예들에서, 텐서 또는 행렬이 정방 행렬로 분할되는 방법에는 아무런 제약이 없다. 즉, 예를 들어, 딥러닝 모델이 L개의 레이어로 구성된 경우, 각 레이어를 구성하는 파라미터 값들이 L개의 행렬로 표현될 수 있는데, 이와 같은 L개의 행렬이 다양한 방식으로 리쉐이핑되어 M1 내지 Mi와 같은 i개의 정방 행렬로 획득될 수 있다. 이때, L 과 i는 같은 숫자일 수도 있고 아닐 수도 있음은 물론이다. . 특히, 2차원 행렬로 텐서를 변환하는 방법에도 제약이 없다. 본 개시의 실시 예들에 따르면, 다양한 차원과 크 기의 텐서 또는 행렬들을 행렬 분해(Matrix Decomposition 또는 Matrix factorization)(특히, 특이값 분해)가 가능한 형태로 분할 내지 변환하기 때문에 더 높은 랭크로 로우 랭크 근사를 진행할 수 있어 더 효율적인 압축 이 가능하다. 한편, 프로세서는 리쉐이핑된 복수의 정방 행렬 중 어느 하나의 정방 행렬에 대해 행렬 분해를 통한 로우 랭크 근사법을 적용하여 상기 어느 하나의 정방 행렬에 대한 근사된 제1 및 제2 행렬을 획득할 수 있다(S420). 행렬 분해(또는 행렬 인수분해)는 어떤 행렬을 특정 구조를 갖는 2 이상의 다른 행렬들의 곱으로 나타내는 것이다. 특히, 본 개시의 일 실시 예에 따르면, 프로세서는 하나의 정방 행렬(예를 들어, Mj)을 행렬 분해를 통해 두 행렬의 곱(예를 들어, Uj * Vj)으로 나타낼 수 있다. 이때, 두 행렬(예를 들어, Uj 및 Vj)이 제1 및 제2 행렬이 된다(후술할 바와 같이, Uj가 제1 행렬인 경우에는 Vj가 제2 행렬이 되고, Vj가 제1 행렬인 경우에는 Uj 가 제2 행렬이 될 수 있다.). 또한, 프로세서는 정방 행렬(Mj)을 단순히 행렬 분해하는 것이 아니라 로우 랭크 근사법을 적용하므로, 근사된 제1 및 제2 행렬(예를 들어, Uj' 및 Vj')이 획득되게 된다. 이때, Uj'와 Vj'의 곱의 결과는 원본 행렬 Mj와 차이가 있다. 이는, 원본 행렬 Mj에 대해 행렬 분해를 통한 로우 랭크 근사법을 적용하는 과정에서 데이터의 근사가 발생하기 때문이며, 이 과정에서 데이터의 압축이 일어날 수 있다. 본 명세서에서 \"근사된\"이라는 표현은 이를 의미한다. 구체적으로, 근사된 제1 및 제2 행렬이 획득된다는 것은, 곱의 결과가 원본 정방 행렬과 정확히 일치하지는 않는, 제1 및 제2 행렬이 획득된다는 것을 의미한다. 예를 들어, m×m 크기의 정방 행렬(Mj)이 랭크(또는 계수) k(이때, k는 m보다 작다.)로 행렬 분해되면, m×k 크 기의 한 행렬(Uj')과 k×m 크기의 다른 행렬(Vj')이 획득될 수 있는데, 이때, 행렬 Uj' 및 Vj'가 획득되는 과정 에서 데이터 근사(또는 압축)이 발생하며, 그 결과 Uj' * Vj'와 Mj는 달라지게 된다. 한편, 이상에서 행렬 분해와 로우 랭크 근사는 동시에 수행될 수 있다. 즉, 위 설명은 행렬 분해와 로우 랭크 근사의 개념을 나누어 설명한 것일 뿐, 프로세서의 동작 순서를 한정하는 의미는 아니다. 프로세서는 복수의 정방 행렬 중 어느 하나의 정방 행렬을 기설정된 기준에 의해 선택하고, 선택된 어느 하나의 정방 행렬에 대해 행렬 분해를 통한 로우 랭크 근사법을 적용할 수 있다. 이때, 기설정된 기준은 실험적 인 방법을 통해 정해질 수 있다. 예를 들어, 선택된 어느 하나의 정방 행렬이 Mj(1＜＝j＜＝i)인 경우, 프로세서는 Mj에 대해 행렬 분해를 통한 로우 랭크 근사법(랭크=k, k＜m)을 적용하여 Mj에 대한 Uj' 및 Vj'을 산출할 수 있다. 행렬 분해의 방법으로 특이값 분해가 이용되는 경우, 프로세서는 Mj에 대해 특이값 분해를 적용하여 Uj 및 Vj를 획득하고, Uj 및 Vj에 로우 랭크 근사법을 적용하여 Mj에 대한 Uj' 및 Vj'를 획득할 수 있다. 이 경우, Uj' 및 Vj'는 각각 Mj에 대한 근사된 왼쪽 특이값 벡터 행렬 및 근사된 오른쪽 특이값 벡터 행렬이 된다. 실제 연산 시 특이값 분해와 로우 랭크 근사가 동시에 수행될 수 있음은 물론이다. 이상에서, Uj' 및 Vj' 중 어느 하나가 Mj에 대한 근사된 제1 행렬이 될 수 있다. 이에 따라, Uj' 및 Vj' 중 나머 지 하나가 Mj에 대한 근사된 제2 행렬이 될 수 있다. 한편, Uj'은 m×k의 크기를 갖고, Vj'는 k×m의 크기를 갖 는다. 이에 따라, 프로세서는 상기 어느 하나의 정방 행렬에 대한 근사된 제1 행렬에 기초하여, 복수의 정방 행 렬 중 나머지 정방 행렬에 대한 근사된 제2 행렬을 획득할 수 있다(S430). 예를 들어, 상기 어느 하나의 정방 행렬(Mj)에 대한 근사된 제1 행렬이 Vj'인 경우, 프로세서는 Vj'에 기초 하여 나머지 정방 행렬 M1...i 각각에 대한 Ux'(즉, U1' 내지 Ui')을 산출할 수 있다. 이때, M1...i 각각의 U'은 m× k의 크기를 갖게 될 것이다. 한편, 행렬 분해의 방법으로 특이값 분해가 이용된 경우 전술한 바와 같이 U'은 ∑'을 포함할 수 있다. 구체적으로, 프로세서는 Mx와 (Ux'*Vj')의 차이를 최소화하는 연산(algorithm)을 통해 Ux'를 산출할 수 있 다. 특히, 행렬 분해의 방법으로 특이값 분해가 이용된 경우, 프로세서는 아래의 수학식 1과 같은 연산을 통해 Ux'를 산출할 수 있다. 수학식 1"}
{"patent_id": "10-2019-0057261", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "이때, Mx*(Vj')-1=Ux'와 같은 간단한 식을 통해 Ux'을 구하지 않는 이유는, Vj'이 정방 행렬이 아니어서 역행렬을 정확히 구할 수 없기 때문이다. 따라서, 본 개시의 일 실시 예에 따르면, Vj가 유니터리 행렬(Unitary matrix) 이라는 특성을 이용하여 수학식 1과 같이, 전치(Transpose)된 행렬 (Vj)T의 역행렬을 구한 뒤에 이를 Low- ranked하여 사용한다. 이와 같이, 본 개시의 일 실시 예에 따르면, 복수의 정방 행렬 중 선택된 어느 하나의 정방 행렬 Mj에 대한 Vj' 를 통해, 나머지 정방 행렬들의 Ux'가 획득될 수 있다. 따라서, Vj'는 경우에 따라 공통 행렬로 불리울 수 있 다.(특히, 특이값 분해가 이용된 경우라면, Vj'는 공통 특이값 벡터 행렬이라 불리울 수 있다.) 한편, 이상에서는, Vj'가 어느 하나의 정방 행렬 Mj에 대한 근사된 제1 행렬 즉, 공통 행렬(또는 공통 특이값 벡 터 행렬)이고, 이에 기초하여 나머지 정방 행렬들의 근사된 제2 행렬 Ux'가 획득되는 경우를 예로 들어 설명하였 으나, 실시 예가 이에 한정되는 것은 아니다. 즉, 실시 예에 따라, Uj' 가 Mj에 대한 근사된 제1 행렬이 될 수도 있다. 이 경우 프로세서는 Uj' 에 기초 하여 나머지 정방 행렬들의 근사된 제2 행렬 즉, Vx'(V1' 내지 Vi')를 획득할 수 있다. 이에 관한 구체적인 내용 은, 근사된 제1 행렬이 Vj'인 경우에 관한 상술한 설명을 통해 당업자에게 자명하게 이해될 수 있으므로, 보다 자세한 설명은 생략한다. 한편, 프로세서는, 상술한 바와 같이 획득된, 어느 하나의 정방 행렬에 대한 근사된 제1 행렬(Vj') 및 복 수의 정방 행렬에 대한 근사된 제2 행렬(U1' 내지 Ui')을 딥러닝 모델의 압축된 형태로 메모리에 저장할 수 있다. 이하에서는, 도 5를 참조하여 딥러닝 모델의 압축된 형태를 설명한다. 도 5는 복수의 정방 행렬이 랭크 k로 행 렬 분해되어 근사화되는 개념을 도시한 도면이다. 도 5에 도시된 바와 같이, m×m 크기의 정방 행렬 M1 내지 Mi는 랭크 k로 분해되어 U1'*V1' 내지 Ui'*Vi'로 각각 근사화될 수 있다. 이때, M1 내지 Mi는 딥러닝 모델의 파라미터 값들에 기초하여 획득되는 복수의 정방 행렬일 수 있다. M1 내지 Mi에 종래의 특이값 분해를 통한 로우 랭크 근사법을 적용하는 경우, M1 내지 Mi는 U1'*V1' 내지 Ui'*Vi' 로 각각 근사화되며, 이 과정에서 전술한 바와 같이 딥러닝 모델이 압축될 수 있다. 즉, 종래 기술에 따라 딥러 닝 모델이 압축된 결과는 i개의 U'과 i개의 V'이 된다. 한편, 전술한 바와 같이, 본 개시의 다양한 실시 예들에 따르면, 프로세서는 하나의 정방 행렬에 대한 근 사된 제1 행렬을 통해 나머지 정방 행렬들의 근사된 제2 행렬을 획득하므로, 복수의 정방 행렬 M1 내지 Mi에 대 해, U1...i와 단 하나의 Vj'을 획득할 수 있다. 즉, 본 개시의 다양한 예들에 따라 딥러닝 모델이 압축된 결과는 i개의 U'과 1개의 V'이 되며, 이는 본 개시의 다양한 실시 예들이 종래 기술에 비해 약 2배의 압축률 향상 효과 를 가짐을 의미한다. 한편, 프로세서는 상술한 바와 같이 획득된 압축된 딥러닝 모델을 재학습할 수 있다(S440). 딥러닝 모델을 압축하면, 압축 전의 딥러닝 모델보다 정확도가 다소 떨어질 수 있다. 따라서, 압축된 딥러닝 모델을 재학습하 여 떨어진 성능을 올릴 필요가 있다. 이 경우, 예를 들어 DeepTwist 기반의 재학습 방법론이 이용될 수 있다. DeepTwist 기반의 재학습 방법론은 압 축 - 복원 - 재학습을 반복하면서 모델 네트웨크의 파라미터들을 압축이 잘되는 형태로 재학습시켜 나가는 방식이다. 모델의 압축 및 복원은 기존의 파라미터에 일종의 노이즈를 넣는 효과로 나타나는데, 이러한 노이즈에도 불구하 고 타당한 학습결과를 보이도록 유도함으로써 딥러닝 모델이 높은 정확도를 갖도록 유도한다. 예를 들어, 본 개시의 일 실시 예에 따르면, 도 4의 S420 단계에서 근사된 제1 행렬을 획득하기 위한 어느 하나 의 정방 행렬을 선택할 때, 매번 다른 정방 행렬을 선택하여 압축할 수 있다. 즉, 최초 딥러닝 모델의 최초 압축 시 정방 행렬 M1을 선택하여 근사된 제1 행렬 V1'을 획득하고 이에 기초하여 압축을 진행했다면, 이와 같이 압축된 딥러닝 모델을 복원 및 재학습한 후 다시 압축할 때에는 정방 행렬 M2를 선택하여 근사된 제1 행렬 V2'을 획득하고 이에 기초하여 압축을 진행하는 방식으로, 매번 다른 정방 행렬을 선 택하여 딥러닝 모델을 압축할 수 있다. 압축을 했다가 복원하는 것이 일종의 노이즈를 모델 파라미터에 가하는 효과라고 봤을 때 노이즈의 방향을 바꾸 어주는 것이 결국 모델을 더 정규화시키는 효과로 이어지기 때문에 더 나은 정확도를 얻을 수 있다. 이것은 다 시 더 높은 압축률을 시도해볼 수 있다는 장점으로 이어진다. 물론, 최종적으로는 하나의 정방 행렬 Mj를 선택하 여 딥러닝 모델의 압축된 형태를 결정하게 될 것이다. 한편, 본 개시의 다양한 실시 예들에 적용될 수 있는 재학습 방법이 DeepTwist 기반의 재학습 방법에 한정되는 것은 아니며, 얼마든지 다른 재학습 기법이 이용될 수 있다. 한편, 도면에는 도시하지 않았지만, 전자 장치는 외부 네트워크나 다른 전자 장치와 통신을 수행하기 위한 통신부(미도시)를 더 포함할 수 있다. 또한, 실시 예에 따라 전자 장치가 각종 단말 장치로 구현되는 경우, 전자 장치는 해당 단말 장치의 기능을 수행하기 위한 다양한 구성들(예를 들어, 각종 센서, 사용자 명령을 입력받기 위한 다양한 입력 인터페이스, 스피커나 디스플레이와 같은 각종 출력 인터페이스 등)을 더 포 함할 수도 있다. 도 6은 본 개시의 다른 일 실시 예에 따른 전자 장치의 블럭도이다. 도 6에 따르면, 전자 장치는 메모리 및 프로세서를 포함한다. 메모리는 각종 및 데이터를 저장할 수 있다. 특히, 메모리는 압축된 딥러닝 모델을 저장할 수 있다. 여기서, 압축된 딥러닝 모델은 도 2 내지 도 5를 통해 전술한 압축된 딥러닝 모델을 포함한다. 구체적으로, 압 축된 딥러닝 모델은 전술한 바와 같이, 딥러닝 모델의 파라미터값들에 기초한 복수의 정방 행렬 중 어느 하나의 정방 행렬에 대한 근사된 제1 행렬 및 상기 복수의 정방 행렬에 대한 근사된 제2 행렬을 포함할 수 있다. 이를 위해, 메모리는 휘발성 메모리(volatile memory) 또는 비휘발성(non-volatile memory) 중 하나 또는 그 이상을 포함할 수 있다. 여기서, 휘발성 메모리는 DRAM(dynamic random access memory), SRAM(static RAM), SDRAM(synchronous DRAM), PRAM(phase-change RAM), MRAM(magnetic RAM), RRAM(resistive RAM), FeRAM(ferroelectric RAM) 등을 포함할 수 있다. 비휘발성 메모리는 ROM(read only memory), PROM(programmable ROM), EPROM(electrically programmable ROM), EEPROM(electrically erasable programmable ROM), 플레시 메모리(flash memory) 등을 포함할 수 있다. 또한, 메모리는 하드 디스크 드 라이브(HDD, hard disk drive), 솔리드 스테이트 디스크(SSD, solid state disk), eMMC(embedded multi media card), UFS(universal flash storage)와 같은 비휘발성 매체(medium)를 포함할 수도 있다. 프로세서는 전자 장치의 전반적인 동작을 제어한다. 특히, 프로세서는 메모리에 저장된 압 축된 딥러닝 모델을 실행할 수 있다. 구체적으로, 프로세서는 메모리에 저장된 압축된 딥러닝 모델을 로딩하고, 로딩된 압축된 딥러닝 모델에 기초하여 출력값을 획득할 수 있다. 이하에서는, 도 7 및 도 8을 통해 프로세서가 압축된 딥러닝 모델을 실행하는 다양한 실시 예들을 구체적 으로 설명한다. 도 7은 전자 장치가 근사화된 행렬을 이용하여 출력값을 생성하는 개념을 도시한 도면이다. 도 7의 왼쪽 그림에 도시된 바와 같이 딥러닝 모델의 레이어가 구성되고 해당 레이어의 파라미터 행렬 M이 존재한다고 할 때, 행렬 M은 U' 및 V'로 근사화되어 분해될 수 있다. 따라서, 도 7의 오른쪽 그림과 같이 입력 x에 대한 출력값이 계산 될 수 있다는 것이 기존의 특이값 분해를 통한 로우 랭크 근사법의 장점이다. 한편, 전술한 본 개시의 다양한 실시 예들에 따른 딥러닝 모델 압축 방법은, 딥러닝 모델의 파라미터들을 복수 의 정방 행렬로 리쉐이핑한 후 복수의 정방 행렬 각각의 근사된 행렬 U' 및 V'의 곱으로 분해하며, 그 중에 V' 는 동일하다. 따라서, 압축된 딥러닝 모델 실행시, 동일한 행렬 V'는 한번만 읽어 프로세서(22O)의 연산부에 가까이 두고 재 사용하는 것이 효율적이다. 즉, 도 8에 도시된 그림과 같은 연산 구조를 생각해 볼 수 있다. 도 8은 본 개시의 다른 일 실시 예에 따른 전자 장치의 상세 블럭도이다. 도 8에 따르면, 프로세서는 하나 의 칩으로 구현되며, 연산부, 1차 캐시 메모리 및 2차 캐시 메모리을 포함할 수 있다. 연산부는 데이터를 연산하는 구성으로, 중앙 처리 유닛(Central Processing Unit, CPU), 어플리케이션 프 로세서(Application Processor, AP) 또는 그래픽 처리 유닛(Graphic Processing Unit) 중 적어도 하나를 포함 할 수 있으며, 다른 말로, PE(Processing Unit)으로 불리울 수 있다. 1차 및 2차 캐시 메모리(222, 223)는, 프로세서 칩 내부에 존재하는 메모리들로써 \"온 칩 메모리\"라고 불 리울 수도 있다. 1차 및 2차 캐시 메모리(222, 223)는 프로세서 칩 외부에 존재하는 메모리보다 연산 부의 접속 속도는 빠르나 용량은 작은 것이 일반적이다. 1차 및 2차는 캐시 메모리의 레벨을 의미하며, 1 차 캐시 메모리가 2차 캐시 메모리보다 용량은 작으나 연산부의 접근 속도는 가장 빠르다. 예를 들어, 메모리는 DRAM으로, 1차 및 2차 캐시 메모리(222, 223)는 SRAM으로 구현될 수 있으나, 이에 한정되 는 것은 아니다. 도 8은 단순하게 데이터 관점에서, 메모리, 온 칩 메모리(222, 223) 및 연산부로 이루어진 딥러닝 추 론 하드웨어를 나타낸 그림이다. 기본적으로, 딥러닝 모델 파라미터와 입력값이 연산부에서 연산되는 구조 를 나타내고 있으며, 딥러닝 연산에 필요한 데이터 즉, 딥러닝 모델은, 필요한 시점에 메모리에서 온 칩 메모리(222, 223)에 로딩되고, 온 칩 메모리(222, 223)에서 연산부로 공급된다. 잘 알려져 있듯이 프로세서 칩 외부의 메모리에서 칩 내부로 데이터를 옮기는 과정은 큰 전력을 소모 하며 높은 지연 시간을 보이는 병목 구간이다. 이를 줄이는 것이 모델 압축의 장점 중 하나인데, 본 개시의 다 양한 실시 예들은 이러한 관점에서 모델 압축의 효과를 크게 높일 수 있다. 도 8에서 선의 굵기는 데이터의 전송량을 추상적으로 표현한 것인데, 공통되지 않는 행렬(Ux')은 상대적으로 전 송량이 많고 많은 횟수의 전송이 필요한 반면, 공통 행렬(Vj')은 전송량이 적어 적은 횟수의 전송만으로 프로세 서 칩 내부에 로딩될 수 있다. 특히, 본 개시의 일 실시 예에 따른 전자 장치가 종래 기술과 다른 점 중 하나는, 실제 연산이 수행되는 연산부 가까이에 제1 캐시 메모리를 두고, 제1 차 캐시 메모리에 공통 행렬(Vj')을 로딩하여 재 사용한다는 점이다. 연산부는 상대적으로 가까운 위치에서 공통된 행렬(Vj')을 읽어오기 때문에 더 빠르게 적은 비용으로 공통된 행렬(Vj')과 관련된 연산을 수행할 수 있다. 즉, 본 개시의 일 실시 예에 따르면, 연산부는, 메모리에 저 장된 근사된 제1 행렬을 1차 캐시 메모 리에 로딩하고, 메모리에 저장된 상기 복수의 근사된 제2 행렬 중 적어도 하나를 2차 캐시 메모리 에 로딩하고, 1차 캐시 메모리 및 상기 2차 캐시 메모리에 로딩된 근사된 행렬들에 기초하여 출 력 값을 획득할 수 있다. 이에 따라, 전자 장치는 더 적은 전력과 지연 시간으로 메모리에 저장된 데이터를 읽어 올 수 있기 때문에 빠른 연산이 가능해 진다. 즉, 이미 가까이에 공통 행렬(Vj')이 로딩되어 있기 때문에 로딩하는 시간을 절약 할 수 있다. 한편, 본 개시의 다른 일 실시 예에 따르면, 연산부는 공통 행렬(Vj')과 관련된 연산을 수행하는 동안 메 모리로부터 Ux'를 로딩할 수 있다. 즉, 본 개시의 일 실시 예에 따르면, 연산부는, 입력값(Input, x) 및 1차 캐시 메모리에 로딩된 근사 된 제1 행렬에 기초하여 제1 연산을 수행하는 동안, 복수의 근사된 제2 행렬 중 적어도 하나의 근사된 제2 행렬 을 2차 캐시 메모리에 로딩하고, 제1 연산 결과 및 2차 캐시 메모리에 로딩된 근사된 제2 행렬에 기 초하여 제2 연산을 수행할 수 있다. 예를 들어, 입력값이 x인 경우, 연산부는, 1차 캐시 메모리에 로딩된 Vj'에 기초하여 Vj'*x 연산을 수행하는 동안 Ux'를 메모리로부터 2차 캐시 메모리에 로딩할 수 있다. 이에 따라, Vj'*x 연산 결과 (예를 들어, x')와 2차 캐시 메모리에 로딩된 Ux'에 기초하여 Ux'*x'연산을 수행함으로써 입력값 x에 관한 출력값 y를 획득할 수 있다. 이 경우, 연산 시간과 메모리로부터 로딩하는 시간을 중첩시킬 수 있으므로, 연산 속도를 더욱 향상시킬 수 있다. 이상에서는, 압축된 딥러닝 모델의 공통 행렬이 Vj'인 경우를 설명하였으나, 전술한 바와 같이, 실시 예에 따라 Uj'가 공통 행렬이 될 수도 있음은 물론이다. 이 경우에는 Uj'가 1차 캐시 메모리에 로딩되게 될 것이다. 한편, 딥러닝 하드웨어 관점에서는, 행렬이 너무 많은 조각으로 나누어져 있으면 추가적인 모델 병합 오버헤드 가 발생할 수 있다. 즉, 연산 방식에 맞게 데이터가 준비되어 있을 필요가 있는데, 전술한 본 개시의 다양한 실 시 예들은 데이터 형식에 따른 제약을 받지 않는다. 따라서, 전술한 본 개시의 다양한 실시 예들에 따르면, 구 체적인 하드웨어 연산 방식에 따라, 딥러닝 모델을 압축하고 재학습하여 데이터를 배치하면 된다. 한편, 도면에는 도시하지 않았지만, 전자 장치는 외부 네트워크나 다른 전자 장치와 통신을 수행하기 위한 통신부(미도시)를 더 포함할 수 있다. 또한, 실시 예에 따라 전자 장치가 각종 단말 장치로 구현되는 경우, 전자 장치는 해당 단말 장치의 기능을 수행하기 위한 다양한 구성들(예를 들어, 각종 센서, 각종 명 령을 입력받기 위한 다양한 입력 인터페이스, 스피커나 디스플레이와 같은 각종 출력 인터페이스 등)을 더 포함 할 수도 있다. 도 9는 본 개시의 일 실시 예에 따른 전자 장치의 제어 방법의 흐름도이다. 도 9에 따르면, 전자 장치는, 딥러닝 모델의 파라미터값들에 기초한 복수의 정방 행렬 중 어느 하나의 정방 행렬에 대해 행렬 분해(Matrix Decomposition)를 통한 로우 랭크 근사법(Low Rank Approximation)을 적용하여 어느 하나의 정방 행렬에 대한 근사된 제1 및 제2 행렬을 획득한다(S910). 예를 들어, 전자 장치는 상기 어느 하나의 정방 행렬에 대해 특이값 분해(Singular Value Decomposition, SVD)를 통한 로우 랭크 근사법을 적용하여 상기 어느 하나의 정방 행렬에 대한 근사된 제1 및 제 2 행렬을 획득 할 수 있다. 구체적으로, 전자 장치는 어느 하나의 정방 행렬에 상기 특이값 분해를 적용하여 제1 및 제2 행렬을 획득 하고, 제1 및 제2 행렬에 로우 랭크 근사법을 적용하여 어느 하나의 정방 행렬에 대한 근사된 제1 및 제2 행렬 을 획득할 수 있다. 이때, 근사된 제1 행렬은, 어느 하나의 정방 행렬에 대한 근사된 오른쪽 특이값 벡터 행렬이고, 복수의 정방 행 렬 각각에 대한 근사된 제2 행렬은, 복수의 정방 행렬 각각에 대한 근사된 왼쪽 특이값 벡터 행렬일 수 있다. 한편, 전자 장치는 어느 하나의 정방 행렬에 대한 근사된 제1 행렬에 기초하여 복수의 정방 행렬 중 나머 지 정방 행렬에 대한 근사된 제2 행렬을 획득한다(S920). 구체적으로, 전자 장치는 나머지 정방 행렬 각각에, 전치된 제1 행렬의 역행렬을 곱하여 나머지 정방 행렬 각각의 상기 근사된 제2 행렬을 획득할 수 있다. 또한, 전자 장치는 제2 정방 행렬과, 제2 정방 행렬의 근사된 제2 행렬 및 제1 정방 행렬의 근사된 제1 행 렬의 곱의 차이를 최소화하는 연산(algorithm)을 통해 제2 정방 행렬의 근사된 제2 행렬을 획득할 수 있다. 이 때, 제1 정방 행렬은, 상기 어느 하나의 정방 행렬이고, 제2 정방 행렬은, 상기 나머지 정방 행렬 중 어느 하나 의 정방 행렬일 수 있다. 이에 따라, 전자 장치는 어느 하나의 정방 행렬에 대한 근사된 제1 행렬 및 복수의 정방 행렬에 대한 근사 된 제2 행렬을, 딥러닝 모델의 압축된 형태로 저장할 수 있다(S930). 전자 장치는 다른 전자 장치의 요청에 따라 저장된 압축된 딥러닝 모델을, 네트워크를 통해 또는 직접 전자 장치로 전송할 수 있다. 도 10은 본 개시의 다른 일 실시 예에 따른 전자 장치의 제어 방법의 흐름도이다. 도 10에 따르면, 전자 장치 는 메모리에 저장된 압축된 딥러닝 모델을 로딩한다(S1010). 여기서, 압축된 딥러닝 모델은, 근사된 제1 행렬 및 복수의 근사된 제2 행렬을 포함하고, 근사된 제1 행렬은, 딥러닝 모델의 파라미터 값들에 기초한 복수의 정방 행렬 중 어느 하나의 정방 행렬에 대해 행렬 분해를 통한 로우 랭크 근사법이 적용되어 획득된 2 개의 행렬 중 어느 하나의 행렬이고, 복수의 근사된 제2 행렬은, 상기 획득된 2 개의 행렬 중 다른 하나의 행렬과, 근사된 제1 행렬 및 복수의 정방 행렬 중 나머지 정방 행렬에 기초 하여 획득되는 행렬을 포함할 수 있다. 이때, 근사된 제1 행렬은, 어느 하나의 정방 행렬에 대해 특이값 분해를 통한 로우 랭크 근사법을 적용하여 획 득된 오른쪽 특이값 벡터 행렬이고, 복수의 근사된 제2 행렬은, 복수의 정방 행렬 각각에 대한 근사된 왼쪽 특 이값 벡터 행렬일 수 있다. 구체적으로, 전자 장치는 메모리에 저장된 근사된 제1 행렬을 1차 캐시 메모리에 로딩하고, 메 모리에 저장된 복수의 근사된 제2 행렬 중 적어도 하나를 2차 캐시 메모리에 로딩할 수 있다. 또한, 전자 장치는 입력 값 및 1차 캐시 메모리에 로딩된 근사된 제1 행렬에 기초하여 제1 연산이 수 행되는 동안, 복수의 근사된 제2 행렬 중 적어도 하나의 근사된 제2 행렬을 2차 캐시 메모리에 로딩할 수 있다. 이에 따라, 전자 장치는 압축된 딥러닝 모델에 기초하여 출력값을 획득할 수 있다(S1020). 구체적으로, 전 자 장치는 1차 캐시 메모리 및 2차 캐시 메모리에 로딩된 근사된 행렬에 기초하여 출력 값을 획 득할 수 있다. 또한, 전자 장치는 제1 연산 결과 및 2차 캐시 메모리에 로딩된 근사된 제2 행렬에 기초하여 제2 연 산할 수 있다. 이상 설명한 바와 같이 본 개시의 다양한 실시 예에 따르면, 성능 저하 없이 딥러닝 모델의 압축률을 높일 수 있다. 또한, 압축된 딥러닝 모델을 활용하여 딥러닝 모델 실행 시 전력 소모를 줄이고, 응답 시간의 지연을 줄 일 수 있다. 한편, 본 개시의 다양한 실시 예들은 기기(machine)(예: 컴퓨터)로 읽을 수 있는 저장 매체(machine-readable storage media)에 저장된 명령어를 포함하는 소프트웨어로 구현될 수 있다. 여기서, 기기는, 저장 매체로부터 저장된 명령어를 호출하고, 호출된 명령어에 따라 동작이 가능한 장치로서, 개시된 실시 예들에 따른 전자 장치 (100, 200)를 포함할 수 있다. 상기 명령이 프로세서에 의해 실행될 경우, 프로세서가 직접, 또는 상기 프로세 서의 제어하에 다른 구성요소들을 이용하여 상기 명령에 해당하는 기능을 수행할 수 있다. 명령은 컴파일러 또 는 인터프리터에 의해 생성 또는 실행되는 코드를 포함할 수 있다. 기기로 읽을 수 있는 저장매체는, 비일시적 (non-transitory) 저장매체의 형태로 제공될 수 있다. 여기서, '비일시적'은 저장매체가 신호(signal)를 포함하 지 않으며 실재(tangible)한다는 것을 의미할 뿐 데이터가 저장매체에 반영구적 또는 임시적으로 저장됨을 구분 하지 않는다. 일 실시 예에 따르면, 본 개시에 개시된 다양한 실시 예들에 따른 방법은 컴퓨터 프로그램 제품(computer program product)에 포함되어 제공될 수 있다. 컴퓨터 프로그램 제품은 상품으로서 판매자 및 구매자 간에 거래 될 수 있다. 컴퓨터 프로그램 제품은 기기로 읽을 수 있는 저장 매체(예: compact disc read only memory (CD- ROM))의 형태로, 또는 어플리케이션 스토어(예: 플레이 스토어TM)를 통해 온라인으로 배포될 수 있다. 온라인 배포의 경우에, 컴퓨터 프로그램 제품의 적어도 일부는 제조사의 서버, 어플리케이션 스토어의 서버, 또는 중계 서버의 메모리와 같은 저장 매체에 적어도 일시 저장되거나, 임시적으로 생성될 수 있다. 다양한 실시 예들에 따른 구성 요소(예: 모듈 또는 프로그램) 각각은 단수 또는 복수의 개체로 구성될 수 있으 며, 전술한 해당 서브 구성 요소들 중 일부 서브 구성 요소가 생략되거나, 또는 다른 서브 구성 요소가 다양한 실시 예에 더 포함될 수 있다. 대체적으로 또는 추가적으로, 일부 구성 요소들(예: 모듈 또는 프로그램)은 하나 의 개체로 통합되어, 통합되기 이전의 각각의 해당 구성 요소에 의해 수행되는 기능을 동일 또는 유사하게 수행 할 수 있다. 다양한 실시 예들에 따른, 모듈, 프로그램 또는 다른 구성 요소에 의해 수행되는 동작들은 순차적, 병렬적, 반복적 또는 휴리스틱하게 실행되거나, 적어도 일부 동작이 다른 순서로 실행되거나, 생략되거나, 또는 다른 동작이 추가될 수 있다. 이상의 설명은 본 개시의 기술 사상을 예시적으로 설명한 것에 불과한 것으로서, 본 개시가 속하는 기술 분야에 서 통상의 지식을 가진 자라면 본 개시의 본질적인 특성에서 벗어나지 않는 범위에서 다양한 수정 및 변형이 가 능할 것이다. 또한, 본 개시에 따른 실시 예들은 본 개시의 기술 사상을 한정하기 위한 것이 아니라 설명하기 한 것이고, 이러한 실시 예에 의하여 본 개시의 기술 사상의 범위가 한정되는 것은 아니다. 따라서, 본 개시의 보호 범위는 아래의 청구범위에 의하여 해석되어야 하며, 그와 동등한 범위 내에 있는 모든 기술 사상은 본 개시의 권리범위에 포함되는 것으로 해석되어야 할 것이다."}
{"patent_id": "10-2019-0057261", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 개시의 일 실시 예에 따른 딥러닝 시스템의 예시도, 도 2는 본 개시의 일 실시 예에 따른 전자 장치의 블럭도, 도 3은 종래의 특이값 분해를 설명하기 위한 도면, 도 4는 본 개시의 일 실시 예에 따라 전자 장치가 딥러닝 모델을 압축하는 방법을 도시한 흐름도, 도 5는 복수의 정방 행렬이 로우 랭크로 분해되어 근사화되는 개념을 도시한 도면, 도 6은 본 개시의 다른 일 실시 예에 따른 전자 장치의 블럭도, 도 7은 전자 장치가 근사화된 행렬을 이용하여 출력값을 생성하는 개념을 도시한 도면, 도 8은 본 개시의 다른 일 실시 예에 따른 전자 장치의 상세 블럭도, 도 9는 본 개시의 일 실시 예에 따른 전자 장치의 제어 방법의 흐름도, 및 도 10은 본 개시의 다른 일 실시 예에 따른 전자 장치의 제어 방법의 흐름도이다."}
