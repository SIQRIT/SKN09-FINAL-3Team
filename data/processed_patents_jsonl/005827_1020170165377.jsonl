{"patent_id": "10-2017-0165377", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2019-0065830", "출원번호": "10-2017-0165377", "발명의 명칭": "인공지능을 이용한 이동 로봇, 이동 로봇의 제어방법, 및 이동 로봇의 제어 시스템", "출원인": "엘지전자 주식회사", "발명자": "이성훈"}}
{"patent_id": "10-2017-0165377", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "본체;상기 본체를 이동시키는 구동부;필드 데이터를 생성하기 위해 주행 중 상기 본체가 위치하는 환경과 관련된 정보를 감지하는 센싱부;소정의 네트워크를 통해 서버와 통신하는 통신부; 및상기 필드 데이터를 소정의 인식 알고리즘에 입력하여 얻어낸 인식 결과를 근거로 하여 자율 주행을 제어하고,상기 필드 데이터 중 적어도 일부를 서버로 송신하도록 제어하고, 상기 서버로부터 수신한 업데이트 정보를 통해 상기 인식 알고리즘을 업데이트하는 제어부를 포함하는 이동 로봇."}
{"patent_id": "10-2017-0165377", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1항에 있어서,상기 이동 로봇은,생성된 상기 필드 데이터를 저장하는 메모리를 더 포함하고,상기 제어부는,상기 필드 데이터가 상기 서버로 송신된 후 삭제되도록 제어하는, 이동 로봇."}
{"patent_id": "10-2017-0165377", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 1항에 있어서,상기 제어부는,상기 필드 데이터를 선별하여 일부만 상기 서버로 송신하도록 제어하는, 이동 로봇."}
{"patent_id": "10-2017-0165377", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 1항에 있어서,상기 제어부는,상기 필드 데이터를 소정의 재인식 알고리즘에 입력하여 얻어진 재인식 결과를 상기 인식 결과와 비교하고, 상기 인식 결과와 상기 재인식 결과의 차이 여부에 근거하여 상기 필드 데이터를 선별하여 상기 서버로 송신하도록 제어하는, 이동 로봇."}
{"patent_id": "10-2017-0165377", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제 4항에 있어서,상기 제어부는, 주행 종료후 상기 필드 데이터를 상기 재인식 알고리즘에 입력하여 상기 재인식 결과를 얻어내는, 이동 로봇."}
{"patent_id": "10-2017-0165377", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제 4항에 있어서,상기 제어부는,상기 인식 결과와 상기 재인식 결과가 서로 상이해지는 필드 데이터를 상기 서버로 송신하도록 제어하는, 이동로봇.공개특허 10-2019-0065830-3-청구항 7 이동 로봇이 주행 중 위치하는 환경과 관련된 정보를 감지하여 필드 데이터를 생성하고, 상기 필드 데이터를 상기 이동 로봇에 저장된 인식 알고리즘에 입력하여 얻어낸 인식 결과를 근거로 하여 자율 주행을 제어하는 주행제어 단계;상기 이동 로봇이 상기 필드 데이터 중 적어도 일부를 서버로 송신하고, 상기 서버는 상기 이동 로봇이 송신한상기 필드 데이터를 근거로 업데이트 정보를 생성하는 서버 학습 단계; 및상기 서버는 상기 업데이트 정보를 상기 이동 로봇으로 송신하는 업데이트 단계를 포함하는 이동 로봇의 제어방법."}
{"patent_id": "10-2017-0165377", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제 7항에 있어서,상기 업데이트 단계에서,상기 이동 로봇은 수신한 상기 업데이트 정보를 통해 상기 인식 알고리즘을 업데이트하는, 이동 로봇의 제어방법."}
{"patent_id": "10-2017-0165377", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제 7항에 있어서,상기 주행 제어 단계 후, 상기 이동 로봇이 상기 필드 데이터를 소정의 재인식 알고리즘에 입력하여 얻어진 재인식 결과를 상기 인식 결과와 비교하는 검토 단계를 포함하고,상기 서버 학습 단계에서,상기 이동 로봇은 상기 인식 결과와 상기 재인식 결과의 차이 여부에 근거하여 상기 필드 데이터를 선별하여 상기 서버로 송신하는, 이동 로봇의 제어방법."}
{"patent_id": "10-2017-0165377", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제 9항에 있어서,상기 검토 단계는, 상기 이동 로봇의 주행 종료후 진행되는, 이동 로봇의 제어방법."}
{"patent_id": "10-2017-0165377", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제 9항에 있어서,상기 인식 알고리즘의 수행에 따른 인식 결과 출력은 상기 재인식 알고리즘의 수행에 따른 재인식 결과 출력에비해 더 짧은 시간이 소요되도록 기설정된, 이동 로봇의 제어방법."}
{"patent_id": "10-2017-0165377", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제 9항에 있어서,상기 서버 학습 단계에서,상기 이동 로봇은 상기 인식 결과와 상기 재인식 결과가 서로 상이해지는 필드 데이터를 상기 서버로 송신하는,이동 로봇의 제어방법."}
{"patent_id": "10-2017-0165377", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제 9항에 있어서,상기 업데이트 단계에서,상기 이동 로봇은 수신한 상기 업데이트 정보를 통해 상기 인식 알고리즘 및 상기 재인식 알고리즘 중 적어도하나를 업데이트하는, 이동 로봇의 제어방법.공개특허 10-2019-0065830-4-청구항 14 제 7항에 있어서,상기 서버 학습 단계에서,상기 서버는 수신한 상기 필드 데이터를 근거로 상기 인식 알고리즘을 학습하여 상기 업데이트 정보를생성하는, 이동 로봇 제어방법."}
{"patent_id": "10-2017-0165377", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제 7항에 있어서,상기 업데이트 정보는 업데이트된 인식 알고리즘을 포함하고,상기 업데이트 단계에서,상기 이동 로봇은 상기 서버로부터 수신한 상기 업데이트된 인식 알고리즘을 상기 이동 로봇의 기저장된 인식알고리즘과 대체함으로써 업데이트를 수행하는, 이동 로봇의 제어방법."}
{"patent_id": "10-2017-0165377", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제 7항에 있어서,상기 서버 학습 단계에서,상기 서버는 복수의 이동 로봇으로부터 수신한 상기 필드 데이터를 근거로 상기 업데이트 정보를 생성하는, 이동 로봇의 제어방법."}
{"patent_id": "10-2017-0165377", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "이동 로봇; 및상기 이동 로봇과 소정의 네트워크를 통해 통신하는 서버를 포함하고,상기 이동 로봇은,주행 중 상기 이동 로봇이 위치하는 환경과 관련된 정보를 감지하여 필드 데이터를 생성하고, 상기 필드 데이터를 상기 이동 로봇에 저장된 인식 알고리즘에 입력하여 얻어낸 인식 결과를 근거로 하여 자율 주행을 제어하고,상기 필드 데이터 중 적어도 일부를 서버로 송신하고,상기 서버는,수신한 상기 필드 데이터를 근거로 업데이트 정보를 생성하고, 상기 업데이트 정보를 상기 이동 로봇으로 송신하는, 이동 로봇 제어 시스템."}
{"patent_id": "10-2017-0165377", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제 17항에 있어서,상기 이동 로봇은,수신한 상기 업데이트 정보를 통해 상기 인식 알고리즘을 업데이트하는, 이동 로봇 제어 시스템."}
{"patent_id": "10-2017-0165377", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제 17항에 있어서,상기 이동 로봇은,상기 필드 데이터를 소정의 재인식 알고리즘에 입력하여 얻어진 재인식 결과를 상기 인식 결과와 비교하고, 상기 인식 결과와 상기 재인식 결과의 차이 여부에 근거하여 상기 필드 데이터를 선별하여 상기 서버로 송신하도록 제어하고, 수신한 상기 업데이트 정보를 통해 상기 인식 알고리즘 및 상기 재인식 알고리즘 중 적어도 하나를 업데이트하는, 이동 로봇 제어 시스템.공개특허 10-2019-0065830-5-청구항 20 제 17항에 있어서,복수의 상기 이동 로봇을 포함하고,상기 서버는 복수의 이동 로봇으로부터 수신한 상기 필드 데이터를 근거로 상기 업데이트 정보를 생성하는, 이동 로봇의 제어 시스템."}
{"patent_id": "10-2017-0165377", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명에 따른 이동 로봇의 제어방법은, 이동 로봇이 주행 중 위치하는 환경과 관련된 정보를 감지하여 필드 데 이터를 생성하고, 상기 필드 데이터를 상기 이동 로봇에 저장된 인식 알고리즘에 입력하여 얻어낸 인식 결과를 근거로 하여 자율 주행을 제어하는 주행 제어 단계; 상기 이동 로봇이 상기 필드 데이터 중 적어도 일부를 서버 로 송신하고, 상기 서버는 상기 이동 로봇이 송신한 상기 필드 데이터를 근거로 업데이트 정보를 생성하는 서버 학습 단계; 및 상기 서버는 상기 업데이트 정보를 상기 이동 로봇으로 송신하는 업데이트 단계를 포함한다."}
{"patent_id": "10-2017-0165377", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 이동 로봇, 그 제어 방법 및 그 제어 시스템에 관한 것으로서, 이동 로봇과 서버의 네트워크를 이용 한 머신 러닝(maching learning)에 관한 것이다."}
{"patent_id": "10-2017-0165377", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "일반적으로 로봇은 산업용으로 개발되어 공장 자동화의 일 부분을 담당하여 왔다. 최근에는 로봇을 응용한 분야 가 더욱 확대되어, 의료용 로봇, 우주 항공 로봇 등이 개발되고, 일반 가정에서 사용할 수 있는 가정용 로봇도 만들어지고 있다. 이러한 로봇 중에서 자력으로 주행이 가능한 것을 이동 로봇이라고 한다. 가정에서 사용되는 이동 로봇의 대표적인 예는 로봇 청소기이다. 이러한 이동 로봇은 일반적으로 충전 가능한 배터리를 구비하고, 주행 중 장애물을 피할 수 있는 장애물 센서를 구비하여 스스로 주행할 수 있다. 최근에는, 이동 로봇이 단순히 자율적으로 주행하여 청소를 수행하는 것에서 벗어나 헬스 케어, 스마트홈, 원격 제어 등 다양한 분야에 활용하기 위한 연구가 활발하게 이루어지고 있다. 또한, 이동 로봇은 다양한 정보를 수집할 수 있으며, 네트워크를 이용하여 수집한 정보를 다양한 방식으로 처리 할 수 있다. 예를 들어, 이동 로봇의 카메라는 이동 로봇의 본체 주변을 촬영하고, 이동 로봇의 제어부는 촬영된 영상에 존 재하는 장애물과 관련된 정보를 검출할 수 있다. 이와 관련하여, 한국공개특허 10-2013-0027355호(공개일자 2013년 03월 15일)에서는 단말 장치와 로봇 청소기를 네트워크를 통해 연결함으로써, 로봇 청소기를 다양하게 제어할 수 있는 로봇 청소기의 원격 제어 시스템을 개 시하고 있다. 그러나, 상기 한국공개특허 10-2013-0027355호에 따른 로봇 청소기 시스템에서는, 로봇 청소기가 주변의 장애물 을 검출함에 있어서, 머신 러닝(Machine Learning) 기법을 활용하지 않기 때문에, 장애물을 정확히 검출하기 어 려운 문제점이 있다. 선행기술문헌 특허문헌 (특허문헌 0001) 한국공개특허 10-2013-0027355호(공개일자 2013년 03월 15일) 비특허문헌"}
{"patent_id": "10-2017-0165377", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "이동 로봇은 기저장된 알고리즘에 의해서만 근거하여, 주변의 장애물 등 환경을 인식하는데, 새로운 유형의 장 애물이 출현하는 등 환경에 따른 예외적인 상황 발생시 기저장된 알고리즘으로는 정확히 파악이 어려우며, 이에따라 잘못된 대응 주행 등을 수행하여 사용자에게 곤란을 초래하는 문제가 있다. 본 발명의 제 1과제는 이러한 문제를 해결하는 것이다. 본 발명의 제 2과제는, 학습에 필요한 이동 로봇의 위치한 환경에 대한 필드 데이터를 효율적으로 수집하면서도, 수집된 필드 데이터를 이용하여 보다 정밀하고 광범위하게 학습을 수행할 수 있게 하는 것이다. 머신 러닝에 있어서, 어느 한 이동 로봇이 감지를 통해 생성시킨 데이터는 상기 어느 한 이동 로봇의 학습에만 이용되어, 다른 이동 로봇은 별도의 중복적인 학습이 필요하다는 중복적인 소요가 발생하는 문제가 있다. 즉, 복수의 이동 로봇이 각자의 환경에 적응하기 위한 각각 별도의 적응 노력(학습 노력)이 필요하다는 문제가 있다. 본 발명의 제 3과제는 이러한 문제를 해결하는 것이다. 상기 제 2과제를 해결하는 수단으로서 이동 로봇이 생성시킨 필드 데이터를 서버로 송신하는 경우, 생성된 모든 필드 데이터를 서버로 송신한다면 데이터 송수신과 데이터를 통한 학습 진행에 부담이 지나치게 커지는 문제가 있다. 본 발명의 제 4과제는 이러한 문제를 해결하는 것이다. 또한, 상기 제 2과제 및 상기 제 4과제를 해결하기 위하여, 만약 이동 로봇이 생성시킨 필드 데이터를 서버로 송신할 때 사용자가 이를 선택적으로 송신하도록 한다면, 사용 측면에 있어 지나친 번거로움이 발생하는 문제가 있다. 본 발명의 제 5과제는 이러한 문제를 해결하는 것이다."}
{"patent_id": "10-2017-0165377", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기 제 1과제들을 해결하기 위하여, 본 발명은 설계자 또는 사용자에 의해 설계된 이동 로봇의 최초 성능에 제 한되지 않고, 머신 러닝(Machine Learning) 기능을 효과적으로 구현시키는 해결 수단을 제시한다. 상기 제 2 과제를 해결하기 위하여, 본 발명은, 이동 로봇이 학습에 필요한 데이터(필드 데이터)를 생성시키고 서버는 상기 필드 데이터를 근거로 이동 로봇의 인식 알고리즘을 학습하는 수단을 제공한다. 상기 제 3과제를 해결하기 위하여, 본 발명은, 서버가 복수의 이동 로봇으로부터 수신한 필드 데이터를 근거로 학습하는 수단을 제공한다. 상기 제 4 및 5 과제를 해결하기 위하여, 본 발명은, 이동 로봇이 필드 데이터를 선별적으로 서버에 전송하는 수단을 제공한다. 상기 과제들을 해결하기 위하여, 본 발명에 따른 이동 로봇은, 본체; 상기 본체를 이동시키는 구동부; 필드 데 이터를 생성하기 위해 주행 중 상기 본체가 위치하는 환경과 관련된 정보를 감지하는 센싱부; 소정의 네트워크 를 통해 서버와 통신하는 통신부; 및 상기 필드 데이터를 소정의 인식 알고리즘에 입력하여 얻어낸 인식 결과를 근거로 하여 자율 주행을 제어하고, 상기 필드 데이터 중 적어도 일부를 서버로 송신하도록 제어하고, 상기 서 버로부터 수신한 업데이트 정보를 통해 상기 인식 알고리즘을 업데이트하는 제어부를 포함한다. 상기 이동 로봇은 생성된 상기 필드 데이터를 저장하는 메모리를 더 포함할 수 있다. 상기 제어부는, 상기 필드 데이터가 상기 서버로 송신된 후 삭제되도록 제어할 수 있다. 상기 제어부는, 상기 필드 데이터를 선별하여 일부만 상기 서버로 송신하도록 제어할 수 있다. 상기 제어부는, 상기 필드 데이터를 소정의 재인식 알고리즘에 입력하여 얻어진 재인식 결과를 상기 인식 결과 와 비교하고, 상기 인식 결과와 상기 재인식 결과의 차이 여부에 근거하여 상기 필드 데이터를 선별하여 상기 서버로 송신하도록 제어할 수 있다. 상기 제어부는, 주행 종료후 상기 필드 데이터를 상기 재인식 알고리즘에 입력하여 상기 재인식 결과를 얻어낼 수 있다. 상기 제어부는, 상기 인식 결과와 상기 재인식 결과가 서로 상이해지는 필드 데이터를 상기 서버로 송신하도록 제어할 수 있다. 상기 과제들을 해결하기 위하여, 본 발명에 따른 이동 로봇의 제어방법은, 이동 로봇이 주행 중 위치하는 환경 과 관련된 정보를 감지하여 필드 데이터를 생성하고, 상기 필드 데이터를 상기 이동 로봇에 저장된 인식 알고리 즘에 입력하여 얻어낸 인식 결과를 근거로 하여 자율 주행을 제어하는 주행 제어 단계; 상기 이동 로봇이 상기 필드 데이터 중 적어도 일부를 서버로 송신하고, 상기 서버는 상기 이동 로봇이 송신한 상기 필드 데이터를 근 거로 업데이트 정보를 생성하는 서버 학습 단계; 및 상기 서버는 상기 업데이트 정보를 상기 이동 로봇으로 송신하는 업데이트 단계를 포함한다. 상기 업데이트 단계에서, 상기 이동 로봇은 수신한 상기 업데이트 정보를 통해 상기 인식 알고리즘을 업데이트 할 수 있다. 상기 주행 제어 단계 후, 상기 이동 로봇이 상기 필드 데이터를 소정의 재인식 알고리즘에 입력하여 얻어진 재 인식 결과를 상기 인식 결과와 비교하는 검토 단계를 포함할 수 있다. 상기 서버 학습 단계에서, 상기 이동 로 봇은 상기 인식 결과와 상기 재인식 결과의 차이 여부에 근거하여 상기 필드 데이터를 선별하여 상기 서버로 송 신할 수 있다. 상기 검토 단계는, 상기 이동 로봇의 주행 종료후 진행될 수 있다. 상기 인식 알고리즘의 수행에 따른 인식 결과 출력은 상기 재인식 알고리즘의 수행에 따른 재인식 결과 출력에 비해 더 짧은 시간이 소요되도록 기설정될 수 있다. 상기 서버 학습 단계에서, 상기 이동 로봇은 상기 인식 결과와 상기 재인식 결과가 서로 상이해지는 필드 데이 터를 상기 서버로 송신할 수 있다. 상기 업데이트 단계에서, 상기 이동 로봇은 수신한 상기 업데이트 정보를 통해 상기 인식 알고리즘 및 상기 재 인식 알고리즘 중 적어도 하나를 업데이트할 수 있다. 상기 서버 학습 단계에서, 상기 서버는 수신한 상기 필드 데이터를 근거로 상기 인식 알고리즘을 학습하여 상기 업데이트 정보를 생성할 수 있다. 상기 업데이트 정보는 업데이트된 인식 알고리즘을 포함할 수 있다. 상기 업데이트 단계에서, 상기 이동 로봇은 상기 서버로부터 수신한 상기 업데이트된 인식 알고리즘을 상기 이동 로봇의 기저장된 인식 알고리즘과 대체함 으로써 업데이트를 수행할 수 있다. 상기 서버 학습 단계에서, 상기 서버는 복수의 이동 로봇으로부터 수신한 상기 필드 데이터를 근거로 상기 업데 이트 정보를 생성할 수 있다. 상기 과제들을 해결하기 위하여, 본 발명에 따른 이동 로봇 제어 시스템은, 이동 로봇; 및 상기 이동 로봇과 소 정의 네트워크를 통해 통신하는 서버를 포함한다. 상기 이동 로봇은, 주행 중 상기 이동 로봇이 위치하는 환경 과 관련된 정보를 감지하여 필드 데이터를 생성하고, 상기 필드 데이터를 상기 이동 로봇에 저장된 인식 알고리 즘에 입력하여 얻어낸 인식 결과를 근거로 하여 자율 주행을 제어하고, 상기 필드 데이터 중 적어도 일부를 서 버로 송신한다. 상기 서버는, 수신한 상기 필드 데이터를 근거로 업데이트 정보를 생성하고, 상기 업데이트 정 보를 상기 이동 로봇으로 송신한다. 상기 이동 로봇은, 수신한 상기 업데이트 정보를 통해 상기 인식 알고리즘을 업데이트할 수 있다. 상기 이동 로봇은, 상기 필드 데이터를 소정의 재인식 알고리즘에 입력하여 얻어진 재인식 결과를 상기 인식 결 과와 비교하고, 상기 인식 결과와 상기 재인식 결과의 차이 여부에 근거하여 상기 필드 데이터를 선별하여 상기 서버로 송신하도록 제어하고, 수신한 상기 업데이트 정보를 통해 상기 인식 알고리즘 및 상기 재인식 알고리즘 중 적어도 하나를 업데이트할 수 있다. 상기 이동 로봇 제어 시스템은 복수의 상기 이동 로봇을 포함할 수 있다. 상기 서버는 복수의 이동 로봇으로부 터 수신한 상기 필드 데이터를 근거로 상기 업데이트 정보를 생성할 수 있다."}
{"patent_id": "10-2017-0165377", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "상기 해결 수단을 통해서, 상기 이동 로봇은 효율적으로 외부 환경에 대한 인식률을 상승시키고 오인식률을 저 감시키도록 인식 알고리즘을 업데이트할 수 있다. 상기 이동 로봇이 필드 데이터를 생성하고 상기 필드 데이터를 근거로 학습하게 함으로써 이동 로봇이 위치한 환경에 대한 정보를 기반으로 인식 알고리즘의 학습이 진행되면서도, 서버 기반 학습을 통해 보다 효과적인 학 습을 수행할 있다. 상기 서버가 상기 복수의 이동 로봇으로부터 필드 데이터를 수집함으로써, 보다 다양한 환경을 근거로 상기 서 버가 인식 알고리즘을 학습할 수 있으며, 복수의 이동 로봇이 중복적인 학습을 수행하는 소요가 줄어들 수 있다.상기 필드 데이터는 서버로 송신된 후 이동 로봇의 메모리에서 삭제됨으로써, 이동 로봇의 메모리 용량 부담을 줄일 수 있는 효과가 있다. 상기 필드 데이터를 선별적으로 일부만 서버로 송신함으로써, 필드 데이터의 송수신 부담 및 서버의 학습 부담 을 완화하고, 보다 효과적으로 서버가 학습을 수행할 수 있게 해준다. 상기 인식 알고리즘 및 상기 재인식 알고리즘에 따른 결과값의 차이 여부에 따라 송신할 필드 데이터를 선별함 으로써, 이동 로봇은 서버의 학습에 보다 유의미한 필드 데이터를 선별할 수 있다. 주행 종료후 상기 재인식 알고리즘을 통한 재인식 결과를 얻음으로써, 주행 중 데이터 처리 부담을 완화하면서 도, 필드 데이터를 효율적으로 선별할 수 있다. 또한, 상기 인식 알고리즘의 수행에 따른 인식 결과 출력은 상 기 재인식 알고리즘의 수행에 따른 재인식 결과 출력에 비해 더 짧은 시간이 소요되도록 기설정됨으로써, 보다 정밀도는 떨어지더라도 빠른 처리가 가능한 상기 인식 알고리즘을 이용하여 이동 로봇의 자율 주행을 제어하고, 상기 인식 결과와 비교되는 상기 재인식 결과를 얻기 위하여 상기 재인식 알고리즘을 이용할 수 있다."}
{"patent_id": "10-2017-0165377", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하에서 언급되는 구성요소의 용어 중 앞에 ‘제 1, 제 2, 제 3’ 등의 표현이 붙는 용어는, 지칭하는 구성요 소의 혼동을 피하기 위한 것 일 뿐, 구성요소 들 사이의 순서, 중요도 또는 주종관계 등과는 무관하다. 예를 들 면, 제 1 구성요소 없이 제 2구성요소 만을 포함하는 발명도 구현 가능하다. 본 발명에 따른 이동 로봇은 바퀴 등을 이용하여 스스로 이동이 가능한 로봇을 의미하고, 가정 도우미 로 봇 및 로봇 청소기 등이 될 수 있다. 이하 도 1 내지 도 4를 참조하여, 이동 로봇 중 로봇 이동 로봇를 예 로 들어 설명하나, 반드시 이에 한정될 필요는 없다. 도 1 내지 도 3을 참고하여, 이동 로봇은 일정 영역을 스스로 주행할 수 있다. 이동 로봇은 바닥을 청소하는 기능을 수행할 수 있다. 여기서 말하는 바닥의 청소에는, 바닥의 먼지(이물질을 포함한다)를 흡입하거 나 바닥을 걸레질하는 것이 포함된다. 이동 로봇은 본체를 포함한다. 본체는 외관을 형성하는 케비닛을 포함한다. 이동 로봇은, 본체에 구비된 흡입 유닛 및 먼지통을 포함할 수 있다. 이동 로봇은 이동 로봇 주변의 환 경과 관련된 정보를 감지하는 센싱부를 포함한다. 이동 로봇은 상기 본체를 이동시키는 구동부를 포함한다. 이동 로봇은 이동 로봇의 제어를 위한 제어부를 포함한다. 제어부는 본체 에 구비된다. 구동부는 이동 로봇의 주행을 위한 휠 유닛을 포함한다. 휠 유닛은 본체에 구비된다. 휠 유닛에 의해 이동 로봇은 전후좌우로 이동되거나 회전될 수 있다. 제어부가 휠 유닛의 구동 을 제어함으로써, 이동 로봇은 바닥을 자율 주행할 수 있다. 휠 유닛은 메인 휠(111a) 및 서브 휠 (111b)을 포함한다. 메인 휠(111a)은 본체의 양측에 각각 구비되어, 제어부의 제어 신호에 따라 일 방향 또는 타 방향으로 회 전 가능하게 구성된다. 각각의 메인 휠(111a)은 서로 독립적으로 구동 가능하게 구성될 수 있다. 예를 들어, 각 각의 메인 휠(111a)은 서로 다른 모터에 의해서 구동될 수 있다. 서브 휠(111b)은 메인 휠(111a)과 함께 본체를 지지하며, 메인 휠(111a)에 의한 이동 로봇의 주행을 보조하도록 이루어진다. 이러한 서브 휠(111b)은 후술하는 흡입 유닛에도 구비될 수 있다. 흡입 유닛은 본체의 전방(F)으로부터 돌출된 형태로 배치될 수 있다. 흡입 유닛은 먼지가 포함 된 공기를 흡입하도록 구비된다. 흡입 유닛이 본체의 전방에서 좌우 양측방으로 돌출된 형태를 가질 수 있다. 흡입 유닛의 전단 부는 본체의 일측으로부터 전방으로 이격된 위치에 배치될 수 있다. 흡입 유닛의 좌우 양단부는 본체 로부터 좌우 양측으로 각각 이격된 위치에 배치될 수 있다. 본체는 원형으로 형성되고, 흡입 유닛의 후단부 양측이 본체로부터 좌우 양측으로 각각 돌출 형 성됨에 따라, 본체와 흡입 유닛 사이에는 빈 공간, 즉 틈이 형성될 수 있다. 상기 빈 공간은 본체 의 좌우 양단부와 흡입 유닛의 좌우 양단부 사이의 공간으로서, 이동 로봇의 내측으로 함몰된 형태를 가진다. 흡입 유닛은 본체에 착탈 가능하게 결합될 수 있다. 흡입 유닛이 본체로부터 분리되면, 분 리된 흡입 유닛을 대체하여 걸레 모듈(미도시)이 본체에 착탈 가능하게 결합될 수 있다. 센싱부는 본체에 배치될 수 있다. 센싱부는 본체의 전방(F)에 배치될 수 있다. 센싱부 는 본체의 상하 방향으로 흡입 유닛과 오버랩(overlap)되도록 배치될 수 있다. 센싱부는 흡입 유닛의 상부에 배치될 수 있다. 센싱부는 이동 로봇 주변의 장애물을 감지할 수 있다. 센싱부는 이동 로봇의 가장 앞쪽에 위치하는 흡입 유닛이 장애물과 부딪히지 않도록 전방의 장애물이나 지형지물 등을 감지할 수 있다. 센싱 부는 이러한 감지 기능 외의 후술할 다른 센싱 기능을 추가로 수행할 수 있다. 본체에는 먼지통 수용부가 구비될 수 있다. 먼지통 수용부에는 흡입된 공기 중의 먼지를 분리하 여 집진하는 먼지통이 착탈 가능하게 결합된다. 먼지통 수용부는 본체의 후방(R)에 형성될 수 있다. 먼지통의 일부는 먼지통 수용부에 수용되되, 먼지통의 다른 일부는 본체의 후방(R) 을 향하여 돌출되게 형성될 수 있다. 먼지통에는 먼지가 포함된 공기가 유입되는 입구(미도시)와 먼지가 분리된 공기가 배출되는 출구(미도시) 가 형성된다. 먼지통 수용부에 먼지통이 장착시 먼지통의 상기 입구와 상기 출구는 먼지통 수용 부의 내측벽에 형성된 제1개구(미도시) 및 제2개구(미도시)와 각각 연통되도록 구성된다. 흡입 유닛의 흡입구부터 상기 제1개구까지 공기를 안내하는 흡입 유로(미도시)가 구비된다. 상기 제2개구 부터 외부를 향해 열린 배기구(미도시)까지 공기를 안내하는 배기 유로(미도시)가 구비된다. 흡입 유닛을 통하여 유입된 먼지가 포함된 공기는 본체 내부의 상기 흡기유로를 거쳐, 먼지통으 로 유입되고, 먼지통의 필터 내지는 사이클론을 거치면서 공기와 먼지가 상호 분리된다. 먼지는 먼지통 에 집진되며, 공기는 먼지통에서 배출된 후 본체 내부의 상기 배기유로를 거쳐 최종적으로 상기 배기구를 통하여 외부로 배출된다. 도 4를 참고하여, 이동 로봇은 소정의 네트워크를 통해 통신하는 통신부를 포함한다. 이동 로봇 은 사용자로부터 각종 지시를 입력받는 입력부를 포함한다. 이동 로봇은 사용자에게 각종 정보 를 출력하는 출력부를 포함한다. 이동 로봇은 정보를 저장하는 메모리를 포함한다.이동 로봇은 전원을 공급하는 전원부를 포함한다. 전원부는 이동 로봇에 포함된 각 구성들 에 구동 전원을 공급한다. 전원부는 이동 로봇이 주행하거나 특정 기능을 수행하는데 요구되는 동작 전원 을 공급할 수 있다. 전원부는 본체에 장착된 배터리(미도시)를 포함할 수 있다. 상기 배터리는 충전 가능하게 구비될 수 있다. 상기 배터리는 외부 상용 전원에 의해 충전 가능하게 구비된다. 상기 배터리는 본체 의 저면부에 착탈 가능하게 구성될 수 있다. 제어부 상기 배터리의 전원 잔량을 감지하고, 전원 잔량이 부족하면 외부 상용 전원과 연결된 충전대로 이 동 로봇이 이동하도록 제어할 수 있다. 출력부은 제어부에 의해 상기 배터리 잔량을 화면에 표시할 수 있다. 구동부는 모터를 구비하여, 상기 모터를 구동함으로써, 좌, 우측 주바퀴를 양 방향으로 회전시켜 본체를 회전 또는 이동시킬 수 있다. 구동부는 이동 로봇의 본체를 전후좌우로 진행시키거나, 곡선주행시키거나, 제자리 회전시킬 수 있다. 입력부는 사용자로부터 로봇 청소기에 대한 각종 제어 명령을 입력 받는다. 입력부는 버튼이나 다이 얼, 터치 스크린 등을 포함할 수 있다. 입력부는 사용자의 음성 지시를 입력 받기 위한 마이크를 포함할 수 있다. 출력부는 각종 정보를 시각적 또는 청각적으로 출력할 수 있다. 출력부는 디스플레이를 포함할 수 있 다. 예를 들어, 배터리 상태 또는 주행 방식 등이 상기 디스플레이에 표시될 수 있다. 출력부는 소리나 음 성을 출력하는 스피커를 포함할 수 있다. 일 예로, 출력부를 통해 주행 영역에 대한 환경 정보를 화면에 출력하거나 음향으로 출력할 수 있다. 다른 예로, 단말 장치가 시각적 정보나 청각적 정보를 출력하도록, 소정의 정보를 소정의 네트워크를 통해 단말 장치로 전송할 수 있다. 센싱부는, 주행 중 본체가 위치하는 환경과 관련된 정보를 감지한다. 센싱부는 필드 데이터 (field data)를 생성하기 위하여 상기 환경과 관련된 정보를 감지한다. 센싱부는, 외부 신호 감지 센서, 장애물 감지 센서, 낭떠러지 감지 센서, 하부 카메라 센서, 상부 카메라 센서, 3차원 카메라 센서, 엔코더, 충격 감지 센서 및 마이크 중 적어도 하나를 포함할 수 있다. 외부 신호 감지 센서는 이동 로봇의 외부 신호를 감지할 수 있다. 외부 신호 감지 센서는, 일 예로, 적외선 센 서(Infrared Ray Sensor), 초음파 센서(Ultra Sonic Sensor), RF 센서(Radio Frequency Sensor) 등일 수 있다. 이에 따라, 외부 신호에 대한 필드 데이터가 생성될 수 있다. 이동 로봇은 외부 신호 감지 센서를 이용하여 충전대가 발생하는 안내 신호를 수신하여 충전대의 위치 및 방향 에 대한 정보를 감지할 수 있다. 이때, 충전대는 이동 로봇이 복귀 가능하도록 방향 및 거리를 지시하는 안내 신호를 발신할 수 있다. 즉, 이동 로봇은 충전대로부터 발신되는 신호를 수신하여 현재의 위치를 판단하고 이동 방향을 설정하여 충전대로 복귀할 수 있다. 장애물 감지 센서는, 이동 로봇의 전방에 설치될 수 있다. 장애물 감지 센서는 전방의 장애물을 감지할 수 있다. 이에 따라, 장애물에 대한 필드 데이터가 생성된다. 장애물 감지 센서는 이동 로봇의 이동 방향에 존재하는 물체를 감지하여 생성된 필드 데이터를 제어부에 전달할 수 있다. 즉, 장애물 감지 센서는, 이동 로봇의 이동 경로 상에 존재하는 돌출물, 집안의 집기, 가구, 벽면, 벽 모서리 등을 감지하여 그 필드 데이터를 제어부에 전달할 수 있다. 장애물 감지 센서는, 일 예로, 적외선 센서, 초음파 센서, RF 센서, 지자기 센서 등일 수 있다. 이동 로봇(10 0)은 장애물 감지 센서로 한 가지 종류의 센서를 사용하거나 필요에 따라 두 가지 종류 이상의 센서를 함께 사 용할 수 있다. 낭떠러지 감지 센서(Cliff Sensor)는, 다양한 형태의 광 센서를 주로 이용하여, 이동 로봇의 본체를 지지하는 바닥의 장애물을 감지할 수 있다. 이에 따라, 바닥의 장애물에 대한 필드 데이터가 생성된다. 낭떠러지 감지 센서는, 바닥의 이동 로봇의 배면에 설치될 수 있다. 낭떠러지 감지 센서는, 바닥의 장애물을 감 지할 수 있다. 낭떠러지 감지 센서는 상기 장애물 감지 센서와 같이 발광부와 수광부를 구비한 적외선 센서, 초 음파 센서, RF 센서, PSD(Position Sensitive Detector) 센서 등일 수 있다. 예를 들어, 낭떠러지 감지 센서는 PSD 센서일 수 있으나, 복수의 서로 다른 종류의 센서로 구성될 수도 있다. PSD 센서는 장애물에 적외선을 발광하는 발광부와, 장애물로부터 반사되어 돌아오는 적외선을 수광하는 수광부 를 구비하되, 일반적으로 모듈 형태로 구성된다. PSD 센서를 이용하여, 장애물을 감지하는 경우, 장애물의 반사 율, 색의 차이에 상관없이 안정적인 측정값을 얻을 수 있다. 제어부는 낭떠러지 감지 센서가 지면을 향해 발광한 적외선의 발광신호와 장애물에 의해 반사되어 수신되 는 반사신호 간의 적외선 각도를 측정하여, 낭떠러지를 감지하고 그 깊이에 대한 필드 데이터를 획득할 수 있다. 하부 카메라 센서는, 이동 로봇의 배면에 구비될 수 있다. 하부 카메라 센서는, 이동 중 피청소면에 대한 이미 지 정보(필드 데이터)를 획득한다. 하부 카메라 센서는, 다른 말로 옵티컬 플로우 센서(Optical Flow Sensor)라 칭하기도 한다. 하부 카메라 센서는, 센서 내에 구비된 이미지 센서로부터 입력되는 하방 영상을 변환하여 소정 형식의 영상 데이터(필드 데이터)를 생성할 수 있다. 상기 하부 카메라 센서를 통해 인식된 영상에 대한 필드 데이터가 생성될 수 있다. 하부 카메라 센서를 이용하여, 제어부는 이동 로봇의 미끄러짐과 무관하게 이동 로봇의 위치를 검출할 수 있다. 제어부은 하부 카메라 센서에 의해 촬영된 영상 데이터를 시간에 따라 비교 분석하여 이동 거리 및 이동 방향을 산출하고, 이를 근거로 이동 로봇의 위치를 산출할 수 있다. 상부 카메라 센서는 이동 로봇의 상방이나 전방을 향하도록 설치되어 이동 로봇 주변을 촬영할 수 있다. 이동 로봇이 복수의 상부 카메라 센서들을 구비하는 경우, 카메라 센서들은 일정 거리 또는 일정 각도로 이동 로봇의 상부나 옆면에 형성될 수 있다. 상기 상부 카메라 센서를 통해 인식된 영상에 대한 필드 데이터가 생성될 수 있 다. 3차원 카메라 센서는 이동 로봇의 본체 일면 또는 일부분에 부착되어, 상기 본체의 주위와 관련된 3차원 좌표 정보를 생성할 수 있다. 즉, 3차원 카메라 센서는 이동 로봇과 피촬영 대상체의 원근거리를 산출하는 3차 원 뎁스 카메라(3D Depth Camera)일 수 있다. 이에 따라, 상기 3차원 좌표 정보에 대한 필드 데이터가 생성될 수 있다. 구체적으로, 3차원 카메라 센서는 본체의 주위와 관련된 2차원 영상을 촬영할 수 있으며, 촬영된 2차원 영상에 대응되는 복수의 3차원 좌표 정보를 생성할 수 있다. 일 실시예에서 3차원 카메라 센서는 기존의 2차원 영상을 획득하는 카메라를 2개 이상 구비하여, 상기 2개 이상 의 카메라에서 획득되는 2개 이상의 영상을 조합하여, 3차원 좌표 정보를 생성하는 스테레오 비전 방식으로 형 성될 수 있다. 구체적으로, 상기 실시예에 따른 3차원 카메라 센서는 본체의 전방을 향해 하측으로 제1 패턴의 광을 조사하는 제1 패턴 조사부와, 상기 본체의 전방을 향해 상측으로 제2 패턴의 광을 조사하는 제2 패턴 조사부 및 본체의 전방의 영상을 획득하는 영상 획득부를 포함할 수 있다. 이로써, 상기 영상 획득부는 상기 제1 패턴의 광과 상 기 제2 패턴의 광이 입사된 영역의 영상을 획득할 수 있다. 또 다른 실시예에서 3차원 카메라 센서는 단일 카메라와 함께 적외선 패턴을 조사하는 적외선 패턴 방출부를 구 비하고, 적외선 패턴 방출부에서 조사된 적외선 패턴이 피촬영 대상체에 투영된 모양을 캡쳐함으로써, 3차원 카 메라 센서와 피촬영 대상체 사이의 거리를 측정할 수 있다. 이러한 3차원 카메라 센서는 IR(Infra Red) 방식의 3차원 카메라 센서일 수 있다. 또 다른 실시예에서 3차원 카메라 센서는 단일 카메라와 함께 빛을 방출하는 발광부를 구비하고, 발광부에서 방 출되는 레이저 중 피촬영 대상체로부터 반사되는 일부를 수신하며, 수신된 레이저를 분석함으로써, 3차원 카메 라 센서와 피촬영 대상체 사이의 거리를 측정할 수 있다. 이러한 3차원 카메라 센서는 TOF(Time of Flight) 방 식의 3차원 카메라 센서일 수 있다. 구체적으로, 위와 같은 3차원 카메라 센서의 레이저는 적어도 일방향으로 연장된 형태의 레이저를 조사하도록 구성된다. 일 예에서, 상기 3차원 카메라 센서는 제1 및 제2 레이저를 구비할 수 있으며, 상기 제1 레이저는 서 로 교차하는 직선 형태의 레이저를 조사하고, 제2 레이저는 단일의 직선 형태의 레이저를 조사할 수 있다. 이에 따르면, 최하단 레이저는 바닥 부분의 장애물을 감지하는 데에 이용되고, 최상단 레이저는 상부의 장애물을 감 지하는 데에 이용되며, 최하단 레이저와 최상단 레이저 사이의 중간 레이저는 중간 부분의 장애물을 감지하는 데에 이용된다.엔코더는 구동부의 바퀴를 동작시키는 모터의 동작과 관련된 정보를 감지할 수 있다. 이에 따라, 모터의 동작에 대한 필드 데이터가 생성된다. 충격 감지 센서는 이동 로봇이 외부의 장애물 등과 충돌시 충격을 감지할 수 있다. 이에 따라, 외부의 충 격에 대한 필드 데이터가 생성된다. 마이크는 외부의 소리를 감지할 수 있다. 이에 따라서, 외부의 소리에 대한 필드 데이터가 생성된다. 본 실시예에서, 센싱부는 영상 센서를 포함한다. 본 실시예에서 상기 필드 데이터는 상기 영상 센서가 획 득한 영상 정보 또는 상기 영상 정보로부터 추출된 특징점 정보이나, 반드시 에에 제한될 필요는 없다. 한편, 메모리는 로봇 청소기를 제어 또는 구동하는 제어 프로그램 및 그에 따른 데이터를 저장한다. 메모 리는 오디오 정보, 영상 정보, 장애물 정보, 위치 정보, 지도 정보 등을 저장할 수 있다. 또, 메모리(18 5)는 주행 패턴과 관련된 정보를 저장할 수 있다. 이동 로봇의 메모리는 통신부를 통해 네트워크 상으로부터 수신한 정보를 저장할 수 있다. 메모리는 입력부로부터 지시를 저장할 수 있다. 메모리는 센싱부로부터 획득한 정보(예를 들어, 필드 데이터)를 저장할 수 있다. 메모리는 상기 필드 데이터를 저장한다. 메모리는 상기 필드 데이터를 임시로 저장하고, 소정의 조건하에 저장된 필드 데 이터를 삭제할 수 있다. 메모리는 후술할 인식 알고리즘을 저장한다. 메모리는 후술할 재인식 알고리즘을 저장한다. 메모리 는 후술할 업데이트 정보를 저장할 수 있다. 상기 메모리는 비휘발성 메모리를 포함할 수 있다. 여기서, 상기 비휘발성 메모리(Non-Volatile Memory, NVM, NVRAM)는 전원이 공급되지 않아도 저장된 정보를 계속 유지할 수 있는 저장 장치로서, 일 예로, 롬(ROM), 플래시 메모리(Flash Memory), 마그네틱 컴퓨터 기억 장치(예를 들어, 하드 디스크, 디스켓 드라이브, 마그네틱 테이프), 광디스크 드라이브, 마그네틱 RAM, PRAM 등일 수 있다. 한편, 통신부는 단말 장치 및/또는 특정 영역 내 위치한 타 기기와 유선, 무선, 위성 통신 방식들 중 하나 의 통신 방식으로 연결되어 신호와 데이터를 송수신한다. 통신부는 특정 영역 내에 위치한 타 기기와 통신할 수 있다. 통신부는 무선 공유기와 통신할 수 있다. 통신부는 이동 단말기와 통신할 수 있다. 통신부는 서버와 통신할 수 있다. 도 6의 Ta를 참고하여, 이동 로봇의 통신부는 무선 공유기와 무선 통신할 수 있다. 도 6의 Tc를 참고하여, 통신부는 이동 단말기(200a)와 무선 통신할 수도 있다. 도시되지는 않았으나, 통신부는 서 버와 직접 무선 통신할 수도 있다. 예를 들어, 통신부는 IEEE 802.11 WLAN, IEEE 802.15 WPAN, UWB, Wi-Fi, Zigbee, Z-wave, Blue-Tooth 등과 같은 무선 통신 기술로 무선 통신하게 구현될 수 있다. 통신부 는 통신하고자 하는 다른 장치 또는 서버의 통신 방식이 무엇인지에 따라 달라질 수 있다. 통신부를 통해 입력부로부터 획득된 정보를 네트워크 상으로 전송할 수 있다. 통신부를 통해 센 싱부로부터 획득된 정보(필드 데이터)를 네트워크 상으로 전송할 수 있다. 이동 로봇의 현재의 동작 상태 정보가, 통신부을 통해 네트워크 상으로 전송될 수 있다. 통신부를 통해 네트워크 상에서 이동 로봇으로 정보를 수신할 수 있고, 이러한 수신된 정보를 근거로 이동 로봇이 제어될 수 있다. 통신부를 통해 네트워크 상에서 이동 로봇으로 수신된 정보(예를 들어, 업데이트 정보)를 근거로, 이동 로봇이 주행 제어를 위한 알고리즘(예를 들어, 인식 알고리즘 및/또 는 재인식 알고리즘)을 업데이트할 수 있다. 도 5를 참고하여, 이동 로봇은 소정의 네트워크를 통해 서버와 통신한다. 통신부는 소정의 네트 워크를 통해 서버와 통신한다. 소정의 네트워크란, 유선 및/또는 무선으로 직접 또는 간접으로 연결된 통 신망을 의미한다. 즉, '통신부는 소정의 네트워크를 통해 서버와 통신한다'는 의미는, 통신부와 서버가 직접적으로 통신하는 경우는 물론, 통신부와 서버가 무선 공유기 등을 매개로 간접 적으로 통신하는 경우까지 포괄하는 의미이다. 상기 네트워크는 와이파이(wi-fi), 이더넷(ethernet), 직비(zigbee), 지-웨이브(z-wave), 블루투스(bluetooth) 등의 기술을 기반으로 하여 구축될 수 있다. 통신부는 소정의 네트워크를 통해 서버로 필드 데이터를 송신할 있다. 서버는 소정의 네트워크 를 통해 통신부로 후술할 업데이트 정보를 송신할 수 있다. 도 6은, 상기 소정의 네트워크의 일 예를 도시한 개념도이다. 이동 로봇, 무선 공유기, 서버 및 이동 단말기들(200a, 200b)을 상기 네트워크에 의해 연결되어, 서로 정보를 송수신할 수 있다. 이 중, 이동 로 봇, 무선 공유기, 이동 단말기들(200a) 등은 집과 같은 건물 내에 배치될 수 있다. 서버는 상기 건물 내에 구현될 수도 있으나, 보다 광범위한 네트워크로서 상기 건물 외에 구현될 수도 있다. 무선 공유기 및 서버는 정해진 통신규약(protocol)에 따라 상기 네트워크와 접속 가능한 통신 모듈을 구비할 수 있다. 이동 로봇의 통신부는 정해진 통신규약(protocol)에 따라 상기 네트워크와 접속 가 능하게 구비된다. 이동 로봇은 상기 네트워크를 통해 서버와 데이터를 교환할 수 있다. 통신부는, 무선 공유기 와 유, 무선으로 데이터 교환을 수행하여, 결과적으로 서버와 데이터 교환을 수행할 수 있다. 본 실 시예는 무선 공유기를 통해서 이동 로봇 및 서버가 서로 통신하는 경우(도 6의 Ta, Tb 참고)이 나, 반드시 이에 제한될 필요는 없다. 도 6의 Ta를 참고하여, 무선 공유기는 이동 로봇과 무선 연결될 수 있다. 도 6의 Tb를 참고하여, 무 선 공유기는 유선 또는 무선 통신을 통해 서버와 연결될 수 있다. 도 6의 Td를 통해, 무선 공유기(40 0)는 이동 단말기(200a)와 무선 연결될 수 있다. 한편, 무선 공유기는, 소정 영역 내의 전자 기기들에, 소정 통신 방식에 의한 무선 채널을 할당하고, 해당 채널을 통해, 무선 데이터 통신을 수행할 수 있다. 여기서, 소정 통신 방식은, WiFi 통신 방식일 수 있다. 무선 공유기는, 소정의 영역 범위 내에 위치한 이동 로봇과 통신할 수 있다. 무선 공유기는, 상 기 소정의 영역 범위 내에 위치한 이동 단말기(200a)와 통신할 수 있다. 무선 공유기는 서버와 통신 할 수 있다. 서버는 인터넷을 통해 접속이 가능하게 구비될 수 있다. 인터넷에 접속된 각종 단말기(200b)로 서버 와 통신할 수 있다. 단말기(200b)는 PC(personal computer), 스마트 폰(smart phone) 등의 이동 단말기(mobile terminal)를 예로 들 수 있다. 서버는 이동 로봇과 소정의 네트워크를 통해 통신한다. 도 6의 Tb를 참고하여, 서버는 무선 공유기와 유무선으로 연결될 수 있다. 도 6의 Tf를 참고하여, 서 버는 이동 단말기(200b)와 직접 무선 연결될 수도 있다. 도시되지는 않았으나, 서버는 이동 로봇 과 직접 통신할 수도 있다. 서버는 프로그램의 처리가 가능한 프로세서를 포함한다. 서버의 기능은 중앙컴퓨터(클라우드)가 수행 할 수도 있으나, 사용자의 컴퓨터 또는 이동 단말기가 수행할 수도 있다. 일 예, 서버는, 이동 로봇 제조자가 운영하는 서버일 수 있다. 다른 예로, 서버는, 공개된 애플 리케이션 스토어 운영자가 운영하는 서버일 수도 있다. 또 다른 예로, 서버는 댁 내에 구비되며, 댁 내 가 전 기기들에 대한 상태 정보를 저장하거나, 댁 내 가전 기기에서 공유되는 컨텐츠를 저장하는 홈 서버일 수도 있다. 서버는, 이동 로봇에 대한 펌웨어 정보, 운전 정보(코스 정보 등)를 저장하고, 이동 로봇에 대 한 제품 정보를 등록할 수 있다. 서버는 머신 러닝(maching learning)을 수행할 수 있다. 서버는 데이터 마이닝(data mining)을 수행 할 수 있다. 서버는 필드 데이터를 이용하여 학습을 수행할 수 있다. 서버는 필드 데이터를 근거로 하여 후술할 업데이트 정보를 생성할 수 있다. 도 6의 Td를 참고하여, 이동 단말기(200a)는 wi-fi 등을 통해 무선 공유기와 무선 연결될 수 있다. 도 6의 Tc를 참고하여, 이동 단말기(200a)는 블루투스 등을 통해 이동 로봇과 직접 무선 연결될 수도 있다. 도 6 의 Tf를 참고하여, 이동 단말기(200b)는 이동 통신 서비스를 통해 서버에 직접 무선 연결될 수도 있다. 상기 네트워크는 추가로 게이트웨이(gateway)(미도시)를 더 포함할 수 있다. 상기 게이트웨이는 이동 로봇(10 0)과 무선 공유기 간의 통신을 매개할 수 있다. 상기 게이트웨이는 무선으로 이동 로봇과 통신할 수 있다. 상기 게이트웨이는 무선 공유기와 통신할 수 있다. 예를 들어, 상기 게이트웨이와 무선 공유기간의 통신은 이더넷(Ethernet) 또는 와이파이(wi-fi)를 기반으로 할 수 있다. 본 설명에서 언급되는 몇가지 용어에 대해 설명하면 다음과 같다. '인식 알고리즘'은, 센싱부에 의해 감지된 정보를 근거로 하여 자율 주행을 수행하기 위한 판단 또는 인식 을 수행하는 알고리즘을 의미한다. 인식 알고리즘은, 입력값을 입력할 때 결과값이 출력되는 알고리즘이다. 상 기 인식 알고리즘은 이동 로봇의 상황을 인식하기 위해 구비된다. 상기 인식 알고리즘은 이동 로봇에 탑재된다. 상기 인식 알고리즘은 업데이트를 시킬 대상이 될 수 있다. '필드 데이터'는, 상기 인식 알고리즘의 상기 입력값을 의미한다. 입력값에서 언급하는 '값'이란 반드시 수치와 관련된 정보를 의미하는 것은 아니다. 여기서, 상기 필드 데이터는 상기 센싱부가 감지한 정보 그 자체일 수도 있고, 상기 센싱부가 감지한 정보에서 소정의 처리를 거친 정보일 수도 있다. 즉, 상기 필드 데이터 는 센싱부가 획득한 정보 또는 센싱부가 획득한 정보에 소정의 처리를 거친 정보일 수 있다. 상기 필 드 데이터는 후술할 재인식 알고리즘의 입력값이 될 수 있다. 복수의 필드 데이터가 생성될 수 있고, 이 경우 복수의 필드 데이터는 상기 인식 알고리즘에 입력되는 입력값 단위로 구분될 수 있다. 예를 들어, 상기 필드 데 이터는 이동 로봇이 감지한 장애물에 대한 데이터일 수 있다. '인식 결과'는, 상기 인식 알고리즘의 상기 결과값을 의미한다. 결과값에서 언급하는 '값'이란 반드시 수치와 관련된 정보를 의미하는 것은 아니다. 상기 인식 결과는 필드 데이터를 근거로 하여 인식 알고리즘을 통해 결정 된다. 예를 들어, 상기 인식 결과는 사물 인식을 위한 사물 분류 정보일 수 있다. '실제값'은, 입력값(필드 데이터)을 근거로 하여 관리자(supervisor)나 매우 정밀한 수퍼(super) 알고리즘를 통 해 결정되는 결과를 의미한다. 여기서, 실제값은 상기 인식 결과와 비교 대상이 될 수 있는 데이터이다. 예를 들어, 상기 인식 결과가 사물 인식을 위한 사물 분류 정보인 경우, 상기 인식 결과와 비교 대상이 되는 실제값 도 사물 분류 정보이다. 상기 인식 알고리즘의 성능이 좋을수록, 같은 필드 데이터를 근거로 얻어진 인식 결과 와 실제값이 같아질 확률이 높아진다. 상기 확률이 높아지도록 상기 인식 알고리즘이 업데이트될 수 있다. 제어부는 상기 필드 데이터를 소정의 인식 알고리즘에 입력하여 인식 결과를 얻어낼 수 있다. (도 12(a) 참고) 일 예로, 상기 필드 데이터는 영상 센서로부터 획득한 영상 정보 또는 영상으로부터 추출된 특징점 정보(예를 들어, 복수의 디스크립터)이고, 상기 인식 결과는 촬영된 영상의 피사체의 종류일 수 있다. 다른 예로, 상기 필드 데이터는 장애물 감지 센서로부터 획득한 정보 또는 이로부터 변환된 정보이고, 상기 인 식 결과는 감지된 장애물의 종류일 수 있다. 또 다른 예로, 상기 필드 데이터는 영상 센서로부터 촬영된 복수의 영상 사이에 발생된 차이 부분과 관련된 정 보이고, 상기 인식 결과는 촬영된 영상의 피사체의 종류나 장애물의 종류일 수 있다. 또 다른 예로, 상기 필드 데이터는 마이크로부터 감지된 소리와 관련된 정보이고, 상기 인식 결과는 사용자의 위치나 사용자의 존재 여부 등에 대한 정보일 수 있다. 제어부는 센싱부의 감지를 통해 대응 필요 상황을 인식할 수 있다. 대응 필요 상황은, 이동 로봇 이 복수의 운전 모드, 모션, 및/또는 기능 중 어느 하나를 선택해야 하는 상황이다. 일 예로, 제어부는 센싱부의 감지에 의해, 이동 로봇의 주행 경로 상에 장애물이 존재하는 것으 로 판단되면, 대응 필요 상황을 인식할 수 있다. 다른 예로, 제어부는 센싱부의 감지에 의해, 구동부의 휠(111a)이 구속된 것으로 판단되면, 대 응 필요 상황을 인식할 수 있다. 또 다른 예로, 제어부는 센싱부의 감지에 의해, 구동부의 휠(111a)이 공회전하는 것으로 판단되 면, 대응 필요 상황을 인식할 수 있다. 또 다른 예로, 제어부는 센싱부의 감지에 의해, 본체의 일 지점이 주행 영역의 바닥으로부터 소 정의 거리 이상 이격된 것으로 판단되면, 대응 필요 상황을 인식할 수 있다. 또 다른 예로, 제어부는 본체가 주행 경로를 이탈한 것으로 판단되면, 대응 필요 상황을 인식할 수 있다. 또 다른 예로, 제어부는 이동 로봇이 소정의 시간 이상 특정 영역(예를 들어, 침대 밑이나 좁은 영역)으로부터 탈출하지 못하는 것으로 판단되면, 대응 필요 상황을 인식할 수 있다. 또 다른 예로, 제어부는 센싱부의 감지에 의해, 이동 로봇이 정지한 상태에서 소정의 시간동안 촬영된 복수의 영상 사이에 유의미한 차이가 검출되는 경우, 대응 필요 상황을 인식할 수 있다. 또 다른 예로, 제어부는 센싱부의 감지에 의해, 본체 주변에서 소리가 발생하는 경우, 대응 필 요 상황을 인식할 수 있다. 상기 대응 필요 상황에서 센싱부에 의해 감지된 정보에 의해 필터 데이터(Ai)가 생성되고, 필터 데이터 (Ai)를 상기 인식 알고리즘에 입력하여 인식 결과(Bi)를 얻어내며, 인식 결과(Bi)를 근거로 하여 복수의 운전 모드, 모션이나 기능 중 어느 하나를 선택할 수 있다. 예를 들어, 제어부는 상기 인식 결과를 근거로 하여 이동 로봇이 장애물에 대한 회피 모션을 수행하도록 제어할 수 있다. 상기 대응 필요 상황에서 인식 결과에 따른 이동 로봇의 제어(운전 모드, 모션, 기능 선택 등)에 대한 예 시들은 다음과 같다. 제어부는 선택된 운전 모드 또는 모션에 따라 구동부를 제어할 수 있다. 일 예로, 제어부는 인식 결과에 근거하여, 이동 로봇의 주행 경로 상에 소정의 제 1그룹에 속하는 장 애물(예를 들어, 가구 또는 벽체)이 존재하는 것으로 판단되면, 상기 장애물을 회피하기 위한 제 1운전 모드를 선택할 수 있다. 다른 예로, 제어부는 인식 결과에 근거하여, 이동 로봇의 주행 경로상에 소정의 제 2그룹에 속하는 장애물(예를 들어, 사용자나 애완 동물)이 존재하는 것으로 판단되면, 이동 로봇의 동작을 일시적으로 정 지시키기 위한 제 2운전 모드를 선택할 수 있다. 또 다른 예로, 제어부는 인식 결과에 근거하여 이동 로봇의 구동이 방해 받는 것으로 판단되면, 이동 로봇의 동작을 일시적으로 정지시키기 위한 제2 운전 모드를 설정할 수 있다. 또 다른 예로, 제어부는 인식 결과에 근거하여, 주행 영역에서 촬영된 영상을 기 등록된 이동 단말기로 전 송할 수 있다. 또 다른 예로, 제어부는, 촬영된 복수의 영상 사이에 발생된 차이 부분에 대한 필드 데이터를 상기 인식 알고리즘에 입력하여 얻은 인식 결과를 근거로, 이동 로봇의 사용자에게 이동 로봇이 위치하는 주행 영역에 대한 모니터링 정보를 제공할 수 있다. 또 다른 예로, 제어부는 인식 결과에 근거하여, 이동 로봇의 주행 경로상에 소정의 제 3그룹에 속하 는 장애물(예를 들어, 보안을 위협하는 물건이나 생명체)이 존재하는 것으로 판단되면, 이동 로봇이 보안 에 대한 경고 기능을 수행하기 위한 제 3운전 모드를 선택할 수 있다. 또 다른 예로, 제어부는 감지된 소리와 관련된 필드 데이터를 상기 인식 알고리즘에 입력하여 얻은 인식 결과에 근거하여, 이동 로봇이 존재하는 주행 영역의 보안을 위협하는 물건이나 생명체가 존재한다고 판단 되면, 이동 로봇이 보안에 대한 경고 기능을 수행하기 위한 제 3운전 모드를 선택할 수 있다. 또 다른 예로, 제어부는 인식 결과에 근거하여, 이동 로봇의 주행 경로상에 소정의 제 4그룹에 속하 는 장애물(예를 들어, 소정 높이 이하의 문턱)이 존재하는 것으로 판단되면, 이동 로봇은 상기 장애물을 넘어가기 위한 제 4운전 모드를 선택할 수 있다. 이하, 도 6 내지 도 13을 참고하여, 본 발명의 실시예들에 따른 이동 로봇의 제어방법 및 이동 로봇의 제어 시 스템을 설명하면 다음과 같다. 상기 제어방법은 제어부 및 서버 중 적어도 어느 하나에 의해 수행될 수 있다. 본 발명은, 상기 제어방법의 각 단계를 구현하는 컴퓨터 프로그램이 될 수도 있고, 상기 제어방법을 구현하기 위한 프로그램이 기록된 기록매체가 될 수도 있다. 상기 ‘기록매체’는 컴퓨터로 판독 가능한 기록매 체를 의미한다. 본 발명은, 하드웨어와 소프트웨어를 모두 포함하는 제어 시스템이 될 수도 있다. 몇 가지 실시예들에서는 단계들에서 언급된 기능들이 순서를 벗어나서 발생하는 것도 가능하다. 예컨대, 잇달아 도시되어 있는 두 개의 단계들은 사실 실질적으로 동시에 수행되는 것도 가능하고 또는 그 단계들이 때때로 해 당하는 기능에 따라 역순으로 수행되는 것도 가능하다. 상기 제어방법은, 상기 필드 데이터를 이동 로봇에 저장된 인식 알고리즘에 입력하여 얻어낸 인식 결과를 근거로 하여 자율 주행을 제어하는 주행 제어 단계를 포함한다. 상기 주행 제어 단계에서, 이동 로봇이 주 행 중 위치하는 환경과 관련된 정보를 감지하여 상기 필드 데이터를 생성한다. 상기 제어방법은, 서버가이동 로봇으로부터 수신한 필드 데이터를 근거로 업데이트 정보를 생성하는 서버 학습 단계를 포함한다. 상기 서버 학습 단계에서, 이동 로봇이 상기 필드 데이터 중 적어도 일부를 서버로 송신한다. 상기 제어방 법은, 이동 로봇이 서버로부터 수신한 업데이트 정보를 근거로 상기 인식 알고리즘을 업데이트하는 업데이트 단계를 포함한다. 상기 업데이트 단계에서, 서버는 상기 업데이트 정보를 이동 로봇으로 송 신한다. 도 7 및 도 9를 참고하여, 본 발명의 제 1실시예에 따른 상기 주행 제어 단계를 설명하면 다음과 같다. 상기 주 행 제어 단계는 이동 로봇에 의해 수행된다. 상기 주행 제어 단계에서, 이동 로봇은 주행 중 이동 로봇이 위치하는 환경과 관련된 정보를 감지한 다(S110). 상기 주행 제어 단계에서, 이동 로봇은 센싱부의 감지를 통해 상기 필드 데이터를 생성된 다(S115). 이 때, 상기 필드 데이터는 메모리에 저장될 수 있다. 이 때, 이동 로봇은, 상기 필드 데 이터를 소정의 인식 알고리즘에 입력하여 인식 결과를 얻어낼 수 있다. 상기 주행 제어 단계에서, 이동 로봇은 상기 필드 데이터를 상기 인식 알고리즘에 입력하여 얻어낸 인식 결과를 근거로 하여 자율 주행을 제어한다. 예를 들어, 이동 로봇이 상기 대응 필요 상황을 인식한 경우, 상기 인식 결과를 근거로 상술한 바와 같이 이동 로봇의 자율 주행이 제어된다. 도 8 및 도 9를 참고하여, 본 발명의 제 1실시예에 따른 상기 서버 학습 단계를 설명하면 다음과 같다. 상기 서 버 학습 단계는 서버에 의해 수행된다. 상기 서버 학습 단계에서, 이동 로봇은 생성된 상기 필드 데이터 중 적어도 일부를 서버로 송신하도 록 제어한다(S120). 이에 따라, 통신부는 상기 네트워크를 통해 상기 서버로 상기 필드 데이터 중 적 어도 일부를 송신한다. 일 예로, 이동 로봇은 생성된 필드 데이터의 전부를 서버로 송신할 수 있다. 다른 예로, 이동 로봇은 생성된 필드 데이터의 일부만 서버로 송신할 수 있다. 여기서, 제어부 는, 생성된 상기 필드 데이터를 선별하여 일부만 서버로 송신하도록 제어할 수 있다. 이에 대한 예시(제 3 실시예)는 후술한다. 이동 로봇의 제어부는 상기 필드 데이터가 상기 서버로 송신(S120)된 후 삭제되도록 제어할 수 있다. 메모리에 임시 저장된 상기 필드 데이터는 상기 과정(S120) 후 삭제된다. 일 예로, 이동 로봇은 생성 된 필드 데이터의 전부를 서버로 송신한 후, 메모리에 저장된 모든 필드 데이터가 삭제된다. 다른 예 로, 이동 로봇은 생성된 필드 데이터의 일부만 서버로 송신한 후, 메모리에 저장된 모든 필드 데이터가 삭제된다. 상기 서버 학습 단계에서, 서버는 이동 로봇이 생성한 필드 데이터를 수집한다(S220). 상기 서버 학 습 단계에서, 서버는 네트워크를 통해 이동 로봇으로부터 필드 데이터를 수신한다. 상기 서버 학습 단계에서, 서버는 업데이트 정보를 생성한다(S230). 서버는 이동 로봇이 송신한 상기 필드 데이터를 근거로 상기 업데이트 정보를 생성한다. 상기 서버 학습 단계에서, 서버는 수집된 필드 데이터를 근거로 하여 인식 알고리즘을 학습할 수 있다 (S231). 서버는 필드 데이터를 근거로 하여 상기 인식 알고리즘을 학습하는 학습엔진이 탑재될 수 있다. 여기서, 서버의 상기 '학습'은, 알려진 다양한 '머신 러닝(machine learning)' 기법을 통해 수행될 수 있다. 예를 들어, 상기 필드 데이터 및 상기 인식 알고리즘을 통해 얻어진 인식 결과와 상기 실제값의 차이시, 상기 업데이트 정보가 생성될 수 있다. 이 때, 상기 업데이트 정보는 상기 인식 결과와 상기 실제값의 차이를 줄이기 위하여 생성된다. 일 예로, 관리자(supervisor)가 상기 실제값을 지도하여, 상기 인식 결과와 상기 실제값을 줄 이는 방향으로 학습을 유도하는 지도(supervised) 학습이 수행될 수 있다. 다른 예로, 딥러닝(deep learning)에 의해 컴퓨터가 스스로 특성을 찾아내고 판별하도록 학습이 수행될 수 있다. 한편, 서버는 수집된 필드데이터를 이용하여 데이터 마이닝(data mining) 기능을 수행할 수도 있다. 서버 는 수집한 필드 데이터를 분석할 수 있다. 서버는 수신한 상기 필드 데이터를 근거로 상기 인식 알고리즘을 학습하여 상기 업데이트 정보를 생성할 수 있다(S232). 서버는, 상기 학습엔진을 통해 상기 업데이트 정보를 생성할 수 있다. 상기 업데이트 정보 는, 상기 인식 알고리즘을 업데이트 하기 위한 정보이다.도 7 및 도 9를 참고하여, 본 발명의 제 1실시예에 따른 상기 업데이트 단계를 설명하면 다음과 같다. 상기 업 데이트 단계는 이동 로봇에 의해 수행된다. 상기 서버 학습 단계에서, 서버는 상기 업데이트 정보를 상기 네트워크를 통해 이동 로봇으로 송신한 다. 서버는 이동 로봇으로부터 수신된 소정의 정보에 근거하여, 이동 로봇에 탑재된 인식 알고리즘 의 버전을 확인할 수 있다. 서버는 확인된 버전에 근거하여, 이동 로봇으로 상기 업데이트 정보의 송 신 여부를 결정할 수 있다. 예를 들어, 상기 업데이트 정보에 의해 업데이트될 인식 알고리즘의 버전이 이동 로 봇에 현재 탑재된 인식 알고리즘의 버전보다 높은 경우에만, 서버는 이동 로봇으로 상기 업데이 트 정보를 송신할 수 있다. 상기 업데이트 단계에서, 이동 로봇은 서버로부터 상기 업데이트 정보를 수신한다(S180). 상기 업데 이트 단계에서, 이동 로봇는 서버로부터 수신한 상기 업데이트 정보를 통해 상기 인식 알고리즘을 업 데이트한다(S190). 제어부는 서버로부터 전송 받은 인식 알고리즘 업데이트 정보를 이용하여, 메모리 에 저장된 인식 알고리즘을 업데이트 시킬 수 있다. 일 예로, 상기 업데이트 정보는 업데이트된 인식 알고리즘을 포함할 수 있다. 상기 업데이트 정보는 업데이트된 인식 알고리즘 자체(프로그램)일 수도 있다. 상기 서버 학습 단계에서, 서버는 수집된 필드 데이터를 이용 하여, 서버에 기저장되어 있는 인식 알고리즘을 업데이트 시키며, 이 때의 서버에서 업데이트된 인식 알고리즘이 상기 업데이트 정보가 될 수 있다. 이 경우, 상기 업데이트 단계에서, 이동 로봇은 서버 로부터 수신한 상기 업데이트된 인식 알고리즘을 이동 로봇의 기저장된 인식 알고리즘과 대체함으로써 업 데이트를 수행할 수 있다. 다른 예로, 상기 업데이트 정보는 인식 알고리즘 자체는 아니지만 기존의 인식 알고리즘에 업데이트를 발생시키 는 정보일 수 있다. 상기 서버 학습 단계에서, 서버는 수집된 필드 데이터를 이용하여 상기 학습 엔진을 구동시키고, 이에 따라 상기 업데이트 정보를 생성할 수 있다. 이 경우, 상기 업데이트 단계에서, 이동 로봇 은 서버로부터 수신한 상기 업데이트 정보에 의해 이동 로봇의 기저장된 인식 알고리즘을 변경 시킴으로써 업데이트를 수행할 수 있다. 이하, 도 10을 참고하여, 본 발명의 제 2실시예에 따른 상기 제어방법 및 상기 제어시스템을 설명하면 다음과 같다. 제 2실시예 중 상기 제 1실시예와 중복되는 내용은 동일 도면 부호로 표기하고, 중복되는 내용의 자세한 설명은 생략한다. 상기 제 2실시예에서, 서버로 필드 데이터를 송신하는 복수의 이동 로봇(100a, 100b)이 구비된다. 도 10에 서는 제 1이동 로봇(100a) 및 제 2이동 로봇(100b)가 구비된 경우를 예로 들어 도시하나, 더 많은 수의 이동 로 봇이 구비되는 것도 물론 가능하다. 제 1이동 로봇(100a)은 상기 주행 제어 단계를 수행한다. 제 1이동 로봇(100a)의 주행 제어 단계에서 제 1이동 로봇(100a)은 필드 데이터를 생성한다(115a). 제 1이동 로봇(100a)은 생성된 필드 데이터의 적어도 일부를 서버 로 송신한다(S120a). 제 2이동 로봇(100b)은 상기 주행 제어 단계를 수행한다. 제 2이동 로봇(100b)의 주행 제어 단계에서 제 2이동 로봇(100b)은 필드 데이터를 생성한다(115b). 제 2이동 로봇(100b)은 생성된 필드 데이터의 적어도 일부를 서버 로 송신한다(S120b). 상기 서버 학습 단계에서, 서버는 복수의 이동 로봇(100a, 100b)으로부터 수신한 상기 필드 데이터를 근거 로 상기 업데이트 정보를 생성한다. 상기 서버 학습 단계에서, 서버는 복수의 이동 로봇(100a, 100b)으로부터 상기 필드 데이터를 수집한다 (S220). 예를 들어, 서버는 복수의 서로 다른 환경에 놓여진 이동 로봇으로부터 각 필드 데이터를 수 신할 수 있다. 상기 서버 학습 단계에서, 서버는 수집된 필드 데이터를 근거로 하여 상기 업데이트 정보를 생성할 수 있 다(S230). 일 예로, 서버는 복수의 이동 로봇(100a, 100b)으로부터 수집된 모든 필드 데이터를 근거로 하여, 복수의 이동 로봇(100a, 100b)의 상기 인식 알고리즘을 일괄적으로 업데이트 시키기 위한 업데이트 정보를 생성할 수있다. 이 경우, 제 2이동 로봇(100b)에서 생성된 필드 데이터가 제 1이동 로봇(100a)의 인식 알고리즘의 업데이 트에 영향을 미치게 된다. 다른 예로, 서버는 복수의 이동 로봇(100a, 100b) 각각의 필드 데이터를 별도로 관리하여, 복수의 이동 로 봇(100a, 100b) 각각의 인식 알고리즘 별로 업데이트 정보를 생성할 수 있다. 이 경우, 제 1이동 로봇(100a)에 서 생성된 필드 데이터는 제 1이동 로봇(100a)의 인식 알고리즘의 업데이트 정보를 생성하기 위해서만 근거로 이용되고, 제 2이동 로봇(100b)의 인식 알고리즘의 업데이트 정보를 생성하기 위해서는 근거로 이용되지 않는다. 상기 업데이트 단계에서, 서버는 복수의 이동 로봇(100a, 100b)에 각각 업데이트 정보를 송신한다(S240a, S240b). 서버는 제 1이동 로봇(100a)에 업데이트 정보를 송신한다(S240a). 서버는 제 2이동 로봇 (100b)에 업데이트 정보를 송신한다(S240b). 복수의 이동 로봇(100a, 100b)은 각각 수신한 업데이트 정보를 통해 각각의 인식 알고리즘을 업데이트 시킨다 (S190a, S190b). 제 1이동 로봇(100a)은 수신한 업데이트 정보를 통해 인식 알고리즘을 업데이트 시킨다 (S190a). 제 2이동 로봇(100b)은 수신한 업데이트 정보를 통해 인식 알고리즘을 업데이트 시킨다(S190b). 이하, 도 11 내지 도 13을 참고하여, 본 발명의 제 3실시예에 따른 상기 제어방법 및 상기 제어시스템을 설명하 면 다음과 같다. 제 3실시예 중 상기 제 1실시예와 중복되는 내용은 동일 도면 부호로 표기하고, 중복되는 내용 의 자세한 설명은 생략한다. 제 3실시예에서, 이동 로봇은 생성한 필드 데이터 중 일부를 선별하여 서버로 전송한다. 이동 로봇 은 필드 데이터마다 송신 대상인진 여부를 판단하여, 송신 대상인 필드 데이터만 서버로 송신한다. 이동 로봇은 서버의 학습에 보다 크게 도움이 될 수 있는 필드 데이터를 송신 대상으로 판단할 수 있 다. 이를 위하여, 이동 로봇에는 인식 알고리즘 및 상기 인식 알고리즘과 별도로 기설정된 소정의 재인식 알고리즘이 탑재된다. 같은 입력값(필드 데이터)에 대한 상기 인식 알고리즘의 결과값(인식 결과)와 상기 재인 식 알고리즘의 결과값(재인식 결과)의 차이가 발생할 경우, 상기 인식 알고리즘 및 상기 재인식 알고리즘 중 적 어도 어느 하나는 업데이트가 필요한 상황이라고 판단한다. 이에 따라, 이동 로봇은 상기 인식 결과와 상 기 재인식 결과가 차이가 나는 입력값(필드 데이터)만 서버로 전송하여, 서버가 상기 입력값(필드 데 이터)를 근거로 상기 인식 알고리즘 및 상기 재인식 알고리즘 중 적어도 하나의 학습을 수행하게 한다. 상기 제 3실시예의 상기 주행 제어 단계에서, 이동 로봇은 주행 중 센싱부를 통한 감지(S110) 후, 필 드 데이터를 생성하고 메모리에 저장한다(S115). 이동 로봇은 복수의 필드 데이터(A1, A2, A3, …, Ap)를 생성한다(S115). (여기서, p는 2이상의 자연수 이다.) 상기 주행 제어 단계에서, 이동 로봇은 생성 된 필드 데이터를 이동 로봇에 탑재된 상기 인식 알고리즘에 입력하여 얻어낸 인식 결과를 근거로 주행을 제어한다(S151). 상기 주행 제어 단계에서, 이동 로봇은 주행 종료 여부를 판단하는 과정(S160)을 더 포함할 수 있다. 상기 과정(S160)에서, 이동 로봇은 소정의 주행 종료 조건의 만족 여부를 판단할 수 있다. 일 예로, 상기 주행 종료 조건은, 이동 로봇의 충전량이 소정치 이하인 조건을 포함할 수 있다. 다른 예로, 상기 주행 종료 조건은, 이동 로봇이 기설정된 주행 코스를 완료한 조건을 포함할 수 있다. 상기 과정(S160)에서 주행이 종료되지 않은 것으로 판단되면 계속해서 상기 주행 제어 단계를 진행할 수 있다. 상기 과정(S160)에서 주행이 종료된 것으로 판단되면, 후술할 검토 단계가 진행될 수 있다. 상기 제 3실시예에 따른 제어방법은, 이동 로봇이 상기 필드 데이터를 소정의 재인식 알고리즘에 입력하여 얻어진 재인식 결과를 상기 인식 결과와 비교하는 검토 단계(S171)를 포함한다. 검토 단계(S171)에서 상기 인식 결과와 상기 재인식 결과의 차이 여부를 판단할 수 있다. '재인식 알고리즘'은, 상기 인식 알고리즘과 달리 별도로 기설정된다. 상기 재인식 알고리즘은, 상기 필드 데이 터를 근거로 하여 상기 인식 결과와 비교 가능한 재인식 결과를 출력하기 위한 알고리즘이다. 상기 재인식 알고 리즘은 상기 인식 알고리즘을 대신하여 이동 로봇의 상황을 인식하는 용도로 이용될 수도 있으나, 본 실시 예에서 상기 재인식 알고리즘은 상기 인식 결과와 차이가 나는 상기 재인식 결과의 유무를 파악하기 위한 용도 로 이용된다. 상기 재인식 알고리즘은 상기 인식 알고리즘에 비해 고성능의 정밀한 알고리즘으로 기설정될 수 있다. 상기 재 인식 알고리즘은 상기 인식 알고리즘에 비해 더 큰 메모리 용량을 차지할 수 있다. 상기 인식 알고리즘의 수행에 따른 인식 결과 출력은 상기 재인식 알고리즘의 수행에 따른 재인식 결과 출력에 비해 더 짧은 시간이 소요 되도록 기설정될 수 있다. 검토 단계(S171)는 상기 주행 제어 단계 후 진행되는 것이 바람직하다. 이에 따라, 보다 정밀도는 떨어지더라도 빠른 처리가 가능한 상기 인식 알고리즘을 이용하여 이동 로봇의 자율 주행을 제어함으로써, 주행시 문제 상황에서 빠른 대응이 가능하다. 또한, 보다 정밀도가 높은 상기 재인식 알고리즘을 이용하여, 상기 인식 알고리즘의 업데이트를 위한 근거 데이터를 효율적으로 선별할 수 있다. 나아가, 오랜 시 간이 걸리는 상기 재인식 알고리즘이 상기 주행 제어 단계 이후 진행됨으로써, 주행 제어를 위한 빠른 대응 처 리가 방해되지 않게 할 수 있다. 도 12를 참고하여, 각각의 필드 데이터(Ai)(D11)를 인식 알고리즘(D13)에 입력하여, 각각의 필드 데이터(Ai)에 대한 각각의 인식 결과(Bi)(D15)를 얻어낼 수 있다. 또한, 각각의 필드 데이터(Ai)(D21)를 재인식 알고리즘 (D23)에 입력하여, 각각의 필드 데이터(Ai)에 대한 각각의 재인식 결과(Ci)(D25)를 얻어낼 수 있다. 여기서, i=1, 2, 3, …, p이고, p는 2이상의 자연수이다. 예를 들어, 어느 한 필드 데이터(A2)를 인식 알고리즘에 입력 하여 인식 결과(B2)를 얻어낼 수 있고, 상기 필드 데이터(A2)를 재인식 알고리즘에 입력하여 재인식 결과(C2)를 얻어낼 수 있다. 제어부는, 주행 종료후 상기 필드 데이터를 상기 재인식 알고리즘에 입력하여 상기 재인식 결과를 얻어낼 수 있다. 제어부는, 상기 필드 데이터를 소정의 재인식 알고리즘에 입력하여 얻어진 재인식 결과(Ci)를 상 기 인식 결과(Bi)와 비교한다. 제어부는, 상기 인식 결과(Bi)와 상기 재인식 결과(Ci)의 차이 여부에 근거하여 상기 필드 데이터를 선별 하여 서버로 송신하도록 제어한다. 이동 로봇은, 상기 인식 결과(Bi)와 상기 재인식 결과(Ci)가 서로 상이 해지는 필드 데이터(Ai)를 서버로 송신할 수 있다(S173). 예를 들어, 인식 결과(B2)와 재인식 결과(C2)가 상이 하면 필드 데이터(A2)는 이동 로봇에서 서버로 송신되고, 인식 결과(B3)와 재인식 결과(C3)가 동일하 면 필드 데이터(A3)은 이동 로봇에서 서버로 송신되지 않는다. 이를 통해, 이동 로봇은 서버 의 학습에 보다 유의미한 필드 데이터를 선별하여 서버로 송신할 수 있다. 이동 로봇이 선별적으로 필드 데이터를 서버로 송신(S173)한 후, 이동 로봇은 기저장된 필드 데 이터를 삭제할 수 있다(S175). 이동 로봇은 상기 인식 결과(Bi)와 상기 재인식 결과(Ci)가 서로 동일해지 는 필드 데이터(Ai)를 삭제할 수 있다. 이동 로봇은 상기 인식 결과(Bi)와 상기 재인식 결과(Ci)가 서로 상이해지는 필드 데이터(Ai)를 서버로 송신한 후 삭제할 수 있다. 도 13을 참고하여, 복수의 필드 데이터 중 서버로의 송신 대상 필드 데이터를 선별하는 예를 보다 자세히 설명하면 다음과 같다. 상기 과정(S115) 후, 각 필드 데이터(Ai) 별로 인식 결과(Bi)와 재인식 결과(Ci)의 차이 여부를 판단하는 과정(S171b)이 진행된다. 여기서, i는 1 내지 p까지의 임의의 자연수를 의미하고, p는 생성된 필드 데이터에 따라 결정되는 2이상의 자연수이다. 상기 과정(S171b)에서 인식 결과(Bi)와 재인식 결과(Ci)가 차이가 있는 것으로 판단되면, 상기 필드 데이터(Ai)는 송신 대상으로 결정된다(S172a). 상기 과정(S171b)에서 인식 결과(Bi)와 재인식 결과(Ci)가 차이가 없는 것으로 판단되면, 상기 필드 데이터(Ai)는 송신 대상이 아닌 것으로 결정된다(S172b). 최초의 상기 과정(S171b) 전에, i값에 1이 대입되어(S171a) 필드 데이터(A1)를 특정하는 과정이 진행된다. 예를 들어, 최초의 상기 과정(S171b)에서 필드 데이터(A1)에 대한 인식 결과(B1)와 재인식 결과(C1)의 차이 여부를 판단하는 과정(S171b)이 진행되고, 그 결과에 따라 상기 필드 데이터(A1)의 송신 대상 여부를 결정한다. 상기 과정(S171b) 후, i값이 p값인지 여부를 판단하는 과정(S171c)이 진행된다. 상기 과정(S171c)에서 i값이 p 값이 아니면, 기존의 i값에 1을 더한 값이 i값이 되는 과정(S171d)이 진행된다. 상기 과정(S171d) 후 상기 과정 (S171b)부터 다시 진행된다. 상기 과정(S171c)에서 i값이 p값이면 모든 필드 데이터의 송신 대상 여부를 결정한 것인바, 필드 데이터의 선별 과정은 종료된다. 제 3실시예에에 따른 상기 서버 학습 단계에서, 서버는 수집된 필드 데이터를 이용하여, 인식 알고리즘 및 재인식 알고리즘 중 적어도 어느 하나를 업데이트 시키기 위한 업데이트 정보를 생성할 수 있다. 일 예로, 서버 의 학습 엔진은 수집된 필드 데이터를 근거로 하여 상기 인식 알고리즘을 학습할 수 있다. 다른 예로, 서 버의 학습 엔진은 필드 수집된 필드 데이터를 근거로 하여 상기 재인식 알고리즘을 학습할 수 있다. 또 다 른 예로, 서버의 학습 엔진은 필드 수집된 필드 데이터를 근거로 하여 상기 인식 알고리즘 및 상기 재인식 알고리즘을 학습할 수 있다. 상기 제 3실시예에 따른 상기 업데이트 단계에서, 이동 로봇은 서버로부터 상기 업데이트 정보를 수 신한다(S180). 상기 업데이트 단계에서, 이동 로봇의 제어부는 수신한 상기 업데이트 정보를 통해 상 기 인식 알고리즘 및 상기 재인식 알고리즘 중 적어도 하나를 업데이트한다(S191). 구체적으로, 이동 로봇(10 0)은 상기 업데이트 정보를 통해, 상기 인식 알고리즘을 업데이트할 수도 있고, 상기 재인식 알고리즘을 업데이 트할 수도 있으며, 상기 인식 알고리즘 및 상기 재인식 알고리즘 모두를 업데이트할 수도 있다."}
{"patent_id": "10-2017-0165377", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일 실시예에 따른 이동 로봇을 도시하는 사시도이다. 도 2는 도 1의 이동 로봇의 평면도이다. 도 3은 도 1의 이동 로봇의 측면도이다. 도 4는 도 1의 이동 로봇의 제어 블록도이다. 도 5는 도 1의 이동 로봇과 서버의 네트워크를 도시한 개념도이다. 도 6은, 도 5의 네트워크의 일 예를 도시한 개념도이다. 도 7은, 본 발명의 제 1실시예에 따른 제어방법을 이동 로봇 기준으로 도시한 순서도이다. 도 8은, 본 발명의 제 1실시예에 따른 제어방법을 서버 기준으로 도시한 순서도이다. 도 9는, 본 발명의 제 1실시예에 따른 제어방법을 이동 로봇과 서버 사이의 통신 과정과 함께 도시한 순서도이다. 도 10은, 본 발명의 제 2실시예에 따른 제어방법을 복수의 이동 로봇(100a, 100b)와 서버 사이의 통신 과 정과 함께 도시한 순서도이다. 도 11은, 본 발명의 제 3실시예에 따른 제어방법을 이동 로봇 기준으로 도시한 순서도이다. 도 12는, 도 11의 인식 알고리즘 및 재인식 알고리즘에 대한 개념도이다. 도 13은, 도 11의 인식 결과 및 재인식 결과의 비교에 따른 송신 대상 필드 데이터의 선별 과정을 구체화한 순 서도이다."}
