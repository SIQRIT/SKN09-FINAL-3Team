{"patent_id": "10-2022-0056799", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0157156", "출원번호": "10-2022-0056799", "발명의 명칭": "증강현실 글래스 장치의 손 거리 추정 방법 및 장치", "출원인": "주식회사 피앤씨솔루션", "발명자": "최치원"}}
{"patent_id": "10-2022-0056799", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "증강현실 글래스 장치(10)에서 각 단계가 수행되며, 싱글 카메라 영상으로부터 손 관절 인식을 통해 손까지의거리를 추정하는, 증강현실 글래스 장치(10)의 손 거리 추정 방법으로서,(1) 상기 증강현실 글래스 장치(10)의 카메라에서 촬영되는 손 영상으로부터 실시간으로 손 관절의 좌표를 추출하는 단계;(2) 상기 단계 (1)에서 추출한 손 관절의 좌표를 사용해 거리 정보가 필요한 기준 손동작을 인식하는 단계;(3) 상기 단계 (2)에서 상기 기준 손동작이 인식된 프레임을 기준 시각으로 설정하는 단계;(4) 상기 기준 시각부터 상기 손 관절의 좌표 중에서 손바닥을 구성하는 관절의 좌표를 이용해 손바닥 면적을계산하는 단계; 및(5) 상기 기준 시각의 손바닥 면적을 기준으로 손바닥 면적의 변화를 통해 손까지의 거리를 추정하는 단계를 포함하는 것을 특징으로 하는, 증강현실 글래스 장치(10)의 손 거리 추정 방법."}
{"patent_id": "10-2022-0056799", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 단계 (4)에서는,손목이 손등과 연결되는 관절 및 각 손가락이 손등과 연결되는 관절의 좌표를 이용해 손바닥 면적을 계산하는것을 특징으로 하는, 증강현실 글래스 장치(10)의 손 거리 추정 방법."}
{"patent_id": "10-2022-0056799", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 단계 (1)에서는, 21개의 손 관절의 좌표를 추출하고,상기 단계 (4)에서는, 상기 21개의 손 관절의 좌표 중 손바닥을 구성하는 7개의 좌표로 상기 손바닥 면적을 계산하는 것을 특징으로 하는, 증강현실 글래스 장치(10)의 손 거리 추정 방법."}
{"patent_id": "10-2022-0056799", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서, 상기 단계 (5)에서는,상기 기준 시각의 손바닥 면적에 대한 현재 시각의 손바닥 면적의 비율을 계산하며, 손바닥 면적의 비율로 손까지의 거리를 추정하는 딥러닝 모델을 사용해, 상기 계산한 비율로부터 손까지의 거리를 추정하는 것을 특징으로하는, 증강현실 글래스 장치(10)의 손 거리 추정 방법."}
{"patent_id": "10-2022-0056799", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서, 상기 단계 (5)에서는,상기 계산한 비율이 0 초과 1 이하의 범위일 때, 상기 손까지의 거리를 추정하는 것을 특징으로 하는, 증강현실글래스 장치(10)의 손 거리 추정 방법.공개특허 10-2023-0157156-3-청구항 6 증강현실 글래스 장치(10)의 싱글 카메라 영상으로부터 손 관절 인식을 통해 손까지의 거리를 추정하는, 증강현실 글래스 장치(10)의 손 거리 추정 장치(100)로서,상기 증강현실 글래스 장치(10)의 카메라에서 촬영되는 손 영상으로부터 실시간으로 손 관절의 좌표를 추출하는좌표 추출부(110);상기 좌표 추출부(110)에서 추출한 손 관절의 좌표를 사용해 거리 정보가 필요한 기준 손동작을 인식하는 손동작 인식부(120);상기 손동작 인식부(120)에서 상기 기준 손동작이 인식된 프레임을 기준 시각으로 설정하는 기준 설정부(130);상기 기준 시각부터 상기 손 관절의 좌표 중에서 손바닥을 구성하는 관절의 좌표를 이용해 손바닥 면적을 계산하는 면적 산출부(140); 및상기 기준 시각의 손바닥 면적을 기준으로 손바닥 면적의 변화를 통해 손까지의 거리를 추정하는 거리 추정부(150)를 포함하는 것을 특징으로 하는, 증강현실 글래스 장치(10)의 손 거리 추정 장치(100)."}
{"patent_id": "10-2022-0056799", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6항에 있어서, 상기 거리 추정부(150)는,상기 기준 시각의 손바닥 면적에 대한 현재 시각의 손바닥 면적의 비율을 계산하며, 손바닥 면적의 비율로 손까지의 거리를 추정하는 딥러닝 모델을 사용해, 상기 계산한 비율로부터 손까지의 거리를 추정하는 것을 특징으로하는, 증강현실 글래스 장치(10)의 손 거리 추정 장치(100)."}
{"patent_id": "10-2022-0056799", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서, 상기 거리 추정부(150)는,상기 계산한 비율이 0 초과 1 이하의 범위일 때, 상기 손까지의 거리를 추정하는 것을 특징으로 하는, 증강현실글래스 장치(10)의 손 거리 추정 장치(100)."}
{"patent_id": "10-2022-0056799", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 증강현실 글래스 장치의 손 거리 추정 방법에 관한 것으로서, 보다 구체적으로는 증강현실 글래스 장 치에서 각 단계가 수행되며, 싱글 카메라 영상으로부터 손 관절 인식을 통해 손까지의 거리를 추정하는, 증강현 실 글래스 장치의 손 거리 추정 방법으로서, 상기 증강현실 글래스 장치의 카메라에서 촬영되는 손 영상으로 (뒷면에 계속)"}
{"patent_id": "10-2022-0056799", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 증강현실 글래스 장치의 손 거리 추정 방법 및 장치에 관한 것으로서, 보다 구체적으로는 증강현실 글래스 장치에서 싱글 카메라 영상으로부터 손 관절 인식을 통해 손까지의 거리를 추정하는 방법 및 장치에 관 한 것이다."}
{"patent_id": "10-2022-0056799", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "디지털 디바이스의 경량화 및 소형화 추세에 따라 다양한 웨어러블 디바이스(wearable device)들이 개발되고 있 다. 이러한 웨어러블 디바이스의 일종인 헤드 마운티드 디스플레이(Head Mounted Display)는 사용자가 머리에 착용하여 멀티미디어 컨텐츠 등을 제공받을 수 있는 각종 디바이스를 의미한다. 여기서 헤드 마운티드 디스플 레이(HMD)는 사용자의 신체에 착용 되어 사용자가 이동함에 따라서 다양한 환경에서 사용자에게 영상을 제공하 게 된다. 이러한 머리 착용형 디스플레이(HMD)는 투과(see-through)형과 밀폐(see-closed)형으로 구분되고 있 으며, 투과형은 주로 증강현실(Augmented Reality, AR)용으로 사용되고, 밀폐형은 주로 가상현실(Virtual Reality, VR)용으로 사용되고 있다. 이러한 머리 착용형 디스플레이 장치는 기존의 터치스크린과 같은 입력 방식을 사용하기 어려우므로, 사용자 상 호작용을 위한 최적화된 입력 방식이 필요하다. 머리 착용형 디스플레이 장치의 증강현실에서 사용할 수 있는 입력 방식으로, HMD에 구비된 버튼이나 HMD와 연결된 별도의 입력 장치, 제스처 인식 등이 있을 수 있다. 그중에서 제스처 인식은, 헤드 마운티드 디스플레이의 증강현실에서 사용할 수 있는 적합한 입력 방식이라고 할 수 있다. 증강현실 글래스에서 구현되는 증강현실, 확장현실(eXpended Reality, XR) 콘텐츠에서 제스처 인식을 사용해 객 체와 상호작용하기 위해서는, 깊이 정보가 포함된 3차원의 손동작을 인식해야 한다. 그러나 일반적인 가시광선 카메라로 제스처를 인식하면 2차원 정보만 획득할 수 있다. 따라서 증강현실 글래스에서 3차원 손동작 인식을 위해서 뎁스 카메라를 이용하기도 한다. 뎁스 카메라로는 IR, ToF 카메라 등을 사용하는데, 이때 사용되는 레이저 광원은 상당한 전력이 소비된다. 그런데 증강현실 글 래스는 머리에 착용하는 특성상 경량화가 중요해 배터리 용량을 크게 늘릴 수 없어서 배터리 용량이 제한되므로, 손동작 인식을 위해 뎁스 카메라를 계속해서 사용하기에는 무리가 있다. 따라서 전력 소비를 최소화하면서도 증강현실 또는 확장현실 콘텐츠에서의 원활한 사용자 상호작용을 위해, 일 반 가시광선 카메라로 3차원 손동작을 인식할 수 있는 기술의 개발이 필요하다. 한편, 본 발명과 관련된 선행기술로, 등록특허 제10-2286018호(발명의 명칭: 손동작을 이용해 마우스 이벤트를 입력하는 착용형 증강현실 장치 및 손동작을 이용한 착용형 증강현실 장치의 마우스 이벤트 입력 방법, 등록일 자: 2021년 07월 29일) 등이 개시된 바 있다."}
{"patent_id": "10-2022-0056799", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 기존에 제안된 방법들의 상기와 같은 문제점들을 해결하기 위해 제안된 것으로서, 카메라에서 촬영되 는 손 영상으로부터 손 관절의 좌표를 추출하고, 손바닥을 구성하는 관절의 좌표를 이용해 손바닥 면적을 계산 하여, 손바닥 면적의 변화를 통해 손까지의 거리를 추정함으로써, 일반 가시광선 카메라의 영상을 이용해 깊이 정보를 획득하고 3차원 손동작을 인식할 수 있으며, 인식된 3차원 손동작을 통해 콘텐츠에서 사용자 상호작용을 할 수 있으므로 전력 소비를 최소화하면서도 원활하게 사용자 상호작용을 할 수 있는, 증강현실 글래스 장치의 손 거리 추정 방법 및 장치를 제공하는 것을 그 목적으로 한다."}
{"patent_id": "10-2022-0056799", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기한 목적을 달성하기 위한 본 발명의 특징에 따른 증강현실 글래스 장치의 손 거리 추정 방법은, 증강현실 글래스 장치에서 각 단계가 수행되며, 싱글 카메라 영상으로부터 손 관절 인식을 통해 손까지의 거리 를 추정하는, 증강현실 글래스 장치의 손 거리 추정 방법으로서, 상기 증강현실 글래스 장치의 카메라에서 촬영되는 손 영상으로부터 실시간으로 손 관절의 좌표를 추출하는 단계; 상기 단계 에서 추출한 손 관절의 좌표를 사용해 거리 정보가 필요한 기준 손동작을 인식하는 단계; 상기 단계 에서 상기 기준 손동작이 인식된 프레임을 기준 시각으로 설정하는 단계; 상기 기준 시각부터 상기 손 관절의 좌표 중에서 손바닥을 구성하는 관절의 좌표를 이용해 손바닥 면적을 계산하는 단계; 및 상기 기준 시각의 손바닥 면적을 기준으로 손바닥 면적의 변화를 통해 손까지의 거리를 추정하는 단계를 포 함하는 것을 그 구성상의 특징으로 한다. 바람직하게는, 상기 단계 에서는, 손목이 손등과 연결되는 관절 및 각 손가락이 손등과 연결되는 관절의 좌표를 이용해 손바닥 면적을 계산할 수 있다. 바람직하게는, 상기 단계 에서는, 21개의 손 관절의 좌표를 추출하고, 상기 단계 에서는, 상기 21개의 손 관절의 좌표 중 손바닥을 구성하는 7개의 좌표로 상기 손바닥 면적을 계 산할 수 있다. 바람직하게는, 상기 단계 에서는, 상기 기준 시각의 손바닥 면적에 대한 현재 시각의 손바닥 면적의 비율을 계산하며, 손바닥 면적의 비율로 손까 지의 거리를 추정하는 딥러닝 모델을 사용해, 상기 계산한 비율로부터 손까지의 거리를 추정할 수 있다. 더욱 바람직하게는, 상기 단계 에서는, 상기 계산한 비율이 0 초과 1 이하의 범위일 때, 상기 손까지의 거리를 추정할 수 있다. 상기한 목적을 달성하기 위한 본 발명의 특징에 따른 증강현실 글래스 장치의 손 거리 추정 장치는, 증강현실 글래스 장치의 싱글 카메라 영상으로부터 손 관절 인식을 통해 손까지의 거리를 추정하는, 증강현실 글래스 장치의 손 거리 추정 장치로서, 상기 증강현실 글래스 장치의 카메라에서 촬영되는 손 영상으로부터 실시간으로 손 관절의 좌표를 추출하는 좌 표 추출부; 상기 좌표 추출부에서 추출한 손 관절의 좌표를 사용해 거리 정보가 필요한 기준 손동작을 인식하는 손동작 인 식부; 상기 손동작 인식부에서 상기 기준 손동작이 인식된 프레임을 기준 시각으로 설정하는 기준 설정부; 상기 기준 시각부터 상기 손 관절의 좌표 중에서 손바닥을 구성하는 관절의 좌표를 이용해 손바닥 면적을 계산 하는 면적 산출부; 및 상기 기준 시각의 손바닥 면적을 기준으로 손바닥 면적의 변화를 통해 손까지의 거리를 추정하는 거리 추정부를 포함하는 것을 그 구성상의 특징으로 한다. 바람직하게는, 상기 거리 추정부는, 상기 기준 시각의 손바닥 면적에 대한 현재 시각의 손바닥 면적의 비율을 계산하며, 손바닥 면적의 비율로 손까 지의 거리를 추정하는 딥러닝 모델을 사용해, 상기 계산한 비율로부터 손까지의 거리를 추정할 수 있다. 더욱 바람직하게는, 상기 거리 추정부는, 상기 계산한 비율이 0 초과 1 이하의 범위일 때, 상기 손까지의 거리를 추정할 수 있다."}
{"patent_id": "10-2022-0056799", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명에서 제안하고 있는 증강현실 글래스 장치의 손 거리 추정 방법 및 장치에 따르면, 카메라에서 촬영되는 손 영상으로부터 손 관절의 좌표를 추출하고, 손바닥을 구성하는 관절의 좌표를 이용해 손바닥 면적을 계산하여, 손바닥 면적의 변화를 통해 손까지의 거리를 추정함으로써, 일반 가시광선 카메라의 영상을 이용해 깊이 정보를 획득하여 3차원 손동작을 인식할 수 있으며, 인식된 3차원 손동작을 통해 콘텐츠에서 사용자 상호작용을 할 수 있으므로 전력 소비를 최소화하면서도 원활하게 사용자 상호작용을 할 수 있다."}
{"patent_id": "10-2022-0056799", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 첨부된 도면을 참조하여 본 발명이 속하는 기술분야에서 통상의 지식을 가진 자가 본 발명을 용이하게 실 시할 수 있도록 바람직한 실시예를 상세히 설명한다. 다만, 본 발명의 바람직한 실시예를 상세하게 설명함에 있어, 관련된 공지 기능 또는 구성에 대한 구체적인 설명이 본 발명의 요지를 불필요하게 흐릴 수 있다고 판단 되는 경우에는 그 상세한 설명을 생략한다. 또한, 유사한 기능 및 작용을 하는 부분에 대해서는 도면 전체에 걸쳐 동일한 부호를 사용한다. 덧붙여, 명세서 전체에서, 어떤 부분이 다른 부분과 ‘연결’ 되어 있다고 할 때, 이는 ‘직접적으로 연결’ 되 어 있는 경우뿐만 아니라, 그 중간에 다른 소자를 사이에 두고 ‘간접적으로 연결’ 되어 있는 경우도 포함한다. 또한, 어떤 구성요소를 ‘포함’ 한다는 것은, 특별히 반대되는 기재가 없는 한 다른 구성요소를 제 외하는 것이 아니라 다른 구성요소를 더 포함할 수 있다는 것을 의미한다. 도 1은 본 발명의 일실시예에 따른 증강현실 글래스 장치의 손 거리 추정 장치의 구성을 도시한 도면이다. 도 1에 도시된 바와 같이, 본 발명의 일실시예에 따른 증강현실 글래스 장치의 손 거리 추정 장치는, 증강 현실 글래스 장치의 싱글 카메라 영상으로부터 손 관절 인식을 통해 손까지의 거리를 추정하는, 증강현실 글래 스 장치의 손 거리 추정 장치로서, 증강현실 글래스 장치의 카메라에서 촬영되는 손 영상으로부터 실시간 으로 손 관절의 좌표를 추출하는 좌표 추출부; 좌표 추출부에서 추출한 손 관절의 좌표를 사용해 거 리 정보가 필요한 기준 손동작을 인식하는 손동작 인식부; 손동작 인식부에서 기준 손동작이 인식된 프레임을 기준 시각으로 설정하는 기준 설정부; 기준 시각부터 손 관절의 좌표 중에서 손바닥을 구성하는 관절의 좌표를 이용해 손바닥 면적을 계산하는 면적 산출부; 및 기준 시각의 손바닥 면적을 기준으로 손바 닥 면적의 변화를 통해 손까지의 거리를 추정하는 거리 추정부를 포함하여 구성될 수 있다. 보다 구체적으로, 거리 추정부는, 기준 시각의 손바닥 면적에 대한 현재 시각의 손바닥 면적의 비율을 계 산하며, 손바닥 면적의 비율로 손까지의 거리를 추정하는 딥러닝 모델을 사용해, 계산한 비율로부터 손까지의 거리를 추정할 수 있다. 또한, 거리 추정부는, 계산한 비율이 0 초과 1 이하의 범위일 때, 손까지의 거리 를 추정할 수 있다.도 2는 본 발명의 일실시예에 따른 증강현실 글래스 장치의 손 거리 추정 장치를 포함하는 증강현실 글래스 장치의 전체 구성을 도시한 도면이다. 도 2에 도시된 바와 같이, 본 발명의 일실시예에 따른 증강 현실 글래스 장치는, 손 거리 추정 장치, 카메라부 및 광학 디스플레이부를 포함하여 구성될 수 있다. 카메라부는, 착용자의 시야 방향을 향하도록 구비된 일반 가시광선 카메라로 구성될 수 있다. 보다 구체 적으로, 카메라부는 증강현실 글래스 장치의 전면에서 착용자의 손을 촬영해 손 영상을 획득할 수 있 다. 여기서, 카메라부는 일반 가시광선 카메라로 구성되므로 손 영상은 일반적인 2차원 영상이며, 복수의 프레임으로 구성되는 동영상 형태일 수 있다. 카메라부에서 획득한 손 영상은 손 거리 추정 장치에 전달되어, 손 영상에 촬영된 손까지의 거리를 추정할 수 있으며, 이를 기초로 깊이 정보(증강현실 글래스 장치 에서 손까지의 거리)가 반영된 3차원 손동작을 인식하고, 객체와 사용자의 상호작용에 적용할 수 있다. 광학 디스플레이부는, 착용자의 양안의 전방에 배치되고, 디스플레이에서 출력되는 영상 광의 적어도 일부를 착용자의 눈 방향으로 전달하여 착용자에게 증강현실을 제공할 수 있다. 즉, 광학 디스플레이부는 증강현실 글래스 장치의 AR 또는 XR(eXtended Reality, 확장 현실) 글라스에 해당하는 구성으로서, 도 2에 도시된 바와 같이 디스플레이 및 광학계를 포함하여 구성될 수 있다. 디스플레이는, 영상 정보가 착용자에게 제공될 수 있도록 영상 광을 출력할 수 있다. 보다 구체적으로, 디스플레이는, 영상 정보가 착용자에게 제공될 수 있도록, 이하에서 상세히 설명할 광학계에 결합해, 광학계에 의해 착용자의 눈 방향으로 전달되는 영상 광을 출력하며, 양안 디스플레이를 위해 한 쌍의 디스플레이로 구성될 수 있다. 디스플레이는 OLED, LCoS(Liquid Crystal on Silicon) 등 다양하게 구성될 수 있다. 광학계는, 증강현실 글래스 장치를 착용한 착용자의 양안의 전방에 배치되어 실제 세계의 광과 영상 광의 결합에 의한 증강현실을 제공할 수 있다. 보다 구체적으로, 광학계는, 착용자의 시야를 통한 실제 세계(real world)의 광의 적어도 일부를 투과시키고, 디스플레이에서 출력되는 영상 광을 착용자의 눈 방 향으로 전달하여 증강현실을 제공할 수 있다. 즉, 광학계는 증강현실 글래스 장치를 착용한 착용자가 증강현실을 경험할 수 있도록 구성될 수 있다. 또한, 광학계는 복수의 렌즈와 미러 등으로 구성되며 다양한 방식으로 구현될 수 있는데, 예를 들어 광학 회절 방식, 빔 스플리터 방식, 핀 미러 방식 등으로 구현될 수 있다. 도 3은 본 발명의 일실시예에 따른 증강현실 글래스 장치의 손 거리 추정 방법의 흐름을 도시한 도면이다. 도 3에 도시된 바와 같이, 본 발명의 일실시예에 따른 증강현실 글래스 장치의 손 거리 추정 방법은, 증강 현실 글래스 장치에서 각 단계가 수행되며, 싱글 카메라 영상으로부터 손 관절 인식을 통해 손까지의 거리 를 추정하는, 증강현실 글래스 장치의 손 거리 추정 방법으로서, 손 영상으로부터 실시간으로 손 관절의 좌 표를 추출하는 단계(S110), 거리 정보가 필요한 기준 손동작을 인식하는 단계(S120), 기준 손동작이 인식된 프 레임을 기준 시각으로 설정하는 단계(S130), 손바닥을 구성하는 관절의 좌표를 이용해 손바닥 면적을 계산하는 단계(S140) 및 손바닥 면적의 변화를 통해 손까지의 거리를 추정하는 단계(S150)를 포함하여 구현될 수 있다. 도 4는 본 발명의 일실시예에 따른 증강현실 글래스 장치의 손 거리 추정 방법의 알고리즘 구조를 도시한 도면이다. 이하에서는, 도 3 및 도 4를 참조하여 본 발명의 일실시예에 따른 증강현실 글래스 장치의 손 거리 추정 방법의 각 단계에 대해 상세히 설명하도록 한다.단계 S110에서는, 증강현실 글래스 장치의 카메라에서 촬영되는 손 영상으로부터 실시간으로 손 관절의 좌 표를 추출할 수 있다. 보다 구체적으로, 도 4에 도시된 바와 같이, 단계 S110에서는 특징 맵(feature Map)을 추출하는 인공지능 모델인 Base Net을 이용해 카메라부에서 촬영된 손 영상으로부터 특징 맵을 추출하고, 특징 맵에서 키-포인트를 추출하는 인공지능 모델인 Keypoints Net에 추출한 특징 맵을 입력해 손 관절의 좌표 를 추출할 수 있다. 여기서, Base Net으로는 ResNet, Inception, MobileNet 등을 사용할 수 있다. 또한, Keypoints Net은 콘볼루션 레이어(Convolution layer)와 덴스 레이어(Dense layer)의 조합으로 손을 구성하는 21개의 (x,y) 좌표를 도출하는 회귀모델로 구성할 수 있다. 이때, Base Net과 Keypoints Net을 통합 학습하여, 하나의 손 관절 추출 모델로 구성할 수 있다. 도 5는 본 발명의 일실시예에 따른 증강현실 글래스 장치의 손 거리 추정 방법의 단계 S110에서 좌표를 추 출하는 손 관절을 나타낸 도면이다. 도 5에 도시된 바와 같이, 본 발명의 일실시예에 따른 증강현실 글래스 장 치의 손 거리 추정 방법의 단계 S110에서는, 21개의 손 관절의 좌표를 추출할 수 있다. 단계 S120에서는, 단계 S110에서 추출한 손 관절의 좌표를 사용해 거리 정보가 필요한 기준 손동작을 인식할 수 있다. 즉, 단계 S120에서는, 단계 S110에서 추출한 21개의 손 관절 좌표를 Classification Net에 입력해 손동 작을 분류함으로써, 손 영상에 촬영된 손의 모습이 미리 설정된 기준 손동작에 해당하는지를 판단할 수 있다. 본 발명에서는 손 거리를 계속 추정하는 것이 아니고, 착용자가 특정한 기준 손동작을 취했을 때 손 거리를 추 정할 수 있다. 여기서, 기준 손동작은 깊이 정보(손까지의 거리 정보)가 필요한 제스처의 시작이 되는 손동작 으로, 증강현실 또는 확장현실 콘텐츠에서 착용자가 객체와의 인터랙션을 위해 객체 방향으로 손을 움직이는 시 작 동작일 수 있으며, 그 구체적인 손동작은 미리 설정될 수 있다. 예를 들어, 착용자는 손등이 보이도록 손을 펼쳐서 눈앞에 들고 미리 정해진 시간 동안 바라보는 것으로 기준 손동작을 취할 수 있다. 다만, 기준 손동작 은 인터랙션 종류, 사용자 설정 등에 따라 다양할 수 있다. 단계 S130에서는, 단계 S120에서 기준 손동작이 인식된 프레임을 기준 시각으로 설정할 수 있다. 즉, 단계 S120에서 기준 손동작이 인식되면 손까지의 거리 추정이 필요한 제스처에 해당하므로, 단계 S130에서는 기준 손 동작을 인식한 순간을 거리 추정을 위한 기준으로 설정할 수 있다. 단계 S140에서는, 기준 시각부터 손 관절의 좌표 중에서 손바닥을 구성하는 관절의 좌표를 이용해 손바닥 면적 을 계산할 수 있다. 즉, 단계 S130에서 기준 손동작을 인식한 다음, 손이 깊이 방향으로 움직임에 따라 손바닥 면적을 계산할 수 있다. 카메라부에서는, 증강현실 글래스 장치로부터 가까운 손은 크게 촬영되고 멀어질수록 손의 크기는 작 게 촬영된다. 또한, 도 5에 도시된 바와 같은 관절의 좌표 중에서, 손가락 부분은 손동작에 따라 변화가 심하 지만, 손바닥에 해당하는 포인트는 동작 변화에 덜 민감하다. 이러한 특성을 이용해, 손바닥 면적의 비율로 증 강현실 글래스 장치에서 손까지의 거리를 추정하는 딥러닝 모델을 학습을 통해 생성할 수 있다. 이를 위해, 단계 S140에서는, 손목이 손등과 연결되는 관절 및 각 손가락이 손등과 연결되는 관절의 좌표를 이 용해 손바닥 면적을 계산할 수 있다. 즉, 단계 S140에서는, 도 5에 도시된 바와 같은 21개의 관절 중에서, 손 바닥을 구성하는 0, 1, 2, 5, 9, 13, 17의 7개의 관절의 좌표로 손바닥의 면적을 계산할 수 있다. 도 6은 본 발명의 일실시예에 따른 증강현실 글래스 장치의 손 거리 추정 방법의 단계 S140에서 계산하는 손바닥 면적을 예를 들어 도시한 도면이다. 도 6에 도시된 바와 같이, 본 발명의 일실시예에 따른 증강현실 글 래스 장치의 손 거리 추정 방법의 단계 S140에서는, 기준 손동작에 대해 손바닥을 구성하는 7개의 관절의좌표로 손바닥을 구성하고(빨간색 다각형), 영상처리 기법으로 면적을 도출할 수 있다. 단계 S150에서는, 기준 시각의 손바닥 면적을 기준으로 손바닥 면적의 변화를 통해 손까지의 거리를 추정할 수 있다. 보다 구체적으로, 단계 S150에서는, 기준 시각의 손바닥 면적에 대한 현재 시각의 손바닥 면적의 비율을 계산하며, 손바닥 면적의 비율로 손까지의 거리를 추정하는 딥러닝 모델을 사용해, 계산한 비율로부터 손까지의 거리를 추정할 수 있다. 즉, 단계 S150에서는, 기준 손동작이 인식된 기준 시각의 손바닥 면적(Area of Ref. Palm)을 분모로 하고, 기준 시각 이후에 손을 깊이 방향으로 움직이면 움직인 후 현재의 손바닥 면적(Area of Cur. Palm)을 분자로 하여, 다음 수학식 1과 같이 비율을 계산할 수 있다. 수학식 1"}
{"patent_id": "10-2022-0056799", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "item": 2, "content": "도 7은 본 발명의 일실시예에 따른 증강현실 글래스 장치의 손 거리 추정 방법의 단계 S150에서, 손바닥 면 적의 변화를 예를 들어 도시한 도면이다. 도 7에 도시된 바와 같이, 본 발명의 일실시예에 따른 증강현실 글래 스 장치의 손 거리 추정 방법의 단계 S150에서는, 착용자가 눈앞에서 기준 손동작을 취한 다음 손을 깊이 방향으로 멀리 움직이는 제스처를 취할 때, 도 7의 좌측에 도시된 바와 같은 기준 시각의 손바닥 면적과, 도 7 의 우측에 도시한 바와 같은 움직인 후 현재 시각의 손바닥 면적의 비율을 계산할 수 있다. 이때, 계산된 비율 은 0 초과 1 이하의 범위일 수 있다. 한편, 단계 S150에서는, 계산한 비율이 0 초과 1 이하의 범위일 때, 손까지의 거리를 추정할 수 있다. 도 8은 본 발명의 일실시예에 따른 증강현실 글래스 장치의 손 거리 추정 방법에서, 손동작을 활용한 증강현실 글 래스 장치의 제어를 설명하기 위해 도시한 도면이다. 도 8에 도시된 바와 같이, 본 발명의 일실시예에 따 른 증강현실 글래스 장치의 손 거리 추정 방법을 이용해 증강현실 또는 확장현실 콘텐츠에서 사용자 인터랙 션을 구현하기 위해서는, 착용자의 손이 객체와 가까워져야 한다. 즉, 도 8은 시간에 따라 맨 위의 그림에서 아래 그림으로 객체와 손이 점점 가까워지는 것을 도시한 것으로, 대부분 사용자 인터랙션이 이 같은 경우에 발 생하게 된다. 본 발명에서는 추정된 손 거리의 정확성을 높이기 위해, 도 7 및 도 8에 도시된 바와 같이 착용 자가 눈앞에서 기준 손동작을 취한 다음 손이 눈앞에서 멀어져 객체에 접근할 때(손바닥 면적의 비율이 0 초과 1 이하의 범위일 때)만 단계 S150에서 손까지의 거리를 추정할 수 있다. 한편, 단계 S150에서는, 딥러닝 기반으로 학습된 거리 추정 모델에 단계 S140에서 계산된 비율을 입력하고, 거 리 추정 모델에서 출력되는 손까지의 거리를 예측할 수 있다. 예측된 손까지의 거리는 깊이 정보로서 단계 S110에서 추출된 손 관절의 좌표와 결합해 3차원 손동작을 인식할 수 있다. 전술한 바와 같이, 본 발명에서 제안하고 있는 증강현실 글래스 장치의 손 거리 추정 방법 및 장치에 따르 면, 카메라에서 촬영되는 손 영상으로부터 손 관절의 좌표를 추출하고, 손바닥을 구성하는 관절의 좌표를 이용 해 손바닥 면적을 계산하여, 손바닥 면적의 변화를 통해 손까지의 거리를 추정함으로써, 일반 가시광선 카메라 의 영상을 이용해 깊이 정보를 획득하여 3차원 손동작을 인식할 수 있으며, 인식된 3차원 손동작을 통해 콘텐츠 에서 사용자 상호작용을 할 수 있으므로 전력 소비를 최소화하면서도 원활하게 사용자 상호작용을 할 수 있다.한편, 본 발명은 다양한 통신 단말기로 구현되는 동작을 수행하기 위한 프로그램 명령을 포함하는 컴퓨터에서 판독 가능한 매체를 포함할 수 있다. 예를 들어, 컴퓨터에서 판독 가능한 매체는, 하드 디스크, 플로피 디스크 및 자기 테이프와 같은 자기 매체(magnetic media), CD_ROM, DVD와 같은 광기록 매체(optical media), 플롭티 컬 디스크(floptical disk)와 같은 자기-광 매체(magneto-optical media) 및 롬(ROM), 램(RAM), 플래시 메모리 등과 같은 프로그램 명령을 저장하고 수행하도록 특별히 구성된 하드웨어 장치를 포함할 수 있다. 이와 같은 컴퓨터에서 판독 가능한 매체는 프로그램 명령, 데이터 파일, 데이터 구조 등을 단독으로 또는 조합 하여 포함할 수 있다. 이때, 컴퓨터에서 판독 가능한 매체에 기록되는 프로그램 명령은 본 발명을 구현하기 위 하여 특별히 설계되고 구성된 것들이거나 컴퓨터 소프트웨어 당업자에게 공지되어 사용 가능한 것일 수도 있다. 예를 들어, 컴파일러에 의해 만들어지는 것과 같은 기계어 코드뿐만 아니라 인터프리터 등을 사용해서 컴퓨터에 의해 실행될 수 있는 고급 언어 코드를 포함할 수 있다."}
{"patent_id": "10-2022-0056799", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "이상 설명한 본 발명은 본 발명이 속한 기술분야에서 통상의 지식을 가진 자에 의하여 다양한 변형이나 응용이 가능하며, 본 발명에 따른 기술적 사상의 범위는 아래의 특허청구범위에 의하여 정해져야 할 것이다."}
{"patent_id": "10-2022-0056799", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일실시예에 따른 증강현실 글래스 장치의 손 거리 추정 장치의 구성을 도시한 도면. 도 2는 본 발명의 일실시예에 따른 증강현실 글래스 장치의 손 거리 추정 장치를 포함하는 증강현실 글래스 장 치의 전체 구성을 도시한 도면. 도 3은 본 발명의 일실시예에 따른 증강현실 글래스 장치의 손 거리 추정 방법의 흐름을 도시한 도면. 도 4는 본 발명의 일실시예에 따른 증강현실 글래스 장치의 손 거리 추정 방법의 알고리즘 구조를 도시한 도면. 도 5는 본 발명의 일실시예에 따른 증강현실 글래스 장치의 손 거리 추정 방법의 단계 S110에서 좌표를 추출하 는 손 관절을 나타낸 도면. 도 6은 본 발명의 일실시예에 따른 증강현실 글래스 장치의 손 거리 추정 방법의 단계 S140에서 계산하는 손바 닥 면적을 예를 들어 도시한 도면. 도 7은 본 발명의 일실시예에 따른 증강현실 글래스 장치의 손 거리 추정 방법의 단계 S150에서, 손바닥 면적의 변화를 예를 들어 도시한 도면. 도 8은 본 발명의 일실시예에 따른 증강현실 글래스 장치의 손 거리 추정 방법에서, 손동작을 활용한 증강현실 글래스 장치의 제어를 설명하기 위해 도시한 도면."}
