{"patent_id": "10-2021-0112501", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0030366", "출원번호": "10-2021-0112501", "발명의 명칭": "로봇 및 그 제어 방법", "출원인": "삼성전자주식회사", "발명자": "강성민"}}
{"patent_id": "10-2021-0112501", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "로봇에 있어서,이미지 센서;구동부;적어도 하나의 인스트럭션을 저장하는 메모리; 및프로세서;를 포함하고,상기 프로세서는,상기 이미지 센서가 촬영한 제1 이미지를 획득하고,상기 제1 이미지를 오브젝트 인식 모델에 입력하여 상기 제1 이미지에 포함된 오브젝트에 대한 제1 식별 정보및 상기 제1 식별 정보의 제1 신뢰도를 포함하는 제1 정보를 획득하고,상기 로봇이 상기 오브젝트에 접근하도록 상기 구동부를 제어하고,상기 로봇이 상기 오브젝트에 접근하는 동안 상기 이미지 센서가 촬영한 제2 이미지를 획득하고,상기 제2 이미지를 상기 오브젝트 인식 모델에 입력하여 상기 오브젝트에 대한 제2 식별 정보 및 상기 제2 식별정보의 제2 신뢰도를 포함하는 제2 정보를 획득하고,상기 제1 정보 및 상기 제2 정보를 비교하여 상기 제1 정보에 에러가 존재하는지 판단하고,상기 판단 결과에 기초하여 상기 로봇의 동작을 제어하는 로봇."}
{"patent_id": "10-2021-0112501", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1 항에 있어서,상기 프로세서는,상기 제1 신뢰도가 상기 제2 신뢰도보다 크면, 상기 제1 정보에 에러가 존재한다고 판단하는로봇."}
{"patent_id": "10-2021-0112501", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1 항에 있어서,상기 프로세서는,상기 제1 식별 정보와 상기 제2 식별 정보가 상이하면, 상기 제1 정보에 에러가 존재한다고 판단하는로봇."}
{"patent_id": "10-2021-0112501", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1 항에 있어서,상기 프로세서는,상기 제1 정보에 에러가 존재하는 것으로 판단되면, 상기 에러에 관한 정보를 상기 메모리에 저장하고,상기 에러에 관한 정보는, 공개특허 10-2023-0030366-3-상기 제1 이미지, 상기 제1 이미지가 촬영된 제1 시점(time point)에서 상기 로봇의 제1 위치 정보 및 제1 방향정보를 포함하는 로봇."}
{"patent_id": "10-2021-0112501", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4 항에 있어서,상기 프로세서는,상기 이미지 센서가 촬영한 제3 이미지를 획득하고,상기 제3 이미지를 상기 오브젝트 인식 모델에 입력하여 상기 제3 이미지에 포함된 오브젝트에 대한 제3 식별정보 및 상기 제3 식별 정보의 제3 신뢰도를 포함하는 제3 정보를 획득하고,상기 제3 정보 및 상기 에러에 관한 정보에 기초하여 상기 로봇의 동작을 제어하는 로봇."}
{"patent_id": "10-2021-0112501", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5 항에 있어서,상기 프로세서는,상기 제3 신뢰도가 기설정된 값보다 크면, 상기 제3 이미지에 포함된 오브젝트를 향해 이동하도록 상기 구동부를 제어하는로봇."}
{"patent_id": "10-2021-0112501", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6 항에 있어서, 상기 프로세서는,상기 제3 이미지가 촬영된 제3 시점에서 상기 로봇의 제3 위치 정보 및 제3 방향 정보를 획득하고, 상기 제1 위치 정보, 상기 제1 방향 정보, 상기 제3 위치 정보 및 상기 제3 방향 정보에 기초하여 상기 제1 이미지가 촬영된 장소가 상기 제3 이미지가 촬영된 장소에 대응되는지 판단하는로봇."}
{"patent_id": "10-2021-0112501", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7 항에 있어서,상기 프로세서는,상기 제1 위치 정보 및 상기 제3 위치 정보의 차이가 임계 값 이내이면, 상기 제1 이미지 및 상기 제3 이미지의유사도를 판단하고,상기 유사도가 임계값보다 크면, 상기 기설정된 값을 증가시키는로봇."}
{"patent_id": "10-2021-0112501", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8 항에 있어서,상기 프로세서는,상기 제1 이미지 및 상기 제3 이미지를 유사도 판단 모델에 입력하여 상기 제1 이미지 및 상기 제3 이미지의 유사도를 판단하는공개특허 10-2023-0030366-4-로봇."}
{"patent_id": "10-2021-0112501", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "이미지 센서를 포함하는 로봇의 제어 방법에 있어서,상기 이미지 센서가 촬영한 제1 이미지를 획득하는 단계;상기 제1 이미지를 오브젝트 인식 모델에 입력하여 상기 제1 이미지에 포함된 오브젝트에 대한 제1 식별 정보및 상기 제1 식별 정보의 제1 신뢰도를 포함하는 제1 정보를 획득하는 단계;상기 오브젝트에 접근하도록 상기 로봇을 제어하는 단계;상기 로봇이 상기 오브젝트에 접근하는 동안 상기 이미지 센서가 촬영한 제2 이미지를 획득하는 단계;상기 제2 이미지를 상기 오브젝트 인식 모델에 입력하여 상기 오브젝트에 대한 제2 식별 정보 및 상기 제2 식별정보의 제2 신뢰도를 포함하는 제2 정보를 획득하는 단계;상기 제1 정보 및 상기 제2 정보를 비교하여 상기 제1 정보에 에러가 존재하는지 판단하는 단계; 및상기 판단 결과에 기초하여 상기 로봇의 동작을 제어하는 단계;를 포함하는 제어 방법."}
{"patent_id": "10-2021-0112501", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제10 항에 있어서,상기 판단하는 단계는,상기 제1 신뢰도가 상기 제2 신뢰도보다 크면, 상기 제1 정보에 에러가 존재한다고 판단하는제어 방법."}
{"patent_id": "10-2021-0112501", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제10 항에 있어서,상기 판단하는 단계는,상기 제1 식별 정보와 상기 제2 식별 정보가 상이하면, 상기 제1 정보에 에러가 존재한다고 판단하는제어 방법."}
{"patent_id": "10-2021-0112501", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제10 항에 있어서,상기 제1 정보에 에러가 존재하는 것으로 판단되면, 상기 에러에 관한 정보를 상기 메모리에 저장하는 단계;를더 포함하고,상기 에러에 관한 정보는, 상기 제1 이미지, 상기 제1 이미지가 촬영된 제1 시점에서 상기 로봇의 제1 위치 정보 및 제1 방향 정보를 포함하는 제어 방법."}
{"patent_id": "10-2021-0112501", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제13 항에 있어서,상기 이미지 센서가 촬영한 제3 이미지를 획득하는 단계;상기 제3 이미지를 상기 오브젝트 인식 모델에 입력하여 상기 제3 이미지에 포함된 오브젝트에 대한 제3 식별정보 및 상기 제3 식별 정보의 제3 신뢰도를 포함하는 제3 정보를 획득하는 단계; 및공개특허 10-2023-0030366-5-상기 제3 정보 및 상기 에러에 관한 정보에 기초하여 상기 로봇의 동작을 제어하는 단계;를 더 포함하는제어 방법."}
{"patent_id": "10-2021-0112501", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제14 항에 있어서,상기 제3 신뢰도가 기설정된 값보다 크면, 상기 제3 이미지에 포함된 오브젝트를 향해 이동하도록 상기 로봇을제어하는 단계;를 더 포함하는제어 방법."}
{"patent_id": "10-2021-0112501", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제15 항에 있어서,상기 제3 이미지가 촬영된 제3 시점에서 상기 로봇의 제3 위치 정보 및 제3 방향 정보를 획득하는 단계; 및상기 제1 위치 정보, 상기 제1 방향 정보, 상기 제3 위치 정보 및 상기 제3 방향 정보에 기초하여 상기 제1 이미지가 촬영된 장소가 상기 제3 이미지가 촬영된 장소에 대응되는지 판단하는 단계;를 더 포함하는제어 방법."}
{"patent_id": "10-2021-0112501", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제16 항에 있어서,상기 제1 이미지가 촬영된 장소가 상기 제3 이미지가 촬영된 장소에 대응된다고 판단되면, 상기 제1 이미지 및상기 제3 이미지의 유사도를 판단하는 단계; 및상기 유사도가 임계값보다 크면, 상기 기설정된 값을 증가시키는 단계;를 더 포함하는제어 방법."}
{"patent_id": "10-2021-0112501", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제17 항에 있어서,상기 제1 이미지 및 상기 제3 이미지의 유사도를 판단하는 단계는,상기 제1 이미지 및 상기 제3 이미지를 유사도 판단 모델에 입력하여 상기 제1 이미지 및 상기 제3 이미지의 유사도를 판단하는제어 방법."}
{"patent_id": "10-2021-0112501", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "로봇이 개시된다. 로봇은, 이미지 센서, 구동부, 메모리 및 프로세서를 포함하고, 프로세서는, 이미지 센서가 촬 영한 제1 이미지를 획득하고, 제1 이미지에 포함된 오브젝트에 대한 제1 정보를 획득하고, 로봇이 오브젝트에 접 근하도록 구동부를 제어하고, 로봇이 오브젝트에 접근하는 동안 제2 이미지를 획득하고, 제2 이미지에 기초하여 오브젝트에 대한 제2 정보를 획득하고, 제1 정보 및 제2 정보에 기초하여 제1 정보 또는 제2 정보에 에러가 존재 하는지 판단하고, 판단 결과에 기초하여 로봇의 동작을 제어한다."}
{"patent_id": "10-2021-0112501", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 로봇 및 그 제어 방법으로, 보다 상세하게는, 오브젝트 오인식 여부를 판단하는 로봇 및 그 제어 방 법에 관한 것이다."}
{"patent_id": "10-2021-0112501", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "로봇 기술의 발달에 힘입어, 사용자와 인터랙션할 수 있는 로봇이 활발히 이용되고 있다. 예를 들어, 로봇은 사 용자의 질문에 응답하거나, 식당에서 음식을 서빙 하거나, 길 안내를 하는 등 인터랙션을 통한 다양한 서비스를 제공하고 있다. 한편, 사용자와의 원활한 인터랙션을 위해서는, 오브젝트를 정확히 인식하는 기술이 필요하다. 그렇지 않다면, 로봇이 불필요한 동작을 수행하게 되어 로봇의 효용성이나 사용자의 만족감이 떨어질 수 있기 때문이다. 예를 들어, 로봇은 사물이나 동물을 사람으로 또는 거울에 비친 사람의 모습을 실제 사람으로 오인식하여 접근할 수있다. 따라서, 로봇의 오브젝트 오인식을 방지하기 위한 기술에 대한 필요성이 대두된다."}
{"patent_id": "10-2021-0112501", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명이 해결하고자 하는 일 기술적 과제는, 오브젝트 오인식 여부를 판단하고, 판단 결과에 기초하여 동작하 는 로봇을 제공하는 것이다. 본 발명의 기술적 과제들은 이상에서 언급한 기술적 과제들로 제한되지 않으며, 언급되지 않은 또 다른 기술적"}
{"patent_id": "10-2021-0112501", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 2, "content": "과제들은 아래의 기재로부터 본 발명의 기술분야에서의 통상의 기술자에게 명확하게 이해 될 수 있을 것이다."}
{"patent_id": "10-2021-0112501", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상술한 기술적 과제를 해결하기 위한 본 개시의 예시적인 일 실시 예에 따르면, 로봇에 있어서, 이미지 센서; 구동부; 적어도 하나의 인스트럭션을 저장하는 메모리; 및 프로세서;를 포함하고, 상기 프로세서는, 상기 이미 지 센서가 촬영한 제1 이미지를 획득하고, 상기 제1 이미지를 오브젝트 인식 모델에 입력하여 상기 제1 이미지 에 포함된 오브젝트에 대한 제1 식별 정보 및 상기 제1 식별 정보의 제1 신뢰도를 포함하는 제1 정보를 획득하 고, 상기 로봇이 상기 오브젝트에 접근하도록 상기 구동부를 제어하고, 상기 로봇이 상기 오브젝트에 접근하는 동안 상기 이미지 센서가 촬영한 제2 이미지를 획득하고, 상기 제2 이미지를 상기 오브젝트 인식 모델에 입력하 여 상기 오브젝트에 대한 제2 식별 정보 및 상기 제2 식별 정보의 제2 신뢰도를 포함하는 제2 정보를 획득하고, 상기 제1 정보 및 상기 제2 정보를 비교하여 상기 제1 정보에 에러가 존재하는지 판단하고, 상기 판단 결과에 기초하여 상기 로봇의 동작을 제어하는 로봇이 제공될 수 있다. 상기 프로세서는, 상기 제1 신뢰도가 상기 제2 신뢰도보다 크면, 상기 제1 정보에 에러가 존재한다고 판단할 수 있다. 상기 프로세서는, 상기 제1 식별 정보와 상기 제2 식별 정보가 상이하면, 상기 제1 정보에 에러가 존재한다고 판단할 수 있다. 상기 프로세서는, 상기 제1 정보에 에러가 존재하는 것으로 판단되면, 상기 에러에 관한 정보를 상기 메모리에 저장하고, 상기 에러에 관한 정보는, 상기 제1 이미지, 상기 제1 이미지가 촬영된 제1 시점(time point)에서 상 기 로봇의 제1 위치 정보 및 제1 방향 정보를 포함할 수 있다. 상기 프로세서는, 상기 이미지 센서가 촬영한 제3 이미지를 획득하고, 상기 제3 이미지를 상기 오브젝트 인식 모델에 입력하여 상기 제3 이미지에 포함된 오브젝트에 대한 제3 식별 정보 및 상기 제3 식별 정보의 제3 신뢰 도를 포함하는 제3 정보를 획득하고, 상기 제3 정보 및 상기 에러에 관한 정보에 기초하여 상기 로봇의 동작을 제어할 수 있다. 상기 프로세서는, 상기 제3 신뢰도가 기설정된 값보다 크면, 상기 제3 이미지에 포함된 오브젝트를 향해 이동하 도록 상기 구동부를 제어할 수 있다. 상기 프로세서는, 상기 제3 이미지가 촬영된 제3 시점에서 상기 로봇의 제3 위치 정보 및 제3 방향 정보를 획득 하고, 상기 제1 위치 정보, 상기 제1 방향 정보, 상기 제3 위치 정보 및 상기 제3 방향 정보에 기초하여 상기 제1 이미지가 촬영된 장소가 상기 제3 이미지가 촬영된 장소에 대응되는지 판단할 수 있다. 상기 프로세서는, 상기 제1 위치 정보 및 상기 제3 위치 정보의 차이가 임계 값 이내이면, 상기 제1 이미지 및 상기 제3 이미지의 유사도를 판단하고, 상기 유사도가 임계값보다 크면, 상기 기설정된 값을 증가시킬 수 있다. 상기 프로세서는, 상기 제1 이미지 및 상기 제3 이미지를 유사도 판단 모델에 입력하여 상기 제1 이미지 및 상 기 제3 이미지의 유사도를 판단할 수 있다. 상술한 기술적 과제를 해결하기 위한 본 개시의 예시적인 다른 일 실시 예에 따르면, 이미지 센서를 포함하는 로봇의 제어 방법에 있어서, 상기 이미지 센서가 촬영한 제1 이미지를 획득하는 단계; 상기 제1 이미지를 오브 젝트 인식 모델에 입력하여 상기 제1 이미지에 포함된 오브젝트에 대한 제1 식별 정보 및 상기 제1 식별 정보의 제1 신뢰도를 포함하는 제1 정보를 획득하는 단계; 상기 오브젝트에 접근하도록 상기 로봇을 제어하는 단계; 상 기 로봇이 상기 오브젝트에 접근하는 동안 상기 이미지 센서가 촬영한 제2 이미지를 획득하는 단계; 상기 제2이미지를 상기 오브젝트 인식 모델에 입력하여 상기 오브젝트에 대한 제2 식별 정보 및 상기 제2 식별 정보의 제2 신뢰도를 포함하는 제2 정보를 획득하는 단계; 상기 제1 정보 및 상기 제2 정보를 비교하여 상기 제1 정보 에 에러가 존재하는지 판단하는 단계; 및 상기 판단 결과에 기초하여 상기 로봇의 동작을 제어하는 단계;를 포 함하는 제어 방법이 제공될 수 있다. 상기 판단하는 단계는, 상기 제1 신뢰도가 상기 제2 신뢰도보다 크면, 상기 제1 정보에 에러가 존재한다고 판단 할 수 있다. 상기 판단하는 단계는, 상기 제1 식별 정보와 상기 제2 식별 정보가 상이하면, 상기 제1 정보에 에러가 존재한 다고 판단할 수 있다. 상기 제어 방법은, 상기 제1 정보에 에러가 존재하는 것으로 판단되면, 상기 에러에 관한 정보를 상기 메모리에 저장하는 단계;를 더 포함하고, 상기 에러에 관한 정보는, 상기 제1 이미지, 상기 제1 이미지가 촬영된 제1 시 점에서 상기 로봇의 제1 위치 정보 및 제1 방향 정보를 포함할 수 있다. 상기 제어 방법은, 상기 이미지 센서가 촬영한 제3 이미지를 획득하는 단계; 상기 제3 이미지를 상기 오브젝트 인식 모델에 입력하여 상기 제3 이미지에 포함된 오브젝트에 대한 제3 식별 정보 및 상기 제3 식별 정보의 제3 신뢰도를 포함하는 제3 정보를 획득하는 단계; 및 상기 제3 정보 및 상기 에러에 관한 정보에 기초하여 상기 로 봇의 동작을 제어하는 단계;를 더 포함할 수 있다. 상기 제어 방법은, 상기 제3 신뢰도가 기설정된 값보다 크면, 상기 제3 이미지에 포함된 오브젝트를 향해 이동 하도록 상기 로봇을 제어하는 단계;를 더 포함할 수 있다. 상기 제어 방법은, 상기 제3 이미지가 촬영된 제3 시점에서 상기 로봇의 제3 위치 정보 및 제3 방향 정보를 획 득하는 단계; 및 상기 제1 위치 정보, 상기 제1 방향 정보, 상기 제3 위치 정보 및 상기 제3 방향 정보에 기초 하여 상기 제1 이미지가 촬영된 장소가 상기 제3 이미지가 촬영된 장소에 대응되는지 판단하는 단계;를 더 포함 할 수 있다. 상기 제어 방법은, 상기 제1 이미지가 촬영된 장소가 상기 제3 이미지가 촬영된 장소에 대응된다고 판단되면, 상기 제1 이미지 및 상기 제3 이미지의 유사도를 판단하는 단계; 및 상기 유사도가 임계값보다 크면, 상기 기설 정된 값을 증가시키는 단계;를 더 포함할 수 있다. 상기 제1 이미지 및 상기 제3 이미지의 유사도를 판단하는 단계는, 상기 제1 이미지 및 상기 제3 이미지를 유사 도 판단 모델에 입력하여 상기 제1 이미지 및 상기 제3 이미지의 유사도를 판단할 수 있다."}
{"patent_id": "10-2021-0112501", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 2, "content": "본 개시의 과제의 해결 수단이 상술한 해결 수단들로 제한되는 것은 아니며, 언급되지 아니한 해결 수단들은 본"}
{"patent_id": "10-2021-0112501", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 3, "content": "명세서 및 첨부된 도면으로부터 본 개시가 속하는 기술분야에서 통상의 지식을 가진 자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2021-0112501", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "이상과 같은 본 개시의 다양한 실시 예에 따르면, 로봇의 오브젝트 오인식이 방지될 수 있다. 이에 따라, 사용 자의 만족감이 향상될 수 있다. 그 외에 본 개시의 실시 예로 인하여 얻을 수 있거나 예측되는 효과에 대해서는 본 개시의 실시 예에 대한 상세 한 설명에서 직접적 또는 암시적으로 개시하도록 한다. 예컨대, 본 개시의 실시 예에 따라 예측되는 다양한 효 과에 대해서는 후술될 상세한 설명 내에서 개시될 것이다."}
{"patent_id": "10-2021-0112501", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 명세서에서 사용되는 용어에 대해 간략히 설명하고, 본 개시에 대해 구체적으로 설명하기로 한다. 본 개시의 실시 예에서 사용되는 용어는 본 개시에서의 기능을 고려하면서 가능한 현재 널리 사용되는 일반적인 용어들을 선택하였으나, 이는 당 분야에 종사하는 기술자의 의도 또는 판례, 새로운 기술의 출현 등에 따라 달 라질 수 있다. 또한, 특정한 경우는 출원인이 임의로 선정한 용어도 있으며, 이 경우 해당되는 개시의 설명 부 분에서 상세히 그 의미를 기재할 것이다. 따라서 본 개시에서 사용되는 용어는 단순한 용어의 명칭이 아닌, 그 용어가 가지는 의미와 본 개시의 전반에 걸친 내용을 토대로 정의되어야 한다. 본 개시의 실시 예들은 다양한 변환을 가할 수 있고 여러 가지 실시 예를 가질 수 있는바, 특정 실시 예들을 도 면에 예시하고 상세한 설명에 상세하게 설명하고자 한다. 그러나 이는 특정한 실시 형태에 대해 범위를 한정하 려는 것이 아니며, 개시된 사상 및 기술 범위에 포함되는 모든 변환, 균등물 내지 대체물을 포함하는 것으로 이 해되어야 한다. 실시 예들을 설명함에 있어서 관련된 공지 기술에 대한 구체적인 설명이 요지를 흐릴 수 있다고 판단되는 경우 그 상세한 설명을 생략한다. 제1, 제2 등의 용어는 다양한 구성요소들을 설명하는데 사용될 수 있지만, 구성요소들은 용어들에 의해 한정되 어서는 안 된다. 용어들은 하나의 구성요소를 다른 구성요소로부터 구별하는 목적으로만 사용된다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 출원에서, \"포함하다\" 또 는 \"구성되다\" 등의 용어는 명세서 상에 기재된 특징, 숫자, 단계, 동작, 구성요소, 부품 또는 이들을 조합한 것이 존재함을 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성요소, 부품 또 는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되어야 한다. 아래에서는 첨부한 도면을 참고하여 본 개시의 실시 예에 대하여 본 개시가 속하는 기술 분야에서 통상의 지식 을 가진 자가 용이하게 실시할 수 있도록 상세히 설명한다. 그러나 본 개시는 여러 가지 상이한 형태로 구현될 수 있으며 여기에서 설명하는 실시 예에 한정되지 않는다. 그리고 도면에서 본 개시를 명확하게 설명하기 위해 서 설명과 관계없는 부분은 생략하였으며, 명세서 전체를 통하여 유사한 부분에 대해서는 유사한 도면 부호를 붙였다. 도 1은 본 개시의 일 실시 예에 따른 로봇의 컨셉을 설명하기 위한 도면이다. 예로, 로봇은 서비스 로봇일 수 있다. 다만 이는 일 실시 예에 불과하며, 로봇이 다양한 종류의 로봇(예로, 청소 로봇 등)으로 구현될 수 있음을 밝혀둔다. 로봇은 공간(S)(예로, TV 매장) 내에서 작업을 수행할 수 있다. 예를 들어, 로봇은 공간(S) 내를 이 동하면서 사용자를 감지할 수 있다. 로봇은 감지된 사용자와 인터랙션을 수행하여 서비스(예로, 상품 안내)를 제공하고 있다. 로봇은 사용자를 감지하기 위해 로봇 주변을 촬영한 이미지를 획득하고, 이미지를 분석하여 사용자를 감지할 수 있다. 한편, 로봇이 동일한 오브젝트를 촬영한 복수의 이미지를 분석하는 경우라도, 다양한 요 인(예로, 이미지를 촬영한 각도, 이미지 센서와 오브젝트 사이의 거리, 외부광의 유무 등)에 의해 각 이미지에 포함된 오브젝트에 대응되는 픽셀 값은 상이할 수 있다. 이에 따라, 각 이미지에 대응되는 오브젝트 인식 결과 는 상이할 수 있다. 예를 들어, 로봇은 제1 이미지를 획득하고, 제1 이미지에 포함된 오브젝트를 인식할 수 있다. 이에 따라, 로봇은 오브젝트와의 인터랙션을 수행하기 위해 이동할 수 있다. 오브젝트를 향해 이동 하는 동안, 로봇은 오브젝트를 포함하지 않는 제2 이미지를 획득할 수 있다. 이와 같이, 각 이미지에서의 오브젝트 인식 결과가 상이할 수 있다. 이 같은 상황에서, 로봇은 제1 이미지 및 제2 이미지에 기초하여 제1 이미지에 대한 분석 결 과가 에러를 포함하고 있음을 판단할 수 있다. 즉, 로봇은 오브젝트를 오인식하였음을 판단할 수 있다. 이 때, 로봇은 에러에 관한 정보를 저장할 수 있다. 예로, 에러에 관한 정보는, 제1 이미지, 제1 이미 지가 촬영된 시점(time point)에서 로봇의 위치 정보를 포함할 수 있다. 이후 공간(S)에 위치하게 되면, 로봇은 현재 위치한 장소가 과거에 에러가 발생했던 장소인 것으로 식별할 수 있다. 그리고, 로봇은 수행할 동작을 판단하기 위한 기설정된 값을 증가시키고, 변경된 기설정된 값에 기초하여 동작을 수행할 수 있다. 여기서, 기설정된 값이란, 식별된 오브젝트와 관련된 동작을 수행할 지 여부 를 결정하기 위한 기준값으로, 기설정된 값이 증가할수록 로봇이 식별된 오브젝트와 관련된 동작을 수행할 가능성이 낮아질 수 있다. 이에 따라, 로봇은 오브젝트 오인식에 의한 오동작을 방지할 수 있다. 도 2는 본 개시의 일 실시 예에 따른 로봇의 구성을 도시한 블록도이다. 로봇은 센서부, 구동부 , 통신 인터페이스, 메모리 및 프로세서를 포함할 수 있다. 다만 이에 한정되는 것은 아니 며, 로봇은 가이드 음성을 출력하기 위한 스피커, 가이드 메시지를 표시하기 위한 디스플레이를 더 포함할 수 있다. 예로, 로봇은 서비스 로봇일 수 있으나, 이에 한정되는 것은 아니며, 산업용 로봇 및 군사 로봇 등 다양한 로봇일 수 있다. 이하 각 구성에 대하여 설명하도록 한다. 센서부는 이미지 센서, 라이다 센서, GPS 센서 및 모션 센서를 포함할 수 있다. 다만 이에 한정되는 것은 아니며, 센서부는 뎁스 센서, 초음파 센서 등 다양한 센서를 더 포함할 수 있다. 이미지 센서(또는 카메라)는 로봇 주변을 촬영한 이미지를 획득하기 위한 구성이다. 프로세서는 이미지 센서의 센싱값에 기초하여 촬영 이미지를 획득할 수 있다. 이미지 센서는 기설정된 주기로 로 봇 주변을 촬영할 수 있다. 예로, 이미지 센서는 로봇의 전방을 촬영하도록 배치될 수 있다. 한 편, 이미지 센서는 CMOS(Complementary Metal Oxide Semiconductor) 센서 및 CCD(Charge Coupled Device) 센서를 포함할 수 있다. 라이다 센서는 로봇 주위에 존재하는 오브젝트에 대한 위치 정보를 포함하는 스캔 데이터를 획득할 수 있다. 예로, 프로세서는 라이다 센서를 통해 획득되는 스캔 데이터를 바탕으로 로봇 주변의 오브젝트에 대한 위치 정보를 획득할 수 있다. 여기서, 오브젝트에 대한 위치 정보는, 로봇과 오브젝트 사 이의 거리 정보 및 각도 정보를 포함할 수 있다. 예로, 라이다 센서는 로봇을 기준으로 기설정된 각 도(예로, 360도)로 스캔을 수행할 수 있다. 이를 위해, 라이다 센서는 점 광원 형태의 레이저 빔을 기설정 된 각도로 출력할 수 있다. 또는, 라이다 센서는 라인 빔 형태의 레이저 빔을 출사할 수 있다. GPS 센서는 GPS(Global Positioning System) 신호를 수신하기 위한 센서이다. GPS 센서는 GPS 신호 에 기초하여 로봇의 현재 위치 정보(x, y, z)를 획득할 수 있다. 모션 센서는 로봇의 모션 정보를 획득할 수 있다. 예로, 모션 센서는 IMU(Inertial Measurement Unit) 센서를 포함할 수 있다. 프로세서는 모션 센서의 센싱값에 기초하여 로봇의 자세 정보를 획득할 수 있다. 로봇의 자세 정보는, 로봇의 회전 방향, 회전 각도 및 로봇이 바 라보는 방향에 대한 정보를 포함할 수 있다. 구동부는 로봇을 이동 시키는 바퀴 및 바퀴를 회전시키는 바퀴 구동 모터를 포함할 수 있다. 또한, 구동부는 바퀴 구동 모터에 구동 전류를 공급하는 모터 구동 회로, 바퀴 구동 모터의 회전력을 바퀴에 전 달하는 동력 전달 모듈, 바퀴 구동 모터 또는 바퀴의 회전 변위 및 회전 속도를 검출하는 회전 감지 센서를 더 포함할 수 있다. 통신 인터페이스는 적어도 하나의 회로를 포함하며 다양한 유형의 통신 방식에 따라 다양한 유형의 외부 기기와 통신을 수행할 수 있다. 예를 들어, 통신 인터페이스는 이미지 센서를 통해 획득된 촬영 이미 지를 외부 서버로 전송할 수 있다. 그리고, 통신 인터페이스는 외부 서버로부터 촬영 이미지에 포함된 오 브젝트에 대한 정보를 수신할 수 있다. 한편, 통신 인터페이스는 와이파이(Wi-Fi) 모듈, 블루투스 모듈, 지그비(ZigBee) 모듈, 비콘(Beacon) 모듈, 셀룰러 통신모듈, 3G(3세대) 이동통신 모듈, 4G(4세대) 이동통신 모 듈, 4세대 LTE(Long Term Evolution) 통신 모듈, 5G(5세대) 이동통신 모듈 중 적어도 하나를 포함할 수 있다. 메모리는 로봇의 구성요소들의 전반적인 동작을 제어하기 위한 운영체제(OS: Operating System) 및 로봇의 구성요소와 관련된 명령 또는 데이터를 저장할 수 있다. 예로, 메모리는 로봇이 위치한공간의 맵 정보를 저장할 수 있다. 또한, 메모리는 로봇의 동작을 제어하기 위한 모듈이 각종 동작을 수행하기 위해 필요한 데이터를 저장할 수 있다. 로봇의 동작을 제어하기 위한 모듈은 오브젝트 정보 획득 모듈, 에러 판단 모듈, 에러 정보 획득 모듈, 에러 장소 식별 모듈 및 동작 제어 모듈 을 포함할 수 있다. 한편, 메모리는 학습된 신경망 모델을 저장할 수 있다. 예로, 메모리는 제1 신경망 모델(예로, 오브 젝트 인식 모델(NN1)) 및 제2 신경망 모델(예로, 유사도 획득 모델(NN2))을 포함할 수 있다. 메모리는 비 휘발성 메모리(ex: 하드 디스크, SSD(Solid state drive), 플래시 메모리), 휘발성 메모리 등으로 구현될 수 있 다. 프로세서는 메모리와 전기적으로 연결되어 로봇의 전반적인 기능 및 동작을 제어할 수 있다. 프 로세서는 사용자 음성이 입력되면, 비휘발성 메모리에 저장되어 있는 모듈(151 내지 155)이 각종 동작을 수행하기 위한 데이터를 휘발성 메모리로 로딩(loading)할 수 있다. 여기서, 로딩이란 프로세서가 액세스 할 수 있도록 비휘발성 메모리에 저장된 데이터를 휘발성 메모리에 불러들여 저장하는 동작을 의미한다. 오브젝트 정보 획득 모듈은 이미지 센서가 촬영한 이미지를 획득할 수 있다. 예로, 오브젝트 정보 획 득 모듈은 제1 이미지 및 제2 이미지를 획득할 수 있다. 여기서, 제1 이미지는 이미지 센서와 오브젝 트 사이의 거리가 제1 거리일 때 촬영된 이미지이며, 제2 이미지는 이미지 센서와 오브젝트 사이의 거리가 제1 거리보다 작은 제2 거리일 때 촬영된 이미지일 수 있다. 이 때, 제1 이미지 및 제2 이미지는 적어도 하나의 공통 오브젝트를 포함할 수 있다. 예로, 제1 이미지 및 제2 이미지는 제1 오브젝트를 공통으로 포함할 수 있다. 오브젝트 정보 획득 모듈은 획득된 이미지에 포함된 오브젝트에 대한 정보를 획득할 수 있다. 여기서, 오 브젝트에 대한 정보는 오브젝트에 대한 식별 정보(예로, 사람) 및 식별 정보의 신뢰도(confidence)를 포함할 수 있다. 신뢰도는 0에서 1사이의 값이며, 신뢰도가 클수록 식별 정보의 정확도가 클 수 있다. 오브젝트 정보 획득 모듈은 촬영 이미지를 오브젝트 인식 모델(NN1)에 입력하여 오브젝트에 대한 정보를 획득할 수 있다. 여기 서, 오브젝트 인식 모델(NN1)은 입력 이미지에 포함된 오브젝트에 대한 정보를 획득하도록 학습된 신경망 모델 로서, CNN (Convolutional Neural Network)을 포함할 수 있다. 예로, 오브젝트 정보 획득 모듈은 제1 이미지를 오브젝트 인식 모델(NN1)에 입력하여 제1 이미지에 포함된 제1 오브젝트에 대한 제1 식별 정보 및 제1 식별 정보의 제1 신뢰도를 포함하는 제1 정보를 획득할 수 있다. 또 한, 오브젝트 정보 획득 모듈은 제2 이미지를 오브젝트 인식 모델(NN1)에 입력하여 제1 이미지 및 제2 이 미지에 공통으로 포함된 제1 오브젝트에 대한 제2 식별 정보 및 제2 식별 정보의 제2 신뢰도를 포함하는 제2 정 보를 획득할 수 있다. 에러 판단 모듈은 오브젝트 정보 획득 모듈을 통해 획득된 오브젝트에 대한 정보에 에러가 존재하는 지 판단할 수 있다. 에러 판단 모듈은 서로 다른 촬영 조건에서 촬영된 복수의 이미지를 비교하여 오브젝 트에 대한 정보에 에러가 존재하는지 판단할 수 있다. 여기서, 촬영 조건은, 이미지 센서와 오브젝트 사이 의 거리 및 각도 중 적어도 하나에 기초하여 정해질 수 있다. 이하에서는 이미지 센서와 오브젝트 사이의 거리가 상이할 때 촬영된 복수의 이미지에 기초하여 오브젝트에 대한 정보에 에러가 존재하는지 판단하는 방법 에 대해 설명하도록 한다. 전술한 바와 같이, 이미지 센서와 오브젝트 사이의 거리가 제1 거리일 때 촬영된 제1 이미지와 이미지 센 서와 오브젝트 사이의 거리가 제1 거리보다 작은 제2 거리일 때 촬영된 제2 이미지가 획득될 수 있다. 그 리고, 제1 이미지 및 제2 이미지는 제1 오브젝트를 공통으로 포함할 수 있다. 에러 판단 모듈은 제1 이미지에 대응되는 제1 정보 및 제2 이미지에 대응되는 제2 정보에 기초하여 제1 정 보에 에러가 존재하는지 판단할 수 있다. 일 예로, 에러 판단 모듈은 제1 식별 정보와 제2 식별 정보가 상 이한 경우, 제1 정보에 에러가 존재한다고 판단할 수 있다. 가령, 제1 오브젝트에 대한 제1 식별 정보는 '사 람'에 대응되며, 제1 오브젝트에 대한 제2 식별 정보는 '강아지'에 대응될 수 있다. 즉, 에러 판단 모듈은 제1 식별 정보 및 제2 식별 정보가 상이한 경우, 제1 식별 정보보다 제2 식별 정보를 우선시하여 제1 식별 정보 에 에러가 존재한다고 판단할 수 있다. 한편, 제2 이미지에는 제1 오브젝트가 포함되지 않을 수 있다. 이에 따라, 제2 이미지에 대한 제2 정보는 제1 오브젝트에 대한 정보를 포함하지 않을 수 있다. 이와 같이 제1 이미지에서 식별된 오브젝트가 제2 이미지에서 는 식별되지 않는 경우, 에러 판단 모듈은 제1 정보에 에러가 존재한다고 판단할 수 있다. 예로, 제1 오브 젝트에 대응되는 제2 이미지의 영역에서 오브젝트가 식별되지 않으면, 에러 판단 모듈은 제1 정보에 에러가 존재한다고 판단할 수 있다. 한편, 에러 판단 모듈은 제1 신뢰도가 제2 신뢰도보다 크면, 제1 정보에 에러가 존재한다고 판단할 수 있 다. 예로, 제1 오브젝트에 대한 제1 식별 정보 및 제2 식별 정보가 각각 '사람'에 대응되고, 제1 신뢰도는 0.7 이며 제2 신뢰도는 0.5일 수 있다. 이 때, 에러 판단 모듈은 제1 신뢰도가 제2 신뢰도보다 크므로, 제1 정 보에 에러가 존재한다고 판단할 수 있다. 한편, 에러 판단 모듈은 서로 다른 각도에서 촬영된 복수의 이미지 각각에 대한 정보를 획득하고, 획득된 정보에 에러가 존재하는지 판단할 수 있다. 예로, 이미지 센서의 시야각의 엣지 부분에 제1 오브젝트가 위 치할 때 촬영된 제1 이미지와, 이미지 센서의 시야각의 중심에 제1 오브젝트 위치할 때 촬영된 제2 이미지 가 획득될 수 있다. 제1 이미지에 포함된 제1 오브젝트에 대한 제1 식별 정보와 제2 이미지에 포함된 제1 오브 젝트에 대한 제2 식별 정보가 상이한 경우, 에러 판단 모듈은 제1 식별 정보 또는 제2 식별 정보에 에러가 존재한다고 판단할 수 있다. 에러 정보 획득 모듈은 에러에 관한 정보를 획득하여 메모리에 저장할 수 있다. 에러에 관한 정보는, 에러 장소를 촬영한 이미지, 이미지가 촬영될 때 로봇의 위치 정보 및 방향 정보를 포함할 수 있다. 예로, 에러 정보 획득 모듈은 제1 이미지, 제1 이미지가 촬영된 제1 시점에서 로봇의 제1 위치 정보 및 제1 방향 정보를 메모리에 저장할 수 있다. 한편, 로봇의 시간 별 위치 정보는 메모리에 저장되어 있을 수 있다. 예로, 로봇의 위치 정보는 미리 저장된 맵 정보와 라이다 센서의 센싱값에 기초하여 산출될 수 있다. 또는, 로봇의 위치 정보는 GPS 센서에 기초하여 획득될 수 있다. 한편, 본 개시에 따른 로봇은 오브젝트에 대한 정보에 에러가 존재하는지 판단하고 에러 정보를 수집 및 저장하는 제1 상태 및 사용자와의 인터랙션을 수행하는 제2 상태에서 동작할 수 있다. 전술한 에러 판단 모듈 및 에러 정보 획득 모듈은 로봇이 제1 상태일 때 동작할 수 있다. 즉, 에러 판단 모듈 및 에러 정보 획득 모듈은 로봇이 제2 상태일 때는 동작하지 않을 수 있다. 에러 장소 식별 모듈은 현재 로봇의 위치 정보 및 방향 정보와 메모리에 저장된 에러에 관한 정 보를 비교하여, 현재 로봇이 위치한 장소가 에러가 발생했던 장소(이하, 에러 장소라 함)인지 식별할 수 있다. 현재 로봇의 위치가 에러가 발생했던 장소로부터 기설정된 범위 이내이고, 현재 로봇 또는 이 미지 센서가 바라보는 각도와 저장된 각도의 차이가 기설정된 범위 이내이면, 에러 장소 식별 모듈은 로봇이 현재 에러 장소에 위치한다고 판단할 수 있다. 동작 제어 모듈은 로봇의 상태에 기초하여 로봇의 다양한 동작들을 제어할 수 있다. 로봇 이 제1 상태일 때 이미지 센서를 통해 획득된 이미지에서 오브젝트가 식별되면, 동작 제어 모듈은 식 별된 오브젝트를 향해 접근하도록 구동부를 제어할 수 있다. 예로, 동작 제어 모듈은 제1 이미지에 포함된 제1 오브젝트를 향해 접근하도록 구동부를 제어할 수 있다. 여기서, 제1 이미지는 로봇과 제1 오브젝트 사이의 거리가 제1 거리일 때 촬영된 이미지일 수 있다. 동작 제어 모듈은 제1 오브젝트와 로봇 사이의 거리가 제1 거리보다 작아지도록 구동부를 제어할 수 있다. 이에 따라, 이미지 센서는 로봇과 제1 오브젝트 사이의 거리가 제1 거리보다 작은 제2 거리에서 제2 이미지를 촬영할 수 있다. 또한, 동작 제어 모듈은 식별된 오브젝트가 이미지 센서의 시야각을 벗어나지 않는 범위 내에서 로봇 이 회전하도록 구동부를 제어할 수 있다. 예로, 제1 오브젝트가 이미지 센서의 시야각의 중심 (즉 0도)에 위치하고, 이미지 센서의 시야각이 -60도에서 +60도인 경우, 동작 제어 모듈은 로봇(10 0)이 +5도 회전하도록 구동부를 제어할 수 있다. 이에 따라, 이미지 센서는 복수의 각도에서 동일한 오브젝트를 촬영할 수 있다. 로봇이 제2 상태일 때, 동작 제어 모듈은 오브젝트 정보 획득 모듈을 통해 획득된 오브젝트에 대한 정보에 기초하여 로봇의 동작을 제어할 수 있다. 특히, 동작 제어 모듈은 오브젝트에 대한 식별 정보의 신뢰도에 기초하여 로봇의 동작을 제어할 수 있다. 구체적으로, 오브젝트에 대한 식별 정보의 신뢰 도가 기설정된 값(예로, 0.5)보다 크면, 동작 제어 모듈은 오브젝트와 관련된 동작을 수행하도록 로봇 을 제어할 수 있다. 반면에, 오브젝트에 대한 식별 정보의 신뢰도가 기설정된 값보다 작으면, 동작 제어 모듈은 오브젝트를 노이즈로 판단하고, 오브젝트와 관련된 동작 제어를 수행하지 않을 수 있다. 즉, 기설 정된 값은, 식별된 오브젝트와 관련된 동작을 수행할 지 여부를 결정하기 위한 기준값일 수 있다. 예로, 오브젝트가 사람이고 오브젝트에 대한 식별 정보의 신뢰도가 기설정된 값보다 큰 경우, 동작 제어 모듈 은 오브젝트를 향해 접근하여 가이드 음성을 출력하도록 스피커를 제어하거나, 가이드 메시지를 출력하도록 디스플레이를 제어할 수 있다. 반면에, 오브젝트가 사람이더라도 오브젝트에 대한 식별 정보의 신뢰도가 기 설정된 값보다 작으면, 동작 제어 모듈은 오브젝트와 관련된 동작 제어를 수행하지 않을 수 있다. 한편, 기설정된 값은 로봇의 위치에 따라 변경될 수 있다. 예로, 로봇이 에러 장소에 위치하는 경우, 기설정된 값은 증가될 수 있다. 기설정된 값이 증가하면, 로봇이 식별된 오브젝트와 관련된 동작을 수행할 가능성이 낮아질 수 있다. 즉, 에러 장소에서는 오브젝트에 대한 정보에 에러가 포함될 가능성이 존재하므로, 기설정된 값이 증가되면 오인식된 오브젝트와 관련된 동작(예로, 사람이 아닌 오브젝트가 사람으로 오인식되어 로봇이 오브젝트로 접근하는 동작)을 수행하는 것을 방지할 수 있다. 로봇이 에러 장소에 위치할 때, 동작 제어 모듈은 현재 위치에서 촬영된 이미지와 에러 정보로서 메 모리에 저장된 이미지 간의 유사도에 기초하여 기설정된 값을 변경할 수 있다. 동작 제어 모듈은 메 모리에 에러 정보로서 저장된 제1 이미지와 현재 위치에서 촬영된 제3 이미지의 유사도를 판단할 수 있다. 유사도가 임계값보다 크면, 동작 제어 모듈은 기설정된 값을 증가시킬 수 있다. 반면에, 유사도가 임계값 보다 작으면, 동작 제어 모듈은 기설정된 값을 변경하지 않을 수 있다. 이와 같이, 저장된 에러 정보와 현재 이미지의 유사도에 기초하여 기설정된 값을 변경하는 이유는, 동일한 위치 에서 동일한 방향을 바라보고 촬영을 하더라도, 기존에 존재하던 오인식된 오브젝트가 사라지거나 새로운 오브 젝트가 추가되는 등의 환경 변화가 발생할 수 있기 때문이다. 가령, 에러 발생 장소에 제1 이미지에 포함되지 않은 새로운 사용자가 위치할 수 있다. 이 때, 기설정된 값이 증가되어 기설정된 값이 새로운 사용자에 대한 식 별 정보의 신뢰도보다 커지게 되면, 로봇은 새로운 사용자와 관련된 동작(예로, 인터랙션)을 수행하지 않 게 된다. 이에 따라, 새로운 사용자의 불편이 초래될 수 있다. 한편, 동작 제어 모듈은 유사도 획득 모델(NN2)을 이용하여 제1 이미지 및 제3 이미지의 유사도를 판단할 수 있다. 유사도 획득 모델(NN2)은 입력된 복수의 이미지 간의 유사도를 획득하도록 학습된 신경망 모델로서, CNN (Convolutional Neural Network)을 포함할 수 있다. 동작 제어 모듈은 제1 이미지 및 제3 이미지를 유사도 획득 모델(NN2)에 입력하여 제1 이미지 및 제3 이미지의 유사도를 판단할 수 있다. 한편, 도 2에서는 각 모듈(151 내지 155)들을 프로세서의 구성으로 설명하였으나, 이는 일 실시 예에 불과 하며, 각 모듈(151 내지 155)들은 메모리에 저장될 수 있다. 이 때, 프로세서는 메모리에 저장 된 복수의 모듈(151 내지 155)을 비휘발성 메모리에서 휘발성 메모리로 로딩(loading)하여 복수의 모듈(151 내 지 155)의 각 기능들을 실행할 수 있다. 또한, 프로세서의 각 모듈들은 소프트웨어(software)로 구현되거 나, 소프트웨어와 하드웨어(hardware)가 결합된 형태로 구현될 수 있다. 한편, 본 개시에 따른 인공지능과 관련된 기능은 프로세서와 메모리를 통해 동작된다. 프로세서(15 0)는 하나 또는 복수의 프로세서로 구성될 수 있다. 이때, 하나 또는 복수의 프로세서는 CPU, AP, DSP(Digital Signal Processor) 등과 같은 범용 프로세서, GPU, VPU(Vision Processing Unit)와 같은 그래픽 전용 프로세서 또는 NPU와 같은 인공지능 전용 프로세서일 수 있다. 하나 또는 복수의 프로세서는, 메모리에 저장된 기 정의된 동작 규칙 또는 인공지능 모델에 따라, 입력 데이터를 처리하도록 제어한다. 또는, 하나 또는 복수의 프 로세서가 인공지능 전용 프로세서인 경우, 인공지능 전용 프로세서는, 특정 인공지능 모델의 처리에 특화된 하 드웨어 구조로 설계될 수 있다. 기 정의된 동작 규칙 또는 인공지능 모델은 학습을 통해 만들어진 것을 특징으로 한다. 여기서, 학습을 통해 만 들어진다는 것은, 기본 인공지능 모델이 학습 알고리즘에 의하여 다수의 학습 데이터들을 이용하여 학습됨으로 써, 원하는 특성(또는, 목적)을 수행하도록 설정된 기 정의된 동작 규칙 또는 인공지능 모델이 만들어짐을 의미 한다. 이러한 학습은 본 개시에 따른 인공지능이 수행되는 기기 자체에서 이루어질 수도 있고, 별도의 서버 및/ 또는 시스템을 통해 이루어 질 수도 있다. 학습 알고리즘의 예로는, 지도형 학습(supervised learning), 비지도 형 학습(unsupervised learning), 준지도형 학습(semi-supervised learning) 또는 강화 학습(reinforcement learning)이 있으나, 전술한 예에 한정되지 않는다. 인공지능 모델은 학습을 통해 만들어 질 수 있다. 여기서, 학습을 통해 만들어진다는 것은, 기본 인공지능 모델 이 학습 알고리즘에 의하여 다수의 학습 데이터들을 이용하여 학습됨으로써, 원하는 특성(또는, 목적)을 수행하 도록 설정된 기 정의된 동작 규칙 또는 인공지능 모델이 만들어짐을 의미한다. 인공지능 모델은, 복수의 신경망 레이어들로 구성될 수 있다. 복수의 신경망 레이어들 각각은 복수의 가중치들(weight values)을 갖고 있으며, 이전(previous) 레이어의 연산 결과와 복수의 가중치들 간의 연산을 통해 신경망 연산을 수행한다. 복수의 신경 망 레이어들이 갖고 있는 복수의 가중치들은 인공지능 모델의 학습 결과에 의해 최적화될 수 있다. 예를 들어,학습 과정 동안 인공지능 모델에서 획득한 로스(loss) 값 또는 코스트(cost) 값이 감소 또는 최소화되도록 복수 의 가중치들이 갱신될 수 있다. 인공지능 모델은 인공지능 모델의 처리에 특화된 하드웨어 구조로 설계된 인공지능 전용 프로세서에 의해 처리 될 수 있다. 인공지능 모델은 학습을 통해 만들어 질 수 있다. 여기서, 학습을 통해 만들어진다는 것은, 기본 인공지능 모델이 학습 알고리즘에 의하여 다수의 학습 데이터들을 이용하여 학습됨으로써, 원하는 특성(또는, 목적)을 수행하도록 설정된 기 정의된 동작 규칙 또는 인공지능 모델이 만들어짐을 의미한다. 인공지능 모델은, 복수의 신경망 레이어들로 구성될 수 있다. 복수의 신경망 레이어들 각각은 복수의 가중치들(weight values)을 갖고 있으며, 이전(previous) 레이어의 연산 결과와 복수의 가중치들 간의 연산을 통해 신경망 연산을 수행한다. 인공 신경망은 심층 신경망(DNN:Deep Neural Network)를 포함할 수 있으며, 예를 들어, CNN (Convolutional Neural Network), DNN (Deep Neural Network), RNN (Recurrent Neural Network), GAN (Generative Adversarial Network), RBM (Restricted Boltzmann Machine), DBN (Deep Belief Network), BRDNN(Bidirectional Recurrent Deep Neural Network) 또는 심층 Q-네트워크 (Deep Q-Networks) 등이 있으나, 전술한 예에 한정되지 않는다. 도 3은 본 개시의 일 실시 예에 따른 에러 판단 방법을 설명하기 위한 도면이다. 특히, 도 3은 오브젝트 오인식 이 발생하지 않는 상황을 도시한 도면이다. 로봇은 로봇과 제1 오브젝트 사이의 거리가 제1 거리 일 때 제1 오브젝트를 촬영한 제1 이미지를 획득할 수 있다. 로봇은 제1 이미지에 기초하여 오 브젝트 인식 동작을 수행하여 제1 오브젝트에 대한 제1 정보를 획득할 수 있다. 예를 들어, 제1 오브젝트 에 대한 제1 정보는 제1 식별 정보(human)와 제1 식별 정보의 제1 신뢰도(0.58)를 포함할 수 있다. 로봇은 제1 오브젝트로 접근하여 로봇과 제1 오브젝트 사이의 거리가 제1 거리보다 작은 제2 거리일 때 제1 오브젝트를 촬영한 제2 이미지를 획득할 수 있다. 로봇은 제2 이미지에 기초하 여 오브젝트 인식 동작을 수행하여 제1 오브젝트에 대한 정보를 획득할 수 있다. 예를 들어, 제1 오브젝트 에 대한 제2 정보는 제2 식별 정보(human)와 제2 식별 정보의 제2 신뢰도(0.7)를 포함할 수 있다. 로봇은 제1 정보 및 제2 정보에 기초하여 제1 정보에 에러가 존재하는지 판단할 수 있다. 구체적으로, 로 봇은 제1 식별 정보와 제2 식별 정보가 일치하는 지 여부, 제1 신뢰도보다 제2 신뢰도가 큰 지 여부를 판 단할 수 있다. 제1 식별 정보와 제2 식별 정보가 일치하고 제1 신뢰도보다 제2 신뢰도가 크면, 로봇 제1 정보에 에러가 존재하지 않는다고 판단할 수 있다. 즉, 로봇은 제1 오브젝트를 오인식하지 않았다고 판 단할 수 있다. 반면에, 제1 식별 정보와 제2 식별 정보가 일치하지 않거나 제1 신뢰도보다 제2 신뢰도가 작으면, 로봇 제1 정보에 에러가 존재하지 않는다고 판단할 수 있다. 도 3에서는, 제1 식별 정보(human)와 제2 식별 정보(human)가 일치하고, 제1 신뢰도(0.58)보다 제2 신뢰도(0.7)가 크므로, 로봇은 제1 정보에 에러가 존재하지 않는다고 판단할 수 있다. 도 4는 본 개시의 다른 일 실시 예에 따른 에러 판단 방법을 설명하기 위한 도면이다. 특히, 도 4는 오브젝트 오인식이 발생하는 상황을 도시한 도면이다. 로봇은 로봇과 제1 오브젝트 사이의 거리가 제1 거리 일 때 제1 오브젝트를 촬영한 제1 이미지를 획득할 수 있다. 여기서, 제1 오브젝트는 실제 오브젝트 가 아니라, 디스플레이 장치에서 출력되는 영상에 포함된 오브젝트일 수 있다. 로봇은 제1 이미지에 기초하여 오브젝트 인식 동작을 수행하여 제1 오브젝트에 대한 제1 정보를 획득할 수 있다. 예를 들어, 제1 오브젝트에 대한 제1 정보는 제1 식별 정보(human)와 제1 식별 정보의 제1 신뢰도(0.48)를 포함할 수 있다. 한편, 로봇은 제1 오브젝트로 접근하기 위해 이동하는 동안 제2 이미지를 획득할 수 있다. 한편, 로봇이 이동하는 동안 디스플레이 장치에서 출력되는 영상이 변하여, 제2 이미지에는 제1 오브젝트 가 아닌 제2 오브젝트가 포함되어 있을 수 있다. 로봇은 제2 이미지에 기초하여 오브젝트 인식 동작을 수행하여 제2 오브젝트에 대한 정보를 획득할 수 있다. 예를 들어, 제2 오브젝트에 대한 제2 정보 는 제2 식별 정보(dog)와 제2 식별 정보의 제2 신뢰도(0.52)를 포함할 수 있다. 도 4와 같이, 제1 식별 정보(human)와 제2 식별 정보(dog)가 일치하지 않는 경우, 로봇은 제1 정보 또는 제2 정보에 에러가 존재한다고 판단할 수 있다. 즉, 로봇은 제1 오브젝트를 오인식하였다고 판단할 수 있다. 도 5는 본 개시의 일 실시 예에 따른 기설정된 값을 제어하는 순서도이다. 로봇은 현재 위치가 에러 장소 인지 여부를 판단할 수 있다(S510). 도 6을 참조하면, 로봇은 현재 위치하는 공간에 대한 맵 정보를저장하고 있다. 또한, 로봇은 기존에 에러가 발생했던 장소(즉, 에러 장소)에 대한 정보(예로, 위치 정보)를 저장하고 있다. 예를 들어, 로봇은 현재 위치(x1, y1), 바라보는 방향(v1) 및 에러 장소에 대한 정보에 기초하여 에러 장소에 위치하는 지 여부를 판단할 수 있다. 한편, 에러 장소는 다양한 환경으로 조성될 수 있다. 예로, 에러 장소에는 사람이 그려진 벽지가 존재하거나, 거울이 놓여져 있을 수 있다. 현재 위치가 에러 장소라고 판단되면, 로봇은 현재 위치에서 획득된 이미지와 에러 장소에서 획득된 이미 지가 유사한 지 여부를 판단할 수 있다(S520). 구체적으로, 로봇은 로봇은 현재 위치에서 획득된 이 미지와 에러 장소에서 획득된 이미지의 유사도가 임계값보다 큰 지 여부를 판단할 수 있다. 유사도가 임계값보 다 크면, 로봇은 현재 위치에서 획득된 이미지와 에러 장소에서 획득된 이미지가 유사하다고 판단할 수 있 다. 반면에, 유사도가 임계값보다 작으면, 로봇은 현재 위치에서 획득된 이미지와 에러 장소에서 획득된 이미지가 유사하지 않다고 판단할 수 있다. 예로, 도 7을 참조하면, 로봇은 에러 장소에서 획득된 제1 이미지 및 현재 위치에서 획득된 제3 이미 지를 유사도 획득 모델(NN2)에 입력하여 제1 이미지 및 제3 이미지의 유사도를 획득할 수 있다. 여 기서, 제1 이미지는 에러 장소에 관한 정보로서, 로봇에 미리 저장되어 있을 수 있다. 다시 도 5를 참조하면, 현재 위치에서 획득된 이미지와 에러 장소에서 획득된 이미지가 유사하다고 판단되면, 로봇은 기설정된 값을 조절할 수 있다(S530). 구체적으로, 로봇은 기설정된 값을 증가시킬 수 있다. 반면에, 현재 위치에서 획득된 이미지와 에러 장소에서 획득된 이미지가 유사하지 않다고 판단되면, 로봇 은 기설정된 값을 유지할 수 있다(S540). 전술한 바와 같이, 기설정된 값이 증가할수록 로봇이 식별된 오브젝트와 관련된 동작을 수행할 가능성이 낮아질 수 있다. 예를 들어, 로봇이 오브젝트에 대한 식별 정보('사람') 및 식별 정보('사람')의 신뢰도 ('0.65')를 획득하였으며, 기설정된 값이 0.6으로 설정되어 있다고 가정한다. 이 때, 획득된 신뢰도('0.65')가 기설정된 값보다 크므로, 로봇은 오브젝트와 관련된 동작을 수행할 수 있다. 예로, 로봇은 오브젝트 로 접근하여 오브젝트와 인터랙션을 수행할 수 있다. 한편, 기설정된 값이 0.6에서 0.7로 증가되면, 획득된 신뢰도('0.65')가 기설정된 값보다 작으므로, 로봇 은 오브젝트와 관련된 동작을 수행하지 않을 수 있다. 즉, 기설정된 값이 증가됨에 따라, 로봇이 오브젝트 를 오인식하여 오동작할 가능성이 감소하게 되는 효과가 있다. 한편, 현재 위치에서 획득된 이미지와 에러 장소에서 획득된 이미지의 유사도를 고려하지 않고 기설정된 값이 조절되면, 사용자의 불편이 초래될 수 있다. 도 7을 참조하면, 에러 장소에서 촬영된 제3 이미지에 사용자 가 포함되는 경우가 있을 수 있다. 유사도 판단 없이 기설정된 값이 증가된다면, 로봇은 사용자와 관련된 동작을 수행하지 않게 되고, 사용자가 서비스를 제공받지 못하는 문제가 있을 수 있다. 본 개시에 따 른 로봇은 제1 이미지 및 제3 이미지가 유사하지 않다고 판단하고, 기설정된 값을 유지할 수 있다. 이에 따라, 로봇은 사용자와 관련된 동작을 수행할 수 있고, 사용자는 서비스를 제공받을 수 있다. 즉, 사용자가 서비스를 제공받지 못하는 문제를 방지될 수 있다. 도 8a는 본 개시의 일 실시 예에 따른 로봇의 제어 방법을 도시한 순서도이다. 특히, 도 8a는 에러 정보를 수집 하는 제1 모드로 동작할 때 로봇의 제어 방법을 도시한 순서도이다. 로봇은 제1 이미지를 획득하고(S811), 제1 이미지에 포함된 오브젝트에 대한 제1 식별 정보 및 제1 식별 정보의 제1 신뢰도를 포함하는 제1 정보를 획 득할 수 있다(S821). 로봇은 오브젝트에 접근하고(S831), 오브젝트에 접근하는 동안 제2 이미지를 획득할 수 있다(S841). 로봇은 제2 이미지에 기초하여 오브젝트에 대한 제2 식별 정보 및 제2 식별 정보의 제2 신 뢰도를 포함하는 제2 정보를 획득할 수 있다(S851). 로봇은 제1 정보 또는 제2 정보에 에러가 존재하는지 판단할 수 있다(S861). 예로, 제1 신뢰도가 제2 신뢰 도보다 크면, 로봇은 제1 정보 또는 제2 정보에 에러가 존재한다고 판단할 수 있다. 또는, 제1 식별 정보 와 제2 식별 정보가 상이하면, 로봇은 제1 정보 또는 제2 정보에 에러가 존재한다고 판단할 수 있다. 제1 정보 또는 제2 정보에 에러가 존재하면, 로봇은 에러에 관한 정보를 획득하여 저장할 수 있다(S871). 예로, 에러에 관한 정보는, 제1 이미지, 제1 이미지가 촬영된 제1 시점(time point)에서 로봇의 제1 위치 정보 및 제1 방향 정보를 포함할 수 있다. 도 8b는 본 개시의 다른 일 실시 예에 따른 로봇의 제어 방법을 도시한 순서도이다. 특히, 도 8b는 서비스 제공 을 위한 동작을 수행하는 제2 모드로 동작할 때 로봇의 제어 방법을 도시한 순서도이다. 로봇은 기설정된 영역을 주행하면서 사용자를 감지하기 위한 동작을 수행할 수 있다. 로봇은 로봇이 에러 장소에 위치하는지 판단할 수 있다(S812). 예로, 로봇은 저장된 에러에 관한 정보 및 현재 위치 정보를 비교하여 현재 위치가 에러 장소에 대응되는 지 판단할 수 있다. 에러 장소에 위치한다고 판단되면, 로봇은 제3 이미지를 획득하고(S822), 에러에 관한 정보 및 제3 이미지 에 기초하여 기설정된 값을 조절할 수 있다(S832). 예로, 로봇은 에러 장소에서 촬영된 제1 이미지와 제3 이미지의 유사도를 판단할 수 있다. 유사도가 임계값보다 크면, 로봇은 기설정된 값을 증가시킬 수 있다. 반면에, 유사도가 임계값보다 작으면, 로봇은 기설정된 값을 조절하지 않고 유지할 수 있다. 한편, 본 개시에 따른 로봇 제어 동작은 로봇 및 서버로 구성된 로봇 제어 시스템에 의해 수행될 수 있다. 이하 에서는 로봇 제어 시스템의 동작에 대하여 살펴본다. 도 9a는 본 개시의 일 실시 예에 따른 로봇 제어 시스템의 동작을 설명하기 위한 시퀀스도이다. 구체적으로, 도 9a는 로봇이 에러 정보를 수집하는 제1 모드로 동작할 때 로봇 제어 시스템의 동작을 설명하기 위한 시퀀스도이 다. 로봇 제어 시스템은 로봇 및 서버를 포함할 수 있다. 로봇은 제1 이미지를 획득하고 (S911), 제1 이미지를 서버로 전송할 수 있다(S921). 서버는 제1 이미지에 포함된 오브젝트에 대한 제1 식별 정보 및 제1 식별 정보의 제1 신뢰도를 포함하는 제1 정보를 획득할 수 있다(S931). 예로, 서버는 오브젝트 인식 모델에 제1 이미지를 입력하여 제1 정보를 획득할 수 있다. 한편, 서버의 프로세서는 로봇의 프로세서에 비해 성능이 높아, 제1 정보를 보 다 빠르게 획득할 수 있다. 또는, 서버에 저장된 오브젝트 인식 모델은 로봇에 저장된 오브젝트 인식 모델에 비해 크기가 클 수 있다. 이에 따라, 도 8a의 S821, S851에서 획득되는 정보에 비해 S931, S971에서 획 득되는 정보가 정확도가 높을 수 있다. 서버는 제1 정보를 로봇으로 전송할 수 있다(S941). 로봇은 제1 정보에 기초하여 오브젝트에 접 근하며, 오브젝트에 접근하는 동안 제2 이미지를 획득할 수 있다(S951). 그리고, 로봇은 제2 이미지를 서 버로 전송할 수 있다(S961). 서버는 제2 이미지에 기초하여 오브젝트에 대한 제2 식별 정보 및 제2 식별 정보의 제2 신뢰도를 포함하는 제2 정보를 획득할 수 있다(S971). 예로, 서버는 오브젝트 인식 모델에 제2 이미지를 입력하여 제2 정보를 획득할 수 있다. 그리고, 서버는 제1 정보 또는 제2 정보에 에러가 존재하는지 판단할 수 있다(S981). 서 버는 도 2 내지 도 4에서 설명한 에러 판단 방법에 기초하여 제1 정보 또는 제2 정보에 에러가 존재하는지 판단할 수 있는 바, 그 상세한 설명은 생략한다. 제1 정보 또는 제2 정보에 에러가 존재하면, 에러에 관한 정보 를 획득하여 저장할 수 있다(S991). 도 9b는 본 개시의 다른 일 실시 예에 따른 로봇 제어 시스템의 동작을 설명하기 위한 시퀀스도이다. 구체적으 로, 도 9b는 로봇이 서비스 제공을 위한 동작을 수행하는 제2 모드로 동작할 때 로봇 제어 시스템의 동작을 설 명하기 위한 시퀀스도이다. 로봇은 서버로 현재 위치 정보를 전송할 수 있다(S912). 서버는 로 봇이 에러 장소에 위치하는지 판단할 수 있다(S922). 서버는 도 5 및 도 6에서 설명한 에러 장소 판 단 방법에 기초하여 로봇이 에러 장소에 위치하는지 판단할 수 있는 바, 그 상세한 설명은 생략한다. 한편, 로봇이 에러 장소에 위치한다고 판단되면, 서버는 로봇에게 현재 위치에서의 촬영 이미지 를 요청할 수 있다. 로봇은 제3 이미지를 획득하고(S932), 제3 이미지를 서버로 전송할 수 있다(S942). 서버는 에러 에 관한 정보 및 제3 이미지에 기초하여 기설정된 값을 조절할 수 있다(S952). 예로, 서버는 에러 장소에 서 촬영된 제1 이미지와 제3 이미지의 유사도를 판단할 수 있다. 이 때, 서버는 제1 이미지 및 제3 이미지 를 유사도 획득 모델에 입력하여 제1 이미지 및 제3 이미지의 유사도를 획득할 수 있다. 획득된 유사도가 임계 값보다 크면, 서버는 기설정된 값을 증가시킬 수 있다. 반면에, 획득된 유사도가 임계값보다 작으면, 서버 는 기설정된 값을 조절하지 않고 유지할 수 있다. 한편, 서버에 저장된 유사도 획득 모델은 로봇 에 저장된 유사도 획득 모델에 비해 크기가 클 수 있다. 이에 따라, 도 8a의 S832에서 획득되는 유사도에 비해 S952에서 획득되는 유사도가 정확도가 높을 수 있다. 서버는 조절된 기설정된 값에 대한 정보를 로봇으로 전송할 수 있다(S962). 이에 따라 로봇은 조절된 기설정된 값에 기초하여 동작할 수 있다(S972). 예로, 로봇은 제3 이미지에 포함된 오브젝트에 대 한 제3 식별 정보의 제3 신뢰도가 조절된 기설정된 값보다 크면, 제3 식별 정보에 기초하여 오브젝트와 관련된 동작을 수행할 수 있다. 한편, 이상에서 설명된 다양한 실시 예들은 소프트웨어(software), 하드웨어(hardware) 또는 이들의 조합을 이 용하여 컴퓨터(computer) 또는 이와 유사한 장치로 읽을 수 있는 기록 매체 내에서 구현될 수 있다. 일부 경우 에 있어 본 명세서에서 설명되는 실시 예들이 프로세서 자체로 구현될 수 있다. 소프트웨어적인 구현에 의하면, 본 명세서에서 설명되는 절차 및 기능과 같은 실시 예들은 별도의 소프트웨어 모듈들로 구현될 수 있다. 소프트 웨어 모듈들 각각은 본 명세서에서 설명되는 하나 이상의 기능 및 작동을 수행할 수 있다. 한편, 상술한 본 개시의 다양한 실시 예들에 따른 처리 동작을 수행하기 위한 컴퓨터 명령어(computer instructions)는 비일시적 컴퓨터 판독 가능 매체(non-transitory computer-readable medium) 에 저장될 수 있 다. 이러한 비일시적 컴퓨터 판독 가능 매체에 저장된 컴퓨터 명령어는 프로세서에 의해 실행되었을 때 상술한 다양한 실시 예에 따른 처리 동작을 특정 기기가 수행하도록 할 수 있다. 비일시적 컴퓨터 판독 가능 매체란 레지스터, 캐쉬, 메모리 등과 같이 짧은 순간 동안 데이터를 저장하는 매체 가 아니라 반영구적으로 데이터를 저장하며, 기기에 의해 판독(reading)이 가능한 매체를 의미한다. 비일시적 컴퓨터 판독 가능 매체의 구체적인 예로는, CD, DVD, 하드 디스크, 블루레이 디스크, USB, 메모리카드, ROM 등 이 있을 수 있다. 이상에서는 본 개시의 바람직한 실시 예에 대하여 도시하고 설명하였지만, 본 개시는 상술한 특정의 실시 예에"}
{"patent_id": "10-2021-0112501", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "한정되지 아니하며, 청구범위에서 청구하는 본 개시의 요지를 벗어남이 없이 당해 개시에 속하는 기술분야에서 통상의 지식을 가진자에 의해 다양한 변형실시가 가능한 것은 물론이고, 이러한 변형실시들은 본 개시의 기술적 사상이나 전망으로부터 개별적으로 이해되어져서는 안될 것이다."}
{"patent_id": "10-2021-0112501", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 개시의 일 실시 예에 따른 로봇의 컨셉을 설명하기 위한 도면이다. 도 2는 본 개시의 일 실시예에 따른 로봇의 구성을 도시한 블록도이다. 도 3은 본 개시의 일 실시 예에 따른 에러 판단 방법을 설명하기 위한 도면이다. 도 4는 본 개시의 다른 일 실시 예에 따른 에러 판단 방법을 설명하기 위한 도면이다. 도 5는 본 개시의 일 실시 예에 따른 기설정된 값을 제어하는 순서도이다. 도 6은 본 개시의 일 실시 예에 따른 에러 장소를 판단하는 방법을 설명하기 위한 도면이다.도 7은 본 개시의 일 실시 예에 따른 이미지 간 유사도를 판단하는 방법을 설명하기 위한 도면이다. 도 8a는 본 개시의 일 실시 예에 따른 로봇의 제어 방법을 도시한 순서도이다. 도 8b는 본 개시의 다른 일 실시 예에 따른 로봇의 제어 방법을 도시한 순서도이다. 도 9a는 본 개시의 일 실시 예에 따른 로봇 제어 시스템의 동작을 설명하기 위한 시퀀스도이다. 도 9b는 본 개시의 다른 일 실시 예에 따른 로봇 제어 시스템의 동작을 설명하기 위한 시퀀스도이다."}
