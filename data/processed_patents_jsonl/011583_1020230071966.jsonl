{"patent_id": "10-2023-0071966", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0088877", "출원번호": "10-2023-0071966", "발명의 명칭": "데이터 처리 가속기에 사용되는, 난독화 유닛에 의해 난독화 를 진행하는 데이터 전송", "출원인": "바이두 유에스에이 엘엘씨", "발명자": "쳉, 위에챵"}}
{"patent_id": "10-2023-0071966", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "데이터 난독화 해제 방법에 있어서,호스트에 의해 데이터 처리(DP) 가속기로부터 난독화 알고리즘 선택기의 리스트를 수신하고, 상기 리스트로부터선택된 난독화 알고리즘에 기반하여 처리해야 할 데이터에 대해 제1 난독화 처리를 수행하는 단계;상기 데이터 처리(DP) 가속기에 의해 링크를 통해 상기 호스트로부터 트레이닝 요청을 수신하는 단계 - 상기 트레이닝 요청은 난독화 알고리즘 선택기와 제1 난독화 처리된 데이터를 포함하며, 상기 난독화된 데이터는 제1난독화 처리된 하나 또는 복수의 인공 지능(AI) 모델 및 트레이닝 입력 데이터를 포함함 -;상기 DP 가속기의 난독화 유닛에 의해 상기 난독화 알고리즘 선택기에 기반하여 상기 제1 난독화 처리된 데이터에 대해 제1 난독화 해제 처리를 수행하여, 제1 난독화 해제 처리된 하나 또는 복수의 AI 모델과 제1 난독화 해제 처리된 트레이닝 입력 데이터를 획득하는 단계; 상기 DP 가속기에 의해 상기 제1 난독화 해제 처리된 트레이닝 입력 데이터에 기반하여 상기 제1 난독화 해제된하나 또는 복수의 AI 모델을 트레이닝하는 단계;상기 DP 가속기에 의해 상기 난독화 알고리즘에 기반하여, 트레이닝 완료 데이터 또는 트레이닝된 AI모델을 제2난독화 처리를 수행하여 호스트로 송신하는 단계; 및상기 호스트에 의해 상기 난독화 알고리즘에 기반하여, 상기 제2 난독화 처리된 트레이닝 완료 데이터 또는 트레이닝된 AI모델을 제2 난독화 해제 처리하는 단계를 포함하는 방법."}
{"patent_id": "10-2023-0071966", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1 항에 있어서,제1 난독화 해제 처리는 상기 난독화 유닛의 프로세서에 의해 수행되는 단계를 더 포함하는 방법."}
{"patent_id": "10-2023-0071966", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 2 항에 있어서, 상기 난독화 유닛의 프로세서는 상기 DP 가속기의 프로세서와 분리되어, AI 모델 트레이닝 및 난독화 알고리즘을 동시에 수행되도록 하는 방법."}
{"patent_id": "10-2023-0071966", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 2 항에 있어서, 상기 난독화 알고리즘은 대칭 알고리즘임으로, 동일한 알고리즘을 사용하여 상기 난독화 해제 처리 및 난독화처리를 수행하는 방법."}
{"patent_id": "10-2023-0071966", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "명령이 저장된 비일시적 기계 판독 가능 매체에 있어서, 상기 명령이 프로세서에 의해 실행될 경우, 상기 프로세서가 하기 동작을 수행하도록 하며, 상기 동작은,호스트에 의해 데이터 처리(DP) 가속기로부터 난독화 알고리즘 선택기의 리스트를 수신하고, 상기 리스트로부터선택된 난독화 알고리즘에 기반하여 처리해야 할 데이터에 대해 제1 난독화 처리를 수행하는 동작;상기 데이터 처리(DP) 가속기에 의해 링크를 통해 상기 호스트로부터 트레이닝 요청을 수신하는 동작 - 상기 트레이닝 요청은 난독화 알고리즘 선택기와 제1 난독화 처리된 데이터를 포함하며, 상기 난독화된 데이터는 제1난독화 처리된 하나 또는 복수의 인공 지능(AI) 모델 및 트레이닝 입력 데이터를 포함함 -;공개특허 10-2023-0088877-3-상기 DP 가속기의 난독화 유닛에 의해 상기 난독화 알고리즘 선택기에 기반하여 상기 제1 난독화 처리된 데이터에 대해 제1 난독화 해제 처리를 수행하여, 제1 난독화 해제 처리된 하나 또는 복수의 AI 모델과 제1 난독화 해제 처리된 트레이닝 입력 데이터를 획득하는 동작; 상기 DP 가속기에 의해 상기 제1 난독화 해제 처리된 트레이닝 입력 데이터에 기반하여 상기 제1 난독화 해제된하나 또는 복수의 AI 모델을 트레이닝하는 동작;상기 DP 가속기에 의해 상기 난독화 알고리즘에 기반하여, 트레이닝 완료 데이터 또는 트레이닝된 AI모델을 제2난독화 처리를 수행하여 호스트로 송신하는 동작; 및상기 호스트에 의해 상기 난독화 알고리즘에 기반하여, 상기 제2 난독화 처리된 트레이닝 완료 데이터 또는 트레이닝된 AI모델을 제2 난독화 해제 처리하는 동작을 포함하는 매체."}
{"patent_id": "10-2023-0071966", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제 5 항에 있어서, 상기 제1 난독화 해제 처리는 상기 난독화 유닛의 프로세서에 의해 수행되는 매체."}
{"patent_id": "10-2023-0071966", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제 6 항에 있어서, 상기 난독화 유닛의 프로세서는 상기 DP 가속기의 프로세서와 분리되어, AI 모델 트레이닝 및 난독화 알고리즘을 동시에 수행되도록 하는 매체."}
{"patent_id": "10-2023-0071966", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제 6 항에 있어서, 상기 난독화 알고리즘은 대칭 알고리즘임으로, 동일한 알고리즘을 사용하여 상기 난독화 해제 및 난독화를 수행하는 매체."}
{"patent_id": "10-2023-0071966", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "일 실시형태에 따르면, 호스트는 난독화 방안과 데이터 처리를 사용하여 데이터 처리(DP)과 통신한다. 데이터 처리(DP) 가속기는 호스트로부터 트레이닝 요청을 수신하고, 상기 트레이닝 요청은 난독화된 데이터를 포함하며, 상기 난독화된 데이터는 하나 또는 복수의 AI 모델 및/또는 트레이닝 입력 데이터를 포함한다. DP 가속기는 DP 가속기의 난독화 유닛에 의해 난독화된 데이터에 대해 난독화 해제를 수행하여, 하나 또는 복수의 AI 모델을 획 득한다. DP 가속기는 트레이닝 입력 데이터에 기반하여 하나 또는 복수의 AI 모델을 트레이닝한다."}
{"patent_id": "10-2023-0071966", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명의 실시형태는 전체적으로 난독화 다자 연산에 관한 것이다. 보다 구체적으로, 본 발명의 실시형태는 데 이터 처리(DP) 가속기에 사용되는, 난독화 유닛에 의해 난독화 를 진행하는 데이터 전송에 관한 것이다."}
{"patent_id": "10-2023-0071966", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "인공 지능(AI) 가속기 또는 협력 프로세서와 같은 데이터 처리(DP) 가속기는 점점 더 민감한 거래를 수행하고 있다. 이는, DP 가속기의 통신 채널을 보호해야 하고, 또한 호스트 시스템을 무단 액세스로부터 보호하기 위해 호스트 시스템의 환경을 보호해야 하는 수요를 증가시킨다. 예를 들어, AI 트레이닝 데이터, 모델 및 추론을 위해 출력된 데이터 전송을 보호를 받을 수 없으며, 또한, 신 뢰할 수 없는 각 측에 누설될 수 있다. 이밖에, 암호화 키에 기반한 해결수단은 매우 느리고 실용적이지 않을 수 있다. 따라서, 출력을 위한 데이터 전송은 보호되지 않으며 신뢰할 수 없는 당사자에게 유출 될 수 있다. 또 한 암호키 기반 솔루션은 느리고 비실용적일 수 있다. 따라서, 암호키의 사용 여부에 관계없이 DP 가속기의 데 이터 전송이 난독화되도록 하는 시스템이 필요하다."}
{"patent_id": "10-2023-0071966", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명의 실시예들은 데이터 난독화 해제 방법과 비일시적 기계 판독 가능 매체을 제공한다."}
{"patent_id": "10-2023-0071966", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 일 양태에 따르면, 데이터 난독화 해제 방법에 있어서, 데이터 처리(DP) 가속기에 의해 링크를 통해 호스트로부터 트레이닝 요청을 수신하는 단계 - 상기 트레이닝 요청은 난독화된 데이터를 포함하며, 상기 난독화된 데이터는 하나 또는 복수의 인공 지능(AI) 모델 및/또는 트레이닝 입력 데이터를 포함함 -; 상기 DP 가속 기의 난독화 유닛에 의해 상기 난독화된 데이터에 대해 난독화 해제를 수행하여, 상기 하나 또는 복수의 AI 모 델을 획득하는 단계; 및 상기 트레이닝 입력 데이터에 기반하여 상기 하나 또는 복수의 AI 모델을 트레이닝하는 단계를 포함하는 방법을 제공한다. 본 발명의 다른 일 양태에 따르면, 데이터 난독화 방법에 있어서, 호스트에 의해 하나 또는 복수의 인공 지능 (AI) 모델 및 / 또는 트레이닝 입력 데이터를 난독화하여, 난독화된 데이터를 생성하는 단계; 데이터 처리(DP) 가속기에 의해 AI 모델 트레이닝을 수행하기 위한 트레이닝 요청을 생성하는 단계 - 상기 트레이닝 요청은 상기 난독화된 데이터를 포함함 -; 및 상기 DP 가속기에 트레이닝 요청을 전송하는 단계 - 상기DP 가속기의 난독화 유닛은 난독화 알고리즘을 적용하여 하나 또는 복수의 AI 모델 및 / 또는 상기 트레이닝 입력 데이터를 획득하 며, 상기 트레이닝 입력 데이터를 사용하여 상기 하나 또는 복수의 AI 모델을 트레이닝시킴 - 를 포함하는 방법 을 제공한다. 본 발명의 또 다른 일 양태에 따르면, 명령이 저장된 비일시적 기계 판독 가능 매체에 있어서, 상기 명령이 프 로세서에 의해 실행될 경우, 상기 프로세서가 하기 동작을 수행하도록 하며, 상기 동작은, 트데이터 처리(DP) 가속기에 의해 링크를 통해 호스트로부터 트레이닝 요청을 수신하는 동작 - 상기 트레이닝 요청은 난독화된 데 이터를 포함하며, 상기 난독화된 데이터는 하나 또는 복수의 인공 지능(AI) 모델 및/또는 트레이닝 입력 데이터 를 포함함 -; 상기 DP 가속기의 난독화 유닛에 의해 상기 난독화된 데이터에 대해 난독화 해제를 수행하여, 상 기 하나 또는 복수의 AI 모델을 획득하는 동작; 및 상기 트레이닝 입력 데이터에 기반하여 상기 하나 또는 복수 의 AI 모델을 트레이닝하는 동작을 포함하는 매체를 제공한다."}
{"patent_id": "10-2023-0071966", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "아래에서 논의되는 상세한 설명을 참조하여 본 발명의 다양한 실시형태 및 양태를 설명하며, 첨부된 도면은 상 기 다양한 실시형태를 도시한다. 아래 설명과 도면은 본 발명에 대한 설명이지, 본 발명을 한정하려는 것으로 해석되어서는 안된다. 본 발명의 다양한 실시형태에 대한 전반적인 이해를 제공하기 위해 많은 특정 세부사항을 설명한다. 그러나, 어떤 경우에는, 본 발명의 실시형태에 대한 간결한 논의를 제공하기 위해 공지되었거나 통상 적인 세부사항들에 대한 설명은 생략한다. 본 명세서에서 “일 실시형태” 또는 “실시형태”에 대한 언급은 상기 실시형태와 결합하여 설명된 특정된 특 징, 구조 또는 특성이 본 발명의 적어도 일 실시형태에 포함될 수 있음을 의미한다. 본 명세서의 각 부분에 나타나는 문구 “일 실시형태에서”는 전부 동일한 실시형태를 지칭하는 것은 아니다. 본 발명의 제1 양태에 따르면, 호스트는 난독화 해결수단을 사용하여 데이터 처리(DP) 가속기와 통신한다. DP 가속기(또는 시스템)는 난독화 커널 알고리즘(또는 난독화 알고리즘)을 수신하고, 여기서, 난독화 커널 알고리 즘은 호스트와의 통신 데이터에 대해 난독화 및 난독화 해제를 수행하는데 사용된다. 시스템은 난독화 커널 알 고리즘을 사용하여 호스트로부터 수신된, 예측 요청에 사용되는 난독화된 데이터에 대해 난독화 해제를 수행하 여, 하나 또는 복수의 AI 모델을 획득한다. 시스템은 하나 또는 복수의 AI 모델을 예측 입력에 응용하여 예측 결과를 생성한다. 시스템은 난독화 커널 알고리즘을 사용하여 예측 결과에 대해 난독화슬 수행한다. 시스템은 난독화된 예측 결과를 호스트에 송신하며, 여기서, 호스트는 난독화된 예측 결과에 대해 난독화 해제를 수행하 여 예측 결과를 복원시킨다. 본 발명의 제2 양태에 따르면, 시스템은 DP 가속기에 의해 하나 또는 복수의 인공 지능(AI) 모델을 사용하여 AI 예측을 수행하는 예측 요청을 생성하며, 여기서, 상기 예측 요청은 난독화 커널 알고리즘에 기반하여 하나 또는 복수의 AI 모델이 난독화되도록 하는 난독화된 데이터를 포함한다. 시스템은 난독화 커널 알고리즘 및 예측 요 청을 DP 가속기에 송신하며, 여기서, 난독화 커널 알고리즘을 사용하여 난독화된 데이터에 대해 난독화 해제를 수행하여, 예측 결과를 생성하도록 하나 또는 복수의 AI 모델을 획득하고, 여기서, DP 가속기는 난독화 커널 알 고리즘을 사용하여 예측 결과에 대해 난독화를 수행한다. 시스템은 DP 가속기로부터 난독화된 예측 결과를 수신 한다. 시스템은 난독화된 예측 결과에 대해 난독화 해제를 수행하여, 예측 결과를 복원시킨다. 본 발명의 제3 양태에 따르면, 시스템은 DP 가속기에 의해 호스트로부터의 트레이닝 요청을 수신하며, 상기 트 레이닝 요청은 난독화된 데이터를 포함하고, 상기 난독화된 데이터는 하나 또는 복수의 AI 모델 및/또는 트레이 닝 입력 데이터를 포함한다. 시스템은 DP 가속기의 난독화 유닛을 통해 난독화된 데이터에 대해 난독화 해제를 수행하여, 하나 또는 복수의 AI 모델을 획득한다. 시스템은 트레이닝 입력 데이터에 기반하여 하나 또는 복수의 AI 모델을 트레이닝한다. 본 발명의 제4 양태에 따르면, 시스템(예를 들어, 호스트)은 하나 또는 복수의 AI 모델 및/또는 트레이닝 입력 데이터에 대해 난독화를 수행하여 난독화된 데이터를 생성한다. 시스템은 DP 가속기에 의해 AI 모델 트레이닝을 수행하는 트레이닝 요청을 생성하며, 여기서 트레이닝 요청은 난독화된 데이터를 포함한다. 상기 시스템은 DP 가속기에 트레이닝 요청을 송신하며, 여기서 DP 가속기의 난독화 유닛은 난독화 알고리즘을 응용하여 하나 또는 복수의 AI 모델 및/또는 트레이닝 입력 데이터를 획득하고, 여기서, 트레이닝 입력 데이터를 사용하여, 하나 또 는 복수의 AI 모델을 트레이닝한다. 도 1은 일부 실시형태에 따른 호스트 및 데이터 처리(DP) 가속기 사이의 통신을 보호하기 위한 시스템 구성을 도시하는 예시적 블록도이다. 도 1을 참조하면, 시스템 구성은 네트워크를 통해 DP 서버에 통신 가능하게 연결된 하나 또는 복수의 클라이언트 장치(101 내지 102)를 포함하지만, 이에 한정되지 않는다. 클라 이언트 장치(101 내지 102)는 개인용 컴퓨터(예를 들어, 데스크탑 컴퓨터, 랩톱 컴퓨터 및 태블릿 PC), “신 (thin)” 클라이언트, 개인 휴대 정보 단말기(PDA), Web을 지지하는 기기, 스마트 워치 또는 휴대폰(예를 들어, 스마트폰)과 같은 임의의 유형의 클라이언트 장치일 수 있다. 선택 가능하게, 클라이언트 장치(101 내지 102)는 다른 서버일 수 있다. 네트워크는 유선 또는 무선과 같은 근거리 통신망(LAN), 인터넷과 같은 광역 통신망 (WAN) 또는 이들의 조합과 같은 임의의 유형의 네트워크일 수 있다. 서버(예를 들어, 호스트)는 Web 또는 클라우드 서버, 응용 서버, 백엔드 서버 또는 이들의 조합과 같은 임 의의 유형의 서버 또는 서버 클러스터일 수 있다. 서버는 클라이언트 장치(101 내지 102)와 같은 클라이언 트가 서버에 의해 제공되는 리소스 또는 서비스(예컨대, 서버를 통해 DP 가속기에 의해 제공되는 리 소스 및 서비스임)에 액세서하도록 허용하는 인터페이스(미도시)를 더 포함한다. 예를 들어, 서버는 클라 이언트에 다양한 클라우드 서비스(예컨대, 클라우드 스토리지, 클라우드 컴퓨팅 서비스, 머신 러닝 트레이닝 서 비스, 데이터 마이닝 서비스 등임)를 제공하는 클라우드 서버 또는 데이터 센터의 서버일 수 있다. 서버는 프라이빗 클라우드(private cloud), 퍼블릭 클라우드(public cloud) 또는 하이브리드 클라우드(hybrid cloud) 일 수 있는 클라우드 상의 서비스형 소프트웨어(Software-as-a-Service, SaaS) 또는 서비스형 플랫폼 (Platform-as-a-Service, PaaS) 시스템의 일부로 구성될 수 있다. 인터페이스는 Web 인터페이스, 응용 프로그래 밍 인터페이스(Application programming interface, API) 및/또는 명령 라인 인터페이스(command line interface, CLI)를 포함할 수 있다. 예를 들어, 클라이언트(상기 예에서, 클라이언트 장치의 사용자 응용 프로그램(예를 들어, Web 브라우저, 응용 프로그램))는 실행하기 위한 명령(예를 들어, 인공 지능(AI) 트레이닝, 추론 명령 등임)을 서버에 송신하거나 전송하고, 또한 서버는 네트워크 상의 인터페이스를 통해 상기 명령을 수신한다. 상기 명령 에 응답하여, 서버는 명령을 완료하기 위해 DP 가속기(105 내지 107)와 통신을 수행한다. 일부 실시형태에 서, 명령은 머신 러닝 유형의 명령이고, 여기서, DP 가속기는 전용 머신 또는 프로세서로서 서버에 비해 몇 배 빠르게 명령을 실행할 수 있다. 따라서, 서버는 분산형 방식으로 하나 또는 복수의 DP 가속기의 실 행 작업을 제어/관리할 수 있다. 다음, 서버는 실행 결과를 클라이언트 장치(101 내지 102)로 리턴시킨다. DP 가속기 또는 AI 가속기는 바이두(Baidu) 회사의 바이두 인공 지능(AI) 칩셋과 같은 하나 또는 복수의 전용 프로세서를 포함할 수 있거나, 선택 가능하게, DP 가속기는 NVIDIA, Intel 또는 일부 다른 AI 칩셋 제공업체의 AI 칩셋일 수 있다. 일 실시형태에 따르면, 데이터 처리 서버(호스트로 지칭되기도 함)에 의해 호스팅되는 DP 가속기(105 내지 107)의 어느 하나에 액세스하는 응용 프로그램 중 각각은 상기 응용 프로그램이 신뢰 가능한 소스 또는 제공업 체에 의해 제공되는 것임을 검증할 수 있다. 호스트의 중앙처리장치(CPU)에 의해 전문적으로 구성되고 수 행되는 신뢰 가능한 수행 환경 내에서 각각의 응용 프로그램을 작동 및 수행할 수 있다. 응용 프로그램이 DP 가 속기(105 내지 107) 중 어느 하나를 액세스하도록 구성될 경우, 호스트와 DP 가속기(105 내지 107) 중 대 응되는 하나 사이에서 난독화 연결을 구축할 수 있고, 이로써 호스트와 DP 가속기(105 내지 107) 사이에서 교환하는 데이터가 악성 소프트웨어/침입 공격으로부터 보호한다. 도 2는 일부 실시형태에 따른 호스트 시스템 및 데이터 처리(DP) 가속기 사이의 난독화 통신을 위한 다중 계층 보호 해결수단을 도시하는 예시적 블록도이다. 일 실시형태에서, 시스템은 DP 가속기에 대한 하드웨어 수 정의 유무에 관계없이 호스트와 DP 가속기 사이의 난독화 통신을 위한 보호 해결수단을 제공한다. 도 2를 참조 하면, 호스트 또는 서버는 침입으로부터 보호될 하나 또는 복수의 계층(예컨대, 사용자 응용 프로그램 , 실행 시간 라이브러리, 드라이버, 운영체제 및 하드웨어(예를 들어, 안전 모듈(신 뢰 플랫폼 모듈(TPM))/중앙처리장치(CPU)))을 갖는 시스템으로 설명될 수 있다. 호스트는 통상적으로 호스 트 또는 DP 가속기(105 내지 107) 상의 수행 작업을 제어하고 관리할 수 있는 CPU 시스템이다. DP 가속기 (105 내지 107)와 호스트 사이의 통신 채널을 보호/난독화하기 위해, 상이한 부재로 호스트 시스템 중 데 이터 침입 또는 공격에 취약한 상이한 계층을 보호해야 될 수 있다. 예를 들어, 신뢰 실행 환경(TEE)은 데이터 침입으로부터 사용자 응용 프로그램 계층 및 실행 시간 라이브러리 계층을 보호할 수 있다. 도 2를 참조하면, 일부 실시형태에 따르면, 시스템은 호스트 시스템 및 DP 가속기(105 내지 107)를 포함한다. DP 가속기는 AI 집약적 컴퓨팅 작업을 수행할 수 있는 바이두 AI 칩셋 또는 NVIDIA그래픽 처리 장치 (GPU)와 같은 임의의 다른 AI 칩셋을 포함할 수 있다. 일 실시형태에서, 호스트 시스템은 하나 또는 복수 의 CPU를 구비한 하드웨어를 포함하며, 이는 호스트 내에 안전 모듈(예컨대, 신뢰 플랫폼 모듈(TP M))을 구비한다. TPM은 단점 장치(endpoint device) 상의 전용 칩이고, 이는 호스트 시스템에 전문적으로 사용 되는 하드웨어 인증을 위한 암호키(예를 들어, RSA 암호키)를 저장한다. 각각의 TPM 칩은 하나 또는 복수의 RSA 키 쌍(예를 들어, 공개 키 및 비밀 키 쌍)을 포함할 수 있으며, 이는 이서 키(Endorsement key, EK) 또는 이서 자격증(Endorsement certificate, EC), 즉 루트 키(Root key)로 지칭된다. 키 쌍은 TPM 칩 내부에 유지되며, 소프트웨어에 의해 액세스될 수 없다. 다음, 펌웨어 및 소프트웨어의 핵심 부분은 실행 이전에 EK 또는 EC에 의 해 해시(hash)되어, 승인되지 않은 펌웨어 및 소프트웨어 수정으로부터 시스템을 보호할 수 있다. 따라서, 호스 트 상의 TPM 칩은 보안 부팅을 위한 신뢰 루트로 사용할 수 있다. TPM 칩은 또한 작업 커널 공간에서의 드라이버 및 운영체제(OS)가 DP 가속기와 통신하도록 보장한다. 여기서, 드라이버는 DP 가속기 제공업체에 의해 제공되며, 또한 사용자 응용 프로그램의 드라이버로 사용 되어, 호스트 및 DP 가속기 사이의 통신 채널을 제어할 수 있다. TPM 칩 및 보안 부팅은 이의 커널 공간에 서의 OS 및 드라이버를 보호하므로, TPM은 또한 드라이버 및 운영체제를 효과적으로 보호한다. DP 가속기(105 내지 107)의 통신 채널이 OS 및 드라이버에 의해 독점될 수 있기 때문에, 통신 채널은 TPM 칩에 의해 보호받을 수 있다. 일 실시형태에서, 통신 채널은 주변 부재 상호연결 채널 또는 주변 부재 상호연결 익스프레스(PCIE) 채널을 포함한다. 일 실시형태에서, 통신 채널은 난독화한 통신 채널이다. 호스트는 신뢰 실행 환경(TEE)을 포함할 수 있으며, 이는 TPM/CPU의 강제 수행에 의해 보호받는 다. TEE는 안전적인 환경이다. TEE는 TEE 내에 로딩된 코드와 데이터가 기밀성과 무결성 면에서 보호받도록 보 장할 수 있다. TEE의 예는 Intel 소프트웨어 보호 확장(SGX) 또는 AMD 보안 암호화 가상화(SEV) 일 수 있다. Intel SGX 및/또는 AMD SEV는 중앙처리장치(CPU) 명령 코드 집합을 포함할 수 있고, 이는 사용자 수준 코드가 CPU 메모리의 개인 영역을 분배하도록 허용하며, 이러한 영역은 보호를 받음으로써 비교적 높은 권한 수준에서실행되는 프로세스의 영향을 받지 않는다. 여기서, TEE는 사용자 응용 프로그램 및 실행 시간 라이브 러리를 보호할 수 있으며, 여기서 사용자 응용 프로그램 및 실행 시간 라이브러리는 각각 단말 사용자 및 DP 가속기 제공업체에 의해 제공될 수 있다. 여기서, 실행 시간 라이브러리는 API 호출을 DP 가 속기의 실행, 구성 및/또는 제어를 위한 명령으로 변환할 수 있다. 일 실시형태에서, 실행 시간 라이브러리 는 사용자 응용 프로그램에 의해 실행되는 기설정된(예를 들어, 미리 정의된) 커널 집합을 제공한다. 호스트는 메모리 안전 응용 프로그램을 포함할 수 있으며, 이는 메모리 안전 언어(예컨대, Rust 및 GoLang)를 사용하여 구현된다. 메모리 안전 Linux 배포판(예컨대, MesaLock Linux)에서 실행되는 이러한 메모리 안전 응용 프로그램은 데이터 기밀성 및 무결성 공격으로부터 시스템을 더 보호할 수 있다. 그러나, 운영 체제는 임의의 Linux 배포판, UNIX, Windows OS 또는 Mac OS일 수 있다. 호스트는 하기와 같이 설정될 수 있다. 즉 메모리 안전 Linux 배포판을 TPM 보안 부팅이 구비된 시스템에 설치 한다. 해당 설치는 제조 또는 준비 단계 기간에 오프라인으로 수행될 수 있다. 해당 설치는 또한 메모리 안전 프로그래밍 언어를 사용하여 호스트 시스템의 사용자 공간의 응용 프로그램에 대해 프로그래밍하도록 보장할 수 있다. 호스트 시스템에서 실행되는 다른 응용 프로그램이 메모리 안전 응용 프로그램임을 보장하면 호스트 시스템 에 대한 잠재적 기밀성 및 무결성 공격을 더 완화시킬 수 있다. 설치 후 TPM 기반 보안 부팅을 통해 시스템을 부팅할 수 있다. TPM 보안 부팅은 커널 공간 중 가속기 서비스를 제공하는 서명/인증된 운영체제 및 가속기 드라이버만 작동되도록 보장한다. 일 실시형태에서, 슈퍼바이저 프로 그램에 의해 운영체제를 로딩할 수 있다. 슈퍼바이저 프로그램 또는 가상 기계 관리자는 가상 기계를 구축하고 작동시키는 컴퓨터 소프트웨어, 펌웨어 또는 하드웨어임에 유의해야 할 것이다. 커널 공간은 선언적 영역 또는 범위이며, 여기서, 커널(즉, 실행되기 위한 기설정된(예를 들어, 미리 정의된) 함수 집합)은 사용자 응용 프로 그램에 기능과 서비스를 제공하기 위해 식별됨을 유의해야 할 것이다. 시스템의 무결성이 손상되면 TPM 보안 부 팅이 작동될 수 없으며, 또한 시스템을 대신 종료시킬 수 없다. 안전적으로 부팅된 이후, 실행 시간 라이브러리는 TEE를 실행 및 구축하고, TEE는 실행 시간 라 이브러리를 CPU와 연관된 신뢰 가능 메모리 공간에 배치한다. 이어서, TEE에서 사용자 응용 프 로그램을 작동시킨다. 일 실시형태에서, 사용자 응용 프로그램 및 실행 시간 라이브러리는 정적 상태로 링크되어 함께 작동된다. 다른 일 실시형태에서, 우선 TEE에서 사용자 응용 프로그램을 작동시킨 다음, TEE에서 실행 시간 라이브러리를 동적 상태로 로딩한다. 정적 상태로 링크된 라이브러리는 컴파일 타임에 응용 프로그램에 링크된 라이브러리임에 유의해야 한다. 동적 상태 로딩은 동적 상태 링커에 의해 수행 될 수 있다. 동적 상태 링커는 공유 라이브러리를 로딩 및 링크하여 실행 시 사용자 응용 프로그램을 간편하게 실행한다. 여기서, TEE 내의 사용자 응용 프로그램 및 실행 시간 라이브러리는 실행 시 서로 보 여질 수 있으며, 예를 들어, 모든 처리 데이터는 서로 보여질 수 있다. 그러나, 외부로부터의 TEE에 대한 액세 스는 거절된다. 일 실시형태에서, 사용자 응용 프로그램은 단지 실행 시간 라이브러리에 의해 미리 결정된 커널 집합으로 부터 커널을 호출할 수 있다. 다른 일 실시형태에서, 사용자 응용 프로그램 및 실행 시간 라이브러리(20 5)는 부채널 자유 알고리즘(side channel free algorithm)으로 강화하여, 캐시에 기반한 부채널 공격과 같은 부 채널 공격을 방어한다. 부채널 공격은 컴퓨터 시스템 구현으로부터 획득된 정보에 기반한 임의의 공격이며, 구 현된 알고리즘 자체 중 약점(예를 들어, 암호 분석 및 소프트웨어 결함)에 기반한 공격이 아니다. 부채널 공격 의 예는, 가상화 환경 또는 클라우드 환경에서 공유 물리 시스템의 캐시를 모니터링할 수 있는 공격자의 능력에 기반한 공격인 캐시를 포함한다. 강화는 캐시를 차단하고, 알고리즘에 의해 생성된 캐시에 배치된 출력을 포함 할 수 있다. 이어서, 사용자 응용 프로그램 실행이 완료될 경우, 사용자 응용 프로그램은 이의 실행을 종료하고 TEE를 종료한다. 일 실시형태에서, TEE 및/또는 메모리 안전 응용 프로그램은 필수적인 것이 아니며, 예를 들어, 사용 자 응용 프로그램 및/또는 실행 시간 라이브러리는 호스트의 운영체제 환경에 호스팅된다. 일 실시형태에서, 커널 집합은 난독화 커널 알고리즘을 포함한다. 일 실시형태에서, 난독화 커널 알고리즘은 대 칭 또는 비대칭 알고리즘일 수 있다. 대칭 난독화 알고리즘은 동일한 알고리즘을 사용하여 데이터 통신에 대해 난독화 및 난독화 해제를 수행할 수 있다. 비대칭 난독화 알고리즘은 알고리즘 쌍이 필요되며, 여기서 상기 알 고리즘 쌍 중의 첫 번째 알고리즘은 난독화에 사용되고, 상기 알고리즘 쌍 중의 두 번째 알고리즘은 난독화 해 제에 사용되며, 그 반대도 마찬가지이다. 다른 일 실시형태에서, 비대칭 난독화 알고리즘은 데이터 집합의 난독 화에 사용되는 단일 난독화 알고리즘을 포함하지만, 상기 데이터 집합은 난독화 해제를 수행하기 위한 것이 아니며, 예를 들어, 대응되는 난독화 해제 알고리즘이 존재하지 않는다. 난독화는, 통신 메시지를 이해하기 어렵 게 하여(보통 혼란스럽고 불명확한 언어를 사용함), 통신에 대한 예상된 의미에 대해 난독화를 수행하는 것을 가리킨다. 역방향 공학의 경우, 데이터에 대해 난독화를 수행하는 것은 보다 어렵고 보다 복잡하다. 데이터를 전송하기 전에 난독화 알고리즘을 적용하여 데이터 통신에 대해 난독화(암호화/복호화)를 수행함으로써 도청의 기회를 감소시킬 수 있다. 일 실시형태에서, 난독화 알고리즘은 난독화된 데이터에 대해 더 암호화하여, 계층에 대해 부가적으로 보호하는 암호화 해결수단을 더 포함할 수 있다. 대량의 연산이 필요할 수 있는 암호화와 달리, 난독화 알고리즘은 연산을 간소화시킬 수 있다. 일부 난독화 기술은 자모 난독화, 명칭 난독화, 데이터 난독화, 제어 흐름 난독화 등을 포함할 수 있지만 이에 한정되지 않는다. 자모 난독화는 데이터 중 하나 또는 복수의 자모를 특정 대체 문자로 대체하여 데이터를 의미 없게 만드는 프로세스이다. 자모 난독화의 예는, 자모 회전 기능을 포함하며, 여기서, 각각의 자모는 자모표에 따라 기설정된 위치량을 따라 위치를 이동시키거나 회 전시킨다. 또 다른 예는 특정 패턴을 기준으로 자모를 재정렬하거나 자모를 혼잡하게 하는 것이다. 명칭 난독화 는 특정 대상 문자열을 의미없는 문자열로 대체하는 프로세스이다. 제어 흐름 난독화는 알고리즘/AI 모델의 실 제 제어 흐름을 은폐하도록 부가적 코드(데드 코드 삽입, 제어되지 않은 점프 삽입, 교체 구조 삽입)를 이용하 여 프로그램 중 제어 흐름의 순서를 변화시킬 수 있다. 종합적으로, 시스템은 데이터 기밀성 및 무결성의 손실을 피하기 위해 DP 가속기(머신 러닝 모델, 트레이 닝 데이터 및 추론 출력을 포함하는 데이터를 전송하는데 사용됨)에 다중 보호 계층을 제공한다. 시스템은 TPM 기반 보안 부팅 보호 계층, TEE 보호 계층 및 커널 확인/검증 계층을 포함할 수 있다. 또한, 시스템은 호스트상의 다른 응용 프로그램이 메모리 안전 프로그래밍 언어를 사용하여 구현되도록 보장함으로써 메모리 안 전 사용자 공간을 제공할 수 있으며, 이는 잠재적인 메모리 손상/취약성을 제거함으로써 공격을 추가로 제거할 수 있다. 또한, 시스템은 부채널 자유 알고리즘을 사용하여 부채널 공격(예컨대, 캐시 기반 부채널 공격) 을 방어하는 응용 프로그램을 포함할 수 있다. 마지막으로, 실행 시간 라이브러리는 난독화 커널 알고리즘을 제공하여 호스트와 DP 가속기 사이의 데이터 통신 에 대해 난독화를 수행할 수 있다. 일 실시형태에서, 상기 난독화는 암호화 해결수단과 함께 사용될 수 있다. 다른 일 실시형태에서, 난독화는 유일한 보호 해결수단이며, 또한 DP 가속기가 암호화에 기반한 하드웨어가 필 요없도록 한다. 도 3은 일 실시형태에 따른 DP 가속기와 통신하는 호스트를 도시하는 예시적 블록도이다. 도 3을 참조하면, 시 스템은 DP 가속기와 통신하는 호스트의 TEE를 포함할 수 있다. DP 가속기는 영구 저장 장 치 또는 비영구 저장 장치를 포함한다. 저장 장치는 난독화 커널 알고리즘에 사용되는 저장 공 간 및 다른 데이터(예를 들어, AI 모델, 입력/출력 데이터)에 사용되는 저장 공간을 포함할 수 있다. 호스 트의 사용자 응용 프로그램은 DP 가속기의 난독화한 통신 채널(예를 들어, 난독화된 및/또는 암 호화된)을 구축할 수 있다. 호스트는 난독화 커널 알고리즘(커널 실행 시간 라이브러리의 일부 로 사용됨)을 생성하여 난독화한 통신 채널을 구축할 수 있다. 다음, 호스트는 DP 가속기(예를 들어, DP 가속기)에 DP 가속기에 사용되는 난독화 커널 알고리즘을 송신하여, 통신 채널을 통한 임의의 데이터 패킷에 대해 난독화 또는 난독화 해제를 수행한다. 다른 일 실시형태에서, 채널 상의 호스트로부터의 출력 통신 데이터 패킷은 제1 난독화 알고리즘을 사용하고, 채널상의 호스트로부터의 입력 데이터는 제1 난독화 알고리즘과 상이한 제2 난독화 알고리즘을 사용한다. 다른 일 실시형태에서, 통신 채널이 끊기거나 종료 될 경우, 난독화 알고리즘을 다시 구축할 수 있으며, 여기서 호스트에 의해, 상기 통신 채널에 대한 현재 통신 채널 또는 새로운 통신 채널을 생성한다. 다른 일 실시형태에서, 채널에 사용되는 난독화 알고리즘/ 해결수단은 호스트와 다른 DP 가속기(예를 들어, DP 가속기(106 내지 107)) 사이의 다른 채널에 사용되는 난독화 해결수단과 상이하다. 일 실시형태에서, 호스트는 DP 가속기(105 내지 107)의 각각의 통신 세션에 사용되는 난독화 알고리즘을 저장하는 난독화 인터페이스를 포함한다. 호스트와 DP 가속기 사이의 난 독화 통신이 도시되어 있지만, 난독화 통신(예를 들어, 난독화)은 클라이언트(101 내지 102)와 호스트 사 이의 통신 채널과 같은 다른 통신 채널에 적용될 수 있다. 도 4는 일 실시형태에 따른 호스트와 DP 가속기 사이의 난독화 통신 프로토콜을 도시하는 예시적 흐름도이다. 도 4를 참조하면, 도 1의 시스템 또는 도 3의 시스템에 의해 프로토콜의 동작 을 수행할 수 있 다. 일 실시형태에서, 클라이언트 장치(예컨대, 클라이언트 장치(예를 들어, 클라이언트/사용자))는 호스 트에 AI 모델 추론/트레이닝 요청을 송신한다. 상기 요청은 리소스 또는 서비스에 대한 요청(예컨대, 빅데 이터 분석, 모델링, 머신 러닝/트레이닝 미션 등에 대한 요청임)일 수 있으며, 이는 호스트의 하나 또는 복수의 DP 가속기에 의해 완료될 수 있다. 일 실시형태에서, 동작 에서, 호스트는 난독화(예를 들어,난독화된) 통신 채널을 구축하도록 난독화 알고리즘을 준비한다. 난독화 알고리즘은 임의의 유형의 난독화 알고 리즘일 수 있으며, 또한 대칭되거나 비대칭일 수 있다. 동작 에서, 호스트는 DP 가속기에 난독 화 알고리즘을 송신하여, 호스트와 DP 가속기 사이에서 난독화(예를 들어, 난독화된)된 통신 채널을 구축한다. 다음, 호스트는 난독화 알고리즘을 이용하여 페이로드(예를 들어, AI 모델 및/또는 입력 데이터)에 대해 난독화를 수행하고, 난독화된 페이로드(예를 들어, 데이터)를 DP 가속기에 송신한다. 다른 일 실시형태에서, 전용 채널(예를 들어, 데이터와 분리됨)을 경유하여 난독화 알고리즘을 송신할 수 있으며, 상 기 전용 채널은 암호화될 수 있거나 암호화되지 않을 수 있다. 다른 일 실시형태에서, 호스트는 난독화 알 고리즘을 송신하는 시각과 동일하지 않는 시각에 난독화된 데이터를 송신한다. 동작 에서, DP 가속기가 난독화 커널 알고리즘 및 난독화된 데이터 양자를 수신하면, DP 가속기(10 5)는 난독화 알고리즘을 사용하여 난독화된 데이터에 대해 난독화 해제를 수행하여, AI 모델 및/또는 입력 데이 터(AI 추론 또는 트레이닝에 사용됨)와 같은 초기의 데이터를 획득한다. 동작 에서, 요청이 AI 추론 요청 이면, DP 가속기는 입력 데이터를 사용하여 AI 모델을 작동시켜 추론 입력을 생성한다. 요청이 트레이닝 요청이 면, DP 가속기는 트레이닝 입력 데이터에 기반하여 AI 모델에 사용되는 트레이닝 세션을 작동시킨다. 동작 5에서, DP 가속기는 난독화 알고리즘을 사용하여, 생성된 출력에 대해 난독화를 수행한다. 동작 (40 6)에서, DP는 난독화된 출력을 호스트로 리턴시킨다. 동작 에서, 호스트는 난독화된 출력에 대 해 난독화 해제를 수행하여, 초기의 출력을 획득한다. 따라서, 호스트와 DP 가속기 사이의 통신은 침 입자/도청자에 대해 차단된다. 도 5는 일 실시형태에 따른 방법을 도시하는 예시적 흐름도이다. 프로세스는 처리 논리에 의해 수행될 수 있으며, 상기 처리 논리는 소프트웨어, 하드웨어 또는 이들의 조합을 포함할 수 있다. 예를 들어, 프로세스 는 도 1의 DP 가속기와 같은 DP 가속기에 의해 수행될 수 있다. 도 5를 참조하면, 블록 에서, 처리 논리는 난독화 커널 알고리즘을 수신하고, 여기서 난독화 커널 알고리즘은 호스트와 통신하는 데이터에 대 해 난독화 및 난독화 해제를 수행하는데 사용된다. 블록 에서, 처리 논리는 난독화 커널 알고리즘을 사용 하여, 호스트로부터 수신된, 예측 요청에 사용되는 난독화된 데이터에 대해 난독화 해제를 수행하여, 하나 또는 복수의 AI 모델을 획득한다. 블록 에서, 처리 논리는 하나 또는 복수의 AI 모델을 예측 입력에 응용하여 예측 결과를 생성한다. 블록 에서, 처리 논리는 난독화 커널 알고리즘을 사용하여 예측 결과에 대해 난독 화를 수행한다. 블록 에서, 처리 논리는 난독화된 예측 결과를 호스트에 송신하며, 여기서 호스트는 난독 화된 예측 결과에 대해 난독화 해제를 수행하여 예측 결과를 복원시킨다. 일 실시형태에서, 난독화 커널 알고리즘은 호스트에 의해 생성된다. 일 실시형태에서, 난독화된 데이터를 전송 하기 위한 데이터 채널과 상이한 전용 통신 채널에서 난독화 커널 알고리즘을 수신한다. 일 실시형태에서, 난독화된 데이터는 트레이닝 입력 데이터를 포함하고, 또한 트레이닝 입력 데이터를 사용하여 하나 또는 복수의 AI 모델을 트레이닝한다. 일 실시형태에서, 난독화 커널 알고리즘은 대칭 알고리즘이고, 이로 써 동일한 알고리즘을 사용하여 난독화 해제 및 난독화를 수행한다. 일 실시형태에서, 난독화 커널 알고리즘은 명칭에 기반한 난독화 알고리즘이다. 일 실시형태에서, 처리 논리는 또한 호스트로부터 하나 또는 복수의 AI 모델에 대한 요청을 수신하고; 요청된 하나 또는 복수의 AI 모델에 대해 난독화를 수행하며; 또한 난독화된 AI 모델을 호스트에 송신하고, 여기서 호 스트는 난독화된 AI 모델에 대해 난독화 해제를 수행하여 AI 모델을 복원시킨다. 도 6은 일 실시형태에 따른 방법을 도시하는 예시적 흐름도이다. 프로세스는 처리 논리에 의해 수행될 수 있으며, 상기 처리 논리는 소프트웨어, 하드웨어 또는 이들의 조합을 포함할 수 있다. 예를 들어, 프로세스 는 도 1의 호스트에 의해 수행될 수 있다. 도 6을 참조하면, 블록 에서, 처리 논리는 데이터 처 리(DP) 가속기에 의해 하나 또는 복수의 인공 지능(AI) 모델을 사용하여 AI 예측을 수행하는 예측 요청을 생성 하며, 여기서 예측 요청은 난독화 커널 알고리즘에 기반하여 상기 하나 또는 복수의 AI 모델이 난독화되도록 하 는 난독화된 데이터를 포함한다. 블록 에서, 처리 논리는 DP 가속기에 난독화 커널 알고리즘 및 예측 요청 을 송신하며, 여기서 난독화 커널 알고리즘을 사용하여 난독화된 데이터에 대해 난독화 해제를 수행하여, 예측 결과를 생성하도록 하나 또는 복수의 AI 모델을 획득하고, 여기서 DP 가속기는 난독화 커널 알고리즘을 사용하 여 예측 결과에 대해 난독화를 수행한다. 블록 에서, 처리 논리는 DP 가속기로부터 난독화된 예측 결과를 수신한다. 블록 에서, 처리 논리는 난독화된 예측 결과에 대해 난독화 해제를 수행하여, 예측 결과를 복원 시킨다. 일 실시형태에서, 난독화 커널 알고리즘은 호스트에 의해 생성된다. 일 실시형태에서, 난독화된 데이터를 전송 하기 위한 데이터 채널과 상이한 전용 통신 채널에서 난독화 커널 알고리즘을 수신한다. 일 실시형태에서, 난독 화된 데이터는 트레이닝 입력 데이터를 포함하고, 또한 트레이닝 입력 데이터를 사용하여 하나 또는 복수의 AI 모델을 트레이닝한다. 일 실시형태에서, 난독화 커널 알고리즘은 대칭 알고리즘이고, 이로써 동일한 알고리즘을 사용하여 난독화 해제 및 난독화를 수행한다. 다른 일 실시형태에서, 난독화 커널 알고리즘은 명칭에 기반한 난 독화 알고리즘이다. 일 실시형태에서, 처리 논리는 또한 DP 가속기로부터 하나 또는 복수의 AI 모델을 복원하기 위한 요청을 생성하 고; DP 가속기에 요청을 송신하며; DP 가속기로부터 하나 또는 복수의 AI 모델을 나타내는 난독화된 데이터를 수신하고; 및 난독화된 AI 모델에 대해 난독화 해제를 수행하여 AI 모델을 복원시킨다. 도 7은 일 실시형태에 따른 난독화 유닛을 구비한 DP 가속기와 통신하는 호스트를 도시하는 예시적 블록도이다. 도 7을 참조하면, 시스템이 난독화 유닛을 더 포함한 것을 제외한 외, 시스템은 도 3의 시스템 과 유사할 수 있다. 난독화 유닛은 전용 하드웨어 모듈일 수 있으며, 이는 복수의 난독화 알고리즘을 갖는 영구 저장 장치 또는 비영구 저장 장치를 포함한다. 난독화 알고리즘은 제조 또는 준비 단계에서 미 리 설치될 수 있다. 일 실시형태에서, 호스트로부터 난독화 알고리즘을 미리 수신한다. 일 실시형태에서, 난독화 유닛은 난독화/난독화 해제 기능을 수행하도록 하나 또는 복수의 프로세서를 포함한다. 난독 화는 전용 처리로서 난독화 유닛에 의해 수행될 수 있으므로, DP 가속기의 별도의 처리 리소스가 필 요없다. 이는 DP 가속기가 클라이언트에게 서비스를 제공하거나 리소스를 추가하지 않고 트레이닝을 수행 하는 중일 때 유용하다. 이밖에, 난독화 유닛은 난독화 알고리즘을 포함하기 때문에, 통신 세션에 사용되 는 난독화 알고리즘은 호스트로부터 DP 가속기로 전송될 수 있거나, 호스트로부터 DP 가속기로 전송 될 수 없다. 일 실시형태에서, 호스트는 난독화 유닛에 의해 지원되는 대응되는 난독화 알고리즘을 포함한다. 일 실시형태에서, 호스트가 난독화된 데이터를 송신할 경우, 호스트는 데이터를 난독화하기 위한 대응되 는 난독화 알고리즘을 지시하는 인디케이터를 송신한다. 인디케이터(또는 선택기 또는 난독화 알고리즘 선택)는 DP 가속기로부터 호스트로 미리 전송될 수 있고, DP 가속기에 의해 지원되는 사용 가능 난독화 알고리즘을 열거한다. 일 실시형태에서, 난독화 알고리즘 선택에 사용되는 인디케이터는 암호화되거나 암호화되 지 않을 수 있다. 다른 일 실시형태에서, 선택기는 데이터를 난독화하는 데이터 채널과 분리된 채널에서 송신될 수 있다. 도 8은 일 실시형태에 따른 호스트 및 DP 가속기 사이의 난독화 통신을 도시하는 예시적 블록도이다. 도 8을 참 조하면, 도 1의 시스템 또는 도 7의 시스템에 의해 프로토콜의 동작 을 수행할 수 있다. 일 실 시형태에서, 클라이언트 장치(예컨대, 클라이언트 장치(예를 들어, 클라이언트/사용자))는 호스트에 AI 모델 추론/트레이닝 요청을 송신한다. 상기 요청은 리소스 또는 서비스에 대한 요청(예컨대, 빅데이터 분석, 모델링, 머신 러닝/트레이닝 미션 등에 대한 요청임)일 수 있으며, 이는 하나 또는 복수의 DP 가속기에 의해 완 료될 수 있다. 다음, 호스트는 DP 가속기와 통신하여 상기 요청을 실행한다. 일 실시형태에서, 동작 에서, DP 가속기의 난독화 유닛에 의해 지원되는 사용 가능 난독화 알고리즘을 결정하기 위해, 호스 트는 사용 가능 난독화 알고리즘에 대한 요청을 송신한다. 동작 에서, DP 가속기는 상기 요청에 응답하여 난독화 알고리즘 선택기의 리스트로 리턴한다. 일 실시형태에서, 동작 내지 는 선택 가능 하다. 동작 에서, 선택기의 리스트에 기반하여, 호스트는 난독화 알고리즘 중 하나를 선택하고, 난독 화 알고리즘 선택기를 사용하여 서비스 요청을 준비하도록 서비스 요청 페이로드(예를 들어, AI 모델 및/또는 입력 데이터)에 대해 난독화를 수행한다. 동작 에서, 호스트는 알고리즘 선택기를 서비스 요청과 난 독화된 데이터와 함께 DP 가속기에 송신한다. 다른 일 실시형태에서, DP 가속기의 난독화 유닛 이 디폴트 선택기를 포함하거나 한 종류의 난독화 알고리즘만을 지원하는 경우, 알고리즘 선택기는 선택 가능한 파라미터일 수 있고 호스트와 DP 가속기 사이에서 알고리즘 선택기를 통신할 필요가 없다. 동작 에서, DP 가속기는 알고리즘 선택기에 기반하여 난독화된 데이터에 대해 난독화 해제를 수행하 여, AI 모델 및/또는 입력 데이터를 획득한다. 동작 에서, 요청이 트레이닝 요청이면, DP 가속기는 AI 모 델의 트레이닝 세션을 작동시킨다. 일 실시형태에서, 동작 에서, 일단 트레이닝이 완료되면, DP 가속기는 선택기에 기반하여 출력 데이 터(예를 들어, 트레이닝 완료 데이터 또는 트레이닝된 AI 모델)에 대해 난독화를 수행한다. 동작 에서, DP 가속기는 난독화된 출력 데이터를 호스트로 리턴시킨다. 동작 에서, 호스트는 선택기에 기 반하여 상기 데이터에 대해 난독화 해제를 수행하여, 트레이닝 완료 데이터 또는 트레이닝된 AI 모델을 획득한다. 도 9는 일 실시형태에 따른 방법을 도시하는 예시적 흐름도이다. 프로세스는 처리 논리에 의해 수행될 수 있으며, 상기 처리 논리는 소프트웨어, 하드웨어 또는 이들의 조합을 포함할 수 있다. 예를 들어, 프로세스 는 DP 가속기(예를 들어, 도 7의 DP 가속기)에 의해 수행될 수 있다. 도 9를 참조하면, 블록 에 서, 처리 논리는 호스트로부터 트레이닝 요청을 수신하고, 상기 트레이닝 요청은 난독화된 데이터를 포함하며, 난독화된 데이터는 하나 또는 복수의 AI 모델 및/또는 트레이닝 입력 데이터를 포함한다. 블록 에서, 처리 논리는 DP 가속기의 난독화 유닛에 의해 난독화된 데이터에 대해 난독화 해제를 수행하여, 하나 또는 복수의 AI 모델을 획득한다. 블록 에서, 처리 논리는 트레이닝 입력 데이터에 기반하여 하나 또는 복수의 AI 모델을 트레이닝한다. 일 실시형태에서, 처리 논리는 또한 난독화 유닛에 의해 지원되는 복수의 난독화 알고리즘 중 하나를 선택하고, 난독화 유닛의 프로세서에 의해 처리하여, 선택된 난독화 알고리즘에 기반하여 난독화된 데이터에 대해 난독화 해제를 수행한다. 일 실시형태에서, 난독화 유닛의 프로세서는 DP 가속기의 프로세서와 분리되므로, 난독화 알 고리즘 및 AI 모델 트레이닝이 동시에 수행되도록 할 수 있다. 일 실시형태에서, 난독화된 데이터는 트레이닝 입력 데이터를 포함하고, 또한 트레이닝 입력 데이터에 기반하여 AI 모델을 트레이닝한다. 일 실시형태에서, 난독화 커널 알고리즘은 대칭 알고리즘임으로써, 동일한 알고리즘을 사용하여 난독화 해제 및 난독화를 수행한다. 일 실시형태에서, 난독화 커널 알고리즘은 제어 흐름 난독화 알고 리즘이다. 일 실시형태에서, 처리 논리는 또한 호스트로부터 하나 또는 복수의 AI 모델에 대한 요청을 수신하고; 상기 난 독화 유닛에 의해 요청된 하나 또는 복수의 AI 모델에 대해 난독화를 수행하며; 또한 난독화된 AI 모델을 호스 트에 송신하고, 여기서 호스트는 난독화된 AI 모델에 대해 난독화 해제를 수행하여 AI 모델을 복원시킨다. 도 10은 일 실시형태에 따른 방법을 도시하는 예시적 흐름도이다. 프로세스는 처리 논리에 의해 수행될 수 있으며, 상기 처리 논리는 소프트웨어, 하드웨어 또는 이들의 조합을 포함할 수 있다. 예를 들어, 프로세스 는 도 7의 호스트에 의해 수행될 수 있다. 도 10을 참조하면, 블록 에서, 처리 논리는 하나 또는 복수의 인공 지능(AI) 모델 및/또는 트레이닝 입력 데이터에 대해 난독화를 수행하여, 난독화된 데이터를 생성한다. 블록 에서, 처리 논리는 DP 가속기에 의해 AI 모델 트레이닝을 수행하는 트레이닝 요청을 생성 하고, 여기서 트레이닝 요청은 난독화된 데이터를 포함한다. 블록 에서, 처리 논리는 트레이닝 요청을 DP 가속기에 송신하고, 여기서 DP 가속기의 난독화 유닛은 난독화 알고리즘을 응용하여 하나 또는 복수의 AI 모델 및/또는 트레이닝 입력 데이터를 획득하며, 여기서 트레이닝 입력 데이터를 사용하여 하나 또는 복수의 AI 모델 에 대해 트레이닝한다. 일 실시형태에서, 처리 논리는 또한 DP 가속기로부터 트레이닝 결과를 수신한다. 일 실시형태에서, 처리 논리는 또한 DP 가속기의 난독화 유닛에 의해 지원되는 복수의 난독화 알고리즘 중 하나로 난독화 알고리즘을 선택하고, 여기서, 난독화 또는 난독화 해제는 선택된 난독화 알고리즘을 사용하여 DP 가속기의 난독화 유닛의 프로세에 의해 수행된다. 일 실시형태에서, 난독화 유닛의 프로세서는 DP 가속기의 프로세서와 분리되므로, 난독화 알고리즘 및 AI 모델 트레이닝이 동시에 수행되도록 할 수 있다. 일 실시형태에서, 난독화 알고리즘은 대칭 알고리즘이고, 이로써 동 일한 알고리즘을 사용하여 난독화 해제 및 난독화를 수행한다. 일 실시형태에서, 난독화 커널 알고리즘은 제어 흐름 난독화 알고리즘이다. 일 실시형태에서, 처리 논리는 또한 DP 가속기로부터 하나 또는 복수의 AI 모델을 복원하기 위한 요청을 생성하 고; DP 가속기로부터 난독화된 하나 또는 복수의 AI 모델을 나타내는 난독화된 데이터를 수신하며; DP 가속기의 난독화 유닛에 의해 지원되는 복수의 난독화 알고리즘 중 난독화 알고리즘의 지시를 수신하고; 및 상기 지시에 기반하여 난독화된 AI 모델에 대해 난독화 해제를 수행하여 AI 모델을 복원시킨다. 상술한 설명에서 도시되고 설명된 부재 중 일부 또는 전부는 소프트웨어, 하드웨어 또는 이들의 조합에서 구현 될 수 있음에 유의해야 한다. 예를 들어, 해당 부재는 영구 저장 장치 중 소프트웨어에 실장 및 저장되도록 구 현될 수 있으며, 상기 소프트웨어는 프로세서(미도시)를 통해 메모리에 로딩되고 메모리에서 실행되어 본 발명 에 따른 프로세스 또는 작동을 구현할 수 있다. 대체 가능하게, 해당 부재는 전용 하드웨어(예를 들어, 집적 회 로(예를 들어, 전용 집적 회로 또는 ASIC), 디지털 신호 프로세서(DSP) 또는 필드 프로그래머블 게이트 어레이 (FPGA))에 프로그래밍 또는 임베디드되는 실행 가능 코드로 구현될 수 있으며, 상기 실행 가능 코드는 애플리케이션으로부터의 대응되는 드라이버 및/또는 운영체제에 의해 액세스될 수 있다. 이밖에, 해당 부재는 하나 또는 복수의 특정 명령을 통해 소프트웨어 부재에 의해 액세스될 수 있는 명령 집합의 일부로서 프로세서 또는 프로 세서 코어에서 특정 하드웨어 논리로 구현될 수 있다. 도 11은 본 발명의 일 실시형태와 함께 사용될 수 있는 데이터 처리 시스템의 예시적 블록도를 나타낸다. 예를 들어, 시스템은 상술한 호스트 또는 DP 가속기(105 내지 107)와 함께 기술된 상기 프로세스 또는 방 법 중 어느 하나를 수행하는 임의의 데이터 처리 시스템을 나타낼 수 있다. 시스템은 다양한 부재를 포함할 수 있다. 이러한 부재는 집적 회로(IC), 집적 회로의 일부, 개별 전자 장 치, 또는 회로기판(예를 들어, 컴퓨터 시스템의 마더보드 또는 삽입카드)에 적용되는 다른 모듈로 구현될 수 있 거나 다른 방식으로 컴퓨터 시스템의 랙 내에 통합된 부재로 구현될 수 있다. 또한 시스템은 컴퓨터 시스템의 많은 부재의 높은 수준의 투시도를 나타내기 위한 것을 목적으로 함에 유 의해야 한다. 그러나, 일부 실시형태는 부가적인 부재를 구비할 수 있으며, 이밖에, 다른 실시형태는 도시된 부 재의 상이한 구성을 나타낼 수 있음을 이해해야 할 것이다. 시스템은 데스크톱 컴퓨터, 랩톱 컴퓨터, 태 블릿 PC, 서버, 휴대폰, 미디어 플레이어, 개인 휴대 정보 단말기(PDA), 스마트 워치, 개인 커뮤니케이터, 게임 장치, 네트워크 라우터 또는 허브, 무선 액세스 포인트(wireless access point, AP) 또는 리피터, 셋톱 박스 또 는 이들의 조합을 나타낼 수 있다. 이밖에, 단일 기계 또는 시스템만 도시되어 있지만, 용어 “기계” 또는 “ 시스템”은 또한 하나(또는 복수)의 명령 집합을 독립적으로 또는 공동으로 실행하여 본문에서 논의된 어느 하 나 또는 다수의 방법을 수행하는 기계 또는 시스템의 임의의 집합을 포함하도록 이해되어야 한다. 일 실시형태에서, 시스템은 버스 또는 인터커넥터에 의해 연결되는 프로세서, 메모리 및 장치(1505 내지 1508)를 포함한다. 프로세서는 단일 프로세서 코어 또는 복수의 프로세서 코어를 포함 하는 단일 프로세서 또는 복수의 프로세서를 나타낼 수 있다. 프로세서는 마이크로 프로세서, 중앙처리장 치(CPU) 등과 같은 하나 또는 복수의 일반 프로세서를 나타낼 수 있다. 보다 구체적으로, 프로세서는 복 합 명령 집합 컴퓨팅(Complex Instruction Set Computing, CISC) 마이크로 프로세서, 축소 명령 집합 컴퓨팅 (Reduced Instruction Set Computing, RISC) 마이크로 프로세서, 훨씬 긴 명령어(Very Long Instruction Word, VLIW) 마이크로 프로세서 또는 다른 명령 집합을 구현하는 프로세서, 또는 명령 집합 조합을 구현하는 프로세서 일 수 있다. 프로세서는 또한, 전용 집접 회로(ASIC), 셀룰러 또는 베이스밴드 프로세서, 필드 프로그래 머블 게이트 어레이(FPGA), 디지털 신호 프로세서(DSP), 네트워크 프로세서, 그래픽 프로세서, 네트워크 프로세 서, 통신 프로세서, 암호화 프로세서, 코프로세서(co-processor), 임베디드 프로세서, 또는 명령을 처리할 수 있는 임의의 다른 유형의 논리와 같은 하나 또는 복수의 전용 프로세서일 수 있다. 프로세서(초 저전압 프로세서와 같은 저전력 멀티 코어 프로세서 소켓일 수 있음)는 상기 시스템의 다양 한 부재와 통신하기 위한 마스터 처리 장치 및 중앙 허브로서 기능할 수 있다. 이러한 프로세서는 시스템 온 칩 (SoC)으로 구현될 수 있다. 프로세서는 본문에서 논의된 작동과 단계를 수행하기 위한 명령을 실행하도록 구성된다. 시스템은 선택 가능한 그래픽 서브시스템과 통신하는 그래픽 인터페이스를 더 포함할 수 있고, 그래픽 서브시스템은 디스플레이 제어기, 그래픽 프로세서 및/또는 디스플레이 장치를 포함할 수 있다. 프로세서는 메모리와 통신할 수 있고, 일 실시형태에서, 메모리는 주어진 양의 시스템 스토 리지를 제공하기 위해 복수의 메모리 장치에 의해 구현될 수 있다. 메모리는 랜덤 액세스 메모리(RAM), 동적 RAM(DRAM), 동기화 DRAM(SDRAM), 정적 RAM(SRAM), 또는 다른 유형의 저장 장치와 같은 하나 또는 복수의 휘발성 메모리(또는 메모리) 장치를 포함할 수 있다. 메모리는 프로세서 또는 임의의 다른 장치에 의해 실행되는 명령 시퀀스를 포함하는 정보를 저장할 수 있다. 예를 들어, 다양한 운영체제, 장치 드라이버, 펌웨어(예를 들어, 입력/출력 베이스 시스템 또는 BIOS) 및/또는 애플리케이션의 실행 가능 코드 및/또는 데이 터는 메모리에 로딩될 수 있고 프로세서에 의해 실행될 수 있다. 운영체제는 Microsoft®회사의 Windows® 운영체제, 애플회사의 MacOS®/iOS®, Google®회사의 Android®, LINUX®, UNIX®, 또는 VxWorks와 같은 다른 실시간 또는 임베디드 운영체제와 같은 임의의 유형의 운영체제일 수 있다. 시스템은 네트워크 인터페이스 장치, 선택 가능한 입력 장치, 및 다른 선택 가능한 IO장치 를 포함하는 장치(1505 내지 1508)와 같은 IO장치를 더 포함할 수 있다. 네트워크 인터페이스 장치(150 5)는 무선 트랜시버 및/또는 네트워크 인터페이스 카드(NIC)를 포함할 수 있다. 상기 무선 트랜시버는 WiFi 트 랜시버, 적외선 트랜시버, 블루투스 트랜시버, WiMax트랜시버, 무선 셀룰러폰 트랜시버, 위성 트랜시버(예를 들어, 위성항법시스템(GPS) 트랜시버) 또는 다른 무선주파수 트랜시버 또는 이들의 조합일 수 있다. NIC는 이더넷 카드일 수 있다. 입력 장치는 마우스, 터치 패드, 터치 센시티브 스크린(이는 디스플레이 장치와 통합될 수 있음), 포인터 장치(스타일러스와 같음) 및/또는 키보드(예를 들어, 물리적 키보드 또는 터치 센시티브 스크린의 일부 로서 디스플레이되는 가상 키보드임)를 포함할 수 있다. 예를 들어, 입력 장치는 터치 스크린에 연결되는 터치 스크린 제어기를 포함할 수 있다. 터치 스크린 및 터치 스크린 제어기는, 예를 들어, 다양한 터치 센시티 브 기술(전기용량, 전기저항, 적외선 및 표면 탄성파 기술을 포함하지만 이에 한정되지 않음) 중 어느 하나, 및 다른 근접 센서 어레이 또는 터치 스크린과의 터치를 결정하기 위한 하나 또는 복수의 포인트의 다른 소자를 사 용하여 그 접촉 및 이동 또는 중단을 검출할 수 있다. IO장치는 오디오 장치를 포함할 수 있다. 오디오 장치는 음성 인식, 음성 복사, 디지털 기록 및/또는 전 화 기능과 같은 음성 지원 기능을 추진하기 위해 스피커 및/또는 마이크로폰을 포함할 수 있다. 다른 IO장치 는 범용질렬버스(universal serial bus, USB) 포트, 병렬 포트, 직렬 포트, 프린터, 네트워크 인터페이 스, 버스 브리지(예를 들어, PCI-PCI 브리지), 센서(예를 들어, 가속도계 운동 센서, 자이로스코프, 자력계, 광 센서, 컴퍼스, 근접 센서 등) 또는 이들의 조합을 더 포함할 수 있다. 장치는 이미지 처리 서브시스템(예 를 들어, 카메라)을 더 포함할 수 있으며, 상기 이미지 처리 서브시스템은 카메라 기능(예를 들어, 사진 및 비 디오 클립을 기록함)을 구현하기 위한 전하결합장치(CCD) 또는 상보성 금속산화물 반도체(CMOS) 광학 센서와 같 은 광학 센서를 포함할 수 있다. 일부 센서는 센서 허브(미도시)를 통해 인터커넥터에 연결될 수 있는 반 면, 키보드 또는 열 센서와 같은 다른 장치는 시스템의 구체적 구성 또는 설계에 따라 임베디드 제어기 (미도시)에 의해 제어될 수 있다. 데이터, 애플리케이션, 하나 또는 복수의 운영체제 등과 같은 정보에 대한 영구 저장을 제공하기 위해, 대용량 저장 장치(미도시)도 프로세서에 연결될 수 있다. 다양한 실시형태에서, 보다 얇고 보다 가벼운 시스템 설계를 구현하고 또한 시스템 응답성을 개선하기 위해, 이러한 대용량 저장 장치는 솔리드 스테이트 장치(SSD) 를 통해 구현될 수 있다. 그러나, 다른 실시형태에서, 대용량 저장 장치는 주로 하드 디스크 드라이브(HDD)를 사용하여 구현될 수 있으며, 여기서 비교적 적은 량의 SSD 저장 장치는 전원 차단 사건 기간에 컨텍스트 상태 및 다른 이러한 유형의 정보의 비휘발성 저장을 구현하기 위해 SSD 캐시로서 작용하며, 이로써 시스템 활동이 다시 작동될 경우 빠른 전원 공급을 구현하도록 할 수 있다. 이밖에, 플래시 장치는 예를 들어, 직렬 주변 장치 인터페이스(SPI)를 통해 프로세서에 연결될 수 있다. 이러한 플래시 장치는 시스템의 기초 입력/출력 소 프트웨어(BIOS) 및 기타 펌웨어를 포함하는 시스템 소프트웨어의 비휘발성 저장을 제공할 수 있다. 저장 장치는 본문에 설명된 임의의 하나 또는 다수의 방법 또는 기능을 수행하는 하나 또는 복수의 명령 집합 또는 소프트웨어(예를 들어, 모듈, 유닛 및/또는 논리)가 포함되는 컴퓨터 액세스 가능 저장 매체 (기계 판독 가능 저장 매체 또는 컴퓨터 판독 가능 매체라고도 함)를 포함할 수 있다. 처리 모듈/유닛/논 리는 예를 들어, 상술한 도 1의 호스트 또는 도 3 또는 도 7의 DP 가속기 등 부재 중의 어느 하나를 나타낼 수 있다. 처리 모듈/유닛/논리는 또한 데이터 처리 시스템, 메모리 및 프로세 서에 의해 실행되는 기간에 메모리 내 및/또는 프로세서 내에 완전하게 또는 적어도 일부가 체류될 수 있으며, 데이터 처리 시스템, 메모리 및 프로세서도 기계 액세스 가능 저장 매체 를 구성한다. 처리 모듈/유닛/논리는 또한 네트워크를 통해 네트워크 인터페이스 장치에 의해 전송 되거나 수신될 수 있다. 컴퓨터 판독 가능 저장 매체는 또한 상술한 일부 소프트웨어 기능을 영구적으로 저장하는데 사용될 수 있 다. 예시적 실시형태에서, 컴퓨터 판독 가능 저장 매체는 단일 매체로서 예시되었지만, 용어 “컴퓨터 판 독 가능 저장 매체”는 상기 하나 또는 복수의 명령 집합을 저장하는 단일 매체 또는 복수의 매체(예를 들어, 집중식 또는 분산식 데이터베이스 및/또는 관련 캐시 및 서버)를 포함하는 것으로 간주해야 한다. 용어 “컴퓨 터 판독 가능 저장 매체”는 또한 명령 집합을 저장하거나 코딩할 수 있는 임의의 매체를 포함하는 것으로 간주 해야 하며, 상기 명령 집합은 기계에 의해 실행되고 또한 상기 기계가 본 발명의 어느 하나 또는 다수의 방법을 수행하도록 한다. 따라서, 용어 “컴퓨터 판독 가능 저장 매체”는 솔리드 스테이트 메모리 및 광학 매체와 자 성 매체, 또는 임의의 다른 비일시적 기계 판독 가능 매체를 포함하지만 이에 한정되지 않는 것으로 간주해야 한다. 본문에 설명된 처리 모듈/유닛/논리, 부재 및 다른 특징은 개별 하드웨어 부재로 구현될 수 있거나 하드 웨어 부재(예를 들어, ASICS, FPGA, DSP 또는 유사한 장치)의 기능에 통합될 수 있다. 이밖에, 처리 모듈/유닛/논리는 하드웨어 장치 내의 펌웨어 또는 기능 회로로 구현될 수 있다. 이밖에, 처리 모듈/유닛/논리 는 하드웨어 장치와 소프트웨어 부재의 임의의 조합으로 구현될 수 있다. 유의해야 할 것은, 시스템이 데이터 처리 시스템의 다양한 부재를 갖는 것으로 도시되어 있지만, 부재를 상호 연결하는 임의의 특정 구조 또는 방식을 나타내도록 의도되지 않았는데, 이는 이러한 세부 사항과 본 발명 의 실시형태가 밀접한 관계가 없기 때문이다. 더 이해해야 할 것은, 보다 적은 부재 또는 가능하게 보다 많은 부재를 갖는 네트워크 컴퓨터, 휴대용 컴퓨터, 휴대폰, 서버 및/또는 다른 데이터 처리 시스템도 본 발명의 실 시형태와 함께 사용될 수 있다. 전술한 상세한 설명의 일부는 컴퓨터 메모리 내의 데이터 비트에 대한 연산의 알고리즘 및 부호 표시에 따라 나 타난다. 이러한 알고리즘의 설명과 표시는 데이터 처리 분야의 당업자가 작업 내용을 본 분야의 다른 기술자에 게 가장 효과적으로 전달하기 위해 사용되는 방식이다. 본문에서, 알고리즘은 통상적으로 바라는 결과를 초래하 는 일관된 동작 시퀀스인 것으로 간주된다. 이러한 작동은 물리량에 대해 물리적으로 작동 및 제어해야 하는 작 동을 가리킨다. 그러나 모든 이러한 유사한 용어는 적절한 물리량과 관련되도록 의도된 것이며, 단지 이러한 양에 응용되기 위 한 간편한 표기일 뿐이다. 이상 논의에서 달리 명시되지 않는 한, 명세서 전체에서, 용어(청구범위에 기술된 용 어와 같음)를 이용하여 진행한 논의는 컴퓨터 시스템 또는 유사 전자 컴퓨팅 장치의 동작 및 처리를 지칭하는 것으로 이해해야 하며, 상기 컴퓨터 시스템 또는 전자 컴퓨팅 장치는 컴퓨터 시스템의 레지스터 및 메모리 내의 물리(전자)량으로 표시되는 데이터를 조절하고, 상기 데이터를 컴퓨터 시스템 메모리 또는 레지스터 또는 다른 유형의 정보 저장 장치, 전송 또는 디스플레이 장치 내 유사하게 물리량으로 표시되는 다른 데이터로 변환시킨 다. 도면에 도시된 기술은 하나 또는 복수의 전자 장치에 저장 및 실행되는 코드 및 데이터를 사용하여 구현될 수 있다. 이러한 전자 장치는 비일시적 컴퓨터 판독 가능 매체(예를 들어, 자기 디스크; 광 디스크; 랜덤 액세스 메모리; 읽기 전용 메모리; 플래시 메모리 장치; 위상 변화 메모리 등) 및 일시적 컴퓨터 판독 가능 전송 매체 (예를 들어, 전기, 광학, 음향 또는 다른 형태의 전파 신호(예컨대, 반송파, 적외선 신호, 디지털 신호))와 같 은 컴퓨터 판독 가능 매체를 사용하여, 코드 및 데이터를 저장하고 전송(내부적으로 전송 및/또는 네트워크 및 다른 전자 장치를 통해 전송함)한다. 전술한 도면에 도시된 프로세스 또는 방법은 하드웨어(예를 들어, 회로, 전용 논리 등), 펌웨어, 소프트웨어(예 를 들어, 비일시적 컴퓨터 판독 가능 매체에 구현됨) 또는 이들의 조합을 포함하는 처리 논리에 의해 수행될 수 있다. 상기 프로세스 또는 방법이 일부 순차적 동작에 의해 설명되었지만, 상기 작동 중 일부는 상이한 순서에 따라 수행될 수 있음을 이해해야 한다. 이밖에, 일부 작동은 순차적이 아니라 병렬로 수행될 수 있다. 상기 명세서에서, 본 발명의 구체적인 예시적 실시형태를 참조하여 본 발명의 실시형태를 설명한다. 청구범위에 기술된 본 발명의 보다 광범위한 사상 및 범위를 벗어나지 않으면서 본 발명에 대해 다양한 수정을 진행할 수 있음은 자명한 것이다. 따라서, 본 명세서와 도면은 한정적 의미가 아닌 설명적 의미로 이해되어야 한다.도면 도면1 도면2 도면3 도면4 도면5 도면6 도면7 도면8 도면9 도면10 도면11"}
{"patent_id": "10-2023-0071966", "section": "도면", "subsection": "도면설명", "item": 1, "content": "본 발명의 실시형태는 첨부된 도면의 각 도면에서 예시적인 방식으로 도시되고, 이에 한정되지 않으며, 도면에 서 유사한 도면 부호는 유사한 요소를 나타낸다. 도 1은 일부 실시형태에 따른 호스트 및 데이터 처리(DP) 가속기 사이의 통신을 보호하기 위한 시스템 구성을 도시하는 예시적 블록도이다. 도 2는 일부 실시형태에 따른 호스트 및 데이터 처리(DP) 가속기 사이의 난독화 통신을 위한 다중 계층 보호 해 결수단을 도시하는 예시적 블록도이다. 도 3은 일 실시형태에 따른 DP 가속기와 통신하는 호스트를 도시하는 예시적 블록도이다. 도 4는 일 실시형태에 따른 호스트와 DP 가속기 사이의 난독화 통신을 도시하는 예시적 흐름도이다. 도 5는 일 실시형태에 따른 방법을 도시하는 예시적 흐름도이다. 도 6은 일 실시형태에 따른 방법을 도시하는 예시적 흐름도이다. 도 7은 일 실시형태에 따른 난독화 유닛을 구비한 DP 가속기와 통신하는 호스트를 도시하는 예시적 블록도이다. 도 8은 일 실시형태에 따른 호스트 및 DP 가속기 사이의 난독화 통신을 도시하는 예시적 블록도이다. 도 9는 일 실시형태에 따른 방법을 도시하는 예시적 흐름도이다. 도 10은 일 실시형태에 따른 방법을 도시하는 예시적 흐름도이다. 도 11은 일 실시형태에 따른 데이터 처리 시스템을 도시하는 블록도이다."}
