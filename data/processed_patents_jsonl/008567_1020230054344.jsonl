{"patent_id": "10-2023-0054344", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0171859", "출원번호": "10-2023-0054344", "발명의 명칭": "사물 식별 장치 및 이를 이용한 입체 영상 생성 방법", "출원인": "기산전자 주식회사", "발명자": "장상환"}}
{"patent_id": "10-2023-0054344", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "지지대모듈을 통해 회전 또는 이동하며, 베이스모듈의 사물을 다양한 위치나 각도에서 촬영하는 적어도 하나의카메라모듈; 및상기 카메라모듈이 사물의 다양한 위치나 각도에서 촬영한 영상을 바탕으로 사물의 입체 영상을 생성하고, 상기사물의 입체 영상을 이용하여 상기 사물에 대한 복수의 가상의 2D 이미지를 생성하거나 상기 사물을 식별하는프로세서를 포함하는 것을 특징으로 하는 사물 식별 장치."}
{"patent_id": "10-2023-0054344", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1항에 있어서, 상기 사물의 정교한 영상 촬영을 지원하기 위한 구조광;을 더 포함하고,상기 구조광은,상기 사물 식별 장치 내의 지정된 위치에 장착되거나, 상기 카메라모듈에 장착되는 것을 특징으로 하는 사물 식별 장치."}
{"patent_id": "10-2023-0054344", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 1항에 있어서, 상기 프로세서는,상기 사물을 식별하기 위한 학습을 수행하며,상기 카메라모듈을 이용하여 촬영한 영상으로부터 측정한 사물의 깊이 정보를 바탕으로 상기 사물이 다른 사물과 겹쳐 있는지 여부를 판단하는 것을 특징으로 하는 사물 식별 장치."}
{"patent_id": "10-2023-0054344", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 1항에 있어서, 상기 프로세서는,사물의 2D 정보 및 깊이 정보를 바탕으로 사물의 형상별 특징을 분류하며,상기 2D 정보 및 깊이 정보는,영상 데이터(IMAGE DATA), 컬러(COLORS), 사이즈(SIZE), 형태(SHAPE), 위치(POSITION), 트랜잭션 히스토리(TRANSACTION HISTORY), 지오메트리(GEOMETRY), 및 밝기(BRIGHTNESS) 정보 중 적어도 하나 이상을 포함하는 것을 특징으로 하는 사물 식별 장치."}
{"patent_id": "10-2023-0054344", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제 3항에 있어서, 상기 사물을 식별하기 위한 학습은, 상기 사물 식별 장치와 통신모듈을 통해 유선 또는 무선으로 연결된 서버나 미리 지정된 클라우드에서공개특허 10-2023-0171859-3-수행되며,상기 서버나 미리 지정된 클라우드에서 수행된 학습 결과가 다시 전송되어 데이터베이스에 저장됨으로써, 상기프로세서가 상기 학습 결과를 사물 식별에 이용하는 것을 특징으로 하는 사물 식별 장치."}
{"patent_id": "10-2023-0054344", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제 1항에 있어서, 상기 프로세서는,상기 카메라모듈이 촬영한 영상에서 사물의 좌표 정보를 공유함으로써, 촬영 영상마다 사물의 위치를 검출하지않고, 상기 좌표 정보를 바탕으로 촬영 영상에서 동일한 사물을 식별하는 것을 특징으로 하는 사물 식별 장치."}
{"patent_id": "10-2023-0054344", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "프로세서가 지지대모듈을 통해 회전 또는 이동하는 적어도 하나의 카메라모듈을 이용해 베이스모듈의 사물을 다양한 위치나 각도에서 촬영하는 단계;상기 카메라모듈이 사물의 다양한 위치나 각도에서 촬영한 영상을 바탕으로 상기 프로세서가 사물의 입체 영상을 생성하는 단계;상기 사물의 입체 영상을 이용하여, 상기 프로세서가 상기 사물에 대한 복수의 가상의 2D 이미지를 생성하거나상기 사물을 식별하는 단계를 포함하는 것을 특징으로 하는 사물 식별 장치를 이용한 입체 영상 생성 방법."}
{"patent_id": "10-2023-0054344", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제 7항에 있어서, 상기 프로세서가 상기 사물의 입체 영상을 이용하여 상기 사물에 대한 복수의 가상의 2D 이미지를 생성하고 상기 가상의 2D 이미지를 이용하여 상기 사물을 식별하기 위한 학습을 수행하는 단계; 및상기 프로세서가,상기 카메라모듈을 이용하여 촬영한 영상으로부터 측정한 사물의 깊이 정보를 바탕으로 상기사물이 다른 사물과 겹쳐 있는지 여부를 판단하는 단계;를 더 포함하는 것을 특징으로 하는 사물 식별 장치를이용한 입체 영상 생성 방법."}
{"patent_id": "10-2023-0054344", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제 7항에 있어서, 상기 사물을 식별하기 위하여,상기 프로세서는,사물의 2D 정보 및 깊이 정보를 바탕으로 사물의 형상별 특징을 분류하며,상기 2D 정보 및 깊이 정보는,영상 데이터(IMAGE DATA), 컬러(COLORS), 사이즈(SIZE), 형태(SHAPE), 위치(POSITION), 트랜잭션 히스토리(TRANSACTION HISTORY), 지오메트리(GEOMETRY), 및 밝기(BRIGHTNESS) 정보 중 적어도 하나 이상을 포함하는 것을 특징으로 하는 사물 식별 장치를 이용한 입체 영상 생성 방법."}
{"patent_id": "10-2023-0054344", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제 8항에 있어서, 상기 사물을 식별하기 위한 학습이, 공개특허 10-2023-0171859-4-상기 사물 식별 장치와 통신모듈을 통해 유선 또는 무선으로 연결된 서버나 미리 지정된 클라우드에서 수행될경우, 상기 서버나 미리 지정된 클라우드에서 수행된 학습 결과를 전송받아 데이터베이스에 저장하는 단계;를 더 포함하고, 상기 프로세서는 상기 학습 결과를 사물 식별에 이용하는 것을 특징으로 하는 사물 식별 장치를 이용한 입체 영상 생성 방법."}
{"patent_id": "10-2023-0054344", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제 7항에 있어서, 상기 프로세서는,상기 카메라모듈이 촬영한 영상에서 사물의 좌표 정보를 공유함으로써, 촬영 영상마다 사물의 위치를 검출하지않고, 상기 좌표 정보를 바탕으로 촬영 영상에서 동일한 사물을 식별하는 것을 특징으로 하는 사물 식별 장치를이용한 입체 영상 생성 방법."}
{"patent_id": "10-2023-0054344", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 사물 식별 장치에 관한 것으로, 지지대모듈을 통해 회전 또는 이동하며, 베이스모듈의 사물을 다양한 위치나 각도에서 촬영하는 적어도 하나의 카메라모듈; 및 상기 카메라모듈이 사물의 다양한 위치나 각도에서 촬 영한 영상을 바탕으로 사물의 입체 영상을 생성하고, 상기 사물의 입체 영상을 이용하여 상기 사물에 대한 복수 의 가상의 2D 이미지를 생성하거나 상기 사물을 식별하는 프로세서를 포함하는 것을 특징으로 한다."}
{"patent_id": "10-2023-0054344", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 사물 식별 장치 및 이를 이용한 입체 영상 생성 방법에 관한 것으로, 보다 상세하게는 사물을 촬영하 여 식별하는 시스템에서 회전이나 이동하는 카메라를 이용하여 입체 영상을 생성할 수 있도록 하는 사물 식별 장치 및 이를 이용한 입체 영상 생성 방법에 관한 것이다."}
{"patent_id": "10-2023-0054344", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "최근 다수의 사업장에서 무인 결제 창구가 설치되고 있으며, 또한 관리자가 없이 무인 결제 시스템만으로 운영 되는 점포도 증가하고 있다. 이러한 무인 결제 시스템은, 기존에는 사용자가 바코드 리더기를 통해 사물(예 : 상품)의 바코드를 하나씩 인식 시켜야 하는 방식이 주로 사용되었으나, 최근에는 물품 받침대 위에 놓여 있는 단일 또는 복수의 사물(예 : 상 품)들을 촬영하여 한번에 인식(식별)하는 방식으로 전환되고 있다. 그런데 무인 결제 시스템의 식별력이 낮아 물품 받침대에 놓여 있는 사물을 정확히 식별하지 못함으로써, 결제 할 금액에 오류가 발생하여 점포나 사용자에게 손실을 발생시킬 수 있는 문제점이 있다. 따라서 이러한 문제점을 방지하기 위해서 사물의 식별력을 향상시킬 수 있도록 하는 기술이 필요한 상황이다."}
{"patent_id": "10-2023-0054344", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 2, "content": "본 발명의 배경기술은 대한민국 공개특허 10-2023-0015618호(2023.01.31.)에 개시되어 있다."}
{"patent_id": "10-2023-0054344", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 상기와 같은 문제점을 해결하기 위한 것으로서, 사물을 촬영하여 식별하는 시스템에서 회전이나 이동 하는 카메라를 이용하여 입체 영상을 생성할 수 있도록 하는 사물 식별 장치 및 이를 이용한 입체 영상 생성 방 법을 제공하는 데 그 목적이 있다."}
{"patent_id": "10-2023-0054344", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 일 측면에 사물 식별 장치는, 지지대모듈을 통해 회전 또는 이동하며, 베이스모듈의 사물을 다양한 위치나 각도에서 촬영하는 적어도 하나의 카메라모듈; 및 상기 카메라모듈이 사물의 다양한 위치나 각도에서 촬 영한 영상을 바탕으로 사물의 입체 영상을 생성하고, 상기 사물의 입체 영상을 이용하여 상기 사물에 대한 복수 의 가상의 2D 이미지를 생성하고, 상기 사물에 대한 복수의 가상의 2D 이미지를 이용하여 사물을 식별하기 위한 학습을 수행하는 프로세서를 포함하는 것을 특징으로 한다.본 발명의 일 측면에 사물 식별 장치를 이용한 입체 영상 생성 방법은, 프로세서가 지지대모듈을 통해 회전 또 는 이동하는 적어도 하나의 카메라모듈을 이용해 베이스모듈의 사물을 다양한 위치나 각도에서 촬영하는 단계; 상기 카메라모듈이 사물의 다양한 위치나 각도에서 촬영한 영상을 바탕으로 상기 프로세서가 사물의 입체 영상 을 생성하는 단계; 상기 사물의 입체 영상을 이용하여, 상기 프로세서가 상기 사물에 대한 복수의 가상의 2D 이 미지를 생성하는 단계; 및 상기 프로세서가 상기 사물에 대한 복수의 가상의 2D 이미지를 이용하여 사물을 식별 하기 위한 학습을 수행하는 단계를 포함하는 것을 특징으로 한다."}
{"patent_id": "10-2023-0054344", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명은 카메라를 회전시키거나 이동시킴으로써 하나의 카메라를 이용하더라도 사물을 다각도로 또는 입체적 으로 촬영할 수 있도록 한다. 또한 본 발명은 사물을 촬영하여 식별하는 시스템에서 회전이나 이동하는 카메라를 이용하여 입체 영상을 생성 할 수 있도록 한다."}
{"patent_id": "10-2023-0054344", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 첨부된 도면을 참조하여 본 발명에 따른 사물 식별 장치 및 이를 이용한 입체 영상 생성 방법의 실시예들 에 대해 설명한다. 이 과정에서 도면에 도시된 선들의 두께나 구성요소의 크기 등은 설명의 명료성과 편의상 과장되게 도시되어 있 을 수 있다. 또한, 후술되는 용어들은 본 발명에서의 기능을 고려하여 정의된 용어들로서 이는 사용자, 운용자 의 의도 또는 관례에 따라 달라질 수 있다. 그러므로 이러한 용어들에 대한 정의는 본 명세서 전반에 걸친 내용 을 토대로 내려져야 할 것이다. 카메라를 이용하여 사물을 식별하는 사물 식별 장치는, 식별력을 향상시키기 위하여, 여러 방향에서 사물을 촬 영하고 촬영한 영상을 학습시켜야 하는데, 조명이나 촬영 각도에 따라 사물을 정확히 식별하지 못하는 문제점이 발생할 수 있다. 따라서 이러한 문제점을 해결하기 위하여, 여러 각도에서 사물을 촬영할 수 있는 복수의 카메 라를 고정 설치할 수 있으나, 이 경우에는 카메라의 수가 증가함으로써 사물 식별 장치의 제작 단가가 증가하게 되는 문제점이 발생할 수 있다. 이에 따라 본 발명은 카메라를 회전시키거나 이동시킴으로써 하나의 카메라를 이용하더라도 사물을 다양한 각도 에서 입체적으로 촬영할 수 있도록 함으로써, 사물 식별 장치의 제작 단가를 낮추면서 오히려 식별력을 향상시 킬 수 있도록 한다. 도 1은 본 발명의 일 실시예에 따른 사물 식별 장치의 개략적인 구성을 보인 예시도이다. 도 1에 도시된 본 실시예에 따른 사물 식별 장치는, 카메라모듈과 프로세서를 포함할 수 있다. 또 다 르게는 도 1에 도시된 바와 같이 본 발명의 실시예에 따른 사물 식별 장치는 지지대모듈, 카메라모듈 , 베이스모듈, 센서모듈, 프로세서, 통신모듈, 조명모듈, 및 데이터베이스(D B)를 포함할 수 있다. 지지대모듈은 사물 식별 장치의 바디(또는 프레임)의 내부 일 측면에 지정된 각도로 형성되며, 카메라모듈 이 부착될 수 있다. 지지대모듈은 카메라모듈의 회전 방향 또는 이동 방향에 대응하여 지정된 형태(예 : 원형, 사각형, 타원형, C형, ㄷ형 등)의 궤도로 형성되거나, 지정된 형태의 궤도가 부착될 수 있다. 지지대모듈에는 적어도 하나의 카메라모듈이 부착될 수 있다. 지지대모듈은 카메라모듈이 부착된 상태에서 지정된 속도에 따라 지정된 방향으로 회전되거나 이동될 수 있다. 지지대모듈은 전동식 모터(미도시)를 포함할 수 있다. 지지대 모듈은 베이스모듈에 놓여 있는 사물을 다양한 높이에서 촬영하기 위하여 베이스모듈을 기준으로 복수의 높이에 복수로 배치될 수 있다. 지지대 모듈이 복수의 높이에 복수로 구성되는 경우, 그에 대응되게 각 지지대 모듈에 카메라모듈이 구비될 수 있다. 카메라모듈은 지지대모듈에 고정 부착될 수 있으며, 지지대모듈의 궤도를 따라 능동적으로 회전 또는 이동할 수 있다. 카메라모듈은, 전동식 모터(미도시)를 구비하여, 지지대모듈의 궤도를 따라 능동적으로 회전 또는 이 동할 수도 있다. 카메라모듈은, 지지대모듈에 고정 부착되어, 지지대모듈의 회전이나 이동에 따라 수동적으로 회 전 또는 이동될 수도 있다. 카메라모듈은, 회전 또는 이동하며, 베이스모듈에 놓여 있는 사물(예 : 상품, 물품 등)을 다양한 각 도에서 연속하여 촬영할 수 있다. 카메라모듈은 베이스모듈의 중심을 기준으로 내측 또는 외측으로 촬영 각도가 조정될 수 있다. 카메라모듈은 베이스모듈에 놓여 있는 사물을 다양한 높이에서 촬영하기 위하여 베이스모듈을 기준으로 복수의 높이에 복수로 배치될 수도 있다. 카메라모듈은 2차원 카메라, 깊이 카메라(Depth camera), 스테레오 카메라 등 3차원 카메라를 포함한다. 카메라모듈은 이차원 영상 또는 깊이 정보를 포함한 3차원 영상 취득이 가능하며, 회전 또는 이동하여 베 이스모듈에 놓여 있는 사물을 다양한 각도에서 촬영한 이차원 영상 또는 깊이 정보를 포함한 3차원 영상을 바탕으로 깊이 영상 또는 입체 영상을 생성할 수도 있다. 본 예에서는 회전 또는 이동하는 하나 또는 둘 이상의 카메라모듈에 대해 설명하고 있으나, 실시 환경이나 목적에 따라서는 상기 카메라모듈 외에 고정형 카메라모듈(미도시)을 더 구비할 수도 있고, 이들에 의해 취득된 영상으로부터 프로세스가 사물을 식별한다. 베이스모듈은 물품 받침대의 기능을 수행한다. 베이스모듈은 카메라모듈의 위치 및 포즈 혹은 상기 사물의 놓인 위치, 크기 및 특징을 추출하여 사 물 인식 성능을 높이는 미리 지정된 참조패턴(도 11 참조)을 베이스모듈의 적어도 일 측면에 구비할 수 있 다. 이러한 참조패턴은 보다 더 강인한 사물 인식 성능을 도출할 수 있게 한다. 또한, 참조패턴이 형성되는 표 면, 즉 베이스모듈 표면 또는 적어도 일측면부의 표면은 무광 처리되게 형성하는 것이 바람직하며, 참조패 턴 이외의 배경은 다양한 칼라나 질감이 가능하겠으나 본 발명의 실시예들에서는 미리 지정된 텍스처(texture) (예: 대리석 등)를 형성하는 것이 바람직하다. 이것은 조명으로부터의 영향을 최소화하고 사물들에 의한 참조패 턴 가림이나 사물을 담은 트레이를 베이스모듈 위에 올려 놓을 때 참조패턴 가려짐에 의한 영향을 최소화 한다. 베이스모듈은 전동식 모터(미도시)에 의해 지정된 방향으로 지정된 속도에 따라 회전될 수 있으며, 또한 지정된 세기로 진동될 수도 있다. 센서모듈은 엔코더와 포지션 센서를 포함할 수 있으며, 프로세서가 센서모듈로부터의 센싱 정보 (예: 위치, 각도 등)를 바탕으로 카메라모듈의 촬영 각도나 회전 위치나 이동 위치를 정확하게 감지하고 제어할 수 있도록 한다. 프로세서는 회전 또는 이동하는 카메라모듈이 베이스모듈에 놓여 있는 사물을 다양한 각도에서 연속 촬영한 영상을 바탕으로 각 사물을 식별한다. 또한, 프로세서는 이차원 영상, 깊이 영상(예: 카메라 시점에서 사물간의 거리값을 지닌 데이터) 및/또는 입체 영상(예: x축, y축, z축 세 가지 3차원 위치 정보를 담 고 있는 영상 데이터) 등을 생성할 수 있고, 이렇게 생성된 영상에 대해 전처리 및 후처리를 통해 사물을 식별 해낸다. 또한, 카메라모듈이 이차원 영상 또는 깊이 정보를 포함한 3차원 영상 취득이 가능하므로, 회전 또는 이동하면서 베이스모듈에 놓여 있는 사물을 다양한 각도에서 촬영한 이차원 영상 또는 깊이 정보를 포함한 3차원 영상을 바탕으로 프로세서는 깊이 영상 또는 입체 영상을 생성하여 이를 이용해 사물을 식별 할 수도 있다. 프로세서는 베이스모듈에 놓여 있는 사물을 식별함에 있어 미리 학습(예 : 패턴매칭, 기계학습 또는 딥러닝학습)된 결과를 이용하여 사물 식별을 수행한다. 또는 프로세서는 베이스모듈에 놓여지는 사물 의 위치와 형상과 형태 및 사물의 상태 조건(예: 조명모듈의 발광 세기, 외부 빛의 영향 등) 등을 바꿔가며 실 험한 결과를 토대로 패턴매칭, 기계학습 또는 딥러닝학습을 수행하여 그 결과를 데이터베이스(DB)에저장시킨다. 프로세서는 베이스모듈에 놓여 있는 사물이 촬영된 영상, 또는 베이스모듈에 놓여 있는 사물이 촬영된 영상으로부터 생성한 깊이 영상이나 입체 영상을 이용하여, 사물을 식별하기 위한 학습(예 : 패턴매칭, 기계학습 또는 딥러닝학습)을 수행한다. 이 때, 상기와 같은 패턴매칭, 기계학습 또는 딥러닝학습은 프로세서에 의해 사물 식별 장치 내에서 수행 될 수도 있지만, 실시 환경이나 실시 의도에 따라 상기 사물 식별 장치와 통신모듈을 통해 유선/무선으로 연결되는 서버나 미리 지정된 클라우드(미도시)에서 수행되고 그 학습 결과가 다시 전송되어 데이터베이스(DB) 에 저장되며, 프로세서에 의해 사물 식별 시에 이용된다. 프로세서는 베이스모듈에 놓여 있는 사물의 학습을 위한 학습모드, 및 베이스모듈에 놓여 있는 사물의 식별을 위한 식별모드를 포함한다. 프로세서는 학습모드 및 식별모드 수행 시, 지지대모듈, 카메라모듈, 및 베이스모듈에 포 함된 전동식 모터(미도시)를 제어한다. 프로세서는 학습모드 및 식별모드 수행 시, 카메라모듈을 통해 촬영된 영상 및 센서모듈을 통해 검출된 카메라모듈의 위치(즉, 회전/이동 위치) 및/또는 각도 정보를 대응시켜 데이터베이스(DB)에 저장한 다. 데이터베이스(DB)는 카메라모듈을 통해 촬영된 영상(예: 이차원 영상, 깊이 영상, 입체 영상)과 센서모듈 을 통해 검출된 위치 정보 및/또는 각도 정보를 대응시켜 저장한다. 데이터베이스(DB)에는 학습모드 및 식 별모드를 수행하기 위한 프로그램, 학습 관련 정보, 학습 결과, 사물의 특성 정보(예 : 길이, 부피, 높이, 색상 등), 및 사물의 가격 정보 중 적어도 하나 이상이 저장된다. 통신모듈은 학습모드 및 식별모드 수행과 관련된 정보를 입력하거나 출력하기 위한 적어도 하나 이상의 외 부 장치(예 : 디스플레이모듈, 사용자단말기, 서버 등)와 유선 또는 무선 방식으로 통신을 연결한다. 예컨대 디스플레이모듈은 학습모드에서 학습을 수행하기 위한 안내메시지를 출력할 수 있으며, 또한 디스플레이 모듈은 식별모드에서 식별한 사물의 이름과 가격 정보를 출력할 수 있다. 사용자단말기는 식별모드에서 식별한 사물의 이름과 가격 정보 및 결제 정보를 출력할 수 있다. 서버는 어느 하나의 사물 식별 장치에서 학습한 정보 를 다른 사물 식별 장치와 공유할 수 있도록 한다. 가령, 제1 사물 식별 장치에서 제1 사물에 대하여 학습한 학 습 정보를, 제2 사물 식별 장치에 전달하여 상호간에 동일한 사물에 대한 학습 정보를 공유할 수 있도록 한다. 또한 서버는 사물 식별 장치에 대한 운영 프로그램이나 데이터를 업데이트할 수 있도록 한다. 이 때, 또 다른 실시예에서는 상기 디스플레이모듈이 사물 식별 장치에 일체로 결합되어 형성될 수도 있다. 조명모듈은 바디(또는 프레임)의 내부 일 측면에 부착되어 조명한다. 본 발명의 실시예들에서는 조명모듈 이 베이스모듈에 대향되는 상부측의 소정 위치(예: 상부 중앙, 상부측 테두리 등)에 형성된다. 조명모듈은 적어도 하나 이상의 색상으로 조명할 수 있으며, 조명 시 밝기가 조정될 수도 있다. 이 때 조명에 대한 색상이나 밝기의 조정은, 사물의 선명한 촬영(즉, 식별력 향상)을 위한 것으로서, 가령, 사 물의 포장지의 재질(예 : 비닐, 종이, 알루미늄 등), 및 포장지에 인쇄된 정보(예 : 사물의 상표, 도안, 바코드, 홀로그램 등)의 종류에 따라, 선명한 촬영을 위하여 조명에 대한 색상이나 밝기가 조정될 수 있다. 조명모듈은 가시광 엘이디(LED)를 포함할 수 있으며, 조명 특성(예 : 할로겐, 적외선, 자외선 등)이 다른 복수의 조명 소자가 추가로 포함될 수도 있다. 이 때 조명 소자의 선택은, 사물의 선명한 촬영(즉, 식별력 향상)을 위한 것으로서, 가령, 사물의 포장지의 재 질(예 : 비닐, 종이, 알루미늄 등), 및 포장지에 인쇄된 정보(예 : 사물의 상표, 도안, 바코드, 홀로그램 등)의 종류에 따라, 선명한 촬영을 위하여 조명 소자가 선택될 수 있다. 도 2는 본 발명의 일 실시예에 따른 사물 식별 장치의 학습모드 동작을 설명하기 위한 흐름도이다. 도 2를 참조하면, 사물 식별 장치의 현재 모드가 학습모드이고(S101의 예), 베이스모듈 위에 사물이 탑재 되어 있을 경우(S102의 예), 프로세서는 카메라모듈을 지정된 속도에 따라 지정된 방향으로 회전시키 거나 이동시키며, 베이스모듈에 놓여 있는 사물을 촬영한다(S103). 이 때 프로세서는, 전동식 모터(미도시)를 제어하여, 지지대모듈의 형태(예 : 궤도 형태)에 따라 카 메라모듈을 능동적으로 회전 또는 이동시킬 수 있으며, 또는 지지대모듈에 카메라모듈을 고정 부착시켜, 지지대모듈의 회전이나 이동에 따라 카메라모듈을 수동적으로 회전 또는 이동될 수도 있다 (도 4 내지 도 8 참조). 이에 따라 프로세서는 카메라모듈이 회전이나 이동(즉, 능동적/수동적인 회전이나 이동)을 수행하면 서 베이스모듈에 놓여 있는 사물을 촬영한 영상(즉, 이차원 영상), 또는 베이스모듈에 놓여 있는 사 물이 촬영된 영상들로부터 생성한 깊이 영상 및/또는 입체 영상을 이용하여, 사물을 식별(또는 인식)하는 학습 (예 : 패턴매칭, 기계학습 또는 딥러닝학습)을 수행하고(S104), 학습 정보(즉, 사물의 식별 또는 인식 정보) 및 이에 대응하는 판매 정보(예 : 가격)를 데이터베이스(DB)에 저장한다(S105). 또한, 카메라모듈이 이차원 영상뿐만 아니라 깊이 정보를 포함한 3차원 영상 취득이 가능한 경우, 회전 또는 이동하면서 베이스모듈에 놓여 있는 사물을 다양한 각도에서 촬영한 이차원 영상 또는 깊이 정보를 포함한 3차원 영상을 바탕으로 깊이 영상 또는 입체 영상을 생성하며 프로세서가 상기 깊이 영상 또는 입체 영상을 이용하여 사물을 식별하는 학습을 수행할 수도 있다. 또 다르게는, 상기 학습이 서버나 클라우드(미도시)에서 수행되게 할 수도 있으므로, 이 경우엔 프로세서가 상기 영상(이차원 영상), 또는 상기 생성한 깊이 영상 및/또는 입체 영상을 외부의 서버나 클라우드(미도시)에 전송시킨다. 또한 도면으로 도시되지는 않았으나, 프로세서는 디스플레이모듈을 통해 학습모드에서 학습을 수행하기 위 한 안내메시지를 출력할 수 있다. 도 3은 본 발명의 일 실시예에 따른 사물 식별 장치의 식별모드 동작을 설명하기 위한 흐름도이다. 도 3을 참조하면, 사물 식별 장치의 현재 모드가 식별모드이고(S201의 예), 베이스모듈 위에 사물이 탑재 되어 있을 경우(S202의 예), 프로세서는 카메라모듈을 지정된 속도에 따라 지정된 방향으로 회전시키 거나 이동시키며, 베이스모듈에 놓여 있는 사물을 촬영한다(S203). 이 때 프로세서는, 학습모드인 경우와 마찬가지로, 전동식 모터(미도시)를 제어하여, 지지대모듈의 형태(예 : 궤도 형태)에 따라 카메라모듈을 능동적으로 회전 또는 이동시킬 수 있으며, 또는 지지대모듈 에 카메라모듈이 고정 부착된 경우, 지지대모듈의 회전이나 이동에 따라 카메라모듈을 수 동적으로 회전 또는 이동시킬 수도 있다(도 4 내지 도 8 참조). 이에 따라 프로세서는 카메라모듈이 회전이나 이동(즉, 능동적/수동적인 회전이나 이동)을 수행하면 서 베이스모듈에 놓여 있는 사물을 촬영한 영상(즉, 2차원 영상), 또는 베이스모듈에 놓여 있는 사물 이 촬영된 영상들로부터 생성한 깊이 영상 및/또는 입체 영상을 이용하여, 사물을 식별(또는 인식)하고(S204), 식별(또는 인식)된 사물에 대응하는 판매 정보(예 : 가격)를 데이터베이스(DB)로부터 로딩한다(S205). 또한, 카 메라모듈이 이차원 영상뿐만 아니라 깊이 정보를 포함한 3차원 영상 취득이 가능한 경우, 회전 또는 이동 하면서 베이스모듈에 놓여 있는 사물을 다양한 각도에서 촬영한 이차원 영상 또는 깊이 정보를 포함한 3차 원 영상을 바탕으로 깊이 영상 또는 입체 영상을 생성하고 프로세서가 상기 깊이 영상 또는 입체 영상을 이용하여 사물을 식별(또는 인식)할 수도 있고(S204), 이렇게 식별(또는 인식)된 사물에 대응하는 판매 정보(예 : 가격)를 데이터베이스(DB)로부터 로딩시킬 수 있다(S205). 또한 도면으로 도시되지는 않았으나, 프로세서는 식별(또는 인식)된 사물에 대응하는 판매 정보(예 : 가격)를 합산한 결제 정보를, 디스플레이모듈이나 사용자 단말에 출력(즉, 전송이나 표시)할 수 있다. 이하 도 4 내지 도 8을 참조하여, 카메라모듈의 회전 또는 이동 방법에 대해서 설명한다. 도 4는 본 발명의 일 실시예에 따른 카메라모듈의 회전 방법을 설명하기 위한 예시도이다. 도 4에 도시된 바와 같이, 지지대모듈은 바디(또는 프레임)의 내부 일 측면에 지정된 각도로 형성되며, 이 에 카메라모듈이 부착된다. 예컨대 도 4의 (a)와 (b)에 도시된 바와 같이, 지지대모듈은 바디(또는 프레임)의 내부 상측에 수평하게 형성될 수 있으며, 구체적으로 (a)에 도시된 바와 같이 하나의 지지대모듈에 하나의 카메라모듈이 부 착되거나, (b)에 도시된 바와 같이 하나의 지지대모듈에 복수의 카메라모듈이 부착될 수 있다. 또한 도 4의 (c)와 (d)에 도시된 바와 같이, 지지대모듈은 바디(또는 프레임)의 내부 일 측면에 지정된 각 도로 형성될 수 있으며, (c)에 도시된 바와 같이 하나의 지지대모듈이 지정된 각도로 형성되거나, (d)에 도시된 바와 같이 복수의 지지대모듈이 각각 지정된 각도로 형성될 수 있다.도 5는 도 4에 있어서, 카메라모듈의 회전 범위를 보인 예시도이다. 도 5의 (a)에 도시된 바와 같이 카메라모듈은 360도 회전하며 베이스모듈 위에 놓여 있는 사물을 360 도 전방향에서 촬영할 수 있다. 또는 도 5의 (b)에 도시된 바와 같이 카메라모듈은 지정된 각도 범위(예 : 180도, 270도 등) 내에서 회전 하며 베이스모듈 위에 놓여 있는 사물을 지정된 각도 범위(예 : 180도, 270도 등)에서 촬영할 수도 있다. 도 6은 도 4에 있어서, 복수의 지지대모듈을 이용한 카메라모듈의 회전 방법을 설명하기 위한 예시도이다. 도 6을 참조하면, 사물 식별 장치의 바디(또는 프레임) 내부의 각기 다른 높이(예 : 상측, 하측)에 복수의 지지 대모듈이 형성되되, (a)에 도시된 바와 같이 각기 다른 높이(예 : 상측, 하측)에 형성된 복수의 지지대모 듈이 모두 카메라모듈을 360도 회전시킬 수 있는 형태로 형성될 수 있으며, 또는 (b)에 도시된 바와 같이 각기 다른 높이(예 : 상측, 하측)에 형성된 복수의 지지대모듈 중 어느 하나는 카메라모듈을 360도 회전시킬 수 있는 형태로 형성되고, 다른 하나는 카메라모듈을 지정된 각도 범위(예 : 270도) 내에 서 회전시킬 수 있는 호 형태로 형성되며, 또는 (c)에 도시된 바와 같이 각기 다른 높이(예 : 상측, 하측)에 형 성된 복수의 지지대모듈이 모두 카메라모듈을 지정된 각도 범위(예 : 270도) 내에서 회전시킬 수 있 는 호 형태로 형성될 수 있다. 도 7은 본 발명의 일 실시예에 따른 카메라모듈의 이동 방법을 설명하기 위한 예시도이다. 도 7의 (a)에 도시된 바와 같이 카메라모듈은 바디(또는 프레임)의 내부 모서리에 형성된 지지대모듈(11 0)을 따라, 모서리 부분에서 수평 방향(또는 X,Y 방향)으로 이동하거나 모서리 부분에서 수직 방향(또는 Z 방향)으로 이동할 수 있으며, (b)와 (c)에 도시된 바와 같이 바디(또는 프레임)의 내부 일 측면(예 : 상측)에 대하여 수평하게 형성된 지지대모듈을 따라, X축 방향 또는 Y축 방향으로 이동할 수 있으며, (d)에 도시된 바와 같이 바디(또는 프레임)의 내부 일 측면의 일 지점에서 타 측면의 일 지점으로 지정된 각도의 호(arc) 형 태로 형성된 지지대모듈을 따라, 지정된 각도 범위(예 : 270도) 내에서 이동할 수 있으며, (e)에 도시된 바와 같이 바디(또는 프레임)의 내부 일 측면의 일 지점에서 타 측면의 일 지점으로 직선 형태(또는 기울기가 있는 직선 형태)로 형성된 지지대모듈을 따라 직진 방향(또는 대각 방향)으로 이동할 수도 있다. 도 8은 도 7에 있어서, 복수의 카메라모듈의 이동 방법을 설명하기 위한 예시도이다. 도 8의 (a)에 도시된 바와 같이 복수의 카메라모듈이 바디(또는 프레임)의 내부 일 측면에 대하여 수평하 게 형성된 지지대모듈을 따라 X축 방향으로 수평하게 이동할 수 있으며, (b)에 도시된 바와 같이 복수의 카메라모듈이 바디(또는 프레임)의 내부 일 측면에 대하여 수평하게 형성된 지지대모듈을 따라 Y축 방향으로 수평하게 이동할 수도 있다. 본 실시예는 하나의 카메라모듈만으로도 사물의 입체적 촬영이 가능하지만, 복수의 카메라모듈을 이 용함으로써 이미지 취득 및 인식 시간을 최소화 할 수 있는 효과가 있으며, 복수의 카메라모듈을 설치할 경우 각 카메라모듈의 화각을 다르게 구성하여 사물 인식(식별)률을 향상시킬 수 있다. 도 9는 본 발명의 일 실시예에 따른 사물 식별 장치의 개략적인 형태를 보인 예시도로서, (a)에 도시된 바와 같 이 사물 식별 장치는 전면측이 개방되어 사물을 베이스모듈에 올려놓고 쉽게 회수할 수 있는 형태로 형성 될 수 있다. 또한, (b)와 (c)에 도시된 바와 같이 사물 식별 장치는 전면측과 좌우측면부가 완전 개방되어 보다 더 쉽게 사물을 베이스모듈에 올려놓거나 회수할 수 있는 형태로 형성될 수 있다. 그리고, (c)에서와 같이 상부측은 원형으로 형성될 수도 있고, 후방측은 전면에서 볼 때 베이스모듈의 폭보다 더 좁게 형성할 수도 있는 등, 본 발명에 따른 사물 식별 장치는 다양한 형태로 디자인될 수 있음은 당연하며, 예시된 예들에 국한되 지 않는다. 도면에는 구체적으로 도시되어 있지 않지만, 프로세서는 카메라모듈이나 센서모듈 또는 또다른 카메라모듈을 통해 베이스모듈 상의 스캔(촬영) 영역 내의 사물을 식별할 수 있고 사용자의 행위(예 : 사 물을 올려놓거나 꺼내는 행위, 결제를 위해 사물 식별 장치에 접근하는 행위, 베이스모듈에 사물을 올려놓은 후 결제를 기다리는 행위, 결제가 완료되어 사물 식별 장치로부터 멀어지는 행위 등)에 따른 변화를 실시간 감지할 수 있다. 또한 본 실시예에 따른 사물 식별 장치는 결제 시스템(예 : POS 시스템)과 결합되어, 사물 식별(인식) 정보를 바탕으로 곧바로 결제를 수행할 수 있도록 한다.도 10은 본 발명의 일 실시예에 따른 사물 식별 장치의 테스트 과정을 촬영한 사진을 보인 예시도로서, 사물 식 별 장치의 바디(프레임)를 개방한 상태에서, (a)는 전면에서 촬영된 사진이고, (b)는 측면에서 촬영된 사진이며, (c)는 바디(프레임) 내부의 상측이 촬영된 사진이다. 도 11은 도 1에 있어서, 베이스모듈, 및 바디나 프레임의 내측 측면에 형성되는 참조패턴을 보인 예시도이다. 본 실시예에서 참조패턴은, 카메라모듈의 위치 및 포즈를 추출하여 캘리브레이션 할 수 있도록 하는 목적, 상기 베이스모듈에 놓인 사물의 위치, 크기 및 특징을 추출하여 사물 인식 성능을 향상시킬 수 있도록 하 는 목적, 및 해당 패턴을 활용해서 다양한 조명환경에서도 균일한 조명을 구성할 수 있도록 활용하는데 그 목적 이 있다. 이러한 참조패턴은, 사물 인식 성능을 보다 더 향상시킬 수 있도록 한다. 참조패턴은 사용자가 항상 인식할 수 있도록 표시되는 잉크를 이용해 형성될 수 있으며, 또는 특정한 조명 상태 에서만 표시됨으로써 사용자가 인식할 수 있도록 하는 잉크를 이용해 형성될 수 있으며, 또는 평상시에는 표시 되지 않고 특정한 조명 상태에서 카메라모듈만 인식할 수 있도록 표시되는 잉크를 이용해 형성될 수도 있 다. 예컨대 참조패턴은, 도 11의 (a)와 같이 베이스모듈의 상부 표면을 제1 영역(예 : 내부 영역)과 제2 영역 (예 : 테두리 영역)으로 구분하고 제2 영역의 적어도 일 측에는 눈금자가 형성되고, 제1 영역에는 검정색과 흰 색의 사각형이 체크무늬(또는 격자무늬) 형태로 형성된 패턴, 도 11의 (b)와 같이 베이스모듈의 상부 표면 을 제1 영역(예 : 내부 영역)과 제2 영역(예 : 테두리 영역)으로 구분하여 제2 영역에는 검정색과 흰색 사각형 이 순차로 반복되는 라인 형태로 형성되고 제1 영역에는 배경색(예 : 흰색)과 다른 색상(예 : 검정색)의 지정된 도형(예 : 원형)이 체크무늬(또는 격자무늬) 형태로 형성된 패턴, 도 11의 (c)와 같이 베이스모듈의 상부 표면을 제1 영역(예 : 내부 영역)과 제2 영역(예 : 테두리 영역)으로 구분하고 제2 영역에는 제1 영역의 중심 방향으로 향하는 직선들(즉, 눈금자 역할을 수행하는 직선들)이 제1 영역의 경계선까지 지정된 간격으로 배열되 며 제1 영역에는 배경색(예 : 흰색)과 다른 색상(예 : 검정색)의 지정된 도형(예 : 원형)이 체크무늬(또는 격자 무늬) 형태로 형성된 패턴, 도 11의 (d)와 같이 베이스모듈의 상부 표면을 제1 영역(예 : 내부 영역)과 제 2 영역(예 : 테두리 영역)으로 구분하고 제2 영역에는 문자나 숫자가 라인 형태로 배열되고 제1 영역에는 배경 색(예 : 대리석 텍스처)과 다른 색상(예 : 검정색)의 지정된 도형(예 : 사각형)이 체크무늬(또는 격자무늬) 형 태로 형성된 패턴, 도 11의 (e)와 같이 베이스모듈의 상부 표면을 제1 영역(예 : 내부 영역)과 제2 영역 (예 : 테두리 영역)으로 구분하고 제1 영역에만 배경색(예 : 흰색)과 다른 색상(예 : 검정색)의 지정된 도형(예 : 사각형)이 체크무늬(또는 격자무늬) 형태로 형성된 패턴, 도 11의 (f)와 같이 베이스모듈의 상부 표면을 제1 영역(예 : 내부 영역)과 제2 영역(예 : 테두리 영역)으로 구분하고 제1 영역에만 검정색과 흰색의 사각형이 체크무늬(또는 격자무늬) 형태로 형성된 패턴, 및 도 11의 (g)와 같이 베이스모듈의 상부 표면을 제1 영역 (예 : 내부 영역)과 제2 영역(예 : 테두리 영역)으로 구분하고 제1 영역에만 외측 경계선에서부터 중심 방향으 로 향하는 길이가 다른 직선들이 번갈아가며 지정된 간격으로 형성된 패턴, 중 적어도 한 가지 형태의 패턴을 포함한다. 또한 상기 패턴은 도 11의 (h)와 같이 바디(또는 프레임)의 내측 측면에 형성될 수 있다. 물론, 다양한 형태의 패턴이 상기 내측 일 측면에 형성될 수 있다. 또한, 상기 패턴은 도 11의 (i)와 같이 바디(또는 프레임)의 내측 일 측면과 베이스모듈 표면상에 형성될 수 있다. 본 예(i)의 경우, 바디(또는 프레임)의 내측 일 측면에 본 사물 식별 장치의 사용법에 대한 문구가 베 이스모듈 면으로부터 소정 높이(b)부터 복수의 행으로 소정 행간격(a)을 유지하게 형성되어 있고, 베이스 모듈 면상에는 제1 영역(예 : 내부 영역)과 제2 영역(예 : 테두리 영역)이 굵은 선으로 구분되어 있고 제 2 영역에 소정의 문구가 형성되어 있는데, 바로 이 문구들을 참조패턴으로 이용하도록 하고 있다. 이 경우에, 측면부와 베이스모듈의 테두리부에 형성된 문구들 중 적어도 하나를 참조패턴으로 이용할 수 있으므로, 사 물들에 의해 참조패턴이 가려지기 어려운 위치 영역에 형성되어 사물 인식의 기준, 카메라모듈의 캘리브레이션, 조명 밝기 대응 등의 처리가 용이해진다. 이 때 상술한 여러 참조패턴의 예시들에서, 제1 영역과 제2 영역은, 지정된 색상(예 : 흰색, 검정색 등)과 굵기 의 경계선이 지정된 형태(예 : 원형, 사각형 등)로 형성됨으로써 각 영역이 구분되도록 하고 있다. 하지만, 이 들에 국한될 필요는 없다. 즉, 제1 영역과 제2 영역의 횐색 또는 검정색 또는 형태는 실시 환경이나 목적에 따 라 조명과 사물 인식의 설정 기준에 따라 달라질 수 있다. 예컨대, 배경색은 흰색이 아니라 회색일 수도 있고 텍스처(texure) 배경일 수도 있으며 패턴의 색상이 검정이 아니라 약검정색일 수 있는 것이다.또한 제1 영역과 제2 영역의 폭과 위치는 조정될 수 있으며, 제1 영역과 제2 영역에 각각 도시되는 정보(예 : 문자, 숫자, 라인, 도형, 이미지, 캐릭터 등)를 한정하는 것은 아니다. 이에 따라 프로세서는 참조패턴의 정보를 활용하여 촬영 영상으로부터 사물의 사이즈를 측정할 수 있으며, 참조패턴을 통해 사물과 배경을 구분하는 성능을 향상시킬 수 있으며, 참조패턴을 통해 센서(예 : Encoder)를 대체할 수 있으며, 참조패턴을 통해 복수의 뷰(View)에서 취득한 영상을 기반으로 3D 모델링 시 정확도를 향상 시킬 수 있으며, 또한 참조패턴을 통해 조명 밝기를 균일화 시킬 수 있고, 카메라모듈의 기하학적 캘리브 레이션(Geometric Calibration)에 이용할 수 있다. 도 12는 본 발명의 제1 실시예에 따라 사물 인식에 참조패턴을 활용하는 방법을 설명하기 위한 예시도이다. 도 12의 (a)와 (b)에 도시된 바와 같이, 프로세서는 베이스모듈에 형성된 참조패턴의 각 격자무늬의 사이즈 정보(즉, a′×a″) 및/또는 테두리 영역의 눈금자 및/또는 사물에 의해 가려진 격자무늬의 개수를 바탕 으로, 사물의 X*Y축 사이즈(예 : 넓이)를 측정하거나 추정할 수 있다. 도 12의 (c)와 (d)에 도시된 바와 같이, 프로세서는 바디(또는 프레임)의 내측 측면에 형성된 참조패턴의 각 격자무늬의 사이즈 정보(즉, a′×a″) 및/또는 테두리 영역의 눈금자 및/또는 사물에 의해 가려진 격자무늬 의 개수( )를 바탕으로, 사물의 Z축 사이즈(예 : 높이)를 측정하거나 추정할 수 있다. 도 13은 본 발명의 제2 실시예에 따라 사물 인식에 참조패턴을 활용하는 방법을 설명하기 위한 예시도이다. 도 13을 참조하면, 프로세서는 베이스모듈에 형성된 참조패턴 정보(예 : 제1 영역에 형성된 격자무늬 정보와 좌표 정보 및 제2 영역에 형성된 눈금자 정보)를 바탕으로, (a)와 같이 사물이 놓여 있지 않은 참조패턴 정보에서 (b)와 같이 사물이 놓여 있는 참조패턴 정보의 차 영상을 추출함으로써, (c)와 같이 베이스모듈 에 놓여 있는 사물의 위치를 측정하거나 추정할 수 있다. 도 14는 본 발명의 제3 실시예에 따라 사물 인식에 참조패턴을 활용하는 방법을 설명하기 위한 예시도이다. 본 실시예에서 카메라모듈은 회전하며 베이스모듈에 놓여 있는 사물을 다양한 각도에서 촬영한다. 따 라서 카메라모듈이 회전할 때의 회전 각도를 정확히 검출하기 위한 센서(예 : 인코더 센서)를 구비할 수 있다. 그러나 센서를 포함할 경우에는 그에 따른 비용의 증가 및 센서의 고장을 감지하기 위한 알고리즘이 필요 하게 되는 단점이 있다. 따라서 본 발명에 따른 실시예는 별도의 센서(예 : 인코더 센서)를 추가하지 않더라도, 도 14에 도시된 바와 같 은 참조패턴을 이용하여 카메라모듈의 회전 각도를 검출하는 데 활용할 수 있다. 프로세서는 베이스모듈에 형성된 참조패턴 정보(예 : 제1 영역에 형성된 격자무늬 정보와 좌표 정보 및 제2 영역에 형성된 눈금자 정보)를 바탕으로, 가령, 카메라모듈과 제2 영역에 형성된 라인(즉, 눈금자 정보에 해당하는 라인)이 일 직선이 될 때의 각도를 카메라모듈의 회전 각도로 측정하거나 추정할 수 있다. 도 15는 본 발명의 제4 실시예에 따라 사물 인식에 참조패턴을 활용하는 방법을 설명하기 위한 예시도이다. 일반적으로 카메라모듈은 주변의 조명 환경 변화로 인하여 사물 인식 성능이 저하될 수 있다. 따라서 본 발명은 균일한 조명 밝기를 제공하기 위하여, 주변의 조명 환경 변화에 대응하여 실시간으로 조명 밝 기를 보정함으로써, 조도 센서를 이용하지 않더라도, 카메라모듈을 통해 촬영된 영상을 바탕으로, 프로세 서가 사물 인식 장치의 조명 밝기를 실시간으로 측정하여 보정할 수 있도록 한다. 예컨대 도 15의 (a)와 같이, 기준 조명 밝기 상태에서 참조패턴을 촬영하여 기준 밝기 정보로서 미리 저장한 상 태에서, 프로세서는, (b)와 같이 참조패턴 촬영 영상에서 참조패턴 전체의 밝기를 실시간으로 측정하는 과 정, (c)와 같이 참조패턴 촬영 영상에서 참조패턴의 제1 격자(예 : 흰색 격자)들의 밝기를 실시간으로 측정하는 과정, (d)와 같이 참조패턴 촬영 영상에서 참조패턴의 제2 격자(예 : 검정색 격자)들의 밝기를 실시간으로 측정 하는 과정, 제1 격자(예 : 흰색 격자)들의 밝기와 제2 격자(예 : 검정색 격자)들의 밝기가 미리 저장된 기준 밝 기와 같아지도록 조명모듈의 조명 밝기를 조절하는 과정, 및 참조패턴 전체의 밝기가 미리 저장된 기준 밝 기와 같은지 체크하는 과정을 반복해서 수행함으로써 균일한 조명 밝기를 제공할 수 있도록 한다. 도 16은 본 발명의 제5 실시예에 따라 사물 인식에 참조패턴을 활용하는 방법을 설명하기 위한 예시도이다. 도 11을 참조하여 설명한 바와 같이, 본 실시예에 따른 참조패턴 정보(예 : 제1 영역에 형성된 격자무늬 정보와 좌표 정보 및 제2 영역에 형성된 눈금자 정보)는, 제1 영역 및 제2 영역에 형성된 정보를 조합하여 참조패턴의 사 면을 구분할 수 있도록 하며, 참조패턴 내에서 일정한 사이즈의 격자가 반복되기 때문에 X축과 Y축의 거리 (또는 길이) 측정을 통해 좌표를 특정할 수 있다. 따라서 복수의 카메라모듈을 이용해 각기 다른 위치에서 참조패턴을 촬영하더라도 동일하게 좌표를 특정할 수 있다. 가령, 다른 위치에 있는 복수의 카메라모듈이 참조패턴 상에 놓여 있는 사물을 각각 촬영한다고 하더라도, 해당 사물이 놓여 있는 영역의 좌표를 동일하게 특정할 수 있다. 이에 따라 프로세서는 복수의 카메라모듈이 동시에 촬영한 동일한 사물(즉, 동일한 좌표 상에 놓여 있는 사물), 또는 하나의 카메라모듈이 회전하거나 이동하며 촬영한 동일한 사물(즉, 동일한 좌표 상에 놓 여 있는 사물)에 대한 정보(즉, 동일한 사물에 대하여 각기 다른 방향 또는 각도에서 촬영된 영상에 관련된 정 보)를 통합(또는 공유)할 수 있게 된다. 이는 복수의 카메라모듈을 사용할 경우, 각각의 복수의 카메라에서 사물을 추출하여 사물을 인식할 수 도 있지 만, 기하학 캘리브레이션을 통해 복수의 카메라들간의 사물 위치 좌표 공유가 가능하게 된다. 따라서 하나의 카 메라에서 추출한 사물의 위치 좌표 정보를 해당 카메라 이외에 카메라로 취득한 영상에 공유함으로써, 해당 각 도 이외에서 취득된 복수의 영상들에서 사물의 위치 좌표를 추가적으로 추출하지 않아도 되기 때문에 복수의 영 상에서 사물의 위치 검출 시간을 단축 할 수 있다는 특징이 있다. 또한 특정 사물의 경우, 특정 위치의 카메라 에서는 사물들의 가림이 발생될 수 있으며, 이러한 가림의 경우 기하학 캘리브레이션을 기반으로 미리 추정할 수 있기 때문에 해당 영역에서는 인식을 시도를 제외함으로써 오인식의 개연성을 피할 수 있는 장점이 있다. 따라서 프로세서는 동일한 사물에 대한 정보를 통합(또는 공유)하여 입체 영상(또는 3D 영상)을 생성할 수 있게 함으로써, 보다 정확한 사물 인식을 수행할 수 있게 한다. 도 17은 도 16에 있어서, 참조패턴 기반으로 동일한 사물에 대하여 360도 전 방향에서 촬영된 영상들 중 일부 영상을 보인 예시도이다. 본 예에서는 예컨대 카메라모듈이 회전/이동하면서 36개의 다양한 각도에서 사물 (예: 우유팩 상품)을 촬영한 영상이 예시되어 있다. 도 17을 참조하면, 프로세서는 복수의 카메라모듈이 지정된 각도씩 이동(또는 회전)하여 동시에 촬영 한 동일한 사물(즉, 동일한 좌표 상에 놓여 있는 사물), 또는 하나의 카메라모듈이 360도(또는 지정된 각 도)를 회전하거나 이동하며 촬영한 동일한 사물(즉, 동일한 좌표 상에 놓여 있는 사물)에 대한 정보(즉, 동일한 사물에 대하여 각기 다른 방향에서 촬영된 영상에 관련된 정보)를 통합하여 입체 영상(또는 3D 영상)을 생성할 수 있다. 도 18은 도 16에 있어서, 참조패턴 기반으로 동일한 사물을 촬영할 경우와 참조패턴을 이용하지 않고 동일한 사 물을 촬영할 경우에 생성되는 입체 영상을 비교하기 위한 예시도이다. 도 18의 (a)에 도시된 바와 같은 참조패턴이 베이스모듈에 형성되어 있다고 가정할 때, (b)에 도시된 바와 같이 각기 다른 방향에서 동일한 사물을 촬영할 경우, 프로세서는 참조패턴 및 참조패턴의 주변에 형성된 참조패턴 마커를 바탕으로 베이스모듈에 놓여 있는 사물의 좌표를 특정할 수 있게 됨으로써, 좌표가 동일 한 사물의 복수의 영상을 이용하여 입체 영상(또는 3D 영상)을 생성 시 영상 정합도를 향상시킬 수 있다. 예컨대 도 18의 (c)에 도시된 바와 같이 참조패턴과 참조패턴 마커가 없는 베이스모듈에 놓여 있는 사물을 촬영한 영상을 이용하여 입체 영상(또는 3D 영상)을 생성할 경우에는 영상 정합도가 저하되는 것을 알 수 있다. 또한 도 18의 (d)에 도시된 바와 같이 참조패턴과 참조패턴 마커가 있는 베이스모듈에 놓여 있는 사물을 촬영한 영상을 이용하여 입체 영상(또는 3D 영상)을 생성할 경우에는 영상 정합도가 향상되는 것을 알 수 있다. 이 때 참조패턴 마커는, 참조패턴의 제1 영역(예 : 내부 영역) 및 제2 영역(예 : 테두리 영역) 중, 제2 영역의 정보로 대체될 수 있다. 도 19는 본 발명의 제6 실시예에 따라 사물 인식에 참조패턴을 활용하는 방법을 설명하기 위한 예시도이다. 상술한 바와 같이 참조패턴은, 베이스모듈의 상부 표면 및 바디(또는 프레임)의 내측 측면(도 11의 (h) 참 조)에도 형성됨으로써, 도 19의 (a) 내지 (d)에 도시된 바와 같이, 사물에 의해 참조패턴(또는 참조패턴 마커) 의 일부 또는 전체가 가려지는 경우, 프로세서는 가려지지 않은 다른 부분에 형성된 참조패턴(또는 참조패 턴 마커)을 활용하여 사물이 놓여 있는 좌표를 특정함으로써, 입체 영상(또는 3D 영상)의 생성 시 영상 정합도를 향상시킬 수 있도록 한다. 상술한 바와 같이 일 측면에 따른 본 발명은 센서를 포함하지 않더라도 참조패턴을 활용하여 카메라모듈의 위치 및 포즈를 추출하고 카메라모듈의 위치 제어 및 캘리브레이션을 수행할 수 있으며, 참조패턴을 활용 해 특정한 좌표를 바탕으로 동일한 사물에 대한 영상을 통합하여 입체 영상(또는 3D 영상)을 생성할 수 있도록 함으로써 사물 인식 성능을 보다 더 향상시킬 수 있도록 하는 효과가 있다. 한편, 상기 실시예들에서는 카메라모듈이 회전하거나 이동하면서 베이스모듈에 놓여진 하나 이상의 사물들을 촬영하고 촬영 영상으로부터 사물을 식별하는 성능을 더 높이기 위하여 참조패턴 및/또는 참조패턴 마 커를 활용하는 방법에 대해 설명하였지만, 본 발명의 참조패턴 및/또는 참조패턴 마커를 활용하는 방식은 하나 또는 복수의 카메라모듈을 고정시킨 형태의 사물 식별 장치의 경우에도 적용될 수는 있다. 도 20은 본 발명에서 스테레오 카메라 대신 회전 또는 이동하는 카메라모듈을 이용하여 입체 영상을 생성하는 방법을 설명하기 위한 예시도이다. 도 20의 (a)는 스테레오 카메라를 보인 예시도로서, 평행하게 배열한 2대의 카메라를 이용하여 입체 영상을 촬 영할 수 있도록 하는 카메라로서, 2대의 카메라를 설치해야 하는 단점이 있다. 도 20의 (b)는 본 발명에 따른 회전 또는 이동하는 카메라모듈로서, 지지대모듈을 따라 회전 또는 이 동할 수 있는 하나의 카메라모듈을 이용해 입체 영상을 촬영할 수 있도록 한다. 예컨대 A 위치에 있을 때의 카메라모듈이 스테레오 카메라 중 A 카메라의 역할을 수행하고, B 위치에 있을 때의 카메라모듈이 스테레오 카메라 중 B 카메라의 역할을 수행한다. 이에 따라 본 발명의 프로세서는 입체 영상을 촬영하기 위한(즉, 깊이 정보를 취득하기 위한) 별도의 장치 (예 : RGB-D, TOF, Stereo 카메라 등)를 사용하지 않더라도, 하나의 카메라모듈을 이용하여 회전이나 이동 을 통해 다양한 각도와 위치에서 동일한 사물에 대한 영상들을 취득하여 삼각측량법 기반으로 사물의 크기 및 깊이 정보를 측정할 수 있는 효과가 있다. 도 21은 도 20에 있어서, 구조광으로 촬영한 영상을 이용하여 입체 영상을 생성하는 방법을 설명하기 위한 예시 도이다. 도 21의 (a)와 (b)는 더욱 정교한 깊이 정보를 취득할 수 있도록 하기 위하여, 구조광(또는 구조광 패턴)을 사 물에 조사한 후, 회전 또는 이동하는 카메라모듈을 이용하여 각기 다른 위치와 각도에서 동일한 사물을 촬 영한 영상을 보인 예시도이다. 이 때 구조광(또는 구조광 패턴)은 사물 식별 장치 내의 지정된 위치에 장착되거나, 카메라모듈에 장착될 수 있다. 도 21을 참조하면, (c)에 도시된 바와 같이 베이스모듈에 놓여 있는 사물을, (d)와 (e)에 도시된 바와 같 이 구조광(또는 구조광 패턴)을 사물에 조사한 후, 회전 또는 이동하는 카메라모듈을 이용하여 각기 다른 위치와 각도에서 사물의 영상을 촬영하고, (f)에 도시된 바와 같이 두 영상을 기반으로하여 깊이 정보를 측정할 수 있다. 도 22는 본 발명에서 회전 또는 이동하는 카메라를 이용하여 깊이 정보를 측정할 때 정확도를 설명하기 위한 예 시도이다. 도 22를 참조하면, (a)에 도시된 바와 같이 베이스모듈에 제1 사물(예 : 쿠키)이 놓여 있는 상태에서 회전 또는 이동하는 카메라모듈을 이용하여 촬영한 영상으로부터 깊이 정보를 측정하였을 때 (b)에 도시된 바와 같이 25mm 가 측정되었으며, (c)에 도시된 바와 같이 베이스모듈에 제2 사물(예 : 빵)이 놓여 있는 상태에 서 회전 또는 이동하는 카메라모듈을 이용하여 촬영한 영상으로부터 깊이 정보를 측정하였을 때 (d)에 도 시된 바와 같이 80mm 가 측정되었으며, (e)에 도시된 바와 같이 제1 사물의 상부에 제2 사물이 겹쳐 있는 상태 (예 : 쿠키의 상부에 빵이 겹쳐 있는 상태)에서 회전 또는 이동하는 카메라모듈을 이용하여 촬영한 영상으 로부터 깊이 정보를 측정하였을 때 (f)에 도시된 바와 같이 105mm 가 정확히 측정됨으로써, 깊이 정보(또는 높 이 정보)를 바탕으로 겹쳐있는 사물도 정확히 식별할 수 있음을 확인할 수 있다. 도 23은 본 발명에서 회전 또는 이동하는 카메라를 이용하여 깊이 정보가 다른 다양한 사물을 촬영한 영상을 보 인 예시도이고, 도 24는 도 23에 있어서, 사물의 형상별 특징을 분류할 수 있는 2D 및 깊이(Depth) 정보를 보인 예시도이다.데이터베이스(DB)에 다양한 사물들의 2D 및 깊이(Depth) 정보를 그룹핑하고, 각 그룹별 인공지능(AI) 모델을 각 각 생성하여, 학습모델 경량화, 처리시간 단축 및 인식(식별) 성능 향상을 가능하게 한다. 이 때 사물의 특징별 로 각기 다른 인공지능(AI) 모델을 생성하여 적용할 수 있다. 즉, 사물들의 2D 및 깊이(Depth) 정보를 특징으로서 추출하고, 이를 딥러닝 학습 특징으로 사용함으로써, 사물 의 식별력을 향상시킬 수 있으며, 또는 모든 사물을 하나의 모델로 학습하고, 추론할 때 그룹핑된 사물들의 후 보들만을 선택해서 최종 추론할 수도 있다. 도 24를 참조하면, 사물의 형상별 특징을 분류할 수 있는 2D 및 깊이(Depth) 정보는, 영상 데이터(IMAGE DATA), 컬러(COLORS), 사이즈(SIZE), 형태(SHAPE), 위치(POSITION), 트랜잭션 히스토리(TRANSACTION HISTORY), 지오메 트리(GEOMETRY), 및 밝기(BRIGHTNESS) 정보 중 적어도 하나 이상을 포함한다. 도 25는 기존에 회전형 턴테이블에 놓여 있는 사물을 고정식 카메라를 이용하여 촬영한 영상을 바탕으로 입체 영상을 생성하는 방법의 문제점을 설명하기 위하여 보인 예시도로서, 턴테이블(Turn Table) 구조는 사물의 크기 와 놓는 위치에 있어 턴테이블의 크기와 회전 속도에 따른 제약이 있다. 가령, 도 25의 (b)와 같이 사물이 턴테 이블의 크기(또는 넓이)를 넘어서는 경우에는 촬영에 어려움이 있으며, 또한 도 25의 (c)와 같이 사물이 턴테이 블의 가장 자리에 놓인 경우에는 턴테이블의 회전 시 외부로 낙하될 수 있으므로 촬영에 어려움이 있다. 반면 본 실시예는, 도 4 내지 도 8에 도시된 바와 같이, 베이스모듈을 회전시키는 것이 아니라, 지지대모 듈의 형태에 따라 카메라모듈을 다양한 각도와 방향으로 회전 또는 이동시키면서 다양한 각도와 위치 에서 사물의 영상을 촬영할 수 있기 때문에(도 17 참조) 기존 대비 더욱 정확한 입체 영상(즉, 3D 모델링 영 상)을 생성할 수 있도록 하는 효과가 있다. 도 26은 본 발명의 일 실시예에 따라 카메라모듈을 다양한 각도와 방향으로 회전 또는 이동시키면서 촬영한 사 물의 영상을 바탕으로 생성한 입체 영상을 보인 예시도이다. 도 26에 도시된 바와 같이, 본 발명은 적어도 하나의 카메라모듈을 지지대모듈의 형태에 따라 지정된 각도씩 이동(또는 회전)하여 촬영한 동일한 사물(즉, 동일한 좌표 상에 놓여 있는 사물)에 대한 복수의 정보(즉, 동일한 사물에 대하여 각기 다른 방향에서 촬영된 영상에 관련된 정보)(도 17 참조)를 통합하여 입체 영상(또는 3D 모델링 영상)을 생성할 수 있다. 도 27은 본 발명의 일 실시예에 따른 사물 식별 장치의 카메라모듈의 촬영 동작을 테스트하는 사진을 보인 예시 도로서, (a)는 바디(프레임)가 개방된 사물 식별 장치에서 베이스모듈에 놓여 있는 사물이 촬영된 사진이고, (b) 내지 (d)는 바디의 내측 상부에 형성된 지지대모듈을 따라 지정된 각도씩 이동(또는 회전)하는 카메라 모듈에서 사물을 촬영한 사진이다. 이와 같이 본 실시예는 동일한 사물에 대하여 하나의 카메라모듈을 이용하더라도 다양한 방향과 각도에서 촬영된 영상들을 통합하여 입체 영상(또는 3D 모델링 영상)을 생성할 수 있도록 한다. 도 28은 본 발명의 일 실시예에 따른 사물 식별 장치를 학습시키는 방법을 설명하기 위한 예시도이다. 보다 구 체적으로, 도 28은 본 발명의 일 실시예에 따른 사물 식별 장치에서 회전 및 이동하는 카메라 모듈에서 취 득한 다수의 영상에서 3D 모델링을 구성하고, 해당 3D 모델링을 통해 사물이 다양한 위치에 놓인 것과 다양한 포즈로 놓인 것들에 대한 데이터를 인위적으로 생성해서 학습시키는 방법을 설명하기 위한 예시도이다. 도 28의 (a)에 도시된 바와 같이, 프로세서는 베이스모듈에 놓여 있는 사물이 촬영된 영상, 또는 베 이스모듈에 놓여 있는 사물이 촬영된 영상으로부터 깊이 영상이나 입체 영상을 생성한다. 이와 같이 하나의 사물에 대한 깊이 영상이나 입체 영상이 생성되면, (b)에 도시된 바와 같이, 프로세서는 각 사물의 깊이 영상이나 입체 영상을 이용하여 베이스모듈 상에 다양한 위치와 각도로 놓여 있는 복수의 가상의 2D 이미지(즉, 가상 이미지)를 생성한다. 이 때 (b)에 도시된 바와 같이 생성된 가상의 2D 이미지(즉, 가상 이미지)와 (c)에 도시된 바와 같이 사물이 실 제로 촬영된 2D 이미지(즉, 실제 이미지)를 비교하면 사실상 동일한 것을 알 수 있다. 따라서 사물의 입체 영상 을 이용하여 가상의 2D 이미지(즉, 가상 이미지)를 생성할 경우 실제 2D 이미지(즉, 실제 이미지)를 촬영하는 것보다 훨씬 빠르고 간편하게 더 많은 복수의 2D 이미지(즉, 가상 이미지)를 생성할 수 있게 된다. 이와 같이 사물의 입체 영상을 이용하여 복수의 가상의 2D 이미지(즉, 가상 이미지)가 생성되면, (d)에 도시된 바와 같이, 프로세서는 복수의 가상의 2D 이미지(즉, 가상 이미지)를 이용하여 사물을 식별하기 위한 학습(예 : 패턴매칭, 기계학습 또는 딥러닝학습)을 수행한다. 이 때, 상기와 같은 가상의 2D 이미지 생성, 패턴매칭, 기계학습 또는 딥러닝학습은 프로세서에 의해 사물 식별 장치 내에서 수행될 수도 있지만, 실시 환경이나 실시 의도에 따라 상기 사물 식별 장치와 통신모듈 을 통해 유선/무선으로 연결되는 서버나 미리 지정된 클라우드(미도시)에서 수행될 수도 있고 그 결과가 다시 전송되어 데이터베이스(DB)에 저장될 수 있고, 프로세서에 의해 사물 식별 시에 이용될 수 있다. 도 29는 본 발명의 일 실시예에 따라 카메라모듈이 지지대모듈을 따라 회전 또는 이동하며 촬영한 사물의 좌표 정보를 공유함으로써 사물의 식별 시간 및 식별 성능을 향상시키는 방법을 설명하기 위한 예시도이다. 도 29를 참조하면, 프로세서는 카메라모듈의 회전이나 이동에 따라 촬영한 사물의 좌표 정보를 공유 함으로써, 촬영 영상에서 매번 사물의 위치를 검출하지 않아도 동일한 사물을 식별할 수 있도록 한다. 본 발명은 적어도 하나 이상의 카메라모듈이 지지대모듈을 따라 회전 또는 이동하며 촬영한 동일한 좌표 상에 놓여 있는 사물에 대한 정보를 공유함으로써 사물의 식별 시간 및 식별 성능을 향상시키는 방법을 설 명하기 위한 예시도이다. 본 발명은 다양한 방향에서 촬영한 동일한 사물에 대한 정보를 통합(또는 공유)하여 입체 영상(또는 3D 영상)을 생성할 수 있게 됨으로써, 특정 위치에서 제1 사물에 의해 제2 사물에 가림이 발생되는 경우 동일한 좌표 상에 놓여 있는 사물에 대한 식별력을 향상시키는 효과가 있다. 이상으로 본 발명은 도면에 도시된 실시예를 참고로 하여 설명되었으나, 이는 예시적인 것에 불과하며, 당해 기 술이 속하는 분야에서 통상의 지식을 가진 자라면 이로부터 다양한 변형 및 균등한 타 실시예가 가능하다는 점 을 이해할 것이다. 따라서 본 발명의 기술적 보호범위는 아래의 청구범위에 의해서 정하여져야 할 것이다. 또한 본 명세서에서 설명된 구현은, 예컨대, 방법 또는 프로세스, 장치, 소프트웨어 프로그램, 데이터 스트림 또는 신호로 구현될 수 있다. 단일 형태의 구현의 맥락에서만 논의(예컨대, 방법으로서만 논의)되었더라도, 논의된 특징의 구현은 또한 다른 형태(예컨대, 장치 또는 프로그램)로도 구현될 수 있다. 장치는 적절한 하드웨어, 소 프트웨어 및 펌웨어 등으로 구현될 수 있다. 방법은, 예컨대, 컴퓨터, 마이크로프로세서, 집적 회로 또는 프로 그래밍 가능한 로직 디바이스 등을 포함하는 프로세싱 디바이스를 일반적으로 지칭하는 프로세서 등과 같은 장 치에서 구현될 수 있다. 프로세서는 또한 최종-사용자 사이에 정보의 통신을 용이하게 하는 컴퓨터, 셀 폰, 휴 대용/개인용 정보 단말기(personal digital assistant: \"PDA\") 및 다른 디바이스 등과 같은 통신 디바이스를 포함한다."}
{"patent_id": "10-2023-0054344", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일 실시예에 따른 사물 식별 장치의 개략적인 구성을 보인 예시도이다. 도 2는 본 발명의 일 실시예에 따른 사물 식별 장치의 학습모드 동작을 설명하기 위한 흐름도이다. 도 3은 본 발명의 일 실시예에 따른 사물 식별 장치의 식별모드 동작을 설명하기 위한 흐름도이다. 도 4는 본 발명의 일 실시예에 따른 카메라모듈의 회전 방법을 설명하기 위한 예시도이다. 도 5는 도 4에 있어서, 카메라모듈의 회전 범위를 보인 예시도이다. 도 6은 도 4에 있어서, 복수의 지지대모듈을 이용한 카메라모듈의 회전 방법을 설명하기 위한 예시도이다. 도 7은 본 발명의 일 실시예에 따른 카메라모듈의 이동 방법을 설명하기 위한 예시도이다. 도 8은 도 7에 있어서, 복수의 카메라모듈의 이동 방법을 설명하기 위한 예시도이다. 도 9는 본 발명의 일 실시예에 따른 사물 식별 장치의 개략적인 형태를 보인 예시도이다. 도 10은 본 발명의 일 실시예에 따른 사물 식별 장치의 테스트 과정을 촬영한 사진을 보인 예시도이다. 도 11은 도 1에 있어서, 베이스모듈 및 바디나 프레임의 내측 측면에 형성되는 참조패턴을 보인 예시도이다. 도 12는 본 발명의 제1 실시예에 따라 사물 인식에 참조패턴을 활용하는 방법을 설명하기 위한 예시도이다. 도 13은 본 발명의 제2 실시예에 따라 사물 인식에 참조패턴을 활용하는 방법을 설명하기 위한 예시도이다. 도 14는 본 발명의 제3 실시예에 따라 사물 인식에 참조패턴을 활용하는 방법을 설명하기 위한 예시도이다. 도 15는 본 발명의 제4 실시예에 따라 사물 인식에 참조패턴을 활용하는 방법을 설명하기 위한 예시도이다. 도 16은 본 발명의 제5 실시예에 따라 사물 인식에 참조패턴을 활용하는 방법을 설명하기 위한 예시도이다. 도 17은 도 16에 있어서, 참조패턴 기반으로 동일한 사물에 대하여 360도 전 방향에서 촬영된 영상들 중 일부 영상을 보인 예시도이다. 도 18은 도 16에 있어서, 참조패턴 기반으로 동일한 사물을 촬영할 경우와 참조패턴을 이용하지 않고 동일한 사 물을 촬영할 경우에 생성되는 입체 영상을 비교하기 위한 예시도이다. 도 19는 본 발명의 제6 실시예에 따라 사물 인식에 참조패턴을 활용하는 방법을 설명하기 위한 예시도이다. 도 20은 본 발명에서 스테레오 카메라 대신 회전 또는 이동하는 카메라모듈을 이용하여 입체 영상을 생성하는 방법을 설명하기 위한 예시도이다. 도 21은 도 20에 있어서, 구조광을 이용하여 촬영한 영상을 이용하여 입체 영상을 생성하는 방법을 설명하기 위 한 예시도이다. 도 22는 본 발명에서 회전 또는 이동하는 카메라를 이용하여 깊이 정보를 측정할 때 정확도를 설명하기 위한 예 시도이다.도 23은 본 발명에서 회전 또는 이동하는 카메라를 이용하여 깊이 정보가 다른 다양한 사물을 촬영한 영상을 보 인 예시도이다. 도 24는 도 23에 있어서, 사물의 형상별 특징을 분류할 수 있는 2D 및 깊이(Depth) 정보를 보인 예시도이다. 도 25는 기존에 회전형 턴테이블에 놓여 있는 사물을 고정식 카메라를 이용하여 촬영한 영상을 바탕으로 입체 영상을 생성하는 방법의 문제점을 설명하기 위하여 보인 예시도이다. 도 26은 본 발명의 일 실시예에 따라 카메라모듈을 다양한 각도와 방향으로 회전 또는 이동시키면서 촬영한 사 물의 영상을 바탕으로 생성한 입체 영상을 보인 예시도이다. 도 27은 본 발명의 일 실시예에 따른 사물 식별 장치의 카메라모듈의 촬영 동작을 테스트하는 사진을 보인 예시 도이다. 도 28은 본 발명의 일 실시예에 따른 사물 식별 장치를 학습시키는 방법을 설명하기 위한 예시도이다. 도 29는 본 발명의 일 실시예에 따라 카메라모듈이 지지대모듈을 따라 회전 또는 이동하며 촬영한 사물의 좌표 정보를 공유함으로써 사물의 식별 시간 및 식별 성능을 향상시키는 방법을 설명하기 위한 예시도이다."}
