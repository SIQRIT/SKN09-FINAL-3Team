{"patent_id": "10-2018-0142739", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2019-0102973", "출원번호": "10-2018-0142739", "발명의 명칭": "카메라 기반의 촉각 센서 시스템", "출원인": "주식회사 비젼인", "발명자": "최학남"}}
{"patent_id": "10-2018-0142739", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "내면에 다수의 돌기패턴이 형성된 촉감감지부재와, 상기 촉감감지부재의 내면을 촬영하는 단일 카메라를 포함하는 핑거를 구비한 촉각감지장치와;딥러닝 네트워크를 이용하여 상기 단일 카메라에서 입력된 2D 영상에 대해 거리정보가 포함된 시차 맵을 생성하고, 상기 2D 영상 및 시차 맵을 기초로 촉각센싱 정보를 획득하는 제어 장치를 포함하는 촉각 센싱 시스템."}
{"patent_id": "10-2018-0142739", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1 항에 있어서,상기 딥러닝 네트워크는,스테레오용 듀얼 카메라를 통해 생성된 시차 맵과 이에 대응되는 상기 스테레어용 듀얼 카메라 중 하나에 의해생성된 2D 영상으로 구축된 딥러닝 학습용 데이터베이스를 학습하고,상기 딥러닝 학습용 데이터베이스에 대한 학습 정보를 기초로, 상기 단일 카메라에서 입력된 2D 영상에 대한 시차 맵을 생성하는촉각 센싱 시스템."}
{"patent_id": "10-2018-0142739", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 1 항에 있어서,상기 딥러닝 네트워크는 GAN 기반 네트워크로 구성된촉각 센싱 시스템."}
{"patent_id": "10-2018-0142739", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 1 항에 있어서,상기 제어 장치는, 상기 2D 영상을 캘리브레이션(calibration)하여 보정 2D 영상을 생성하고,무접촉 상태의 기준 2D 영상을 기준으로 상기 보정 2D 영상을 비교하여, 상기 패턴돌기의 위치 변이에 관한 2D패턴 분석 정보를 검출하고,상기 2D 패턴 분석 정보에 상기 시차 맵의 거리 정보가 부가된 3D 패턴 정보를 분석하는촉각 센싱 시스템."}
{"patent_id": "10-2018-0142739", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제 1 항에 있어서,상기 촉각센싱 정보는, 눌린 위치, 눌린 방향, 가해진 힘을 포함하는공개특허 10-2019-0102973-3-촉각 센싱 시스템."}
{"patent_id": "10-2018-0142739", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제 1 항에 있어서,상기 핑거는,내부에 관통홀이 형성된 튜브 형상을 갖고, 일끝단에 상기 촉각감지부재가 결합된 핑거프레임과;상기 핑거프레임의 타끝단에 결합되어 상기 관통홀을 덮고, 내면에 상기 단일 카메라가 장착된 리드를 포함하는촉각 센싱 시스템."}
{"patent_id": "10-2018-0142739", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 내면에 다수의 돌기패턴이 형성된 촉감감지부재와, 상기 촉감감지부재의 내면을 촬영하는 단일 카메라 를 포함하는 핑거를 구비한 촉각감지장치와; 딥러닝 네트워크를 이용하여 상기 단일 카메라에서 입력된 2D 영상 에 대해 거리정보가 포함된 시차 맵을 생성하고, 상기 2D 영상 및 시차 맵을 기초로 촉각센싱 정보를 획득하는 제어 장치를 포함하는 촉각 센싱 시스템을 제공한다."}
{"patent_id": "10-2018-0142739", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 카메라 기반의 촉각 센서 시스템에 관한 것이다."}
{"patent_id": "10-2018-0142739", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "로봇 기술 발전과 더불어 사람과 로봇이 보다 긴밀하게 협력하기 위해 촉각 센싱 기술에 대한 연구가 진행되고 있다. 그런데, 현재까지 개발된 촉각 센싱 기술은 고가의 촉각 센서를 사용하며 정확도가 높지 않는 등 여러 가지 제 한이 있다. 따라서, 보다 효율적인 새로운 방식의 촉각 센싱 기술에 대한 개발이 필요하다."}
{"patent_id": "10-2018-0142739", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은, 보다 효율적인 새로운 방식의 촉각 센싱 기술을 구현하는 방안을 제공하는 것에 과제가 있다."}
{"patent_id": "10-2018-0142739", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "전술한 과제를 달성하기 위해, 본 발명은 내면에 다수의 돌기패턴이 형성된 촉감감지부재와, 상기 촉감감지부재 의 내면을 촬영하는 단일 카메라를 포함하는 핑거를 구비한 촉각감지장치와; 딥러닝 네트워크를 이용하여 상기 단일 카메라에서 입력된 2D 영상에 대해 거리정보가 포함된 시차 맵을 생성하고, 상기 2D 영상 및 시차 맵을 기 초로 촉각센싱 정보를 획득하는 제어 장치를 포함하는 촉각 센싱 시스템을 제공한다. 여기서, 상기 딥러닝 네트워크는, 스테레오용 듀얼 카메라를 통해 생성된 시차 맵과 이에 대응되는 상기 스테레 어용 듀얼 카메라 중 하나에 의해 생성된 2D 영상으로 구축된 딥러닝 학습용 데이터베이스를 학습하고, 상기 딥 러닝 학습용 데이터베이스에 대한 학습 정보를 기초로, 상기 단일 카메라에서 입력된 2D 영상에 대한 시차 맵을 생성할 수 있다. 상기 딥러닝 네트워크는 GAN 기반 네트워크로 구성될 수 있다. 상기 제어 장치는, 상기 2D 영상을 캘리브레이션(calibration)하여 보정 2D 영상을 생성하고, 무접촉 상태의 기 준 2D 영상을 기준으로 상기 보정 2D 영상을 비교하여, 상기 패턴돌기의 위치 변이에 관한 2D 패턴 분석 정보를 검출하고, 상기 2D 패턴 분석 정보에 상기 시차 맵의 거리 정보가 부가된 3D 패턴 정보를 분석할 수 있다. 상기 촉각센싱 정보는, 눌린 위치, 눌린 방향, 가해진 힘을 포함할 수 있다. 상기 핑거는, 내부에 관통홀이 형성된 튜브 형상을 갖고, 일끝단에 상기 촉각감지부재가 결합된 핑거프레임과; 상기 핑거프레임의 타끝단에 결합되어 상기 관통홀을 덮고, 내면에 상기 단일 카메라가 장착된 리드를 포함할 수 있다."}
{"patent_id": "10-2018-0142739", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명에서는, 새로운 방식의 효율적인 촉각센싱 기술을 제공하게 되는데, 시차 맵을 이용한 딥러닝 기반의 학 습 기법을 통해 단일 카메라에 의해 촬영된 2D 영상에 대해 거리정보를 검출하여 고성능의 촉각센싱을 수행하는 기술을 제공하게 된다. 이에 따라, 촉각센싱 능력이 진화된 로봇을 구현할 수 있어, 로봇 산업이 획기적으로 발전될 수 있다."}
{"patent_id": "10-2018-0142739", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 도면을 참조하여 본 발명의 실시예를 설명한다. 도 1은 본 발명의 실시예에 따른 촉각 센싱 시스템을 개략적으로 도시한 도면이다. 도 2는 본 발명의 실시예에 따른 촉각 센싱 시스템의 핑거를 개략적으로 도시한 도면이다. 한편, 도 2에서는 하측 및 상측에서 바라본 핑거 를 각각 도시하였다. 도 3은 본 발명의 실시예에 따른 핑거의 패턴돌기를 개략적으로 도시한 도면이다. 도 1을 참조하면, 본 발명의 실시예에 따른 촉각 센싱 시스템은 영상을 기반으로 한 촉각 센싱 시스템에 해당된 다. 이와 같은 촉각 센싱 시스템은, 촉각 감지 장치와 제어 장치를 포함할 수 있다. 촉각 감지 장치는, 대상체(OB)에 대해 촉각 센싱을 수행하고 센싱 결과에 따라 대상체(OB)에 대한 작업을 수행하는 소위 로봇암(robot arm)을 이용하여 구성될 수 있다. 이와 같이 구성된 촉각 감지 장치는 로봇암 본체와, 로봇암 본체의 끝단(또는 말단)에 구성된 적어도 하나의 핑거를 포함할 수 있다. 로봇암 본체에는 적어도 하나의 관절부재가 구성되어, 사람의 팔과 유사한 동작을 수행할 수 있도록 구성 될 수 있다. 핑거는 로봇암 본체와 관절부재를 통해 연결될 수 있다. 한편, 핑거의 로봇암 본체 측 끝 단에는 힘센서(일예로, 6축 힘센서)가 결합될 수 있다. 이와 같은 핑거는, 핑거의 실질적인 형상을 정의하는 핑거프레임과, 핑거프레임의 일끝단 에 장착된 촉각감지부재(또는 촉각감지팁)를 포함할 수 있다. 이와 같은 핑거에 대해 도 2를 함께 참조하여 살펴보면, 핑거프레임은 내부에 관통홀을 포함할 수 있 다. 즉, 핑거프레임은 내부에 이의 길이방향을 따라 양단이 개방된 형태 즉 중공 형태로 구성될 수 있다.일예로, 핑거프레임은 원형의 튜브 형상인 실리더 형상으로 형성될 수 있는데, 이에 한정되지는 않으며 다 각형의 튜브 형상으로 형성될 수 있다. 이와 같은 핑거프레임의 일끝단(또는 말단)에는 촉각감지부재가 결합될 수 있다. 촉각감지부재는 영상 기반의 촉각센싱을 위한 부재로서, 이는 고무와 같이 탄성을 갖는 물질로 형성될 수 있다. 즉, 촉각감지부재는, 대상체(OB)와 접촉하는 경우에 그 형태가 변형되고, 접촉이 해제되면 원래의 형태로 복원되는 탄성재질로 형성될 수 있다. 이와 같은 촉각감지부재는 외부 방향으로 볼록하게 돌출된 형태로 형성될 수 있다. 이와 같은 촉각감지부재의 내면(즉, 접촉면인 외면에 반대되는 표면)에는, 도 3에 도시한 바와 같이, 영상 기반의 촉각센싱을 실질적으로 구현하기 위한 다수의 패턴돌기가 형성될 수 있다. 패턴돌기들은 실질적으로 촉각감지부재의 내면 전체를 따라 서로 일정 간격 이격되어 분포될 수 있다. 여기서, 이격 간격은 모두 동일하거나 위치에 따라 변화되도록 구성될 수 있다. 한편, 패턴돌기들은, 카르테시안 좌표계 또는 폴라 좌표계 기반의 2D-to-3D 매핑 방법에 따라 촉각감지부 재 내면에 배치되도록 구성될 수 있다. 한편, 촉각감지부재의 내면을 영상 촬영(또는 캡쳐)할 때, 영상 내에서 패턴돌기들의 시인성을 용이 하게 확보하기 위해, 패턴돌기들과 이 주변에 위치하는 촉각감지부재의 내면 부분들은 서로 다른 컬 러를 갖도록 형성될 수 있다. 이와 관련하여 예를 들면, 패턴돌기들의 표면은 반사특성 또는 형광특성을 갖도록 형성될 수 있다. 일예로, 백색이나 은색의 물질 반사 물질이 도포되거나 형광물질이 도포될 수 있다. 그리고, 패턴돌기들 주변에 위치하는 촉각감지부재의 내면 부분들은 광흡수 특성을 갖도록 검은색으로 형성될 수 있다. 이와 같이 패턴돌기들이 촉각감지부재의 내면에 형성됨으로써, 대상체(OB)에 접촉되는 경우에 패턴돌 기들의 분포나 위치 등이 변형되고 이와 같은 변형을 기초로 촉각센싱이 구현될 수 있다. 한편, 핑거에는 촉각감지부재의 내면을 촬영하는 촬영수단인 카메라가 장착될 수 있다. 더욱이, 핑거에는 촬영시 요구되는 광을 제공하는 광원으로서 예를 들어 발광다이오드가 적어도 하나 장착될 수 있다. 여기서, 핑거에는 단일의 카메라가 장착되는 것이 바람직하다. 이와 같은 카메라는, 촉각감지부 재의 내면을 바라보는 위치에 장착될 수 있다. 이와 관련하여 예를 들면, 핑거프레임의 타끝단에는 관통홀을 덮는 리드가 구비될 수 있고, 이 리드의 내면에 카메라가 촉각감지부재의 내면을 바라보도록 배치될 수 있다. 이때, 단일의 카메라는 리드의 내면 중앙부에 위치하는 것이 바람직하다. 그리고, 발광다이오드는 핑거프레임에 설치될 수 있는데, 일예로 핑거프레임의 일끝단 바닥면에 설치될 수 있다. 다른 예로서, 발광다이오드는 핑거프레임의 내주면 하단부에 설치될 수도 있다. 이와 같이 설치된 발광다이오드에서 발생된 광은 촉각감지부재의 내면에 제공되고, 이와 같이 광이 제공된 상태에서 카메라가 촉각감지부재를 촬영할 수 있다. 카메라에 의해 촬영된 영상인 2D(2차원) 영상으로서 촉각센싱을 위한 영상이 제어 장치에 전송된다. 제어 장치는 촉각 감지 장치를 전반적으로 제어하는 구성으로서, 촉각감지에 관한 촉각 감지 장치 의 동작을 제어할 수 있다. 이와 관련하여, 제어 장치는 카메라의 촬영을 제어하고, 카메라에 의해 촬영된 촉각감지부재 내면의 2D 영상 즉 패턴돌기들에 대한 2D 영상을 분석하여, 촉각센싱 정보를 획득할 수 있다. 이에 대해, 입력된 2D 영상에서의 패턴돌기들을 특징점으로 하여 이들의 분포 패턴 또는 배열 패턴을 분석 함으로써, 대상체(OB) 터치시의 센서감지부재에 가해진(또는 인가된 또는 작용하는) 힘, 눌린(또는 접촉) 위치, 눌린 방향 등 다양한 촉각센싱 정보를 획득할 수 있다. 더욱이, 제어 장치는, 획득된 촉각센싱 정보를 기초로 하여 촉각 센싱 장치를 구성하는 로봇암의 후 속 동작을 제어할 수 있다.이와 같은 제어 장치는 영상 분석을 포함하여 다양한 데이터 연산 처리를 수행하는 소위 컴퓨터를 이용하 여 구성될 수 있다. 한편, 단일의 카메라에서 촬영된 2D 영상은 평면적인 영상으로서 예를 들어 카메라 위치를 기준으로 한 거 리 정보(또는 깊이정보)는 포함되어 있지 않은 상태이다. 이러한바, 대상체(OB)에 대한 눌린 위치, 눌린 방향, 3축 힘 등 보다 다양하고 정확한 촉각센싱 정보를 획득하기 위해서, 2D 영상에서 특징점인 패턴돌기에 대 한 거리정보(또는 깊이정보)를 추출하는 것이 바람직하다 할 것이다. 이를 위해, 본 실시예에서는, 제어 장치는 인공지능 기술인 딥러닝 네트워크를 이용하도록 구성될 수 있다. 이와 관련하여 예를 들면, 도 4에 도시한 바와 같이, 2대의 카메라 즉 스테레오용 듀얼 카메라를 이 용하여, 다양한 접촉 환경에서, 3D 영상에 해당되는 시차 맵(disparity map) (또는 시창 영상 또는 스테레오 (stereo) 영상)을 생성하고 이를 딥러닝 학습용 데이터베이스로 구축할 수 있다. 여기서, 딥러닝 학습용 데이터 베이스에는, 각 시차 맵에 대해 이에 대응되는 2대의 스테레오용 듀얼 카메라 중 하나에 의해 생성된 2D 영상이 함께 저장될 수 있다. 한편, 도 4는 딥러닝 학습용 데이터베이스 구축을 수행하는 과정에서 사용되는 핑거의 구조를 개략적으로 도시한 것으로서, 도 2의 촉각센싱 과정에서의 핑거의 구조와 비교할 때, 서로 일정 간격 이격된 2대의 스 테레오용 듀얼 카메라가 리드의 내면에 촉각감지부재의 내면을 바라보도록 배치될 수 있다. 제어 장치는 딥러닝 네트워크를 통해 딥러닝 학습용 데이터베이스를 학습함으로써, 단일 카메라를 통 해 촬영된 2D 영상에 대한 거리 정보를 보다 정확하게 추측(또는 예측)할 수 있게 된다. 이와 관련하여 도 5 및 6을 참조할 수 있다. 도 5는 본 발명의 실시예에 따른 딥러닝 학습용 데이터베이스를 설명하기 위한 도면이다. 이와 같은 학습용 데 이터베이스에는 스테레오용 카메라를 통해 생성된 각 시차 맵과 이에 대응되는 2D 영상이 데이터베이스화될 수 있다. 그리고, 도 6은 본 발명의 실시예에 따른 딥러닝 기반의 거리 추출 과정을 설명하기 위한 도면이다. 촉각센싱 과정에서, 제어 장치에 설치된 딥러닝 네트워크는 입력된 2D 영상에 대해 딥러닝 학습을 기초로 하여 해당 시차 맵을 생성할 수 있다. 즉, 딥러닝 학습 정보를 기초로, 단일 카메라에 의해 입력된 2D 영상에 대해 거리 정보를 예측하고 이 거리 정보를 반영한 시차 맵이 생성될 수 있다. 위와 같이, 본 실시예에서는 딥러닝 기술을 이용하여 2D 영상에 대해 정확도가 높은 거리 정보를 추출할 수 있 게 된다. 이에 따라, 단일 카메라를 이용하면서도 듀얼카메라를 사용한 경우와 실질적으로 동등 수준의 촉 각센싱을 효과적으로 구현할 수 있는 장점이 있다. 한편, 시차 맵을 생성하기 위한 딥러닝 네트워크는, 예를 들면 도 6의 하부에 도시한 GAN 기반의 네트워크 를 이용할 수 있다. 한편, 제어 장치에서의 영상패턴 분석을 통한 촉각센싱 과정에 대해 도 7을 참조할 수 있다. 도 7은 본 발 명의 실시예에 따른 제어 장치의 패턴분석부에서의 영상패턴 분석 과정을 도시한 도면이다. 도 7을 참조하면, 제어 장치에는 패턴분석부가 구비될 수 있으며, 이 패턴분석부는 단일 카메라에 의 해 촬영된 2D 영상을 입력받고 이를 보정(즉, 캘리브레이션)하여 보정된 2D 영상을 생성할 수 있다. 이와 관련 하여, 사전에 준비된 변환행렬(transform matrix)을 통해 입력 영상의 패턴돌기들 즉 특징점들의 위치를 변환함으로써 캘리브레이션된 보정 2D 영상이 생성될 수 있다. 이와 같은 보정 2D 영상은, 기준(reference) 2D 영상과 비교되어 평면적 즉 2D(이차원) 패턴 분석이 수행될 수 있다. 여기서, 기준 2D 영상은, 단일의 카메라를 통해 무접촉 상태 즉 원형 상태의 촉각감지부재의 내면을 촬영한 영상에 해당된다. 이와 같은 기준 2D 영상을 기초로 한 보정 2D 영상의 패턴 분석은 실질적으로 거리정보가 반영되지 않은 것으로 서, 이 2D 패턴 분석에서는 기준 2D 영상의 특징점들(즉, 기준 특징점들)을 기준으로 이들 각각에 대응되는 보 정 2D 영상 내의 특징점들의 2D 위치 변이(또는 변화)를 추출할 수 있다. 즉, 특징점들의 배열 패턴의 2D 변이 를 추출할 수 있다.이와 같은 2D 패턴 분석에서의 특징점들의 위치 변이를 통해, 대상체(OB)에 의해 눌린 위치, 형상 등을 검출할 수 있다. 한편, 단일 카메라에 의해 촬영된 2D 영상 입력시, 딥러닝 네트워크에 의해 생성된 시차 맵이 패턴분 석부에 입력될 수 있으며, 입력된 시차 맵은 보정 2D 영상 생성과 연동되어 보정될 수 있다. 다음으로, 2D 패턴 분석 정보에 거리 정보(z)가 부가된 3D 패턴 분석 정보가 생성될 수 있다. 이와 같은 거리 정보(z)는, 2D 영상과 함께 입력된 시차 맵에서 추출될 수 있다. 한편, 2D 패턴 분석 정보를 기초로 한 거리 정보가 시차 맵의 거리 정보에 반영되어, 거리 정보(z)의 정확도가 향상될 수도 있다. 이에 대해, 2D 패턴 분석에서의 위치 변화는 거리 변화와 관련되어 있으므로, 2D 패턴 분석 정보를 기초로 한 거리 정보가 시차 맵의 거리 정보에 반영되어, 정확도가 향상된 거리 정보(z)가 추출될 수 있 다. 위와 같은 과정에 따라, 2D 패턴 분석 정보에 거리 정보(z)가 포함된 3D 패턴 정보가 획득될 수 있다. 이와 같이 획득된 거리 정보가 포함된 3D 패턴 정보를 분석하여, 대상체(OB)에 의해 눌린 힘과 방향을 산출할 수 있다. 한편, 제어 장치에는 특징점 추출을 위한 특징점 추출부가 구성될 수 있으며 이 특징점 추출부는 강인한 특징점 추출을 위한 알고리즘을 이용할 수 있다. 이와 관련하여 도 8을 참조할 수 있는데, 특징점 추출 알고리즘은 특징점 추출부에 입력된 입력 영상(또는 소스 영상)을 이진화 영상으로 변환하는 것을 포함하는 이진화 프로세스 즉 스레스홀딩(thresholding) 프로세스와, 픽셀 레벨에서의 그룹핑(grouping) 프로세스와, 블럽레벨에서의 머징(merging) 프로세스와, 필터링(filtering) 프로세스와, 볼검출 즉 센터 및 반경 산출 프로세스 등의 단계들을 포함할 수 있다. 도 9에는, 입력 영상에 특징점 추출 알고리즘을 적용하여 특징점을 추출한 결과가 도시되어 있다. 한편, 제어 장치에는 촉각센싱 대상체(OB)에 의해 눌린 형상(또는 모양)을 검출하는 형상 검출부가 구성될 수 있으며 이 형상 검출부는 정확한 형상 검출을 위한 알고리즘을 이용할 수 있다. 한편, 형상 검출부는, 전술 한 패턴분석부에 포함되거나 별도로 구성될 수 있으며, 2D 패턴 분석 정보를 이용할 수 있다. 도 10을 참조하면, 형상 검출 알고리즘은 오프라인 페이스(offline phase)와 온라인 페이스(online phase)를 포 함할 수 있다. 촉각센싱 수행 전의 오프라인 페이스에서는, 무접촉 상태의 입력 영상들을 평균화하여 평균 백그라운드(mBG)를 산출하고, 이를 온라인페이스에 사용할 수 있도록 저장하게 된다. 촉각센싱이 수행되는 온라인 페이스에서는, 입력 영상에 대해 특징점들(key points)을 검출하고, 특징점들에 대 한 특성(feature)을 산출하고, SVM 분류기(classifier)를 통해 형상을 추정할 수 있다. 여기서, 특징점들의 특성은, 특징점들의 개수(nK), 특징점 크기의 평균(mS), 특징점들의 표준편차(sS), 백그라 운드(mBG)와 입력 영상 사이의 평균 차이(또는 평균 차분 영상)(mD)를 포함할 수 있다. SVM 분류기는 형상 분류기로서, 사전에 정의되고 분류된 다수의 형상들 중 입력 영상의 특징점들의 특성에 대응 되는 형상을 출력할 수 있다. 일예를 들면, 삼각형, 사각형, 또는 무접촉 상태 등이 정의될 수 있고, 이들 중 입력 영상의 특성에 대응되는 형상이 선택되어 출력될 수 있다. 한편, 제어 장치는 위와 같이 추출된 형상과 특징점들의 분포 패턴을 이용하여 대상체(OB)의 접촉면의 면 적 즉 눌린 면적을 산출할 수 있다. 한편, 제어 장치는 위와 같이 추출된 형상과 특징점들의 분포 패턴을 이용하여 눌린 힘 보다 상세하게는 3 축 힘의 크기 및/또는 방향을 산출할 수 있다. 3축 힘의 산출과 관련하여 도 11을 참조할 수 있는데, 입력 영상에 대해 특징점을 추출하고, 힘의 위치와 방향 을 검출할 수 있다. 그 후, 특징점들을 분석하여 힘이 가해진 방향을 확인한 후, 해당 방향에서의 패턴돌기들의 패턴 형태와 주변 돌기들의 패턴 형태를 분석하여 최종 힘을 계산한다. 전술한 바와 같이, 본 발명의 실시예에서는, 새로운 방식의 효율적인 촉각센싱 기술을 제공하게 되는데, 시차 맵을 이용한 딥러닝 기반의 학습 기법을 통해 단일 카메라에 의해 촬영된 2D 영상에 대해 거리정보를 검출하여고성능의 촉각센싱을 수행하는 기술을 제공하게 된다. 이에 따라, 촉각센싱 능력이 진화된 로봇을 구현할 수 있어, 로봇 산업이 획기적으로 발전될 수 있다. 한편, 전술한 본 발명의 실시예의 촉각센싱 방법은 컴퓨터를 통하여 수행될 수 있는 프로그램 명령 형태로 구현 되어 컴퓨터 판독 가능 매체에 기록될 수 있다. 컴퓨터 판독 가능 매체는 프로그램 명령, 데이터 파일, 데이터 구조 등을 단독으로 또는 조합하여 포함할 수 있다. 매체에 기록되는 프로그램 명령은 본 발명을 위하여 특별히 설계되고 구성된 것들이거나 컴퓨터 소프트웨어 당업자에게 공지되어 사용 가능한 것일 수도 있다. 컴퓨터 판독 가능 기록 매체의 예에는 하드 디스크, 플로피 디스크 및 자기 테이프와 같은 자기 매체(magnetic media), CD- ROM, DVD와 같은 광기록 매체(optical media), 플롭티컬 디스크(floptical disk)와 같은 자기-광 매체 (magneto-optical), 및 롬(ROM), 램(RAM), 플래시 메모리 등을 포함한다. 프로그램 명령의 예에는 컴파일러에 의해 만들어지는 것과 같은 기계어 코드뿐만 아니라 인터프리터 등을 사용해서 컴퓨터에 의해서 실행될 수 있는 고급 언어 코드를 포함한다. 상기된 하드웨어 장치는 본 발명의 일 실시예들의 동작을 수행하기 위해 하나 이상 의 소프트웨어 모듈로서 작동하도록 구성될 수 있으며, 그 역도 마찬가지이다. 전술한 본 발명의 실시예는 본 발명의 일예로서, 본 발명의 정신에 포함되는 범위 내에서 자유로운 변형이 가능 하다. 따라서, 본 발명은, 첨부된 특허청구범위 및 이와 등가되는 범위 내에서의 본 발명의 변형을 포함한다."}
{"patent_id": "10-2018-0142739", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 실시예에 따른 촉각 센싱 시스템을 개략적으로 도시한 도면. 도 2는 본 발명의 실시예에 따른 촉각 센싱 시스템의 핑거를 개략적으로 도시한 도면. 도 3은 본 발명의 실시예에 따른 핑거의 패턴돌기를 개략적으로 도시한 도면. 도 4는 본 발명의 실시예에 따른 촉각 센싱 시스템에서 딥러닝 학습용 데이터베이스 구축을 수행하는 과정에서 사용되는 핑거의 구조를 개략적으로 도시한 것 도 5는 본 발명의 실시예에 따른 딥러닝 학습용 데이터베이스를 설명하기 위한 도면. 도 6은 본 발명의 실시예에 따른 딥러닝 기반의 거리 추출 과정을 설명하기 위한 도면. 도 7은 본 발명의 실시예에 따른 제어 장치의 패턴분석부에서의 영상패턴 분석 과정을 도시한 도면. 도 8은 본 발명의 실시예에 따른 특징점 추출 알고리즘을 설명한 도면. 도 9는 본 발명의 실시예에 따른 입력 영상에 대해 특징점 추출 알고리즘을 적용하여 특징점을 추출한 결과를 도시한 도면. 도 10은 본 발명의 실시예에 따른 형상 검출 알고리즘을 설명한 도면. 도 11은 본 발명의 실시예에 따른 힘 검출 과정을 설명한 도면."}
