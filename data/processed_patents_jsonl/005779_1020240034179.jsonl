{"patent_id": "10-2024-0034179", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0138038", "출원번호": "10-2024-0034179", "발명의 명칭": "비전-언어 트랜스포머를 사전 훈련하는 방법 및 이를 통해 사전 훈련된 비전-언어 트랜스포머", "출원인": "주식회사 LG 경영개발원", "발명자": "김범수"}}
{"patent_id": "10-2024-0034179", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "메모리와 프로세서를 포함하는 컴퓨팅 시스템이 복수의 원본 이미지-텍스트 쌍의 데이터셋으로 비전-언어 트랜스포머를 사전 훈련하는 방법으로서,상기 원본 이미지를 무작위 증강하여 복수의 증강 이미지를 생성하는 단계;상기 원본 이미지에 매칭된 텍스트를 텍스트 인코더에 입력하여 텍스트 특징벡터 표현들을 출력하는 단계;상기 원본 이미지와 복수의 증강 이미지를 티처 이미지 인코더에 입력하여 제1 이미지 특징벡터 표현들을 출력하는 단계;상기 원본 이미지와 복수의 증강 이미지를 스튜던트 이미지 인코더에 입력하여 제2 이미지 특징벡터 표현들을출력하는 단계;상기 텍스트 특징벡터 표현들과 상기 제1 이미지 특징벡터 표현들에 대해 제1 정렬 매트릭을 생성하는 단계;이미지-텍스트 쌍의 포지티브와 네거티브 맵핑 관계에 따라서 유사성을 가지도록 상기 텍스트 특징벡터 표현들과 상기 제1 이미지 특징벡터 표현들이 정렬되도록 상기 제1 정렬 매트릭을 학습하는 단계;상기 학습된 제1 정렬 매트릭의 출력을 예측하도록 상기 제2 정렬 매트릭을 정렬시켜 스튜던트 이미지 인코더에지식 증류를 수행하는 단계를 포함하는 비전-언어 트랜스포머 사전 훈련 방법."}
{"patent_id": "10-2024-0034179", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1 항에 있어서,상기 티처 이미지 인코더에 입력하여 제1 이미지 특징벡터 표현들을 출력하는 단계는,상기 원본 이미지들과 복수의 증강 이미지들을 복수의 셀프 어텐션 레이어와, 피드 포워트 네트워크 레이어를통해 제1 이미지 특징벡터 표현들을 출력하는 단계를 포함하는 비전-언어 트랜스포머 사전 훈련 방법."}
{"patent_id": "10-2024-0034179", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2 항에 있어서,상기 스튜던트 이미지 인코더에 입력하여 제2 이미지 특징벡터 표현들을 출력하는 단계는,상기 원본 이미지들과 복수의 증강 이미지들을 복수의 셀프 어텐션 레이어에서의 출력 값을 기초로 토큰 희소화레이어에 입력하여 토큰 희소화를 수행하는 단계를 포함하는 비전-언어 트랜스포머 사전 훈련 방법."}
{"patent_id": "10-2024-0034179", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1 항에 있어서,상기 텍스트 특징벡터 표현들과 상기 제1 이미지 특징벡터 표현들이 정렬되도록 상기 제1 정렬 매트릭을 학습하는 단계는,상기 원본 이미지-텍스트 쌍과 증강 이미지-텍스트 쌍의 맵핑관계에 따라서 상기 텍스트 특징벡터 표현들과 상기 제1 이미지 특징벡터 표현들과의 포지티브 특징벡터 표현 쌍과, 네가티브 특징벡터 표현 쌍을 결정하는 단계와, 공개특허 10-2024-0138038-3-유사성 정렬을 위해 상기 포지티브 특징벡터 표현 쌍 사이의 거리는 가까워지도록 하고 상기 네가티브 특징벡터표현 쌍 사이의 거리는 멀어지도록 하는 손실함수에 따라 티처 이미지 인코더를를 학습하는 단계를 포함하는 비전-언어 트랜스포머 사전 훈련 방법."}
{"patent_id": "10-2024-0034179", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4 항에 있어서,상기 손실함수에 따라 인코더들을 학습하는 단계는,상기 손실함수에 따라 유사성 정렬을 위하 학습시, 상기 티처 이미지 인코더에 모멘텀 정지 기울기를 적용해 역전파를 차단하는 단계를 포함하는 비전-언어 트랜스포머 사전 훈련 방법."}
{"patent_id": "10-2024-0034179", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5 항에 있어서,상기 스튜던트 이미지 인코더에 지식 증류를 수행하는 단계는,상기 유사성 정렬에 따른 제1 정렬 매트릭의 출력 값을 상기 제2 정렬 메트릭이 예측하도록 지식 증류하는 단계를 포함하는 비전-언어 트랜스포머 사전 훈련 방법."}
{"patent_id": "10-2024-0034179", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6 항에 있어서,상기 제2 정렬 매트릭에 대해 지식 증류를 수행하는 단계는,상기 지식 증류 중 상기 텍스트 인코더로의 역전파를 차단하는 단계를 포함하는 비전-언어 트랜스포머 사전 훈련 방법."}
{"patent_id": "10-2024-0034179", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7 항에 있어서,상기 제2 정렬 매트릭에 대해 지식 증류를 수행하는 단계는,상기 제2 정렬 매트릭의 매개변수가 상기 제1 정렬 매트릭의 매개변수를 따르도록 지식 증류하는 단계를 포함하는 비전-언어 트랜스포머 사전 훈련 방법."}
{"patent_id": "10-2024-0034179", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8 항에 있어서,상기 제2 정렬 매트릭의 매개변수가 상기 제1 정렬 매트릭의 매개변수를 따르도록 지식 증류하는 단계는, 상기 제2 정렬 매트릭의 매개변수를 제1 정렬 매트릭의 매개변수에 지수 이동 평균(EMA)로 업데이트하는 단계를포함하는 비전-언어 트랜스포머 사전 훈련 방법."}
{"patent_id": "10-2024-0034179", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제1 항에 있어서,상기 제2 정렬 매트릭에 대해 지식 증류를 수행하는 단계는,상기 제1 이미지 특징벡터 표현과 텍스트 특징벡터 표현의 거리 및 상기 제2 이미지 특징벡터 표현과 텍스트 특공개특허 10-2024-0138038-4-징벡터 표현의 거리를 통해 증강 이미지와 텍스트 사이의 오정렬 정보를 반영한 손실함수를 정의하여 지식 증류하는 단계를 포함하는 비전-언어 트랜스포머 사전 훈련 방법."}
{"patent_id": "10-2024-0034179", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제10 항에 있어서,상기 거리를 기초로 손실함수를 정의하여 지식 증류하는 단계는,상기 스튜던트 이미지 인코더가 출력한 원본 이미지 특징벡터 표현과 텍스트 특징벡터 표현 사이의 제1 유클리드 거리와, 상기 스튜던트 이미지 인코더가 출력한 증강 이미지 특징벡터 표현과 텍스트 특징벡터 표현의 제2유클리드 거리를 산출하고, 상기 제1 유클리드 거리와 제2 유클리드 거리의 비율을 로그 스케일로 산출한 제1로그 비율을 산출하는 단계를 포함하는 비전-언어 트랜스포머 사전 훈련 방법."}
{"patent_id": "10-2024-0034179", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11 항에 있어서,상기 거리를 기초로 손실함수를 정의하여 지식 증류하는 단계는,상기 티처 이미지 인코더가 출력한 원본 이미지 특징벡터 표현과 텍스트 특징벡터 표현 사이의 제3 유클리드 거리와, 상기 티처 이미지 인코더가 출력한 증강 이미지 특징벡터 표현과 텍스트 특징벡터 표현의 제4 유클리드거리를 산출하고, 상기 제3 유클리드 거리와 상기 제4 유클리드 거리의 비율을 로그 스케일로 산출한 제2 로그비율을 산출하는 단계를 포함하는 비전-언어 트랜스포머 사전 훈련 방법."}
{"patent_id": "10-2024-0034179", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제12 항에 있어서,상기 거리를 기초로 손실함수를 정의하여 지식 증류하는 단계는,상기 제1 로그 비율과 상기 제2 로그 비율의 차이를 제2 정렬 메트릭이 제1 정렬 메트릭에 근사하도록 정렬시키기 위한 손실함수로 정의하여 지식 증류를 수행하는 단계를 더 포함하는 비전-언어 트랜스포머 사전 훈련 방법."}
{"patent_id": "10-2024-0034179", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제13 항에 있어서,상기 제1 정렬 매트릭과 제2 정렬 매트릭을 정렬하도록 하기 위한 손실함수는,로 정의되는 비전-언어 트랜스포머 사전 훈련 방법."}
{"patent_id": "10-2024-0034179", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제10 항에 있어서,상기 티처 이미지 인코더와 상기 텍스트 인코더 사이의 역전파 방지를 위해 정지 기울기를 통한 업데이트를 수행하는 단계를 더 포함하는 비전-언어 트랜스포머 사전 훈련 방법.공개특허 10-2024-0138038-5-청구항 16 제1 항에 따라 사전 훈련된 비전-언어 트랜스포머를 포함하여여 비전 테스크 수행를 수행하는 인공지능 시스템."}
{"patent_id": "10-2024-0034179", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "메모리와 프로세서를 포함하는 컴퓨팅 시스템이 사전 훈련한 비전-언어 트랜스포머로서,텍스트들을 입력받아 텍스트 특징벡터 표현을 출력하는 텍스트 인코더;원본 이미지들과 상기 원본 이미지들로부터 증강된 복수의 증강 이미지를 입력 받아 제1 이미지 특징벡터 표현들을 출력하는 티처 이미지 인코더;상기 원본 이미지들과 상기 원본 이미지들로부터 증강된 복수의 증강 이미지를 입력 받아 제2 이미지 특징벡터표현들을 출력하는 스튜던트 이미지 인코더; 및상기 티처 이미지 인코더와 상기 텍스트 인코더는 상기 텍스트 특징벡터 표현들과 상기 제1 이미지 특징벡터 표현들을 유사성 정렬하여 제1 정렬 매트릭이 학습되고, 상기 스튜던트 이미지 인코더는 상기 텍스트 특징벡터 표현들과 상기 제2 이미지 특징벡터 표현들에 대한 제2정렬 매트릭이 상기 제1 정렬 매트릭에 출력값을 예측하도록 지식 증류된사전 훈련된 비전-언어 트랜스포머."}
{"patent_id": "10-2024-0034179", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 대규모 크기의 선별되지 않은 데이터셋(large uncurated datasets)을 이미지 확대 또는/및 마스킹 등 을 통해 증강하고, 비전-언어 트랜스포머(Vision Transformers)를 증강에 따라 증강 이미지와 텍스트 사이의 오 정렬된 정보를 지식 증류 프레임워크를 통해 반영하여 사전 훈련하여, 데이터처리 오버헤드를 감소시키며 신속하 게 간소화된 비전-언어 트랜스포머를 학습시키는 방법 및 시스템에 관한 것이다."}
{"patent_id": "10-2024-0034179", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 비전과 언어 데이터로 트랜스포머를 사전 훈련하는 방법과, 이를 통해 사전 훈련된 비전 트랜스포머 를 포함하는 인공지능 시스템에 관한 것이다."}
{"patent_id": "10-2024-0034179", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "최근 대규모 일반 도메인 데이터에 대하여 사전 훈련된(pre-trained) 비전-언어 모델(Vision-Language Pretraining, VLP)이 등장하면서, 인공지능 기반 컴퓨터 비전 처리 기술이 급격하게 발전하고 있다. 특히, 선행문헌 1과 같이 글로벌 셀프 어텐션(Global self-attention)과 대조 언어-이미지 기반 사전훈련 (Contrastive Language-Image Pretraining) 등의 기술을 적용한 대규모 이미지-텍스트 데이터 세트로 훈련된 비전 트랜스포머(Vision Transformers)는 다양하고 까다로운 비전 작업 등에 대한 다운스트림 테스크에서 혁신 적인 진전을 나타내었다. 그러나 비전 트랜스포머에서 주로 구동되는 글로벌 셀프 언텐션을 완전히 트레이닝하기 위해서는 대규모의 데이 터 세트가 필요하며 과도한 데이터 처리 오버헤드를 가지는 문제가 있다. 이러한 대규모 데이터 세트를 확보하기 위해서, 언어 데이터 또는/및 비전 데이터를 증강(Augmentation)하여 다 양한 데이터를 확보하는 방식을 많이 사용하며, 예를 들어, 기존 이미지를 회전, 뒤집기, 크기 조절, 잘라내기, 색상 조정, 확대, 자르기 및 가우시안 노이즈 추가 등을 무작위로 적용하는 방식을 사용한다. 위 이미지를 증강하는 과정 중 특히 특정 영역을 확대하거나 축소하고, 잘라내기 등을 하는 등을 무작위로 수행 할 경우, 기존 증강 대상이였던 이미지와 매칭된 텍스트와 불일치되는 오정렬(Misalign) 문제가 발생한다. 그리고 이와 같이 오정렬된 증강된 이미지에 증강 전 이미지와 매칭된 텍스트를 쌍을 기초로 비전-언어 트랜스 포머를 기존 방식대로 사전 훈련할 경우, 사전 훈련된 비전-언어 트랜스포머의 최종 성능이 저하되는 문제가 발 생한다. 이러한 문제를 극복하기 위하여, 선행문헌 2는 오정렬을 객체 감지기를 통해 검출하고 오정렬이 검출되면 텍스"}
{"patent_id": "10-2024-0034179", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 2, "content": "트를 요약 추출기를 통해 수정하는 추가적인 외부 모듈을 도입하는 기술을 제안하였으며, 선행문헌 3은, 스테이 션 임베딩을 통해 사전 훈련 중 정렬을 일치시키는 기술을 제안하였다. 그러나 이와같이 외부 모듈을 사용할 경 우 데이터 처리량 등이 증가하여 사전 훈련에 큰 부담을 주는 문제가 있다. 선행기술문헌 특허문헌 (특허문헌 0001) 선행문헌 1: Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, Gretchen Krueger, Ilya Sutskever. Learning Transferable Visual Models From Natural Language Supervision, on 26 Feb 2021 (특허문헌 0002) 선행문헌 2: Yuting Gao, Jinfeng Liu, Zihan Xu, Jun Zhang, Ke Li, and Chunhua Shen. Pyramidclip: Hierarchical feature alignment for vision-language model pretraining. arXiv preprint arXiv:2204.14095, 2022. 1, 2, 3 (특허문헌 0003) 선행문헌 3: Janghyeon Lee, Jongsuk Kim, Hyounguk Shon, Bumsoo Kim, Seung Hwan Kim, Honglak Lee, and Junmo Kim. Uniclip: Unified framework for contrastive language-image pretraining. In Advances in Neural Information Processing Systems, 2022. 1, 2, 3, 5, 6, 7"}
{"patent_id": "10-2024-0034179", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명에 따른 비전-언어 트랜스포머 사전 훈련 방법은, 사전 훈련에 필요한 다수의 이미지 데이터를 무작위로 확대하거나 마스킹하여 다수의 이미지-텍스트 쌍의 사전 훈련 데이터를 확보하고자 한다. 또한, 본 발명에 비전-언어 트랜스포머 사전 훈련 방법은, 이미지 무작위 확대나 마스킹시 발생하는 이미지-텍 스트 쌍의 정렬 불량을 유용한 정보로 활용하여 비전-언어 트랜스포머를 학습하고자 한다. 그리고 본 발명은 이와같이 사전 훈련된 비전-언어 트랜스포머를 이용하여 다양한 비전 테스크를 효과적으로 수 행할 수 있는 인공지능 시스템을 개발하고자 한다."}
{"patent_id": "10-2024-0034179", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 실시예에 따른 비전-언어 트랜스포머 사전 훈련 방법은, 이미지를 무작위로 증강하여 증강된 이미지 와 텍스트와의 불일치를 의도적으로 유도하고, 오정렬을 유용한 정보로 비전-언어 트랜스포머(Vision-languge Transformers)를 사전 훈련하는 방법을 제안한다. 자세히, 본 발명은 실시예에 따른 비전-언어 트랜스포머 사전훈련 방법은, 증강된 이미지-텍스트 쌍의 정렬 불 량을 유용한 정보로 활용하여 사전 훈련할 수 있는 지식 증류를 이용한 대조 이미지-텍스트 사전훈련 방법 (Misalign, Con-trast then Distill: MCD, 이하. “MCD 사전 훈련 방법”)을 제안한다. 구체적으로, 본 발명의 실시예에 따른 비전-언어 트랜스포머 사전 훈련 방법은, 메모리와 프로세서를 포함하는 컴퓨팅 시스템이 복수의 원본 이미지-텍스트 쌍의 데이터셋으로 비전-언어 트랜스포머를 사전 훈련하는 방법으 로서, 상기 원본 이미지를 무작위 증강하여 복수의 증강 이미지를 생성하는 단계; 상기 원본 이미지에 매칭된 텍스트를 텍스트 인코더에 입력하여 텍스트 특징벡터 표현들을 출력하는 단계; 상기 원본 이미지와 복수의 증강 이미지를 티처 이미지 인코더에 입력하여 제1 이미지 특징벡터 표현들을 출력하는 단계; 상기 원본 이미지와 복 수의 증강 이미지를 스튜던트 이미지 인코더에 입력하여 제2 이미지 특징벡터 표현들을 출력하는 단계; 상기 텍 스트 특징벡터 표현들과 상기 제1 이미지 특징벡터 표현들에 대해 제1 정렬 매트릭을 생성하는 단계; 이미지-텍 스트 쌍의 포지티브와 네거티브 맵핑 관계에 따라서 유사성을 가지도록 상기 텍스트 특징벡터 표현들과 상기 제 1 이미지 특징벡터 표현들이 정렬되도록 상기 제1 정렬 매트릭을 학습하는 단계; 상기 학습된 제1 정렬 매트릭 의 출력을 예측하도록 상기 제2 정렬 매트릭을 정렬시켜 스튜던트 이미지 인코더에 지식 증류를 수행하는 단계 를 포함한다. 이때, 상기 티처 이미지 인코더에 입력하여 제1 이미지 특징벡터 표현들을 출력하는 단계는, 상기 원본 이미지 들과 복수의 증강 이미지들을 복수의 셀프 어텐션 레이어와, 피드 포워트 네트워크 레이어를 통해 제1 이미지 특징벡터 표현들을 출력하는 단계를 포함할 수 있다. 또한, 상기 스튜던트 이미지 인코더에 입력하여 제2 이미지 특징벡터 표현들을 출력하는 단계는, 상기 원본 이 미지들과 복수의 증강 이미지들을 복수의 셀프 어텐션 레이어에서의 출력 값을 기초로 토큰 희소화 레이어에 입 력하여 토큰 희소화를 수행하는 단계를 포함할 수 있다. 또한, 상기 텍스트 특징벡터 표현들과 상기 제1 이미지 특징벡터 표현들이 정렬되도록 상기 제1 정렬 매트릭을 학습하는 단계는, 상기 원본 이미지-텍스트 쌍과 증강 이미지-텍스트 쌍의 맵핑관계에 따라서 상기 텍스트 특징 벡터 표현들과 상기 제1 이미지 특징벡터 표현들과의 포지티브 특징벡터 표현 쌍과, 네가티브 특징벡터 표현 쌍 을 결정하는 단계와, 유사성 정렬을 위해 상기 포지티브 특징벡터 표현 쌍 사이의 거리는 가까워지도록 하고 상 기 네가티브 특징벡터 표현 쌍 사이의 거리는 멀어지도록 하는 손실함수에 따라 티처 이미지 인코더를를 학습하 는 단계를 포함할 수 있다. 또한, 상기 손실함수에 따라 인코더들을 학습하는 단계는, 상기 손실함수에 따라 유사성 정렬을 위하 학습시, 상기 티처 이미지 인코더에 모멘텀 정지 기울기를 적용해 역전파를 차단하는 단계를 포함할 수 있다. 또한, 상기 스튜던트 이미지 인코더에 지식 증류를 수행하는 단계는, 상기 유사성 정렬에 따른 제1 정렬 매트릭 의 출력 값을 상기 제2 정렬 메트릭이 예측하도록 지식 증류하는 단계를 포함할 수 있다. 또한, 상기 제2 정렬 매트릭에 대해 지식 증류를 수행하는 단계는, 상기 지식 증류 중 상기 텍스트 인코더로의 역전파를 차단하는 단계를 포함할 수 있다. 또한, 상기 제2 정렬 매트릭에 대해 지식 증류를 수행하는 단계는, 상기 제2 정렬 매트릭의 매개변수가 상기 제 1 정렬 매트릭의 매개변수를 따르도록 지식 증류하는 단계를 포함할 수 있다. 또한, 상기 제2 정렬 매트릭의 매개변수가 상기 제1 정렬 매트릭의 매개변수를 따르도록 지식 증류하는 단계는, 상기 제2 정렬 매트릭의 매개변수를 제1 정렬 매트릭의 매개변수에 지수 이동 평균(EMA)로 업데이트하는 단계를 포함할 수 있다. 또한, 상기 제2 정렬 매트릭에 대해 지식 증류를 수행하는 단계는, 상기 제1 이미지 특징벡터 표현과 텍스트 특 징벡터 표현의 거리 및 상기 제2 이미지 특징벡터 표현과 텍스트 특징벡터 표현의 거리를 통해 증강 이미지와 텍스트 사이의 오정렬 정보를 반영한 손실함수를 정의하여 지식 증류하는 단계를 포함할 수 있다. 또한, 상기 거리를 기초로 손실함수를 정의하여 지식 증류하는 단계는, 상기 스튜던트 이미지 인코더가 출력한 원본 이미지 특징벡터 표현과 텍스트 특징벡터 표현 사이의 제1 유클리드 거리와, 상기 스튜던트 이미지 인코더 가 출력한 증강 이미지 특징벡터 표현과 텍스트 특징벡터 표현의 제2 유클리드 거리를 산출하고, 상기 제1 유클 리드 거리와 제2 유클리드 거리의 비율을 로그 스케일로 산출한 제1 로그 비율을 산출하는 단계를 포함할 수 있 다. 또한, 상기 거리를 기초로 손실함수를 정의하여 지식 증류하는 단계는, 상기 티처 이미지 인코더가 출력한 원본 이미지 특징벡터 표현과 텍스트 특징벡터 표현 사이의 제3 유클리드 거리와, 상기 티처 이미지 인코더가 출력한 증강 이미지 특징벡터 표현과 텍스트 특징벡터 표현의 제4 유클리드 거리를 산출하고, 상기 제3 유클리드 거리 와 상기 제4 유클리드 거리의 비율을 로그 스케일로 산출한 제2 로그 비율을 산출하는 단계를 포함할 수 있다. 또한, 상기 거리를 기초로 손실함수를 정의하여 지식 증류하는 단계는, 상기 제1 로그 비율과 상기 제2 로그 비 율의 차이를 제2 정렬 메트릭이 제1 정렬 메트릭에 근사하도록 정렬시키기 위한 손실함수로 정의하여 지식 증류 를 수행하는 단계를 더 포함할 수 있다. 이때, 상기 제1 정렬 매트릭과 제2 정렬 매트릭을 정렬하도록 하기 위한 손실함수는, 로 정의될 수 있다. 또한, 상기 티처 이미지 인코더와 상기 텍스트 인코더 사이의 역전파 방지를 위해 정지 기울기를 통한 업데이트 를 수행하는 단계를 더 포함할 수 있다. 또한, 본 발명의 실시예에 따른 메모리와 프로세서를 포함하는 컴퓨팅 시스템이 사전 훈련한 비전-언어 트랜스 포머는, 텍스트들을 입력받아 텍스트 특징벡터 표현을 출력하는 텍스트 인코더; 원본 이미지들과 상기 원본 이 미지들로부터 증강된 복수의 증강 이미지를 입력 받아 제1 이미지 특징벡터 표현들을 출력하는 티처 이미지 인 코더; 상기 원본 이미지들과 상기 원본 이미지들로부터 증강된 복수의 증강 이미지를 입력 받아 제2 이미지 특 징벡터 표현들을 출력하는 스튜던트 이미지 인코더; 및 상기 티처 이미지 인코더와 상기 텍스트 인코더는 상기텍스트 특징벡터 표현들과 상기 제1 이미지 특징벡터 표현들을 유사성 정렬하여 제1 정렬 매트릭이 학습되고, 상기 스튜던트 이미지 인코더는 상기 텍스트 특징벡터 표현들과 상기 제2 이미지 특징벡터 표현들에 대한 제2 정렬 매트릭이 상기 제1 정렬 매트릭에 출력값을 예측하도록 지식 증류된다. 또한, 본 발명은 사전 훈련에 필요한 데이터를 상기 이미지 증강 방식을 통해 다수 확보하고, 다수 확보된 오정 렬된 이미지-텍스트 쌍으로 효율적으로 비전-언어 트랜스포머를 사전 훈련시켜, 향상된 성능의 비전 테스크를 수행할 수 있는 비전-언어 트랜스포머를 포함하는 인공지능 시스템을 제공하고자 한다."}
{"patent_id": "10-2024-0034179", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명은 실시예에 따른 비전-언어 트랜스포머 사전훈련 방법은, 이미지를 무작위로 증강하여 복수의 오정렬된 이미지-텍스트 쌍을 사전 훈련 데이터로 확대하여, 다양하고 유용한 정보를 다각적으로 포함하는 사전 훈련 데 이터를 손쉽게 다수 확보할 수 있다. 또한, 본 발명은 실시예에 따른 비전-언어 트랜스포머 사전훈련 방법은, 증강된 이미지-텍스트 쌍의 정렬 불량 을 유용한 정보로 학습할 수 있는 MCD 사전 훈련 방법을 통해 향상된 성능의 비전-언어 트랜스포머를 제공할 수 있다. 그리고 본 발명에 실시예에 따라서 사전 훈련된 비전-언어 트랜스포머를 포함하는 인공지능 시스템은, 상기 다 양하고 유용한 정보를 다각적으로 포함하는 사전 훈련 데이터로 학습된 비전-언어 트랜스포머를 이용하여 이미 지 분류, 객체 탐지, 이미지 세그멘테이션, 이미지 캡셔닝, 영상 분석 및 광학 문자 인식 등의 비전 테스크를 효과적으로 수행할 수 있다."}
{"patent_id": "10-2024-0034179", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명은 다양한 변환을 가할 수 있고 여러 가지 실시예를 가질 수 있는 바, 특정 실시예들을 도면에 예시하고"}
{"patent_id": "10-2024-0034179", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "상세한 설명에 상세하게 설명하고자 한다. 본 발명의 효과 및 특징, 그리고 그것들을 달성하는 방법은 도면과 함께 상세하게 후술되어 있는 실시예들을 참조하면 명확해질 것이다. 그러나 본 발명은 이하에서 개시되는 실시 예들에 한정되는 것이 아니라 다양한 형태로 구현될 수 있다. 이하의 실시예에서, 제1, 제2 등의 용어는 한정적 인 의미가 아니라 하나의 구성 요소를 다른 구성 요소와 구별하는 목적으로 사용되었다. 또한, 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 또한, 포함하다 또는 가지다 등의 용어는 명 세서상에 기재된 특징, 또는 구성요소가 존재함을 의미하는 것이고, 하나 이상의 다른 특징들 또는 구성요소가 부가될 가능성을 미리 배제하는 것은 아니다. 또한, 도면에서는 설명의 편의를 위하여 구성 요소들이 그 크기가 과장 또는 축소될 수 있다. 예컨대, 도면에서 나타난 각 구성의 크기 및 두께는 설명의 편의를 위해 임의로 나 타내었으므로, 본 발명이 반드시 도시된 바에 한정되지 않는다. 도 1은 본 발명의 실시예에 따른 MCD 사전 훈련 방법을 실행하는 컴퓨팅 시스템의 블록도의 예시를 도시한다. 도 1을 참조하면, 본 발명의 일 실시예에 따른 컴퓨팅 시스템은, 유저 컴퓨팅 디바이스, 트레이닝 컴퓨팅 시스템 및 서버 컴퓨팅 시스템을 포함하며, 각 디바이스 및 시스템은 네트워크를 통해통신 가능하게 연결된다. 본 발명의 다양한 실시예에 따르면, 1) 유저 컴퓨팅 디바이스가 로컬에서 비전-언어 트랜스포머를 사 전 훈련시키고, 학습된 비전-언어 트랜스포머를 포함하는 애플리케이션을 실행할 수 있으며, 2) 유저 컴퓨 팅 디바이스와 통신하는 서버 컴퓨팅 시스템이 비전-언어 트랜스포머(120 또는/및 140)를 사전 훈련 시키고, 비전-언어 트랜스포머(120 또는/및 140) 또는/및 비전-언어 트랜스포머(120 또는/및 140)를 포함하는 애플리케이션을 유저 컴퓨팅 디바이스에 직접 또는 웹 서비스 형태로 제공할 수 있으며, 3) 유저 컴퓨팅 디바이스와 서버 컴퓨팅 시스템이 서로 연계하여 비전-언어 트랜스포머(120 또는/및 140)를 사전훈련 시키거나, 사전훈련된 비전-언어 트랜스포머(120 또는/및 140)를 실행하여 각종 애플리케이션 서비스를 제공할 수 있다. 또한, 본 발명의 다양한 실시예에 따르면, 유저 컴퓨팅 디바이스 및/또는 서버 컴퓨팅 시스템은 네트 워크를 통해 통신적으로 연결된 트레이닝 컴퓨팅 시스템과의 인터렉션을 통해 모델을 트레이닝 할 수 있다. 이때, 트레이닝 컴퓨팅 시스템은 서버 컴퓨팅 시스템과 별개이거나 서버 컴퓨팅 시스템 의 일부일 수 있다 즉, 실시예에 따른 비전-언어 트랜스포머 사전훈련 방법은, 1) 유저 컴퓨팅 디바이스가 로컬에서 직접 비 전-언어 트랜스포머를 사전 훈련시킬 수 있고, 2) 서버 컴퓨팅 시스템과 유저 컴퓨팅 디바이스 가 네트워크를 통해 서로 인터랙션하며 사전 훈련할 수 있고, 3) 별도의 트레이닝 컴퓨팅 시스템이 비전- 언어 트랜스포머를 다양한 트레이닝 기법과 학습 기법을 사용하여 사전 훈련시킬 수 있다. 그리고 트레이닝 컴퓨팅 시스템이 사전 훈련시킨 비전-언어 트랜스포머(120 또는/및 140)를 네트워크를 통 해 유저 컴퓨팅 디바이스 또는/및 서버 컴퓨팅 시스템에 전송하여 제공 또는/및 업데이트 하는 방식 으로 구현될 수도 있다. 일부 실시예에서, 트레이닝 컴퓨팅 시스템은, 서버 컴퓨팅 시스템의 일부이거나, 유저 컴퓨팅 디바이 스에 일부일 수 있다. 또한, 본 발명은 비전-언어 트랜스포머 사전훈련 방법 및 시스템은, 사전 훈련된 비전-언어 트랜스포머를 파인 튜닝하는 등의 추가 작업을 수행하여 각종 다운스트림 테스크를 수행하는 애플리케이션에 포함시킬 수 있다. 유저 컴퓨팅 디바이스는, 스마트 폰(smart phone), 휴대폰, 디지털방송용 디바이스, PDA(personal digital assistants), PMP(portable multimedia player), 데스크 탑, 웨어러블 디바이스, 임베디드 컴퓨팅 장 치 및/또는 태블릿 PC(tablet PC) 등 기타 모든 유형의 컴퓨팅 장치를 포함할 수 있다. 이러한 유저 컴퓨팅 디바이스는, 적어도 하나 이상의 프로세서 및 메모리를 포함한다. 여기서, 프로세서는, 중앙처리장치(CPU), 그래픽처리장치(GPU), ASICs (application specific integrated circuits), DSPs(digital signal processors), DSPDs(digital signal processing devices), PLDs(programmable logic devices), FPGAs(field programmable gate arrays), 제어기(controllers), 마이크로 컨트롤러(micro-controllers), 마이크로 프로세스(microprocessors) 및/또는 기타 기능 수행을 위한 전기적 유 닛 중 적어도 하나 또는 전기적으로 연결된 복수의 프로세서들로 구성될 수 있다. 메모리는, RAM, ROM, EEPROM, EPROM, 플래시 메모리 디바이스, 자기 디스크 등 같은 하나 이상의 비일시 적/일시적 컴퓨터 판독가능한 저장 매체 및 이들의 조합을 포함할 수 있고, 인터넷(internet) 상에서 메모리의 저장 기능을 수행하는 서버의 웹 스토리지(web storage)를 포함할 수 있다. 이러한 메모리는, 상기 적어도 하나 이상의 프로세서가 비전-언어 트랜스포머를 사전 훈련시키거나, 사전 훈련된 비전-언어 트랜스 포머를 포함하는 애플리케이션을 실행 등의 동작을 수행하기 위하여 필요한 데이터 및 명령어들 을 저장할 수 있다. 일 실시예에서, 유저 컴퓨팅 디바이스는, 적어도 하나 이상의 머신 러닝 모델들(예들 들어, 비전-언어 트 랜스포머)을 저장할 수 있다. 자세히, 일 실시예의 비전-언어 트랜스포머는, 복수의 뉴럴 네트워크(예를 들어, Deep neural network)와 같은 다양한 머신 러닝 모델들 또는 비선형 모델 및/또는 선형 모델을 포함하는 다른 유형의 머신 러닝 모델들 일 수 있으며, 이들의 조합으로 구성할 수 있다. 그리고 뉴럴 네트워크는 피드-포워드 뉴럴 네트워크들(feed-forward neural networks), 순환 뉴럴 네트워크(예 를 들어, 장단기 메모리 순환 신경 네트워크들), 컨벌루션 신경 네트워크 또는/및 다른 형태의 신경 네트워크들 중 적어도 하나 이상을 포함할 수 있다. 일 실시예에서, 유저 컴퓨팅 디바이스는, 네트워크를 통해서 서버 컴퓨팅 시스템으로부터 적어 도 하나 이상의 비전-언어 트랜스포머를 수신하고, 메모리에 저장한 후, 저장된 비전-언어 트랜스포머 를 프로세서에 의해 실행하여, 다양한 비전 기반 테스크를 가지는 애플리케이션을 동작할 수 있다. 다른 실시예에서, 서버 컴퓨팅 시스템은, 적어도 하나 이상의 머신 러닝 모델(예를 들어, 비전-언어 트랜 스포머)를 포함하여 비전-언어 트랜스포머를 통한 동작을 수행하며, 유저 컴퓨팅 디바이스와 이 와 관련된 데이터를 통신하는 방식으로 유저 컴퓨팅 디바이스와 연동해 비전-언어 트랜스포머를 이용 한 다양한 테스크 수행하는 인공지능 시스템을 유저에게 제공할 수 있다. 예를 들어, 유저 컴퓨팅 디바이스 는, 웹을 통해 서버 컴퓨팅 시스템이 비전-언어 트랜스포머를 이용하여 유저의 입력에 대한 출 력을 제공하는 방식으로 비전-언어 트랜스포머를 포함한 비전- 테스크가 수행될 수 있다. 또한, 비전-언어 트랜스포머들(120 또는/및 140) 중 적어도 일부는 유저 컴퓨팅 디바이스에서 실행되고, 나머지는 서버 컴 퓨팅 시스템에서 실행되는 방식으로도 비전-언어 트랜스포머(120 또는/및 140)를 구현될 수 있다. 또한, 유저 컴퓨팅 디바이스는, 유저의 입력을 감지하는 적어도 하나 이상의 입력 컴포넌트를 포함할 수 있다. 예를 들어, 유저 입력 컴포넌트는, 유저의 입력 매체(예를 들어, 손가락 또는 스타일러스)의 터치를 감지 하는 터치 센서(예를 들어, 터치 스크린 또는/및 터치 패드 등), 유저의 모션 입력을 감지하는 이미지 센서, 유 저 음성 입력을 감지하는 마이크로폰, 버튼, 마우스 및/또는 키보드 등을 포함할 수 있다. 또한, 유저 입력 컴 포넌트는, 인터페이스를 통해 외부 컨트롤러(예컨대, 마우스, 키보드 등)에 대한 입력을 수신할 경우에, 인터페 이스와 외부 컨트롤러가 포함될 수 있다. 서버 컴퓨팅 시스템은 적어도 하나 이상의 프로세서와 메모리를 포함한다. 여기서, 프로세서 는, 중앙처리장치(CPU), 그래픽처리장치(GPU), ASICs (application specific integrated circuits), DSPs(digital signal processors), DSPDs(digital signal processing devices), PLDs(programmable logic devices), FPGAs(field programmable gate arrays), 제어기(controllers), 마이크로 컨트롤러(micro- controllers), 마이크로 프로세스(microprocessors) 및/또는 기타 기능 수행을 위한 전기적 유닛 중 적어도 하 나 또는 전기적으로 연결된 복수의 프로세서들로 구성될 수 있다. 그리고 메모리는, RAM, ROM, EEPROM, EPROM, 플래시 메모리 디바이스, 자기 디스크 등 같은 하나 이상의 비일시적/일시적 컴퓨터 판독가능한 저장 매체 및 이들의 조합을 포함할 수 있다. 이러한 메모리는, 프로 세서가 비전-언어 트랜스포머를 사전 훈련하거나, 비전-언어 트랜스포머를 이용한 다양한 비전 테스크(예를 들어, image detection, classification, segmentation 등) 동작을 수행하기 위하여 필요한 데이 터 및 명령어들을 저장할 수 있다. 일 실시예에서, 서버 컴퓨팅 시스템은, 적어도 하나 이상의 컴퓨팅 디바이스를 포함하여 구현될 수 있다. 예를 들어, 서버 컴퓨팅 시스템은, 복수의 컴퓨팅 디바이스를 순차적 컴퓨팅 아키텍처, 병렬 컴퓨팅 아키 텍처 또는 이들의 조합에 따라 동작하도록 구현될 수 있다. 또한, 서버 컴퓨팅 시스템은, 네트워크로 연결 된 복수의 컴퓨팅 디바이스를 포함할 수 있다. 또한, 서버 컴퓨팅 시스템은 적어도 하나 이상의 비전-언어 트랜스포머를 저장할 수 있다. 예를 들어, 서버 컴퓨팅 시스템은, 비전-언어 트랜스포머로 뉴럴 네트워크 또는/및 기타 멀티 레이어 비선 형 모델을 포함할 수 있다. 예시적 신경 네트워크는 피드 포워드 뉴럴 네트워크, 딥 뉴럴 네트워크, 순환 뉴럴 네트워크 및 컨벌루션 뉴럴 네트워크를 포함할 수 있다. 트레이닝 컴퓨팅 시스템은 적어도 하나 이상의 프로세서와 메모리를 포함한다. 여기서, 프로세 서는, 중앙처리장치(CPU), 그래픽처리장치(GPU), ASICs (application specific integrated circuits), DSPs(digital signal processors), DSPDs(digital signal processing devices), PLDs(programmable logic devices), FPGAs(field programmable gate arrays), 제어기(controllers), 마이크로 컨트롤러(micro- controllers), 마이크로 프로세스(microprocessors) 및/또는 기타 기능 수행을 위한 전기적 유닛 중 적어도 하 나 또는 전기적으로 연결된 복수의 프로세서들로 구성될 수 있다. 그리고 메모리는, RAM, ROM, EEPROM, EPROM, 플래시 메모리 디바이스, 자기 디스크 등 같은 하나 이상의 비일시적/일시적 컴퓨터 판독가능한 저장 매체 및 이들의 조합을 포함할 수 있다. 이러한 메모리는, 프로세서가 비전-언어 트랜스포머를 학습을 수행하기 위하여 필요한 데이터 및 명령어들을 저장할 수 있다. 예를 들어, 트레이닝 컴퓨팅 시스템은, 에러의 역방향 전파와 같은 다양한 트레이닝 또는 학습 기법을 사 용하여(도 5에 도시된 프레임워크에 따라), 유저 컴퓨팅 디바이스 또는/및 서버 컴퓨팅 시스템에 저 장된 비전-언어 트랜스포머(120 또는/및 140)를 사전 훈련(training)하는 모델 트레이너를 포함할 수 있다. 예를 들어, 모델 트레이너는, 정의된 손실 함수에 기초하여 비전-언어 트랜스포머(120 또는/및 140)의 하 나 이상의 파라미터를 업데이트를 역전파 방식으로 수행할 수 있다. 일부 구현예에서, 에러의 역방향 전파를 수행하는 것은 시간을 통한 잘린 역 전파(truncated backpropagation through time)를 수행하는 것을 포함할 수 있다. 모델 트레이너는 트레이닝되는 비전-언어 트랜스포머(120 또는/및 140)의 일반화 능력을 향상시키기 위해 다수의 일반화 기법들(예를 들어, 가중치 감소, 드롭 아웃, 지 식 증류 등)을 수행할 수 있다. 특히, 모델 트레이너는 일련의 트레이닝 데이터에 기초하여 비전-언어 트랜스포머(120 또는/및 140)를 트 레이닝할 수 있다. 트레이닝 데이터는 예를 들어, 이미지, 오디오 샘플, 텍스트 등과 같은 상이한 복수의 양식 (multi-modal)의 데이터를 포함할 수 있다. 사용될 수 있는 이미지 유형의 예는 일반적인 RGB 이미지부터 비디 오 프레임, LiDAR 포인트 클라우드, X선 이미지, 컴퓨터 단층 촬영 스캔, 초분광 이미지 및/또는 다양한 기타 형태의 이미지를 포함할 수 있다. 이러한 트레이너 데이터와, 다운스트림 테스크를 위한 입력 데이터는, 유저 컴퓨팅 디바이스 또는/및 서버 컴퓨팅 시스템에 의해 제공될 수 있다. 유저 컴퓨팅 디바이스의 특정 데이터에 대해 트레이닝 컴퓨팅 디바이스가 비전-언어 트랜스포머를 학습시킬 경우, 비전-언어 트랜스포머는 개인화된 모델로 특성화 될 수 있다. 그리고 모델 트레이너는 원하는 기능을 제공하기 위해 활용되는 컴퓨터 로직을 포함한다. 모델 트레이너 는 범용 프로세서를 제어하는 하드웨어, 펌웨어 및/또는 소프트웨어로 구현될 수 있다. 예를 들어, 일 실 시예에서, 모델 트레이너는 저장 디바이스에 저장된 프로그램 파일을 포함하고, 메모리에 로딩되고 하나 이상의 프로세서에 의해 실행될 수 있다. 다른 구현예에서, 모델 트레이너는 RAM 하드 디스크 또는 광학 또는 자기적 매체와 같은 유형적 컴퓨터 판독가능 저장 매체에 저장된 컴퓨터 실행가능 명령어들의 하나 이상의 세트들을 포함한다. 네트워크는 3GPP(3rd Generation Partnership Project) 네트워크, LTE(Long Term Evolution) 네트워크, WIMAX(World Interoperability for Microwave Access) 네트워크, 인터넷(Internet), LAN(Local Area Network), Wireless LAN(Wireless Local Area Network), WAN(Wide Area Network), PAN(Personal Area Network), 블루투스(Bluetooth) 네트워크, 위성 방송 네트워크, 아날로그 방송 네트워크 및/또는 DMB(Digital Multimedia Broadcasting) 네트워크 등이 포함되나 이에 한정되지는 않는다. 일반적으로, 네트워크를 통한 통신은 임의의 유형의 유선 및/또는 무선 연결을 사용하여, 다양한 통신 프 로토콜들(예를 들어, TCP/IP, HTTP, SMTP, FTP), 인코딩 또는 포맷들(예를 들어, HTML, XML), 및/또는 보호 스 키마(예를 들어, VPN, 시큐어 HTTP, SSL)를 통해 수행될 수 있다. 도 2는 본 발명의 실시예에 따른 따른 지식 증류 프레임워크에 따라서 비전-언어 트랜스포머 사전 훈련하고, 사 전 훈련된 비전-언어 트랜스포머를 실행하는 컴퓨팅 디바이스의 블록도의 예시를 도시한다. 도 2를 포함하면, 유저 컴퓨팅 디바이스, 서버 컴퓨팅 시스템 및 트레이닝 컴퓨팅 시스템에 포 함되는 컴퓨팅 디바이스는, 다수의 애플리케이션(예를 들어, 애플리케이션 1 내지 애플리케이션 N)을 포함 한다. 각 애플리케이션은 머신 러닝 라이브러리 및 하나 이상의 비전-언어 트랜스포머를 포함할 수 있다. 예를 들어, 애플리케이션은 비전 테크스(예를 들어, detection, classification, segmentation 등) 애플리케이션 및 이러한 비전 테스크를 포함한 텍스트 메시징 애플리케이션, 이메일 애플리케이션, 받아쓰기 애플리케이션, 가상 키보드 애플리케이션, 브라우저 애플리케이션, 쳇-봇(chat-bot) 애플리케이션 등을 포함할 수 있다. 실시예에서, 컴퓨팅 디바이스는, 비전-언어 트랜스포머를 사전 훈련시키기 위한 모델 트레이너를 포 함할 수 있고, 상기 사전 훈련된 비전-언어 트랜스포머를 저장하고 동작시켜 입력 데이터에 대해 비전-언어 트랜스포머를 이용한 각종 비전 테스크를 수행할 수 있다. 컴퓨팅 디바이스의 각 애플리케이션은 예를 들어, 하나 이상의 센서, 컨텍스트 관리자, 디바이스 상태 컴 포넌트 및/또는 추가 컴포넌트들과 같은 컴퓨팅 디바이스의 다수의 다른 컴포넌트들과 통신할 수 있다. 일 실시예에서, 각 애플리케이션은 API(예를 들어, 퍼블릭 API)를 사용하여 각 디바이스 컴포넌트와 통신할 수 있 다. 일 실시예에서, 각 애플리케이션에 의해 사용되는 API는 해당 애플리케이션에 대해 특정적일 수 있다. 도 3은 본 발명의 실시예에 따른 지식 증류 프레임워크를 통해 비전-언어 트랜스포머 사전 훈련하고, 사전 훈련 된 비전-언어 트랜스포머를 실행하는 컴퓨팅 디바이스에 대한 다른 측면에서의 블록도의 예시를 도시한다. 도 3을 참조하면, 컴퓨팅 디바이스는 다수의 애플리케이션(예를 들어, 애플리케이션 1 내지 애플리케이션 N)을 포함한다. 각 애플리케이션은 중앙 인텔리전스 레이어와 통신할 수 있다. 예를 들어, 애플리케이션은 이미 지 처리 애플리에키션, 문자 메시지 애플리케이션, 이메일 애플리케이션, 받아쓰기 애플리케이션, 가상 키보드 애플리케이션, 브라우저 애플리케이션 등을 포함할 수 있다. 일 실시예에서, 각 애플리케이션은 API(예: 모든 애플리케이션에 걸쳐 공통 API)를 사용하여 중앙 인텔리전스 레이어(및 그 안에 저장된 모델)과 통신할 수 있다. 그리고 중앙 인텔리전스 레이어는 다수의 비전-언어 트랜스포머들을 포함할 수 있다. 예를 들어, 도 3에 도시된 바와 같이, 각각의 비전-언어 트랜스포머 중 적어도 일부가 각 애플리케이션에 대해 제공될 수 있고, 중앙 인텔 리전스 레이어에 의해 관리될 수 있다. 다른 구현예에서, 2개 이상의 애플리케이션들은 단일의 비전-언어 트랜 스포머를 공유할 수 있다. 예를 들어, 일부 구현예에서, 중앙 인텔리전스 레이어는 모든 애플리케이션에 대해 단일 모델을 제공할 수 있다. 일부 구현예에서, 중앙 인텔리전스 레이어는 컴퓨팅 디바이스의 운영 체제 내에 포함되거나 이와 다르게 구현될 수 있다. 중앙 인텔리전스 레이어는 중앙 디바이스 데이터 레이어와 통신할 수 있다. 중앙 디바이스 데이터 레이어는 컴 퓨팅 디바이스에 대한 중앙 집중식 데이터 저장소일 수 있다. 도 3에 도시된 바와 같이, 중앙 디바이스 데 이터 레이어는 예를 들어, 하나 이상의 센서, 컨텍스트 관리자, 디바이스 상태 컴포넌트 및/또는 추가 컴포넌트 들과 같은 컴퓨팅 디바이스의 다수의 다른 컴포넌트들과 통신할 수 있다. 일부 구현예에서, 중앙 디바이스 데이터 레이어는 API(예를 들어, 사설 API)를 사용하여 각 디바이스 컴포넌트와 통신할 수 있다. 본 명세서에서 설명한 기술은 서버, 데이터베이스, 소프트웨어 애플리케이션들 및 다른 컴퓨터 기반 시스템뿐만 아니라 취해진 액션들 및 상기 시스템으로 전송되거나 그로부터 전송된 정보를 참조할 수 있다. 컴퓨터 기반 시 스템들의 내재적 유연성은 광범위한 가능한 구성들, 조합들 및 작업의 분할 및 컴포넌트들 간의 및 그로부터의 기능성을 허용함을 인식할 것이다. 예를 들어, 본 명세서에서 기술한 프로세스들은 단일의 디바이스 또는 컴포 넌트 또는 조합으로 작동하는 다수의 디바이스들 또는 컴포넌트들을 사용하여 구현될 수 있다. 데이터베이스 및 애플리케이션들은 단일 시스템 또는 다수의 시스템들에 걸쳐 분산된 시스템에서 구현될 수 있다. 분산 컴포넌트 들은 순차적으로 또는 병렬로 동작할 수 있다. 이하, 이러한 컴퓨팅 시스템이, 무작위 이미지 확대를 통해 증강한 데이터셋으로 지식 증류 프레임워크에 따라 비전-언어 트랜스포머를 사전 훈련하는 과정을 도 4 내지 도 6을 참조하여 상세히 설명한다. 본 발명에서 설명하는 비전-언어 트랜스포머는, 비전-언어(이미지-텍스트) 쌍의 두가지 이종 형식의 데이터 간 공동 표현을 대규모 스케일의 데이터셋으로 사전 훈련된 비전-언어 기반 인공지능 모델(VLP)을 의미한다. 이러한 실시예에 따른 비전-언어 트랜스포머는, 이미지와 텍스트가 결합된 입력 데이터를 변환하는 싱글-스트림 모델과, 이미지-텍스트를 별도의 이미지 인코더 및 텍스트 인코더를 통해 처리하는 듀얼(멀티)-스트림 모델을 포함할 수 있다. 이하 실시예에서, 작업의 편의를 위해 이미지-텍스트가 매칭되어 있는 데이터셋에 대해 대조 목표로 사전 훈련 하는 듀얼 스트림 아키텍처를 가지는 비전-언어 트랜스포머를 기준으로 설명한다. 실시예에 따른 비전-언어 트랜스포머 사전 훈련방법은, 이미지 무작위 증강을 통해 확보된 다수의 증강된 이미 지-텍스트 쌍을 기초로 지식 증류된 인코더를 사용하여 대조 이미지-텍스트 쌍의 데이터셋의 사전 훈련을 촉진 할 수 있다. 도 4 내지 5를 참조하면, 실시예에 따른 비전-언어 트랜스포머 사전 훈련 아키텍처는, 텍스트 인코더, 티처 이미지 인코더 및 스튜던트 이미지 인코더를 포함한다. 그리고 스튜던트 이미지 인코더와 티처 이 미지 인코더는, 멀티-헤드 셀프-어텐션 레이어와, 피드-포워드 네트워크를 포함할 수 있다. 그리고 스튜던 트 이미지 인코더는, 토큰 희소화 레이어를 더 포함할 수 있다. 여기서, 사전 훈련을 위한 이미지-텍스트 데이터셋은 선별되지 않은(uncurated) 데이터셋으로, 예를 들어, 레이 블링 작업이다 캡셔닝 작업 등이 수행되지 않은 데이터를 의미한다. 실시예에서는, 본 실시예에 따른 비전-언어 트랜스포머 사전 훈련방법의 효율성을 명확히 검증하기 위해서 사전 훈련을 위한 데이터셋으로 대규모 오픈 소스 데이터셋인 CC (Conceptual Captions) 3M, YFCC (Yahoo Flickr Creative Commons) 15M 및 YFCC15M, 88M 중 적어도 하나 이상의 데이터셋을 포함할 수 있다. 또한, 본 실시예에 따라서 사전 훈련된 비전-언어 트랜스포머의 성능을 확인하기 위한 다운스트림 데이터셋으로, Flickr30K 또는/및 MS-COCO에서 제로샷 이미지-텍스트를 포함할 수 있다. 특히, 본 발명의 실시예에 따른 컴퓨팅 시스템은, 데이터셋에서 이미지 데이터(이하, 이미지)와 이미지에 대한 레이블(label)인 텍스트 데이터(이하, 텍스트)를 한 쌍으로 하는 복수의 이미지-텍스트 쌍을 사전 훈련 데 이터셋으로 준비할 수 있다. 그리고 컴퓨팅 시스템은, 데이터셋의 다양성을 높이고 비전-언어 트랜스포머의 일반화 능력을 향상시키기 위해, 원본 이미지를 무작위로 증강(random augmentation)하여 증강 이미지를 생성할 수 있다. 실시예에 따른 컴퓨팅 시스템은, 의도적으로 증강 이미지와 텍스트 사이에 잘못된 정렬을 유발하기 위해, 이미지 증강 중 특히 이미지 무작위 확대(예를 들어, 무작위 자르기(random crop), 무작위 회전, 무작위 뒤집기 (random flip), 색상 변형(color jittering) 또는/및 무작위 회색조(grayscale))를 적용하여 다수의 증강 이미 지를 생성할 수 있다. 또한, 컴퓨팅 시스템은, 이미지의 랜덤한 일부 영역을 마스킹하는 방식을 적용하여 다수의 증강 이미지를 추가 생성할 수 있다. 이와 같이 무작위 이미지 증강을 통해 생성한 추가적인 증강 이미지는 원본 이미지에 텍스트 쌍에 대해 심각한 불량을 일으킬 수 있다. 이하, 이에 대한 간단한 이론적 근거를 제시한다. 먼저, 텍스트 특징벡터 T, 원본 이미지 특징벡터 I, 증강 이미지 특징벡터 I'를 Markov Chain T → I → I'로 공식화하고, 이는 I'가 원본 이미지 I에만 의존한다는 것을 의미한다. 데이터 처리가 정보의 양을 늘릴 수 없다는 데이터 처리 불평등 이론에 따르면, 하이과 같은 공식이 도출될 수 있다. [수학식 1]"}
{"patent_id": "10-2024-0034179", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "여기서, 는 상호 정보를 나타내고, 두 정보가 동일한 경우는 이미지(I)와 증강 이미지(I')가 동일하게 캡처되어 텍스트(T)에 대해 동일한 정보를 포함하는 경우에만 해당된다. 실시예에 따른 컴퓨팅 시스템은, 이러한 원본 이미지-텍스트 쌍과, 증강 이미지-텍스트 쌍의 정보 불균형 을 학습 정보로 활용하는 새로운 방법을 제안하고자 한다. 도 4는 본 발명의 실시예에 따른 MCD 사전 훈련 방법의 프레임워크를 개념적으로 나타낸다. 도 4를 참조하면, 실시예에 따른 컴퓨팅 시스템은, 1) 전술한 바와 같이 원본 이미지를 증강하여 복수의 증강 이미지를 생성하여 원본 이미지-텍스트 쌍과, 증강 이미지-텍스트 쌍을 생성하고, 2) 원본 이미지-텍스트 쌍과, 복수의 증강 이미지-텍스트 쌍을 각각 티처 이미지 인코더, 스튜던트 이미지 인코더 및 텍스트 인코더에 입력하여 이미지-텍스트 쌍에 대한 특징벡터 표현을 출력하고, 3) 출력된 이미지 특징표현 벡터와, 텍스트 특징표현 벡터를 대조 목표(contrastive objectives)에 따라서 투영하여 특징표현 벡터 사이의 거리를 획득하고, 4) 획득된 거리를 기초로 티처 이미지 인코더의 지식을 스튜던트 이미지 인코더로 증 류하는 방식으로 이미지 인코더(20, 30)와, 텍스트 인코더의 사전 훈련을 수행할 수 있다. 이하에서는 좀더 MCD 사전 훈련 과정을 상세히 설명해본다. 먼저, 컴퓨팅 시스템은, 원본 이미지를 무작위 확대 또는/및 마스킹하여 복수의 증강 이미지를 생성할 수 있다. 그 다음으로, MCD 사전 훈련 방법의 프레임워크는, 도 4와 같이, 모멘텀 티처 이미지 인코더와, 스튜던트 이미지 인코더와, 텍스트 인코더를 포함하며, 정지 그라이디언트를 기초로 티처 이미지 인코더의 지식을 스튜던트 이미지 인코더로 증류할 수 있다. 여기서, 모멘텀 티처 이미지 인코더는, 모델의 매개변수가 시간이 지남에 따라 더 느리게 업데이트되는 티 처 이미지 인코더로서, 스튜던트 이미지 인코더를 안정적으로 학습시킬 수 있다. 그리고 스튜던트 이미지 인코더는, 티처 이미지 인코더의 동작을 모방하도록 훈련되는 티처 이미지 인 코더 대비 상대적으로 단순한(예컨대, 매개변수가 적은) 머신러닝 모델일 수 있다. 이러한 티처와 스튜던트 이미지 인코더는, 원본 이미지와, 증강 이미지를 특징을 특징표현으로 변환하도록 학습되어, 입력된 이미지의 이미지 특징벡터 표현을 출력할 수 있다. 여기서, 특징벡터 표현은, 이미지 객체가 나타내는 특징을 n차원으로 나타내는 벡터를 의미하며, 변환 객체의 여러 특징을 머신러닝 모델이 처리할 수 있는 형식으로 결합하여 구조화된 형태로 변환한 특징벡터로 임베딩이 라고 부를 수 있다. 마지막트로, 텍스트 인코더는, 텍스트를 입력받으면 텍스트 특징벡터 표현(T)을 출력하는 인코더이다. 자세 히, 텍스트 인코더는, 텍스트의 특징을 특징표현으로 변환하도록 학습되어, 입력된 텍스트에 대한 텍스트 특징벡터 표현(T)을 출력할 수 있다. 컴퓨팅 시스템은, 원본 이미지, 증강 이미지를 각각 티처 이미지 인코더와, 원본 이미지 특징벡터 표 현(bar I)과 증강 이미지 특징벡터 표현(bar I')을 포함하는 제1 이미지 특징벡터 표현을 획득할 수 있다. 또한, 컴퓨팅 시스템은, 원본 이미지, 증강 이미지를 스튜던트 이미지 인코더에 입력하여 원본 이미 지 특징벡터 표현(I)과, 증강 이미지 특징벡터 표현(I')를 포함하는 제2 이미지 특징벡터 표현을 획득할 수 있 다. 그리고 컴퓨팅 시스템은, 원본 이미지에 매칭된 텍스트를 텍스트 인코더에 입력하여 텍스트 특징벡터 표현(T)을 획득할 수 있다. 다음으로, 컴퓨팅 시스템은, 텍스트 특징벡터 표현(T)들과, 티처 이미지 인코더에서 출력된 제1 이미 지 특징벡터 표현들을 기 매칭된 포지티브 쌍과, 매칭되지 않은 네가티브 쌍에 따라서 맵핑하여 제1 정렬 매트 릭(bar A)을 생성할 수 있다. 그리고 컴퓨팅 시스템은, 출력된 텍스트 특징벡터 표현(T)들과, 제1 이미지 특징벡터 표현들이 기 맵핑된 포지티브/네거티브 기준에 따라 제1 정렬 매트릭(bar A)을 유사성 대조 정렬하는 방식(예를 들어, InfoNCE loss(포지티브 쌍의 유사성이 최대화되고, 네거티브 쌍의 유사성을 최소화하도록 훈련하는 방식)으로 티처 이미 지 인코더와 텍스트 인코더를 학습할 수 있다. 이때, 컴퓨팅 시스템은, 제1 이미지 특징벡터 표현들로 구성된 제1 정렬 매트릭(bar A)을 유사성 정렬을 위해 훈련하는 과정에서 티처 이미지 인코더는 정지 기울기가 있는 모멘텀 티처(Momentum Teacher with Stop Gradient) 모멘텀 모델일 수 있으며, 따라서, 유사성 정렬 학습 중 티처 이미지 인코더로 역전파(sg) 되는 것을 차단할 수 있다. 이후, 컴퓨팅 시스템은, 유사성 정렬을 위해 포지티브 특징벡터 표현들 사이의 공간 상 거리가 가까워지 도록, 네가티브 특징벡터 표현들 사이의 공간 상 거리가 멀어지도록 손실함수에 따라 학습시킬 수 있다. 즉, 이 되도록 손실함수를 정의하여 대조 학습(contrastive learnin g)할 수 있다. 예를 들어 전술한 바와 같이, 컴퓨팅 시스템은, 유사성 메트릭에 손실함수인 InfoNCE Loss를 적용되도록 제1 정렬 매트릭(bar A)을 대조 학습하여 티처 이미지 인코더를 학습시킬 수 있다. 그리고 컴퓨팅 시스템은, 원본 이미지와, 증강 이미지를 스튜던트 이미지 인코더에 입력하여 제2 이 미지 특징벡터 표현들을 출력할 수 있다. 이때, 스튜던트 이미지 인코더는 토큰 희소화 레이어를 포함하여 패치 토큰을 재구성함으로써, 사전 훈련을 가속화할 수도 있다. 다만, 토큰 희소화 레이어는 생략되어도 무방하다. 자세히, 스튜던트 이미지 인코더는, 이미지들 사이의 주의 가치(value)를 산출(self-attention)하고, 산출 된 각 이미지들 사이의 주의 가치에 따라서 기 정해진 기준 이하의 토큰을 폐기할 수 있다. 예를 들어, 스튜던트 이미지 인코더는, 셀프 어텐셜 레이어 중 4, 7, 10번째 변환기 레이어의 각 패치 사이 의 주의 가치에 따라 부주의한 토큰을 고정 비율(1-κ)에 따라서 폐기할 수 있다. 여기서 κ는 토큰 유지율이다. 그리고 컴퓨팅 시스템은, 텍스트 특징벡터 표현(T)들과, 제2 이미지 특징벡터 표현들을 기 매칭된 포지티 브 쌍과, 매칭되지 않은 네가티브 쌍에 따라서 맵핑하여 제2 정렬 매트릭(A)를 생성할 수 있다. 다음으로, 컴퓨팅 시스템은, 기존 지식 증류 방식과 상이하게 제2 정렬 매트릭(A)이 유사성 맵핑에 따라 정렬된 제1 정렬 매트릭(bar A)의 출력 값을 예측하도록 지식 증류할 수 있다. 즉, 컴퓨팅 시스템은, 제1 정렬 매트릭(bar A)를 소프트 얼라인먼트하여 제2 정렬 매트릭(A)이 정렬되도 록 스튜던트 이미지 인코더를 훈련하는 방식으로 지식 증류(distillation)할 수 있다. 이때, 텍스트 인코더와 티처 이미지 인코더는, 지식 증류 중 텍스트 인코더로 역전파(sg)되는 것을 차단하는 정지 기울기가 있는 모멘텀 모델(Momentum moedel with Stop Gradient) 일 수 있다. 자세히, 컴퓨팅 시스템은, 제2 정렬 매트릭(A)이 제1 정렬 매트릭(bar A)에 따라서 정렬되도록 스튜던트 이미지 인코더의 매개변수를 학습하여 지식 증류할 수 있다. 그리고 컴퓨팅 시스템은, 스튜던트 이미지 인코더의 매개변수에 기초하여 티처 이미지 인코더의 매개변수를 지수 이동 평균(EMA)로 업데이트할 수 있다. 이때, 컴퓨팅 시스템은, 전술한바와 같이 증강 이미지와 텍스트 사이의 오정렬 정보를 반영하여 지식 증 류하기 위하여, 이미지 특징벡터 표현과 텍스트 특징벡터 표현(T)의 거리를 기초로 손실함수를 정의하여 지식 증류할 수 있다. 자세히, 컴퓨팅 시스템은, 스튜던트 이미지 인코더가 출력한 원본 이미지 특징벡터 표현(I)과 텍스트 특징벡터 표현(T) 사이의 제1 유클리드 거리와, 스튜던트 이미지 인코더가 출력한 증강 이미지 특징벡터 표 현(I')과 텍스트 특징벡터 표현(T)의 제2 유클리드 거리를 산출하고, 제1 유클리드 거리와 제2 유클리드 거리의 제1 비율을 산출할 수 있으며, 이때 로그 스케일을 적용할 수 있다. 즉, 제1 비율을 로그 스케일로 산출하여 제 1 로그 비율을 산출할 수 있다. 또한, 컴퓨팅 시스템은, 티처 이미지 인코더가 출력한 원본 이미지 특징벡터 표현(bar I)과 텍스트 특징벡터 표현(T) 사이의 제3 유클리드 거리와, 티처 이미지 인코더가 출력한 증강 이미지 특징벡터 표현 (bar I')과 텍스트 특징벡터 표현(T)의 제4 유클리드 거리를 산출하고, 제3 유클리드 거리와 제4 유클리드 거리 의 제2 비율을 산출할 수 있으며, 이때 로그 스케일을 적용할 수 있다. 즉, 제2 비율을 로그 스케일로 산출하여 제2 로그 비율을 산출할 수 있다. 그리고 컴퓨팅 시스템은, 제1 로그 비율과 제2 로그 비율의 차이를 제2 정렬 메트릭이 제1 정렬 매트릭 (bar A)에 근사하도록 정렬시키기 위한 손실함수로 정의하여, 인코더를 학습시킬 수 있다. 이하에서는, 구체적인 수학식을 통해서 위 사전 훈련을 위한 계산 과정을 면밀하게 설명한다. 구체적으로, 정지 기울기를 가진 모멘텀 티처 이미지 인코더에 대한 함수 와, 정지 기울기를 가진 모멘 텀 텍스트 인코더에 대한 함수 와, 스튜던트 인코더에 대한 함수 에 대한 제1 정렬 매트릭 과, 제2 정렬 매트릭 는 하기 수학식 2와 같이 정의될 수 있다. [수학식 2]"}
{"patent_id": "10-2024-0034179", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "여기서, sg는 정지 기울기이고, 와 는 각각 티처 이미지 인 코더와 스튜던트 이미지 인코더를 사용하여 j번째 이미지에 대한 이미지 특징벡터 표현이고, 로 i번째 텍스트에 대한 텍스트 특징벡터 표현(T)이고, sim은, 코사인 유사도 함수 를 의미한다. 그리고 전술한 바와 같이 원본 이미지 특징벡터 표현(I, bar I)과 증강 이미지 특징벡터 표현(I', bar I')과, 텍스트 특징벡터 표현(T) 사이의 거리를 기초로 InfoNCE 손실함수를 정의하여 사전훈련할 수 있으며, 이 과정을 수학식 3 내지 수학식 6을 통해 설명한다. 그리고 컴퓨팅 시스템은, InfoNCE 손실(수학식 3)을 사용하여 제1 정렬 매트릭(bar A)과 제2 정렬 매트릭 (A)을 얼라인하기 위한 손실함수를 정의할 수 있다. [수학식 3]"}
{"patent_id": "10-2024-0034179", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "여기서, 는 align loss을 의미하며, 은 벡터와 벡터 사이의 유클리드 거리를 의미하고, 코 사인 유사도를 통해 산출될 수 있다. 따라서, 는 제1 유클리드 거리이며, 는 제2 유클리드 거리이고, 는 제3 유클리드 거리이며, 는 제4 유클리느 거리이다. 구체적으로 실시예에서는, 원본 이미지 특징벡터 와, 텍스트 특징벡터 는 L2 정규화된 벡터로서, 유클리 드 거리는 코사인 유사도 함수인 를 통해 산출될 수 있다. 다음으로 컴퓨팅 시스템은, 위 손실함수를 기초로 티처 이미지 인코더를 지식을 스튜던트 이미지 인 코더로 점진적으로 증류할 수 있다. 다음으로, 같이 컴퓨팅 시스템은, 제2 정렬 행렬과 제1 정렬 행렬이 일치하도록 예측하는 지식 증류를 수 행한다. 자세히, 제1 정렬 매트릭(bar A)과, 제2 정렬 매트릭(A) 사이의 각 행과 열에 대한 KL 발산으로 증류 손실을 정 의한다. 자세히, 전체 증류 손실(overall distillation loss)은, 제1 정렬 매트릭(bar A)과, 제2 정렬 매트릭(A) 사이의 각 행과 열에 대한 KL 발산으로 증류 손실을 정의할 때, σ를 소프트맥스 함수라고 하면 제1 정렬 매트릭(bar A)과, 제2 정렬 매트릭(A) 사이의 KL 발산인 을 하기 수학식 4와 같이 나타내어, 수학 식 4에 따라 증류 손실을 산출할 수 있다. [수학식 4]"}
{"patent_id": "10-2024-0034179", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "여기서, 전체 증류 손실(overall distillation loss)인 Ldistill은, 제1 정렬 매트릭의 매개변수와 제2 정렬 매트릭 매개변수의 각각의 행 벡터와 열 벡터에 대한 KL 손실의 평균이므로, 하기 수학식 5와 같이 정의할 수 있다. [수학식 5]"}
{"patent_id": "10-2024-0034179", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 7, "content": "그리고 스튜던트 이미지 인코더의 훈련을 가속화하기 위하여, 지식 증류 훈련과, 티처 이미지 인코더 훈련 사이의 균형을 맞추면 스튜던트 이미지 인코더의 최종 손실 Lstudent와 MCD 사전 훈련의 최종 손실 L 는 수학식 6에 따라서 정의된다. 이때, 컴퓨팅 시스템은, 스튜던트 이미지 인코더의 훈련을 가속화하기 위해, 기존 지식증류 방식의 손실인 과 상기 InfoNCE loss인 사이의 균형을 수학식 6과 같이 맞출 수 있다. [수학식 6]"}
{"patent_id": "10-2024-0034179", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 8, "content": "여기서, λ는 KL 발산 손실과 InfoNCE 손실의 균형을 맞추는 매개변수로 실시예에서 지수 이동 평균(ema)에 기 초하여 설정된다. 따라서, 마지막으로 MCD 사전훈련의 최종 손실 은, 수학식 7와 같이 산출될 수 있다 [수학식 7]"}
{"patent_id": "10-2024-0034179", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 9, "content": "그리고 전술한 바와 같이, 티처 이미지 인코더와 텍스트 인코더에서 역전파 방지를 위해 정지 기울기를 통해 인코더(10, 20)의 매개변수에 대한 업데이트를 수행할 수 있다. 자세히, 와 는 각각 스튜던트 인코더와, 모멘텀 티처 이미지 인코더의 매개변수를 의미하고, t 번째 단계에서 를 업데이트는 하기 수학식 8에 따라 수행될 수 있다. [수학식 8] 실험결과, m은 0.994일 때 가장 효율적인 훈련이 수행될 수 있었다. 이하에서는, 본 발명의 실시예에 따른 MCD 사전 훈련을 통해 학습된 비전-언어 트랜스포머의 효과를 기존 기술 과 비교하기 위한 설명을 기술한다. 본 발명의 비전-언어 트랜스포머를 포함하는 인공지능 시스템은, 이미지 분류(Image Classification), 분할 (segmentation), 객체 검출(object detetion), 이미지 생성, 자동캡션생성, 이미지 검색, 이미지 설명 등의 비 전 테스크 작업을 기존 트랜스포머 대비 상대적으로 높은 정확도로 수행할 수 있다. 이하 표 1은, 11개의 다운스트림 데이터세트를 포함하는 YFCC15M 데이터세트에 대해 MCD 사전 훈련 방식으로 비 전-언어 트랜스포머 모델을 사전 훈련시킨 MCD 모델과, YFCC15M 데이터셋으로 기존 기술로 훈련시킨 비전-언어 트랜스포머 모델의 제로샷 이미지 분류 성능을 비교한 표이다. 이때, 이미지-텍스트 쌍에 대한 대비 손실 이외 의 추가 감독을 수행하였는지 여부를 S: 증강 간 SSL, E: 텍스트 증강, N: 가장 가까운 이웃, L: 마스크된 언어 모델링, I: 추가 임베딩 레이어로 인코딩된 증강 정보 X로 축약하여 표현한다. [표 1]"}
{"patent_id": "10-2024-0034179", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 10, "content": "위표를 보면 알수 있듯, 증강 간 SSL만 수행한 MCD 모델이 기존 기술 대비 11개 다운스트림 데이터세트 중 9개 에서 기존 모델 대비 우수한 성능을 보이고 있으며, 평균치 또한 상당하게 향상된 것을 알 수 있다. 따라서, 컴퓨팅 시스템은, 이러한 비전 테스크에 대해 우수한 성능을 가지는 비전-언어 트랜스포머를 포 함한 다양한 애플리케이션을 실행하여, 각종 인공지능 업무를 수행할 수 있다. 그리고 이러한 대조 언어-이미지 사전 훈련에 토큰 희소화와 지식 증류를 활용한 프레임워크는 오디오 등의 추 가적인 양식에 대한 사전 훈련에도 통상의 기술자에 수준에서 확장되어 적용 가능할 것이다. 이상 설명된 본 발명에 따른 실시예는 다양한 컴퓨터 구성요소를 통하여 실행될 수 있는 프로그램 명령어의 형 태로 구현되어 컴퓨터 판독 가능한 기록 매체에 기록될 수 있다. 상기 컴퓨터 판독 가능한 기록 매체는 프로그 램 명령어, 데이터 파일, 데이터 구조 등을 단독으로 또는 조합하여 포함할 수 있다. 상기 컴퓨터 판독 가능한 기록 매체에 기록되는 프로그램 명령어는 본 발명을 위하여 특별히 설계되고 구성된 것이거나 컴퓨터 소프트웨 어 분야의 당업자에게 공지되어 사용 가능한 것일 수 있다. 컴퓨터 판독 가능한 기록 매체의 예에는, 하드 디 스크, 플로피 디스크 및 자기 테이프와 같은 자기 매체, CD-ROM 및 DVD와 같은 광기록 매체, 플롭티컬 디스크 (floptical disk)와 같은 자기-광 매체(magneto-optical medium), 및 ROM, RAM, 플래시 메모리 등과 같은, 프 로그램 명령어를 저장하고 실행하도록 특별히 구성된 하드웨어 장치가 포함된다. 프로그램 명령어의 예에는, 컴파일러에 의하여 만들어지는 것과 같은 기계어 코드뿐만 아니라 인터프리터 등을 사용하여 컴퓨터에 의해서 실행될 수 있는 고급 언어 코드도 포함된다. 하드웨어 장치는 본 발명에 따른 처리를 수행하기 위하여 하나 이 상의 소프트웨어 모듈로 변경될 수 있으며, 그 역도 마찬가지이다.도면 도면1 도면2 도면3 도면4 도면5"}
{"patent_id": "10-2024-0034179", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 실시예에 따른 MCD 사전 훈련 방법을 실행하는 컴퓨팅 시스템의 블록도의 예시를 도시한다. 도 2는 본 발명의 실시예에 따른 MCD 사전 훈련 방법에 따라서 비전-언어 트랜스포머 사전 훈련하고, 사전 훈련 된 비전-언어 트랜스포머를 실행하는 컴퓨팅 디바이스의 블록도의 예시를 도시한다. 도 3은 본 발명의 실시예에 따른 MCD 사전 훈련 방법을 수행하고, 사전 훈련된 비전-언어 트랜스포머를 실행하 는 컴퓨팅 디바이스에 대한 다른 측면에서의 블록도의 예시를 도시한다. 도 4는 본 발명의 실시예에 따른 MCD 사전 훈련 방법의 프레임워크를 개념적으로 나타낸다. 도 5는 본 발명의 실시예에 따른 MCD 사전 훈련 방법의 프레임워크의 메타-아키텍처(meta-architecture)를 나타 낸다."}
