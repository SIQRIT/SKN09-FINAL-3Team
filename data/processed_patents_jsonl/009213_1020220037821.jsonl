{"patent_id": "10-2022-0037821", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0139467", "출원번호": "10-2022-0037821", "발명의 명칭": "의류 옷깃을 집어내는 로봇 장치 및 이 제어 방법", "출원인": "한국전자통신연구원", "발명자": "김태이"}}
{"patent_id": "10-2022-0037821", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "의류의 옷깃을 잡기 위한 엔드 이펙터를 구비한 두 개의 다관절 로봇팔들;적어도 하나 이상의 의류가 쌓여 있는 의류 더미를 실시간으로 영상 촬영하는 영상 촬영부; 및상기 촬영된 의류 더미 영상을 영상 분석하고, 상기 영상 분석된 의류 더미 영상을 입력으로 하는 미리 학습된인공지능 모델을 이용하여 잡고자 하는 옷깃을 검출하고, 상기 검출된 옷깃을 잡을 수 있도록, 상기 다관절 로봇팔들 각각을 제어하는 제어부를 포함하는, 다관절 로봇 장치."}
{"patent_id": "10-2022-0037821", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "의류 옷깃을 집어내는 로봇 장치 및 이 제어 방법이 개시된다. 상기 다관절 로봇 장치는, 의류의 옷깃을 잡기 위 한 엔드 이펙터를 구비한 두 개의 다관절 로봇팔들; 적어도 하나 이상의 의류가 쌓여 있는 의류 더미를 실시간으 로 영상 촬영하는 영상 촬영부; 및 상기 촬영된 의류 더미 영상을 영상 분석하고, 상기 영상 분석된 의류 더미 영상을 입력으로 하는 미리 학습된 인공지능 모델을 이용하여 잡고자 하는 옷깃을 검출하고, 상기 검출된 옷깃을 잡을 수 있도록, 상기 다관절 로봇팔들 각각을 제어하는 제어부를 포함한다."}
{"patent_id": "10-2022-0037821", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 다관절 로봇 장치에 관한 것이며, 보다 구체적으로 의류 옷깃을 집어내는 로봇 장치 및 이 제어 방법 에 대한 것이다."}
{"patent_id": "10-2022-0037821", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "일반적으로 의류는 섬유 소재 등의 부드러운 재질로 제조되고, 의류를 보관 및 이동하기 위하여 의류를 접을 수 있다. 사람이 의류를 접을 수 있지만, 의류를 접는 기기인 의류 폴딩 장치를 이용할 수도 있다. 세탁, 건조, 먼지 제거 등이 진행된 의류는 의류 폴딩 장치에 투입되기 전에 서로 뭉쳐진 상태로 여러 벌의 옷 이 섞여 있다. 따라서, 사람이 직접 복수개의 옷 중에서 하나의 옷만 펼친 다음, 의류 폴딩 장치에 투입할 수 있다. 그런데, 세탁, 건조 등을 마친 의류들은 뭉쳐지고 구겨진 상태로 배출되기 때문에 사용자가 직접 구겨진 옷들 가운에서 하나를 픽업하여 주름을 편 상태로 의류 폴딩 장치에 공급해야 하는 번거로움이 있다. 즉, 사용자가 의류를 일일이 집어서 의류 폴딩 장치에 넣어주어야 하기에 사용자에게 번거로움을 줄 수 있다."}
{"patent_id": "10-2022-0037821", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 개시의 기술적 과제는, 의류 옷깃을 집어내는 로봇 장치 및 이 제어 방법을 제공하는데 그 목적이 있다. 본 개시에서 이루고자 하는 기술적 과제들은 이상에서 언급한 기술적 과제들로 제한되지 않으며, 언급하지 않은"}
{"patent_id": "10-2022-0037821", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 2, "content": "또 다른 기술적 과제들은 아래의 기재로부터 본 개시가 속하는 기술분야에서 통상의 지식을 가진 자에게 명확하 게 이해될 수 있을 것이다."}
{"patent_id": "10-2022-0037821", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 개시의 일 실시예에 따르면, 의류 옷깃을 집어내는 로봇 장치 및 이 제어 방법이 개시된다. 상기 다관절 로 봇 장치는, 의류의 옷깃을 잡기 위한 엔드 이펙터를 구비한 두 개의 다관절 로봇팔들; 적어도 하나 이상의 의류 가 쌓여 있는 의류 더미를 실시간으로 영상 촬영하는 영상 촬영부; 및 상기 촬영된 의류 더미 영상을 영상 분석 하고, 상기 영상 분석된 의류 더미 영상을 입력으로 하는 미리 학습된 인공지능 모델을 이용하여 잡고자 하는 옷깃을 검출하고, 상기 검출된 옷깃을 잡을 수 있도록, 상기 다관절 로봇팔들 각각을 제어하는 제어부를 포함한다. 이때, 상기 영상 촬영부는, RGB 카메라와 뎁스 카메라를 포함하고, 상기 RGB 카메라와 상기 뎁스 카메라를 이용 하여 상기 의류 더미에 대한 컬러 영상과 뎁스 영상을 촬영할 수 있다. 이때, 상기 제어부는, 상기 인공지능 모델을 이용하여 의류 종류를 판별하고 상기 의류 종류에 따른 옷깃을 검 출하여, 상기 검출된 옷깃의 위치로 상기 다관절 로봇팔들이 이동하도록 상기 다관절 로봇팔들 각각을 제어할 수 있다. 이때, 상기 제어부는, 상기 인공지능 모델에 의해 옷깃이 검출되지 않는 경우 상기 다관절 로봇팔들 각각을 제 어하여 상기 의류 더미에서 어느 하나의 의류의 일부를 잡아 펼쳐서 미리 결정된 테이블 상에 이동시킨 후 상기 인공지능 모델을 이용하여 상기 테이블 상에 펼쳐진 의류의 옷깃을 검출함으로써, 상기 검출된 옷깃을 잡을 수 있도록, 상기 다관절 로봇팔들 각각을 제어할 수 있다. 이때, 상기 제어부는, 상기 다관절 로봇팔들이 상기 검출된 옷깃을 집으면, 상기 옷깃을 집은 의류를 의류 종류 별로 분류되도록 상기 다관절 로봇팔들 각각의 이동을 제어할 수 있다. 이때, 상기 제어부는, 상기 다관절 로봇팔들이 상기 검출된 옷깃을 집으면, 상기 옷깃을 집은 의류를 미리 결정 된 테이블 상에 놓은 후 해당 의류를 의류 종류별로 미리 설정된 접는 방식으로 상기 해당 의류를 접도록 상기 다관절 로봇팔들 각각을 제어할 수 있다."}
{"patent_id": "10-2022-0037821", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 2, "content": "본 개시에 대하여 위에서 간략하게 요약된 특징들은 후술하는 본 개시의 상세한 설명의 예시적인 양상일 뿐이며, 본 개시의 범위를 제한하는 것은 아니다."}
{"patent_id": "10-2022-0037821", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 개시에 따르면, 의류 옷깃을 집어내는 로봇 장치 및 이 제어 방법을 제공할 수 있다. 본 개시에서 얻을 수 있는 효과는 이상에서 언급한 효과들로 제한되지 않으며, 언급하지 않은 또 다른 효과들은 아래의 기재로부터 본 개시가 속하는 기술 분야에서 통상의 지식을 가진 자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2022-0037821", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하에서는 첨부한 도면을 참고로 하여 본 개시의 실시 예에 대하여 본 개시가 속하는 기술 분야에서 통상의 지 식을 가진 자가 용이하게 실시할 수 있도록 상세히 설명한다. 그러나, 본 개시는 여러 가지 상이한 형태로 구현 될 수 있으며 여기에서 설명하는 실시 예에 한정되지 않는다. 본 개시의 실시 예를 설명함에 있어서 공지 구성 또는 기능에 대한 구체적인 설명이 본 개시의 요지를 흐릴 수 있다고 판단되는 경우에는 그에 대한 상세한 설명은 생략한다. 그리고, 도면에서 본 개시에 대한 설명과 관계없는 부분은 생략하였으며, 유사한 부분에 대해서는 유사한 도면 부호를 붙였다. 본 개시에 있어서, 어떤 구성요소가 다른 구성요소와 \"연결\", \"결합\" 또는 \"접속\"되어 있다고 할 때, 이는 직접 적인 연결 관계 뿐만 아니라, 그 중간에 또 다른 구성요소가 존재하는 간접적인 연결관계도 포함할 수 있다. 또 한 어떤 구성요소가 다른 구성요소를 \"포함한다\" 또는 \"가진다\"고 할 때, 이는 특별히 반대되는 기재가 없는 한 다른 구성요소를 배제하는 것이 아니라 또 다른 구성요소를 더 포함할 수 있는 것을 의미한다. 본 개시에 있어서, 제1, 제2 등의 용어는 하나의 구성요소를 다른 구성요소로부터 구별하는 목적으로만 사용되 며, 특별히 언급되지 않는 한 구성요소들 간의 순서 또는 중요도 등을 한정하지 않는다. 따라서, 본 개시의 범 위 내에서 일 실시 예에서의 제1 구성요소는 다른 실시 예에서 제2 구성요소라고 칭할 수도 있고, 마찬가지로 일 실시 예에서의 제2 구성요소를 다른 실시 예에서 제1 구성요소라고 칭할 수도 있다. 본 개시에 있어서, 서로 구별되는 구성요소들은 각각의 특징을 명확하게 설명하기 위한 것일 뿐, 구성요소들이 반드시 분리되는 것을 의미하지는 않는다. 즉, 복수의 구성요소가 통합되어 하나의 하드웨어 또는 소프트웨어 단위로 이루어질 수도 있고, 하나의 구성요소가 분산되어 복수의 하드웨어 또는 소프트웨어 단위로 이루어질 수 도 있다. 따라서, 별도로 언급하지 않더라도 이와 같이 통합된 또는 분산된 실시 예도 본 개시의 범위에 포함된 다. 본 개시에 있어서, 다양한 실시 예에서 설명하는 구성요소들이 반드시 필수적인 구성요소들은 의미하는 것은 아 니며, 일부는 선택적인 구성요소일 수 있다. 따라서, 일 실시 예에서 설명하는 구성요소들의 부분집합으로 구성 되는 실시 예도 본 개시의 범위에 포함된다. 또한, 다양한 실시예에서 설명하는 구성요소들에 추가적으로 다른 구성요소를 포함하는 실시 예도 본 개시의 범위에 포함된다. 본 개시에 있어서, 본 명세서에 사용되는 위치 관계의 표현, 예컨대 상부, 하부, 좌측, 우측 등은 설명의 편의 를 위해 기재된 것이고, 본 명세서에 도시된 도면을 역으로 보는 경우에는, 명세서에 기재된 위치 관계는 반대 로 해석될 수도 있다. 본 개시의 실시예들은, 의류 더미에 개별적 옷들을 분리하여 옷깃, 바짓단, 수건 끝단을 찾아내어 다관절 로봇 팔로 의류의 옷깃을 정확하게 집어내는 것을 그 요지로 한다. 여기서, 의류의 옷깃은, 상의의 옷깃, 하의의 바짓단(또는 바지춤), 수건의 끝단과 양말의 끝단 등을 포함할 수 있으며, 이렇게 옷깃을 집어낸 의류를 의류 접는 기계에 넣거나 사람에게 전달할 수도 있고, 의류를 종류별로 분류할 수도 있다. 도 1은 본 개시의 실시예에 따른 의류 옷깃을 집어내는 로봇 장치의 구성을 나타낸 도면이다. 도 1을 참조하면, 본 개시의 실시예에 따른 의류 옷깃을 집어내는 로봇 장치는, 두 개의 다관절 로봇팔 , 영상 촬영부와 제어부를 포함한다. 다관절 로봇팔들은, 제어부의 제어에 의하여 동작되며, 의류를 집기 위한 엔드 이펙터를 구비할 수 있다 이때, 다관절 로봇팔들은, 특정 위치에 고정된 상태일 수도 있고, 이동 가능한 기기에 부착된 상태일 수도 있다. 다관절 로봇팔들 각각은, 제어부의 제어에 의하여 각각 제어될 수 있으며, 각각의 제어를 통해 의류 의 옷깃을 순차적으로 잡거나 특정 위치로 이동시키거나 미리 설정된 접는 방식으로 의류를 접을 수도 있다. 물 론, 다관절 로봇팔에 의해 집어낸 의류는 해당 의류를 사용자에게 전달하거나 의류를 접는 의류 접는 기기 예를 들어, 폴딩메이트에 넣어서 의류가 자동으로 접어지게 하거나, 집어낸 의류의 종류를 확인하여 의류 종류별로 분류할 수도 있다. 물론, 의류 종류별로 의류를 분류하기 위해서, 의류를 종류별로 분류하기 위한 분류함이나 장소가 따로 설정되어야 한다. 영상 촬영부는, 의류가 쌓인 의류 더미를 영상 촬영하는 수단으로, 특정 위치 예를 들어, 의류 더미를 넣 는 바구니나 통 또는 의류 더미를 놓는 특정 위치를 실시간으로 촬영한다. 이때, 영상 촬영부는, RGB 카메라와 뎁스 카메라 중 적어도 하나의 카메라를 이용하여 의류 더미에 대한 컬러 영상 또는 뎁스 영상을 촬영할 수 있으며, 이렇게 촬영된 영상은 제어부로 전달될 수 있다. 영상 촬영부는, 다관절 로봇팔의 특정 부위에 부착되어 있을 수도 있고, 다관절 로봇팔들이 부착되어 있는 수단에 부착되어, 의류 더미 뿐만 아니라 집어낸 의류를 이동시키는 방향의 영상을 실시간으로 촬영할 수 도 있다. 제어부는, 영상 촬영부에 의해 촬영된 의류 더미 영상을 영상 분석하고, 영상 분석된 의류 더미 영상 예를 들어, RGB 영상과 뎁스 영상 중 적어도 하나의 영상을 입력으로 하는 미리 학습된 인공지능 모델을 이용하 여 잡고자 하는 옷깃을 검출하고, 검출된 옷깃을 잡을 수 있도록, 다관절 로봇팔들 각각을 제어한다. 이때, 인공지능 모델은, 인터넷 쇼핑몰, 무료 사진 홈페이지 등에서 의류 사진 수집하고, 의류 업체와 공장 등 과의 협약을 통하여 의류 사진을 수집할 수 있으며, 이렇게 수집된 데이터를 학습 데이터, 검증 데이터와 테스 트 데이터로 분할한 후, 학습 데이터에 포함된 의류 사진에서 옷깃에 해당하는 부분을 라벨링함으로써, 라벨링 된 학습 데이터를 이용하여 인공 지능 모델을 학습할 수 있다. 여기서, 인공지능 모델은, 입력으로 의류 영상과 의류 영상에 대한 뎁스 영상 중 적어도 하나를 입력으로 하여, 의류 종류와 의류의 옷깃을 검출하는 모델일 수 있다. 물론, 이렇게 학습된 인공지능 모델은 검증 데이터를 이용하여 검증하고, 테스트 데이터를 이용하여 모델 성능을 측정하고 개선할 수 있다. 본 개시의 실시예에서의 인공지능 모델은, 의류 영상에서 옷깃을 검출하는 것으로 제한되거나 한정되지 않으며, 의류 영상을 분석하는 것 또한 별도의 인공지능 모델 또는 동일한 인공지능 모델을 이용하여 수행될 수도 있다. 제어부는, 적어도 하나의 의류가 쌓인 의류 더미에서 미리 학습된 인공지능 모델을 이용하여 의류 종류를 판별하고 의류 종류에 따른 옷깃을 검출하여, 검출된 옷깃의 위치로 다관절 로봇팔들이 이동하도록 다관절 로봇팔들 각각을 제어함으로써, 의류 옷깃을 집을 수 있다. 상황에 따라, 제어부는, 인공지능 모델을 이용 하여 의류의 종류를 판별하지 않고, 의류의 옷깃만을 검출하여 검출된 옷깃의 위치로 다관절 로봇팔들이 이동하도록 다관절 로봇팔들 각각을 제어할 수도 있다. 예컨대, 제어부가 옷깃 형태 등을 통해 의류 종류 와 상관없이 옷깃을 검출할 수 있을 때, 옷깃을 직접 검출하여 옷깃을 집을 수 있도록, 다관절 로봇팔들 각각을 제어할 수 있다. 나아가, 제어부는, 인공지능 모델에 의해 옷깃이 검출되지 않는 경우 다관절 로봇팔들 각각을 제어하 여 의류 더미에서 어느 하나의 의류 예를 들어, 가장 위에 있는 의류의 일부를 잡아 펼쳐서 미리 결정된 테이블 상에 이동시킨 후 인공지능 모델을 이용하여 테이블 상에 펼쳐진 의류의 옷깃을 검출함으로써, 검출된 옷깃을 잡을 수 있도록, 다관절 로봇팔들 각각을 제어할 수도 있다. 예컨대, 제어부는, 집어 올린 의류의 옷깃을 찾지 못한 경우, 한쪽 로봇팔로 집어든 의류를 다른 로봇팔로 옷의 다른 쪽을 잡아 펼친 상태가 되도록 하여 테이블 또는 보조테이블 위에 올려놓는다. 이때, 로봇팔로 의류 를 흔들어 펼칠 수도 있고, 옷이 형태를 알아보기 어렵도록 말려져 있거나 한쪽이 심하게 뒤집힌 경우 등 예외 상황은 미분류 수거함에 의류를 분리하도록 할 수도 있다. 그리고, 제어부는, 테이블 위에 올려 놓은 후에 도 겹쳐진 부분이 있는 의류의 경우 뎁스 카메라를 통해 상대적으로 겹쳐진 위치를 확인하여 최종적으로 의류가 펼쳐진 상태가 되도록 제어하고, 펼쳐진 옷을 테이블에 올려놓은 후에는 RGB 카메라로 이미지를 촬영하고 학습 된 인공지능 모델을 통해 의류를 셔츠, 바지 등으로 카테고리를 인식하여, 인공지능 모델로 의류의 옷깃의 위치 를 검출함으로써, 의류의 옷깃 위치를 로봇팔로 집도록 제어하여 의류의 옷깃을 다관절 로봇팔들이 집게 된다. 본 개시의 실시예에 따른 로봇 장치는, 의류의 옷깃을 검출하여 집는 것에 제한되거나 한정되지 않으며, 옷깃을 집은 의류를 폴딩메이트에 넣을 수도 있고, 옷깃을 집은 의류를 의류 종류별로 분류되도록 다관절 로봇 팔들 각각의 이동을 제어할 수 있다. 일 실시예에 따라, 로봇 장치는, 집은 의류를 상의, 하의, 수건, 양말 등 으로 분류하여, 각각에 대하여 설정된 위치, 테이블, 보관함 등에 전달할 수도 있다. 다른 실시예 따라, 로봇 장치는 다관절 로봇팔들이 검출된 옷깃을 집으면, 옷깃을 집은 의류를 미리 결정된 테이블 상에 놓은 후 해당 의류를 의류 종류별로 미리 설정된 접는 방식으로 해당 의류를 접도록 다관절 로봇팔들 각각을 제어할 수도 있다. 즉, 로봇 장치는, 의류의 옷깃을 검출하여 집는 것 뿐만 아니라 집은 의류에 대하여 다관절 로봇팔들 각각을 제어하여 접을 수도 있다. 이때, 접는 방식은 상의, 하의, 수건, 양말 등에 따라 달라지고, 사용자의 접는 방식에 따라 달라질 수 있으며, 이는 사용자에 의해 직접 설정되거나 미리 설정된 접는 방식들 중에서 선택될 수도 있다.이러한 본 개시의 실시예에 따른 로봇 장치의 동작을 도 2를 참조하여 설명한다. 도 2는 본 개시의 로봇 장치에 대한 동작을 설명하기 위한 예시도를 나타낸 도면이다. 도 2a에 도시된 바와 같이, 적어도 하나의 의류가 쌓인 의류 더미를 영상 촬영하고, 인공지능 모델을 이용하여 촬영된 영상을 분석하고, 영상 분석을 통해 집고자 하는 의류와 옷깃을 검출한다. 그리고, 도 2b에 도시된 바와 같이, 인공지능 모델을 이용하여 의류의 옷깃이 검출되면, 검출된 옷깃의 한쪽을 제1 다관절 로봇팔로 집도록 제어하고 검출된 옷깃의 다른 한쪽을 제2 다관절 로봇팔로 집도록 제어함으로써, 도 2d에 도시된 바와 같이, 옷 깃들을 잡아서 들어올릴 수 있다. 실시예에 따라, 다관절 로봇팔들에 의해 집어진 의류는 도 3에 도시된 예와 같이, 의류 접는 기계 예 를 들어, 폴딩메이트와 협동하여 편리하게 옷을 정리할 수 있다. 기존에는 사람이 의류 더미에서 옷을 하나씩 꺼내서 옷깃부분을 들어서 기계에 올려놓아야 하지만, 본 개시의 실시예에 따른 로봇 장치를 이용하면 의 류 더미에서 의류를 집어서 폴딩메이트에 전달하는 과정을 자동화할 수 있다. 다른 실시예에 따라, 다관절 로봇팔들에 의해 집어진 의류는 도 4에 도시된 예와 같이, 인공지능 기반으로 의류를 분류할 수도 있다. 즉, 로봇 장치는 인공지능 기반으로 다관절 로봇팔들에 의해 집어진 의류 가 사용자가 분류하기 원하는 의류 예를 들어, 상의인지 판별하고, 사용자가 분류하기를 원하는 의류로 판별되 는 경우 해당 의류를 별도의 테이블 또는 위치로 이동시킬 수 있다. 예를 들어, 로봇 장치는 의류 더 미에서 옷걸이에 걸어야 하는 의류를 따로 분류하는 기능을 제공할 수도 있다. 이 뿐만 아니라, 본 개시의 실시예에 따른 로봇 장치는 의류 더미에서 집어낸 의류의 종류를 판별하고, 의 류 종류가 판별된 의류를 의류 종류별로 미리 설정된 테이블 또는 위치로 이동시킴으로써, 의류 더미에 쌓인 의 류를 의류 종류별로 분리할 수 있다. 반면, 도 2c에 도시된 바와 같이, 로봇 장치는 인공지능 모델에 의해 옷깃이 검출되지 않는 경우 의류 더 미에서 가장 위에 있는 의류의 일부를 잡아 펼쳐서 보조테이블에 이동시킨 후 인공지능 모델을 이용하여 테이블 상에 펼쳐진 의류의 옷깃을 검출함으로써, 도 2d에 도시된 바와 같이, 검출된 옷깃들을 잡아서 들어올릴 수 있 다. 이와 같이, 본 개시의 실시예에 따른 의류 옷깃을 집어내는 로봇 장치는, 인공지능 모델과 다관절 로봇팔들을 이용하여 의류가 쌓인 의류 더미에서 개별적인 옷을 꺼내어 옷깃을 집어내고, 집어낸 의류를 원하는 위치로 이 동하여 놓을 수 있기 때문에 사용자가 의류 더미에서 의류를 일일이 집어야 하는 번거로움을 해소할 수 있다. 또한, 본 개시의 실시예에 따른 의류 옷깃을 집어내는 로봇 장치는, 의류 더미에서 의류를 종류별로 분류하거나 사용자가 원하는 의류 종류를 별도로 분류함으로써, 사용자에게 편리함을 제공할 수 있다. 또한, 로봇 장치를 구성하는 다관절 로봇팔들은 사용자의 선택에 따라 이동체 구조물에 부착된 구조일 수도 있 고 한 위치에 고정되어 있을 수도 있기 때문에 자유로운 이동과 고정이 가능하며, 의류를 접는 기계 등에 부착 되어 있지 않음으로써, 다른 기술을 접목하여 사용자 편의에 따라 소프트웨어적인 조작을 통해 다른 기능 또한 수행할 수도 있다. 도 5는 본 개시의 실시예에 따른 의류 옷깃을 집어내는 로봇 장치 제어 방법의 순서도를 나타낸 도면으로, 도 1 내지 도 4의 로봇 장치에서 수행하는 동작을 나타낸 도면이다. 도 5를 참조하면, 본 개시의 실시예에 따른 의류 옷깃을 집어내는 로봇 장치 제어 방법은, 의류가 쌓여 있는 의 류 더미를 실시간으로 영상 촬영하고, 촬영된 영상을 처리하여 처리된 영상 예를 들어, RGB 영상과 뎁스 영상 그리고 미리 학습된 인공지능 모델을 이용하여 의류 더미에서 어느 하나의 의류와 해당 의류의 옷깃을 검출한다 (S510, S520). 이때, 단계 S520은 의류를 검출하지 않고 의류의 옷깃만을 검출할 수도 있다. 상술한 과정을 통해 의류 더미에서 의류 옷깃이 검출되는지 판단(S530)하고, 상기 판단 결과 옷깃이 검출되면, 검출된 옷깃의 한쪽을 제1 다관절 로봇팔을 이용하여 잡은 후 옷깃의 다른 한쪽을 제2 다관절 로봇팔을 이용하여 잡는다(S540). 제1, 제2 다관절 로봇팔에 의해 옷깃이 잡히면, 제1, 제2 다관절 로봇팔로 평행하도 옷깃을 들어올림으로써, 해 당 의류 또는 옷을 원하는 위치로 이동시킬 수 있다(S550). 반면 단계 S530 판단 결과, 인공지능 모델을 통해 의류 더미에서 옷깃이 검출되지 않는 경우에는 다관절 로봇팔 들 각각을 제어하여 의류 더미에서 어느 하나의 의류 예를 들어, 가장 위에 있는 의류의 일부를 잡아 펼쳐서 미 리 결정된 테이블 상에 이동시킨 후 인공지능 모델을 이용하여 테이블 상에 펼쳐진 의류의 옷깃을 검출함으로써, 검출된 옷깃을 다관절 로봇팔들을 이용하여 집어낼 수 있다(S560, S570). 비록, 도 5의 방법에서 그 설명이 생략되더라도, 본 개시의 실시예에 따른 방법은 도 1 내지 도 4의 장치에서 설명한 모든 내용을 포함할 수 있으며, 이는 해당 기술 분야에 종사하는 당업자에게 있어서 자명하다. 도 6은 본 개시의 다른 실시예에 따른 의류 옷깃을 집어내는 로봇 장치가 적용되는 디바이스의 구성도를 나타낸 도면이다. 예를 들어, 도 1의 본 개시의 실시예에 따른 의류 옷깃을 집어내는 로봇 장치는 도 6의 디바이스가 될 수 있다. 도 6을 참조하면, 디바이스는 메모리, 프로세서, 송수신부 및 주변 장치(160 1)를 포함할 수 있다. 또한, 일 예로, 디바이스는 다른 구성을 더 포함할 수 있으며, 상술한 실시예로 한 정되지 않는다. 이때, 상기 디바이스는 예를 들어 이동 가능한 사용자 단말기(예를 들어, 스마트 폰, 노 트북, 웨어러블 기기 등) 이거나 고정된 관리 장치(예를 들어, 서버, PC 등) 일 수 있다. 보다 상세하게는, 도 6의 디바이스는 로봇 장치, 의류 분류 장치, 의류 전달 장치, 의류 접는 장치 등과 같은 예시적인 하드웨어/소프트웨어 아키텍처일 수 있다. 이때, 일 예로, 메모리는 비이동식 메모리 또는 이동식 메모리일 수 있다. 또한, 일 예로, 주변 장치는 디스플레이, GPS 또는 다른 주변기기들을 포함할 수 있으며, 상술한 실시예로 한정되지 않는다. 또한, 일 예로, 상술한 디바이스는 상기 송수신부와 같이 통신 회로를 포함할 수 있으며, 이에 기 초하여 외부 디바이스와 통신을 수행할 수 있다. 또한, 일 예로, 프로세서는 범용 프로세서, DSP(digital signal processor), DSP 코어, 제어기, 마이크 로제어기, ASIC들(Application Specific Integrated Circuits), FPGA(Field Programmable Gate Array) 회로들, 임의의 다른 유형의 IC(integrated circuit) 및 상태 머신과 관련되는 하나 이상의 마이크로프로세서 중 적어도 하나 이상일 수 있다. 즉, 상술한 디바이스를 제어하기 위한 제어 역할을 수행하는 하드웨어적 /소프트웨어적 구성일 수 있다. 또한 상기 프로세서는 전술한 도 1의 제어부의 기능을 모듈화하여 수행할 수 있다. 이때, 프로세서는 의류 옷깃을 집어내는 로봇 장치의 다양한 필수 기능들을 수행하기 위해 메모리 에 저장된 컴퓨터 실행가능한 명령어들을 실행할 수 있다. 일 예로, 프로세서는 신호 코딩, 데이터 처리, 전력 제어, 입출력 처리 및 통신 동작 중 적어도 어느 하나를 제어할 수 있다. 또한, 프로세서는 물리 계 층, MAC 계층, 어플리케이션 계층들을 제어할 수 있다. 또한, 일 예로, 프로세서는 액세스 계층 및/또는 어플리케이션 계층 등에서 인증 및 보안 절차를 수행할 수 있으며, 상술한 실시예로 한정되지 않는다. 일 예로, 프로세서는 송수신부를 통해 다른 장치들과 통신을 수행할 수 있다. 일 예로, 프로세서 는 컴퓨터 실행가능한 명령어들의 실행을 통해 의류 옷깃을 집어내는 로봇 장치가 네트워크를 통해 다른 장치들과 통신을 수행하게 제어할 수 있다. 즉, 본 개시에서 수행되는 통신이 제어될 수 있다. 일 예로, 송수신 부는 안테나를 통해 RF 신호를 전송할 수 있으며, 다양한 통신망에 기초하여 신호를 전송할 수 있다. 또한, 일 예로, 안테나 기술로서 MIMO 기술, 빔포밍 등이 적용될 수 있으며, 상술한 실시예로 한정되지 않는다. 또한, 송수신부를 통해 송수신한 신호는 변조 및 복조되어 프로세서에 의해 제어될 수 있으며, 상 술한 실시 예로 한정되지 않는다. 본 개시의 예시적인 방법들은 설명의 명확성을 위해서 동작의 시리즈로 표현되어 있지만, 이는 단계가 수행되는 순서를 제한하기 위한 것은 아니며, 필요한 경우에는 각각의 단계가 동시에 또는 상이한 순서로 수행될 수도 있 다. 본 개시에 따른 방법을 구현하기 위해서, 예시하는 단계에 추가적으로 다른 단계를 포함하거나, 일부의 단 계를 제외하고 나머지 단계를 포함하거나, 또는 일부의 단계를 제외하고 추가적인 다른 단계를 포함할 수도 있다. 본 개시의 다양한 실시 예는 모든 가능한 조합을 나열한 것이 아니고 본 개시의 대표적인 양상을 설명하기 위한 것이며, 다양한 실시 예에서 설명하는 사항들은 독립적으로 적용되거나 또는 둘 이상의 조합으로 적용될 수도 있다. 또한, 본 개시의 다양한 실시 예는 하드웨어, 펌웨어(firmware), 소프트웨어, 또는 그들의 결합 등에 의해 구현 될 수 있다. 하드웨어에 의한 구현의 경우, 하나 또는 그 이상의 ASICs(Application Specific Integrated Circuits), DSPs(Digital Signal Processors), DSPDs(Digital Signal Processing Devices), PLDs(Programmable Logic Devices), FPGAs(Field Programmable Gate Arrays), 범용 프로세서(general processor), 컨트롤러, 마이크로 컨트롤러, 마이크로 프로세서 등에 의해 구현될 수 있다. 본 개시의 범위는 다양한 실시 예의 방법에 따른 동작이 장치 또는 컴퓨터 상에서 실행되도록 하는 소프트웨어 또는 머신-실행가능한 명령들(예를 들어, 운영체제, 애플리케이션, 펌웨어(firmware), 프로그램 등), 및 이러한 소프트웨어 또는 명령 등이 저장되어 장치 또는 컴퓨터 상에서 실행 가능한 비-일시적 컴퓨터-판독가능 매체 (non-transitory computer-readable medium)를 포함한다."}
{"patent_id": "10-2022-0037821", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 개시의 실시예에 따른 의류 옷깃을 집어내는 로봇 장치의 구성을 나타낸 도면이다. 도 2는 본 개시의 로봇 장치에 대한 동작을 설명하기 위한 예시도를 나타낸 도면이다. 도 3은 본 개시의 실시예에 따른 의류 옷깃을 집어내는 로봇 장치가 적용되는 예시도를 나타낸 도면이다. 도 4는 본 개시의 실시예에 따른 의류 옷깃을 집어내는 로봇 장치를 이용하여 의상을 구분하는 예시도를 나타낸 도면이다. 도 5는 본 개시의 실시예에 따른 의류 옷깃을 집어내는 로봇 장치 제어 방법의 순서도를 나타낸 도면이다. 도 6은 본 개시의 다른 실시예에 따른 의류 옷깃을 집어내는 로봇 장치가 적용되는 디바이스의 구성도를 나타낸 도면이다."}
