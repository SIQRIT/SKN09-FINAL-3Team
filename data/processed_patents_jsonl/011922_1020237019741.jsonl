{"patent_id": "10-2023-7019741", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0108293", "출원번호": "10-2023-7019741", "발명의 명칭": "입력 값 처리 방법 및 시스템", "출원인": "프라운호퍼 게젤샤프트 쭈르 푀르데룽 데어 안겐", "발명자": "짐머만, 하이코"}}
{"patent_id": "10-2023-7019741", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "인공 학습 시스템인 작업 레벨(710)과 평가 레벨(730)을 갖는 전체 시스템에서 하나 이상의 센서에 의해 감지된센서 데이터를 포함하는 입력 값(Xi)을 처리하기 위해, 기계의 컨트롤러에서 실행되는 방법에 있어서, a) 제1 분류에 따라, 제1 입력 값(Xi(t1))을 상기 작업 레벨에 입력하고 상기 작업 레벨에 의해 상기 제1 입력값으로부터 제1 출력 값(Output11)을 결정하는 단계;b) 상기 제1 출력 값(Output11)을 기초로 제1 상황 데이터(Y(t3))를 형성하는 단계;c) 상기 초기 상황 데이터를 상기 평가 레벨에 입력하여 상기 초기 상황 데이터가 소정의 초기 조건을 충족하는지 여부 또는 어느 정도를 충족하는지를 나타내는 초기 평가(Output21)를 상기 평가 레벨에 의해 결정하는단계;d) 제1 평가에 기초하여 상기 작업 레벨에서 상기 제1 출력 값의 상기 결정에 영향을 미치는 단계; 단계 a) - d)를 반복적으로 수행하는 단계;e) 제2 분류에 따라, 제2 입력 값(Xi(t2))을 상기 작업 레벨에 입력하고 상기 작업 레벨에 의해 상기 제2 입력값으로부터 제2 출력 값(Output12)을 결정하는 단계 - 상기 제2 출력 값의 상기 결정은 상기 제1 출력 값에 의해 영향을 받음 - ;f) 상기 제2 출력 값에 기초하여 제2 상황 데이터(Y(t4))를 형성하는 단계; g) 상기 제2 상황 데이터를 상기 평가 레벨에 입력하고 제2 상황 데이터가 미리 결정된 제2 조건을 충족하는지또는 어느 정도를 충족하는지를 나타내는 제2 평가(output22)를 상기 평가 레벨에 의해 결정하는 단계 - 상기제2 평가의 상기 결정은 상기 제1 평가에 의해 영향을 받음 - ;h) 상기 제2 평가에 기초하여 상기 작업 레벨에서 상기 제2 출력 값의 상기 결정에 영향을 미치는 단계; 단계 e) - h)를 반복적으로 수행하는 단계를 포함하고, 상기 제1 및/또는 제2 출력 값은 상기 전체 시스템의 전체 출력 값(Output)으로 사용되며, 상기 전체 출력 값은상기 기계의 제어 매개변수 및/또는 상태 매개변수로 사용되는, 방법."}
{"patent_id": "10-2023-7019741", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 단계 a) - d)는 미리 결정된 제1 기간이 경과할 때까지 및/또는 상기 제1 출력 값이 미리 결정된 제1 허용 오차 내에서 연속적인 반복 사이에서 더 이상 변경되지 않을 때까지 및/또는 상기 제1 평가가 상기제1 조건이 적어도 어느 정도 충족되는 것을 나타낼 때까지 반복적으로 수행되고; 바람직하게 상기 제1 출력 값은 이 반복 수행이 완료될 때 전체 출력 값으로 사용되는, 방법."}
{"patent_id": "10-2023-7019741", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "선행 항들 중 어느 한 항에 있어서, 단계 e) - h)는 미리 결정된 제2 기간이 경과할 때까지 및/또는 상기 제2출력 값이 미리 결정된 제2 허용 오차 내에서 연속적인 반복 사이에서 더 이상 변경되지 않을 때까지 및/또는상기 제2 평가가 상기 제2 조건이 적어도 어느 정도 충족되는 것을 나타낼 때까지 반복적으로 수행되고; 바람직하게 상기 제2 출력 값은 이 반복 수행이 완료될 때 전체 출력 값으로 사용되는, 방법."}
{"patent_id": "10-2023-7019741", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "선행 항들 중 어느 한 항에 있어서, 전체 시퀀스 메모리(760, 860)에, 각각이 상호 대응하는 입력 값 및/또는제1 출력 값 및/또는 제1 상황 데이터 및/또는 제1 평가 및/또는 제2 출력 값 및/또는 제2 상황 데이터 및/또는공개특허 10-2023-0108293-3-제2 평가를 포함하는, 전체 레코드의 전체 시퀀스를 저장하는 단계를 포함하고; 바람직하게 상기 전체 기록 및/또는 상기 전체 기록에 포함된 상기 값 또는 데이터에는 각각의 시간 정보 및/또는 번호 지정이 제공되는,방법."}
{"patent_id": "10-2023-7019741", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "선행 항들 중 어느 한 항에 있어서, 상기 제1 및/또는 제2 조건을 보완하여, 상기 보완 전에 상기 제1 및 제2조건이 각각 충족되지 않는 제1, 제2 상황 데이터에 대해, 상기 보완된 제1 및 제2 조건이 각각 충족되거나 적어도 어느 정도 충족되도록 하는 단계를 더 포함하고; 바람직하게 상기 제2 조건만 변경되고 상기 제1 조건은변경되지 않고 유지되는, 방법."}
{"patent_id": "10-2023-7019741", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5항에 있어서, 제3항에 따른 경우, 상기 단계 e)-h)의 반복이 중단된 경우, 상기 제2 기간이 만료되었거나,바람직하게는 상기 제2 출력 값이 상기 제2 허용 오차 내에서 더 이상 변경되지 않기 때문에, 상기 제2 조건이보완되어 중단시 존재하는 상기 상황 데이터가 상기 보완된 제2 조건을 충족하는, 방법."}
{"patent_id": "10-2023-7019741", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제5항 또는 제6항에 있어서, 제4항에 따른 경우, 상기 제1 및/또는 제2 조건의 상기 보완은 상기 제1 또는 제2조건이 각각 충족될 수 없는 저장된 전체 시퀀스에 기초하여 발생하는, 방법."}
{"patent_id": "10-2023-7019741", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "선행 항들 중 어느 한 항에 있어서, 상기 전체 시스템은 투영 레벨을 포함하고 상기 제1 및/또는 제2 상황 데이터의 상기 형성은 상기 투영 레벨에 의해 수행되는, 방법."}
{"patent_id": "10-2023-7019741", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "선행 항들 중 어느 한 항에 있어서, 상기 제2 분류는 상기 제1 분류의 적어도 하나의 클래스를 복수의 하위 클래스로 분류하고, 및/또는 상기 제1 조건 중 적어도 하나에 대해 상기 하나의 제1 조건은 복수의 상기 제2 조건에 의해 암시되는, 방법."}
{"patent_id": "10-2023-7019741", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "선행 항들 중 어느 한 항에 있어서, 상기 제1 조건은 규칙의 형식으로 제공되고 상기 제2 조건은 규칙 분류의형식으로 제공되고; 각각의 규칙은 상기 각 규칙의, 특히 여러 레벨로의 세분화를 나타내는 규칙 분류가 지정되고; 바람직하게는 상기 규칙 및 상기 규칙 분류가 저장되는 메모리가 제공되고; 더 바람직하게는 상기 규칙 분류는 블록체인을 통해 연결되는 레벨로 세분되며, 상기 규칙 및/또는 규칙 분류는 스마트 계약의 형태로 구현되고; 및/또는 제5항에 따른 경우, 상기 제2 조건을 보완할 때 상기 세분화의 추가 레벨이 추가되는, 방법."}
{"patent_id": "10-2023-7019741", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "선행 항들 중 어느 한 항에 있어서, 상기 작업 레벨은 단계 a)에서 상기 제1 출력 값의 상기 결정은 더 짧은 시간을 필요로 하고 단계 e)에서 상기 제2 출력 값의 상기 결정은 더 긴 시간을 필요로 하도록 설계되고; 및/또는상기 평가 레벨은 단계 c)에서 상기 제1 평가의 상기 결정이 더 짧은 시간을 필요로 하고 단계 g)에서 상기 제2평가의 상기 결정이 더 긴 시간을 필요로 하도록 설계되고; 바람직하게는 두 경우 모두 서로 독립적으로 상기더 긴 기간은 상기 더 짧은 기간보다 적어도 2배, 특히 적어도 5배 더 긴, 방법."}
{"patent_id": "10-2023-7019741", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "선행 항들 중 어느 한 항에 있어서, 상기 제1 및 제2 입력 값은 시간 연속 입력 신호 또는 시간 이산 시계열로제공되며, 바람직하게는 상기 제1 및 제2 입력 값은 전체적으로 또는 부분적으로 동일한, 방법."}
{"patent_id": "10-2023-7019741", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "선행 항들 중 어느 한 항에 있어서, 작업 평면은 제1 및 제2 인공 학습 작업 유닛(810, 820)을 포함하고; 상기 제1 인공 학습 작업 유닛(810)은 상공개특허 10-2023-0108293-4-기 제1 입력 값(Xi(t1))을 수신하고 상기 제1 출력 값을 결정하도록 적응되고; 상기 제2 인공 학습 작업 유닛(820)은 상기 제2 입력 값(Xi(t2))을 수신하고 상기 제2 출력 값을 결정하도록 적응되고; 상기 작업 레벨에서하나 이상의 제1 변조 함수(fmod1_f, fmod2_w)는 제1 출력 값 및/또는 그로부터 도출된 값에 기초하여 형성되고, 상기 형성된 하나 이상의 제1 변조 함수는 상기 제2 인공 학습 작업 유닛(820)의 하나 이상의 매개변수(foutA2,faktA2, ftransA2, wiA2)에 적용되고, 상기 하나 이상의 매개변수는 상기 제2 인공 학습 작업 유닛에서 상기 입력 값의 처리 및 상기 출력 값의 획득에 영향을 미치는, 방법."}
{"patent_id": "10-2023-7019741", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제13항에 있어서, 하나 이상의 제2 변조 함수(fmod2_f, fmod2_w)는 상기 제1 평가 및/또는 그로부터 도출된 값에 기초하여 형성되고, 상기 형성된 하나 이상의 제2 변조 함수는 상기 제1 인공 학습 작업 유닛(810)의 하나 이상의매개변수(foutA1, faktA1, ftransA1, wiA1)에 적용하고, 상기 하나 이상의 매개변수는 상기 제1 인공 학습 작업 유닛에서 상기 입력 값의 처리 및 상기 출력 값의 획득에 영향을 미치는, 방법."}
{"patent_id": "10-2023-7019741", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제13항 또는 제14항에 있어서, 상기 제1 평가 및/또는 그로부터 도출된 값은 상기 제1 인공 학습 작업 유닛(810)의 평가 입력 값으로 사용되고; 및/또는상기 제2 평가 및/또는 그로부터 도출된 값은 상기 제2 인공 학습 작업 유닛(820)의 평가 입력 값으로사용되는, 방법."}
{"patent_id": "10-2023-7019741", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "선행 항들 중 어느 한 항에 있어서, 상기 평가 레벨은 제1 및 제2 인공 학습 평가 유닛(830, 840)을 포함하고;상기 제1 인공 학습 평가 유닛(830)은 상기 제1 상황 데이터(Y(t3))를 수신하고 상기 제1 평가를 결정하도록 배열되고; 상기 제2 인공 학습 평가 유닛(840)은 상기 제2 상황 데이터(Y(t4))를 수신하고 상기 제2 평가를 결정하도록 배열되고; 상기 평가 레벨에서 하나 이상의 제3 변조 함수(fmod3_f, fmod3_w)는 상기 제1 평가 및/또는 그로부터 도출된 값에기초하여 형성되고, 상기 형성된 하나 이상의 제2 변조 함수는 상기 제2 인공 학습 평가 유닛(840)의 하나 이상의 매개변수(foutB2, faktB2, ftransB2, wiB2)에 적용되고, 상기 하나 이상의 매개변수는 상기 제2 인공 학습 평가 유닛에서 상기 입력 값의 처리 및 상기 출력 값의 획득에 영향을 미치는, 방법."}
{"patent_id": "10-2023-7019741", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제16항에 있어서, 상기 제1 평가 유닛의 입력 값 및 연관된 제1 평가를 포함하는 제1 평가 세트의 제1 평가 시퀀스를 제1 시퀀스메모리에 저장하는 단계 - 상기 제1 평가 세트에는 특히 각각의 시간 정보 및/또는 번호가 제공됨 - ; 및/또는상기 제2 평가 유닛의 입력 값 및 연관된 제2 평가를 포함하는 제2 평가 세트의 제2 평가 시퀀스를 제2 시퀀스메모리(832)에 저장하는 단계 - 상기 제2 평가 세트에는 특히 각각의 시간 정보 및/또는 번호가 제공됨 - ;바람직하게 상기 제1 및/또는 상기 제2 평가의 결정은 상기 저장된 제1 또는 제2 평가 시퀀스를 고려하여 수행되는, 방법."}
{"patent_id": "10-2023-7019741", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "선행 항들 중 어느 한 항에 있어서, 제4항 또는 제17항에 따른 경우, 상기 저장은 암호학적으로 안전한 형태로이루어지며; 바람직하게는 각각 하나의 블록체인이 사용되며, 상기 각 블록체인의 블록은 각각 상기 제1 평가세트, 상기 제2 평가 세트 및 상기 전체 세트 중 적어도 하나를 포함하는, 방법."}
{"patent_id": "10-2023-7019741", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "선행 항들 중 어느 한 항에 있어서, 공개특허 10-2023-0108293-5-다른 시스템으로부터 출력 값을 수신하는 단계;상기 수신된 출력 값으로부터 제1 및/또는 제2 상황 데이터를 형성하는 단계;상기 수신된 출력 값으로부터 형성된 상기 제1 또는 제2 상황 데이터에 기초하여 상기 평가 레벨별로 제1 및/또는 제2 평가를 결정하는 단계; 및상기 결정된 제1 및/또는 제2 평가가 상기 제1 또는 제2 조건이 각각 충족되는 것을 나타내는 경우 상기 다른시스템이 호환 가능하다고 결정하는 단계를 포함하는, 방법."}
{"patent_id": "10-2023-7019741", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "작업 레벨(710) 및 평가 레벨(730)을 포함하고 선행 항들 중 어느 한 항에 따른 방법을 수행하도록 배열된 기계의 제어기 내의 시스템에 있어서,상기 작업 레벨은 상기 입력 값을 수신하도록 구성되며 바람직하게는 상기 평가 레벨은 상기 입력 값을 수신할수 없는, 시스템."}
{"patent_id": "10-2023-7019741", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_21", "content": "제20항에 있어서, 상기 작업 레벨 및 상기 평가 레벨은 각각 적어도 하나의 컴퓨팅 유닛에서 구현되는, 시스템."}
{"patent_id": "10-2023-7019741", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_22", "content": "제21항에 있어서, 상기 작업 레벨이 구현되는 상기 적어도 하나의 컴퓨팅 유닛은 상기 평가 레벨이 구현되는 상기 적어도 하나의 컴퓨팅 유닛과 상이하고, 특히 개별적인, 시스템."}
{"patent_id": "10-2023-7019741", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_23", "content": "제20항 내지 제22항 중 어느 한 항에 있어서, 투영 레벨 및/또는 전체 시퀀스 메모리(760, 860)를 더 포함하는,시스템."}
{"patent_id": "10-2023-7019741", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_24", "content": "제20항 내지 제23항 중 어느 한 항에 있어서, 상기 작업 레벨은 제1 및 제2 인공 학습 작업 유닛(810, 820)을포함하고, 상기 평가 레벨은 제1 및 제2 인공 학습 평가 유닛(830, 840)을 포함하고; 상기 인공적으로 학습하는작업 유닛 및/또는 평가 유닛은 바람직하게는 각각 복수의 노드를 갖는 신경망을 포함하고, 더 바람직하게는 상기 하나 이상의 매개변수(들)은 각각 상기 신경망의 노드에 대한 가중치, 노드의 활성화 함수, 노드의 출력 함수, 노드의 전파 함수 중 적어도 하나인, 시스템."}
{"patent_id": "10-2023-7019741", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_25", "content": "제24항에 있어서, 상기 제1 및 제2 인공 학습 평가 유닛은 제1 및/또는 제2 컴퓨팅 유닛에서 하드웨어 및/또는컴퓨터 프로그램으로 구현 및/또는 실행되며, 상기 제1 및 제2 컴퓨팅 유닛은 제1 인터페이스에 의해 상호접속되고; 제13항에 따른 경우, 상기 제1 인터페이스는 상기 하나 이상의 제1 변조 함수를 형성하도록 배열되고; 및/또는상기 제1 및 제2 인공 학습 평가 유닛은 제3 및/또는 제4 컴퓨팅 유닛에서 하드웨어 및/또는 컴퓨터 프로그램으로 구현 및/또는 실행되고, 상기 제3 및 제4 컴퓨팅 유닛은 제3 인터페이스에 의해 상호 연결되고; 제16항에 따른 경우, 상기 제3 인터페이스는 상기 하나 이상의 제3 변조 함수를 형성하도록 배열되고; 및/또는상기 제3 컴퓨팅 유닛과 상기 제1 컴퓨팅 유닛은 제2 인터페이스에 의해 상호접속되며; 제14항에 따른 경우, 상기 제2 인터페이스는 상기 하나 이상의 제2 변조 함수를 형성하도록 배열되는, 시스템."}
{"patent_id": "10-2023-7019741", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_26", "content": "제25항에 있어서, 적어도 하나의, 바람직하게는 모든 컴퓨팅 유닛은 상기 각각의 컴퓨팅 유닛에 연결되거나 포함된 메모리가 할당되고; 바람직하게는 상기 제1 컴퓨팅 유닛에 할당된 상기 메모리는 상기 제1 분류를 저장하도록 배열되고, 및/또는 상기 제2 컴퓨팅 유닛에 할당된 메모리는 상기 제2 분류를 저장하도록 배열되며, 및/또공개특허 10-2023-0108293-6-는 상기 제3 컴퓨팅 유닛에 할당된 상기 메모리는 상기 제1 조건을 저장하도록 구성되고, 및/또는 상기 제4 컴퓨팅 유닛에 할당된 상기 메모리는 상기 제2 조건을 저장하도록 구성되는, 시스템."}
{"patent_id": "10-2023-7019741", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 작업 레벨 및 평가 레벨을 갖는 전체 시스템에서 입력값을 처리하기 위한 기계의 제어 시스템에서 구 현되는 방법에 관한 것으로, 작업 레벨에 제1 입력 값을 입력하고 제1 출력 값을 결정하는 단계; 제1 상황 데이 터를 형성하는 단계; 상기 제1 상황 데이터를 상기 평가 등급에 입력하고 상기 제1 상황 데이터가 미리 결정된 (뒷면에 계속)"}
{"patent_id": "10-2023-7019741", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 인공 학습 시스템인 작업 레벨과 평가 레벨을 포함하는 전체 시스템에 관한 것으로, 특히 기계의 제 어 시스템에서 입력 값을 처리하기 위해 내부에서 구현되는 방법에 관한 것이다."}
{"patent_id": "10-2023-7019741", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "인공 지능은 이제 수많은 애플리케이션에서 점점 더 많은 역할을 하고 있다. 이것은 처음에는 지능형 행동 및 기계 학습의 자동화를 의미하는 것으로 이해되었다. 그러나, 이러한 시스템은 일반적으로 특수 작업을 위해 고 안되고 훈련된다. 이러한 형태의 인공 지능(AI)은 종종 \"약한 AI\"라고 불리며 본질적으로 고정된 영역에서 지능 형 동작을 시뮬레이션하기 위한 계산 및 알고리즘의 적용을 기반으로 한다. 예로는 차량의 안전 시스템과 같은 특정 패턴을 인식할 수 있거나 체스와 같은 특정 규칙을 학습하고 구현할 수 있는 시스템이 있다. 동시에, 이러 한 시스템은 본질적으로 다른 영역에서는 쓸모가 없으며 다른 애플리케이션에 대해 완전히 재훈련되거나 완전히 다른 접근 방식을 사용하여 훈련되어야 한다. 무엇보다도 신경망은 이러한 인공/인공 학습 유닛의 실제 구현에 사용된다. 원칙적으로, 이러한 신경망은 추상 적 레벨에서 생물학적 뉴런의 기능을 복제한다. 서로 연결되어 신호를 수신, 처리 및 다른 노드로 전송할 수 있 는 여러 개의 인공 뉴런 또는 노드가 있다. 각 노드에 대해, 함수, 가중치 및 임계값이 정의되고, 이들은 예를 들어 신호가 노드에 전달되는지 여부와 전달되는 강도를 결정한다. 일반적으로, 노드는 계층으로 간주되므로, 각 신경망에는 적어도 하나의 출력 계층이 있다. 그 전에, 추가 계층 이 소위 숨겨진 계층으로 존재할 수 있으므로 다계층 신경망이 형성된다. 입력 값 또는 기능도 계층로 간주할 수 있다. 서로 다른 계층의 노드 사이의 연결을 에지라고 하며 일반적으로 고정된 처리 방향이 지정된다. 신경 망 토폴로지에 따라 어떤 계층의 노드가 다음 계층의 어떤 노드에 연결되는지 지정할 수 있다. 이 경우, 모든 노드가 연결될 수 있지만, 예를 들어 학습된 가중치 값이 0이라는 것은 특정 노드를 통해 더 이상 신호를 처리 할 수 없다는 것을 의미한다. 신경망에서의 신호 처리는 다양한 함수로 설명될 수 있다. 이하, 신경망의 단일 뉴런 또는 노드에 대해 이 원리 를 설명한다. 노드에 도달하는 여러 가지 입력 값에서 신경망 입력은 전파 함수 (또한 입력 함수)에 의해 형성 된다. 종종 이 전파 함수는 단순 가중 합으로 구성되고, 이로써 각 입력 값에 대해 연관된 가중이 지정된다. 그 러나 원칙적으로 다른 전파 함수도 가능한다. 가중치는 신경망에 대한 가중치 행렬로 지정할 수 있다. 이렇게 형성된 노드의 신경망 입력에는 임계값에 따라 달라질 수 있는 활성화 함수가 적용된다. 이 함수는 신경 망 입력과 뉴런의 활동 레벨 간의 관계를 나타낸다. 다양한 활성화 함수가 알려져 있는데, 예를 들어 출력이 임 계값 미만에서는 0이고 임계값 초과에서는 항등식인 단순 이진 임계값 함수; 시그모이드 함수; 또는 주어진 기 울기가 있는 조각별 선형 함수. 이러한 함수는 신경망을 설계할 때 지정된다. 활성화 함수의 결과는 활성화 상 태를 형성한다. 선택적으로 활성화 함수의 출력에 적용되어 노드의 최종 출력 값을 결정하는 추가 출력 함수를 지정할 수 있다. 그러나 종종 활성화 함수의 결과는 단순히 출력 값으로 직접 전달되고, ID가 출력 함수로 사용 된다. 사용된 명명법에 따라 활성화 함수와 출력 함수를 전달 함수로 결합할 수도 있다. 각 노드의 출력 값은 신경망의 다음 계층에 계층의 각 노드에 대한 입력 값으로 전달되고, 여기에서 해당 단계 는 노드의 각 함수 및 가중치로 처리하기 위해 반복된다. 네트워크의 토폴로지에 따라, 또한 이전 계층으로 또 는 다시 출력 계층으로 역방향 에지가 있을 수 있으므로, 결과적으로 순환 네트워크가 생성된다. 반면에, 입력 값에 각각 가중치 부여된 가중치는 네트워크에 의해 변경될 수 있으므로 신경망의 \"학습\"으로 간 주되는 전체 네트워크의 출력 값과 기능을 조정할 수 있다. 이 목적을 위해, 오류 역전파가 일반적으로 네트워 크에서 사용되는데, 즉, 출력 값을 예상 값과 비교하고 이 비교를 사용하여 오류를 최소화하기 위해 입력 값을 조정한다. 오류 피드백을 통해, 네트워크의 다양한 매개변수, 예를 들어, 노드에서의 입력 값의 가중치 또는 계 단 크기(학습률)가 적절하게 조정될 수 있다. 마찬가지로, 입력 값이 재평가될 수도 있다. 그런 다음 훈련 모드에서 네트워크를 훈련할 수 있다. 사용된 학습 전략은 또한 신경망의 가능한 적용에 결정적 이다. 특히 다음 변형이 구별된다. 감독 학습에서, 입력 패턴 또는 학습 데이터 세트가 제공되고 네트워크의 출력이 예상 값과 비교된다. 비지도 학습은 상관관계나 규칙을 찾는 일을 시스템에 맡기므로, 학습할 패턴만이 지정된다. 중간 변형은 준지도 학습 으로, 이 때 미리 정의된 분류가 없는 데이터 세트가 또한 사용될 수 있다. 강화학습이나 Q 학습에서, 행동에 대한 보상과 처벌을 받을 수 있는 에이전트가 생성되고, 이를 기반으로 받은 보상을 최대화하여 행동을 조정한 다. 신경망의 중요한 애플리케이션은 입력 데이터 또는 입력을 특정 범주 또는 클래스로 분류하는 것, 즉, 상관 관 계 및 할당의 인식이다. 클래스는 알려진 데이터를 기반으로 훈련될 수 있고 적어도 부분적으로 미리 정의되거 나 네트워크에 의해 독립적으로 개발되거나 학습될 수 있다. 이러한 신경망의 기본 기능 및 추가 세부 사항은 예를 들어 R. Schwaiger, J. Steinwender, Neuronale Netze programmieren mit Python, Rheinwerk Computing, Bonn 2019의 해당 주제에 알려져 있다. 단 하나의 특수 작업에 대해 훈련되지 않은 보편적으로 적용 가능한 AI 시스템은 다차원 또는 고차원 공간으로 이어지고 따라서 기하급수적으로 증가하는 훈련 및 테스트 데이터 세트가 필요하다. 따라서 실시간 응답이 빠르 게 불가능해진다. 따라서 일반적으로 이러한 시스템의 차원과 복잡성을 줄이려는 시도가 이루어진다. 이 문제를 해결하기 위한 다양한 접근 방식이 추구되고 있다. 예를 들어, 복잡성은 데이터 세트를 연결하고 자유도를 줄이 거나 알려진 지식을 시스템에 공급하여 줄일 수 있다. 또 다른 접근법은 예를 들어 원리 성분 분석(Principal Component Analysis)과 같은 방법을 사용하여 적어도 부분적으로 상관 데이터 또는 상호 종속 데이터 세트를 분 리하는 것이다. 특성에 필터링 방법을 적용하여, 예를 들어 카이제곱 테스트 등의 통계적 테스트를 적용하여 신 경망을 훈련시킬 때 눈에 띄지 않거나 부정적으로 눈에 띄는 데이터를 제거할 수 있다. 마지막으로 훈련 데이터 자체의 선택은 AI 네트워크에서 최적화 문제로 행해질 수 있다. 이 경우, 훈련 데이터는 가능한 한 빠르고 효과 적으로 새로운 네트워크를 훈련할 수 있는 방식으로 결합된다. 보다 진보된 접근 방식에는 단순한 행렬 변환 대신 완전히 연결된 다층 네트워크의 적어도 하나의 계층에 컨벌 루션을 적용하는 소위 \"컨볼루션 신경망\"이 포함된다. 예를 들어, 소위 \"딥 드립(deep-dream)\" 방법은 특히 이 미지 인식 분야에서 알려져 있으며, 여기서 훈련된 네트워크의 가중치는 최적으로 유지되지만, 대신에 입력 값 (예: 입력 이미지)은 출력 값에 따라 피드백 루프로 수정된다. 예를 들어, 이러한 방식으로 시스템이 식별한다 고 믿는 것이 희미해진다. 이 이름은 과정에서 드림과 같은 이미지가 만들어진다는 사실과 관련된다. 이러한 방 식으로 신경망의 내부 프로세스와 그 방향을 추적할 수 있다. 이러한 방법은 여전히 인간 지능과 큰 차이를 보인다는 것은 명백하다. 데이터베이스, 텍스트 파일, 이미지 및 오디오 파일은 원칙적으로 사실, 언어, 음성 논리, 사운드, 이미지 및 이벤트 시퀀스가 뇌에서 저장되고 처리되 는 방식과 비교할 수 있지만, 인간의 지능은 예를 들어, 감정과 무의식적인 \"소프트\" 분류의 맥락에서 이 모든 데이터를 연결한다는 점에서 크게 다르다."}
{"patent_id": "10-2023-7019741", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명에 따르면, 기계의 제어 시스템에서 인공 학습 시스템인 작업 레벨과 평가 레벨을 갖는 전체 시스템에서 입력 값을 처리하기 위해 수행되는 방법, 및 독립항의 특징을 갖는 대응 시스템이 제안된다. 바람직한 실시 예 는 종속항 및 다음 설명의 대상이다."}
{"patent_id": "10-2023-7019741", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "인공 학습 시스템인, 작업 레벨과 평가 레벨을 갖는 전체 시스템에서 하나 이상의 센서에 의해 감지된 센서 데 이터(또는 값 또는 측정 값)를 포함하는 입력 값을 처리하기 위해, 기계의 제어 시스템에서 실행되는 방법(또는 방법들)은, a) 제1 분류에 따라, 제1 입력 값을 상기 작업 레벨에 입력하고 상기 작업 레벨에 의해 상기 제1 입력 값으로부 터 제1 출력 값을 결정하는 단계; b) 상기 제1 출력 값을 기초로 제1 상황 데이터를 형성하는 단계; c) 상기 제1 상황 데이터를 상기 평가 레벨에 입력하여 상기 제1 상황 데이터가 소정의 초기 조건을 충족하는지 여부 또는 어느 정도를 충족하는지를 나타내는 초기 평가를 상기 평가 레벨에 의해 결정하는 단계; d) 제1 평가에 기초하여 상기 작업 레벨에서 상기 제1 출력 값의 상기 결정에 영향을 미치는 단계; 단계 a) - d)를 반복적으로 수행하는 단계; e) 제2 분류에 따라, 제2 입력 값을 상기 작업 레벨에 입력하고 상기 작업 레벨에 의해 상기 제2 입력 값으로부 터 제2 출력 값을 결정하는 단계 - 상기 제2 출력 값의 상기 결정은 상기 제1 출력 값에 의해 영향을 받음 - ; f) 상기 제2 출력 값에 기초하여 제2 상황 데이터를 형성하는 단계; g) 상기 제2 상황 데이터를 상기 평가 레벨에 입력하고 제2 상황 데이터가 미리 결정된 제2 조건을 충족하는지 또는 어느 정도를 충족하는지를 나타내는 제2 평가를 상기 평가 레벨에 의해 결정하는 단계 - 상기 제2 평가의 상기 결정은 상기 제1 평가에 의해 영향을 받음 - ; h) 상기 제2 평가에 기초하여 상기 작업 레벨에서 상기 제2 출력 값의 상기 결정에 영향을 미치는 단계; 단계 e) - h)를 반복적으로 수행하는 단계를 포함하고, 상기 제1 및/또는 제2 출력 값은 상기 전체 시스템의 전체 출력 값으로 사용되며, 상기 전체 출력 값은 상기 기 계의 제어 매개변수 및/또는 상태 매개변수로 사용된다. 특히, 이 애플리케이션의 의미 내에서 \"인공 학습 시스템\"은 서로 결합된 2개(또는 그 이상)의 인공 학습 유닛 을 포함할 수 있으며, 참조 도 1 내지 6의 설명을 참조한다. \"인공 학습 유닛\"은 기계 학습 기반 알고리즘을 구 현하는 유닛, 예를 들어 인공 신경망으로 간주될 수 있다. 기계 학습 기반 알고리즘은 출력 값의 형태로 출력되 는 입력 값을 기반으로 예측 또는 결정을 내리는 모델을 구축하기 위해 학습 데이터를 사용하여 학습할 수 있다. 작업 레벨과 평가 레벨의 인공 학습 유닛은 각각 제1/제2 입력 값에서 제1/제2 출력 값을 획득하고, 제1/ 제2 상황 데이터에서 제1/제2 평가를 획득하도록 훈련될 수 있다. 특히 인공 학습 시스템 내에서 인공 학습 유 닛의 결합이 구현된다. 제1 유닛 또는 그 출력 값이 제2 유닛 또는 그 입력 값 처리에 영향을 주지만 제2 유닛 은 제1 유닛에 영향을 미치지 않는 방식이다. 인공 학습 시스템 또는 유닛은 컴퓨팅 유닛(예를 들어, 프로세서, 컴퓨터, 서버 시스템 또는 가속기 카드)에서 실행되는 컴퓨터 프로그램으로 구현될 수 있다. 인공 학습 시스템 또는 유닛은 또한 적어도 부분적으로는 하드 웨어로, 예를 들어, FPGA(필드 프로그래머블 게이트 어레이)로 구현될 수 있다. 특히, 서로 다른 컴퓨팅 장치에 서도 실행될 수 있는 상호 연결된 인공 학습 장치를 통해 인공 학습 시스템을 구현하는 것도 가능한다. 기계는 예를 들어 산업 기계, 산업 플랜트(상호작용 기계의 시스템), 이동식 작업 기계 및/또는 차량, 특히 자 율 또는 반자율 차량일 수 있다. 제어 시스템은 (예를 들어, 기계의 하나 이상의 제어 장치에서) 하나 이상의 제어 장치 또는 컴퓨팅 장치를 포함할 수 있다. 특히, 작업 수준과 평가 수준이 서로 분리된 서로 다른 컴퓨팅 유닛 (예를 들어, 서로 다른 제어 장치)에서 구현된다고 생각할 수 있다. 각 제어 장치 또는 컴퓨팅 장치는 하 나 이상의 프로세서, 휘발성 메모리, 비휘발성 메모리, 통신 인터페이스(센서, 기계 부품, 다른 제어 장치 또는 외부 장치와의 데이터 통신용) 등을 포함할 수 있다. 하드웨어 가속기 요소(AI 가속기, 인공 학습 시스템 또는 인공 학습 유닛의 가속 평가 컴퓨팅 단계용)도 제어 장치에 제공될 수 있다. 특히, 비휘발성 메모리에 있어서, 방법이 구현되는 프로그램 및/또는 방법 구현 중에 발생하는 데이터가 저장되거나 저장될 수 있다. 한편, 기계 또는 기계의 구성 요소의 속성 또는 변수를 결정하거나 측정하는 센서(가급적 기계에 장착됨), 예를 들어, 예를 들어 압력 센서(예를 들어, 유압 유체의 압력 결정), 전류 및/또는 전압 센서(예를 들어, 전기 작동 액추에이터 또는 전기 모터/발전기), 온도 센서, 속도 센서, 회전 속도 센서, 광 센서, 위치 센서, 액추에이터 의 위치를 결정하는 센서 등이 제공될 수 있다. 한편, 부가적으로 또는 대안적으로, 기계의 환경에 영향을 미치 는 특성 또는 양을 결정하거나 측정하는 센서(가급적 기계에 있음), 예를 들어 카메라, 레이더, 라이더 또는 적 외선 센서, 마이크 등이 제공될 수 있다. 센서 데이터 외에도, 입력 값에는 다른 데이터 또는 값, 예를 들어 사 용자 입력, 다른 장치에서 전송된 데이터, 요청 또는 사양, 제어 매개변수 또는 상태 매개변수의 이전 값 등을 포함할 수도 있다. \"제어 매개변수\"라는 용어는 기계를 제어하는 데 사용되는 매개변수 또는 수량, 예를 들어 기계의 구성 요소가 제어되는 매개 변수/수량을 의미한다. \"상태 매개변수\"라는 용어는 기계의 상태를 나타내는 매개변수, 예를 들 어 가능한 다양한 평가 상태 중 어떤 것이 존재하는지, 위험 상태가 존재하는지 여부, 또는 기계가 올바르게 작 동하는지 또는 결함 상태가 존재하는지 여부를 의미한다.제1 또는 제2 평가에 의한 제1 또는 제2 출력 값 결정의 영향(단계 d) 또는 h))은 제1 또는 제2 입력 값에서 제 1 또는 제2 출력 값의 결정의 각 다음 반복, 즉 단계 a)-d) 또는 e)-h)의 다음 반복을 나타낸다. 제1 반복에서, 특히 제1 또는 제2 출력 값의 결정은 아직 영향을 받지 않는다. 이는 예를 들어, 중립적인 제1 또는 제2 평가로 초기화하여 실현될 수 있다. 입력 값은 a)-d) 또는 e)-h) 단계를 반복하는 동안 일정하게 유지되거나 가변적일 수 있고, 이에 의해 둘 다 동 시에 사용하는 것도 가능하다. 예를 들어, 상대적으로 높은 비율로 결정된 센서 데이터(측정값)는 예를 들어 전 류 강도, 전압, 온도 또는 속도 센서의 반복 중에 적어도 약간 변경될 수 있다. 큰 변경의 경우, 예를 들어, 미 리 결정된 임계값보다 큰 경우, 새로운 상황의 존재를 가정할 수 있다(새로운 상황이 있는 경우 제1 출력 값을 먼저 총 출력 값으로 사용할 수 있으며, 예를 들어 특정 시간이 지난 후 또는 다른 조건이 충족되면 제2 출력 값을 총 출력 값으로 사용할 수 있다). 예를 들어, 카메라의 다른 센서 데이터는 다시 일정하게 유지될 수 있어, 상대적으로 낮은 속도(예를 들어, 30, 60 또는 < 100Hz)에서 캡처된 캡처 이미지를 평가한다. 이 경우, 이 낮은 비율에 따라 반복에 최대로 사용할 수 있는 (제1/제2) 시간 범위를 선택할 수 있다. 예를 들어, 약 33ms의 두 개의 연속적인 이미지 사이의 시간 간격에 해당하는 30Hz의 주파수로 이미지를 캡처하는 경우, 시간 범위는 33ms보다 작게 선택할 수 있다. 새로 캡처된 이미지가 각 시간 범위에서 평가되도록 30ms이다. 더 높은 주파수에서 동시에 취득한 데이터를 입력 값으로 사용하면, 이들은 이 시간 범위(예: 30ms) 동안 변경될 수 있 다. 이 때 이 변화가 상대적으로 적으므로, 근본적으로 새로운 상황이 발생하지 않는다고 가정한다. 특히, 입력 값은 또한 시간 종속적일 수 있으며, 예를 들어 입력 값은 샘플링된 신호의 시계열일 수 있다. 그러 므로 이러한 시간 종속성으로 인해 제2 작업 유닛에 입력된 입력 값은 (이전에) 제1 작업 유닛에 입력된 입력 값과 (현재에서) 상이하고, 또는 방법의 추가 과정에서, 입력 값이 하나의 작업 유닛에 의해 반복적으로 사용될 때 이 하나의 작업 유닛은 상이한 현재 입력 값을 처리하는 것이 가능하다. 그러나 단순화를 위해서, 시간 종속 성을 명시적으로 언급하지 않고 항상 \"입력 값\"을 참조한다. 제1 또는 제2 조건은 순전히 기술적 특성일 수 있다. 예를 들어, 방법이 기계 제어 시스템에서 사용되고 총 출 력 값이 예를 들어, 모터의 제어 매개변수를 나타내는 경우, 한 가지 조건은 제어 매개변수가 기술적으로 지정 된 범위 내에, 예를 들어 제어 모터의 최대 속도 이하에 있어야 한다는 것이다. 특히, 조건은 또한 적어도 부분적으로는 비기술적 성격일 수 있다. 이것은 도덕 윤리적 측면이나 경제적 측면과 관련될 수 있다. 도덕 윤리적 측면은 예를 들어 인공 학습 시스템이 제어 시스템으로 사용되는 자율 주행 차량과 관련이 있다. 예를 들어, 이 제어 시스템이 예를 들어 자율 주행 차량이 캡처하고 제어 시스템에서 평가한 카메라 이미지 또 는 라이다 이미지를 기반으로, 조향 보정 없이 풀 브레이킹을 해도 다른 차량과의 충돌을 더 이상 피할 수 없다 고 결정하면, 충돌을 피할 수 있는 다양한 조향 보정을 결정한다. 예를 들어 가능한 조향 보정 중 하나는 보행 자를 위험에 빠뜨릴 수 있는 반면, 다른 가능한 조향 수정은 벽과의 충돌로 이어질 수 있다. 제1 조건 중 하나 는 인간의 생명이 직접적으로 위험하지 않아야 한다는 것일 수 있으며, 이 조건으로 인해 보행자의 위험을 초래 하는 조향 움직임이 다른 솔루션에 비해 배제되거나 억제될 수 있다. 이러한 기본 평가는 제1 평가와 제1 출력 값의 상호 작용을 초래할 수 있다. 예를 들어 다른 차량과 탑승자를 위험에 빠뜨리는 행위는 피해야 하기 때문 에, 도덕 윤리적 측면도 이 예의 나머지 두 가지 옵션에서 역할을 할 수 있다(조향 보정 없음 및 상대 차량과의 충돌; 조향 보정 및 벽과의 충돌). 이것은 이 예에서, 예를 들어, 제2 출력 값의 기반이 되는 보다 자세한 분석 을 위해, 가능한 제2 조건이다. 이 예에서, 제1 조건은 절대적 고려 사항을 나타내는 반면, 제2 조건은 상대적 고려 사항을 나타낸다. 이러한 도덕 윤리적 또는 경제적 고려 사항은 적절한 방식으로 조건으로: 예를 들어 자동 실행 프로그램의 형 태로 특정 트레이드 오프를 수행하는 계약으로 성문화될 수 있다. 이런 의미에서 조건은 말하자면 도덕적 계약 을 구성한다. 조건은 \"규범 코드\", 즉 노력해야 하지만 모든 경우에 달성할 수 없는 규칙이다. 따라서 조건은 모든 경우에 충 족되어야 하는 절대적인 조건이 아니다. 따라서 전체 산출량은 작업 수준에 따라 결정되며, 이에 의해 각 입력 값에 대한 평가 수준을 통해 작업 수준에 영향을 미침으로써 가능한 한 최상의 조건이 관찰되는 방식으로 전체 출력이 결정된다. 따라서 본 발명에 의하면 입력 값을 처리하기 위해 본 발명에 따른 방법에 의해 제어되거나 모니터링되는 기술 시스템에서 직접적인 기술적 특성이 아닌 측면을 고려하는 것이 가능하다. 경제적 고려 사항의 예는 생산 공장의 기계 제어에서 시스템을 사용하는 것이고, 한편으로는 가능한 한 많은 제 품을 가능한 한 빨리 생산해야 하지만(즉, 높은 수익을 창출해야 함), 다른 한편으로 이것은 더 높은 마모로 이 어진다. 따라서 원칙적으로 이것은 경제적 및 기술적 고려 사항이 혼합된 것이다. 바람직하게, 단계 a) - d)는 미리 결정된 제1 기간이 경과할 때까지 및/또는 상기 제1 출력 값이 미리 결정된 제1 허용 오차 내에서 연속적인 반복 사이에서 더 이상 변경되지 않을 때까지 및/또는 상기 제1 평가가 상기 제 1 조건이 적어도 어느 정도 충족되는 것을 나타낼 때까지 반복적으로 수행되고; 바람직하게 상기 제1 출력 값은 이 반복 수행이 완료될 때 전체 출력 값으로 사용된다. 바람직하게, 단계 e) - h)는 미리 결정된 제2 기간이 경과할 때까지 및/또는 상기 제2 출력 값은 미리 결정된 제2 허용 오차 내에서 연속적인 반복 사이에서 더 이상 변경되지 않을 때까지 및/또는 상기 제2 평가가 상기 제 2 조건이 적어도 어느 정도 충족되는 것을 나타낼 때까지 반복적으로 수행되고; 바람직하게 상기 제2 출력 값은 이 반복 수행이 완료될 때 전체 출력 값으로 사용된다. 바람직하게, 전체 시퀀스 메모리에, 각각이 상호 대응하는 입력 값 및/또는 제1 출력 값 및/또는 제1 상황 데이 터 및/또는 제1 평가 및/또는 제2 출력 값 및/또는 제2 상황 데이터 및/또는 제2 평가를 포함하는, 전체 레코드 의 전체 시퀀스를 저장하는 단계를 포함하고; 바람직하게 상기 전체 기록 및/또는 상기 전체 기록에 포함된 상 기 값 또는 데이터에는 각각의 시간 정보 및/또는 번호 지정이 제공된다. 바람직하게, 상기 방법은 상기 제1 및/또는 제2 조건을 보완하므로, 상기 보완 전에 상기 제1 및 제2 조건이 각 각 충족되지 않는 제1, 제2 상황 데이터에 대해, 상기 보완된 제1 및 제2 조건이 각각 충족되거나 적어도 어느 정도 충족되도록 하는 단계를 더 포함하고; 바람직하게 상기 제2 조건만 변경되고 상기 제1 조건은 변경되지 않 고 유지된다. 바람직하게, 상기 단계 e)-h)의 반복이 중단된 경우, 상기 제2 기간이 만료되었거나, 바람직하게는 상기 제2 출 력 값이 상기 제2 허용 오차 내에서 더 이상 변경되지 않기 때문에, 상기 제2 조건이 보완되어 중단시 존재하는 상기 상황 데이터가 상기 보완된 제2 조건을 충족한다. 바람직하게, 상기 제1 및/또는 제2 조건의 상기 완료 또는 보완은 상기 제1 또는 제2 조건이 충족될 수 없는 (또는 일정 정도로 충족될 수 없는) 저장된 전체 시퀀스에 기초하여 발생한다. 바람직하게, 상기 전체 시스템은 투영 레벨을 포함하고 상기 제1 및/또는 제2 상황 데이터의 상기 형성은 상기 투영 레벨에 의해 수행된다. 바람직하게, 상기 제2 분류는 상기 제1 분류의 적어도 하나의 클래스를 복수의 하위 클래스로 분류하고, 및/또 는 상기 제1 조건 중 적어도 하나에 대해 상기 하나의 제1 조건은 복수의 상기 제2 조건에 의해 암시된다. 바람직하게, 상기 제1 조건은 규칙의 형식으로 제공되고 상기 제2 조건은 규칙 분류의 형식으로 제공되고; 각각 의 규칙은 상기 각 규칙의, 특히 여러 레벨로의 세분화를 나타내는 규칙 분류가 지정되고; 바람직하게는 상기 규칙 및 상기 규칙 분류가 저장되는 메모리가 제공되고; 더 바람직하게는 상기 규칙 분류는 블록체인을 통해 연 결되는 레벨로 세분되며, 상기 규칙 및/또는 규칙 분류는 스마트 계약의 형태로 각 경우에 구현되고; 및/또는 필요하다면, 상기 제2 조건을 보완할 때 상기 세분화의 추가 레벨이 추가된다. 상기 작업 레벨은 바람직하게 단계 a)에서 상기 제1 출력 값의 상기 결정은 더 짧은 시간을 필요로 하고 단계 e)에서 상기 제2 출력 값의 상기 결정은 더 긴 시간을 필요로 하도록 설계되고; 및/또는 상기 평가 레벨은 단계 c)에서 상기 제1 평가의 상기 결정이 더 짧은 시간을 필요로 하고 단계 g)에서 상기 제2 평가의 상기 결정이 더 긴 시간을 필요로 하도록 설계되고; 두 경우 모두 각각의 경우에 상기 더 긴 기간은 바람직하게 상기 더 짧은 기간보다 적어도 2배, 특히 적어도 5배 더 길다. 바람직하게, 상기 제1 및 제2 입력 값은 연속적 시간 입력 신호 또는 이산 시간 시계열로 제공되며, 또한 바람 직하게는 상기 제1 및 제2 입력 값은 전체적으로 또는 부분적으로 동일하다. 작업 레벨은 바람직하게 제1 및 제2 인공 학습 작업 유닛을 포함하고; 상기 상기 제1 인공 학습 작업 유닛은 상 기 제1 입력 값을 수신하고 상기 제1 출력 값을 결정하도록 적응되고; 상기 제2 인공 학습 작업 유닛은 상기 제 2 입력 값을 수신하고 상기 제2 출력 값을 결정하도록 적응되고; 상기 작업 레벨에서 하나 이상의 제1 변조 함 수는 제1 출력 값 및/또는 그로부터 도출된 값에 기초하여 형성되고, 상기 형성된 하나 이상의 제1 변조 함수는 상기 제2 인공 학습 작업 유닛의 하나 이상의 매개변수에 적용되고, 상기 하나 이상의 매개변수는 상기 제2 인공 학습 작업 유닛에서 상기 입력 값의 처리 및 상기 출력 값의 획득에 영향을 미친다. 가장 간단한 경우, 상황 데이터는 예를 들어 각각의 출력 값 자체일 수 있다. 제1 및 제2 상황 데이터는 제1 및 제2 작업 유닛에 의해 형성되는 작업 레벨 내 지배력에 따라 형성될 수 있다. 즉. 제1 작업 유닛이 지배적인 경 우, 적어도 제1 작업 유닛의 제1 출력 값을 기준으로 제1 상황 데이터를 형성한다(예: 제1 작업 유닛의 출력 값 및/또는 그로부터 파생된 값을 상황 데이터로 사용); 반면에, 제2 작업 유닛이 지배적인 경우, 적어도 제2 작업 유닛을 기준으로 제2상황데이터를 형성한다 (예: 제2 작업 유닛의 출력 값 및/또는 여기서 파생된 값을 상황 데 이터로 사용). 바람직하게는, 제1 평가 및/또는 그로부터 유도된 값은 제1 인공 학습 작업 유닛의 평가 입력 값으로 사용되며; 하나 이상의 제2 변조 함수는 상기 제1 평가 및/또는 그로부터 도출된 값에 기초하여 형성되고, 상기 형성된 하 나 이상의 제2 변조 함수는 상기 제1인공 학습 작업 유닛의 하나 이상의 매개변수에 적용하고, 상기 하나 이상 의 매개변수는 상기 제1 인공 학습 작업 유닛에서 상기 입력 값의 처리 및 상기 출력 값의 획득에 영향을 미치 고, 상기 제2 평가 및/또는 그로부터 도출된 값은 상기 제2 인공 학습 작업 유닛의 평가 입력 값으로 사용된다. 평가 입력 값은 입력 값의 일부이며, 분석하고자 하는 입력 값에 대한 추가 입력 값이므로 그에 따라 제1 출력 값이 변경될 수 있다. a) 단계를 처음 실행하기 전, 입력 값이 크게 변경되어 새로운 상황이 있음을 나타내는 경우, 모든 제1 조건이 충족되었음을 나타내기 위해 제1 평가를 초기화할 수 있다. 상기 평가 계층은 바람직하게 제1 및 제2 인공 학습 평가 유닛을 포함하고; 상기 제1 인공 학습 평가 유닛은 상 기 제1 상황 데이터를 수신하고 상기 제1 평가를 결정하도록 배열되고; 상기 제2 인공 학습 평가 유닛은 상기 제2 상황 데이터를 수신하고 상기 제2 평가를 결정하도록 배열되고; 상기 평가 계층에서 하나 이상의 제3 변조 함수는 상기 제1 평가 및/또는 그로부터 도출된 값에 기초하여 형성되고, 상기 형성된 하나 이상의 제2 변조 함 수는 상기 제2 인공 학습 평가 유닛의 하나 이상의 매개변수에 적용되고, 상기 하나 이상의 매개변수는 상기 제 2 인공 학습 평가 유닛에서 상기 입력 값의 처리 및 상기 출력 값의 획득에 영향을 미친다. 상기 방법은 바람직하게, 상기 제1 평가 유닛의 입력 값 및 연관된 제1 평가를 포함하는 제1 평가 세트의 제1 평가 시퀀스를 제1 시퀀스 메모리에 저장하는 단계 - 상기 제1 평가 세트에는 특히 각각의 시간 정보 및/또는 번호가 제공됨 - ; 및/또는 상기 제2 평가 유닛의 입력 값 및 연관된 제2 평가를 포함하는 제2 평가 세트의 제2 평가 시퀀스를 제2 시퀀스 메모리에 저장하는 단계 - 상기 제2 평가 세트에는 특히 각각의 시간 정보 및/또는 번호가 제공됨 - ; 바람직하게 상기 제1 및/또는 상기 제2 평가의 결정은 상기 저장된 제1 또는 제2 평가 시퀀 스를 고려하여 수행된다. 제1/제2 평가 시퀀스를 저장하면 평가 유닛의 \"결정\"을 추적할 수 있으며, 필요한 경우, 예를 들어 원하는 대로 작동하지 않는 경우 평가 시퀀스를 사용하여 추가 훈련을 수행할 수 있다. 바람직하게, 저장은 암호화된 보안 형태로 수행되고, 이에 의해 바람직하게는 각 경우에 하나의 블록체인이 사 용되어, 각 블록체인의 블록은 제1 평가 기록, 제2 평가 기록 또는 전체 기록 중 적어도 하나를 포함한다. 바람직하게, 상기 방법은 다른 시스템으로부터 출력 값을 수신하는 단계; 상기 수신된 출력 값으로부터 제1 및/ 또는 제2 상황 데이터를 형성하는 단계; 상기 수신된 출력 값으로부터 형성된 상기 제1 또는 제2 상황 데이터에 기초하여 상기 평가 레벨별로 제1 및/또는 제2 평가를 결정하는 단계; 및 상기 결정된 제1 및/또는 제2 평가가 상기 제1 또는 제2 조건이 각각 충족되는 것을 나타내면 상기 다른 시스템이 호환 가능하다고 결정하는 단계를 포함한다. 평가 유닛이 일반적으로 다른 조건을 테스트하는 시스템은 이 시스템이 이들의 평가시 서로 모순되지 않는 경우, 즉, 시스템 중 하나가 조건에 따라 분류한 평가 유닛의 입력 값(상황 데이터)이 (다른) 조건의 측면에서 는 허용 불가능한 것으로 다른 시스템에 의해 분류되지 않은 경우 \"호환 가능\"이라고 하여, 특히 점진적 평가의 경우 적절한 허용 오차를 고려한다. 본 발명에 따른 시스템은 작업 레벨 및 평가 레벨을 포함하고 선행 항들 중 어느 한 항에 따른 방법을 수행하도 록 적응되고, 상기 작업 레벨은 상기 입력 값을 수신하도록 구성되며 바람직하게는 상기 평가 레벨은 상기 입력 값을 수신할 수 없다. 상기 작업 레벨 및 상기 평가 레벨은 각각 적어도 하나의 컴퓨팅 유닛에서 구현되고, 상기 작업 레벨이 구현되 는 상기 적어도 하나의 컴퓨팅 유닛은 상기 평가 레벨이 구현되는 상기 적어도 하나의 컴퓨팅 유닛과 바람직하 게 상이하고, 특히 개별적이다. 작업 레벨 또는 평가 레벨이 구현되는 적어도 하나의 컴퓨팅 유닛 각각이 여러개의 컴퓨팅 유닛을 포함하는 경우, 또한 각각의 컴퓨팅 시스템이라고도 한다. 각각의 적어도 하나의 컴퓨팅 유 닛 (또는 컴퓨팅 시스템)은 데이터 교환을 위해 대응하는 (유선 및/또는 무선) 인터페이스를 통해 서로 연결된 다. 작업 수준과 평가 수준은 예를 들어 서로 다른 제어 장치(컴퓨팅 장치 또는 컴퓨팅 시스템)에서 구현될 수 있다. 다른 모바일 무선 장치도 생각할 수 있다. 또한 작업 레벨은 기계에 영구적으로 설치된 제어 장치(컴퓨팅 장치/컴퓨팅 시스템)에 의해 구현되고 평가 레벨은 모바일 컴퓨팅 장치(예를 들어, 모바일 무선 장치)에 구현되 는 것이 가능하다. 시스템은 바람직하게는 투영 레벨 및/또는 전체 시퀀스 메모리를 포함한다. 바람직하게는, 상기 시스템에 있어서, 작업 평면은 제1 및 제2 인공 학습 작업 유닛을 포함하고, 상기 평가 레 벨은 제1 및 제2 인공 학습 평가 유닛을 포함하고; 상기 인공적으로 학습하는 작업 유닛 및/또는 평가 유닛은 바람직하게는 각각 복수의 노드를 갖는 신경망을 포함하고, 더 바람직하게는 상기 하나 이상의 매개변수(들)은 각각 상기 신경망의 노드에 대한 가중치, 노드의 활성화 함수, 노드의 출력 함수, 노드의 전파 함수 중 적어도 하나이다. 바람직하게, 상기 제1 작업 유닛, 제2 작업 유닛, 제1 평가 유닛 및 제2 평가 유닛 각각에 분류 메모리가 할당 되고, 제1 작업 유닛, 제2 작업 유닛, 제1 평가 유닛 및 제2 평가 유닛은 출력 값 또는 평가를 생성할 때 입력 값 또는 평가의 분류를 수행하도록 설정되고, 상기 제1 작업 유닛, 제2 평가 유닛 및 제2 평가 유닛은 입력 값 또는 상황 데이터를 출력 값 또는 평가 생성 시 하나 이상의 클래스로 분류하도록 설정되며, 어떤 클래스가 각 각의 분류 메모리에 저장되고, 각각의 클래스는 하나 이상의 종속 레벨로 구조화되며; 제1 작업 유닛 및/또는 제1 평가 유닛의 분류 메모리의 클래스 및/또는 레벨의 수는 바람직하게는 제2 작업 유닛의 분류 메모리의 클래 스 및/또는 레벨의 수보다 작고, 제2 평가 유닛의 분류 메모리의 클래스 및/또는 레벨의 수는 추가로 바람직하 게는 제1 평가 유닛의 분류 메모리의 클래스 및/또는 레벨의 수보다 더 바람직하게 크다. 바람직하게, 시스템에서, 제1 및 제2 인공 학습 처리 유닛은 각각 제1 및 제2 컴퓨팅 유닛에서 하드웨어 및/또 는 컴퓨터 프로그램으로 구현 및/또는 실행되며, 제1 및 제2 컴퓨팅 유닛은 제1 인터페이스에 의해 상호 연결되 고; 선택적으로, 제1 인터페이스는 하나 이상의 제1 변조 함수를 형성하도록 배열된다. 독립적으로, 바람직하게 는 시스템에서, 제1 및 제2 인공 학습 평가 유닛은 각각 제3 및 제4 컴퓨팅 유닛에서 하드웨어 및/또는 컴퓨터 프로그램으로서 구현 및/또는 실행되며, 제3 및 제4 컴퓨팅 유닛은 제3 인터페이스에 의해 상호 연결되며; 선택 적으로 제3 인터페이스는 하나 이상의 제3 변조 함수를 형성하도록 배열된다. 바람직하게는, 제3 컴퓨팅 유닛과 제1 컴퓨팅 유닛은 제2 인터페이스에 의해 상호 연결되고; 선택적으로 제2 인터페이스는 하나 이상의 제2 변조 함수를 형성하도록 배열된다. 제1, 제2, 제3 및/또는 제4 컴퓨팅 유닛은 서로 완전히 또는 부분적으로 구별(분 리)될 수 있다. 특히, 작업 레벨이 구현되는 상기 언급된 적어도 하나의 컴퓨팅 유닛은 제1 및 제2 컴퓨팅 유닛 을 포함하고, 즉, 제1 및 제2 컴퓨팅 유닛은 작업 레벨이 구현되는 컴퓨팅 시스템으로 간주될 수 있다. 유사하 게, 평가 레벨이 구현되는 상기 언급된 적어도 하나의 컴퓨팅 유닛은 특히 제3 및 제4 컴퓨팅 유닛을 포함하고, 즉, 제3 및 제4 컴퓨팅 유닛은 평가 수준이 구현되는 컴퓨팅 시스템으로 간주될 수 있다. 여기서 제1 유닛은 제 2 유닛과 다른 (별도의) 컴퓨팅 유닛이고/이거나 제3 유닛은 제4 유닛과 다른 (별도의) 컴퓨팅 유닛이라는 것도 생각할 수 있다. 바람직하게, 적어도 하나, 바람직하게는 모든 컴퓨팅 유닛은 각각의 컴퓨팅 유닛에 연결되거나 포함된 메모리와 연관되고; 추가로 바람직하게는 제1 컴퓨팅 유닛과 연관된 메모리는 제1 분류를 저장하도록 배열되고, 및/또는 제2 컴퓨팅 유닛과 연관된 메모리는 제2 분류를 저장하도록 배열되고, 및/또는 제3 컴퓨팅 유닛과 연관된 메모 리는 제1 조건을 저장하도록 배열되고, 및/또는 제4 컴퓨팅 유닛과 연관된 메모리는 제4 조건을 저장하도록 배 열된다. 시스템은 바람직하게는 제1 및/또는 제2 출력 값을 사용자에게 출력하기 위한 적어도 하나의 출력 모듈을 더욱 포함하고, 상기 출력 모듈은 스크린, 터치 스크린, 스피커, 투영 모듈 중 적어도 하나를 포함한다. 본 발명의 추가적인 이점 및 실시 예는 상세한 설명 및 첨부된 도면으로부터 명백하다. 위에서 언급한 기능과 아래에서 설명할 기능은 본 발명의 범위를 벗어나지 않고. 각각의 경우에 표시된 조합으 로 사용할 수 있을 뿐만 아니라, 다른 조합으로 또는 자체적으로 사용될 수 있다는 것이 이해될 것이다. 본 발명은 도면의 실시 예에 의해 개략적으로 예시되고 도면을 참조하여 아래에서 설명된다."}
{"patent_id": "10-2023-7019741", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "item": 1, "content": "도 1 내지 6 및 이들에 대한 다음 설명은 인공 학습 작업 유닛와 인공 학습 평가 유닛 모두에 관한 것이다. 도 1 내지 도 6의 설명에 있어서, \"인공 학습 유닛\" 또는 \"인공적으로 학습하는 유닛\"라는 용어가 사용되며, 이는 \"인공 학습 작업 유닛\"와 \"인공 학습 평가 유닛\"를 모두 나타낼 수 있다. 도 1 내지 도 6과 관련하여 설명된 바 와 같이 결합된 인공 학습 유닛은 \"인공 학습 시스템\"이라고 불린다. 도 1은 2개의 링크된 인공 학습 유닛(110, 120)을 갖는 예시적인 실시 예를 도시하며, 이는 아래에서 더 상세히 설명된다. 인공 학습 유닛(110, 120)은 함께 인공 학습 시스템을 형성한다. 다음 설명에서, 인공 학습 유닛은 예를 들어 각각의 네트워크에 대한 입력으로서 화살표(112, 122)로 표시된 출력 값을 사용함으로써, 특히 피드 백되는 신경망으로 예시적으로 설계된다. 이 경우, 여기서는 제1 신경망의 형태인 제1 인공 학습 유닛이 제공되며, 이는 본질적으로 입력 신호 Xi를 범주화하거나 분류하고, 이 범주화 또는 분류의 결과로 제2 인공 학습 유닛, 여기서는 제2 신경망에 영향 을 주는 역할을 할 수 있다. 그렇게 함으로써, 제1 신경망의 결과는 바람직하게는 제2 신경망에 대한 입력 값으 로 사용되지 않고, 네트워크의 기존 가중치, 단계 크기 및 기능에 영향을 미친다. 특히, 제2 신경망의 이러한 매개변수는 완전히 재정의되는 것이 아니고, 제1 신경망의 출력 신호를 기반으로 제2 신경망의 원래 매개변수들이 변조되거나 중첩되는 방식으로 영향을 받을 수 있다. 이는 두 개의 신경망이 독립적으로 바람직하 게 작동한다고, 예를 들어, 기본 값 자체를 훈련하지만 중첩에 의해 결합될 수 있다는 것을 의미한다. 이와 관 련하여, 2개의 신경망은 서로 실질적으로 유사하도록 설계될 수 있지만, 예를 들어 존재하는 계층 및 분류의 수 와 같이 복잡성 레벨이 상당히 다르다. 또한, 각 신경망은 자체 메모리를 포함할 수 있다. 가능한 실시 예에서, 제1 신경망은 입력 값을 대략적이고 빠르게 분류하는 분류망으로 사용될 수 있으며, 그런 다음 범주화 결과에 기초하여 제2 네트워크는 제2 네트워크의 매개변수를 변조함으로써 그에 따라 영향을 받는다. 이 목적을 위해, 제1 신경망은 대략적인 범주화를 달성하기 위해 바람직하게는 고도로 추상화된, 몇 개 의 클래스 K1, K2, ...Kn을 갖는 메모리를 갖는 비교적 적은 레벨을 갖는 네트워크일 수 있다. 예를 들어, 이 제 1 신경망은 10, 50, 100 또는 500개의 클래스로 제한될 수 있고, 이에 의해 이러한 숫자는 대략적인 예로만 이 해해야 한다. 특히, 제1 신경망의 훈련은 추가로 결합된 신경망과 개별적으로 그리고 독립적으로 수행될 수 있 다. 그러나 추가로 또는 대안적으로 하나 이상의 결합된 신경망과 결합된 상태의 훈련 단계가 사용될 수도 있다. 따라서 제1 신경망은 짧은 시간 내에 사용 가능한 출력을 제공해야 하며, 이를 통해 제2 신경망은 의미 있는 영 향을 받을 수 있다. 가중치 및 함수는 제1 신경망의 출력 값 Output1로부터 생성될 수 있으며, 이것은 자 체 생성된 제2 신경망의 가중치 및 함수에 중첩될 수 있다. 이것은 제2 신경망이 처음에는 독립적으로 기 능하고 제1 신경망의 출력 값이나 그로부터 얻은 매개 변수를 채택하지 않는다는 것을 의미한다. 제2 신경망 도 초기에 일반적인 방식으로 독립적으로 훈련될 수 있고 그에 따라 자체 생성된 가중치를 가질 수 있다. 제2 신경망은 제1 신경망보다 훨씬 더 복잡할 수 있으며 특히 더 많은 레벨 및/또는 메모리 클래스를 가질 수 있다. 제1 신경망에 비해 제2 신경망의 복잡도가 증가하는 정도는 애플리케이션에 따라 다르게 결정될 수 있다. 제2 신경망에 대한 입력 값 또는 입력 데이터는 바람직하게는 제1 신경망에 대한 것과 동일한 입력 값이므로, 이제 동일한 데이터로 더 복잡한 분석을 수행할 수 있다. 그러나 대안적으로, 제1 신경망의 출력 값은 또한 적어도 부분적으로 제2 신경망의 입력 값으로 사용될 수 있다. 특히 제2 네트워크의 복잡성이 크게 다른 경우, 예 를 들어, 제1 네트워크의 입력 값이기도 한 원래 입력 값이 모두 입력 값으로 공급되는 제2 네트워크가 제공될 수 있으며, 추가적으로 제1 네트워크의 출력 값은 제2 네트워크의 입력 값으로 사용된다. 도 2는 제2 신경망의 하나 이상의 매개변수가 중첩될 수 있는 다양한 변조 함수 fmod의 예를 보여준다. 원칙적으 로, 중첩 또는 변조는 어떤 방식으로든 발생할 수 있다. 노드의 가중치 wi2에 변조 함수 fmod_w를 적용하면, 예를 들어, 제2 네트워크의 가중 행렬이 변조 함수의 인수로 사용되거나, 제1원(또한 다른) 함수가 각각의 가중 값 wi2에 대해 제공될 수 있다고 할 수 있다. 변조 함수 fmod_f가 제2 신경망의 기술 함수 중 하나, 즉 신경망 의 전달 함수 ftrans2, 활성화 함수 fakt2, 전파 함수 또는 출력 함수 fout2에 적용되면, 이는 두 함수를 연결 하여 수행할 수 있으며 다시 변조 함수 fmod_f를 일부 또는 모든 관련 설명 함수에 적용할 수 있다(예를 들어, 제 2 신경망의 모든 활성화 함수 fakt2). 유사하게, 제2 신경망의 함수의 매개변수는 변조 함수에 의해 변경될 수 있다. 변조는 네트워크의 모든 노드에 동일하게 적용되거나 대안적으로 노드의 하위 집합에만 적용되거나 각 노드에 대해 다르게 변조될 수 있다. 마찬가지로, 예를 들어 변조는 네트워크의 각 계층에 대해 개별적으로 또 는 다른 방식으로 시차를 둘 수 있다. 특히, 변조 함수 fmod는 또한 시간 종속 함수일 수 있으므로, 제2 신경망의 가중치 wi2 또는 함수는 시간 종속 방 식으로 변경된다. 그러나 제2 신경망을 변조하기 위한 정적 변조 함수도 생각할 수 있다. 이 경우, 변조는 (전 파 함수 또는 활성화 함수와 같이) 제2 네트워크에 대해 원래 이미 정의되거나, 적응된 자체 생성된 가중치와 같이 훈련 단계에서 독립적으로 얻은 제2 네트워크의 매개변수에 적용된다. 이에 대한 예로서, 8개의 다른 시간 종속 변조 함수가 도 2에 도시되며, 이 때 변조 함수는 도 2에 도시된 바와 같이 원래 매개변수에 값을 곱하여 제공된다. 예 a)는 값 0이 지정된 시간까지 지정된 다음에 0보다 큰 값이 지 정되는 간단한 이진 스텝 함수를 보여준다. 이 때, 제2 값은 원칙적으로 1일 수 있지만 다른 값을 가질 수도 있 으므로 원래 매개변수에 추가로 계수가 할당된다. 이러한 방식으로, 예를 들어, 가중은 시간에 종속하여 켜지거 나 꺼지거나 시간에 종속하여 증폭된다. 예 b)는 0보다 작은 제2 값을 가진 단계 함수가 지정된 유사한 상황을 보여준다. 마찬가지로, 예 a) 및 b)의 변형에 대한 대안으로서, 0이 아닌 두 개 이상의 다른 값을 포함하는 단 계 함수를 생각할 수 있으므로, 레벨은 시간의 함수에 따라 올라가거나 내려간다. 예 c)는 제2 네트워크의 모든 매개변수에도 적용할 수 있는 주기적 변조 함수를 보여주며 이러한 방식으로 시간 에 따라 특정 요소를 주기적으로 증폭하거나 감쇠한다. 예를 들어, 서로 다른 노드 및/또는 서로 다른 계층에 대한 이러한 함수에 대해 서로 다른 진폭 및/또는 기간이 선택될 수도 있다. 이 시점에서 사인 함수 또는 비정 상 함수와 같은 모든 주기적 함수를 사용할 수 있다. 함수와 제2 네트워크의 자체 생성 함수의 연결 유형에 따 라, 양수 또는 음수 함수 값만이 선택될 수 있다. 예 d)는 느리고 지속적인 일시적인 레벨 증가 및 감소를 보여준다. 반면, 예 e)는 선택적으로 0이 될 수 있는 적은 함수 값을 가진 짧고 대략적인 직사각형의 높은 레벨을 설명한다. 유사하게, 예 f)는 불규칙하게 분포되고 매우 짧은 피크 또는 스파이크를 보여주므로 매우 짧은 시간 동안 레벨 증가 또는 변화를 유발한다. 이 때, 피 크는 진폭이 다르며 양수 값과 음수 값을 모두 가질 수 있다(기본값 기준). 예 e) 및 f)의 변형에 대해, 정규적, 주기적 및 시간적으로 완전히 불규칙한 (예를 들어, 확률론적으로 결정된) 피크 또는 증폭의 분포가 모 두 존재할 수 있다. 예를 들어 짧은 레벨 증가는 제2 신경망의 결정 주기 시간 내에 있을 수 있지만, 더 긴 레 벨 변경은 여러 결정 주기에 걸쳐 확장될 수 있다. 도 2의 예 g)는 다른 감쇠 및 진폭으로 임의로 설계될 수 있는, 감쇠되는 진동을 추가로 보여준다. 마지막으로, 예 h)는 기본 값 주변의 서로 다른 진동의 시간적 시퀀스를 보여주며, 특히 진동의 주기 길이는 다르지만 진폭 은 동일하게 유지된다. 서로 다른 진동의 이러한 조합은 추가 중첩, 즉 비트로 설계될 수도 있다. 일반적으로, 모든 변조 함수를 생각할 수 있으며 도 2에 표시된 함수는 예제로만 이해해야 한다. 특히, 표시된 예시 함수의 모든 조합이 가능한다. 또한 모든 예에서 보여지는 베이스라인은 변조 함수의 원하는 효과에 따라 0 또는 다른 기본 값에서 실행될 수 있음을 이해해야 한다. 각각의 변조된 함수와 변조 함수의 순수한 연결의 경우, 기본 값 0과 그에 상응하는 함수 값의 증가는 각 노드가 시간 종속 방식으로만 처리에 기여하고 다른 시 간에 꺼지는 것을 보장할 수 있다. 반면에 기본 값이 1이면, 예를 들어, 도 2a)의 예에서, 가중치에 적용되는 변조 함수가 먼저 변조된 네트워크의 자체 생성 가중치를 기본 값으로 재생산한 다음에, 단계적으로 높은 값에 서 그에 따라 가중치가 증가하는 것을 달성할 수 있다. 따라서 이러한 함수는 활성화 함수와 같은 함수의 변조에도 작용한다. 이미 설명한 바와 같이, 변조 함수는 제1 인공 학습 유닛의 출력 값에 기초하여, 즉 본 예에서는 제1 신경망에 기초하여 형성될 수 있다. 출력 값과 그로부터 형성되는 변조 함수의 관계는 임의로 설계할 수 있다. 예를 들어, 이 관계는 결합된 네트워크의 공동 훈련 단계에서 적어도 부분적으로 생성될 수 있다. 다른 실시 예에서, 변조 함수와 제1 네트워크의 출력 값 사이의 종속성은 미리 정의될 수 있으며, 예를 들어, 변조 함수는 도면에 도시된 함수 중 하나로 주어질 수 있으며, 레벨 편위의 크기는 출력 값에 의해 결정된다. 선택적으로, 특정 출 력 값에서 처음에는 제2 네트워크의 변조가 발생하지 않는다고 결정될 수 있다. 제2 신경망의 가중치 및 함수에 변조 함수를 적용하는 것 외에 또는 대안으로, 결합된 드롭아웃 방법이 또한 적 용할 수 있으며, 이는 도 3에 도시된다. 이것은 전통적으로 신경망에 대한 훈련 절차로서 여기서 각 훈련 주기 에서 숨겨진 계층과 입력 계층에 존재하는 뉴런 중 일부만 사용되고 나머지는 사용되지 않는다(\"드롭아웃\"). 이 를 위해, 종래 기술은 일반적으로 네트워크의 피드백 오류를 기반으로 드롭아웃 비율을 설정하고, 이는 전체 네 트워크 중 얼마나 많은 부분이 꺼져 있는 뉴런으로 구성되어 있는지를 결정한다. 마찬가지로, 뉴런 대신에, 뉴 런 사이의 에지 또는 연결의 일부가 꺼질 수 있다. 뉴런 및/또는 에지의 이러한 부분적 단절은 이하 예시적인 실시 예에서 제2 신경망에서도 사용될 수 있고, 이로 써 드롭아웃 매개변수는 네트워크 자체의 오류 피드백을 기반으로 사용되지 않고 제1 신경망의 출력 값에 따라 시간 종속 변조의 경우와 같이 사용된다. 이에 의해, 예를 들어, 제1 신경망의 출력 값 Output1에 기초하 여 제2 신경망에 대한 드롭아웃 비율이 결정될 수 있고, 이는 제2 신경망에 적용될 수 있다. 도면은 다시 도 1 에서와 같이 2개의 결합된 네트워크(310, 320)를 도시하고, 이에 의해 제2 네트워크의 뉴런 또는 노드 (326, 328)는 개략적으로 원으로 표시된다. 연결 에지는 표시되지 않았으며 표시된 뉴런의 배열은 실제 토폴로 지와 강력한 관계를 갖지 않는다. 드롭아웃 비율을 통해, 기존 뉴런의 일부는 이제 비활성화되어 사용되지 않는 다. 제2 네트워크의 활성 뉴런은 도면에서 빗금으로 도시된 반면, 채워지지 않은 뉴런은 비활성 드롭아웃 뉴런을 나타내도록 의도된다. 일반적으로, 본 명세서에서 설명된 결합 드롭아웃은 가중치에 대한 변조 함수 또는 예를 들어, 각 개별 노드의 출력 함수로 0 또는 1을 사용함으로써 변조 함수 fmod로 이해될 수도 있다. 이 경우, 제1 네트워크의 출력 값에 기초하여 어떤 뉴런(326, 328)이 꺼져 있는지를 결정할 수 있거나, 속도만 지정될 수 있으며 뉴런이 꺼지는 확 률 함수를 통해 결정될 수 있다. 다시, 드롭아웃 비율은 제1 네트워크의 출력 값 Output1에 기초하여 결정 될 수 있다. 선택적으로, 드롭아웃 변조 함수는 또한 도 2에 표시된 바와 같이 드롭아웃 함수와 변조 함수의 연 결에 해당하는 시간 종속적 셧다운을 유발할 수도 있다. 유사하게, 이전 훈련에서 입증된 일련의 패턴 컷오프도 사용할 수 있으므로, 예를 들어, 제2 신경망에서 컷오프를 위해 순환 패턴 변형이 사용되도록 한다. 일반적으로 드롭아웃은 신경망의 작업 속도를 높일 수 있다. 또한 인접한 뉴런의 행동이 너무 유사해지는 것을 방지한다. 위에서 설명한 결합 드롭아웃은 두 개의 네트워크가 결합된 공동 훈련 단계와 이미 훈련된 네트워크 모두에서 사용될 수 있다. 결합된 신경망이 의미 있는 방식으로 서로를 보완하도록 하기 위해, 어떤 신경망이 주어진 시간에 전체 시스템 을 지배하는지 결정할 수 있다. 출력 값이 전체 시스템의 출력을 결정하는 네트워크는, 지배 네트워크 또는 지 배적인 것으로 설명할 수 있다. 이하, 둘 이상의 연결된 네트워크 그룹에서 하나의 네트워크만 지배적이며 지배 네트워크의 출력은 전체 시스템의 출력과 같다고 가정한다. 그러나, 원칙적으로 다른 실시 예도 생각할 수 있으 므로, 예를 들어, 하나 이상의 지배 네트의 경우 지배 네트의 출력 값을 최종 총 출력 값으로 처리하는 것을 설 명하는 규칙이 지정된다. 예시적인 실시 예에서, 하나 이상의 연결된 신경망에 대한 시간 제한을 설정하는 타이머 또는 타이밍 요소를 이 러한 목적으로 구현할 수 있다. 이 시간 사양은 각 네트워크의 출력 값을 사용할 수 있어야 하는 최대값 또는 시간 상한값으로 이해하는 것이 바람직하므로, 출력은 또한 더 일찍 사용할 수 있다. 늦어도 특정 네트워크에 대해 지정된 시간이 경과한 후, 이 네트워크의 출력 값이 평가된다. 따라서 타이머는 고정된 시간 사양에 기초 하여 결합된 네트 사이의 지배도를 제어 및/또는 변경할 수 있다. 이러한 유형의 예시적인 실시 예가 도 4에 도시되어 있다. 2개의 신경망(410, 420)의 설계 및 결합은 도 1에서 이미 설명한 예에 대응할 수 있다. 이제 타이머는 제1 신경망의 출력이 미리 결정된 시간 매개변수 값에 의해 정의되는 미리 결정된 시간 후에 늦어도 평가되도록 보장한다. 필요한 시간은 예를 들어 입력 값 Xi가 해당 네트워크에 공급되는 시간부터 측정할 수 있다. 네트워크에 대한 사전 정의된 시간 매개변수의 선택은 특히 네트워크의 복잡성에 따라 수행될 수 있으므로 사전 정의된 시간에 실제로 사용 가능한 결과를 기대할 수 있 다. 제1 신경망이 히든 계층이 적고 분류 수가 적은 네트워크로 구성하는 것이 바람직한, 상술한 것과 같 은 예에서, 상응하는 짧은 시간이 이 제1 네트워크에 대해 선택될 수도 있다. 마찬가지로, 네트워크의 컴퓨팅 시간 및/또는 결합된 네트워크에 의해 고려되는 애플리케이션 영역에 결정적으로 영향을 미치는 기존 하드웨어 와 같은 네트워크에 대한 시간 매개변수를 선택할 때 추가 고려 사항이 고려될 수 있다. 더 나아가, 미리 결정 된 시간 매개변수는 가변적일 수 있고, 예를 들어 결합된 신경망 중 적어도 하나로부터의 결과에 따라 수정되거 나 재정의될 수 있다. 그러한 시간 사양은 각각의 네트워크(410, 420)의 단일 순회를 위한 최소 시간으로서 요 구되는 시간 범위를 적어도 포함해야 한다는 것이 이해된다. 도 4에서, 30ms의 시간 범위가 제1 네트워크의 예 로 지정되므로, 프로세스가 실행되는 동안 이 네트워크는 프로세스 시작부터 0ms에서 30ms까지 시간을 지배한다. 그러나, 이 시간 범위에 적합한 다른 값도 물론 선택될 수 있다. 제1 네트워크에 대한 시간 매개변수에 의해 지정된 기간 동안(여기서는 30ms), 제1 신경망은 일반적인 방 식으로 입력 값 Xi를 처리한다. 소정의 시간이 경과한 후, 함수는 제1 신경망의 출력 Output1에서 생성될 수 있으며, 이는 제2 신경망 자체의 가중치와 함수를 중첩하거나 변조하는 데 사용된다. 뿐만 아니라, 제1 신경 망의 출력 값은 대안으로서 또는 제2 신경망에 영향을 미치기 위해 사용되는 것 이외에 독립적으로 처리될 수 있고, 예를 들어 전체 시스템의 빠른 출력으로 사용될 수 있다. 변조 함수 fmod_f, fmod_w가 제2 신경망에 적용되면, 타이머는 새로운 타이밍 측정을 시작할 수 있고, 이제 제2 신경망에 대해 미리 결정된 제2 타이밍 매개변수를 적용할 수 있다. 이 경우, 제2 신경망은 획득된 변조 함수 fmod_f, fmod_w에 의한 변조 이전에 입력 값 Xi를 선택적으로 독립적 으로 처리할 수 있으므로, 예를 들어, 입력 값은 또한 제2 미리 결정된 기간의 시작 전에 제2 신경망으로 전달될 수 있고 이에 따라 그곳에서 처리될 수 있다. 제1 기간이 경과한 후, 해당 변조 함수 fmod_f, fmod_w 를 적 용하여 제2 신경망의 매개변수 값과 함수를 중첩한다. 하나 이상의 변조 함수는 제2 신경망의 다른 부분, 예를 들어 제2 신경망의 가중치, 출력 함수, 전파 함수 및/또는 활성화 함수에 대해 형성될 수 있다. 제1 신경 망보다 훨씬 더 복잡하도록 설계된 제2 신경망의 경우, 예를 들어 훨씬 더 많은 계층과 노드를 가짐 으로써 및/또는 더 많은 수의 메모리 클래스를 가짐으로써, 제2 신경망은 상대적으로 더 높은 계산 노력과 더 많은 시간을 필요로 하므로 이 경우 제2 기간은 대응하여 더 길게 선택될 수 있다. 선택적으로, 각각의 네트워크(410, 420)는 다른 네트워크가 현재 시간 범위로 인해 전체 시스템에서 지배 네트 워크로 결정되는 동안에도, 계속해서 입력 값을 처리하고 평가할 수 있다. 특히, 2개의 결합된 네트가 도시된 예에서, 제1 네트는 제2 네트가 지배하더라도 입력 값을 지속적으로 평가할 수 있고, 따라서 전체 시스템의 출 력 값은 제2 기간이 경과하고 제2 네트에 의해 솔루션이 발견된 후 제2 네트의 출력 값에 대응한다. 이런 식으 로, 전체적으로 이용 가능한 입력 값을 평가하는, 본 명세서에서 설명된 제1 네트워크와 같은 빠른 범주화 네트워크는, 발견된 출력 값이 전체 출력으로 들어가는 한, 단기 개입을 수행할 수 있다. 이러한 실시 예는 아 래에서 더 자세히 설명된다. 타이머에서 사전 정의된 시간 주기를 통해 이러한 시간 제어의 결과로, 전체 시스템은 초기에 결정을 내릴 수 있으며, 예를 들어 이미 완료되어야 하는 제2 신경망에 의한 최종 평가 및 세부 분석 없이 이미 작동할 수 있다. 예를 들어, 적어도 두 개의 결합된 네트워크가 있는 시스템에 의해 평가될 자율 주행 시스템의 상황을 고 려한다. 제1 유닛 또는 제1 신경망을 통해, 위험 유형에 대한 추가 평가가 아직 포함되지 않은 조기 분류 \"위험\"이 달성될 수 있지만, 이미 차량 속도 감소, 제동 및 센서 시스템 활성화와 같은 즉각적인 반응으로 이어 질 수 있다. 동시에, 범주화에 기초하여, 즉 제1 네트워크의 출력 값에 의한 변조의 영향 하에서, 제2 신경망은 상황에 대한 보다 심층적인 분석을 수행하고, 이는 다음에 제2 신경망의 출력 값을 기반으로 전체 시스템의 추 가 반응 또는 변경으로 이어질 수 있다. 결합된 각 네트워크에 대해 시간 제한을 지정하지 않고 네트워크 중 하나에 대해서만 (또는, 2개 이상의 네트워 크가 결합된 경우 결합된 네트워크의 하위 집합에 대해서만) 지정하는 것도 생각할 수 있다. 예를 들어, 상기 예에서, 빠르게 범주화하는 제1 신경망에 타이머를 사용할 수 있는 반면, 제2 신경망에는 고정된 시간 제한이 주어지지 않거나, 그 반대일 수도 있다. 이러한 실시 예는 또한 현재 지배 네트워크를 결정하기 위한 추가 방법 과 조합될 수 있으며, 이는 아래에서 더 상세히 설명된다. 타이머가 삽입된 모든 실시 예에서, 현재 활성 타이머를 갖는 신경망의 출력 값을 전체 시스템의 출력으로 사용 하도록 할 수 있다. 네트워크가 주어진 입력 값에 대한 제1 솔루션에 도달하는 데 필요한 시간으로 인해, 이전출력 값(제1 또는 제2 네트워크의)이 여전히 총 출력 값으로 사용 가능한 특정 대기 시간이 있다. 연결된 네트 중 일부에 대해서만 타이머 또는 타이밍이 정의된 경우, 예를 들어 타이머가 제1 네트에서만 활성 화된 경우, 예를 들어 전체 시스템의 출력은 일반적으로 항상 제2 네트의 출력에 해당하고 타이머가 제1 네트에 대해 활성화된 경우, 즉 사전 정의된 기간이 활발하게 실행되고 아직 만료되지 않은 경우에만 제1 네트의 출력 으로 대체된다고 정의할 수 있다. 네트가 2개 이상인 시스템에서, 특히 서로 다른 작업을 가진 여러 개의 네트가 한 결과에 동시에 도달하고, 다 음에 하나 이상의 다른 네트에 영향을 미치는 경우, 미리 정의된 시간 범위를 정렬하고 타이머를 변경하여 서로 간의 네트의 합리적인 동기화도 가능하게 될 수 있다. 마찬가지로 지정된 기간과 프로세스를 조정하여, 동기화 는 각각 여러 개의 결합된 네트워크로 구성된 여러 개별적인 전체 시스템 간에도 달성될 수 있다. 예를 들어, 시간 정렬을 통해 시스템이 동기화될 수 있으며 다음에 각각의 타이머 사양에 따라 독립적이지만 동기적으로 실 행된다. 타이머를 기반으로 전체 시스템에서 각각의 지배 신경망을 변경하는 것에 추가로 또는 대안적으로, 각 신경망 자체도 협력 방식으로 지배력의 이전에 대해 결정을 내릴 수 있다. 이것은 예를 들어, 전체 시스템의 제1 신경 망이 입력 값을 처리하고 특정 제1 솔루션 또는 특정 출력 값에 도달하고, 예를 들어 학습 단계에서 학습된 분 류에 따라 입력 값을 특정 클래스로 분류하고, 이 분류를 달성하면 지배력을 전체 시스템의 제2 신경망으로 이 전하는 것을 의미할 수 있다. 타이머의 도움으로 무게 중심을 변경하는 것과 같이, 본 명세서에서 전체 네트워크의 출력 값이 각 경우에 현재 지배 네트워크의 출력 값에 해당한다고 지정할 수 있다. 이를 위해, 예를 들어 입력 값의 변화를 평가할 수 있다. 입력 값이 기본적으로 변경되지 않는 한, 결합된 네트 워크 사이의 지배력 분포는 또한 본질적으로 변경되지 않은 상태로 유지될 수 있고 및/또는 타이머에만 기초하 여 결정될 수 있다. 하지만, 입력 값이 갑자기 변경되면, 결합된 네트의 다른 지배 동작을 무시하는 미리 결정 된 지배력을 설정할 수 있다. 예를 들어, 갑자기 변경된 입력 값에 대해, 어느 경우에나 지배력이 먼저 제1 신 경망으로 다시 전달된다고 결정될 수 있다. 이것은 또한 이 제1 신경망에 대해 선택적으로 사용 가능한 타이머 를 다시 시작하고 프로세스는 이전에 설명한 대로 수행된다. 예를 들어 센서 값이 새로운 환경을 감지하는 경우, 또는 이전에 평가된 프로세스가 완료되었고 이제 새 프로세스가 트리거되는 경우, 입력 값에 상당한 변화 가 발생할 수 있다. 임계값은 입력 값의 변화가 중요한 것으로 간주되어 지배력의 변화로 이어지는지 여부를 결정하는 데 사용할 수 있는 유의성 임계값 형식으로 지정할 수 있다. 개별의 중요 임계값은 다른 입력 값 또는 각 입력 값에 대해 지 정될 수 있거나, 예를 들어, 백분율 편차의 형태로 된 일반 값은 입력 값의 변화를 평가하기 위한 기준으로 제 공될 수 있다. 유사하게, 고정된 유의성 임계값 대신에, 상황에 따라 시간에 따라 또는 적응적으로 변경될 수 있는 임계값이 있을 수 있거나, 이들은 변화의 중요성의 평가 기준이 되는, 함수, 행렬 또는 패턴일 수 있다. 대안으로 또는 추가적으로, 결합된 네트워크 간의 지배력의 변화는 각 네트워크에 대해 발견된 출력 값에 따라 달라질 수 있다. 실시 예에 따라, 예를 들어, 제1 신경망은 입력 값 및/또는 그 변화를 평가할 수 있다. 이 경 우, 분류를 위해 제1 신경망에 사용할 수 있는 클래스에 대해 각 경우에 유의성 임계값이 미리 정의될 수 있으 므로, 입력 데이터에 대해 발견된 클래스에 상당한 변화를 초래하는 제1 신경망의 결과의 경우, 제1 신경망으로 의 지배 이전이 즉시 이루어져, 상황을 신속하게 재평가하고 필요한 경우 대응이 이루어질 수 있도록 한다. 이 런 식으로, 빠르게 범주화하는 제1 네트워크에 의해 인식되는, 크게 달라진 입력 상황에도 불구하고, 제2 신경 망은 변화를 고려하지 않고 불필요하게 오랜 시간 동안 심층 분석을 계속한다. 위의 모든 예에서, 전체 시스템의 출력 값은 예를 들어 액추에이터에 대한 직접 또는 간접 제어 신호로, 향후 사용을 위해 저장되는 데이터로, 또는 출력 유닛에 전달되는 신호로 어떤 방식으로든 추가로 사용될 수 있다. 모든 경우에, 출력 값은 추가 기능 및 평가에 의해 먼저 추가 처리되고 및/또는 추가 데이터 및 값과 결합될 수 있다. 도 5는 2개의 단방향 결합 네트워크(510, 520)를 갖는 도 1에서와 같은 간단한 구현 예를 다시 도시하므로, 분 류 메모리(512, 522)가 이제 각각의 네트워크에 대해 개략적으로 도시된다. 사용된 분류 유형 Ki은 처음에는 여 기에서 이차적으로 중요하며 아래에서 더 자세히 설명한다. 특히, 제1 네트워크 및 제2 네트워크의 2 개의 분류 메모리의 치수 및 구조는 상당히 다를 수 있으므로, 속도와 초점이 다른 두 개의 신경망이 형성된다. 따라서, 빠르고 대략적으로 분류하는 네트워크와 느리지만 더 자세한 분석 네트워크의 상호 작용을 통해 결합된전체 시스템을 형성할 수 있다. 본 예시에서, 제1 신경망은 비교적 적은 수의 분류 K1, K2, ...., Kn으로 형성되며, 이는 예를 들어 평평 한 계층만을 따를 수 있으므로, 분류는 한 차원에서만 발생한다. 바람직하게, 이러한 제1 네트워크는 또한 그 토폴로지에서 비교적 간단한데, 즉 너무 많지 않은 n개의 뉴런 및 은닉층을 갖는. 그러나 원칙적으로, 네트 워크 토폴로지는 본질적으로 분류와는 독립적일 수도 있다. 그러면 제2 신경망은 훨씬 더 크고 복잡한 분류 시스템을 가질 수 있다. 예를 들어, 이 메모리 또는 기본 분류는 또한, 도 5에 도시된 바와 같이 여러 레벨로 계층적으로 구조화될 수도 있다. 제2 네트워크 의 클래스 K1, K2, ...., Km의 총 개수 m은 매우 클 수 있으며, 특히 제1 신경망이 사용하는 클래스 의 개수 n보다 훨씬 클 수 있다. 예를 들어, 클래스의 수 m, n은 하나 이상의 자릿수만큼 다를 수 있다. 이것은 전체 시스템에서 개별 네트워크의 비대칭 분포를 달성한다. 제1 신경망에 의한 빠른 분류는 입력 값을 빠르게 분류하는 데 사용될 수 있다. 이 목적을 위해 추상, 요 약 클래스를 사용할 수 있다. 감지된 상황의 분류(예를 들어, 이미지 및 오디오 데이터와 같은 센서 데이터 기 반)는 예를 들어, 이에 대한 추가 평가를 수행하지 않고 \"크고 잠재적으로 위험한 동물\"로서 제1 신경망에 의해 초기에 수행될 수 있다. 이는 예를 들어 동물 종(늑대, 개)에 따른 또는 위험한 포식자에 따른 추가 분류 가 제1 네트워크에서 수행되지 않지만, 대신에 분류는 크기, 치아 감지, 공격 자세 및 기타 특성과 같은 가능한 가장 광범위한 일반 특성에 따라 수행되는 것을 의미한다. 본질적으로 출력 \"위험\"에 해당하는 이 데이터는, 예 비 및 신속한 반응을 위해 선택적으로 이미 적절한 외부 시스템으로, 예를 들어 사용자 또는 자동화 시스템의 특정 액추에이터에 대한 경고 시스템으로 전달될 수 있다. 또한, 제1 신경망의 출력 Output1은 설명된 바 와 같이 제2 신경망에 대한 변조 함수를 생성하는 데 사용된다. 동일한 입력 값 Xi, 예를 들어, 언급된 센서 값은 제2 신경망에도 제공된다. 이 경우, 입력 값은 즉시, 즉 제1 네트워크에 대해서와 본질적으로 동시에 또는 지연되어 입력될 수 있고, 따라서 실시 예에 따라, 이들은 변 조 함수가 적용되기 전에 또는 그 때만, 즉 제1 네트워크의 결과가 이용 가능하기 전에 또는 그 때에만 이미 입 력된다. 바람직하게, 이들은 지연을 피하기 위해서, 특히 시간이 중요한 프로세스의 경우, 나중에 제2 신경망에 제공하거나 전달해서는 안 된다. 그런 다음 제2 신경망도 솔루션을 계산하고, 이에 의해 이 제2 네트워크로부터 의 원래 자체 생성 가중치 및 그것의 기본 함수(특정 활성화 함수 및 출력 함수와 같은)는 각각 제1 네트워크의 출력 값으로부터 형성된 변조 함수에 기초하여 중첩될 수 있다. 이를 통해 제2 네트워크의 반복 작업에서 제1 네트에서 빠르게 검출된 위험 상황의 경우 시간이 없는 많은 가능한 변형을 생략할 수 있다. 제2 신경망의 느린 분석이 진행되는 동안, 설명된 바와 같이, 제1 신경망을 기반으로 가능한 반응이 이미 수행될 수 있다. 이것은 생물학적 시스템의 초기 본능적 반응에 해당한다. 계층적이며, 제1 네트워크에 비해, 훨씬 더 큰 메모리의 제2 네트워크는 다음 입력 값의 정확한 분석, 언급된 예에서, \"개\" 클래스로의 상세한 분류, 각 품종, 위험 또는 무 해 상황을 나타내는 행동 특성 등의 분류를 가능하게 한다. 필요한 경우, 제2 신경망이 하나의 결과에 도달한 후, 제1 분류 \"위험\"을 다시 다운그레이드하여, 전체 시스템의 이전 반응을 덮어쓸 수 있다. 전반적으로, 비대칭 분류를 갖는 이러한 결합된 전체 시스템에 대해, 예를 들어 신속 분류 제1 네트워크의 클래스 Kn은 심층적으로 들어가지 않고 새로운/알려진 상황, 위험/비위험 사건, 흥미로운/비흥미로운 특징, 결 정 필요/불필요 등과 같은 추상적인 분류를 주로 수행한다고 생각할 수 있다. 이 제1 분류는 제2 유닛에 의해 궁극적으로 발견된 최종 결과와 반드시 일치할 필요는 없다. 하지만, 적어도 하나의 빠르고 하나의 심층 분석 유닛에 의한 2단계 분류는 인공적으로 학습하는 전체 시스템의 감정적 또는 본능적 반응을 허용한다. 예를 들어, 뱀일 가능성이 있는 물체가 이미지 인식으로 식별되면, \"최악의 경우\"는 바람직하게는 이 분류가 아마도 정확한지 아닌지에 관계없이, 제1 분류의 결과일 수 있다. 진화적 지식과 본능적 반응으로서 인간 지능의 경우 에 존재하는 것은 미리 프로그래밍된 지식을 가진 빠른 제1 분류로 대체될 수 있으므로, 해당 표준 반응(거리 유지, 움직임 시작, 주의력 활성화)도 전체 시스템과 해당 액추에이터에 의해 수행될 수 있다. 이 제1 분류에 기초한 제2 학습 유닛의 추가 변조는 감정 관련 중첩과 유사하게, 즉, 예를 들어 무해한 것으로 이해되는 상황 과 다른 의식적 상황 분석을 자동으로 시작하는 공포 반응에 해당하여, 이해될 수 있다. 이에 의해, 변조 함수 에 의해 수행되는 제2 신경망의 매개변수의 중첩은 기본적으로 도달하지 않거나 즉시 도달하지 않는 다른 분류 공간으로 필요한 이동을 유발할 수 있다. 따라서, 이러한 시스템은 예를 들어 중요한 의사 결정 상황이 발생하는 모든 애플리케이션과 같이 다양한 애플 리케이션 영역에 사용될 수 있다. 예를 들면 운전 시스템, 다양한 유형의 위험에 대한 구조 또는 경고 시스템, 수술 시스템 및 일반적으로 복잡하고 비선형적인 작업이 있다.지금까지 설명한 실시 예에서, 두 개의 인공 학습 유닛만 함께 결합되었다. 그러나 이 아이디어는 원칙적으로 2 개 이상의 유닛에도 적용 가능하므로, 예를 들어, 3개 이상의 인공 학습 유닛이 상응하는 방식으로 결합될 수 있고, 이에 의해 어느 유닛이 특정 다른 유닛 또는 여러 다른 유닛의 매개변수를 변조할 수 있는지를 결정될 수 있다. 도 6은 3개의 신경망(610, 620, 630)(및/또는 다른 인공 학습 유닛)이 제공될 수 있는 예를 도시하고, 이에 의 해 제1 신경망의 출력 값은 제2 신경망의 가중치 및/또는 함수에 대한 변조 함수를 생성하고, 다음에 제2 신경망의 출력 값은 제3 신경망의 가중치 및/또는 함수에 대한 변조 함수를 생성한다. 이런 식으로, 임의의 길이의 인공적으로 학습하는 유닛 체인이 형성될 수 있으며, 이는 중첩에 의해 결합된 방식으로 서로에 게 영향을 미친다. 두 개의 신경망이 있는 이전 예와 유사하게, 일 실시 예에서, 결합된 모든 신경망은 동일한 입력 값을 수신할 수 있으며 처리는 각 신경망의 변조에 의해서만 결합될 수 있다. 그러나, 예를 들어, 도 1과 같이 두 개의 신경 망에 이어 제3 신경망이 제공되며, 제1 및/또는 제2 신경망의 출력 값을 입력 값으로 받는 실시 예도 생각할 수 있다. 선택적으로, 이 제3 신경망의 함수 및/또는 가중치는 예를 들어 제1 신경망의 출력 값으로부터 형성되는 변조 함수에 의해 변조될 수도 있다. 이들은 제2 네트워크에 대해 형성된 변조 함수와 동일하거나 상이한 변조 함수일 수 있다. 또는 예를 들어, 제3 신경망의 출력 값은 제1 및/또는 제2 신경망에 재귀적으로 적용되는 추가 변조 함수를 형성하는 데 사용될 수 있다. 상응하게 결합된 학습 유닛의 다양한 추가 조합이 가능하다는 것을 이해해야 하며, 이 때 상기 연결된 유닛 중 적어도 2개는 유닛의 기술 매개변수에 대해, 특히 신경망의 가중치 및/또는 함수에 대한 신경망에 대해, 변조 함수를 형성함으로써 결합을 갖는다. 결합된 유닛의 수가 증가함에 따라, 변조 및 결합의 더 복잡한 변형도 생 각할 수 있다. 처음에 이미 언급한 바와 같이, 본 명세서에서 설명된 실시 예는 신경망에 관한 예로서 설명되었지만, 원칙적으 로 다른 형태의 기계 학습으로 이전될 수도 있다. 출력 값에 기초하여 중첩 또는 변조에 의해 제1 인공 학습 유 닛에 의해 적어도 제2 인공 학습 유닛에 영향을 미칠 수 있는 모든 변형이 고려된다. 이전 예의 변조 함수에 의 한 중첩에 의한 신경망의 가중치 및 함수의 수정은 이러한 학습 유닛의 동작을 제어하거나 설명하는 임의의 적 절한 매개변수의 대응하는 변조로 대체될 수 있다. 각각의 예에서, \"학습 유닛\"라는 용어는 신경망의 특별한 경 우로 대체될 수 있고, 반대로, 예시적인 실시 예의 설명된 신경망은 각각의 예에서 명시적으로 언급되지 않더라 도 인공 학습 유닛의 형태로 일반화된 형태로 각각 구현될 수 있다. 신경망 외에도, 알려진 예로는 진화 알고리즘, 지지 벡터 머신(SVM), 의사 결정 트리 및 랜덤 포레스트 또는 유 전자 알고리즘과 같은 특수 형식이 있다. 마찬가지로, 신경망 및 기타 인공 학습 유닛을 서로 결합할 수 있다. 특히, 예를 들어 빠른 분류 유닛으로 표시 된 이전 예제의 제1 신경망을 다른 인공 학습 유닛으로 대체할 수 있다. 특징의 빠르고 대략적인 분류에 특히 적합한 방법을 선택적으로 선택하는 것도 가능하다. 그런 다음 이러한 제1 학습 유닛의 출력 값은 특히 다시 신 경망일 수 있는 제2 인공 학습 유닛을 위한 변조 함수를 형성하기 위해 2개의 신경망에 대해 설명된 바와 같이 사용될 수 있다. 상술한 바와 같이, 결합된 여러 인공 학습 유닛을 포함하는 시스템은 \"인공 학습 시스템\"을 형성한다. 설명된 변형에 추가로 또는 대안적으로, 인공 학습 시스템의 결과에 대한 평가 또는 검증을 수행하고 이 평가에 따라 인공 학습 시스템이 결과를 얻는 데 영향을 주는 인스턴스를 추가함으로써 2개 이상의 결합된 인공 학습 유닛으로 구성되거나 포함하는 인공 학습 시스템을 더욱 개선할 수 있다. 본 발명에 따르면, 추가적인 인공 학 습 시스템이 이러한 목적을 위해 사용된다. 두 개의 인공 학습 시스템으로 구성된 전체 시스템의 구조와 기능은 다음과 같다. 이러한 다른 인공 학습 유닛의 결과 또는 그 결과를 평가/검증하는 인공 학습 유닛을 평가 유닛이라고 한다. 이 에 반해, 입력 값을 처리하거나 분석하여 해당 결과에 도달하고 이를 평가 유닛에서 확인하는 인공 학습 유닛을 작업 유닛이라고 한다. 특히 신경망인 인공 학습 유닛의 기능, 즉 입력 값을 출력 값으로 매핑하는 것은, 상술 한 바와 같은 기능 및/또는 가중치에 의해 결정된다. 전체 시스템의 기본 구조 및 기능 도 7은 인공 학습 시스템인 작업 레벨과 평가 레벨으로 구성된 전체 시스템(또는 처리 및 평가 시스 템)의 기본 구조를 보여준다. 즉, 결합된 인공 학습 유닛을 포함하고 위에서 설명한 대로 구성되거나 기능한다. 또한, 전체 시스템은 투영 레벨 및 전체 시퀀스 메모리를 포함한다. 전체 시스템은 예를 들어, 시계열의 센서 데이터 또는 이로부터 전처리된 데이터인, 입력 데이터 또는 입력 값 Xi를 처리하고, 이로써 전체 시스템의 전체 출력을 형성하는 출력 데이터 또는 출력 값(출력)을 획득할 수 있다. 작업 레벨은 제1 및 제2 입력 값 Xi(t1) 및 Xi(t2), 예를 들어, 시간 t1, t2에서 연속적 센서 데이터의 형 태로 입력되는 입력 값 Xi를 처리 또는 분석하도록 설정된다. 한편으로는, 제1 분류에 따라 제1 입력 값 Xi(t1) 로부터 제1 출력 값(output11)이 결정되고, 즉, 인공 학습 시스템인 작업 레벨은 제1 입력 값의 해당 분류를 수 행하도록 훈련된다. 반면에, 제2 출력 값(output12)은 제2 분류에 따라 제2 입력 값 Xi(t2)로부터 결정되고, 즉, 작업 레벨이 이에 따라 훈련된다. 제1 출력 값의 결정은 바람직하게는 제2 출력 값을 결정하는 데 필요한 시간에 비해 짧은 시간 내에 수행된다. 따라서, 제1 분류는 제2 분류에 비해 적은 클래스로 구성된다. 따라서, 제1 출력 값은 입력 값의 대략적인 분석 을 기반으로 하는 반면, 제2 출력 값은 입력 값의 미세 분석을 기반으로 한다. 투영 레벨에서, 제1 및/또는 제2 출력 값에 기초하여 제1 상황 데이터 Y(t3) 및 제2 상황 데이터 Y(t4)가 형성된다. 따라서, 제1 상황 데이터는 제1 출력 값에 적어도 부분적으로 기초하고 제2 상황 데이터는 제2 출력 값에 적어도 부분적으로 기초한다. 예를 들어, 가장 간단한 경우, 상황 데이터는 각각의 출력 값 자체일 수 있 다. 더 나아가, 상황 데이터는 적어도 부분적으로 다른 값을 기반으로 형성될 수도 있다. 그러나, 바람직하게는 제1 상황 데이터는 제1 출력 값에 기초하여 형성되고 제2 상황 데이터는 제2 출력 값에 기초하여 형성된다. 게 다가, 선택적 메모리 요소는 투영 메모리로 투영 레벨에 할당될 수 있고(도 7에 표시되지 않음, 도 8 참조), 이 때 투영 레벨에서 발생하는 데이터를 저장할 수 있다. 투영 레벨은 소프트웨어 및/또는 하드웨어 유닛 또는 이러한 여러 유닛의 조합으로 설계될 수 있다. 특히, 투영 레벨은 인공 학습 유닛 및 이들의 기억 요소를 포함할 수 있는 여러 유닛의 합성물을 형성할 수 있다. 이 에 따라 투영 레벨은 적어도 작업 레벨의 출력이 처리되고 연결되는 중앙 유닛, 멀티플렉서 유닛, 데이터 에서 시퀀스를 생성하는 유닛, 긍정적 또는 부정적 평가 후에, 예를 들어 새 데이터를 저장된 데이터와 비교할 때 결정을 생략할 수 있는 저장된 데이터 또는 시퀀스에 식별자 또는 레이블을 각인하는 유닛을 형성할 수 있다. 이러한 기능은 프로그램 모듈에 의해 전체적으로 또는 부분적으로 수행될 수도 있다. 투사층은 또한 스크 린 또는 음향 유닛과 같은 입력 및/또는 출력 유닛을 포함할 수 있으며, 이를 통해 사용자 또는 예를 들어 시스 템의 훈련 단계를 지원하는 사용자와 통신하고, 예를 들어 현재 처리 상태를 평가하는 것이 가능하다. 투영 레벨에 형성된 제1/제2 상황 데이터는 평가 레벨의 입력을 형성한다. 작업 레벨은 제1 상 황 데이터가 소정의 제1 조건을 충족하는지 여부 또는 어느 정도 충족하는지, 또는 제2 상황 데이터가 소정의 제2 조건을 충족하는지 또는 어느 정도를 충족하는지를 나타내는 제1 평가(output21) 및 제2 평가(output22)를 출력으로서 결정하도록 배열된다. 따라서 인공 학습 시스템으로서의 평가 레벨은 제1/제2 상황 데이터가 미리 정해진 제1/제2 조건을 충족하는지 여부 또는 어느 정도를 나타내는 제1/제2 평가라고 하는 출력 값을 결정하도 록 훈련된다. 평가는 독립적으로 단순한 예/아니오 평가(예를 들어, 평가는 0 또는 1의 값만 취할 수 있음) 또 는 조건이 충족되는 정도를 나타내는 점진적 평가(예를 들어, 평가는 0에서 1까지의 모든 값을 취할 수 있음)일 수 있다. 따라서, 본 출원의 맥락에서 \"조건 충족 여부\" 또는 이와 유사한 문구는, 항상 명시적으로 언급되지는 않지만, 조건이 어느 정도 충족되는 경우도 포함하도록 의도되고, 따라서 \"조건이 충족되는지 또는 어느 정도까 지 충족되는지\" 또는 이와 유사한 의미로 이해되어야 한다. 시스템은 이제 특히 작업 레벨에 의한 입력 값 처리 에 영향을 미치기 위해서, 평가를 기반으로 작업 유닛의 출력 값을 거부하거나 아니면 수정하도록 설정될 수 있 다. 제1 평가의 판정은 제2 평가의 판정에 필요한 시간에 비해 짧은 시간에 행해지는 것이 바람직하다. 따라서, 상 대적으로 적은(특히 1000 미만, 바람직하게는 100 미만) 제1 조건 및 상대적으로 많은 제2 조건이 주어진다. 따 라서 제1 평가는 대충의 조건이 충족되었는지 또는 어느 정도 충족되었는지를 나타내는 반면, 제2 평가는 세밀 한 제2 조건이 제1 조건에 비해 충족되었는지 여부 또는 어느 정도 충족되었는지를 나타낸다. 제1 및 제2 평가(output21, output22)는 이제 제1 및 제2 입력 값 Xi(t1), Xi(t2)의 처리에 영향을 준다. 특히, 제1 평가는 제1 입력 값으로부터 제1 출력 값의 결정에 영향을 미치고, 제2 평가는 제2 입력 값으로부터 제2 출 력 값의 결정에 영향을 미친다.전체 또는 총 출력은 어떠한 경우에도 작업 레벨의 제1 및/또는 제2 출력 값에 기초한다. 제1 또는 제2 출 력 값을 특정 시간의 총 출력으로 간주할지 여부는 작업 레벨에 따라 결정되는 것이 바람직하지만, 작업 레벨의 구성 요소로 간주될 수 있는 타이머에 의해 제어될 수도 있다. 본 명세서에서 제1 및 제2 출력 값의 조합을 총 출력으로 사용하는 것도 생각할 수 있다. 따라서, 평가 레벨에 의한 작업 레벨의 영향은 전체 출력에 간접적인 영향만 미치며; 이러한 의미에서 제1와 제2 조건은 절대적인 제한을 나타내지 않는다. 따라서, 입력 값을 처리할 때, 제1/제2 출력 값(output11, output12)은 제1/2 입력 값 Xi(t1), Xi(t2)의 워킹 레벨에 의해 결정되고, 제1/2 상황 데이터 Y(t3),Y(t4)은 제1/제2 출력 값의 투영 레벨에 의해 결정 되고, 제1/제2 평가(Output21, Output22)는 제1/제2 상황 데이터로부터 결정되고, 다음에 작업 레벨에 영향을 미친다. 총 또는 전체 출력은 제1/제2 출력 값으로부터 결정된다. 이 프로세스는 여러번 반복되고, 이 때 작업 레벨은 평가 레벨의 평가에 영향을 받아 전체 출력 또는 제1/제2 조건에 따른 제1 및/또는 제2 출력 값을 결정하려고 한다. 일반적으로, 이러한 모든 조건을 충족하는 전체 출력 (또는 제1 및/또는 제2 출력 값)을 찾을 수 없는 입력 값 Xi가 발생할 수 있다. 이 경우, 전체 출력(또는 제1 및/또는 제2 출력 값)이 더 이상 반복 마다 또는 특정 기간 동안, 즉 지정된 허용 오차 내에서만 크게 변경되지 않는다고 판단되면 반복 프로세스를 중단할 수 있다. 그런 다음 시스템의 마지막 총 출력이 최종 총 출력으로 사용된다. 그러면 최종 총 출력은 평가 레벨의 영향이나 조언에 따라 작업 레벨에 의해 찾을 수 있는 최상의 총 출력을 형성한다. 종료는 또한 타이머(예를 들어, 실시간 시스템)에 의해 시간 제어될 수 있으며, 이 경우 마지 막 총 출력도 사용된다. 각 반복은 제1 및 제2 입력 값, 제1 및 제2 출력 값, 제1 및 제2 상황 데이터, 제1 및 제2 평가 및 총 출력을 포함할 수 있는 대응하는 데이터를 생성한다. 특히, 이들 요소의 일부 또는 바람직하게는 전부가 전체 또는 전 체 세트로 지칭되는 데이터 세트를 형성할 것으로 예상된다. 대체로, 총 또는 전체 레코드의 시퀀스 또는 총 또는 전체 시퀀스는 반복 시퀀스에 따라 생성된다. 총 세트 또 는 총 세트의 시퀀스는 총 시퀀스 메모리에 저장될 수 있다. 이는 총 시퀀스 메모리를 세 가지 레벨에 연 결하는 점선으로 표시된다. 저장하는 동안, 전체 기록은 바람직하게는 타임스탬프 및/또는 번호가 매겨지고/되 거나 순서에 따라 배열된다. 바람직하게는, 입력 값이 실질적으로, 즉 미리 결정된 허용 오차 이상으로 변경될 때마다 전체 레코드의 새로운 시퀀스를 저장하기 시작하도록 의도된다. 저장된 완전한 세트의 시퀀스는 특히 전 체 시스템에 의한 입력 값 처리를 추적하는 데 사용될 수 있다. 조건 및 이들의 전체 시스템에 미치는 영향의 설명 (제1/제2) 조건은 예를 들어 상황 데이터가 특정 값 범위 내에 있는지 여부를 확인하는 간단한 조건일 수 있다. 그러나 (제1/제2) 조건은 예를 들어 규범적 규칙 R1 내지 Rn의 형태로 더 복잡할 수도 있다. (제1/제2) 조건은 기술적 조건일 수 있다. 예를 들어, (예를 들어 진동 센서 데이터 및 출력을 기준으로 작업 레벨에 따라 분석되는) 모터의 속도가 허용 속도 범위 내에 있는지가 확인될 수 있다. 추가 규칙은 (센서 데이 터를 사용하여 작업 레벨에서도 기록되는) 작동 상태에 따라 이러한 속도 검사를 수행하는 것이다. 또한 규칙은 \"아무도 죽일 수 없다\"(R1), 또는 \"어떤 사람도 자유에 제한을 받을 수 없다\"(R2) 또는 \"거짓말을 할 수 없다\"(R3)와 같은 비기술적인 성격일 수도 있다. 규칙 이행 또는 규칙 위반은 일반적인 매개변수, 0 = 규 칙 위반 없음, 1 = 규칙 위반 또는 더 세밀하게 등급이 매겨짐 중 하나를 통해 엔지니어링할 수 있다. 이러한 규칙은 제1 조건으로 구현될 수 있으며 규칙 이행 또는 규칙 위반의 매개변수화는 제1 평가에 해당한다. 그런 다음 제2 조건은 규칙 R1 내지 Rn의 규칙을 규칙 분류 K1 내지 Kn로 미세하게 세분화하는 것을 나타낼 수 있다. 이들은 규칙에 대한 예외, 추가 또는 변경 사항이다. 이들은 이러한 규칙에 대한 예외, 추가 및 대안이다. 이러 한 규칙 분류는 초기에 R1에 대한 예외가 규칙 분류 K1에 주어지고, R2에 대한 예외는 K2에, 등의 방식으로 구 성된다. 규칙 분류에 이름이 지정된 일부 상황에서, 해당 규칙 Rx가 깨질 수 있다. 규칙 R3의 예시적인 규칙 분 류 K1y는 다음과 같을 수 있다: \"진실을 말했을 때 심각한 피해를 입게 되면 거짓말은 허용된다\". 규칙은 여전 히 원칙적으로 적용되지만, 규칙 분류가 적용되지 않는 한 우선 진실로 받아들여진다. 따라서 제2 조건(규칙 분 류 K1 내지 Kn)은 제1 조건(규칙 R1 내지 Rn)을 더 정교하게 표현한 것이다. 제1 및 제2 조건이 저장된 메모리가 제공될 수 있다. 메모리 또는 규칙 R1 내지 Rn의 구조화 및 규칙 분류는 특 히 도 5에 도시된 것에 대응할 수 있으므로, 이에 의해 상대적으로 대략적인 규칙 R1 내지 Rn은 메모리에 저장되고 상대적으로 미세한 규칙 분류 K1 내지 Kn은 메모리에 저장되고 레벨로의 보다 미세한 세분화가 메모리에 저장되고, 이 때 m은 바람직하게는 n과 동일하다. 바람직하게, 규칙 및/또는 규칙 분류, 즉 제1 및 특히 제2 조건은 블록체인에 저장되고, 이 때 규칙은 소위 스 마트 계약의 형태로 구현된다. 스마트 계약은 규칙 또는 규칙 분류를 매핑하고 준수 여부를 확인하는 컴퓨터 프 로토콜로 간주될 수 있다. 규칙 분류가 사용되는 경우, 이 조건은 문서화되고 상황에 따라 다른 메모리(특히 전체 시퀀스 메모리)에 저장되며, 이는 바람직하게는 이 문서가 수정될 수 없도록 블록체인에서 수행된다. 따라서 전체 시퀀스 또는 전 체 평가 시퀀스가 저장된다. 규칙 R3의 원칙 타당성은 규칙 분류에 의해 의문시되지 않는다. 작업 레벨 또는 전 체 시스템의 작업 모드에서, 일련의 조치의 경우 작업 레벨과 평가 레벨 간의 반복적인 조정 및 평가 체인으로 이어지므로, 상황에 관련된 조정 해결순서가 블록체인에 저장되고, 이 때 평가단이 실무자에게 규칙과의 충돌을 지적하고 이들의 수정에 대해 제안하지만 향후 조치를 결정하지는 않는다. 조치 결정, 즉 시스템의 전체 출력은 외부 상황 및 솔루션 전략과 직접 관련되므로 작업 레벨을 통해서만 이루어지는 반면에, 평가 레벨은 투영 레벨 을 통해 이미 압축된 정보를 간접적으로만 제공하는 것이 바람직한다. 이 기본 원칙의 예시적인 확장은, 평가 레벨이 규칙 R1...n을 위반할 위험이 있는 충돌 상황의 검색시 전체 시 퀀스(바람직하게 블록체인 결정 경로)도 포함하고 이전에 수행된 솔루션을 확인하는 것이다. 자가 학습 시스템 의 측면에서, 다시 오류를 행하지 않기 위해서 취한 조치의 성공 또는 실패를 전체 시퀀스의 각 문서(가급적 블 록체인 문서)에 대해 기록해야 한다. 원칙의 추가 확장에서, 예를 들어 규칙 R1과 충돌하는 경우, 이전에 알려지지 않은 조합이 있는지 확인하여 상 황을 해결하기 위해서, 연결 또는 결합, 수정 등에 대한 규칙 분류 K1 및 이들의 하위 분류 뿐만 아니라, 모든 바람직한 분류에서 검색하는 것이 가능한데, 다른 규칙 분류가 실제로 규칙 R1에 속하지 않는 경우에도 더욱 그 렇다. 원칙을 더 확장하면, 새롭고 성공적인 규칙 분류를 삽입하고, 필요한 경우 더 이상 최신이 아니거나 바람직하지 않은 것으로 입증된 기존 규칙 분류를 삭제함으로써, 성공 또는 실패 시 규칙 분류 메모리를 변경할 수 있다. 그 결과 엄격한 규칙 세트가 있는 자가 학습 평가 시스템(전체 시스템), 및 동시에 유연한 분류 시스템이 생성 된다. 이러한 변형은 특히 \"하드 AI 시스템\"의 구현을 가능하게 한다. 전체 시스템의 예시적인 구체적인 설계 도 8은 작업 레벨이 제1 인공 학습 작업 유닛 및 이에 결합된 제2 인공 학습 작업 유닛에 의해 형성 되고 평가 레벨이 제1 인공학습 평가 유닛 및 이에 결합된 제2 인공학습 평가 유닛에 의해 형성되는, 전체 시스템의 예시적인 실시 예를 보여준다. 인공 학습 작업 및 평가 유닛은 각각 특히 함수별로(예: 전달 함 수 ftrans, 활성화 함수 fakt, 전파 함수 및 출력 함수 fout) 및 가중치/가중별로, 함수가 매개 변수에 의해 결정되 는 신경망일 수 있다. 제1 작업 유닛은 제1 입력 값 Xi(t1)으로부터 제1 출력 값(output11)을 결정하도록 설정되며, 즉, 작업 유 닛은 인공 학습 유닛에 따라 훈련된다. 제1 작업 유닛의 함수는 매개 변수, 특히 함수 foutA1(전파 및 출력 함 수), faktA1(활성화 함수), ftransA1(전송 함수) 및 가중치 wiA1에 의해 각각 결정된다. 제2 작업 유닛은 제2 입력 값 Xi(t2)로부터 제2 출력 값(output12)을 결정하도록 설정되며, 즉 그에 따라 훈련된다. 제2 작업 유닛의 기능은 매개변수, 특히 함수 foutA2, faktA2, ftransA2 또는 가중치 wiA2 에 의해 결정된다. 제1 평가 유닛은 제1 상황 데이터 Y(t3)로부터 제1 평가(output21)를 결정하도록 설정된다. 제1 평가 유닛의 기능은 매개변수, 특히 함수 foutB1, faktB1, ftransB1 또는 가중치 wiB1에 의해 결정된다. 제2 평가 유닛은 제2 상황 데이터 Y(t4)로부 터 제2 평가(output22)를 결정하도록 설정된다. 제2 평가 유닛의 함수는 매개변수, 특히 함수 foutB2, faktB2, ftransB2 또는 가중치 wiB2에 의해 결정된다. 2개의 작업 유닛(810, 820) 간 또는 2개의 평가 유닛(830, 840) 간의 결합은 도 1 내지 6과 관련하여 설명한 것 에 대응한다. 따라서, 제1 작업 유닛의 제1 출력 값(output11)을 기준으로, 변조 함수 fmod1_f, fmod1_w가 형 성되고, 이에 의해 제2 작업 유닛의 매개변수(함수 foutA2, faktA2, ftransA2 및/또는 가중치 wiA2)가 변조되므로, 제2 평가 유닛 출력 값(ouput12, 제2 출력 값)의 결정 또는 함수가 영향을 받는다. 마찬가지로, 제 1 평가 유닛의 제1 평가(output21)에 기초하여, 제3 변조 함수 fmod3_f, fmod3_w가 형성되고, 이에 의해 제2평가 유닛의 매개변수(함수 foutB2, faktB2, ftransB2 또는 가중치 wiB2)가 변조되므로, 제2 평가 유닛의 출력 값 (Ouput22, 제2 평가)의 결정 또는 함수가 영향을 받는다. 전체 시스템은 바람직하게는 도 7과 관련하여 언급된 것이 적용되는 투영 레벨을 다시 포함한다. 게다가, 선택적 메모리 요소가 투영 메모리로서 투영 레벨에 할당되고, 여기서 데이터, 특히 상황 데이터뿐만 아니라 투영 레벨로부터 또는 투영 레벨에 의한 제1 및 제2 출력 값이 적어도 일시적으로 저장될 수 있다. 이 데이터의 저장 기간은 일반적으로 다음과 같이 결정될 수 있지만, 예를 들어 제1 평가 유닛에 의해 유닛들 중 하나에 의해 결정될 수도 있다. 실시 예에 따라, 투영 레벨 메모리는 본질적으로 단기 메모리의 역할을 할 수 있으며, 그 컨텐츠는 필요에 따라 확인, 삭제, 덮어쓰기 및/또는 각 신경망 또는 유닛의 메모리 요소와 같은 메 모리로 전송될 수 있다. 따라서, 투영 메모리는 예를 들어 특정 수의 입력 또는 특정 양의 데이터 이후에 각각의 경우에 메모리가 \"가득 찬\" 링 메모리로 설계될 수 있고, 따라서 이전 데이터는 처음부터 덮어쓰여지고, 이는 링 구조에 해당한다. 유사하게, 도시된 실시 예는 전체 시퀀스 메모리를 다시 포함하며, 이에 대해 도 7과 관련하여 언급된 것 이 적용된다. 점선은 다시 전체 시퀀스 메모리가 두 작업 유닛, 두 평가 유닛, 및 투영 레벨로부터 데이터 를 수신하거나 이들과 데이터를 교환할 수 있고, 유닛은 바람직하게는 전체 시퀀스 메모리에 저장된 데이터에 액세스할 수 있음을 나타낸다. 작업 레벨(즉, 제1 및 제2 작업 유닛) 또는 평가 레벨(즉, 제1 및 제2 평가 유닛)에 의해 또는 그 안에 형성된 제1 및 제2 평가에 의해 형성된 제1 및 제2 출력 값의 영향은 다음과 같이 구현된다. 도 8에 도시된 실시 예에 따르면, 제1 평가 유닛의 제1 평가(output21)에 의해 제1 작업 유닛에 영향 을 미치도록 의도된다. 이것은 한편으로 제1 작업 유닛의 (Xi(t)에 더하여) 추가 입력 값으로서 제1 평가 또는 이들로부터 도출된 값을 사용함으로써 달성될 수 있으며, 이들은 제1 평가 입력 값이라고 부를 수 있다. 이 경우, 제1 평가는 입력 값 Xi(t)의 분석 시작 시 중립 값으로, 예를 들어, 모든 제1 조건이 충족되었음을 나 타내는 값으로 초기화되어야 한다. 예를 들어 입력 값이 크게 변경되는 경우, 중립 값을 사용한 이러한 초기화 는 추가 프로세스에서 다시 수행할 수도 있거나, 작업 유닛 중 하나에서 다른 작업 유닛으로(특히 제2 작업 유 닛에서 제1 작업 유닛으로) 지배력이 전달되는 경우, 시간적 제어도 생각할 수 있다. 추가적으로 또는 대안적으로, 제1 평가 유닛은 바람직하게는 특히 도 1 내지 6과 관련하여 상술한 결합에 따라 제1 작업 유닛에 결합될 수 있다. 따라서 제1 평가 유닛의 제1 평가(output21)를 기초로, 제2 변조 함수 fmod2_f, fmod2_w는 제1 작업 유닛의 매개변수, 즉 foutA1, faktA1, ftransA1 및/또는 가중치 wiA1을 변 조함으로써 형성될 수 있으므로, 제1 작업 유닛의 출력 값(Ouput11)의 획득 또는 함수에 영향을 준다. 또한, 제2 평가는 제2 작업 유닛의 함수에 영향을 미친다. 이는 제2 작업 유닛의 (Xi(t)에 더하여) 추가 입력 값(제2 평가 입력 값)으로서 제2 평가 또는 이들로부터 도출된 값을 사용함으로써 행해질 수 있다. 이 경우, 해당하는 제2 평가는 입력 값 Xi(t)의 처리 시작시 중립 값으로 초기화되어야 한다. 제2 조건이 모두 충족되었음을 나타내는 값이 있다. 예를 들어 입력 값이 크게 변경되는 경우 중립 값을 사용한 이러한 초기화는 추가 과정에서 다시 수행할 수 있거나, 지배력이 작업 유닛 중 하나에서 다른 작업 유닛으로 (특히 제1 작업 유 닛에서 제2 작업 유닛으로) 전달되는 경우, 시간 제어를 다시 생각할 수 있다. 또한 (도면에 도시되지 않음), 제2 평가 유닛의 제2 평가(output22)에 기초하여, 제4 변조 함수 fmod4_f, fmod4_w는 제2 작업 유닛의 출력 값(Ouput12)의 획득 또는 함수에 영향을 미치기 위해, 제2 작업 유닛의 매 개변수, 즉 foutA2, faktA2, ftransA2 및/또는 가중치 wiA2가 변조됨에 따라 형성될 수 있다. 하지만, 제4 변조 함수에 의해 변조된 제2 작업 유닛의 매개변수(함수 및/또는 가중치) 세트는 제1 변조 함수에 의해 변조된 제2 작업 유닛의 매개변수(함수 및/또는 가중치) 세트와 분리되어야 한다. 따라서, 제2 평가 유닛은 제1 작업 유닛 에 의해 변조되지 않은 제2 작업 유닛의 매개변수(함수 및/또는 가중치)만을 변조해야 한다. 이는 불안정성을 방지하는 데 유리한다. 제2 작업 유닛이 소위 \"딥 러닝\"에서 사용할 수 있는 것과 같이 여러 숨겨진 계층이 있 는 신경망인 경우, 예를 들어, 하나 이상의 입력측 계층은 제1 변조 함수를 통해 변조될 수 있는 반면(즉, 계층 의 뉴런의 함수 및/또는 가중치가 변조됨), 하나 이상의 출력측 계층은 제4 변조 함수에 의해 변조된다. 비유하 자면, 제1 변조 함수에 의한 제1 출력 값을 갖는 제1 작업 유닛은 제2 작업 유닛에서 입력 값의 기본 분석에 영 향을 미치는 반면, 제4 변조 함수에 의한 제2 평가를 갖는 제2 평가 유닛은 제2 작업 유닛에서 이 기본 분석에의해 얻은 결과의 분류에 영향을 미칠 것이다. 작업 유닛(810, 820) 및 평가 유닛(830, 840)은 각각 메모리, 특히 분류 메모리를 가질 수 있고, 여기에 분류 또는 조건이 저장된다. 해당 메모리 구조는 도 5와 관련하여 자세히 설명했다. 도 8에서, 메모리는 예로서 제2 평가 유닛에 대해서만 그려진다. 메모리는 유닛과 별도로 설계되거나 각 유닛에 포함될 수도 있다. 제2 평가 유닛의 메모리(및 또한 제1 평가 유닛의 대응하는 메모리)는 (분류 메모리에 추가하여) 시퀀스 메모리, 보다 구체적으로는 평가 시퀀스를 저장하는 데 사용되는 제2 시퀀스 메모리를 포함할 수 있다. 제2 평 가 유닛의 경우, 이것은 제2 평가 유닛의 입력 값(제2 상황 데이터) 세트 및 제2 평가 유닛에 의해 그로부터 획 득된 제2 평가 세트를 각각 포함하는 제2 평가 세트를 포함하는 하나(또는 그 이상)의 제2 평가 시퀀스를 저장 하는 것을 수반한다. 평가 세트에는 각각의 시간 정보가 제공되고/되거나 번호 매기기에 의해 번호가 매겨지거 나 및/또는 그들의 순서에 따라 배열될 수 있다. 마찬가지로 미도시된 제1 평가 유닛의 메모리에는, 제1 평가 유닛의 입력 값(제1 상황 데이터) 세트 및 제1 평가 유닛에 의해 그로부터 획득된 제1 평가를 각각 포함하 는 제1 평가 세트를 포함하는 제1 평가 시퀀스를 저장하는 역할을 유사하게 수행하는 제1 시퀀스 메모리를 포함 할 수 있다. 작업 레벨과 평가 레벨 모두 추가 인공 학습 유닛을 포함할 수 있으며, 이들 각각은 도 6과 같이 결합된다. 따 라서 작업 레벨은 제2 (또는 이전) 작업 유닛의 출력 값에 의해 결정되는 변조 함수를 통해 제2 작업 유닛 (또 는 각각의 이전 작업 유닛)에 결합되는 제3 (및 가능하게는 제4, 제5, ...) 작업 유닛을 포함할 수 있다. 비슷 하게, 평가 레벨은 제2 (또는 이전) 평가 유닛의 평가에 의해 결정되는 변조 함수에 의해 제2 평가 유닛 (또는 각각의 이전 평가 유닛)에 결합되는, 제3 (및 아마도 제4, 제5, ...) 평가 유닛을 포함할 수 있다. 해당하는 n 번째 작업 유닛과 평가 유닛 간의 상호 작용은 제2 작업 유닛과 제2 평가 유닛 간의 상호 작용처럼 발생할 수 있고, 즉, 특히 n번째 평가 유닛은 n번째 작업 유닛에 영향을 미친다. 입력 값의 예시적인 처리 입력 데이터의 결과적인 처리 또는 분석은 예를 들어 아래에 설명되어 있다. 입력 데이터는 작업 유닛(810, 820)에 대한 입력 값을 형성한다. 입력 값은 두 작업 유닛에 대해 동일하거나 예를 들어 시계열의 다른 시간에 서 상이할 수 있다. 입력 값 Xi(t)는 시간에 따라, 예를 들어, 센서 측정 값의 시계열 또는 비디오/오디오 스트 림에 좌우될 수 있고, 이에 의해 작업 유닛은 예를 들어 타이머 또는 지배 전환에 의해 제어되거나 특히 반복 신경망의 경우 지속적으로 제어되는, 특정 시점에서 입력 값 Xi(t1), Xi(t2)를 수신하거나 수락할 수 있다. 처리 유닛은 입력 값의 연속 처리를 수행하거나 특정 시점에서, 예를 들어 타이머 제어 또는 특정 이벤트에서. 지배 력 전환시 시작하여 처리를 수행할 수 있다. 제1 작업 유닛은 입력 값 Xi(t1)으로부터 제1 출력 값(output11)을 결정하고, 이로부터 제1 상황 데이터 (예를 들어, 제1 출력 값 자체 또는 그 일부 또는 그로부터 파생된 값)가 투영 레벨에 의해 형성되고, 이 것은 다음에 제1 평가 유닛의 입력 역할을 하고, 이것은 이들(즉, 제1 상황 데이터)을 평가하고, 즉, 제1 조건이 충족되었는지 확인하고 해당하는 제1 평가(output21)를 생성한다. 제1 평가에 기초하여, 제1 작업 유닛 또는 출력(output11)이 영향을 받는다. (제1 평가에 기초하여) 제1 조건이 충족되지 않거나 어느 정도만 충족된다고 판단되는 경우, 입력 값 Xi(t)는 제1 평가 유닛에 의해 다시 처리될 수 있고, 이로써, 이제 제1 평가의 영향이 고려되므로 (예를 들어, 제1 평가로부터 결정된 제2 변조 함수에 의해 또는 제1 평가 또는 그로부터 도출된 값을 추가 입력 값으로 사용함으 로써) 일반적으로 수정된 제1 출력 값(output11)이 결과되고, 이는 특히 제1 작업 유닛의 적절한 훈련을 통해, 제1 평가의 영향을 받는다. 이것은 제1 조건이 충족되었다고 판단될 때까지 여러 번 반복될 수 있으며, 이 시점에서 제1 출력 값은 시스템 의 (총) 출력 또는 전체 출력 값으로 사용될 수 있다. 이어서, 입력 값은 제2 평가 유닛에 의해 처리될 수 있고 및/또는 지배력이 제2 평가 유닛에 전달될 수 있다. 이렇게 생성된 제2 출력 값은 추가로 또는 대안적으로 지배에 따라 전체 또는 전체 출력이 될 수 있다. 대안으로 또는 추가적으로, 예를 들어 모든 제1 조건을 충족할 수 없거나 예를 들어 실시간 시스템에서 제한된 기간만 사용할 수 있는 경우, 제2 작업 유닛에 의한 처리 및/또는 제2 작업 유닛의 지배력은 또한 바람직 하게 미리 결정된 시간 기간(타이머에 의해 제어됨) 후에, 미리 결정된 반복 횟수에 도달한 후에, 제1 출력 값 이 두 번의 연속적인 반복 사이에 사전 결정된 허용 오차 내에서 더 이상 변경되지 않을 때, 또는 제1 평가가두 번의 연속적인 반복 사이에 미리 결정된 허용 오차 내에서 더 이상 변경되지 않을 때 종료될 수 있다. 이들 의 조합도 생각할 수 있다. 예를 들어 입력 값 Xi가 크게 변경된 경우와 같이 지배력이 제1 작업 유닛로 다시 넘어가면, 이 과정 또는 평가는 필요한 경우 제1 평가를 초기화한 후, 제1 평가 유닛에 의해 다시 수행될 수 있다. 선택적으로, 특히 제2 작업 유닛이 지배한 경우, 상황 데이터는 또한 제2 작업 유닛의 제2 출력 값 (output12)에 기초하여 투영 레벨에 의해 형성되고 제1 평가 유닛에 의해 평가될 수 있으며, 즉, 제2 출력 값이 제1 조건에 부합하는지 여부가 확인된다. 그렇지 않거나 부분적으로만 그런 경우, 제2 작업 유닛은 제1 평가가 제1 작업 유닛에 영향을 미치는 것과 유사하게, (이제 변경된) 제1 평가의 영향을 받을 수 있고, 이 에 의해 본 명세서에서 어떠한 변조 함수도, 특히 제1 변조 함수에 의해 변조되는 제2 작업 유닛의 매개변 수, 즉 함수 foutA2, faktA2, ftransA2 및/또는 가중치 wiA2를 변조하는 어떤 변조 함수도 사용되지 않아야 한다. 제1 평가 유닛에 의해 형성된 제1 평가도 결합을 통해, 즉, 제3 변조 함수 fmod3_f, fmod3_w를 통해 제2 평가 유닛의 함수에 간접적으로 영향을 미친다. 제2 평가 유닛은 투영 레벨에서 형성된 제2 상황 데이터(제1 평가 유닛에 의해 수신된 제1 상황 데이터와 동일할 필요는 없음)를 입력 값으로서 수신한다. 바람직하게는, 이러한 제2 상황 데이터는 적어도 제2 인공 학습 유닛의 제2출력 값(output12)을 기반으로 형성되며, 즉, 제2 상황 데이터는 제2 출력 값의 일부 또는 전부 또는 또한 그로부터 도출된 값을 포함할 수 있다; 이에 따라, 상황 데이터는 또한 적어도 부분적으로 제1 인공 학습 유닛의 제1 출력 값(output11) 또는 다른 값에 기초하여 형성될 수 있다. 제2 작업 유닛이 입력 값 Xi(t2)을 처리하고/하거나 지배력이 제2 작업 유닛으로 넘어간 경우, 제2 상황 데이터는 투영 레벨에 의해 형성되고, 이는 제2 작업 유닛의 제2 출력 값(output12)에 적어도 부분적 으로 기초한다. 이 제2 상황 데이터는 제2 평가를 형성하는 제2 평가 유닛에 대한 입력 값의 역할을 한다. 제2 평가에서 모든 제2 조건이 충족되는 것으로 표시되면, 제2 출력 값은 예를 들어 시스템의 총/전체 출력으로 사용할 수 있다. 제2 평가에 의해 제2 작업 유닛에 영향을 주어, 일반적으로 적어도 제2 평가에서 모든 제2 조건이 충족되지 않 았으며 제2 작업 유닛이 그에 따라 훈련되었다고 표시되는 경우, 수정된 제2 출력 값(output12)이 결과되고, 이 로 인해 수정된 상황 데이터가 투영 레벨에 의해 형성되고, 필요한 경우 이것은 제2 평가 유닛에 의해 확인되어 수정된 제2 평가로 이어진다. 예를 들어, 미리 정의된 반복 횟수에 도달하거나, 미리 정의된 시간이 경과하거나, 제2 연속적인 반복 사이에서 미리 정의된 허용 오차 내에서 제2 출력 값이 더 이상 변경되지 않을 때까지 여러 번 반복될 수 있다. 이들 또 는 다른 조건의 조합도 생각할 수 있다. 따라서 제2 평가 유닛과 제2 작업 유닛 사이의 상호작용은 제1 평가 유닛과 제1 작업 유닛 사이의 상호작용에 대응한다. 그러나 또한 두 평가 유닛의 결합으로 인해, 제2 평가 유닛에 의한 평가, 즉, 제2 평가는 제1 평가 유닛에 의해 획득된 제1 평가에 의해 영향을 받는다. 따라서, 타이밍은 바람직하 게는 제1 작업 유닛과 제1 평가 유닛 사이의 상호작용이 먼저 발생하는 방식으로 제어된 다음에 제2 작업 유닛 과 제2 평가 유닛 간의 상호 작용이 발생한다. 앞에서는 입력 값의 처리를 개별 인공 학습 유닛에서 순차적으로 처리하는 과정으로 제시하였지만, 유닛 (제1, 제2 작업 유닛, 제1, 제2 평가 유닛)는 원칙적으로 서로 비동기적으로 작동할 수 있고, 즉, 각 유닛은 현재 사 용 가능한 입력 데이터 또는 변조(일부 다른 유닛의 출력)를 사용하여 자체 속도에 따라 작동할 수 있다. 시간 동기화가 제공될 수 있지만 반드시 그런것은 아니다. 유닛은 그에 따라 서로 병렬로 작동할 수 있다. 훈련 전체 시스템의 예시적인 훈련이 아래에 설명되어 있다. 위에서 설명한 것처럼 감독 학습에서는, 입력 값 및 해 당 (즉, 각 입력 값과 연관된) 원하는 출력 값(즉, 알려진 훈련 데이터)이 제공되고 상기 인공 학습 유닛에 의 해 결정된 출력 값과 원하는 출력 값 사이의 편차를 나타내는 오차 척도에 관련하는 훈련 동안 오차는 최소화된 다. 사용되는 일반적인 오류 측정은 평균(가중 가능) 제곱 오류이다. 인공 학습 유닛의 매개 변수(예: 가중치) 는 오류를 최소화하기 위해 훈련 중에 변경된다. 이 절차는 당업자에게 그 자체로 알려져 있다. 시스템은 먼저 작업 레벨과 평가 레벨이 개별적으로 훈련되는 방식으로 훈련된다. 이들은 \"인공/인공 학습 시스 템\"을 나타내며, 이들의 훈련은 도 1 내지 5와 관련하여 설명되었다. 따라서 앞서 언급한 지도 학습에서, 작업 레벨을 훈련할 때, 입력 값(센서 데이터 포함)은 입력 값으로 사용되고 해당 (알려진) 원하는 출력 값(제어 매 개변수, 상태 매개변수)은 출력 값으로 사용되고, 평가 레벨을 훈련할 때, (출력 값 또는 제어 매개변수/상태 매개변수로 구성되는) 상황 데이터는 입력 값으로 사용되며 (조건이 충족되는 정도를 나타내는) 해당하는 (알려 진) 원하는 평가는 출력 값으로 사용된다. 또한, 작업 레벨과 평가 레벨의 연동 운영 시, 조건을 조정하거나 보완할 수 있다(아래 참조). 이 프로세스는 작업 및 평가 레벨, 즉 전체 시스템의 공동 학습으로 볼 수 있다. 작업 레벨과 평가 레벨에 대해서는, 도 8에 도시된 실시 예를 참조하여 두 레벨 각각에서, 제1 인공 학습 유닛 (810, 830) 및 제2 인공 학습 유닛(820, 840)이 포함되며, 이들은 도 1 내지 5와 유사하게 결합된다. 이 때, 특 히 한 레벨 내에서, 2개의 (제1/제2) 유닛 각각의 독립적인 훈련 (즉, 결합된 유닛과 개별적으로 및 독립적으로)이 초기에 수행되고, 입력 값의 동일한 훈련 데이터 세트가 두 유닛 모두에 사용될 수 있거나 입력 값의 다른 훈련 데이터 세트가 사용될 수 있다. 제1 유닛와 제2 유닛의 차이점은 관련된 원하는 출력 값이고 (입력 값에 해당, 즉 훈련에서 바람직하게 달성되어야 하는 값), 이에 의해 제2 유닛의 원하는 출력 값은 바람 직하게는 제1 유닛의 원하는 출력 값의 어떤 종류의 개선을 나타낸다. 예를 들어, 제1 유닛의 원하는 출력 값은 제2 유닛의 원하는 출력 값의 진정한 (사소하지 않은) 부분 집합이라고 생각할 수 있고, 또한 특정 출력 값의 편차에 대해 서로 다른 가중치가 오류 측정에 사용되는 것으로 예상할 수 있다. 또한, 결합된 (제1/제2) 유닛의 합동 훈련을 수행할 수 있다. 여기서, 제1 유닛과 제2 유닛의 오차가 포함될 수 있으므로, 이에 의해 제1 유닛 과 제2 유닛의 오차는 서로 다르게 가중될 수 있다. 합동 훈련에서 제1 유닛의 출력 값과 제2 유닛이 영향을 받 는 변조 함수의 상관관계가 또한 생성될 수 있다. 제1/제2 시퀀스 메모리 제1/제2 평가 시퀀스를 저장하면 평가 유닛의 \"결정\"을 추적할 수 있고, 필요한 경우, 예를 들어 원하는 대로 작동하지 않거나 기능하지 않는 경우, 평가 시퀀스를 사용하여 추가 훈련을 수행하는 것이 가능해진다. 더 나아가, 평가 유닛(830, 840)은 입력된 상황 데이터 Y(t3), Y(t4)의 비교를 수행할 수 있으며, 평가 레코드 는 평가(output21, output22)의 결정 전 또는 그와 동시에 평가 시퀀스 또는 세트로 시퀀스 메모리에 저장되고, 즉, 입력된 상황 데이터는 저장된 평가 기록의 해당 상황 데이터와 비교된다. 동일하거나 유사한 것으로 판명된 경우, 즉 동일하거나 유사한 상황 데이터가 이전에 발생한 경우, 이전 평가는 스코어링 시퀀스에서 읽을 수 있 으며 출력, 즉 현재 상황 데이터에 대한 평가로 사용할 수 있다. 특히, 동일 또는 유사한 상황 자료가 발생한 평가기록 및 해당하는 경우 해당 평가순서에 따라 이어지는 평가기록은 생략할 수 있다. 따라서, 이전 평가는 입력된 상황 데이터 Y(t3), Y(t4)에 대한 현재 평가로 사용되며, 이것은 각 평가 시퀀스에서 나중에 발생한 평 가 레코드에서 가져온다(이를 위해, 평가 기록은 유리하게 타임 스탬프와 함께 제공되고, 발생 순서에 따라 번 호가 매겨지고 및/또는 배열된다). \"유사하다\"는 각각의 경우에 적합하게 선택된 공차의 의미로 이해되어야 한 다. 평가가 스킵된 평가 레코드의 미리 정의된 수에 도달했음을 나타낼 때까지 및/또는 시간 정보가 평가 순서 내에 서 미리 정의된 기간이 경과했다는 것을 나타낼 때 까지 최대 평가 레코드 수를 건너뛸 수 있고 및/또는 각각의 평가 시퀀스에서 평가 유닛(상황 데이터)의 입력 값은 평가 시퀀스의 이전 항목과 비교하여 미리 정의된 허용 오차 내에서 변경되지 않는다. 이 절차는 프로세스 흐름의 가속화를 가져올 수 있다. 제1 및/또는 제2 평가 시퀀스를 제1 또는 제2 시퀀스 메모리에 저장하는 것은 조작으로부터 보호하기 위해 암호 학적으로 보안된 형태로 수행되는 것이 바람직한다. 특히, 이를 위해 블록체인 사용이 제공되며, 이로 인해 시 퀀스의 항목(예를 들어, 제1 평가 시퀀스에 대한 하나 이상의 평가 레코드)이 블록체인의 블록을 형성한다. 따 라서 블록은 각각의 경우에 적어도 하나의 평가 기록을 포함하고 블록체인 원칙에 따라 이전 블록에 저장된 이 전 평가 기록의 시퀀스에 연결된다. 복잡성 구조 바람직하게는 작업 레벨 및 평가 레벨의 복잡성 구조는 특히 도 1 및 5와 관련하여 설명된 대로 설계되고, 즉, 제1 작업 유닛은 상대적으로 대략적인 분석을 수행하거나 입력 값을 상대적으로 적은 수의 클래스로 분할하는 것을 수행하고, 이에 비해 제2 작업 유닛은 상대적으로 많은 클래스 또는 하위 클래스 및 추가 계층 레벨으로 비교적 정밀한 분석 또는 분할을 수행하고, 상기 제1 평가 유닛은 또한 상기 제1 상황 데이터 또는 상기 제1 출 력 값이 상대적으로 대략적인 조건을 충족하는지 여부를 확인하고, 상기 제2 평가 유닛은 상기 제1 상황 데이터또는 상기 제1 출력 값이 상대적으로 대략적인 조건을 충족하는지 여부를 확인하고, 제1 평가 유닛도 제1 상황 데이터 또는 제1 출력 값이 상대적으로 대략적인 조건을 충족하는지 여부를 확인하고, 제2 평가 유닛도 제2 상 황 데이터 또는 제2 출력 값이 상대적으로 미세한 조건을 충족하는지 여부를 확인한다. 제1 평가 유닛은 비교적 적은 레벨 및 클래스로 설계된 분류 메모리(미도시)를 할당받을 수 있다. 본 예시 에서, 제1 평가 유닛에 대한 레벨 및/또는 클래스의 수는 분석 유닛으로 제공되는 제2 작업 유닛에 대한 것보다 훨씬 더 적다고, 예를 들어, 하나 이상의 크기만큼 적다고 가정된다. 유사하게, 제2 평가 유닛 에 대한 레벨 및/또는 클래스의 수는 제1 평가 유닛에 대한 레벨 및/또는 클래스의 수보다 훨씬 더 클 수 있다. 또한, 제2 작업 유닛에 대한 레벨 및/또는 클래스의 수는 제1 작업 유닛에 대한 레벨 및 /또는 클래스의 수보다 상당히 클 수 있다. 메모리는 더욱 다를 수 있지만, 이 경우 메모리 크기와 복잡성 사이 의 명확한 비대칭이 일반적으로 지배한다. 조건 조정 또는 보완 도 7과 관련하여 설명된 바와 같이, 전체 시스템이 제1/제2 출력 값, 즉 전체 출력을 찾지 못하는 경우가 있을 수 있으므로, 모든 제1 및 제2 조건과 각각 일치하는 제1/제2 상황 데이터가 도출된다. 제1 작업 유닛에서 제2 작업 유닛으로, 이에 상응하는 제1 작업 유닛에서 제2 작업 유닛으로의 지배적 전이로 인해, 이는 특히 시스템 의 궁극적인 전체 출력을 나타내는 제2 출력 값 또는 제2 상황 데이터와 관련된다. 따라서 바람직하게는 조건, 바람직하게는 제2 조건의 변경 또는 보완을 수행하도록 의도되므로, 이들 경우, 해 당 출력 값 또는 보완된 조건 중 적어도 일부에 대해, 보완된 조건은 충족된 것으로 간주된다. 따라서 향후 입 력 값의 처리에 영향을 미치는 시스템의 적응이 발생한다. 그러나 바람직하게는 이러한 조건의 추가는 모든 조건이 충족되지 않은 경우에는 수행되지 않고, 특정 조건이 충족되는 경우에만 수행된다. 한 가지 가능한 조건은 모든 조건의 특정 수 또는 백분율(예를 들어, 20% 또는 10% 또는 5%)만이 충족될 수 없고, 나머지는 충족된다는 것이다. 조건의 추가는 입력 값의 정상적인 처리 중에 및/또는 전체 시퀀스 메모리에 저장된 전체 시퀀스를 사용하여 특 정 시간 간격으로 영향을 받을 수 있다. 저장된 전체 시퀀스를 사용하는 경우, 조건을 보완하기 위한 전제 조건 으로서, 조건이 동일한 유형의 전체 시퀀스의 특정한 최소 수(예: 10, 50 또는 100)에서 (특정 허용 오차 내) 충족되지 않았다는 것, 즉, 이러한 전체 시퀀스에 대해 (불이행 유형에 따라 가능한 허용 오차를 포함하는) 보 완 조건으로 조건을 보완할 때 조건이 충족되는 것이 간주된다. 신경망인 평가 유닛의 간단한 예에서, 조건이 추가/변경되면, 조건에 해당하는 뉴런의 출력에 값 범위를 추가할 수 있다. 따라서 여기서 뉴런은 조건 중 하나에 할당된다. 예를 들어, 뉴런은 이 뉴런의 수치적 출력이 -1에서 +1 사이의 범위에 있도록 출력 함수를 가지고 있다. 초기 훈련에서, 신경망은 조건이 충족되고 및 조건이 충족 되지 않아 이 범위 밖에 있는 경우, 신경망이 -0.1에서 0.1 사이의 간격에서 값을 출력하도록 훈련되었다. 현재 작업 레벨의 출력에 대한 조건이 충족되지 않는 경우가 발생하면, 즉, 신경망이 간격 [-0.1; +0.1]에 있지 않은 값 R을 출력하는 경우가 발생하고, 조건을 보완하고자 하는 경우, R 값을 유효한 값으로 간격에 추가할 수 있다. 바람직하게, 값 R 자체 및 값 R 주변의 작은 범위, 예를 들어, R±0.01가 추가된다. 이 조건을 추가한 이 유는 상기 조건 중 하나가 충족되었기 때문으로, 예를 들어 이 조건이 충족되지 않은 유일한 하나 또는 소수 중 하나이거나, R±0.01 범위 내의 출력이 여러 전체 시퀀스에서 발생했기 때문이다. 그런 다음 두 간격, 즉 [-0.1; +0.1] 및 [R-0.01; R+0.01]이 있다. 미래의 입력 값을 처리할 때, 신경망의 출 력이 이 두 간격 중 하나에 있으면 해당 조건이 충족된 것으로 간주된다. 더 추가할 경우 이 두 간격에 더 많은 간격을 추가할 수 있으므로, 조건이 일련의 간격으로 표시되도록 한다. 이러한 간격은 평가 유닛의 분류 메모리 에 저장할 수 있다. 물론, 이 예와 유사하게, 조건은 여러 뉴런과 연관될 수도 있으며, 이 경우 뉴런의 출력은 n차원 공간의 하위 집합인 총 값 범위에 있고, 여기서 n은 조건과 관련된 뉴런의 수와 같다. 다음에 조건은 이들 다수의 뉴런의 출 력이 총 값 범위의 하나 이상의 하위 집합(이전 예의 간격에 해당)에 있는 경우 충족된 것으로 간주된다. 그런 다음 이러한 하위 집합을 동일한 방식으로 완료할 수 있다. 원래 조건 및 조건에 대한 각 추가는 평가 유닛의 분류 메모리에 조건/추가와 함께 저장될 수 있는 레벨 S의 표 시와 함께 추가로 제공될 수 있다. 원본은 예를 들어 0번째 레벨 S=0일 수 있다. 추가는 더 높은 레벨, S>0을 갖는다. 그런 다음 관련 평가는 조건이 예를 들어, 레벨을 지정하는 것으로 어느 정도 충족되는지에 대해 나타 낸 수 있다. 또는 0.9S(또는 0.9 대신 1보다 작은 다른 실제 값)와 같은 해당 값을 지정함으로써, 값 1은 원래조건이 충족된 경우, 즉 조건 완전 충족에 해당한다. 추가(S>1)는 이들의 레벨에 따라 조건을 특정 정도까지 (0.9S <1)까지조건을 충족한다. 추가 레벨은 추가를 유발하는 조건이 충족되는 조건 및/또는 수에 따라 결정될 수 있다. 예를 들어 전제 조건이 하나 또는 몇 가지 조건만 충족되지 않는 경우, 레벨은 충족된 조건의 최고 레벨에 1을 더한 것과 같을 수 있다. 단계 또는 레벨을 통해, 소위 조건의 위계가 도입되고, 이에 의해 원래의 조건이 점점 더 세련되고 세분화된다. 레벨 또는 해당 정도에 따라, 특정 출력 값은 다시 작업 레벨에 영향을 미치는 것으로, 평가를 통해 선호된다. 이러한 절차는 원칙적으로 제1 조건과 제2 조건 모두에 대해 수행될 수 있다. 다만, 제2 조건만 보완 또는 변경 하는 것이 바람직하다. 반면에 제1 조건은 변경되지 않은 상태로 유지되어야 하고; 이들은 말하자면 기본적이고"}
{"patent_id": "10-2023-7019741", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "변경 불가능한 조건을 나타낸다. (발명의 내용 섹션에서) 언급한 도덕적 계약과 같은 조건의 예에서, 절대적인 제1 고려사항은 불변한 반면, 상대적인 제2 고려 사항은 실제 총 출력 값에 따라 시간이 지남에 따라 변경될 수 있다. 기계 제어에서 이 방법을 사용하면, 기계의 도덕성은 말하자면 진화한다. 다른 시스템과의 호환성 확인 또한, 두 개의 전체 시스템이 서로 통신할 때, 제1 전체 시스템은 전체 출력 값이 어느 정도인지 평가할 수 있 고/있거나 제2 전체 시스템의 평가는 자체 평가와 호환되고, 즉, 제1 및 제2 조건과 일치한다. 제1 실시 예에 따르면, 제2 전체 시스템은 일반적으로 여러 전체 레코드를 포함하는 전체 시퀀스를 제1 전체 시 스템으로 전송한다. 제1 시스템은 전체 집합에 포함된 입력 값 및/또는 상황 데이터를 자체 작업 또는 평가 레 벨에 대한 입력 값/상황 데이터로 사용하고 그로부터 얻은 제1/제2 평가 및/또는 제1/제2 출력 값을 전송된 전 체 시퀀스에 포함된 해당 값과 비교한다. 이들은 적어도 부분적으로 일치한다면, 제1 전체 시스템은 제2 전체 시스템을 신뢰할 수 있거나 호환 가능한 것으로 간주하고(즉, 제1/제2 조건과 모순되지 않음) 예를 들어, 그로 부터 수신한 분석 데이터(즉, 작업 유닛에서 얻은 데이터)를 정확하거나 호환 가능한 것으로 분류하여 이들을 자체 처리에 사용할 수 있다. 그렇지 않으면, 수신된 데이터가 부정확하거나 호환되지 않는 것으로 분류되어 사 용되지 않거나 일정 범위만 사용된다. 수신된 데이터는 전체 시스템에서 입력 값으로 사용되는 데이터일 수 있 다. 예를 들어, 두 개의 전체 시스템이 두 대의 자율 주행 차량의 제어 시스템으로 포함된 경우, 데이터는 속도, 제동 등을 포함할 수 있다. 한 차량이 다른 차량보다 일정 거리를 두고 주행하는 경우, 전방 차량에 있는 전체 시스템의 신뢰성/호환성에 따라 이 거리를 선택할 수 있다(여기서 평가 유닛에 의해 확인된 조건은 예를 들어 차량마다 다를 수 있는 급제동 시 차량별 제동 감속을 포함한다). 대안적으로 또는 추가적으로 사용될 수 있는 다른 실시 예에 따르면, 질문-답변 과정에서 호환성 검사가 수행될 수 있다. 이 대안에서, 제2 전체 시스템은 전체 시퀀스 메모리를 가질 필요가 있는 것이 아니고, 입력 값에서 출력 값을 생성하는 시스템일 필요가 있다. 이를 위해, 제1 전체 시스템은 전체 시퀀스 메모리로부터 하나 또는 바람직하게는 여러 개의 전체 시퀀스를 취하고 각각의 전체 시퀀스에 대해 그 안에 포함된 입력 값(질문)을 제2 전체 시스템으로 전송한다. 제2 종합 시스템은 이를 처리하고 이에 따라 출력 값을 결정하여 제1 종합시스템으 로 전달한다(답). 제1 전체 시스템은 이 답변을 그 투영 레벨에 제공하거나 가능하면 평가 레벨에 직접 제공하 고, 평가 등급을 통해 제1/제2 평가를 결정한다. 이것은 모든 전체 시퀀스에 대해 반복된다. 모든 전체 시퀀스 에 대한 평가에서 제1/제2 조건이 충족되면 제2 전체 시스템은 호환 가능한 것으로 분류된다. 대안으로 또는 추 가적으로, 전체 시퀀스에 포함된 해당 평가와 제2 전체 시스템의 응답에서 결정된 평가의 비교가 또한 수행될 수 있고, 이에 의해 제2 전체 시스템은 예를 들어 사전 정의된 허용 오차 내에서 사소한 차이가 비교시 찾을 수 있는 경우 호환 가능한 것으로 분류된다. 이러한 접근 방식의 중요한 이점은 또한 조건 자체가 다른 시스템에 공개되지 않는다는 것이다. 이것은 예를 들 어, 조건이 공개적으로 접근할 수 없어야 하는 도덕 윤리적 규칙을 체계화하는 경우, 특히 위에서 설명한 대로 조정되거나 보완된 경우, 장점이 된다. 예를 들어 영업 비밀과 관련된 경제적 측면에도 동일하게 적용된다. 위에서 설명한 호환성 검사의 가능성은 물론 제2 전체 시스템의 입력 및 출력 값의 의미가 제1 전체 시스템에 알려지므로 이들을 자체 작업 및 평가 유닛의 입력/출력에 할당할 수 있다는 것을 의미한다. 자율 주행차의 경 우, 예를 들어 이 할당은 예를 들어, 제조업체별로 지정되거나 표준화된 형식으로 사양으로 제공되거나 인터페 이스로 구현될 수 있다. 투영 레벨에 대한 추가 정보 평가 유닛은 투영 레벨에 존재하거나 투영 레벨에 의해 형성된 상황 데이터를 평가하도록 훈련된다. 상황 데이터는 예를 들어 이미 언급한 바와 같이 입력 데이터 및/또는 2개의 작업 유닛(810, 820) 중 하나로부터의 출력 데이터 및/또는 추가 데이터일 수 있다. 예를 들어, 선택적으로 추가 정보가 있는 출력 데이터만 투영 레 벨에서 처리될 수도 있다. 그러나, 투영 레벨에서는 작업 레벨의 입력 값 Xi(t)이 사용되지 않는 것이 바 람직하다. 작업 유닛(810, 820)의 출력 값(Output11, Ouput12), 즉 작업 레벨만이 상황 데이터를 형성하는데 사 용되는 것이 더 바람직하다. 이런 식으로, 투영 레벨은 작업 평면에서 평가 레벨을 분리하는 것을 달성하고, 이 에 의해 작업 유닛의 입력 값 X(t)는 평가 유닛에 표시되지 않으므로, 평가 유닛에 의한 작업 유닛의 출력 값 평가가 독립적인 형태로 발생할 수 있다. 또한, 데이터가 처리되거나, 예를 들어 투영 레벨 이전에 일부 방식으로 단순화되는 것이 가능하다. 분류 또는 평가에 해당하는 평가 유닛에 의한 상황 데이터 처리에 대응하여, 특히 전체 시스템의 최종 출력 값 및 액추에 이터, 출력 인터페이스 등 대한 관련 신호에 영향을 미치는 작업 레벨에 영향을 주는 다양한 작업 및/또는 전체 시스템, 특히 시스템에 포함된 다른 유닛의 추가 동작에 영향을 미치는 동작에 영향을 주는 동작이 수행될 수 있다. 적어도 하나의 추가 정보가 생성되도록 투영 레벨의 데이터를 서로 연결하는 것도 생각할 수 있다. 또한, 예를 들어 특정 출력 값이 출력된 시간을 나타내는 시간 매개변수가 있을 수 있다. 이러한 시간적 매개변수는 절대 시간 표시를 포함할 수 있지만 현재 평가 시간 또는 다른 기준 시간에 따라 상대적 시간 표시도 포함할 수 있다. 마찬가지로, 고정된 시점이 아니라 유닛의 하나 이상의 입력 및/또는 출력 값이 할당되는 시간적 섹션이 지정될 수 있다. 실제 시간 매개변수에 추가로 또는 대안적으로, 시퀀스는 적어도 데이터의 일부와 연관될 수 있으므로, 투영 레벨에서 명시적인 시간 지정 없이도, 예를 들어 투영 레벨의 출력 값에 대해 할당된 번호 지정 의 형식으로, 존재하는 여러 데이터 값이 어느 시퀀스에서 생성되거나 처리되는지 인식 가능하다. 이런 식으로, 투영 레벨에 존재하는 데이터, 특히 작업 유닛의 출력 값은 예를 들어 시간적 시퀀스를 형성할 수 있다. 선택적으로 이러한 시퀀스는 예를 들어 특정 기간 또는 지정된 출력 값이 정의된 시퀀스에 속하도록 지정 되도록 표시될 수 있다. 추가 처리, 저장 또는 평가를 위해, 이러한 방식으로 형성된 시퀀스가 전체적으로 처리 될 수 있다. 대안적으로, 동일한 시구간 또는 동일한 시퀀스에 속하는 상이한 입력 및/또는 바람직하게 출력 값 은 예를 들어 서로 비교하여 함께 처리될 수 있다. 데이터를 시간의 투영 레벨에 배치하고 다시 액세스될 수 있 는 특정 프로세스 및 시퀀스로 그룹화함으로써, 메모리와 같은 구조가 가능해질 수 있다. 타이머가 제공될 수 있고(미도시), 이는 작업 유닛들 사이의 지배를 제어하기 위해 도 4와 관련하여 설명된 아이디어에 따라 이 시 스템에서 또한 사용될 수 있다. 투영 레벨에 바람직하게 제공되는 메모리는 예를 들어, 휘발성 메모리 요소로서 또는 링 메모리 또는 다른 단기 메모리 형태의 비휘발성 메모리 요소로서 설계될 수 있다. 투영 레벨에서 처리될 데이터는 이 투영 메모리에 저장될 수 있다. 데이터의 저장 기간과 저장할 데이터의 선택은 매우 다르게 설계될 수 있다. 예 를 들어 초기에 고정된 저장 기간이 지정될 수 있다. 이 시간이 지나면, 투영 메모리의 데이터를 삭제 및/또는 덮어쓸 수 있다. 추가적으로 또는 대안적으로, 시스템의 일부, 예를 들어 평가 유닛(830, 840) 중 하나 또는 둘 모두는 투영 메모리의 데이터가 적어도 부분적으로 시스템의 다른 요소로 전달되는지 여부에 대해 결정을 내릴 수 있다. 데이터 손실을 방지하기 위해, 이러한 결정은 미리 결정된 저장 기간이 만료되기 전에 이루어질 수 있 다. 예를 들어, 평가 유닛 중 하나는 투영 레벨 또는 투영 메모리에 저장된 데이터의 일부 또는 전부가 장 기간 저장을 위해 다른 저장 요소로 전달되어야 한다고 결정할 수 있다. 예를 들어 이것은 작업 유닛의 저장 요 소 중 하나일 수도 있다. 나중에 새로운 상황을 평가하는 시스템의 다른 유닛의 메모리에 저장함으로써 이미 평 가된 상황을 경험과 유사한 방식으로 통합할 수 있다. 그러나 원칙적으로, 별도의 메모리 모듈(미도시)이 또한 장기 메모리로 제공될 수 있으며, 여기서 유닛 중 하나에 의해 어느 유닛이 저장된 데이터에 어느 정도까지 액 세스할 수 있는지가 고정 또는 정의될 수 있다. 본 발명의 추가 세부사항 및 실시 예가 이하 설명된다. 제1 및/또는 제2 평가를 기반으로, 제1 및/또는 제2 작 업 유닛의 제1 및/또는 제2 출력 값이 유효한 범위 또는 매개변수 내에 있는지 또는 특정 규범 규칙을 충족하는 지, 즉, 유효한(조건 또는 규칙의 의미에서) 솔루션으로 허용 가능한지 또는 적어도 어느 정도까지 허용 가능한 지 결정할 수 있다. 예를 들어, 이전 예제에서 시스템의 총 출력 값으로 결정된 제1 및/또는 제2 작업 유닛의 현재 출력 값이 허용 범위를 벗어났다고 결정되면, 이 평가를 기준으로 전체 시스템의 반응을 방지하거나 중지 할 수 있으므로, 예를 들어, 제1/2 작업 유닛의 이전에 획득된 제1/2 출력 값이 액추에이터 또는 인터페이스로 전달되지 않도록 한다. 허용되지 않거나 유효하지 않은 것으로 평가된 출력 값은 폐기될 수 있지만, 예를 들어,비교에 의해서, 나중 상황에서 다시 사용할 수 있도록 이 평가와 함께 저장될 수도 있다. 이와 같이, 이미 유효 하지 않은 것으로 인식된 솔루션을 추구하지 않거나 우선순위가 낮은 솔루션만 추구함으로써 나중에 감지된 상 황에 대한 평가를 단순화하거나 가속화할 수 있다. 또는 예를 들어 모든 조건을 충족하는 솔루션을 찾을 수 없 는 경우 제1/제2 출력 값을 전체 출력으로 사용할 수도 있고, 이로써 본 발명에 따른 작업 레벨과 평가 레벨 사 이의 상호 작용은 최상의 가능한 솔루션을 찾는 것을 보장한다. 출력 값과 솔루션은 허용 가능성에 대해서 뿐만 아니라, 특정 조건이나 사양에 특히 잘 부합하는지, 즉 가장 이 상적인 솔루션을 나타내는지 확인될 수 있다. 이러한 방식으로 찾은 출력 값은 바람직하게는 전체 시스템의 전 체 출력으로 사용하거나, 예를 들어 미래에 찾은 최상의 솔루션을 신속하게 검색하기 위해 장기 메모리에 저장 할 수 있다. 거꾸로, 특히 불리하거나 유리한 것으로 평가된 출력 값은 해당 평가 매개변수와 함께 제공될 수도 있으며, 이는 또한 이러한 값에 연결되어 저장 및/또는 추가 전송될 수도 있다. 이러한 평가 옵션은 개별적으로 또는 서로 조합하여 구현할 수 있다. 예를 들어, 전술한 투영 레벨(750, 850)로부터 데이터를 전송 및 저장하는 것에 대한 결정은 평가 유닛에 의한 이러한 평가에 기초하여 이루어질 수 있다. 추가 실시 예에서, 처음에는 제1 및 제2 작업 유닛의 입력 값으로 사용되는 시스템의 입력 값만 투영 레벨 또는 관련 메모리(752, 852)에 저장되는 것도 가능하다. 이것은 현재 상황에 대한 가공되지 않은 이미지라고 볼 수 있다. 동시에, 제1 및 제2 작업 유닛은 앞에서 설명한 바와 같이 이들 입력 값을 처리하기 시작하고, 즉, 작업 유닛 사이의 지배도를 변경하고 제2 작업 유닛의 결정 매개변수 및 함수를 변조하는 것과 같이 다양한 가능성을 사용하기 시작한다. 찾은 솔루션, 즉 제1 및/또는 제2 작업 유닛의 출력 값은 투영 레벨으로 전달될 수 있고, 그에 따라 각각의 관 련 입력 값을 각각 덮어쓰거나 이들과 함께 저장 및 연결될 수 있다. 예를 들어 변형에 따라, 동일한 입력 값에 서 얻은 각각의 최신 결과는 이전 결과를 덮어쓸 수 있다. 다른 경우, 이전 솔루션을 유지하면서 결과를 투영 계층로 전송할 수 있으므로, 예를 들어, 현재 솔루션과 이전 솔루션의 비교를 사용하여 나중에 또는 이전 결과 가 평가 시스템의 사양 또는 조건에 더 잘 부합하는지 여부를 평가할 수 있다. 링크의 예로서, 예를 들어 도면 에 관련하는 한, 동시에 중첩된 요소 또는 또한 중첩된 요소가 고려될 수 있다. 선택적으로, 결합된 유닛 사이의 이전에 설명한 지배도 고려될 수 있으므로, 예를 들어, 현재 지배적인 네트워 크의 출력 값만 처리되어 투영 레벨 또는 해당 메모리에 저장된다. 이 과정에서, 임시 매개변수가 다시 값에 링 크될 수 있다. 예를 들어, 길이가 같거나 다른 시간 세그먼트가 정의될 수 있으며, 여기에 각각의 입력 값 및 출력 값이 상황의 시간적 순서를 재현하기 위해 적절하게 할당된다. 예를 들어, 제1 기간에 입력 값을 저장할 수 있는 반면, 다음 기간에는 제1 작업 유닛의 출력 값이 저장되고 제2 작업 유닛의 출력 값이 저장된다. 또한, 개선되거나 적어도 변경된 출력 값은 추가 섹션에 저장될 수 있다. 인식된 상황의 순서를 명확히 하기 위해 선 택적으로 함께 속하는 것으로 표시될 수 있는 출력 값의 각 블록에 대해 기간이 지정될 수 있다. 예시적인 실시 예에서, 투영 메모리 안팎의 데이터 저장에 대한 제어는 시스템의 여러 유닛에서 적어도 부분적 으로 가정될 수 있다. 예를 들어, 정의된 유닛의 지배력을 가진 시스템에서, 새로운 상황이 가정되도록 입력 값 이 사전 정의된 레벨 이상으로 변경되는지 여부가 확인되는 상황은 이미 설명했다. 이 경우, 지배력은 제1 작업 유닛으로 전달되어 입력 값의 대략적인 새로운 분류를 생성할 수 있다. 동시에, 제1 작업 유닛은 (이전 상황에 해당하는) 저장된 데이터를 다른 메모리 요소, 예를 들어, 장기 메모리에 전송해야 하는지 여부, 또는 나중에 덮어쓸 수 있는지 여부를 나타내는 신호를 투영 메모리에 보낼 수 있다. 마찬가지로, 현재 처리 작업에 따라, 제1 및/또는 제2 작업 유닛은 다양한 상황이나 목표에 대응하기 위해 투영 메모리의 저장 기간을 조정할 수 있 다. 예를 들어, 길고 심층적인 솔루션 검색이 필요한 경우 투영 계층에서 더 긴 저장 기간이 설정될 수 있는 반 면, 빠른 결정은 저장된 데이터의 빠른 변화로 이어질 수 있다. 선택적으로, 또한 유닛 중 하나가 예를 들어 저장 기간을 우선적으로 결정할 수 있으므로, 예를 들어 투영 메모 리의 이전 데이터를 폐기하기로 한 제1 작업 유닛에 의한 결정은 제2 작업 유닛에 의해 확인되거나 차단될 수 있으므로, 각 데이터는 예를 들어, 반복되는 입력 값의 경우 저장된다. 더욱, 적어도 제한된 범위로, 유닛 중 하나가 다른 유닛의 분류 메모리를 변경하고 예를 들어 새 범주를 생성할 수 있다는 것도 생각할 수 있다. 그러 나, 어떤 유닛에 의해서도 변경하거나 삭제할 수 없는 모든 기본값이 저장되는 보호 영역을 정의할 수도 있다. 도 4에 표시된 시스템에서와 같이, 시간 간격을 측정하고 이 정보를 유닛에 전달할 수 있는 타이머가 지정된 경 우, 이 타이머는 예를 들어, 지정된 저장 기간도 모니터링할 수 있다. 이런 식으로, 저장 시간은 또한 시스템의서로 다른 유닛 사이의 지배 분포로 조정되거나 이와 동기화될 수 있다. 그러나 대안으로, 시스템의 다른 부분 이 이 목적을 위해 제공될 수 있다. 원칙적으로, 평가 유닛은 사전 정의된 저장 기간을 변경하고 재정의할 수도 있다. 이렇게 하면, 저장 기간 동안 상이한 사양이 다른 값에 대해 정의될 수도 있다. 예를 들어, 빠른 범주화 유닛인 제1 작업 유닛의 출력 값이 투영 레벨에 짧은 시간 동안만 저장되므로, 저장 기간 동안 처음 시간 사양 이 이에 대해 정의되는 반면, 제2 작업 유닛의 출력 값에는 저장 기간 동안 더 긴 시간 사양이 제공된다고 정의 할 수 있다. 제1 작업 유닛의 출력 값이 제2 작업 유닛의 출력 값을 사용할 수 있을 때까지만 저장되는 것도 가 능하다. 선택적으로, 평가 유닛의 출력 값 확인을 먼저 기다릴 수 있다. 제2 유닛의 출력 값이 사전 정의된 조 건에 해당하지 않기 때문에 유효하지 않다고 판단되는 경우, 이러한 값의 저장을 취소할 수 있는 반면, 제1 작 업 유닛의 대략적인 출력 값은 계속 유지된다. 추가적으로 또는 대안적으로, 평가 유닛은 또한 수행된 평가에 기초하여 제1 유닛과 제2 유닛 사이에 상술된 변 조를 더욱 수정할 수 있다. 시스템은 평가 시스템이 결과 및 출력 값의 유효성 또는 무효성에 대해 단독으로 결정하지 않지만, 예를 들어 처리 매개변수, 저장 시간 및 기타 요소에 영향을 미침으로써. 시스템의 다른 유닛와 결합하여 결정할 수 있는 방식으로 설계될 수 있다. 평가 유닛, 즉 평가 레벨이 평가 또는 검증 유닛으로 설계되는 한, 예를 들어 이들은 금지, 우선 순위, 규범적 규칙 및 가치 유형 사양과 같은 기능을 본질적으로 포함하는 분류를 포함할 수 있다. 이러한 평가 레벨에서 작 업 레벨의 출력 값을 평가하게 함으로써, 이러한 사양을 준수하는 전체 시스템에 대해 해당 솔루션만 승인되도 록 보장할 수 있다. 이것은 시스템의 단순한 고정 경계 조건일 수 있지만, 이들은 또한 가치와 규칙에 의해 주 어진 방향으로 전체 시스템의 개발과 결정을 유지하는 윤리와 같은 모듈로 더 발전될 수 있다. 특히 평가 레벨 의 분류에 의해 미리 정의되는 이들 경계 조건은, 바람직하게는 시스템에 의해 변경 가능하지 않고 제1 평가 유 닛에 대해 확고하게 정의 및 저장될 수 있고 바람직하게 사전 정의된 조건에서 시작하여 제2 평가 유닛에 대해 변경 가능할 수 있다. 따라서 시스템이 작업 및 평가 유닛의 상호 작용에서 적어도 부분적으로는 이들 분류 자 체를 학습하는 것을, 즉 비지도 학습에 해당하는 것을 또한 생각할 수 있으므로, 적어도 부분적으로 자체 가치 체계 또는 학습된 경계 조건 집합이 형성된다. 변경할 수 없는 경계 조건의 기본 시스템이 미리 정의된 설계도 사용할 수 있으며, 이 때 이들은 훈련 단계 또는 작동 중에 및/또는 외부 데이터 입력에 의해 보완될 수 있다. 평가 유닛에 의해 지정된 조건은 결합된 네트워크의 공동 훈련 단계 및 이전에 훈련된 시스템의 이후 평가 단계 모두에 적용될 수 있다. 선택적으로, 평가 유닛의 분류 메모리는 분류의 여러 닫힌 그룹에 해당하는 여러 개별 사전 설정을 포함할 수 있다. 필요한 경우, 당면한 상황에 따라 이러한 그룹 중 하나를 선택할 수 있다. 당면한 각 상황의 인식 및 적용될 분류 그룹의 할당은 다시 제1 및/또는 제2 작업 유닛의 결과를 기반으로 할 수 있다. 예를 들어 이러한 방식으로, 시스템의 다양한 위험 성향 또는 \"기본 분위기\"가 구현될 수 있다. 이 경우, 특정 경우에만 변경되는 기본 설정도 미리 정의될 수 있다. 또한 평가 레벨에 대한 추가 또는 유연한 경계 조건을 가 진 새로운 분류 그룹이 결합 시스템의 훈련 및 운영 단계에서 변경 불가능한 평가 레벨의 기본 설정으로부터 활 발하게 형성되는 것도 생각할 수 있다. 일 예로 사람을 구조하는 데 사용되는 자율주행차 또는 항공기(예를 들어, 항공 드론)의 경우, 특히 차량이 미 리 정해진 위치에 빨리 도착해야 하는 경우, 승객을 태우지 않는 한 위험한 운전 스타일이 허용될 수 있다. 상 황, 예를 들어. 제1 작업 유닛에 의해 수행될 수 있는 \"경보 상황\"의 대략적 인식 후에, 예를 들어, 대응하는 분류 그룹은 제1 평가 유닛에 대해 선택될 수 있고, 이에 기초하여 솔루션 또는 출력 값이 바람직하게는 제1 및 /또는 가능하게는 제2 작업 유닛에 의해 평가된다. 유사하게, 가능한 더 미세한 분류 그룹이 제2 평가 유닛에서 선택되고, 이에 의해 이 선택은 제3 변조 함수로 인한 제1 평가에 의해 영향을 받는다. 이러한 방식으로, 기본 경계 조건을 계속 관찰하여, 예를 들어, 사고를 피할 수 있지만, 동시에 다른 경계 조건(예를 들어, 빠른 코너 링, 손상 허용 또는 기타)을 완화할 수 있다. 시스템이 새로운 상황, 예를 들어, 차량 내 승객의 존재를 감지하 자마자, 제1 평가 유닛 및 제2 평가 유닛에 대해 각각 다른 분류 그룹을 적용할 수 있으며, 이제 승객 또는 구 조된 사상자의 건강에 더 집중할 수 있다. 확장된 실시 예에서, 추가 기준 카탈로그를 생성할 수 있으며, 이는 예를 들어 화물 운송, 소방 중, 정찰 비행 또는 정찰 여행 중 등과 같은 특정 상황에서 분류에 사용할 수 있다. 이와 같이 알려진 상황으로 상황을 분류할 수 있다면, 평가 레벨은 경계 조건의 유효성을 유지하는 것으로 제한 될 수 있으며 모순이 발생하지 않는 한 수동적으로 유지된다. 그러나 손상 또는 기타 바람직하지 않은 결과를 초래할 수 있는 더 복잡하거나 알 수 없는 상황이 발생하는 경우, 평가 레벨은 또한 작업 레벨의 솔루션 찾기에 보다 적극적으로 개입할 수 있고, 예를 들어, 새로운 검색 공간을 지정하고, 작업 유닛의 매개변수를 변경하거나 변조하거나, 그렇지 않으면 적합한 솔루션을 찾는 것을 지원한다. 이런 식으로, 금지, 우선 순위 및 가치 체계와 같은 전체 시스템의 기본 조건은 평가 레벨의 메모리에 위치하며, 바람직하게는 제1 평가 유닛에 대해 영구적으로 프로그래밍되어 제2 평가 유닛에 대해 어느 정도 수 정 가능한다. 처리 가속화는 또한 특정 솔루션을 제외하고 달성될 수도 있다. 평가 레벨은 보상이나 처벌과 같 은 행위를 통해 또는 새로운 단계 크기를 도출함으로써 작업 레벨의 해결책 찾기에 능동적으로 개입할 수 있다. 따라서 작업 레벨의 출력 값도 특별한 유형의 피드백을 통해 평가 레벨의 영향을 받는다. 추가 옵션으로, 평가 레벨은 시스템, 바람직하게는 작업 레벨에서 개별 유닛의 지배력에 대한 관련 결정 및 타 이머에 영향을 줄 수 있으며, 이는 도 4와 관련하여 이미 설명된 바와 같이 여러 개의 연결된 유닛의 시스템에 서 구현된다. 예를 들어, 평가 레벨은 지배력의 이전을 위해 지정된 시간 매개변수가 합리적인 결과로 이어지는 지 여부 또는 기간의 다른 분포 또는 사양이 지정되어야 하는지 여부를 확인할 수 있다. 이를 통해 예를 들어, 평소보다 더 대략적인 범주화가 필요한 상황, 예를 들어 더 짧은 시간 내에 결정해야 하는 상황에 유연하게 대 응할 수 있다. 따라서, 평가 레벨에서 타이머 모듈로의 신호는 필요한 경우 이를 기반으로 이미 설명한 대로 지 배의 추가 결정이 수행되는 것에 따라, 결합된 인공 학습 유닛 각각에 대해 하나 이상의 새로운 시간 매개변수 를 설정하는 데 사용될 수 있다. 유사하게, 상황 데이터의 시간 평가 후, 평가 레벨은 입력 값 및 그에 따라 평 가할 상황이 매우 빠르게 크게 변하거나, 상황이 준정적 방식으로 오랫동안 변하지 않는 것을 결정할 수 있고, 이를 바탕으로 처리를 위한 다른 시간 매개변수를 규정할 수 있다. 도 7 및 도 8에 설명된 요소 및 프로세스 단계는 물론 4개의 인공 학습 유닛으로 도시된 실시 예에 제한되지 않 는다. 모든 실시 예에서, 개별 요소, 예를 들어, 메모리 요소, 인공 학습 유닛(신경망), 이러한 요소 간의 연결 등도 여기에 도시된 것과 다르게 구현될 수 있다는 것이 이해된다. 예를 들어, 물론 이러한 개략도에 도시되지 않은 추가 메모리 요소도 존재할 수 있거나, 이들 메모리 중 일부 또는 전부는 단일 물리적 메모리 요소의 형태 일 수 있으며, 예를 들어, 주소 지정에 따라 세분화될 수 있다. 위에서 설명한 다양한 하위 접근 방식은 특히 서로 조합하여 연관 및 독립적으로 작동하는 시스템으로 이어질 수 있다. 이러한 시스템은 하나의 전문 영역에서만 훈련된 지능형 시스템보다 훨씬 더 광범위한 애클리케이션 범위를 다룰 수 있다. 기존 시스템에서, 데이터 처리는 다차원 공간에서 오류 최소값 또는 성공 최대값을 찾는 것에 해당한다. 이 공간의 차원이 (분류, 옵션, 계층적 레벨을 통해) 더 클수록, 시스템이 로컬 최소값 또는 최 대값에 갇힐 가능성이 더 크다. 반면에 가중치, 계단 크기, 함수 등에 적용된 변조 함수의 형태로 제1 유닛에 의한 제2 유닛의 앞에서 설명한 결합 및 영향은 정의된 계단 크기에 따라, 다른 방법으로는 절대 도달할 수 없 는 초기에 검사되지 않은 영역으로의 검색 공간의 점프를 허용할 수 있다. 진행중에, 각각의 경우에 새로운 솔 루션 공간이 적절한지 여부가 신속하게 확인되는 바와 같이, 작업은 또한 짧은 시간 동안 변경될 수 있다. 예를 들어, 잠재적으로 위험하지만 식별할 수 없는 동물이 입력 값으로부터 인식되고, 제1 작업 유닛와 제2 작 업 유닛 모두 이에 대해 적절한 이미지 패턴을 찾을 수 없는 경우, 시스템은 이제 (예를 들어, 확률적으로 도출 된) 변조된 계단 크기에 의한 사운드 분석으로 이동하여 식별할 수 없는 동물에 의해 기록된 적절한 사운드를 찾을 수 있다. 이하, 이렇게 변조된 제2 작업 유닛은 찾은 솔루션이 연관 성능에 해당하는 이전에 분류할 수 없 었던 이미지에 적용될 수 있는지를 확인한다. 유사하게, 투영 레벨을 도입하면 예를 들어 (출력 값 형식의) 결정을 이전 결정과 비교하고 선택적으로 평가할 수도 있다는 점에서 연관 동작을 복제할 수 있다. 따라서 긍정적이거나 부정적인 보상에 기반한 추상적인 학습 능력 대신 평가 시스템이 연관적으로 완성된다. 예를 들어, 시스템이 점프 영역에서 더 나은 솔루션을 찾지 못 하면, 투영 레벨의 평가에 의해 결정되고 선택적으로 저장되는 지금까지 최상의 솔루션의 영역으로 다시 점프하 여, 새로운 점프 변형을 시작할 수 있다. 이와 같이, 예를 들면, 제1 유닛에 의한 변조는 평가 레벨에 의한 평 가에 기초하여 찾아낸 적절한 시작점부터 항상 수행될 수 있다. 가능한 애플리케이션 예시로, 사용자에게 적합한 개인용 인공지능 시스템을 고려할 수 있다. 이상적으로는 이러 한 시스템은 특히 변조를 통한 설명된 피드백 및 해당 저장 옵션이 있는 평가 레벨을 포함하는 여러 인공 학습 유닛을 결합하여 하드 인공 지능의 의미에서 지능형 동작을 개발할 수 있다. 이러한 시스템은 바람직하게는 문 제를 독립적으로 문제를 연관시키고 분류할 수 있어야 한다. 또한 AI 시스템이 사용자에게 개별적으로 대응할 수 있도록 사용자별 행동이 가능해야 하며, 즉, 특히 사용자가 어떤 관심, 특질, 기분, 감정, 성격 특성 및 지 식 레벨을 가지고 있는지 감지 및/또는 학습할 수 있어야 한다. 본 명세서에서 이러한 외부 수집 데이터를 시스템에 추가할 수 있다. 예를 들어 작업 레벨 또는 분류 및/또는 평가 레벨 또는 특정 제한 내 조건을 변경하기 위해 전체 시스템에 대한 업데이트도 가능하다. 그러나 바람직하 게, 특히 시스템이 매우 개인적인 레벨에서 작동하기 때문에, 시스템에서 데이터 내보내기를 완전히 방지하는 메커니즘이 마련되어 있다. 따라서 개인 데이터는 외부에 공개되어서는 안 되며 선택적으로 액세스할 수도 없다. 예를 들어, 또한 AI 시스템은 주로 오프라인, 즉 외부 통신 네트워크나 다른 인터페이스에 연결하지 않고, 작동한다고 생각할 수 있다. 시스템을 업데이트하거나 배경 지식 및 기타 데이터를 로드하기 위해서, 시 간 제한이 있는 보안 연결을 설정할 수 있으며 예를 들어 사용자가 이를 완전히 제어할 수 있다. 예를 들어 추 가된 데이터의 소스가 지정될 수 있으며, 사용자에게는 연결에 동의할지 여부에 대한 선택권이 주어질 수 있다. 시스템에 대한 초기 훈련 단계를 제공할 수 있으며, 이 때 외국인과의 학습 커뮤니케이션, 미리 정의된 훈련 데 이터 세트 및/또는 시스템의 실제 사용자가 생성하지 않은 데이터가 발생한다. 이 훈련 단계는 나중에 특별한 경우에만 외부 데이터에 의존하기 위해 주제, 지식, 경험 및 전문 지식에 대한 일반적인 기본 설정을 제공하는 역할을 할 수 있다. 미리 정의된 통신 문자와 일반 상태에 대한 학습 프로세스 및 연결의 초기 깊이를 설정할 수도 있다. 또한, 상황에 대한 문제 인식 및 적절한 반응 뿐만 아니라 연관 커뮤니케이션 프로세스는 훈련 단계 에서 훈련될 수 있다. 예를 들어 제조업체가 수행할 수 있는 이 초기 훈련 단계를 완료한 후 최종 사용자가 제2 훈련 단계를 수행할 수 있다. 이 때, 예를 들어, 시간 매개변수가 사용자에게 설정될 수 있다(동기화). 이전에 초기에 설정된 통신 문자는 (미러링 또는 보완을 통해) 연결된 네트워크에서 시스템을 학습하고 적용하여 최종 사용자에 맞게 조정 될 수 있다. 마찬가지로 일반 사용자에 대해 이전에 설정한 캐릭터 특성과 관심사가 이제 특정 최종 사용자에게 조정될 수 있다. 또한, 예시적인 실시 예에서, 특히 시각적 평가를 포함하는 실시 예에서, 투영 레벨은 그 상태 의 현재 이미지를 생성하고 스크린에 표시할 수 있다. 이렇게 중첩된 이미지는 작업 단계, 특히 훈련 단계 동안 외부 사용자나 트레이너가 평가할 수 있도록 하며, 이를 사용하여 시스템이 현재 상황을 대략적으로 평가하는 방법을 결정할 수 있다. 이런 식으로, 초기 단계에서 시스템이 어떻게 작동하는지 인식하거나, 필요한 경우 개 입하여 특정 측면을 수정하거나 변형하여 훈련 단계를 가속화할 수 있다. 이러한 훈련 단계가 끝나면, 시스템은 사용할 준비가 된 것이다. 그러나, 나중에 보완 훈련 단계를 사용할 수도 있다. 실시 예에 따라, AI 시스템은 사용자의 감정 및 정신 상태뿐만 아니라 사용자가 수행한 환경 조건 및 작업을 등 록하기 위해 서로 다른 인터페이스를 가질 수 있다. 이를 위해 카메라, 마이크, 모션 센서, 적외선 센서, 화합 물용 센서(\"인공 코\"), 초음파 센서 등과 같은 다양한 센서를 사용할 수 있다. 이것들은 가능한 가장 종합적인 분석을 가능하게 하기 위해 개별적으로 배열, 분산 및/또는 적절한 모바일 또는 정적 개체에 결합될 수 있다. 게다가, AI 시스템이 사용자와 통신할 수 있는 음성 출력용 라우드스피커 또는 스크린 및 시각적 디스플레이 및 텍스트 표현을 위한 기타 디스플레이 수단과 같은 다른 인터페이스가 제공될 수 있다. 하나의 가능한 실시 예에서, 그러한 AI 시스템이 사용자를 위해 통합되는 객체가 제공된다. 이것은 기술 장치 (예를 들어, 스마트폰)와 같은 모바일 개체일 수 있지만, 특히 램프, 꽃병, 스크린, 거울 또는 가정에서 이미 고정된 장소를 가지고 있는 다른 물체와 같은 가구 또는 일상적인 사용 물체일 수도 있다. 시스템의 임무는 사 용자 사람을 위한 인공 개인 지능형 동반자가 되는 것이다. 시스템은 사용자의 신원을 확인하고 예를 들어 화면 이거나 투영이 방에 설치된 경우 음성 및/또는 이미지를 통해 사용자와 통신한다. 따라서, 출력은 인터페이스 (예를 들어, 확성기, 스크린, 프로젝터)에 연결된다. 위에서 설명한 발명 요소를 기반으로 시스템은 상황을 분류하고 저장 및 학습된 지식을 가져와 연관시킬 수 있 다. 목표는 영감을 제공하고, 제안을 하고, 사용자의 외로움과 우울한 기분을 해소하고, 코치 또는 전문 조언자 /문제 해결사 역할을 하는 것이다. 애플리케이션 분야는 여가 동반자로서의 용도(지루함을 돕고, 대화 자극을 주고, 사람들을 즐겁게 하고, 삶의 도움을 줌); 지적, 과학적, 예술적 충동을 주는 영감자로서의 용도; 특히 정 신 질환자에게 심리적 또는 지적 지원을 제공하는 코치 또는 조언자로서의 용도; 다양한 일상 상황(패션, 위생, 건강, 업무, 관리)에 대한 조언자로서의 용도; 개인비서로의 용도, 이에 의해 광범위한 지식 데이터베이스를 생 성하고 사용할 수 있고; 가장 다양한 게임의 플레이 파트너로서의 용도; 그 외 용도를 포함한다. 특히, 이러한 시스템은 사용자에, 단기적으로 현재 기분, 및 장기적으로 예를 들어 사용자의 문자 유형에 적응 할 수 있다. 무엇보다도, 투영 레벨을 통해 처리되고 장기 메모리에 저장된 정보는 이러한 목적으로 사용될 수 있다. 이상적으로, 시스템에는 코드, 생체 인식 사용자 인식(이미지, 음성, 지문, 음성 톤 또는 기타 기능) 및 이를 위한 기타 액세스 제어 옵션이 장착될 수 있다.바람직하게, 도덕 윤리적 시스템은 이러한 시스템과 설명된 프로세스 단계로 구현될 수 있다. 예를 들어, 개인 지능형 동반자는 사용자와 그의 환경을 위해 충족스럽고 유용한 행동을 장려할 수 있고; 사용자의 유형, 성격 상황 및 분위기에 맞는 도덕 윤리적 문제에 주의를 끌 수 있으며, 예를 들어 특정 미덕을 전파할 수 있다(도움, 관대함, 친절, 용기, 지혜). 평가 레벨에서 적절한 조건을 통해, 시스템은 사용자뿐만 아니라 그들의 결정에 영향을 받는 모든 사람들을 위 해 피해, 고통 및 괴로움을 피하도록 설정할 수 있다. 중대한 잘못된 판단이 예상되는 경우, 개인 수행자는 토 론을 시작할 수 있으며, 특히 특정 행동 과정의 결과에 대해 논쟁하고 대안에 대한 건설적인 제안을 할 수 있다. 행동을 처방하는 것이 아니라, 행동이 어떻게 되어야 하고 될 수 있는지에 대한 이상적인 것을 선호한다. 개인 간병인은 딜레마 상황을 식별하고 이를 사용자에게 지적하는 동시에, 대안 솔루션이나 이들 중에서 선택할 수 있는 가장 유리한 솔루션을 찾을 수 있다. 특히 사용자의 예술 작품 맥락에서, 개인 지식 동반자는 사전 프 로그래밍되고 학습된 평가를 통해서만 지원할 가능성이 있다. 이 맥락에서, 반영은 이미 사용자에 맞게 조정될 수 있다. 시스템의 연관 능력은 이 때 필수적인 역할을 한다. 구현의 추가 예로서 \"지능형 미러\"가 설명된다. 입구 영역이나 욕실 영역에는 이미 거울이 있다. 다양한 센서와 같이, 이전의 일반 예에서 이미 설명한 입력 및 출력 인터페이스는 거울에 쉽게 통합될 수 있다. 사용자가 짧지 만 자주 지나치는 물건을 이용하여, 다양한 가능성이 이러한 AI 시스템에서 구현될 수 있다. 예를 들어, 적절한 카메라, 마이크, 동작 감지기, 초음파 센서, 인공 코, 적외선 센서 등을 사용하여 적극적으 로 입력하지 않고도 사용자와 일반적인 상황 및 사용자 습관에 대한 다양한 정보를 수집할 수 있다. 특히 입구 영역에서는, 출입 통제도 구현할 수 있다. 이러한 방식으로, 지능형 AI 시스템은 사용자에게 의류 문제를 경고하고 의류 추천을 제공할 수 있다. 예를 들 어, 예상 날씨와 필요한 도구가 없어진 것을 감지하면 알려줄 수 있다. 사용자가 소지한 물품을 기록 및 인식할 수 있다. 필요한 경우 사용자와의 대화에서 (음성 또는 기타 입력 수단을 통해), 무언가 필요한지, 잊어버렸는 지 또는 잃어버렸는지 등을 질문하여 명확히 할 수 있다. 사용자가 예를 들어, 상황이나 개체에 대해 언급하거나 이들을 녹음하라고 적극적으로 지적하여 이들 프로세스 를 지원할 수 있도록 마이크에 의해 녹음된 설명도 포함될 수 있다. 얼마 후, AI 시스템은 이러한 방식으로 거 의 모든 물체, 의류 품목 및 이들의 아파트 내 위치를 알 수 있다. 무언가를 검색 중이거나, 사용자가 자신의 옷, 식료품, 도서 재고 등에 대해 질문이 있는 경우, 시스템이 힌트를 제공할 수 있다. 예를 들어, 사용자는 그 가 아파트에 들어갈 때 안경을 쓰고 있었다고 말할 수 있고 안경은 아파트 안에 있어야 한다고 결론을 내릴 수 있다. 일상 생활을 위한 약속 일기, 목록 및 기타 지원 보조 장치도 대화를 통해 AI 시스템에 의해 관리될 수 있다. 따라서 이 시스템은 또한 노인과 환자 또는 일반적으로 일상 생활에서 어떤 식으로든 제한을 받는 사람들에게 특히 유용하다. 기록된 데이터의 적절한 평가, 예를 들어 얼굴 표정 인식 및 음성 피치 또는 추가 데이터 평가에 의해, 시스템 은 예를 들어 누군가 서둘러 긴 여행을 시작하고 싶다면, 사용자의 기분을 단기간에 기록하고 이를 기반으로 해 당 표시를 제공할 수 있다. 예를 들면, 검출된 기분은 상기 실시 예에서 평가 레벨에 의해 수행된 평가에 포함 될 수 있다. 이러한 맥락에서, 감지 옵션 및 대화가 개체, 즉 이 경우 지능형 거울에 반드시 바인딩되지는 않는다. 사용자가 부적절한 장소에서 AI 시스템과 긴 대화를 나누는 것을 방지하기 위해, 시스템은 아파트 내 적절한 위치에 분산 된 라우드스피커, 마이크 및 기타 장치를 통해 사용자와의 대화를 시작하거나 계속할 수 있다. AI 시스템 자체 의 구성 요소는 여러 모듈에 분산될 수 있으며 예를 들어, 적합한 무선 또는 유선 통신 인터페이스를 통해 서로 연결될 수 있다. 본 명세서에 제시된 모든 AI 시스템에 대해, 기록 및 저장된 데이터, 특히 개인 데이터는 엄격하게 보호되고 특 히 암호로 보호된 데이터 저장 장치가 제공되는 것이 바람직한다. 이 목적을 위해, 사용자를 이미지, 음성뿐만 아니라, 움직임 특성, 어음 강조 또는 기타 생체 특성 평가로부터 안정적으로 식별할 수 있는 식별 시스템도 통 합할 수 있다. 이렇게 하면 개인 정보가 대화에서 게스트 또는 권한이 없는 다른 사람에게 공개되는 것을 방지 할 수 있다."}
{"patent_id": "10-2023-7019741", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "개별적으로 또는 서로 및 상기 실시 예와 조합하여 구현될 수 있는 추가 가능한 실시 예가 이하 요약된다: 예를 들어, 일 실시 예에 따르면, 방법은 적어도 제1 인공 학습 유닛 및 제2 인공 학습 유닛에 입력 값을 입력 하는 단계를 포함하는 다중 인공 학습 유닛의 시스템에서 구현될 수 있으며, 이에 따라 제1 인공 학습 유닛의 제1 출력 값이 획득된다. 제1 인공 학습 유닛의 출력 값에 기초하여, 하나 이상의 변조 함수가 형성될 수 있으 며, 이것은 다음에 제2 인공 학습 유닛의 하나 이상의 매개 변수에 적용된다. 하나 이상의 매개변수는 어떤 방 식으로든 제2 인공 학습 유닛에서 입력 값의 처리 및 출력 값의 획득에 영향을 미치는 매개변수일 수 있다. 또 한, 제2 인공학습 유닛의 출력 값이 획득된다. 이들은 예를 들어 제2 유닛의 변조된 출력 값을 나타낼 수 있다. 이런 식으로, 두 개의 인공 학습 유닛이 함께 결합되어 입력 또는 출력 값의 직접적인 피드백을 사용하지 않고 인공 학습 시스템을 형성한다. 대신, 유닛 중 하나는 기능적으로 관련된 특정 매개변수를 변조하여 제2 유닛의 함수에 영향을 미치는 데 사용되어, 결과적으로 기존 학습 유닛와 비교하여 다른 결과 또는 출력 값으로 이어지 는 새로운 결합이 발생한다. 또한 두 개의 결합된 유닛에서 입력 값을 처리하여, 기존 시스템에서보다 더 짧은 시간 또는 더 심층적인 분석으로 결과를 성취할 수 있으므로, 전반적인 효율성을 높일 수 있다. 특히 당면한 문 제를 빠르게 분류하여 급격한 변화를 고려할 수 있다. 예시적인 실시 예에서, 인공 학습 유닛(작업 유닛 및 평가 유닛) 중 적어도 하나는 복수의 노드, 특히 변조 함 수가 적용되는 인공 학습 유닛 중 하나를 갖는 신경망을 포함할 수 있다. 이 경우, 하나 이상의 매개변수는 신 경망의 노드에 대한 가중치, 노드의 활성화 함수, 노드의 출력 함수, 노드의 전파 함수 중 적어도 하나일 수 있 다. 이들은 네트워크에서 데이터 처리를 결정하는 신경망의 필수 구성 요소이다. 노드에 대한 새로운 가중치 또 는 함수를 정의하는 대신에, 변조 함수는 제1 인공 학습 유닛의 결과에 따라 변조된 네트워크의 기존, 자체 학 습 및/또는 미리 정의된 함수를 중첩하는 데 사용될 수 있다. 에 의하면, 이러한 변조 함수의 적용은 특히 네트 워크의 훈련 단계 외부에서도 발생할 수 있으므로 입력 값 처리에서 둘 이상의 네트워크의 활성 결합을 달성할 수 있다. 예시적인 실시 예에 따르면, 인공 학습 유닛(작업 및 평가 유닛) 중 적어도 하나, 바람직하게는 각각에는, 분류 메모리가 할당될 수 있으며, 여기에서 상기 각 인공 학습 유닛은 상기 입력 값을 상기 분류 메모리에 저장된 하 나 이상의 클래스로 분류하고, 클래스는 각각 하나 이상의 종속 레벨로 구성되며, 제1 인공 학습 유닛(제1 작업 /평가 유닛)의 제1 분류 메모리에 있는 클래스 및/또는 레벨의 수는 인공 학습 유닛의 제2 인공 학습 유닛(제2 작업/평가 유닛)의 제2 분류 메모리에 있는 클래스 및/또는 레벨의 수보다 적다. 이렇게 결합된 2개의 인공학습 유닛의 분류 메모리를 비대칭으로 만들어서, 서로 다른 목표를 가진 입력 값의 병렬 또는 시간 종속 교대 평가, 예를 들어, 입력 값의 빠른 분류 및 입력 값의 깊고 느린 분석의 조합이 발생할 수 있다. 분류 메모리의 비대칭 설계의 대안으로 또는 이에 추가하여, 제1 및 제2 인공 학습 유닛의 복잡성도 다르게 설 계될 수 있으므로 예를 들어, 제1 인공 학습 유닛(제1 작업/평가 유닛)는 제2 인공 학습 유닛(제1 작업/평가 유 닛)보다 복잡도가 상당히 낮다. 예를 들어 신경망의 경우 제1 신경망은 제2 신경망보다 훨씬 적은 수의 노드 및 /또는 계층 및/또는 에지를 가질 수 있다. 가능한 실시 예에서, 적어도 하나의 변조 함수의 적용은 제2 인공 학습 유닛의 매개변수의 시간 의존적 중첩을 야기할 수 있고, 이 때 상기 적어도 하나의 변조 함수는 다음 특징들 중 하나를 포함할 수 있다: 주기 함수, 계 단 함수, 진폭이 잠시 증가하는 함수, 감쇠 진동 함수, 여러 주기 함수의 중첩으로서의 비트 함수, 연속적으로 증가하는 함수, 지속적으로 감소하는 함수. 이러한 함수의 조합 또는 시간적 순서도 생각할 수 있다. 이러한 방 식으로 학습 유닛의 관련 매개변수를 시간 종속 방식으로 중첩할 수 있다. 예를 들어 출력 값은 중첩 없이는 도 달할 수 없는 변조로 인해 검색 공간으로 \"점프\"한다. 선택적으로, 제2 인공 학습 유닛은 복수의 노드를 갖는 제2 신경망을 포함할 수 있고, 이 때 적어도 하나의 변 조 함수를 적용하는 것은 노드의 적어도 일부의 비활성화를 야기한다. 이러한 유형의 비활성화는 제1 인공 학습 유닛의 출력 값을 기준으로 \"드롭아웃\"으로 간주될 수도 있으며 분류에서 새로 열린 검색 영역 뿐만 아니라 감 소된 계산 비용 및 이에 의해 방법의 가속화된 실행을 제공할 수 있다. 예시적인 실시 예에서, 상기 방법은 시스템에서 현재 지배적인 인공 학습 유닛을 결정하는 단계 및 상기 현재 지배 유닛의 출력 값으로부터 시스템의 전체 출력 값을 형성하는 단계를 더 포함할 수 있다. 이런 식으로, 시스 템에 있는 두 개 이상의 인공 학습 유닛은 의미 있게 연결되고 동기화될 수 있다. 예를 들어, 제1 인공 학습 유닛(특히 제1 작업 유닛)은 적어도 제2 인공 학습 유닛(특히 제2 작업 유닛)의 하나 이상의 출력 값이 이용 가능할 때까지 지배 유닛으로 설정될 수 있다. 이러한 방식으로, 시스템의 모든 기존 인 공 학습 유닛에 의해 입력 값의 완전한 분류가 이루어지기 전에도, 시스템이 항상 의사 결정 안전하고, 즉, (제1 작업 유닛의 제1 실행 후) 시스템의 반응이 항상 가능하다는 것이 보장될 수 있다. 시스템의 적어도 하나의 인공 학습 유닛에 의해 현재 입력 값과 이전 입력 값의 비교를 추가로 적용하는 것도 가능하고, 이에 의해 비교 결과 미리 정의된 입력 임계값을 초과하는 편차가 발생하는 경우, 제1 인공 학습 유 닛이 지배 유닛으로 설정된다. 이러한 방식으로, 실질적으로 변경된 입력 값(예를 들어, 센서를 통한 새로운 상 황 감지)이 입력 값의 새로운 분석으로 즉시 반응하는 것이 보장될 수 있다. 추가적으로 또는 대안적으로, 제1 인공 학습 유닛(특히, 제1 작업 유닛)의 이전 출력 값과 제1 인공 학습 유닛 의 현재 출력 값의 비교가 더욱 이루어질 수 있으며, 이에 의해 비교 결과 편차가 미리 결정된 출력 임계값을 초과하는 경우, 제1 인공 학습 유닛이 지배 유닛으로 결정된다. 출력 값의 편차를 평가하여, 예를 들어 이전 실 행과 비교하여 결과로 편차 클래스가 있는 경우, 입력 값의 변화는 간접적으로 특정 의미를 가지며 따라서 새로 운 분류를 의미 있게 만드는 것을 감지할 수 있다. 특정 실시 예에서, 시스템은 하나 이상의 인공 학습 유닛과 연관된 하나 이상의 미리 결정된 기간을 저장하는 적어도 하나의 타이머를 더 포함할 수 있고, 타이머는 한 번에 하나의 인공 학습 유닛에 대해 그 유닛과 관련된 미리 결정된 기간의 경과를 측정하도록 배열된다. 이러한 요소는 예를 들어 시스템의 서로 다른 유닛을 동기화 하고 특정 유닛의 출력 값이 예상되거나 추가 처리되는 시기를 제어할 수 있는 가능성을 형성한다. 따라서 타이 머는 결정이 시스템의 전체 출력 값으로 사용 가능해야 하는 전체 시스템의 조정 가능한 대기 시간을 정의하는 데 사용될 수 있다. 이 시간은 몇 ms, 예를 들어, 30 또는 50ms일 수 있으며, 무엇보다도 컴퓨팅 장치(프로세서 또는 기타 데이터 처리 수단)의 기존 토폴로지 및 사용 가능한 컴퓨팅 장치에 따라 달라질 수 있다. 예를 들어, 인공 학습 유닛 중 하나에 대한 할당된 미리 정의된 기간의 측정은 이 인공 학습 유닛이 지배 유닛 으로 결정되자마자 시작될 수 있다. 이런 식으로, 유닛이 미리 결정된 시간 내에 솔루션을 개발하거나, 선택적 으로 데이터 처리가 중단되는 것이 보장될 수 있다. 하나의 가능한 실시 예에서, 제2 인공 학습 유닛(특히, 제2 작업 유닛)은 제1 인공 학습 유닛에 대해 미리 정해 진 타이머의 제1 기간이 경과하면 지배 유닛으로 설정될 수 있다. 이것은 추가 인공 학습 유닛에 의해 입력 값 이 분석되기 전에 제1 인공 유닛에 기반한 반응이 이미 가능한 반면에, 그 후 데이터는 제2 유닛에 의해 더 자 세히 평가된다는 것을 확실히 한다. 임의의 실시 예에서, 입력 값은 예를 들어 다음 중 하나 이상을 포함할 수 있다: 하나 이상의 센서에 의해 검출 된 측정값, 사용자 인터페이스에 의해 검출된 데이터, 메모리로부터 검색된 데이터, 통신 인터페이스를 통해 수 신된 데이터, 컴퓨팅 유닛에 의해 출력된 데이터. 예를 들어, 카메라로 캡처한 이미지 데이터, 오디오 데이터, 위치 데이터, 속도와 같은 물리적 측정, 거리 측정, 저항 값 및 일반적으로 적절한 센서로 캡처한 모든 값이 될 수 있다. 마찬가지로 데이터는 사용자가 키보드나 화면을 통해 입력하거나 선택할 수 있으며 선택적으로 센서 데이터와 같은 다른 데이터에 연결할 수 있다. 위에서 설명한 예는 어떤 방식으로든 결합될 수 있다는 것이 이해되어야 한다. 예를 들어, 설명된 임의의 실시 예에서, 도 4와 관련하여 설명된 바와 같은 타이머도 있을 수 있다. 마찬가지로 모든 예시에서, 학습 유닛은 도 5와 관련하여 일 예로서 설명된 것과 같은 분류 메모리를 가질 수 있다. 이러한 모든 변형은 3개 또는 4개 이상 의 인공 학습 유닛의 결합에 다시 적용할 수 있다.도면 도면1 도면2 도면3 도면4 도면5 도면6 도면7 도면8"}
{"patent_id": "10-2023-7019741", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 서로 결합된 두 개의 인공 학습 유닛의 조합을 도시한다; 도 2는 다양한 예시의 변조 함수를 개략적으로 도시한다; 도 3은 두 개의 연결된 신경망에서 드롭아웃 절차의 적용을 도시한다; 도 4는 추가 타이머가 있는 도 1과 같은 시스템을 도시한다; 도 5는 연관된 분류 메모리를 갖는 도 1과 같은 시스템을 개략적으로 도시한다; 도 6은 3개의 연결된 인공 학습 유닛이 있는 대체 시스템을 도시한다; 도 7은 작업 레벨, 평가 레벨 및 투영 레벨을 갖는 본 발명에 따른 예시적인 전체 시스템을 도시한다; 및 도 8은 2개의 인공 학습 작업 유닛, 2개의 인공 학습 평가 유닛 및 투영 레벨을 갖는 본 발명에 따른 예시적인 전체 시스템을 도시한다."}
