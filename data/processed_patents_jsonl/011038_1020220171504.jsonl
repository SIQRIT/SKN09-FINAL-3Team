{"patent_id": "10-2022-0171504", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0086195", "출원번호": "10-2022-0171504", "발명의 명칭": "확산 모델을 이용한 비지도 학습 기반 변형 영상 정합 및 합성 영상 생성 시스템 및 그 방법", "출원인": "한국과학기술원", "발명자": "예종철"}}
{"patent_id": "10-2022-0171504", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "영상 획득장치, 정합장치, 합성장치, 및 손실확인기를 포함하는 확산 모델을 이용한 비지도 학습 기반 변형 영상 정합 및 합성 영상 생성 시스템으로서,상기 영상 획득장치는 동영상인 제1 영상데이터를 획득하는 제1 영상 획득장치, 및 고정영상인 제2 영상데이터를 획득하는 제2 영상 획득장치를 포함하며,상기 정합장치는 제1 영상 획득장치와 제2 영상 획득장치에서 제공된 상기 제1 영상데이터의 좌표와 상기 제2영상데이터의 좌표를 대응시켜상기 제1 영상데이터와 상기 제2 영상데이터의 정합을 수행하며, 상기 합성장치는 비지도 학습 기반의 뉴럴 네트워크를 구성하는 확산 모듈을 이용하여, 노이지한 영상을 출력하고, 출력된 노이지한 영상에 대한 반복적 역확산 프로세스를 통해 합성영상을 생성하는 역확산 처리기를 포함하는 확산 모델을 이용한 비지도 학습 기반 변형 영상 정합 및 합성 영상 생성 시스템."}
{"patent_id": "10-2022-0171504", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "청구항 1에 있어서,상기 손실확인기는 영상데이터 정합 시에 손실율을 최소로 할 수 있는 영상데이터를 선택하여 영상데이터를 정합시키는 손실확인기를 더 포함하는 확산 모델을 이용한 비지도 학습 기반 변형 영상 정합 및 합성 영상 생성시스템."}
{"patent_id": "10-2022-0171504", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "청구항 1에 있어서,상기 정합장치는 특징맵 추출기, 벡터장 추출기, 공간 변환기를 포함하며,상기 특징맵 추출기는 비지도 학습 기반의 뉴럴 네트워크를 구성하는 확산 모듈을 이용하여, 상기 제1 영상 획득장치에서 획득된 상기 제1 영상데이터 및 상기 제2 영상 획득장치에서 획득된 상기 제2 영상데이터를 이용하여 잠재 특징맵을 추출하는 확산 모델을 이용한 비지도 학습 기반 변형 영상 정합 및 합성 영상 생성 시스템."}
{"patent_id": "10-2022-0171504", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "청구항 3에 있어서,상기 벡터장 추출기는 상기 특징맵 추출기에서 추출된 상기 잠재 특징맵을 수신하고, 상기 수신된 잠재 특징맵에서의 도든 좌표점에 대한 벡터장을 추출하는 확산 모델을 이용한 비지도 학습 기반 변형 영상 정합 및 합성영상 생성 시스템."}
{"patent_id": "10-2022-0171504", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "청구항 4에 있어서,상기 공간 변환기는 비지도 학습 기반의 뉴럴 네트워크를 구성하는 정합 모듈을 이용하여 상기 벡터장 추출기에서 추출된 벡터장으로 변형 필드를 출력하고, 상기 출력된 변형 필드를 영상공간 변형 함수에 기초하여 상기 제1 영상데이터 및 상기 제2 영상데이터에 적용시켜 정합 영상을 생성하는 확산 모델을 이용한 비지도 학습 기반공개특허 10-2024-0086195-3-변형 영상 정합 및 합성 영상 생성 시스템."}
{"patent_id": "10-2022-0171504", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "청구항 1에 있어서,상기 정합장치와 상기 합성장치는 상기 특징맵 추출기를 공유하는 확산 모델을 이용한 비지도 학습 기반 변형영상 정합 및 합성 영상 생성 시스템."}
{"patent_id": "10-2022-0171504", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "영상 획득장치, 정합장치, 합성장치, 및 손실확인기를 포함하는 확산 모델을 이용한 비지도 학습 기반 변형 영상 정합 및 합성 영상 생성 시스템에 의한 확산 모델을 이용한 비지도 학습 기반 변형 영상 정합 방법으로서,상기 영상 획득장치의 제1 영상획득장치 및 제2 영상획득장치를 통해 제1 영상데이터 및 제2 영상데이터를 각각획득하는 단계와;상기 정합장치의 특징맵 추출기를 통해 상기 획득된 제1 영상데이터 및 제2 영상데이터로부터 잠재 특징맵을 추출하는 단계;상기 정합장치의 벡터장 추출기를 통해. 상기 추출된 잠재 특징맵을 수신하고, 상기 수신된 잠재 특징맵에서의모든 좌표점에 대한 벡터장을 추출하는 단계; 및상기 정합장치의 공간 변환기를 통해, 상기 벡터장 추출기에서 추출된 벡터장으로 변형 필드를 출력하고, 상기출력된 변형 필드를 공간 변형 함수에 기초하여 상기 제1 영상데이터 및 제2 영상데이터에 적용시켜 정합 영상을 생성하는 단계를 포함하는 확산 모델을 이용한 비지도 학습 기반 변형 영상 정합 방법."}
{"patent_id": "10-2022-0171504", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "청구항 7에 있어서,상기 잠재 특징맵을 추출하는 단계에서, 비지도 학습 기반의 뉴럴 네트워크를 구성하는 확산 모듈을 이용하여,상기 추출된 잠재 특징맵은 상기 제1 영상데이터 및 제2 영상데이터에서 확인되는 모든 좌표점을 포함하는 확산모델을 이용한 비지도 학습 기반 변형 영상 정합 방법."}
{"patent_id": "10-2022-0171504", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "청구항 8에 있어서,상기 잠재 특징맵을 추출하는 단계에서, 상기 비지도 학습 기반의 뉴럴 네트워크를 구성하는 확산 모듈을 이용하여, 상기 제1 영상데이터가 동영상이고 상기 제2 영상데이터가 고정 영상인 경우, 상기 제1 영상데이터를 상기 제2 영상데이터에 정합하기 위해 상기 제2 영상데이터에 대한 변형 잠재 특징 맵을 출력하는 확산 모델을 이용한 비지도 학습 기반 변형 영상 정합 방법."}
{"patent_id": "10-2022-0171504", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "청구항 9에 있어서,상기 제1 영상데이터 및 제2 영상데이터에 적용시켜 정합 영상을 생성하는 단계에서,비지도 학습 기반의 뉴럴 네트워크를 구성하는 정합 모듈을 이용하여, 상기 잠재 특징맵을 이용하여, 상기 제1영상데이터를 상기 제2 영상데이터에 정합하기 위해 상기 제1 영상데이터에 대한 상기 변형 필드를 출력하고,상기 공간 변형함수를 이용하여 상기 제1 영상데이터에 상기 제1 영상데이터에 대한 변형 필드를 적용함으로써공개특허 10-2024-0086195-4-상기 정합 영상을 생성하는 확산 모델을 이용한 비지도 학습 기반 변형 영상 정합 방법."}
{"patent_id": "10-2022-0171504", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "영상 획득장치, 정합장치, 합성장치, 및 손실확인기를 포함하는 확산 모델을 이용한 비지도 학습 기반 변형 영상 정합 및 합성 영상 생성 시스템에 의한 확산 모델을 이용한 비지도 학습 기반 변형 영상 생성 방법으로서,상기 영상 획득장치의 제1 영상획득장치 및 제2 영상획득장치를 통해 제1 영상데이터 및 제2 영상데이터를 각각획득하는 단계와;비지도 학습 기반의 뉴럴 네트워크를 구성하는 확산 모듈을 이용하여, 제1 영상데이터에 대해 포워드 확산을 적용하여 노이지한 영상을 출력하는 단계; 및상기 출력된 노이지한 영상에 대한 반복적 역확산 프로세스를 통해 합성영상을 생성하는 단계를 포함하는 확산모델을 이용한 비지도 학습 기반 변형 영상 생성 방법."}
{"patent_id": "10-2022-0171504", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "청구항 11에 있어서,상기 출력된 노이지한 영상에 대한 반복적 역확산 프로세스를 통해 합성영상을 생성하는 단계는,상기 비지도 학습 기반의 뉴럴 네트워크를 구성하는 확산 모듈을 이용하며,상기 제1 영상데이터가 동영상이고 상기 제2 영상데이터가 고정 영상인 경우, 시간 스텝에 따라 상기 제1 영상데이터를 상기 제2 영상데이터로 합성하기 위해 상기 제2 영상데이터에 대한 변형 잠재 특징 맵을 출력하고, 상기 출력된 변형 잠재 특징 맵을 역확산 프로세스에 적용함으로써 합성영상을 생성하는 확산 모델을 이용한 비지도 학습 기반 변형 영상 생성 방법."}
{"patent_id": "10-2022-0171504", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 디노이징 확산 확률 모델(DDPM)을 변형 필드 생성에 적용한 확산 모델을 이용한 비지도 학습 기반 변 형 영상 정합 및 합성 영상 생성 시스템 및 그 방법에 관한 것이다. 본 발명에 따른 확산 모델을 이용한 비지도 학습 기반 변형 영상 정합 및 합성 영상 생성 시스템 및 그 방법은 (뒷면에 계속)"}
{"patent_id": "10-2022-0171504", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 확산 모델을 이용한 비지도 학습 기반 변형 영상 정합 및 합성 영상 생성 시스템 및 그 방법에 관한 것으로, 보다 상세하게는 디노이징 확산 확률 모델(DDPM: Denoising Diffusion Probabilistic Model, 이하 \"DDPM\" 이라 총칭함)을 변형 필드 생성에 적용한 확산 모델을 이용한 비지도 학습 기반 변형 영상 정합 및 합성 영상 생성 시스템 및 그 방법에 관한 것이다."}
{"patent_id": "10-2022-0171504", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "최근, 딥러닝(deep learning) 알고리즘을 적용하여 빅데이터를 처리하는 다양한 기법들이 개발되고 있으며, 이 를 적용한 성공사례도 점점 증가하고 있다. 특히, X-ray, 초음파, CT(computed tomography), MRI(magnetic resonance imaging), PET(positron emission tomography), 광각안저카메라(ultra-widefield fundus imaging) 등의 진단기기들로부터 획득된 의료영상데이터를 인공지능 알고리즘에 적용하여 의사의 의사결정에 도움을 주는 방법이 개발되고 있다. 이 중에서도 최근에는 안구의 상태를 진단하기 위해 광각안저카메라에서 획득된 멀티 위 상 초광각 망막 영상을 이용한다. 이와 같은 멀티 위상 초광각 망막 영상의 분석을 위해서는 위상에 따라 변화되는 영상의 특성을 파악하는 것이 중요한데 이를 위해서는 각각의 영상에서 발생되는 왜곡 및 위치가 보정되어야 한다. 이를 위해, 딥러닝 기법을 이용하여 영상간 왜곡과 위치 변화를 보정하는 정합 기법에 대한 연구가 진행되고 있다. 그러나 이러한 연구는 영상의 종류가 유사한 경우를 가정하여 진행되고 있으므로, 이동영상데이터와 고정영상데이터와 같이 서로 다른 종류의 영상을 정합하고자 할 때에는 영상간 왜곡 및 위치 변화가 효율적이지 못한 문제가 발생한다. 영상 정합은 한 쌍의 동영상과 고정영상 간의 좌표를 대응시키는 것이다. 이는 사람, 촬영 시각, 영상 모달리티 등의 다양한 요인에 따라 의료 영상에서 해부학적 구조의 모양이 달라지기 때문에, 질병진단을 하거나 치료 과 정을 모니터링 하는 데 있어서 영상 정합은 중요한 단계이다. 기존의 고전적인 영상 정합 기법은 반복접 기법으로 에너지 함수를 최소화하여 영상을 정렬하는 방식으로 개발되었으며 이는 계산량이 많다는 단점이 있다. 이를 해결하기 위해 딥 러닝 기반의 영상 정합 기법이 개발되고 있으며, 이는 네트워크가 동영상과 고정영상을 입력 받아 변형 필드를 출력할 수 있도록 학습하고, 새로운 영상에 대해 실시간으로 변형이 가능하다는 장점이 있다. 그러나 지도학습 기법은 변형 필드에 대한 라벨이 필요하며, 비지도학습 기법은 영상의 토폴로지 보존을 위해 이형(diffeomorphic) 제약 또는 사이클 일관성과 같은 추가적인 제약이 필요하다. 한편, 시간에 따른 의료영상의 변화를 관측하기 위한 4D 이미징은 해부학적 구조의 변화를 분석하는 데 필요하 다. 그러나 MRI의 경우 CT, 초음파 등의 의료영상과 달리 4D 영상을 획득하는 데 오랜 시간이 걸린다. 이를 해 결하기 위한 딥 러닝 기반 영상 생성 기법 중, GAN 기반의 모델은 의료영상에 존재하지 않은 요소를 만들어낼 수 있는 단점이 있다. 또한 영상정합 기반의 생성 기법은 소스 영상의 토폴로지 보존이 가능하지만, 선행기술은 연속 영상을 생성하는 기술이 아닌, 아이, 어른 영상과 같이 기본 템플릿을 생성하는 기법이다. 최근에는 스코어 기반의 확산 모델이 영상 생성에 있어 높은 성능을 보여주고 있다. 특히 DDPM(Denoising Diffusion Probabilistic Model)은 가우시안 노이즈로부터 데이터 분포로의 Markov 변환을 학습함으로써 확률적 확산 과정을 통해 다양한 샘플을 생성하는 모델이다. 이는 다양한 컴퓨터 비전 분야에 적용되고 있지만, 영상 정합의 경우에는 동영상에 대한 변형 필드를 통해 수행되어져야 하는 점에 있어서 DDPM을 영상 정합에 적용하는 것은 도전적인 과제이다."}
{"patent_id": "10-2022-0171504", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "따라서 본 발명의 목적은 상기와 같은 문제를 해결하기 위해 안출된 것으로, DDPM을 변형 필드 생성에 적용하기 위해 디퓨즈모프(DiffuseMorph)라는 확산 모델 기반 확률적 영상 등록의 접근 방식으로 빠른 역방향 확산을 통 해 변형된 영상을 생성할 뿐만 아니라 동영상과 고정영상 사이의 연속적인 궤적을 따라 영상 등록이 가능한 확 산 모델을 이용한 비지도 학습 기반 변형 영상 정합 및 합성 영상 생성 시스템 및 그 방법을 제공하고자 하는 것이다."}
{"patent_id": "10-2022-0171504", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명에 따른 확산 모델을 이용한 비지도 학습 기반 변형 영상 정합 및 합성 영상 생성 시스템은 영상 획득장 치, 정합장치, 합성장치, 및 손실확인기를 포함하는 확산 모델을 이용한 비지도 학습 기반 변형 영상 정합 및 합성 영상 생성 시스템으로서, 상기 영상 획득장치는 동영상인 제1 영상데이터를 획득하는 제1 영상 획득장치, 및 고정영상인 제2 영상데이터를 획득하는 제2 영상 획득장치를 포함하며, 상기 정합장치는 제1 영상 획득장치 와 제2 영상 획득장치에서 제공된 상기 제1 영상데이터의 좌표와 상기 제2 영상데이터의 좌표를 대응시켜상기 제1 영상데이터와 상기 제2 영상데이터의 정합을 수행하며, 상기 합성장치는 비지도 학습 기반의 뉴럴 네트워크 를 구성하는 확산 모듈을 이용하여, 노이지한 영상을 출력하고, 출력된 노이지한 영상에 대한 반복적 역확산 프 로세스를 통해 합성영상을 생성하는 역확산 처리기를 포함한다. 또한, 본 발명에 따른 확산 모델을 이용한 비지도 학습 기반 변형 영상 정합 방법은 영상 획득장치, 정합장치, 합성장치, 및 손실확인기를 포함하는 확산 모델을 이용한 비지도 학습 기반 변형 영상 정합 및 합성 영상 생성 시스템에 의한 확산 모델을 이용한 비지도 학습 기반 변형 영상 정합 방법으로서, 상기 영상 획득장치의 제1 영 상획득장치 및 제2 영상획득장치를 통해 제1 영상데이터 및 제2 영상데이터를 각각 획득하는 단계와; 상기 정합 장치의 특징맵 추출기를 통해 상기 획득된 제1 영상데이터 및 제2 영상데이터로부터 잠재 특징맵을 추출하는 단 계; 상기 정합장치의 벡터장 추출기를 통해. 상기 추출된 잠재 특징맵을 수신하고, 상기 수신된 잠재 특징맵에 서의 모든 좌표점에 대한 벡터장을 추출하는 단계; 및 상기 정합장치의 공간 변환기를 통해, 상기 벡터장 추출 기에서 추출된 벡터장으로 변형 필드를 출력하고, 상기 출력된 변형 필드를 공간 변형 함수에 기초하여 상기 제 1 영상데이터 및 제2 영상데이터에 적용시켜 정합 영상을 생성하는 단계를 포함한다. 또한, 본 발명에 따른 확산 모델을 이용한 비지도 학습 기반 변형 영상 생성 방법은 영상 획득장치, 정합장치, 합성장치, 및 손실확인기를 포함하는 확산 모델을 이용한 비지도 학습 기반 변형 영상 정합 및 합성 영상 생성 시스템에 의한 확산 모델을 이용한 비지도 학습 기반 변형 영상 생성 방법으로서, 상기 영상 획득장치의 제1 영 상획득장치 및 제2 영상획득장치를 통해 제1 영상데이터 및 제2 영상데이터를 각각 획득하는 단계와; 비지도 학 습 기반의 뉴럴 네트워크를 구성하는 확산 모듈을 이용하여, 제1 영상데이터에 대해 포워드 확산을 적용하여 노 이지한 영상을 출력하는 단계; 및 상기 출력된 노이지한 영상에 대한 반복적 역확산 프로세스를 통해 합성영상을 생성하는 단계를 포함한다."}
{"patent_id": "10-2022-0171504", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "상술한 바와 같이, 본 발명에 따른 확산 모델을 이용한 비지도 학습 기반 변형 영상 정합 및 합성 영상 생성 시 스템 및 그 방법은 동영상과 고정영상 간의 변형에 대한 스코어 함수를 학습하는 확산 네트워크와 스코어 함수 의 잠재 기능(latent feature)을 이용하여 동영상에 대한 변형 필드를 추정하고 정합 영상을 제공하는 변형 네 트워크로 이루어지며, 엔드 투 엔드 학습(end-to-end learning)에 의하여 함께 학습됨으로써, 동영상이 고정영 상의 모양에 맞게 변형되는 방향으로의 마코브(Markov) 변환을 추정할 뿐 아니라 동영상에 대한 변형 필드를 제 공할 수 있다는 이점이 있다. 또한, 확산 모델의 스코어 함수로부터의 잠재 기능은 동영상/고정영상의 공간적 정보를 가지고 있기 때문에, 잠 재 기능을 스케일링하면, 동영상에서 고정영상으로의 연속적인 궤적을 따라 영상 정합을 수행할 뿐만 아니라 빠 른 역확산 프로세스를 통해 합성 변형 영상을 생성할 수 있다는 이점이 있다. 또한, 2D 및 3D 영상 정합 작업에 적용될 수 있으며, 기존 방법과 유사한 위상 보존으로 정확한 변형을 제공할 수 있다는 이점이 있다."}
{"patent_id": "10-2022-0171504", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 도면을 참조한 실시 예들의 상세한 설명을 통하여 본 발명에 따른 확산 모델을 이용한 비지도 학습 기반 변형 영상 정합 및 합성 영상 생성 시스템 및 그 방법을 보다 상세히 기술하기로 한다. 본 발명을 설명함에 있 어서 관련된 공지기술 또는 구성에 대한 구체적인 설명이 본 발명의 요지를 불필요하게 흐릴 수 있다고 판단되 는 경우에는 그 상세한 설명은 생략될 것이다. 그리고, 후술되는 용어들은 본 발명에서의 기능을 고려하여 정의 된 용어들로서 이는 클라이언트나 운용자, 사용자의 의도 또는 관례 등에 따라 달라질 수 있다. 그러므로 정의 는 본 명세서 전반에 걸친 내용을 토대로 내려져야 할 것이다. 도면 전체에 걸쳐 같은 참조번호는 같은 구성 요소를 가리킨다. 도 1은 본 발명에 따른 확산 모델을 이용한 비지도 학습 기반 변형 영상 정합 및 합성 영상 생성 시스템의 개략 적인 구성 블록도이며, 도 2는 본 발명에 따른 확산 모델을 이용한 비지도 학습 기반 변형 영상 정합 방법의 순 서도이며, 도 3은 본 발명에 따른 확산 모델을 이용한 비지도 학습 기반 합성 영상 생성 방법의 순서도이며, 도 4는 본 발명에 따른 DiffuseMorph에 의한 영상 정합 및 합성 영상 생성의 예시도이며, 도 5는 본 발명에 따른DiffuseMorph의 훈련 체제의 예시도이며, 도 6은 본 발명에 따른 DiffuseMorph의 추론 단계에서의 영상 정합 및 합성 영상 생성의 예시도이며, 도 7은 본 발명에 따른 고정 대상 데이터 분포를 향한 생성 프로세스의 예시도이 며, 도 8은 추정 정합 필드를 이용하여 안면 영상에 영상 정합을 시각적으로 비교한 결과의 예시도이며, 도 9는 얼굴 랜드마크가 있는 얼굴 영상의 연속적인 영상 변형 결과의 예시도이며, 도 10은 생성 프로세스를 통한 합성 변형 영상 생성 결과의 예시도이며, 도 11은 심장 MR 영상의 영상 정합 및 연속 변형 결과의 예시도이며, 도 12 는 뇌 MR 영상의 영상 정합 및 추정 정합 필드의 결과의 예시도이며, 도 13은 뇌 MR 영상 정합 실험에서 뇌 해 부학적 구조에 대한 다이스 스코어의 정량적 평가 결과의 예시도이다. 본 발명에서는 추정된 잠재적 피처가 영상을 생성하기 위해 공간 정보를 제공하는 확산 모델의 속성을 활용하여 변형 필드를 생성하기 위해 DDPM을 조정함으로써 DiffuseMorph라고 하는 새로운 비감독 변형 영상 정합 접근 방 식을 제시한다. 구체적으로 제안하는 모델은 확산 네트워크와 변형 네트워크로 구성된다. 전자의 네트워크는 동 영상과 고정영상 사이의 변형에 대한 조건부 스코어 함수를 학습하고, 후자의 네트워크는 스코어 함수에서 잠재 적 특징을 사용하여 변형 필드를 추정하고 변형된 영상을 제공한다. 이 두 네트워크는 엔드 투 엔드(end-to- end) 학습 방식으로 공동으로 학습되므로 DiffuseMorph는 동영상이 고정영상으로 변형되는 방향의 마르코프 변 환을 추정할 뿐만 아니라 동영상이 고정영상으로 왜곡되어질 정합 필드를 생성한다. 확산 모델의 조건부 스코어 함수의 잠재적 특징은 조건에 대한 공간 정보를 가지고 있기 때문에, 잠재적 특징의 선형 스케일링은 동영상에 서 고정영상까지 연속적인 궤적을 따라 변형 필드를 제공할 수 있다. 이제, 도 1을 참조하여, 본 발명에 따른 확산 모델을 이용한 비지도 학습 기반 변형 영상 정합 및 합성 영상 생 성 시스템을 살펴보고자 한다. 도 1에 도시된 바와 같이, 본 발명에 따른 확산 모델을 이용한 비지도 학습 기반 변형 영상 정합 및 합성 영상 생성 시스템은 영상 획득장치, 정합장치, 합성장치, 및 손실 확인기를 포함하고, 영상획득 장치는 제1 영상획득장치, 제2 영상획득장치를 포함하며, 정합 장치는 특징맵 추출기 , 벡터장 추출기, 공간 변환기를 포함하며, 합성장치는 정합장치의 특징맵 추출기 와 역확산 처리기를 포함한다. 여기서, 영상 획득장치는 예를 들어, 멀티 위상 초광각 망막 영상데이터를 획득하는 광각안저카메라일 수 있다. 이때, 제1 영상 획득장치는 광각안저카메라에서 동영상데이터인 제1 영상데이터(moving image dat a)를 획득하는 이미지 센서이며, 획득된 제1 영상데이터를 특징맵 추출기, 벡터장 추출기, 및 공간 변환기로 제공한다. 또한, 제2 영상 획득장치는 광각안저카메라에서 고정영상데이터인 제2 영상데이터(fixed image data)를 획 득하는 이미지 센서이며, 획득된 제2 영상데이터를 특징맵 추출기, 벡터장 추출기, 및 공간 변환기 로 제공한다. 또한, 정합장치는 제1 영상 획득장치와 제2 영상 획득장치에서 제공된 제1 영상데이터와 제2 영 상데이터의 정합을 수행한다. 이를 위해, 정합장치는 제1 영상 획득장치에 의해 획득된 제1 영상데이 터의 좌표와 제2 영상 획득장치에의해 획득된 제2 영상데이터의 좌표를 대응시킨다. 이러한 정합장치(20 0)는 특징맵 추출기, 벡터장 추출기, 공간 변환기를 포함할 수 있으며, 정합 장치는 컴퓨 터, 태블릿 PC 등의 장치일 수 있다. 또한, 특징맵 추출기는, 비지도 학습 기반의 뉴럴 네트워크를 구성하는 확산 모듈을 이용하여, 제1 영상 획득장치에서 획득된 제1 영상데이터 및 제2 영상 획득장치에서 획득된 제2 영상데이터를 이용하여 잠재 특징맵을 추출한다. 이를 위해, 특징맵 추출기는 프랜지 필터(frangi filter), 혈관 및 분기점 검출 기, SIFT 및 에지기반 해리스 코너 검출기 등을 포함하는 다양한 특징맵 추출기를 적용할 수 있다. 또한, 벡터장 추출기는 특징맵 추출기에서 추출된 잠재 특징맵을 수신하고, 수신된 잠재 특징맵에서 의 모든 좌펴에 대한 벡터장을 추출한다. 또한, 공간 변환기는 경사하강법(gradient-descent)을 사용하는 최적화에서 손실 함수와 관련된 매개 변수 를 차별화 한다. 이를 위해, 공간변환기는 쌍선형(bilinear) 보간을 이용하여 이미지의 픽셀 사이의 값을 계산한다. 이러한 공간변환기는, 비지도 학습 기반의 뉴럴 네트워크를 구성하는 정합 모듈을 이용하여 벡 터장 추출기에서 추출된 벡터장으로 변형 필드를 출력하고, 출력된 변형 필드를 영상공간 변형 함수에 기 초하여 제1 영상데이터 및 제2 영상데이터에 적용시켜 정합 영상을 생성한다. 또한, 손실확인기는 특징맵 추출기, 벡터장 추출기, 공간 변환기에 연결되어, 영상데이터 정합 시에 손실율을 최소로 할 수 있는 영상데이터를 선택하여 영상데이터를 정합시킨다. 또한, 합성장치의 역확산 처리기는, 비지도 학습 기반의 뉴럴 네트워크를 구성하는 확산 모듈을 이용 하여, 노이지한 영상을 출력하고, 출력된 노이지한 영상에 대한 반복적 역확산 프로세스를 통해 합성영상을 생 성한다. 한편, 정합장치와 합성장치는 특징맵 추출기를 공유하며, 툭징맵 추출기는 정합장치 의 특징맵 추출기에 대한 전술한 바와 같은 설명과 동일하므로 이에 대한 상세한 설명은 생략된다. 또 한편, 본 발명의 실시 예에서는 영상 획득장치가 서로 다른 제1 영상 획득장치와 제2 영상 획득장 치를 포함하는 것을 예로 설명하고 있으나, 이는 설명의 편의를 위한 것이다. 즉, 제1 영상 획득장치(11 0)와 제2 영상 획득장치는 하나의 이미지 센서로 구성되되, 영상 획득장치를 이용하는 사용자에 의해 동영상데이터 획득 시 특정 시점에 동영상데이터를 캡쳐하여 고정영상데이터를 획득할 수 있다. 또한, 본 발명 의 실 시예에서는 설명의 편의를 위해 광각안저카메라를 예로 설명하고 있으나, 반드시 이에 한정되는 것은 아 니며, Xray, 초음파, CT(computed tomography), MRI(magnetic resonance imaging), PET(positron emission tomography) 등과 같이 동영상데이터와 고정영상데이터를 획득할 수 있는 의료영상 획득장치에 변경적용이 가능 하다. 이제, 도 2를 참조하여, 본 발명에 따른 확산 모델을 이용한 비지도 학습 기반 변형 영상 정합 방법을 살펴보고 자 한다. 도 2에 도시된 바와 같이, 본 발명에 따른 확산 모델을 이용한 비지도 학습 기반 변형 영상 정합 방법은 먼저, 단계 S210에서 제1 영상획득장치 및 제2 영상획득장치를 통해 제1 영상데이터 및 제2 영상데이터를 각각 획득한다. 이후, 단계 S230에서, 비지도 학습 기반의 뉴럴 네트워크를 구성하는 확산 모듈을 이용하여, 특징맵 추출기 를 통해 획득된 제1 영상데이터 및 제2 영상데이터로부터 잠재 특징맵을 추출한다. 여기서, 추출된 잠재 특징맵은 제1 영상 데이터 및 제2 영상 데이터에서 확인되는 모든 좌표점을 포함할 수 있가. 또한, 제1 영상데 이터가 동영상이고 제2 영상데이터가 고정 영상인 경우, 제1 영상데이터를 제2 영상데이터에 정합하기 위해 제2 영상데이터에 대한 변형 잠재 특징 맵을 출력한다. 그 후, 단계 S250에서, 추출된 잠재 특징맵을 수신하고, 벡터장 추출기를 통해 수신된 잠재 특징맵에서의 모든 좌표점에 대한 벡터장을 추출한다. 이후, 단계 S270에서, 비지도 학습 기반의 뉴럴 네트워크를 구성하는 정합 모듈을 이용하여, 공간 변환기 를 통해 벡터장 추출기에서 추출된 벡터장으로 변형 필드를 출력하고, 출력된 변형 필드를 공간 변형 함수 에 기초하여 제1 영상데이터 및 제2 영상데이터에 적용시켜 정합 영상을 생성한다. 여기서, 잠재 특징맵을 이용 하여, 제1 영상데이터를 제2 영상데이터에 정합하기 위해 제1 영상데이터에 대한 변형 필드를 출력하고, 공간 변형함수를 이용하여 제1 영상데이터에 제1 영상데이터에 대한 변형 필드를 적용함으로써 정합 영상을 생성할 수 있다. 이제, 도 3을 참조하여, 본 발명에 따른 확산 모델을 이용한 비지도 학습 기반 합성 생성 방법을 살펴보고자 한 다. 도 3에 도시된 바와 같이, 본 발명에 따른 확산 모델을 이용한 비지도 학습 기반 합성 영상 생성 방법은 먼저, 단계 S310에서 제1 영상획득장치 및 제2 영상획득장치를 통해 제1 영상데이터 및 제2 영상데이터를 각각 획득한다. 이후, 단계 S330에서, 비지도 학습 기반의 뉴럴 네트워크를 구성하는 확산 모듈을 이용하여, 제1 영상데이터에 대해 포워드 확산을 적용하여 노이지한 영상을 출력한다. 그 후, 단계 S350에서, 비지도 학습 기반의 뉴럴 네트워크를 구성하는 확산 모듈을 이용하여, 출력된 노이지한 영상에 대한 반복적 역확산 프로세스를 통해 합성영상을 생성한다. 여기서, 제1 영상데이터가 동영상이고 제2 영상데이터가 고정 영상인 경우, 시간 스텝에 따라 제1 영상데이터를 제2 영상데이터로 합성하기 위해 제2 영상 데이터에 대한 변형 잠재 특징 맵을 출력하고 이를 역확산 프로세스에 적용함으로써 합성영상을 생성할 수 있다 한편, 뉴럴 네트워크는 제2 영상데이터와 제1 영상데이터 간의 데이터 정합에서의 정합 손실(registration loss) 및 제1 영상데이터와 제2 영상데이터에 대한 잠재 특징맵의 확산 손실(diffusion loss)에 기초하여 비지도 학습될 수 있다. 또한, 정합 영상 생성 및 합성 영상 생성에 있어, 제1 영상 획득장치 및 제2 영상 획득장치로 제1 영상데이터 및 제2 영상데이터를 취득하는 단계는 동일하나, 이후 정합 영상 생성 단계 및 합성 영상 생성단계로 나뉘어 지 게 되며, 비지도 학습 기반의 뉴럴 네트워크를 구성하는 확산 모듈은 동일하게 사용된다. 이제, 도 4를 참조하여 본 발명에 따른 DiffuseMorph에 의한 영상 정합 및 합성 영상 생성을 살펴보고자 한다. 도 4에 도시된 바와 같이, 본 발명에 따른 DiffuseMorph에 의한 영상 정합 및 합성 영상 생성에서 본 발명의 DiffuseMorph는 연속 궤적을 따라 영상 정합과 합성 변형 영상 생성을 모두 허용한다. 여기서, DiffuseMorph는 변형 필드를 생성할 때 단순히 잠재적 특징을 스케일링하여 연속 궤적을 따라 변형 가 능한 영상 정합을 제공할 뿐만 아니라 역확산 프로세스에 의한 연속 생성을 통해 합성 변형 영상을 제공한다. 특히 훈련된 모델은 변형 네트워크의 입력으로 사용되는 잠재적 특징을 단순히 보간하여 동영상에서 고정영상으 로 연속 변형을 제공한다. 또한 본 발명의 모델은 고정영상과 유사한 합성 변형 영상을 빠르게 생성할 수 있다. 본 발명에선 확산 절차를 더욱 가속화하기 위해 임의의 가우시안 노이즈로부터 시작하는 대신에 순방향 확산을 통해 동영상을 한 단계 전파한 다음 DDPM의 역확산 프로세스를 통해 반복적으로 정제하는 생성 프로세스를 제시 한다. 이러한 제시는 확산 단계의 수를 크게 줄이고 샘플이 원래 동영상 콘텐츠를 유지하도록 한다. 본 발명에선, 2D 얼굴 표정 정합 및 3D 의료 영상 정합 작업에서 제안한 방법의 성능을 시연한다. 실험 결과는 발명의 모델이 정합 정확도에서 높은 성능을 달성함을 확인한다. 또한, 확산 모델에서 추정된 잠재적 특징 덕분 에 본 발명의 방법은 비교 학습 기반 정합 방법보다 더 사실적인 동영상과 고정영상 사이의 연속적인 궤적을 따"}
{"patent_id": "10-2022-0171504", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "라 실시간 영상 정합이 가능한다. 본 발명의 주요 기여는 다음과 같이 요약된다. - 한 쌍의 동영상과 고정영상에 조건을 둔 노이즈 제거 확산 모델을 사용하는 최초의 영상 정합 방법인 DiffuseMorph를 제안한다. - 제안한 모델이 훈련되면 본 발명의 모델은 잠재적 특징을 스케일하여 동영상에서 고정영상까지 연속적인 궤적 을 따라 영상 정합을 수행할 뿐만 아니라 빠른 역확산 프로세스를 통해 합성 변형 영상을 생성한다. - 본 발명의 방법이 2D 및 3D 영상 정합 작업에 적용될 수 있음을 입증하고 기존 방법과 유사한 위상 보존으로 정확한 변형을 제공한다. 이하, 영상 정합에 대해 보다 상세히 살펴보고자 한다. 변형 가능한 영상 정합 동영상 m과 고정영상 f가 주어지면 고전적인 변형 영상 정합 방법은 다음의 식과 같은 최적화 문제를 해결하 여 수행된다."}
{"patent_id": "10-2022-0171504", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "여기서 는 동영상을 고정영상으로 변형하기 위한 최적의 정합 필드이다. Lsim은 변형된 영상과 고정영상 사 이의 유사도를 계산하는 비유사성 함수이고, Lreg는 변형 필드의 정규화 페널티이다. 에너지 함수를 최소화함으 로써 변형된 영상 은 동영상을 왜곡하여 추정한다. 특히, 변형 매핑이 미분 가능하고 반전 가능하도록 토폴 로지를 보존함으로써, 필드 에 추가 제약을 부과할 때 미분동형(diffeomorphic) 정합이 달성될 수 있다. 학습 기반 정합 방법 기존의 정합 방식은 일반적으로 많은 계산과 긴 실행 시간이 필요하기 때문에 최근에는 신경망이 훈련되면 변형 필드를 추정하는 딥 러닝 방법이 광범위하게 연구되고 있다. 그러나 감독 학습 방법은 학습을 위해 고품질 레이 블이 필요한 ground-truth 정합 필드를 사용하여 네트워크를 학습한다. 이를 완화하기 위해 세분화 맵과 같은 의사 레이블을 사용하는 약 지도(weakly-supervised) 정합 모델이 개발되었다. 반면 비지도 학습 방식은 변형된 영상과 고정 참조 영상 사이의 유사성을 계산하여 네트워크를 훈련한다. 토폴로지 보존을 보장하기 위해 학습 기반 미분동형 정합 방법도 제시되며, 이 방법에는 미분동형 제약 조건에 대한 스케일링 및 제곱 통합 계층이 있다. 이러한 기존 방법은 정합 필드의 크기를 조정하거나 더 짧은 시간의 척도로 속도 필드를 통합하여 동영상과 고 정영상 사이에 중간 변형을 제공할 수 있다. 그러나 본 발명의 방법은 동영상과 고정영상의 공간 정보를 가진 잠재적 특징을 스케일링하여 보다 사실적인 연속 변형을 생성하여 영상 정합 성능을 향상시킨다. 노이즈 제거 확산 확률 모델 최근에는 단순 가우시안 분포를 데이터 분포로 전환하기 위해 마르코프 연쇄 프로세스를 학습하는 생성 모델로 노이즈 제거 확산 확률 모델(DDPM, Denoising Diffusion Probabilistic Model)이 제시된다. 순방향확산 프로세 스에서 마르코프 체인(Markov chain)을 이용하여 데이터 x0에 노이즈를 점진적으로 추가하는데, 각 샘플링 단계 에서 동안 잠재적 변수 xt,는 다음의 식와 같이 가우스 전이로 표현된다."}
{"patent_id": "10-2022-0171504", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "여기서 0 < βt < 1은 노이즈의 분산이다. x0이 주어지면 xt의 결과 분포는 다음의 식과 같이 표현된다."}
{"patent_id": "10-2022-0171504", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "여기서, 이다. 따라서, 주어진 에 대해, xt는 다음의 식과 같이 샘플링할 수 있다."}
{"patent_id": "10-2022-0171504", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "역확산을 수행하기 위한 생성 프로세스를 위해, DDPM은 매개변수화된 가우시안 프로세스 를 학습 한다. 는 다음의 식과 같이 표현된다."}
{"patent_id": "10-2022-0171504", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 7, "content": "여기서 는 고정 분산이고 는 다음의 식과 같이 정의된 학습 평균이다."}
{"patent_id": "10-2022-0171504", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 8, "content": "여기서, 은 매개변수화된 모델이다. 실제로 모델 은 의 기울기인 스코어 함수 의 스케일링된 버전일 뿐이다. 일단 모델 이 훈련되면 데이터는 다음과 같은 확률적 생성 단계 에 의해 샘플링된다. 여기서, 이고, 이다. 조건부 확산 모델 원하는 시맨틱을 가진 영상을 생성하기 위해 최근 조건부 참조 영상을 네트워크 또는 생성 프로세스에 제공하는 조건부 확산 모델이 제안되었다. DDIM은 역확산 프로세스의 영상 생성을 제어하기 위해 초기 조건에서 시작하는 결정론적 비마르코프(non-Markovian 생성 프로세스를 제안한다. SR3는 초고해상도 작업을 위해 조건부 영상으로 DDPM을 훈련시키는 방법을 제시한다. ILVR은 비조건 모델을 사용하여 조건화 반복 생성 프로세스를 제안한다. 그러나 이러한 확산 모델 기반의 생성 방법은 영상 생성에 대한 우려가 있으며 정합을 위한 어떠한 변형 필드를 생성하지 않기 때문에 영상 정합에 사용할 수 없다. 이제, 도 5를 참조하여 본 발명에 따른 DiffuseMorph의 훈련 체제를 살펴보고자 한다. 도 5에 도시된 바와 같이, 본 발명에 따른 DiffuseMorph의 훈련 체제는 한 쌍의 동영상m 및 고정영상 f라는 조 건이 주어지면 확산 네트워크 는 변형의 조건 스코어 함수를 학습하고 변형 네트워크 은 정합 필드 를 출력한다. 그후 공간 변환 계층(STL, spatial transformation layer)를 사용하여 동영상을 고정영상으로 왜곡된 다. DiffuseMorph의 체제 DDPM의 기능을 활용하여 새로운 확산 모델 기반 비지도 영상 정합 방식을 개발하는 것을 목표로 한다. 영상 정 합은 변형 필드를 사용하여 동영상을 왜곡하는 것이므로, 도 5와 같이 두 개의 네트워크로 모델을 설계한다. 하 나는 조건부 스코어 함수를 추정하기 위한 확산 네트워크 이고, 다른 하나는 실제로 스코어 함수를 사용하여 정합 필드를 출력하는 변형 네트워크 이다. 특히, 움직이는 소스 영상 m과 고정 기준 영상 f에 대해 확산 네트워크 는 조건 c = (m, f)에서 동영상과 고정영상 사이의 변형의 조건부 스코어 함수를 학습하도록 훈련된다. 이를 위해 대상의 잠재적 변수 x를 식 으로 샘플링하고, 고정영상을 대상, 즉 x0 = f로 정의한다. 또한 네트워크 가 노이즈 수준을 인식하도록 “ Neural Information Processing Systems”와 유사한 네트워크에 노이즈에 대한 시간 단계의 수를 제공한다. 한편, 변형 네트워크 은 움직이는 소스 영상 m 뿐만 아니라 확산 네트워크의 출력인 조건부 스코어 함수 의 조건부 잠재적 특성을 취한다. 그후, 네트워크는 정합 필드 를 출력하고 공간 변환 계층(STL, spatial transformation layer)을 사용하여 움직이는 소스 영상 m을 왜곡함으로써 변형된 영상 을 제공한다. 실험 에서 2D/3D 영상을 변형하기 위해 bi-/trilinear 보간법(interpolation)을 사용하는 변형 함수를 채택한다. 손실 함수 확산 네트워크 와 변형 네트워크 은 엔드 투 엔드(end-to end) 학습을 통해 공동으로 학습된다. 따라 서 모델 학습을 위해 대상 함수를 다음의 식과 같이 설계한다."}
{"patent_id": "10-2022-0171504", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 9, "content": "여기서, 과 은 각기 확산 손실 및 정합 손실이고 λ는 하이퍼 매개변수이다. 각각의 손 실 함수의 상세한 설명은 다음의 식과 같다."}
{"patent_id": "10-2022-0171504", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 10, "content": "여기서, 이다. 또한, 정합 손실은 변형된 소스 영상이 식에서 전통적인 에너지 함수로서 설계 된 고정영상과 유사한 모양을 갖도록 다음의 식와 같이 변형 필드를 추정하는 것이다."}
{"patent_id": "10-2022-0171504", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 11, "content": "여기서, 확산 네트워크 출력에 관한 에 대해 이고 은 하이퍼 매개변수이다. 식의 첫 번째 항은 변형된 영상과 고정영상 간의 국부적 정규화 상호관계이고, 두 번째 항은 정합 필드에 대한 평활 도 페널티이다. λR = 1로 설정한다. 두 가지 손실 함수의 순 효과는 동영상 및 고정영상의 공간 정보를 갖는 변형의 조건부 스코어 함수에 대한 잠 재적 특징을 추종하도록 가 훈련된다는 점에서 주목할 만한다. 따라서, 잠재적 특징은 본 발명의 모델이 토 폴로지 보존을 제공할 수 있는 연속 궤적을 따라 영상 정합을 수행하는 데 도움이 된다. 또한, 역확산 프로세스 와 결합되면 잠재적 특징은 역확산을 유도하여 동영상 초기화에서 합성 변형 영상을 생성한다(도 6 참조, 도 6 은 추론 단계에서, 동영상을 왜곡하는 영상 정합 을 제공할 뿐만 아니라 합성 영상 도 생성한다). DiffuseMorph를 사용한 영상 정합 본 발명의 모델의 네트워크가 훈련되면 추론 단계에서 고정영상과 정렬되어질 동영상에 대한 변형 필드를 추정 하여 영상 정합을 제공한다. 본 발명의 모델의 엔드 투 엔드(end-to-end) 훈련 덕분에 확산 네트워크는 변형 네 트워크가 정규 정합 필드를 생성할 수 있도록 한다. 구체적으로 및 의 학습된 매개변수를 사용하여 t = 0에서 정합 필드는 다음의 식 과 같이 추정된다. 여기서 x0은 고정 대상 영상 f로 설정된다. 그후, 변형된 영상 은 공간 변환 계층을 통해 추정된 필드"}
{"patent_id": "10-2022-0171504", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 12, "content": "을 사용하여 계산된다. 따라서 본 발명의 모델은 단일 단계에서 매끄러운 정합 필드로 영상 정합을 수행한다. 연속 궤적을 따른 영상 정합 동영상을 고정영상으로 왜곡하는 영상 정합에서 본 발명의 모델은 고정영상을 향한 궤적을 따라 동영상의 지속 적인 변형을 제공한다. 이는 변형 네트워크가 잠재적 특징에 따라 정합 필드를 추정하기 때문에 가능한다. 구체 적으로, 조건부 스코어로부터의 잠재적 특징이 0으로 설정되면, 변형 네트워크는 동영상을 거의 왜곡하지 않는 정합 필드를 출력하는 반면, 잠재적 특징이 식에서와 같이 주어지면 변형 네트워크는 동영상을 고정영상으 로 변형하는 정합 필드를 추정한다. 따라서, 이하 알고리즘 1(연속한 영상 정합)에 기술된 바와 같이, 잠재적 특징 에 대해, 연속한 영상 변형에 대한 정합 필드 는 잠재적 특징을 단순히 보간함으로써 다음의 식과 같이 생성될 수 있다."}
{"patent_id": "10-2022-0171504", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 13, "content": "여기서, 에 대해, 이다."}
{"patent_id": "10-2022-0171504", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 14, "content": "이러한 흥미로운 현상은 나중에 실험에서 관찰되어질 변형의 조건부 스코어 함수를 학습함으로써 발생한다고 여 겨진다. 이제, 도 7을 참조하여 본 발명에 따른 고정 대상 데이터 분포를 향한 생성 프로세스를 살펴보고자 한다. 역확산을 통한 합성 영상 생성 본 발명에서 확산 네트워크 자체에 의해 생성된 잠재적 특징은 역확산 프로세스를 통해 합성 변형 영상 생성을 가이드한다. 여기서, 확산 네트워크는 동영상과 고정영상 사이의 변형에 대한 조건부 스코어 함수를 학습하므로, 본 발명의 영상 생성은 순수한 가우시안 노이즈 에서 시작하는 기존 DDPM의 조건부 생 성 프로세스와 달리 동영상에서 시작된다. 원래의 동영상 m으로 초기 상태를 설정하면 다음의 식와 같이 한 단계 전진 확산이 수행된다."}
{"patent_id": "10-2022-0171504", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 15, "content": "여기서, 및 는 시간 단계 에서 노이즈 레벨이다. 여기에서, 시간 단계 T는 영상 의 정체성(identity)을 잃지 않는 값으로 설정된다. 이 순방향 샘플링은 도 7에서와 같이 동영상 분포가 고정영 상 분포에 가까워지도록 하여 역확산 단계의 수와 생성 시간을 줄이다. 그 후, xT 에서 시작하여 고정영상 f에 맞는 합성 영상 x0의 생성은 t = T에서 t = 1까지 다음의 식과 같은 역 확산 프로세스에 의해 수행된다. 여기서, . 여기에서 역확산의 전체 단계를 선택할 때, 효율적인 추론 방법을 제시하는 것을 사용한 다. 따라서 샘플링 단계의 수를 유연하게 설정할 수 있으며 실험에서는 역방향 단계를 최대 200으로 설정한다. DiffuseMorph의 이 생성 프로세스의 의사코드는 이하 알고리즘 2(합성 영상 생성 프로세스)에 기술되어 있다."}
{"patent_id": "10-2022-0171504", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 16, "content": "실험 결과 DiffuseMorph가 동영상에서 고정영상으로 고품질 변형 영상을 생성한다는 것을 입증하기 위해, 다양한 영상 정 합 작업에 본 발명의 방법을 적용한다. 2D 얼굴 표정 영상과 3D 심장 MR 스캔을 이용하여 피사체 내 영상 정합 에 대한 실험을 진행한다. 또한, 개별 뇌 영상을 공통 아틀라스(Atlas)로 변형하는 3D 뇌 MR 정합에 본 발명의 모델을 적용한다. 데이터 세트 및 훈련 세부사항은 다음과 같다. 데이터 세트 2D 얼굴 영상의 경우 RaFD(Radboud Faces Database)를 사용한다. 67명의 피험자로부터 수집한 8개의 얼굴 표정 (중립, 분노, 경멸, 역겨움, 두려움, 행복, 슬픔, 놀람)이 포함되어 있다. 각 표정에 대해 3가지 시선 방향이 제공된다. 데이터를 640×640으로 자르고 128×128로 크기를 조정한 다음 RGB 영상을 그레이 스케일로 변환한다. 데이터를 교육, 검증, 및 테스트를 위해 각각 53, 7, 및 7 주제로 나누었다. 3D 심장 MR 스캔의 경우, 확장기에서 수축기 단계까지 100개의 4D 측두부 심장 MRI 데이터를 제공하는 ACDC 데 이터 세트와 단계의 양쪽 끝에서 세분화 맵을 사용한다. 1.5×1.5×3.15mm의 복셀(voxel) 간격으로 모든 스캔을 리샘플링하고 128×128×32로 자르고 강도를 [-1, 1]로 정규화한다. 교육 및 테스트를 위해 90 및 10 스캔을 사 용한다. 또한 3D 뇌 MR 정합을 위해 OASIS-3 데이터 세트를 사용한다. FreeSurfer에서 뇌 MR 영상과 해당 체적 세분화 맵을 제공한다. 본 발명은 1mm3 등방성 복셀, 아핀 공간 정규화 및 뇌 추출을 사용하여 256 × 256 × 256 그리 드로 영상 리샘플링하여 전처리한 1156개의 T1 가중 스캔을 사용한다. 영상은 160×192×224로 잘렸다. 교육, 검증 및 테스트에 각각 1027, 93 및 129 스캔을 사용한다. 구현 세부정보 본 발명의 모델은 파이썬(Python)의 PyTorch 라이브러리를 사용하여 구현되었다. 확산 네트워크를 위해 DDPM에 서 설계된 네트워크 아키텍처를 사용하고, Ttrain = 2000으로 선형 스케줄링하여 노이즈 레벨을 10-6에서 10-2로 설정하였다. 또한 변형 네트워크를 위해 VoxelMorph-1의 백본(backbone)을 사용하였다. 여기에서 본 발명은 영 상의 크기, 예를 들어, 2D 영상 정합을 위한 2D 전환 계층에 따른 네트워크의 계층을 구성한다. 얼굴 데이터 세 트를 위해, 하이퍼 파라미터를 λ = 2로 설정하고 40 epoch 동안 학습률 5 x 10-6으로 모델을 학습한다. 심장 MR 데이터를 위해, 하이퍼 파라미터를 λ = 20으로 설정하고 800 epoch 동안 학습률 2 x 10-4로 모델을 학습시 켰다. 또한, 뇌 MR 데이터를 사용하여 하이퍼 파라미터를 λ = 10으로 설정하고 60 epoch 동안 학습률 1 x 10-4 로 모델을 학습시켰다. 단일 Nvidia Quadro RTX 6000 GPU를 사용하여 Adam 최적화 알고리즘으로 모델을 교육한 다.평가 정합 성능을 평가하기 위해 정합 필드 에서 야코비 행렬식(Jacobian determinant)의 비-포지티브 (non-positive) 값의 백분율을 계산하는데, 이는 정합의 일대일 매핑이 손실되었음을 나타낸다. 여기서 얼굴 영 상의 경우, 변형된 영상과 고정영상 사이에서 NMSE와 SSIM을 측정한다. MR 영상의 경우, 변형된 세분화 맵과 여 러 해부학적 구조에 대한 그라운드-트루스 레이블(ground-truth labels) 사이의 다이스(Dice) 스코어를 계산한 다. 한편, 심장 스캔의 연속 변형 품질을 평가하기 위해 변형된 영상과 실제 데이터 간의 PSNR 및 NMSE를 계산 한다. 비교 학습 기반 모델의 경우 공정한 비교를 위해 동일한 변형 네트워크 아키텍처와 매개 변수를 사용한다. 이제, 도 8을 참조하여 추정 정합 필드를 이용하여 안면 영상에 영상 정합을 시각적으로 비교한 결과를 살펴보 고자 한다. 도 8에 도시된 바와 같이, 추정 정합 필드(우)를 이용하여 안면 영상(좌)에 영상 정합을 시각적으로 비교한 결 과는 오른쪽을 응시하는 슬픈 영상에서 정면을 응시하는 경멸적인 영상(위)로, 왼쪽을 응시하는 혐오스러운 영 상에서 정면을 응시하는 두려운 영상(아래)로 변형된다. MSE/SSIM의 평균값은 각 정합 결과에 표시된다. 피험자 내 2D 얼굴 영상 정합 결과 본 발명은 DiffuseMorph를 VM 및 VM-diff과 비교한다. 각 RGB 채널에 정합 필드를 적용하여 RGB 스케일의 변형 된 영상에 대한 영상 정합 성능을 테스트한다. 도 8은 정합 결과의 시각적 비교를 보여준다. VM 및 VM-diff와 비교할 때 본 발명의 모델은 소스 영상을 대상 영상과 더 정확하게 정렬되도록 변형한다. 또한, 이하 표 1에 보 고된 바와 같이 본 발명의 모델은 더 낮은 NMSE와 더 높은 SSIM을 달성한다. 또한, 본 발명의 정합 필드에 대한 야코비 행렬식의 측정 기준(metric)은 미분동형 제약 조건이 있는 VM-diff와 비슷한 값을 보여준다. 이러한 결 과는 본 발명의 미분동형이 고품질 영상 정합을 제공한다는 것을 나타낸다. 표 1"}
{"patent_id": "10-2022-0171504", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 17, "content": "표 1에는 표정 영상 정합의 정량적 평가 결과가 표시되며. 표준 편차는 괄호 안에 표시된다. 이제, 도 9를 참조하여, 얼굴 랜드마크가 있는 얼굴 영상의 연속적인 영상 변형 결과를 살펴보고자 한다. 연속적인 영상 변형 또한, 움직이는 소스에서 고정 대상으로 얼굴 표정의 연속 변형도 수행한다. 도 9는 본 발명의 모델의 중간 영 상과 비교 방법을 보여준다. 본 발명은 정합 필드, 즉 인 의 크기를 조정하여 VM의 결 과를 얻었고 시간의 척도 즉, 에 따라 속도 필드를 통합하여 VM-diff의 결과를 얻었다. 여기서 v는 시 간 단계의 수이다. VM의 추정 정합 필드는 규모만 다를 뿐 상대적인 공간 분포는 변하지 않음을 알 수 있다. 또 한 VM-diff는 규칙적으로 연속적인 변형을 제공하지 않는다. 또 한편, 본 발명의 방법에서는 중간 변형 수준에서 변화의 중요도에 따라 정합 필드가 η에 따라 불균일하게 변화한다. 또한 본 발명의 방법의 향상된 성능은 파이썬(Python)의 dlib 라이브러리에서 추출한 얼굴 랜드마크 를 사용하여 정량적으로 검증할 수도 있다. 특히 도 9의 시각적 결과와 MSE 값은 본 발명의 모델이 연속 변형에 대해 우수한 성능을 제공한다는 것을 보여 주며 변형에 대한 조건부 스코어의 중요성을 나타낸다. 도 9에서, 변형은 오른쪽을 응시하는 혐오 영상에서 왼쪽을 응시하는 경멸적인 영상으로 진행된다. 변형된 랜드 마크와 대상 랜드마크 사이의 MSE 평균이 각 결과에 표시된다.이제, 도 10을 참조하여, 생성 프로세스를 통한 합성 변형 영상 생성 결과를 살펴보고자 한다. 합성 변형 영상 생성 DiffuseMorph에서 영상 생성 기능을 확인하기 위해 얼굴 영상을 사용하여 생성을 평가한다. 여기서 생성 프로세 스는 학습 단계에서 보이지 않는 영상을 사용하여 수행되었다. 도 10은 움직이는 소스와 고정 타겟 영상이 주어 졌을 때 생성된 샘플 을 보여준다. 샘플은 순방향 확산을 위한 노이즈 레벨 α200의 노이즈가 있는 동영상에서 얻는다. 역 확산 단계의 수를 80으로 설정한다. 결과에서 볼 수 있듯이 모델은 다양한 표정 쌍에 대해 대상 영 상과 유사한 합성 변형 영상을 제공한다. 또한, 정합 필드를 이용한 왜곡된 영상 m(φ)와 비교하였을 때, 고정 영상에서 보여진 치아가 동영상에 없는 경우에, 본 발명의 생성 프로세스가 영상 변형을 제공하는 데 효과적임 을 관찰할 수 있다. 이제, 도 11을 참조하여, 심장 MR 영상의 영상 정합 및 연속 변형 결과를 살펴보고자 한다. 도 11에서 정합 결과는 세분화 맵의 중첩된 윤곽을 보여준다(녹색: RV, 빨간색: Myo, 파란색: BP). GT는 지상 실측 데이터이다. 피험자 내 3차원 심장 MR 영상 정합 결과 수축기말 영상과 정렬된 확장기말 영상의 영상 정합을 테스트한다. 표 2는 야코비 메트릭 뿐만 아니라 좌심장 혈액풀(BP), 심근(Myo), 좌심실(LV), 우심실(RV) 및 이들 전체 영역의 세분화 맵에 대한 평균 다이스 스코어의 정합 결과를 기술한다. 메트릭. VM 및 VM-diff의 기본 방법과 비교할 때 본 발명의 모델은 토폴로지 보존에서 비슷한 수의 접기로 높은 정합 정확도를 달성한다. 또한, 본 발명이 사용한 심장 데이터 세트는 확장기 말기에서 수축기 말기 사이의 4D 데이터를 제공하므로 연속 변형에 대한 정량적 평가를 수행한다. 이하 표 2에서 보는 바와 같이 변형 영상과 실측 기준 영상 사이의 PSNR 과 NMSE를 측정한 결과 비교 방법보다 실측 영상과 유사한 연속 변형 영상을 제공하였다. 도 11의 시각적 비교 결과도 본 발명의 방법의 우수성을 보여준다. 표 2"}
{"patent_id": "10-2022-0171504", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 18, "content": "표 2에는 심장 영상 정합의 정량적 비교 결과가 표시되며, 표준 편차는 괄호 안에 표시된다. 이제, 도 12를 참조하여, 뇌 MR 영상의 영상 정합 및 추정 정합 필드의 결과를 살펴보고자 한다. 도 12에서 여러 해부학적 구조의 분할 지도가 윤곽선으로 중첩된다(파란색: 뇌실, 녹색: 시상, 주황색: 세 번째 뇌실, 분홍색: 해마). 각 구조에 대한 다이스 스코어는 각 결과에 해당 색상으로 표시된다. 아틀라스 기반 3차원 뇌 MR 영상 정합 결과 뇌 MR 영상 정합을 위해 DiffuseMorph를 SyN, VM, VM-diff, SYMNet, MSDIRNet 및 CM과 같은 비교 방법과 비교 한다. 도 12의 시각적 비교 결과에서 볼 수 있듯이 모델은 매끄러운 정합 필드를 추정하고 기본 모델과 비교하 여 고정영상에 더 정확하게 정렬된 변형된 동영상을 생성한다. 이것은 또한 여러 뇌 해부학적 구조의 분할 지도 의 윤곽을 통해 관찰할 수 있다. 이제, 도 13을 참조하여, 뇌 MR 영상 정합 실험에서 뇌 해부학적 구조에 대한 다이스 스코어의 정량적 평가 결 과를 살펴보고자 한다. 도 13 및 이하 표 3은 정량적 평가 결과를 보고한다. 이를 통해 제안하는 방법이 기존의 학습 기반 방법보다 야 코비 행렬식의 비-포지티브(non-positive) 값이 적으면서 더 높은 Dice 스코어를 얻을 수 있음을 보여주며, 이는 제안하는 방법이 향상된 토폴로지 보존으로 정확한 영상 정합을 제공할 수 있음을 경험적으로 시사한다. 표 3"}
{"patent_id": "10-2022-0171504", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 19, "content": "표 3에는 뇌 MR 영상 정합의 정량적 평가 결과가 표시되며, 표준 편차는 괄호 안에 표시된다. 정합 손실의 영향에 관한 연구 정합 손실이 모델의 성능에 미치는 영향을 알아보기 위해 뇌 MR 데이터를 사용하여 의 λ 값을 변경하여 비 교 연구를 수행한다. 이하, 표 4에 보고된 바와 같이, λ가 낮을 때 Dice 스코어는 감소하지만 정합 필드의 규 칙성이 향상된다. 이는 정합 손실로 인해 모델이 보다 정확한 영상 정합을 제공하도록 강제하지만 트레이드 오 프가 균형을 이루어야 함을 나타낸다. 표 4"}
{"patent_id": "10-2022-0171504", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 20, "content": "표 4에는 정합 손실의 영향에 대한 연구결과가 표시되며. 표준 편차는 괄호 안에 표시된다. 결론 본 발명은 변형 네트워크와 함께 훈련된 확산 확률 모델을 사용하여 비지도 영상 정합을 위한 새로운 DiffuseMorph 모델을 제시한다. 변형의 조건부 스코어 함수를 학습할 수 있는 기능 덕분에 제안하는 방법은 합 성 변형 영상을 생성할 뿐만 아니라 동영상이 고정영상을 향한 궤적을 따른 정합 필드를 추정하여 연속 변형으 로부터 고품질 영상 정합을 제공한다. 본 발명은 DiffuseMorph가 동영상과 고정영상을 사용하여 시간 데이터를 생성하는 유망한 알고리즘이 될 수 있을 것으로 기대한다. 전술한 바와 같은 본 발명에 따른 확산 모델을 이용한 비지도 학습 기반 변형 영상 정합 및 합성 영상 생성 시 스템 및 그 방법은 동영상과 고정영상 간의 변형에 대한 스코어 함수를 학습하는 확산 네트워크와 스코어 함수 의 잠재 기능(latent feature)을 이용하여 동영상에 대한 변형 필드를 추정하고 정합 영상을 제공하는 변형 네 트워크로 이루어지며, 엔드 투 엔드 학습(end-to-end learning)에 의하여 함께 학습됨으로써, 동영상이 고정영 상의 모양에 맞게 변형되는 방향으로의 마코브(Markov) 변환을 추정할 뿐 아니라 동영상에 대한 변형 필드를 제 공할 수 있으며, 확산 모델의 스코어 함수로부터의 잠재 기능은 동영상/고정영상의 공간적 정보를 가지고 있기 때문에, 잠재 기능을 스케일링하면, 동영상에서 고정영상으로의 연속적인 궤도에 대한 변형 필드를 생성할 수 있게 된다. 이상과 같이 본 발명은 양호한 실시 예에 근거하여 설명하였지만, 이러한 실시 예는 본 발명을 제한하려는 것이"}
{"patent_id": "10-2022-0171504", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 21, "content": "아니라 예시하려는 것이므로, 본 발명이 속하는 기술분야의 숙련자라면 본 발명의 기술사상을 벗어남이 없이 위실시 예에 대한 다양한 변화나 변경 또는 조절이 가능할 것이다. 그러므로, 본 발명의 보호 범위는 본 발명의 기술적 사상의 요지에 속하는 변화 예나 변경 예 또는 조절 예를 모두 포함하는 것으로 해석되어야 할 것이다."}
{"patent_id": "10-2022-0171504", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명에 따른 확산 모델을 이용한 비지도 학습 기반 변형 영상 정합 및 합성 영상 생성 시스템의 개략 적인 구성 블록도이다. 도 2는 본 발명에 따른 확산 모델을 이용한 비지도 학습 기반 변형 영상 정합 방법의 순서도이다. 도 3은 본 발명에 따른 확산 모델을 이용한 비지도 학습 기반 합성 영상 생성 방법의 순서도이다. 도 4는 본 발명에 따른 DiffuseMorph에 의한 영상 정합 및 합성 영상 생성의 예시도이다. 도 5는 본 발명에 따른 DiffuseMorph의 훈련 체제의 예시도이다. 도 6은 본 발명에 따른 DiffuseMorph의 추론 단계에서의 영상 정합 및 합성 영상 생성의 예시도이다. 도 7은 본 발명에 따른 고정 대상 데이터 분포를 향한 생성 프로세스의 예시도이다. 도 8은 추정 정합 필드를 이용하여 안면 영상에 영상 정합을 시각적으로 비교한 결과의 예시도이다. 도 9는 얼굴 랜드마크가 있는 얼굴 영상의 연속적인 영상 변형 결과의 예시도이다. 도 10은 생성 프로세스를 통한 합성 변형 영상 생성 결과의 예시도이다. 도 11은 심장 MR 영상의 영상 정합 및 연속 변형 결과의 예시도이다. 도 12는 뇌 MR 영상의 영상 정합 및 추정 정합 필드의 결과의 예시도이다. 도 13은 뇌 MR 영상 정합 실험에서 뇌 해부학적 구조에 대한 다이스 스코어의 정량적 평가 결과의 예시도이다."}
