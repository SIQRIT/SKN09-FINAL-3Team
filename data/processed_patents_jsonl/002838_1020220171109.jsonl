{"patent_id": "10-2022-0171109", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0086004", "출원번호": "10-2022-0171109", "발명의 명칭": "디지털 휴먼 실감 가시화를 위한 컴퓨팅 장치 및 방법", "출원인": "한국전자통신연구원", "발명자": "김태준"}}
{"patent_id": "10-2022-0171109", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "디지털 휴먼의 실감 가시화 방법에 있어서,상기 디지털 휴먼의 특정액션을 설정하는 단계;상기 디지털 휴먼의 특정액션을 포함하는 장면(scene)을 결정하고 결정된 장면을 렌더링하여 제1 렌더링 영상을생성하는 단계;상기 제1 렌더링 영상을 구성하는 이미지를 프레임마다 캡쳐함으로써 프레임 데이터를 획득하는 단계;상기 제1 렌더링 영상의 프레임 데이터 각각을 적어도 둘 이상의 실감 가시화 모듈에 입력하여 제2 렌더링 영상의 프레임 데이터를 획득하는 단계 및상기 제2 렌더링 영상의 프레임 데이터를 조합하여 실감 가시화된 장면을 생성하는 단계를 포함하는,디지털 휴먼의 실감 가시화 방법."}
{"patent_id": "10-2022-0171109", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1항에 있어서,상기 장면을 결정하는 단계는,상기 디지털 휴먼의 자세, 카메라, 조명, 배경, 시야각, 거리 및 좌표정보 중 적어도 하나를 포함하는 장면(scene)이 결정하는 단계를 포함하는,디지털 휴먼의 실감 가시화 방법."}
{"patent_id": "10-2022-0171109", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 1항에 있어서,상기 둘 이상의 실감 가시화 모듈은 적어도 한쌍의 병렬연결된 실감 가시화 모듈을 포함하는,디지털 휴먼의 실감 가시화 방법."}
{"patent_id": "10-2022-0171109", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 3항에 있어서,상기 한쌍의 병렬연결된 실감 가시화 모듈 각각은, 상기 한쌍의 병렬연결된 실감 가시화 모듈 각각과 직렬연결된 적어도 하나 이상의 실감 가시화 모듈을 포함하는,디지털 휴먼의 실감 가시화 방법."}
{"patent_id": "10-2022-0171109", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제 4항에 있어서,상기 한쌍의 병렬연결된 실감 가시화 모듈 각각과 직렬연결된 적어도 하나 이상의 실감 가시화 모듈의 종류는서로 상이한,디지털 휴먼의 실감 가시화 방법."}
{"patent_id": "10-2022-0171109", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제 1항에 있어서,상기 실감 가시화된 장면에 대한 식별정보를 생성하는 단계 및 상기 실감 가시화된 장면에 대한 식별정보와 새공개특허 10-2024-0086004-3-로 입력된 제3 렌더링 영상의 식별정보가 동일한 경우, 상기 제2 렌더링 영상을 캐시하여 실감 가시화된 영상을생성하는 단계를 더 포함하는,디지털 휴먼의 실감 가시화 방법."}
{"patent_id": "10-2022-0171109", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제 6항에 있어서,상기 식별정보는 장면식별정보(scene_ID), 액션식별정보(action_ID) 및 상기 장면식별정보와 상기액션식별정보를 포함하는 쿼리식별정보(query_id) 중 적어도 하나를 포함하는,디지털 휴먼의 실감 가시화 방법."}
{"patent_id": "10-2022-0171109", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "디지털 휴먼의 실감 가시화를 위한 컴퓨팅 장치에 있어서,상기 디지털 휴먼의 실감 가시화를 위한 동작을 수행하는 적어도 하나 이상의 프로세서를 포함하고,상기 프로세서는, 상기 디지털 휴먼의 특정액션을 설정하고, 상기 디지털 휴먼의 특정액션을 포함하는 장면(scene)을 결정하고 결정된 장면을 렌더링하여 제1 렌더링 영상을 생성하고, 상기 제1 렌더링 영상을 구성하는 이미지를 프레임마다캡쳐함으로써 프레임 데이터를 획득하고, 상기 제1 렌더링 영상의 프레임 데이터 각각을 적어도 둘 이상의 실감가시화 모듈에 입력하여 제2 렌더링 영상의 프레임 데이터를 획득하고, 상기 제2 렌더링 영상의 프레임 데이터를 조합하여 실감 가시화된 장면을 생성하는,컴퓨팅 장치."}
{"patent_id": "10-2022-0171109", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제 8항에 있어서, 상기 프로세서는, 상기 장면을 결정하는 경우, 상기 디지털 휴먼의 자세, 카메라, 조명, 배경, 시야각, 거리 및 좌표정보 중 적어도 하나를 포함하는 장면(scene)이 결정하는,컴퓨팅 장치."}
{"patent_id": "10-2022-0171109", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제 8항에 있어서, 상기 둘 이상의 실감 가시화 모듈은 적어도 한쌍의 병렬연결된 실감 가시화 모듈을 포함하는,컴퓨팅 장치."}
{"patent_id": "10-2022-0171109", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제 10항에 있어서,상기 한쌍의 병렬연결된 실감 가시화 모듈 각각은, 상기 한쌍의 병렬연결된 실감 가시화 모듈 각각과 직렬연결된 적어도 하나 이상의 실감 가시화 모듈을 포함하는,컴퓨팅 장치."}
{"patent_id": "10-2022-0171109", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제 11항에 있어서,상기 한쌍의 병렬연결된 실감 가시화 모듈 각각과 직렬연결된 적어도 하나 이상의 실감 가시화 모듈의 종류는서로 상이한,컴퓨팅 장치.공개특허 10-2024-0086004-4-청구항 13 제 8항에 있어서, 상기 프로세서는상기 실감 가시화된 장면에 대한 식별정보를 생성하고 상기 실감 가시화된 장면에 대한 식별정보와 새로 입력된제3 렌더링 영상의 식별정보가 동일한 경우, 상기 제2 렌더링 영상을 캐시하여 실감 가시화된 영상을 생성하는,컴퓨팅 장치."}
{"patent_id": "10-2022-0171109", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제 13항에 있어서,상기 식별정보는 장면식별정보(scene_ID), 액션식별정보(action_ID) 및 상기 장면식별정보와 상기액션식별정보를 포함하는 쿼리식별정보(query_id) 중 적어도 하나를 포함하는,컴퓨팅 장치."}
{"patent_id": "10-2022-0171109", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "디지털 휴먼 특정 영역에 대한 실감 가시화 방법에 있어서,상기 디지털 휴먼의 특정액션을 포함하는 장면(scene)을 결정하고 결정된 장면을 렌더링하여 제1 렌더링 영상을생성하는 단계;상기 디지털 휴먼의 얼굴영역을 추출하는 단계;병렬연결된 적어도 둘 이상의 실감 가시화 모듈을 이용해 상기 얼굴영역에 대하여 실감 가시화 동작을 수행하여실감 가시화된 얼굴영역 영상의 프레임 데이터를 생성하는 단계;상기 얼굴영역 영상의 각 프레임 데이터와 상기 제1 렌더링 영상의 각 프레임 데이터를 합성하는 단계를 포함하는,디지털 휴먼 특정 영역에 대한 실감 가시화 방법."}
{"patent_id": "10-2022-0171109", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명의 실시 예는 디지털 휴먼의 실감 가시화 방법에 있어서, 상기 디지털 휴먼의 특정액션을 설정하는 단계, 상기 디지털 휴먼의 특정액션을 포함하는 장면(scene)을 결정하고 결정된 장면을 렌더링하여 제1 렌더링 영상을 생성하는 단계, 상기 제1 렌더링 영상을 구성하는 이미지를 프레임마다 캡쳐함으로써 프레임 데이터를 획득하는 단계, 상기 제1 렌더링 영상의 프레임 데이터 각각을 적어도 둘 이상의 실감 가시화 모듈에 입력하여 제2 렌더링 영상의 프레임 데이터를 획득하는 단계 및 상기 제2 렌더링 영상의 프레임 데이터를 조합하여 실감 가시화된 장 면을 생성하는 단계를 포함하는, 디지털 휴먼의 실감 가시화 방법 및 컴퓨팅 장치를 개시한다."}
{"patent_id": "10-2022-0171109", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 디지털 휴먼 실감 가시화를 위한 컴퓨팅 장치에 관한 것이다."}
{"patent_id": "10-2022-0171109", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "최근 인공지능 기술의 발달로 디지털 휴먼이 주목을 받으면서, 디지털 휴먼을 실제 존재하는 사람과 같이 극사 실적으로 표현하는 기술 또한 개발되고 있다. 그런데 실감화의 품질이 높을수록 영상을 처리하는데 필요한 자원 과 시간이 늘어나 수많은 영상을 포함하는 장시간의 서비스에는 한계가 존재한다. 예를 들어, 실시간으로 디지털 휴먼이 사용자의 이름을 언급하거나 사용자의 동작에 따라 반응하는 등 미리 예 상할 수 없는 상황에 대응하기 위해서는 영상 처리를 위한 모든 과정이 평균 33 ms 이내에 이루어져야 한다. 그러나, 현재 실시간 서비스는 상기 한계점을 극복하지 못하고, 시간 제약을 만족하기 위해 영상 처리 결과의 기대 품질 수준을 많이 낮추는 실정이다. 또한 종래에 존재하는 얼굴 등과 같이, 다른 부분보다 특히 더 민감하게 받아들여진 데이터의 실감 가시화에 더 많은 자원을 할당하는 것이 정해진 자원으로 더 높은 품질을 얻기에 유리하나, 상기 방법 또한 특정 영역만 추 출한다거나 이를 반영해 영상을 개선하는 등의 추가적인 과정이 요구되므로, 실시간 서비스를 실현할 수 있고 이를 위해서는 또한 특별한 장치와 방법이 필요하였다."}
{"patent_id": "10-2022-0171109", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 2, "content": "발명의 내용"}
{"patent_id": "10-2022-0171109", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 디지털 휴먼의 실감 가시화를 수행할 시, 복수개의 가시화 모듈을 이용하여 실시간 실감 가시화를 수 행하기 위함이다. 또한 실감 가시화 시, 중복된 처리를 캐시(cache)하여 기술의 평균 처리속도를 높이기 위함이다. 또한 실감 가시화 시, 디지털 휴먼의 특정 영역만 추출하고 집중적으로 처리하기 위함이다."}
{"patent_id": "10-2022-0171109", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 실시예는 디지털 휴먼의 실감 가시화 방법에 있어서, 상기 디지털 휴먼의 특정액션을 설정하는 단계, 상기 디지털 휴먼의 특정액션을 포함하는 장면(scene)을 결정하고 결정된 장면을 렌더링하여 제1 렌더링 영상을 생성하는 단계, 상기 제1 렌더링 영상을 구성하는 이미지를 프레임마다 캡쳐함으로써 프레임 데이터를 획득하는 단계, 상기 제1 렌더링 영상의 프레임 데이터 각각을 적어도 둘 이상의 실감 가시화 모듈에 입력하여 제2 렌더 링 영상의 프레임 데이터를 획득하는 단계 및 상기 제2 렌더링 영상의 프레임 데이터를 조합하여 실감 가시화된 장면을 생성하는 단계를 포함하는, 디지털 휴먼의 실감 가시화 방법을 개시한다. 또한, 상기 장면을 결정하는 단계는, 상기 디지털 휴먼의 자세, 카메라, 조명, 배경, 시야각, 거리 및 좌표정보 중 적어도 하나를 포함하는 장면(scene)이 결정하는 단계를 포함할 수 있다. 또한, 상기 둘 이상의 실감 가시화 모듈은 적어도 한쌍의 병렬연결된 실감 가시화 모듈을 포함할 수 있다. 또한, 상기 한쌍의 병렬연결된 실감 가시화 모듈 각각은, 상기 한쌍의 병렬연결된 실감 가시화 모듈 각각과 직 렬연결된 적어도 하나 이상의 실감 가시화 모듈을 포함할 수 있다. 또한, 상기 한쌍의 병렬연결된 실감 가시화 모듈 각각과 직렬연결된 적어도 하나 이상의 실감 가시화 모듈의 종 류는 서로 상이할 수 있다. 또한, 상기 실감 가시화된 장면에 대한 식별정보를 생성하는 단계 및 상기 실감 가시화된 장면에 대한 식별정보 와 새로 입력된 제3 렌더링 영상의 식별정보가 동일한 경우, 상기 제2 렌더링 영상을 캐시하여 실감 가시화된 영상을 생성하는 단계를 더 포함할 수 있다. 또한, 상기 식별정보는 장면식별정보(scene_ID), 액션식별정보(action_ID) 및 상기 장면식별정보와 상기액션식 별정보를 포함하는 쿼리식별정보(query_id) 중 적어도 하나를 포함할 수 있다. 또한, 디지털 휴먼의 실감 가시화를 위한 컴퓨팅 장치에 있어서, 상기 디지털 휴먼의 실감 가시화를 위한 동작 을 수행하는 적어도 하나 이상의 프로세서를 포함하고, 상기 프로세서는, 상기 디지털 휴먼의 특정액션을 설정 하고, 상기 디지털 휴먼의 특정액션을 포함하는 장면(scene)을 결정하고 결정된 장면을 렌더링하여 제1 렌더링 영상을 생성하고, 상기 제1 렌더링 영상을 구성하는 이미지를 프레임마다 캡쳐함으로써 프레임 데이터를 획득하 고, 상기 제1 렌더링 영상의 프레임 데이터 각각을 적어도 둘 이상의 실감 가시화 모듈에 입력하여 제2 렌더링 영상의 프레임 데이터를 획득하고, 상기 제2 렌더링 영상의 프레임 데이터를 조합하여 실감 가시화된 장면을 생 성하는 컴퓨팅 장치를 포함할 수 있다. 상기 프로세서는, 상기 장면을 결정하는 경우, 상기 디지털 휴먼의 자세, 카메라, 조명, 배경, 시야각, 거리 및 좌표정보 중 적어도 하나를 포함하는 장면(scene)이 결정할 수 있다. 또한, 상기 프로세서는 상기 실감 가시화된 장면에 대한 식별정보를 생성하고 상기 실감 가시화된 장면에 대한 식별정보와 새로 입력된 제3 렌더링 영상의 식별정보가 동일한 경우, 상기 제2 렌더링 영상을 캐시하여 실감 가 시화된 영상을 생성할 수 있다. 또한, 디지털 휴먼 특정 영역에 대한 실감 가시화 방법에 있어서, 상기 디지털 휴먼의 특정액션을 포함하는 장 면(scene)을 결정하고 결정된 장면을 렌더링하여 제1 렌더링 영상을 생성하는 단계, 상기 디지털 휴먼의 얼굴영 역을 추출하는 단계, 병렬연결된 적어도 둘 이상의 실감 가시화 모듈을 이용해 상기 얼굴영역에 대하여 실감 가 시화 동작을 수행하여 실감 가시화된 얼굴영역 영상의 프레임 데이터를 생성하는 단계, 상기 얼굴영역 영상의 각 프레임 데이터와 상기 제1 렌더링 영상의 각 프레임 데이터를 합성하는 단계를 포함하는, 디지털 휴먼 특정 영역에 대한 실감 가시화 방법을 개시한다."}
{"patent_id": "10-2022-0171109", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명은 변화하는 장면(scene)에 실시간으로 대응하는 디지털 휴먼의 실감 가시화를 가능하도록 한다. 본 발명은 디지털 휴먼의 실감 가시화 동작을 수행할 시, 특정 영역만 추출하고 집중적으로 처리함으로써 처리 시간당 품질 효율을 극대화할 수 있다."}
{"patent_id": "10-2022-0171109", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하 설명하는 기술은 다양한 변경을 가할 수 있고 여러 가지 실시예를 가질 수 있는 바, 특정 실시예들을 도면 에 예시하고 상세하게 설명하고자 한다. 그러나, 이는 이하 설명하는 기술을 특정한 실시 형태에 대해 한정하려 는 것이 아니며, 이하 설명하는 기술의 사상 및 기술 범위에 포함되는 모든 변경, 균등물 내지 대체물을 포함하 는 것으로 이해되어야 한다. 명세서 전체에서, 어떤 부분이 다른 부분과 \"연결\"되어 있다고 할 때, 이는 \"직접적으로 연결\"되어 있는 경우뿐 아니라, 그 중간에 다른 소자를 사이에 두고 \"전기적으로 연결\"되어 있는 경우도 포함한다. 제1, 제2, A, B 등의 용어는 다양한 구성요소들을 설명하는데 사용될 수 있지만, 해당 구성요소들은 상기 용어 들에 의해 한정되지는 않으며, 단지 하나의 구성요소를 다른 구성요소로부터 구별하는 목적으로만 사용된다. 예 를 들어, 이하 설명하는 기술의 권리 범위를 벗어나지 않으면서 제1 구성요소는 제2 구성요소로 명명될 수 있고, 유사하게 제2 구성요소도 제1 구성요소로 명명될 수 있다. 및/또는 이라는 용어는 복수의 관련된 기재된 항목들의 조합 또는 복수의 관련된 기재된 항목들 중의 어느 항목을 포함한다. 본 명세서에서 사용되는 용어에서 단수의 표현은 문맥상 명백하게 다르게 해석되지 않는 한 복수의 표현을 포함 하는 것으로 이해되어야 하고, \"포함한다\" 등의 용어는 설명된 특징, 개수, 단계, 동작, 구성요소, 부분품 또는 이들을 조합한 것이 존재함을 의미하는 것이지, 하나 또는 그 이상의 다른 특징들이나 개수, 단계 동작 구성요 소, 부분품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 배제하지 않는 것으로 이해되어야 한다. 도면에 대한 상세한 설명을 하기에 앞서, 본 명세서에서의 구성부들에 대한 구분은 각 구성부가 담당하는 주기 능 별로 구분한 것에 불과함을 명확히 하고자 한다. 즉, 이하에서 설명할 2개 이상의 구성부가 하나의 구성부로 합쳐지거나 또는 하나의 구성부가 보다 세분화된 기능별로 2개 이상으로 분화되어 구비될 수도 있다. 그리고 이 하에서 설명할 구성부 각각은 자신이 담당하는 주기능 이외에도 다른 구성부가 담당하는 기능 중 일부 또는 전 부의 기능을 추가적으로 수행할 수도 있으며, 구성부 각각이 담당하는 주기능 중 일부 기능이 다른 구성부에 의 해 전담되어 수행될 수도 있음은 물론이다. 또, 방법 또는 동작 방법을 수행함에 있어서, 상기 방법을 이루는 각 과정들은 문맥상 명백하게 특정 순서를 기 재하지 않은 이상 명기된 순서와 다르게 일어날 수 있다. 즉, 각 과정들은 명기된 순서와 동일하게 일어날 수도 있고 실질적으로 동시에 수행될 수도 있으며 반대의 순서대로 수행될 수도 있다. 이하 실감 가시화를 위한 컴퓨팅 장치가 실감 가시화를 수행한다고 설명한다. 컴퓨팅 장치는 입력된 데이터를 일정하게 처리하고 특정 모델이나 알고리즘에 따라 실감 가시화에 필요한 연산을 수행하는 장치이다. 예컨대, 컴퓨팅 장치는 PC, 네트워크상의 서버, 스마트기기, 설계 프로그램이 임베딩된 칩셋 등과 같은 형태로 구현될 수 있다. 도 1은 본 발명의 일 실시 예에 따른 컴퓨팅 장치를 나타낸다. 도 1은 본 개시의 일 실시예와 관련된 디지털 휴먼의 실감 가시화를 제공하는 컴퓨팅 장치의 블록 구성도를 도 시한다. 도 1에 도시된 실감 가시화를 제공하는 컴퓨팅 장치의 컴포넌트들은 예시적인 것이다. 도 1에 도 시된 컴포넌트 중 일부만이 실감 가시화를 제공하는 컴퓨팅 장치를 구성할 수도 있으며, 도 1에 도시된 컴 포넌트 이외에 추가적인 컴포넌트(들)가 상기 실감 가시화를 제공하는 컴퓨팅 장치에 포함될 수도 있다. 도 1에 도시된 바와 같이, 실감 가시화를 제공하는 컴퓨팅 장치는 프로세서, 메모리 및 통신부 를 포함할 수 있다. 통신부는 유무선 통신 기술을 이용하여 다른 전자장치나 서버 등의 외부 장치들과 데이터를 송수신할 수 있다. 예컨대, 통신부는 외부 장치들과 센서 정보, 사용자 입력, 학습 모델, 제어 신호 등을 송수신할 수 있다. 메모리는 컴퓨팅 장치의 다양한 기능을 지원하는 데이터를 저장할 수 있다. 프로세서는 컴퓨팅 장치의 적어도 하나의 실행 가능한 동작을 결정할 수 있다. 그리고, 프로세서 는 컴퓨팅 장치의 구성 요소들을 제어하여 결정된 동작을 수행할 수 있다. 이를 위해, 프로세서는 메모리의 데이터를 요청, 검색, 수신 또는 활용할 수 있고, 상기 적어도 하나 의 실행 가능한 동작 중 예측되는 동작이나, 바람직한 것으로 판단되는 동작을 실행하도록 컴퓨팅 장치의 구성 요소들을 제어할 수 있다. 이때, 프로세서는 결정된 동작을 수행하기 위하여 외부 장치의 연계가 필요한 경우, 해당 외부 장치를 제 어하기 위한 제어 신호를 생성하고, 생성한 제어 신호를 해당 외부 장치에 전송할 수 있다. 프로세서는 메모리에 저장된 응용 프로그램을 구동하기 위하여, 컴퓨팅 장치의 구성 요소들 중 적어도 일부 또는 구성요소들의 조합을 제어할 수 있다. 본 발명의 일 실시예에 따른 컴퓨팅 장치는 무선 및/또는 유선을 통한 상호 연결을 통해 데이터를 전송할 수 있고, 그리고 수신할 수 있다. 본 개시의 컴퓨팅 장치는 전자 형태의 데이터를 연산할 수 있는 모든 종류의 컴퓨팅 장치를 포함할 수 있다. 예를 들어, TV, 프로젝터, 휴대폰, 스마트폰, 데스크탑 컴퓨터, 노트북, 디지털방송용 단말기, PDA(personal digital assistants), PMP(portable multimedia player), 네비게이션, 태블릿 PC, 웨어러블 장치, 셋톱박스 (STB), DMB 수신기, 라디오, 세탁기, 냉장고, 데스크탑 컴퓨터, 디지털 사이니지, 로봇, 차량 등과 같은, 고정 형 기기 또는 이동 가능한 기기 등으로 구현될 수 있다. 이하 도 2 및 도 3을 참조하여 본 발명의 실시 예에 따른 디지털 휴먼 가시화를 위한 컴퓨팅 장치의 동작 을 설명한다. 도 2는 본 발명의 일 실시 예에 따른 흐름도를 나타낸 것이고, 도 3은 본 발명의 일 실시 예에 따른 컴퓨팅 장 치의 동작 및 구성을 나타낸 것이다. 먼저 도 3을 참조하면, 컴퓨팅 장치의 프로세서는 디지털 휴먼을 포함하는 장면(scene)으로부터 프레 임을 추출하기 위한 응용프로그램, 실감 가시화를 수행하는 적어도 하나 이상의 실감 가시화 모듈 및 실감 가시화를 작업큐 및 결과큐를 이용하여 제어하는 실감 가시화 제어기의 동작 전반을 제어 할 수 있다. 이하 세부 구성에 대하여 설명토록 한다. 본 발명의 실시 예에 따른 실감 가시화 서비스를 위한 응용프로그램은 액션 제어기, 렌더 카메라 및 프레임 추출기를 포함할 수 있다. 먼저, 액션 제어기는 상황에 따라 디지털 휴먼의 특정 액션(예를 들어 인사하기, 손을 내밀기, 사용자 이 름을 부르기 등)을 결정할 수 있다(S201). 상기 디지털 휴먼은 액션 제어기로부터 설정된 특정 액션을 수행할 수 있다. 렌더 카메라는 상기 특정 액션이 반영된 상기 디지털 휴먼의 자세, 카메라, 조명, 배경 등을 포함하는 장 면(scene)이 결정되면 이를 렌더링할 수 있다(S203). 이때, 렌더링이라 함은 3D 장면을 이용해 특정 카메라에서 바라보는 시점에서 2D 영상을 생성하는 과정을 의미 할 수 있다. 그리고, 렌더 카메라는 상기 디지털 휴먼을 포함하는 장면(scene)을 결정하기 위하여 시야각(Fov), 거리 및 좌표값을 설정하고 설정된 정보에 기초하여 장면(scene)을 생성할 수 있을 것이다. 기존의 응용 프로그램은 상기 렌더 카메라를 통하여 생성된 렌더링 장면(scene)을 출력하게된다. 이하, 응용 프 로그램으로부터 출력되는 종래의 렌더링 장면을 '제1 렌더링 영상'으로 명명한다. 본 발명의 실시 예에 따른 프레임 추출기는 상기 제1 렌더링 영상이 결정되면, 상기 렌더 카메라에서 생성 된 제1 렌더링 영상을 실시간으로 캡쳐함으로써 프레임 영상을 추출할 수 있다(S205). 이때, 상기 캡쳐는 상기 제1 렌더링 영상의 각 프레임마다 수행될 수 있다. 본 발명의 실시 예에 따르면 프로세서는 추출된 프레임을 실감 가시화 제어기에 전달할 수 있다. 실감 가시화 제어기는 응용 프레임 추출기로부터 수신한 제1 렌더링 영상의 각 프레임을 작업큐에 입 력할수 있다. 구체적으로 작업큐는 제1 렌더링 영상의 각 프레임에 대하여 실감 가시화를 수행하기 위한 순서를 저장하는 자료구조를 의미할 수 있다. 적어도 하나 이상의 실감 가시화부는 상기 작업큐에 저장된 제1 렌더링 영상의 프레임 데이터 각각에 대한 실감 가시화를 수행할 수 있다(S207). 이때, 실감 가시화부이 적어도 하나 이상의 실감 가시화 모듈을 포함할 수 있다. 상기 복수개의 실감 가시 화 모듈은 서로 병렬 또는 직렬 연결될 수 있다. 구체적으로 상기 제1 렌더링 영상의 프레임 영상 각각을 적어 도 둘 이상의 실감 가시화 모듈에 입력하여 실감 가시화를 수행할 수 있으며, 상기 둘 이상의 실감 가시화 모듈 에는, 적어도 한쌍의 병렬연결된 실감 가시화 모듈이 존재할 수 있다. 예를 들어, 도 3을 참조하면, 상기 제1 렌더링 영상에 기초하여 작업큐 '0'에 저장된 프레임 데이터는 실감 가 시화 모듈 1, 실감 가시화 모듈2 및 실감 가시화 3 등 m 개의 실감 가시화 모듈(3311,3312,3313 등)이 직렬 연 결된 제1 직렬 실감 가시화 모듈에 입력되어 실감 가시화가 수행될 수 있다. 또한 작업큐 '1'에 저장된 프레임 데이터는 상기 직렬 연결된 실감 가시화 모듈과 병렬적으로 구성된 제2 직렬 실감 가시화 모듈에 입력되어 실감 가시화가 수행될 수 있다. 또한 제1 직렬 실감 가시화 모듈 및 제2 직렬 실감 가시화 모듈는 서로 병렬구조를 이룰수 있다. 그리고, 제1 직렬 실감 가시화 모듈 및 제2 직렬 실감 가시화 모듈을 이루는 실감 가시화 모듈(3311, 3312, 3313 등)의 순서 및 종류는 서로 동일하거나 상이할 수 있다. 한편, 복수개의 병렬 구조를 이루는 실감 가시화 모듈이 존재하며, 상기 병렬 구조를 이루는 실감 가시화 모듈 각각에 직렬 연결된 실감 가시화모듈 또한 존재할 수 있을 것이다. 상기 동작은 작업큐에 저장된 프레임 데이터 각각에 대하여 반복적으로 수행될 수 있다. 즉, 병렬 실감 가 시화 모듈이 n개 존재하는 경우, 작업큐의 '0'부터 'n-1'에 할당된 프레임 데이터는 n 개의 병렬 실감 가시화 모듈에 각각 입력되며, 'n'에 할당된 프레임 데이터는 다시 제1 실감 가시화 모듈에 입력될 수 있다. 상기와 예시와 같이, 실감 가시화부는 작업큐에 순서대로 저장된 제1 렌더링 영상의 프레임 데이터 각각에 대하여 실감 가시화를 수행할 수 있으며, 실감 가시화 수행 결과를 결과큐에 순서대로 저장할 수 있다. 이하 제1 렌더링 영상의 프레임 마다 실감 가시화가 수행된 렌더링 영상을 '제2 렌더링 영상'으로 명명한다. 한편, 본 발명의 실시예는 실감 가시화 모듈의 구조적인 배치에 특징이 있으며 실감 가시화 방법에 대해서는 공 개된 알고리즘 또는 종래의 기술을 사용할 수 있을 것이다. 실감 가시화 제어기는 결과큐에 할당된 제2 렌더링 영상의 프레임을 렌더 카메라에 전송할 수 있다. 렌더 카메라는 상기 제2 렌더링 영상의 프레임 각각을 조합하여 제2 렌더링 영상을 출력함으로써 실감 가시화된 장면(scene)을 제공할 수 있다(S209). 이를 통해 사용자는 실감 나는 디지털 휴먼을 경험할 수 있게 된다. 한편, 상기 실감 가시화부를 통해 제1 렌더링 영상의 실감 가시화가 수행됨에 따라 일련의 과정으로 걸리 는 시간은 지연시간이 되며 이는 실감 가시화 모듈의 처리 시간에 기초하게 된다. 구체적으로 상기 지연시간은 특정 액션이 필요한 시점부터 실제로 제공되기 시작하는 시점 사이의 시간을 의미 할 수 있다. 예를 들어 사용자가 서비스 기기에 등장하는 경우, 디지털 휴먼이 인사를 시작하기까지의 시간차도 지연시간으 로 볼 수 있다. 실감 가시화부에 포함된 실감 가시화 모듈의 처리 프로세스가 하나만 존재한다면 지연시간과 프레임 처리 시간 이 같아지며, 상기 시간이 33 ms를 넘는다면 실시간성을 보장할 수 없을 것이다. 그러나 본원발명과 같이 실감 가시화 모듈을 병렬로 구성(331,332 등)하여 동시에 처리된다면 매 프레임 생성 시간을 병렬 모듈들의 개수 비례해서 줄일 수 있으므로, 실시간성을 보장할 수 있을 것이다. 이하 본 발명의 실감 가시화 캐시에 대하여 설명한다. 본 발명의 렌더 카메라의 렌더링 수행 중, 장면(scene)을 구성하는 디지털 휴먼, 디지털 휴먼이 착용하고 있는 의상, 조명, 배경, 카메라 등이 모두 같으면 동일한 액션에 대해서 렌더링 되는 매 프레임 영상이 같음을 기대 할 수 있게 된다. 다시말해, 실감 가시화 모듈이 결정론적(deterministic)이라면, 즉, 항상 같은 입력에 대해 같은 출력을 낸다면 실감 가시화 결과 또한 동일한 장면과 액션에 대해서 결과가 같음을 기대할 수 있다. 따라서 매번 실감 가시화를 수행하는 대신 한 번 수행한 결과는 캐시(cache)해 두면 캐시한 결과와 같은 장면 및 액션에 대한 요청이 있을시 캐시한 결과를 바로 렌더 카메라에 제공하여 평균 처리속도를 높일 수 있다. 구체적으로 이전에 생성된 제2 렌더링 영상을 상기 실감 가시화 캐시는 네트워크 또는 메모리에 저장할 수 있다. 예를 들어, 서로 다른 장면에 ID(scene_id)를 부여하고 액션 또한 액션마다 ID(action_id)를 부여해서 두 ID를 합한 ID를 새로 query_id라 정의하고 query_id로 캐시 사용 여부를 결정할 수 있다. 이후, 장면(scene)을 구성하는 디지털 휴먼, 디지털 휴먼이 착용하고 있는 의상, 조명, 배경, 카메라 등에 부여 된 장면식별정보(scene_id) 및 디지털 휴먼의 동작 및 자세 정보가 포함된 액션 정보(action_id)가 모두 제2 렌 더링 영상과 동일한 경우, 이전에 저장된 제2 렌더링 영상을 캐시하여 렌더 카메라에 전달함으로써 곧바로 실감 가시화된 영상을 생성할 수 있다. 실감 가시화 캐시는 응용프로그램이 구동되는 장치와 같은 장치에 존재할 수도 있고 서버에 존재하여 네트워크 를 통해 제공될 수도 있다. 다수의 서비스 장치가 캐시 서버를 공유하면 캐시 효율을 보다 더 높일 수 있다. 한편, 본 발명의 실시예에 따라, 전체 영상을 모두 같은 품질로 실감 가시화하는 것보다 특정 부분의 실감 가시 화 정도를 더 높인다면 정해진 자원으로 같은 시간에 더 높은 사용자 만족도를 얻을 수 있다. 이하 도 4를 참조하여, 디지털 휴먼의 특정 부분에 대한 가시화를 수행함으로써 보다 향상된 속도를 제공하는 디지털 휴먼 렌더링을 위한 컴퓨팅 장치를 설명한다. 도 4는 본 발명의 일 실시 예에 따른 컴퓨팅 장치의 동작 및 구성을 나타낸 것이다. 본 발명의 실시 예에 따르면, 실감 가시화부는 디지털 휴먼 렌더링 시, 디지털 휴먼의 특정 영역만을 실감 가시 화하는 적어도 하나 이상의 모듈을 포함할 수 있다. 이때, 상기 특정 영역은 디지털 휴먼의 얼굴 영역에 해당할 수 있다. 한편, 다양한 실시예를 제공함에 따라 얼 굴이 아닌 다른 부분을 특정 영역으로 설정하는 것 또한 가능하다. 본 발명에서는 설명의 편의를 위하여 특정 영역을 얼굴영역으로 예를 들어 설명한다. 먼저, 본 발명은 먼저 얼굴 영역을 탐지하고 추출하는 얼굴 특징점 추출기를 더 포함할 수 있다. 얼굴 특징점 추출기는 제1 렌더링 영상의 프레임 데이터 또는 장면(scene)의 3D 데이터를 이용하여 얼굴 특징점을 도출할 수 있다. 구체적으로 상기 얼굴 특징점 추출기는 얼굴 영역을 탐지하기 위하여 얼굴을 대상으로 하는 실감 가시화 모듈이 요구하는 형태에 기초하여 얼굴의 특징이 되는 점들(양쪽 눈, 코끝, 입술 양쪽 끝 등)을 얼굴 특징점으 로 검출할 수 있다. 얼굴 특징점 추출기가 얼굴 특징점들을 찾으면 얼굴 영역 변환 계산기는 이를 기초로 얼굴에 해당하 는 얼굴영역을 프레임에서 추출하기 위한 변환(transform) 정보를 계산할 수 있다. 상기 변환 정보는 얼굴 특징점에 대한 이동, 확대/축소, 회전 정보 등을 의미할 수 있다. 얼굴 영역 변환 계산기는 상기 얼굴 특징점에 대한 변환 정보를 이용하여 프레임 내에서의 얼굴영역의 위 치를 특정 좌표로 변환할 수 있다. 얼굴 영역 프레임 추출기는 상기 변환 정보를 이용해 얼굴 특징영역에 포함된 점뿐만 아니라 얼굴영역 내 모든 점들을 변환함으로써 얼굴영역을 검출할 수 있다. 실감 가시화 제어기는 프레임 추출기에서 추출된 제1 렌더링 영상 및 얼굴 영역 프레임 추출기 에서 획득한 얼굴영역 정보를 획득할 수 있다. 이후, 실감 가시화 제어기는 앞서 설명한 바와 같이, 실감 가시화부에 포함된 적어도 하나 이상의 실감 가시화 모듈을 이용해 상기 얼굴영역 정보에 대하여 실감 가시화를 병렬로 수행할 수 있다. 영상 합성기는 상기 얼굴영역 정보의 실감 가시화에 따라 생성된 실감 가시화된 얼굴영역 영상의 각 프레 임 데이터와 상기 프레임 추출기를 통해 렌더링된 제1 렌더링 영상의 각 프레임 데이터를 합성함으로써 얼 굴영역 실감 가시화를 수행할 수 있다. 이때, 생성된 최종 실감 가시화 영상은 제2 렌더링 영상일 수 있다. 이때, 정확한 영상 합성을 위하여 상기 얼굴영역 변환 계산기를 통해 도출한 변환정보 역(inverse)변환을 수행하여 상기 얼굴영역을 제1 렌더링 영상에 정확히 매칭시킬 수 있을 것이다. 한편, 설명의 편의상 생략하였으나, 얼굴영역에 대한 실감 가시화 과정은 도 2 및 도 3의 동작을 그대로 포함하 는 것으로 해석되어야 할 것이다. 본 발명은 이를 통해 특정 영역에 국한된 실감 가시화를 수행함으로써 실시간성을 가질 수 없었던 기존의 실감 가시화 기술을 적용할 수 있게 하여 기존에는 볼 수 없었던 실감나는 품질로 서비스를 제공하는데 사용할 수 있 다. 본 개시의 기술 분야에서 통상의 지식을 가진 자는 여기에 개시된 실시예들과 관련하여 설명된 다양한 예시적인 논리 블록들, 모듈들, 프로세서들, 수단들, 회로들 및 알고리즘 단계들이 전자 하드웨어, (편의를 위해, 여기에 서 소프트웨어로 지칭되는) 다양한 형태들의 프로그램 또는 설계 코드 또는 이들 모두의 결합에 의해 구현될 수 있다는 것을 이해할 것이다. 전술한 본 발명은, 프로그램이 기록된 매체에 컴퓨터가 읽을 수 있는 코드로서 구현하는 것이 가능하다. 컴퓨터 가 읽을 수 있는 매체는, 컴퓨터 시스템에 의하여 읽혀질 수 있는 데이터가 저장되는 모든 종류의 기록장치를 포함한다. 컴퓨터가 읽을 수 있는 매체의 예로는, HDD(Hard Disk Drive), SSD(Solid State Disk), SDD(Silicon Disk Drive), ROM, RAM, CD-ROM, 자기 테이프, 플로피 디스크, 광 데이터 저장 장치 등이 있다."}
{"patent_id": "10-2022-0171109", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일 실시 예에 따른 컴퓨팅 장치의 구성도를 나타낸 것이다. 도 2는 본 발명의 일 실시 예에 따른 흐름도를 나타낸 것이다. 도 3은 본 발명의 일 실시 예에 따른 컴퓨팅 장치의 동작 및 구성을 나타낸 것이다. 도 4는 본 발명의 일 실시 예에 따른 컴퓨팅 장치의 동작 및 구성을 나타낸 것이다."}
