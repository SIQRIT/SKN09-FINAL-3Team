{"patent_id": "10-2019-0083131", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2020-0018237", "출원번호": "10-2019-0083131", "발명의 명칭": "신경망을 위한 데이터 처리 방법 및 장치", "출원인": "베이징 바이두 넷컴 사이언스 앤 테크놀로지 코.,", "발명자": "시, 지아씬"}}
{"patent_id": "10-2019-0083131", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "적어도 하나의 활성화 함수가 구비된 신경망을 위한 데이터 처리 방법에 있어서, 현재 데이터를 획득하는 활성화 함수가 타깃 함수인 것에 대응하여, 상기 타깃 함수와 기설정 함수 사이의 환산관계에 따라 현재 데이터를 상기 기설정 함수의 입력 데이터로 전환하는 단계와,상기 기설정 함수에 대응되는 룩업 테이블에서, 상기 입력 데이터를 입력으로 하는 상기 기설정 함수의 제1 출력 데이터를 조회하는 단계와,상기 환산 관계 및 상기 제1 출력 데이터에 따라 현재 데이터를 입력으로 하는 상기 타깃 함수의 제2 출력 데이터를 전환하여 획득하는 단계와,상기 제2 출력 데이터를 출력하는 단계를 포함하는 신경망을 위한 데이터 처리 방법."}
{"patent_id": "10-2019-0083131", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 타깃 함수는 sigmoid 비선형 함수를 포함하고,상기 기설정 함수는 tanh 쌍곡선 탄젠트 함수를 포함하며, 상기 타깃 함수와 기설정 함수 사이의 환산 관계에 따라 현재 데이터를 상기 기설정 함수의 입력 데이터로 전환하는 단계는, 상기 기설정 함수의 입력 데이터로서, 현재 데이터를 2로 나눈 몫을 확정하는 단계를 포함하는 것을 특징으로 하는 신경망을 위한 데이터 처리 방법."}
{"patent_id": "10-2019-0083131", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서, 현재 데이터가 부동 소수점 수이고, 부동 소수점 수가 2를 기수로 하고 가수 및 지수를 포함하는 표현 방식을이용할 경우, 상기 현재 데이터를 2로 나눈 몫을 확정하는 단계는, 현재 데이터의 지수에서 1을 감하여 현재 데이터를 2로 나눈 몫을 획득하는 단계를 포함하는 것을 특징으로 하는 신경망을 위한 데이터 처리 방법."}
{"patent_id": "10-2019-0083131", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제2항에 있어서, 상기 환산 관계 및 상기 제1 출력 데이터에 따라 현재 데이터를 입력으로 하는 상기 타깃 함수의 제2 출력 데이터를 전환하여 획득하는 단계는, 현재 데이터를 입력으로 하는 상기 타깃 함수의 제2 출력 데이터로서, 상기 제1 출력 데이터에 1을 합산하고,합산한 값을 2로 나눈 몫을 확정하는 단계공개특허 10-2020-0018237-3-를 포함하는 것을 특징으로 하는 신경망을 위한 데이터 처리 방법."}
{"patent_id": "10-2019-0083131", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서, 합산한 값이 부동 소수점 수이고, 부동 소수점 수가 2를 기수로 하고 가수 및 지수를 포함하는 표현 방식을 이용할 경우, 상기 합산한 값을 2로 나눈 몫을 확정하는 단계는, 합산한 값의 지수에서 1을 감하여 합산한 값을 2로 나눈 몫을 획득하는 단계를 포함하는 것을 특징으로 하는 신경망을 위한 데이터 처리 방법."}
{"patent_id": "10-2019-0083131", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제2항 내지 제5항 중 어느 한 항에 있어서, 상기 기설정 함수에 대응되는 룩업 테이블에는 양수 입력 구간 및 음수 입력 구간 중 적어도 하나가 포함되는것을 특징으로 하는 신경망을 위한 데이터 처리 방법."}
{"patent_id": "10-2019-0083131", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에 있어서, 상기 타깃 함수는 tanh 쌍곡선 탄젠트 함수를 포함하고,상기 기설정 함수는 sigmoid 비선형 함수를 포함하며, 상기 타깃 함수와 기설정 함수 사이의 환산 관계에 따라 현재 데이터를 상기 기설정 함수의 입력 데이터로 전환하는 단계는, 상기 기설정 함수의 입력 데이터로서, 현재 데이터와 2의 곱을 확정하는 단계를 포함하는 것을 특징으로 하는 신경망을 위한 데이터 처리 방법."}
{"patent_id": "10-2019-0083131", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서, 현재 데이터가 부동 소수점 수이고, 부동 소수점 수가 2를 기수로 하고 가수 및 지수를 포함하는 표현 방식을이용할 경우, 상기 현재 데이터와 2의 곱을 확정하는 단계는, 현재 데이터의 지수에 1을 더하여 현재 데이터와 2의 곱을 획득하는 단계를 포함하는 것을 특징으로 하는 신경망을 위한 데이터 처리 방법."}
{"patent_id": "10-2019-0083131", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제7항에 있어서, 상기 환산 관계 및 상기 제1 출력 데이터에 따라 현재 데이터를 입력으로 하는 상기 타깃 함수의 제2 출력 데이터를 전환하여 획득하는 단계는, 현재 데이터를 입력으로 하는 상기 타깃 함수의 제2 출력 데이터로서, 상기 제1 출력 데이터와 2의 곱을 확정하고, 곱에서 1을 감한 차이값을 확정하는 단계공개특허 10-2020-0018237-4-를 포함하는 것을 특징으로 하는 신경망을 위한 데이터 처리 방법."}
{"patent_id": "10-2019-0083131", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9항에 있어서, 상기 제1 출력 데이터는 부동 소수점 수이고, 부동 소수점 수가 2를 기수로 하고 가수 및 지수를 포함하는 표현방식을 이용할 경우, 상기 제1 출력 데이터와 2의 곱을 확정하는 단계는, 상기 제1 출력 데이터의 지수에 1을 더하여 상기 제1 출력 데이터와 2의 곱을 획득하는 단계를 포함하는 것을 특징으로 하는 신경망을 위한 데이터 처리 방법."}
{"patent_id": "10-2019-0083131", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "적어도 하나의 활성화 함수가 구비된 신경망을 위한 데이터 처리 장치에 있어서,현재 데이터를 획득하는 활성화 함수가 타깃 함수인 것에 대응하여, 상기 타깃 함수와 기설정 함수 사이의 환산관계에 따라 현재 데이터를 상기 기설정 함수의 입력 데이터로 전환하도록 구성된 제1 전환 유닛;상기 기설정 함수에 대응되는 룩업 테이블에서, 상기 입력 데이터를 입력으로 하는 상기 기설정 함수의 제1 출력 데이터를 조회하도록 구성된 조회 유닛;상기 환산 관계 및 상기 제1 출력 데이터에 따라 현재 데이터를 입력으로 하는 상기 타깃 함수의 제2 출력 데이터를 전환하여 획득하도록 구성된 제2 전환 유닛; 및상기 제2 출력 데이터를 출력하도록 구성된 출력 유닛을 포함하는 신경망을 위한 데이터 처리 장치."}
{"patent_id": "10-2019-0083131", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항에 있어서, 상기 타깃 함수는 sigmoid 비선형 함수를 포함하고,상기 기설정 함수는 tanh 쌍곡선 탄젠트 함수를 포함하며, 상기 제1 전환 유닛은, 상기 기설정 함수의 입력 데이터로서, 현재 데이터를 2로 나눈 몫을 확정하도록 구성되는 것을 특징으로 하는신경망을 위한 데이터 처리 장치."}
{"patent_id": "10-2019-0083131", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제12항에 있어서, 현재 데이터가 부동 소수점 수이고, 부동 소수점 수가 2를 기수로 하고 가수 및 지수를 포함하는 표현 방식을이용할 경우, 상기 제1 전환 유닛은, 현재 데이터의 지수에서 1을 감하여 현재 데이터를 2로 나눈 몫을 획득하도록 구성되는 것을 특징으로 하는 신경망을 위한 데이터 처리 장치."}
{"patent_id": "10-2019-0083131", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제12항에 있어서, 공개특허 10-2020-0018237-5-상기 제2 전환 유닛은, 현재 데이터를 입력으로 하는 상기 타깃 함수의 제2 출력 데이터로서, 상기 제1 출력 데이터에 1을 합산하고,합산한 값을 2로 나눈 몫을 확정하도록 구성되는 것을 특징으로 하는 신경망을 위한 데이터 처리 장치."}
{"patent_id": "10-2019-0083131", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제14항에 있어서, 합산한 값이 부동 소수점 수이고, 부동 소수점 수가 2를 기수로 하고 가수 및 지수를 포함하는 표현 방식을 이용할 경우, 상기 제2 전환 유닛은, 합산한 값의 지수에서 1을 감하여 합산한 값을 2로 나눈 몫을 획득하도록 더 구성되는 것을 특징으로 하는 신경망을 위한 데이터 처리 장치."}
{"patent_id": "10-2019-0083131", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제12항 내지 제15항 중 어느 한 항에 있어서, 상기 기설정 함수에 대응되는 룩업 테이블에는 양수 입력 구간 및 음수 입력 구간 중 적어도 하나 포함되는 것을 특징으로 하는 신경망을 위한 데이터 처리 장치."}
{"patent_id": "10-2019-0083131", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "하나 또는 다수의 프로그램이 저장된 저장 부재;실행하고자 하는 명령어에 따라 명령어 스케줄링를 진행하도록 구성된 스케줄링 부재;상기 스케줄링 부재에서 발송된 명령어를 수신하여 대응되는 프로그램을 실행하거나, 및/또는 상기 스케줄링 부재에서 발송된 명령어에 따라 서브 명령어를 생성하고, 생성된 서브 명령어를 대응되는 전용 실행 부재에 발송하도록 구성된 적어도 하나의 범용 실행 부재; 및상기 적어도 하나의 범용 실행 부재에서 발송된 서브 명령어를 수신하여 대응되는 프로그램을 실행하도록 구성된 적어도 하나의 전용 실행 부재를 포함하되, 하나 또는 다수의 전용 실행 부재가 대응되는 프로그램을 실행할 경우, 제1항 내지 제5항 및 제7항 내지 제10항중 어느 한 항에 따른 방법이 구현되는 것을 특징으로 하는 인공 지능 칩."}
{"patent_id": "10-2019-0083131", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "컴퓨터 프로그램이 저장된 컴퓨터 판독 가능한 매체에 있어서,상기 컴퓨터 프로그램이 실행 부재에 의해 실행될 경우, 제1항 내지 제5항 및 제7항 내지 제10항 중 어느 한 항에 따른 방법이 구현되는 것을 특징으로 하는 컴퓨터 판독 가능한 매체."}
{"patent_id": "10-2019-0083131", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "프로세서;저장 장치; 및 공개특허 10-2020-0018237-6-적어도 하나의 제17항에 따른 인공 지능 칩을 포함하는 전자 장치."}
{"patent_id": "10-2019-0083131", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 출원의 실시예는 신경망을 위한 데이터 처리 방법 및 장치를 개시한다. 신경망에는 적어도 하나의 활성화 함 수가 구비된다. 해당 방법의 일 구체적인 실시예는, 현재 데이터를 획득하는 활성화 함수가 타깃 함수인 것에 대 응하여, 타깃 함수와 기설정 함수 사이의 환산 관계에 따라 현재 데이터를 기설정 함수의 입력 데이터로 전환하 (뒷면에 계속)"}
{"patent_id": "10-2019-0083131", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 출원의 실시예는 인공 지능 기술 분야에 관한 것으로, 특히는 신경망을 위한 데이터 처리 방법 및 장치에 관 한 것이다."}
{"patent_id": "10-2019-0083131", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "인공 신경망(Artificial Neural Networks, ANNs)은 동물 신경망 행동 특성을 모방하여 분산형 병행 정보 처리를 진행하는 알고리즘 수학 모델이며, 일반적으로 신경망 또는 유사 신경망으로 약칭된다. 신경망은 일종의 연산 모델로서, 대량의 노드(또는 뉴런으로 지칭됨) 사이의 상호 결합으로 구성된다. 각 노드 는 하나의 특정된 출력 함수를 대표하며, 활성화 함수(activation function)로 지칭된다. 각 2개의 노드 사이의 연결은 모두 해당 연결을 통과하는 신호에 대한 하나의 가중값(가중이라 지칭됨)을 대표하고, 이는 인공 신경망 의 기억에 해당한다. 네트워크의 출력은 네트워크의 연결 방식, 가중치 및 활성화 함수가 상이함에 따라 상이하 게 된다."}
{"patent_id": "10-2019-0083131", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 출원의 실시예는 신경망을 위한 데이터 처리 방법 및 장치를 제공한다."}
{"patent_id": "10-2019-0083131", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "제1 양태에 있어서, 본 출원의 실시예는 적어도 하나의 활성화 함수가 구비된 신경망을 위한 데이터 처리 방법 을 제공하며, 해당 방법은, 현재 데이터를 획득하는 활성화 함수가 타깃 함수인 것에 대응하여, 타깃 함수와 기 설정 함수 사이의 환산 관계에 따라 현재 데이터를 기설정 함수의 입력 데이터로 전환하는 단계와, 기설정 함수 에 대응되는 룩업 테이블에서, 입력 데이터를 입력으로 하는 기설정 함수의 제1 출력 데이터를 조회하는 단계와, 환산 관계 및 제1 출력 데이터에 따라 현재 데이터를 입력으로 하는 타깃 함수의 제2 출력 데이터를 전 환하여 획득하는 단계와, 제2 출력 데이터를 출력하는 단계를 포함한다. 일부 실시예에 있어서, 타깃 함수는 sigmoid 비선형 함수를 포함하고, 기설정 함수는 tanh 쌍곡선 탄젠트 함수 를 포함하며, 타깃 함수와 기설정 함수 사이의 환산 관계에 따라 현재 데이터를 기설정 함수의 입력 데이터로 전환하는 단계는, 기설정 함수의 입력 데이터로서, 현재 데이터를 2로 나눈 몫을 확정하는 단계를 포함한다. 일부 실시예에 있어서, 현재 데이터가 부동 소수점 수이고, 부동 소수점 수가 2를 기수로 하고 가수 및 지수를 포함하는 표현 방식을 이용할 경우, 현재 데이터를 2로 나눈 몫을 확정하는 단계는, 현재 데이터의 지수에서 1 을 감하여 현재 데이터를 2로 나눈 몫을 획득하는 단계를 포함한다. 일부 실시예에 있어서, 환산 관계 및 제1 출력 데이터에 따라 현재 데이터를 입력으로 하는 타깃 함수의 제2 출 력 데이터를 전환하여 획득하는 단계는, 현재 데이터를 입력으로 하는 타깃 함수의 제2 출력 데이터로서, 제1 출력 데이터에 1을 합산하고, 합산한 값을 2로 나눈 몫을 확정하는 단계를 포함한다. 일부 실시예에 있어서, 합산한 값이 부동 소수점 수이고, 부동 소수점 수가 2를 기수로 하고 가수 및 지수를 포 함하는 표현 방식을 이용할 경우, 합산한 값을 2로 나눈 몫을 확정하는 단계는, 합산한 값의 지수에서 1을 감하 여 합산한 값을 2로 나눈 몫을 획득하는 단계를 포함한다. 일부 실시예에 있어서, 기설정 함수에 대응되는 룩업 테이블에는 양수 입력 구간 및/또는 음수 입력 구간이 포 함된다. 일부 실시예에 있어서, 타깃 함수는 tanh 쌍곡선 탄젠트 함수를 포함하고, 기설정 함수는 sigmoid 비선형 함수 를 포함하며, 타깃 함수와 기설정 함수 사이의 환산 관계에 따라 현재 데이터를 기설정 함수의 입력 데이터로 전환하는 단계는, 기설정 함수의 입력 데이터로서, 현재 데이터와 2의 곱을 확정하는 단계를 포함한다.일부 실시예에 있어서, 현재 데이터가 부동 소수점 수이고, 부동 소수점 수가 2를 기수로 하고 가수 및 지수를 포함하는 표현 방식을 이용할 경우, 현재 데이터와 2의 곱을 확정하는 단계는, 현재 데이터의 지수에 1을 더하 여 현재 데이터와 2의 곱을 획득하는 단계를 포함한다. 일부 실시예에 있어서, 환산 관계 및 제1 출력 데이터에 따라 현재 데이터를 입력으로 하는 타깃 함수의 제2 출 력 데이터를 전환하여 획득하는 단계는, 현재 데이터를 입력으로 하는 타깃 함수의 제2 출력 데이터로서, 제1 출력 데이터와 2의 곱을 확정하고, 곱에서 1을 감한 차이값을 확정하는 단계를 포함한다. 일부 실시예에 있어서, 제1 출력 데이터는 부동 소수점 수이고, 부동 소수점 수가 2를 기수로 하고 가수 및 지 수를 포함하는 표현 방식을 이용할 경우, 제1 출력 데이터와 2의 곱을 확정하는 단계는, 제1 출력 데이터의 지 수에 1을 더하여 제1 출력 데이터와 2의 곱을 획득하는 단계를 포함한다. 제2 양태에 있어서, 본 출원읜 실시예는 적어도 하나의 활성화 함수가 구비된 신경망을 위한 데이터 처리 장치 를 제공하며, 해당 장치는 현재 데이터를 획득하는 활성화 함수가 타깃 함수인 것에 대응하여, 타깃 함수와 기 설정 함수 사이의 환산 관계에 따라 현재 데이터를 기설정 함수의 입력 데이터로 전환하도록 구성된 제1 전환 유닛과, 기설정 함수에 대응되는 룩업 테이블에서, 입력 데이터를 입력으로 하는 기설정 함수의 제1 출력 데이 터를 조회하도록 구성된 조회 유닛과, 환산 관계 및 제1 출력 데이터에 따라 현재 데이터를 입력으로 하는 타깃 함수의 제2 출력 데이터를 전환하여 획득하도록 구성된 제2 전환 유닛과, 제2 출력 데이터를 출력하도록 구성된 출력 유닛을 포함한다. 일부 실시예에 있어서, 타깃 함수는 sigmoid 비선형 함수를 포함하고, 기설정 함수는 tanh 쌍곡선 탄젠트 함수 를 포함하며, 제1 전환 유닛은, 기설정 함수의 입력 데이터로서, 현재 데이터를 2로 나눈 몫을 확정하도록 구성 된다. 일부 실시예에 있어서, 현재 데이터가 부동 소수점 수이고, 부동 소수점 수가 2를 기수로 하고 가수 및 지수를 포함하는 표현 방식을 이용할 경우, 제1 전환 유닛은, 현재 데이터의 지수에서 1을 감하여 현재 데이터를 2로 나눈 몫을 획득하도록 더 구성된다. 일부 실시예에 있어서, 제2 전환 유닛은, 현재 데이터를 입력으로 하는 타깃 함수의 제2 출력 데이터로서, 제1 출력 데이터에 1을 합산하고, 합산한 값을 2로 나눈 몫을 확정하도록 구성된다. 일부 실시예에 있어서, 합산한 값이 부동 소수점 수이고, 부동 소수점 수가 2를 기수로 하고 가수 및 지수를 포 함하는 표현 방식을 이용할 경우, 제2 전환 유닛은, 합산한 값의 지수에서 1을 감하여 합산한 값을 2로 나눈 몫 을 획득하도록 더 구성된다. 일부 실시예에 있어서, 기설정 함수에 대응되는 룩업 테이블에는 양수 입력 구간 및/또는 음수 입력 구간이 포 함된다. 일부 실시예에 있어서, 타깃 함수는 tanh 쌍곡선 탄젠트 함수를 포함하고, 기설정 함수는 sigmoid 비선형 함수 를 포함하며, 제1 전환 유닛은, 기설정 함수의 입력 데이터로서, 현재 데이터와 2의 곱을 확정하도록 더 구성된 다. 일부 실시예에 있어서, 현재 데이터가 부동 소수점 수이고, 부동 소수점 수가 2를 기수로 하고 가수 및 지수를 포함하는 표현 방식을 이용할 경우, 제1 전환 유닛은, 현재 데이터의 지수에 1을 더하여 현재 데이터와 2의 곱 을 획득하도록 더 구성된다. 일부 실시예에 있어서, 제2 전환 유닛은, 현재 데이터를 입력으로 하는 타깃 함수의 제2 출력 데이터로서, 제1 출력 데이터와 2의 곱을 확정하고, 곱에서 1을 감한 차이값을 확정하도록 더 구성된다. 일부 실시예에 있어서, 제1 출력 데이터는 부동 소수점 수이고, 부동 소수점 수가 2를 기수로 하고 가수 및 지 수를 포함하는 표현 방식을 이용할 경우, 제2 전환 유닛은, 제1 출력 데이터의 지수에 1을 더하여 제1 출력 데 이터와 2의 곱을 획득하도록 더 구성된다. 제3 양태에 있어서, 본 출원의 실시예는 인공 지능 칩을 제공하며, 인공 지능 칩은, 하나 또는 다수의 프로그램 이 저장된 저장 부재(저장부)와, 실행하고자 하는 명령어에 따라 명령어 스케줄링를 진행하도록 구성된 스케줄 링 부재(스케줄링부)와, 스케줄링 부재에서 발송된 명령어를 수신하여 대응되는 프로그램을 실행하거나 및/또는 스케줄링 부재에서 발송된 명령어에 따라 서브 명령어를 생성하고, 생성된 서브 명령어를 대응되는 전용 실행 부재에 발송하도록 구성된 적어도 하나의 범용 실행 부재(범용실행부)와, 적어도 하나의 범용 실행 부재에서 발송된 명령어를 수신하여 대응되는 프로그램을 실행하도록 구성된 적어도 하나의 전용 실행 부재(전용실행부)를 포함하되, 하나 또는 다수의 전용 실행 부재가 대응되는 프로그램을 실행할 경우, 상술한 제1 양태 중 임의의 실시예에서 설명한 방법이 실현된다. 제4 양태에 있어서, 본 출원의 실시예는 컴퓨터 프로그램이 저장된 컴퓨터 판독 가능한 매체를 제공하며, 컴퓨 터 프로그램이 실행 부재에 의해 실행될 경우, 상술한 제1 양태 중 임의의 실시예에서 설명한 방법이 실현된다. 제5 양태에 있어서, 본 출원의 실시예는 프로세서, 저장 장치 및 적어도 하나의 상술한 제3 양태에서 설명한 인 공 지능 칩을 포함하는 전자 장치를 제공한다."}
{"patent_id": "10-2019-0083131", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 출원의 실시예에서 제공하는 신경망을 위한 데이터 처리 방법 및 장치는 현재 데이터를 획득하는 활성화 함 수가 타깃 함수임이 확정될 경우, 타깃 함수와 기설정 함수 사이의 환산 관계에 따라 현재 데이터를 기설정 함 수의 입력 데이터로 전환할 수 있다. 이어서, 기설정 함수에 대응되는 룩업 테이블에서, 입력 데이터를 입력으 로 하는 기설정 함수의 제1 출력 데이터를 조회할 수 있다. 다음, 환산 관계 및 제1 출력 데이터에 따라 현재 데이터를 입력으로 하는 타깃 함수의 제2 출력 데이터를 전환하여 획득할 수 있다. 또한, 제2 출력 데이터를 출 력할 수 있다. 다시 말해서, 기설정 함수를 이용하여 타깃 함수를 표현하고, 타깃 함수에 대해 상응한 룩업 테 이블을 작성하는 절차를 생략함으로써, 저장 공간에 대한 점용을 저감시키기에 유리할 수 있다. 또한, 상이한 활성화 함수를 산출함에 있어서, 룩업 테이블의 교체를 줄임으로써, 전반적인 처리 성능의 향상에 유리할 수 있 다."}
{"patent_id": "10-2019-0083131", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 첨부된 도면 및 실시예들을 결부하여 본 출원에 대한 보다 상세한 설명을 진행하기로 한다. 여기에 설명 되는 구체적인 실시예들은 단지 관련된 발명을 해석하기 위한 것일 뿐, 해당 발명을 한정하기 위한 것이 아님을 이해할 수 있을 것이다. 또한, 설명의 편의를 위해 첨부된 도면에는 단지 관련 발명에 관한 부분만이 도시된다. 본 출원의 실시예 및 실시예 중의 특징들은 모순되지 않는 한 서로 조합될 수 있다. 이하, 첨부된 도면을 참조 하고 실시예들을 결부하여 본 출원에 대한 상세한 설명을 진행하기로 한다. 도 1은 본 출원 실시예의 신경망을 위한 데이터 처리 방법 및 장치의 실시예를 적용할 수 있는 예시적 시스템 체계 구조를 나타낸다. 도 1에 도시된 바와 같이, 시스템 체계구조는 단말기(101, 102, 103), 네트워크 및 서버를 포함 할 수 있다. 네트워크는 단말기(101, 102, 103)와 서버 사이에서 통신 링크를 제공하는 매체로 이용 될 수 있다. 네트워크는 예컨대 유선 통신 링크, 무선 통신 링크 또는 광섬유 케이블 등과 같은 다양한 연 결 유형을 포함할 수 있다. 사용자는 단말기(101, 102, 103)를 이용하여 네트워크를 통해 서버와 교호하여 메세지 등을 수신하거 나 발송할 수 있다. 단말기(101, 102, 103) 상에는 예컨대 모델 트레이닝 및 테스트 유형의 애플리케이션, 모델예측 유형의 애플리케이션, 웹 브라우저, 쇼핑 유형의 애플리케이션, 인스턴트 통신 수단 등과 같은 다양한 클 라이언트 애플리케이션이 설치될 수 있다. 여기의 단말기(101, 102, 103)는 하드웨어일 수 있으며, 소프트웨어일 수도 있다. 단말기(101, 102, 103)가 하 드웨어일 경우, 스크린을 구비하는 다양한 전자 장치일 수 있고, 스마트폰, 태블릿 PC, 스마트 워치, 전자책 리 더, MP3 플레이어(Moving Picture Experts Group Audio Layer III; MPEG 오디오 계층 3), 랩탑형 컴퓨터 및 데 스크탑형 컴퓨터 등을 포함하나, 이에 한정되지 않는다. 단말기(101, 102, 103)가 소프트웨어일 경우, 앞서 나 열한 전자 장치에 설치될 수 있다. 이는 (예컨대, 분산형 서비스를 제공하기 위한) 다수의 소프트웨어 또는 소 프트웨어 모듈로 구현될 수 있으며, 단일 소프트웨어 또는 소프트웨어 모듈로 구현될 수도 있다. 여기서 이에 대한 구체적인 한정을 진행하지 않는다. 서버는 다양한 서비스를 제공하는 서버일 수 있으며, 예컨대, 단말기(101, 102, 103)에 설치된 다양한 애 플리케이션을 지원하는 백엔드 서버일 수 있다. 백엔드 서버는 사용자가 애플리케이션 상에서 진행하는 동작 행 위에 대해 분석 및 처리를 진행할 수 있으며, 처리 결과(예컨대, 동작 행위에 대응되는 응답 정보)를 단말기 (101, 102, 103)에 피드백할 수 있다. 또한, 서버에는 인공 지능 칩이 설치될 수 있다. 인공 지능 칩(AI(Artificial Intelligence) 칩)은 AI 가속기 또는 컴퓨팅 카드로 지칭될 수도 있으며, 즉, 전문적으로 인공 지능 애플리케이션 중의 대량의 컴퓨팅 태스크를 처리하기 위한 모듈이다. 예를 들어, 서버의 CPU(Central Processing Unit, 중앙 프로세 서)는 예컨대 PCIE(peripheral component interconnect express, 고속 직렬 컴퓨터 확장 버스 표준)를 통해 획 득한 트레이닝 데이터 및/또는 테스트 데이터를 인공 지능 칩에 전송할 수 있다. 이때, 인공 지능 칩(10 6)은 이러한 데이터를 이용하여 모델 트레이닝 및/또는 테스트를 진행할 수 있다. 또한 예를 들어, CPU는 획득 한 분석하고자 하는 데이터를 인공 지능 칩에 전송할 수 있다. 이때, 인공 지능 칩은 분석하고자 하 는 데이터를 이미 트레이닝된 모델에 입력하여, 해당 모델을 이용하여 분석을 진행할 수 있다. 이로써, CPU는 인공 지능 칩의 처리 결과(예컨대, 트레이닝된 모델 데이터, 모델의 테스트 결과 데이터 또 는 모델의 분석 결과 데이터 등)에 따라 진일보로 처리 및 분석을 실행할 수 있다. 다시 말해서, 기타 비 컴퓨 팅 태스크는 여전히 서버의 CPU가 담당할 수 있다. 인공 지능 칩으로 서버의 CPU를 대체하여 부 분적인 처리 기능을 구현하고, CPU의 작업 부하를 저감시켜, 서버의 전반적인 처리 성능의 향상에 유리할 수 있음을 이해할 수 있을 것이다. 여기의 서버는 마찬기지로 하드웨어일 수 있으며, 소프트웨어일 수도 있다. 서버가 하드웨어일 경우, 다수의 서버로 구성된 분산형 서버 클러스트로 구현될 수 있으며, 또는 단일 서버로 구현될 수도 있다. 서버 가 소프트웨어일 경우, (예를 들어, 분산형 서비스를 제공하기 위한) 다수의 소프트웨어 또는 소프트웨어 모듈로 구현될 수 있으며, 단일 소프트웨어 또는 소프트웨어 모듈로 구현될 수도 있다. 여기서 이에 대한 구체 적인 한정을 진행하지 않는다. 본 출원의 실시예에서 제공하는 신경망을 위한 데이터 처리 방법은 일반적으로 인공 지능 칩에 의해 실행 될 수 있다. 따라서, 신경망을 위한 데이터 처리 장치는 일반적으로 인공 지능 칩에 설치된다. 도 1 중의 단말기, 네트워크, 서버 및 인공 지능 칩의 수량은 단지 개략적인 것이며, 구현 수요에 따라, 임의의 수량의 단말기, 네트워크, 서버 및 인공 지능 칩이 구비될 수 있음을 이해하여야 한다. 이어서, 도 2를 참조하면, 본 출원에 따른 신경망을 위한 데이터 처리 방법의 일 실시예의 흐름을 나타낸 다. 해당 신경망을 위한 데이터 처리 방법은 아래와 같은 단계를 포함할 수 있다. 단계에서, 현재 데이터를 획득하는 활성화 함수가 타깃 함수인 것에 대응하여, 타깃 함수와 기설정 함수 사이의 환산 관계에 따라 현재 데이터를 기설정 함수의 입력 데이터로 전환한다. 본 실시예에 있어서, 신경망을 위한 데이터 처리 방법의 실행 주체(예컨대, 도 1에 도시된 인공 지능 칩) 는 유선 연결 방식 또는 무선 연결 방식을 통해 데이터를 수신하거나 획득할 수 있다. 또한, 이러한 데이터를 이용하여 이에 저장된 신경망 모델에 대해 트레이닝 또는 테스트를 진행할 수 있다. 또한, 이에 저장된 신경망 모델을 이용하여 이러한 데이터에 대해 분석 및 처리를 진행할 수도 있다. 여기서, 신경망 모델은 기계 학습 기 술을 기반으로 구축된 다양한 기존의 학습 모델일 수 있다. 해당 신경망 모델은 다양한 기존의 신경망 구조(예 컨대, DenseBox, VGGNet, ResNet, SegNet 등)를 구비할 수 있다. 또한, 신경망 모델에는 통상적으로 적어도 하 나의 노드(즉, 활성화 함수)가 설정된다.본 실시예에 있어서, 실행 주체는 현재 데이터를 획득하는 활성화 함수가 타깃 함수인지 여부를 확정할 수 있다. 즉, 현재 데이터를 입력으로 이용하여야 할 활성화 함수가 타깃 함수인지 여부를 확정한다. 또한, 현재 데이터를 획득하는 활성화 함수가 타깃 함수임이 확정될 경우, 타깃 함수와 기설정 함수 사이의 환산 관계에 따 라 현재 데이터를 기설정 함수의 입력 데이터로 전환할 수 있다. 신경망 모델을 구축함에 있어서, 각 노드에 이용되는 활성화 함수는 이미 알려진 것임을 이해할 수 있다. 이로 써, 실행 주체는 현재 데이터가 위치한 노드에 따라 해당 노드의 활성화 함수가 타깃 함수인지 여부를 확정할 수 있다. 또는, 실행 주체는 현재 실행 중인 프로그램 중 활성화 함수의 관련 코딩에 따라 이가 타깃 함수인지 여부를 확정할 수 있다. 여기의 현재 데이터는 신경망 모델의 초기 입력 데이터일 수 있으며, 신경망 모델 중 임의 하나의 노드의 입력 데이터, 즉, 이전 노드의 출력 데이터일 수도 있다. 여기서, 타깃 함수 및 기설정 함 수는 신경망 모델에서 사용되는 임의의 2가지 활성화 함수일 수 있다. 예를 들어, 비선형 활성화 함수 sigmoid, tanh(hyperbolic tangent, 쌍곡선 탄젠트) 및 relu(rectified linear unit, 보정된 선형 유닛) 중 임의의 2가 지일 수 있다. 타깃 함수 및 기설정 함수가 확정된 경우, 양자 사이의 환산 관계가 산출될 수 있으며, 통상적으 로 이는 변경되지 않는다. 본 출원의 일부 선택 가능한 구현에 있어서, 타깃 함수는, 수학식 1일 수 있다. 수학식 1"}
{"patent_id": "10-2019-0083131", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "기설정 함수는, 수학식 2일 수 있다. 수학식 2"}
{"patent_id": "10-2019-0083131", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "양자 사이의 환산 관계는, 수학식 3이다. 수학식 3"}
{"patent_id": "10-2019-0083131", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "이로부터 알 수 있는 바, tanh(x) 함수의 입력 데이터는 sigmoid(x) 함수의 입력 데이터의 2배이다. 이때, 현재 데이터와 2의 곱을 확정하면 즉 기설정 함수의 입력 데이터이다. 컴퓨터에서 전송되는 데이터는 통상적으로 부동 소수점 수임을 이해할 수 있을 것이다. 또한, 부동 소수점 수는 일반적으로 2를 기수로 하고 가수 및 지수를 포함하는 표현 방식을 이용한다. 예를 들어, 이다. 여기서, 여기서 M은 가수를 표시하고, 양수이거나 음수일 수 있으며, E는 지수를 표시한다. 또한, 예를 들면, 이다. 여기서 S는 기호 위치, 즉, 양 또는 음을 표시한다. 이때, 가수 M은 단지 양 수일 수 있다. 여기서, 실행 주체는 계산 공식(예컨대, 부동 소수점 수의 곱셈법)을 이용하여 현재 데이터와 2의 곱을 직접적 으로 산출할 수 있다. 이러한 산출 방법은 통상적으로 효율이 상대적으로 낮다. 데이터의 처리 효율을 향상시키 기 위하여, 관찰을 통해 발견할 수 있는 바, 현재 데이터와 2의 곱에 있어서, 현재 데이터의 지수에 1을 더하면 된다. 즉, 실행 주체는 현재 데이터의 지수에 1을 더하여 현재 데이터와 2의 곱을 획득할 수 있다. 다시 말해서, 현재 데이터 x로부터 전환되어 획득한 기설정 함수의 입력 데이터 또는 를 획득할 수 있다. 이로써, 대량의 산출 과정을 감소시켜 효율적인 처리를 실현할 수 있다. 단계에서, 기설정 함수에 대응되는 룩업 테이블에서, 입력 데이터를 입력으로 하는 기설정 함수의 제1 출 력 데이터를 조회한다. 본 실시예에 있어서, 실행 주체는 이미 저장된 기설정 함수에 대응되는 룩업 테이블에서, 입력 데이터를 입력으 로 하는 기설정 함수의 제1 출력 데이터를 조회할 수 있다. 여기의 룩업 테이블은 통상적으로 입력 범위 내의 활성화 함수의 근사 출력값을 설명하기 위한 것일 수 있다. 즉, 활성화 함수 곡선 중의 여러개의 포인트를 취하 고, 인접한 2개의 포인트를 연결시켜 하나의 직선을 획득할 수 있다. 해당 2개의 포인트 사이에 위치한 횡좌표 의 함수값은 이러한 직선의 종좌표 값으로 근사하게 대체할 수 있다. 또한, 근사값을 최대한으로 진실값에 접근 시키기 위하여, 통상적으로 보다 많은 포인트들을 연결시켜야 한다. 기존의 기술에 있어서, 일반적으로 각 활성화 함수에 대해, 이에 대응되는 룩업 테이블을 구축한다. 또한, 상응 한 활성화 함수의 산출은 통상적으로 룩업 테이블을 이용하는 방식을 통해 실현한다. 예를 들어, sigmoid 함수 및 tanh 함수에 대응되는 룩업 테이블은 흔히 상이한 것이다. 다시 말해서, 기설정 함수에 대응되는 룩업 테이 블에서, 입력 데이터를 횡좌표로 하는 포인트를 조회하여, 해당 포인트에 대응되는 종좌표를 제1 출력 데이터로 확정한다. 단계에서, 환산 관계 및 제1 출력 데이터에 따라 현재 데이터를 입력으로 하는 타깃 함수의 제2 출력 데이 터를 전환하여 획득한다. 본 실시예에 있어서, 제1 출력 데이터를 획득한 후, 실행 주체는 타깃 함수와 기설정 함수 사이의 환산 관계에 따라 현재 데이터를 입력으로 하는 타깃 함수의 제2 출력 데이터를 전환하여 획득할 수 있다. 본 실시예의 일부 선택 가능한 구현에 있어서, 타깃 함수가 tanh 함수이고, 기설정 함수가 sigmoid 함수일 경우, 실행 주체는 제1 출력 데이터와 2의 곱을 확정할 수 있다. 또한, 곱에서 1을 감한 차이값을 현재 데이터 를 입력으로 하는 타깃 함수의 제2 출력 데이터로 이용할 수 있다. 즉, 이다. 여기서, 실행 주체는 마찬가지로 계산 공식을 이용하여 제2 출력 데이터를 구할 수 있다. 대안으로, 제1 출력 데이터는 부동 소수점 수이고, 부동 소수점 수가 2를 기수로 하고 가수 및 지수를 포함하는 표현 방식을 이용할 경우, 실행 주체는 제1 출력 데이터의 지수에 1을 더하여 제1 출력 데이터와 2의 곱을 획득할 수도 있다. 이로 써, 부동 소수점 수의 곱셈법을 이용할 필요가 없어, 처리 효율의 향상에 유리할 수 있다. 마지막으로, 부동 소 수점 수의 뺄셈법을 통해 곱과 1의 차이값을 산출하여 타깃 함수의 제2 출력 데이터를 획득한다. 단계에서, 제2 출력 데이터를 출력한다. 본 실시예에 있어서, 단계에서 전환하여 획득한 타깃 함수의 제2 출력 데이터에 따라, 실행 주체는 해당 제2 출력 데이터를 출력할 수 있다. 여기의 출력은, 제2 출력 데이터를 저장하는 것; 제2 출력 데이터를 현재 타깃 함수가 위치한 노드에서 다음 노드로 전송하는 것, 즉 다음 노드의 활성화 함수의 입력 데이터로 이용하는 것; 및 제2 출력 데이터(예컨대 모델의 출력으로서)를 기타 전자 장치(예컨대, 도 1에 도시된 서버)에 전 송하는 것; 중의 적어도 하나를 포함할 수 있으나, 이에 한정되지 않는다.하드웨어의 설계에 있어서, 각 룩업 테이블은 일반적으로 단지 하나의 판독 포트를 구비한다. 그러나, 실제로 실행하는 과정에, 흔히 대량의 병렬 계산이 발생된다. 이로 인해 여러 개의 계산 통로가 동시에 모두 룩업 테이 블을 판독하여야 하는 경우가 발생할 가능성이 존재하게 된다. 따라서, 각 노드에 모두 다양한 활성화 함수에 대응되는 하나의 룩업 테이블을 저장할 필요가 있다. 이로 인해 메모리의 대량의 저장 공간이 점용된다. 그러나, 본 출원은 기설정 함수로 타깃 함수를 표현함으로써, 더이상 타깃 함수의 룩업 테이블을 구축하고 저장 할 필요가 없으며, 특히는 상대적으로 흔히 쓰이는 활성화 함수를 타깃 함수로 이용함으로써, 대량의 저장 공간 을 절약할 수 있다. 또한, 흔히 쓰이는 활성화 함수를 기설정 함수로 이용하여, 상이한 활성화 함수를 산출함에 있어서, 룩업 테이블의 교체를 줄이거나 생략하는데 유리하여, 전반적인 처리 성능의 향상에 유리할 수 있다. 본 실시예 중의 신경망을 위한 데이터 처리 방법에 따르면, 현재 데이터를 획득하는 활성화 함수가 타깃 함수임 이 확정될 경우, 타깃 함수와 기설정 함수 사이의 환산 관계에 따라 현재 데이터를 기설정 함수의 입력 데이터 로 전환할 수 있다. 이어서, 기설정 함수에 대응되는 룩업 테이블에서, 입력 데이터를 입력으로 하는 기설정 함 수의 제1 출력 데이터를 조회할 수 있다. 이어서, 환산 관계 및 제1 출력 데이터에 따라 현재 데이터를 입력으 로 하는 타깃 함수의 제2 출력 데이터를 전환하여 획득할 수 있다. 또한, 제2 출력 데이터를 출력할 수 있다. 다시 말해서, 기설정 함수를 이용하여 타깃 함수를 표현하고, 타깃 함수에 대한 상응한 룩업 테이블을 작성하는 것을 생략함으로써, 저장 공간에 대한 점용을 저감시키기에 유리할 수 있다. 또한, 상이한 활성화 함수를 산출 함에 있어서, 룩업 테이블의 교체 과정을 줄임으로써, 전반적인 처리 성능의 향상에 유리할 수 있다. 도 3을 참조하면, 본 출원에 따른 신경망을 위한 데이터 처리 방법의 다른 일 실시예의 흐름을 나타낸다. 해당 신경망을 위한 데이터 처리 방법은 아래와 같은 단계들을 포함할 수 있다. 단계에서, 현재 데이터를 획득하는 활성화 함수가 sigmoid 함수인 것에 대응하여, tanh 함수의 입력 데이 터로서, 현재 데이터를 2로 나눈 몫을 확정한다. 본 실시예에 있어서, 신경망을 위한 데이터 처리 방법의 실행 주체(예컨대, 도 1에 도시된 인공 지능 칩) 는 유선 연결 방식 또는 무선 연결 방식을 통해 데이터를 수신하거나 획득할 수 있다. 또한, 이러한 데이터를 이용하여 이에 저장된 신경망 모델에 대해 트레이닝 또는 테스트를 진행할 수 있다. 또한, 이에 저장된 신경망 모델을 이용하여 이러한 데이터에 대해 분석 및 처리를 진행할 수도 있다. 여기서, 신경망 모델은 기계 학습 기 술을 기반으로 구축된 다양한 기존의 학습 모델일 수 있다. 또한, 신경망 모델에는 통상적으로 적어도 하나의 노드(즉, 활성화 함수)가 설정된다. 본 실시예에 있어서, 현재 데이터를 획득하는 활성화 함수가 sigmoid 함수인지 여부를 확정할 수 있다. 또한, 현재 데이터를 획득하는 활성화 함수가 sigmoid 함수인 것으로 확정될 경우, tanh 함수의 입력 데이터로서, 현 재 데이터를 2로 나눈 몫을 확정할 수 있다. 이때, 양자 사이의 환산 관계는, 수학식 4이다. 수학식 4"}
{"patent_id": "10-2019-0083131", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "여기서, 실행 주체는 계산 공식을 이용하여 직접적으로 몫을 확정할 수 있다. 예시적으로, 현재 데이터는 부동 소수점 수이고, 부동 소수점 수는 2를 기수로 하고 가수 및 지수를 포함하는 표현 방식을 이용할 수 있다. 다시 말해서, 실행 주체는 이러한 표현 방식을 이용하여 부동 소수점 수를 기록할 수 있다. 이러할 경우, 실행 주체 는 현재 데이터의 지수에서 1을 감하여 현재 데이터를 2로 나눈 몫을 신속하게 획득할 수 있다. 즉, 또는 이다. 이로써, 부동 소수점 수의 나눗셈 산출을 생략하여 처 리 효율을 진일보로 향상시킬 수 있다. 단계에서, tanh 함수에 대응되는 룩업 테이블에서, 입력 데이터를 입력으로 하는 tanh 함수의 제1 출력 데 이터를 조회한다. 본 실시예에 있어서, 실행 주체는 tanh 함수에 대응되는 룩업 테이블에서, 입력 데이터를 입력으로 하는 tanh 함수의 제1 출력 데이터를 조회할 수 있다. 이는 도 2의 실시예의 단계에 대한 관련 설명을 참조할 수 있 으며, 이에 대한 중복된 설명은 생략하기로 한다. tanh 함수의 출력은 0을 중심으로, -1 내지 1의 구간 내에 위치함을 이해할 수 있을 것이다. 다시 말해서, tanh 함수는 원점을 기반으로 대칭되며, 즉, tanh(-x)=-tanh(x)이다. 이로부터 알수 있는 바, tanh 함수의 룩업 테이 블은 완전한 룩업 테이블이 필요하지 않을 수 있다. 이때, tanh 함수에 대응되는 룩업 테이블에는 양수 입력 구 간 및/또는 음수 입력 구간이 포함될 수 있다. 따라서, 진일보로 저장 공간을 절약하기 위하여, 실행 주체에는 단지 룩업 테이블의 양수 부분(또는 음수 부분)만 저장될 수 있다. 또한, 음수 부분(양수 부분)은 양수 부분(또 는 음수 부분)을 통해 산출할 수 있다. 단계에서, 현재 데이터를 입력으로 하는 sigmoid 함수의 제2 출력 데이터로서, 제1 출력 데이터에 1을 합 산하고, 합산한 값을 2로 나눈 몫을 확정한다. 본 실시예에 있어서, 실행 주체는 단계에서 획득한 제1 출력 데이터와 1의 합계를 구할수 있다. 또한, 합 산한 값을 2로 나누고, 몫을 현재 데이터를 입력으로 하는 sigmoid 함수의 제2 출력 데이터로 이용할 수 있다. 여기서, 합산한 값이 부동 소수점 수이고, 부동 소수점 수가 2를 기수로 하고 가수 및 지수를 포함하는 표현 방 식을 이용할 경우, 실행 주체는 부동 소수점 수의 뎃셈법 산출을 이용하여 합산한 값을 획득할 수 있다. 이어서, 합산한 값의 지수에서 1을 감함으로써, 합산한 값을 2로 나눈 몫을 획득할 수 있다. 이로써, 부동 소수 점 수의 나눗셈 산출을 생략하여, 처리 효율을 향상시키기에 유리할 수 있다. 단계에서, 제2 출력 데이터를 출력한다. 본 실시예에 있어서, 현재 데이터를 입력으로 하는 sigmoid 함수의 제2 출력 데이터를 확정할 경우, 실행 주체 는 해당 제2 출력 데이터를 출력할 수 있다. 이는 도 2의 실시예의 단계에 대한 관련 설명을 참조할 수 있 으며, 이에 대한 중복된 설명은 생략하기로 한다. 본 실시예 중의 신경망을 위한 데이터 처리 방법은, 흔히 쓰이는 sigmoid 활성화 함수를 흔히 쓰이는 tanh 활성 화 함수로 표현할 수 있다. 이로써, 대량의 저장 공간을 절약할 수 있을 뿐만 아니라, 이러한 2가지 흔히 쓰이 는 활성화 함수를 산출함에 있어서, 룩업 테이블의 교체를 진행할 필요가 없을 수 있다. 따라서, 룩업 테이블의 교체 횟수를 크게 감소시켜, 처리 성능의 현저한 향상에 유리할 수 있다. 또한, tanh 활성화 함수 자체의 특성 에 의해, 단지 룩업 테이블의 양수 부분 또는 음수 부분이 저장될 수 있다. 이로써, 저장 공간에 대한 점용을 진일보로 감소시킬 수 있다. 나아가 도 4를 참조하면, 도 4는 상술한 각 실시예에 따른 신경망을 위한 데이터 처리 방법의 일 응용 정경의 개략도이다. 도 4의 응용 정경에 있어서, 서버에는 인공 지능 칩(A) 및 인공 지능 칩(B)이 설치될 수 있다. 여기서, 인공 지능 칩(A)은 주로 신경망 모델의 트레이닝 및 테스트에 관련된 데이터 처리에 이용될 수 있다. 인공 지능 칩(B)은 주로 신경망 모델의 예측 및 분석에 관련된 데이터 처리에 이용될 수 있다. 여기서, 사용자는 단말기를 이용하여 서버에 모델 트레이닝 명령어를 발송할 수 있다. 서버 중 의 CPU는 해당 명령어를 수신한 이후, 로컬 저장 장치로부터 트레이닝 데이터 및 모델 데이터를 획득할 수 있다. 또한, 획득한 데이터를 인공 지능 칩(A)에 전송할 수 있다. CPU는 클라우드 등과 같은 기타 장치로부터 상술한 데이터를 획득할 수도 있다. 또는, 이러한 데이터는 인공 지능 칩(A)에 저장될 수도 있다. 이로써, CPU 는 단말기에서 발송하는 모델 트레이닝 명령어를 수신한 이후, 인공 지능 칩(A)에 상응한 명령어를 발송할 수 있다. 이때, 인공 지능 칩(A)은 트레이닝 데이터를 이용하여 모델에 대해 트레이닝을 진행할 수 있다. 또한, 트레이닝 과정에는 신경망을 위한 데이터 처리 방법이 실행될 수 있으며, 해당 방법은 아래와 같은 단계들을 포함한다. 먼저, 현재 데이터를 획득하는 활성화 함수가 타깃 함수일 경우, 타깃 함수와 기설정 함수 사이의 환산 관계에 따라 현재 데이터를 기설정 함수의 입력 데이터로 전환할 수 있고, 이어서, 기설정 함수에 대응되는 룩업 테이 블에서, 입력 데이터를 입력으로 하는 기설정 함수의 제1 출력 데이터를 조회할 수 있고, 다음으로, 환산 관계 및 제1 출력 데이터에 따라 현재 데이터를 입력으로 하는 타깃 함수의 제2 출력 데이터를 전환하여 획득할 수 있으며, 그 후, 모델 트레이닝이 종료될 때까지, 제2 출력 데이터를 현재 데이터로 이용하여, 다음 노드의 활성 화 함수에 입력할 수 있다.이로써, CPU는 트레이닝된 모델을 저장 장치 또는 인공 지능 칩(B)에 저정할 수 있다. 아울러, 서버는 단 말기에 트레이닝 결과를 설명하기 위한 피드백 정보를 발송할 수 있다. 여기서, 피드백 정보는, 모델 트레 이닝 종료, 트레이닝된 모델의 저장 위치, 모델 트레이닝 실패, 착오 원인 및 착오 위치 등 중 적어도 하나를 포함할 수 있다. 본 응용 정경에 있어서, 인공 지능 칩으로 서버 중의 CPU를 대체하여 모델 트레이닝을 진행하여, CPU의 부하를 감소시킬 수 있다. 아울러, 인공 지능 칩은 상술한 각 실시예 중의 신경망을 위한 데이터 처리 방법을 이용함으 로써, 모델의 트레이닝 효율을 향상시키기에 유리할 수 있다. 이로써, 서버의 전반적인 성능을 향상시켜, 사용 자의 대기 시간을 감소시킴으로써, 사용자의 사용 체험을 향상시킬 수 있다. 이어서 도 5를 참조하면, 상술한 각 도면에 도시된 방법의 구현으로서, 본 출원은 신경망을 위한 데이터 처리 장치의 일 실시예를 제공한다. 해당 장치 실시예는 상술한 각 실시예에 도시된 방법 실시예에 대응되며, 해당 장치는 구체적으로 다양한 전자 장치에 적용될 수 있다. 도 5에 도시된 바와 같이, 본 실시예의 신경망을 위한 데이터 처리 장치는, 현재 데이터를 획득하는 활성 화 함수가 타깃 함수인 것에 대응하여, 타깃 함수와 기설정 함수 사이의 환산 관계에 따라 현재 데이터를 기설 정 함수의 입력 데이터로 전환하도록 구성된 제1 전환 유닛; 기설정 함수에 대응되는 룩업 테이블에서, 입 력 데이터를 입력으로 하는 기설정 함수의 제1 출력 데이터를 조회하도록 구성된 조회 유닛; 환산 관계 및 제1 출력 데이터에 따라 현재 데이터를 입력으로 하는 타깃 함수의 제2 출력 데이터를 전환하여 획득하도록 구 성된 제2 전환 유닛; 및 제2 출력 데이터를 출력하도록 구성된 출력 유닛을 포함할 수 있다. 여기서, 신경망에는 적어도 하나의 활성화 함수가 설정된다. 본 실시예의 일부 선택 가능한 구현에 있어서, 타깃 함수는 sigmoid 비선형 함수를 포함할 수 있고, 기설정 함 수는 tanh 쌍곡선 탄젠트 함수를 포함할 수 있으며, 제1 전환 유닛은 기설정 함수의 입력 데이터로서, 현 재 데이터를 2로 나눈 몫을 확정하도록 구성될 수 있다. 대안으로, 현재 데이터는 부동 소수점 수이고, 부동 소수점 수가 2를 기수로 하고 가수 및 지수를 포함하는 표 현 방식을 이용할 수 있을 경우, 제1 전환 유닛은 현재 데이터의 지수에서 1을 감하여 현재 데이터를 2로 나눈 몫을 획득하도록 더 구성될 수 있다. 일부 실시예에 있어서, 제2 전환 유닛은 현재 데이터를 입력으로 하는 타깃 함수의 제2 출력 데이터로서, 제1 출력 데이터에 1을 합산하고, 합산한 값을 2로 나눈 몫을 확정하도록 구성될 수 있다. 나아가, 합산한 값이 부동 소수점 수이고, 부동 소수점 수가 2를 기수로 하고 가수 및 지수를 포함하는 표현 방 식을 이용할 수 있을 경우, 제2 전환 유닛은 합산한 값의 지수에서 1을 감하여 합산한 값을 2로 나눈 몫을 획득하도록 더 구성될 수 있다. 예시적으로, 기설정 함수에 대응되는 룩업 테이블에는 양수 입력 구간 및/또는 음수 입력 구간이 포함될 수 있 다. 일부의 응용 정경에 있어서, 타깃 함수는 tanh 쌍곡선 탄젠트 함수를 포함할 수 있고, 기설정 함수는 sigmoid 비선형 함수를 포함할 수 있으며, 제1 전환 유닛은 기설정 함수의 입력 데이터로서, 현재 데이터와 2의 곱 을 확정하도록 더 구성될 수 있다. 대안으로, 현재 데이터는 부동 소수점 수이고, 부동 소수점 수가 2를 기수로 하고 가수 및 지수를 포함하는 표 현 방식을 이용할 수 있을 경우, 제1 전환 유닛은 현재 데이터의 지수에 1을 더하여 현재 데이터와 2의 곱 을 획득하도록 진일보로 더 구성될 수 있다. 일부 실시예에 있어서, 제2 전환 유닛은, 현재 데이터를 입력으로 하는 타깃 함수의 제2 출력 데이터로서, 제1 출력 데이터와 2의 곱을 확정하고, 곱에서 1을 감한 차이값을 확정하도록 더 구성될 수 있다. 나아가, 제1 출력 데이터는 부동 소수점 수이고, 부동 소수점 수가 2를 기수로 하고 가수 및 지수를 포함하는 표현 방식을 이용할 수 있을 경우, 제2 전환 유닛은 제1 출력 데이터의 지수에 1을 더하여 제1 출력 데이 터와 2의 곱을 획득하도록 진일보로 더 구성될 수 있다. 해당 장치에 기재되는 각각의 유닛들은 도 2 및 도 3을 참조하여 설명한 방법 중의 각 단계에 대응되는 것 임을 이해할 수 있다. 이로써, 앞서 방법을 상대로 하여 설명한 동작, 특징 및 실현되는 유익한 효과는 마찬가 지로 해당 장치 및 이에 포함된 유닛에 적용되며, 이에 대한 중복된 설명은 생략하기로 한다. 본 출원의 실시예는 인공 지능 칩을 더 제공한다. 해당 인공 지능 칩의 구조는 도 6을 참조할 수 있으며, 이는 본 출원의 인공 지능 칩의 일 실시예의 개략적 구조도를 나타낸다. 도 6에 도시된 바와 같이, 본 실시예 중의 인공 지능 칩은 저장 부재(저장부), 스케줄링 부재(스케줄링부), 적어도 하나의 범용 실행 부재(범용 실행부) 및 적어도 하나의 전용 실행 부재(전용실행부)를 포함할 수 있다. 본 실시예에 있어서, 저장 부재는 정보 저장 기능을 구현할 수 있는 회로 또는 소자일 수 있다. 예를 들어, 정적 랜덤 액세스 메모리(Static Random-Access Memory, SRAM), 랜덤 액세스 메모리(RAM), 메모리 스틱, 보안 디지털 카드(Secure Digital Memory Card, SD 카드) 또는 플래시 메모리 카드(TF 카드, microSD로도 지칭 됨) 등일 수 있다. 저장 부재에는 하나 또는 다수의 프로그램이 저장될 수 있다. 스케줄링 부재는 명령어의 스케줄링 분배 기능을 실현할 수 있는 회로 또는 소자일 수 있다. 스케줄링 부 재는 실행하고자 하는 명령어에 대해 해석을 진행하여, 어떠한 동작을 실행할 것인지, 즉, 무엇을 할 것인 지를 확정할 수 있다. 이어서, 실행하고자 하는 명령어를 대응되는 범용 실행 부재, 즉, 실행하고자 하는 명령어로 지시하는 동작을 실행할 수 있는 범용 실행 부재에 발송할 수 있다. 스케줄링 부재는 프로 세서에 설치될 수 있으며, 독립적으로 설치될 수도 있다. 실행하고자 하는 명령어는 기타 전자 장치 또는 전자 소자(도 1에 도시된 서버 중의 CPU)에서 인공 지능 칩에 발송된는 것일 수 있다. 이는 인공 지능 칩으로 처리하고자 하는 데이터에 따라 생성한 것일 수도 있다. 예를 들어, 현재 데이터를 획득하는 활성화 함수가 타깃 함수인 것으로 확정될 경우, 상술한 각 실시예에서 설 명되는 데이터 처리 방법을 실행하는 것을 지시하기 위한 실행하고자 하는 명령어를 생성한다. 범용 실행 부재는 흔히 쓰이는 동작 기능을 실현할 수 있는 회로 또는 소자일 수 있다. 여기의 흔히 쓰이 는 동작 기능은 예컨대 전방 전파 알고리즘, 역 전파 알고리즘 등과 같은 인공 지능 응용에서 통상적으로 사용 되는 알고리즘을 포함할 수 있으나, 이에 한정되지 않는다. 이로써, 사용자는 필요한 동작 기능에 따라 각 범용 실행 부재를 조합하여, 칩의 개발 주기 및 개발 비용을 저감시키기에 유리할 수 있다. 여기의 흔히 쓰이는 동작 기능은 명령어의 스케줄링 분배 기능을 포함할 수도 있다. 즉, 범용 실행 부재는 마찬가지로 스케줄링 부재에서 발송하는 명령어(즉, 실행하고자 하는 명령어)에 대해 해석을 진행할 수 있 다. 이어서, 해석 결과에 따라, 적어도 하나의 서브 명령어를 생성할 수 있다. 또한, 생성된 적어도 하나의 서 브 명령어를 각각 대응되는 전용 실행 부재에 발송할 수 있다. 여기서, 어느 한 전용 실행 부재가 실 행하고자 하는 명령어가 지시하는 동작을 수행할 수 있을 경우, 범용 실행 부재는 실행하고자 하는 명령어 를 서브 명령어로 이용할 수 있다. 실행하고자 하는 명령어로 지시하는 동작을 실현하기 위해, 다수의 전용 실 행 부재가 필요할 경우, 범용 실행 부재는 다수의 서브 명령어를 생성할 수 있다. 다시 말해서, 범용 실행 부재는 독립적으로 상응한 동작을 완성할 수 있을 뿐만 아니라, 스케줄링 부재 와 협동하여 명령어 스케줄링을 진행할 수도 있다. 이로써, 스케줄링 부재의 작업 부하를 줄임으로써 칩의 전반적인 처리 효율의 향상에 유리하다. 본 실시예에 있어서, 전용 실행 부재는 특정된 동작 기능을 수행할 수 있는 회로 또는 소자일 수 있다. 여 기에 설명된 특정된 동작 기능은 흔히 쓰이는 동작 기능에 대응될 수 있으며, 즉, 예컨대 상술한 각 실시예에 설명된 데이터 처리 방법과 같은 인공 지능 응용에서 흔히 쓰이지 않는 알고리즘을 포함할 수 있다. 따라서, 전 용 실행 부재는 흔히 다양한 사용자의 요구에 따라 설계되어야 한다. 대안으로, 적어도 하나의 전용 실행 부재는 각 범용 실행 부재로 실현할 수 있는 흔히 쓰이는 동작 기능을 분할하여, 분할된 동작 기능에 따라 설계된 것일 수 있다. 이때, 각 범용 실행 부재는 모두 각 전 용 실행 부재와 통신 연결될 수 있다. 이로써, 상이한 전용 실행 부재를 조합하여 보다 많은 동작 기 능을 수행하고, 실행 부재의 수량을 줄이기에 유리할 수 있다. 인공 지능 칩에는 하나 또는 다수의 저장 부재가 설치될 수 있으며, 기타 각 부재에 필요한 프로그램 등의 데이터가 저장된다. 이때, 스케줄링 부재, 범용 실행 부재 및 전용 실행 부재는 직렬 버스 또는 데이터 인터페이스 등을 통해 저장 부재로부터 프로그램 등의 데이터를 판독할 수 있다. 일부의 응용 정경에 있어서, 데이터 처리 효율을 향상시키기 위하여, 스케줄링 부재, 범용 실행 부재 및 전용 실행 부재에는 각각 저장 부재가 설치될 수도 있다. 또한, 상이한 부재 중의 저장 부재(60 1)는 대응되는 부재에 필요한 데이터를 저장할 수 있다. 예를 들어, 스케줄링 부재 중의 저장 부재에 는 명령어 스케줄링 프로그램이 저장될 수 있다. 본 실시예 중의 인공 지능 칩은 심층 학습 트레이닝 및 예측에 대해 고밀도 컴퓨팅 및 메모리 액세스 요구 사항 을 만족시킬 수 있으며, 이로써, 심층 학습 정경에서의 전통적인 CPU, GPU 등의 범용 프로세서의 처리 성능을 개선할 수 있다. 아룰러, 심층 학습 중의 데이터 처리 방법에 대해 최적화를 진행하여, 소프트웨어, 하드웨어의 전반적인 실행 효율의 향상에 유리하다. 또한, 본 출원의 실시예에 관련된 유닛은 소프트웨어 방식으로 실현될 수 있으며, 하드웨어 방식으로 실현될 수 도 있다. 설명된 유닛은 실행 부재에 설치될 수도 있다. 예를 들어, 실행 부재는 제1 전환 유닛, 조회 유닛, 제 2 전환 유닛 및 출력 유닛을 포함하는 것으로 설명될 수 있다. 여기서, 이러한 유닛의 명칭은 일부의 경우에 해 당 유닛 자체에 대한 한정을 의미하는 것이 아닌 바, 예컨대, 출력 유닛은 \"제2 출력 데이터를 출력하는 유닛\" 으로 설명될 수도 있다. 다른 일 양태에 있어서, 본 출원은 컴퓨터 판독 가능한 매체를 제공하며, 해당 컴퓨터 판독 가능한 매체는 상술 한 실시예에 설명된 인공 지능 칩에 포함된 것일 수 있으며, 해당 인공 지능 칩에 조립되지 않고 독립적으로 존 재할 수도 있다. 상기 컴퓨터 판독 가능한 매체에는 하나 또는 다수의 프로그램이 적재되고, 상기 하나 또는 다 수의 프로그램이 해당 인공 지능 칩에 의해 실행될 경우, 해당 인공 지능 칩으로 하여금, 현재 데이터를 획득하 는 활성화 함수가 타깃 함수인 것에 대응하여, 타깃 함수와 기설정 함수 사이의 환산 관계에 따라 현재 데이터 를 기설정 함수의 입력 데이터로 전환하는 단계; 기설정 함수에 대응되는 룩업 테이블에서, 입력 데이터를 입력 으로 하는 기설정 함수의 제1 출력 데이터를 조회하는 단계; 환산 관계 및 제1 출력 데이터에 따라 현재 데이터 를 입력으로 하는 타깃 함수의 제2 출력 데이터를 전환하여 획득하는 단계; 및 제2 출력 데이터를 출력하는 단 계를 실행하도록 한다. 본 출원의 컴퓨터 판독 가능한 매체는 컴퓨터 판독 가능한 신호 매체 또는 컴퓨터 판독 가능한 저장 매체 또는 상술한 양자의 임의의 조합일 수 있다. 컴퓨터 판독 가능한 저장 매체는 예컨대 전기, 자기, 광, 전자기, 적외 선 또는 반도체 시스템, 장치 소자, 또는 이들의 임의의 조합일 수 있으나, 이에 한정되지 않는다. 컴퓨터 판독 가능한 저장 매체의 보다 구체적인 예시로서, 하나 또는 다수의 와이어를 구비하는 전기적 연결, 휴대용 컴퓨터 디스켓, 하드 디스크, 랜덤 액세스 메모리(RAM), 판독 전용 메모리(ROM), 소거 및 프로그래밍 가능한 판독 전용 메모리(EPROM 또는 플래시 메모리), 광섬유, 휴대용 콤팩트 디스크 판독 전용 메모리(CD-ROM), 광학 메모리 소 자, 자기 메모리 소자, 또는 이들의 임의의 적합한 조합을 포함할 수 있으나, 이에 한정되지 않는다. 본 출원에 있어서, 컴퓨터 판독 가능한 매체는 프로그램을 포함하거나 저장하는 유형 매체일 수 있고, 해당 프로그램은 명 령어 실행 시스템, 장치 또는 소자에 의해 사용되거나 이들과 결합되어 사용될 수 있다. 그러나 본 출원에 있어 서, 컴퓨터 판독 가능한 신호 매체는 컴퓨터 판독 가능한 프로그램 코드를 적재한 베이스 밴드 또는 캐리어의 일부로서 전파되는 데이터에 포함될 수 있다. 이렇게 전파되는 데이터 신호는 전자기 신호, 광 신호 또는 이들 의 임의의 적합한 조합을 포함하는 여러가지 형식을 가질 수 있으나, 이에 한정되지 않는다. 컴퓨터 판독 가능 한 신호 매체는 컴퓨터 판독 가능한 저장 매체 이외의 임의의 컴퓨터 판독 가능한 매체일 수도 있으며, 해당 컴 퓨터 판독 가능한 매체는 명령어 실행 시스템, 장치 또는 소자의해 사용되거나 이들과 결합되어 사용되는 프로 그램을 발송하거나, 전파 또는 전송할 수 있다. 컴퓨터 판독 가능한 매체에 포함된 프로그램 코드는 무선, 유선, 광섬유 케이블, RF 등, 또는 이들의 임의의 적합한 조합을 포함하는 임의의 적당한 매체로 전송할 수 있 으나, 이에 한정되지 않는다. 아래에 도 7을 참조하면, 도 7은 본 출원의 실시예의 전자 장치(예컨대, 도 1에 도시된 단말기(101, 102, 103) 또는 서버)를 구현하기에 적합한 컴퓨터 시스템의 개략적 구조도를 나타낸다. 도 7에 도시된 전자 장 치는 단지 일 예시일 뿐, 본 출원의 실시예의 기능 및 이용 범위를 한정하기 위한 것이 아니다. 도 7에 도시된 바와 같이, 컴퓨터 시스템은 중앙 처리 유닛(701; CPU)을 포함하되, 이는 판독 전용 메모리 장치(702; ROM)에 저장된 프로그램 또는 저장부로부터 랜덤 액세스 메모리 장치(703; RAM)에 로딩된 프로 그램에 의해 다양한 적당한 동작과 처리를 실행할 수 있다. RAM에는 시스템을 작동하기에 필요한 다 양한 프로그램 및 데이터가 더 저장되어 있다. CPU는 인공 지능 칩을 통해 데이터의 처리 및 분석을 진행할 수도 있다. CPU, ROM, RAM 및 인공 지능 칩은 버스를 통해 서로 연결된다. 입력/출력(I/O) 인터페이스도 버스에 연결된다. I/O 인터페이스에 연결되는 부재로서, 터치 스크린, 버튼, 마우스, 마이크, 카메라 등을 포함하는 입력부 와, 예를 들어 음극선관(CRT), 액정 표시 장치(LCD) 등 및 스피커 등을 포함하는 출력부와, 하드 드 라이버 등을 포함하는 저장부와, 예를 들어 LAN 카드, 모뎀 등의 네트워크 인터페이스 카드를 포함하는 통 신부가 포함된다. 통신부는 인터넷과 같은 네트워크를 통해 통신처리를 실행한다. 구동부도 수요에 따라 I/O 인터페이스에 연결된다. 자기 디스크, 광 디스크, 광자기 디스크, 반도체 메모리 장치 등과 같은 착탈 가능한 매체는 이러한 매체로부터 판독된 컴퓨터 프로그램을 수요에 따라 저장부에 설치하 도록 수요에 따라 구동부에 설치된다. 특히, 본 출원에 개시된 실시예에 의하면, 흐름도를 참조하여 설명한 상기 과정들은 컴퓨터 소프트웨어 프로그 램으로 구현될 수 있다. 예를 들어, 본 출원에 개시된 실시예는 컴퓨터 프로그램 제품을 포함하고, 상기 컴퓨터 프로그램 제품은 컴퓨터 판독 가능한 매체에 적재되는 컴퓨터 프로그램을 포함한다. 해당 컴퓨터 프로그램은 흐 름도에 도시된 방법을 실행하기 위한 컴퓨터 코드를 포함한다. 이러한 실시예에 있어서, 해당 컴퓨터 프로그램 은 통신부를 경유하여 네트워크로부터 다운로드되어 설치될 수 있고 및/또는 착탈 가능한 매체로부터 설치될 수 있다. 해당 컴퓨터 프로그램이 인공 지능 칩에 의해 실행될 경우, 본 출원의 방법에 한정된 상 기 기능을 실행한다. 첨부된 도면 중의 흐름도 및 블록도는 본 출원의 각 실시예에 따른 시스템, 방법 및 컴퓨터 프로그램 제품의 구 현 가능한 체계구조, 기능 및 동작을 도시하였음을 이해할 수 있을 것이다. 이러한 방면에서, 흐름도 또는 블록 도 중의 각 블록은 하나의 모듈, 프로그램 세그먼트 또는 코드의 일부분을 대표할 수 있고, 해당 모듈, 프로그 램 세그먼트 또는 코드의 일부분은 규정된 로직 기능을 구현하기 위한 하나 또는 다수의 실행 가능한 명령어를 포함한다. 일부 대체 구현에 있어서, 블록에 표기된 기능들은 첨부된 도면에 표기된 순서와 다른 순서로 발생할 수도 있다. 예를 들어, 순차적으로 표시된 두개의 블록은 실제적으로 거의 동시에 실행될 수 있고, 경우에 따라 반대된 순서에 따라 실행될 수도 있으며, 이는 관련 기능에 따라 결정된다. 블록도 및/또는 흐름도 중의 각 블 록 및 블록도 및/또는 흐름도 중의 블록들의 조합은 규정된 기능 또는 동작을 실행하는 하드웨어 기반의 전용 시스템으로 구현되거나, 전용 하드웨어와 컴퓨터 명령어의 조합으로 구현될 수 있음을 유의하여야 한다. 이상의 설명은 단지 본 출원의 비교적 바람직한 실시예 및 운용한 기술적 원리에 대한 설명이다. 본 출원에 관 련된 발명의 범위가 상기 기술적 특징들의 특정 조합으로 이루어진 기술적 방안들에 한정되는 것이 아니라 본 발명의 주지를 벗어나지 않고서 상기 기술적 특징들 또는 그들의 균등한 특징들의 임의의 조합으로 이루어진 기"}
{"patent_id": "10-2019-0083131", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "타 기술적 방안들도 포함되어야 함을 해당 기술분야의 당업자는 이해하여야 한다. 예를 들어, 상기 특징들과 본 출원에 개시되어 있으나 이에 한정되지 않는 유사한 기능을 구비한 기술적 특징을 서로 대체하여 이루어진 기술 적 방안도 포함된다.도면 도면1 도면2 도면3 도면4 도면5 도면6 도면7"}
{"patent_id": "10-2019-0083131", "section": "도면", "subsection": "도면설명", "item": 1, "content": "본 출원의 기타 특징, 과제 및 이점들은 아래의 첨부된 도면들을 참조하여 진행한 비 한정적인 실시예들에 대한 상세한 설명으로부터 명확해 질 것이다. 도 1은 본 출원의 일 실시예가 적용 가능한 예시적 시스템 체계 구조도이다. 도 2는 본 출원에 따른 신경망을 위한 데이터 처리 방법의 일 실시예의 흐름도이다. 도 3은 본 출원에 따른 신경망을 위한 데이터 처리 방법의 다른 일 실시예의 흐름도이다. 도 4는 본 출원에 따른 신경망을 위한 데이터 처리 방법의 일 응용 정경의 개략도이다. 도 5는 본 출원에 따른 신경망을 위한 데이터 처리 장치의 일 실시예의 개략적 구조도이다. 도 6은 본 출원에 따른 인공 지능 칩의 일 실시예의 개략적 구조도이다. 도 7은 본 출원의 실시예의 전자 장치를 구현하기에 적합한 컴퓨터 시스템의 개략적 구조도이다."}
