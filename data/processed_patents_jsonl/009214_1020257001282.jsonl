{"patent_id": "10-2025-7001282", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2025-0023539", "출원번호": "10-2025-7001282", "발명의 명칭": "신경망 모듈, 칩, 전자 장치 및 매체의 컴퓨팅 파워를 최적화하는 방법", "출원인": "베이징 요우쭈쥐 네트워크 테크놀러지 컴퍼니 리", "발명자": "유안, 항지안"}}
{"patent_id": "10-2025-7001282", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "칩을 통해 신경망 모듈의 컴퓨팅 파워를 최적화하는 방법에 있어서,상기 칩에 의해, 각각의 연산자를 갖는 상기 신경망 모듈의 계산 그래프를 획득하는 단계 - 상기 신경망 모듈은애플리케이션 데이터의 프로세스 출력 결과를 획득하기 위해 상기 애플리케이션 데이터를 수신함 -, 상기 칩에 의해, 상기 계산 그래프의 제1 연산자에 대해 각 연산자의 특정 연산에 따라, 상기 계산 그래프에서상기 제1 연산자의 위치를 후속 연산자 또는 선행 연산자로 바꿔치고, 상기 제1 연산자를 두 개 이상의 동일한연산자로 분할하고, 및 서로를 상쇄할 수 있는 복수의 제1 연산자를 삽입하는 적어도 하나의 조정을 적어도 한번 수행하는 단계 - 상기 제1 연산자는 입력 텐서에서 수치 값을 변경하지 않는 텐서 연산임 -, 상기 칩에 의해, 각 연산자의 상기 특정 연산에 따라 상기 계산 그래프에서 상기 조정된 제1 연산자에 인접한제2 연산자를 결정하는 단계 - 상기 조정된 제1 연산자의 연산과 상기 제2 연산자의 연산은 연산 결과에 영향을미치지 않고 병합되거나 상쇄될 수 있음 -, 및 상기 칩에 의해, 상기 조정된 제1 연산자와 상기 제2 연산자에 대해 병합 또는 상쇄를 수행하고, 상기 병합 또는 상기 상쇄 후에 상기 계산 그래프에서 각 연산자의 연산을 실행하는 단계를 포함하는, 방법."}
{"patent_id": "10-2025-7001282", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 애플리케이션 데이터는, 적어도 한 유형의 이미지 데이터 및 자연어 데이터를 포함하는, 방법."}
{"patent_id": "10-2025-7001282", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 칩에 의해, 상기 계산 그래프의 제1 연산자에 대해 각 연산자의 특정 연산에 따라, 상기 계산 그래프에서상기 제1 연산자의 위치를 후속 연산자 또는 선행 연산자로 바꿔치고, 상기 제1 연산자를 두 개 이상의 동일한연산자로 분할하고, 및 서로를 상쇄할 수 있는 복수의 제1 연산자를 삽입하는 적어도 하나의 조정을 적어도 한번 수행하는 단계는, 두 개 이상의 후속 연산자와 분기된 선행 연산자를 갖는 제1 연산자에 응답하여, 각 제1 연산자가 후속 연산자또는 선행 연산자와 일대일로 대응하도록 상기 제1 연산자를 두 개 이상의 동일한 연산자로 분할하는 단계, 및 두 개 이상의 동일한 제1 연산자의 후속 연산자가 동일한 연산자인 것에 응답하여, 상기 두 개 이상의 동일한제1 연산자를 하나의 연산자로 통합하는 단계를 포함하는, 공개특허 10-2025-0023539-3-방법."}
{"patent_id": "10-2025-7001282", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,상기 칩에 의해, 상기 조정된 제1 연산자와 상기 제2 연산자에 대해 병합 또는 상쇄를 수행하고, 상기 병합 또는 상기 상쇄 후에 상기 계산 그래프에서 각 연산자의 연산을 실행하는 단계는, 상기 병합 또는 상기 상쇄 전의 상기 제2 연산자의 상기 연산이 상기 조정된 제1 연산자의 출력 텐서에 있는 숫자 값에 대해 수행되는 제2 연산자 연산인 것에 응답하여, 상기 병합 또는 상기 상쇄 후 상기 조정된 제1 연산자와 상기 제2 연산자를 제4 연산자로 병합하는 단계를 포함하고, 상기 제4 연산자의 연산은, 상기 칩에 의해, 상기 조정된 제1 연산자 자체의 텐서 연산을 대체하기 위해, 상기 조정된 제1 연산자의 상기입력 텐서의 상기 수치 값을 미리 정해진 순서로 판독하는 단계 - 상기 미리 정해진 순서는 상기 조정된 제1 연산자 자체의 상기 텐서 연산에 따라 결정됨 -, 및 상기 제2 연산자의 상기 연산에 따라 상기 칩에 의해 판독한 상기 수치 값에 대해 상기 제2 연산자 연산을 수행하는 단계를 포함하는, 방법."}
{"patent_id": "10-2025-7001282", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서,상기 칩에 의해, 상기 조정된 제1 연산자의 상기 입력 텐서에서 상기 숫자 값을 상기 미리 정해진 순서에 따라판독하는 단계는, 소프트웨어를 통해 칩 판독에 대한 스트라이드, 오프셋 및 루프 카운트로 구성된 그룹에서 선택된 적어도 하나를 설정하여 구현되는, 방법."}
{"patent_id": "10-2025-7001282", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서,상기 칩에 의해, 상기 조정된 제1 연산자와 상기 제2 연산자에 대해 병합 또는 상쇄를 수행하고, 상기 병합 또는 상기 상쇄 후에 상기 계산 그래프에서 각 연산자의 연산을 실행하는 단계는, 상기 병합 또는 상기 상쇄 전에 입력 텐서의 숫자 값을 변경하지 않고 상기 제2 연산자가 텐서 연산인 것에 응답하여, 상기 병합 또는 상쇄 후에, 상기 조정된 제1 연산자와 상기 제2 연산자를 제3 연산자로 병합하는 단계를 포함하고, 상기 제3 연산자의 텐서 연산은, 상기 조정된 제1 연산자의 텐서 연산과 상기 제2 연산자의 텐서 연산을 모두 구현하는, 방법.공개특허 10-2025-0023539-4-청구항 7 제1항에 있어서,상기 칩에 의해, 상기 조정된 제1 연산자와 상기 제2 연산자에 대해 병합 또는 상쇄를 수행하고, 상기 병합 또는 상기 상쇄 후에 상기 계산 그래프에서 각 연산자의 연산을 실행하는 단계는, 상기 병합 또는 상기 상쇄 전에 상기 조정된 제1 연산자와 상기 제2 연산자가 상호 역연산인 것에 응답하여, 상기 제1 연산자와 상기 제2 연산자를 상쇄시키는 단계를 포함하는, 방법."}
{"patent_id": "10-2025-7001282", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1항에 있어서,상기 제1 연산자는, 전치 연산자, 재성형 연산자, 브로드캐스트 연산자, 수집 연산자, 역방향 연산자, 컨캣 연산자 및 캐스트 연산자로 구성된 그룹에서 선택되는 적어도 하나인, 방법."}
{"patent_id": "10-2025-7001282", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1항에 있어서,상기 제2 연산자는, 전치 연산자, 재성형 연산자, 브로드캐스트 연산자, 수집 연산자, 역방향 연산자, 컨캣 연산자, 플래튼 연산자,캐스트 연산자, 요소별 이진 연산자, 배치 완전 연결 연산자 및 컨볼루션 연산자로 구성된 그룹에서 선택되는적어도 하나인, 방법."}
{"patent_id": "10-2025-7001282", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "인공 지능 칩에 있어서,애플리케이션 데이터의 프로세스 출력 결과를 획득하기 위해 신경망 모듈의 계산 그래프에 입력되는 수신된 애플리케이션 데이터를 저장하도록 구성된 메모리, 제어기를 포함하고, 상기 제어기는, 상기 계산 그래프의 제1 연산자에 대해 각 연산자의 특정 연산에 따라, 상기 계산 그래프에서 상기 제1 연산자의 위치를 후속 연산자 또는 선행 연산자로 바꿔치고, 상기 제1 연산자를 두 개 이상의 동일한 연산자로 분할하고, 및 서로를 상쇄할 수 있는 복수의 제1 연산자를 삽입하는 적어도 하나의 조정을 적어도 한 번 수행하는 단계 - 상기 제1 연산자는 입력 텐서에서 수치 값을 변경하지 않는 텐서 연산임 -, 각 연산자의 특정 연산에 따라 상기 계산 그래프에서 상기 조정된 제1 연산자에 인접한 제2 연산자를 결정하고- 상기 조정된 제1 연산자의 연산과 상기 제2 연산자의 연산은 연산 결과에 영향을 미치지 않고 병합되거나 상쇄될 수 있음 -, 및 공개특허 10-2025-0023539-5-상기 칩에 의해, 상기 조정된 제1 연산자와 상기 제2 연산자에 대해 병합 또는 상쇄를 수행하고, 상기 병합 또는 상기 상쇄 후에 상기 계산 그래프에서 각 연산자의 연산을 실행하도록 구성되는, 칩."}
{"patent_id": "10-2025-7001282", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제10항에 있어서,상기 애플리케이션 데이터는, 적어도 한 유형의 이미지 데이터 및 자연어 데이터를 포함하는, 칩."}
{"patent_id": "10-2025-7001282", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제10항에 있어서,상기 칩에 의해, 상기 계산 그래프의 제1 연산자에 대해 각 연산자의 특정 연산에 따라, 상기 계산 그래프에서상기 제1 연산자의 위치를 후속 연산자 또는 선행 연산자로 바꿔치고, 상기 제1 연산자를 두 개 이상의 동일한연산자로 분할하고, 및 서로를 상쇄할 수 있는 복수의 제1 연산자를 삽입하는 적어도 하나의 조정을 적어도 한번 수행하는 단계는, 두 개 이상의 후속 연산자와 분기된 선행 연산자를 갖는 상기 제1 연산자에 응답하여, 각 제1 연산자가 후속 연산자 또는 선행 연산자와 일대일로 대응하도록, 상기 제1 연산자를 두 개 이상의 동일한 연산자로 분할하는 단계, 및 두 개 이상의 동일한 제1 연산자의 후속 연산자가 동일한 연산자인 것에 응답하여, 상기 두 개 이상의 동일한제1 연산자를 하나의 연산자로 통합하는 단계를 포함하는, 칩."}
{"patent_id": "10-2025-7001282", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제10항에 있어서,상기 칩에 의해, 상기 조정된 제1 연산자와 상기 제2 연산자에 대해 병합 또는 상쇄를 수행하고, 상기 병합 또는 상기 상쇄 후에 상기 계산 그래프에서 각 연산자의 연산을 실행하는 단계는, 상기 병합 또는 상기 상쇄 전의 상기 제2 연산자의 상기 연산이 상기 조정된 제1 연산자의 출력 텐서에 있는 숫자 값에 대해 수행되는 제2 연산자 연산인 것에 응답하여, 상기 병합 또는 상기 상쇄 후 상기 조정된 제1 연산자와 상기 제2 연산자를 제4 연산자로 병합하는 단계를 포함하고, 상기 제4 연산자의 연산은, 상기 칩에 의해, 상기 조정된 제1 연산자 자체의 텐서 연산을 대체하기 위해, 상기 조정된 제1 연산자의 상기입력 텐서의 상기 수치 값을 미리 정해진 순서로 판독하는 단계 - 상기 미리 정해진 순서는 상기 조정된 제1 연산자 자체의 상기 텐서 연산에 따라 결정됨 -, 및 상기 제2 연산자의 상기 연산에 따라 상기 칩에 의해 판독한 상기 수치 값에 대해 상기 제2 연산자 연산을 수행하는 단계공개특허 10-2025-0023539-6-를 포함하는, 칩."}
{"patent_id": "10-2025-7001282", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제13항에 있어서,상기 칩에 의해, 상기 조정된 제1 연산자의 상기 입력 텐서에서 상기 숫자 값을 미리 정해진 순서에 따라 판독하는 단계는, 소프트웨어를 통해 칩 판독에 대한 스트라이드, 오프셋 및 루프 카운트로 구성된 그룹에서 선택된 적어도 하나를 설정하여 구현되는, 칩."}
{"patent_id": "10-2025-7001282", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제10항에 있어서,상기 칩에 의해, 상기 조정된 제1 연산자와 상기 제2 연산자에 대해 병합 또는 상쇄를 수행하고, 상기 병합 또는 상기 상쇄 후에 상기 계산 그래프에서 각 연산자의 연산을 실행하는 단계는, 상기 병합 또는 상기 상쇄 전에 입력 텐서의 숫자 값을 변경하지 않고 상기 제2 연산자가 텐서 연산인 것에 응답하여, 상기 병합 또는 상쇄 후에, 상기 조정된 제1 연산자와 상기 제2 연산자를 제3 연산자로 병합하는 단계를 포함하고, 상기 제3 연산자의 텐서 연산은, 상기 조정된 제1 연산자의 텐서 연산과 상기 제2 연산자의 텐서 연산을 모두 구현하는, 칩."}
{"patent_id": "10-2025-7001282", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제10항에 있어서,상기 칩에 의해, 상기 조정된 제1 연산자와 상기 제2 연산자에 대해 병합 또는 상쇄를 수행하고, 상기 병합 또는 상기 상쇄 후에 상기 계산 그래프에서 각 연산자의 연산을 실행하는 단계는, 상기 병합 또는 상기 상쇄 전에 상기 조정된 제1 연산자와 상기 제2 연산자가 상호 역연산인 것에 응답하여, 상기 제1 연산자와 상기 제2 연산자를 상쇄시키는 단계를 포함하는, 칩."}
{"patent_id": "10-2025-7001282", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제10항에 있어서,상기 제1 연산자는, 전치 연산자, 재성형 연산자, 브로드캐스트 연산자, 수집 연산자, 역방향 연산자, 컨캣 연산자 및 캐스트 연산자로 구성된 그룹에서 선택되는 적어도 하나인, 공개특허 10-2025-0023539-7-칩."}
{"patent_id": "10-2025-7001282", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제10항에 있어서,상기 제2 연산자는, 전치 연산자, 재성형 연산자, 브로드캐스트 연산자, 수집 연산자, 역방향 연산자, 컨캣 연산자, 플래튼 연산자,캐스트 연산자, 요소별 이진 연산자, 배치 완전 연결 연산자 및 컨볼루션 연산자로 구성된 그룹에서 선택되는적어도 하나인, 칩."}
{"patent_id": "10-2025-7001282", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "칩을 통해 신경망 모듈의 컴퓨팅 파워를 최적화하기 위한 전자 장치에 있어서, 명령들을 저장하도록 구성된 메모리, 및 상기 메모리에 있는 명령들을 판독하고 제1항 내지 제9항 중 어느 하나에 따른 상기 방법을 실행하도록 구성된프로세서를 포함하는, 전자 장치."}
{"patent_id": "10-2025-7001282", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "명령들이 저장된 비일시적 저장 매체에 있어서,상기 명령들은, 프로세서에 의해 판독될 때, 상기 프로세서로 하여금, 제1항 내지 제9항 중 어느 하나에 따른 방법을 실행하게 하는, 비일시적 저장 매체."}
{"patent_id": "10-2025-7001282", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "칩, 전자 장치 및 매체를 통해 신경망의 컴퓨팅 파워를 최적화하는 방법이 제공된다. 본 방법은 칩에 의해, 실행 되며, 이는, 연산자를 갖는 신경망의 계산 그래프를 획득하는 단계 - 여기서 신경망은, 각 연산자의 특정 동작에 따라, 애플리케이션 데이터의 출력 처리 결과를 획득하기 위해, 애플리케이션 데이터를 수신함 -, 계산 그래프에 (뒷면에 계속)"}
{"patent_id": "10-2025-7001282", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 공개는 신경망 분야(neural networks)에 관한 것이며, 보다 구체적으로는 신경망 모듈(neural network module), 칩(chip), 전자 장치(electronic device) 및 매체(medium)의 컴퓨팅 파워(computing power)를 최적화 하는 방법에 관한 것이다. 본 출원은, 2020년 6월 23일에 출원된 중국 특허 출원 번호 202010718056.6의 우선권을 주장하고, 중국 특허 출 원에 의해 공개된 전체 내용은 본 출원의 일부로 참조로 여기에 통합된다."}
{"patent_id": "10-2025-7001282", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "인공지능(AI) 칩은 신경망 연산(neural network operations)에 전념하는 칩으로, 주로 신경망 실행(neural network execution)을 가속화하기 위해 특별히 설계된 칩이다. 신경망(neural network)은 순수한 수학 공식(mathematical formulas)을 사용하여 표현될 수 있다. 이러한 수학 공식에 따르면, 신경망은 계산 그래프 모델(computational graph model)을 사용하여 표현될 수 있다. 계산 그래 프(computational graph)는 이러한 수학 공식을 시각적으로 표현한 것이다. 계산 그래프 모델은 복합 연산 (composite operation)을 복수의 하위 연산(sub-operation)으로 분할할 수 있으며, 각 하위 연산을 연산자 (operator)(Op)라고 한다. 계산 그래프는 노드(nodes)와 엣지(edges)로 구성된다. 노드는 연산자를 나타내고, 에지는 계산 간의 종속 관계(dependency relationship)를 나타낸다. 실선은 데이터 전달 종속성 관계(transfer dependency relationship)를 나타내며, 전달되는 데이터는 텐서(tensor)이다. 점선은 일반적으로 제어 종속성 (control dependency), 즉 실행 순서를 나타낸다. 계산 그래프에서, 연산자는 자체 입력 데이터를 가지며, 다른 연산자는 다른 연산 로직을 갖늬며; 각 연산자는 자체 연산 로직에 따라 연산된 출력 데이터를 출력하기 위해 입력 데이터를 사용한다. 신경망의 계산 그래프의 실행 속도를 높이고 신경망 모듈의 컴퓨팅 파워를 최적화하는 칩을 설계해야 한다."}
{"patent_id": "10-2025-7001282", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 공개의 일 측면에 따르면, 칩을 통해 신경망 모듈의 컴퓨팅 파워를 최적화하는 방법이 제공되며, 이는: 칩에 의해, 각각의 연산자를 갖는 신경망 모듈의 계산 그래프(computational graph)를 획득하는 단계 - 여기서 신경 망 모듈은 애플리케이션 데이터(application data)의 프로세스 출력 결과(process output result)를 획득하기 위해 애플리케이션 데이터(application data)를 수신함 -; 칩에 의해, 계산 그래프의 제1 연산자(first operator)에 대해 각 연산자의 특정 연산(specific operation)에 따라, 계산 그래프에서 제1 연산자의 위치를 후속 연산자(subsequent operator) 또는 선행 연산자(preceding operator)로 바꿔치고(counterchanging), 제1 연산자를 두 개 이상의 동일한 연산자로 분할하고(splitting), 및 서로를 상쇄할 수 있는 복수의 제1 연산자를 삽입하는(inserting) 적어도 하나의 조정을 적어도 한 번 수행하는(performing) 단계 - 여기서 제1 연산자는 입 력 텐서(input tensor)에서 수치 값(numerical values)을 변경하지 않는 텐서 연산(tensor operation)임 -; 칩 에 의해, 각 연산자의 특정 연산에 따라 계산 그래프에서 조정된 제1 연산자(adjusted first operator)에 인접 한 제2 연산자(second operator)를 결정하는(determining) 단계 - 여기서 조정된 제1 연산자의 연산과 제2 연 산자의 연산은 연산 결과에 영향을 미치지 않고 병합되거나 상쇄될 수 있음 -; 및 칩에 의해, 조정된 제1 연산 자와 제2 연산자에 대해 병합(merge) 또는 상쇄(cancellation)를 수행하고, 병합 또는 상쇄 후에 계산 그래프에 서 각 연산자의 연산을 실행하는(executing) 단계를 포함한다. 본 공개의 한 측면에 따르면, 인공 지능 칩(artificial intelligence chip)이 제공되며, 이는: 애플리케이션 데 이터의 프로세스 출력 결과를 얻기 위해 신경망 모듈의 계산 그래프에 입력되는 수신된 애플리케이션 데이터를 저장하도록 구성된 메모리(memory); 제어기(controller)를 포함하고, 이는; 계산 그래프의 제1 연산자(first operator)에 대해 각 연산자의 특정 연산(specific operation)에 따라, 계산 그래프에서 제1 연산자의 위치를 후속 연산자(subsequent operator) 또는 선행 연산자(preceding operator)로 바꿔치고(counterchanging), 제1 연산자를 두 개 이상의 동일한 연산자로 분할하고(splitting), 및 서로를 상쇄할 수 있는 복수의 제1 연산자를 삽입하는(inserting) 적어도 하나의 조정을 적어도 한 번 수행하고 - 여기서 제1 연산자는 입력 텐서(input tensor)에서 수치 값(numerical values)을 변경하지 않는 텐서 연산(tensor operation)임 -; 각 연산자의 특정 연산에 따라 계산 그래프에서 조정된 제1 연산자(adjusted first operator)에 인접한 제2 연산자(second operator)를 결정하고 - 여기서 조정된 제1 연산자의 연산과 제2 연산자의 연산은 연산 결과에 영향을 미치지 않고 병합되거나 상쇄될 수 있음 -; 및 칩에 의해, 조정된 제1 연산자와 제2 연산자에 대해 병합(merge) 또는 상쇄(cancellation)를 수행하고, 병합 또는 상쇄 후에 계산 그래프에서 각 연산자의 연산을 실행하도록 구성된 다. 본 공개의 한 측면에 따르면, 칩을 통해 신경망 모듈의 컴퓨팅 파워를 최적화하기 위한 전자 장치(electronic device)가 제공되며, 이는: 명령들(instructions)을 저장하도록 구성된 메모리; 메모리에 있는 명령들을 판독하 고 본 공개에 따른 방법을 실행하도록 구성된 프로세서(processor)를 포함한다. 본 공개의 일 측면에 따르면, 명령들이 저장된 비일시적 저장 매체(non-temporary storage medium)가 제공되며, 명령들은 프로세서에 의해 판독될 때 프로세서가 본 공개에 따른 방법을 실행하게 한다. 이런 방식으로, 이러한 연산자들은 이미지 데이터를 처리하기 위한 신경망의 계산 그래프에 있는 연산자의 특정 연산 규칙에 따라 최적화될 수 있으며, 계산해야 할 연산자의 수를 줄이거나 연산자 연산의 계산 복잡도를 낮출 수 있고, 그 결과 칩에서 이미지 데이터를 처리하기 위한 신경망의 실시간 실행 지연 시간(real-time running latency)을 단축할 수 있다."}
{"patent_id": "10-2025-7001282", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이제 출원의 특정 실시예에 대해 자세히 참조할 것이며, 그 예는 동봉된 도면에 도시된다. 본 출원은 특정 실시 예와 관련하여 설명되어 있지만, 본 출원을 설명된 실시예에 한정하려는 것은 아니라는 점을 이해해야 할 것이다. 오히려, 이는 첨부된 청구항에 의해 정의된 본 출원의 정신 및 범위 내에 포함되는 변경, 수정 및 균등물을 포괄하도록 의도된다. 여기에 설명된 방법 단계는 어떠한 기능 블록이나 기능적 배치에 의해서도 실현될 수 있 으며, 어떠한 기능 블록이나 기능적 배치도 물리적 개체나 논리적 개체, 또는 그 둘의 조합으로 실현될 수 있다 는 점에 유의한다. 본 공개의 다양한 실시예에서 공개된 기술적 솔루션을 이용하기 전에 사용자는 관련 법률, 규정에 따라 적절한 방식으로 본 공개에 포함된 개인정보의 종류, 이용 범위, 이용 시나리오 등을 고지받고 사용자의 승인을 받아야 함을 이해할 수 있다. 예를 들어, 사용자로부터 적극적인 요청을 받은 경우, 사용자가 요청한 연산을 실행하려면 사용자의 개인 정보 를 수집하고 사용해야 한다는 사실을 사용자에게 명확하게 상기시키는 알림 메시지가 사용자에게 전송된다. 따 라서 사용자는 신속한 정보에 따라 본 공개의 기술적 솔루션의 연산을 실행하는 전자 장치, 애플리케이션, 서버 또는 저장 매체와 같은 소프트웨어 또는 하드웨어에 개인 정보를 제공할지 여부를 자율적으로 선택할 수 있다. 선택 사항이지만 제한적이지 않은 구현으로, 사용자로부터 활성 요청을 수신한 경우 팝업 창을 통해 사용자에게 프롬프트 메시지를 보낼 수 있으며, 프롬프트 메시지는 텍스트로 표시될 수 있다. 또한, 팝업 창(pop-up window)은 사용자가 개인 정보를 전자 장치에 제공하는 것에 대해 \"동의\" 또는 \"동의하지 않음\"을 선택할 수 있 는 선택 제어를 수반할 수도 있다. 위에 기술된 사용자 권한 부여 및 통지 프로세스는 단지 예시일 뿐이며, 본 공개의 구현에 대한 제한을 구성하 지 않는다는 점을 이해할 수 있으며, 관련 법률 및 규정을 충족하는 다른 방식도 본 공개의 구현에 적용될 수 있다. 기술적 솔루션에 관련된 데이터(데이터그 자체, 데이터의 취득 또는 사용을 포함하되 이에 국한되지 않음)는 해 당 법률, 규정 및 관련 규정의 요구 사항을 준수해야 함을 이해할 수 있다. 현재, 신경망이나 머신 러닝 시스템(machine learning system)은 텐서를 기본적인 데이터 구조로 사용한다. 텐 서 개념의 핵심은 텐서가 데이터 컨테이너라는 점에 있으며, 여기에 포함된 데이터는 거의 항상 수치 데이터이 므로 텐서는 숫자의 컨테이너이다. 텐서의 특정 숫자 값은 애플리케이션 데이터일 수 있으며, 예를 들어 이미지 데이터, 자연어 데이터 등이 있다. 예를 들어, 스칼라는 2, 3, 5와 같이 0축 텐서이다. 예를 들어, 특정 애플리케이션플리케이션 시나리오에서 이 미지 데이터는 다음과 같다: 예를 들어, 2는 이미지 데이터의 픽셀의 회색조 값을 나타내고, 예를 들어 3은 이 미지 데이터의 픽셀의 회색조 값을 나타내고, 예를 들어 5는 이미지 데이터의 픽셀의 회색조 값을 나타내며, 예 를 들어, 벡터는 1축 텐서, 즉 [0, 3, 20]이고, 행렬은 2축 텐서, 즉 [ ] 또는 [ [2,3], [1,5] ]이다. 예를 들어, 3축 텐서(예: a: (형태: (3, 2, 1)), [[[1],[2]],[[3],[4]],[[5],[6]]]), 4축 텐서 등이 또한 있을 수 있다. 이러한 텐서는, 예를 들어 이미지 데이터, 자연어 데이터 등 특정애플리케이션 시나리오에서 데이터를 표현하는 데 사용될 수 있다. 이러한 애플리케이션 데이터를 대상으로 하는 신경망 기능에는 이미지 인식(예: 이미지 데이터를 입력하여 이미지에 포함된 동물이 무엇인지 인식), 자연어 인식(예: 사용자의 언어를 입력하여 사용자의 말 의도를 인식, 예를 들어, 사용자가 음악 플레이어를 여는 목적으로 말하는지 여부 인식) 등을 포함 할 수 있다. 위에 설명된 애플리케이션 시나리오에 대한 인식 과정은 신경망이 다양한 입력 애플리케이션 데이터를 텐서로 수신하고 신경망을 통해 동일한 데이터를 계산함으로써 구현될 수 있다. 위에서 설명한 것처럼 신경망의 계산은 일련의 텐서 연산으로 구성될 수 있으며; 이러한 텐서 연산은 텐서의 여러 축에 대한 입력 데이터의 복잡한 기 하학적 변환이 될 수 있다. 이러한 텐서 연산은 연산자라고 부를 수 있으며, 신경망 계산은 계산 그래프로 변환 될 수 있으며; 여기서 계산 그래프는 복수의 연산자를 가지며, 복수의 연산자는 각 연산자의 계산 간의 종속 관 계를 나타내는 에지로 연결될 수 있다. 연산자 유형은 활성화-클래스 연산자(예: Relu 연산자, 시그모이드 연산자, Tan 연산자); 2-텐서 계산 클래스 연산자(예: BiasAdd 연산자(바이어스 연산 추가를 위해), MatMul 연산자(행렬 곱셈), Axpy 연산자(벡터 합));다중-텐서 계산-클래스 연산자(예: EltwiseOp 연산자(다수의 텐서의 해당 위치에 있는 요소의 곱셈, 덧셈 및 최 대값을 취하는 연산 중 하나); 정규화-클래스 연산자(예: BatchNorm 연산자(신경망의 학습 수렴 속도를 가속화 하기 위한 것), LRN 연산자(즉, 로컬 응답 정규화), SsdNormalize 연산자(일회성 정규화 범위를 제한하기 위한 것); 특징-추출-클래스 연산자(컨볼루션 연산자(영역별 특징 값 추출), 완전 연결 연산자(전체 입력을 특징 맵 으로 사용하여 특징 추출), 상관 연산자(Correlation operator), 디컨볼루션 연산자(DeConvolution operator) (연결성/패턴을 유지하면서 저축 공간을 고축 공간으로 매핑하기 위한 것), 딥컨볼루션 연산자(DepConvolution operator)(단계별 계산 방법을 사용하여 일반적인 3D 커널의 계산을 완료하기 위한 것); 과적합 방지 클래스 연 산자(예: 풀링 연산자(Pooling operator)(입력 이미지를 여러 개의 직사각형 영역으로 분할하고 각 영역에 대한 최대값 또는 평균값을 출력하기 위한 것) 하위 지역), 평균 연산자(평균값만을 취하는 함수를 갖는 슬라이딩 윈 도우 연산자) 축 변환 클래스 연산자(예: 플래튼 연산자(Flatten operator)(입력 텐서에서 시작 축에서 끝 축으 로 하나의 축으로 병합), 재성형 연산자(입력 텐서 설명을 새 형태로 변환), FreespaceExtract 연산자(다른 축 은 변경하지 않고 h 축을 1로 변경하여 h의 샘플링을 완료, h는 양의 정수), 팩 연산자(Pack operator)(R 축의 텐서 어레이(tensor array)를 R+1 축의 텐서로 변환), 패드 연산자(Pad operator)(데이터 확장), 퍼뮤트 연산 자(Permute operator)(텐서의 입력 축 순서를 조정),ShuffleChannel(C축 정렬을 조정), 타이틀 연산자(Title operator)(각 축에서 지정된 횟수만큼 입력 데이터를 복사하여 출력 데이터를 생성), 전치 연산자(transpose operator)(텐서에서 값의 정렬 순서를 전치, 변경), 재성형 연산(reshape operator)(텐서를 다른 형태 의 텐서 로 변환), 브로드캐스트 연산자(broadcast operator)(입력 텐서를 다른 텐서로 확장), 수집 연산자(gather operator), 역방향 연산자(reverse operator), 컨캣 연산자(concat operator)(복수의 연산자를 연결하는 경 우), 캐스트 연산자(cast operator) 등을 포함할 수 있다. 또한, 사용자는 일부 연산자를 사용자 정의할 수도 있다. 연산자 이름과 특정 연산의 종류가 너무 많으므로, 여기서는 모든 연산자의 종류와 이름, 그리고 해당 연 산을 하나하나 예시하지 않겠다. 기존 기술에서는 신경망의 계산 그래프를 얻은 후, 이러한 연산자를 계산 그래프에 제공된 연산자와 연산자 사 이의 에지에 따라 순차적으로 연산하여 최종 계산 결과를 얻는 것이 일반적이었다. 그러나, 각 연산자를 계산하 는 데는 어느 정도 시간이 걸리며, 기존 기술에서는 이러한 연산자가 해당 연산자의 연산 속도를 가속화하고 연 산자의 연산 시간을 줄이도록 최적화되어 있지 않다. 이미지 데이터를 처리하기 위한 신경망의 계산 그래프에서 연산자를 연구할 때, 특정 연산 내용으로 인해 일부 연산자 자체, 또는 상향 또는 아래로 시프트된 연산자는 다른 연산자의 연산과 병합되거나 상쇄될 수 있으며, 이를 통해 이들 연산자를 최적화하고, 계산해야 할 연산자 수를 줄이거나 연산자 연산의 계산 복잡도를 낮추고, 예를 들어 칩에서 이미지 데이터를 처리하기 위한 신경망의 실시간 실행 지연 시간을 단축할 수 있다. 또한, 출 원인이 개발한 인공지능 칩의 특정 하드웨어 판독 기능을 결합하여, 최적화 전에 이들 연산자의 계산 결과와 계 산 결과가 일관성을 유지하도록 보장하는 동시에, 계산해야 할 연산자의 수를 줄이거나 연산자 연산의 계산 복 잡도를 줄일 수 있다. 이러한 최적화는 계산 그래프와 같은 높은 수준의 의미 표현을 기반으로 수행되므로 명령 어 수준에서 복잡하고 지루한 최적화 작업을 피할 수 있으며 최적화 가능한 시나리오를 보다 보편화할 수 있다. 도 1은 본 개시의 구현예에 따른 이미지 데이터 처리 및 인식에 적용된 신경망의 계산 그래프의 예시적 다이어 그램을 나타낸다. 예를 들어, 이미지 데이터(예: 픽셀의 색도 값)를 수반하는 텐서는 도 1에 표시된 예시적인 계산 그래프에 입력 된다. 계산 그래프는 독자의 탐색 편의를 위해 본 공개의 구현에 따른 일부 연산자만을 보여준다. 계산 그래프 의 연산 과정은: 먼저 텐서에 전치 연산자 계산을 적용하고, 그다음 한 브랜치(branch)에 재성형 연산자 계산을 적용하고, 다른 브랜치에 완전 연결 연산자 계산을 적용한다. 텐서는 먼저 전치 연산자에 입력되고, 전치 연산자는 전치 연산자에 입력된 입력 텐서의 수치 값을 변경하지 않 는 텐서 연산이라고 가정한다. 전치 연산자는 어레이(array)의 축 레이아웃 순서를 변경하는 역할을 한다. 예를 들어, 2축 어레이를 고려하면, 두 축의 순서를 바꿔치는 것은 단순히 행렬 전치일 뿐이다. 전치 연산자는 더 많 은 축의 경우에 적용될 수 있다. 전치 연산자의 입력 파라미터는 출력 어레이의 축 레이아웃 순서이며, 순서 번 호 0에서 카운트한다. 예를 들어, 전치 연산자의 입력 텐서는 2축 행렬 [[1, 2, 3], [4, 5, 6], [7, 8, 9], [10, 11, 12]]이거나, 으로 표현되며, 예를 들어, 이미지 데이터를 4*3으로 나타내는 2축 행렬과 같이 표현된다고 가정한다. 전치(Transpose)([[1, 2, 3], [4, 5, 6], [7, 8, 9], [10, 11, 12]])는 전치를 나타내며, 즉 2축 행렬을 [[1, 4, 7, 10], [2, 5, 8, 11], [3, 6, 9, 12]]로 변경하거나, 또는 와 같이 3*4로 표현된 행렬로 변경하는 것이다. 보시다시피, 전치 연산자는 축 레이아웃 순서를 변경하고, 즉 텐서의 형태를 변경하지만 텐서의 숫자 값은 변경 하지 않으며, 예를 들어, 숫자 값은 여전히 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12이다. 물론, 전치 연산자는 텐서의 형태를 변경하지 않고(예: 3*3 행렬은 전치 후에도 여전히 3*3 행렬임) 숫자 값의 레이아웃 순서를 변경 할 수도 있고 텐서의 숫자 값을 변경할 수도 있다. 그러면, 전치 연산자 연산을 거치는 위에서 설명한 텐서 는 두 브랜치로 나뉜다. 한 브랜치는 재 성형 연산 계산을 받고, 다른 브랜치는 완전 연결 연산자 계산을 받는다. 재성형 연산의 특정 연산은 텐서의 형태 속성을 변경하는 것으로, m*n 크기의 행렬 a를 i*j 크기의 행렬 b로 배 치할 수 있다. 예를 들어, 재성형 연산(재성형(A, 2, 6), 여기서 A는 입력 텐서)는 위에 설명된 텐서 의 형태를 3*4에서 2*6으로 변경한다. 따라서 재성형 연산를 통해 얻은 출력 텐서는 예를 들어 와 같다. 재성형 연산자는 텐서의 숫자 값을 변경하지 않고 텐서의 형태 만 변경하며, 예를 들어, 숫자 값은 여전히 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12임을 볼 수 있다. 완전 연결 연산자(Fully connected operator)(완전한 연결 연산자(Full Connection operator)라고도 함)는 특 수한 컨볼루셔널 계층(convolutional layer) 또는 텐서의 곱으로 간주될 수 있으며, 여기서 전체 텐서 입력은 특징 추출 연산(feature extraction operation)을 위한 특징 맵(feature map) 역할을 한다. 즉, 하나의 특징 공간(feature space)이 다른 특징 공간으로 선형적으로 변환되고, 출력 텐서는 입력 텐서의 가중 합이다. 예를 들어, 완전 연결 연산자는, 예를 들어 와 같은, 4*1 크기의 가중치 행렬 x로 곱해진, 입력 텐서(전치 연산자 의 출력 텐서) 행렬을 가진다. 지금까지, 도 1에 도시된 바와 같이 이미지 데이터 처리 및 인식에 적용되는 신경망의 계산 그래프의 구체적인 연산 과정을 소개하였다. 도 1의 예를 기반으로 보면, 전치 연산자는 축 레이아웃 순서를 변경하고, 즉 텐서의 형태를 변경하지만 텐서의 숫자 값은 변경하지 않으며, 예를 들어, 숫자 값은 여전히 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12이다. 계산 그래프에는 재성형 연산와 완전 연결 연산자라는 두 개의 후속 연산자가 있지만, 전치 연산자에서 재성형 연산 와 완전 연결 연산자로 출력되는 텐서의 숫자 값은 전치 연산자의 입력 텐서의 숫자 값과 동일하다. 따라서, 이 들 연산자의 실행 속도와 실행 시간을 최적화하기 위해 계산 그래프의 전치 연산자 등의 연산자에 어떤 변경을 가하는 것을 고려해 볼 수 있다. 도 2는 본 개시의 구현에 따른 칩을 통해 신경망 모듈의 컴퓨팅 파워를 최적화하는 방법을 나타낸다. 도 2에 도시된 바와 같이, 칩을 통한 신경망 모듈(neural network module)의 컴퓨팅 파워를 최적화하기 위한 방 법은: 단계 201: 칩에 의해, 각각의 연산자를 갖는 신경망 모듈의 계산 그래프(computational graph)를 획 득하는 단계 - 여기서 신경망 모듈은 애플리케이션 데이터의 프로세스 출력 결과(process output result)를 획 득하기 위해 애플리케이션 데이터(application data)를 수신함 -; 단계 202에서, 칩에 의해, 계산 그래프의 제1 연산자(first operator)에 대해 각 연산자의 특정 연산(specific operation)에 따라, 계산 그래프에서 제1 연 산자의 위치를 후속 연산자(subsequent operator) 또는 선행 연산자(preceding operator)로 바꿔치고 (counterchanging), 제1 연산자를 두 개 이상의 동일한 연산자로 분할하고(splitting), 및 서로를 상쇄할 수 있 는 복수의 제1 연산자를 삽입하는(inserting) 적어도 하나의 조정을 적어도 한 번 수행하는(performing) 단계 - 여기서 제1 연산자는 입력 텐서(input tensor)에서 수치 값(numerical values)을 변경하지 않는 텐서 연산(tensor operation)임 -; 단계 203: 칩에 의해, 각 연산자의 특정 연산에 따라 계산 그래프에서 조정된 제1 연 산자(adjusted first operator)에 인접한 제2 연산자(second operator)를 결정하는(determining) 단계 - 여기 서 조정된 제1 연산자의 연산과 제2 연산자의 연산은 연산 결과에 영향을 미치지 않고 병합되거나 상쇄될 수 있 음 -; 및 칩에 의해, 조정된 제1 연산자와 제2 연산자에 대해 병합(merge) 또는 상쇄(cancellation)를 수행하고, 병합 또는 상쇄 후에 계산 그래프에서 각 연산자의 연산을 실행하는(executing) 단계를 포함한다. 도 1의 예를 바탕으로, 위에 기술된 방법의 구체적인 과정을 도 3a~3c와 함께 설명하겠다. 도 3a는 본 개 시의 구현에 따른 복수의 연산자를 포함하는 원래의 계산 그래프의 개략도를 나타낸다. 도 3b는 본 개시의 구현 에 따른 계산 그래프에서 제1 연산자를 두 개 이상의 동일한 연산자로 분할하는 개략도를 나타낸다. 도 3c는 본 개시의 구현에 따라 제1 연산자를 조정한 후의 최적화된 계산 그래프의 개략도를 나타낸다. 먼저, 단계 201에서, 칩에 의해, 각각의 연산자를 갖는 신경망 모듈의 계산 그래프를 획득하고, 애플리케이션 데이터의 프로세스 출력 결과를 획득하기 위해 신경망 모듈은 애플리케이션 데이터를 수신한다. 예를 들어, 칩 은, 도 3a에서 보이는 것처럼, 예를 들어 전치 연산자, 재성형 연산자, 완전 연결 연산자 등의 각각의 연산자를 갖는 신경망 모듈의 계산 그래프를 획득한다. 신경망 모듈은 이미지 데이터의 프로세스 출력 결과를 획득하기 위해 이미지 데이터를 수신한다. 단계 202에서, 칩에 의해, 계산 그래프의 제1 연산자(first operator)에 대해 각 연산자의 특정 연산(specific operation)에 따라, 계산 그래프에서 제1 연산자의 위치를 후속 연산자(subsequent operator) 또는 선행 연산자 (preceding operator)로 바꿔치고(counterchanging), 제1 연산자를 두 개 이상의 동일한 연산자로 분할하고 (splitting), 및 서로를 상쇄할 수 있는 복수의 제1 연산자를 삽입하는(inserting) 적어도 하나의 조정을 적어 도 한 번 수행한다. 제1 연산자는 입력 텐서(input tensor)에서 수치 값(numerical values)을 변경하지 않는 텐서 연산(tensor operation)이다. 예를 들어, 입력 텐서의 숫자 값을 변경하지 않는 텐서 연산은 텐서의 형태 또는 레이아웃 순서를 변경하는 텐서 연산이 될 수 있다. 도 3a에서 보는 것 처럼, 전치 연산자는 입력 텐서의 수치 값을 변경하지 않고 텐서 연산의 제1 연산자로 결정된다. 한 실시예에서, 제1 연산자가 분기된 두 개 이상의 후속 연산자(subsequent operators)를 갖거나 두 개 이상의 분기된 선행 연산자(preceding operators)를 갖는 경우(예: 제1 연산자 뒤에 두 개 이상의 후속 연산자가 오거 나, 제1 연산자가 분기된 두 개 이상의 선행 연산자를 갖거나, 제1 연산자가 하나 이상의 후속 연산자와 하나 이상의 선행 연산자를 갖는 경우), 제1 연산자를 두 개 이상의 동일한 연산자로 분할되어 각 제1 연산자가 하나 의 후속 연산자 또는 하나의 선행 연산자와 일대일로 대응하도록 한다. 도 3b와 같이, 전치 연산자 뒤에는 두 개의 후속 연산자, 즉 재성형 연산와 완전 연결 연산자가 분기되어 따르 므로, 전치 연산자는 두 개의 동일한 전치 연산자로 분할되어, 각 전치 연산자는 후속 연산자와 일대일 대응하 며, 즉, 하나의 전치 연산자는 후속 재성형 연산자에 대응하고, 다른 전치 연산자는 후속 완전 연결 연산자에 대응한다. 즉, 원래, 입력 텐서는 먼저 전치 연산자의 한 연산을 거치고, 그런 다음 전치 연산자의 출력 텐서는 두 개의 출력 텐서를 획득하기 위해 각각 재성형 연산의 연산과 완전 연결 연산자의 연산을 거친 후, 계속해서 후속 연산자의 연산을 거친다. 조정 후, 입력 텐서는 전치 연산자의 한 가지 연산만 받고, 그 다음에 재성형 연 산의 연산을 거치며, 다음으로, 입력 텐서는 전치 연산자의 또 다른 연산을 거치고 그 다음에 완전 연결 연산자 의 연산을 거친다. 물론, 이때 추가로 조정이 이루어질 수도 있으며; 예를 들어, 도 3c에서, 좌측 브랜치의 전치 연산자는 후속 재 성형 연산와 위치가 바꿔치게 될 수 있으므로, 입력 텐서는 먼저 재성형 연산의 연산을 거치고, 그 다음에 전치 연산자의 연산을 거치게 된다. 여기서, 전치 연산자의 연산은 입력 텐서의 수치 값을 변경하지 않는 텐서 연산 이기 때문에, 전치 연산자 후에 있는 각 연산자의 연산은 최종 연산 결과를 변경하지 않는다. 이런 식으로, 전 치 연산자의 위치를 그에 뒤따른 재성형 연산자로 바꿔치게 되면, 전치 연산자가 위치를 바꿔친 후에(여기서는 다운시프트) 전치 연산자의 선행 연산자나 후속 연산자(여기서는 후속 연산자)와 병합되거나 상쇄될 수 있는지 고려할 수 있다. 도 3a~도 3c에 표시된 예에서, 분할된 전치 연산자는 왼쪽 브랜치에서 아래로 이동되며; 그러나, 실제로, 전치 연산자는 각 브랜치에서 위로 시프트되거나 아래로 시프트될 수 있으며, 하나의 전치 연산자가 브랜치 수에 따 라 전치 연산자로 분할되고 분할된 전치 연산자의 수는 브랜치 수와 같으므로, 전치 연산자가 다른 연산자와 병 합되거나 상쇄될 기회를 찾기 위해 각 브랜치에서 위로 또는 아래로 시프트될 수 있다. 단계 203에서, 칩에 의해, 각 연산자의 특정 연산에 따라 계산 그래프에서 조정된 제1 연산자(adjusted first operator)에 인접한 제2 연산자(second operator)를 결정하고, 및 여기서 조정된 제1 연산자의 연산과 제2 연산 자의 연산은 연산 결과에 영향을 미치지 않고 병합되거나 상쇄될 수 있다. 칩은 각 연산자의 구체적인 연산에 따라 계산 그래프에서 분할 전치 연산자에 인접한 완전 연결 연산자를 결정 하고, 분할 전치 연산자의 연산과 완전 연결 연산자의 연산은 연산 결과에 영향을 미치지 않고 병합되거나 상쇄 될 수 있다고 가정한다. 일 실시예에서, 병합 또는 상쇄 전의 제2 연산자의 연산이 조정된 제1 연산자의 출력 텐서에 있는 숫자 값에 수 행된 제2 연산자 연산인 경우, 병합 또는 상쇄 후에 조정된 제1 연산자와 제2 연산자를 제4 연산자에 병합한다. 제4 연산자의 연산은: 칩에 의해, 조정된 제1 연산자 자체의 텐서 연산을 대체하기 위해, 조정된 제1 연산자의 입력 텐서의 수치 값을 미리 정해진 순서로 판독하는(reading) 단계 - 여기서 미리 정해진 순서는 조정된 제1 연산자 자체의 텐서 연산에 따라 결정됨 -; 그리고 제2 연산자의 연산에 따라 칩에 의해 판독한 수치 값에 대해 제2 연산자 연산을 수행하는(performing) 단계를 포함한다. 도 3c의 오른쪽 가지에 표시된 것처럼, 분할된 전치 연산자와 그에 따른 완전 연결 연산자는 전치 병합 완전 연 결 연산자를 형성하기 위해 병합될 수 있다. 즉, 전치 연산자는 실제로 텐서의 전치이기 때문에, 원래는, 입력 텐서에 먼저 전치 연산자를 적용하여 전치시키고, 그런 다음 전치된 텐서는 완전 연결 연산자의 연산에 적용되 며; 하지만 병합 후에, 칩은 입력 텐서의 해당 숫자 값을 전치 순서로 판독하여서 바로 완전 연결 연산자의 연 산을 수행한다. 이는 전치 연산자가 텐서의 해당 숫자 값을 변경하지 않고 입력 텐서를 전치시키고, 단지 행이 나 열에서의 위치만 변경하기 때문이다. 원래의 전치 연산자는, 예를 들어 과 같은 입력 텐서, 출력 텐서 를 갖는다. 예를 들 어, 완전 연결 연산자는, 예를 들어 와 같은, 4*1 크기의 가중치 행렬 x로 곱해진, 입력 텐서(전치 연산자의 출력 텐서) 행렬을 가지며, 즉, 각각 전치 행렬의 행을 판독하는데, 제1 행은 가중치 행렬 x에 곱해지고, 제2 행은 가중치 행렬 x에 곱해지고, 마지막으로 제3 행은 가중치 행렬 x에 곱해진다. 구체적으로, 1 을 40으로 곱한 것, 4를 50으로 곱한 것, 7을 60으로 곱한 것, 10을 70으로 곱한 것을 더한 것은 완전 연결 연 산자의 결과 텐서의 제1 값이되며; 2를 40으로 곱한 것, 5를 50으로 곱한 것, 8을 60으로 곱한 것, 11을 70으로 곱한 것을 더한 것은 완전 연결 연산자의 결과 텐서의 제2 값이 되며, 그리고 3을 40으로 곱한 것, 6을 50으로 곱한 것, 9를 60으로 곱한 것, 12를 70으로 곱한 것을 더한 것은 완전 연결 연산자의 결과 텐서의 제3 값이 된 다. 그러면 전치 병합된 완전 연결 연산자의 입력 텐서는 이며, 즉, 전치하기 전의 행렬이며; 반면 전 치 병합된 완전 연결 연산자는 행렬 곱셈을 위해 입력 텐서의 제1 열로부터 숫자 값을 직접 판독할 수 있고, 그 런 다음 제2 열을 판독하고 제3 열을 판독하며, 즉 또한, 1을 40으로 곱한 것, 4를 50으로 곱한 것, 7을 60으로 곱한 것, 10을 70으로 곱한 것을 더한 것은 완전 연결 연산자의 결과 텐서의 제1 값이되며; 2를 40으로 곱한 것, 5를 50으로 곱한 것, 8을 60으로 곱한 것, 11을 70으로 곱한 것을 더한 것은 완전 연결 연산자의 결과 텐서 의 제2 값이 되며, 그리고 3을 40으로 곱한 것, 6을 50으로 곱한 것, 9를 60으로 곱한 것, 12를 70으로 곱한 것 을 더한 것은 완전 연결 연산자의 결과 텐서의 제3 값이 된다. 선택적으로 판독의 연산(전치된 행렬의 제1 행, 제2 행, 제3 행을 원래 판독하던 것에서 전치되기 전 행렬의 제 1 열, 제2 열, 제3 열을 판독하는 것으로 변경하는 연산)은 칩에 의한 판독 연산을 통해 완료될 수 있다. 즉, 칩은 분할 전치 연산자의 텐서 연산을그 자체로 대체하기 위해 전치 병합된 완전 연결 연산자의 입력 텐서에 있 는 숫자 값을 미리 정해진 순서대로 판독한다. 이 예에서, 입력 텐서의 숫자 값을 제1 열, 제2 열, 제3 열의 미 리 정해진 순서로 판독하는 칩의 하드웨어 연산은 전치 연산자 그 자체의 전치 연산을 대체할 수 있다. 미리 정 해진 순서는 분할 전치 연산자 자체의 텐서 연산에 따라 결정되는데, 즉, 여기서 전치라면 미리 정해진 순서는전치의 효과를 달성해야 한다. 일 실시예에서, 조정된 제1 연산자의 입력 텐서에서 숫자 값을 미리 정해진 순서에 따라 판독하는 칩은 소프트 웨어를 통해 칩 판독에 대한 스트라이드, 오프셋 및 루프 카운트 중 적어도 하나를 설정하여 구현될 수 있다. 이런 방식으로 사용자는 판독 순서를 변경하기 위해 소프트웨어를 통해 칩 판독의 스트라이드(stride), 오프셋 (offset), 루프 카운트(loop count) 중 적어도 하나를 유연하게 설정하고, 이를 통해 일부 연산자 자체의 텐서 연산을 칩의 하드웨어 판독 연산으로 대체할 수 있다. 칩의 하드웨어 판독 연산은 정적 램(SRAM)에서 스트라이드, 오프셋 및 루프 카운트 중 적어도 하나를 판독/기록 하기 위해 소프트웨어를 통해 일부 정적 램(SRAM) 제어기에 의해 특별히 구성될 수 있다. 예를 들어, SRAM 의 잔차의 입력 텐서에 관하여, 이는 SRAM에 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12로 연속적으 로 저장되고, SRAM 제어기는 소프트웨어를 통해 스트라이드, 오프셋 및 루프 카운트를 구성하며, 예를 들어, 스 트라이드를 3(즉, 각 판독에서 다음 판독으로 몇 자릿수가 스트라이드되는지)으로 구성하고; 오프셋을 0으로 구 성하고 각 루프 후에 1을 더하며(즉, 각 루프를 판독한 후 다음 판독 루프를 시작할 위치); 그리고 루프 카운트 를 3(즉, 3개의 판독 루프)으로 구성하여 판독 순서가 더 이상 원래의 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12 가 아니라 1, 4, 7, 10, 2, 5, 8, 11, 3, 6, 9, 12로 변경된다. 여기서 오프셋이 기본적으로 특정 수치 값이고, 루프 횟수도 기본적으로 특정 수치 값이면, 소프트웨어 구성 파라미터는 판독의 스트라이드만 될 수 있 다는 점에 유의하라. 따라서, SRAM 제어기는 소프트웨어로 판독의 스트라이드, 오프셋 및 루프 카운트 중 적어 도 하나를 구성할 수 있으며, 여기서는 이에 대한 예를 들지 않는다. 그런 다음, 칩에 의해 판독한 숫자 값은, 전치 병합 완전 연결 연산자의 연산을 구현하기 위해, 완전 연결 연산자의 후속 연산에 따라 완전 연결 연산자 의 행렬 곱셈 연산을 순차적으로 거쳐간다. 따라서, 이러한 병합은 최종 연산 결과를 변경하지 않으면서 전치 연산자를 별도로 계산하는 데 필요한 시간을 없애 시간을 절약할 수 있다. 단계 204에서, 칩에 의해, 조정된 제1 연산자와 제2 연산자에 대해 병합(merge) 또는 상쇄(cancellation)를 수 행하고, 병합 또는 상쇄 후에 계산 그래프에서 각 연산자의 연산을 실행한다. 여기에서, 계산 그래프에서 연산자를 조정, 병합 또는 상쇄한 후, 칩은 최적화된 전체 계산 그래프에서 해당 연 산자의 연산을 수행할 수 있다. 이런 방식으로, 이러한 연산자들은 이미지 데이터를 처리하기 위한 신경망의 계산 그래프에 있는 연산자의 특정 연산 규칙에 따라 최적화될 수 있으며, 계산해야 할 연산자의 수를 줄이거나 연산자 연산의 계산 복잡도를 낮출 수 있고, 그렇게 함으로써 칩에서 이미지 데이터를 처리하기 위한 신경망의 실시간 실행 지연 시간을 단축할 수 있다. 일 실시예에서, 두 개 이상의 동일한 제1 연산자의 후속 연산자가 동일한 연산자인 경우, 두 개 이상의 동일한 제1 연산자는 하나의 연산자로 통합된다. 도 4는 본 발명의 실시 예에 따라 두 개 이상의 동일한 제1 연산자를 하나의 연산자로 통합하고 계산 그래프에 서 연산자를 다운시프트(down-shifting)하는 개략도를 나타낸다. 도 4에서 보는 바와 같이, 두 개 이상의 동일한 제1 연산자의 후속 연산자가 동일한 연산자인 경우, 세 개의 전 치 연산자의 후속 연산자는 동일한 SomeOp 연산자(특정 연산자를 말하며, 여기서는 이에 국한되지 않음)가 되며, 즉, SomeOp 연산자의 여러 선행 연산자가 모두 동일한 전치 연산자인 경우, SomeOp 연산자의 세 선행 전 치 연산자를 하나의 전치 연산자로 통합할 수 있다. 도 4에 표시되지 않았지만, 세 개의 선행 연산자의 세 가지 분기 각각에 앞서는 연산자가 세 개 더 있을 수 있다는 점에 유의해야 한다. 통합된 전치 연산자는 다른 연산자와 병합되거나 상쇄될 기회를 찾기 위해 위로 시프트(즉, 선행 연산자와의 위 치가 반대 방향으로 변경)되거나 아래로 시프트(즉, 후속 연산자와의 위치가 반대 방향으로 변경)될 수 있다. 도 4의 예에서, SomeOp 연산자는, 중복된 전치 연산자를 줄이거나 후속 병합 또는 대응 연산(counteract operations)의 가능성을 생성하기 위해, 후속 연산자와 병합하거나 상쇄되는 SomeOp 연산자(미도시)의 후속 연 산자로 전치 연산자를 아래로 이동할 수 있다고 가정한다. 위의 예에서, 전치 연산자가 아래로 이동되었지만, 실제로는, 최적화 기회를 찾기 위해 전치 연산자가 위로 이 동될 수도 있으며, 즉, 계산 복잡성을 줄이기 위해 인접한 연산자와 병합하거나 상쇄할 수 있는지 여부를 파악 하는 것이다. 예를 들어, 위로 시프트된 전치 연산자는 다른 인접한 전치 연산자의 역연산으로 나타나므로 두연산자는 상쇄될 수 있다. 위의 모든 예에서, 전치 연산자는 한 번 다운시프트되지만, 전치 연산자는 최적화 기회를 찾기 위해 여러 번 업 시프트되거나 다운시프트될 수도 있으며, 즉, 계산 복잡성을 줄이기 위해 인접 연산자와 병합되거나 상쇄될 수 있다. 도 5는 본 발명의 구현에 따른 계산 그래프에서 전치 연산자(Transpose operator)를 연속적으로 여러 번 다운시 프트하고 이를 완전 연결 연산자(Fully connected operator)와 병합하는 개략도를 나타낸다. 도 5에서 보듯이, 전치 연산자는 2번 연속적으로 다운시프트(즉, 이후의 SomeOp 연산자와 위치가 2번 바뀌는 것)된 후 완전 연결 연산자와 병합된다. 위에서 설명한 대로, 이러한 병합은 칩의 하드웨어 판독 동작을 통해 구현될 수도 있으며, 예를 들어, 일부 정적 램(SRAM) 제어기는, 전치 연산자와 동일한 의미를 구현하기 위해, 즉 전치 효과를 달성하기 위해, 정적 램(SRAM)에서 판독/기록을 위한 스트라이드, 오프셋 및 루프 카운트 중 적 어도 하나를 구성할 수 있다. 이런 식으로, 전치 연산자는 전치 병합 완전 연결 연산자를 형성하기 위해 계속해 서 2번 다운시프트되어 인접한 후속 완전 연결 연산자와 병합될 수 있다. 전치 연산자와 병합될 수 있는 완전 연결 연산자 외에도, 최적화를 위해 전치 연산자와 병합을 지원하는 다른 연산자로는 재성형 연산자, 브로드캐스트 연산자, 수집 연산자, 역방향 연산자, 컨캣 연산자, 플래튼 연산자, 캐스트 연산자, 요소별 이진 연산자(elementwise 바이너리 operator), 배치 완전 연결 연산자(batch fully connected operator), 컨볼루션 연산자, 상쇄는 불가능하지만 병합은 가능한 기타 전치 연산자가 있을 수 있다. 한 실시예에서, 병합 또는 상쇄 전에 조정된 제1 연산자와 제2 연산자가 서로 역연산인 경우, 제1 연산자와 제2 연산자는 서로를 상쇄한다. 도 6은 본 발명의 구현에 따른 계산 그래프에서 제1 연산자와 제2 연산자의 상쇄에 대한 개략도를 나타낸다. 도 6에서 보는 바와 같이, 왼쪽의 원래 계산 그래프에서 위 전치 연산자와 아래 전치 연산자는 서로 역연산이며, 예를 들어, 위 전치 연산자는 3*4 행렬로부터 전치된 4*3 행렬이고, 아래 전치 연산자는 4*3 행렬 로부터 전치된 3*4 행렬이며, 이 경우 두 전치 연산자는 서로 역연산임을 가정한다. 원래의 계산 그래프에서는 두 개의 전치 연산자가 서로 인접하지 않으므로 두 연산자는 직접 상쇄될 수 없다. 따라서, 위의 전치 연산자는 계속해서 두 번 아래로 이동하여(후속 연산자와 위치가 2번 바뀌어) 아래의 전치 연산자와 인접하게 되고, 그런 다음 두 개의 전치 연산자는 서로 상쇄되어 삭제될 수 있다. 이런 방식으로, 계산해야 할 연산자의 수나 연산자 연산의 계산 복잡도가 줄어들고, 그에 따라 칩에서 이미지 데이터를 처리하는 신경망의 실시간 실행 지연 시간이 단축된다. 한 실시예에서, 병합 또는 상쇄 이전에, 제2 연산자가 입력 텐서의 숫자 값을 변경하지 않는 텐서 연산인 경우, 병합 또는 상쇄 이후에, 조정된 제1 연산자와 제2 연산자는 제3 연산자로 병합되고, 제3 연산자의 텐서 연산은 조정된 제1 연산자의 텐서 연산과 제2 연산자의 텐서 연산을 모두 구현한다. 즉, 제1 연산자가 입력 텐서의 수치 값을 변경하지 않는 텐서 연산이고, 그에 인접한 제2 연산자도 입력 텐서의 수치 값을 변경하지 않는 텐서 연산인 경우, 둘은 동일한 연산도 아니고 서로 역연산도 아니지만, 서로 다른 모 드 또는 유형의 텐서 연산이다. 예를 들어, 제1 연산자는 전치 연산자, 재성형 연산자, 브로드캐스트 연산자, 수집 연산자, 역방향 연산자, 컨 캣 연산자 및 캐스트 연산자 중 적어도 하나일 수 있다. 제2 연산자는 또한 전치 연산자, 재성형 연산자, 브로 드캐스트 연산자, 수집 연산자, 역방향 연산자, 연결 연산자 및 캐스트 연산자 중 적어도 하나일 수 있다. 예를 들어, 제1 연산자는 전치 연산자이고, 제2 연산자도 전치 연산자이다. 하지만 두 개의 전치 연산자는 정확히 동 일한 연산도 아니고, 서로 역연산도 아니다. 도 7은 본 발명의 구현에 따른 계산 그래프에서 전치 연산자를 다운시프트한 다음, 인접한 전치 연산자와 병합 하여 하나의 전치 연산자로 만드는 개략도를 나타낸다. 도 7에 표시된 것처럼, 계산 그래프에서 먼저 전치 연산자가 아래로 이동한 후 인접한 전치 연산자를 찾으면 병 합될 수 있다. 따라서, 아래로 시프트된 전치 연산자는 하나의 병합된 전치 연산자를 형성하기 위해 인접한 전 치 연산자와 병합된다. 전치 연산자의 연산은 모두 텐서의 형태를 바꾸는 것이므로, 병합된 전치 연산자는 아래 로 시프트된 전치 연산자의 텐서 연산과 그에 인접한 전치 연산자의 텐서 연산을 모두 구현하며, 즉, 전치 연산 자를 2번 사용하여 2개의 텐서 연산을 수행하여 최종 결과를 구현하는 대신, 전치 연산자를 1번만 사용하여 텐서의 형태를 최종 결과로 변경한다. 위의 예는 전치 연산자는 다른 연산자와 병합, 상쇄 등이 가능한 제1 연산자 역할을 한다는 것을 알 수 있으며; 그리고 제1 연산자 역할을 하는 다른 연산자들은 아래에서 소개한다. 한 실시예에서, 제1 연산자는 재성형 연산자일 수 있다. 재성형 연산자는 텐서를 다른 형태 의 텐서로 변환한다. 재성형 연산자의 연산은 입력 텐서의 수치 값을 변경하지 않는 텐서 연산임을 알 수 있다. 도 8a는 본 발명의 구현에 따른 계산 그래프에서 상호 역연산(inverse operations)인 다른 재성형 연산자 (Reshape operator)로 재성형 연산자를 상쇄하는 개략도를 나타낸다. 도 8a에 표시된 것처럼, 왼쪽의 원래 계산 그래프에서 위의 재성형 연산자와 아래의 재성형 연산자는 서로 역연 산이며, 예를 들어, 위의 재성형 연산자의 연산은 3*4 행렬로부터 2*6 행렬로 형태를 변경하고, 아래의 재성형 연산자의 연산은 2*6 행렬에서 3*4 행렬로 형태를 변경하는 것을 가정한다. 두 개의 재성형 연산자는 역연산자 이다. 원래의 계산 그래프에서, 두 개의 재성형 연산자가 서로 인접하지 않으므로 두 연산자를 직접 상쇄할 수 없다. 따라서, 위의 재성형 연산자는 계속해서 2번 아래로 시프트하여(후속 연산자와 위치가 2번 바뀌어) 아래 의 재성형 연산자와 인접하게 되고, 그런 다음 두 재성형 연산자는 상호 상쇄되고 삭제될 수 있다. 이런 방식으로, 계산해야 할 연산자의 수나 연산자 연산의 계산 복잡도가 줄어들고, 그에 따라 칩에서 이미지 데이터를 처리하는 신경망의 실시간 실행 지연 시간이 단축된다. 도 8b는 본 발명의 구현에 따른 계산 그래프에서 하나의 재성형 연산자를 다운시프트한 다음, 이를 인접한 재성 형 연산자와 병합하여 하나의 재성형 연산자로 만드는 개략도를 나타낸다. 도 8b에 표시된 것처럼, 계산 그래프에서 먼저 1개의 재성형 연산자가 다운시프트되고 인접한 재성형 연산자를 찾으면 병합될 수 있다. 따라서, 아래로 시프트된 재성형 연산자는 하나의 병합된 재성형 연산자를 형성하기 위 해 인접한 재성형 연산자와 병합된다. 재성형 연산자의 연산은 모두 텐서의 형태를 바꾸는 것에 관한 것이므로, 병합된 재성형 연산자는 아래로 시프트된 재성형 연산자의 텐서 연산과 그에 인접한 재성형 연산자의 텐서 연산 을 모두 구현하며, 즉, 재성형 연산자를 2번 사용하여 2개의 텐서 연산을 수행하여 최종 결과를 구현하는 대신, 연산자를 1번만 사용하여 텐서의 형태를 최종 결과로 변경한다. 예를 들어, 위의 재성형 연산자의 연산이 3*4 행렬에서 2*6 행렬로 형태를 변경하고, 하부 재성형 연산자의 연 산이 2*6 행렬에서 6*2 행렬로 형태를 변경하는 경우, 병합된 재성형 연산자의 연산은 3*4 행렬에서 6*2 행렬로 형태를 변경할 수 있다. 물론, 위의 예는 재성형 연산자의 여러 최적화 모드를 보여 주지만 이에 국한되지는 않으며; 실제로 재성형 연 산자는 다른 연산자(제2 연산자)와 병합될 수도 있다. 입력 텐서의 수치 값을 변경하지 않는 텐서 연산이므로, 칩은 조정된 재성형 연산자 자체의 텐서 연산을 대체하기 위해 조정된 재성형 연산자의 입력 텐서의 수치 값을 미리 정해진 순서에 따라 판독하는데 사용될 수 있다. 한 실시예에서, 제1 연산자는 브로드캐스트 연산자일 수 있다. 브로드캐스트 연산자는 입력 텐서를 다른 텐서로 확장하며, 예를 들어, 형태가 A인 텐서를 형태가 B인 텐서로 확장하며, 여기서 A와 B는 축으로 표현된 텐서 형 태이다. 브로드캐스트 연산자의 연산은 입력 텐서의 숫자 값을 변경하지 않는 텐서 연산임을 알 수 있다. 도 9a는 본 개시의 구현에 따라 계산 그래프를 최적화하기 위해 하나의 브로드캐스트 연산자(Broadcast operator)를 두 개의 브로드캐스트 연산자로 분할하는 개략도를 나타낸다. 도 9a에 도시된 바와 같이, 브로드캐스트 연산자 뒤에는 재성형 연산자와 이진 연산자라는 두 개의 후속 연산자 가 따르므로, 브로드캐스트 연산자는 두 개의 동일한 브로드캐스트 연산자로 분할되어 각 브로드캐스트 연산자 는 후속 연산자와 일대일 대응하며, 즉, 하나의 브로드캐스트 연산자는 후속 재성형 연산자에 대응하고 다른 브 로드캐스트 연산자는 후속 이진 연산자에 대응한다. 즉, 원래, 입력 텐서는 먼저 브로드캐스트 연산자의 연산을 1번 거치고, 그런 다음 브로드캐스트 연산자의 출력 텐서는 각각 재성형 연산자의 연산과 이진 연산자의 연산을 거쳐 두 개의 출력 텐서를 얻은 후 계속해서 후속 연산자의 연산을 거치게 된다. 조정 후, 입력 텐서는 브로드 캐스트 연산자의 연산을 한 번 받고, 그다음 재성형 연산자의 연산을 거치며; 입력 텐서는 다시 브로드캐스트 연산자의 연산을 거치고, 그다음 이진 연산자의 연산을 거친다. 이진 연산자는 요소별 이진 연산자라고도 하며 입력 텐서의 숫자 값을 이진화한다. 물론, 이때 추가로 다른 조정이 이루어질 수도 있으며; 예를 들어, 도 9a에서 왼쪽 브랜치의 브로드캐스트 연산 자는 그에 뒤따르는 재성형 연산자와 위치가 반대 방향으로 바뀌어 입력 텐서가 먼저 재성형 연산자의 연산을 거친 다음 브로드캐스트 연산자의 연산을 거치게 될 수 있다. 여기서, 브로드캐스트 연산자의 연산은 입력 텐서 의 수치 값을 변경하지 않는 텐서 연산이므로, 브로드캐스트 연산자를 아래로 옮긴 후 각 연산자의 연산은 최종 연산 결과를 변경하지 않는다. 이런 식으로, 브로드캐스트 연산자의 위치를 후속 재성형 연산자와 바꿔치기 하 면 위치가 바꿔치기 된(여기서는 아래로 시프트된) 브로드캐스트 연산자가 추가의 선행 연산자 또는 후속 연산 자(여기서는 후속 연산자)와 병합되거나 상쇄될 수 있는지 여부를 고려할 수 있다. 도 9a의 오른쪽 브랜치에 표시된 것처럼, 분할된 브로드캐스트 연산자와 후속의 이진 연산자는 브로드캐스트 병합 이진 연산자를 형성하기 위해 병합될 수 있다. 즉, 브로드캐스트 연산자는 실제로 텐서의 확장이므로 원래 는 입력 텐서가 먼저 브로드캐스트 연산자를 거쳐 확장되고, 그런 다음 확장된 텐서가 이진 연산자의 연산을 거 치며; 칩은 병합 후에, 브로드캐스트 연산자의 입력 텐서에서 각각의 숫자 값을 확장된 텐서 순서대로 판독하며; 예를 들어 숫자 값을 확장(즉, 복사)해야 하는 경우, 숫자 값을 여러 번 판독해야 하고, 판독한 숫자 값을 직접 이진 연산자의 연산을 거친다. 이는 브로드캐스트 연산자가 텐서 내의 해당 숫자 값을 변경하지 않고 입력 텐서를 확장하고, 숫자 값이 텐서에 나타나는 횟수만 변경하기 때문이다. 브로드캐스트 연산자가 [1,2,4]를 [[1,1],[2,2],[4,4]]로 변경하고, 이진 연산자가 수치 값이 3보다 크면 값 1 을 취하고, 수치 값이 3보다 작으면 값 0을 취하는 경우, 브로드캐스트 병합 이진 연산자는 칩이 미리 정해진 순서대로 판독하여 구현될 수 있다. 예를 들어, 칩은 1을 저장하는 위치에서 2번 판독하고, 각 판독 후에 이진 연산자 연산을 수행하여 0,0으로 결정하고; 칩은 2를 저장하는 위치에서 2번 판독하고 각 판독 후에 이진 연산 자 연산을 수행하여 0,0으로 결정하고; 칩은 4를 저장하는 위치에서 2번 판독하고 각 판독 후에 이진 연산자 연 산을 수행하여 1,1로 결정하고; 및 마지막으로 브로드캐스트 병합 이진 연산자의 출력 텐서는 [[0,0],[0,0],[1,1]]이다. 도 9b는 본 발명의 구현에 따른 계산 그래프에서 브로드캐스트 연산자를 다운시프트하고 이를 이진 연산자와 병 합하는 개략도를 나타낸다. 도 9b에 도시된 것처럼, 브로드캐스트 연산자는 아래로 이동하고(즉, 이후 재성형 연산자와 위치가 반대 방향으 로 변경됨) 바이너리 연산자와 병합된다. 위에서 설명한 대로, 이러한 병합은 칩의 하드웨어 판독 동작을 통해 구현될 수도 있으며, 예를 들어, 일부 정적 램(SRAM) 제어기는, 브로드캐스트 연산자와 동일한 의미를 구현하기 위해, 즉 확장 효과를 달성하기 위해, 정적 램(SRAM)에서 판독/기록을 위한 스트라이드, 오프셋 및 루프 카운트 중 적어도 하나를 구성할 수 있다. 이런 방식으로, 아래로 시프트된 브로드캐스트 연산자는 브로드캐스트 병합 바이너리 연산자를 형성하기 위해 인접한 후속 바이너리 연산자와 병합될 수 있다. 브로드캐스트 연산자와 병합될 수 있는 바이너리 연산자 외에도, 최적화를 위해 브로드캐스트 연산자와 병합을 지원하는 다른 연산자는 배치 완전 연결 연산자(batch fully connected operator)(배치 matmul 연산자라고도 함) 등이 있다. 한 실시예에서, 제1 연산자는 수집 연산자일 수 있다. 수집 연산자의 연산은 입력 텐서의 일부 숫자 값 중 일부 숫자 값을 선택하여 출력 텐서로 사용하는 것이다. 수집 연산자의 연산은 입력 텐서의 수치 값을 변경하지 않는 텐서 연산임을 알 수 있다. 도 10은 본 개시의 구현에 따라 두 개의 수집 연산자(Gather operators)를 하나의 수집 연산자로 통합하고 동일 한 연산자를 다운시프트하는 개략도를 나타낸다. 도 10과 같이, 두 개 이상의 동일한 제1 연산자의 후속 연산자가 동일한 연산자인 경우, 두 수집 연산자의 후속 연산자가 동일한 SomeOp 연산자인 경우, SomeOp 연산자의 앞선 두 수집 연산자는 하나의 수집 연산자로 통합될 수 있다. 통합된 수집 연산자는 다른 운영자와 합병되거나 상쇄될 기회를 모색하기 위해 계속해서 순위가 낮아질 수 있다 (즉, 후속 운영자와 위치가 바뀔 수 있음). 도 10의 예에서, SomeOp 연산자는, 중복된 수집 연산자를 줄이거나 후속 병합 또는 대응 연산(counteract operations)의 가능성을 생성하기 위해, 후속 연산자와 병합하거나 상쇄 되는 SomeOp 연산자(미도시)의 후속 연산자로 수집 연산자로 하여금 아래로 시프트될 수 있다고 가정한다. 한 실시예에서, 제1 연산자는 역방향 연산자일 수 있다. 역연산자는 입력 텐서의 특정 축에 대한 데이터 정렬을 역전시키는 역할을 한다. 도 11은 본 발명의 구현에 따른 역방향 연산자(Reverse operator)를 다운시프트하고 이를 컨볼루션 연산자 (Convolution operator)와 병합하는 개략도를 나타낸다. 컨볼루션 연산자의 연산은 가중치 컨볼루션(convolution)을 푸는 것이다. 역방향 연산자는 컨볼루션 연산자와 병합될 수 있으며, 왜냐하면 특정 방향으로 연방향 연산자의 연산을 거친 컨볼루션 연산자의 입력 텐서는 역방 향 연산자의 연산 규칙에 따라 컨볼루션 연산자의 가중치 레이아웃만 변경하면 되기 때문이며, 출력을 변경하지 않고 원래의 컨볼루션 연산자와 동일한 의미론을 따르게 된다. 따라서, 중복된 역방향 연산자는 역방향 연산자 를 다운시프트하고 이를 컨볼루션 연산자와 병합함으로써 최적화될 수 있다. 위에서는 재성형 연산자와 전치 연산자를 각자의 유사한 연산자와 병합하는 구현 예를 설명하였으며, 다른 연산 자도 같은 카테고리에 병합될 수 있다. 도 12a 및 12b는 각각 본 개시의 구현에 따른 컨캣 연산자(Concat operators) 및 캐스트 연산자(Cast operators) 병합의 개략도를 나타낸다. 컨캣 연산자의 연산은 두 개 이상의 텐서를 연결하는 것이며, 예를 들어, 3*4 텐서와 3*6 텐서를 연결하여 3*10 텐서로 만드는 것이다. 컨캣 연산자는 입력 텐서의 숫자 값을 변경하지 않는 텐서 연산이라는 것을 알 수 있다. 도 12a에 표시된 것처럼, 하나의 컨캣 연산자는 하나의 컨캣 연산자를 형성하기 위해 인접한 다른 컨캣 연산자 와 병합될 수 있다. 예를 들어, 한 컨캣 연산자의 연산은 3*4 텐서와 3*6 텐서(도 12a에서 왼쪽 컨캣 연산자 위 의 두 개의 아래쪽 입력 화살표로 표시된 두 개의 입력 텐서)를 연결하여 3*10 텐서로 만들고, 다른 컨캣 연산 자의 연산은 왼쪽 컨캣 연산자의 출력 텐서(3*10 텐서)와 다른 두 개의 입력 텐서, 예를 들어 3*5 텐서와 3*7 텐서(도 12a에서 가운데 컨캣 연산자의 오른쪽 상단에 있는 두 개의 아래쪽 입력 화살표로 표시된 다른 두 개의 입력 텐서)를 연결하여 3*22 텐서로 만든다. 따라서 두 개의 컨캣 연산자를 병합한 후 컨캣 연산자의 연산은 3*4 텐서와 3*6 텐서, 그리고 3*5 텐서와 3*7 텐서 등 4개의 텐서를 입력한 후 이를 한 번에 3*22 텐서로 연결 하는 것이 될 수 있다. 이런 방식으로, 계산해야 할 연산자의 수나 연산자 연산의 계산 복잡도가 줄어들고, 그에 따라 칩에서 이미지 데이터를 처리하는 신경망의 실시간 실행 지연 시간이 단축된다. 캐스트 연산자의 연산은 숫자 값의 유형을 변환하는 것이며, 예를 들어, 정수 1을 부동 소수점 숫자 1.0으로 변 환하거나 32비트 정수에서 64비트 정수로 변환하는 것이다. 컨캣 연산자는 입력 텐서의 수치 값을 변경하지 않 고 수치 값의 유형만 변경한다는 것을 알 수 있다. 도 12b에 표시된 것과 같이, 왼쪽 위의 Cast A to B는 텐서를 유형 A에서 유형 B로 변환하는 것을 나타내고, 왼 쪽 아래의 Cast B to C는 텐서를 유형 B에서 유형 C로 변환하는 것을 나타내며; 따라서, 두 개의 캐스트 연산자 를 병합한 후의 캐스트 연산자의 연산은 Cast A to C, 즉 텐서를 유형 A에서 유형 C로 직접 변환하는 것이 될 수 있다. 이런 방식으로, 계산해야 할 연산자의 수나 연산자 연산의 계산 복잡도가 줄어들고, 그에 따라 칩에서 이미지 데이터를 처리하는 신경망의 실시간 실행 지연 시간이 단축된다. 일 실시예에서, 제1 연산자를 조정하는 과정에서, 서로를 상쇄하는 복수의 제1 연산자를 삽입하는 것을 고려할 수 있으며, 복수의 제1 연산자가 다른 인접 연산자와 병합되거나 상쇄될 수 있다. 여기서, 서로를 상쇄하는 제1 연산자는 서로 역연산을 의미할 수 있다. 도 13a는, 복수의 제1 연산자가 본 공개의 구현에 따라 다른 인접한 연산자와 병합 또는 상쇄될 수 있도록, 서 로 상쇄시키는 복수의 제1 연산자를산자를 삽입하는 일 실시예를 나타낸다. 첫째, 이미지 데이터 채널 형식에는 두 가지 유형이 있다: NCHW 레이아웃은: \"channels_first\"로도 지칭되고, NHWC는 \"channels_last\"로도 지칭된다. NCHW 레이아웃에서, C는 바깥쪽 레이어에 있으므로, 각 채널 내에서 이 미지 픽셀이 서로 가깝게 배치되며, 즉, \"RRRGGGBBB\"이며, 반면 NHWC 레이아웃에서는 C가 가장 안쪽 레이어에 있으므로 각 채널 내에서 이미지 픽셀이 서로 떨어져 있으며, 즉, \"RGRGBRGB\"이다. 일부 신경망 모델의 형식은 기본적으로 NCHW 레이아웃의 컨볼루션 연산자를 지원하며; 그러나 NHWC 레이아웃의 칩에서 작동하는 경우 NCHW 컨볼루션을 수행하기 위해 계산 그래프에서 NHWC 레이아웃을 NCHW 레이아웃으로 변 환한 다음 컨볼루션 결과를 NHWC 레이아웃으로 변환해야 한다. 예를 들어, 도 13a의 왼쪽에 표시된 계산 그래프 에 구현된 이러한 프로세스는: 전치 NHWC2NCHW 연산자를 거친 다음 NCHW_Convolution 연산자를 거친 후, 마지막 으로 전치 NCHW2NHWC 연산자를 거친다.이러한 레이아웃을 변환하기 위해 서로 상쇄되는 복수의 전치 연산자가 원래의 계산 그래프에 삽입되면, 다운 시프트, 병합 및/또는 상쇄를 사용하여 전체 계산 그래프를 최적화할 수 있으므로, 레이아웃을 변환하는 데 드 는 비용이 최소화되고, 모든 삽입된 전치 연산자가 상쇄될 수 있는 최적의 경우에는 비용이 제거될 수도 있다. 예를 들어, 도 13a에 표시된 것처럼, 제1 단계에서는 서로를 상쇄하는 두 개의 전치 연산자, 즉 전치 NCHW2NHWC 연산자와 전치 NHWC2NCHW 연산자(서로 역연산)를 각각 원래의 전치 NHWC2NCHW 연산자 아래, 전치 NCHW2NHWC 연 산자 위에 삽입된다. 제2 단계에서, 원래 계산 그래프에 삽입된 전치 NCHW2NHWC 연산자와 전치 NHWC2NCHW 연산 자가 서로 역연산이기 때문에 서로 상쇄되고, 원래 계산 그래프에 삽입된 전치 NHWC2NCHW 연산자와 전치 NCHW2NHWC 연산자가 서로 역연산이기 때문에 서로 상쇄된다. 따라서, 원래의 계산 그래프는 NHWC_Convolution 연산자만 남기도록 최적화될 수 있다. 이런 방식으로, 계산해야 할 연산자의 수나 연산자 연산의 계산 복잡도가 줄어들고, 그에 따라 칩에서 이미지 데이터를 처리하는 신경망의 실시간 실행 지연 시간이 단축된다. 도 13b는, 복수의 제1 연산자가 본 공개의 구현에 따라 다른 인접 연산자와 병합 또는 상쇄될 수 있도록, 서로 상쇄시키는 복수의 제1 연산자를 삽입하는 또 다른 실시예의 개략도를 나타낸다.. 우선, 신경망 모델의 연산자가 2개의 입력을 가질 때, 2개의 입력은 좌측(left-hand-side)(LHS) 입력 텐서와 우 측(right-hand-side)(RHS) 입력 텐서로 표현될 수 있다. 일부 신경망 모델의 형식은 기본적으로 완전 연결 연산자(즉, 마트뮬 연산자(matmul operator))를 지원하는데, 이것의 RHS(제2 입력)는 전치(Transpose)를 수반하지 않으며; 그러나 일부 칩은 전치(Transpose)를 수반하기 위 해 완전 연결 연산자(즉, 마트뮬 연산자)의 RHS를 요구한다. 두 텐서가 완전 연결 연산자의 연산을 거칠 때, 축 일관성 문제에 주의해야 하며; 예를 들어, 3*4 텐서는 곱셈을 구현하기 위해 4*5 텐서가 필요하며, 즉, 제1 텐 서의 열 개수 4가 제2 텐서의 행 개수 4와 같아야 숫자 값을 하나씩 곱하고 더할 수 있으며, 즉 행렬 곱셈을 구 현할 수 있다. 따라서, 완전 연결 연산자의 후속 연산을 다른 입력 텐서로 원활하게 수행하기 위해, 원래의 계 산 그래프에는 하나의 입력 텐서의 축을 변환하기 위한 NC_Transpose 연산자가 있다. 따라서, 서로를 상쇄하는 두 개의 전치 연산자를 원래의 계산 그래프에 삽입하여 레이아웃을 변환한 다음, 다운 시프트, 병합, 상쇄를 통해 전체 계산 그래프를 최적화하여 레이아웃을 변환하는 데 드는 비용을 최소화하고, 모든 삽입된 전치 연산자가 상쇄될 수 있는 최적의 경우에는 비용도 제거될 수 있다. 전치 연산자를 삽입하여 RHS를 변환하는 것과 비슷한 사례는, NCHW 또는 HWCN의 가중치 레이아웃을 NHWC로 변환하기 위해, 컨볼루션의 가중치를 삽입하는 단계를 더 포함한다. 도 13b에 표시된 것처럼, 제1 단계에서, 서로 역연산이며 상쇄될 수 있는 두 개의 전치 연산자가 도 13b의 왼쪽 에 있는 원래의 계산 그래프에 삽입되며; 즉, NC_Transpose 연산자(다이어그램에서 어둡게 표시되었으며 원래 NC_Transpose 연산자의 역으로 설정해야 함)와 전자의 역인 NC_Transpose 연산자가 삽입되며, 각각 원래 NC_Transpose 연산자 아래, 완전 연결 연산자 위에 삽입된다. 제2 단계에서, 완전 연결 연산자 위에 삽입된 NC_Transpose 연산자와 원래 계산 그래프의 완전 연결 연산는 RHS 전치를 수반하는 완전 연결 연산자를 형성하 기 위해 병합된(완전 연결 rhs는 도 13b와 같이 전치됨). 제3 단계에서는, 다이어그램에서 어둡게 표시된 삽입 된 NC_Transpose 연산자와 원래 계산 그래프의 NC_Transpose 연산자는 서로 반대 연산이기 때문에 상호 대응될 수 있다. 결과적으로, 원래의 계산 그래프는 RHS 전치를 수행하는 완전 연결 연산자만 갖도록 최적화되었다. 이런 방식으로, 계산해야 할 연산자의 수나 연산자 연산의 계산 복잡도가 줄어들고, 그에 따라 칩에서 이미지 데이터를 처리하는 신경망의 실시간 실행 지연 시간이 단축된다. 위에서 소개한 (조정된) 제1 연산자는 인접한 제2 연산자와 병합되지만, 병합된 연산자는 위나 아래로 이동하여 다른 인접한 연산자와 병합 또는 상쇄함으로써 추가로 최적화될 수 있으며, 즉, 연속적인 병합과 가능한 상쇄가 수행될 수 있다. 이런 방식으로, 일부 연산자는 그 특정한 연산 내용으로 인해 계산 그래프에 삽입되거나 다른 연산자의 연산과 병합되거나 상쇄되도록 위로 또는 아래로 시프트될 수 있으므로, 계산해야 할 연산자의 수를 줄이거나 연산자 연산의 계산 복잡도를 낮추기 위해 이러한 연산자가 최적화되어, 그 결과 칩에서 이미지 데이터를 처리하는 신 경망의 실시간 실행 지연 시간을 단축한다. 또한, 출원인이 개발한 인공지능 칩의 특정 하드웨어 판독 기능을 결합하여, 최적화 전에 이들 연산자의 계산 결과와 계산 결과가 일관성을 유지하도록 보장하는 동시에, 계산해 야 할 연산자의 수를 줄이거나 연산자 연산의 계산 복잡도를 줄일 수 있다. 이러한 최적화는 계산 그래프와 같은 높은 수준의 의미 표현을 기반으로 수행되므로 명령어 수준에서 복잡하고 지루한 최적화 작업을 피할 수 있 으며 최적화 가능한 시나리오를 보다 보편화할 수 있다."}
{"patent_id": "10-2025-7001282", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "요약하면, 본 공개의 각각의 구현예는 적어도 아래와 같은 효과를 달성할 수 있다: 1. 계산 그래프의 전치 연산자는 분할된 후에, 아래로 시프트, 병합 또는 상쇄되어 공동 최적화되며, 이는 전치 연산자의 스케줄링 순서가 변경하고, 궁극적으로 계산 그래프의 레이아웃을 변형하고, 중복 연산자의 계산 복잡 도를 줄이고, 계산 그래프의 런타임 지연 시간을 최적화한다. 2. 계산 그래프의 재성형 연산자는 공동 최적화를 위해 다운시프트, 병합 또는 상쇄되고, 이는 재성형 연산자의 스케줄링 순서를 변경하고, 궁극적으로 계산 그래프의 중복된 재성형 연산자의 중복 계산을 줄이고, 계산 그래 프의 런타임 지연 시간을 최적화한다. 3. 브로드캐스트 연산자는 텐서의 형태를 브로드캐스트하고 확장할 수 있으며; 계산 그래프의 브로드캐스트 연 산자는 분할된 후에, 최적화를 위해 다운 시프트되고 병합되고,이는 원래 계산 그래프의 후속 브로드캐스트 연 산자의 계산 복잡도를 줄이고, 궁극적으로 계산 그래프의 런타임 지연 시간을 최적화한다. 4. 수집 연산자는 일반적으로 입력 데이터의 일부를 출력으로 선택하므로, 수집 연산자가 출력하는 데이터 볼륨 은 일반적으로 입력 데이터 볼륨보다 작다. 그러나, 일부 칩에서, 입력 데이터 볼륨과 출력 데이터 볼륨의 차이 가 특정 임계값보다 작을 때, 수집 연산자를 2번 계산하고 수집 연산자의 후속 노드가 작은 볼륨의 데이터를 계 산하는 비용이 후속 노드가 약간 더 큰 볼륨의 데이터를 계산하고 수집 연산자를 1번만 계산하는 비용보다 훨씬 크다. 따라서, 두 개의 동일한 수집 연산자를 병합하고 이를 다운시프트하는 기술은 최적화 효과를 달성한다."}
{"patent_id": "10-2025-7001282", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "5. 컨볼루션 연산자의 가중치 레이아웃을 변경하면, 컨볼루션 연산자의 입력의 선행 역방향 연산자가 병합될 수 있다. 이러한 특성에 따라, 중복된 역방향 연산자는 계산 복잡성을 줄이기 위해 다운시프트 및 병합 연산을 통 해 최적화될 수 있다. 6. 수학적 의미론에 따라 지속적으로 병합될 수 있는 연산자는 칩 파라미터에 따라 특정 칩에 선택적으로 병합 될 수 있으며, 이를 통해 중복된 연산자를 줄이고 계산 복잡성을 줄일 수 있다. 7. 다양한 특정 시나리오와 다양한 칩에 따라 최적화 기술의 다운시프트, 병합 및 상쇄 작업은 가변적인 순서로 실행되고 유연하게 결합될 수 있으며, 이를 통해 수학적 의미론을 변경하지 않고도 최적화 효과를 달성할 수 있 다. 8. 위에 설명된 과정은 1GHz 시뮬레이터로 시뮬레이션된다. 위에 설명한 최적화 작업이 없을 경우, 4pe 4batch 의 추론 지연 시간(inference latency)은 4562102ns이다. 최적화 작업 후, 추론 지연 시간은 4450052ns이다. 즉, 해당 모델에서 신경망을 실시간으로 구동하는 칩 시뮬레이터의 지연 최적화 비율은 2.46%에 이르며, 절대값 은 112.05us이다. 도 14는 본 개시의 구현에 따른 인공지능 칩의 개략적인 블록 다이어그램을 나타낸다. 도 14에 도시된 바와 같이, 인공 지능 칩(artificial intelligence chip)은: 신경망 모듈의 계산 그래프 에 입력되어 애플리케이션 데이터의 프로세스 출력 결과를 얻기 위한 수신된 애플리케이션 데이터를 저장하도록 구성된 메모리; 제어기를 포함하며, 이는: 계산 그래프의 제1 연산자(first operator)에 대해 각 연산자의 특정 연산(specific operation)에 따라, 계산 그래프에서 제1 연산자의 위치를 후속 연산자 (subsequent operator) 또는 선행 연산자(preceding operator)로 바꿔치고(counterchanging), 제1 연산자를 두 개 이상의 동일한 연산자로 분할하고(splitting), 및 서로를 상쇄할 수 있는 복수의 제1 연산자를 삽입하는 (inserting) 적어도 하나의 조정을 적어도 한 번 수행하고 - 여기서 제1 연산자는 입력 텐서(input tensor)에서 수치 값(numerical values)을 변경하지 않는 텐서 연산(tensor operation)임 -; 각 연산자의 특정 연산에 따라 계산 그래프에서 조정된 제1 연산자(adjusted first operator)에 인접한 제2 연산자(second operator)를 결정 하고 - 여기서 조정된 제1 연산자의 연산과 제2 연산자의 연산은 연산 결과에 영향을 미치지 않고 병합되거나 상쇄될 수 있음 -; 및 칩에 의해, 조정된 제1 연산자와 제2 연산자에 대해 병합(merge) 또는 상쇄 (cancellation)를 수행하고, 병합 또는 상쇄 후에 계산 그래프에서 각 연산자의 연산을 실행하도록 구성된다. 한 실시예에서, 애플리케이션 데이터는 적어도 한 유형의 이미지 데이터 및 자연어 데이터를 포함한다. 일 실시예에서, 칩에 의해, 계산 그래프의 제1 연산자(first operator)에 대해 각 연산자의 특정 연산(specific operation)에 따라, 계산 그래프에서 제1 연산자의 위치를 후속 연산자(subsequent operator) 또는 선행 연산자 (preceding operator)로 바꿔치고(counterchanging), 제1 연산자를 두 개 이상의 동일한 연산자로 분할하고 (splitting), 및 서로를 상쇄할 수 있는 복수의 제1 연산자를 삽입하는(inserting) 적어도 하나의 조정을 적어 도 한 번 수행하는(performing) 단계는: 두 개 이상의 후속 연산자와 분기된 선행 연산자를 갖는 제1 연산자에 응답하여, 각 제1 연산자가 후속 연산자 또는 선행 연산자와 일대일로 대응하도록 제1 연산자를 두 개 이상의 동일한 연산자로 분할하는(splitting) 단계; 및 두 개 이상의 동일한 제1 연산자의 후속 연산자가 동일한 연산 자인 것에 응답하여, 두 개 이상의 동일한 제1 연산자를 하나의 연산자로 통합하는(unifying) 단계를 포함한다. 일 실시예에서, 칩에 의해, 조정된 제1 연산자와 제2 연산자에 대해 병합(merge) 또는 상쇄(cancellation)를 수 행하고, 병합 또는 상쇄 후에 계산 그래프에서 각 연산자의 연산을 실행하는 단계는: 병합 또는 상쇄 전의 제2 연산자의 연산이 조정된 제1 연산자의 출력 텐서에 있는 숫자 값에 대해 수행되는 제2 연산자 연산인 것에 응답 하여, 병합 또는 상쇄된 후 조정된 제1 연산자와 제2 연산자를 제4 연산자로 병합하는 단계를 포함하고, 여기서 제4 연산자의 연산은: 칩에 의해, 조정된 제1 연산자 자체의 텐서 연산을 대체하기 위해, 조정된 제1 연산자의 입력 텐서의 수치 값을 미리 정해진 순서로 판독하는(reading) 단계 - 여기서 미리 정해진 순서는 조정된 제1 연산자 자체의 텐서 연산에 따라 결정됨 -; 그리고 제2 연산자의 연산에 따라 칩에 의해 판독한 수치 값에 대해 제2 연산자 연산을 수행하는(performing) 단계를 포함한다. 일 실시예에서, 칩에 의해, 조정된 제1 연산자의 입력 텐서에서 숫자 값을 미리 정해진 순서에 따라 판독하는 것은 소프트웨어를 통해 칩 판독에 대한 스트라이드, 오프셋 및 루프 카운트 중 적어도 하나를 설정하여 구현될 수 있다. 일 실시예에서, 칩에 의해, 조정된 제1 연산자와 제2 연산자에 대해 병합(merge) 또는 상쇄(cancellation)를 수 행하고, 병합 또는 상쇄 후에 계산 그래프에서 각 연산자의 연산을 실행하는(executing) 단계는: 병합 또는 상 쇄 전에 입력 텐서의 숫자 값을 변경하지 않고 제2 연산자가 텐서 연산인 것에 응답하여, 병합 또는 상쇄된 후 조정된 제1 연산자와 제2 연산자를 제3 연산자로 병합하는(merging) 단계를 포함하고, 여기서 제3 연산자의 텐 서 연산은 조정된 제1 연산자의 텐서 연산과 제2 연산자의 텐서 연산을 모두 구현한다. 일 실시예에서, 칩에 의해, 조정된 제1 연산자와 제2 연산자에 대해 병합(merge) 또는 상쇄(cancellation)를 수 행하고, 병합 또는 상쇄 후에 계산 그래프에서 각 연산자의 연산을 실행하는(executing) 단계는: 병합 또는 상 쇄 전에 조정된 제1 연산자와 제2 연산자가 상호 역연산인 것에 응답하여, 제1 연산자와 제2 연산자를 상쇄시키 는(canceling) 단계를 포함한다. 한 실시예에서, 제1 연산자는 전치 연산자, 재성형 연산자, 브로드캐스트 연산자, 수집 연산자, 역방향 연산자, 컨캣 연산자 및 캐스트 연산자로 구성된 그룹에서 선택되는 적어도 하나이다. 한 실시예에서, 제2 연산자는 전치 연산자, 재성형 연산자, 브로드캐스트 연산자, 수집 연산자, 역방향 연산자, 컨캣 연산자, 플래튼 연산자, 캐스트 연산자, 요소별 이진 연산자, 배치 완전 연결 연산자(batch fully connected operator) 및 컨볼루션 연산자로 구성된 그룹에서 선택되는 적어도 하나이다. 이런 방식으로, 일부 연산자는 그 특정한 연산 내용으로 인해 계산 그래프에 삽입되거나 다른 연산자의 연산과 병합되거나 상쇄되도록 위로 또는 아래로 시프트될 수 있으므로, 계산해야 할 연산자의 수를 줄이거나 연산자 연산의 계산 복잡도를 낮추기 위해 이러한 연산자가 최적화되어, 그 결과 칩에서 이미지 데이터를 처리하는 신 경망의 실시간 실행 지연 시간을 단축한다. 또한, 출원인이 개발한 인공지능 칩의 특정 하드웨어 판독 기능을 결합하여, 최적화 전에 이들 연산자의 계산 결과와 계산 결과가 일관성을 유지하도록 보장하는 동시에, 계산해 야 할 연산자의 수를 줄이거나 연산자 연산의 계산 복잡도를 줄일 수 있다. 이러한 최적화는 계산 그래프와 같 은 높은 수준의 의미 표현을 기반으로 수행되므로 명령어 수준에서 복잡하고 지루한 최적화 작업을 피할 수 있 으며 최적화 가능한 시나리오를 보다 보편화할 수 있다. 도 15는 본 개시의 구현예에 따른 본 개시의 구현예를 구현하는 데 적합한 예시적인 전자 장치의 블록 다이어그 램을 나타낸다. 전자 장치(electronic device)는 프로세서(processor)(H1)와 저장 매체(storage medium)(H2)를 포함할 수 있으 며, 이는 프로세서(H1)에 결합되어 있으며, 프로세서에 의해 실행될 때 본 개시의 실시예에 따른 각각의 방법의 단계를 수행하기 위한 컴퓨터 실행가능 명령들(computer-executable instructions)이 저장된다. 프로세서(H1)는, 예를 들어 하나 이상의 프로세서 또는 마이크로프로세서를 포함할 수 있지만 이에 국한되지 않 는다. 저장 매체(H2)는, 예를 들어, 랜덤 액세스 메모리(RAM), 리드 온리 메모리(ROM), 플래시 메모리, EPROM 메모리, EEPROM 메모리, 레지스터, 컴퓨터 저장 매체(예: 하드 드라이브, 플로피 디스크, 솔리드 스테이트 드라이브, 이 동식 디스크, CD-ROM, DVD-ROM, 블루 디스크 등)가 포함될 수 있지만 이에 국한되지 않는다. 또한, 전자 장치는 데이터 버스(data bus)(H3), 입출력(I/O) 버스(input/output (I/O) bus)(H4), 디스플레이 (display)(H5) 및 입출력 장치(input/output device)(H6)(예: 키보드, 마우스, 스피커 등)를 추가로 포함할 수 있다. 프로세서(H1)는 I/O 버스(H4)를 통해 유선 또는 무선 네트워크(도시되지 않음)를 통해 외부 장치(H5, H6 등)와 통신할 수 있다. 저장 매체(H2)는, 프로세서(H1)에 의해 실행될 때, 기술 분야에 설명된 실시 예에 따른 각각의 기능 및/또는 방 법의 단계를 실행하기 위한 적어도 하나의 컴퓨터 실행가능 명령이 추가로 저장되어 있을 수 있다. 일 실시예에서, 적어도 하나의 컴퓨터 실행가능 명령은 또한 소프트웨어 제품으로 컴파일되거나 소프트웨어 제 품을 구성할 수 있으며, 여기서 적어도 하나의 컴퓨터 실행가능 명령들은 프로세서에 의해 실행될 때 해당 기술 분야에 설명된 실시예에 따른 각각의 기능 및/또는 방법의 단계를 실행한다. 도 16은 본 개시의 구현에 따른 비일시적 컴퓨터 판독가능 저장 매체(non-temporary computer-readable storage medium)의 개략도를 나타낸다. 도 16에 도시된 바와 같이, 컴퓨터 판독가능 저장 매체에는 명령들(instructions)이 저장되어 있으며, 이 명령들은 예를 들어 컴퓨터 판독가능 명령들(computer-readable instructions)이다. 컴퓨터 판독가능 명 령은, 프로세서에 의해 실행될 때, 위에 설명된 각각의 방법을 실행할 수 있다. 컴퓨터 판독가능 저장 매 체는, 예를 들어 휘발성 메모리 및/또는 비휘발성 메모리가 포함되지만 이에 국한되지는 않는다. 휘발성 메모리 (volatile memory)는, 예를 들면, 램(RAM) 및/또는 캐시 등을 포함할 수 있다. 비휘발성 메모리는, 예를 들어, 리드 온리 메모리(Read-Only Memory)(ROM), 하드 디스크 및 플래시 메모리를 포함할 수 있다. 예를 들어, 컴퓨 터 판독가능 저장 매체는 컴퓨터와 같은 컴퓨팅 장치에 결합될 수 있으며; 다음으로, 컴퓨팅 장치가 컴퓨 터 판독가능 저장 매체에 저장된 컴퓨터 판독가능 명령을 실행하는 경우, 위에 설명된 각각의 방법 이 실행될 수 있다. 본 공개는 다음과 같은 항목을 포함할 수 있다: 항목 1. 칩을 통해 신경망 모듈의 컴퓨팅 파워를 최적화하는 방법은 다음을 포함한다: 칩에 의해, 각각의 연산자를 갖는 신경망 모듈의 계산 그래프를 획득하는 단계 - 애플리케이션 데이터의 프로세 스 출력 결과를 획득하기 위해 신경망 모듈은 애플리케이션 데이터를 수신함 -; 칩에 의해, 계산 그래프의 제1 연산자(first operator)에 대해 각 연산자의 특정 연산(specific operation)에 따라, 계산 그래프에서 제1 연산자의 위치를 후속 연산자(subsequent operator) 또는 선행 연산자(preceding operator)로 바꿔치고(counterchanging), 제1 연산자를 두 개 이상의 동일한 연산자로 분할하고(splitting), 및 서로를 상쇄할 수 있는 복수의 제1 연산자를 삽입하는(inserting) 적어도 하나의 조정을 적어도 한 번 수행 하는(performing) 단계 - 여기서 제1 연산자는 입력 텐서(input tensor)에서 수치 값(numerical values)을 변 경하지 않는 텐서 연산(tensor operation)임 -; 칩에 의해, 각 연산자의 특정 연산에 따라 계산 그래프에서 조정된 제1 연산자(adjusted first operator)에 인 접한 제2 연산자(second operator)를 결정하는(determining) 단계 - 여기서 조정된 제1 연산자의 연산과 제2 연산자의 연산은 연산 결과에 영향을 미치지 않고 병합되거나 상쇄될 수 있음 -; 및 칩에 의해, 조정된 제1 연산자와 제2 연산자에 대해 병합(merge) 또는 상쇄(cancellation)를 수행하고, 병합 또 는 상쇄 후에 계산 그래프에서 각 연산자의 연산을 실행하는(executing) 단계를 포함한다. 항목 2. 항목 1에 따른 방법으로, 애플리케이션 데이터는 적어도 한 유형의 이미지 데이터 및 자연어 데이터를 포함한다. 항목 3. 항목 1에 따른 방법으로, 칩에 의해, 계산 그래프의 제1 연산자(first operator)에 대해 각 연산자의 특정 연산(specific operation)에 따라, 계산 그래프에서 제1 연산자의 위치를 후속 연산자(subsequentoperator) 또는 선행 연산자(preceding operator)로 바꿔치고(counterchanging), 제1 연산자를 두 개 이상의 동일한 연산자로 분할하고(splitting), 및 서로를 상쇄할 수 있는 복수의 제1 연산자를 삽입하는 단계는: 두 개 이상의 후속 연산자와 분기된 선행 연산자를 갖는 제1 연산자에 응답하여, 각 제1 연산자가 후속 연산자 또는 선행 연산자와 일대일로 대응하도록 제1 연산자를 두 개 이상의 동일한 연산자로 분할하는(splitting) 단 계; 및 두 개 이상의 동일한 제1 연산자의 후속 연산자가 동일한 연산자인 것에 응답하여, 두 개 이상의 동일한 제1 연 산자를 하나의 연산자로 통합하는(unifying) 단계를 포함한다. 항목 4. 항목 1에 따른 방법으로, 칩에 의해, 조정된 제1 연산자와 제2 연산자에 대해 병합(merge) 또는 상쇄 (cancellation)를 수행하고, 병합 또는 상쇄 후에 계산 그래프에서 각 연산자의 연산을 실행하는 단계는: 병합 또는 상쇄 전의 제2 연산자의 연산이 조정된 제1 연산자의 출력 텐서에 있는 숫자 값에 대해 수행되는 제2 연산자 연산인 것에 응답하여, 병합 또는 상쇄된 후 조정된 제1 연산자와 제2 연산자를 제4 연산자로 병합하는 단계를 포함하고, 여기서 제4 연산자의 연산은: 칩에 의해, 조정된 제1 연산자 자체의 텐서 연산을 대체하기 위 해, 조정된 제1 연산자의 입력 텐서의 수치 값을 미리 정해진 순서로 판독하는(reading) 단계 - 여기서 미리 정 해진 순서는 조정된 제1 연산자 자체의 텐서 연산에 따라 결정됨 -; 그리고 제2 연산자의 연산에 따라 칩에 의 해 판독한 수치 값에 대해 제2 연산자 연산을 수행하는(performing) 단계를 포함한다. 항목 5. 항목 4에 따른 방법으로, 칩에 의해, 조정된 제1 연산자의 입력 텐서에서 숫자 값을 미리 정해진 순서 에 따라 판독하는 단계는 소프트웨어를 통해 칩 판독에 대한 스트라이드, 오프셋 및 루프 카운트 중 적어도 하 나를 설정하여 구현될 수 있다. 항목 6. 항목 1에 따른 방법으로, 칩에 의해, 조정된 제1 연산자와 제2 연산자에 대해 병합(merge) 또는 상쇄 (cancellation)를 수행하고, 병합 또는 상쇄 후에 계산 그래프에서 각 연산자의 연산을 실행하는 단계는: 병합 또는 상쇄 전에 입력 텐서의 숫자 값을 변경하지 않고 제2 연산자가 텐서 연산인 것에 응답하여, 병합 또 는 상쇄된 후 조정된 제1 연산자와 제2 연산자를 제3 연산자로 병합하는(merging) 단계를 포함하고, 여기서 제3 연산자의 텐서 연산은 조정된 제1 연산자의 텐서 연산과 제2 연산자의 텐서 연산을 모두 구현한다. 항목 7. 항목 1에 따른 방법으로, 칩에 의해, 조정된 제1 연산자와 제2 연산자에 대해 병합(merge) 또는 상쇄 (cancellation)를 수행하고, 병합 또는 상쇄 후에 계산 그래프에서 각 연산자의 연산을 실행하는 단계는: 병합 또는 상쇄 전에 조정된 제1 연산자와 제2 연산자가 상호 역연산인 것에 응답하여, 제1 연산자와 제2 연산 자를 상쇄시키는(canceling) 단계를 포함한다. 항목 8. 항목 1에 따른 방법으로, 제1 연산자는 전치 연산자, 재성형 연산자, 브로드캐스트 연산자, 수집 연산 자, 역방향 연산자, 컨캣 연산자 및 캐스트 연산자로 구성된 그룹에서 선택되는 적어도 하나이다. 항목 9. 항목 1에 따른 방법으로, 제2 연산자는 전치 연산자, 재성형 연산자, 브로드캐스트 연산자, 수집 연산 자, 역방향 연산자, 컨캣 연산자, 플래튼 연산자, 캐스트 연산자, 요소별 이진 연산자, 배치 완전 연결 연산자 (batch fully connected operator) 및 컨볼루션 연산자로 구성된 그룹에서 선택되는 적어도 하나이다. 항목 10. 인공지능 칩은: 애플리케이션 데이터의 프로세스 출력 결과를 얻기 위해 신경망 모듈의 계산 그래프에 입력되는 수신된 애플리 케이션 데이터를 저장하도록 구성된 메모리(memory); 제어기를 포함하고, 제어기는, 계산 그래프의 제1 연산자(first operator)에 대해 각 연산자의 특정 연산(specific operation)에 따라, 계산 그래프에서 제1 연산자의 위치를 후속 연산자(subsequent operator) 또는 선행 연산자(preceding operator)로 바꿔치고(counterchanging), 제1 연산자를 두 개 이상의 동일한 연산자로 분할하고(splitting), 및 서로를 상쇄 할 수 있는 복수의 제1 연산자를 삽입하는(inserting) 적어도 하나의 조정을 적어도 한 번 수행하고 - 여기서 제1 연산자는 입력 텐서(input tensor)에서 수치 값(numerical values)을 변경하지 않는 텐서 연산(tensor operation)임 -; 각 연산자의 특정 연산에 따라 계산 그래프에서 조정된 제1 연산자(adjusted first operator)에 인접한 제2 연 산자(second operator)를 결정하고 - 여기서 조정된 제1 연산자의 연산과 제2 연산자의 연산은 연산 결과에 영향을 미치지 않고 병합되거나 상쇄될 수 있음 -; 및 칩에 의해, 조정된 제1 연산자와 제2 연산자에 대해 병합(merge) 또는 상쇄(cancellation)를 수행하고, 병합 또 는 상쇄 후에 계산 그래프에서 각 연산자의 연산을 실행하도록 구성된다. 항목 11. 항목 10에 따른 칩으로, 애플리케이션 데이터는 적어도 한 유형의 이미지 데이터 및 자연어 데이터를 포함한다. 항목 12. 항목 10에 따른 칩에서, 칩에 의해, 계산 그래프의 제1 연산자(first operator)에 대해 각 연산자의 특정 연산(specific operation)에 따라, 계산 그래프에서 제1 연산자의 위치를 후속 연산자(subsequent operator) 또는 선행 연산자(preceding operator)로 바꿔치고(counterchanging), 제1 연산자를 두 개 이상의 동일한 연산자로 분할하고(splitting), 및 서로를 상쇄할 수 있는 복수의 제1 연산자를 삽입하는(inserting) 적 어도 하나의 조정을 적어도 한 번 수행하는(performing) 단계는: 두 개 이상의 후속 연산자와 분기된 선행 연산자를 갖는 제1 연산자에 응답하여, 각 제1 연산자가 후속 연산자 또는 선행 연산자와 일대일로 대응하도록 제1 연산자를 두 개 이상의 동일한 연산자로 분할하는(splitting) 단 계; 및 두 개 이상의 동일한 제1 연산자의 후속 연산자가 동일한 연산자인 것에 응답하여, 두 개 이상의 동일한 제1 연 산자를 하나의 연산자로 통합하는(unifying) 단계를 포함한다. 항목 13. 항목 10에 따른 칩에서, 칩에 의해, 조정된 제1 연산자와 제2 연산자에 대해 병합(merge) 또는 상쇄 (cancellation)를 수행하고, 병합 또는 상쇄 후에 계산 그래프에서 각 연산자의 연산을 실행하는 단계는: 병합 또는 상쇄 전의 제2 연산자의 연산이 조정된 제1 연산자의 출력 텐서에 있는 숫자 값에 대해 수행되는 제2 연산자 연산인 것에 응답하여, 병합 또는 상쇄된 후 조정된 제1 연산자와 제2 연산자를 제4 연산자로 병합하는 단계를 포함하고, 여기서 제4 연산자의 연산은: 칩에 의해, 조정된 제1 연산자 자체의 텐서 연산을 대체하기 위 해, 조정된 제1 연산자의 입력 텐서의 수치 값을 미리 정해진 순서로 판독하는(reading) 단계 - 여기서 미리 정 해진 순서는 조정된 제1 연산자 자체의 텐서 연산에 따라 결정됨 -; 그리고 제2 연산자의 연산에 따라 칩에 의 해 판독한 수치 값에 대해 제2 연산자 연산을 수행하는(performing) 단계를 포함한다. 항목 14. 항목 10에 따른 칩에서, 칩에 의해, 조정된 제1 연산자의 입력 텐서에서 숫자 값을 미리 정해진 순서 에 따라 판독하는 단계는 소프트웨어를 통해 칩 판독에 대한 스트라이드, 오프셋 및 루프 카운트 중 적어도 하 나를 설정하여 구현될 수 있다. 항목 15. 항목 10에 따른 칩에서, 칩에 의해, 조정된 제1 연산자와 제2 연산자에 대해 병합(merge) 또는 상쇄 (cancellation)를 수행하고, 병합 또는 상쇄 후에 계산 그래프에서 각 연산자의 연산을 실행하는 단계는: 병합 또는 상쇄 전에 입력 텐서의 숫자 값을 변경하지 않고 제2 연산자가 텐서 연산인 것에 응답하여, 병합 또 는 상쇄된 후 조정된 제1 연산자와 제2 연산자를 제3 연산자로 병합하는(merging) 단계를 포함하고, 여기서 제3 연산자의 텐서 연산은 조정된 제1 연산자의 텐서 연산과 제2 연산자의 텐서 연산을 모두 구현한다. 항목 16. 항목 10에 따른 칩에서, 칩에 의해, 조정된 제1 연산자와 제2 연산자에 대해 병합(merge) 또는 상쇄 (cancellation)를 수행하고, 병합 또는 상쇄 후에 계산 그래프에서 각 연산자의 연산을 실행하는 단계는: 병합 또는 상쇄 전에 조정된 제1 연산자와 제2 연산자가 상호 역연산인 것에 응답하여, 제1 연산자와 제2 연산 자를 상쇄시키는(canceling) 단계를 포함한다. 항목 17. 항목 10에 따른 칩에서, 제1 연산자는 전치 연산자, 재성형 연산자, 브로드캐스트 연산자, 수집 연산 자, 역방향 연산자, 컨캣 연산자 및 캐스트 연산자로 구성된 그룹에서 선택되는 적어도 하나이다. 항목 18. 항목 10에 따른 칩에서, 제2 연산자는 전치 연산자, 재성형 연산자, 브로드캐스트 연산자, 수집 연산 자, 역방향 연산자, 컨캣 연산자, 플래튼 연산자, 캐스트 연산자, 요소별 이진 연산자, 배치 완전 연결 연산자 (batch fully connected operator) 및 컨볼루션 연산자로 구성된 그룹에서 선택되는 적어도 하나이다. 항목 19. 칩을 통해 신경망 모듈의 컴퓨팅 파워를 최적화하기 위한 전자 장치는: 명령들을 저장하도록 구성된 메모리; 및 항목 1 내지 9 중 하나에 따라 메모리에 있는 명령들을 판독하고 해당 방법을 실행하도록 구성된 프로세서를 포 함한다. 항목 20. 명령들이이 저장된 비일시적 저장 매체; 여기서, 명령들은, 프로세서에 의해 판독될 때, 프로세서로 하여금, 항목 1 내지 9 중 하나에 따른 방법을 실행 하게 한다. 물론, 위의 구체적인 실시예는 제한이 아닌 단지 예시일 뿐이며, 당업자는 본 출원의 효과를 달성하기 위해 본 출원의 개념에 따라 위의 별도로 설명한 실시예의 일부 단계 및 장치를 조합 및 결합할 수 있다. 이러한 결합 및 조합된 실시예도 본 출원에 포함되며, 이러한 결합 및 조합은 여기에서 설명되지 않는다. 본 공개에 언급된 이점, 장점, 효과 등은 제한 사항이 아닌 단지 예시일 뿐이며, 이러한 이점, 장점, 효과 등은 본 출원의 각 실시예에 필요한 것으로 간주될 수 없다. 또한, 위에 공개된 구체적인 세부 사항은 단지 설명 및 쉬운 이해를 위한 목적일 뿐, 제한이 아니며, 위의 세부 사항은 본 출원이 위의 구체적인 세부 사항에 따라 구 현되어야 함을 제한하지 않는다. 본 공개에 포함된 장치, 기기, 장비 및 시스템의 블록 다이어그램은 단지 설명적인 예일 뿐이며, 블록 다이어그 램에 표시된 방식으로 연결, 배치 및 구성되어야 함을 요구하거나 암시하는 것이 아니다. 해당 기술 분야 종사 자라면 이러한 장치, 기기, 장치 및 시스템은 어떤 방식으로든 연결, 배치 및 구성될 수 있다는 사실을 알고 있 을 것이다. \"포함하다(including)\", \"함유하다(containing)\", \"가지다(having)\" 등의 단어는 \"포함하지만 이에 국한되지 않는다\"는 의미의 개방형 단어이므로 이러한 단어와 상호 교환하여 사용할 수 있다. 본 문서에서 사용 되는 \"또는\" 및 \"및\"이라는 용어는 \"및/또는\"이라는 용어를 지칭하며, 문맥상 명확히 달리 표시되지 않는 한 이 두 용어와 상호 교환하여 사용할 수 있다. 본 문서에서 사용된 \"예를 들어\"라는 단어는 \"예를 들어, 이에 국한 되지 않음\"이라는 문구를 의미하며 이와 호환하여 사용할 수 있다. 본 공개의 단계 흐름도와 위의 방법 설명은 단지 설명적인 예일 뿐이며, 다양한 실시예의 단계가 주어진 순서에 따라 수행되어야 함을 요구하거나 암시하는 것은 아니다. 해당 기술 분야 종사자라면 알겠지만, 위의 실시 예에 서 설명한 단계의 순서는 어떠한 순서로도 수행될 수 있다. \"그 후\", \"그 다음\", \"다음\" 등의 단어는 단계의 순 서를 제한하려는 것이 아니며; 이러한 단어는 독자가 이러한 방법에 대한 설명을 안내하는 데만 사용된다. 또한, \"하나\", \"한\", \"그\" 등의 관사를 사용하는 등 단수 형태의 요소에 대한 모든 참조는 해당 요소를 단수 형 태로 제한하는 것으로 해석되어서는 안 된다. 또한, 본 명세서에 기재된 다양한 실시예의 단계 및 장치는 특정 실시예에 한정되지 않는다. 사실, 본원의 다양 한 실시예에서의 몇몇 관련 단계 및 장치는 본 출원의 개념에 따른 새로운 실시예를 구상하기 위해 결합될 수 있으며, 이러한 새로운 실시예도 본 출원의 범위에 포함된다. 위에 기술된 방법의 각각의 연산은 해당 기능을 수행할 수 있는 적절한 수단을 통해 수행될 수 있다. 이러한 수 단에는 하드웨어 회로, 주문형 집적 회로(application-specific integrated circuits)(ASICs) 또는 프로세서를 포함하되 이에 국한되지 않는 다양한 하드웨어 및/또는 소프트웨어 구성 요소 및/또는 모듈이 포함될 수 있다. 여기에 설명된 기능을 수행하도록 설계된 범용 프로세서, 디지털 신호 프로세서(DSP), ASIC, 필드 프로그래밍 가능 게이트 어레이(FPGA) 신호 또는 기타 프로그래밍 가능 논리 장치(PLD), 개별 게이트 또는 트랜지스터 논리, 개별 하드웨어 구성 요소 또는 이들의 조합은 설명된 각각의 논리 블록, 모듈 및 회로를 구현하거나 수행 하는 데 활용될 수 있다. 범용 프로세서는 마이크로프로세서일 수 있지만, 대체품으로서 프로세서는 상업적으로 판매되는 프로세서, 제어기, 마이크로제어기 또는 상태 머신이 될 수 있다. 프로세서는 또한 컴퓨팅 장치의 조 합으로 구현될 수 있으며, 예를 들어, DSP와 마이크로프로세서의 조합, 복수의 마이크로프로세서, DSP 코어와 협력하는 마이크로프로세서 또는 이와 유사한 다른 구성일 수 있다. 본 공개에 기술된 방법 또는 알고리즘과 관련된 단계는 하드웨어에 직접 내장될 수도 있고, 프로세서에 의해 실 행되는 소프트웨어 모듈일 수도 있으며, 이 둘의 조합일 수도 있다. 소프트웨어 모듈은 모든 형태의 실제 저장 매체에 존재할 수 있다. 사용될 수 있는 저장 매체의 예로는 랜덤 액세스 메모리(RAM), 리드 온리 메모리(ROM), 플래시 메모리, EPROM 메모리, EEPROM 메모리, 레지스터, 하드 드라이브, 이동식 디스크, CD-ROM 등이 있다. 저 장 매체는 프로세서에 결합될 수 있으므로, 프로세서는 저장 매체로부터 정보를 판독하고 저장 매체에 정보를 기록할 수 있다. 교체 모드(replacement mode)에서, 저장 매체가 프로세서와 통합될 수 있다. 소프트웨어 모듈 은 단일 명령들이거나 복수의 명령들일 수 있으며, 여러 개의 서로 다른 코드 세그먼트, 서로 다른 프로그램 간 및 복수의 저장 매체에 분산될 수 있다. 여기에 공개되는 방법은 설명된 방법을 구현하기 위한 동작을 포함한다. 방법 및/또는 동작은 청구항의 범위를 벗어나지 않고 서로 호환될 수 있다. 다시 말해, 특정한 동작 순서가 지정되지 않는 한, 특정 동작의 순서 및/ 또는 사용은 청구항의 범위를 벗어나지 않고도 수정될 수 있다. 위에 설명된 기능은 하드웨어, 소프트웨어, 펌웨어 또는 이들의 조합을 통해 구현될 수 있다. 소프트웨어로 구 현하는 경우 해당 기능은 유형의 컴퓨터 판독가능 매체에 명령들로 저장될 수 있다. 저장 매체는 컴퓨터로 접근 할 수 있는 모든 유형의 매체가 될 수 있다. 제한이 아닌 예시로서, 이러한 컴퓨터 판독 매체에는 RAM, ROM, EEPROM, CD-ROM 또는 기타 광 저장 장치, 자기 저장 장치 또는 기타 자기 저장 장치, 또는 명령 또는 데이터 구 조의 형태로 원하는 프로그램 코드를 수단하거나 저장하는 데 사용될 수 있는 기타 유형의 매체가 포함될 수 있 으며 컴퓨터에서 액세스될 수 있다. 본 명세서에서 사용되는 디스크(disk) 및 디스크는 콤팩트 디스크(CD), 레 이저 디스크, 광 디스크, 디지털 다기능 디스크(DVD), 플로피 디스크, 블루 디스크를 포함하며, 여기서 디스크 는 일반적으로 데이터를 자기적으로 재생하는 반면, 디스크는 레이저를 이용하여 광학적으로 데이터를 재생한다. 따라서, 컴퓨터 프로그램 제품(computer program product)은 여기에 제시된 동작을 수행할 수 있다. 예를 들어, 이러한 컴퓨터 프로그램 제품은 명령들이 유형적으로 저장되어 있거나 인코딩되어 있는 컴퓨터 판독가능한 유형 매체일 수 있으며, 명령들은 프로세서에 의해 실행되어 여기에 설명된 동작을 수행할 수 있다. 컴퓨터 프로그램 제품에는 포장재가 포함될 수 있다. 소프트웨어나 명령들도 전송 매체를 통해 전송될 수 있다. 예를 들어, 소프트웨어는 동축 케이블, 광섬유 케이 블, 연선(twisted pair cable), 디지털 가입자 회선(DSL)이나 적외선, 라디오, 마이크로파와 같은 무선 기술과 같은 전송 매체를 사용하여 웹사이트, 서버 또는 기타 원격 소스에서 전송될 수 있다. 또한, 여기에 설명된 방법 및 기술을 수행하기 위한 모듈 및/또는 기타 적절한 수단은 사용자 단말기 및/또는 기지국에서 필요에 따라 다운로드 및/또는 다른 방법으로 획득될 수 있다. 예를 들어, 이러한 장치는 여기에 설 명된 방법을 수행하기 위한 수단의 전송을 용이하게 하기 위해 서버에 결합될 수 있다. 또는, 여기에 설명된 각 각의 방법은 저장 구성요소(예: RAM, ROM, CD나 플로피 디스크와 같은 물리적 저장 매체 등)에 의해 제공될 수 있으므로, 사용자 단말 및/또는 기지국은 장치에 결합되거나 장치에 저장 구성요소를 제공할 때 다양한 방법을 얻을 수 있다. 또한, 여기에 설명된 방법 및 기술을 장치에 제공하기 위한 다른 적절한 기술이 활용될 수 있다. 다른 예와 구현예는 본 공개내용과 첨부된 청구항의 범위 및 사상 내에 포함된다. 예를 들어, 소프트웨어의 특 성상 위에 설명된 기능은 프로세서, 하드웨어, 펌웨어, 하드 와이어링 또는 이들의 조합을 통해 실행되는 소프 트웨어를 사용하여 실현될 수 있다. 기능을 구현하는 특징은 물리적으로 다양한 위치에 위치할 수도 있으며, 기 능의 일부가 서로 다른 물리적 위치에서 구현되도록 분산될 수도 있다. 또한, 본 명세서에서, 청구항을 포함하 여, \"적어도 하나\"로 시작하는 항목의 열거에 사용되는 \"또는\"은 별도의 열거를 나타내므로, 예를 들어, \"A, B 또는 C 중 적어도 하나\"의 열거는 A 또는 B 또는 C, 또는 AB 또는 AC 또는 BC, 또는 ABC(즉, A와 B와 C)를 의미 한다. 더욱이, \"예시적\"이라는 단어는 설명된 예가 다른 예보다 선호되거나 더 낫다는 것을 의미하지 않는다. 여기에 설명된 기술에 대한 다양한 변경, 대체 및 수정은 첨부된 청구항에 의해 정의된 교시된 기술에서 벗어나 지 않고 이루어질 수 있다. 더욱이, 본 공개의 특허청구범위는 위에 기술한 공정, 기계, 제조, 사건의 구성, 수 단, 방법 및 행동의 구체적인 측면에 국한되지 않는다. 여기에 기술된 해당 측면과 실질적으로 동일한 기능을 수행하거나 실질적으로 동일한 결과를 달성하는 기존 또는 나중에 개발될 프로세스, 기계, 제조품, 조성물, 수 단, 방법 또는 실행을 활용할 수 있다. 따라서, 첨부된 청구항는 그 범위 내에 있는 그러한 프로세스, 기계, 제 조물, 사건의 구성, 수단, 방법 또는 행위를 포함한다. 공개된 측면에 대한 위의 설명은 해당 기술 분야 종사자가 본 출원을 구현하거나 활용할 수 있도록 제공된다. 이러한 측면에 대한 다양한 수정은 해당 기술 분야의 숙련자에게는 자명할 것이며, 여기에 정의된 일반 원칙은 본 출원의 범위를 벗어나지 않고도 다른 측면에도 적용될 수 있다. 따라서, 본 개시는 여기에 예시된 실시예에 제한되지 않고, 여기에 개시된 원리 및 신규한 특징과 일치하는 가장 넓은 범위를 따를 것이다. 앞서 설명한 내용은 설명과 예시를 목적으로 제시되었다. 더욱이, 본 설명은 본 출원의 실시예를 여기에 공개된 형태로 제한하려는 것이 아니다. 위에서 여러 가지 예시적인 측면과 실시예를 논의했지만, 해당 기술 분야 종사 자라면 그 중 특정한 변형, 수정, 변경, 추가 및 하위 조합을 인식할 수 있을 것이다.도면 도면1 도면2 도면3a 도면3b 도면3c 도면4 도면5 도면6 도면7 도면8a 도면8b 도면9a 도면9b 도면10 도면11 도면12a 도면12b 도면13a 도면13b 도면14 도면15 도면16"}
{"patent_id": "10-2025-7001282", "section": "도면", "subsection": "도면설명", "item": 1, "content": "본 발명의 실시예 또는 종래 기술의 기술적 해결책을 보다 명확하게 설명하기 위해, 실시예 또는 종래 기술의 설명에 필요한 도면을 간략히 소개한다. 물론, 다음 설명에 있는 도면은 본 공개의 일부 실시예에 불과하며, 이 분야의 당업자가 창의적인 작업을 하지 않고도 이러한 도면에 따라 다른 도면을 얻을 수 있다. 도 1은 본 개시의 구현예에 따른 이미지 데이터 처리 및 인식에 적용된 신경망의 계산 그래프의 예시적 다이어 그램을 나타낸다. 도 2는 본 개시의 구현에 따른 칩을 통해 신경망 모듈의 컴퓨팅 파워를 최적화하는 방법을 나타낸다. 도 3a는 본 개시의 구현에 따른 복수의 연산자를 포함하는 원래의 계산 그래프의 개략도를 나타낸다. 도 3b는 본 개시의 구현에 따른 계산 그래프에서 제1 연산자를 두 개 이상의 동일한 연산자로 분할하는 개략도를 나타낸 다. 도 3c는 본 개시의 구현에 따라 제1 연산자를 조정한 후의 최적화된 계산 그래프의 개략도를 나타낸다. 도 4는 본 발명의 실시 예에 따라 두 개 이상의 동일한 제1 연산자를 하나의 연산자로 통합하고 계산 그래프에 서 연산자를 다운시프트(down-shifting)하는 개략도를 나타낸다. 도 5는 본 발명의 구현에 따른 계산 그래프에서 전치 연산자(Transpose operator)를 연속적으로 여러 번 다운시 프트하고 이를 완전 연결 연산자(Fully connected operator)와 병합하는 개략도를 나타낸다. 도 6은 본 발명의 구현에 따른 계산 그래프에서 제1 연산자와 제2 연산자의 상쇄에 대한 개략도를 나타낸다. 도 7은 본 발명의 구현에 따른 계산 그래프에서 전치 연산자를 다운시프트한 다음, 인접한 전치 연산자와 병합 하여 하나의 전치 연산자로 만드는 개략도를 나타낸다. 도 8a는 본 발명의 구현에 따른 계산 그래프에서 상호 역연산(inverse operations)인 다른 재성형 연산자 (Reshape operator)로 재성형 연산자를 상쇄하는 개략도를 나타낸다. 도 8b는 본 발명의 구현에 따른 계산 그래 프에서 재성형 연산자를 다운시프트한 다음, 이를 인접한 재성형 연산자와 병합하여 하나의 재성형 연산자로 만 드는 개략도를 나타낸다. 도 9a는 본 개시의 구현에 따라 계산 그래프를 최적화하기 위해 하나의 브로드캐스트 연산자(Broadcast operator)를 두 개의 브로드캐스트 연산자로 분할하는 개략도를 나타낸다. 도 9b는 본 발명의 구현에 따른 계산 그래프에서 브로드캐스트 연산자를 다운시프트하고 이를 이진 연산자와 병합하는 개략도를 나타낸다. 도 10은 본 개시의 구현에 따라 두 개의 수집 연산자(Gather operators)를 하나의 수집 연산자로 통합하고 동일 한 연산자를 다운시프트하는 개략도를 나타낸다. 도 11은 본 발명의 구현에 따른 역방향 연산자(Reverse operator)를 다운시프트하고 이를 컨볼루션 연산자 (Convolution operator)와 병합하는 개략도를 나타낸다. 도 12a 및 12b는 각각 본 개시의 구현에 따른 컨캣 연산자(Concat operators) 병합 및 캐스트 연산자(Cast operators) 병합의 개략도를 나타낸다. 도 13a는, 복수의 제1 연산자가 본 공개의 구현에 따라 다른 인접한 연산자와 병합 또는 상쇄될 수 있도록, 서 로 상쇄시키는 복수의 제1 연산자를 삽입하는 일 실시예를 나타낸다. 도 13b는, 복수의 제1 연산자가 본 공개의 구현에 따라 다른 인접 연산자와 병합 또는 상쇄될 수 있도록, 서로 상쇄시키는 복수의 제1 연산자를 삽입하는 또 다른 실시예의 개략도를 나타낸다. 도 14는 본 개시의 구현에 따른 인공지능 칩의 개략적인 블록 다이어그램을 나타낸다. 도 15는 본 개시의 구현예에 따른 본 개시의 구현예를 구현하는 데 적합한 예시적인 전자 장치의 블록 다이어그 램을 나타낸다. 도 16은 본 개시의 구현에 따른 비일시적 컴퓨터 판독가능 저장 매체(non-transitory computer-readable storage medium)의 개략도를 나타낸다."}
