{"patent_id": "10-2024-7024886", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0128945", "출원번호": "10-2024-7024886", "발명의 명칭": "신경망 동작 방법, 장치 및 저장 매체", "출원인": "다탕 모바일 커뮤니케이션즈 이큅먼트 코포레이션", "발명자": "진, 리창"}}
{"patent_id": "10-2024-7024886", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "가변 차원의 유형에 따라 제1 신경망에 랜덤 마스크층을 설정하여 제2 신경망을 획득하는 단계 - 상기 랜덤 마스크층은 상기 랜덤 마스크층에 입력되는 텐서에 대해 랜덤 마스크 처리를 진행하는 데 사용됨-; 및샘플 데이터를 이용하여 상기 제2 신경망을 훈련시키는 단계를 포함하는 것을 특징으로 하는 신경망 동작 방법."}
{"patent_id": "10-2024-7024886", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 가변 차원의 유형은,입력 차원이 가변적인 것;출력 차원이 가변적인 것; 또는중간 차원이 가변적인 것; 중 하나 이상을 포함하는 것을 특징으로 하는 신경망 동작 방법."}
{"patent_id": "10-2024-7024886", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,상기 가변 차원의 유형에 따라 제1 신경망에 랜덤 마스크층을 설정하는 단계는,상기 가변 차원의 유형이 입력 차원이 가변적인 경우, 상기 제1 신경망의 입력층 앞에 랜덤 마스크층을 설정하는 단계를 포함하는 것을 특징으로 하는 신경망 동작 방법."}
{"patent_id": "10-2024-7024886", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제2항에 있어서,상기 가변 차원의 유형에 따라 제1 신경망에 랜덤 마스크층을 설정하는 단계는,상기 가변 차원의 유형이 출력 차원이 가변적인 경우, 상기 제1 신경망의 출력층 뒤에 랜덤 마스크층을 설정하는 단계를 포함하는 것을 특징으로 하는 신경망 동작 방법."}
{"patent_id": "10-2024-7024886", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제2항에 있어서,상기 가변 차원의 유형에 따라 제1 신경망에 랜덤 마스크층을 설정하는 단계는,상기 가변 차원의 유형이 중간 차원이 가변적인 경우, 상기 제1 신경망의 중간층에 랜덤 마스크층을 설정하는단계를 포함하는 것을 특징으로 하는 신경망 동작 방법."}
{"patent_id": "10-2024-7024886", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5항에 있어서,상기 제1 신경망의 중간층에 랜덤 마스크층을 설정하는 단계는,하나의 중간 차원만 가변적인 경우, 연관된 중간층 앞이나 뒤에 하나의 랜덤 마스크층을 설정하는 단계를 포함하는 것을 특징으로 하는 신경망 동작 방법."}
{"patent_id": "10-2024-7024886", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제5항에 있어서,공개특허 10-2024-0128945-3-상기 제1 신경망의 중간층에 랜덤 마스크층을 설정하는 단계는,복수의 중간 차원이 가변적인 경우, 각 연관된 중간층의 앞이나 뒤에 각각 하나의 랜덤 마스크층을 설정하는 단계를 포함하는 것을 특징으로 하는 신경망 동작 방법."}
{"patent_id": "10-2024-7024886", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1항에 있어서,상기 샘플 데이터를 이용하여 상기 제2 신경망을 훈련시키는 단계는,각 샘플 데이터의 입력 데이터의 차원이 모두 제1 임계값인 경우, 전체 샘플 데이터를 직접 이용하여 상기 제2신경망을 훈련시키는 단계를 포함하며, 상기 제1 임계값은 전체 샘플 데이터의 입력 데이터 차원의 최대값인 것을 특징으로 하는 신경망 동작 방법."}
{"patent_id": "10-2024-7024886", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1항에 있어서,상기 샘플 데이터를 이용하여 상기 제2 신경망을 훈련시키는 단계는,적어도 하나의 제1 샘플 데이터가 존재하는 경우, 우선 상기 제1 샘플 데이터에 대해 증강 처리를 수행하고, 다음 전체 제1 샘플 데이터와 전체 제2 샘플 데이터를 이용하여 상기 제2 신경망을 훈련시키는 단계를 포함하며,상기 제1 샘플 데이터는 입력 데이터의 차원이 제1 임계값이 아닌 샘플 데이터이고, 상기 제2 샘플 데이터는 입력 데이터의 차원이 상기 제1 임계값인 샘플 데이터이고, 상기 제1 임계값은 전체 샘플 데이터의 입력 데이터차원의 최대값인 것을 특징으로 하는 신경망 동작 방법."}
{"patent_id": "10-2024-7024886", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9항에 있어서,상기 제1 샘플 데이터에 대해 증강 처리를 수행하는 단계는,상기 제1 샘플 데이터의 입력 데이터에 대해 하이 비트 제로 패딩(high-bit zero padding)을 수행하는 단계를포함하는 것을 특징으로 하는 신경망 동작 방법."}
{"patent_id": "10-2024-7024886", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제9항에 있어서,상기 제1 샘플 데이터에 대해 증강 처리를 수행하는 단계는,상기 제1 샘플 데이터의 입력 데이터에 대해 로우 비트 제로 패딩(low-bit zero padding)을 수행하는 단계를 포함하는 것을 특징으로 하는 신경망 동작 방법."}
{"patent_id": "10-2024-7024886", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제1항에 있어서,상기 샘플 데이터를 이용하여 상기 제2 신경망을 훈련시키는 단계는,적어도 하나의 제1 샘플 데이터가 존재하는 경우, 우선 상기 제1 샘플 데이터를 제거하고, 다음 전체 제2 샘플데이터를 이용하여 상기 제2 신경망을 훈련시키는 단계를 포함하며, 상기 제1 샘플 데이터는 입력 데이터의 차원이 제1 임계값이 아닌 샘플 데이터이며, 상기 제2 샘플 데이터는 입력 데이터의 차원이 상기 제1 임계값인 샘플 데이터이며, 상기 제1 임계값은 전체 샘플 데이터의 입력 데이터 차원의 최대값인 것을 특징으로 하는 신경망 동작 방법."}
{"patent_id": "10-2024-7024886", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제1항에 있어서,상기 랜덤 마스크층에 입력되는 텐서에 대해 랜덤 마스크 처리를 진행하는 단계는,공개특허 10-2024-0128945-4-상기 랜덤 마스크층에 입력되는 텐서 및 랜덤 마스크 텐서를 결정하는 단계; 및상기 랜덤 마스크 텐서를 이용하여 상기 랜덤 마스크층에 입력되는 텐서에 대해 랜덤 마스크 처리를 진행하는단계를 포함하는 것을 특징으로 하는 신경망 동작 방법."}
{"patent_id": "10-2024-7024886", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제13항에 있어서,상기 랜덤 마스크층에 입력되는 텐서에 대해 랜덤 마스크 처리를 진행하기 위한 표현식은,이고,는 랜덤 마스크층에서 출력되는 텐서를 나타내고, X는 랜덤 마스크층에 입력되는 텐서를 나타내며, 는 텐서에 대한 비트별 포인트 곱셈 연산(bitwise point multiplication operation)을 나타내고, M은 랜덤 마스크텐서를 나타내는 것을 특징으로 하는 신경망 동작 방법."}
{"patent_id": "10-2024-7024886", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제13항에 있어서,상기 랜덤 마스크 텐서는 하드 마스킹 텐서인 것을 특징으로 하는 신경망 동작 방법."}
{"patent_id": "10-2024-7024886", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제13항에 있어서,상기 랜덤 마스크 텐서는 소프트 마스킹 텐서인 것을 특징으로 하는 신경망 동작 방법."}
{"patent_id": "10-2024-7024886", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제13항에 있어서,상기 랜덤 마스크 텐서는 하드 마스킹 텐서와 소프트 마스킹 텐서의 조합으로 형성된 것을 특징으로 하는 신경망 동작 방법."}
{"patent_id": "10-2024-7024886", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제1항에 있어서,상기 샘플 데이터를 이용하여 상기 제2 신경망을 훈련시키는 단계 이후에,훈련된 제2 신경망의 랜덤 마스크층을 텐서 변환층으로 업데이트하는 단계를 더 포함하며, 상기 텐서 변환층은상기 텐서 변환층에 입력되는 텐서에 대해 차원 변환을 수행하는 데 사용되는 것을 특징으로 하는 신경망 동작방법."}
{"patent_id": "10-2024-7024886", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제18항에 있어서,상기 훈련된 제2 신경망의 랜덤 마스크층을 텐서 변환층으로 업데이트하는 단계는,훈련된 제2 신경망의 입력층 앞에 랜덤 마스크층이 존재하는 경우, 훈련된 제2 신경망의 입력층 앞에 있는 랜덤마스크층을 텐서 패딩층으로 업데이트하는 단계를 포함하고, 상기 텐서 패딩층은 상기 텐서 패딩층에 입력되는텐서의 차원을 제1 임계값으로 증가하는 데 사용되고, 상기 제1 임계값은 전체 샘플 데이터의 입력 데이터 차원의 최대값인 것을 특징으로 하는 신경망 동작 방법."}
{"patent_id": "10-2024-7024886", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제18항에 있어서,상기 훈련된 제2 신경망의 랜덤 마스크층을 텐서 변환층으로 업데이트하는 단계는,공개특허 10-2024-0128945-5-훈련된 제2 신경망의 출력층 뒤에 랜덤 마스크층이 존재하는 경우, 훈련된 제2 신경망의 출력층 뒤에 있는 랜덤마스크층을 텐서 크로핑층으로 업데이트하는 단계를 포함하며, 상기 텐서 크로핑층은 상기 텐서 크로핑층에 입력되는 텐서의 차원을 제1 목표값으로 감소하는 데 사용되는 것을 특징으로 하는 신경망 동작 방법."}
{"patent_id": "10-2024-7024886", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_21", "content": "제18항에 있어서,상기 훈련된 제2 신경망의 랜덤 마스크층을 텐서 변환층으로 업데이트하는 단계는,훈련된 제2 신경망의 중간층에 랜덤 마스크층이 존재하는 경우, 훈련된 제2 신경망의 중간층에 있는 랜덤 마스크층을 텐서 크로핑 캐스케이드 텐서 패딩 층으로 업데이트하는 단계를 포함하고, 상기 텐서 크로핑 캐스케이드텐서 패딩 층은 상기 텐서 크로핑 캐스케이드 텐서 패딩 층에 입력되는 텐서의 차원을 제2 목표값으로 감소한후 원래 차원으로 증가하는 데 사용되는 것을 특징으로 하는 신경망 동작 방법."}
{"patent_id": "10-2024-7024886", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_22", "content": "메모리, 송수신기, 프로세서를 포함하고,메모리는 컴퓨터 프로그램을 저장하는 데 사용되고, 송수신기는 상기 프로세서의 제어에 따라 데이터를 송수신하는 데 사용되며, 프로세서는 상기 메모리에 있는 컴퓨터 프로그램을 리드하여,가변 차원의 유형에 따라 제1 신경망에 랜덤 마스크층을 추가하여 제2 신경망을 획득하는 동작 - 상기 랜덤 마스크층은 상기 랜덤 마스크층에 입력되는 텐서에 대해 랜덤 마스크 처리를 진행함 -; 및샘플 데이터를 이용하여 상기 제2 신경망을 훈련시키는 동작;을 수행하는 데 사용되는 것을 특징으로 하는 전자기기."}
{"patent_id": "10-2024-7024886", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_23", "content": "제22항에 있어서,상기 가변 차원의 유형은,입력 차원이 가변적인 것;출력 차원이 가변적인 것; 또는중간 차원이 가변적인 것; 중 하나 이상을 포함하는 것을 특징으로 하는 전자 기기."}
{"patent_id": "10-2024-7024886", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_24", "content": "제23항에 있어서,상기 가변 차원의 유형에 따라 제1 신경망에 랜덤 마스크층을 설정하는 동작은,상기 가변 차원의 유형이 입력 차원이 가변적인 경우, 상기 제1 신경망의 입력층 앞에 랜덤 마스크층을 설정하는 동작을 포함하는 것을 특징으로 하는 전자 기기."}
{"patent_id": "10-2024-7024886", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_25", "content": "제23항에 있어서,상기 가변 차원의 유형에 따라 제1 신경망에 랜덤 마스크층을 설정하는 동작은,상기 가변 차원의 유형이 출력 차원이 가변적인 경우, 상기 제1 신경망의 출력층 뒤에 랜덤 마스크층을 설정하는 동작을 포함하는 것을 특징으로 하는 전자 기기."}
{"patent_id": "10-2024-7024886", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_26", "content": "제23항에 있어서,상기 가변 차원의 유형에 따라 제1 신경망에 랜덤 마스크층을 설정하는 동작은,상기 가변 차원의 유형이 중간 차원이 가변적인 경우, 상기 제1 신경망의 중간층에 랜덤 마스크층을 설정하는공개특허 10-2024-0128945-6-동작을 포함하는 것을 특징으로 하는 전자 기기."}
{"patent_id": "10-2024-7024886", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_27", "content": "제26항에 있어서,상기 제1 신경망의 중간층에 랜덤 마스크층을 설정하는 동작은,하나의 중간 차원만 가변적인 경우, 연관된 중간층의 앞이나 뒤에 하나의 랜덤 마스크층을 설정하는 동작을 포함하는 것을 특징으로 하는 전자 기기."}
{"patent_id": "10-2024-7024886", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_28", "content": "제26항에 있어서,상기 제1 신경망의 중간층에 랜덤 마스크층을 설정하는 동작은,복수의 중간 차원이 가변적인 경우, 각 연관된 중간층의 앞이나 뒤에 각각 하나의 랜덤 마스크층을 설정하는 동작을 포함하는 것을 특징으로 하는 전자 기기."}
{"patent_id": "10-2024-7024886", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_29", "content": "제22항에 있어서,상기 샘플 데이터를 이용하여 상기 제2 신경망을 훈련시키는 동작은,각 샘플 데이터의 입력 데이터의 차원이 모두 제1 임계값인 경우, 전체 샘플 데이터를 직접 이용하여 상기 제2신경망을 훈련시키는 동작을 포함하며, 상기 제1 임계값은 전체 샘플 데이터의 입력 데이터 차원의 최대값인 것을 특징으로 하는 전자 기기."}
{"patent_id": "10-2024-7024886", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_30", "content": "제22항에 있어서,상기 샘플 데이터를 이용하여 상기 제2 신경망을 훈련시키는 동작은,적어도 하나의 제1 샘플 데이터가 존재하는 경우, 우선 상기 제1 샘플 데이터에 대해 증강 처리를 수행하고, 다음 전체 제1 샘플 데이터와 전체 제2 샘플 데이터를 이용하여 상기 제2 신경망을 훈련시키는 동작을 포함하며,상기 제1 샘플 데이터는 입력 데이터의 차원이 제1 임계값이 아닌 샘플 데이터이고, 상기 제2 샘플 데이터는 입력 데이터의 차원이 상기 제1 임계값인 샘플 데이터이고, 상기 제1 임계값은 전체 샘플 데이터의 입력 데이터차원의 최대값인 것을 특징으로 하는 전자 기기."}
{"patent_id": "10-2024-7024886", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_31", "content": "제30항에 있어서,상기 제1 샘플 데이터에 대해 증강 처리를 수행하는 동작은,상기 제1 샘플 데이터의 입력 데이터에 대해 하이 비트 제로 패딩(high-bit zero padding)을 수행하는 동작을포함하는 것을 특징으로 하는 전자 기기."}
{"patent_id": "10-2024-7024886", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_32", "content": "제30항에 있어서,상기 제1 샘플 데이터에 대해 증강 처리를 수행하는 동작은,상기 제1 샘플 데이터의 입력 데이터에 대해 로우 비트 제로 패딩(low-bit zero padding)을 수행하는 동작을 포함하는 것을 특징으로 하는 전자 기기."}
{"patent_id": "10-2024-7024886", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_33", "content": "제22항에 있어서,공개특허 10-2024-0128945-7-상기 샘플 데이터를 이용하여 상기 제2 신경망을 훈련시키는 동작은,적어도 하나의 제1 샘플 데이터가 존재하는 경우, 우선 상기 제1 샘플 데이터를 제거하고, 다음 전체 제2 샘플데이터를 이용하여 상기 제2 신경망을 훈련시키는 동작을 포함하며, 상기 제1 샘플 데이터는 입력 데이터의 차원이 제1 임계값이 아닌 샘플 데이터이며, 상기 제2 샘플 데이터는 입력 데이터의 차원이 제1 임계값인 샘플 데이터이며, 상기 제1 임계값은 전체 샘플 데이터의 입력 데이터 차원의 최대값인 것을 특징으로 하는 전자 기기."}
{"patent_id": "10-2024-7024886", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_34", "content": "제22항에 있어서,상기 랜덤 마스크층에 입력되는 텐서에 대해 랜덤 마스크 처리를 진행하는 동작은,상기 랜덤 마스크층에 입력되는 텐서 및 랜덤 마스크 텐서를 결정하는 동작; 및상기 랜덤 마스크 텐서를 이용하여 상기 랜덤 마스크층에 입력되는 텐서에 대해 랜덤 마스크 처리를 진행하는동작;을 포함하는 것을 특징으로 하는 전자 기기."}
{"patent_id": "10-2024-7024886", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_35", "content": "제34항에 있어서,상기 랜덤 마스크층에 입력되는 텐서에 대해 랜덤 마스크 처리를 진행하기 위한 표현식은,이고,는 랜덤 마스크층에서 출력되는 텐서를 나타내고, X는 랜덤 마스크층에 입력되는 텐서를 나타내며, 는 텐서에 대한 비트별 포인트 곱셈 연산(bitwise point multiplication operation)을 나타내고, M은 랜덤 마스크텐서를 나타내는 것을 특징으로 하는 전자 기기."}
{"patent_id": "10-2024-7024886", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_36", "content": "제34항에 있어서,상기 랜덤 마스크 텐서는 하드 마스킹 텐서인 것을 특징으로 하는 전자 기기."}
{"patent_id": "10-2024-7024886", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_37", "content": "제34항에 있어서,상기 랜덤 마스크 텐서는 소프트 마스킹 텐서인 것을 특징으로 하는 전자 기기."}
{"patent_id": "10-2024-7024886", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_38", "content": "제34항에 있어서,상기 랜덤 마스크 텐서는 하드 마스킹 텐서와 소프트 마스킹 텐서의 조합으로 형성된 것을 특징으로 하는 전자기기."}
{"patent_id": "10-2024-7024886", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_39", "content": "제22항에 있어서,상기 샘플 데이터를 이용하여 상기 제2 신경망을 훈련시키는 동작 이후에,훈련된 제2 신경망의 랜덤 마스크층을 텐서 변환층으로 업데이트하는 동작을 더 포함하며, 상기 텐서 변환층은상기 텐서 변환층에 입력되는 텐서에 대해 차원 변환을 수행하는 데 사용되는 것을 특징으로 하는 전자 기기."}
{"patent_id": "10-2024-7024886", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_40", "content": "제39항에 있어서,공개특허 10-2024-0128945-8-상기 훈련된 제2 신경망의 랜덤 마스크층을 텐서 변환층으로 업데이트하는 동작은,훈련된 제2 신경망의 입력층 앞에 랜덤 마스크층이 존재하는 경우, 훈련된 제2 신경망의 입력층의 앞에 있는 랜덤 마스크층을 텐서 패딩층으로 업데이트하는 동작을 포함하며, 상기 텐서 패딩층은 상기 텐서 패딩층에 입력되는 텐서의 차원을 제1 임계값으로 증가하는 데 사용되고, 상기 제1 임계값은 전체 샘플 데이터의 입력 데이터차원의 최대값인 것을 특징으로 하는 전자 기기."}
{"patent_id": "10-2024-7024886", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_41", "content": "제39항에 있어서,상기 훈련된 제2 신경망의 랜덤 마스크층을 텐서 변환층으로 업데이트하는 동작은,훈련된 제2 신경망의 출력층 뒤에 랜덤 마스크층이 존재하는 경우, 훈련된 제2 신경망의 출력층의 뒤에 있는 랜덤 마스크층을 텐서 크로핑층으로 업데이트하는 동작을 포함하며, 상기 텐서 크로핑층은 상기 텐서 크로핑층에입력되는 텐서의 차원을 제1 목표값으로 감소하는 데 사용되는 것을 특징으로 하는 전자 기기."}
{"patent_id": "10-2024-7024886", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_42", "content": "제39항에 있어서,상기 훈련된 제2 신경망의 랜덤 마스크층을 텐서 변환층으로 업데이트하는 동작은,훈련된 제2 신경망의 중간층에 랜덤 마스크층이 존재하는 경우, 훈련된 제2 신경망의 중간층에 있는 랜덤 마스크층을 텐서 크로핑 캐스케이드 텐서 패딩 층으로 업데이트하는 동작을 포함하며, 상기 텐서 크로핑 캐스케이드텐서 패딩 층은 상기 텐서 크로핑 캐스케이드 텐서 패딩 층에 입력되는 텐서의 차원을 제2 목표값으로 감소한후 원래의 차원으로 증가하는 데 사용되는 것을 특징으로 하는 전자 기기."}
{"patent_id": "10-2024-7024886", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_43", "content": "예측 데이터를 획득하는 단계; 배치된 타겟 신경망에 상기 예측 데이터를 입력하여 상기 타겟 신경망으로부터 출력된 예측 결과를 얻는 단계를포함하며, 상기 타겟 신경망은 적어도 하나의 텐서 변환층을 포함하고, 상기 텐서 변환층은 상기 텐서 변환층에입력되는 텐서에 대해 차원 변환을 수행하는 데 사용되는 것을 특징으로 하는 신경망 동작 방법."}
{"patent_id": "10-2024-7024886", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_44", "content": "제43항에 있어서,상기 타겟 신경망은 제1항 내지 제21항 중 어느 한 항에 따른 제2 신경망인 것을 특징으로 하는 신경망 동작 방법."}
{"patent_id": "10-2024-7024886", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_45", "content": "메모리, 송수신기, 프로세서를 포함하고,메모리는 컴퓨터 프로그램을 저장하는 데 사용되고, 송수신기는 상기 프로세서의 제어에 따라 데이터를 송수신하는 데 사용되며, 프로세서는 상기 메모리에 있는 컴퓨터 프로그램을 리드하여,예측 데이터를 획득하는 동작; 및배치된 타겟 신경망에 상기 예측 데이터를 입력하여 상기 타겟 신경망으로부터 출력된 예측 결과를 얻는 동작;을 수행하는 데 사용되며, 상기 타겟 신경망은 적어도 하나의 텐서 변환층을 포함하고, 상기 텐서 변환층은 상기 텐서 변환층에 입력되는 텐서에 대해 차원 변환을 수행하는 데 사용되는 것을 특징으로 하는 전자 기기."}
{"patent_id": "10-2024-7024886", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_46", "content": "제45항에 있어서,상기 타겟 신경망은 제1항 내지 제21항 중 어느 한 항에 따른 제2 신경망인 것을 특징으로 하는 전자 기기.공개특허 10-2024-0128945-9-청구항 47 가변 차원의 유형에 따라 제1 신경망에 랜덤 마스크층을 추가하여 제2 신경망을 획득하는 데 사용되는 추가 모듈 - 상기 랜덤 마스크층은 상기 랜덤 마스크층에 입력되는 텐서에 대해 랜덤 마스크 처리를 진행하는 데 사용됨 -; 및샘플 데이터를 이용하여 상기 제2 신경망을 훈련시키는 데 사용되는 훈련 모듈;을 포함하는 것을 특징으로 하는신경망 동작 장치."}
{"patent_id": "10-2024-7024886", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_48", "content": "제47항에 있어서,상기 가변 차원의 유형은,입력 차원이 가변적인 것;출력 차원이 가변적인 것; 또는중간 차원이 가변적인 것; 중 하나 이상을 포함하는 것을 특징으로 하는 신경망 동작 장치."}
{"patent_id": "10-2024-7024886", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_49", "content": "제48항에 있어서,상기 추가 모듈은,상기 가변 차원의 유형이 입력 차원이 가변적인 경우, 상기 제1 신경망의 입력층 앞에 랜덤 마스크층을 추가하는 데 사용되는 것을 특징으로 하는 신경망 동작 장치."}
{"patent_id": "10-2024-7024886", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_50", "content": "제48항에 있어서,상기 추가 모듈은,상기 가변 차원의 유형이 출력 차원이 가변적인 경우, 상기 제1 신경망의 출력층 뒤에 랜덤 마스크층을 추가하는 데 사용되는 것을 특징으로 하는 신경망 동작 장치."}
{"patent_id": "10-2024-7024886", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_51", "content": "제48항에 있어서,상기 추가 모듈은,상기 가변 차원의 유형이 중간 차원이 가변적인 경우, 상기 제1 신경망의 중간층에 랜덤 마스크층을 추가하는데 사용되는 것을 특징으로 하는 신경망 동작 장치."}
{"patent_id": "10-2024-7024886", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_52", "content": "제51항에 있어서,상기 추가 모듈은,하나의 중간 차원만 가변적인 경우, 연관된 중간층 앞이나 뒤에 하나의 랜덤 마스크층을 추가하는 데 사용되는것을 특징으로 하는 신경망 동작 장치."}
{"patent_id": "10-2024-7024886", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_53", "content": "제51항에 있어서,상기 추가 모듈은,복수의 중간 차원이 가변적인 경우, 각 연관된 중간층의 앞이나 뒤에 각각 하나의 랜덤 마스크층을 추가하는 데사용되는 것을 특징으로 하는 신경망 동작 장치.공개특허 10-2024-0128945-10-청구항 54 제47항에 있어서,상기 훈련 모듈은,각 샘플 데이터의 입력 데이터의 차원이 모두 제1 임계값인 경우, 전체 샘플 데이터를 직접 이용하여 상기 제2신경망을 훈련시키는 데 사용되며, 상기 제1 임계값은 전체 샘플 데이터의 입력 데이터 차원의 최대값인 것을특징으로 하는 신경망 동작 장치."}
{"patent_id": "10-2024-7024886", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_55", "content": "제47항에 있어서,상기 훈련 모듈은,적어도 하나의 제1 샘플 데이터가 존재하는 경우, 우선 상기 제1 샘플 데이터에 대해 증강 처리를 수행하고, 다음 전체 제1 샘플 데이터와 전체 제2 샘플 데이터를 이용하여 상기 제2 신경망을 훈련시키는 데 사용되며, 상기제1 샘플 데이터는 입력 데이터의 차원이 제1 임계값이 아닌 샘플 데이터이고, 상기 제2 샘플 데이터는 입력 데이터의 차원이 상기 제1 임계값인 샘플 데이터이고, 상기 제1 임계값은 전체 샘플 데이터의 입력 데이터 차원의최대값인 것을 특징으로 하는 신경망 동작 장치."}
{"patent_id": "10-2024-7024886", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_56", "content": "제55항에 있어서,상기 훈련 모듈은,상기 제1 샘플 데이터의 입력 데이터에 대해 하이 비트 제로 패딩을 수행하는 데 사용되는 것을 특징으로 하는신경망 동작 장치."}
{"patent_id": "10-2024-7024886", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_57", "content": "제55항에 있어서,상기 훈련 모듈은,상기 제1 샘플 데이터의 입력 데이터에 대해 로우 비트 제로 패딩을 수행하는 데 사용되는 것을 특징으로 하는신경망 동작 장치."}
{"patent_id": "10-2024-7024886", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_58", "content": "제47항에 있어서,상기 훈련 모듈은,적어도 하나의 제1 샘플 데이터가 존재하는 경우, 우선 상기 제1 샘플 데이터를 제거하고, 다음 전체 제2 샘플데이터를 이용하여 상기 제2 신경망을 훈련시키는 데 사용되며, 상기 제1 샘플 데이터는 입력 데이터의 차원이제1 임계값이 아닌 샘플 데이터이며, 상기 제2 샘플 데이터는 입력 데이터의 차원이 상기 제1 임계값인 샘플 데이터이며, 상기 제1 임계값은 전체 샘플 데이터의 입력 데이터 차원의 최대값인 것을 특징으로 하는 신경망 동작 장치."}
{"patent_id": "10-2024-7024886", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_59", "content": "제47항에 있어서,상기 훈련 모듈은,상기 랜덤 마스크층에 입력되는 텐서 및 랜덤 마스크 텐서를 결정하며;상기 랜덤 마스크 텐서를 이용하여 상기 랜덤 마스크층에 입력되는 텐서에 대해 랜덤 마스크 처리를 진행하는데 사용되는 것을 특징으로 하는 신경망 동작 장치.공개특허 10-2024-0128945-11-청구항 60 제59항에 있어서,상기 랜덤 마스크층에 입력되는 텐서에 대해 랜덤 마스크 처리를 진행하기 위한 표현식은,이며,는 랜덤 마스크층에서 출력되는 텐서를 나타내고, X는 랜덤 마스크층에 입력되는 텐서를 나타내며, 는 텐서에 대한 비트별 포인트 곱셈 연산을 나타내고, M은 랜덤 마스크 텐서를 나타내는 것을 특징으로 하는 신경망동작 장치."}
{"patent_id": "10-2024-7024886", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_61", "content": "제59항에 있어서,상기 랜덤 마스크 텐서는 하드 마스킹 텐서인 것을 특징으로 하는 신경망 동작 장치."}
{"patent_id": "10-2024-7024886", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_62", "content": "제59항에 있어서,상기 랜덤 마스크 텐서는 소프트 마스킹 텐서인 것을 특징으로 하는 신경망 동작 장치."}
{"patent_id": "10-2024-7024886", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_63", "content": "제59항에 있어서,상기 랜덤 마스크 텐서는 하드 마스킹 텐서와 소프트 마스킹 텐서의 조합으로 형성되는 것을 특징으로 하는 신경망 동작 장치."}
{"patent_id": "10-2024-7024886", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_64", "content": "제47항에 있어서, 배치 모듈을 더 포함하고,상기 배치 모듈은 훈련된 제2 신경망의 랜덤 마스크층을 텐서 변환층으로 대체하는 데 사용되고, 상기 텐서 변환층은 상기 텐서 변환층에 입력되는 텐서에 대해 차원 변환을 수행하는 데 사용되는 것을 특징으로 하는 신경망 동작 장치."}
{"patent_id": "10-2024-7024886", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_65", "content": "제64항에 있어서,상기 배치 모듈은,훈련된 제2 신경망의 입력층 앞에 랜덤 마스크층이 존재하는 경우, 훈련된 제2 신경망의 입력층 앞에 있는 랜덤마스크층을 텐서 패딩층으로 대체하는 데 사용되며, 상기 텐서 패딩층은 상기 텐서 패딩층에 입력되는 텐서의차원을 제1 임계값으로 증가하는 데 사용되고, 상기 제1 임계값은 전체 샘플 데이터의 입력 데이터 차원의 최대값인 것을 특징으로 하는 신경망 동작 장치."}
{"patent_id": "10-2024-7024886", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_66", "content": "제64항에 있어서,상기 배치 모듈은,훈련된 제2 신경망의 출력층 뒤에 랜덤 마스크층이 존재하는 경우, 훈련된 제2 신경망의 출력층 뒤에 있는 랜덤마스크층을 텐서 크로핑층으로 대체하는데 사용되고, 상기 텐서 크로핑층은 상기 텐서 크로핑층에 입력되는 텐서의 차원을 제1 목표값으로 감소하는 데 사용되는 것을 특징으로 하는 신경망 동작 장치."}
{"patent_id": "10-2024-7024886", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_67", "content": "공개특허 10-2024-0128945-12-제64항에 있어서,상기 배치 모듈은,훈련된 제2 신경망의 중간층에 랜덤 마스크층이 존재하는 경우, 훈련된 제2 신경망의 중간층에 있는 랜덤 마스크층을 텐서 크로핑 캐스케이드 텐서 패딩 층으로 대체하는 데 사용되고, 상기 텐서 크로핑 캐스케이드 텐서 패딩 층은 상기 텐서 크로핑 캐스케이드 텐서 패딩 층에 입력되는 텐서의 차원을 제2 목표값으로 감소한 후 원래차원으로 증가하는 데 사용되는 것을 특징으로 하는 신경망 동작 장치."}
{"patent_id": "10-2024-7024886", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_68", "content": "예측 데이터를 획득하는 획득 모듈;배치된 타겟 신경망에 상기 예측 데이터를 입력하여 상기 타겟 신경망으로부터 출력된 예측 결과를 얻는 처리모듈을 포함하며, 상기 타겟 신경망은 적어도 하나의 텐서 변환층을 포함하고, 상기 텐서 변환층은 상기 텐서변환층에 입력되는 텐서에 대해 차원 변환을 수행하는 데 사용되는 것을 특징으로 하는 신경망 동작 장치."}
{"patent_id": "10-2024-7024886", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_69", "content": "제68항에 있어서,상기 타겟 신경망은 제47항 내지 제67항 중 어느 한 항에 따른 제2 신경망인 것을 특징으로 하는 신경망 동작장치."}
{"patent_id": "10-2024-7024886", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_70", "content": "컴퓨터로 하여금 제1항 내지 제21항 중 어느 한 항에 따른 신경망 동작 방법, 또는 제43항 내지 제44항 중 어느한 항에 따른 신경망 동작 방법을 수행하게 하는 컴퓨터 프로그램이 저장된 컴퓨터 판독 가능한 저장 매체."}
{"patent_id": "10-2024-7024886", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 개시의 실시예는 신경망 동작 방법, 장치 및 저장 매체를 제공한다. 상기 동작 방법은 가변 차원의 유형에 따 라 제1 신경망에 랜덤 마스크층을 추가하여 제2 신경망을 획득하는 단계 - 상기 랜덤 마스크층은 상기 랜덤 마스 크층에 입력되는 텐서에 대해 랜덤 마스크 처리를 진행하는 데 사용됨-; 및 샘플 데이터를 이용하여 상기 제2 신 경망을 훈련시키는 단계를 포함한다. 본 개시의 실시예에서 제공되는 신경망 동작 방법, 장치 및 저장 매체에 따 르면, 신경망에 랜덤 마스크층을 추가함으로써, 단 하나의 신경망만을 훈련 및 배치하여 서로 다른 입력 및 출력 차원 요구에 적응하며, 상기 방법은 훈련 복잡도가 낮고 저장 오버헤드가 낮으며, 배치 및 온라인 훈련 지속적인 진화에 도움이 된다."}
{"patent_id": "10-2024-7024886", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 출원은 2021년 12월 23일자로 출원되고 출원 번호가 202111593613.7이며 발명의 명칭이 \"신경망 훈련 및 배 치 방법, 장치 및 저장 매체\"인 중툭특허출원 및 2022년 01월 13일자로 출원되고 출원 번호가 202210039452.5이 며 발명의 명칭이 \"신경망 동작 방법, 장치 및 저장 매체\"인 중국특허출원의 우선권을 주장하며, 이는 인용을 통해 전체 내용이 본 문에 포함된다. 본 개시는 통신 기술 분야에 관한 것이며, 특히 신경망 동작 방법, 장치 및 저장 매체에 관한 것이다."}
{"patent_id": "10-2024-7024886", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "신경망의 입력 차원(일부 데이터의 수집으로 인해 입력 차원이 다름) 및/또는 출력 차원이 불확실한 경우, 모든 가능한 입력 및/또는 출력 차원 각각에 대해 하나의 신경망을 훈련하여 다양한 차원과 작업 수요에 대처해야 한 다. 도 1은 종래 기술에 따른 차원 가변 신경망의 훈련 방법의 개략도이다. 도 1에 도시된 바와 같이, 종래의 실행 가능한 솔루션으로서 서로 다른 입력 차원 각각에 대해 하나의 신경망을 훈련시키는 것이다. 도 1에 도시된 바 와 같이, 시스템은 입력 차원에 따라 대응되는 신경망을 자동으로 선택하여 예측을 수행하며, 입력 차원이 계속 증가함(수집된 실시간 데이터가 부분에서 완전으로 변경됨)에 따라 신경망의 예측값은 점차 \"러프함(rough)\"에 서 \"정확함(accurate)\"으로 변경된다. 하지만, 상기 솔루션에서 신경망의 수는 차원의 가능한 상황이 증가함에 따라 증가하며, 신경망(모델) 훈련의 복잡도가 높고 모델 저장 오버헤드가 커서 실제 배치와 신경망 온라인 학습의 지속적인 진화에 불리하다. 본 개시의 실시예는 종래 기술의 신경망의 수가 차원의 가능한 상황이 증가함에 따라 증가하는 기술적 과제를 해결하는 신경망 동작 방법, 장치 및 저장 매체를 제공한다.제1 측면으로, 본 개시의 실시예는 신경망 동작 방법을 제공하며, 상기 방법은, 가변 차원의 유형에 따라 제1 신경망에 랜덤 마스크층을 추가하여 제2 신경망을 획득하는 단계 - 상기 랜덤 마 스크층은 상기 랜덤 마스크층에 입력되는 텐서에 대해 랜덤 마스크 처리를 진행하는 데 사용됨-; 및 샘플 데이터를 이용하여 상기 제2 신경망을 훈련시키는 단계를 포함한다. 일부 실시예에서, 상기 가변 차원의 유형은, 입력 차원이 가변적인 것; 출력 차원이 가변적인 것; 또는 중간 차원이 가변적인 것; 중 하나 이상을 포함한다. 일부 실시예에서, 가변 차원의 유형에 따라 제1 신경망에 랜덤 마스크층을 추가하는 단계는, 상기 가변 차원의 유형이 입력 차원이 가변적인 경우, 상기 제1 신경망의 입력층 앞에 랜덤 마스크층을 추가하 는 단계를 포함한다. 일부 실시예에서, 가변 차원의 유형에 따라 제1 신경망에 랜덤 마스크층을 추가하는 단계는, 상기 가변 차원의 유형이 출력 차원이 가변적인 경우, 상기 제1 신경망의 출력층 뒤에 랜덤 마스크층을 추가하 는 단계를 포함한다. 일부 실시예에서, 가변 차원의 유형에 따라 제1 신경망에 랜덤 마스크층을 추가하는 단계는, 상기 가변 차원의 유형이 중간 차원이 가변적인 경우, 상기 제1 신경망의 중간층에 랜덤 마스크층을 추가하는 단계를 포함한다. 일부 실시예에서, 상기 제1 신경망의 중간층에 랜덤 마스크층을 추가하는 단계는, 하나의 중간 차원만 가변적인 경우, 연관된 중간층 앞이나 뒤에 하나의 랜덤 마스크층을 추가하는 단계를 포함 한다. 일부 실시예에서, 상기 제1 신경망의 중간층에 랜덤 마스크층을 추가하는 단계는, 복수의 중간 차원이 가변적인 경우, 각 연관된 중간층 앞이나 뒤에 각각 하나의 랜덤 마스크층을 추가하는 단계 를 포함한다. 일부 실시예에서, 샘플 데이터를 이용하여 상기 제2 신경망을 훈련시키는 단계는, 각 샘플 데이터의 입력 데이터의 차원이 모두 제1 임계값인 경우, 전체 샘플 데이터를 직접 이용하여 상기 제2 신경망을 훈련시키는 단계를 포함하며, 상기 제1 임계값은 전체 샘플 데이터의 입력 데이터 차원의 최대값이다. 일부 실시예에서, 샘플 데이터를 이용하여 상기 제2 신경망을 훈련시키는 단계는, 적어도 하나의 제1 샘플 데이터가 존재하는 경우, 우선 상기 제1 샘플 데이터에 대해 증강 처리를 수행하고, 다 음 전체 제1 샘플 데이터와 전체 제2 샘플 데이터를 이용하여 상기 제2 신경망을 훈련시키는 단계를 포함하며, 상기 제1 샘플 데이터는 입력 데이터의 차원이 제1 임계값이 아닌 샘플 데이터이고, 상기 제2 샘플 데이터는 입 력 데이터의 차원이 상기 제1 임계값인 샘플 데이터이고, 상기 제1 임계값은 전체 샘플 데이터의 입력 데이터 차원의 최대값이다. 일부 실시예에서, 상기 제1 샘플 데이터에 대해 증강 처리를 수행하는 단계는, 상기 제1 샘플 데이터의 입력 데이터에 대해 하이 비트 제로 패딩을 수행하는 단계를 포함한다. 일부 실시예에서, 상기 제1 샘플 데이터에 대해 증강 처리를 수행하는 단계는, 상기 제1 샘플 데이터의 입력 데이터에 대해 로우 비트 제로 패딩을 수행하는 단계를 포함한다. 일부 실시예에서, 샘플 데이터를 이용하여 상기 제2 신경망을 훈련시키는 단계는, 적어도 하나의 제1 샘플 데이터가 존재하는 경우, 우선 상기 제1 샘플 데이터를 제거하고, 다음 전체 제2 샘플 데이터를 이용하여 상기 제2 신경망을 훈련시키는 단계를 포함하며, 상기 제1 샘플 데이터는 입력 데이터의 차 원이 제1 임계값이 아닌 샘플 데이터이며, 상기 제2 샘플 데이터는 입력 데이터의 차원이 제1 임계값인 샘플 데이터이며, 상기 제1 임계값은 전체 샘플 데이터의 입력 데이터 차원의 최대값이다. 일부 실시예에서, 상기 랜덤 마스크층에 입력되는 텐서에 대해 랜덤 마스크 처리를 진행하는 단계는, 상기 랜덤 마스크층에 입력되는 텐서 및 랜덤 마스크 텐서를 결정하는 단계; 및 상기 랜덤 마스크 텐서를 이용하여 상기 랜덤 마스크층에 입력되는 텐서에 대해 랜덤 마스크 처리를 진행하는 단계를 포함한다. 일부 실시예에서, 상기 랜덤 마스크층에 입력되는 텐서에 대해 랜덤 마스크 처리를 진행하기 위한 표현식은, 이고, 는 랜덤 마스크층에서 출력되는 텐서를 나타내고, X는 랜덤 마스크층에 입력되는 텐서를 나타내며, 는 텐 서에 대한 비트별 포인트 곱셈 연산을 나타내고, M은 랜덤 마스크 텐서를 나타낸다. 일부 실시예에서, 상기 랜덤 마스크 텐서는 하드 마스킹 텐서이다. 일부 실시예에서, 상기 랜덤 마스크 텐서는 소프트 마스킹 텐서이다. 일부 실시예에서, 상기 랜덤 마스크 텐서는 하드 마스킹 텐서와 소프트 마스킹 텐서의 조합으로 형성된다. 일부 실시예에서, 샘플 데이터를 이용하여 상기 제2 신경망을 훈련시키는 단계 이후에, 훈련된 제2 신경망의 랜덤 마스크층을 텐서 변환층으로 대체하는 단계를 더 포함하며, 상기 텐서 변환층은 상기 텐서 변환층에 입력되는 텐서에 대해 차원 변환을 수행하는 데 사용된다. 일부 실시예에서, 훈련된 제2 신경망의 랜덤 마스크층을 텐서 변환층으로 업데이트하는 단계는, 훈련된 제2 신경망의 입력층 앞에 랜덤 마스크층이 존재하는 경우, 훈련된 제2 신경망의 입력층 앞에 있는 랜덤 마스크층을 텐서 패딩층으로 대체하는 단계를 포함하고, 상기 텐서 패딩층은 상기 텐서 패딩층에 입력되는 텐서 의 차원을 제1 임계값으로 증가하는 데 사용되고, 상기 제1 임계값은 전체 샘플 데이터의 입력 데이터 차원의 최대값이다. 일부 실시예에서, 훈련된 제2 신경망의 랜덤 마스크층을 텐서 변환층으로 대체하는 단계는, 훈련된 제2 신경망의 출력층 뒤에 랜덤 마스크층이 존재하는 경우, 훈련된 제2 신경망의 출력층 뒤에 있는 랜덤 마스크층을 텐서 크로핑층으로 대체하는 단계를 포함하고, 상기 텐서 크로핑층은 상기 텐서 크로핑층에 입력되 는 텐서의 차원을 제1 목표값으로 감소하는 데 사용된다. 일부 실시예에서, 훈련된 제2 신경망의 랜덤 마스크층을 텐서 변환층으로 대체하는 단계는, 훈련된 제2 신경망의 중간층에 랜덤 마스크층이 존재하는 경우, 훈련된 제2 신경망의 중간층에 있는 랜덤 마스 크층을 텐서 크로핑 캐스케이드 텐서 패딩 층으로 대체하는 단계를 포함하고, 상기 텐서 크로핑 캐스케이드 텐 서 패딩 층은 상기 텐서 크로핑 캐스케이드 텐서 패딩 층에 입력되는 텐서의 차원을 제2 목표값으로 감소한 후 원래 차원으로 증가하는 데 사용된다. 제2 측면으로, 본 개시의 실시예는 전자 기기를 제공하고, 상기 전자 기기는 메모리, 송수신기, 프로세서를 포 함하고, 메모리는 컴퓨터 프로그램을 저장하는 데 사용되고, 송수신기는 상기 프로세서의 제어에 따라 데이터를 송수신 하는 데 사용되며, 프로세서는 상기 메모리에 있는 컴퓨터 프로그램을 리드하여, 일부 실시예에서, 상기 가변 차원의 유형은, 입력 차원이 가변적인 것; 출력 차원이 가변적인 것; 또는 중간 차원이 가변적인 것; 중 하나 이상을 포함한다. 일부 실시예에서, 가변 차원의 유형에 따라 제1 신경망에 랜덤 마스크층을 추가하는 동작은, 상기 가변 차원의 유형이 입력 차원이 가변적인 경우, 상기 제1 신경망의 입력층 앞에 랜덤 마스크층을 추가하 는 동작을 포함한다. 일부 실시예에서, 가변 차원의 유형에 따라 제1 신경망에 랜덤 마스크층을 추가하는 동작은 상기 가변 차원의 유형이 출력 차원이 가변적인 경우, 상기 제1 신경망의 출력층 뒤에 랜덤 마스크층을 추가하 는 동작을 포함한다. 일부 실시예에서, 가변 차원의 유형에 따라 제1 신경망에 랜덤 마스크층을 추가하는 동작은, 상기 가변 차원의 유형이 중간 차원이 가변적인 경우, 상기 제1 신경망의 중간층에 랜덤 마스크층을 추가하는 동작을 포함한다. 일부 실시예에서, 상기 제1 신경망의 중간층에 랜덤 마스크층을 추가하는 동작은, 하나의 중간 차원만 가변적인 경우, 연관된 중간층의 앞이나 뒤에 하나의 랜덤 마스크층을 추가하는 동작을 포 함한다. 일부 실시예에서, 상기 제1 신경망의 중간층에 랜덤 마스크층을 추가하는 동작은, 복수의 중간 차원이 가변적인 경우, 각 연관된 중간층의 앞이나 뒤에 각각 하나의 랜덤 마스크층을 추가하는 동 작을 포함한다. 일부 실시예에서, 샘플 데이터를 이용하여 상기 제2 신경망을 훈련시키는 동작은, 각 샘플 데이터의 입력 데이터의 차원이 모두 제1 임계값인 경우, 전체 샘플 데이터를 직접 이용하여 상기 제2 신경망을 훈련시키는 동작을 포함하며, 상기 제1 임계값은 전체 샘플 데이터의 입력 데이터 차원의 최대값이다. 일부 실시예에서, 샘플 데이터를 이용하여 상기 제2 신경망을 훈련시키는 동작은, 적어도 하나의 제1 샘플 데이터가 존재하는 경우, 우선 상기 제1 샘플 데이터에 대해 증강 처리를 수행하고, 다 음 전체 제1 샘플 데이터와 전체 제2 샘플 데이터를 이용하여 상기 제2 신경망을 훈련시키는 동작을 포함하며, 상기 제1 샘플 데이터는 입력 데이터의 차원이 제1 임계값이 아닌 샘플 데이터이고, 상기 제2 샘플 데이터는 입 력 데이터의 차원이 상기 제1 임계값인 샘플 데이터이고, 상기 제1 임계값은 전체 샘플 데이터의 입력 데이터 차원의 최대값이다. 일부 실시예에서, 상기 제1 샘플 데이터에 대해 증강 처리를 수행하는 동작은, 상기 제1 샘플 데이터의 입력 데이터에 대해 하이 비트 제로 패딩을 수행하는 동작을 포함한다. 일부 실시예에서, 상기 제1 샘플 데이터에 대해 증대 처리를 수행하는 동작은, 상기 제1 샘플 데이터의 입력 데이터에 대해 로우 비트 제로 패딩을 수행하는 동작을 포함한다. 일부 실시예에서, 샘플 데이터를 이용하여 상기 제2 신경망을 훈련시키는 동작은, 적어도 하나의 제1 샘플 데이터가 존재하는 경우, 우선 상기 제1 샘플 데이터를 제거하고, 다음 전체 제2 샘플 데이터를 이용하여 상기 제2 신경망을 훈련시키는 동작을 포함하며, 상기 제1 샘플 데이터는 입력 데이터의 차 원이 제1 임계값이 아닌 샘플 데이터이며, 상기 제2 샘플 데이터는 입력 데이터의 차원이 제1 임계값인 샘플 데 이터이며, 상기 제1 임계값은 전체 샘플 데이터의 입력 데이터 차원의 최대값이다. 일부 실시예에서, 상기 랜덤 마스크층에 입력되는 텐서에 대해 랜덤 마스크 처리를 진행하는 동작은, 상기 랜덤 마스크층에 입력되는 텐서 및 랜덤 마스크 텐서를 결정하는 동작; 및 상기 랜덤 마스크 텐서를 이용하여 상기 랜덤 마스크층에 입력되는 텐서에 대해 랜덤 마스크 처리를 진행하는 동작을 포함한다. 일부 실시예에서, 상기 랜덤 마스크층에 입력되는 텐서에 대해 랜덤 마스크 처리를 진행하기 위한 표현식은, 이고, 는 랜덤 마스크층에서 출력되는 텐서를 나타내고, X는 랜덤 마스크층에 입력되는 텐서를 나타내며, 는 텐 서에 대한 비트별 포인트 곱셈 연산을 나타내고, M은 랜덤 마스크 텐서를 나타낸다.일부 실시예에서, 상기 랜덤 마스크 텐서는 하드 마스킹 텐서이다. 일부 실시예에서, 상기 랜덤 마스크 텐서는 소프트 마스킹 텐서이다. 일부 실시예에서, 상기 랜덤 마스크 텐서는 하드 마스킹 텐서와 소프트 마스킹 텐서의 조합으로 형성된다. 일부 실시예에서, 샘플 데이터를 이용하여 상기 제2 신경망을 훈련시키는 동작 이후에, 훈련된 제2 신경망의 랜덤 마스크층을 텐서 변환층으로 대체하는 동작을 더 포함하며, 상기 텐서 변환층은 상기 텐서 변환층에 입력되는 텐서에 대해 차원 변환을 수행하는 데 사용된다. 일부 실시예에서, 훈련된 제2 신경망의 랜덤 마스크층을 텐서 변환층으로 대체하는 동작은, 훈련된 제2 신경망의 입력층 앞에 랜덤 마스크층이 존재하는 경우, 훈련된 제2 신경망의 입력층의 앞에 있는 랜 덤 마스크층을 텐서 패딩층으로 대체하는 동작을 포함하며, 상기 텐서 패딩층은 상기 텐서 패딩층에 입력되는 텐서의 차원을 제1 임계값으로 증가하는 데 사용되고, 상기 제1 임계값은 전체 샘플 데이터의 입력 데이터 차원 의 최대값이다. 일부 실시예에서, 훈련된 제2 신경망의 랜덤 마스크층을 텐서 변환층으로 대체하는 동작은, 훈련된 제2 신경망의 출력층 뒤에 랜덤 마스크층이 존재하는 경우, 훈련된 제2 신경망의 출력층의 뒤에 있는 랜 덤 마스크층을 텐서 크로핑층으로 대체하는 동작을 포함하며, 상기 텐서 크로핑층은 상기 텐서 크로핑층에 입력 되는 텐서의 차원을 제1 목표값으로 감소하는 데 사용된다. 일부 실시예에서, 훈련된 제2 신경망의 랜덤 마스크층을 텐서 변환층으로 대체하는 동작은, 훈련된 제2 신경망의 중간층에 랜덤 마스크층이 존재하는 경우, 훈련된 제2 신경망의 중간층에 있는 랜덤 마스 크층을 텐서 크로핑 캐스케이드 텐서 패딩 층으로 대체하는 동작을 포함하며, 상기 텐서 크로핑 캐스케이드 텐 서 패딩 층은 상기 텐서 크로핑 캐스케이드 텐서 패딩 층에 입력되는 텐서의 차원을 제2 목표값으로 감소한 후 원래의 차원으로 증가하는 데 사용된다. 제3 측면으로, 본 개시의 실시예는 신경망 동작 방법을 제공하며, 예측 데이터를 획득하는 단계; 배치된 타겟 신경망에 상기 예측 데이터를 입력하여 상기 타겟 신경망으로부터 출력된 예측 결과를 얻는 단계를 포함하며, 상기 타겟 신경망은 적어도 하나의 텐서 변환층을 포함하고, 상기 텐서 변환층은 상기 텐서 변환층에 입력되는 텐서에 대해 차원 변환을 수행하는 데 사용된다. 일부 실시예에서, 상기 타겟 신경망은 상기 제1 측면 중 어느 한 항에 따른 제2 신경망이다. 제4 측면으로, 본 개시의 실시예는 전자 기기를 제공하며, 상기 전자 기기는메모리, 송수신기, 프로세서를 포함 하고, 메모리는 컴퓨터 프로그램을 저장하는 데 사용되고, 송수신기는 상기 프로세서의 제어에 따라 데이터를 송수신 하는 데 사용되며, 프로세서는 상기 메모리에 있는 컴퓨터 프로그램을 리드하여, 예측 데이터를 획득하는 동작; 및 배치된 타겟 신경망에 상기 예측 데이터를 입력하여 상기 타겟 신경망으로부터 출력된 예측 결과를 얻는 동작을 수행하는 데 사용되며, 상기 타겟 신경망은 적어도 하나의 텐서 변환층을 포함하고, 상기 텐서 변환층은 상기 텐서 변환층에 입력되는 텐서에 대해 차원 변환을 수행하는 데 사용된다. 일부 실시예에서, 상기 타겟 신경망은 제1 측면 중 어느 한 항에 따른 제2 신경망이다. 제5 측면으로, 본 개시의 실시예는 신경망 동작 장치를 제공하며, 상기 신경망 동작 장치는, 가변 차원의 유형에 따라 제1 신경망에 랜덤 마스크층을 추가하여 제2 신경망을 획득하는 데 사용되는 추가 모 듈 - 상기 랜덤 마스크층은 상기 랜덤 마스크층에 입력되는 텐서에 대해 랜덤 마스크 처리를 진행하는 데 사용 됨 -; 및 샘플 데이터를 이용하여 상기 제2 신경망을 훈련시키는 데 사용되는 훈련 모듈을 포함한다. 일부 실시예에서, 상기 가변 차원의 유형은, 입력 차원이 가변적인 것; 출력 차원이 가변적인 것; 또는 중간 차원이 가변적인 것; 중 하나 이상을 포함한다. 일부 실시예에서, 상기 추가 모듈은, 상기 가변 차원의 유형이 입력 차원이 가변적인 경우, 상기 제1 신경망의 입력층 앞에 랜덤 마스크층을 추가하 는 데 사용된다. 일부 실시예에서, 상기 추가 모듈은, 상기 가변 차원의 유형이 출력 차원이 가변적인 경우, 상기 제1 신경망의 출력층 뒤에 랜덤 마스크층을 추가하 는 데 사용된다. 일부 실시예에서, 상기 추가 모듈은, 상기 가변 차원의 유형이 중간 차원이 가변적인 경우, 상기 제1 신경망의 중간층에 랜덤 마스크층을 추가하는 데 사용된다. 일부 실시예에서, 상기 추가 모듈은, 하나의 중간 차원만 가변적인 경우, 연관된 중간층 앞이나 뒤에 하나의 랜덤 마스크층을 추가하는 데 사용된다. 일부 실시예에서, 상기 추가 모듈은, 복수의 중간 차원이 가변적인 경우, 각 연관된 중간층의 앞이나 뒤에 각각 하나의 랜덤 마스크층을 추가하는 데 사용된다. 일부 실시예에서, 상기 훈련 모듈은, 각 샘플 데이터의 입력 데이터의 차원이 모두 제1 임계값인 경우, 전체 샘플 데이터를 직접 이용하여 상기 제2 신경망을 훈련시키는 데 사용되며, 상기 제1 임계값은 전체 샘플 데이터의 입력 데이터 차원의 최대값이다. 일부 실시예에서, 상기 훈련 모듈은, 적어도 하나의 제1 샘플 데이터가 존재하는 경우, 우선 상기 제1 샘플 데이터에 대해 증강 처리를 수행하고, 다 음 전체 제1 샘플 데이터와 전체 제2 샘플 데이터를 이용하여 상기 제2 신경망을 훈련시키는 데 사용되며, 상기 제1 샘플 데이터는 입력 데이터의 차원이 제1 임계값이 아닌 샘플 데이터이고, 상기 제2 샘플 데이터는 입력 데 이터의 차원이 상기 제1 임계값인 샘플 데이터이고, 상기 제1 임계값은 전체 샘플 데이터의 입력 데이터 차원의 최대값이다. 일부 실시예에서, 상기 훈련 모듈은, 상기 제1 샘플 데이터의 입력 데이터에 대해 하이 비트 제로 패딩을 수행하는 데 사용된다. 일부 실시예에서, 상기 훈련 모듈은, 상기 제1 샘플 데이터의 입력 데이터에 대해 로우 비트 제로 패딩을 수행하는 데 사용된다. 일부 실시예에서, 상기 훈련 모듈은, 적어도 하나의 제1 샘플 데이터가 존재하는 경우, 우선 상기 제1 샘플 데이터를 제거하고, 다음 전체 제2 샘플 데이터를 이용하여 상기 제2 신경망을 훈련시키는 데 사용되며, 상기 제1 샘플 데이터는 입력 데이터의 차원이 제1 임계값이 아닌 샘플 데이터이며, 상기 제2 샘플 데이터는 입력 데이터의 차원이 제1 임계값인 샘플 데이터 이며, 상기 제1 임계값은 전체 샘플 데이터의 입력 데이터 차원의 최대값이다. 일부 실시예에서, 상기 훈련 모듈은, 상기 랜덤 마스크층에 입력되는 텐서 및 랜덤 마스크 텐서를 결정하며; 상기 랜덤 마스크 텐서를 이용하여 상기 랜덤 마스크층에 입력되는 텐서에 대해 랜덤 마스크 처리를 진행하는 데 사용된다. 일부 실시예에서, 상기 랜덤 마스크층에 입력되는 텐서에 대해 랜덤 마스크 처리를 진행하기 위한 표현식은, 이며, 는 랜덤 마스크층에서 출력되는 텐서를 나타내고, X는 랜덤 마스크층에 입력되는 텐서를 나타내며, 는 텐 서에 대한 비트별 포인트 곱셈 연산을 나타내고, M은 랜덤 마스크 텐서를 나타낸다. 일부 실시예에서, 상기 랜덤 마스크 텐서는 하드 마스킹 텐서이다. 일부 실시예에서, 상기 랜덤 마스크 텐서는 소프트 마스킹 텐서이다. 일부 실시예에서, 상기 랜덤 마스크 텐서는 하드 마스킹 텐서와 소프트 마스킹 텐서의 조합으로 형성된다. 일부 실시예에서, 배치 모듈을 더 포함하고, 상기 배치 모듈은 훈련된 제2 신경망의 랜덤 마스크층을 텐서 변환층으로 대체하는 데 사용되고, 상기 텐서 변 환층은 상기 텐서 변환층에 입력되는 텐서에 대해 차원 변환을 수행하는 데 사용된다. 일부 실시예에서, 상기 배치 모듈은, 훈련된 제2 신경망의 입력층 앞에 랜덤 마스크층이 존재하는 경우, 훈련된 제2 신경망의 입력층 앞에 있는 랜덤 마스크층을 텐서 패딩층으로 대체하는 데 사용되고, 상기 텐서 패딩층은 상기 텐서 패딩층에 입력되는 텐서의 차원을 제1 임계값으로 증가하는 데 사용되고, 상기 제1 임계값은 전체 샘플 데이터의 입력 데이터 차원의 최대 값이다. 일부 실시예에서, 상기 배치 모듈은, 훈련된 제2 신경망의 출력층 뒤에 랜덤 마스크층이 존재하는 경우, 훈련된 제2 신경망의 출력층 뒤에 있는 랜덤 마스크층을 텐서 크로핑층으로 대체하는 데 사용되고, 상기 텐서 크로핑층은 상기 텐서 크로핑층에 입력되는 텐 서의 차원을 제1 목표값으로 감소하는 데 사용된다. 일부 실시예에서, 상기 배치 모듈은, 훈련된 제2 신경망의 중간층에 랜덤 마스크층이 존재하는 경우, 훈련된 제2 신경망의 중간층에 있는 랜덤 마스 크층을 텐서 크로핑 캐스케이드 텐서 패딩 층으로 대체하는 데 사용되고, 상기 텐서 크로핑 캐스케이드 텐서 패 딩 층은 상기 텐서 크로핑 캐스케이드 텐서 패딩 층에 입력되는 텐서의 차원을 제2 목표값으로 감소한 후 원래 차원으로 증가하는 데 사용된다. 제6 측면으로, 본 개시의 실시예는 신경망 동작 장치를 제공하며, 상기 신경망 동작 장치는, 예측 데이터를 획득하는 획득 모듈; 배치된 타겟 신경망에 상기 예측 데이터를 입력하여 상기 타겟 신경망으로부터 출력된 예측 결과를 얻는 처리 모듈을 포함하며, 상기 타겟 신경망은 적어도 하나의 텐서 변환층을 포함하고, 상기 텐서 변환층은 상기 텐서 변환층에 입력되는 텐서에 대해 차원 변환을 수행하는 데 사용된다. 일부 실시예에서, 상기 타겟 신경망은 제5 측면 중 어느 한 항에 따른 제2 신경망이다. 제7 측면으로, 본 개시의 실시예는 프로세서 판독 가능한 저장 매체를 제공하며, 프로세서로 하여금 상기 제1 측면 또는 제3 측면의 신경망 동작 방법의 단계를 수행하게 하는 컴퓨터 프로그램이 상기 프로세서 판독 가능한 저장 매체에 저장된다. 제8 측면으로, 본 개시의 실시예는 컴퓨터 판독 가능한 저장 매체를 제공하며, 컴퓨터로 하여금 상기 제1 측면 또는 제3 측면의 신경망 동작 방법의 단계를 수행하게 하는 컴퓨터 프로그램이 상기 컴퓨터 판독 가능한 저장 매체에 저장된다. 제9 측면으로, 본 개시의 실시예는 통신 기기 판독 가능한 저장 매체를 제공하며, 통신 기기로 하여금 상기 제1 측면 또는 제3 측면의 신경망 동작 방법의 단계를 수행하게 하는 컴퓨터 프로그램이 상기 통신 기기 판독 가능 한 저장 매체에 저장된다. 제10 측면으로, 본 개시의 실시예는 칩 제품 판독 가능한 저장 매체를 제공하며, 칩 제품으로 하여금 상기 제1 측면 또는 제3 측면의 신경망 동작 방법의 단계를 수행하게 하는 컴퓨터 프로그램이 상기 칩 제품 판독 가능한 저장 매체에 저장된다.본 개시의 실시예에서 제공하는 신경망 동작 방법, 장치 및 저장 매체는 신경망에 랜덤 마스크층을 추가함으로 써, 단 하나의 신경망만을 훈련 및 배치하여 서로 다른 입력 및 출력 차원 요구에 적응하며, 상기 방법은 훈련 복잡도가 낮고 저장 오버헤드가 낮으며, 배치 및 온라인 훈련 지속적인 발전에 도움이 된다."}
{"patent_id": "10-2024-7024886", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "인공 신경망은 정보 처리 관점에서 인간 뇌의 신경망을 추상화하여 구성한 단순화된 모델이다. 학술계와 산업계 에서는 인공 신경망을 신경망이라고 약칭하며, 이는 수많은 컴퓨팅 노드가 특정 방식으로 서로 연결되어 구성된 컴퓨팅 모델이이며, 이 모델은 일반적으로 특정 알고리즘, 특정 함수 매핑에 대한 표현 또는 근사한 표현이다. 신경망의 훈련 단계에서 엔지니어는 먼저 신경망의 구조, 하이퍼매개변수를 결정해야 하며, 다음 모델에 데이터 를 공급하고 기울기 역전파를 제공하여 훈련된 신경망의 가중치를 업데이트해야 한다. 훈련된 신경망은 입력 데 이터와 레이블(labels) 간의 매핑 관계에 대한 근사치이며, 배치하는 단계에서 새로운 데이터를 신경망에 공급 하여 예측값을 얻을 수 있다. 일반적인 신경망에는 피드포워드(또는 완전 연결) 신경망(feedforward(or fully connect) neural networks), 컨볼루션 신경망(convolutional neural networks), 재귀 신경망(recurrent neural networks) 등이 포함된다. 컴퓨터 성능이 향상되고 그래픽 처리 장치(GPU)가 대규모로 배치됨에 따라 신경망의 적용은 컴퓨터 비전, 자연언어처리, 생물의학 및 자동 제어 분야에서 매우 보편화되었다. 신경망의 훈련 및 배치는 일반적으로 구체적인 작업 지향적이므로 신경망의 입력 및 출력 차원은 일반적으로 결 정된 것이다. 작업 A에 대해 훈련된 신경망은 일반적으로 작업 B에 사용할 수 없거나 작업 B에 사용될 때 성능 이 좋지 않다. 신경망의 입력 및 출력 차원이 불확실한 경우, 모든 가능한 입력 및 출력 차원 각각에 대해 하나 의 신경망을 훈련하여 다양한 차원과 작업 수요에 대처해야 한다. 예를 들어, 시스템은 배치된 신경망의 예측값 에 따라 응답하고, 신경망의 입력은 실시간으로 수집되는 데이터이다. 시스템의 즉시성에 대한 요구가 비교적 높을 때 시스템은 신경망이 수집된 일부 데이터에 기반하여 \"러프한\" 예측 결과를 제공하여 시스템이 사전에 바 람직한 방향으로 응답함으로써 최적의 방향으로 응답하는 데 소요되는 총 시간을 절약할 것을 요구한다. 종래의 실행 가능한 솔루션은 도 1에 도시된 바와 같이 서로 다른 입력 데이터 차원(일부 데이터의 수집으로 인해 입력 차원이 다름) 각각에 대해 하나의 신경망을 훈련하는 것이다. 시스템은 입력 차원에 따라 대응되는 신경망을 자 동으로 선택하여 예측을 수행하며, 입력 차원이 계속 증가함(수집된 실시간 데이터가 부분에서 완전으로 변경됨)에 따라, 신경망의 예측 값은 \"러프함(rough)\"에서 점차 \"정확함(accurate)\"으로 변경된다.신경망의 입력 차원과 출력 차원이 불확실한 경우, 종래 기술은 서로 다른 입력 및 출력 차원에 대한 요구에 대 처하기 위해 복수의 신경망을 배치해야 한다. 신경망의 수는 차원의 가능한 상황이 증가함에 따라 증가하며, 모 델 훈련의 복잡도가 높고 모델 저장 오버헤드가 커서 실제 배치와 신경망 온라인 학습의 지속적인 진화에 불리 하다. 상기 기술적 과제에 기초하여, 본 개시의 실시예는 신경망 동작 방법, 장치 및 저장 매체를 제공하며, 이 방법 은 신경망에 랜덤 마스크층을 추가함으로써, 단 하나의 신경망만을 훈련 및 배치하여 서로 다른 입력 및 출력 차원의 요구에 적응하며, 훈련 복잡도가 낮고 저장 오버헤드가 낮으며, 배치 및 온라인 훈련의 지속적인 진화에 도움이 된다. 본 개시의 실시예의 목적, 기술방안 및 장점을 더 명확하게 설명하기 위해, 이하 본 개시의 실시예의 첨부 도면 을 결합하여 본 개시의 실시예의 기술 방안에 대해 명확하고 완전하게 설명할 것이며, 설명되는 실시예는 본 개 시의 일부 실시예일 뿐, 모든 실시예가 아님은 자명한 것이다. 본 개시의 실시예에 기초하여 당업자가 창의적인 작업 없이 획득한 다른 모든 실시예는 본 개시의 보호 범위 내에 속한다. 도 2는 본 개시의 실시예에서 제공하는 신경망 동작 방법의 개략적인 흐름도이며, 도 2에 도시된 바와 같이, 본 개시의 실시예는 신경망 동작 방법을 제공하며, 그 수행 주체는 전자 기기, 예를 들면 단말, 기지국, 코어 네트 워크 요소 등일 수 있다. 상기 방법은 다음과 같은 단계를 포함한다. 단계 201: 가변 차원의 유형에 따라 제1 신경망에 랜덤 마스크층을 추가하여 제2 신경망을 획득하며, 상기 랜덤 마스크층은 상기 랜덤 마스크층에 입력되는 텐서에 대해 랜덤 마스크 처리를 진행하는 데 사용된다. 단계 202: 샘플 데이터를 이용하여 상기 제2 신경망을 훈련시킨다. 일부 실시예에서, 상기 가변 차원의 유형은 다음 유형 중 하나 이상을 포함한다: 입력 차원이 가변적인 것; 출력 차원이 가변적인 것; 중간 차원이 가변적인 것이다. 일부 실시예에서, 가변 차원의 유형에 따라 제1 신경망에 랜덤 마스크층을 추가하는 단계는, 상기 가변 차원의 유형이 입력 차원이 가변적인 경우, 상기 제1 신경망의 입력층의 앞에 랜덤 마스크층을 추가 하는 단계를 포함한다. 일부 실시예에서, 가변 차원의 유형에 따라 제1 신경망에 랜덤 마스크층을 추가하는 단계는, 상기 가변 차원의 유형이 출력 차원이 가변적인 경우, 상기 제1 신경망의 출력층의 뒤에 랜덤 마스크층을 추가 하는 단계를 포함한다. 일부 실시예에서, 가변 차원의 유형에 따라 제1 신경망에 랜덤 마스크층을 추가하는 단계는, 상기 가변 차원의 유형이 중간 차원이 가변적인 경우, 상기 제1 신경망의 중간층에 랜덤 마스크층을 추가하는 단계를 포함한다. 일부 실시예에서, 상기 제1 신경망의 중간층에 랜덤 마스크층을 추가하는 단계는, 하나의 중간 차원만 가변적인 경우, 연관된 중간층의 앞이나 뒤에 랜덤 마스크층을 추가하는 단계를 포함한다. 일부 실시예에서, 상기 제1 신경망의 중간층에 랜덤 마스크층을 추가하는 단계는, 복수의 중간 차원이 가변적인 경우, 각 연관된 중간층의 앞이나 뒤에 각각 하나의 랜덤 마스크층을 추가하는 단 계를 포함한다. 일부 실시예에서, 샘플 데이터를 이용하여 상기 제2 신경망을 훈련시키는 단계는, 각 샘플 데이터의 입력 데이터의 차원이 모두 제1 임계값인 경우, 전체 샘플 데이터를 직접 이용하여 상기 제2 신경망을 훈련시키는 단계를 포함하며, 상기 제1 임계값은 전체 샘플 데이터의 입력 데이터 차원의 최대값이다. 일부 실시예에서, 샘플 데이터를 이용하여 상기 제2 신경망을 훈련시키는 단계는, 적어도 하나의 제1 샘플 데이터가 존재하는 경우, 우선 상기 제1 샘플 데이터에 대해 증강 처리를 수행하고, 다 음 전체 제1 샘플 데이터와 전체 제2 샘플 데이터를 이용하여 상기 제2 신경망을 훈련시키는 단계를 포함하고, 상기 제1 샘플 데이터는 입력 데이터의 차원이 제1 임계값이 아닌 샘플 데이터이고, 상기 제2 샘플 데이터는 입 력 데이터의 차원이 상기 제1 임계값인 샘플 데이터이고, 상기 제1 임계값은 전체 샘플 데이터의 입력 데이터 차원의 최대값이다. 일부 실시예에서, 상기 제1 샘플 데이터에 대해 증강 처리를 수행하는 단계는, 상기 제1 샘플 데이터의 입력 데이터에 대해 하이 비트 제로 패딩(high-bit zero padding)을 수행하는 단계를 포함한다. 일부 실시예에서, 상기 제1 샘플 데이터에 대해 증강 처리를 수행하는 단계는, 상기 제1 샘플 데이터의 입력 데이터에 대해 로우 비트 제로 패딩(low-bit zero padding)을 수행하는 단계를 포 함한다. 일부 실시예에서, 샘플 데이터를 이용하여 상기 제2 신경망을 훈련시키는 단계는, 적어도 하나의 제1 샘플 데이터가 존재하는 경우, 우선 상기 제1 샘플 데이터를 제거하고, 다음 전체 제2 샘플 데이터를 이용하여 상기 제2 신경망을 훈련시키는 단계를 포함하며, 상기 제1 샘플 데이터는 입력 데이터의 차 원이 제1 임계값이 아닌 샘플 데이터이며, 상기 제2 샘플 데이터는 입력 데이터의 차원이 제1 임계값인 샘플 데 이터이며, 상기 제1 임계값은 전체 샘플 데이터의 입력 데이터 차원의 최대값이다. 일부 실시예에서, 상기 랜덤 마스크층에 입력되는 텐서에 대해 랜덤 마스크 처리를 진행하는 단계는, 상기 랜덤 마스크층에 입력되는 텐서 및 랜덤 마스크 텐서를 결정하는 단계; 및 상기 랜덤 마스크 텐서를 이용하여 상기 랜덤 마스크층에 입력되는 텐서에 대해 랜덤 마스크 처리를 진행하는 단계를 포함한다. 일부 실시예에서, 상기 랜덤 마스크층에 입력되는 텐서에 대해 랜덤 마스크 처리를 진행하기 위한 표현식은 다 음과 같다:"}
{"patent_id": "10-2024-7024886", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "여기서 는 랜덤 마스크층에서 출력되는 텐서를 나타내고, X는 랜덤 마스크층에 입력되는 텐서를 나타내며, 는 텐서에 대한 비트별 포인트 곱셈 연산(bitwise point multiplication operation)을 나타내고, M은 랜덤 마스크 텐서를 나타낸다. 일부 실시예에서, 상기 랜덤 마스크 텐서는 하드 마스킹 텐서이다. 일부 실시예에서, 상기 랜덤 마스크 텐서는 소프트 마스킹 텐서이다. 일부 실시예에서, 상기 랜덤 마스크 텐서는 하드 마스킹 텐서와 소프트 마스킹 텐서의 조합으로 형성된다. 일부 실시예에서, 샘플 데이터를 이용하여 상기 제2 신경망을 훈련시키는 단계 이후에, 훈련된 제2 신경망의 랜덤 마스크층을 텐서 변환층으로 대체하는 단계를 더 포함하며, 상기 텐서 변환층은 상기 텐서 변환층에 입력되는 텐서에 대해 차원 변환을 수행하는 데 사용된다. 일부 실시예에서, 훈련된 제2 신경망의 랜덤 마스크층을 텐서 변환층으로 대체하는 단계는, 훈련된 제2 신경망의 입력층 앞에 랜덤 마스크층이 존재하는 경우, 훈련된 제2 신경망의 입력층 앞에 있는 랜덤 마스크층을 텐서 패딩층으로 대체하는 단계를 포함하며, 상기 텐서 패딩층은 상기 텐서 패딩층에 입력되는 텐서 의 차원을 제1 임계값으로 증가하는 데 사용되고, 상기 제1 임계값은 전체 샘플 데이터의 입력 데이터 차원의 최대값이다. 일부 실시예에서, 훈련된 제2 신경망의 랜덤 마스크층을 텐서 변환층으로 대체하는 단계는, 훈련된 제2 신경망의 출력층 뒤에 랜덤 마스크층이 존재하는 경우, 훈련된 제2 신경망의 출력층 뒤에 있는 랜덤 마스크층을 텐서 크로핑층으로 대체하는 단계를 포함하며, 상기 텐서 크로핑층은 상기 텐서 크로핑층에 입력되 는 텐서의 차원을 제1 목표값으로 감소하는 데 사용된다.일부 실시예에서, 훈련된 제2 신경망의 랜덤 마스크층을 텐서 변환층으로 대체하는 단계는, 훈련된 제2 신경망의 중간층에 랜덤 마스크층이 존재하는 경우, 훈련된 제2 신경망의 중간층에 있는 랜덤 마스 크층을 텐서 크로핑 캐스케이드 텐서 패딩 층(cascaded tensor cropping and tensor padding layer)으로 대체 하는 단계를 포함하며, 상기 텐서 크로핑 캐스케이드 텐서 패딩 층은 상기 텐서 크로핑 캐스케이드 텐서 패딩 층에 입력되는 텐서의 차원을 제2 목표값으로 감소한 후 원래 차원으로 증가하는 데 사용된다. 본 개시의 실시예에서, 훈련 데이터의 최대 차원, 레이블의 최대 차원 및 작업 요구에 따라 신경망의 입력층, 출력층, 일부 중간층의 입력 텐서 차원 및 출력 텐서 차원을 결정한다. 도 3은 본 개시의 실시예에서 제공하는 차원 가변 신경망 훈련의 블록도이다. 도 3에 도시된 바와 같이, 훈련 단계에서 가변 차원이 필요한 텐서에 대응하는 층에 랜덤 마스크 모듈(랜덤 마스크층이라고도 함)을 추가하여 신경망을 훈련시킨다. 구체적으로 다음 단계를 포함할 수 있다. 1. 신경망의 입력 차원이 가변적인 경우 입력층 좌측에 랜덤 마스크 모듈을 추가한다. 2. 신경망의 출력 차원이 가변적인 경우 출력층 우측에 랜덤 마스크 모듈을 추가한다. 3. 신경망에서 i번째 중간층의 출력 차원과 (i+1)번째 중간층의 입력 차원이 가변적인 경우, 중간층(i)와 중간 층(i+1) 사이에 랜덤 마스크 모듈을 추가한다. 4. 신경망의 입력층, 출력층 및 중간층에 동시에 복수의 차원 가변 요구가 존재하는 경우, 해당 위치에 복수의 랜덤 마스크 모듈을 추가한다. 5. 입력층의 좌측에서 훈련 데이터는 최대 차원 데이터만 사용할 수 있으며(최대 차원 데이터가 아닌 경우 이러 한 데이터를 먼저 제거할 수 있음), 또는 훈련 전에 하이 비트 또는 로우 비트 제로 패딩을 통해 저차원 입력 데이터를 최대 차원 데이터로 증가시키는 데이터 증강 처리를 진행할 수도 있다. 신경망은 랜덤 마스크 모듈을 추가한 후 신경망의 가중치에 대한 손실 함수의 기울기 값을 계산하여 훈련된 신 경망을 업데이트한다. 랜덤 마스크 동작(랜덤 마스크 처리)은 텐서 X에 작용하며 다음과 같이 표현된다:"}
{"patent_id": "10-2024-7024886", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "여기서 은 차원(예를 들어 X는 길이가 64이고 너비가 64인 이미지인 경우, 이며, 3은 빨간색, 녹색, 파란색의 3원색 채널을 나타냄)의 차 텐서이며, 는 입력 텐서의 i차 차원이며, 연산 는 텐서의 비트별 포인트 곱셈을 나타내고, M은 (랜덤) 마스크 텐서이고, 는 마스크 결과이다. 마스크 텐서 M은 각 훈련 샘플과 각 훈련 에포크(Epoch)에 대 해 독립적이고 동일하게 분포되는 랜덤 텐서이다. 차 마스크 텐서 M은 의 차원을 가지며, 이는 다음과 같을 수 있으나 이에 국한되지는 않는다: 1. 하드 마스킹(Hard-Masking) , 여기서 은 마스킹이 필요한 차 수를 나타낸다(예를 들어, 차원의 이미지인 경우, 도 4에 도시된 바와 같이 빨간색, 녹색, 파란색의 3원 색 채널의 3차원은 마스크되지 않고 I={1,2}이다. 3차 텐서 차원은 이며, 및 에 대해, t=3 및 t=4이다). 텐서 의 요소 값은 의 인덱스를 기반으로 다음과 같은 값을 가진다: 여기서 정수 는 주어진 확률 분포(예: 균일 분포)를 따르고 각 에 대해 t는 독립적이고 동 일하게 분포된다. 2. 소프트 마스킹(Soft-Masking) 예를 들어, 지수적으로 감소하는 소프트 마스킹은 이고, 텐서 의 요소 값 은 의 인덱스를 기반으로 다음과 같은 값을 가진다:"}
{"patent_id": "10-2024-7024886", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "여기서 실수 는 특정 분포(예: 균일 분포)를 따르고 각 에 대해 λ도 독립적이고 동일하게 분포된다. 3. M에서 일부는 하드 마스킹을 사용하고, 일부는 소프트 마스킹을 사용할 수도 있으며, 즉 하드 마스킹과 소프 트 마스킹을 조합하는 것이 가능하다. 상술한 마스크 텐서가 특정 텐서에 작용하는 경우 텐서 자체의 차원은 변경되지 않으며 상기 텐서에 가중치를 부여하는 동작과 동등하며, 인덱스가 작은 위치의 텐서 값에 더 큰 가중치가 할당된다. 예를 들어, 1차 텐서(벡터)의 경우, 하드 마스킹 은 처음 t 비트가 1이고, 마지막 비트가 0인 벡터이며, 은 X의 마지막 비트를 0으로 설정하는 것과 동 일하며 텐서의 차원은 변경되지 않는다. 훈련 과정에서, 옵티마이저는 손실을 기반으로 기울기 역전파를 계산하고 신경망의 가중치 매개변수를 업데이트 한다. 또한, 도 3은 다음과 같은 내용을 포함할 수 있다. 1. 신경망은 컨볼루션 신경망, 피드포워드(또는 완전 연결) 신경망, 재귀 신경망 및 이들의 조합일 수 있지만 이에 국한되지는 않는다. 2. 손실 함수는 평균 제곱 오차(mean square error), 1 노름(norm), 범주형 교차 엔트로피(categorical cross entropy) 및 코사인 유사성(cosine similarity)일 수 있지만 이에 국한되지는 않는다. 3. 랜덤 마스크 모듈은 기울기를 사용자 정의하고 마스크 텐서를 상수 텐서로 처리하여 기울기가 사라지거나 미 분 불가능한 문제를 방지한다. 4. 입력측 랜덤 마스크, 출력측 랜덤 마스크, 중간층 랜덤 마스크는 동시에 존재할 수 있고, 이들 중 일부만 존 재할 수도 있으며, 특정 작업에 따라 구체적으로 사용되는 랜덤 마스크의 개수가 결정될 수 있다. 도 5는 본 개시의 실시예에서 제공하는 차원 가변 신경망 배치의 블록도이다. 도 5에 도시된 바와 같이, 배치 단계에서 차원 가변 신경망은 훈련된 신경망에서 랜덤 마스크 모듈을 제거하고 텐서 패딩 모듈(텐서 패딩층이라 고도 함) 및 텐서 크로핑 모듈(텐서 크로핑층이라고도 함)을 추가하여 구성될 수 있다. 구체적으로 다음과 같은 단계를 포함할 수 있다. 1. 입력층 좌측의 랜덤 마스크 모듈을 텐서 패딩 모듈로 대체하며, 로우 비트 또는 하이 비트 제로 패딩 방식을 통해 입력 텐서를 최대 입력 차원으로 패딩한다. 2. 출력층 우측의 랜덤 마스크 모듈을 텐서 크로핑 모듈로 대체하며, 하이 비트 또는 로우 비트 크로핑 방식을 통해 텐서를 출력한다. 3. 중간층(i)와 중간층(i+1) 사이의 랜덤 마스크 모듈을 텐서 크로핑 모듈 캐스케이드 텐서 패딩 모듈(cascaded tensor cropping module and tensor padding module)로 대체한다. 전체 과정에서, 단 하나의 신경망만 훈련 및 배치하여 서로 다른 입력 및 출력 차원에 대한 요구에 적응할 수 있으며, 여러 신경망 훈련 및 저장 문제를 방지할 수 있다. 도 5에 도시된 바와 같이, 상술한 훈련된 신경망을 기반으로 랜덤 마스크 모듈을 제거하고, 랜덤 마스크 모듈을 텐서 패딩 모듈과 텐서 크로핑 모듈로 대체하여 차원 가변 신경망을 구축한다. 대체된 텐서 패딩 모듈과 텐서 크로핑 모듈은 도 6에 도시된 바와 같이, 입력 텐서 X의 i차 길이가 보다 작으면 하이 비트 또는 로우 비트 제로 패딩을 수행하여 텐서를 패딩함으로써 i차 차원이 와 같도록 한다: 1. 하이 비트 제로 패딩을 적용하는 경우, 훈련 과정은 도 3과 같다. 2. 로우 비트 제로 패딩을 적용하는 경우, 텐서 X에 대응하는 랜덤 마스크 텐서 M에 대해 i차 인덱스는 추가적 인 역방향 재배열 동작이 필요하다. 출력 텐서 X의 i차 차원이 필요한 차원보다 큰 경우, 출력 텐서 X는 로우 비트 또는 하이 비트를 트리밍하여 텐 서를 크로핑하므로써 출력 차원에 대한 요구를 충족하는 텐서 를 얻는다: 1. 로우 비트 트리밍을 적용하는 경우, 훈련 과정은 도 3과 같다. 2. 하이 비트 트리밍을 적용하는 경우, 훈련 단계에서 텐서 X에 대응하는 랜덤 마스크 텐서 M에 대해 i차 인덱 스는 추가적인 역방향 재배열 동작이 필요하다. 시스템은 하나의 신경망 배치만 필요하고 출력 텐서는 필요에 따라 크로핑되고 입력 텐서에 대해 제로 패딩을 수행하면 서로 다른 입력 및 출력 차원의 요구를 충족할 수 있는 것을 알 수 있다. 아래에서 여러 특정 실시예를 통해 상술한 방법에 대해 더 설명한다. 실시예1: 도 7에 도시된 바와 같이, 신경망은 이미지 압축에 사용되는 오토인코더로, 인코더 모듈은 이미지를 압축하는 데 사용되고 디코더 모듈은 이미지를 복원하는 데 사용된다. 인코더의 입력과 디코더의 출력은 모두 차원의 이미지이다. 인코더의 출력(디코더의 입력이기도 함) 차원에 대한 요구는 가 변적이며, 최대 차원은 이다. 훈련 단계에서 인코더와 디코더 사이에 랜덤 하드 마스킹 모듈이 추가 되며, 마스크 텐서의 매개변수 는 균일 분포를 따르며 Adam 옵티마이저를 사용하여 오토인코더 신 경망을 훈련시킨다. 신경망 훈련이 완료되면 인코더가 송신단에 배치되고 디코더가 수신단에 배치된다. 송신단 은 압축률 요구에 따라 인코더 출력 텐서를 트리밍한다. 수신단은 수신되는 텐서 길이에 따라 텐서 패딩 비트 수를 결정하고 텐서를 패딩한 후 디코더로 전송하여 이미지를 복원한다. 실시예2: 실시예 1과 같이, 오토인코더는 이미지 압축에 사용되고 인코더의 입력과 디코더의 출력은 모두 차원의 이미지이다. 인코더의 출력(디코더의 입력이기도 함) 차원은 가변적이며, 최대 차원은 이다. 인코딩 특징 Z 차원이 작을수록 압축률 은 높아지고 복원된 이미지는 흐려지며; 인코딩 특징 Z 차원이 클수록 압축률 은 낮아지고 복원된 이미지는 선명 해진다. 가능한 압축률은 이다. 훈련 단계에서 하드 마스킹 모듈 의 매개변수 는 등확률 분포를 따르며 인코더의 출력에 작용한다. 실시예3: 인공지능 기반 채널 추정 알고리즘에서 수신단은 복조 참조 신호(Demodulation Reference Signal, DMRS)의 수 신값을 기반으로 모든 시간-주파수 자원 블록 상의 채널 계수를 추정한다. 채널 복구 알고리즘은 신경망을 기반 으로 구현된다. 단일 슬롯(14 개 OFDM 기호), 8개의 물리 자원 블록(96 개 주파수)의 상황에서 단일 기호 DMRS 및 듀얼 기호 DMRS 구성은 도 8에 도시된 바와 같다. 단일 기호 DMRS 구성은 입력 차원이 48×1×2(여기서 48은 주파수에 해당하고 1은 시간에 해당하며 2는 복소수의 실수부와 허수부에 해당함)인 신경망에 해당하고, 듀얼 기호 DMRS 구성(단일 기호 구성의 기초상에서 하나의 DMRS 기호를 추가로 구성함)은 입력 차원이 48×2×2인 신 경망에 해당하고, 신경망의 출력 차원은 96×14×2이다. 채널 추정에 사용되는 신경망의 최대 입력 차원은 이다. 훈련 단계에서 입력 텐서의 2차 인덱스 차원(시간 차원)에 대해 소프트 마스킹을 진행 하고, 매개변수 은 균일 분포를 따른다. 가변 입력 차원을 갖춘 배치된 신경망은 단일 기호와 듀얼 기호의 DMRS 구성 모두의 채널 추정에 사용된다. 실시예4: 실시예 3과 같이, 단일 슬롯(14개 OFDM 기호), 8개의 물리 자원 블록(96개 주파수)의 상황에서 단일 기호 DMRS 구성은 입력 차원이 48×1×2인 신경망에 해당하고, 듀얼 기호 DMRS 구성은 입력 차원이 48×2×2인 신경망에 해당한다. 채널 추정에 사용되는 신경망의 최대 입력 차원은 이다. 훈련 단계에서 입력 텐서의 2차 인덱스 차원(시간 차원)에 대해 하드 마스킹을 진행하며, 여기서 매개변수는 이고 확률 분포는 이다. 실시예5: 도 9에 도시된 바와 같이, 오토인코더를 이용하여 인공지능 기반의 채널 상태 정보(CSI) 압축 알고리즘을 구현 한다. 인코더는 UE 측에 배치되고 디코더는 기지국 측에 배치된다. UE 측은 CSI 참조 신호(RS)를 기반으로 채널 H를 추정하고 프리코딩 벡터 V를 계산한다. 프리코딩 벡터 V의 차원의 크기는 이며, 여기서 는 12개의 서브밴드를 나타내고, 는 32개의 송신 안테나를 나타내고, 2는 실수부와 허수부를 나타낸다. 인코더는 768차원 V 입력 값을 하나의 벡 터로 압축한다. 텐서 크로핑 모듈은 피드백이 필요한 비트 수 k에 따라 인코더의 출력을 크로핑하여 기지국 측 으로 송신한다. 기지국 측은 피드백 비트 수에 따라 수신된 비트 스트림에 대해 텐서 패딩을 수행하고, 이를 디 코더에 입력하여 프리코딩 벡터 를 복원한다. 훈련 단계에서 인코더와 디코더 사이에 텐서 마스크 모듈이 추 가되고 랜덤 하드 마스킹을 적용하며 마스크 텐서의 매개변수 는 균일 분포를 따르며 손실 함수 는 코사인 유사성(cosine similarity)이다. 본 개시의 실시예에서 제공하는 신경망 동작 방법은, 단 하나의 신경망만을 훈련 및 배치하여 서로 다른 입력 및 출력 차원 요구에 적응하며, 상기 방법은 훈련 복잡도가 낮고 저장 오버헤드가 낮으며, 배치 및 온라인 훈련 의 지속적인 진화에 도움이 된다. 도 10은 본 개시의 실시예에서 제공하는 전자 기기의 개략적인 구조도이며, 도 10에 도시된 바와 같이, 상기 전 자 기기는 메모리, 송수신기, 프로세서를 포함한다. 메모리는 컴퓨터 프로그램을 저장하는 데 사용되고, 송수신기는 상기 프로세서의 제어에 따 라 데이터를 송수신하는 데 사용되며, 프로세서는 상기 메모리에 있는 컴퓨터 프로그램을 리드하여 다음과 같은 동작을 수행하는 데 사용된다: 가변 차원의 유형에 따라 제1 신경망에 랜덤 마스크층을 추가하여 제2 신경망을 획득하며, 상기 랜덤 마스크층 은 상기 랜덤 마스크층에 입력되는 텐서에 대해 랜덤 마스크 처리를 진행하는데 사용되며; 샘플 데이터를 이용하여 상기 제2 신경망을 훈련시킨다. 구체적으로, 송수신기는 프로세서의 제어 하에 데이터를 수신 및 송신하는 데 사용된다. 도 10에서 버스 아키텍처는 임의의 수의 상호 연결된 버스 및 브리지를 포함할 수 있고, 구체적으로 프로세서 로 표시되는 하나 이상의 프로세서와 메모리로 표시되는 메모리의 다양한 회로를 통해 함께 연결된 다. 버스 아키텍처는 또한 주변 장치, 전압 조정기 및 전력 관리 회로와 같은 다양한 기타 회로를 함께 연결할 수 있다. 이는 모두 본 기술 분야에서 잘 알려져 있으므로 본 출원에서는 이에 대해 더 이상 설명하지 않는다. 버스 인터페이스는 인터페이스를 제공한다. 송수신기는 복수의 소자일 수 있으며, 즉 무선 채널, 유선 채 널, 광섬유 케이블 등을 포함하는 전송 매체를 통해 다양한 다른 장치와 통신하기 위한 유닛을 제공하는 송신기 및 수신기를 포함할 수 있다. 프로세서는 버스 아키텍처 및 통상적인 처리를 관리하는 역할을 담당하며, 메모리는 프로세서가 동작을 수행하는 데 사용되는 데이터를 저장할 수 있다. 프로세서는 중앙 처리 장치(CPU), 주문형 집적 회로(Application Specific Integrated Circuit, ASIC), 필드 프로그래밍 가능한 게이트 어레이(Field Programmable Gate Array, FPGA) 또는 복합 프로그래밍 가능한 논리 장치(Complex Programmable Logic Device, CPLD)일 수 있다. 프로세서는 또한 멀티 코어 아키텍처 를 사용할 수도 있다. 일부 실시예에서, 상기 가변 차원의 유형은 다음 유형 중 하나 이상을 포함한다: 입력 차원이 가변적인 것; 출력 차원이 가변적인 것; 중간 차원이 가변적인 것이다. 일부 실시예에서, 상기 가변 차원의 유형에 따라 제1 신경망에 랜덤 마스크층을 추가하는 단계는, 상기 가변 차원의 유형이 입력 차원이 가변적인 경우, 상기 제1 신경망의 입력층의 앞에 랜덤 마스크층을 추가 하는 단계를 포함한다. 일부 실시예에서, 상기 가변 차원의 유형에 따라 제1 신경망에 랜덤 마스크층을 추가하는 단계는, 상기 가변 차원의 유형이 출력 차원이 가변적인 경우, 상기 제1 신경망의 출력층의 뒤에 랜덤 마스크층을 추가 하는 단계를 포함한다. 일부 실시예에서, 상기 가변 차원의 유형에 따라 제1 신경망에 랜덤 마스크층을 추가하는 단계는, 상기 가변 차원의 유형이 중간 차원이 가변적인 경우, 상기 제1 신경망의 중간층에 랜덤 마스크층을 추가하는 단계를 포함한다. 일부 실시예에서, 상기 제1 신경망의 중간층에 랜덤 마스크층을 추가하는 단계는, 하나의 중간 차원만 가변적인 경우, 연관된 중간층의 앞이나 뒤에 랜덤 마스크층을 추가하는 단계를 포함한다. 일부 실시예에서, 상기 제1 신경망의 중간층에 랜덤 마스크층을 추가하는 단계는, 복수의 중간 차원이 가변적인 경우, 각 연관된 중간층의 앞이나 뒤에 각각 하나의 랜덤 마스크층을 추가하는 단 계를 포함한다. 일부 실시예에서, 상기 샘플 데이터를 이용하여 상기 제2 신경망을 훈련시키는 단계는: 각 샘플 데이터의 입력 데이터의 차원이 모두 제1 임계값인 경우, 전체 샘플 데이터를 직접 이용하여 상기 제2 신경망을 훈련시키는 단계를 포함하며, 상기 제1 임계값은 전체 샘플 데이터의 입력 데이터 차원의 최대값이다. 일부 실시예에서, 상기 샘플 데이터를 이용하여 상기 제2 신경망을 훈련시키는 단계는, 적어도 하나의 제1 샘플 데이터가 존재하는 경우, 우선 상기 제1 샘플 데이터에 대해 증강 처리를 수행하고, 다 음 전체 제1 샘플 데이터와 전체 제2 샘플 데이터를 이용하여 상기 제2 신경망을 훈련시키는 단계를 포함하고, 상기 제1 샘플 데이터는 입력 데이터의 차원이 제1 임계값이 아닌 샘플 데이터이고, 상기 제2 샘플 데이터는 입 력 데이터의 차원이 상기 제1 임계값인 샘플 데이터이고, 상기 제1 임계값은 전체 샘플 데이터의 입력 데이터 차원의 최대값이다.일부 실시예에서, 상기 제1 샘플 데이터에 대해 증강 처리를 수행하는 단계는, 상기 제1 샘플 데이터의 입력 데이터에 대해 하이 비트 제로 패딩을 수행하는 단계를 포함한다. 일부 실시예에서, 상기 제1 샘플 데이터에 대해 증강 처리를 수행하는 단계는, 상기 제1 샘플 데이터의 입력 데이터에 대해 로우 비트 제로 패딩을 수행하는 단계를 포함한다. 일부 실시예에서, 상기 샘플 데이터를 이용하여 상기 제2 신경망을 훈련시키는 단계는, 적어도 하나의 제1 샘플 데이터가 존재하는 경우, 우선 상기 제1 샘플 데이터를 제거하고, 다음 전체 제2 샘플 데이터를 이용하여 상기 제2 신경망을 훈련시키는 단계를 포함하며, 상기 제1 샘플 데이터는 입력 데이터의 차 원이 제1 임계값이 아닌 샘플 데이터이며, 상기 제2 샘플 데이터는 입력 데이터의 차원이 제1 임계값인 샘플 데 이터이며, 상기 제1 임계값은 전체 샘플 데이터의 입력 데이터 차원의 최대값이다. 일부 실시예에서, 상기 랜덤 마스크층에 입력되는 텐서에 대해 랜덤 마스크 처리를 진행하는 단계는, 상기 랜덤 마스크층에 입력되는 텐서 및 랜덤 마스크 텐서를 결정하는 단계; 및 상기 랜덤 마스크 텐서를 이용하여 상기 랜덤 마스크층에 입력되는 텐서에 대해 랜덤 마스크 처리를 진행하는 단계를 포함한다. 일부 실시예에서, 상기 랜덤 마스크층에 입력되는 텐서에 대해 랜덤 마스크 처리를 진행하기 위한 표현식은 다 음과 같다:"}
{"patent_id": "10-2024-7024886", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "여기서 는 랜덤 마스크층에서 출력되는 텐서를 나타내고, X는 랜덤 마스크층에 입력되는 텐서를 나타내며, 는 텐서에 대한 비트별 포인트 곱셈 연산을 나타내고, M은 랜덤 마스크 텐서를 나타낸다. 일부 실시예에서, 상기 랜덤 마스크 텐서는 하드 마스킹 텐서이다. 일부 실시예에서, 상기 랜덤 마스크 텐서는 소프트 마스킹 텐서이다. 일부 실시예에서, 상기 랜덤 마스크 텐서는 하드 마스킹 텐서와 소프트 마스킹 텐서의 조합으로 형성된다. 일부 실시예에서, 상기 샘플 데이터를 이용하여 상기 제2 신경망을 훈련시키는 단계 이후에, 훈련된 제2 신경망의 랜덤 마스크층을 텐서 변환층으로 대체하는 단계를 더 포함하며, 상기 텐서 변환층은 상기 텐서 변환층에 입력되는 텐서에 대해 차원 변환을 수행하는 데 사용된다. 일부 실시예에서, 상기 훈련된 제2 신경망의 랜덤 마스크층을 텐서 변환층으로 대체하는 단계는, 훈련된 제2 신경망의 입력층 앞에 랜덤 마스크층이 존재하는 경우, 훈련된 제2 신경망의 입력층 앞에 있는 랜덤 마스크층을 텐서 패딩층으로 대체하는 단계를 포함하며, 상기 텐서 패딩층은 상기 텐서 패딩층에 입력되는 텐서 의 차원을 제1 임계값으로 증가하는 데 사용되고, 상기 제1 임계값은 전체 샘플 데이터의 입력 데이터 차원의 최대값이다. 일부 실시예에서, 상기 훈련된 제2 신경망의 랜덤 마스크층을 텐서 변환층으로 대체하는 단계는, 훈련된 제2 신경망의 출력층 뒤에 랜덤 마스크층이 존재하는 경우, 훈련된 제2 신경망의 출력층 뒤에 있는 랜덤 마스크층을 텐서 크로핑층으로 대체하는 단계를 포함하며, 상기 텐서 크로핑층은 상기 텐서 크로핑층에 입력되 는 텐서의 차원을 제1 목표값으로 감소하는 데 사용된다. 일부 실시예에서, 상기 훈련된 제2 신경망의 랜덤 마스크층을 텐서 변환층으로 대체하는 단계는, 훈련된 제2 신경망의 중간층에 랜덤 마스크층이 존재하는 경우, 훈련된 제2 신경망의 중간층에 있는 랜덤 마스 크층을 텐서 크로핑 캐스케이드 텐서 패딩 층으로 대체하는 단계를 포함하며, 상기 텐서 크로핑 캐스케이드 텐 서 패딩 층은 상기 텐서 크로핑 캐스케이드 텐서 패딩 층에 입력되는 텐서의 차원을 제2 목표값으로 감소한 후 원래 차원으로 증가하는 데 사용된다. 구체적으로, 본 개시의 실시예에서 제공하는 전술한 전자 기기는, 전자 기기를 통해 실행되는 상술한 방법 실시 예에 의해 구현되는 모든 방법 단계를 구현할 수 있고, 동일한 기술적 효과를 달성할 수 있다. 본 실시예에서는 방법 실시예와 동일한 부분 및 유익한 효과에 대해 반복하여 설명하지 않는다. 본 개시의 실시예는 신경망 동작 방법을 더 제공하며, 상기 방법은 다음과 같은 단계를 포함한다: 예측 데이터를 획득하는 단계; 배치된 타겟 신경망에 상기 예측 데이터를 입력하여 상기 타겟 신경망으로부터 출력된 예측 결과를 얻는 단계, 여기서 상기 타겟 신경망은 적어도 하나의 텐서 변환층을 포함하고, 상기 텐서 변환층은 상기 텐서 변환층에 입 력되는 텐서에 대해 차원 변환을 수행하는 데 사용된다. 일부 실시예에서, 상기 타겟 신경망은 상술한 실시예 중의 임의의 상기 제2 신경망이다. 본 개시의 실시예에서 제공되는 신경망 동작 방법은, 단 하나의 신경망만을 훈련 및 배치하여 서로 다른 입력 및 출력 차원 요구에 적응하며, 상기 방법은 훈련 복잡도가 낮고 저장 오버헤드가 낮으며, 배치 및 온라인 훈련 의 지속적인 진화에 도움이 된다. 본 개시의 실시예는 메모리, 송수신기, 프로세서를 포함하는 전자 기기를 더 제공한다. 메모리는 컴퓨터 프로그램을 저장하는 데 사용되고, 송수신기는 상기 프로세서의 제어에 따라 데이터를 송수신 하는 데 사용되며, 프로세서는 상기 메모리에 있는 컴퓨터 프로그램을 리드하여 다음과 같은 동작을 수행하는 데 사용된다: 예측 데이터를 획득하며; 배치된 타겟 신경망에 상기 예측 데이터를 입력하여 상기 타겟 신경망으로부터 출력된 예측 결과를 얻는다. 여 기서 상기 타겟 신경망은 적어도 하나의 텐서 변환층을 포함하고, 상기 텐서 변환층은 상기 텐서 변환층에 입력 되는 텐서에 대해 차원 변환을 수행하는 데 사용된다. 구체적으로, 송수신기는 프로세서의 제어 하에 데이터를 수신 및 송신하는 데 사용된다. 버스 아키텍처는 임의의 수의 상호 연결된 버스 및 브리지를 포함할 수 있고, 구체적으로 프로세서로 표시되는 하나 이상의 프로세서와 메모리로 표시되는 메모리의 다양한 회로를 통해 함께 연결된다. 버스 아키텍처는 또한 주변 장치, 전압 조정기 및 전력 관리 회로와 같은 다양한 기타 회로를 함께 연결할 수 있다. 이는 모두 본 기 술 분야에서 잘 알려져 있으므로 본 출원에서는 이에 대해 더 이상 설명하지 않는다. 버스 인터페이스는 인터페 이스를 제공한다. 송수신기는 복수의 소자일 수 있으며, 즉 무선 채널, 유선 채널, 광섬유 케이블 등을 포함하 는 전송 매체를 통해 다양한 다른 장치와 통신하기 위한 유닛을 제공하는 송신기 및 수신기를 포함할 수 있다. 프로세서는 버스 아키텍처 및 통상적인 처리를 관리하는 역할을 담당하며, 메모리는 프로세서가 동작을 수행하 는 데 사용되는 데이터를 저장할 수 있다. 프로세서는 중앙 처리 장치(CPU), 주문형 집적 회로(Application Specific Integrated Circuit, ASIC), 필드 프로그래밍 가능한 게이트 어레이(Field Programmable Gate Array, FPGA) 또는 복합 프로그래밍 가능한 논리 장치(Complex Programmable Logic Device, CPLD)일 수 있다. 프로세서는 또한 멀티 코어 아키텍처를 사 용할 수도 있다. 일부 실시예에서, 상기 타겟 신경망은 상술한 실시예 중의 임의의 상기 제2 신경망이다. 본 개시의 실시예에서 제공되는 전자 기기는, 단 하나의 신경망만을 훈련 및 배치하여 서로 다른 입력 및 출력 차원 요구에 적응하며, 상기 방법은 훈련 복잡도가 낮고 저장 오버헤드가 낮으며, 배치 및 온라인 훈련의 지속 적인 전화에 도움이 된다. 도 11은 본 개시의 실시예에서 제공하는 신경망 동작 장치의 개략적인 구조도이다. 도 11에 도시된 바와 같이, 본 개시의 실시예는 추가 모듈 및 훈련 모듈을 포함하는 신경망 동작 장치를 제공한다. 추가 모듈은 가변 차원의 유형에 따라 제1 신경망에 랜덤 마스크층을 추가하여 제2 신경망을 획득하는 데 사용되고, 상기 랜덤 마스크층은 상기 랜덤 마스크층에 입력되는 텐서에 대해 랜덤 마스크 처리를 진행하는 데 사용된다. 훈련 모듈은 샘플 데이터를 이용하여 상기 제2 신경망을 훈련시키는 데 사용된다. 일부 실시예에서, 상기 가변 차원의 유형은 다음 유형 중 하나 이상을 포함한다: 입력 차원이 가변적인 것; 출력 차원이 가변적인 것; 중간 차원이 가변적인 것이다. 일부 실시예에서, 상기 추가 모듈은 구체적으로, 상기 가변 차원의 유형이 입력 차원이 가변적인 경우, 상기 제1 신경망의 입력층의 앞에 랜덤 마스크층을 추가 하는 데 사용된다. 일부 실시예에서, 상기 추가 모듈은 구체적으로, 상기 가변 차원의 유형이 출력 차원이 가변적인 경우, 상기 제1 신경망의 출력층의 뒤에 랜덤 마스크층을 추가 하는 데 사용된다. 일부 실시예에서, 상기 추가 모듈은 구체적으로, 상기 가변 차원의 유형이 중간 차원이 가변적인 경우, 상기 제1 신경망의 중간층에 랜덤 마스크층을 추가하는 데 사용된다. 일부 실시예에서, 상기 추가 모듈은 구체적으로, 하나의 중간 차원만 가변적인 경우, 연관된 중간층의 앞이나 뒤에 랜덤 마스크층을 추가하는 데 사용된다. 일부 실시예에서, 상기 추가 모듈은 구체적으로, 복수의 중간 차원이 가변적인 경우, 각 연관된 중간층의 앞이나 뒤에 각각 하나의 랜덤 마스크층을 추가하는 데 사용된다. 일부 실시예에서, 상기 훈련 모듈은 구체적으로, 각 샘플 데이터의 입력 데이터의 차원이 모두 제1 임계값인 경우, 전체 샘플 데이터를 직접 이용하여 상기 제2 신경망을 훈련시키는 데 사용되며, 상기 제1 임계값은 전체 샘플 데이터의 입력 데이터 차원의 최대값이다. 일부 실시예에서, 상기 훈련 모듈은 구체적으로, 적어도 하나의 제1 샘플 데이터가 존재하는 경우, 우선 상기 제1 샘플 데이터에 대해 증강 처리를 수행하고, 다 음 전체 제1 샘플 데이터와 전체 제2 샘플 데이터를 이용하여 상기 제2 신경망을 훈련시키는 데 사용되며, 상기 제1 샘플 데이터는 입력 데이터의 차원이 제1 임계값이 아닌 샘플 데이터이고, 상기 제2 샘플 데이터는 입력 데 이터의 차원이 상기 제1 임계값인 샘플 데이터이고, 상기 제1 임계값은 전체 샘플 데이터의 입력 데이터 차원의 최대값이다. 일부 실시예에서, 상기 훈련 모듈은 구체적으로, 상기 제1 샘플 데이터의 입력 데이터에 대해 하이 비트 제로 패딩을 수행하는 데 사용된다. 일부 실시예에서, 상기 훈련 모듈은 구체적으로, 상기 제1 샘플 데이터의 입력 데이터에 대해 로우 비트 제로 패딩을 수행하는 데 사용된다. 일부 실시예에서, 상기 훈련 모듈은 구체적으로, 적어도 하나의 제1 샘플 데이터가 존재하는 경우, 우선 상기 제1 샘플 데이터를 제거하고, 다음 전체 제2 샘플 데이터를 이용하여 상기 제2 신경망을 훈련시키는 데 사용되며, 상기 제1 샘플 데이터는 입력 데이터의 차원이 제1 임계값이 아닌 샘플 데이터이며, 상기 제2 샘플 데이터는 입력 데이터의 차원이 제1 임계값인 샘플 데이터 이며, 상기 제1 임계값은 전체 샘플 데이터의 입력 데이터 차원의 최대값이다. 일부 실시예에서, 상기 훈련 모듈은 구체적으로, 상기 랜덤 마스크층에 입력되는 텐서 및 랜덤 마스크 텐서를 결정하며; 상기 랜덤 마스크 텐서를 이용하여 상기 랜덤 마스크층에 입력되는 텐서에 대해 랜덤 마스크 처리를 진행하는 데 사용된다. 일부 실시예에서, 상기 랜덤 마스크층에 입력되는 텐서에 대해 랜덤 마스크 처리를 진행하기 위한 표현식은 다 음과 같다:"}
{"patent_id": "10-2024-7024886", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "여기서 는 랜덤 마스크층에서 출력되는 텐서를 나타내고, X는 랜덤 마스크층에 입력되는 텐서를 나타내며, 는 텐서에 대한 비트별 포인트 곱셈 연산을 나타내고, M은 랜덤 마스크 텐서를 나타낸다. 일부 실시예에서, 상기 랜덤 마스크 텐서는 하드 마스킹 텐서이다. 일부 실시예에서, 상기 랜덤 마스크 텐서는 소프트 마스킹 텐서이다. 일부 실시예에서, 상기 랜덤 마스크 텐서는 하드 마스킹 텐서와 소프트 마스킹 텐서의 조합으로 형성된다. 일부 실시예에서, 배치 모듈을 더 포함한다. 상기 배치 모듈은 훈련된 제2 신경망의 랜덤 마스크층을 텐서 변환층으로 대체하는 데 사용되며, 상기 텐서 변 환층은 상기 텐서 변환층에 입력되는 텐서에 대해 차원 변환을 수행하는 데 사용된다. 일부 실시예에서, 상기 배치 모듈은 구체적으로, 훈련된 제2 신경망의 입력층 앞에 랜덤 마스크층이 존재하는 경우, 훈련된 제2 신경망의 입력층 앞에 있는 랜덤 마스크층을 텐서 패딩층으로 대체하는 데 사용되며, 상기 텐서 패딩층은 상기 텐서 패딩층에 입력되는 텐서의 차원을 제1 임계값으로 증가하는 데 사용되고, 상기 제1 임계값은 전체 샘플 데이터의 입력 데이터 차원의 최대 값이다. 일부 실시예에서, 상기 배치 모듈은 구체적으로, 훈련된 제2 신경망의 출력층 뒤에 랜덤 마스크층이 존재하는 경우, 훈련된 제2 신경망의 출력층 뒤에 있는 랜덤 마스크층을 텐서 크로핑층으로 대체하는 데 사용되며, 상기 텐서 크로핑층은 상기 텐서 크로핑층에 입력되는 텐 서의 차원을 제1 목표값으로 감소하는 데 사용된다. 일부 실시예에서, 상기 배치 모듈은 구체적으로, 훈련된 제2 신경망의 중간층에 랜덤 마스크층이 존재하는 경우, 훈련된 제2 신경망의 중간층에 있는 랜덤 마스 크층을 텐서 크로핑 캐스케이드 텐서 패딩 층으로 대체하는 데 사용되며, 상기 텐서 크로핑 캐스케이드 텐서 패 딩 층은 상기 텐서 크로핑 캐스케이드 텐서 패딩 층에 입력되는 텐서의 차원을 제2 목표값으로 감소한 후 원래 차원으로 증가하는 데 사용된다. 구체적으로, 본 개시의 실시예에서 제공하는 전술한 신경망 동작 장치는, 신경망 동작 장치를 통해 실행되는 상 술한 방법 실시예에 의해 구현되는 모든 방법 단계를 구현할 수 있고, 동일한 기술적 효과를 달성할 수 있다. 본 실시예에서는 방법 실시예와 동일한 부분 및 유익한 효과에 대해 반복하여 설명하지 않는다. 본 개시의 실시예는 신경망 동작 장치를 더 제공하며, 상기 신경망 동작 장치는, 예측 데이터를 획득하는 획득 모듈; 배치된 타겟 신경망에 상기 예측 데이터를 입력하여 상기 타겟 신경망으로부터 출력된 예측 결과를 얻는 처리 모듈;을 포함한다. 여기서 상기 타겟 신경망은 적어도 하나의 텐서 변환층을 포함하고, 상기 텐서 변환층은 상 기 텐서 변환층에 입력되는 텐서에 대해 차원 변환을 수행하는 데 사용된다. 일부 실시예에서, 상기 타겟 신경망은 상술한 실시예 중의 임의의 상기 제2 신경망이다. 본 개시의 실시예에서 제공되는 신경망 동작 장치는, 단 하나의 신경망만을 훈련 및 배치하여 서로 다른 입력 출력 차원 요구에 적응하며, 상기 방법은 훈련 복잡도가 낮고 저장 오버헤드가 낮으며, 배치 및 온라인 훈련의 지속적인 진화에 도움이 된다. 본 개시의 상기 실시예에서 유닛/모듈의 분할은 예시적인 것이고 단지 논리적인 기능 분할일 뿐이며 실제 구현 에서는 다른 분할 방식이 있을 수 있다는 점에 유의해야 한다. 또한, 본 개시의 다양한 실시예에서의 기능 유닛 들은 하나의 처리 유닛에 통합될 수 있고, 각 유닛이 물리적으로 단독으로 존재할 수도 있고, 둘 이상의 유닛이 하나의 유닛에 통합될 수도 있다. 전술한 통합 유닛은 하드웨어 또는 소프트웨어 기능 유닛의 형태로 구현될 수있다. 상기 통합 유닛이 소프트웨어 기능 유닛의 형태로 구현되어 독립 제품으로 판매되거나 사용되는 경우, 프로세서 판독 가능한 저장 매체에 저장될 수 있다. 이러한 이해를 바탕으로, 본 개시의 기술방안이 본질적으로 종래 기 술에 기여하는 부분 또는 해당 기술방안의 전부 또는 일부가 소프트웨어 제품의 형태로 구현되어 저장될 수 있 다. 해당 컴퓨터 소프트웨어 제품은 저장 매체에 저장되며 복수의 커맨드를 포함하여 컴퓨터 장치(개인용 컴퓨 터, 서버 또는 네트워크 장치 등일 수 있음) 또는 프로세서가 본 개시의 각 실시예에의 상술한 방법 단계의 전 부 또는 일부를 수행하도록 한다. 전술한 저장 매체는 U디스크, 모바일 하드디스크, ROM(Read Only Memory), RAM(Random Access Memory), 자기디스크, 광디스크 등 프로그램 코드를 저장할 수 있는 다양한 매체를 포함한다. 일부 실시예에서, 컴퓨터 판독 가능한 저장 매체를 더 제공한다. 상기 컴퓨터 판독 가능한 저장매체는 컴퓨터 프로그램이 저장된다. 상기 컴퓨터 프로그램은 컴퓨터가 상술한 각 방법 실시예에서 제공하는 신경망 동작 방법 의 단계를 수행하도록 한다. 구체적으로, 본 개시의 실시예에서 제공하는 전술한 컴퓨터 판독 가능한 저장 매체는 전술한 각 방법 실시예에 서 구현된 모든 방법 단계를 구현하고 동일한 기술적 효과를 달성할 수 있다. 본 실시예에서는 방법 실시예와 동일한 부분 및 유익한 효과에 대해 반복하여 설명하지 않는다. 상기 컴퓨터 판독 가능한 저장 매체는 프로세서가 액세스할 수 있는 임의의 이용 가능한 매체 또는 데이터 저장 장치일 수 있으며, 자기 메모리(예: 플로피 디스크, 하드 디스크, 테이프, 광자기 디스크(MO) 등), 광학 메모리 (CD, DVD, BD, HVD 등), 반도체 메모리(예: ROM, EPROM, EEPROM, 비휘발성 메모리(NAND FLASH), 솔리드 스테이 트 드라이브(SSD)) 등를 포함하되 이에 국한되지 않는다는 점에 유의해야 한다. 또한, 본 개시의 실시예에서 \"제1\", \"제2\" 등의 용어는 유사한 대상을 구별하기 위해 사용되며 특정 순서나 시 퀀스를 설명하기 위해 사용되지 않는다는 점에 유의해야 한다. 이렇게 사용된 용어는 본 개시의 실시예가 본 명 세서에 도시되거나 설명된 것 이외의 순서로 실시될 수 있도록 적절한 상황에서 상호교환 가능하며, \"제1\"과 \" 제2\"가 구별하는 대상은 일반적으로 한가지 유형이며 대상의 수는 제한하지 않는다. 예를 들어 제1 대상은 하나 이거나 복수 개일 수 있다. 본 개시의 실시예에서, \"및/또는\"이라는 용어는 연관 객체들의 연관된 관계를 설명하며, 세 가지 관계가 있을 수 있음을 나타낸다. 예를 들어, A 및/또는 B는, A가 단독으로 존재하거나, A와 B가 동시에 존재하거나, B가 단 독으로 존재하는 세 가지 경우를 나타낼 수 있다. 부호 \"/\"는 일반적으로 전후로 연관된 대상은 \"또는\" 관계를 가지고 있음을 나타낸다. 본 개시의 실시예에서 \"복수\"라는 용어는 2개 또는 2개 이상을 의미하며, 다른 수량사도 이와 유사하다. 본 개시의 실시예에서 제공하는 기술방안은 다양한 시스템, 특히 5G 시스템에 적용될 수 있다. 예를 들어, 적용 가능한 시스템은 GSM(Global System of Mobile Communication) 시스템, CDMA(Code Division Multiple Access) 시스템, WCDMA(Wideband Code Division Multiple Access) GPRS(General Packet Radio Service) 시스템, LTE(Long Term Evolution) 시스템, LTE FDD(Frequency Division Duplex) 시스템, LTE TDD(Time Division Duplex) 시스템, LTE-A(Long Term Evolution Advanced) 시스템, UMTS(Universal Mobile Telecommunication System), WiMAX(Worldwide interoperability for Microwave Access) 시스템, 5G NR(New Radio) 시스템 등일 수 있다. 이러한 다양한 시스템에는 모두 단말 기기와 네트워크 기기가 포함된다. 시스템은 EPS(Evolved Packet System), 5GS(5G System) 등과 같은 코어 네트워크 부분을 포함할 수도 있다. 본 개시의 실시예의 단말 기기는 사용자에게 음성 및/또는 데이터 연결을 제공하는 기기, 무선 연결 기능이 있 는 휴대용 기기, 또는 무선 모뎀에 연결된 기타 처리 기기 등일 수 있다. 시스템마다 단말 기기의 명칭이 다를 수도 있다. 예를 들어, 5G 시스템에서 단말 기기는 사용자 기기 (User Equipment, UE)로 불릴 수 있다. 무선 단 말 기기는 무선 액세스 네트워크(Radio Access Network, RAN)을 통해 하나 이상의 코어 네트워크(Core Network, CN)와 통신할 수 있고, 무선 단말 기기는 이동 단말 기기일 수 있으며, 예를 들면, 모바일 폰(또는 \" 셀룰라\" 폰) 및 이동 단말 기기를 갖춘 컴퓨터일 수 있으며, 무선 액세스 네트워크와 언어 및/또는 데이터를 교 환하는 휴대용 모바일 장치, 주머니 크기의 모바일 장치, 핸드피스 모바일 장치, 컴퓨터 내장형 모바일 장치 또 는 차량 탑재형 모바일 장치일 수 있다. 예를 들어, 개인 통신 서비스(Personal Communication Service, PCS) 폰, 무선 전화, 세션 시작 프로토콜(Session Initiated Protocol, SIP) 전화, 무선 로컬 루프(Wireless Local Loop, WLL)스테이션, 개인 디지털 어시스턴트(Personal Digital Assistant, PDA) 등 기기일 수 있다. 무선 단말 기기는 시스템, 가입자 유닛(subscriber unit), 가입자 스테이션(subscriber station), 모바일 스테이션 (mobile station), 모바일(mobile), 원격 스테이션(remote station), 액세스 포인트(access point), 원격 단말 기기(remote terminal), 액세스 단말 기기(access terminal), 사용자 단말 기기(user terminal), 사용자 에이 전트(user agent), 사용자 장치(user device)로 칭될 수 있으며, 본 개시의 실시예에서는 제한하지 않는다. 본 개시의 실시예에서 네트워크 기기는 기지국일 수 있고, 해당 기지국은 단말에 서비스를 제공하는 복수의 셀 을 포함할 수 있다. 특정 애플리케이션에 따라, 네트워크 기기는 액세스 포인트라고도 불릴 수 있거나, 무선 인 터페이스에서 하나 이상의 섹터를 통해 무선 단말기와 통신하는 액세스 네트워크의 기기, 또는 기타 이름으로 불릴 수 있다. 네트워크 기기는 수신된 에어 프레임을 인터넷 프로토콜(Internet Protocol, IP) 패킷과 교환하 는 데 사용될 수 있으며, 무선 단말 기기와 액세스 네트워크의 나머지 부분 사이의 라우터 역할을 할 수 있으며, 액세스 네트워크의 나머지 부분은 인터넷 프로토콜(IP) 통신 네트워크를 포함할 수 있다. 네트워크 기 기는 무선 인터페이스에 대한 속성 관리를 조정할 수도 있다. 예를 들어, 본 개시의 실시예에서 네트워크 기기 는 GSM(Global System for Mobile Communications) 또는 CDMA(Code Division Multiple Access)의 네트워크 기 기(Base Transceiver Station, BTS)일 수도 있고, WCDMA(Wide-band Code Division Multiple Access)의 네트워 크 기기(NodeB)일 수도 있으며, LTE(long term evolution) 시스템의 eNB 또는 e-Node B(evolutional Node B)일 수도 있고, 5G 네트워크 아키텍처(next generation system)의 5G 기지국 (gNB)일 수도 있으며, HeNB(Home Evolved Node B), 릴레이 노드(Relay Node), 펨토(femto), 피코(pico) 등일 수 있으며, 본 개시의 실시예에서 는 이에 제한되지 않는다. 일부 네트워크 구조에서 네트워크 기기는 집중 유닛(Centralized Unit, CU) 노드와 분산 유닛(Distributed Unit, DU) 노드를 포함할 수 있으며, 집중 유닛과 분산 유닛은 지리적으로 분리될 수도 있다. 네트워크 기기와 단말 기기 사이에서 하나 이상의 안테나를 각각 사용하여 MIMO(Multi-Input Multi-Output) 전 송을 수행할 수 있으며, MIMO 전송은 단일 사용자 MIMO(Single User MIMO, SU-MIMO) 또는 다중 사용자 MIMO(Multiple User MIMO, MU-MIMO)일 수 있다. 안테나 조합의 형태와 개수에 따라 MIMO 전송은 2D-MIMO, 3D- MIMO, FD-MIMO 또는 Massive-MIMO일 수 있으며, 다이버시티 전송(diversity transmission) 또는 프리코딩 전송 (precoding transmission), 빔포밍 전송(beamforming transmission)일 수도 있다. 당업자는, 본 개시의 실시예는 방법, 시스템 또는 컴퓨터 프로그램 제품으로 제공될 수 있다는 것을 이해해야 한다. 따라서, 본 개시는 완전한 하드웨어 실시예, 완전한 소프트웨어 실시예, 또는 소프트웨어와 하드웨어 측 면을 결합한 실시예의 형태를 취할 수 있다. 또한, 본 개시는 컴퓨터 사용 가능한 프로그램 코드가 포함된 하나 이상의 컴퓨터 사용 가능한 저장 매체(디스크 저장 장치, 광학 저장 장치 등을 포함하지만 이에 국한되지 않 음)에서 구현되는 컴퓨터 프로그램 제품의 형태를 취할 수 있다. 본 개시는 본 개시의 실시예에 따른 방법, 기기(시스템) 및 컴퓨터 프로그램 제품의 흐름도 및/또는 블록도를 참조하여 설명된다. 흐름도 및/또는 블록도의 각 흐름 및/또는 블록, 및 흐름도 및/또는 블록도의 흐름 및/또는 블록의 조합은 컴퓨터 실행 가능한 커맨드에 의해 구현될 수 있다는 것을 이해해야 한다. 이러한 컴퓨터 실행 가능한 커맨드는 범용 컴퓨터, 특수 목적 컴퓨터, 내장형 프로세서 또는 기타 프로그래밍 가능한 데이터 처리 기기의 프로세서에 제공되어 기계를 생성할 수 있으며 컴퓨터 또는 기타 프로그래밍 가능한 데이터 처리 기기의 프로세서에 의해 실행되는 커맨드는 흐름도의 하나 이상의 흐름 및/또는 블록도의 하나 이상의 블록에 지정된 기능을 수행하기 위한 수단을 형성한다. 이러한 프로세서 실행 가능한 커맨드는 컴퓨터 또는 다른 프로그래밍 가능한 데이터 처리 기기가 특정 방식으로 작동하도록 유도할 수 있는 프로세서 판독 가능한 메모리에 저장될 수 있으며, 해당 프로세서 판독 가능한 메모 리에 저장된 커맨드는 커맨드 수단을 포함하는 제조품을 생성할 수 있으며, 해당 커맨드 수단은 흐름도의 하나 이상의 흐름 및/또는 블록도의 하나 이상의 블록에 지정된 기능을 수행할 수 있다. 이러한 프로세서 실행 가능한 커맨드는 컴퓨터 또는 기타 프로그래밍 가능한 데이터 처리 기기에 로드되어 컴퓨 터 또는 기타 프로그래밍 가능한 데이터 처리 기기에서 일련의 동작 단계를 수행하여 컴퓨터에서 구현되는 프로 세스를 생성하도록 할 수 있으므로, 컴퓨터 또는 기타 프로그래밍 가능한 기기에서 수행되는 커맨드는 흐름도의 하나 이상의 흐름 및/또는 블록도의 하나 이상의 블록에 지정된 기능을 수행하기 위한 단계를 제공한다. 당업자는 본 개시의 사상 및 범위를 벗어나지 않고 본 개시에 대해 다양한 수정 및 변형을 진행할 수 있다. 따 라서, 본 개시의 이러한 수정 및 변형이 본 개시의 청구범위 및 그 균등물의 범위 내에 속한다면, 본 개시는 또 한 이러한 수정 및 변형을 포함하도록 의도된다.도면 도면1 도면2 도면3 도면4 도면5 도면6 도면7 도면8 도면9 도면10 도면11"}
{"patent_id": "10-2024-7024886", "section": "도면", "subsection": "도면설명", "item": 1, "content": "본 개시의 실시예의 기술방안을 더 명확하게 설명하기 위해, 이하 실시예의 설명에 사용될 도면을 간략하게 설 명하며, 이하의 설명에서 도면은 본 개시의 일부 실시예일 뿐, 당업자에게 있어서 창의적인 작업 없이 이러한 도면을 기반으로 다른 도면을 얻을 수 있는 것은 자명한 것이다. 도 1은 종래 기술의 차원 가변 신경망의 훈련 방법의 개략도이다. 도 2는 본 개시의 실시예에서 제공하는 신경망 동작 방법의 개략적인 흐름도이다. 도 3은 본 개시의 실시예에서 제공하는 차원 가변 신경망 훈련의 블록도이다. 도 4는 본 개시의 실시예에서 제공하는 하드 마스킹 텐서(hard-masking tensor)의 개략도이다. 도 5는 본 개시의 실시예에서 제공하는 차원 가변 신경망 배치의 블록도이다. 도 6은 본 개시의 실시예에서 제공하는 텐서 패딩(tensor padding) 모듈과 텐서 크로핑(tensor cropping) 모듈 의 개략도이다. 도 7은 본 개시의 실시예에서 제공하는 오토인코더(autoencoder) 신경망의 개략도이다. 도 8은 본 개시의 실시예에서 제공하는 단일 기호 및 듀얼 기호 복조 참조 신호(demodulation reference signal, DMRS)의 개략도이다. 도 9는 본 개시의 실시예에서 제공하는 오토인코더 기반 채널 상태 정보(channel state information, CSI) 압축 피드백의 블록도이다. 도 10은 본 개시의 실시예에서 제공하는 전자 기기의 개략적인 구조도이다. 도 11은 본 개시의 실시예에서 제공하는 신경망 동작 장치의 개략적인 구조도이다."}
