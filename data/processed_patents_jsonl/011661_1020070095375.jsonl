{"patent_id": "10-2007-0095375", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2009-0030063", "출원번호": "10-2007-0095375", "출원인": "한국전자통신연구원", "발명자": "이성주"}}
{"patent_id": "10-2007-0095375", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "외부로부터 수신된 음향 신호의 부가 잡음을 제거하는 입력 신호 음질 향상부;상기 입력 신호 음질 향상부로부터 음향 신호를 수신하여 상기 음향 신호에 포함된 음성 신호의 끝점을 검출하는 제1 끝점 검출부;상기 제1 끝점 검출부로부터 수신된 음향 신호에 포함된 음성 신호의 유성음 특징을 추출하는 유성음 특징 추출부;상기 유성음 특징 추출부에서 추출된 유성음 특징의 판단 기준이 되는 유성음 모델 파라미터를 저장하는 유성음/비유성음 판단 모델부 및상기 유성음 특징 추출부에서 추출된 유성음 특징을 상기 유성음/비유성음 판단 모델부의 유성음 모델 파라미터를 이용하여 유성음 부분을 판단하는 유성음/비유성음 판별부를 포함하는 음성 신호 판별장치."}
{"patent_id": "10-2007-0095375", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 유성음/비유성음 판별부의 판단 결과 및 제1 끝점 검출부의 검출 결과에 상응하여 수신된 상기 음향 신호에 포함된 음성 신호의 끝점을 검출하는 제2 끝점 검출부를 더 포함하는 음성 신호 판별장치."}
{"patent_id": "10-2007-0095375", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 입력 음성 음질 향상부는 위너 필터, 최소 평균 제곱 오류(MMSE : Minimum mean square error) 방식 및칼만 방식 중 어느 하나의 방식을 사용하여 부가 잡음을 제거한 시간축 신호를 출력하는 것을 특징으로 하는 음성 신호 판별장치."}
{"patent_id": "10-2007-0095375", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,상기 유성음 특징 추출부는 수신된 연속 음성 신호의 변형 시간-주파수 신호 파라미터(Modified TF parameter),HLFBER(high-to-Low Frequency Band Energy Ratio), 조성(Tonality), CMNDV(Cumulative Mean NormalizedDifference Valley), ZCR(Zero-Crossing Rate), LCR(Level-Crossing Rate), PVR(Peak-to-Valley Ratio),ABPSE(Adaptive Band-Partitioning Spectral Entropy), NAP(Normalized Autocorrelation Peak),스펙트럼 엔트로피(Spectral entropy) 및 AMDV(Average Magnitude Difference Valley) 특징을 모두 추출하는 것을 특징으로 하는 음성 신호 판별장치."}
{"patent_id": "10-2007-0095375", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서,상기 유성음/비유성음 판단 모델부는 순수 음성 모델에서 추출된 각 유성음 특징의 임계치 및 경계치,GMM(Gaussian Mixture Model), MLP(Multi-Layer Perceptron) 및 SVM(Support Vector Machine) 방식의 모델 파라미터 값 중 어느 하나를 포함하는 것을 특징으로 하는 음성 신호 판별장치."}
{"patent_id": "10-2007-0095375", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서,- 3 -공개특허 10-2009-0030063상기 유성음/비유성음 판별부는 상기 유성음 특징의 임계치 및 경계치와 상기 추출된 음성 신호의 유성음 특징을 단순 비교하는 방식, 통계적 모델을 이용하는 GMM 방식, 인공 지능을 이용하는 MLP 방식,CART(Classification and Regression Tree) 방식, LRT(Likelihood Ratio Test) 방식 및 SVM 방식 중 어느 하나를 이용하는 것을 특징으로 하는 음성 신호 판별장치."}
{"patent_id": "10-2007-0095375", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에 있어서,상기 제1 끝점 검출부는 상기 수신된 음향 신호의 시간-주파수 영역의 에너지 및 엔트로피 기반의 특징을 이용하여 상기 음향 신호에 포함된 음성 신호의 끝점을 검출하고 VSFR(Voiced Speech Frame Ratio)를 이용하여 음성인지 판단하고 음성 마킹 정보를 제공하는 것을 특징으로 하는 음성 신호 판별장치."}
{"patent_id": "10-2007-0095375", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제2항에 있어서,상기 제2 끝점 검출부는 GSAP(Global Speech Absence Probability), ZCR, LCR 및 엔트로피 계열의 파라미터 중어느 하나를 이용하여 상기 음향 신호에 포함된 음성 신호의 끝점을 검출하는 것을 특징으로 하는 음성 신호 판별장치."}
{"patent_id": "10-2007-0095375", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "외부로부터 음향 신호를 수신하는 단계;상기 입력된 음향 신호의 부가 잡음을 제거하는 단계;상기 부가 잡음이 제거된 음향 신호를 수신하여 상기 음향 신호에 포함된 음성 신호의 제1 끝점을 검출하는 단계 상기 제1 끝점이 검출된 음성 신호의 유성음 특징들을 추출하는 단계 및상기 추출된 유성음 특징들과 미리 설정된 유성음/비유성음 판단 모델을 비교하여 입력된 음향 신호 중 유성음부분을 판단하는 단계를 포함하는 음성 신호 판별 방법."}
{"patent_id": "10-2007-0095375", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9항에 있어서,상기 유성음 부분의 판단 결과에 상응하여 상기 음향 신호에 포함된 음성 신호의 제2 끝점을 검출하는 단계를 더 포함하는 음성 신호 판별 방법."}
{"patent_id": "10-2007-0095375", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제9항에 있어서,상기 음향 신호의 부가 잡음 제거는 위너 필터, 최소 평균 제곱 오류방식 및 칼만 방식 중 어느 하나의 방식을사용하는 것을 특징으로 하는 음성 신호 판별 방법."}
{"patent_id": "10-2007-0095375", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제9항에 있어서,상기 유성음 특징은 수신된 연속 음성 신호의 변형 시간-주파수 신호 파라미터, HLFBER, 조성, CMNDV, ZCR,- 4 -공개특허 10-2009-0030063LCR, PVR, ABPSE, NAP, 스펙트럼 엔트로피 및 AMDV 특징인 것을 특징으로 하는 음성 신호 판별 방법."}
{"patent_id": "10-2007-0095375", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제9항에 있어서,상기 유성음/비유성음 판단 모델은 순수 음성 모델에서 추출된 각 유성음 특징의 임계치 및 경계치, GMM, MLP및 SVM 방식의 모델 파라미터 값 중 어느 하나를 포함하는 것을 특징으로 하는 음성 신호 판별 방법."}
{"patent_id": "10-2007-0095375", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제9항에 있어서,상기 유성음 부분을 판단하는 방법은 상기 유성음 특징의 임계치 및 경계치와 상기 추출된 음성 신호의 유성음특징을 단순 비교하는 방식, 통계적 모델을 이용하는 GMM 방식, 인공 지능을 이용하는 MLP 방식, CART 방식,LRT 방식 및 SVM 방식 중 어느 하나를 이용하는 것을 특징으로 하는 음성 신호 판별 방법."}
{"patent_id": "10-2007-0095375", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제9항에 있어서,상기 제1 끝점을 검출하는 단계는 끝점 찾기 방식(EPD : end-point detection)을 적용하여 상기 음향 신호에 포함된 음성 신호의 시작점 및 종료점을 검출하는 단계를 더 포함하는 음성 신호 판별 방법.명 세 서발명의 상세한 설명 기 술 분 야본 발명은 인간 음성의 유성음 특징을 이용한 음성/비음성 판별 방법 및 장치에 관한 것이다. <1>본 발명은 정보통신부 및 정보통신연구진흥원의 IT신성장동력핵심기술개발사업의 일환으로 수행한 연구로부터 <2>도출된 것이다[과제관리번호: 2006-S-036-02, 과제명: 신성장동력산업용 대용량 대화형 분산 처리 음성인터페이스 기술개발] 배 경 기 술실제 다양한 잡음 환경에서 자동음성인식시스템을 적용하기 위해서는 많은 진입 장벽들이 존재하는데 그 중 하 <3>나가 실제 잡음 문제이다. 일상 생활에서 흔히 발생하는 다양한 잡음환경 속에서 자동음성인식시스템이 잘 동작하기 위해서는 음성에 섞여 있는 잡음신호를 잘 추정하여 제거하는 기술도 중요하지만 사용자 음성만을 검출해낼 수 있는 끝점검출 기술 또한 매우 중요한 기술 중의 하나이다. 특히, 사용자가 발성의 시작을 알리지 않는연속 음성(NON-PTT : non-push-to-talk) 방식에서는 사용자 음성이 아닌 다른 잡음신호들이 음성인식시스템으로입력되어 그 성능을 저하시키는 요인으로 작용하는 문제가 있어 실제 상용화 시스템에서는 NON-PTT 방식을 적용하기 어려웠다. NON-PTT 방식의 자동음성인식을 위해서는 입력된 음성신호가 사용자 음성인지 아닌지를 판별하는 음성 판별기술 <4>이 요구된다. 그러나 기존의 방식을 이용할 경우에는 배경 음악이나 배블(Babble) 잡음과 같은 화자의 음성 신호와 유사한 특성을 갖는 잡음 신호의 경우에는 이를 판별하기 힘들다는 단점이 존재하였다. 발명의 내용 해결 하고자하는 과제- 5 -공개특허 10-2009-0030063본 발명은 인간 음성의 유성음 특징을 이용한 음성 판별 방법 및 장치를 제공하는 것을 목적으로 한다. <5>또한 본 발명은 종래의 음성과 비음성의 판별 기술들이 실제 다양한 잡음 환경에서 그 성능이 저하되는 단점을 <6>극복하고 잡음에 강인한 유성음 검출 기술 및 이를 바탕으로 한 음성 판별 기술을 제공하는 것을 목적으로한다. 과제 해결수단상술한 목적들을 달성하기 위하여, 본 발명의 일 측면에 따르면, 외부로부터 수신된 음향 신호의 부가 잡음을 <7>제거하는 입력 신호 음질 향상부, 상기 입력 신호 음질 향상부로부터 음향 신호를 수신하여 상기 음향 신호에포함된 음성 신호의 끝점을 검출하는 제1 끝점 검출부, 상기 제1 끝점 검출부로부터 수신된 음향 신호에 포함된음성 신호의 유성음 특징을 추출하는 유성음 특징 추출부, 상기 유성음 특징 추출부에서 추출된 유성음 특징의판단 기준이 되는 유성음 모델 파라미터를 저장하는 유성음/비유성음 판단 모델부 및 상기 유성음 특징 추출부에서 추출된 유성음 특징을 상기 유성음/비유성음 판단 모델부의 유성음 모델 파라미터를 이용하여 유성음 부분을 판단하는 유성음/비유성음 판별부를 포함하는 음성 신호 판별장치를 제공할 수 있다.바람직한 실시예에 있어서, 상기 유성음/비유성음 판별부의 판단 결과 및 제1 끝점 검출부의 검출 결과에 상응 <8>하여 수신된 상기 음향 신호에 포함된 음성 신호의 끝점을 검출하는 제2 끝점 검출부를 더 포함할 수 있다. 또한, 상기 입력 음성 음질 향상부는 위너 필터, 최소 평균 제곱 오류(MMSE : Minimum mean square error) 방식및 칼만 방식 중 어느 하나의 방식을 사용하여 부가 잡음을 제거한 시간축 신호를 출력하는 것을 특징으로 할수 있다. 또한, 상기 유성음 특징 추출부는 수신된 연속 음성 신호의 변형 시간-주파수 신호 파라미터(Modified TF <9>parameter), HLFBER(high-to-Low Frequency Band Energy Ratio), 조성(Tonality), CMNDV(Cumulative MeanNormalized Difference Valley), ZCR(Zero-Crossing Rate), LCR(Level-Crossing Rate), PVR(Peak-to-ValleyRatio), ABPSE(Adaptive Band-Partitioning Spectral Entropy), NAP(Normalized Autocorrelation Peak),스펙트럼 엔트로피(Spectral entropy) 및 AMDV(Average Magnitude Difference Valley) 특징을 모두 추출하는 것을특징으로 할 수 있다. 또한, 상기 유성음/비유성음 판단 모델부는 순수 음성 모델에서 추출된 각 유성음 특징의임계치 및 경계치, GMM(Gaussian Mixture Model), MLP(Multi-Layer Perceptron) 및 SVM(Support VectorMachine) 방식의 모델 파라미터 값 중 어느 하나를 포함하는 것을 특징으로 할 수 있다. 또한, 상기 유성음/비유성음 판별부는 상기 유성음 특징의 임계치 및 경계치와 상기 추출된 음성 신호의 유성음 <10>특징을 단순 비교하는 방식, 통계적 모델을 이용하는 GMM 방식, 인공 지능을 이용하는 MLP 방식,CART(Classification and Regression Tree) 방식, LRT(Likelihood Ratio Test) 방식 및 SVM 방식 중 어느 하나를 이용하는 것을 특징으로 할 수 있다. 또한, 상기 제1 끝점 검출부는 상기 수신된 음향 신호의 시간-주파수영역의 에너지 및 엔트로피 기반의 특징을 이용하여 상기 음향 신호에 포함된 음성 신호의 끝점을 검출하고VSFR(Voiced Speech Frame Ratio)를 이용하여 음성인지 판단하고 음성 마킹 정보를 제공하는 것을 특징으로 할수 있다. 또한, 상기 제2 끝점 검출부는 GSAP(Global Speech Absence Probability), ZCR, LCR 및 엔트로피 계열의 파라미터 중 어느 하나를 이용하여 상기 음향 신호에 포함된 음성 신호의 끝점을 검출하는 것을 특징으로할 수 있다. 본 발명의 다른 일 측면을 참조하면, 외부로부터 음향 신호를 수신하는 단계, 상기 입력된 음향 신호의 부가 잡 <11>음을 제거하는 단계, 상기 부가 잡음이 제거된 음향 신호를 수신하여 상기 음향 신호에 포함된 음성 신호의 제1끝점을 검출하는 단계, 상기 제1 끝점이 검출된 음성 신호의 유성음 특징들을 추출하는 단계 및 상기 추출된 유성음 특징들과 미리 설정된 유성음/비유성음 판단 모델을 비교하여 입력된 음향 신호 중 유성음 부분을 판단하는 단계를 포함하는 음성 신호 판별 방법을 제공할 수 있다.바람직한 실시예에 있어서,상기 유성음 부분의 판단 결과에 상응하여 상기 음향 신호에 포함된 음성 신호의 제2 <12>끝점을 검출하는 단계를 더 포함할 수 있다. 또한, 상기 음향 신호의 부가 잡음 제거는 위너 필터, 최소 평균제곱 오류방식 및 칼만 방식 중 어느 하나의 방식을 사용하는 것을 특징으로 할 수 있다. 또한, 상기 유성음 특징은 수신된 연속 음성 신호의 변형 시간-주파수 신호 파라미터, HLFBER, 조성, CMNDV, ZCR, LCR, PVR, ABPSE,NAP, 스펙트럼 엔트로피 및 AMDV 특징인 것을 특징으로 할 수 있다. 또한, 상기 유성음/비유성음 판단 모델은순수 음성 모델에서 추출된 각 유성음 특징의 임계치 및 경계치, GMM, MLP 및 SVM 방식의 모델 파라미터 값 중어느 하나를 포함하는 것을 특징으로 할 수 있다. 또한, 상기 유성음 부분을 판단하는 방법은 상기 유성음 특징의 임계치 및 경계치와 상기 추출된 음성 신호의 유성음 특징을 단순 비교하는 방식, 통계적 모델을 이용하는- 6 -공개특허 10-2009-0030063GMM 방식, 인공 지능을 이용하는 MLP 방식, CART 방식, LRT 방식 및 SVM 방식 중 어느 하나를 이용하는 것을 특징으로 할 수 있다. 또한, 상기 제1 끝점을 검출하는 단계는 끝점 찾기 방식(EPD : end-point detection)을 적용하여 상기 음향 신호에 포함된 음성 신호의 시작점 및 종료점을 검출하는 단계를 더 포함할 수 있다. 효 과본 발명에 의하면 인간 음성의 유성음 특징을 이용한 음성 판별 방법 및 장치를 제공할 수 있다. <13>또한 본 발명에 의하면 종래의 음성과 비음성의 판별 기술들이 실제잡음 환경에서 그 성능이 저하되는 단점을 <14>극복하고 잡음에 강인한 유성음 검출 기술 및 이를 바탕으로 한 음성 판별 기술을 제공할 수 있다. 발명의 실시를 위한 구체적인 내용이하 첨부된 도면을 참조하여 본 발명에 따른 잡음 적응형 변별 학습 방법을 포함하는 잡음 적응형 음향 모델 <15>생성 방법 및 장치에 대하여 상세히 설명한다.도 1은 본 발명이 적용되는 음성 인식 장치의 전체적인 도면이다. <16>도 1을 참조하면, 본 발명이 적용되는 음성 인식 장치는 크게 전처리부(101), 특징벡터 추출부(103) 및 음성 인 <17>식부(105)로 나눌 수 있다.이러한 음성 인식 장치는 외부로부터 NON-PTT 방식으로 음성 및 잡음을 포함하는 음향 신호를 수신하면 전처리 <18>부(101)에서는 입력된 음향 중에서 부가 잡음 신호를 분리해낸 다음, 발화자가 발화하는 음성 구간을 정확히 구분해 내는 역할을 담당한다. 일반적으로 사용자가 발화 순간을 알려주는 PTT(Push-to-talk)방식에 비하여 연속음성에 대한 음성 인식은 잡음과 음성 구간을 분리하여 음성구간을 정확하게 추출해 내는 것이 매우 중요하며,본 발명이 중요하게 적용되는 부분이다.상기 전처리부(101)에서 음성 구간을 분리해 내면 특징 벡터 추출부(103)에서 상기 분리된 음성 신호를 음성 인 <19>식에 필요한 여러 가지 형태로 변환하게 된다. 이러한 특징 벡터 추출부(103)에서 변환되는 특징 벡터는 일반적으로 음성 인식에 적합하도록 각 음소의 특징이 잘 나타나며, 환경에 따라서 크게 변화하지 않는 특성을 가지는것이 된다.상기 특징 벡터 추출부(103)에서 추출된 특징 벡터를 이용하여 음성 인식부(105)에서는 그에 상응하는 음성을 <20>인식하게 된다. 이러한 음성 인식부(105)는 음향 모델이 및 음성 모델을 이용하여 통계적인 방법이나 의미론적인 방법 등을 이용하여 상기 특징 벡터가 나타내는 음소나 음가를 판단하여 입력된 음성 신호가 정확하게 어떤음성이었는지를 나타내게 된다.이렇게 음성 인식이 완료되면 음성 인식 결과를 바탕으로 의미 모델을 이용하여 음성을 해석하거나, 음성에 따 <21>른 명령을 내릴 수 있다.상기와 같은 음성 인식 방법에서 특히, 연속 음성을 수신하는 음성 인식 장치의 경우 음성 구간과 비음성 구간 <22>을 분리하는 것이 매우 중요하다.도 2는 본 발명의 바람직한 일 실시예에 따른 전처리부를 개략적으로 나타낸 도면이다. <23>도 2를 참조하면 본 발명에 따른 전처리부(101)는 입력 음성 음질 향상부(201), 제1 끝점 검출 및 음성 판별부 <24>(203), 유성음 특징 추출부(205), 유성음/비유성음 판단 모델(207), 유성음/비유성음 판별부(209) 및 제2 끝점검출부(211)를 포함한다.상기와 같은 전처리부의 구성은 본 발명의 일 실시예일 뿐이며, 본 발명의 권리범위 이내에서 다양한 실시예가 <25>가능할 것이다.우선 입력 신호의 음질 향상부(201)는 음성 신호 및 잡음 신호를 모두 포함하는 음향 신호에서 부가 잡음을 제 <26>거하여 부가 잡음에 의한 입력 신호의 음질 저하를 최소화하는 역할을 담당한다. 이러한 부가 잡음은 일반적으로 화자가 발성하는 동안 연속적으로 들려오는 단일 채널의 배경 잡음이 될 수 있다. 이러한 잡음을 제거하는방식으로는 위너 필터(Wiener Filter)나 최소 평균 제곱 오류(MMSE :Minimum mean-square error) 및 칼만(Kalman) 방식을 이용할 수 있다. 위너 필터는 입력을 원하는 출력과 가능한 한 매우 근사하게 변환시켜주는 필터로서, 필터 출력과 원하는 결과 <27>의 차의 제곱의 합이 최소가 되도록 하는 필터이다. 또한 최소 평균 제곱 오류는 상관함수를 이용한 것으로서- 7 -공개특허 10-2009-0030063모두 가우시안 잡음이나 균일 잡음 제거에 적합한 방식이다. 최소 제곱 오류에 관한 사항은 Y. Ephraim and D. Malah, \"Speech enhancement using a minimum mean-square <28>error short-time spectral amplitude estimator,\"IEEE Trans. Acoust., Speech, Signal Process., vol. 32,no. 6, pp. 1109-1121, Dec. 1984에서 확인 할 수 있으며, 위너 필터는 ETSI standard document, \"SpeechProcessing, Transmission and Quality aspects (STQ); Distributed speech recognition; Front-end featureextraction algorithm; Compression algorithm\", ETSI ES 201 108 v1.1.2 (2000-04), April 2000에서 확인 이가능하고, 칼만 방식은 Gannot, S., Burshtein, D., Weinstein, E., \"Iterative and sequential Kalmanfilter-based speech enhancement algorithms,\" IEEE Trans. On Speech and Audio Processing, vol. 6, Issue4. pp. 373-385, JULY 1998을 참조 할 수 있다.유성음 특징 추출부(205)는 상기 입력 음성 음질 향상부(201)에서 수신된 음성 신호를 바탕으로 유성음 특징을 <29>추출하는 역할을 담당한다. 입력되는 음성 신호에서 음악 잡음이나 배블(Babble) 잡음 등 음성신호와 유사한 음향특성을 갖는 잡음 신호가 혼합된 경우에는 기존의 방법으로는 화자의 음성 신호와 잡음을 구분하기가 까다로웠다. 본 발명에 있어서는 유성음 특징 추출부에서 음성과 비음성을 구분하기 위해서 음성의 유성음 부분을 나타내는 음성 특징을 11종류를 검출하여 기존의 방식으로는 구분하기 까다로운 잡음까지 분리할 수 있도록 하였다. 이러한 유성음 특징 11 종류 및 음성 추출 방법은 도 4에서 다시 자세하게 설명하도록 한다.유성음/비유성음 판단 모델부(207)는 잡음이 포함되지 않은 순수한 음성 모델로부터 추출된 유성음 특징의 임계 <30>치나 경계치를 저장하고 있는 부분이다. 즉, 상기 유성음 특징 추출부에서 추출된 특징이 실제로 유성음으로서판단되는지의 기준값을 저장하고 있는 부분이다. 이러한 유성음/비유성음 판단 모델부(207)에서 저장하는 모델파라미터 값은 다음에서 설명할 유성음/비유성음 판별부(209)에서 어떠한 판별 방식을 사용하느냐에 따라 달라질 수 있다.예를 들어, 단순히 유성음 특징들을 임계값이나 경계치와 단순 비교할 경우에는 순수 음성 모델로부터 추출된 <31>임계치나 경계치값을 저장하고 있으면 될 것이나, GMM(Gaussian Mixture Model), MLP(Multi-LayerPerceptron), SVM(Support Vector Machine) 방식, CART(Classification and Regression Tree) 방식,LRT(Likelihood Ratio Test) 방식 과 같은 방식이 사용될 경우 그에 따른 각각의 모델 파라미터 값을 저장하고있어야 할 것이다.여기서 GMM은 관측 데이터를 가우시안 분포의 확률 밀도 함수(pdf)로 표현하는 모델링 방법으로 통계적 기법이 <32>며, MLP는 신경망을 이용하여 데이터를 분석하는 방법 중 가장 널리 사용되는 모델로서, MLP는 입력층(inputlayer), 은닉마디로 구성된 은닉층(hidden layer), 그리고 출력층(output layer)으로 구성된 전방향(feed-forward) 신경망 모델을 의미한다.또한, SVM은 통계적 학습이론으로서 학습데이터와 범주 정보의 학습 진단을 대상으로 학습과정에서 얻어진 확률 <33>분포를 이용하여 의사결정함수를 추정한 후 이 함수에 따라 새로운 데이터를 이원 분류하는 방식으로 비선형 최적화 기법이다. 또한, CART는 분류 회기 트리 구조로 패턴을 분류하는 방식으로 분지 트리를 기반으로 데이터를분류하는 방식이다. LRT는 우도(尤度 -Likelihood)를 이용하여 데이터를 분류하는 방식이다.유성음/비유성음 판별부(209)는 상기 유성음 특징 추출부(205)에서 추출된 유성음 특징 11 가지와 유성음/비유 <34>성음 판단 모델부(207)에 저장된 판단 기준을 비교하여 입력된 음성 신호가 유성음 인지 판단하는 역할을 담당한다.이러한 유성음 판별부는 실시예 및 필요에 따라 단순히 유성음 특징들을 임계값이나 경계치와의 단순 비교, <35>GMM, MLP 방식, SVM(Support Vector Machine) 방식, CART 방식, LRT 방식 등이 존재할 수 있다.제1 끝점 검출 및 음성 판별부(203)는 음성 신호의 시간-주파수 영역의 에너지 및 엔트로피 기반의 특징등을 이 <36>용하여 음성의 시작점 혹은 끝점을 검출한다. 제1 끝점 검출 및 음성 판별부(203)에서 시작점이 검출된 음성신호 혹은 끝점이 검출되기 전까지 음성신호를 상기 유성음/비유성음 판별부(209) 유성음 특징추출부(205)에 전달하고 유성음/비유성음 판별부(209)의 결과를 바탕으로 VSFR(Voiced Speech Frame Ratio)를 이용하여 음성인지판단하고 음성의 시작점 및 끝점을 표시하는 음성 마킹 정보를 제공하는 역할을 담당한다. 여기서 VSFR은 전체 음성 프레임과 유성음 음성 프레임의 비를 나타낸다. 인간의 발성에는 일정구간 이상의 유 <37>성음이 반드시 포함되므로, 이러한 특성을 이용하여 쉽게 입력된 음향 신호의 음성/비음성을 판별할 수 있다.따라서 VSFR와 특정 임계값을 비교하는 방식으로 입력 음성구간이 음성인지 아닌지를 판별할 수 있게 된다.- 8 -공개특허 10-2009-0030063상기 제1 끝점 검출부(203)에서 우선 결정된 끝점 구간에 상기 유성음/비유성음 판별부(209)의 결과를 이용하여 <38>VSFR을 적용하면 판단된 끝점 구간이 실제로 음성 구간인지를 정확하게 확인 할 수 있다. 이렇게 음성 구간을판단한 다음 후술할 제2 끝점 검출부(211)에서 좀더 정확한 구간을 판단할 수 있도록 음성 마킹 정보를 제공할수 있다. 제2 끝점 검출부(211)는 상기 제1 끝점 검출부 및 음성판별부(203)에서 판단된 음성 구간에 대해서 좀더 정확한 <39>음성의 시작점 및 끝점을 검출하는 역할을 담당한다. 이러한 끝점 판단을 위하여 GSAP(Global Speech AbsenceProbability), ZCR(Zero-Crossing Rate), LCR(Level-Crossing Rate) 및 엔트로피 계열의 파라미터 중 어느 하나를 이용할 수 있다.여기서 GSAP는 전역 음성 부재 확률이며, 이는 매 프레임에서 하나의 값으로 표현되어지는 음성 부재 확률(SAP: <40>Speech Absence Probability)값이다.도 3은 본 발명의 바람직한 일 실시예에 따른 유성음, 비유성음 판단 방법을 개략적으로 나타낸 도면이다. <41>도 3은 상기 도 2에서 설명된 유성음/비유성음 판별부에서 유성음/비유성음을 판단하는 방법을 나타낸다. 도 3 <42>을 참조하면, 입력된 음향 신호 중 음성 구간으로 1차 판별된 부분의 부가 잡음이 제거된 음성 신호가 입력되면유성음 판별을 위한 특징을 추출한다(301). 이때 추출되는 유성음 특징은 상기 도 2에서 설명한 바와 같이 11종류의 특징이 추출된다. 이러한 11 종류의 특징에 의해서 기존의 방식으로는 구분하기 힘들었던 음악 잡음이나배블(Babble)잡음도 모두 검출이 가능하다. 이러한 11 종류의 특징은 도 4에서 자세히 설명하겠지만, 변형 시간-주파수 신호 파라미터(Modified TF parameter), HLFBER(high-to-Low Frequency Band Energy Ratio), 조성(Tonality), CMNDV(Cumulative Mean Normalized Difference Valley), ZCR(Zero-Crossing Rate), LCR(Level-Crossing Rate), PVR(Peak-to-Valley Ratio), ABPSE(Adaptive Band-Partitioning Spectral Entropy),NAP(Normalized Autocorrelation Peak),스펙트럼 엔트로피(Spectral entropy) 및 AMDV(Average MagnitudeDifference Valley) 특징이 될 수 있다.이러한 특징들은 크게 정규화된 자기상관 함수와 같은 시간 영역의 특징과 엔트로피 계열의 주파수 영역의 특징 <43>으로 분로될 수 있다.이렇게 특징이 추출되면 유성음/비유성음 판단 모델(303)과 추출된 특징을 이용하여 유성음과 비유성음을 결정 <44>할 수 있게 된다. 이러한 유성음/비유성음 판단은 실시예 및 필요에 따라 단순히 유성음 특징들을 임계값이나경계치와의 단순 비교, GMM(Gaussian Mixture Model), MLP(Multi-Layer Perceptron) 방식, SVM(Support VectorMachine) 방식, CART(Classification and Regression Tree) 방식, LRT(Likelihood Ratio Test) 방식 등을 이용할 수 있다.도 4는 본 발명의 바람직한 일 실시예에 따른 유성음 판단을 위한 특징 추출 방법을 나타낸 도면이다. <45>도 4를 참조하면, 우선 부가 잡음이 제거된 음성 신호가 입력되면 우선 유성음 특징 중 하나인 변형된 시간-주 <46>파수 신호 파라미터(Modified TF parameter)(401)를 구한다. 이러한 변형 시간-주파수 신호 파라미터(ModifiedTF parameter)를 구하는 방법은 도 5에서 자세히 설명하기로 한다. 그런 다음 변형 시간-주파수 신호 파라미터(Modified TF parameter)가 유성음 판단 모델부에 존재하는 임계치와 비교하여 임계치 이상인 경우에는 나머지유성음 특징 파라미터를 구한다. 나머지 유성음 특징 파라미터는 HLFBER(high-to-Low Frequency Band EnergyRatio)(415), 조성(Tonality)(417), CMNDV(Cumulative Mean Normalized Difference Valley)(413), ZCR(Zero-Crossing Rate)(419), LCR(Level-Crossing Rate)(421), PVR(Peak-to-Valley Ratio)(423), ABPSE(AdaptiveBand-Partitioning Spectral Entropy)(425), NAP(Normalized Autocorrelation Peak)(411),스펙트럼 엔트로피(Spectral entropy)(429) 및 AMDV(Average Magnitude Difference Valley)(427)가 된다. 이러한 특징 값의 의미 및 구하는 방법을 살펴보면, 우선 HLFBER(high-to-Low Frequency Band Energy <47>Ratio)(415)는 저주파 주파수 영역에서 에너지가 높은 유성음의 특징을 나타내며, 다음과 같은 수식으로 구할수 있다.- 9 -공개특허 10-2009-0030063<48>이러한 내용에 대한 자세한 사항은 James D. Johnston, \"Transform Coding of Audio Signals Using Perceptual <49>Noise Criteria\", IEEE Journal On Selected Areas In Communications, VOL. 6, NO. 2, FEBRUARY 1988을 통하여 확인 할 수 있다.조성(Tonality)(417)은 톤(tone)과 하모니 성분으로 구성된 유성음의 특징을 나타내며 다음과 같은 수식으로 구 <50>할 수 있다. 하기 수식에서 alpha는 조성이다.<51>여기서, <52>CMNDV(Cumulative Mean Normalized Difference Valley)(413)는 YIN 알고리듬을 기본으로 하여 구해지며, 유성 <53>음의 주기적인 특성을 나타내는 대표적인 특징으로 정규화된 자기 상관함수의 최고치와 유사한 특성을 가진다.이러한 특성에 대한 자세한 내용은 Alain de Cheveigne and Hideki Kawahara, \"YIN, A Fundamental Frequency <54>Estimator for Speech and Music\", Journal of the Acoustical Society of America, 111(4), 2002.을 통하여확인할 수 있다.ZCR(Zero-Crossing Rate) 및 LCR(Level-Crossing Rate)은 유성음의 주파수 적인 특징을 나타내는 <55>파라미터이다.이 특징에 관한 내용은 Lawrence R. Rabiner, \"On the Use of Autocorrelation Analysis for Pitch <56>Detection\", IEEE Trans. On Acoustics, Speech, And Signal Proc., VOL. ASSP-25, NO. 1, FEBRUARY 1977. 및, Lawrence R. Rabiner, \"On the Use of Autocorrelation Analysis for Pitch Detection\", IEEE Trans. OnAcoustics, Speech, And Signal Proc., VOL. ASSP-25, NO. 1, FEBRUARY 1977.을 통하여 확인할 수 있다.PVR(Peak-to-Valley Ratio)(423)은 유성음 크기의 주기성을 나타내는 특징으로 반파 정류된 자기 상관함수를 구 <57>하고 신호의 최고값과 최저값을 구하여 그 비를 계산하여 구한다.ABPSE(Adaptive Band-Partitioning Spectral Entropy)(425) 및 스펙트럼 엔트로피(Spectral entropy)(429)는 <58>유성음의 스펙트럼 특성을 잘 표현하는 특징으로 유성음의 하모닉 특성을 나타내는 파라미터이다.이 특성에 관한 참고는 Bing-Fei Wu and Kun-Ching Wang, \"Robust Endpoint Detection Algorithm Based on <59>the Adaptive Band-Partitioning Spectral Entropy in Adverse Environments\", IEEE Trans. On Speech andAudio Processing, VOL. 13, NO. 5. SEPTEMBER 2005에서 확인할 수 있다.NAP(Normalized Autocorrelation Peak)(411) 및 AMDV(Average Magnitude Difference Valley)(427)는 CMNDV와 <60>는 다른 유성음의 주기적인 특성을 나타내는 특징이다.여기서 AMDV는 Myron J. Ross, Harry L. Shaffer,Andrew Cohen, Richard Freudberg, and Harold J. Manley, \"Average Magnitude Difference Function PitchExtractor\", IEEE Trans. On Acoustics, Speech And Signal Proc., VOL. ASSP-22, NO. 5, OCTOBER 1974에서- 10 -공개특허 10-2009-0030063참조할 수 있다.이러한 유성음 특징의 경우 기존의 전처리 방식에서 거의 사용하지 않았던 특성으로 이러한 특성을 모두 판별할 <61>경우 기존의 유성음 판별방식에 비해 획기적으로 개선된 음성 구간의 판별이 가능하다.이렇게 각각 다른 방식으로 구해진 유성음 특징들을 유성음/비유성음 분류 방법(407)을 이용하여 분류할 수 있 <62>다. 본 도면에서는 유성음/비유성음 분류 방법 중 가장 간단한 임계치와 경계치를 이용하여 단순히 비교하는 방법을 이용하였다. 이렇게 유성음/비유성음 분류 방법을 이용하여 분류한 결과가 모든 유성음 특징이 임계치와 경계치를 만족한다 <63>면(409) 이는 유성음 신호로서 판단할 수 있게 된다.본 도면에서 간단한 임계치 및 경계치를 이용하는 방법을 사용한 것은 비교적 조용한 환경에서 수집된 음성 데 <64>이터들로부터 변형된 시간-주파수 신호 파라미터를 이용하면 유성음 구간은 자동으로 검출되고 이러한 유성음구간에 대해서 나머지 유성음 특징들을 추출한 후 특징들의 임계치를 추출하면 대량의 음성 데이터나 잡음 데이터를 수집하거나 훈련하는 과정 없이 비교적 간단하게 구현이 가능하기 때문이다.도 5는 본 발명에 적용되는 변형된 시간-주파수 신호 파라미터를 구하는 순서를 나타내는 도면이다. <65>도 5를 참조하면, 본 발명에서 이용되는 유성음 특징 중 가장 먼저 구하는 변형된 시간-주파수 신호 파라미터 <66>(Modified TF parameter)는 우선 부가 잡음이 제거된 음성 신호가 입력되면(단계 501), 상기 신호는 각각 주파수 신호 구간과 시간 신호 구간으로 나눠져서 계산된다. 우선 주파수 신호 구간에서는 입력되는 음성 신호는 시간축 기준의 파형이므로 이른 주파수 신호로 변형하기 위하여 페스트 푸리에 변환(FFT : Fast FourierTransform)을 이용하여 시간 신호를 주파수 신호로 변환한다(단계 503). 그 후 변환된 주파수 신호 중 주 사용에너지인 500Hz ~ 3500Hz 구간의 에너지를 계산한다(단계 507). 한편으로 시간 신호는 특별한 변형이 필요하지않으므로 바로 시간 신호의 에너지를 계산한다(단계 505). 그런 다음 상기 참조 번호 507 및 505 단계에서 계산된 결과 값을 합산하고(단계 509), 그 후 평탄화 <67>(smoothing) 작업을 수행한다(단계 511). 그럼 다음 결과 값을 로그(Log) 스케일로 변환한다(단계 513). 이러한단계를 거쳐서 변형된 시간-주파수 신호 파라미터(Modified TF parameter)가 구해진다(단계 515).이러한 방법에 대한 자세한 참고는 Jean-Claude Junqua, Brain Mak and Ben Reaves, \"A Robust Algorithm for <68>Word Boundary Detection in the Presence of Noise\", IEEE Trans. Speech and Audio Proc., VOL. 2, NO. 3,pp. 406~412, JULY 1994를 통하여 확인할 수 있다.본 발명은 상기 실시예에 한정되지 않으며, 많은 변형이 본 발명의 사상 내에서 당 분야에서 통상의 지식을 가 <69>진 자에 의하여 가능함은 물론이다. 도면의 간단한 설명도 1은 본 발명이 적용되는 음성 인식 장치의 전체적인 도면. <70>도 2는 본 발명의 바람직한 일 실시예에 따른 전처리부를 개략적으로 나타낸 도면. <71>도 3은 본 발명의 바람직한 일 실시예에 따른 유성음, 비유성음 판단 방법을 개략적으로 나타낸 도면. <72>도 4는 본 발명의 바람직한 일 실시예에 따른 유성음, 비유성음 판단을 위한 특징 추출 방법을 나타낸 도면. <73>도 5는 본 발명에 적용되는 변형된 시간-주파수 신호 파라미터를 구하는 순서를 나타내는 도면. <74><도면의 주요 부분에 대한 부호의 설명> <75>201 : 입력 음성 음질 향상부 <76>203 : 제1 끝점 검출 및 음성 판별부 <77>205 : 유성음 특징 추출부 <78>207 : 유성음 판단 모델 <79>209 : 유성음 판별부 <80>211 : 제2 끝점 검출부 <81>- 11 -공개특허 10-2009-0030063도면 도면1 도면2- 12 -공개특허 10-2009-0030063 도면3 도면4- 13 -공개특허 10-2009-0030063 도면5- 14 -공개특허 10-2009-0030063"}
{"patent_id": "10-2007-0095375", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 외부로부터 수신된 음향 신호의 부가 잡음을 제거하는 입력 신호 음질 향상부, 입력 신호 음질 향상부 로부터 음향 신호를 수신하여 음향 신호에 포함된 음성 신호의 끝점을 검출하는 제1 끝점 검출부, 제1 끝점 검출 부로부터 수신된 음향 신호에 포함된 음성 신호의 유성음 특징을 추출하는 유성음 특징 추출부, 유성음 특징 추 출부에서 추출된 유성음 특징의 판단 기준이 되는 유성음 모델 파라미터를 저장하는 유성음/비유성음 판단 모델 부 및 유성음 특징 추출부에서 추출된 유성음 특징을 유성음/비유성음 판단 모델부의 유성음 모델 파라미터를 이 용하여 유성음 부분을 판단하는 유성음/비유성음 판별부를 포함하는 음성 신호 판별장치를 제공할 수 있다."}
{"patent_id": "10-2007-0095375", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 인간 음성의 유성음 특징을 이용한 음성/비음성 판별 방법 및 장치에 관한 것이다. <1> 본 발명은 정보통신부 및 정보통신연구진흥원의 IT신성장동력핵심기술개발사업의 일환으로 수행한 연구로부터 <2> 도출된 것이다[과제관리번호: 2006-S-036-02, 과제명: 신성장동력산업용 대용량 대화형 분산 처리 음성인터페이 스 기술개발]"}
{"patent_id": "10-2007-0095375", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "실제 다양한 잡음 환경에서 자동음성인식시스템을 적용하기 위해서는 많은 진입 장벽들이 존재하는데 그 중 하 <3> 나가 실제 잡음 문제이다. 일상 생활에서 흔히 발생하는 다양한 잡음환경 속에서 자동음성인식시스템이 잘 동작 하기 위해서는 음성에 섞여 있는 잡음신호를 잘 추정하여 제거하는 기술도 중요하지만 사용자 음성만을 검출해 낼 수 있는 끝점검출 기술 또한 매우 중요한 기술 중의 하나이다. 특히, 사용자가 발성의 시작을 알리지 않는 연속 음성(NON-PTT : non-push-to-talk) 방식에서는 사용자 음성이 아닌 다른 잡음신호들이 음성인식시스템으로 입력되어 그 성능을 저하시키는 요인으로 작용하는 문제가 있어 실제 상용화 시스템에서는 NON-PTT 방식을 적용 하기 어려웠다. NON-PTT 방식의 자동음성인식을 위해서는 입력된 음성신호가 사용자 음성인지 아닌지를 판별하는 음성 판별기술 <4> 이 요구된다. 그러나 기존의 방식을 이용할 경우에는 배경 음악이나 배블(Babble) 잡음과 같은 화자의 음성 신 호와 유사한 특성을 갖는 잡음 신호의 경우에는 이를 판별하기 힘들다는 단점이 존재하였다."}
{"patent_id": "10-2007-0095375", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 2, "content": "발명의 내용 해결 하고자하는 과제 - 5 -공개특허 10-2009-0030063본 발명은 인간 음성의 유성음 특징을 이용한 음성 판별 방법 및 장치를 제공하는 것을 목적으로 한다. <5> 또한 본 발명은 종래의 음성과 비음성의 판별 기술들이 실제 다양한 잡음 환경에서 그 성능이 저하되는 단점을 <6> 극복하고 잡음에 강인한 유성음 검출 기술 및 이를 바탕으로 한 음성 판별 기술을 제공하는 것을 목적으로 한다. 과제 해결수단 상술한 목적들을 달성하기 위하여, 본 발명의 일 측면에 따르면, 외부로부터 수신된 음향 신호의 부가 잡음을 <7> 제거하는 입력 신호 음질 향상부, 상기 입력 신호 음질 향상부로부터 음향 신호를 수신하여 상기 음향 신호에 포함된 음성 신호의 끝점을 검출하는 제1 끝점 검출부, 상기 제1 끝점 검출부로부터 수신된 음향 신호에 포함된 음성 신호의 유성음 특징을 추출하는 유성음 특징 추출부, 상기 유성음 특징 추출부에서 추출된 유성음 특징의 판단 기준이 되는 유성음 모델 파라미터를 저장하는 유성음/비유성음 판단 모델부 및 상기 유성음 특징 추출부 에서 추출된 유성음 특징을 상기 유성음/비유성음 판단 모델부의 유성음 모델 파라미터를 이용하여 유성음 부분 을 판단하는 유성음/비유성음 판별부를 포함하는 음성 신호 판별장치를 제공할 수 있다. 바람직한 실시예에 있어서, 상기 유성음/비유성음 판별부의 판단 결과 및 제1 끝점 검출부의 검출 결과에 상응 <8> 하여 수신된 상기 음향 신호에 포함된 음성 신호의 끝점을 검출하는 제2 끝점 검출부를 더 포함할 수 있다. 또 한, 상기 입력 음성 음질 향상부는 위너 필터, 최소 평균 제곱 오류(MMSE : Minimum mean square error) 방식 및 칼만 방식 중 어느 하나의 방식을 사용하여 부가 잡음을 제거한 시간축 신호를 출력하는 것을 특징으로 할 수 있다. 또한, 상기 유성음 특징 추출부는 수신된 연속 음성 신호의 변형 시간-주파수 신호 파라미터(Modified TF <9> parameter), HLFBER(high-to-Low Frequency Band Energy Ratio), 조성(Tonality), CMNDV(Cumulative Mean Normalized Difference Valley), ZCR(Zero-Crossing Rate), LCR(Level-Crossing Rate), PVR(Peak-to-Valley Ratio), ABPSE(Adaptive Band-Partitioning Spectral Entropy), NAP(Normalized Autocorrelation Peak),스펙 트럼 엔트로피(Spectral entropy) 및 AMDV(Average Magnitude Difference Valley) 특징을 모두 추출하는 것을 특징으로 할 수 있다. 또한, 상기 유성음/비유성음 판단 모델부는 순수 음성 모델에서 추출된 각 유성음 특징의 임계치 및 경계치, GMM(Gaussian Mixture Model), MLP(Multi-Layer Perceptron) 및 SVM(Support Vector Machine) 방식의 모델 파라미터 값 중 어느 하나를 포함하는 것을 특징으로 할 수 있다. 또한, 상기 유성음/비유성음 판별부는 상기 유성음 특징의 임계치 및 경계치와 상기 추출된 음성 신호의 유성음 <10> 특징을 단순 비교하는 방식, 통계적 모델을 이용하는 GMM 방식, 인공 지능을 이용하는 MLP 방식, CART(Classification and Regression Tree) 방식, LRT(Likelihood Ratio Test) 방식 및 SVM 방식 중 어느 하나 를 이용하는 것을 특징으로 할 수 있다. 또한, 상기 제1 끝점 검출부는 상기 수신된 음향 신호의 시간-주파수 영역의 에너지 및 엔트로피 기반의 특징을 이용하여 상기 음향 신호에 포함된 음성 신호의 끝점을 검출하고 VSFR(Voiced Speech Frame Ratio)를 이용하여 음성인지 판단하고 음성 마킹 정보를 제공하는 것을 특징으로 할 수 있다. 또한, 상기 제2 끝점 검출부는 GSAP(Global Speech Absence Probability), ZCR, LCR 및 엔트로피 계 열의 파라미터 중 어느 하나를 이용하여 상기 음향 신호에 포함된 음성 신호의 끝점을 검출하는 것을 특징으로 할 수 있다. 본 발명의 다른 일 측면을 참조하면, 외부로부터 음향 신호를 수신하는 단계, 상기 입력된 음향 신호의 부가 잡 <11> 음을 제거하는 단계, 상기 부가 잡음이 제거된 음향 신호를 수신하여 상기 음향 신호에 포함된 음성 신호의 제1 끝점을 검출하는 단계, 상기 제1 끝점이 검출된 음성 신호의 유성음 특징들을 추출하는 단계 및 상기 추출된 유 성음 특징들과 미리 설정된 유성음/비유성음 판단 모델을 비교하여 입력된 음향 신호 중 유성음 부분을 판단하 는 단계를 포함하는 음성 신호 판별 방법을 제공할 수 있다. 바람직한 실시예에 있어서,상기 유성음 부분의 판단 결과에 상응하여 상기 음향 신호에 포함된 음성 신호의 제2 <12> 끝점을 검출하는 단계를 더 포함할 수 있다. 또한, 상기 음향 신호의 부가 잡음 제거는 위너 필터, 최소 평균 제곱 오류방식 및 칼만 방식 중 어느 하나의 방식을 사용하는 것을 특징으로 할 수 있다. 또한, 상기 유성음 특 징은 수신된 연속 음성 신호의 변형 시간-주파수 신호 파라미터, HLFBER, 조성, CMNDV, ZCR, LCR, PVR, ABPSE, NAP, 스펙트럼 엔트로피 및 AMDV 특징인 것을 특징으로 할 수 있다. 또한, 상기 유성음/비유성음 판단 모델은 순수 음성 모델에서 추출된 각 유성음 특징의 임계치 및 경계치, GMM, MLP 및 SVM 방식의 모델 파라미터 값 중 어느 하나를 포함하는 것을 특징으로 할 수 있다. 또한, 상기 유성음 부분을 판단하는 방법은 상기 유성음 특징 의 임계치 및 경계치와 상기 추출된 음성 신호의 유성음 특징을 단순 비교하는 방식, 통계적 모델을 이용하는 - 6 -공개특허 10-2009-0030063GMM 방식, 인공 지능을 이용하는 MLP 방식, CART 방식, LRT 방식 및 SVM 방식 중 어느 하나를 이용하는 것을 특 징으로 할 수 있다. 또한, 상기 제1 끝점을 검출하는 단계는 끝점 찾기 방식(EPD : end-point detection)을 적 용하여 상기 음향 신호에 포함된 음성 신호의 시작점 및 종료점을 검출하는 단계를 더 포함할 수 있다. 효 과 본 발명에 의하면 인간 음성의 유성음 특징을 이용한 음성 판별 방법 및 장치를 제공할 수 있다. <13> 또한 본 발명에 의하면 종래의 음성과 비음성의 판별 기술들이 실제잡음 환경에서 그 성능이 저하되는 단점을 <14> 극복하고 잡음에 강인한 유성음 검출 기술 및 이를 바탕으로 한 음성 판별 기술을 제공할 수 있다. 발명의 실시를 위한 구체적인 내용 이하 첨부된 도면을 참조하여 본 발명에 따른 잡음 적응형 변별 학습 방법을 포함하는 잡음 적응형 음향 모델 <15> 생성 방법 및 장치에 대하여 상세히 설명한다. 도 1은 본 발명이 적용되는 음성 인식 장치의 전체적인 도면이다. <16> 도 1을 참조하면, 본 발명이 적용되는 음성 인식 장치는 크게 전처리부, 특징벡터 추출부 및 음성 인 <17> 식부로 나눌 수 있다. 이러한 음성 인식 장치는 외부로부터 NON-PTT 방식으로 음성 및 잡음을 포함하는 음향 신호를 수신하면 전처리 <18> 부에서는 입력된 음향 중에서 부가 잡음 신호를 분리해낸 다음, 발화자가 발화하는 음성 구간을 정확히 구 분해 내는 역할을 담당한다. 일반적으로 사용자가 발화 순간을 알려주는 PTT(Push-to-talk)방식에 비하여 연속 음성에 대한 음성 인식은 잡음과 음성 구간을 분리하여 음성구간을 정확하게 추출해 내는 것이 매우 중요하며, 본 발명이 중요하게 적용되는 부분이다. 상기 전처리부에서 음성 구간을 분리해 내면 특징 벡터 추출부에서 상기 분리된 음성 신호를 음성 인 <19> 식에 필요한 여러 가지 형태로 변환하게 된다. 이러한 특징 벡터 추출부에서 변환되는 특징 벡터는 일반적 으로 음성 인식에 적합하도록 각 음소의 특징이 잘 나타나며, 환경에 따라서 크게 변화하지 않는 특성을 가지는 것이 된다. 상기 특징 벡터 추출부에서 추출된 특징 벡터를 이용하여 음성 인식부에서는 그에 상응하는 음성을 <20> 인식하게 된다. 이러한 음성 인식부는 음향 모델이 및 음성 모델을 이용하여 통계적인 방법이나 의미론적 인 방법 등을 이용하여 상기 특징 벡터가 나타내는 음소나 음가를 판단하여 입력된 음성 신호가 정확하게 어떤 음성이었는지를 나타내게 된다. 이렇게 음성 인식이 완료되면 음성 인식 결과를 바탕으로 의미 모델을 이용하여 음성을 해석하거나, 음성에 따 <21> 른 명령을 내릴 수 있다. 상기와 같은 음성 인식 방법에서 특히, 연속 음성을 수신하는 음성 인식 장치의 경우 음성 구간과 비음성 구간 <22> 을 분리하는 것이 매우 중요하다. 도 2는 본 발명의 바람직한 일 실시예에 따른 전처리부를 개략적으로 나타낸 도면이다. <23> 도 2를 참조하면 본 발명에 따른 전처리부는 입력 음성 음질 향상부, 제1 끝점 검출 및 음성 판별부 <24> , 유성음 특징 추출부, 유성음/비유성음 판단 모델, 유성음/비유성음 판별부 및 제2 끝점 검출부를 포함한다. 상기와 같은 전처리부의 구성은 본 발명의 일 실시예일 뿐이며, 본 발명의 권리범위 이내에서 다양한 실시예가 <25> 가능할 것이다. 우선 입력 신호의 음질 향상부는 음성 신호 및 잡음 신호를 모두 포함하는 음향 신호에서 부가 잡음을 제 <26> 거하여 부가 잡음에 의한 입력 신호의 음질 저하를 최소화하는 역할을 담당한다. 이러한 부가 잡음은 일반적으 로 화자가 발성하는 동안 연속적으로 들려오는 단일 채널의 배경 잡음이 될 수 있다. 이러한 잡음을 제거하는 방식으로는 위너 필터(Wiener Filter)나 최소 평균 제곱 오류(MMSE :Minimum mean-square error) 및 칼만 (Kalman) 방식을 이용할 수 있다. 위너 필터는 입력을 원하는 출력과 가능한 한 매우 근사하게 변환시켜주는 필터로서, 필터 출력과 원하는 결과 <27> 의 차의 제곱의 합이 최소가 되도록 하는 필터이다. 또한 최소 평균 제곱 오류는 상관함수를 이용한 것으로서 - 7 -공개특허 10-2009-0030063모두 가우시안 잡음이나 균일 잡음 제거에 적합한 방식이다. 최소 제곱 오류에 관한 사항은 Y. Ephraim and D. Malah, \"Speech enhancement using a minimum mean-square <28> error short-time spectral amplitude estimator,\"IEEE Trans. Acoust., Speech, Signal Process., vol. 32, no. 6, pp. 1109-1121, Dec. 1984에서 확인 할 수 있으며, 위너 필터는 ETSI standard document, \"Speech Processing, Transmission and Quality aspects (STQ); Distributed speech recognition; Front-end feature extraction algorithm; Compression algorithm\", ETSI ES 201 108 v1.1.2 (2000-04), April 2000에서 확인 이 가능하고, 칼만 방식은 Gannot, S., Burshtein, D., Weinstein, E., \"Iterative and sequential Kalman filter-based speech enhancement algorithms,\" IEEE Trans. On Speech and Audio Processing, vol. 6, Issue 4. pp. 373-385, JULY 1998을 참조 할 수 있다. 유성음 특징 추출부는 상기 입력 음성 음질 향상부에서 수신된 음성 신호를 바탕으로 유성음 특징을 <29> 추출하는 역할을 담당한다. 입력되는 음성 신호에서 음악 잡음이나 배블(Babble) 잡음 등 음성신호와 유사한 음 향특성을 갖는 잡음 신호가 혼합된 경우에는 기존의 방법으로는 화자의 음성 신호와 잡음을 구분하기가 까다로 웠다. 본 발명에 있어서는 유성음 특징 추출부에서 음성과 비음성을 구분하기 위해서 음성의 유성음 부분을 나 타내는 음성 특징을 11종류를 검출하여 기존의 방식으로는 구분하기 까다로운 잡음까지 분리할 수 있도록 하였 다. 이러한 유성음 특징 11 종류 및 음성 추출 방법은 도 4에서 다시 자세하게 설명하도록 한다. 유성음/비유성음 판단 모델부는 잡음이 포함되지 않은 순수한 음성 모델로부터 추출된 유성음 특징의 임계 <30> 치나 경계치를 저장하고 있는 부분이다. 즉, 상기 유성음 특징 추출부에서 추출된 특징이 실제로 유성음으로서 판단되는지의 기준값을 저장하고 있는 부분이다. 이러한 유성음/비유성음 판단 모델부에서 저장하는 모델 파라미터 값은 다음에서 설명할 유성음/비유성음 판별부에서 어떠한 판별 방식을 사용하느냐에 따라 달라 질 수 있다. 예를 들어, 단순히 유성음 특징들을 임계값이나 경계치와 단순 비교할 경우에는 순수 음성 모델로부터 추출된 <31> 임계치나 경계치값을 저장하고 있으면 될 것이나, GMM(Gaussian Mixture Model), MLP(Multi-Layer Perceptron), SVM(Support Vector Machine) 방식, CART(Classification and Regression Tree) 방식, LRT(Likelihood Ratio Test) 방식 과 같은 방식이 사용될 경우 그에 따른 각각의 모델 파라미터 값을 저장하고 있어야 할 것이다. 여기서 GMM은 관측 데이터를 가우시안 분포의 확률 밀도 함수(pdf)로 표현하는 모델링 방법으로 통계적 기법이 <32> 며, MLP는 신경망을 이용하여 데이터를 분석하는 방법 중 가장 널리 사용되는 모델로서, MLP는 입력층(input layer), 은닉마디로 구성된 은닉층(hidden layer), 그리고 출력층(output layer)으로 구성된 전방향(feed- forward) 신경망 모델을 의미한다. 또한, SVM은 통계적 학습이론으로서 학습데이터와 범주 정보의 학습 진단을 대상으로 학습과정에서 얻어진 확률 <33> 분포를 이용하여 의사결정함수를 추정한 후 이 함수에 따라 새로운 데이터를 이원 분류하는 방식으로 비선형 최 적화 기법이다. 또한, CART는 분류 회기 트리 구조로 패턴을 분류하는 방식으로 분지 트리를 기반으로 데이터를 분류하는 방식이다. LRT는 우도(尤度 -Likelihood)를 이용하여 데이터를 분류하는 방식이다. 유성음/비유성음 판별부는 상기 유성음 특징 추출부에서 추출된 유성음 특징 11 가지와 유성음/비유 <34> 성음 판단 모델부에 저장된 판단 기준을 비교하여 입력된 음성 신호가 유성음 인지 판단하는 역할을 담당 한다. 이러한 유성음 판별부는 실시예 및 필요에 따라 단순히 유성음 특징들을 임계값이나 경계치와의 단순 비교, <35> GMM, MLP 방식, SVM(Support Vector Machine) 방식, CART 방식, LRT 방식 등이 존재할 수 있다. 제1 끝점 검출 및 음성 판별부는 음성 신호의 시간-주파수 영역의 에너지 및 엔트로피 기반의 특징등을 이 <36> 용하여 음성의 시작점 혹은 끝점을 검출한다. 제1 끝점 검출 및 음성 판별부에서 시작점이 검출된 음성신 호 혹은 끝점이 검출되기 전까지 음성신호를 상기 유성음/비유성음 판별부 유성음 특징추출부에 전달 하고 유성음/비유성음 판별부의 결과를 바탕으로 VSFR(Voiced Speech Frame Ratio)를 이용하여 음성인지 판단하고 음성의 시작점 및 끝점을 표시하는 음성 마킹 정보를 제공하는 역할을 담당한다. 여기서 VSFR은 전체 음성 프레임과 유성음 음성 프레임의 비를 나타낸다. 인간의 발성에는 일정구간 이상의 유 <37> 성음이 반드시 포함되므로, 이러한 특성을 이용하여 쉽게 입력된 음향 신호의 음성/비음성을 판별할 수 있다. 따라서 VSFR와 특정 임계값을 비교하는 방식으로 입력 음성구간이 음성인지 아닌지를 판별할 수 있게 된다. - 8 -공개특허 10-2009-0030063상기 제1 끝점 검출부에서 우선 결정된 끝점 구간에 상기 유성음/비유성음 판별부의 결과를 이용하여 <38> VSFR을 적용하면 판단된 끝점 구간이 실제로 음성 구간인지를 정확하게 확인 할 수 있다. 이렇게 음성 구간을 판단한 다음 후술할 제2 끝점 검출부에서 좀더 정확한 구간을 판단할 수 있도록 음성 마킹 정보를 제공할 수 있다. 제2 끝점 검출부는 상기 제1 끝점 검출부 및 음성판별부에서 판단된 음성 구간에 대해서 좀더 정확한 <39> 음성의 시작점 및 끝점을 검출하는 역할을 담당한다. 이러한 끝점 판단을 위하여 GSAP(Global Speech Absence Probability), ZCR(Zero-Crossing Rate), LCR(Level-Crossing Rate) 및 엔트로피 계열의 파라미터 중 어느 하 나를 이용할 수 있다. 여기서 GSAP는 전역 음성 부재 확률이며, 이는 매 프레임에서 하나의 값으로 표현되어지는 음성 부재 확률(SAP: <40> Speech Absence Probability)값이다. 도 3은 본 발명의 바람직한 일 실시예에 따른 유성음, 비유성음 판단 방법을 개략적으로 나타낸 도면이다. <41> 도 3은 상기 도 2에서 설명된 유성음/비유성음 판별부에서 유성음/비유성음을 판단하는 방법을 나타낸다. 도 3 <42> 을 참조하면, 입력된 음향 신호 중 음성 구간으로 1차 판별된 부분의 부가 잡음이 제거된 음성 신호가 입력되면 유성음 판별을 위한 특징을 추출한다. 이때 추출되는 유성음 특징은 상기 도 2에서 설명한 바와 같이 11 종류의 특징이 추출된다. 이러한 11 종류의 특징에 의해서 기존의 방식으로는 구분하기 힘들었던 음악 잡음이나 배블(Babble)잡음도 모두 검출이 가능하다. 이러한 11 종류의 특징은 도 4에서 자세히 설명하겠지만, 변형 시간 -주파수 신호 파라미터(Modified TF parameter), HLFBER(high-to-Low Frequency Band Energy Ratio), 조성 (Tonality), CMNDV(Cumulative Mean Normalized Difference Valley), ZCR(Zero-Crossing Rate), LCR(Level- Crossing Rate), PVR(Peak-to-Valley Ratio), ABPSE(Adaptive Band-Partitioning Spectral Entropy), NAP(Normalized Autocorrelation Peak),스펙트럼 엔트로피(Spectral entropy) 및 AMDV(Average Magnitude Difference Valley) 특징이 될 수 있다. 이러한 특징들은 크게 정규화된 자기상관 함수와 같은 시간 영역의 특징과 엔트로피 계열의 주파수 영역의 특징 <43> 으로 분로될 수 있다. 이렇게 특징이 추출되면 유성음/비유성음 판단 모델과 추출된 특징을 이용하여 유성음과 비유성음을 결정 <44> 할 수 있게 된다. 이러한 유성음/비유성음 판단은 실시예 및 필요에 따라 단순히 유성음 특징들을 임계값이나 경계치와의 단순 비교, GMM(Gaussian Mixture Model), MLP(Multi-Layer Perceptron) 방식, SVM(Support Vector Machine) 방식, CART(Classification and Regression Tree) 방식, LRT(Likelihood Ratio Test) 방식 등을 이 용할 수 있다. 도 4는 본 발명의 바람직한 일 실시예에 따른 유성음 판단을 위한 특징 추출 방법을 나타낸 도면이다. <45> 도 4를 참조하면, 우선 부가 잡음이 제거된 음성 신호가 입력되면 우선 유성음 특징 중 하나인 변형된 시간-주 <46> 파수 신호 파라미터(Modified TF parameter)를 구한다. 이러한 변형 시간-주파수 신호 파라미터(Modified TF parameter)를 구하는 방법은 도 5에서 자세히 설명하기로 한다. 그런 다음 변형 시간-주파수 신호 파라미터 (Modified TF parameter)가 유성음 판단 모델부에 존재하는 임계치와 비교하여 임계치 이상인 경우에는 나머지 유성음 특징 파라미터를 구한다. 나머지 유성음 특징 파라미터는 HLFBER(high-to-Low Frequency Band Energy Ratio), 조성(Tonality), CMNDV(Cumulative Mean Normalized Difference Valley), ZCR(Zero- Crossing Rate), LCR(Level-Crossing Rate), PVR(Peak-to-Valley Ratio), ABPSE(Adaptive Band-Partitioning Spectral Entropy), NAP(Normalized Autocorrelation Peak),스펙트럼 엔트로피 (Spectral entropy) 및 AMDV(Average Magnitude Difference Valley)가 된다. 이러한 특징 값의 의미 및 구하는 방법을 살펴보면, 우선 HLFBER(high-to-Low Frequency Band Energy <47> Ratio)는 저주파 주파수 영역에서 에너지가 높은 유성음의 특징을 나타내며, 다음과 같은 수식으로 구할 수 있다. - 9 -공개특허 10-2009-0030063<48> 이러한 내용에 대한 자세한 사항은 James D. Johnston, \"Transform Coding of Audio Signals Using Perceptual <49> Noise Criteria\", IEEE Journal On Selected Areas In Communications, VOL. 6, NO. 2, FEBRUARY 1988을 통하 여 확인 할 수 있다. 조성(Tonality)은 톤(tone)과 하모니 성분으로 구성된 유성음의 특징을 나타내며 다음과 같은 수식으로 구 <50> 할 수 있다. 하기 수식에서 alpha는 조성이다. <51> 여기서, <52> CMNDV(Cumulative Mean Normalized Difference Valley)는 YIN 알고리듬을 기본으로 하여 구해지며, 유성 <53> 음의 주기적인 특성을 나타내는 대표적인 특징으로 정규화된 자기 상관함수의 최고치와 유사한 특성을 가진다. 이러한 특성에 대한 자세한 내용은 Alain de Cheveigne and Hideki Kawahara, \"YIN, A Fundamental Frequency <54> Estimator for Speech and Music\", Journal of the Acoustical Society of America, 111, 2002.을 통하여 확인할 수 있다. ZCR(Zero-Crossing Rate) 및 LCR(Level-Crossing Rate)은 유성음의 주파수 적인 특징을 나타내는 <55> 파라미터이다. 이 특징에 관한 내용은 Lawrence R. Rabiner, \"On the Use of Autocorrelation Analysis for Pitch <56> Detection\", IEEE Trans. On Acoustics, Speech, And Signal Proc., VOL. ASSP-25, NO. 1, FEBRUARY 1977. 및 , Lawrence R. Rabiner, \"On the Use of Autocorrelation Analysis for Pitch Detection\", IEEE Trans. On Acoustics, Speech, And Signal Proc., VOL. ASSP-25, NO. 1, FEBRUARY 1977.을 통하여 확인할 수 있다. PVR(Peak-to-Valley Ratio)은 유성음 크기의 주기성을 나타내는 특징으로 반파 정류된 자기 상관함수를 구 <57> 하고 신호의 최고값과 최저값을 구하여 그 비를 계산하여 구한다. ABPSE(Adaptive Band-Partitioning Spectral Entropy) 및 스펙트럼 엔트로피(Spectral entropy)는 <58> 유성음의 스펙트럼 특성을 잘 표현하는 특징으로 유성음의 하모닉 특성을 나타내는 파라미터이다. 이 특성에 관한 참고는 Bing-Fei Wu and Kun-Ching Wang, \"Robust Endpoint Detection Algorithm Based on <59> the Adaptive Band-Partitioning Spectral Entropy in Adverse Environments\", IEEE Trans. On Speech and Audio Processing, VOL. 13, NO. 5. SEPTEMBER 2005에서 확인할 수 있다. NAP(Normalized Autocorrelation Peak) 및 AMDV(Average Magnitude Difference Valley)는 CMNDV와 <60> 는 다른 유성음의 주기적인 특성을 나타내는 특징이다.여기서 AMDV는 Myron J. Ross, Harry L. Shaffer, Andrew Cohen, Richard Freudberg, and Harold J. Manley, \"Average Magnitude Difference Function Pitch Extractor\", IEEE Trans. On Acoustics, Speech And Signal Proc., VOL. ASSP-22, NO. 5, OCTOBER 1974에서 - 10 -공개특허 10-2009-0030063참조할 수 있다. 이러한 유성음 특징의 경우 기존의 전처리 방식에서 거의 사용하지 않았던 특성으로 이러한 특성을 모두 판별할 <61> 경우 기존의 유성음 판별방식에 비해 획기적으로 개선된 음성 구간의 판별이 가능하다. 이렇게 각각 다른 방식으로 구해진 유성음 특징들을 유성음/비유성음 분류 방법을 이용하여 분류할 수 있 <62> 다. 본 도면에서는 유성음/비유성음 분류 방법 중 가장 간단한 임계치와 경계치를 이용하여 단순히 비교하는 방 법을 이용하였다. 이렇게 유성음/비유성음 분류 방법을 이용하여 분류한 결과가 모든 유성음 특징이 임계치와 경계치를 만족한다 <63> 면 이는 유성음 신호로서 판단할 수 있게 된다. 본 도면에서 간단한 임계치 및 경계치를 이용하는 방법을 사용한 것은 비교적 조용한 환경에서 수집된 음성 데 <64> 이터들로부터 변형된 시간-주파수 신호 파라미터를 이용하면 유성음 구간은 자동으로 검출되고 이러한 유성음 구간에 대해서 나머지 유성음 특징들을 추출한 후 특징들의 임계치를 추출하면 대량의 음성 데이터나 잡음 데이 터를 수집하거나 훈련하는 과정 없이 비교적 간단하게 구현이 가능하기 때문이다. 도 5는 본 발명에 적용되는 변형된 시간-주파수 신호 파라미터를 구하는 순서를 나타내는 도면이다. <65> 도 5를 참조하면, 본 발명에서 이용되는 유성음 특징 중 가장 먼저 구하는 변형된 시간-주파수 신호 파라미터 <66> (Modified TF parameter)는 우선 부가 잡음이 제거된 음성 신호가 입력되면(단계 501), 상기 신호는 각각 주파 수 신호 구간과 시간 신호 구간으로 나눠져서 계산된다. 우선 주파수 신호 구간에서는 입력되는 음성 신호는 시 간축 기준의 파형이므로 이른 주파수 신호로 변형하기 위하여 페스트 푸리에 변환(FFT : Fast Fourier Transform)을 이용하여 시간 신호를 주파수 신호로 변환한다(단계 503). 그 후 변환된 주파수 신호 중 주 사용 에너지인 500Hz ~ 3500Hz 구간의 에너지를 계산한다(단계 507). 한편으로 시간 신호는 특별한 변형이 필요하지 않으므로 바로 시간 신호의 에너지를 계산한다(단계 505). 그런 다음 상기 참조 번호 507 및 505 단계에서 계산된 결과 값을 합산하고(단계 509), 그 후 평탄화 <67> (smoothing) 작업을 수행한다(단계 511). 그럼 다음 결과 값을 로그(Log) 스케일로 변환한다(단계 513). 이러한 단계를 거쳐서 변형된 시간-주파수 신호 파라미터(Modified TF parameter)가 구해진다(단계 515). 이러한 방법에 대한 자세한 참고는 Jean-Claude Junqua, Brain Mak and Ben Reaves, \"A Robust Algorithm for <68> Word Boundary Detection in the Presence of Noise\", IEEE Trans. Speech and Audio Proc., VOL. 2, NO. 3, pp. 406~412, JULY 1994를 통하여 확인할 수 있다. 본 발명은 상기 실시예에 한정되지 않으며, 많은 변형이 본 발명의 사상 내에서 당 분야에서 통상의 지식을 가 <69> 진 자에 의하여 가능함은 물론이다."}
