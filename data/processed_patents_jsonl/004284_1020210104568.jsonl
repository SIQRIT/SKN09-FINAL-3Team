{"patent_id": "10-2021-0104568", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0022598", "출원번호": "10-2021-0104568", "발명의 명칭": "인공지능 모델을 이용하여 분석된 무인 매장 고객 행동 분석 결과를 표현하는 방법 및 장치,", "출원인": "양주섭", "발명자": "양주섭"}}
{"patent_id": "10-2021-0104568", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "컴퓨팅 장치를 통한, 무인 매장에서의 고객 행동 분석 결과를 표현하는 방법에 있어서,상기 무인 매장 내 출입한 고객의 제 1 영상 데이터, 고객의 상품 선택과 관련된 제 2 영상 데이터, 및 고객의상품 결제와 관련된 제 3 영상 데이터를 조합하여 분석한 고객 행동 분석 결과를 획득하는 단계; 및상기 획득된 고객 행동 분석 결과를 기반으로, 상기 무인 매장 내 출입한 고객의 행동의 단계 또는 상기 고객의행동 타입을 식별하여 시청각적으로 표현하도록 제어하는 단계를 포함하는, 무인 매장에서의 고객 행동 분석 결과를 표현하는 방법."}
{"patent_id": "10-2021-0104568", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1 항에 있어서,상기 획득된 고객 행동 분석 결과를 기반으로 상기 무인 매장 내 출입한 고객의 행동의 단계를 순차적으로 (i)매장 출입 단계, (ii) 상품 선택 단계 및 (iii) 상품 결제 단계로 구분하여 실시간으로 표현하도록 제어하는,무인 매장에서의 고객 행동 분석 결과를 표현하는 방법."}
{"patent_id": "10-2021-0104568", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 2 항에 있어서, 상기 식별되는 고객의 행동 단계와 관련된 정보는,(i) 매장 내 디스플레이 장치로 제공되어 실시간으로 영상 표시되거나, 또는(ii) 매장 내 스피커로 제공되어 실시간으로 음성 출력되도록 제어하는, 무인 매장에서의 고객 행동 분석 결과를 표현하는 방법."}
{"patent_id": "10-2021-0104568", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 3 항에 있어서,상기 매장 내 디스플레이 장치로 실시간 영상 표시될 때, 상기 디스플레이 장치를 화면 분할하여 복수 명의 고객의 영상을 표시하되,개별 고객에 대해 표시되는 영상은 고객의 현재 행동 단계의 영상과 현재 행동 단계를 지시하는 텍스트를 함께표시하도록 제어하는, 무인 매장에서의 고객 행동 분석 결과를 표현하는 방법."}
{"patent_id": "10-2021-0104568", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제 4 항에 있어서,상기 매장 내 디스플레이 장치로 실시간 영상 표시될 때, 고객의 상기 무인 매장 퇴장을 감지함에 대응하여 퇴장 후 일정 시간이 지난 후 해당 고객의 화면을 오프시키도록 제어하는, 무인 매장에서의 고객 행동 분석 결과를 표현하는 방법."}
{"patent_id": "10-2021-0104568", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제 1 항에 있어서, 상기 식별되는 고객의 타입은,매장 내 출입만 하고 상품 선택 및 결제는 하지 않은 제 1 타입(type)의 고객;상기 제 1 고객은 매장 내 출입 및 상품 선택만 하고, 결제는 하지 않은 제 2 타입의 고객; 및매장 내 출입, 상품 선택 및 결제까지 모두 수행한 제 3 타입의 고객 중 하나로 결정되는, 무인 매장에서의 고공개특허 10-2023-0022598-3-객 행동 분석 결과를 표현하는 방법."}
{"patent_id": "10-2021-0104568", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제 6 항에 있어서, 상기 제 1 타입의 고객과 관련된 정보, 상기 제 2 타입의 고객과 관련된 정보, 및 상기 제 3 타입의 고객과 관련된 정보는 시각적으로 서로 다르게 표현되는, 무인 매장에서의 고객 행동 분석 결과를 표현하는 방법."}
{"patent_id": "10-2021-0104568", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제 7 항에 있어서,상기 제 1 타입의 고객은 제 1 색상으로, 상기 제 2 타입의 고객은 제 2 색상으로, 상기 제 3 타입의 고객은 제3 색상으로 표현되는, 무인 매장에서의 고객 행동 분석 결과를 표현하는 방법."}
{"patent_id": "10-2021-0104568", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제 6 항에 있어서,개별 고객의 타입에 따른 행동을 테이블(table) 형태로 표시하도록 제어하되,개별 고객의 식별 라벨 및 행동 단계 중 하나를 테이블의 열(column)로, 다른 하나를 테이블의 행으로표시하고,이때, 행동 단계는 (i) 매장 출입 단계, (ii) 상품 선택 단계 및 (iii) 상품 결제 단계로 구분되는, 무인 매장에서의 고객 행동 분석 결과를 표현하는 방법."}
{"patent_id": "10-2021-0104568", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제 9 항에 있어서,(i) 제 1 시점의 재고와 (ii) 상기 제 1 시점부터 제 2 시점 사이에 결제 완료된 상품 수와 상기 제 2 시점의재고의 합을 비교하여 일치하지 않음에 대응하여, 재고 부족 상황을 디스플레이 수단을 통해 표시하도록 제어하는, 무인 매장에서의 고객 행동 분석 결과를 표현하는 방법."}
{"patent_id": "10-2021-0104568", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제 10 항에 있어서,상기 재고 부족 상황에 대한 상세 정보를 요청하는 사용자 입력에 대응하여, (i) 상기 제 1 타입의 고객을 먼저표시하고, 후속하여 (ii) 상기 제 2 타입의 고객, 그리고 (iii) 상기 제 3 타입의 고객을 순차적으로 표시하도록 제어하는, 무인 매장에서의 고객 행동 분석 결과를 표현하는 방법."}
{"patent_id": "10-2021-0104568", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제 11 항에 있어서,상기 재고 부족 상황에 따라 제 1 타입부터 제 3 타입까지의 고객을 순차적으로 표시함에 있어서, 제 1 고객과 관련된 상세 영상 정보를 요청하는 사용자 입력에 대응하여, 상기 제 1 고객과 관련된, 상기 제 1영상 데이터, 상기 제 2 영상 데이터 및 상기 제 3 영상 데이터 중 적어도 하나를 재생하되,상기 제 1 영상 데이터, 상기 제 2 영상 데이터 및 상기 제 3 영상 데이터 중 적어도 하나는 고객의 행동 단계와 연관된 시점을 기준으로 전후 일정 시간 구간만큼의 영상을 로딩(loading)하여 재생하도록 제어하는, 무인매장에서의 고객 행동 분석 결과를 표현하는 방법."}
{"patent_id": "10-2021-0104568", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제 9 항에 있어서,상기 테이블 상에서, 제 1 고객의 식별 라벨을 클릭함에 대응하여 상기 제 1 고객과 관련된 전체 행동 단계의영상 데이터가 재생되고,공개특허 10-2023-0022598-4-상기 테이블 상에서 제 1 고객의 특정 행동 단계를 클릭함에 대응하여, 상기 클릭된 행동 단계에 영상 데이터가재생되도록 제어하는, 무인 매장에서의 고객 행동 분석 결과를 표현하는 방법."}
{"patent_id": "10-2021-0104568", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제 6 항에 있어서,매장 내 퇴장과 관련된 제 3 센싱 정보를 기반으로 촬영된 제 4 영상 데이터를 획득하는 단계; 및 상기 제 4 영상 데이터 내의 개별 고객이 상품을 들고 나갔는지 판단하는 단계를 더 포함하되,상기 제 1 타입의 고객이 상기 제 4 영상 데이터 상에서 상품을 들고 나갔는지 여부를 기반으로 강화된 시각적표현으로 표시하도록 제어하는, 무인 매장에서의 고객 행동 분석 결과를 표현하는 방법."}
{"patent_id": "10-2021-0104568", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제 14 항에 있어서,상기 제 1 타입의 고객이 상기 제 4 영상 데이터 상에서 상품을 들고 나갔음에 대응하여, 경고 표시를부여하는, 무인 매장에서의 고객 행동 분석 결과를 표현하는 방법."}
{"patent_id": "10-2021-0104568", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제 1 항에 있어서,연기 감지 센서로부터 연기가 감지됨에 응답하여, 매장 내 디스플레이 장치로 경고 메시지를 표시하고, 매장 내스피커를 통해 경고 음성을 출력하도록 제어하는, 무인 매장에서의 고객 행동 분석 결과를 표현하는 방법."}
{"patent_id": "10-2021-0104568", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제 1 항에 있어서,제 1 영상 데이터, 제 2 영상 데이터, 제 3 영상 데이터 및 매장 내에 배열된 제 4 카메라에 의해 촬영된 제 4영상 데이터 중 적어도 하나에서, 고객의 음주 행위가 검출됨에 대응하여, 경고 메시지를 시각적 또는 청각적으로 출력하도록 제어하는, 무인 매장에서의 고객 행동 분석 결과를 표현하는 방법."}
{"patent_id": "10-2021-0104568", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "무인 매장에서의 고객 행동 분석 결과를 표현하는 장치에 있어서,영상 분석 장치로부터, 상기 무인 매장 내 출입한 고객의 제 1 영상 데이터, 고객의 상품 선택과 관련된 제 2영상 데이터, 및 고객의 상품 결제와 관련된 제 3 영상 데이터를 수신하는 통신부; 및상기 제 1 영상 데이터, 상기 제 2 영상 데이터 및 상기 제 3 영상 데이터를 조합하여 분석하여 고객 행동 분석결과를 생성하고, 상기 획득된 고객 행동 분석 결과를 기반으로, 상기 무인 매장 내 출입한 고객의 행동의 단계또는 상기 고객의 행동 타입을 식별하여 시청각적으로 표현하도록 제어하는 프로세서를 포함하는, 무인 매장에서의 고객 행동 분석 결과를 표현하는 장치."}
{"patent_id": "10-2021-0104568", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명의 일 양태는, 출력 장치를 통한, 무인 매장에서의 고객 행동 분석 결과를 표현하는 방법을 개시하고 있 다. 상기 방법은, 영상 분석 장치로부터, 상기 무인 매장 내 출입한 고객의 제 1 영상 데이터, 고객의 상품 선택 과 관련된 제 2 영상 데이터, 및 고객의 상품 결제와 관련된 제 3 영상 데이터를 조합하여 분석한 고객 행동 분 석 결과를 획득하는 단계 및 상기 획득된 고객 행동 분석 결과를 기반으로, 상기 무인 매장 내 출입한 고객의 행 동의 단계 또는 상기 고객의 행동 타입을 식별하여 시청각적으로 표현하는 단계를 포함한다."}
{"patent_id": "10-2021-0104568", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 분석 결과를 출력하는 방법에 관한 것으로, 보다 상세하게는, 무인 매장에 출입한 고객의 행동 패턴 을 분석한 결과를 효과적으로 표현하는 방법에 관한 것이다."}
{"patent_id": "10-2021-0104568", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "무인 매장의 운영에 있어서 방범 및 보안은 매우 중요한 요소라고 할 수 있다. 현재의 방범 및 보안 체계는 오 픈된 시간 동안 CCTV를 통한 관찰 및 마감 시간 이후의 움직임에 대한 분석 및 이를 통한 신고 과정 등이 있을 수 있다. 다만, 사용자에 최적화된 주문 접수가 어려워 비효율을 초래할 수 있고, 도난 및 파손에 대한 신속하고 정확한 대응이 어렵다. 특히, 무인 상태가 장기간 지속된 상태에서, 도난 및 파손이 발생한 경우, 관리자는 다수의 CCTV의 전체 시간 구간을 일일이 재생시키면서 그 사이 출입했던 모든 고객의 행동을 유심히 살펴봐야 하기에, 도난 관련 사고의 범인 검출에 있어, 매우 비효율적이며, 실제로 이런 방식이면, 도난 및 파손의 원인 을 찾는 것은 거의 불가능에 가깝다. 더욱이, 무인 매장의 경우, 흡연 및 음주에 따른 재난이 매우 빈번이 발생함에도, 이에 대응할 수 있는 매뉴얼 이 따로 구분되어 존재하지 않으며, 이와 관련된 정보를 저장하는 수단도 미비한 것이 현실이다. 따라서, 매장 관리자에게 방법 및 보안 측면뿐만 아니라 매장 경영에도 최적화된 사용 환경을 제공하고, 도난 및 파손에 대응하기 위한 수단을 제공하며, 흡연 및 음주에 따른 사고 이벤트에도 즉각적으로 대응할 수 있는 기술의 개발이 요구된다."}
{"patent_id": "10-2021-0104568", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "상술한 문제점을 해결하기 위한 본 발명의 일 양태에 따른 목적은, 무인 매장 내 구비된 센서들과 복수의 카메 라 영상을 서버에서 분석한 결과를 관리자 또는 매장 내 디스플레이 장치나 스피커를 통해 효과적으로 표출하는 방법을 제공하는 것이다."}
{"patent_id": "10-2021-0104568", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기한 목적을 달성하기 위한 본 발명의 일 양태에 따른, 컴퓨팅 장치를 통한, 무인 매장에서의 고객 행동 분석 결과를 표현하는 방법은, 영상 분석 장치로부터, 상기 무인 매장 내 출입한 고객의 제 1 영상 데이터, 고객의 상품 선택과 관련된 제 2 영상 데이터, 및 고객의 상품 결제와 관련된 제 3 영상 데이터를 조합하여 분석한 고 객 행동 분석 결과를 획득하는 단계 및 상기 획득된 고객 행동 분석 결과를 기반으로, 상기 무인 매장 내 출입 한 고객의 행동의 단계 또는 상기 고객의 행동 타입을 식별하여 시청각적으로 표현하도록 제어하는 단계를 포함 할 수 있다. 상기 획득된 고객 행동 분석 결과를 기반으로 상기 무인 매장 내 출입한 고객의 행동의 단계를 순차적으로 (i) 매장 출입 단계, (ii) 상품 선택 단계 및 (iii) 상품 결제 단계로 구분하여 실시간으로 표현하도록 제어할 수 있다. 상기 식별되는 고객의 행동 단계와 관련된 정보는, (i) 매장 내 디스플레이 장치로 제공되어 실시간으로 영상 표시되거나, 또는 (ii) 매장 내 스피커로 제공되어 실시간으로 음성 출력될 수 있다. 상기 매장 내 디스플레이 장치로 실시간 영상 표시될 때, 상기 디스플레이 장치를 화면 분할하여 복수 명의 고 객의 영상을 표시하되, 개별 고객에 대해 표시되는 영상은 고객의 현재 행동 단계의 영상과 현재 행동 단계를 지시하는 텍스트를 함께 표시하도록 제어할 수 있다. 상기 매장 내 디스플레이 장치로 실시간 영상 표시될 때, 고객의 상기 무인 매장 퇴장을 감지함에 대응하여 퇴 장 후 일정 시간이 지난 후 해당 고객의 화면을 오프시키도록 제어할 수 있다. 상기 식별되는 고객의 타입은, 매장 내 출입만 하고 상품 선택 및 결제는 하지 않은 제 1 타입(type)의 고객, 상기 제 1 고객은 매장 내 출입 및 상품 선택만 하고, 결제는 하지 않은 제 2 타입의 고객 및 매장 내 출입, 상 품 선택 및 결제까지 모두 수행한 제 3 타입의 고객 중 하나로 결정될 수 있다. 상기 제 1 타입의 고객과 관련된 정보, 상기 제 2 타입의 고객과 관련된 정보, 및 상기 제 3 타입의 고객과 관 련된 정보는 시각적으로 서로 다르게 표현될 수 있다. 상기 제 1 타입의 고객은 제 1 색상으로, 상기 제 2 타입의 고객은 제 2 색상으로, 상기 제 3 타입의 고객은 제 3 색상으로 표현될 수 있다. 개별 고객의 타입에 따른 행동을 테이블(table) 형태로 표시하되, 개별 고객의 식별 라벨 및 행동 단계 중 하나 를 테이블의 열(column)로, 다른 하나를 테이블의 행으로 표시하고, 이때, 행동 단계는 (i) 매장 출입 단계, (ii) 상품 선택 단계 및 (iii) 상품 결제 단계로 구분될 수 있다. (i) 제 1 시점의 재고와 (ii) 상기 제 1 시점부터 제 2 시점 사이에 결제 완료된 상품 수와 상기 제 2 시점의 재고의 합을 비교하여 일치하지 않음에 대응하여, 재고 부족 상황을 디스플레이 수단을 통해 표시하도록 제어할수 있다. 상기 재고 부족 상황에 대한 상세 정보를 요청하는 사용자 입력에 대응하여, (i) 상기 제 1 타입의 고객을 먼저 표시하고, 후속하여 (ii) 상기 제 2 타입의 고객, 그리고 (iii) 상기 제 3 타입의 고객을 순차적으로 표시하도 록 제어할 수 있다. 상기 재고 부족 상황에 따라 제 1 타입부터 제 3 타입까지의 고객을 순차적으로 표시함에 있어서, 제 1 고객과 관련된 상세 영상 정보를 요청하는 사용자 입력에 대응하여, 상기 제 1 고객과 관련된, 상기 제 1 영상 데이터, 상기 제 2 영상 데이터 및 상기 제 3 영상 데이터 중 적어도 하나를 재생하되, 상기 제 1 영상 데이터, 상기 제 2 영상 데이터 및 상기 제 3 영상 데이터 중 적어도 하나는 고객의 행동 단계와 연관된 시점을 기준으로 전후 일정 시간 구간만큼의 영상을 로딩(loading)하여 재생하도록 제어할는, 무인 매장에서의 고객 행동 분석 결과를 표현할 수 있다. 상기 테이블 상에서, 제 1 고객의 식별 라벨을 클릭함에 대응하여 상기 제 1 고객과 관련된 전체 행동 단계의 영상 데이터가 재생되고, 상기 테이블 상에서 제 1 고객의 특정 행동 단계를 클릭함에 대응하여, 상기 클릭된 행동 단계에 영상 데이터가 재생되도록 제어할 수 있다. 상기 방법은, 매장 내 퇴장과 관련된 제 3 센싱 정보를 기반으로 촬영된 제 4 영상 데이터를 획득하는 단계 및 상기 제 4 영상 데이터 내의 개별 고객이 상품을 들고 나갔는지 판단하는 단계를 더 포함하되, 상기 제 1 타입 의 고객이 상기 제 4 영상 데이터 상에서 상품을 들고 나갔는지 여부를 기반으로 강화된 시각적 표현으로 표시 하도록 제어할 수 있다. 상기 제 1 타입의 고객이 상기 제 4 영상 데이터 상에서 상품을 들고 나갔음에 대응하여, 경고 표시를 부여할 수 있다. 연기 감지 센서로부터 연기가 감지됨에 응답하여, 매장 내 디스플레이 장치로 경고 메시지를 표시하고, 매장 내 스피커를 통해 경고 음성을 출력하도록 제어할 수 있다. 제 1 영상 데이터, 제 2 영상 데이터, 제 3 영상 데이터 및 매장 내에 배열된 제 4 카메라에 의해 촬영된 제 4 영상 데이터 중 적어도 하나에서, 고객의 음주 행위가 검출됨에 대응하여, 경고 메시지를 시각적 또는 청각적으 로 출력하도록 제어할 수 있다. 상기한 목적을 달성하기 위한 본 발명의 다른 양태에 따른, 무인 매장에서의 고객 행동 분석 결과를 표현하는 장치는, 영상 분석 장치로부터, 상기 무인 매장 내 출입한 고객의 제 1 영상 데이터, 고객의 상품 선택과 관련 된 제 2 영상 데이터, 및 고객의 상품 결제와 관련된 제 3 영상 데이터를 수신하는 통신부 및 상기 제 1 영상 데이터, 상기 제 2 영상 데이터 및 상기 제 3 영상 데이터를 조합하여 분석하여 고객 행동 분석 결과를 생성하 고, 상기 획득된 고객 행동 분석 결과를 기반으로, 상기 무인 매장 내 출입한 고객의 행동의 단계 또는 상기 고 객의 행동 타입을 식별하여 시청각적으로 표현하도록 제어하는 프로세서를 포함할 수 있다."}
{"patent_id": "10-2021-0104568", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명의 무인 매장에서의 고객 행동 분석 결과를 표현하는 방법에 따르면, 관리자에게 무인 매장 내 도난 및 방범과 관련된 데이터를 직관적으로 이해할 수 있도록 시각화하여 표시하고, 매장 내 고객에게는 실시간으로 자 신의 행동 단계를 볼 수 있도록 함으로써 도난, 파손, 흡연, 음주 등의 행동을 미연에 방지하는 효과가 있다."}
{"patent_id": "10-2021-0104568", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명은 다양한 변경을 가할 수 있고 여러 가지 실시예를 가질 수 있는 바, 특정 실시예들을 도면에 예시하고 상세하게 설명하고자 한다. 그러나, 이는 본 발명을 특정한 실시 형태에 대해 한정하려는 것이 아니며, 본 발명의 사상 및 기술 범위에 포 함되는 모든 변경, 균등물 내지 대체물을 포함하는 것으로 이해되어야 한다. 제 1, 제 2 등의 용어는 다양한 구성요소들을 설명하는데 사용될 수 있지만, 상기 구성요소들은 상기 용어들에 의해 한정되어서는 안 된다. 상기 용어들은 하나의 구성요소를 다른 구성요소로부터 구별하는 목적으로만 사용 된다. 예를 들어, 본 발명의 권리 범위를 벗어나지 않으면서 제 1 구성요소는 제 2 구성요소로 명명될 수 있고, 유사하게 제 2 구성요소도 제 1 구성요소로 명명될 수 있다. 및/또는 이라는 용어는 복수의 관련된 기재된 항목 들의 조합 또는 복수의 관련된 기재된 항목들 중의 어느 항목을 포함한다. 어떤 구성요소가 다른 구성요소에 \"연결되어\" 있다거나 \"접속되어\" 있다고 언급된 때에는, 그 다른 구성요소에 직접적으로 연결되어 있거나 또는 접속되어 있을 수도 있지만, 중간에 다른 구성요소가 존재할 수도 있다고 이 해되어야 할 것이다. 반면에, 어떤 구성요소가 다른 구성요소에 \"직접 연결되어\" 있다거나 \"직접 접속되어\" 있 다고 언급된 때에는, 중간에 다른 구성요소가 존재하지 않는 것으로 이해되어야 할 것이다. 본 출원에서 사용한 용어는 단지 특정한 실시예를 설명하기 위해 사용된 것으로, 본 발명을 한정하려는 의도가 아니다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 출원에서, \"포함 하다\" 또는 \"가지다\" 등의 용어는 명세서상에 기재된 특징, 숫자, 단계, 동작, 구성요소, 부품 또는 이들을 조 합한 것이 존재함을 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성요소, 부 품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되어야 한다. 다르게 정의되지 않는 한, 기술적이거나 과학적인 용어를 포함해서 여기서 사용되는 모든 용어들은 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자에 의해 일반적으로 이해되는 것과 동일한 의미를 가지고 있다. 일 반적으로 사용되는 사전에 정의되어 있는 것과 같은 용어들은 관련 기술의 문맥상 가지는 의미와 일치하는 의미 를 가진 것으로 해석되어야 하며, 본 출원에서 명백하게 정의하지 않는 한, 이상적이거나 과도하게 형식적인 의 미로 해석되지 않는다. 이하, 첨부한 도면들을 참조하여, 본 발명의 바람직한 실시예를 보다 상세하게 설명하고자 한다. 본 발명을 설 명함에 있어 전체적인 이해를 용이하게 하기 위하여 도면상의 동일한 구성요소에 대해서는 동일한 참조부호를 사용하고 동일한 구성요소에 대해서 중복된 설명은 생략한다. 도 1은 본 발명의 일 실시예에 따른 고객 행동 패턴 분석을 수행하는 무인 매장 시스템을 나타낸 개념도이다. 도 1에 도시된 바와 같이, 본 발명의 일 실시예에 따른 무인 매장 시스템은, 출입문 센서, 카메라, 상품 보관소 센서, 카메라, 결제 단말, 카메라, 디스플레이 장치, 스피커, 액 세스 포인트(170: AP(Access Point)), 프록시 서버 및 통합 서버를 포함할 수 있다. 도 1을 참조하면, 출입문 센서는 무인 매장에 출입하는 고객을 감지하는 센서이다. 이는 도어 개폐 센서, 접근 센서, 모션 인식 센서 및 적외선 센서 중 적어도 하나를 포함할 수 있다. 출입문 센서가 고객의 출입을 감지하면, 카메라가 동작하여 출입문으로 들어오는 고객의 형상을 촬영한다. 이때, 고객의 전체 형상을 촬영하는 것이 바람직하며, 특히, 추후, 얼굴 트랙킹(face tracking) 등의 기술을 사용하기 위해서, 고객 얼굴 형상이 나타나는 방향으로 촬영하는 것이 바람직하다. 출입문 센서는 고객의 입장뿐만 아니라 퇴장시에도 센싱을 수행하고, 카메라에 센싱된 신호를 보내 고객의 매장 퇴장 모습도 촬영될 수 있도록 할 수 있다. 무인 매장 내에는 다수의 상품 보관소가 존재할 수 있다. 상품 보관소라는 용어를 사용하였지만, 상 품을 내부에 보관하는 박스 형태의 장소가 아니라, 단순히 상품을 진열하는 진열대로 구현될 수도 있다. 즉, 상 품이 놓인 단위 공간을 의미한다. 일 예에서, 상품 보관소는 냉장고, 냉동고, 진열대 등을 포함할 수 있다. 그리고, 고객이 상품 구매를 위해 상품을 선택하는 동작(상품을 집는 동작)을 감지하기 위해, 상품 보관 소 내에, 또는 주변에, 센서가 배치된다. 센서는 도어 개폐 센서, 접근 센서, 모션 인식 센서 및 적외선 센서 중 적어도 하나를 포함한다. 특히, 냉장고 또는 냉동고와 같이, 문이 닫힌 상태로 상품들이 보 관되는 상황이라면, 고객이 상품 구매를 위해 특정 상품을 선택하는 동작은 도어 개폐 감지 센서를 통해 감지하 는 것이 바람직하다. 진열대와 같이 특별한 도어 개폐 동작을 요구하지 않는 환경이라면, 접근 센서, 모션 인식 센서, 적외선 센서 등을 통해 고객이 상품을 선택하는 동작을 감지할 수 있다. 한편, 센서를 통해, 고객의 특정 상품보관소와 관련된 상품을 선택하는 행위가 감지되면, 그에 대응 하는 카메라가 상품 선택 중인 고객을 촬영한다. 센서와 카메라는 개별 상품 보관소마다 하나 또는 그 이상씩 구비될 수 있다. 따라서, 제 1 상품보관소의 센서에서 고객의 상품 선택 행위가 감지되면, 그에 대응하는 카메라에서 촬영이 이루어지고, 다른 상품보관소의 센서에서 고객의 상품 선택 행위가 감지되면, 그에 대응하는 다른 카메라에서 촬영이 이루어진다. 여기서도, 고객의 전면 또는 후면, 윗면 을 바라보는 방향으로 촬영이 수행될 수 있다. 고객이 상품 선택을 하고 나면, 결제가 요구된다. 따라서, 결제 단말로 접근하여, 결제 단말에 결제 관련 사용자 입력을 입력함에 의해, 결제를 진행한다. 이때, 결제 단말의 실행 및/또는 결제 단말 주 변에 별도로 구비된 접근 센서(미도시) 등을 통해 고객의 상품 결제 행위를 감지할 수 있다. 이렇게 감지된 고 객의 결제 (개시) 행위에 대응하여, 카메라가 촬영을 개시한다. 결제 단말은 키오스크 및 POS 단말을 포함한다. 또는, POS 단말 기능이 포함되어 있는 키오스크 장치일 수 있다. 본 발명의 실시예에 따르면, 매장 내 인바운드(In-bound) 장비는 근거리 통신을 이용하여 서로 통신할 수 있다. 이때, 근거리 통신은 와이-파이(Wi-Fi), 지그비(Zigbee), 블루투스(Bluetooth) 등을 포함할 수 있다. 와이-파이 통신을 할 때, 액세스 포인트를 매개로 내부적으로 분배된 IP를 이용하여 서로 정보를 송수신한다. 즉, 액 세스 포인트는 센서(112, 132) 및 결제 단말, 그리고 카메라들(120, 134, 142)에 각각 개별 IP를 할 당하고, 인바운드 장비들 간에 서로의 IP를 기억하여 정보를 송수신할 수 있다. 예를 들어, 인바운드 장비들이 프록시 서버를 거치지 않고 직접 통신하는 실시예에서, 제 1 센서는 카메라의 IP를 통해 카메라 로 센싱 정보를 전달하고, 제 2 센서는 카메라의 IP를 매개로 카메라로 센싱 정보를 전달 하며, 결제 단말은 카메라의 IP를 매개로 카메라로 결제 개시 정보를 전달하여, 각각의 카메라 들(120, 134, 142)에서 촬영을 활성화하도록 제어할 수 있다. 관리자는 관리자 단말을 이용하여, 통합 서 버 또는 프록시 서버를 매개로 개별 센서(112, 132) 및/또는 결제 단말에게 그들이 센싱한 정보 를 전달해야 할 수신처에 대한 IP 정보를 결정할 수 있다. 그리고, 원하는 때, 이를 변경할 수도 있다. 즉, 센 서/단말과 카메라간 매핑 관계를 임의로 설정할 수 있다. 다른 예에서, 매장 내 인바운드 장비들은 반드시 근거 리 통신만을 이용해야 하는 것은 아니고, NB-IoT(NarrowBand IoT), 로라(LoRa), 원엠투엠(oneM2M), OCF(Open Connectivity Foundation), LwM2M(Lightweight M2M) 등 글로벌 IoT 표준에서 제정한 표준 통신 프로토콜 중 적 어도 하나에 따라 서로 간에 또는 외부 장치로 정보를 송수신할 수 있다. 또한, 적어도 두 개의 센서들(112, 132)에서의 센싱 정보, 적어도 세 개의 카메라(120, 134, 142)에서 촬영된 영상 데이터(이는 동영상(video)을 포함함), 그리고 결제 단말에서의 결제 개시 및 진행 정보, 그리고 결 제 내역 정보는 프록시 서버로 제공될 수 있다. 그리고, 프록시 서버는 해당 데이터들을 광대역 통신 망을 이용하여 통합 서버로 제공할 수 있다. 프록시 서버는 무인 매장 현장에 배치된 서버이다. 이는 무인 매장에 배치된 컴퓨팅 장치에 데몬 툴 (daemon tool)이 에뮬레이팅된(emulated) 형태로 존재할 수 있다. 해당 서버는 통합 서버와 연동한다. 이 는 통합 서버에서 제공하는 무인 매장 보안 및 경영 관리 서비스를 이용하는 회원 매장에 설치하는 서버 또는 프로그램일 수 있다. 다만, 본 발명의 실시예에 따르면, 프록시 서버가 반드시 필요하지 않을 수 있다. 프록시 서버를 거 치지 않고, 센서들(112, 132), 카메라(120, 134, 142) 및 결제 단말이 관련 정보를 직접 통합 서버 로 보낼 수도 있다. 통합 서버는 수신된 센싱 정보, 영상 데이터 및 결제 정보를 기반으로, 영상 데이터 내의 고객을 라벨링 (labeling)함에 따라 고객의 행동 패턴을 분석하고, 분석 결과를 관리자 단말, 매장 내 디스플레이 장비 및 스피커를 통해 출력하도록 제어한다. 매장 내 디스플레이 장비 및 스피커로의 출력은 프록시 서버를 매개로 이루어질 수 있다. 디스플레이 장비 및 스피커는 출력장치라 불릴 수 있 고, 이는 고객 행동 패턴 분석 결과(및 분석 결과에 대한 표현 방법)을 획득하는 정보 획득부(미도시) 및 이를 출력하는 출력부(미도시)를 포함할 수 있다. 또한, 통합 서버(또는 프록시 서버)는 출력 제어 장치, 시각화 장치, 시각적 표현 장치, 청각적 표현 장치, 표현 제어 장치 등으로 불릴 수 있다. 한편, 고객의 행동 패턴은 카메라에서 촬영된 영상을 기반으로 매장 출입 동작을 분석하고, 카메라에 서 촬영된 영상을 기반으로 고객의 상품 선택 동작을 분석하며, 카메라에서 촬영된 영상을 기반으로 고객 의 상품 결제 동작을 분석한 결과를 종합적으로 분석하여 도출된다. 이에 따라, 어떤 고객은 출입만 하고 매장 을 나갔는지, 어떤 고객은 출입 및 상품 선택까지만 하고 결제는 하지 않고 매장을 나갔는지, 또 어떤 고객은 출입부터 상품 선택, 그리고 결제까지 모두 진행하고 매장을 나갔는지를 확인하여, 고객을 타입별로 분류할 수 있고, 분류된 결과를 관리자 단말 또는 매장 내 출력 장치(150, 160)로 제공할 수 있다. 또한, 통합 서버는 상기 센싱 정보, 영상 데이터 및 결제 정보를 데이터베이스에 고객별로, 상품별로 및/또는 시간별로 구분하여 저장한다. 그리고는, 저장된 정보들을 이용하여 인공지능 기반의 기계 학습 모델을 통해, 매출 증대를 위한 방안을 도출해낼 수 있다. 도출되는 방안 중 예시적인 하나는, 고객의 상품 선택 성향 에 맞는 상품 진열 방식이 될 수 있다. 한편, 통합 서버에서의 기능은 매장 내 배치된 프록시 서버에서 수행될 수 있다. 즉, 통합 서버(19 0)에서 제공하는 분석 기능이 프록시 서버에 에이전트 형태로 설치되어, 프록시 서버 자체적으로 분 석 및 분석 결과 출력이 가능하게 동작할 수 있다. 통합 서버 또는 프록시 서버는 센싱 정보 및/또는 영상 정보를 분석하기에, 분석 장치, 영상 분석 장치 등으로 불릴 수 있다. 센서(112, 132)는 위에서 예시로 든 것 이외에, 다양한 형태의 IoT 센서로 구현될 수 있다. 여기에는, 온도 센 서, 습도 센서, 모션 감지 센서 등을 포함할 수 있다. 또한, 센서(112, 132) 및 결제 단말 위치의 센서 이 외에 매장 내 또는 매장 주변의 다른 위치에 하나 또는 다수의 다른 센서들이 존재할 수도 있다. 또한, 카메라 (120, 134, 142) 중 적어도 하나는 위와 같이 다른 곳에 배치된 센서들과 연동하여, 영상을 촬영할 수 있고, 이 를 통합 서버로 전송할 수 있다. 관리자 단말은 매장 관리를 수행하는 관리자가 소지한 사용자 단말로, 스마트폰(smart phone), 데스크톱 (dest top), 랩톱(laptop), PDA(Personal Digital Assistants) 등으로 구현될 수 있다. 관리자 단말은 통 합 서버에서 제공하는 애플리케이션(Application: 이하 \"앱\"이라 부름)을 설치하여 통합 서버와 연동 가능하며, 통합 서버에서 제공하는 정보를 앱에서 제공하는 사용자 인터페이스(UX/UI)를 통해 표시할 수 있다. 특수한 경우에, 관리자 단말은 매장 내의 단말로 구현될 수 있고, 프록시 서버와 관리자 단말 은 하나의 장비로 구현될 수 있다. 도 2는 본 발명의 다른 실시예에 따른 고객 행동 패턴 분석을 수행하는 무인 매장 시스템을 나타낸 도면이다. 도 2를 참조하면, 상품보관소에 부착되어 고객의 상품 선택 동작을 감지하기 위한 센서와 카메라의 관계는 반드 시 1:1의 관계를 가져야 하는 것은 아니다. 1:N, N:1, N:M의 관계를 가질 수 있다. 도 2의 실시예에서처럼, 6개의 센서가 4개의 카메라에 대응될 수도 있다. 이때, 개별 센서와 대응되는 카메라와 의 매칭 관계는 미리 정해져 있을 수 있다. 예를 들어, 제 1 센서와 제 2 센서는 제 1 카메라와, 제 3 센서와 제 4 센서는 제 2 카메라와 제 3 카메라와, 제 5 센서는 제 3 카메라와 제 4 카메라와, 제 6 센서는 제 4 카메 라와 매칭되어 있을 수 있다. 이와 같은 시나리오는, 통합 서버에서 설정할 수 있고, 관리자 단말을 이용하여 통합 서버 및 프록시 서버를 매개로 설정할 수도 있다. 본 발명의 실시예에 따르면, 카메라들 중 적어도 일부는 회전이 가능하게 설치되어, 센서로부터의 센싱 정보가 수신되면, 센싱된 상품 보관소를 향하는 방향으로 회전하고, 회전된 상태에서 해당 상품보관소를 바라보는 방향 으로 촬영을 개시하도록 제어될 수 있다. 이러한 카메라의 회전은 PTZ(Pan Tilt Zoom) 제어를 포함한다. 또한, 이러한 회전 및 PTZ 제어 메카니즘은 고객의 상품 선택 동작 촬영 이외에, 고객의 매장 출입 동작을 촬영하는카메라, 상품 결제 동작을 촬영하는 카메라 등에도 응용될 수 있다. 도 3은 도 1 또는 도 2의 무인 매장 내 장비들 간의 정보 교류 과정을 나타낸 흐름도이다. 도 3을 참조하면, 출입 센서가 고객의 입장을 센싱하면(S310), 관련 정보는 제 1 카메라(도 1의 120)로 제공된 다(S312). 제 1 카메라는 상기 센싱 정보를 기반으로 촬영을 개시한다(S314). 촬영은 기설정된 시간동안 진행된 다. 예를 들어, 1분의 시간동안 촬영할 수 있다. 다만, 반드시 1분으로 설정되어야만 하는 것은 아니고, 2분, 3 분, 4분, 5분, 10분, 15분, 20분으로 설정되도 무방하다. 제 1 카메라가 영상을 촬영하면, 촬영된 영상 데이터 는 프록시 서버로 전달된다(S316). 프록시 서버는 수신한 영상 데이터를 실시간으로 통합 서버로 전송한다 (S318). 상품 보관소 도어 개폐 센서가 도어의 개폐를 센싱하면(S320), 이를 고객의 상품 선택 행위로 간주하고, 센싱 정보를 제 2 카메라(도 1의 134)로 제공한다(S322). 제 2 카메라는 개폐 센싱 정보를 트리거로 하여 영상 촬영 을 개시하고(S324), 프록시 서버로 제공한다(S326). 프록시 서버는 이를 통합 서버로 전송한다(S328). 다음으로, 상품 결제와 관련하여, 결제 단말에서 결제 프로세스가 진행되면(S330), 결제 단말은 결제 진행과 관 련된 정보를 제 3 카메라(도 1의 142)에 제공한다(S332). 제 3 카메라는 이를 트리거로 하여, 영상 촬영을 개시 하고(S334), 프록시 서버로 제공한다(S336). 프록시 서버는 이를 통합 서버로 전송한다(S338). 도 3의 실시예에서는, 개별 센서들이 직접 센싱 정보를 대응하는 카메라로 제공하는 것으로 설명하고 있지만, 직접 센싱 정보를 송수신하지 않고, 프록시 서버를 거쳐 정보를 송수신할 수도 있다. 예를 들어, 출입 센서가 고객의 출입을 센싱하면, 센싱 정보를 프록시 서버로 전달하고, 프록시 서버는 어느 센서로부터의 센싱 정보인 지 식별한 후, 그에 대응하는 카메라(즉, 제 1 카메라)로 촬영 요청 메시지를 전송하는 방식으로 동작할 수 있 다. 즉, 센서는 센싱 정보를 모두 프록시 서버로 전송하고, 프록시 서버는 센서로부터의 센싱 정보를 식별하여 그에 대응하는 카메라를 추출한 뒤, 추출된 카메라로 촬영 요청 메시지를 전달한다. 본 실시예에서, 프록시 서 버는 센서와 카메라 간의 매핑 관계를 나타내는 매핑 테이블을 보유하고 있을 수 있다. 또한 관리자는 이를 임 의로 변경 또는 새로 설정할 수 있다. 또한, 본 발명의 다른 실시예에 따르면, 센싱이 이루어졌을 때, 촬영을 개시할 수도 있으나, 카메라가 촬영을 계속하고 있는 상태에서 다른 동작이 수행되도록 할 수도 있다. 카메라는, 센싱 정보에 기반하여, 고객의 행동 패턴 또는 행동 단계 식별을 위한 기준 시점을 설정하도록 제어할 수 있다. 예를 들어, 제 1 카메라는 출입문 방향을 계속하여 촬영하고 있다가, 출입 센서로부터 센싱 정보를 수신함에 대응하여, 센싱 정보 수신 시점을 고 객의 매장 출입 시점으로 인식할 수 있다. 이에 따라, 고객의 매장 출입 시점을 센싱 정보 수신 시점을 기준으 로 설정하여, 영상 분석에 활용할 수 있다. 일 예로, 기준 시점 전후 기설정된 일정 시간의 영상을 해당 고객 관련 매장 출입 영상으로 구분하고, 매장 출입 영상이 필요할 때, 이 일정 시간의 영상을 호출하여 분석에 이용 할 수 있다. 즉, 카메라는 센싱 정보를 기반으로 영상에 시점 관련 기준 인덱스(index)를 부여하는 형태로 동작 한다. 도 4는 무인 매장 내 다수의 카메라 장비를 통해 획득된 영상 데이터들에 라벨링(Labeling)을 수행하여 일괄적 으로 관리하는 방법을 설명하기 위한 개념도이다. 도 4를 참조하면, 통합 서버는 출입 감지 카메라로부터 획득한 제 1 영상 데이터, 상품 선택과 관련된 카메라로 부터 획득한 제 2 영상 데이터 및 상품 결제와 관련된 카메라로부터 획득한 제 3 영상 데이터를 수집하여, 개별 영상 내에 존재하는 고객마다 라벨링을 수행한다. 둘 이상의 고객이 하나의 영상에 존재할 때는 각각 서로 다른 라벨을 부착한다. 제 1 영상 데이터에는 두 명의 고객이 있어, 하나는 #1, 다른 하나는 #2의 라벨이 부착된다. 영상 내 고객의 검출은 인공지능(AI: Artificial Intelligence) 기반의 기계 학습 모델(Machine Learning Model)(이하, '인공지능 모델'로 부를 수 있음)을 통해 수행된다. 즉, 얼굴 트랙킹(face tracking), 또는 기타 사람의 인상착의를 트랙킹하는 영상 분석/객체 검출 모델을 이용하여 영상 내의 사람을 인식하고, 복수의 인식 된 사람을 구분할 수 있다. 위와 같은 인공지능 모델을 통해, 제 1 영상 데이터에서 라벨링이 이루어지고 나면, 제 2 영상 데이터(상품 선 택 동작 촬영 데이터)들 중에서 라벨링된 고객의 영상을 검출한다. 그리고는, 해당 영상에도 동일하게 라벨링을 수행한다. 즉, 다수의 제 2 영상 데이터에서 #1로 라벨링된 고객을 검출하여, 검출된 영상 내의 고객을 #1로 라 벨링한다. 이와 동일한 방식으로 다수의 제 3 영상 데이터(상품 결제 동작 촬영 데이터)에서도 #1로 라벨링된 고객을 검출하여, 검출된 영상 내의 고객을 #1로 라벨링한다. 그리고는, #1로 라벨링된 고객이 포함된 영상을 데이터베이스 내의 특정 물리적 위치(#1로 표시된 폴더)에 저장 한다. 동일한 방식으로 #2로 라벨링된 고객과 관련된 영상은 다른 물리적 위치(#2로 표시된 폴더)에 저장한다. 영상 내에 다수의고객의 존재할 때, 하나의 영상 데이터는 다수의 폴더에 동시에 저장될 수 있다. 이러한 라벨 링은 특정 상품을 대상으로 이루어질 수도 있고, 상품별 영상 데이터가 기지정된 물리적 위치에 저장될 수도 있 다. 한편, 통합 서버는 고객의 동작을 인공지능 기반의 모션 인식 모델을 이용하여 구분할 수 있다. 예를 들어, 고 객의 입장 및 퇴장은 기본적인 출입 동작에서 크게 벗어남이 없겠지만, 상품의 선택 동작은 다양한 모션이 존재 할 수 있다. 예를 들어, 상품을 집어드는 행위, 집었다가 다시 놓는 행위, 냉장고 도어만 개폐하는 행위, 상품 을 다양하게 시험해보는 행위 등이 존재할 수 있다. 이러한 다양한 동작을 크라우드 소싱(Crowd Sourcing) 등의 방법을 통해 다양한 학습데이터로 생성하여 보다 세 분화된 동작으로 구분할 수도 있다. 즉, 크라우드 소싱을 통해 전세계 관련 영상들을 수집함으로써 방대한 양의 학습 데이터 셋을 확보할 수 있다. 또한, 실제 인공지능 모델을 실행하면서 촬영된 영상 데이터 및 그에 대한 분석 결과를 다시 학습 데이터 셋으로 생성하여 자가 학습을 수행할 수도 있다. 이때, 세분화된 동작 구분과 관련하여, 제 2 영상 데이터를 상품 선택 관련 영상으로 할 것이 아니라, 제 2-1 영상으로 상품을 집어드는 영상, 제 2-2 영상으로 상품을 장바구니에 넣는 행위와 관련된 영상, 제 2-3 영상으 로 상품을 장바구니에서 빼내는 행위와 관련된 영상 등 보다 세분화된 동작을 지시하는 영상으로 구분하고, 이 를 고객의 행동 패턴 또는 행동 단계로 적용할 수 있다. 결제 행위와 관련하여서도, 상품을 장바구니에서 빼내는 행위, 계산대에 놓는 행위, 상품 내의 바코드를 바코드 리더에 읽히는 행위, 결제 카드를 삽입하는 행위 등을 구분할 수 있다. 더 나아가서는, 계산대에 물건을 놓는 행위를 기반으로 계산대에 놓은 상품의 갯수를 추론할 수 있고, 상품 바코드를 읽히는 행위 및 결제 내역을 기 반으로 결제된 상품의 갯수를 추론할 수 있으며, 둘 간의 차이를 비교하여 결제시 누락된 상품의 갯수를 추론할 수 있다. 또한, 카메라를 통해 획득된 제 2 영상 데이터 내에서, 라벨링된 고객이 선택한 상품의 종류 및 갯수에 대 한 정보와 결제 단말을 통해 획득되는 결제 내역에서, 결제된 상품의 종류 및 갯수를 비교하여, 누락된 상품이 존재하는지 여부 및 누락된 상품의 갯수를 산출할 수 있다. 특히, 인공지능 기반의 객체 검출 및 모션 인식 기술을 통해, 세분화된 단계 및/또는 패턴이 많을수록 도난 및 보안 관련 분석을 위한 데이터 및 매장의 매출 증대를 위한 경영 데이터로서의 활용성은 증가된다. 기본적으로, 통합 서버는 고객을 위의 제 1 내지 제 3 영상 데이터 내의 라벨링된 고객의 존재 및 고객의 행동 분석을 통해, 특정 고객이 매장에 입장만 한 고객인지, 상품 선택까지 한 고객인지, 상품 결제까지 한 고객인지 구분할 수 있다. 즉, #1의 고객은 제 1 영상 데이터에도 존재하고, 제 2 영상 데이터에도 존재하며, 제 3 영상 데이터에도 존재함에 근거하여, 매장 출입부터, 상품 선택 및 상품 결제까지 한 고객으로 판단할 수 있다. #2의 고객은 제 1 영상 데이터에는 존재하나 제 2 영상 데이터 및 제 3 영상 데이터에는 존재하지 않음에 근거하여, 매장 출입만 하고, 상품 선택 및 상품 결제는 하지 않고 나간 고객으로 판단할 수 있다. 또한, 제 1 영상 데이 터와 제 2 영상 데이터에는 존재하나, 제 3 영상 데이터에는 존재하지 않는 고객은, 매장 출입과 상품 선택까지 하였으나, 상품 결제는 하지 않은 고객으로 판단할 수 있다. 이때, 제 2 영상 데이터를 세분화하여, 상품을 도 로 상품보관소에 놓는 행위와 관련된 데이터가 있는지 확인하는 것이 바람직하다. 더욱이, 고객의 퇴장 영상(제 4 영상 데이터(미도시))을 활용하면 보다 효과적으로 고객의 행동 패턴을 분석할 수 있다. 퇴장 영상 분석을 통 해, 고객이 상품을 들고 나갔는지 들고 나가지 않았는지를 명확히 확인할 수 있기 때문이다. 다시 말해, 통합 서버는, 제 1 영상 데이터를 이용하여 개별 고객의 출입 여부를 체크(check)하고, 제 2 영상 데이터를 이용하여 고객의 상품 선택 여부를 체크하며, 제 3 영상 데이터 및/또는 결제 정보를 이용하여 고객의 상품 결제 여부를 체크할 수 있다. 또한, 퇴장 영상 데이터를 이용하여 고객이 상품을 가지고 나갔는지, 가져가 지 않고 들어올 때와 동일 또는 유사하게 나갔는지를 최종 점검할 수 있다. 이때, 고객이 상품을 들고 나가는 백(bag)이 비닐 봉지와 같이 내부가 보이는 백인 경우에는, 가져나간 상품의 종류 및 갯수까지 보다 명확하게 분별할 수 있다. 특히, 카메라가 촬영한 영상 데이터에는 모두 시간 정보가 포함되어 있기 때문에, 시간의 흐름에 따른 고객의 행동을 보다 명확하게 유추할 수 있다. 즉, 매장 출입 후, 제 1 냉장고로 가서 상품을 선택하였고, 그 다음 제 3 냉장고로, 그 다음 제 2 냉장고로 가서 상품을 선택하였으며, 이후 상품 결제 후, 14시 05분 12초에 퇴장하였 다는 일련의 고객의 매장 내 행동 흐름을 거의 완벽하게 파악할 수 있다. 위와 같은 고객의 중요 행위마다 센싱정보, 및 결제 정보가 존재하고, 이를 기반으로 동작하는 카메라가 존재하기 때문에, 영상 내의 특정 행동 관련 인덱스를 기반으로 고객의 행동 흐름을 조합할 수 있는 것이다. 도 5는 도 4의 라벨링된 영상 데이터를 분석한 결과를 표현하는 테이블이다. 도 5를 참조하면, 통합 서버는, 도 4의 영상 분석 방법을 통해, 행동 패턴을 기설정된 복수 개의 타입으로 구분 할 수 있다. 도 4의 실시예에서는 A부터 C까지 3가지 타입으로 구분하였지만, 행동 패턴 시나리오를 다르게 설"}
{"patent_id": "10-2021-0104568", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "정함에 따라 더 많은 타입으로 세분화될 수 있음은 본 발명이 속하는 기술분야의 통상의 기술자에게는 자명한 것일 것이다. 먼저, 통합 서버는 매장 입장, 상품 선택 및 결제까지 수행한 #1과 같은 고객은 A 타입(type)으로 구분할 수 있 다. 그리고, 매장 입장 및 상품 선택을 하였으나, 결제는 수행하지 않은 #2와 같은 고객을 B 타입으로 구분할 수 있다. 또한, 매장 입장만 하고, 상품 선택 및 결제를 하지 않은 #3과 같은 고객을 C 타입으로 구분할 수 있 다. 즉, 이와 같은 구분법을 이용하여 사용자가 설정한 제 1 시점부터 제 2 시점까지의 고객에 대해 모두 행동 패턴을 분석하여 3가지 타입 중 하나로 구분할 수 있다. 본 발명의 실시예에 따르면, 통합 서버는 위 3가지 타입에 대해 서로 다른 시각적 표현으로 디스플레이 수단에 서 표시되도록 제어할 수 있다. 또는, 청각적 표현을 다르게 할 수도 있다. 예를 들어, 관리자 단말에서 상기와 같이 타입 구분된 고객 행동 패턴 분석 결과를 표시할 때, 서버는 A 타입 고객은 푸른 색으로, C 타입 고객은 노란 색으로, B 타입 고객은 붉은 색으로 표시되도록 제어할 수 있다. 상대적으로, 도난과 관련하여, A 타입 고 객이 가장 정상적인 구매 행위를 한 고객으로 볼 수 있고, 그 다음이 C 타입 고객, 그리고, B 타입 고객이, 가 장 이상한 행동 패턴을 보인 고객으로 볼 수 있기 때문이다. 다시 말해, 매장 입장 및 상품 선택까지 했는데, 결제를 하지 않은 것은 상품을 가지고 결제하지 않고 그냥 가지고 나갔을 가능성을 배제할 수 없기 때문이다. 한편, 앞서 도 4에서도 언급한 바와 같이, 인공지능 모델은 보다 다양한 모션 인식이 가능하고, 이에 따라 세분 화된 행동을 기반으로 3개보다 더 세분화된 행동 타입 설정 또한 가능하다. 예를 들어, 매장 퇴장 영상을 분석 하여, 퇴장시 상품을 들고 나갔는지에 따라 타입을 구분할 수 있다. 특히, B 타입의 고객 중 퇴장시 영상을 기 반으로 상품을 들고 나가지 않은 고객은 B-1 타입으로, 상품을 들고 나간 고객은 B-2 타입으로 보다 세분화할 수 있다. 이때, B-2 타입의 고객은 하이라이트 표시가 되도록 할 수도 있다. 도 6은 무인 매장의 재고 수량이 맞지 않을 때 영상 데이터 분석 결과를 사용자가 직관적으로 이해하도록 시각 화하는 방법을 나타낸 흐름도이다. 도 6을 참조하면, 무인 매장 관리자는 정기적으로 재고 수량을 확인할 수 있다(S610). 관리자는 이미 재고 수량 을 확인한 제 1 시점부터 다음 재고 수량 확인을 위한 제 2 시점까지의 기간 정보를 설정하고, 고객 행동 패턴 분석 결과를 활용할 수 있다. 즉, 관리자가 설정한 기간 내의 재고 수량과 결제된 상품 수량을 비교하여, 이상 이 없는지 확인한다(S620). 제 1 시점의 재고는 제 2 시점의 재고에 결제된 상품을 더한 값과 일치해야 도난 없 이 해당 기간 동안 모든 상품이 결제되어 빠져나간 셈이 된다. 이는 정상적이라 볼 수 있다. 그런데, 위 두 값 이 맞지 않으면, 도난과 관련하여, 고객들의 영상 분석 결과를 살펴보는 것이 바람직하다. 이때, 영상 분석 결과를 표시함에 있어서, 도난과 관련되어 있을 가능성이 높은 타입의 고객들을 먼저 표시한다. 즉, B 타입의 고객을 먼저 표시하고(S630), 그 다음 C 타입의 고객(S640), 그리고 마지막에 A 타입의 고객들을 표시한다(S650). 표시할 때, 도 5와 같이, 테이블 형태로 해당 타입의 고객들을 표시한다. 행에는 고 객의 라벨이 열에는 고객의 행동 단계가 표시되도록 할 수 있다. 그 반대여도 무방하다. 관리자는 먼저 B 타입의 고객을 정렬하여 볼 수 있고, 그 다음 C 타입의 고객을 본다. 그리고 나서, A 타입의 고객을 보면서 도난과 관련된 행위를 한 고객을 찾아낸다. 이하 도 7을 통해 이 과정을 보다 상세히 설명한다. 도 7은 도 6의 방법에 따라 시각화하는 중에, 사용자 입력이 있을 때, 그에 대응하는 영상 데이터를 효율적으로 재생하는 방법을 설명하기 위한 개념도이다. 도 7을 참조하면, 통합 서버는 관리자 단말이든, 프록시 서버와 연결된 디스플레이 수단이든, 매장 내 디스플레 이 장치든, 고객의 행동 패턴이 시각화되어 표시되도록 제어한다. 이때, 도 6의 방법과 같이, 개별 타입별로 고 객들을 정리하는 형식으로 표시하는 것이 바람직하다. 예를 들어, B 타입의 고객들만 나열하여 표시하는 경우, 도 7의 실시예와 같이, 해당 설정된 기간 내에는 #3, #7, 및 #8의 고객들만이 표시될 수 있다. 이들은 모두, 매 장 입장과 상품 선택을 했지만, 상품 결제는 하지 않고 간 고객들이다. 이때, 통합 서버는 고객의 퇴장 영상을 고려하여, 고객의 입장부터 퇴장까지의 체류 시간을 더 표시해줄 수 있 다. 다른 예에서, 앞서 설명한 바와 같이, 퇴장시 고객이 상품을 들고 나갔는지를 분석하여 표시해줄 수 있다. 일반적으로 이러한 도난 사고가 발생했을 때, 관리자는 매장 내 설치된 CCTV 화면을 백워드 재생(backward play)하여 사고 당시 화면을 찾아낸다. 즉, 설정된 기간동안의 영상을 빠르게 포워딩한다 하더라도, 모든 시간 대의 영상을 일일이 확인하여야 하기에, 효율적이지 못하다. 실제 도난 사고 화면을 찾아내기도 어렵다. 하지만, 본 발명의 일 실시예에 따른, 무인 매장 시스템은 타입별 고객들을 테이블로 표시하는 사용자 인터페이 스 상에서, 특정 라벨의 고객을 선택하여, 해당 고객의 영상 데이터를 신속하게 로딩하여 재생함으로써 도난 사 고와 관련된 영상을 빠르게 확인할 수 있다. 도 7의 실시예에서, #8의 고객의 체류시간이 비정상적으로 긴 것을 인지한 관리자는 상기 테이블에서 #8 고객을 클릭하여, 해당 고객과 관련된 영상 데이터를 전체 로딩 후 재생할 수 있다. 이때, 영상 데이터는 #8 고객과 관 련된 모든 영상(예를 들어, 제 1 영상부터 제 n 영상)까지 준비될 수 있다. 그리고, 개별 영상 데이터는 특정 행위가 발생한 시점을 기준으로 전후 ±1분의 시간동안의 영상을 추출하여 재생하는 것이기 때문에, 이를 확인 하는데 그리 오랜 시간이 걸리지 않는다. 이러한 방법을 활용하기에, 관리자는 설정 기간 전체에 대한 영상을 일일이 확인할 필요가 없다. 여기서, 전후 ±n 분의 시간은 반드시 1분일 필요는 없고, 2분, 3분, 4분, 5분, 10 분, 20분 등 다른 기간으로 설정되어도 무방하다. 예를 들어, #8 고객의 매장 출입 영상을 재생할 때, #8 고객 의 매장 출입 시점을 기준점으로 하여, 매장 출입 전 1분부터 매장 출입 후 1분까지의 영상(카메라을 통해 촬영된 영상)을 재생한다. 그리고, 상품 선택과 관련하여, #8 고객과 관련된 제 2 영상 데이터가 존재할 때, 상 품 선택 시점을 기준으로, 상품 선택 전 1분부터 상품 선택 후 1분까지의 영상을 준비하여 재생한다. 상품 선택 관련하여서는, 다수의 냉장고(냉장고 1, 냉장고 3, 냉장고 4, ...)를 뒤져가며 선택을 할 수도 있기 때문에, 다 수의 상품 선택 영상 데이터에서, 상품 선택 시점을 기준으로 ±1분의 영상을 다수 재생할 수 있다. 여기서, 상 품 선택 시점은 냉장고의 경우, 냉장고 도어 개폐 시점이 될 수 있다. 또한, 출입문, 냉장고, 결제 단말 외, 다 른 곳을 비추는 영상 데이터 상에 #8의 고객이 표시되는 경우, 해당 고객의 표시 시점을 기준으로 표시되기 전 1분부터 표시된 후 1분의 데이터를 준비하여 재생시킬 수 있다. 이때, 사용자가 기준시점 이전 또는 이후로 더 많은 시간 구간에 대한 영상을 보고 싶으면, 사용자의 명령 입력에 의해, 해당 영상의 1분 이전 구간 또는 1분 이후 구간에 대한 컨텐츠를 재생할 수 있다. 앞서 도 5의 실시예에서, 보다 세분화된 동작으로 구분할 수 있다는 것을 언급하였듯이, 도 7의 테이블 상에서 상품 선택과 더불어 상품 선택 취소 동작을 인식할 수 있고, 상품 선택 취소 동작의 유무를 테이블 상에 표시해 줄 수 있다. 즉, #3 및 #8 고객은 상품 선택 동작도 있고, 상품 선택 취소 동작도 있는 반면, #7 고객은 상품 선택 동작만 있고, 상품 선택 취소 동작이 없는 분석 결과를 관리자에게 표시해줄 수도 있다. 그러면, 관리자는 #7 고객의 세부 영상을 보고자 할 것이고, 관리자는 #7 고객 관련 영상을 살펴봄으로써 어디에서 도난이 발생하 였는지를 확인할 수 있다. 본 발명의 실시예에 따르면, 테이블 내의 고객 라벨 부분과 동작 부분(720-1, 720-2, ...)을 특정하여 클 릭함으로써, 해당 고객의 해당 동작에 대응하는 화면만 표시되도록 제어할 수 있다. 예를 들어, 고객의 라벨 부 분을 클릭하면, 해당 고객과 관련된 모든 영상이 준비될 수 있다. 다만, 특정 고객의 매장 입장 부분(720- 1)을 클릭하면, 매장 입장과 관련된 제 1 영상 데이터만 재생되도록 할 수 있다. 상품 선택 부분만 보고 싶은 땐, 해당 고객의 열 내에서 상품 선택 동작을 지시하는 행 부분(720-2)을 클릭하면, 해당 동작과 관련된 제 2 영상 데이터만이 재생되도록 할 수 있다. 도 8은 도 1의 매장 내 디스플레이 장비 및 스피커를 통해 매장 내 고객의 행동 패턴을 실시간으로 나타내는 동 작을 설명하기 위한 개념도이다. 도 8을 참조하면, 통합 서버(또는 프록시 서버)는 매장 내 고객의 행동 패턴을 실시간으로 분석하여, 매장 내 디스플레이 장치 및/또는 스피커로 출력되도록 할 수 있다. 예를 들어, 디스플레이 장치의 화면을 분할하여, 다 수의 고객을 표시하도록 하고, 현재 입장된 고객들에 대해, 고객을 촬영하는 영상을 고객 라벨과 함께 출력하도 록 하며, 이때, 고객의 행동 단계를 앞서 행동 패턴 분석과 동일 또는 유사한 형태로 파악하여 출력할 수 있다. 예를 들어, #1의 고객이 입장 후, 상품 선택도 완료하였고, 현재 결제 단말에서 결제를 수행하고 있다면, 고객 입장이 감지되었을 때, 제 1 카메라(도 1의 120) 영상을 (동시에 라벨링도 수행) 표시하면서 \"입장\"이라는 동작 단계를 표시하고, 상품 선택 센싱 정보가 있을 때, 제 2 카메라(도 1의 134) 영상을 표시하면서 \"상품 선택\"이 라는 동작 단계를 표시하며, 결제 단말에서 결제 진행이 감지될 때, 제 3 카메라(도 1의 142) 영상을 표시하면 서 \"결제 중\"이라는 동작 단계를 표시하도록 제어할 수 있다. 이를 통해, 고객이 매장 내에 있을 때, 자신의 행 동이 계속하여 모니터링된다는 것을 느끼게 하여, 도난 및 파손 행위를 방지하는 효과를 가질 수 있다. 동작 단계의 표현는 영상으로만 출력하는 것이 아니라, 스피커를 통해 \"2번 고객님 입장하였습니다\" 또는 \"3번 고객님 상품 선택 중이십니다\" 등과 같이, 고객의 라벨과 동작 단계 정보를 음성으로 출력되게 제어할 수 있다. 한편, 디스플레이 장치 내에서 특정 고객의 영상은 해당 고객이 퇴장한 후 5분 후에 삭제되도록 할 수 있다. 이 때, 반드시 5분일 필요는 없고, 1분, 2분 등으로 설정되어도 무방하다. 또한, 매장 내 고객이 많아질수록, 화면 분할을 보다 세분화하여, 더 작게 분할된 다수의 화면을 확보하는 것이 바람직하다. 이는 입장 고객 수에 맞게 적응적으로 실행도리 수 있다. 도 9는 매장 내 연기 감지시 매장 내 디스플레이 장비 및 스피커를 통해 흡연자에게 경고하는 방법을 설명하기 위한 흐름도이다. 도 9를 참조하면, 본 발명의 일 실시예에 따른 무인 매장 시스템은 흡연 등을 감지하여 경고하는 시스템을 포함 한다. 앞서 설명한 바와 같이, 본 발명의 일 실시예에 따른 무인 매장 시스템은 다양한 IoT 센서들과 연동할 수 있다. 일 예로, 연기 감지 센서를 일정 구역마다 배열하여, 전체 매장 내에서의 흡연 연기를 감지할 수 있다. 실제로, 무인 매장 내에서의 흡연은 큰 문제가 되고 있음에도 매장 내 사람이 없기에, 이를 검거하지 못하고 있 는 실정이다. 따라서, 본 발명의 일 실시예에 따른 무인 매장 시스템은 흡연 감지 센서를 구비하고, 연기가 감지될 때, 도 8 의 실시예와 같이, 매장 내 디스플레이 장치를 통해 경고 메시지를 표시한다. 이때, 라벨링된 해당 고객의 현재 위치에 대응하는 카메라의 영상을 함께 표시한다. B 구역의 경우, 카메라 1과 매핑관계를 가질 수 있고, B 구역 연기 감지에 대응하여, 카메라 1에서 해당 고객의 영상을 촬영하며, 촬영된 영상을 디스플레이 장치에 표시된다. 이때, \"흡연 금지\"라는 문구와 함께 붉은 색으로 배경 화면을 변경시켜 경고 메시지를 표시한다. 이 때, 스피커를 통해 음성 경고도 함께 출력하는 것이 바람직하다. 예를 들어, \"9번 고객님 흡연 금지 구역입니다. 흡연을 금하여 주시기 바랍니다\"라는 코멘트를 출력할 수 있다. 이러한 1차적인 경고에도 불구하고, 연기 감지 센서를 통해 계속하여 (임계 시간 이상동안) 흡연이 감지되면, 서버는 기설정된 보안 시스 템과 연계하여 보안 요원이 출동하는 등의 조치를 취할 수 있다. 또는 관리자 단말로 흡연 감지 메시지를 전송 하여 관리자로 하여금 적절한 조치를 취할 수 있도록 지원한다. 흡연과 마찬가지로, 매장 내 주류 취식도 사회적으로 큰 문제가 되고 있다. 본 발명의 일 실시예에 따른 무인 매장 시스템은 주류 상품류가 배열된 장소에 센서(도어 개폐 센서, 접근센서, 적외선 센서 등)를 배치하여, 주 류 상품이 고객에 의해 선택되었음을 감지할 수 있다. 주류 선택이 감지되면, 해당 센서와 대응하는 카메라를 통해 해당 고객의 영상을 촬영하게 되는데, 이때, 주류 취식 행위(음주 행위)가 인공지능 기반의 모션 감지 모 델을 통해 검출되면, 시스템은 흡연시와 유사하게, 매장 내 디스플레이 장치를 통해 주류 취식 영상과 경고 메 시지를 함께 표시한다. 또한, 스피커로 경고할 수 있다. 위와 같은 1차 경고에도 불구하고, 계속하여 주류 취식 이 이어지면, 서버는, 기설정된 보안 시스템과 연계하여 보안 요원이 출동케 하는 조치를 취하거나 관리자 단말 로 주류 취식 감지 메시지를 전송하여 적절한 조취가 취해지도록 할 수 있다. 도 10은 도 1의 시스템을 통해 획득된 데이터를 무인 매장 경영 측에 활용하여 최적의 상품 진열 방법을 추론하 는 인공지능 모델을 학습시키는 방법을 설명하기 위한 개념도이다. 도 10을 참조하면, 본 발명의 일 실시예에 따른 무인 매장 시스템의 통합 서버는 매장 입장 수, 상품 선택 수, 결제 상품 수, 매장 매출 등을 고객의 행동 패턴과 함께 분석하여 매장 경영과 관련된 데이터를 도출할 수 있다. 일 예로, 시간대별 매장 입장 수, 상품 선택 수, 결제 상품 수 및 매장 매출 지표 중 적어도 일부를 학습 데이 터 셋으로 하여, 상품 진열을 변경(A-B-C-D → B-C-A-D → ...)해가며, 상기 학습 데이터 셋을 인공지능 기반의 기계 학습 모델에 입력했을 때, 매장 매출을 최대화하는 방향으로 최적의 상품 진열 방법이 추론될 수 있다. 이 때, 진열과 관련된 파라미터도 함께 입력으로 들어갈 수 있으며, 진열 파라미터를 변경하면서, 매장 매출 지표 및/또는 상품 선택 횟수와의 관계를 추론할 때, 매장 매출 지표 및/또는 상품 선택 횟수가 증대되는 방향으로 최적의 상품 배열 방안을 추론하는 형태로 인공지능 모델을 학습한다. 서버는, 이와 같은 방법으로 학습된 모델 을 이용하여 최적의 상품 배열 방안을 추론한다. 특히, 상품 선택수와 결제 상품 수와의 관계에서 최적 상품 진열을 추론할 수 있다. 통합 서버는, 상품별 선택 횟수 및 결제 횟수를 분석하여, 선택은 많았으나, 결제까지 이루어지지 않은 상품을 검출할 수 있고, 이를 관리 자에게 표시할 수 있다. 예를 들어, 아이스크림 A 상품은 선택을 많이 되었으나, 선택했다가 다시 냉장고에 놓 아지는 경우가 많을 수 있다. 이는, 앞서 설명하였던, 모션 인식 인공지능 모델을 통해, 상품별로 고객의 동작패턴 인식을 통해 확인할 수 있다. 서버는, 이러한 상품은 현재 진열 형태가 적절하지 않다고 판단하고, 이를 변경할 수 있으며, 변경된 상품 진열 포맷을 학습데이터로 입력할 수 있다. 이와 함께, 상품 진열 포맷 변경과 그에 따른 매출 증대 또는 상품 진열 포맷 변경에 따라 상품 선택 후 다시 회귀하지 않고 결제까지 이루어지는 지 여부 등의 결과 값을 함께 학습데이터로 생성하여, 최적의 상품 진열 포맷을 도출하는 인공지능 모델을 생성, 학습 및 실행할 수 있다. 다른 예에서, 서버는, 시간대별 매출 지표 및, 고객 행동 패턴 분석 결과를 기반으로, 특정 시간대에는 매장 입 장은 많음에 비해, 상품 선택 및 상품 결제가 많이 이루어지지 않음에 대응하여, 해당 시간대를 추출, 추출된 시간대에 입장한 고객들에게는 상품 할인 등의 이벤트를 추천하는 형태로 관리자에게 도움을 줄 수 있다. 도 11은 본 발명의 일 실시예에 따른 고객 행동 패턴 분석을 수행하는 무인 매장 시스템을 구성하는 장치의 구 성을 구체적으로 나타낸 상세 블록도이다. 도 11에 도시된 바와 같이, 본 발명의 일 실시예에 따른, 무인 매장 시스템의 장치는, 통신부, 프로세서, 메모리 및 입출력 모듈을 포함할 수 있다. 여기 서, 장치는 프록시 서버 또는 통합 서버일 수 있다. 도 11을 참조하면, 통신부는 유선 또는 무선 네트워크를 이용하여 타 단말과 주고받기 위한 구성요소이다. 통신부는 안테나를 포함할 수 있다. 통신부는 센서들로부터 센싱 정보, 결제 단말로 부터 결제 정보뿐만 아니라, 카메라들로부터 영상 데이터를 수신한다. 프로세서는 통신부를 통해 수신된 정보를 처리하는 구성요소이다. 이는 하드웨어적으로 마이크로 프로세서로 구현될 수 있다. 프로세서는 센서로부터의 센싱 정보를 식별하여, 그에 대응하는 카메라에 촬 영 명령을 전달한다. 그리고, 수집된 영상 데이터를 얼굴 인식, 객체 검출 및 모션 인식 등의 인공지능 모델을 실행시켜 고객 별로 라벨링하고, 고객의 행동 패턴 및 단계를 분석한다. 프로세서는 메모리와 신호선을 통해 연결되어 있으며, 메모리에 저장된 프로그램을 실행한 다. 프로세서는 앞서 설명한 바와 같이, 도난 및 보안 관련 고객의 행동을 분석할 뿐만 아니라, 분석된 고객의 행동 패턴을 매출 지표와 연계하여, 매장 경영에 도움이 되는 데이터로 가공한다. 이때도 역시 인공지능 기반의 학습 모델이 실행될 수 있다. 메모리는 프로세서에서 수행해야 할 프로그램들과 연관된 명령어들을 저장하고 있으며, 프로세서 에서 요구하는 각종 데이터를 저장하고 있는 저장장치이다. 메모리는 매장 내 센서로부터 획득되는 각종 센싱 데이터 및 카메라로부터 획득되는 영상 데이터를 저장하고 있다. 또한, 센서와 카메라와의 매핑 관계 뿐만 아니라, 센싱 정보를 획득했을 때 다음 동작으로 어떤 동작을 행해야 하는 등의 시나리오를 프로그램 언어 의 형태로 저장하고 있을 수 있다. 메모리는 장치 내부의 로컬 메모리 또는 외부의 대용량 데이터베이스 로써 구현될 수 있다. 입출력 모듈은 키보드, 마우스와 같은 정보 입력 수단 및 모니터, TV, 터치스크린과 같은 정보 출력 수단 을 포함한다. 입출력 모듈은 고객 행동 패턴 분석 대상 시간 구간의 설정 등 각종 설정값을 변경하고 분 석 결과 등을 표시하는데 사용될 수 있다. 이상에서 설명된 시스템 또는 장치는 하드웨어 구성요소, 소프트웨어 구성요소, 및/또는 하드웨어 구성요소 및 소프트웨어 구성요소의 조합으로 구현될 수 있다. 예를 들어, 실시예들에서 설명된 시스템, 장치 및 구성요소는, 예를 들어, 프로세서, 콘트롤러, ALU(arithmetic logic unit), 디지털 신호 프로세서(digital signal processor), 마이크로컴퓨터, FPA(field programmable array), PLU(programmable logic unit), 마이크 로프로세서, 또는 명령(instruction)을 실행하고 응답할 수 있는 다른 어떠한 장치와 같이, 하나 이상의 범용 컴퓨터 또는 특수 목적 컴퓨터를 이용하여 구현될 수 있다. 처리 장치는 운영 체제(OS) 및 상기 운영 체제 상에 서 수행되는 하나 이상의 소프트웨어 애플리케이션을 수행할 수 있다. 또한, 처리 장치는 소프트웨어의 실행에 응답하여, 데이터를 접근, 저장, 조작, 처리 및 생성할 수도 있다. 이해의 편의를 위하여, 처리 장치는 하나가"}
{"patent_id": "10-2021-0104568", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "사용되는 것으로 설명된 경우도 있지만, 해당 기술분야에서 통상의 지식을 가진 자는, 처리 장치가 복수 개의 처리요소(processing element) 및/또는 복수 유형의 처리 요소를 포함할 수 있음을 알 수 있다. 예를 들어, 처 리 장치는 복수 개의 프로세서 또는 하나의 프로세서 및 하나의 콘트롤러를 포함할 수 있다. 또한, 병렬 프로세 서(parallel processor)와 같은, 다른 처리 구성(processing configuration)도 가능하다. 소프트웨어는 컴퓨터 프로그램(computer program), 코드(code), 명령(instruction), 또는 이들 중 하나 이상의 조합을 포함할 수 있으며, 원하는 대로 동작하도록 처리 장치를 구성하거나 독립적으로 또는 결합적으로(collectively) 처리 장치를 명령할 수 있다. 소프트웨어 및/또는 데이터는, 처리 장치에 의하여 해석되거나 처 리 장치에 명령 또는 데이터를 제공하기 위하여, 어떤 유형의 기계, 구성요소(component), 물리적 장치, 가상 장치(virtual equipment), 컴퓨터 저장 매체 또는 장치, 또는 전송되는 신호 파(signal wave)에 영구적으로, 또는 일시적으로 구체화(embody)될 수 있다. 소프트웨어는 네트워크로 연결된 컴퓨터 시스템 상에 분산되어서, 분산된 방법으로 저장되거나 실행될 수도 있다. 소프트웨어 및 데이터는 하나 이상의 컴퓨터 판독 가능 기록 매 체에 저장될 수 있다. 실시예들에 따른 방법은 다양한 컴퓨터 수단을 통하여 수행될 수 있는 프로그램 명령 형태로 구현되어 컴퓨터 판독 가능 매체에 기록될 수 있다. 상기 컴퓨터 판독 가능 매체는 프로그램 명령, 데이터 파일, 데이터 구조 등 을 단독으로 또는 조합하여 포함할 수 있다. 상기 매체에 기록되는 프로그램 명령은 실시예를 위하여 특별히 설 계되고 구성된 것들이거나 컴퓨터 소프트웨어 당업자에게 공지되어 사용 가능한 것일 수도 있다. 컴퓨터 판독 가능 기록 매체의 예에는 하드 디스크, 플로피 디스크 및 자기 테이프와 같은 자기체(magnetic media), CD-ROM, DVD와 같은 광기록 매체(optical media), 플롭티컬 디스크(floptical disk)와 같은 자기-광 매체(magneto- optical media), 및 롬(ROM), 램(RAM), 플래시 메모리 등과 같은 프로그램 명령을 저장하고 수행하도록 특별히 구성된 하드웨어 장치가 포함된다. 프로그램 명령의 예에는 컴파일러에 의해 만들어지는 것과 같은 기계어 코드 뿐만 아니라 인터프리터 등을 사용해서 컴퓨터에 의해서 실행될 수 있는 고급 언어 코드를 포함한다. 상기된 하 드웨어 장치는 실시예의 동작을 수행하기 위해 하나 이상의 소프트웨어 모듈로서 작동하도록 구성될 수 있으며, 그 역도 마찬가지이다."}
{"patent_id": "10-2021-0104568", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "이상과 같이 실시예들이 비록 한정된 실시예와 도면에 의해 설명되었으나, 해당 기술분야에서 통상의 지식을 가 진 자라면 상기의 기재로부터 다양한 수정 및 변형이 가능하다. 예를 들어, 설명된 기술들이 설명된 방법과 다 른 순서로 수행되거나, 및/또는 설명된 시스템, 구조, 장치, 회로 등의 구성요소들이 설명된 방법과 다른 형태 로 결합 또는 조합되거나, 다른 구성요소 또는 균등물에 의하여 대치되거나 치환되더라도 적절한 결과가 달성될 수 있다. 그러므로, 다른 구현들, 다른 실시예들 및 특허청구범위와 균등한 것들도 후술하는 특허청구범위의 범위에 속한 다.도면 도면1 도면2 도면3 도면4 도면5 도면6 도면7 도면8 도면9 도면10 도면11"}
{"patent_id": "10-2021-0104568", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일 실시예에 따른 고객 행동 패턴 분석을 수행하는 무인 매장 시스템을 나타낸 개념도, 도 2는 본 발명의 다른 실시예에 따른 고객 행동 패턴 분석을 수행하는 무인 매장 시스템을 나타낸 도면, 도 3은 도 1 또는 도 2의 무인 매장 내 장비들 간의 정보 교류 과정을 나타낸 흐름도, 도 4는 무인 매장 내 다수의 카메라 장비를 통해 획득된 영상 데이터들에 라벨링(Labeling)을 수행하여 고객을 일괄적으로 관리하는 방법을 설명하기 위한 개념도, 도 5는 도 4의 라벨링된 영상 데이터를 분석한 결과를 표현하는 테이블, 도 6은 무인 매장의 재고 수량이 맞지 않을 때 영상 데이터 분석 결과를 사용자가 직관적으로 이해하도록 시각 화하는 방법을 나타낸 흐름도,도 7은 도 6의 방법에 따라 시각화하는 중에, 사용자 입력이 있을 때, 그에 대응하는 영상 데이터를 효율적으로 재생하는 방법을 설명하기 위한 개념도, 도 8은 도 1의 매장 내 디스플레이 장비 및 스피커를 통해 매장 내 고객의 행동 패턴을 실시간으로 나타내는 동 작을 설명하기 위한 개념도, 도 9는 매장 내 연기 감지시 매장 내 디스플레이 장비 및 스피커를 통해 흡연자에게 경고하는 방법을 설명하기 위한 흐름도, 도 10은 도 1의 시스템을 통해 획득된 데이터를 무인 매장 경영 측에 활용하여 최적의 상품 진열 방법을 추론하 는 인공지능 모델을 학습시키는 방법을 설명하기 위한 개념도, 도 11은 본 발명의 일 실시예에 따른 고객 행동 패턴 분석을 수행하는 무인 매장 시스템을 구성하는 장치의 구 성을 구체적으로 나타낸 상세 블록도이다."}
