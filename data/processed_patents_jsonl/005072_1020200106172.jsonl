{"patent_id": "10-2020-0106172", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2022-0025455", "출원번호": "10-2020-0106172", "발명의 명칭": "적대적 공격에 대한 방어 방법 및 그 장치", "출원인": "주식회사 케이티", "발명자": "박영철"}}
{"patent_id": "10-2020-0106172", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "훈련 데이터를 기반으로 딥러닝 모델을 학습하는 단계;상기 딥러닝 모델의 순전파(feedforward) 과정을 통해 출력층의 예측 정확도를 산출하는 단계;상기 출력층의 예측 정확도가 제1 임계치 이상인 경우, 상기 딥러닝 모델의 은닉층에 존재하는 하나 이상의 중요 노드들을 검출하는 단계; 및상기 딥러닝 모델의 역전파(backpropagation) 과정 시, 상기 검출된 중요 노드들의 가중치(weight), 편향(bias)및 기울기(gradient) 중 적어도 하나를 동형암호화(Homomorphic Encryption)하는 단계를 포함하는 적대적 공격방어 방법."}
{"patent_id": "10-2020-0106172", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 훈련 데이터는 바이오 인증(biometrics)과 관련된 데이터임을 특징으로 하는 적대적 공격 방어 방법."}
{"patent_id": "10-2020-0106172", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 딥러닝 모델은 다층 퍼셉트론(Multi-Layer Perceptron)을 이용한 심층 신경망(Deep Neural Network) 모델임을 특징으로 하는 적대적 공격 방어 방법."}
{"patent_id": "10-2020-0106172", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서, 상기 중요 노드 검출 단계는, 상기 은닉층에 존재하는 노드들의 가중치 변경 빈도를 기반으로 상기 중요 노드들을 검출하는 것을 특징으로 하는 적대적 공격 방어 방법."}
{"patent_id": "10-2020-0106172", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서, 상기 중요 노드 검출 단계는, 상기 은닉층에 존재하는 노드들의 가중치에 관한 이력(history) 정보를 분석하여 상기 중요 노드들을 검출하는것을 특징으로 하는 적대적 공격 방어 방법."}
{"patent_id": "10-2020-0106172", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서,상기 중요 노드 검출 시, 상기 딥러닝 모델의 훈련 데이터와 관련된 객체의 위치정보를 검출하는 단계; 및Word2Vec 알고리즘을 이용하여 상기 객체의 위치정보를 벡터 값으로 변환하는 단계를 더 포함하는 적대적 공격방어 방법."}
{"patent_id": "10-2020-0106172", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6항에 있어서,상기 변환된 벡터 값을 포함하는 노드를 생성하고, 상기 노드를 상기 출력층에 추가하는 단계를 더 포함하는 적대적 공격 방어 방법."}
{"patent_id": "10-2020-0106172", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "공개특허 10-2022-0025455-3-제7항에 있어서,상기 출력층에 추가된 노드의 벡터 값은, 역전파(BP) 과정 시, 상기 중요 노드의 입력 값으로 사용되는 것을 특징으로 하는 적대적 공격 방어 방법."}
{"patent_id": "10-2020-0106172", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1항에 있어서,상기 중요 노드들에 대해서만 순전파(FF)/역전파(BP) 과정을 반복 수행하는 단계를 더 포함하는 적대적 공격 방어 방법."}
{"patent_id": "10-2020-0106172", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9항에 있어서,상기 순전파(FF) 과정을 통해 획득된 출력층의 예측 정확도가 제2 임계치 이상인 경우, 상기 딥러닝 모델의 학습을 종료하는 단계를 더 포함하는 적대적 공격 방어 방법."}
{"patent_id": "10-2020-0106172", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "청구항 제1항 내지 제10항 중 어느 하나의 항에 따른 방법이 컴퓨터 상에서 실행되도록 컴퓨터 판독 가능한 기록매체에 저장된 컴퓨터 프로그램."}
{"patent_id": "10-2020-0106172", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "딥러닝 모델의 학습 과정 중 순전파(feedforward) 과정을 처리하는 순전파 처리부;상기 딥러닝 모델의 학습 과정 중 역전파(backpropagation) 과정을 처리하는 역전파 처리부;상기 순전파(FF) 과정을 통해 계산된 출력층의 예측 정확도가 제1 임계치 이상인 경우, 상기 딥러닝 모델의 은닉층에 존재하는 하나 이상의 중요 노드들을 검출하는 중요노드 검출부; 및상기 딥러닝 모델의 역전파(BP) 과정 시, 상기 검출된 중요 노드들의 가중치(weight), 편향(bias) 및 기울기(gradient) 중 적어도 하나를 동형암호화(Homomorphic Encryption)하는 암호화 처리부를 포함하는 적대적 공격방어 장치."}
{"patent_id": "10-2020-0106172", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제12항에 있어서,데이터베이스에 수집된 원천 데이터(raw data)를 상기 딥러닝 모델에 적합한 학습 데이터로 변환하는 데이터 전처리부를 더 포함하는 적대적 공격 방어 장치."}
{"patent_id": "10-2020-0106172", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제12항에 있어서,상기 딥러닝 모델과, 상기 딥러닝 모델에 사용할 최적의 딥러닝 알고리즘을 선택하는 학습모델 선정부를 더 포함하는 적대적 공격 방어 장치."}
{"patent_id": "10-2020-0106172", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제12항에 있어서,상기 중요 노드 검출 시, 상기 딥러닝 모델의 훈련 데이터와 관련된 객체의 위치정보를 검출하고, 상기 검출된객체의 위치정보를 벡터 값으로 변환하는 위치정보 검출부를 더 포함하는 적대적 공격 방어 장치."}
{"patent_id": "10-2020-0106172", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제15항에 있어서,상기 위치정보 검출부는, 상기 변환된 벡터 값을 포함하는 노드를 생성하고, 상기 노드를 상기 출력층에 추가하공개특허 10-2022-0025455-4-는 것을 특징으로 하는 적대적 공격 방어 장치."}
{"patent_id": "10-2020-0106172", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제12항에 있어서,상기 중요노드 검출부는, 상기 은닉층에 존재하는 노드들의 가중치 변경 빈도를 기반으로 상기 중요 노드들을검출하는 것을 특징으로 하는 적대적 공격 방어 장치."}
{"patent_id": "10-2020-0106172", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 적대적 공격 방어 방법에 관한 것으로, 훈련 데이터를 기반으로 딥러닝 모델을 학습하는 단계; 상기 딥러닝 모델의 순전파(feedforward) 과정을 통해 출력층의 예측 정확도를 산출하는 단계; 상기 출력층의 예측 정 확도가 제1 임계치 이상인 경우, 상기 딥러닝 모델의 은닉층에 존재하는 하나 이상의 중요 노드들을 검출하는 단 계; 및 상기 딥러닝 모델의 역전파(backpropagation) 과정 시, 상기 검출된 중요 노드들의 가중치, 편향 및 기울 기 중 적어도 하나를 동형암호화하는 단계를 포함한다."}
{"patent_id": "10-2020-0106172", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 적대적 공격에 대한 방어 방법 및 그 장치에 관한 것으로서, 보다 구체적으로는 인공지능(AI) 애플리 케이션에 대한 적대적 공격을 효과적으로 방어하기 위한 적대적 공격 방어 방법 및 그 장치에 관한 것이다."}
{"patent_id": "10-2020-0106172", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "인공지능(Artificial Intelligence, AI)의 목표는 '사람처럼 생각하고 행동하는 기계/컴퓨터'를 만드는 것이다. 인공지능을 구현하고자 할 때, 지식과 규칙에서 시작해서 다양한 응용을 추구하는 top-down 방식과, 실 세계의 데이터에서 시작해서 특정 응용 문제를 해결하고 더 나아가 지식과 규칙의 발견까지도 기대하는 bottom-up 방식 의 두 방향이 가능하다. 최근 주목을 받고 있는 머신러닝(machine learning)은 대표적인 bottom-up 방식이며, 딥러닝(deep learning)은 머신러닝의 한 분야이다. 딥러닝(Deep Learning)은 컴퓨터가 여러 데이터를 이용해 마치 사람처럼 스스로 학습할 수 있도록 인공 신경망 (ANN, Artificial Neural Network)을 기반으로 구축한 기술이다. 딥러닝은 인간의 두뇌가 수많은 데이터 속에서 패턴을 발견한 뒤 사물을 구분하는 정보 처리 방식을 모방해 컴퓨터가 사물을 분별하도록 기계를 학습시킨다. 딥러닝 기술을 적용하면 사람이 모든 판단 기준을 정해주지 않아도 컴퓨터가 스스로 인지, 추론, 판단할 수 있 게 된다. 이러한 딥러닝 기술을 가능하게 하는 딥러닝 알고리즘에는 심층 신경망(DNN, Deep Neural Network), 합성곱 신경망(CNN, Convolutional Neural Network), 순환 신경망(RNN, Recurrent Neural Network) 등이 있다. 최근 들어 딥러닝 기술에 대한 사회적 관심이 증가함에 따라 해당 기술이 자율주행 및 생체인식 등과 같은 다양"}
{"patent_id": "10-2020-0106172", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 2, "content": "한 기술분야에 폭넓게 적용되면서, 크게 두 가지 단점이 대두되고 있다. 첫 번째는, 딥러닝 모델이 내재적으로 가진 불확실성(uncertainty)이고, 두 번째는 명시적으로 정의된 특징(handcrafted feature) 기반의 머신러닝에 비해 학습된 딥러닝 모델은 블랙박스(black-box)와 같아 그 추론 결과가 설명가능(explainable)하지 않다는 점 이다. 이러한 딥러닝 모델의 단점을 이용하여 AI 애플리케이션에 대해 적대적 공격(Adversarial Attack)을 시도 하는 경우가 점점 늘어나고 있다. 예를 들어, 얼굴/음성/지문/홍채 인식 등과 같은 바이오 인증 시, 외부 공격 자(가령, 해커)가 딥러닝 알고리즘에 사용되는 경사 하강법의 기울기(gradient) 값을 이용하거나 혹은 탐욕 알 고리즘을 이용하여 딥러닝 모델의 결과를 위/변조할 수 있다. 일반적으로 적대적 공격은 딥러닝 알고리즘에 내재하고 있는 취약점에 의해 적대적 환경에서 발생할 수 있는 보 안 위험을 통칭한다. 상기 적대적 공격의 종류로는 악의적인 학습 데이터를 주입하여 딥러닝 모델을 망가뜨리는 중독 공격(poisoning attack), 딥러닝 모델의 추론 과정에서 데이터를 교란해 딥러닝을 속이는 회피 공격 (evasion attack), 역공학을 이용해 학습 데이터를 탈취하는 학습 데이터 추출 공격(inversion attack) 등이 있다. 이러한 적대적 공격으로부터 딥러닝 모델을 안전하게 보호하기 위해, 여러 가지 방어 기법이 제안되고 있다. 적 대적 공격에 대한 대표적인 방어 기법으로는 적대적 훈련 기법, Gradient Masking/Distillation 기법, Feature Squeezing 기법 등이 있다. 적대적 훈련 기법은 자동 진단 모델을 학습시킬 때, 적대적 사례로서 작동할 수 있는 모든 경우의 수를 미리 학 습 데이터 셋에 포함시키는 기법이다. Gradient Masking/Distillation 기법은 학습모델의 기울기(gradient)가 출력으로서 그대로 노출되는 것을 방지하거나, 학습모델의 구조상 기울기 자체를 일종의 정규화 방법과 같이 두 드러지지 않게 하여 적대적 공격의 학습 방향에 힌트를 주지 않도록 하는 기법이다. Feature Squeezing 기법은 본래의 학습모델과 별도로, 주어진 입력 데이터에 대해 적대적 사례인지 아닌지를 판단하는 학습모델을 추가하 는 기법이다. 하지만, 기존의 방어 기법들은 적대적 공격에 대한 근본적인 해결책은 아니며, 추가적인 학습 데이터 및 학습 알고리즘을 필요로 하는 문제가 있다. 또한, 기존의 방어 기법들은 실시간 대응이 필요한 기술 분야에는 적합하 지 않다는 문제가 있다. 따라서, 바이오 인증과 관련된 AI 애플리케이션에 대한 적대적 공격을 방어하기 위한 새로운 기법이 필요하다."}
{"patent_id": "10-2020-0106172", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 전술한 문제 및 다른 문제를 해결하는 것을 목적으로 한다. 또 다른 목적은 심층 신경망(DNN) 모델을 이용하는 AI 애플리케이션에 대한 적대적 공격을 효과적으로 방어하기 위한 적대적 공격 방어 방법 및 그 장치 를 제공함에 있다. 또 다른 목적은 바이오 인증(biometrics)과 관련된 AI 애플리케이션에 대한 적대적 공격을 효과적으로 방어하기 위한 적대적 공격 방어 방법 및 그 장치를 제공함에 있다."}
{"patent_id": "10-2020-0106172", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기 또는 다른 목적을 달성하기 위해 본 발명의 일 측면에 따르면, 훈련 데이터를 기반으로 딥러닝 모델을 학 습하는 단계; 상기 딥러닝 모델의 순전파(feedforward) 과정을 통해 출력층의 예측 정확도를 산출하는 단계; 상 기 출력층의 예측 정확도가 제1 임계치 이상인 경우, 상기 딥러닝 모델의 은닉층에 존재하는 하나 이상의 중요 노드들을 검출하는 단계; 및 상기 딥러닝 모델의 역전파(backpropagation) 과정 시, 상기 검출된 중요 노드들의 가중치, 편향 및 기울기 중 적어도 하나를 동형암호화하는 단계를 포함하는 적대적 공격 방어 방법을 제공한다. 본 발명의 다른 측면에 따르면, 딥러닝 모델의 학습 과정 중 순전파(feedforward) 과정을 처리하는 순전파 처리 부; 상기 딥러닝 모델의 학습 과정 중 역전파(backpropagation) 과정을 처리하는 역전파 처리부; 상기 순전파 (FF) 과정을 통해 계산된 출력층의 예측 정확도가 제1 임계치 이상인 경우, 상기 딥러닝 모델의 은닉층에 존재 하는 하나 이상의 중요 노드들을 검출하는 중요노드 검출부; 및 상기 딥러닝 모델의 역전파(BP) 과정 시, 상기 검출된 중요 노드들의 가중치, 편향 및 기울기 중 적어도 하나를 동형암호화하는 암호화 처리부를 포함하는 적 대적 공격 방어 장치를 제공한다. 본 발명의 또 다른 측면에 따르면, 훈련 데이터를 기반으로 딥러닝 모델을 학습하는 과정; 상기 딥러닝 모델의 순전파(feedforward) 과정을 통해 출력층의 예측 정확도를 산출하는 과정; 상기 출력층의 예측 정확도가 제1 임 계치 이상인 경우, 상기 딥러닝 모델의 은닉층에 존재하는 하나 이상의 중요 노드들을 검출하는 과정; 및 상기 딥러닝 모델의 역전파(backpropagation) 과정 시, 상기 검출된 중요 노드들의 가중치, 편향 및 기울기 중 적어 도 하나를 동형암호화하는 과정이 컴퓨터 상에서 실행 가능하도록 컴퓨터 판독 가능한 기록매체에 저장된 컴퓨 터 프로그램을 제공한다."}
{"patent_id": "10-2020-0106172", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명의 실시 예들에 따른 적대적 공격 방어 방법 및 그 장치의 효과에 대해 설명하면 다음과 같다. 본 발명의 실시 예들 중 적어도 하나에 의하면, 딥러닝 모델의 은닉층에 존재하는 중요 노드들을 검출하고 해당 노드들의 가중치를 동형암호화함으로써, 해당 모델을 이용하는 AI 애플리케이션에 대한 적대적 공격을 효과적으 로 방어할 수 있다는 장점이 있다. 또한, 본 발명의 실시 예들 중 적어도 하나에 의하면, 은닉층의 중요 노드 검출 시, 입력 데이터(즉, 바이오 인 증 데이터)와 관련된 객체의 위치정보를 딥러닝 모델에 추가함으로써, 해당 모델의 성능을 개선할 수 있을 뿐만 아니라 적대적 공격에 대한 회피 능력을 향상시킬 수 있다는 장점이 있다. 다만, 본 발명의 실시 예들에 따른 적대적 공격 방어 방법 및 그 장치가 달성할 수 있는 효과는 이상에서 언급"}
{"patent_id": "10-2020-0106172", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 2, "content": "한 것들로 제한되지 않으며, 언급하지 않은 또 다른 효과들은 아래의 기재로부터 본 발명이 속하는 기술분야에 서 통상의 지식을 가진 자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2020-0106172", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 첨부된 도면을 참조하여 본 명세서에 개시된 실시 예를 상세히 설명하되, 도면 부호에 관계없이 동일하거 나 유사한 구성요소는 동일한 참조 번호를 부여하고 이에 대한 중복되는 설명은 생략하기로 한다. 이하의 설명 에서 사용되는 구성요소에 대한 접미사 \"모듈\" 및 \"부\"는 명세서 작성의 용이함만이 고려되어 부여되거나 혼용 되는 것으로서, 그 자체로 서로 구별되는 의미 또는 역할을 갖는 것은 아니다. 즉, 본 발명에서 사용되는 '부' 라는 용어는 소프트웨어, FPGA 또는 ASIC과 같은 하드웨어 구성요소를 의미하며, '부'는 어떤 역할들을 수행한 다. 그렇지만 '부'는 소프트웨어 또는 하드웨어에 한정되는 의미는 아니다. '부'는 어드레싱할 수 있는 저장 매 체에 있도록 구성될 수도 있고 하나 또는 그 이상의 프로세서들을 재생시키도록 구성될 수도 있다. 따라서, 일 예로서 '부'는 소프트웨어 구성요소들, 객체지향 소프트웨어 구성요소들, 클래스 구성요소들 및 태스크 구성요 소들과 같은 구성요소들과, 프로세스들, 함수들, 속성들, 프로시저들, 서브루틴들, 프로그램 코드의 세그먼트들, 드라이버들, 펌웨어, 마이크로 코드, 회로, 데이터, 데이터베이스, 데이터 구조들, 테이블들, 어레 이들 및 변수들을 포함한다. 구성요소들과 '부'들 안에서 제공되는 기능은 더 작은 수의 구성요소들 및 '부'들 로 결합되거나 추가적인 구성요소들과 '부'들로 더 분리될 수 있다. 또한, 본 명세서에 개시된 실시 예를 설명함에 있어서 관련된 공지 기술에 대한 구체적인 설명이 본 명세서에 개시된 실시 예의 요지를 흐릴 수 있다고 판단되는 경우 그 상세한 설명을 생략한다. 또한, 첨부된 도면은 본 명세서에 개시된 실시 예를 쉽게 이해할 수 있도록 하기 위한 것일 뿐, 첨부된 도면에 의해 본 명세서에 개시된 기술적 사상이 제한되지 않으며, 본 발명의 사상 및 기술 범위에 포함되는 모든 변경, 균등물 내지 대체물을 포 함하는 것으로 이해되어야 한다. 본 발명은 심층 신경망(DNN) 모델을 이용하는 AI 애플리케이션에 대한 적대적 공격을 효과적으로 방어하기 위한 적대적 공격 방어 방법 및 그 장치를 제안한다. 또한, 본 발명은 바이오 인증(biometrics)과 관련된 AI 애플리 케이션에 대한 적대적 공격을 효과적으로 방어하기 위한 적대적 공격 방어 방법 및 그 장치를 제안한다. 이하에서는, 본 발명의 다양한 실시 예들에 대하여, 도면을 참조하여 상세히 설명한다. 도 1은 본 발명과 관련된 다층 퍼셉트론(MLP)의 구조를 나타내는 도면이고, 도 2는 도 1에 도시된 다층 퍼셉트 론의 학습 과정을 설명하기 위해 참조되는 도면이다. 도 1 및 도 2를 참조하면, 본 발명과 관련된 다층 퍼셉트론(Multi-Layer Perceptron, MLP, 100)은 입력층 (input layer, 110), 은닉층(hidden layer, 120) 및 출력층(output layer, 130)으로 구성된다. 다층 퍼셉트론은 단일 퍼셉트론의 한계를 극복하기 위해 제안된 인공 신경망 구조이다. 즉, 다층 퍼셉트론 은 XOR 게이트(exclusive-OR gate)와 같이 비선형적으로 분리되는 데이터에 대해서도 학습이 가능하도록 제안된 인공 신경망 구조이다. 이를 위해, 상기 다층 퍼셉트론은, 단일 퍼셉트론과 달리, 하나 이상의 은 닉층을 더 포함하는 구조를 갖는다. 다층 퍼셉트론의 입력층은 학습 데이터에 해당하는 입력 벡터가 위치하는 층을 의미하고, 출력층 은 학습 모델의 최종 결과값이 위치하는 층을 의미한다. 그리고, 은닉층은 입력층과 출력층 사이에 존재하는 모든 층을 의미한다. 상기 은닉층의 개수가 많아질수록 인공 신경망이 ‘깊어졌다 (deep)’라고 부르며, 이렇게 충분히 깊어진 인공 신경망을 학습 모델로 사용하는 머신러닝 패러다임을 바로 딥 러닝(Deep Learning)이라고 한다. 그리고, 딥러닝을 위해 사용하는 충분히 깊은 인공 신경망을 심층 신경망 (DNN: Deep neural network)이라 통칭한다. 다층 퍼셉트론에서, 입력층에 존재하는 노드들은 매개 변수(parameter)와 활성 함수(activation function)를 사용하지 않은 반면, 은닉층 및 출력층에 존재하는 노드들은 매개 변수와 활성 함수를 사용한다. 여기서, 상기 매개 변수는 학습 과정을 통해 자동으로 가변되는 값으로서 가중치(weight)와 편향 (bias)을 포함할 수 있다. 가중치는 입력 신호가 결과 출력에 주는 영향도를 조절하는 매개변수이고, 편향은 노 드(또는 뉴런)가 얼마나 쉽게 활성화(activation)되느냐를 조정하는 매개변수이다. 활성 함수는 어떠한 신호를입력 받아 이를 적절히 처리하여 출력해주는 함수를 의미한다. 상기 활성 함수로는 시그모이드(sigmoid) 함수, ReLU(Rectified Linear Unit) 함수, 소프트맥스(softmax) 함수, 항등(identity) 함수 등이 사용될 수 있으며 반드시 이에 제한되지는 않는다. 다층 퍼셉트론은 각 층의 노드들(또는 뉴런들, nodes) 간에 2차원적으로 연결되는 완전 연결 구조(fully- connected structure)를 갖는다. 이때, 상기 완전 연결 구조는 서로 같은 층에 위치한 노드들 간에는 연결 관계 가 존재하지 않으며, 바로 인접한 층에 위치한 노드들 간에만 연결 관계가 존재하는 구조이다. 이와 같은 다층 퍼셉트론의 학습 동작을 간단히 설명하면 다음과 같다. 먼저, 각 층에서의 매개 변수인 가 중치(weight)와 편향(bias)의 초기값을 설정한다. 이후, 하나의 학습(훈련) 데이터에 대해 각 층에서의 순입력 함수값을 계산하고 최종적으로 활성 함수(activation function)에 의한 출력값(즉, 결과값)을 계산한다. 여기서, 상기 순입력 함수값은 각 노드의 활성 함수에 입력되는 값을 의미한다. 그 다음, 출력층의 활성 함수에 의한 출력값과 실제값의 차이가 허용 오차 이내가 되도록 각 층에서의 가중치 및 편향을 업데이트한다. 마지막 으로, 모든 학습 데이터에 대해서 출력층의 활성 함수에 의한 출력값과 실제값의 차이가 허용 오차 이내가 되면 학습을 종료한다. 즉, 도 2에 도시된 바와 같이, 다층 퍼셉트론의 학습 과정은 순전파(feedforward, FF)와 역전파 (backpropagation, BP)의 반복 과정으로 정의될 수 있다. 이러한 반복 과정은 출력층에서의 오차가 0에 가 까워질 때까지 계속될 수 있다. 순전파(FF) 과정은 입력층에서 출력층 방향으로 이동하면서 각 입력에 해당하는 가중치(w)가 곱해지 고, 결과적으로 가중치 합으로 계산되어 각 층의 활성 함수로 입력되며, 최종적으로 출력층의 활성 함수에 서 결과값이 출력되는 일련의 학습 과정을 일컫는다. 역전파(BP) 과정은 출력층에서 입력층 방향으로 이동하면서 순전파 과정에서 발생한 오차(Error)를 줄이기 위해 각 층의 가중치 및 편향을 업데이트하는 일련의 학습 과정을 일컫는다. 상기 역전파(BP) 과정에서 가중치를 결정하는 방법으로 경사 하강법(Gradient Descent)이 사용될 수 있다. 경사 하강법은 손실 함수(loss function)의 최저 지점을 찾아가는 최적화 기법으로서, 상기 손실 함수의 기울기 를 구하여 기울기가 낮은 쪽으로 계속 이동시켜서 최저 지점에 이를 때까지 계속 반복하는 기법이다. 여기서, 상기 손실 함수는 출력층에서 계산한 결과값과 실제값과의 차이(즉, 오차)를 정의한 함수이다. 상기 손실 함수로는 평균 제곱 오차(Mean Squared Error, MSE) 또는 교차 엔트로피 오차(Cross Entropy Error, CEE)가 사 용될 수 있으며 반드시 이에 제한되지는 않는다. 도 3은 본 발명의 일 실시 예에 따른 적대적 공격 방어 장치의 구성을 나타내는 구성 블록도이다. 도 3을 참조하면, 본 발명의 일 실시 예에 따른 적대적 공격 방어 장치는 데이터 전처리부, 학습모델 선정부, 순전파 처리부, 역전파 처리부, 중요노드 검출부, 암호화 처리부, 위치정보 검출부 및 학습모델 검증부를 포함할 수 있다. 도 3에 도시된 구성요소들은 적대적 공격 방어 장치 를 구현하는데 있어서 필수적인 것은 아니어서, 본 명세서 상에서 설명되는 적대적 공격 방어 장치는 위에 서 열거된 구성요소들 보다 많거나, 또는 적은 구성요소들을 가질 수 있다. 데이터 전처리부는 데이터베이스(미도시)에 수집된 원천 데이터(raw data)를 딥러닝 알고리즘에 적합한 학 습 데이터로 변환하는 전 처리 동작을 수행할 수 있다. 이하 본 실시 예에서, 상기 학습 데이터는 바이오 인증 (biometrics)과 관련된 데이터임을 예시하여 설명하도록 한다. 데이터 전처리부는 전 처리된 학습 데이터를 훈련 데이터 셋(training data set)과 시험 데이터 셋(test data set)으로 분류할 수 있다. 여기서, 상기 훈련 데이터 셋은 딥러닝 모델을 학습하기 위해 제공되는 데이터 셋이고, 시험 데이터 셋은 학습된 딥러닝 모델의 성능을 검증하기 위해 제공되는 데이터 셋이다. 학습모델 선정부는 학습 데이터에 적합한 딥러닝 모델을 선택하는 동작을 수행할 수 있다. 본 실시 예에서, 상기 딥러닝 모델은 다층 퍼셉트론을 이용한 심층 신경망(DNN) 모델일 수 있다. 학습모델 선정부는 딥러닝 모델에 사용할 최적의 딥러닝 알고리즘을 선택할 수 있다. 또한, 학습모델 선정 부는 딥러닝 알고리즘의 하이퍼파라미터(Hyper-parameter)를 설정할 수 있다. 여기서, 상기 하이퍼파라미 터는 개발자에 의해 설정되는 값으로서, 학습 횟수, 학습률(learning rate), 은닉층의 개수, 노드의 개수, 미니배치(mini-batch)의 크기, 에포크(epoch) 등을 포함할 수 있다. 순전파 처리부는 딥러닝 모델(즉, 심층 신경망 모델)의 학습 과정 중 순전파 과정을 처리하는 동작을 수행 할 수 있다. 즉, 순전파 처리부는 입력층에서 출력층 방향으로 이동하면서 각 입력에 해당하는 가중치(w)가 곱해지고, 결과적으로 가중치 합으로 계산되어 각 층의 활성 함수로 입력되며, 최종적으로 출력층 의 활성 함수를 통해 결과값이 출력되는 일련의 학습 과정을 순차적으로 수행할 수 있다. 상기 순전파 처 리부는 순전파 과정을 통해 생성되는 데이터를 메모리 또는 데이터베이스에 저장할 수 있다. 역전파 처리부는 딥러닝 모델(즉, 심층 신경망 모델)의 학습 과정 중 역전파 과정을 처리하는 동작을 수행 할 수 있다. 즉, 역전파 처리부는 출력층에서 입력층 방향으로 이동하면서 순전파 과정에서 발 생한 오차(Error)를 줄이기 위해 각 층의 가중치 및 편향을 업데이트하는 일련의 학습 과정을 순차적으로 수행 할 수 있다. 상기 역전파 처리부는 역전파 과정을 통해 생성되는 데이터를 메모리 또는 데이터베이스에 저 장할 수 있다. 역전파 처리부는 경사 하강법(Gradient Descent)을 이용하여 각 층의 가중치 및 편향을 업데이트할 수 있 다. 이때, 새로운 가중치(W')는 아래 수학식 1과 같이 계산될 수 있고, 새로운 편향(B')은 아래 수학식 2와 같 이 계산될 수 있다. 수학식 1"}
{"patent_id": "10-2020-0106172", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "수학식 2"}
{"patent_id": "10-2020-0106172", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "여기서, α는 학습률(learning rate), Etotal은 순전파 과정에서 발생한 전체 오차값, 는 가중치 기울 기(weight gradient), 는 편향 기울기(bias gradient)임. 중요노드 검출부는 순전파(FF) 과정을 통해 계산된 출력층의 예측 정확도가 미리 결정된 제1 임계치 (가령, 70%) 이상인지 여부를 확인할 수 있다. 상기 확인 결과, 출력층의 예측 정확도가 제1 임계치 이상 인 경우, 중요노드 검출부는 은닉층에 존재하는 노드들의 가중치 값(weight value)에 관한 히스토리 (history) 정보를 분석하여 하나 이상의 중요 노드를 검출할 수 있다. 이때, 상기 중요노드 검출부는 가중 치 값의 변경 빈도(또는 변경 횟수)를 기반으로 은닉층에 존재하는 중요 노드들을 검출할 수 있다. 이는 가중치 값이 자주 변경되는 노드일수록 학습 과정에서 중요한 노드로 작용하기 때문이다. 암호화 처리부는, 역전파(BP) 과정 수행 시, 은닉층에 존재하는 중요 노드들의 가중치 값에 대해 동 형암호화(Homomorphic Encryption)를 수행할 수 있다. 여기서, 동형암호화란 정보를 암호화한 상태에서 각종 연 산을 했을 때, 그 결과가 암호화하지 않은 상태의 연산 결과와 동일하게 나오는 4세대 암호 체계를 의미한다. 마치 책을 펴지 않은 상태에서 책에서 가장 많이 나온 단어가 무엇인지, 주인공이 누구인지 맞히는 것과 비슷하 다. 동형암호화는 암호문을 복호화하지 않아도 검색, 통계 처리 및 기계 학습이 가능하고, 데이터를 처리하는 중간 과정에서 복호화하지 않아도 되므로, 데이터 유출 위험이 감소하는 장점이 있다. 따라서, 은닉층에 존재하 는 중요 노드들의 가중치 값에 동형암호화를 사용하는 경우, 역전파 과정에서의 암호화 처리 속도를 증가시킬 수 있고, 해커 등이 암호화된 가중치를 복호화하여 적대적 공격을 시도하는 것을 미연에 차단할 수 있다.위치정보 검출부는, 은닉층의 중요 노드 검출 시, 입력층의 입력 데이터(가령, 바이오 인증 데 이터)와 관련된 객체의 위치정보를 검출할 수 있다. 상기 위치정보 검출부는 Word2Vec 알고리즘을 이용하 여 객체의 위치정보에 해당하는 문자를 벡터 값으로 변환할 수 있다. 상기 위치정보 검출부는 변환된 벡터 값을 포함하는 노드를 생성하여 출력층에 추가할 수 있다. 상기 출력층에 추가된 노드의 벡터 값은, 역전파(BP) 과정 수행 시, 은닉층에 존재하는 중요 노드들의 입력 값으로 사용될 수 있다. 이는 객체의 위 치정보(즉, 주변 환경)에 따라 바이오 인증 데이터의 특징(feature) 패턴이 달라지기 때문이다. 학습모델 검증부는 훈련 데이터 셋으로 학습된 딥러닝 모델의 성능을 검증하는 동작을 수행할 수 있다. 이 때, 상기 학습모델 검증부는 시험 데이터 셋을 이용하여 딥러닝 모델의 성능을 검증할 수 있다. 도 4는 본 발명의 일 실시 예에 따른 적대적 공격 방어 방법을 설명하는 순서도이다. 도 4를 참조하면, 본 발명에 따른 적대적 공격 방어 장치는 데이터베이스에 수집된 원천 데이터(raw dat a)를 딥러닝 알고리즘에 적합한 학습 데이터로 변환하는 데이터 전처리 동작을 수행할 수 있다(S405). 그리고, 적대적 공격 방어 장치는 전 처리된 학습 데이터를 훈련 데이터 셋(training data set)과 시험 데이터 셋 (test data set)으로 분류할 수 있다. 적대적 공격 방어 장치는 학습 데이터에 적합한 딥러닝 모델과, 상기 딥러닝 모델에 사용할 최적의 딥러닝 알고리즘을 선택할 수 있다(S410). 또한, 적대적 공격 방어 장치는 개발자의 설정 명령에 따라 딥러닝 알 고리즘의 하이퍼파라미터(Hyper-parameter)를 설정할 수 있다. 적대적 공격 방어 장치는 상기 선택된 딥러닝 모델에 훈련 데이터 셋을 입력할 수 있다(S415). 이때, 상기 적대적 공격 방어 장치는 전체 훈련 데이터 셋을 딥러닝 모델에 입력하는 배치(batch) 방식을 사용할 수 있다. 또는, 상기 적대적 공격 방어 장치는 전체 훈련 데이터 셋을 미리 결정된 집합 단위로 분할한 후 딥 러닝 모델에 순차적으로 입력하는 미니 배치(mini-batch) 방식을 사용할 수 있다. 적대적 공격 방어 장치는 훈련 데이터 셋을 기반으로 딥러닝 모델(즉, 심층 신경망 모델)의 학습 과정, 즉 순전파(FF)와 역전파(BP)의 반복 과정을 수행할 수 있다(S420). 좀 더 구체적으로, 적대적 공격 방어 장치는 심층 신경망 모델의 입력층에서 출력층 방향으로 이동하면서 각 입력에 해당하는 가중치(w)가 곱해지고, 결과적으로 가중치 합으로 계산되어 각 층의 활성 함수 로 입력되며, 최종적으로 출력층의 활성 함수를 통해 결과값이 출력되는 순전파 과정을 수행할 수 있다. 적대적 공격 방어 장치는 순전파 과정을 통해 출력층의 결과값과 실제값 사이의 오차를 계산할 수 있 다. 이때, 상기 적대적 공격 방어 장치는 평균 제곱 오차(MSE) 또는 교차 엔트로피 오차(CEE)와 같은 손실 함수를 이용하여 오차를 계산할 수 있다. 적대적 공격 방어 장치는 심층 신경망 모델의 출력층에서 입력층 방향으로 이동하면서 순전파 과정에서 발생한 오차(Error)를 줄이기 위해 각 층의 가중치 및 편향을 업데이트하는 역전파 과정을 수행할 수 있다. 이때, 상기 적대적 공격 방어 장치는 경사 하강법(Gradient Descent)을 이용하여 각 층의 가중치 및 편향을 업데이트할 수 있다. 적대적 공격 방어 장치는 상술한 순전파 과정을 통해 출력층의 예측 정확도를 산출하고, 상기 산출된 예측 정확도가 미리 결정된 제1 임계치(가령, 70%) 이상인지 여부를 확인할 수 있다(S425). 여기서, 상기 예측 정확도는 출력층의 오차 정보를 기반으로 계산될 수 있다. 상기 확인 결과, 출력층의 예측 정확도가 제1 임계치 미만인 경우, 적대적 공격 방어 장치는 상술한 420 단계로 이동하여 순전파(FF) 및 역전파(BP) 과정을 반복하여 수행할 수 있다. 한편, 상기 확인 결과, 출력층의 예측 정확도가 제1 임계치 이상인 경우, 적대적 공격 방어 장치는, 역전파(BP) 과정 수행 시, 은닉층에 존재하는 노드들의 가중치 값(weight value)에 관한 히스토리 정보를 분석하여 하나 이상의 중요 노드를 검출할 수 있다(S430). 가령, 도 5에 도시된 바와 같이, 적대적 공격 방어 장치는, 역전파(BP) 과정 수행 시, 은닉층에 존재 하는 노드들의 가중치 변경 빈도(또는 가중치 변경 횟수)를 기반으로 상기 은닉층에 존재하는 중요 노드들 을 검출할 수 있다. 적대적 공격 방어 장치는, 역전파(BP) 과정 수행 시, 은닉층에 존재하는 중요 노드들의 가중치 값에 대해 동형암호화(Homomorphic Encryption)를 수행할 수 있다(S435). 한편, 다른 실시 예로, 적대적 공격 방어장치는 중요 노드들의 가중치 값과 함께 편향(bias) 값 및/또는 기울기(gradient) 값에 대해서도 동형암호 화를 수행할 수 있다. 이에 따라, 적대적 공격 방어 장치는 심층 신경망 모델을 이용하는 AI 애플리케이션 에 대한 적대적 공격을 사전에 차단할 수 있다. 가령, 중요 노드의 가중치 값이 8 + 10 = 18인 경우, 적대적 공격 방어 장치는 원본 데이터 8을 동형암호 화하여 제1 암호 데이터 (0, 1)를 생성할 수 있고, 원본 데이터 10을 동형암호화하여 제2 암호 데이터 (2, 3)를 생성할 수 있다. 여기서, 제1 암호 데이터 (0, 1)는 원본 데이터 8을 4와 7로 나눈 나머지이고, 제2 암호 데이 터 (2, 3)는 원본 데이터 10을 4와 7로 나눈 나머지이다. 동형암호화는 원본 데이터의 연산 결과와 암호화된 데이터의 연산 결과가 서로 동일하다. 따라서, 제1 및 제2 암호 데이터를 기초로 중요 노드의 가중치 값을 동형복호화하는 방법은 다음과 같다. 먼저, 원본 데이터를 나눈 숫자, 즉 4와 7을 알고 있다면, 제1 및 제2 암호 데이터를 복호화할 필요없이, 제1 암호 데이터 (0, 1)와 제2 암호 데이터 (2, 3)를 서로 합산한다. 그리고, 제1 및 제2 암호 데이터를 합산한 값인 (2, 4)를 기반으로 중요 노드의 가중치 값 18을 획득할 수 있다. 즉, 4로 나눈 나머지가 2이고, 7로 나눈 나머지가 4인 숫자는 18이다. 적대적 공격 방어 장치는, 은닉층의 중요 노드 검출 시, 입력층의 입력 데이터(가령, 바이오 인 증 데이터)와 관련된 객체의 위치정보를 검출할 수 있다(S440). 가령, 도 6에 도시된 바와 같이, 적대적 공격 방어 장치는 GPS 장치(미도시)와 연동하여 객체의 좌표 정보(즉, 위도/경도 정보)를 검출하고, 상기 검출 된 좌표 정보를 정밀 지도 상에 맵핑하여 해당 객체의 위치 정보를 검출할 수 있다. 적대적 공격 방어 장치는 미리 결정된 알고리즘(가령, Word2Vec 알고리즘)을 이용하여 상기 검출된 객체의 위치정보를 벡터 값으로 변환할 수 있다. 그리고, 적대적 공격 방어 장치는 변환된 벡터 값을 포함하는 노 드를 생성하여 출력층에 추가할 수 있다. 가령, 도 7에 도시된 바와 같이, 적대적 공격 방어 장치는 객체의 위치정보에 해당하는 벡터 값을 포함하는 노드를 출력층에 추가할 수 있다. 상기 출력층(13 0)에 추가된 노드의 벡터 값은, 역전파 과정 수행 시, 은닉층에 존재하는 중요 노드들의 입력 값으로 사용될 수 있다. 적대적 공격 방어 장치는, 역전파(BP) 과정 수행 시, 객체의 위치정보를 딥러닝 모델에 추가함으로써, 해 당 딥러닝 모델의 성능을 향상시킬 수 있다. 또한, 적대적 공격 방어 장치는 객체의 위치정보를 딥러닝 모 델에 추가함으로써, 적대적 공격으로부터 용이하게 회피할 수 있다. 이는 해커 입장에서는 객체의 위치정보가 딥러닝 모델에 추가된 사실을 인지할 수 없기 때문에, 해당 모델의 매개변수를 유추하는 것이 어려워지기 때문 이다. 한편, 상술한 440 단계는 본 발명의 실시 형태에 따라 생략 가능하도록 구성될 수 있다. 이후, 적대적 공격 방어 장치는 은닉층에 존재하는 중요 노드들에 대해서만 학습 과정, 즉 순전파 (FF)와 역전파(BP)의 반복 과정을 수행할 수 있다(S445). 적대적 공격 방어 장치는 순전파 과정을 통해 획득한 출력층의 예측 정확도가 미리 결정된 제2 임계 치(가령, 95%) 이상인지 여부를 확인할 수 있다(S450). 상기 확인 결과, 출력층의 예측 정확도가 제2 임계치 미만인 경우, 적대적 공격 방어 장치는 상술한 445 단계로 이동하여 중요 노드들에 대한 학습 과정을 반복하여 수행할 수 있다. 한편, 상기 확인 결과, 출력층의 예측 정확도가 제2 임계치 이상인 경우, 적대적 공격 방어 장치는 딥러닝 모델의 학습 과정을 종료할 수 있다(S455). 이후, 적대적 공격 방어 장치는 시험 데이터 셋을 이용 하여 딥러닝 모델의 성능을 검증할 수 있다. 이상 상술한 바와 같이, 본 발명의 일 실시 예에 따른 적대적 공격 방어 방법은 딥러닝 모델의 은닉층에 존재하 는 중요 노드들을 검출하고 해당 노드들의 가중치를 동형암호화함으로써, 해당 모델을 이용하는 AI 애플리케이 션에 대한 적대적 공격을 효과적으로 방어할 수 있다. 또한, 상기 적대적 공격 방어 방법은, 은닉층의 중요 노 드 검출 시, 입력 데이터(즉, 바이오 인증 데이터)와 관련된 객체의 위치정보를 딥러닝 모델에 추가함으로써, 해당 모델의 성능을 개선할 수 있을 뿐만 아니라 적대적 공격에 대한 회피 능력을 향상시킬 수 있다. 도 8은 본 발명의 일 실시 예에 따른 컴퓨팅 장치의 구성 블록도이다. 도 8을 참조하면, 본 발명의 일 실시 예에 따른 컴퓨팅 장치는 적어도 하나의 프로세서, 컴퓨터 판독 가능 저장 매체 및 통신 버스를 포함한다. 상기 컴퓨팅 장치는 상술한 적대적 공격 방어 장치 또는 상기 적대적 공격 방어 장치를 구성하는 데이터 전처리부, 학습모델 선정부, 순전파 처리부, 역전파 처리부, 중요노드 검출부, 암호화 처리부, 위치정보 검출부 및 학습모델 검증부에 포함되는 하나 이상의 컴포넌트일 수 있다. 프로세서는 컴퓨팅 장치로 하여금 앞서 언급된 예시적인 실시 예에 따라 동작하도록 할 수 있다. 예 컨대, 프로세서는 컴퓨터 판독 가능 저장 매체에 저장된 하나 이상의 프로그램들을 실행할 수 있다. 상기 하나 이상의 프로그램들은 하나 이상의 컴퓨터 실행 가능 명령어를 포함할 수 있으며, 상기 컴퓨터 실행 가능 명령어는 프로세서에 의해 실행되는 경우 컴퓨팅 장치로 하여금 예시적인 실시 예에 따른 동작들을 수행하도록 구성될 수 있다. 컴퓨터 판독 가능 저장 매체는 컴퓨터 실행 가능 명령어 내지 프로그램 코드, 프로그램 데이터 및/또는 다 른 적합한 형태의 정보를 저장하도록 구성된다. 컴퓨터 판독 가능 저장 매체에 저장된 프로그램은 프 로세서에 의해 실행 가능한 명령어의 집합을 포함한다. 일 실시 예에서, 컴퓨터 판독 가능 저장 매체(82 0)는 메모리(랜덤 액세스 메모리와 같은 휘발성 메모리, 비휘발성 메모리, 또는 이들의 적절한 조합), 하나 이 상의 자기 디스크 저장 디바이스들, 광학 디스크 저장 디바이스들, 플래시 메모리 디바이스들, 그 밖에 컴퓨팅 장치에 의해 액세스되고 원하는 정보를 저장할 수 있는 다른 형태의 저장 매체, 또는 이들의 적합한 조합 일 수 있다. 통신 버스는 프로세서, 컴퓨터 판독 가능 저장 매체를 포함하여 컴퓨팅 장치의 다른 다양 한 컴포넌트들을 상호 연결한다. 컴퓨팅 장치는 또한 하나 이상의 입출력 장치를 위한 인터페이스를 제공하는 하나 이상의 입출력 인 터페이스 및 하나 이상의 네트워크 통신 인터페이스를 포함할 수 있다. 입출력 인터페이스 및 네트워크 통신 인터페이스는 통신 버스에 연결된다. 입출력 장치는 입출력 인터페이스를 통해 컴퓨팅 장치의 다른 컴포넌트들에 연결될 수 있다. 예 시적인 입출력 장치는 포인팅 장치(마우스 또는 트랙패드 등), 키보드, 터치 입력 장치(터치패드 또는 터 치스크린 등), 음성 또는 소리 입력 장치, 다양한 종류의 센서 장치 및/또는 촬영 장치와 같은 입력 장치, 및/ 또는 디스플레이 장치, 프린터, 스피커 및/또는 네트워크 카드와 같은 출력 장치를 포함할 수 있다. 예시적인 입출력 장치는 컴퓨팅 장치를 구성하는 일 컴포넌트로서 컴퓨팅 장치의 내부에 포함될 수도 있 고, 컴퓨팅 장치와는 구별되는 별개의 장치로 컴퓨팅 장치와 연결될 수도 있다. 전술한 본 발명은, 프로그램이 기록된 매체에 컴퓨터가 읽을 수 있는 코드로서 구현하는 것이 가능하다. 컴퓨터 가 읽을 수 있는 매체는, 컴퓨터로 실행 가능한 프로그램을 계속 저장하거나, 실행 또는 다운로드를 위해 임시 저장하는 것일 수도 있다. 또한, 매체는 단일 또는 수개 하드웨어가 결합된 형태의 다양한 기록수단 또는 저장 수단일 수 있는데, 어떤 컴퓨터 시스템에 직접 접속되는 매체에 한정되지 않고, 네트워크 상에 분산 존재하는 것일 수도 있다. 매체의 예시로는, 하드 디스크, 플로피 디스크 및 자기 테이프와 같은 자기 매체, CD-ROM 및 DVD와 같은 광기록 매체, 플롭티컬 디스크(floptical disk)와 같은 자기-광 매체(magneto-optical medium), 및 ROM, RAM, 플래시 메모리 등을 포함하여 프로그램 명령어가 저장되도록 구성된 것이 있을 수 있다. 또한, 다른 매체의 예시로, 애플리케이션을 유통하는 앱 스토어나 기타 다양한 소프트웨어를 공급 내지 유통하는 사이트, 서버 등에서 관리하는 기록매체 내지 저장매체도 들 수 있다. 따라서, 상기의 상세한 설명은 모든 면에서 제한 적으로 해석되어서는 아니되고 예시적인 것으로 고려되어야 한다. 본 발명의 범위는 첨부된 청구항의 합리적 해 석에 의해 결정되어야 하고, 본 발명의 등가적 범위 내에서의 모든 변경은 본 발명의 범위에 포함된다."}
{"patent_id": "10-2020-0106172", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명과 관련된 다층 퍼셉트론의 구조를 나타내는 도면; 도 2는 도 1에 도시된 다층 퍼셉트론의 학습 과정을 설명하기 위해 참조되는 도면;도 3은 본 발명의 일 실시 예에 따른 적대적 공격 방어 장치의 구성을 나타내는 구성 블록도; 도 4는 본 발명의 일 실시 예에 따른 적대적 공격 방어 방법을 설명하는 순서도; 도 5 내지 도 7은 본 발명의 일 실시 예에 따른 적대적 공격 방어 방법을 설명하기 위해 참조되는 도면; 도 8은 본 발명의 일 실시 예에 따른 컴퓨팅 장치의 구성 블록도."}
