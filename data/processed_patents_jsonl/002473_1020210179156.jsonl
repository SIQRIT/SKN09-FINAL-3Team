{"patent_id": "10-2021-0179156", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0052169", "출원번호": "10-2021-0179156", "발명의 명칭": "SHAP 기반 이미지 어노테이션 생성 장치 및 방법", "출원인": "경기대학교 산학협력단", "발명자": "김용수"}}
{"patent_id": "10-2021-0179156", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "동일한 부품에 대하여 결함이 있는 결함 이미지 데이터와 결함이 없는 정상 이미지 데이터로부터 결함에 대한특징을 추출하도록 학습된 제1 딥러닝 모델을 이용하여 입력된 부품 이미지에 대하여 결함에 대한 특징을 추출하여 출력하는 특징 추출부;부품 이미지에 대한 결함에 대한 특징을 군집 분석하여 유사한 유형별로 군집화하도록 학습된 군집 모델을 이용하여 특징 추출부가 출력한 결함에 대한 특징의 군집 결과에 기초하여 결함 유형에 대한 레이블을 산출하고 입력된 부품 이미지에 레이블링하는 유형 레이블 산출부;부품 이미지에 대하여 결함 유형으로 분류하도록 학습된 제2 딥러닝 모델을 포함하여 유형 레이블 산출부에 의해 결함 유형으로 레이블링된 이미지를 결함 유형으로 분류하며 SHAP(Shapley additive explanations)을 적용하여 분류 결과를 도출하는데 기여한 결함 부위에 대한 위치 정보를 포함하는 수퍼픽셀을 도출하는 수퍼픽셀 도출부; 및수퍼픽셀에 대하여 미리 정의된 이미지 좌표계 상의 좌표들을 구하여 결함 부위에 대한 바운딩 박스를 도출하고산출된 결함 유형에 대한 레이블과 결합하여 어노테이션 정보를 생성하는 어노테이션 생성부;를 포함하는 SHAP 기반 이미지 어노테이션 생성 장치."}
{"patent_id": "10-2021-0179156", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1 항에 있어서, 제1 딥러닝 모델은 컨볼루션 신경망(CNN)을 기반으로 하여 입력된 부품 이미지에 대하여 결함에 대한 특징을 추출하는 SHAP 기반 이미지 어노테이션 생성 장치."}
{"patent_id": "10-2021-0179156", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 2 항에 있어서,컨볼루션 신경망은 VggNet 구조, MobileNet 구조, 인셉션(Inception) 구조 중 어느 하나의 구조를 갖는 SHAP기반 이미지 어노테이션 생성 장치."}
{"patent_id": "10-2021-0179156", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 1 항에 있어서, 군집 모델은 K-평균 군집분석 모델, 가우시안 혼합 모델(GMM) 중 어느 하나의 모델인 SHAP 기반 이미지 어노테이션 생성 장치."}
{"patent_id": "10-2021-0179156", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제 1 항에 있어서, 제2 딥러닝 모델은 컨볼루션 신경망(CNN)을 기반으로 하여 결함 유형으로 레이블링된 이미지를 결함 유형으로분류하는 SHAP 기반 이미지 어노테이션 생성 장치.공개특허 10-2023-0052169-3-청구항 6 제 5 항에 있어서,컨볼루션 신경망은 VggNet 구조, MobileNet 구조, 인셉션(Inception) 구조 중 어느 하나의 구조를 갖는 SHAP기반 이미지 어노테이션 생성 장치."}
{"patent_id": "10-2021-0179156", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제 1 항에 있어서, 제2 딥러닝 모델은 결함이 없는 정상 유형을 포함하는 군집 유형으로 결함 유형을 다중 분류하는 분류 모델인SHAP 기반 이미지 어노테이션 생성 장치."}
{"patent_id": "10-2021-0179156", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제 1 항에 있어서,제2 딥러닝 모델은 설정된 특정 군집 유형으로 결함 유형을 이진 분류하는 분류 모델인 SHAP 기반 이미지 어노테이션 생성 장치."}
{"patent_id": "10-2021-0179156", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "각 단계가 컴퓨팅 장치의 프로세서에서 실행되는 프로그램 명령어로 구현되어 프로세서에서 실행되는 SHAP 기반이미지 어노테이션 생성 방법에 있어서,동일한 부품에 대하여 결함이 있는 결함 이미지 데이터와 결함이 없는 정상 이미지 데이터로부터 결함에 대한특징을 추출하도록 학습된 제1 딥러닝 모델을 이용하여 입력된 부품 이미지에 대하여 결함에 대한 특징을 추출하여 출력하는 특징 추출 단계;부품 이미지에 대한 결함에 대한 특징을 군집 분석하여 유사한 유형별로 군집화하도록 학습된 군집 모델을 이용하여 특징 추출 단계에서 출력된 결함에 대한 특징의 군집 결과에 기초하여 결함 유형에 대한 레이블을 산출하고 입력된 부품 이미지에 레이블링하는 유형 레이블 산출 단계;부품 이미지에 대하여 결함 유형으로 분류하도록 학습된 제2 딥러닝 모델을 포함하여 유형 레이블 산출부에 의해 결함 유형으로 레이블링된 이미지를 결함 유형으로 분류하며 SHAP(Shapley additive explanations)을 적용하여 분류 결과를 도출하는데 기여한 결함 부위에 대한 위치 정보를 포함하는 수퍼픽셀을 도출하는 수퍼픽셀 도출단계; 및수퍼픽셀에 대하여 미리 정의된 이미지 좌표계 상의 좌표들을 구하여 결함 부위에 대한 바운딩 박스를 도출하고산출된 결함 유형에 대한 레이블과 결합하여 어노테이션 정보를 생성하는 어노테이션 생성 단계;를 포함하는 SHAP 기반 이미지 어노테이션 생성 방법."}
{"patent_id": "10-2021-0179156", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제 9 항에 있어서, 제1 딥러닝 모델은 컨볼루션 신경망(CNN)을 기반으로 하여 입력된 부품 이미지에 대하여 결함에 대한 특징을 추출하는 SHAP 기반 이미지 어노테이션 생성 방법."}
{"patent_id": "10-2021-0179156", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "공개특허 10-2023-0052169-4-제 10 항에 있어서,컨볼루션 신경망은 VggNet 구조, MobileNet 구조, 인셉션(Inception) 구조 중 어느 하나의 구조를 갖는 SHAP기반 이미지 어노테이션 생성 방법."}
{"patent_id": "10-2021-0179156", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제 9 항에 있어서, 군집 모델은 K-평균 군집분석 모델, 가우시안 혼합 모델(GMM) 중 어느 하나의 모델인 SHAP 기반 이미지 어노테이션 생성 방법."}
{"patent_id": "10-2021-0179156", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제 9 항에 있어서, 제2 딥러닝 모델은 컨볼루션 신경망(CNN)을 기반으로 하여 결함 유형으로 레이블링된 이미지를 결함 유형으로분류하는 SHAP 기반 이미지 어노테이션 생성 방법."}
{"patent_id": "10-2021-0179156", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제 13 항에 있어서,컨볼루션 신경망은 VggNet 구조, MobileNet 구조, 인셉션(Inception) 구조 중 어느 하나의 구조를 갖는 SHAP기반 이미지 어노테이션 생성 방법."}
{"patent_id": "10-2021-0179156", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제 9 항에 있어서, 제2 딥러닝 모델은 결함이 없는 정상 유형을 포함하는 군집 유형으로 결함 유형을 다중 분류하는 분류 모델인SHAP 기반 이미지 어노테이션 생성 방법."}
{"patent_id": "10-2021-0179156", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제 9 항에 있어서,제2 딥러닝 모델은 설정된 특정 군집 유형으로 결함 유형을 이진 분류하는 분류 모델인 SHAP 기반 이미지 어노테이션 생성 방법."}
{"patent_id": "10-2021-0179156", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명의 SHAP 기반 이미지 어노테이션 생성 장치는 부품 이미지로부터 추출된 결함에 대한 특징을 군집 분석하 여 결함 유형에 대한 레이블을 산출하고 결함 유형이 레이블링된 이미지를 분류하며 SHAP을 적용하여 분류 결과 를 도출한 특징에 대한 수퍼픽셀을 도출한 후 수퍼픽셀의 위치정보를 기반으로 바운딩 박스를 산출하고 산출된 결함 유형에 대한 레이블과 결합하여 이미지에 대한 어노테이션 정보를 생성한다."}
{"patent_id": "10-2021-0179156", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 인공지능 학습 데이터 생성 기술에 관한 것으로, 더욱 상세하게는 설명 가능한 인공지능 기법 중 하 나인 SHAP를 이용하여 이미지 내 결함을 검출하는 컴퓨터 비전 기술 학습을 위한 이미지 어노테이션을 자동으로 생성하는 기술에 관한 것이다."}
{"patent_id": "10-2021-0179156", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "인공지능 기술인 딥러닝이 적용된 컴퓨터 비전 기술이 제조업에 접목되어 제조 공정에서 불량 판정, 결함 검출 등 다양한 검사과정에 사용되고 있다. 딥러닝이 적용된 컴퓨터 비전을 수행하기 위해서는 확보된 이미지 및 영상 데이터를 학습이 가능한 형태로 전처 리하는 이미지 어노테이션 작업이 필요하며, 이를 통해 이미지에서 분석이 필요한 결함 영역에 대한 정보를 수 집할 수 있다. 어노테이션 기법 중 이미지 또는 영상 데이터에 대하여 사각형 틀을 그린 바운딩 박스(Bounding Box)가 있으며, 결함 영역에 대하여 바운딩 박스로 어노테이션을 생성할 수 있다. 종래에는 사람이 직접 수동으로 이미지 내의 결함 영역에 대하여 바운딩 박스를 작성하여 어노테이션을 생성하였으며 결함 유형 또한 사람이 직접 판단하여 레이블링 작업을 수행하였다. 이러한 사람에 의한 어노테이션 작업은 소요되는 시간이 많이 요구되며 비용 또한 매우 높은 문제가 있다. 또한, 어노테이션 작업의 품질이 작업자의 숙련도에 따라 상이할 수 있다는 한계가 있 다. 이러한 문제점을 해결하기 위하여 자동으로 이미지 어노테이션을 생성하는 방법과 관련하여 연구가 활발히 진행 되고 있다. 하지만, 이러한 연구들은 결함에 대한 특징 및 정보를 수집하기 위하여 사전에 사람에 의한 전처리 작업이 요구되며, 이를 기반으로 자동으로 어노테이션 작업이 수행되는 한계를 가지고 있다. 또한, 종래의 자동 어노테이션 방법은 결함 유형에 대한 레이블링 작업만 가능하고 이미지 내 결함에 대한 위치 정보 수집이 어렵 다는 한계를 가지고 있다."}
{"patent_id": "10-2021-0179156", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 사람이 직접 이미지 어노테이션 정보를 생성하는 대신 특정 부품에 대하여 수집된 이미지들을 처리하 여 결함에 대한 유형 및 위치 정보가 포함된 이미지 어노테이션 정보를 자동으로 생성하여 제공하는 것을 목적 으로 한다."}
{"patent_id": "10-2021-0179156", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 일 양상에 따르는 SHAP 기반 이미지 어노테이션 생성 장치는 특징 추출부와, 유형 레이블 산출부와, 수퍼픽셀 도출부와, 어노테이션 생성부를 포함한다. 특징 추출부는 동일한 부품에 대하여 결함이 있는 결함 이미지 데이터와 결함이 없는 정상 이미지 데이터로부터 결함에 대한 특징을 추출하도록 학습된 제1 딥러닝 모델을 이용하여 입력된 부품 이미지에 대하여 결함에 대한 특징을 추출하여 출력한다. 유형 레이블 산출부는 부품 이미지에 대한 결함에 대한 특징을 군집 분석하여 유사한 유형별로 군집화하도록 학 습된 군집 모델을 이용하여 특징 추출부가 출력한 결함에 대한 특징의 군집 결과에 기초하여 결함 유형에 대한 레이블을 산출하고 입력된 부품 이미지에 레이블링한다. 수퍼픽셀 도출부는 부품 이미지에 대하여 결함 유형으로 분류하도록 학습된 제2 딥러닝 모델을 포함하여 유형 레이블 산출부에 의해 결함 유형으로 레이블링된 이미지를 결함 유형으로 분류하며 SHAP(Shapley additive explanations)을 적용하여 분류 결과를 도출하는데 기여한 결함 부위에 대한 위치 정보를 포함하는 수퍼픽셀을 도출한다. 어노테이션 생성부는 수퍼픽셀에 대하여 미리 정의된 이미지 좌표계 상의 좌표들을 구하여 결함 부위에 대한 바 운딩 박스를 도출하고 산출된 결함 유형에 대한 레이블과 결합하여 어노테이션 정보를 생성한다. 본 발명의 일 실시 예에 따르는 SHAP 기반 이미지 어노테이션 생성 방법은 특징 추출 단계와, 유형 레이블 산출 단계와, 수퍼픽셀 도출 단계와, 어노테이션 생성 단계를 포함한다. 특징 추출 단계는 동일한 부품에 대하여 결함이 있는 결함 이미지 데이터와 결함이 없는 정상 이미지 데이터로 부터 결함에 대한 특징을 추출하도록 학습된 제1 딥러닝 모델을 이용하여 입력된 부품 이미지에 대하여 결함에 대한 특징을 추출하여 출력하는 단계이다. 유형 레이블 산출 단계는 부품 이미지에 대한 결함에 대한 특징을 군집 분석하여 유사한 유형별로 군집화하도록 학습된 군집 모델을 이용하여 특징 추출 단계에서 출력된 결함에 대한 특징의 군집 결과에 기초하여 결함 유형 에 대한 레이블을 산출하고 입력된 부품 이미지에 레이블링하는 단계이다. 수퍼픽셀 도출 단계는 부품 이미지에 대하여 결함 유형으로 분류하도록 학습된 제2 딥러닝 모델을 포함하여 유 형 레이블 산출부에 의해 결함 유형으로 레이블링된 이미지를 결함 유형으로 분류하며 SHAP(Shapley additiveexplanations)을 적용하여 분류 결과를 도출하는데 기여한 결함 부위에 대한 위치 정보를 포함하는 수퍼픽셀을 도출하는 단계이다. 어노테이션 생성 단계는 수퍼픽셀에 대하여 미리 정의된 이미지 좌표계 상의 좌표들을 구하여 결함 부위에 대한 바운딩 박스를 도출하고 산출된 결함 유형에 대한 레이블과 결합하여 어노테이션 정보를 생성하는 단계이다."}
{"patent_id": "10-2021-0179156", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명에 의하면 사람이 직접 이미지 어노테이션 정보를 생성하지 않아도 특정 부품에 대하여 수집된 이미지들 을 처리하여 결함에 대한 유형 및 위치 정보가 포함된 이미지 어노테이션 정보를 자동으로 생성하여 제공할 수 있어 결함 검출을 위한 딥러닝 모델 학습 시 필요한 어노테이션 정보 생성에 소요되는 시간 및 비용 절감이 가 능하다."}
{"patent_id": "10-2021-0179156", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "전술한, 그리고 추가적인 양상들은 첨부된 도면을 참조하여 설명하는 실시 예들을 통해 구체화된다. 각 실시 예들의 구성 요소들은 다른 언급이나 상호간에 모순이 없는 한 실시 예 내에서 다양한 조합이 가능한 것으로 이 해된다. 블록도의 각 블록은 어느 경우에 있어서 물리적인 부품을 표현할 수 있으나 또 다른 경우에 있어서 하 나의 물리적인 부품의 기능의 일부 혹은 복수의 물리적인 부품에 걸친 기능의 논리적인 표현일 수 있다. 때로 는 블록 혹은 그 일부의 실체는 프로그램 명령어들의 집합(set)일 수 있다. 이러한 블록들은 전부 혹은 일부가 하드웨어, 소프트웨어 혹은 이들의 결합에 의해 구현될 수 있다. 도 1은 본 발명의 일 양상에 따른 이미지 어노테이션 생성 장치의 블록도이고, 도 2는 본 발명의 일 양상에 따 른 이미지 어노테이션 생성 장치가 어노테이션 정보를 생성하는 절차의 개념을 도시한 것이다. 본 발명의 일 양상에 따르는 SHAP 기반 이미지 어노테이션 생성 장치는 특징 추출부와, 유형 레이블 산 출부와, 수퍼픽셀 도출부와, 어노테이션 생성부를 포함한다. 이미지 어노테이션 생성 장치는 입력 인터페이스와, 출력 인터페이스와, 메모리와, 저장장치와, 프로세서 등을 포함하는 컴퓨팅 장치로 구성될 수 있다. 입력 인터페이스는 사용자의 입력을 받아들이는 인터페이스로 키 보드(keyboard), 터치스크린(touch screen), 마우스(mouse), 전자펜(stylus pen) 및 펜 태블릿(pen tablet)을 포함하며, 이에 한정되는 것은 아니다. 출력 인터페이스는 사용자 인터페이스 등을 표시하는 디스플레이 (display)를 포함한다. 프로세서는 메모리 및/또는 저장 장치에 저장되어 이미지 어노테이션 생성을 위해 구현 된 프로그램 명령어 세트를 실행할 수 있다. 프로세서는 중앙 처리 장치(CPU), 그래픽 처리 장치(GPU) 또는 전 용의 프로세서일 수 있다. 메모리와 저장 장치는 휘발성 저장 매체 및/또는 비휘발성 저장 매체로 구성될 수 있 다. 예를 들어, 메모리는 읽기 전용 메모리(read only memory, ROM) 및/또는 랜덤 액세스 메모리(random access memory, RAM)로 구성될 수 있다. 이미지 어노테이션 생성 장치의 각 기능 블록들 즉, 특징 추출부와, 유형 레이블 산출부와, 수퍼픽 셀 도출부와, 어노테이션 생성부는 적어도 그 기능의 일부가 프로세서에서 실행되는 프로그램 명령어 세트로 구현된다. 특징 추출부는 이미지로부터 특징을 추출하도록 학습된 제1 딥러닝 모델을 포함한다. 제1 딥러닝 모델은 지 도 학습 모델이며 동일한 부품을 촬영한 이미지를 학습 데이터로 하여 학습한다. 제1 딥러닝 모델이 학습에 사 용하는 학습 데이터는 동일한 부품을 촬영한 이미지로 결함이 있는 결함 이미지 데이터와 결함이 없는 정상 이 미지 데이터로 구성된다. 제1 딥러닝 모델은 이 학습 데이터로부터 결함에 대한 특징을 추출하도록 학습한다. 특징 추출부는 학습된 제1 딥러닝 모델을 이용하여 입력된 부품 이미지에 대하여 결함에 대한 특징을 추출 하여 출력한다. 이때, 특징 추출부에 의해 출력되는 특징은 특징 벡터이다. 특징 추출부는 도 2에서 Step 1의 전처리 프로세스(Preprocessing)를 수행하는 블록이다. 특징 추출부는 제1 딥러닝 모델의 학습 성능을 높이기 위하여 부품을 촬영한 이미지 학습 데이터에서 부품 을 제외한 배경과 같은 불필요한 특징을 제거하는 전처리 과정을 먼저 수행할 수 있다. 제1 딥러닝 모델은 컨볼루션 신경망(CNN)을 기반으로 하여 입력된 부품 이미지에 대하여 결함에 대한 특징을 추 출하는 모델일 수 있다. 알려진 것과 같이 컨볼루션 신경망은 이미지에서 특징(feature)을 추출하는 필터를 학 습하여 이미지의 특징을 이해하는데 장점을 가진 모델이다. 이때, 컨볼루션 신경망은 VGGNet 구조, MobileNet 구조, 인셉션(Inception) 구조 중 어느 하나의 구조를 가질 수 있다. VGGNet 구조는 3x3 필터를 깊게 쌓는 것을 특징으로 하며 컨볼루션 레이어를 11개, 13개, 16개, 19개 로 구성할 수 있다. MobileNet 구조는 CNN에서 연산량을 줄이기 위하여 채널마다 따라 필터를 학습하는 컨볼루 션(depthwise convolution)과 필터 크기가 1x1으로 고정된 컨볼루션 (pointwise convolution)을 조합하여 사용 한다. 인셉션은 GoogLeNet이라고도 알려져 있으며 특징을 효율적으로 수행하기 위하여 1x1 필터를 사용하여 컨 볼루션 연산 후 이를 3x3, 5x5의 컨볼루션 연산을 수행하고 필터를 병합하는 인셉션 모듈을 반복적으로 사용하 는 구조를 갖는다. 다만, 컨볼루션 신경망은 VGGNet 구조, MobileNet 구조, 인셉션 구조 이외에 다른 구조를 가질 수도 있다. 예를 들어, 컨볼루션 신경만은 AlexNet, LeNet, ResNet 등과 같이 알려진 다른 구조를 가질 수도 있다. 유형 레이블 산출부는 이미지로부터 추출된 특징을 유사한 유형별로 군집화하도록 학습된 군집 모델을 포함 한다. 군집 모델은 비지도 학습 모델이며 특징 추출부가 출력한 특징 벡터들을 학습 데이터로 하여 학습한 다. 군집 모델은 이 학습 데이터로부터 결함에 대한 특징을 유형별로 군집화하도록 학습한다. 유형 레이블 산출 부는 군집 모델의 유형별 군집 결과에 기초하여 결함 유형에 대한 레이블을 산출한다. 이때, 유형 레이블은 범주형 변수일 수 있다. 유형 레이블 산출부는 학습된 군집 모델을 이용하여 이용하여 특징 추출부가 출력한 결함에 대한 특징의 군집 결과에 기초하여 결함 유형에 대한 레이블을 산출하고 입력된 부품 이미지에 레이블링한다. 유형 레이블 산출부는 도 2에서 Step 2의 레이블링(Labeling)를 수행하는 블록이다. 발명의 양상에 따라서는 군집 모델이 군집화한 결과에 기초하여 산출된 결함 유형에 대한 레이블에 실제 결함 레이블을 매핑하여 레이블을 산출할 수도 있다. 실제 결함 레이블을 사람에 의해 입력될 수 있다. 결함 유형의 개수가 한정적이므로 결함 유형에 대한 레이블에는 많은 시간과 비용이 소요되지 않는다. 도 3은 부품 이미지들에 대하여 결함 유형별로 군집 분석한 결과의 예시이다. 도 3은 결함이 있는 부품 이미지 들의 추출된 특징 벡터를 군집 분석하여 결함 유형별로 군집한 예시이다. 군집 모델은 K-평균(means) 군집분석 모델, 가우시안 혼합 모델(GMM) 중 어느 하나의 모델일 수 있다. 다만, 이 에 제한되지 않으며 군집 모델은 평균 이동 군집(Mean-Shift Clustering) 모델, DBSCAN 모델 등 다른 군집 모델 일 수 있다. 수퍼픽셀 도출부는 부품 이미지를 결함 유형으로 분류하도록 학습된 제2 딥러닝 모델을 포함한다. 제2 딥러 닝 모델은 지도 학습 모델이며 결함 유형으로 레이블링된 이미지를 학습 데이터로 하여 학습한다. 제2 딥러닝 모델이 학습에 사용하는 학습 데이터는 유형 레이블 산출부가 출력한 결함 유형이 레이블된 이미지가 사용 될 수 있다. 제2 딥러닝 모델은 이 학습 데이터로부터 결함 유형을 종속 변수로 하여 이미지를 분류하도록 학습 한다. 제2 딥러닝 모델이 결함 유형으로 레이블링된 이미지를 학습할 때 분류 결과 해석을 위하여 설명 가능한 인공지능(Explainable AI, XAI) 기법 중 하나인 SHAP(Shapley additive explanations)을 적용하여 분류 결과를 도출하는데 기여한 픽셀들의 섀플리 값(Shapley Value)를 도출한다. SHAP는 딥러닝 등 머신러닝 모델의 출력을 설명하는 게임 이론적 접근 방법이다. SHAP는 섀플리 값을 기반으로 하며 특징들의 조합이 변경된 데이터 셋을 구성하여 결과를 도출하는 데 기여한 특징들의 새플리 값을 이용한다. 수퍼픽셀 도출부는 학습된 제2 딥러닝 모델을 이용하여 유형 레이블 산출부에 의해 결함 유형으로 레이블링되어 출력된 이미지를 결함 유형으 로 분류하며 SHAP을 적용하여 분류 결과를 도출하는데 기여한 결함 부위에 대한 위치 정보를 포함하는 수퍼픽셀 을 도출한다. 결함 부위의 픽셀들이 높은 섀플리 값을 갖는다. 따라서, 수퍼픽셀들은 결함 부위의 픽셀들의 집 합으로 볼 수 있다. 수퍼픽셀 도출부는 도 2에서 Step 3의 결함 위치 수집 프로세스(Collecting Defect Location)를 수행하는 블록이다. 수퍼픽셀은 특징을 구성하는 픽셀들을 그룹화한 것으로 결함 부위의 픽셀들의 집합이다. 수퍼픽셀의 크기는 섀 플리 값의 적용 기준(예, 상위 30 픽셀, 상위 100 픽셀)에 따라 설정될 수 있다. 제2 딥러닝 모델은 컨볼루션 신경망(CNN)을 기반으로 하여 결함 유형으로 레이블링된 이미지를 결함 유형으로 분류하는 모델일 수 있다. 이때, 컨볼루션 신경망은 VGGNet 구조, MobileNet 구조, 인셉션(Inception) 구조 중 어느 하나의 구조를 가질 수 있다. VGGNet 구조는 3x3 필터를 깊게 쌓는 것을 특징으로 하며 컨볼루션 레이어를 11개, 13개, 16개, 19개 로 구성할 수 있다. MobileNet 구조는 CNN에서 연산량을 줄이기 위하여 채널마다 따라 필터를 학습하는 컨볼루 션(depthwise convolution)과 필터 크기가 1x1으로 고정된 컨볼루션 (pointwise convolution)을 조합하여 사용 한다. 인셉션은 GoogLeNet이라고도 알려져 있으며 특징을 효율적으로 수행하기 위하여 1x1 필터를 사용하여 컨 볼루션 연산 후 이를 3x3, 5x5의 컨볼루션 연산을 수행하고 필터를 병합하는 인셉션 모듈을 반복적으로 사용하 는 구조를 갖는다. 다만, 컨볼루션 신경망은 VGGNet 구조, MobileNet 구조, 인셉션 구조 이외에 다른 구조를 가질 수도 있다. 예를 들어, 컨볼루션 신경만은 AlexNet, LeNet, ResNet 등과 같이 알려진 다른 구조를 가질 수도 있다. 도 4는 결함 유형에 대한 다중 분류 결과와 이진 분류 결과의 예를 도시한 것이고, 도 5는 결함 유형에 대한 다 중 분류 결과와 이진 분류 결과의 섀플리 값 기준 상위 30, 80, 200, 500 픽셀을 도시한 것이다. 제2 딥러닝 모 델은 분류 모델로 결함이 없는 정상 유형을 포함하는 군집 유형으로 결함 유형을 다중 분류하는 분류 모델일 수 있다. 도 4의 (a)에 도시된 예에서 제2 딥러닝 모델은 결함 유형으로 레이블링된 이미지를 정상 유형(ok)과 세 가지 결함 유형(Defect1, Defect2, Defect3)을 포함하여 4개의 클래스 중 하나로 분류한다. Original은 이미지 의 원본을 의미하고 Ok, Defect1, Defect2, Defect3 이미지는 분류 결과에 대해 SHAP로 해석을 한 결과이다. SHAP를 이용하여 해석하여 각 분류결과를 도출한 이유에 해당하는 픽셀 즉, 섀플리 값이 높은 픽셀을 표시한단. 예를 들어, Defect1에서 빨간색으로 표시된 부분은 Defect1으로 분류하게 된 이유에 해당하는 픽셀이며 Original 이미지와 비교하면 결함이 있는 부위로 새플리값이 높은 부분을 의미하며, 파란색으로 표시된 부분은 Defect1으로 분류 이유와는 거리가 먼 픽셀들 즉, 새플리값이 낮은 부분을 의미한다. 또한, 제2 딥러닝 모델은 지정된 특정 결함 유형을 갖는지 여부로 이진 분류하는 분류 모델일 수 있다. 즉, 제2 딥러닝 모델은 설정된 특정 군집 유형으로 결함 유형을 이진 분류하는 분류 모델일 수 있다. 도 4의 (b)에 도시 된 예에서 제2 딥러닝 모델은 결함 유형으로 레이블링된 이미지가 지정된 결함 유형(Defect1)을 갖는지 이진 분 류할 수 있다. 도 5의 (a)는 결함 유형에 대한 다중 분류 결과에서 해당 결과를 도출하는 기여한 픽셀 중 새플리 값이 높은 상 위 30개부터 80, 200, 500까지 픽셀을 표시하여 비교한 것이며 이는 상위 몇 개부터 원본 이미지의 결함부분을 가장 잘 설명하는지 확인하기 위한 도면이고, 도 5의 (b)는 결함 유형에 대한 이진 분류 결과에서 해당 결과를 도출하는 기여한 픽셀 중 새플리 값이 높은 상위 30개부터 80, 200, 500까지 비교하여 상위 몇 개부터 원본 이 미지의 결함부분을 가장 잘 설명하는지 확인하기 위한 도면이다. 도 6은 섀플리 값 기준 상위 30, 200 픽셀로 구성되는 수퍼픽셀의 이미지 좌표계 변환의 예를 도시한 것이다. 어노테이션 생성부는 수퍼픽셀에 대하여 미리 정의된 이미지 좌표계 상의 좌표들을 구하여 결함 부위에 대 한 바운딩 박스를 도출하고 산출된 결함 유형에 대한 레이블과 결합하여 어노테이션 정보를 생성한다. 어노테이 션 생성부는 수퍼픽셀로부터 도출되는 좌표들을 이용하여 수퍼픽셀에 속한 픽셀의 좌표 중 x좌표계 상의 최 소값(xmin)과 최대값(xmax)과 y좌표계 상의 최소값(ymin)과 최대값(ymax)를 결함 부위의 위치 좌표를 구하여 사 각형 형태의 바운딩 박스 좌표를 도출한다. 도 6의 (a), (b)는 섀플리 값 적용 기준(예, top 30개, top 200개) 에 따른 수퍼픽셀의 위치 정보를 이미지 좌표계로 변환한 예를 도시하고 있다. 상위 30개와 상위 200개의 픽셀 을 이용하여 바운딩 박스를 도출하면 상위 30개의 경우 결함 부분만을 의미하지만 상위 200개의 경우 결함 부분 외에 결함이 없는 부분까지 포함될 수 있다. 도 7은 결함 유형에 대한 레이블과 결함 위치에 대한 좌표를 병합한 예를 도시한 것이고, 도 8은 바운딩 박스 형태의 어노테이션 정보를 도출한 예를 도시한 것이다. 어노테이션 생성부는 도출된 바운딩 박스와 결합 유형에 대한 레이블 정보를 결합하여 이미지에 포함된 결 함에 대한 어노테이션 정보를 생성한다. 이 어노테이션 정보를 이미지에 대한 메타 정보로 사용하여 학습 데이 터를 도출할 수 있다. 도 7의 예에서 결함 유형에 대한 레이블링으로 산출된 Blowhole과 결함 위치에 대한 좌표 를 병합한 예가 도시되어 있고, 도 8은 결함 유형에 대한 레이블과 결함 위치에 대한 좌표로부터 도출된 바운딩 박스를 결합하여 생성한 어노테이션을 이미지에 결합시킨 것을 도시하고 있다. 어노테이션 생성부는 도 2에 서 Step 4의 어노테이션 생성 프로세스(Generate Annotation)를 수행하는 블록이다. 본 발명의 일 실시 예에 따르는 SHAP 기반 이미지 어노테이션 생성 방법은 특징 추출 단계와, 유형 레이블 산출 단계와, 수퍼픽셀 도출 단계와, 어노테이션 생성 단계를 포함한다. 이미지 어노테이션 생성 방법의 각 단계는 컴퓨팅 장치의 프로세서에서 실행되는 프로그램 명령어로 구현되어 프로세서에서 실행된다. 특징 추출 단계는 이미지 어노테이션 생성 장치가 동일한 부품에 대하여 결함이 있는 결함 이미지 데이터와 결함이 없는 정상 이미지 데이터로부터 결함에 대한 특징을 추출하도록 학습된 제1 딥러닝 모델을 이용하여 입 력된 부품 이미지에 대하여 결함에 대한 특징을 추출하여 출력하는 단계이다. 제1 딥러닝 모델은 지도 학습 모델이며 동일한 부품을 촬영한 이미지를 학습 데이터로 하여 학습한다. 제1 딥러 닝 모델이 학습에 사용하는 학습 데이터는 동일한 부품을 촬영한 이미지로 결함이 있는 결함 이미지 데이터와 결함이 없는 정상 이미지 데이터로 구성된다. 제1 딥러닝 모델은 이 학습 데이터로부터 결함에 대한 특징을 추 출하도록 학습한다. 특징 추출 단계에서 제1 딥러닝 모델의 학습 성능을 높이기 위하여 부품을 촬영한 이미지 학습 데이터에서 부품 을 제외한 배경과 같은 불필요한 특징을 제거하는 전처리 과정을 먼저 수행될 수 있다. 제1 딥러닝 모델은 컨볼루션 신경망(CNN)을 기반으로 하여 입력된 부품 이미지에 대하여 결함에 대한 특징을 추 출하는 모델일 수 있다. 이때, 컨볼루션 신경망은 VGGNet 구조, MobileNet 구조, 인셉션(Inception) 구조 중 어 느 하나의 구조를 가질 수 있다. 다만, 컨볼루션 신경망은 VGGNet 구조, MobileNet 구조, 인셉션 구조 이외에 다른 구조를 가질 수도 있다. 예를 들어, 컨볼루션 신경만은 AlexNet, LeNet, ResNet 등과 같이 알려진 다른 구 조를 가질 수도 있다. 유형 레이블 산출 단계는 이미지 어노테이션 생성 장치가 부품 이미지에 대한 결함에 대한 특징을 군집 분 석하여 유사한 유형별로 군집화하도록 학습된 군집 모델을 이용하여 특징 추출 단계에서 출력된 결함에 대한 특 징의 군집 결과에 기초하여 결함 유형에 대한 레이블을 산출하고 입력된 부품 이미지에 레이블링하는 단계이다. 군집 모델은 비지도 학습 모델이며 특징 추출부가 출력한 특징 벡터들을 학습 데이터로 하여 학습한다. 군 집 모델은 이 학습 데이터로부터 결함에 대한 특징을 유형별로 군집화하도록 학습한다. 유형 레이블 산출 단계 에서 군집 모델의 유형별 군집 결과에 기초하여 결함 유형에 대한 레이블을 산출한다. 이때, 유형 레이블은 범 주형 변수일 수 있다. 발명의 양상에 따라서는 유형 레이블 산출 단계에서 군집 모델이 군집화한 결과에 기초하여 산출된 결함 유형에 대한 레이블에 실제 결함 레이블을 매핑하여 레이블을 산출할 수도 있다. 실제 결함 레이블을 사람에 의해 입력 될 수 있다. 결함 유형의 개수가 한정적이므로 결함 유형에 대한 레이블에는 많은 시간과 비용이 소요되지 않는 다. 군집 모델은 K-평균(means) 군집분석 모델, 가우시안 혼합 모델(GMM) 중 어느 하나의 모델일 수 있다. 다만, 이 에 제한되지 않으며 군집 모델은 평균 이동 군집(Mean-Shift Clustering) 모델, DBSCAN 모델 등 다른 군집 모델 일 수 있다. 수퍼픽셀 도출 단계는 이미지 어노테이션 생성 장치가 부품 이미지에 대하여 결함 유형으로 분류하도록 학 습된 제2 딥러닝 모델을 포함하여 유형 레이블 산출부에 의해 결함 유형으로 레이블링된 이미지를 결함 유 형으로 분류하며 SHAP(Shapley additive explanations)을 적용하여 분류 결과를 도출하는데 기여한 결함 부위에 대한 위치 정보를 포함하는 수퍼픽셀을 도출하는 단계이다. 제2 딥러닝 모델은 지도 학습 모델이며 결함 유형으로 레이블링된 이미지를 학습 데이터로 하여 학습한다. 제2 딥러닝 모델이 학습에 사용하는 학습 데이터는 유형 레이블 산출 단계에서 출력된 결함 유형이 레이블된 이미지가 사용될 수 있다. 제2 딥러닝 모델은 이 학습 데이터로부터 결함 유형을 종속 변수로 하여 이미지를 분류하도 록 학습한다. 제2 딥러닝 모델이 결함 유형으로 레이블링된 이미지를 학습할 때 분류 결과 해석을 위하여 설명 가능한 인공지능(Explainable AI, XAI) 기법 중 하나인 SHAP(Shapley additive explanations)을 적용하여 분류 결과를 도출하는데 기여한 픽셀들의 섀플리 값(Shapley Value)를 도출한다. SHAP는 딥러닝 등 머신러닝 모델의 출력을 설명하는 게임 이론적 접근 방법이다. SHAP는 섀플리 값을 기반으로 하며 특징들의 조합이 변경된 데이 터 셋을 구성하여 결과를 도출하는 데 기여한 특징들의 새플리 값을 이용한다. 제2 딥러닝 모델은 컨볼루션 신경망(CNN)을 기반으로 하여 결함 유형으로 레이블링된 이미지를 결함 유형으로 분류하는 모델일 수 있다. 이때, 컨볼루션 신경망은 VGGNet 구조, MobileNet 구조, 인셉션(Inception) 구조 중 어느 하나의 구조를 가질 수 있다. 다만, 컨볼루션 신경망은 VGGNet 구조, MobileNet 구조, 인셉션 구조 이외에 다른 구조를 가질 수도 있다. 예를 들어, 컨볼루션 신경만은 AlexNet, LeNet, ResNet 등과 같이 알려진 다른 구 조를 가질 수도 있다. 제2 딥러닝 모델은 분류 모델로 결함이 없는 정상 유형을 포함하는 군집 유형으로 결함 유형을 다중 분류하는 분류 모델일 수 있다. 또한, 제2 딥러닝 모델은 지정된 특정 결함 유형을 갖는지 여부로 이진 분류하는 분류 모 델일 수 있다. 즉, 제2 딥러닝 모델은 설정된 특정 군집 유형으로 결함 유형을 이진 분류하는 분류 모델일 수 있다. 어노테이션 생성 단계는 수퍼픽셀에 대하여 미리 정의된 이미지 좌표계 상의 좌표들을 구하여 결함 부위에 대한 바운딩 박스를 도출하고 산출된 결함 유형에 대한 레이블과 결합하여 어노테이션 정보를 생성하는 단계이다. 이미지 어노테이션 생성 장치는 수퍼픽셀로부터 도출되는 좌표들을 이용하여 수퍼픽셀에 속한 픽셀의 좌표 중 x좌표계 상의 최소값(xmin)과 최대값(xmax)과 y좌표계 상의 최소값(ymin)과 최대값(ymax)를 결함 부위의 위 치 좌표를 구하여 사각형 형태의 바운딩 박스 좌표를 도출한다. 이미지 어노테이션 생성 장치는 도출된 바 운딩 박스와 결합 유형에 대한 레이블 정보를 결합하여 이미지에 포함된 결함에 대한 어노테이션 정보를 생성한 다. 이 어노테이션 정보를 이미지에 대한 메타 정보로 사용하여 학습 데이터를 도출할 수 있다. 본 발명의 일 실시 예에 따라 SHAP 기반으로 이미지에 대한 어노테이션을 생성하는 방법은 이미지 어노테이션 생성 장치가 제1 딥러닝 모델을 이용하여 입력된 부품 이미지에 대하여 결함에 대한 특징을 추출(S1000)하 여 출력하고, 이미지 어노테이션 생성 장치가 추출된 결함에 대한 특징의 군집 결과에 기초하여 결함 유형 에 대한 레이블을 산출(S1001)하여 입력된 부품 이미지에 레이블링하고, 이미지 어노테이션 생성 장치가 결 함 유형으로 레이블링된 이미지를 결함 유형으로 분류(S1002)하며 SHAP을 적용하여 분류 결과를 도출하는데 기 여한 결함 부위에 대한 위치 정보를 포함하는 수퍼픽셀을 도출(S1020)하고, 이미지 어노테이션 생성 장치가 수퍼픽셀에 대하여 이미지 좌표계를 적용하여 결함 위치에 대한 좌표를 도출(S1021)하고, 도출된 좌표를 이용하 여 결함 부위에 대한 바운딩 박스를 도출(S1040)한다. 이미지 어노테이션 생성 장치는 도출된 바운딩 박스 와 결함 유형에 대한 레이블을 결합하여 이미지에 대한 어노테이션 정보를 생성(S1060)한다. 이상에서 본 발명을 첨부된 도면을 참조하는 실시 예들을 통해 설명하였지만 이에 한정되는 것은 아니며, 이들 로부터 당업자라면 자명하게 도출할 수 있는 다양한 변형 예들을 포괄하도록 해석되어야 한다. 특허청구범위는 이러한 변형 예들을 포괄하도록 의도되었다."}
{"patent_id": "10-2021-0179156", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일 양상에 따른 이미지 어노테이션 생성 장치의 블록도이다. 도 2는 본 발명의 일 양상에 따른 이미지 어노테이션 생성 장치가 어노테이션 정보를 생성하는 절차의 개념을 도시한 것이다. 도 3은 부품 이미지들에 대하여 결함 유형별로 군집 분석한 결과의 예시이다. 도 4는 결함 유형에 대한 다중 분류 결과와 이진 분류 결과의 예를 도시한 것이다. 도 5는 결함 유형에 대한 다중 분류 결과와 이진 분류 결과의 섀플리 값 기준 상위 30, 80, 200, 500 픽셀을 도 시한 것이다. 도 6은 섀플리 값 기준 상위 30, 200 픽셀로 구성되는 수퍼픽셀의 이미지 좌표계 변환의 예를 도시한 것이다. 도 7은 결함 유형에 대한 레이블과 결함 위치에 대한 좌표를 병합한 예를 도시한 것이다. 도 8은 바운딩 박스 형태의 어노테이션 정보를 도출한 예를 도시한 것이다. 도 9는 본 발명의 일 실시 예에 따른 이미지 어노테이션 생성 방법의 절차도이다."}
