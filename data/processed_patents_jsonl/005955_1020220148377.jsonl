{"patent_id": "10-2022-0148377", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0067420", "출원번호": "10-2022-0148377", "발명의 명칭": "사이드 아우터 추출 시스템 및 사이드 아우터 추출 방법", "출원인": "현대자동차주식회사", "발명자": "박성현"}}
{"patent_id": "10-2022-0148377", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "적어도 하나의 프로세서에 의해 수행되는 사이드 아우터 추출 방법에 있어서, 영역 탐지 서버가, 캐드 모듈로부터 3차원 데이터로부터 전처리된 이미지를 수신하는 단계;상기 영역 탐지 서버가, 인공지능 모델로 상기 전처리된 이미지로부터 검출하고자 하는 복수의 타겟 레퍼런스각각에 대응하는 복수의 영역 각각에 대한 분류 값 및 바운딩 박스(bounding box)를 검출하는 단계;상기 영역 탐지 서버가, 상기 복수의 영역 각각에 대한 분류 값 및 바운딩 박스를 나타내는 신호를 상기 캐드모듈에 전송하는 단계; 및상기 캐드 모듈이, 수신한 신호에 기초하여 상기 복수의 영역 각각에 대한 분류 값 및 바운딩 박스로부터 상기복수의 타겟 레퍼런스를 추출하는 단계를 포함하는, 사이드 아우터 추출 방법."}
{"patent_id": "10-2022-0148377", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 영역 탐지 서버가, 상기 캐드 모듈로부터 학습 데이터셋을 수신하는 단계; 및상기 인공지능 모델이 상기 학습 데이터셋에 기초하여 상기 전처리된 이미지로부터 상기 복수의 영역을 검출하는 방법을 학습하는 단계를 더 포함하는, 사이드 아우터 추출 방법."}
{"patent_id": "10-2022-0148377", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서, 상기 캐드 모듈이 단말을 통해 어플리케이션에 상기 전처리된 이미지를 제공하는 단계;상기 캐드 모듈이 관리자로부터 상기 전처리된 이미지의 복수의 영역에 대한 위치 값 및 분류 값 각각을 나타내는 데이터를 입력 받는 단계; 및상기 캐드 모듈이 상기 입력 받은 데이터에 기초하여 상기 학습 데이터셋을 생성하는 단계를 더 포함하는, 사이드 아우터 추출 방법."}
{"patent_id": "10-2022-0148377", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서, 상기 복수의 영역에 대한 위치 값은, 박스 형태의 복수의 제1 영역에 대한 위치 값이고, 상기 복수의 제1 영역 각각에 대한 분류 값 및 바운딩 박스를 검출하는 단계는,상기 전처리된 이미지로부터 특징 맵을 생성하는 단계;상기 특징 맵으로부터 적어도 하나의 제안 영역을 도출하는 단계;상기 적어도 하나의 제안 영역으로부터 상기 특징 맵을 고정된 크기의 특징으로 풀링하는 단계;상기 고정된 크기의 특징으로부터 상기 적어도 하나의 제안 영역 각각에 대한 클래스가 존재할 확률 분포를 나타내는 데이터를 생성하는 단계; 및상기 고정된 크기의 특징으로부터 상기 적어도 하나의 제안 영역 각각에 대하여 복수의 타겟 레퍼런스 각각을정확히 감싸는 복수의 바운딩 박스의 위치를 정의하는 단계를 포함하는, 사이드 아우터 추출 방법.공개특허 10-2024-0067420-3-청구항 5 제4항에 있어서, 상기 적어도 하나의 제안 영역 각각에 대한 클래스가 존재할 확률 분포를 나타내는 데이터 및 상기 복수의 바운딩 박스의 위치에 기초하여, 상기 복수의 제1 영역 각각에 대한 상기 분류 값 및 상기 바운딩 박스를 검출하는단계를 더 포함하는, 사이드 아우터 추출 방법."}
{"patent_id": "10-2022-0148377", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5항에 있어서, 상기 복수의 영역 각각에 대한 분류 값 및 바운딩 박스로부터 상기 복수의 타겟 레퍼런스를 추출하는 단계는,상기 각 영역의 분류 값에 기초하여 상기 바운딩 박스를 나타내는 사각형으로부터 하나의 라인을 추출하는 단계를 포함하는, 사이드 아우터 추출 방법."}
{"patent_id": "10-2022-0148377", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제3항에 있어서, 상기 복수의 영역에 대한 위치 값은, 세분화된 형태의 복수의 제2 영역에 대한 위치 값이고, 상기 복수의 제2 영역 각각에 대한 분류 값 및 바운딩 박스를 검출하는 단계는,상기 복수의 제2 영역 각각에 대한 상기 바운딩 박스 중 타겟 레퍼런스가 존재하는 객체 마스크를 검출하는 단계를 포함하는, 사이드 아우터 추출 방법."}
{"patent_id": "10-2022-0148377", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서, 상기 복수의 제2 영역 각각에 대한 분류 값 및 바운딩 박스를 검출하는 단계는,상기 전처리된 이미지로부터 특징 맵을 생성하는 단계;상기 특징 맵으로부터 적어도 하나의 제안 영역을 도출하는 단계;상기 특징 맵을 상기 적어도 하나의 제안 영역과 정렬시켜 고정된 크기의 특징을 추출하는 단계;상기 고정된 크기의 특징으로부터 상기 적어도 하나의 제안 영역 각각에 대한 클래스가 존재할 확률 분포를 나타내는 데이터를 생성하는 단계;상기 고정된 크기의 특징으로부터 상기 적어도 하나의 제안 영역 각각에 대하여 복수의 타겟 레퍼런스 각각을정확히 감싸는 복수의 바운딩 박스의 위치를 정의하는 단계; 및상기 고정된 크기의 특징으로부터 모든 픽셀에 클래스가 존재할지를 예측하여 마스크를 생성하는 단계를 포함하는, 사이드 아우터 추출 방법."}
{"patent_id": "10-2022-0148377", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서, 상기 적어도 하나의 제안 영역 각각에 대한 클래스가 존재할 확률 분포를 나타내는 데이터, 상기 복수의 바운딩박스의 위치, 및 상기 마스크에 기초하여, 상기 복수의 제2 영역 각각에 대한 상기 분류 값, 타겟 바운딩 박스,및 상기 타겟 바운딩 박스 중 객체 마스크를 검출하는 단계를 더 포함하는, 사이드 아우터 추출 방법."}
{"patent_id": "10-2022-0148377", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "인공지능 모델로 전처리 이미지로부터 검출하고자 하는 복수의 타겟 레퍼런스 각각에 대응하는 복수의 영역 각각을 검출하는 방법을 학습하고, 학습 결과 상기 복수의 영역 각각을 검출하는 영역 탐지 서버; 및차량에 대한 3차원 데이터로부터 렌더링 이미지를 추출하고, 상기 렌더링 이미지로부터 상기 전처리 이미지를공개특허 10-2024-0067420-4-생성하며, 관리 단말로부터 수신한 신호에 기초하여 학습 데이터셋을 생성하고, 상기 복수의 영역 각각으로부터상기 복수의 타겟 레퍼런스 각각을 추출하는 캐드 모듈을 포함하는, 사이드 아우터 추출 시스템."}
{"patent_id": "10-2022-0148377", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제10항에 있어서,상기 캐드 모듈은, 상기 3차원 데이터로부터 상기 차량의 사이드 아우터를 정면으로 오도록 하는 렌더링 이미지를 추출하고, 상기렌더링 이미지로부터 배경 및 제품의 색상을 변경하며, 라인의 색상 및 두께를 변경하고, 음영을 조정하여 상기전처리 이미지를 생성하는 전처리부; 및 상기 복수의 영역 각각으로부터 상기 복수의 타겟 레퍼런스 각각을 추출하는 레퍼런스 매핑부를 포함하는, 사이드 아우터 추출 시스템."}
{"patent_id": "10-2022-0148377", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제10항에 있어서,상기 인공지능 모델은, 상기 전처리 이미지로부터 박스 형태인 복수의 제1 영역 각각을 검출하는 박스 탐지부; 및 상기 전처리 이미지로부터 세분화된 형태인 복수의 제2 영역 각각을 검출하는 세그멘테이션 탐지부를 포함하는,사이드 아우터 추출 시스템."}
{"patent_id": "10-2022-0148377", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제12항에 있어서,상기 박스 탐지부는, 상기 전처리 이미지로부터 특징 맵을 생성하는 백본 네트워크;상기 특징 맵으로부터 적어도 하나의 제안 영역을 도출하는 RPN(Region Proposal Network) 계층;상기 적어도 하나의 제안 영역으로부터 상기 특징 맵을 고정된 크기의 특징으로 풀링하는 ROI(Region OfInterest) 풀링부;상기 고정된 크기의 특징으로부터 상기 적어도 하나의 제안 영역 각각에 대한 클래스가 존재할 확률 분포를 나타내는 데이터를 생성하는 분류 계층; 및상기 고정된 크기의 특징으로부터 상기 적어도 하나의 제안 영역 각각에 대하여 복수의 타겟 레퍼런스 각각을정확히 감싸는 복수의 바운딩 박스의 위치를 정의하는 박스 리그레션 계층을 포함하는, 사이드 아우터 추출 시스템."}
{"patent_id": "10-2022-0148377", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제12항에 있어서,상기 세그멘테이션 탐지부는,상기 전처리 이미지로부터 특징 맵을 생성하는 백본 네트워크;상기 특징 맵으로부터 적어도 하나의 제안 영역을 도출하는 RPN 계층;상기 특징 맵을 상기 적어도 하나의 제안 영역과 정렬시켜 고정된 크기의 특징을 추출하는 ROI Align부;상기 고정된 크기의 특징으로부터 상기 적어도 하나의 제안 영역 각각에 대한 클래스가 존재할 확률 분포를 나타내는 데이터를 생성하는 분류 계층;상기 고정된 크기의 특징으로부터 상기 적어도 하나의 제안 영역 각각에 대하여 복수의 타겟 레퍼런스 각각을정확히 감싸는 복수의 바운딩 박스의 위치를 정의하는 박스 리그레션 계층; 및공개특허 10-2024-0067420-5-상기 고정된 크기의 특징으로부터 모든 픽셀에 클래스가 존재할지를 예측하여 마스크를 생성하는 마스크 브런치를 포함하는, 사이드 아웃터 추출 시스템."}
{"patent_id": "10-2022-0148377", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제1항의 사이드 아우터 추출 방법을 수행하기 위한 제어 명령을 포함하는 컴퓨터 프로그램을 저장한 컴퓨터 판독가능 저장 매체."}
{"patent_id": "10-2022-0148377", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "적어도 하나의 제1 프로그램을 실행하기 위한 제1 명령어들을 저장하는 제1 메모리 및 상기 제1 명령어들을 실행하는 적어도 하나의 제1 프로세서를 포함하는 영역 탐지 서버; 및적어도 하나의 제2 프로그램을 실행하기 위한 제2 명령어들을 저장하는 제2 메모리 및 상기 제2 명령어들을 실행하는 적어도 하나의 제2 프로세서를 포함하는 캐드 모듈을 포함하고, 상기 적어도 하나의 제2 프로세서가 상기 적어도 하나의 제2 프로그램에 따라 차량에 대한 3차원 데이터로부터렌더링 이미지를 추출하고, 상기 렌더링 이미지로부터 전처리 이미지를 생성하며, 관리 단말로부터 수신한 신호에 기초하여 학습 데이터셋을 생성하여 상기 영역 탐지 서버에 전송하는, 사이드 아우터 추출 시스템."}
{"patent_id": "10-2022-0148377", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제16항에 있어서,상기 적어도 하나의 제1 프로세서는,상기 적어도 하나의 제1 프로그램에 따라 상기 학습 데이터셋으로 상기 전처리 이미지로부터 검출하고자 하는복수의 타겟 레퍼런스 각각에 대응하는 복수의 영역 각각을 검출하는 인공지능 모델을 학습시키는, 사이드 아우터 추출 시스템."}
{"patent_id": "10-2022-0148377", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제17항에 있어서,상기 적어도 하나의 제1 프로세서는,상기 학습된 인공지능 모델을 이용하여 상기 복수의 영역 각각을 검출하며,상기 적어도 하나의 제2 프로세서는,상기 적어도 하나의 상기 제2 프로그램에 따라 상기 복수의 영역 각각으로부터 상기 복수의 타겟 레퍼런스 각각을 추출하는, 사이드 아우터 추출 시스템."}
{"patent_id": "10-2022-0148377", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "사이드 아우터 추출 방법은, 적어도 하나의 프로세서에 의해 수행되는 사이드 아우터 추출 방법에 있어서, 영역 탐지 서버가, 캐드 모듈로부터 3차원 데이터로부터 전처리된 이미지를 수신하는 단계, 상기 영역 탐지 서버가, 인공지능 모델로 상기 전처리된 이미지로부터 검출하고자 하는 복수의 타겟 레퍼런스 각각에 대응하는 복수의 영 역 각각에 대한 분류 값 및 바운딩 박스(bounding box)를 검출하는 단계, 상기 영역 탐지 서버가, 상기 복수의 영역 각각에 대한 분류 값 및 바운딩 박스를 나타내는 신호를 상기 캐드 모듈에 전송하는 단계, 및 상기 캐드 모 듈이, 수신한 신호에 기초하여 상기 복수의 영역 각각에 대한 분류 값 및 바운딩 박스로부터 상기 복수의 타겟 레퍼런스를 추출하는 단계를 포함함한다."}
{"patent_id": "10-2022-0148377", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 사이드 아우터 추출 시스템 및 사이드 아우터 추출 방법에 관한 것이다."}
{"patent_id": "10-2022-0148377", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "제조업 분야에서 설비의 무인화 및 자동화가 활발히 일어나면서 인공지능과 기계학습 모델의 활용이 중요해지고 있다. 제품 생산 과정에서는 제품의 결함을 탐지하거나, 제품을 판별하는 데 인공지능을 활용하고 있다. 다만 금형 설계 과정에서, 3차원 모델링으로부터 타겟 라인을 수작업으로 추출하고 있어 이로 인해 라인 추출의 정확 도가 저하되고 시간도 많이 소요되는 문제가 발생하였다. 설계된 제품에 대한 3차원 도면에서 제반 데이터를 추출하는 과정의 자동화에 대한 필요성이 대두되고 있다."}
{"patent_id": "10-2022-0148377", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 2, "content": "발명의 내용"}
{"patent_id": "10-2022-0148377", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명이 이루고자 하는 기술적 과제는, 3차원 데이터로부터 추출할 라인을 나타내는 레퍼런스를 자동으로 추 출할 수 있도록 하는 시스템 및 방법을 제공하고자 한다."}
{"patent_id": "10-2022-0148377", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 한 특징에 따른 사이드 아우터 추출 방법은, 적어도 하나의 프로세서에 의해 수행되는 사이드 아우터 추출 방법에 있어서, 영역 탐지 서버가, 캐드 모듈로부터 3차원 데이터로부터 전처리된 이미지를 수신하는 단계, 상기 영역 탐지 서버가, 인공지능 모델로 상기 전처리된 이미지로부터 검출하고자 하는 복수의 타겟 레퍼 런스 각각에 대응하는 복수의 영역 각각에 대한 분류 값 및 바운딩 박스(bounding box)를 검출하는 단계, 상기 영역 탐지 서버가, 상기 복수의 영역 각각에 대한 분류 값 및 바운딩 박스를 나타내는 신호를 상기 캐드 모듈에 전송하는 단계, 및 상기 캐드 모듈이, 수신한 신호에 기초하여 상기 복수의 영역 각각에 대한 분류 값 및 바운 딩 박스로부터 상기 복수의 타겟 레퍼런스를 추출하는 단계를 포함한다. 상기 영역 탐지 서버가, 상기 캐드 모듈로부터 학습 데이터셋을 수신하는 단계 및 상기 인공지능 모델이 상기 학습 데이터셋에 기초하여 상기 전처리된 이미지로부터 상기 복수의 영역을 검출하는 방법을 학습하는 단계를 더 포함할 수 있다. 상기 캐드 모듈이 단말을 통해 어플리케이션에 상기 전처리된 이미지를 제공하는 단계, 상기 캐드 모듈이 관리 자로부터 상기 전처리된 이미지의 복수의 영역에 대한 위치 값 및 분류 값 각각을 나타내는 데이터를 입력 받는 단계, 및 상기 캐드 모듈이 상기 입력 받은 데이터에 기초하여 상기 학습 데이터셋을 생성하는 단계를 더 포함 할 수 있다. 상기 복수의 영역에 대한 위치 값은, 박스 형태의 복수의 제1 영역에 대한 위치 값이고, 상기 복수의 제1 영역 각각에 대한 분류 값 및 바운딩 박스를 검출하는 단계는, 상기 전처리된 이미지로부터 특징 맵을 생성하는 단계, 상기 특징 맵으로부터 적어도 하나의 제안 영역을 도출하는 단계, 상기 적어도 하나의 제안 영역으로부터 상기 특징 맵을 고정된 크기의 특징으로 풀링하는 단계, 상기 고정된 크기의 특징으로부터 상기 적어도 하나의 제안 영역 각각에 대한 클래스가 존재할 확률 분포를 나타내는 데이터를 생성하는 단계, 및 상기 고정된 크기의 특징으로부터 상기 적어도 하나의 제안 영역 각각에 대하여 복수의 타겟 레퍼런스 각각을 정확히 감싸는 복수의 바운딩 박스의 위치를 정의하는 단계를 포함할 수 있다. 상기 적어도 하나의 제안 영역 각각에 대한 클래스가 존재할 확률 분포를 나타내는 데이터 및 상기 복수의 바운 딩 박스의 위치에 기초하여, 상기 복수의 제1 영역 각각에 대한 상기 분류 값 및 상기 바운딩 박스를 검출하는 단계를 더 포함할 수 있다. 상기 복수의 영역 각각에 대한 분류 값 및 바운딩 박스로부터 상기 복수의 타겟 레퍼런스를 추출하는 단계는, 상기 각 영역의 분류 값에 기초하여 상기 바운딩 박스를 나타내는 사각형으로부터 하나의 라인을 추출하는 단계 를 포함할 수 있다. 상기 복수의 영역에 대한 위치 값은, 세분화된 형태의 복수의 제2 영역에 대한 위치 값이고, 상기 복수의 제2 영역 각각에 대한 분류 값 및 바운딩 박스를 검출하는 단계는, 상기 복수의 제2 영역 각각에 대한 상기 바운딩 박스 중 타겟 레퍼런스가 존재하는 객체 마스크를 검출하는 단계를 포함할 수 있다. 상기 복수의 제2 영역 각각에 대한 분류 값 및 바운딩 박스를 검출하는 단계는, 상기 전처리된 이미지로부터 특 징 맵을 생성하는 단계, 상기 특징 맵으로부터 적어도 하나의 제안 영역을 도출하는 단계, 상기 특징 맵을 상기 적어도 하나의 제안 영역과 정렬시켜 고정된 크기의 특징을 추출하는 단계, 상기 고정된 크기의 특징으로부터 상기 적어도 하나의 제안 영역 각각에 대한 클래스가 존재할 확률 분포를 나타내는 데이터를 생성하는 단계, 상 기 고정된 크기의 특징으로부터 상기 적어도 하나의 제안 영역 각각에 대하여 복수의 타겟 레퍼런스 각각을 정 확히 감싸는 복수의 바운딩 박스의 위치를 정의하는 단계, 및 상기 고정된 크기의 특징으로부터 모든 픽셀에 클 래스가 존재할지를 예측하여 마스크를 생성하는 단계를 포함할 수 있다. 상기 적어도 하나의 제안 영역 각각에 대한 클래스가 존재할 확률 분포를 나타내는 데이터, 상기 복수의 바운딩 박스의 위치, 및 상기 마스크에 기초하여, 상기 복수의 제2 영역 각각에 대한 상기 분류 값, 타겟 바운딩 박스, 및 상기 타겟 바운딩 박스 중 객체 마스크를 검출하는 단계를 더 포함할 수 있다. 발명의 다른 특징에 따른 사이드 아우터 추출 시스템은, 학습 데이터셋으로 상기 전처리 이미지로부터 검출하고 자 하는 복수의 타겟 레퍼런스 각각에 대응하는 복수의 영역 각각을 검출하는 방법을 학습하고, 학습 결과 상기 복수의 영역 각각을 검출하는 영역 탐지 서버, 및 차량에 대한 3차원 데이터로부터 렌더링 이미지를 추출하고, 상기 렌더링 이미지로부터 상기 전처리 이미지를 생성하며, 관리 단말로부터 수신한 신호에 기초하여 학습 데이 터셋을 생성하고, 상기 복수의 영역 각각으로부터 상기 복수의 타겟 레퍼런스 각각을 추출하는 캐드 모듈을 포 함한다. 상기 캐드 모듈은, 상기 3차원 데이터로부터 상기 차량의 사이드 아우터를 정면으로 오도록 하는 렌더링 이미지 를 추출하고, 상기 렌더링 이미지로부터 배경 및 제품의 색상을 변경하며, 라인의 색상 및 두께를 변경하고, 음 영을 조정하여 상기 전처리 이미지를 생성하는 전처리부, 및 상기 복수의 영역 각각으로부터 상기 복수의 타겟 레퍼런스 각각을 추출하는 레퍼런스 매핑부를 포함할 수 있다. 상기 인공지능 모델은, 상기 전처리 이미지로부터 박스 형태인 복수의 제1 영역 각각을 검출하는 박스 탐지부, 및 상기 전처리 이미지로부터 세분화된 형태인 복수의 제2 영역 각각을 검출하는 세그멘테이션 탐지부를 포함할 수 있다. 상기 박스 탐지부는, 상기 전처리 이미지로부터 특징 맵을 생성하는 백본 네트워크, 상기 특징 맵으로부터 적어 도 하나의 제안 영역을 도출하는 RPN(Region Proposal Network) 계층, 상기 적어도 하나의 제안 영역으로부터 상기 특징 맵을 고정된 크기의 특징으로 풀링하는 ROI(Region Of Interest) 풀링부, 상기 고정된 크기의 특징으 로부터 상기 적어도 하나의 제안 영역 각각에 대한 클래스가 존재할 확률 분포를 나타내는 데이터를 생성하는 분류 계층, 및 상기 고정된 크기의 특징으로부터 상기 적어도 하나의 제안 영역 각각에 대하여 복수의 타겟 레 퍼런스 각각을 정확히 감싸는 복수의 바운딩 박스의 위치를 정의하는 박스 리그레션 계층을 포함할 수 있다. 상기 세그멘테이션 탐지부는, 상기 전처리된 이미지로부터 특징 맵을 생성하는 백본 네트워크, 상기 특징 맵으 로부터 적어도 하나의 제안 영역을 도출하는 RPN 계층, 상기 특징 맵을 상기 적어도 하나의 제안 영역과 정렬시 켜 고정된 크기의 특징을 추출하는 ROI Align부, 상기 고정된 크기의 특징으로부터 상기 적어도 하나의 제안 영 역 각각에 대한 클래스가 존재할 확률 분포를 나타내는 데이터를 생성하는 분류 계층, 상기 고정된 크기의 특징 으로부터 상기 적어도 하나의 제안 영역 각각에 대하여 복수의 타겟 레퍼런스 각각을 정확히 감싸는 복수의 바 운딩 박스의 위치를 정의하는 박스 리그레션 계층, 및 상기 고정된 크기의 특징으로부터 모든 픽셀에 클래스가 존재할지를 예측하여 마스크를 생성하는 마스크 브런치를 포함할 수 있다. 발명의 또 다른 특징에 따른 컴퓨터 프로그램을 저장한 컴퓨터 판독가능 저장 매체는, 적어도 하나의 프로세서 에 의해 수행되는 사이드 아우터 추출 방법에 있어서, 영역 탐지 서버가, 캐드 모듈로부터 3차원 데이터로부터 전처리된 이미지를 수신하는 단계, 상기 영역 탐지 서버가, 인공지능 모델로 상기 전처리된 이미지로부터 검출 하고자 하는 복수의 타겟 레퍼런스 각각에 대응하는 복수의 영역 각각에 대한 분류 값 및 바운딩 박스(bounding box)를 검출하는 단계, 상기 영역 탐지 서버가, 상기 복수의 영역 각각에 대한 분류 값 및 바운딩 박스를 나타 내는 신호를 상기 캐드 모듈에 전송하는 단계, 및 상기 캐드 모듈이, 수신한 신호에 기초하여 상기 복수의 영역 각각에 대한 분류 값 및 바운딩 박스로부터 상기 복수의 타겟 레퍼런스를 추출하는 단계를 포함하는 사이드 아 우터 추출 방법을 수행하기 위한 제어 명령을 포함할 수 있다. 발명의 또 다른 특징에 따른 사이드 아우터 추출 시스템은, 적어도 하나의 제1 프로그램을 실행하기 위한 제1 명령어들을 저장하는 제1 메모리 및 상기 제1 명령어들을 실행하는 적어도 하나의 제1 프로세서를 포함하는 영 역 탐지 서버, 및 적어도 하나의 제2 프로그램을 실행하기 위한 제2 명령어들을 저장하는 제2 메모리 및 상기 제2 명령어들을 실행하는 적어도 하나의 제2 프로세서를 포함하는 캐드 모듈을 포함하고, 상기 적어도 하나의 제2 프로세서가 상기 적어도 하나의 제2 프로그램에 따라 차량에 대한 3차원 데이터로부터 렌더링 이미지를 추 출하고, 상기 렌더링 이미지로부터 전처리 이미지를 생성하며, 관리 단말로부터 수신한 신호에 기초하여 학습 데이터셋을 생성하여 상기 영역 탐지 서버에 전송한다. 상기 적어도 하나의 제1 프로세서는, 상기 적어도 하나의 제1 프로그램에 따라 상기 학습 데이터셋으로 상기 전 처리 이미지로부터 검출하고자 하는 복수의 타겟 레퍼런스 각각에 대응하는 복수의 영역 각각을 검출하는 인공 지능 모델을 학습시킬 수 있다. 상기 적어도 하나의 제1 프로세서는, 상기 학습된 인공지능 모델을 이용하여 상기 복수의 영역 각각을 검출하며, 상기 적어도 하나의 제2 프로세서는, 상기 적어도 하나의 상기 제2 프로그램에 따라 상기 복수의 영 역 각각으로부터 상기 복수의 타겟 레퍼런스 각각을 추출할 수 있다."}
{"patent_id": "10-2022-0148377", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명을 통해 3차원 데이터로부터 인공지능 학습에 필요한 이미지 데이터를 생성하고, 이미지 데이터로부터 추출할 라인 레퍼런스와 연관이 있는 영역을 검출하며, 검출된 영역을 이용하여 라인 레퍼런스를 추출하여, 라 인 추출 과정의 자동화로 작업의 정확도를 향상시키고, 라인 추출의 품질을 작업자의 능력에 관계없이 균일하게 할 수 있다."}
{"patent_id": "10-2022-0148377", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 첨부된 도면을 참조하여 본 명세서에 개시된 실시예를 상세히 설명하되, 동일하거나 유사한 구성요소에는 동일, 유사한 도면부호를 부여하고 이에 대한 중복되는 설명은 생략하기로 한다. 이하의 설명에서 사용되는 구 성요소에 대한 접미사 \"모듈\" 및/또는 \"부\"는 명세서 작성의 용이함만이 고려되어 부여되거나 혼용되는 것으로 서, 그 자체로 서로 구별되는 의미 또는 역할을 갖는 것은 아니다. 또한, 본 명세서에 개시된 실시예를 설명함 에 있어서 관련된 공지 기술에 대한 구체적인 설명이 본 명세서에 개시된 실시예의 요지를 흐릴 수 있다고 판단 되는 경우 그 상세한 설명을 생략한다. 또한, 첨부된 도면은 본 명세서에 개시된 실시예를 쉽게 이해할 수 있도 록 하기 위한 것일 뿐, 첨부된 도면에 의해 본 명세서에 개시된 기술적 사상이 제한되지 않으며, 본 발명의 사 상 및 기술 범위에 포함되는 모든 변경, 균등물 내지 대체물을 포함하는 것으로 이해되어야 한다. 제1, 제2 등과 같이 서수를 포함하는 용어는 다양한 구성요소들을 설명하는데 사용될 수 있지만, 상기 구성요소 들은 상기 용어들에 의해 한정되지는 않는다. 상기 용어들은 하나의 구성요소를 다른 구성요소로부터 구별하는 목적으로만 사용된다. 본 출원에서, \"포함한다\" 또는 \"가지다\" 등의 용어는 명세서상에 기재된 특징, 숫자, 단계, 동작, 구성요소, 부 품 또는 이들을 조합한 것이 존재함을 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성요소, 부품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되 어야 한다. 일 실시예에 따른 구성들 중 특정 제어 조건에서 다른 구성을 제어하는 구성에는, 다른 구성을 제어하기 위해 필요한 제어 알고리즘을 구체화한 명령어의 집합으로 구현된 프로그램이 설치될 수 있다. 제어 구성은 설치된 프로그램에 따라 입력 데이터 및 저장된 데이터를 처리하여 출력 데이터를 생성할 수 있다. 제어 구성은 프로그 램을 저장하는 비휘발성 메모리 및 데이터를 저장하는 메모리를 포함할 수 있다. 도 1은 일 실시예에 따른 사이드 아우터 추출 시스템 및 CAD 시스템의 구성을 도식적으로 나타낸 블록도이다. 추출 시스템은, 차량에 대한 3차원 데이터로부터 이미지를 전처리하고, 전처리한 이미지와 인공지능 모델로 전처리한 이미지로부터 차량의 사이드 아우터(Side-Outer) 라인의 레퍼런스와 연관이 있는 영역을 검출하며, 검 출된 영역을 이용하여 라인을 추출할 수 있다. 인공지능 모델은 학습 데이터셋을 이용한 학습을 통해 구현될 수있다. 사이드 아우터는, 차량의 측면을 구성하는 외판재를 나타낼 수 있다. 예를 들어, 3차원 데이터는, 차량의 사이드 아우터를 포함하는 CAD 데이터일 수 있다. 추출 시스템은 차량으로부터 복수의 라인을 가리키는 레 퍼런스들을 검출할 수 있다. 추출 시스템은 차량의 사이드 아우터 추출을 위한 복수의 단계들을 수행하기 위 한 제어 명령들로 구성된 프로그램(이하, 사이드 아우터 추출 프로그램)을 실행할 수 있다. 사이드 아우터 추출 프로그램은 컴퓨터로 판독 가능하고, 추출 시스템은 아우터 추출 프로그램을 저장한 기록 매체를 포함하는 저장부를 포함할 수 있다. 도 1에 도시된 추출 시스템의 구성들 각각은 추출 시스템이 사이드 아우터 추 출 프로그램을 실행할 때 수행되는 단계들 각각에 기초하여 정의될 수 있다. 복수의 타겟 레퍼런스는, 차량으로부터 검출하고자 하는 각 라인을 가리키는 레퍼런스들을 나타낼 수 있다. 예 를 들어, 복수의 타겟 레퍼런스는, 차량 주유구 라인을 지시하는 제1 타겟 레퍼런스, 차량 루프부 라인을 지시 하는 제2 타겟 레퍼런스, 차량 뒷 좌석의 사이드도어 경계 라인을 지시하는 제3 타겟 레퍼런스, 뒷 좌석의 테일 램프 경계 라인을 지시하는 제4 타겟 레퍼런스, 차량 백 램프의 사이드도어 경계 라인을 지시하는 제5 타겟 레 퍼런스, 차량 앞 좌석의 사이드도어 쪽의 가장 두꺼운 중심 면의 라인을 지시하는 제6 타겟 레퍼런스, 및 차량 뒷 좌석의 사이드도어 쪽의 가장 두꺼운 중심 면의 라인을 지시하는 제7 타겟 레퍼런스를 포함할 수 있다. 이하, 설명의 편의를 위해 복수의 타겟 레퍼런스는 예시의 제1 타겟 레퍼런스 내지 제7 타겟 레퍼런스인 것으로 한다. 추출 시스템은 이미지 데이터로부터 특정한 형상을 가진 복수의 타겟 레퍼런스에 대응하는 복수의 영역(이하, 복수의 영역)에 대해 박스 라벨링(box labeling) 또는 세그멘테이션 라벨링(segmentation labeling)하여 Object detection 및 Instance Segmentation 모델로 학습을 한다. 추출 시스템은, 학습된 모 델을 이용하여 이미지 데이터로부터 복수의 영역을 예측한 후에 복수의 영역 각각으로부터 각 타겟 레퍼런스를 검출할 수 있다. 이와 같이 본 발명은 차량으로부터 복수의 타겟 레퍼런스를 사람이 직접 검출하는 종래 방식과 다르다. 추출 시스템은, 영역 탐지 서버, 캐드 모듈, 및 관리 단말을 포함할 수 있다. 캐드 모듈은 CAD(Computer Aid Design) 시스템으로, CATIA 프로그램 등의 3차원 모델링 시스템으로 구현될 수 있다. 영역 탐지 서버, 캐드 모듈, 및 관리 단말 각각은, 프로그램을 실행하기 위한 인스트럭션(명령어) 을 저장하는 메모리 및 상기 인스트럭션을 실행하는 적어도 하나의 프로세서(processor)를 포함하는 컴퓨팅 장 치일 수 있다. 이하에서 영역 탐지 서버, 캐드 모듈, 및 관리 단말 각각의 동작은, 적어도 하나의 처리기 각각의 동작일 수 있다. 예를 들어, 적어도 하나의 처리기는, CPU, AP, DSP(Digital Signal Processor) 등과 같은 범용 프로세서, GPU, VPU(Vision Processing Unit)와 같은 그래픽 전용 프로세서 또는 NPU와 같은 인공지능 전용 프로세서일 수 있다. 적어도 하나의 처리기는, 메모리에 저장된 기 정의된 동작 규칙 또는 인공 지능 모델에 따라, 입력 데이터를 처리하도록 제어한다. 또는, 적어도 하나의 처리기가 인공지능 전용 프로세서 인 경우, 인공지능 전용 프로세서는, 특정 인공지능 모델의 처리에 특화된 하드웨어 구조로 설계될 수 있다. 영역 탐지 서버는, 적어도 하나의 제1 프로그램을 실행하기 위한 제1 명령어들을 저장하는 제1 메모리 및 제1 명령어들을 실행하는 적어도 하나의 제1 프로세서를 포함하는 컴퓨팅 장치일 수 있다. 적어도 하나의 제1 프로세서는 적어도 하나의 제1 프로그램에 따라 후술할 영역 탐지 서버의 동작을 수행할 수 있다. 캐드 모듈은, 적어도 하나의 제2 프로그램을 실행하기 위한 제2 명령어들을 저장하는 제2 메모리 및 상기 제2 명령어들을 실행하는 적어도 하나의 제2 프로세서를 포함하는 컴퓨팅 장치일 수 있다. 적어도 하나의 제2 프로세서는 적어도 하나의 제2 프로그램에 따라 후술할 캐드 모듈의 동작을 수행할 수 있다. 캐드 모듈은 3차원 데이터로부터 전처리 이미지 및 전처리 이미지에 대한 학습 데이터셋을 생성하여, 전처 리 이미지 및 학습 데이터셋을 영역 탐지 서버에 송신할 수 있다. 영역 탐지 서버는, 캐드 모듈로 부터 전처리 이미지 및 학습 데이터셋(training dataset)을 수신하고, 학습 데이터셋을 통해 전처리 이미지로부 터 복수의 타겟 레퍼런스에 대응하는 복수의 영역(이하, 복수의 영역)을 추출하는 방법을 학습할 수 있다. 복수의 영역은, 복수의 타겟 레퍼런스 각각에 대응하는 영역일 수 있다. 예를 들어, 복수의 영역은 제1 타겟 레 퍼런스를 검출하기 위해 인공지능 모델이 예측해야 하는 차량 주유구 부근의 영역을 지시하는 제1 영역, 제2 타겟 레퍼런스를 검출하기 위해 인공지능 모델이 예측해야 하는 차량 루프부 부근의 T자 모양의 영역 을 지시하는 제2 영역, 제3 타겟 레퍼런스를 검출하기 위해 인공지능 모델이 예측해야 하는 차량 뒷 좌석 의 사이드도어 경계와 주유구 부근의 영역 사이에 빈 영역을 지시하는 제3 영역, 제4 타겟 레퍼런스를 검출하기 위해 인공지능 모델이 예측해야 하는 차량 뒷 좌석의 테일 램프와 후방 펜더 사이에 빈 영역을 지시하는제4 영역, 제5 타겟 레퍼런스를 검출하기 위해 인공지능 모델이 예측해야 하는 차량 백 램프의 사이드도어 경계와 주유구 부근의 영역 사이에 빈 영역을 지시하는 제5 영역, 제6 타겟 레퍼런스를 검출하기 위해 인공지능 모델이 예측해야 하는 차량 앞 좌석의 사이드도어 쪽의 가장 두꺼운 중심 면의 왼쪽 및 오른쪽 영역 각각 을 지시하는 제6-1 영역 및 제6-2 영역, 그리고 제7 타겟 레퍼런스를 검출하기 위해 인공지능 모델이 예측 해야 하는 차량 뒷 좌석의 사이드도어 쪽의 가장 두꺼운 중심 면의 왼쪽 및 오른쪽 영역 각각을 지시하는 제7-1 영역 및 제7-2 영역을 포함할 수 있다. 이하, 설명의 편의를 위해 복수의 영역은 예시의 제1 영역 내지 제5 영 역, 제6-1 영역, 제6-2 영역, 제7-1 영역, 및 제7-2 영역인 것으로 한다. 영역 탐지 서버는, 통신부 및 인공지능 모델을 포함할 수 있다. 통신부는, 전처리부로부터 전처리 이미지를 수신하고, 학습 데이터셋 생성부로부터 학습 데이터 셋을 수신하며, 인공지능 모델이 추출한 복수의 영역을 나타내는 데이터를 레퍼런스 매핑부에 송신할 수 있다. 인공지능 모델은, 학습 데이터셋으로 전처리 이미지로부터 복수의 영역을 추출하는 방법을 학습할 수 있다. 캐드 모듈은, 3차원 데이터로부터 렌더링 이미지를 추출하고, 렌더링 이미지를 전처리한 전처리 이미지를 영역 탐지 서버에 전달하고, 전처리 이미지로부터 학습 데이터셋을 생성하며, 복수의 영역 각각으로부터 복 수의 타겟 레퍼런스 각각을 검출할 수 있다. 캐드 모듈은, 전처리부, 학습 데이터셋 생성부, 및 레퍼런스 매핑부를 포함할 수 있다. 캐드 모듈은, 네트워크를 통해 관리 단말과 유무선 통신하여 데이터를 서로 주고받을 수 있다. 관리 단말에는 어플리케이션이 설치되어 있을 수 있다. 캐드 모듈로부터 관리 단말에 수신된 신호는 관리 단말의 어플리케이션 프로세서(application processor, AP)에 의해 정보로 처리되고, AP는 해 당 정보를 일 실시예에 따른 어플리케이션에 전달할 수 있다. 어플리케이션은 AP로부터 수신되는 정 보에 기초하여 연산을 수행하고, 수행된 연산 결과를 관리 단말에 표시하거나, 관리 단말을 통해 캐드 모듈에 송신되도록 할 수 있다. 전처리부는, 3차원 데이터로부터 렌더링 이미지를 추출하고, 전처리 이미지를 영역 탐지 서버에 전달 할 수 있다. 전처리부는, 영역 탐지 서버로부터 사이드 아우터 추출의 시작 요청 신호를 수신하면, 3 차원 데이터로부터 사이드 아우터를 정면으로 오도록 하는 렌더링 이미지를 추출하고, 렌더링 이미지로부터 전 처리 이미지를 생성할 수 있다. 캐드 모듈은, 관리 단말을 통해 어플리케이션에 일 실시예에 따른 인공지능 학습 데이터셋 생성을 시작할지를 문의하는 신호를 송신할 수 있다. 어플리케이션은, 관리 단말을 통해 인공지능 학습 데이 터셋 생성 요청을 가리키는 신호를 입력 받을 수 있다. 예를 들어, 관리자는, 관리 단말의 화면에 나타난 GUI를 통해 인공지능 학습 데이터셋 생성을 나타내는 \"생성(Training Gen.)\" 버튼을 눌러 인공지능 학습 데이터 셋 생성 요청 신호를 입력할 수 있다. 전처리부는, 인공지능 학습 데이터셋 생성 요청에 대한 응답으로 전 처리 이미지를 생성하고, 영역 탐지 서버에 전달할 수 있다. 전처리부는, 사이드 아우터 추출의 시작 요청에 대한 응답으로 렌더링 이미지를 생성할 수 있다. 전처리부는, 렌더링 이미지의 각도를 미리 결정된 초기 정보로 결정할 수 있다. 전처리부는, 렌더링 이미지로부터 배경 및/또는 제품의 색상을 변경하거나, 라인의 색상 및/또는 두께를 변경하거나, 또는 음영을 조정한 이미지를 전처리 이미지로 결정할 수 있다. 예를 들어, 전처리부는, 인공지능 모델에 학습의 주요 요소가 아닌 배경색을 기존 색인 보라색(Purple)에 서 흰 색(White)으로 변경하고, 타겟 라인을 기존 색인 파란색(Blue)에서 흰색으로 변경한다. 전처리부는, 학습에 필요 없고, 추출되는 이미지마다 다르게 표시되어 학습에 방해가 될 수 있는 요소인 배경의 트리 및 좌 표계를 삭제한다. 이처럼 전처리부는, 정답이 되는 타겟 라인에 색상을 입힌다. 인공지능 모델은, 전처리부가 색 상을 입힌 부분을 타겟 라인 레퍼런스로 인식하도록 학습할 수 있다. 타겟 라인의 두께가 충분히 두껍지 않으면, 이미지의 해상도에 따라 끊김 현상이 발생할 수 있다. 타겟 라인이 끊기면, 인공지능 모델이 학습할 때, 끊긴 라인들을 같은 라인에 속하는 것으로 인식하지 못할 수 있다. 따라서 전처리부는, 타겟 라인의 두께를 일정 수준 이상의 소정의 두께로 설정할 수 있다. 예를 들어, 전처리부는, 타겟 라인의 두께를 0.13mm 내지 2.6mm로 설정한다. 전처리부는, 렌더링 이미지로부터 인공지능 학습에 주요 요소가 아닌 제품 음영 설정을 조절하여 균일한 음영으로 설정할 수 있다. 통신부는 전처리부로부터 전처리 이미지를 수신할 수 있다. 학습 데이터셋 생성부는, 전처리 이미지로부터 복수의 영역을 탐지하는 인공지능 모델을 학습시키기 위한 정답 데이터인 학습 데이터셋을 생성할 수 있다. 학습 데이터셋은, 전처리 이미지의 복수의 영역에 위치 및 분류가 각각 라벨링된 데이터일 수 있다. 학습 데이터셋 생성부는, 관리 단말에 전처리 이미지를 전달할 수 있다. 관리 단말은, 전처리 이 미지에 복수의 영역 각각에 대한 위치 값 및 분류 값 각각을 나타내는 데이터를 학습 데이터셋 생성부에 전달할 수 있다. 위치 값은, 전처리 이미지 중 해당 영역이 차지하는 픽셀을 식별할 수 있는 정보를 포함하고, 분류 값은, 해당 영역이 복수의 타겟 레퍼런스 중 어느 것에 대응하는 영역인지를 나타내는 정보를 포함할 수 있다. 학습 데이터셋 생성부는, 관리 단말을 통해 어플리케이션에 전처리 이미지를 제공할 수 있고, 어 플리케이션은, 관리자로부터 전처리 이미지의 복수의 영역에 대한 위치 값 및 분류 값 각각을 나타내는 데 이터를 입력 받을 수 있다. 예를 들어, 관리자는, 관리 단말의 입력부를 통해 전처리 이미지 상에 박스 형 태의 영역을 선택하고, 해당 영역이 나타내는 분류를 입력할 수 있다. 어플리케이션은, 관리 단말을 통해 전처리 이미지의 복수의 영역 중 일부 영역 각각에 대한 위치 정보 를 박스 형태로 입력 받을 수 있다. 이하, 복수의 영역 중 어플리케이션이 입력 받은 박스 형태의 위치 정 보에 대응하는 일부 영역을 복수의 박스 영역이라 한다. 어플리케이션은, 복수의 박스 영역 각각에 대한 위치 및 분류를 입력 받기 위해 레이블링 툴을 이용할 수 있다. 예를 들어, 레이블링 툴은, \"Labelimg\"일 수 있 다. 복수의 박스 영역 각각에는, 복수의 박스 영역으로 검출해야 하는 복수의 타겟 레퍼런스(이하, 복수의 박 스 타겟 레퍼런스) 각각을 지시하는 위치가 포함될 수 있다. 예를 들어, 제1 영역은, 제1 타겟 레퍼런스가 지시 하는 차량 주유구 위치를 포함하는 영역일 수 있다. 어플리케이션은, 관리 단말을 통해 전처리 이미지의 복수의 영역 중 복수의 박스 영역과 다른 일부 영 역 각각에 대한 위치 정보를 세분화된(Segmentation) 형태로 입력 받을 수 있다. 이하, 복수의 영역 중 어플리 케이션이 입력 받은 세분화된 형태의 위치 정보에 대응하는 일부 영역을 복수의 세그멘테이션 영역이라 한 다. 어플리케이션은, 관리자가 검출해야 하는 영역을 소정의 색상으로 표시한 이미지 데이터를 복수의 세 그멘테이션 영역으로 입력 받을 수 있다. 예를 들어, 관리자는, 전처리 이미지 중 복수의 세그멘테이션 영역으 로 검출해야 하는 복수의 타겟 레퍼런스(이하, 복수의 세그멘테이션 타겟 레퍼런스) 각각을 서로 다른 색으로 칠하여 어플리케이션에 입력할 수 있다. 복수의 세그멘테이션 영역 각각은, 세그멘테이션 영역에 대응하는 하나의 타겟 레퍼런스가 지시하는 위치 중 일부를 포함할 수 있다. 예를 들어, 제6-1 영역은, 제6 타겟 레퍼런 스가 지시하는 차량 앞 좌석의 사이드도어 쪽의 가장 두꺼운 중심 면의 라인 중 왼쪽 영역을 포함할 수 있다. 관리 단말은, 전처리 이미지의 복수의 영역에 대한 위치 값 및 해당 위치의 분류 값 각각을 가리키는 신호 를 캐드 모듈에 송신할 수 있다. 학습 데이터셋 생성부는, 관리 단말로부터 수신한 신호에 기초하여 학습 데이터셋을 생성할 수 있다. 구체적으로, 학습 데이터셋에서, 복수의 박스 영역 각각은 박스 형태 영역의 위치를 지시하는 위치 레이블과 해 당 영역에 대응하는 분류를 지시하는 분류 레이블로 라벨링 되고, 복수의 세그멘테이션 영역 각각은 박스 형태 가 아닌 세분화된 형태 영역의 픽셀 위치를 지시하는 위치 레이블과 해당 영역에 대응하는 분류를 지시하는 분 류 레이블로 라벨링될 수 있다. 캐드 모듈은, 관리 단말을 통해 어플리케이션에 일 실시예에 따른 사이드 아우터 추출을 시작할지 를 문의하는 신호를 송신할 수 있다. 어플리케이션은, 관리 단말을 통해 사이드 아우터 추출 요청을 가리키는 신호를 입력 받을 수 있다. 예를 들어, 관리자는, 관리 단말의 화면에 나타난 그래픽 사용자 인터 페이스(Graphic User Interface, GUI)를 통해 디렉토리, 해상도, 가상 환경 명을 입력한 후 사이드 아우터 추출 시작을 나타내는 \"추출(Prediction)\" 버튼을 눌러 사이드 아우터 추출 요청 신호를 입력할 수 있다. 캐드 모듈 은, 사이드 아우터 추출 요청 신호를 영역 탐지 서버에 전달할 수 있다. 인공지능 모델은, 학습 데이터셋을 통해 전처리 이미지로부터 각 복수의 영역을 검출하는 방법을 학습할 수 있다. 이하, 복수의 박스 영역의 위치를 지시하는 위치 레이블과 해당 영역에 대응하는 분류를 지시하는 분류 레이블 로 라벨링된 데이터를 박스 레이블 데이터, 세그멘테이션 영역의 픽셀 위치를 지시하는 위치 레이블과 해당 영 역에 대응하는 분류를 지시하는 분류 레이블로 라벨링된 데이터를 세그멘테이션 레이블 데이터라 한다. 예를 들 어, 제1 내지 제5 영역 각각은 박스 레이블 데이터이고, 제6-1 영역, 제6-2 영역, 제7-1 영역, 및 제7-2 영역 각각은 세그멘테이션 레이블 데이터일 수 있다. 통신부는 학습 데이터셋 생성부로부터 학습 데이터셋을 수신할 수 있다. 인공지능 모델은, 박스 탐지부 및 세그멘테이션 탐지부를 포함할 수 있다. 박스 탐지부는, 박스 레이블 데이터를 통해 전처리 이미지로부터 박스 레이블 데이터 각각에 대응하는 타 겟 레퍼런스를 검출하는 인공지능 모델일 수 있다. 박스 탐지부는, 박스 레이블 데이터를 학습 데이터로 하는 Faster R-CNN 모델로 구현될 수 있다. 이하, 도 2를 참조하여 박스 탐지부의 세부 구성 별 동작을 설명한다. 도 2는 도 1의 박스 탐지부의 세부 구성을 도식적으로 나타낸 블록도이다. 박스 탐지부는, 백본 네트워크(Backbone Network) 계층(layer), RPN(Region Proposal Network) 계층, ROI(Region Of Interest) 풀링부, 분류 계층(Classification layer), 및 박스 리 그레션 계층(Box-Regression Layer)을 포함할 수 있다. 백본 네트워크 계층은, 입력 이미지(D11)로부터 특징 맵(D12)을 추출할 수 있다. 여기서 입력 이미지 (D11)는, 전처리 이미지일 수 있다. 백본 네트워크 계층은, 입력 이미지(D11)가 갖고 있는 다양한 의미 (semantics)를 검출하여 입력 이미지(D11)를 특징 맵(feature map)(D12)으로 변형시킬 수 있다. 백본 네트워크 계층에는 전처리 이미지가 입력 이미지(D11)로, 박스 레이블 데이터가 학습 데이터로 입력될 수 있다. 백본 네트워크 계층은, 합성곱 신경망(Convolutional Neural Network, CNN)으로 구현될 수 있다. RPN 계층은, 특징 맵(D12)으로부터 타겟 레퍼런스가 있을 법한 위치의 제안 영역(Region Proposal)(D13)을 선별할 수 있다. RPN 계층에는, 특징 맵(D12)이 입력될 수 있다. RPN 계층은, 타겟 레퍼런스가 있을 법한 위치들을 제안 영역(D13)으로 출력할 수 있다. RPN 계층은, 특징 맵(D12)에 컨볼루션 연산을 수행하여 중간 특징 맵(intermediate feature map)을 생성할 수 있다. RPN 계층은, 중 간 특징 맵에 대해 대해 1*1 컨볼루션을 수행하여 제안 영역(D13) 별로 2개의 출력 값을 도출할 수 있다. 여기 서 2개의 출력 값은, 분류 계층이 객체의 존재를 예측하기 위한 값과 박스 리그레션 계층이 객체 의 위치를 예측하기 위한 값일 수 있다. RPN 계층은, 컨볼루션 연산을 수행함에 있어서 k개(k는 자연수)의 앵커 박스(anchor box)를 생성할 수 있다. k개의 앵커 박스 각각은, 앵커 박스의 가로-세로 비율 및/또는 앵커의 크기가 서로 다를 수 있다. 앵커 박스는, 네트워크가 감지할 객체의 형태(shape)를 가정하기 위한 박스 형태의 영역일 수 있다. RPN 계층(1121 2)은, 특징 맵(D12)으로부터 관심 영역(D13)을 선별하는 방법을 end-to-end로 학습할 수 있다. RPN 계층 은, k개의 앵커 박스 마다 제안 영역(D13)에 대한 값들을 도출할 수 있다. 예를 들어, RPN 계층 은, 분류(classification) 예측 값을 얻기 위하여 Softmax 함수를 통해 각 앵커 박스가 타겟 레퍼런스일 확률을 classification loss 값으로 출력할 수 있다. 또한 RPN 계층은, bounding box regression(BBR) 예측 값 을 얻기 위하여 앵커 박스들을 리그레션(regression)하여 각 앵커 박스로 얻은 후보 바운딩 박스(Bounding Box Proposal)들의 4개 좌표를 표현할 수 있는 값들을 출력할 수 있다. 후보 바운딩 박스 각각의 4개 좌표는, 후보 바운딩 박스의 위치 및 크기를 나타내기 위한 좌표일 수 있다. 예를 들어, 후보 바운딩 박스 각각의 4개 좌표는, 중심 점의 x좌표 값, 중심 점의 y좌표 값, 박스의 너비 값, 및 박스의 높이 값일 수 있다. RPN 계층 이 출력하는 제안 영역(D13)에 대한 데이터는, 제안 영역(D13)에 대한 classification loss 값 및 제안 영역(D13)에 대한 후보 바운딩 박스의 4개 좌표를 포함할 수 있다. ROI 풀링부는, 제안 영역(D13)으로부터 특징 맵(D12)을 고정된 크기의 특징(warped feature)(D14)으로 풀링할 수 있다. ROI 풀링부는, 백본 네트워크 계층으로부터 특징 맵(D12)을 입력 받고, RPN 계 층으로부터 제안 영역(D13)에 대한 데이터를 입력 받을 수 있다. ROI 풀링부는, 서로 다른 크기 를 갖는 ROI 특징에 해당하는 부분을 max-pooling하여 특징 맵으로부터 고정된 크기의 특징(D14)을 출력할 수 있다. 분류 계층은, 고정된 크기의 특징(D14)으로부터 복수의 박스 영역 중 대응하는 영역의 클래스를 분류할 수 있다. 클래스는, 복수의 타겟 레퍼런스 각각을 지시하는 구분 중 하나일 수 있다. 분류 계층은, 제안 영역(D13)에 대한 클래스가 존재할 확률 분포를 나타내는 데이터를 생성할 수 있다. 분류 계층은, 고정 된 크기의 특징으로부터 classification loss를 도출할 수 있다. 분류 계층은, classification loss에 기초하여 객체가 타겟 레퍼런스와 동일한 분류에 해당하는 것으로 판단할 수 있다. 박스 리그레션 계층은, 고정된 크기의 특징(D14)으로부터 타겟 레퍼런스가 존재하는 것으로 보이는 바운 딩 박스의 위치를 예측할 수 있다. 박스 리그레션 계층은, 고정된 크기의 특징으로부터 바운딩 박스 리 그레션 loss를 도출할 수 있다. 박스 리그레션 계층은, 제안 영역(D13)에 대하여 바운딩 박스 리그레션 loss에 기초하여 바운딩 박스 각각이 복수의 타겟 레퍼런스 각각을 정확히 감싸도록 바운딩 박스의 위치를 재정 의할 수 있다. 세그멘테이션 탐지부는, 세그멘테이션 레이블 데이터를 통해 전처리 이미지로부터 세그멘테이션 레이블 데이터 각각에 대응하는 타겟 레퍼런스를 검출하는 인공지능 모델일 수 있다. 세그멘테이션 탐지부는, 세 그멘테이션 레이블 데이터를 학습 데이터로 하는 MASK R-CNN 모델로 구현될 수 있다. 이하, 도 3을 참조하여 세 그멘테이션 탐지부의 세부 구성 별 동작을 설명한다. 도 3은 도 1의 세그멘테이션 탐지부의 세부 구성을 도식적으로 나타낸 블록도이다. 세그멘테이션 탐지부는, 백본 네트워크 계층, RPN 계층, ROI Align부, 분류 계층 , 박스 리그레션 계층 , 및 마스크 브런치(Mask branch)를 포함할 수 있다. 세그멘테이션 탐지부에 대한 설명 중 박스 탐지부의 동작과 중복되는 설명은 이하 생략할 수 있다. 백본 네트워크 계층은, 입력 이미지(D21)로부터 특징 맵(D22)을 추출할 수 있다. RPN 계층은, 특징 맵(D22)으로부터 타겟 레퍼런스가 있을 법한 위치들을 제안 영역(D23)으로 선별할 수 있다. ROI Align부는, 특징 맵(D23) 및 제안 영역(D23)으로부터 고정된 크기의 특징(D24)을 출력할 수 있다. ROI Align부는, 추출된 특징을 관심 영역(D23)과 정렬(align)시켜 이중 선형 보간법(bilinear interpolation)을 사용하여 고정된 크기의 특징(D24)을 출력할 수 있다. ROI Align부는, ROI 영역이 여 러 픽셀에 걸쳐 있는 경우, 이중 선형 보간법을 이용하여 여러 픽셀들을 모두 반영할 수 있도록 하는 점에서 픽 셀 단위로 풀링하는 ROI 풀링부와 차이가 있다. 분류 계층은, 고정된 크기의 특징(D24)으로부터 복수의 박스 영역 중 대응하는 영역의 클래스를 분류할 수 있다. 박스 리그레션 계층은, 고정된 크기의 특징(D24)으로부터 타겟 레퍼런스가 존재하는 것으로 보이는 바운 딩 박스의 위치를 예측할 수 있다. 마스크 브런치는, 고정된 크기의 특징(D24)에서의 모든 픽셀에 대하여 클래스가 존재할 것 같은지를 예 측하여 마스크(mask)를 생성할 수 있다. 마스크 브런치는, 클래스에 관계없이 타겟 레퍼런스인지 아닌지 만 구분하는 이진(binary) 마스크를 예측할 수 있다. 마스크 브런치는, FCN(Fully Connected Network) 기반으로 구현될 수 있다. 통신부는 박스 탐지부 및 세그멘테이션 탐지부 각각이 생성한 복수의 영역을 지시하는 신호를 레퍼런스 매핑부에 전달할 수 있다. 이하, 도 4를 참조하여 본 발명의 일 실시예에 따른 사이드 아우터 추출 방법의 각 단계를 설명한다. 도 4는 일 실시예에 따른 사이드 아우터 추출 방법의 순서도이다. 전처리부는, 3차원 데이터로부터 전처리한 이미지(이하, 전처리 이미지)를 생성할 수 있다(S1). 전처리부 는, 3차원 데이터로부터 렌더링 이미지를 추출하고, 렌더링 이미지를 전처리한 전처리 이미지를 생성하여 영역 탐지 서버에 송신할 수 있다. 전처리 이미지는, 관리 단말에 전달될 수 있다. 캐드 모듈은, 관리 단말을 통해 어플리케이션에 전처리 이미지를 제공할 수 있다(S2). 관리자는, 관리 단말을 통해 어플리케이션에 복수의 영역 각각에 대한 위치 값 및 분류 값 각각을 나타내는 데이 터를 입력할 수 있다. 캐드 모듈은, 관리 단말로부터 전처리 이미지의 복수의 영역에 대한 위치 값 및 분류 값 각각을 가리키 는 신호를 수신할 수 있다(S3). 학습 데이터셋 생성부는, 관리 단말로부터 수신한 신호에 기초하여 학습 데이터셋을 생성할 수 있다 (S4). 인공지능 모델은, 학습 데이터셋으로 학습할 수 있다(S5). 인공지능 모델은, 학습 데이터셋으로 전처리 이미지로부터 각 복수의 영역을 검출하는 방법을 학습할 수 있다. 복수의 박스 타겟 레퍼런스는, 복수의 박스 영역 정보를 이용하여 검출될 수 있으므로, 박스 탐지부 는, Object Detection 모델로 복수의 박스 영역을 검출하는 방법을 학습할 수 있다. 예를 들어, 박스 탐 지부는, Faster R-CNN 모델로 구현될 수 있다. 백본 네트워크 계층, RPN 계층, ROI 풀링 부, 분류 계층, 및 박스 리그레션 계층 각각은, 복수의 박스 레이블 데이터를 학습 데이 터셋으로 하여 전처리 데이터로부터 복수의 박스 영역 각각을 검출하는 방법을 학습할 수 있다. 복수의 세그멘테이션 타겟 레퍼런스는, 복수의 세그멘테이션 영역 정보를 이용하여 검출될 수 있으므로, 세그멘 테이션 탐지부는, Instant Segmentation 모델로 복수의 세그멘테이션 영역을 검출하는 방법을 학습할 수 있다. 예를 들어, 세그멘테이션 탐지부는, Mask R-CNN 모델로 구현될 수 있다. 백본 네트워크 계층 , RPN 계층, ROI Align부, 분류 계층, 박스 리그레션 계층 , 및 마스크 브런치(Mask branch) 각각은, 복수의 세그멘테이션 레이블 데이터를 학습 데이터셋으로 하여 전처리 데 이터로부터 복수의 세그멘테이션 영역 각각을 검출하는 방법을 학습할 수 있다. 영역 탐지 서버는 학습된 인공지능 모델로 전처리 이미지로부터 각 복수의 영역을 검출할 수 있다 (S6). 박스 탐지부는, 적어도 하나의 제안 영역(D13) 각각에 대한 클래스가 존재할 확률 분포를 나타내는 데이 터 및 복수의 바운딩 박스의 위치에 기초하여, 복수의 박스 영역 각각에 대한 분류 값 및 타겟 바운딩 박스를 검출할 수 있다. 여기서 타겟 바운딩 박스는, 복수의 바운딩 박스 중 박스 타겟 레퍼런스가 존재하는 바운딩 박 스를 나타낼 수 있다. 세그멘테이션 탐지부는, 적어도 하나의 제안 영역(D23) 각각에 대한 클래스가 존재할 확률 분포를 나타내 는 데이터, 복수의 바운딩 박스의 위치, 및 마스크에 기초하여, 복수의 세그멘테이션 영역 각각에 대한 분류 값, 타겟 바운딩 박스, 및 타겟 바운딩 박스 중 세그멘테이션 타겟 레퍼런스가 존재하는 객체 마스크를 검출할 수 있다. 여기서 타겟 바운딩 박스는, 복수의 바운딩 박스 중 세그멘테이션 타겟 레퍼런스가 존재하는 바운딩 박스를 나타낼 수 있다. 레퍼런스 매핑부는, 학습된 인공지능 모델의 출력인 복수의 영역 각각으로부터 타겟 레퍼런스를 매핑 할 수 있다(S7). 레퍼런스 매핑부는, 검출할 타겟 레퍼런스의 종류에 따라 다른 알고리즘으로 매핑할 수 있다. 레퍼런스 매 핑부는, 바운딩 박스를 나타내는 사각형으로부터 하나의 라인을 타겟 레퍼런스로 추출하거나, 바운딩 박스 중 객체 마스크 형태로부터 하나의 라인을 타겟 레퍼런스로 추출할 수 있다. 이하, 도 5 내지 도 9를 참조하여, 레퍼런스 매핑부가 제1 영역 내지 제5 영역 각각으로부터 제1 타겟 레 퍼런스 내지 제5 타겟 레퍼런스 각각을 추출하는 동작을 설명한다. 도 5는 제1 영역으로부터 제1 타겟 레퍼런스를 매핑하는 동작을 설명하기 위한 예시도이다. 도 5를 참조하면, 박스 탐지부는, 점선의 사각형으로 도시한 제1 영역(R1)을 출력할 수 있다. 레퍼런스 매핑부는, 제1 영역(R1)의 위쪽 선분(L1)의 중심점(P1)에서 1픽셀씩 아래 방향으로 이동하면서 검은색 레 퍼런스를 클릭 해 나갔을 때, 두 번째로 클릭 가능한 라인을 제1 타겟 레퍼런스로 인식하고 추출할 수 있다. 도 6은 제2 영역으로부터 제2 타겟 레퍼런스를 매핑하는 동작을 설명하기 위한 예시도이다. 도 6을 참조하면, 박스 탐지부는, 점선의 사각형으로 도시한 제2 영역(R2)을 출력할 수 있다. 레퍼런스 매핑부는, 제2 영역(R2)의 위쪽 선분(L2)의 중심점(P2)에서 1픽셀씩 아래 방향으로 이동하면서 검은색 레 퍼런스를 클릭 해 나갔을 때, 2번째로 클릭 가능한 라인을 제2 타겟 레퍼런스로 인식하고 추출할 수 있다. 도 7은 제3 영역으로부터 제3 타겟 레퍼런스를 매핑하는 동작을 설명하기 위한 예시도이다. 도 7을 참조하면, 박스 탐지부는, 점선의 사각형으로 도시한 제3 영역(R3)을 출력할 수 있다. 레퍼런스 매핑부는, 제3 영역(R3)의 중심점(P3)에서 1픽셀씩 왼쪽 방향으로 이동하면서 검은색 레퍼런스를 클릭 해 나갔을 때, 2번째로 클릭 가능한 라인을 제3 타겟 레퍼런스로 인식하고 추출할 수 있다. 도 8은 제4 영역으로부터 제4 타겟 레퍼런스를 매핑하는 동작을 설명하기 위한 예시도이다. 도 8을 참조하면, 박스 탐지부는, 점선의 사각형으로 도시한 제4 영역(R4)을 출력할 수 있다. 레퍼런스 매핑부는, 제4 영역(R4)의 중심점(P4)에서 1픽셀씩 오른쪽 아래 방향으로 이동하면서 검은색 레퍼런스를 클릭 해 나갔을 때, 2번째로 클릭 가능한 라인을 제4 타겟 레퍼런스로 인식하고 추출할 수 있다. 도 9는 제5 영역으로부터 제5 타겟 레퍼런스를 매핑하는 동작을 설명하기 위한 예시도이다. 도 9를 참조하면, 박스 탐지부는, 점선의 사각형으로 도시한 제5 영역(R5)을 출력할 수 있다. 레퍼런스 매핑부는, 제5 영역(R5)의 중심점에서 1픽셀씩 오른쪽 방향으로 이동하면서 검은색 레퍼런스를 클릭 해 나 갔을 때, 2번째로 클릭 가능한 라인을 제5 타겟 레퍼런스로 인식하고 추출할 수 있다. 이하, 도 10 및 도 11을 참조하여, 레퍼런스 매핑부가 제6-1 영역, 제6-2 영역, 제7-1 영역, 및 제7-2 영 역 각각으로부터 제6 타겟 레퍼런스 및 제7 타겟 레퍼런스 각각을 추출하는 동작을 설명한다. 제6 타겟 레퍼런 스는 제6-1 타겟 레퍼런스와 제6-2 타겟 레퍼런스를 포함하고, 제7 타겟 레퍼런스는 제7-1 타겟 레퍼런스와 제 7-2 타겟 레퍼런스를 포함하는 것으로 나타낸다. 도 10은 제6-1 영역으로부터 제6-1 타겟 레퍼런스를 매핑하는 동작을 설명하기 위한 예시도이다. 도 10을 참조하면, 세그멘테이션 탐지부는, 제6-1 영역(R6-1)을 출력할 수 있다. 레퍼런스 매핑부는, 제6-1 영역(R6-1)의 무게중심에서 1픽셀씩 왼쪽 아래 방향으로 이동하면서 검은색 레퍼런스를 클릭 해 나갔을 때, 2번째로 클릭 가능한 라인을 제6-1 타겟 레퍼런스로 인식하고 추출할 수 있다. 또한, 세그멘테이션 탐지부는, 제7-1 영역을 출력할 수 있다. 같은 방식으로, 레퍼런스 매핑부는, 제7-1 영역의 무게중심에서 1픽셀씩 왼쪽 아래 방향으로 이동하면서 검은색 레퍼런스를 클릭 해 나갔을 때, 2번 째로 클릭 가능한 라인을 제7-1 타겟 레퍼런스로 인식하고 추출할 수 있다. 도 11은 제6-2 영역으로부터 제6-2 타겟 레퍼런스를 매핑하는 동작을 설명하기 위한 예시도이다. 도 10을 참조하면, 세그멘테이션 탐지부는, 제6-2 영역(R6-2)을 출력할 수 있다. 레퍼런스 매핑부는, 제6-2 영역(R6-2)의 무게중심에서 1픽셀씩 오른쪽 아래 방향으로 이동하면서 검은색 레퍼런스를 클릭 해 나갔을 때, 2번째로 클릭 가능한 라인을 제6-2 타겟 레퍼런스로 인식하고 추출할 수 있다. 또한, 세그멘테이션 탐지부는, 제7-2 영역을 출력할 수 있다. 같은 방식으로, 레퍼런스 매핑부는, 제7-2 영역의 무게중심에서 1픽셀씩 왼쪽 아래 방향으로 이동하면서 검은색 레퍼런스를 클릭 해 나갔을 때, 2번 째로 클릭 가능한 라인을 제7-2 타겟 레퍼런스로 인식하고 추출할 수 있다. 이처럼 레퍼런스 매핑부는 복수의 타겟 레퍼런스를 매핑할 수 있다. 레퍼런스 매핑부는, 복수의 타겟 레퍼런스를 나타내는 신호를 어플리케이션에 전달할 수 있다. 이상에서 본 발명의 실시예에 대하여 상세하게 설명하였으나, 본 발명의 권리범위가 이에 한정되는 것은 아니며 본 발명이 속하는 분야에서 통상의 지식을 가진 자가 여러 가지로 변형 및 개량한 형태 또한 본 발명의 권리범 위에 속한다."}
{"patent_id": "10-2022-0148377", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 일 실시예에 따른 사이드 아우터 추출 시스템 및 CAD 시스템의 구성을 도식적으로 나타낸 블록도이다. 도 2는 도 1의 박스 탐지부의 세부 구성을 도식적으로 나타낸 블록도이다. 도 3은 도 1의 세그멘테이션 탐지부의 세부 구성을 도식적으로 나타낸 블록도이다. 도 4는 일 실시예에 따른 사이드 아우터 추출 방법의 순서도이다. 도 5는 제1 영역으로부터 제1 타겟 레퍼런스를 매핑하는 동작을 설명하기 위한 예시도이다. 도 6은 제2 영역으로부터 제2 타겟 레퍼런스를 매핑하는 동작을 설명하기 위한 예시도이다. 도 7은 제3 영역으로부터 제3 타겟 레퍼런스를 매핑하는 동작을 설명하기 위한 예시도이다. 도 8은 제4 영역으로부터 제4 타겟 레퍼런스를 매핑하는 동작을 설명하기 위한 예시도이다. 도 9는 제5 영역으로부터 제5 타겟 레퍼런스를 매핑하는 동작을 설명하기 위한 예시도이다. 도 10은 제6-1 영역으로부터 제6-1 타겟 레퍼런스를 매핑하는 동작을 설명하기 위한 예시도이다. 도 11은 제6-2 영역으로부터 제6-2 타겟 레퍼런스를 매핑하는 동작을 설명하기 위한 예시도이다."}
