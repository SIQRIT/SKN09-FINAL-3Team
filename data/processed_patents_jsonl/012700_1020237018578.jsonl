{"patent_id": "10-2023-7018578", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0097157", "출원번호": "10-2023-7018578", "발명의 명칭": "개인화된 3D 헤드 모델 변형을 위한 방법 및 시스템", "출원인": "텐센트 아메리카 엘엘씨", "발명자": "류 쑹룬"}}
{"patent_id": "10-2023-7018578", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "3차원(three-dimensional, 3D) 헤드 변형 모델을 생성하는 컴퓨터 구현 방법으로서,2차원(two-dimensional, 2D) 얼굴 이미지를 수신하는 단계;인공 지능(artificial intelligence, AI) 모델에 기초하여 상기 2D 얼굴 이미지에서 제1 키포인트 세트를 식별하는 단계;3D 헤드 템플릿 모델에 위치된 사용자 제공 키포인트 주석 세트에 기초하여 상기 3D 헤드 템플릿 모델의 메시(mesh)의 복수의 정점에 위치된 제2 키포인트 세트에 상기 제1 키포인트 세트를 매핑하는 단계;상기 제1 키포인트 세트와 상기 제2 키포인트 세트 사이의 차이를 줄임으로써, 변형된 3D 헤드 메시 모델을 획득하기 위해 상기 3D 헤드 템플릿 모델의 메시에 대한 변형을 수행하는 단계; 및상기 2D 얼굴 이미지에 따라 헤드 모델을 획득하기 위해 상기 변형된 3D 헤드 메시 모델에 블렌드셰이프(blendshape) 방법을 적용하는 단계를 포함하는 3차원 헤드 변형 모델을 생성하는 컴퓨터 구현 방법."}
{"patent_id": "10-2023-7018578", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 제2 키포인트 세트에 상기 제1 키포인트 세트를 매핑하는 단계는,상기 2D 얼굴 이미지의 제1 키포인트 세트를 상기 3D 헤드 템플릿 모델의 메시의 복수의 정점과 관련시키는 단계; 및얼굴 각각의 키포인트에 의해 대응하는 식별된 특징에 기초하여 상기 제1 키포인트 세트와 상기 제2 키포인트세트를 매핑하는 단계를 더 포함하는, 3차원 헤드 변형 모델을 생성하는 컴퓨터 구현 방법."}
{"patent_id": "10-2023-7018578", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서, 상기 변형을 수행하는 단계는, 상기 제2 키포인트 세트에 대한 상기 제1 키포인트 세트의 매핑을 사용하여 그리고 상기 제1 키포인트 세트와 관련된 변형에 대한 경계 조건을 사용하여 상기 3D 헤드 템플릿 모델의 메시를 상기 변형된 3D 헤드 메시 모델로 변형하는 단계를 포함하는,3차원 헤드 변형 모델을 생성하는 컴퓨터 구현 방법."}
{"patent_id": "10-2023-7018578", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서, 상기 변형을 수행하는 단계는, 변형 최적화 프로세스에서 키포인트의 위치, 인접 평활도, 특성 및 원래 위치 중하나 이상을 포함하는 상이한 제약들을 적용하는 단계를 더 포함하는,3차원 헤드 변형 모델을 생성하는 컴퓨터 구현 방법."}
{"patent_id": "10-2023-7018578", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제3항에 있어서, 상기 변형을 수행하는 단계는, 변형 프로세스에 키포인트의 위치, 인접 평활도, 특성 및 원래 위치 중 하나 이공개특허 10-2023-0097157-3-상의 가중 합산인 제약을 적용하는 단계를 더 포함하는,3차원 헤드 변형 모델을 생성하는 컴퓨터 구현 방법."}
{"patent_id": "10-2023-7018578", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서, 상기 제1 키포인트 세트를 식별하는 단계는 합성곱 신경망(convolutional neural network, CNN)을 사용하는 단계를 포함하는,3차원 헤드 변형 모델을 생성하는 컴퓨터 구현 방법."}
{"patent_id": "10-2023-7018578", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에 있어서, 상기 변형은 라플라시안 연산자가 없는 아핀(affine) 변형을 포함하는,3차원 헤드 변형 모델을 생성하는 컴퓨터 구현 방법."}
{"patent_id": "10-2023-7018578", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서, 상기 아핀 변형은 평활도 파라미터를 변경함으로써 변형 튜닝을 달성하는,3차원 헤드 변형 모델을 생성하는 컴퓨터 구현 방법."}
{"patent_id": "10-2023-7018578", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1항에 있어서, 상기 3D 헤드 템플릿 모델의 메시는 스켈레톤(skeleton)과 결합되지 않고 변형되는,3차원 헤드 변형 모델을 생성하는 컴퓨터 구현 방법."}
{"patent_id": "10-2023-7018578", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제1항에 있어서, 상기 얼굴 변형 모델은 사실적인 스타일 모델 또는 만화 스타일 모델을 포함하는,3차원 헤드 변형 모델을 생성하는 컴퓨터 구현 방법."}
{"patent_id": "10-2023-7018578", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제1항에 있어서, 상기 변형된 3D 헤드 메시 모델에 상기 블렌드셰이프 방법을 적용하는 단계는,각각의 키포인트의 위치에 따라 상기 변형된 3D 헤드 메시 모델의 제2 키포인트 세트 각각에 각각의 블렌드 가중치를 할당하는 단계; 및상이한 블렌드 가중치들을 갖는 상기 제2 키포인트 세트에 상이한 레벨들의 변형을 적용하는 단계를 포함하는, 3차원 헤드 변형 모델을 생성하는 컴퓨터 구현 방법."}
{"patent_id": "10-2023-7018578", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제1항에 있어서, 상기 변형된 3D 헤드 메시 모델에 상기 블렌드셰이프 방법을 적용하는 단계는, 상기 변형된 3D 헤드 메시 모델의 후면 형상을 상기 변형 전 상기 3D 헤드 템플릿 모델의 원래 후면 형상과 동일하게 유지하는 단계를 포함하는, 공개특허 10-2023-0097157-4-3차원 헤드 변형 모델을 생성하는 컴퓨터 구현 방법."}
{"patent_id": "10-2023-7018578", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "전자 장치로서,하나 이상의 처리 유닛, 상기 하나 이상의 처리 유닛에 연결된 메모리, 및 상기 하나 이상의 처리 유닛에 의해실행될 때, 상기 전자 장치로 하여금 3차원(3D) 헤드 변형 모델을 생성하는 복수의 작동을 수행하게 하는, 상기메모리에 저장된 복수의 프로그램을 포함하며,상기 복수의 작동은, 2차원(2D) 얼굴 이미지를 수신하는 작동;인공 지능(AI) 모델에 기초하여 상기 2D 얼굴 이미지에서 제1 키포인트 세트를 식별하는 작동;3D 헤드 템플릿 모델에 위치된 사용자 제공 키포인트 주석 세트에 기초하여 상기 3D 헤드 템플릿 모델의 메시의복수의 정점에 위치된 제2 키포인트 세트에 상기 제1 키포인트 세트를 매핑하는 작동;상기 제1 키포인트 세트와 상기 제2 키포인트 세트 사이의 차이를 줄임으로써 변형된 3D 헤드 메시 모델을 획득하기 위해 상기 3D 헤드 템플릿 모델의 메시에 대한 변형을 수행하는 작동; 및상기 2D 얼굴 이미지에 따라 헤드 모델을 획득하기 위해 상기 변형된 3D 헤드 메시 모델에 블렌드셰이프 방법을적용하는 작동을 포함하는, 전자 장치."}
{"patent_id": "10-2023-7018578", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제13항에 있어서, 상기 제2 키포인트 세트에 상기 제1 키포인트 세트를 매핑하는 작동은,상기 2D 얼굴 이미지의 제1 키포인트 세트를 상기 3D 헤드 템플릿 모델의 메시의 복수의 정점과 관련시키는 작동; 상기 3D 헤드 템플릿 모델의 메시의 복수의 정점에 대한 사용자 제공 키포인트 주석 세트에 기초하여 상기 제2키포인트 세트를 식별하는 작동; 및얼굴 각각의 키포인트에 의해 대응하는 식별된 특징에 기초하여 상기 제1 키포인트 세트와 상기 제2 키포인트세트를 매핑하는 작동을 더 포함하는, 전자 장치."}
{"patent_id": "10-2023-7018578", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제13항에 있어서, 상기 변형을 수행하는 작동은, 상기 제2 키포인트 세트에 대한 상기 제1 키포인트 세트의 매핑을 사용하여 그리고 상기 제1 키포인트 세트와 관련된 변형에 대한 경계 조건을 사용하여 상기 3D 헤드 템플릿 모델의 메시를 상기 변형된 3D 헤드 메시 모델로 변형하는 작동을 포함하는,전자 장치."}
{"patent_id": "10-2023-7018578", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제13항에 있어서, 상기 변형을 수행하는 작동은, 변형 최적화 프로세스에서 키포인트의 위치, 인접 평활도, 특성 및 원래 위치 중하나 이상을 포함하는 상이한 제약들을 적용하는 작동을 더 포함하는,전자 장치.공개특허 10-2023-0097157-5-청구항 17 제13항에 있어서,상기 변형된 3D 헤드 메시 모델에 상기 블렌드셰이프 방법을 적용하는 작동은,각각의 키포인트의 위치에 따라 상기 변형된 3D 헤드 메시 모델의 제2 키포인트 세트 각각에 각각의 블렌드 가중치를 할당하는 작동; 및상이한 블렌드 가중치들을 갖는 상기 제2 키포인트 세트에 상이한 레벨들의 변형을 적용하는 작동을 포함하는, 전자 장치."}
{"patent_id": "10-2023-7018578", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "비일시적 컴퓨터 판독 가능 저장 매체로서,하나 이상의 처리 유닛을 갖는 전자 장치에 의해 실행되는 복수의 프로그램을 저장하고,상기 복수의 프로그램은, 상기 하나 이상의 처리 유닛에 의해 실행될 때, 상기 전자 장치로 하여금 3차원(3D)헤드 변형 모델을 생성하는 복수의 작동을 수행하게 하며,상기 복수의 작동은,2차원(2D) 얼굴 이미지를 수신하는 작동;인공 지능(AI) 모델에 기초하여 상기 2D 얼굴 이미지에서 제1 키포인트 세트를 식별하는 작동;3D 헤드 템플릿 모델에 위치된 사용자 제공 키포인트 주석 세트에 기초하여 상기 3D 헤드 템플릿 모델의 메시의복수의 정점에 위치된 제2 키포인트 세트에 상기 제1 키포인트 세트를 매핑하는 작동;상기 제1 키포인트 세트와 상기 제2 키포인트 세트 사이의 차이를 줄임으로써 변형된 3D 헤드 메시 모델을 획득하기 위해 상기 3D 헤드 템플릿 모델의 메시에 대한 변형을 수행하는 작동; 및상기 2D 얼굴 이미지에 따라 헤드 모델을 획득하기 위해 상기 변형된 3D 헤드 메시 모델에 블렌드셰이프 방법을적용하는 작동을 포함하는, 비일시적 컴퓨터 판독 가능 저장 매체."}
{"patent_id": "10-2023-7018578", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제18항에 있어서, 상기 제2 키포인트 세트에 상기 제1 키포인트 세트를 매핑하는 작동은,상기 2D 얼굴 이미지의 제1 키포인트 세트를 상기 3D 헤드 템플릿 모델의 메시의 복수의 정점과 관련시키는 작동; 상기 3D 헤드 템플릿 모델의 메시의 복수의 정점에 대한 사용자 제공 키포인트 주석 세트에 기초하여 상기 제2키포인트 세트를 식별하는 작동; 및얼굴 각각의 키포인트에 의해 대응하는 식별된 특징에 기초하여 상기 제1 키포인트 세트와 상기 제2 키포인트세트를 매핑하는 작동을 더 포함하는, 비일시적 컴퓨터 판독 가능 저장 매체."}
{"patent_id": "10-2023-7018578", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제18항에 있어서, 상기 변형된 3D 헤드 메시 모델에 상기 블렌드셰이프 방법을 적용하는 작동은,각각의 키포인트의 위치에 따라 상기 변형된 3D 헤드 메시 모델의 제2 키포인트 세트 각각에 각각의 블렌드 가중치를 할당하는 작동; 및공개특허 10-2023-0097157-6-상이한 블렌드 가중치들을 갖는 상기 제2 키포인트 세트에 상이한 레벨들의 변형을 적용하는 작동을 포함하는, 비일시적 컴퓨터 판독 가능 저장 매체."}
{"patent_id": "10-2023-7018578", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "전자 장치는, 2차원(2D) 얼굴 이미지를 수신하는 단계; 인공 지능(AI) 모델에 기초하여 2D 얼굴 이미지에서 제1 키포인트 세트를 식별하는 단계; 3D 헤드 템플릿 모델에 위치된 사용자 제공 키포인트 주석 세트에 기초하여 3D 헤드 템플릿 모델의 메시의 복수의 정점에 위치된 제2 키포인트 세트에 제1 키포인트 세트를 매핑하는 단계; 제1 키포인트 세트와 상기 제2 키포인트 세트 사이의 차이를 줄임으로써 변형된 3D 헤드 메시 모델을 획득하기 위해 3D 헤드 템플릿 모델의 메시에 대한 변형을 수행하는 단계; 및 2D 얼굴 이미지에 따라 헤드 모델을 획득하기 위 해 변형된 3D 헤드 메시 모델에 블렌드셰이프 방법을 적용하는 단계를 포함하는 3차원(3D) 헤드 변형 모델을 생 성하는 방법을 수행한다."}
{"patent_id": "10-2023-7018578", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 출원은 2021년 3월 15일에 출원된 미국 특허 출원 제17/202,112호 ('개인화된 3D 헤드 모델 변형을 위한 방 법 및 시스템')의 계속 출원으로 우선권을 주장하며, 이는 그 전체가 참조로서 본 명세서에 포함된다. 본 개시는 일반적으로 이미지 기술에 관한 것으로, 구체적으로는, 이미지 처리 및 헤드(head)/얼굴 모델 형성 방법 및 시스템에 관한 것이다."}
{"patent_id": "10-2023-7018578", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "다중 센서(예를 들어, 다중 뷰 카메라, 깊이 센서 등)를 갖춘 상업용 얼굴 캡처링 시스템은 명확한 마커가 있거 나 없는 사람에 대한 정확한 3차원(three-dimensional, 3D) 얼굴 모델을 획득하는 데 사용된다. 이러한 도구는 다중 센서에서 사람 얼굴의 기하구조 및 텍스처 정보를 캡처하고 다중 모달(multi-modal) 정보를 일반 3D 얼굴 모델에 융합한다. 다양한 센서로부터의 다중 모달 정보를 활용하여 획득되는 3D 얼굴 모델은 정확하다. 그러 나, 이러한 상업용 시스템은 비용이 많이 들고 원시 데이터를 처리하기 위해 추가 소프트웨어 구매가 필요하다. 또한, 이러한 시스템은 일반적으로 얼굴 캡처링 스튜디오에 배포되며, 데이터를 수집하기 위해 배우 또는 자원 봉사자가 필요하므로 데이터 수집 프로세스에 시간과 비용이 많이 든다. 요컨대, 얼굴 캡처링 시스템은 3D 얼 굴 데이터를 획득하는 데 비용이 많이 들고 시간이 많이 걸린다. 반면에, 요즘은 스마트폰이나 카메라가 널리 보급되어 사용 가능한 RGB(적색, 녹색, 청색) 이미지가 많을 수 있다. 3D 얼굴 모델을 생성하기 위해 RGB 이미 지를 입력으로 사용하면 많은 양의 이미지 데이터를 활용할 수 있다. 2차원(2D) RGB 이미지는 3D 세계를 2D 평면으로 투영한 것이다. 2D 이미지에서 3D 기하구조를 복원하는 것은 재구성 프로세스를 정규화하기 위해 최적화 또는 학습 알고리즘을 필요로 하는 잘못된 문제이다. 3D 얼굴 재구 성을 위해, 파라미터화된 3D 변형 가능 모델(3D Morphable Model, 3DMM) 기반의 방법이 개발되어 사용되고 있다. 구체적으로, 바젤 얼굴 모델(Basel Face Model, BFM), 써리 얼굴 모델(Surrey Face Model, SFM)과 같은 얼굴 모델은 일반적으로 사용되는 얼굴 모델로서 상업용 라이선스를 필요로 한다. 얼굴 모델 기반 방법은 스캐 닝된 3D 인간 얼굴 모델 세트(다양한 얼굴 특징 및 표정 표시)를 기반으로 한 다음, 3D 얼굴 모델에 기초하여 얼굴 특징 및 표정의 파라미터화된 표현을 생성한다. 새로운 3D 얼굴은 파라미터화에 기초하여 기본 3D 얼굴 모델의 선형 조합으로서 표현될 수 있다. 이러한 방법의 특성으로 인해, 기초를 형성하는 데 사용되는 3D 얼굴 모델과 파라미터 공간은 얼굴 모델 기반 방법의 표현력을 제한한다. 또한, 입력 얼굴 이미지 또는 2D 랜드마크 로부터 3DMM 파라미터를 맞추는 최적화 프로세스는 얼굴 이미지의 상세한 얼굴 특징을 추가로 희생시킨다. 따 라서, 얼굴 모델 기반 방법은 3D 얼굴 특징을 정확하게 복원할 수 없으며 BFM 및 SFM과 같은 얼굴 모델을 사용 하려면 상업용 라이선스가 필요하다. 딥러닝 알고리즘이 대중화되면서, 시맨틱 분할(semantic segmentation) 알고리즘이 많은 주목을 받고 있다. 이 러한 알고리즘은 얼굴 이미지 내의 각각의 픽셀을 배경, 피부, 머리카락, 눈, 코 및 입과 같은 다른 카테고리로 나눌 수 있다. 시맨틱 분할 방법이 상대적으로 정확한 결과를 얻을 수 있지만, 모든 픽셀의 시맨틱 분할은 매우 복잡한 문제로 종종 복잡한 네트워크 구조를 필요로 하여 계산 복잡도가 높아진다. 또한, 시맨틱 분할 신경망을 훈련시키기 위해, 많은 양의 훈련 데이터가 라벨화되어야 하고, 시맨틱 분할은 전체 이미지의 픽셀을 나눠야 하므로 매우 지루하고 시간과 비용이 많이 든다. 따라서, 높은 평균 색상 정확도가 필요하지 않지만, 높은 효율성이 필요한 장면에는 적합하지 않다. 라플라시안(Laplacian) 및 기타 파생 연산자를 최적화하는 키포인트 기반 변형 방법은 학계에서 잘 연구되었다. 이중조화 변형(Biharmonic deformation)의 수학식은 으로 표시될 수 있다. 제한된 키포인트, 즉 경계 조건은 로 표현될 수 있다. 상기 수학식에서, 는 라플라시안 연산자이고, x'는 미지의 변형된 메시 정점의 위치이며, xbc는 변형 후 주어진 키포인트의 위치이다. 이중 라플라스(bi-Laplace) 수학식의 해는 각각의 차원에서 필요하다. 이중조화 함수는 이중 라플라스 수학식의 해결수단이지만, 소위 \"라플라시안 에너지\"의 최소화 함수이기도 하다. 에너지 최소화의 본질은 메시(mesh)의 평활화이다. 전술한 최소화기(minimizer)를 직접 적용하면, 모든 세부 특징이 평활화될 것이다. 게다가, 키포인트의 위치가 변경되지 않는 경우, 변형된 메시는 원래 메시와 정확히 동일할 것으로 예상된다. 이러한 고려 사항 중에서, 이중조화 변형의 선호되는 사용은 그들의 위치가 아닌 정 점의 변위를 해결하는 것이다. 이러한 방식으로, 변형된 위치는 로 기록될 수 있으며, 여기서 d는 각 각의 차원에서의 미지의 정점의 변위이다. 당연히, 이중조화 변형 수학식은 일 때 이 되며, 여기서 db는 변형 후 키포인트의 변위이다. 게임 산업의 급속한 발전과 함께, 맞춤형 얼굴 아바타 생성이 점점 대중화되고 있다. 예술적인 기술이 없는 일 반 플레이어의 경우, 미묘한 변화를 설명할 수 있는 얼굴을 생성하기 위해 제어 파라미터를 조정하는 것은 매우 어렵다. 저스티스(Justice) 얼굴 생성 시스템과 같은 일부 기존의 얼굴 생성 시스템 및 방법에서, 얼굴 모델의 예측은 눈썹, 입, 코 및 사진 내의 기타 픽셀의 분할과 같은 이미지의 2D 정보를 예측하는 것이다. 이러한 2D 분할은 평면외 회전 및 부분 폐색(occlusion)의 영향을 받기 쉽고, 기본적으로 정면 얼굴이 필요하다. 또한, 최종 게 임 얼굴 아바타와 입력의 유사성이 얼굴 인식 시스템에 의해 결정되기 때문에, 이러한 방법은 실제 스타일 게임 으로만 제한된다. 게임의 스타일이 실제 얼굴과 상당히 다른 만화 스타일인 경우, 이러한 방법은 사용될 수 없 다. 문라이트 블레이드(Moonlight Blade) 얼굴 생성 시스템과 같은 일부 다른 기존의 얼굴 생성 시스템 및 방법에서, 실제 얼굴은 입력 이미지로부터 재구성된다. 이러한 방법은 실제 스타일 게임에 한정되며 만화 스타 일 게임에는 적용될 수 없다. 둘째, 이러한 방법의 출력 파라미터는 재구성된 게임 스타일의 얼굴 메시이며, 메시의 각각의 부분에 대해 템플릿 매칭이 수행된다. 이러한 접근 방식은 서로 다른 얼굴 부분의 조합을 제한 한다. 게임 얼굴의 전반적인 다양성은 미리 생성된 템플릿의 개수와 밀접한 관련이 있다. 입 형상과 같은 특 정 부분이 적은 개수의 템플릿을 갖는 경우, 다양한 변형이 거의 생성되지 않아 생성된 얼굴의 다양성이 부족할 수 있다. 학습 기반 얼굴 재구성 및 키포인트 검출 방법은 3D 실측 데이터를 금본위제로 사용하여 가능한 한 실측에 근접 하는 모델을 훈련시킨다. 따라서, 3D 실측은 학습 기반 접근 방식의 상한을 결정한다. 얼굴 재구성의 정확도 및 바람직한 키포인트 검출을 보장하기 위해, 일부 실시예에서, 고가의 얼굴 캡처링 시스템을 사용하지 않고 3D 얼굴 모델의 실측치를 생성하는 데 2D 얼굴 키포인트 주석이 사용된다. 여기에서 개시된 접근 방식은 입력 이 미지의 상세한 얼굴 특징을 보존하고, 얼굴 특징을 상실하는 3DMM 기반 방법과 같은 기존 얼굴 모델의 단점을 극복하며, 또한 일부 기존 얼굴 모델 기반 방법에서 요구되는 BFM 및 SFM(둘 다 상용 라이센스 필요)과 같은 파 라미터화된 얼굴 모델의 사용을 피하는 3D 실측 얼굴 모델을 생성한다. 얼굴 키포인트 검출과는 별개로, 일부 실시예에서, 얼굴 특징 분류 작업을 위해 다중 작업 학습 및 전이 학습 해결수단이 구현되어, 키포인트 정보에 보완적인 입력 얼굴 이미지로부터 더 많은 정보가 추출될 수 있다. 예 측된 얼굴 특징과 함께 검출된 얼굴 키포인트는 플레이어의 얼굴 아바타를 생성하기 위한 컴퓨터 또는 모바일 게임에 유용하다. 일부 실시예에서, 피부, 눈썹, 동공, 입술, 헤어(hair) 및 눈 그림자의 평균 색상을 포함하는 단일 사진으로부 터 사람 얼굴의 각 부분의 평균 색상을 추출하기 위한 경량 방법이 여기에서 개시된다. 동시에, 평균 색상을 기준으로 텍스처 맵을 자동으로 변환하는 알고리즘이 또한 사용되어, 변환된 텍스처가 여전히 원래 밝기와 색상 차이를 갖지만 주요 색상이 타깃 색상이 될 수 있게 한다. 컴퓨터 비전 및 인공 지능(artificial intelligence, AI) 기술의 급속한 발전으로, 3D 사람 얼굴 키포인트의 캡 처 및 재구성은 높은 수준의 정밀도를 달성하였다. 점점 더 많은 게임이 AI 검출을 활용하여 게임 캐릭터를 더 욱 생생하게 만들고 있다. 여기에서 개시된 방법 및 시스템은 재구성된 3D 키포인트에 기초하여 3D 헤드 아바 타를 맞춤화한다. 일반적인 포인트 구동 변형은 임의의 메시에 적용할 수 있다. 여기에서 제안되는 헤드 아바 타 맞춤화 프로세스와 변형 방법은 자동 아바타 생성 및 표정 재현과 같은 시나리오에서 응용될 수 있다.단일 사진에 기초하여 게임의 얼굴 아바타를 자동으로 생성하는 방법 및 시스템이 여기에서 개시된다. 얼굴 키 포인트의 예측, 키포인트의 자동 처리 및 모델 파라미터를 예측하기 위한 딥러닝 방법의 사용을 통해, 여기에서 개시된 시스템은 게임의 얼굴 아바타를 자동으로 생성하여, 1) 사진의 실제 얼굴의 특성을 갖고, 2) 타깃 게임 스타일을 준수하게 한다. 이러한 시스템은 실제 스타일 게임과 만화 스타일 게임을 위한 얼굴 생성에 동시에 적용될 수 있으며, 다양한 게임 모델이나 뼈대(bone) 정의에 따라 자동으로 쉽게 조정할 수 있다. 본 출원의 제1 측면에 따르면, 실존 사람의 2차원(two-dimensional, 2D) 얼굴 이미지로부터 얼굴 위치 맵을 구 성하는 방법은, 2D 얼굴 이미지로부터 거친 얼굴 위치 맵을 생성하는 단계; 거친 얼굴 위치 맵에 기초하여 2D 얼굴 이미지에서 제1 키포인트 세트를 예측하는 단계; 사용자 제공 키포인트 주석에 기초하여 2D 얼굴 이미지에 서 제2 키포인트 세트를 식별하는 단계; 및 2D 얼굴 이미지에서 제1 키포인트 세트와 제2 키포인트 세트 사이의 차이를 줄이기 위해 거친 얼굴 위치 맵을 업데이트하는 단계를 포함한다. 일부 실시예에서, 실제 사람의 2D 얼굴 이미지로부터 얼굴 위치 맵을 구성하는 방법은 업데이트된 얼굴 위치 맵 에 기초하여 제3 키포인트 세트를 최종 키포인트 세트로서 추출하는 단계를 더 포함하고, 제3 키포인트 세트는 얼굴 위치 맵에서 제1 키포인트 세트와 동일한 위치를 갖는다. 일부 실시예에서, 실제 사람의 2D 얼굴 이미지로부터 얼굴 위치 맵을 구성하는 방법은 업데이트된 얼굴 위치 맵 에 기초하여 실제 사람의 3차원(3D) 얼굴 모델을 재구성하는 단계를 더 포함한다. 본 출원의 제2 측면에 따르면, 실존 사람의 2차원 얼굴 이미지에서 색상을 추출하는 방법은 키포인트 예측 모델 에 기초하여 2D 얼굴 이미지에서 복수의 키포인트를 식별하는 단계; 복수의 키포인트로부터 선택된 키포인트가 정렬될 때까지 2D 얼굴 이미지를 회전시키는 단계; 회전된 2D 얼굴 이미지에서 복수의 부분을 찾는 단계 ― 각 각의 부분은 복수의 키포인트의 각각의 서브세트에 의해 정의됨 ―; 2D 얼굴 이미지의 픽셀 값으로부터, 키포인 트의 대응하는 서브세트에 의해 정의된 복수의 부분 각각에 대한 평균 색상을 추출하는 단계; 및 2D 얼굴 이미 지의 복수의 부분의 추출된 색상을 사용하여 2D 얼굴 이미지의 각각의 얼굴 특징 색상과 일치하는 실제 사람의 개인화된 3차원(3D) 모델을 생성하는 단계를 포함한다. 본 출원의 제3 측면에 따르면, 3차원(3D) 헤드 변형 모델을 생성하는 컴퓨터 구현 방법은, 2차원(2D) 얼굴 이미 지를 수신하는 단계; 인공 지능(AI) 모델에 기초하여 2D 얼굴 이미지에서 제1 키포인트 세트를 식별하는 단계; 3D 헤드 템플릿 모델에 위치된 사용자 제공 키포인트 주석 세트에 기초하여 3D 헤드 템플릿 모델의 메시의 복수 의 정점(vertice)에 위치된 제2 키포인트 세트에 제1 키포인트 세트를 매핑하는 단계; 제1 키포인트 세트와 제2 키포인트 세트 사이의 차이를 줄임으로써, 변형된 3D 헤드 메시 모델을 획득하기 위해 3D 헤드 템플릿 모델의 메시에 대한 변형을 수행하는 단계; 및 2D 얼굴 이미지에 따라 헤드 모델을 획득하기 위해 변형된 3D 헤드 메시 모델에 블렌드셰이프(blendshape) 방법을 적용하는 단계를 포함한다. 본 출원의 제4 측면에 따르면, 실제 사람의 2차원(2D) 얼굴 이미지를 사용하여 게임의 아바타의 표준 얼굴을 맞 춤화하는 방법은, 2D 얼굴 이미지의 실제 키포인트 세트를 식별하는 단계; 실제 키포인트 세트를 게임의 아바타 와 연관된 게임 스타일 키포인트 세트로 변환하는 단계; 게임 스타일 키포인트 세트를 키포인트 대 파라미터 (keypoint to parameter, K2P) 신경망 모델에 적용함으로써 게임의 아바타의 표준 얼굴의 제어 파라미터 세트를 생성하는 단계; 및 제어 파라미터 세트에 기초하여 게임의 아바타의 표준 얼굴을 변형하는 단계를 포함하며, 변 형된 아바타의 얼굴은 2D 얼굴 이미지의 얼굴 특징을 갖는다. 본 출원의 제5 측면에 따르면, 전자 장치는 하나 이상의 처리 유닛, 메모리 및 메모리에 저장된 복수의 프로그 램을 포함한다. 프로그램은, 하나 이상의 처리 유닛에 의해 실행될 때, 전자 장치로 하여금 전술한 바와 같은 하나 이상의 방법을 수행하게 한다. 본 출원의 제6 측면에 따르면, 비일시적 컴퓨터 판독 가능 저장 매체는 하나 이상의 처리 유닛을 갖는 전자 장 치에 의해 실행되는 복수의 프로그램을 저장한다. 프로그램은, 하나 이상의 처리 유닛에 의해 실행될 때, 전자 장치로 하여금 전술한 바와 같은 하나 이상의 방법을 수행하게 한다. 위에서 설명된 다양한 실시예는 여기에서 설명된 임의의 다른 실시예와 결합될 수 있다. 본 명세서에서 설명된 특징 및 이점은 모든 것을 포함하는 것은 아니며, 특히 많은 부가적인 특징 및 이점은 도면, 명세서 및 청구범 위에 비추어 당업자에게 명백할 것이다. 또한, 본 명세서에서 사용된 언어는 주로 가독성 및 교육 목적을 위해 선택되었으며, 발명 주제를 기술하거나 제한하기 위해 선택되지 않았을 수 있음을 유의해야 한다."}
{"patent_id": "10-2023-7018578", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "첨부된 도면에 그 예가 예시된 특정 구현에 대해 상세히 참조될 것이다. 다음의 상세한 설명에서, 본 명세서에 제시된 주제의 이해를 돕기 위해 많은 비제한적 세부사항이 제시된다. 그러나, 청구범위의 범위를 벗어나지 않 고 다양한 대안이 사용될 수 있고 주제가 이러한 특정 세부사항 없이 실시될 수 있다는 것이 당업자에게 명백할 것이다. 예를 들어, 본 명세서에서 제시된 주제가 많은 유형의 전자 장치에서 구현될 수 있다는 것이 당업자에 게 명백할 것이다. 본 출원의 실시예들이 더 상세히 설명되기 전에, 본 출원의 실시예들에 관련된 명칭 및 용어들이 설명되고, 본 출원의 실시예들에 관련된 명칭 및 용어들이 다음과 같이 설명된다. 얼굴 키포인트: 특정 얼굴 부분, 예를 들어, 눈꼬리, 턱, 코끝 및 입꼬리의 형상을 결정하는 미리 정의된 랜드 마크. 얼굴 부분: 얼굴 경계, 눈, 눈썹, 코, 입 및 기타 부분. 얼굴 재구성: 인간 얼굴의 3D 기하구조, 및 메시 모델, 포인트 클라우드 또는 깊이 맵을 포함하는 일반적으로 사용되는 표현을 재구성함. RGB 이미지: 적색, 녹색, 청색 3채널 이미지 포맷. 위치 맵: 3D 인간 얼굴의 표현인 얼굴 영역의 x, y, z 좌표를 저장하기 위해 일반적인 이미지 포맷의 적생, 녹 색, 청색 채널을 사용함. 얼굴 특징 분류: 안경 분류가 있거나 없는 헤어스타일 분류를 포함함. 합성곱 신경망(convolutional neural network, CNN): 시각적 이미지를 분석하는 데 가장 일반적으로 적용되는 심층 신경망 클래스. 기본 네트워크: 특징 추출기 역할을 하기 위해 하나 이상의 다운스트림 작업에 의해 사용되는 CNN과 같은 네트 워크. 라플라시안 연산자: 유클리디안 공간에서 함수 기울기의 발산에 의해 주어지는 미분 연산자. 미분 가능 매니폴드(manifold): 미적분을 수행할 수 있도록 선형 공간과 국부적으로 유사한 위상 공간 유형. 이중조화 함수: 미분 가능한 매니폴드에서 정의된, 제곱 라플라시안 연산자가 0인 4차 미분 가능한 함수. 키포인트 구동 변형: 특정 정점의 위치를 변경하여 메시를 변형하는 방법 클래스. 이중조화 변형: 일부 경계 조건으로 이중조화 함수의 최적화를 사용하는 변형 방법. 아핀 변형: 메시 변형의 목적을 달성하기 위해 삼각형의 아핀 변환을 최적화하는, 본 개시에서 제안된 키포인트 구동 변형 방법. 얼굴 모델: 미리 정의된 타깃 게임의 표준 얼굴의 메시. 뼈대/슬라이더: 얼굴 모델을 변형하기 위한 파라미터의 제어. 전술한 바와 같이, 입력 2D 이미지 및 2D 키포인트 모두를 3DMM 파라미터에 맞추기 위해 최적화 프로세스에 공 급하더라도, 최적화는 기초(즉, 3D 얼굴 모델 세트)에 기초한 3D 얼굴 모델의 적합(fitting)과 2D 키포인트의 충실도 사이에서 균형을 이루어야 한다. 이러한 최적화는 2D 입력 키포인트를 무시하는 획득된 3D 얼굴 모델로 이어져 입력 2D 키포인트에 의해 가져온 상세한 얼굴 정보가 희생될 수 있도록 있다. 기존의 3D 얼굴 재구성 방법 중, 얼굴 캡처 해결수단은 정확한 재구성을 생성할 수 있지만 비용과 시간이 많이 소요되며, 획득된 데이 터도 얼굴 특징의 변형이 제한적임(액터(actor)의 개수가 제한됨)을 나타낸다. 반면에, 얼굴 모델 기반 방법은 2D 이미지 또는 2D 랜드마크 주석을 입력으로 사용할 수 있지만, 획득된 3D 모델은 정확하지 않다. 컴퓨터/모 바일 게임의 빠른 개발 요구사항을 충족하려면, 원하는 3D 모델 정확도를 생성하고 필요한 비용과 시간을 줄이 는 것이 모두 필요하다. 이러한 요구사항을 충족시키기 위해, 여기에서 개시된 새로운 3D 실측 얼굴 모델 생성 알고리즘은 2D 이미지, 2D 키포인트 주석 및 거친 3D 얼굴 모델(위치 맵 포맷)을 입력으로 취하고, 2D 키포인트 에 기초하여 거친 3D 모델을 변환하며, 마지막으로 상세한 얼굴 특징이 잘 보존된 3D 얼굴 모델을 생성한다. 얼굴 재구성 및 키포인트 예측의 주요 문제를 해결하는 것 외에, 얼굴 특징 분류를 위한 다중 작업 학습 및 전 이 학습 기반 접근 방식도 여기에서 개시되며, 부분적으로는 얼굴 재구성 및 키포인트 예측 프레임워크 위에 구 축된다. 특히, 얼굴 재구성 및 키포인트 예측의 기본 네트워크를 재사용하면, (안경 유무에 관계없이) 안경 분 류가 다중 작업 학습을 통해 수행된다. 기존의 얼굴 재구성 및 키포인트 예측 프레임워크 위에 선형 분류기가 훈련되어 기존 모델을 크게 재사용하고 이미지 특징 추출을 위한 또 다른 더 큰 네트워크를 도입하지 않게 된다. 또한, 남성과 여성 헤어스타일 분류를 위해 또 다른 공유 기반 네트워크가 사용된다. 헤어스타일은 얼 굴 키포인트 또는 3D 얼굴 모델을 보완하는 중요한 얼굴 특징 유형이다. 사용자를 위한 3D 아바타를 생성하는 프로세스에서, 헤어스타일과 안경 예측을 추가하면 사용자의 얼굴 특징을 더 잘 반영하고 더 나은 개인화 경험 을 제공할 수 있다. 얼굴 키포인트 예측은 수십년 동안 컴퓨터 비전 분야의 연구 주제였다. 최근 몇 년간 인공 지능과 딥러닝의 발 전으로, 합성곱 신경망(CNN)은 얼굴 키포인트 예측의 진행을 용이하게 하였다. 3D 얼굴 재구성과 얼굴 키포인 트 검출은 서로 얽힌 두 가지 문제로, 하나를 해결하면 다른 하나를 단순화할 수 있다. 전통적인 방법은 먼저 2D 얼굴 키포인트 검출을 해결한 다음, 추정된 2D 얼굴 키포인트를 기반으로 3D 얼굴 모델을 추가로 추론하는 것이다. 그러나, 이미지의 얼굴이 기울어지는 경우(끄덕거리거나 헤드를 흔드는 경우), 특정 얼굴 키포인트가 가려져 잘못된 2D 얼굴 키포인트 추정이 발생하므로, 잘못된 2D 얼굴 키포인트 위에 3D 얼굴 모델 구축이 부정 확해질 수 있다. 실측 데이터가 딥러닝 기반 방법의 상한선을 결정하기 때문에, 기존의 3D 얼굴 모델 데이터세트는 그 수에 제한 이 있을 뿐만 아니라 학술 연구에만 사용될 수 있다. 반면에, 얼굴 모델 기반 방법은 상업용 라이선스가 필요 한 바젤 얼굴 모델(BFM) 또는 써리 얼굴 모델(SFM)을 모두 사용해야 한다. 높은 정확도와 대량의 3D 실측 (ground-truth)은 임의의 얼굴 재구성 또는 키포인트 추정 모델을 훈련하는 데 가장 중요한 문제가 된다. 얼굴 키포인트 예측 외에, 얼굴 특징 분류는 사용자 3D 아바타 생성의 중요한 측면이다. 예측된 얼굴 키포인트 로 사용자의 얼굴 부분(즉, 눈, 눈썹, 코, 입, 얼굴 윤곽)의 스타일 변환만이 수행될 수 있다. 그러나, 사용자 의 얼굴 특징을 더 잘 반영하기 위해서는, 사용자의 헤어스타일을 매칭하고, 사용자가 안경을 착용한 경우 안경 을 입력 이미지에 추가하는 것이 매우 도움이 된다. 이러한 요구사항에 기초하여, 남성/여성 헤어스타일 예측및 안경 예측(유/무)을 달성하기 위해 다중 작업 학습 및 전이 학습 기반 얼굴 특징 분류 접근 방식이 개발되어 생성된 얼굴 아바타를 보다 개인화함으로써 사용자 경험을 개선할 수 있다. 일부 실시예에서, 얼굴의 주요 부분의 3차원 형상을 나타내기 위해, 키포인트 표현이 도 1에 도시된 바와 같이 사용된다. 도 1은 본 개시의 일부 구현에 따른 예시적인 키포인트 정의를 도시한 도면이다. 키포인트는 얼굴 의 특정 특징을 정의하는 순서대로 번호가 매겨진다. 즉, 키포인트의 시퀀스 번호와 얼굴의 특정 위치 사이에 는 매핑 관계가 있다. 예를 들어, 시퀀스 번호 9는 턱 아래에 대응하고 시퀀스 번호 21은 코끝에 대응하는 식 이다. 키포인트는 얼굴의 주요 부분의 경계, 예를 들어 얼굴의 윤곽, 눈의 윤곽 및 눈썹의 윤곽에 집중된다. 키포인트가 많을수록 예측이 더 어려워지지만, 형상 표현은 더 정확해진다. 일부 실시예에서, 96개의 키 포인 트의 정의가 도 1에서 채택된다. 일부 실시예에서, 사용자는 자신의 필요에 따라 특정 정의 및 키포인트의 개 수를 수정할 수 있다. 많은 알고리즘이 사람 얼굴의 키포인트의 3차원 좌표를 예측할 수 있다. 성능이 더 좋은 방법은 대량의 오프라 인 3D 훈련 데이터에 기초한 딥러닝 알고리즘을 사용한다. 그러나, 일부 실시예에서, 임의의 3차원 키포인트 예측 알고리즘이 사용될 수 있다. 일부 실시예에서, 키포인트의 정의는 고정되어 있지 않으며 사용자는 필요에 따라 정의를 맞춤화할 수 있다. 3D 실측 얼굴 모델 생성 문제를 해결하기 위해, 2D RGB 이미지, 2D 키포인트 주석 및 거친 위치 맵을 입력으로 취하는 다음과 같은 자동 알고리즘이 개발되었다. 도 2는 본 개시의 일부 구현에 따른 예시적인 키포인트 생성 프로세스를 도시한 블록도이다. 예를 들어, 얼굴의 2D RGB 이미지는 입력 이미지로 사용되고 2D RGB 이미 지는 대응하는 초기 거친 위치 맵을 가지며, 초기 거친 맵의 각각의 픽셀은 2D RGB 이미지에서 대응하는 얼굴 포인트의 공간 좌표를 나타낸다. 2D 키포인트 주석은 초기 거친 맵에서 검출된 키포인트 세트 를 정정하는 데 사용되는 사용자 제공 키포인트 세트를 나타낸다. 도 3은 본 개시의 일부 구현에 따른 초기 거친 위치 맵을 변환하는 예시적인 프로세스를 도시한 도면이다. 일부 실시예에서, 3D 재구성 방법은 입력 얼굴 이미지를 얼굴 특징에 대한 3D 깊이 정보를 포함하는 위치 맵으 로 변환하는 데 사용된다. 예를 들어, 위치 맵은 256 x 256 매트릭스 배열을 갖는 2D 3색(RGB) 채널 맵일 수 있으며 각각의 배열 요소는 얼굴 모델의 3D 위치를 나타내는 좌표(x, y, z)를 갖는다. 3D 위치 좌표(x, y, z) 는 각각의 배열 요소에 대한 위치 맵의 RGB 픽셀 값으로 표현된다. 특정 얼굴 특징은 2D 위치 맵 내의 고정된 2D 위치에 있다. 예를 들어, 코끝은 위치 맵 내에서 X=128, Y=128의 2D 배열 요소 위치로 식별될 수 있다. 마 찬가지로, 얼굴의 특정 얼굴 특징에 대해 식별된 특정 키포인트는 2D 위치 맵에서 동일한 배열 요소 위치에 위 치될 수 있다. 그러나, 특정 키포인트는 위치 맵에 대한 상이한 입력 얼굴 이미지에 따라 상이한 3D 위치 좌표 (x, y, z)를 가질 수 있다. 일부 실시예에서, 도 2 및 도 3에 도시된 바와 같이, 입력 이미지(202, 302)로부터 초기 거친 위치 맵(204, 304)을 획득하기 위해 3D 재구성 방법이 이용된다. 그런 다음, 조정된 위치 맵에서 키포인트의 조정된 (x, y) 좌표가 주석이 달린 2D 키포인트와 동일한 것을 보장하기 위해, 입력된 2D 키포인트 주석(208, 308)이 초기 위 치 맵의 해당 키포인트(206, 306)의 (x, y) 좌표를 조정하는 데 사용된다. 특히, 먼저, 초기 위치 맵(P)으로부 터 96개의 키포인트 세트가 획득된다. 키포인트 인덱스를 기반으로, 96개의 키포인트 세트는 K = k_i로서 지칭 되며, 여기서 각각의 k_i는 키포인트의 2D 좌표(x, y)이고, i = 0, ..., 95이다. 2D 키포인트 주석(208, 30 8)으로부터, 2D (x, y) 좌표인, 96개의 제2 키포인트 세트 A = a_i가 획득되고, i = 0, ..., 95이다. 두 번째 로, 공간 변환 매핑(210. 310)은 K에서 A로 추정되고, T: Ω -> Ω로 정의되며, 여기서 Ω ⊂ R^2이다. 그 다 음, 획득된 변환 T는 변환된 위치 맵 P'(212, 312)를 얻기 위해 초기 위치 맵 P에 적용된다. 이와 같이, 변환 된 위치 맵 P'(212, 312)은 입력 이미지(202, 302)에서 사람의 상세한 얼굴 특징을 보존하고, 동시에, 변환된 위치 맵 P'(212, 312)은 합리적인 3D 깊이 정보이다. 따라서, 여기에서 개시된 해결수단은 비싸고 시간 소모적 인 얼굴 캡처링 시스템을 사용하지 않도록 3D 실측 정보를 생성하기 위한 정확하고 실용적인 대안의 해결수단을 제공한다. 일부 실시예에서, 96개의 얼굴 키포인트가 전체 얼굴 영역(즉, 눈썹 아래, 얼굴 윤곽의 내부)의 일부만을 커버 하기 때문에, 예를 들어 도 3에서, 눈에서 턱까지의 키포인트는 아래턱을 따라 있지만, 그러나 눈에 보이는 얼 굴 윤곽에는 없다. 입력 이미지에서 얼굴이 기울어져 있는 경우, 전체 얼굴 영역은 서로 연결된 키포인트의 윤 곽에 의해 커버되지 않는다. 또한, 수동 키포인트 주석을 수행하는 경우, 이미지의 얼굴이 기울어져 있는지 여 부에 관계없이. 키포인트는 눈에 보이는 얼굴 윤곽을 따라서만 레이블을 지정할 수 있다(즉, 가려진 키포인트에 정확하게 주석을 달 수 있는 방법이 없음). 그 결과, 변환 매핑 T(210. 310)가 영역에서 추정을 갖지 않음으로인해 얼굴 영역의 일부가 유효한 값을 갖지 않는다. 또한, 이마 영역은 눈썹 위에 있기 때문에 T도 해당 영역 에 대한 추정을 갖지 않는다. 이러한 모든 문제는 변환된 위치 맵 P'(212, 312)이 특정 영역에서 유효한 값을 갖지 못하게 한다. 도 4는 본 개시의 일부 구현에 따른 전체 얼굴 영역을 커버하지 않는 예시적인 변환된 위치 맵을 도시한 도면이다. 도 4에서, 상단 원(402, 406)은 이마 영역을 강조 표시하고 우측 원(404, 408)은 키포인트 윤곽이 눈에 보이는 얼굴 윤곽보다 작은 영역을 지시한다. 일부 실시예에서, 위의 문제를 해결하고 얼굴 이미지에 공통으로 존재하는 기울어진 얼굴에 강건한 알고리즘을 만들기 위해, 도 2에 도시된 바와 같은 정제 프로세스가 사용된다. 변환된 위치 맵으로부터의 키포인트는 헤드 포즈와 거친 3D 얼굴 모델에 기초하여 눈에 보이는 얼굴 윤곽과 일치시키기 위해 얼굴 윤곽을 따라 이동된 다. 그 후, 얼굴 윤곽 영역에서 누락된 값이 획득된 위치 맵을 채울 수 있다. 그러나, 이마 영역의 값은 여전 히 누락되어 있다. 이마 영역을 커버하기 위해, 두 키포인트 세트 K와 A에 이미지의 네 개의 코너에 있는 8개 의 랜드마크를 추가함으로써 제어 포인트가 확장된다. 도 5는 본 개시의 일부 구현에 따른 전체 얼굴 영역을 커버하기 위해 변환된 위치 맵을 정제하는 예시적인 프로 세스를 도시한 도면이다. 위치 맵 정제 처리는 도 5에 도시되어 있다. 일부 실시예에서, 헤드가 좌측 또는 우측을 향해 기울어져 있는지를 결정하기 위해 거친 위치 맵 P에 기초하여 헤드 포즈가 먼저 결정되고, 좌측 또는 우측은 3D 얼굴 모델 공간에서 정의된다(예를 들어, 도 5에 도시된 바와 같이 얼굴이 좌측을 향해 기울어져 있음). 얼굴이 좌측 또는 우측으로 기울어져 있는지의 결정에 기초하여, 얼 굴 윤곽의 대응하는 측면의 키포인트가 조정된다. 얼굴 윤곽의 우측면 키포인트는 1에서 8까지의 인덱스를 갖 고, 얼굴 윤곽의 좌측면 키포인트는 10에서 17까지의 인덱스를 갖는다. 좌측으로 기울어진 얼굴을 예로 사용하 면, 초기 위치 맵 P의 2D 투영은 도 5에 도시된 이미지와 같은 깊이 맵을 얻기 위해 계산된다. 좌측 얼굴 윤곽 키포인트 k_i, i = 10, ..., 17은 깊이 맵의 경계에 도달할 때까지 개별적으로 우측으로 이동된다. 그런 다음, 새로운 좌표가 사용되어 원래의 키포인트 위치를 대체한다. 마찬가지로, 얼굴이 우측으로 기울어져 있는 경우, 처리된 키포인트는 k_i, i=1, ..., 8로 인덱싱되고 검색 방향은 좌측이다. 얼굴 윤곽 키포인트를 조정한 후, 업데이트된 키포인트는 도 5의 이미지로 시각화되고 위치 맵의 업데이트된 커버리지는 도 5의 이미지 로 표시된다. 업데이트된 위치 맵은 얼굴 윤곽 영역에서 더 나은 얼굴 커버리지를 갖지만, 이마 영역은 여전히 누락된 값을 갖는다. 일부 실시예에서, 이마 영역을 커버하기 위해, 업데이트된 키포인트 세트 K'을 얻기 위해 추가 키포인트 k_i, i = 96, ..., 103으로서 이미지 도메인 Ω의 각각의 코너에 2개의 앵커(anchor) 포인트가 추가된다(도 5의 이미지 로 도시된 바와 같음). 업데이트된 A'를 얻기 위해 수동 주석 키포인트 세트, a_i, i = 96, ..., 103에 대해 동일한 작업이 수행된다. 업데이트된 키포인트 세트 K' 및 A'를 사용하면, 변환 매핑 T'이 재추정되고, 그 다음 전체 얼굴 영역을 커버하기 위해 최종 위치 맵 P\"(도 2의 216)을 얻기 위해 초기 위치 맵 P에 적용된다 (도 5의 이미지에 도시된 바와 같음). 최종 키포인트는 최종 위치 맵으로부터 도출된다. 도 6은 본 개시의 일부 구현에 따른 위치 맵 정제 알고리즘의 일부 예시적인 결과를 도시한 도면이다. 602는 초기 변환된 위치 맵의 예시이다. 604는 얼굴 윤곽을 고정한 후 업데이트된 위치 맵의 예시이다. 606은 최종 위치 맵의 예시이다. 도 7a 및 도 7b는 본 개시의 일부 구현에 따른 초기 거친적 위치 맵에 대한 최종 위치 맵의 일부 예시적인 비교 를 도시한다. 도 7a의 일 예에서, 초기 위치 맵 및 관련 3D 모델 및 키포인트에서의 코는 사람의 얼굴 특 징(화살표로 강조 표시됨)을 완전히 반영할 수 없을 정도로 부정확지만, 여기에서 설명된 방법을 적용한 후 코 는 최종 위치 맵 및 관련 3D 모델 및 키포인트에서의 이미지와 잘 정렬된다(화살표로 강조 표시됨). 도 7b의 두 번째 예에서, 얼굴 윤곽, 벌린 입 및 코 형상 불일치와 같은 초기 위치 맵 및 관련 3D 모델 및 키포인 트에 여러 부정확성이 있다(화살표로 지시됨). 최종 위치 맵 및 관련 3D 모델 및 키포인트에서, 이 러한 모든 오류가 수정된다(화살표로 지시됨). 헤어스타일 및 안경 분류는 얼굴 아바타 생성 프로세스를 위한 모바일 게임 애플리케이션에서 중요하다. 일부 실시예에서, 다중 작업 학습 및 전이 학습 기반 해결수단은 이러한 문제를 해결하기 위해 여기에서 구현된다. 일부 실시예에서, 여성 헤어 예측을 위해 4개의 상이한 분류 작업(헤드)이 구현된다. 분류 카테고리 및 파라미 터는 아래와 같다.분류 헤드 1: 커브(curve) 스트레이트 ; 커브 분류 헤드 2: 길이 쇼트(short); 롱(long) 분류 헤드 3: 뱅(bang) 뱅 또는 분할 없음 ; 좌측 분할 ; 우측 분할 ; M 형상 ; 스트레이트 뱅 ; 내추럴(natural) 뱅 ; 에어(air) 뱅 분류 헤드 4: 브레이드(braid) 단일 브레이드 ; 2개 이상의 브레이드 ; 단일 번(bun) ; 2개 이상의 번 ; 기타 . 일부 실시예에서, 남성 헤어 예측을 위해 3개의 상이한 분류 작업(헤드)이 구현된다. 분류 카테고리 및 파라미 터는 다음과 같다. 분류 헤드 1: 극단 쇼트 , 컬(curly) , 기타 분류 헤드 2: 뱅 없음 , 분할 뱅 , 내추럴 뱅 분류 헤드 3: 분할 뱅 좌측 및 분할 뱅 우측 일부 실시예에서, 안경 분류는 이진 분류 작업이다. 분류 파라미터는 다음과 같다. 안경 없음 ; 안경 있음 . 상이한 딥러닝 이미지 분류 모델 중에서, ImageNet에서 최첨단 정확도를 달성하는 모델은 일반적으로 모델 크기 가 크고 EfficientNet, noise student 및 FixRes와 같은 복잡한 구조를 갖는다. 특징 추출기의 기본 네트워크 로 사용할 아키텍처를 결정하는 경우, 예측 정확도와 모델 크기가 모두 균형을 이루어야 한다. 실제로, 1%의 분류 정확도 향상은 최종 사용자에게 명백한 변화를 가져오지 않을 수 있지만, 모델 크기는 기하급수적으로 증 가할 수 있다. 훈련된 모델이 클라이언트 측에 배포될 수 있다는 점을 감안할 때, 더 작은 기본 네트워크는 서 버와 클라이언트 측 모두에게 유연하게 배포될 수 있다. 따라서, MobileNetV2는 예를 들어 상이한 분류 헤드에 대한 전이 학습을 수행하기 위한 기본 네트워크로 채택된다. MobileNetV2 아키텍처는 잔차 블록의 입력 및 출 력이 입력에서 확장된 표현을 사용하는 기존 잔차 모델과 반대되는 얇은 병목 층인 반전된 잔차 구조에 기초한 다. MobileNetV2는 중간 확장 계층의 특징을 필터링하기 위해 가벼운 깊이별 합성곱을 사용한다. 안경 분류를 위해, 다중 작업 학습 접근 방식이 사용된다. 키포인트 예측 네트워크를 기본 네트워크로 재사용 하고 파라미터를 동결하면, U자형 기반 네트워크의 병목 계층에서, 교차 엔트로피 손실이 있는 특징 벡터가 이 진 분류기를 훈련하는 데 사용된다. 도 8a는 본 개시의 일부 구현에 따른 예시적인 안경 분류 네트워크 구조를 도시한 도면이다. 도 8b는 본 개시의 일부 구현에 따른 예시적인 여성 헤어 예측 네트워크 구조를 도시한 도면 이다. 도 8c는 본 개시의 일부 구현에 따른 예시적인 남성 헤어 예측 네트워크 구조를 도시한 도면이다. 도 9a는 본 개시의 일부 구현에 따른 일부 예시적인 안경 분류 예측 결과를 도시한다. 도 9b는 본 개시의 일부 구현에 따른 일부 예시적인 여성 헤어 예측 결과를 도시한다. 도 9c는 본 개시의 일부 구현에 따른 일부 예시 적인 남성 헤어 예측 결과를 도시한다. 도 10은 본 개시의 일부 구현에 따른 실제 사람의 2D 얼굴 이미지로부터 얼굴 위치 맵을 구성하는 예시적인 프 로세스를 도시한 흐름도이다. 실생활에서, 서로 다른 사람은 서로 다른 얼굴 특성을 가지므로 동일한 얼 굴 특성(예를 들어, 사람 얼굴의 눈썹 위치)에 대응하는 동일한 키포인트가 매우 다른 공간 좌표를 가질 수 있 다. 3D 얼굴 모델을 생성하는 데 사용되는 2D 얼굴 이미지가 다른 각도와 다른 조명 조건에서 캡처되기 때문에 얼굴 검출 문제가 더욱 어려워지고 있으며 이러한 분야에 대한 연구는 컴퓨터 비전 기술 분야에서 매우 활발한 주제였다. 본 출원에서, 실제 사람에서 만화 캐릭터에 이르는 피사체의 2D 얼굴 이미지에서 얼굴 키포인트 검 출의 효율과 정확도를 개선하기 위한 여러 가지 방법이 제안되었다. 일부 실시예에서, 동일한 얼굴 이미지의 사용자 제공 얼굴 키포인트 세트는 컴퓨터 구현 방법에 의해 초기에 검출된 얼굴 키포인트 세트를 수정하거나 개선하기 위한 참조로서 제공된다. 예를 들어, 각각의 시퀀스 번호에 기초한 사용자 제공 얼굴 키포인트와 컴 퓨터 생성 얼굴 키포인트 사이에 일대일 매핑 관계가 있기 때문에, 컴퓨터 생성 얼굴 키포인트의 정제는 예를들어, 위치 맵에서 대응하는 공간 좌표로 측정된 얼굴 키포인트의 두 세트 사이의 차이를 줄이는 최적화 문제로 서 정의된다. 얼굴 위치 맵을 구성하는 프로세스는 2D 얼굴 이미지로부터 거친 얼굴 위치 맵을 생성하는 단계를 포함한 다. 프로세스는 또한 거친 얼굴 위치 맵에 기초하여 2D 얼굴 이미지에서 제1 키포인트 세트를 예측하는 단계 를 포함한다. 프로세스는 사용자 제공 키포인트 주석에 기초하여 2D 얼굴 이미지에서 제2 키포인트 세트를 식별하는 단계 를 추가로 포함한다. 이 프로세스는 2D 얼굴 이미지에서 제1 키포인트 세트와 제2 키포인트 세트 사이의 차이를 줄이기 위해 거친 얼 굴 위치 맵을 업데이트하는 단계를 추가로 포함한다. 예를 들어, 대응하는 공간 좌표 측면에서 2D 얼굴 이미지의 제1 키포인트 세트와 제2 키포인트 세트 간의 차이를 줄임으로써, 거친 얼굴 위치 맵에 기초한 2D 얼 굴 이미지의 제1 키포인트 세트는 사용자 제공 키포인트 주석을 기반으로 2D 얼굴 이미지의 제2 키포인트 세트 와 더 유사하도록 수정되며, 이는 종종 더 정확한 것으로 간주되고 제1 얼굴 키포인트 세트의 수정은 제1 키포 인트 세트가 생성되는 초기 거친 얼굴 위치 맵의 업데이트를 자동으로 트리거한다. 사용자 제공 키포인트 주석 을 기반으로 한 2D 얼굴 이미지의 제2 키포인트 세트가 수동으로 수행되었음을 의미하지는 않는다. 대신에, 사 용자는 주석을 수행하기 위해 다른 컴퓨터 구현 방법을 사용할 수 있다. 일부 실시예에서, 제2 키포인트 세트 (예를 들어, 10-20)의 개수가 제1 키포인트 세트의 개수(예를 들어, 96 또는 그 이상)의 일부일 뿐이지만, 제2 키포인트 세트가 훨씬 더 정확하여 제1 키포인트 세트의 전반적인 개선에 기여한다. 일 구현에서, 프로세스는 업데이트된 얼굴 위치 맵/최종 위치 맵에 기초하여 제3 키포인트 세트를 최종 키포인 트 세트로서 추출하는 단계를 더 포함하고, 제3 키포인트 세트는 얼굴 위치 맵의 제1 키포인트 세트와 동 일한 위치를 갖는다. 일부 실시예에서, 얼굴 위치 맵에서 키포인트의 위치는 위치 맵에서 배열 요소의 2D 좌표 로 표현된다. 위에서 언급된 바와 같이, 업데이트된 얼굴 위치 맵은 사용자 제공 키포인트 주석에 기초하여 2D 얼굴 이미지의 제2 키포인트 세트의 이점을 얻었으므로, 제3 키포인트 세트는 더 정확하고 보다 정확한 얼굴 검 출 또는 보다 정확한 3D 얼굴 모델링을 위한 컴퓨터 그래픽을 위해 컴퓨터 비전과 같은 영역에서 사용될 수 있 다. 일 구현에서, 단계에 대한 대안 또는 추가로, 프로세스는 업데이트된 얼굴 위치 맵에 기초하여 실제 사람 의 3D 얼굴 모델을 재구성하는 단계를 더 포함한다. 일 예로, 3D 얼굴 모델은 3D 깊이 모델이다. 추가 구현은 다음 특징 중 하나 이상을 포함할 수 있다. 일부 실시예에서, 업데이트하는 단계는 거친 얼굴 위치 맵을 변환된 얼굴 위치 맵으로 변환하는 단계, 및 변환된 얼굴 위치 맵을 정제하는 단계를 포함할 수 있다. 위에서 언급된 바와 같이, 변환된 얼굴 위치 맵은 초 기의 거친 얼굴 위치 맵보다 입력 이미지에 있는 사람의 얼굴 특징을 더 상세하게 보존할 수 있으므로, 변환된 얼굴 위치 맵에 기초한 3D 얼굴 모델은 더 정확하다. 일부 실시예에서, 변환하는 단계는 제1 키포인트 세트와 제2 키포인트 세트 사이의 차이를 학습하는 것으로부터, 거친 얼굴 위치 맵으로부터 변환된 얼굴 위치 맵으로의 변환 맵핑을 추정하는 단계; 및 거친 얼굴 위치 맵에 변환 매핑을 적용하는 단계를 포함한다. 일부 실시예에서, 정제하는 단계는 2D 얼굴 이미지가 기울어져 있다는 결정에 따라, 전체 얼굴 영역을 커버하기 위해 얼굴 윤곽의 가려진 측면에서 변환된 얼굴 위치 맵에 대응하는 키포인트를 조정하는 단계를 포함한다. 위 에서 언급된 바와 같이, 상이한 2D 얼굴 이미지는 상이한 각도에서 캡처될 수 있으며 이러한 정제 단계는 상이 한 이미지 캡처 조건에 의해 도입된 편향 또는 오류를 수정하고 2D 얼굴 이미지의 보다 정확한 3D 얼굴 모델을 보존할 수 있다. 또한, 변환된 얼굴 위치 맵은 초기의 거친 얼굴 위치 맵보다 입력 이미지에 있는 사람의 얼굴 특징을 더 상세하게 보존할 수 있으므로, 변환된 얼굴 위치 맵에 기초한 3D 얼굴 모델이 더 정확하다. 일부 실시예에서, 제1 키포인트 세트는 96개의 키포인트를 포함할 수 있다. 일부 실시예에서, 얼굴 위치 맵을 구성하는 프로세스는 얼굴 특징 분류를 포함할 수 있다. 일부 실시예에서, 얼굴 특징 분류는 딥러닝 방법을 통해 이루어진다. 일부 실시예에서, 얼굴 특징 분류는 다중 작업 학습 또는 전이 학습 방법을 통해 이루어진다. 일부 실시예에서, 얼굴 특징 분류는 헤어 예측 분류를 포함한다. 일부 실시예에서, 헤어 예측 분류는 곡선, 길이, 뱅 및 브레이드를 포함할 수 있는 복수의 분류 작업을 갖는 여 성 헤어 예측을 포함한다. 일부 실시예에서, 헤어 예측 분류는 커브/길이, 뱅 및 헤어 분할을 포함할 수 있는 복수의 분류 작업을 갖는 남 성 헤어 예측을 포함한다. 일부 실시예에서, 얼굴 특징 분류는 안경 예측 분류를 포함한다. 안경 예측 분류는 안경이 있는 경우와 안경이 없는 경우를 포함할 수 있는 분류 작업을 포함한다. 여기에서 개시된 방법 및 시스템은 3D 실측 생성을 위한 2D 키포인트 주석에 기초하여 정확한 3D 얼굴 모델(즉, 위치 맵)을 생성할 수 있다. 이 접근 방식은 BFM 및 SFM 얼굴 모델을 사용하지 않을 뿐만 아니라 상세한 얼굴 특징을 더 잘 보존함으로써 얼굴 모델 기반 방법으로 인한 이러한 중요한 특징의 손실을 방지한다. 키포인트를 제공하는 것 외에, 헤어스타일 및 안경과 같은 보완적인 얼굴 특징을 제공하기 위한 딥러닝 기반 해 결수단이 사용되며, 이는 사용자 입력 얼굴 이미지를 기반으로 얼굴 아바타를 개인화하는 데 필수적이다. 얼굴 특징 분류를 위한 헤어스타일 및 안경 예측이 여기에서 예로서 개시되지만, 프레임워크는 이러한 예시 작 업에 제한되지 않는다. 프레임워크와 해결수단은 다중 작업 학습 및 전이 학습을 기반으로 하며, 이는 여성 메 이크업 유형 분류, 남성 수염 유형 분류 및 마스크 분류 유무와 같은 다른 얼굴 특징을 포함하도록 프레임워크 를 쉽게 확장할 수 있다. 프레임워크의 설계는 다양한 컴퓨터 또는 모바일 게임의 요구사항에 따라 더 많은 작 업으로 확장하기에 적합하다. 일부 실시예에서, 키포인트에 기반한 경량 색상 추출 방법이 여기에서 도입된다. 경량화된 이미지 처리 알고리 즘은 모든 픽셀의 분할 없이 로컬 픽셀을 빠르게 추정함으로써 효율을 높일 수 있다. 훈련 프로세스 동안, 사용자는 픽셀 레벨 레이블을 가질 필요가 없지만, 눈꼬리, 입꼬리 및 눈썹과 같은 몇 개 의 키포인트에만 레이블을 붙일 필요가 있다. 여기에서 개시된 경량 색상 추출 방법은 다양한 게임을 위한 개인화된 얼굴 생성 시스템에서 사용될 수 있다. 더 많은 자유로운 개인화 캐릭터 생성을 제공하기 위해, 많은 게임에서 자유로운 조정 방법을 채택하기 시작하 였다. 얼굴 형상을 조정하는 것 외에도, 사용자는 다양한 색상 조합을 선택할 수 있다. 미적 목적을 위해, 게 임에서의 얼굴은 종종 실제 얼굴 텍스처 대신에 미리 정의된 텍스처를 사용한다. 여기에서 개시된 이러한 방법 및 시스템은 사용자가 사진을 업로드하는 것만으로 얼굴의 각각의 부분의 평균 색상을 자동으로 추출할 수 있게 한다. 동시에, 시스템은 추출된 색상에 따라 텍스처를 자동으로 수정할 수 있으므로, 개인화 된 얼굴의 각각의 부분이 사용자 사진의 실제 색상에 더 가깝게 생성되어 사용자 경험을 향상시킬 수 있게 한다. 예를 들어, 사 용자의 피부색이 대부분의 사람의 평균 피부색보다 어두우면, 게임 내 캐릭터의 피부색이 그에 따라 어두워질 것이다. 도 11은 본 개시의 일부 구현에 따른 예시적인 색상 추출 및 조정 프로세스를 도시한 흐름도이다. 얼굴의 다양한 부분을 찾기 위해, 위에서 설명된 도 1에 도시된 바와 같이, 얼굴의 주요 특징 부분에 대해 키포 인트가 정의된다. 위에서 설명된 알고리즘은 키포인트 예측에 사용된다. 시맨틱 분할 방식과 달리, 각각의 픽 셀을 분류할 필요 없이 이미지에서 키포인트만이 예측되므로, 예측 비용과 훈련 데이터의 레이블링 비용이 크게 줄어들 수 있다. 이러한 키포인트를 통해, 얼굴의 다양한 부분이 대략적으로 찾아질 수 있다. 도 12는 본 개시의 일부 구현에 따른 예시적인 피부색 추출 방법을 도시한다. 이미지의 특징을 추출하기 위해, 원래 이미지의 얼굴 영역을 회전시킴으로써 얼굴의 좌측 및 우측의 키포인트(1, 17)가 회전 정렬 후의 이미지에 도시된 바와 같이, 표준 얼굴의 좌측 및 우측의 대응하는 키포인트와 정렬될 수 있다. 다음으로, 피부색 픽셀 검사를 위한 영역이 결정된다. 눈의 키포인트 하단 좌표는 검출 영역의 상한선으로 선 택되고, 코의 하단 키포인트는 검출 영역의 하한선으로 선택되며, 좌측 및 우측 경계는 얼굴 경계 키포인트에 의해 결정된다. 이러한 방식으로, 피부색 검출 영역은 이미지 상의 영역에 도시된 바와 같이 획득 된다. 이러한 영역의 모든 픽셀이 피부 픽셀은 아니며, 픽셀은 또한 일부 속눈썹, 콧구멍, 팔자 주름, 헤어 등 을 포함할 수도 있다. 따라서, 이러한 영역의 모든 픽셀의 R, G, B 값의 중앙값이 최종 예측 평균 피부색으로 선택된다. 도 13은 본 개시의 일부 구현에 따른 예시적인 눈썹 색상 추출 방법을 도시한다. 눈썹의 평균 색상에 대해, 메 인 눈썹, 즉 렌즈에 더 가까운 쪽의 눈썹이 타깃으로서 먼저 선택된다. 일부 실시예에서, 양쪽 눈썹이 메인 눈 썹인 경우, 양쪽 눈썹 픽셀이 추출된다. 좌측 눈썹이 메인 눈썹이라고 가정하면, 도 13에 도시된 바와 같이, 키포인트(77, 78, 81, 82)로 구성된 사각형 영역이 눈썹 픽셀 검색 영역으로 선택된다. 이것은 바깥쪽에 더 가 까운 눈썹이 너무 가늘어서 이며 작은 키포인트 오류의 영향이 커질 것이다. 안쪽에 가까운 눈썹은 종종 희박 하고 피부색과 섞일 수 있기 때문에, 중간 눈썹 영역이 픽셀을 수집하도록 선택된다. 그리고, 각각의 픽 셀은 먼저 평균 피부색과 비교되어야 하며, 일정 임계값보다 큰 차이를 갖는 픽셀만이 수집될 것이다. 마지막 으로, 피부색과 마찬가지로, 수집된 픽셀의 중앙 R, G, B 값이 최종 평균 눈썹 색상으로 선택된다. 도 14는 본 개시의 일부 구현에 따른 예시적인 동공 색상 추출 방법을 도시한다. 눈썹 색상 추출과 유사하게, 동공 색상 추출 시, 렌즈에 가까운 메인 눈쪽이 먼저 선택된다. 일부 실시예에서, 양쪽 눈이 메인 눈인 경우, 양쪽의 픽셀이 함께 수집된다. 동공 자체 외에도, 눈의 키포인트 내부에 포함된 닫힌 영역은 또한 속눈썹, 눈 의 흰자위 및 리플렉션(reflection)을 포함할 수 있다. 이들은 대부분의 최종 픽셀이 동공 자체에서 나오도록 픽셀 수집 프로세스에서 가능한 한 많이 제거되어야 한다. 속눈썹 픽셀을 제거하기 위해, 눈의 키포인트는 y축(도 14의 수직 방향)을 따라 일정 거리만큼 안쪽으로 수축되 어 도 14에 도시된 영역을 형성한다. 백색 눈 및 리플렉션(도 14의 원에 의해 도시된 바와 같음) 을 제거하기 위해, 이러한 픽셀은 이러한 영역에서 추가로 제외된다. 예를 들어, 픽셀의 R, G 및 B 값이 모두 미리 정의된 임계값보다 큰 경우, 해당 픽셀이 제외된다. 이러한 방식으로 수집된 픽셀은 대부분이 동공 자체에서 나온 것임을 보장할 수 있다. 마찬가지로, 중간 색상은 평균 동공 색상으로 사용된다. 일부 실시예에서, 입술 색상 추출을 위해, 아랫 입술 영역의 검출 픽셀만이 검출된다. 윗 입술은 얇아서 키포 인트 오류에 상대적으로 민감한 경우가 많으며, 윗 입술의 색상이 옅기 때문에, 입술 색상을 잘 표현하지 못하 는 경우가 많다. 따라서, 사진을 회전하고 보정한 후에, 아랫 입술의 키포인트로 둘러싸인 영역의 모든 픽셀이 수집되고, 평균 입술 색상을 나타내는 중간 색상이 사용된다. 도 15는 본 개시의 일부 구현에 따른 헤어 색상 추출 방법에서 사용되는 예시적인 헤어 색상 추출 영역을 도시 한다. 헤어 색상 추출은 이전 부분보다 더 어렵다. 주요 이유는 사람마다 헤어 스타일이 독특하고, 사진의 배 경이 복잡하고 다양하기 때문이다. 따라서, 헤어의 픽셀을 찾기가 어렵다. 헤어 픽셀을 정확하게 찾는 한 가지 방법으로, 이미지의 헤어 픽셀을 분할하는 데 신경망이 사용된다. 이미지 분할의 주석 비용이 매우 높고 게임 애플리케이션에 매우 높은 정확도의 색상 추출이 필요하지 않기 때문에, 키포인트의 대략적인 예측에 기반한 방 법이 사용된다. 헤어 픽셀을 획득하기 위해, 검출 영역이 먼저 결정된다. 도 15에 도시된 바와 같이, 검출 영역은 직사 각형이다. 아랫쪽 경계는 양쪽 눈썹 코너이고, 높이(세로선)는 눈썹 위쪽 에지에서 눈 아래쪽 에지까지 의 거리이다. 좌측과 우측은 고정된 거리를 각각 좌측과 우측으로 연장하기 위한 키 포인트 1, 17이다. 이렇게 획득된 헤어 픽셀 검출 영역이 도 15에 도시되어 있다. 도 16은 본 개시의 일부 구현에 따른 헤어 색상 추출 영역 내의 헤어 픽셀과 피부 픽셀 사이의 예시적인 분할을 도시한다. 일반적으로, 검출 영역은 피부, 헤어 및 배경의 세 가지 유형의 픽셀을 포함한다. 좀 더 복잡한 경 우, 모자도 포함한다. 우리의 검출 영역의 좌우 범위가 상대적으로 보수적이기 때문에, 포함된 헤어 픽셀은 대 부분의 경우 배경 픽셀보다 훨씬 더 많은 것으로 가정된다. 따라서, 검출 영역의 픽셀을 헤어나 피부로 나누는 것이 주요 프로세스이다. 검출 영역 내 픽셀의 각각의 라인에 대해, 피부 색상 변화는 종종 예를 들어 밝은 색에서 어두운 색과 같이 연 속적이고, 피부 색상 및 헤어 접합부는 종종 명백한 변화를 갖는다. 따라서, 각각의 행의 중간 픽셀이 시작점 으로 선택되고, 피부 픽셀은 좌측 및 우측으로 검출된다. 먼저, 상대적으로 보수적인 임계값이 사용되어 보다 신뢰할 수 있는 피부 색상 픽셀을 찾는 데 사용되며, 그 다음 좌측 및 우측으로 확장된다. 이웃 픽셀의 색상이 비교적 가까우면, 피부 색상으로도 표시된다. 이러한 방법은 피부 색상의 그라데이션(gradation)을 고 려하여 비교적 정확한 결과를 획득할 수 있다. 도 16에 도시된 바와 같이, 헤어 색상 추출 영역 내에서, 1604와 같은 어두운 영역은 피부 색상 픽셀을 나타내고, 1606과 같은 밝은 영역은 헤어 색상 픽셀을 나타낸다. 헤어 색상 영역 내에서 수집된 헤어 색상 픽셀의 중앙 R, G, B 값이 최종 평균 헤어 색상으로 선택된다. 도 17은 본 개시의 일부 구현에 따른 예시적인 아이섀도 색상 추출 방법을 도시한다. 아이섀도 색상 추출은 이 전 부분들과 조금 다르다. 아이섀도는 존재할 수 있거나 존재하지 않을 수 있는 메이크업이기 때문이다. 따라 서, 아이섀도 색상을 추출하는 경우, 아잇섀도가 존재하는지 여부가 먼저 결정되어야 하고, 만약 존재하면, 그평균 색상이 추출된다. 눈썹과 동공의 색상 추출과 마찬가지로, 아이섀도 색상 추출은 렌즈에 가까운 주요 눈 부분에 대해서만 수행된다. 먼저, 아이섀도에 속하는 픽셀이 결정되어야 한다. 아이섀도 픽셀의 검출 영역에 대해서는, 도 17에 도시된 바 와 같이 라인(1704, 1706) 내의 영역이 사용된다. 영역의 좌측 및 우측은 눈의 내부 및 외부 에지 로서 정의되고, 해당 영역의 상부 및 하부 쪽은 눈썹의 하부 에지 및 눈의 상부 에지이다. 이러한 영역 에서 가능한 아이섀도 픽셀에 더하여, 아이섀도를 추출할 때 제외되어야 하는 속눈썹, 눈썹 및 피부가 또한 있 을 수 있다. 일부 실시예에서, 눈썹의 영향을 제거하기 위해, 검출 영역의 상부 에지가 추가로 아래로 이동된다. 속눈썹의 영향을 줄이기 위해, 밝기가 일정 임계값 아래인 픽셀은 제외된다. 아이섀도와 피부 색상을 구분하기 위해, 각 각의 픽셀의 색조와 평균 피부 색조 사이의 차이가 확인된다. 그 차이가 특정 임계값보다 큰 경우에만, 해당 픽셀이 가능한 아이섀도 픽셀로서 수집된다. RGB 값 대신에 색조가 사용되는 이유는 평균적인 피부 색상이 주 로 눈 아래에 모이고, 눈 위의 피부 색상은 밝기의 변화가 클 수 있기 때문이다. 색상은 밝기에 민감하지 않기 때문에, 색상은 비교적 안정적이다. 결과적으로, 색조는 픽셀이 피부인지 여부를 판단하는 데 더 적합하다. 상기 프로세스를 통해, 각각의 검출 영역의 픽셀이 아이섀도에 속하는지 여부가 결정될 수 있다. 일부 실시예 에서, 아이섀도가 없는 경우, 일부 픽셀이 여전히 아이섀도로 인식될 수 있는 오류가 발생할 수 있다. 상기 오류를 줄이기 위해, 검출 영역의 각각의 열(column)이 확인된다. 현재 열의 아이섀도 픽셀 개수가 특정 임계값보다 크면, 현재 열이 아이섀도 열로 표시된다. 검출 영역의 폭에 대한 아이섀도 열의 비율이 특정 임계 값보다 크면, 현재 이미지에 아이섀도가 있는 것으로 간주되고, 수집된 아이섀도 픽셀의 중간 색상이 최종 색상 으로 사용된다. 이와 같은 방식으로, 아이섀도로 오분류되는 소수의 픽셀이 전체 아이섀도에 대한 잘못된 판단 을 초래하지 않을 것이다. 아트(art) 스타일을 고려할 때, 대부분의 게임은 종종 위의 모든 부분이 색상을 자유롭게 조정하는 것을 허용하 지 않는다. 색상 조정이 열려 있는 부분의 경우, 미리 정의된 색상의 세트에만 일치시키는 것만이 종종 허용된 다. 헤어를 예로 들면, 헤어스타일에서 5가지 헤어 색상이 선택될 수 있는 경우, 리소스(resource pack) 팩의 헤어스타일에는 각각의 헤어 색상에 대응하는 텍스처 이미지가 포함될 것이다. 검출 시, 헤어 색상 예측 결과 에 따라 가장 가까운 색상의 텍스처 이미지가 선택되기만 하면, 원하는 헤어 렌더링 효과가 획득될 수 있다. 일부 실시예에서, 오직 하나의 색상 텍스처 이미지가 제공되는 경우, 텍스처 이미지의 색상은 검출된 임의의 색 상에 따라 합리적으로 변경될 수 있다. 색상 변환을 용이하게 하기 위해, 일반적으로 사용되는 RGB 색상 공간 표현은 HSV 색상 모델로 변환된다. HSV 색상 모델은 색조(hue) H, 채도(saturation) S 및 명도(lightness) V 의 세 가지 차원으로 구성된다. 색조 H는 360도의 색상 범위, 즉 0도 범위의 적색, 120도 범위의 녹색 및 240 도 범위의 청색으로서 모델에서 표현된다. 채도 S는 스펙트럼 색상과 흰색의 혼합을 나타낸다. 채도가 높을수 록 색상이 더 밝아진다. 채도가 0에 가까워지면, 색상은 흰색에 가까워진다. 명도 V는 색상의 밝기를 나타내 며, 값 범위는 흑색에서 백색까지이다. 색상 조정 후, 텍스처 이미지의 HSV 중앙값은 예측된 색상과 일치할 것으로 예상된다. 따라서, 각각의 픽셀의 색상 값 계산은 Hi'=(Hi+H'-H)%1과 같이 표현될 수 있으며, 여기서 H i'와 Hi는 조정 전과 후의 픽셀 i의 색조를 나타내고, H와 H'은 조정 전과 후의 텍스처 이미지 색조의 중앙값을 나타낸다. 끝과 끝이 연결된 연속적인 공간인 색조(hue)와 달리, 채도와 명도는 0과 1과 같은 경계 특이성(boundary singularity)을 갖는다. 색조 조정과 유사한 선형 처리 방법이 사용되면, 초기 픽처 또는 조정된 픽처의 중앙 값이 0 또는 1에 가까운 경우, 많은 픽셀 값이 채도 또는 명도가 너무 높거나 낮게 나타날 것이다. 이 현상은 부자연스러운 색상을 유발한다. 이러한 문제를 해결하기 위해, 다음과 같은 비선형 곡선이 사용되어 픽셀 조정 전후의 채도와 명도를 맞춘다. y = 1/(1+(1-α)(1-x)/(αx)), α∈(0,1) 상기 수학식에서, x 및 y는 각각 조정 전후의 채도 또는 명도 값이다. 유일하게 불확실한 파라미터는 α이며, 이는 다음과 같이 유도될 수 있다. α = 1/(1+x/(1-x)×(1-y)/y) 이러한 수학식은 α가 0에서 1까지의 간격에 속한다는 것을 보장할 수 있다. 채도를 예로 들면, 초기 중간 채 도 S는 입력 픽처에 기초하여 간단히 계산될 수 있다. 그리고, 타깃 채도 값 St는 헤어 색상 추출 및 색상 공간 변환에 의해 얻어질 수 있다. 따라서, α = 1/(1+S/(1-S)×(1-St)/St)이다. 기본 텍스처 이미지의 각각의 픽셀 Si에 대해, 조정된 값은 수학식 Si = 1/(1+(1-α)(1-Si)/(αSi))에 의해 계산될 수 있다. 동일한 계산이 명도에 적용된다. 조정된 텍스처 픽처의 디스플레이 효과를 실제 픽처에 더 가깝게 만들기 위해, 다른 부분에 대해 특별한 처리가 행해진다. 예를 들어, 헤어 채도를 낮게 유지하기 위해, S'=S'×V'^0.3이 설정된다. 도 18은 본 개시의 일부 구현에 따른 일부 예시적인 색상 조정 결과를 도시한다. 열 1802는 특정 게임에 의해 제공되는 일부 기본 텍스 처 픽처를 나타내고, 열 1804는 동일한 행의 대응하는 기본 텍스처 픽처에서 열 1804의 상단에 표시된 실제 픽 처에 따라 조정된 일부 텍스처 픽처를 나타내며, 열 1806은 동일한 행의 대응하는 기본 텍스처 픽처에서 열 1806의 상단에 표시된 실제 픽처에 따라 조정된 일부 텍스처 픽처를 나타낸다. 도 19는 본 개시의 일부 구현에 따른 실제 사람의 2D 얼굴 이미지로부터 색상을 추출하는 예시적인 프로세스를 도시한 흐름도이다. 실제 사람의 2D 얼굴 이미지로부터 색상을 추출하는 프로세스는 키포인트 예측 모델에 기초하여 2D 얼굴 이미지 에서 복수의 키포인트를 식별하는 단계를 포함한다. 프로세스는 또한 복수의 키포인트로부터 선택된 키포인트가 정렬될 때까지 2D 얼굴 이미지를 회전시키는 단계 를 포함한다. 프로세스는 회전된 2D 얼굴 이미지에서 복수의 부분을 찾는 단계를 추가로 포함하고, 각각의 부분은 복수 의 키포인트의 각각의 서브세트에 의해 정의된다. 프로세스는 2D 얼굴 이미지의 픽셀 값으로부터 대응하는 키포인트 서브세트에 의해 정의된 복수의 부분 각각에 대한 평균 색상을 추출하는 단계를 추가로 포함한다. 프로세스는 2D 얼굴 이미지에서 복수의 부분의 추출된 색상을 사용하여 2D 얼굴 이미지의 각각의 얼굴 특징 색 상을 일치시키는 실제 사람의 개인화된 3D 모델을 생성하는 단계를 추가로 포함한다. 추가 구현은 다음의 특징 중 하나 이상을 포함할 수 있다. 일부 실시예에서, 식별 단계에서의 키포인트 예측 모델은 사용자가 수동으로 주석을 단 키포인트로부터의 기계 학습에 기초하여 형성된다. 일부 실시예에서, 정렬을 위해 사용되는 회전 단계에서 선택된 키포인트는 2D 얼굴 이미지의 대칭적인 좌 측 및 우측에 위치한다. 일부 실시예에서, 단계에서, 복수의 부분 각각에 대한 평균 색상을 추출하는 것은 대응하는 부분 내 각각 의 정의된 영역에 있는 모든 픽셀의 R, G, B 값의 중앙값을 예측된 평균 색상으로 선택하는 것을 포함할 수 있 다. 일부 실시예에서, 단계 1940에서, 복수의 부분 각각에 대한 평균 색상을 추출하는 단계는 피부 부분 내에서 피 부 색상 추출을 위한 영역을 결정하고, 피부 색상 추출을 위한 영역의 모든 픽셀의 R, G, B 값의 중앙값을 피부 부분의 예측된 평균 색상으로 선택하는 단계를 포함할 수 있다. 일부 실시예에서, 피부 부분 내에서 피부 색상 추출을 위한 영역은 얼굴에서 눈의 아래 및 코의 아래 에지 위의 영역으로 결정된다. 일부 실시예에서, 단계 1940에서, 복수의 부분 각각에 대한 평균 색상을 추출하는 단계는, 눈썹이 2D 얼굴 이미 지의 뷰어(viewer)에 더 가까운 쪽에 있는 것으로의 결정에 따라, 눈썹을 타깃 눈썹으로 선택하는 단계; 양쪽 눈썹이 2D 얼굴 이미지의 뷰어에게 동일하게 가까운 것으로의 결정에 따라, 양쪽 눈썹을 타깃 눈썹으로 선택하 는 단계; 타깃 눈썹(들) 내의 중간 눈썹 영역(들)을 추출하는 단계; 중간 눈썹 영역(들) 내의 각각의 픽셀 값을 평균 피부 색상과 비교하는 단계; 임계값을 초과하는 평균 피부 색상과의 픽셀 값 차이를 갖는 중간 눈썹 영역 (들) 내의 픽셀을 수집하는 단계; 및 눈썹 색상 추출을 위해 수집된 픽셀의 R, G, B 값의 중앙값을 눈썹 부분의 예측된 평균 색상으로 선택하는 단계를 포함하는 눈썹 부분 내의 눈썹 색상 추출을 포함할 수 있다. 일부 실시예에서, 단계 1940에서, 복수의 부분 각각에 대한 평균 색상을 추출하는 단계는, 눈이 2D 얼굴 이미지 의 뷰어에 더 가까운 쪽에 있는 것으로의 결정에 따라, 눈을 타깃 눈으로 선택하는 단계; 양쪽 눈이 2D 얼굴 이 미지의 뷰어에 동일하게 가까운 것으로의 결정에 따라, 양쪽 눈을 타깃 눈으로 선택하는 단계; 속눈썹이 없는 타깃 눈(들) 내의 영역(들)을 추출하는 단계; 추출된 영역(들) 내의 각각의 픽셀 값을 미리 결정된 임계값과 비교하는 단계; 미리 결정된 임계값을 초과하는 픽셀 값을 갖는 추출된 영역(들) 내에서 픽셀을 수집하는 단계; 및 동공 색상 추출을 위해 수집된 픽셀의 R, G, B 값의 중앙값을 예측된 동공의 평균 색상으로 선택하는 단계를 포함하는 눈 부분 내의 동공 색상 추출을 포함할 수 있다. 일부 실시예에서, 단계 1940에서, 복수의 부분 각각에 대한 평균 색상을 추출하는 단계는, 아랫 입술의 키포인 트로 둘러싸인 영역의 모든 픽셀을 수집하는 단계; 및 입술 색상 추출을 위해 수집된 픽셀의 R, G, B 값의 중앙 값을 예측된 입술 부분의 평균 색상으로 선택하는 단계를 포함하는 입술 부분 내의 입술 색상 추출을 포함할 수 있다. 일부 실시예에서, 단계 1940에서, 복수의 부분 각각에 대한 평균 색상을 추출하는 단계는, 양쪽으로 헤어 부분 으로 연장되는 이마의 부분을 포함하는 영역을 식별하는 단계; 영역의 중간에서 좌측 경계 및 우측 경계로 미리 결정된 임계값을 초과하는 픽셀 색상 변화를 결정하는 단계; 미리 결정된 임계값을 초과하는 픽셀 색상 변화에 기초하여 상기 영역을 헤어 영역과 피부 영역으로 나누는 단계; 및 상기 영역 내의 헤어 영역에 대한 픽셀의 R, G, B 값의 중앙값을 예측된 헤어 부분의 평균 색상으로 선택하는 단계를 포함하는 헤어 부분 내의 헤어 색상 추 출을 포함할 수 있다. 일부 실시예에서, 양쪽의 헤어 부분으로 연장되는 이마의 부분을 포함하는 영역은 양쪽 눈썹 코너의 하부 경계, 2D 얼굴 이미지의 좌우 대칭에 위치한 키포인트에서 바깥쪽으로 고정된 거리의 좌측 경계 및 우측 경계, 및 눈 썹의 상부 에지에서 눈의 하부 에지까지의 거리에서의 높이로서 식별된다. 일부 실시예에서, 단계 1940에서, 복수의 부분 각각에 대한 평균 색상을 추출하는 단계는, 눈이 2D 얼굴 이미지 의 뷰어에게 더 가까운 쪽에 있는 것으로의 결정에 따라, 눈을 타깃 눈으로 선택하는 단계; 양쪽 눈이 2D 얼굴 이미지의 뷰어에게 동일하게 가까운 것으로의 결정에 따라, 양쪽 눈을 타깃 눈으로 선택하는 단계; 타깃 눈 (들)에 가까운 아이섀도 부분 내의 중간 영역(들)을 추출하고, 속눈썹을 제외하기 위해 미리 결정된 명도 임계 값 위의 명도를 갖고 미리 결정된 임계값을 초과하는 평균 피부 색조 값과의 픽셀 색조 값 차이를 갖는 추출된 중간 영역(들) 내의 픽셀을 수집하는 단계; 추출된 중간 영역(들) 내의 하나의 픽셀 열에서 수집된 픽셀의 개수 가 임계값보다 큰 것으로의 결정에 따라, 픽셀 열을 아이섀도 열로 레이블링하는 단계; 및 추출된 중간 영역의 폭에 대한 아이섀도 열의 비율이 특정 임계값보다 큰 것으로의 결정에 따라, 아이섀도 색상 추출을 위한 수집된 픽셀의 R, G, B 값의 중앙값을 예측된 아이섀도 부분의 아이섀도 색상으로 선택하는 단계를 포함하는 아이섀도 부분 내의 아이섀도 추출을 포함할 수 있다. 일부 실시예에서, 실제 사람의 2D 얼굴 이미지로부터 색상을 추출하는 프로세스는, 평균 색상을 RGB 색상 공간 표현으로부터 HSV(색조, 채도, 명도) 색상 공간 표현으로 변환하는 단계, 및 텍스처 맵의 평균 색상의 중간 HSV 값과 중간 HSV 값 픽셀 사이의 차이를 줄이기 위해 텍스처 맵의 색상을 조정하는 단계를 포함하는 텍스처 맵의 원래 명도 및 색상 차이를 유지하면서 평균 색상에 기초하여 텍스처 맵을 변환하는 단계를 추가로 포함할 수 있 다. 여기에서 개시된 방법 및 시스템은 캐릭터 모델링 및 게임 캐릭터 생성과 같은 상이한 시나리오의 애플리케이션 에서 사용될 수 있다. 경량화 방법은 모바일 장치를 포함하는 다양한 장치에 유연하게 적용될 수 있다. 일부 실시예에서, 현재 시스템 및 방법에서 얼굴의 키포인트의 정의는 현재 정의에 제한되지 않으며, 각 부분의 윤곽이 충분히 표현될 수 있는 한 다른 정의도 가능하다. 또한, 일부 실시예에서, 이 방식에서 직접 반환된 색 상은 직접 사용되지 않을 수 있지만, 추가 색상 스크리닝 및 제어를 달성하기 위해 미리 정의된 색상 리스트와 일치시킬 수 있다. 라플라시안 연산자를 최적화하는 변형 방법은 메시가 미분 가능한 매니폴드일 것을 요구한다. 그러나, 실제로, 게임 아티스트가 만든 메시는 매니폴드의 속성을 손상시키는 경우가 많은 중복된 정점, 봉인되지 않은 에지와 같은 아티팩트를 포함한다. 따라서, 이중조화 변형과 같은 방법은 메시가 주의 깊게 정리된 후에만 사용될 수 있다. 여기에서 제안되는 아핀 변형 방법은 라플라시안 연산자를 사용하지 않으므로, 이러한 강한 제약을 갖지 않는다. 이중조화 변형으로 대표되는 변형 방법의 패밀리는 일부 경우에 변형 능력의 부적절함을 겪는다. 라플라시안 연산자를 한 번 해결하는 조화 함수는 낮은 평활도 요구사항으로 인해 평활화된 결과를 달성할 수 없는 경우가 많다. 고차(>= 3) 라플라시안 연산자를 푸는 다조화 함수는 최소 6차 미분 가능이라는 높은 요구사항으로 인해 많은 메시에서 실패한다. 대부분의 경우, 라플라시안 연산자를 두 번 푸는 이중조화 변형만이 허용 가능한 결 과를 제공할 수 있음이 관찰된다. 그렇더라도, 튜닝 자유도의 부족으로 인해 변형이 여전히 만족스럽지 않을수 있다. 여기서 제안되는 아핀 변형은 평활도 파라미터를 변경함으로써 미묘한 변형 튜닝을 달성할 수 있으며, 변형 결과의 범위는 이중조화 변형을 사용하는 것을 포함한다. 도 20은 본 개시의 일부 구현에 따른 예시적인 헤드 아바타 변형 및 생성 프로세스를 도시한 흐름도이다. 본 개시에서 제안된 기술을 사용하면, 헤드 메시는 스켈레톤과 결합하지 않고 적절하게 변형될 수 있다. 따라서, 아티스트에게 필요한 작업량이 크게 줄어든다. 이 기술은 더 나은 일반성을 얻기 위해 다양한 스타일의 메시를 수용한다. 게임 에셋(asset) 제작 시, 아티스트는 3DMax 또는 Maya와 같은 도구를 사용하여 헤드 모델을 다양 한 포맷으로 저장할 수 있지만, 이러한 포맷의 내부 표현은 모두 다각형 메시이다. 다각형 메시는 템플릿 모델 이라고 하는 순수한 삼각형 메시로 쉽게 변환될 수 있다. 각각의 템플릿 모델에 대해, 3D 키포인트는 템플릿 모델에 한 번 수작업으로 표시된다. 그런 다음, 임의의 사람 얼굴 픽처에서 검출되고 재구성된 3D 키포인트에 따라 특징적인 헤드 아바타로 변형하는 데 사용될 수 있다. 도 21은 본 개시의 일부 구현에 따른 예시적인 헤드 템플릿 모델 구성을 도시한 도면이다. 헤드 템플릿 모델 은 일반적으로 도 21에 도시된 바와 같이, 얼굴, 눈, 속눈썹, 치아 및 헤어와 같은 부분으로 구성된다. 스켈레톤을 결합하지 않고, 메시 변형은 템플릿 메시의 연결된 구조에 의존한다. 따 라서, 템플릿 모델은 이러한 시맨틱 부분으로 분해되어야 하며 얼굴 메시가 먼저 변형되어야 한다. 다른 모든 부분은 얼굴 메시의 특정 키포인트를 설정하고 따라감으로써 자동으로 조정될 수 있다. 일부 실시예에서, 토폴 로지적으로(topologically) 연결된 모든 부분을 검출하기 위해 대화형 도구가 제공되며, 사용자는 이를 사용하 여 추가 변형을 위해 해당 시맨틱 부분을 편리하게 내보낼 수 있다. 일부 실시예에서, 사람 얼굴의 이미지 키포인트는 일부 검출 알고리즘 또는 AI 모델을 통해 얻어질 수 있다. 메시 변형을 유도하기 위해, 이러한 키포인트는 템플릿 모델의 정점에 매핑되어야 한다. 메시 연결의 무작위성 과 3D 사람 키포인트 표시 데이터의 부족으로 인해, 임의의 헤드 모델에 3D 키포인트를 정확하게 자동으로 표시 할 수 있는 도구가 없다. 따라서, 수동으로 3D 모델에 키포인트를 신속하게 표시할 수 있는 대화형 도구가 개 발되었다. 도 22는 본 개시의 일부 구현에 따라 2202, 2204와 같은 사실적인 스타일의 3D 모델 및 2206, 2208 과 같은 만화 스타일의 3D 모델에 표시하는 일부 예시적인 키포인트를 도시한 도면이다. 표시 과정에서, 3D 모델에 표시된 3D 키포인트의 위치는 픽처 키포인트와 최대한 일치해야 한다. 키포인트는 3D 모델 메시의 불연속 정점에 표시되므로, 편차 가져오기가 불가피한다. 이러한 편차를 상쇄하기 위한 한 가 지 방법은 포즈 처리에서 적절한 규칙을 정의하는 것이다. 도 23은 본 개시의 일부 구현에 따른 템플릿 모델 렌더링, 수동으로 표시된 키포인트 및 AI 검출 키포인트 사이의 예시적인 비교를 도시한 도면이다. 일부 실시 예에서, 비교적 현실적으로 만들어진 모델의 경우, 키포인트 검출 및 재구성된 알고리즘이 템플릿 모델의 렌더링에 적용될 수 있고, 예를 들어 인공 지능에 의한 3D 키포인트의 결과는 수동으로 표시된 것 과 추가로 비교될 수 있고 따라서 키포인트의 두 그룹 사이의 편차가 계산된다. 사람 픽처를 검출하는 경우, 실제 이미지에서 검출된 키포인트에서 계산된 편차가 줄어들고 인공 표시의 악영향이 제거될 것이다. 여기에서 개시된 아핀 변형 방법은 궁극적으로 선형 수학식 시스템을 푸는 키포인트 구동 수학적 모델링이다. 여기에서 개시된 방법은 검출된 키포인트를 경계 조건으로 사용하여 템플릿 메시를 변형하는 한 단계를 취하고 최적화 프로세스에서 다른 제약 조건을 사용한다. 도 24는 본 개시의 일부 구현에 따른 예시적인 삼각형의 아 핀 변환을 도시한 도면이다. 일부 실시예에서, 템플릿 메시로부터 예측된 메시로의 변형은 각각의 삼각형의 아핀 변환의 조합으로 간주된다. 삼각형의 아핀 변환은 3×3 매트릭스 T와 변환 벡터 d로 정의될 수 있다. 도 24에 도시된 바와 같이, 아핀 변 환 후 변형된 정점의 위치는 로 표시되며, 여기서 v1, v2, v3은 삼각형의 각각의 정점을 각 각 나타내고 v4는 수학식 을 충족하는 삼각형의 법선 방향으로 도입된 여분의 포인트이다. 상기 수학식에서, 외적(cross product)의 결과는 삼각형의 에지 길이에 비례하도록 정규화된다. v4를 도입한 이유는 세 정점의 좌표가 고유한 아핀 변환을 결정하기에 충분하지 않기 때문이다. v4를 도입한 후, 도출된 수학식은 와 같 으며 매트릭스 T의 비변환 부분이 결정된다. 매트릭스 V=[v2-v1 v3-v1 v4-v1]-1은 템플릿 메시에만 의존하고 다른 변형 인자에 불변하므로, 나중에 선형 시스템을 구축하기 위한 희소 계수 매트릭스로서 미리 계산될 수 있다.지금까지 수학 공식에서 아핀 변환 T의 비변환 부분이 표시되었다. 최적화의 선형 시스템을 구축하기 위해, 메 시 정점의 개수가 N이고 삼각형의 개수가 F라고 가정하면, 다음의 네 가지 제약 조건이 고려된다. 키포인트 위치의 제약: , c'i는 메시 변형 후 검출된 키포인트 위치를 나타낸다. 인접성 평활도의 제약: , 이는 인접한 삼각형 사이의 아핀 변환이 가능한 한 유사 해야 함을 의미한다. 인접성 관계는 미리 조회되고 저장되어 중복 계산을 피하고 시스템 구축을 위한 성능을 향상시킬 수 있다. 특성의 제약: , 여기서 I는 항등 매트릭스를 나타낸다. 이러한 제약 조건은 아핀 변환이 가 능한 한 변경되지 않은 상태에 가까워야 함을 의미하며, 이는 템플릿 메시의 특성을 유지하는 데 도움이 된다. 원래 위치의 제약: , 여기서 ci는 변형 전 템플릿 메시 상의 각각의 정점의 위치를 나타 낸다. 최종 제약은 상기 제약의 가중 합산이다: minE=wkEk+wsEs+wiEi+wlEl, 여기서 가중치 wk, ws, wi, wl은 가장 강한 것 에서 가장 약한 것으로 등급이 매겨진다. 위의 제약 조건을 사용하여, 궁극적으로 선형 시스템이 구축될 수 있 으며 그 크기는 (F+N)×(F+N)이고, 가중치는 시스템의 대응하는 계수와 곱해진다. 미지수는 각각의 삼각형에 대한 여분의 포인트 v'4 외에 변형 후 각각의 정점의 좌표이다. 전자의 용어가 유용하므로, v'4의 결과는 버려 질 것이다. 연속 변형의 프로세스에서, 모든 제약 조건 매트릭스를 제외하고 키포인트의 위치의 제약 조건이 재사용될 수 있다. 아핀 변환은 수천 개의 정점을 갖는 메시에 대해 일반 개인용 컴퓨터와 지능형 전화기에서 30 fps의 실시간 성능을 달성할 수 있다. 도 25는 본 개시의 일부 구현에 따라 블렌드셰이프(blendshape) 프로세스가 있거나 없는 일부 헤드 모델 변형 결과의 예시적인 비교를 도시한 도면이다. 일부 실시예에서, 게임 아바타의 헤드 모델을 변형하는 경우, 관심 영역은 일반적으로 얼굴뿐이다. 헤드와 목 의 상단, 후면은 변경되지 않은 상태로 유지되어야 하며, 그렇지 않으면 헤드와 헤어 또는 몸통 사이에 메시 침 투가 발생할 수 있다. 이러한 문제를 피하기 위해, 아핀 변형의 결과와 템플릿 메시는 블렌드셰이프 방식으로 선형 보간된다. 블렌딩을 위한 가중치는 3D 모델링 소프트웨어에서 페인팅(paint)되거나, 또는 사소한 변경을 통해 이중조화 또는 아핀 변형으로 계산될 수 있다. 예를 들어, 키포인트에 대한 가중치는 1로 설정되는 한편, 헤드 모델에는 더 많은 마커(도 25의 2504에서 어두운 점)가 추가되고 그들의 가중치는 0으로 설정된다. 일부 실시예에서, 부등식 제약은 모든 가중치가 0 내지 1의 범위에 속하도록 강제하기 위해 풀이 과정에서 추가되지 만, 그렇게 하면 풀이의 복잡성이 크게 증가할 것이다. 실험을 통해 0보다 작거나 1보다 큰 가중치를 잘라냄으 로써 좋은 결과가 얻어질 수 있다. 도 25의 2504에 도시된 바와 같이, 가장 어두운 색상의 모델 부분의 가중치 는 1이고, 무색인 모델 부분의 가중치는 0이다. 블렌드 가중치 렌더링에서 밝은 키포인트와 어두운 마커 사이에 자연스러운 전환이 있다. 블렌드셰이프를 사용하면, 변형 후 모델의 후면(도 25의 2506에 표시됨)은 원 래와 동일하게 유지된다(도 25에 표시됨). 블렌드셰이프가 없으면, 변형 후 모델의 후면(도 25의 2508에 표시 됨)은 원래와 동일하게 유지되지 않는다(도 25의 2502에 표시됨). 일부 실시예에서, 아핀 변형은 이중조화 변형의 결과를 시뮬레이션하는 것을 포함하여 제약조건의 가중치를 조 작함으로써 상이한 변형 효과를 달성할 수 있다. 도 26은 본 개시의 일부 구현에 따라 상이한 가중치를 갖는 아핀 변형 및 이중조화 변형의 예시적인 비교를 도시한 도면이다. 도 26에 도시된 바와 같이, 평활도는 인접 평활도 가중치 ws와 특성 가중치 wi의 비율이다. 어두운 점이 키포인트이며, 색상의 어두움은 정점의 변형된 위 치와 원래 위치 사이의 변위를 나타낸다. 모든 변형 결과에서, 하나의 키포인트는 변경되지 않고, 다른 키포인 트는 동일한 위치로 이동한다. 특성 가중치에 대해 인접 평활도 가중치를 점진적으로 증가시키는 경우, 그에 상응하여 변형된 구체(sphere)의 평활도도 증가함을 보여준다. 또한, 이중조화 변형의 결과는 평활도가 10에서 100 사이에 속하는 아핀 변형의 결과와 일치할 수 있다. 이는 아핀 변형이 이중조화 변형에 비해 변형에 대한 자유도가 더 크다는 것을 지시한다. 여기에서 설명된 작업 흐름을 사용하면, 게임은 헤드 아바타의 지능형 생성 기능을 쉽게 통합할 수 있다. 예를 들어, 도 27은 본 개시의 일부 구현에 따라 사실적인 템플릿 모델을 사용하여 무작위로 선택된 일부 여성 픽처(도 27에 도시되지 않음)로부터 자동으로 생성되는 일부 예시적인 결과를 도시한다. 모든 개인화된 헤드 아바 타는 대응하는 픽처의 일부 특성을 반영한다. 도 28은 본 개시의 일부 구현에 따라 실제 사람의 2D 얼굴 이미지로부터 3D 헤드 변형 모델을 생성하는 예시적 인 프로세스를 도시한 흐름도이다. 2D 얼굴 이미지로부터 3D 헤드 변형 모델을 생성하는 프로세스는 2차원(2D) 얼굴 이미지를 수신하는 단계(281 0)를 포함한다. 프로세스는 또한 인공 지능(artificial intelligence, AI) 모델, 예를 들어 합성곱 신경망에 기초하여 2D 얼굴 이미지에서 제1 키포인트 세트를 식별하는 단계를 포함한다. 프로세스는 3D 헤드 템플릿 모델에 위치한 사용자 제공 키포인트 주석 세트에 기초하여 3D 헤드 템플릿 모델의 메시의 복수의 정점에 위치한 제2 키포인트 세트에 제1 키포인트 세트를 매핑하는 단계를 추가로 포함한 다. 프로세스는 제1 키포인트 세트와 제2 키포인트 세트 사이의 차이를 감소시킴으로써 변형된 3D 헤드 메시 모델을 획득하기 위해 3D 헤드 템플릿 모델의 메시에 대한 변형을 수행하는 단계를 추가로 포함한다. 일부 실시 예에서, 제1 키포인트 세트와 제2 키포인트세트 사이에 대응관계가 있다. 제2 키포인트 세트를 제1 키포인트 세트와 동일한 공간에 투영한 후, 제1 키포인트 세트와 제2 키포인트 세트 사이의 위치 차이를 측정하는 함수가 생성된다. 3D 헤드 템플릿 모델의 메시에 변형을 수행함으로써, 제1 키포인트 세트 각각과 제2 키포인트 세트 사이의 위치 차이를 측정하는 함수가 최소화되는 경우 공간의 제2 키포인트 세트가 최적화된다. 프로세스는 2D 얼굴 이미지에 따라 개인화된 헤드 모델을 획득하기 위해 변형된 3D 헤드 메시 모델에 블렌드셰 이프 방법을 적용하는 단계를 추가로 포함한다. 추가 구현은 다음의 특징 중 하나 이상을 포함할 수 있다. 일부 실시예에서, 매핑 단계는, 2D 얼굴 이미지의 제1 키포인트 세트를 3D 헤드 템플릿 모델의 메시의 복 수의 정점과 관련시키는 단계; 3D 헤드 템플릿 모델의 메시 상의 복수의 정점에 대한 사용자 제공 키포인트 주 석 세트에 기초하여 제2 키포인트 세트를 식별하는 단계; 및 얼굴의 각각의 키포인트에 의해 대응하는 식별된 특징에 기초하여 제1 키포인트 세트 및 제2 키포인트 세트를 매핑하는 단계를 더 포함할 수 있다. 일부 실시예에서, 변형을 수행하는 단계는, 제1 키포인트 세트의 제2 키포인트 세트에 대한 매핑을 사용 하고, 제1 키포인트 세트와 관련된 변형에 대한 경계 조건을 사용함으로써 3D 헤드 템플릿 모델의 메시를 변형 된 3D 헤드 메시 모델로 변형하는 단계를 포함할 수 있다. 일부 실시예에서, 변형을 수행하는 단계는, 변형 최적화 프로세스에서 키포인트의 위치, 인접성 평활도, 특성 및 원래 위치 중 하나 이상을 포함하는 상이한 제약 조건을 적용하는 단계를 더 포함할 수 있다. 일부 실시예에서, 변형을 수행하는 단계는, 변형 프로세스에 키포인트의 위치, 인접성 평활도, 특성 및 원래 위치 중 하나 이상의 가중 합계인 제약 조건을 적용하는 단계를 더 포함할 수 있다. 일부 실시예에서, 제1 키포인트 세트를 식별하는 단계는 합성곱 신경망(CNN)을 사용하는 단계를 포함한다. 일부 실시예에서, 변형은 라플라시안 연산자가 없는 아핀 변형을 포함한다. 일부 실시예에서, 아핀 변형은 평 활도 파라미터를 변경함으로써 변형 튜닝을 달성한다. 일부 실시예에서, 3D 헤드 템플릿 모델의 메시는 스켈레톤과 결합하지 않고 변형될 수 있다. 일부 실시예에서, 얼굴 변형 모델은 사실적 스타일 모델 또는 만화 스타일 모델을 포함한다. 일부 실시예에서, 단계 2850에서, 블렌드셰이프 방법을 변형된 3D 헤드 메시 모델에 적용하는 단계는, 키포인트 의 위치에 따라 변형된 3D 헤드 메시 모델의 키포인트에 각각의 블렌드 가중치를 지정하는 단계; 및 상이한 블 렌드 가중치로 키포인트에 상이한 레벨의 변형을 적용하는 단계를 포함한다. 일부 실시예에서, 단계 2850에서, 블렌드셰이프 방법을 변형된 3D 헤드 메시 모델에 적용하는 단계는, 변형된 3D 헤드 메시 모델의 후면을 변형 전 3D 헤드 템플릿 모델의 원래 후면 형상과 동일한 형상으로 유지하는 단계 를 포함한다. 일부 실시예에서, 템플릿 모델 상의 시맨틱 부분은 눈, 속눈썹 또는 치아로 제한되지 않는다. 안경과 같은 장 식은 얼굴 메시에 새로운 키포인트를 추가하고 추적함으로써 잠재적으로 적응 조정될 수 있다. 일부 실시예에서, 템플릿 모델의 키포인트는 수동으로 추가된다. 일부 다른 실시예에서, 상이한 템플릿 모델에 대한 키포인트를 자동으로 추가하기 위해 딥러닝 기술이 또한 이용될 수 있다. 일부 실시예에서, 아핀 변형의 해결 절차는 컴퓨팅 성능을 추가로 개선하기 위해 일부 수치 트릭을 이용할 수 있다. 일부 실시예에서, 여기에서 개시된 시스템 및 방법은 하기에서 열거된 것과 같은 많은 이점을 갖는 경량 키포인 트 기반 얼굴 아바타 생성 시스템을 형성한다: 입력 이미지에 대한 낮은 요구사항. 이 시스템 및 방법은 얼굴이 카메라를 직접 향할 필요가 없으며, 어느 정 도의 평면내 회전, 평면외 회전 및 폐색은 성능에 분명히 영향을 미치지 않을 것이다. 실제 게임과 만화 게임 모두에 적용 가능하다. 현재 시스템은 게임 스타일을 실제 스타일로 제한하지 않으며, 만화 스타일에도 적용될 수 있다. 경량 및 맞춤형. 현재 시스템의 각각의 모듈은 상대적으로 가볍고 모바일 장치에 적합하다. 이러한 시스템의 모듈은 분리되어 있으며 사용자는 다양한 게임 스타일에 따라 다양한 조합을 채택하여 최종 얼굴 생성 시스템을 구축할 수 있다. 일부 실시예에서, 주어진 단일 픽처에 대해, 주요 얼굴이 먼저 검출되고, 키포인트 검출이 수행된다. 실제 픽 처에서, 얼굴은 카메라를 향하지 않을 수 있으며, 실제 얼굴은 항상 완벽하게 대칭이 아니다. 따라서, 원래 픽 처의 키포인트는 통일되고 대칭적이며 매끄러운 키포인트 세트를 얻기 위해 전처리된다. 그런 다음, 커진 눈 및 작은 얼굴과 같은 게임의 특정 스타일에 따라 키포인트가 조정된다. 스타일화된 키포인트를 얻은 후, 스타 일화된 키포인트는 게임에서 얼굴 모델의 제어 파라미터, 일반적으로 뼈대 파라미터 또는 슬라이더 파라미터로 변환된다. 일부 실시예에서, 실제 얼굴의 시야각은 카메라를 직접 향하지 않을 수 있고, 좌우 비대칭 및 키포인트 검출 오 류와 같은 문제가 존재할 수 있다. 도 29는 본 개시의 일부 구현에 따른 예시적인 키포인트 처리 흐름 단계를 도시한 도면이다. 원래 픽처에서 검출된 키포인트는 직접 사용될 수 없으며, 특정 처리가 요구된다. 여 기서, 프로세스는 도 29에 도시된 바와 같이, 정규화, 대칭 및 평활화의 세 단계로 나뉜다. 일부 실시예에서, 실제 얼굴의 키포인트의 예측에 기초한 게임의 표준 얼굴 모델은 조정될 필요가 있다. 이 프 로세스는 게임의 표준 얼굴 모델과 실제 얼굴의 키포인트가 스케일, 위치 및 방향 측면에서 정렬되는 것을 보장 해야 한다. 따라서, 예측된 키포인트와 게임 얼굴 모델의 키포인트 정규화는 스케일 정규화, 변환 정규 화, 및 각도 정규화 부분을 포함한다. 일부 실시예에서, 원래 검출의 모든 3차원 얼굴 키포인트는 p로 정의되며, 여기서 i번째 키포인트는 pi={xi, yi, zi}이다. 예를 들어, 정규화된 원점은 키포인트 1번과 17번의 중간점(도 1의 키포인트 정의 참조), 즉 c=(p1 + p17)/2로 정의된다. 스케일의 경우, 원점으로부터 첫 번째와 17번째 사이의 거리는 1로 조정되어 스케일과 변환 으로 정규화된 3차원 키포인트가 p'=(p-c)/||p1-c||가 될 수 있게 한다. 일부 실시예에서, 스케일 및 변환을 정규화한 후, 얼굴 방향이 추가로 정규화된다. 도 29의 이미지에 도 시된 바와 같이, 실제 사진의 얼굴은 렌즈를 직접 향하지 않을 수 있으며, 항상 3개의 좌표축에 존재할 수 있는 특정 편향이 있을 것이다. 얼굴의 방향이 카메라를 향할 수 있도록 x, y, z 좌표축을 따른 얼굴의 예측된 3차 원 키포인트가 순차적으로 회전된다. x를 따른 회전의 경우, 키포인트 18과 24(도 1의 키포인트 정의 참조)의 z 좌표가 정렬된다. 즉, 회전 매트릭스 RX를 획득하기 위해 콧등의 가장 윗부분의 깊이가 코의 밑부분과 같은 깊이가 되도록 한다. y축을 따른 회전의 경우, 키포인트 1과 17의 z 좌표는 회전 매트릭스 RY를 얻도록 정렬된 다. z축을 따른 회전의 경우, 키포인트 1과 17의 y 좌표는 회전 매트릭스 RZ를 얻도록 정렬된다. 따라서, 키 포인트의 방향은 정렬되고 정규화된 키포인트는 아래에 나타낸 바와 같다. Pnorm = RZ × RY × RX × P' 일부 실시예에서, 정규화된 키포인트의 스케일, 위치 및 각도는 균일하도록 조정되었지만, 획득된 키포인트는 종종 완벽한 얼굴이 아니다. 예를 들어, 콧등은 중앙에서 일직선이 아니며, 얼굴 특징이 대칭적이지 않을 수있다. 이것은 사진 속 실제 얼굴이 표정이나 그 자체의 특성상 완벽한 대칭이 아니고, 키포인트 예측 시 추가 적인 오류가 발생하기 때문이다. 실제 얼굴은 대칭이 아닐 수 있지만, 게임의 얼굴 모델이 대칭이 아니면, 보 기 흉하고 사용자 경험을 크게 저하시킬 것이다. 따라서, 2908에 도시된 바와 같이 키포인트 대칭이 필요한 프 로세스이다. 키포인트가 정규화되었기 때문에, 일부 실시예에서, 간단한 대칭 방법은 원래의 y 및 z 좌표를 대체하기 위해 모든 좌측 및 우측 대칭 키포인트의 y 및 z 좌표를 평균화하는 것이다. 이러한 방법은 대부분의 경우 잘 작동 하지만 얼굴이 y축 방향으로 큰 각도로 회전하는 경우, 성능이 희생될 것이다. 일부 실시예에서, 도 29의 사람 얼굴을 예로 사용하면, 얼굴이 좌측으로 큰 각도로 편향되어 있는 경우, 눈썹의 일부가 보이지 않을 것이다. 동시에, 원근법으로 인해 좌측 눈이 우측 눈보다 작아질 것이다. 3D 키포인트는 원근 관계로 인한 영향을 부분적으로 보상할 수 있지만, 키포인트에 대응하는 3D 키포인트의 2D 투영은 여전히 픽처 상에서 유지되어야 한다. 따라서, 과도하게 큰 각도 편향은 3D 키포인트 검출 결과에서 눈과 눈썹의 크기 가 확연히 차이가 나게 된다. 각도에 의한 영향에 대처하기 위해, y축을 따른 얼굴 편향 각도가 큰 경우, 렌즈 에 가까운 눈과 눈썹이 메인 눈과 메인 눈썹으로 사용되고, 그들이 각도 편향으로 인한 오류를 줄이기 위해 반 대편으로 복사된다. 일부 실시예에서, 키포인트의 예측 오류가 불가피하기 때문에, 일부 개별적인 경우에, 대칭화된 키포인트는 여 전히 실제 얼굴과 일치하지 않을 수 있다. 실제 얼굴의 형상과 얼굴 특징이 상당히 다르기 때문에. 미리 정의 된 파라미터화된 곡선을 사용하여 비교적 정확한 설명을 얻기가 어렵다. 따라서, 2910에서 도시된 바와 같이 평활화를 하는 경우, 예를 들어 얼굴 윤곽, 눈, 눈썹, 아랫입술 등 일부 영역만이 평활화된다. 이러한 영역은 기본적으로 단조롭고 매끄러움을 유지한다. 즉, 들쭉날쭉한 상태가 없다. 이러한 경우, 타깃 곡선은 항상 볼 록한 곡선이거나 오목한 곡선이어야 한다. 일부 실시예에서, 키포인트가 볼록한 곡선(또는 오목한 곡선)의 정의를 충족하는지 여부는 관련된 경계에 대해 하나씩 확인된다. 도 30은 본 개시의 일부 구현에 따른 예시적인 키포인트 평활화 프로세스를 도시한 도 면이다. 도 30에 도시된 바와 같이, 일반성을 잃지 않고, 타깃 곡선은 볼록해야 한다. 각각의 키포인트(3002, 3004, 3006, 3008, 3010)에 대해, 그 위치가 인접한 좌측 및 우측 키포인트의 라인보다 위에 있는지 여부가 확 인된다. 조건이 충족되면, 현재 키포인트가 볼록 곡선 요구사항을 충족함을 의미한다. 그렇지 않으면, 현재 키포인트가 좌측과 우측 키포인트를 연결하는 라인까지 위로 이동된다. 예를 들어, 도 30에서, 키포인트(300 6)는 볼록 곡선의 한계를 충족하지 못하고, 위치 3012로 이동될 것이다. 여러 키포인트가 이동되면, 곡선은 이 동 후 볼록 또는 오목한 것으로 보장되지 않을 수 있다. 따라서, 일부 실시예에서, 다수 라운드의 평활화가 사 용되어 비교적 평활한 키포인트 곡선을 얻을 수 있다. 상이한 게임은 상이한 얼굴 스타일을 갖는다. 일부 실시예에서, 실제 얼굴의 키포인트는 게임에서 요구되는 스 타일로 변환될 필요가 있다. 실제 스타일의 게임 얼굴은 비슷하지만, 만화 얼굴은 매우 다르다. 따라서, 키포 인트의 스타일화에 대한 통일된 표준을 갖기가 어렵다. 실제 사용에서 스타일화의 정의는 특정 게임 스타일에 따라 얼굴의 특성을 조정하는 게임 설계자로부터 비롯된다. 일부 실시예에서, 대부분의 게임에 필요할 수 있는 보다 일반적인 얼굴 조정 방식이 구현된다. 예를 들어, 얼 굴 길이 조정, 폭 조정, 얼굴 특징 등. 다양한 게임 아트 스타일, 조정 레벨, 줌 비율 등에 따라, 사용자 정의 보정이 행해질 수 있다. 동시에, 사용자는 예를 들어 눈 형상을 직사각형으로 변경하는 등의 특별한 스타일 조 정 방법을 사용자 정의할 수도 있다. 시스템은 모든 조정 방식을 지원할 수 있다. 일부 실시예에서, 스타일화된 얼굴의 키포인트를 사용하여, 변형된 얼굴의 키포인트가 타깃 키포인트의 위치에 도달할 수 있도록 표준 게임 얼굴이 변형된다. 대부분의 게임은 뼈대나 슬라이더와 같은 제어 파라미터를 사용 하여 얼굴을 조정하므로, 키포인트를 타깃 위치로 이동하기 위해 제어 파라미터 세트가 필요하다. 서로 다른 게임에서 뼈대 또는 슬라이더의 정의가 다를 수 있고, 언제든지 수정할 가능성이 있기 때문에, 키포 인트에서 뼈대 파라미터까지 간단한 파라미터화된 함수를 직접 정의하는 것은 실현 가능하지 않다. 일부 실시 예에서, 기계 학습 방법은 신경망을 통해 키포인트를 파라미터로 변환하는 데 사용되며, 이는 K2P(keypoints to parameters) 네트워크라고 한다. 일반적인 파라미터와 키포인트의 개수가 크지 않기 때문에(일반적으로 100개 미만), 일부 실시예에서, K 레이어 완전 연결 네트워크가 사용된다. 도 31은 본 개시의 일부 구현에 따른 예시적인 키포인트 대 제어 파라미터(K2P) 변환 프로세스를 도시한 블록도 이다. 기계 학습 방법을 사용하기 위해, 일부 실시예에서, 먼저 뼈대 또는 슬라이더 파라미터가 무작위로 샘플링되고, 게임 클라이언트에게 공급되며, 키포인트가 생성된 게임 얼굴에서 추출된다. 이러한 방식으로, 많은 훈련 데이터가 획득될 수 있다(파라미터 3112 및 키포인트 3114 쌍). 그런 다음, 자기 감독 기계 학습 방 법이 구현되며, 이는 두 단계로 나뉜다. 제1 단계는 키포인트에 대한 게임 파라미터를 생성하는 프로세스를 시 뮬레이션하기 위해 P2K(parameter to keypoint) 네트워크를 훈련하는 것이다. 제2 단계에서, 많은 개수 의 레이블이 지정되지 않은 실제 얼굴 이미지가 사용되어 실제 얼굴 키포인트를 생성한 다음 여기 에서 설명된 방법에 따라 대량의 스타일화된 키포인트를 생성한다. 이러한 레이블이 지정되지 않은 스타 일화된 키포인트는 자기 감독 학습 훈련 데이터이다. 일부 실시예에서, 키포인트 세트 K는 출력 파라미 터 P를 얻기 위한 학습을 위해 K2P 네트워크에 입력된다. 이러한 키포인트에 대응하는 이상적인 파라미 터의 실측값이 사용될 수 없기 때문에, P는 키포인트 K'를 획득하기 위해 제1 단계에서 훈련된 P2K 네트워크 에 추가로 입력된다. 일부 실시예에서, K와 K' 사이의 평균 제곱 오차(Mean Square Error, MSE) 손실을 계산함으로써, K2P 네트워크가 학습될 수 있다. 일부 실시예에서, 제2 단계 동안, P2K 네트워크는 고정되고 계속 조정되지 않을 것이다. P2K 네트워크의 도움으로, 게임 클라이언트의 파라미터를 키포인트로 제어하는 프로세스는 신경망을 사용하여 시뮬레이션됨으로써, 제2 단계에서 K2P 네트워크 학 습을 위한 기반을 마련한다. 이러한 방식으로, 파라미터에 의해 생성된 최종 얼굴은 생성된 타깃 스타일화된 얼굴의 키포인트에 가깝게 유지된다. 일부 실시예에서, 동시에, K와 K' 사이의 MSE 손실을 계산하는 경우 대응하는 가중치를 조정함으로써 눈의 키포 인트와 같은 특정 키포인트에 대한 가중치가 추가된다. 키포인트의 정의가 미리 정의되어 있고 게임 클라이언 트의 뼈대나 슬라이더의 영향을 받지 않기 때문에, 가중치를 조정하기가 더 쉽다. 일부 실시예에서, 실제 애플리케이션에서, 모델의 정확도를 향상시키기 위해, 분리될 수 있는 부분에 대해, 신 경망이 개별적으로 훈련될 수 있다. 예를 들어, 일부 뼈대 파라미터는 눈 영역의 키포인트에만 영향을 주고 다 른 파라미터는 이러한 영역에 영향을 미치지 않는 경우, 이러한 파라미터와 이러한 키포인트의 부분은 독립 영 역 세트를 형성한다. 별도의 K2P 모델은 그러한 지역의 각각의 그룹에 대해 훈련되며, 각각의 모델은 더 가벼운 네트워크 설계를 채택할 수 있다. 이는 모델의 정확도를 더욱 향상시킬 수 있을 뿐만 아니라, 계산 복 잡성도 줄일 수 있다. 도 32는 본 개시의 일부 구현에 따른 모바일 게임의 자동 얼굴 생성의 일부 예시적인 결과를 도시한다. 도 32 에 도시된 바와 같이, 원래 얼굴 이미지(3202, 3206)로부터 게임 얼굴 아바타 이미지 생성(3204, 3208)까지의 결과가 도시되어 있다. 일부 실시예에서, 스타일화되는 경우, 열린 입은 닫히고, 코, 입, 얼굴 형상, 눈 및 눈 썹에 다른 레벨의 제한 및 만화화(cartoonization)가 적용된다. 최종 생성된 결과는 여전히 특정 사람 얼굴 특 성을 유지하고 게임 스타일의 미적 요구사항을 충족한다. 도 33은 본 개시의 일부 구현에 따라 실제 사람의 2D 얼굴 이미지를 사용하여 게임에서 아바타의 표준 얼굴을 맞춤화하는 예시적인 프로세스를 도시한 흐름도이다. 실제 사람의 2D 얼굴 이미지를 사용하여 게임에서 아바타의 표준 얼굴을 맞춤화하는 프로세스는 2D 얼굴 이미지 에서 실제 키포인트 세트를 식별하는 단계를 포함한다. 프로세스는 또한 실제 키포인트 세트를 게임의 아바타와 연관된 게임 스타일 키포인트 세트로 변환하는 단계 를 포함한다. 프로세스는 게임 스타일 키포인트 세트를 키포인트 대 파라미터(keypoint to parameter, K2P) 신경망 모델에 적 용함으로써 게임에서 아바타의 표준 얼굴의 제어 파라미터 세트를 생성하는 단계를 추가로 포함한다. 도 31과 관련하여 위에서 언급한 바와 같이, 얼굴 제어 파라미터 세트가 아바타의 표준 얼굴에 적용될 때 조정된 표준 얼굴의 키포인트가 입력 아바타 키포인트 세트와 유사한 키포인트 세트를 가질 수 있도록 상이한 아바타 키포인트 세트가 상이한 얼굴 제어 파라미터 세트에 대응할 수 있으므로, K2P 네트워크는 입력 아바타 키 포인트 세트에 기초하여 얼굴 제어 파라미터 세트를 예측하는 딥러닝 신경망 모델이다. 도 31과 관련하여 위에 서 언급한 바와 같이, K2P 네트워크와 반대로, 2개의 신경망 모델이 서로의 역 프로세스를 수행하는 것으 로 간주될 때 P2K 네트워크와 연관된 출력 아바타 키포인트 세트가 K2P 네트워크와 연관된 입력 아 바타 키포인트 세트와 일치해야 하도록 상이한 얼굴 제어 파라미터 세트가 상이한 아바타 키포인트 세트를 유발 할 수 있으므로, P2K 네트워크는 입력 얼굴 제어 파라미터 세트에 기초하여 아바타 키포인트 세트를 예측 하는 딥러닝 신경망 모델이다. 프로세스는 얼굴 제어 파라미터 세트를 표준 얼굴에 적용함으로써 표준 얼굴의 복수의 얼굴 특징을 조정하는 단 계를 추가로 포함한다. 추가 구현은 다음 특징 중 하나 이상을 포함할 수 있다. 일부 실시예에서, 단계에서, K2P 신경망 모델은, 실제 사람의 복수의 훈련 2D 얼굴 이미지를 획득하고, 복수의 훈련 2D 얼굴 이미지 각각에 대한 훈련 게임 스타일 키포인트 세트를 생성하며, 제어 파라미터 세트를 획득하기 위해 훈련 게임 스타일 키포인트 세트 각각을 K2P 신경망 모델에게 공급하고, 훈련 게임 스타일 키포 인트 세트에 대응하는 예측된 게임 스타일 키포인트 세트를 획득하기 위해 제어 파라미터 세트를 키포인트(P2K) 신경망 모델에게 공급하며, 훈련 게임 스타일 키포인트 세트와 대응하는 예측된 게임 스타일 키포인트 세트 사 이의 차이를 줄임으로써 K2P 신경망 모델을 업데이트함으로써, 훈련된다. 일부 실시예에서, 미리 훈련된 P2K 신경망 모델은, 게임의 아바타와 연관된 뼈대 또는 슬라이더 파라미터를 포 함하는 제어 파라미터 세트를 수신하고, 제어 파라미터 세트에 따라 게임의 아바타에 대한 게임 스타일 키포인 트 세트를 예측하도록 구성된다. 일부 실시예에서, 훈련 게임 스타일 키포인트 세트와 대응하는 예측된 게임 스타일 키포인트 세트 사이의 차이 는 훈련 게임 스타일 키포인트 세트와 대응하는 예측된 게임 스타일 키포인트 세트 사이의 평균 제곱 오차의 합 이다. 일부 실시예에서, 훈련된 K2P 및 미리 훈련된 P2K 신경망 모델은 게임에 특정적이다. 일부 실시예에서, 2D 얼굴 이미지의 실제 키포인트 세트는 2D 얼굴 이미지의 실제 사람의 얼굴 특징에 대응한다. 일부 실시예에서, 게임의 아바타의 표준 얼굴은 다른 실제 사람의 얼굴 이미지에 따라 게임의 다른 캐릭터로 맞 춤화될 수 있다. 일부 실시예에서, 아바타의 변형된 얼굴은 실제 사람의 만화 스타일 얼굴이다. 일부 실시예에서, 아바타의 변 형된 얼굴은 실제 사람의 실제 스타일 얼굴이다. 일부 실시예에서, 단계 3320에서, 실제 키포인트 세트를 게임 스타일 키포인트 세트로 변환하는 단계는, 실제 키포인트 세트를 정규(canonical) 공간으로 정규화하는 단계; 정규화된 실제 키포인트 세트를 대칭화하는 단계; 및 게임의 아바타와 연관된 미리 정의된 스타일에 따라 대칭화된 실제 키포인트 세트를 조정하는 단계를 포함한 다. 일부 실시예에서, 실제 키포인트 세트를 정규 공간으로 정규화하는 단계는, 실제 키포인트 세트를 정규 공간으 로 스케일링하는 단계; 및 2D 얼굴 이미지의 실제 키포인트 세트의 방향에 따라 스케일링된 실제 키포인트 세트 를 회전시키는 단계를 포함한다. 일부 실시예에서, 실제 키포인트 세트를 게임 스타일 키포인트 세트로 변환하는 단계는 미리 정의된 볼록 또는 오목 곡선 요구사항을 충족시키기 위해 대칭화된 키포인트 세트를 평활화하는 단계를 더 포함한다. 일부 실시예에서, 게임의 아바타와 연관된 미리 정의된 스타일에 따라 대칭화된 실제 키포인트 세트를 조정하는 단계는 얼굴 길이 조정, 얼굴 폭 조정, 얼굴 특징 조정, 줌 조정, 및 눈 형상 조정 중 하나 이상을 포함한다. 여기에서 개시된 시스템 및 방법은 실제 스타일 및 만화 스타일 게임 모두에 대한 다양한 게임을 위한 자동 얼 굴 생성 시스템에 적용될 수 있다. 이 시스템은 통합하기 쉬운 인터페이스를 가지고 있어 사용자 경험을 향상 시킨다. 일부 실시예에서, 여기에서 개시된 시스템 및 방법은 다양한 게임을 위한 3D 얼굴 아바타 생성 시스템에서 사용 될 수 있고, 복잡한 수동 튜닝 프로세스는 사용자 경험을 개선하기 위해 자동화된다. 사용자는 셀카를 찍거나 기존 사진을 업로드할 수 있다. 시스템은 사진 속 얼굴에서 특징을 추출한 다음, AI 얼굴 생성 시스템을 통해 게임 얼굴의 제어 파라미터(예: 뼈대 또는 슬라이더)를 자동으로 생성할 수 있다. 게임 엔드(end)는 이러한 파 라미터를 사용하여 얼굴 아바타를 생성하므로 생성된 얼굴이 사용자의 얼굴 특징을 가질 수 있게 한다. 일부 실시예에서, 이러한 시스템은 키포인트 정의, 스타일화 방법, 스켈레톤/슬라이더의 정의 등을 포함하여 다 양한 게임에 따라 쉽게 맞춤화될 수 있다. 사용자는 특정 파라미터만 조정하거나, 모델을 자동으로 재훈련하거 나, 또는 사용자 정의 제어 알고리즘을 추가하도록 선택할 수 있다. 이러한 방식으로, 본 발명은 상이한 게임 에 쉽게 배포될 수 있다.추가 실시예는 또한 다양한 다른 실시예에서 조합되거나 그렇지 않으면 재배열된 상기 실시예의 다양한 서브세 트를 포함한다. 여기서, 본 출원의 실시예의 이미지 처리 장치는 첨부된 도면의 설명을 참조하여 구현된다. 이미지 처리 장치 는 다양한 형태, 예를 들어 서버 또는 단말(예를 들어, 데스크탑 컴퓨터, 노트북 컴퓨터, 스마트폰)과 같은 다 양한 유형의 컴퓨터 장치로 구현될 수 있다. 본 출원의 실시예의 이미지 처리 장치의 하드웨어 구조는 아래에 서 추가로 설명된다. 도 34는 이미지 처리 장치의 전체 구조가 아닌 예시적인 구조를 도시한 것으로 이해될 수 있으며, 도 34에 도시된 일부 또는 전체 구조는 필요에 따라 구현될 수 있다. 도 34를 참조하면, 도 34는 본 출원의 실시예에 따른 이미지 처리 장치의 선택적 하드웨어 구조의 개략도이고, 실제 애플리케이션에서, 애플리케이션을 실행하는 서버 또는 다양한 단말에 적용될 수 있다. 도 34에 도시된 이미지 처리 장치는 적어도 하나의 프로세서, 메모리, 사용자 인터페이스 및 적어도 하나의 네트워크 인터페이스를 포함한다. 이미지 처리 장치의 컴포넌트는 버스 시스템에 의 해 함께 연결된다. 버스는 컴포넌트들 간의 연결 및 통신을 구현하도록 구성된다는 것을 이해할 수 있다. 버스 시스템은 데이터 버스 외에 전원 버스, 제어 버스 및 상태 신호 버스를 더 포함할 수 있다. 그러나, 명확한 설명을 위해, 모든 버스는 도 34에서 버스 시스템으로 표시된다. 사용자 인터페이스는 디스플레이, 키보드, 마우스, 트랙볼, 클릭 휠, 키, 버튼, 터치패드, 터치스크린 등 을 포함할 수 있다. 메모리는 휘발성 메모리 또는 비휘발성 메모리일 수 있거나, 또는 휘발성 메모리 및 비휘발성 메모리 모 두를 포함할 수 있음을 이해할 수 있다. 본 출원의 실시예에서 메모리는 이미지 처리 장치의 작동을 지원하기 위해 상이한 유형의 데이터를 저장하도록 구성된다. 데이터의 예는 실행 가능한 프로그램과 같은 임의의 컴퓨터 프로그램 및 이미지 처리 장치에서 작동을 수행하는 데 사용되는 운영체제를 포함하고, 본 출원의 실시예의 이미지 처 리 방법을 수행하는 데 사용되는 프로그램은 실행 가능한 프로그램에 포함될 수 있다. 본 출원의 실시예에서 개시된 이미지 처리 방법은 프로세서에 적용될 수 있거나, 또는 프로세서에 의해 수행될 수 있다. 프로세서는 집적 회로 칩일 수 있고 신호 처리 능력을 갖는다. 구현 과정에서, 이미지 처리 방법의 각각의 단계는 프로세서 내의 하드웨어의 집적 로직 회로 또는 소프트웨어 형태의 명 령어를 사용하여 완성될 수 있다. 전술한 프로세서는 범용 프로세서, 디지털 신호 프로세서(digital signal processor, DSP), 다른 프로그램 가능 로직 장치, 이산 게이트, 트랜지스터 로직 장치, 이산 하드웨어 컴포넌트 등일 수 있다. 프로세서는 본 출원의 실시예에서 제공되는 방법, 단계 및 로직 블록도를 구현 하거나 실행할 수 있다. 범용 프로세서는 마이크로프로세서, 임의의 종래 프로세서 등일 수 있다. 본 출원의 실시예에서 제공되는 방법의 단계는 하드웨어 디코딩 프로세서에 의해 직접 수행될 수 있거나, 또는 디코딩 프 로세서에서 하드웨어와 소프트웨어 모듈을 결합하여 수행될 수 있다. 소프트웨어 모듈은 저장 매체에 위치할 수 있다. 저장 매체는 메모리에 위치한다. 프로세서는 메모리의 정보를 읽고 정보를 하드 웨어와 결합함으로써 본 출원의 실시예에서 제공되는 이미지 처리 방법의 단계를 수행한다. 일부 실시예에서, 이미지 처리 및 3D 얼굴 및 헤드 형성은 서버 그룹 또는 네트워크 상의 클라우드에서 달성될 수 있다. 하나 이상의 예에서, 설명된 기능은 하드웨어, 소프트웨어, 펌웨어 또는 이들의 임의의 조합으로 구현될 수 있 다. 소프트웨어로 구현되는 경우, 기능은 하나 이상의 명령어 또는 코드로서 컴퓨터 판독 가능 매체에 저장되 거나 전송될 수 있으며 하드웨어 기반 처리 장치에 의해 실행될 수 있다. 컴퓨터 판독 가능 매체는 데이터 저 장 매체와 같은 유형의 매체에 대응하는 컴퓨터 판독 가능 저장 매체, 또는 예를 들어 통신 프로토콜에 따라 한 장소에서 다른 장소로 컴퓨터 프로그램의 전송을 용이하게 하는 임의의 매체를 포함하는 통신 매체를 포함할 수 있다. 이러한 방식으로, 컴퓨터 판독 가능 매체는 일반적으로 비일시적인 유형의 컴퓨터 판독 가능 저장 매체 또는 신호 또는 반송파와 같은 통신 매체에 대응할 수 있다. 데이터 저장 매체는 본 출원에서 설명된 구현을 위한 명령어, 코드 및/또는 데이터 구조를 검색하기 위해 하나 이상의 컴퓨터 또는 하나 이상의 프로세 서에 의해 액세스될 수 있는 임의의 이용 가능한 매체일 수 있다. 컴퓨터 프로그램 제품은 컴퓨터 판독 가능 매체를 포함할 수 있다. 여기서 구현의 설명에서 사용된 용어는 특정 구현을 설명하기 위한 목적으로만 사용되며 청구범위를 제한하고자 하는 것은 아니다. 구현 및 첨부된 청구범위의 설명에서 사용된 바와 같이, 단수 형태 \"하나(a)\", \"하나(an)\"및 \"상기(the)\"는 문맥상 명백하게 달리 지시하지 않는 한 복수 형태도 포함하는 것으로 의도된다. 또한, 여기 에서 사용된 \"및/또는\"이라는 용어는 연관된 나열된 항목 중 하나 이상의 임의의 그리고 모든 가능한 조합을 지 칭하고 포함하는 것으로 이해될 것이다. \"포함하다\" 및/또는 \"포함하는\"이라는 용어는 본 명세서에서 사용될 때 명시된 특징, 요소 및/또는 컴포넌트의 존재를 지정하지만, 하나 이상의 다른 특징, 요소, 컴포넌트, 및/또 는 그 그룹의 존재 또는 추가를 배제하지 않는다는 것이 추가로 이해될 것이다. 또한, 제1, 제2 등의 용어가 다양한 요소를 설명하기 위해 여기에서 사용될 수 있지만, 이들 요소는 이러한 용 어에 의해 제한되지 않아야 한다는 것이 또한 이해될 것이다. 이들 용어는 한 요소를 다른 요소와 구별하는 데 에만 사용된다. 예를 들어, 구현의 범위를 벗어남이 없이, 제1 전극은 제2 전극으로 명명될 수 있고, 유사하게 제2 전극도 제1 전극으로 명명될 수 있다. 제1 전극과 제2 전극은 모두 전극이지만, 동일한 전극은 아니다. 본 출원의 설명은 예시 및 설명의 목적으로 제공되었으며, 개시된 형태의 본 발명을 모두 포함하거나 제한고자 하는 것은 아니다. 전술한 설명 및 관련 도면에 제시된 교시의 이점을 갖는 당업자에게는 많은 수정, 변형 및 대체 구현이 명백할 것이다. 본 실시예는 본 발명의 원리, 실제 적용을 가장 잘 설명하고, 당업자가 다양한 구 현에 대해 본 발명을 이해하고 고려되는 특정 사용에 적합한 다양한 수정을 갖는 기본 원리 및 다양한 구현을 가장 잘 활용할 수 있도록 하기 위해 선택되고 설명되었다. 따라서, 청구항의 범위는 개시된 구현의 특정 예에 제한되지 않으며 수정 및 다른 구현이 첨부된 청구항의 범위 내에 포함되도록 의도됨을 이해해야 한다."}
{"patent_id": "10-2023-7018578", "section": "도면", "subsection": "도면설명", "item": 1, "content": "본 개시 내용이 보다 상세하게 이해될 수 있도록, 다양한 실시예의 특징을 참조하여 보다 구체적인 설명이 이루 어질 수 있으며, 그 중 일부는 첨부된 도면에 도시되어 있다. 그러나, 첨부된 도면은 단지 본 개시의 적절한 특징을 예시한 것일 뿐이며, 따라서 설명이 다른 효과적인 특징을 허용할 수 있기 때문에 제한하는 것으로 간주 되어서는 안된다. 도 1은 본 개시의 일부 구현에 따른 예시적인 키포인트 정의를 도시한 도면이다. 도 2는 본 개시의 일부 구현에 따른 예시적인 키포인트 생성 프로세스를 도시한 블록도이다. 도 3은 본 개시의 일부 구현에 따른 초기 거친 위치 맵을 변환하는 예시적인 프로세스를 도시한 도면이다. 도 4는 본 개시의 일부 구현에 따른 전체 얼굴 영역을 커버하지 않는 예시적인 변환된 위치 맵을 도시한 도면이 다. 도 5는 본 개시의 일부 구현에 따른 전체 얼굴 영역을 커버하기 위해 변환된 위치 맵을 정제하는 예시적인 프로 세스를 도시한 도면이다. 도 6은 본 개시의 일부 구현에 따른 위치 맵 정제 알고리즘의 일부 예시적인 결과를 도시한 도면이다. 도 7a 및 도 7b는 본 개시의 일부 구현에 따른 초기 거친 위치 맵에 대한 최종 위치 맵의 일부 예시적인 비교를 도시한다. 도 8a는 본 개시의 일부 구현에 따른 예시적인 안경 분류 네트워크 구조를 도시한 도면이다. 도 8b는 본 개시의 일부 구현에 따른 예시적인 여성 헤어 예측 네트워크 구조를 도시한 도면이다. 도 8c는 본 개시의 일부 구현에 따른 예시적인 남성 헤어 예측 네트워크 구조를 도시한 도면이다. 도 9a는 본 개시의 일부 구현에 따른 일부 예시적인 안경 분류 예측 결과를 도시한다. 도 9b는 본 개시의 일부 구현에 따른 일부 예시적인 여성 헤어 예측 결과를 도시한다. 도 9c는 본 개시의 일부 구현에 따른 일부 예시적인 남성 헤어 예측 결과를 도시한다. 도 10은 본 개시의 일부 구현에 따른 실제 사람의 2D 얼굴 이미지로부터 얼굴 위치 맵을 구성하는 예시적인 프 로세스를 도시한 흐름도이다. 도 11은 본 개시의 일부 구현에 따른 예시적인 색상 추출 및 조정 프로세스를 도시한 흐름도이다. 도 12는 본 개시의 일부 구현에 따른 예시적인 피부 색상 추출 방법을 도시한다. 도 13은 본 개시의 일부 구현에 따른 예시적인 눈썹 색상 추출 방법을 도시한다. 도 14는 본 개시의 일부 구현에 따른 예시적인 동공 색상 추출 방법을 도시한다. 도 15는 본 개시의 일부 구현에 따른 헤어 색상 추출 방법에서 사용되는 예시적인 헤어 색상 추출 영역을 도시 한다. 도 16은 본 개시의 일부 구현에 따른 헤어 색상 추출 영역 내의 헤어 픽셀과 피부 픽셀 사이의 예시적인 분리를 도시한다. 도 17은 본 개시의 일부 구현에 따른 예시적인 아이섀도 색상 추출 방법을 도시한다. 도 18은 본 개시의 일부 구현에 따른 일부 예시적인 색상 조정 결과를 도시한다. 도 19는 본 개시의 일부 구현에 따른 실제 사람의 2D 얼굴 이미지로부터 색상을 추출하는 예시적인 프로세스를 도시한 흐름도이다. 도 20은 본 개시의 일부 구현에 따른 예시적인 헤드 아바타 변형 및 생성 프로세스를 도시한 흐름도이다. 도 21은 본 개시의 일부 구현에 따른 예시적인 헤드 템플릿 모델 구성을 도시한 도면이다. 도 22는 본 개시의 일부 구현에 따른 사실적인 스타일 3D 모델 및 만화 스타일 3D 모델에 대한 일부 예시적인 키포인트 마킹을 도시한 도면이다. 도 23은 본 개시의 일부 구현에 따른 템플릿 모델 렌더링, 수동 표시 키포인트 및 AI 검출 키포인트 사이의 예시적인 비교를 도시한 도면이다. 도 24는 본 개시의 일부 구현에 따른 예시적인 삼각형의 아핀 변환을 도시한 도면이다. 도 25는 본 개시의 일부 구현에 따른 블렌드섀이프 프로세스가 있거나 없는 일부 헤드 모델 변형 결과의 예시적 인 비교를 도시한 도면이다. 도 26은 본 개시의 일부 구현에 따른 상이한 가중치를 갖는 아핀 변형 및 이중조화 변형의 예시적인 비교를 도 시한 도면이다. 도 27은 본 개시의 일부 구현에 따른 사실적인 템플릿 모델을 사용하여 무작위로 선택된 일부 여성 픽처로부터 자동으로 생성되는 일부 예시적인 결과를 도시한다. 도 28은 본 개시의 일부 구현에 따른 실제 사람의 2D 얼굴 이미지로부터 3D 헤드 변형 모델을 생성하는 예시적 인 프로세스를 도시한 흐름도이다. 도 29는 본 개시의 일부 구현에 따른 예시적인 키포인트 처리 흐름 단계를 도시한 도면이다. 도 30은 본 개시의 일부 구현에 따른 예시적인 키포인트 평활화 프로세스를 도시한 도면이다. 도 31은 본 개시의 일부 구현에 따른 키포인트 대 제어 파라미터(K2P) 변환 프로세스를 도시한 도면이다. 도 32는 본 개시의 일부 구현에 따른 모바일 게임의 자동 얼굴 생성의 일부 예시적인 결과를 도시한다. 도 33은 본 개시의 일부 구현에 따른 실제 사람의 2D 얼굴 이미지를 사용하여 게임의 아바타의 표준 얼굴을 맞 춤화하는 예시적인 프로세스를 도시한 흐름도이다. 도 34는 본 개시의 일부 구현에 따른 이미지 처리 장치의 예시적인 하드웨어 구조의 개략도이다. 통상적인 관행에 따라, 도면에 예시된 다양한 특징은 축척에 맞게 그려지지 않을 수 있다. 따라서, 다양한 특 징의 치수는 명확성을 위해 임의로 확장되거나 축소될 수 있다. 또한, 일부 도면은 주어진 시스템, 방법 또는 장치의 모든 컴포넌트를 묘사하지 않을 수 있다. 마지막으로, 명세서 및 도면 전체에 걸쳐 유사한 참조 번호가 유사한 특징을 나타내기 위해 사용될 수 있다."}
