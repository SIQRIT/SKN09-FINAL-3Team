{"patent_id": "10-2020-0187143", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2022-0095532", "출원번호": "10-2020-0187143", "발명의 명칭": "네트워크 환경에서의 디바이스와 서버 간의 인공지능 처리 기능 분할방법", "출원인": "주식회사 쿠오핀", "발명자": "김경수"}}
{"patent_id": "10-2020-0187143", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "통신 네트워크 상에 연결되어 영상 신호 혹은 오디오 신호를 입력받는 복수의 디바이스와 서버를 갖는 네트워크환경에서의 분산 컨볼루션 처리 시스템에 있어서, 상기 각 디바이스는 행렬 곱과 그 합산을 전처리하는 컨볼루션 수단을 가지며, 계산된 특징맵(FM: Feature Map)과 컨볼루션 네트워크(CNN) 구조 정보, 주요 파라미터(WP: Weighting Parameter)를 패킷들로 변환하고, 상기패킷들을 상기 서버로 전달하며, 상기 서버는 분산된 상기 각 디바이스로부터 전달된 상기 패킷들에서 전처리된 컨볼루션 계산 결과값인 상기 특징맵(FM: Feature Map)과 상기 주요 파라미터(WP)을 이용하여 종합적인 학습과 추론 연산을 수행하고, 업데이트된 각 뉴럴 네트워크의 구조에 대한 각 파라미터들을 다시 상기 각 디바이스로 전달하여 업데이트하는 과정을반복함으로써 학습을 수행하는 네트워크 환경에서의 분산 컨볼루션 처리 시스템."}
{"patent_id": "10-2020-0187143", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 각 디바이스는 상기 서버로부터 CNN 초기화 메시지 수신 시 CNN 관련 파라미터를 상기 서버에서 정해준 값으로 초기화하며, 상기 CNN 관련 파라미터는 네트워크 인식 구분자인 NID(Network Identifier), 기 정의된 NN구조에 대한 구분자인 NNA(Neural Network Architecture), 및 NID(Network Id), CNN Type, NL (전체 계층 수),#layer(Convolution Block 내의 층수), #Stride(컨볼루션 처리 시 stride 수), Padding(패딩 유무), ReLU(액티배이션 함수), BN(batch normalization관련 지정), Pooling(풀링 관련 파라미터), Dropout(드롭-아웃 방식 관련 파라미터)을 포함한 뉴럴 네트워크에 관련된 실제 구성요소에 대한 설정값을 지정하는 NNP(Neural NetworkParameter) 중 적어도 하나를 포함하는 네트워크 환경에서의 분산 컨볼루션 처리 시스템."}
{"patent_id": "10-2020-0187143", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 서버는 상기 각 디바이스로부터 상기 패킷을 전달받고, 해당 CNN을 업데이트하라는 요청 메시지를 수신하면, 지금까지 연산된 컨볼루션 연산 결과를 이용하여 추론을 위한 완전결합층의 연산 처리를 수행하며, 그 결과를 이용하여 정의된 Cost Function(Loss function)을 계산하고, Learning parameter에 의해서 각 파라미터를보정하는 작업을 수행하며, 그런 후 업데이트된 WP(Weighting p지ameter)와 LP(Learning parameter)를 상기 각디바이스 쪽으로 업데이트하라는 정보를 Reply하고, 이런 하나의 배치 작업을 계속 반복하되 미리 정의된 Costfunction이 최소값(Loss function이 최소값 0)에 가까워지면 배치 연산을 멈추는 네트워크 환경에서의 분산 컨볼루션 처리 시스템."}
{"patent_id": "10-2020-0187143", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,상기 각 디바이스는 입력되는 상기 영상 신호를 컨볼루션 커널 필터의 크기에 따라서 중첩된 타일로 가공하여,수직 및 수평으로 분할하고 병렬로 컨볼루션 처리하는 네트워크 환경에서의 분산 컨볼루션 처리 시스템."}
{"patent_id": "10-2020-0187143", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서,공개특허 10-2022-0095532-3-상기 각 디바이스는 연속된 픽셀 수평열로부터, 해당 컨볼루션 커널의 크기에 따른 위치값에 일치하는 픽셀을추출하는 방식을 갖는 가속기를 포함하는 네트워크 환경에서의 분산 컨볼루션 처리 시스템."}
{"patent_id": "10-2020-0187143", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서, 상기 각 디바이스는 영상 혹은 오디오 신호를 실시간으로 압축하여, 이벤트 발생 정보와 같이, 상기 서버로 지연없이 전달할 수 있는 코덱, 및 전달 정보를 지연없이 패킷 가공처리를 위한 네트워크 프로세서를 포함하는 네트워크 환경에서의 분산 컨볼루션 처리 시스템."}
{"patent_id": "10-2020-0187143", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에 있어서, 상기 각 디바이스는 비디오 입력 인터페이스를 통해 입력되는 상기 영상 신호를 내부에서 조작이 용이한 데이터형태로 변환하여 고속 버스를 통해, 상기 버스에 연결된 외부 메모리 제어기 통해 외부 메모리에 임시 저장하는비디오 데이터 제어부, 상기 오디오 신호를 입력받아 고속 버스를 통해 외부 메모리에 임시 저장하거나, 시간에대한 조각 처리를 위해서 1D 신호 처리부로 전달하는 오디오 데이터 제어부, 상기 비디오 데이터 제어부로부터내부 변환 데이터를 받아, 컨볼루션 수행을 위한 이미지를 다수의 타일 형태로 조각 낸 후 중첩부분을 고려한영상 조각을 처리하는 2차원 데이터 변환부, 및 상기 오디오 데이터 제어부로부터 받은 오디오 데이터를 1차원가공 처리를 위한 매트릭스로 변환하는 1차원 신호 처리부를 포함하는 네트워크 환경에서의 분산 컨볼루션 처리시스템."}
{"patent_id": "10-2020-0187143", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1항에 있어서, 상기 각 디바이스는 2차원 비디오 입력에 대한 컨볼루션 연산 처리를 수행하는 컨볼루션 어레이, 동시에 오디오입력 신호와 같은 시간적인 데이터에 의미가 있는 시계열 데이터에 대한 행렬 연산을 위한 RNN 프로세서를 포함하는 네트워크 환경에서의 분산 컨볼루션 처리 시스템."}
{"patent_id": "10-2020-0187143", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1항에 있어서, 상기 각 디바이스는 1차원 오디오 정보에 대한 행렬 연산 처리 혹은 2차원 비디오 신호에 대한 컨볼루션 연산의결과로 얻은 특징맵 정보를 지연없이 네트워크을 통해, 상기 서버로 전달하기 위하여 다수의 네트워크 프로세서를 두어서, IP 패킷화 처리와 필요한 프로토콜 스택에 따라서 TCP/IP, UDP/IP 패킷을 네트워크측으로 전달하는기능을 수행하는 것을 특징으로 하는 네트워크 환경에서의 분산 컨볼루션 처리 시스템."}
{"patent_id": "10-2020-0187143", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제1항에 있어서, 상기 각 디바이스는 주요 이벤트 발생 시 혹은 선택된 영상이나 이미지, 음성신호 혹은 오디오 신호 파일을 원본을 서버에 저장 혹은 다른 처리를 위하여, 실시간으로 압축하는 오디오 및 비디오 코덱을 두며 실시간으로 제어하기 위하여 관련 펌웨어를 탑재하여, 실시간 압축 알고리즘을 구동하는 전용 프로세서를 포함하는 네트워크환경에서의 분산 컨볼루션 처리 시스템.공개특허 10-2022-0095532-4-청구항 11 제 1항에 있어서,상기 각 디바이스는 입력되는 음성 혹은 오디오 신호를 받아서, 일정한 샘플링 시간 변위에 따라서, 이전 상태정보와 이와 관련 가중치의 행렬곱과 현재 입력값과 해당 입력의 가중치의 행렬곱과 초기 가중치의 합으로 현재의 상태를 나타내며, 현재 상태값의 가중치 곱으로 출력하는 상태천이 관계에 있어서, 외부 제어 프로세서로부터 제어를 받아서 이전 상태의 가중치, 입력의 가중치, 현재 상태의 가중치 벡터값을 받아서 행렬 곱을 처리하여, 현재 상태와 미래의 상태를 예측하는 네트워크 환경에서의 분산 컨볼루션 처리 시스템."}
{"patent_id": "10-2020-0187143", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 통신 네트워크 상에 연결되어 영상 신호 혹은 오디오 신호를 입력받는 복수의 디바이스와 서버를 갖는 네트워크 환경에서의 분산 컨볼루션 처리 시스템에 있어서, 상기 각 디바이스는 행렬 곱과 그 합산을 전처리하는 컨볼루션 수단을 가지며, 계산된 특징맵(FM: Feature Map)과 컨볼루션 네트워크(CNN) 구조 정보, 주요 파라미터 (뒷면에 계속)"}
{"patent_id": "10-2020-0187143", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 네트워크 환경에서의 디바이스와 서번 간의 인공지능 처리 기능 분할 방법에 관한 것으로, 보다 상세 하게는 분산된 컨볼루션 연산을 디바이스에서 직접 수행하도록 함으로써 서버의 연산 부하를 줄이는 네트워크 환경에서의 분산 컨볼루션 처리 시스템에 관한 것이다."}
{"patent_id": "10-2020-0187143", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "현재 인공지능(AI, Artificial Intelligence) 기술이 자율주행 자동차·드론·인공지능 비서·인공지능 카메라 등 전 산업분야에서 활용되어 새로운 기술혁신을 이루고 있다. 인공지능은 4차 산업혁명을 촉발하는 핵심 동력 으로 평가되고 있으며, 인공지능의 발전은 산업 자동화를 통한 산업구조의 변화뿐만 아니라 사회 제도에까지 영 향을 미치고 있다. 인공지능 기술의 산업·사회적 영향력이 증가하고, 이를 응용한 서비스 개발의 수요가 증가 하면서, 다양한 장치나 디바이스에 인공지능이 탑재되며, 이들이 네트워크에 연결되어 서로 유기적으로 동작할 것이므로 네트워크과 연계된 분산 동작 관련 기술 표준화가 필요한 상황이다. 딥러닝(Deep learning)을 위한 인공신경망은 데이터를 입력받아 신경망을 학습하는 트레이닝(training) 과정과 학습된 신경망으로 자료 인식을 수행하는 추론 (inference) 과정으로 구성된다. 이를 위해 인공신경망 알고리즘으로 많이 사용되는 Convolutional Neural Network(CNN)은 크게 컨볼루션층 (convolution layer)과 완전결합층(fully connected layer)으로 분류할 수 있는데, 두 구분된 속성은 연산량과 메모리 접근 특성이 상반된다. 다층으로 구성된 컨볼루션층(convolution layer)에서의 convolution 연산은 전체 인공신경망 연산량의 90%~99% 를 차지할 정도로 연산량이 많다. 반면 완전결합층(fully connected layer)에서는 신경망의 파라미터, 즉 weight 변수의 사용량이 컨볼루션층에 비해 월등히 많다. 완전결합층들이 전체 인공신경망에서 차지하는 비중은 매우 적지만, 메모리 접근량은 대부분의 비중을 차지할 정도로 많고, 결국 메모리 병목이 나타나 성능 저하를 유발한다. 그러나 대부분 인공지능 응용을 위해서 개발되는 AI 프로세서는 에지(Edge) 전용 혹은 서버 전용 등으로 목표 시장에 맞게 개발되고 있다. 대용량 데이터 세트(Data Set)와 대규모 리소스를 투입하여 장시간 학습과정을 수 행하고, 보다 광범위한 응용에 사용되는 서버용 AI 프로세서는 각종 데이터 세트의 입력과 저장, 이를 입력 받 아서 컨볼루션 처리, 계산된 연산 결과값을 이용하여 학습 과정, 추론 과정을 수행하려면 대단위의 리소스가 구 축되어야 한다. 대용량 서버를 이용한 접근은 구글·아마존·마이크로소프트 등과 같은 글로벌 포털 업체를 중 심으로 투자되고 있다. 음성 신호를 예로 들면, 비영리 기업 Open AI는 GPT-3(Open AI Speech dataset) 학습을 위한 리소스를 공개하 였는데, 기존 신경망 기반 언어처리모델에 비해 10배나 많은 1750억 개 파리미터를 담고 있다. 학습사용 데이터 수는 4,990억 개이며, 학습하는 데 엄청난 리소스를 요구한다. 전체 학습소요 비용은 54억원(4.6M USD) 정도 소 요된다고 알려져 있다. 이에 본 발명에서는 어느 한 지점에서 모든 리소스를 보유하여, 학습과 추론이 모두 이루어지는 방식에서 탈피 하여, 모든 데이터 세트를 분산해서 처리하고, 계산된 데이터를 약속된 데이터 구조를 갖는 패킷으로 상호 전달 하도록 하여 모든 리소스를 서버에 집중 구축되는 것을 피하도록 하였다.중앙 서버집중 방식과는 반대로 휴대용 디바이스 혹은 사용자 주변의 에지단에서 사용되는 인공지능을 위해서는 최대한 간략화된 CNN 구조와 가능한 작은 수의 파라미터를 저장하는 기술로 적용하고 있다. CNN은 계산적으로 비용이 많이 들기 때문에 많은 기업이 고속 및 저전력에서 신경망 기반 추론 시간을 단축하기 위해 모바일 및 임베디드 프로세서 아키텍처를 적극적으로 개발하고 있다. 추론의 정확도를 조금 양보하는 대신에 상대적으로 저가의 리소스를 이용하도록 설계하고 있다. 이에 본 발명에서는 컨볼루션 전처리를 위한 부분은 분산된 각 디바이스에 구현하고, 각 디바이스상의 탑재된 컨볼루션 수단에서 전처리하며, 계산된 특징맵과 컨볼루션 네트워크(CNN) 구조 정보, 주요 파라미터를 표준화된 패킷 구조로 변환하여 서버로 전달하며, 서버에서는 전처리된 컨볼루션 계산 결과와 주요 파라미터 값을 이용하 여 학습과 추론을 하는 기능만을 수행하도록 한다. 이에 따라 모든 리소스가 서버에 집중되는 부분을 피할 수 있으며, 분산 처리된 계산값을 활용하므로 처리 성능 및 속도를 개선할 수 있을 것이다. 물론 중간마다 계산된 값을 상호 전달하는 네트워크 지연을 감수하여야 하지 만, 향후 도래하는 Standalone 방식의 5G망에서는 전달지연이 1ms 수준이므로 무시 가능한 수준이다. 그동안 CNN의 발전과 동시에 대부분의 학계 및 업계에서 GPU를 이용하여 인공신경망 연산을 수행 중이지만, 인 공신경망 연산 전용 하드웨어 가속기 개발을 위한 연구 또한 활발히 이루어지고 있다. 딥 러닝에 GPU가 널리 사 용되는 가장 큰 이유는 딥 러닝에서 사용되는 주요 연산들이 GPU를 활용하기에 매우 적합하기 때문이다. 현재 이미지 처리 딥러닝에서 가장 많이 사용되는 연산은 이미지 컨볼루션(convolution) 연산인데, 이는 GPU에서 매 우 높은 성능이 나오는 행렬 곱셈 연산으로 쉽게 치환이 가능하다. 이미지 컨볼루션을 가속화하기 위해 사용되 는 FFT(Fast Fourier Transform) 연산 또한 GPU에 적합한 것으로 알려져 있다. 그러나 GPU는 프로그램 융통성 측면에서 우수하나, 모든 디바이스 마다 탑재하기에는 너무 고가여서 인공지능을 필요로 하는 모든 디바이스에 탑재 불가능하므로 응용에 맞는 수준의 컨볼루션 처리용 프로세서 개발이 필수적 이다. 이에 본 발명에서는 인공신경망 연산을 위해, GPU보다는 에너지 대비 연산성능이 우수한 전용 가속기 개발에 초 점을 둔다. 또한 본 발명에서는 저가의 디바이스에도 적용 가능한 컨볼루션 프로세싱 소자를 개발 적용하고자 한다. 나아가 영상 및 오디오 입력 시 이를 신호 특성에 맞는 이를 행렬 곱에 적합한 구조로 변환하는 입력변환 부와 CNN과 RNN 처리 어레이, 계산 결과를 IP 패킷화 처리 및 저지연(Low Latency) 전달기능을 수행하는 네트워 크 프로세서(Network processor)들로 구성된 디바이스용 칩을 개발하고자 한다. 선행기술문헌 특허문헌 (특허문헌 0001) 대한민국 공개특허 제10-2020-0127702호(2020. 11. 11. 공개)"}
{"patent_id": "10-2020-0187143", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "이에 본 발명은 상기 문제점을 해결하기 위해 창출된 것으로, 분산된 컨볼루션 연산을 디바이스에서 직접 수행 하도록 함으로써 서버의 연산 부하를 줄이는 네트워크 환경에서의 분산 컨볼루션 처리 시스템을 제공하는 데 그 목적이 있다. 이를 위해 디바이스 장치에 최적의 컨볼루션 연산을 위한 컨볼루션 어레이를 로직회로로 구현하였으며, 이를 위 한 고속처리를 위한 병렬회로로 구성하였다. 또한 디바이스와 서버 간의 역할 분담이 중요하다. 다양한 신경망 네트워크 구조에 따라서 대응 가능한 연산 구조를 가져야 하며, 상호간의 연산 결과를 서로 교환하여, 학습과 추론을 최대한 빨리 수행해야 하므로 빈번한 정보 교환이 지연없이 이루어져야 한다. 이를 위한 패킷전달 전용 네트워크 프로세스 세부 구성을 제안한다. 그러나 본 발명의 기술적 과제들은 위에서 언급한 과제들로 제한되지 않으며, 언급되지 않은 또 다른 기술적 과 제들은 아래의 기재로부터 당업자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2020-0187143", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 실시 예에 따른 통신 네트워크 상에 연결되어 영상 신호 혹은 오디오 신호를 입력받는 복수의 디바이 스와 서버를 갖는 네트워크 환경에서의 분산 컨볼루션 처리 시스템은, 상기 각 디바이스는 행렬 곱과 그 합산을 전처리하는 컨볼루션 수단을 가지며, 계산된 특징맵(FM: Feature Map)과 컨볼루션 네트워크(CNN) 구조 정보, 주 요 파라미터(WP: Weighting Parameter)를 패킷들로 변환하고, 상기 패킷들을 상기 서버로 전달하며, 상기 서버 는 분산된 상기 각 디바이스로부터 전달된 상기 패킷들에서 전처리된 컨볼루션 계산 결과값인 상기 특징맵(FM: Feature Map)과 상기 주요 파라미터(WP)를 이용하여 종합적인 학습과 추론 연산을 수행하고, 업데이트된 각 뉴 럴 네트워크의 구조에 대한 각 파라미터들을 다시 상기 각 디바이스로 전달하여 업데이트하는 과정을 반복함으 로써 학습을 수행한다. 상기 각 디바이스는 상기 서버로부터 CNN 초기화 메시지 수신 시 CNN 관련 파라미터를 상기 서버에서 정해준 값 으로 초기화하며, 상기 CNN 관련 파라미터는 네트워크 인식 구분자인 NID(Network Identifier), 기 정의된 NN 구조에 대한 구분자인 NNA(Neural Network Architecture), 및 NID(Network Id), CNN Type, NL (전체 계층 수), #layer(Convolution Block 내의 층수), #Stride(컨볼루션 처리 시 stride 수), Padding(패딩 유무), ReLU(액티 배이션 함수), BN(batch normalization관련 지정), Pooling(풀링 관련 파라미터), Dropout(드롭-아웃 방식 관 련 파라미터)을 포함한 뉴럴 네트워크에 관련된 실제 구성요소에 대한 설정값을 지정하는 NNP(Neural Network Parameter) 중 적어도 하나를 포함할 수 있다. 상기 서버는 상기 각 디바이스로부터 상기 패킷을 전달받고, 해당 CNN을 업데이트하라는 요청 메시지를 수신하 면, 지금까지 연산된 컨볼루션 연산 결과를 이용하여 추론을 위한 완전결합층의 연산 처리를 수행하며, 그 결과 를 이용하여 정의된 Cost Function(Loss function)을 계산하고, Learning parameter에 의해서 각 파라미터를 보정하는 작업을 수행하며, 그런 후 업데이트된 WP(Weighting p지ameter)와 LP(Learning parameter)를 상기 각 디바이스 쪽으로 업데이트하라는 정보를 Reply하고, 이런 하나의 배치 작업을 계속 반복하되, 미리 정의된 Cost function이 최소값(Loss function이 최소값 0)에 가까워지면 배치 연산을 멈출 수 있다. 상기 각 디바이스는 입력되는 상기 영상 신호를 컨볼루션 커널 필터의 크기에 따라서 중첩된 타일로 가공하여, 수직 및 수평으로 분할하고 병렬로 컨볼루션 처리할 수 있다. 상기 각 디바이스는 연속된 픽셀 수평열로부터, 해당 컨볼루션 커널의 크기에 따른 위치값에 일치하는 픽셀을 추출하는 방식을 갖는 가속기를 포함할 수 있다. 또한 본 발명의 실시례에 따른 디바이스용 컨볼루션 처리기는 외부로부터 입력된 영상 신호를 입력받는 AV 입력 정합부, 상기 AV 입력 정합부로부터 상기 영상 신호를 전달받아 버퍼링하고, 컨볼루션 커널의 크기에 따라서 중 첩된 영상 조각으로 분할하고 상기 분할 데이터를 전달하는 컨볼루션 연산 제어부, 다수 어레이로 구성되어 상 기 컨볼루션 연산 제어부로부터 상기 분할 데이터를 전달받아 분할된 영상 블록별로 독립적인 컨볼루션 연산을 수행하고, 그 결과를 전달하는 컨볼루션 연산 어레이, 다수의 상기 컨볼루션 연산 어레이로부터 컨볼루션 연산 결과인 FM(feature map) 정보들을 수신하여, 연이은 컨볼루션 연산을 위해서 다시 상기 컨볼루션 연산 제어부로 전달하거나, 뉴럴 네트워크 구조상 액티베이션 판단과 풀링 연산을 수행하는 액티브 패스 제어부, 컨볼루션 연 산의 결과인 특징 맵을 네트워크을 통해 서버로 전달하기 위해 IP 패킷을 생성, TCP/IP 혹은 UDP/IP 패킷 가공 을 하는 네트워크 프로세스, 구성블록들을 제어하기 위한 소프트웨어를 탑재하여 운용하는 제어프로세스를 포함 할 수 있다."}
{"patent_id": "10-2020-0187143", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명에 의한 네트워크 환경에서의 분산 컨볼루션 처리 시스템은 분산된 컨볼루션 연산을 디바이스에서 직접 수행하도록 함으로써 서버의 연산 부하를 줄이는 효과를 갖는다. 컨볼루션 연산을 위한 전용 논리회로를 구성하여, 각 단말 디바이스에 분산 함으로써 서버에서 유지해야 하는 연산 부하뿐만 아니라 메모리와 같은 리소스를 감소할 수 있게 하여, 서버에서는 보다 많은 판단과 추론을 위한 상위 기능을 수행 할 수 있는 효과를 갖는다."}
{"patent_id": "10-2020-0187143", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명의 장점 및 특징 그리고 그것들을 달성하는 방법들은 첨부되는 도면과 함께 상세하게 후술되어 있는 실 시례들을 참조하면 명확해질 것이다. 그러나 본 발명은 이하에서 개시되는 실시례들에 한정되는 것이 아니라 또 다른 다양한 형태로 구현될 수 있으며, 단지 본 실시례들은 본 발명의 개시가 완전하도록 하고 본 발명이 속하"}
{"patent_id": "10-2020-0187143", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "는 기술분야에서 통상의 지식을 가진 자에게 발명의 범주를 완전하게 알려주기 위해 제공되는 것이며, 본 발명 은 단지 청구항에 의해 정의될 뿐이다. 명세서 전체에 걸쳐 동일 참조 부호는 동일 구성요소를 지칭한다. 이하 첨부된 도면들을 참고하여 본 발명의 실시례에 따른 네트워크 환경에서의 분산 컨볼루션 처리 시스템에 대 해 설명하도록 한다. 이때 처리 흐름도 도면들의 각 블록과 흐름도 도면들의 조합들은 컴퓨터 프로그램 인스트럭션들에 의해 수행될 수 있음을 이해할 수 있을 것이다. 이들 컴퓨터 프로그램 인스트럭션들은 범용 컴퓨터·특수용 컴퓨터 또는 기타 프로그램 가능한 데이터 프로세싱 장비의 프로세서에 탑재될 수 있으므로, 컴퓨터 또는 기타 프로그램 가능한 데이터 프로세싱 장비의 프로세서를 통해 수행되는 그 인스트럭션들이 흐름도 블록(들)에서 설명된 기능들을 수행하는 수단을 생성하게 된다. 이들 컴퓨터 프로그램 인스트럭션들은 특정 방식으로 기능을 구현하기 위해 컴퓨터 또는 기타 프로그램 가능한 데이터 프로세싱 장비를 지향할 수 있는 컴퓨터 이용 가능 또는 컴퓨터 판독 가능 메모리에 저장되는 것도 가능 하므로, 그 컴퓨터 이용 가능 또는 컴퓨터 판독 가능 메모리에 저장된 인스트럭션들은 흐름도 블록(들)에서 설 명된 기능을 수행하는 인스트럭션 수단을 내포하는 제조 품목을 생산하는 것도 가능하다. 컴퓨터 프로그램 인스트럭션들은 컴퓨터 또는 기타 프로그램 가능한 데이터 프로세싱 장비 상에 탑재되는 것도 가능하므로, 컴퓨터 또는 기타 프로그램 가능한 데이터 프로세싱 장비 상에서 일련의 동작 단계들이 수행되어 컴퓨터로 실행되는 프로세스를 생성해서 컴퓨터 또는 기타 프로그램 가능한 데이터 프로세싱 장비를 수행하는 인스트럭션들은 흐름도 블록(들)에서 설명된 기능들을 실행하기 위한 단계들을 제공하는 것도 가능하다. 또한 각 블록은 특정된 논리적 기능(들)을 실행하기 위한 하나 이상의 실행 가능한 인스트럭션들을 포함하는 모 듈·세그먼트 또는 코드의 일부를 나타낼 수 있다. 또한 몇 가지 대체 실행례들에서는 블록들에서 언급된 기능 들이 순서를 벗어나서 발생하는 것도 가능함을 주목해야 한다. 예컨대 잇달아 도시되어 있는 두 개의 블록들은 사실 실질적으로 동시에 수행되는 것도 가능하고 또는 그 블록들이 때때로 해당하는 기능에 따라 역순으로 수행되는 것도 가능하다. 도 1은 클라우드 AI와 에지(Edge) AI비교 및 뉴럴넷(신경망) 구성례를 나타낸다. 2012년 The Proceedings of the 25th International Conference on Neural Information Processing Systems(Lake Tahoe, NV, Dec. 2012, P.1097-1105.)에 게재된 논문인 \"ImageNet Classification with Deep Convolutional Neural Networks\"에서 Krizhevsky는 AlexNet이라는 간단한 CNN을 제안하였다. 기존의 화상처리기술에 이용한 이미지 분류 방법보다 CNN(Convolution Neural Network)을 이용한 기술이 월등한 성능개선을 보였다. 그 당시 2대의 Nvidia Geforce GTX 580 GPU를 사용하여 6일 동안 학습을 하였으며, (11x11), (5x5), (3x3), convolutions층을 5층과 완전결합층 3개를 사용하였다. AlexNet은 60M(6천만)개 이상 의 model parameters 가지며, 32bit Floating Point format으로 저장 시 250MB storage space를 요구한다. 이후 옥스포드 대학에서는 도 1의 (가)에 도시한 바와 같이, VGGNet에서는 (3*3) 컨볼루션 13층과 완전결합층 (FC) 3층으로 구성하여 총 16층을 이용하여, 인식률을 대폭 개선하였다. 해를 거듭하면서 구글에서 제안한 GoogleNet/Inception, ResNet 등이 개발되면서, 컨볼루션층의 깊이를 수십에서 수백으로 증가시켜 인간의 인식 능력을 능가하는 성능을 제공하게 되었으며, 큰 사이즈 커널보다 작은 사이즈 커널을 중첩 사용하는 것이 성능 이 우수하고, 파라미터수를 감소할 수 있다는 것을 발견하여 다각도로 발전되고 있다. 도 1의 (나)에는 간단한 디바이스 등에서는 복잡한 뉴럴 네트워크 구조보다는 인식 성능이 다소 감소하더라도, 간단한 단말장치에 탑재가능 하도록 간소화된 뉴럴 네트워크를 도시하였다. 그러나 이 두 가지 구성 모두 단일 장치내에서 학습과 추론 도구가 통합되어 탑재되어, 인공지능 처리를 독립적으로 수행하는 방식이다. 이 경우 독립된 장치에서 학습 데이터 세트를 저장하고, 컨볼루션 연산처리와 완전결합층의 분류를 위한 연산 및 이들의 중간 계산값, Feature map을 저장하는 엄청난 용량의 메모리를 모두 유지해야 하므로 비용이 급증하게 된다. 도 2는 본 발명의 일 실시례에 따른 분산 인공지능 개념도이다. 딥러닝에 사용되는 Convolutional Neural Network(CNN)는 크게 컨볼루션층(convolution layer)과 완전결합층 (fully connected layer)으로 구분되는데, 연산량과 메모리 접근 특성이 서로 상반된다. 다층으로 구성된 컨볼 루션층에서의 convolution 연산은 전체 인공 신경망 연산량의 90%~99%를 차지할 정도로 연산량이 많다. 그래서 컨볼루션 연산 시간을 줄이기 위한 대책이 필요하다. 반면 완전결합층(fully connected layer)에서는 신경망의 파라미터, 즉 weight 변수의 사용량이 컨볼루션층에 비해 월등히 많다. 완전결합층들이 전체 인공 신경망에서 차지하는 비중은 매우 적지만, 메모리 접근량은 대부분의 비중을 차지할 정도로 많고 결국 메모리 병목이 나타 나 성능 저하를 유발한다. 따라서 서로 다른 특성을 갖는 두 블록을 하나의 장치나 서버에 집중 구현하는 것보 다 그 특성에 맞게 분산하는 것이 네트워크 지연에 의한 영향보다는 많은 장점을 제공할 수 있다. 향후 도래할 5G망에서는 네트워크 전달 지연이 수 ms이내이므로, 분산 인공 지능 기술이 보다 더 활용 가능성이 높을 것으로 본다. 도 2에 도시된 바와 같이, 통신 네트워크 상에 연결된 수많은 디바이스(D1~D3)에서 영상 신호 혹은 오디오 신호 를 입력받는 경우, 디바이스 상의 탑재된 컨볼루션 수단에서 전처리하고, 계산된 특징맵(FM: Feature Map)과 컨 볼루션 네트워크(CNN) 구조 정보, 주요 파라미터(WP: Weighting Parameter)를 표준화된 패킷 구조로 변환하고, 다수의 디바이스(D1~D3)와 중앙 서버(S1) 간에 약속된 통신규칙에 따라 패킷들을 서버(S1)로 전달하며, 서버 (S1)에서는 분산된 각 디바이스(D1~D3)에서 전처리된 컨볼루션 계산 결과값인 Feature Map(FM) 정보와 주요 파 라미터 값(WP)을 이용하여, 종합적인 학습과 추론 연산을 수행한다. 서버(S1)에서 업데이트된 각 뉴럴 네트워크의 구조에 대한 각 파라미터들을 다시 각 디바이스(D1~D3)로 전달하 여 업데이트 하는 과정을 반복함으로써 학습이 완료된다. 학습이 완료되어 최종 뉴럴 네트워크의 가중치 파라미 터 등이 확정되고 그 이후 영상/오디오 정보가 입력되면, 각 디바이스(D1~D3)에서는 내부의 컨볼루션 처리수단 에서 Feature를 추출하고, 추출된 feature Map을 서버(S1)로 초저지연(Ultra low latency)으로 전달하여 서버 (S1)에서 종합적으로 판단할 수 있도록 해준다. 도 3은 본 발명의 일 실시례에 따른 분산 인공 지능 학습 절차를 나타낸다. 인공지능 클라우드 서버(S1)는 네트워크에 연결된 AI 디바이스(D1)에게 Initialize_CNN 메시지를 보낸다. 이 메시지를 수신하면, 디바이스(D1)는 보유 CNN 관련 파라미터를 서버에서 정해준 값으로 초기화한다. 이 메시지 내에는 다음과 같은 파라미터를 갖는다. - NID(Network Identifier, CNN 네트워크 Id를 부여): 네트워크의 인식 구분자 - NNA(Neural Network Architecture) : 기 정의된 NN 구조에 대한 구분자 - NNP(Neural Network Parameter) : NID(Network Id), CNN Type(CNN 구성 정보, convolution block 등), NL (전체 계층 수를 의미하며, Hidden Layer 수+1 의미함), #layer(Convolution Block 내의 층수), #Stride(컨볼 루션 처리 시 stride 수), Padding(패딩 유무), ReLU(액티배이션 함수), BN(batch normalization 관련 지정), Pooling(풀링 관련 파라미터), Dropout(드롭-아웃 방식 관련 파라미터) 등 뉴럴 네트워크에 관련된 실제 구성요 소에 대한 설정값을 지정한다. 서버에서는 학습을 위한 전처리 컨볼루션 연산을 위해서, Transfer datasets(NID, #dset, ID1, Di1 …IDn, Din) 메시지를 각 디바이스에 전달하여, 서버에서 통합 연산하기보다는 분산해서 컨볼루션 처리하도록 한다. 각 디바이스에 서로 다른 데이터 세트를 전달하여, 컨볼루션 연산을 처리하도록 한다. 이를 위해 서버 측에서는 각 NID(네트워크 인식자)와 전체 데이터세트 수, #dset, 학습에 필요한 데이터세트를 데이터 구분자 Idi(i=1, to n)와 함께 데이터세트 Di1~Din를 전달한다. 각 데이터 세트는 사전에 정해진 해상도 크기에 맞는 이미지 데이터를 전달한다. 반드시 이미지 데이터에 국한하는 것은 아니며, 다른 2차원 데이터나 1 차원 음성 데이터도 가능하다. 서버로부터 데이터 세트를 수신 후, Compute_CNN 메시지를 받으면, 각 디바이스는 컨볼루션 연산(DL1)을 위 한 수단 집합체, 컨볼루션 어레이로 구성된 가속기에서 컨볼루션 연산 처리를 수행한다. 디바이스에서는 컨볼루 션 연산과 ReLU와 같은 액티베이션 연산, Pooling 연산을 수행한다. 일련의 컨볼루션 연산을 마치면, 해당 디바이스(D1)는 메시지 Report CNN(NID, FMc1, FMc2, … , FMcn, Wc1. Wc2, ..Wcn )를 서버로 보낸다. 해당 뉴럴네트워크 인식자와 해당하는 각 컨볼루션층의 Feature Map과 가 중치 weighted parameter들을 같이 서버로 전달한다. 해당 정보 전송을 마치면, 서버로 해당 CNN을 업데이트하 라는 요청 메시지(5, Request_Update)를 보낸다. 그러면 서버(S1)에서는 지금까지 연산된 컨볼루션 연산 결과를 이용하여, 추론을 위한 완전결합층의 연산 처리를 수행하며, 그 결과를 이용하여 정의된 Cost Function(Loss function)을 계산하고, Learning parameter에 의해서 각 파라미터를 보정하는 작업을 수행한다. 그런 후, 서버 에서는 이렇게 업데이트된 WP(Weighting parameter)와 LP(Learning parameter)를 각 디바이스 쪽으로 업데이트 하라는 정보를 Reply 한다. 이런 하나의 배치작업을 계속 반복한다. 메시지 ~의 과정을 반복적으로 처 리하고, 미리 정의된 Cost function이 최소값(Loss function이 최소값 0)에 가까워지면 배치 연산을 멈춘다. 최종 학습이 종료된 후, 서버는 각 디바이스에게 Save CNN(NID, WP, LP) 메시지를 보내어 최종 업데이트된 WP(Weighting parameter)와 LP(Learning parameter)를 전송하여 저장하도록 한다. 그리고 서버에서 Finalize CNN(NID, FC1, FC2, ..FCn) 메시지을 보내어, 완전결합층에서 연산 완료된 완전결합층의 WP인 FC1, FC2, ..FCn를 송신하여, 최종 뉴럴 네트워크의 파라미터를 완성시킨다. 이를 수신한 디바이스는 내부 메모리에 서버에 서 전송한 WP, LP, FC의 파라미터를 저장한다. 이후 입력되는 오디오/비디오 신호를 받으면 해당 가중치 파라미 터를 이용하여 컨볼루션 연산을 수행하여, 임무를 수행하여 각 입력의 object를 판별한다. 위의 파라미터는 하 나의 실시례에 대한 것이며, 다양한 컨볼루션 뉴럴 네트워크의 발전에 따라 가변 가능하다. CNN Processor Array는 통상, 대부분 행렬 연산에서 사용하는 Systolic array로 컨볼루션 연산을 구현 가능하다. 그러나 본 발명에서는 기본적인 Matrix 곱셈기 기반의 구성을 고려하였다. 도 4에서는 초당 60 프레임의 연속된 비디오 입력의 경우, 한 장의 이미지에 대한 컨볼루션 연산을 위한 처리 방식을 행렬 곱 연산(Matrix multiplication)으로 펼쳐서 이해를 돕도록 하였다. 실제 입력되는 영상 이미지의 1장의 해상도를 (10x10)으로 가정했을 때의 실시례이다. (10x10) 이미지를 일렬로 펼치면, 총 100개의 픽셀값을 갖는다. 일렬로 입력되는 픽셀 열을 받아서 컨볼루션 커널 파라미터가 (3x3)을 가정한 경우, 9개 파라미터가 일 렬의 픽셀과 pixel-by-pixel 곱의 1차원으로 도시하면, 도 4와 같이 순차적으로 연산됨을 알 수 있다. 컨볼루션 커널 (3x3)이 각 첫번째 행을 따라서 좌측에서 우측으로 이동하면서, 컨볼루션 연산을 수행한다. 하나의 행을 따라서 연산을 완료 후, 다음의 행에 대한 컨볼루션 연산을 위해서, 첫째 열로 이동 시는 다음 둘째 적색 박스 로 표시된다. 이와 같이, 컨볼루션 연산의 커널(필터)의 움직임을 Matrix로 표현 시 (64 x 100)으로 표현된다. (64 * 100) matrix 와 Input Image (100 * 1)를 matrix multiplication(행렬 곱)으로 표현하면, 행렬 곱 결과 는 (64 *1) 벡터 결과가 나온다. 이를 2차원 FM(Feature Map)은 (8*8)로 표현된다. 그러나 실제 네트워크 전달 을 위한 패킷화 처리를 위해서는 2차원 개념보다는 1차원 일렬로 정렬된 데이터를 파이프 라인 방식으로 패킷화 처리하도록 구현한다. 도 4의 행렬곱 형태로 구현 시 실제 0인 요소 부분이 많이 존재하므로 불필요한 메모리공간을 낭비할 수 있다. 실제 컨볼루션 커널이 (3x3)인 경우, 입력 픽셀렬이 입력되면 9개의 곱셈기와 이를 덧 셈하는 연산기만 있으면 된다. 그러므로 (3x3) 컨볼루션 커널의 Weighting vector를 저장하는 9개 레지스트와 입력 픽셀렬의 9개를 선택 저장하는 레지스트, 9개 곱셈기, 그 결과를 합하는 덧셈기, 그 결과를 저장하는 레지 스트만으로 구현 가능하다. 연속된 프레임 영상을 파이프라인 연산을 실시간 처리하기 위해서는 여러 개의 컨볼루션 연산기를 병렬로 구성 하여, 동시 처리 가능한 구조가 필요하다. 이를 위해서 가상의 (10x10) 이미지를 2개의 컨볼루션 연산기로 구분 하는 방식을 도 5에 도시하였다. (3*3) 컨볼루션 처리를 위해서는 적어도 2개의 라인을 중첩해서 사용해야만 동 시에 처리 가능하다. (10x10) 이미지를 상하로 2 구분 위해서 (6x10) 영상 2개로 분리하면, 동시에 2개의 컨볼 루션 연산 처리가 가능함을 알 수 있다. 만일 커널 필터가 (3*3)이 아니라 증가한다면, 중첩되는 부분도 증가되 어야 한다. 그러나 많은 연구의 결과로 커널 필터의 증가보다는 작은 필터를 반복 적용하는 것이 더 유리하므로, 본 실시례에서는 (3x3)으로 한정하였다. 도 6에서는 영상 해상도의 1/2로 구분하여 컨볼루션하는 2분할 병렬 시차처리에 대해 도시하였다. 컨볼루션 연 산기는 입력 수평 라인별 3개 라인에 대해서 하나의 출력값을 갖기 때문에 출력에 따라 병렬 연산을 위해서 4개 연산기로 구분하고, 하나의 연산기는 영상의 입력되는 수평라인 열 전체 영상 중 임의의 하나 이미지가 (10x1 0)인 경우, 이를 일렬로 입력되는 순서를 고려할 때 전체 이미지 입력시간을 T인 경우, 각 행에 해당하는 horizontal line은 10개로 나누어지고 각 행은 h1의 시간이 소요된다. (3x3) 컨볼루션 커널인 경우, 적어도 2개 의 영상 수평 라인과 3번째 수평 라인의 3개의 픽셀 값들이 입력되어야만 각 픽셀 별 곱셈이 가능하다. 그래서 3개의 수평 라인이 모두 입력되면, Feature map은 하나의 행이 컨볼루션 결과로 만들어진다. 인접 연산기2는 h2~h4에 대한 연산 수행하여, Feature map 다음 행을 계산한다. 그래서 입력 영상을 수평으로 2개 그룹으로 나 누었다면, 각 그룹마다 입력되는 수평 라인이 6개 라인이 모두 입력되면 그룹A의 연산이 끝나지만, 그룹B의 연 산은 h5입력부터 시작하여 h10 라인의 입력이 완료되어야만 컨볼루션 연산이 완료된다. 연산기 C1은 첫째 라인 의 결과를 계산 후, 바로 (t+1) 시간 구간 동안 그룹2의 연산을 수행한다. 이와 같이 파이프라인식으로 연산을 수행하면, 연속된 영상입력이 되어도 일정 지연 후 연속적인 연산 처리가 가능할 것이다. 실제로 CNN 네트워크 구조에 따라서, 이런 컨볼루션 연산은 컨볼루션과 ReLU 액티베이션 연산, 그리고 pooling 과정 등을 거치면서 보다 작은 해상도의 Feature map을 구하기 위해서 이러한 배치(Batch)작업을 반복 수행한다. 반복적으로 수행하기 위해서는 적어도 이런 컨볼루션 연산자 어레이를 구성하여, 연속 반복 연산이 가능하도록 병렬화 하는 것이 중요하다. 그리고 또한 영상의 해상도 크기가 증가하거나, FPS(frame per second, 초당 영상 프레임 처리 수)에 따라서 컨볼루션 어레이를 유기적으로 관리할 필요 있다. 영상의 해상도가 커질 경우, 수평 그룹과 수직 그룹으로 분리하여, 병렬처리 가능하므로 이에 대한 처리 가능하도록 컨볼루션 어레이 제어기법을 사용한다. 도 7에서는 해상도가 큰 영상의 경우, 전체를 4개의 그룹으로 분리하여 병렬처리 하도록 한 개념도이다. 영상을 1/4로 분할하여, 컨볼루션 처리 후 각 병합하면 된다. 여기에서도 컨볼루션 커널이 (3x3)이면 2개의 수평/수직 라인을 중첩해서 구분한다. 영상 해상도가 FHD(해상도,1920x1080), UHD(해상도3840*2160) 등과 같이, 실제 사용 하는 높은 해상도의 경우, 기존의 영상/이미지 등 인공지능에 사용하는 각 종 데이터 세트의 해상도 보다 많이 크다. 그래서 표준 영상의 입력에 컨볼루션을 적용해서 object를 추출하기 위한 전처리 수행하고, 주어진 알고 리즘을 수행 후, 찾은 대상물(object)에 대해서 데이터 세트와 동일한 영상 크기로 정규화하는 것이 필요 할 것 이다. 도 8에서는 일반적인 영상 해상도가 큰 경우, (3x3) 컨볼루션 처리 시 2개의 중첩 라인을 이용하여 다수의 영상 으로 구분하는 방법을 도시하였다. 도 9에는 컨볼루션 연산기 어레이를 구현하기 위한 블록 구성을 나타낸다. 본 발명의 실시례에서는 (4 x 4) 컨 볼루션 어레이의 실시례에 대해서 도시하였다. 실제 구현에서는 보다 다수의 어레이 (m, n)을 구성하여, 입력되 는 다양한 영상 크기와, CNN 네트워크의 구조에 따라서 다양하게 운영하기 위해 구현할 것이다. 도 9의 CAC(Convolution array controller, 101)는 외부 메모리에 저장된 컨볼루션 연산에 사용하는 커널필터 값인 WP(Weighting parameter)값을 읽어 와서, KWB(Kernel Weight buffer, 102)에 저장한다. 그 후 KWB는 이 (3x3) 9개 값을 모든 컨볼루션 요소(105-1~105-4, 106-1~106-4, 107-1~107-4, 108-1~108-4)에 각 해당 라인 K1~K4를 통해서 모두 전달하여, 컨볼루션 연산 시의 커널의 가중변수로 사용한다. 이와는 별개로 입력 영상의 픽셀 열들은 CAC을 통해서, 외부 버퍼에 저장된 해상도의 영상 중 하나의 이미지를 읽어와서, CNTL-IB 제 어신호와 In_Data 버스를 통하여, 일정한 크기 단위(본 실시예에서는 x+1개)로 분할된 수평라인 별로 Inputbuffer from Neuron(IBN)에 임시 저장하며, IBN은 이를 (x, y)로 구성된 영상 타일에 중첩부분을 고려한 (x+1, y+1)의 크기의 조각 영상을 각 해당 행/렬에 따라서, 시리얼 I1, ~I4 라인을 통하여 각 컨볼루션 요소 (CE)로 입력시킨다. 그 후 각 컨볼루션 요소 CE의 독립적인 컨볼루션 연산의 제어는 CAC에서 해당 영상 조 각의 크기에 따라서, 정해진 연산 타이밍 정보를 제어신호CNTL-F와 데이터 Data_F를 통하여Flow controller에 저장하면, FC는 각 컨볼루션 요소의 타이밍정보 F1 ~F4를 발생하여, 각 CE의 컨볼루션 연산을 동작 제어한다. 각 컨볼루션 요소에서 각자 연산한 결과를 매 행렬곱과 덧셈의 결과를 순차적으로 P1~P4 신호라인를 통해서 받으면, ALU Pooling Block에서는 전체 이미지에 대한 컨볼루션 연산 결과인 특징점 맵 을 생성 저장한다. 도 2의 그림에서 같이, 뉴럴네트워크 구조에 따라서 어떤 경우는 Pooling 연산없이 계속적인 컨볼루션을 반복 시행 시에는 APB는 바이패스되어, Output Buffer to Euron(OBN)을 통하여 Data_FM은 원 래 입력단으로 다시 피드백되어 진다. 만일 컨볼루션 연산 후, 영상의 해상도를 다시 축소하기 위한 Pooling 연 산이 필요한 경우는 APB에서는 이전의 연산 결과인 Feature Map을 (2, 2) 윈도우 사용한 최대값 선택방식 과 같은 주어진 풀링규격(Stride, Pooling 방법에 따라서 풀링 연산을 수행한다. 도 10에는 도 9의 그림에 도시된, 각 컨볼루션 연산요소에 대한 실시례를 표현하였다. 실시례와 같이 (3x3) 컨 볼루션 커널을 사용하는 경우, 9개의 컨볼루션 커널 가중치와 입력되는 영상의 픽셀 열중 해당 9개의 픽셀 값을 선택하여, 상호 곱셈으로 이루어진다. 곱셈 후 9개의 곱셈 결과를 서로 합하면 된다. 커널 가중치 버퍼(Kernel weight buffer, 202)는 앞에서 설명했듯이, 컨볼루션 커널의 가중치 벡터값을 저장하는 버 퍼이다. 이는 서버 측에서 전달해준 패킷 내의 정보를 이용하여, 본 다비이스에 사용할 커널 가중치 값을 저장 하는 곳이다. 이 버퍼는 9개 가중치 값을 신호 W[1:9]를 통해서 병렬로 곱셈기에 입력한다. 이와 동시에, 입력 되는 이전 컨볼루션 연산의 결과인 특징맵 혹은 입력 영상의 이미지 중 해당 영상 조각 정보를 Data_In[x+1, y+1] 데이터를 시리얼 I1신호를 통해, 입력 받아서 해당 픽셀 값을 추출하기 위한 시프트 레지스트을 이용 하여, 컨볼루션에 적용할 픽셀 값을 추출한다. 이를 받으면, 픽셀 선택기는 9개의 병렬 데이터 IP[1:9]를 곱셈 기에 입력하여 곱셈기에서 가중치 W[1:9]와 IP[1:9]를 서로 곱셈 연산을 수행한다. 곱셈기에서는 해 당 디지트 별로 W1*IP1, W2*IP2,…W9*IP9을 각각 수행하며, 그 결과 M[1:9]는 덧셈기에서 모두 덧셈 처리 한다. 그 결과인 FM(특징맵)은 각 행의 위치를 이동함에 따라서 각 결과를 모으면 FM 벡터를 생성 가능한다. 이 결과값을 모아서 벡터로 정리 저장하고, 출력을 전달하는 블록을 두고 있다. 전체 세부 구성별로 동작 시 간을 제어하기 위하여 타이밍 제어기을 둔다. 지금까지 살펴본 2D 영상 혹은 이미지에 대한 컨볼루션 처리의 경우, 이미지를 구성하는 각 픽셀 간에 수직/수 평 인접 픽셀 간에는 공간적인 관계를 유지하므로, 포함하는 주요 특징점을 찾는 데 있어 컨볼루션 연산이 아주 적절성을 갖는다. 그러나 음성 혹은 오디오 신호의 경우, 시간 축에 따라 변화하는 1차원 신호이므로 공간적인 인접 값의 관계가 아니므로 지금까지의 컨볼루션 연산과는 차별성이 있다. 이들 1차원 신호는 그 주어진 시간에 음성 내용이나 언어적인 의미 등이 인접 시간과의 관련성으로 의미를 부여하므로 다른 접근방식이 필요하다. 이 에 대한 별도의 연산자는 도 13에서 제안한다. 실제로 지능형 CCTV와 같은 영상을 입력 받아서, 인공처리 수행을 하는 디바이스에는 직접 원본 영상을 서버 측 으로 전달하여, 학습에 이용 및 상황인지에 필요한 연산을 모두 클라우드 서버에서 수행하고 있다. 또한 어떤 이벤트 발생이 검출 시, 서버에서 입력영상을 저장하는 영상 녹화기능이 필수적이다. 그러나 대부분의 IP CCTV 카메라의 경우, 카메라 자체에서 영상을 압축하여 전송하고, 서버에서는 이를 다시 디코딩하는 기능을 갖는다. 이와 같은 장치는 코덱을 탑재하나, 외부 응용 프로세서를 두어서 프로세서내의 탑재된 응용 소프트웨어 방식으 로 IP 패킷화 처리 후 RTP/UDP/IP 혹은 RTP/TCP/IP 패킷을 스트리밍하거나 서버로 전송한다. 그래서 망을 통한 end-to-end 전달지연은 0.5 ~ 1초 이상 소요되고 있다. 기존에는 영상 압축전달 등의 시간에 비해서 망 전달 지 연이 지배적이어서 압축지연/패킷 전달성능 및 전송지연 등을 크게 관심이 없었으나, 향후 도래할 SA(standalone) 방식의 5G망에서는 전송지연이 1ms이므로 초저지연 서비스가 필수적으로 대두되고 있는바, 이를 위해서는 영상 입력/처리 디바이스에는 초저지연 영상 처리가 필수적이다. 그래서 도 11에서는 영상 입력되는 디바이스에서, 컨볼루션 연산을 수행과 동시에 주요 영상을 압축하여 실시간 (초저지연)으로 압축된 영상을 전달해주는 기능을 포함한 분산형 컨볼루션 처리기이다. 사실 지능형 CCTV의 기 능을 갖는 카메라 등에서, 영상과 오디오 입력 시 에지 단에서 물체를 검출하고 이에 대한 이상함을 바로 인식 하고 처리 한다면, 많은 부분이 실시간 처리가 가능할 것이다. 도 11에 도시한 분산 AI 위한 디바이스용 컨볼루션 처리기 실시례와 같이, 영상 입력 시 AV입력 정합부에 서는 입력된 영상/오디오 신호를 수신하여, 영상 데이터인 경우 R/G/B 등의 채널별 해상도 크기에 맞게 입력을 받아서 정상적인 처리를 위하여, 고속버스 인터페이스부(를 통해서 컨볼루션 연산제어부에 전달하거나 일시적인 저장을 위해서 메모리 제어부로 전달된다. 시스템중앙 제어 프로세서(CPU, 307)은 제어 프로그램에 의해서 이를 실시간 제어하며, 메모리제어부를 통해 외부 메모리에 저장될 수 있다. 컨볼루션 연산제어부 는 실시간 입력되는 영상/오디오 신호를 버퍼링하기 위해서 제어/명령/데이터제어 등을 수행한다. 다수의 컨볼루션 연산을 위한 어레이(CA, 303)는 다수로 구성되어, 분할된 블록별로 독립적인 컨볼루션 연산을 수행한 다. 그 후 그 결과값을 다시 반복적인 연산을 위하여 입력단으로 피드백하기 위하여, 고속인터페이스부를 통하여 다시 컨볼루션 연산제어부로 전달될 수 있으며, 아니면 결과를 비선형 액티베이션 연산을 수행 후, 다음 절차를 위해서 네트워크을 통하여 서버 측으로 전달 가능하다. 이 최종 제어를 액티브 패스제어부에서 수 행한다. 네트워크을 통해 서버 측과 지연없이 전달하기 위해서는 특별히 할당된 네트워크 프로세서으로 전 달되어서, 가중치 파라미터뿐만 아니라 컨볼루션 결과인 FM(feature map) 정보를 패킷화 처리하여, IP 패킷으로 가공 후 TCP/IP 혹은 UDP/IP 등의 프로토콜에 맞게 패킷을 가공한다. 이외에도 입력된 영상과 오디오 정보의 원 소스를 전달하기 위하여, H.264/H.265 압축 연산과 오디오의 AAC 압축을 위한 A/V CODEC을 두고 있으며, 코딩을 위한 알고리즘 수행을 위하여 프레임 단위 저장이 가능한 internal memory을 구비한다. 이 또한 압 축된 영상/오디오 정보를 서버 측으로 전달하기 위해서는 IP패킷 가공을 위하여, 일련의 네트워크 프로세스 를 사용한다. 이와 같이 별도의 다수의 네트워크 프로세스를 두어서, 네트워크 IP 통신을 위한 프로 토콜 스택 처리와 패킷화(Packetization) 처리, 우선순위 처리 및 네트워크 상태에 따라서 전송 품질을 제어하 는 기능을 한다. 도 12에서는 Audio/Video 동시 처리 가능한 분산 AI 가속기의 상세한 실시례를 도시하였다. 실제 구현에 있어서 메인 제어프로세서를 ARM사의 프로세서와 AMBA 버스 규격을 적용한다. 그래서 다중 채널 버스로, 읽기/쓰기에 최적화 되어 있는 AXI(Advanced eXtensible Interface) 버스와 주변 상대적으로 저속인 주변 인터페이스를 접 속하기 위한 APB(Advanced Peripheral Bus)를 사용하며, 버스 분리를 위한 AXI bridge(407, 415, 416, 418)를 사용한다. 비디오 입력 인터페이스를 통해 입력되는 영상신호는 비디오 데이터 제어부(Video Data controller, 401)에서 칩내에서 핸들링 위한 데이터 형태로 변환하며, 이는 AXI Bridge을 통해 버스에 연결된 외부 메모리 제어 기(Universal Memory Controller, 408)의 제어를 받아서 외부 메모리에 임시 저장한다. 또한 내부 데이터 변환 된 후 비로소 컨볼루션 수행을 위한 이미지를 다수의 타일 형태로 조각 낸 후 중첩 부분을 고려한 영상 조각 처 리를 위해서 2D 영상 타일 변환부로 전달된다. 그 후 조각 낸 각 이미지 조각들을 컨볼루션 처리를 위해서 CAC로 전달한다. 이와 비슷하게 음성 혹은 오디오 신호는 오디오 데이터 제어부(Audio Data controller, 402)를 통해서 입력받아서, 비디오 동일하게 AXI 버스를 통해서 외부 메모리에 임시 저장하거나, RNC 처리와 시 간에 대한 조각 처리를 위해서 1D신호 처리부로 전달된다. 그 후 1D 가공 처리한 오디오 데이터는 RNN 연 산 처리를 위해서, RNC(Recurrent Neural Network Controller, 406)로 전달된다. 여기에서 CNN Processor Array의 구성과 동작은 도 9와 도 10에 설명한 내용을 따른다. 그리고 RNN 프로세서는 도 13을 참조한다. CAC와 RNC은 내부 연산을 수행하며, 결과 등을 일시적으로 저장하기 위하여 각 연산기에 종속된 지역 메모리뱅크(Local Memory Bank, 411, 413)를 사용한다. 각 2D 컨볼루 션 연산의 결과로 얻은 특징맵 정보를 지연없이 네트워크을 통해 서버로 전달하기 위하여, NP(Network Processor, NP3, 424, NP4, 425) 등은 IP 패킷화 처리하고, 필요한 프로토콜 스택에 따라서 TCP/IP, UDP/IP 패 킷을 네트워크 측으로 전달하는 기능을 수행한다. 그리고 주요 이벤트 발생 시 혹은 선택된 영상이나 이미지· 음성신호 혹은 오디오 신호파일을 원본을 서버 측으로 전달하기 위하여, 오디오/비디오 코덱(A/V CODEC. 421)에 서 중앙 제어 프로세서의 제어를 받아서, 외부 메모리에 임시로 저장된 데이터를 AXI bud를 통해서 Local Memory bank3으로 읽어 와서 코딩 처리 수행한다. 이를 위해서 별도의 할당된 NP1, NP2을 두어 서 각 오디오 및 비디오 코덱을 실시간으로 제어한다. 관련 펌웨어를 탑재하여, 실시간 압축 알고리즘을 수행한 다. 이와 같은 일련의 과정을 통해서 압축이 완료되면, NP3, NP4 등은 네트워크 인터페이스 처리를 수행하며, 서버와 통신을 안정되게 수행한다. 전체적인 칩의 기능을 제어하고 상위 어플리케이션 소프트웨어를 이용하기 위하여, 다수의 범용 프로세서를 두어 관리한다. 이를 위한 외부 플래쉬 메모리와 외부 일반 DDR 메모리를 연결하도록 Universal Memory controller을 구비한다. 도 14에는 도 12의 Audio/Video 동시 처리 가능한 분산 AI 가속기에서 오디오 혹은 음성과 같은 시간에 종속성 갖는 시계열 데이터에 대한 머신러닝을 연산하는 최적화 연산기를 도시하였다. 도 15는 같은 Recurrent Neural Network(RNN)이며, RNN의 기본적인 상태 천이도를 나타낸다. 수식에 표시한 출력 y^(t)는 은닉층의 상태 h(t)의 결합되는 가중치 V(t)와 초기값 C(t)에 의해 결정짓는데, 여기 에서는 softmax( ) 함수값을 적용하여 확률적인 가장 가증성이 높은 값을 취하도록 한다. Softmax는 입력받은 값을 출력으로 0~1사이의 값으로 모두 정규화하며, 출력 값들의 총합은 항상 1이 되는 특성을 가진 함수를 말한 다. 확률과 유사한 의미를 갖는다. 히든 상태(은닉층) h(t)는 이전의 상태와 결합되는 가중치 W(t)와 입력의 가중치 U(t) 그리고 상수 b(t)의 관계에서 결정된다. 여기의 실시례에서는 비선형 액티베이션 함수 tanh( )를 취하여 결정된다. 관련 식은 수식에 표시 하였다. ----(수식 1) -----------------(수식 2, 3) --------------------(Weighting parameter변수) 이전의 입력 값과 이전의 히든층(hidden layer, 은닉층)의 상태 결합에 의해서 현재의 은닉층의 상태가 결정되 는 관계를 가지며, 원래 알고 있는 데이터 세트를 적용하여 반복된 연산을 적용하면서, (수식 1)의 loss function을 최소화하는 가중치 파라미터, W, U, V, b, c를 결정하는 최적화 문제이다. 이 모두가 Matrix multiplication(행렬곱) 연산이므로, 기존의 컨볼루션 연산기와는 다른 고차원의 벡터 행렬을 곱 연산할 수 있 어야 한다. 따라서 도 13에서는 이를 위한 RNN 연산을 위한 프로세서를 도시하였다. RNC(Recurrent network controller, 501)은 외부 제어 프로세서로부터 제어를 받아서, 가중치 벡터값, W, U, V, b, c 를 받아서 제어신호 CNTL-W와 버스 Data-W를 통하여, 가중치버퍼인 Weight Buffer에 저장하며, 아울러 입력값인 x(t)와 이전 히든층의 상태인 h(t-1)의 정보를 입력버퍼인 IBN(input buffer from Neuron, 503)에 로딩한다. 그 후 행렬곱 연산을 위 한 Matrix Multiplier는 외부 제어신호를 Flow Controller의 제어를 받아서 행렬곱 연산을 수행한 후, Accumulation register으로 전달한다. 여기에선 행렬곱 결과 연산의 합을 계산하고, AFB(activation function block, 507)에서는 tanh( )와 같은, 비선형 액티베이션 결과를 계산한다. 그 결과치를 이용하여 현재 의 은닉층의 상태값을 결정짓는다. 그리고 softmax와 같은 출력값을 계산한 후, 이들 값을 다시 다음 (t+1)의 연산을 위해서 OBN(Output buffer to Neuron, 508)은 이들 값을 입력단으로 피드백 처리한다. 한편 상술한 본 발명의 실시례들은 컴퓨터에서 실행될 수 있는 프로그램으로 작성 가능하고, 컴퓨터로 읽을 수 있는 기록 매체를 이용하여 상기 프로그램을 동작시키는 범용 디지털 컴퓨터에서 구현될 수 있다. 상기 컴퓨터 로 읽을 수 있는 기록매체는 마그네틱 저장매체(예를 들면 롬· 플로피 디스크·하드디스크 등), 광학적 판독 매체(예를 들면 CD-ROM·DVD 등) 및 캐리어 웨이브(예를 들면 인터넷을 통한 전송)와 같은 저장 매체를 포함한 다. 이와 같이 본 발명은 분산된 컨볼루션 연산을 디바이스에서 직접 수행하도록 함으로써 서버의 연산 부하를 줄이 는 효과를 갖는다. 이제까지 본 발명에 대하여 그 바람직한 실시례들을 중심으로 살펴보았다. 본 발명이 속하는 기술 분야에서 통 상의 지식을 가진 자는 본 발명이 본 발명의 본질적인 특성에서 벗어나지 않는 범위에서 변형된 형태로 구현될 수 있음을 이해할 수 있을 것이다. 그러므로 개시된 실시례들은 한정적인 관점이 아니라 설명적인 관점에서 고 려되어야 한다. 본 발명의 범위는 전술한 설명이 아니라 특허청구범위에 나타나 있으며, 그와 동등한 범위 내에 있는 모든 차이점은 본 발명에 포함된 것으로 해석되어야 할 것이다.도면 도면1 도면2 도면3 도면4 도면5 도면6 도면7 도면8 도면9 도면10 도면11 도면12 도면13 도면14 도면15"}
{"patent_id": "10-2020-0187143", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 클라우드 AI와 에지(Edge) AI비교 및 뉴럴넷(신경망) 구성례를 나타낸다. 도 2는 본 발명의 일 실시례에 따른 분산 인공지능 개념도이다. 도 3은 본 발명의 일 실시례에 따른 분산 인공지능 학습 절차에 대한 흐름도이다. 도 4는 본 발명의 일 실시례에 따른 한 장의 이미지에 컨볼루션 처리 방식을 도식화한 도면이다. 도 5는 본 발명의 일 실시례에 따른 컨볼루션 2 분할 병렬 처리 실시례이다. 도 6은 본 발명의 일 실시례에 따른 컨볼루션 2 분할 병렬 시차 처리 실시례이다. 도 7은 본 발명의 일 실시례에 따른 컨볼루션 4 분할 병렬 처리 실시례이다. 도 8은 본 발명의 일 실시례에 따른 (X, Y)해상도 지원 (m x n) Convolution 분리 구성도이다. 도 9는 본 발명의 일 실시례에 따른 CNN Processors Array의 세부 구성도이다. 도 10은 본 발명의 일 실시례에 따른 컨볼루션 요소 세부 구성도이다. 도 11은 본 발명의 일 실시례에 따른 분산 AI 위한 디바이스용 컨볼루션 처리기이다. 도 12는 본 발명의 일 실시례에 따른 Audio/Video 동시 처리 가능한 분산 AI 가속기이다. 도 13은 본 발명의 일 실시례에 따른 RNN Processors의 세부 구성도이다. 도 14에는 도 12의 Audio/Video 동시 처리 가능한 분산 AI 가속기에서 오디오 혹은 음성과 같은 시간에 종속성 갖는 시계열 데이터에 대한 머신러닝을 연산하는 최적화 연산기를 나타낸다. 도 15는 같은 Recurrent Neural Network(RNN)이며, RNN의 기본적인 상태 천이도를 나타낸다."}
