{"patent_id": "10-2020-0111765", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2022-0030050", "출원번호": "10-2020-0111765", "발명의 명칭": "복수의 VNF", "출원인": "삼성전자주식회사", "발명자": "김경래"}}
{"patent_id": "10-2020-0111765", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "서버가 복수의 VNF(Virtualized Network Function)에 대한 컴퓨팅 자원의 할당(allocation)을 조정하는 방법에있어서,상기 서버에 연결된 UE들에 관련된 작업을 처리하기 위해, 상기 서버가 상기 작업에 관련된 복수의 VNF를 식별하는 단계;상기 복수의 VNF를 통하여 상기 작업을 처리함으로써 상기 서버 내에서 발생될 예측 트래픽을 획득하는 단계;적어도 하나의 연관 서버로부터, 상기 연관 서버 내의 컴퓨팅 자원의 상태 정보를 획득하는 단계;상기 연관 서버 내의 상기 컴퓨팅 자원의 상태 정보 및 상기 예측 트래픽에 기초하여, 상기 복수의 VNF에 대한컴퓨팅 자원의 할당을 조정하는 단계;를 포함하고,상기 연관 서버는, 상기 서버에 연결된 UE들에 관련된 상기 작업을 처리하는 다른 서버를 포함하는, 방법."}
{"patent_id": "10-2020-0111765", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 연관 서버는,상기 작업에 관련된 복수의 VNF를 포함하는 다른 서버, 상기 서버와 ToR 스위치(Top of Rack Switch)를 공유하는 다른 서버, 또는 상기 서버가 처리하는 물리적 영역의 일부와 매칭되는 영역의 작업을 처리하는 다른 서버중 적어도 하나를 포함하는, 방법."}
{"patent_id": "10-2020-0111765", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서, 상기 연관 서버 내의 컴퓨팅 자원의 상태 정보는,상기 연관 서버 내의 복수의 VNF에 대한 컴퓨팅 자원의 할당 정보, 상기 연관 서버 내의 컴퓨팅 자원의 점유율정보, 상기 연관 서버 내의 CPU 코어들의 온/오프 여부에 관련된 정보, 또는 상기 연관 서버 내의 CPU 코어들의클럭 속도(clock speed) 정보 중 적어도 하나를 포함하는, 방법."}
{"patent_id": "10-2020-0111765", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,상기 UE들에 관련된 작업을 함께 처리하는 서버들 및 복수의 VNF를 관리하는 VNF 매니저로부터, 복수의 VNF의식별 정보 및 상기 연관 서버의 식별 정보를 수신하는 단계;를 더 포함하는, 방법."}
{"patent_id": "10-2020-0111765", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서,상기 예측 트래픽을 획득하는 단계는, 기 설정된 주기에 따라, 상기 예측 트래픽을 획득하는, 방법."}
{"patent_id": "10-2020-0111765", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서,상기 예측 트래픽을 획득하는 단계는, 제1 인공지능 모델을 이용하여 예측 트래픽을 획득하고,상기 복수의 VNF에 대한 컴퓨팅 자원의 할당을 조정하는 단계는, 제2 인공지능 모델을 이용하여 상기 컴퓨팅 자원의 할당을 조정하는, 방법.공개특허 10-2022-0030050-3-청구항 7 제6항에 있어서, 상기 제1 인공지능 모델은,LSTM(Long Short-Term Memory) 구조의 심층 신경망(Deep Neural Network, DNN)을 포함하고,상기 서버의 버퍼(buffer)에 대기중인 대기 트래픽 및 트래픽 이력 정보를 입력 값으로 하여 상기 예측 트래픽을 예측하도록 훈련된, 방법."}
{"patent_id": "10-2020-0111765", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서,상기 복수의 VNF를 통하여 상기 작업을 처리함으로써 상기 서버 내에서 발생된 실제 트래픽을 획득하는 단계;상기 예측 트래픽 및 상기 실제 트래픽에 기초하여 예측 에러를 획득하는 단계;상기 예측 에러와 기 설정된 임계값의 비교에 기초하여 상기 제1 인공지능 모델의 업데이트 여부를 결정하는 단계; 및상기 결정된 제1 인공지능 모델의 업데이트 여부에 기초하여, 상기 제1 인공지능 모델을 업데이트 하는 단계;를 더 포함하는, 방법."}
{"patent_id": "10-2020-0111765", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제6항에 있어서, 상기 제2 인공지능 모델은,멀티-에이전트 강화 학습(multi-agent deep reinforcement learning) 모델을 포함하고,상기 예측 트래픽, 상기 서버 내의 컴퓨팅 자원의 상태 정보, 및 상기 연관 서버 내의 컴퓨팅 자원의 상태 정보를 입력 값으로 하여 상기 서버 내의 컴퓨팅 자원의 할당을 조정하도록 훈련된, 방법."}
{"patent_id": "10-2020-0111765", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9항에 있어서,상기 서버의 전력 사용량 정보, 상기 서버의 온도 상승 정보, 상기 서버가 처리하는 작업의 처리 지연에 관련된정보, 또는 상기 서버가 처리한 작업의 작업량 중 적어도 하나의 정보를 획득하는 단계;상기 획득된 정보에 기초하여 상기 제2 인공지능 모델의 최적화를 위한 보상값을 획득하는 단계;상기 보상값과 기 설정된 임계값의 비교에 기초하여 상기 제2 인공지능 모델의 업데이트 여부를 결정하는 단계;및상기 결정된 제2 인공지능 모델의 업데이트 여부에 기초하여, 상기 제2 인공지능 모델을 업데이트 하는 단계;를 더 포함하는, 방법."}
{"patent_id": "10-2020-0111765", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "복수의 VNF(Virtualized Network Function)에 대한 컴퓨팅 자원의 할당(allocate)을 조정하는 서버에 있어서,복수의 컴퓨팅 자원;다른 서버들 또는 코어 네트워크와 통신하는 통신부;하나 이상의 명령어들(instructions)을 포함하는 프로그램을 저장하는 저장부; 및상기 저장부에 저장된 하나 이상의 명령어들을 실행하는 적어도 하나의 프로세서를 포함하고,상기 적어도 하나의 프로세서는,상기 서버에 연결된 UE들에 관련된 작업을 처리하기 위해, 상기 작업에 관련된 복수의 VNF를 식별하고,상기 복수의 VNF를 통하여 상기 작업을 처리함으로써 상기 서버 내에서 발생될 예측 트래픽을 획득하고,공개특허 10-2022-0030050-4-적어도 하나의 연관 서버로부터, 상기 연관 서버 내의 컴퓨팅 자원의 상태 정보를 획득하고,상기 연관 서버 내의 상기 컴퓨팅 자원의 상태 정보 및 상기 예측 트래픽에 기초하여, 상기 복수의 VNF에 대한컴퓨팅 자원의 할당을 조정하고,상기 연관 서버는, 상기 서버에 연결된 UE들에 관련된 상기 작업을 처리하는 다른 서버를 포함하는, 서버."}
{"patent_id": "10-2020-0111765", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항에 있어서, 상기 연관 서버는,상기 작업에 관련된 복수의 VNF를 포함하는 다른 서버, 상기 서버와 ToR 스위치(Top of Rack Switch)를 공유하는 다른 서버, 또는 상기 서버가 처리하는 물리적 영역의 일부와 매칭되는 영역의 작업을 처리하는 다른 서버중 적어도 하나를 포함하는, 서버."}
{"patent_id": "10-2020-0111765", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제11항에 있어서, 상기 연관 서버 내의 컴퓨팅 자원의 상태 정보는,상기 연관 서버 내의 복수의 VNF에 대한 컴퓨팅 자원의 할당 정보, 상기 연관 서버 내의 컴퓨팅 자원의 점유율정보, 상기 연관 서버 내의 CPU 코어들의 온/오프 여부에 관련된 정보, 또는 상기 연관 서버 내의 CPU 코어들의클럭 속도(clock speed) 정보 중 적어도 하나를 포함하는, 서버."}
{"patent_id": "10-2020-0111765", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제11항에 있어서,상기 프로세서는 상기 하나 이상의 명령어들을 실행하여,상기 UE들에 관련된 작업을 함께 처리하는 서버들 및 복수의 VNF를 관리하는 VNF 매니저로부터, 복수의 VNF의식별 정보 및 상기 연관 서버의 식별 정보를 수신하는 것을 더 포함하는, 서버."}
{"patent_id": "10-2020-0111765", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제11항에 있어서,상기 프로세서는 상기 하나 이상의 명령어들을 실행하여,제1 인공지능 모델을 이용하여 상기 예측 트래픽을 획득하고,제2 인공지능 모델을 이용하여 상기 복수의 VNF에 대한 컴퓨팅 자원의 할당을 조정하는 것을 더 포함하는,서버."}
{"patent_id": "10-2020-0111765", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제15항에 있어서, 상기 제1 인공지능 모델은,LSTM(Long Short-Term Memory) 구조의 심층 신경망(Deep Neural Network, DNN)을 포함하고,상기 서버의 버퍼(buffer)에 대기중인 대기 트래픽 및 트래픽 이력 정보를 입력 값으로 하여 상기 예측 트래픽을 예측하도록 훈련된, 서버."}
{"patent_id": "10-2020-0111765", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제16항에 있어서,상기 프로세서는 상기 하나 이상의 명령어들을 실행하여,상기 복수의 VNF를 통하여 상기 작업을 처리함으로써 상기 서버 내에서 발생된 실제 트래픽을 획득하고,상기 예측 트래픽 및 상기 실제 트래픽에 기초하여 예측 에러를 획득하고,상기 예측 에러와 기 설정된 임계값의 비교에 기초하여 상기 제1 인공지능 모델의 업데이트 여부를 결정하고,상기 결정된 제1 인공지능 모델의 업데이트 여부에 기초하여, 상기 제1 인공지능 모델을 업데이트 하는 것을 더공개특허 10-2022-0030050-5-포함하는, 서버."}
{"patent_id": "10-2020-0111765", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제15항에 있어서, 상기 제2 인공지능 모델은,멀티-에이전트 강화 학습(multi-agent deep reinforcement learning) 모델을 포함하고,상기 예측 트래픽, 상기 서버 내의 컴퓨팅 자원의 상태 정보, 및 상기 연관 서버 내의 컴퓨팅 자원의 상태 정보를 입력 값으로 하여 상기 서버 내의 컴퓨팅 자원의 할당을 조정하도록 훈련된, 서버."}
{"patent_id": "10-2020-0111765", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제18항에 있어서,상기 프로세서는 상기 하나 이상의 명령어들을 실행하여,상기 서버의 전력 사용량 정보, 상기 서버의 온도 상승 정보, 상기 서버가 처리하는 작업의 처리 지연에 관련된정보, 또는 상기 서버가 처리한 작업의 작업량 중 적어도 하나의 정보를 획득하고,상기 획득된 정보에 기초하여 상기 제2 인공지능 모델의 최적화를 위한 보상값을 획득하고,상기 보상값과 기 설정된 임계값의 비교에 기초하여 상기 제2 인공지능 모델의 업데이트 여부를 결정하고,상기 결정된 제2 인공지능 모델의 업데이트 여부에 기초하여, 상기 제2 인공지능 모델을 업데이트 하는 것을 더포함하는, 서버."}
{"patent_id": "10-2020-0111765", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제1항 내지 제10항 중 어느 한 항의 방법을 구현하기 위한 프로그램이 기록된 기록매체."}
{"patent_id": "10-2020-0111765", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "서버가 복수의 VNF(Virtualized Network Function)에 대한 컴퓨팅 자원의 할당(allocation)을 조정하는 방법 및 그 서버가 제공된다. 방법은, 상기 서버에 연결된 UE들에 관련된 작업을 처리하기 위해, 상기 서버가 상기 작업 에 관련된 복수의 VNF를 식별하는 단계; 상기 복수의 VNF를 통하여 상기 작업을 처리함으로써 상기 서버 내에서 발생될 예측 트래픽을 획득하는 단계; 적어도 하나의 연관 서버로부터, 상기 연관 서버 내의 컴퓨팅 자원의 상태 정보를 획득하는 단계; 상기 연관 서버 내의 상기 컴퓨팅 자원의 상태 정보 및 상기 예측 트래픽에 기초하여, 상 기 복수의 VNF에 대한 컴퓨팅 자원의 할당을 조정하는 단계를 포함할 수 있다. 상기 연관 서버는, 상기 서버에 연결된 UE들에 관련된 상기 작업을 처리하는 다른 서버를 포함할 수 있다."}
{"patent_id": "10-2020-0111765", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은, 연관 서버 내의 컴퓨팅 자원의 상태 정보에 기초하여 서버가 복수의 VNF(Virtualized Network Function)에 대한 컴퓨팅 자원의 할당을 조정하는 방법 및 그 서버에 관한 것이다."}
{"patent_id": "10-2020-0111765", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "클라우드 컴퓨팅(cloud computing) 및 가상화(virtualization)와 같은 아이디어 및 기술이 발전함에 따라, 전통 적인 통신 네트워크 분야에서의 아키텍처 변형이 이루어지고 있다. 밀폐성(closeness)이 개방성으로 대체되고, 배타성(exclusiveness)이 일반성으로 대체되며, 통신 네트워크 요소 상의 네트워크 기능이 추출 및 가상화되어 일반적인 하드웨어 플랫폼에서 실행된다. 네트워크 기능 가상화(Network Function Virtualization, NFV)는 전용 하드웨어 의존성이 큰 기존의 네트워크 에서 벗어나 상용 고성능 서버, 저장 장치 및 스위치를 통해 네트워크를 구성하고, 서비스 제공에 필요한 다양 한 네트워크 기능들을 가상화하여 유연하게 관리하는 기술이다. NFV에서는 다양한 네트워크 소프트웨어 기능을 수행하기 위해 상용 하드웨어를 사용한다. 이에 따라, 데이터센 터, 광역 네트워크 등의 위치에서 소프트웨어의 유연한 구성을 구현할 수 있다. 또한, 서비스 배포(service deployment)의 복잡성이나 전체 투자 비용을 감소시킬 수 있고, 네트워크 장치의 일반화 및 적응력을 향상시킬 수도 있다. 통신 네트워크의 경우, 게이트웨이 GPRS 지원 노드(Gateway General Packet Radio Service Support Node, GGSN), 이동성 관리 엔티티(Mobility Management Entity, MME) 등의 일부 표준 네트워크 요소들의 기능 은 가상화되고, 데이터센터의 일반적인 하드웨어 장치에 장착될 수 있다. 이러한 NFV에서는, 네트워크 서비스를 구현하기 위한 하나 이상의 VNF(Virtualized Network Function)가 정의 될 수 있다. 각각의 네트워크 서비스를 구현할 때 필요한 VNF에 대해, 물리적/가상적 네트워크 자원이 자동으로 할당될 수 있다. 예를 들어, NFV(특히 MANO(Management and Orchestration)의 Orchestrator)에서는 네트워크 서비스의 요구사항, 컴퓨팅 자원의 최대 성능 및 용량, 네트워크 사업자의 컴퓨팅 자원 관리 정책, 또는 네트워 크 서비스 및 컴퓨팅 자원의 실시간 상황 변동 등의 다양한 요인에 따라 자동으로 컴퓨팅 자원의 할당이 관리될수 있다. 한편, NFV에서 특정 VNF에 대해 할당된 컴퓨팅 리소스가 부족하거나 지나치게 많은 경우, 컴퓨팅 리소스의 할당 에 조정이 필요하다. 그러나, 종래에는 VNF 별로 요구되는 컴퓨팅 리소스의 양을 고려하지 못한 채, 일률적으로 컴퓨팅 리소스를 할당하였다. 일률적으로 컴퓨팅 리소스를 할당할 경우, 컴퓨팅 리소스가 낭비되거나, 변화하는 트래픽에 빠르게 대응할 수 없는 문제가 있다. 네트워크의 서비스는 더욱 다양해지고 있으며, 더 짧은 지연 시간과 높은 신뢰성을 갖는 데이터 처리가 요구된 다. 이에 따라, 서버 내에서 복수의 VNF에 대한 컴퓨팅 자원의 할당을 효과적으로 조정할 수 있는 기술이 요구 된다."}
{"patent_id": "10-2020-0111765", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 개시의 일 실시예는, 서버가 서버 내에서 발생될 트래픽을 예측하고, 예측된 트래픽 및 획득한 연관 서버 내 의 컴퓨팅 자원의 상태 정보에 기초하여 복수의 VNF(Virtualized Network Function)에 대한 컴퓨팅 자원의 할당 을 조정함으로써, 예측되지 않은 트래픽 패턴에 실시간으로 빠르게 대응할 수 있고, 컴퓨팅 자원의 효율적인 활 용이 가능한, 방법 및 서버를 제공할 수 있다. 또한, 본 개시의 일 실시예는, 하나 이상의 인공지능 모델을 이용하여 서버 내에서 발생될 트래픽을 예측하고 컴퓨팅 자원의 할당을 조정함으로써, 예측 정확도를 높이고, 컴퓨팅 자원의 할당을 최적화할 수 있는 방법 및 서버를 제공할 수 있다."}
{"patent_id": "10-2020-0111765", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상술한 기술적 과제를 달성하기 위한 기술적 수단으로서 개시된, 서버가 복수의 VNF(Virtualized Network Function)에 대한 컴퓨팅 자원의 할당(allocation)을 조정하는 방법은, 상기 서버에 연결된 UE들에 관련된 작업 을 처리하기 위해, 상기 서버가 상기 작업에 관련된 복수의 VNF를 식별하는 단계; 상기 복수의 VNF를 통하여 상 기 작업을 처리함으로써 상기 서버 내에서 발생될 예측 트래픽을 획득하는 단계; 적어도 하나의 연관 서버로부 터, 상기 연관 서버 내의 컴퓨팅 자원의 상태 정보를 획득하는 단계; 상기 연관 서버 내의 상기 컴퓨팅 자원의 상태 정보 및 상기 예측 트래픽에 기초하여, 상기 복수의 VNF에 대한 컴퓨팅 자원의 할당을 조정하는 단계를 포 함할 수 있다. 상기 연관 서버는, 상기 서버에 연결된 UE들에 관련된 상기 작업을 처리하는 다른 서버를 포함할 수 있다. 상술한 기술적 과제를 달성하기 위한 기술적 수단으로서 개시된, 복수의 VNF(Virtualized Network Function)에 대한 컴퓨팅 자원의 할당(allocate)을 조정하는 서버는, 복수의 컴퓨팅 자원; 다른 서버들 또는 코어 네트워크 와 통신하는 통신부; 하나 이상의 명령어들(instructions)을 포함하는 프로그램을 저장하는 저장부; 및 상기 저 장부에 저장된 하나 이상의 명령어들을 실행하는 적어도 하나의 프로세서를 포함할 수 있다. 상기 적어도 하나 의 프로세서는, 상기 서버에 연결된 UE들에 관련된 작업을 처리하기 위해, 상기 작업에 관련된 복수의 VNF를 식 별하고, 상기 복수의 VNF를 통하여 상기 작업을 처리함으로써 상기 서버 내에서 발생될 예측 트래픽을 획득하고, 적어도 하나의 연관 서버로부터, 상기 연관 서버 내의 컴퓨팅 자원의 상태 정보를 획득하고, 상기 연 관 서버 내의 상기 컴퓨팅 자원의 상태 정보 및 상기 예측 트래픽에 기초하여, 상기 복수의 VNF에 대한 컴퓨팅 자원의 할당을 조정할 수 있다. 상기 연관 서버는, 상기 서버에 연결된 UE들에 관련된 상기 작업을 처리하는 다 른 서버를 포함할 수 있다. 상술한 기술적 과제를 달성하기 위한 기술적 수단으로서 개시된, 기록매체는, 개시된 방법의 실시예들 중에서 적어도 하나를 실행시키기 위한 프로그램이 저장된 것일 수 있다."}
{"patent_id": "10-2020-0111765", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "아래에서는 첨부한 도면을 참조하여 본 개시가 속하는 기술 분야에서 통상의 지식을 가진 자가 용이하게 실시할 수 있도록 본 개시의 실시예를 상세히 설명한다. 그러나 본 개시는 여러 가지 상이한 형태로 구현될 수 있으며 여기에서 설명하는 실시예에 한정되지 않는다. 그리고 도면에서 본 개시를 명확하게 설명하기 위해서 설명과 관 계없는 부분은 생략하였으며, 명세서 전체를 통하여 유사한 부분에 대해서는 유사한 도면 부호를 붙였다. 본 개시의 실시예들에서 사용되는 용어는 본 개시의 기능을 고려하면서 가능한 현재 널리 사용되는 일반적인 용 어들을 선택하였으나, 이는 당 분야에 종사하는 기술자의 의도 또는 판례, 새로운 기술의 출현 등에 따라 달라 질 수 있다. 또한, 특정한 경우는 출원인이 임의로 선정한 용어도 있으며, 이 경우 해당되는 실시예의 설명 부 분에서 상세히 그 의미를 기재할 것이다. 따라서 본 명세서에서 사용되는 용어는 단순한 용어의 명칭이 아닌, 그 용어가 가지는 의미와 본 개시의 전반에 걸친 내용을 토대로 정의되어야 한다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함할 수 있다. 기술적이거나 과학적인 용어를 포함해서 여기서 사용되는 용어들은 본 명세서에 기재된 기술 분야에서 통상의 지식을 가진 자에 의해 일반적으로 이해되는 것과 동일한 의미를 가질 수 있다. 본 개시 전체에서 어떤 부분이 어떤 구성요소를 “포함”한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다른 구성요소를 제외하는 것이 아니라 다른 구성요소를 더 포함할 수 있음을 의미한다. 또한, 본 명세서에 기 재된 “...부”, “...모듈” 등의 용어는 적어도 하나의 기능이나 동작을 처리하는 단위를 의미하며, 이는 하 드웨어 또는 소프트웨어로 구현되거나 하드웨어와 소프트웨어의 결합으로 구현될 수 있다. 명세서 전체에서, 어떤 부분이 다른 부분과 \"연결\"되어 있다고 할 때, 이는 \"직접적으로 연결\"되어 있는 경우뿐 아니라, 그 중간에 다른 소자를 사이에 두고 \"전기적으로 연결\"되어 있는 경우도 포함한다. 또한 어떤 부분이 어떤 구성요소를 \"포함\"한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다른 구성요소를 제외하는 것이 아 니라 다른 구성요소를 더 포함할 수 있는 것을 의미한다. 본 명세서에서 사용된 표현 “~하도록 구성된(또는 설정된)(configured to)”은 상황에 따라, 예를 들면, “~에 적합한(suitable for)”, “~하는 능력을 가지는(having the capacity to)”, “~하도록 설계된(designed to) ”, “~하도록 변경된(adapted to)”, “~하도록 만들어진(made to)”, 또는 “~를 할 수 있는(capable of)” 과 바꾸어 사용될 수 있다. 용어 “~하도록 구성된(또는 설정된)”은 하드웨어적으로 “특별히 설계된 (specifically designed to)” 것만을 반드시 의미하지 않을 수 있다. 대신, 어떤 상황에서는, “~하도록 구성 된 시스템”이라는 표현은, 그 시스템이 다른 장치 또는 부품들과 함께 “~할 수 있는” 것을 의미할 수 있다. 예를 들면, 문구 “A, B, 및 C를 수행하도록 구성된(또는 설정된) 프로세서”는 해당 동작을 수행하기 위한 전 용 프로세서(예: 임베디드 프로세서), 또는 메모리에 저장된 하나 이상의 소프트웨어 프로그램들을 실행함으로 써, 해당 동작들을 수행할 수 있는 범용 프로세서(generic-purpose processor)(예: CPU 또는 application processor)를 의미할 수 있다. 본 개시에 따른 인공지능과 관련된 기능은 프로세서와 메모리를 통해 동작된다. 프로세서는 하나 또는 복수의 프로세서로 구성될 수 있다. 이때, 하나 또는 복수의 프로세서는 CPU, AP, DSP(Digital Signal Processor) 등 과 같은 범용 프로세서, GPU, VPU(Vision Processing Unit)와 같은 그래픽 전용 프로세서 또는 NPU와 같은 인공지능 전용 프로세서일 수 있다. 하나 또는 복수의 프로세서는, 메모리에 저장된 기 정의된 동작 규칙 또는 인 공지능 모델에 따라, 입력 데이터를 처리하도록 제어한다. 또는, 하나 또는 복수의 프로세서가 인공지능 전용 프로세서인 경우, 인공지능 전용 프로세서는, 특정 인공지능 모델의 처리에 특화된 하드웨어 구조로 설계될 수 있다. 기 정의된 동작 규칙 또는 인공지능 모델은 학습을 통해 만들어진 것을 특징으로 한다. 여기서, 학습을 통해 만 들어진다는 것은, 기본 인공지능 모델이 학습 알고리즘에 의하여 다수의 학습 데이터들을 이용하여 학습됨으로 써, 원하는 특성(또는, 목적)을 수행하도록 설정된 기 정의된 동작 규칙 또는 인공지능 모델이 만들어짐을 의미 한다. 이러한 학습은 본 개시에 따른 인공지능이 수행되는 기기 자체에서 이루어질 수도 있고, 별도의 서버 및/ 또는 시스템을 통해 이루어 질 수도 있다. 학습 알고리즘의 예로는, 지도형 학습(supervised learning), 비지도 형 학습(unsupervised learning), 준지도형 학습(semi-supervised learning) 또는 강화 학습(reinforcement learning)이 있으나, 전술한 예에 한정되지 않는다. 인공지능 모델은, 복수의 신경망 레이어들로 구성될 수 있다. 복수의 신경망 레이어들 각각은 복수의 가중치들 (weight values)을 갖고 있으며, 이전(previous) 레이어의 연산 결과와 복수의 가중치들 간의 연산을 통해 신경 망 연산을 수행한다. 복수의 신경망 레이어들이 갖고 있는 복수의 가중치들은 인공지능 모델의 학습 결과에 의 해 최적화될 수 있다. 예를 들어, 학습 과정 동안 인공지능 모델에서 획득한 로스(loss) 값 또는 코스트(cost) 값이 감소 또는 최소화되도록 복수의 가중치들이 갱신될 수 있다. 인공 신경망은 심층 신경망(DNN:Deep Neural Network)를 포함할 수 있으며, 예를 들어, CNN (Convolutional Neural Network), DNN (Deep Neural Network), RNN (Recurrent Neural Network), RBM (Restricted Boltzmann Machine), DBN (Deep Belief Network), BRDNN(Bidirectional Recurrent Deep Neural Network) 또는 심층 Q-네트워크 (Deep Q-Networks) 등이 있으나, 전술한 예에 한정되지 않는다. 본 개시에서 ‘서버(server)’는 사용자 단말(User Equipment, UE) 또는 클라이언트에게 네트워크를 통해 정보 나 서비스를 제공하는 컴퓨터 시스템으로서, 서버 프로그램(server program) 또는 장치(device)를 의미한다. 서 버는 파일 관리 등 네트워크 전체를 감시 또는 제어하거나, 메인 프레임이나 공중망을 통해 다른 네트워크와 연 결할 수 있도록 한다. 서버는 데이터, 프로그램, 파일 등과 같은 소프트웨어 자원이나 모뎀, 팩스, 공유기 등과 같은 하드웨어 자원을 공유할 수 있도록 한다. 서버는 사용자(클라이언트)의 요청에 따라 서비스를 제공할 수 있다. 서버에서는 하나 이상의 응용 프로그램들이 상호 협력적인 환경에서 분산 처리 형태로 운용될 수 있다. 본 개시에서 ‘NFV(Network Function Virtualization)’는 네트워크 기능을 가상화하는 기술을 의미한다. NFV 에서는, 통신 서비스를 만들기 위해 IT 가상화 기술이 사용되고, 모든 계열의 네트워크 노드 기능들이 함께 묶 이거나 연결이 가능한 빌딩 블록으로 가상화될 수 있다. NFV 기술은 하드웨어 중심의 네트워크 인프라에서 범용 클라우드 인프라 환경으로, 소프트웨어 중심의 네트워크 인프라를 실현하기 위한 기술이다. 예를 들어, NFV을 통하여, 서버 내의 라우터, 방화벽 및 부하 분산 장치와 같은 고가의 전용 하드웨어 장치가 가상 머신(VM)으로 실행되는 소프트웨어 기반 네트워크 어플라이언스로 대체될 수 있다. NFV를 통해, 전용 하드웨어 장치에서 네트 워크 기능(Network Function, NF)이 분리되어 가상 머신으로 이동됨으로써, 여러 네트워크 기능들이 가상 머신 들을 포함하는 단일한 물리적 서버에 통합될 수 있다. 시스템을 운용하고 유지 보수하는 측면에 있어서 하드웨 어적인 고장/수리/교체의 문제 및 소프트웨어적인 업데이트(예를 들어, 기능 추가, 디버깅 등의 목적의 업데이 트)의 문제 등과 시간에 따른 장비의 노후화 문제 등은 필연적으로 발생할 수 있다. 폐쇄적으로 운용되던 물리 적 시스템을 가상화를 통한 논리적 시스템으로 대체함으로써, 인프라 측면에서는 유지 보수 비용의 최소화 및 장비 이용 효율의 극대화가 가능하고, 시스템의 운영 도중 새로운 장비의 추가가 용이해지며, 시스템의 운용관 리 측면에서 원격 모니터링과 통합 관리를 통해 사용자 편이성을 높여줄 수 있다. 즉, NFV에서는 고가의 네트워 크 하드웨어들을 간단한 소프트웨어 어플라이언스들로 대체할 수 있다. 한편, NFV에서의 네트워크 서비스는 일 련의 가상 네트워크 기능(Virtualized Network Function, VNF)의 집합인 서비스 체인(service chain)을 통해 제공될 수 있다. 본 개시에서 ‘VNF(Virtualized Network Function)’는 소프트웨어로서 실행되는 네트워크 기능(NF) 또는 네트 워크 기능(NF)의 일부를 의미한다. VNF는 가상 머신(VM)을 통해 구현될 수도 있다. VNF는 네트워크 기능(NF)을 위한 커스텀 하드웨어 어플라이언스 대신 표준의 고용량 서버, 스위치, 스토리지 장치, 또는 클라우드 컴퓨팅 인프라스트럭처 위에서 각기 다른 소프트웨어와 프로세스를 구동하는 적어도 하나의 가상 머신(VM)으로 구성될 수 있다. 예를 들어, VNF에는 라우팅, 방화벽, 로드밸런싱, WAN 가속, 암호화 등을 위한 VM이 포함될 수 있다. 본 개시에서 ‘데이터센터(data center)’는 서버와 네트워크 회선 등을 제공하는 네트워크 시스템을 의미한다. 데이터센터는 ‘서버 호텔(server hotel)’로 지칭될 수도 있다. 데이터센터에는 복수의 서버들이 포함될 수 있 다. 통신업체의 데이터센터는 인터넷 데이터센서(IDC), 클라우드 데이터 센서(cloud data center)로 지칭될 수 도 있다. 본 개시에서 ‘작업(work)’은 서버에 연결된 UE들에 제공하는 서비스를 의미하고, ‘작업의 처리’는 서비스를 제공하기 위한 동작의 수행을 의미할 수 있다. 본 개시에서 서버 내에서 발생되는 ‘트래픽(traffic)’은 서버에 연결된 UE들로부터의 서비스 제공 요청에 따 라, 서버가 처리해야할 작업의 작업량(workload)을 나타낼 수 있다. 본 개시에서 ‘예측 트래픽(predicted traffic)’은 서버 내에서 특정 시점에 발생될 트래픽을 의미한다. 예를 들어, 연결된 UE들로부터 특정 시점에 서비스 제공 요청 얼마나 들어올지, 서버가 처리해야할 작업의 작업량이 어느 정도일지에 관련될 수 있다. 본 개시에서 ‘실제 트래픽(real traffic)’은 서버 내에서 특정 시점에 실제로 발생된 트래픽을 의미한다. 예 를 들어, 특정 시점에 실제로 연결된 UE들로부터 서비스 제공 요청 얼마나 들어왔는지, 서버가 처리해야하는 작 업의 작업량이 어느 정도일지에 관련될 수 있다. 본 개시에서 ‘대기 트래픽(waiting traffic)’은 서버의 버퍼(buffer)에 대기중인 트래픽을 의미한다. 예를 들 어, 버퍼에서 처리를 기다리는 작업들의 작업 량을 의미할 수 있다. ‘버퍼(buffer)’는 컴퓨팅 동작에서, 데이 터를 한 곳에서 다른 한 곳으로 전송하는 동안 일시적으로 그 데이터를 보관하는 메모리의 영역을 의미한다. 버 퍼는 ‘큐(queue)’ 또는 ‘대기열’로 지칭될 수도 있다. 본 개시에서 ‘컴퓨팅 자원(computing resource)’은 컴퓨팅을 위한 자원으로서 CPU를 의미할 수 있다. 예를 들 어, 컴퓨팅 자원을 정의하는데 사용되는 단위로 밀리세컨드(ms)가 사용될 수 있고, 약 1000ms의 컴퓨팅 자원이 1 vCore (단위 가상 CPU 코어)를 구성할 수 있다. 이하 첨부된 도면을 참고하여 본 개시를 상세히 설명하기로 한다. 도 1은 본 개시의 일 실시예에 따른 서버가 포함된 NFV(Network Function Virtualization)에서의 네트워크 구 조를 도시한다. 도 1을 참조하면, 이동 통신을 구성하는 네트워크(NW)는 코어 네트워크(CN)와 액세스 네트워크(AN)를 포함할 수 있다. 코어 네트워크(CN)는 가입자 정보를 관리하는 기능, 유선 전화망 서비스와 연결하는 기능, 및 다른 부가 서비스의 제공을 위한 기능을 수행할 수 있다. 코어 네트워크(CN)는 네트워크(NW)를 총괄하여 관리하는 부분과 각각의 지역별 액세스 네트워크(AN)와 연결되는 부분으로 나눌 수 있다. 액세스 네트워크(AN)는 가입자 또는 사 용자 단말(UE)과 직접 연결되는 망으로서, 사용자 단말(UE)에 네트워크 서비스를 연결하거나, 사용자 단말(UE) 과 정보를 송수신할 수 있다. 액세스 네트워크(AN)의 주요한 거점은 기지국이다. 또한, 액세스 네트워크(AN)는 코어 네트워크(CN)와 연결될 수 있다. 일 실시예에서, 사용자 단말(UE)은 기지국을 통해 액세스 네트워크(AN)로 서비스를 요청할 수 있다. 수신된 서 비스 요청에 관련된 정보는 액세스 네트워크(AN)에서 코어 네트워크(CN)로 전달될 수 있다. 코어 네트워크(CN) 는 수신된 서비스 요청과 관련된 작업을 처리하기 위해, 연결된 데이터센터에 작업을 처리하도록 요청할 수 있다. 일 실시예에서, 데이터센터에 포함된 서버 내에서 발생되는 트래픽을 나타낼 때, 기지국과 사용자 단 말(UE) 간에 발생하는 접속량이 고려될 수 있다. 예를 들어, 기지국과 사용자 단말(UE) 간에 발생하는 접속량은 서버 외에서 발생되는 트래픽으로 지칭될 수 있고, 이는 UE들로부터의 서비스 제공 요청 정도를 나타낼 수 있다. UE들에 관련된 작업에는 적어도 하나의 네트워크 기능(NF)이 연관되고, 도 1을 참조하면, UE에 관련된 작업의 정보는 UE로부터 액세스 네트워크(AN) 및 코어 네트워크(CN)를 거쳐 데이터센터에 전달될 수 있다. 데이터 센터에 전달된 UE에 관련된 작업은 데이터센터 내의 적어도 하나의 서버(101, 102, 103)에서 처리될 수 있다. 일 실시예에서, 데이터센터는 VNF 매니저(VNFM)를 더 포함할 수 있다. VNF 매니저(VNFM)는, UE들에 관련된 작업에 관련된 네트워크 기능으로부터, UE들에 관련된 작업들을 위한 하나 이상의 VNF를 정의할 수 있다. 이후, VNF 매니저(VNFM)는 정의된 각각의 VNF를 복수의 서버들(101, 102, 103)에 할당할 수 있다. 일 실시예에서, 특정 VNF는 복수의 서버들에게 할당될 수 있다. 특정 서버는 복수의 VNF를 할 당 받을 수도 있다. 예를 들어, 각각의 서버에 할당된 VNF들의 적어도 일부는 서로 다를 수 있다.서버(101, 102, 103)는, 컴퓨터 시스템으로서, 사용자 단말(UE)들에 관련된 작업을 직접 처리할 수 있다. 즉, 서버(101, 102, 103)들은 각각 VNF 매니저(VNFM)로부터 할당 받은 VNF를 통하여, UE로부터 요청된 작업을 처리 할 수 있다. 서버(101, 102, 103)들은 할당 받은 VNF에 대해, 연산에 필요한 컴퓨팅 자원(CPU)을 할당하고, 조 정할 수 있다. 예를 들어, 서버(101, 102, 103)들은 각각 할당 받은 VNF 간에 해당 서버가 보유하고 있는 컴퓨 팅 자원(CPU)을 어떻게 배분할지, 및 각각의 컴퓨팅 자원(CPU)의 클럭 속도(clock speed)를 어떻게 설정할지 조 정할 수 있다. 이하, 각각의 서버가 할당 받은 복수의 VNF에 대하여, 보유하고 있는 컴퓨팅 자원(CPU)의 할당을 조정하는 방법 을 보다 구체적으로 설명하기로 한다. 도 2는 본 개시의 일 실시예에 따른 서버가 복수의 VNF에 대한 컴퓨팅 자원의 할당을 조정하는 방법의 개요도이다. 도 2를 참조하면, 서버는 복수의 컴퓨팅 자원, 프로세서, 및 저장부를 포함할 수 있다. 일 실시예에서, 저장부는 복수의 VNF을 포함할 수 있다. 일 실시예에서, 프로세서는 복수의 VNF에 대해 컴퓨팅 자원을 할당하고, 할당을 조정할 수 있다. 본 개시에 따른 서버가 복수의 VNF에 대한 컴퓨팅 자원의 할당을 조정하는 방법에 있어서, 서버 내에서 발생될 예측 트래픽을 추론 또는 예측하기 위한 방법으로 서버의 버퍼에 대기중인 대기 트래픽 및 트래픽 이력 정보를 이용하는 인공지능 모델을 이용할 수 있다. 또한, 복수의 VNF에 대한 컴퓨팅 자원의 할당을 조정하기 위한 방법으로, 예측 트래픽, 서버 자체 내의 컴퓨팅 자원(21 0)의 상태 정보, 및 연관 서버(200R) 내의 컴퓨팅 자원(210R)의 상태 정보를 이용하는 인공지능 모델 을 이용할 수 있다. 프로세서는 각각의 데이터들에 대해 전처리 과정을 수행하여 인공지능 모델의 입력으 로 사용하는 데에 적합한 형태로 변환할 수 있다. 인공지능 모델은 학습을 통해 만들어 질 수 있다. 여기서, 학 습을 통해 만들어진다는 것은, 기본 인공지능 모델이 학습 알고리즘에 의하여 다수의 학습 데이터들을 이용하여 학습됨으로써, 원하는 특성(또는, 목적)을 수행하도록 설정된 기 정의된 동작 규칙 또는 인공지능 모델이 만들 어짐을 의미한다. 인공지능 모델은, 복수의 신경망 레이어들로 구성될 수 있다. 복수의 신경망 레이어들 각각은 복수의 가중치들(weight values)을 갖고 있으며, 이전(previous) 레이어의 연산 결과와 복수의 가중치들 간의 연산을 통해 신경망 연산을 수행한다. 추론 예측은 정보를 판단하여 논리적으로 추론하고 예측하는 기술로서, 지식/확률 기반 추론(Knowledge based Reasoning), 최적화 예측(Optimization Prediction), 선호 기반 계획(Preference-based Planning), 추천 (Recommendation) 등을 포함한다. 프로세서는, 복수의 VNF를 통하여 작업을 처리함으로써 서버 내에서 발생될 예측 트래픽을 획득할 수 있다. 예측 트래픽을 획득하는 동작에는 제1 인공지능 모델(M1)이 이용될 수 있다. 일 실시예에서, 제1 인공지능 모델(M1)은, 서버 내에서 발생될 예측 트래픽을 예측하기 위한 인공지 능 모델로서, 심층 신경망(Deep Neural Network, DNN)을 포함할 수 있다. 심층 신경망은 인공 신경망의 한 종류 로서, 입력층과 출력층 사이에 여러 개의 은닉층(hidden layer)이 포함되는 특징을 가질 수 있다. DNN은 일반적 인 인공 신경망과 마찬가지로 복잡한 비선형 관계들을 모델링할 수 있다. 예를 들어, 사물 식별 모델을 위한 심 층 신경망 구조에서는 각 객체가 이미지 기본 요소들의 계층적 구성으로 표현될 수 있다. 이때, 추가 계층들은 점진적으로 모인 하위 계층들의 특징을 규합 시킬 수 있다. DNN의 이러한 특징은, 더 적은 수의 유닛들만으로도 복잡한 데이터를 모델링할 수 있게 한다. DNN은 본 개시에서와 같이 미래의 예측 값을 획득하는데 이용될 수 있 다. 제1 인공지능 모델(M1)은, 예를 들어, LSTM(Long Short-Term Memory) 구조의 심층 신경망(Deep Neural Network, DNN)을 포함할 수 있다. 일 실시예에서, 제1 인공지능 모델(M1)은, 서버의 버퍼에 대기중인 대기 트래픽 및 트래픽 이력 정보(23 2)를 입력 값으로 하여 예측 트래픽을 예측하도록 훈련될 수 있다. 일 실시예에서, 대기 트래픽은 서 버의 버퍼에서 처리를 기다리는 작업들의 양(amount)을 나타낼 수 있다. 트래픽 이력 정보는 주간, 일간, 또는 시간 단위에 따른 과거의 트래픽 통계치를 포함할 수 있다. 예를 들어, 일요일 낮 12시경에 예측 트래픽을 예측하는 동작은, 트래픽 이력으로부터 통상적으로 ‘일요 일 낮 12시경’에 서버 내에 어느 정도의 트래픽이 발생하는지 정보를 추출하고, 추출된 트래픽 이력 정보 및 현재 버퍼에서 처리를 기다리는 작업들의 양에 기초하여, 예측 트래픽을 예측할 수 있다. 이 경우, 예 를 들어, 대기 트래픽이 추출된 트래픽 이력 정보를 참조하여 볼 때 통상적으로 발생하는 트래픽의양에 비해 적다고 판단되는 경우, 앞으로 들어올 트래픽이 많아질 것으로 예측할 수 있다. 또 다른 예를 들어, 트래픽 이력으로부터 트래픽이 변화하는 패턴을 학습하고, 트래픽 이력으로부터 이전 시점 의 트래픽 이력 정보를 추출하고, 추출된 트래픽 이력 정보 및 현재 대기 트래픽으로부터 학습 된 패턴에 따라 이후 시점에 트래픽이 어떻게 변화할지 예측할 수도 있다. 프로세서는, 적어도 하나의 연관 서버(200R)로부터, 연관 서버(200R) 내의 컴퓨팅 자원의 상태 정보 를 획득할 수 있다. 연관 서버(200R)는, 서버에 연결된 UE들에 관련된 작업을 처리하는 다른 서버를 포함할 수 있다. 예를 들 어, 연관 서버(200R)는, 작업에 관련된 복수의 VNF를 포함하는 서버, 서버와 ToR 스위치(Top of Rack Switch)를 공유하는 서버, 또는 상기 서버가 처리하는 물리적 영역의 일부와 매칭되는 영역의 작업을 처리하는 서버 중 적어도 하나를 포함할 수 있다. 일 실시예에서, 도 2를 참조하면, 연관 서버(200R)는 작업에 관련된 복수의 VNF(251R)를 포함하는, 서버와 다른 서버를 포함할 수 있다. 일 실시예에서, UE들이 요청한 서비스에 관련된 작업은 복수의 서버들(200, 200 R)에서 처리될 수 있다. 이 때, 서버에 할당된 복수의 VNF 중 일부와 매칭되는 VNF(251R)를 포함하는 다른 서버는 연관 서버(200R)가 될 수 있다. 일 실시예에서, 연관 서버(200R)는 서버와 ToR 스위치(Top of Rack Switch)를 공유하는 다른 서버, 또는 상기 서버가 처리하는 물리적 영역의 일부와 매칭되는 영역의 작업을 처리하는 다른 서버 중 적어도 하나를 포 함할 수도 있다. 일 실시예에서, 데이터센터는 여러 개의 랙(rack)을 포함하고, 각각의 랙은 여러 대의 서버 및 서버들을 연결하는 스위치(switch)를 포함할 수 있다. 즉, 데이터센터 등의 하드웨어에서, 특정 서버와 동일한 랙(rack)에 배치되고, ToR 스위치를 공유하는 다른 서버는 ‘연관 서버’가 될 수 있다. 또한, 특정 서버가 처 리하는 작업에 대응되는 물리적인 액세스 네트워크(AN) 영역과 매칭되는 영역에 관련된 작업을 처리하는 다른 서버도 ‘연관 서버’가 될 수 있다. 연관 서버의 종류는 기술한 실시예에 한정되지 않으며, 특정 서버에서의 컴퓨팅 자원의 할당을 조정하는데 도움이 될 수 있는 정보를 갖는 어떠한 서버도 포함될 수 있다. 연관 서버 내의 컴퓨팅 자원의 상태 정보는, 예를 들어, 연관 서버(200R) 내의 복수의 VNF(251R)에 대한 컴퓨팅 자원(210R)의 할당 정보, 연관 서버(200R) 내의 컴퓨팅 자원(210R)의 점유율 정보, 연관 서버(200R) 내 의 CPU 코어들의 온/오프 여부에 관련된 정보, 또는 연관 서버(200R) 내의 CPU 코어들의 클럭 속도(clock speed) 정보 중 적어도 하나를 포함할 수 있다. 일 실시예에서, 연관 서버 내의 컴퓨팅 자원의 상태 정보 는 서버가 자신의 컴퓨팅 자원의 할당을 조정하는 동작에 이용될 수 있다. 프로세서는, 연관 서버 내의 컴퓨팅 자원의 상태 정보 및 예측 트래픽에 기초하여, 복수의 VNF에 대한 컴퓨팅 자원의 할당을 조정할 수 있다. 복수의 VNF에 대한 컴퓨팅 자원의 할당을 조정하는 동작에는 제2 인공지능 모델(M2)이 이용될 수 있다. 일 실시예에서, 제2 인공지능 모델(M2)은, 복수의 VNF에 대한 컴퓨팅 자원의 할당을 조정하기 위한 인공지능 모델일 수 있다. 예를 들어, 제2 인공 지능 모델은, 멀티-에이전트 강화 학습(multi-agent deep reinforcement learning) 모델을 포함할 수 있다. 강화 학습은 기계 학습의 한 영역으로서, 어떤 환경 안에서 정의된 에이전트가 현재의 상태를 인식하여, 선택 가능한 행동들 중 보상을 최대화하는 행동 혹은 행동 순서를 선택하는 방법이다. 강화 학습을 통해 구축된 모델은 다중 에이전트 시스템 또는 최적화 제어 이론에서 이용될 수 있다. 따라서, 멀티-에이전트 강화 학습 모델은 본 개시에서와 같이 다중 입력을 가지면서 컴퓨팅 자원 할당 의 조정을 최적화하는데 효과적으로 이용될 수 있다. 일 실시예에서, 제2 인공지능 모델(M2)은, 예측 트래픽 및 연관 서버(200R) 내의 컴퓨팅 자원(210R)의 상 태 정보를 입력 값으로 하여, 서버 내의 컴퓨팅 자원의 할당을 조정하도록 훈련될 수 있다. 일 실시예에서, 제2 인공지능 모델(M2)은, 서버 자체 내의 컴퓨팅 자원의 상태 정보를 입 력 값으로 더 포함할 수도 있다. 일 실시예에서, 컴퓨팅 자원의 상태 정보는 예를 들어, 서버 내의 복수의 VNF에 대한 컴퓨팅 자원의 할당 정보, 서버 내의 컴퓨팅 자원의 점유율 정보, 서버 내의 CPU 코어들의 온/오프 여부에 관련된 정보, 또는 서버 내의 CPU 코어들의 클럭 속도(clock speed) 정보 중 적어도 하나를 포함할 수 있다. 예를 들어, 제2 인공지능 모델(M2)을 통한 복수의 VNF에 대한 컴퓨팅 자원의 할당을 조정하는 동작은 다음과 같을 수 있다. 먼저, 서버는 현재 복수의 VNF에 대한 컴퓨팅 자원의 할당 정보, 현재 할 당된 CPU 코어들의 클럭 속도 등을 포함하는 서버 자체 내의 컴퓨팅 자원의 상태 정보를 획득할수 있다. 또한, 서버는 제1 인공지능 모델(M1)을 통해 예측된 예측 트래픽을 획득할 수 있고, 연관 서버(200R)로부터 연관 서버(200R)의 컴퓨팅 자원 상태 정보를 획득할 수 있다. 서버는 획득된 정보 들을 통해, 복수의 VNF에 대한 컴퓨팅 자원의 할당을 조정할 수 있다. 예를 들어, 예측 트래픽 이 현재 트래픽에 비해 큰 경우, VNF에 대해 컴퓨팅 자원을 추가로 할당하거나, 기 할당된 CPU 코어 의 클럭 속도를 올리는 방식으로 컴퓨팅 자원의 할당을 조정할 수 있다. 또 다른 예를 들어, 연관 서버(200R)가 서버에 포함된 복수의 VNF 중 일부와 매칭되는 VNF(251R)를 포함하고, 연관 서버(200R)의 컴퓨팅 자원(210R) 점유율이 좋지 않은 경우, 서버는 연관 서버(200R)의 작 업 처리량이 적을 것을 예측하고, 서버 내에서 VNF에 대해 컴퓨팅 자원을 추가로 할당하거나, 기 할당된 CPU 코어의 클럭 속도를 올리는 방식으로 컴퓨팅 자원의 할당을 조정할 수도 있다. 도 3은 본 개시의 일 실시예에 따른 서버의 블록도이다. 도 3을 참조하면, 서버는 복수의 컴퓨팅 자원, 프로세서, 저장부, 인공지능 모델, 및 통신부를 포함할 수 있다. 도 3에 도시된 구성요소 모두가 서버의 필수 구성요소인 것은 아니다. 도 3에 도시된 구성요소보다 많은 구성요소에 의해 서버가 구현될 수도 있고, 도 3에 도시된 구성요소보다 적 은 구성요소에 의해 서버가 구현될 수도 있다. 컴퓨팅 자원은, 연산을 위한 자원으로서 CPU를 의미할 수 있다. 일 실시예에서, 컴퓨팅 자원은 멀티코어 CPU로 구현될 수도 있다. 컴퓨팅 자원은 전술한 도 2에서의 컴퓨팅 자원과 유사하게 구현될 수 있다. 통신부는, 다른 서버들 또는 코어 네트워크와 통신할 수 있다. 일 실시예에서, 통신부는 연관 서버들 로부터 연관 서버 내의 컴퓨팅 자원의 상태 정보를 획득할 수 있고, 다른 서버에게 자신의 컴퓨팅 자원에 대한 상태 정보를 제공할 수 있다. 통신부는 코어 네트워크(CN)와 통신함으로써, 사용자 단말(UE)로부터의 서비 스 요청 정보를 수신하고, 처리해야할 작업에 대한 정보를 수신하고, 처리된 작업 및 그에 대응하는 서비스를 사용자 단말(UE)에 제공할 수 있다. 저장부는 서버의 동작을 제어하기 위해 후술할 프로세서에 의해 실행될 프로그램을 저장할 수 있다. 저장부는 서버의 동작을 제어하기 위한 적어도 하나의 명령어들(instruction)을 포함하는 프로 그램을 저장할 수 있다. 저장부에는 프로세서가 판독할 수 있는 명령어들 및 프로그램 코드(program code)가 저장될 수 있다. 일 실시예에서, 프로세서는 저장부에 저장된 프로그램의 명령어들 또는 코 드들을 실행하도록 구현될 수 있다. 저장부는 서버로 입력되거나 서버로부터 출력되는 데이터를 저장할 수 있다. 일 실시예에서, 저장부는 서버에게 할당되는 VNF를 저장할 수 있다. 저장부는 예를 들어, 플래시 메모리(flash memory), 하드디스크(hard disk), 멀티미디어 카드 마이크로 타 입(multimedia card micro type), 카드 타입의 메모리(예를 들어, SD 또는 XD 메모리 등), 램(RAM, Random Access Memory), SRAM(Static Random Access Memory), 롬(ROM, Read-Only Memory), EEPROM(Electrically Erasable Programmable Read-Only Memory), PROM(Programmable Read-Only Memory), 자기 메모리, 자기 디스크, 광디스크 중 적어도 하나의 타입의 저장 매체를 포함할 수 있다. 저장부에 저장된 프로그램들은 그 기능에 따라 복수 개의 모듈들로 분류할 수 있다. 예를 들어, 저장부 는, VNF 식별 모듈, 예측 트래픽 획득 모듈, 컴퓨팅 자원 상태 정보 획득 모듈, 및 컴퓨팅 자원 할당 조정 모듈을 포함할 수 있다. 또한, 저장부는 DB(데이터베이스)를 포함할 수 있다. 인공지능 모델은, 본 개시의 일 실시예에 따른 복수의 VNF에 대한 컴퓨팅 자원의 할당을 조정하는 방법 및 그 서버에서 이용되는 인공지능 모델들을 포함할 수 있다. 일 실시예에서, 본 개시에 따른 방법은 두 개의 인공 지능 모델을 이용하는 단계를 포함할 수 있고, 따라서, 인공지능 모델은 제1 인공지능 모델 및 제2 인공지능 모델을 포함할 수 있다. 제1 인공지능 모델은, 서버가 예측 트래픽을 획득하는 동작에 이용될 수 있다. 제2 인공지능 모델은, 서버가 복수의 VNF에 대한 컴퓨팅 자원을 할당하거 나, 할당을 조정하는 동작에 이용될 수 있다. 일 실시예에서, 인공지능 모델은 저장부에 포함될 수도 있다. 프로세서는, 서버의 전반적인 동작을 제어할 수 있다. 예를 들어, 프로세서는 저장부에 저 장된 프로그램들을 실행함으로써, 컴퓨팅 자원, 인공지능 모델, 통신부, 및 저장부 등을 전반적으로 제어할 수 있다. 프로세서는 전술한 도 2에서의 프로세서와 유사하게 구현될 수 있다. 프로세서는 산술, 로직 및 입출력 연산과 시그널 프로세싱을 수행하는 하드웨어 구성 요소로 구성될 수 있 다. 프로세서는 예를 들어, 중앙 처리 장치(Central Processing Unit), 마이크로 프로세서 (microprocessor), 그래픽 프로세서(Graphic Processing Unit), ASICs(Application Specific Integrated Circuits), DSPs(Digital Signal Processors), DSPDs(Digital Signal Processing Devices), PLDs(Programmable Logic Devices), 및 FPGAs(Field Programmable Gate Arrays) 중 적어도 하나로 구성될 수 있으나, 이에 제한되는 것은 아니다. 프로세서는, 저장부에 저장된 프로그램들 중 VNF 식별 모듈을 구성하는 적어도 하나의 명령어들 을 실행함으로써, 서버에 연결된 UE들에 관련된 작업을 처리하기 위해, 작업에 관련된 복수의 VNF를 식별할 수 있다. 예를 들어, 서버는 복수의 VNF들을 연관된 작업에 따라 식별하거나, 구현되는 가상 머신(VM)에 따라 식별할 수 있다. 일 실시예에서, 복수의 VNF의 식별 정보는 서버 외부에 배치된 VNF 매니저로부터 수신할 수 있다. VNF 매니저는 UE들에 관련된 작업을 함께 처리하는 서버들 및 복수의 VNF를 관리 할 수 있다. 일 실시예에서, 프로세서는 통신부를 제어함으로써, VNF의 식별 정보를 수신할 수 있다. 예를 들어, VNF 매니저가 각각의 서버들에 VNF를 배포할 때, 복수의 VNF들에 대한 식별 정보를 함께 배포할 수도 있다. 프로세서는, 저장부에 저장된 프로그램들 중 예측 트래픽 획득 모듈을 구성하는 적어도 하나의 명령어들을 실행함으로써, 복수의 VNF를 통하여 작업을 처리하는데 서버내에서 발생될 예측 트래픽을 획득할 수 있다. 예를 들어, 예측 트래픽은 미래의 특정 시점에 발생할 트래픽의 정도(amount)를 의미할 수 있 다. 일 실시예에서, 예측 트래픽 획득 모듈을 구성하는 적어도 하나의 명령어들이 실행되면, 프로세서는 제1 인공지능 모델을 제어함으로써 예측 트래픽을 획득할 수 있다. 예를 들어, 예측 트래픽 획득 모듈 을 구성하는 적어도 하나의 명령어들이 실행되면, 제1 인공지능 모델로부터 예측 트래픽이 획득 될 수 있다. 이 때, 제1 인공지능 모델은 전술한 도 2에서의 제1 인공지능 모델(M1)과 유사하게 구현될 수 있다. 예를 들어, 제1 인공지능 모델은 서버의 버퍼에 대기중인 대기 트래픽 및 트래픽 이력 정보를 입력 값으로 하여 예측 트래픽을 예측하도록 훈련될 수 있다. 프로세서는, 제1 인공지능 모델을 제어하기 에 앞서, DB를 제어하여 트래픽 이력 정보를 획득하고, 획득된 트래픽 이력 정보를 제1 인공지능 모델 에 제공할 수 있다. 프로세서는, 저장부에 저장된 프로그램들 중 컴퓨팅 자원 상태 정보 획득 모듈을 구성하는 적어 도 하나의 명령어들을 실행함으로써, 적어도 하나의 연관 서버로부터, 연관 서버 내의 컴퓨팅 자원의 상태 정보 를 획득할 수 있다. 예를 들어, 연관 서버 내의 컴퓨팅 자원의 상태 정보에는 연관 서버 내에서 컴퓨팅 자원이 어느 VNF에 어느 정도 할당되어 있는지와 관련된 정보, 또는 전체적인 컴퓨팅 자원의 점유율 등을 포함할 수 있 다. 일 실시예에서, 컴퓨팅 자원 상태 정보 획득 모듈은 서버 자신의 컴퓨팅 자원에 대한 상태 정보를 획득할 수도 있다. 프로세서는, 저장부에 저장된 프로그램들 중 컴퓨팅 자원 할당 조정 모듈을 구성하는 적어도 하 나의 명령어들을 실행함으로써, 앞서 획득된 컴퓨팅 자원의 상태 정보 및 예측 트래픽에 기초하여, 복수의 VNF에 대한 컴퓨팅 자원의 할당을 조정할 수 있다. 컴퓨팅 자원의 상태 정보는 연관 서버 내의 컴퓨 팅 자원의 상태 정보를 포함할 수 있고, 일 실시예에서, 서버 자체의 컴퓨팅 자원의 상태 정보를 더 포함 할 수도 있다. 예를 들어, 컴퓨팅 자원의 할당을 조정하는 동작은, 복수의 VNF 사이에 해당 서버가 보유하고 있는 제한된 컴퓨팅 자원(CPU)을 어떻게 배분할지 결정하는 동작, 및 배분된 각각의 컴퓨팅 자원 (CPU)의 클럭 속도(clock speed)를 어떻게 설정할지 결정하는 동작을 포함할 수 있다. 일 실시예에서, 컴퓨팅 자원 할당 조정 모듈을 구성하는 적어도 하나의 명령어들이 실행되면, 프로세서 는 제2 인공지능 모델을 제어함으로써 VNF에 대한 컴퓨팅 자원의 할당을 조정할 수 있다. 예를 들어, 컴퓨팅 자원 할당 조정 모듈이 실행되면, 제2 인공지능 모델로부터 컴퓨팅 자원의 할당 조정이 도출될 수 있다. 이 때, 제2 인공지능 모델은 전술한 도 2에서의 제2 인공지능 모델(M2)과 유 사하게 구현될 수 있다. 예를 들어, 제2 인공지능 모델은 예측 트래픽 및 연관 서버 내의 컴퓨팅 자원의 상태 정보를 입력 값으로 하여, 서버 내의 컴퓨팅 자원의 할당을 조정하도록 훈련될 수 있다. 일 실 시예에서, 제2 인공지능 모델은, 서버 자체 내의 컴퓨팅 자원의 상태 정보를 입력 값으로 더 포 함할 수도 있다. 프로세서는 제2 인공지능 모델을 제어하기에 앞서, 예측 트래픽 획득 모듈에 저장된 적어도 하나의 명령어를 실행하여 예측 트래픽을 획득하고, 컴퓨팅 자원 상태 정보 획득 모듈에 저 장된 적어도 하나의 명령어를 실행하여 연관 서버의 컴퓨팅 자원 상태 정보 및 서버 자체의 컴퓨팅 자원상태 정보를 획득할 수 있다. 획득된 예측 트래픽 및 컴퓨팅 자원 상태 정보는 제2 인공지능 모델에 입력 으로 제공될 수 있다. 저장부에 포함된 DB(데이터베이스)는 방대한 양의 데이터의 집합으로 구성될 수 있다. 일 실시예에서, DB는 컴퓨팅 자원의 할당 조정 히스토리에 관련된 조정 이력 DB(353-1)를 포함할 수 있 다. 일 실시예에서 DB는 예측 트래픽을 획득하는 동작에 이용되거나, 인공지능 모델을 훈련하고 업데 이트 하는 동작에 이용될 수 있다. 본 개시의 일 실시예에 따른 서버가 복수의 VNF에 대한 컴퓨팅 자원의 할당 을 조정하는 방법에서 획득된 모든 데이터는 DB에 저장될 수 있고, 따라서 데이터를 귀납적으로 이용할 수 있다. 도 4는 본 개시의 일 실시예에 따른 서버가 복수의 VNF에 대한 컴퓨팅 자원의 할당(allocation)을 조정하는 방 법의 흐름도이다. 단계 410에서, 복수의 VNF를 식별할 수 있다. 복수의 VNF는 UE들에 관련된 작업을 처리하기 위해 서버에 할당될 수 있다. 일 실시예에서, 서버는 작업에 관련된 복수의 VNF를 VNF 식별 정보 또는 연관 서버의 식별 정보를 이 용해 식별할 수 있다. 예를 들어, 제1 내지 제4 VNF를 통해 제1 작업이 처리될 수 있는데, 제1 VNF 및 제2 VNF는 제1 서버에 할당되고, 제2 VNF, 제3 VNF, 및 제4 VNF는 제2 서버에 할당될 수 있다. 이 때, 제1 서버 및 제2 서버에는 각각 제2 VNF가 할당된다는 점에서 제1 서버 및 제2 서버는 연관 관계를 가진다고 볼 수 있다. 따라서, 제1 서버의 관점에서 제2 서버는 연관 서버가 될 수 있다. 이 때, 제1 서버는 할당 받은 제1 VNF 및 제2 VNF를 구별하고, 제2 VNF에 대해 제2 서버를 연관 서버로 식별할 수 있다. 단계 420에서, 예측 트래픽을 획득할 수 있다. 예측 트래픽은 복수의 VNF를 통해 작업을 처리함에 있어서, 미래 특정 시점에서 서버 내에 발생될 트래픽을 의미할 수 있다. 일 실시예에서, 예측 트래픽은 서버 전체에 발생될 트래픽 또는 특정 VNF에 대해 발생될 트래픽을 포함할 수 있다. 일 실시예에서, 예측 트래픽은 복수의 미래 시 점에서 발생할 트래픽에 대응하는 정보를 포함할 수도 있다. 예를 들어, 예측 트래픽은 버퍼에 대기중인 대기 트래픽 및 트래픽 이력 정보를 입력 값으로 하는 인공지능 모 델을 통해 획득될 수 있다. 일 실시예에서, 예측 트래픽을 획득하는 단계는, 기 설정된 주기에 따라, 예측 트래 픽을 획득하는 동작일 수 있다. 기 설정된 주기는 예를 들어, 1분일 수 있다. 예측 트래픽을 1분 주기로 획득할 경우, 시간에 따른 트래픽의 변화를 1분 단위로 추적할 수 있으며, 트래픽의 변화에 대해 실시간에 가까운 대응 을 할 수 있다. 단계 430에서, 연관 서버 내의 컴퓨팅 자원의 상태 정보를 획득할 수 있다. 예를 들어, 연관 서버는, 서버에 연 결된 UE들에 관련된 작업을 처리하는 다른 서버를 포함할 수 있다. 일 실시예에서, 두 개 이상의 연관 서버로부 터, 각각의 서버 내의 컴퓨팅 자원의 상태 정보를 획득할 수도 있다. 예를 들어, 제1 작업과 관련된 제1 내지 제4 VNF 중, 제1 VNF 및 제2 VNF는 제1 서버에 할당되고, 제2 VNF, 제3 VNF, 및 제4 VNF는 제2 서버에 할당된 경우, 제1 서버는 연관 서버인 제2 서버로부터, 제2 서버 내의 컴퓨팅 자 원이 제2 VNF, 제3 VNF, 및 제4 VNF에 대해 어떻게 할당되어 있는지 그 상태 정보를 획득할 수 있다. 단계 440에서, 복수의 VNF에 대한 컴퓨팅 자원의 할당을 조정할 수 있다. 예를 들어, 연관 서버 내의 컴퓨팅 자 원의 상태 정보 및 예측 트래픽에 기초하여, 복수의 VNF에 대한 컴퓨팅 자원의 할당을 조정할 수 있다. 일 실시 예에서, 예측 트래픽 및 다른 연관 서버의 정보를 이용해 해당 서버의 컴퓨팅 자원을 새롭게 할당하거나, 기존 의 할당을 조정하는 경우, 시간에 따라 변화하는 트래픽 패턴에 실시간으로 빠르게 대응할 수 있고, 컴퓨팅 자 원의 효율적인 활용이 가능하다. 복수의 VNF에 대한 컴퓨팅 자원의 할당은 예측 트래픽이 획득되는 주기에 따라 조정될 수 있다. 예를 들어, 예 측 트래픽을 획득하는 동작과 컴퓨팅 자원의 할당을 조정하는 동작은 일대일 대응되고, 번갈아 가며 수행될 수 있다. 즉, 예측 트래픽이 획득되면, 항상 예측 트래픽을 이용해 컴퓨팅 자원의 할당이 조정될 수 있다. 일 실시 예에서, 예측 트래픽과 현재 트래픽 간의 차이가 기 설정된 임계 값을 초과하는 경우에 한하여, 복수의 VNF에 대한 컴퓨팅 자원의 할당이 조정될 수도 있다. 예를 들어, 예측 트래픽은 기 설정된 주기로 획득되나, 예측 트 래픽이 획득될 때마다 컴퓨팅 자원의 할당이 조정되는 것이 아니라, 예측 트래픽이 현재 트래픽과 차이가 커서 이후 시점에 트래픽의 과도한 변경이 예측되는 경우에 한해 컴퓨팅 자원의 할당이 조정될 수도 있다. 예를 들어, 복수의 VNF에 대한 컴퓨팅 자원의 할당을 조정하는 동작은, 예측 트래픽이 현재 트래픽에 비해 변화가 없 거나, 각각의 VNF에 대한 트래픽의 증감 비율이 동일하여 복수의 VNF에 대해 기 할당된 컴퓨팅 자원의 변경이필요하지 않은 경우, 컴퓨팅 자원의 할당을 유지하는 동작을 포함할 수도 있다. 일 실시예에서, 복수의 VNF에 대한 컴퓨팅 자원의 할당의 조정에는, 예측 트래픽 및 연관 서버 내의 컴퓨팅 자 원의 상태 정보를 입력 값으로 하는 인공지능 모델이 이용될 수 있다. 예를 들어, 제1 작업과 관련된 제1 내지 제4 VNF 중, 제1 VNF 및 제2 VNF는 제1 서버에 할당되고, 제2 VNF, 제3 VNF, 및 제4 VNF는 제2 서버에 할당된 경우, 제1 서버가 제1 VNF 및 제2 VNF에 대한 컴퓨팅 자원의 할당을 조정 하는 동작은 다음과 같을 수 있다. 먼저, 제1 서버는 제1 VNF 및 제2 VNF에 발생할 예측 트래픽을 획득할 수 있 다. 또한, 연관 서버인 제2 서버로부터, 제2 서버 내의 컴퓨팅 자원이 제2 VNF, 제3 VNF, 및 제4 VNF에 대해 어 떻게 할당되어 있는지 그 상태 정보를 획득할 수 있다. 제1 서버는 획득한 예측 트래픽 및 연관 서버의 컴퓨팅 자원 상태 정보에 기초하여 제1 VNF 및 제2 VNF에 대한 컴퓨팅 자원의 할당을 조정할 수 있다. 예를 들어, 제1 서버 내에서, 제2 VNF에 관련된 예측 트래픽이 제1 VNF에 관련된 예측 트래픽보다 크거나, 제2 서버 내의 컴퓨 팅 자원이 제2 VNF에 대해 적게 할당된 경우, 제1 서버는 제1 VNF에 대한 컴퓨팅 자원의 할당을 낮추고, 제2 VNF에 대한 컴퓨팅 자원의 할당을 높이는 방식으로 컴퓨팅 자원의 할당을 조정할 수 있다. 도 5는 본 개시의 일 실시예에 따른 서버가 예측 트래픽을 획득하는 동작에서 이용하는 제1 인공지능 모델을 업 데이트하는 동작을 설명하기 위한 도면이다. 일 실시예에서, 서버는 버퍼에 대기중인 대기 트래픽 및 트래픽 이력 정보를 입력 값으로 하여 예측 트래픽을 출력하도록 훈련된 제1 인공지능 모델을 이용하여, 예측 트래픽을 획득할 수 있다. 제1 인공지능 모델의 최적화 를 위하여, 서버가 제1 인공지능 모델을 업데이트 하는 동작을 더 포함할 수 있다. 단계 510에서, 기 설정된 시점에 서버 내에서 발생된 실제 트래픽을 획득할 수 있다. 실제 트래픽은 예측 트래 픽과는 달리, 복수의 VNF를 통하여 작업을 처리함으로써 서버 내에서 실제로 발생된 트래픽을 의미한다. 단계 520에서, 특정 시점에서의 예측 트래픽과 실제 트래픽에 기초하여 예측 에러를 획득할 수 있다. 예측 에러 는 트래픽의 예측에 대한 오차에 해당한다. 일 실시예에서 예측 에러는 예측 트래픽과 실제 트래픽의 차이로부 터 획득될 수 있다. 단계 530에서, 예측 에러와 기 설정된 임계값의 비교에 기초하여 제1 인공지능 모델의 업데이트 여부를 결정할 수 있다. 일 실시예에서, 업데이트 여부는 기 설정된 시간 주기로 결정될 수 있다. 예측 트래픽과 실제 트래픽 의 차이를 지속적으로 모니터링하여, 예측 에러가 과도해질 경우, 모델을 업데이트 함으로서 모델의 최적화가 가능하다. 단계 540에서, 결정된 업데이트 여부에 기초하여, 제1 인공지능 모델을 업데이트할 수 있다. 업데이트를 수행함 으로써, 시간에 따른 트래픽의 패턴 예측이 더욱 정확해질 수 있다. 도 6은 본 개시의 일 실시예에 따른 서버가 복수의 VNF에 대한 컴퓨팅 자원의 할당을 조정하는 동작에서 이용하 는 제2 인공지능 모델을 업데이트하는 동작을 설명하기 위한 도면이다. 일 실시예에서, 서버는 예측 트래픽, 서버 자체 내의 컴퓨팅 자원의 상태 정보, 및 연관 서버 내의 컴퓨팅 자원 의 상태 정보를 입력 값으로 하여 컴퓨팅 자원의 할당을 조정하도록 훈련된 제2 인공지능 모델을 이용하여, 서 버 내의 컴퓨팅 자원의 할당을 조정할 수 있다. 제2 인공지능 모델의 최적화를 위하여, 서버가 제2 인공지능 모 델을 업데이트 하는 동작을 더 포함할 수 있다. 단계 610에서, 서버의 전력 사용량 정보, 서버의 온도 상승 정보, 서버가 처리하는 작업의 처리 지연에 관련된 정보, 또는 서버가 처리한 작업의 작업량 중 적어도 하나의 정보를 획득할 수 있다. 서버가 제2 인공지능 모델 의 최적화를 위해 획득하는 정보는 기재한 정보에 한정되지 않으며, 모델을 보완하는 동작에 이용될 수 있는 다 양한 정보를 획득할 수 있다. 단계 620에서, 획득된 정보에 기초하여 제2 인공지능 모델의 최적화를 위한 보상값을 획득할 수 있다. 일 실시 예에서, 서버가 컴퓨팅 자원의 할당을 조정했음에도 불구하고 트래픽의 지연이 발생하거나 또는 서버가 과열될 수 있다. 이 경우, 컴퓨팅 자원의 할당을 조정하는 데이터의 설정에 오류가 있는 것으로서, 획득한 보상값을 적 용하여 모델을 수정할 수 있다. 단계 630에서, 보상값과 기 설정된 임계값의 비교에 기초하여 제2 인공지능 모델의 업데이트 여부를 결정할 수 있다. 일 실시예에서, 업데이트 여부는 기 설정된 시간 주기로 결정될 수 있다. 컴퓨팅 자원의 할당을 조정하는 것에 의한 효과를 지속적으로 관측하여, 조정으로 인해 부정적인 효과가 발생한 경우, 피드백을 통해 모델을 업데이트 함으로서 모델의 최적화가 가능하다. 단계 640에서, 결정된 업데이트 여부에 기초하여, 제2 인공지능 모델을 업데이트할 수 있다. 업데이트를 수행함 으로써, 컴퓨팅 자원의 할당을 보다 정확하게 조정할 수 있다. 도 7은 본 개시의 일 실시예에 따른 서버가 서버들 및 복수의 VNF를 관리하는 VNF 매니저(VNFM)로부터 복수의 VNF의 식별 정보 및 연관 서버의 식별 정보를 수신하는 동작을 설명하기 위한 도면이다. 도 7을 참조하면, VNF 매니저(VNFM)는, UE들에 관련된 작업에 대응되는 네트워크 기능으로부터, 하나 이상의 VNF(VNF1, VNF2, VNF3, VNF4)를 정의할 수 있다. 이후, VNF 매니저(VNFM)는 정의된 각각의 VNF(VNF1, VNF2, VNF3, VNF4)를 복수의 서버들(701, 702, 703)에 할당할 수 있다. 일 실시예에서, 특정 VNF는 복수의 서버들에게 할당될 수 있고, 특정 서버에는 복수의 VNF가 할당될 수 있다. 예를 들어, VNF1은 제1 서버 및 제3 서버에 할당되고, VNF2는 제1 서버 및 제2 서버에 할 당되고, VNF3은 제2 서버 및 제3 서버에 할당될 수 있다. 이를 각각의 서버의 입장에서 보면, 제1 서 버에는 두 개의 VNF(VNF1, VNF2)가 할당될 수 있고, 제2 서버에는 다른 두 개의 VNF(VNF2, VNF3)가 할당될 수 있고, 제3 서버에는 또 다른 두 개의 VNF(VNF1, VNF3)가 할당될 수 있다. 즉, 각각의 서버(701, 702, 703)들에 할당된 서비스 체인(일련의 VNF)은 서로 다를 수 있다. 서버(701, 702, 703)들은 각각 VNF 매니저(VNFM)로부터 할당 받은 VNF(VNF1, VNF2, VNF3)를 통하여, UE로부터 요청된 작업을 처리할 수 있다. 서버(701, 702, 703)들은 각각 할당 받은 VNF에 대해, 연산에 필요한 컴퓨팅 자 원(CPU)을 할당하고, 조정할 수 있다. 예를 들어, 제1 서버의 제1 프로세서는 할당 받은 VNF1, VNF2 에 대해 각각 어느 정도의 컴퓨팅 자원을 어떤 속도로 배분할지를 결정할 수 있다. 도 7을 참조하여, 제2 서버가 복수의 VNF에 대한 컴퓨팅 자원의 할당을 조정하는 방법을 보다 구체적으로 살펴본다. 제2 서버는 먼저, 작업에 관련된 복수의 VNF를 식별할 수 있다. 즉, 제2 서버는 자신에게 할당된 VNF2 및 VNF3를 인식하고 구분할 수 있다. 다음으로, 제2 서버는 서버 내에서 발생될 예측 트래픽을 획득할 수 있다. 예를 들어, 제2 서버는 VNF2와 관련하여 발생할 트래픽 및 VNF3와 관련하여 발생할 트래픽을 구별하여 획득할 수도 있고, 전체로서 제2 서버에 발생할 트래픽을 획득할 수 있다. 이후, 제2 서버는 적어도 하나의 연관 서버로부터, 연관 서버 내의 컴퓨팅 자원의 상태 정보를 획득할 수 있다. VNF2의 관점에서는 제1 서버가 연관 서버일 수 있고, VNF3의 관점에서는 제3 서버가 연관 서버 일 수 있다. 따라서, 제2 서버는 제1 서버 내의 컴퓨팅 자원의 상태 정보 및 제3 서버 내의 컴 퓨팅 자원의 상태 정보를 획득할 수 있다. 다만, 이는 일 실시예에 불과하며, 동일한 VNF 포함 여부가 아닌 다 른 기준에 의해 연관 서버가 정해질 수도 있다. 나아가, 제2 서버는 획득한 연관 서버 내의 컴퓨팅 자원의 상태 정보 및 예측 트래픽에 기초하여, 각각의 VNF2 및 VNF3에 대한 컴퓨팅 자원의 할당을 조정할 수 있다. 예를 들어, 제2 서버가 VNF3에 대한 컴퓨팅 자원의 할당을 조정하는데 있어서, VNF3을 포함하는 제3 서버가 VNF3에 자신의 컴퓨팅 자원을 어느정도 할 당하였는지 고려될 수 있다. 예를 들어, 제3 서버가 VNF3에 컴퓨팅 자원을 적게 할당한 경우, 제2 서버 는 VNF3에 컴퓨팅 자원을 더 할당하건, 할당된 CPU 코어의 클럭 속도를 증가시키는 방향으로 조정할 수 있 다. 일 실시예에서, VNF에 연관 서버의 식별 정보가 포함될 수도 있다. 예를 들어, VNF 매니저(VNFM)가 각각의 서버 들에 VNF를 배포할 때, 특정 VNF 내부에 해당 VNF가 할당된 서버들의 식별 정보가 포함될 수 있다. 예를 들어, 제2 서버가 수신한 VNF3의 식별 정보에는, ‘제3 서버 또한 VNF3을 할당 받았음’의 정보가 포함될 수 있다. 일 실시예에서, 연관 서버의 식별 정보의 전송은 VNF의 할당과 별개로 이루어질 수도 있다. 예를 들어 VNF3의 식별 정보는 제2 서버 및 제3 서버의 수신부가 각각 수신하고(실선), ‘제2 서버 및 제3 서버 가 VNF3을 할당 받음’의 정보는 제2 서버의 제2 프로세서 및 제3 서버의 제3 프로세서 가 각각 수신할 수 있다(점선). 도 8은 본 개시의 일 실시예에 따른 서버가 복수의 VNF(851a. 851b, 851c)에 대한 컴퓨팅 자원(811, 812, 813, 814, 815)의 할당을 조정하는 동작을 설명하기 위한 도면이다.도 8을 참조하면, 서버는 프로세서를 통해 컴퓨팅 자원(811, 812, 813, 814, 815)의 할당을 조정할 수 있 다. 이 경우, 복수의 VNF(851a. 851b, 851c)가 각각 모든 컴퓨팅 자원(811, 812, 813, 814, 815)에 접근하는 경우와 달리, 프로세서를 통한 안정적인 자원 배분이 가능하다. 각각의 VNF(851a. 851b, 851c)가 컴퓨팅 자원(811, 812, 813, 814, 815)에 직접 접근하는 경우, 특정 컴퓨팅 자원에 연산이 몰리는 경우도 발생할 수 있 고, CPU 코어의 온/오프 여부를 결정하기도 어렵다. 본 개시의 일 실시예에서는, 프로세서가 서버 내에서 발생될 트래픽을 예측하고, 예측된 트래픽 및 획득한 연관 서버 내의 컴퓨팅 자원의 상태 정보에 기초하여 복수의 VNF(Virtualized Network Function)에 대한 컴퓨팅 자원의 할당을 조정할 수 있다. 따라서, 컴퓨팅 자원의 안정적인 조정이 가능하고, 예측되지 않은 트래픽 패턴 에도 실시간으로 빠르게 대응할 수 있다. 또한, 본 개시의 일 실시예에 의하면, 컴퓨팅 자원의 효율적인 활용이 가능하며, 필요 이상의 전력을 소모하거나 작업의 처리에 지연이 발생하는 것을 방지할 수 있다. 본 개시의 일 실시예에서는, 하나 이상의 인공지능 모델을 이용하여 서버 내에서 발생될 트래픽을 예측하고 컴 퓨팅 자원의 할당을 조정할 수 있다. 이때, 예측 에러의 크기 또는 보상값을 통해 하나 이상의 인공지능 모델을 각각 업데이트 함으로써, 트래픽 예측의 정확도를 높이고, 컴퓨팅 자원의 할당을 더욱 최적화할 수 있다."}
{"patent_id": "10-2020-0111765", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "전술한 본 개시의 설명은 예시를 위한 것이며, 본 개시가 속하는 기술분야의 통상의 지식을 가진 자는 본 개시 의 기술적 사상이나 필수적인 특징을 변경하지 않고서 다른 구체적인 형태로 쉽게 변형이 가능하다는 것을 이해 할 수 있을 것이다. 그러므로 이상에서 기술한 실시예들은 모든 면에서 예시적인 것이며 한정적이 아닌 것으로 이해해야만 한다. 예를 들어, 단일형으로 설명되어 있는 각 구성 요소는 분산되어 실시될 수도 있으며, 마찬가 지로 분산된 것으로 설명되어 있는 구성 요소들도 결합된 형태로 실시될 수 있다. 본 개시의 범위는 상기 상세한 설명보다는 후술하는 특허청구범위에 의하여 나타내어지며, 특허청구범위의 의미 및 범위 그리고 그 균등 개념으로부터 도출되는 모든 변경 또는 변형된 형태가 본 개시의 범위에 포함되는 것으 로 해석되어야 한다.도면 도면1 도면2 도면3 도면4 도면5 도면6 도면7 도면8"}
{"patent_id": "10-2020-0111765", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 개시의 일 실시예에 따른 서버가 포함된 NFV(Network Function Virtualization)에서의 네트워크 구 조를 도시한다. 도 2는 본 개시의 일 실시예에 따른 서버가 복수의 VNF(Virtualized Network Function)에 대한 컴퓨팅 자원의 할당(allocation)을 조정하는 방법의 개요도이다.도 3은 본 개시의 일 실시예에 따른 서버의 블록도이다. 도 4는 본 개시의 일 실시예에 따른 서버가 복수의 VNF에 대한 컴퓨팅 자원의 할당(allocation)을 조정하는 방 법의 흐름도이다. 도 5는 본 개시의 일 실시예에 따른 서버가 예측 트래픽을 획득하는 동작에서 이용하는 제1 인공지능 모델을 업 데이트하는 동작을 설명하기 위한 도면이다. 도 6은 본 개시의 일 실시예에 따른 서버가 복수의 VNF에 대한 컴퓨팅 자원의 할당을 조정하는 동작에서 이용하 는 제2 인공지능 모델을 업데이트하는 동작을 설명하기 위한 도면이다. 도 7은 본 개시의 일 실시예에 따른 서버가 서버들 및 복수의 VNF를 관리하는 VNF 매니저로부터 복수의 VNF의 식별 정보 및 연관 서버의 식별 정보를 수신하는 동작을 설명하기 위한 도면이다. 도 8은 본 개시의 일 실시예에 따른 서버가 복수의 VNF에 대한 컴퓨팅 자원의 할당을 조정하는 동작을 설명하기 위한 도면이다."}
