{"patent_id": "10-2017-0162116", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2018-0111467", "출원번호": "10-2017-0162116", "발명의 명칭": "사용자 감정 판단을 위한 전자 장치 및 이의 제어 방법", "출원인": "삼성전자주식회사", "발명자": "윤소정"}}
{"patent_id": "10-2017-0162116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "인공지능 신경망(Neural Network) 모델을 이용하는 전자 장치의 제어 방법에 있어서,상기 전자 장치와 연결된 외부 단말로부터 사용자를 포함하는 영상 데이터 및 부가 데이터를 획득하는 단계;상기 영상 데이터 및 상기 부가 데이터를 이용하여 상기 사용자의 실제 감정을 판단하기 위한 특징 데이터를 생성하는 단계; 상기 특징 데이터를 감정 인식 모델에 입력하여 상기 사용자의 실제 감정을 판단하는 단계; 를 포함하는 제어방법."}
{"patent_id": "10-2017-0162116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 부가 데이터는,상기 영상의 GPS 정보, 방위 정보, 해시 태그 정보, 상기 사용자에 대한 기 입력된 정보, 상기 사용자의 과거감정 및 상기 영상에 대한 크롤링 정보 중 적어도 하나를 포함하는 제어 방법."}
{"patent_id": "10-2017-0162116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 특징 데이터는 제1 특징 데이터 및 제2 특징 데이터를 포함하고,상기 제1 특징 데이터는 주변 정보를 제외한 상기 사용자의 감정과 관련된 특징 데이터이며, 상기 제2 특징 데이터는, 상기 사용자의 주변 정보에 대한 특징 데이터인 것을 특징으로 하는 제어 방법."}
{"patent_id": "10-2017-0162116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서,상기 판단하는 단계는,상기 제1 특징 데이터를 감정 인식 모델에 입력하여 상기 사용자의 감정을 판단하고, 상기 제2 특징 데이터를감정 인식 모델에 입력하여 상기 주변 정보를 판단하며,판단된 상기 제1 특징 데이터에 대한 사용자의 감정 및 상기 제2 특징 데이터에 대한 주변 정보를 분석하여 상기 사용자의 실제 감정을 판단하는 것을 특징으로 하는 제어 방법."}
{"patent_id": "10-2017-0162116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서,상기 감정을 판단하는 단계는,상기 사용자의 과거 감정에 대한 가중치를 계산하는 단계; 및상기 특징 데이터 및 상기 가중치를 이용하여 상기 사용자의 현재 감정을 판단하는 단계; 를 포함하는 제어 방법."}
{"patent_id": "10-2017-0162116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서,상기 특징 데이터를 시간 또는 장소로 분류하여 메모리에 저장하는 단계;를 포함하는 제어 방법.공개특허 10-2018-0111467-2-청구항 7 제6항에 있어서,상기 외부 단말로부터 사용자 요청이 수신되면, 상기 특징 데이터를 감정 추론 모델에 입력하여 상기 사용자의감정 발생 원인을 판단하는 단계; 및상기 판단된 감정 발생 원인을 상기 외부 단말로 제공하는 단계;를 포함하는 제어 방법."}
{"patent_id": "10-2017-0162116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서,상기 판단하는 단계는,상기 사용자의 감정 발생 원인을 시간, 장소, 인물 또는 사건 별로 판단하는 것을 특징으로 하는 포함하는 제어방법."}
{"patent_id": "10-2017-0162116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "인공지능 신경망(Neural Network) 모델을 이용하는 전자 장치에 있어서,상기 전자 장치와 연결된 외부 단말로부터 사용자를 포함하는 영상 데이터 및 부가 데이터를 수신하는 통신부;상기 영상 데이터 및 상기 부가 데이터를 이용하여 상기 사용자의 실제 감정을 판단하기 위한 특징 데이터를 결정하고, 상기 특징 데이터를 감정 인식 모델에 입력하여 상기 사용자의 실제 감정을 판단하는 프로세서; 및상기 특징 데이터를 저장하는 메모리; 를 포함하는 전자 장치."}
{"patent_id": "10-2017-0162116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9항에 있어서,상기 부가 데이터는,상기 영상의 GPS 정보, 방위 정보, 해시태그 정보, 상기 사용자에 대한 기 입력된 정보, 상기 사용자의 과거 감정 및 상기 영상에 대한 크롤링 정보 중 적어도 하나를 포함하는 전자 장치."}
{"patent_id": "10-2017-0162116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제9항에 있어서,상기 특징 데이터는 제1 특징 데이터 및 제2 특징 데이터를 포함하고,상기 제1 특징 데이터는 주변 정보를 제외한 상기 사용자의 감정과 관련된 특징 데이터이며, 상기 제2 특징 데이터는, 상기 사용자의 주변 정보에 대한 특징 데이터인 것을 특징으로 하는 전자 장치"}
{"patent_id": "10-2017-0162116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항에 있어서,상기 프로세서는,상기 제1 특징 데이터를 감정 인식 모델에 입력하여 상기 사용자의 감정을 판단하고, 상기 제2 특징 데이터를감정 인식 모델에 입력하여 상기 주변 정보를 판단하며, 판단된 상기 제1 특징 데이터에 대한 사용자의 감정 및제2 특징 데이터에 대한 주변 정보를 분석하여 상기 사용자의 실제 감정을 판단하는 것을 특징으로 하는 전자장치."}
{"patent_id": "10-2017-0162116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제9항에 있어서,상기 프로세서는,상기 사용자의 과거 감정에 대한 가중치를 계산하고, 상기 특징 데이터 및 상기 가중치를 이용하여 상기 사용자공개특허 10-2018-0111467-3-의 현재 감정을 판단하는 것을 특징으로 하는 전자 장치."}
{"patent_id": "10-2017-0162116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제9항에 있어서,상기 프로세서는,상기 특징 데이터를 시간, 장소, 인물 또는 사건별로 분류하여 메모리에 전송하는 것을 특징으로 하는 전자 장치."}
{"patent_id": "10-2017-0162116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제14항에 있어서,상기 프로세서는,상기 외부 단말로부터 사용자 요청이 수신되면, 상기 특징 데이터를 감정 추론 모델에 입력하여 상기 사용자의감정 발생 원인을 판단하고, 상기 판단된 감정 발생 원인을 상기 외부 단말로 제공하는 전자 장치."}
{"patent_id": "10-2017-0162116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제15항에 있어서,상기 프로세서는,상기 사용자의 감정 발생 원인을 시간 또는 장소 별로 판단하는 것을 특징으로 하는 포함하는 전자 장치."}
{"patent_id": "10-2017-0162116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "인공지능 신경망(Neural Network) 모델을 이용하는 전자 장치의 제어 방법을 수행하기 위한 프로그램이 저장된컴퓨터가 판독 가능한 기록 매체에 있어서,상기 전자 장치의 제어 방법은, 상기 전자 장치와 연결된 외부 단말로부터 사용자를 포함하는 영상 데이터 및 부가 데이터를 획득하는 단계;상기 영상 데이터 및 상기 부가 데이터를 이용하여 상기 사용자의 실제 감정을 판단하기 위한 특징 데이터를 결정하는 단계; 상기 특징 데이터를 감정 인식 모델에 입력하여 상기 사용자의 실제 감정을 판단하는 단계;를 포함하는 기록 매체."}
{"patent_id": "10-2017-0162116", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 개시는 딥러닝 등의 기계학습 알고리즘을 활용하는 인공지능(AI)시스템 및 그 응용에 관련된 것이다. 특히 본 개시의 전자 장치의 제어 방법은, 전자 장치와 연결된 외부 단말로부터 사용자를 포함하는 영상 데이터 및 부가 데이터를 획득하고, 영상 데이터 및 부가 데이터를 이용하여 사용자의 실제 감정을 판단하기 위한 특징 데이터를 생성하며, 특징 데이터를 감정 인식 모델에 입력하여 사용자의 실제 감정을 판단한다."}
{"patent_id": "10-2017-0162116", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 전자 장치 및 이의 제어 방법에 관한 것으로, 더욱 상세하게는 데이터를 분석하여 사용자의 감정을 판단하고, 해당 감정이 발생한 원인을 추론할 수 있는 전자 장치 및 이의 제어 방법에 관한 것이다. 또한, 본 개시는 딥러닝 등의 기계 학습 알고리즘을 활용하여 인간 두뇌의 인지, 판단 등의 기능을 모사하는 인 공지능(AI) 시스템 및 그 응용에 관련된 것이다."}
{"patent_id": "10-2017-0162116", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "인공지능(Artificial Intelligence, AI) 시스템은 인간 수준의 지능을 구현하는 컴퓨터 시스템이며, 기존의 규 칙 기반 스마트 시스템과 달리 기계가 스스로 학습하고 판단하며 똑똑해지는 시스템이다. 인공지능 시스템은 사 용할수록 인식률이 향상되고 사용자의 취향을 더욱 정확하게 이해할 수 있게 된다. 따라서, 기존의 규칙 기반 스마트 시스템은 점차 딥러닝 기반의 인공지능 시스템으로 대체되고 있다. 인공지능 기술은 기계학습(ex. 딥러닝) 및 기계 학습을 활용한 요소 기술들로 구성된다. 기계 학습은 입력 데이 터들의 특징을 스스로 분류하여 학습하는 알고리즘 기술이다. 요소 기술은 딥러닝 등의 기계학습 알고리즘을 활 용하는 기술로서, 언어적 이해, 시각적 이해, 추론/예측, 지식 표현, 동작 제어 등의 기술 분야로 구성될 수 있 다. 인공지능 기술이 응용되는 다양한 분야는 다음과 같다. 언어적 이해는 인간의 언어/문자를 인식하고 응용/처리 하는 기술로서, 자연어 처리, 기계 번역, 대화 시스템, 질의응답, 음성 인식/합성 등을 포함한다. 시각적 이해 는 사물을 인간의 시각처럼 인식하여 처리하는 기술로서, 객체 인식, 객체 추적, 영상 검색, 사람 인식, 장면 이해, 공간 이해, 영상 개선 등을 포함한다. 추론/예측은 정보를 판단하여 논리적으로 추론하고 예측하는 기술 로서, 지식/확률 기반 추론, 최적화 예측, 선호 기반 계획, 추천 등을 포함한다. 지식 표현은 인간의 경험 정보 를 지식 데이터로 자동화 처리하는 기술로서, 지식 구축(데이터 생성/분류), 지식 관리(데이터 활용) 등을 포함 한다. 동작 제어는 차량의 자율 주행, 로봇의 움직임 등을 제어하는 기술로서, 움직임 제어(항법, 충돌, 주행), 조작 제어(행동 제어) 등을 포함한다. 한편, 종래에는 감정을 판단하고자 하는 사용자의 얼굴 표정을 분석하여 사용자의 감정 상태를 판단하였다. 그 러나, 사용자의 얼굴을 분석한 감정과 실제 사용자의 감정은 다른 경우가 존재한다. 즉, 사용자의 얼굴 표정은 화가난 상태지만, 실제 사용자의 감정은 행복한 기분일 수 있고, 사용자의 얼굴 표정은 웃고 있으나, 실제 사용 자의 감정은 슬플 수도 있다. 이와 같이, 사용자의 얼굴 표정만을 분석하여 감정을 판단하는 경우, 사용자의 실 제 감정을 정확하게 파악하지 못하는 경우가 존재한다."}
{"patent_id": "10-2017-0162116", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 개시는 상술한 문제점을 해결하기 위한 것으로, 감정을 판단하고자 하는 사용자의 표정을 분석함과 동시에 사용자의 주변 환경 정보를 함께 분석하여, 사용자의 실제 감정을 판단할 수 있는 전자 장치 및 이의 제어 방법 을 제공함에 있다."}
{"patent_id": "10-2017-0162116", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기 목적을 달성하기 위한 본 개시의 일 실시예에 따른 전자 장치의 제어 방법은, 상기 전자 장치와 연결된 외 부 단말로부터 사용자를 포함하는 영상 데이터 및 부가 데이터를 획득하는 단계; 상기 영상 데이터 및 상기 부 가 데이터를 이용하여 상기 사용자의 실제 감정을 판단하기 위한 특징 데이터를 생성하는 단계; 상기 특징 데이 터를 감정 인식 모델에 입력하여 상기 사용자의 실제 감정을 판단하는 단계; 를 포함한다. 이때, 상기 부가 데이터는, 상기 영상의 GPS 정보, 방위 정보, 상기 사용자에 대한 기 입력된 정보 상기 사용자 의 과거 감정 및 상기 영상에 대한 크롤링 정보 중 적어도 하나를 포함할 수 있다. 이때, 상기 특징 데이터는 제1 특징 데이터 및 제2 특징 데이터를 포함하고, 상기 제1 특징 데이터는 주변 정보 를 제외한 상기 사용자의 감정과 관련된 특징 데이터이며, 상기 제2 특징 데이터는, 상기 사용자의 주변 정보에 대한 특징 데이터일 수 있다. 이때, 상기 판단하는 단계는, 상기 제1 특징 데이터를 감정 인식 모델에 입력하여 상기 사용자의 감정을 판단하 고, 상기 제2 특징 데이터를 감정 인식 모델에 입력하여 상기 주변 정보를 판단하며, 판단된 상기 제1 특징 데 이터에 대한 사용자의 감정 및 제2 특징 데이터에 대한 주변 정보를 분석하여 상기 사용자의 실제 감정을 판단 할 수 있다. 이때, 상기 감정을 판단하는 단계는, 상기 사용자의 과거 감정에 대한 가중치를 계산하는 단계; 및 상기 특징 데이터 및 상기 가중치를 이용하여 상기 사용자의 현재 감정을 판단하는 단계; 를 포함할 수 있다. 이때, 상기 특징 데이터를 시간, 장소, 인물 또는 사건별로 분류하여 메모리에 저장하는 단계; 를 포함할 수 있 다. 이때, 상기 외부 단말로부터 사용자 요청이 수신되면, 상기 특징 데이터를 감정 추론 모델에 입력하여 상기 사 용자의 감정 발생 원인을 판단하는 단계; 및 상기 판단된 감정 발생 원인을 상기 외부 단말로 제공하는 단계;를 포함할 수 있다. 이때, 상기 판단하는 단계는, 상기 사용자의 감정 발생 원인을 시간 또는 장소 별로 판단하는 것을 특징으로 하 는 포함할 수 있다.한편, 본 개시의 일 실시예에 따른 전자 장치는, 상기 전자 장치와 연결된 외부 단말로부터 사용자를 포함하는 영상 데이터 및 부가 데이터를 수신하는 통신부; 상기 영상 데이터 및 상기 부가 데이터를 이용하여 상기 사용 자의 실제 감정을 판단하기 위한 특징 데이터를 생성하고, 상기 특징 데이터를 감정 인식 모델에 입력하여 상기 사용자의 실제 감정을 판단하는 프로세서; 및 상기 특징 데이터를 저장하는 메모리; 를 포함한다. 이때, 상기 부가 데이터는, 상기 영상의 GPS 정보, 방위 정보, 상기 사용자에 대한 기 입력된 정보 상기 사용자 의 과거 감정 및 상기 영상에 대한 크롤링 정보 중 적어도 하나를 포함할 수 있다. 이때, 상기 특징 데이터는 제1 특징 데이터 및 제2 특징 데이터를 포함하고, 상기 제1 특징 데이터는 주변 정보 를 제외한 상기 사용자의 감정과 관련된 특징 데이터이며, 상기 제2 특징 데이터는, 상기 사용자의 주변 정보에 대한 특징 데이터일 수 있다. 이때, 상기 프로세서는, 상기 제1 특징 데이터를 감정 인식 모델에 입력하여 상기 사용자의 감정을 판단하고, 상기 제2 특징 데이터를 감정 인식 모델에 입력하여 상기 주변 정보를 판단하며, 판단된 상기 제1 특징 데이터 에 대한 사용자의 감정 및 제2 특징 데이터에 대한 주변 정보를 분석하여 상기 사용자의 실제 감정을 판단하는 것을 특징으로 할 수 있다. 이때, 상기 프로세서는, 상기 사용자의 과거 감정에 대한 가중치를 계산하고, 상기 특징 데이터 및 상기 가중치 를 이용하여 상기 사용자의 현재 감정을 판단하는 것을 특징으로 할 수 있다. 이때, 상기 프로세서는, 상기 특징 데이터를 시간, 장소, 인물 또는 사건별로 분류하여 메모리에 전송하는 것을 특징으로 할 수 있다. 이때, 상기 프로세서는, 상기 외부 단말로부터 사용자 요청이 수신되면, 상기 특징 데이터를 감정 추론 모델에 입력하여 상기 사용자의 감정 발생 원인을 판단하고, 상기 판단된 감정 발생 원인을 상기 외부 단말로 제공할 수 있다. 이때, 상기 프로세서는, 상기 사용자의 감정 발생 원인을 시간 또는 장소 별로 판단하는 것을 특징으로 할 수 있다. 한편, 본 개시의 일 실시예에 따른 전자 장치의 제어 방법을 실행하기 위한 프로그램을 저장하는 비일시적인 컴 퓨터 판독 가능 매체에 있어서, 상기 전자 장치의 제어 방법은, 상기 전자 장치와 연결된 외부 단말로부터 사용 자를 포함하는 영상 데이터 및 부가 데이터를 획득하는 단계; 상기 영상 데이터 및 상기 부가 데이터를 이용하 여 상기 사용자의 실제 감정을 판단하기 위한 특징 데이터를 생성하는 단계; 상기 특징 데이터를 감정 인식 모 델에 입력하여 상기 사용자의 실제 감정을 판단하는 단계; 를 포함한다."}
{"patent_id": "10-2017-0162116", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "상술한 바와 같이 본 개시의 실시예에 따라, 주변 정보를 이용하여 사용자의 감정을 더욱 정확하게 판단할 수 있으며, 특징데이터를 통해 감정 원인을 추론할 수 있다."}
{"patent_id": "10-2017-0162116", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 명세서에서 사용되는 용어에 대해 간략히 설명하고, 본 발명에 대해 구체적으로 설명하기로 한다. 본 발명의 실시 예에서 사용되는 용어는 본 발명에서의 기능을 고려하면서 가능한 현재 널리 사용되는 일반적인 용어들을 선택하였으나, 이는 당 분야에 종사하는 기술자의 의도 또는 판례, 새로운 기술의 출현 등에 따라 달 라질 수 있다. 또한, 특정한 경우는 출원인이 임의로 선정한 용어도 있으며, 이 경우 해당되는 발명의 설명 부 분에서 상세히 그 의미를 기재할 것이다. 따라서 본 발명에서 사용되는 용어는 단순한 용어의 명칭이 아닌, 그 용어가 가지는 의미와 본 발명의 전반에 걸친 내용을 토대로 정의되어야 한다. 본 발명의 실시 예들은 다양한 변환을 가할 수 있고 여러 가지 실시 예를 가질 수 있는바, 특정 실시 예들을 도 면에 예시하고 상세한 설명에 상세하게 설명하고자 한다. 그러나 이는 특정한 실시 형태에 대해 범위를 한정하 려는 것이 아니며, 발명된 사상 및 기술 범위에 포함되는 모든 변환, 균등물 내지 대체물을 포함하는 것으로 이 해되어야 한다. 실시 예들을 설명함에 있어서 관련된 공지 기술에 대한 구체적인 설명이 요지를 흐릴 수 있다고 판단되는 경우 그 상세한 설명을 생략한다. 제1, 제2 등의 용어는 다양한 구성요소들을 설명하는데 사용될 수 있지만, 구성요소들은 용어들에 의해 한정되 어서는 안 된다. 용어들은 하나의 구성요소를 다른 구성요소로부터 구별하는 목적으로만 사용된다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 출원에서, \"포함하다\" 또 는 \"구성되다\" 등의 용어는 명세서 상에 기재된 특징, 숫자, 단계, 동작, 구성요소, 부품 또는 이들을 조합한 것이 존재함을 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성요소, 부품 또 는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되어야 한다. 본 발명의 실시 예에서 '모듈' 혹은 '부'는 적어도 하나의 기능이나 동작을 수행하며, 하드웨어 또는 소프트웨 어로 구현되거나 하드웨어와 소프트웨어의 결합으로 구현될 수 있다. 또한, 복수의 '모듈' 혹은 복수의 '부'는 특정한 하드웨어로 구현될 필요가 있는 '모듈' 혹은 '부'를 제외하고는 적어도 하나의 모듈로 일체화되어 적어 도 하나의 프로세서로 구현될 수 있다. 본 발명의 실시 예에서, 어떤 부분이 다른 부분과 \"연결\"되어 있다고 할 때, 이는 \"직접적으로 연결\"되어 있는 경우뿐 아니라, 그 중간에 다른 소자를 사이에 두고 \"전기적으로 연결\"되어 있는 경우도 포함한다. 또한, 물리 적인 연결뿐만 아니라 무선 연결되어 있는 경우도 포함한다. 또한 어떤 부분이 어떤 구성요소를 \"포함\"한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다른 구성요소를 제외하는 것이 아니라 다른 구성요소를 더 포함 할 수 있는 것을 의미한다. 아래에서는 첨부한 도면을 참고하여 본 개시의 실시 예에 대하여 본 개시가 속하는 기술 분야에서 통상의 지식 을 가진 자가 용이하게 실시할 수 있도록 상세히 설명한다. 그러나 본 개시는 여러 가지 상이한 형태로 구현될 수 있으며 여기에서 설명하는 실시 예에 한정되지 않는다. 그리고 도면에서 본 개시를 명확하게 설명하기 위해 서 설명과 관계없는 부분은 생략하였으며, 명세서 전체를 통하여 유사한 부분에 대해서는 유사한 도면 부호를 붙였다. 한편, 본 개시에서, 사용자라는 용어는 전자 장치를 사용하는 사람 또는 전자 장치를 사용하는 장치(예: 인공지 능 전자 장치)를 지칭할 수 있다. 도 1a 및 도 1b는 본 개시의 일 실시예에 따른 전자 장치의 구성을 설명하기 위한 도면이다. 전자 장치는 도 1에 도시된 바와 같이, 서버로 구현되어 외부 단말(200-1 내지 200-3)과 연동하여 사용자 의 감정 분석 서비스를 제공할 수 있다. 도 1b에 도시된 바와 같이, 전자 장치는 통신부, 메모리 및 프로세서를 포함한다. 통신부는 다양한 외부 단말로부터 사용자의 감정을 분석하기 위한 데이터를 수신한다. 구체적으로, 통신부 는 외부 사용자 단말(200-1), 외부 서버(200-2) 또는 외부 촬영 장치(200-3)등과 같은 다양한 외부 단말로부터 사용자 감정을 분석하기 위한 데이터를 수신할 수 있다. 이때, 외부로부터 수신된 데이터는 영상 데이터 및 부가데이터를 포함할 수 있다. 구체적으로, 영상데이터는 외 부 촬영 장치(200-3)로부터 수신한 사진 및 동영상 데이터일 수 있다. 이때, 영상 데이터가 동영상 데이터인 경 우, 영상 데이터는 동영상 데이터에 포함된 소리 데이터를 포함할 수 있다. 부가데이터는 영상 데이터와 관련된 데이터를 의미한다. 예를 들어, 부가데이터는 영상데이터에 포함된 사람들 의 대화 내용, 영상 데이터에 포함된 GPS 정보, 방위 정보, 해시태그 정보, 사용자에 대한 기 입력된 정보, 전 자 장치로부터 판단된 사용자의 과거 감정 정보, 영상을 크롤링하여 획득한 정보 등 다양한 형태로 구성될 수 있다. 다만, 부가 데이터는 상술한 예에 한정되는 것은 아니며 사용자 감정 판단을 위해 필요하다고 판단되 는 다양한 데이터를 포함할 수 있음은 물론이다. 메모리는 전자 장치를 구동시키기 위한 다양한 O/S(Operating System)가 저장될 수 있으며, 전자 장 치가 동작하기 위한 각종 소프트웨어 프로그램이나 어플리케이션이 저장될 수 있다. 메모리는 특징 데이터를 저장할 수 있다. 이때, 특징 데이터란 영상 데이터 및 부가 데이터를 이용하여 생 성된 데이터를 의미한다. 이에 대한 자세한 설명은 후술한다. 또는 필요에 따라 메모리는 영상 데이터 및 부가 데이터를 저장할 수 있다. 한편, 메모리는 사용자의 감정 판단 및 감정 원인 분석을 수행하기 위한 복수의 소프트웨어 모듈을 포함할 수 있다. 구체적으로, 메모리는 도 2에 도시된 바와 같이, 데이터 입력 모듈, 특징 데이터 판단 모듈 , 감정 판단 모듈, 특징 데이터 저장 모듈 및 감정 원인 추론 모듈을 포함할 수 있다. 데이터 입력 모듈은 외부 단말로부터 다양한 형태의 데이터를 획득할 수 있다. 특징 데이터 판단 모듈은 입력 데이터를 분석하여 특징 데이터를 판단할 수 있다. 구체적으로, 특징 데이 터 판단 모듈은 감정 인식 모델를 이용하여 특징 데이터를 판단할 수 있다. 감정 판단 모듈는 특징 데이터로부터 사용자의 실제 감정을 판단할 수 있다. 도 2에 도시 되지는 않았으나, 사용자의 실제 감정은 특징 데이터를 감정 인식 모델에 적용하여 획득할 수도 있음은 물론이다. 특징 데이터 저장 모듈은 생성된 특징 데이터를 저장할 수 있다. 감정 추론 모듈은 사용자의 감정 발생 원인을 판단할 수 있다. 예를 들어, 감정 추론 모듈은 특징 데 이터를 감정 추론 모델에 적용하여 감정이 발생한 원인을 파악할 수 있다. 프로세서는 전자 장치의 상술한 구성들을 제어 할 수 있다. 예를 들어, 프로세서는 메모리(12 0)에 저장된 복수의 소프트웨어 모듈을 이용하여 사용자의 실제 감정을 판단하거나, 사용자의 감정 원인을 판단 할 수 있다. 구체적으로, 프로세서는 영상 데이터 및 부가 데이터를 이용하여 사용자의 감정을 판단하기 위한 특징 데 이터를 생성할 수 있다. 그리고, 프로세서는 감정 판단 모듈을 제어하여 생성된 특징 데이터를 감정 인식 모델에 입력하여 사용자의 실제 감정을 판단할 수 있다. 프로세서는 특징 데이터 판단 모듈을 제어하여 영상 데이터 및 부가 데이터를 이용하여 제1 특징 데 이터 및 제2 특징 데이터를 포함하는 특징 데이터를 생성할 수 있다. 이때 제1 특징 데이터는 감정을 판단하고 자 하는 사용자에 관련된 데이터일 수 있다. 예를 들어, 프로세서는 특징 데이터 판단 모듈을 제어하 여 영상 데이터에서 사용자의 표정을 검출하고, 검출된 사용자의 표정에 해당하는 감정을 제1 특징 데이터로 결 정할 수 있다. 이때 검출된 사용자의 감정(제1 특징 데이터)은 사용자가 느끼는 실제 감정과 다를 수 있다. 예 를 들어 실제 사용자의 감정은 \"행복\"이나 제1 특징 데이터에 대응되는 감정은\"화남\" 일 수 있다. 한편, 제2 특징 데이터는, 제1 특징 데이터를 제외한 특징 데이터일 수 있다. 예를 들어, 제2 특징 데이터는 영 상에 포함된 사용자 주변 인물들의 얼굴 표정으로부터 결정된 감정 정보일 수 있다. 또는, 영상에 포함된 대화 내용으로부터 결정된 대화자 및 대화 상대방의 감정에 관한 것일 수 있다. 또는, 영상을 촬영한 장소 및 해당 장소에서 통계적으로 사람들이 느끼는 감정에 대한 것일 수 있다. 상술한 바와 같이 특징 데이터는 입력된 영상 데이터 및 부가 데이터 중 사용자 또는 주변 인물들의 감정과 관 련된 데이터일 수 있다. 그러나 이에 한정되는 것은 아니고, 감정 이외의 다양한 정보를 포함할 수도 있음은 물 론이다. 예를 들어, 특징 데이터는, 사용자 주변의 다양한 오브젝트, 상황, 날씨 및 시간 정보 등 다양한 정보를 포함할 수도 있음은 물론이다. 이때, 특징 데이터는 영상 데이터 및 부가 데이터와 비교할 때 더 적은 용량을 가질 수 있다. 즉, 다양한 입력 데이터 중 사용자의 감정을 판단하는데 필요한 데이터만을 특징 데이터로 생성함으로써, 프로세서는 메모 리에 할당된 저장 공간을 사용할 수 있다. 한편, 프로세서는 제1 특징 데이터 및 제2 특징 데이터를 감정 인식 모델에 입력하여 사용자의 실제 감정 을 판단할 수 있다. 예를 들어, 프로세서는 제1 특징 데이터를 감정 인식 모델이 입력하여 제1 특징 데이 터에 대한 사용자의 감정을 판단할 수 있다. 이때 판단된 감정은 사용자의 실제 감정과 다를 수 있다. 또한 프 로세서는 제2 특징 데이터를 감정 인식 모델에 입력하여 주변 인물에 대한 감정 및 기타 주변 정보를 판단 할 수 있다. 프로세서는 판단된 제1 특징 데이터에 대한 사용자의 감정 정보 및, 제2 특징 데이터에 대한 주변 정보를 바탕으로 사용자의 실제 감정을 판단할 수 있다. 다만, 상술한 실시예에 한정되는 것은 아니며, 제1 특징 데이터 및 제2 특징 데이터를 감정 인식 모델에 동시에 적용하여 사용자의 실제 감정을 판단할 수 있음은 물론이다. 이때, 사용자의 실제 감정을 판단할 때, 프로세서는 사용자의 과거 감정에 대한 가중치를 계산하고, 계산 된 가중치를 이용하여 사용자의 현재 감정을 판단할 수 있다. 이에 대한 설명은 후술한다. 또한, 프로세서는 특징 데이터를 특정 카테고리별로 분류하여 메모리에 저장할 수 있다. 예를 들어 프로세서는 특징 데이터를 시간의 흐름에 따라 분류하여 메모리에 저장할 수 있다. 또 다른 예로 프 로세서는 특징 데이터를 장소별로 분류하여 메모리에 저장할 수 있다. 상술한 예에서는 시간 및 장소 별로 특징 데이터를 분류하는 예에 대하여 설명하였으나, 다양한 카테고리별로 특징 데이터를 분류할 수 있음은 물론이다. 한편, 외부 단말로부터 사용자 요청을 수신한 경우, 프로세서는 특징 데이터를 감정 추론 모델에 입력하여 사용자의 감정 발생 원인을 판단하여 외부 단말에 제공할 수 있다. 예를 들어, 사용자의 실제 감정이 \"화남\" 인 경우, 프로세서는 사용자가 화가 난 원인을 특징 데이터로부터 분석하여 사용자에게 제공할 수 있다. 또한, 프로세서는 사용자의 실제 감정 및 감정 발생 원인을 시간, 장소, 인물 또는 사건별로 판단할 수 있다. 사용자의 요청이 있는 경우, 프로세서는 사용자에게 감정 및 원인 정보를 제공할 수 있다. 예를 들 어 사용자가 시간별로 정리된 감정 및 감정 원인을 요청한 경우, 프로세서는 시간에 따른 감정 및 감정 발 생 원인 정보를 사용자에게 제공할 수 있다. 따라서 사용자는 시간별로 사용자의 감정 상태 및 감정 발생원인을 파악할 수 있다. 또는, 사용자가 장소별로 정리된 감정 및 감정 원인을 요청한 경우, 프로세서는 장소에 따른 감정 및 감정 발생 원인 정보를 사용자에게 제공할 수 있다. 또는, 사용자가 인물별로 정리된 감정 및 감정 원인을 요청한 경우, 프로세서는 특정 인물에 따른 감정 및 감정 발생 원인 정보를 사용자에게 제공할 수 있다. 구체적으로, 프로세서는 특정 인물과 함께 있는 경우, 사용자의 감정 및 감정 발생 원인 정보를 사용자에게 제공할 수 있다. 또는, 사용자가 사건별로 정리된 감정 및 감정 원인을 요청한 경우, 프로세서는 특정 사건에 대한 감정 및 감정 발생 원인 정보를 사용자에게 제공할 수 있다. 구체적으로, 프로세서는 특정 사건이 발생한 경우, 사 용자의 감정 및 감정 발생 원인 정보를 사용자에게 제공할 수 있다. 또한 본 개시에 따른 다양한 실시예에 의할 때. 전자 장치는 입력된 영상 데이터 및 부가 데이터로부터 특 징 데이터를 획득하고, 획득된 특징 데이터를 분석하여 감정 데이터를 결정할 수 있다. 본 개시에서 학습된 인 식 모델은 인식 모델의 적용 분야 또는 장치의 컴퓨터 성능 등을 고려하여 구축될 수 있다. 학습된 객체 인식 모델은, 예로, 신경망(Neural Network)을 기반으로 하는 모델일 수 있다. 객체 인식 모델은 인간의 뇌 구조를 컴퓨터 상에서 모의하도록 설계될 수 있으며 인간의 신경망의 뉴런(neuron)을 모의하는, 가중치를 가지는 복수 의 네트워크 노드들을 포함할 수 있다. 복수의 네트워크 노드들은 뉴런이 시냅스(synapse)를 통하여 신호를 주 고 받는 뉴런의 시냅틱(synaptic) 활동을 모의하도록 각각 연결 관계를 형성할 수 있다. 또한 객체 인식 모델은, 일 예로, 신경망 모델, 또는 신경망 모델에서 발전한 딥 러닝 모델을 포함할 수 있다. 딥 러닝 모델에 서 복수의 네트워크 노드들은 서로 다른 깊이(또는, 레이어)에 위치하면서 컨볼루션(convolution) 연결 관계에 따라 데이터를 주고 받을 수 있다. 객체 인식 모델의 예에는 DNN(Deep Neural Network), RNN(Recurrent Neural Network), BRDNN(Bidirectional Recurrent Deep Neural Network) 등이 있을 수 있으나 이에 한정되지 않는다.상술한 객체 인식 모델의 구체적인 적용예는 후술한다. 또한, 전자 장치는 상술한 바와 같은 동작을 수행하기 위하여 인공지능 에이전트(Artificial intelligence agent)를 이용할 수 있다. 이때, 인공지능 에이전트는 AI(Artificial Intelligence) 기반의 서비스(예를 들어, 음성 인식 서비스, 비서 서비스, 번역 서비스, 검색 서비스 등)를 제공하기 위한 전용 프로그램으로서, 기존의 범용 프로세서(예를 들어, CPU) 또는 별도의 AI 전용 프로세서(예를 들어, GPU 등)에 의해 실행될 수 있다. 도 4a 내지 도 6은 본 개시의 다양한 실시예들을 설명하기 위한 도면이다. 도 4a 및 도 4b는 주변 정보를 이용하여 사용자의 감정을 분석하는 방법을 설명하는 도면이다. 구체적으로, 도 4a 및 도 4b는 축구 경기 우승팀의 축구선수들을 촬영한 사진 데이터를 이용하여 사용자의 감정을 판단하 는 과정을 설명하는 도면이다. 프로세서는 특징 데이터 판단 모듈를 제어하여 사진 데이터로부터 특징 데이터를 생성할 수 있다. 예 를 들어, 프로세서는 특징 데이터 판단 모듈를 제어하여 이미지 분석을 통해 사용자의 감정을 판단할 수 있다. 이때, 프로세서는 특징 데이터 판단 모듈를 제어하여 감정을 판단하고자 하는 사용자 및 주변 인물(421,431)의 얼굴 표정을 분석하여 감정을 판단할 수 있다. 구체적으로, 도 4a에 도시된 바와 같이, 프로세서는 특징 데이터 판단 모듈를 제어하여 사용자 의 얼굴 표정을 분석하여 감정 테이블을 생성할 수 있다. 이때, 사용자의 감정은 \"화남\"이다. 또한, 주변 인물(421,431) 및 주변 인물들의 감정 테이블(422,432)를 살펴보면 주변인물의 감정 상태는 \"행복\"이다. 이때, 사용자 및 주변 인물(411,421,431)의 감정 상태가 특징 데이터이며, 특징 데이터는 특징 데이터 저장 모 듈에 저장될 수 있다. 구체적으로, 사용자의 \"화남\"에 대한 데이터는 제1 특징 데이터, 주변인물 (421,431)의 \"행복\"에 대한 데이터는 제2 특징 데이터가 될 수 있다. 프로세서는 감정 판단 모듈을 제어하여 획득한 특징 데이터를 분석하고, 사용자의 실제 감정을 판단할 수 있다. 구체적으로, 프로세서는 감정 판단 모듈을 제어하여 특징 데이터를 감정 인식 모델 에 입력하여 사용자의 감정을 판단할 수 있다. 이때 프로세서는 감정 판단 모듈을 제어하 여 주변 인물(421,422)에 관한 특징 데이터를 이용하여 사용자가 행복한 상태임을 판단할 수 있다. 구체적 으로, 프로세서는 감정 판단 모듈을 제어하여 도 4b에 도시된 바와 같이 주변 정보를 포함하여 사용 자의 감정이 \"행복\"임을 판단할 수 있다. 상술한 실시예에서는 사용자 및 주변 인물(411,421,431)의 얼굴 표정만을 이용하여 사용자의 감정을 분석 하는 방법에 대하여 설명하였으나, 이에 한정되는 것은 아니다. 예를 들어, 제1 특징 데이터 및 제2 특징 데이 터는 얼굴 표정뿐만 아니라, 시선 방향, 행동, 주변 상황, 주변 소음, 장소, 대화 내용등 다양한 데이터로부터 판단될 수 있다. 도 5a 및 도 5b는 본 개시의 일 실시예에 따른 감정 원인 분석을 설명하기 위한 도면이다. 구체적으로, 도 5a는 전자 장치에 의해 판단된 사용자의 감정을 나타낸 도면이다. 구체적으로, 사용자 의 감정 테이블를 살펴보면, 사용자는 \"슬픔\" 상태인 것을 알 수 있다. 또한, 사용자의 감 정 테이블를 살펴보면 사용자는 \"행복\" 상태임을 알 수 있다. 이때, 사용자의 요청이 있는 경우, 전자 장치는 사용자(511,521)의 감정 원인을 분석할 수 있다. 구체적으 로, 프로세서는 감정 추론 모듈을 제어하여 감정 원인을 판단할 수 있다. 구체적으로, 특징 데이터 저장 모듈에 저장된 특징 데이터를 감정 원인 추론 모델에 입력하여 사용자의 감정 원인을 추론할 수 있다. 예를 들어, 프로세서는 특정 감정과 관련된 특징 데이터를 분석하여 감정 원인을 추론할 수 있다. 즉, 프로세서는 특징 데이터 저장 모듈에 저장된 작은 크기의 데이터만을 이용하여 감정 원인을 판단 할 수 있다. 구체적으로, 도 5b에 도시된 바와 같이, 프로세서는 사용자가 슬픈 원인에 대응하여 사용자의 친구가 사용자를 괴롭히는 이미지를 제공하고, 사용자 기쁜 이유에 대응하여 사용자가 선물을 받 은 이미지를 제공할 수 있다. 한편 상술한 바와 같이, 프로세서는 사용자의 요청이 있는 경우, 사용자의 감정 및 감정 발생 원인을 특정 카테고리별로 분류하여 사용자에게 제공할 수 있다. 이때, 특정 카테고리란 시간 장소, 인물 또는 사건에 대한 것일 수 있으며, 그 외 다양한 카테고리일 수 있다. 예를 들어, 카테고리는 사용자가 특정 인물과 함께 있는 경 우, 사용자가 특정 방송을 시청하는 경우, 특정 사이트에 접속하는 경우 등 다양할 수 있다. 그러나 상술한 실 시예에 한정되는 것은 아니며 다양한 종류의 카테고리별로 사용자의 감정 및 감정 발생 원인을 분류할 수 있다. 한편, 사용자가 시간에 따른 감정 및 감정 원인에 대한 정보를 요청하는 경우, 프로세서는 시간별 사용자 의 감정 및 감정 발생 원인을 제공할 수 있다."}
{"patent_id": "10-2017-0162116", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "이때, 프로세서는 가장 특징적인 감정들을 요약하여 사용자에게 제공할 수 있다. 예를 들어, 하루 중, 사 용자가 가장 화난 경우, 가장 흥분한 경우, 가장 행복한 경우, 가장 슬픈 경우 등을 특정하여 사용자에게 제공 할 수 있다. 그러나 상술한 실시예에 한정되는 것은 아니며, 다양한 방법에 의해 사용자의 감정 및 감정 원인이 제공될 수 있다. 이때, 사용자에게 제공되는 정보는 영상 데이터의 형태일 수 있다. 그러나 영상 데이터에 한정되는 것은 아니며, 음성 데이터 또는 텍스트 데이터로 제공될 수도 있으며, 상술한 다양한 데이터가 함께 제공될 수 있음 은 물론이다. 예를 들어, 사용자가 감정 및 감정 원인 정보를 요청한 경우, 프로세서는 도 5b와 같은 영상 데이터를 제 공할 수 있다. 또는 프로세서는, \"제니는 오늘 전체적으로 재미있는 유치원 생활을 했지만, 블록 쌓기 시 간에 친구와의 다툼으로 잠시 울었다. 하지만 결국엔 블록 쌓기 1등을 하여 선생님께 상을 받았고, 그때 최고로 즐거워하였다.\"와 같은 텍스트 또는 음성을 사용자에게 제공할 수도 있다. 한편, 상술한 실시예에서는 하나의 카테고리로 사용자의 감정을 분류하였으나 이에 한정되는 것은 아니다. 즉, 전자 장치는 복수의 카테고리를 함께 고려하여 사용자의 감정을 분류할 수 있다. 예를 들어, 선택된 카테 고리가 시간 및 장소인 경우, 전자 장치는 특정 장소에서의 사용자의 감정을 시간에 따라 분류할 수 있다. 도 6은 본 개시의 또다른 실시예에 따른 사용자의 실제 감정 및 감정 원인을 판단하는 과정을 설명하는 도면이 다. 구체적으로, 도 6은 동일한 장소에서 시간에 따른 사용자의 감정을 판단하는 방법을 설명하는 도면이다. 프로세서는 특징 데이터 판단 모듈 및 감정 판단 모듈을 제어하여 사용자의 감정을 판단할 수 있다. 예를 들어, 프로세서는 특징 데이터 판단 모듈를 제어하여 특징 데이터를 생성할 수 있다. 이 때 특징 데이터는 사용자의 얼굴 표정, 사용자가 위치한 장소, 영상이 촬영된 시간에 관한 데이터일 수 있다. 프로세서는 감정 판단 모듈을 제어하여 감정 테이블을 생성할 수 있으며, 14시 15분의 사용자의 감정이 \"중립\" 임을 판단할 수 있다. 또한, 프로세서는 15시 15분의 사용자의 감정을 판단할 수 있다. 예를 들어, 프로세서는 특징 데이터 판단 모듈를 제어하여 특징 데이터를 생성할 수 있다. 이때 특징 데이터는 사용자의 얼굴 표 정, 사용자가 위치한 장소, 영상이 촬영된 시간에 관한 데이터일 수 있으며, 추가적으로, 해당 장소에서 판단된 사용자의 과거 감정을 포함할 수 있다. 프로세서는 감정 판단 모듈을 제어하여 감정 테이블을 생성할 수 있으며, 15시 15분의 사용자 의 감정이 \"행복\" 임을 판단할 수 있다. 한편, 도 5a 및 도 5b와 같이, 프로세서는 사용자의 요청이 있는 경우, 사용자의 감정 및 감정 발생 원인 을 특정 카테고리별로 분류하여 사용자에게 제공할 수 있다. 상술한 바와 같이, 프로세서는 사용자의 요청에 대응하여 영상 데이터를 제공할 수 있으며, 텍스트 또는 음성 메시지를 제공할 수도 있다. 예를 들어, 사용자가 감정 및 감정 원인 정보를 요청한 경우, 프로세서는 도 6과 같은 영상 데이터를 제공 할 수 있다. 또는, 프로세서는 \"존은 오늘 낮 14시 15분에 에 공원 벤치에 앉아 여자친구를 기다렸다. 이 때 존의 감정은 \"중립\" 이었으나, 15시 15분 여자친구를 만나 행복해졌다.\" 와 같은 텍스트 또는 음성을 사용자 에게 제공할 수도 있다.도 7은 본 개시의 일 실시예에 따른 전자 장치의 제어 방법을 설명하기 위한 흐름도이다. 먼저, 전자 장치는 외부 단말(200-1 내지 200-3)으로부터 영상 데이터 및 부가 데이터를 수신하여 획득할 수 있다(S710). 전자 장치는 획득된 데이터를 이용하여 특징 데이터를 생성할 수 있다. 구체적으로, 프로세서는 특징 데이터 판단 모듈을 제어하여 특징 데이터를 생성할 수 있다. 전자 장치는 생성된 특징 데이터를 감정 인식 모델에 입력하여 사용자의 실제 감정을 판단할 수 있다. 도 8는 본 개시의 일 실시예에 따른 사용자 감정 판단 및 감정 원인 분석을 추론하기 위한 시스템의 제어 방법 을 설명하기 위한 시퀀스도이다. 상술한 바와 같이, 도1 내지 도 7에서 설명한 전자 장치는 서버로 구현될 수 있다. 이때, 사용자 단말은 범용 프로세서를 포함하고, 서버는 인공지능 전용 프로세서를 포함할 수 있다. 또는, 사용자 단말은 적어도 하나의 어플리케이션을 포함할 수 있고, 서버는 운영 체제(operating system)를 포함할 수 있다. 서버는 사용자 단말보다 더 집적화되거나, 전용화되거나, 딜레이(delay) 가 작거나, 성능이 우수하거나 또는 많은 리소스를 가진 구성 요소로서 인식 모델의 생성, 갱신 또는 적용 시에 요구되는 많은 연산을 사용자 단말보다 신속하고 효과적으로 처리 가능한 구성 요소가 될 수 있다. 이 경우, 사용자 단말 및 서버 간에 데이터를 송/수신하기 위한 인터페이스가 정의될 수 있다. 예로, 인식 모델에 적용할 학습 데이터를 인자 값(또는, 매개 값 또는 전달 값)으로 갖는 API(application program interface)가 정의될 수 있다. API는 어느 하나의 프로토콜(예로, 사용자 단말에서 정의된 프로토 콜)에서 다른 프로토콜(예로, 서버에서 정의된 프로토콜)의 어떤 처리를 위해 호출할 수 있는 서브 루틴 또는 함수의 집합으로 정의될 수 있다. 즉, API를 통하여 어느 하나의 프로토콜에서 다른 프로토콜의 동작이 수 행될 수 있는 환경을 제공될 수 있다. 사용자 단말은 데이터를 획득한다(S810). 이때, 데이터는 상술한 바와 같이 영상 데이터 및 부가데이터를 포함할 수 있다. 사용자 단말은 감정 분석을 위해 획득한 데이터를 서버로 전송할 수 있다(S820). 이때, 서버는 사용자 단말로부터 수신한 데이터를 이용하여 특징 데이터를 획득할 수 있다(S830). 생 성된 특징 데이터는 서버에 저장될 수 있으며, 사용자 단말의 메모리에 저장될 수도 있다. 서버는 특징 데이터를 감정 판단 모델에 입력하여 사용자의 실제 감정을 판단할 수 있다(S840). 서버는 판단된 사용자 감정을 사용자 단말로 전송할 수 있다(S850). 이때, 사용자 단말이 감정 원인 분석을 요청한 경우(S860), 서버는 감정 원인을 추론할 수 있다(S870). 구체적으로, 서버는 특 징 데이터를 감정 원인 추론 모델에 입력하여 감정 원인을 판단할 수 있다. 도 9는 본 개시의 또 다른 실시예에 따른, 감정 판단 및 감정 원인 분석을 수행하는 사용자 단말을 설명하는 도 면이다. 상술한 실시예에서는 전자 장치가 서버로 구현되어 사용자의 실제 감정을 판단하고, 감정 원인을 분석하였 으나 이러한 실시예에 한정되는 것은 아니다. 구체적으로, 도 9에 도시된 바와 같이 전자 장치는 사용자 단말로 구성될 수 있다. 예를 들어, 사용자 단말은 스마트 폰, 타블렛 PC, 노트북 PC, 데스크탑 PC, 스마트 워치와 같은 웨어러블 장치, 전자 액자, 인간형 로봇, 오디오 장치, 스마트 TV 등과 같은 다양한 전자 장치로 구성되어 단독으로 사용자의 감정을 분석할 수도 있다. 구체적으로, 도 9에 도시된 바와 같이, 사용자 단말은 센서, 메모리, 디스플레이, 통신부 촬영부 및 프로세서을 포함할 수 있다. 센서는 다양한 형태의 데이터를 감지할 수 있다. 예를 들어, 센서는 자이로 센서, GPS 센서, 가속도 센서, 조도 센서, 습도 센서 등을 포함할 수 있다. 상술한 다양한 센서들은 다양한 데이터를 감지할 수 있다. 메모리는 센서로부터 감지한 데이터들을 저장할 수 있다. 또한, 메모리는 서버로부터 특징 데이터를 수신하여 저장할 수도 있다. 디스플레이은, 사용자 단말에 제공되는 다양한 컨텐츠를 표시할 수 있다. 이때, 디스플레이는 액정 표시 장치(Liquid Crystal Display, LCD), 유기 전기 발광 다이오드(Organic Light Emitting Display, OLED) 또는 플라즈마 표시 패널(Plasma Display Panel, PDP) 등으로 구현되어, 사용자 단말을 통해 제공 가능한 다양한 화면을 표시할 수 있다. 통신부는 와이파이 칩, 블루투스 칩, 무선 통신 칩, NFC칩중 적어도 하나를 포함할 수 있다. 와이파이 칩이나 블루투스 칩을 이용하는 경우에는 SSID 및 세션 키 등과 같은 각종 연결 정보를 먼저 송수신하여, 이를 이용하여 통신 연결한 후 각종 정보들을 송수신할 수 있다. 무선 통신 칩은 IEEE, Zigbee, 3G(3rd Generation), 3GPP(3rd Generation Partnership Project), LTE(Long Term Evolution) 등과 같은 다양한 통신 규격에 따라 통신을 수행하는 칩을 의미한다. NFC 칩은 135kHz, 13.56MHz, 433MHz, 860~960MHz, 2.45GHz 등과 같은 다양한 RF-ID 주파수 대역들 중에서 13.56MHz 대역을 사용하는 NFC(Near Field Communication) 방식으로 동작하는 칩을 의미한다. 통신부는 상술한 바와 같이 서버와의 통신을 수행할 수 있다. 구체적으로, 사용자 단말은 통신 부를 통해 다양한 데이터를 서버로 전송할 수 있으며, 서버로부터 다양한 결과를 수신할 수 있다. 촬영부는 영상 데이터를 촬영할 수 있다. 촬영된 영상 데이터는 센서로부터 감지된 다양한 데이터들 과 함께 사용자의 감정을 분석하기 위해 서버로 전송될 수 있다. 프로세서는 전자 장치의 전반적인 동작을 제어한다. 상술한 바와 같이, 프로세서는 획득된 데이터를 이용하여 사용자의 감정을 판단하거나 감정 원인을 분석할 수도 있으며, 서버의 요청이 있는 경우, 다양한 형태의 데이터를 전송하도록 통신부를 제어할 수 있다. 한편, 도 1 내지 도 9에서 상술한 다양한 실시예에서는, 영상 데이터를 분석하여 사용자의 감정을 분석하는 방 법에 대하여 설명하였으나, 이에 한정되는 것은 아니다. 즉, 영상 데이터가 아닌 오디오 데이터를 이용하여 사 용자 감정을 분석할 수도 있다. 예를 들어, 사용자의 통화 내용에 대한 오디오 데이터 및 통화 상대방, 통화 내 용 등을 분석하여 사용자의 감정을 분석할 수 있다. 또는, 사용자가 작성하거나 공유한 다양한 컨텐츠(예를 들 어, SNS에 작성하거나 공유한 글, 공유한 영상 및 해당 영상에 태그된 다른 사용자들)를 분석하여 사용자 감정 을 판단할 수도 있다. 이와 같이 본 개시는 영상뿐만 아니라 다양한 컨텐츠들을 분석하여 사용자 감정을 판단할 수 있다. 도 10은 본 개시의 일부 실시 예에 따른 프로세서의 블록도이다. 도 10을 참조하면, 일부 실시 예에 따른 프로 세서는 데이터 학습부 및 감정 판단부를 포함할 수 있다. 데이터 학습부는 사용자 감정 판단을 위한 기준을 학습할 수 있다. 프로세서는 학습된 기준에 따라 입력된 데이터을 분석하여 사용자의 실제 감정을 판단할 수 있다. 데이터 학습부는 사용자의 실제 감정을 판단하기 위하여 어떠한 데이터(또는 특징 데이터)를 이용할 것인지 결정할 수 있다. 또한, 데이터 학습부(13 1)는 학습에 이용될 데이터를 획득하고, 획득된 데이터를 후술할 감정 인식 모델 및 감정 추론 모델에 적용함으 로써 사용자의 실제 감정 또는 감정 발생 원인 판단을 위한 기준을 학습할 수 있다. 감정 판단부는 기학습된 감정 인식 모델 및 감정 추론 모델을 이용하여, 소정의 데이터로부터 사용자의 실 제 감정 또는 감정 발생 원인을 판단할 수 있다. 감정 판단부는 학습에 의한 기설정된 기준에 따라 소정의 데이터(예를 들어, 특징 데이터)를 획득하고, 획득된 데이터를 입력값으로 하여 감정 판단 모델을 이용할 수 있 다. 또한, 감정 판단부는 입력된 데이터를 감정 판단 모델에 적용하여 사용자의 실제 감정을 판단할 수 있 다. 데이터 학습부의 적어도 일부 및 감정 판단부의 적어도 일부는, 소프트웨어 모듈로 구현되거나 적어 도 하나의 하드웨어 칩 형태로 제작되어 전자 장치에 탑재될 수 있다. 예를 들어, 데이터 학습부 및 데이 터 인식부 중 적어도 하나는 인공 지능(AI; artificial intelligence)을 위한 전용 하드웨어 칩 형태로 제작될 수도 있고, 또는 기존의 범용 프로세서(예: CPU 또는 application processor) 또는 그래픽 전용 프로세 서(예: GPU)의 일부로 제작되어 전술한 각종 전자 장치에 탑재될 수도 있다. 이 때, 인공 지능을 위한 전용 하 드웨어 칩은 확률 연산에 특화된 전용 프로세서로서, 기존의 범용 프로세서보다 병렬처리 성능이 높아 기계 학습과 같은 인공 지능 분야의 연산 작업을 빠르게 처리할 수 있다. 데이터 학습부 및 데이터 인식부가 소프트웨어 모듈(또는, 인스트럭션(instruction) 포함하는 프로그램 모듈)로 구현되는 경우, 소프트웨어 모듈은 컴퓨터로 읽을 수 있는 판독 가능한 비일시적 판독 가능 기록매체(non-transitory computer readable media)에 저장될 수 있다. 이 경우, 소프트웨어 모듈은 OS(Operating System)에 의해 제공되거나, 소정의 애플리케이션에 의해 제공될 수 있다. 또는, 소프트웨어 모듈 중 일부는 OS(Operating System)에 의해 제공되고, 나머지 일부는 소정의 애플리케이션에 의해 제공될 수 있다. 데이터 인식 모델은, 인식 모델의 적용 분야, 학습의 목적 또는 장치의 컴퓨터 성능 등을 고려하여 구축될 수 있다. 데이터 인식 모델은, 예를 들어, 신경망(Neural Network)을 기반으로 하는 모델일 수 있다. 데이터 인 식 모델은 인간의 뇌 구조를 컴퓨터 상에서 모의하도록 설계될 수 있다. 데이터 인식 모델은 인간의 신경망의 뉴런(neuron)을 모의하는, 가중치를 가지는 복수의 네트워크 노드들을 포함할 수 있다. 복수의 네트워크 노드들 은 뉴런이 시냅스(synapse)를 통하여 신호를 주고 받는 시냅틱(synaptic) 활동을 모의하도록 각각 연결 관계를 형성할 수 있다. 데이터 인식 모델은, 일 예로, 신경망 모델, 또는 신경망 모델에서 발전한 딥 러닝 모델을 포 함할 수 있다. 딥 러닝 모델에서 복수의 네트워크 노드들은 서로 다른 깊이(또는, 레이어)에 위치하면서 컨볼루 션(convolution) 연결 관계에 따라 데이터를 주고 받을 수 있다. 예컨대, DNN(Deep Neural Network), RNN(Recurrent Neural Network), BRDNN(Bidirectional Recurrent Deep Neural Network)과 같은 모델이 데이터 인식 모델로서 사용될 수 있으나, 이에 한정되지 않는다. 도 10의 실시 예에서는 데이터 학습부 및 감정 판단부가 모두 전자 장치에 탑재된 경우를 도시 하였으나, 이들은 각각 별개의 장치에 탑재될 수도 있다. 예를 들어, 데이터 학습부 및 감정 판단부 중 하나는 서버에 포함되고, 나머지 하나는 사용자 단말에 포함될 수 있다. 또한 데이터 학습부 및 감정 판단부는 서로 유선 또는 무선으로 연결되어, 데이터 학습부가 구축한 감정 판단 모델에 대 한 정보가 감정 판단부로 제공될 수 있고, 감정 판단부로 입력된 데이터가 추가 학습 데이터로 데이 터 학습부로 제공될 수도 있다. 한편, 데이터 학습부 및 감정 판단부 중 적어도 하나는 소프트웨어 모듈로 구현될 수 있다. 데이터 학습부 및 감정 판단부 중 적어도 하나가 소프트웨어 모듈(또는, 인스트럭션을 포함하는 프로그램 모 듈)로 구현되는 경우, 소프트웨어 모듈은 비일시적 컴퓨터 판독 가능 기록매체에 저장될 수 있다. 적어도 하나 의 소프트웨어 모듈은 OS(Operating System)에 의해 제공되거나, 소정의 어플리케이션에 의해 제공될 수 있다. 또는 적어도 하나의 소프트웨어 모듈 중 일부는 OS에 의해 제공되고, 나머지 일부는 소정의 어플리케이션에 의 해 제공될 수도 있다. 도 11a는 본 개시의 일부 실시 예에 따른 데이터 학습부의 블록도이다. 도 11a를 참조하면, 일부 실시 예 에 따른 데이터 학습부는 데이터 획득부(131-1), 전처리부(131-2), 학습 데이터 선택부(131-3), 모델 학습 부(131-4) 및 모델 평가부(131-5)를 포함할 수 있다. 데이터 획득부(131-1)는 사용자의 실제 감정을 판단하기 위해 필요한 데이터를 획득할 수 있다. 특히, 데이터 획득부(131-1)는 영상 데이터, 부가 데이터 또는 영상 데이터 및 부가 데이터로부터 생성된 특징 데이터를 학습 데이터로 획득할 수 있다. 전처리부(131-2)는 사용자의 실제 감정 판단을 위한 학습에 획득된 데이터가 이용될 수 있도록, 획득된 데이터 를 전처리할 수 있다. 전처리부(131-2)는 후술할 모델 학습부(131-4)가 사용자의 실제 감정 판단을 위한 학습을 위하여 획득된 데이터를 이용할 수 있도록, 획득된 데이터를 기설정된 포맷으로 가공할 수 있다. 학습 데이터 선택부(131-3)는 전처리된 데이터 중에서 학습에 필요한 데이터를 선택할 수 있다. 선택된 데이터 는 모델 학습부(131-4)에 제공될 수 있다. 학습 데이터 선택부(131-3)는 사용자의 실제 감정 판단을 위한 기설 정된 기준에 따라, 전처리된 데이터 중에서 학습에 필요한 데이터를 선택할 수 있다. 또한, 학습 데이터 선택부 (131-3)는 후술할 모델 학습부(131-4)에 의한 학습에 의해 기설정된 기준에 따라 데이터를 선택할 수도 있다. 모델 학습부(131-4)는 학습 데이터에 기초하여 사용자의 실제 감정을 어떻게 판단할지에 관한 기준을 학습할 수 있다. 또한, 모델 학습부(131-4)는 사용자의 실제 감정 판단을 위하여 어떤 학습 데이터를 이용해야 하는지에 대한 기준을 학습할 수도 있다. 모델 학습부(131-4)는 사용자의 실제 감정 판단에 이용되는 감정 판단 모델을 학습 데이터를 이용하여 학습시킬 수 있다. 이 경우, 감정 판단 모델은 미리 구축된 모델일 수 있다. 예를 들어, 감정 판단 모델은 기본 학습 데이터을 입력 받아 미리 구축된 모델일 수 있다. 다른 예로, 감정 판단 모델은 빅데이터를 이용하여 미리 구축된 모델일 수 있다. 감정 판단 모델은, 인식 모델의 적용 분야, 학습의 목적 또는 장치의 컴퓨터 성능 등을 고려하여 구축될 수 있 다. 감정 판단 모델은, 예를 들어, 신경망(Neural Network)을 기반으로 하는 모델일 수 있다. 예컨대, DNN(Deep Neural Network), RNN(Recurrent Neural Network), BRDNN(Bidirectional Recurrent Deep Neural Network)과 같은 모델이 감정 판단 모델로서 사용될 수 있으나, 이에 한정되지 않는다. 구체적으로, 본 개시에 따른 감정 판단 모델은 도 3a에 도시된 바와 같이 DNN 모델을 이용할 수 있다. 그러나, 도 3b에 도시된 바와 같이 RNN 모델을 이용하여 사용자의 실제 감정을 판단할 수도 있다. 구체적으로, RNN 모델 에 의할 경우, 과거 데이터 과거 감정(311 내지313) 및 현재의 데이터 입력를 이용하여 현재의 감정 (t)를 획득할 수 있다. 또한 미래의 감정(t+1)을 판단하는 경우 데이터 입력과 현재의 데이터 입력을 이용할 수 있다. 다양한 실시 예에 따르면, 모델 학습부(131-4)는 미리 구축된 감정 판단 모델이 복수 개가 존재하는 경우, 입력 된 학습 데이터와 기본 학습 데이터의 관련성이 큰 감정 판단 모델을 학습할 감정 판단 모델로 결정할 수 있다. 이 경우, 기본 학습 데이터는 데이터의 타입별로 기분류되어 있을 수 있으며, 감정 판단 모델은 데이터의 타입 별로 미리 구축되어 있을 수 있다. 예를 들어, 기본 학습 데이터는 학습 데이터가 생성된 지역, 학습 데이터가 생성된 시간, 학습 데이터의 크기, 학습 데이터의 장르, 학습 데이터의 생성자, 학습 데이터 내의 오브젝트의 종류 등과 같은 다양한 기준으로 기분류되어 있을 수 있다. 또한, 모델 학습부(131-4)는, 예를 들어, 오류 역전파법(error back-propagation) 또는 경사 하강법(gradient descent)을 포함하는 학습 알고리즘 등을 이용하여 감정 판단 모델을 학습시킬 수 있다. 예를 들어, 모델 학습부(131-4)는 학습 데이터를 입력 값으로 하는 지도 학습(supervised learning) 을 통하여 감정 판단 모델을 학습시킬 수 있다. 다른 예로, 모델 학습부(131-4)는 별도의 지도 없이 감정 판단을 위해 필 요한 데이터의 종류를 스스로 학습함으로써 감정 판단을 위한 기준을 발견하는 비지도 학습(unsupervised learning)을 통하여, 감정 판단 모델을 학습시킬 수 있다. 또 다른 예로, 모델 학습부(131-4)는 학습에 따른 감 정 판단의 결과가 올바른지에 대한 피드백을 이용하는 강화 학습(reinforcement learning)을 통하여, 감정 판단 모델을 학습시킬 수 있다. 또한, 감정 판단 모델이 학습되면, 모델 학습부(131-4)는 학습된 감정 판단 모델을 저장할 수 있다. 이 경우, 모델 학습부(131-4)는 학습된 감정 판단 모델을 전자 장치의 메모리에 저장할 수 있다. 이 경우, 학습된 감정 판단 모델이 저장되는 메모리는 전자 장치의 적어도 하나의 다른 구성요소에 관계된 명령 또는 데이터를 함께 저장할 수도 있다. 또한, 메모리는 소프트웨어 및/또는 프로그램을 저장 할 수도 있다. 예를 들어, 프로그램은 커널, 미들웨어, 어플리케이션 프로그래밍 인터페이스(API) 및/또는 어플 리케이션 프로그램(또는 \"어플리케이션\") 등을 포함할 수 있다. 모델 평가부(131-5)는 감정 판단 모델에 평가 데이터를 입력하고, 평가 데이터로부터 출력되는 판단 결과가 소 정 기준을 만족하지 못하는 경우, 모델 학습부(131-4)로 하여금 다시 학습하도록 할 수 있다. 이 경우, 평가 데 이터는 감정 판단 모델을 평가하기 위한 기설정된 데이터일 수 있다. 예를 들어, 모델 평가부(131-5)는 평가 데이터에 대한 학습된 감정 판단 모델의 판단 결과 중에서, 판단 결과가 정확하지 않은 평가 데이터의 개수 또는 비율이 미리 설정된 임계치를 초과하는 경우 소정 기준을 만족하지 못 한 것으로 평가할 수 있다. 예컨대, 소정 기준이 비율 2%로 정의되는 경우, 학습된 감정 판단 모델이 총 1000개 의 평가 데이터 중의 20개를 초과하는 평가 데이터에 대하여 잘못된 판단 결과를 출력하는 경우, 모델 평가부 (131-5)는 학습된 감정 판단 모델이 적합하지 않은 것으로 평가할 수 있다. 한편, 학습된 감정 판단 모델이 복수 개가 존재하는 경우, 모델 평가부(131-5)는 각각의 학습된 감정 판단 모델 에 대하여 소정 기준을 만족하는지를 평가하고, 소정 기준을 만족하는 모델을 최종 감정 판단 모델로서 결정할 수 있다. 이 경우, 소정 기준을 만족하는 모델이 복수 개인 경우, 모델 평가부(131-5)는 평가 점수가 높은 순으 로 미리 설정된 어느 하나 또는 소정 개수의 모델을 최종 감정 판단 모델로서 결정할 수 있다. 한편, 데이터 학습부 내의 데이터 획득부(131-1), 전처리부(131-2), 학습 데이터 선택부(131-3), 모델 학 습부(131-4) 및 모델 평가부(131-5) 중 적어도 하나는, 적어도 하나의 하드웨어 칩 형태로 제작되어 전자 장치 에 탑재될 수 있다. 예를 들어, 데이터 획득부(131-1), 전처리부(131-2), 학습 데이터 선택부(131-3), 모델 학습부(131-4) 및 모델 평가부(131-5) 중 적어도 하나는 인공 지능(AI; artificial intelligence)을 위한 전용 하드웨어 칩 형태로 제작될 수도 있고, 또는 기존의 범용 프로세서(예를 들어, CPU 또는 application processor) 또는 특정 기능을 위한 IP의 일부로 제작되어 전술한 각종 전자 장치에 탑재될 수도 있다. 또한, 데이터 획득부(131-1), 전처리부(131-2), 학습 데이터 선택부(131-3), 모델 학습부(131-4) 및 모델 평가 부(131-5)는 하나의 전자 장치에 탑재될 수도 있으며, 또는 별개의 전자 장치들에 각각 탑재될 수도 있다. 예를 들어, 데이터 획득부(131-1), 전처리부(131-2), 학습 데이터 선택부(131-3), 모델 학습부(131-4) 및 모델 평가 부(131-5) 중 일부는 전자 장치에 포함되고, 나머지 일부는 서버에 포함될 수 있다. 한편, 데이터 획득부(131-1), 전처리부(131-2), 학습 데이터 선택부(131-3), 모델 학습부(131-4) 및 모델 평가 부(131-5) 중 적어도 하나는 소프트웨어 모듈로 구현될 수 있다. 데이터 획득부(131-1), 전처리부(131-2), 학습 데이터 선택부(131-3), 모델 학습부(131-4) 및 모델 평가부(131-5) 중 적어도 하나가 소프트웨어 모듈(또는, 인 스트럭션을 포함하는 프로그램 모듈)로 구현되는 경우, 소프트웨어 모듈은 비일시적 컴퓨터 판독가능 기록매체 에 저장될 수 있다. 적어도 하나의 소프트웨어 모듈은 OS(Operating System)에 의해 제공되거나, 소정의 어플리 케이션에 의해 제공될 수 있다. 또는 적어도 하나의 소프트웨어 모듈 중 일부는 OS에 의해 제공되고, 나머지 일 부는 소정의 어플리케이션에 의해 제공될 수도 있다. 도 11b는 본 개시의 일부 실시 예에 따른 감정 판단부의 블록도이다. 도 11b를 참조하면, 일부 실시예에 따른 감정 판단부는 데이터 획득부(132-1), 전처리부(132-2), 데이터 선택부(132-3), 판단 결과 제공부 (132-4) 및 모델 갱신부(132-5)를 포함할 수 있다 데이터 획득부(132-1)는 사용자의 실제 감정 판단에 필요한 데이터를 획득할 수 있으며, 전처리부(132-2)는 사 용자의 실제 감정 판단을 위해 획득된 데이터가 이용될 수 있도록, 획득된 데이터를 전처리할 수 있다. 전처리 부(132-2)는 후술할 판단 결과 제공부(132-4)가 사용자의 실제 감정 판단을 위하여 획득된 데이터를 이용할 수 있도록, 획득된 데이터를 기설정된 포맷으로 가공할 수 있다. 데이터 선택부(132-3)는 전처리된 데이터 중에서 사용자의 실제 감정 판단에 필요한 데이터를 선택할 수 있다. 선택된 데이터는 판단 결과 제공부(132-4)에게 제공될 수 있다. 데이터 선택부(132-3)는 사용자의 실제 감정 판 단을 위한 기설정된 기준에 따라, 전처리된 데이터 중에서 일부 또는 전부를 선택할 수 있다. 또한, 데이터 선 택부(132-3)는 후술할 모델 학습부(142-4)에 의한 학습에 의해 기설정된 기준에 따라 데이터를 선택할 수도 있 다. 판단 결과 제공부(132-4)는 선택된 데이터를 감정 판단 모델에 적용하여 사용자의 실제 감정을 판단할 수 있다. 판단 결과 제공부(132-4)는 데이터 선택부(132-3)에 의해 선택된 데이터를 입력 값으로 이용함으로써, 선택된 데이터를 감정 판단 모델에 적용할 수 있다. 또한, 판단 결과는 감정 판단 모델에 의해 결정될 수 있다. 예를 들어, 판단 결과 제공부(132-4)는 사용자의 실제 감정을 판단할 수 있는 데이터를 감정 판단 모델에 입력하여 사용자의 실제 감정을 판단할 수 있다. 모델 갱신부(132-5)는 판단 결과 제공부(132-4)에 의해 제공되는 판단 결과에 대한 평가에 기초하여, 감정 판단 모델이 갱신되도록 할 수 있다. 예를 들어, 모델 갱신부(132-5)는 판단 결과 제공부(132-4)에 의해 제공되는 판 단 결과를 모델 학습부(131-4)에게 제공함으로써, 모델 학습부(131-4)가 감정 판단 모델을 갱신하도록 할 수 있 다. 한편, 감정 판단부 내의 데이터 획득부(132-1), 전처리부(132-2), 데이터 선택부(132-3), 판단 결과 제공 부(132-4) 및 모델 갱신부(132-5) 중 적어도 하나는, 적어도 하나의 하드웨어 칩 형태로 제작되어 전자 장치에 탑재될 수 있다. 예를 들어, 데이터 획득부(132-1), 전처리부(132-2), 데이터 선택부(132-3), 판단 결과 제공부 (132-4) 및 모델 갱신부(132-5) 중 적어도 하나는 인공 지능(AI; artificial intelligence)을 위한 전용 하드 웨어 칩 형태로 제작될 수도 있고, 또는 기존의 범용 프로세서(예를 들어, CPU 또는 application processor) 또 는 특정 기능을 위한 IP의 일부로 제작되어 전술한 각종 전자 장치에 탑재될 수도 있다. 또한, 데이터 획득부(132-1), 전처리부(132-2), 데이터 선택부(132-3), 판단 결과 제공부(132-4) 및 모델 갱신 부(132-5) 하나의 전자 장치에 탑재될 수도 있으며, 또는 별개의 전자 장치들에 각각 탑재될 수도 있다. 예를 들어, 데이터 획득부(132-1), 전처리부(132-2), 데이터 선택부(132-3), 판단 결과 제공부(132-4) 및 모델 갱신 부(132-5) 중 일부는 전자 장치에 포함되고, 나머지 일부는 전자 잗치와 연동하는 서버에 포함될 수 있다. 한편, 데이터 획득부(132-1), 전처리부(132-2), 데이터 선택부(132-3), 판단 결과 제공부(132-4) 및 모델 갱신 부(132-5) 중 적어도 하나는 소프트웨어 모듈로 구현될 수 있다. 데이터 획득부(132-1), 전처리부(132-2), 데이 터 선택부(132-3), 판단 결과 제공부(132-4) 및 모델 갱신부(132-5) 중 적어도 하나가 소프트웨어 모듈(또는, 인스트럭션을 포함하는 프로그램 모듈)로 구현되는 경우, 소프트웨어 모듈은 비일시적 컴퓨터 판독가능 기록매 체에 저장될 수 있다. 적어도 하나의 소프트웨어 모듈은 OS(Operating System)에 의해 제공되거나, 소정의 어플 리케이션에 의해 제공될 수 있다. 또는 적어도 하나의 소프트웨어 모듈 중 일부는 OS에 의해 제공되고, 나머지 일부는 소정의 어플리케이션에 의해 제공될 수도 있다. 한편, 도 10 내지 도 11b에서는, 사용자의 실제 감정을 판단하기 위한 감정 판단 모델을 중심으로 설명하였으나, 사용자의 감정 발생 원인을 판단할 수 있는 감정 추론 모델에도 상술한 기술적 사상이 적용될 수 있음은 물론이다. 구체적으로, 프로세서는 데이터 학습부 및 감정 추론부(미도시)를 포함할 수 있으 며, 프로세서는 감정 추론 모델을 구축할 수 있음은 물론이다. 본 개시에서 사용된 용어 \"~부\"는 하드웨어, 소프트웨어 또는 펌웨어로 구성된 유닛을 포함하며, 예를 들면, 로 직, 논리 블록, 부품, 또는 회로 등의 용어와 상호 호환적으로 사용될 수 있다. 모듈은, 일체로 구성된 부품 또 는 하나 또는 그 이상의 기능을 수행하는 최소 단위 또는 그 일부가 될 수 있다. 예를 들면, 모듈은 ASIC(application-specific integrated circuit)으로 구성될 수 있다. 본 문서의 다양한 실시예들은 기기(machine)(예: 컴퓨터)로 읽을 수 있는 저장 매체(machine-readable storage media에 저장된 명령어를 포함하는 소프트웨어로 구현될 수 있다. 기기는, 저장 매체로부터 저장된 명령어를 호 출하고, 호출된 명령어에 따라 동작이 가능한 장치로서, 개시된 실시예들에 따른 전자 장치(예: 전자 장치(A)) 를 포함할 수 있다. 상기 명령이 프로세서에 의해 실행될 경우, 프로세서가 직접, 또는 상기 프로세서의 제어하 에 다른 구성요소들을 이용하여 상기 명령에 해당하는 기능을 수행할 수 있다. 명령은 컴파일러 또는 인터프리 터에 의해 생성 또는 실행되는 코드를 포함할 수 있다. 기기로 읽을 수 있는 저장매체는, 비일시적(non- transitory) 저장매체의 형태로 제공될 수 있다. 여기서, '비일시적'은 저장매체가 신호(signal)를 포함하지 않 으며 실재(tangible)한다는 것을 의미할 뿐 데이터가 저장매체에 반영구적 또는 임시적으로 저장됨을 구분하지 않는다. 일시예에 따르면, 본 문서에 개시된 다양한 실시예들에 따른 방법은 컴퓨터 프로그램 제품(computer program product)에 포함되어 제공될 수 있다. 컴퓨터 프로그램 제품은 상품으로서 판매자 및 구매자 간에 거래될 수 있 다. 컴퓨터 프로그램 제품은 기기로 읽을 수 있는 저장 매체(예: compact disc read only memory (CD-ROM))의 형태로, 또는 어플리케이션 스토어(예: 플레이 스토어TM)를 통해 온라인으로 배포될 수 있다. 온라인 배포의 경 우에, 컴퓨터 프로그램 제품의 적어도 일부는 제조사의 서버, 어플리케이션 스토어의 서버, 또는 중계 서버의 메모리와 같은 저장 매체에 적어도 일시 저장되거나, 임시적으로 생성될 수 있다. 다양한 실시예들에 따른 구성 요소(예: 모듈 또는 프로그램) 각각은 단수 또는 복수의 개체로 구성될 수 있으며, 전술한 해당 서브 구성 요소들 중 일부 서브 구성 요소가 생략되거나, 또는 다른 서브 구성 요소가 다 양한 실시예에 더 포함될 수 있다. 대체적으로 또는 추가적으로, 일부 구성 요소들(예: 모듈 또는 프로그램)은 하나의 개체로 통합되어, 통합되기 이전의 각각의 해당 구성 요소에 의해 수행되는 기능을 동일 또는 유사하게 수행할 수 있다. 다양한 실시예들에 따른, 모듈, 프로그램 또는 다른 구성 요소에 의해 수행되는 동작들은 순차 적, 병렬적, 반복적 또는 휴리스틱하게 실행되거나, 적어도 일부 동작이 다른 순서로 실행되거나, 생략되거나, 또는 다른 동작이 추가될 수 있다. 이상과 같이 본 개시는 비록 한정된 실시 예와 도면에 의해 설명되었으나, 본 개시는 상기의 실시 예에 한정되 는 것은 아니며, 본 개시가 속하는 분야에서 통상의 지식을 가진 자라면 이러한 기재로부터 다양한 수정 및 변 형이 가능하다. 그러므로, 본 개시의 범위는 설명된 실시 예에 국한되어 정해져서는 아니 되며, 후술하는 특허 청구범위뿐 아니라 이 특허청구범위와 균등한 것들에 의해 정해져야 한다."}
{"patent_id": "10-2017-0162116", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1a 및 도 1b는 본 개시의 일 실시예에 따른 전자 장치의 구성을 설명하기 위한 도면이다. 도 2는 본 개시의 일 실시예에 따른 사용자의 실제 감정 판단 및 감정 원인 추론을 설명하기 위한 블록도이다. 도 3은 본 개시의 일 실시예에 따른, 감정 판단 방법을 설명하는 도면이다. 도 4a 및 도 4b는 주변 정보를 이용하여 사용자의 감정을 분석하는 방법을 설명하는 도면이다. 도 5a 및 도 5b는 본 개시의 일 실시예에 따른 감정 원인 분석을 설명하기 위한 도면이다. 도 6은 본 개시의 또다른 실시예에 따른 사용자의 실제 감정 및 감정 원인을 판단하는 과정을 설명하는 도면이 다. 도 7은 본 개시의 일 실시예에 따른 전자 장치의 제어 방법을 설명하기 위한 흐름도이다. 도 8은 본 개시의 일 실시예에 따른 사용자 감정 판단 및 감정 원인 분석을 추론하기 위한 시스템의 제어 방법 을 설명하기 위한 시퀀스도이다.도 9는 본 개시의 또 다른 실시예에 따른, 감정 판단 및 감정 원인 분석을 수행하는 사용자 단말을 설명하는 도 면이다. 도 10은 본 개시의 일부 실시 예에 따른 프로세서의 블록도이다. 도 11a 및 도 11b는 본 개시의 일부 실시 예에 따른 데이터 학습부 및 감정 판단부의 블록도이다."}
