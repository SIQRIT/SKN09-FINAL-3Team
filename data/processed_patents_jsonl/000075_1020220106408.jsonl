{"patent_id": "10-2022-0106408", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0028207", "출원번호": "10-2022-0106408", "발명의 명칭": "인공지능 기반의 반려동물 행동 분석 서비스를 제공하는 방법 및 이를 지원하는 인공지능 기", "출원인": "서강대학교산학협력단", "발명자": "최용순"}}
{"patent_id": "10-2022-0106408", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "인공지능 기반의 반려동물 행동 분석 시스템에 있어서,전자 장치;사용자 단말; 및상기 전자 장치 및 상기 사용자 단말과 통신 연결되는 서버를 포함하고,상기 서버는,상기 전자 장치로부터 비디오 데이터를 수신하고,상기 수신된 비디오 데이터의 복수의 프레임들에 상에 배치된 반려동물에 대응하는 복수의 특징점들(keypoints) 각각을 재생 구간별로 확인하고,상기 재생 구간별로 확인된 복수의 특징점들 각각에 기반하여 상기 재생 구간의 시간 순서에 따른 상기 반려동물의 자세들을 결정하고,상기 결정된 자세들에 기반하여 상기 반려동물의 행동을 결정하고,상기 결정된 행동에 기반하여 상기 반려동물과 관련된 상태 정보를 상기 사용자 단말로 전송하도록 설정된, 인공지능 기반의 반려동물 행동 분석 시스템."}
{"patent_id": "10-2022-0106408", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "청구항 1에 있어서,상기 결정된 자세들은 3차원(3dimension)의 자세 정보에 해당하고,상기 서버는, 상기 복수의 프레임들 각각의 색상 데이터를 포함하는 이미지 데이터에 기반하여 상기 3차원의 자세 정보를 결정하도록 설정된, 인공지능 기반의 반려동물 행동 분석 시스템."}
{"patent_id": "10-2022-0106408", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "청구항 1에 있어서,상기 서버는, 복수의 다중 시점(multi view) 이미지 데이터에 기반하여, 상기 반려동물의 자세들을 결정하기 위한 기계 학습을 수행하도록 설정된, 인공지능 기반의 반려동물 행동 분석 시스템."}
{"patent_id": "10-2022-0106408", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "청구항 3에 있어서,상기 서버는, 상기 기계 학습에 기반하여 상기 반려동물의 자세들과 관련된 이미지 데이터 세트(image dataset)를 생성하도록 설정된, 인공지능 기반의 반려동물 행동 분석 시스템."}
{"patent_id": "10-2022-0106408", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "청구항 1에 있어서,상기 상태 정보는, 상기 결정된 행동을 반복한 횟수, 지정된 구간 동안 상기 결정된 행동을 반복한 횟수의 변화율, 상기 반려동물의 산책 시간, 및 상기 반려동물이 반려인과 단절된 시간 중 적어도 하나를 포함하는, 인공지능 기반의 반려동물 행동 분석 시스템."}
{"patent_id": "10-2022-0106408", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "공개특허 10-2024-0028207-3-청구항 1에 있어서,상기 전자 장치는 상기 비디오 데이터를 획득하기 위한 카메라 모듈을 포함하는, 인공지능 기반의 반려동물 행동 분석 시스템."}
{"patent_id": "10-2022-0106408", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "청구항 1에 있어서,상기 사용자 단말은 상기 상태 정보를 표시하기 위한 디스플레이 모듈을 포함하는, 인공지능 기반의 반려동물행동 분석 시스템."}
{"patent_id": "10-2022-0106408", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "청구항 1에 있어서,상기 사용자 단말은, 상기 디스플레이 모듈을 통해 상기 비디오 데이터를 실시간으로 재생하는 모니터링 기능,및 상기 디스플레이 모듈을 통해 상기 반려동물의 산책 시간과 상기 반려동물이 반려인과 단절된 시간을 기록하는 입력 기능을 지원하는, 인공지능 기반의 반려동물 행동 분석 시스템."}
{"patent_id": "10-2022-0106408", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "인공지능 기반의 반려동물 행동 분석 서비스를 제공하는 방법에 있어서,전자 장치로부터 비디오 데이터를 수신하는 단계;상기 수신된 비디오 데이터의 복수의 프레임들에 상에 배치된 반려동물에 대응하는 복수의 특징점들(keypoints) 각각을 재생 구간별로 확인하는 단계;상기 재생 구간별로 확인된 복수의 특징점들 각각에 기반하여 상기 재생 구간의 시간 순서에 따른 상기 반려동물의 자세들을 결정하는 단계;상기 결정된 자세들에 기반하여 상기 반려동물의 행동을 결정하는 단계; 및상기 결정된 행동에 기반하여 상기 반려동물과 관련된 상태 정보를 사용자 단말로 전송하는 단계를 포함하는,인공지능 기반의 반려동물 행동 분석 서비스를 제공하는 방법."}
{"patent_id": "10-2022-0106408", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "청구항 9에 있어서,상기 결정된 자세들은 3차원(3dimension)의 자세 정보에 해당하고,상기 자세들을 결정하는 단계는 상기 복수의 프레임들 각각의 색상 데이터를 포함하는 이미지 데이터에 기반하여 상기 3차원의 자세 정보를 결정하는, 인공지능 기반의 반려동물 행동 분석 서비스를 제공하는 방법."}
{"patent_id": "10-2022-0106408", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "청구항 9에 있어서,복수의 다중 시점(multi view) 이미지 데이터에 기반하여, 상기 반려동물의 자세들을 결정하기 위한 기계 학습을 수행하는 단계를 더 포함하는, 인공지능 기반의 반려동물 행동 분석 서비스를 제공하는 방법."}
{"patent_id": "10-2022-0106408", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "청구항 11에 있어서,상기 기계 학습에 기반하여 상기 반려동물의 자세들과 관련된 이미지 데이터 세트를 생성하는 단계를 더 포함하는, 인공지능 기반의 반려동물 행동 분석 서비스를 제공하는 방법."}
{"patent_id": "10-2022-0106408", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "청구항 9에 있어서,공개특허 10-2024-0028207-4-상기 상태 정보는, 상기 결정된 행동을 반복한 횟수, 지정된 구간 동안 상기 결정된 행동을 반복한 횟수의 변화율, 상기 반려동물의 산책 시간, 및 상기 반려동물이 반려인과 단절된 시간 중 적어도 하나를 포함하는, 인공지능 기반의 반려동물 행동 분석 서비스를 제공하는 방법."}
{"patent_id": "10-2022-0106408", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "청구항 9에 있어서,상기 사용자 단말의 디스플레이 모듈을 통해 상기 반려동물의 산책 시간과 상기 반려동물이 반려인과 단절된 시간을 기록하는 입력 기능을 수행하도록 상기 사용자 단말로 알림을 제공하는 단계를 더 포함하는, 인공지능 기반의 반려동물 행동 분석 서비스를 제공하는 방법."}
{"patent_id": "10-2022-0106408", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "전자 장치, 사용자 단말, 및 상기 전자 장치 및 상기 사용자 단말과 통신 연결되는 서버를 포함하고, 상기 서버 는, 상기 전자 장치로부터 비디오 데이터를 수신하고, 상기 수신된 비디오 데이터의 복수의 프레임들에 상에 배 치된 반려동물에 대응하는 복수의 특징점들(key points) 각각을 재생 구간별로 확인하고, 상기 재생 구간별로 확 인된 복수의 특징점들 각각에 기반하여 상기 재생 구간의 시간 순서에 따른 상기 반려동물의 자세들을 결정하고, 상기 결정된 자세들에 기반하여 상기 반려동물의 행동을 결정하고, 상기 결정된 행동에 기반하여 상기 반려동물 과 관련된 상태 정보를 상기 사용자 단말로 전송하도록 설정된, 인공지능 기반의 반려동물 행동 분석 시스템이 개시된다. 이 외에도 본 문서를 통해 파악되는 다양한 실시 예가 가능하다."}
{"patent_id": "10-2022-0106408", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 문서에서 개시되는 실시 예들은 인공지능 기반의 반려동물 행동 분석 서비스를 제공하는 방법 및 이를 지원 하는 인공지능 기반의 반려동물 행동 분석 시스템에 관한 것이다."}
{"patent_id": "10-2022-0106408", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "1인 가구의 증가와 더불어 개, 고양이 등과 같은 반려동물과 함께 생활하는 반려인구 또한 꾸준히 증가하고 있 다. 반려동물은 짖거나 움직이는 등 특정 행위를 통해 보호자에게 메시지를 전달할 수 있다. 일례로, 개는 개의 의 사소통 신호인 카밍 시그널(calming signal)을 통해 보호자에게 공포, 불안함 등을 표현할 수 있다. 이와 다른 예로서, 개는 반복적인 선회 운동(circling) 등 문제 행동을 통해 누적된 스트레스를 표출할 수 있다. 상당수의 보호자는 카밍 시그널과 문제 행동을 구별하지 못하고, 문제 행동을 개의 나쁜 습관이라고 여겨 결국 에는 그 문제 행동을 이유로 개를 유기하는 상황을 맞이할 수 있다. 종래에는 반려동물의 행동을 파악하기 위해 다양한 기술들이 제안된 바 있다. 그러나, 상기 관련 기술들은 반려 동물의 행동을 분석하기 위해 반려동물의 신체에 센서가 탑재된 웨어러블 디바이스를 장착해야만 하는 등의 문 제점을 포함하고 있다. 따라서 반려인구의 증가 추세에 발맞춰 반려동물의 스트레스 등 정신 질환으로 인한 문제 행동을 보호자에게 알 리는 시스템의 개발이 필요한 실정이다."}
{"patent_id": "10-2022-0106408", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "이에 따라 본 문서에 개시되는 다양한 실시 예에서는, 반려동물의 행동을 분석하여 보호자로 하여금 반려동물의 문제 행동을 파악할 수 있도록 하는 인공지능 기반의 반려동물 행동 분석 서비스를 제공하는 방법 및 이를 지원 하는 인공지능 기반의 반려동물 행동 분석 시스템을 제공할 수 있다."}
{"patent_id": "10-2022-0106408", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "일 실시 예에 따르면, 인공지능 기반의 반려동물 행동 분석 시스템은, 전자 장치, 사용자 단말, 및 상기 전자 장치 및 상기 사용자 단말과 통신 연결되는 서버를 포함하고, 상기 서버는, 상기 전자 장치로부터 비디오 데이 터를 수신하고, 상기 수신된 비디오 데이터의 복수의 프레임들에 상에 배치된 반려동물에 대응하는 복수의 특징 점들(key points) 각각을 재생 구간별로 확인하고, 상기 재생 구간별로 확인된 복수의 특징점들 각각에 기반하 여 상기 재생 구간의 시간 순서에 따른 상기 반려동물의 자세들을 결정하고, 상기 결정된 자세들에 기반하여 상 기 반려동물의 행동을 결정하고, 상기 결정된 행동에 기반하여 상기 반려동물과 관련된 상태 정보를 상기 사용 자 단말로 전송하도록 설정될 수 있다. 일 실시 예에 따르면, 상기 결정된 자세들은 3차원(3dimension)의 자세 정보에 해당하고, 상기 서버는, 상기 복 수의 프레임들 각각의 색상 데이터를 포함하는 이미지 데이터에 기반하여 상기 3차원의 자세 정보를 결정하도록설정될 수 있다. 일 실시 예에 따르면, 상기 서버는, 복수의 다중 시점(multi view) 이미지 데이터에 기반하여, 상기 반려동물의 자세들을 결정하기 위한 기계 학습을 수행하도록 설정될 수 있다. 일 실시 예에 따르면, 상기 서버는, 상기 기계 학습에 기반하여 상기 반려동물의 자세들과 관련된 이미지 데이 터 세트(image data set)를 생성하도록 설정될 수 있다. 일 실시 예에 따르면, 상기 상태 정보는, 상기 결정된 행동을 반복한 횟수, 지정된 구간 동안 상기 결정된 행동 을 반복한 횟수의 변화율, 상기 반려동물의 산책 시간, 및 상기 반려동물이 반려인과 단절된 시간 중 적어도 하 나를 포함할 수 있다. 일 실시 예에 따르면, 상기 전자 장치는 상기 비디오 데이터를 획득하기 위한 카메라 모듈을 포함할 수 있다. 일 실시 예에 따르면, 상기 사용자 단말은 상기 상태 정보를 표시하기 위한 디스플레이 모듈을 포함할 수 있다. 일 실시 예에 따르면, 상기 사용자 단말은, 상기 디스플레이 모듈을 통해 상기 비디오 데이터를 실시간으로 재 생하는 모니터링 기능, 및 상기 디스플레이 모듈을 통해 상기 반려동물의 산책 시간과 상기 반려동물이 반려인 과 단절된 시간을 기록하는 입력 기능을 지원할 수 있다. 일 실시 예에 따르면, 인공지능 기반의 반려동물 행동 분석 서비스를 제공하는 방법은, 전자 장치로부터 비디오 데이터를 수신하는 단계, 상기 수신된 비디오 데이터의 복수의 프레임들에 상에 배치된 반려동물에 대응하는 복 수의 특징점들(key points) 각각을 재생 구간별로 확인하는 단계, 상기 재생 구간별로 확인된 복수의 특징점들 각각에 기반하여 상기 재생 구간의 시간 순서에 따른 상기 반려동물의 자세들을 결정하는 단계, 상기 결정된 자 세들에 기반하여 상기 반려동물의 행동을 결정하는 단계, 및 상기 결정된 행동에 기반하여 상기 반려동물과 관 련된 상태 정보를 사용자 단말로 전송하는 단계를 포함할 수 있다. 일 실시 예에 따르면, 상기 결정된 자세들은 3차원(3dimension)의 자세 정보에 해당하고, 상기 자세들을 결정하 는 단계는 상기 복수의 프레임들 각각의 색상 데이터를 포함하는 이미지 데이터에 기반하여 상기 3차원의 자세 정보를 결정할 수 있다. 일 실시 예에 따르면, 복수의 다중 시점(multi view) 이미지 데이터에 기반하여, 상기 반려동물의 자세들을 결 정하기 위한 기계 학습을 수행하는 단계를 더 포함할 수 있다. 일 실시 예에 따르면, 상기 기계 학습에 기반하여 상기 반려동물의 자세들과 관련된 이미지 데이터 세트를 생성 하는 단계를 더 포함할 수 있다. 일 실시 예에 따르면, 상기 상태 정보는, 상기 결정된 행동을 반복한 횟수, 지정된 구간 동안 상기 결정된 행동 을 반복한 횟수의 변화율, 상기 반려동물의 산책 시간, 및 상기 반려동물이 반려인과 단절된 시간 중 적어도 하 나를 포함할 수 있다. 일 실시 예에 따르면, 상기 사용자 단말의 디스플레이 모듈을 통해 상기 반려동물의 산책 시간과 상기 반려동물 이 반려인과 단절된 시간을 기록하는 입력 기능을 수행하도록 상기 사용자 단말로 알림을 제공하는 단계를 더 포함할 수 있다."}
{"patent_id": "10-2022-0106408", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 문서에 개시되는 다양한 실시 예에 따른 인공지능 기반의 반려동물 행동 분석 서비스를 제공하는 방법 및 이 를 지원하는 인공지능 기반의 반려동물 행동 분석 시스템은 반려동물의 행동을 분석하여 보호자로 하여금 반려 동물의 문제 행동을 파악할 수 있도록 함으로써, 반려동물의 문제 행동에 대한 해결책을 마련할 기회를 제공할 수 있다. 또한, 본 문서에 개시되는 다양한 실시 예에 따르면, 반려동물의 문제 행동에 대한 해결책을 마련할 기회를 통 해 반려동물 유기율을 감소시킬 수 있다. 이 외에도 본 문서를 통해 직접적 또는 간접적으로 파악되는 다양한 효과가 제공될 수 있다."}
{"patent_id": "10-2022-0106408", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 첨부된 도면을 참조하여 본 발명의 바람직한 실시 예를 상세히 설명한다. 본 발명의 이점 및 특징, 그리 고 그것들을 달성하는 방법은 첨부되는 도면과 함께 상세하게 후술되어 있는 실시 예들을 참조하면 명확해질 것 이다. 그러나 본 발명은 이하에서 개시되는 실시 예들에 한정되는 것이 아니라 서로 다른 다양한 형태로 구현될"}
{"patent_id": "10-2022-0106408", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "것이며, 단지 본 실시 예들은 본 발명의 개시가 완전하도록 하며, 본 발명이 속하는 기술분야에서 통상의 지식 을 가진 자에게 발명의 범주를 완전하게 알려주기 위해 제공되는 것이며, 본 발명은 청구항의 범주에 의해 정의 될 뿐이다. 이하에서 동일한 참조 부호는 동일 구성요소를 지칭한다. 비록 제1, 제2 등이 다양한 소자, 구성요소 및/또는 섹션들을 서술하기 위해서 사용되나, 이들 소자, 구성요소 및/또는 섹션들은 이들 용어에 의해 제한되지 않음은 물론이다. 이들 용어들은 단지 하나의 소자, 구성요소 또 는 섹션들을 다른 소자, 구성요소 또는 섹션들과 구별하기 위하여 사용하는 것이다. 따라서, 이하에서 언급되는 제1 소자, 제1 구성요소 또는 제1 섹션은 본 발명의 기술적 사상 내에서 제2 소자, 제2 구성요소 또는 제2 섹션 일 수도 있음은 물론이다. 본 명세서에서 사용된 용어는 실시 예들을 설명하기 위한 것이며 본 발명을 제한하고자 하는 것은 아니다. 본 명세서에서, 단수형은 문구에서 특별히 언급하지 않는 한 복수형도 포함한다. 명세서에서 사용되는 \"포함한다 (comprises)\" 및/또는 \"이루어지다(made of)\"는 언급된 구성요소, 단계, 동작 및/또는 소자는 하나 이상의 다른 구성요소, 단계, 동작 및/또는 소자의 존재 또는 추가를 배제하지 않는다. 다른 정의가 없다면, 본 명세서에서 사용되는 모든 용어(기술 및 과학적 용어를 포함)는 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자에게 공통적으로 이해될 수 있는 의미로 사용될 수 있을 것이다. 또한, 일반적 으로 사용되는 사전에 정의되어 있는 용어들은 명백하게 특별히 정의되어 있지 않는 한 이상적으로 또는 과도하 게 해석되지 않는다. 이하, 첨부된 도면을 참조하여 본 발명의 구성에 대하여 상세히 설명한다. 도 1은 일 실시 예에 따른 인공지능 기반의 반려동물 행동 분석 시스템을 도시한 블록도이다. 도 1을 참조하면, 일 실시 예에 따른 인공지능 기반의 반려동물 행동 분석 시스템(이하, 행동 분석 시스템 )은 전자 장치, 서버 및 사용자 단말을 포함할 수 있다. 이러한 행동 분석 시스템은 네트워크(예: 근거리 무선 통신 네트워크 또는 원거리 무선 통신 네트워크)를 통하여 전자 장치, 서 버 및 사용자 단말을 연결할 수 있다. 이하에서 설명하는 행동 분석 시스템은 반려동물 중 개의 행동을 분석하는 것을 예로 들었으나, 행동 분석의 대상을 개로 한정하는 것은 아니다. 예를 들어, 행동 분석의 대상은 개뿐만 아니라 고양이 등 움직임을 관찰할 수 있는 모든 반려동물을 포함할 수 있다. 일 실시 예에 따르면, 전자 장치는 반려동물을 촬영한 비디오 데이터를 획득할 수 있다. 예를 들어, 전자 장치는 카메라 모듈을 통해 개의 움직임을 촬영한 비디오 데이터를 획득할 수 있다. 상기 획득된 비 디오 데이터 내에는 개의 여러 자세들이 복수의 프레임들 각각에 포함될 수 있다. 다양한 실시 예에 따르면, 전자 장치는 지정된 장소(예: 개의 생활 공간)에 설치되는 스마트폰(smart phone) 또는 CCTV(closed-circuit television, CCTV)일 수 있다. 전자 장치는 서버 및/또는 사용자 단말과 통신하기 위한 통신 모듈을 추가적으로 포함할 수 있다. 일 실시 예에 따르면, 서버는 비디오 데이터를 분석하여 반려동물의 행동을 구별할 수 있다. 예를 들어, 서버는 전자 장치로부터 수신된 비디오 데이터의 프레임들을 분석하여, 반려동물의 반복적인 문제 행 동(예: 선회 운동 등의 상동 행동)을 다른 행동(예: 카밍 시그널)과 구별할 수 있다. 서버는 문제 행동을다른 행동과 구별하기 위하여, 비디오 데이터의 프레임들 내에 포함된 반려동물의 복수의 특징점들(key points) 각각을 기반으로 해당 프레임들의 시간 순서에 따라 반려동물의 변화되는 자세들을 추정하고, 상기 추정된 자세 들을 기반으로 행동을 분류할 수 있다. 일 실시 예에 따르면, 서버는 상술한 문제 행동과 다른 행동을 구별하기 위한 기계 학습(machine learning)을 진행할 수 있다. 예를 들어, 서버는 전자 장치(또는, 사용자 단말)로부터 수신된 다중 시점(multi view) 이미지 데이터(또는, 비디오 데이터)에 기반하여, 개의 자세들을 미리 지정하기 위한 이 미지 데이터 세트(image data set)를 생성할 수 있다. 상기 이미지 데이터 세트에는 예컨대, 프레임 내에 포함 된 개의 단일 시점 RGB 이미지 데이터 및 상기 RGB 이미지 데이터에 해당하는 3차원 자세 정보가 포함될 수 있 다. 서버는 상술한 기계 학습에 따라 지정된 알고리즘을 구성할 수 있다. 일 실시 예에 따르면, 사용자 단말은 반려동물과 관련된 상태 정보를 확인할 수 있다. 예를 들어, 사용자 단말은 서버로부터 수신된 반려동물의 문제 행동 분석 정보를 디스플레이 모듈을 통해 표시할 수 있다. 반려동물의 문제 행동 분석 정보에는 반려동물이 문제 행동을 반복한 횟수, 일자별 또는 시간별로 상 기 문제 행동을 반복한 횟수의 증감 추이, 반려동물이 산책한 시간, 및 반려동물이 보호자와 단절된 시간 등이 포함될 수 있다. 일 실시 예에 따르면, 사용자 단말은 반려인이 반려동물과 다른 공간에 있더라도 반려인으로 하여금 반려 동물의 움직임을 실시간으로 확인하도록 할 수 있다. 예를 들어, 사용자 단말은 전자 장치에서 촬영 중인 비디오 데이터를 디스플레이 모듈을 통해 실시간으로 재생할 수 있다. 다양한 실시 예에 따르면, 사용자 단말은 반려인, 즉 사용자가 휴대 가능한 스마트폰, 태블릿 등 모바일 단말을 포함할 수 있다. 도 2는 일 실시 예에 따른 서버의 구성요소를 도시한 블록도이다. 일 실시 예에 따르면, 서버는 통신 모듈, 행동 분석 알고리즘 모듈, 및 데이터베이스를 포 함할 수 있다. 일 실시 예에 따르면, 통신 모듈은 전자 장치, 서버 및 사용자 단말 간의 직접 통신 채널 또는 무선 통신 채널의 수립, 및 수립된 통신 채널을 통한 통신 수행을 지원할 수 있다. 다양한 실시 예에서, 통신 모듈은 무선 통신 모듈(예: 셀룰러 통신 모듈, 근거리 무선 통신 모듈, 또는 GNSS(global navigation satellite system) 통신 모듈) 또는 유선 통신 모듈(예: LAN(local area network) 통신 모듈, 또는 전력선 통 신 모듈)을 포함할 수 있다. 일 실시 예에 따르면, 행동 분석 알고리즘 모듈은 반려동물의 문제 행동을 다른 행동과 구별하기 위한 기 계 학습을 수행할 수 있다. 예를 들어, 행동 분석 알고리즘 모듈은 전자 장치(또는, 사용자 단말 )로부터 수신된 다중 시점(multi view) 이미지 데이터(또는, 비디오 데이터)에 기반하여, 개의 자세들을 미리 지정하기 위한 이미지 데이터 세트를 생성할 수 있다. 상기 이미지 데이터 세트에는 예컨대, 프레임 내에 포함된 개의 단일 시점 RGB 이미지 데이터 및 상기 RGB 이미지 데이터에 해당하는 3차원 자세 정보가 포함될 수 있다. 일 실시 예에서, 행동 분석 알고리즘 모듈은 3차원 자세 정보를 획득하기 위하여, 카메라 캘리브레 이션(camera calibration) 및 삼각측량(triangulation) 기법 등을 이용할 수 있다. 일 실시 예에 따르면, 행동 분석 알고리즘 모듈은 비디오 데이터를 분석하여 반려동물의 행동을 구별할 수 있다. 예를 들어, 행동 분석 알고리즘 모듈은 전자 장치로부터 수신된 비디오 데이터의 프레임들을 분석하여, 반려동물의 반복적인 문제 행동(예: 선회 운동 등의 상동 행동)을 다른 행동(예: 카밍 시그널)과 구 별할 수 있다. 행동 분석 알고리즘 모듈은 문제 행동을 다른 행동과 구별하기 위하여, 비디오 데이터의 프 레임들 내에 포함된 반려동물의 복수의 특징점들(key points) 각각을 기반으로 해당 프레임들의 시간 순서에 따 라 반려동물의 변화되는 자세들을 추정하고, 상기 추정된 자세들을 기반으로 행동을 분류할 수 있다. 다양한 실시 예에 따르면, 행동 분석 알고리즘 모듈은 예컨대, 지도형 학습(supervised learning), 비지도 형 학습(unsupervised learning), 준지도형 학습(semi-supervised learning), 강화 학습(reinforcement learning), 또는 회귀 학습(regression learning)을 포함할 수 있으나, 전술한 예에 한정되지 않는다. 상기 행 동 분석 알고리즘 모듈은 복수의 인공 신경망 레이어들을 포함할 수 있다. 인공 신경망은 심층 신경망 (DNN: deep neural network), CNN(convolutional neural network), RNN(recurrent neural network), RBM(restricted boltzmann machine), DBN(deep belief network), BRDNN(bidirectional recurrent deep neural network), 심층 Q-네트워크(deep Q-networks) 또는 상기 중 둘 이상의 조합 중 하나일 수 있으나, 전술한 예에한정되지 않는다. 행동 분석 알고리즘 모듈은 하드웨어 구조 이외에, 추가적으로 또는 대체적으로, 소프트 웨어 구조를 포함할 수 있다. 일 실시 예에 따르면, 데이터베이스에는 반려동물의 행동을 분석하기 위한 다양한 데이터가 저장될 수 있 다. 예를 들어, 데이터베이스에는 행동 분석 알고리즘 모듈에서 미리 학습된 이미지 데이터 세트가 저장될 수 있다. 다양한 실시 예에 따르면, 데이터베이스는 적어도 하나의 프로세서(미도시)와 전기적으로 연결될 수 있다. 데이터베이스에는 행동 분석 알고리즘 모듈를 동작시키기 위한 다양한 프로그램들, 적어도 하나의 프 로세서를 동작시키기 위한 다양한 명령 및/또는 인스트럭션들이 저장될 수 있다. 다양한 실시 예에 따르면, 서버 내 적어도 하나의 구성요소들의 동작(또는 기능)은 적어도 하나의 프로세 서(미도시)에 의하여 수행될 수 있다. 다양한 실시 예에 따르면, 적어도 하나의 프로세서는 메모리(미도시)로부터 명령(command) 또는 인스트럭션들 (instructions)을 수신하고, 수신된 명령 또는 인스트럭션들에 따라 각 구성요소들을 제어하여, 다양한 기능들 을 수행할 수 있다. 적어도 하나의 프로세서는 중앙 처리 장치(central processing unit, CPU), 마이크로 컨트 롤 유닛(micro control unit, MCU), 마이크로 프로세서 유닛(micro processor unit, MPU) 등으로 구현될 수 있 다. 도 3은 일 실시 예에 따른 반려동물의 행동을 분석하기 위한 과정들을 도시한 도면이다. 일 실시 예에 따르면, 제1 과정(300a)은 이미지 데이터 세트를 생성하기 위한 과정일 수 있다. 서버는 행 동 분석 알고리즘 모듈의 기계 학습을 위한 데이터 준비 과정으로써 이미지 데이터 세트를 생성할 수 있다. 예를 들어, 서버는 전자 장치(또는, 사용자 단말)로부터 수신된 다중 시점(multi view) 이미지 데이터(또는, 비디오 데이터)에 기반하여, 개의 자세들을 미리 지정하기 위한 이미지 데이터 세트를 생 성할 수 있다. 제1 동작에서, 서버는 상기 이미지 데이터로부터 개의 2차원 특징점들을 추출할 수 있 다. 제2 동작에서, 서버는 상기 제1 동작에서 추출된 개의 2차원 특징점들(예: 2차원 자세)에 기반하여, 개의 3차원 자세를 추정할 수 있다. 이 과정에서 서버는 카메라 캘리브레이션(camera calibration) 및 삼각측량(triangulation) 기법 등을 이용할 수 있다. 일 실시 예에 따르면, 제2 과정(300a)은 제1 과정(300a) 이후, 반려동물의 실시간 비디오 데이터를 분석하여 해 당 반려동물의 행동을 구별하기 위한 과정일 수 있다. 서버는 이미지 데이터 세트에 따라 기계 학습된 행 동 분석 알고리즘 모듈을 이용하여 반려동물의 문제 행동을 다른 행동과 구별할 수 있다. 제3 동작에 서, 서버는 전자 장치로부터 수신된 비디오 데이터의 프레임들로부터 개의 3차원 특징점들을 추출할 수 있다. 제4 동작에서, 서버는 상기 제3 동작에서 추출된 개의 3차원 특징점들에 기반하여 개 의 행동을 인지할 수 있다. 예를 들어, 서버는 데이터베이스 내에 저장된 이미지 데이터 세트와 비교 하여, 개의 3차원 특정점들에 해당하는 행동이 개의 문제 행동인지 여부를 결정할 수 있다. 도 4는 일 실시 예에 따른 서버의 특징점 추출과 관련된 객체 이미지를 예시적으로 도시한 도면이다. 도 4를 참조하면, 서버는 비디오 데이터의 프레임들 내에 포함된 객체의 특징점들에 기반하여, 해당 객체 의 자세들을 결정할 수 있다. 제1 상태(400a)를 참조하면, 행동 분석 알고리즘 모듈은 프레임 내에 포함된 객체가 개인 경우, 제1 특징 점 내지 제18 특징점(401~418)을 식별할 수 있다. 일 실시 예에서, 행동 분석 알고리즘 모듈은 복수의 특 징점들을 연결하여 뼈대(skeleton)를 구분할 수 있다. 예를 들어, 행동 분석 알고리즘 모듈은 제1 특징점 및 제2 특징점을 연결하여 개의 신체 중 오른쪽 발에 대응되는 뼈대(401, 402)를 지정하고, 제3 특 징점 및 제4 특징점을 연결하여 개의 신체 중 왼쪽 발에 대응되는 뼈대(403, 404)를 지정할 수 있다. 제2 상태(400b)를 참조하면, 행동 분석 알고리즘 모듈은 상술한 제1 상태(400a)에서 지정된 뼈대에 기반하 여, 개의 자세들을 결정할 수 있다. 예를 들어, 행동 분석 알고리즘 모듈은 비디오 데이터의 시간 순서에 따른 프레임들 상에서 제1 뼈대(401, 402) 및 제2 뼈대(403, 404)의 위치 변화에 기반하여 개의 3D 자세를 선회 운동으로 추정할 수 있다. 도 5는 다양한 실시 예에 따른 전자 장치 및 사용자 단말 각각의 반려동물 행동 분석 서비스를 제공하는 화면을 예시적으로 도시한 도면이다.일 실시 예에 따르면, 사용자 단말은 디스플레이 모듈을 통해 제1 화면 내지 제6 화면(501a~501f)을 표시할 수 있다. 제1 화면(501a)은 예컨대 반려동물 모니터링 애플리케이션의 초기 화면일 수 있다. 제2 화면 (501b)은 반려인의 사용자 계정을 이용하여 상기 앱에 접속하기 위한 로그인 화면일 수 있다. 제3 화면(501c)은 반려동물의 견종 및 생년월일 등 회원 정보를 입력하기 위한 화면일 수 있다. 제4 화면(501d)은 전자 장치(11 0)를 통해 촬영 중인 반려동물의 실시간 비디오 데이터를 확인하기 위한 모니터링 화면(예: 라이브스트림)일 수 있다. 제5 화면(501e)은 반려동물의 생활(예: 산책 시간 등)과 관련된 데이터를 입력하기 위한 화면일 수 있다. 제6 화면(501f)은 상기 제5 화면(501e)을 통해 입력된 데이터에 기반하여, 해당 데이터들을 지정된 구간(예: 일 자 또는 시간)별로 확인하기 위한 화면일 수 있다. 일 실시 예에 따르면, 전자 장치는 디스플레이 모듈(미도시)을 통해 제1 화면 내지 제3 화면(502a~502c)을 표시할 수 있다. 제1 화면(502a)은 예컨대 반려동물 모니터링 애플리케이션의 초기 화면일 수 있다. 제2 화면 (502b)은 반려인의 사용자 계정을 이용하여 상기 앱에 접속하기 위한 로그인 화면일 수 있다. 제3 화면(502c)은 카메라 모듈을 이용하여 개의 생활 공간을 촬영하기 위한 카메라 실행 화면일 수 있다. 도 6은 일 실시 예에 따른 인공지능 기반의 반려동물 행동 분석 서비스를 제공하는 방법을 도시한 흐름도이다. 단계 S610을 참조하면, 서버는 전자 장치로부터 비디오 데이터를 수신할 수 있다. 상기 수신되는 비 디오 데이터 내에는 반려동물을 촬영한 영상이 포함될 수 있다. 단계 S620을 참조하면, 서버는 비디오 데이터의 복수의 프레임들 상에 배치된 반려동물에 대응하는 복수의 특징점들 각각을 재생 구간별로 확인할 수 있다. 예를 들어, 행동 분석 알고리즘 모듈은 비디오 데이터의 재생 구간 중 제1 구간(예: 1~5초) 사이의 프레임들 상에 배치된 반려동물의 특징점들을 확인한 이후, 상기 재 생 구간 중 제2 구간(예: 6~10초) 사이의 프레임들 상에 배치된 반려동물의 특징점들을 확인할 수 있다. 단계 S630을 참조하면, 서버는 복수의 특징점들 각각에 기반하여 재생 구간의 시간 순서에 따른 반려동물 의 자세들을 결정할 수 있다. 예를 들어, 행동 분석 알고리즘 모듈은 비디오 데이터의 제1 구간에서 반려 동물의 2D 자세로부터 3D 자세를 추출하고, 비디오 데이터의 제2 구간에서 반려동물의 2D 자세로부터 3D 자세를 추출할 수 있다. 단계 S640을 참조하면, 서버는 반려동물의 자세들에 기반하여 반려동물의 행동을 결정할 수 있다. 예를 들 어, 행동 분석 알고리즘 모듈은 상기 단계 S640에서 추출된 3D 자세들에 기반하여 반려동물의 선회 운동 등 행동을 결정할 수 있다. 단계 S650을 참조하면, 서버는 단계 S640에서 결정된 반려동물의 행동에 기반하여 반려동물과 관련된 상태 정보를 사용자 단말로 전송할 수 있다. 예를 들어, 서버는 반려동물이 문제 행동을 반복한 횟수, 일 자별 또는 시간별로 상기 문제 행동을 반복한 횟수의 증감 추이, 반려동물이 산책한 시간, 및 반려동물이 보호 자와 단절된 시간 등을 포함하는 상태 정보를 사용자 단말로 전송할 수 있다. 다양한 실시 예에 따르면, 서버는 단계 S650을 수행하기 위하여, 사용자 단말로 반려동물의 산책 시 간 및 반려동물이 반려인과 단절된 시간 등 반려동물의 생활(예: 산책 시간 등)과 관련된 데이터를 입력하도록 알림을 전송할 수 있다. 이상과 같이 본 발명의 도시된 실시 예를 참고하여 설명하고 있으나, 이는 예시적인 것들에 불과하며, 본 발명"}
{"patent_id": "10-2022-0106408", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "이 속하는 기술분야에서 통상의 지식을 가진 자라면 본 발명의 요지 및 범위에 벗어나지 않으면서도 다양한 변 형, 변경 및 균등한 다양한 타 실시 예들이 가능하다는 것을 명백하게 알 수 있을 것이다. 따라서 본 발명의 진 정한 기술적 보호 범위는 첨부된 청구범위의 기술적인 사상에 의해 정해져야 할 것이다."}
{"patent_id": "10-2022-0106408", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 일 실시 예에 따른 인공지능 기반의 반려동물 행동 분석 시스템을 도시한 블록도이다. 도 2는 일 실시 예에 따른 서버의 구성요소를 도시한 블록도이다. 도 3은 일 실시 예에 따른 반려동물의 행동을 분석하기 위한 과정들을 도시한 도면이다. 도 4는 일 실시 예에 따른 서버의 특징점 추출과 관련된 객체 이미지를 예시적으로 도시한 도면이다. 도 5는 다양한 실시 예에 따른 전자 장치 및 사용자 단말 각각의 반려동물 행동 분석 서비스를 제공하는 화면을 예시적으로 도시한 도면이다. 도 6은 일 실시 예에 따른 인공지능 기반의 반려동물 행동 분석 서비스를 제공하는 방법을 도시한 흐름도이다. 도면의 설명과 관련하여, 동일 또는 대응되는 구성요소에 대해서는 동일한 참조 번호가 부여될 수 있다."}
