{"patent_id": "10-2024-0101042", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2025-0052945", "출원번호": "10-2024-0101042", "발명의 명칭": "음성인식시스템을 자동으로 학습시키기 위한 방법 및 장치", "출원인": "현대자동차주식회사", "발명자": "천창우"}}
{"patent_id": "10-2024-0101042", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "하나 이상의 NLU 엔진들을 포함하는 음성인식시스템을 자동으로 학습시키기 위한 방법에 있어서,상기 하나 이상의 NLU 엔진들이 출력한 NLU 결과들을 획득하는 과정;상기 NLU 결과들 간 비교에 기초하여 대규모 언어 모델을 위한 프롬프트를 생성하는 과정;생성된 프롬프트를 상기 대규모 언어 모델에 사용하여 상기 NLU 결과들이 적절한지 판단하는 과정; 및판단 결과를 이용하여 상기 음성인식시스템을 학습시키는 과정;을 포함하는 방법."}
{"patent_id": "10-2024-0101042", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1 항에 있어서,상기 하나 이상의 NLU 엔진들이 출력한 NLU 결과들을 획득하는 과정은,서로 다른 방법으로 학습된 하나 이상의 NLU 엔진들을 병렬 연결하여 NLU 결과들을 획득하는 과정을 포함하는 방법."}
{"patent_id": "10-2024-0101042", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2 항에 있어서,상기 NLU 결과들 간 비교는,상기 NLU 결과들을 비교하여 의도를 예측한 결과가 가장 다른 문장을 선별하는 과정을 포함하는 방법."}
{"patent_id": "10-2024-0101042", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3 항에 있어서,상기 NLU 결과들이 적절한지 판단하는 과정은,상기 대규모 언어 모델을 이용하여 의도를 예측한 결과가 적절한지 판단하고 올바른 의도를 추론하는 과정을 포함하는 방법."}
{"patent_id": "10-2024-0101042", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4 항에 있어서,판단 결과를 이용하여 상기 음성인식시스템을 학습시키는 과정은,상기 대규모 언어 모델이 올바르게 추론한 결과에 기초하여 상기 음성인식시스템을 학습시키는 과정공개특허 10-2025-0052945-3-을 포함하는 방법."}
{"patent_id": "10-2024-0101042", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1 항에 있어서,상기 하나 이상의 NLU 엔진들이 출력한 NLU 결과들을 획득하는 과정은,학습된 상기 하나 이상의 NLU 엔진들이 출력한 상기 NLU 결과들을 레이블 간 대조학습과 클러스터링하는 과정을 포함하는 방법."}
{"patent_id": "10-2024-0101042", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6 항에 있어서,상기 NLU 결과들 간 비교는,전체 의도 집합에 포함되지 않는 클러스터 중 가장 많은 샘플을 포함하는 클러스터를 선별하고, 대표문장을 선택하는 과정을 포함하는 방법."}
{"patent_id": "10-2024-0101042", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7 항에 있어서,상기 NLU 결과들이 적절한지 판단하는 과정은,상기 클러스터의 대표문장을 이용하여 새로운 의도를 탐지하고, 새로운 의도 레이블을 생성하는 과정을 포함하는 방법."}
{"patent_id": "10-2024-0101042", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8 항에 있어서,판단 결과를 이용하여 상기 음성인식시스템을 학습시키는 과정은,새롭게 생성된 의도 레이블에 기초하여 상기 음성인식시스템을 학습시키는 과정을 포함하는 방법."}
{"patent_id": "10-2024-0101042", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "하나 이상의 NLU 엔진들을 포함하는 음성인식시스템을 자동으로 학습시키기 위한 장치로서,명령어들을 저장하는 적어도 하나의 메모리; 및 적어도 하나의 프로세서를 포함하되,상기 적어도 하나의 프로세서는 상기 명령어들을 실행함으로써,상기 하나 이상의 NLU 엔진들이 출력한 NLU 결과들을 획득하는 과정;상기 NLU 결과들 간 비교에 기초하여 대규모 언어 모델을 위한 프롬프트를 생성하는 과정;생성된 프롬프트를 상기 대규모 언어 모델에 사용하여 상기 NLU 결과들이 적절한지 판단하는 과정; 및판단 결과를 이용하여 상기 음성인식시스템을 학습시키는 과정공개특허 10-2025-0052945-4-을 수행하는 장치."}
{"patent_id": "10-2024-0101042", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제10 항에 있어서,상기 하나 이상의 NLU 엔진들이 출력한 NLU 결과들을 획득하는 과정은,서로 다른 방법으로 학습된 하나 이상의 NLU 엔진들을 병렬 연결하여 NLU 결과들을 획득하는 과정을 포함하는 장치."}
{"patent_id": "10-2024-0101042", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11 항에 있어서,상기 NLU 결과들 간 비교는,상기 NLU 결과들을 비교하여 의도를 예측한 결과가 가장 다른 문장을 선별하는 과정을 포함하는 장치."}
{"patent_id": "10-2024-0101042", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제12 항에 있어서,상기 NLU 결과들이 적절한지 판단하는 과정은,상기 대규모 언어 모델을 이용하여 의도분류기의 예측결과가 적절한지 판단하고 올바른 의도를 추론하는 과정을 포함하는 장치."}
{"patent_id": "10-2024-0101042", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제13 항에 있어서,판단 결과를 이용하여 상기 음성인식시스템을 학습시키는 과정은,상기 대규모 언어 모델이 올바르게 추론한 예측결과에 기초하여 상기 음성인식시스템을 학습시키는 과정을 포함하는 장치."}
{"patent_id": "10-2024-0101042", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제10 항에 있어서,상기 하나 이상의 NLU 엔진들이 출력한 NLU 결과들을 획득하는 과정은,학습된 상기 하나 이상의 엔진들이 출력한 상기 NLU 결과들을 레이블 간 대조학습과 클러스터링하는 과정을 포함하는 장치."}
{"patent_id": "10-2024-0101042", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제15 항에 있어서,공개특허 10-2025-0052945-5-상기 NLU 결과들 간 비교는,전체 의도 집합에 포함되지 않는 클러스터 중 가장 많은 샘플을 포함하는 클러스터를 선별하고, 대표문장을 선택하는 과정을 포함하는 장치."}
{"patent_id": "10-2024-0101042", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제16 항에 있어서,상기 NLU 결과들이 적절한지 판단하는 과정은,상기 클러스터의 대표문장을 이용하여 새로운 의도를 탐지하고, 새로운 의도 레이블을 생성하는 과정을 포함하는 장치."}
{"patent_id": "10-2024-0101042", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제17 항에 있어서,판단 결과를 이용하여 상기 음성인식시스템을 학습시키는 과정은,새롭게 생성된 의도 레이블에 기초하여 상기 음성인식시스템을 학습시키는 과정을 포함하는 장치."}
{"patent_id": "10-2024-0101042", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 개시는 음성인식시스템을 자동으로 학습시키기 위한 방법 및 장치에 관한 것이다. 본 개시의 일 측면에 의하면, 하나 이상의 NLU 엔진들을 포함하는 음성인식시스템을 자동으로 학습시키기 위한 방법에 있어서, 상기 하나 이상의 NLU 엔진들이 출력한 NLU 결과들을 획득하는 과정; 상기 NLU 결과들 간 비교에 기초하여 대규모 언어 모델을 위한 프롬프트를 생성하는 과정; 생성된 프롬프트를 상기 대규모 언어 모델에 사용 하여 NLU 결과들이 적절한지 판단하는 과정; 판단 결과를 이용하여 상기 음성인식시스템을 학습시키는 과정을 포 함하는 방법을 제공한다."}
{"patent_id": "10-2024-0101042", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 음성인식시스템을 자동으로 학습시키기 위한 방법 및 장치에 관한 것이다."}
{"patent_id": "10-2024-0101042", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "이하에 기술되는 내용은 단순히 본 실시예와 관련되는 배경 정보만을 제공할 뿐 종래기술을 구성하는 것이 아니 다. 최근 인공지능의 기법이 발전함에 따라, 인공지능을 응용하는 범위도 넓어지고 있다. 특히, 자연어를 이용하여 이용자와 대화를 할 수 있도록 하는 대화시스템, 예컨대, 챗봇 또는 가상 비서는 다양한 분야에서 활용되고 있 다. 대화시스템이 사용자와의 대화를 진행하기 위해서는, 사용자로부터의 발화, 즉 입력메시지를 대화시스템의 관점에서 이해할 필요가 있다. 이러한 자연어 이해(Natural Language Understanding, NLU)를 달성하기 위해서, 대화시스템은 대화시스템과 사용자 간의 대화로부터 현재 맥락(context)과, 그러한 맥락에서 예상되는, 사용자 의 의도(intent)를 도출하고, 도출된 현재 맥락 및/또는 의도에 기초하여 입력 메시지를 분석할 필요가 있다. 이러한 음성인식 서비스는 적용 범위가 가정으로부터 자동차 등의 다양한 분야로 확대되고 있다. 또한, 텔레매 틱스(telematics) 기술은 다양한 기능을 포함하고 있다. 그 예로는, 실시간 내비게이션 기능, 인터넷을 이용한 정보 검색 기능, 차량의 위치와 날씨 정보를 활용하여 차량 내 환경을 최적화하는 등의 기능이 있다. 음성인식시스템(speech recognition system)은 스마트폰, 스마트 스피커, 차량 인포테인먼트 시스템 등 일상생 활에서 널리 이용된다. 발화의 의도를 분석하는 자연어 이해시스템을 구축하기 위해서는 사전에 예상되는 사용 자의 의도 세트를 설계하고, 문장을 수집하여 의도 분류모델을 학습시켜야 한다. 그러나 사전에 정의된 의도만 으로는 지속적으로 변화하는 사용자의 요구 사항을 완전히 충족시킬 수 없다. 따라서 레이블이 지정되지 않은 사용자 발화에서 발견된 새로운 의도를 반복적으로 통합하여 의도 분류모델을 확장해야 한다.의도 분류모델의 확장을 위해 기존의 방법은 사람 평가자가 데이터를 선별하고 문장을 수집해야 했다. 이러한 방식은 수동으로 태깅(Tagging)하는 과정이 필요하며 시간과 비용이 많이 소모된다. 또한 복수의 사람이 평가하 는 경우 일관된 결과를 얻기 어렵다는 문제가 있다. 이 외에도, 음성인식시스템은 자체적으로 오류를 포함하고 있어서 음성인식 로그로부터 오분류(misclassification)를 찾거나 새로운 의도를 탐지하기가 어렵다. 또한 음성 인식 및 자연어 처리 모델을 학습시켜도 시간이 지남에 따라 사용자의 발화 패턴이 변화하여 모델 성능이 저하 된다. 따라서 오분류와 새로운 의도를 탐지하고 시스템을 개선하기 위한 방법과 시스템이 필요하다."}
{"patent_id": "10-2024-0101042", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 개시는, 음성인식시스템이 의도를 분류한 결과를 기반으로 오분류를 찾고 새로운 의도를 도출하여 음성인식 시스템을 자동으로 학습시키기 위한 방법 및 장치를 제공하는 데 주된 목적이 있다. 본 발명이 해결하고자 하는 과제들은 이상에서 언급한 과제들로 제한되지 않으며, 언급되지 않은 또 다른 과제 들은 아래의 기재로부터 통상의 기술자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2024-0101042", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 개시의 일 측면에 의하면, 하나 이상의 NLU 엔진들을 포함하는 음성인식시스템을 자동으로 학습시키기 위한 방법에 있어서, 상기 하나 이상의 NLU 엔진들이 출력한 NLU 결과들을 획득하는 과정; 상기 NLU 결과들 간 비교 에 기초하여 대규모 언어 모델을 위한 프롬프트를 생성하는 과정; 생성된 프롬프트를 상기 대규모 언어 모델에 사용하여 NLU 결과들이 적절한지 판단하는 과정; 판단 결과를 이용하여 상기 음성인식시스템을 학습시키는 과정 을 포함하는 방법을 제공한다. 본 개시의 다른 측면에 의하면, 하나 이상의 NLU 엔진들을 포함하는 음성인식시스템을 자동으로 학습시키기 위 한 장치로서, 명령어들을 저장하는 적어도 하나의 메모리; 및 적어도 하나의 프로세서를 포함하되, 상기 적어도 하나의 프로세서는 상기 명령어들을 실행함으로써, 상기 하나 이상의 NLU 엔진들이 출력한 NLU 결과들을 획득하 는 과정; 상기 NLU 결과들 간 비교에 기초하여 대규모 언어 모델을 위한 프롬프트를 생성하는 과정; 생성된 프 롬프트를 상기 대규모 언어 모델에 사용하여 NLU 결과들이 적절한지 판단하는 과정; 판단 결과를 이용하여 상기 음성인식시스템을 학습시키는 과정을 수행하는 장치를 제공한다."}
{"patent_id": "10-2024-0101042", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 개시의 일 실시예에 의하면, 음성인식시스템이 의도를 분류한 결과를 기반으로 오분류를 찾고 새로운 의도를 도출하여 음성인식시스템을 자동으로 학습시킬 수 있다. 본 개시의 일 실시예에 의하면, 음성인식시스템을 자동을 학습시킴으로써 지속적으로 변화하는 사용자의 의도를 탐지할 수 있다. 본 개시의 효과들은 이상에서 언급한 효과들로 제한되지 않으며, 언급되지 않은 또 다른 효과들은 아래의 기재 로부터 통상의 기술자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2024-0101042", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 본 개시의 일부 실시예들을 예시적인 도면을 이용해 상세하게 설명한다. 각 도면의 구성 요소들에 참조 부호를 부가함에 있어서, 동일한 구성 요소들에 대해서는 비록 다른 도면 상에 표시되더라도 가능한 한 동일한 부호를 가지도록 하고 있음에 유의해야 한다. 또한, 본 개시를 설명함에 있어, 관련된 공지 구성 또는 기능에 대한 구체적인 설명이 본 개시의 요지를 흐릴 수 있다고 판단되는 경우에는 그 상세한 설명은 생략한다. 본 개시에 따른 실시예의 구성요소를 설명하는 데 있어서, 제1, 제2, i), ii), a), b) 등의 부호를 사용할 수 있다. 이러한 부호는 그 구성요소를 다른 구성 요소와 구별하기 위한 것일 뿐, 그 부호에 의해 해당 구성요소의 본질 또는 차례나 순서 등이 한정되지 않는다. 명세서에서 어떤 부분이 어떤 구성요소를 '포함' 또는 '구비'한 다고 할 때, 이는 명시적으로 반대되는 기재가 없는 한 다른 구성요소를 제외하는 것이 아니라 다른 구성요소를 더 포함할 수 있는 것을 의미한다. 첨부된 도면과 함께 이하에 개시될 상세한 설명은 본 개시의 예시적인 실시형태를 설명하고자 하는 것이며, 본 개시가 실시될 수 있는 유일한 실시형태를 나타내고자 하는 것이 아니다. 도 1은 음성인식 시스템의 구성도이다. 도 1을 참조하면, 음성인식(speech recognition) 시스템은 사용자의 발화(utterance)를 인식하고, 인식한 발화를 이해하고, 사용자의 발화에 대응되는 서비스를 제공한다. 이를 위해 음성인식 시스템은 사용자의 음성발화를 텍스트로 변환하는 음성 인식기, 사용자의 음성발 화에 포함된 의도(intent) 및 엔티티(entity)를 판단하는 자연어 이해기 및 사용자의 의도 및 엔티티에 대 응되는 결과를 제공하기 위한 처리를 수행하는 결과 처리기를 포함한다. 음성 인식기는 적어도 하나의 음성 인식 엔진을 이용하여 사용자의 발화를 입력 문장(input sentence)으로 변환할 수 있다. 여기서, 음성 인식 엔진은 STT(Speech to Text)엔진을 지칭할 수 있으며, 사용자의 발화를 나 타내는 음성 신호에 음성 인식 알고리즘 또는 신경망 모델을 적용하여 음성 신호를 텍스트로 변환할 수 있다. 예를 들어, 음성 인식기는 켑스트럼(Cepstrum), 선형 예측 코딩(Linear Predictive Coefficient: LPC), 멜프리퀀시켑스트럼(Mel Frequency Cepstral Coefficient: MFCC) 또는 필터 뱅크 에너지(Filter Bank Energy) 등의 특징 벡터 추출 기술을 적용하여 사용자 발화에서 특징 벡터를 추출할 수 있다 음성 인식기는 추출된 특징 벡터를 훈련된 기준 패턴과 비교하여 인식 결과를 얻을 수 있다. 이를 위해, 음성의 신호적인 특성을 모델링하여 비교하는 음향 모델(Acoustic Model) 또는 인식 어휘에 해당하는 단어나 음 절 등의 언어적인 순서 관계를 모델링하는 언어 모델(Language Model)이 사용될 수 있다. 음성 인식기는 머신 러닝 또는 딥 러닝을 적용한 모델에 기반하여 사용자 발화를 텍스트로 변환할 수도 있 다. 본 개시에서, 음성 인식 결과는 음성 인식 엔진을 이용하여 획득된 텍스트를 나타낸다. 자연어 이해기는 적어도 하나의 자연어 이해(Natural Language Understanding: NLU) 엔진을 이용하여 입 력 문장에 포함된 사용자 의도 또는 엔티티 중 적어도 하나를 판단한다. 본 개시에서, 의도 분류기는 자연어 이 해기를 이용하여 사용자의 입력으로부터 사용자가 의도하는 바를 파악하는 언어 모델이다. 자연어 이해기는 NLU 엔진을 이용하여 입력 문장으로부터 도메인, 개체명, 화행(speech act) 등의 정보를 추출하고, 추출 결과에 기초하여 의도(intent) 및 의도에 따른 엔티티(entity)를 인식할 수 있다. 엔티티는 슬 롯으로 지칭될 수 있다. NLU 엔진은 입력 문장을 형태소 단위로 분절하고, 형태소들을 벡터공간에 투영하고, 투영된 벡터들을 그룹핑하 여 입력 문장에 따른 의도를 분류하며, 입력 문장 내 의도에 따른 단어 성분들을 엔티티로 추출할 수 있다. 본 개시에서, NLU 결과는 NLU 엔진을 이용하여 획득된 의도 또는 엔티티 중 적어도 하나를 가리킨다. 결과 처리기는 사용자의 의도에 대응되는 서비스를 제공하기 위한 처리를 수행하기 위해, 차량, 사용자 기 기 또는 외부 서버에 결과 신호를 출력할 수 있다. 예를 들어, 사용자의 의도에 대응되는 서비스가 차량 관련 제어인 경우, 결과 처리기는 차량 관련 제어를 수행하기 위한 결과 신호를 차량에 전송할 수 있다. 다른 예로서, 사용자의 의도에 대응되는 서비스가 특정 정 보의 제공인 경우, 결과 처리기는 특정 정보를 검색하고, 검색된 정보를 사용자 단말에 제공할 수 있다. 필요에 따라, 정보의 검색이 외부 서버에서 이루어지는 것도 가능하다. 다른 예로서, 사용자의 의도에 대응되는 서비스가 특정 컨텐츠의 제공인 경우에는, 결과 처리기는 컨텐츠를 제공하는 외부 서버에 대상 컨텐츠의 전송을 요청할 수 있다. 다른 예에서, 사용자의 의도에 대응되는 서비스가 단순 대화의 지속인 경우, 결과 처리 기는 사용자의 발화에 대한 응답을 생성하고, 응답을 시각적 또는 청각적으로 출력할 수 있다. 음성인식시스템은 외부 서버 또는 사용자 단말에 설치될 수도 있고, 그 구성요소 중 일부는 외부 서버에 설치되고 다른 일부는 사용자 단말에 설치되는 것도 가능하다. 사용자 단말은 스마트폰, 태블릿 PC, 웨어러블 기기 등의 모바일 기기일 수도 있고, 사용자 인터페이스가 마련된 가전 기기일 수도 있으며, 차량일 수도 있다. 음성인식시스템은 음성인식시스템과 사용자 사이의 대화 전반을 관리하는 대화 관리기(dialogue manager)를 더 포함할 수 있다. 음성인식시스템의 구성요소들은 그 동작 또는 기능을 기준으로 구분된 것으로서, 그 전부 또는 일부가 메 모리나 프로세서를 공유할 수 있다. 음성인식시스템은 차량 또는 서버 중 어느 하나 상에서 구현될 수 있 다. 그렇지 않으면, 음성인식시스템의 구성요소들 중 일부는 차량에 포함되고, 나머지는 서버에 포함될 수 있다. 예를 들면, 차량은 탑승자의 음성 신호를 서버에 전송하고, 서버는 탑승자의 음성 신호를 처리하여 탑승 자에게 필요한 정보 또는 제어 명령을 생성하고, 정보 또는 제어 명령을 차량으로 전송한다. 도 2는 본 발명의 일 실시예에 따른 대규모 언어 모델에 기반한 자동학습장치를 개략적으로 나타낸 블록구성도 이다. 자동학습장치는 메모리 및 프로세서를 포함한다. 본 개시의 일 실시예에 따른 자동학습장치는 오분류 후보군 선택부, 신규의도 추정부, 프롬프트 생성부, 자동화 판단부 및 재학습부를 전부 또는 일부 포함할 수 있다. 도 2에 도시된 모든 블 록이 필수 구성요소는 아니며, 자동학습장치에 포함된 일부 블록이 추가, 변경 또는 삭제될 수 있다. 한편, 도 2에 도시된 구성요소들은 기능적으로 구분되는 요소들을 나타낸 것으로서, 적어도 하나의 구성요소가 실제 물리적 환경에서는 서로 통합되는 형태로 구현될 수도 있다. 메모리는 자동학습장치의 동작에 필요한 데이터(data) 및 명령어(command)를 저장한다. 프로세서는 자동학습장치 전반의 동작을 제어한다. 프로세서는 하나 또는 그 이상의 프로세서로 구현될 수 있다. 프로세서는 메모리에 저장된 명령어를 실행할 수 있다. 프로세서는 의도판단부, 오분류 후보군 선택부, 신규의도 추정부, 프롬프트 생성부, 자동 화 판단부 및 재학습부를 포함할 수 있다. 본 개시에서, 대규모 언어 모델은 자동학습장치 내에 포함되어 사용될 수도 있고, 자동학습장치의 외 부에 설치되어 서버와의 통신으로 데이터를 주고받으며 사용될 수도 있다. 본 발명에서, 도메인(domain)은 사용자의 발화를 입력 받아 '처리할 수 있는 발화(In-Domain: IND)'와 '처리가 어려운 발화(Out-of-Domain: OOD)'를 포함할 수 있다. IND는 시스템이 이미 학습한 범위 내에서 처리할 수 있는 데이터 또는 입력을 의미한다. 이는 시스템이 미리 정의된 도메인 내에서, 학습된 데이터에 기초하여 정확하게 이해하고 처리할 수 있는 데이터이다. OOD는 시스템이 학습한 범위 밖에 있는 데이터 또는 입력을 의미한다. 구 체적으로, OOD는 시스템이 사전에 학습하지 않은 새로운 도메인, 패턴 또는 의도를 포함하는 데이터를 의미한다. 시스템은 OOD를 포함한 입력에 대해 적절히 반응하기 어렵고, 정확하게 예측하기 어려울 수 있다. 의도판단부는 의도분류기 또는 대규모 언어 모델을 포함할 수 있다. 의도판단부는 사용자의 로그데이 터를 입력 받아 IND와 OOD를 구분할 수 있다. IND와 ODD를 구분하는 작업은 의도분류기 또는 대규모 언어 모델로 수행될 수 있다. IND와 OOD를 구분하기 위해 의도판단부는 레이블이 있는 데이터(labeled data)를 이용 하여 의도분류기 또는 대규모 언어 모델을 학습시킬 수 있다. 의도판단부는 학습된 의도분류기 또는 학습된 대규모 언어 모델을 이용하여 레이블이 없는 데이터 (unlabeled data)에 임시 레이블을 부여할 수 있다(pseudo-label). 도 1의 NLU 엔진은 의도판단부의 의도분류기 또는 대규모 언어 모델을 포함할 수 있다. NLU 결과는 의도판 단부가 구분한 IND와 OOD 데이터셋을 포함할 수 있다. 오분류 후보군 선택부는 의도분류기 앙상블(intent classifier ensemble)을 이용하여 오분류 후보군을 선 택할 수 있다. 의도분류기 앙상블은 하나 의상의 의도분류기(intent classifier)를 병렬 연결하여 의도를 예측 하는 방법을 의미한다. 예를 들어, 하나의 발화에 대해 서로 다른 버전의 의도분류기를 병렬로 실행하여 다양하 게 의도를 예측하게 할 수 있다. 오분류 후보군 선택부는 하나 이상의 의도분류기를 포함할 수 있고, 여기서 의도분류기는 서로 다른 방법 으로 미리 학습된 의도분류기를 의미한다. 본 실시예에서, 의도분류기를 학습시키는 방법은 같은 종류의 모델의 드랍아웃 비율(dropout ratio)을 변경하여 하나 이상의 모델을 학습하는 제1 학습방법, 같은 알고리즘을 사용하지만 학습 파라미터(초기화, 에포크, 배치 크기 등)를 다르게 설정하여 하나 이상의 모델을 학습하는 제2 학습방법, BERT, ALBERT, ELECTRA, RoBERTa 등 서로 다른 알고리즘을 사용하여 하나 이상의 모델을 학습하는 제3 학습방법 및 동일한 전체 의도 집합 데이터셋 내에서 필수 의도는 공통으로 포함하고, 그 외 의도를 서로 다르게 구성하여 하나 이상의 모델을 학습시키는 제 4 학습방법을 포함할 수 있다. 예를 들어, 오분류 후보군 선택부는 전체 의도 집합으로부터 중요한 의도를 선택할 수 있다. 여기서 중요 한 의도는 모든 데이터셋에 공통적으로 포함되는 의도를 의미한다. 오분류 후보군 선택부는 전체 의도 집 합 N으로부터 세 개의 의도 집합 n1, n2 및 n3를 생성할 수 있다. 전체 의도 집합 N은 시스템이 이해하고 처리 할 수 있는 모든 의도들의 집합이다. 의도 집합 n1, n2 및 n3는 중요한 의도를 포함하되, 덜 중요한 다른 의도 를 각각 다르게 포함한다. 오분류 후보군 선택부는 의도 집합 n1, n2 및 n3을 각각 데이터셋으로 이용하여 하나 이상의 모델을 학습시킬 수 있다. 오분류 후보군 선택부는 하나 이상의 학습된 의도분류기를 병렬로 연결할 수 있다. 오분류 후보군 선택부는 예컨대, 제1 학습방법을 이용하여 학습된 하나 이상의 의도분류기를 병렬로 연결 할 수 있다. 오분류 후보군 선택부는 예컨대, 제2 학습방법을 이용하여 학습된 하나 이상의 의도분류기를 병렬로 연결할 수 있다. 오분류 후보군 선택부는 예컨대, 제3 학습방법을 이용하여 학습된 하나 이상의 의 도분류기를 병렬로 연결할 수 있다. 오분류 후보군 선택부는 예컨대, 제4 학습방법을 이용하여 학습된 하 나 이상의 의도분류기를 병렬로 연결할 수 있다. 오분류 후보군 선택부는 학습된 의도분류기를 사용하여 동일한 입력 문장으로부터 발화의 의도를 예측할 수 있다. 또한 의도분류기의 예측결과를 각각 수집할 수 있다. 오분류 후보군 선택부는 예측결과가 얼마나 다양한지 평가하고 오류를 일으키기 쉬운 오분류 후보군을 선 택할 수 있다. 오분류 후보군 선택부는 서로 다른 의도분류기의 결과로부터 오류를 일으키기 쉬운 오분류 후보군을 선택 할 수 있다. 본 실시예에서 오분류 후보군을 선택하는 방법은, 예측결과가 가장 다른 순으로 정렬하여 오분류 가능성이 높은 문장을 찾는 제1 선택방법, 예측결과가 가장 다른 문장들 중에서, 가장 빈도 높은 의도 순으로 그룹핑 (grouping)하고 정렬하여 오분류 가능성이 높은 문장을 찾는 제2 선택방법 및 예측결과의 서브워드(subword) 간 유사도를 분석하여 유사도가 낮은 순으로 정렬하여 오분류 가능성이 높은 문장을 찾는 제3 선택방법을 포함할 수 있다. 예컨대, 오분류 후보군 선택부는 병렬로 연결된 각각의 의도분류기가 예측한 의도가 서로 다를수록 다양성 이 높다고 판단한다. 오분류 후보군 선택부는 예측결과가 가장 다양한 문장을 찾고, 가장 다양한 결과를 얻은 문장을 오분류 후보군으로서 선택한다. 신규의도 추정부는 의도판단부가 OOD라고 분류한 데이터셋으로부터 대조학습과 클러스터링을 수행할 수 있다. 대조학습(contrastive learning)은 데이터 포인트를 벡터 공간에 임베딩하여 유사한 데이터는 더 가깝게, 비유 사한 데이터는 더 멀리 위치하도록 학습하는 방법이다. 신규의도 추정부는 준지도 대조학습(semi- supervised contrastive learning)을 이용하여 신규의도 추정을 위한 대규모 언어 모델을 학습시킬 수 있다. 준 지도 대조학습은 레이블이 있는 데이터와 레이블이 없는 데이트를 함께 사용하여 대조학습을 하는 것을 의미한 다. 신규의도 추정부는 대규모 언어 모델을 이용하여 새로운 의도를 발견할 수 있다. 본 개시 일 실시예에서는 풀 기반(pool-based) 샘플링 방식의 그리디 매서드(greedy method)를 이용했다. 풀 기 반 샘플링은 레이블이 없는 대규모 데이터 풀(pool)로부터 일부 데이터를 선택하여 모델을 학습시키는 방식이다. 이 데이터 풀은 이미 준비된 레이블이 없는 데이터셋이다. 레이블이 없는 데이터 중 모델이 추가적인 학습에 가장 유용한 샘플을 선택하도록 한다. 그리디 메서드는 최적의 선택을 하기 위해 현재 상황에서 가장 좋 은 선택을 반복적으로 하는 방식을 의미한다. 신규 의도 추정부는 전체 의도 집합에 포함되지 않는 클러스터 중 가장 많은 샘플을 포함하는 클러스터를 선별할 수 있다. 또한 신규 의도 추정부는 클러스터의 대표 문장을 선택할 수 있다. 클러스터의 대표문장을 선택하는 방법은 클러스터의 중심(centroid)으로부터 가장 가까운 문장을 선택하는 방법, 클러스터 내에서 가장 빈도가 높은 문장을 선택하는 방법, 및 클러스터의 중심 거리 및 빈도를 고려하여 선택하는 방법을 포함할 수 있다. 포롬프트 생성부는 IND와 OOD를 구분하는 의도분류 성능을 향상시키기 위한 프롬프트를 생성할 수 있다. 일 예시로, 프롬프트 생성부는 후보군 데이터셋으로부터 의도 사용 비율을 조정하고, 발화 예제 샘플링 비 율을 조정하여 의도분류를 위한 프롬프트를 생성할 수 있다. 프롬프트 생성부는 전체 데이터셋으로부터 의도 사용 비율을 조정하고, 발화 예제 샘플링 비율을 조정하여 신규의도 생성을 위한 프롬프트를 생성할 수 있다. 프롬프트 생성부는 적은 양의 예시를 사용하여 프롬프 트를 생성하고 입력 크기를 줄일 수 있다. 자동화 판단부는 대규모 언어 모델을 이용하여 오분류 예측결과가 적절한 것인지 판단할 수 있다. 구체적 으로, 자동화 판단부는 오분류 가능성이 높은 문장 데이터와 의도분류기의 예측결과를 입력 받아 발화의 실제 의미와 예측 결과의 관계를 판단할 수 있다. 자동화 판단부는 발화의 의미를 분석하고 그 결과를 프 롬프트로서 활용할 수 있다. 자동화 판단부는 대규모 언어 모델을 이용하여 새로운 의도(new intention)를 탐지할 수 있다. 특히, 자동 화 판단부는 클러스터의 대표문장을 이용하여 새로운 의도를 탐지할 수 있다. 또한 자동화 판단부는 OOD 데이터에서 정탐(True-Negative) IND 발화를 찾을 수 있다. 자동화 판단부는 새로운 의도를 탐지한 결 과에 기초하여 새로운 의도 레이블을 생성할 수 있다. 재학습부는 자동화 판단부의 결과에 기초하여 자동학습장치가 포함하는 의도분류기 또는 대규모 언어 모델을 지속적으로 학습시킬 수 있다. 기존에는 지속적 학습(continual learning)과 액티브 러닝(active learning)을 이용하기 위해서는 인간 평가자 (human evaluator)가 필요했다. 특히 모델이 오분류한 사례를 식별하고, 새로운 의도를 탐지하기 위해서는 도메 인 전문가나 인간 평가자가 데이터를 검토하고 주석을 다는 작업이 필요했다. 이러한 과정은 시간과 비용이 많 이 소모된다. 본 개시의 자동학습장치는 인간 평가자의 역할을 자동화하여 인간 평가자 없이 텍스트 의미를 분석하고, 새로운 의도를 자동으로 라벨링할 수 있다. 따라서 본 개시의 자동학습장치는 모든 데이터를 처리할 때까 지 무한히 반복 학습을 할 수 있다. 이에 따라, 새로운 데이터가 지속적으로 업데이트 되는 환경에서 유용할 수 있다. 자동학습장치는 성능과 효율을 유지하기 위하여 적절한 종료 조건을 가진다. 자동학습장치의 성능이 미리 설정된 기준 이하로 떨어지지 않을 때까지 학습을 반복하는 조건을 가진다. 예를 들어, IND 분류 성능이 일정 수준 이하로 하락한다면 학습을 중단한다. 도 3은 본 발명의 일 실시예에 따른 새로운 의도를 탐지하는 과정을 나타내는 순서도이다. 의도판단부는 사용자의 발화를 입력받아 IND와 OOD를 구분한다(S300). IND와 OOD를 구분하는 작업은 의도 분류기 또는 대규모 언어 모델을 이용하여 수행될 수 있다. 포롬프트 생성부는 IND와 OOD를 구분하는 의도분류 성능을 향상시키기 위한 프롬프트를 생성할 수 있다. 프롬프트 생성부는 후보군 데이터셋으로부터 의도 사용 비율을 조정하고, 발화 예제 샘플링 비율을 조정하 여 의도분류를 위한 프롬프트를 생성할 수 있다. 표 1은 본 발명에서 IND와 OOD를 구분하는 의도분류기의 작업을 대규모 언어 모델 기반으로 수행한 정확도를 나 타낸 것이다. 표 1"}
{"patent_id": "10-2024-0101042", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "의도분류기는 한국어 기반의 ELECTRA-base를 사용했다. 의도분류기는 한국어 데이터셋에 기초하여 미리 학습되 고, 의도분류 데이터셋에 기초하여 미세 조정된 모델을 사용했다. 모델의 레이어, 임베딩 크기 등 파라미터 설 정은 공개된 ELECTRA-base 모델의 설정과 동일했다. 대규모 언어 모델은 gpt-3.5-turbo-16k-0613 모델을 사용 했다. 대규모 언어 모델은 16k의 입력 크기를 가지고 있음에도 전체 446개의 의도와 발화문장 1개를 예시로써 사용할 경우, 입력 크기의 한계를 넘어섰다. 따라서 학습데이터 전체 의도의 100%, 75%, 50%, 25%를 사용했을 경우로 각각 분할하여 의도 분류 작업을 수행했다. 테스트셋은 상위발화 테스트셋(top utterance test set)과 균등분포 테스트셋(evenly distributed test set)을 포함한다. 상위발화 테스트셋은 전체 발화 데이터의 도메인 비율과 유사한 테스트셋을 포함한다. 균등분포 테스트셋은 의도별로 같은 수의 테스트셋을 포함한다. 표 1은 본 개시에서 IND와 OOD를 구분하는 의도분류기의 작업을 대규모 언어 모델 기반으로 수행한 정확도(accuracy) 성능을 나타낸다. 대규모 언어 모델을 사용할 경우 100%의 의도 레이블 예시를 퓨샷(few shot)을 이용하여 제공 하더라도 모든 의도를 맞출 수는 없었다. 다만 적은 수의 의도 레이블 예시를 보여준 경우에도 성능 하락이 작 았다. 신규의도 추정부는 의도판단부가 OOD라고 분류한 데이터셋으로부터 클러스터별 대표 문장을 샘플링할 수 있다(S310). 신규의도 추정부는 레이블 간 대조학습과 클러스터링을 수행할 수 있다. 신규 의도 추정부는 전체 의 도 집합에 포함되지 않는 클러스터 중 가장 많은 샘플을 포함하는 클러스터를 선별할 수 있다. 신규 의도 추정 부는 클러스터의 대표 문장을 선택할 수 있다. 자동화 판단부는 대규모 언어 모델을 이용하여 새로운 의도를 탐지할 수 있다(S320). 특히, 자동화 판단부 는 클러스터의 대표문장을 이용하여 새로운 의도를 탐지할 수 있다. 자동화 판단부는 OOD 데이터에서 정탐(True-Negative) IND 발화를 찾을 수 있다. 프롬프트 생성부는 전체 데이터셋으로부터 의도 사용 비율을 조정하고, 발화 예제 샘플링 비율을 조정하여 신규의도 생성을 위한 프롬프트를 생성할 수 있다. 본 개시의 일 실시예에서는, 전체 OOD 문장 19,461개 중 각 클러스터의 대표 발화를 선별했다. 그리고 전체 161 개의 문장으로부터 기존 의도 또는 새로운 의도 발견을 동시에 수행하도록 프롬프트를 설정했다. 대규모 언어 모델에게 의도 레이블을 예시로 제공하고, 새로운 발화에 대하여 의도분류를 수행하고, 기존 의도에 없다고 판 단되는 경우 새로운 의도 레이블을 생성하는 방식으로 진행했다. 대규모 언어 모델은 의도 레이블 예시의 양에 변화를 주는 것에 크게 영향을 받지 않았다. 평균적으로 14% 정도를 IND라고 분류하고, 나머지 86%를 새로운 의 도 레이블이라고 예측했다. OOD 데이터 셋은 정답 레이블이 없기 때문에, 예측결과를 두 명의 사람 평가자가 평가했다. 그 결과, 80%의 정확도로 새로운 의도 레이블이 사용 가능하다고 판단되었다. IND로 분류된 발화의 67%가 정확하게 분류되었다. 두 사람 평가자의 신뢰도를 판단할 수 있는 Cohen's Kappa 계수는 0.741이다. 재학습부는 새롭게 생성된 의도 레이블에 기초하여 자동학습장치의 의도분류기 또는 대규모 언어 모델을 학습시킬 수 있다(S330). 또한 재학습부는 정탐 IND 발화에 기초하여 의도분류기 또는 대규모 언어 모델을학습시킬 수 있다. 재학습부는 평가데이터에 기초하여 의도 분류 성능을 평가할 수 있다(S340). 재학습부는 미리 정의된 의도에 대한 의도 분류 성능이 하락하지 않는 범위 내에서 학습을 반복하고, 분류 성능이 하락하는 경우에 학습 을 멈출 수 있다. 재학습부는 하나씩 점진적으로 중요한 클러스터를 새로운 의도 레이블로써 포함시켜 모 르는 의도를 알 수 없는 의도의 개수를 줄여갈 수 있다. 재학습부는 모든 데이터를 처리할 때까지 무한히 반복 학습할 수 있다. 도 4는 본 발명의 일 실시예에 따른 오분류를 판단하는 과정을 나타내는 순서도이다. 의도판단부는 사용자의 발화를 입력받아 IND와 OOD를 구분한다(S400). IND와 OOD를 구분하는 작업은 의도 분류기 또는 대규모 언어 모델을 이용하여 수행될 수 있다. 포롬프트 생성부는 IND와 OOD를 구분하는 의도분류 성능을 향상시키기 위한 프롬프트를 생성할 수 있다. 프롬프트 생성부는 후보군 데이터셋으로부터 의도 사용 비율을 조정하고, 발화 예제 샘플링 비율을 조정하 여 의도분류를 위한 프롬프트를 생성할 수 있다. 오분류 후보군 선택부는 의도판단부가 IND라고 분류한 데이터셋으로부터 오분류 문장을 추정할 수 있다 (S410). 오분류 후보군 선택부는 하나 이상의 의도분류기를 포함할 수 있다. 여기서 의도분류기는 서로 다른 방법 으로 미리 학습된 의도분류기를 의미한다. 오분류 후보군 선택부는 하나 이상의 학습된 의도분류기를 병렬 로 연결하여, 동일한 입력 문장으로부터 의도 예측을 수행할 수 있다. 오분류 후보군 선택부는 동일한 입 력 문장에 따른 예측결과가 얼마나 다양한지 평가하고 의도 분포의 다양성에 기초하여 예측결과를 정렬할 수 있 다. 오분류 후보군 선택부는 서로 다른 의도분류기의 예측결과를 비교하여 오류를 일으키기 쉬운 오분류 후보군을 선택할 수 있다. 본 발명의 일 실시예에서는, 전체 의도 집합 N으로부터 세 개의 의도 집합 n1, n2 및 n3를 생성했다. 전체 의도 집합 N은 시스템이 이해하고 처리할 수 있는 모든 의도들의 집합이다. 의도 집합 n1, n2 및 n3는 중요한 (important) 의도를 포함하되, 덜 중요한(less important) 다른 의도를 각각 다르게 포함한다. 여기서 중요한 의도는 모든 데이터셋에 공통적으로 포함되는 의도를 의미한다. 오분류 후보군 선택부는 의도 집합 n1, n2 및 n3을 각각 데이터셋으로 이용하여 하나 이상의 의도분류기를 학습시켰다. 그리고 의도분류기를 이용하여 예 측된 결과를 의도 분포의 다양성을 기준으로 정렬했다. 가장 다양한 결과를 얻은 문장을 오분류 후보군이라고 선별했다. 본 개시의 일 실시예에서 예측을 수행한 결과, 발화 161,843개를 포함하는 전체 데이터셋 중에서 5,746개 (3.55%)의 발화의 의도분류기 결과가 불일치했다. 이 중에서 학습된 의도가 달라서 발생한 차이를 제외한 후 2,320건(1.43%)의 발화에서 의도분류기가 혼동을 일으킨 데이터가 발견되었다. 자동화 판단부는 대규모 언어 모델을 이용하여 오분류 예측결과가 적절한 것인지 판단할 수 있다(S420). 자동화 판단부의 대규모 언어 모델은 오분류 가능성이 높은 문장 데이터와 의도분류기의 예측결과를 입력 받아 발화의 실제 의미와 예측 결과의 관계를 판단할 수 있다. 자동화 판단부는 발화의 의미를 분석하고 그 결과를 프롬프트로 활용할 수 있다. 본 개시의 일 실시예에서는 선별된 2,320개의 오분류 후보군 발화를 세 그룹으로 나누고 대규모 언어 모델을 사 용하여 의도분류기의 예측 결과를 평가했다. 오분류 후보군 발화는 발화 빈도를 기준으로 나누었다. 세 그룹은 100회 이상 발화한 그룹A(395개), 30회 이상 100회 미만 발화한 그룹B(1,348개) 및 30회 미만 발화한 그룹C(577 개)를 포함한다. 각 그룹에서 100개의 샘플을 무작위로 추출하고, 대규모 언어 모델을 사용하여 의도분류기의 결과를 판단하고 올바른(correct) 의도를 추론하게 했다. 표 2는 의도분류기의 예측결과, 대규모 언어 모델이 올바르게 추론한 결과 및 사람 평가자가 평가한 결과를 나 타낸다.표 2"}
{"patent_id": "10-2024-0101042", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "대규모 언어 모델이 올바르게 추론한 경우 Human란에 1을 기입했고, 대규모 언어 모델의 추론이 틀렸을 경우 0 을 기입했다. 표 3는 사람 평가자가 결과를 평가한 결과 일치도를 나타낸 것이다. 표 3"}
{"patent_id": "10-2024-0101042", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "그 결과, 평균 일치도(average matching ratio) 85.46%의 성능을 나타냈다. 대규모 언어 모델의 판단 능력이 사 람의 판단 능력을 모방할 수 있다는 결과를 보여줬다. 재학습부는 대규모 언어 모델이 올바르게 추론한 예측결과에 기초하여 자동학습장치의 의도분류기 또는 대 규모 언어 모델을 학습시킬 수 있다(S430). 재학습부는 평가데이터에 기초하여 의도 분류 성능을 평가할 수 있다(S440). 재학습부는 미리 정의된 의도에 대한 의도 분류 성능이 하락하지 않는 범위 내에서 학습을 반복하고, 분류 성능이 하락하는 경우에 학습 을 멈출 수 있다. 도 5는 본 발명의 일 실시예에 따른 의도 분석 방법의 순서도이다. 의도판단부는 사용자의 데이터로그를 입력받아 IND와 OOD를 구분한다(S500). 오분류 후보군 선택부는 의도분류기 또는 대규모 언어 모델이 IND라고 분류한 데이터로부터 오분류 문장을 추정할 수 있다. 또한 신규의도 추정부는 의도분류기 또는 대규모 언어 모델이 OOD라고 분류한 데이터로부 터 클러스터별 대표 문장을 샘플링 할 수 있다(S510). 자동화 판단부는 대규모 언어 모델을 이용하여 의도분류기의 예측결과가 적절한 것인지 판단할 수 있다. 또한 자동화 판단부는 대규모 언어 모델을 이용하여 새로운 의도를 탐지할 수 있다(S520). 재학습부는 자동화 판단부의 결과에 기초하여 자동학습장치의 의도분류기 또는 대규모 언어 모델을 학습시킬 수 있다(S530). 재학습부는 평가데이터에 기초하여 의도 분류 성능을 평가할 수 있다(S540). 도 6은 대규모 언어 모델의 한정된 입력 크기 안에서 효과적인 프롬프팅을 수행하기 위한 방법을 예시적으로 나 타낸 도면이다. 대규모 언어 모델은, 입력과 출력 토큰의 길이가 길수록 생성속도가 느려진다. 따라서 짧은 프롬프트를 사용하 는 방법은 새로운 의도 발견 속도를 향상시키고 비용을 절감할 수 있다. 또한 액티브 러닝의 자동화를 이용하여 의도 분류기의 성능을 지속적으로 향상시킬 수 있다. 도 6a는 한정된 입력 크기 안에서 의도 분류 작업을 효과적으로 수행하기 위한 프롬프팅 방법을 예시적으로 나 타낸 도면이다. 대규모 언어 모델이 문장의 의도를 예측하기 위해서는 퓨삿을 이용하여 예시를 제공해야 한다. 대규모 언어 모 델은 제한된 입력 크기(context size)를 가진다. 입력 크기는 모델이 한 번에 처리할 수 있는 최대 토큰 수를 의미한다. 토큰 수의 제한 때문에 입력 텍스트의 길이에 제한이 있다. 프롬프트 생성부는 제한된 입력크기 에서 의도분류 성능을 향상시키기 위한 프롬프트를 생성할 수 있다. 일 예시로, 대규모 언어 모델은 16k의 입력 크기를 가지고 있음에도 전체 446개의 의도와 발화문장 1개를 예시 로써 사용할 경우, 입력 크기의 한계를 넘어섰다. 이를 해결하기 위해 프롬프트 생성부는 후보군 데이터셋 으로부터 의도 사용 비율을 조정하고, 발화 예제 샘플링 비율을 조정하여 의도분류를 위한 프롬프트를 생성할 수 있다. 생성된 프롬프트는 \"발화:의도\"와 같이 발화와 의도가 하나의 쌍(pair)을 이루는 예제를 포함할 수 있 다. 예를 들어, \"창문 열어줘\"라는 발화와 \"OpenWindow\"라는 의도가 하나의 쌍을 이루면서 \"창문 열어 줘:OpenWindow\"의 예제를 포함할 수 있다. 프롬프트 생성부는 발화 예제를 N개씩 사용하고, 전체 의도의 1/N을 사용하면서 입력 크기의 100%의 프롬 프트를 생성할 수 있다. 프롬프트 생성부는 예컨대, 발화 예제를 1개씩 사용하고, 전체 의도의 100%를 사용하면서 입력 크기의 100%의 프롬프트를 생성할 수 있다. 전체 의도의 100%를 사용하는 방식은 모든 의도를 고르게 분류할 수 있다. 프롬프트 생성부는 예컨대, 발화 예제를 2개씩 사용하고, 전체 의도의 50%를 사용하면서 입력 크기의 100% 의 프롬프트를 생성할 수 있다. 전체 의도의 50%를 사용하는 방식은 평균적으로 다양항 의도를 분류할 때 유리 할 수 있다. 프롬프트 생성부는 예컨대, 발화 예제를 4개씩 사용하고, 전체 의도의 25%를 사용하면서 입력 크기의 100% 의 프롬프트를 생성할 수 있다. 전체 의도의 25%를 사용하는 방식은 통계적으로 많이 사용되는 의도를 잘 분류 할 수 있다 도 6b는 한정된 입력 크기 안에서 새로운 의도를 효과적으로 생성하기 위한 프롬프팅 방법을 예시적으로 나타낸 도면이다. 프롬프트 생성부는 전체 데이터셋으로부터 의도 사용 비율을 조정하고, 발화 예제 샘플링 비율을 조정하여 신규의도 생성을 위한 프롬프트를 생성할 수 있다. 생성된 프롬프트는 \"발화:의도\"와 같이 발화와 의도가 하나의 쌍(pair)을 이루는 예제를 포함할 수 있다. 예를 들어, \"창문 열어줘\"라는 발화와 \"OpenWindow\"라는 의도가 하나의 쌍을 이루면서 \"창문 열어줘:OpenWindow\"의 예제를 포함할 수 있다. 본 개시의 일 실시예에서, 기존 의도를 분류하는 작업의 경우에는 많은 양의 예시가 팔요하고, 새로운 의도를 발견하는 작업의 경우에는 5% 수준의 적은 예시만으로도 충분히 높은 정확도를 가질 수 있었다. 도 7은 본 개시에 따른 방법 또는 장치를 구현하기 위해 사용될 수 있는 예시적인 컴퓨팅 장치를 개략적으로 나 타낸 블록구성도이다. 컴퓨팅 장치는 메모리, 프로세서, 스토리지, 입출력 인터페이스 및 통신 인터페이스 중 일부 또는 전부를 포함할 수 있다. 컴퓨팅 장치는 자동학습장치의 적어도 일부를 구조적 및 /또는 기능적으로 포함할 수 있다. 컴퓨팅 장치는 데스크탑 컴퓨터, 서버 등과 같은 고정형(stationary) 컴퓨팅 장치뿐만 아니라, 랩탑 컴퓨터, 스마트 폰, 차량용 전장 등과 같은 휴대용(mobile) 컴퓨팅 장치일 수도 있다. 컴퓨팅 장치는 인공지능 모델에 대한 연산들을 효율적인 방식으로 처리하는 것이 가능한 임의의 특 수화된 하드웨어 가속기(accelerator)로 구현될 수도 있다. 예컨대, 컴퓨팅 장치는 그래픽 처리 장치 (graphic processing unit, GPU), 텐서 처리 장치(Tensor Processing Unit, TPU) 또는 신경망 처리 장치 (neural processing unit, NPU)를 포함할 수 있다. 메모리는 프로세서로 하여금 본 개시의 다양한 실시예에 따른 방법 또는 동작을 수행하도록 하는 프 로그램을 저장할 수 있다. 예를 들면, 프로그램은 프로세서에 의해서 실행 가능한(executable) 복수의 명 령어들을 포함할 수 있고, 복수의 명령어들이 프로세서에 의해서 실행됨으로써 전술한 방법 또는 동작들이 수행될 수 있다. 메모리는 단일 메모리 또는 복수의 메모리들일 수 있다. 이 경우, 본 개시의 다양한 실시 예에 따른 방법 또는 동작을 수행하기 위해 필요한 정보는 단일 메모리에 저장되거나 복수의 메모리들에 나뉘어저장될 수 있다. 메모리가 복수의 메모리들로 구성된 경우, 복수의 메모리들은 물리적으로 분리될 수 있다. 메모리는 휘발성 메모리 및 비휘발성 메모리 중 적어도 하나를 포함할 수 있다. 휘발성 메모리는 SRAM(Static Random Access Memory) 또는 DRAM(Dynamic Random Access Memory) 등을 포함하고, 비휘발성 메모 리는 플래시 메모리(flash memory) 등을 포함한다. 프로세서는 적어도 하나의 명령어들을 실행할 수 있는 적어도 하나의 코어를 포함할 수 있다. 프로세서 는 메모리에 저장된 명령어들을 실행할 수 있다. 프로세서는 단일 프로세서 또는 복수의 프로세 서들일 수 있다. 스토리지는 컴퓨팅 장치에 공급되는 전력이 차단되더라도 저장된 데이터를 유지한다. 예를 들면, 스 토리지는 비휘발성 메모리를 포함할 수도 있고, 자기 테이프, 광학 디스크, 자기 디스크와 같은 저장 매체 를 포함할 수도 있다. 스토리지에 저장된 프로그램은 프로세서에 의해서 실행되기 이전에 메모리 로 로딩될 수 있다. 스토리지는 프로그램 언어로 작성된 파일을 저장할 수 있고, 파일로부터 컴파일 러 등에 의해서 생성된 프로그램은 메모리로 로딩될 수 있다. 스토리지는 프로세서에 의해서 처 리될 데이터 및/또는 프로세서에 의해서 처리된 데이터를 저장할 수 있다. 입출력 인터페이스는 키보드, 마우스 등과 같은 입력 장치 및/또는 디스플레이 장치, 프린터 등과 같은 출 력 장치와의 인터페이스를 제공할 수 있다. 사용자는 입력 장치를 통해 프로세서에 의한 프로그램의 실행 을 트리거하고/거나 출력 장치를 통해 프로세서의 처리 결과를 확인할 수 있다. 통신 인터페이스는 외부 네트워크에 대한 액세스를 제공할 수 있다. 컴퓨팅 장치는 통신 인터페이스 를 통해 다른 장치들과 통신할 수 있다. 본 발명에 따른 장치 또는 방법의 각 구성요소는 하드웨어 또는 소프트웨어로 구현되거나, 하드웨어 및 소프트 웨어의 결합으로 구현될 수 있다. 또한, 각 구성요소의 기능이 소프트웨어로 구현되고 마이크로프로세서가 각 구성요소에 대응하는 소프트웨어의 기능을 실행하도록 구현될 수도 있다. 본 명세서에 설명되는 시스템들 및 기법들의 다양한 구현예들은, 디지털 전자 회로, 집적회로, FPGA(field programmable gate array), ASIC(application specific integrated circuit), 컴퓨터 하드웨어, 펌웨어, 소프 트웨어, 및/또는 이들의 조합으로 실현될 수 있다. 이러한 다양한 구현예들은 프로그래밍가능 시스템 상에서 실 행 가능한 하나 이상의 컴퓨터 프로그램들로 구현되는 것을 포함할 수 있다. 프로그래밍가능 시스템은, 저장 시 스템, 적어도 하나의 입력 디바이스, 그리고 적어도 하나의 출력 디바이스로부터 데이터 및 명령들을 수신하고 이들에게 데이터 및 명령들을 전송하도록 결합되는 적어도 하나의 프로그래밍가능 프로세서(이것은 특수 목적 프로세서일 수 있거나 혹은 범용 프로세서일 수 있음)를 포함한다. 컴퓨터 프로그램들(이것은 또한 프로그램들, 소프트웨어, 소프트웨어 애플리케이션들 혹은 코드로서 알려져 있음)은 프로그래밍가능 프로세서에 대한 명령어 들을 포함하며 \"컴퓨터가 읽을 수 있는 기록매체\"에 저장된다. 컴퓨터가 읽을 수 있는 기록매체는, 컴퓨터 시스템에 의하여 읽혀질 수 있는 데이터가 저장되는 모든 종류의 기 록장치를 포함한다. 이러한 컴퓨터가 읽을 수 있는 기록매체는 ROM, CD-ROM, 자기 테이프, 플로피디스크, 메모 리 카드, 하드 디스크, 광자기 디스크, 스토리지 디바이스 등의 비휘발성(non-volatile) 또는 비일시적인(non- transitory) 매체일 수 있으며, 또한 데이터 전송 매체(data transmission medium)와 같은 일시적인 (transitory) 매체를 더 포함할 수도 있다. 또한, 컴퓨터가 읽을 수 있는 기록매체는 네트워크로 연결된 컴퓨터 시스템에 분산되어, 분산방식으로 컴퓨터가 읽을 수 있는 코드가 저장되고 실행될 수도 있다. 본 명세서의 흐름도/타이밍도에서는 각 과정들을 순차적으로 실행하는 것으로 기재하고 있으나, 이는 본 개시의 일 실시예의 기술 사상을 예시적으로 설명한 것에 불과한 것이다. 다시 말해, 본 개시의 일 실시예가 속하는 기 술 분야에서 통상의 지식을 가진 자라면 본 개시의 일 실시예의 본질적인 특성에서 벗어나지 않는 범위에서 흐 름도/타이밍도에 기재된 순서를 변경하여 실행하거나 각 과정들 중 하나 이상의 과정을 병렬적으로 실행하는 것으로 다양하게 수정 및 변형하여 적용 가능할 것이므로, 흐름도/타이밍도는 시계열적인 순서로 한정되는 것은 아니다. 이상의 설명은 본 실시예의 기술 사상을 예시적으로 설명한 것에 불과한 것으로서, 본 실시예가 속하는 기술 분 야에서 통상의 지식을 가진 자라면 본 실시예의 본질적인 특성에서 벗어나지 않는 범위에서 다양한 수정 및 변 형이 가능할 것이다. 따라서, 본 실시예들은 본 실시예의 기술 사상을 한정하기 위한 것이 아니라 설명하기 위 한 것이고, 이러한 실시예에 의하여 본 실시예의 기술 사상의 범위가 한정되는 것은 아니다. 본 실시예의 보호 범위는 아래의 청구범위에 의하여 해석되어야 하며, 그와 동등한 범위 내에 있는 모든 기술 사상은 본 실시예의권리범위에 포함되는 것으로 해석되어야 할 것이다."}
{"patent_id": "10-2024-0101042", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 음성인식 시스템의 구성도이다. 도 2는 본 발명의 일 실시예에 따른 대규모 언어 모델에 기반한 자동학습장치를 개략적으로 나타낸 블록구성도 이다. 도 3은 본 발명의 일 실시예에 따른 새로운 의도를 탐지하는 과정을 나타내는 순서도이다.도 4는 본 발명의 일 실시예에 따른 오분류를 판단하는 과정을 나타내는 순서도이다. 도 5는 본 발명의 일 실시예에 따른 의도 분석 방법의 순서도이다. 도 6a 및 도 6b는 대규모 언어 모델의 한정된 입력 크기 안에서 효과적인 프롬프팅을 수행하기 위한 방법을 예 시적으로 나타낸 도면이다. 도 7은 본 개시에 따른 방법 또는 장치를 구현하기 위해 사용될 수 있는 예시적인 컴퓨팅 장치를 개략적으로 나 타낸 블록구성도이다."}
