{"patent_id": "10-2022-0021511", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0124335", "출원번호": "10-2022-0021511", "발명의 명칭": "흉부 X-ray 영상을 이용한 척추측만증 조기 스크리닝 시스템", "출원인": "건양대학교산학협력단", "발명자": "태기식"}}
{"patent_id": "10-2022-0021511", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "폐결핵 검사를 위해 촬영된 흉부 X-ray 영상으로 척추측만증 유무가 확인된 원영상을 수집하는 수집모듈(110);가우시안 필터를 기반으로 수집된 상기 원영상의 선명도를 높이는 전처리부(121)와, 전처리된 원영상을 척추증만증 유무를 기준으로 분류하여 훈련 데이터셋을 구축하는 분류부(122)를 구비하는 전처리모듈(120);상기 훈련 데이터셋을 CNN 모델을 통해 학습하여 예측정보를 생성하는 학습모듈(140);신규 입력된 흉부 X-ray 영상을 상기 예측정보를 통해 척추증만증 여부를 판단하는 판단모듈(150); 로 이루어지는 것을 특징으로 하는 흉부 X-ray 영상을 이용한 척추측만증 조기 스크리닝 시스템."}
{"patent_id": "10-2022-0021511", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 훈련 데이터셋에 포함된 영상의 각도 변위가 발생하지 않는 선에서 폭범위 및 밝기 변화를 적용시킨 영상을 랜덤하게 생성하여 상기 학습모듈(140)의 훈련 데이터셋으로 입력하는 영상데이터증가모듈(130); 을 더 포함하는 것을 특징으로 하는 흉부 X-ray 영상을 이용한 척추측만증 조기 스크리닝 시스템."}
{"patent_id": "10-2022-0021511", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 CNN 모델은 ResNet152 모델을 사용하는 것을 특징으로 하는 흉부 X-ray 영상을 이용한 척추측만증 조기 스크리닝 시스템."}
{"patent_id": "10-2022-0021511", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,상기 전처리부(121)는,수집된 영상을 분석하여 부적합 데이터를 선별 및 제외시키는 선별부(123)를 포함하는 것을 특징으로 하는 흉부X-ray 영상을 이용한 척추측만증 조기 스크리닝 시스템."}
{"patent_id": "10-2022-0021511", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 국내에서 건강검진을 통해 척추 전장 영상보다 비교적 높은 빈도로 촬영되는 흉부 X-ray 영상만으로도 척추측만증을 진단할 수 있도록 인공지능 알고리즘을 이용한 딥러닝 모델 학습에서 영상 전처리를 실시하고 결과 에 따른 평가가 가능한 흉부 X-ray 영상을 이용한 척추측만증 조기 스크리닝 시스템에 관한 것이다."}
{"patent_id": "10-2022-0021511", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 X-ray 영상 스크리닝 시스템에 관한 것으로 자세하게는, 국내에서 건강검진을 통해 척추 전장 영상보 다 비교적 높은 빈도로 촬영되는 흉부 X-ray 영상만으로도 척추측만증을 진단할 수 있도록 인공지능 알고리즘을 이용한 딥러닝 모델 학습에서 영상 전처리를 실시하고 결과에 따른 평가가 가능한 흉부 X-ray 영상을 이용한 척 추측만증 조기 스크리닝 시스템에 관한 것이다."}
{"patent_id": "10-2022-0021511", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "척추(spine)란 중추에 척추와 추간판 등으로 구성되어 경추(cervical), 흉추(thoracic), 요추(lumbar), 천추 (sacrum) 및 미추(coccyx)로 나눠져 중추신경계(central nervous system)와 말초신경계(peripheral nervous system)의 통로 역할을 하는 신체의 중심으로, 척추측만증이란 척추의 3차원적인 변형의 일환으로 척추뼈의 비정상적 회전 여부에 따라 신체적이거나 질병의 원인으로 인해 일시적인 변형이 발생하는 것을 말한다. 척추측만증은 비구조성 척추측만증(nonstructural scoliosis)과 척추 구조의 영구적 변형인 구조성 척추측만증 (structural scoliosis)으로 구분할 수 있고, 구조성 측만증은 다시 특발성, 선천성, 신경근육성 등으로 분류되 는데 이 중 가장 중요한 유형은 특발성 척추측만증(idiopathic scoliosis)으로 원인이 밝혀지지 않은 척추측만 증을 의미한다. 이는 전체 측만증의 80% 이상으로, 이는 모든 측만증에서 가장 높은 비율이며, 특히 청소년기에 서 발병률이 전 세계적으로는 0.5 ~ 5.2%, 국내에서는 연구 결과 3.26%로 점차적으로 증가되는 추세다. 이러한 청소년기 특발성 척추측만증(adolescent idiopathic scoliosis)은 일반적으로 잘못된 자세와 생활습관으 로 인해 주로 발생하며 초기 발견 시기가 치료에 중요한 영향을 미친다. 그러나 측만증 환자의 50% 이상이 초기에 진단된 척추측만증 진단을 자체를 부정하고 치료 시기를 미루는 경향 을 보이고 있어, 전체 측만증 환자 중 10%의 환자만이 의학적인 치료를 진행하고 있으며, 90%의 환자들은 검사 를 통한 관찰만을 시행하는 실정으로, 청소년기에 발생한 척추측만증이 올바른 관리 및 치료를 받지 못한 상황 에서 성인이 되어 외형적인 문제에 따른 부정적 영향을 받게 된다. 이러한 척추측만증의 판독 방법은 주로 척추 전장(spinal column) X-ray 영상을 통해 이뤄지며, 판독 방법으로 는 Cobb angle, 즉 가장 오목한 만곡에서 가장 기울어짐이 심한 상하 척추로부터 수직선상의 교차각을 측정하게 된다. 이 Cobb angle의 각도가 10도 이상일 경우 척추측만증이 있다고 진단하며, 척추 변형의 정도와 진행 위험도에 따라 치료 방법이 다르고, 조기 발견할수록 비수술적 치료의 효과가 높아진다. 다만, 수동으로 측정한 Cobb angle의 경우 영상의학과 전문의의 주관적인 경험에 의존하는 경우가 많기 때문에 최대 11.8도의 측정 오류가 발생하기도 한다. 이러한 오차는 특히 흉부 X-ray 단독 촬영 영상을 이용하여 척추측만증을 진단하는 경우 크게 일어난다. 도 1은 흉부 영상으로 척추측만증 판독 가능한 영상(A)과 흉요추영상을 통해서만 척추측만증으로 판독 가능한 영상(B)으로, 기존의 전통적인 수동적 척추측만증 진단 방법에서 흉부 X-ray 영상만으로는 흉부에 척추측만증이 있는 A와 같은 경우 척추측만증 식별이 가능하지만 흉부에는 측만증이 발생하지 않은 B와 같은 경우 흉부 X-ray 영상을 통한 척추측만증 판독에서 심한 오차 및 오진이 발생하였다. 그 중에서도 척추측만증이 가장 많이 발생하는 요추 부분에 영상이 없기에 척추측만증 환자를 정상군으로 분류 하거나, Cobb angle이 각도 측정의 부정확성으로 인해 척추측만증 위험도를 잘못 판단하는 경우가 적지않다. 특 히 청소년기 특발성 척추측만증의 경우 흉부 영상만으로 척추측만증 유무를 판독할 경우 27.9%의 정확도를 보여 줄 정도로 진단 결과에 대한 신뢰성이 부족하다. 특히 국내에서 건강검진의 경우 불필요한 검사와 의료 비용, 방사선 피폭으로 위험성으로 인해 폐결핵검사를 위 해 진행하는 흉부 촬영만을 진행하기 때문에 이러한 흉부 X-ray 영상만으로는 청소년기 특발성 척추측만증을 식 별하지 못하기 때문에 진단 및 치료 시기를 놓치는 경우가 발생하였다. 선행기술문헌 특허문헌 (특허문헌 0001) 대한민국 등록특허 제10-1968144호(2019.04.05)"}
{"patent_id": "10-2022-0021511", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 상기와 같은 문제를 해결하기 위하여 창출된 것으로, 본 발명의 목적은 딥러닝 모델의 학습을 통해 주기적으로 검진을 받는 폐결핵검사에서 촬영되는 흉부 X-ray 영상만으로도 척추측만증을 진단할 수 있도록 하 는 흉부 X-ray 영상을 이용한 척추측만증 조기 스크리닝 시스템을 제공하는 것이다."}
{"patent_id": "10-2022-0021511", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기와 같은 목적을 위해 본 발명은 폐결핵 검사를 위해 촬영된 흉부 X-ray 영상으로 척추측만증 유무가 확인된 원영상을 수집하는 수집모듈; 가우시안 필터를 기반으로 수집된 상기 원영상의 선명도를 높이는 전처리부와, 전 처리된 원영상을 척추증만증 유무를 기준으로 분류하여 훈련 데이터셋을 구축하는 제1분류부를 구비하는 전처리 모듈; 상기 훈련 데이터셋을 CNN 모델을 통해 학습하여 예측정보를 생성하는 학습모듈; 신규 입력된 흉부 X-ray 영상을 상기 예측정보를 통해 척추증만증 여부를 판단하는 판단모듈; 로 이루어지는 것을 특징으로 한다. 이때 상기 훈련 데이터셋에 포함된 영상의 각도 변위가 발생하지 않는 선에서 폭범위 및 밝기 변화를 적용시킨 영상을 랜덤하게 생성하여 상기 학습모듈의 훈련 데이터셋으로 입력하는 영상데이터증가모듈; 을 더 포함하는 것이 바람직하다. 또한, 상기 CNN 모델은 ResNet152 모델을 사용하는 것이 바람직하다. 또한, 상기 전처리부는, 수집된 영상을 분석하여 부적합 데이터를 선별 및 제외시키는 선별부를 포함하는 것이 바람직하다."}
{"patent_id": "10-2022-0021511", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명을 통해 국내에서 건강검진을 통해 척추 전장 영상보다 비교적 높은 빈도로 촬영되는 흉부 X-ray 영상만 으로도 척추측만증을 진단할 수 있으며, 질병 판독을 위한 추가적인 방사선 촬영을 하지 않아도 되므로 비용이 절감될 뿐 아니라 척추측만증의 조기진단을 위한 새로운 방안으로써 활용 가능하다. 특히 기존 흉부 X-ray 영상을 사람이 수동적으로 직접 분류하는 방식보다 딥러닝 모델을 이용한 학습을 통해 더 높은 정확도로 분류가 가능하며, 영상 전처리 및 Data Augmentation를 통해 딥러닝 모델의 학습 효율을 높일 수 있다."}
{"patent_id": "10-2022-0021511", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하 첨부된 도면을 참고하여 본 발명 흉부 X-ray 영상을 이용한 척추측만증 조기 스크리닝 시스템의 구성을 구 체적으로 설명한다. 도 2는 본 발명의 실시예에 따른 구성 및 연결관계를 나타낸 블록도, 도 3은 본 발명의 실시예에 따른 척추측만 증 조기 스크리닝 방법을 나타낸 순서도이다. 본 발명에서는 종래 방식에서 척추 전장 영상이 요구되거나 혹은 흉추에 척추측만증이 있어야만 Cobb angle 판 독 및 진단 가능한 한계를 극복하기 위해 국내에서 건강검진을 통해 척추 전장 영상보다 비교적 높은 빈도로 촬 영되는 흉부 X-ray 영상만으로도 척추측만증을 진단할 수 있도록 하며, 이를 위한 주요 구성으로 수집모듈과, 전처리모듈과, 영상데이터증가모듈과 학습모듈 및 판단모듈을 구비한다. 상기 수집모듈은 폐결핵 검사를 위해 촬영된 흉부 X-ray 영상으로 척추측만증 유무가 확인된 원영상을 수 집하는 하는 구성이다. 본 발명의 실시예에서는 정형외과 전문의로부터 척추측만증 유무가 확인된 224×224 크 기의 흉부 X-ray 영상 121장을 사용하였다. 또한, 종래에는 X-ray에 추가적인 전처리를 진행하지 않은 상태에서 활용하였으나 본 발명에서는 딥러닝 모델 학습 이전에 노이즈 제거 및 데이터 정리를 위해 전처리 과정을 진행하며, 이 과정을 통해 흉부 X-ray 영상에서 측만증 판독에 불필요한 조직 부분을 흐릿하게 하거나 제거하며 척추의 윤곽은 강조한 학습(train) 및 검증 (test) 영상을 얻을 수 있다. 이를 위한 상기 전처리모듈은 가우시안 필터를 기반으로 수집된 상기 원영상의 선명도를 높이는 전처리부 와, 전처리된 원영상을 척추증만증 유무를 기준으로 분류하여 훈련 데이터셋을 구축하는 분류부 및 수집된 영상을 분석하여 부적합 데이터를 선별 및 제외시키는 선별부를 구비한다. 구체적으로 상기 전처리부는 Gaussian Sharpening, Multi-frequency enhancement image를 사용하게 된다. Gaussian Sharpening은 Gaussian Filter를 통해 원본 영상과 Gaussian Smoothing 작업을 거친 차영상을 다시 원본 영상에 더하는 기법으로 이를 통해 영상이 선명해지는 효과를 얻을 수 있다. 여기서 Gasussian Filter에서 생성되는 값은 2D Gaussian [수학식 1]을 이용하여 생성된 필터로서 원본 영상에 합성곱 하여 생성한 차영상을 원래 영상에 더하면서 곱해지는 상수에 따라 결과를 도출하며, 영상의 명도, 해상도와 같은 특성에 따라 상수는 조절될 수 있다. [수학식 1]에서 는 분산을 나타낸다. [수학식 1]"}
{"patent_id": "10-2022-0021511", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "앞서 설명한 Gaussian Filter와 같은 방법들은 단순히 필터 자체로서 사용하기보다는 다른 필터와의 합성곱을 통해 영상을 계산식화 하여 함께 활용할 때 더 좋은 결과를 얻을 수 있다. 그 기법 중 하나로 본 발명에서는 Multi Frequency 영상 선명화 작업을 통해 더욱 딥러닝 모델학습에 효과적인 결과를 얻어낼 수 있도록 하였다. Multi-frequency enhancement image란 Unsharp Mask 기법을 통해 원본 영상에서 Gaussian Smoothing 작업을 거 친 영상을 뺀 차영상을 원본 영상에 다시 더하는 기법으로 반복함으로써 얻게 되는 선명한 영상을 의미한다. 이렇게 전처리 된 영상들을 Sigmoid 함수 변환 식인 [수학식 2]를 이용하여 입력영상 s의 결과를 결과 영상 r로 반환하였다. 여기서 a는 기울기, c는 평균값을 나타내며, 도 4의 함수 곡선에서 보이는 바와 같이 두 개의 값을 조정하여 영상의 특정부분을 밝게 또는 어둡게 조절할 수 있다. 또한, Sigmoid 함수변환의 결과 영상은 0~1 사 이로 정규화되어있는 것이 특징이다. 이를 사용하여 흉부 영상에서 높은 레벨의 픽셀을 가지는 뼈 부분은 더욱 밝게, 낮은 레벨의 픽셀을 가지는 조직부분은 어둡게 처리하여 척추를 강조할 수 있게 된다. [수학식 2]"}
{"patent_id": "10-2022-0021511", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "이렇게 Multi Frequency 영상 선명화 작업과 Sigmoid 함수변환을 마친 결과 영상을 최종적으로 원영상과 합치는 데 사용되는 Unsharp Mask 필터 또한 영상을 선명하게 만드는 작업이다. 흐릿하거나 선명하지 않은(unsharp) 영 상을 사용하여 원본 영상의 Mask를 만들어내는 원리로 작용한다. 도 5는 원본 영상(A)과 가우시안 필터링 영상(B), 최종 전처리 영상(C)으로, 원본 영상과 전처리 과정에 따른 결과 영상을 보여준다. 이후 상기 선별부를 통해 훈련에 부적합한 데이터를 선별 후 제외시키게 되며, 선별 기준으로는 척추 부분 이 명확하게 확인되지 않거나, 시술 등을 통해 변형이 발생한 영상 내지는 아동이나 기형 등 정상적이지 않은 대상으로부터 취득한 영상을 부적합 데이터로 선별할 수 있으며, 본 발명의 실시예에서는 부적합데이터를 제외한 비측만증 64장, 측만증 47장으로 총 111장의 데이터를 생성하였다. gray scale 영상 데이터로 추후 딥러닝 모델의 학습에 사용하기 위해 Normal image와 Scoliosis image를 분류 하여 비측만증 49장, 측만증 33장으로 Train 데이터 셋을 구축하였다. 또한, 학습결과의 검증을 위한 Test 데이 터셋의 경우 16장의 Normal image와 14장의 Scoliosis image로 구성하였다. [표 1]은 각 데이터 셋의 분포와 해당 영상의 개수를 나타내며, 도 6은 정상군 학습데이터(A), 측만증 학습데이터(B), 정상군 검증데이터(C), 측 만증 검증데이터(D)의 전처리 영상으로 전처리 과정을 거친 정상, 비정상 흉부영상 데이터를 보여준다. 표 1 Train Image Test Image Normal image 49 15 Scololsos image 33 14 Total image 82 29 딥러닝 모델 학습은 Over-fitting을 방지하기 위해 주로 Big-data 와 같이 활용된다. 그러나 의료 영상과 같은 데이터에서는 Big-data에 접근하기 위한 권한 발급이 쉽지 않기 때문에 데이터가 제한되는 경우가 많다. 이러한 문제를 해결하기 위해 Data Augmentation을 활용하며, 영상 데이터에서는 Image generation을 통해 이 문제를 해결한다. 이를 위해 상기 영상데이터증가모듈은 상기 훈련 데이터셋에 포함된 영상의 각도 변위가 발생하지 않는 선 에서 폭범위 및 밝기 변화를 적용시킨 영상을 랜덤하게 생성하여 상기 학습모듈의 훈련 데이터셋으로 입력 하게 된다. 단순하게는 영상의 기하학적 구조의 변화를 통해 영상이 가지고 있는 구조를 변화시키는 간단한 방식부터 영상 의 특징 부분을 추출해내는 Spatial-Level, 픽셀 단위의 컬러값을 변환시키는 Pixel-Level, 영상의 NxN 값을 랜 덤하게 섞어주는 PatchShuffle 기법, 영상의 객체정보를 유지하기 위해 위치적인 구조를 고정한 상태로 다른 영 상과 Mix를 진행하는 Puzzle Mix 방식 등 다양한 Augmentation 방안을 통해 딥러닝 모델 학습의 효율을 올리는 연구가 진행되고 있다. 도 7은 전처리 영상을 바탕으로 한 생성 영상의 예시, [표 2]는 본 발명에 사용된 전처리 및 영상 생성 이후 데 이터 분포이다. 본 발명에서는 영상에서 가장 중요한 특징인 척추의 각도의 손실이 발생할 경우 학습에 문제가 될 수 있다고 판 단하였다. 따라서 영상 자체 영상의 각도 변위가 발생하지 않은 선에서 영상의 width range를 최대 30%까지 변 화시키면서 brightness를 40% 정도까지 변화시킨 영상을 랜덤하게 생성하여 원 영상의 20배수로 Image Generation을 진행하여 원본 영상과 같이 학습에 사용하였다. 표 2 Train Image Test Image Normal image 1,029 315 Scololsos image 693 294 Total image 1,722 609 상기 학습모듈은 상기 훈련 데이터셋을 CNN 모델을 통해 학습하여 예측정보를 생성하는 구성으로, 본 발명 에서는 딥러닝 모델로 VGG16, ResNet152, EfficientNet B0를 검토하였다. VGG16은 16개의 layer를 가진 VGG 모델의 일환으로 모든 Convolution layer에서 3x3 Filter를 학습 매개변수로 사용하여 기존 모델들에 비해 깊은 신경망을 학습할 수 있다는 특징을 가진다. 3-layer 3x3 Filtering을 통해 Convolution 연산에서 포함되는 ReLU함수의 비선형성을 증가시켜 모델의 특징 식별성이 증가되었고 학습 파라미 터의 감소를 통해 작은 필터를 사용하였음에도 영상 분류의 정확도는 비약적으로 개선된 모델이다. 본 발명에서 는 13개의 Convolution layer와 3개의 Fully-connected later로 구성되며 출력층에서는 Classification을 위한 Softmax 함수를 사용하였다. ResNet152는 이전에 사용되던 모델들 보다 훨씬 더 심층적인 네트워크의 학습을 용이하게 하기 위한 Residual learning framework(잔여 학습 프레임워크라)는 새로운 방법으로 기존보다 더욱 심층적인 신경망 구조를 가진다 는 것이 특징적이다. 일반적으로 입력 x를 받아 2개의 weight layer를 거쳐 출력된 결과가 다음 layer의 입력되 는 구조와 는 달리 ResNet은 layer의 입력을 layer의 출력에 바로 연결시키게 된다. 이는 모델의 파라미터를 최 적화하기 쉽고 상당히 깊어지는 모델 구조를 통해 보다 높은 정확도를 얻을 수 있게 하는 효과를 나타낸다. 본 발명에는 그 중에서도 모델의 layer 층의 깊이라는 특성이 학습에 있어서 어떠한 영향을 끼치는지 알아보기 위 해 최대 152개의 layer로 구성된 ResNet152 모델을 학습에 활용하였다. 기존 딥러닝 모델의 경우 일반적으로 정확도의 향상을 위해 모델의 Depth, Width, Resolution을 조절하였으며, 이러한 방식이 수동적으로 이뤄졌기 때문에 최적의 성능을 얻기 쉽지 않다는 문제가 있었다. 이러한 문제를 해 결하고자 EfficientNet은 Depth, Width, Resolution가 서로 비례적인 관계를 있다는 것을 실험으로 검증하고 세심하게 조절하여 보다 효율적으로 확장을 통해 성능이 향상된 모델이다. 이러한 방식 구조를 Compound scaling이 라고 한다. 이를 본 발명에 적용하여 입력 데이터로 사용되는 흉부영상에서 척추의 미세한 회전의 변화를 효과적으로 감지 할 수 있다고 판단하여 해당 모델을 선정하였다.이러한 EfficientNet 모델은 데이터 크기에 따라 B0 - B7으로 구성하였으며, 본 발명에서는 224×224 영상 데이터를 사용하였기 때문에 B0 모델을 학습에 활용하였다. 본 발명의 실시예에서 딥러닝 모델 학습 환경은 GTX2080, tensorflow 2.3.1, Keras 2.4.3 환경 내에서 진행하 였다. 학습을 위한 데이터 전처리 유무 및 Generation 영상 사용 유무에 따라 총 4가지 Type을 설정하였다. - Type 1: 전처리를 거치지 않은 원영상을 학습시켜 원영상의 분류 정확 도 확인 - Type 2: 전처리 영상 학습 모델에 전처리 영상을 통한 정확도 확인. - Type 3: 전처리 영상에 추가 생성한 Generation 영상을 추가하여 학습 을 진행 후 전처리 영상만으로 정확도 확인 - Type 4: Type 3와 같이 학습을 진행 후 모델 정확도 확인에 전전처리 영상에 추가 생성한 Generation 영상을 추가하여 사용 이때 정확도는 Epoch 1,000회 학습시킨 결과를 50회 반복 학습에 대한 정확도의 평균값을 도출하였다. 또한, 학 습 데이터의 학습 순서는 랜덤으로 설정하였다. 최종적으로 학습 데이터 상태에 따른 각 모델에서의 학습 정확 도의 평균값의 차이를 확인하였다. 이후 상기 판단모듈()을 통해 신규 입력된 흉부 X-ray 영상을 상기 예측정보를 통해 척추증만증 여부를 판단하 게 된다. 본 발명에서 사용된 데이터 및 반복 실험을 통한 실험결과의 유효성을 검증하기 위한 통계 분석은 SPSS (version 25.0; SPSS Inc, Chicago, IL) 소프트웨어를 통해 진행되었다. 실험 결과의 동질성 검증은 One-way ANOVA(Analysis of Variance)를 통해 이뤄졌으며, 동일성 검증은 독립 표본 T-test를 통해 이뤄졌다. 통계적 유의 수준은 p < .05로 정의되었다. [표 3]은 Type 1 학습 구조에서 각 모델별 정확도이다. 결과적으로 Type 1의 경우 경우 표 3와 같이 VGG16모델은 51.7%, ResNet152는 59.8%의 정확도를 보여주었으며, 가장 높은 결과를 보여준 EfficientNet B0의 경우 55.8%의 평균 정확도를 보였다. 다만 VGG16 모델을 제외하면 통계적으로 유의함을 보여주지 못하였다. 이러한 결과는 기존 흉부 X-ray 영상을 눈으로 판독하여 확인할 경우 의 27.9%의 정확도를 훨씬 상회하는 수치이다. 표 3 Accuracy Standard deviation p-value VGG16 51.7% ±0.001 <.05 ResNet152 59.8% ±0.129 >.05 EfficientNet B0 55.8% ±0.169 >.05[표 4]는 Type 2 학습 구조에서 각 모델별 정확도로서, Type 2 학습의 결과는 Type 1에 결과와 비교하여 영상의 전처리를 진행한 경우 척추측만증 분류 정확도가 소폭 정확도가 상승하였음을 [표 4]와 같은 내용을 통해 확인 할 수 있었다. 다만, VGG16 모델같은 경우는 전처리 전과 후 사이 변화가 없는 것처럼 확인되나 실제 결과를 확 인할 경우 학습이 제대로 이뤄지지 않아 모든 영상을 정상군으로 분류하였기 때문에 정확도가 변화하지 않는 것 을 확인하였다. 표 4 Accuracy Standard deviation p-value VGG16 51.7% ±0.001 <.05 ResNet152 63.5% ±0.096 >.05 EfficientNet B0 68.7% ±0.074 <.05 [표 5]는 Type 3 학습 구조에서 각 모델별 정확도로서, Generation 진행한 영상을 학습 데이터를 추가한 Type 3 의 결과를 살펴보면 학습 데이터와 검증 데이터와의 극심한 데이터 차이로 인해 기존에 전처리 영상의 학습 결 과를 보여주었던 Type 2와 비교하여 정확도가 감소함을 확인할 수 있었다. 학습 정확도도 일편 확률적으로 한쪽 으로만 분류되는 모습을 보여주었다. VGG16 모델의 경우 여전히 학습이 진행되지 않음을 확인하였다. 표 5 Accuracy Standard deviation p-value VGG16 51.7% ±0.001 <.05 ResNet152 49.6% ±0.018 <.05 EfficientNet B0 51.1% ±0.042 <.05 도 8은 Type 4 학습에서의 학습률에 따른 Accuracy와 Loss 변화를 나타낸 그래프, [표 6]은 Type 4 학습 구조에 서 모델별 정확도로서, 마지막으로 Generation 진행한 영상을 학습 데이터에 마찬가지로 Generation 작업을 진 행하여 추가한 검증 데이터로 검증을 진행한 Type 4의 결과를 확인하면 이전 그 어떠한 경우보다도 높은 결과가 나타났음을 확인할 수 있었다. 특히 ResNet152 모델의 경우 정확도에 큰 상승을 확인할 수 있었다. 이에 대해 결과가 증가하게 된 이유를 확인하고자 세부적으로 결과 모델의 분석을 진행한 결과 흥미로운 점을 발견하였다. 표 6 Accuracy Standard deviation p-value VGG16 51.7% ±0.001 <.05 ResNet152 85.9% ±0.057 <.05 EfficientNet B0 71.7% ±0.033 <.05 도 9는 각 모델에 대한 모든 Type에서의 학습 결과를 나타낸 그래프로, 앞서 언급한 각 타입 및 모델에 따른 결 과의 정확도를 나타내고 있다. 도 10은 인공지능 모델이 예측한 Label과 실제 영상의 Label을 나타낸 그래프로, 이번 결과에서 Generation으로 생성된 검증 데이터와 모델이 예측한 결과를 그래프로 나타낸 것이다. 단, 여기서 학습이 이뤄지지 않아 결과의 의미가 없는 VGG16 모델의 결과는 제외하였다. 그래프의 상단은 딥러닝 모델이 예측한 결과이며 하단은 학습에 서 사용된 검증 데이터의 구조이다. 이를 보면 앞서 진행한 학습 방법의 결과보다 높은 정확도를 보여주는 것과 마찬가지로 정상군과 측만증군의 분류에 있어서 분류가 일부 진행되는 것을 확인할 수 있었다. 도 11은 원본 영상과 Generation 영상의 검증 결과 및 정확도로서, 이러한 이유로는 도 11처럼 전처리 영상과 Generation 영상을 함께 분류하는데 있어서 정상군의 경우 Generation 영상의 대부분을 정상으로 분류하며 측만 증 영상의 경우 이와 반대로 원본 영상으로는 분류하지 못한 영상의 Generation 영상을 대부분 측만증으로 분류 하는 것으로 확인되었다. 정리하면 Type 1과 Type 2의 결과를 서로 비교한다면 전처리 영상을 학습시킴으로서 딥러닝 모델의 정확도의 향 상을 기대할 수 있다. 하지만, 그 차이가 미비하며, 원영상을 그대로 학습시킨 결과는 통계적으로도 그 유의성 을 보여주지 못하였다. 이러한 이유로는 학습 결과에 있어서 손실률이 매우 높으며, 정확도의 편차가 매우 크게나타날 정도로 학습의 안정성이 부족하기 때문으로 확인된다. 이러한 모델별로 학습을 진행하는 데 있어서 결과 값의 편차는 원영상을 학습시키는데 있어서 매우 큰 값으로 존재하였으나 이와 반대로 VGG16 모델의 경우에는 큰 차이는 발견하지 못 하였다. 이러한 이유로는 딥러닝 학습에 있어서 모델의 구조가 너무 단순하여 Under- fitting이 발생하였기 때문으로 이러한 분석은 동일 데이터로 학습을 진행한 ResNet152 및 EfficientNet B0 모 델에서는 발생하지 않은 문제라는 것을 근거로 말할 수 있다. 이후 Data Augmentation을 통해 데이터의 크기를 증가시킨 후 학습을 진행한 Type 3 및 Type 4를 통해 척추측만 증 진단 모델의 정확도의 향상을 바랄 수 있음을 확인할 수 있는 결과를 확인하였다. 이러한 결과를 기존 기술 과 비교해본다면 학습 데이터의 비율의 문제로 인해 검증 데이터가 학습 데이터와 비교하여 너무 큰 비율적인 차이(98.3:1.7)를 보였기 때문에 생긴 것으로 확인된다. 이뿐만 아니라 Type 1 및 Type 2과 마찬가지로 영상 전 처리를 통해 딥러닝 모델의 학습 효율이 더 높아질 수 있음을 확인하였다. 또한 데이터의 크기를 증가시킨다면 더 좋은 결과를 도출해낼 수 있을 것이다. 다만 Type 2 방식와 Type 4 방식을 ResNet152와 EfficientNet B0 모델을 통해 비교하면 두 모델 모두 정확도가 Type 2에 비해 Type 4 방식에서 증가하였으나 그 증가폭이 ResNet152 모델에서 더 크게 나타남을 확인할 수 있 다. 이러한 결과를 바탕으로 기존의 82장이라는 학습용 영상 데이터로는 ResNet152 모델에서 학습을 진행하는데 있어서 Over-fitting이 일부 발생하였음을 알 수 있다. 이러한 문제가 Data Augmentation을 통해 해결되었기 때 문에 Type 4 방식에서는 그 정확도가 크게 향상될 수 있었다. 본 발명에서는 흉부 X-ray를 통한 척추측만증의 판독을 기준으로 하였으며 기술의 개선을 통해 판독이 충분히 가능함을 보여주었다. 물론 2차원 영상에서만 확인할 수 있는 척추의 만곡만을 판별할 수 있다는 한계점이 있어 85.96% 정도의 정확도를 보여주고 있으나 일반적으로 건강검진을 위해 촬영되는 흉부 X-ray를 통해 청소년기 특 발성 척추측만증 위험군 혹은 예상군으로 식별을 진행하는데 유용하게 활용될 수 있으며, 조기 진단 및 비수술 적 치료의 효율성을 크게 증가시킬 수 있게 된다. 본 발명의 권리는 위에서 설명된 실시 예에 한정되지 않고 청구범위에 기재된 바에 의해 정의되며, 본 발명의 분야에서 통상의 지식을 가진 자가 청구범위에 기재된 권리범위 내에서 다양한 변형과 개작을 할 수 있다는 것 은 자명하다."}
{"patent_id": "10-2022-0021511", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 흉부 영상으로 척추측만증 판독 가능한 영상(A)과 흉요추영상을 통해서만 척추측만증으로 판독 가능한 영상(B), 도 2는 본 발명의 실시예에 따른 구성 및 연결관계를 나타낸 블록도, 도 3은 본 발명의 실시예에 따른 척추측만증 조기 스크리닝 방법을 나타낸 순서도, 도 4는 Sigmoid 함수의 곡선 그래프, 도 5는 원본 영상(A)과 가우시안 필터링 영상(B) 최종 전처리 영상(C), 도 6은 정상군 학습데이터(A), 측만증 학습데이터(B), 정상군 검증데이터(C), 측만증 검증데이터(D)의 전처리 영상, 도 7은 전처리 영상을 바탕으로 한 생성 영상의 예시, 도 8은 Type 4 학습에서의 학습률에 따른 Accuracy와 Loss 변화를 나타낸 그래프, 도 9는 각 모델에 대한 모든 Type에서의 학습 결과를 나타낸 그래프, 도 10은 인공지능 모델이 예측한 Label과 실제 영상의 Label을 나타낸 그래프, 도 11은 원본 영상과 Generation 영상의 검증 결과 및 정확도이다."}
