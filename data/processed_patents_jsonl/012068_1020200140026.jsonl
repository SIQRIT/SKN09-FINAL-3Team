{"patent_id": "10-2020-0140026", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2021-0073442", "출원번호": "10-2020-0140026", "발명의 명칭": "변형가능한 3D 움직임 모델을 생성하는 방법 및 시스템", "출원인": "주식회사 일루니", "발명자": "박병화"}}
{"patent_id": "10-2020-0140026", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "변형가능한 3D 움직임 모델을 생성하는 방법에 있어서,사용자를 포함한 이미지에 대한 정보를 수신하는 단계;상기 수신된 이미지에 대한 정보를 기초로 변형가능한(morphable) 3D 움직임 모델을 생성하는 단계;미리 저장된 콘텐츠 스타일 중 대상 콘텐츠 스타일을 선택하는 단계; 및상기 대상 콘텐츠 스타일을 상기 생성된 변형가능한 3D 움직임 모델에 적용하는 단계를 포함하는, 변형가능한 3D 움직임 모델 생성 방법."}
{"patent_id": "10-2020-0140026", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 개시는 변형가능한 3D 움직임 모델을 생성하는 방법에 관한 것이다. 사용자를 포함한 이미지로부터 변형가능 한 3D 움직임 모델을 생성하는 방법은 사용자를 포함한 이미지에 대한 정보를 수신하는 단계, 수신된 이미지에 대한 정보를 기초로 변형가능한(morphable) 3D 움직임 모델을 생성하는 단계, 미리 저장된 콘텐츠 스타일 중 대 상 콘텐츠 스타일을 선택하는 단계 및 대상 콘텐츠 스타일을 생성된 변형가능한 3D 움직임 모델에 적용하는 단계 를 포함할 수 있다."}
{"patent_id": "10-2020-0140026", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 컴퓨터 비전 기술, 그래픽스, 머신러닝 기술 등을 이용하여 변형가능한 3D 움직임 모델을 생성하는 방법 및 시스템에 관한 것으로서, 보다 상세하게는, 사용자를 포함한 이미지에 대한 정보를 기초로 변형가능한 (morphable) 3D 움직임 모델을 생성하고, 대상 콘텐츠 스타일을 생성된 변형가능한 3D 움직임 모델에 적용하는 방법 및 시스템에 관한 것이다."}
{"patent_id": "10-2020-0140026", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "최근 프로세서, 메모리 및 카메라 등의 하드웨어가 급속히 발전됨에 따라, 인공지능(AI), 가상현실(VR), 증강현 실(AR) 및 혼합현실(MR) 등의 기술이 발전되고 각광받고 있다. 예를 들어, 이러한 AI기술은 이미지 처리 분야 에 적용하는 연구가 활발히 이루어지고 있다. 특히, 3D(Dimensional) 모델 또는 이미지를 생성하고 변형하는 기술에 AI 기술이 적용되고 있다. 한편, 종래의 3D 모델 및 이미지를 생성하고 변형하는 기술에 있어서, 사용자 맞춤형 3D 모델을 생성하는 기술 이 개발되고 있다. 예를 들어, 제작된 애니메이션에 사용자 얼굴을 포함한 이미지를 적용하는 시도가 있어왔다. 그러나, 이러한 사용자 얼굴이 적용된 애니메이션은 사용자 얼굴 이미지와 애니메이션에 포함된 콘 텐츠 사이의 상이함 때문에, 부자연스럽게 생성될 수 있다."}
{"patent_id": "10-2020-0140026", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 개시에 따른 방법 및 시스템은 외부의 콘텐츠 스타일을 사용자 맞춤형 변형가능한3D 움직임 모델에 적용하여, 외부의 콘텐츠 스타일을 반영한 사용자 콘텐츠를 생성할 수 있다. 본 개시에 따른 방법 및 시스템은, 커스터마이징 정보, 특정 표정 정보 및 블렌드 형태에 대한 수치 정보 중 적 어도 하나를 수신하고, 수신된 정보를 변형가능한 3D 움직임 모델에 적용할 수 있다. 본 개시에 따른 방법 및 시스템은, 하나 이상의 국소 객체에 대한 변형가능한 3D 움직임 모델을 제공할 수 있으 며, 국소 객체의 크기 및 경사 부분이 변형가능한 3D 움직임 모델의 대응 부분에 맞추도록 보정할 수 있다. 본 개시에 따른 방법 및 시스템은, 3D 액세서리 모델 및 상기 3D 머리카락 모델 중 적어도 하나의 모델을 제공 할 수 있으며, 변형가능한3D 움직임 모델의 기준 포인트 변형에 대응되도록 제공된 모델에 포함된 기준 포인트를 변형시킬 수 있다."}
{"patent_id": "10-2020-0140026", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 개시는 방법, 시스템, 장치 또는 명령어들을 저장하는 컴퓨터 판독가능 저장 매체를 포함한 다양한 방식으로 구현될 수 있다. 본 개시의 일 실시예에 따른 변형가능한 3D 움직임 모델을 생성하는 방법에 있어서, 사용자를 포함한 이미지에 대한 정보를 수신하는 단계, 수신된 이미지에 대한 정보를 기초로 변형가능한(morphable) 3D 움직임 모델을 생 성하는 단계, 미리 저장된 콘텐츠 스타일 중 대상 콘텐츠 스타일을 선택하는 단계 및 대상 콘텐츠 스타일을 생 성된 변형가능한 3D 움직임 모델에 적용하는 단계를 포함한다. 일 실시예에 따르면, 대상 콘텐츠 스타일을 상기 생성된 변형가능한 3D 움직임 모델에 적용하는 단계는, 블렌드 형태(blend shape)에 대한 수치를 수신하는 단계 및 수신된 블렌드 형태에 대한 수치에 따라 콘텐츠 스타일의 적용 정도(Level)를 조정하는 단계를 포함한다. 일 실시예에 따르면, 대상 콘텐츠 스타일을 생성된 변형가능한 3D 움직임 모델에 적용하는 단계는, 커스터마이 징 정보에 기초하여 대상 콘텐츠 스타일이 적용된 상기 변형가능한 3D 움직임 모델을 변형하는 단계를 포함한다. 일 실시예에 따르면, 대상 콘텐츠 스타일을 생성된 변형가능한 3D 움직임 모델에 적용하는 단계는, 특정 표정을 가진 모델의 형태 정보를 이용하여 특정 표정이 대상 콘텐츠 스타일이 적용된 변형가능한 3D 움직임 모델에 반 영되도록 변형가능한 3D 움직임 모델을 변형하는 단계를 포함한다. 일 실시예에 따르면, 미리 저장된 콘텐츠 스타일 중 대상 콘텐츠 스타일을 선택하는 단계는, 미리 저장된 콘텐 츠 스타일 중 복수의 대상 콘텐츠 스타일을 선택하는 단계를 포함하고, 대상 콘텐츠 스타일을 생성된 변형가능 한 3D 움직임 모델에 적용하는 단계는, 선택된 복수의 대상 콘텐츠 스타일을 생성된 변형가능한 3D 움직임 모델 에 적용하는 단계를 포함한다. 일 실시예에 따르면, 사용자를 포함한 이미지는 사용자 내에 포함된 하나 이상의 국소(local) 객체를 포함하는 이미지를 포함하고, 변형가능한 3D 움직임 모델은 사용자 내에 포함된 하나 이상의 국소 객체에 대한 변형가능 한 3D 움직임 모델을 포함한다. 일 실시예에 따르면, 대상 콘텐츠 스타일을 생성된 변형가능한 3D 움직임 모델에 적용하는 단계는, 대상 콘텐츠 스타일에 포함된 국소 콘텐츠 스타일의 크기 및 경사(gradient)를 변형가능한 3D 움직임 모델에 포함된 대응 객 체에 맞추도록 보정하는 단계 및 보정된 국소 콘텐츠 스타일을 변형가능한 3D 움직임 모델에 포함된 대응 객체 에 적용하는 단계를 포함한다. 일 실시예에 따르면, 대상 콘텐츠 스타일에 대응하는 변형가능한 3D 움직임 모델은 3D 액세서리 모델 및 3D 머 리카락 모델 중 적어도 하나를 포함하고, 대상 콘텐츠 스타일을 생성된 변형가능한 3D 움직임 모델에 적용하는 단계는, 대상 콘텐츠 스타일이 적용된 변형가능한 3D 움직임 모델의 형태의 변형에 따라 3D 액세서리 모델 및 3D 머리카락 모델 중 적어도 하나의 형태를 변형하는 단계를 포함한다. 일 실시예에 따르면, 대상 콘텐츠 스타일이 적용된 변형가능한 3D 움직임 모델의 형태의 변형에 따라 3D 액세서 리 모델 및 3D 머리카락 모델 중 적어도 하나의 형태를 변형하는 단계는, 대상 콘텐츠 스타일이 적용된 변형가 능한 3D 움직임 모델의 기준 포인트의 변형에 대응되도록 3D 액세서리 모델 및 3D 머리카락 모델 중 적어도 하 나에 포함된 기준 포인트를 변형시키는 단계를 포함한다. 일 실시예에 따르면, 수신된 이미지에 대한 정보를 기초로 변형가능한 3D 움직임 모델을 생성하는 단계는, 사용 자를 포함한 2D 이미지를 학습된 인공신경망 모델에 입력하여 변형가능한 3D 움직임 모델을 출력하는 단계를 포 함한다. 일 실시예에 따르면, 사용자를 포함한 이미지에 대한 정보를 수신하는 단계는, 사용자를 포함한 3D 이미지에 대 한 정보를 수신하는 단계를 포함하고, 수신된 이미지에 대한 정보를 기초로 변형가능한 3D 움직임 모델을 생성 하는 단계는, 사용자를 포함한 3D 이미징에 대한 정보를 이용하여 변형가능한 3D 움직임 모델을 생성하는 단계 를 포함한다.일 실시예에 따르면, 대상 콘텐츠 스타일을 생성된 변형가능한 3D 움직임 모델에 적용하는 단계는, 대상 콘텐츠 스타일로부터 텍스처를 추출하는 단계, 추출된 텍스처의 데이터 분포를 분석하는 단계 및 추출된 텍스처의 데이 터 분포를 생성된 변형가능한 3D 움직임 모델의 텍스처에 적용하는 단계를 포함한다. 다른 실시예에 따르면, 변형가능한 3D 움직임 모델을 생성하는 방법을 컴퓨터에서 실행시키기 위한 컴퓨터 프로 그램이 기록된 컴퓨터로 판독 가능한 기록매체가 제공된다. 본 개시의 또 다른 실시예에 따르면, 변형가능한 3D 움직임 모델을 생성하는 시스템은 사용자를 포함한 이미지 에 대한 정보를 수신하도록 구성된 통신부, 복수의 콘텐츠 스타일을 저장하도록 구성된 저장부, 수신된 이미지 에 대한 정보를 기초로 변형가능한(morphable) 3D 움직임 모델을 생성하고, 저장부에 저장된 복수의 콘텐츠 스 타일 중 적어도 하나의 스타일을 대상 콘텐츠 스타일로서 선택하고, 대상 콘텐츠 스타일을 생성된 변형가능한 3D 움직임 모델에 적용하도록 구성된 제어부를 포함한다. 본 개시의 또 다른 실시예에 따르면, 변형가능한 3D 움직임 모델을 생성하는 시스템의 통신부는 블렌드 형태에 대한 수치를 수신하도록 더 구성되고, 제어부는 수신된 블렌드 형태에 대한 수치에 따라 상기 콘텐츠 스타일의 적용 정보를 조정하도록 더 구성된다."}
{"patent_id": "10-2020-0140026", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 개시의 일부 실시예들에 따르면, 사용자의 신체의 적어도 일부에 대응하는 변형가능한 3D 움직임 모델이 생 성되고, 이러한 3D 움직임 모델에 특정 콘텐츠의 스타일이 적용되어, 사용자 3D 움직임 모델에 그러한 콘텐츠를 제공한 제작사 또는 제작자의 콘텐츠 스타일이 적용될 수 있다. 이에 따라, 제작사 또는 제작자의 콘텐츠 스타 일이 적용된 하나 이상의 사용자 콘텐츠는 제작사 또는 제작자가 만든 콘텐츠와 동일 또는 유사한 스타일이 적 용될 수 있다. 본 개시의 일부 실시예에 따르면, 특정 콘텐츠 스타일이 반영된 변형가능한 3D 움직임 모델에 특정 표정이 적용 될 수 있기 때문에, 특정 콘텐츠 스타일의 제작자 또는 제작사가 이러한 특정 표정을 제공하지 않더라도, 이러 한 표정이 반영된 애니메이션 제작이 손쉽게 가능하다. 본 개시의 효과는 이상에서 언급한 효과로 제한되지 않으며, 언급되지 않은 다른 효과들은 청구범위의 기재로부 터 당업자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2020-0140026", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 본 개시의 실시를 위한 구체적인 내용을 첨부된 도면을 참조하여 상세히 설명한다. 다만, 이하의 설명에 서는 본 개시의 요지를 불필요하게 흐릴 우려가 있는 경우, 널리 알려진 기능이나 구성에 관한 구체적 설명은 생략하기로 한다. 첨부된 도면에서, 동일하거나 대응하는 구성요소에는 동일한 참조부호가 부여되어 있다. 또한, 이하의 실시예 들의 설명에 있어서, 동일하거나 대응하는 구성요소를 중복하여 기술하는 것이 생략될 수 있다. 그러나 구성요 소에 관한 기술이 생략되어도, 그러한 구성요소가 어떤 실시예에 포함되지 않는 것으로 의도되지는 않는다. 개시된 실시예의 이점 및 특징, 그리고 그것들을 달성하는 방법은 첨부되는 도면과 함께 후술되어 있는 실시예 들을 참조하면 명확해질 것이다. 그러나 본 개시는 이하에서 개시되는 실시예들에 한정되는 것이 아니라 서로 다른 다양한 형태로 구현될 수 있으며, 단지 본 실시예들은 본 개시가 완전하도록 하고, 본 개시가 속하는 기술 분야에서 통상의 지식을 가진 자에게 발명의 범주를 완전하게 알려주기 위해 제공되는 것일 뿐이다. 본 개시에서 사용되는 용어에 대해 간략히 설명하고, 개시된 실시예에 대해 구체적으로 설명하기로 한다. 본 개시에서 사용되는 용어는 본 개시에서의 기능을 고려하면서 가능한 현재 널리 사용되는 일반적인 용어들을 선택하였으나, 이는 관련 분야에 종사하는 기술자의 의도 또는 판례, 새로운 기술의 출현 등에 따라 달라질 수 있다. 또한, 특정한 경우는 출원인이 임의로 선정한 용어도 있으며, 이 경우 해당되는 발명의 설명 부분에서 상세히 그 의미를 기재할 것이다. 따라서 본 개시에서 사용되는 용어는 단순한 용어의 명칭이 아닌, 그 용어가 가지는 의미와 본 개시의 전반에 걸친 내용을 토대로 정의되어야 한다. 본 개시에서의 단수의 표현은 문맥상 명백하게 단수인 것으로 특정하지 않는 한, 복수의 표현을 포함한다. 또 한 복수의 표현은 문맥상 명백하게 복수인 것으로 특정하지 않는 한, 단수의 표현을 포함한다. 본 개시의 전체에서 어떤 부분이 어떤 구성요소를 '포함'한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다른 구성요소를 제외하는 것이 아니라 다른 구성요소를 더 포함할 수 있음을 의미한다. 또한, 명세서에서 사용되는 '부' 또는 '모듈'이라는 용어는 소프트웨어 또는 하드웨어 구성요소를 의미하며, ' 부' 또는 '모듈'은 어떤 역할들을 수행한다. 그렇지만 '부' 또는 '모듈'은 소프트웨어 또는 하드웨어에 한정되 는 의미는 아니다. '부' 또는 '모듈'은 어드레싱할 수 있는 저장 매체에 있도록 구성될 수도 있고 하나 또는 그 이상의 프로세서들을 재생시키도록 구성될 수도 있다. 따라서, 일 예로서 '부' 또는 '모듈'은 소프트웨어 구성요소들, 객체지향 소프트웨어 구성요소들, 클래스 구성요소들 및 태스크 구성요소들과 같은 구성요소들과, 프로세스들, 함수들, 속성들, 프로시저들, 서브루틴들, 프로그램 코드의 세그먼트들, 드라이버들, 펌웨어, 마이 크로 코드, 회로, 데이터, 데이터베이스, 데이터 구조들, 테이블들, 어레이들 및 변수들 중 적어도 하나를 포함 할 수 있다. 구성요소들과 '부' 또는 '모듈'들은 안에서 제공되는 기능은 더 작은 수의 구성요소들 및 '부' 또 는 '모듈'들로 결합되거나 추가적인 구성요소들과 '부' 또는 '모듈'들로 더 분리될 수 있다. 본 개시의 일 실시예에 따르면 '부' 또는 '모듈'은 프로세서 및 메모리로 구현될 수 있다. 용어 '프로세서'는 범용 프로세서, 중앙 처리 장치(CPU), 마이크로프로세서, 디지털 신호 프로세서(DSP), 제어기, 마이크로제어기, 상태 머신 등을 포함하도록 넓게 해석되어야 한다. 몇몇 환경에서는, '프로세서'는 주문형 반도체(ASIC), 프로 그램가능 로직 디바이스(PLD), 필드 프로그램가능 게이트 어레이(FPGA) 등을 지칭할 수도 있다. 용어 '프로세 서'는, 예를 들어, DSP와 마이크로프로세서의 조합, 복수의 마이크로프로세서들의 조합, DSP 코어와 결합한 하 나 이상의 마이크로프로세서들의 조합, 또는 임의의 다른 그러한 구성들의 조합과 같은 처리 디바이스들의 조합 을 지칭할 수도 있다. 본 개시에서, '시스템'은 서버 장치와 클라우드 서버 장치 중 적어도 하나의 장치를 지칭할 수 있지만, 이에 한정되는 것은 아니다. 본 개시에서, '사용자 단말'은 통신 모듈을 구비하여 네트워크 연결이 가능하고, 웹사이트, 애플리케이션 등을 접속하여 임의의 데이터 및/또는 정보의 입출력이 가능한 임의의 전자기기(예를 들어, 스마트폰, PC, 태블릿 PC, 랩톱 PC 등)를 포함할 수 있다. 사용자는 사용자 단말을 통해 사용자 단말의 인터페이스(예를 들어, 터치 디스플레이, 키보드, 마우스, 터치펜 또는 스틸러스, 마이크로폰, 동작인식 센서 등)를 통한 입력에 의해 네트 워크를 통해 접속가능한 임의의 정보/데이터를 제공받을 수 있다. 본 개시에서, '이미지'는 하나 이상의 픽셀을 포함한 이미지를 포함할 수 있으며, 하나 이상의 이미지 또는 동 영상을 지칭할 수 있다. 본 개시에서, '변형가능한 3D 움직임 모델'은 3차원 모델에 다양한 기법을 적용하여 움직임 및/또는 표정을 생 성하는 모델을 포함할 수 있다. 여기서, 변형가능한 3D 움직임 모델은 변형가능한 3D 모델(Morphable 3D model) 기법이 적용되는 애니메이션에 포함된 3D 움직인 모델을 지칭할 수 있다. 예를 들어, 변형가능한 3D 움 직임 모델에서, 객체 내에서 3D 형상 및/또는 텍스처 변형이 지속적으로 매개 변수화되어, 저차원 매개변수 공 간 및/또는 텍스처가 적용된 3D 모델의 고차원 공간 간의 매핑이 설정될 수 있다. 본 개시에서, '대상 콘텐츠 스타일'은 임의의 캐릭터 및/또는 배경에 대한 스타일을 나타낼 수 임의의 정보(예 를 들어, 콘텐츠의 형태 정보 및/또는 텍스처 정보)를 포함한 변형가능한 3D 움직임 모델로 표현될 수 있다. 예를 들어, 어느 한 제작사(예시: 디즈니)의 애니메이션에 포함된 3D 캐릭터 콘텐츠 스타일의 경우, 3D 캐릭터 의 특유의 형태(예시: 얼굴의 형태 및 크기, 얼굴 내의 눈, 코 및 입의 크기 및 위치 정보 등), 텍스처(예시: 머리색, 피부색, 그림자 및 반사광 등의 색상값)를 포함할 수 있다. 도 1은 본 개시의 일 실시예에 따른, 변형가능한 3D 움직임 모델 생성 시스템의 구성을 나타내는 블록도이 다. 도시된 바와 같이, 시스템은 통신부, 저장부 및 제어부를 포함할 수 있다. 시스템 은 통신부를 통해 외부 장치 또는 시스템과 임의의 데이트/정보를 송수신할 수 있도록 구성될 수 있 다. 일 실시예에 따르면, 시스템은 통신부를 통해 사용자를 포함한 이미지를 수신하고, 대상 스타일이 반영된 변형가능한 3D 움직임 모델을 송신하도록 구성될 수 있다. 시스템의 제어부는 수신된 사용자를 포함한 이미지를 이용하여 변형가능한 3D 움직임 모델을 생 성하도록 구성될 수 있다. 여기서, 이미지는 통신부를 통해 수신하거나, 입력 장치(미도시)를 통해 수신 될 수 있다. 일 실시예에 따르면, 사용자를 포함한 이미지는 2D 이미지인 경우, 제어부는 2D 이미지를 학 습된 인공신경망 모델에 입력하여 변형가능한 3D 움직임 모델을 출력할 수 있다. 이러한 인공신경망 모델을 이 용한 2D 이미지를 변형가능한 3D 움직임 모델을 생성하는 구성은 아래 도 11을 참조하여 상세히 설명된다. 다 른 실시예에 따르면, 사용자를 포함한 이미지는 3D 이미지를 생성할 수 있는 임의의 장치(예를 들어, depth 카 메라 등)를 통해 촬상된 이미지를 포함할 수 있다. 수신된 사용자를 포함한 이미지가 3D 이미지인 경우, 제어 부는 3D 이미지의 형태 정보를 이용하여 변형가능한 3D 움직임 모델을 생성할 수 있다. 제어부는 생성된 변형가능한 3D 움직임 모델에 대상 콘텐츠 스타일을 적용하여 대상 콘텐츠 스타일이 반영 된 변형가능한 3D 움직임 모델을 출력하도록 구성될 수 있다. 제어부는 통신부 및/또는 입력 장치 (미도시)를 통해 미리 저장된 콘텐츠 스타일 중 대상 콘텐츠 스타일에 대한 선택을 수신할 수 있고, 선택된 대 상 콘텐츠 스타일을 생성된 변형가능한 3D 움직임 모델에 적용할 수 있다. 일 실시예에 따르면, 제어부는 이러한 콘텐츠를 제작한 제작사 또는 제작자로부터 통신부를 통해 이러한 콘텐츠 스타일을 수신할 수 있다. 다른 실시예에 따르면, 제어부는 임의의 3D 이미지 작성 툴/애플리케이션을 통해 이러한 콘텐츠를 제작할 수 있다. 제어부는 통신부 및/또는 입력 장치(미도시)를 통해 블렌드 형태(blend shape)에 대한 수치를 수신하 고, 수신된 블렌드 형태에 대한 수치에 따라 콘텐츠 스타일의 적용 정도를 조정할 수 있다. 여기서, 블랜드 형 태를 제작하고 변형하는 기법은 3D 움직임 모델의 애니메이션 효과를 위해서, 3D 움직임 모델의 각 정점들의 움 직임을 제어하는 뼈대(bone)에 가중치를 부여하는 리깅(rigging) 과정 또는 사용자의 수작업 없이 정점 변환 (Vertex Transformation)을 제공할 수 있다. 보다 상세한 설명은 아래 도3을 통해 후술한다. 예를 들어, 블렌 드 형태에 대한 수치는 콘텐츠 스타일에 대응하는 블렌드 형태를 생성된 변형가능한 3D 움직임 모델에 적용하는 정도 또는 비율에 대한 수치를 포함할 수 있다. 제어부는 통신부 및/또는 입력 장치(미도시)를 통해 수신된 커스터마이징 정보에 기초하여, 대상 콘 텐츠 스타일이 적용된 변형가능한 3D 움직임 모델을 변형할 수 있다. 여기서, 커스터마이징 정보는 생성된 3D 움직임 모델 내에 포함된 하나 이상의 객체에 대한 변형 정보를 포함할 수 있다. 커스터마이징 정보를 이용한 대상 콘텐츠 스타일이 적용된 변형가능한 3D 움직임 모델을 변형하는 구성은 도 4를 통해 상세히 설명된다.제어부는 특정 표정을 가진 모델의 형태 정보를 기초로 특정 표정이 대상 콘텐츠 스타일이 적용된 변형가 능한 3D 움직임 모델에 반영되도록 변형가능한 3D 움직임 모델을 변형할 수 있다. 여기서, 특정 표정을 가진 모델의 형태 정보는 사람 및/또는 동물의 신체(얼굴 및/또는 신체 전체 등)을 통해 표현될 수 있는 표정에 대한 임의의 형태 정보를 포함할 수 있다. 예를 들어, 특정 표정을 가진 모델의 형태 정보는 무표정 얼굴, 웃는 얼 굴, 우는 얼굴, 웃을 때의 신체 등에 대한 형태 정보를 포함할 수 있으나, 이에 한정되지 않는다. 특정 표정을 가진 모델의 형태 정보를 이용하여 대상 콘텐츠 스타일이 적용된 변형가능한 3D 움직임 모델을 생성하는 구성은 아래 도 5를 참조하여 상세히 설명된다. 제어부는 통신부 및/또는 입력 장치(미도시)를 통해 수신된 복수의 대상 콘텐츠 스타일을 생성된 변 형가능한 3D 움직임 모델에 적용할 수 있다. 일 실시예에 따르면, 복수의 대상 콘텐츠 스타일은 하나의 애니매 이션 및/또는 주제에 대한 콘텐츠 스타일을 포함할 수 있다. 다른 실시예에 따르면, 복수의 대상 콘텐츠 스타 일은 서로 상이한 애니매이션 및/또는 주제에 대한 콘텐츠 스타일을 포함할 수 있다. 복수의 대상 콘텐츠 스타 일을 변경가능한 3D 움직임에 적용하는 구성은 아래 도 6를 참조하여 상세히 설명된다. 제어부는 대상 콘텐츠 스타일에 포함된 국소 콘텐츠 스타일을 변형가능한 3D 움직임 모델에 포함된 국소 객체에 적용할 수 있다. 여기서, 제어부는 이미지 처리 분야에서 알려진 임의의 기법(예를 들어, 라플라 시안 변형, 라플라시안 스무딩, Free Form Deformation 등)을 이용하여 대상 국소 콘텐츠 스타일을 변형가능한 3D 움직임 모델에 적용할 수 있다. 일 실시예에 따르면, 제어부는 대상 콘텐츠 스타일에 포함된 국소 객 체의 크기 및 경사 부분을 변형가능한 3D 움직임 모델의 대응 부분에 맞추도록 보정할 수 있다. 예를 들어 제 어부는, 변형된 국소 객체와 변형가능한 3D 움직임 모델의 대응 부분의 매끄럽지 못한 표면을 이미지 처리 분야에서 알려진Gradient Descent, Morphable 3D Model Regression, Laplacian Smoothing 등의 기술로 보정할 수 있으며, 이에 제한되지 않는다. 이러한 대상 국소 콘텐츠 스타일을 변형가능한 3D 움직임 모델에 포함된 국 소 객체에 적용하는 구성은 아래 도 7 및 도 8를 참조하여 상세히 설명된다. 제어부는 대상 콘텐츠 스타일이 적용된 변형가능한 3D 움직임 모델의 형태의 변형에 따라 3D 액세서리 모 델 및 3D 머리카락 모델 중 적어도 하나의 형태를 변형할 수 있다. 여기서, 3D 액세서리 모델 및/또는 3D 머리 카락 모델은 대상 콘텐츠 스타일을 나타내는 변형가능한 3D 움직임 모델에 포함될 수 있다. 일 실시예에 따르 면, 제어부는 대상 콘텐츠 스타일이 적용된 변형가능한 3D 움직임 모델의 기준 포인트의 변형에 대응되도 록 3D 액세서리 모델 및 3D 머리카락 모델 중 적어도 하나의 기준 포인트를 변형시킬 수 있다. 예를 들어, 대 상 콘텐츠 스타일이 적용된 변형가능한 3D 움직임 모델의 기준 포인트는 3D 움직임 모델을 나타내는 임의의 형 태 정보 내의 vertex 정보를 포함할 수 있다. 또한, 3D 액세서리 모델 및 3D 머리카락 모델 중 적어도 하나의 기준 포인트는 3D 액세서리 모델 및 3D 머리카락 모델 중 적어도 하나를 나타내는 임의의 형태 정보 내의 vertex 정보를 포함할 수 있다. 이러한 대상 콘텐츠 스타일이 적용된 변형가능한 3D 움직임 모델의 형태의 변 형에 따라 3D 액세서리 모델 및 3D 머리카락 모델 중 적어도 하나의 형태를 변형하는 구성은 도 9 및 도 10을 참조하여 상세히 설명된다. 제어부는 대상 콘텐츠 스타일로부터 텍스처를 추출하고, 추출된 텍스처를 생성된 변형가능한 3D 움직임 모 델에 적용할 수 있다. 일 실시예에 따르면, 제어부는 대상 콘텐츠 스타일에 해당하는 변형가능한 3D 움직임 모 델에 포함된 머리 색상, 피부색 등의 콘텐츠 스타일 색감을 이미지 처리 분야에서 알려진 Style transfer 기법 을 이용하여 변형가능한 3D 움직임 모델에 적용할 수 있다. 예를 들어, 이러한 Style transfer 기법은 인공신 경망 모델을 이용하여 구현될 수 있다. 일 실시예에 따르면, 제어부는 대상 콘텐츠 스타일로부터 텍스처를 추출하고, 추출된 텍스처의 데이터 분 포를 분석하도록 구성될 수 있다. 그리고 나서, 제어부는 추출된 텍스처의 데이터 분포를 생성된 변형가 능한 3D 움직임 모델의 텍스처에 적용할 수 있다. 예를 들어, 제어부는 대상 키프레임과 시퀀스 내의 다 른 모든 프레임 사이의 밀도 일치를 추정하고, 결과 변형 필드(resulting deformation field)를 이용하여 스타 일을 변형시키도록 구성될 수 있다. 저장부는 통신부 및/또는 입력장치(미도시)를 통해 외부 장치로부터 수신된 임의의 정보 및/또는 데 이터를 저장할 수 있다. 일 실시예에 따르면, 저장부는 복수의 콘텐츠 스타일을 저장할 수 있다. 예를 들 어, 저장부는 복수의 콘텐츠 스타일의 각각에 대응하는 변형가능한 3D 움직임 모델을 저장할 수 있다. 여 기서, 복수의 콘텐츠 스타일에 대응하는 변형가능한 3D 움직임 모델은 국소 객체에 대한 모델, 3D 액세서리 모 델 및 3D 머리카락 모델 중 적어도 하나를 포함할 수 있다. 또한, 저장부는 콘텐츠 스타일에서 추출된 임 의의 정보(예를 들어, 형태 정보, 텍스처 정보 등)를 저장할 수 있다.저장부는 수신된 사용자를 포함한 이미지를 저장할 수 있으며, 수신된 사용자를 포함한 이미지를 이용하여 생성된 변형가능한 3D 움직임 모델을 저장할 수 있다. 예를 들어, 3D 움직임 모델을 나타내는 임의의 정보(예 를 들어, 형태 정보, 텍스처 정보)가 저장부에 저장될 수 있다. 또한, 사용자를 포함한 이미지가 2D 이미 지인 경우, 3D 움직임 모델을 출력하도록 구성된 인공신경망 모델이 저장부에 저장될 수 있다. 또한, 저 장부는 특정 표정을 가진 모델의 형태 정보를 저장할 수 있다. 도 1에서는 저장부가 시스템에 포함되도록 도시되어 있으나, 이에 한정되지 않으며, 저장부는 시스템이 통신부를 통해 접근가 능한 임의의 외부 장치에 저장될 수 있다. 도 2는 본 개시의 일 실시예에 따른, 변형가능한 3D 움직임 모델 생성 방법을 나타내는 흐름도이다. 먼저, 방법은 사용자를 포함한 이미지에 대한 정보를 수신하는 단계(S210)로 개시될 수 있다. 일 실시예 에서, 사용자를 포함한 이미지에 대한 정보는 사용자를 포함한 2D 이미지 및 사용자를 포함한 3D 이미지 중 적 어도 하나를 포함할 수 있다. S220에서, 수신된 사용자를 포함한 이미지에 대한 정보를 기초로 변형가능한(morphable) 3D 움직임 모델이 생성 될 수 있다. 예를 들어, 수신된 이미지에 대한 정보가 2D 이미지인 경우, 기계학습을 통해 생성된 모델에 입력 되어 변형가능한 3D 움직임 모델이 출력될 수 있다. 그리고 나서, 미리 저장된 콘텐츠 스타일 중에서, 변형가 능한 3D 움직임 모델에 적용될 하나 이상의 대상 콘텐츠 스타일이 선택될 수 있다(S230). S240에서, 선택된 대 상 콘텐츠 스타일은 생성된 변형가능한 3D 움직임 모델에 적용될 수 있다. 이러한 방법을 통해 생성된 변형가 능한 3D 움직임 모델은 사용자의 특징뿐만 아니라 대상 콘텐츠의 특징이 반영될 수 있다. 도 3은 본 개시의 일 실시예에 따른, 변형가능한 3D 움직임 모델에 콘텐츠 스타일의 적용 정도 (level)를 조정하고, 조정된 적용 정도에 따라 변형된 3D 움직임 모델(330, 340)을 보여주는 예시도이다. 일 실시예에서, 변형가능한 3D 움직임 모델 생성 시스템은 블렌드 형태에 대한 수치를 수신하고, 수신된 블렌 드 형태에 대한 수치에 따라 콘텐츠 스타일의 적용 정도를 조정할 수 있다. 예를 들어, 시스템은 수신된 블렌드 형태에 대한 수치로서, 콘텐츠 스타일의 적용 정도를 나타내는 비율이 수신될 수 있다. 이에 따라, 시스템은 수신된 비율에 맞추어 콘텐츠 스타일의 적용 정도를 조정하고, 조정된 적용 정도에 따라 변형가능한 3D 움직임 모델이 변형될 수 있다. 일 실시예에서, 시스템은 블렌드 형태에 대한 수치로서 낮은 비율(예를 들어, 10%)를 수신하고, 콘텐츠 스 타일이 낮은 비율이 적용된 변형가능한 3D 움직임 모델을 생성할 수 있다. 도시된 바와 같이, 시스 템은 비현실적인 얼굴 비율의 어린아이 콘텐츠 스타일을 대상 콘텐츠 스타일로서 선택하고, 선택된 어린아이 콘텐츠 스타일을 4명의 성인을 나타내는 변형가능한 3D 움직임 모델에 수신된 낮은 비율로 적용할 수 있다. 이에 따라, 낮은 비율로 어린아이 콘텐츠 스타일을 적용한 변형가능한 3D 움직임 모델 은 예를 들어, 4명의 성인 사람 얼굴의 비율 특징을 대부분 유지하면서, 얼굴의 세부 부분들 및 외곽선이 조금씩 둥글어진 형태를 포함할 수 있다. 다른 실시예에 따르면, 시스템은 블렌드 형태에 대한 수치로서 높은 비율(예를 들어, 60%)를 수신하고, 콘 텐츠 스타일이 높은 비율이 적용된 변형가능한 3D 움직임 모델을 생성할 수 있다. 도시된 바와 같이, 시스템은 대상 콘텐츠 스타일로서 선택된 비현실적인 얼굴 비율의 어린아이 콘텐츠 스타일을 4 명의 성인을 나타내는 변형가능한 3D 움직임 모델에 수신된 높은 비율로 적용할 수 있다. 이에 따라, 높 은 비율로 어린아이 콘텐츠 스타일을 적용한 변형가능한 3D 움직임 모델은 예를 들어, 4명의 성인 전 체적인 얼굴 형상이 비교적 더 둥글어지고, 턱 라인이 눈에 띄게 둥글어지며, 얼굴에서 눈이 차지하는 비율이 커진 형태를 포함할 수 있다. 도 3의 콘텐츠 스타일이 적용된 변형가능한 3D 움직임 모델(330, 340)은 예 시적으로 도시된 것으로서, 이에 한정되지 않으며, 콘텐츠 스타일의 상이한 특징이 4명의 성인을 나타내는 변형가능한 3D 움직임 모델에 수신된 블렌드 형태의 수치에 대응하는 비율만큼 적용될 수 있다. 도 4는 본 개시의 일 실시예에 따른, 커스터마이징 정보에 기초해 변형된 변형가능한 3D 움직임 모델(415, 42 5)을 나타내는 예시도이다. 일 실시예에 따르면, 변형가능한 3D 움직임 모델 생성 시스템은, 대상 콘텐츠 스타일이 적용된 변형가능한 3D 움직임 모델을 변형하여, 커스터마이징 정보이 반영된 3D 움직임 모델 을 생성할 수 있다(S450). 여기서, 커스터마이징 정보는 통신부 및/또는 입력장치를 통해 수신된 3D 움직임 모델 전체 및/또는 3D 움직임 모델 내의 하나 이상의 객체에 대한 형태 정보를 포함할 수 있다. 예를 들어, 형태 정보는 모델 전체 및/또는 하나 이상의 객체에 대한 크기, 회전, 위치 등에 대한 정보를 포함할 수 있다. 다른 실시예에 따르면, 시스템은 통신부 및/또는 입력 장치를 통해 수신된 커스터마이징 정보를 대상 콘텐츠 스타일이 아직 적용되지 않은 변형가능한 3D 움직임 모델에 적용하여 커스터마이징 정보가 반영된 3D 움직임 모델을 생성할 수 있다(S460). 그리고 나서, 시스템은 대상 콘텐츠 스타일을 커스터마이징 정보가 반영된 3D 움직임 모델에 적용할 수 있다(S470). 이에 따라, 커스터마이징 정보 및 대상 콘텐츠 스타일이 반영된 변형가능한 3D 움직임 모델이 생성될 수 있다. 도 5는 본 개시의 일 실시예에 따른, 특정 표정 정보를 가진 모델의 형태 정보를 이용하여 변형된 변형가 능한 3D 움직임 모델을 나타내는 예시도이다. 변형가능한 3D 움직임 모델 생성 시스템은, 특정 표정 을 가진 모델의 형태 정보를 이용하여 특정 표정이 대상 콘텐츠 스타일이 적용된 변형가능한 3D 움직임 모 델에 반영되도록 변형가능한 3D 움직임 모델을 변형할 수 있다. 도시된 바와 같이, 특정 표정을 가 진 모델의 형태 정보는 사람 얼굴의 무표정, 놀란 표정, 화난 표정을 포함한 변형가능한 3D 움직임 모델에 대한 정보(예를 들어, 메쉬 형태, 정점 등)를 포함할 수 있으나, 이에 한정되지 않으며, 표정을 가진 모델의 형 태를 나타낼 수 있는 임의의 정보/데이터를 포함할 수 있다. 일 실시예에 따르면, 시스템은 특정 표정을 갖는 모델의 형태 정보로부터 특정 표정을 특징화하는 정 보를 추출할 수 있다. 예를 들어, 도시된 바와 같이, 화난 표정의 변형가능한 3D 움직임 모델은 눈 사이의 형 태가 찌푸려지고, 입의 양 측면이 점점 더 벌어지면서 입꼬리는 내려가는 형태에 대한 정보를 포함할 수 있다. 이러한 추출된 정보는 변형가능한 3D 움직임 모델에 적용될 수 있다. 예를 들어, 추출된 정보는 변형가능 한3D 움직임 모델 내의 특정 표정을 특징화하는 메쉬 정보 및 정점 정보를 포함할 수 있으며, 이러한 메쉬 정보 및 정점 정보를 대상 콘텐츠 스타일이 적용된 변형가능한 3D 움직임 모델에 적용할 수 있다. 도 5에서는 변형가능한 3D 움직임 모델이 대상 콘텐츠 스타일이 이미 반영된 변형가능한 3D 움직임 모델로 도시되어 있으나, 이에 한정되지 않으며, 시스템은 대상 콘텐츠 스타일이 반영되지 않은 변형가능한 3D 움직임 모델 에 특정 표정을 적용할 수 있고, 그리고 나서, 대상 콘텐츠 스타일을 특정 표정이 적용된 변형가능한 3D 움직임 모델에 적용할 수 있다. 도 6은 본 개시의 일 실시예에 따른, 복수의 콘텐츠 스타일(620, 625)이 적용된 변형가능한 3D 움직임 모델 을 나타내는 예시도이다. 변형가능한 3D 움직임 모델 생성 시스템은 미리 저장된 복수의 콘텐츠 스 타일 중 복수의 대상 콘텐츠 스타일(620, 625)을 선택하고, 선택된 복수의 대상 콘텐츠 스타일을 생성된 변형가 능한 3D 움직임 모델에 적용할 수 있다. 여기서, 변형가능한 3D 움직임 모델은 사용자를 포함한 이 미지를 기초로 생성될 수 있다. 일 실시예에서, 도 6에 도시된 바와 같이, 시스템은 복수의 대상 콘텐츠 스타일로서 매부리코 콘텐츠 스타 일 및 어린아이 콘텐츠 스타일을 선택할 수 있다. 그리고 나서, 선택된 복수의 대상 콘텐츠 스타일 은 변형가능한 3D 움직임 모델에 적용될 수 있다. 예를 들어, 시스템은 선택된 대상 콘텐츠 스타일 을 변형가능한 3D 움직임 모델에 블렌딩할 수 있다. 즉, 선택된 대상 콘텐츠 스타일을 특징화하는 정보가 조합되어 3D 움직임 모델에 적용될 수 있다. 도시된 바와 같이, 선택된 복수의 대상 콘텐츠 스타일(620, 625)가 적용된 변형가능한 3D 움직임 모델은 대상 콘텐츠 스타일에 따라 메부리코 형태가 적용되고, 대상 콘텐츠 스타일에 따라 눈이 상대적으로 커지고, 얼굴 형이 상대적으로 둥근형으로 변경된 특징을 포 함할 수 있다. 도 6에서는 2개의 대상 콘텐츠 스타일이 선택되어 생성된 변형가능한 3D 움직임 모델에 적 용되도록 도시되어 있으나, 이에 한정되지 않으며, 3개 이상의 대상 콘텐츠 스타일이 선택되어 생성된 변형가능 한 3D 움직임 모델에 적용될 수 있다. 도 7은 본 개시의 일 실시예에 따른, 변형가능한 3D 움직임 모델에 포함된 복수의 국소(local) 객체에 대 한 변형가능한 3D 움직임 모델(710, 720, 730, 740)을 설명하는 예시도이다. 일 실시예에 따르면, 변형가능한 3D 움직임 모델 생성 시스템은 사용자를 포함한 이미지를 수신할 수 있다. 예를 들어, 사용자를 포함한 이미지는 사용자 내에 포함된 하나 이상의 국소(local) 객체를 포함할 수 있다. 이에 따라, 시스템은 사 용자를 포함한 이미지를 기초로 하나 이상의 국소 객체에 대한 변형가능한 3D 움직임 모델 및 국소 객체를 포함 한 전체에 대한 변형가능한 3D 움직임 모델을 생성할 수 있다. 여기서, 국소 객체에 대한 변형가능한 모델은, 도시된 바와 같이, 눈에 대한 변형가능한 3D 움직임 모델, 코에 대한 변형가능한 3D 움직임 모델, 입 에 대한 변형가능한 3D 움직임 모델 및 귀에 대한 변형가능한 3D 움직임 모델을 포함할 수 있다. 또 한, 시스템은 얼굴 전체에 대한 변형가능한 3D 움직임 모델을 생성할 수 있으며, 이러한 3D 움직임 모델은 국소 객체에 대한 변형가능한 모델(710, 720, 730, 740)을 포함할 수 있다. 일 실시예에서, 국소 객체에 대한 변형가능한 3D 움직임 모델(710, 720, 730, 740)의 각각은 눈, 코, 입 및 귀 의 영역을 구성하는 메쉬 및 정점들 중 적어도 하나의 집합을 국소 객체로써 포함할 수 있다. 또한, 얼굴 전체에 대한 변형가능한 3D 움직임 모델은 얼굴 전체에 대한 메쉬 및 정점들 중 적어도 하나의 집합에 대한 정 보를 포함할 수 있다. 이에 더하여, 복수의 국소 객체에 대한 메쉬 및 정점들 중 적어도 하나의 집합에 대한 정보가 얼굴 전체에 대한 변형가능한 3D 움직임 모델에 포함될 수 있다. 도 7에서는 얼굴에 대한 국소 객 체로서, 눈, 코, 입 및 귀가 도시되어 있지만, 이에 제한되지 않으며, 이마, 뺨, 턱, 두상, 광대, 입술 두께, 머리카락 등의 얼굴 내에 포함된 객체가 국소 객체로서 구성될 수 있다. 또한, 도 7에서는 얼굴에 대한 국소 객체 및 전체 얼굴에 대한 3D 움직임 모델은 형태에 대한 정보를 포함하도록 도시되어 있으나, 이에 한정되지 않고, 얼굴에 대한 국소 객체 및 전체 얼굴에 대한 텍스처, 색상 등의 정보를 포함할 수 있다. 도 8은 본 개시의 일 실시예에 따른, 변형가능한 3D 움직임 모델의 국소 객체에 콘텐츠 스타일 에 포함된 국소 컨텐츠 스타일을 적용하는 방법을 설명하는 예시도이다. 일 실시예에서, 변형가능한 3D 움직임 모델 생성 시스템은, 대상 콘텐츠 스타일에 포함된 국소 콘텐츠 스타일을 변형가능한 3D 움직임 모델에 포함된 대응 국소 객체에 적용할 수 있다. 이를 위해, 시스템은 대상 콘텐츠 스타일 으로부터 국소 콘텐츠 스타일을 추출할 수 있다. 예를 들어, 도시된 바와 같이, 대상 콘텐츠 스타일 으로부터 코에 대한 콘텐츠 스타일이 추출될 수 있다. 이에 따라, 시스템은 추출된 국소 콘텐 츠 스타일을 기초로 변형가능한 3D 움직임 모델의 코 영역에 해당하는 국소 객체만 변형시킬 수 있다. 한편, 변형가능한 3D 움직임 모델의 국소 객체를 추출된 국소 콘텐츠 스타일에 대한 정보를 이 용하여 변형될 경우, 변형된 국소 객체는 변형가능한 3D 움직임 모델 사이의 연결부가 매끄럽지 못할 수 있다. 이러한 문제점을 해결하기 위하여, 시스템은 대상 콘텐츠 스타일에 포함된 국소 객체의 크기(size) 및 경사(gradient)를 변형가능한 3D 움직임 모델의 대응 객체에 맞추도록 보정할 수 있다. 일 실시예에 따르면, 국소 콘텐츠 스타일이 반영된 국소 객체와 변형가능한 3D 움직임 모델 사이의 연결부의 크기 및 경사(gradient)가 최소화되도록, 시스템은 변형가능한 3D 움직임 모델의 국소 객체 의 크기, 회전 및 정점을 고려하여 국소 콘텐츠 스타일의 크기, 회전 및 정점 변환을 수행할 수 있다. 여 기서, 시스템은 이러한 보정을 위하여, 이미지 처리 분야에서 알려진 경사 하강법(Gradient Descent) 알고 리즘, 변형가능한 모델 회귀(Morphable Model Regression)등을 사용할 수 있으나, 이에 한정되지 않으며, 대응 부분의 형태 정보를 맞추도록 수행될 수 있는 임의의 기법이 적용될 수 있다. 그리고 나서, 이렇게 보정된 국 소 객체 스타일이 반영된 변형가능한 3D 움직임 모델이 생성될 수 있다. 도 9는 본 개시의 일 실시예에 따른, 대상 콘텐츠 스타일에 대응하는 변형가능한 3D 움직임 모델에 포함된 머리카락 모델을 대상 콘텐츠 스타일이 반영된 변형가능한 3D 움직임 모델의 형태 변형에 따라 머리카락 모델을 변형하는 방법을 나타내는 예시도이다. 도시된 바와 같이, 대상 콘텐츠 스타일에 대응하는 변형가능한 3D 움직임 모델은 3D 머리카락 모델을 포함할 수 있다. 변형가능한 3D 움직임 모델 생성 시스템 은, 사용자를 포함한 이미지를 기초로 생성된 변형가능한 3D 움직임 모델에 대상 콘텐츠 스타일에 대 응하는 변형가능한 3D 움직임 모델을 적용할 수 있다. 이 때, 대상 콘텐츠 스타일에 대응하는 변형가능한 3D 움직임 모델에 포함된 3D 머리카락 모델도 변형가능한 3D 움직임 모델에 적용될 수 있다. 이에 따르면, 변형가능한 3D 움직임 모델에 대상 콘텐츠 스타일을 적용한 변형가능한 3D 움직임 모델(93 0)은 3D 머리카락 모델의 연결 영역이 부자연스러워 보일 수 있다. 예를 들어, 도시된 바와 같이, 대상 콘텐츠 스타일을 적용한 변형가능한 3D 움직임 모델에 포함된 3D 머리카락 모델의 중앙 부분의 연결이 매 끄럽지 않을 수 있다. 이는, 변형가능한 3D 움직임 모델과 대상 콘텐츠 스타일에 대응하는 변형가능한 3D 움직임 모델의 머리모양 및 크기가 서로 상이하기 때문일 수 있다. 즉, 변형가능한 3D 움직임 모델 에 대상 콘텐츠 스타일 적용 시, 변형가능한 3D 움직임 모델에 포함된 머리카락 모델에도 일괄적인 변형을 적용 하면, 도 9에 도시된 보정 전 변형가능한 3D 움직임 모델과 같이, 3D 머리카락 모델의 연결 부분의 불일치가 나타날 수 있다. 이러한 문제점을 해결하기 위하여, 시스템은 대상 콘텐츠 스타일이 반영된 변형가능한 3D 움직임 모델 의 형태 변형에 따라 3D 머리카락 모델의 형태를 변형할 수 있다. 일 실시예에 따르면, 시스템(10 0)은 이미지 처리 분야에서 알려진 자유형태변형 기법(Free Form Deformation)을 이용해 3D 머리카락 모델(92 5)을 보정할 수 있으나, 이에 제한되지 않는다. 일 실시예에 따르면, 시스템은 대상 콘텐츠 스타일이 반영된 변형가능한 3D 움직임 모델의 기준 포인 트 변형에 대응되도록, 3D 머리카락 모델의 기준 포인트를 변형하도록 구성될 수 있다. 여기서, 각 모델 (930, 925)의 기준 포인트는 각 모델의 형태를 특징화할 수 있는 임의의 포인트를 포함할 수 있으며, 예를 들어, 각 모델의 x, y, z 축 방향의 최대 및/또는 최소값이 기준 포인트로서 설정될 수 있다. 이 경우, 시스템은 각 모델(930, 925)의 x, y, z 축 방향의 최대 및/또는 최소값(기준 포인트)를 포함하여, 즉 각 모델 (930, 925)을 포함하도록 직육면체 모양을 생성할 수 있다. 이에 따라, 시스템은 대상 콘텐츠 스타일이 반 영된 변형가능한 3D 움직임 모델을 포함한 직육면체의 변형에 따라 3D 머리카락 모델을 포함한 직육 면체 모양의 형태를 변경할 수 있다. 이렇게 변형된 3D 머리카락 모델이 반영된 변형가능한 움직임 모델 이 생성될 수 있다. 도 9에서는 대상 콘텐츠 스타일에 포함된 3D 머리카락 모델의 변형에 대해 도시되어 있으나, 이에 한정되지 않고, 대상 콘텐츠 스타일이 반영된 변형가능한 3D 움직임 모델의 변형에 맞추어 대상 스타일 콘텐츠에 포함된 3D 액세서리 모델의 형태도 변형될 수 있다. 도 10은 본 개시에서 적용될 수 있는 인공신경망 모델을 나타내는 예시도이다. 인공신경망 모델은, 머신러닝(Machine Learning) 기술과 인지과학에서, 생물학적 신경망의 구조에 기초하여 구현된 통계학적 학습 알고리즘 또는 그 알고리즘을 실행하는 구조이다. 일 실시예에 따르면, 인공신경망 모델 은, 생물학적 신경망에서와 같이 시냅스의 결합으로 네트워크를 형성한 인공 뉴런인 노드(Node)들이 시냅스의 가중치를 반복적으로 조정하여, 특정 입력에 대응한 올바른 출력과 추론된 출력 사이의 오차가 감소되도록 학습 함으로써, 문제 해결 능력을 가지는 머신러닝 모델을 나타낼 수 있다. 예를 들어, 인공신경망 모델은 머 신 러닝, 딥러닝 등의 인공지능 학습법에 사용되는 임의의 확률 모델, 뉴럴 네트워크 모델 등을 포함할 수 있다. 일 실시예에 따르면, 인공신경망 모델은 얼굴 등과 같은 사람이 포함된 2D 학습 이미지 및/또는 이러한 2D 학습 이미지로부터 추출된 이미지 피처를 입력하여 변형가능한 3D 움직임 모델을 출력하도록 구성된 인공신 경망 모델을 포함할 수 있다. 다른 실시예에서, 인공신경망 모델은 변형가능한 3D 움직임 모델 및 하나 이상의 대상 콘텐츠 스타일을 입력받아, 대상 콘텐츠 스타일이 반영된 변형가능한 3D 움직임 모델을 출력하도록 구성된 인공신경망 모델을 포함할 수 있다. 또 다른 실시예에서, 인공신경망 모델은 특정 표정을 가진 모 델의 형태 정보 및 대상 콘텐츠 스타일이 적용된 변형가능한 3D 움직임 모델을 입력받아 특정 표정이 반영된 변 형가능한 3D 움직임 모델을 출력하도록 구성된 인공신경망 모델을 포함할 수 있다. 인공신경망 모델은 다층의 노드들과 이들 사이의 연결로 구성된 다층 퍼셉트론(MLP: multilayer perceptron)으로 구현된다. 본 실시예에 따른 인공신경망 모델은 MLP를 포함하는 다양한 인공신경망 모 델 구조들 중의 하나를 이용하여 구현될 수 있다. 도 10에 도시된 바와 같이, 인공신경망 모델은, 외부 로부터 입력 신호 또는 데이터를 수신하는 입력층, 입력 데이터에 대응한 출력 신호 또는 데이터 를 출력하는 출력층, 입력층과 출력층 사이에 위치하며 입력층으로부터 신호를 받아 특성을 추출하여 출력층으로 전달하는 n개(여기서, n은 양의 정수)의 은닉층(1030_1 내지 1030_n)으 로 구성된다. 여기서, 출력층은 은닉층(1030_1 내지 1030_n)으로부터 신호를 받아 외부로 출력한다. 인공신경망 모델의 학습 방법에는, 교사 신호(정답)의 입력에 의해서 문제의 해결에 최적화되도록 학습하 는 지도 학습(Supervised Learning) 방법과, 교사 신호를 필요로 하지 않는 비지도 학습(Unsupervised Learning) 방법이 있다. 제어부는 학습 2D 이미지를 변형가능한 3D 움직임 모델을 출력하기 위하여 지도 학습(Supervised Learning)을 이용하여 입력 이미지에 대한 분석을 수행하고, 이미지에 대응되는 변형가능한 3D 움직임 모델이 추론될 수 있도록 인공신경망 모델을 학습시킬 수 있다. 이렇게 학습된 인공신경망 모델 은 저장부에 저장될 수 있으며, 통신부 및/또는 입력장치로부터 수신된 사용자를 포함한 이미 지의 입력에 응답하여 변형가능한 3D 움직임 모델을 출력할 수 있다. 일 실시예에 따르면, 도 10에 도시된 바와 같이, 깊이 정보를 추출할 수 있는 인공신경망 모델의 입력변 수는, 사람의 적어도 일부를 포함한 학습 이미지가 될 수 있다. 예를 들어, 인공신경망 모델의 입력층 에 입력되는 입력변수는, 학습 이미지를 하나의 벡터 데이터 요소로 구성한, 이미지 벡터가 될 수 있다. 사람의 적어도 일부를 포함한 학습 이미지의 입력에 응답하여, 인공신경망 모델의 출력층에 서 출력되는 출력변수는 변형가능한 3D 움직임 모델을 나타내는 벡터가 될 수 있다. 이에 더하여, 인공 신경망 모델의 출력층은 출력된 변형가능한 3D 움직임 모델에 대한 신뢰도 및/또는 정확도를 나타 내는 벡터를 출력하도록 구성될 수 있다. 예를 들어, 이러한 출력에 대한 신뢰도 또는 정확도를 나타내는 벡터 는 스코어(score)로서 해석되거나 표시될 수 있다. 본 개시에 있어서 인공신경망 모델의 출력변수는, 이 상에서 설명된 유형에 한정되지 않으며, 변형가능한 3D 움직임 모델을 나타내는 임의의 정보/데이터를 포함할 수 있다. 이와 같이 인공신경망 모델의 입력층과 출력층에 복수의 입력변수와 대응되는 복수의 출력변 수가 각각 매칭되고, 입력층, 은닉층(1030_1 내지 1030_n) 및 출력층에 포함된 노드들 사이의 시냅스 값이 조정됨으로써, 특정 입력에 대응한 올바른 출력이 추출될 수 있도록 학습될 수 있다. 이러한 학습 과 정을 통해, 인공신경망 모델의 입력변수에 숨겨져 있는 특성을 파악할 수 있고, 입력변수에 기초하여 계 산된 출력변수와 목표 출력 간의 오차가 줄어들도록 인공신경망 모델의 노드들 사이의 시냅스 값(또는 가 중치)를 조정할 수 있다. 이렇게 학습된 인공신경망 모델을 이용하여, 입력된 사용자를 포함한 이미지에 응답하여, 입력 이미지에 대응하는 변형가능한 3D 움직임 모델에 대한 정보가 출력될 수 있다. 다른 실시예에 따르면, 변형가능한 3D 움직임 모델을 생성할 수 있는 인공신경망 모델의 입력 변수는, 사 용자를 포함한 이미지에 대응하는 변형가능한 3D 움직임 모델 및 하나 이상의 대상 콘텐츠 스타일에 대한 정보 를 나타내는 벡터를 포함할 수 있다. 이러한 입력 변수에 응답하여, 인공신경망 모델의 출력층은 대상 콘텐츠 스타일이 적용된 변형가능한 3D 움직임 모델을 나타내는 벡터가 될 수 있다. 여기서, 특정 입력에 대응한 올바른 출력이 추출될 수 있도록 입력층, 은닉층(1030_1 내지 1030_n) 및 출력층에 포함된 노드들 사이의 가중치 값이 조정될 수 있다. 이러한 변형가능한 3D 움직임 모델을 생성할 수 있는 인공신경망 모델은 저장부에 저장될 수 있다. 이렇게 학습된 인공신경망 모델을 이용하여, 입력된 사용 자를 포함한 이미지에 대응하는 변형가능한 3D 움직임 모델 및 하나 이상의 대상 콘텐츠 스타일에 대한 정보에 응답하여, 대상 콘텐츠 스타일이 적용된 변형가능한 3D 움직임 모델에 대한 정보가 출력될 수 있다. 또 다른 실시예에 따르면, 특정 표정이 반영된 변형가능한 3D 움직임 모델을 생성할 수 있는 인공신경망 모델 의 입력 변수는, 특정 표정을 가진 모델의 형태 정보 및 대상 콘텐츠 스타일이 적용된 변형가능한 3D 움 직임 모델에 대한 정보를 나타내는 벡터를 포함할 수 있다. 이러한 입력 변수에 응답하여, 인공신경망 모델 의 출력층은 특정 표정이 반영된 변형가능한 3D 움직임 모델을 나타내는 벡터가 될 수 있다. 여기 서, 특정 입력에 대응한 올바른 출력이 추출될 수 있도록 입력층, 은닉층(1030_1 내지 1030_n) 및 출력층 에 포함된 노드들 사이의 가중치 값이 조정될 수 있다. 이러한 특정 표정이 반영된 변형가능한 3D 움직 임 모델을 생성할 수 있는 인공신경망 모델은 저장부에 저장될 수 있다. 이렇게 학습된 인공신경망 모델을 이용하여, 특정 표정을 가진 모델의 형태 정보 및 대상 콘텐츠 스타일이 적용된 변형가능한 3D 움 직임 모델에 대한 정보에 응답하여, 특정 표정이 반영된 변형가능한 3D 움직임 모델에 대한 정보가 출력될 수 있다. 이상 설명된 다양한 실시예에 따른 변형가능한 3D 움직임 모델 생성 시스템은, 데스크탑 컴퓨터, 랩탑 컴퓨터, 무선 전화기, 셀룰러 전화기, 무선 멀티미디어 디바이스, PDA, 컴퓨터의 외부에 설치된 모뎀이나 내부에 설치된 모뎀, 무선 채널을 통해 통신하는 디바이스 등과 같은 다양한 타입들의 디바이스들을 나타낼 수도 있다. 이와 같은 디바이스는, 액세스 단말기 (access terminal; AT), 액세스 유닛, 가입자 유닛, 이동국, 모바일 디바이스, 모바일 유닛, 모바일 전화기, 모바일, 원격국, 원격 단말, 원격 유닛, 유저 디바이스, 유저 장비 (user equipment), 핸드헬드 디바이스 등과 같은 다양한 이름들을 가질 수도 있다. 본원에 설명된 임의의 디바이스는, 이상 설명한 방법의 실행에 필요한 명령들 및 데이터를 저장하기 위한 메모리, 뿐만 아니라 하드웨 어, 소프트웨어, 펌웨어, 또는 이들의 조합들을 가질 수도 있다. 본원에 기술된 기법들은 다양한 수단에 의해 구현될 수도 있다. 예를 들어, 이러한 기법들은 하드웨어, 펌웨어, 소프트웨어, 또는 이들의 조합으로 구현될 수도 있다. 본원의 개시와 연계하여 설명된 다양한 예시적 인 논리적 블록들, 모듈들, 회로들, 및 알고리즘 단계들은 전자 하드웨어, 컴퓨터 소프트웨어, 또는 양자의 조 합들로 구현될 수도 있음을 당업자들은 더 이해할 것이다. 하드웨어 및 소프트웨어의 이러한 상호교환성을 명 확하게 설명하기 위해, 다양한 예시적인 컴포넌트들, 블록들, 모듈들, 회로들, 및 단계들이 그들의 기능성의 관 점에서 일반적으로 위에서 설명되었다. 그러한 기능이 하드웨어로서 구현되는지 또는 소프트웨어로서 구현되는 지의 여부는, 특정 애플리케이션 및 전체 시스템에 부과되는 설계 제약들에 따라 달라진다. 당업자들은 각각의 특정 애플리케이션을 위해 다양한 방식들로 설명된 기능을 구현할 수도 있으나, 그러한 구현 결정들은 본 개시 의 범위로부터 벗어나게 하는 것으로 해석되어서는 안된다. 하드웨어 구현에서, 기법들을 수행하는 데 이용되는 프로세싱 유닛들은, 하나 이상의 ASIC들, DSP들, 디지털 신 호 프로세싱 디바이스들 (digital signal processing devices; DSPD들), 프로그램가능 논리 디바이스들 (programmable logic devices; PLD들), 필드 프로그램가능 게이트 어레이들 (field programmable gate arrays; FPGA들), 프로세서들, 제어기들, 마이크로제어기들, 마이크로프로세서들, 전자 디바이스들, 본원에 설명된 기능 들을 수행하도록 설계된 다른 전자 유닛들, 컴퓨터, 또는 이들의 조합 내에서 구현될 수도 있다. 따라서, 본원의 개시와 연계하여 설명된 다양한 예시적인 논리 블록들, 모듈들, 및 회로들은 범용 프로세서, DSP, ASIC, FPGA나 다른 프로그램 가능 논리 디바이스, 이산 게이트나 트랜지스터 로직, 이산 하드웨어 컴포넌트들, 또는 본원에 설명된 기능들을 수행하도록 설계된 것들의 임의의 조합으로 구현되거나 수행될 수도 있다. 범용 프로세서는 마이크로프로세서일 수도 있지만, 대안에서, 프로세서는 임의의 종래의 프로세서, 제어기, 마 이크로제어기, 또는 상태 머신 일 수도 있다. 프로세서는 또한 컴퓨팅 디바이스들의 조합, 예를 들면, DSP와 마이크로프로세서, 복수의 마이크로프로세서들, DSP 코어와 연계한 하나 이상의 마이크로프로세서들, 또는 임의 의 다른 그러한 구성의 조합으로써 구현될 수도 있다. 펌웨어 및/또는 소프트웨어 구현에 있어서, 기법들은 랜덤 액세스 메모리 (random access memory; RAM), 판독 전용 메모리 (read-only memory; ROM), 불휘발성 RAM (non-volatile random access memory; NVRAM), PROM (programmable read-only memory), EPROM (erasable programmable read-only memory), EEPROM (electrically erasable PROM), 플래시 메모리, 컴팩트 디스크 (compact disc; CD), 자기 또는 광학 데이터 스토리지 디바이 스 등과 같은 컴퓨터 판독가능 매체 상에 저장된 명령들로써 구현될 수도 있다. 명령들은 하나 이상의 프로세 서들에 의해 실행 가능할 수도 있고, 프로세서(들)로 하여금 본원에 설명된 기능의 특정 양태들을 수행하게 할 수도 있다. 소프트웨어로 구현되면, 상기 기능들은 하나 이상의 명령들 또는 코드로서 컴퓨터 판독 가능한 매체 상에 저장 되거나 또는 컴퓨터 판독 가능한 매체를 통해 전송될 수도 있다. 컴퓨터 판독가능 매체들은 한 장소에서 다른 장소로 컴퓨터 프로그램의 전송을 용이하게 하는 임의의 매체를 포함하여 컴퓨터 저장 매체들 및 통신 매체들 양자를 포함한다. 저장 매체들은 컴퓨터에 의해 액세스될 수 있는 임의의 이용 가능한 매체들일 수도 있다. 비제한적인 예로서, 이러한 컴퓨터 판독가능 매체는 RAM, ROM, EEPROM, CD-ROM 또는 다른 광학 디스크 스토리지, 자기 디스크 스토리지 또는 다른 자기 스토리지 디바이스들, 또는 소망의 프로그램 코드를 명령들 또 는 데이터 구조들의 형태로 이송 또는 저장하기 위해 사용될 수 있으며 컴퓨터에 의해 액세스될 수 있는 임의의 다른 매체를 포함할 수 있다. 또한, 임의의 접속이 컴퓨터 판독가능 매체로 적절히 칭해진다. 예를 들어, 소프트웨어가 동축 케이블, 광섬유 케이블, 연선, 디지털 가입자 회선 (DSL), 또는 적외선, 무선, 및 마이크로파와 같은 무선 기술들을 사용하여 웹사이트, 서버, 또는 다른 원격 소스로부터 전송되면, 동축 케 이블, 광섬유 케이블, 연선, 디지털 가입자 회선, 또는 적외선, 무선, 및 마이크로파와 같은 무선 기술들은 매 체의 정의 내에 포함된다. 본원에서 사용된 디스크 (disk)와 디스크 (disc)는, CD, 레이저 디스크, 광 디스크, DVD (digital versatile disc), 플로피디스크, 및 블루레이 디스크를 포함하며, 여기서 디스크들 (disks) 은 보통 자기적으로 데이터를 재생하고, 반면 디스크들 (discs) 은 레이저를 이용하여 광학적으로 데이터를 재생한 다. 위의 조합들도 컴퓨터 판독가능 매체들의 범위 내에 포함되어야 한다. 소프트웨어 모듈은 RAM 메모리, 플래시 메모리, ROM 메모리, EPROM 메모리, EEPROM 메모리, 레지스터들, 하드 디스크, 이동식 디스크, CD-ROM, 또는 공지된 임의의 다른 형태의 저장 매체 내에 상주할 수도 있다. 예시적인 저장 매체는, 프로세가 저장 매체로부터 정보를 판독하거나 저장 매체에 정보를 기록할 수 있도록, 프로세서에 커플링 될 수 있다. 대안으로, 저장 매체는 프로세서에 통합될 수도 있다. 프로세서와 저장 매체는 ASIC 내에 존재할 수도 있다. ASIC은 유저 단말 내에 존재할 수도 있다. 대안으로, 프로세서와 저장 매체는 유저 단말에 서 개별 컴포넌트들로써 존재할 수도 있다. 본 개시의 앞선 설명은 당업자들이 본 개시를 행하거나 이용하는 것을 가능하게 하기 위해 제공된다. 본 개시 의 다양한 수정예들이 당업자들에게 쉽게 자명할 것이고, 본원에 정의된 일반적인 원리들은 본 개시의 취지 또 는 범위를 벗어나지 않으면서 다양한 변형예들에 적용될 수도 있다. 따라서, 본 개시는 본원에 설명된 예들에 제한되도록 의도된 것이 아니고, 본원에 개시된 원리들 및 신규한 특징들과 일관되는 최광의의 범위가 부여되도 록 의도된다. 비록 예시적인 구현예들이 하나 이상의 독립형 컴퓨터 시스템의 맥락에서 현재 개시된 주제의 양태들을 활용하 는 것을 언급할 수도 있으나, 본 주제는 그렇게 제한되지 않고, 오히려 네트워크나 분산 컴퓨팅 환경과 같은 임 의의 컴퓨팅 환경과 연계하여 구현될 수도 있다. 또 나아가, 현재 개시된 주제의 양상들은 복수의 프로세싱 칩 들이나 디바이스들에서 또는 그들에 걸쳐 구현될 수도 있고, 스토리지는 복수의 디바이스들에 걸쳐 유사하게 영 향을 받게 될 수도 있다. 이러한 디바이스들은 PC들, 네트워크 서버들, 및 핸드헬드 디바이스들을 포함할 수도 있다."}
{"patent_id": "10-2020-0140026", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "본 명세서에서는 본 개시가 일부 실시예들과 관련하여 설명되었지만, 본 발명이 속하는 기술분야의 통상의 기술 자가 이해할 수 있는 본 개시의 범위를 벗어나지 않는 범위에서 다양한 변형 및 변경이 이루어질 수 있다는 점 을 알아야 할 것이다. 또한, 그러한 변형 및 변경은 본 명세서에서 첨부된 특허청구의 범위 내에 속하는 것으 로 생각되어야 한다.부호의 설명 100: 변형가능한 3D 움직임 모델 생성 시스템 102: 사용자를 포함한 이미지 104: 대상 콘텐츠 스타일이 반영된 변형가능한 3D 움직임 모델 110: 통신부 120: 저장부 130: 제어부"}
{"patent_id": "10-2020-0140026", "section": "도면", "subsection": "도면설명", "item": 1, "content": "본 개시의 실시예들은, 이하 설명하는 첨부 도면들을 참조하여 설명될 것이며, 여기서 유사한 참조 번호는 유사 한 요소들을 나타내지만, 이에 한정되지는 않는다. 도 1은 본 개시의 일 실시예에 따른, 변형가능한 3D 움직임 모델 생성 시스템의 구성을 나타내는 블록도이다. 도 2는 본 개시의 일 실시예에 따른, 변형가능한 3D 움직임 모델 생성 방법을 나타내는 흐름도이다. 도 3은 본 개시의 일 실시예에 따른, 변형가능한 3D 움직임 모델에 콘텐츠 스타일의 적용 정도(level)를 조정하 고, 조정된 적용 정보에 따라 변형된 3D 움직임 모델을 보여주는 예시도이다. 도 4는 본 개시의 일 실시예에 따른, 커스터마이징 정보에 기초해 변형된 변형가능한 3D 움직임 모델을 나타내 는 예시도이다. 도 5는 본 개시의 일 실시예에 따른, 특정 표정 정보를 가진 모델의 형태 정보를 이용하여 변형된 변형가능한 3D 움직임 모델을 나타내는 예시도이다. 도 6은 본 개시의 일 실시예에 따른, 복수의 콘텐츠 스타일이 적용된 변형가능한 3D 움직임 모델을 나타내는 예 시도이다. 도 7은 본 개시의 일 실시예에 따른, 변형가능한 3D 움직임 모델에 포함된 복수의 국소(local) 객체에 대한 변 형가능한 3D 움직임 모델를 설명하는 예시도이다. 도 8은 본 개시의 일 실시예에 따른, 변형가능한 3D 움직임 모델의 국소 객체에 콘텐츠 스타일에 포함된 국소컨텐츠 스타일을 적용하는 방법을 설명하는 예시도이다. 도 9는 본 개시의 일 실시예에 따른, 대상 콘텐츠 스타일에 대응하는 변형가능한 3D 움직임 모델에 포함된 3D 머리카락 모델을 대상 콘텐츠 스타일이 반영된 변형가능한 3D 움직임 모델의 형태 변형에 따라 머리카락 모델을 변형하는 방법을 나타내는 예시도이다. 도 10은 본 개시에서 적용될 수 있는 인공신경망 모델을 나타내는 예시도이다."}
