{"patent_id": "10-2018-0122683", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2020-0046145", "출원번호": "10-2018-0122683", "발명의 명칭": "예측 모델 훈련 관리 시스템, 예측 모델 훈련 관리 방법, 예측 모델 학습 관리를 위한 마스터", "출원인": "펑션베이", "발명자": "홍충선"}}
{"patent_id": "10-2018-0122683", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "예측 모델을 생성하고 예측 모델에 대한 훈련을 수행하여 훈련된 예측 모델을 획득하는 마스터 장치; 및데이터를 수집하여 상기 마스터 장치에 전송하고, 상기 마스터 장치로부터 상기 예측 모델 또는 상기 훈련된 예측 모델을 수신하고 상기 예측 모델 또는 상기 훈련된 예측 모델을 기반으로 동작하는 슬레이브 장치;를 포함하되,상기 마스터 장치는, 상기 슬레이브 장치로부터 전송된 데이터를 기반으로 상기 예측 모델을 생성하거나 또는상기 예측 모델에 대한 훈련을 수행하는 예측 모델 훈련 관리 시스템."}
{"patent_id": "10-2018-0122683", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 예측 모델은, 입력된 데이터에 대응하는 클래스에 대한 예측 결과를 획득하는 제1 예측 모델; 및 상기 제1 예측 모델의 결과가 입력되고, 상기 제1 예측 모델의 결과에 대응하여 예측 결과를 획득하는 제2 예측모델;을 포함하는 예측 모델 훈련 관리 시스템."}
{"patent_id": "10-2018-0122683", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,상기 제1 예측 모델은, 데이터가 입력되는 제1 알고리즘; 및 상기 제1 알고리즘의 출력 결과가 입력되는 제2 알고리즘;을 포함하는 예측 모델 훈련 관리 시스템."}
{"patent_id": "10-2018-0122683", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서,상기 제1 알고리즘 및 상기 제2 알고리즘은 기계 학습 알고리즘 중 적어도 하나를 포함하되, 상기 기계 학습 알고리즘은, 다층 퍼셉트론(MLN, Multilayer Perceptron), 심층 신경망(DNN, Deep NeuralNetwork), 또는 콘볼루션 신경망(CNN, Convolutional Neural Network), 순환 신경망(RNN, Recurrent NeuralNetwork), 콘볼루션 순환 신경망(CRNN, Convolutional Recurrent Neural Network), 심층 신뢰 신경망(DBN,Deep Belief Network) 및 심층 Q-네트워크(Deep Q-Networks) 중 적어도 하나를 포함하는 예측 모델 훈련 관리시스템."}
{"patent_id": "10-2018-0122683", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제3항에 있어서,상기 입력된 데이터는, 데이터가 다차원으로 배열된 텐서인 예측 모델 훈련 관리 시스템."}
{"patent_id": "10-2018-0122683", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5항에 있어서,상기 텐서는, 특성의 종류 및 예측하고자 하는 데이터 주변의 데이터 포인트를 포함하는 예측 모델 훈련 관리시스템.공개특허 10-2020-0046145-3-청구항 7 제1항에 있어서,상기 슬레이브 장치는, 상기 마스터 장치와 독립적으로 상기 예측 모델 또는 상기 훈련된 예측 모델에 대한 훈련을 수행하고, 상기 훈련 결과를 상기 마스터 장치로 전송하는 예측 모델 훈련 관리 시스템."}
{"patent_id": "10-2018-0122683", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서,상기 마스터 장치는, 상기 훈련 결과를 기반으로 훈련된 예측 모델을 갱신하는 예측 모델 훈련 관리 시스템."}
{"patent_id": "10-2018-0122683", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1항에 있어서,상기 마스터 장치 및 상기 슬레이브 장치 중 적어도 하나는,수집된 데이터에 대한 적어도 하나의 처리를 수행하거나, 수집된 데이터를 기반으로 데이터 셋을 생성하는 데이터 처리부;적어도 하나의 예측 모델을 생성하는 모델 생성부;데이터 처리부가 전달한 데이터 또는 데이터 셋을 기반으로 상기 모델 생성부가 생성한 적어도 하나의 예측 모델에 대한 훈련을 수행하는 모델 훈련부; 상기 모델 생성부가 생성한 예측 모델 및 상기 모델 훈련부에 의해 훈련된 예측 모델 중 적어도 하나를 이용하여 예측 결과를 획득하는 예측부; 및상기 데이터 처리부, 상기 모델 생성부, 상기 모델 훈련부 및 상기 예측부 중 적어도 하나를 제어 및 관리하는인공 지능 관리자;를 포함하는 예측 모델 훈련 관리 시스템."}
{"patent_id": "10-2018-0122683", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "슬레이브 장치와 통신 가능하게 연결되고, 상기 슬레이브 장치로부터 데이터를 수신하는 통신부; 및예측 모델을 생성하고 예측 모델에 대한 훈련을 수행하여 훈련된 예측 모델을 획득하는 프로세서;를 포함하되,상기 통신부는 상기 예측 모델 또는 상기 훈련된 예측 모델을 상기 슬레이브 장치로 전송하는 마스터 장치."}
{"patent_id": "10-2018-0122683", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제10항에 있어서,상기 프로세서는, 수집된 데이터에 대한 적어도 하나의 처리를 수행하거나, 수집된 데이터를 기반으로 데이터 셋을 생성하는 데이터 처리부;적어도 하나의 예측 모델을 생성하는 모델 생성부; 및데이터 처리부가 전달한 데이터 또는 데이터 셋을 기반으로 상기 모델 생성부가 생성한 적어도 하나의 예측 모델에 대한 훈련을 수행하는 모델 훈련부;를 포함하는 마스터 장치."}
{"patent_id": "10-2018-0122683", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항에 있어서,상기 예측 모델은, 입력된 데이터에 대응하는 클래스에 대한 예측 결과를 획득하는 제1 예측 모델; 및 상기 제1 예측 모델의 결과가 입력되고, 상기 제1 예측 모델의 결과에 대응하여 예측 결과를 획득하는 제2 예측모델;을 포함하는 마스터 장치.공개특허 10-2020-0046145-4-청구항 13 제12항에 있어서,상기 제1 예측 모델은, 데이터가 입력되는 제1 알고리즘; 및 상기 제1 알고리즘의 출력 결과가 입력되는 제2 알고리즘;을 포함하는 마스터 장치."}
{"patent_id": "10-2018-0122683", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제13항에 있어서,상기 제1 알고리즘 및 상기 제2 알고리즘은 기계 학습 알고리즘 중 적어도 하나를 포함하되, 상기 기계 학습 알고리즘은, 다층 퍼셉트론, 심층 신경망, 또는 콘볼루션 신경망, 순환 신경망, 콘볼루션 순환신경망, 심층 신뢰 신경망 및 심층 Q-네트워크 중 적어도 하나를 포함하는 마스터 장치."}
{"patent_id": "10-2018-0122683", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제11항에 있어서,상기 프로세서는,상기 모델 생성부가 생성한 예측 모델 및 상기 모델 훈련부에 의해 훈련된 예측 모델 중 적어도 하나를 이용하여 예측 결과를 획득하는 예측부;를 더 포함하는 마스터 장치."}
{"patent_id": "10-2018-0122683", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제15항에 있어서,상기 프로세서는,상기 데이터 처리부, 상기 모델 생성부, 상기 모델 훈련부 및 상기 예측부 중 적어도 하나를 제어 및 관리하는인공 지능 관리자;를 더 포함하는 마스터 장치."}
{"patent_id": "10-2018-0122683", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "마스터 장치로부터 예측 모델 또는 훈련된 예측 모델을 수신하는 통신부; 및상기 예측 모델 또는 상기 훈련된 예측 모델을 기반으로 제어 명령을 생성하는 프로세서;를 포함하되,상기 프로세서는, 상기 예측 모델 또는 상기 훈련된 예측 모델에 대한 훈련을 수행하고,상기 통신부는, 상기 훈련 결과를 상기 마스터 장치로 전송하는 슬레이브 장치."}
{"patent_id": "10-2018-0122683", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제17항에 있어서,상기 예측 모델은, 입력된 데이터에 대응하는 클래스에 대한 예측 결과를 획득하는 제1 예측 모델; 및 상기 제1 예측 모델의 결과가 입력되고, 상기 제1 예측 모델의 결과에 대응하여 예측 결과를 획득하는 제2 예측모델;을 포함하는 슬레이브 장치."}
{"patent_id": "10-2018-0122683", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "마스터 장치 및 슬레이브 장치 중 적어도 하나가 데이터를 수집하는 단계;상기 마스터 장치 및 상기 슬레이브 장치 중 적어도 하나가 상기 데이터를 기반으로 예측 모델을 생성하는단계;상기 마스터 장치 및 상기 슬레이브 장치 중 적어도 하나가 상기 예측 모델에 대한 훈련을 수행하여 훈련된 예공개특허 10-2020-0046145-5-측 모델을 획득하는 단계; 및상기 마스터 장치 및 상기 슬레이브 장치 중 적어도 하나가 상기 예측 모델 및 상기 훈련된 예측 모델 중 적어도 하나를 기반으로 예측을 수행하는 단계;를 포함하되,상기 예측 모델은, 입력된 데이터에 대응하는 클래스에 대한 예측 결과를 획득하는 제1 예측 모델; 및 상기 제1 예측 모델의 결과가 입력되고, 상기 제1 예측 모델의 결과에 대응하여 예측 결과를 획득하는 제2 예측모델;을 포함하는 예측 모델 훈련 관리 방법."}
{"patent_id": "10-2018-0122683", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제19항에 있어서,상기 제1 예측 모델은, 데이터가 입력되는 제1 알고리즘 및 상기 제1 알고리즘의 출력 결과가 입력되는 제2 알고리즘을 포함하되, 상기 제1 알고리즘 및 상기 제2 알고리즘은 기계 학습 알고리즘 중 적어도 하나를 포함하고,상기 기계 학습 알고리즘은, 다층 퍼셉트론, 심층 신경망, 또는 콘볼루션 신경망, 순환 신경망, 콘볼루션 순환신경망, 심층 신뢰 신경망 및 심층 Q-네트워크 중 적어도 하나를 포함하는 예측 모델 훈련 관리 방법."}
{"patent_id": "10-2018-0122683", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명의 실시예에 따른 예측모델 훈련 관리 시스템은 예측 모델을 생성하고 예측 모델에 대한 훈련을 수행하여 훈련된 예측 모델을 획득하는 마스터 장치 및 데이터를 수집하여 상기 마스터 장치에 전송하고, 상기 마스터 장 치로부터 상기 예측 모델 또는 상기 훈련된 예측 모델을 수신하고 상기 예측 모델 또는 상기 훈련된 예측 모델을 기반으로 동작하는 슬레이브 장치를 포함하되, 상기 마스터 장치는, 상기 슬레이브 장치로부터 전송된 데이터를 기반으로 상기 예측 모델을 생성하거나 또는 상기 예측 모델에 대한 훈련을 수행할 수 있다."}
{"patent_id": "10-2018-0122683", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "예측 모델 훈련 관리 시스템, 예측 모델 훈련 관리 방법, 예측 모델 학습 관리를 위한 마스터 장치 및 슬레이브 장치에 관한 것이다."}
{"patent_id": "10-2018-0122683", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "근자에 다양한 분야에서 인공 지능이 이용되고 있다. 구체적으로 인공 지능은 바둑의 다음 수를 결정하거나, 글 자를 인식하거나 또는 하나의 언어를 다른 언어로 번역하는 등 다양한 분야에 채용되어 이용되고 있다. 인공 지능 기술은 기계 학습(machine learning)을 포함한다. 기계 학습은 소정의 알고리즘이 주어지면, 획득한 다양한 정보를 이용하여 소정의 알고리즘에 대한 학습을 수행하고, 학습 수행 결과에 따른 학습된 알고리즘을 획득하는 과정이다. 다시 말해서, 기계 학습은 장치(예를 들어, 컴퓨터)가 직접 학습을 수행하여 스스로 규칙을 형성하는 과정을 의미한다. 한편, 네트워크 자원의 지능적 관리를 위한 기계 학습을 수행함에 있어서, 이를 위한 알고리즘(예를 들어, 예측 모델)의 학습 과정은 여러 가지 문제점을 가지고 있다. 구체적으로 다양한 유형의 학습 모델들(예를 들어, 다층 퍼셉트론(MLN, Multilayer Perceptron)이나, 심층 신경망(DNN, Deep Neural Network)이나, 또는 콘볼루션 신경 망(CNN, Convolutional Neural Network) 등) 중에서 어떠한 학습 모델이 적절한 모델인지를 판단하는 것에 있 어 어려움이 존재한다. 또한, 서로 상이한 하이퍼 파라미터(hyper parameter)를 이용하여 다양한 유형의 학습 모델들 중에서 검색하는 것은 조합적인 문제이다. 선택된 학습 모델의 깊이, 학습 모델의 유형 또는 예측 속도 의 정확성 향상을 위한 학습 속도 등 매개 변수를 조정 및 결정하는 것에도 어려움이 존재한다. 이런 점 때문에 종래의 네트워크 자원의 지능적 관리를 위해 적절한 예측 모델을 결정 및 획득하는 방법은, 기술적, 산업적 및/ 또는 경제적으로 많은 문제점이 내포하고 있었다."}
{"patent_id": "10-2018-0122683", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "적절한 예측 모델의 획득 및/또는 이의 학습을 자동화할 수 있는 예측 모델 훈련 관리 시스템, 예측 모델 훈련 관리 방법, 예측 모델 학습 관리를 위한 마스터 장치 및 슬레이브 장치를 제공하는 것을 해결하고자 하는 과제 로 한다."}
{"patent_id": "10-2018-0122683", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상술한 과제를 해결하기 위하여 예측 모델 훈련 관리 시스템, 예측 모델 훈련 관리 방법, 예측 모델 학습 관리 를 위한 마스터 장치 및 슬레이브 장치를 제공한다. 예측 모델 훈련 관리 시스템은, 예측 모델을 생성하고 예측 모델에 대한 훈련을 수행하여 훈련된 예측 모델을 획득하는 마스터 장치 및 데이터를 수집하여 상기 마스터 장치에 전송하고, 상기 마스터 장치로부터 상기 예측 모델 또는 상기 훈련된 예측 모델을 수신하고 상기 예측 모델 또는 상기 훈련된 예측 모델을 기반으로 동작하는 슬레이브 장치를 포함하되, 상기 마스터 장치는, 상기 슬레이브 장치로부터 전송된 데이터를 기반으로 상기 예 측 모델을 생성하거나 또는 상기 예측 모델에 대한 훈련을 수행할 수 있다. 상기 예측 모델은, 입력된 데이터에 대응하는 클래스에 대한 예측 결과를 획득하는 제1 예측 모델 및 상기 제1 예측 모델의 결과가 입력되고, 상기 제1 예측 모델의 결과에 대응하여 예측 결과를 획득하는 제2 예측 모델을 포함할 수 있다. 상기 제1 예측 모델은, 데이터가 입력되는 제1 알고리즘 및 상기 제1 알고리즘의 출력 결과가 입력되는 제2 알 고리즘을 포함할 수 있다. 상기 제1 알고리즘 및 상기 제2 알고리즘은 기계 학습 알고리즘 중 적어도 하나를 포함하되, 상기 기계 학습 알 고리즘은, 다층 퍼셉트론(MLN, Multilayer Perceptron), 심층 신경망(DNN, Deep Neural Network), 또는 콘볼루 션 신경망(CNN, Convolutional Neural Network), 순환 신경망(RNN, Recurrent Neural Network), 콘볼루션 순환 신경망(CRNN, Convolutional Recurrent Neural Network), 심층 신뢰 신경망(DBN, Deep Belief Network) 및 심 층 Q-네트워크(Deep Q-Networks) 중 적어도 하나를 포함할 수 있다. 상기 입력된 데이터는, 데이터가 다차원으로 배열된 텐서를 포함할 수 있다. 상기 텐서는, 특성의 종류 및 예측하고자 하는 데이터 주변의 데이터 포인트를 포함할 수 있다. 상기 슬레이브 장치는, 상기 마스터 장치와 독립적으로 상기 예측 모델 또는 상기 훈련된 예측 모델에 대한 훈 련을 수행하고, 상기 훈련 결과를 상기 마스터 장치로 전송할 수 있다. 상기 마스터 장치는, 상기 훈련 결과를 기반으로 훈련된 예측 모델을 갱신할 수 있다. 상기 마스터 장치 및 상기 슬레이브 장치 중 적어도 하나는, 수집된 데이터에 대한 적어도 하나의 처리를 수행 하거나, 수집된 데이터를 기반으로 데이터 셋을 생성하는 데이터 처리부, 적어도 하나의 예측 모델을 생성하는 모델 생성부, 데이터 처리부가 전달한 데이터 또는 데이터 셋을 기반으로 상기 모델 생성부가 생성한 적어도 하 나의 예측 모델에 대한 훈련을 수행하는 모델 훈련부, 상기 모델 생성부가 생성한 예측 모델 및 상기 모델 훈련 부에 의해 훈련된 예측 모델 중 적어도 하나를 이용하여 예측 결과를 획득하는 예측부 및 상기 데이터 처리부, 상기 모델 생성부, 상기 모델 훈련부 및 상기 예측부 중 적어도 하나를 제어 및 관리하는 인공 지능 관리자를 포함할 수 있다. 마스터 장치는, 슬레이브 장치와 통신 가능하게 연결되고, 상기 슬레이브 장치로부터 데이터를 수신하는 통신부 및 예측 모델을 생성하고 예측 모델에 대한 훈련을 수행하여 훈련된 예측 모델을 획득하는 프로세서를 포함하되, 상기 통신부는 상기 예측 모델 또는 상기 훈련된 예측 모델을 상기 슬레이브 장치로 전송할 수 있다. 상기 프로세서는, 수집된 데이터에 대한 적어도 하나의 처리를 수행하거나, 수집된 데이터를 기반으로 데이터 셋을 생성하는 데이터 처리부, 적어도 하나의 예측 모델을 생성하는 모델 생성부 및 데이터 처리부가 전달한 데 이터 또는 데이터 셋을 기반으로 상기 모델 생성부가 생성한 적어도 하나의 예측 모델에 대한 훈련을 수행하는 모델 훈련부를 포함할 수 있다. 상기 예측 모델은, 입력된 데이터에 대응하는 클래스에 대한 예측 결과를 획득하는 제1 예측 모델 및 상기 제1 예측 모델의 결과가 입력되고, 상기 제1 예측 모델의 결과에 대응하여 예측 결과를 획득하는 제2 예측 모델을 포함할 수 있다. 상기 제1 예측 모델은, 데이터가 입력되는 제1 알고리즘 및 상기 제1 알고리즘의 출력 결과가 입력되는 제2 알 고리즘을 포함할 수 있다. 상기 제1 알고리즘 및 상기 제2 알고리즘은 기계 학습 알고리즘 중 적어도 하나를 포함하되, 상기 기계 학습 알 고리즘은, 다층 퍼셉트론, 심층 신경망, 또는 콘볼루션 신경망, 순환 신경망, 콘볼루션 순환 신경망, 심층 신뢰 신경망 및 심층 Q-네트워크 중 적어도 하나를 포함할 수 있다.상기 프로세서는, 상기 모델 생성부가 생성한 예측 모델 및 상기 모델 훈련부에 의해 훈련된 예측 모델 중 적어 도 하나를 이용하여 예측 결과를 획득하는 예측부를 더 포함할 수 있다. 상기 프로세서는, 상기 데이터 처리부, 상기 모델 생성부, 상기 모델 훈련부 및 상기 예측부 중 적어도 하나를 제어 및 관리하는 인공 지능 관리자를 더 포함할 수 있다. 슬레이브 장치는, 마스터 장치로부터 예측 모델 또는 훈련된 예측 모델을 수신하는 통신부 및 상기 예측 모델 또는 상기 훈련된 예측 모델을 기반으로 제어 명령을 생성하는 프로세서를 포함하되, 상기 프로세서는, 상기 예 측 모델 또는 상기 훈련된 예측 모델에 대한 훈련을 수행하고, 상기 통신부는, 상기 훈련 결과를 상기 마스터 장치로 전송할 수 있다. 상기 예측 모델은, 입력된 데이터에 대응하는 클래스에 대한 예측 결과를 획득하는 제1 예측 모델 및 상기 제1 예측 모델의 결과가 입력되고, 상기 제1 예측 모델의 결과에 대응하여 예측 결과를 획득하는 제2 예측 모델을 포함할 수 있다. 예측 모델 훈련 관리 방법은, 마스터 장치 및 슬레이브 장치 중 적어도 하나가 데이터를 수집하는 단계, 상기 마스터 장치 및 상기 슬레이브 장치 중 적어도 하나가 상기 데이터를 기반으로 예측 모델을 생성하는 단계, 상 기 마스터 장치 및 상기 슬레이브 장치 중 적어도 하나가 상기 예측 모델에 대한 훈련을 수행하여 훈련된 예측 모델을 획득하는 단계 및 상기 마스터 장치 및 상기 슬레이브 장치 중 적어도 하나가 상기 예측 모델 및 상기 훈련된 예측 모델 중 적어도 하나를 기반으로 예측을 수행하는 단계를 포함하되, 상기 예측 모델은, 입력된 데 이터에 대응하는 클래스에 대한 예측 결과를 획득하는 제1 예측 모델 및 상기 제1 예측 모델의 결과가 입력되고, 상기 제1 예측 모델의 결과에 대응하여 예측 결과를 획득하는 제2 예측 모델을 포함할 수 있다. 상기 제1 예측 모델은, 데이터가 입력되는 제1 알고리즘 및 상기 제1 알고리즘의 출력 결과가 입력되는 제2 알 고리즘을 포함하되, 상기 제1 알고리즘 및 상기 제2 알고리즘은 기계 학습 알고리즘 중 적어도 하나를 포함하고, 상기 기계 학습 알고리즘은, 다층 퍼셉트론, 심층 신경망, 또는 콘볼루션 신경망, 순환 신경망, 콘볼 루션 순환 신경망, 심층 신뢰 신경망 및 심층 Q-네트워크 중 적어도 하나를 포함할 수 있다."}
{"patent_id": "10-2018-0122683", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "상술한 예측 모델 훈련 관리 시스템, 예측 모델 훈련 관리 방법, 예측 모델 학습 관리를 위한 마스터 장치 및 슬레이브 장치에 의하면, 다양한 유형의 예측 작업에 대해 자동적으로 가장 적절한 예측 모델을 획득하고, 획득 한 예측 모델에 대한 학습을 수행할 수 있게 되는 효과를 얻을 수 있다. 상술한 예측 모델 훈련 관리 시스템, 예측 모델 훈련 관리 방법, 예측 모델 학습 관리를 위한 마스터 장치 및 슬레이브 장치에 의하면, 상대적으로 용이하게 복수의 모델 중에서 최적의 예측 모델의 검색 및 선택을 수행할 수 있게 되는 효과도 얻을 수 있다. 상술한 예측 모델 훈련 관리 시스템, 예측 모델 훈련 관리 방법, 예측 모델 학습 관리를 위한 마스터 장치 및 슬레이브 장치에 의하면, 상대적으로 낮은 복잡성을 갖는 시스템도 여러 예측 모델 중에서 최적의 예측 모델을 획득하는 효과를 얻을 수 있으며, 이에 따라 시스템 구축의 경제성 역시 개선되는 효과도 얻을 수 있다. 상술한 예측 모델 훈련 관리 시스템, 예측 모델 훈련 관리 방법, 예측 모델 학습 관리를 위한 마스터 장치 및 슬레이브 장치에 의하면, 사용자의 수요 예측 모델 등을 적절하게 획득하게 되어 이를 기반으로 한 네트워크의 자원의 지능적 관리를 수행할 수 있게 되고, 이에 따라 시스템의 자원 활용 효율을 증진할 수 있는 효과도 얻을 수도 있다. 상술한 예측 모델 훈련 관리 시스템, 예측 모델 훈련 관리 방법, 예측 모델 학습 관리를 위한 마스터 장치 및 슬레이브 장치에 의하면, 획득한 예측 모델의 정확성이 향상되는 효과도 얻을 수 있다. 또한, 상술한 예측 모델 훈련 관리 시스템, 예측 모델 훈련 관리 방법, 예측 모델 학습 관리를 위한 마스터 장 치 및 슬레이브 장치는 다양한 응용 분야의, 다양한 유형의 전자/기계 장치, 애플리케이션 및/또는 네트워크 관 리 등의 각종 서비스에 적용될 수 있으며, 이에 따라 다양한 장치, 애플리케이션 및/또는 서비스가, 각각의 동 작에 필요한 예측 모델을 용이하면서도 적합하게 획득할 수 있게 되는 효과도 얻을 수 있다."}
{"patent_id": "10-2018-0122683", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하 명세서 전체에서 특별한 사정이 없는 한 동일 구성 요소에 대해선 동일한 참조 부호를 이용하였다. 또한, 사용되는 '부'가 부가된 용어는, 소프트웨어 및/또는 하드웨어로 구현될 수 있으며, 실시예에 따라 '부'가 하나 의 소프트웨어, 하드웨어 및/또는 소정의 부품으로 구현되는 것도 가능하고, 하나의 '부'가 복수의 소프트웨어, 하드웨어 및/또는 소정의 부품들로 구현되는 것도 가능하다. 명세서 전체에서 어떤 부분이 다른 부분과 연결되어 있다고 할 때, 이는 어떤 부분과 다른 부분에 따라서 물리 적 연결을 의미할 수도 있고, 또는 전기적으로 연결된 것을 의미할 수도 있다. 또한, 어떤 부분이 다른 부분을 포함한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다른 부분 이외의 또 다른 부분을 제외하는 것이 아니 며, 설계자의 선택에 따라서 또 다른 부분을 더 포함할 수 있음을 의미한다. 단수의 표현은 문맥상 명백하게 예외가 있지 않는 한, 복수의 표현을 포함할 수 있다. 아울러, 제 1 이나 제 2 등의 용어는 하나의 부분을 다른 부분으로부터 구별하기 위해 사용되는 것으로, 특별한 기재가 없는 이상 이들 이 반드시 순차적인 표현을 의미하는 것은 아니다. 이하 도 1 내지 도 6을 참조하여 마스터 장치, 예측 모델 학습 관리를 위한 슬레이브 장치 및 이들을 포함하는 예측 모델 훈련 관리 시스템의 일 실시예에 대해서 설명하도록 한다. 도 1은 예측 모델 훈련 관리 시스템의 일 실시예에 대한 개요도이다. 도 1에 도시된 바에 따르면, 예측 모델 훈련 관리 시스템은, 일 실시예에 있어서, 마스터 노드(100, Master Node, 이하 마스터 장치라 지칭함)와, 마스터 장치와 통신 가능하게 마련되는 슬레이브 노드(200, Slave Node, 이하 슬레이브 장치라 지칭함)를 포함할 수 있다. 마스터 장치는, 데이터를 수집하고, 수집한 데이터를 기반으로 예측 모델을 생성하고, 예측 모델에 대한 훈련(training) 또는 학습(learing)을 수행하여 최적의 모델을 선택할 수 있도록 설계된 것일 수 있다. 여기서, 예측 모델은, 제품, 서비스, 애플리케이션 및/또는 영상이나 음악 콘텐트 등에 대한 사용자 수요 예측이나, 특 정 콘텐트에 대한 인기도의 예측이나, 마스터 장치나 슬레이브 장치 등에 대한 사용자의 선호 동작에 대한 예측 등과 같이 설계자가 요구하는 소정의 예측을 수행하기 위해 이용되는 모델을 포함한다. 이와 같은 예 측 모델의 생성, 훈련 및 학습에 대한 자세한 내용은 후술한다. 마스터 장치는, 하나 또는 둘 이상의 컴퓨팅 장치(100-1 내지 100-3)를 포함할 수 있다. 다시 말해서, 마 스터 장치는 오직 하나의 컴퓨팅 장치(100-1)를 이용하여 구현될 수도 있고, 또는 둘 이상의 컴퓨팅 장치 (100-2, 100-3)를 이용하여 구현될 수도 있다. 둘 이상의 컴퓨팅 장치(100-2, 100-3)를 이용하는 경우, 이들은 상호 통신 가능하게 연결된 것일 수도 있다. 컴퓨팅 장치(100-1 내지 100-3)는, 연산 및 처리가 가능한 전자 장 치를 포함할 수 있으며, 예를 들어 통상적인 데스크톱 컴퓨터, 랩톱 컴퓨터 및/또는 서버 컴퓨터 등을 이용하여 구현될 수도 있다. 또한, 컴퓨팅 장치(100-1 내지 100-3)는, 실시예에 따라서, 스마트폰(smart phone), 태블릿 피씨(tablet PC) 및/또는 사물 인터넷(IoT) 등과 연결된 가전 기기 등과 같은 전자 장치를 포함하는 것도 가능 하다. 슬레이브 장치는, 마스터 장치로부터 예측 모델을 수신하고, 수신된 모델을 이용하여 소정의 태스크 를 처리하거나 소정의 동작을 수행할 수 있다. 예를 들어, 슬레이브 장치는 콘텐트의 인기도를 예측하거나, 또는 사용자의 수요를 예측할 수도 있다. 또한, 슬레이브 장치는, 마스터 장치로부터 제 어 명령을 수신하고, 수신한 제어 명령에 따라 동작할 수도 있다. 슬레이브 장치는, 주변 환경으로부터 각종 로컬 데이터를 수집하고, 수집한 로컬 데이터를 마스터 장치 로 전송할 수도 있다. 또한, 슬레이브 장치는, 실시예에 따라서, 마스터 장치와 독립적으로 마스터 장치로부터 수신한 예측 모델에 대한 훈련/학습을 수행할 수도 있다. 다시 말해서, 마스터 장치(10 0)와 슬레이브 장치 양자 모두 기계 학습을 처리하도록 마련되는 것도 가능하다. 이 경우, 슬레이브 장치 는 독립적으로 학습된 예측 모델을 마스터 장치에 전송할 수도 있다. 학습된 예측 모델에 대한 정보 는, 예를 들어, 모델의 가중치 및/또는 그래디언트(기울기) 등에 대한 정보를 포함할 수 있다. 이 경우, 마스터 장치는, 슬레이브 장치로부터 로컬 데이터를 수신하거나 및/또는 슬레이브 장치에 의해 학습된 예측 모델을 수신하면, 슬레이브 장치로부터 수신한 로컬 데이터 및/또는 예측 모델을 이용하여, 기존의 예측 모델에 대해 학습/훈련을 더 수행함으로써 기존의 예측 모델을 갱신할 수도 있다. 슬레이브 장치는, 하나 또는 둘 이상의 슬레이브 장치(200-1 내지 200-5)를 포함할 수 있다. 둘 이상의 슬 레이브 장치(200-1 내지 200-5)를 포함하는 경우, 이들 슬레이브 장치(200-1 내지 200-5)는 서로 동종의 장치일 수도 있고, 또는 서로 이종의 장치일 수도 있다. 또한, 이들 장치(200-1 내지 200-5) 중 일부는 동종이고 다른 일부는 이종인 것도 가능하다. 일 실시예에 의하면, 슬레이브 장치는, 베이스 스테이션(200-1, base station, 기지국으로 표현 가능함)이 나 스몰 셀 스테이션(미도시, small cell station, 소형 기지국으로 표현 가능함)을 포함할 수도 있다. 또한, 슬레이브 장치는, 예를 들어, 스마트 폰(200-2), 차량(200-3) 또는 차량에 설치된 전자 기기(예를 들어, 내비게이션 장치 등), 컴퓨터 장치(200-4, 예를 들어, 데스크톱 컴퓨터, 랩톱 컴퓨터 및/또는 서버 컴퓨터 등), 사물 인터넷이 적용된 가전 기기(200-5, 예를 들어, 디지털 텔레비전 등의 흑색 가전이나 냉장고 등의 백색 가 전) 등을 포함할 수 있다. 뿐만 아니라, 슬레이브 장치는, 태블릿 피씨, 스마트 시계, 두부 장착형 디스플 레이(HMD, Head Mounted Display) 장치, 셋톱 박스, 개인용 디지털 보조기(PDA, Personal Digital Assistant), 휴대용 게임기, 전자 칠판, 전자 광고판, 음향 재생 장치, 및/또는 현금 자동 입출입기(ATM, Automated Teller Machine) 등을 포함할 수도 있으며, 또한 이들 외에도 설계자의 선택에 따라서 데이터의 수집 및/또는 연산 처 리가 가능한 장치 중 적어도 하나를 포함할 수도 있다. 마스터 장치 및 슬레이브 장치 각각은, 소정의 통신 네트워크를 통하여 데이터를 송신하거나 및/ 또는 수신할 수 있다. 소정의 통신 네트워크는 유선 통신 네트워크, 무선 통신 네트워크 또는 이들의 조합 으로 이루어진 통신 네트워크를 포함할 수 있다. 여기서, 유선 통신 네트워크는, 소정의 케이블을 이용하여 구 축된 통신 네트워크를 포함할 수 있다. 케이블은, 예를 들어, 페어 케이블, 동축 케이블, 광섬유 케이블 및/또 는 이더넷 케이블 등을 단독적으로 또는 조합하여 이용하여 구현된 것일 수 있다. 무선 통신 네트워크는 근거리 통신 네트워크 및 원거리 통신 네트워크 중 적어도 하나를, 단독으로 또는 조합하여 구현된 것일 수 있다. 예를 들어, 근거리 통신 네트워크는 와이파이(Wi-Fi), 와이파이 다이렉트(Wi-Fi Direct), 블루투스(Bluetooth), 저전 력 블루투스(Bluetooth Low Energy), 캔(CAN) 통신, 지그비(zigbee) 통신 및/또는 엔에프씨(NFC, Near Field Communication) 등을 통상 이용 가능한 근거리 통신 네트워크를 기반으로 구현된 것일 수 있다. 원거리 통신 네 트워크는, 예를 들어, 3GPP(예를 들어, HSPA+나 LTE 등), 3GPP2(CDMA2000 등) 및/또는 와이맥스나 와이브로 계 열 등과 같이 통상적으로 채용 가능한 이동 통신 규격을 기반으로 구현된 것일 수 있다. 도 2는 예측 모델 훈련 관리 시스템의 일 실시예에 대한 블록도이다. 도 2에 도시된 바에 의하면, 예측 모델 훈련 관리 시스템의 마스터 장치는 수집부, 프로세서 및 저장부를 포함할 수 있고, 슬레이브 장치는 통신부 및 프로세서를 포함할 수 있다. 슬 레이브 장치는, 필요에 따라, 수집부 및 저장부 중 적어도 하나를 더 포함하는 것도 가능하다. 마스터 장치의 수집부는 모델의 생성 및/또는 학습에 필요한 적어도 하나의 데이터를 수집할 수 있다. 예를 들어, 수집부는 슬레이브 장치가 수집한 다양한 종류의 데이터를 수집할 수도 있다. 이 경우, 수집부는 슬레이브 장치의 통신부과 통신 수행이 가능한 통신부를 포함할 수 있다. 통신부 는 상술한 통신 네트워크를 통해 데이터를 수신할 수 있는 통신 장치를 포함할 수 있다. 통신부는 슬 레이브 장치로부터 슬레이브 장치가 수집한 다양한 종류의 데이터를 수신할 수 있다. 또한, 수집부 는 별도로 사전에 구축된 데이터베이스(미도시) 등에서 데이터를 추출하여 수집할 수도 있다. 뿐만 아니라, 수집부는 소정의 입력 장치(예를 들어, 키보드, 마우스, 터치 스크린, GPS 수신기, 천공 카드, 외 장 메모리 슬롯, 카메라, 마이크로 폰, 인터넷 네트워크 등을 통해 수집되는 각종 외부 정보 등)를 포함할 수도 있다. 수집부는 이들 입력 장치의 조작 또는 동작에 따라 각종 데이터를 수집하는 것도 가능하다. 수집부에 의해 수집되는 데이터는 한정되지 않는다. 예를 들어, 데이터는 사용자가 기존에 선택한 명령이 나 지시, 사용자가 기존에 요청한 콘텐트(content), 요청된 명령/지시 또는 콘텐트의 메타 정보(예를 들어, 카 테고리나 등급 등), 이들의 요청 또는 선택 횟수, 이들의 요청 또는 선택 날짜/시즌/시간, 예측 대상이 되는 데 이터 주변의 데이터 포인트(date point) 또는 이들의 개수 및/또는 이외 설계자가 예측에 필요하다가 고려 가능 한 다양한 항목 등을 포함할 수 있다. 수집부에 의해 수집된 각종 정보는, 전자 회로나 케이블 등을 통해 프로세서로 전달될 수 있다. 프로세서는, 예측 모델 훈련 관리 및 이와 관련된 각종 연산 처리를 수행 가능하도록 마련된다. 또한, 프 로세서는 예측 모델의 생성, 예측 모델의 학습 및/또는 예측 모델에 기반한 동작(예를 들어, 사용자의 요 청/선택에 대한 예측) 등을 수행할 수 있도록 마련된다. 보다 구체적으로 예를 들어, 프로세서는 수집부를 제어하여 데이터베이스로부터 데이터를 추출하거나, 슬레이브 장치로 데이터 전송 명령을 전달하여 슬레이브 장치가 수집한 데이터를 마스터 장치로 전송하도록 제어하거나, 모델 사전(도 3의 121)으로부터 필요한 학습 모델을 호출하거나, 다양한 유형의 예측 모델을 생성하거나, 각종 기계 학습 알고리즘을 이용하여 예측 모델에 대한 학습을 수행하거나, 슬 레이브 장치로의 생성된 예측 모델 또는 학습된 예측 모델의 전송을 제어하거나, 및/또는 생성되거나 학습 된 예측 모델을 이용하여 예측 결과를 결정 및 획득할 수도 있다. 또한, 필요에 따라, 프로세서는, 예측 결과에 따른 동작을 수행하거나, 예측 결과를 슬레이브 장치로 전송하거나, 및/또는 예측 결과에 대응하는 명령을 생성한 후 생성한 명령을 슬레이브 장치로 전송할 수도 있다. 이외에도 프로세서는 마스터 장 치의 전반적인 동작을 제어하는 것도 가능하다. 프로세서의 예측 모델의 생성 및 학습에 대한 자세한 설명은 후술하도록 한다. 프로세서는 저장부에 저장된 애플리케이션을 구동시켜, 미리 정의된 연산, 판단, 처리 및/또는 제어 동작 등을 수행할 수도 있다. 여기서, 저장부에 저장된 애플리케이션은, 설계자에 의해 미리 작성되어 저 장부에 저장된 것일 수도 있고, 또는 유선 또는 무선 통신 네트워크를 통해 접속 가능한 전자 소프트웨어 유통망을 통하여 획득 또는 갱신된 것일 수도 있다. 프로세서는 적어도 하나의 전자 장치를 채용하여 구현 가능하며, 적어도 하나의 전자 장치는, 예를 들어, 중앙 처리 장치(CPU, Central Processing Unit), 마이크로 컨트롤러 유닛(MCU, Micro Controller Unit), 마이 컴(Micom, Micro Processor), 애플리케이션 프로세서(AP, Application Processor), 전자 제어 유닛(ECU, Electronic Controlling Unit) 및/또는 각종 연산 처리 및 제어 신호의 생성이 가능한 다른 전자 장치 등을 포 함할 수 있다. 이들 장치는 예를 들어 하나 또는 둘 이상의 반도체 칩 및 관련 부품을 이용하여 구현 가능하다. 저장부는, 프로세서의 동작에 필요하거나 또는 기타 기록할 필요가 있는 각종 데이터나 애플리케이션 등을 일시적 또는 비일시적으로 기록하여 보관하도록 마련된다. 예를 들어, 저장부는 후술하는 바와 같이, 모델 사전, 적어도 하나의 수집한 데이터(도 3의 123, 원 시 데이터나 사전 처리 데이터 등을 포함할 수도 있다), 적어도 하나의 생성/획득한 예측 모델(도 3의 125), 적 어도 하나의 학습된 예측 모델(도 3의 127) 및/또는 이들과 관련된 각종 정보를 저장할 수 있다. 이들과 관련된 각종 정보는 로 데이터(raw data) 및/또는 생성된 모델이나 학습된 모델의 설정 정보(configuration) 등을 포함 가능하다. 또한, 저장부는 예측 모델 및/또는 학습된 예측 모델을 저장함에 있어서, 그들의 하 이퍼 파라미터를 단독적으로 또는 이들과 함께 저장할 수도 있다. 하이퍼 파라미터는 기계 학습 알고리즘의 실 행을 위해 설정되는 변수로, 예를 들어, 은닉층(hidden layer)의 개수나 학습 비율(learing rate) 등을 포함할 수 있다. 저장부는 하나 또는 둘 이상의 물리적 저장 매체(예를 들어, 하드 디스크 장치)를 이용하여 구현될 수 있 으며, 상술한 데이터 및/또는 모델 등은 하나의 물리적 저장 매체에 저장될 수도 있고, 복수의 물리적 저장 매 체에 분산되어 저장될 수도 있다. 필요에 따라서, 각각의 데이터 및/또는 모델 등을 저장하기 위해 특정한 저장 매체가 할당되어 있을 수도 있다. 저장부는, 주기억장치 및 보조기억장치 중 적어도 하나를 포함할 수 있다. 주기억장치는 롬(ROM) 및/또는 램(RAM)과 같은 반도체 저장 매체를 이용하여 구현된 것일 수 있다. 롬은, 예를 들어, 통상적인 롬, 이프롬 (EPROM), 이이프롬(EEPROM) 및/또는 마스크롬(MASK-ROM) 등을 포함할 수 있다. 램은 예를 들어, 디램(DRAM) 및 /또는 에스램(SRAM) 등을 포함할 수 있다. 보조기억장치는, 플래시 메모리 장치, SD(Secure Digital) 카드, 솔 리드 스테이트 드라이브(SSD, Solid State Drive), 하드 디스크 드라이브(HDD, Hard Disc Drive), 자기 드럼, 컴팩트 디스크(CD), 디브이디(DVD) 또는 레이저 디스크 등과 같은 광 기록 매체(optical media), 자기 테이프,광자기 디스크 및/또는 플로피 디스크 등과 같이 데이터를 영구적 또는 반영구적으로 저장 가능한 적어도 하나 의 저장 매체를 이용하여 구현될 수 있다. 일 실시예에 의하면, 슬레이브 장치의 통신부는 마스터 장치의 통신부와 통신 가능하게 마 련된다. 통신부는 마스터 장치의 통신부로부터 제어 명령, 데이터 및/또는 예측 모델을 수신할 수도 있고, 또한 마스터 장치의 통신부로 수집부에 의해 수집한 데이터, 직접 생성하거나 학습 하여 갱신한 예측 모델 또는 이와 같은 예측 모델과 관련된 정보 및/또는 제어 명령에 대응하는 피드백 신호 등 을 전송할 수 있다. 슬레이브 장치의 통신부 역시 상술한 통신 네트워크를 통해 데이터를 수신할 수 있는 통신 장치를 채용하여 구현 가능하다. 슬레이브 장치의 수집부는 각종 데이터를 수집할 수 있다. 예를 들어, 수집부는 슬레이브 장치 에 연결된 각종 장치(예를 들어, 키보드, 터치 스크린, 외장 메모리 슬롯, GPS 수신기, 카메라, 마이크로 폰, 스티어링 휠, 온도계 또는 습도계 등 각종 정보를 수집할 수 있는 장치)로부터 필요한 데이터를 획득하고, 획득한 정보를 프로세서로 전달할 수 있다. 또한, 수집부는 통신부를 통해 수신되는 다양한 외 부 정보를 수집하여 프로세서로 전달하는 것도 가능하다. 보다 구체적으로 예를 들어, 수집부는 각각 의 콘텐트의 요청 회수에 대한 카운트 값이나 캐쉬 히트 값과 같은 베이스 스테이션의 정보를 수집할 수도 있다. 프로세서는 슬레이브 장치의 전반적인 동작에 필요한 각종 연산 처리를 수행하거나 또는 이와 관련된 제어 신호를 생성할 수 있다. 프로세서는 실시예에 따라서 마스터 장치의 프로세서에 의해 생성 된 제어 명령에 따라 연산 및 제어 동작을 수행할 수도 있다. 일 실시예에 의하면, 프로세서는, 마스터 장치의 프로세서와 독립적으로 예측 모델의 생성 및/ 또는 학습을 수행할 수도 있다. 이 경우, 프로세서는 슬레이브 장치의 수집부가 수집한 데이터 를 기반으로 마스터 장치로부터 전송된 예측 모델을 학습할 수도 있다. 이에 따라 마스터 장치로부터 전송된 예측 모델이 갱신될 수도 있다. 이와 같은 프로세서에 의한 예측 모델의 학습은 마스터 장치 의 프로세서와 독립적으로 수행될 수도 있다. 실시예에 따라서, 프로세서에 의한 예측 모델의 학습은, 마스터 장치의 프로세서가 이용한 학습 방법과 동일한 방법을 이용하여 수행될 수도 있고 또 는 상이한 방법을 이용하여 수행될 수도 있다. 프로세서는 마스터 장치의 프로세서와 동일하게 적어도 하나의 전자 장치를 채용하여 구현 가능 하다. 저장부는 프로세서의 동작에 필요한 각종 데이터나 애플리케이션을 저장할 수 있다. 예를 들어, 저장 부는, 마스터 장치로부터 전달된 예측 모델을 일시적 또는 비일시적으로 저장하거나, 및/또는 프로세 서에 의해 생성되거나 학습된 예측 모델을 일시적 또는 비일시적으로 저장할 수 있다. 저장부는, 상술한 마스터 장치의 저장부와 동일하게 주기억장치 및 보조기억장치 중 적어도 하 나를 포함할 수 있으며, 반도체나 자기 디스크 등을 이용하여 구현 가능하다. 이하 도 3 내지 도 5를 참조하여 마스터 장치 및/또는 슬레이브 장치에서 수행되는 예측 모델의 생성 및 갱신의 일 실시예에 대해 설명하도록 한다. 이하에서는 오직 마스터 장치에 의해 수행되는 예측 모델 생성 및 모델 학습 과정의 일 실시예에 대해 설명하도록 한다. 이는 슬레이브 장치에 의해 수행되는 예측 모델 생성 및/또는 모델 학습 과정에도 동일하게 또는 일부 변형을 거쳐 적용될 수 있다. 다만 반복 기재를 회 피하기 위해, 슬레이브 장치에 의해 수행되는 예측 모델 생성 및/또는 모델 학습 과정에 대한 자세한 설명 은 생략하도록 한다. 도 3은 마스터 장치의 일 실시예를 보다 상세히 도시한 블록도이다. 도 3에 도시된 일 실시예에 따르면, 프로세서는 인공 지능 관리자, 데이터 처리부, 모델 생성부 , 모델 훈련부 및 예측부를 포함할 수 있다. 인공 지능관리자, 데이터 처리부, 모델 생성부, 모델 훈련부 및 예측부는, 각각 논리적으로 구분되는 것일 수도 있고, 또는 물리적으로 구분되는 것일 수도 있다. 물리적으로 구분되는 경우, 인공 지능관리자, 데이터 처리부, 모델 생성부 , 모델 훈련부 및 예측부 중 적어도 둘은, 서로 상이한 물리적 프로세서(예를 들어, 중앙 처리 장치 등)에 의해 구현되는 것일 수 있다. 인공 지능 관리자는, 데이터 수집부, 데이터 처리부, 모델 생성부, 모델 훈련부 및/ 또는 예측부 등의 전반적인 또는 일부의 동작을 제어하도록 마련된다. 예를 들어, 인공 지능 관리자 는 모델 생성부가 적절한 데이터나 예측 모델을 생성, 선택하거나, 모델 훈련부가 적절한 예측 모델 을 선택하여 학습할 수 있도록 제어할 수 있다. 또한, 실시예에 따라서, 인공 지능 관리자는 모델 훈련부 및 예측부 중 적어도 하나로부터 전달되는 피드백 정보(예를 들어, 모델의 정확성에 대한 정보나 모 델의 학습 로스)를 기반으로 최적의 모델의 학습 및 선택을 수행 및/또는 제어하는 것도 가능하다. 데이터 처리부는, 상술한 데이터 수집부에 의해 수집된 데이터(123, 예를 들어, 각각의 콘텐트의 요 청 회수에 대한 카운트 값이나 캐쉬 히트 값 등)에 대한 선택, 추출, 가공 및/또는 변형 등의 처리를 수행하거 나, 또는 이를 기반으로 데이터 셋(data set)을 생성하여 모델 생성부로 전달할 수 있다. 여기서 수집된 데이터는 저장부에 저장된 것일 수 있다. 보다 구체적으로 예를 들어, 데이터 처리부는 메모리 의 청소나 데이터로부터 로그 파일의 추출 등의 작업을 수행할 수 있다. 또한 데이터 처리부는, 다른 예를 들어, 복수의 데이터를 조합하여 특징점 정보(feature information, 이에 대해선 후술한다)를 생성할 수도 있다. 데이터 처리부에 의해 처리된 데이터 또는 데이터 셋은 모델 생성부 및/또는 모델 훈련부(11 6)로 전달될 수 있다. 모델 생성부는, 적어도 하나의 다양한 형태의 예측 모델을 생성 및 획득할 수 있다. 여기서 예측 모델은 다층 퍼셉트론(MLN), 심층 신경망(DNN), 콘볼루션 신경망(CNN), 순환 신경망(RNN, Recurrent Neural Network), 콘볼루션 순환 신경망(CRNN, Convolutional Recurrent Neural Network), 심층 신뢰 신경망(DBN, Deep Belief Network) 및 심층 Q-네트워크(Deep Q-Networks) 중 적어도 하나를 이용하여 구현된 것일 수 있다. 물론, 예측 모델은 이들뿐만 아니라, 이들에 더해서 또는 이들을 대체해서, 기계 학습에 이용되는 다양한 신경망을 포함할 수도 있다. 모델 생성부는, 필요에 따라, 데이터 처리부에 의해 처리된 데이터 또는 생성된 데이터 셋을 모델 생성에 이용할 수도 있다. 필요에 따라, 모델 생성부가 생성한 예측 모델은 저장부에 일시적 또는 비일시적으로 저장될 수 있다. 상술한 바와 같이 다양한 형태의 예측 모델의 생성을 위해, 모델 생성부는, 저장부 등에 저장된 모델 사전을 이용할 수도 있다. 모델 사전은 다양한 형태의 딥 러닝 모델(deep learning model)에 대한 규 칙 및 프레임 등으로 구축된 데이터 집단으로, 모델 생성부에 의해 열람 또는 검색되어 모델 생성부 에 적어도 하나의 모델을 제공할 수 있도록 마련된다. 모델 훈련부는 데이터 처리부로부터 데이터 및/또는 데이터 셋을 이용하여, 모델 생성부에서 생 성된 예측 모델에 대한 학습, 훈련을 수행할 수 있다. 이 경우, 모델 훈련부는, 저장부에 저장 된 예측 모델을 호출하고 호출한 예측 모델을 획득한 데이터 및/또는 데이터 셋을 기반으로 훈련시킬 수 있다. 모델 훈련부의 처리 결과는 저장부로 전달될 수 있다. 저장부는 모델 훈련부에 의해 학습/훈련된 예측 모델을 저장하거나, 및/또는 학습/훈련된 예측 모델과 관련된 각종 정보(예를 들어, 모델의 설정 정보, 훈련 정확도 및/또는 확인 정확도(validation accuracy) 등)을 저장할 수 있다. 이들 의 저장은 일시적인 것일 수도 있고, 또는 비일시적인 것일 수 있다. 예측부는 저장부에 저장된 학습된 모델을 접근하여 호출하고, 학습된 모델을 기반으로 예 측을 수행하고, 예측 결과를 획득할 수 있다. 실시예에 따라서, 예측부는, 예측 결과(미도시)를 저장부 에 저장하거나, 및/또는 인공 지능 관리자로 전송할 수 있다. 또한, 예측부는, 예측 정확도 등 과 같이 예측과 관련된 정보(미도시)를 저장부에 저장하거나 및/또는 인공 지능 관리자로 전송할 수 도 있다. 일 실시예에 의하면, 인공 지능 관리자는, 저장부에 접근하여 예측부에 의해 저장된 예측 결과 또는 예측과 관련된 정보(일례로 예측 정확도 등)를 확인하거나 및/또는 예측부로부터 이들 정 보를 직접 전달 받고, 예측 결과 또는 예측과 관련된 정보를 기반으로 소정의 동작을 수행할 수 있다. 예를 들 어, 인공 지능 관리자는 이들을 기반으로 마스터 장치 및 슬레이브 장치 중 적어도 하나에 대한 제어 명령을 생성하여 이들을 제어할 수도 있다. 또한, 일 실시예에 따르면, 인공 지능 관리자는 예측 정 확도 등의 정보를 기반으로 훈련을 더 진행할 것인지 또는 훈련을 중단시킬 것인지 여부를 결정할 수도 있다. 만약 인공 지능 관리자가 훈련 중단을 결정하면, 그 시점까지 훈련된 예측 모델은 저장부에 저장된다. 이 경우, 그 시점까지 훈련된 예측 모델은 기존의 또는 다른 훈련된 예측 모델(125, 127)과는 차별적 으로 저장될 수도 있다. 한편, 예측 문제에 대한 최적의 모델을 찾아내기 위하여, 프로세서는 여러 가지 방법을 통하여 최상의 모 델을 검출할 수 있다. 일 실시예에 따르면, 프로세서(110, 상세하게는, 인공 지능 관리자, 모델 생성부 및 모델 훈련부 중 적어도 하나)는, 최적의 예측 모델을 검출하기 위해서, 소정의 검색 방법을 이용할 수 있다. 소정의 검색 방법은, 예를 들어, 그리드 검색(grid-search) 및 랜덤 검색(random-search) 중 적어 도 하나를 포함할 수 있다. 그리드 검색은 순차으로 하이퍼 파라미터의 값을 증가시켜 최적의 모델을 검색하는 방법이고, 랜덤 검색은 검색 공간을 축소하기 위해 무작위로 최적의 모델을 검색하는 방법이다. 보다 상세하게 설명하면, 프로세서는 소정의 후보 모델을 선택할 수 있다. 소정의 후보 모델은, 예를 들어, 콘볼루션 신경망(CNN), 순환 신경망(RNN) 및 콘볼루션 순환 신경망(CRNN)를 포함할 수 있다. 순차적으로 프로세서는 소정의 검색 방법, 일례로 랜덤 검색 방법을 기반으로 모델을 구성한다. 일 실시예에 의하면, 프로세서는 훈련/학습 손실을 최소화하기 위하여 그래디언트(gradient)를 계산하기 위한 최적화 도구(optimizer)를 선택할 수도 있다. 최적화 도구로는, 예를 들어, 그래디언트 하강법(gradient descent), 확률적 그래디언트 하강법(stochastic gradient descent) 또는 적응형 모멘트 추정법(ADAM, adaptive moment estimation) 등이 채용될 수 있다. 보다 상세하게 예를 들어, 콘볼루션 신경망(CNN)의 그래디 언트 연산에서는 최적화 도구로 적응형 모멘트 추정법이 채용될 수 있다. 이 경우, 적응형 모멘트 추정법과 더 불어 역전파(backpropagation) 알고리즘이 더 이용될 수도 있다. 만약 롱 숏 텀 메모리 모델(LSTM model, Long Short-Term Memory models) 및/또는 콘볼루션 신경망 특성을 갖는 구역(R-CNN, Regions with CNN features) 방 법 등을 이용하는 경우라면, 이들의 그래디언트를 계산하기 위해서, 시간을 통해 절개된 역전파 방법(TBTT, Truncated Backpropagation Through Time)이 더 이용될 수 있다. 시간을 통해 절개된 역전파 방법은, 상술한 적응형 모멘트 추정법과 더불어 이용될 수도 있다. 시간을 통해 절개된 역전파 방법은, 순환 신경망(RNN)에 대 한 시간을 통한 역전파 훈련 알고리즘(BPTT, Backpropagation Through Time)을 개선한 것이다. 시간을 통해 절 개된 역전파 방법에서는, 시퀀스는 한 번에 한 단계씩 처리되고, 고정된 수의 시간 간격 동안 시간을 통한 역전 파 훈련 알고리즘이 반대로 갱신된다. 이상 설명한 바와 같이, 프로세서는 예측 모델의 생성 및/또는 훈련(학습) 등을 수행하고, 이에 대응하는 예측 결과를 획득할 수 있다. 프로세서는 획득된 예측 결과를 기반으로 사용자의 동작(예를 들어, 사용자 의 콘텐트에 대한 수요 등)을 예측할 수 있으며, 예측된 동작을 기반으로 마스터 장치 및 슬레이브 장치 중 여러 자원들(예를 들어, 적어도 하나의 소모 전력, 캐쉬 리소스나 컴퓨팅 리소스 등)을 적절하고 효율 적으로 관리할 수 있게 된다. 도 4는 예측 결과 획득의 일 실시예를 설명하기 위한 도면이다. 이하 도 4를 참조하여 설명되는 예측 모델은 상술한 마스터 장치에 의해 이용될 수도 있고, 또는 슬 레이브 장치에 의해 이용될 수도 있다. 뿐만 아니라, 예측 모델은, 마스터 장치 및 슬레이브 장 치 모두에 의해 이용될 수도 있다. 이 경우, 마스터 장치 및 슬레이브 장치 각각은 상호 독립적 으로 예측 모델을 이용할 수도 있다. 도 4에 도시된 바를 참조하면, 예측 모델은, 일 실시예에 있어서, 두 계의 예측 모델, 즉 제1 예측 모델 및 제2 예측 모델을 포함할 수 있다. 제1 예측 모델은, 예를 들어, 클래스(class)를 예측하기 위해 설계된 것일 수 있다. 보다 구체적으로는 제 1 예측 모델은 다중 클래스 레이블(multi-class label) 예측을 위해 이용되는 것일 수 있다. 제1 예측 모델은, 두 개의 알고리즘, 즉 제1 알고리즘 및 제2 알고리즘를 포함할 수 있다. 제1 알고리즘 및 제2 알고리즘은 순차적으로 데이터를 처리한다. 구체적으로 제1 예측 모델에 소정 의 데이터가 입력되면, 입력된 데이터는 제1 알고리즘에 입력되고, 제1 알고리즘의 출력 데이터(302, 예를 들어 콘볼루션 결과 데이터)는 순차적으로 제2 알고리즘에 입력된다. 제2 알고리즘(31 3)의 결과 값(316, 예를 들어, 클래스 예측 데이터)은, 실시예에 따라 완전 연결 층(315, Fully Connected Layer)에 의해 처리되고 출력단을 통하여 출력될 수 있다. 이에 따라, 제1 예측 모델은, 클래스 예측 데이터를 획득할 수 있게 된다. 획득한 클래스 예측 데이터는, 제2 예측 모델에 입력될 수 있다. 제1 알고리즘 및 제2 알고리즘 각각은 소정의 기계 학습 알고리즘(일례로 신경망(Neural Network)) 중 적어도 하나를 채용한 것일 수 있다. 예를 들어, 제1 알고리즘 및 제2 알고리즘 각각은 심층 신경 망(DNN), 콘볼루션 신경망(CNN), 순환 신경망(RNN), 콘볼루션 순환 신경망(CRNN), 심층 신뢰 신경망(DBN) 또는 심층 Q-네트워크를 포함할 수 있다. 제1 알고리즘 및 제2 알고리즘은, 실시예에 따라서, 서로 동일한 신경망을 이용하여 구현될 수도 있고, 또는 서로 상이한 신경망을 이용하여 구현될 수도 있다. 예를 들어, 제1 알고리즘은 콘볼루션 신경망(CNN)을 이용하여 구현되고, 제2 알고리즘은 순환 신경망 (RNN)을 이용하여 구현된 것일 수 있다. 이 경우, 입력 데이터는 콘볼루션 신경망에 입력된 후 콘볼 루션 신경망에 의해 콘볼루션된다. 이에 따라 입력 데이터에 대응하는 콘볼루션 결과 데이터가 획득된다. 실시예에 따라서, 콘볼루션 결과 데이터는 제2 예측 모델으로 전달될 수 있다. 콘볼루션 결과 데이터가 획득되면, 콘볼루션 결과 데이터는 순환 신경망에 입력된다. 순환 신경 망은 입력된 순차적인 데이터의 시간적 다이나믹스를 위해 특별히 설계된 것일 수 있다. 순환 신경망(31 3)은, 상호 연결되거나 단절된 복수의 순환 신경망 셀를 포함할 수 있다. 실시예에 따라서, 순환 신경망 셀은, 예를 들어, 개패 순환 유닛(Gated Recurrent Unit) 및/또는 롱 숏 텀 메모리(Long Short-term Memory) 등을 포함할 수 있다. 순환 신경망에 의해 처리되어 출력된 데이터는 완전 연결 층에 입력된 다. 완전 연결 층은 입력된 데이터에 대한 클래스 레이블을 분류하고, 출력단은 이에 따른 결과 데이터, 즉 클래스 예측 데이터를 출력할 수 있다. 이 경우, 클래스 예측 데이터는 다중 클래스 레이블일 수 있다. 다중 클래스 레이블은 확률 값을 포함할 수 있다. 일 실시예에 의하면, 클래스 레이블의 분류를 위하여 교차 엔트로피(cross-entropy)가 사용 가능하다. 교차-엔트로피 손실은 로그-선형 모델 및 신경망 내에서 일반 적인 것이며, 가능한 레이블에 대한 분포를 예측하게 한다. 교차-엔트로피 손실을 이용하는 경우, 완전 연결 층 의 출력은 소정의 변환을 이용하여 변환된 것일 수 있다. 예를 들어, 완전 연결 층의 출력은 소프트 맥스 변환(softmax transformation)을 이용하여 변환되거나, 이를 이용하여 변환되는 것으로 가정될 수 있다. 클래스 예측 데이터는 상술한 바와 같이 제2 예측 모델로 전달될 수 있다. 이와 같은 과정에 의해 제1 예측 모델은 콘볼루션 신경망 및 순환 신경망에 의해 학습된 클래스 예측 데이터를 출력하여 제2 예측 모델에 전달할 수 있게 된다. 제2 예측 모델은, 예를 들어, 예측 결과를 획득하기 위해 마련된 것일 수 있다. 예를 들어, 제2 예측 모델 은 요청 횟수에 대한 예측을 위해 설계된 것일 수 있다. 물론, 제2 예측 모델는 이외에도 다양한 종 류의 예측에 적합하도록 설계된 것일 수도 있다. 즉, 제2 예측 모델은 설계자의 임의적 선택에 따라 설계 자가 원하는 예측을 위해 설계될 수도 있다. 제2 예측 모델은 제1 예측 모델으로부터 데이터(302a)를 수신하고, 수신한 입력 데이터(302a)를 처리 한다. 일 실시예에 의하면, 입력 데이터(302a)는 제1 알고리즘의 출력 데이터(302, 예를 들어 콘볼루션 결 과 데이터)일 수도 있고, 또는 클래스 예측 데이터일 수도 있다. 또한, 입력 데이터(302a)는 콘볼루션 결 과 데이터 및 클래스 예측 데이터 양자를 모두 포함할 수도 있다. 제2 예측 모델은 입력 데이터(302a)를 처리하기 위한 제3 알고리즘을 포함할 수 있다. 제3 알고리즘 은 상술한 기계 학습 알고리즘 중 적어도 하나를 채용하여 구현될 수 있다. 예를 들어, 제3 알고리즘(32 1)은 순환 신경망(RNN)을 이용하여 구현될 수 있다. 상술한 바와 동일하게 제3 알고리즘으로 이용되는 순 환 신경망도 입력된 순차적인 데이터의 시간적 다이나믹스를 위해 특별히 설계된 것일 수 있고, 또한 복수의 순 환 신경망 셀를 포함할 수도 있다. 제2 예측 모델, 일례로 순환 신경망에 의해 처리된 결과 데이터는 출력단를 통해 출력된다. 여기서, 결과 데이터는, 원하는 예측 결과에 대한 데이터를 포함하며, 예를 들어, 요청 횟수에 대한 예측 결과에 대한 데이터를 포함할 수 있다. 이에 따라 설계자가 원하는 대상에 대한 예측 결과의 획득이 가능해지며, 상술한 프 로세서, 보다 상세한 예로는 인공 지능 관리자는 획득한 예측 결과를 기반으로 적어도 하나의 마스터 장치 및/또는 적어도 하나의 슬레이브 장치을 적절하게 관리할 수 있게 된다. 제2 예측 모델에 있어서, 손실은 설계자가 선택한 소정의 방법을 이용하여 획득될 수 있다. 예를 들어, 제 2 예측 모델에서 결과(예를 들어, 요청 횟수 예측)에 대한 손실은 평균 제곱근 편차(MSE, mean square error)를 이용하여 측정될 수도 있다. 평균 제곱근 편차는 수학적 특성이 우수하여 그래디언트의 연산을 좀더 용이하게 수행할 수 있게 한다. 이하 도 5를 참조하여, 도 4에서 예측 모델에 의해 이용되는 데이터(302 및/또는 302a)에 대해 보다 구체 적으로 설명하도록 한다. 도 5는 샘플 데이터의 일 실시예를 설명하기 위한 도면이다. 도 5에서 t1 내지 tn은 타임 슬롯(time slot)을 의 미하며, n은 타임 슬롯의 개수를 의미한다. 예를 들어, 연이은 시간(시, 분, 초 등)이나 날짜(일, 월, 년 등) 등의 개수를 의미한다. 상술한 바와 같이 예측 모델 내에서는 여러 데이터(샘플 데이터)가 소정의 알고리즘(311, 313, 321)에 입 력된다. 예를 들어, 제1 예측 모델에서는, 데이터가 제1 알고리즘에 입력되고, 콘볼루션 결과 데이터가 제2 알고리즘에 입력되될 수 있다. 또한, 제2 예측 모델에서는 상술한 입력 데이터 (302a)가 제3 알고리즘에 입력될 수 있다. 이와 같이 예측 모델에서 이용되는 샘플 데이터(301, 302 및 302a) 중 적어도 하나는, 도 5에 도시된 바와 같이, 데이터가 다차원으로 배열된 텐서(tensor)를 기반으로 구현될 수 있다. 텐서는 특정 시점(t1 내지 tn)마 다 획득될 수 있다. 다시 말해서, t1 시점, tn 시점 또는 이들 사이의 tm 시점(1<m<n) 각각마다 데이터가 텐서 의 형태로 입력 또는 생성될 수 있다. 텐서는 iⅹjⅹk개의 데이터들의 집합일 수 있다. 구체적으로 텐서는 데이 터(예를 들어, 특정 콘텐츠에 대한 요구 회수나 특정 명령에 대한 선택 회수 등)가 포함 가능한 iⅹjⅹk개의 슬 롯을 포함할 수 있으며, 각각의 슬롯에는 소정의 데이터가 기록되어 있거나 및/또는 또는 기록되어 있지 않을 수 있다. 만약 텐서가 특성 정보(feature information)에 관한 것인 경우, 텐서는 특성의 종류(예를 들어, 콘텐 트의 명칭, 요구 횟수, 콘텐트의 등급(영화 등급 등))나, 예측하고자 하는 데이터 주변의 데이터 포인트 등과 같은 소정의 데이터를 포함할 수 있다. 이 경우, i는 특성의 종류마다 입력된 데이터 값들의 개수를 의미하도록 정의될 수 있다. 또한, j는 특성의 종류의 개수를 의미하고, k는 데이터 주변의 데이터 포인트의 개수를 의미하 도록 정의될 수도 있다. 물론 이는 예시적인 것이며, 설계자의 임의적 선택에 따라서 텐서는 다양하게 정의 가 능함은 자명하다. 이하 도 6 및 도 7을 참조하며, 예측 모델 훈련 관리 방법의 일 실시예에 대해 설명하도록 한다. 도 6은 예측 모델 훈련 관리 방법의 일 실시예를 설명하기 위한 도면이다. 예측 모델 훈련 관리 방법은 상술한 예측 모델 훈련 관리 시스템을 기반으로 수행될 수 있다. 즉, 예측 모델 훈 련 관리 방법은, 마스터 장치 및 슬레이브 장치 중 적어도 하나에 의해 수행될 수 있다. 구체적으로 도 6에 도 시된 예측 모델 훈련 관리 방법의 일 실시예를 참조하면, 먼저 마스터 장치 및 슬레이브 장치 중 적어도 하나가 예측에 필요하거나 관련된 각종 데이터(정보)를 수집할 수 있다. 이 경우, 마스터 장치 및 슬레이브 장치는 각각 독립적으로 데이터를 수집할 수도 있고, 또는 상호 의존하여 데이터를 수집할 수도 있다. 실시예에 따라서, 마스터 장치에 의한 데이터 수집 및 슬레이브 장치에 의한 데이터 수집 중 어느 하나는 생략될 수도 있다. 슬레이브 장치는 수집한 데이터를 마스터 장치로 전송하고, 마스터 장치는 이를 수신할 수 있다. 마스터 장치는 직접 수집한 데이터 및 슬레이브 장치로부터 수신한 데이터 중 적어도 하나를 기반으로 모델을 획득하여 생성할 수 있다. 이 경우, 마스터 장치는 직접 수집한 데이터만 이용하는 것도 가능하고, 슬레이 브 장치로부터 수신한 데이터만을 이용하는 것도 가능하다. 마스터 장치에 의해 획득된 예측 모델은 슬레이브 장치로 전송될 수도 있다. 모델을 수신하면 슬레이브 장 치는 수신한 모델을 이용하여 각종 동작(예를 들어, 수요의 예측 등)을 수행할 수 있다. 슬레이브 장치는 모델의 이용 결과에 대한 정보를 마스터 장치로 전송할 수도 있다. 예를 들어, 슬레이브 장치는 예측 모델의 정 확성에 대한 정보를 마스터 장치로 전송할 수 있으며, 마스터 장치는 이를 예측 모델의 훈련에 이용할 수도 있다. 한편, 마스터 장치 역시 필요에 따라 생성 및 획득한 예측 모델을 이용할 수도 있다. 실시 예에 따라서, 모델의 전송, 마스터 장치에 의한 모델의 이용, 슬레이브 장치에 의한 모델의 이용 과정은 생략될 수도 있다. 마스터 장치는, 예측 모델에 대한 훈련/학습을 수행할 수 있다. 구체적으로 마스터 장치는 생성된 모델을 훈련시키고, 모델의 설정 값, 훈련 정확도 및 확인 정확도 등을 저장할 수 있다. 예측 모델이 훈련되면, 훈련된 모델은 슬레이브 장치로 전송되고, 슬레이브 장치는 훈련된 모델을 이용하거 나, 또는 필요에 따라 더 훈련시킬 수 있다. 또한, 슬레이브 장치는 기존에 저장된 훈련된 모델을 갱신할 수도 있다. 한편, 슬레이브 장치 역시 예측 모델에 대한 훈련을 수행할 수 있다. 구체적으로 슬레이브 장치는 마스터 장치로부터 전송된 예측 모델(22 참조)을 직접 수집한 데이터(30 참조)를 기반으로 훈련/학습 시킬 수 있다. 이 에 따라 슬레이브 장치 역시 훈련된 모델을 획득할 수 있다. 슬레이브 장치에 의해 훈련된 모델은 마스터 장치 로 전송될 수 있다. 설계자의 선택에 따라서 슬레이브 장치는 모델 그 자체가 아니라 모델과 관련된 정보, 예를 들어, 모델의 가중치나 그래디언트 등과 같은 정보를 마스터 장치로 전송할 수도 있다.마스터 장치는 슬레이브 장치로부터 훈련된 모델을 수신하면, 이를 기반으로 기존의 훈련된 모델을 갱신할 수도 있다. 물론, 마스터 장치의 설정 등에 따라서 슬레이브 장치로부터 수신된 모델은 갱신되지 않고 폐기되는 것도 가능하다. 필요에 따라서, 마스터 장치는 슬레이브 장치로부터 훈련된 모델을 더 훈련시키거 나 및/또는 원하는 동작을 수행하기 위해 이용할 수도 있다. 이와 같은 과정에 의해서, 예측 모델은 마스터 장치 및 슬레이브 장치 중 적어도 하나에 의해 훈련/학습될 수 있으며, 이에 따라 예측 모델의 정확성이 더욱 개선 가능하게 된다. 도 7은 예측 결과의 획득 과정의 일 실시예를 도시한 흐름도이다. 도 7에 도시된 예측 결과의 획득 과정은, 상술한 마스터 장치에 의해 수행될 수도 있고, 슬레이브 장치에 의해 수행될 수도 있으며, 양자 모두에 의해 수행될 수도 있다. 또한, 일부의 과정은 마스터 장치에 의해 수행되고 다른 일부의 과정은 슬레이브 장치에 의해 수행되는 것도 가능하다. 도 7에 도시된 바를 참조하면, 먼저 소정의 데이터가 생성된다. 생성된 데이터는, 도 5를 통해 설명한 바와 같이 텐서 형태의 샘플 데이터를 포함할 수 있다. 생성된 데이터는, 예측 모델에 입력될 수 있다. 예측 모델은 제1 예측 모델 및 제2 예측 모델을 포함할 수 있으며, 이 경우, 데이터는 도 4에 도시된 바와 같이, 먼저 제1 예측 모델에 입력될 수 있다. 제1 예측 모델은 하나, 둘 또는 그 이상의 알고리즘을 적용하여 입력된 데이터를 처리할 수 있다. 제1 예측 모델은 클래스(예를 들어, 다중 클래스 레이블)를 예측하기 위한 모델일 수 있다. 여기서, 적용되는 알고리즘은 신경망을 포함할 수 있다. 또한, 제1 예측 모델은 순차적으로 이용되는 두 개의 신경망을 이용하여 구현될 수도 있다. 예를 들어, 제1 예측 모델은 콘볼루션 신경망(CNN) 및 순환 신경망(RNN)을 이용하여 구현될 수 있다. 이 경우, 입력된 데이터는 콘볼루션 신경망(CNN)에 입력되어 콘볼루션 처리되고, 이어서 순환 신경망에 입력된다. 또한, 제1 예측 모델은 클래스 레이블의 분류를 위한 완전 연결 층을 포함할 수 있으며, 순환 신경망에서 출력 된 값은 완전 연결 층에 입력되고, 완전 연결 층은 클래스 예측 데이터를 출력하게 된다. 이에 따라 제1 예측 모델은 클래스 예측 데이터를 최종적으로 출력한다. 제2 예측 모델은 예측 결과를 획득하기 위해 설계된 모델을 포함할 수 있다. 제2 예측 모델은 제1 예측 모델에 서 출력된 클래스 예측 데이터에 대해 하나 또는 둘 이상의 알고리즘을 적용하여 처리할 수 있다. 제2 예측 모델은 클래스 예측 데이터를 순환 신경망(RNN) 등에 입력하여, 결과 데이터를 출력할 수 있다. 여기서, 결과 데이터는, 설계자가 목표로 하는 대상에 대한 예측 결과를 포함할 수 있다. 다시 말해서, 결과 데이터는 최종적 인 예측 결과를 포함한다. 이에 따라 적절한 예측 결과를 획득할 수 있게 된다. 상술한 실시예에 따른 예측 모델 훈련 관리 방법이나 예측 결과의 획득 방법은, 컴퓨터 장치에 의해 구동될 수 있는 프로그램의 형태로 구현될 수 있다. 여기서 프로그램은, 프로그램 명령, 데이터 파일 및 데이터 구조 등을 단독으로 또는 조합하여 포함할 수 있다. 프로그램은 기계어 코드나 고급 언어 코드를 이용하여 설계 및 제작된 것일 수 있다. 프로그램은 상술한 예측 모델 훈련 관리 방법을 구현하기 위하여 특별히 설계된 것일 수도 있고, 컴퓨터 소프트웨어 분야에서 통상의 기술자에게 기 공지되어 사용 가능한 함수(라이브러리 함수를 포함 가능하 다)나 정의 등을 이용하여 구현된 것일 수도 있다. 또한, 여기서, 프로그램이 구동 가능한 컴퓨터 장치는, 상술 한 프로그램의 기능을 실현 가능하게 하는 프로세서나 메모리 등을 포함하여 구현된 것일 수 있다. 예측 모델 훈련 관리 방법이나 예측 결과의 획득 방법을 구현하기 위한 프로그램은, 컴퓨터에 의해 판독 가능한 기록 매체에 기록된 것일 수도 있다. 컴퓨터에 의해 판독 가능한 기록 매체는, 예를 들어, 하드 디스크나 플로 피 디스크와 같은 자기 디스크 저장 매체, 자기 테이프, 콤팩트 디스크나 디브이디와 같은 광 기록 매체, 플롭 티컬 디스크와 같은 자기-광 기록 매체 및 롬, 램 또는 플래시 메모리 등과 같은 반도체 저장 장치 등 컴퓨터 등의 호출에 따라 실행되는 특정 프로그램을 저장 가능한 다양한 종류의 하드웨어 장치를 포함할 수 있다. 상술한 예측 모델 훈련 관리 시스템, 마스터 장치, 슬레이브 장치 및 예측 모델 훈련 관리 방법 중 적어도 하나는, 단독적으로 또는 조합되어 다양한 분야에 채용되어 이용될 수 있다. 예를 들어, 상술한 예측 모델 훈련 관리 시스템, 마스터 장치, 슬레이브 장치 및/또는 예측 모델 훈련 관리 방법 등은, 주 문형 비디오(VOD) 서비스, 비디오 스트리밍 서비스, 에지 컴퓨팅, 지능형 네트워크 관리, 가상화된 네트워크, 사물 인터넷 등 다양한 기술을 구현하기 위해 이용될 수 있다. 보다 상세하게 예를 들어, 상술한 시스템, 장치 및 방법 등은 이들 기술의 콘텐트 캐싱 등에 채용될 수 있다.이상 예측 모델 훈련 관리 시스템, 예측 모델 훈련 관리 방법, 예측 모델 학습 관리를 위한 마스터 장치 및 슬 레이브 장치의 여러 실시예에 대해 설명하였으나, 예측 모델 훈련 관리 시스템, 예측 모델 훈련 관리 방법, 예 측 모델 학습 관리를 위한 마스터 장치 및 슬레이브 장치는 오직 상술한 실시예에 한정되는 것은 아니다. 해당 기술 분야에서 통상의 지식을 가진 자가 상술한 실시예를 기초로 수정 및 변형하여 구현 가능한 다양한 장치나 방법 역시 상술한 예측 모델 훈련 관리 시스템, 예측 모델 훈련 관리 방법, 예측 모델 학습 관리를 위한 마스터 장치 및 슬레이브 장치의 일 실시예가 될 수 있다. 예를 들어, 설명된 기술들이 설명된 방법과 다른 순서로 수 행되거나, 및/또는 설명된 시스템, 구조, 장치, 회로 등의 구성 요소들이 설명된 방법과 다른 형태로 결합 또는 조합되거나 다른 구성 요소 또는 균등물에 의하여 대치되거나 또는 치환되더라도 상술한 예측 모델 훈련 관리 시스템, 예측 모델 훈련 관리 방법, 예측 모델 학습 관리를 위한 마스터 장치 및 슬레이브 장치의 일 실시예에 포함된다."}
{"patent_id": "10-2018-0122683", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 예측 모델 훈련 관리 시스템의 일 실시예에 대한 개요도이다. 도 2는 예측 모델 훈련 관리 시스템의 일 실시예에 대한 블록도이다. 도 3은 마스터 장치의 일 실시예를 보다 상세히 도시한 블록도이다. 도 4는 예측 결과 획득의 일 실시예를 설명하기 위한 도면이다. 도 5는 샘플 데이터의 일 실시예를 설명하기 위한 도면이다. 도 6은 예측 모델 훈련 관리 방법의 일 실시예를 설명하기 위한 도면이다. 도 7은 예측 결과의 획득 과정의 일 실시예를 도시한 흐름도이다."}
