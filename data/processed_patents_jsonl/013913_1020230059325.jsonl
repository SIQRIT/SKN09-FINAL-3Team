{"patent_id": "10-2023-0059325", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0162355", "출원번호": "10-2023-0059325", "발명의 명칭": "콘텐트를 제공하는 방법 및 전자 장치", "출원인": "삼성전자주식회사", "발명자": "장상현"}}
{"patent_id": "10-2023-0059325", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "전자 장치가 콘텐트를 제공하는 방법에 있어서,재생 중인 제1 콘텐트와 관련된 정보를 획득하는 단계;상기 제1 콘텐트와 관련된 정보에 기초하여, 상기 제1 콘텐트에서 편집 가능한 콘텐트 요소들 및 생성 가능한콘텐트 요소들 중 적어도 하나를 포함하는 사용자 인터페이스를 생성하는 단계;상기 사용자 인터페이스를 통해 콘텐트 요소를 선택하는 사용자 입력을 수신하는 단계;상기 사용자 입력에 대응하는 콘텐트 요소를 기초로 상기 제1 콘텐트에 대응하는 제2 콘텐트를 생성하는 단계;및상기 제1 콘텐트 및 상기 제2 콘텐트를 포함하는 개인화된 콘텐트를 생성하는 단계를 포함하는, 방법."}
{"patent_id": "10-2023-0059325", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 제1 콘텐트와 관련된 정보는, 타이틀, 제작자, 재생 시간, 장르, 출연자 정보, 플랫폼 정보 및 채널 정보중 적어도 하나를 포함하는 것인, 방법."}
{"patent_id": "10-2023-0059325", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 방법은,상기 제1 콘텐트에 포함되는 비디오 프레임을 이용하여 장면 콘텍스트 데이터를 생성하는 단계; 및상기 제1 콘텐트와 관련된 정보 및 상기 장면 콘텍스트 데이터 중 적어도 하나에 기초하여 상기 제1 콘텐트의장르를 식별하는 단계를 더 포함하고,상기 사용자 인터페이스를 생성하는 단계는,상기 제1 콘텐트의 장르에 기초하여 상기 사용자 인터페이스를 생성하는 것인, 방법."}
{"patent_id": "10-2023-0059325", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서,상기 사용자 인터페이스를 생성하는 단계는,상기 제1 콘텐트의 장르에 대응하는 기 정의된 콘텐트 요소가 포함되도록 상기 사용자 인터페이스를 생성하는것인, 방법."}
{"patent_id": "10-2023-0059325", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항 내지 제4항 중 어느 한 항에 있어서,상기 제2 콘텐트를 생성하는 단계는,공개특허 10-2024-0162355-3-상기 사용자 입력에 대응하는 콘텐트 요소를 생성형 인공지능 모델에 입력하여 상기 제2 콘텐트를 획득하는 단계를 포함하는, 방법."}
{"patent_id": "10-2023-0059325", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5항에 있어서,상기 생성형 인공지능 모델은, 이미지를 생성하는 제1 생성형 인공지능 모델, 오디오를 생성하는 제2 생성형 인공지능 모델 및 텍스트를 생성하는 제3 생성형 인공지능 모델 중 적어도 하나를 포함하는 것인, 방법."}
{"patent_id": "10-2023-0059325", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항 내지 제6항 중 어느 한 항에 있어서,상기 제2 콘텐트는, 이미지, 오디오, 및 텍스트 중 적어도 하나를 포함하는 것인, 방법."}
{"patent_id": "10-2023-0059325", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1항 내지 제7항 중 어느 한 항에 있어서, 상기 방법은,상기 제2 콘텐트를 사용자 정보와 연계하여 저장하는 단계를 더 포함하는, 방법."}
{"patent_id": "10-2023-0059325", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1항 내지 제8항 중 어느 한 항에 있어서, 상기 방법은,상기 제1 콘텐트의 재생이 종료되는 것에 기초하여, 상기 제1 콘텐트의 요약을 사용자에게 제공하는 단계를 더포함하는, 방법."}
{"patent_id": "10-2023-0059325", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9항에 있어서,상기 제1 콘텐트의 요약을 사용자에게 제공하는 단계는,상기 전자 장치에서 재생 중인 상기 제1 콘텐트가 다른 콘텐트로 변경되는 경우, 백그라운드 프로세스에서 상기제1 콘텐트의 요약을 생성하는 단계를 포함하는, 방법."}
{"patent_id": "10-2023-0059325", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "콘텐트를 제공하는 전자 장치에 있어서,통신 인터페이스;디스플레이;하나 이상의 인스트럭션들을 저장하는 메모리; 및상기 하나 이상의 인스트럭션들을 실행하는 적어도 하나의 프로세서를 포함하고,상기 적어도 하나의 프로세서는, 상기 하나 이상의 인스트럭션들을 실행함으로써,공개특허 10-2024-0162355-4-재생 중인 제1 콘텐트와 관련된 정보를 획득하고,상기 제1 콘텐트와 관련된 정보에 기초하여, 상기 제1 콘텐트에서 편집 가능한 콘텐트 요소들 및 생성 가능한콘텐트 요소들 중 적어도 하나를 포함하는 사용자 인터페이스를 생성하고,상기 사용자 인터페이스를 통해 콘텐트 요소를 선택하는 사용자 입력을 수신하고,상기 사용자 입력에 대응하는 콘텐트 요소를 기초로 상기 제1 콘텐트에 대응하는 제2 콘텐트를 생성하고,상기 제1 콘텐트 및 상기 제2 콘텐트를 포함하는 개인화된 콘텐트를 상기 디스플레이의 화면에 표시하는, 전자장치."}
{"patent_id": "10-2023-0059325", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항에 있어서,상기 제1 콘텐트와 관련된 정보는, 타이틀, 제작자, 재생 시간, 장르, 출연자 정보, 플랫폼 정보 및 채널 정보중 적어도 하나를 포함하는 것인, 전자 장치."}
{"patent_id": "10-2023-0059325", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제11항에 있어서,상기 적어도 하나의 프로세서는, 상기 하나 이상의 인스트럭션들을 실행함으로써,상기 제1 콘텐트에 포함되는 비디오 프레임을 이용하여 장면 콘텍스트 데이터를 생성하고,상기 제1 콘텐트와 관련된 정보 및 상기 장면 콘텍스트 데이터 중 적어도 하나에 기초하여 상기 제1 콘텐트의장르를 식별하고,상기 제1 콘텐트의 장르에 기초하여 상기 사용자 인터페이스를 생성하는, 전자 장치."}
{"patent_id": "10-2023-0059325", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제13항에 있어서,상기 적어도 하나의 프로세서는, 상기 하나 이상의 인스트럭션들을 실행함으로써, 상기 제1 콘텐트의 장르에 대응하는 기 정의된 콘텐트 요소가 포함되도록 상기 사용자 인터페이스를 생성하는, 전자 장치."}
{"patent_id": "10-2023-0059325", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제11항 내지 제14항 중 어느 한 항에 있어서,상기 적어도 하나의 프로세서는, 상기 하나 이상의 인스트럭션들을 실행함으로써, 상기 사용자 입력에 대응하는콘텐트 요소를 생성형 인공지능 모델에 입력하여 상기 제2 콘텐트를 획득하는, 전자 장치."}
{"patent_id": "10-2023-0059325", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제15항에 있어서,상기 생성형 인공지능 모델은, 이미지를 생성하는 제1 생성형 인공지능 모델, 오디오를 생성하는 제2 생성형 인공지능 모델 및 텍스트를 생성하는 제3 생성형 인공지능 모델 중 적어도 하나를 포함하는 것인, 전자 장치.공개특허 10-2024-0162355-5-청구항 17 제11항에 내지 제16항 중 어느 한 항에 있어서,상기 적어도 하나의 프로세서는, 상기 하나 이상의 인스트럭션들을 실행함으로써, 상기 제2 콘텐트를 사용자 정보와 연계하여 저장하는, 전자 장치."}
{"patent_id": "10-2023-0059325", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제11항 내지 제17항 중 어느 한 항에 있어서,상기 적어도 하나의 프로세서는, 상기 하나 이상의 인스트럭션들을 실행함으로써, 상기 제1 콘텐트의 재생이 종료되는 것에 기초하여, 상기 제1 콘텐트의 요약을 사용자에게 제공하는, 전자 장치."}
{"patent_id": "10-2023-0059325", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제18항에 있어서,상기 적어도 하나의 프로세서는, 상기 하나 이상의 인스트럭션들을 실행함으로써, 상기 전자 장치에서 재생 중인 상기 제1 콘텐트가 다른 콘텐트로 변경되는 경우, 백그라운드 프로세스에서 상기 제1 콘텐트의 요약을 생성하는, 전자 장치."}
{"patent_id": "10-2023-0059325", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제1항 내지 제10항 중 어느 한 항의 방법을 컴퓨터에서 실행시키기 위한 프로그램을 기록한 컴퓨터로 읽을 수있는 기록매체."}
{"patent_id": "10-2023-0059325", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "콘텐트를 제공하는 방법 및 전자 장치가 제공된다. 상기 전자 장치는, 재생 중인 제1 콘텐트와 관련된 정보를 획 득하고, 상기 제1 콘텐트와 관련된 정보에 기초하여, 상기 제1 콘텐트에서 편집 가능한 콘텐트 요소들 및 생성 가능한 콘텐트 요소들 중 적어도 하나를 포함하는 사용자 인터페이스를 생성하고, 상기 사용자 인터페이스를 통 해 콘텐트 요소를 선택하는 사용자 입력을 수신하고, 상기 사용자 입력에 대응하는 콘텐트 요소를 기초로 상기 제1 콘텐트에 대응하는 제2 콘텐트를 생성하고, 상기 제1 콘텐트 및 상기 제2 콘텐트를 포함하는 개인화된 콘텐 트를 표시할 수 있다."}
{"patent_id": "10-2023-0059325", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는, 개인화된 콘텐트를 생성하는 전자 장치 및 그 동작 방법에 관한 것이다."}
{"patent_id": "10-2023-0059325", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "최근, 인공지능을 활용하는 기술로써, 입력 데이터를 바탕으로 새로운 데이터를 생성하는 생성형 인공지능이 대 두되고 있으며, 이러한 생성형 인공지능을 활용하여 생산되는 콘텐트가 증가하고 있다. 한편, 생성형 인공지능 기술을 이용하여 콘텐트를 편집하는 작업은 일반 사용자들에게는 다소 어려우므로, 직관적이고 효율적인 사용자 인터페이스가 필요하다. 콘텐트 내 객체의 외형, 음성, 텍스트 등에 대한 다양한 커스터마이징 옵션을 제공하기 위해, 생성형 인공지능 을 이용하기 위한 환경을 최적화된 사용자 인터페이스를 통해 구현함으로써, 사용자에게 새로운 콘텐트 경험을 제공하는 것이 요구된다."}
{"patent_id": "10-2023-0059325", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 개시의 일 측면에 따르면, 전자 장치가 콘텐트를 제공하는 방법이 제공될 수 있다. 상기 방법은, 재생 중인 제1 콘텐트와 관련된 정보를 획득하는 단계를 포함할 수 있다. 상기 방법은, 상기 제1 콘텐트와 관련된 정보에 기초하여, 상기 제1 콘텐트에서 편집 가능한 콘텐트 요소들 및 생성 가능한 콘텐트 요소들 중 적어도 하나를 포 함하는 사용자 인터페이스를 생성하는 단계를 포함할 수 있다. 상기 방법은, 상기 사용자 인터페이스를 통해 콘 텐트 요소를 선택하는 사용자 입력을 수신하는 단계를 포함할 수 있다. 상기 방법은, 상기 사용자 입력에 대응 하는 콘텐트 요소를 기초로 상기 제1 콘텐트에 대응하는 제2 콘텐트를 생성하는 단계를 포함할 수 있다. 상기방법은, 상기 제1 콘텐트 및 상기 제2 콘텐트를 포함하는 개인화된 콘텐트를 생성하는 단계를 포함할 수 있다. 본 개시의 일 측면에 따르면, 콘텐트를 제공하는 전자 장치가 제공될 수 있다. 상기 전자 장치는, 통신 인터페 이스; 디스플레이; 하나 이상의 인스트럭션들을 저장하는 메모리; 및 상기 하나 이상의 인스트럭션들을 실행하 는 적어도 하나의 프로세서를 포함할 수 있다. 상기 적어도 하나의 프로세서는, 상기 하나 이상의 인스트럭션들 을 실행함으로써, 재생 중인 제1 콘텐트와 관련된 정보를 획득할 수 있다. 상기 적어도 하나의 프로세서는, 상 기 하나 이상의 인스트럭션들을 실행함으로써, 상기 제1 콘텐트와 관련된 정보에 기초하여, 상기 제1 콘텐트에 서 편집 가능한 콘텐트 요소들 및 생성 가능한 콘텐트 요소들 중 적어도 하나를 포함하는 사용자 인터페이스를 생성할 수 있다. 상기 적어도 하나의 프로세서는, 상기 하나 이상의 인스트럭션들을 실행함으로써, 상기 사용자 인터페이스를 통해 콘텐트 요소를 선택하는 사용자 입력을 수신할 수 있다. 상기 적어도 하나의 프로세서는, 상 기 하나 이상의 인스트럭션들을 실행함으로써, 상기 사용자 입력에 대응하는 콘텐트 요소를 기초로 상기 제1 콘 텐트에 대응하는 제2 콘텐트를 생성할 수 있다. 상기 적어도 하나의 프로세서는, 상기 하나 이상의 인스트럭션 들을 실행함으로써, 상기 제1 콘텐트 및 상기 제2 콘텐트를 포함하는 개인화된 콘텐트를 상기 디스플레이의 화 면에 표시할 수 있다. 본 개시의 일 측면에 따르면, 전자 장치가 콘텐트를 제공하는, 전술 및 후술하는 방법들 중 어느 하나를 실행시 키기 위한 프로그램이 기록된 컴퓨터 판독 가능 기록매체를 제공할 수 있다."}
{"patent_id": "10-2023-0059325", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 명세서에서 사용되는 용어에 대해 간략히 설명하고, 본 개시에 대해 구체적으로 설명하기로 한다. 본 개시에 서, \"a, b 또는 c 중 적어도 하나\" 표현은 \" a\", \" b\", \" c\", \"a 및 b\", \"a 및 c\", \"b 및 c\", \"a, b 및 c 모두\", 혹은 그 변형들을 지칭할 수 있다. 본 개시에서 사용되는 용어는 본 개시에서의 기능을 고려하면서 가능한 현재 널리 사용되는 일반적인 용어들을 선택하였으나, 이는 당 분야에 종사하는 기술자의 의도 또는 판례, 새로운 기술의 출현 등에 따라 달라질 수 있 다. 또한, 특정한 경우는 출원인이 임의로 선정한 용어도 있으며, 이 경우 해당되는 설명 부분에서 상세히 그 의미를 기재할 것이다. 따라서 본 개시에서 사용되는 용어는 단순한 용어의 명칭이 아닌, 그 용어가 가지는 의 미와 본 개시의 전반에 걸친 내용을 토대로 정의되어야 한다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함할 수 있다. 기술적이거나 과학적인 용어를 포함해서 여기서 사용되는 용어들은 본 명세서에 기재된 기술 분야에서 통상의 지식을 가진 자에 의해 일반적으로 이해되는 것과 동일한 의미를 가질 수 있다. 또한, 본 명세서에서 사용되는 '제1' 또는 '제2' 등과 같이 서수를 포함하는 용어는 다양한 구성 요소들을 설명하는데 사용할 수 있지만, 상기 구성 요소들은 상기 용 어들에 의해 한정되어서는 안 된다. 상기 용어들은 하나의 구성 요소를 다른 구성 요소로부터 구별하는 목적으 로만 사용된다. 명세서 전체에서 어떤 부분이 어떤 구성요소를 \"포함\"한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다른 구성요소를 제외하는 것이 아니라 다른 구성요소를 더 포함할 수 있음을 의미한다. 또한, 명세서에 기재된 \"부\", \"모듈\" 등의 용어는 적어도 하나의 기능이나 동작을 처리하는 단위를 의미하며, 이는 하드웨어 또는 소 프트웨어로 구현되거나 하드웨어와 소프트웨어의 결합으로 구현될 수 있다. 아래에서는 첨부한 도면을 참고하여 본 개시의 실시예에 대하여 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자가 용이하게 실시할 수 있도록 상세히 설명한다. 그러나 본 개시는 여러 가지 상이한 형태로 구현될 수 있으며 여기에서 설명하는 실시예에 한정되지 않는다. 그리고 도면에서 본 개시를 명확하게 설명하기 위해서 설 명과 관계없는 부분은 생략하였으며, 명세서 전체를 통하여 유사한 부분에 대해서는 유사한 도면 부호를 붙였다. 이하 첨부된 도면을 참고하여 본 개시를 상세히 설명하기로 한다. 도 1은 본 개시의 일 실시예에 따른 전자 장치가 콘텐트 서비스를 제공하는 것을 개략적으로 도시한 도면이다. 일 실시예에 따른 전자 장치는 디스플레이를 포함하여 영상 및/또는 동영상을 출력하는 장치일 수 있다. 예를 들어, 전자 장치는 스마트 TV, 스마트폰, 태블릿 PC, 랩탑 PC, 액자형 디스플레이 등을 포함할 수 있으나, 이에 한정되는 것은 아니며, 전자 장치 디스플레이를 포함하는 다양한 종류 및 형태의 전자 장치 로 구현될 수 있다. 또한, 전자 장치는 스피커를 포함하여 오디오를 출력할 수 있다. 본 개시에서 전자 장치는 전자 장치에서 재생되는 원본 콘텐트는 제1 콘텐트로 지칭된다. 일 실시 예에 따른 전자 장치는 전자 장치에서 재생되는 제1 콘텐트를 커스터마이징할 수 있다. 예를 들면, 전자 장치는 제1 콘텐트에 포함되는 콘텐트 요소들을 기초로 새로운 콘텐트인 제2 콘텐트를 생성할 수 있다. 제2 콘텐트는 이미지, 오디오 및 텍스트 중 적어도 하나를 포함할 수 있다. 전자 장치는 생성된 제2 콘텐트를 제1 콘텐트와 결합하여 개인화된 콘텐트를 생성할 수 있다. 예를 들어, 전자 장치는 제1 콘텐트에 포함되는 콘텐트 요소들인 이미지, 오디오, 텍스트 중 적어도 하나 를 제2 콘텐트으로 대체할 수 있다. 일 실시예에서, 전자 장치가 제2 콘텐트를 생성할 때, 생성형 인공지능 모델이 이용될 수 있다. 생성형 인공지능 모델은 제1 콘텐트 내 포함되는 콘텐트 요소들과 유사한 특성 또는 새로운 특성을 갖는 콘텐트를 생성 하기 위한 인공지능 모델을 말한다. 전자 장치는 생성형 인공지능 모델을 이용하여 제2 콘텐트를 생성하 고, 제1 콘텐트 및 제2 콘텐트로 구성되는 개인화된 콘텐트를 사용자에게 제공할 수 있다. 전자 장치가 제2 콘텐트를 생성하고 원본 콘텐트에 적용함으로써, 개인화된 콘텐트를 생성하기 위한 구체 적인 동작들에 대해서는, 후술하는 도면들과 그에 대한 설명에서 더 상세하게 서술하기로 한다. 도 2는 본 개시의 일 실시예에 따른 전자 장치가 콘텐트를 생성하는 동작들을 도시한 흐름도이다. 단계 S210에서, 전자 장치는 재생 중인 제1 콘텐트와 관련된 정보를 획득한다. 본 개시에서, 제1 콘텐트는 영화, 드라마 시리즈, 다큐멘터리, 엔터테인먼트, TV 프로그램, 기타 비디오 콘텐트 등을 포함하는 다양한 미디어 콘텐트를 지칭하며, 멀티미디어 콘텐트라고 지칭될 수도 있다. 일 실시예에서, 제1 콘텐트는 멀티미디어 데이터를 패키징하는 표준화된 방식으로 제작된 디지털 파일 포맷일 수 있다. 예를 들어, MP4, AVI, MKV, MOV, WMV 등의 미디어 컨테이너 포맷이 이용될 수 있으나, 이에 한정되는 것은 아니다. 제1 콘텐트는 다양한 타입의 미디어 데이터를 포함할 수 있다. 예를 들어, 제1 콘텐트는 비디오, 오디오, 및 텍 스트를 포함할 수 있다. 전자 장치는 전자 장치에서 재생 중인 제1 콘텐트를 식별하고, 제1 콘텐트 와 관련된 정보를 획득할 수 있다. 제1 콘텐트는 콘텐트와 관련된 다양한 정보를 포함할 수 있다. 예를 들어, 제1 콘텐트는 타이틀, 제작자, 재생 시간, 장르, 출연자 정보, 플랫폼 정보 및 채널 정보를 메타데이터로 포함할 수 있다. 다만, 콘텐트와 관련된 정보는 전술한 예시에 한정되는 것은 아니다. 단계 S220에서, 전자 장치는 제1 콘텐트와 관련된 정보에 기초하여, 제1 콘텐트에서 편집 가능한 콘텐트 요소들 및 생성 가능한 콘텐트 요소들 중 적어도 하나를 포함하는 사용자 인터페이스를 생성한다. 사용자 인터 페이스는 전자 장치의 사용자가 제1 콘텐트를 커스터마이징 할 수 있도록 하는 직관적인 인터페이스를 말 한다. 일 실시예에서, 전자 장치는 제1 콘텐트에서 편집 가능한 콘텐트 요소들을 포함하는 사용자 인터페이스를 생성할 수 있다. 편집 가능한 콘텐트 요소들은 제1 콘텐트에 포함되는 이미지, 오디오, 텍스트 중 적어도 하나 일 수 있다. 예를 들어, 전자 장치는 제1 콘텐트 내 인물의 외형을 사용자가 편집할 수 있도록 하는 사용 자 인터페이스를 생성할 수 있다. 일 실시예에서, 전자 장치는 제1 콘텐트에서 생성 가능한 콘텐트 요소들을 포함하는 사용자 인터페이스를 생성할 수 있다. 생성 가능한 콘텐트 요소들은 제1 콘텐트에 추가할 수 있는 이미지, 오디오, 텍스트 중 적어도 하나일 수 있다. 예를 들어, 전자 장치는 제1 콘텐트 내에 새로운 가상 객체를 사용자가 추가할 수 있도 록 하는 사용자 인터페이스를 생성할 수 있다. 일 실시예에서, 사용자 인터페이스는 제1 콘텐트와 관련된 정보에 기초하여 생성될 수 있다. 예를 들어, 전자 장치는 제1 콘텐트의 장르에 기초하여, 장르 별로 기 정의된 콘텐트 요소가 포함되도록 사용자 인터페이 스를 생성할 수 있다. 전자 장치가 기 정의된 설정에 기초하여 사용자 인터페이스를 생성하는 것은 도 5 를 참조하여 더 기술한다. 단계 S230에서, 전자 장치는 사용자 인터페이스를 통해 콘텐트 요소를 선택하는 사용자 입력을 수신한다. 일 실시예에서, 전자 장치의 사용자는 사용자 인터페이스를 통해 제1 콘텐트 내 콘텐트 요소를 변경하거 나, 제1 콘텐트에 추가될 새로운 콘텐트 요소를 생성할 수 있다. 일 실시예에서, 전자 장치의 사용자는 제1 콘텐트에 포함되는 이미지, 오디오, 텍스트 중 적어도 하나를 사용자 인터페이스를 통해 선택할 수 있다. 예를 들어, 전자 장치의 사용자는 제1 콘텐트 내 인물의 외형 을 편집하기 위해, 사용자 인터페이스를 통해 제1 콘텐트 내의 인물을 선택할 수 있다. 일 실시예에서, 전자 장치의 사용자는 제1 콘텐트에 추가될 이미지, 오디오, 텍스트 중 적어도 하나를 사 용자 인터페이스를 통해 선택할 수 있다. 예를 들어, 전자 장치의 사용자는 제1 콘텐트에 가상 객체를 추 가하기 위해, 사용자 인터페이스를 통해 가상 객체를 선택할 수 있다. 일 실시예에서, 전자 장치는 사용자 입력에 기초하여 제1 콘텐트 내의 콘텐트 요소를 변경하거나, 새로운 콘텐트 요소를 생성할 수 있다. 본 개시에서 전자 장치가 변경 및/또는 생성하는 콘텐트 요소는 \"제2 콘 텐트\"라고 지칭된다. 단계 S240에서, 일 실시예에 따른 전자 장치는 사용자 입력에 대응하는 콘텐트 요소를 기초로 제1 콘텐트 에 대응하는 제2 콘텐트를 생성한다.일 실시예에서, 전자 장치는 제1 콘텐트 내 콘텐트 요소들 중에서 사용자 입력에 대응하는 콘텐트 요소를 변경함으로써 제2 콘텐트를 생성할 수 있다. 예를 들어, 제2 콘텐트는, 제1 콘텐트 내 인물의 외형을 변경한 새 로운 인물의 이미지일 수 있다. 일 실시예에서, 전자 장치는 사용자 입력에 대응하는 콘텐트 요소를 생성함으로써 제2 콘텐트를 생성할 수 있다. 예를 들어, 제2 콘텐트는, 제1 콘텐트에 추가될 수 있는 가상 객체의 이미지일 수 있다. 일 실시예에서, 전자 장치는 생성형 인공지능 모델을 이용하여 제2 콘텐트를 생성할 수 있다. 전자 장치 는 이미지, 오디오, 텍스트 중 적어도 하나를 포함하는 제2 콘텐트를 생성할 수 있다. 단계 S250에서, 일 실시예에 따른 전자 장치는 제1 콘텐트 및 제2 콘텐트를 포함하는 개인화된 콘텐트를 생성한다. 일 실시예에서, 제1 콘텐트는 원본(original) 콘텐트이고, 제2 콘텐트는 사용자에 의해 전자 장치에서 생 성된 콘텐트이다. 따라서, 제1 콘텐트에 제2 콘텐트가 결합되면, 다른 사용자들에게는 제공되지 않는 사용자만 의 개인화된 콘텐트가 생성될 수 있다. 도 3은 본 개시의 일 실시예에 따른 전자 장치의 전반적인 동작을 도시한 도면이다. 단계 S310에서, 전자 장치는 제2 콘텐트 생성 모드를 실행한다. 제2 콘텐트는, 전자 장치에서 재생 중이거나 재생 가능한 원본 콘텐트인 제1 콘텐트에 대응되는 콘텐트를 말한다. 예를 들어, 제1 콘텐트는 이미지, 오디오, 텍스트 등의 콘텐트 요소로 구성되고 제1 콘텐트에 부가적으로 결합될 수 있는 콘텐트를 말한 다. 도 2에서 전술한 전자 장치가 제2 콘텐트를 생성하고 개인화된 콘텐트를 생성하는 동작들은, 제2 콘텐트 생 성 모드를 실행함으로써 수행될 수 있다. 일 실시예에서, 전자 장치의 홈 메뉴에는 제2 콘텐트 생성 모드(예를 들어, 생성형 인공지능 모드)가 포 함될 수 있다. 전자 장치는 사용자가 홈 메뉴에서 제2 콘텐트 생성 모드를 실행하는 것을 식별할 수 있다. 일 실시예에서, 전자 장치가 동작하는 도중에, 전자 장치의 사용자가 단축 메뉴를 통해서 제2 콘텐 트 생성 모드(예를 들어, 생성형 인공지능 모드)를 실행할 수 있다. 이 경우, 전자 장치는 제1 콘텐트를 재생하는 도중에, 제2 콘텐트 생성 모드의 실행을 식별하고, 제2 콘텐트 생성 모드를 직접적으로 실행할 수 있 다. 전자 장치는 제2 콘텐트를 생성하기 위해, 제1 콘텐트와 관련된 정보를 획득할 수 있다. 구체적으로, 전 자 장치는 제1 콘텐트의 장르를 식별하고, 식별된 장르에 대응하는 최적화 기능을 실행할 수 있다. 제1 콘텐트의 장르는 예를 들어, 시사, 스포츠, 영화, 예능, 음악, 토론, 경제, 다큐멘터리 등으로 분류될 수 있으 나, 이에 한정되는 것은 아니다. 단계 S320에서, 전자 장치는 제1 콘텐트와 관련된 정보에 기초하여 제2 콘텐트를 생성하기 위한 사용자 인터페이스를 생성할지 여부를 결정할 수 있다. 예를 들어, 전자 장치는 제1 콘텐트의 장르에 기초하여 사용자 인터페이스의 생성 여부를 결정할 수 있다. 전자 장치는 제1 콘텐트의 장르에 따라, 제1 콘텐트에 대응하는 부가 콘텐트인 제2 콘텐트를 생성하기 위 한 사용자 인터페이스를 생성할 수 있다. 사용자 인터페이스는 제1 콘텐트에서 편집 가능한 콘텐트 요소들 및 생성 가능한 콘텐트 요소들 중 적어도 하나를 포함할 수 있다. 전자 장치의 사용자는 사용자 인터페이스를 통한 사용자 입력을 통해 제2 콘텐트를 생성할 수 있다. 이 경우, 사용자에게 제공되는 사용자 인터페이스는 제1 콘텐트의 장르별로 상이한 양식일 수 있으며, 콘텐트의 장 르마다 각각의 장르에 맞게 최적화된 것일 수 있다. 제1 콘텐트의 장르가 사용자 인터페이스의 생성이 필요 없 는 것으로 설정된 것인 경우, 전자 장치는 자동으로 최적화를 진행하여 제1 콘텐트와 관련된 제2 콘텐트 를 생성할 수 있다. 단계 S330에서, 전자 장치는 제2 콘텐트를 생성할 수 있다. 예를 들어, 전자 장치는 사용자 인터페 이스를 통한 사용자 입력에 기초하여 제2 콘텐트를 생성할 수 있다. 또는, 전자 장치는 제1 콘텐트 내 요 소를 기초로 제2 콘텐트를 생성할 수 있다. 생성된 제2 콘텐트는 서버에 사용자 정보와 연계하여 업데이트될 수 있다. 예를 들어, 사용자가 전자 장치에 로그인하여 계정 정보가 존재하면, 전자 장치는 사용자에 대하여 생성된 제2 콘텐트를 누적하여 저장하고 업데이트하며 관리할 수 있다. 사용자에 대하여 저장되는 제2콘텐트의 이력은, 사용자가 장래 시점에 또다른 제1 콘텐트에 대하여 또다른 제2 콘텐트를 생성하는 데 이용될 수 있다. 도 4a는 본 개시의 일 실시예에 따른 전자 장치에서 제2 콘텐트 생성 모드를 실행하는 동작을 설명하기 위한 도 면이다. 일 실시예에서, 전자 장치는 홈 메뉴에 제2 콘텐트 생성 모드(예를 들어, 생성형 인공지능 모드)의 메뉴 를 표시할 수 있다. 또한, 제2 콘텐트 생성 모드의 메뉴에는, 콘텐트의 장르가 표시될 수 있다. 예를 들어, 토론, 음악방송, 스포츠와 같은 콘텐트 장르가 표시될 수 있다. 전자 장치는 사용자에 의해 콘텐트 장르가 선택되면, 콘텐트 장르에 대응하는 장르별 최적화된 사용자 인 터페이스를 생성하고 전자 장치의 화면에 표시할 수 있다. 예를 들어, 토론 장르가 전자 장치 에서 선택되는 경우, 토론 장르에 포함되는 복수의 콘텐츠가 표시된다. 사용자가 복수의 콘텐츠 중 어느 한 콘텐트(제1 콘텐트)를 선택하는 경우, 제1 콘텐트가 재생될 수 있다. 이 경우, 제1 콘텐트의 시청 화면 이 표시되며, 제1 콘텐트에 대응하는 제2 콘텐트를 생성하기 위한 사용자 인터페이스가 표시될 수 있다. 도 4a의 예시에서, 사용자에 의해 선택된 콘텐트 장르가 토론이므로, 토론 장르에 최적화된 사용자 인터페이스가 표시될 수 있다. 다만 이는 예시일 뿐이며, 제1 콘텐트의 장르에 따라 장르별로 최적화된 사 용자 인터페이스가 상이하게 표시될 수 있다. 이는 도 5를 참조하여 더 기술한다. 도 4b는 본 개시의 일 실시예에 따른 전자 장치에서 제2 콘텐트 생성 모드를 실행하는 동작을 설명하기 위한 도 면이다. 일 실시예에서, 전자 장치가 동작하는 도중에, 전자 장치의 사용자가 단축 메뉴를 통해서 제2 콘텐 트 생성 모드(예를 들어, 생성형 인공지능 모드)를 실행할 수 있다. 이 경우, 전자 장치는 제1 콘텐트의 시청 화면이 표시되는 도중에, 제2 콘텐트 생성 모드를 실행하고, 장르별 최적화된 사용자 인터페이스 를 제1 콘텐트의 시청 화면과 함께 표시할 수 있다. 한편, 도 4a에서 사용자가 제1 콘텐트의 장르를 선택하는 반면에, 도 4b에서는 장르 선택 없이 제1 콘텐트가 재 생되는 도중에 사용자에 의해 제2 콘텐트 생성 모드가 실행된다. 이 경우, 전자 장치는 제1 콘텐트의 장 르를 식별하는 일련의 동작들을 수행할 수 있다. 일 실시예에서, 전자 장치는 제1 콘텐트와 관련된 정보인 제1 콘텐트의 메타데이터를 이용할 수 있다. 메 타데이터는 제1 콘텐트의 타이틀, 제작자, 재생 시간, 장르, 출연자 정보, 플랫폼 정보 및 채널 정보를 포함할 수 있으나, 이에 한정되는 것은 아니다. 메타데이터에 제1 콘텐트의 장르 정보가 포함되지 않는 경우, 전자 장 치는 메타데이터에 포함되는 다른 정보들(예를 들어, 타이틀 등)을 이용하여 제1 콘텐트의 장르를 추론할 수 있다. 메타데이터에 제1 콘텐트의 장르 정보가 포함되는 경우, 전자 장치는 제1 콘텐트의 장르를 식별 할 수 있다. 일 실시예에서, 메타데이터로부터 제1 콘텐트의 장르가 추론되지 않거나, 메타데이터가 획득되지 않는 경우, 전 자 장치는 제1 콘텐트를 분석하여 제1 콘텐트의 장르를 식별할 수 있다. 예를 들어, 전자 장치는 장면 분석을 수행하여 장면 콘텍스트 데이터를 획득할 수 있다. 전자 장치는 장면 분석을 위해 하나 이상 의 인공지능 모델들을 이용할 수 있다. 전자 장치는 제1 콘텐트에 포함되는 비디오 데이터의 하나 이상의 비디오 프레임들을 선택하고, 비디오 프레임 내에서 적어도 하나의 객체를 검출할 수 있다. 전자 장치는 객체 검출을 위해, 인공지능 모델인 객체 검출 모델을 이용할 수 있다. 객체 검출 모델은 이미지를 입력 받아 검출된 객체들을 나타내는 정보를 출 력하는 심층 신경망 모델일 수 있다. 예를 들어, 객체 검출 모델은 이미지를 입력 받아 검출된 객체들을 나타내 는 바운딩 박스를 출력할 수 있다. 객체 검출 모델은 알려진 다양한 심층 신경망 아키텍처 및 알고리즘을 이용 하거나, 알려진 다양한 심층 신경망 아키텍처 및 알고리즘의 변형을 통해 구현될 수 있다. 전자 장치는 비디오 프레임 내에서 검출된 적어도 하나의 객체의 카테고리를 인식할 수 있다. 전자 장치 는 객체 인식을 위해, 인공지능 모델인 객체 인식 모델을 이용할 수 있다. 객체 인식 모델은 이미지를 입 력 받아 객체 클래스 레이블(들)을 나타내는 정보를 출력하는 심층 신경망 모델일 수 있다. 예를 들어, 객체 인 식 모델은, 객체를 잘라낸 이미지를 입력 받아 하나 이상의 객체 클래스 레이블(예를 들어, \"자동차\", \"사람\" 등) 및 신뢰도 스코어를 출력할 수 있다. 객체 인식 모델은 알려진 다양한 심층 신경망 아키텍처 및 알고리즘을 이용하거나, 알려진 다양한 심층 신경망 아키텍처 및 알고리즘의 변형을 통해 구현될 수 있다.전자 장치는 인식된 객체들 간 관계를 검출할 수 있다. 전자 장치는 객체 관계 검출을 위해, 인공 지능 모델인 객체 관계 검출 모델을 이용할 수 있다. 객체 관계 검출 모델은 검출된 객체들에 관한 정보를 입력 받아 객체들 간 관계를 나타내는 정보를 출력하는 심층 신경망 모델일 수 있다. 예를 들어, 객체 관계 검출 모 델은 검출된 객체 \"사람 a\" 및 \"사람 b\"에 관한 정보를 입력 받아, 사람이 지붕 위에 있음을 나타내는 두 객체 간 관계 \"옆에(next to)\"를 출력하는 모델일 수 있다. 객체 관계 검출 모델은 알려진 다양한 심층 신경망 아키 텍처 및 알고리즘을 이용하거나, 알려진 다양한 심층 신경망 아키텍처 및 알고리즘의 변형을 통해 구현될 수 있 다. 전자 장치는 객체 검출, 객체 인식, 객체 관계 검출의 결과 데이터에 기초하여, 장면 그래프를 생성할 수 있다. 여기서, 장면 그래프의 하나 이상의 노드들은 하나 이상의 객체들을 나타내고, 하나 이상의 에지들은 하 나 이상의 객체들 간 관계들을 나타낸다. 또한, 전자 장치는 장면 그래프에 기초하여 장면 콘텍스트를 생 성할 수 있다. 전자 장치는 하나 이상의 비디오 프레임들에 대하여 각각 장면 콘텍스트를 생성하고, 장면 콘텍스트에 기초하여 제1 콘텐트의 장르를 식별할 수 있다. 도 4b의 예시에서, 시청 화면의 제1 콘텐트가 \"TV 토론\"인 경우, 장면 분석에 의해 제1 콘텐트의 장르가 토론으로 식별되고, 토론 장르에 최적화된 사용자 인터페이스가 표시될 수 있다. 다만 이는 예시일 뿐이며, 제1 콘텐트의 장르에 따라 장르별로 최적화된 사용자 인터페이스가 상이하게 표시될 수 있다. 이는 도 5를 참조하여 더 기술한다. 도 5는 본 개시의 일 실시예에 따른 전자 장치가 사용자 인터페이스를 생성할 때 이용하는 기 정의된 설정을 설 명하기 위한 도면이다. 일 실시예에서, 전자 장치는 제1 콘텐트에 대응하는 제2 콘텐트를 생성하기 위한 사용자 인터페이스를 생 성할 때, 기 정의된 설정을 이용할 수 있다. 기 정의된 설정은, 제1 콘텐트의 장르에 따라, 사용자 인터페이스에 포함될 콘텐트 요소를 정의 하고, 사용자 인터페이스를 통해 생성될 제2 콘텐트를 정의한 것일 수 있다. 예를 들어, 제1 콘텐트의 장르가 \"뉴스, 토론\"인 경우, \"뉴스, 토론\" 장르에 대응하는 기 정의된 콘텐트 요소는 \"인물, 대화 내용\"일 수 있다. 이 경우, 제2 콘텐트를 생성하기 위한 사용자 인터페이스에는 콘텐 트 요소인 \"인물, 대화 내용\"이 포함될 수 있다. 전자 장치의 사용자는, 사용자 인터페이스를 통해 제2 콘텐트를 생성할 수 있다. 예를 들어, \"뉴스, 토론\" 장르의 제1 콘텐트에 대하여, 사용자는 콘텐트 요소인 \"인물\"을 편집할 수 있다. 구체적으로, 사용 자는 3D 캐릭터를 제2 콘텐트로 생성할 수 있다. 사용자는 제2 콘텐트를 이용하여 뉴스, 토론에 출연 한 인물의 모습을 3D 캐릭터로 변경할 수 있다. 예를 들어, 사용자는 콘텐트 요소인 \"대화 내용\"을 생성할 수"}
{"patent_id": "10-2023-0059325", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "있다. 구체적으로, 사용자는 키워드 추출 및 분석 결과, 대화 내용 요약 등을 제2 콘텐트로 생성할 수 있"}
{"patent_id": "10-2023-0059325", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "다. 사용자는 제2 콘텐트를 이용하여 뉴스, 토론이 진행중인 화면에 키워드 분석 결과, 대화 내용 요약 등"}
{"patent_id": "10-2023-0059325", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "을 중첩하여 표시되도록 할 수 있다. 한편, 키워드 분석 결과, 대화 내용 요약 등의 제2 콘텐트는, 전자 장치 에서 제1 콘텐트의 재생이 종료된 이후에 사용자에게 제공될 수 있고, 전자 장치 외의 다른 전자 장치를 통해 사용자에게 제공될 수도 있다. 일 실시예에 따른 전자 장치는 기 정의된 설정에 기초하여, 제1 콘텐트의 장르별로 최적화된 사용자 인터페이스를 생성할 수 있다. 또다른 예를 들면, 제1 콘텐트의 장르가 \"스포츠\"인 경우, 제2 콘텐트를 생 성하기 위한 사용자 인터페이스에는 포함되는 콘텐트 요소는 \"인물, 배경\" 일 수 있으며, 사용자는 사용자 인터페이스를 통해 \"인물, 배경\"을 편집하거나 생성함으로써 제2 콘텐트를 생성할 수 있다. 도 6은 본 개시의 일 실시예에 따른 전자 장치가 제2 콘텐트를 생성하는 예를 설명하기 위한 도면이다. 도 6을 참조하면, 일 실시예에 따른 전자 장치는 재생 중인 제1 콘텐트(예를 들어, 라이브 채널 방송 )를 식별할 수 있다. 전자 장치는 재생 중인 제1 콘텐트와 관련된 정보를 획득할 수 있다. 예를 들어, 전자 장치는 제1 콘텐트의 타이틀, 제작자, 재생 시간, 장르, 출연자 정보, 플랫폼 정보 및 채널 정보 등을 포함하는 메타데이터 에 기초하여, 제1 콘텐트의 장르를 식별할 수 있다. 또는, 전자 장치는 제1 콘텐트에 대하여 장면 분석을 통해 장면 콘텍스트 데이터를 획득하고, 제1 콘텐트의 장르를 인식할 수 있다. 전자 장치가 제1 콘텐트의 장르를 인식하는 것은 도 4b에 대한 설명에서 전술하였으므로, 반복되는 설명은 생략한다.일 실시예에서, 전자 장치는 제1 콘텐트의 장르에 기초하여, 제2 콘텐트를 생성하기 위한 사용 자 인터페이스를 생성할 수 있다. 사용자 인터페이스는 제1 콘텐트에서 편집 가능한 콘텐트 요소들 및 생성 가 능한 콘텐트 요소들 중 적어도 하나를 포함할 수 있으며, 장르별로 최적화된 기 정의된 콘텐트 요소들이 포함될 수 있다. 예를 들어, 제1 콘텐트의 장르가 \"토론\"인 경우, 사용자 인터페이스에는 \"토론\"에 대응하도록 기 정의된 콘텐트 요소인 \"인물, 대화 내용\"등이 포함될 수 있다. 전자 장치의 사용자는 사용자 인터페이"}
{"patent_id": "10-2023-0059325", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "스를 통해 토론에 출연한 인물을 편집하거나, 대화 내용과 관련된 키워드, 요약 등을 생성하는 등, 사용자 선호 에 맞게 제2 콘텐트를 생성할 수 있다. 일 실시예에서, 전자 장치는 생성형 인공지능 모델을 이용하여 제2 콘텐트를 생성할 수 있다. 생성형 인공지능 모델은 이미지 생성(또는, 비디오 생성, 3D 객체 생성), 오디오 생성(또는, 음성 생성, 오디오 생성), 텍스트 생성 중 적어도 하나의 태스크를 수행하는 심층 신경망 모델일 수 있다. 생성형 인공지능 모델은 알려진 다양한 심층 신경망 아키텍처 및 알고리즘을 이용하거나, 알려진 다양한 심층 신경망 아키 텍처 및 알고리즘의 변형을 통해 구현될 수 있다. 일 실시예에서, 전자 장치가 이용하는 생성형 인공지능 모델은 복수 개일 수 있다. 예를 들어, 생성 형 인공지능 모델은 이미지를 생성하는 제1 생성형 인공지능 모델, 오디오를 생성하는 제2 생성형 인공지능 모 델, 텍스트를 생성하는 제3 생성형 인공지능 모델을 포함할 수 있다. 제1 생성형 인공지능 모델은 이미지 생성 태스크를 수행하는 인공지능 모델일 수 있다. 제1 생성형 모델은 이미 지, 비디오, 3D 객체 등을 생성하기 위한 알려진 다양한 심층 신경망 아키텍처 및 알고리즘을 이용하거나, 알려 진 다양한 심층 신경망 아키텍처 및 알고리즘의 변형을 통해 구현될 수 있다. 제1 생성형 인공지능 모델은 예를 들어, 생성형 적대 네트워크(Generative Adversarial Networks; GANs), 가변적 오토인코더(Variational Autoencoders; VAEs) 등을 이용하여 구현될 수 있으나, 이에 한정되는 것은 아니다. 일 실시예에서, 제2 콘텐트는 이미지일 수 있다. 전자 장치는 제1 생성형 인공지능 모델을 이 용하여 이미지를 생성할 수 있다. 예를 들어, 전자 장치는 제1 생성형 인공지능 모델을 이용하여 제 1 콘텐트의 인물, 객체, 배경들과 유사한 특성을 갖는 이미지, 새로운 특성을 갖는 이미지를 생성할 수 있다. 구체적으로, 인물에 대하여, 머리 색상, 얼굴 표정, 복장 종류 등을 변경한 새로운 이미지를 생성할 수 있다. 제2 생성형 인공지능 모델은 오디오 생성 태스크를 수행하는 인공지능 모델일 수 있다. 제2 생성형 모델은 음성, 음악 및 기타 사운드 등의 오디오를 생성하기 위한 알려진 다양한 심층 신경망 아키텍처 및 알고리즘을 이용하거나, 알려진 다양한 심층 신경망 아키텍처 및 알고리즘의 변형을 통해 구현될 수 있다. 제2 생성형 인공 지능 모델은 예를 들어, 순환 신경망(Recurrent Newral Networks; RNNs), 가변적 오토인코더(Variational Autoencoders; VAEs), WaveNet, Tacotron 등을 이용하여 구현될 수 있으나, 이에 한정되는 것은 아니다. 일 실시예에서, 제2 콘텐트는 오디오일 수 있다. 전자 장치는 제2 생성형 인공지능 모델을 이 용하여 오디오를 생성할 수 있다. 예를 들어, 전자 장치는 제2 생성형 인공지능 모델을 이용하여 제 1 콘텐트의 사람, 악기 등과 관련된 오디오와 유사한 특성을 갖는 오디오, 새로운 특성을 갖는 오디오를 생성할 수 있다. 구체적으로, 사람의 음성에 대하여, 톤, 목소리, 성별, 언어, 대화 내용 등을 변경한 새로운 음성을 생성할 수 있다. 제3 생성형 인공지능 모델은 텍스트 생성 태스크를 수행하는 인공지능 모델일 수 있다. 제3 생성형 모델은 텍스 트를 생성하기 위한 알려진 다양한 심층 신경망 아키텍처 및 알고리즘을 이용하거나, 알려진 다양한 심층 신경 망 아키텍처 및 알고리즘의 변형을 통해 구현될 수 있다. 제3 생성형 인공지능 모델은 예를 들어, 순환 신경망 (Recurrent Newral Networks; RNNs), Transformers 등을 이용하여 구현될 수 있으나, 이에 한정되는 것은 아니 다. 일 실시예에서, 제2 콘텐트는 텍스트일 수 있다. 전자 장치는 제3 생성형 인공지능 모델을 이 용하여 텍스트를 생성할 수 있다. 예를 들어, 전자 장치는 제3 생성형 인공지능 모델을 이용하여 제 1 콘텐트의 사람의 대화 내용과 관련된 텍스트와 유사한 특성을 갖는 텍스트, 새로운 특성을 갖는 텍스트를 생 성할 수 있다. 구체적으로, 사람의 대화 내용에 대하여, 대화 내용의 성향, 감정, 키워드, 주제 등을 나타내는 텍스트를 생성할 수 있다. 한편, 전술한 제1 생성형 인공지능 모델, 제2 생성형 인공지능 모델 및 제3 생성형 인공지능 모델은, 하나의 통 합된 생성형 인공지능 모델로 구현될 수도 있다. 전자 장치는 이미지, 오디오 및 텍스트 중 적어도 하나를 포함하는 제2 콘텐트를 생 성하고, 생성된 제2 콘텐트를 제1 콘텐트(예를 들어, 라이브 채널 방송)에 결합함으로써 개인화된 콘 텐트를 생성할 수 있다. 그리고, 전자 장치는 개인화된 콘텐트를 사용자에게 제공할 수 있다. 도 7a는 본 개시의 일 실시예에 따른 전자 장치가 생성하는, 제2 콘텐트를 생성하기 위한 사용자 인터페이스를 설명하기 위한 도면이다. 일 실시예에서, 전자 장치는 제1 콘텐트와 관련된 정보에 기초하여, 제1 콘텐트에서 편집 가능한 콘텐트 요소들 및 생성 가능한 콘텐트 요소들 중 적어도 하나를 포함하는 사용자 인터페이스를 생성할 수 있다. 일 실시예에서, 사용자 인터페이스는 제1 콘텐트의 장르에 따라 최적화된 것일 수 있다. 예를 들어, 제1 콘텐트의 장르가 \"토론\"인 경우, 제2 콘텐트를 사용하기 위한 사용자 인터페이스는 \"토론\" 장르에 대하여 최적화된 콘텐트 요소들을 포함하도록 구성될 수 있다. 구체적으로, \"토론\" 장르에서 주요 콘텐트 요소에 해당 하는 인물, 대화 내용이 사용자 인터페이스에 포함될 수 있다. 전자 장치의 사용자는 사용자 인터페이스에 표시되는 콘텐트 요소를 선택하고, 콘텐트 요소를 편집 하거나 생성함으로써, 제2 콘텐트를 생성할 수 있다. 예를 들어, 사용자는 사용자 인터페이스에 표시된 콘텐트 요소인 제1 인물을 선택할 수 있다. 사용자 는 제1 인물의 머리 색상, 얼굴 표정, 복장 종류 등을 변경한 새로운 이미지(제2 콘텐트)를 생성할 수 있 다. 또는, 사용자는 제1 인물의 음성에 대하여, 톤, 목소리, 성별, 언어, 대화 내용 등을 변경한 새로운 음성(제2 콘텐트)을 생성할 수도 있다. 이 경우, 전자 장치에서 제1 콘텐트인 인물 간 토론 프로그램이 재생될 때, 제1 인물의 외형, 음성 등은 사용자가 생성한 제2 콘텐트로 대체될 수 있다. 같은 방식으로, 전자 장치의 사용자는 사용자 인터페이스를 통해 제2 인물, 제3 인물의 외형, 음성 등에 사용자가 생성한 제2 콘텐트를 적용함으로써 인물의 외형, 음성 등을 변경할 수 있다. 예를 들어, 사용자는 사용자 인터페이스에 표시된 콘텐트 요소인 대화 내용을 선택할 수 있다. 사용 자는 제1 인물의 대화 내용 및 제2 인물의 대화 내용에 대하여, 대화 내용의 성향, 감정, 키워드, 주 제 등을 나타내는 텍스트를 생성할 수 있다. 이 경우, 제1 콘텐트인 인물 간 토론 프로그램이 재생될 때, 제2"}
{"patent_id": "10-2023-0059325", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "콘텐트인 제1 인물의 대화 내용의 요약 및 제2 인물의 대화 내용의 요약이 함께 표시될 수 있다. 도 7b는 본 개시의 일 실시예에 따른 전자 장치가 백그라운드 프로세스에서 제2 콘텐트를 생성하는 동작을 설명 하기 위한 도면이다. 도 7b에 도시된 제1 화면을 참조하면, 일 실시예에 따른 전자 장치는 제1 콘텐트 및 제2 콘텐트를 포함하는 개인화된 콘텐트를 표시할 수 있다. 이 경우, 제2 콘텐트는 자동으로 생성되거나, 사용자의 요청에 의 해 생성되는 것일 수 있다. 일 실시예에서, 전자 장치에서 재생 중인 제1 콘텐트가 다른 콘텐트로 변경될 수 있다. 예를 들어, 사용 자의 전자 장치 조작에 의해, 전자 장치의 채널이 변경되어 제2 화면과 같이 다른 콘텐트가 재생될 수 있다. 전자 장치는 전자 장치에서 재생 중인 제1 콘텐트가 다른 콘텐트로 변경되는 것을 식별하면, 제2 콘텐트의 생성을 종료하지 않고 백그라운드 프로세스에서 제2 콘텐트 생성 작업을 계속할 수 있다. 예를 들어,"}
{"patent_id": "10-2023-0059325", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 7, "content": "전자 장치가 생성하는 제2 콘텐트는 제1 콘텐트의 요약일 수 있다. 전자 장치는 토론 프로그램이"}
{"patent_id": "10-2023-0059325", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 8, "content": "종료될 때까지 토론 참여자들의 대화 내용을 요약하고, 다른 채널에서 방송 중인 제1 콘텐트가 종료되면, 제2 콘텐트 생성 알림을 사용자에게 제공할 수 있다. 전자 장치의 사용자는 전자 장치의 화면을 통해 제2 콘텐트를 확인하거나, 전자 장치 외의 다른 전자 장치를 이용하여 제2 콘텐트를 확인할 수 있다. 도 8a는 본 개시의 일 실시예에 따른 전자 장치가 개인화된 콘텐트를 제공하는 예시를 도시한 도면이다. 일 실시예에서, 전자 장치는 제1 콘텐트 및 제2 콘텐트를 포함하는 개인화된 콘텐트를 생성할 수 있다. 전자 장치는 제1 콘텐트와 관련된 정보에 기초하여, 제1 콘텐트에서 편집 가능한 콘텐트 요소들 및 생성 가능한 콘텐트 요소들 중 적어도 하나를 포함하는 사용자 인터페이스를 생성할 수 있다. 예를 들어, 제1 콘텐트의 장르가 스포츠(단거리 달리기)인 경우, 전자 장치는 스포츠 장르에 대하여 편집 가능한 기 정의된 콘 텐트 요소들을 표시할 수 있다. 스포츠 장르에 대하여 기 정의된 콘텐트 요소들은 예를 들어, 인물, 배경 등일 수 있으나, 이에 한정되는 것은 아니다. 전자 장치는 사용자 인터페이스를 통해 콘텐트 요소를 선택하는 사용자 입력을 수신하고, 사용자 입력에 대응하는 콘텐트 요소를 기초로 제2 콘텐트를 생성할 수 있다. 예를 들어, 전자 장치가 단거리 달리기에 출전한 제1 선수를 선택한 경우, 전자 장치는 생성 형 인공지능 모델을 통해 제1 선수의 외형(예를 들어, 머리 색상, 얼굴 표정, 복장 종류 등)을 변경함으로 써 제2 콘텐트를 생성할 수 있다. 이에 따라, 단거리 달리기 콘텐트가 재생될 때 제1 선수 실제 외형 대신에 변경된 외형인 제2 콘텐트가 적용되어 표시될 수 있다. 전자 장치는 사용자 입력에 기초하여 제2 선수, 제3 선수 등에 대해서도 외형을 변경할 수 있다. 이 경우, 생성형 인공지능 모델이 이용될 수 있다. 또는, 전자 장치는 제1 콘텐트 내 콘텐트 요소를 변경하는 것 외에도, 새로운 콘텐트를 제2 콘텐트로 생 성할 수 있다. 예를 들어, 전자 장치는 생성형 인공지능 모델을 이용하여 가상 캐릭터를 제2 콘텐트 로 생성할 수 있다. 전자 장치는 제1 선수, 제2 선수, 제3 선수가 달리기 경주를 할 때, 가상 캐릭터가 함께 경주하는 것처럼 보이도록 그래픽을 생성할 수 있다. 도 8b는 본 개시의 일 실시예에 따른 전자 장치가 개인화된 콘텐트를 제공하는 예시를 도시한 도면이다. 일 실시예에서, 제1 콘텐트의 장르가 스포츠(축구)인 경우, 전자 장치는 도 8a에서 전술한 것과 같이 스 포츠 장르에 대하여 편집 가능한 기 정의된 콘텐트 요소들을 표시할 수 있다. 스포츠 장르에 대하여 기 정의된 콘텐트 요소들은 예를 들어, 인물, 배경 등일 수 있으나, 이에 한정되는 것은 아니다. 일 실시예에서, 전자 장치는 콘텐트에 관련된 정보 및/또는 사용자 입력에 기초하여 제2 콘텐트를 생성할 수 있다. 예를 들어, 제1 콘텐트가 축구 경기인 경우, 제1 콘텐트와 관련된 정보에는 선수 정보가 포함될 수 있 다. 이 경우, 전자 장치는 제1 콘텐트 내에서 사용자가 선호하는 축구선수인 제1 선수를 식별하거나, 사용자 입력에 기초하여 제1 선수를 식별할 수 있다. 그리고, 전자 장치는 제1 선수 에 그래픽 효과를 부가한 제2 콘텐트를 생성할 수 있다. 예를 들어, 전자 장치는 생성형 인공 지능 모델을 이용하여 제1 선수를 확대하거나, 강조 표시하거나, 유니폼을 변경하는 등의 처리가 적용된, 제2 콘텐트를 생성할 수 있다. 이에 따라, 축구 경기 콘텐트가 재생될 때, 사용자가 선호하는 제1 선수 는 실제 외형 대신에 변경된 외형인 제2 콘텐트가 적용되어 표시될 수 있다. 같은 방식으로, 전자 장 치는 제1 콘텐트 내 존재하는 콘텐트 요소인 제2 선수, 제3 선수 각각에 대응하는 제2 콘텐트 를 생성할 수 있다. 한편, 도 8a 및 도 8b를 설명함에 있어서, 스포츠 장르의 경우 스포츠 선수가 변경 및/또는 생성 가능한 콘텐트 요소임을 예시로 설명하였으나, 이에 한정되는 것은 아니다. 예를 들어, 전자 장치는 배경, 경기장, 관중, 날씨 등과 같은 다른 콘텐트 요소들을 기초로 제2 콘텐트를 생성하고, 생성된 제2 콘텐트를 제1 콘텐트에 결합함으로써, 개인화된 콘텐트를 생성할 수 있다. 도 9는 본 개시의 일 실시예에 따른 전자 장치가 개인화된 콘텐트를 제공하는 예시를 도시한 도면이다. 일 실시예에서, 전자 장치는 제1 콘텐트와 관련된 정보에 기초하여 제2 콘텐트를 생성하기 위한 사용자 인터페이스를 생성할지 여부를 결정할 수 있다. 예를 들어, 전자 장치는 제1 콘텐트의 장르에 기초하여 사용자 인터페이스의 생성 여부를 결정할 수 있다. 일 실시예에서, 제2 콘텐트를 생성하기 위한 사용자 인터페이스를 생성하는 미리 정의되어 있을 수 있다. 예를 들어, 제1 콘텐트의 장르가 \"음악 방송\"인 경우, 사용자 인터페이스의 생성이 필요 없는 것으로 설정되어 있을 수 있다. 이 경우, 전자 장치는 자동으로 제2 콘텐트를 생성할 수 있다. 구체적으로, 제1 콘텐트가 오케 스트라 연주 방송인 경우, 전자 장치는 생성형 인공지능 모델을 이용하여 오케스트라 연주를 시각화한 3D 객체를 제2 콘텐트로 생성할 수 있다. 한편, 제2 콘텐트의 생성은, 도 4a 및 도 4b에서 전술한 방식에 의해 제2 콘텐트 생성 모드가 실행된 상태인 것 을 전제로 한다. 즉, 전자 장치는, 제2 콘텐트 생성 모드가 실행되지 않은 상태에서는 제1 콘텐트만을 재 생하고, 제2 콘텐트 생성 모드가 실행된 상태에서는 제1 콘텐트 및 제2 콘텐트를 포함하는 개인화된 콘텐트를 재생할 수 있다.도 10a는 본 개시의 일 실시예에 따른 전자 장치의 사용자가 사용자 입력을 통해 제2 콘텐트를 생성하는 동작을 설명하기 위한 도면이다. 일 실시예에서, 전자 장치는 제1 콘텐트에 관련된 정보에 기초하여 제1 콘텐트의 장르를 분석하고, 제1 콘텐트의 장르에 따라 제1 콘텐트를 개인화할 수 있도록 하는 직관적인 사용자 인터페이스를 제공할 수 있다. 이 경우, 전자 장치의 사용자는 사용자 인터페이스 내에서 개인화하고자 하는 콘텐트 요소를 선택하고, 선택된 요소를 편집 및/또는 변경함으로써 제2 콘텐트를 생성할 수 있다. 일 실시예에서, 전자 장치는 생성형 인공지능 모델을 이용하여 제2 콘텐트를 생성할 수 있다. 예를 들어, 사용자가 콘텐트 요소인 인물 A를 선택하는 경우, 전자 장치는 인물 A의 외형, 음성 등을 변 형할 수 있는 옵션을 사용자에게 제공할 수 있다. 예를 들어, 사용자가 옵션 중에서 외형을 선택하 는 경우, 얼굴, 머리 색상, 눈 모양, 입 꼬리, 복장 색상, 복장 종류 등이 변경된 제2 콘텐트가 생성될 수 있다. 또는, 사용자가 옵션 중에서 음성을 선택하는 경우, 목소리, 톤, 성별, 언어 등이 변경된 제2 콘텐 트가 생성될 수 있다. 일 실시예에서, 전자 장치는 생성형 인공지능 모델에 인물 A의 외형, 음성, 제1 콘텐트의 장르 중 적어도 하나를 입력 데이터로 제공할 수 있다. 생성형 인공지능 모델은 입력 데이터에 기초하여, 입력 데이터와 유사한 특성을 갖거나 새로운 특성을 갖는 데이터를 생성하여 출력할 수 있다. 일 실시예에서, 전자 장치는 제1 콘텐트에 적용 가능한 복수의 스타일 이미지들을 표시할 수 있다. 전자 장치는 복수의 스타일 이미지들 중에서 어느 하나를 선택하는 사용자 입력을 수신할 수 있다. 이 경우, 선택된 스타일 이미지가 제1 콘텐트에 적용됨으로써 제2 콘텐트가 생성될 수 있다. 전자 장치는 제1 콘텐트에 사용자가 선택한 스타일을 적용하기 위해, 생성형 인공지능 모델을 이용하여 스타일을 이전 (transfer)시킬 수 있다. 도 10b는 본 개시의 일 실시예에 따른 전자 장치가 사용자 입력에 의해 제2 콘텐트를 생성한 결과를 도시한 도 면이다. 일 실시예에서, 전자 장치는 생성형 인공지능 모델을 이용하여 생성된 제2 콘텐트의 결과를 복수개 표시 할 수 있다. 예를 들어, 전자 장치는 제1 콘텐트 내의 제1 사용자의 외형을 변경하여 생성된 제2 콘텐트들을 표시할 수 있다. 전자 장치의 사용자가 제2 콘텐트들 하나를 선택하면, 선택된 제2 콘텐트의 얼굴 이미지가 제1 콘텐트에 적용됨으로써 개인화된 콘텐트가 생성될 수 있다. 일 실시예에 따른 전자 장치는 복수 타입의 제2 콘텐트를 생성할 수 있다. 예를 들어, 개인화된 콘텐트에 는 이미지 타입의 제2 콘텐트인 얼굴 이미지가 포함될 수 있고, 제1 사용자의 음성을 텍스트로 변 환한 텍스트 타입의 제2 콘텐트인 말풍선이 표시될 수 있다. 일 실시예에서, 전자 장치는 사용자가 제2 콘텐트를 생성할 수 있는 다양한 옵션을 제공할 수 있다. 예를 들어, 전자 장치는 제1 콘텐트 내 인물의 얼굴을 변경하거나, 제1 콘탠트 내 인물의 헤어 색상, 복장 등 을 변경할 수 있고, 제1 콘텐트 내 인물의 목소리를 특정 목소리(예를 들어, 격양된 목소리, 차분한 목소리 등)으로 변경하거나, 목소리를 시각화하여 자막으로 표시하거나, 목소리를 음소거할 수 있다. 도 10c는 본 개시의 일 실시예에 따른 전자 장치의 사용자가 다른 전자 장치를 이용하여 제2 콘텐트를 편집하는 동작을 설명하기 위한 도면이다. 일 실시예에서, 전자 장치는 제2 콘텐트 생성 기능을 실행할 때, 전자 장치의 사용자가 다른 전자 장치(예를 들어, 스마트폰)를 이용하도록 할 수 있다. 도 4b에서 전술한 것과 같이, 일 실시예에 따른 전자 장치는 제1 콘텐트가 재생되면, 메타데이터 또는 장 면 분석을 수행하고, 제1 콘텐트에 제2 콘텐트를 부가하여 표시할 수 있다. 이 경우, 제2 콘텐트를 변경 하기 위한 세분화된 작업을 수행하기 위해, 전자 장치는 사용자의 다른 전자 장치를 식별할 수 있다. 예 를 들어, 전자 장치는 전자 장치와 같은 네트워크(예를 들어, 와이파이)에 연결된 다른 전자 장치 를 식별할 수 있다. 또는, 전자 장치는 서버를 통해 전자 장치에 로그인 된 사용자 계정을 이용하 는 또다른 전자 장치를 식별할 수도 있다. 전자 장치의 사용자는, 다른 전자 장치(예를 들어, 스마트폰)을 이용하여 제2 콘텐트를 편집할 수 있다. 예를 들어, 사용자는 다른 전자 장치를 이용하여 제2 콘텐트의 가상 객체가 입고 있는 옷을 변경하 거나, 성별을 변경할 수 있다. 또는 사용자는 다른 전자 장치를 이용하여 제2 콘텐트를 다른 가상 객체로변경하거나, 새로운 가상 객체를 추가할 수도 있다. 일 실시예에서, 전자 장치는 사용자의 다른 전자 장치를 식별하고 사용자가 다른 전자 장치 에서 제2 콘텐트를 편집 및/또는 생성하도록 하는 인터페이스를 제공할 수 있다. 구체적으로, 전자 장치 가 TV이고, 사용자의 다른 전자 장치가 스마트폰일 수 있다. 스마트폰을 통한 인터랙션이 보다 편리하므로, 사 용자는 스마트폰을 이용하여 제2 콘텐트를 편집 및/또는 생성하는 작업을 보다 디테일하고 수월하게 수행할 수 있다. 도 11a는 본 개시의 일 실시예에 따른 전자 장치가 제2 콘텐트 정보를 사용자 정보와 연계하여 저장하는 동작을 설명하기 위한 도면이다. 일 실시예에서, 전자 장치는 사용자가 생성한 제2 콘텐트에 관한 정보를 사용자 정보와 연계하여 서버에 저장할 수 있다. 사용자 정보와 연계되어 저장된 제2 콘텐트에 관한 정보는, 전자 장치의 사용자가 장래 의 다른 시점에 제2 콘텐트를 생성하고자 할 때 이용될 수 있다. 예를 들어, 채널 1에서 제1 콘텐트가 재생되고, 사용자가 제1 콘텐트에 대하여 제2 콘텐트를 생성한 이력이 있는 경우, 제2 콘텐트에 관한 정보가 서 버에 저장될 수 있다. 시간이 경과한 후에, 채널 1에서 제1 콘텐트가 다시 재생(재방송)되고, 사용자가 동일한 것이 식별되면, 전자 장치는 서버로부터 실시간으로 제2 콘텐트에 관한 정보를 수신하고 제2 콘텐트를 적 용하여 개인화된 콘텐트를 생성할 수 있다. 또한, 전자 장치는 서버로부터 수신된 제2 콘텐트에 관한 정 보에 기초하여 제2 콘텐트를 제공하면서, 추가적으로 제2 콘텐트를 생성 및 편집하도록 하는 제2 콘텐트 생성 기능을 사용자에게 제공할 수도 있다. 도 11b는 본 개시의 일 실시예에 따른 전자 장치가 제2 콘텐트 정보를 사용자 정보와 연계하여 저장하는 동작을 설명하기 위한 도면이다. 일 실시예에서, 전자 장치는 사용자가 생성한 제2 콘텐트에 관한 정보를 사용자 정보와 연계하여 서버에 저장할 수 있다. 사용자 정보와 연계되어 저장된 제2 콘텐트에 관한 정보는, 전자 장치의 사용자가 다른 채널에서 제2 콘텐트를 생성하고자 할 때 이용될 수 있다. 예를 들어, 채널 1에서 제1 콘텐트가 재생되고, 사용 자가 제1 콘텐트에 대하여 제2 콘텐트를 생성한 이력이 있는 경우, 제2 콘텐트에 관한 정보가 서버에 저장될 수 있다. 일 실시예에서, 전자 장치의 방송 채널이 채널 1에서 채널 2로 변경되고, 채널 2에서 표시되는 콘텐트 내 에 채널 1에서 재생된 제1 콘텐트와 동일한 인물이 등장할 수 있다. 이 경우, 전자 장치는 서버로부터 실 시간으로 제2 콘텐트에 관한 정보를 수신하고, 제2 콘텐트를 적용하여 개인화된 콘텐트를 생성할 수 있다. 또한, 전자 장치는 서버로부터 수신된 제2 콘텐트에 관한 정보에 기초하여 제2 콘텐트를 제공하면서, 추 가적으로 제2 콘텐트를 생성 및 편집하도록 하는 제2 콘텐트 생성 기능을 사용자에게 제공할 수도 있다. 도 12는 본 개시의 일 실시예에 따른 전자 장치의 구성을 도시한 블록도이다. 일 실시예에서, 전자 장치는 통신 인터페이스, 디스플레이, 메모리 및 프로세서(240 0)를 포함할 수 있다. 통신 인터페이스는 프로세서의 제어에 의해 다른 전자 장치들과 데이터 통신을 수행할 수 있다. 통신 인터페이스는 예를 들어, 유선 랜, 무선 랜(Wireless LAN), 와이파이(Wi-Fi), 블루투스 (Bluetooth), 지그비(ZigBee), WFD(Wi-Fi Direct), 적외선 통신(IrDA, infrared Data Association), BLE (Bluetooth Low Energy), NFC(Near Field Communication), 와이브로(Wireless Broadband Internet, Wibro), 와이맥스(World Interoperability for Microwave Access, WiMAX), SWAP(Shared Wireless Access Protocol), 와이기그(Wireless Gigabit Alliances, WiGig) 및 RF 통신을 포함하는 데이터 통신 방식 중 적어도 하나를 이 용하여, 전자 장치와 다른 디바이스들 간의 데이터 통신을 수행할 수 있는, 통신 회로를 포함할 수 있다. 일 실시예에 따른 통신 인터페이스는 제2 콘텐트를 생성하기 위한 데이터를 외부 디바이스와 송신할 수 있다. 예를 들어, 통신 인터페이스는 제1 콘텐트를 수신하거나, 생성형 인공지능 모델을 포함하는 복수의 인공지능 모델들 및 인공지능 모델을 훈련시키기 위한 훈련 데이터를 수신할 수 있다. 디스플레이는 프로세서의 제어에 의해 전자 장치의 화면에 영상 신호를 출력할 수 있다. 디 스플레이는 프로세서의 제어에 의해 제1 콘텐트, 제2 콘텐트 및 개인화된 콘텐트를 표시할 수 있다.메모리는 프로세서가 판독할 수 있는 명령어들, 데이터 구조, 및 프로그램 코드(program code)가 저장될 수 있다. 개시된 실시예들에서, 프로세서가 수행하는 동작들은 메모리에 저장된 프로그램의 명령어들 또는 코드들을 실행함으로써 구현될 수 있다. 메모리는 플래시 메모리 타입(flash memory type), 하드디스크 타입(hard disk type), 멀티미디어 카드 마이크로 타입(multimedia card micro type), 카드 타입의 메모리(예를 들어 SD 또는 XD 메모리 등)를 포함할 수 있으며, 롬(ROM, Read-Only Memory), EEPROM(Electrically Erasable Programmable Read-Only Memory), PROM(Programmable Read-Only Memory), 자기 메모리, 자기 디스크, 광디스크 중 적어도 하나를 포함하는 비 휘 발성 메모리 및 램(RAM, Random Access Memory) 또는 SRAM(Static Random Access Memory)과 같은 휘발성 메모 리를 포함할 수 있다. 일 실시예에 따른 메모리는 전자 장치가 제2 콘텐트를 생성하기 위해 동작하도록 하는 하나 이상의 인스트럭션 및/또는 프로그램을 저장할 수 있다. 예를 들어, 메모리에는 콘텐트 분석 모듈, 사용자 인터페이스 생성 모듈 및 콘텐트 생성 모듈이 저장될 수 있다. 프로세서는 전자 장치의 전반적인 동작들을 제어할 수 있다. 예를 들어, 프로세서는 메모리 에 저장된 프로그램의 하나 이상의 명령어들(instructions)을 실행함으로써, 전자 장치가 제2 콘텐 트를 생성하기 위한 전반적인 동작들을 제어할 수 있다. 프로세서는 예를 들어, 중앙 처리 장치(Central Processing Unit), 마이크로 프로세서(microprocessor), 그래픽 처리 장치(Graphic Processing Unit), ASICs(Application Specific Integrated Circuits), DSPs(Digital Signal Processors), DSPDs(Digital Signal Processing Devices), PLDs(Programmable Logic Devices), FPGAs(Field Programmable Gate Arrays), 애플리케이션 프로세서(Application Processor), 신경망 처리 장치(Neural Processing Unit) 또는 인공지능 모델의 처리에 특화된 하드웨어 구조로 설계된 인공지능 전 용 프로세서 중 적어도 하나로 구성될 수 있으나, 이에 제한되는 것은 아니다. 일 실시예에서, 프로세서는 콘텐트 분석 모듈을 실행하여, 제1 콘텐트를 분석할 수 있다. 프로세서 는 하나 이상의 인공지능 모델들을 이용하여 제1 콘텐트의 장면들을 분석하고, 제1 콘텐트와 관련된 정보 (예를 들어, 제1 콘텐트의 장르)를 획득할 수 있다. 콘텐트 분석 모듈의 동작들과 관련된 설명은 이전의 도면들에서 전술하였으므로, 반복되는 설명은 생략한다. 일 실시예에서, 프로세서는 사용자 인터페이스 생성 모듈을 실행하여, 제2 콘텐트를 생성하기 위한 사용자 인터페이스를 생성할 수 있다. 사용자 인터페이스는 제1 콘텐트에서 편집 가능한 콘텐트 요소들 및 생성 가능한 콘텐트 요소들 중 적어도 하나를 포함할 수 있다. 전자 장치의 사용자는 사용자 인터페이스 내에 서 개인화하고자 하는 콘텐트 요소를 선택하고, 선택된 요소를 편집 및/또는 변경함으로써 제2 콘텐트를 생성할 수 있다. 사용자는 전자 장치를 이용하여 콘텐트를 편집할 수 있다. 전자 장치는 콘텐트를 편집하 기 위한 사용자 인터페이스를 표시하고, 사용자로부터 미디어 콘텐트를 편집하는 사용자 입력을 수신할 수 있다. 사용자 인터페이스 생성 모듈의 동작들과 관련된 설명은 이전의 도면들에서 전술하였으므로, 반복 되는 설명은 생략한다. 일 실시예에서, 프로세서는 콘텐트 생성 모듈을 실행하여, 제2 콘텐트를 생성할 수 있다. 프로세서 는 제1 콘텐트의 특징(예를 들어, 제1 콘텐트 내 콘텐트 요소 등)를 생성형 인공지능 모델에 입력으로 제 공하여, 콘텐트 요소의 특성이 변경된 제2 콘텐트를 생성할 수 있다. 제2 콘텐트는 제1 콘텐트에 결합되어 개인 화된 콘텐트로써 사용자에게 제공될 수 있다. 제2 콘텐트는, 이미지, 오디오, 및 텍스트 중 적어도 하나를 포함"}
{"patent_id": "10-2023-0059325", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 9, "content": "할 수 있다. 일 실시예에서, 제2 콘텐트는 제1 콘텐트의 요약일 수 있다. 사용자는 전자 장치를 통해 제1"}
{"patent_id": "10-2023-0059325", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 10, "content": "콘텐트의 요약을 제공받을 수 있다. 콘텐트 생성 모듈의 동작들과 관련된 설명은 이전의 도면들에서 전술 하였으므로, 반복되는 설명은 생략한다. 본 개시는, 생성형 인공지능을 활용하여 콘텐트를 시청하는 사용자에게 개인화된 콘텐트를 생성할 수 있도록 하 는 사용자 인터페이스를 제공하고, 생성된 개인화된 콘텐트를 사용자에게 제공한다. 본 개시에서 이루고자 하는 기술적 과제는, 이상에서 언급한 것으로 제한되지 않으며, 언급되지 않은 또 다른 기술적 과제들은 본 명세서의"}
{"patent_id": "10-2023-0059325", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 11, "content": "기재로부터 본 발명이 속하는 기술분야에서 통상의 지식을 가진 자에게 명확하게 이해될 수 있을 것이다. 본 개시의 일 측면에 따르면, 전자 장치가 콘텐트를 제공하는 방법이 제공될 수 있다. 상기 방법은, 재생 중인 제1 콘텐트와 관련된 정보를 획득하는 단계를 포함할 수 있다. 상기 방법은, 상기 제1 콘텐트와 관련된 정보에 기초하여, 상기 제1 콘텐트에서 편집 가능한 콘텐트 요소들 및 생성 가능한 콘텐트 요소들 중 적어도 하나를 포함하는 사용자 인터페이스를 생성하는 단계를 포함할 수 있다. 상기 방법은, 상기 사용자 인터페이스를 통해 콘텐트 요소를 선택하는 사용자 입력을 수신하는 단계를 포함할 수 있다. 상기 방법은, 상기 사용자 입력에 대응하는 콘텐트 요소를 기초로 상기 제1 콘텐트에 대응하는 제2 콘텐트를 생 성하는 단계를 포함할 수 있다. 상기 방법은, 상기 제1 콘텐트 및 상기 제2 콘텐트를 포함하는 개인화된 콘텐트를 생성하는 단계를 포함할 수 있다. 상기 제1 콘텐트와 관련된 정보는, 타이틀, 제작자, 재생 시간, 장르, 출연자 정보, 플랫폼 정보 및 채널 정보 중 적어도 하나를 포함할 수 있다. 상기 방법은, 상기 제1 콘텐트에 포함되는 비디오 프레임을 이용하여 장면 콘텍스트 데이터를 생성하는 단계를 포함할 수 있다. 상기 방법은, 상기 제1 콘텐트와 관련된 정보 및 상기 장면 콘텍스트 데이터 중 적어도 하나에 기초하여 상기 제1 콘텐트의 장르를 식별하는 단계를 포함할 수 있다. 상기 사용자 인터페이스를 생성하는 단계는, 상기 제1 콘텐트의 장르에 기초하여 상기 사용자 인터페이스를 생 성하는 것일 수 있다. 상기 사용자 인터페이스를 생성하는 단계는, 상기 제1 콘텐트의 장르에 대응하는 기 정의된 콘텐트 요소가 포함 되도록 상기 사용자 인터페이스를 생성하는 것일 수 있다. 상기 제2 콘텐트를 생성하는 단계는, 상기 사용자 입력에 대응하는 콘텐트 요소를 생성형 인공지능 모델에 입력 하여 상기 제2 콘텐트를 획득하는 단계를 포함할 수 있다. 상기 생성형 인공지능 모델은, 이미지를 생성하는 제1 생성형 인공지능 모델, 오디오를 생성하는 제2 생성형 인 공지능 모델 및 텍스트를 생성하는 제3 생성형 인공지능 모델 중 적어도 하나를 포함할 수 있다. 상기 제2 콘텐트는, 이미지, 오디오, 및 텍스트 중 적어도 하나를 포함하는 것일 수 있다. 상기 방법은, 상기 제2 콘텐트를 사용자 정보와 연계하여 저장하는 단계를 포함할 수 있다."}
{"patent_id": "10-2023-0059325", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 12, "content": "상기 방법은, 상기 제1 콘텐트의 재생이 종료되는 것에 기초하여, 상기 제1 콘텐트의 요약을 사용자에게 제공하 는 단계를 포함할 수 있다."}
{"patent_id": "10-2023-0059325", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 13, "content": "상기 제1 콘텐트의 요약을 사용자에게 제공하는 단계는, 상기 전자 장치에서 재생 중인 상기 제1 콘텐트가 다른"}
{"patent_id": "10-2023-0059325", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 14, "content": "콘텐트로 변경되는 경우, 백그라운드 프로세스에서 상기 제1 콘텐트의 요약을 생성하는 단계를 포함할 수 있다. 본 개시의 일 측면에 따르면, 콘텐트를 제공하는 전자 장치가 제공될 수 있다. 상기 전자 장치는, 통신 인터페이스; 디스플레이; 하나 이상의 인스트럭션들을 저장하는 메모리; 및 상기 하나 이상의 인스트럭션들을 실행하는 적어도 하나의 프로세서를 포함할 수 있다. 상기 적어도 하나의 프로세서는, 상기 하나 이상의 인스트럭션들을 실행함으로써, 재생 중인 제1 콘텐트와 관련 된 정보를 획득할 수 있다. 상기 적어도 하나의 프로세서는, 상기 하나 이상의 인스트럭션들을 실행함으로써, 상기 제1 콘텐트와 관련된 정 보에 기초하여, 상기 제1 콘텐트에서 편집 가능한 콘텐트 요소들 및 생성 가능한 콘텐트 요소들 중 적어도 하나 를 포함하는 사용자 인터페이스를 생성할 수 있다. 상기 적어도 하나의 프로세서는, 상기 하나 이상의 인스트럭션들을 실행함으로써, 상기 사용자 인터페이스를 통 해 콘텐트 요소를 선택하는 사용자 입력을 수신할 수 있다. 상기 적어도 하나의 프로세서는, 상기 하나 이상의 인스트럭션들을 실행함으로써, 상기 사용자 입력에 대응하는 콘텐트 요소를 기초로 상기 제1 콘텐트에 대응하는 제2 콘텐트를 생성할 수 있다. 상기 적어도 하나의 프로세서는, 상기 하나 이상의 인스트럭션들을 실행함으로써, 상기 제1 콘텐트 및 상기 제2 콘텐트를 포함하는 개인화된 콘텐트를 상기 디스플레이의 화면에 표시할 수 있다.상기 제1 콘텐트와 관련된 정보는, 타이틀, 제작자, 재생 시간, 장르, 출연자 정보, 플랫폼 정보 및 채널 정보 중 적어도 하나를 포함하는 것일 수 있다. 상기 적어도 하나의 프로세서는, 상기 하나 이상의 인스트럭션들을 실행함으로써, 상기 제1 콘텐트에 포함되는 비디오 프레임을 이용하여 장면 콘텍스트 데이터를 생성할 수 있다. 상기 적어도 하나의 프로세서는, 상기 하나 이상의 인스트럭션들을 실행함으로써, 상기 제1 콘텐트와 관련된 정 보 및 상기 장면 콘텍스트 데이터 중 적어도 하나에 기초하여 상기 제1 콘텐트의 장르를 식별할 수 있다. 상기 적어도 하나의 프로세서는, 상기 하나 이상의 인스트럭션들을 실행함으로써, 상기 제1 콘텐트의 장르에 기 초하여 상기 사용자 인터페이스를 생성할 수 있다. 상기 적어도 하나의 프로세서는, 상기 하나 이상의 인스트럭션들을 실행함으로써, 상기 제1 콘텐트의 장르에 대 응하는 기 정의된 콘텐트 요소가 포함되도록 상기 사용자 인터페이스를 생성할 수 있다. 상기 적어도 하나의 프로세서는, 상기 하나 이상의 인스트럭션들을 실행함으로써, 상기 사용자 입력에 대응하는 콘텐트 요소를 생성형 인공지능 모델에 입력하여 상기 제2 콘텐트를 획득할 수 있다. 상기 생성형 인공지능 모델은, 이미지를 생성하는 제1 생성형 인공지능 모델, 오디오를 생성하는 제2 생성형 인 공지능 모델 및 텍스트를 생성하는 제3 생성형 인공지능 모델 중 적어도 하나를 포함하는 것일 수 있다. 상기 적어도 하나의 프로세서는, 상기 하나 이상의 인스트럭션들을 실행함으로써, 상기 제2 콘텐트를 사용자 정 보와 연계하여 저장할 수 있다. 상기 적어도 하나의 프로세서는, 상기 하나 이상의 인스트럭션들을 실행함으로써, 상기 제1 콘텐트의 재생이 종"}
{"patent_id": "10-2023-0059325", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 15, "content": "료되는 것에 기초하여, 상기 제1 콘텐트의 요약을 사용자에게 제공할 수 있다. 상기 적어도 하나의 프로세서는, 상기 하나 이상의 인스트럭션들을 실행함으로써, 상기 전자 장치에서 재생 중"}
{"patent_id": "10-2023-0059325", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 16, "content": "인 상기 제1 콘텐트가 다른 콘텐트로 변경되는 경우, 백그라운드 프로세스에서 상기 제1 콘텐트의 요약을 생성 할 수 있다. 한편, 본 개시의 실시예들은 컴퓨터에 의해 실행되는 프로그램 모듈과 같은 컴퓨터에 의해 실행 가능한 명령어 를 포함하는 기록 매체의 형태로도 구현될 수 있다. 컴퓨터 판독 가능 매체는 컴퓨터에 의해 액세스 될 수 있는 임의의 가용 매체일 수 있고, 휘발성 및 비휘발성 매체, 분리형 및 비분리형 매체를 모두 포함한다. 또한, 컴퓨 터 판독 가능 매체는 컴퓨터 저장 매체 및 통신 매체를 포함할 수 있다. 컴퓨터 저장 매체는 컴퓨터 판독 가능 명령어, 데이터 구조, 프로그램 모듈 또는 기타 데이터와 같은 정보의 저장을 위한 임의의 방법 또는 기술로 구 현된 휘발성 및 비휘발성, 분리형 및 비분리형 매체를 모두 포함한다. 통신 매체는 전형적으로 컴퓨터 판독 가 능 명령어, 데이터 구조, 또는 프로그램 모듈과 같은 변조된 데이터 신호의 기타 데이터를 포함할 수 있다. 또한, 컴퓨터에 의해 읽을 수 있는 저장매체는, 비일시적(non-transitory) 저장매체의 형태로 제공될 수 있다. 여기서, '비일시적 저장매체'는 실재(tangible)하는 장치이고, 신호(signal)(예: 전자기파)를 포함하지 않는다 는 것을 의미할 뿐이며, 이 용어는 데이터가 저장매체에 반영구적으로 저장되는 경우와 임시적으로 저장되는 경 우를 구분하지 않는다. 예로, '비일시적 저장매체'는 데이터가 임시적으로 저장되는 버퍼를 포함할 수 있다. 일 실시예에 따르면, 본 문서에 개시된 다양한 실시예들에 따른 방법은 컴퓨터 프로그램 제품(computer program product)에 포함되어 제공될 수 있다. 컴퓨터 프로그램 제품은 상품으로서 판매자 및 구매자 간에 거래될 수 있 다. 컴퓨터 프로그램 제품은 기기로 읽을 수 있는 저장 매체(예: compact disc read only memory (CD-ROM))의 형태로 배포되거나, 또는 어플리케이션 스토어를 통해 또는 두개의 사용자 장치들(예: 스마트폰들) 간에 직접, 온라인으로 배포(예: 다운로드 또는 업로드)될 수 있다. 온라인 배포의 경우에, 컴퓨터 프로그램 제품(예: 다운 로더블 앱(downloadable app))의 적어도 일부는 제조사의 서버, 어플리케이션 스토어의 서버, 또는 중계 서버의 메모리와 같은 기기로 읽을 수 있는 저장 매체에 적어도 일시 저장되거나, 임시적으로 생성될 수 있다."}
{"patent_id": "10-2023-0059325", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 17, "content": "전술한 본 개시의 설명은 예시를 위한 것이며, 본 개시가 속하는 기술분야의 통상의 지식을 가진 자는 본 개시 의 기술적 사상이나 필수적인 특징을 변경하지 않고서 다른 구체적인 형태로 쉽게 변형이 가능하다는 것을 이해 할 수 있을 것이다. 그러므로 이상에서 기술한 실시예들은 모든 면에서 예시적인 것이며 한정적이 아닌 것으로 이해해야만 한다. 예를 들어, 단일형으로 설명되어 있는 각 구성 요소는 분산되어 실시될 수도 있으며, 마찬가 지로 분산된 것으로 설명되어 있는 구성 요소들도 결합된 형태로 실시될 수 있다. 본 개시의 범위는 상기 상세한 설명보다는 후술하는 특허청구범위에 의하여 나타내어지며, 특허청구범위의 의미 및 범위 그리고 그 균등 개념으로부터 도출되는 모든 변경 또는 변형된 형태가 본 개시의 범위에 포함되는 것으 로 해석되어야 한다."}
{"patent_id": "10-2023-0059325", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 개시의 일 실시예에 따른 전자 장치가 콘텐트 서비스를 제공하는 것을 개략적으로 도시한 도면이다. 도 2는 본 개시의 일 실시예에 따른 전자 장치가 콘텐트를 생성하는 동작들을 도시한 흐름도이다. 도 3은 본 개시의 일 실시예에 따른 전자 장치의 전반적인 동작을 도시한 도면이다. 도 4a는 본 개시의 일 실시예에 따른 전자 장치에서 제2 콘텐트 생성 모드를 실행하는 동작을 설명하기 위한 도 면이다. 도 4b는 본 개시의 일 실시예에 따른 전자 장치에서 제2 콘텐트 생성 모드를 실행하는 동작을 설명하기 위한 도 면이다. 도 5는 본 개시의 일 실시예에 따른 전자 장치가 사용자 인터페이스를 생성할 때 이용하는 기 정의된 설정을 설 명하기 위한 도면이다. 도 6은 본 개시의 일 실시예에 따른 전자 장치가 제2 콘텐트를 생성하는 예를 설명하기 위한 도면이다. 도 7a는 본 개시의 일 실시예에 따른 전자 장치가 생성하는, 제2 콘텐트를 생성하기 위한 사용자 인터페이스를 설명하기 위한 도면이다. 도 7b는 본 개시의 일 실시예에 따른 전자 장치가 백그라운드 프로세스에서 제2 콘텐트를 생성하는 동작을 설명 하기 위한 도면이다. 도 8a는 본 개시의 일 실시예에 따른 전자 장치가 개인화된 콘텐트를 제공하는 예시를 도시한 도면이다. 도 8b는 본 개시의 일 실시예에 따른 전자 장치가 개인화된 콘텐트를 제공하는 예시를 도시한 도면이다. 도 9는 본 개시의 일 실시예에 따른 전자 장치가 개인화된 콘텐트를 제공하는 예시를 도시한 도면이다. 도 10a는 본 개시의 일 실시예에 따른 전자 장치의 사용자가 사용자 입력을 통해 제2 콘텐트를 생성하는 동작을 설명하기 위한 도면이다. 도 10b는 본 개시의 일 실시예에 따른 전자 장치가 사용자 입력에 의해 제2 콘텐트를 생성한 결과를 도시한 도 면이다. 도 10c는 본 개시의 일 실시예에 따른 전자 장치의 사용자가 다른 전자 장치를 이용하여 제2 콘텐트를 편집하는 동작을 설명하기 위한 도면이다. 도 11a는 본 개시의 일 실시예에 따른 전자 장치가 제2 콘텐트 정보를 사용자 정보와 연계하여 저장하는 동작을 설명하기 위한 도면이다. 도 11b는 본 개시의 일 실시예에 따른 전자 장치가 제2 콘텐트 정보를 사용자 정보와 연계하여 저장하는 동작을설명하기 위한 도면이다. 도 12는 본 개시의 일 실시예에 따른 전자 장치의 구성을 도시한 블록도이다."}
