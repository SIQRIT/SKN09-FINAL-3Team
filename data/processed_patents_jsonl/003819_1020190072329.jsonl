{"patent_id": "10-2019-0072329", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2020-0144363", "출원번호": "10-2019-0072329", "발명의 명칭": "로봇 및 그의 구동 방법", "출원인": "엘지전자 주식회사", "발명자": "김정식"}}
{"patent_id": "10-2019-0072329", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "일정 공간 내 배치되는 로봇으로서,이동 모듈;로봇 관제 시스템과 통신하는 통신부;하나 이상의 센싱부;사용자 입력 또는 영상 신호 입력을 위한 입력부;디스플레이; 및상기 입력부를 통해 목적지 정보가 입력되는 경우, 영상 정보, 상기 공간의 공간 맵 정보 및 감지된 장애물 영역 정보 중 적어도 하나에 기초하여 이동 경로를 탐색하는 제어 모듈을 포함하며,상기 제어 모듈은,상기 로봇의 이동 가능 영역 정보를 상기 로봇 관제 시스템으로부터 수신하는 경우, 수신된 이동 가능 영역 정보에 기초하여 상기 이동 경로를 갱신하는, 로봇."}
{"patent_id": "10-2019-0072329", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 이동 가능 영역 정보는,상기 공간의 상부에 배치된 하나 이상의 카메라가 촬영한 영상에 기초하여 결정되는, 로봇."}
{"patent_id": "10-2019-0072329", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 입력부는 하나 이상의 카메라를 포함하며,상기 제어 모듈은,상기 이동 경로 상에서 상기 카메라에 의해 촬영된 영상 정보를 상기 디스플레이에 표시하는, 로봇."}
{"patent_id": "10-2019-0072329", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,상기 디스플레이는,상기 통신부를 통해 수신된 상기 로봇 및 상기 로봇의 인접 영역을 촬영한 촬영 영상을 표시하는, 로봇."}
{"patent_id": "10-2019-0072329", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서,상기 디스플레이는 복수의 영역으로 가상적으로 분할되고,상기 복수의 영역은,상기 로봇의 이동 경로를 나타내는 영상이 표시되는 제1 영역, 상기 입력부를 통해 입력된 영상이 표시되는 제2영역, 상기 통신부를 통해 수신된 상기 로봇 및 상기 로봇의 인접 영역을 촬영한 촬영 영상이 표시되는 제3 영역으로 이루어지는, 로봇.공개특허 10-2020-0144363-3-청구항 6 제1항에 있어서,상기 제어 모듈은,동일 방향으로 이동하는 동적 장애물을 인식하는 경우, 인식된 동적 장애물의 이동 속도에 맞추어 상기 로봇이이동하도록 상기 이동 모듈을 제어하는, 로봇."}
{"patent_id": "10-2019-0072329", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6항에 있어서,상기 제어 모듈은,상기 로봇이 상기 동적 장애물과 소정 거리 내로 인접하거나 충돌하는 경우 특정 대응 모션을 수행하도록 상기이동 모듈을 제어하는, 로봇."}
{"patent_id": "10-2019-0072329", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서,상기 특정 대응 모션은 상기 로봇이 감속하는 모션, 대기하는 모션 및 외부의 조작에 따라 상기 로봇이 이동하는 모션 중 적어도 하나를 포함하는, 로봇."}
{"patent_id": "10-2019-0072329", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "일정 공간 내 배치되는 로봇의 구동 방법으로서,목적지 정보가 입력되는 경우, 영상 정보, 공간 맵 정보 및 장애물 영역 정보 중 적어도 하나에 기초하여 이동경로를 탐색하는 단계;장애물 영역 중에 상기 로봇의 이동 가능 영역 정보를 로봇 관제 시스템으로부터 수신하는 단계; 및수신된 이동 가능 영역 정보에 기초하여 상기 이동 경로를 갱신하는 단계를 포함하는, 로봇의 구동 방법."}
{"patent_id": "10-2019-0072329", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9항에 있어서,상기 이동 가능 영역 정보는, 상기 공간의 상부에 배치된 하나 이상의 카메라가 촬영한 영상에 기초하여 결정되는, 로봇의 구동 방법."}
{"patent_id": "10-2019-0072329", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제9항에 있어서,동일 방향으로 이동하는 동적 장애물이 인식되는 경우, 인식된 동적 장애물의 이동 속도에 맞추어 상기 로봇을이동시키는 단계를 더 포함하는, 로봇의 구동 방법."}
{"patent_id": "10-2019-0072329", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항에 있어서,상기 로봇이 상기 동적 장애물과 소정 거리 내로 인접하거나 충돌하는 경우, 특정 대응 모션을 수행하는 단계를더 포함하는, 로봇의 구동 방법."}
{"patent_id": "10-2019-0072329", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제12항에 있어서,상기 특정 대응 모션은 상기 로봇이 감속하는 모션, 대기하는 모션 및 외부의 조작에 따라 상기 로봇이 이동하는 모션 중 적어도 하나를 포함하는, 로봇의 구동 방법.공개특허 10-2020-0144363-4-청구항 14 일정 공간 내 배치되는 로봇을 제어하는 로봇 관제 시스템의 구동 방법에 있어서,이동 경로의 정보 및 장애물 영역의 정보를 상기 로봇으로부터 수신하는 단계;상기 공간 상부에 배치된 하나 이상의 카메라를 통해 촬영된 영상에 기초하여 상기 장애물 영역 중에 상기 로봇의 이동 가능 영역을 결정하는 단계; 및결정된 이동 가능 영역을 포함하는 이동 경로를 상기 로봇으로 전송하는 단계를 포함하는, 로봇 관제 시스템의구동 방법."}
{"patent_id": "10-2019-0072329", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제14항에 있어서,상기 이동 경로를 이동하는 상기 로봇 및 상기 로봇의 인접 영역이 상기 공간의 상부에 배치된 하나 이상의 카메라를 통해 촬영되면, 촬영된 영상을 상기 로봇으로 전송하는 단계를 더 포함하는, 로봇 관제 시스템의 구동방법."}
{"patent_id": "10-2019-0072329", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "일정 공간 내 배치된 로봇이 개시된다. 본 로봇은 로봇 관제 시스템과 통신하는 통신부, 하나 이상의 센싱부, 사 용자 입력 또는 영상 신호 입력을 위한 입력부, 디스플레이 및 입력부를 통해 목적지 정보가 입력되는 경우, 영 상 정보, 공간 맵 정보 및 감지된 장애물 영역 정보 중 적어도 하나에 기초하여 이동 경로를 탐색하는 제어 모듈 을 포함한다. 이에 따라, 인공 지능 및 5G 통신이 로봇을 통해 수행될 수 있으며, 사용자 편의가 제고될 수 있으 며, 로봇의 이동 효율이 향상될 수 있다."}
{"patent_id": "10-2019-0072329", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 일정 공간 내 배치되어 장애물 회피 기능을 수행하는 로봇 및 그의 구동 방법에 관한 것이다."}
{"patent_id": "10-2019-0072329", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "로봇은 산업용으로 개발되어 공장 자동화의 일 부분을 담당하여 왔다. 최근에는 로봇을 응용한 분야가 더욱 확 대되어, 의료용 로봇, 안내 로봇, 우주 항공 로봇 등이 개발되고, 일반 가정에서 사용할 수 있는 가정용 로봇도 만들어지고 있다. 종래 기술 1(KR20190004959A)에 개시된 안내 로봇은 프로세서와 표시부가 구비된 상부모듈, 상기 상부모듈과 분 리 가능하게 연결되는 하부모듈을 포함하며, 하중 센서의 감지 정보에 기초하여 충돌을 감지한다. 그러나, 종래 기술 1의 안내 로봇의 경우 외부 장애물의 접근을 감지하지 못하며, 사용자가 원하는 목적지로 사 용자를 가이드하지 못하는 문제점이 있다. 종래 기술 2(KR101480774B)에 개시된 CCTV를 이용한 위치 인식 장치는 마커가 부착된 이동 로봇의 이동을 모니 터링하고 이동 로봇을 제어한다. 그러나, 종래 기술 2의 이동 로봇의 경우 CCTV의 영상 정보만 의존하기 때문에 장애물 탐지의 정밀성이 떨어져 장애물을 회피하여 이동 로봇을 이동시키는데 한계점이 존재한다."}
{"patent_id": "10-2019-0072329", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명이 해결하고자 하는 과제는 장애물 인식률이 떨어지는 종래의 문제점을 해결함으로써, 장애물을 회피하 는 최적의 경로 탐색 방법을 제공하는데 있다. 본 발명의 또 다른 과제는 장애물을 회피하여 이동하면서도, 다양한 정보를 사용자에게 제공하는 로봇을 제공하 는데 있다. 본 발명의 또 다른 과제는 장애물과의 충돌을 회피하는 로봇 및 이를 위한 로봇 관제 시스템을 제공하는데 있다. 본 발명에서 이루고자 하는 기술적 과제들은 이상에서 언급한 기술적 과제들로 제한되지 않으며, 언급하지 않은"}
{"patent_id": "10-2019-0072329", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 2, "content": "또 다른 기술적 과제들은 아래의 기재로부터 본 발명이 속하는 기술분야에서 통상의 지식을 가진 자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2019-0072329", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기 과제를 달성하기 위하여, 본 발명의 일 실시 예에 따른 로봇은 로봇 자체적으로 획득하는 정보와 외부에서 입력된 정보를 이용하여 최적의 경로 탐색을 수행할 수 있다. 구체적으로, 본 발명의 일 실시 예에 따른 일정 공간 내 배치되는 로봇은 목적지 정보가 입력되는 경우, 영상 신호 정보, 공간 맵 정보 및 감지된 장애물 영역 정보 중 적어도 하나에 기초하여 이동 경로를 탐색할 수 있다. 보다 구체적으로, 상기 제어 모듈은 장애물 영역 중에 로봇의 이동 가능 영역 정보를 로봇 관제 시스템으로부터 수신하고, 수신된 이동 가능 영역에 기초하여 탐색된 이동 경로를 갱신할 수 있다. 여기서, 상기 이동 가능 영역 정보는 상기 공간의 상부에 배치된 하나 이상의 카메라가 촬영한 영상에 기초하여 결정될 수 있다. 이에 따라, 로봇은 자체적으로 인식하지 못하는 이동 경로를 이용하여 정체된 경로를 우회 또는 회피할 수 있다. 상기 과제를 달성하기 위해, 본 발명의 일 실시 예에 따른 로봇의 제어 모듈은 동적 장애물과 소정 거리로 인접 하거나 충돌하는 경우 특정 대응 모션을 수행할 수 있다. 여기서, 특정 대응 모션은 로봇이 감속하는 모션, 대 기하는 모션 및 외부의 조작에 따라 로봇이 이동하는 모션 중 적어도 하나를 포함할 수 있다. 상기 과제를 달성하기 위해, 본 발명의 일 실시 예에 따른 일정 공간에서 로봇을 제어하는 로봇 관제 시스템의 구동 방법은 이동 경로의 정보 및 장애물 영역의 정보를 로봇으로부터 수신하는 단계, 공간 상부에 배치된 하나 이상의 카메라를 통해 촬영된 영상에 기초하여 장애물 영역 중에 로봇의 이동 가능 영역의 정보를 결정하는 단 계 및 결정된 이동 가능 영역 정보를 적용한 이동 경로를 로봇으로 전송하는 단계를 포함할 수 있다."}
{"patent_id": "10-2019-0072329", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명의 다양한 실시 예에 따르면 아래와 같은 효과가 도출될 수 있다. 첫째로, 로봇이 인식하지 못한 경로가 탐색될 수 있어 로봇의 이동 효율이 향상될 수 있으며 사용자 편의가 제 고될 수 있다. 둘째로, 장애물을 회피하거나 우회하는 로봇이 제공됨으로써, 경로 탐색의 시간 효율이 향상될 수 있으며 사용 자 편의가 제고될 수 있다."}
{"patent_id": "10-2019-0072329", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 첨부된 도면을 참조하여 본 명세서에 개시된 실시 예를 상세히 설명하되, 동일하거나 유사한 구성요소에 는 동일유사한 도면 부호를 부여하고 이에 대한 중복되는 설명은 생략하기로 한다. 또한, 본 명세서에 개시된 실시 예를 설명함에 있어서 관련된 공지 기술에 대한 구체적인 설명이 본 명세서에 개시된 실시 예의 요지를 흐 릴 수 있다고 판단되는 경우 그 상세한 설명을 생략한다. 도 1 및 도 2는 본 발명의 일 실시 예에 따른 로봇의 외관을 나타내는 도면들이다. 도 1 및 도 2를 참고하면, 로봇은 상부 모듈(UB) 및 하부 모듈(LB)을 포함할 수 있다. 그리고 상부 모듈 (UB)과 하부모듈(LB)은 상호간에 탈부착 가능하도록 구비될 수 있다. 참고로, 로봇은 공항, 병원 등에 배치되어 사용자에게 다양한 정보를 제공할 수 있으며, 사용자가 원하는 목적지로 사용자를 안내할 수 있다. 다만, 상기 로봇의 기능은 정보 제공 목적 및 안내 목적에만 한정되는 것은 아니다. 로봇에서, 상기 상부모듈(UB)은 서비스 환경에 따라 변경 가능한 유저 인터페이스(UI)를 사용자에게 제공 할 수 있으며, 그리고 상기 하부모듈(LB)은 이동을 위한 주행기능을 제공할 수 있다. 상부모듈(UB)은 몸체를 형성하는 바디부, 헤드부(HE) 및 복수의 디스플레이(141a, 141b)를 포함할 수 있다. 바 디부는 제1 카메라(121a)를 포함할 수 있으며, 헤드부(HE)는 제2 카메라(121b)를 포함할 수 있다. 헤드부(HE)는 몸체를 중심으로 180도 이상 회전할 수 있어서 디스플레이(141b)가 다양한 방향을 향하도록 구현될 수 있다. 입력부는 사용자로부터 터치 입력을 받기 위해 디스플레이(141b)를 포함할 수 있으며, 상기 디스플레이 (141b)는 터치 패드와 상호 레이어 구조를 이루어 터치스크린으로 구성될 수 있다. 입력부는 사용자가 상기 디스플레이(141b)를 아래로 내려다보면서 쉽게 조작할 수 있도록 일정 각도가 상 측을 향할 수 있다. 예를 들어, 상기 입력부는 상기 헤드(HE)의 일부가 절단되어 형성되는 면에 배치될 수 있어서, 경사지도록 디스플레이(141b)가 배치될 수 있다. 즉, 상기 입력부 상에는 사람의 눈, 코, 입, 눈썹 등을 표현하기 위하여 특정 구조물이 배치될 수 있고 또 는 특정 페인트가 도색될 수 있다. 따라서, 상기 입력부는 사람의 얼굴 형상을 가짐으로써, 사용자에게 감 성적인 느낌을 제공할 수 있다. 더욱이, 사람의 얼굴 형상을 가지는 로봇이 주행하는 경우, 마치 사람이 움직이는 것과 같은 느낌을 줄 수 있어 로봇에 대한 거부감이 해소될 수 있다. 다른 실시 예에 의하면, 상기 디스플레이(141b) 상에는 사람의 눈, 코, 입, 눈썹 등을 표현하기 위한 이미지가 하나 이상 표시될 수 있다. 즉, 상기 헤드 디스플레이(141b) 상에는 길 안내 서비스에 관련된 정보뿐만 아니라, 사람의 얼굴 형상을 표현하기 위한 다양한 이미지가 표시될 수 있다. 그리고 상기 디스플레이(141b) 상에는 일 정 시간 간격 또는 특정 시각에 정해진 얼굴 표정을 표현하기 위한 이미지가 표시될 수도 있다. 도 1을 기준으로 상기 입력부가 향하는 방향을 \"전방\"이라고 정의한다. 그리고 \"전방\"의 반대 방향을 \"후 방\"이라고 정의한다. 이에, 로봇은 전방 방향으로 이동하면서 뒤따르는 사용자에게 대화면의 디스플레이 (141a)를 통해 다양한 정보를 제공할 수 있다. 아울러, 로봇의 헤드(HE)는 도 2와 같이 180도 회전하여 후방 방향을 향할 수 있다. 디스플레이(141a)는 로봇을 뒤따르는 사용자에게 다양한 정보를 제공할 수 있으며, 디스플레이(141a) 상에 카메라(121c)가 더 포함되어 사용자를 인식하는데 이용될 수 있다. 또한, 로봇의 장애물 센서(가령, 라이더 센서)는 전방 방향을 향하여 제1 지점(131a)에 배치될 수 있으며, 후방 방향을 향하여 제2 지점(131b)에 배치될 수 있다. 상기 제1 지점(131a) 및 제2 지점(131b)에는 절개면이 포함되어 장애물 센서의 광이 전방 또는 후방을 향하여 직진하도록 구현될 수 있다. 다만, 상기 장애물 센서의 배치 위치는 구현 예에 따라 다를 수 있다. 이하에서는, 도 3을 참고하여 로봇의 구성을 설명하기로 한다. 로봇은 통신부, 입력부, 센 싱부, 출력부, 저장부, 전원공급부, 이동 모듈 및 제어 모듈을 포함할 수 있다. 도 3에 도시된 구성요소들은 로봇을 구현하는데 있어서 필수적인 것은 아니어서, 본 명세서 상에서 설명되는 로봇은 위에서 열거된 구성요소들 보다 많거나, 또는 적은 구성요소들을 가질 수 있다. 보다 구체적으로, 상기 구성요소들 중 통신부는 로봇과 로봇 관제 시스템 사이, 또는 로봇과 통 신 모듈을 구비한 장치 사이의 통신을 가능하게 하는 하나 이상의 유무선 통신 모듈을 포함할 수 있다. 우선, 통신부는 이동 통신 모듈을 포함할 수 있다. 여기서, 이동 통신 모듈은 이동통신을 위한 기술표준들 또는 통신방식(예를 들어, GSM(Global System for Mobile communication), CDMA(Code Division Multi Access), CDMA2000(Code Division Multi Access 2000), EV-DO(Enhanced Voice-Data Optimized or Enhanced Voice-Data Only), WCDMA(Wideband CDMA), HSDPA(High Speed Downlink Packet Access), HSUPA(High Speed Uplink Packet Access), LTE(Long Term Evolution), LTE-A(Long Term Evolution-Advanced) 등) 및 5G(Generation) 통신에 따라 구축된 이동 통신망 상에서 기지국, 외부의 단말, 로봇 관제 시스템 중 적어도 하 나와 무선 신호를 송수신한다. 또한, 통신부는 근거리 통신 모듈을 포함할 수 있다. 여기서, 근거리 통신 모듈은 근거리 통신(Short range communication)을 위한 것으로서, 블루투스(Bluetooth™), RFID(Radio Frequency Identification), 적외 선 통신(Infrared Data Association; IrDA), UWB(Ultra Wideband), ZigBee, NFC(Near Field Communication), Wi-Fi(Wireless-Fidelity), Wi-Fi Direct, Wireless USB(Wireless Universal Serial Bus) 기술 중 적어도 하 나를 이용하여 근거리 통신을 수행할 수 있다. 입력부는 영상 신호 입력을 위한 카메라 또는 영상 입력부, 오디오 신호 입력을 위한 마이크로폰 (microphone, 123), 또는 오디오 입력부, 사용자로부터 정보를 입력받기 위한 사용자 입력부(예를 들어, 터치키 (touch key), 푸시키(mechanical key) 등)를 포함할 수 있는데,. 카메라는 복수 개로 구현될 수 있다. 센싱부는 로봇 내 정보, 로봇을 둘러싼 주변 환경 정보 및 사용자 정보 중 적어도 하나를 센싱 하기 위한 하나 이상의 센서를 포함할 수 있다. 예를 들어, 센싱부는 장애물 센서(131, 가령, 근접센서 (proximity sensor), 라이다 센서(Lidar sensor) 등), 무게 감지 센서, 조도 센서(illumination sensor), 터치 센서(touch sensor), 가속도 센서(acceleration sensor), 자기 센서(magnetic sensor), 중력 센서(G-sensor), 자이로스코프 센서(gyroscope sensor), 모션 센서(motion sensor), RGB 센서, 적외선 센서(IR 센서: infrared sensor), 지문인식 센서(finger scan sensor), 초음파 센서(ultrasonic sensor), 광 센서(optical sensor, 예 를 들어, 카메라(121 참조)), 마이크로폰(microphone, 123 참조), 배터리 게이지(battery gauge), 환경 센서 (예를 들어, 기압계, 습도계, 온도계, 방사능 감지 센서, 열 감지 센서, 가스 감지 센서 등), 화학 센서(예를 들어, 전자 코, 헬스케어 센서, 생체 인식 센서 등) 중 적어도 하나를 포함할 수 있다. 한편, 본 명세서에 개시 된 로봇은, 이러한 센서들 중 적어도 둘 이상의 센서에서 센싱되는 정보들을 조합하여 활용할 수 있다. 출력부는 시각, 청각 또는 촉각 등과 관련된 출력을 발생시키기 위한 것으로, 디스플레이(141, 복수 개 적 용 가능하나 대표적으로 도 1의 141a), 하나 이상의 발광 소자, 음향 출력부 및 햅팁 모듈 중에서 적어도 하나 를 포함할 수 있다. 디스플레이는 터치 센서와 상호 레이어 구조를 이루거나 일체형으로 형성됨으로써, 터치 스 크린으로 구현될 수 있다. 이러한 터치 스크린은, 로봇과 사용자 사이의 입력 인터페이스를 제공하는 사용 자 입력부로써 기능함과 동시에, 로봇과 사용자 사이의 출력 인터페이스를 제공할 수 있다. 저장부는 로봇의 다양한 기능을 지원하는 데이터를 저장한다. 저장부는 로봇에서 구동되는 다수의 응용 프로그램(application program 또는 애플리케이션(application)), 로봇의 동작을 위한 데이 터들, 명령어들을 저장할 수 있다. 이러한 응용 프로그램 중 적어도 일부는, 무선 통신을 통해 외부 서버로부터 다운로드 될 수 있다. 또한, 저장부는 로봇과 인터랙션을 수행하려는 사용자 정보를 저장할 수 있다. 상기 사용자 정보는 인식된 사용자가 누구인지 식별하는데 사용될 수 있다. 전원공급부는 제어 모듈의 제어 하에서, 외부의 전원, 내부의 전원을 인가 받아 로봇의 각 구성 요소들에 전원을 공급한다. 이러한 전원공급부는 배터리를 포함하며, 상기 배터리는 내장형 배터리 또는 교체가능한 형태의 배터리가 될 수 있다. 상기 배터리는 유선 또는 무선 충전 방식으로 충전될 수 있는데, 무선 충전 방식은 자기 유도 방식 또는 자기 공진 방식을 포함할 수 있다. 이동 모듈은 제어 모듈의 제어에 따라 로봇을 소정의 장소로 이동하기 위한 모듈이며, 하나 이 상의 휠(Wheel)을 포함할 수 있다. 상기 제어 모듈은 로봇을 이동시킬 수 있는데, 입력부를 통해 목적지 정보가 입력되는 경우, 목 적지까지 로봇을 이동시킬 수 있다. 여기서, 목적지 정보는 도 1의 입력부 상에서 터치 입력, 음성 입력, 버튼 입력 등을 통해 입력될 수 있다. 제어 모듈은 일정 공간에 대응되는 공간 맵 정보를 저장부에 저장할 수 있다. 구현 예에 따라서는, 상기 공간 맵 정보가 외부 로봇 관제 시스템으로부터 수신될 수 있다. 제어 모듈은 카메라로부터 촬영된 정보, 공간 맵 정보 및 센싱부를 통해 감지된 장애물 영역 정 보에 기초하여 목적지까지의 이동 경로를 탐색할 수 있다. 제어 모듈은 탐색된 이동 경로 정보를 디스플레 이에 표시할 수 있다. 또한, 제어 모듈은 로봇 관제 시스템에 장애물 영역 중에 로봇이 이동 가능한 영역 정보를 로봇 관제 시스템에 요청할 수 있고, 로봇 관제 시스템은 공간의 상부에 배치된 카메라들로부터 촬영된 영상에 기초하여 장애물 주변에 로봇이 이동 가능한 공간을 탐색할 수 있고, 탐색된 이동 가능 공간 정보를 로봇에 전 송할 수 있다.다른 실시 예에 의하면, 제어 모듈은 카메라를 이용하여 외부 장애물들을 촬영하고, 장애물의 형상, 특성 에 기초하여 장애물 영역이 아닌 이동 가능 영역이 있는지 판단할 수 있다. 가령, 제어 모듈은 장애물들의 사이즈, 재질, 형상 등을 참고하여 해당 장애물의 사이즈와 차지하는 공간 등을 추정하여, 장애물 주변에 로봇 이 이동 가능한 영역을 탐지할 수 있다. 제어 모듈은 이동 경로 상에서 입력된 영상 신호 정보를 상기 디스플레이에 표시할 수 있다. 즉, 제 어 모듈의 로봇이 카메라를 통해 바라보는 영상을 디스플레이에 표시할 수 있다. 이에, 로봇 을 따라가는 유저는 상기 디스플레이에 표시된 영상을 바라볼 수 있다. 아울러, 제어 모듈은 공간을 상부에서 촬영하는 하나 이상의 카메라가 상기 이동 경로 상에 배치된 로봇 및 로봇의 인접 영역을 촬영하는 경우, 촬영된 영상을 통신부를 통해 수신할 수 있다. 제어 모 듈은 수신한 촬영 영상을 디스플레이에 표시할 수 있다. 이런 경우, 사용자가 현재 이동하는 지점에 대한 정보가 디스플레이에 표시되어 사용자 편의가 제고될 수 있다. 제어 모듈은 상기 디스플레이를 복수의 구분 영역으로 가상적으로 분할하여 영상을 표시할 수 있다. 구체적으로, 제어 모듈은 공간 맵 상에서 로봇의 이동 경로를 나타내는 영상을 제1 구분 영역에 표시 하고, 이동 경로 상에서 입력부를 통해 입력된 영상 신호 정보를 제2 구분 영역에 표시하며, 이동 경로 상 에서 로봇 및 상기 로봇의 인접 영역을 상부에서 촬영한 영상을 제3 구분 영역에 표시하도록 상기 디 스플레이를 제어할 수 있다. 아울러, 제어 모듈은 정적인 장애물 뿐만 아니라 동적 장애물을 인식할 수 있다. 구체적으로, 제어 모듈 은 로봇과 동일 방향으로 이동하는 동적 장애물이 인식되는 경우, 인식된 동적 장애물의 이동 속도에 맞추어 이동하도록 상기 로봇의 이동 모듈을 제어할 수 있다. 또한, 제어 모듈은 특정 긴급 상황(가령, 충돌 상황 등)이 발생되는 경우 특정 대응 모션을 수행할 수 있 다. 특정 대응 모션은 패시브(Passive) 모션일 수 있으며, 로봇이 감속하는 모션, 이동을 대기하는 모션 및 펜딩하였다가 외부의 조작에 따라 로봇이 이동하는 모션 등을 포함할 수 있으나, 실시 예가 이에 국한 되는 것은 아니다. 한편, 본 발명의 일 실시 예에 다른 로봇의 구동 방법은 목적지 정보가 입력되는 경우, 입력된 영상 신호 정보, 공간 맵 정보 및 감지된 장애물 영역 정보 중 적어도 하나에 기초하여 이동 경로를 탐색한다. 그 후에, 로봇은 장애물 영역 중에 로봇이 이동 가능한 영역 정보를 로봇 관제 시스템으로부터 수신할 수 있다. 그러면, 로봇은 수신된 이동 가능 영역에 기초하여 상기 이동 경로를 갱신할 수 있다. 이 때, 로봇은 충돌을 방지하기 위해 다양한 동작을 수행할 수 있는데, 구체적으로, 로봇은 같은 방 향으로 이동하는 동적 장애물이 인식되면, 인식된 동적 장애물의 이동 속도에 맞추어 이동할 수 있으며, 상술한 패시브 모션을 수행할 수 있다. 같은 방향으로 이동하는 동적 장애물의 경우 로봇과 가장 근접한 동적 장 애물일 수 있으나, 실시 예가 이에 국한되는 것은 아니다. 도 4는 본 발명의 일 실시 예에 따른 이동 경로를 효과적으로 개선하는 로봇의 구동 방법을 나타낸다. 도 4를 참고하면, 일정 공간 내에는 상부에 하나 이상의 카메라(221a~221d)가 배치될 수 있다. 상기 카메라들 (221a~221d)은 상기 공간을 상부에서 촬영할 수 있으며, 3차원 reconstruction 기능을 수행하도록 구현될 수 잇 다. 로봇(100a)은 상기 공간에 대응되는 공간 맵 정보를 저장부에 저장할 수 있다. 로봇(100a)은 최초에 출발 지점(SP)에서 목적지 지점(EP)로 이동할 수 있다. 로봇(100a)은 장애물 센서를 구비하여 반사되는 광을 인식하여 거리를 탐색할 수 있다. 로봇(100a)은 출발 지점(SP)에서 자체 카메라들로부 터 촬영된 정보, 장애물 센서로부터 감지된 정보만 이용할 경우, 제1 경로(Pa1) 또는 제2 경로(Pa2)만 탐 색될 수 있다. 이는, 로봇(100a)의 장애물 센서가 출발 지점(SP)에서 장애물 주변의 이동 가능 영역을 탐색할 수 없 기 때문이다. 로봇(100a)의 장애물 센서는 그리드 맵을 생성할 수 있는데, 로봇(100a)을 중심점에 두고 장 애물 센서에 의해 감지된 장애물들을 동서남북 사방으로 표시할 수 있다. 장애물 센서는 거리를 측정 할 수 있으므로, 주변에 배치된 장애물들을 그리드 맵에 표시할 수 있다. 이 경우, 로봇(100a)은 로봇 관제 시스템에 이동 경로 정보를 제공할 수 있으며, 로봇 관제 시스템은 장애물 영 역 가운데 로봇이 이동 가능한 영역에 관한 정보를 카메라들(221a~221d)로부터 수집하여, 로봇으 로부터 수집된 이동 경로를 갱신할 수 있으며, 갱신된 이동 경로에 대한 정보를 로봇으로 제공할 수 있다. 그러면, 로봇(100a)은 장애물 영역 중에 이동 가능한 영역을 통과하여 목적지(EP)까지 이동할 수 있다. 이 에 따라, 이동 경로의 거리 및 시간이 단축될 수 있으므로, 로봇의 이동 효율이 향상될 수 있으며, 안내를 받는 사용자의 편의가 제고될 수 있다. 도 5는 본 발명의 일 실시 예에 따른 로봇이 제공하는 디스플레이 화면을 나타낸다. 도 5를 참고하면, 로봇은 디스플레이의 상부 영역에 공간 맵 상에서 이동 경로를 표시하는 화면을 표 시할 수 있다. 가령, 상기 화면은 환전소까지의 경로를 나타내며, 예상 거리 및 예상 시간 정보를 표시할 수 있 다. 또한, 로봇은 로봇이 이동하면서 촬영한 영상을 구분 영역에 표시할 수 있으며, 로봇이 정 면 방향을 바라보는 것과 같이 표시할 수 있다. 또한, 로봇은 공간의 상부에 배치된 카메라들을 이용하여 촬영한 영상을 다른 구분 영역에 표시할 수 있다. 상기 촬영 영상은 로봇 관제 시스템으로부터 수신할 수 있다. 이에 따라, 사용자에게 다양한 정보를 제공 함으로써 사용자 편의가 제고될 수 있다. 이때, 로봇은 로봇 자체적인 센싱이나 촬영으로는 판단하기 어려운 충돌 가능성에 대한 정보를 로봇 관제 시스템으로부터 수신할 수 있다. 로봇은 상기 정보를 수신하면 출력부의 소리 출력부를 통해 로봇이 이동하고 있음을 소리로 출력할 수 있으며, 이동을 대기할 수도 있다. 도 6은 본 발명의 일 실시 예에 따른 로봇 관제 시스템의 구동 방법을 설명하기 위한 도면이다. 먼저, 로봇 관제 시스템은 로봇으로부터 목적지 정보 및 감지된 장애물 영역 수신한다(S610). 그 후에, 로봇 관제 시스템은 로봇의 목적지 정보, 장애물 영역, 장애물 영역 중에 이동 가능 영역 및 공 간 맵 정보에 기초하여 이동 경로를 생성(S620) 또는 갱신할 수 있다. 마지막으로, 로봇 관제 시스템은 이동 경로에 기초하여 로봇이 이동하도록 제어할 수 있다(S630). 이 때, 로봇 관제 시스템은 공간의 상부에 배치된 하나 이상의 카메라를 통해 이동 경로를 이동하는 로봇 및 로봇의 인접 영역이 촬영되면, 촬영된 영상을 상기 로봇으로 전송할 수 있다. 도 7은 본 발명의 일 실시 예에 따른 로봇 통신 시스템을 설명하기 위한 도면이다. 로봇 통신 시스템은 제1 로봇(100a), 제2 로봇(100b) 및 이동 단말을 포함할 수 있다. 여기서, 이동 단말은 차량, 디바이스, IoT 장치 등으로 대체될 수 있다. 로봇들(100a, 100b) 및 이동 단말은 상술 한 5G 통신 모듈을 구비할 수 있다. 이 경우, 제1 로봇(100a)은 100Mbps 내지 20Gbps 속도로 데이터를 전송할 수 있어서 대용량의 동영상을 제2 로 봇(100b) 및 이동 단말로 전송할 수 있다. 5G 통신 모듈을 구비한 제1 로봇(100a)은 자체적으로 촬영한 영상 정보, 공간 맵 정보, 장애물 영역 정보, 이동 가능 영역 정보 중 적어도 하나에 기초한 공간 맵 정보를 제2 안내 로봇(100b)에 제공할 수 있으며, 5G 통신 모 듈을 구비한 제2 로봇(100b)도 공간 맵 정보를 제1 로봇(100a)에 제공할 수 있다. 이에 따라, 각각의 로봇들(100a, 100b)은 상대 로봇이 제공하는 정보에 기초하여 보다 정확하게 공간을 인식할 수 있으며, 장애물 회피 경로를 보다 신속하게 검색할 수 있다. 아울러, 각가의 로봇들(100a, 100b)은 각각의 디스플레이 상에 상대 로봇이 제공하는 공간 맵 정보, 이동 중에 촬영한 영상 정보, 공간을 상부에서 촬영한 영상 정보를 표시할 수 있다. 또한, 5G 통신 모듈을 구비한 로봇들(100a, 100b)은 각종 사물 지능 통신(IoT(Internet of Things), IoE(Internet of Everything), IoST(Internet of Small Things) 등)을 지원할 수 있으며, 로봇들(100a, 100b) 은 M2M(Machine to Machine) 통신, V2X(Vehicle to Everything Communication) 통신, D2D(Device to Device) 통신 등을 지원할 수 있다. 이에 따라, 다양한 기기와 공간 상에서 취득할 수 있는 정보를 공유할 수 있다. 전술한 본 발명은, 프로그램이 기록된 매체에 컴퓨터가 읽을 수 있는 코드로서 구현하는 것이 가능하다. 컴퓨터 가 읽을 수 있는 매체는, 컴퓨터 시스템에 의하여 읽혀질 수 있는 데이터가 저장되는 모든 종류의 기록장치를포함한다. 컴퓨터가 읽을 수 있는 매체의 예로는, HDD(Hard Disk Drive), SSD(Solid State Disk), SDD(Silicon Disk Drive), ROM, RAM, CD-ROM, 자기 테이프, 플로피 디스크, 광 데이터 저장 장치 등이 있으며, 또한, 상기 컴퓨터는 로봇의 제어 모듈을 포함할 수도 있다. 앞에서, 본 발명의 특정한 실시예가 설명되고 도시되었지만 본 발명은 기재된 실시예에 한정되는 것이 아니고, 이 기술 분야에서 통상의 지식을 가진 자는 본 발명의 사상 및 범위를 벗어나지 않고서 다른 구체적인 실시예로 다양하게 수정 및 변형할 수 있음을 이해할 수 있을 것이다. 따라서, 본 발명의 범위는 설명된 실시예에 의하여 정하여 질 것이 아니고 청구범위에 기재된 기술적 사상에 의해 정하여져야 할 것이다."}
{"patent_id": "10-2019-0072329", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1 및 도 2는 본 발명의 일 실시 예에 따른 로봇의 외관을 나타내는 도면들, 도 3은 본 발명의 일 실시 예에 따른 로봇의 구성을 나타내는 블록도, 도 4는 본 발명의 일 실시 예에 따른 로봇이 효과적으로 이동 경로를 설정하는 방법을 설명하기 위한 도면, 도 5는 본 발명의 일 실시 예에 따른 로봇의 디스플레이 화면을 나타내는 도면, 도 6은 본 발명의 일 실시 예에 따른 로봇 관제 시스템의 구동 방법을 나타내는 시퀀스도, 그리고, 도 7은 본 발명의 일 실시 예에 따른 로봇 통신 시스템을 설명하기 위한 도면이다."}
