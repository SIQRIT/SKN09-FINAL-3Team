{"patent_id": "10-2023-0063411", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0166101", "출원번호": "10-2023-0063411", "발명의 명칭": "인공지능 기반의 말 객체 식별 시스템 및 그 방법", "출원인": "주식회사 라임솔루션", "발명자": "신은동"}}
{"patent_id": "10-2023-0063411", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "서버에 의해 수행되는 인공지능 기반의 말 객체 식별 방법에 있어서,빅데이터를 기반으로 반복학습하여 표준데이터를 생성하는 단계;대상체에 대한 촬영데이터로부터 이미지정보를 추출하는 단계;상기 이미지정보를 비교 및 분석하여 대상체의 흰점을 식별하여 식별데이터를 생성하는 단계; 및상기 표준데이터를 기초로 상기 식별데이터를 비교 및 분석하여 대상체의 객체결과데이터를 생성하는 단계를 포함하고,상기 식별데이터를 생성하는 단계는,상기 이미지정보에 격자패턴을 매칭하여 흰점을 위치별, 크기별 및 형상별로 순차적으로 식별하는 단계를 포함하는, 인공지능 기반의 말 객체 식별 방법."}
{"patent_id": "10-2023-0063411", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 식별데이터를 생성하는 단계는,상기 촬영데이터가 사진인 경우, 상기 이미지정보를 이용하여 대상체와 배경을 분리하여 대상체를 객체로 인식하는 단계;상기 객체를 중심으로 바운더리 영역을 검출하여 이미지별로 바운딩 박스를 설정하는 단계;상기 바운딩 박스 내에 위치하는 상기 객체의 신체부위에 대하여 위치별, 크기별 및 형상별로 격자패턴을 설정하는 단계; 및위치별, 크기별 및 형상별로 분류되어 식별된 상기 식별데이터를 생성하는 단계를 포함하는, 인공지능 기반의말 객체 식별 방법."}
{"patent_id": "10-2023-0063411", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,상기 식별데이터를 생성하는 단계는,상기 바운딩 박스 내에 위치하는 상기 객체의 신체부위에 대응하여 위치식별격자패턴을 설정하는 단계;상기 위치식별격자패턴을 기초로 흰점의 위치를 식별하여 위치식별데이터를 생성하는 단계;상기 바운딩 박스 내에 위치하는 상기 객체의 신체부위에 대응하여 크기식별격자패턴을 설정하는 단계;상기 크기식별격자패턴을 기초로 흰점의 위치를 식별하여 크기식별데이터를 생성하는 단계;상기 바운딩 박스 내에 위치하는 상기 객체의 신체부위에 대응하여 형상식별격자패턴을 설정하는 단계; 및상기 형상식별격자패턴을 기초로 흰점의 위치를 식별하여 형상식별데이터를 생성하는 단계를 포함하고,상기 위치식별격자패턴의 크기는 상기 크기식별격자패턴보다 크고, 상기 크기식별격자패턴의 크기는 상기 형상식별격자패턴보다 크게 형성되는, 인공지능 기반의 말 객체 식별 방법."}
{"patent_id": "10-2023-0063411", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서,공개특허 10-2024-0166101-3-상기 식별데이터를 생성하는 단계는,상기 위치식별격자패턴을 기초로 대상체의 머리를 이마가마영역, 콧등가마영역 및 코·입술영역으로 구분하는단계;이마가마영역에 흰점이 있는 경우, 흰점의 위치를 머리부위로 식별하는 단계;콧등가마영역에 흰점이 있는 경우, 흰점의 위치를 콧등부위로 식별하는 단계;코영역에 흰점이 있는 경우, 흰점의 위치를 코부위로 식별하는 단계; 및이마가마영역, 콧등가마영역 및 코영역이 혼합된 혼합영역에 혼합된 흰점이 있는 경우, 흰점의 위치를 이마·콧등·코부위로 식별하는 단계를 포함하는, 인공지능 기반의 말 객체 식별 방법."}
{"patent_id": "10-2023-0063411", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서,상기 식별데이터를 생성하는 단계는,기설정된 기준범위를 기준으로 상기 크기식별격자패턴을 기초로 머리부위, 콧등부위, 코부위 및 이마·콧등·코부위에 대응하는 위치별로 식별된 흰점의 크기를 식별하는 단계를 포함하고,상기 흰점의 크기를 식별하는 단계는,머리부위에 흰점이 있는 경우, 제1 기준범위(엄지첫마디)를 기준으로 상기 크기식별격자패턴의 폭이 작으면 흰점의 크기를 작게 식별하고, 제2 기준범위(주먹)를 기준으로 상기 크기식별격자패턴의 폭이 크면 흰점의 크기를크게 식별하는 단계;콧등부위에 흰점이 있는 경우, 제1 기준범위(엄지첫마디)를 기준으로 상기 크기식별격자패턴의 폭이 작으면 흰점의 크기를 작게 식별하고, 제3 기준범위(코뼈)를 기준으로 상기 크기식별격자패턴의 폭이 크면 흰점의 크기를크게 식별하는 단계; 및코부위에 흰점이 있는 경우, 제1 기준범위(엄지첫마디)를 기준으로 상기 크기식별격자패턴의 폭이 작으면 흰점의 크기를 작게 식별하고, 제3 기준범위(코뼈)를 기준으로 상기 크기식별격자패턴의 폭이 크면 흰점의 크기를크게 식별하는 단계를 포함하는, 인공지능 기반의 말 객체 식별 방법."}
{"patent_id": "10-2023-0063411", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5항에 있어서,상기 식별데이터를 생성하는 단계는,기설정된 기준범위를 기준으로 상기 형상식별격자패턴을 기초로 머리부위, 콧등부위, 코부위 및 이마·콧등·코부위에 대응하는 위치별 및 크기별로 식별된 흰점의 형상을 식별하는 단계를 포함하고,상기 흰점의 형상을 식별하는 단계는,머리부위에 흰점이 있는 경우, 상기 형상식별격자패턴에 도출되는 라인의 개수, 공백의 크기 및 채움의 크기를식별하는 단계;콧등부위에 흰점이 있는 경우, 상기 형상식별격자패턴에 도출되는 라인의 개수, 공백의 크기 및 채움의 크기를식별하는 단계;코부위에 흰점이 있는 경우, 상기 형상식별격자패턴에 도출되는 라인의 개수, 공백의 크기 및 채움의 크기를 식별하는 단계; 및이마·콧등·코부위에 흰점이 있는 경우, 상기 형상식별격자패턴에 도출되는 라인의 개수, 공백의 크기 및 채움의 크기를 식별하는 단계를 포함하는, 인공지능 기반의 말 객체 식별 방법."}
{"patent_id": "10-2023-0063411", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6항에 있어서,공개특허 10-2024-0166101-4-상기 식별데이터를 생성하는 단계는,흰점을 머리부위, 콧등부위, 코부위 및 이마·콧등·코부위에 대응하는 위치별로 식별하고,위치별로 식별된 흰점을 머리부위에서 성(星), 소성(小星), 대성(大星), 유성(流星), 소유성(小流星) 및 대유성(大流星)에 대응하는 크기별로 분류하고, 위치별로 식별된 흰점을 콧등부위에서 비량세백(鼻梁細白), 비량대백(鼻梁大白) 및 비량백(鼻梁白)에 대응하는 크기별로 분류하여 식별하고, 위치별로 식별된 흰점을 코부위에서 비소백(鼻小白), 비대백(鼻大白) 및 비백(鼻白)에 대응하는 크기별로 분류하여 식별하고,위치별로 식별된 흰점을 머리부위에서 곡성(曲星), 환성(環星), 난성(亂星), 곡유성(曲流星), 환유성(環流星),난유성(亂流星)에 대응하는 형상별로 분류하여 식별하고, 위치별로 식별된 흰점을 콧등부위에서 환비량백(環鼻梁白)에 대응하는 형상별로 분류하여 식별하고, 위치별로 식별된 흰점을 코부위에서 환비백(環鼻白)에 대응하는형상별로 분류하여 식별하고, 위치별로 식별된 흰점을 이마·콧등·코부위에서 유성·비량세백, 유성·비량백,대유성·비량백, 유성·비백, 비량백·비백, 유성·비량대백·비량백·비백, 대유성·비량백·비량대백·비백,대유성·비량백·비대백, 대유성·비량대백·비대백, 유성·단비량백·비백, 유성·단비량백·비대백, 곡대유성·비량백·단비백, 유성·단비량백·단비백, 환대유성·비량새치·비량대백·비량새치·비소백, 환대유성·환비량대백·비백 및 백면에 대응하는 형상별로 분류하여 식별하는, 인공지능 기반의 말 객체 식별 방법."}
{"patent_id": "10-2023-0063411", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1항에 있어서,상기 식별데이터를 생성하는 단계는,상기 촬영데이터가 동영상인 경우 프레임별로 이미지를 추출하여 프레임별 이미지정보를 생성하는 단계;상기 프레임별 이미지 정보에 포함된 대상체와 배경을 분리하여 대상체를 객체로 인식하는 단계;상기 객체를 중심으로 바운더리 영역을 검출하여 이미지별로 바운딩 박스를 설정하는 단계;상기 바운딩 박스 내에 위치하는 상기 객체의 신체부위에 위치별, 크기별 및 형상별로 격자패턴을 설정하는 단계; 및위치별, 크기별 및 형상별로 분류되어 식별된 상기 식별데이터를 생성하는 단계를 포함하는, 인공지능 기반의말 객체 식별 방법."}
{"patent_id": "10-2023-0063411", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1항에 있어서,상기 식별데이터를 생성하는 단계는,대상체의 흰점을 다리부위에 대응하는 위치별로 식별하고, 위치별로 식별된 흰점을 다리부위에서 소백(小白),반백(半白), 백(白), 장반백(長半白) 및 장백(長白)에 대응하는 크기별 및 형상별로 분류하여 식별하여 다리식별데이터를 생성하는 단계; 및대상체의 입술부위에 대응하는 위치별로 식별하고, 위치별로 식별된 입술점을 입술부위에서 상순백(上脣白), 상순대백(上脣大白), 상순소백(上脣小白), 하순백(下脣白), 하순대백(下脣大白), 및 하순소백(下脣小白)에 대응하는 크기 및 형상별로 분류하여 입술식별데이터를 생성하는 단계를 더 포함하는, 인공지능 기반의 말 객체 식별방법."}
{"patent_id": "10-2023-0063411", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "인공지능 기반의 말 객체 식별 시스템에 있어서,검사하고자 하는 대상체로부터 촬영데이터를 획득하는 사용자 단말기; 및빅데이터를 기반으로 반복학습하여 표준데이터를 생성하고, 대상체에 대한 상기 촬영데이터로부터 이미지정보를추출하며, 이미지정보를 비교 및 분석하여 대상체의 흰점을 식별하여 식별데이터를 생성하고, 상기 표준데이터를 기초로 상기 식별데이터를 비교 및 분석하여 대상체의 객체결과데이터를 생성하는 관리서버;를 포함하고,상기 관리서버는,공개특허 10-2024-0166101-5-상기 이미지정보에 격자패턴을 매칭하여 흰점을 위치별, 크기별 및 형상별로 순차적으로 식별하는 추출하여 상기 식별데이터를 생성하는, 인공지능 기반의 말 객체 식별 시스템."}
{"patent_id": "10-2023-0063411", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "하드웨어인 컴퓨터와 결합되어, 제1항의 방법을 수행할 수 있도록 컴퓨터에서 독출가능한 기록매체에 저장된 컴퓨터 프로그램."}
{"patent_id": "10-2023-0063411", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 인공지능 기반의 말 객체 식별 시스템 및 그 방법이 제공된다. 상기 방법은 서버에 의해 수행되는 인 공지능 기반의 말 객체 식별 방법에 있어서, 빅데이터를 기반으로 반복학습하여 표준데이터를 생성하는 단계; 대 상체에 대한 촬영데이터로부터 이미지정보를 추출하는 단계; 상기 이미지정보를 비교 및 분석하여 대상체의 흰점 을 식별하여 식별데이터를 생성하는 단계; 및 상기 표준데이터를 기초로 상기 식별데이터를 비교 및 분석하여 대 상체의 객체결과데이터를 생성하는 단계를 포함하고, 상기 식별데이터를 생성하는 단계는, 상기 이미지정보에 격 자패턴을 매칭하여 흰점을 위치별, 크기별 및 형상별로 순차적으로 식별하는 단계를 포함할 수 있다."}
{"patent_id": "10-2023-0063411", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 인공지능 기반의 말 객체 식별 시스템 및 그 방법에 관한 것으로서, 특히 인공지능을 기반으로 말의 신체로부터 획득한 흰점의 위치, 크기 및 형상을 순차적으로 판단하여 말을 자동으로 객체 식별할 수 있는 인공 지능 기반의 말 객체 식별 시스템 및 그 방법에 관한 것이다."}
{"patent_id": "10-2023-0063411", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "인간은 신분을 검증하고 확인하는 방법으로 생체인증(Biometrics) 분야를 사용하고 있고, 이는 이미 오랜 기간 동안 발전해왔다. 이러한 생체인증 방식으로는 지문인식, 홍채인식, 정맥인식(Vein recognition) 등이 있다. 이와 관련하여 인간의 지문은 사람마다 모두 다르듯이, 개과에 속하는 동물들의 비문(코 무늬)은 동물마다 각각 다르다. 이에 이를 이용하여 동물의 종 확인 또는 주인이 찾고자 하는 동물을 확인할 수 있는 방법은 동물의 체계적인 관리를 가능하게 할 수 있다. 다만 일반적인 사람의 지문인식 방법과, 동물의 비문인식 방법은 구체적인 인식방 식 등의 차이가 있기 때문에 이를 위한 새로운 모델을 마련할 필요성이 있다. 전통적으로 동물 개체 인식 방법은 플라스틱이나 바코드가 있는 귀표(Electronic Ear Tag)를 붙이는 방법, 목에 숫자가 적인 태그를 이용하는 방법(Neck Chain), 몸에 페인트를 칠하거나(Paint Branding) 문신을 새기는 방법 (Tattooing)이 사용되었다. 현재는 마이크로 칩과 안테나를 귀표에 넣거나 피부조직에 이식(Injectable Transponder)하여 비접촉 무선기술 로 인식하는 방법이 널리 활용되고 있다. 이 방법은 장치를 일부러 훼손하거나 위변조할 경우 개체를 구별할 수 없다는 약점이 있다. 또한, 일부 연구에 의하면 동물 개체 내로 삽입된 마이크로 칩과 안테나를 둘러싼 물질이 동물 조직에 종양이 생기거나 조직이 괴사하는 현상이 생기는 것으로 알려져 동물에게 안전하지 않은 방법이 되 었다. 동물 개체의 고유 생체 정보인 비문도 사람의 지문처럼 개체 유일성이 있다. 비문 인증은 비문의 이미지를 획득 하여, 그 주름 등의 패턴 이미지의 특징을 등록하였다가 같은 동물인지 인증하는 방식이다. 비문인증에서 비문 이미지를 획득하는 방식은 카메라를 이용하여 비문을 촬영하는 비접촉 방식이 있고, 지문 이 미지를 획득하듯 직접 접촉하여 획득하는 접촉방식이 있다. 동물의 코는 촉촉하게 습기가 있는 상태이기 때문에 비문을 카메라로 촬영하는 방식은 주변의 조명 상태에 아주 많은 영향을 받아서 주름 모양을 인식할 수 있는 이 미지를 획득하는 것이 쉽지 않다. 또한, 일정한 수준의 해상도를 유지하기 어렵고 각도 및 포즈에 따른 인증율 이 낮아지는 문제도 생긴다. 접촉방식으로는 프리즘을 이용하여 광학적인 방법으로 비문 이미지를 획득하는 것이다. 이 방식은 지문 인식에 사용하는 광학식 지문 획득 방식을 그대로 적용한 것이다. 광학식 비문 이미지 획득에서도 동물의 코가 젖어 있 는 상 태라는 점을 고려해야 한다. 이에 이를 이용하여 동물의 종 확인 또는 주인이 찾고자 하는 동물을 확인할 수 있는 방법은 동물의 체계적인 관리를 가능하게 할 수 있다. 다만 일반적인 사람의 지문인식 방법과, 동물의 비문인식 방법은 구체적인 인식방식 등의 차이가 있기 때문에 이를 위한 새로운 모델을 마련할 필요성이 있다."}
{"patent_id": "10-2023-0063411", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 2, "content": "상기의 배경기술로서 설명된 사항들은 본 발명의 배경에 대한 이해 증진을 위한 것을 뿐, 이 기술분야에서 통상 의 지식을 가진 자에게 이미 알려진 종래기술에 해당함을 인정하는 것으로 받아들여서는 안될 것이다.선행기술문헌 특허문헌 (특허문헌 0001) 대한민국 등록특허 제1494716호(2015. 02. 12. 등록) (특허문헌 0002) 대한민국 등록특허 제2466215호(2022. 11. 08. 등록)"}
{"patent_id": "10-2023-0063411", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명이 해결하고자 하는 과제는 인공지능 기반의 말 객체 식별 시스템 및 그 방법을 제공하는 것이다. 본 발명이 해결하고자 하는 과제들은 이상에서 언급된 과제로 제한되지 않으며, 언급되지 않은 또 다른 과제들 은 아래의 기재로부터 통상의 기술자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2023-0063411", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상술한 과제를 해결하기 위한 본 발명의 일 실시예에 따른 인공지능 기반의 말 객체 식별 방법은, 상기 방법은 서버에 의해 수행되는 인공지능 기반의 말 객체 식별 방법에 있어서, 빅데이터를 기반으로 반복학습하여 표준데 이터를 생성하는 단계; 대상체에 대한 촬영데이터로부터 이미지정보를 추출하는 단계; 상기 이미지정보를 비교 및 분석하여 대상체의 흰점을 식별하여 식별데이터를 생성하는 단계; 및 상기 표준데이터를 기초로 상기 식별데 이터를 비교 및 분석하여 대상체의 객체결과데이터를 생성하는 단계를 포함하고, 상기 식별데이터를 생성하는 단계는, 상기 이미지정보에 격자패턴을 매칭하여 흰점을 위치별, 크기별 및 형상별로 순차적으로 식별하는 단계 를 포함할 수 있다. 본 발명의 일 실시예에 있어서, 상기 식별데이터를 생성하는 단계는, 상기 촬영데이터가 사진인 경우, 상기 이 미지정보를 이용하여 대상체와 배경을 분리하여 대상체를 객체로 인식하는 단계; 상기 객체를 중심으로 바운더 리 영역을 검출하여 이미지별로 바운딩 박스를 설정하는 단계; 상기 바운딩 박스 내에 위치하는 상기 객체의 신 체부위에 대하여 위치별, 크기별 및 형상별로 격자패턴을 설정하는 단계; 및 위치별, 크기별 및 형상별로 분류 되어 식별된 상기 식별데이터를 생성하는 단계를 포함할 수 있다. 본 발명의 일 실시예에 있어서, 상기 식별데이터를 생성하는 단계는, 상기 바운딩 박스 내에 위치하는 상기 객 체의 신체부위에 대응하여 위치식별격자패턴을 설정하는 단계; 상기 위치식별격자패턴을 기초로 흰점의 위치를 식별하여 위치식별데이터를 생성하는 단계; 상기 바운딩 박스 내에 위치하는 상기 객체의 신체부위에 대응하여 크기식별격자패턴을 설정하는 단계; 상기 크기식별격자패턴을 기초로 흰점의 위치를 식별하여 크기식별데이터를 생성하는 단계; 상기 바운딩 박스 내에 위치하는 상기 객체의 신체부위에 대응하여 형상식별격자패턴을 설정하 는 단계; 및 상기 형상식별격자패턴을 기초로 흰점의 위치를 식별하여 형상식별데이터를 생성하는 단계를 포함 하고, 상기 위치식별격자패턴의 크기는 상기 크기식별격자패턴보다 크고, 상기 크기식별격자패턴의 크기는 상기 형상식별격자패턴보다 크게 형성될 수 있다. 본 발명의 일 실시예에 있어서, 상기 식별데이터를 생성하는 단계는, 상기 위치식별격자패턴을 기초로 대상체의 머리를 이마가마영역, 콧등가마영역 및 코·입술영역으로 구분하는 단계; 이마가마영역에 흰점이 있는 경우, 흰 점의 위치를 머리부위로 식별하는 단계; 콧등가마영역에 흰점이 있는 경우, 흰점의 위치를 콧등부위로 식별하는 단계; 코영역에 흰점이 있는 경우, 흰점의 위치를 코부위로 식별하는 단계; 및 이마가마영역, 콧등가마영역 및 코영역이 혼합된 혼합영역에 혼합된 흰점이 있는 경우, 흰점의 위치를 이마·콧등·코부위로 식별하는 단계를 포함할 수 있다. 본 발명의 일 실시예에 있어서, 상기 식별데이터를 생성하는 단계는, 기설정된 기준범위를 기준으로 상기 크기 식별격자패턴을 기초로 머리부위, 콧등부위, 코부위 및 이마·콧등·코부위에 대응하는 위치별로 식별된 흰점의 크기를 식별하는 단계를 포함하고, 상기 흰점의 크기를 식별하는 단계는, 머리부위에 흰점이 있는 경우, 제1 기 준범위(엄지첫마디)를 기준으로 상기 크기식별격자패턴의 폭이 작으면 흰점의 크기를 작게 식별하고, 제2 기준 범위(주먹)를 기준으로 상기 크기식별격자패턴의 폭이 크면 흰점의 크기를 크게 식별하는 단계; 콧등부위에 흰 점이 있는 경우, 제1 기준범위(엄지첫마디)를 기준으로 상기 크기식별격자패턴의 폭이 작으면 흰점의 크기를 작게 식별하고, 제3 기준범위(코뼈)를 기준으로 상기 크기식별격자패턴의 폭이 크면 흰점의 크기를 크게 식별하는 단계; 및 코부위에 흰점이 있는 경우, 제1 기준범위(엄지첫마디)를 기준으로 상기 크기식별격자패턴의 폭이 작 으면 흰점의 크기를 작게 식별하고, 제3 기준범위(코뼈)를 기준으로 상기 크기식별격자패턴의 폭이 크면 흰점의 크기를 크게 식별하는 단계를 포함할 수 있다. 본 발명의 일 실시예에 있어서, 상기 식별데이터를 생성하는 단계는, 기설정된 기준범위를 기준으로 상기 형상 식별격자패턴을 기초로 머리부위, 콧등부위, 코부위 및 이마·콧등·코부위에 대응하는 위치별 및 크기별로 식 별된 흰점의 형상을 식별하는 단계를 포함하고, 상기 흰점의 형상을 식별하는 단계는, 머리부위에 흰점이 있는 경우, 상기 형상식별격자패턴에 도출되는 라인의 개수, 공백의 크기 및 채움의 크기를 식별하는 단계; 콧등부위 에 흰점이 있는 경우, 상기 형상식별격자패턴에 도출되는 라인의 개수, 공백의 크기 및 채움의 크기를 식별하는 단계; 코부위에 흰점이 있는 경우, 상기 형상식별격자패턴에 도출되는 라인의 개수, 공백의 크기 및 채움의 크 기를 식별하는 단계; 및 이마·콧등·코부위에 흰점이 있는 경우, 상기 형상식별격자패턴에 도출되는 라인의 개 수, 공백의 크기 및 채움의 크기를 식별하는 단계를 포함할 수 있다. 본 발명의 일 실시예에 있어서, 상기 식별데이터를 생성하는 단계는, 흰점을 머리부위, 콧등부위, 코부위 및 이 마·콧등·코부위에 대응하는 위치별로 식별하고, 위치별로 식별된 흰점을 머리부위에서 성(星), 소성(小星), 대성(大星), 유성(流星), 소유성(小流星) 및 대유성(大流星)에 대응하는 크기별로 분류하고, 위치별로 식별된 흰점을 콧등부위에서 비량세백(鼻梁細白), 비량대백(鼻梁大白) 및 비량백(鼻梁白)에 대응하는 크기별로 분류하 여 식별하고, 위치별로 식별된 흰점을 코부위에서 비소백(鼻小白), 비대백(鼻大白) 및 비백(鼻白)에 대응하는 크기별로 분류하여 식별하고, 위치별로 식별된 흰점을 머리부위에서 곡성(曲星), 환성(環星), 난성(亂星), 곡유 성(曲流星), 환유성(環流星), 난유성(亂流星)에 대응하는 형상별로 분류하여 식별하고, 위치별로 식별된 흰점을 콧등부위에서 환비량백(環鼻梁白)에 대응하는 형상별로 분류하여 식별하고, 위치별로 식별된 흰점을 코부위에서 환비백(環鼻白)에 대응하는 형상별로 분류하여 식별하고, 위치별로 식별된 흰점을 이마이마·콧등·코부위에서 유성·비량세백, 유성·비량백, 대유성·비량백, 유성·비백, 비량백·비백, 유성·비량대백·비량백·비백, 대 유성·비량백·비량대백·비백, 대유성·비량백·비대백, 대유성·비량대백·비대백, 유성·단비량백·비백, 유 성·단비량백·비대백, 곡대유성·비량백·단비백, 유성·단비량백·단비백, 환대유성·비량새치·비량대백·비 량새치·비소백, 환대유성·환비량대백·비백 및 백면에 대응하는 형상별로 분류하여 식별할 수 있다. 본 발명의 일 실시예에 있어서, 상기 식별데이터를 생성하는 단계는, 상기 촬영데이터가 동영상인 경우 프레임 별로 이미지를 추출하여 프레임별 이미지정보를 생성하는 단계; 상기 프레임별 이미지 정보에 포함된 대상체와 배경을 분리하여 대상체를 객체로 인식하는 단계; 상기 객체를 중심으로 바운더리 영역을 검출하여 이미지별로 바운딩 박스를 설정하는 단계; 상기 바운딩 박스 내에 위치하는 상기 객체의 신체부위에 위치별, 크기별 및 형 상별로 격자패턴을 설정하는 단계; 및 위치별, 크기별 및 형상별로 분류되어 식별된 상기 식별데이터를 생성하 는 단계를 포함할 수 있다. 본 발명의 일 실시예에 있어서, 상기 식별데이터를 생성하는 단계는, 대상체의 흰점을 다리부위에 대응하는 위 치별로 식별하고, 위치별로 식별된 흰점을 다리부위에서 소백(小白), 반백(半白), 백(白), 장반백(長半白) 및 장백(長白)에 대응하는 크기별 및 형상별로 분류하여 식별하여 다리식별데이터를 생성하는 단계; 및 대상체의 입술부위에 대응하는 위치별로 식별하고, 위치별로 식별된 입술점을 입술부위에서 상순백(上脣白), 상순대백(上 脣大白), 상순소백(上脣小白), 하순백(下脣白), 하순대백(下脣大白), 및 하순소백(下脣小白)에 대응하는 크기 및 형상별로 분류하여 입술식별데이터를 생성하는 단계를 더 포함할 수 있다. 또한, 상술한 과제를 해결하기 위한 본 발명의 다른 일실시예에 따른 인공지능 기반의 말 객체 식별 시스템은, 인공지능 기반의 말 객체 식별 시스템에 있어서, 검사하고자 하는 대상체로부터 촬영데이터를 획득하는 사용자 단말기; 및 빅데이터를 기반으로 반복학습하여 표준데이터를 생성하고, 대상체에 대한 상기 촬영데이터로부터 이미지정보를 추출하며, 이미지정보를 비교 및 분석하여 대상체의 흰점을 식별하여 식별데이터를 생성하고, 상 기 표준데이터를 기초로 상기 식별데이터를 비교 및 분석하여 대상체의 객체결과데이터를 생성하는 관리서버;를 포함하고, 상기 관리서버는, 상기 이미지정보에 격자패턴을 매칭하여 흰점을 위치별, 크기별 및 형상별로 순차 적으로 식별하는 추출하여 상기 식별데이터를 생성할 수 있다. 본 발명의 일실시예에 따른 프로그램은 하드웨어인 컴퓨터와 결합되어, 상기 인공지능 기반의 말 객체 식별 방 법을 수행할 수 있도록 컴퓨터에서 독출가능한 컴퓨터에서 독출가능한 기록매체에 저장된다. 본 발명의 기타 구체적인 사항들은 상세한 설명 및 도면들에 포함되어 있다."}
{"patent_id": "10-2023-0063411", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명에 따르면, 인공지능을 기반으로 동물로부터 획득한 흰점의 위치, 크기 및 형상을 순차적으로 판단하여 말을 자동으로 객체식별할 수 있다. 본 발명에 따르면, 인공지능을 기반으로 자동으로 동물을 객체식별함으로써, 육안이미지로만 판단하는 경우 발 생할 수 있는 객체식별의 오류를 방지할 수 있다."}
{"patent_id": "10-2023-0063411", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 2, "content": "본 발명의 효과들은 이상에서 언급된 효과로 제한되지 않으며, 언급되지 않은 또 다른 효과들은 아래의 기재로 부터 통상의 기술자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2023-0063411", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명의 이점 및 특징, 그리고 그것들을 달성하는 방법은 첨부 함께 상세하게 후술되어 있는 실시예들을 참조 하면 명확해질 것이다. 그러나, 본 발명은 이하에서 개시되는 실시예들에 제한되는 것이 아니라 서로 다른 다양 한 형태로 구현될 수 있으며, 단지 본 실시예들은 본 발명의 개시가 완전하도록 하고, 본 발명이 속하는 기술 분야의 통상의 기술자에게 본 발명의 범주를 완전하게 알려주기 위해 제공되는 것이며, 본 발명은 청구항의 범 주에 의해 정의될 뿐이다. 본 명세서에서 사용된 용어는 실시예들을 설명하기 위한 것이며 본 발명을 제한하고자 하는 것은 아니다. 본 명 세서에서, 단수형은 문구에서 특별히 언급하지 않는 한 복수형도 포함한다. 명세서에서 사용되는 \"포함한다 (comprises)\" 및/또는 \"포함하는(comprising)\"은 언급된 구성요소 외에 하나 이상의 다른 구성요소의 존재 또는 추가를 배제하지 않는다. 명세서 전체에 걸쳐 동일한 도면 부호는 동일한 구성 요소를 지칭하며, \"및/또는\"은 언급된 구성요소들의 각각 및 하나 이상의 모든 조합을 포함한다. 비록 \"제1\", \"제2\" 등이 다양한 구성요소들을 서술하기 위해서 사용되나, 이들 구성요소들은 이들 용어에 의해 제한되지 않음은 물론이다. 이들 용어들은 단 지 하나의 구성요소를 다른 구성요소와 구별하기 위하여 사용하는 것이다. 따라서, 이하에서 언급되는 제1 구성 요소는 본 발명의 기술적 사상 내에서 제2 구성요소일 수도 있음은 물론이다.다른 정의가 없다면, 본 명세서에서 사용되는 모든 용어(기술 및 과학적 용어를 포함)는 본 발명이 속하는 기술 분야의 통상의 기술자에게 공통적으로 이해될 수 있는 의미로 사용될 수 있을 것이다. 또한, 일반적으로 사용되 는 사전에 정의되어 있는 용어들은 명백하게 특별히 정의되어 있지 않는 한 이상적으로 또는 과도하게 해석되지 않는다. 이하, 첨부된 도면을 참조하여 본 발명의 실시예를 상세하게 설명한다. 도 1은 본 발명의 일실시예에 따른 인공지능 기반의 말 객체 식별 시스템을 설명하기 위한 개념도이고, 도 2는 도 1에 도시된 인공지능 기반의 말 객체 식별 시스템의 상세 구성을 설명하기 위한 도면이며, 도 3은 본 발명의 일실시예에 따른 위치식별데이터를 생성하는 방법을 설명하기 위한 도면이고, 도 4는 본 발명의 일실시예에 따 른 머리부위로 분류되는 흰점을 설명하기 위한 도면이며, 도 5는 본 발명의 일실시예에 따른 콧등부위로 분류되 는 흰점을 설명하기 위한 도면이고, 도 6은 본 발명의 일실시예에 따른 코부위로 분류되는 흰점을 설명하기 위 한 도면이며, 도 7은 본 발명의 일실시예에 따른 이마·콧등·코부위로 분류되는 흰점을 설명하기 위한 도면이 고, 도 8은 본 발명의 일실시예에 따른 크기식별데이터를 생성하는 방법을 설명하기 위한 도면이며, 도 9는 본 발명의 일실시예에 따른 형상식별데이터를 생성하는 방법을 설명하기 위한 도면이고, 도 10은 본 발명의 일실시 예에 따른 다리부위로 분류되는 흰점을 설명하기 위한 도면이며, 도 11은 본 발명의 일실시예에 따른 입술부위 로 분류되는 입술점을 설명하기 위한 도면이다. 도 1 및 도 2에 도시된 바와 같이, 본 발명의 일실시예인 인공지능 기반의 말 객체 식별 시스템은 사용자 단 말기, 관리서버 및 관리자 단말기를 포함할 수 있다. 이때, 관리자 단말기는 생략될 수 있다. 여기서, 사용자 단말기, 관리서버 및 관리자 단말기는 무선통신망을 이용하여 실시간으로 동기화되 어 데이터를 송수신할 수 있다. 무선통신망은 다양한 원거리 통신 방식이 지원될 수 있으며, 예를 들어 무선랜 (Wireless LAN: WLAN), DLNA(Digital Living Network Alliance), 와이브로(Wireless Broadband: Wibro), 와이 맥스(World Interoperability for Microwave Access: Wimax), GSM(Global System for Mobile communication), CDMA(Code Division Multi Access), CDMA2000(Code Division Multi Access 2000), EV-DO(Enhanced Voice-Data Optimized or Enhanced Voice-Data Only), WCDMA(Wideband CDMA), HSDPA(High Speed Downlink Packet Access), HSUPA(High Speed Uplink Packet Access), IEEE 802.16, 롱 텀 에볼루션(Long Term Evolution: LTE), LTEA(Long Term Evolution-Advanced), 광대역 무선 이동 통신 서비스(Wireless Mobile Broadband Service: WMBS), BLE(Bluetooth Low Energy), 지그비(Zigbee), RF(Radio Frequency), LoRa(Long Range) 등과 같은 다양한 통신 방식이 적용될 수 있으나 이에 한정되지 않으며 널리 알려진 다양한 무선통신 또는 이동통신 방식이 적용될 수도 있다. 우선, 본 실시예에서, 인공지능 기반의 말 객체 식별 시스템을 이용하여 대상체 예를 들어, 동물 특히, 말로 한정하여 동물의 신체를 촬영하고, 흰점을 위치별, 크기별 및 형상별로 분류하여 대상체를 식별하는 것으로 개 시하였지만, 이에 한정하지 않는다. 예를 들어, 보호자 또는 반려인 또는 보호자와 함께 생활하는 포유류, 조류, 파충류, 양서류, 어류 등과 같은 척추동물, 절지동물, 연체동물과 같은 무척추동물 등을 포함하는 다양한 동물을 객체로 인식하여 동물의 기본 종류 및 세부 종류로 분류하여 식별할 수 있다. 사용자 단말기는 대상체의 보호자가 소지한 휴대 가능한 단말기로써, 본 개시에서 응용 프로그램 (application program 또는 애플리케이션(application))을 이용하여 동작할 수 있으며, 이러한 응용 프로그램은 무선통신을 통해 외부서버 또는 관리서버로부터 다운로드 될 수 있다. 예를 들어, 사용자 단말기는 스 마트폰(Smart phone), PDA(Personal Digital Assistant), 테블릿(Tablet), 웨어러블 디바이스(Wearable Device, 예를 들어, 워치형 단말기(Smartwatch), 글래스형 단말기(Smart Glass), HMD(Head Mounted Display)등 포함) 및 각종 IoT(Internet of Things) 단말과 같은 다양한 단말을 포함할 수 있지만 이에 한정하는 것은 아니 다. 이와 같은 사용자 단말기는 대상체의 움직임을 인식하여 촬영한 촬영데이터를 획득할 수 있다. 예를 들어, 촬영데이터는 얼굴, 다리 등의 신체인식이 필요한 대상체인 대상체의 얼굴의 정면 방향으로 촬 영된 사진과 같은 이미지파일일 수 있다. 이와 달리 촬영데이터가 동영상일 수 있고, 동영상파일인 경우, 최소 10초 이상의 동영상일 수 있다. 이때, 동영상파일은 대상체의 움직임을 정면, 측면 또는 후면에서 동일한 방향으로 촬영할 수 있다.실시예에 따라, 사용자 단말기는 주변환경, 흔들림, 움직임 속도, 모색 등을 고려하여 자동으로 촬영데이터 의 밝기 및 선명도 등을 조절할 수 있다. 또한, 사용자 단말기는 촬영데이터를 실시간으로 관리서버로 전송할 수 있다. 실시예에 따라, 사용자 단말기는 별도의 저장매체를 통해 저장된 촬영데이터를 관리서버로 전송할 수 있다. 또한, 사용자 단말기는 대상체의 촬영데이터와 매칭되는 대상체의 기초정보를 관리서버로 전송 할 수 있다. 기초정보에는 병원기록정보, 고유식별번호, 성별, 나이, 몸무게, 임신유무, 출산유무, 경주유무, 중성화유무 및 보호자정보가 포함될 수 있고, 병원기록정보는 예방접종정보, 진료정보, 알러지유무 및 미용정보 등을 포함할 수 있다. 실시예에 따라, 대상체의 기초정보는 별도의 서버로부터 제공받을 수 있다. 또한, 사용자 단말기는 촬영데이터에 대응하는 객체결과데이터를 수신하여 출력할 수 있다. 이때, 객체결과데이터는 표준데이터를 기초로 촬영데이터를 이용하여 대상체을 객체식별한 결과가 포함된 데이터일 수 있다. 여기서, 즉, 객체결과데이터는 대상체의 흰점 및 입술점의 위치, 크기 및 형상을 고려하 여 대상체을 명확히 인지할 수 있는 데이터가 포함될 수 있다. 이때, 대상체의 흰점은 대상체의 머리 및 다리에 위치하며 뚜렷이 밀집나게 난 흰털을 뜻하고, 말의 입술점은 대상체의 입술 및 콧구멍 주변에 위치하며 입술주변 핑크색 같은 반점무늬를 뜻할 수 있다. 실시예에 따라, 객체결과데이터는 대상체의 말의 모색(毛色) 및 특정검사 또는 혈액형감정 등을 고려하거나, 새치(흰점보다 밀도가 드믄 흰털의 모임), 가마(털의 흐름이 정상적인 방향을 바꾸면서 불규칙적으 로 고정된 상태), 기타점(흰점 및 새치이와의 색깔을 띤 반점), 함몰(근육이 움푹 꺼져 들어간 형태), 흉터(원 상회복이 불가능하다고 판단되는 상처 자국), 낙인 또는 문신(마체에 인위적으로 기호, 문자, 심볼 등을 표시) 등을 고려하여 대상체의 객체식별이 판단된 데이터가 포함될 수 있다. 실시예에 따라, 객체결과데이터에는 대상체의 건강이상유무에 대한 질환별 진행단계 등을 포함할 수 있다. 또한, 사용자 단말기는 객체 식별 서비스를 사용 후 또는 사용 중에 객체 식별 서비스에 대한 피드백신호를 생성하여 관리서버로 전송할 수 있다. 이와 달리, 사용자 단말기는 객체 식별 서비스를 사용하기 전에 도 전송할 수 있다. 실시예에 따라, 사용자 단말기는 피드백신호에 대응하는 제어신호를 객체 식별 서비스를 사용 전, 사용 중, 또는 사용후에 관리서버로부터 실시간으로 수신할 수 있다. 이때, 피드백신호에는 촬영데이터에 대응하는 객체 식별 서비스의 객체결과데이터에 대한 만족도, 정확도, 신뢰 도 등의 정보가 포함될 수 있고, 제어신호는 피드백신호에 대응하는 객체 식별 서비스의 개선 또는 업데이트된 정보가 포함될 수 있다. 여기서, 제어신호에는 이벤트정보가 포함될 수 있다. 이벤트정보는 광고가 포함되거나, 객체 식별 서비스에 대한 할인 또는 행사에 대한 정보가 포함될 수 있지만, 이에 한정하지 않는다. 또한, 사용자 단말기는 관리서버로부터 최초의 촬영데이터를 전송한 후, 객체결과데이터를 수신하기 전 에 촬영데이터에 관련된 추가데이터를 요청받는 경우, 추가데이터에 대한 추가촬영데이터를 관리서버로 전 송하고, 추가촬영데이터에 대응하는 추가결과데이터가 반영된 객체결과데이터를 관리서버로부터 수신할 수 있다. 실시예에 따라, 사용자 단말기는 추가촬영데이터만 반영된 객체결과데이터를 수신하거나, 추가촬영데이터가 반영되지 않는 객체결과데이터만을 수신할 수도 있다. 여기서, 사용자 단말기는 관리서버를 통해 객체 식별 서비스를 제공받는 경우, 별도의 결제서버(미도시) 또는 관리서버로부터 제공되는 결제서비스를 통해 결제절차가 이루어지는 것은 바람직하 다. 결제절차는 공지 기술이므로 생략한다. 또한, 사용자 단말기는 관리서버와 객체 식별 서비스를 수행하기 위해 사용자정보를 이용하여 회원가입 을 선 진행할 수 있지만, 이에 한정하지 않고 일회성 아이디를 이용하여 객체 식별 서비스를 이용할 수도 있다.실시예에 따라, 사용자 단말기는 표준데이터를 기초로 촬영데이터를 비교 및 분석하여 객체결과데이터를 생 성할 수 있다. 또한, 사용자 단말기는 사용자 단말기에서 구동되는 다수의 응용 프로그램(application program 또는 애플리케이션(application)), 사용자 단말기의 동작을 위한 데이터들, 명령어들을 저장할 수 있다. 이러한 응용 프로그램 중 적어도 일부는, 무선통신을 통해 외부 서버로부터 다운로드 될 수 있다. 다시 말하면, 사용자 단말기는 휴대 가능한 단말기를 이용하여 시간 및 장소에 상관없이 비대면으로 대상체 의 객체식별에 대한 객체결과데이터를 실시간으로 수신할 수 있다. 이에 따라, 대상체의 객체식별을 정 확하게 파악함으로써, 사용자의 다양성을 존중하면서 편의성 및 신뢰성을 높일 수 있다. 관리서버는 데이터송수신부, 데이터베이스부, 모니터링부 및 관리제어부를 포함할 수 있다. 데이터송수신부는 사용자 단말기 및 관리자 단말기와 데이터를 송수신할 수 있다. 데이터베이스부는 무선통신망을 통해 사용자 단말기 및 관리자 단말기와 송수신되는 데이터를 저 장할 수 있다. 이때, 표준데이터는 객체결과데이터에 대응하여 실시간으로 업데이트되어 저장될 수 있다. 데이터베이스부는 관리서버의 다양한 기능을 지원하는 데이터를 저장할 수 있다. 데이터베이스부(22 0)는 관리서버에서 구동되는 다수의 응용 프로그램(application program 또는 애플리케이션 (application)), 관리서버의 동작을 위한 데이터들, 명령어들을 저장할 수 있다. 이러한 응용 프로그램 중 적어도 일부는, 무선통신을 통해 외부 서버로부터 다운로드 될 수 있다. 모니터링부는 사용자 단말기의 동작상태, 관리서버의 동작상태, 그리고 사용자 단말기와 관리 서버 사이의 송수신되는 데이터 등을 화면을 통해 모니터링 할 수 있다. 즉, 사용자 단말기의 사용 상 태를 실시간으로 확인함으로써, 보호자의 사용을 편리하게 하여 보호자에게 더욱 신뢰감을 줄 수 있다. 관리제어부는 사용자 단말기로부터 대상체의 촬영데이터를 수신한 경우, 표준데이터를 기초로 객 체결과데이터를 생성할 수 있다. 구체적으로, 관리제어부는 촬영데이터가 사진인 경우, 사진으로부터 이미지정보를 추출할 수 있다. 예를 들어, 관리제어부는 촬영데이터를 자동으로 전처리하고, 전처리된 촬영데이터를 이용하여 이미지정보 를 추출할 수 있다. 실시예에 따라, 관리제어부는 이미지정보를 추출한 후, 이미지정보를 전처리할 수 있다. 이와 달리, 관리제어부는 촬영데이터가 동영상인 경우, 동영상 데이터를 전처리한 후, 프레임별로 이미지 정보를 추출할 수 있다. 실시예에 따라, 관리제어부는 프레임별로 이미지정보를 추출한 후, 이미지정보를 전처리할 수 있다. 실시예에 따라, 관리제어부는 별도의 서버 또는 데이터베이스에 저장된 촬영데이터를 이용하여 객체 결과데이터를 생성할 수 있다. 또한, 관리제어부는 전처리된 이미지정보를 이용하여 대상체와 배경을 분리하여 대상체를 객체로 인식한 후, 인식된 객체로부터 흰점을 식별하여 식별데이터를 생성할 수 있다. 구체적으로, 관리제어부는 인식된 객체를 중심으로 바운더리 영역을 검출하여 이미지별로 바운딩 박스 (Bounding Box, B)를 설정한 후, 바운딩 박스(B) 내에 위치하는 객체의 신체부위에 위치별, 크기별 및 형상별로 격자패턴(L)을 설정하고, 설정된 격자패턴(L)에 의해 흰점이 위치별, 크기별 및 형상별로 순차적으로 분류되어 식별된 흰점에 대한 식별데이터를 생성할 수 있다. 예를 들어, 관리제어부는 도 3에 도시된 바와 같이, 인식된 객체를 중심으로 바운더리 영역을 검출하여 이 미지별로 바운딩 박스(B)를 설정한 후(도 3(a) 참조), 바운딩 박스(B)에 매칭되는 위치식별격자패턴(L1)을 배치 하여 대상체의 머리를 이마가마영역(L11), 콧등가마영역(L12) 및 코·입술영역(L13)으로 구분하여 위치식별 데이터를 생성할 수 있다(도 3(b) 참조). 다시 말하면, 관리제어부는 위치식별격자패턴(L1)을 이용하여 바운딩 박스(B) 내에 위치하는 대상체의 이마가마영역(L11)을 머리부위로 식별하고, 콧등가마영역(L12)를 콧등부위로 식별하고, 코·입술영역(L13)을 코부위로 식별하고, 이마가마영역(L11), 콧등가마영역(L12) 및 코·입술영역(L13)이 합쳐진 합한영역(L14)을 이마 ·콧등·코부위로 식별하여 흰점에 대한 위치식별데이터를 생성할 수 있다. 예를 들어, 도 4에 도시된 바와 같이, 이마가마영역(L11) 즉, 머리부위에 위치하는 흰점의 종류에는 순서대로 성(星 ,폭이 엄지첫마디 머리보다 크고 주먹보다 작은 흰점), 소성(小星, 폭이 엄지첫마디 머리보다 작은 흰 점), 대성(大星, 폭이 주먹보다 큰 흰점), 곡성(曲星, 초생달처럼 휘어진 흰점), 환성(環星, 반지모양의 흰점), 난성(亂星, 윤곽이 불규칙하게 찌그러진 흰점), 유성(流星, 흰점이 콧등 쪽으로 흘러내린 것으로 폭이 엄지첫마 디 머리보다 크고 주먹보다 작은 흰점), 소유성(小流星, 폭이 엄지첫마디 머리보다 작은 흰점), 대유성(大流星, 폭이 주먹보다 큰 흰점), 곡유성(曲流星, 곡성과 유성이 혼합된 형태), 환유성(環流星, 환성과 유성이 혼합된 형태) 및 난유성(亂流星, 난성과 유성이 혼합된 형태)가 포함될 수 있지만, 이에 한정하지 않는다. 도 5을 참조하면, 콧등가마영역(L12) 즉, 콧등부위에 위치하는 흰점의 종류에는 순서대로 비량세백(鼻梁細白, 엄지첫마디 폭보다 가는 크기의 흰점, 비량대백(鼻梁大白, 코뼈의 폭보다 넓은 크기의 흰점, 비량백(鼻梁白, 엄 지첫마디 폭 이상 코뼈 폭 이하 크기의 흰점) 및 환비량백(環鼻梁白, 크기에 상관없이 반지 모양으로 생긴 콧등 점)이 포함될 수 있지만, 이에 한정하지 않는다. 도 6을 참조하면, 코·입술영역(L13) 즉, 코부위에 위치하는 흰점의 종류에는 비소백(鼻小白, 엄지첫마디 폭보 다 좁은 크기의 흰점), 비대백(鼻大白, 코뼈의 폭보다 넓은 크기의 흰점), 비백(鼻白, 엄지첫마디 폭 이상 코뼈 폭 이하 크기의 흰점) 및 환비백(環鼻白, 크기에 상관없이 반지 모양으로 생긴 콧점)이 포함될 수 있지만, 이에 한정하지 않는다. 도 7을 참조하면, 이마가마영역(L11), 콧등가마영역(L12) 및 코·입술영역(L13)이 합쳐진 합한영역(L14)을 즉, 이마·콧등·코부위에 위치하는 흰점의 종류에는 유성·비량세백(유성과 비량세백이 끊기지 않고 연결되어 있는 모양), 유성·비량백(유성과 비량백이 끊기지 않고 연결되어 있는 모양), 대유성·비량백(대유성과 비량백이 끊 이지 않고 연결되어 있는 모양), 유성·비백(유성과 비백사이에 흰점이 없이 유성과 비백이 각각 떨어져 있는 모양), 비량백·비백(비량백과 비백이 끊기지 않고 연결되어 있는 모양), 유성·비량대백·비량백·비백(유성, 비량대백, 비량백, 비백의 순으로 끊기지 않고 모두 연결되어 있는 모양), 대유성·비량백·비량대백·비백(대 유성, 비량백, 비량대백, 비백의 순으로 모두 연결되어 있는 모양), 대유성·비량백·비대백(대유성, 비량백, 비대백이 끊기지 않고 연결되어 있는 모양), 대유성·비량대백·비대백(대유성, 비량대백, 비대백이 끊기지 않 고 연결되어있는 모양), 유성·단비량백·비백(유성과 비량백은 끊어진 모양이고 비량백과 비백이 연결되어 있 는 모양), 유성·단비량백·비대백(유성과 비량백은 끊어진 모양이고 비량백과 비대백은 연결되어 있는 모양), 곡대유성·비량백·단비백(곡대유성과 비량백은 연결되어 있고 단비백은 끊어져 있는 모양), 유성·단비량백· 단비백(유성, 비량백, 비백이 연결되지 않고 각각 끊어져 있는 모양), 환대유성·비량새치·비량대백·비량새치 ·비소백(환대유성, 비량새치, 비량대백, 비량새치, 비소백의 순으로 연결되어 있는 모양), 환대유성·환비량대 백·비백(환대유성, 환비량대백, 비백의 순으로 연결되어 있는 모양) 및 백면(이마에서 입술까지 얼굴의 반 이 상에 걸쳐 흰점이 퍼져 있으며 그 폭이 양눈에 이름)이 포함될 수 있지만, 이에 한정하지 않는다. 또한, 도 8에 도시된 바와 같이, 인식된 객체를 중심으로 바운더리 영역을 검출하여 이미지별로 바운딩 박스 (B)를 설정한 후(도 8(a) 참조), 바운딩 박스(B)에 매칭되는 크기식별격자패턴(L2)을 배치하여 대상체에 위 치하는 흰점의 크기를 이마가마영역(L11), 콧등가마영역(L12), 코·입술영역(L13) 및 합한영역(L14)으로 구분하 여 크기식별데이터를 생성할 수 있다(도 8(b) 참조). 구체적으로, 관리제어부는 기설정된 기준범위를 기초로 이마가마영역(L11), 콧등가마영역(L12), 코·입술 영역(L13) 및 합한영역(L14)에 배치된 흰점의 크기가 크기식별격자패턴(L2)의 폭보다 큰 경우, 흰점의 크기를 크게 식별하고, 크기식별격자패턴(L2)의 폭보다 작은 경우, 흰점의 크기를 작게 식별할 수 있다. 다시 말하면, 관리제어부는 일반인 기준의 엄지첫마디 머리의 폭, 주먹의 폭, 코뼈의 폭을 기준으로 흰점 의 크기를 이마가마영역(L11), 콧등가마영역(L12), 코·입술영역(L13) 및 합한영역(L14)에서 식별하여 크기식별 데이터를 생성할 수 있다. 이때, 크기식별격자패턴(L2)은 위치식별격자패턴(L1)과 크기가 상이하고, 위치식별격자패턴(L1)의 크기보다 작 게 형성되는 것이 바람직하다. 크기식별격자패턴(L2)은 동일한 크기를 가지며 동일한 간격으로 위치식별격자패 턴(L1)과 겹쳐져서 균일하게 배치될 수 있지만, 이에 한정하지 않고 서로 상이한 크기로 비균일하게 배치될 수 있다. 예를 들어, 관리제어부는 머리부위에 흰점이 있는 경우, 제1 기준범위(엄지첫마디)를 기준으로 크기식별격 자패턴(L2)의 폭이 작으면 흰점의 크기를 작게 식별하고, 제2 기준범위(주먹)를 기준으로 크기식별격자패턴(L 2)의 폭이 크면 흰점의 크기를 크게 식별하여 성(星), 소성(小星), 대성(大星), 유성(流星), 소유성(小流星) 및 대유성(大流星)으로 크기식별데이터를 생성할 수 있다. 관리제어부는 콧등부위에 흰점이 있는 경우, 제1 기준범위(엄지첫마디)를 기준으로 크기식별격자패턴(L2) 의 폭이 작으면 흰점의 크기를 작게 식별하고, 제3 기준범위(코뼈)를 기준으로 크기식별격자패턴(L2)의 폭이 크 면 흰점의 크기를 크게 식별하여 비량세백(鼻梁細白), 비량대백(鼻梁大白) 및 비량백(鼻梁白)으로 크기식별데이 터를 생성할 수 있다. 관리제어부는 코부위에 흰점이 있는 경우, 제1 기준범위(엄지첫마디)를 기준으로 크기식별격자패턴(L2)의 폭이 작으면 흰점의 크기를 작게 식별하고, 제3 기준범위(코뼈)를 기준으로 크기식별격자패턴(L2)의 폭이 크면 흰점의 크기를 크게 식별하여 비소백(鼻小白), 비대백(鼻大白) 및 비백(鼻白)으로 크기식별데이터를 생성할 수 있다. 또한, 도 9에 도시된 바와 같이, 인식된 객체를 중심으로 바운더리 영역을 검출하여 이미지별로 바운딩 박스 (B)를 설정한 후(도 9(a) 참조), 바운딩 박스(B)에 매칭되는 형상식별격자패턴(L3)을 배치하여 대상체에 위 치하는 흰점의 형상을 이마가마영역(L11), 콧등가마영역(L12), 코·입술영역(L13) 및 합한영역(L14)으로 구분하 여 형상식별데이터를 생성할 수 있다(도 9(b) 참조). 구체적으로, 관리제어부는 형상식별격자패턴(L3)를 기준으로 형상식별격자패턴(L3)에 인식되는 곡선라인의 개수, 공백의 크기 및 채움의 크기를 분석하여 흰점의 형상을 이마가마영역(L11), 콧등가마영역(L12), 코·입술 영역(L13) 및 합한영역(L14)에서 식별하여 형상식별데이터를 생성할 수 있다. 이때, 형상식별격자패턴(L3)은 위치식별격자패턴(L1) 및 크기식별격자패턴(L2)과 크기가 상이하고, 위치식별격 자패턴(L1) 및 크기식별격자패턴(L2)의 크기보다 작게 형성되는 것이 바람직하다. 형상식별격자패턴(L3)은 상이 한 크기를 가지며 비균일한 간격으로 위치식별격자패턴(L1) 및 크기식별격자패턴(L2)과 겹쳐져서 배치될 수 있 지만, 이에 한정하지 않고 서로 동일한 크기로 균일하게 배치될 수 있다. 예를 들어, 관리제어부는 머리부위에 흰점이 있는 경우, 형상식별격자패턴(L3)에 인식되는 곡선라인의 개 수, 공백의 크기 및 채움의 크기를 식별하여 곡성(曲星), 환성(環星), 난성(亂星), 곡유성(曲流星), 환유성(環 流星), 난유성(亂流星)으로 형상식별데이터를 생성할 수 있다. 다시 말하면, 관리제어부는 객체에 겹쳐지는 형상식별격자패턴(L3) 내에 인식되는 곡선라인 또는 직선라인 의 개수와, 형상식별격자패턴(L3) 내에 인식되는 흰점이 없는 공백의 크기와, 형상식별격자패턴(L3) 내에 인식 되는 흰점이 채워지는 채움의 크기를 표준데이터를 기초로 분석하여 흰점의 형상에 대한 형상식별데이터를 생성 할 수 있다. 관리제어부는 콧등부위에 흰점이 있는 경우, 형상식별격자패턴(L3)에 인식되는 곡선라인의 개수, 공백의 크기 및 채움의 크기를 식별하여 환비량백(環鼻梁白)으로 형상식별데이터를 생성할 수 있다. 관리제어부는 코부위에 흰점이 있는 경우, 형상식별격자패턴(L3)에 인식되는 곡선라인의 개수, 공백의 크 기 및 채움의 크기를 식별하여 환비백(環鼻白)으로 형상식별데이터를 생성할 수 있다. 관리제어부는 이마·콧등·코부위에 흰점이 있는 경우, 형상식별격자패턴(L3)에 인식되는 곡선라인의 개수, 공백의 크기 및 채움의 크기를 식별하여 유성·비량세백, 유성·비량백, 대유성·비량백, 유성·비백, 비 량백·비백, 유성·비량대백·비량백·비백, 대유성·비량백·비량대백·비백, 대유성·비량백·비대백, 대유성 ·비량대백·비대백, 유성·단비량백·비백, 유성·단비량백·비대백, 곡대유성·비량백·단비백, 유성·단비량 백·단비백, 환대유성·비량새치·비량대백·비량새치·비소백, 환대유성·환비량대백·비백 및 백면으로 형상식 별데이터를 생성할 수 있다. 또한, 관리제어부는 표준데이터를 기초로 식별데이터를 비교 및 분석하여 객체결과데이터를 생성할 수 있 다. 구체적으로, 관리제어부는 표준데이터를 기초로 대상체의 흰점이 인식된 식별데이터를 이용하여 객체 결과데이터를 생성할 수 있다. 또한, 관리제어부는 표준데이터를 생성할 수 있다. 구체적으로, 관리제어부는 인공지능 기반으로 빅데이터를 이용하여 표준데이터를 생성할 수 있다. 본 실시 예에서 딥러닝을 이용하는 것으로 기재하였지만, 이에 한정하지 않고 랜덤 포레스트(Random Forest), 서포트 벡 터 머신(Support Vector Machine) 등의 머신러닝 기법을 이용할 수 있다. 이때, 관리제어부는 객체결과데 이터에 대응하여 실시간으로 표준데이터를 업데이트할 수 있다. 예를 들어, 관리제어부는 빅데이터를 CNN(Convolutional Neural Network) 알고리즘을 기초로 반복 학습하 여 적합성을 검증하여 표준데이터를 생성할 수 있다. 또한, 관리제어부는 대상체의 얼굴부위뿐만 아니라 다리부위에 위치하는 흰점을 위치별, 크기별 및 형 상별로 분류하여 식별하여 다리식별데이터를 생성할 수 있다. 구체적으로, 관리제어부는 인식된 객체를 중심으로 바운더리 영역을 검출하여 이미지별로 바운딩 박스(B) 를 설정한 후, 바운딩 박스(B) 내에 위치하는 객체의 다리부위에 위치별, 크기별 및 형상별로 격자패턴(L)을 설 정하고, 설정된 격자패턴(L)에 의해 흰점이 위치별, 크기별 및 형상별로 순차적으로 분류되어 식별된 흰점에 대 한 다리식별데이터를 생성할 수 있다. 예를 들어, 관리제어부는 도 10을 참조하면, 순서대로 다리부위에 위치하는 흰점의 종류에는 소백(小白, 제관부에 난 흰점으로서, 그 크기(폭)는 제관부의 반 바퀴 이하인 것), 반백(半白, 구절상단 이하에 난 흰점으 로서, 소백보다는 크지만 어떤 부위에서도 그 둘레가 완전히 흰점으로 감싸여 있지 않고 끊어져 있는 것), 백 (白, 구절상단 이하에 난 흰점으로서, 최소한 어느 한부위의 둘레는 흰점으로 완전히 감싸여 있는 것), 장반백 (長半白, 흰점이 구절상단 이상의 부위까지 미치지만, 어느 부위에서도 그 둘레가 완전히 흰점으로 감싸여 있지 않고 끊어져 있는 것) 및 장백(長白, 흰점이 구절상단을 완전히 감싸고 그 이상에까지 미치는 것)이 포함될 수 있지만, 이에 한정하지 않는다. 또한, 관리제어부는 대상체의 얼굴부위뿐만 아니라 입술부위에 위치하는 입술점을 위치별, 크기별 및 형상별로 분류하여 식별하여 입술식별데이터를 생성할 수 있다. 구체적으로, 관리제어부는 인식된 객체를 중심으로 바운더리 영역을 검출하여 이미지별로 바운딩 박스(B) 를 설정한 후, 바운딩 박스(B) 내에 위치하는 객체의 입술부위에 위치별, 크기별 및 형상별로 격자패턴(L)을 설 정하고, 설정된 격자패턴(L)에 의해 입술점이 위치별, 크기별 및 형상별로 순차적으로 분류되어 식별된 입술점 에 대한 입술식별데이터를 생성할 수 있다. 예를 들어, 관리제어부는 도 11을 참조하면, 순서대로 입술부위에 위치하는 입술점의 종류에는 상순백(上 脣白, 엄지첫마디 폭보다는 넓고 코뼈 폭보다는 좁음), 상순대백(上脣大白, 코뼈폭보다 넓음), 상순소백(上脣小 白, 엄지첫마디 폭보다 좁음), 하순백(下脣白, 엄지첫마디 폭보다는 넓고 코뼈 폭보다는 좁음), 하순대백(下脣 大白, 코뼈 폭보다 넓음) 및 하순소백(下脣小白, 엄지첫마디 폭보다 좁음)이 포함될 수 있지만, 이에 한정하지 않는다. 또한, 관리제어부는 사용자 단말기로부터 최초의 촬영데이터를 수신한 후, 촬영데이터에 대응하는 객 체결과데이터를 생성하지 못하는 경우, 객체결과데이터를 전송하기 전에 사용자 단말기로 추가데이터를 전 송하고, 추가데이터에 대응하는 추가촬영데이터를 수신한 후, 표준데이터를 기초로 추가결과데이터를 생성할 수 있다. 예를 들어, 관리제어부는 사용자 단말기로부터 추가데이터에 대응하는 추가촬영데이터가 수신되면, 추 가촬영데이터를 기준으로 객체결과데이터를 생성할 수 있다. 이에 따라, 관리제어부는 추가촬영데이터에 대응하는 추가결과데이터가 반영된 결과데이터를 생성할 수 있다. 실시예에 따라, 관리제어부는 최초촬영데이터가 반영되지 않고 추가촬영데이터만 반영된 객체결과데이터를 생성하거나, 추가촬영데이터가 반영되지 않는 객체결과데이터를 생성할 수 있다. 실시예에 따라, 관리제어부는 최초촬영데이터가 반영되지 않고 추가촬영데이터만 반영된 객체결과데이터를 생성하거나, 추가촬영데이터가 반영되지 않는 객체결과데이터를 생성할 수 있다. 또한, 관리제어부는 사용자 단말기로부터 수신된 피드백신호에 대응하여 객체 식별 서비스를 개선할 수 있는 제어신호를 생성할 수 있다. 실시예에 따라, 관리제어부는 이벤트정보가 포함된 제어신호를 생성하여 사용자 단말기의 객체 식별 서비스의 사용을 증대시킬 수 있다. 실시예에 따라, 관리제어부는 사용자 단말기 및 관리자 단말기에서 표준데이터를 기초로 촬영데이 터를 비교 및 분석하여 객체결과데이터를 생성된 경우, 객체결과데이터를 수신할 수 있다. 이와 같은 구조의 관리서버는 복수의 대상체로부터 획득한 빅데이터를 반복 학습하여 검증된 표준데이 터를 기초로, 사용자 단말기를 통해 획득한 촬영데이터로부터 추출된 이미지를 비교 및 분석하여 대상체 에 위치하는 흰점을 위치별, 크기별 및 형상별로 순차적으로 판단하여 식별된 식별데이터를 이용하여 객체 결과데이터를 생성할 수 있다. 이에 따라, 대상체의 상태를 육안이미지로만 판단하는 경우 발생할 수 있는 객체식별의 오류를 방지할 수 있다. 이와 같은 관리서버는 하드웨어 회로(예를 들어, CMOS 기반 로직 회로), 펌웨어, 소프트웨어 또는 이들의 조합에 의해 구현될 수 있다. 예를 들어, 다양한 전기적 구조의 형태로 트랜지스터, 로직게이트 및 전자회로를 활용하여 구현될 수 있다. 관리자 단말기는 별도의 관리자가 소지한 단말기로써, 사용자 단말기 및 관리서버와 무선통신망을 이용하여 실시간으로 동기화되어 데이터를 송수신할 수 있다. 이때, 관리자 단말기는 응용 프로그램 (application program 또는 애플리케이션(application))을 이용하여 데이터를 송수신할 수 있다. 관리자 단말기는 관리서버로부터 수신된 표준데이터를 학습하여, 사용자 단말기로부터 수신받은 촬 영데이터를 분석하여 촬영데이터에 대응하는 객체결과데이터를 생성할 수 있다. 실시예에 따라, 관리자 단말기는 사용자 단말기로부터 촬영데이터를 수신하는 경우, 표준데이터를 기초 로 촬영데이터를 비교 및 분석하여 객체결과데이터를 생성할 수 있다. 실시예에 따라, 관리자 단말기는 사용자 단말기에서 객체결과데이터가 생성된 경우, 사용자 단말기(1 0)로부터 객체결과데이터를 수신받아 관리서버로 전송할 수 있다. 또한, 관리자 단말기는 관리서버에서 객체결과데이터가 생성된 경우, 관리서버로부터 객체결과데이 터를 수신받아 사용자 단말기로 전송할 수 있다. 이와 같은 관리자 단말기는 사용자 단말기 및 관리서버와의 통신을 지원하는 각종 휴대 가능한 전 자통신기기를 포함할 수 있다. 예를 들어, 별도의 스마트 기기로써, 스마트폰(Smart phone), PDA(Personal Digital Assistant), 테블릿(Tablet), 웨어러블 디바이스(Wearable Device, 예를 들어, 워치형 단말기 (Smartwatch), 글래스형 단말기(Smart Glass), HMD(Head Mounted Display)등 포함) 및 각종 IoT(Internet of Things) 단말과 같은 다양한 단말을 포함할 수 있지만 이에 한정하는 것은 아니다. 이와 같은 구조를 갖는 본 발명의 일실시예에 따른 인공지능 기반의 말 객체 식별 시스템의 동작은 다음과 같다. 도 12는 본 발명의 일실시예에 따른 인공지능 기반의 말 객체 식별 방법을 설명하기 위한 도면이고, 도 13은 도 12에 도시된 식별데이터를 생성하는 단계를 설명하기 위한 도면이며, 도 14는 도 13에 도시된 식별데이 터를 생성하는 단계를 설명하기 위한 도면이고, 도 15는 도 14에 도시된 위치별로 흰점을 인식하는 화면을 설명 하기 위한 도면이며, 도 16은 도 14에 도시된 크기별로 흰점을 인식하는 화면을 설명하기 위한 도면이고, 도 17 은 도 14에 도시된 형상별로 흰점을 인식하는 화면을 설명하기 위한 도면이다. 우선, 본 발명의 실시예에서 대상체을 말의 얼굴부위로 한정하여 개시하였지만, 이에 한정하지 않는다. 도 12에 도시된 바와 같이, 관리서버는 표준데이터를 생성할 수 있다(S10). 구체적으로, 관리서버는 복수의 대상체로부터 기초정보를 획득할 수 있다. 여기서, 기초정보에는 병원 기록정보, 고유식별번호, 성별, 나이, 몸무게, 임신유무, 출산유무, 경주유무, 중성화유무 및 보호자정보가 포 함될 수 있고, 병원기록정보는 예방접종정보, 진료정보, 알러지유무 및 미용정보 등을 포함할 수 있다. 실시예에 따라, 관리서버는 별도의 이동 단말기를 이용하여 대상체의 기초정보를 입력할 수 있다. 다음, 관리서버는 기초정보를 기초로 대상체의 신체를 촬영한 촬영정보를 획득할 수 있다. 실시예에 따 라, 관리서버는 별도의 촬영도구 또는 스캐너를 이용하여 대상체의 촬영정보를 획득할 수 있다. 이때, 관리서버는 사진 또는 동영상으로 이루어진 촬영데이터를 먼저 전처리할 수 있다. 다음, 관리서버는 촬영정보에 포함된 대상체을 객체로 인식하여 바운딩 박스(Bounding Box)를 설정한 후, 바운딩 박스(B) 내에 위치하는 객체의 신체부위에 위치별, 크기별 및 형상별로 격자패턴(L)을 설정하고, 설 정된 격자패턴(L)에 의해 흰점이 위치별, 크기별 및 형상별로 순차적으로 분류되어 식별된 흰점에 대한 식별데이터를 생성한 후, 식별데이터에 매칭되는 결과데이터를 객체결과데이터로 생성할 수 있다. 다음, 관리서버는 식별데이터 및 식별데이터와 매칭되는 객체결과데이터에 대한 검증 단계 및 보정 및 표준 화하여 표준데이터를 생성할 수 있다. 즉, 관리서버는 식별데이터와 객체결과데이터를 매칭하여, CNN 알고 리즘을 기초로 반복 학습함으로써, 적합성을 검증하여 표준데이터를 생성할 수 있다. 다음으로, 보호자가 대상체의 객체식별을 요청하는 경우, 관리서버는 사용자 단말기로부터 대상체 의 신체에 대한 촬영데이터를 획득할 수 있다(S12). 실시예에 따라, 사용자 단말기는 별도의 촬영 장비를 통해 대상체의 움직임에 대한 촬영데이터를 획득 할 수 있다. 이때, 촬영데이터는 객체식별이 필요한 대상체에 대하여 촬영된 사진 또는 10초 이상의 일관된 방향으로 촬 영된 동영상으로 이루어질 수 있다. 다음으로, 관리서버는 표준데이터를 기초로 촬영데이터에 대응하는 식별데이터를 생성할 수 있다(S14). 구체적으로, 도 13에 도시된 바와 같이, 관리서버는 사용자 단말기로부터 촬영데이터를 수신한 후 (S100), 촬영데이터가 사진인 경우(S110), 촬영데이터를 전처리하여 보정된 이미지를 추출할 수 있다(S120, S130). 구체적으로, 관리서버는 촬영데이터에 포함된 자동으로 밝기, 선명도 등이 보정된 사진에서 객체식별을 위 한 이미지정보를 추출할 수 있다. 실시예에 따라, 관리서버는 이미지정보를 추출한 후, 이미지정보를 전처리할 수 있다. 다음, 관리서버는 추출된 이미지정보를 비교 및 분석하여 대상체의 흰점을 식별하여 식별데이터를 생성 할 수 있다(S140). 구체적으로, 도 14에 도시된 바와 같이, 추출된 이미지정보를 이용하여 이미지별로 바운딩 박스(B)를 설정할 수 있다(S200). 구체적으로, 관리서버는 추출된 이미지정보로부터 대상체와 배경을 분리하여 대상체를 객체로 인식 한 후, 인식된 객체를 중심으로 바운더리 영역을 검출하여 프레임별로 바운딩 박스(B)를 설정할 수 있다. 다음, 관리서버는 바운딩 박스(B)에 매칭되는 위치식별격자패턴(L1)을 배치하여(S210), 위치별로 식별되는 흰점의 위치에 대한 위치식별데이터를 생성할 수 있다(S220). 예를 들어, 도 15를 참고하면, 관리서버는 설정된 바운딩 박스(B) 내에 위치하는 객체의 신체부위에 바운딩 박스(B)에 매칭되는 위치식별격자패턴(L1)을 설정한 후, 대상체의 머리를 이마가마영역(L11), 콧등가마영역 (L12), 코·입술영역(L13) 및 합한영역(L14)으로 구분하여 위치별로 식별되는 흰점의 데이터를 위치식별데이터 로 생성할 수 있다. 다음, 관리서버는 바운딩 박스(B)에 매칭되는 크기식별격자패턴(L2)을 배치하여(S230), 크기별로 식별되는 흰점의 크기에 대한 크기식별데이터를 생성할 수 있다(S240). 예를 들어, 도 16을 참고하면, 관리서버는 설정된 바운딩 박스(B) 내에 위치하는 객체의 신체부위에 바운딩 박스(B)에 매칭되는 크기식별격자패턴(L2)을 설정한 후, 기설정된 기준범위를 기초로 이마가마영역(L11), 콧등 가마영역(L12), 코·입술영역(L13) 및 합한영역(L14)에 배치된 크기별로 식별되는 흰점의 데이터를 크기식별데 이터로 생성할 수 있다. 다음, 관리서버는 바운딩 박스(B)에 매칭되는 형성식별격자패턴(L3)을 배치하여(S250), 형상별로 식별되는 흰점의 형상에 대한 형상식별데이터를 생성할 수 있다(S260). 예를 들어, 도 17을 참고하면, 관리서버는 설정된 바운딩 박스(B) 내에 위치하는 객체의 신체부위에 바운딩 박스(B)에 매칭되는 형상식별격자패턴(L3)을 설정한 후, 이마가마영역(L11), 콧등가마영역(L12), 코·입술영역 (L13) 및 합한영역(L14)에 배치된 형상별로 식별되는 흰점의 데이터를 형상식별데이터로 생성할 수 있다. 이와 달리, 촬영데이터가 동영상인 경우(S110), 관리서버는 10초 이상의 동영상을 프레임별로 이미지를 추 출하고(S150), 프레임별로 추출된 이미지정보를 전처리될 수 있다. 이때, 관리서버는 동영상으로 이루어진 촬영데이터를 주변환경, 흔들림, 움직임 속도 등을 고려하여 자동으 로 동영상의 밝기 및 선명도 등을 조절할 수 있다. 다음으로, 사용자 단말기는 관리서버로부터 표준데이터를 기초로 식별데이터를 비교 및 분석하여 대상 체의 객체결과데이터를 생성할 수 있다(S16). 여기서, 객체결과데이터는 표준데이터를 기초로 촬영데이터에 매칭되는 데이터로써, 텍스트, 동영상, 이미지, URL 주소, 음성 등 다양한 형식으로 촬영데이터에 대한 답변 정보가 포함될 수 있지만, 이에 한정하는 것은 아 니다. 다음으로, 사용자 단말기는 관리서버로부터 촬영데이터에 대응하는 객체결과데이터를 수신할 수 있다 (S18). 다음으로, 사용자 단말기는 촬영데이터에 대응하는 객체 식별 서비스를 제공받은 후, 해당 객체 식별 서비 스에 대한 피드백신호를 생성할 수 있다(S20). 실시예에 따라, 사용자 단말기는 관리서버로부터 수신된 객체결과데이터의 유사성과, 실제 제공받은 객 체 식별 서비스를 판단하여 피드백신호를 생성할 수 있다. 이때, 피드백신호에는 객체 식별 서비스에 대한 만족 도, 정확도, 신뢰도 등의 정보가 포함될 수 있다. 다음으로, 관리서버는 사용자 단말기로부터 수신된 피드백신호에 대응하여 객체 식별 서비스를 개선할 수 있는 제어신호를 생성할 수 있다(S22). 실시예에 따라, 관리서버는 이벤트정보가 포함된 제어신호를 생성하여 사용자 단말기의 객체 식별 서비 스의 사용을 증대시킬 수 있다. 실시예에 따라, 사용자 단말기는 피드백신호에 대응하여 객체 식별 서비스의 개선 또는 업데이트된 정보가 포함된 제어신호를 객체 식별 서비스를 사용 전, 사용중, 또는 사용후에 수신할 수 있다. 이때, 제어신호에는 이벤트정보가 포함될 수 있다. 이벤트정보는 광고가 포함되거나, 객체 식별 서비스에 대한 할인 또는 행사에 대 한 정보가 포함될 수 있지만, 이에 한정하지 않는다. 실시예에 따라, 관리자 단말기가 피드백신호에 대응하여 객체 식별 서비스를 개선할 수 있는 제어신호를 생 성할 수 있다. 다음으로, 관리서버는 객체결과데이터에 대응하여 실시간으로 표준데이터를 업데이트할 수 있다(S24). 실시예에 따라, 관리서버는 사용자 단말기로부터 수신된 피드백신호에 대응하여 표준데이터를 실시간으 로 업데이트할 수 있다. 마지막으로, 관리자 단말기는 객체 식별 서비스를 실시간으로 모니터링할 수 있다(S26). 본 발명의 실시예와 관련하여 설명된 방법 또는 알고리즘의 단계들은 하드웨어로 직접 구현되거나, 하드웨어에 의해 실행되는 소프트웨어 모듈로 구현되거나, 또는 이들의 결합에 의해 구현될 수 있다. 소프트웨어 모듈은 RAM(Random Access Memory), ROM(Read Only Memory), EPROM(Erasable Programmable ROM), EEPROM(Electrically Erasable Programmable ROM), 플래시 메모리(Flash Memory), 하드 디스크, 착탈형 디스크, CD-ROM 또는 본 발명이 속하는 기술 분야에서 잘 알려진 임의의 형태의 컴퓨터 판독가능 기록매체에 상 주할 수도 있다."}
{"patent_id": "10-2023-0063411", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "이상, 첨부된 도면을 참조로 하여 본 발명의 실시예를 설명하였지만, 본 발명이 속하는 기술분야의 통상의 기술 자는 본 발명이 그 기술적 사상이나 필수적인 특징을 변경하지 않고서 다른 구체적인 형태로 실시될 수 있다는 것을 이해할 수 있을 것이다. 그러므로, 이상에서 기술한 실시예들은 모든 면에서 예시적인 것이며, 제한적이 아닌 것으로 이해해야만 한다."}
{"patent_id": "10-2023-0063411", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일실시예에 따른 인공지능 기반의 말 객체 식별 시스템을 설명하기 위한 개념도이다. 도 2는 도 1에 도시된 인공지능 기반의 말 객체 식별 시스템의 상세 구성을 설명하기 위한 도면이다. 도 3은 본 발명의 일실시예에 따른 위치식별데이터를 생성하는 방법을 설명하기 위한 도면이다. 도 4는 본 발명의 일실시예에 따른 머리부위로 분류되는 흰점을 설명하기 위한 도면이다. 도 5는 본 발명의 일실시예에 따른 콧등부위로 분류되는 흰점을 설명하기 위한 도면이다. 도 6은 본 발명의 일실시예에 따른 코부위로 분류되는 흰점을 설명하기 위한 도면이다. 도 7은 본 발명의 일실시예에 따른 이마·콧등·코부위로 분류되는 흰점을 설명하기 위한 도면이다. 도 8은 본 발명의 일실시예에 따른 크기식별데이터를 생성하는 방법을 설명하기 위한 도면이다. 도 9는 본 발명의 일실시예에 따른 형상식별데이터를 생성하는 방법을 설명하기 위한 도면이다. 도 10은 본 발명의 일실시예에 따른 다리부위로 분류되는 흰점을 설명하기 위한 도면이다. 도 11은 본 발명의 일실시예에 따른 입술부위로 분류되는 입술점을 설명하기 위한 도면이다. 도 12는 본 발명의 일실시예에 따른 인공지능 기반의 말 객체 식별 방법을 설명하기 위한 도면이다. 도 13은 도 12에 도시된 식별데이터를 생성하는 단계를 설명하기 위한 도면이다. 도 14는 도 13에 도시된 식별데이터를 생성하는 단계를 설명하기 위한 도면이다. 도 15는 도 14에 도시된 위치별로 흰점을 인식하는 화면을 설명하기 위한 도면이다. 도 16은 도 14에 도시된 크기별로 흰점을 인식하는 화면을 설명하기 위한 도면이다. 도 17은 도 14에 도시된 형상별로 흰점을 인식하는 화면을 설명하기 위한 도면이다."}
