{"patent_id": "10-2021-0130903", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0039468", "출원번호": "10-2021-0130903", "발명의 명칭": "영상의 객체 간 상호작용행위 검출 장치 및 방법", "출원인": "주식회사 포딕스시스템", "발명자": "정재호"}}
{"patent_id": "10-2021-0130903", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "동영상을 획득하여 프레임 단위의 프레임 영상을 출력하는 이미지 획득부;상기 프레임 영상 내의 객체를 검출하고, 상기 검출된 객체들의 종류를 분류하여 각 객체에 대한 분류정보 및위치정보를 출력하는 객체 검출부;상기 객체 검출부로부터 입력되는 분류정보 및 위치정보에 기반하여 상기 프레임 영상 내에서 검출된 상기 객체중 상관관계가 있는 객체를 포함하는 대상 객체 그룹을 생성한 후, 생성된 대상 객체 그룹만을 필터링하여 출력하는 객체 필터링부;상기 필터링된 대상 객체 그룹의 각 개체의 자세를 추정하여 상기 대상 객체 그룹별 각 객체의 자세추정정보를출력하는 자세 추정부;상기 객체의 종류 및 자세추정정보에 대해 상호작용행위가 정의된 데이터세트에 의해 학습된 상호작용행위 추정인공지능모델에 상기 대상 객체 그룹별로 필터링된 상기 객체의 분류정보 및 자세추정정보를 적용하여 상기 필터링 객체 간의 상호작용행위 정보를 출력하는 객체 간 이벤트 검출부; 및필터링된 적어도 하나 이상의 상기 대상 객체 그룹을 순차적으로 입력받고, 상기 객체 간 이벤트 검출부로부터상기 대상 객체 그룹에 대한 상호작용행위 정보를 입력받으며, 상기 입력된 상호작용행위 정보가 상호작용행위검출이면 대상 객체 그룹을 출력하는 대상 객체 그룹 선택부를 포함하는 것을 특징으로 하는 영상의 객체 간 상호작용행위 검출 장치."}
{"patent_id": "10-2021-0130903", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 객체 필터링부는,검출된 상기 객체 중 상관관계가 있는 둘 이상의 객체를 검출하고, 상관관계가 있는 둘 이상의 객체를 그룹핑하여 대상 객체 그룹을 생성하는 대상 객체 그룹 결정부; 및상기 프레임 영상 내의 객체 중 생성된 대상 객체 그룹만을 필터링하여 출력하는 대상 필터링부를 포함하는 것을 특징으로 하는 영상의 객체 간 상호작용행위 검출 장치."}
{"patent_id": "10-2021-0130903", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,분류된 객체의 종류에 따른 적어도 하나 이상의 상관관계를 결정하여 상기 객체 그룹 필터링부 및 객체 간 이벤트 검출부로 결정된 상기 상관관계에 대한 상관관계정보를 출력하는 상관관계 검출부를 더 포함하는 것을 특징으로 하는 영상의 객체 간 상호작용행위 검출 장치."}
{"patent_id": "10-2021-0130903", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서,상기 상관관계는 객체(객체의 경계 박스) 간의 겹침, 객체 간의 거리, 객체의 사라짐, 객체의 무너짐, 객체의떨어짐, 착용 중 어느 하나 이상인 것을 특징으로 하는 영상의 객체 간 상호작용행위 검출 장치.공개특허 10-2023-0039468-3-청구항 5 제3항에 있어서,객체 분류부로 입력되는 상관관계 정보 및 분류정보와, 자세추정정보에 의해 둘 이상의 프레임 영상 분석이 필요한지를 판단하고, 둘 이상의 프레임 영상 간의 관계를 분석하여 관계분석정보를 상기 객체 간 이벤트 검출부로 출력하는 프레임 간 관계 분석부를 더 포함하되,상기 객체 간 이벤트 검출부는,상기 프레임 간 관계 분석부로부터 출력되는 관계분석정보에 따른 둘 이상의 프레임 영상에 대한 데이터세트에의해 학습된 상기 상호작용행위 추정 인공지능모델에 상기 분류정보 및 자세추정정보를 더 적용하여 상호작용행위 정보를 출력하는 것을 특징으로 하는 영상의 객체 간 상호작용행위 검출 장치."}
{"patent_id": "10-2021-0130903", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5항에 있어서,상기 객체 간 이벤트 검출부는,상기 상관관계가 겹침이고, 상기 대상 객체 그룹의 둘 이상의 객체가 모두 사람이면 상기 상호작용행위인 폭행에 대해 학습된 폭행 상호작용행위 추정 인공지능모델 및 인질에 대해 학습된 인질 상호작용행위 추정 인공지능모델을 적용하여 상기 대상 객체 그룹의 폭행 및 인질 상호작용행위 중 어느 하나 이상을 검출하는 것을 특징으로 하는 영상의 객체 간 상호작용행위 검출 장치."}
{"patent_id": "10-2021-0130903", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제5항에 있어서,상기 객체 간 이벤트 검출부는,상기 상관관계가 겹침이고, 상기 대상 객체 그룹의 적어도 하나가 자동차이고, 다른 하나 이상의 객체가 사람이면 상기 상호작용행위인 교통사고 및 뺑소니에 대해 학습된 교통사고 상호작용행위 추정 인공지능모델 및 뺑소니 상호작용행위 추정 인공지능모델을 적용하여 교통사고 및 뺑소니 상호작용행위 중 어느 하나 이상을 검출하는 것을 특징으로 하는 영상의 객체 간 상호작용행위 검출 장치."}
{"patent_id": "10-2021-0130903", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제5항에 있어서,상기 객체 간 이벤트 검출부는,상기 상관관계가 사라짐이고, 상기 대상 객체 그룹의 하나의 객체가 사람이고, 다른 어느 하나가 싱크홀이면 상기 분류정보, 자세추정정보 및 프레임 간 관계정보를 싱크홀 빠짐 상호작용행위 추정 인공지능모델에 적용하여상호작용행위를 검출하는 것을 특징으로 하는 영상의 객체 간 상호작용행위 검출 장치."}
{"patent_id": "10-2021-0130903", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제5항에 있어서,상기 객체 간 이벤트 검출부는,상기 상관관계가 사라짐이고, 상기 대상 객체 그룹의 하나의 객체가 사람이고, 다른 어느 하나가 싱크홀이면 상기 분류정보, 자세추정정보 및 프레임 간 관계정보를 싱크홀 빠짐 상호작용행위 추정 인공지능모델에 적용하여공개특허 10-2023-0039468-4-상호작용행위를 검출하는 것을 특징으로 하는 영상의 객체 간 상호작용행위 검출 장치."}
{"patent_id": "10-2021-0130903", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제5항에 있어서,상기 객체 간 이벤트 검출부는,상기 상관관계가 무너짐이고, 상기 대상 객체 고객 그룹의 하나가 사람이고 다른 어느 하나가 건물, 담벼락, 전봇대, 가로등, 기중기, 거치대, 실외기 및 돌 중 어느 하나이면 상기 분류정보, 자세추정정보 및 프레임 간 관계 정보를 무너짐 상호작용행위 추정 인공지능모델에 적용하여 무너짐 사고 작용행위를 검출하는 것을 특징으로하는 영상의 객체 간 상호작용행위 검출 장치."}
{"patent_id": "10-2021-0130903", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제5항에 있어서,상기 개체 간 이벤트 검출부는,상기 상관관계가 거리이고, 상기 대상 객체 고객 그룹의 둘 이상의 객체가 사람이면 상기 분류정보, 자세추정정보를 안전거리 상호작용행위 추정 인공지능모델에 적용하여 안전거리 유지 상호작용행위를 검출하는 것을 특징으로 하는 영상의 객체 간 상호작용행위 검출 장치."}
{"patent_id": "10-2021-0130903", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제5항에 있어서,상기 객체 간 이벤트 검출부는,상기 상관관계가 착용이고, 상기 대상 객체 고객 그룹의 하나가 사람이고, 다른 하나가 마스크이면, 상기 분류정보, 자세추정정보를 노마스크 상호작용행위 추정 인공지능모델에 적용하여 노마스크 상호작용행위를 검출하는것을 특징으로 하는 영상의 객체 간 상호작용행위 검출 장치."}
{"patent_id": "10-2021-0130903", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "이미지 획득부가 동영상을 획득하여 프레임 단위의 프레임 영상을 출력하는 이미지 획득 과정;객체 검출부가 상기 이미지 획득부로부터 상기 프레임 영상을 입력받고, 상기 프레임 영상 내의 객체를 검출하고, 상기 검출된 객체들의 종류를 분류하여 각 객체에 대한 분류정보를 출력하는 객체 검출 과정;객체 필터링부가 검출된 상기 객체 중 상관관계가 있는 객체를 포함하는 대상 객체 그룹을 생성한 후, 생성된대상 객체 그룹만을 필터링하여 출력하는 객체 필터링 과정;자세 추정부가 필터링된 상기 대상 객체 그룹의 각 개체의 자세를 추정하여 상기 대상 객체 그룹별 각 객체의자세추정정보를 출력하는 자세 추정 과정;이벤트 검출부가 상기 객체의 종류 및 자세추정정보에 대해 상호작용행위가 정의된 데이터세트에 의해 학습된상호작용행위 추정 인공지능모델에 상기 대상 객체 그룹별로 필터링된 상기 객체의 분류정보 및 자세추정정보를적용하여 상기 필터링 객체 간의 상호작용행위 정보를 출력하는 객체 간 이벤트 검출 과정; 및객체 그룹 선택부가 필터링된 적어도 하나 이상의 상기 대상 객체 그룹을 입력받고, 상기 객체 간 이벤트 검출부로부터 상기 대상 객체 그룹에 대한 상호작용행위 정보를 입력받으며, 상기 입력된 상호작용행위 정보가 상호작용행위 검출이면 대상 객체 그룹을 출력하는 대상 객체 그룹 선택 과정을 포함하는 것을 특징으로 하는 영상의 객체 간 상호작용행위 검출 방법.공개특허 10-2023-0039468-5-청구항 14 제13항에 있어서,상기 객체 필터링 과정은,검출된 상기 객체 중 상관관계가 있는 둘 이상의 객체를 검출하고, 상관관계가 있는 둘 이상의 객체를 그룹핑하여 대상 객체 그룹을 생성하는 대상 객체 그룹 결정 단계; 및상기 프레임 영상 내의 객체 중 생성된 대상 객체 그룹만을 필터링하여 출력하는 대상 필터링 단계를 포함하는것을 특징으로 하는 영상의 객체 간 상호작용행위 검출 방법."}
{"patent_id": "10-2021-0130903", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제14항에 있어서,상기 객체 분류 과정은,상기 객체 분류부가 상기 프레임 영상 내의 검출된 객체에 대한 종류를 분류 후, 분류된 객체의 종류에 따른 적어도 하나 이상의 상관관계를 결정하는 상관관계 결정 단계;상기 객체 분류부가 상기 객체 그룹 필터링부 및 객체 간 이벤트 검출부로 결정된 상기 상관관계에 대한 상관관계 정보를 출력하는 상관관계 정보 제공 단계; 및상기 객체 분류부가 상기 검출된 객체들의 종류를 분류하여 각 객체에 대한 분류정보를 출력하는 객체 분류 단계를 포함하는 것을 특징으로 하는 영상의 객체 간 상호작용행위 검출 방법."}
{"patent_id": "10-2021-0130903", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제15항에 있어서,상기 상관관계는 객체(객체의 경계 박스) 간의 겹침, 객체 간의 거리, 객체의 사라짐, 객체의 무너짐, 객체의떨어짐, 착용 중 어느 하나 이상인 것을 특징으로 하는 영상의 객체 간 상호작용행위 검출 방법."}
{"patent_id": "10-2021-0130903", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제15항에 있어서,프레임 간 관계 분석부가 상기 객체 분류부로 입력되는 상관관계 정보 및 분류정보와, 자세추정정보에 의해 둘이상의 프레임 영상 분석이 필요한지를 판단하고, 둘 이상의 프레임 영상 간의 관계를 분석하여 관계분석정보를상기 객체 간 이벤트 검출부로 출력하는 프레임 간 관계 분석 과정을 더 포함하되,상기 객체 간 이벤트 검출 과정에서 상기 객체 간 이벤트 검출부가 상기 프레임 간 관계 분석부로부터 출력되는관계분석정보에 대응하는 복수의 프레임 영상에 대해 학습된 상기 상호작용행위 추정 인공지능모델에 상기 프레임 영상들 각각에 대응하는 분류정보 및 자세추정정보를 적용하여 상호작용행위 정보를 출력하는 것을 특징으로하는 영상의 객체 간 상호작용행위 검출 방법."}
{"patent_id": "10-2021-0130903", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제17항에 있어서,상기 객체 간 이벤트 검출 과정에서, 상기 상관관계가 겹침이고, 상기 대상 객체 그룹의 둘 이상의 객체가 모두사람이면 객체 간 이벤트 검출부가 상기 상호작용행위인 폭행에 대해 학습된 폭행 상호작용행위 추정 인공지능모델 및 인질에 대해 학습된 인질 상호작용행위 추정 인공지능모델을 적용하여 상기 대상 객체 그룹의 폭행 및공개특허 10-2023-0039468-6-인질 상호작용행위 중 어느 하나 이상을 검출하는 것을 특징으로 하는 영상의 객체 간 상호작용행위 검출 방법."}
{"patent_id": "10-2021-0130903", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 영상의 객체 간 상호작용행위 검출 장치 및 방법에 관한 것으로, 더욱 상세하게는 인공지능 기반의 객 체 검출 및 객체 분류를 수행하고, 검출된 객체 간의 상관관계에 따른 상호작용행위 검출 대상인 대상 객체 그룹 만을 필터링한 후, 필터링된 대상 객체 그룹의 상관관계, 객체의 종류 및 객체의 추정된 자세에 따라 객체 상호 간의 상호작용행위를 검출하여 출력하는 영상의 객체 간 상호작용행위 검출 장치 및 방법에 관한 것이다."}
{"patent_id": "10-2021-0130903", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 영상의 객체 간 상호작용행위 검출 장치 및 방법에 관한 것으로, 더욱 상세하게는 인공지능 기반의 객체 검출 및 객체 분류를 수행하고, 검출된 객체 간의 상관관계에 따른 상호작용행위 검출 대상인 대상 객체 그룹만을 필터링한 후, 필터링된 대상 객체 그룹의 상관관계, 객체의 종류 및 객체의 추정된 자세에 따라 객체 상호 간의 상호작용행위를 검출하여 출력하는 영상의 객체 간 상호작용행위 검출 장치 및 방법에 관한 것이다."}
{"patent_id": "10-2021-0130903", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "영상기술 및 카메라 기술이 발전함에 따라 다양한 분야에서 무수히 많은 영상이 만들어지고 있다. 일반적으로 시, 도, 군 등과 같은 지자체들은 시민의 안전 및 치안을 위해 거리 및 다양한 장소에 다수의 폐쇄 회로 텔레비전(Closed Circuit Television: CCTV)을 설치하고 있다. 지자체뿐만 아니라 건물에는 건물 내의 보안을 위해 다수의 CCTV가 설치되고 있으며, 최근에는 일반 가정에도 치안, 보안 및 육아 돌봄 등을 위해 가정용 CCTV가 설치되고 있다. 이처럼 CCTV로부터 획득되는 영상은 CCTV 영상획득장치에 저장된다. 통상적으로, CCTV 영상획득장치는 촬영되는 영상을 저장수단에 저장하였다가 추후 확인할 수 있도록 할 뿐만 아 니라 인터넷을 통해 실시간 확인할 수 있도록 한다. 일반적인 CCTV 영상획득장치를 이용하는 경우, 관리자가 직접 촬영 영상을 확인하여 영상에서 발생하는 침입, 폭력, 사고 등과 같은 상황 및 이벤트 발생을 분석하는 것이 일반적이었으나, 동시다발적으로 발생하는 영상을 소수의 관리자가 일일이 모니터링하여 이벤트의 발생을 감지하는 데는 한계가 있는 문제점이 있었다. 이러한 문제점을 해결하기 위해 최근에는 획득되는 영상을 자동으로 분석하여 영상 내에서 발생하는 침입, 폭력, 사고 등과 같은 다양한 이벤트를 검출하는 영상 분석 시스템이 개발되어 적용되고 있다. 이러한 영상 분석 시스템은 딥러닝(Deep Learning) 등과 같은 인공지능(AI)기술이 접목되어 영상 내의 객체 인 식을 통해 해당 영상의 상황을 빠르게 판단하고, 영상 내에서의 다양한 이벤트를 빠르게 감지하고 있다. 또한, 최근 영상 분석 시스템은 이러한 이벤트의 검출을 넘어, 사고를 예방하는 사전적 보안 단계까지 실현할 수 있을 것으로 기대를 모으고 있다. 딥러닝 알고리즘은 비지도 학습 및 지도 학습, 합성곱신경망(Convolution Neural Network: CNN), 순환신경망 (Recursive Neural Network: RNN) 등으로 고도화되고 있으며, 이를 처리하는 하드웨어의 발전도 진화하는 추세 이다. 통상적으로 영상의 처리는 그래픽 프로세싱 유닛(Graphic Processing Unit: GPU)에서 수행된다. 그러나 수많은 영상을 빠르게 분석하여야 하므로 영상을 처리하기 위한 GPU 등과 같은 하드웨어의 속도가 빨라 져야 하나, 하드웨어의 속도를 향상시키기 위해서는 그 가격이 비싸지는 문제점이 있으며, 가격이 저렴한 하드 웨어로는 사용자가 원하는 속도를 확보하기 어려운 문제점이 있었다. 또한, 속도가 빠른 하드웨어라도 물리적으로 그 속도를 향상시키는데는 한계가 있는 문제점이 있었다. 또한, 종래 영상 분석 시스템은 인공지능을 이용한 영상 내의 객체의 자세 추정을 통해 영상 내에서 발생되는 이벤트를 검출하므로 사람과 같은 특정 객체에 대해서만 폭행 등의 상호작용만을 검출하므로, 서로 다른 객체 간의 상호작용행위를 검출할 수 없는 문제점이 있다. 선행기술문헌 특허문헌(특허문헌 0001) 대한민국 공개특허 제10-2021-0020723호(2021.02.24.공개)"}
{"patent_id": "10-2021-0130903", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "따라서 본 발명의 목적은 인공지능 기반의 객체 검출 및 객체 분류를 수행하고, 검출된 객체 간의 상관관계에 따른 상호작용행위 검출 대상인 대상 객체 그룹만을 필터링한 후, 필터링된 대상 객체 그룹의 상관관계, 객체의 종류 및 객체의 추정된 자세에 따라 객체 상호 간의 상호작용행위를 검출하여 출력하는 영상의 객체 간 상호작 용행위 검출 장치 및 방법을 제공함에 있다."}
{"patent_id": "10-2021-0130903", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기와 같은 목적을 달성하기 위한 본 발명에 따른 영상의 객체 간 상호작용행위 검출 장치는: 동영상을 획득하 여 프레임 단위의 프레임 영상을 출력하는 이미지 획득부; 상기 프레임 영상 내의 객체를 검출하고, 상기 검출 된 객체들의 종류를 분류하여 각 객체에 대한 분류정보 및 위치정보를 출력하는 객체 검출부; 상기 객체 검출부 로부터 입력되는 분류정보 및 위치정보에 기반하여 상기 프레임 영상 내에서 검출된 상기 객체 중 상관관계가 있는 객체를 포함하는 대상 객체 그룹을 생성한 후, 생성된 대상 객체 그룹만을 필터링하여 출력하는 객체 필터 링부; 상기 필터링된 대상 객체 그룹의 각 개체의 자세를 추정하여 상기 대상 객체 그룹별 각 객체의 자세추정 정보를 출력하는 자세 추정부; 상기 객체의 종류 및 자세추정정보에 대해 상호작용행위가 정의된 데이터세트에 의해 학습된 상호작용행위 추정 인공지능모델에 상기 대상 객체 그룹별로 필터링된 상기 객체의 분류정보 및 자 세추정정보를 적용하여 상기 필터링 객체 간의 상호작용행위 정보를 출력하는 객체 간 이벤트 검출부; 및 필터 링된 적어도 하나 이상의 상기 대상 객체 그룹을 순차적으로 입력받고, 상기 객체 간 이벤트 검출부로부터 상기 대상 객체 그룹에 대한 상호작용행위 정보를 입력받으며, 상기 입력된 상호작용행위 정보가 상호작용행위 검출 이면 대상 객체 그룹을 출력하는 대상 객체 그룹 선택부를 포함하는 것을 특징으로 한다. 상기 객체 필터링부는, 검출된 상기 객체 중 상관관계가 있는 둘 이상의 객체를 검출하고, 상관관계가 있는 둘 이상의 객체를 그룹핑하여 대상 객체 그룹을 생성하는 대상 객체 그룹 결정부; 및 상기 프레임 영상 내의 객체 중 생성된 대상 객체 그룹만을 필터링하여 출력하는 대상 필터링부를 포함하는 것을 특징으로 한다. 상기 장치는:분류된 객체의 종류에 따른 적어도 하나 이상의 상관관계를 결정하여 상기 객체 그룹 필터링부 및 객체 간 이벤트 검출부로 결정된 상기 상관관계에 대한 상관관계정보를 출력하는 상관관계 검출부를 더 포함하 는 것을 특징으로 한다. 상기 상관관계는 객체(객체의 경계 박스) 간의 겹침, 객체 간의 거리, 객체의 사라짐, 객체의 무너짐, 객체의 떨어짐, 착용 중 어느 하나 이상인 것을 특징으로 한다. 상기 장치는: 객체 분류부로 입력되는 상관관계 정보 및 분류정보와, 자세추정정보에 의해 둘 이상의 프레임 영 상 분석이 필요한지를 판단하고, 둘 이상의 프레임 영상 간의 관계를 분석하여 관계분석정보를 상기 객체 간 이 벤트 검출부로 출력하는 프레임 간 관계 분석부를 더 포함하되, 상기 객체 간 이벤트 검출부는, 상기 프레임 간 관계 분석부로부터 출력되는 관계분석정보에 따른 둘 이상의 프레임 영상에 대한 데이터세트에 의해 학습된 상 기 상호작용행위 추정 인공지능모델에 상기 분류정보 및 자세추정정보를 더 적용하여 상호작용행위 정보를 출력 하는 것을 특징으로 한다. 상기 객체 간 이벤트 검출부는, 상기 상관관계가 겹침이고, 상기 대상 객체 그룹의 둘 이상의 객체가 모두 사람 이면 상기 상호작용행위인 폭행에 대해 학습된 폭행 상호작용행위 추정 인공지능모델 및 인질에 대해 학습된 인 질 상호작용행위 추정 인공지능모델을 적용하여 상기 대상 객체 그룹의 폭행 및 인질 상호작용행위 중 어느 하 나 이상을 검출하는 것을 특징으로 한다. 상기 객체 간 이벤트 검출부는, 상기 상관관계가 겹침이고, 상기 대상 객체 그룹의 적어도 하나가 자동차이고, 다른 하나 이상의 객체가 사람이면 상기 상호작용행위인 교통사고 및 뺑소니에 대해 학습된 교통사고 상호작용 행위 추정 인공지능모델 및 뺑소니 상호작용행위 추정 인공지능모델을 적용하여 교통사고 및 뺑소니 상호작용행 위 중 어느 하나 이상을 검출하는 것을 특징으로 한다. 상기 객체 간 이벤트 검출부는, 상기 상관관계가 사라짐이고, 상기 대상 객체 그룹의 하나의 객체가 사람이고, 다른 어느 하나가 싱크홀이면 상기 분류정보, 자세추정정보 및 프레임 간 관계정보를 싱크홀 빠짐 상호작용행위 추정 인공지능모델에 적용하여 상호작용행위를 검출하는 것을 특징으로 한다. 상기 객체 간 이벤트 검출부는, 상기 상관관계가 사라짐이고, 상기 대상 객체 그룹의 하나의 객체가 사람이고, 다른 어느 하나가 싱크홀이면 상기 분류정보, 자세추정정보 및 프레임 간 관계정보를 싱크홀 빠짐 상호작용행위 추정 인공지능모델에 적용하여 상호작용행위를 검출하는 것을 특징으로 한다. 상기 객체 간 이벤트 검출부는, 상기 상관관계가 무너짐이고, 상기 대상 객체 고객 그룹의 하나가 사람이고 다 른 어느 하나가 건물, 담벼락, 전봇대, 가로등, 기중기, 거치대, 실외기 및 돌 중 어느 하나이면 상기 분류정보, 자세추정정보 및 프레임 간 관계 정보를 무너짐 상호작용행위 추정 인공지능모델에 적용하여 무너짐 사고 작용행위를 검출하는 것을 특징으로 한다. 상기 개체 간 이벤트 검출부는, 상기 상관관계가 거리이고, 상기 대상 객체 고객 그룹의 둘 이상의 객체가 사람 이면 상기 분류정보, 자세추정정보를 안전거리 상호작용행위 추정 인공지능모델에 적용하여 안전거리 유지 상호 작용행위를 검출하는 것을 특징으로 한다. 상기 객체 간 이벤트 검출부는, 상기 상관관계가 착용이고, 상기 대상 객체 고객 그룹의 하나가 사람이고, 다른 하나가 마스크이면, 상기 분류정보, 자세추정정보를 노마스크 상호작용행위 추정 인공지능모델에 적용하여 노마 스크 상호작용행위를 검출하는 것을 특징으로 한다. 상기와 같은 목적을 달성하기 위한 본 발명에 따른 영상의 객체 간 상호작용행위 검출 방법은: 이미지 획득부가 동영상을 획득하여 프레임 단위의 프레임 영상을 출력하는 이미지 획득 과정; 객체 검출부가 상기 이미지 획득 부로부터 상기 프레임 영상을 입력받고, 상기 프레임 영상 내의 객체를 검출하고, 상기 검출된 객체들의 종류를 분류하여 각 객체에 대한 분류정보를 출력하는 객체 검출 과정; 객체 필터링부가 검출된 상기 객체 중 상관관계 가 있는 객체를 포함하는 대상 객체 그룹을 생성한 후, 생성된 대상 객체 그룹만을 필터링하여 출력하는 객체 필터링 과정; 자세 추정부가 필터링된 상기 대상 객체 그룹의 각 개체의 자세를 추정하여 상기 대상 객체 그룹 별 각 객체의 자세추정정보를 출력하는 자세 추정 과정; 이벤트 검출부가 상기 객체의 종류 및 자세추정정보에 대해 상호작용행위가 정의된 데이터세트에 의해 학습된 상호작용행위 추정 인공지능모델에 상기 대상 객체 그룹 별로 필터링된 상기 객체의 분류정보 및 자세추정정보를 적용하여 상기 필터링 객체 간의 상호작용행위 정보를 출력하는 객체 간 이벤트 검출 과정; 및 객체 그룹 선택부가 필터링된 적어도 하나 이상의 상기 대상 객체 그룹 을 입력받고, 상기 객체 간 이벤트 검출부로부터 상기 대상 객체 그룹에 대한 상호작용행위 정보를 입력받으며, 상기 입력된 상호작용행위 정보가 상호작용행위 검출이면 대상 객체 그룹을 출력하는 대상 객체 그룹 선택 과정 을 포함하는 것을 특징으로 한다. 상기 객체 필터링 과정은, 검출된 상기 객체 중 상관관계가 있는 둘 이상의 객체를 검출하고, 상관관계가 있는 둘 이상의 객체를 그룹핑하여 대상 객체 그룹을 생성하는 대상 객체 그룹 결정 단계; 및 상기 프레임 영상 내의 객체 중 생성된 대상 객체 그룹만을 필터링하여 출력하는 대상 필터링 단계를 포함하는 것을 특징으로 한다. 상기 객체 분류 과정은, 상기 객체 분류부가 상기 프레임 영상 내의 검출된 객체에 대한 종류를 분류 후, 분류 된 객체의 종류에 따른 적어도 하나 이상의 상관관계를 결정하는 상관관계 결정 단계; 상기 객체 분류부가 상기 객체 그룹 필터링부 및 객체 간 이벤트 검출부로 결정된 상기 상관관계에 대한 상관관계 정보를 출력하는 상관 관계 정보 제공 단계; 및 상기 객체 분류부가 상기 검출된 객체들의 종류를 분류하여 각 객체에 대한 분류정보 를 출력하는 객체 분류 단계를 포함하는 것을 특징으로 한다. 상기 방법은: 프레임 간 관계 분석부가 상기 객체 분류부로 입력되는 상관관계 정보 및 분류정보와, 자세추정정 보에 의해 둘 이상의 프레임 영상 분석이 필요한지를 판단하고, 둘 이상의 프레임 영상 간의 관계를 분석하여 관계분석정보를 상기 객체 간 이벤트 검출부로 출력하는 프레임 간 관계 분석 과정을 더 포함하되, 상기 객체 간 이벤트 검출 과정에서 상기 객체 간 이벤트 검출부가 상기 프레임 간 관계 분석부로부터 출력되는 관계분석 정보에 대응하는 복수의 프레임 영상에 대해 학습된 상기 상호작용행위 추정 인공지능모델에 상기 프레임 영상 들 각각에 대응하는 분류정보 및 자세추정정보를 적용하여 상호작용행위 정보를 출력하는 것을 특징으로 한다."}
{"patent_id": "10-2021-0130903", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명은 객체 검출 및 분류를 수행한 후 검출된 객체 간의 객체 분류에 따른 객체 경계박스 겹침 등과 같은 상관관계에 따라 상호작용행위를 검출할 대상 객체를 필터링함으로써 상호작용행위 검출을 수행할 대상을 줄일 수 있고, 이로 인한 제어수단의 부하 감소 및 검출 시간을 줄일 수 있는 효과가 있다.또한, 본 발명은 검출 및 필터링된 객체의 종류를 분류하여 식별하므로 분류된 종류에 따른 다양한 상호작용행 위를 검출할 수 있는 효과가 있다. 즉 본원발명은 객체를 사람으로 한정하지 않고 상호작용행위를 폭행으로 한 정하지 않으며, 사람뿐만이 아닌 동물, 맨홀, 자동차 등과 같은 다양한 객체 간의 폭행, 교통사고, 맨홀 빠짐 사고, 코로나 거리두기 위반 등과 같은 다양한 상호작용행위를 검출할 수 있는 효과가 있다."}
{"patent_id": "10-2021-0130903", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하 첨부된 도면을 참조하여 본 발명에 따른 영상의 객체 간 상호작용행위 검출 장치의 구성 및 동작을 상세히 설명하고, 상기 장치에서의 다양한 실시예에 따른 상호작용행위 검출 방법을 설명한다. 도 1은 본 발명에 따른 영상의 객체 간 상호작용행위 검출 장치의 구성을 나타낸 도면이다. 도 1을 참조하면, 영상의 객체 간 상호작용행위 검출 장치는 이미지 획득부, 객체 검출부, 객체 그룹 필터링부, 자세 추정부, 객체 간 이벤트 검출부 및 대상 객체 그룹 선택부를 포함하고, 실시예 에 따라 상관관계 검출부, 프레임 간 관계 분석부 및 결과 출력부를 더 포함한다. 이미지 획득부는 영상을 획득하고 상기 영상을 프레임 단위의 영상(이하 \"프레임 영상\"이라 함)으로 출력한 다. 상기 영상은 폐쇄회로텔레비전(Closed Circuit Television: CCTV)으로부터 직접 입력되는 영상일 수도 있고, 다수의 CCTV와 연결되는 인공지능(Artificial Intelligence: AI) 박스로부터 입력되는 영상일 수도 있으 며, 네트워크 비디오 레코더(Network Video Record: NVR)로부터 입력되는 영상일 수도 있을 것이다. 또한, 상기 영상은 둘 이상의 CCTV 등의 촬영장치에서 촬영된 복수의 영상을 단일채널, 즉 하나의 영상으로 결합한 영상(이 하 \"단일채널 처리 영상\"이라 함)일 수도 있을 것이다. 따라서 단일채널 처리 영상의 프레임 영상 내에도 복수 의 채널에 대한 프레임 영상이 포함되어 있을 것이다. 객체 검출부는 이미지 획득부로 출력되는 프레임 영상 내의 객체들을 검출하고, 검출된 객체 각각에 대 한 종류를 식별하여 분류하고, 분류된 분류정보 및 각 개체의 영상 프레임 내 위치정보를 출력한다. 상기 검출 된 객체들은 경계박스(Boundign Box)를 포함하며, 상기 위치정보는 상기 경계박스의 위치정보일 것이다. 상기 객체는 사람(남자, 여자, 어린이, 성인 등), 동물(고양이, 개, 사슴, 쥐 등), 물건(건물, 가로등, 가로수, 싱크 홀, 마스크 등) 등이 될 수 있을 것이다. 상기 객체 검출부는 영상 프레임 내 객체 검출, 검출된 객체의 경계박스의 위치 및 분류정보를 출력하는 합 성곱신경망(Convolution Neural Network: CNN) 인공지능모델 중 하나인 VGGNet에 이 적용되는 것이 바람직할 것이다. 상기 객체 검출부에서 출력되는 위치정보 및 분류정보는 객체 그룹 필터링부 및 실시예에 따른 상관관 계 검출부로 출력된다. 객체 그룹 필터링부는 대상 객체 그룹 결정부 및 대상 필터링부를 포함하여, 이미지 획득부로 부터 프레임 영상을 입력받고, 상기 객체 검출부로부터 입력되는 분류정보 및 위치정보에 기반하여 상기 프 레임 영상으로부터 검출된 상기 객체 중 상관관계가 있는 둘 이상의 객체 검출하고, 검출된 둘 이상의 객체를 포함하는 대상 객체 그룹을 생성한 후, 생성된 대상 객체 그룹만을 필터링하여 자세 추정부 및 대상 객체그룹 선택부로 출력한다. 즉, 대상 객체 그룹 결정부는 상기 프레임 영상에서 검출된 상기 객체 중 상관관계가 있는 둘 이상의 객체 를 검출하고, 상관관계가 있는 둘 이상의 객체를 그룹핑하여 대상 객체 그룹(이미지, 또는 대상 객체 그룹의 둘 이상의 객체를 모두 포함하는 경계박스의 위치정보)을 생성한다. 상기 상관관계는 상호작용행위를 검출하기 위한 두 객체 간의 관계를 정의하는 것으로, 두 객체의 경계박스의 겹침, 두 객체의 거리(또는 간격), 객체의 사라짐, 객체의 무너짐, 객체의 떨어짐, 착용(객의 겹침으로 정의될 수도 있음), 등이 될 수 있을 것이다. 상기 상호작용행위는 적어도 두 객체 상호 간에 발생할 수 있는 행위일 수 있으며, 두 객체의 종류에 따라 폭행 /싸움, 범인/인질 상황, 악수/포옹, 차량 사고, 뺑소니, 기차 사고, 비행기 사고, 선박 사고(선체 분리, 컨테이 너 낙하, 해양오염, 좌초, 도선사고, 등), 건축물 기울어짐/쓰러짐 등이 될 수 있을 것이다. 상기 두 객체는 인 간과 인간, 인간과 사물, 사물과 사물 등이 될 수 있을 것이다. 상기 대상 필터링부는 상기 프레임 영상 내의 객체 중 생성된 대상 객체 그룹만을 필터링하여 자세 추정부 및 대상 객체 그룹 선택부로 출력한다. 또한, 객체 그룹 필터링부는 필터링된 대상 객체 그룹의 각 객체에 대한 분류정보 및 위치정보를 객체 간 이벤트 검출부 및 자세 추정부로 제공한다. 상관관계 검출부는 실시예에 따라 구성되어, 상기 객체 검출부에서 분류된 객체의 종류에 따른 적어도 하나 이상의 상관관계를 결정하여 상기 객체 그룹 필터링부 및 객체 간 이벤트 검출부로 결정된 상기 상관관계에 대한 상관관계 정보를 출력한다. 좀 더 구체적으로 설명하면, 상관관계 검출부는 둘 이상의 객체 종류별 상관관계 테이블을 정의하고 있으며, 객체 검출부로부터 객체별 분류정보가 입력되면 객체들의 종류에 대응하는 상관관계를 상기 상관관 계 테이블에서 찾아 상관관계를 정의한다. 상관관계는 둘 이상의 객체 종류에 따라 둘 이상으로 설정될 수 있을 것이다. 또한, 상관관계 검출부는 객체 검출부에서 검출된 객체 중 인접한 두 객체의 종류에 대해 상관관계를 정의하도록 구성될 수도 있을 것이다. 예를 들어, 상관관계 검출부는 분류된 적어도 둘 이상의 객체 모두가 사람인 경우 겹침, 객체 간의 거리 등 이 될 수 있고, 두 객체 중 하나가 사람이고, 다른 하나가 사물이면 객체 간의 겹침, 객체 간의 거리, 객체의 사라짐, 객체의 무너짐, 객체의 떨어짐, 착용 등이 될 수 있으며, 두 객체가 모두 사물이면 객체의 겹침, 객체 의 분리, 객체의 무너짐 등이 될 수 있을 것이다. 상기 객체의 겹침은 두 객체 각각의 경계박스가 겹치는 것을 의미하며, 경계박스의 겹침 면적에 따라 레벨(예: 교통사고 레벨- 교통사고의 심각성 정도를 표현할 수 있음)을 분류할 수도 있을 것이다. 상기 상관관계 검출부가 구성되지 않는 경우 객체 그룹 필터링부에는 상기 다수의 상관관계 중 어느 하 나가 미리 적용되어 있어야 할 것이다. 즉, 상기 상관관계는 대상 객체 그룹을 결정하기 위한 정보이다. 자세 추정부는 상기 객체 그룹 필터링부에서 필터링된 대상 객체 그룹별로 각 객체의 자세를 추정하여 자세추정정보를 생성한 후 객체 간 이벤트 검출부로 출력하고, 실시예에 따라 프레임 간 관계 분석부로 출력한다. 상기 자세 추정부는 객체의 스켈레톤 이미지를 생성하고, 스켈레톤 이미지를 기반으로 객체의 위치, 자세 및 방향을 탐지하고, 탐지된 위치 및 방향을 포함하는 자세추정정보를 생성하여 객체 간 이벤 검출부 및 실 시예에 따른 프레임 간 관계 분석부로 출력한다. 객체가 사람인 경우 자세 추정부는 사람 신체의 스켈레톤 이미지를 생성하고, 스켈레톤 이미지에 기반하여 사람의 관절인 키포인트가 어떻게 구성되어 있는지를 분석하여 사람의 위치, 자세 및 방향을 판단하고 그에 따 른 자세추정정보를 생성한다. 상기 자세 추정부는 포즈넷(PoseNet)에 시계열적인 순환 신경망 인공지능 모델인 LSTM(Long Short Term Memory)이 결합된 딥러닝 인공지능 모델이 적용되는 것이 바람직할 것이다. 프레임 간 관계 분석부는 실시예에 따라 구성되며, 객체 검출부로부터 분류정보를 입력받고, 상관관계 검출부로부터 상관관계정보를 입력받으며, 자세 추정부로부터 자세추정정보를 입력받아 단일 프레임 영 상으로 상호작용행위의 검출이 가능한지 둘 이상의 프레임 영상이 필요한지를 판단하고, 둘 이상의 프레임 영상 이 필요한 경우 둘 이상의 프레임 영상의 동일 대상 객체 그룹의 각 객체의 변화를 검출하여 프레임 간 관계 분 석정보를 객체 간 이벤트 검출부로 출력한다. 객체 간 이벤트 검출부는 상기 객체의 종류 및 자세추정정보에 대해 상호작용행위가 정의된 데이터세트에 의해 학습된 상호작용행위 추정 인공지능모델에 상기 대상 객체 그룹별로 필터링된 상기 객체의 분류정보 및 자 세추정정보를 적용하여 상기 필터링 객체 간의 상호작용행위 정보를 출력한다. 상기 객체 간 이벤트 검출부는 실시예에 따라 상관관계정보 및 대상 객체 그룹의 객체 종류별 상호작용행위 추정 인공지능모델을 포함할 수 있다. 즉, 겹침 상관관계 및 사람 객체에 대한 폭행 상호작용행위 추정 인공지 능모델, 범인/인질 상호작용행위 추정 인공지능모델 등을 저장하고, 겹침 상관관계 및 사람 및 사물 객체에 대 한 차량인명 사고(차량사고, 뺑소니 등) 상호작용행위 추정 인공지능모델, 건축물 쓸어짐 상호작용행위 추정 인 공지능모델 등을 저장하며, 상관관계가 거리이고 사람 객체에 대한 거리두기 상호작용행위 추정 인공지능모델, 기침 상호작용행위 추정 인공지능모델, 착용 상관관계와 사람 객체 및 사물 객체에 대한 노마스크 상호작용행위 추정 인공지능모델, 사라짐 상관관계와 사람 객체 및 사물 객체에 대한 싱크홀 빠짐 상호작용행위 추정 인공지 능모델 등을 저장하고 있을 수 있을 것이다. 상기 객체 간 이벤트 검출부는 입력되는 상관관계정보의 상관관계 및 분류정보의 대상 객체 그룹의 객체들 의 종류에 따른 해당 상호작용행위 추정 인공지능모델을 선택하여 입력되는 대상 객체 그룹의 상호작용행위를 추정하고 그 결과를 대상 객체 그룹 선택부로 출력한다. 대상 객체 그룹 선택부는 객체그룹 필터링부로부터 필터링된 대상 객체 그룹(이미지)을 순차적으로 입 력받고, 객체 간 이벤트 검출부로부터 상호작용행위 추정 결과값을 입력받고 입력된 상호작용행위 추정 결 과값이 상호작용행위 검출인 경우 대상 객체 그룹을 결과 출력부로 출력한다. 결과 출력부는 대상 객체 그룹 선택부로부터 출력되는 대상 객체 그룹을 디스플레이 수단을 통해 표시 하거나, 원격지의 관리자 단말기(미도시)로 전송하여 표시 및 저장하거나, 미리 설정된 메일 등으로 전송하거나, 경보 수단을 제어하여 경보를 발생시킨다. 도 2는 본 발명에 따른 영상의 객체 간 상호작용행위 검출 방법을 나타낸 흐름도이다. 도 2를 참조하면, 우선, 이미지 획득부는 영상이 획득되는지를 모니터링하고, 영상이 획득되면 프레임 단위 의 프레임 영상으로 분리하여 객체 검출부로 출력한다(S111). 객체 검출부는 이미지 획득부로부터 프레임 영상이 입력되면 프레임 영상 내에서 객체를 검출하고, 검 출된 객체별로 종류를 분류하여 객체별 분류정보 및 검출된 객체의 위치정보(객체의 경계를 구성하는 경계박스 (Boundary Box)의 위치정보)를 객체 그룹 필터링부 및 객체 간 이벤트 검출부로 출력하고, 분류정보 및 위치정보를 실시예에 따라 상관관계 검출부 및 프레임 간 관계 분석부로 출력한다(S113). 객체 그룹 필터링부는 이미지 획득부로부터 프레임 영상을 입력받고 객체 검출부로부터 분류정보 및 위치정보를 입력받으며 미리 설정되어 있거나 실시예에 따라 상관관계 검출부로부터 입력되는 상관관계 정보의 상관관계를 가지는 둘 이상의 객체, 즉 이벤트 분석 대상 객체가 상기 프레임 영상에 존재하는지를 판단 하고(S115), 상기 상관관계를 가지는 둘 이상의 객체를 포함하는 대상 객체 그룹(이미지)를 생성한 후 필터링, 즉 자른(Crop) 후 자세 추정부 및 대상 객체 그룹 선택부로 출력한다(S117). 자세 추정부는 객체 그룹 필터링부로부터 대상 객체 그룹을 입력받아 상기 대상 객체 그룹의 각 객체에 대한 자세추정을 수행하여 각 객체에 대한 자세추정정보를 객체 간 이벤트 검출부로 출력하고, 실시예에 따 라 프레임 간 관계 분석부로 출력한다(S119). 객체 간 이벤트 검출부는 객체 그룹 필터링부로부터 필터링된 대상 객체 그룹의 객체에 대한 분류정보 를 입력받고, 자세 추정부로부터 자세추정정보를 입력받으며, 미리 설정된 상관관계 또는 실시예에 따라 프 레임 간 관계 분석부로부터 입력되는 상관관계정보의 상관관계 및 상기 분류정보의 객체 종류에 대응하는 적어도 하나 이상의 상호작용행위 추정 인공지능모델에 상기 입력된 분류정보 및 자세추정정보와 실시예에 따른 프레임 영상 간의 관계분석정보를 적용하여 객체 간 관계를 분석하며(S121), 그 분석에 의해 상기 필터링된 대 상 객체 그룹이 적용된 상호작용행위 추정 인공지능모델에 대응하는 상호작용행위가 존재하는지를 검사하고 (S123), 존재하면 해당 대상 객체 그룹의 상호작용행위를 결정하여 대상 객체 그룹 선택부로 출력한다(S125). 대상 객체 그룹 선택부는 객체 간 이벤트 검출부로부터 결정된 상호작용행위 결과값이 입력되고 입력된 상호작용행위 결과값이 상호작용행위 검출이면 대상 객체 그룹을 결과 출력부로 출력한다(S127). 도 3은 본 발명의 제1실시예에 따른 폭행 상호작용행위 검출 방법을 설명하기 위한 도면이고, 도 4는 본 발명의 제2실시예에 따른 범인/인질 상호작용행위 검출 방법을 설명하기 위한 도면이며, 도 5는 본 발명의 제3실시예에 따른 뺑소니 상호작용행위 검출 방법을 설명하기 위한 도면이다. 이하 도 3 내지 도 4를 참조하여 설명한다. 이미지 획득부는 도 3의 S301 및 도 4의 S401에서와 같이 획득되는 영상을 프레임 영상으로 분리하여 객체 검출부로 출력한다(S301). 객체 검출부는 프레임 영상 내에 존재하는 모든 객체(1 : 1-1, 1-2, ... 1-7)를 검출하고, 검출된 객체 각각에 대해 종류를 식별하고, 객체별 위치정보 및 각 객체의 분류정보를 생성하여 출력한다(S302, S402). 상기 위치정보는 각 객체의 경계박스의 위치정보이며, 도 3에서 객체 1-1, 1-2, 1-4, 1-5, 1-6, 1-7의 분류정보는 사람이고, 객체 1-3의 분류정보는 자동차일 것이다. 그리고 도 4의 객체 1-8 및 객체 1-9의 분류정 보는 사람이고, 다른 객체들은 객체 1-1 및 객체 1-2를 제외하고 도 3과 동일하다 상관관계 검출부는 실시예에 따라 객체 검출부로부터 입력되는 각 객체의 분류정보 및 위치정보에 의해 상관관계를 결정하여 객체 그룹 필터링부로 제공할 것이다. 그러면 객체 그룹 필터링부는 S303 및 S403에서와 같이 미리 설정된 상관관계(도 3의 경우 상관관계는 겹침 (두 객체의 경계박스의 겹침) 또는 실시예에 따라 상관관계 검출부로부터 입력되는 상관관계에 기반하여 대 상 객체 그룹을 생성하고, 대상 객체 그룹 및 대상 객체 그룹의 각 객체의 위치정보 또는 대상 객체 그룹 경계박스의 위치정보 및 분류정보를 출력한다(S304, S404) 자세 추정부는 객체 그룹 필터링부로부터 대상 객체 그룹를 입력받고, 실시예에 따라 대상 객체 그룹별 분류정보 및 위치정보를 입력받아 대상 객체 그룹(3-1, 3-2, 3-3)별로 자세 추정을 수행하여 대상 객체 그룹별 각 객체별 자세추정정보를 생성하여 객체 간 이벤트 검출부로 출력한다(S305, S405). 객체 간 이벤트 검출부는 상관관계정보 및 분류정보에 의해 상호작용행위 추정 인공지능모델을 선택하고, 선택된 상호작용행위 추정 인공지능모델에 상관관계정보, 분류정보, 자세추정정보를 적용하여 상기 필터링된 대 상 객체 그룹에 대항 상호작용행위를 검출하고, 그 결과를 출력한다(S307). 즉, 도 3 및 도 4의 경우, 상관관계가 겹침이고, 검출 객체가 사람+사람, 사람+차량이므로, 제1 대상 객체 그룹 (3-1) 및 제2 대상 객체 그룹(3-2)에 대해 폭행 상호작용행위 추정 인공지능모델 및 인질/범인 상호작용행위 추 정 인공지능모델이 선택될 수 있고, 제3대상 객체 그룹(3-1)에 대해 교통사고 상호작용행위 추정 인공지능모델 및 뺑소니 상호작용행위 추정 인공지능모델이 적용될 수 있을 것이다. 객체 간 이벤트 검출부는 도 3의 경우, 제1 대상 객체 그룹(3-1)에 대해 폭행 상호작용행위 추정 인공지능 모델을 통해 폭행 결과값을 출력하고, 제2 대상 객체 그룹(3-2)에 대해 상호작용행위 없음 결과값을 출력할 것 이다(S306). 반면, 객체 간 이벤트 검출부는 도 4의 경우, 제1대상 객체 그룹(3-1)에 대해 인질/범인 상호작용행위 추정 인공지능모델을 통해 인질/범인 상호작용행위 결과값을 출력할 것이다. 그리고 객체 간 이벤트 검출부는 제3 대상 객체 그룹(3-3)에 대해 단일 프레임 영상만으로 교통사고인지 뺑 소니인지 판단할 수 없을 것이다. 이 경우 실시예에 따른 프레임 간 관계 분석부는 상관관계가 겹침이고, 객체가 사람과 자동차이면 둘 이상 의 연속 프레임 영상이 필요한 것을 판단하고, 이미지 획득부에서 획득되는 영상의 프레임 영상들을 분석하 여 몇 프레임 영상까지 관련성이 있는지에 대한 관계분석정보를 객체 간 이벤트 검출부로 제공한다. 그러면 객체 간 이벤트 검출부는 도 5의 S501, S502 및 S503에서 보이는 바와 같은 연속되는 시계열적인 프 레임 영상들에 대한 분류정보(LSTM), 자세추정정보, 상관관계정보를 교통사고 상호작용행위 추정 인공지능모델 및 뺑소니 상호작용행위 추정 인공지능모델에 적용하여 교통사고가 발생하는지 뺑소니가 발생하는지에 대한 상 호작용행위 결과값을 출력할 것이다. 도 5의 경우, 객체 간 이벤트 검출부는 뺑소니 상호작용행위 추정 인공지능모델을 통해 뺑소니 상호작용행 위 결과값을 출력할 것이다. 도 6은 본 발명의 제4실시예에 따른 싱크홀 빠짐 상호작용행위 검출 방법을 설명하기 위한 도면이다. 도 6은 두 객체 중 하나가 사람이고, 다른 하나가 싱크홀인 경우로 상관관계는 사라짐이다. 이 경우, 객체 간 이벤트 검출부는 싱크홀 빠짐 상호작용행위 추정 인공지능모델을 선택하고, S601, S602, S603에서 보이는 바와 같이 상기 싱크홀 빠짐 상호작용행위 추정 인공지능모델에 연속되는 복수의 프레임 영상 들에 대한 분류정보, 자세추정정보를 적용하여 프레임 영상들 내에서 사람의 싱크홀 빠짐 상호작용행위가 발생 하는지를 검출하고, 그에 따른 결과값을 출력할 것이다. 도 7은 본 발명의 제5실시예에 따른 건물 무너짐 상호작용행위 검출 방법을 설명하기 위한 도면이다. 도 7은 제1 객체가 건물이고, 제2 객체가 사람인 경우로, 상관관계는 무너짐/기울어짐이다. 이 경우, 객체 간 이벤트 검출부는 무너짐 상호작용행위 추정 인공지능모델을 선택하고, 도 7의 S701, S702, S703에서 보이는 바와 같이 무너짐 상호작용행위 추정 인공지능 모델에 연속되는 복수의 프레임 영상들에 대한 분류정보, 자세추정정보를 적용하여 프레임 영상들 내에서 제1 객체가 무너지고, 제2 객체가 제1객체에 매 몰되는지를 검출하고, 그에 따른 결과값을 출력할 것이다. 도 8은 본 발명의 제6실시예에 따른 거리두기 상호작용행위 검출 방법을 설명하기 위한 도면이다. 도 8은 두 객체 모두 사람이고 상관관계는 거리(또는 간격)이다. 도 8에서 대상 객체 그룹은 S801의 경우 세 사 람이 될 수도 있고, 제1사람과 제2사람 또는 제2사람과 제3사람이 될 수도 있을 것이다. 이 경우, 객체 간 이벤트 검출부는 거리두기 상호작용행위 추정 인공지능모델을 선택하고, S801, S802, S803에서 보이는 바와 같이 상기 거리두기 상호작용행위 추정 인공지능모델에 단일 프레임 영상에 대한 분류정 보, 자세추정정보를 적용하여 프레임 영상 내에서의 사람들이 일정 간격 또는 일정 거리를 유지하는지를 모니터 링하고 S803에서와 같이 특정 사람이 일정 거리를 유지하지 않는 경우 거리두기 상호작용행위 결과값을 출력할 것이다. 도 9는 본 발명의 제7실시예에 따른 기침 및 노마스크 상호작용행우 검출 방법을 설명하기 위한 도면이다. 도 9는 제1 객체는 사람이고, 제2 객체는 마스크이고, 상관관계는 착용 및 기침이다. 이 경우, 객체 간 이벤트 검출부는 노마스크 상호작용행위 추정 인공지능모델을 선택하고, S901 및 S902에 서와 같이 각 객체의 위치정보, 자세추정정보를 노마스크 상호작용행위 추정 인공지능모델에 적용하여 제2객체 인 마스크가 제1객체인 사람의 입과 코에 정확하게 착용되었는지를 검출하고, 그에 따른 결과값을 출력할 것이다. 즉, S901에서 객체 간 이벤트 검출부는 대상 객체 그룹인 모든 사람이 마스크를 정확하게 착용하고 있으면 객체 간 이벤트 검출부는 결과값으로 널(Null)값을 출력하거나 마스크 착용 결과값을 출력할 것이다. 반면, S902와 같이 사람만 검출되고 마스크가 검출되지 않는 경우, 객체 간 이벤트 검출부는 객체 검출부 에서 입력되는 분류정보만으로도 노마스크인 사람을 검출할 수 있을 것이다. 그리고 도면에는 나타내지 않았으나 마스크를 착용하고 있으나, 코가 보이거나 입이 보이는 경우, 객체 간 이벤 트 검출부의 노마스크 상호작용행위 추정 인공지능모델은 그 결과값으로 (마스크 착용)불량을 출력할 것이다. 또한, S903에서 보이는 바와 같이 노마스크 상호작용행위 추정 인공지능모델을 선택한 객체 간 이벤트 검출부 는 마스크를 착용하지 않은 사람이 기침을 하는지를 모니터링하고 그에 대한 결과값을 출력할 것이다. 기침 의 경우 복수의 프레임 영상에 대한 분류정보 및 자세추정정보가 노마스크 상호작용행위 추정 인공지능모델에 적용되어야 할 것이다. 한편, 본 발명은 전술한 전형적인 바람직한 실시예에만 한정되는 것이 아니라 본 발명의 요지를 벗어나지 않는"}
{"patent_id": "10-2021-0130903", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "범위 내에서 여러 가지로 개량, 변경, 대체 또는 부가하여 실시할 수 있는 것임은 당해 기술분야에서 통상의 지 식을 가진 자라면 용이하게 이해할 수 있을 것이다. 이러한 개량, 변경, 대체 또는 부가에 의한 실시가 이하의 첨부된 특허청구범위의 범주에 속하는 것이라면 그 기술사상 역시 본 발명에 속하는 것으로 보아야 한다. 부호의 설명10: 이미지 획득부 20: 객체 검출부 30: 상관관계 검출부 40: 객체 그룹 필터링부 41: 대상 객체 그룹 결정부 42: 대상 필터링부 50: 자세 추정부 60: 프레임 간 관계 분석부 70: 객체 간 이벤트 검출부 80: 대상 객체 그룹 선택부 90: 결과 출력부"}
{"patent_id": "10-2021-0130903", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명에 따른 영상의 객체 간 상호작용행위 검출 장치의 구성을 나타낸 도면이다. 도 2는 본 발명에 따른 영상의 객체 간 상호작용행위 검출 방법을 나타낸 흐름도이다. 도 3은 본 발명의 제1실시예에 따른 폭행 상호작용행위 검출 방법을 설명하기 위한 도면이다. 도 4는 본 발명의 제2실시예에 따른 범인/인질 상호작용행위 검출 방법을 설명하기 위한 도면이다. 도 5는 본 발명의 제3실시예에 따른 뺑소니 상호작용행위 검출 방법을 설명하기 위한 도면이다. 도 6은 본 발명의 제4실시예에 따른 싱크홀 빠짐 상호작용행위 검출 방법을 설명하기 위한 도면이다. 도 7은 본 발명의 제5실시예에 따른 건물 무너짐 상호작용행위 검출 방법을 설명하기 위한 도면이다. 도 8은 본 발명의 제6실시예에 따른 거리두기 상호작용행위 검출 방법을 설명하기 위한 도면이다. 도 9는 본 발명의 제7실시예에 따른 기침 및 노마스크 상호작용행우 검출 방법을 설명하기 위한 도면이다."}
