{"patent_id": "10-2023-0132460", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2025-0049706", "출원번호": "10-2023-0132460", "발명의 명칭": "서버 및 그 동작 방법, 영상 처리 장치 및 그 동작 방법", "출원인": "삼성전자주식회사", "발명자": "김동현"}}
{"patent_id": "10-2023-0132460", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "서버(100)에 있어서,통신부(110);하나 이상의 인스트럭션들을 저장하는 메모리(130); 및상기 하나 이상의 인스트럭션들을 실행하는 적어도 하나의 프로세서(120)를 포함하고,상기 적어도 하나의 프로세서(120)는, 상기 하나 이상의 인스트럭션들을 실행함으로써,원본 영상을 압축하여, 제1 영상을 획득하고,상기 제1 영상에 대한 화질을 분석하여, 상기 제1 영상의 품질 정보를 획득하고,상기 품질 정보에 기초하여, 상기 제1 영상의 화질 처리에 이용되는 메타 모델에 대한 메타 모델 정보를 획득하고,상기 메타 모델 정보 및 상기 제1 영상을 영상 처리 장치로 전송하도록 상기 통신부를 제어하는, 서버."}
{"patent_id": "10-2023-0132460", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 제1 영상은 비디오 컨텐츠에 포함되는 복수의 프레임 영상들을 포함하고,상기 적어도 하나의 프로세서(120)는, 상기 하나 이상의 인스트럭션들을 실행함으로써,상기 복수의 프레임 영상들의 전체적인 품질 정보에 기초하여, 상기 복수의 프레임 영상들 중 제1 시점의 프레임 영상의 품질 정보를 획득하는, 서버."}
{"patent_id": "10-2023-0132460", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,상기 적어도 하나의 프로세서(120)는, 상기 하나 이상의 인스트럭션들을 실행함으로써,상기 복수의 프레임 영상들의 품질 평균 값 및 표준 편차에 기초하여, 품질 상한 값 및 품질 하한 값을 설정하고,상기 품질 상한 값 및 품질 하한 값에 기초하여, 상기 제1 시점의 프레임 영상의 품질 값을 결정하는, 서버."}
{"patent_id": "10-2023-0132460", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항 내지 제3항 중 어느 한 항에 있어서,상기 적어도 하나의 프로세서(120)는, 상기 하나 이상의 인스트럭션들을 실행함으로써,상기 품질 정보를 상기 영상 처리 장지로 전송하도록 상기 통신부를 제어하는, 서버."}
{"patent_id": "10-2023-0132460", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항 내지 제4항 중 어느 한 항에 있어서,상기 메타 모델은 적어도 하나의 참고 모델에 기초하여, 획득되고,상기 메타 모델 정보는,상기 적어도 하나의 참고 모델에 대한 정보 및 상기 적어도 하나의 참고 모델에 적용되는 가중치에 대한 정보를공개특허 10-2025-0049706-3-포함하고,상기 적어도 하나의 프로세서(120)는, 상기 하나 이상의 인스트럭션들을 실행함으로써,상기 품질 정보에 기초하여, 상기 적어도 하나의 참고 모델 및 상기 적어도 하나의 참고 모델에 적용되는 가중치를 결정하는, 서버."}
{"patent_id": "10-2023-0132460", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5항에 있어서,상기 적어도 하나의 프로세서(120)는, 상기 하나 이상의 인스트럭션들을 실행함으로써,상기 적어도 하나의 참고 모델에 대응하는 품질 정보와 상기 제1 영상에 대한 품질 정보의 차이에 기초하여, 상기 가중치를 결정하는 서버."}
{"patent_id": "10-2023-0132460", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제5항 또는 제6항에 있어서,상기 적어도 하나의 참고 모델은,상기 서버에 기 저장된 제1 참고 모델 또는 상기 영상 처리 장치에 기 저장된 제2 참고 모델을 포함하는, 서버."}
{"patent_id": "10-2023-0132460", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서,상기 적어도 하나의 프로세서(120)는, 상기 하나 이상의 인스트럭션들을 실행함으로써,상기 제1 영상에 기초하여, 상기 제1 영상에 대응하는 상기 제1 참고 모델을 생성하는, 서버."}
{"patent_id": "10-2023-0132460", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제7항 또는 제8항에 있어서,상기 적어도 하나의 프로세서(120)는, 상기 하나 이상의 인스트럭션들을 실행함으로써,상기 품질 정보에 기초하여, 상기 제1 참고 모델 또는 상기 제2 참고 모델을 선택하고,상기 선택된 제1 참고 모델에 대한 정보 또는 상기 선택된 제2 참고 모델의 식별 정보를 상기 영상 처리 장치로전송하도록 상기 통신부를 제어하는, 서버."}
{"patent_id": "10-2023-0132460", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "영상 처리 장치(200)에 있어서,통신부(210);하나 이상의 인스트럭션들을 저장하는 메모리(230); 및상기 하나 이상의 인스트럭션들을 실행하는 적어도 하나의 프로세서(220)를 포함하고,상기 적어도 하나의 프로세서(220)는, 상기 하나 이상의 인스트럭션들을 실행함으로써,서버(100)로부터 제1 영상 및 메타 모델 정보를 수신하도록 상기 통신부(210)를 제어하고,상기 메타 모델 정보에 기초하여, 메타 모델을 생성하며,상기 제1 영상에 대응하는 학습 데이터 셋을 이용하여 상기 메타 모델을 학습시키고,상기 학습된 메타 모델에 기초하여, 상기 제1 영상을 화질 처리한 제2 영상을 획득하는, 영상 처리 장치."}
{"patent_id": "10-2023-0132460", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제10항에 있어서,공개특허 10-2025-0049706-4-상기 적어도 하나의 프로세서(220)는, 상기 하나 이상의 인스트럭션들을 실행함으로써,상기 메타 모델 정보에 포함되는 적어도 하나의 참고 모델 정보와 상기 적어도 하나의 참고 모델에 적용되는 가중치 정보에 기초하여, 상기 메타 모델을 생성하는, 영상 처리 장치."}
{"patent_id": "10-2023-0132460", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항에 있어서,상기 적어도 하나의 프로세서(120)는, 상기 하나 이상의 인스트럭션들을 실행함으로써,상기 제1 영상의 품질 정보를 획득하고,상기 제1 영상의 품질 정보에 기초하여, 상기 제1 영상과 동일한 카테고리로 분류되는 영상들을열화시킴으로써, 상기 학습 데이터 셋을 생성하는, 영상 처리 장치."}
{"patent_id": "10-2023-0132460", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "서버(100)의 동작 방법에 있어서,원본 영상을 압축하여, 제1 영상을 획득하는 단계;상기 제1 영상에 대한 화질을 분석하여, 상기 제1 영상의 품질 정보를 획득하는 단계;상기 품질 정보에 기초하여, 상기 제1 영상의 화질 처리에 이용되는 메타 모델에 대한 메타 모델 정보를 획득하는 단계; 및상기 메타 모델 정보 및 상기 제1 영상을 영상 처리 장치로 전송하는 단계를 포함하는, 서버의 동작 방법."}
{"patent_id": "10-2023-0132460", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제13항에 있어서,상기 제1 영상은 비디오 컨텐츠에 포함되는 복수의 프레임 영상들을 포함하고,상기 제1 영상의 품질 정보를 획득하는 단계는,상기 복수의 프레임 영상들의 전체적인 품질 정보에 기초하여, 상기 복수의 프레임 영상들 중 제1 시점의 프레임 영상의 품질 정보를 획득하는 단계를 포함하는, 서버의 동작 방법."}
{"patent_id": "10-2023-0132460", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제14항에 있어서,상기 제1 영상의 품질 정보를 획득하는 단계는,상기 복수의 프레임 영상들의 품질 평균 값 및 표준 편차에 기초하여, 품질 상한 값 및 품질 하한 값을 설정하는 단계; 및상기 품질 상한 값 및 품질 하한 값에 기초하여, 상기 제1 시점의 프레임 영상의 품질 값을 결정하는 단계를 포함하는, 서버의 동작 방법."}
{"patent_id": "10-2023-0132460", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제13항 내지 제15항 중 어느 한 항에 있어서,상기 동작 방법은,상기 품질 정보를 상기 영상 처리 장지로 전송하는 단계를 더 포함하는, 서버의 동작 방법."}
{"patent_id": "10-2023-0132460", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제13항 내지 제16항 중 어느 한 항에 있어서,상기 메타 모델은 적어도 하나의 참고 모델에 기초하여, 획득되고,공개특허 10-2025-0049706-5-상기 메타 모델 정보는,상기 적어도 하나의 참고 모델에 대한 정보 및 상기 적어도 하나의 참고 모델에 적용되는 가중치에 대한 정보를포함하고,상기 메타 모델 정보를 획득하는 단계는,상기 품질 정보에 기초하여, 상기 적어도 하나의 참고 모델 및 상기 적어도 하나의 참고 모델에 적용되는 가중치를 결정하는 단계를 포함하는, 서버의 동작 방법."}
{"patent_id": "10-2023-0132460", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제17항에 있어서,상기 적어도 하나의 참고 모델에 적용되는 가중치를 결정하는 단계는,상기 적어도 하나의 참고 모델에 대응하는 품질 정보와 상기 제1 영상에 대한 품질 정보의 차이에 기초하여, 상기 가중치를 결정하는 단계를 포함하는, 서버의 동작 방법."}
{"patent_id": "10-2023-0132460", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제17항 또는 제18항에 있어서,상기 적어도 하나의 참고 모델은,상기 서버에 기 저장된 제1 참고 모델 또는 상기 영상 처리 장치에 기 저장된 제2 참고 모델을 포함하고,상기 동작 방법은,상기 제1 영상에 기초하여, 상기 제1 영상에 대응하는 상기 제1 참고 모델을 생성하는 단계를 더 포함하는, 서버의 동작 방법."}
{"patent_id": "10-2023-0132460", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제19항에 있어서,상기 메타 모델 정보를 획득하는 단계는,상기 품질 정보에 기초하여, 상기 제1 참고 모델 또는 상기 제2 참고 모델을 선택하는 단계를 포함하고,상기 메타 모델 정보를 전송하는 단계는,상기 선택된 제1 참고 모델에 대한 정보 또는 상기 선택된 제2 참고 모델의 식별 정보를 상기 영상 처리 장치로전송하는 단계를 포함하는, 서버의 동작 방법."}
{"patent_id": "10-2023-0132460", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "일 실시예에 따른 서버는, 통신부, 하나 이상의 인스트럭션들을 저장하는 메모리, 및 하나 이상의 인스트럭션들 을 실행하는 적어도 하나의 프로세서를 포함하고, 적어도 하나의 프로세서는, 하나 이상의 인스트럭션들을 실행 함으로써, 원본 영상을 압축하여, 제1 영상을 획득하고, 제1 영상에 대한 화질을 분석하여, 제1 영상의 품질 정 보를 획득하고, 품질 정보에 기초하여, 제1 영상의 화질 처리에 이용되는 메타 모델에 대한 메타 모델 정보를 획 득하고, 메타 모델 정보 및 제1 영상을 영상 처리 장치로 전송하도록 통신부를 제어할 수 있다."}
{"patent_id": "10-2023-0132460", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "다양한 실시예들은 저화질의 영상을 영상 처리 장치로 전송하는 서버 및 그의 동작 방법과 서버로부터 수신한 저화질의 영상을 화질 처리하여 고화질의 영상을 출력하는 영상 처리 장치 및 그의 동작 방법에 관한 것이다."}
{"patent_id": "10-2023-0132460", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "딥러닝 기술의 발전과 함께 다양한 형태의 학습 기반 업스케일링 방법들이 개발되고 있다. 학습 기반 업스케일 방법은 학습 영상의 품질과 실제 처리하는 입력 영상의 품질 특성이 유사할 경우에는 우수한 성능을 보이지만 처리될 영상의 특성이 학습 시 가정한 입력 화질과 차이가 있는 경우 화질 성능이 크게 저하되는 문제가 있다. 이러한 문제를 해결하기 위해서 입력되는 데이터에 맞춰서 AI 모델을 처리하여 적응 시키는 온 디바이스 러닝 (On-Device Learning) 연구가 진행되고 있다. 온 디바이스 러닝 연구 분야에서 최근 영상 처리 및 화질 개선에 대한 논문(ZSSR, CVPR 2018, Zero-Shot Super-Resolution using Deep Internal Learning, 이하 논문 1)이 발표 되었다. 논문 1은 ZSSR (Zero-Shot Super Resolution)로 명명되며, 입력 영상의 열화 특성에 맞게 자기 입력 영상을 사 용하여 데이터베이스(DB)를 구성하고 이를 이용하여 학습된 모델을 사용하여 영상을 확대하는 기술이다. ZSSR은 매번 입력 영상에 맞게 처음부터 새로 데이터베이스를 생성하고 이를 이용하여 모델을 학습시키므로, 학습 복잡 도가 높고, 화질의 변화가 심한 동영상에서는 적용하기 힘들다는 문제가 있다. 이러한 문제점을 개선하기 위해서 또 다른 논문(MetaSR, ECCV 2021, Fast Adaptation to Super-Resolution Networks via Meta-Learning, 이하 논문 2)이 발표되었다. 논문 2는 ZSSR의 학습 연산 복잡도를 줄이기 위해서 초기 메타 모델을 외부 데이터베이스로부터 학습하고 전이 학습(Transfer Learning)을 통해서 입력 영상의 특성 에 맞는 모델을 찾는 기술이다. 그러나, 논문 2의 기술은 하나의 메타 모델만을 이용하므로, 다양한 입력 영상 별 특성을 하나의 메타 모델에 모두 포함시키기에는 성능상의 제약이 있으며, 또한 엣지 디바이스(Edge Devic e)와 같은 저용량 네트워크를 사용하는 환경에서는 이러한 메타 모델의 한계는 온 디바이스 러닝의 성능을 제한 하는 요소가 된다. 논문 1 및 논문 2는 입력 영상을 참조하여 학습 DB를 구성하여 학습하기 때문에 입력 영상이 반복되는 윤곽선 특성을 가지는 빌딩이나 주기적인 텍스쳐가 포함되는 정지 영상의 경우에는 화질 개선 성능을 갖는다. 그렇지만 현실적으로는 기존 방법에서 가정한 영상 외에도 촬영, 전송, 압축 과정에서 열화가 발생된 영상이 많고 이러한 영상들은 화질 복원에 힌트가 되는 고주파 성분들이 손실되어 있고 또한 영상들 내에서 반복되는 성분도 찾기 어려운 경우가 많다. 그래서 자신의 영상 만으로는 학습 DB를 구성하는데 한계가 있으며 이는 성능 저하로 나타 난다. 또한, 기존의 방법은 정지 영상의 화질을 개선하기 위해 개발된 방법이므로, 동영상에는 적용하기 어렵다. 영상 별로 서로 독립적으로 학습된 모델은 학습의 수렴 정도, 학습 데이터베이스의 특성 차이로 인해서 복원 성능 편 차가 존재할 수 있다. 이로 인해서 매 프레임 별로 독립적인 모델을 적용할 경우 영상의 선명도 또한 매번 변화 하게 되어 시간적인 화질의 불균일 현상인 플리커(Flicker) 왜곡이 발생할 수 있다."}
{"patent_id": "10-2023-0132460", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "일 실시예에 따른 서버는, 통신부, 하나 이상의 인스트럭션들을 저장하는 메모리, 및 상기 하나 이상의 인스트 럭션들을 실행하는 적어도 하나의 프로세서를 포함할 수 있다. 상기 적어도 하나의 프로세서는, 상기 하나 이상의 인스트럭션들을 실행함으로써, 원본 영상을 압축하여, 제1 영상을 획득할 수 있다. 상기 적어도 하나의 프로세서는, 상기 하나 이상의 인스트럭션들을 실행함으로써, 상기 제1 영상에 대한 화질을 분석하여, 상기 제1 영상의 품질 정보를 획득할 수 있다. 상기 적어도 하나의 프로세서는, 상기 하나 이상의 인스트럭션들을 실행함으로써, 상기 품질 정보에 기초하여, 상기 제1 영상의 화질 처리에 이용되는 메타 모델에 대한 메타 모델 정보를 획득할 수 있다. 상기 적어도 하나의 프로세서는, 상기 하나 이상의 인스트럭션들을 실행함으로써, 상기 메타 모델 정보 및 상기 제1 영상을 영상 처리 장치로 전송하도록 상기 통신부를 제어할 수 있다. 일 실시예에 따른 영상 처리 장치는, 통신부, 하나 이상의 인스트럭션들을 저장하는 메모리, 및 상기 하나 이상 의 인스트럭션들을 실행하는 적어도 하나의 프로세서를 포함할 수 있다. 상기 적어도 하나의 프로세서는, 상기 하나 이상의 인스트럭션들을 실행함으로써, 서버로부터 제1 영상 및 메타 모델 정보를 수신하도록 상기 통신부를 제어할 수 있다. 상기 적어도 하나의 프로세서는, 상기 하나 이상의 인스트럭션들을 실행함으로써, 상기 메타 모델 정보에 기초 하여, 메타 모델을 생성할 수 있다. 상기 적어도 하나의 프로세서는, 상기 하나 이상의 인스트럭션들을 실행함으로써, 상기 제1 영상에 대응하는 학 습 데이터 셋을 이용하여 상기 메타 모델을 학습시킬 수 있다. 상기 적어도 하나의 프로세서는, 상기 하나 이상의 인스트럭션들을 실행함으로써, 상기 학습된 메타 모델에 기 초하여, 상기 제1 영상을 화질 처리한 제2 영상을 획득할 수 있다. 일 실시예에 따른 서버의 동작 방법은, 원본 영상을 압축하여, 제1 영상을 획득하는 단계를 포함할 수 있다. 상기 서버의 동작 방법은, 상기 제1 영상에 대한 화질을 분석하여, 상기 제1 영상의 품질 정보를 획득하는 단계 를 포함할 수 있다. 상기 서버의 동작 방법은, 상기 품질 정보에 기초하여, 상기 제1 영상의 화질 처리에 이용되는 메타 모델에 대 한 메타 모델 정보를 획득하는 단계를 포함할 수 있다. 상기 서버의 동작 방법은, 상기 메타 모델 정보 및 상기 제1 영상을 영상 처리 장치로 전송하는 단계를 포함할 수 있다."}
{"patent_id": "10-2023-0132460", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 명세서에서 사용되는 용어에 대해 간략히 설명하고, 본 발명에 대해 구체적으로 설명하기로 한다. 본 발명에서 사용되는 용어는 본 발명에서의 기능을 고려하면서 가능한 현재 널리 사용되는 일반적인 용어들을 선택하였으나, 이는 당 분야에 종사하는 기술자의 의도 또는 판례, 새로운 기술의 출현 등에 따라 달라질 수 있 다. 또한, 특정한 경우는 출원인이 임의로 선정한 용어도 있으며, 이 경우 해당되는 발명의 설명 부분에서 상세 히 그 의미를 기재할 것이다. 따라서 본 발명에서 사용되는 용어는 단순한 용어의 명칭이 아닌, 그 용어가 가지 는 의미와 본 발명의 전반에 걸친 내용을 토대로 정의되어야 한다. 명세서 전체에서 어떤 부분이 어떤 구성요소를 \"포함\"한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다른 구성요소를 제외하는 것이 아니라 다른 구성요소를 더 포함할 수 있음을 의미한다. 또한, 명세서에 기재된 \"...부\", \"모듈\" 등의 용어는 적어도 하나의 기능이나 동작을 처리하는 단위를 의미하며, 이는 하드웨어 또는 소프트웨어로 구현되거나 하드웨어와 소프트웨어의 결합으로 구현될 수 있다. 아래에서는 첨부한 도면을 참고하여 실시예들에 대하여 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자 가 용이하게 실시할 수 있도록 상세히 설명한다. 그러나 본 발명은 여러 가지 상이한 형태로 구현될 수 있으며여기에서 설명하는 실시예에 한정되지 않는다. 그리고 도면에서 본 발명을 명확하게 설명하기 위해서 설명과 관 계없는 부분은 생략하였으며, 명세서 전체를 통하여 유사한 부분에 대해서는 유사한 도면 부호를 붙였다. 본 명세서의 실시예에서 \"사용자\"라는 용어는 시스템, 기능 또는 동작을 제어하는 사람을 의미하며, 개발자, 관 리자 또는 설치 기사를 포함할 수 있다. 또한, 본 명세서의 실시예에서, '영상(image)' 또는 '픽처'는 정지영상, 복수의 연속된 정지영상(또는 프레임) 으로 구성된 동영상, 또는 비디오를 나타낼 수 있다. 도 1은 일 실시예에 따른 영상의 화질 처리 시스템을 나타내는 도면이다. 도 1을 참조하면, 일 실시예에 따른 서버는 영상 처리 장치로 컨텐츠를 제공하는 컨텐츠 프로바이더 일 수 있다. 컨텐츠 프로바이더는 소비자에게 다양한 컨텐츠를 제공하는 지상파 방송국이나 케이블 방송국, 또 는 OTT 서비스 제공자, IPTV 서비스 제공자를 의미할 수 있다. 다만, 이에 한정되지 않는다. 일 실시예에 따른 서버는 비디오 컨텐츠, 영상 컨텐츠, 오디오 컨텐츠, 텍스트 컨텐츠 등의 다양한 컨텐츠 를 영상 처리 장치로 전송할 수 있다. 예를 들어, 서버는 영상 처리 장치가 영상 데이터를 실시 간으로 재생할 수 있도록 영상 처리 장치로 영상 데이터를 스트리밍할 수 있다. 또한, 서버는 영상 데이터 이외에도 오디오 데이터 및 텍스트 데이터 등 다양한 타입의 데이터를 영상 처리 장치로 스트리밍 할 수 있다. 일 실시예에 따른 서버는 텔레비전 프로그램이나 VOD 서비스를 통한 각종 영화나 드라마 등의 비디오 컨텐 츠를 영상 처리 장치로 제공할 수 있다. 비디오 컨텐츠는 복수의 프레임 영상들을 포함할 수 있다. 비디오 컨텐츠는 캡쳐 장치에 의해 캡쳐된 후 일 실시예에 따른 서버에 의해 압축되어 전송되고, 영상 처 리 장치에 의해 복원되어 출력될 수 있다. 이때, 비디오 컨텐츠의 획득, 전송, 및 저장하는 과정에서 발생 하는 열화에 따라 비디오 컨텐츠는 다양한 품질을 가질 수 있다. 일 실시예에 따른 서버는 영상 컨텐츠(비디오 컨텐츠)를 압축할 수 있다. 예를 들어, 서버는 동일한 영상 컨텐츠에 대해 서로 다른 해상도 또는 서로 다른 비트레이트를 가지는 복수의 압축 영상 데이터를 획득하 여, 저장할 수 있다. 일 실시예에 따른 서버는 압축된 제1 영상을 영상 처리 장치로 전송할 수 있다. 일 실시예에 따른 영상 처리 장치는 영상을 처리하여 출력할 수 있는 전자 장치일 수 있다. 일 실시예에 따른 영상 처리 장치는 디스플레이를 포함하는 다양한 형태로 구현될 수 있다. 예를 들어, 영상 처리 장치 는 TV, 휴대폰, 태블릿 PC, 디지털 카메라, 캠코더, 노트북 컴퓨터(laptop computer), 데스크탑, 전자책 단말기, 디지털 방송용 단말기, PDA(Personal Digital Assistants), PMP(Portable Multimedia Player), 네비게 이션, MP3 플레이어, 착용형 기기(wearable device) 등과 같은 다양한 전자 장치로 구현될 수 있다. 일 실시예에 따른 영상 처리 장치는 서버로부터 수신한 제1 영상(101, 입력 영상)의 화질 처리를 수 행함으로써, 제2 영상(102, 출력 영상)을 획득할 수 있다. 예를 들어, 영상 처리 장치는 화질 처리 모델을 이용하여, 저해상도(또는 저화질)의 입력 영상을 업스케일링함으로써, 고해상도(또는 고화질)의 출력 영상을 획 득할 수 있다. 일 실시예에 따른 화질 처리 모델은, 제1 영상의 품질에 기초하여, 획득된 메타 모델을, 제1 영상에 대응하는 학습 데이터 셋을 이용하여 학습시킨 모델을 포함할 수 있다. 일 실시예에 따른 서버는 압축된 제1 영상의 품질 정보를 획득하고, 제1 영상의 품질 정보에 기 초하여, 메타 모델 정보를 획득할 수 있다. 서버는 메타 모델 정보와 압축된 제1 영상을 영상 처리 장치 로 전송할 수 있다. 일 실시예에 따른 영상 처리 장치는 서버로부터 수신한 메타 모델 정보에 기초하여, 메타 모델을 생 성하고, 메타 모델을 제1 영상에 대응하는 학습 데이터 셋을 이용하여 학습시킬 수 있다. 영상 처리 장치 는 학습된 메타 모델을 이용하여, 제1 영상의 화질을 처리함으로써, 고화질(또는 고해상도)의 제2 영 상을 획득할 수 있다. 이하, 도면들을 참고하여, 일 실시예에 따른 서버 및 영상 처리 장치의 동작들에 대해 자세히 설명하 기로 한다.도 2는 일 실시예에 따른 다양한 영상들의 품질 정보를 그래프에 나타내는 도면이다. 도 2는 다양한 영상들의 화질을 분석한 결과를 품질 평면으로 나타낸 그래프로, 화질 분석기를 통해서 캡쳐한 동영상들의 품질을 분석한 결과를 2차원 그래프로 보여준다. 도 2를 참조하면, 그래프의 가로 축은 Kernel Sigma 값을 나타내고, 세로 축은 영상의 압축 품질(Quality Factor, QF)을 나타낸다. Kernel Sigma 값은 영상의 블러 품질을 나타내는 값으로, Kernel Sigma 값이 클수록 블러 정도가 크고, Kernel Sigma 값이 작을수록 블러 정도가 작음을 나타낸다. QF는 압축으로 인한 열화 정도를 나타내는 것으로, QF 값이 작을수록 압축으로 인한 열화가 심하고, QF 값이 클수록 압축으로 인한 열화가 적음 을 나타낸다. 그래프에서 동일한 모양의 기호는 동일한 해상도를 갖는 영상의 품질 값을 나타낸다. 그래프에 도시 된 바와 같이 기호가 서로 동일한 동일 해상도의 영상들이라도 영상들의 품질 값은 다양하게 분포될 수 있다. 동일한 해상도를 가지는 영상들이라도 영상들의 취득, 전송, 저장 과정에서 발생하는 열화에 따라서 영상들은 다양한 품질들을 가질 수 있기 때문이다. 따라서, 영상의 품질 정보에 따라 품질 정보에 적응적인 화질 처리(영상 처리)가 필요하다. 일 실시예에 따른 서버는 제1 영상의 품질 정보에 기초하여, 제1 영상에 적응적인 메타 모델을 획득할 수 있다. 일 실시예에 따른 영상 처리 장치는 서버로부터 획득한 메타 모델 및 제1 영상의 품질 정보에 기초하여, 제1 영상 에 적응적인 화질 처리 모델을 생성하고, 화질 처리 모델을 이용하여, 제1 영상의 화질 처리를 수행할 수 있다. 이에 따라, 제1 영상의 화질 처리 성능을 향상시킬 수 있다. 도 3은 일 실시예에 따른 서버의 동작 방법을 나타내는 흐름도이다. 도 3을 참조하면, 일 실시예에 따른 서버는 원본 영상을 압축하여, 제1 영상을 획득할 수 있다(S310). 일 실시예에 따른 서버는 동일한 원본 영상에 대해 서로 다른 해상도 또는 서로 다른 비트레이트를 가지는 복수의 압축 영상 데이터를 획득하여, 저장할 수 있다. 예를 들어, 압축 영상 데이터는 동일한 컨텐츠에 대하여, 8k, 4k, FHD, HD의 해상도를 가지는 영상 데이터를 포 함할 수 있다. 또는, 압축 영상 데이터는 동일한 원본 영상에 대하여, 40Mbps, 30Mbps, 20Mbps, 10Mbps의 비트 레이트를 가지는 복수의 압축 영상 데이터를 포함할 수 있다. 다만, 이에 한정되지 않는다. 일 실시예에 따른 서버는 일 실시예에 따른 영상 처리 장치와 연결된 네트워크의 상태에 따라, 복수 의 압축 영상 데이터 중, 영상 처리 장치로 전송할 영상 데이터(제1 영상)를 결정할 수 있다. 네트워크의 상태 는 예를 들어, 서버와 영상 처리 장치 간의 송수신 경로에서의 트래픽 발생 정도에 따라 결정될 수 있으나, 이에 한정되지 않는다. 또는, 서버는 영상 처리 장치의 요청에 의해 복수의 압축 영상 데이터 중 영상 처리 장치로 전송할 영상 데이터(제1 영상)를 결정할 수 있다. 일 실시예에 따른 서버는 제1 영상에 대한 화질을 분석하여, 품질 정보를 획득할 수 있다(S320). 예를 들어, 서버는 제1 영상의 화질 또는 품질을 판단할 수 있다. 영상의 화질은 영상의 열화 정도를 나타 낼 수 있다. 서버는 제1 영상의 압축 열화, 제1 영상의 선명도(sharpness degree), 블러(blur) 정도, 노 이즈 정도, 영상의 해상도 중 적어도 하나를 평가 또는 판단할 수 있다. 일 실시예에 따른 서버는 제1 영상의 화질을 분석 또는 평가하도록 훈련된 제1 뉴럴 네트워크를 이용하여 제1 영상의 화질을 분석 또는 평가할 수 있다. 예를 들어, 제1 뉴럴 네트워크는 영상 화질 평가(Image Quality Assessment: IQA) 기술, 비디오 화질 평가(Video Quality Assessment: VQA) 기술 등을 이용하여, 영상 또는 비 디오의 화질을 평가하도록 훈련된 뉴럴 네트워크일 수 있다. 예를 들어, 서버는 제1 뉴럴 네트워크를 이용하여, 영상의 블러 품질을 나타내는 커널 시그마(kernel sigma) 값과 영상의 압축 품질을 나타내는 퀄리티 팩터(QF: Quality Factor)를 품질 정보로 획득할 수 있다. 다 만, 이에 한정되지 않는다. 일 실시예에 따른 서버는 제1 영상이 비디오 컨텐츠에 포함되는 복수의 프레임 영상들 중 어느 하나인 경 우, 복수의 프레임 영상들 각각에 대한 품질 정보에 기초하여, 제1 영상의 품질 정보를 획득할 수 있다. 예를 들어, 서버는 복수의 프레임 영상들 각각의 품질 값들에 기초하여, 제1 영상의 품질 값이 이상이 있 는 지를 판단하고, 이상이 있는 경우에는 해당 값을 사용하지 않을 수 있다. 서버는 복수의 프레임 영상들 의 품질 값들의 평균값, 표준 편차에 기초하여, 제1 영상의 품질 값의 이상 여부를 결정할 수 있다. 이에 대해 서는 도 6을 참조하여, 자세히 후술하기로 한다. 일 실시예에 따른 서버는 320 단계(S320)에서 획득한 품질 정보에 기초하여, 메타 모델 정보를 획득할 수 있다(S330). 예를 들어, 서버는 적어도 하나의 참고 모델을 이용하여, 메타 모델을 획득할 수 있다. 참고 모델은 학습 영상을 이용하여 기 학습된 화질 처리 모델로, 영상 처리 장치에 저장된 제1 참고 모델들과 서버에 저장된 제2 참고 모델들을 포함할 수 있다. 일 실시예에 따른 서버는 제1 영상의 화질 처리를 위한 제2 참고 모델들을 생성할 수 있다. 예를 들어, 서 버는 제1 영상과 유사한 품질 정보를 가지는 학습 영상들을 이용하여, 화질 처리 모델을 학습시킴으로써, 제2 참고 모델들을 생성할 수 있다. 또는, 다양한 품질 정보를 가지는 학습 영상들을 이용하여, 기 학습된 제1 참고 모델들은 영상 처리 장치 에 저장될 수 있다. 일 실시예에 따른 서버는 복수의 참고 모델들 각각에 대응하는 학습 영상들의 품질 정보와 제1 영상의 품 질 정보를 비교하여, 제1 영상의 품질 정보와 유사한 품질 정보를 가지는 학습 영상에 대응하는 참고 모델을 검 색할 수 있다. 일 실시예에 따른 서버는 복수의 참고 모델들을 검색할 수 있으며, 복수의 참고 모델들 각각에 가중치를 적용하여, 복수의 참고 모델들의 가중 합을 수행함으로써, 메타 모델을 획득할 수 있다. 이때, 복수의 참고 모 델들 각각에 적용되는 가중치는 참고 모델에 대응하는 학습 영상의 품질 정보와 제1 영상의 품질 정보의 차이에 기초하여 결정될 수 있다. 일 실시예에 따른 메타 모델 정보는, 메타 모델을 획득하기 위한 적어도 하나의 참고 모델에 대한 정보, 적어도 하나의 참고 모델에 적용되는 가중치 정보, 획득된 메타 모델 등을 포함할 수 있다. 예를 들어, 적어도 하나의 참고 모델에 대한 정보는, 제1 참고 모델을 이용하여, 메타 모델이 획득되는 경우, 제1 참고 모델의 식별 정보를 포함할 수 있다. 또는, 제2 참고 모델을 이용하여, 메타 모델이 획득되는 경우, 적어도 하나의 참고 모델에 대한 정보는, 제2 참고 모델을 포함할 수 있다. 일 실시예에 따른 서버는 메타 모델 정보 및 제1 영상을 영상 처리 장치로 전송할 수 있다(S340). 예를 들어, 서버는 제2 참고 모델들에 기초하여, 메타 모델을 획득하는 경우, 획득한 메타 모델 또는 제2 참고 모델들을 영상 처리 장치로 전송할 수 있다. 또는 서버는 제1 참고 모델들에 기초하여, 메타 모 델을 획득하는 경우, 제1 참고 모델들에 대한 식별 정보(예를 들어, 모델 번호 등)를 영상 처리 장치로 전 송할 수 있다. 또한, 서버는 메타 모델을 획득하기 위한 복수의 참고 모델들 각각에 적용되는 가중치 정보를 영상 처리 장치로 전송할 수 있다. 또한, 서버는 서버에서 획득한 제1 영상에 대한 품질 정보를 영상 처리 장치로 전송할 수 있다. 도 4는 일 실시예에 따른 서버의 구성을 나타내는 도면이다. 도 4를 참조하면, 일 실시예에 따른 서버는 영상 압축부, 화질 분석부 및 메타 모델 획득부 를 포함할 수 있다. 일 실시예에 따른 영상 압축부는 원본 영상에 대하여, 서로 다른 해상도 또는 서로 다른 비트레이트를 가 지는 복수의 압축 영상 데이터를 획득하여, 저장할 수 있다. 예를 들어, 압축 영상 데이터는 동일한 컨텐츠에 대하여, 8k, 4k, FHD, HD의 해상도를 가지는 영상 데이터를 포함할 수 있다. 또는, 압축 영상 데이터는 동일한 원본 영상에 대하여, 40Mbps, 30Mbps, 20Mbps, 10Mbps의 비트레이트를 가지는 복수의 압축 영상 데이터를 포함 할 수 있다. 다만, 이에 한정되지 않는다. 일 실시예에 따른 서버와 영상 처리 장치 간에 연결된 네트워크의 상태에 따라, 복수의 압축 영상 데 이터 중에 영상 처리 장치로 전송할 영상 데이터(제1 영상)가 결정될 수 있다. 또는, 영상 처리 장치(20 0)의 요청에 기초하여, 영상 처리 장치로 전송할 영상 데이터(제1 영상)가 결정될 수 있다.일 실시예에 따른 화질 분석부는 영상 처리 장치로 전송할 제1 영상의 화질 또는 품질을 분석 또는 평가할 수 있다. 영상의 화질은 영상의 열화 정도를 나타낼 수 있다. 화질 분석부는 제1 영상의 압축 열화, 제1 영상의 선명도(sharpness degree), 블러(blur) 정도, 노이즈 정도, 영상의 해상도 중 적어도 하나를 평가 또는 결정할 수 있다. 일 실시예에 따른 화질 분석부는 제1 영상의 화질을 분석 또는 평가하도록 훈련된 제1 뉴럴 네트워크를 이 용하여 제1 영상의 화질을 분석 또는 평가할 수 있다. 예를 들어, 제1 뉴럴 네트워크는 영상 화질 평가(Image Quality Assessment: IQA) 기술, 비디오 화질 평가(Video Quality Assessment: VQA) 기술 등을 이용하여, 영상 또는 비디오의 화질을 평가하도록 훈련된 뉴럴 네트워크일 수 있다. 예를 들어, 제1 뉴럴 네트워크는 제1 영상을 입력 받아 제1 영상의 블러 품질을 나타내는 커널 시그마(kernel sigma) 값과 영상의 압축 품질을 나타내는 퀄리티 팩터(QF: Quality Factor)를 출력하도록 훈련된 뉴럴 네트워 크일 수 있다. 도 5를 참조하여, 일 실시예에 따른 제1 뉴럴 네트워크를 자세히 설명하기로 한다. 도 5는 일 실시예에 따른 제1 뉴럴 네트워크의 구조를 나타내는 도면이다. 도 5를 참조하면, 제1 뉴럴 네트워크는 CNN(Convolution Neural Network), DCNN(Deep Convolution Neural Network) 또는 캡스넷(Capsnet) 기반의 신경망일 수 있다. 예를 들어, 제1 뉴럴 네트워크는 다양한 데이터들을 입력 받고, 입력된 데이터들을 분석하는 방법, 입력된 데이터들을 분류하는 방법, 및/또는 입력된 데이터들에서 결과 데이터 생성에 필요한 특징을 추출하는 방법 등 을 스스로 발견 또는 터득할 수 있도록 훈련될 수 있다. 제1 뉴럴 네트워크는 다수의 학습 데이터들에 학 습 알고리즘을 적용하여, 원하는 특성의 인공지능 모델로 만들어질 수 있다. 이러한 학습은 서버 자체에서 이루어질 수도 있고, 별도의 서버/시스템을 통해 이루어 질 수도 있다. 학습 알고리즘의 예로는, 지도형 학습(supervised learning), 비지도형 학습(unsupervised learning), 준지도 형 학습(semi-supervised learning) 또는 강화 학습(reinforcement learning)이 있으며, 실시 예에서의 학습 알고리즘은 명시한 경우를 제외하고 전술한 예에 한정되지 않는다. 예를 들어, 제1 뉴럴 네트워크는 학습 데이터를 입력 값으로 하는 지도 학습(supervised learning) 을 통 하여, 데이터 추론 모델로 학습될 수 있다. 또는, 제1 뉴럴 네트워크는 별다른 지도 없이 영상의 화질을 판단하기 위해 필요한 데이터의 종류를 스스로 학습함으로써, 영상의 화질을 판단하기 위한 기준을 발견하는 비 지도 학습(unsupervised learning)을 통하여, 데이터 추론 모델로 학습될 수 있다. 또는 제1 뉴럴 네트워크 는 학습에 따라 영상의 품질을 추론한 결과가 올바른 지에 대한 피드백을 이용하는 강화 학습 (reinforcement learning)을 통하여, 데이터 추론 모델로 학습될 수 있다. 실시 예에서, 제1 뉴럴 네트워크는 입력 계층, 숨은 계층, 및 출력 계층을 포함할 수 있다. 실시 예에서, 숨은 계층은 복수개의 히든 레이어들을 포함할 수 있다. 제1 뉴럴 네트워크는 두 개 이상의 히든 레이어들 을 포함하는 딥 뉴럴 네트워크(DNN)일 수 있다. 딥 뉴럴 네트워크(DNN)는 복수의 계층들을 통한 연산을 수행하 는 뉴럴 네트워크로, 연산을 수행하는 내부의 계층(layer)의 개수에 따라서 네트워크의 심도(depth)가 증가할 수 있다. 딥 뉴럴 네트워크(DNN) 연산은 컨볼루션 뉴럴 네트워크(CNN: Convolution Neural Network) 연산 등을 포함할 수 있다. 일 실시예에 따른 제1 뉴럴 네트워크는 각 학습 영상 및 각 학습 영상에 대응하는 품질 값들을 학습 데이 터 셋으로 포함하는 학습 DB를 이용하여 학습될 수 있다. 예를 들어, 학습 데이터 셋은 고해상도 영상을 다양한 방법으로 압축하거나 블러링하거나 또는 노이즈를 추가하여 생성된 열화 영상과 열화 영상의 품질 값을 포함할 수 있다. 즉, 제1 뉴럴 네트워크는 제1 뉴럴 네트워크로 열화 영상이 입력되었을 때 열화 영상의 품 질 값이 출력되도록 훈련될 수 있다. 예를 들어, 도 5에 도시된 제1 뉴럴 네트워크에는 R, G, B 채널들(RGB 3ch)을 포함하는 제1 영상이 입력될 수 있다. 또는, Y, U, V 채널들(YUV 3ch)을 포함하는 제1 영상이 입력될 수 있다. 일 실시예에 따른 제1 뉴럴 네트워크는 R, G, B 채널들(RGB 3ch) 또는 Y, U, V 채널들(YUV 3ch)을 포함하 는 제1 영상을 입력 받고, 제1 영상에 하나 이상의 커널들 또는 필터들을 적용하여 컨볼루션 연산을 수행하여 특징 맵을 추출할 수 있다. 예컨대, 제1 뉴럴 네트워크는 제1 영상에 3X3 필터 32개를 적용하여 32채널을 출력할 수 있다. 제1 뉴럴 네트워크는 컨볼루션 연산의 대상을 좌측에서 우측으로, 상단에서 하단으로 한픽셀씩 스캔하면서, 커널(Kernel)에 포함되는 가중치 값들을 곱하여 합산함으로써, 결과 값을 생성할 수 있다. 컨볼루션 연산의 대상이 되는 데이터는 한 픽셀씩 이동하면서 스캔될 수도 있으나, 2개 픽셀 또는 그 이상의 픽 셀 개수만큼 이동하면서 스캔될 수도 있다. 스캔 과정에서 입력 데이터가 이동하는 픽셀의 개수를 스트라이드 (stride)라고 하며, 스트라이드의 크기에 따라 출력되는 특징 맵의 크기가 결정될 수 있다. 일 실시예에 따른 제1 뉴럴 네트워크는 하나의 입력 영상에 대해서 두 종류의 품질 값이 출력되는, Single Input Multi Output 구조를 가질 수 있다. 또한, 일 실시예에 따른 제1 뉴럴 네트워크는 네트워크의 복잡도를 줄이기 위해서 특징을 추출하는 중간 레이어들은 공용으로 사용하고 마지막 단에서 출력을 분리시켜 영상의 품질 요소들을 출력하는 구조를 가질 수 있다. 일 실시예에 따른 제1 뉴럴 네트워크는 풀링을 통해 128 채널의 벡터를 획득하고, 이를 리니어(linear) 네 트워크를 통해서 256 채널의 벡터로 변환할 수 있다. 이후, 제1 뉴럴 네트워크는 256 채널의 벡터를 1차원 으로 줄여 최종 결과를 획득할 수 있다. 실시 예에서, 제1 뉴럴 네트워크는 입력 영상의 품질 값을 정의된 두 개의 품질 값으로 출력할 수 있다. 일 실시예에 따른 제1 뉴럴 네트워크는 블러 시그마(blur sigma 또는 Kernel Sigma)와 압축 화질 (Compression QF)을 결과 값들로 출력할 수 있다. Kernel Sigma와 QF는 압축된 영상이 가지는 열화를 함축적으 로 표현할 수 있다. 다만, 이에 한정되지 않으며, 일 실시예에 따른 제1 뉴럴 네트워크는 블러 시그마(blur sigma 또는 Kernel Sigma)와 압축 화질(Compression QF) 값 이외에도 다양한 형태의 품질 값들을 결과로 획득 할 수 있다. 일 실시예에 따른 화질 분석부는 제1 영상을 포함하는 컨텐츠 일부 또는 전체에 대한 품질 값들에 기초하 여, 제1 영상에 대해 통계적으로 안정적인 품질 값을 획득할 수 있다. 예를 들어, 컨텐츠가 비디오 컨텐츠인 경 우, 컨텐츠는 복수의 프레임 영상들을 포함할 수 있으며, 제1 영상은 복수의 프레임 영상들 중 어느 하나일 수 있다. 일 실시예에 따른 화질 분석부는 복수의 프레임 영상들 각각에 대한 품질 값을 획득할 수 있다. 화질 분석 부는 복수의 프레임 영상들의 품질 값들에 기초하여 제1 영상의 품질 값을 결정할 수 있다. 이에 대해서는 도 6을 참조하여, 설명하기로 한다. 도 6은 일 실시예에 따른 비디오 컨텐츠에 포함되는 복수의 프레임 영상들에 대한 품질 값을 나타내는 그래프이 다. 도 6의 그래프의 x축은 복수의 프레임 영상들의 번호를 나타내며, y축은 프레임 영상의 품질 값(예를 들어, 블 러 품질 값)을 나타낸다. 일 실시예에 따른 화질 분석부는 복수의 프레임 영상들의 블러 품질 값들의 평균 값과 표준 편차에 기초하 여, 품질 값의 상한(upper bound)과 하한(lower bound)을 설정함으로써, 품질 값의 가변 범위를 결정할 수 있다. 화질 분석부는 제1 영상의 품질 값이 상한보다 크거나 하한보다 작은 경우, 해당 품질 값을 사용하 지 않고, 다른 값으로 대체할 수 있다. 예를 들어, 화질 분석부는 복수의 프레임 영상들의 품질 값들의 평 균 값을 제1 영상의 품질 값으로 사용할 수 있다. 또는, 화질 분석부는 제1 영상의 이전 프레임 영상의 품 질 값과 제1 영상의 이후 프레임 영상의 품질 값에 기초하여, 계산된 품질 값을 제1 영상의 품질 값으로 사용할 수 있다. 다만, 이에 한정되지 않으며, 화질 분석부는 다양한 방법으로 컨텐츠 전체에 대한 화질 분석을 수행함으로 써, 제1 영상의 품질 값이 이상이 있는 것으로 판단되는 경우, 제1 영상의 품질 값을 보정할 수 있다. 일 실시예에 따른 서버의 화질 분석부는 복수의 프레임 영상들을 포함하는 컨텐츠 전체에 대한 화질 분석을 수행함으로써, 복수의 프레임 영상들 중 하나의 품질 값에 이상이 있는 경우, 해당 품질 값을 보정함으 로써, 화질 분석에 대한 정확도를 향상시킬 수 있다. 또한, 서버는 컨텐츠의 평균 품질 값 또는 품질 값 가변 범위 등의 통계를 영상 처리 장치로 전송할 수 있다. 다시, 도 3을 참조하면, 메타 모델 획득부는 화질 분석부에서 획득한 제1 영상의 품질 정보에 기초하 여, 제1 영상의 화질 처리를 위한 메타 모델 정보를 생성할 수 있다.예를 들어, 메타 모델 획득부는 적어도 하나의 참고 모델을 이용하여, 메타 모델을 획득할 수 있다. 참고 모델은 학습 영상을 이용하여 기 학습된 화질 처리 모델로, 영상 처리 장치에 저장된 제1 참고 모델들과 서버에 저장된 제2 참고 모델들을 포함할 수 있다. 다양한 품질 정보를 가지는 학습 영상들을 이용하여, 기 학습된 제1 참고 모델들은 영상 처리 장치에 저장될 수 있다. 일 실시예에 따른 메타 모델 획득부는 제1 영상의 화질 처리를 위한 제2 참고 모델들을 생성할 수 있다. 예를 들어, 메타 모델 획득부는 제1 영상과 유사한 품질 정보를 가지는 학습 영상들을 이용하여, 화질 처 리 모델을 학습시킴으로써, 제2 참고 모델들을 생성할 수 있다. 일 실시예에 따른 메타 모델 획득부가 제1 영상의 품질 정보 및 적어도 하나의 참고 모델을 이용하여 메타 모델을 획득하는 방법에 대해서는 이하, 도 7을 참조하여, 설명하기로 한다. 도 7은 일 실시예에 따른 적어도 하나의 참고 모델에 기초하여, 메타 모델이 획득되는 것을 설명하기 위한 도면 이다. 일 실시예에 따른 제1 영상의 화질 처리를 위한 메타 모델은 기 학습된 화질 처리 모델인 참고 모델에 기초하여 생성될 수 있다. 도 7의 그래프는 품질 평면 그래프를 나타낸다. 품질 평면 그래프는 영상의 품질을 2개의 품질 요소로 나타낸 그래프로, 가로축은 품질 요소 1을 나타내고, 세로 축은 품질 요소 2를 나타낼 수 있다. 일 실시예에 따른 품질 평면 그래프는 격자 형태로 N개의 포인트를 포함할 수 있다. 예를 들어, N개의 포인트들 각각에 대응하는 학습 영상들은 해당 품질을 가지도록 열화된 학습 영상들을 포함할 수 있다. 즉, 도 7의 그래 프에서 포인트들 각각의 좌표 값에 해당하는 품질 값을 가지는 학습 영상들을 의미할 수 있다. 예를 들어, 제1 포인트(Pt1)는 제1 포인트의 좌표 값(x1, y1)을 품질 값으로 가지는 학습 영상들을 의미하고, 제2 포인트(Pt2) 는 제2 포인트의 좌표 값(x2, y1)을 품질 값으로 가지는 학습 영상들을 의미할 수 있다. 참고 모델을 생성하는 장치(참고 모델 생성 장치)는 열화 전 학습 영상들을 열화시켜 N개의 포인트들 각각에 대 한 학습 영상들을 생성할 수 있다. 참고 모델 생성 장치는 열화 전 학습 영상들과 열화 후 학습 영상들을 포함 하는 학습 데이터 셋을 이용하여, 화질 처리 모델을 훈련시킴으로써, 참고 모델을 생성할 수 있다. 예를 들어, 참고 모델 생성 장치는 열화 전 학습 영상들과 열화 전 학습 영상들을 제1 포인트(Pt 1)의 품질 값을 가지도록 열화시켜 획득한 학습 영상들을 학습 데이터 셋으로 이용하여, 화질 처리 모델을 학습시킴으로써, 제1 포인트 (Pt1)에 대응하는 참고 모델 1을 생성할 수 있다. 참고 모델 1은 제1 포인트(Pt1)의 품질 값에 대응하는 열화 후 학습 영상들이, 열화 전 학습 영상들로 복원되도 록 학습된 화질 처리 모델일 수 있다. 또한, 참고 모델 1은 제1 포인트(Pt1)의 품질 값을 가지는 영상들의 화질 을 처리하기에 적합한 모델일 수 있다. 또한, 참고 모델 생성 장치는 열화 전 학습 영상들과 열화 전 학습 영상들을 제2 포인트(Pt2)의 품질 값을 가지 도록 열화시켜 획득한 학습 영상들을 학습 데이터 셋으로 이용하여, 화질 처리 모델을 학습시킴으로써, 제2 포 인트(Pt2)에 대응하는 참고 모델 2를 생성할 수 있다. 참고 모델 2는 제2 포인트(Pt2)의 품질 값에 대응하는 열화 후 학습 영상들이, 열화 전 학습 영상들로 복원되도 록 학습된 화질 처리 모델일 수 있다. 또한, 참고 모델 2는 제2 포인트(Pt2)의 품질 값을 가지는 영상들의 화질 을 처리하기에 적합한 모델일 수 있다. 일 실시예에 따른 참고 모델 생성 장치는 도 7에 도시된 격자 형태의 N개의 포인트들 각각에 대응하는 참고 모 델을 생성할 수 있다. 참고 모델 생성 장치는 균일 샘플링을 통해서 목표가 되는 학습 영상들의 품질 값의 위치 를 격자 형태의 N개의 포인트들 각각의 위치로 결정함으로써, N개의 참고 모델들이 균일한 간격의 품질 값을 갖 는 학습 영상들로 각각 학습되도록 할 수 있다. 다만, 이에 한정되는 것은 아니며, 참고 모델을 생성하는 장치는 학습 영상들의 품질 값 분포를 기반으로 참고 모델에 대응하는 품질 값을 결정할 수 있다. 예를 들어, 참고 모델 생성 장치는 학습 영상들을 분석하여, 학습 영상들의 품질 값을 획득하고, 학습 영상들의 품질 값의 통계적 분포를 통해서 대표 품질 샘플링 위치를 결정할 수 있다. 예를 들어, 참고 모델 생성 장치는 K-means clustering 알고리즘을 이용하여 대표 샘플링 위치를 결정 할 수 있다. 이 방법은 데이터의 분포를 K개의 대표점으로 나타낼 경우 최소의 에러를 가지는 지점을 찾는 알고 리즘이다.참고 모델 생성 장치는 학습 영상들의 품질 값 분포를 소정 개수, 예를 들어, K개의 클러스터(cluster)로 묶고, 각 클러스터에서 거리 차이의 분산이 최소가 되는 품질 값을 결정할 수 있다. 참고 모델 생성 장치는 결정된 품 질 값을 갖는 화질 열화 후 학습 영상들과, 그 영상들에 대응하는 화질 열화 전의 학습 영상들을 학습 데이터 셋으로 이용하여, 참고 모델을 학습시킬 수 있다. 이 경우, 높은 통계의 품질 값을 갖는 영상들을 학습 영상들 을 이용하여, 참고 모델을 학습시킬 수 있기 때문에, 참고 모델의 개수를 줄일 수 있다. 또한, 이와 같이 획득 된 참고 모델은 향후 메타 모델 생성 시에 이용 가능성이 보다 높아질 수 있다. 또한, 이와 같이 획득된 참고 모델을 이용하여 메타 모델을 생성할 경우, 연산 복잡도 및 메모리 사용량을 줄일 수 있다. 학습된 참고 모델들은 일 실시예에 따른 서버 또는 영상 처리 장치에 저장될 수 있다. 한편, 일 실시예에 따른 서버는 상기에서 설명한 방법과 동일한 방법으로 참고 모델들을 생성할 수 있다. 예를 들어, 서버는 제1 영상의 화질 처리를 수행하기 위한 제2 참고 모델들을 생성할 수 있다. 서버 는 제1 영상과 유사한 품질 정보를 가지는 학습 영상들을 이용하여, 화질 처리 모델을 학습시킴으로써, 제2 참 고 모델들을 생성할 수 있다. 제2 참고 모델들은 제1 영상과 유사한 품질 정보를 가지는 열화 후 학습 영상들이, 열화 전 학습 영상들로 복원되도록 학습된 화질 처리 모델일 수 있다. 다만, 이에 한정되지 않는다. 일 실시예에 따른 메타 모델 획득부는 복수의 참고 모델들 각각에 대응하는 학습 영상들의 품질 정보와 제 1 영상의 품질 정보를 비교하여, 제1 영상의 품질 정보와 유사한 품질 정보를 가지는 학습 영상에 대응하는 참 고 모델을 검색할 수 있다. 메타 모델 획득부는 제1 영상의 품질 값과 가까운 품질 값을 가지는 학습 영상들로 학습된 참고 모델을 검 색할 수 있다. 예를 들어, 메타 모델 획득부는 도 7에 도시된 바와 같이, 제1 영상의 품질 값과 참고 모델 들을 학습시키는 데 이용된 학습 영상들의 품질 값의 차이를 거리로 계산하여, 거리 순으로 가까운 참고 모델을 검색할 수 있다. 또한, 메타 모델 획득부는 복수개의 참고 모델들 중에서, 제1 영상의 품질 값과의 차이가 기준 값 이내인 품질 값을 가지는 학습 영상들로 학습된 참고 모델들을 검색할 수 있다. 또는, 메타 모델 획득부는 복수의 참고 모델들 중에서, 제1 영상의 품질 값과의 차이가 적은(거리가 가까운) 순서대로 기 설정된 개수만큼의 품질 값을 가지는 학습 영상들로 학습된 참고 모델들을 검색할 수 있다. 도 7에 도시된 바와 같이, 제1 영상이 별표 모양이 표시된 지점의 품질 값을 가지는 경우, 메타 모델 획득부 는 도 7의 그래프 상에서 별표 모양과 가까운 포인트, 즉, 제1 영상의 품질 값과 가까운 품질 값을 가지는 학습 영상들로 학습된 참고 모델을 검색할 수 있다. 메타 모델 획득부는 별표 모양과 가까운 제1 포인트(Pt1)에 대응하는 참고 모델 1, 제2 포인트(Pt2)에 대 응하는 참고 모델 2, 제3 포인트(Pt3)에 대응하는 참고 모델 3, 제4 포인트(Pt4)에 대응하는 참고 모델 4를 검 색 또는 선택할 수 있다. 일 실시예에 따른 메타 모델 획득부는 검색된 복수개의 참고 모델들을 보간(interpolation)하여 메타 모델 을 획득할 수 있다. 복수개의 참고 모델들을 보간한다는 것은, 알려진 참고 모델들의 파라미터를 보간하여 메타 모델의 파라미터로 이용하는 것을 의미할 수 있다. 메타 모델 획득부는 제1 영상의 품질 값과 참고 모델에 대응하는 품질 값의 차이(별표 모양의 위치와 참고 모델에 대응하는 품질 값의 위치 사이의 거리)를 이용하여, 가중치(보간 계수)를 획득할 수 있다. 예를 들어, 메타 모델 획득부는 다음의 수학식 1과 같이 참고 모델들을 보간하여, 메타 모델을 획득할 수 있다. [수학식 1] 메타 모델 = W1 * 참고 모델 1 + W2 * 참고 모델 2 + … + WN * 참고 모델 N 여기서, 참고 모델 1 내지 N은 참고 모델의 파라미터를 의미할 수 있다. W1 내지 WN은 각 참고 모델에 적용되는 가중치이며, 가중치는 선택된 참고 모델들에 대응하는 품질 값과 제1 영상의 품질 값의 차이(별표 모양의 위치 와 참고 모델에 대응하는 품질 값의 위치 사이의 거리)에 반비례하는 값으로 결정될 수 있다. 또한, 가중치들의 합은 1일 수 있다. 다만, 이에 한정되는 것은 아니며, 메타 모델 획득부는 복수개의 참고 모델들을 보간하여 메타 모델을 획득하기 위해 다양한 방법을 이용할 수 있다. 예를 들어, 메타 모델 획득부는 선형 보간 법, spline 보간법, 삼차 보간법(cubic interpolation), 선형 보간법을 2차원으로 확장시킨 쌍선형보간법 (bilinear interpolation), 삼차 보간법을 2차원으로 확장시킨 쌍삼차보간법(bicubic interpolation) 등 다양 한 보간 방법을 이용하여 참고 모델로부터 메타 모델을 획득할 수 있다. 일 실시예에 따른 메타 모델 획득부는 획득된 메타 모델에 대한 정보(메타 모델 정보)와 제1 영상을 영상 처리 장치로 전송할 수 있다. 또한, 메타 모델 획득부는 제1 영상의 품질 정보를 영상 처리 장치 로 전송할 수 있다. 일 실시예에 따른 메타 모델 정보는, 메타 모델을 획득하기 위한 적어도 하나의 참고 모델에 대한 정보, 적어도 하나의 참고 모델에 적용되는 가중치 정보, 획득된 메타 모델 등을 포함할 수 있다. 예를 들어, 제1 참고 모델을 이용하여, 메타 모델이 획득되는 경우, 메타 모델 정보는 제1 참고 모델의 식별 정 보와 제1 참고 모델에 적용되는 가중치 정보를 포함할 수 있다. 또는, 제2 참고 모델을 이용하여, 메타 모델이 획득되는 경우, 메타 모델 정보는 제2 참고 모델 정보와 제2 참고 모델에 적용되는 가중치 정보를 포함할 수 있 다. 일 실시예에 따른 메타 모델 정보 및 제1 영상의 품질 정보는 제1 영상의 식별 정보 또는 제1 영상의 시간 정보 (예를 들어, 타임 스탬프)와 함께 영상 처리 장치로 전송될 수 있다. 도 8은 일 실시예에 따른 영상 처리 장치의 동작 방법을 나타내는 흐름도이다. 도 8을 참조하면, 일 실시예에 따른 영상 처리 장치는 제1 영상 및 메타 모델 정보를 수신할 수 있다 (S810). 일 실시예에 따른 영상 처리 장치는 메타 모델 정보에 기초하여, 메타 모델을 생성할 수 있다(S820). 일 실시예에 따른 영상 처리 장치는 메타 모델 정보에 제1 참고 모델의 식별 정보가 포함된 경우, 제1 참 고 모델의 식별 정보에 대응하는, 영상 처리 장치에 기 저장된 제1 참고 모델을 로딩할 수 있다. 또한, 영 상 처리 장치는 메타 모델 정보에 제2 참고 모델 또는 메타 모델에 대한 정보가 포함된 경우, 제2 참고 모 델 또는 메타 모델을 영상 처리 장치에 저장할 수 있다. 영상 처리 장치는 제1 참고 모델 또는 제2 참고 모델에 메타 모델 정보에 포함된 가중치를 적용하여, 메타 모델을 생성할 수 있다. 예를 들어, 영상 처리 장치는 복수개의 참고 모델들 각각에 가중치를 적용하고, 가중치가 적용된 참고 모델들을 합함으로써(가중 합), 메타 모델을 생성할 수 있다. 다만, 이에 한정되지 않는 다. 일 실시예에 따른 영상 처리 장치는 제1 영상에 대응하는 학습 데이터 셋을 이용하여, 820 단계(S820)에서 생성된 메타 모델을 학습시킬 수 있다(S830). 예를 들어, 영상 처리 장치는 제1 영상을 이용하여, 제1 영상에 대응하는 학습 데이터 셋을 획득할 수 있 다. 영상 처리 장치는 제1 영상의 카테고리를 식별하고, 식별된 카테고리에 속한 영상을 데이터베이스에 저장되어 있는 학습 데이터로부터 선별할 수 있다. 학습 데이터는 고화질 영상들을 포함할 수 있다. 학습 데이 터는 외부 데이터 베이스에 저장되어 있거나, 또는 영상 처리 장치 내부 메모리에 저장되어 있을 수 있다. 일 실시예에 따른 영상 처리 장치는 선별된 학습 영상들을 압축 열화하거나, 블러링(blurring)하거나, 노 이즈를 추가하거나 다운 샘플링(down sampling)하는 방법 중 적어도 하나를 수행하여, 화질 열화된 영상을 생성 할 수 있다. 일 실시예에 따른 영상 처리 장치는 선별된 학습 영상들과, 학습 영상들을 화질 처리하여 획득한 화질 열 화된 영상들을 학습 데이터 셋으로 이용하여, 메타 모델을 학습시킬 수 있다. 예를 들어, 영상 처리 장치 는 학습 데이터 셋에 포함된 화질 열화된 영상을 메타 모델에 입력시켜, 메타 모델로부터 출력되는 영상과 학습 데이터 셋에 포함된 고화질 학습 영상과의 차이가 최소가 되도록 메타 모델의 파라미터를 업데이트할 수 있다. 일 실시예에 따른 영상 처리 장치는 학습된 메타 모델에 기초하여, 제1 영상을 화질 처리한 제2 영상을 획 득할 수 있다(S840). 일 실시예에 따른 학습된 메타 모델(업데이트된 모델)은 입력 영상의 화질을 처리하도록 훈련된 뉴럴 네트워크 를 포함할 수 있다. 예를 들어, 학습된 메타 모델은 저해상도 또는 저화질의 영상을 고해상도 또는 고화질의 영상으로 처리하도록 훈련된 모델일 수 있다. 일 실시예에 따른 제2 영상은 제1 영상보다 고해상도 또는 고화질의 영상일 수 있다. 도 9는 일 실시예에 따른 영상 처리 장치의 구성을 나타내는 도면이다. 도 9를 참조하면, 일 실시예에 따른 영상 처리 장치는 화질 처리부 및 모델 학습부를 포함할 수 있다. 화질 처리부는 서버로부터 수신한 제1 영상의 화질 처리를 수행하여, 제2 영상을 획득할 수 있다. 예를 들어, 화질 처리부는 영상의 화질을 처리하도록 훈련된 제2 뉴럴 네트워크를 이용하여, 제1 영상의 화질 처리를 수행할 수 있다. 제2 뉴럴 네트워크는 저해상도 영상(Low Resolution, LR)을 고해상도 영상 (High Resolution, HR)으로 변환할 수 있는 초해상도(Super Resolution, SR) 알고리즘을 구현하는 추론 네트워 크(Inference Network)일 수 있다. 화질 처리부는 딥 러닝을 이용한 SR 기술을 이용하여, 제1 영상의 화질 을 처리함으로써, 고해상도 영상(제2 영상)을 획득할 수 있다. 일 실시예에 따른 모델 학습부는 온 디바이스 러닝 동작을 수행할 수 있다. 온 디바이스 러닝 동작은 입력 영상의 화질을 처리하기 위한 화질 처리 모델을 입력 영상에 적응적으로 학습시키는 동작을 포함할 수 있다. 모델 학습부는 서버로부터 수신한 메타 모델 정보에 기초하여, 제1 영상에 적용하기 위한 메타 모델 을 생성할 수 있다. 모델 학습부는 생성된 메타 모델을 제1 영상에 대응하는 학습 데이터 셋을 이용하여 학습(전이 학습)시킴으로써, 업데이트된 모델을 생성할 수 있다. 일 실시예에 따른 모델 학습부가 메타 모델 및 업데이트된 모델을 생성하는 동작에 대해서는 도 10을 참조 하여, 자세히 후술하기로 한다. 화질 처리부는 모델 학습부에서 생성된 업데이트된 모델을 로딩하여, 업데이트된 모델을 이용하여, 제1 영상의 화질 처리를 수행할 수 있다. 일 실시예에 따른 온 디바이스 러닝 동작은 활성화(동작 ON)될 수도 있고, 비활성화(동작 OFF)될 수도 있다. 일 실시예에 따른 온 디바이스 러닝 동작이 활성화 또는 비활성화되는 것은 영상 처리 장치의 모델 사양이나 용량, 성능 등에 따라 달라질 수 있다. 예를 들어, 영상 처리 장치가 대용량 메모리와 고 성능의 CPU 등을 내장하고 있는 경우, 영상 처리 장치는 온 디바이스 러닝 동작을 활성화하여, 서버로부터 수신한 제1 영상에 적합하게 업데이트된 화질 처리 모델을 이용하여, 제1 영상의 화질 처리를 수행할 수 있다. 또는, 영상 처리 장치는 사용자 입력에 기초하여, 온 디바이스 러닝 동작의 활성화 여부를 결정할 수 있다. 일 실시예에 따른 모델 학습부는 온 디바이스 러닝 동작이 활성화된 것에 기초하여, 제1 영상에 적응적으 로 화질 처리 모델을 학습시켜, 업데이트된 모델을 획득할 수 있다. 화질 처리부는 모델 학습부에서 획득된 업데이트된 모델을 이용하여, 제1 영상의 화질 처리를 수행함으로써, 제2 영상을 획득할 수 있다. 일 실시예에 따른 온 디바이스 러닝 동작이 비활성화 된 경우, 모델 학습부는 업데이트된 모델을 획득하지 않을 수 있다. 화질 처리부는 기 저장된 참고 모델들 중에 어느 하나의 모델을 이용하여, 제1 영상의 화질 처리를 수행할 수 있다. 또는, 모델 학습부는 일 실시예에 따른 메타 모델 정보에 기초하여, 메타 모델은 획득하되, 제1 영상에 대 응하는 학습 데이터 셋을 이용하여 학습(전이 학습)시키는 과정을 생략할 수 있다. 화질 처리부는 메타 모 델을 이용하여, 제1 영상의 화질 처리를 수행할 수 있다. 도 10은 일 실시예에 따른 모델 학습부의 동작을 설명하기 위한 도면이다. 도 10을 참조하면, 일 실시예에 따른 모델 학습부는 데이터 파싱부, 모델 저장부, 메타 모델 생성부, 전이 학습부, 및 학습 데이터 베이스(DB) 생성부를 포함할 수 있다. 일 실시예에 따른 모델 학습부는 제1 영상 및 메타 모델 정보를 수신할 수 있다. 메타 모델 정보는 데이터 파싱부로 입력될 수 있다. 데이터 파싱부는 서버로부터 수신한 메타 모델 정보를 파싱(parsing)하여, 서로 다른 데이터를 구분 할 수 있다. 예를 들어, 데이터 파싱부는 메타 모델 정보에 포함된 제1 참고 모델의 식별 정보, 제2 참고 모델에 대한 정보, 메타 모델 정보, 가중치 정보 등을 구분할 수 있다. 일 실시예에 따른 데이터 파싱부는 메타 모델 정보에 제2 참고 모델에 대한 정보가 포함된 경우, 제2 참 고 모델 정보를 제2 모델 저장부로 전송할 수 있다. 또는, 데이터 파싱부는 메타 모델 정보에 메타 모델이 포함된 경우, 메타 모델을 제2 모델 저장부에 저장할 수 있다. 일 실시예에 따른 모델 학습부는 참고 모델들을 저장하는 모델 저장부를 포함할 수 있으며, 기 학습 된 참고 모델을 저장하는 제1 모델 저장부와 서버로부터 수신한 참고 모델 또는 메타 모델을 저장하 는 제2 모델 저장부를 포함할 수 있다. 다만, 이에 한정되지 않으며, 영상 처리 장치의 모델 사양이 나 용량, 성능 등에 따라 제2 참고 모델 저장부는 포함하지 않을 수 있다. 일 실시예에 따른 데이터 파싱부는 메타 모델 정보에 제1 참고 모델의 식별 정보가 포함된 경우, 제1 참 고 모델의 식별 정보를 제1 모델 저장부로 전송할 수 있다. 제1 모델 저장부는 기 저장된 제1 참고 모델들 중 수신한 식별 정보에 대응하는 제1 참고 모델을 메타 모델 생성부로 로딩할 수 있다. 일 실시예에 따른 데이터 파싱부는 메타 모델 정보에 포함되는 참고 모델에 적용되는 가중치 정보를 메타 모델 생성부로 전송할 수 있다. 일 실시예에 따른 메타 모델 생성부는 제1 모델 저장부 또는 제2 모델 저장부로부터 로딩된 적어도 하나의 참고 모델들과 적어도 하나의 참고 모델에 적용되는 가중치 정보에 기초하여, 메타 모델을 생성 할 수 있다. 예를 들어, 메타 모델 생성부는 복수개의 참고 모델들 각각에 가중치를 적용하고, 가중치가 적용된 참고 모델들을 합함으로써(가중 합), 메타 모델을 생성할 수 있다. 또는, 메타 모델 생성부는 제2 모델 저장부로부터 메타 모델을 획득할 수도 있다. 메타 모델 생성부는 생성된 메타 모델을 전이 학습부로 전송할 수 있다. 일 실시예에 따른 전이 학습부는 메타 모델을 학습 DB 생성부로부터 수신한 학습 데이터 셋을 이용 하여, 학습시킬 수 있다. 일 실시예에 따른 학습 DB 생성부는 제1 영상을 이용하여 제1 영상에 대응하는 학습 데이터 셋을 획득할 수 있다. 이를 위해, 학습 DB 생성부는 제1 영상의 카테고리를 식별할 수 있다. 예를 들어, 학습 DB 생성 부는 제1 영상을 분석하여 제1 영상의 카테고리를 확률 값으로 식별할 수 있다. 학습 DB 생성부는 가장 확률 값이 높은 카테고리를 제1 영사의 카테고리로 식별하고, 식별된 카테고리에 속한 영상을 데이터베이 스에 저장되어 있는 학습 데이터로부터 선별할 수 있다. 학습 데이터는 고화질 영상들을 포함할 수 있다. 학습 데이터는 외부 데이터 베이스에 저장되어 있거나, 또는 내부 메모리에 저장되어 있을 수 있다. 일 실시예에 따른 학습 DB 생성부는 제1 영상과 동일한 카테고리에 속하는 영상들 중에, 기 설정된 개수 의 영상들을 획득할 수 있다. 또는, 학습 DB 생성부는 제1 영상의 카테고리 중 확률 값이 높은 순서대로 기 설정된 수의 카테고리를 식별하고, 식별된 카테고리에 속하는 영상들을 확률 값에 비례하여 획득할 수도 있 다. 예를 들어, 학습 DB 생성부는 제1 영상에 포함된 오브젝트가 강아지일 확률이 70%, 고양이일 확률이 30%로 판단한 경우, 학습 데이터 중에 강아지 영상과 고양이 영상을 7:3의 비율로 획득할 수 있다. 일 실시예에 따른 학습 DB 생성부는 식별된 카테고리에 속하는 영상들을 열화시켜 화질 열화된 영상을 획 득할 수 있다. 학습 DB 생성부는 식별된 카테고리에 속하는 영상들의 화질이, 제1 영상의 화질에 대응하 도록 처리할 수 있다. 예를 들어, 학습 DB 생성부는 식별된 카테고리에 속한 영상들을 압축 열화하거나, 블러링(blurring)하거나, 노이즈를 추가하거나 다운 샘플링(down sampling)하는 방법 중 적어도 하나를 수행하 여, 화질 열화된 영상을 생성할 수 있다. 일 실시예에 따른 학습 DB 생성부는 식별된 카테고리에 속하는 영상과 이 영상을 화질 처리하여 획득한 화질 열화된 영상을 학습 데이터 셋으로 이용할 수 있다. 일 실시예에 따른 학습 DB 생성부는 학습 데이터 셋을 전이 학습부로 전송할 수 있다. 일 실시예에 따른 전이 학습부는 학습 DB 생성부로부터 수신한 학습 데이터 셋을 이용하여, 메타 모델을 학습시킬 수 있다. 예를 들어, 전이 학습부는 경사 하강법(gradient descent) 알고리즘을 사용하여 메타 모델을 학습시킬 수 있다. 경사 하강법은 1차 근사값 발견용 최적화 알고리즘으로, 함수의 기울기(경사, gradient)를 구하고, 경사 의 절대값이 낮은 쪽으로 계속 이동시켜 함수 값이 최소 값일 때의 x 값을 찾는 방법이다.일 실시예에 따른 전이 학습부는 학습 데이터 셋에 포함된 화질 열화된 영상을 메타 모델에 입력시켜서 메타 모델로부터 출력되는 영상과, 학습 데이터 셋에 포함된 식별된 카테고리에 속한 영상을 비교하여, 두 영상 의 차이를 함수의 기울기로 구하고, 기울기의 절대값이 최소가 될 때의 모델의 파라미터를 획득할 수 있다. 즉, 전이 학습부는 메타 모델에서 출력된 영상과 학습 데이터 셋에 포함된 고화질 영상의 정량적 차이가 최소 가 되도록 메타 모델의 파라미터를 계속적으로 업데이트함으로써, 메타 모델을 학습시킬 수 있다. 일 실시예에 따른 전이 학습부는 복수의 영상들에 서로 다른 메타 모델을 적용하는 경우, 급격한 화질 변 화가 생기는 경우를 고려하여, 메타 모델을 안정화시킬 수 있다. 예를 들어, 전이 학습부는 프레임 영상 별 업데이트된 메타 모델의 성능 편차를 조절할 수 있다. 전이 학습부는 프레임 영상들의 메타 모델들의 파라미터들을 평균하는 방법을 이용하여, 메타 모델을 안정화시킬 수 있다. 전이 학습부는 단순 이동 평 균이나 지수 이동 평균 방법을 사용하여, 메타 모델들을 평균화할 수 있다. 다만, 이에 한정되지 않는다. 도 11은 일 실시예에 따른 학습 DB 생성부가 제1 영상과 유사한 카테고리의 영상들을 획득하는 동작을 설명하기 위한 도면이다. 도 11을 참조하면, 학습 DB 생성부는 제1 영상의 컨텐츠 특성과 유사한 특성을 가지는 영상을 외부 데이 터베이스로부터 선별적으로 수집하여, 학습 DB를 생성할 수 있다. 일 실시예에 따른 학습 DB 생성부는 제1 영상이 속한 카테고리를 식별할 수 있다. 일 실시예에 따른 학습 DB 생성부는 제3 뉴럴 네트워크를 이용하여, 제1 영상의 카테고리를 식별할 수 있다. 일 실시예에 따른 제3 뉴럴 네트워크는 영상을 입력 받고, 입력된 영상으로부터 영상의 카테고 리를 분류하는 알고리즘, 또는 알고리즘의 집합, 알고리즘의 집합을 실행하는 소프트웨어 및/또는 알고리집의 집합을 실행하는 하드웨어일 수 있다. 일 실시예에 따른 제3 뉴럴 네트워크는 다양한 클래스 내지는 카테고리를 결과로 획득하기 위해 소프트맥 스 회귀(Softmax Regression) 함수를 이용할 수 있다. 소프트맥스 함수는 분류해야하는 정답지(클래스)가 여러 개인 경우, 즉, 다중 클래스를 예측할 때 이용될 수 있다. 소프트맥스 함수는 클래스의 총 개수를 k라고 할 때, k차원의 벡터를 입력 받아 각 클래스에 대한 확률을 추정할 수 있다. 일 실시예에 따른 제3 뉴럴 네트워크 는 k차원의 벡터를 입력받고 이로부터 획득된 각 클래스에 대한 확률이 정답셋과 같아지도록 학습된 뉴럴 네트워크일 수 있다. 다만, 이에 한정되는 것은 아니며, 제3 뉴럴 네트워크는 입력 영상으로부터 영상의 카테고리를 분류할 수 있는 다양한 형태의 알고리즘으로 구현될 수 있다. 일 실시예에 따른 제3 뉴럴 네트워크는 입력된 제1 영상의 카테고리 내지는 클래스에 대한 확률 값을 결 과로 획득할 수 있다. 예를 들어, 제3 뉴럴 네트워크는 제1 영상의 카테고리가 사람의 얼굴일 확률과 강 아지일 확률, 고양이일 확률, 건물일 확률을 각각 0.5, 0.2, 0.2, 0.1로 표현한 벡터를 결과 값으로 획득할 수 있다. 일 실시예에 따른 학습 DB 생성부는 가장 확률 값이 높은 카테고리를 제1 영상의 카테고리로 식별할 수 있다. 예를 들어, 위 예에서, 학습 DB 생성부는 제1 영상의 카테고리가, 가장 벡터 값이 큰 카테고리인 사람의 얼굴이라고 식별할 수 있다. 일 실시예에 따른 학습 DB 생성부는 제1 영상과 콘텐츠 특성과 유사한 영상들, 즉, 제1 영상과 동일한 카 테고리 또는 유사한 카테고리에 포함된 영상을 획득할 수 있다. 일 실시예에 따른 학습 DB 생성부는 제1 영상과 유사한 카테고리에 포함된 영상을 외부 데이터베이스로부터 획득할 수 있다. 다만, 이에 한정되는 것은 아니며, 학습 DB 생성부는 외부 데이터베이스가 아닌, 영상 처리 장치의 내부 메모리에 저장된 학습 영상들 중에서 제1 영상과 유사한 카테고리에 포함된 영상을 획득할 수도 있다. 일 실시예에 따른 외부 데이터베이스 또는 내부 메모리에는 다양한 종류의 카테고리를 갖는 영상들이 각 영상의 카테고리에 대한 인덱스 내지는 태그로 라벨링되어 저장되어 있을 수 있다. 도 11을 참조하면, 학습 DB 생성부는 제1 영상과 유사한 카테고리의 인덱스로 식별되는 영상을 외부 데이 터베이스로부터 한 개 또는 복수 개를 획득하고, 이들을 포함하는 새로운 데이터베이스를 생성할 수 있다. 일 실시예에 따른 학습 DB 생성부는 제1 영상의 카테고리 중 확률 값이 가장 높은 카테고리만을 식별하고, 식별된 카테고리에 속한 영상들을 획득할 수 있다. 예를 들어, 위 예에서, 학습 DB 생성부는확률 값이 가장 높은 사람의 얼굴 영상만을 외부 데이터베이스로부터 획득할 수 있다. 또는, 학습 DB 생성부는 제1 영상의 카테고리 중 확률 값이 높은 순서대로 기 정해진 수의 카테고리만을 식별하고, 식별된 카테고리에 속하는 영상들을 확률 값에 비례하여 획득할 수도 있다. 예를 들어, 위 예에서, 학습 DB 생성부는 확률 값이 높은 순서대로 세 개의 카테고리만을 식별할 수 있다. 예를 들어, 학습 DB 생성부는 사람의 얼굴, 강아지, 고양이를 입력 영상의 카테고리로 식별하고, 사람의 얼굴 영상, 강아지 영상, 고양이 영상을 외부 데이터베이스로부터 각각 5:2:2의 비율로 획득할 수 있다. 일 실시예에 따른 학습 DB 생성부는 제1 영상 또한 새로운 데이터베이스에 포함시킬 수 있다. 도 11은 학습 DB 생성부가 가장 확률 값이 높은 카테고리인 사람의 얼굴을 입력 영상의 카테고리로 식별 한 경우를 가정한다. 학습 DB 생성부는 외부 데이터베이스로부터 N개의 다양한 사람 얼굴 영상을 획득하고, 이들을 포함하는 새로운 데이터베이스를 생성할 수 있다. 여기서 N개의 사람 얼굴 영상은 서로 다른 영상일 수 있다. 도 12는 일 실시예에 따른 학습 DB 생성부가 학습 데이터 셋을 생성하는 동작을 설명하기 위한 도면이다. 도 12를 참조하면, 일 실시예에 따른 학습 DB 생성부는 새로운 데이터베이스에 포함된 영상들을 디 그레이드(degrade)하여 화질을 열화시킬 수 있다. 일 실시예에 따른 학습 DB 생성부는 새로운 데이터베이스에 포함된 영상들을 제1 영상의 품질 특성 에 맞게 열화시킬 수 있다. 일 실시예에 따른 학습 DB 생성부는 제1 영상의 품질 정보를 수신하고, 이에 대응하는 품질 정보를 가지 도록 수집한 영상들을 열화시킬 수 있다. 이때, 제1 영상의 품질 정보는 서버에서 제1 영상의 화질을 분석 또는 평가하여 획득한 품질 정보일 수 있다. 또는, 일 실시예에 따른 영상 처리 장치가 제1 영상의 화질을 분석 또는 평가하여 획득한 품질 정보일 수 있다. 일 실시예에 따른 제1 영상의 품질 정보는 제1 영상의 블러 정도를 나타내는 Kernel Sigma와 제1 영상의 압축 열화 정도를 나타내는 QF를 포함할 수 있다. 학습 DB 생성부는 제1 영상과 동일한 정도의 블러와 압축 열 화를 가지도록 새로운 데이터베이스에 포함된 영상들을 열화시킬 수 있다. 예를 들어, 학습 DB 생성부는 새로운 데이터베이스에 포함된 영상들을 열화 하기 위해 필터링 (Filtering)을 수행할 수 있다. 학습 DB 생성부는 영상들에 블러 열화를 주기 위해서, 2차원 Kernel을 사 용할 수 있다. 또는 학습 DB 생성부는 움직임 열화를 모델링하기 위해 박스 블러(Box Blur)를 처리할 수 있다. 또는 학습 DB 생성부는 형태나 광학 블러를 주기 위해 가우시안(Gaussian) 필터를 사용할 수 있다. 일 실시예에 따른 학습 DB 생성부는 필터의 계수를 제1 영상이 가지는 블러에 맞추어서 조절할 수 있다. 열화는 일반적인 알려진 공간적 필터링을 통해서 수행되며, 신호 처리 분야의 저주파 통과 필터의 동작과 동일 할 수 있다. 구체적으로 열화는 2D Gaussian Kernel과의 Convolution 연산을 통해서 수행될 수 있다. 일 실시예에 따른 학습 DB 생성부는 새로운 데이터베이스에 포함된 영상들과, 이들을 화질 열화시 켜 생성한, 열화된 영상들을 학습 데이터 셋으로 이용할 수 있다. 도 13은 일 실시예에 따른 압축 과정에서 발생하는 열화를 학습 영상에 반영하는 방법을 설명하기 위한 도면이 다. 비디오 등을 포함하는 멀티미디어 데이터는 그 양이 방대하여 전송 시에 넓은 대역폭을 필요로 한다. 예를 들어, 4K 이상 해상도의 무 압축 영상은 중장거리 전송이 불가능할 수준으로 높은 대역폭을 필요로 한다. UHD 방송 표준 해상도인 3840x2160해상도를 가진 4K 60FPS 무압축 영상은, 초당 11,384Bbps라는 매우 높은 대역폭을 필요로 한다. 이러한 대용량 데이터 전송을 위해서는 압축 코딩 기법을 사용하여 영상을 부호화하는 것이 필수 적이다. 영상은 다양한 압축 포맷 방식으로 압축될 수 있다. 예컨대 영상은 JPEG, MPEG2, H.264, HEVC 등과 같 은 다양한 압축 포맷 방식으로 압축될 수 있다. 영상은 압축되는 과정에서 정보를 손실하게 되어 왜곡이 발생할 수 있다. 부호화된 영상 데이터는 각 비디오 코덱에서 규정한 소정 포맷으로 생성되어 디코딩 장치로 전송되고, 디코딩 장치는 영상 시퀀스를 복호화하여 영상 데이터를 출력한다. 압축된 영상은 디코딩 과정에서 영상을 복원할 때 다시 정보가 손실되어 열화가 발생할 수 있다. 일 실시예에 따른 학습 DB 생성부는 다양한 종류의 열화 중, 압축 과정에서 발생하는 열화를 학습 영상에 반영하여, 압축 열화된 영상을 생성할 수 있다. 일 실시예에 따른 학습 DB 생성부는 새로운 데이터베이스에 포함된 영상들을 압축 열화하여 압축 열화된 영상을 생성할 수 있다. 이를 위해, 학습 DB 생성부는 새로운 데이터베이스에 포함된 영상 들을 인코딩/디코딩하여 압축 열화된 영상을 생성할 수 있다. 예컨대, 학습 DB 생성부는 정지 영상에 대 해서는 JPEG 압축 방법을 사용하여 정지 영상을 열화시킬 수 있다. 또한, 학습 DB 생성부는 동영상에 대 해서는 MPEG2, H.264, HEVC 등의 압축 방법을 사용하여, 동영상을 압축 열화시킬 수 있다. 도 13은 영상에 대한 JPEG 인코딩 및 디코딩 과정을 순서대로 도시하고 있다. 도 13을 참조하면, 로우 이미지 데이터(Raw image data)는 순서대로, 컬러 변환, 주파수 변환(DCT), 양자화(Quantization), 부호화 코딩 (Arithmetic Coding)을 거쳐 JPEG 압축 영상으로 인코딩될 수 있다. 인코딩된 영상은 복호화, 역양자화 (Dequantization), 역변환(Inverse DCT), 역 컬러변환 과정을 거쳐 복원될 수 있다. 일 실시예에 따른 학습 DB 생성부는 열화시킬 영상을 도 13에 도시된 순서대로 JPEG 인코딩 및 디코딩 하 여, 압축 열화된 영상을 획득할 수 있다. 인코딩/디코딩 과정에서 수행되는 엔트로피 코딩은 무손실 압축 방식이기 때문에, 엔트로피 코딩 및 엔트로피 디코딩 과정에서는 품질 열화가 발생하지 않는다. 따라서, 일 실시예에 따른 학습 DB 생성부는 열화시킬 영상에 대해 엔트로피 코딩 및 엔트로피 디코딩 과정은 생략하고, 도면 부호 1310으로 표기된 방법들만을 수행 하여, 압축 열화된 영상을 획득할 수 있다. 일 실시예에 따른 학습 DB 생성부는 열화시킬 영상을 로우 이미지 데이터(Raw image data) 자리에 위치시 키고, 열화시킬 영상에 대해, 컬러 변환, 주파수 변환(DCT), 양자화(Quantization)를 수행하고, 양자화된 영상 을 역양자화(Dequantization), 역변환(Inverse DCT), 역 컬러변환하여, 압축 열화된 영상을 획득할 수 있다. 도 14는 일 실시예에 따른 서버의 구성을 나타내는 블록도이다. 도 14를 참조하면, 일 실시예에 따른 서버는 통신부, 프로세서 및 메모리를 포함할 수 있다. 일 실시예에 따른 통신부는 외부 장치 또는 서버와 데이터 또는 신호를 송수신할 수 있다. 예를 들어, 통 신부는 와이- 파이(Wi-Fi) 모듈, 블루투스 모듈, 적외선 통신 모듈 및 무선 통신 모듈, LAN 모듈, 이더넷 (Ethernet) 모듈, 유선 통신 모듈 등을 포함할 수 있다. 이때, 각 통신 모듈은 적어도 하나의 하드웨어 칩 형태 로 구현될 수 있다. 와이 파이 모듈, 블루투스 모듈은 각각 Wi-Fi 방식, 블루투스 방식으로 통신을 수행한다. 와이 파이 모듈이나 블루투스 모듈을 이용하는 경우에는 SSID 및 세션 키 등과 같은 각종 연결 정보를 먼저 송수신하고, 이를 이용 하여 통신 연결한 후 각종 정보들을 송수신할 수 있다. 무선 통신 모듈은 지그비(zigbee), 3G(3rd Generation), 3GPP(3rd Generation Partnership Project), LTE(Long Term Evolution), LTE-A(LTE Advanced), 4G(4th Generation), 5G(5th Generation) 등과 같은 다양한 무선 통신 규격에 따라 통신을 수행하는 적어도 하나의 통 신 칩을 포함할 수 있다. 일 실시예에 따른 통신부는 영상 처리 장치로부터 제1 영상의 요청을 수신할 수 있다. 또한, 일 실시 예에 따른 통신부는 제1 영상, 메타 모델 정보, 제1 영상의 품질 정보를 일 실시예에 따른 영상 처리 장치 로 전송할 수 있다. 일 실시예에 따른 프로세서는 서버의 전반적인 동작 및 서버의 내부 구성 요소들 사이의 신호 흐름을 제어하고, 데이터를 처리하는 기능을 수행한다. 프로세서는 싱글 코어, 듀얼 코어, 트리플 코어, 쿼드 코어 및 그 배수의 코어를 포함할 수 있다. 또한, 프로세서는 복수의 프로세서들을 포함할 수 있다. 예를 들어, 프로세서는 메인 프로세서(main processor, 도시되지 아니함) 및 서브 프로세서(sub processor, 도시되지 아니함)로 구현될 수 있다. 또한, 프로세서는 CPU(Cetral Processing Unit), GPU (Graphic Processing Unit) 및 VPU(Video Processing Unit) 중 적어도 하나를 포함할 수 있다. 또는, 실시예에 따라, CPU, GPU 및 VPU 중 적어도 하나를 통합한 SoC(System On Chip) 형태로 구현될 수 있다. 또는, 프로세서는 NPU(Neural Processing Unit)를 더 포함할 수 있다. 일 실시예에 따른 메모리는 서버를 구동하고 제어하기 위한 다양한 데이터, 프로그램 또는 어플리케 이션을 저장할 수 있다. 또한, 메모리에 저장되는 프로그램은 하나 이상의 인스트럭션들을 포함할 수 있다. 메모리에 저장된 프로그램(하나 이상의 인스트럭션들) 또는 어플리케이션은 프로세서에 의해 실행될 수 있다. 일 실시예에 따른 프로세서는 도 4의 영상 압축부, 화질 분석부, 및 메타 모델 획득부를 포함할 수 있으며, 영상 압축부, 화질 분석부, 및 메타 모델 획득부의 동작들을 수행할 수 있다. 일 실시예에 따른 프로세서는 상기 메모리에 저장된 하나 이상의 인스트럭션들을 실행함으로써, 원본 영상을 압축하여, 제1 영상을 획득할 수 있다. 프로세서는 동일한 원본 영상에 대해 서로 다른 해상도 또 는 서로 다른 비트레이트를 가지는 복수의 압축 영상 데이터를 획득하여, 메모리에 저장할 수 있다. 예를 들어, 압축 영상 데이터는 동일한 컨텐츠에 대하여, 8k, 4k, FHD, HD의 해상도를 가지는 영상 데이터를 포함할 수 있다. 또는, 압축 영상 데이터는 동일한 원본 영상에 대하여, 40Mbps, 30Mbps, 20Mbps, 10Mbps의 비트레이트 를 가지는 복수의 압축 영상 데이터를 포함할 수 있다. 다만, 이에 한정되지 않는다. 일 실시예에 따른 프로세서는 일 실시예에 따른 영상 처리 장치와 연결된 네트워크의 상태에 따라, 복수의 압축 영상 데이터 중, 영상 처리 장치로 전송할 영상 데이터(제1 영상)를 결정할 수 있다. 네트워크의 상태는 예를 들어, 서버와 영상 처리 장치 간의 송수신 경로에서의 트래픽 발생 정도에 따라 결정될 수 있으나, 이에 한정되지 않는다. 또는, 프로세서는 영상 처리 장치의 요청에 의해 복수의 압축 영상 데이터 중 영상 처리 장치로 전송 할 영상 데이터(제1 영상)를 결정할 수 있다. 일 실시예에 따른 프로세서는 상기 메모리에 저장된 하나 이상의 인스트럭션들을 실행함으로써, 제1 영상에 대한 화질을 분석하여, 품질 정보를 획득할 수 있다. 예를 들어, 프로세서는 제1 영상의 화질 또는 품질을 판단할 수 있다. 영상의 화질은 영상의 열화 정도를 나타낼 수 있다. 프로세서는 제1 영상의 압축 열화, 제1 영상의 선명도(sharpness degree), 블러(blur) 정도, 노이즈 정도, 영상의 해상도 중 적어도 하나를 평가 또는 판단할 수 있다. 일 실시예에 따른 프로세서는 제1 영상의 화질을 분석 또는 평가하도록 훈련된 제1 뉴럴 네트워크를 이용 하여 제1 영상의 화질을 분석 또는 평가할 수 있다. 예를 들어, 제1 뉴럴 네트워크는 영상 화질 평가(Image Quality Assessment: IQA) 기술, 비디오 화질 평가(Video Quality Assessment: VQA) 기술 등을 이용하여, 영상 또는 비디오의 화질을 평가하도록 훈련된 뉴럴 네트워크일 수 있다. 예를 들어, 프로세서는 제1 뉴럴 네트워크를 이용하여, 영상의 블러 품질을 나타내는 커널 시그마(kernel sigma) 값과 영상의 압축 품질을 나타내는 퀄리티 팩터(QF: Quality Factor)를 품질 정보로 획득할 수 있다. 다 만, 이에 한정되지 않는다. 일 실시예에 따른 프로세서는 제1 영상이 비디오 컨텐츠에 포함되는 복수의 프레임 영상들 중 어느 하나인 경우, 복수의 프레임 영상들 각각에 대한 품질 정보에 기초하여, 제1 영상의 품질 정보를 획득할 수 있다. 예를 들어, 프로세서는 복수의 프레임 영상들 각각의 품질 값들에 기초하여, 제1 영상의 품질 값이 이상이 있는 지를 판단하고, 이상이 있는 경우에는 해당 값을 사용하지 않을 수 있다. 프로세서는 복수의 프레임 영상들의 품질 값들의 평균값, 표준 편차에 기초하여, 제1 영상의 품질 값의 이상 여부를 결정할 수 있다. 이에 대해서는 도 6을 참조하여, 자세히 설명하였으므로, 구체적인 설명은 생략하기로 한다. 일 실시예에 따른 프로세서는 상기 메모리에 저장된 하나 이상의 인스트럭션들을 실행함으로써, 획득 한 품질 정보에 기초하여, 메타 모델 정보를 획득할 수 있다. 예를 들어, 프로세서는 적어도 하나의 참고 모델을 이용하여, 메타 모델을 획득할 수 있다. 참고 모델은 학습 영상을 이용하여 기 학습된 화질 처리 모델로, 영상 처리 장치에 저장된 제1 참고 모델들과 서버 에 저장된 제2 참고 모델들을 포함할 수 있다. 일 실시예에 따른 프로세서는 제1 영상의 화질 처리를 위한 제2 참고 모델들을 생성할 수 있다. 예를 들어, 프로세서는 제1 영상과 유사한 품질 정보를 가지는 학습 영상들을 이용하여, 화질 처리 모델을 학습 시킴으로써, 제2 참고 모델들을 생성할 수 있다. 또는, 다양한 품질 정보를 가지는 학습 영상들을 이용하여, 기 학습된 제1 참고 모델들은 영상 처리 장치 에 저장될 수 있다. 일 실시예에 따른 프로세서는 복수의 참고 모델들 각각에 대응하는 학습 영상들의 품질 정보와 제1 영상의 품질 정보를 비교하여, 제1 영상의 품질 정보와 유사한 품질 정보를 가지는 학습 영상에 대응하는 참고 모델을 검색할 수 있다. 일 실시예에 따른 프로세서는 복수의 참고 모델들을 검색할 수 있으며, 복수의 참고 모델들 각각에 가중치 를 적용하여, 복수의 참고 모델들의 가중 합을 수행함으로써, 메타 모델을 획득할 수 있다. 이때, 복수의 참고 모델들 각각에 적용되는 가중치는 참고 모델에 대응하는 학습 영상의 품질 정보와 제1 영상의 품질 정보의 차이 에 기초하여 결정될 수 있다. 일 실시예에 따른 메타 모델 정보는, 메타 모델을 획득하기 위한 적어도 하나의 참고 모델에 대한 정보, 적어도 하나의 참고 모델에 적용되는 가중치 정보, 획득된 메타 모델 등을 포함할 수 있다. 예를 들어, 적어도 하나의 참고 모델에 대한 정보는, 제1 참고 모델을 이용하여, 메타 모델이 획득되는 경우, 제1 참고 모델의 식별 정보를 포함할 수 있다. 또는, 제2 참고 모델을 이용하여, 메타 모델이 획득되는 경우, 적어도 하나의 참고 모델에 대한 정보는, 제2 참고 모델을 포함할 수 있다. 일 실시예에 따른 프로세서는 상기 메모리에 저장된 하나 이상의 인스트럭션들을 실행함으로써, 메타 모델 정보 및 제1 영상을 영상 처리 장치로 전송하도록 통신부를 제어할 수 있다. 예를 들어, 통신부는 제2 참고 모델들에 기초하여, 메타 모델을 획득하는 경우, 획득한 메타 모델 또는 제 2 참고 모델들을 영상 처리 장치로 전송할 수 있다. 또는 통신부는 제1 참고 모델들에 기초하여, 메 타 모델을 획득하는 경우, 제1 참고 모델들에 대한 식별 정보(예를 들어, 모델 번호 등)를 영상 처리 장치(20 0)로 전송할 수 있다. 또한, 통신부는 메타 모델을 획득하기 위한 복수의 참고 모델들 각각에 적용되는 가중치 정보를 영상 처리 장치로 전송할 수 있다. 또한, 통신부는 서버에서 획득한 제1 영상에 대한 품질 정보를 영상 처리 장치로 전송할 수 있다. 도 15는 일 실시예에 따른 영상 처리 장치의 구성을 나타내는 블록도이다. 도 15를 참조하면, 일 실시예에 따른 영상 처리 장치는 통신부, 프로세서, 메모리 및 디스 플레이를 포함할 수 있다. 일 실시예에 따른 통신부는 외부 장치 또는 서버와 데이터 또는 신호를 송수신할 수 있다. 예를 들어, 통 신부는 와이- 파이(Wi-Fi) 모듈, 블루투스 모듈, 적외선 통신 모듈 및 무선 통신 모듈, LAN 모듈, 이더넷 (Ethernet) 모듈, 유선 통신 모듈 등을 포함할 수 있다. 이때, 각 통신 모듈은 적어도 하나의 하드웨어 칩 형태 로 구현될 수 있다. 와이 파이 모듈, 블루투스 모듈은 각각 Wi-Fi 방식, 블루투스 방식으로 통신을 수행한다. 와이 파이 모듈이나 블루투스 모듈을 이용하는 경우에는 SSID 및 세션 키 등과 같은 각종 연결 정보를 먼저 송수신하고, 이를 이용 하여 통신 연결한 후 각종 정보들을 송수신할 수 있다. 무선 통신 모듈은 지그비(zigbee), 3G(3rd Generation), 3GPP(3rd Generation Partnership Project), LTE(Long Term Evolution), LTE-A(LTE Advanced), 4G(4th Generation), 5G(5th Generation) 등과 같은 다양한 무선 통신 규격에 따라 통신을 수행하는 적어도 하나의 통 신 칩을 포함할 수 있다. 일 실시예에 따른 통신부는 서버로 제1 영상(영상 컨텐츠 또는 비디오 컨텐츠)을 요청할 수 있다. 또 한, 일 실시예에 따른 통신부는 서버로부터 제1 영상, 메타 모델 정보, 제1 영상의 품질 정보를 수신 할 수 있다. 일 실시예에 따른 프로세서는 영상 처리 장치의 전반적인 동작 및 영상 처리 장치의 내부 구성 요소들 사이의 신호 흐름을 제어하고, 데이터를 처리하는 기능을 수행한다. 프로세서는 싱글 코어, 듀얼 코어, 트리플 코어, 쿼드 코어 및 그 배수의 코어를 포함할 수 있다. 또한, 프로세서는 복수의 프로세서들을 포함할 수 있다. 예를 들어, 프로세서는 메인 프로세서(main processor, 도시되지 아니함) 및 서브 프로세서(sub processor, 도시되지 아니함)로 구현될 수 있다. 또한, 프로세서는 CPU(Cetral Processing Unit), GPU (Graphic Processing Unit) 및 VPU(Video Processing Unit) 중 적어도 하나를 포함할 수 있다. 또는, 실시예에 따라, CPU, GPU 및 VPU 중 적어도 하나를 통합한 SoC(System On Chip) 형태로 구현될 수 있다. 또는, 프로세서는 NPU(Neural Processing Unit)를 더 포함할 수 있다. 일 실시예에 따른 메모리는 영상 처리 장치를 구동하고 제어하기 위한 다양한 데이터, 프로그램 또는 어플리케이션을 저장할 수 있다. 또한, 메모리에 저장되는 프로그램은 하나 이상의 인스트럭션들을 포함할 수 있다. 메모리에 저장된 프로그램(하나 이상의 인스트럭션들) 또는 어플리케이션은 프로세서에 의해 실행될 수 있다. 일 실시예에 따른 프로세서는 도 9의 화질 처리부와 모델 학습부를 포함할 수 있으며, 화질 처 리부와 모델 학습부의 동작들을 수행할 수 있다. 일 실시예에 따른 프로세서는 상기 메모리에 저장된 하나 이상의 인스트럭션들을 실행함으로써, 서버 로부터 수신한 메타 모델 정보에 기초하여, 메타 모델을 생성할 수 있다. 예를 들어, 프로세서는 메 타 모델 정보에 제1 참고 모델의 식별 정보가 포함된 경우, 제1 참고 모델의 식별 정보에 대응하는, 메모리 에 기 저장된 제1 참고 모델을 로딩할 수 있다. 또한, 프로세서는 메타 모델 정보에 제2 참고 모델 또는 메타 모델에 대한 정보가 포함된 경우, 제2 참고 모델 또는 메타 모델을 메모리에 저장할 수 있다. 프로세서는 제1 참고 모델 또는 제2 참고 모델에 메타 모델 정보에 포함된 가중치를 적용하여, 메타 모델 을 생성할 수 있다. 예를 들어, 프로세서는 복수개의 참고 모델들 각각에 가중치를 적용하고, 가중치가 적 용된 참고 모델들을 합함으로써(가중 합), 메타 모델을 생성할 수 있다. 다만, 이에 한정되지 않는다. 일 실시예에 따른 프로세서는 상기 메모리에 저장된 하나 이상의 인스트럭션들을 실행함으로써, 제1 영상에 대응하는 학습 데이터 셋을 이용하여, 메타 모델을 학습시킬 수 있다. 예를 들어, 프로세서는 제1 영상을 이용하여, 제1 영상에 대응하는 학습 데이터 셋을 획득할 수 있다. 프 로세서는 제1 영상의 카테고리를 식별하고, 식별된 카테고리에 속한 영상을 데이터베이스에 저장되어 있는 학습 데이터로부터 선별할 수 있다. 학습 데이터는 고화질 영상들을 포함할 수 있다. 학습 데이터는 외부 데이 터 베이스에 저장되어 있거나, 또는 내부 메모리에 저장되어 있을 수 있다. 일 실시예에 따른 프로세서는 선별된 학습 영상들을 압축 열화하거나, 블러링(blurring)하거나, 노이즈를 추가하거나 다운 샘플링(down sampling)하는 방법 중 적어도 하나를 수행하여, 화질 열화된 영상을 생성할 수 있다. 일 실시예에 따른 프로세서는 선별된 학습 영상들과, 학습 영상들을 화질 처리하여 획득한 화질 열화된 영 상들을 학습 데이터 셋으로 이용하여, 메타 모델을 학습시킬 수 있다. 예를 들어, 프로세서는 학습 데이터 셋에 포함된 화질 열화된 영상을 메타 모델에 입력시켜, 메타 모델로부터 출력되는 영상과 학습 데이터 셋에 포 함된 고화질 학습 영상과의 차이가 최소가 되도록 메타 모델의 파라미터를 업데이트할 수 있다. 일 실시예에 따른 프로세서는 상기 메모리에 저장된 하나 이상의 인스트럭션들을 실행함으로써, 학습 된 메타 모델에 기초하여, 제1 영상을 화질 처리한 제2 영상을 획득할 수 있다. 일 실시예에 따른 학습된 메타 모델(업데이트된 모델)은 입력 영상의 화질을 처리하도록 훈련된 뉴럴 네트워크 를 포함할 수 있다. 예를 들어, 학습된 메타 모델은 저해상도 또는 저화질의 영상을 고해상도 또는 고화질의 영 상으로 처리하도록 훈련된 모델일 수 있다. 일 실시예에 따른 제2 영상은 제1 영상보다 고해상도 또는 고화질의 영상일 수 있다. 일 실시예에 따른 디스플레이는 프로세서에서 처리된 영상 신호, 데이터 신호, OSD 신호, 제어 신호 등을 변환하여 구동 신호를 생성한다. 디스플레이는 PDP, LCD, OLED, 플렉시블 디스플레이(flexible display)등으로 구현될 수 있으며, 또한, 3차원 디스플레이(3D display)로 구현될 수 있다. 또한, 디스플레이 는, 터치 스크린으로 구성되어 출력 장치 이외에 입력 장치로 사용되는 것도 가능하다. 일 실시예에 따른 디스플레이는 제1 영상이 화질 처리된 제2 영상을 표시할 수 있다. 도 16은 일 실시예에 따른 영상 처리 장치의 구성을 나타내는 블록도이다. 도 16의 영상 처리 장치는 도 1 및 도 15의 영상 처리 장치의 일 실시예일 수 있다. 도 16을 참조하면, 일 실시예에 따른 영상 처리 장치는, 튜너부, 프로세서, 디스플레이부 , 통신부, 감지부, 입/출력부, 비디오 처리부, 오디오 처리부, 오디오 출력부, 메모리, 전원부를 포함할 수 있다. 도 16의 통신부는 도 15의 통신부에, 도 16의 프로세서는, 도 15의 프로세서에 도 16의 메모리는 도 15의 메모리에, 도 16의 디스플레이부는 도 15의 디스플레이에 대응하는 구 성일 수 있다. 따라서, 앞에서 설명한 내용과 동일한 내용은 생략하기로 한다. 일 실시예에 따른 튜너부는 유선 또는 무선으로 수신되는 방송 신호를 증폭(amplification), 혼합 (mixing), 공진(resonance)등을 통하여 많은 전파 성분 중에서 영상 처리 장치에서 수신하고자 하는 채널 의 주파수만을 튜닝(tuning)시켜 선택할 수 있다. 방송 신호는 오디오(audio), 비디오(video) 및 부가 정보(예 를 들어, EPG(Electronic Program Guide))를 포함한다. 튜너부는 지상파 방송, 케이블 방송, 위성 방송, 인터넷 방송 등과 같이 다양한 소스로부터 방송 신호를 수신할 수 있다. 튜너부는 아날로그 방송 또는 디지털 방송 등과 같은 소스로부터 방송 신호를 수신할 수 도 있다. 일 실시예에 따른 통신부는 외부 제어 장치로부터 제어 신호 또는 제어 명령 등을 수신할 수 있다. 예를 들어, 통신부는 IR 통신 규격에 따라 외부 제어 장치와 신호를 송수신할 수 있는 IR 모듈을 포함할 수 있 다. 구체적으로, 통신부는 제어 장치로부터 사용자 입력(예를 들어, 제어 장치의 키 또는 버튼 입력 등) 에 대응하는 제어 신호 또는 제어 명령 등을 수신할 수 있다. 일 실시예에 따른 감지부는 사용자의 음성, 사용자의 영상 또는 사용자의 인터랙션을 감지하며, 마이크 , 카메라부 및 광 수신부를 포함할 수 있다. 마이크는 사용자의 발화(utterance)된 음성을 수신한다. 마이크는 수신된 음성을 전기 신호로 변 환하여 프로세서로 출력할 수 있다. 사용자 음성은 예를 들어, 영상 처리 장치의 메뉴 또는 기능 에 대응되는 음성을 포함할 수 있다. 예를 들어, 마이크는 디스플레이의 회전 명령에 대응하는 사용자 음 성을 수신하고, 수신된 음성을 전기 신호로 변환하여 프로세서로 출력할 수 있다. 카메라부는 카메라 인식 범위에서 제스처를 포함하는 사용자의 모션에 대응되는 영상(예를 들어, 연속되 는 프레임)을 수신할 수 있다. 프로세서는 수신된 모션의 인식 결과를 이용하여 영상 처리 장치에 표시되는 메뉴를 선택하거나 모션 인식 결과에 대응되는 제어를 할 수 있다. 예를 들어, 프로세서는 카메 라부로부터 영상을 수신하여, 수신한 영상으로부터 디스플레이의 회전에 대응하는 사용자의 모션을 인식 하고, 이에 대응하여, 디스플레이를 회전시킬 수 있다. 광 수신부는 외부의 제어 장치에서부터 수신되는 광 신호(제어 신호를 포함)를 디스플레이부의 베 젤의 광창(도시되지 아니함) 등을 통해 수신한다. 광 수신부는 제어 장치로부터 사용자 입력(예를 들어, 터치, 눌림, 터치 제스처, 음성, 또는 모션)에 대응되는 광 신호를 수신할 수 있다. 수신된 광 신호로부터 프 로세서의 제어에 의해 제어 신호가 추출될 수 있다. 일 실시예에 따른 입/출력부는, 영상 처리 장치의 외부에서부터 비디오(예를 들어, 동영상 등), 오 디오(예를 들어, 음성, 음악 등) 및 부가 정보(예를 들어, EPG 등) 등을 수신할 수 있다. 입/출력부는 HDMI (High-Definition Multimedia Interface), MHL(Mobile High-Definition Link), USB(Universal Serial Bus), DP(Display Port), 썬더볼트(Thunderbolt), VGA(Video Graphics Array) 포트, RGB 포트, D-SUB(D- subminiature), DVI(Digital Visual Interface), 컴포넌트 잭(component jack), PC 포트(PC port) 중 어느 하 나를 포함할 수 있다. 프로세서는 영상 처리 장치의 전반적인 동작 및 영상 처리 장치의 내부 구성 요소들 사이의 신호 흐름을 제어하고, 데이터를 처리하는 기능을 수행한다. 프로세서는 사용자의 입력이 있거나 기 설정 되어 저장된 조건을 만족하는 경우, 메모리에 저장된 OS(Operation System) 및 다양한 애플리케이션을 실 행할 수 있다. 프로세서는 영상 처리 장치의 외부에서부터 입력되는 신호 또는 데이터를 저장하거나, 영상 처리 장치에서 수행되는 다양한 작업에 대응되는 저장 영역으로 사용되는 램(RAM), 영상 처리 장치의 제 어를 위한 제어 프로그램이 저장된 롬(ROM) 및 프로세서(Processor)를 포함할 수 있다. 비디오 처리부는, 영상 처리 장치가 수신한 비디오 데이터에 대한 처리를 수행한다. 비디오 처리부 에서는 비디오 데이터에 대한 디코딩, 스케일링, 노이즈 필터링, 프레임 레이트 변환, 해상도 변환 등과같은 다양한 이미지 처리를 수행할 수 있다. 오디오 처리부는 오디오 데이터에 대한 처리를 수행한다. 오디오 처리부에서는 오디오 데이터에 대한 디코딩이나 증폭, 노이즈 필터링 등과 같은 다양한 처리가 수행될 수 있다. 한편, 오디오 처리부는 복수의 컨텐츠에 대응되는 오디오를 처리하기 위해 복수의 오디오 처리 모듈을 구비할 수 있다. 오디오 출력부는 프로세서의 제어에 의해 튜너부를 통해 수신된 방송 신호에 포함된 오디오 를 출력한다. 오디오 출력부는 통신부 또는 입/출력부를 통해 입력되는 오디오(예를 들어, 음성, 사운드)를 출력할 수 있다. 또한, 오디오 출력부는 프로세서의 제어에 의해 메모리에 저장된 오디오를 출력할 수 있다. 오디오 출력부는 스피커, 헤드폰 출력 단자 또는 S/PDIF(Sony/Philips Digital Interface: 출력 단자 중 적어도 하나를 포함할 수 있다. 전원부는 프로세서의 제어에 의해 영상 처리 장치 내부의 구성 요소들로 외부의 전원 소스에 서부터 입력되는 전원을 공급한다. 또한, 전원부는 프로세서의 제어에 의해 영상 처리 장치 내부에 위치하는 하나 또는 둘 이상의 배터리(도시되지 아니함)에서부터 출력되는 전원을 내부의 구성 요소들에 게 공급할 수 있다. 메모리는 프로세서의 제어에 의해 영상 처리 장치를 구동하고 제어하기 위한 다양한 데이터, 프로그램 또는 어플리케이션을 저장할 수 있다. 메모리는 도시되지 아니한 방송 수신 모듈, 채널 제어 모 듈, 볼륨 제어 모듈, 통신 제어 모듈, 음성 인식 모듈, 모션 인식 모듈, 광 수신 모듈, 디스플레이 제어 모듈, 오디오 제어 모듈, 외부 입력 제어 모듈, 전원 제어 모듈, 무선(예를 들어, 블루투스)으로 연결되는 외부 장치 의 전원 제어 모듈, 음성 데이터베이스(DB), 또는 모션 데이터베이스(DB)를 포함할 수 있다. 메모리의 도 시되지 아니한 모듈들 및 데이터 베이스는 디스플레이 장치에서 방송 수신의 제어 기능, 채널 제어 기능, 볼륨 제어 기능, 통신 제어 기능, 음성 인식 기능, 모션 인식 기능, 광 수신 제어 기능, 디스플레이 제어 기능, 오디오 제어 기능, 외부 입력 제어 기능, 전원 제어 기능 또는 무선(예를 들어, 블루투스)으로 연결되는 외부 장치의 전원 제어 기능을 수행하기 위하여 소프트웨어 형태로 구현될 수 있다. 프로세서는 메모리 에 저장된 이들 소프트웨어를 이용하여 각각의 기능을 수행할 수 있다. 한편, 도 14 내지 도 16에 도시된 서버, 영상 처리 장치(200, 1600)의 블록도들은 일 실시예를 위한 블록 도들이다. 블록도들의 각 구성요소는 실제 구현되는 서버, 영상 처리 장치(200, 1600)의 사양에 따라 통합, 추가, 또는 생략될 수 있다. 즉, 필요에 따라 2 이상의 구성요소가 하나의 구성요소로 합쳐지거나, 혹은 하나의 구성요소가 2 이상의 구성요소로 세분되어 구성될 수 있다. 또한, 각 블록에서 수행하는 기능은 실시예 들을 설명하기 위한 것이며, 그 구체적인 동작이나 장치는 본 발명의 권리범위를 제한하지 아니한다. 일 실시예에 따른 서버는, 통신부, 하나 이상의 인스트럭션들을 저장하는 메모리, 및 상기 하나 이상의 인스트 럭션들을 실행하는 적어도 하나의 프로세서를 포함할 수 있다. 상기 적어도 하나의 프로세서는, 상기 하나 이상의 인스트럭션들을 실행함으로써, 원본 영상을 압축하여, 제1 영상을 획득할 수 있다. 상기 적어도 하나의 프로세서는, 상기 하나 이상의 인스트럭션들을 실행함으로써, 상기 제1 영상에 대한 화질을 분석하여, 상기 제1 영상의 품질 정보를 획득할 수 있다. 상기 적어도 하나의 프로세서는, 상기 하나 이상의 인스트럭션들을 실행함으로써, 상기 품질 정보에 기초하여, 상기 제1 영상의 화질 처리에 이용되는 메타 모델에 대한 메타 모델 정보를 획득할 수 있다. 상기 적어도 하나의 프로세서는, 상기 하나 이상의 인스트럭션들을 실행함으로써, 상기 메타 모델 정보 및 상기 제1 영상을 영상 처리 장치로 전송하도록 상기 통신부를 제어할 수 있다. 상기 제1 영상은 비디오 컨텐츠에 포함되는 복수의 프레임 영상들을 포함할 수 있다. 상기 적어도 하나의 프로세서는, 상기 하나 이상의 인스트럭션들을 실행함으로써, 상기 복수의 프레임 영상들의 전체적인 품질 정보에 기초하여, 상기 복수의 프레임 영상들 중 제1 시점의 프레임 영상의 품질 정보를 획득할 수 있다. 상기 적어도 하나의 프로세서는, 상기 하나 이상의 인스트럭션들을 실행함으로써, 상기 복수의 프레임 영상들의 품질 평균 값 및 표준 편차에 기초하여, 품질 상한 값 및 품질 하한 값을 설정할 수 있다. 상기 적어도 하나의 프로세서는, 상기 하나 이상의 인스트럭션들을 실행함으로써, 상기 품질 상한 값 및 품질 하한 값에 기초하여, 상기 제1 시점의 프레임 영상의 품질 값을 결정할 수 있다. 상기 적어도 하나의 프로세서는, 상기 하나 이상의 인스트럭션들을 실행함으로써, 상기 품질 정보를 상기 영상 처리 장지로 전송하도록 상기 통신부를 제어할 수 있다. 상기 메타 모델은 적어도 하나의 참고 모델에 기초하여, 획득될 수 있다. 상기 메타 모델 정보는, 상기 적어도 하나의 참고 모델에 대한 정보 및 상기 적어도 하나의 참고 모델에 적용되 는 가중치에 대한 정보를 포함할 수 있다. 상기 적어도 하나의 프로세서는, 상기 하나 이상의 인스트럭션들을 실행함으로써, 상기 품질 정보에 기초하여, 상기 적어도 하나의 참고 모델 및 상기 적어도 하나의 참고 모델에 적용되는 가중치를 결정할 수 있다. 상기 적어도 하나의 프로세서는, 상기 하나 이상의 인스트럭션들을 실행함으로써, 상기 적어도 하나의 참고 모 델에 대응하는 품질 정보와 상기 제1 영상에 대한 품질 정보의 차이에 기초하여, 상기 가중치를 결정할 수 있다. 상기 적어도 하나의 참고 모델은, 상기 서버에 기 저장된 제1 참고 모델 또는 상기 영상 처리 장치에 기 저장된 제2 참고 모델을 포함할 수 있다. 상기 적어도 하나의 프로세서는, 상기 하나 이상의 인스트럭션들을 실행함으로써, 상기 제1 영상에 기초하여, 상기 제1 영상에 대응하는 상기 제1 참고 모델을 생성할 수 있다. 상기 적어도 하나의 프로세서는, 상기 하나 이상의 인스트럭션들을 실행함으로써, 상기 품질 정보에 기초하여, 상기 제1 참고 모델 또는 상기 제2 참고 모델을 선택할 수 있다. 상기 적어도 하나의 프로세서는, 상기 하나 이상의 인스트럭션들을 실행함으로써, 상기 선택된 제1 참고 모델에 대한 정보 또는 상기 선택된 제2 참고 모델의 식별 정보를 상기 영상 처리 장치로 전송하도록 상기 통신부를 제 어할 수 있다. 일 실시예에 따른 영상 처리 장치는, 통신부, 하나 이상의 인스트럭션들을 저장하는 메모리, 및 상기 하나 이상 의 인스트럭션들을 실행하는 적어도 하나의 프로세서를 포함할 수 있다. 상기 적어도 하나의 프로세서는, 상기 하나 이상의 인스트럭션들을 실행함으로써, 서버로부터 제1 영상 및 메타 모델 정보를 수신하도록 상기 통신부를 제어할 수 있다. 상기 적어도 하나의 프로세서는, 상기 하나 이상의 인스트럭션들을 실행함으로써, 상기 메타 모델 정보에 기초 하여, 메타 모델을 생성할 수 있다. 상기 적어도 하나의 프로세서는, 상기 하나 이상의 인스트럭션들을 실행함으로써, 상기 제1 영상에 대응하는 학 습 데이터 셋을 이용하여 상기 메타 모델을 학습시킬 수 있다. 상기 적어도 하나의 프로세서는, 상기 하나 이상의 인스트럭션들을 실행함으로써, 상기 학습된 메타 모델에 기 초하여, 상기 제1 영상을 화질 처리한 제2 영상을 획득할 수 있다. 상기 적어도 하나의 프로세서는, 상기 하나 이상의 인스트럭션들을 실행함으로써, 상기 메타 모델 정보에 포함 되는 적어도 하나의 참고 모델 정보와 상기 적어도 하나의 참고 모델에 적용되는 가중치 정보에 기초하여, 상기 메타 모델을 생성할 수 있다. 상기 적어도 하나의 프로세서는, 상기 하나 이상의 인스트럭션들을 실행함으로써, 상기 제1 영상의 품질 정보를 획득할 수 있다. 상기 적어도 하나의 프로세서는, 상기 하나 이상의 인스트럭션들을 실행함으로써, 상기 제1 영상의 품질 정보에 기초하여, 상기 제1 영상과 동일한 카테고리로 분류되는 영상들을 열화시킴으로써, 상기 학습 데이터 셋을 생성 할 수 있다. 일 실시예에 따른 서버의 동작 방법은, 원본 영상을 압축하여, 제1 영상을 획득하는 단계를 포함할 수 있다. 상기 서버의 동작 방법은, 상기 제1 영상에 대한 화질을 분석하여, 상기 제1 영상의 품질 정보를 획득하는 단계 를 포함할 수 있다. 상기 서버의 동작 방법은, 상기 품질 정보에 기초하여, 상기 제1 영상의 화질 처리에 이용되는 메타 모델에 대 한 메타 모델 정보를 획득하는 단계를 포함할 수 있다. 상기 서버의 동작 방법은, 상기 메타 모델 정보 및 상기 제1 영상을 영상 처리 장치로 전송하는 단계를 포함할 수 있다. 상기 제1 영상은 비디오 컨텐츠에 포함되는 복수의 프레임 영상들을 포함할 수 있다. 상기 제1 영상의 품질 정보를 획득하는 단계는, 상기 복수의 프레임 영상들의 전체적인 품질 정보에 기초하여, 상기 복수의 프레임 영상들 중 제1 시점의 프레임 영상의 품질 정보를 획득하는 단계를 포함할 수 있다. 상기 제1 영상의 품질 정보를 획득하는 단계는, 상기 복수의 프레임 영상들의 품질 평균 값 및 표준 편차에 기 초하여, 품질 상한 값 및 품질 하한 값을 설정하는 단계를 포함할 수 있다. 상기 제1 영상의 품질 정보를 획득하는 단계는, 상기 품질 상한 값 및 품질 하한 값에 기초하여, 상기 제1 시점 의 프레임 영상의 품질 값을 결정하는 단계를 포함할 수 있다. 상기 동작 방법은, 상기 품질 정보를 상기 영상 처리 장지로 전송하는 단계를 더 포함할 수 있다. 상기 메타 모델은 적어도 하나의 참고 모델에 기초하여, 획득될 수 있다. 상기 메타 모델 정보는, 상기 적어도 하나의 참고 모델에 대한 정보 및 상기 적어도 하나의 참고 모델에 적용되 는 가중치에 대한 정보를 포함할 수 있다. 상기 메타 모델 정보를 획득하는 단계는, 상기 품질 정보에 기초하여, 상기 적어도 하나의 참고 모델 및 상기 적어도 하나의 참고 모델에 적용되는 가중치를 결정하는 단계를 포함할 수 있다. 상기 적어도 하나의 참고 모델에 적용되는 가중치를 결정하는 단계는, 상기 적어도 하나의 참고 모델에 대응하 는 품질 정보와 상기 제1 영상에 대한 품질 정보의 차이에 기초하여, 상기 가중치를 결정하는 단계를 포함할 수 있다. 상기 적어도 하나의 참고 모델은, 상기 서버에 기 저장된 제1 참고 모델 또는 상기 영상 처리 장치에 기 저장된 제2 참고 모델을 포함할 수 있다. 상기 서버의 동작 방법은, 상기 제1 영상에 기초하여, 상기 제1 영상에 대응하는 상기 제1 참고 모델을 생성하 는 단계를 더 포함할 수 있다. 상기 메타 모델 정보를 획득하는 단계는, 상기 품질 정보에 기초하여, 상기 제1 참고 모델 또는 상기 제2 참고 모델을 선택하는 단계를 포함할 수 있다. 상기 메타 모델 정보를 전송하는 단계는, 상기 선택된 제1 참고 모델에 대한 정보 또는 상기 선택된 제2 참고 모델의 식별 정보를 상기 영상 처리 장치로 전송하는 단계를 포함할 수 있다. 일 실시예에 따른 서버는 제1 영상(입력 영상)뿐만 아니라 제1 영상이 포함되는 컨텐츠 전체의 화질을 분석하여, 제1 영상의 품질 정보를 결정함으로써, 화질 분석에 대한 정확도를 향상시킬 수 있다. 입력 영상에 대한 적응적인 화질 처리 모델을 획득하고, 획득된 화질 처리 모델을 이용하여, 입력 영상의 화질 처리를 수행함으로써, 영상 처리 장치의 화질 처리 성능을 향상시킬 수 있다. 일 실시예에 따른 서버의 동작 방법 및 영상 처리 장치의 동작 방법은 다양한 컴퓨터 수단을 통하여 수행될 수 있는 프로그램 명령 형태로 구현되어 컴퓨터 판독 가능 매체에 기록될 수 있다. 상기 컴퓨터 판독 가능 매체는 프로그램 명령, 데이터 파일, 데이터 구조 등을 단독으로 또는 조합하여 포함할 수 있다. 상기 매체에 기록되는 프로그램 명령은 본 발명을 위하여 특별히 설계되고 구성된 것들이거나 컴퓨터 소프트웨어 당업자에게 공지되어 사용 가능한 것일 수도 있다. 컴퓨터 판독 가능 기록 매체의 예에는 하드 디스크, 플로피 디스크 및 자기 테이 프와 같은 자기 매체(magnetic media), CD-ROM, DVD와 같은 광기록 매체(optical media), 플롭티컬 디스크 (floptical disk)와 같은 자기-광 매체(magneto-optical media), 및 롬(ROM), 램(RAM), 플래시 메모리 등과 같 은 프로그램 명령을 저장하고 수행하도록 특별히 구성된 하드웨어 장치가 포함된다. 프로그램 명령의 예에는 컴 파일러에 의해 만들어지는 것과 같은 기계어 코드뿐만 아니라 인터프리터 등을 사용해서 컴퓨터에 의해서 실행 될 수 있는 고급 언어 코드를 포함한다. 또한, 개시된 실시예들에 따른 서버의 동작 방법 및 영상 처리 장치의 동작 방법은 컴퓨터 프로그램 제품 (computer program product)에 포함되어 제공될 수 있다. 컴퓨터 프로그램 제품은 상품으로서 판매자 및 구매자간에 거래될 수 있다. 컴퓨터 프로그램 제품은 S/W 프로그램, S/W 프로그램이 저장된 컴퓨터로 읽을 수 있는 저장 매체를 포함할 수 있다. 예를 들어, 컴퓨터 프로그램 제품은 전자 장치의 제조사 또는 전자 마켓(예, 구글 플레이 스토어, 앱 스 토어)을 통해 전자적으로 배포되는 S/W 프로그램 형태의 상품(예, 다운로더블 앱)을 포함할 수 있다. 전자적 배 포를 위하여, S/W 프로그램의 적어도 일부는 저장 매체에 저장되거나, 임시적으로 생성될 수 있다. 이 경우, 저 장 매체는 제조사의 서버, 전자 마켓의 서버, 또는 SW 프로그램을 임시적으로 저장하는 중계 서버의 저장매체가 될 수 있다. 컴퓨터 프로그램 제품은, 서버 및 클라이언트 장치로 구성되는 시스템에서, 서버의 저장매체 또는 클라이언트 장치의 저장매체를 포함할 수 있다. 또는, 서버 또는 클라이언트 장치와 통신 연결되는 제3 장치(예, 스마트폰)가 존재하는 경우, 컴퓨터 프로그램 제품은 제3 장치의 저장매체를 포함할 수 있다. 또는, 컴퓨터 프 로그램 제품은 서버로부터 클라이언트 장치 또는 제3 장치로 전송되거나, 제3 장치로부터 클라이언트 장치로 전 송되는 S/W 프로그램 자체를 포함할 수 있다. 이 경우, 서버, 클라이언트 장치 및 제3 장치 중 하나가 컴퓨터 프로그램 제품을 실행하여 개시된 실시예들에 따른 방법을 수행할 수 있다. 또는, 서버, 클라이언트 장치 및 제3 장치 중 둘 이상이 컴퓨터 프로그램 제품을 실행하여 개시된 실시예들에 따른 방법을 분산하여 실시할 수 있다. 예를 들면, 서버(예로, 클라우드 서버 또는 인공 지능 서버 등)가 서버에 저장된 컴퓨터 프로그램 제품을 실행 하여, 서버와 통신 연결된 클라이언트 장치가 개시된 실시예들에 따른 방법을 수행하도록 제어할 수 있다. 이상에서 실시예들에 대하여 상세하게 설명하였지만 본 발명의 권리범위는 이에 한정되는 것은 아니고 다음의 청구범위에서 정의하고 있는 본 발명의 기본 개념을 이용한 당업자의 여러 변형 및 개량 형태 또한 본 발명의 권리범위에 속한다."}
{"patent_id": "10-2023-0132460", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 일 실시예에 따른 영상의 화질 처리 시스템을 나타내는 도면이다. 도 2는 일 실시예에 따른 다양한 영상들의 품질 정보를 그래프에 나타내는 도면이다. 도 3은 일 실시예에 따른 서버의 동작 방법을 나타내는 흐름도이다. 도 4는 일 실시예에 따른 서버의 구성을 나타내는 도면이다. 도 5는 일 실시예에 따른 제1 뉴럴 네트워크의 구조를 나타내는 도면이다. 도 6은 일 실시예에 따른 비디오 컨텐츠에 포함되는 복수의 프레임 영상들에 대한 품질 값을 나타내는 그래프이 다. 도 7은 일 실시예에 따른 적어도 하나의 참고 모델에 기초하여, 메타 모델이 획득되는 것을 설명하기 위한 도면 이다. 도 8은 일 실시예에 따른 영상 처리 장치의 동작 방법을 나타내는 흐름도이다. 도 9는 일 실시예에 따른 영상 처리 장치의 구성을 나타내는 도면이다. 도 10은 일 실시예에 따른 모델 학습부의 동작을 설명하기 위한 도면이다. 도 11은 일 실시예에 따른 학습 DB 생성부가 제1 영상과 유사한 카테고리의 영상들을 획득하는 동작을 설명하기 위한 도면이다. 도 12는 일 실시예에 따른 학습 DB 생성부가 학습 데이터 셋을 생성하는 동작을 설명하기 위한 도면이다. 도 13은 일 실시예에 따른 압축 과정에서 발생하는 열화를 학습 영상에 반영하는 방법을 설명하기 위한 도면이 다. 도 14는 일 실시예에 따른 서버의 구성을 나타내는 블록도이다. 도 15는 일 실시예에 따른 영상 처리 장치의 구성을 나타내는 블록도이다. 도 16은 일 실시예에 따른 영상 처리 장치의 구성을 나타내는 블록도이다."}
