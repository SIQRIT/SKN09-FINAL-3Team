{"patent_id": "10-2021-0150409", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0064860", "출원번호": "10-2021-0150409", "발명의 명칭": "라이트 필드 이미지 장치 및 방법", "출원인": "국민대학교산학협력단", "발명자": "윤상민"}}
{"patent_id": "10-2021-0150409", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "물리적 카메라를 통해 적어도 하나의 객체를 포함하는 평면 이미지를 생성하는 이미지 생성부;상기 물리적 카메라 및 상기 적어도 하나의 객체 사이에 가상적으로 배치되고 인공지능 학습 모델로 구현되는복수의 가상 카메라 집합들을 통해 상기 적어도 하나의 객체 각각에 관한 깊이 레이어를 생성하는 깊이 레이어생성부; 및상기 깊이 레이어를 통해 상기 평면 이미지를 3차원 이미지로 변환하고 상기 적어도 하나의 객체 중 하나에 대하여 리포커싱(refocus)을 수행하여 상기 3차원 이미지를 가공하는 이미지 가공부를 포함하는 라이트 필드(light field) 이미지 장치."}
{"patent_id": "10-2021-0150409", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 이미지 생성부는 상기 평면 이미지를 기초로 깊이 맵(depth map)을 생성하고 상기 평면 이미지와 상기 깊이 맵으로 구성된 통합이미지(integral image)를 생성하는 것을 특징으로 하는 라이트 필드 이미지 장치."}
{"patent_id": "10-2021-0150409", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서, 상기 깊이 레이어 생성부는상기 복수의 가상 카메라 집합들을 통해 상기 평면 이미지에 대응하는 라이트 필드 이미지들을 생성하고 상기라이트 필드 이미지들을 MPI(Multi Plane Image) 모델에 입력하여 상기 깊이 레이어를 생성하는 것을 특징으로하는 라이트 필드 이미지 장치."}
{"patent_id": "10-2021-0150409", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서, 상기 깊이 레이어 생성부는상기 복수의 가상 카메라 집합들 각각을 단일 메인 렌즈와 상기 단일 메인 렌즈를 통해 투과되는 라이트 범위(light range)에 있는 동일 평면 상에 배치되는 복수의 마이크로 렌즈들로 구성하는 것을 특징으로 하는 라이트필드 이미지 장치."}
{"patent_id": "10-2021-0150409", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서, 상기 깊이 레이어 생성부는상기 복수의 마이크로 렌즈들 각각을 협각 학습 모델로 구현하고 상기 메인 렌즈를 상기 협각 학습 모델에 전체적인 라이트 방향을 제공하는 광각 학습 모델로 구현하는 것을 특징으로 하는 라이트 필드 이미지 장치."}
{"patent_id": "10-2021-0150409", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제4항에 있어서, 상기 깊이 레이어 생성부는상기 단일 메인 렌즈를 통해 처리되는 객체의 입체성을 조절하기 위해 상기 단일 메인 렌즈 및 상기 복수의 마공개특허 10-2023-0064860-3-이크로 렌즈들 간의 거리를 가변시키는 것을 특징으로 하는 라이트 필드 이미지 장치."}
{"patent_id": "10-2021-0150409", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에 있어서, 상기 깊이 레이어 생성부는상기 적어도 하나의 객체 중 하나를 배경 객체로 설정하고 상기 배경 객체를 가장 깊은 깊이를 가지는 배경 레이어에 배치하는 것을 특징으로 하는 라이트 필드 이미지 장치."}
{"patent_id": "10-2021-0150409", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1항에 있어서, 상기 이미지 가공부는상기 리포커싱의 과정에서 나머지 객체와의 상대적 거리와 무관하게 배경 레이어의 깊이를 독립적으로 증가시킬수 있도록 상기 배경 레이어를 구성하는 것을 특징으로 하는 라이트 필드 이미지 장치."}
{"patent_id": "10-2021-0150409", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1항에 있어서, 상기 이미지 가공부는상기 적어도 하나의 객체 중 배경 객체를 제외한 나머지 객체의 깊이 레이어의 배치를 변경하여 상기 3차원 이미지를 재구성하는 것을 특징으로 하는 라이트 필드 이미지 장치."}
{"patent_id": "10-2021-0150409", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제1항에 있어서, 상기 이미지 가공부는상기 적어도 하나의 객체 중 배경 객체를 제외한 배경 제외 객체를 선별하여 해당 깊이 레이어 기반의 객체로서다른 3차원 이미지에 삽입하는 것을 특징으로 하는 라이트 필드 이미지 장치."}
{"patent_id": "10-2021-0150409", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "물리적 카메라를 통해 적어도 하나의 객체를 포함하는 평면 이미지를 생성하는 이미지 생성단계;상기 물리적 카메라 및 상기 적어도 하나의 객체 사이에 가상적으로 배치되고 인공지능 학습 모델로 구현되는복수의 가상 카메라 집합들을 통해 상기 적어도 하나의 객체 각각에 관한 깊이 레이어를 생성하는 깊이 레이어생성단계; 및상기 깊이 레이어를 통해 상기 평면 이미지를 3차원 이미지로 변환하고 상기 적어도 하나의 객체 중 하나에 대하여 리포커싱(refocus)을 수행하여 상기 3차원 이미지를 가공하는 이미지 가공단계를 포함하는 라이트 필드(light field) 이미지 방법."}
{"patent_id": "10-2021-0150409", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항에 있어서, 상기 깊이 레이어 생성단계는상기 복수의 가상 카메라 집합들 각각을 단일 메인 렌즈와 상기 단일 메인 렌즈를 통해 투과되는 라이트 범위(light range)에 있는 동일 평면 상에 배치되는 복수의 마이크로 렌즈들로 구성하는 단계를 포함하는 것을 특징으로 하는 라이트 필드 이미지 방법.공개특허 10-2023-0064860-4-청구항 13 제11항에 있어서, 상기 이미지 가공단계는상기 적어도 하나의 객체 중 배경 객체를 제외한 나머지 객체의 깊이 레이어의 배치를 변경하여 상기 3차원 이미지를 재구성하는 단계를 포함하는 것을 특징으로 하는 라이트 필드 이미지 방법."}
{"patent_id": "10-2021-0150409", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제11항에 있어서, 상기 이미지 가공단계는상기 적어도 하나의 객체 중 배경 객체를 제외한 배경 제외 객체를 선별하여 해당 깊이 레이어 기반의 객체로서다른 3차원 이미지에 삽입하는 단계를 포함하는 것을 특징으로 하는 라이트 필드 이미지 방법."}
{"patent_id": "10-2021-0150409", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 라이트 필드 이미지 장치 및 방법에 관한 것으로, 상기 장치는 물리적 카메라를 통해 적어도 하나의 객체를 포함하는 평면 이미지를 생성하는 이미지 생성부; 상기 물리적 카메라 및 상기 적어도 하나의 객체 사이 에 가상적으로 배치되고 인공지능 학습 모델로 구현되는 복수의 가상 카메라 집합들을 통해 상기 적어도 하나의 객체 각각에 관한 깊이 레이어를 생성하는 깊이 레이어 생성부; 및 상기 깊이 레이어를 통해 상기 평면 이미지를 3차원 이미지로 변환하고 상기 적어도 하나의 객체 중 하나에 대하여 리포커싱(refocus)을 수행하여 상기 3차원 이미지를 가공하는 이미지 가공부를 포함한다."}
{"patent_id": "10-2021-0150409", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 3차원 이미지 생성 기술에 관한 것으로, 보다 상세하게는 단안 영상으로부터 기계학습을 통해 깊이 정보를 검출하여 영상 공간을 3차원으로 재구성할 수 있는 라이트 필드 이미지 장치 및 방법에 관한 것이다."}
{"patent_id": "10-2021-0150409", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "카메라가 보편화됨에 따라 많은 응용 프로그램이 개발되고 있다. 일반적으로 사진은 3차원 실세계가 카메라를 통해 2차원 영상으로 투영됨으로써 물체까지의 깊이 정보와 공간 정보가 손실될 수 있다. 따라서, 영상으로부터 사용자가 그림을 그리거나 저작하기 위해서는 2차원 환경에서만 저작할 수 있다. 또한, 단안 영상으로부터 3차원 기학학적 구조를 추정하는 작업은 컴퓨터 비전 연구에서 매우 어려운 과제 중 하나일 수 있다. 주어진 영상의 3차원 구조를 추정하기 위해 초기에는 카메라 이동에 의해 촬영된 여러 시점의 정적 객체에 대한 3차원 정보를 계산하는 움직임 기반 모양 추정 방법(Shape from Motion), 초점을 달리하여 촬 영한 여러 장의 영상을 조합하여 3차원 정보를 계산하는 초점 변화 기반 방법(Depth from Focus/Defocus) 등 두 장 이상의 영상을 기반으로 하는 방법을 이용하여 영상의 3차원 구조를 추정하는 방법이 주로 연구되었다. 그러나, 이는 매우 제한된 조건 아래에서만 적용 가능하고, 서로 다른 위치에서 촬영한 영상 간에 대응되는 특 징점에 삼각법(triangulation)을 적용하여 3차원 정보를 획득하기 때문에 단안 영상으로부터 얻을 수 있는 풍부 한 3차원 정보를 배제하고 있다. 단안 영상의 소실점 검출 기술 등을 이용하여 깊이 정보를 추정하는 것을 시작 으로 최근에는 단안 영상에서 얻을 수 있는 기하학적 단서(monocular cue)를 기반으로 한 3차원 구조 추정 기술 에 대한 연구가 소개되고 있다. 선행기술문헌 특허문헌 (특허문헌 0001) 한국등록특허 제10-1082046호 (2011.11.03)"}
{"patent_id": "10-2021-0150409", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명의 일 실시예는 단안 영상으로부터 기계학습을 통해 깊이 정보를 검출하여 영상 공간을 3차원으로 재구 성할 수 있는 라이트 필드 이미지 장치 및 방법을 제공하고자 한다.본 발명의 일 실시예는 단안 영상을 기초로 3차원으로 재구성된 영상의 깊이 정보를 기초로 영상 내 객체를 구 분함으로써 객체 이동 및 저작을 통해 사용자에게 풍부한 경험을 제공할 수 있는 라이트 필드 이미지 장치 및 방법을 제공하고자 한다."}
{"patent_id": "10-2021-0150409", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "실시예들 중에서, 라이트 필드 (light field) 이미지 장치는 물리적 카메라를 통해 적어도 하나의 객체를 포함 하는 평면 이미지를 생성하는 이미지 생성부; 상기 물리적 카메라 및 상기 적어도 하나의 객체 사이에 가상적으 로 배치되고 인공지능 학습 모델로 구현되는 복수의 가상 카메라 집합들을 통해 상기 적어도 하나의 객체 각각 에 관한 깊이 레이어를 생성하는 깊이 레이어 생성부; 및 상기 깊이 레이어를 통해 상기 평면 이미지를 3차원 이미지로 변환하고 상기 적어도 하나의 객체 중 하나에 대하여 리포커싱(refocus)을 수행하여 상기 3차원 이미 지를 가공하는 이미지 가공부를 포함한다. 상기 이미지 생성부는 상기 평면 이미지를 기초로 깊이 맵(depth map)을 생성하고 상기 평면 이미지와 상기 깊 이 맵으로 구성된 통합 이미지(integral image)를 생성할 수 있다. 상기 깊이 레이어 생성부는 상기 복수의 가상 카메라 집합들을 통해 상기 평면 이미지에 대응하는 라이트 필드 이미지들을 생성하고 상기 라이트 필드 이미지들을 MPI(Multi Plane Image) 모델에 입력하여 상기 깊이 레이어 를 생성할 수 있다. 상기 깊이 레이어 생성부는 상기 복수의 가상 카메라 집합들 각각을 단일 메인 렌즈와 상기 단일 메인 렌즈를 통해 투과되는 라이트 범위(light range)에 있는 동일 평면 상에 배치되는 복수의 마이크로 렌즈들로 구성할 수 있다. 상기 깊이 레이어 생성부는 상기 복수의 마이크로 렌즈들 각각을 협각 학습 모델로 구현하고 상기 메인 렌즈를 상기 협각 학습 모델에 전체적인 라이트 방향을 제공하는 광각 학습 모델로 구현할 수 있다. 상기 깊이 레이어 생성부는 상기 단일 메인 렌즈를 통해 처리되는 객체의 입체성을 조절하기 위해 상기 단일 메 인 렌즈 및 상기 복수의 마이크로 렌즈들 간의 거리를 가변시킬 수 있다. 상기 깊이 레이어 생성부는 상기 적어도 하나의 객체 중 하나를 배경 객체로 설정하고 상기 배경 객체를 가장 깊은 깊이를 가지는 배경 레이어에 배치할 수 있다. 상기 이미지 가공부는 상기 리포커싱의 과정에서 나머지 객체와의 상대적 거리와 무관하게 배경 레이어의 깊이 를 독립적으로 증가시킬 수 있도록 상기 배경 레이어를 구성할 수 있다. 상기 이미지 가공부는 상기 적어도 하나의 객체 중 배경 객체를 제외한 나머지 객체의 깊이 레이어의 배치를 변 경하여 상기 3차원 이미지를 재구성할 수 있다. 상기 이미지 가공부는 상기 적어도 하나의 객체 중 배경 객체를 제외한 배경 제외 객체를 선별하여 해당 깊이 레이어 기반의 객체로서 다른 3차원 이미지에 삽입할 수 있다. 실시예들 중에서, 라이트 필드 (light field) 이미지 방법은 물리적 카메라를 통해 적어도 하나의 객체를 포함 하는 평면 이미지를 생성하는 이미지 생성단계; 상기 물리적 카메라 및 상기 적어도 하나의 객체 사이에 가상적 으로 배치되고 인공지능 학습 모델로 구현되는 복수의 가상 카메라 집합들을 통해 상기 적어도 하나의 객체 각 각에 관한 깊이 레이어를 생성하는 깊이 레이어 생성단계; 및 상기 깊이 레이어를 통해 상기 평면 이미지를 3차 원 이미지로 변환하고 상기 적어도 하나의 객체 중 하나에 대하여 리포커싱(refocus)을 수행하여 상기 3차원 이 미지를 가공하는 이미지 가공단계를 포함한다. 상기 깊이 레이어 생성단계는 상기 복수의 가상 카메라 집합들 각각을 단일 메인 렌즈와 상기 단일 메인 렌즈를 통해 투과되는 라이트 범위(light range)에 있는 동일 평면 상에 배치되는 복수의 마이크로 렌즈들로 구성하는 단계를 포함할 수 있다. 상기 이미지 가공단계는 상기 적어도 하나의 객체 중 배경 객체를 제외한 나머지 객체의 깊이 레이어의 배치를 변경하여 상기 3차원 이미지를 재구성하는 단계를 포함할 수 있다. 상기 이미지 가공단계는 상기 적어도 하나의 객체 중 배경 객체를 제외한 배경 제외 객체를 선별하여 해당 깊이 레이어 기반의 객체로서 다른 3차원 이미지에 삽입하는 단계를 포함할 수 있다."}
{"patent_id": "10-2021-0150409", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "개시된 기술은 다음의 효과를 가질 수 있다. 다만, 특정 실시예가 다음의 효과를 전부 포함하여야 한다거나 다 음의 효과만을 포함하여야 한다는 의미는 아니므로, 개시된 기술의 권리범위는 이에 의하여 제한되는 것으로 이 해되어서는 아니 될 것이다. 본 발명의 일 실시예에 따른 라이트 필드 이미지 장치 및 방법은 단안 영상으로부터 기계학습을 통해 깊이 정보 를 검출하여 영상 공간을 3차원으로 재구성할 수 있다. 본 발명의 일 실시예에 따른 라이트 필드 이미지 장치 및 방법은 사용자가 몰입감을 느끼며 3차원 공간에서 저 작할 수 있는 환경을 제공할 수 있으며, 실제 3차원 공간처럼 사용자가 3차원으로 재구성된 영상을 재구성하기 때문에 가상환경 및 증강현실 구현에 활용 가능할 수 있다."}
{"patent_id": "10-2021-0150409", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명에 관한 설명은 구조적 내지 기능적 설명을 위한 실시예에 불과하므로, 본 발명의 권리범위는 본문에 설 명된 실시예에 의하여 제한되는 것으로 해석되어서는 아니 된다. 즉, 실시예는 다양한 변경이 가능하고 여러 가 지 형태를 가질 수 있으므로 본 발명의 권리범위는 기술적 사상을 실현할 수 있는 균등물들을 포함하는 것으로 이해되어야 한다. 또한, 본 발명에서 제시된 목적 또는 효과는 특정 실시예가 이를 전부 포함하여야 한다거나 그러한 효과만을 포함하여야 한다는 의미는 아니므로, 본 발명의 권리범위는 이에 의하여 제한되는 것으로 이해 되어서는 아니 될 것이다. 한편, 본 출원에서 서술되는 용어의 의미는 다음과 같이 이해되어야 할 것이다. \"제1\", \"제2\" 등의 용어는 하나의 구성요소를 다른 구성요소로부터 구별하기 위한 것으로, 이들 용어들에 의해 권리범위가 한정되어서는 아니 된다. 예를 들어, 제1 구성요소는 제2 구성요소로 명명될 수 있고, 유사하게 제2 구성요소도 제1 구성요소로 명명될 수 있다. 어떤 구성요소가 다른 구성요소에 \"연결되어\"있다고 언급된 때에는, 그 다른 구성요소에 직접적으로 연결될 수 도 있지만, 중간에 다른 구성요소가 존재할 수도 있다고 이해되어야 할 것이다. 반면에, 어떤 구성요소가 다른 구성요소에 \"직접 연결되어\"있다고 언급된 때에는 중간에 다른 구성요소가 존재하지 않는 것으로 이해되어야 할 것이다. 한편, 구성요소들 간의 관계를 설명하는 다른 표현들, 즉 \"~사이에\"와 \"바로 ~사이에\" 또는 \"~에 이웃 하는\"과 \"~에 직접 이웃하는\" 등도 마찬가지로 해석되어야 한다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한 복수의 표현을 포함하는 것으로 이해되어야 하고, \"포함 하다\"또는 \"가지다\" 등의 용어는 실시된 특징, 숫자, 단계, 동작, 구성요소, 부분품 또는 이들을 조합한 것이 존재함을 지정하려는 것이며, 하나 또는 그 이상의 다른 특징이나 숫자, 단계, 동작, 구성요소, 부분품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되어야 한다. 각 단계들에 있어 식별부호(예를 들어, a, b, c 등)는 설명의 편의를 위하여 사용되는 것으로 식별부호는 각 단 계들의 순서를 설명하는 것이 아니며, 각 단계들은 문맥상 명백하게 특정 순서를 기재하지 않는 이상 명기된 순 서와 다르게 일어날 수 있다. 즉, 각 단계들은 명기된 순서와 동일하게 일어날 수도 있고 실질적으로 동시에 수 행될 수도 있으며 반대의 순서대로 수행될 수도 있다. 본 발명은 컴퓨터가 읽을 수 있는 기록매체에 컴퓨터가 읽을 수 있는 코드로서 구현될 수 있고, 컴퓨터가 읽을 수 있는 기록 매체는 컴퓨터 시스템에 의하여 읽혀질 수 있는 데이터가 저장되는 모든 종류의 기록 장치를 포함 한다. 컴퓨터가 읽을 수 있는 기록 매체의 예로는 ROM, RAM, CD-ROM, 자기 테이프, 플로피 디스크, 광 데이터 저장 장치 등이 있다. 또한, 컴퓨터가 읽을 수 있는 기록 매체는 네트워크로 연결된 컴퓨터 시스템에 분산되어, 분산 방식으로 컴퓨터가 읽을 수 있는 코드가 저장되고 실행될 수 있다. 여기서 사용되는 모든 용어들은 다르게 정의되지 않는 한, 본 발명이 속하는 분야에서 통상의 지식을 가진 자에 의해 일반적으로 이해되는 것과 동일한 의미를 가진다. 일반적으로 사용되는 사전에 정의되어 있는 용어들은 관 련 기술의 문맥상 가지는 의미와 일치하는 것으로 해석되어야 하며, 본 출원에서 명백하게 정의하지 않는 한 이 상적이거나 과도하게 형식적인 의미를 지니는 것으로 해석될 수 없다. 도 1은 본 발명에 따른 라이트 필드 이미지 시스템을 설명하는 도면이다. 도 1을 참조하면, 라이트 필드 이미지 시스템은 사용자 단말, 라이트 필드 이미지 장치 및 데이 터베이스를 포함할 수 있다. 사용자 단말은 라이트 필드 이미지 장치와 연결되어 이미지를 입력하거나 입력된 이미지의 3차원 영 상을 확인할 수 있는 컴퓨팅 장치에 해당할 수 있다. 사용자 단말은 스마트폰, 노트북 또는 컴퓨터로 구현 될 수 있으며, 반드시 이에 한정되지 않고, 태블릿 PC 등 다양한 디바이스로도 구현될 수 있다. 사용자 단말 은 라이트 필드 이미지 장치와 네트워크를 통해 연결될 수 있고, 복수의 사용자 단말들이 라이 트 필드 이미지 장치와 동시에 연결될 수도 있다. 일 실시예에서, 사용자 단말은 2차원 단안 영상을 촬영할 수 있는 카메라를 포함하여 구현될 수 있다. 즉, 사용자는 사용자 단말을 통해 단안 영상을 직접 촬영할 수 있으며, 사용자 단말 상에서 생성된 2차원 영상은 라이트 필드 이미지 장치로 전송되어 관련 동작 과정에서 사용될 수 있다. 이때, 사용자 단말 상에 포함되는 카메라는 기본적으로 2차원 단안 영상을 촬영하도록 구현될 수 있으며, 필요에 따라 복수개로 구 성되거나 또는 3차원 입체 영상을 촬영하도록 구현될 수도 있다. 라이트 필드 이미지 장치는 본 발명에 따른 라이트 필드 이미지 방법을 수행하는 컴퓨터 또는 프로그램에 해당하는 서버로 구현될 수 있다. 라이트 필드 이미지 장치는 사용자 단말과 유선 또는 무선 네트워 크를 통해 연결될 수 있고 상호 간에 데이터를 주고받을 수 있다. 일 실시예에서, 라이트 필드 이미지 장치 는 본 발명에 따른 라이트 필드 이미지 생성 방법을 수행하는 과정에서 다양한 외부 시스템(또는 서버)과 연동하여 동작할 수 있다. 데이터베이스는 라이트 필드 이미지 장치의 동작 과정에서 필요한 다양한 정보들을 저장하는 저장장 치에 해당할 수 있다. 예를 들어, 데이터베이스는 이미지 데이터 셋을 저장할 수 있고, 학습 모델 구축을 위한 학습 알고리즘 및 모델 정보를 저장할 수 있으며, 반드시 이에 한정되지 않고, 라이트 필드 이미지 장치 가 본 발명에 라이트 필드 이미지 방법을 수행하는 과정에서 다양한 형태로 수집 또는 가공된 정보들을 저 장할 수 있다. 한편, 데이터베이스는 도 1과 달리, 라이트 필드 이미지 장치 내부에 포함되어 구현될 수 있다. 도 2는 도 1의 라이트 필드 이미지 장치의 시스템 구성을 설명하는 도면이다. 도 2를 참조하면, 라이트 필드 이미지 장치는 프로세서, 메모리, 사용자 입출력부 및 네트 워크 입출력부를 포함할 수 있다. 프로세서는 라이트 필드 이미지 장치가 동작하는 과정에서의 각 단계들을 처리하는 프로시저를 실행 할 수 있고, 그 과정 전반에서 읽혀지거나 작성되는 메모리를 관리할 수 있으며, 메모리에 있는 휘발성 메모리와 비휘발성 메모리 간의 동기화 시간을 스케줄할 수 있다. 프로세서는 라이트 필드 이미지 장치 의 동작 전반을 제어할 수 있고, 메모리, 사용자 입출력부 및 네트워크 입출력부와 전기적 으로 연결되어 이들 간의 데이터 흐름을 제어할 수 있다. 프로세서는 라이트 필드 이미지 장치의 CPU(Central Processing Unit)로 구현될 수 있다. 메모리는 SSD(Solid State Drive) 또는 HDD(Hard Disk Drive)와 같은 비휘발성 메모리로 구현되어 라이트 필드 이미지 장치에 필요한 데이터 전반을 저장하는데 사용되는 보조기억장치를 포함할 수 있고, RAM(Random Access Memory)과 같은 휘발성 메모리로 구현된 주기억장치를 포함할 수 있다. 사용자 입출력부는 사용자 입력을 수신하기 위한 환경 및 사용자에게 특정 정보를 출력하기 위한 환경을 포함할 수 있다. 예를 들어, 사용자 입출력부는 터치 패드, 터치 스크린, 화상 키보드 또는 포인팅 장치와 같은 어댑터를 포함하는 입력장치 및 모니터 또는 터치스크린과 같은 어댑터를 포함하는 출력장치를 포함할 수 있다. 일 실시예에서, 사용자 입출력부는 원격 접속을 통해 접속되는 컴퓨팅 장치에 해당할 수 있고, 그러 한 경우, 라이트 필드 이미지 장치는 독립적인 서버로서 수행될 수 있다. 네트워크 입출력부은 네트워크를 통해 외부 장치 또는 시스템과 연결하기 위한 환경을 포함하고, 예를 들 어, LAN(Local Area Network), MAN(Metropolitan Area Network), WAN(Wide Area Network) 및 VAN(Value Added Network) 등의 통신을 위한 어댑터를 포함할 수 있다. 도 3은 도 1의 라이트 필드 이미지 장치의 기능적 구성을 설명하는 도면이다. 도 3을 참조하면, 라이트 필드 이미지 장치는 이미지 생성부, 깊이 레이어 생성부, 이미지 가공 부 및 제어부를 포함할 수 있다. 이미지 생성부는 물리적 카메라를 통해 적어도 하나의 객체를 포함하는 평면 이미지를 생성할 수 있다. 이 때, 물리적 카메라는 사용자 단말 상에 포함되어 구현될 수 있으며, 독립된 장치로서 구현되어 이미지 생 성부와 직접 연동될 수도 있다. 이미지 생성부는 물리적 카메라에 의해 촬영된 단안 영상을 기초로 평면 이미지를 생성할 수 있으며, 평면 이미지는 2차원 이미지로서 RGB 이미지에 해당할 수 있다. 이미지 생성 부는 단안 영상으로부터 복수의 평면 이미지들을 생성하여 데이터베이스에 저장할 수 있다. 일 실시예에서, 이미지 생성부는 단안 영상으로부터 평면 이미지를 생성하는 과정에서 소정의 전처리 동작 을 수행할 수 있다. 즉, 이미지 생성부는 전처리 동작을 통해 이후 동작 과정에서 평면 이미지가 효율적으 로 활용될 수 있도록 할 수 있다. 예를 들어, 이미지 생성부는 단안 영상에서 생성된 평면 이미지들 중에 서 객체를 포함하지 않는 이미지들을 제거하여 적어도 하나의 객체를 포함하는 평면 이미지만을 생성할 수 있다. 또한, 이미지 생성부는 생성된 평면 이미지에 대해 소정의 필터(filter)를 적용하거나 또는 샘플링 (sampling)을 통해 이미지의 크기를 변경하는 동작을 수행할 수 있다. 일 실시예에서, 이미지 생성부는 평면 이미지를 기초로 깊이 맵(depth map)을 생성할 수 있다. 이를 위해, 이미지 생성부는 사전 구축된 깊이 추청 모델(depth estimation network)을 활용할 수 있다. 깊이 추정 모 델은 RGB 이미지와 깊이 이미지를 학습 데이터로서 학습하여 구축될 수 있으며, 입력된 이미지에 대한 깊이를 추정하는 동작을 수행할 수 있다. 즉, 이미지 생성부는 평면 이미지를 깊이 추정 모델에 입력으로 제공하 고 그 결과로서 평면 이미지에 대응하는 깊이 맵을 출력으로 수신할 수 있다. 평면 이미지와 깊이 맵은 하나의 통합 이미지(integral image)로서 이후 동작 단계에서 활용될 수 있다. 깊이 레이어 생성부는 물리적 카메라 및 적어도 하나의 객체 사이에 가상적으로 배치되고 인공지능 학습 모델로 구현되는 복수의 가상 카메라 집합들을 통해 적어도 하나의 객체 각각에 관한 깊이 레이어를 생성할 수 있다. 여기에서, 깊이 레이어는 적어도 하나의 객체를 독립적으로 포함하고 해당 객체의 깊이에서 정의되는 평 면 상의 이미지에 해당할 수 있으며, 깊이 레이어들의 집합은 주어진 이미지에 대응되는 다중 평면 이미지(MPI, Multi Plane Image)에 해당할 수 있다. 또한, 깊이 레이어는 해당 객체의 깊이에 대응되는 RGB 이미지와 알파 (σ) 이미지로 구성될 수 있다. 이때, 알파 이미지는 해당 객체의 깊이에서의 투명도 정보를 포함할 수 있으며, RGB 이미지의 가시성(visibility)을 결정할 수 있다. 일 실시예에서, 깊이 레이어 생성부는 복수의 가상 카메라 집합들을 통해 평면 이미지에 대응하는 라이트 필드 이미지들을 생성하고 라이트 필드 이미지들을 MPI(Multi Plane Image) 모델에 입력하여 깊이 레이어를 생 성할 수 있다. 즉, 깊이 레이어 생성부는 입력된 평면 이미지를 기초로 다중 평면 이미지(MPI, MultiPlane Image), 즉 깊이 레이어를 생성하기 위하여 크게 2가지의 과정을 순차적으로 수행할 수 있다. 먼저, 제1 과정에서, 깊이 레이어 생성부는 RGB 이미지와 깊이 이미지(depth image)의 통합 이미지(integral imag e)를 수신하여 복수의 라이트 필드 이미지들을 생성할 수 있다. 이후, 제2 과정에서, 깊이 레이어 생성부 는 각 라이트 필드 이미지들에 대해 MPI 모델을 적용하여 적어도 하나의 객체 각각에 관한 깊이 레이어를 생성 할 수 있다. 이때, MPI 모델은 주어진 입력 이미지에 대해 다중 평면 이미지(MPI)를 생성하도록 학습된 기계학 습 모델에 해당할 수 있다. 일 실시예에서, 깊이 레이어 생성부는 복수의 가상 카메라 집합들 각각을 단일 메인 렌즈와 단일 메인 렌 즈를 통해 투과되는 라이트 범위(light range)에 있는 동일 평면 상에 배치되는 복수의 마이크로 렌즈들로 구성 할 수 있다. 깊이 레이어 생성부는 전용 하드웨어 장치 대신 소프트웨어 접근을 통해 평면 이미지에 관한 라이트 필드 이미지들을 생성할 수 있다. 즉, 소프트웨어로 구현된 복수의 가상 카메라 집합들은 각각이 독립적으로 평면 이미지 상의 특정 영역에 대응 되도록 배치될 수 있으며, 이에 따라 복수의 가상 카메라 집합들에 의해 생성된 라이트 필드 이미지들은 입력된 평면 이미지의 전체 영역을 커버할 수 있다. 또한, 하나의 가상 카메라 집합에는 단일 메인 렌즈와 복수의 마이 크로 렌즈들로 구성될 수 있으며, 복수의 마이크로 렌즈들은 단일 메인 렌즈의 라이트 범위를 커버하는 동일 평 면 상에 배치될 수 있다. 예를 들어, 하나의 가상 카메라 집합이 240×120 크기의 영역에 대응되고, 4×3=12개 의 마이크로 렌즈들을 포함하는 경우, 60×40 크기를 갖는 16개의 라이트 필드 이미지들이 생성될 수 있다. 일 실시예에서, 깊이 레이어 생성부는 복수의 마이크로 렌즈들 각각을 협각 학습 모델로 구현하고 메인 렌 즈를 협각 학습 모델에 전체적인 라이트 방향을 제공하는 광각 학습 모델로 구현할 수 있다. 깊이 레이어 생성 부는 복수의 가상 카메라 집합들을 소프트웨어적으로 구현할 수 있으며, 가상 카메라 집합을 구성하는 렌 즈들의 광학적인 동작을 소정의 기계학습 모델을 통해 구현할 수 있다. 특히, 단일 메인 렌즈는 광각 학습 모델로 구현되어 실제 카메라의 단일 렌즈의 동작을 수행할 수 있으며, 구체 적으로 카메라 전방으로부터 투사된 라이트(light)들을 수집하여 마이크로 렌즈들의 방향으로 투사하도록 구현 될 수 있다. 이때, 메인 렌즈가 마이크로 렌즈들을 향해 투사하는 라이트들은 소정의 방향을 가질 수 있으며, 광각 학습 모델은 카메라 전방에서 투사된 라이트를 입력으로 수신하여 마이크로 렌즈들을 향해 투사되는 라이 트를 출력으로 생성하도록 학습될 수 있다. 또한, 복수의 마이크로 렌즈들 각각은 메인 렌즈에서 투사된 라이트들 중 설정된 방향의 라이트만을 입력으로 수신하여 라이트 필드 이미지가 형성되는 이미지 평면(image plane)을 향해 투사되는 라이트를 출력으로 생성하 는 협각 학습 모델로 구현될 수 있다. 결과적으로, 광각 학습 모델은 가상 카메라의 화각(FOV, Field Of View) 방향의 라이트들을 마이크로 렌즈의 화각 방향으로 변경하도록 학습될 수 있고, 협각 학습 모델은 단일 렌즈로 부터의 라이트 방향을 이미지 평면 방향으로 변경하도록 학습될 수 있다. 일 실시예에서, 깊이 레이어 생성부는 단일 메인 렌즈를 통해 처리되는 객체의 입체성을 조절하기 위해 단 일 메인 렌즈 및 복수의 마이크로 렌즈들 간의 거리를 가변시킬 수 있다. 깊이 레이어 생성부는 가상 카메 라 집합의 렌즈들을 소프트웨어적으로 구현함으로써 렌즈 간의 거리를 손쉽게 조절할 수 있다. 특히, 깊이 레이 어 생성부는 객체의 입체성에 따라 단일 메인 렌즈와 복수의 마이크로 렌즈들 간의 거리를 조절할 수 있다. 예를 들어, 메인 렌즈와 복수의 마이크로 렌즈들 간의 거리가 작을수록 마이크로 렌즈에 의해 수집되는 라이트 영역이 작아질 수 있고 공간 정보의 양이 작아짐에 따라 객체의 입체성은 낮아질 수 있다. 일 실시예에서, 깊이 레이어 생성부는 적어도 하나의 객체 중 하나를 배경 객체로 설정하고 배경 객체를 가장 깊은 깊이를 가지는 배경 레이어에 배치할 수 있다. 깊이 레이어 생성부는 객체들 중 어느 하나를 배 경 객체로 설정할 수 있으며, 배경 객체로 설정된 객체는 실제 위치와 상관없이 가장 깊은 깊이에 배치된 배경 레이어에 추가되어 배치될 수 있다. 한편, 깊이 레이어 생성부는 배경 객체를 배경 레이어로 배치하는 과 정에서 배경 객체의 크기를 함께 변경할 수 있다. 또한, 깊이 레이어 생성부는 배경 객체를 배경 레이어로 배치하는 과정에서 배경 레이어의 투명도를 함께 변경할 수 있다. 이미지 가공부는 깊이 레이어를 통해 평면 이미지를 3차원 이미지로 변환하고 적어도 하나의 객체 중 하나 에 대하여 리포커싱(refocus)을 수행하여 3차원 이미지를 가공할 수 있다. 깊이 레이어 생성부에 의해 생 성된 깊이 레이어는 다중 평면 이미지에 해당할 수 있으며, 이미지 가공부는 다중 평면 이미지를 이용하여 3차원 이미지를 생성할 수 있다. 특히, 이미지 가공부는 다중 평면 이미지를 기초로 객체별 깊이 레이어에 대한 와핑(warping)을 통해 다양한 시점에서의 3차원 이미지를 생성할 수 있다. 또한, 이미지 가공부는 3차원 이미지를 생성하는 과정에서 특정 객체에 관한 포커싱(focusing)을 수행할 수 있다. 일 실시예에서, 이미지 가공부는 리포커싱의 과정에서 나머지 객체와의 상대적 거리와 무관하게 배경 레이 어의 깊이를 독립적으로 증가시킬 수 있도록 배경 레이어를 구성할 수 있다. 이를 위해, 이미지 가공부는 배경 레이어에 객체가 포함되어 있는지에 따라 보조 레이어를 생성할 수 있다. 즉, 배경 레이어에 객체가 포함 된 경우 이미지 가공부는 보조 레이어를 추가로 생성할 수 있고, 보조 레이어의 깊이를 독립적으로 증가시 킬 수 있다. 일 실시예에서, 이미지 가공부는 적어도 하나의 객체 중 배경 객체를 제외한 나머지 객체의 깊이 레이어의 배치를 변경하여 3차원 이미지를 재구성할 수 있다. 깊이 레이어는 객체별로 독립적으로 생성된 결과, 깊이 레 이어의 배치 순서에 따라 공간 상에서 객체의 위치가 변경될 수 있고, 결과적으로 3차원 이미지도 대응되어 재 구성될 수 있다. 한편, 이미지 가공부는 객체들을 재배치하는 과정에서 객체의 크기를 변경할 수 있으며, 필요에 따라 소정의 객체를 삭제할 수 있다. 또한, 이미지 가공부는 특정 객체를 복제하여 동일 깊이 레이 어에 추가할 수도 있다. 일 실시예에서, 이미지 가공부는 적어도 하나의 객체 중 배경 객체를 제외한 배경 제외 객체를 선별하여 해당 깊이 레이어 기반의 객체로서 다른 3차원 이미지에 삽입할 수 있다. 이미지 가공부는 객체별 깊이 레 이어들 중 특정 깊이 레이어를 선별하여 3차원 이미지에서 제거할 수 있으며, 필요에 따라 제거된 깊이 레이어 를 다른 3차원 이미지에 삽입할 수도 있다. 즉, 객체 별로 깊이 레이어가 독립적으로 생성된 결과, 이미지 가공 부는 3차원 이미지에서 특정 객체를 제거하거나 추가하는 동작을 효과적으로 수행할 수 있다. 제어부는 라이트 필드 이미지 장치의 전체적인 동작을 제어하고, 이미지 생성부, 깊이 레이어 생성부 및 이미지 가공부 간의 제어 흐름 또는 데이터 흐름을 관리할 수 있다. 도 4는 본 발명에 따른 라이트 필드 이미지 생성 방법을 설명하는 순서도이다. 도 4를 참조하면, 라이트 필드 이미지 장치는 이미지 생성부를 통해 물리적 카메라를 통해 적어도 하 나의 객체를 포함하는 평면 이미지를 생성할 수 있다(단계 S410). 라이트 필드 이미지 장치는 한 대의 카 메라로 3차원 복원하기 위하여 기계학습을 통해 구축된 깊이 추정 모델을 통해 3차원 깊이 정보를 추출할 수 있 다. 또한, 라이트 필드 이미지 장치는 깊이 레이어 생성부를 통해 물리적 카메라 및 적어도 하나의 객체 사이에 가상적으로 배치되고 인공지능 학습 모델로 구현되는 복수의 가상 카메라 집합들을 통해 적어도 하나의 객체 각각에 관한 깊이 레이어를 생성할 수 있다(단계 S430). 즉, 라이트 필드 이미지 장치는 깊이 정보를 기반으로 단안 영상으로부터 RGB 영상과 깊이 영상을 바탕으 로 라이트 필드 영상을 생성할 수 있다. 이때, 가상의 마이크로 렌즈를 통해 입력된 단안 영상으로부터 라이트 필드 영상을 생성함으로써 다양한 시점을 가진 3차원 영상을 제작할 수 있다. 특히, 가상으로 만든 마이크로 렌 즈를 통해 얻은 라이트 필드 영상은 기존의 물리적인 마이크로 렌즈를 활용하여 라이트 필드 영상을 만드는 방 법에 비하여 정확하게 카메라의 회전 및 이동 정보를 추정하기 때문에 보다 정확하게 3차원 정보를 획득할 수 있다. 또한, 라이트 필드 이미지 장치는 이미지 가공부를 통해 깊이 레이어를 통해 평면 이미지를 3차원 이 미지로 변환할 수 있으며(단계 S450), 적어도 하나의 객체 중 하나에 대하여 리포커싱(refocus)을 수행하여 3차 원 이미지를 가공할 수 있다(단계 S470). 라이트 필드 이미지 장치는 획득된 3차원 정보를 기초로 사용자 가 원하는 영역에서 저작할 수 있도록 지원할 수 있다. 예를 들어, 사용자는 3차원 이미지에 그림을 그리더라도 깊이 영역이 다른 영역에만 색칠할 수 있으며, 깊이 정보를 바탕으로 특정 객체를 검출하여 다른 영상에 합성할 수도 있다. 도 5는 본 발명에 따른 다중 평면 이미지(MPI)를 설명하는 도면이다. 도 5를 참조하면, 다중 평면 이미지는 참조 카메라 좌표 프레임에 관한 고정된 깊이(fixed depth)들 각각 에서 깊이 레이어들의 평행한 정면 영상 집합으로 표현될 수 있다. 이때, 각 깊이 레이어 d에서의 영상은 RGB 이미지 Cd와 알파 이미지 αd(투명도 이미지)를 기초로 인코딩(encoding)될 수 있다. 즉, 다중 평면 이미지는 깊이 레이어에 해당하는 RGBA 레이어들((C1,α1), (C2,α2), ..., (CD,αD))의 모음(collection)에 해당할 수 있다. 이때, D는 깊이 레이어들의 개수이다. 다중 평면 이미지는 참여하는 깊이 레이어들의 개수가 많을수록 보다 넓은 범위의 깊이를 표현할 수 있으며, 이에 따라 3차원 이미지에 대한 카메라의 시점(viewpoint) 표현은 더 넓은 범위를 커버할 수 있다. 도 6 및 7은 본 발명에 따른 라이트 필드 이미지를 설명하는 도면이다. 도 6 및 7을 참조하면, 라이트 필드 이미지 장치는 입력된 평면 이미지(large scale image)를 기초로 소프 트웨어적으로 구현된 가상 카메라 집합을 통해 라이트 필드 이미지를 생성할 수 있다. 가상 카메라 집합은 단일 메인 렌즈(Main lens)와 복수의 마이크로 렌즈(Micro lens)들로 구성될 수 있다. 특히, 하드웨어 장치로 구현된 라이트 필드 카메라(light field camera)의 경우, 실제 마이크로 렌즈 배열의 배 치가 어긋나는 경우 3차원 정보를 효과적으로 추출하기 어렵고 메인 렌즈와 마이크로 렌즈 간의 초점 거리를 변 경할 수 없으며, 해상도가 낮고 시야(Field-of-view)가 매우 좁다는 문제점이 존재할 수 있다. 특히, 라이트 필 드 카메라는 매우 고가일 수 있다. 라이트 필드 이미지 장치는 가상 카메라 집합에 관한 소프트웨어적인 구현을 통해 컴퓨팅 가능한 광 시야 라이트 필드 이미지 시스템(computational large field of view light field imaging system)을 구축할 수 있다. 결과적으로, 라이트 필드 이미지 장치는 광시야를 통해 파노라마 영상의 3차원 가시화를 제공할 수 있다. 한편, 라이트 필드 이미지 장치는 가상 카메라 집합을 통해 라이트 필드 이미지를 생성할 수 있으나, 하나의 가상 카메라 집합을 통해 생성 가능한 영역은 입력된 평면 이미지(large scale image)의 특정 영역으로 제한될 수 있다. 이를 해결하기 위해, 라이트 필드 이미지 장치는 서로 다른 영역을 독립적으로 처리하는 복수의 가상 카메라 집합들을 적용하여 독립된 라이트 필드 이미지들을 생성하고 이를 통합하여 평면 이미지 전 체 영역에 대한 광시야 라이트 필드 이미지를 생성할 수 있다. 도 8a 및 8b는 본 발명에 따른 라이트 필드 이미지 생성 프로세스를 설명하는 도면이다. 도 8a 및 8b를 참조하면, 라이트 필드 이미지 장치는 입력된 평면 이미지를 깊이 추정 모델(Depth Estimation Network)에 입력하여 평면 이미지에 대응되는 깊이 맵(Depth Map)을 생성할 수 있고, 평 면 이미지와 깊이 맵을 통합하여 통합 이미지(Integral Image)를 생성할 수 있다. 이때, 깊이 추정 모델을 사전 학습을 통해 구축될 수 있으며, 한 쌍의 인코더(encoder)와 디코더(decoder)를 포함하여 구현될 수 있다. 또한, 라이트 필드 이미지 장치는 통합 이미지를 기초로 가상 카메라 집합을 통해 독립된 영역에 대한 라 이트 필드 이미지들을 생성할 수 있다. 라이트 필드 이미지 장치는 개별 라이트 필드 이미지들 을 통합하여 평면 이미지 전체 영역에 대한 라이트 필드 이미지들을 생성할 수 있다. 도 9는 본 발명에 따른 라이트 필드 이미지 방법을 통해 입력 이미지로부터 3차원 영상을 생성하는 과정을 설명 하는 도면이다. 도 9를 참조하면, 라이트 필드 이미지 장치는 입력 이미지(Input RGB)를 기초로 깊이 이미지(Depth imag e)를 생성할 수 있으며, 해당 이미지들을 기초로 복수의 라이트 필드 이미지들(RGB-D Sub-aperture images)을 생성할 수 있다. 이때, 라이트 필드 이미지는 RGB 이미지와 깊이 이미지를 포함할 수 있다. 라이트 필드 이미지 장치는 각 라이트 필드 이미지를 사전 구축된 MPI 모델(MPI Network)에 입력하여 해당 시야(FOV)에서의 다중 평면 이미지(MPI)를 획득할 수 있다. 라이트 필드 이미지 장치는 다중 평면 이미지 를 기초로 다양한 시점에서의 3차원 이미지를 생성할 수 있다. 이때, 3차원 이미지는 다중 평면 이미지의 각 평 면에서의 깊이 레이어들을 시점을 기준으로 정렬한 결과로서 획득될 수 있다. 라이트 필드 이미지 장치는 단안 영상으로부터 3차원 이미지를 효과적으로 생성하여 제공할 수 있으며, 사 용자는 이를 통해 3차원 공간에서 3차원 이미지를 손쉽게 재구성할 수 있다. 예를 들어, 사용자는 3차원 이미지에서 특정 객체를 선택적으로 제거할 수 있으며, 다른 객체를 3차원 공간 상에 추가하여 기존의 객체들 사이에 배치할 수 있다. 또한, 사용자는 3차원 이미지 상에서 특정 객체의 이미지를 분리할 수 있고, 해당 객체의 이미 지를 독립적으로 저작하거나 또는 해당 객체를 다른 3차원 이미지에 추가할 수도 있다. 결과적으로, 라이트 필 드 이미지 장치는 한 대의 카메라로부터 3차원으로 그림을 그리거나 저작하는데 한계가 있었던 종래의 문 제점을 극복함으로써 사용자가 몰입감을 느끼며 3차원 공간에서 저작할 수 있는 환경을 제공할 수 있다. 상기에서는 본 발명의 바람직한 실시예를 참조하여 설명하였지만, 해당 기술 분야의 숙련된 당업자는 하기의 특 허 청구의 범위에 기재된 본 발명의 사상 및 영역으로부터 벗어나지 않는 범위 내에서 본 발명을 다양하게 수정 및 변경시킬 수 있음을 이해할 수 있을 것이다."}
{"patent_id": "10-2021-0150409", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명에 따른 라이트 필드 이미지 시스템을 설명하는 도면이다. 도 2는 도 1의 라이트 필드 이미지 장치의 시스템 구성을 설명하는 도면이다. 도 3은 도 1의 라이트 필드 이미지 장치의 기능적 구성을 설명하는 도면이다. 도 4는 본 발명에 따른 라이트 필드 이미지 생성 방법을 설명하는 순서도이다. 도 5는 본 발명에 따른 다중 평면 이미지를 설명하는 도면이다. 도 6 및 7은 본 발명에 따른 라이트 필드 이미지를 설명하는 도면이다. 도 8a 및 8b는 본 발명에 따른 라이트 필드 이미지 생성 프로세스를 설명하는 도면이다. 도 9는 본 발명에 따른 라이트 필드 이미지 방법을 통해 입력 이미지로부터 3차원 영상을 생성하는 과정을 설명 하는 도면이다."}
