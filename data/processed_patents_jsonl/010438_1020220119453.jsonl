{"patent_id": "10-2022-0119453", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0040453", "출원번호": "10-2022-0119453", "발명의 명칭": "준 지도 학습에 기반하여 의료 영상 데이터에서 장기를 분할하여 출력하기 위한 시스템 및 방", "출원인": "숭실대학교산학협력단", "발명자": "정민영"}}
{"patent_id": "10-2022-0119453", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "장기를 촬영한 의료영상데이터를 제공받는 입력모듈;구조와 크기가 동일한 제1 및 제2 심층신경망으로 구성되며, 상기 의료영상데이터에 포함된 상기 장기를 상기장기의 종류에 대응하는 클래스 별로 분할하는 V-Net 백본(Backbone);상기 클래스의 라벨(label)된 정답값을 기준으로 상기 제1 및 제2 심층신경망에서 추출된 복셀-레벨 특성(Voxel-level feature)을 샘플링하고, 표현공간(Representation space)에서 동일한 상기 클래스끼리 클러스터링(Clustering)되도록 표현학습(Representation Learning)을 수행하는 제1 학습모듈; 및 상기 동일한 클래스 별로 상기 제1 심층신경망에서 출력된 언라벨(Unlabel)된 임시(pseudo)값의 분포가 상기 라벨된 정답값의 분포를 따라가도록 적대적 학습(Adversarial Learning)을 수행하는 제2 학습모듈을 포함하는,준 지도 학습에 기반하여 의료 영상 데이터에서 장기를 분할하여 출력하기 위한 시스템."}
{"patent_id": "10-2022-0119453", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1 항에 있어서, 상기 제1 학습모듈은,상기 제1 및 제2 심층신경망을 구성하는 다중 은닉층 각각에서 상기 의료영상데이터 중 상기 장기가 차지하는영역인 복셀(Voxel) 및 상기 복셀(Voxel)의 상기 복셀-레벨 특성(Voxel-level feature)들을 추출하는,준 지도 학습에 기반하여 의료 영상 데이터에서 장기를 분할하여 출력하기 위한 시스템."}
{"patent_id": "10-2022-0119453", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2 항에 있어서,상기 제1 학습모듈은,상기 라벨된 정답값을 기준으로 상기 제1 심층신경망을 구성하는 다중 은닉층 각각에서 추출된 상기 복셀-레벨특성들 각각이 해당하는 제1 클래스를 판단하고, 상기 라벨된 정답값을 기준으로 상기 제2 심층신경망을 구성하는 다중 은닉층 각각에서 추출된 상기 복셀-레벨특성들 각각이 해당하는 제2 클래스를 판단하는,준 지도 학습에 기반하여 의료 영상 데이터에서 장기를 분할하여 출력하기 위한 시스템."}
{"patent_id": "10-2022-0119453", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3 항에 있어서,상기 제1 학습모듈은, 상기 제1 및 제2 클래스 중 서로 상기 동일한 클래스에 해당하는 제1 및 제2 클래스를 샘플링하고, 상기 표현공간에서 상기 제1 클래스에 해당하는 상기 복셀-레벨 특성들을 기준으로 상기 제2 클래스에 해당하는 복셀-레벨특성들이 상기 클러스터링되도록 유사 손실값(similarity loss)를 설정하여 상기 표현학습을 수행하는,준 지도 학습에 기반하여 의료 영상 데이터에서 장기를 분할하여 출력하기 위한 시스템."}
{"patent_id": "10-2022-0119453", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제2 항에 있어서,상기 제2 학습모듈은, 공개특허 10-2024-0040453-3-상기 제2 심층신경망을 구성하는 다중 은닉층 각각에서 추출된 상기 복셀-레벨 특성들을 식별하는 분류자를 포함하는,준 지도 학습에 기반하여 의료 영상 데이터에서 장기를 분할하여 출력하기 위한 시스템."}
{"patent_id": "10-2022-0119453", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5 항에 있어서,상기 제2 학습모듈은,상기 분류자에 의해 식별된 상기 복셀-레벨 특성들 각각이 해당하는 상기 제2 클래스를 판단하는, 준 지도 학습에 기반하여 의료 영상 데이터에서 장기를 분할하여 출력하기 위한 시스템."}
{"patent_id": "10-2022-0119453", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6 항에 있어서,상기 제2 학습모듈은, 상기 동일한 클래스에 해당하는 상기 제2 클래스를 샘플링하고, 상기 제2 클래스 중 상기 동일한 클래스 별로상기 언라벨된 임시값의 분포가 상기 라벨된 상기 정답값의 분포를 따라가도록 적대적 손실값(AdversarialLoss)를 설정하고 상기 적대적 학습을 수행하는, 준 지도 학습에 기반하여 의료 영상 데이터에서 장기를 분할하여 출력하기 위한 시스템."}
{"patent_id": "10-2022-0119453", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1 항에 있어서,상기 제1 심층신경망은 교사 네트워크 모델(Teacher Network Model)이고 상기 제2 심층신경망은 학생 네트워크모델(Student Network Model)인,준 지도 학습에 기반하여 의료 영상 데이터에서 장기를 분할하여 출력하기 위한 시스템."}
{"patent_id": "10-2022-0119453", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제7 항에 있어서,상기 제1 심층신경망은,EMA(Exponential Moving Average)방식을 통해 상기 제2 심층신경망의 학습과정에서 획득되는 파라미터의 변화량의 일부를 이용하여 상기 제1 심층신경망의 파라미터를 업데이트하는, 준 지도 학습에 기반하여 의료 영상 데이터에서 장기를 분할하여 출력하기 위한 시스템."}
{"patent_id": "10-2022-0119453", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "입력모듈에 의해 장기를 촬영한 의료영상데이터를 제공받는 단계;V-Net 백본(Backbone)에 의해 구조와 크기가 동일한 제1 및 제2 심층신경망으로 구성되며, 상기 의료영상데이터에 포함된 상기 장기를 상기 장기에 대응하는 타겟 클래스 별로 분할하는 단계;제1 학습모듈에 의해 상기 타겟 클래스의 라벨(label)된 정답값을 기준으로 상기 제1 및 제2 심층신경망에서 추출된 복셀-레벨 특성(Voxel-level feature)을 샘플링하고, 표현공간(Representation space)에서 동일한 클래스끼리 클러스터링(Clustering)되도록 표현학습(Representation Learning)을 수행하는 단계; 및 제2 학습모듈에 의해 상기 동일한 클래스 별로 상기 제1 심층신경망에서 출력된 언라벨(Unlabel)된 임시(pseudo)값의 분포가 상기 라벨된 정답값의 분포를 따라가도록 적대적 학습(Adversarial Learning)을 수행하는단계를 포함하는,준 지도 학습에 기반하여 의료 영상 데이터에 포함된 장기를 분할하여 출력하기 위한 방법.공개특허 10-2024-0040453-4-청구항 11 제10 항의 준 지도 학습에 기반하여 의료 영상 데이터에 포함된 장기를 분할하여 출력하기 위한 방법을 실행시키는 프로그램이 기록된 컴퓨터로 판독가능한 기록매체."}
{"patent_id": "10-2022-0119453", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명인 준 지도 학습에 기반하여 의료 영상 데이터에서 장기를 분할하여 출력하기 위한 시스템은 장기를 촬영 한 의료영상데이터를 제공받는 입력모듈, 구조와 크기가 동일한 제1 및 제2 심층신경망으로 구성되며, 의료영상 데이터에 포함된 장기를 장기의 종류에 대응하는 클래스 별로 분할하는 V-Net 백본(Backbone), 클래스의 라벨 (label)된 정답값을 기준으로 제1 및 제2 심층신경망에서 추출된 복셀-레벨 특성(Voxel-level feature)을 샘플 링하고, 표현공간(Representation space)에서 동일한 클래스끼리 클러스터링(Clustering)되도록 표현학습 (Representation Learning)을 수행하는 제1 학습모듈, 및 동일한 클래스 별로 제1 심층신경망에서 출력된 언라벨 (Unlabel)된 임시(pseudo)값의 분포가 라벨된 정답값의 분포를 따라가도록 적대적 학습(Adversarial Learning) 을 수행하는 제2 학습모듈을 포함한다."}
{"patent_id": "10-2022-0119453", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 준 지도 학습에 기반하여 의료 영상 데이터에서 장기를 분할하여 출력하기 위한 시스템 및 방법에 관 한 것이다."}
{"patent_id": "10-2022-0119453", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "준 지도 학습에 기반한 의료 영상 분할(Semi-supervised Medical image segmentation)이란, 소량의 라벨 (label)된 정답값을 이용하여 의료 영상에 포함된 장기 영역을 종류에 따라 분할하는 기술을 의미한다. 종래에는, 컨볼루션 신경망(CNN, Convolutional Neural Network)을 기본으로 하여 Consistency Regularization, Pseudo Labeling, Adversarial Learning 등 의료 영상에 포함된 장기 영역을 분할하기 위한 다양한 방법이 존재하였다. 한편, 종래 방식들은 CNN의 마지막 레이어(Layer)의 출력값(또는 예측값)과 라벨(label)된 정답값의 차이를 최 소화시켜 단일 장기를 인식하므로, 다중 장기를 분할하는 과정에 한계가 존재하였다. 이에, 의료 영상의 전체적인 문맥과 장기(또는, 클래스) 사이의 특성을 고려하여 다중 장기를 분할하여 출력하 기 위한 기술이 필요한 실정이다."}
{"patent_id": "10-2022-0119453", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명이 해결하고자 하는 기술적 과제는, 준 지도 학습에 기반하여 의료 영상에서 다양한 장기 사이의 특성 또는 관계를 학습하여 다중 장기를 분할하기 위한 인공지능 학습 모델을 생성하기 위함이다. 또한, 본 발명이 해결하고자 하는 기술적 과제는, 상술한 인공지능 학습 모델을 이용하여 의료 영상에서 다중 장기를 장기의 종류(즉, 클래스)에 따라 분할하기 위함이다."}
{"patent_id": "10-2022-0119453", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 한 실시예에 따른 준 지도 학습에 기반하여 의료 영상 데이터에서 장기를 분할하여 출력하기 위한 시 스템은 장기를 촬영한 의료영상데이터를 제공받는 입력모듈, 구조와 크기가 동일한 제1 및 제2 심층신경망으로 구성되며, 의료영상데이터에 포함된 장기를 장기의 종류에 대응하는 클래스 별로 분할하는 V-Net 백본 (Backbone), 클래스의 라벨(label)된 정답값을 기준으로 제1 및 제2 심층신경망에서 추출된 복셀-레벨 특성 (Voxel-level feature)을 샘플링하고, 표현공간(Representation space)에서 동일한 클래스끼리 클러스터링 (Clustering)되도록 표현학습(Representation Learning)을 수행하는 제1 학습모듈 및 동일한 클래스 별로 제1 심층신경망에서 출력된 언라벨(Unlabel)된 임시(pseudo)값의 분포가 라벨된 정답값의 분포를 따라가도록 적대적 학습(Adversarial Learning)을 수행하는 제2 학습모듈을 포함한다. 또한, 본 발명의 한 실시예에 따른 제1 학습모듈은, 제1 및 제2 심층신경망을 구성하는 다중 은닉층 각각에서 의료영상데이터 중 장기가 차지하는 영역인 복셀(Voxel) 및 복셀(Voxel)의 복셀-레벨 특성(Voxel-level feature)들을 추출한다. 또한, 본 발명의 한 실시예에 따른 제1 학습모듈은, 라벨된 정답값을 기준으로 제1 심층신경망을 구성하는 다중 은닉층 각각에서 추출된 복셀-레벨 특성들 각각이 해당하는 제1 클래스를 판단하고, 라벨된 정답값을 기준으로 제2 심층신경망을 구성하는 다중 은닉층 각각에서 추출된 복셀-레벨 특성들 각각이 해당하는 제2 클래스를 판단 한다. 또한, 본 발명의 한 실시예에 따른 제1 학습모듈은, 제1 및 제2 클래스 중 서로 동일한 클래스에 해당하는 제1 및 제2 클래스를 샘플링하고, 표현공간에서 제1 클래스에 해당하는 복셀-레벨 특성들을 기준으로 제2 클래스에해당하는 복셀-레벨 특성들이 클러스터링되도록 유사 손실값(similarity loss)를 설정하여 표현학습을 수행한다. 또한, 본 발명의 한 실시예에 따른 제2 학습모듈은, 제2 심층신경망을 구성하는 다중 은닉층 각각에서 추출된 복셀-레벨 특성들을 식별하는 분류자를 포함한다. 또한, 본 발명의 한 실시예에 따른 제2 학습모듈은, 분류자에 의해 식별된 복셀-레벨 특성들 각각이 해당하는 제2 클래스를 판단한다. 또한, 본 발명의 한 실시예에 따른 제2 학습모듈은, 동일한 클래스에 해당하는 제2 클래스를 샘플링하고, 제2 클래스 중 동일한 클래스 별로 언라벨된 임시값의 분포가 라벨된 정답값의 분포를 따라가도록 적대적 손실값 (Adversarial Loss)를 설정하고 적대적 학습을 수행한다. 또한, 본 발명의 한 실시예에 따른 제1 심층신경망은 교사 네트워크 모델(Teacher Network Model)이고 제2 심층 신경망은 학생 네트워크 모델(Student Network Model)이다. 또한, 본 발명의 한 실시예에 따른 제1 심층신경망은, EMA(Exponential Moving Average)방식을 통해 제2 심층 신경망의 학습과정에서 획득되는 파라미터의 변화량의 일부를 이용하여 제1 심층신경망의 파라미터를 업데이트 한다. 또한, 본 발명의 한 실시예에 따른 준 지도 학습에 기반하여 의료 영상 데이터에 포함된 장기를 분할하여 출력 하기 위한 방법은 입력모듈에 의해 장기를 촬영한 의료영상데이터를 제공받는 단계, V-Net 백본(Backbone)에 의 해 구조와 크기가 동일한 제1 및 제2 심층신경망으로 구성되며, 의료영상데이터를 이용하여 장기에 대응하는 타 겟 클래스 별로 분할하는 단계, 제1 학습모듈에 의해 타겟 클래스의 라벨(label)된 정답값을 기준으로 제1 및 제2 심층신경망에서 추출된 복셀-레벨 특성(Voxel-level feature)을 샘플링하고, 표현공간(Representation space)에서 동일한 클래스끼리 클러스터링(Clustering)되도록 표현학습(Representation Learning)을 수행하는 단계 및 제2 학습모듈에 의해 동일한 클래스 별로 제1 심층신경망에서 출력된 언라벨(Unlabel)된 임시(pseudo) 값의 분포가 라벨된 정답값의 분포를 따라가도록 적대적 학습(Adversarial Learning)을 수행하는 단계를 포함한 다. 또한, 본 발명의 한 실시예에 따른 준 지도 학습에 기반하여 의료 영상 데이터에 포함된 장기를 분할하여 출력 하기 위한 방법을 실행시키는 프로그램이 기록된 컴퓨터로 판독가능한 기록매체를 포함한다."}
{"patent_id": "10-2022-0119453", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명에 따른 준 지도 학습에 기반하여 의료 영상 데이터에서 장기를 분할하여 출력하기 위한 시스템 및 방법 은, 준 지도 학습에 기반하여 다양한 장기 사이의 특성 또는 관계를 학습하여 다중 장기를 분할하기 위한 인공 지능 학습 모델을 생성할 수 있다. 또한, 본 발명에 따른 준 지도 학습에 기반하여 의료 영상 데이터에서 장기를 분할하여 출력하기 위한 시스템 및 방법은, 상술한 인공지능 학습 모델을 이용하여 다중 장기가 촬영된 의료 영상 데이터에서 장기의 종류(즉, 클래스)에 따라 명확하게 분할할 수 있다."}
{"patent_id": "10-2022-0119453", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 첨부한 도면을 참고로 하여 본 발명의 여러 실시 예들에 대하여 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자가 용이하게 실시할 수 있도록 상세히 설명한다. 본 발명은 여러 가지 상이한 형태로 구현될 수 있으며 여기에서 설명하는 실시 예들에 한정되지 않는다. 본 발명을 명확하게 설명하기 위해서 설명과 관계없는 부분은 생략하였으며, 명세서 전체를 통하여 동일 또는 유사한 구성요소에 대해서는 동일한 참조 부호를 붙이도록 한다. 따라서 앞서 설명한 참조 부호는 다른 도면에 서도 사용할 수 있다. 또한, 도면에서 나타난 각 구성의 크기 및 두께는 설명의 편의를 위해 임의로 나타내었으므로, 본 발명이 반드 시 도시된 바에 한정되지 않는다. 도면에서 여러 층 및 영역을 명확하게 표현하기 위하여 두께를 과장되게 나 타낼 수 있다. 또한, 설명에서 \"동일하다\"라고 표현한 것은, \"실질적으로 동일하다\"는 의미일 수 있다. 즉, 통상의 지식을 가 진 자가 동일하다고 납득할 수 있을 정도의 동일함일 수 있다. 그 외의 표현들도 \"실질적으로\"가 생략된 표현들 일 수 있다. 또한, 설명에서 어떤 부분이 어떤 구성요소를 '포함'한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다른 구성요소를 제외하는 것이 아니라 다른 구성요소를 더 포함할 수 있는 것을 의미한다. 본 명세서에서 사용되는 '~부'는 적어도 하나의 기능이나 동작을 처리하는 단위로서, 예를 들어 소프트웨어, FPGA 또는 하드웨어 구성요 소를 의미할 수 있다. '~부'에서 제공하는 기능은 복수의 구성요소에 의해 분리되어 수행되거나, 다른 추가적인 구성요소와 통합될 수도 있다. 본 명세서의 '~부'는 반드시 소프트웨어 또는 하드웨어에 한정되지 않으며, 어드 레싱할 수 있는 저장 매체에 있도록 구성될 수도 있고, 하나 또는 그 이상의 프로세서들을 재생시키도록 구성될 수도 있다. 이하에서는 도면을 참조하여 본 발명의 실시예에 대해서 구체적으로 설명하기로 한다. 도 1은 본 발명의 한 실시예에 따른 준 지도 학습에 기반하여 의료 영상 데이터에서 장기를 분할하여 출력하기 위한 시스템의 구성요소에 관한 도면이다. 본 발명의 한 실시예에 따른 준 지도 학습에 기반하여 의료 영상 데이터에서 장기를 분할하여 출력하기 위한 시 스템은 입력모듈, V-Net 백본(Backbone, 11), 제1 학습모듈, 제2 학습모듈, 및 출력모듈을 포함할 수 있다. 단, 본 발명의 한 실시예에 따른 준 지도 학습에 기반하여 의료 영상 데이터에서 장기를 분할하여 출력하기 위 한 시스템을 구동하기 위해 도 1에 도시된 구성요소 보다 더 적은 구성요소 또는 더 많은 구성요소를 포함할 수 있다. 입력모듈은 장기를 촬영한 의료영상데이터를 제공받을 수 있다. 예를 들어, 입력모듈이 제공받는 의료영상데이터에는 간, 신장, 대장 등 다양한 장기(이하, 다중 장기라 명 명함)에 대한 영상데이터가 포함될 수 있다. V-Net 백본(Backbone, 11)은 구조와 크기가 서로 동일한 제1 심층신경망(또는, 교사 네트워크 모델(Teacher Network Model))과 제2 심층신경망(또는, 학생 네트워크 모델(Student Network Model))로 구성될 수 있다. V-Net 백본(11, Backbone)을 구성하는 제1 심층신경망과 제2 심층신경망은 Mean Teacher Network 방식과 동일 또는 유사한 방식으로 구현될 수 있다. 한편, V-Net 백본(11, Backbone)을 구성하는 제1 심층신경망과 제2 심층신경망은 입력층, 다중 은닉층, 및 출력 층으로 구성될 수 있다. V-Net 백본(11, Backbone)을 구성하는 제1 심층신경망과 제2 심층신경망의 입력층은 입력모듈로부터 의료영 상데이터를 제공받을 수 있으며, 다중 은닉층 및 출력층을 통해 다중 장기가 분할된 출력값(Ypseudo, Y)이 출력 될 수 있다. 예를 들어, V-Net 백본(11, Backbone)을 구성하는 제1 심층신경망의 출력층은 다중 장기 중 장기의 종류에 대응 하는 클래스 별로 분할된 출력값(이하, 언라벨(Unlabel)된 임시(pseudo)값이라 명명함, Ypseudo)을 출력할 수 있다. 또한, V-Net 백본(11, Backbone)을 구성하는 제2 심층신경망의 출력층은 다중 장기 중 장기의 종류에 대응하는 클래스 별로 분할된 출력값(Y)을 출력할 수 있다. V-Net 백본(11, Backbone)을 구성하는 제1 심층신경망은 EMA(Exponential Moving Average)방식을 통해 제2 심 층신경망의 학습과정에서 획득되는 파라미터(또는, 가중치)의 변화량의 일부를 이용하여 파라미터(또는, 가중치)를 업데이트 할 수 있다. V-Net 백본(11, Backbone)을 구성하는 제2 심층신경망은 출력값(Y)과 라벨(label)된 정답값(Ygt) 사이의 Dice Loss(Ldice), 언라벨(Unlabel)된 임시(pseudo)값(Ypseudo)과 출력값(Y) 사이의 Consistency Loss(Lc), 제1 학 습모듈에서 복셀 간 표현 학습(Voxel-wise Representation Learning) 과정 중 설정되는 유사 손실값 (Similarity Loss, Lfeature), 및 제2 학습모듈에서 복셀 간 적대적 학습(Voxel-wise Adversarial Learning) 과정 중 설정되는 적대적 손실값(Adversarial Loss, Ladv)을 이용하여 학습을 수행할 수 있다. 제1 학습모듈은 특성 추출층(Voxel-wise Feature Layer)을 통해 V-Net 백본(11, Backbone)을 구성하는 제1 심층신경망과 제2 심층신경망의 다중 은닉층 각각에서 의료영상데이터 중 장기가 차지하는 영역인 복셀(Voxel) 및 복셀-레벨 특성(Voxel-level feature)들을 추출(Voxel-wise Feature Layer)할 수 있다. 제1 학습모듈은 라벨된 정답값(Ygt)을 기준으로 제1 심층신경망을 구성하는 다중 은닉층 각각에서 추출된 복셀-레벨 특성(Voxel-level feature)들 각각이 대응하는 클래스(이하, 제1 클래스라 명명함)를 추출할 수 있다. 제1 학습모듈은 라벨된 정답값(Ygt)을 기준으로 제2 심층신경망을 구성하는 다중 은닉층 각각에서 추출된 복셀-레벨 특성(Voxel-level feature)들 각각이 해당하는 클래스(이하, 제2 클래스라 명명함)를 추출할 수 있다. 제1 학습모듈은 제1 및 제2 심층신경망에서 추출된 복셀-레벨 특성(Voxel-level feature)들 중 동일한 클래 스에 해당하는 복셀-레벨 특성(Voxel-level feature)들을 샘플링(Sampling)하고, 표현공간(Representation Space)에서 제1 클래스를 기준으로 제2 클래스가 클러스터링(Clustering)되도록 복셀 간 표현학습(Voxel-wise Representation Learning)을 수행할 수 있다. 제2 학습모듈은 V-Net 백본(11, Backbone)을 구성하는 제2 심층신경망의 다중 은닉층 각각에서 의료영상데 이터 중 상기 장기가 차지하는 영역인 복셀(Voxel)을 추출하고 복셀-레벨 특성(Voxel-level feature)들을 분류 하는 분류자(Voxel-wise feature Discriminator)를 포함할 수 있다. 제2 학습모듈은 분류자(Voxel-wise feature Discriminator)에 의해 분류된 복셀-레벨 특성(Voxel-level feature)들 각각이 해당하는 제2 클래스를 추출할 수 있다. 제2 학습모듈은 복셀-레벨 특성(Voxel-level feature)들 중 동일한 클래스에 해당하는 복셀-레벨 특성 (Voxel-level feature)들을 샘플링하고, 동일한 클래스 별로 제1 심층신경망에서 출력된 언라벨된 임시값 (Ypseudo)의 분포가 라벨된 정답값(Ygt)의 분포를 따라가도록 적대적 학습(Adversarial Learning)을 수행할 수 있다. 출력모듈은 V-Net 백본(11, Backbone)을 구성하는 제1 심층신경망의 학습과정에서 다중 장기가 장기의 종류 에 대응하는 클래스 별로 분할된 언라벨(Unlabel)된 임시(pseudo)값(Ypseudo)을 출력할 수 있다. 출력모듈은 V-Net 백본(11, Backbone)을 구성하는 제2 심층신경망의 학습과정에서 다중 장기가 장기의 종류 에 대응하는 클래스 별로 분할된 출력값(Y)을 출력할 수 있다. 또한, 출력모듈은 학습이 완료된 V-Net 백본(11, Backbone)을 구성하는 제1 심층신경망에서 다중 장기가 장 기의 종류에 대응하는 클래스 별로 분할된 최종 결과값을 출력할 수 있다. 도 2a는 본 발명의 한 실시예에 따른 제1 학습모듈에서의 복셀 간 표현학습에 관한 도면이다. 도 2b는 본 발명 의 한 실시예에 따른 복셀 간 표현학습 방법 중 하나인 BYOL(Bootstrap your own latent-a new approach to self-superviced learning)에 관한 도면이다. 도 1 및 도 2a를 함께 참고하면, 제1 학습모듈은 V-Net 백본(11, Backbone)을 구성하는 제1 심층신경망(교 사 네트워크 모델)의 다중 은닉층 각각에서 복셀(Voxel) 및 상기 복셀의 복셀-레벨 특성(Voxel-level feature) 들을 추출할 수 있다. 또한, 제1 학습모듈은 V-Net 백본(11, Backbone)을 구성하는 제2 심층신경망(학생 네트워크 모델)의 다중 은닉층 각각에서 복셀(Voxel) 및 상기 복셀의 복셀-레벨 특성(Voxel-level feature)들을 추출할 수 있다. 구체적으로, 제1 학습모듈은 제1 및 제2 심층 신경망의 다중 은닉층 각각에서 추출된 복셀(Voxel)의 크기를 일정하게 맞춘 후(Conv) 융합(Unsample + Conv)하여 복셀-레벨 특성(Voxel-level feature)들을 추출할 수 있다. 제1 학습모듈은 라벨된 정답값(Ygt)을 기준으로 제1 심층 신경망(교사 네트워크 모델)의 다중 은닉층 각각 에서 추출된 복셀-레벨 특성(Voxel-level feature)들 각각이 해당하는 제1 클래스를 판단할 수 있다. 제1 학습모듈은 라벨된 정답값(Ygt)을 기준으로 제2 심층 신경망(학생 네트워크 모델)의 다중 은닉층 각각 에서 추출된 복셀-레벨 특성(Voxel-level feature)들 각각이 해당하는 제2 클래스를 판단할 수 있다. 또한, 제1 학습모듈은 제1 및 제2 심층 신경망의 다중 은닉층 각각에서 추출된 복셀-레벨 특성(Voxel-level feature)들 각각이 해당하는 제1 및 제2 클래스 중 서로 동일한 클래스에 해당하는 제1 및 제2 클래스를 샘플링 (Class-specific Feature Selection)할 수 있다. 제1 학습모듈은 표현공간에서 제1 클래스에 해당하는 복셀-레벨 특성(Voxel-level feature)들을 기준으로 제2 클래스에 해당하는 복셀-레벨 특성(Voxel-level feature)들이 클러스터링(Clustering)되도록 유사 손실값 (Similarity Loss, Lfeature)를 설정할 수 있다. 즉, 제1 학습모듈은 제1 클래스에 해당하는 복셀-레벨 특성(Voxel-level feature)들과 제2 클래스에 해당하 는 복셀-레벨 특성(Voxel-level feature)들 중 동일한 클래스끼리 서로 클러스터링(Clustering)할 수 있다. 도 2b를 참고하면, 도 2b의 Online network는 도 2a의 제2 심층 신경망을 의미하고, 도 2b의 Target network는 도 2a의 제1 심층신경망을 의미한다. 도 1, 도 2a 및 도 2b를 참고하면, 제1 학습모듈은 제2 심층신경망(학생 네트워크 모델)의 예측 계층 (Prediction Layer)에서 출력된 값( )이 제1 심층신경망(교사 네트워크 모델)의 투영 계층(Projection Layer)에서 출력된 값( )과 동일하도록 유사 손실값(Similarity Loss, Lfeature, )을 설 정할 수 있다. 한편, 제1 학습모듈은 EMA(Exponential Moving Average)방식을 통해 제2 심층신경망(학생 네트워크 모델) 의 학습과정에서 획득되는 파라미터(또는, 가중치)의 변화량의 일부를 이용하여 제1 심층신경망(교사 네트워크 모델)의 파라미터(또는, 가중치)를 업데이트 할 수 있다. 즉, 제1 심층신경망(교사 네트워크 모델)의 파라미터의 업데이터는 EMA를 기반으로, 제2 심층신경망(학생 네트 워크 모델)의 파라미터의 변화량의 일부만을 이용하여 업데이트된다. 제1 심층신경망(교사 네트워크 모델)이 제 2 심층신경망(학생 네트워크 모델)보다 안정적이고 견고하게 업데이터되어 제2 심층신경망(학생 네트워크 모 델)보다 더 정확할 수 있다. 또한, 제1 심층신경망(교사 네트워크 모델)의 출력값(또는, 예측값)을 정답값처럼 다루어 제2 심층신경망(학생 네트워크 모델)의 출력값(또는, 예측값)과 상기 유사 손실값(Lfeature)을 설정하여 제2 심층신경망(학생 네트워크 모델)을 학습시킬 수 있다. 상술한 바와 같이, 제1 학습모듈은 제1 및 제2 심층 신경망을 구성하는 다중 은닉층 각각에서 추출된 복셀- 레벨 특성(Voxel-level feature)들이 표현공간 상에서 같은 클래스끼리 서로 가까워질 수 있도록 또는 클러스터 링될 수 있도록 제1 및 제2 심층 신경망의 표현학습을 수행할 수 있다. 도 3은 본 발명의 한 실시예에 따른 제2 학습모듈에서의 복셀 간 적대적 학습에 관한 도면이다. 도 1 및 도 3을 함께 참고하면, 제2 학습모듈은 V-Net 백본(11, Backbone)을 구성하는 제2 심층신경망의 다 중 은닉층 각각에서 복셀(Voxel)을 추출하고 복셀-레벨 특성(Voxel-level feature)들을 식별(Conv + Unsample + Conv)하는 분류자(Voxel-wise feature Discriminator)를 포함할 수 있다. 제2 학습모듈은 분류자에 의해 식별된 복셀-레벨 특성(Voxel-level feature)들 각각이 해당하는 제2 클래스 를 추출할 수 있다. 제2 학습모듈은 분류자에 의해 식별된 복셀-레벨 특성(Voxel-level feature)들을 2개의 다중 퍼셉트론(MLP, Multi-Layer Perceptron)과 예측 계층(Prediction Layer)를 통과시켜, 클래스 별로 복셀-레벨 특성(Voxel- level feature)들이 라벨된 정답값(Ygt)에서 온 것(real)인지 언라벨된 임시값(Ypseudo)에서 온 것(fake)인지 분류자(Discriminator)가 구분하지 못하도록 적대적 손실값(Adversarial Loss, Ladv)을 설정할 수 있다. 이때, 예측 계층(Prediction Layer)의 개수는 클래스의 개수와 동일하게 설정되어 각 클래스 별로 real/fake 구 분을 할 수 있다. 상술한 과정을 이용하여 제2 학습모듈은 제2 클래스 중 동일한 클래스에 해당하는 복셀-레벨 특성(Voxel- level feature)들을 샘플링하고, 동일한 클래스 별로 언라벨된 임시값(Ypseudo)의 분포가 라벨된 정답값(Ygt)의 분포를 따라가도록 제1 및 제2 심층 신경망의 복셀 간 적대적 학습(Voxel-wise Adversarial Learning)을 수행 할 수 있다. 도 4는 V-Net 백본 만을 이용하여 획득한 클래스에 따른 복셀-레벨 특성(Voxel-level feature)들의 분포와 본 발명에 따라 획득한 클래스에 따른 복셀-레벨 특성(Voxel-level feature)들의 분포에 관한 도면이다. 도 4(a)는 장기를 촬영한 의료영상데이터를 이용하여 기본 네트워크인 V-Net 백본 만을 이용하여 획득한 클래스 에 따른 복셀-레벨 특성(Voxel-level feature)들의 분포를 나타낸다. 도 4(b)는 본 발명을 이용하여 획득한 클 래스에 따른 복셀-레벨 특성(Voxel-level feature)들의 분포를 나타낸다. 도 4(a) 및 도 4(b)의 각 포인트의 색상은 복셀-레벨 특성(Voxel-level feature)들의 클래스 별로 서로 다르게 표시된다. 도 4(b)를 참고하면, 도 4(a)에 비해 클래스 별로 구조화되어 있음을 알 수 있다. 예를 들어, 도 4(b)를 참고하면 노란색, 파란색, 빨간색, 갈색, 핑크색 등은 서로 같은 색상에 해당하는 서로 같은 클래스끼리 모여있는 반면, 도 4(a)를 참고하면 도 4(b)에 비해 서로 같은 색상끼리 모여있지 않고 분산되 어 있는 것을 확인할 수 있다. 즉, 본 발명을 이용하는 경우 기본 네트워크인 V-Net 백본 만을 이용하는 경우에 비해 의료 영상 데이터에서 다 중 장기를 클래스 별로 더욱더 구조화할 수 있다. 도 5a는 V-Net 백본과 도 3의 복셀 간 적대적 학습 만을 함께 사용하여 획득한 라벨된 정답값과 언라벨된 임시 값의 분포를 나타낸 도면이다. 도 5a를 참고하면, 복셀 간 적대적 학습의 반복횟수(Iteration)가 증가할수록 제1 심층신경망에서 출력된 언라 벨된 임시값(Ypseudo)의 분포는 라벨된 정답값(Ygt)의 분포를 따라감을 알 수 있다. 예를 들어, 복셀 간 적대적 학습의 반복횟수(Iteration)가 500번(0.5k)인 경우는 100번(0.1k)인 경우에 비해 빨 간색, 노란색, 파란색에 해당하는 언라벨된 임시값(Ypseudo)의 분포가 라벨된 정답값(Ygt)의 분포와 더 유사함 을 알 수 있다.또한, 복셀 간 적대적 학습의 반복횟수가 1000번(1k)인 경우 500번(0.5k)인 경우에 비해 빨간색, 노란색, 파란 색, 갈색에 해당하는 언라벨된 임시값(Ypseudo)의 분포가 라벨된 정답값(Ygt)의 분포와 더 유사함을 알 수 있다. 즉, 복셀 간 적대적 학습의 반복횟수가 증가할수록 언라벨된 임시값(Ypseudo)의 분포가 라벨된 정답값(Ygt)의 분포를 따라감을 알 수 있다. 도 5b는 V-Net 백본과 도 2의 복셀 간 표현학습 만을 함께 사용하여 획득한 라벨된 정답값과 언라벨된 임시값의 분포를 나타낸 도면이다. 도 5b를 참고하면, 복셀 간 표현학습의 반복횟수(Iteration)가 증가할수록 언라벨된 임시값(Ypseudo)의 분포는 라벨된 정답값(Ygt)의 분포와 유사하게 클래스 별로 구조화(또는, 분할)됨을 알 수 있다. 예를 들어, 복셀 간 표현학습의 반복횟수(Iteration)가 100번(0.1k), 500번(0.5k), 1000번(1k)으로 증가할수록 언라벨된 임시값(Ypseudo)의 분포에서 노란색, 빨간색, 파란색, 갈색은 라벨된 정답값(Ygt)에서 노란색, 빨간색, 파란색, 갈색의 분포구조와 같이 클래스 별로 같은 색상끼리 모여 있는 것을 알 수 있다. 즉, 복셀 간 표현학습의 반복횟수(Iteration)가 증가할수록 클래스 별로 언라벨된 임시값(Ypseudo)의 분포구조 는 클래스 별로 라벨된 정답값(Ygt)의 분포구조와 유사해짐을 알 수 있다. 도 5c는 본 발명의 한 실시예에 따른 V-Net 백본과 도 2a의 복셀 간 표현학습 및 도 3의 복셀 간 적대적 학습을 함께 사용하여 획득한 라벨된 정답값과 언라벨된 임시값의 분포를 나타낸 도면이다. 도 5c를 참고하면, 본 발명의 복셀 간 표현학습과 복셀 간 적대적 학습을 함께 사용하는 경우 반복횟수 (Iteration)가 증가할수록 도 5a 및 도 5b에 비해 언라벨된 임시값(Ypseudo)의 분포는 클래스 별로 구조화될 수 있으며, 언라벨된 임시값(Ypseudo)의 분포가 라벨된 정답값(Ygt)의 분포를 효과적으로 따라감을 알 수 있다. 도 6은 본 발명의 한 실시예에 따른 V-Net 백본과 도 2a의 복셀 간 표현학습 및 도 3의 복셀 간 적대적 학습을 함께 사용하여 획득한 다중 장기 분할에 관한 결과이다. 도 6의 표를 참고하면, 본 발명의 준 지도 학습에 기반하여 의료 영상 데이터에서 장기를 분할하여 출력하는 경 우(OURS)에는 Dice%(Dice similarity coefficient)는 71.28이고, JC%(Jaccard similarity coefficient)는 79.38, HD(voxel)은 4.32이고, ASSD(voxel)은 1.24값으로서 기존의 다른 방법(V-Net, UA-MT, SASSNET, DTC, MC-Net)에 비해 높은 정확도를 가짐을 정량적인 지표로 알 수 있다. 또한, 도 6의 그림을 참고하면, 본 발명의 준 지도 학습에 기반하여 의료 영상 데이터에서 장기를 분할하여 출 력하는 경우(OURS)에는 기존의 다른 방법(V-Net, UA-MT, SASSNET, DTC, MC-Net)에 비해 장기의 종류(또는, 클 래스)에 따라서 다중장기를 명확하게 분할하여 정성적으로도 성능이 뛰어남을 알 수 있다. 도 7은 본 발명의 한 실시예에 따른 본 발명의 한 실시예에 따른 준 지도 학습에 기반하여 의료 영상 데이터에 서 장기를 분할하여 출력하기 위한 방법에 관한 흐름도이다. 단계(S10)에서 장기를 촬영한 의료영상데이터를 제공받을 수 있다. 구체적으로, 입력모듈은 장기를 촬영한 의료영상데이터를 제공받을 수 있다. 단계(S11)에서 라벨된 정답값을 기준으로 복셀-레벨 특성을 샘플링하고, 동일 클래스끼리 클러스터링되도록 표 현학습을 수행할 수 있다. 구체적으로, 제1 학습모듈은 라벨된 정답값(Ygt)을 기준으로 제1 심층신경망을 구성하는 다중 은닉층 각각 에서 추출된 복셀-레벨 특성(Voxel-level feature)들 각각이 대응하는 제1 클래스를 추출할 수 있다. 제1 학습모듈은 라벨된 정답값(Ygt)을 기준으로 제2 심층신경망을 구성하는 다중 은닉층 각각에서 추출된 복셀-레벨 특성(Voxel-level feature)들 각각이 대응하는 제2 클래스를 추출할 수 있다.제1 학습모듈은 제1 및 제2 심층 신경망의 다중 은닉층 각각에서 추출된 복셀-레벨 특성(Voxel-level feature)들 각각이 해당하는 제1 및 제2 클래스 중 서로 동일한 클래스에 해당하는 제1 및 제2 클래스를 샘플링 (Class-specific Feature Selection)할 수 있다. 제1 학습모듈은 제1 클래스에 해당하는 복셀-레벨 특성(Voxel-level feature)들과 제2 클래스에 해당하는 복셀-레벨 특성(Voxel-level feature)들 중 동일한 클래스끼리 서로 클러스터링(Clustering)하여 표현학습을 수 행할 수 있다 단계(S12)에서 동일 클래스 별로 언라벨된 임시값의 분포가 라벨된 정답값의 분포를 따라가도록 적대적학습을 수행할 수 있다. 구체적으로, 제2 학습모듈은 V-Net 백본(11, Backbone)을 구성하는 제2 심층신경망의 다중 은닉층 각각에서 의료영상데이터 중 상기 장기가 차지하는 영역인 복셀(Voxel)을 추출하고 복셀-레벨 특성(Voxel-level featur e)들을 분류하는 분류자(Voxel-wise feature Discriminator)를 포함할 수 있다. 제2 학습모듈은 분류자에 의해 식별된 복셀-레벨 특성(Voxel-level feature)들 각각이 해당하는 제2 클래스 를 추출할 수 있다. 제2 학습모듈은 제2 클래스 중 동일한 클래스에 해당하는 복셀-레벨 특성(Voxel-level feature)들을 샘플링 하고, 동일한 클래스 별로 언라벨된 임시값(Ypseudo)의 분포가 라벨된 정답값(Ygt)의 분포를 따라가도록 제1 및 제2 심층 신경망의 복셀 간 적대적 학습(Voxel-wise Adversarial Learning)을 수행할 수 있다. 단계(S13)에서 의료영상데이터를 이용하여 장기의 종류에 대응하는 클래스 별로 분할할 수 있다. 구체적으로, 출력모듈은 학습이 완료된 V-Net 백본(11, Backbone)을 구성하는 제1 심층신경망에서 다중 장 기가 장기의 종류에 대응하는 클래스 별로 분할된 최종 결과값을 출력할 수 있다. 지금까지 참조한 도면과 기재된 발명의 상세한 설명은 단지 본 발명의 예시적인 것으로서, 이는 단지 본 발명을 설명하기 위한 목적에서 사용된 것이지 의미 한정이나 특허청구범위에 기재된 본 발명의 범위를 제한하기 위하 여 사용된 것은 아니다. 그러므로 본 기술 분야의 통상의 지식을 가진 자라면 이로부터 다양한 변형 및 균등한 타 실시 예가 가능하다는 점을 이해할 것이다. 따라서, 본 발명의 진정한 기술적 보호 범위는 첨부된 특허청구 범위의 기술적 사상에 의해 정해져야 할 것이다. 이상에서 설명된 실시예들은 하드웨어 구성요소, 소프트웨어 구성요소, 및/또는 하드웨어 구성요소 및 소프트웨 어 구성요소의 조합으로 구현될 수 있다. 예를 들어, 실시예들에서 설명된 장치, 방법 및 구성요소는, 예를 들 어, 프로세서, 콘트롤러, ALU(Arithmetic Logic Unit), 디지털 신호 프로세서(Digital Signal Processor), 마 이크로컴퓨터, FPGA(Field Programmable Gate Array), PLU(Programmable Logic Unit), 마이크로프로세서, 또는 명령(instruction)을 실행하고 응답할 수 있는 다른 어떠한 장치와 같이, 하나 이상의 범용 컴퓨터 또는 특수 목적 컴퓨터를 이용하여 구현될 수 있다. 처리 장치는 운영 체제 및 상기 운영 체제 상에서 수행되는 하나 이상의 소프트웨어 애플리케이션을 수행할 수 있다. 또한, 처리 장치는 소프트웨어의 실행에 응답하여, 데이터를 접근, 저장, 조작, 처리 및 생성할 수도 있 다. 이해의 편의를 위하여, 처리 장치는 하나가 사용되는 것으로 설명된 경우도 있지만, 해당 기술 분야에서 통 상의 지식을 가진 자는 처리 장치가 복수 개의 처리 요소(Processing Element) 및/또는 복수 유형의 처리요소를 포함할 수 있음을 이해할 것이다. 예를 들어, 처리 장치는 복수 개의 프로세서 또는 하나의 프로세서 및 하나의 콘트롤러를 포함할 수 있다. 또한, 병렬 프로세서(Parallel Processor) 와 같은, 다른 처리 구성(Processing configuration)도 가능하다. 소프트웨어는 컴퓨터 프로그램(Computer Program), 코드(code), 명령(instruction), 또는 이들 중 하나 이상의 조합을 포함할 수 있으며, 원하는 대로 동작하도록 처리 장치를 구성하거나 독립적으로 또는 결합적으로 (collectively) 처리 장치를 명령할 수 있다. 소프트웨어 및/또는 데이터는, 처리 장치에 의하여 해석되거나 처리 장치에 명령 또는 데이터를 제공하기 위하 여, 어떤 유형의 기계, 구성요소(component), 물리적 장치, 가상 장치(virtual equipment), 컴퓨터 저장 매체 또는 장치에 구체화(embody) 될 수 있다. 소프트웨어는 네트워크로 연결된 컴퓨터 시스템 상에 분산되어서, 분 산된 방법으로 저장되거나 실행될 수도 있다. 소프트웨어 및 데이터는 하나 이상의 컴퓨터 판독 가능 기록 매체 에 저장될 수 있다.실시예에 따른 방법은 다양한 컴퓨터 수단을 통하여 수행될 수 있는 프로그램 명령 형태로 구현되어 컴퓨터 판 독 가능 매체에 기록될 수 있다. 컴퓨터 판독 가능 매체는 프로그램 명령, 데이터 파일, 데이터 구조 등을 단독 으로 또는 조합하여 포함할 수 있다. 매체에 기록되는 프로그램 명령은 실시예를 위하여 특별히 설계되고 구성 된 것들이거나 컴퓨터 소프트웨어 당업자에게 공지되어 사용 가능한 것일 수도 있다. 컴퓨터 판독 가능 기록 매체의 예에는 하드 디스크, 플로피 디스크 및 자기 테이프와 같은 자기 매체(magnetic media), CDROM, DVD와 같은 광기록 매체(optical media) 및 롬(ROM), 램(RAM), 플래시 메모리 등과 같은 프로 그램 명령을 저장하고 수행하도록 특별히 구성된 하드웨어 장치가 포함된다. 프로그램 명령의 예에는 컴파일러 에 의해 만들어지는 것과 같은 기계어 코드뿐만 아니라 인터프리터 등을 사용해서 컴퓨터에 의해서 실행될 수 있는 고급 언어 코드를 포함한다. 상기된 하드웨어 장치는 실시예의 동작을 수행하기 위해 하나 이상의 소프트 웨어 모듈로서 작동하도록 구성될 수 있으며, 그 역도 마찬가지이다."}
{"patent_id": "10-2022-0119453", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "이상과 같이 실시예들이 비록 한정된 실시예와 도면에 의해 설명되었으나, 해당 기술분야에서 통상의 지식을 가 진 자라면 상기의 기재로부터 다양한 수정 및 변형이 가능하다. 예를 들어, 설명된 기술들이 설명된 방법과 다 른 순서로 수행되거나, 및/또는 설명된 시스템, 구조, 장치, 회로 등의 구성요소들이 설명된 방법과 다른 형태 로 결합 또는 조합되거나, 다른 구성요소 또는 균등물에 의하여 대치되거나 치환되더라도 적절한 결과가 달성될 수 있다. 그러므로, 다른 구현들, 다른 실시예들 및 청구범위와 균등한 것들도 후술하는 청구범위의 범위에 속 한다."}
{"patent_id": "10-2022-0119453", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 한 실시예에 따른 준 지도 학습에 기반하여 의료 영상 데이터에서 장기를 분할하여 출력하기 위한 시스템의 구성요소에 관한 도면이다. 도 2a는 본 발명의 한 실시예에 따른 제1 학습모듈에서의 복셀 간 표현학습에 관한 도면이다. 도 2b는 본 발명 의 한 실시예에 따른 복셀 간 표현학습 방법 중 하나인 BYOL(Bootstrap your own latent-a new approach to self-superviced learning)에 관한 도면이다. 도 3은 본 발명의 한 실시예에 따른 제2 학습모듈에서의 복셀 간 적대적 학습에 관한 도면이다. 도 4는 V-Net 백본 만을 이용하여 획득한 클래스에 따른 복셀-레벨 특성(Voxel-level feature)들의 분포와 본 발명에 따라 획득한 클래스에 따른 복셀-레벨 특성(Voxel-level feature)들의 분포에 관한 도면이다. 도 5a는 V-Net 백본과 도 3의 복셀 간 적대적 학습 만을 함께 사용하여 획득한 라벨된 정답값과 언라벨된 임시 값의 분포를 나타낸 도면이다. 도 5b는 V-Net 백본과 도 2의 복셀 간 표현학습 만을 함께 사용하여 획득한 라벨된 정답값과 언라벨된 임시값의 분포를 나타낸 도면이다. 도 5c는 본 발명의 한 실시예에 따른 V-Net 백본과 도 2a의 복셀 간 표현학습 및 도 3의 복셀 간 적대적 학습을 함께 사용하여 획득한 라벨된 정답값과 언라벨된 임시값의 분포를 나타낸 도면이다. 도 6은 본 발명의 한 실시예에 따른 V-Net 백본과 도 2a의 복셀 간 표현학습 및 도 3의 복셀 간 적대적 학습을 함께 사용하여 획득한 다중 장기 분할에 관한 결과이다. 도 7은 본 발명의 한 실시예에 따른 본 발명의 한 실시예에 따른 준 지도 학습에 기반하여 의료 영상 데이터에 서 장기를 분할하여 출력하기 위한 방법에 관한 흐름도이다."}
