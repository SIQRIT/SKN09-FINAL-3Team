{"patent_id": "10-2023-0138313", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2025-0055001", "출원번호": "10-2023-0138313", "발명의 명칭": "포인트 클라우드 기반의 시맨틱 모델링 장치 및 방법", "출원인": "건국대학교 산학협력단", "발명자": "김형석"}}
{"patent_id": "10-2023-0138313", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "포인트 클라우드 기반의 시맨틱 모델링 방법에 있어서,대상 공간에 존재하는 실제 객체에 대응하도록 계측된 복수의 3차원 점을 포함하는 포인트 클라우드 입력을 획득하는 단계;상기 포인트 클라우드 입력으로부터 상기 실제 객체에 대응하는 유형 정보, 위치 정보 및 크기 정보를 포함하는객체 추출 정보를 탐지하는 단계;상기 유형 정보에 따라 미리 파악된 객체 기준 형상을 고려하여, 상기 실제 객체와 관련하여 상기 포인트 클라우드 입력에 누락된 손실 포인트를 추가하는 컴플리션(Completion) 처리를 수행하는 단계; 및상기 컴플리션 처리가 적용된 타겟 포인트 클라우드를 포함하는 바운딩 박스와 상기 실제 객체에 대응하여 생성되는 탐지 오브젝트에 대한 복셀 단위 비교를 통해 상기 탐지 오브젝트의 배치 방향을 결정하는 단계,를 포함하는, 모델링 방법."}
{"patent_id": "10-2023-0138313", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 포인트 클라우드 입력에서 상기 객체 추출 정보가 미탐지된 잔여 포인트를 클러스터 단위로 분류하는단계; 및상기 클러스터 각각에 대응하는 미탐지 오브젝트를 생성하는 단계,를 더 포함하는 것인, 모델링 방법."}
{"patent_id": "10-2023-0138313", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,상기 대상 공간에 대응하여 가상으로 모사되는 가상 공간에 상기 탐지 오브젝트 및 상기 미탐지 오브젝트를 배치하는 단계,를 더 포함하는 것인, 모델링 방법."}
{"patent_id": "10-2023-0138313", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,상기 객체 추출 정보를 탐지하는 단계는,상기 포인트 클라우드 입력을 입력으로 하여 상기 포인트 클라우드 입력 내에 존재하는 객체 별 바운딩 박스를식별하고, 상기 바운딩 박스마다의 상기 유형 정보를 추정하도록 미리 구축된 인공지능 기반의 3차원 객체 탐지알고리즘을 적용하는 것인, 모델링 방법."}
{"patent_id": "10-2023-0138313", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서,상기 컴플리션 처리를 수행하는 단계는,상기 실제 객체와 무관한 노이즈 포인트를 제거하는 단계를 포함하는 것인, 모델링 방법."}
{"patent_id": "10-2023-0138313", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "공개특허 10-2025-0055001-3-제1항에 있어서,상기 탐지 오브젝트의 배치 방향을 결정하는 단계는,상기 크기 정보를 기초로 하여 상기 탐지 오브젝트의 크기를 정규화하는 단계를 포함하는 것인, 모델링 방법."}
{"patent_id": "10-2023-0138313", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제2항에 있어서,상기 미탐지 오브젝트는, 상기 클러스터 각각에 포함된 복수의 포인트가 분포된 공간을 커버하고, 미리 설정된형상을 가지도록 생성되는 것인, 모델링 방법."}
{"patent_id": "10-2023-0138313", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제3항에 있어서,상기 배치하는 단계는,상기 탐지 오브젝트 및 상기 미탐지 오브젝트에 대하여 상기 포인트 클라우드 입력을 이미지로 투사하여 상기탐지 오브젝트 및 상기 미탐지 오브젝트 각각에 대응하는 텍스처를 결정하는 단계; 및상기 이미지 내에 빈 픽셀이 존재하면, 상기 빈 픽셀에 대한 보간(Interpolation)을 수행하는 단계,를 포함하는 것인, 모델링 방법."}
{"patent_id": "10-2023-0138313", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1항에 있어서,상기 대상 공간이 실내 공간인 것을 특징으로 하는, 모델링 방법."}
{"patent_id": "10-2023-0138313", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제3항에 있어서,상기 가상 공간을 포함하는 인터페이스를 사용자 단말을 통해 출력하는 단계,를 더 포함하는 것인, 모델링 방법."}
{"patent_id": "10-2023-0138313", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "포인트 클라우드 기반의 시맨틱 모델링 장치에 있어서,대상 공간에 존재하는 실제 객체에 대응하도록 계측된 복수의 3차원 점을 포함하는 포인트 클라우드 입력을 획득하고, 상기 포인트 클라우드 입력으로부터 상기 실제 객체에 대응하는 유형 정보, 위치 정보 및 크기 정보를포함하는 객체 추출 정보를 탐지하는 객체 탐지부;상기 유형 정보에 따라 미리 파악된 객체 기준 형상을 고려하여, 상기 실제 객체와 관련하여 상기 포인트 클라우드 입력에 누락된 손실 포인트를 추가하는 컴플리션(Completion) 처리를 수행하는 데이터 가공부; 및상기 컴플리션 처리가 적용된 타겟 포인트 클라우드를 포함하는 바운딩 박스와 상기 실제 객체에 대응하여 생성되는 탐지 오브젝트에 대한 복셀 단위 비교를 통해 상기 탐지 오브젝트의 배치 방향을 결정하는 정렬부,를 포함하는, 모델링 장치."}
{"patent_id": "10-2023-0138313", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항에 있어서,상기 포인트 클라우드 입력에서 상기 객체 추출 정보가 미탐지된 잔여 포인트를 클러스터 단위로 분류하고, 상기 클러스터 각각에 대응하는 미탐지 오브젝트를 생성하는 후처리 수행부,를 더 포함하는 것인, 모델링 장치.공개특허 10-2025-0055001-4-청구항 13 제12항에 있어서,상기 대상 공간에 대응하여 가상으로 모사되는 가상 공간에 상기 탐지 오브젝트 및 상기 미탐지 오브젝트를 배치하는 모델링부,를 더 포함하는 것인, 모델링 장치."}
{"patent_id": "10-2023-0138313", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제11항에 있어서,상기 객체 탐지부는,상기 포인트 클라우드 입력을 입력으로 하여 상기 포인트 클라우드 입력 내에 존재하는 객체 별 바운딩 박스를식별하고, 상기 바운딩 박스마다의 상기 유형 정보를 추정하도록 미리 구축된 인공지능 기반의 3차원 객체 탐지알고리즘을 적용하는 것인, 모델링 장치."}
{"patent_id": "10-2023-0138313", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제13항에 있어서,상기 가상 공간을 포함하는 인터페이스를 사용자 단말을 통해 출력하는 인터페이스부,를 더 포함하는 것인, 모델링 장치."}
{"patent_id": "10-2023-0138313", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "포인트 클라우드 기반의 시맨틱 모델링 장치 및 방법이 개시되며, 본원의 일 실시예에 따른 포인트 클라우드 기 반의 시맨틱 모델링 방법은, 대상 공간에 존재하는 실제 객체에 대응하도록 계측된 복수의 3차원 점을 포함하는 포인트 클라우드 입력을 획득하는 단계, 상기 포인트 클라우드 입력으로부터 상기 실제 객체에 대응하는 유형 정 보, 위치 정보 및 크기 정보를 포함하는 객체 추출 정보를 탐지하는 단계, 상기 유형 정보에 따라 미리 파악된 객체 기준 형상을 고려하여, 상기 실제 객체와 관련하여 상기 포인트 클라우드 입력에 누락된 손실 포인트를 추 가하는 컴플리션(Completion) 처리를 수행하는 단계 및 상기 컴플리션 처리가 적용된 타겟 포인트 클라우드를 포 함하는 바운딩 박스와 상기 실제 객체에 대응하여 생성되는 탐지 오브젝트에 대한 복셀 단위 비교를 통해 상기 탐지 오브젝트의 배치 방향을 결정하는 단계를 포함할 수 있다."}
{"patent_id": "10-2023-0138313", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본원은 포인트 클라우드 기반의 시맨틱 모델링 장치 및 방법에 관한 것이다."}
{"patent_id": "10-2023-0138313", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "실내 공간은 모든 사람들의 삶에서 가장 친숙하고 필수적인 환경이며, 이에 따라 가상 세계에서도 마찬가지로 실내 장면에 대한 모델은 3차원 게임, 인테리어 디자인, 가상 회의, 다양한 VR/AR 어플리케이션 등에서 필수적 인 요소이다. 특히 HMD(Head Mounted Display)의 빠른 발전으로 최근 몇 년 동안 가상현실이 점점 대중화되고 있으며, 몰입감 있는 가상 경험을 제공하기 위해서는 가상 캐릭터가 생활하는 사실적인 3차원 실내 공간 모델이 필요하다. 현재 존재하는 대부분의 3차원 실내 공간 모델은 일반 3차원 모델링 전문 실내 공간 CAD 도구를 사용하여 수작 업으로 만들어 지는 것이 일반적이다. 이러한 도구를 사용하여 공간을 모델링하려면 숙련된 3차원 설계 및 모델링 기술이 필요하고, 상세하고 복잡한 3차원 실내 공간을 모델링 하려면 훨씬 더 많은 전문 지식이 필요하고 시간도 많이 필요하다는 어려움이 있다. 이를 해결 하기 위한 방법으로 영상에 기반한 방법, Sketch 등의 사용자 입력으로부터 Deep-Learning 기반 모델 의 생성기법등이 있으나, 실제공간과의 정합성 및 3차원 정보의 추정에 대한 정확성에서 한계가 있다. 상기 문제를 해결하기 위하여 3차원 포인트 클라우드 데이터로부터 모델링하고자 하는 접근이 있으나, 생성된 모델은 단순 다각형 및 점 정보 기반 3차원 정보로 구성되어 실제 물체를 분리하고 조작하기 위하여는 요구되는 수작업이 매우 크며, 이로 인한 한계가 크다. 본원의 배경이 되는 기술은 한국등록특허공보 제10-2351002호에 개시되어 있다."}
{"patent_id": "10-2023-0138313", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본원은 전술한 종래 기술의 문제점을 해결하기 위한 것으로서, 3차원 포인트 클라우드 데이터 내에서 추정한 시 맨틱한 정보를 기반으로 객체별 조작이 가능한 시맨틱 모델링을 수행하는 포인트 클라우드 기반의 시맨틱 모델 링 장치 및 방법을 제공하려는 것을 목적으로 한다. 다만, 본원의 실시예가 이루고자 하는 기술적 과제는 상기된 바와 같은 기술적 과제들로 한정되지 않으며, 또 다른 기술적 과제들이 존재할 수 있다."}
{"patent_id": "10-2023-0138313", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기한 기술적 과제를 달성하기 위한 기술적 수단으로서, 본원의 일 실시예에 따른 포인트 클라우드 기반의 시 맨틱 모델링 방법은, 대상 공간에 존재하는 실제 객체에 대응하도록 계측된 복수의 3차원 점을 포함하는 포인트 클라우드 입력을 획득하는 단계, 상기 포인트 클라우드 입력으로부터 상기 실제 객체에 대응하는 유형 정보, 위 치 정보 및 크기 정보를 포함하는 객체 추출 정보를 탐지하는 단계, 상기 유형 정보에 따라 미리 파악된 객체 기준 형상을 고려하여, 상기 실제 객체와 관련하여 상기 포인트 클라우드 입력에 누락된 손실 포인트를 추가하 는 컴플리션(Completion) 처리를 수행하는 단계 및 상기 컴플리션 처리가 적용된 타겟 포인트 클라우드를 포함 하는 바운딩 박스와 상기 실제 객체에 대응하여 생성되는 탐지 오브젝트에 대한 복셀 단위 비교를 통해 상기 탐 지 오브젝트의 배치 방향을 결정하는 단계를 포함할 수 있다. 또한, 본원의 일 실시예에 따른 포인트 클라우드 기반의 시맨틱 모델링 방법은, 상기 포인트 클라우드 입력에서 상기 객체 추출 정보가 미탐지된 잔여 포인트를 클러스터 단위로 분류하는 단계 및 상기 클러스터 각각에 대응 하는 미탐지 오브젝트를 생성하는 단계를 포함할 수 있다. 또한, 본원의 일 실시예에 따른 포인트 클라우드 기반의 시맨틱 모델링 방법은, 상기 대상 공간에 대응하여 가 상으로 모사되는 가상 공간에 상기 탐지 오브젝트 및 상기 미탐지 오브젝트를 배치하는 단계를 포함할 수 있다. 또한, 상기 객체 추출 정보를 탐지하는 단계는, 상기 포인트 클라우드 입력을 입력으로 하여 상기 포인트 클라 우드 입력 내에 존재하는 객체 별 바운딩 박스를 식별하고, 상기 바운딩 박스마다의 상기 유형 정보를 추정하도 록 미리 구축된 인공지능 기반의 3차원 객체 탐지 알고리즘을 적용할 수 있다. 또한, 상기 컴플리션 처리를 수행하는 단계는, 상기 실제 객체와 무관한 노이즈 포인트를 제거하는 단계를 포함 할 수 있다. 또한, 상기 탐지 오브젝트의 배치 방향을 결정하는 단계는, 상기 크기 정보를 기초로 하여 상기 탐지 오브젝트 의 크기를 정규화하는 단계를 포함할 수 있다. 또한, 상기 미탐지 오브젝트는, 상기 클러스터 각각에 포함된 복수의 포인트가 분포된 공간을 커버하고, 미리 설정된 형상을 가지도록 생성될 수 있다. 또한, 상기 배치하는 단계는, 상기 탐지 오브젝트 및 상기 미탐지 오브젝트에 대하여 상기 포인트 클라우드 입 력을 이미지로 투사하여 상기 탐지 오브젝트 및 상기 미탐지 오브젝트 각각에 대응하는 텍스처를 결정하는 단계 및 상기 이미지 내에 빈 픽셀이 존재하면, 상기 빈 픽셀에 대한 보간(Interpolation)을 수행하는 단계를 포함할 수 있다. 또한, 상기 대상 공간이 실내 공간일 수 있다. 또한, 본원의 일 실시예에 따른 포인트 클라우드 기반의 시맨틱 모델링 방법은, 상기 가상 공간을 포함하는 인 터페이스를 사용자 단말을 통해 출력하는 단계를 포함할 수 있다. 한편, 본원의 일 실시예에 따른 포인트 클라우드 기반의 시맨틱 모델링 장치는, 대상 공간에 존재하는 실제 객 체에 대응하도록 계측된 복수의 3차원 점을 포함하는 포인트 클라우드 입력을 획득하고, 상기 포인트 클라우드 입력으로부터 상기 실제 객체에 대응하는 유형 정보, 위치 정보 및 크기 정보를 포함하는 객체 추출 정보를 탐 지하는 객체 탐지부, 상기 유형 정보에 따라 미리 파악된 객체 기준 형상을 고려하여, 상기 실제 객체와 관련하 여 상기 포인트 클라우드 입력에 누락된 손실 포인트를 추가하는 컴플리션(Completion) 처리를 수행하는 데이터 가공부 및 상기 컴플리션 처리가 적용된 타겟 포인트 클라우드를 포함하는 바운딩 박스와 상기 실제 객체에 대 응하여 생성되는 탐지 오브젝트에 대한 복셀 단위 비교를 통해 상기 탐지 오브젝트의 배치 방향을 결정하는 정 렬부를 포함할 수 있다. 또한, 본원의 일 실시예에 따른 포인트 클라우드 기반의 시맨틱 모델링 장치는, 상기 포인트 클라우드 입력에서 상기 객체 추출 정보가 미탐지된 잔여 포인트를 클러스터 단위로 분류하고, 상기 클러스터 각각에 대응하는 미탐지 오브젝트를 생성하는 후처리 수행부를 포함할 수 있다. 또한, 본원의 일 실시예에 따른 포인트 클라우드 기반의 시맨틱 모델링 장치는, 상기 대상 공간에 대응하여 가 상으로 모사되는 가상 공간에 상기 탐지 오브젝트 및 상기 미탐지 오브젝트를 배치하는 모델링부를 포함할 수 있다. 또한, 상기 객체 탐지부는, 상기 포인트 클라우드 입력을 입력으로 하여 상기 포인트 클라우드 입력 내에 존재 하는 객체 별 바운딩 박스를 식별하고, 상기 바운딩 박스마다의 상기 유형 정보를 추정하도록 미리 구축된 인공 지능 기반의 3차원 객체 탐지 알고리즘을 적용할 수 있다. 또한, 본원의 일 실시예에 따른 포인트 클라우드 기반의 시맨틱 모델링 장치는, 상기 가상 공간을 포함하는 인 터페이스를 사용자 단말을 통해 출력하는 인터페이스부를 포함할 수 있다. 상술한 과제 해결 수단은 단지 예시적인 것으로서, 본원을 제한하려는 의도로 해석되지 않아야 한다. 상술한 예 시적인 실시예 외에도, 도면 및 발명의 상세한 설명에 추가적인 실시예가 존재할 수 있다."}
{"patent_id": "10-2023-0138313", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "전술한 본원의 과제 해결 수단에 의하면, 3차원 포인트 클라우드 데이터 내에서 추정한 시맨틱한 정보를 기반으 로 객체별 조작이 가능한 시맨틱 모델링을 수행하는 포인트 클라우드 기반의 시맨틱 모델링 장치 및 방법을 제 공할 수 있다. 전술한 본원의 과제 해결 수단에 의하면, 기존의 표면을 재구성한 메쉬 형태의 모델에 비해, 시맨틱한 정보를 제공함으로 객체를 편집하거나 다른 모델로 대체 가능하며, 객체를 조작하는 등의 상호작용이 가능한 이점이 있 다. 다만, 본원에서 얻을 수 있는 효과는 상기된 바와 같은 효과들로 한정되지 않으며, 또 다른 효과들이 존재할 수 있다."}
{"patent_id": "10-2023-0138313", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "아래에서는 첨부한 도면을 참조하여 본원이 속하는 기술 분야에서 통상의 지식을 가진 자가 용이하게 실시할 수 있도록 본원의 실시예를 상세히 설명한다. 그러나 본원은 여러 가지 상이한 형태로 구현될 수 있으며 여기에서 설명하는 실시예에 한정되지 않는다. 그리고 도면에서 본원을 명확하게 설명하기 위해서 설명과 관계없는 부분 은 생략하였으며, 명세서 전체를 통하여 유사한 부분에 대해서는 유사한 도면 부호를 붙였다. 본원 명세서 전체에서, 어떤 부분이 다른 부분과 \"연결\"되어 있다고 할 때, 이는 \"직접적으로 연결\"되어 있는 경우뿐 아니라, 그 중간에 다른 소자를 사이에 두고 \"전기적으로 연결\" 또는 \"간접적으로 연결\"되어 있는 경우 도 포함한다. 본원 명세서 전체에서, 어떤 부재가 다른 부재 \"상에\", \"상부에\", \"상단에\", \"하에\", \"하부에\", \"하단에\" 위치 하고 있다고 할 때, 이는 어떤 부재가 다른 부재에 접해 있는 경우뿐 아니라 두 부재 사이에 또 다른 부재가 존 재하는 경우도 포함한다. 본원 명세서 전체에서, 어떤 부분이 어떤 구성 요소를 \"포함\"한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다른 구성 요소를 제외하는 것이 아니라 다른 구성 요소를 더 포함할 수 있는 것을 의미한다. 본원은 포인트 클라우드 기반의 시맨틱 모델링 장치 및 방법에 관한 것이다. 도 1은 본원의 일 실시예에 따른 포인트 클라우드 기반의 시맨틱 모델링 장치를 포함하는 시맨틱 모델링 시스템 의 개략적인 구성도이다. 도 1을 참조하면, 본원의 일 실시예에 따른 시맨틱 모델링 시스템은 본원의 일 실시예에 따른 포인트 클라 우드 기반의 시맨틱 모델링 장치(이하, '모델링 장치'라 한다.), 스캔 장치, 사용자 단말 및 데이터베이스를 포함할 수 있다. 모델링 장치, 스캔 장치, 사용자 단말 및 데이터베이스 상호간은 네트워크를 통해 통 신할 수 있다. 네트워크는 단말들 및 서버들과 같은 각각의 노드 상호간에 정보 교환이 가능한 연결 구조를 의미하는 것으로, 이러한 네트워크의 일 예에는, 3GPP(3rd Generation Partnership Project) 네트워크, LTE(Long Term Evolution) 네트워크, 5G 네트워크, WIMAX(World Interoperability for Microwave Access) 네 트워크, 인터넷(Internet), LAN(Local Area Network), Wireless LAN(Wireless Local Area Network), WAN(Wide Area Network), PAN(Personal Area Network), wifi 네트워크, 블루투스(Bluetooth) 네트워크, 위성 방송 네트 워크, 아날로그 방송 네트워크, DMB(Digital Multimedia Broadcasting) 네트워크 등이 포함되나 이에 한정되지 는 않는다. 사용자 단말은 예를 들면, 스마트폰(Smartphone), 스마트패드(SmartPad), 태블릿 PC등과 PCS(Personal Communication System), GSM(Global System for Mobile communication), PDC(Personal Digital Cellular), PHS(Personal Handyphone System), PDA(Personal Digital Assistant), IMT(International Mobile Telecommunication)-2000, CDMA(Code Division Multiple Access)-2000, W-CDMA(W-Code Division Multiple Access), Wibro(Wireless Broadband Internet) 단말기 같은 모든 종류의 무선 통신 장치일 수 있다. 한편, 본원의 실시예에 관한 설명에서 스캔 장치는 대상 공간에 존재하는 실제 객체에 대응하도록 계측된 복수의 3차원 점을 포함하는 포인트 클라우드 입력을 획득하기 위한 라이다(LiDAR) 센서 등을 구비하는 계측 장 치일 수 있다. 예를 들어, 스캔 장치는 대상 공간에서 탑재된 라이다 센서를 이용하여 포인트 클라우드를 수집하는 사용자 단말을 포함할 수 있으나, 이에만 한정되는 것은 아니다. 또한, 본원의 실시예에 관한 설명에서 데이터베이스는 이하에서 상세히 설명하는 바와 같이 모델링 장치 에 의해 구축되는 포인트 클라우드를 이용한 시맨틱 모델링 데이터, 대상 공간에 대한 모델링 시 활용되는객체 유형 별 가상 오브젝트 등을 저장하기 위한 서버 내지 디바이스일 수 있다. 도 2는 본원의 일 실시예에 따른 포인트 클라우드 기반의 시맨틱 모델링 장치에 의해 수행되는 주요 프로세스를 설명하기 위한 개념도이다. 도 2를 참조하면, 모델링 장치는 실제 공간에 해당하는 대상 공간을 캡처한 포인트 클라우드 데이터를 입 력 데이터(포인트 클라우드 입력)로 하여 포인트 클라우드 기반 3차원 객체 탐지(Object Detection) 네트워크를 통해 입력 데이터 내의 객체를 탐지하고, 탐지된 객체의 레이블과 해당 객체의 위치와 크기를 추정하는 3차원 바운딩 박스를 파악할 수 있다. 이 때, 탐지된 객체에 대응하여 생성되는 3차원 바운딩 박스 내에서도 해당 실제 객체에 대응하는 모델(탐지 오 브젝트)이 여러 방향으로 배치될 수 있기 때문에, 모델링 장치는 실제 객체에 대응하는 모델(탐지 오브젝 트)이 배치될 방향을 알기 위한 정렬(Alignment) 작업을 추가로 수행하며, 모델링 장치는 전술한 정렬 (Alignment) 작업 진행 전, 객체 탐지(Object Detection) 시 예측한 3차원 바운딩 박스를 기준으로 장면 내의 객체를 추출할 수 있다. 또한, 모델링 장치는 컴플리션(Completion) 네트워크 등을 통해 추출된 객체의 포인트 클라우드에 대하여, 노이즈는 샘플링하고 가림 현상 등으로 손실된 부분은 보완하여 탐지된 객체들에 대한 컴플리션(Completion) 작 업을 수행할 수 있으며, 이러한 컴플리션 작업을 통해 완성된 객체의 포인트 클라우드(타겟 포인트 클라우드)를 이용하여 모델링 장치는 해당 모델(탐지 오브젝트)의 배치될 방향을 정하는 정렬(Alignment) 작업을 후속 하여 수행할 수 있다. 여기서, 정렬(Alignment) 작업은 장면에서 탐지된 객체와 탐지된 객체에 해당하는 3D 모델과의 복셀 단위의 비 교를 통해 진행되며, 이를 위해 모델링 장치는 탐지된 객체와 3차원 모델을 복셀화 할 수 있다. 또한, 모 델링 장치는 복셀화 된 3차원 모델을 일정한 각도로 회전하여, 회전된 3차원 모델과 탐지된 객체와의 복셀 단위의 비교를 통해 가장 유사성이 높은 3차원 모델의 회전 각도를 선정하고, 모델링 장치는 선정된 3차원 모델의 회전 각도를 3차원 객체 탐지(Object Detection)을 통해 얻은 3차원 바운딩 박스에 적용하여 최종적으로 조작이 가능한 3차원 시맨틱 모델을 배치하도록 동작한다. 이하에서는 모델링 장치의 구체적인 기능 및 동작에 대하여 상세히 설명하도록 한다. 먼저, 모델링 장치는 대상 공간에 존재하는 실제 객체에 대응하도록 계측된 복수의 3차원 점을 포함하는 포인트 클라우드 입력을 획득할 수 있다. 예시적으로 모델링 장치는 사용자 단말에 탑재된 라이다 센 서(미도시)와 소정의 데이터 수집 어플리케이션(예를 들면, SiteScape와 같은 어플리케이션 등)을 이용하여 실 내 공간에 해당하는 타겟 공간을 캡처한 포인트 클라우드 데이터를 입력 데이터로서 획득할 수 있다. 예시적으 로, 포인트 클라우드 입력에 포함된 캡처된 각 포인트의 좌표 정보 및 색상 정보는 x, y, z, r, g, b 형태의 ply 파일 형태 등으로 반영될 수 있다. 또한, 본원의 일 실시예에 따르면, 모델링 장치는 후술하는 3차원 객체 탐지 알고리즘에서 사용하는 데이 터 셋(예를 들면, SUN RGB-D 데이터셋)과 실측된 포인트 클라우드 입력의 좌표계가 일치하지 않는 경우, 수집된 포인트 클라우드 입력에 포함된 데이터를 회전(예를 들면, X축 기준 90도 회전 등)시켜 좌표계를 일치시키고, 필터링을 통해 노이즈를 제거하는 전처리를 수행할 수 있다. 이와 관련하여 도 3은 포인트 클라우드 입력에 대한 필터링 적용 결과를 예시적으로 나타낸 도면이다. 도 3을 참조하면, 도 3의 좌측에 도시된 3개의 이미지는 필터링을 적용하기 전의 포인트 클라우드 입력을 나타 내고, 도 3의 우측에 도시된 3개의 이미지는 필터링을 적용한 후의 포인트 클라우드 입력을 나타낸다. 또한, 도 3을 참조하면, 모델링 장치는 통계학적 정보를 이용하여 노이즈를 탐지하는 기법으로서, 이웃 점 들과의 평균 거리정보를 계산하여 일정 분포 이상의 점들을 노이즈로 간주하는 Statistical Outlier Removal 알 고리즘을 기초로 필터링을 적용할 수 있다. 구체적으로 예시하면, 모델링 장치는 포인트 클라우드 입력에 대한 필터링을 위한 분석 시 고려하는 이웃 점의 수를 50개로 설정하고, 이상치(Outlier)로 처리할 거리 정보는 3으로 설정하여 기준점 이웃에 위치한 50개의 점들의 평균 거리의 표준 편차가 3 이상인 거리에 있는 점은 노이 즈로 간주하여 제거할 수 있으나, 이에만 한정되는 것은 아니다. 즉, 본원의 일 실시예에 따르면, 모델링 장치는 포인트 클라우드 입력에 포함된 복수의 포인트 중 대상 공 간에 존재하는 실제 객체와 무관한 노이즈 포인트를 제거할 수 있다.또한, 모델링 장치는 획득한 포인트 클라우드 입력으로부터 실제 객체에 대응하는 유형 정보, 위치 정보 및 크기 정보를 포함하는 객체 추출 정보를 탐지할 수 있다. 구체적으로 모델링 장치는 포인트 클라우드 입력을 입력으로 하여 포인트 클라우드 입력 내에 존재하는 객 체 별 바운딩 박스를 식별하고, 바운딩 박스마다의 상기 유형 정보를 추정하도록 미리 구축된 인공지능 기반의 3차원 객체 탐지 알고리즘을 적용함으로써 객체 추출 정보를 도출할 수 있다. 이와 관련하여 본원의 일 실시예에 따르면, 포인트 클라우드 입력에 반영된 장면 내의 객체들을 3차원 모델(탐 지 오브젝트)로 대체하여 가상 공간을 생성하기 위하여 포인트 클라우드 입력에 반영된 장면 내 객체들의 정확 한 3차원 위치와 객체들의 크기를 파악하여야 하며, 포인트 클라우드 장면 내에서 객체들의 위치와 크기를 알아 내기 위해 모델링 장치는 포인트 클라우드 입력에 대하여 3차원 객체 탐지(Object Detection)를 수행하는 3차원 객체 탐지 알고리즘을 적용하여 객체들의 위치와 크기를 추정할 수 있다. 도 4는 포인트 클라우드 입력으로부터 도출된 객체 추출 정보를 예시적으로 나타낸 도면이다. 도 4를 참조하면, 포인트 클라우드 입력으로부터 파악된 각 객체의 위치와 크기는 3차원 바운딩 박스로 표현될 수 있다. 또한, 본원의 일 실시예에 따르면, 네트워크의 정확도와 적용해야 할 데이터와의 유사성을 고려하여, 모델링 장 치는 실내 공간 데이터 셋인 SUN RGB-D와 ScanNet 데이터셋을 사용하여 구축되는 Group-Free 3D 네트워크 를 3차원 객체 탐지 알고리즘으로서 적용할 수 있으나, 이에만 한정되는 것은 아니고, 본원의 구현예에 따라서 단일 영상 기반의 객체 탐지 기법(Monocular Image Based Methods), 프로젝션 기반의 방식과 볼륨 기반의 방식, PointNet 기반 방식 등을 포함하는 포인트 클라우드 기반의 객체 탐지 기법(Point Cloud Based Methods) 등 종 래 이미 공지되었거나 향후 개발될 수 있는 다양한 유형의 3차원 객체 탐지 알고리즘이 폭넓게 적용될 수 있다. 도 5는 포인트 클라우드 입력으로부터 도출된 3차원 객체를 각 객체 별로 구분하여 나타낸 도면이다. 도 5를 참조하면, 모델링 장치는 객체 추출 정보를 이용하여 포인트 클라우드 입력 중 각 객체에 대응하는 포인트 클라우드를 객체 별로 구분 추출할 수 있다. 예시적으로 모델링 장치는 객체의 정보 및 기하학적인 특성 을 활용하거나 제약 조건을 설정하여 객체를 추출하는 지식 기반(Knowledge-Driven) 방식, 일련의 기능을 설계 하고 적용하여 레이블이 지정된 방대한 학습 데이터를 기반으로 학습을 진행하는 데이터 기반(Data-Driven) 방 식을 적용할 수 있다. 보다 구체적으로 지식 기반 방식 중 매칭 기반(Matching-Based) 방법은 객체를 미리 선정된 모델과의 비교를 통 해 유사한 특성을 보이는 지역을 추출하는 기법이며, 규칙 기반(Rule-Based) 방법은 각 객체에 대한 기하학적 특징(위치, 크기, 방향, 모양)을 사용하여 추출하고자 하는 객체가 아닌 부분을 제거하여 추출하고자 하는 객체 만을 남겼다. 또한 여러 가지 매개변수(위치, 크기)를 추출하고자 하는 객체가 아닌 부분을 필터링하거나, 객체 를 추출하기 위해 장면을 분할한 후 규칙을 포함하는 부분끼리의 병합을 진행하는 슬라이스 방법을 사용 할 수 있다. 또한, 데이터 기반(Data-Driven) 방법 중 2차원 이미지와 포인트 클라우드의 통합을 기반으로 하는 로컬라이제 이션(Localization) 기법은, 위치와 크기 관련 특징, 위치 맵과 관련된 픽셀의 강도 등에 대한 지역적, 전역적 특징을 SVM 및 랜덤 포레스트 분류기를 통해 학습시키는 방식이며, ESF(Ensemble of Shape Function)과 기하학 적 특징을 사용하여 객체의 특징을 학습하는 경우, ESF는 세 가지의 모양 함수(점 사이의 거리, 면적, 각도)와 비율 함수를 정의하고, ESF는 선형성, 평면성, 공분산 행렬의 산란, 바운딩 박스의 비율 등의 기하학적 특징을 포함하며, 랜덤 포레스트 분류기를 통해 학습이 진행될 수 있다. 또한, 본원의 일 실시예에 따르면, 모델링 장치는 각 객체별 바운딩 박스 내의 포인트를 구하기 위하여, 주어진 바운딩 박스의 각 꼭지점의 좌표를 통해 해당 바운딩 박스를 이루는 각 평면에 대한 방정식을 정의할 수 있다. 구체적으로 평면의 방정식은 Ax + By + Cz + D = 0 으로 표현할 수 있고, 최소한 세 개의 점을 통해 평면 을 명확히 정의할 수 있다. 즉, 바운딩 박스 각 평면의 네 개의 점 중 세 점 (x1, y1, z1), (x2, y2, z2), (x3, y3, z3)를 통해 평면의 방정식의 A, B, C, D를 특정할 수 있으며, 이는 하기 식 1-1과 같은 행렬식으로 정 의될 수 있다.[식 1-1]"}
{"patent_id": "10-2023-0138313", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "또한, 상기의 식 1-1은 하기의 식 1-2로 전개될 수 있다. [식 1-2]"}
{"patent_id": "10-2023-0138313", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "또한, 모델링 장치는 상기와 같이 연산한 A, B, C, D를 통해 바운딩 박스의 각 평면의 방정식을 구한 다음, 도형의 방정식 f(x, y, z) = 0에 의해 나누어지는 X, Y, Z 평면에서, 동일한 영역에 속하는 점들에 대해 서는 f(x, y, z)의 부호가 같다는 점을 이용하여 바운딩 박스의 중심점(Tx, Ty, Tz)과 같은 영역에 속한 점들을 구할 수 있다. 즉, f(Tx, Ty, Tz) * f(x, y, z) > 0이면 바운딩 박스 내부의 점이고, f(Tx, Ty, Tz) * f(x, y, z) < 0이면 외 부의 점에 해당하며, 이러한 방식으로 각 장면에서 3차원 객체 탐지(Object Detection)을 통해 탐지된 각 객체 들의 바운딩 박스 내부의 포인트들을 추출할 수 있게 된다. 종합하면, 모델링 장치는 객체 추출 단계에서 3차원 모델과 포인트 클라우드 내의 객체를 비교하기 위하여 포인트 클라우드 장면에서 3차원 객체 탐지(Object Detection)를 통해 탐지된 객체들을 추출할 수 있으며, 구체 적으로 3차원 객체 탐지 결과 도출된 객체 탐지 정보로부터 각 탐지 객체의 바운딩 박스의 꼭지점과 중심점을 구한 후, 바운딩 박스의 각 면의 평면의 방정식을 이용하여 객체 내부의 있는 점을 추출하는 방법으로 포인트 클라우드 내 객체를 추출할 수 있다. 또한, 모델링 장치는 객체 별 유형 정보에 따라 미리 파악된 객체 기준 형상을 고려하여, 실제 객체와 관 련하여 포인트 클라우드 입력에 누락된 손실 포인트를 추가하는 컴플리션(Completion) 처리를 수행할 수 있다. 또한, 컴플리션 처리 단계에서 모델링 장치는 포인트 클라우드 입력에 포함된 복수의 포인트 중 대상 공간 에 존재하는 실제 객체와 무관한 노이즈 포인트를 제거할 수 있다. 이와 관련하여, 컴플리션(Completion)을 적용하지 않고 3차원 객체 탐지 결과만을 이용하여 곧바로 정렬 (Alignment)을 적용하는 경우, 탐지된 객체가 실제 공간에 배치된 상태에 부합하지 않으며, 제대로 정렬되지 않 는 경우가 발생할 수 있으며, 이는 포인트 클라우드 입력 계측 시 발생할 수 있는 가림 현상으로 인한 포인트 클라우드 손실, 측정 노이즈 등을 원인으로 할 수 있다. 이에 따라, 모델링 장치는 추출된 객체를 샘플링하여 노이즈 문제를 해결하고, 가림 현상으로 인한 포인트 클라우드 손실을 컴플리션(Completion) 작업을 통해 보완할 수 있다. 보다 구체적으로, 모델링 장치는 미리 구축된 인공지능 기반의 컴플리션 네트워크를 적용할 수 있으며, 이 러한 컴플리션 네트워크는 예시적으로 고려하여 PoinTr 네트워크 등을 포함할 수 있으나, 이에만 한정되는 것은 아니다. 예시적으로, PoinTr 네트워크의 경우, 학습 데이터로 입력 데이터와의 유사성을 고려하여 ShapeNetCore 를 활용할 수 있다. 이와 관련하여 본원의 일 실시예에 따르면, PoinTr 네트워크는 입력 포인트 클라우드를 다운 샘플링하여 객체의 중심점들을 얻고 중심점 주변의 지역적 특징들을 추출하고, 위치 간의 고유한 관계를 캡처하는 방법인 위치 임 베딩(Positional Embedding)을 통해 위치 정보를 지역적 특징에 추가하고, 인코더-디코더(Encoder-decoder) 구 조를 사용하여 누락된 부분에 대한 포인트를 예측하고, 2차원 그리드를 포인트 클라우드로 재구성하는 기법인 FoldingNet을 활용하여 예측된 포인트들을 기반으로 포인트 클라우드를 복원하도록 동작할 수 있다. 도 6은 컴플리션(Completion) 처리가 적용된 결과를 예시적으로 나타낸 도면이다. 도 6을 참조하면, 모델링 장치에 의해 수행되는 컴플리션(Completion) 처리는 해당 객체가 정형적이고, 대 칭적인 형태를 가질수록 상대적으로 정확한 결과를 얻을 수 있는 것을 확인할 수 있다. 한편, 본원의 일 실시예에 따르면, 모델링 장치는 외부 데이터 없이 입력된 부분 데이터의 기하학적 신호 를 통해 완전한 모양을 만드는 표면 재구성 방법(Surface Reconstruction Methods) 등의 기하학 기반 (Geometry-based) 방식, 입력 데이터와 데이터베이스의 템플릿 데이터와의 매칭을 통해 형상을 복원하는 정렬 기반(Alignment-based) 방식, 포인트 클라우드를 복셀화하고 3차원 컨볼루션 연산을 진행하는 학습 기반 (Learning-based) 방식 등을 포함하는 다양한 방식으로 컴플리션(Completion) 처리를 수행할 수 있다. 도 7은 컴플리션(Completion) 처리 적용 우무에 따른 정렬(Alignment) 수행 결과를 비교하여 나타낸 도면이다. 도 7을 참조하면, 컴플리션 처리가 적용되지 않은 경우 가림 현상과 노이즈로 인해 실제 공간에 배치된 대로 제 대로 배치되지 못했던 객체들이 컴플리션 처리 및 샘플링(노이즈 제거)을 통해 모델과의 방향 비교가 용이해졌 고, 그로 인해 정확한 방향으로 배치될 수 있는 것을 확인할 수 있다. 또한, 모델링 장치는 컴플리션 처리가 적용된 타겟 포인트 클라우드를 포함하는 바운딩 박스와 실제 객체 에 대응하여 생성되는 탐지 오브젝트에 대한 복셀 단위 비교를 통해 탐지 오브젝트의 배치 방향을 결정하는 정 렬(Alignment) 처리를 수행할 수 있다. 도 8은 객체 별 배치 방향을 결정하는 정렬(Alignment)을 수행하지 않은 경우 도출되는 모델링 결과를 예시적으 로 나타낸 도면이다. 도 8을 참조하면, 정렬(Alignment) 과정 없이 3차원 객체 탐지(Object Detection) 결과를 기반으로 모델링을 수 행한 결과, 모델링 된 객체의 위치, 크기는 어느 정도 실제 객체에 부합하도록 배치되었지만, 각 모델링 객체의 방향이 3차원 모델들에서는 모두 같은 방향만을 보고 있어 실제 장면과는 다른 모습을 보이는 것을 확인할 수 있다. 이는, 3차원 객체 탐지 결과에 따라 도출되는 방향 값은 탐지된 바운딩 박스가 Y축 기준으로 얼마나 회전되어있 는가에 대한 값을 의미할 뿐, 바운딩 박스 내부의 모델의 방향에 대한 정보를 포함하지 않기 때문이다. 이와 관련하여 도 9는 동일한 바운딩 박스 내에서 다른 방향으로 배치된 모델을 예시적으로 나타낸 도면이다. 도 9를 참조하면, 두 객체는 같은 바운딩 박스 내에 배치된 객체로 모두 같은 중심점(x, y, z)과 크기(h, w, l), 각도로 배치되어 있음에도 다른 방향으로 배치되어 있다. 3차원 모델은 각각의 모델 좌표계 내에서 같은 방 향으로 배치되어 있기 때문에 같은 모델을 사용하여 모델링 할 경우, 모두 같은 방향으로 배치되며, 이러한 문 제를 해결하기 위해 본원에서 개시하는 모델링 장치는 각 객체에 대응하는 모델(탐지 오브젝트)을 실제 장 면의 객체와 같은 방향으로 배치될 수 있도록 하는 정렬(Alignment) 처리를 수행할 수 있다. 정렬(Alignment) 작업(처리) 단계에서 모델링 장치는 추출된 객체에 대응하는 타겟 포인트 클라우드(컴플 리션 처리가 수행된 포인트 클라우드 데이터) 내에서 추출된 객체의 방향을 결정할 수 있다. 구체적으로 모델링 장치는 실제 객체와 모델을 모두 복셀화하고, 복셀화된 모델을 여러 방향으로 회전하여 복셀화된 객체와 복셀 단위의 비교를 통해 유사도를 측정할 수 있다. 또한, 모델링 장치는 객체 탐지 정보로서 도출된 크기 정보를 기초로 하여 탐지 오브젝트의 크기를 정규화 할 수 있다. 도 10은 탐지 오브젝트의 크기를 고려한 정규화 프로세스 및 탐지 오브젝트의 배치 방향을 결정하는 프로세스를 설명하기 위한 개념도이다. 도 10을 참조하면, 모델링 장치는 장면에서 추출된 객체의 포인트 클라우드는 그대로의 크기를 유지한 채, 원점 좌표계로만 이동하는 좌표계 정규화만을 진행할 수 있다. 모델의 경우에는 마찬가지로 좌표계 정규화를 진 행한 후, 각 점의 최소-최대값을 객체의 최소-최대값으로 맞춰줌으로써 모델을 객체와 같은 크기 비율로 변환할 수 있으며, 이를 수식으로 표현하면 하기 식 2와 같다.[식 2]"}
{"patent_id": "10-2023-0138313", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "즉, 모델링 장치는 복셀 단위의 비교를 용이하게 하기 위한 정규화를 통해 객체의 좌표계와 크기를 맞추고, 정규화 과정에서의 오차를 줄이기 위해 필터링을 통해 포인트 클라우드 노이즈를 제거할 수 있으며, 정 규화 과정에서 형태적 특징보다 크기 비율적 특징이 큰 객체들의 비교를 위해 비교 대상끼리 크기를 맞추는 정 규화 기법을 적용할 수 있으며, 이러한 정규화 후, 모델링 장치는 포인트 클라우드 객체와 배치될 모델(탐 지 오브젝트)을 정해진 각도만큼 회전시켜가며 복셀 단위의 비교를 하여 가장 유사도가 높은 방향으로 탐지 오 브젝트의 가상 공간 상에서의 배치 방향을 선정할 수 있다. 또한, 모델링 장치는 포인트 클라우드 입력에서 객체 추출 정보가 미탐지된 잔여 포인트로 이루어진 클러 스터 각각에 대응하는 미탐지 오브젝트를 생성할 수 있다(Postprocessing). 이와 관련하여, 정렬(Alignment) 단계에서는 포인트 클라우드 데이터에서 3차원 객체 탐지를 통해 탐지된 객체 의 위치에 탐지된 객체의 크기에 부합하는 모델(탐지 오브젝트)을 생성하여 시맨틱한 가상공간을 생성할 수 있 으나, 3차원 객체 탐지 네트워크의 정확도로 인해 탐지되지 않았거나, 학습 데이터셋에 해당 객체 유형이 레이 블로 포함이 되지 않아 탐지되지 못한 객체들도 가상 공간 상에 모델링 되어야 하며, 이를 위하여 후처리 (Postprocessing) 단계에서는 3차원 객체 탐지 단계에서 탐지되지 않은 객체들도 모델링(달리 말해, 미탐지 오 브젝트를 생성)하기 위한 포스트 프로세싱을 적용할 수 있다. 이를 위하여, 모델링 장치는 이하에서 상세히 설명하는 바와 같이 3차원 객체 탐지 단계에서 탐지되지 않 은 객체들에 해당하는 포인트 클라우드의 위치에, 해당 객체의 크기만한 큐브를 생성하여 정확히 어떤 객체가 배치되어 있는지에 대한 정보를 제공하지는 못하지만, 해당 공간에 임의의 객체가 존재한다는 정보를 제공하도 록 가상 공간에 대한 모델링이 이루어지도록 할 수 있다. 도 11은 객체 추출 정보가 미탐지된 잔여 포인트를 예시적으로 나타낸 도면이다. 도 11을 참조하면, 모델링 장치는 포인트 클라우드 입력에서 탐지된 객체들을 추출하고 남은, 달리 말해 탐지되지 않은 객체들만 남게 된 장면에서 먼저 필터링과 샘플링 단계를 거쳐 장면 내 노이즈를 제거할 수 있다. 도 12는 잔여 포인트 중 대상 공간을 이루는 벽면, 바닥면 및 미탐지 오브젝트에 대응하는 포인트를 구분하여 나타낸 도면이다. 도 12를 참조하면, 모델링 장치는 RANSAC(RANdom SAmple consensus) 기반의 평면 추출 등을 적용함으로써 잔여 포인트 중 바닥면 또는 벽면에 대응되는 포인트들을 제거하여 오롯이 탐지되지 않은 객체(달리 말해, 객체 탐지 정보가 미할당된 포인트)들만이 남은 장면을 생성할 수 있다. 도 13은 잔여 포인트를 클러스터 단위로 분류한 결과를 예시적으로 나타낸 도면이다. 도 13을 참조하면, 모델링 장치는 바닥면 또는 벽면에 대응되는 포인트들이 제거된 잔여 포인트들로 이루 어진 장면에서 유클리드 거리(Euclidean Distance)를 이용한 클러스터링(Clustering)을 진행하여 동일한 객체로 취급될 수 있는 포인트들을 군집화 할 수 있다. 즉, 모델링 장치는 포인트 클라우드 입력에서 객체 추출 정보가 미탐지된 잔여 포인트를 클러스터 단위로 분류할 수 있다. 도 14클러스터 단위의 분류 결과를 고려하여 생성되는 미탐지 오브젝트를 예시적으로 나타낸 도면이다. 도 14를 참조하면, 모델링 장치는 분류된 각 클러스터의 클러스터 위치에, 해당 클러스터의 크기만한 큐브 를 생성할 수 있다. 즉, 모델링 장치는 분류된 클러스터 각각에 대응하는 미탐지 오브젝트를 생성할 수 있 으며, 구체적으로 본원의 일 실시예에 따르면, 모델링 장치는 클러스터 각각에 포함된 복수의 포인트가 분포된 공간을 커버하고, 미리 설정된 형상을 가지도록 미탐지 오브젝트를 생성할 수 있다. 도 15는 대상 공간의 벽면 및 바닥면을 반영한 모델링 결과를 예시적으로 나타낸 도면이다. 도 15를 참조하면, 모델링 장치는 미탐지 오브젝트를 클러스터링 결과를 기반으로 하여 모델링 한 후, 추 출된 평면에서 규칙 기반의 방법을 통해 벽과 바닥을 구분하여 모델링할 수 있다. 달리 말해, 모델링 장치는 대상 공간에 대응하여 가상으로 모사되는 가상 공간에 생성된 탐지 오브젝트 및 미탐지 오브젝트를 배치할 수 있다. 구체적으로 모델링 장치는 생성된 탐지 오브젝트 및 미탐지 오브젝트에 대하여, 포인트 클라우드 입력을 이미지로 투사하여 탐지 오브젝트 및 미탐지 오브젝트 각각에 대응하는 텍스처를 결정할 수 있다. 또한, 모델링 장치는 투사된 이미지 내에 빈 픽셀이 존재하면, 해당 빈 픽셀에 대한 보간(Interpolation) 을 수행할 수 있다. 도 16은 포인트 클라우드 입력 및 생성된 오브젝트의 텍스처를 비교하여 나타낸 도면이다. 도 16을 참조하면, 모델링 장치는 텍스처링을 통해 큐브 형태로 생성된 객체와 바닥 및 벽에 텍스처를 맵 핑하여 보다 실제 타겟 공간의 형태와 가까운 현실적인 모델을 생성할 수 있으며, 이를 위하여 모델링 장치 는 바닥면과 벽면 및 해당 객체를 이루고 있는 포인트 클라우드를 프로젝션하여 텍스처를 생성할 수 있다. 이 때, 포인트 클라우드가 프로젝션하는 면을 기준으로 넓고 골고루 분포할수록 정확한 텍스처를 얻을 수 있으 며, 생성한 텍스처는 각 모델의 크기에 맞게 정규화가 진행될 수 있다. 포인트 클라우드는 이미지의 픽셀처럼 균일하지 않기 때문에 포인트 클라우드를 이미지로 프로젝션한 경우, 이미지 내에 빈 픽셀이 발생할 수 있으며, 이를 해결하기 위해 모델링 장치는 빈 픽셀에 대한 보간(Interpolation) 작업을 진행할 수 있으며, 이러한 보간 작업은 주변 픽셀들의 색상의 평균을 사용하는 최근접이웃 보간(Nearest-neighbor Interpolation)방법 등 이 적용될 수 있으나, 이에만 한정되는 것은 아니다. 또한, 모델링 장치는 모델링된 가상 공간을 포함하는 인터페이스를 사용자 단말을 통해 출력할 수 있 다. 이와 관련하여, 가상 공간에 대한 인터페이스를 통해 사용자 단말의 사용자는 가상 공간 내에 배치된 오브젝트(탐지 객체 및 미탐지 객체) 각각을 개별 조작(예를 들면, 위치, 방향 변경 등)을 위한 사용자 입력을 인가하는 등의 방식으로 가상 공간에 대한 자유로운 상호 작용을 수행할 수 있다. 도 17은 본원의 일 실시예에 따른 포인트 클라우드 기반의 시맨틱 모델링 장치에 의해 수행되는 시맨틱 모델링"}
{"patent_id": "10-2023-0138313", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "방식의 전체 파이프라인을 요약하여 나타낸 도면이다. 도 17을 참조하면, 도 17의 (a)는 포인트 클라우드 입력이고, 도 17의 (b)는 입력한 장면에 대한 3차원 Object Detection을 진행한 결과이고, 도 17의 (c)는 포인트 클라우드 입력으로부터 탐지된 객체들만을 추출한 결과를 나타낸 것이고, 도 17의 (d)는 (c)의 탐지된 객체들을 장면에서 제외하고 남은 잔여 포인트들로 이루어진 포인 트 클라우드를 나타낸다. 또한, 도 17의 (e)는 (d)의 탐지되지 않은 객체들의 포인트 클라우드에서 Clustering을 진행한 결과이며, (c)의 탐지된 객체들을 모델로 대체하고 (e)의 탐지되지 않은 객체들을 큐브로 대체하여 모델링한 결과가 도 17의 (f)에 표현되어 있다. 도 18은 본원의 일 실시예에 따른 포인트 클라우드 기반의 시맨틱 모델링 장치의 개략적인 구성도이다. 도 18을 참조하면, 모델링 장치는 객체 탐지부, 데이터 가공부, 정렬부, 후처리 수행부 , 모델링부 및 인터페이스부를 포함할 수 있다. 객체 탐지부는 대상 공간에 존재하는 실제 객체에 대응하도록 계측된 복수의 3차원 점을 포함하는 포인트 클라우드 입력을 획득할 수 있다. 또한, 객체 탐지부는 획득한 포인트 클라우드 입력으로부터 실제 객체에 대응하는 유형 정보, 위치 정보 및 크기 정보를 포함하는 객체 추출 정보를 탐지할 수 있다. 구체적으로 객체 탐지부는 포인트 클라우드 입력을 입력으로 하여 포인트 클라우드 입력 내에 존재하는 객 체 별 바운딩 박스를 식별하고, 바운딩 박스마다의 상기 유형 정보를 추정하도록 미리 구축된 인공지능 기반의 3차원 객체 탐지 알고리즘을 적용함으로써 객체 추출 정보를 도출할 수 있다.데이터 가공부는 객체 별 유형 정보에 따라 미리 파악된 객체 기준 형상을 고려하여, 실제 객체와 관련하 여 포인트 클라우드 입력에 누락된 손실 포인트를 추가하는 컴플리션(Completion) 처리를 수행할 수 있다. 이와 관련하여 본원의 일 실시예에 따르면, 데이터 가공부는 포인트 클라우드 입력에 포함된 복수의 포인 트 중 대상 공간에 존재하는 실제 객체와 무관한 노이즈 포인트를 제거할 수 있다. 정렬부는 데이터 가공부에 의해 컴플리션 처리가 적용된 타겟 포인트 클라우드를 포함하는 바운딩 박 스와 실제 객체에 대응하여 생성되는 탐지 오브젝트에 대한 복셀 단위 비교를 통해 탐지 오브젝트의 배치 방향 을 결정할 수 있다. 또한, 정렬부는 객체 탐지 정보로서 도출된 크기 정보를 기초로 하여 탐지 오브젝트의 크기를 정규화할 수 있다. 후처리 수행부는 포인트 클라우드 입력에서 객체 추출 정보가 미탐지된 잔여 포인트로 이루어진 클러스터 각각에 대응하는 미탐지 오브젝트를 생성할 수 있다. 구체적으로 후처리 수행부는 포인트 클라우드 입력에서 객체 추출 정보가 미탐지된 잔여 포인트를 클러스 터 단위로 분류할 수 있다. 또한, 후처리 수행부는 분류된 클러스터 각각에 대응하는 미탐지 오브젝트를 생성할 수 있다. 이와 관련하여 본원의 일 실시예에 따르면, 후처리 수행부는 클러스터 각각에 포함된 복수의 포인트가 분 포된 공간을 커버하고, 미리 설정된 형상을 가지도록 미탐지 오브젝트를 생성할 수 있다. 모델링부는 대상 공간에 대응하여 가상으로 모사되는 가상 공간에 생성된 탐지 오브젝트 및 미탐지 오브젝 트를 배치할 수 있다. 구체적으로 모델링부는 생성된 탐지 오브젝트 및 미탐지 오브젝트에 대하여, 포인트 클라우드 입력을 이미 지로 투사하여 탐지 오브젝트 및 미탐지 오브젝트 각각에 대응하는 텍스처를 결정할 수 있다. 또한, 모델링부는 투사된 이미지 내에 빈 픽셀이 존재하면, 해당 빈 픽셀에 대한 보간(Interpolation)을 수행할 수 있다. 인터페이스부는 모델링된 가상 공간을 포함하는 인터페이스를 사용자 단말을 통해 출력할 수 있다. 이하에서는 상기에 자세히 설명된 내용을 기반으로, 본원의 동작 흐름을 간단히 살펴보기로 한다. 도 19는 본원의 일 실시예에 따른 포인트 클라우드 기반의 시맨틱 모델링 방법에 대한 동작 흐름도이다. 도 19에 도시된 포인트 클라우드 기반의 시맨틱 모델링 방법은 앞서 설명된 모델링 장치에 의하여 수행될 수 있다. 따라서, 이하 생략된 내용이라고 하더라도 모델링 장치에 대하여 설명된 내용은 포인트 클라우드 기반의 시맨틱 모델링 방법에 대한 설명에도 동일하게 적용될 수 있다. 도 19를 참조하면, 단계 S11에서 객체 탐지부는 대상 공간에 존재하는 실제 객체에 대응하도록 계측된 복 수의 3차원 점을 포함하는 포인트 클라우드 입력을 획득할 수 있다. 다음으로, 단계 S12에서 객체 탐지부는 획득한 포인트 클라우드 입력으로부터 실제 객체에 대응하는 유형 정보, 위치 정보 및 크기 정보를 포함하는 객체 추출 정보를 탐지할 수 있다. 구체적으로 단계 S12에서 객체 탐지부는 포인트 클라우드 입력을 입력으로 하여 포인트 클라우드 입력 내 에 존재하는 객체 별 바운딩 박스를 식별하고, 바운딩 박스마다의 상기 유형 정보를 추정하도록 미리 구축된 인 공지능 기반의 3차원 객체 탐지 알고리즘을 적용함으로써 객체 추출 정보를 도출할 수 있다. 다음으로, 단계 S13에서 데이터 가공부는 객체 별 유형 정보에 따라 미리 파악된 객체 기준 형상을 고려하 여, 실제 객체와 관련하여 포인트 클라우드 입력에 누락된 손실 포인트를 추가하는 컴플리션(Completion) 처리 를 수행할 수 있다. 또한, 본원의 일 실시예에 따르면, 단계 S13에서 데이터 가공부는 포인트 클라우드 입력에 포함된 복수의 포인트 중 대상 공간에 존재하는 실제 객체와 무관한 노이즈 포인트를 제거할 수 있다. 다음으로, 단계 S14에서 정렬부는 단계 S13을 통해 컴플리션 처리가 적용된 타겟 포인트 클라우드를 포함 하는 바운딩 박스와 실제 객체에 대응하여 생성되는 탐지 오브젝트에 대한 복셀 단위 비교를 통해 탐지 오브젝트의 배치 방향을 결정할 수 있다. 또한, 단계 S14에서 정렬부는 객체 탐지 정보로서 도출된 크기 정보를 기초로 하여 탐지 오브젝트의 크기 를 정규화할 수 있다. 다음으로, 단계 S15에서 후처리 수행부는 포인트 클라우드 입력에서 객체 추출 정보가 미탐지된 잔여 포인 트로 이루어진 클러스터 각각에 대응하는 미탐지 오브젝트를 생성할 수 있다. 구체적으로 단계 S15에서 후처리 수행부는 포인트 클라우드 입력에서 객체 추출 정보가 미탐지된 잔여 포 인트를 클러스터 단위로 분류할 수 있다. 또한, 단계 S15에서 후처리 수행부는 분류된 클러스터 각각에 대응하는 미탐지 오브젝트를 생성할 수 있다. 이와 관련하여 본원의 일 실시예에 따르면, 단계 S15에서 후처리 수행부는 클러스터 각각에 포함된 복수의 포인트가 분포된 공간을 커버하고, 미리 설정된 형상을 가지도록 미탐지 오브젝트를 생성할 수 있다. 다음으로, 단계 S16에서 모델링부는 대상 공간에 대응하여 가상으로 모사되는 가상 공간에 생성된 탐지 오 브젝트 및 미탐지 오브젝트를 배치할 수 있다. 구체적으로 단계 S16에서 모델링부는 생성된 탐지 오브젝트 및 미탐지 오브젝트에 대하여, 포인트 클라우 드 입력을 이미지로 투사하여 탐지 오브젝트 및 미탐지 오브젝트 각각에 대응하는 텍스처를 결정할 수 있다. 또한, 단계 S16에서 모델링부는 투사된 이미지 내에 빈 픽셀이 존재하면, 해당 빈 픽셀에 대한 보간 (Interpolation)을 수행할 수 있다. 다음으로, 단계 S17에서 인터페이스부는 모델링된 가상 공간을 포함하는 인터페이스를 사용자 단말을 통해 출력할 수 있다. 상술한 설명에서, 단계 S11 내지 S17은 본원의 구현예에 따라서, 추가적인 단계들로 더 분할되거나, 더 적은 단 계들로 조합될 수 있다. 또한, 일부 단계는 필요에 따라 생략될 수도 있고, 단계 간의 순서가 변경될 수도 있다. 본원의 일 실시예에 따른 포인트 클라우드 기반의 시맨틱 모델링 방법은 다양한 컴퓨터 수단을 통하여 수행될 수 있는 프로그램 명령 형태로 구현되어 컴퓨터 판독 가능 매체에 기록될 수 있다. 상기 컴퓨터 판독 가능 매체 는 프로그램 명령, 데이터 파일, 데이터 구조 등을 단독으로 또는 조합하여 포함할 수 있다. 상기 매체에 기록 되는 프로그램 명령은 본 발명을 위하여 특별히 설계되고 구성된 것들이거나 컴퓨터 소프트웨어 당업자에게 공 지되어 사용 가능한 것일 수도 있다. 컴퓨터 판독 가능 기록 매체의 예에는 하드 디스크, 플로피 디스크 및 자 기 테이프와 같은 자기 매체(magnetic media), CD-ROM, DVD와 같은 광기록 매체(optical media), 플롭티컬 디 스크(floptical disk)와 같은 자기-광 매체(magneto-optical media), 및 롬(ROM), 램(RAM), 플래시 메모리 등 과 같은 프로그램 명령을 저장하고 수행하도록 특별히 구성된 하드웨어 장치가 포함된다. 프로그램 명령의 예에 는 컴파일러에 의해 만들어지는 것과 같은 기계어 코드뿐만 아니라 인터프리터 등을 사용해서 컴퓨터에 의해서 실행될 수 있는 고급 언어 코드를 포함한다. 상기된 하드웨어 장치는 본 발명의 동작을 수행하기 위해 하나 이 상의 소프트웨어 모듈로서 작동하도록 구성될 수 있으며, 그 역도 마찬가지이다. 또한, 전술한 포인트 클라우드 기반의 시맨틱 모델링 방법은 기록 매체에 저장되는 컴퓨터에 의해 실행되는 컴 퓨터 프로그램 또는 애플리케이션의 형태로도 구현될 수 있다."}
{"patent_id": "10-2023-0138313", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "전술한 본원의 설명은 예시를 위한 것이며, 본원이 속하는 기술분야의 통상의 지식을 가진 자는 본원의 기술적 사상이나 필수적인 특징을 변경하지 않고서 다른 구체적인 형태로 쉽게 변형이 가능하다는 것을 이해할 수 있을 것이다. 그러므로 이상에서 기술한 실시예들은 모든 면에서 예시적인 것이며 한정적이 아닌 것으로 이해해야만 한다. 예를 들어, 단일형으로 설명되어 있는 각 구성 요소는 분산되어 실시될 수도 있으며, 마찬가지로 분산된 것으로 설명되어 있는 구성 요소들도 결합된 형태로 실시될 수 있다. 본원의 범위는 상기 상세한 설명보다는 후술하는 특허청구범위에 의하여 나타내어지며, 특허청구범위의 의미 및 범위 그리고 그 균등 개념으로부터 도출되는 모든 변경 또는 변형된 형태가 본원의 범위에 포함되는 것으로 해 석되어야 한다."}
{"patent_id": "10-2023-0138313", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본원의 일 실시예에 따른 포인트 클라우드 기반의 시맨틱 모델링 장치를 포함하는 시맨틱 모델링 시스템 의 개략적인 구성도이다. 도 2는 본원의 일 실시예에 따른 포인트 클라우드 기반의 시맨틱 모델링 장치에 의해 수행되는 주요 프로세스를 설명하기 위한 개념도이다. 도 3은 포인트 클라우드 입력에 대한 필터링 적용 결과를 예시적으로 나타낸 도면이다. 도 4는 포인트 클라우드 입력으로부터 도출된 객체 추출 정보를 예시적으로 나타낸 도면이다. 도 5는 포인트 클라우드 입력으로부터 도출된 3차원 객체를 각 객체 별로 구분하여 나타낸 도면이다. 도 6은 컴플리션(Completion) 처리가 적용된 결과를 예시적으로 나타낸 도면이다. 도 7은 컴플리션(Completion) 처리 적용 우무에 따른 정렬(Alignment) 수행 결과를 비교하여 나타낸 도면이다. 도 8은 객체 별 배치 방향을 결정하는 정렬(Alignment)을 수행하지 않은 경우 도출되는 모델링 결과를 예시적으 로 나타낸 도면이다. 도 9는 동일한 바운딩 박스 내에서 다른 방향으로 배치된 모델을 예시적으로 나타낸 도면이다. 도 10은 탐지 오브젝트의 크기를 고려한 정규화 프로세스 및 탐지 오브젝트의 배치 방향을 결정하는 프로세스를 설명하기 위한 개념도이다. 도 11은 객체 추출 정보가 미탐지된 잔여 포인트를 예시적으로 나타낸 도면이다. 도 12는 잔여 포인트 중 대상 공간을 이루는 벽면, 바닥면 및 미탐지 오브젝트에 대응하는 포인트를 구분하여 나타낸 도면이다. 도 13은 잔여 포인트를 클러스터 단위로 분류한 결과를 예시적으로 나타낸 도면이다. 도 14클러스터 단위의 분류 결과를 고려하여 생성되는 미탐지 오브젝트를 예시적으로 나타낸 도면이다.도 15는 대상 공간의 벽면 및 바닥면을 반영한 모델링 결과를 예시적으로 나타낸 도면이다. 도 16은 포인트 클라우드 입력 및 생성된 오브젝트의 텍스처를 비교하여 나타낸 도면이다. 도 17은 본원의 일 실시예에 따른 포인트 클라우드 기반의 시맨틱 모델링 장치에 의해 수행되는 시맨틱 모델링"}
{"patent_id": "10-2023-0138313", "section": "도면", "subsection": "도면설명", "item": 2, "content": "방식의 전체 파이프라인을 요약하여 나타낸 도면이다. 도 18은 본원의 일 실시예에 따른 포인트 클라우드 기반의 시맨틱 모델링 장치의 개략적인 구성도이다. 도 19는 본원의 일 실시예에 따른 포인트 클라우드 기반의 시맨틱 모델링 방법에 대한 동작 흐름도이다."}
