{"patent_id": "10-2019-0072336", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2019-0080834", "출원번호": "10-2019-0072336", "발명의 명칭": "사투리 음소 적응 학습 시스템 및 방법", "출원인": "엘지전자 주식회사", "발명자": "이지혜"}}
{"patent_id": "10-2019-0072336", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "사투리 음소 적응 학습 시스템에 의해 수행되는 방법으로서,수집된 음성 데이터 중에서 사투리가 포함된 음성 데이터를 선별하고, 텍스트 데이터를 전사하는 단계;상기 텍스트 데이터 및 사투리가 포함된 음성 데이터를 이용하여 사투리 코퍼스(corpus)를 생성하는 단계; 및상기 사투리 코퍼스를 이용하여 음향 모델 및 언어 모델을 생성하는 단계를 포함하되,상기 음향 모델 및 언어모델을 생성하는 단계는,사투리 음소와 이의 빈도수를 추출하고 이들에 기반하여 음소 적응 모델을 학습시키는 단계를 포함하는,사투리 음소 적응 학습 방법."}
{"patent_id": "10-2019-0072336", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1 항에 있어서,음성 인식 서비스 도메인을 통해 음성 데이터를 수집하는 단계를 더 포함하는,사투리 음소 적응 학습 방법."}
{"patent_id": "10-2019-0072336", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 2 항에 있어서,상기 음성 데이터를 수집하는 단계는,각종 전자 기기의 음성 입력/출력 인터페이스를 통해 지역적으로 서로 다른 사투리를 사용하는 사용자의 음성데이터를 수집하는, 사투리 음소 적응 학습 방법."}
{"patent_id": "10-2019-0072336", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 1 항에 있어서,상기 텍스트 데이터를 전사하는 단계는,수집된 음성 데이터에서 이상 발성을 제거하는 단계;상기 음성 데이터의 신뢰도 측정을 이용하여 사투리가 포함된 음성 데이터를 선택하는 단계; 및상기 사투리가 포함된 음성 데이터로부터 전사 데이터를 얻는 단계를 포함하는,사투리 음소 적응 학습 방법."}
{"patent_id": "10-2019-0072336", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제 1 항에 있어서,상기 사투리 코퍼스를 생성하는 단계는,상기 사투리가 포함된 음성 데이터에서 특징(feature)을 추출하는 단계;추출된 상기 특징을 이용하여 상기 사투리가 포함된 음성 데이터에 대해 유사 사투리 클러스터링을 수행하는 단계;유사 사투리 클러스터에서 핵심 사투리를 추출하는 단계; 및추출된 상기 핵심 사투리를 이용하여 사투리 코퍼스를 표준화하는 단계를 포함하고,공개특허 10-2019-0080834-3-상기 음향 모델 및 언어모델을 생성하는 단계는,상기 핵심 사투리 음소에 대해 사투리 음소와 이의 빈도수를 추출하고 이들에 기반하여 음소 적응모델을 학습시키는,사투리 음소 적응 학습 방법."}
{"patent_id": "10-2019-0072336", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제 5 항에 있어서,상기 사투리가 포함된 음성 데이터에서 특징을 추출하는 단계는,사투리의 발음열의 특징, 어휘적인 특징, 도메인 특징 및 빈도수 특징 중에서 적어도 하나를 추출하는,사투리 음소 적응 학습 방법."}
{"patent_id": "10-2019-0072336", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제 6 항에 있어서,상기 도메인 특징은,사용자에게 음성 인식 서비스를 제공하는 전자 기기의 종류, 상기 전자 기기가 위치하는 지역 및 상기 전자 기기를 사용하는 사용자의 연령대에 관한 정보를 포함하는,사투리 음소 적응 학습 방법."}
{"patent_id": "10-2019-0072336", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제 5 항에 있어서,상기 유사 사투리 클러스터링을 수행하는 단계는,비지도 학습 방식에 따라 특징 간 가중치 연산을 통해 특징 간 유사도를 측정하고, 임계값 대비 높은 유사도를갖는 사투리를 클러스터링하는,사투리 음소 적응 학습 방법."}
{"patent_id": "10-2019-0072336", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제 5 항에 있어서,상기 유사 사투리 클러스터에서 핵심 사투리를 추출하는 단계는,클러스터 내 빈도수 특징이 높은 상위 n 개의 객체를 추출하고, 클러스터 내 다른 객체들과 특징 유사도 계산을통해 핵심 객체를 추출하는,사투리 음소 적응 학습 방법."}
{"patent_id": "10-2019-0072336", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제 5 항에 있어서,상기 사투리 코퍼스를 표준화하는 단계는,기존의 사투리를 핵심 객체 사투리로 치환하고, 원 사투리 문장과 치환된 문장의 유사도 측정을 통해 검증하는,사투리 음소 적응 학습 방법."}
{"patent_id": "10-2019-0072336", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "수집된 음성 데이터 중에서 사투리가 포함된 음성 데이터로부터 텍스트 데이터를 전사하는 데이터 전사모듈;상기 텍스트 데이터 및 사투리가 포함된 음성 데이터를 이용하여 사투리 코퍼스(corpus)를 생성하는 코퍼스 생성모듈;공개특허 10-2019-0080834-4-상기 사투리 코퍼스를 이용하여 음향 모델 및 언어 모델을 각각 생성하는 음향 모델 생성모듈 및 언어 모델 생성모듈; 및학습된 상기 음향 모델 및 언어 모델을 이용하여 음성을 인식하는 음성 인식 엔진을 포함하되,상기 음향 모델 생성모듈은,사투리 음소와 이의 빈도수를 추출하고 이들에 기반하여 음소 적응 모델을 학습시키는,사투리 음소 적응 학습 시스템."}
{"patent_id": "10-2019-0072336", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제 11 항에 있어서,상기 음향 모델 생성모듈은,사투리가 포함된 음성 데이터에서 사투리 음소를 추출하는 제1 모듈;상기 사투리 음소의 빈도수를 추출하는 제2 모듈; 및상기 사투리 음소와 상기 빈도수를 이용하여 음소 적응모델을 학습시키는 제3 모듈을 포함하는,사투리 음소 적응 학습 시스템."}
{"patent_id": "10-2019-0072336", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제 11 항에 있어서,각종 전자 기기의 음성 입력/출력 인터페이스를 통해 지역적으로 서로 다른 사투리를 사용하는 사용자의 음성데이터를 수집하는 데이터 수집모듈을 더 포함하는,사투리 음소 적응 학습 시스템."}
{"patent_id": "10-2019-0072336", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제 11 항에 있어서,상기 데이터 전사모듈은,수집된 음성 데이터에서 이상 발성을 제거하고, 상기 음성 데이터의 신뢰도 측정을 이용하여 사투리가 포함된음성 데이터를 선택하고, 상기 사투리가 포함된 음성 데이터로부터 전사 데이터를 생성하는,사투리 음소 적응 학습 시스템."}
{"patent_id": "10-2019-0072336", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제 11 항에 있어서,상기 코퍼스 생성모듈은,상기 사투리가 포함된 음성 데이터에서 특징을 추출하는 특징추출 모듈;추출된 상기 특징을 이용하여 상기 사투리가 포함된 음성 데이터에 대해 유사 사투리 클러스터링을 수행하는 딥러닝 모듈;유사 사투리 클러스터에서 핵심 사투리를 추출하는 핵심 사투리추출 모듈; 및추출된 상기 핵심 사투리를 이용하여 사투리 코퍼스를 표준화하는 코퍼스 표준화 모듈을 포함하는,사투리 음소 적응 학습 시스템."}
{"patent_id": "10-2019-0072336", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제 15 항에 있어서,상기 특징추출 모듈은,공개특허 10-2019-0080834-5-사투리의 발음열의 특징, 어휘적인 특징, 도메인 특징 및 빈도수 특징 중에서 적어도 하나를 추출하는,사투리 음소 적응 학습 시스템."}
{"patent_id": "10-2019-0072336", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제 16 항에 있어서,상기 도메인 특징은,사용자에게 음성 인식 서비스를 제공하는 전자 기기의 종류, 상기 전자 기기가 위치하는 지역 및 상기 전자 기기를 사용하는 연령대에 관한 정보를 포함하는,사투리 음소 적응 학습 시스템."}
{"patent_id": "10-2019-0072336", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제 15 항에 있어서,상기 딥 러닝 모듈은,비지도 학습 방식에 따라 특징 간 가중치 연산을 통해 특징 간 유사도를 측정하고, 임계값 대비 높은 유사도를갖는 사투리를 클러스터링하는,사투리 음소 적응 학습 시스템."}
{"patent_id": "10-2019-0072336", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제 15 항에 있어서,상기 핵심 사투리추출 모듈은,클러스터 내 빈도수 특징이 높은 상위 n 개의 객체를 추출하고, 클러스터 내 다른 객체들과 특징 유사도 계산을통해 핵심 객체를 추출하는,사투리 음소 적응 학습 시스템."}
{"patent_id": "10-2019-0072336", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제 15 항에 있어서,상기 코퍼스 표준화 모듈은,기존의 사투리를 핵심 사투리로 치환하고, 원 사투리 문장과 치환된 문장의 유사도 측정을 통해 검증하는,사투리 음소 적응 학습 시스템."}
{"patent_id": "10-2019-0072336", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 사투리 음소 적응 학습 방법 및 시스템을 개시한다. 사투리 음소 적응 학습 방법은, 텍스트 데이터 전 사; 텍스트 데이터 및 사투리가 포함된 음성 데이터 기반의 사투리 코퍼스 생성 및 사투리 코퍼스를 이용한 음향 모델 및 언어 모델을 생성을 포함하되, 음향 모델 및 언어 모델의 생성은, 사투리 음소와 이의 빈도수를 추출하 고 이들을 이용하는 인공지능(AI) 알고리즘에 의한 기계학습(Machine Learning)에 의해 수행될 수 있다. 본 발명 에 따르면, 사용자는 5G 이동통신의 eMBB, URLLC, mMTC 기술을 이용하여 향상된 사투리 인식의 서비스 이용이 가 능하다."}
{"patent_id": "10-2019-0072336", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 사투리 음소 적응 학습 시스템 및 방법에 관한 것으로, 더욱 상세하게는 학습에 필요한 사투리 데이 터를 선별하고, 텍스트를 반자동으로 정제하고, 사투리 음소를 이용하여 모델을 적응 학습시키는 시스템 및 방 법에 관한 것이다."}
{"patent_id": "10-2019-0072336", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "음성 인식이란 사람과 기계 사이의 대화 중에 사람이 내는 음성의 인식(recognition), 해석(analysis) 및 이해 (understanding)를 포함하는 개념으로서, 음성 인식을 위해서 다양한 기술들이 사용된다. 음성 인식 과정은 크게 세 가지 단계로 구성될 수 있다. 우선 입력된 음성 중에서 실제 사람이 발성한 음성의 특징이 추출된다. 그리고 추출된 음성의 특징을 기반으로 음향 모델과의 유사도 측정을 통해 음성의 패턴이 분 류된다. 그리고 인식된 패턴에서 언어 모델을 이용하여 음성의 특징들이 언어로 처리되고 최종적으로 음성이 문 장으로 인식된다.사투리는 한 언어 내부에서 지역과 사회적 요인에 따라 변화된 언어적인 변이체를 말한다. 사투리는 독자적인 체계와 역사를 지니고 있어서 한 언어의 다양성을 보여주는 귀중한 문화 유산에 해당한다. 사투리는 언어학적으 로는 한 언어의 변이와 역사를 보여주는 자료이고, 문화적으로는 언어에 투영된 지역 사람들의 삶의 모습을 나 타내는 자료이다. 그리고 사투리는 지금도 표준어와 더불어 해당 지역의 사람들에 의해 사용되고 있다. 특정 언어로 발화되는 음성을 인식하는 음성 인식 시스템은 해당 언어의 표준어에 기초하여 만들어지기 때문에, 방언 즉 사투리를 인식하는 능력은 현저히 떨어질 수밖에 없다. 대화체 연속 음성 인식을 위한 의사형태소 기반 다중발음사전 구축방법에 관한 선행기술 1에 개시되어 있다. 그러나 선행기술 1에 따르면 대표 어휘만을 이용하여 언어모델 및 어휘사전을 구성하므로 사투리를 반영하지 못 하는 단점이 있다. 또한, 사투리가 포함된 음성이 입력되는 경우, 사투리가 갖는 음색 노이즈 및 음소 노이즈가 제거된 상태에서 사투리를 표준어로 고쳐서 인식하는 기술이 선행기술 2에 개시되어 있다. 그러나 음색만으로 표준어와 사투리가 서로 구별되지 않는 경우가 있다. 선행기술 2에 따르면 사투리가 포함된 음성에서 음소 노이즈 제거만으로 사투리가 표준어로 단순 변환되지 않기 때문에 사투리와 표준어 인식 능력이 동시에 저하되는 문제점이 있다. 선행기술문헌 특허문헌 (특허문헌 0001) 선행기술 1: 한국 공개특허공보 제10-2005-0036303호(2005.04.20. 공개) (특허문헌 0002) 선행기술 2: 한국 등록특허공보 제10-1836430호(2018.03.02. 등록)"}
{"patent_id": "10-2019-0072336", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명의 일 과제는, 사투리에 포함된 음소 적응 학습을 통해 사투리를 음운학적으로 처리함으로써 표준어와 관련시켜 처리하려 했던 종래 기술의 문제점을 해결하는 것이다. 본 발명의 일 과제는, 표준어 말뭉치를 기준으로 띄어쓰기를 판단하여 사투리를 인식했던 종래 기술의 문제점을 해결하는 것이다. 본 발명의 일 과제는, 사투리를 그대로 인식하지 않고 표준어로 변환함으로써 사투리와 표준어의 구별에 있어서 정확하지 않았던 종래 기술의 문제점을 해결하는 것이다. 본 발명의 일 과제는, 음성 데이터 처리에 사람이 수동으로 전사하여 많은 시간과 비용이 들었던 종래 기술의 문제점을 해결하는 것이다. 본 발명의 과제는 이상에서 언급한 과제에 한정되지 않으며, 언급되지 않은 본 발명의 다른 과제 및 장점들은 하기의 실시 예에 의해 보다 분명하게 이해될 것이다. 또한, 본 발명의 과제 및 장점들은 특허 청구 범위에 나 타낸 수단 및 그 조합에 의해 실현될 수 있음을 알 수 있을 것이다."}
{"patent_id": "10-2019-0072336", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 일 실시 예에 따른 사투리 음소 적응 학습 방법은 사투리 음소 적응 학습 시스템에 의해 수행되는 것 을 특징으로 한다. 본 발명의 일 실시 예에 따른 사투리 음소 적응 학습 방법은, 수집된 음성 데이터 중에서 사투리가 포함된 음성 데이터를 선별하고, 텍스트 데이터를 전사하는 단계, 상기 텍스트 데이터 및 사투리가 포함된 음성 데이터를 이 용하여 사투리 코퍼스(corpus)를 생성하는 단계 및 사투리 코퍼스를 이용하여 음향 모델 및 언어 모델을 생성하 는 단계를 포함하되, 음향 모델 및 언어모델을 생성하는 단계는, 사투리 음소와 이의 빈도수를 추출하고 이들에 기반하여 음소 적응 모델을 학습시키는 단계를 포함한다.또한, 음성 인식 서비스 도메인을 통해 음성 데이터를 수집하는 단계를 더 포함할 수 있다. 또한, 음성 데이터를 수집하는 단계는, 각종 전자 기기의 음성 입력/출력 인터페이스를 통해 지역적으로 서로 다른 사투리를 사용하는 사용자의 음성 데이터를 수집할 수 있다. 또한, 상기 텍스트 데이터를 전사하는 단계는, 수집된 음성 데이터에서 이상 발성을 제거하는 단계, 음성 데이 터의 신뢰도 측정을 이용하여 사투리가 포함된 음성 데이터를 선택하는 단계 및 사투리가 포함된 음성 데이터로 부터 전사 데이터를 얻는 단계를 포함할 수 있다. 또한, 사투리 코퍼스를 생성하는 단계는, 사투리가 포함된 음성 데이터에서 특징(feature)을 추출하는 단계, 추 출된 상기 특징을 이용하여 상기 사투리가 포함된 음성 데이터에 대해 유사 사투리 클러스터링을 수행하는 단계, 유사 사투리 클러스터에서 핵심 사투리를 추출하는 단계 및 추출된 상기 핵심 사투리를 이용하여 사투리 코퍼스를 표준화하는 단계를 포함하고, 음향 모델 및 언어모델을 생성하는 단계는, 핵심 사투리 음소에 대해 사 투리 음소와 이의 빈도수를 추출하고 이들에 기반하여 음소 적응모델을 학습시킬 수 있다. 또한, 사투리가 포함된 음성 데이터에서 특징을 추출하는 단계는, 사투리의 발음열의 특징, 어휘적인 특징, 도 메인 특징 및 빈도수 특징 중에서 적어도 하나를 추출할 수 있다. 또한, 도메인 특징은, 사용자에게 음성 인식 서비스를 제공하는 전자 기기의 종류, 상기 전자 기기가 위치하는 지역 및 상기 전자 기기를 사용하는 사용자의 연령대에 관한 정보를 포함할 수 있다. 또한, 유사 사투리 클러스터링을 수행하는 단계는, 비지도 학습 방식에 따라 특징 간 가중치 연산을 통해 특징 간 유사도를 측정하고, 임계값 대비 높은 유사도를 갖는 사투리를 클러스터링할 수 있다. 또한, 유사 사투리 클러스터에서 핵심 사투리를 추출하는 단계는, 클러스터 내 빈도수 특징이 높은 상위 n 개의 객체를 추출하고, 클러스터 내 다른 객체들과 특징 유사도 계산을 통해 핵심 객체를 추출할 수 있다. 또한, 사투리 코퍼스를 표준화하는 단계는, 기존의 사투리를 핵심 객체 사투리로 치환하고, 원 사투리 문장과 치환된 문장의 유사도 측정을 통해 검증할 수 있다. 본 발명의 일 실시 예에 따른 사투리 음소 적응 학습 시스템은, 수집된 음성 데이터 중에서 사투리가 포함된 음 성 데이터로부터 텍스트 데이터를 전사하는 데이터 전사모듈 텍스트 데이터 및 사투리가 포함된 음성 데이터를 이용하여 사투리 코퍼스(corpus)를 생성하는 코퍼스 생성모듈 사투리 코퍼스를 이용하여 음향 모델 및 언어 모 델을 각각 생성하는 음향 모델 생성모듈 및 언어 모델 생성모듈; 및 학습된 상기 음향 모델 및 언어 모델을 이 용하여 음성을 인식하는 음성 인식 엔진을 포함하되, 음향 모델 생성모듈은, 사투리 음소와 이의 빈도수를 추출 하고 이들에 기반하여 음소 적응 모델을 학습시킨다. 또한, 음향 모델 생성모듈은, 사투리가 포함된 음성 데이터에서 사투리 음소를 추출하는 제1 모듈, 사투리 음소 의 빈도수를 추출하는 제2 모듈 및 사투리 음소와 상기 빈도수를 이용하여 음소 적응모델을 학습시키는 제3 모 듈을 포함할 수 있다. 또한, 각종 전자 기기의 음성 입력/출력 인터페이스를 통해 지역적으로 서로 다른 사투리를 사용하는 사용자의 음성 데이터를 수집하는 데이터 수집모듈을 더 포함할 수 있다. 또한, 데이터 전사모듈은, 수집된 음성 데이터에서 이상 발성을 제거하고, 상기 음성 데이터의 신뢰도 측정을 이용하여 사투리가 포함된 음성 데이터를 선택하고, 상기 사투리가 포함된 음성 데이터로부터 전사 데이터를 생 성할 수 있다. 또한, 코퍼스 생성모듈은, 사투리가 포함된 음성 데이터에서 특징을 추출하는 특징추출 모듈, 추출된 특징을 이 용하여 사투리가 포함된 음성 데이터에 대해 유사 사투리 클러스터링을 수행하는 딥 러닝 모듈, 유사 사투리 클 러스터에서 핵심 사투리를 추출하는 핵심 사투리추출 모듈 및 추출된 핵심 사투리를 이용하여 사투리 코퍼스를 표준화하는 코퍼스 표준화 모듈을 포함할 수 있다. 또한, 특징추출 모듈은, 사투리의 발음열의 특징, 어휘적인 특징, 도메인 특징 및 빈도수 특징 중에서 적어도 하나를 추출할 수 있다. 또한, 도메인 특징은, 사용자에게 음성 인식 서비스를 제공하는 전자 기기의 종류, 상기 전자 기기가 위치하는 지역 및 상기 전자 기기를 사용하는 연령대에 관한 정보를 포함할 수 있다. 또한, 딥 러닝 모듈은, 비지도 학습 방식에 따라 특징 간 가중치 연산을 통해 특징 간 유사도를 측정하고, 임계 값 대비 높은 유사도를 갖는 사투리를 클러스터링할 수 있다. 또한, 핵심 사투리추출 모듈은, 클러스터 내 빈도수 특징이 높은 상위 n 개의 객체를 추출하고, 클러스터 내 다 른 객체들과 특징 유사도 계산을 통해 핵심 객체를 추출할 수 있다. 또한, 코퍼스 표준화 모듈은, 기존의 사투리를 핵심 사투리로 치환하고, 원 사투리 문장과 치환된 문장의 유사 도 측정을 통해 검증할 수 있다."}
{"patent_id": "10-2019-0072336", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명에 의하면, 사투리에 포함된 음소 적응 학습을 통해 사투리를 음운학적으로 처리함으로써 사투리 인식률 을 향상시킬 수 있다. 또한, 표준어를 거치지 않고서도 사투리가 포함된 음성 그대로를 인식할 수 있으므로, 사투리를 사용한 자연어 처리가 가능하다. 또한, 데이터 마이닝에 인공지능을 활용함으로써 데이터 정제가 반자동의 방법으로 수행될 수 있다. 또한, 사투리를 포함하는 코퍼스 표준화를 통해 사투리 인식에 소요되는 시간을 줄일 수 있다."}
{"patent_id": "10-2019-0072336", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 첨부된 도면을 참조하여 본 명세서에 개시된 실시 예를 상세히 설명하되, 도면 부호에 관계없이 동일하거 나 유사한 구성요소는 동일한 참조 번호를 부여하고 이에 대한 중복되는 설명은 생략하기로 한다. 이하의 설명 에서 사용되는 구성요소에 대한 접미사 '모듈' 및 '부'는 명세서 작성의 용이함만이 고려되어 부여되거나 혼용 되는 것으로서, 그 자체로 서로 구별되는 의미 또는 역할을 갖는 것은 아니다. 또한, 본 명세서에 개시된 실시 예를 설명함에 있어서 관련된 공지 기술에 대한 구체적인 설명이 본 명세서에 개시된 실시 예의 요지를 흐릴 수 있다고 판단되는 경우 그 상세한 설명을 생략한다. 또한, 첨부된 도면은 본 명세서에 개시된 실시 예를 쉽게 이 해할 수 있도록 하기 위한 것일 뿐, 첨부된 도면에 의해 본 명세서에 개시된 기술적 사상이 제한되지 않으며, 본 발명의 사상 및 기술 범위에 포함되는 모든 변경, 균등물 내지 대체물을 포함하는 것으로 이해되어야 한다. 제1, 제2 등과 같이 서수를 포함하는 용어는 다양한 구성요소들을 설명하는데 사용될 수 있지만, 상기 구성요소 들은 상기 용어들에 의해 한정되지는 않는다. 상기 용어들은 하나의 구성요소를 다른 구성요소로부터 구별하는 목적으로만 사용된다. 어떤 구성요소가 다른 구성요소에 '연결되어' 있다거나 '접속되어' 있다고 언급된 때에는, 그 다른 구성요소에 직접적으로 연결되어 있거나 또는 접속되어 있을 수도 있지만, 중간에 다른 구성요소가 존재할 수도 있다고 이 해되어야 할 것이다. 반면에, 어떤 구성요소가 다른 구성요소에 '직접 연결되어' 있다거나 '직접 접속되어' 있 다고 언급된 때에는, 중간에 다른 구성요소가 존재하지 않는 것으로 이해되어야 할 것이다. 지능형 가상 비서(Intelligent Virtual Assistant)란 개인 비서처럼 사용자가 요구하는 작업을 처리하고 사용자 에게 특화된 서비스를 제공하는 소프트웨어 에이전트이다. 최근 지능형 가상 비서는 인공지능 엔진과 음성 인식 을 기반으로 사용자에게 맞춤 정보를 제공하고, 사용자의 음성 명령에 따라 일정 관리, 이메일 전송, 식당 예약 등 여러 기능을 수행한다. 소위 말하는 스마트 스피커로 구현된 지능형 가상 비서가 제공하는 서비스의 종류가 전자 기기의 기능 제어, 날 씨 등의 정보 제공 및 채팅에 머물고 있지만, 그 서비스의 범위가 점차 넓어지고 있다. 스마트 스피커가 제공하는 다양한 음성 인식 관련 서비스 중에서 독거 노인 관련 서비스도 중요한 자리를 차지 하고 있다. 스마트 스피커는 점점 늘어가는 독거 노인들의 건강 및 복지 관리를 위한 수단으로 이용될 수 있다. 대화 및 감시 기능을 통해 스마트 스피커는 때로는 복지 공무원 역할을, 때로는 상담사 역할을, 때로는 긴급 구 조 안내 역할을 수행할 수 있다. 그런데 스마트 스피커가 음성 인식을 통해 독거 노인들의 상태를 인식하는데 가장 걸림돌이 되는 것은 독거 노인들이 많이 사용하고 있는 지역적 특징이 강한 사투리이다. 한국 내에서 사용되는 사투리 중에서 가장 많은 비중을 차지하는 사투리는 경상도와 전라도 사투리이다. 그리고 사투리 중에서 대화자 사이에서 의사 소통과 관련된 구어(spoken language) 사투리는 연령대가 높을수록 사용 빈도가 높다. 본 발명은 사용자 단말, 스마트 스피커와 같은 각종 전자 기기에 모듈 형태로 구현될 수 있는 음 성 인식을 위한 입력/출력 인터페이스를 통해 서비스될 수 있는 음성 인식 서비스에서 사투리 인식을 위한 사투 리 음소 적응 학습 시스템 및 방법에 관한 것이다. 도 1은 본 발명의 일 실시 예에 따른 사투리 음소 적응 학습 시스템을 포함하는 네트워크 환경의 예시도이다. 도 1을 참조하면, 음성 인식 시스템과 이의 구축을 돕는 본 발명의 일 실시 예에 따른 사투리 음소 적응 학습 시스템, 음성 인터페이스를 통해 제어될 수 있는 각종 스마트 전자 기기 및 이들을 서로 연결시 켜 통신이 가능하게 하는 네트워크가 묘사되어 있다. 음성 인식 시스템은 각종 음성을 인식하고, 인식된 음성에 기반하여 자연어 처리 과정을 통해 말과 문자 형태로 처리 결과를 출력하는, 복합적인 기능을 수행하는 시스템이다. 음성 인식 시스템은 각종 음성 인식 서비스 도메인을 통해 스마트 전자 기기에 음성 인식 서비스를 제공할 수 있다. 여기서 음성 인식 서비스는 사람의 음성을 인식하는 것에 한정되지 않고 자연어 처리를 통한 인공지능 비서 기능과 음성 인터페이스를 통한 전자 기기 제어 서비스를 포함할 수 있다. 음성 인식 시스템은 음성 인식, 자연어 이해, 자연어 생성 및 음성 합성을 포함하는 음성 처리 전체 과정 을 수행할 수 있도록 구성될 수 있다. 음성 인식 시스템은 컴퓨팅 장치와 같은 하나의 서버 형태로 구성되 거나, 음성 인식, 자연어 이해, 자연어 생성 및 음성합성 각각에 대해 하나 이상의 서버로 구성될 수 있다. 사투리 음소 적응 학습 시스템은 사투리를 포함하는 데이터를 처리하고, 처리된 데이터를 이용하여 사투리 인식에 필요한 모델을 학습시키는 시스템이다. 사투리 음소 적응 학습 시스템은 해당 도메인을 통해 사용자의 음성, 예를 들어 사투리가 포함된 음성 데 이터를 수집할 수 있다. 즉 사투리 음소 적응 학습 시스템은 사용자 로그데이터를 통해 음성 데이터를 수 집할 수 있다. 그리고 각 도메인에서 수집된 사투리가 포함된 음성 데이터, 즉 사투리 데이터는 음향 모델 및 언어 모델을 학습시키는 훈련용 데이터로 활용될 수 있다. 특히 해당 도메인에 관한 각종 정보 및 전자 기기 가 갖는 지역 정보는 사투리 데이터를 지역별로 분류하는 데에 지침이 될 수 있다. 사투리 음소 적응 학습 시스템은 도메인 별로 또는 지역 별로 구별되는 특징을 갖는 사투리 데이터를 수집 할 수 있다. 사투리 데이터를 음성 인식 시스템 서버로 전송하는 스마트 전자 기기의 네트워크 접속 주소, 또는 하드웨어 정보를 통해 해당 스마트 전자 기기가 위치해 있는 지역이 파악될 수 있다. 따라서, 경기도, 전라도, 경상도, 충청도, 강원도, 및 제주도 등의 각 지역의 사투리 데이터는 지역별로 선별되어 수집 될 수 있다. 이하 본 발명의 일 실시 예에 따른 사투리 음소 적응 학습 시스템에 대해 자세히 설명하기로 한다. 전자 기기는 음성 입력/출력 인터페이스를 포함하고, 사물인터넷(Internet of thing)으로서 임베디드 시스 템(Embedded System)을 포함하도록 구성될 수 있다. 전자 기기의 예로는 인공지능 비서 기능을 수행하는 사용자 단말, 타 전자 기기를 네트워크에 연결시키는 허브 역할을 하는 인공지능 스피커,로봇 청소기, 공조기 및 냉장고와 같은 사물인터넷(IoT)에 해당하는 각종 전자 기기가 있 을 수 있다. 다만, 전자 기기의 예가 도 1에 묘사된 것에 한정되는 것은 아니다. 전자 기기는 해당 도메인을 통해 음성 인식 시스템에 연결하여 음성 인식 서비스를 이용할 수 있다. 사용자 단말을 통해 제공되는 대표적인 음성 인식 서비스는 애플리케이션에 의한 인공지능 비서 기능이다. 인공지능 스피커는, 인공지능(AI) 알고리즘을 이용하는 에이전트 기능의 스피커로서 음성 입출력 기능이 없는 전자 기기를 제어하는 허브 역할을 할 수도 있다. 그 밖에 생활 가전 제품들(303 내지 306)에 음성 입출력 기능이 수용되어서, 사용자는 음성 인터페이스를 이용하여 전자 제품을 제어할 수 있다. 이러한 점에서 전자 기 기들은 스마트 전자 기기로 불린다. 네트워크는 유선 및 무선 네트워크, 예를 들어 LAN(local area network), WAN(wide area network), 인터 넷(internet), 인트라넷(intranet) 및 엑스트라넷(extranet), 그리고 모바일 네트워크, 예를 들어 셀룰러, 3G, 4G LTE, 5G, WiFi 네트워크, 애드혹 네트워크 및 이들의 조합을 비롯한 임의의 적절한 통신 네트워크 일 수 있 다. 네트워크는 허브, 브리지, 라우터, 스위치 및 게이트웨이와 같은 네트워크 요소들의 연결을 포함할 수 있 다. 네트워크는 인터넷과 같은 공용 네트워크 및 안전한 기업 사설 네트워크와 같은 사설 네트워크를 비롯 한 하나 이상의 연결된 네트워크들, 예컨대 다중 네트워크 환경을 포함할 수 있다. 네트워크에의 액세스는 하나 이상의 유선 또는 무선 액세스 네트워크들을 통해 제공될 수 있다. 각종 스마트 전자 기기는 5G 네트워크를 통해 사투리 음소 적응 학습 시스템과 데이터를 전송하고 수 신할 수 있다. 특히 스마트 전자 기기는 5G 네트워크를 통해 모바일 브로드밴드(Enhanced Mobile Broadband, eMBB), URLLC(Ultra-reliable and low latency communications) 및 mMTC(Massive Machine-type communications) 중에서 적어도 하나의 서비스를 이용하여 사투리 음소 적응 학습 시스템과 데이터 통신을 할 수 있다. eMBB(Enhanced Mobile Broadband)는 모바일 브로드밴드 서비스로, 이를 통해 멀티미디어 콘텐츠, 무선데이터 액 세스 등이 제공된다. 또한, 폭발적으로 증가하고 있는 모바일 트래픽을 수용하기 위한 핫스팟 (hot spot)과 광 대역 커버리지 등 보다 향상된 모바일 서비스가 eMBB를 통해 제공될 수 있다. 핫스팟을 통해 사용자 이동성이 작고 밀도가 높은 지역으로 대용량 트래픽이 수용될 수 있다. 광대역 커버리지를 통해 넓고 안정적인 무선 환경 과 사용자 이동성이 보장될 수 있다. URLLC(Ultra-reliable and low latency communications) 서비스는 데이터 송수신의 신뢰성과 전송 지연 측면에 서 기존 LTE 보다 훨씬 엄격한 요구사항을 정의하고 있으며, 산업 현장의 생산 프로세스 자동화, 원격 진료, 원 격 수술, 운송, 안전 등을 위한 5G 서비스가 여기에 해당한다. mMTC(Massive Machine-type communications)는 비교적 작은 양의 데이터 전송이 요구되는 전송지연에 민감하지 않은 서비스이다. 센서 등과 같이 일반 휴대폰 보다 훨씬 더 많은 수의 단말들이 동시에 무선액세스 네트워크에 mMTC에 의해 접속할 수 있다. 이 경우, 단말의 통신모듈 가격은 저렴해야 하고, 배터리 교체나 재충전 없이 수 년 동안 동작할 수 있도록 향상된 전력 효율 및 전력 절감 기술이 요구된다. 도 2는 음성 인식 시스템과 사투리 음소 적응 학습 시스템의 관계를 나타내는 개략적인 블록도이다. 도 2를 참조하면, 음성 인식 시스템과 사투리 음소 적응 학습 시스템의 구성요소들이 묘사되어 있다. 음성 인식 시스템은 전자 기기에 포함된 마이크를 통해 입력되어 전처리된 음성 신호를 이용하 여 음성을 인식하고, 인식된 텍스트에 기반하여 그 내용을 이해하고, 이해된 내용에 기반하여 자연어를 생성하 고, 생성된 텍스트를 이용하여 스피커를 통해 출력 가능한 음성을 합성한다. 음성 인식 시스템은 음성의 입력에서 출력까지의 일련의 과정들을 각각 수행하는 음성 인식기(Automatic Speech Recognition, ASR), 자연어 이해(Natural Language Understanding, NLU) 모듈, 자연어 생성 (Natural Language Generation, NLG) 모듈 텍스트-문장 변환(Text-to-Sentence) 모듈을 포함하도록 구성될 수 있다. 여기서, 음성 인식 시스템을 이루는 구성요소들은 하나의 서버 형태, 또는 각각이 하나 이상의 서버 형태로 구성될 수 있다. 도 2를 다시 참조하면, ASR 내지 TTS가 수행하는 음성 인식 과정을 온라인 단계라고 하면, 오프라인 단계에서는 데이터 처리 장치와 모델 생성모듈에 의해 데이터 수집, 가공 및 이를 이용하는 음성 인식에 필요한 각종 모델 학습 과정이 수행된다. 본 발명의 일 실시 예에 따른 사투리 음소 적응 학습 시스템은 데이터 처리 장치와 모델 생성모듈 을 포함하도록 구성될 수 있다. 데이터 처리 장치는 데이터를 수집하고, 선별하고, 가공하여 음성 코 퍼스, 단어 발음에 관한 정보 및 문장 코퍼스를 생성할 수 있다. 그리고 모델 생성모듈은 위의 정보들을 이용하여 음향 모델링, 발음 모델링 및 언어 모델링을 수행하고, 수행 결과 음소 적응모델, 발음 사전 및 언어 모델이 각각 생성된다. 여기서, 음소 적응모델, 발음 사전 및 언어 모델은 음성 인식 엔진의 음성 인식에 필요 한 판단의 기준이 된다. 즉, 많은 데이터가 학습에 사용될수록 음성 인식기의 인식률은 높아질 수 있다. 도 3은 본 발명의 일 실시 예에 따른 사투리 음소 적응 학습 시스템의 구성을 나타내는 블록도이다. 도 3을 참조하면, 사투리 음소 적응 학습 시스템은 데이터 수집모듈, 데이터 전사모듈, 코퍼스 생성모듈, 음향 모델 생성모듈, 언어 모델 생성모듈 및 성능 추정모듈을 포함하도록 구성 될 수 있다. 이들 각 구성요소들 전체가 하나의 서버 형태로 또는 각각의 구성요소가 하나 이상의 서버 형태로 구현될 수 있다. 데이터 수집모듈은 음성 데이터베이스로부터 지역별 사투리 데이터를 수집할 수 있다. 도 1의 스마트 전자 기기를 통해 입력된 각 지역의 사투리는 도메인 및 지역별로 분류되어 데이터 수집모듈에 의해 수집되어 데이터베이스에 저장된다. 데이터 전사모듈은 사투리 음소 적응 학습 시스템에 저장되어 있는 데이터베이스에서 데이터를 선택하되, 음성 인식 결과 및 lattice 등의 정보를 이용한다. 데이터 전사모듈은 이상발성 분류기를 이용 하여 수집된 데이터 중에서 학습에 사용 불가능한 데이터, 예를 들어 음성이 아닌 소리, 다중화자 간의 음성 및 오인식된 음성을 제외하고 데이터를 선택한다. 선택된 음성 데이터는 자동 전사(Auto Transcription) 또는 수동 전사(Manual Transcription)를 통해 전사될 수 있다. 자동 전사의 경우 발생할 수 있는 오류를 방지하기 위해 자동 전사 결과에 대해 신뢰도가 측정되고, 신뢰도에 따라 데이터가 분류될 수 있다. 이 경우 신뢰도가 높은 데이터와 신뢰도가 낮은 데이터가 존재할 수 있다. 신뢰도가 높은 데이터는 사투리 데이 터를 포함할 수 있다. 따라서, 수집된 데이터 중에서 신뢰도가 낮은 데이터를 선택해서, 악센트 분석을 통해 사 투리를 포함하는 음성 데이터를 선택할 수 있다. 악센트 분석을 통해 신뢰도 낮은 데이터 중에서 사투리가 아닌 데이터, 예를 들어 비속어, 줄임 말 등이 제거될 수 있다. 선택된 사투리 데이터로부터 전사 데이터가 추출되어 저장된다. 코퍼스 생성모듈은 음향모델과 언어모델을 학습시키기 위한 학습용 데이터를 생성하기 위해 원시 데이터를 가공하는, 즉 데이터 마이닝을 수행하는 모듈이다. 도 4는 사투리 음소 적응 학습 시스템의 구성요소 중 하나인 코퍼스 생성모듈의 구성요소를 나타내는 블록도이 다. 도 4를 참조하면, 본 발명의 일 실시 예에 따른 코퍼스 생성모듈의 구성요소들이 묘사되어 있다. 코퍼스 생성모듈은 특징 추출모듈, 딥 러닝 모듈, 핵심사투리 추출모듈, 및 코퍼스 표준화 모듈를 포함하도록 구성될 수 있다. 특징 추출모듈은 음성 데이터, 특히 사투리 데이터의 발음열의 특징(feature), 어휘, 즉 형태소, 품사, 임 베딩(embedding)의 특징, 도메인의 특징 및 빈도수 특징 중에서 적어도 하나의 특징을 추출할 수 있다. 여기서, 발음열의 특징과 어휘의 특징은 사투리가 갖는 언어적인 특징에 해당한다. 도메인 특징은 사투리의 생성과 관련된 언어 외적인 특징에 해당한다. 도 1에서 설명하였듯이 사투리는 음성 인 식 서비스 도메인을 통해서 수집되고, 분석 및 정제될 수 있다. 도메인 특징은 해당 음성 인식 서비스가 어떠한 전자 기기를 통해서 제공되고 있는지, 전자 기기가 어느 지역에 분포하고 있는지, 전자 기기를 사용하는 사용자의 연령대는 어느 정도인지에 관한 정보를 포함할 수 있다. 따라서 도메인 특징을 통해 해당 지 역에서 사용되는 사투리 별로 음성 데이터가 분류될 수 있다.딥 러닝 모듈은 특징 간 가중치를 연산하고, 특징 간 유사도를 측정하고, 그리고 임계 값보다 높은 유사도 를 갖는 사투리에 대해 클러스터링을 수행한다. 핵심사투리 추출모듈은 클러스터 내 빈도수 특징이 높은 상위 n게 사투리를 추출하고, 클러스터 내 다른 객체들과 특징 유사도 계산을 통해 핵심 객체를 추출한다. 코퍼스 표준화모듈은 기존의 사투리를 핵심 객체 사투리로 치환하고, 원 사투리 문장과 치환된 문장의 유 사도 측정을 통해 표준화 작업을 검증한다. 한 지역, 예를 들어 경상도 또는 전라도 사투리의 경우 같은 뜻을 갖는 하나의 사투리 어휘에서 변이를 통해 다 양한 모양의 사투리가 파생될 수 있다. 이 경우 유사한 사투리끼리 분류할 필요가 있다. 동일한 뜻을 갖는 유사 한 사투리끼리 분류하는 것을 군집화(clustering)라고 한다. 동일한 뜻을 갖는 다양한 형태의 사투리 어휘가 군집화된 집단에서 핵심 사투리가 추출되고, 핵심 사투리를 이 용하여 사투리 어휘의 코퍼스를 표준화한다. 음향 모델 생성모듈은 음소별 발음에 따른 음향적 특성을 통계적 또는 패턴 분류화하여 수천 내지 수만여 개의 모델로 모델링된 음향 모델을 생성한다. 구체적으로 음향 모델 생성모듈은 음향 모델을 생성하고, 사 투리를 포함하는 전사 데이터 및 사투리를 포함하는, 정제된 음성 데이터로 구성되는 코퍼스를 이용하여 음향 모델을 학습시킨다. 본 발명의 일 실시 예에 따른 음향 모델 생성모듈은 코퍼스로부터 사투리 음소를 추출하는 제1 모듈, 추출 된 사투리 음소의 빈도수를 추출하는 제2 모듈, 및 사투리 음소에 대해 음소의 빈도수에 따라 가중치를 설정하 여 그 결과를 이용하여 음소 적응 모델을 학습시키는 제3 모듈을 포함하도록 구성될 수 있다. 또한, 표준화된 코퍼스로부터 클러스터링된 군에서 핵심 객체에 해당하는 사투리가 있는 경우에는 선정된 핵심 객체만을 음소 적응 모델 학습에 적용할 수 있다. 이 경우 표준화된 사투리 텍스트가 언어 모델 학습에 적용된 다. 언어 모델 생성모듈은 언어의 문법체계를 수천만 내지 수억 개 단어의 텍스트 데이터로부터 통계적으로 모 델링된 언어 모델을 생성한다. 구체적으로 언어 모델 생성모듈은 언어 모델을 생성하고, 사투리를 포함하 는 전사 데이터를 이용하여 언어 모델을 학습시킨다. 또한, 표준화된 코퍼스로부터 클러스터링된 군에서 핵심 객체에 해당하는 사투리가 있는 경우에는 선정된 핵심 객체의 사투리 텍스트가 언어 모델 학습에 적용된다. 또한, 언어 모델 생성모듈은 사투리의 인식률을 높이기 위해 실제 사용자 로그데이터로부터 수집된 사투리 의 띄어쓰기에 관한 음성 정보를 이용하여 언어 모델을 학습시킨다. 실제 발화된 음성에 기초하여 어절이 분리 하고, 분리된 어절에 빈도수라는 가중치를 적용한 학습을 통해 본 발명의 일 실시 예에 따른 언어 모델이 생성 될 수 있다. 도 5는 음성인식기에 의한 음성 인식 과정의 개략적인 블록도이다. 도 5를 참조하면, 본 발명의 일 실시 예에 따른 음성인식기가 묘사되어 있다. 음성인식기는 음성 인 식 엔진, 음소 적응 모델 모듈, 발음 사전 및 언어 모델을 포함하도록 구성될 수 있다. 발화된 음성은 마이크(Microphone)를 통해 아날로그 신호(Analog Signal)로 변환되고, 아날로그 신호는 디지털 샘플링(Digital Sampling) 과정을 거쳐 디지털 신호(Digital Signal)로 변환된다. 디지털 신호는 음향 신호 처 리(Acoustic Signal Processing)를 거친다. 여기서, 음향 신호 처리에 스펙트럴 분석(Spectral Analysis)이 포 함되기도 한다. 스마트 전자 기기, 예를 들어 인공지능(AI) 스피커를 통해 사투리가 입력되고, 입력된 음성은 아날로 그 신호로 변환되고, 변화된 아날로그 신호는 다시 샘플링을 통해 디지털 신호로 변환된다. 음성 인식 엔진 은 디지털 신호에서 음성의 특징, 즉 특징벡터를 추출한다. 그리고 음성 인식 엔진은 추출된 특징벡 터를 기반으로 음소 적응 모델 및 발음 사전을 이용하여 패턴인식 과정을 통해 후보단위를 생성하고, 발음 사전 및 언어 모델을 이용하여 언어처리 과정을 통해 최종적으로 인식된 문장을 출력한다. 음성인식기는 패턴인식 과정에서, 예를 들어 간단한 숫자로 표현된 음성 신호의 특징을 기초로 음소, 음절, 단어라는 문장의 원소를 인식해 낸다. 그리고 음성인식기는 후처리 단계인 언어처리 단계에서 문장 의 원소를 재구성해 문장을 복원해 낸다. 패턴인식 단계에서는 음성학, 음운학, 음운 배열론 및 시형론의 지식 이 이용되고, 후처리 단계인 언어처리 단계에서는 구문론, 의미론, 어형론의 지식이 이용될 수 있다. 같은 언어라 할지라도, 음성은 발음하는 사람의 성별, 나이, 발음 시의 상태 등에 따라 매우 복잡하게 변할 뿐 아니라 단독으로 발음될 때와 단어나 문장 내에서 발음될 때마다 그 성질이 변하기 때문에 음성의 특징을 잘 표 현할 수 있는 특징검출이 중요하다. 즉, 특징 추출 과정에서는 불필요하게 중복되는 음성정보를 없애고 동일 음 성 신호들 간의 일관성을 높임과 동시에 다른 음성 신호와는 변별력을 높일 수 있는 정보를 추출해야 한다. 이 러한 정보를 특징벡터라고 한다. 특징추출은 인식에 유용한 성분을 음성신호로부터 뽑아내는 과정이다. 특징추출은 일반적으로 정보의 압축, 차 원 감소 과정과 관련된다. 특징추출에서는 이상적인 정답이 없기 때문에 음성 인식을 위한 특징의 좋고 나쁨은 음성인식률로 판단된다. 특징추출의 주요 연구 분야는 인간의 청각특성을 반영하는 특징 표현, 다양한 잡음환경 /화자/채널 변이에 강인한(robust) 특징, 시간적인 변화를 잘 표현하는 특징의 추출이다. 음성 인식에 필요한 입력 음성의 특징을 추출하는 기술로는 선형예측계수(Linear Predictive Coefficient), 켑 스트럼(Cepstrum), 멜프리퀀시켑스트럼(Mel Frequency Cepstral Coefficient, MFCC), 및 주파수 대역별 에너지 (Filter Bank Energy)가 이용될 수 있다. 음성 인식 단계 중에서 패턴인식 알고리즘이 가장 활발히 연구되고 있다. 패턴인식 알고리즘의 종류로 DTW(Dynamic Time Warping), HMM(Hidden markov Modeling), 지식기반 시스템(Knowledge base system), 인공 신경망(Artificial Neural Network)이 있다. 여기서 DTW 는 동적 프로그래밍 (dynamic programming)을, HMM 은 확률추정을, 지식기반 시스템은 인공지능을 이용한 추론을, 인공 신경망은 패턴인식의 기능을 이용해 동일한 문 제를 각기 다른 방법으로 해결한다. 본 발명의 일 실시 예에 따른 사투리 음소 적응 학습 시스템은 음성 인식 단계에서 인공지능 알고리즘의 한 종류인 딥 러닝(deep learning)을 적용하여 음성의 패턴을 인식할 수 있다. 예를 들어 HMM의 각 상태(state) 확률 분포를 모델링하는데 사용되는 GMM이 DNN으로 대체되는, 인공 신경망 중에서 DNN(Deep Neural Network)과 HMM을 결합하는 방식이 이용될 수 있다. DNN-HMM을 이용한 음성 인식에서는 DNN을 적용하여 음성 특징 벡터로부터 상태확률이 계산될 수 있다. DNN의 입 력은 10여 개 프레임의 음성 특징 벡터가 되고, 출력은 HMM에서 단위로 사용하는 모든 트라이폰(triphone)의 각 상태 확률이 된다. 10여 개 프레임으로부터 얻은 특징벡터 열을 입력하여 학습된 DNN의 layer 별 모델 파라미터 에 따라 최종 출력에서 트라이폰의 상태확률 값이 얻어지고, 이를 이용하여 등록된 어휘 단위의 인식결과가 탐 색된다. 영상 인식 분야에서 탁월한 성능을 발휘하는 컨볼루션 신경망으로 해결하기 어려운 음성 인식, 언어번역, 자연 어 처리 등 시계열 데이터 분야에 순환 신경망(Recurrent Neural Network, RNN)이 이용될 수 있다. 순환 신경망 의 경우 고정 길이 입력이 아닌 임의의 길이를 가진 시퀀스(sequence)를 처리할 수 있다. 순환 신경망은 연상 메모리(Associative memory)처럼 출력이 입력에 귀환되는 구조라기보다는 은닉층의 상태를 저장하기 위해 출력이 귀환되는 구조를 갖는다. 순환의 의미는 반복을 의미하며, 순환 신경망은 특정 부분이 반 복되는 구조를 갖는다. 기존 신경망 대비 순환 신경망에서, 은닉층 뉴런은 자기 자신에게 다시 돌아오는 가중치 인 순환 가중치(Recurrent Weight)를 포함한다. 순환 가중치는 과거의 데이터에 대한 정보를 기억할 수 있는 기 능이 있어서 순환 신경망은 새로운 데이터를 처리할 때 과거의 기억을 사용할 수 있다. 성능 추정모듈은 학습된 음소 적응 모델 및 언어 모델을 이용하여 음성 인식 엔진이 수행 한 음성 인식 결과의 신뢰도 측정을 통하여 사투리 인식성능을 추정할 수 있다. 그리고 성능 추정모듈은 이전의 음성인식기와 신뢰도가 추정된 새로운 음성인식기를 비교하고, 새로운 음소 적응 모델 및 언어 모 델에 의한 음성 인식 성능이 개선된 것으로 판단되는 경우, 음성인식기의 음향 모델과 언어 모 델은 새롭게 학습된 사항을 포함하도록 업데이트 된다. 언어처리 알고리즘으로 구문규칙 모델과 통계적 모델이 있다. 구문규칙 방식은 구문론 규칙에 따라 매 단어 다 음에 올 수 있는 단어의 종류를 제한해 문장을 구성하는 방식이다. 한편, N-gram으로 표현되는 통계적 모델은 매 단어에 대해 이전의 N 개의 단어가 발생할 확률을 고려해 문장을 인식한다. 음성 인식 과정은 음성 데이터와 언어 데이터로부터 인식 네트워크 모델을 생성하는 오프라인 학습 단계와 사용 자가 발성한 음성을 인식하는 온라인 탐색 단계로 구분된다. 음성 인식 엔진은 음성학적 및 언어학적 정보라는 중요한 지식, 즉 음향 모델, 언어 모델 및 여기에 추가 적으로 발음 사전을 사용하여 음성 신호로부터 문자 정보를 출력한다. 이때 음성 신호를 문자 기호로 해석한다 는 차원에서 음성 인식 엔진을 디코더(Decoder)라고 부르기도 한다. 특징 추출에서 얻어진 특징벡터는 유사도 측정 및 인식과정을 거치게 된다. 유사도 측정 및 인식을 위해서는 음 성의 신호적인 특성을 모델링하여 비교하는 음향 모델(Acoustic Model), 특히 사투리 음소의 적응을 위한 음소 적응 모델과 인식 어휘에 해당하는 단어나 음절 등의 언어적인 순서 관계를 모델링하는 언어 모델 (Language Model)이 사용된다. 음향 모델은 다시 인식대상을 특징벡터 모델로 설정하고 이를 입력신호의 특징벡터와 비교하는 직접비교 방법과 인식대상의 특징벡터를 통계적으로 처리하여 이용하는 통계방법으로 나누어진다. 직접비교 방법은 인식대상이 되는 단어, 음소 등의 단위를 특징벡터 모델로 설정하고 입력음성이 이와 얼마나 유사한가 비교하는 방법이다. 대표적인 것으로 벡터양자화(Vector Quantization) 방법이 있는데, 앞서 구한 특징벡터 또는 계수들을 기존 모 델인 코드북(Codebook)과 매핑시켜 대표 값으로 부호화함으로써 이 부호 값들을 서로 비교하는 방법이다. 통계적 모델방법은 인식대상에 대한 단위를 상태 열(State Sequence)로 구성하고 상태 열간의 관계를 이용하는 방법이다. 상태 열은 복잡한 모델을 표시할 수 있어 간단한 단어인식을 제외하고는 대부분의 음성 인식이 이 기 술을 이용한다. 상태 열간의 관계를 이용하는 방법은 다시 DTW(Dynamic Time Warping)과 같이 시간적 배열관계 를 이용하는 방법, HMM과 같이 확률값, 평균, 그리고 분산을 비교대상으로 하는 통계적 방법, 그리고 인공 신경 망을 이용하는 방법이 있다. 디코딩 단계에서 학습 단계 결과인 음향 모델(Acoustic Model, AM), 언어 모델(Language Model, LM)(14 0)과 발음 사전(Pronunciation Lexicon)을 이용하여 입력된 특징 벡터를 모델과 비교, 스코어링을 하여 단 어 열이 최종 결정된다. 데이터베이스는 도 1에 묘사된 음성 인식 서비스를 제공하는 도메인을 통해서 각종 스마트 전자 기기(30 0)로부터 수집된 지역별 사투리 데이터를 포함하는 사용자 로그데이터 및 국가 기관 또는 연구소 등에서 구축된 공공 음성 데이터를 포함하도록 구성될 수 있다. 그리고 데이터베이스는 빅데이터(Big Data)를 포함하도록 구성될 수 있다. 이하 사투리 음소 적응 학습 시스템에 의해 수행되는 사투리 음소 적응 학습 방법, 특히 오프라인 단계에 해당하는 음향 모델과 언어 모델을 생성하고 학습시키는 과정에 대해 자세히 설명하기로 한다. 도 6은 본 발명의 일 실시 예에 따른 사투리 음소 적응 학습 방법의 흐름도이다. 도 6을 참조하면, 본 발명의 일 실시 예에 따른 사투리 음소 적응 학습 방법(S100)은, 음성 데이터를 수집하는 단계(S110), 사투리 인식에 적합한 음성인식기를 구성하기 위한 데이터 처리 단계(S121 내지 S134)와 음성 인식기를 이용하여 실제로 발화 음성을 인식하는 단계를 포함하도록 구성될 수 있다. 본 발명의 일 실시 예에 따른 사투리 음소 적응 학습 방법(S100), 그 중에서도 음성인식기를 구성하기 위 한 데이터 처리 단계는, 주요 과정으로 사투리 인식에 필요한 음향 모델 및 언어 모델을 업데이트하는 단계를 포함하는 것을 특징으로 한다. 본 발명의 일 실시 예에 따른 사투리 음소 적응 학습 시스템은 사투리 인식 성능 향상을 위해, 다음의 단 계들을 수행하는 것을 특징으로 한다. 먼저, 사투리 음소 적응 학습 시스템은 데이터 수집모듈을 통해 데이터를 수집한다(S110). 데이터 수 집모듈은 독립된 파일 서버로 구현될 수 있다. 데이터 수집모듈은 음성 인식 서비스를 제공하는 도메 인에 접속된 각종 스마트 전자 기기를 통해 사용자 로그데이터를 수집할 수 있다. 사용자 로그데이터는 지 역별 사투리를 포함할 수 있다. 다음으로 사투리 음소 적응 학습 시스템은 데이터 전사모듈을 이용하여 음성 데이터를 텍스트 데이터 로 전사한다(S120). 사투리 음소 적응 학습 시스템은 기존의 사투리가 포함되지 않은 전사 데이터에 사투 리가 포함된 음성 데이터에서 전사된 사투리 텍스트가 추가함으로써 사투리가 포함된 전사 데이터를 생성할 수 있다.S120 단계는 내부적으로 이상발성을 제거하는 단계(S121), 음성 데이터의 신뢰도를 측정하는 단계(S122), 음성 데이터의 악센트를 분석하는 단계 및 음성 데이터를 전사하는 단계(S124)를 포함하도록 구성될 수 있다. 사투리 음소 적응 학습 시스템은 사용자 로그데이터에서 사투리 전사 데이터를 추출하기 위해서 음성 데이 터의 신뢰도 측정을 통해 일반 음성과 사투리를 구별할 수 있다. 여기서, 신뢰도는 인식률을 포함하는 개념으로 서 표준어 대비 사투리가 포함된 음성의 인식률은 낮게 분포될 수 있다. 이 경우, 신뢰도 측정에 의한 사투리 선별에 추가하여 지역별 사투리가 갖는 고유의 악센트 분석을 통해 사투리가 표준어 음성으로부터 높은 정확성 을 갖고 선별될 수 있다. 다음으로 사투리 음소 적응 학습 시스템은 코퍼스 생성모듈을 이용하여 사투리가 포함된 음성 데이터 를 분석 및 정제하고 그 결과로서 코퍼스를 생성한다(S130). S130 단계는 내부적으로, 사투리의 특징을 추출하는 단계(S131), 유사 사투리 별로 클러스터링 하는 단계(S132) 및 클러스터에서 핵심 사투리를 추출하는 단계(S133) 및 사투리 코퍼스를 표준화하는 단계(S134)를 포함하도록 구성될 수 있다. 사투리의 특징으로서 발음열의 특징, 어휘(형태소/품사/임베딩) 특징, 도메인 특징, 및 빈도수 특징이 포함될 수 있다. 발음열의 특징이란 사투리 문장을 구성하는 음소, 음절의 음향학적 특징을 말한다. 어휘(형태소/품사/ 임베딩) 특징이란 사투리 문장을 구성하는 형태소, 품사, 임베딩의 언어학적 특징을 말한다. 도메인 특징이란 사용자가 이용하는 전자 기기의 종류, 전자 기기가 위치하는 지역 및 전자 기기를 사용하는 사 용자의 연령대에 관한 정보를 포함한다. 사용자의 연령대에 관한 정보는 전자 기기를 구입한 사용자의 사 용자 등록을 통해서 수집될 수 있다. 지역적으로 많이 사용되는 사투리는 연령대 별로 다르게 나타날 수 있으므 로 사용자 연령대 별로 사투리를 수집하는 것이 필요하다. 도 7은 본 발명의 일 실시 예에 따른 코퍼스 생성모듈에 의해 수행되는 데이터 분석 및 정제의 일 실시 예를 설 명하기 위한 예시도이다. 도 7을 참조하면, 본 발명의 일 실시 예에 따른 사투리 음소 적응 학습 방법(S100)을 구성하는 단계들 중에서 데이터 분석 및 정제에 관한 S131 내지 S134 단계의 예시가 묘사되어 있다. 음성 데이터의 분석 및 정제에 사용 되는 사투리 문장으로, 제1 문장 '풍력 센 바람으로 운행하재이', 제2 문장 '풍력 센 바람으로 운행하지', 및 제3 문장 '풍력 센 바람으로 운행해도라'를 예시 문장으로 선정한다. 특징 추출 모듈은 제1 문장 내지 제3 문장에 대해서 각 문장의 발음열에 대한 특징, 어휘의 특징, 도메인 특징 및 빈도수 특징을 추출할 수 있다(S131). 도메인 특징의 예로서 에어컨, 세탁기 등의 도메인이 묘사되어 있다. 다음으로 딥 러닝 모듈은 비지도 방식의 유사 사투리 클러스터링을 수행한다(S132). 사투리 문장에서 서술 어에 대한 클러스터링 결과가 묘사되어 있다. 제1 문장 내지 제3 문장에서, '운행하재이' 및 '운행하지'가 함께 군집화되었고, '운행해도라'는 같은 군집에 포함되지 않았다. 다음으로 핵심 사투리추출 모듈은 빈도수 특징이 높은 사투리를 추출하고, 유사도 연산을 통해 핵심 사투 리를 추출한다(S133). 제1 문장과 제2 문장의 서술어 중에서 '운행하재이'가 '운행하지'보다 빈도수 특징이 높 고 나타난다. 유사도 연산을 통해 '운행하재이'가 핵심 객체로 선정된다. 다음으로 코퍼스 표준화 모듈은 기존 사투리를 핵심 객체 사투리로 치환하고, 원 사투리 문장과 치환된 문 장의 유사도 측정을 통해 코퍼스 표준화를 검증한다(S134). 제1 문장 내지 제3 문장에서 제2 문장의 서술어 '운 행하지'가 핵심 객체인 '운행하재이'로 치환되었다. 다음으로 사투리 음소 적응 학습 시스템은 음향 모델 생성모듈 및 언어 모델 생성모듈을 통해 음소 적응 모델 및 언어 모델을 각각 생성하고, S134 단계에서 생성된 사투리 코퍼스를 이용하여 음 소 적응 모델 및 언어 모델을 학습시킨다(S140). S140 단계는 사투리 음소를 추출하는 단계(S141), 추출된 사투리 음성의 빈도수를 추출하는 단계(S142) 및 추출 된 음소 및 빈도수를 이용하여 사투리 음소 적응 학습을 시키는 단계(S143)를 포함하도록 구성되는 음향 모델 학습 과정과, 분리된 어절 단위의 빈도를 추출하는 단계(S144), 및 분리된 어절 및 이에 따른 빈도를 이용하여 언어 모델을 학습시키는 단계(S145)를 포함하도록 구성되는 언어 모델 학습 과정을 포함하도록 구성될 수있다. 도 8은 본 발명의 일 실시 예에 따른 음소 적응 모델 생성모듈에 의해 수행되는 학습 과정의 일 실시 예를 설명 하기 위한 예시도이다. 도 8을 참조하면, 음향 모델 생성모듈에 의해 수행되는 코퍼스 데이터를 이용하여 음소 적응 모델을 학습 시키는 과정이 묘사되어 있다. 음소(Phoneme)는 음운론상(Phonology)의 최소 단위로서, 하나 이상의 음소가 모여서 음절(Syllable)을 이룬다. 사투리에서 음소를 추출하는 이유는 사투리 문장에는 지역에 따라 빈번히 사용되는 음소를 포함하고 있는 경우 가 많기 때문이다. 예를 들어 용언의 말미를 통일적으로 끝맺는 어미(Suffix)를 이루는 음소, 경음(Fortis) 또 는 복모음(Diphthong)의 음소가 사투리 문장에서 자주 사용될 수 있다. 음향 모델 생성모듈은 코퍼스에 포함된 음성 데이터로부터 사투리 음소를 추출한다(S141). 핵심 사투리 클 러스터가 형성되어 있는 경우 음향 모델 생성모듈은 핵심 사투리를 대상으로 음소를 추출할 수 있다. 예를 들어 '풍력 센 바람으로 운행 하재이' 및 '풍력 센 바람으로 운행해도라'의 2개의 사투리 문장을 구성하는 어절 의 음소, '풍력', '센', '바람으로', '운행하재이', '운행해도라'가 추출될 수 있다. 그리고 음향 모델 생성모듈은 사투리 음소의 빈도수를 추출한다(S142). 음소의 빈도수에 따라 학습 과정에 서 가중치가 설정된다. 따라서, 음소의 빈도수가 높을수록 더 높은 가중치의 영향을 받아 강도 높은 학습이 이 루어진다. 이 경우 음향 모델은 사투리 음소에 적응하는 훈련을 통해 사투리의 음소를 인식할 수 있는 능 력을 키우게 되고, 이러한 의미에서, 본 발명의 일 실시 예에 따른 음향 모델은 음소 적응 모델이라 명명 될 수 있다. 사투리 음소의 빈도수는 인공지능 알고리즘을 이용한 학습 과정, 예를 들어 딥 러닝의 인공 신경망 구조에서 가 중치(weight)로 작용한다. 음향 모델 및 언어 모델의 학습에는 발음 사전(Pronunciation Dictionary)이 함께 사용될 수 있다. 발음 사전은 형태소와 이에 관한 발음을 나타내는 음소로 구성되고, 지역별 사투리 발음에 관한 정 보를 포함하도록 구성될 수 있다. 학습을 통해 표준어와 사투리에 관한 음향모델 및 언어모델의 성능이 향상된 다. 마지막으로 사투리 음소 적응 학습 시스템은 성능 추정모듈을 통해 학습된 음소 적응 모델 및 언어 모델의 성능을 추정한다(S150). S150 단계는 내부적으로 적어도 하나의 모델에 대해 신뢰도를 측정하는 단계(S151), 신뢰도를 이용하여 인식성 능을 추정하는 단계(S152), 복수의 모델간의 인식성능을 비교하는 단계(S153) 및 복수의 모델 중에서 인식성능 이 더 좋은 모델을 이용하여 이전의 모델과 비교하여 인식성능 개선 여부를 확인하는 단계(S154)를 포함하도록 구성될 수 있다. S150 단계는 음소 적응 모델 및 언어 모델 각각에 대해서 수행될 수 있다. 다양한 변이에 의해 다양한 형태로 파생되는 전체 사투리 어휘를 음성 인식 대상으로 한다면, 인식률이 떨어지 고 사투리 인식 속도가 떨어질 수 있다. 따라서, 사투리 코퍼스의 표준화를 통해 사투리의 인식률을 높이고, 사 투리 인식 속도도 높아질 수 있다. 또한, 사투리에서 발생하는 띄어쓰기 구조는 표준어의 띄어쓰기와 구별되므로 사투리 자체의 띄어쓰기를 학습시 킨 언어 모델을 이용하여 음성 인식을 수행하는 경우 사투리의 인식률이 향상될 수 있다. 또한, 음성 인식의 패턴인식 단계에서 사용되는 음향 모델의 학습에 있어서, 사투리 문장에서 빈도수가 높은 음 소에 대해 빈도수에 따라 가중치를 적용한 학습이 이루어지는 경우 음향 모델을 이용한 사투리의 패턴인식이 더 높은 정확성과 속도로 수행될 수 있다. 이와 같이 본 발명의 일 실시 예에 의하면, 사투리에 포함된 음소 적응 학습을 통해 사투리를 음운학적으로 처 리함으로써 사투리 인식률을 향상시킬 수 있다. 또한, 표준어를 거치지 않고서도 사투리가 포함된 음성 그대로를 인식할 수 있으므로, 사투리를 사용한 자연어 처리가 가능하다. 또한, 데이터 마이닝에 인공지능을 활용함으로써 데이터 정제가 반자동의 방법으로 수행될 수 있다. 또한, 사투리를 포함하는 코퍼스 표준화를 통해 사투리 인식에 소요되는 시간을 줄일 수 있다. 이상 설명된 본 발명에 따른 실시 예는 컴퓨터 상에서 다양한 구성요소를 통하여 실행될 수 있는 컴퓨터 프로그 램의 형태로 구현될 수 있으며, 이와 같은 컴퓨터 프로그램은 컴퓨터로 판독 가능한 매체에 기록될 수 있다. 이 때, 매체는 하드 디스크, 플로피 디스크 및 자기 테이프와 같은 자기 매체, CD-ROM 및 DVD와 같은 광기록 매체, 플롭티컬 디스크(floptical disk)와 같은 자기-광 매체(magneto-optical medium), 및 ROM, RAM, 플래시 메모리 등과 같은, 프로그램 명령어를 저장하고 실행하도록 특별히 구성된 하드웨어 장치를 포함할 수 있다. 한편, 상기 컴퓨터 프로그램은 본 발명을 위하여 특별히 설계되고 구성된 것이거나 컴퓨터 소프트웨어 분야의 당업자에게 공지되어 사용 가능한 것일 수 있다. 컴퓨터 프로그램의 예에는, 컴파일러에 의하여 만들어지는 것 과 같은 기계어 코드뿐만 아니라 인터프리터 등을 사용하여 컴퓨터에 의해서 실행될 수 있는 고급 언어 코드도 포함될 수 있다. 본 발명의 명세서(특히 특허청구범위에서)에서 '상기'의 용어 및 이와 유사한 지시 용어의 사용은 단수 및 복수 모두에 해당하는 것일 수 있다. 또한, 본 발명에서 범위(range)를 기재한 경우 상기 범위에 속하는 개별적인 값 을 적용한 발명을 포함하는 것으로서(이에 반하는 기재가 없다면), 발명의 상세한 설명에 상기 범위를 구성하는 각 개별적인 값을 기재한 것과 같다. 본 발명에 따른 방법을 구성하는 단계들에 대하여 명백하게 순서를 기재하거나 반하는 기재가 없다면, 상기 단 계들은 적당한 순서로 행해질 수 있다. 반드시 상기 단계들의 기재 순서에 따라 본 발명이 한정되는 것은 아니 다. 본 발명에서 모든 예들 또는 예시적인 용어(예들 들어, 등등)의 사용은 단순히 본 발명을 상세히 설명하기 위한 것으로서 특허청구범위에 의해 한정되지 않는 이상 상기 예들 또는 예시적인 용어로 인해 본 발명의 범위 가 한정되는 것은 아니다. 또한, 당업자는 다양한 수정, 조합 및 변경이 부가된 특허청구범위 또는 그 균등물의 범주 내에서 설계 조건 및 팩터에 따라 구성될 수 있음을 알 수 있다. 따라서, 본 발명의 사상은 상기 설명된 실시 예에 국한되어 정해져서는 아니 되며, 후술하는 특허청구범위뿐만 아니라 이 특허청구범위와 균등한 또는 이로부터 등가적으로 변경된 모든 범위는 본 발명의 사상의 범주에 속한 다고 할 것이다."}
{"patent_id": "10-2019-0072336", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일 실시 예에 따른 사투리 음소 적응 학습 시스템을 포함하는 네트워크 환경의 예시도이다. 도 2는 음성 인식 시스템과 사투리 음소 적응 학습 시스템의 관계를 나타내는 개략적인 블록도이다. 도 3은 본 발명의 일 실시 예에 따른 사투리 음소 적응 학습 시스템의 구성을 나타내는 블록도이다. 도 4는 사투리 음소 적응 학습 시스템의 구성요소 중 하나인 코퍼스 생성모듈의 구성요소를 나타내는 블록도이 다. 도 5는 음성인식기에 의한 음성 인식 과정의 개략적인 블록도이다. 도 6은 본 발명의 일 실시 예에 따른 사투리 음소 적응 학습 방법의 흐름도이다. 도 7은 본 발명의 일 실시 예에 따른 코퍼스 생성모듈에 의해 수행되는 데이터 분석 및 정제의 일 실시 예를 설 명하기 위한 예시도이다. 도 8은 본 발명의 일 실시 예에 따른 음소 적응 모델 생성모듈에 의해 수행되는 학습 과정의 일 실시 예를 설명 하기 위한 예시도이다."}
