{"patent_id": "10-2023-0078689", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0177397", "출원번호": "10-2023-0078689", "발명의 명칭": "영상속 객체의 학습중요도 설정 방법 및 장치", "출원인": "포티투닷 주식회사", "발명자": "최수민"}}
{"patent_id": "10-2023-0078689", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "객체가 인식되어 있는 주행영상을 수신하는 단계;수신된 주행영상에서 객체의 특성정보로 객체의 클래스를 파악하고, 파악된 클래스를 기초로 3차원 모델을 구축하는 단계;상기 구축된 3차원 모델을 칼리브레이션 파라미터(calibration parameter)를 기초로 2차원 사영(2Dprojection)시키는 단계;상기 2차원 사영된 두 개의 객체에서 차폐되는 피차폐객체와 상기 피차폐객체를 차폐하는 차폐객체간의 중첩영역을 파악하는 단계; 및상기 중첩영역을 기초로 피차폐객체의 관측도(visibility)를 산출하고, 산출된 관측도를 기초로 상기 피차폐객체의 학습중요도를 설정하는 단계를 포함하는, 영상속 객체의 학습중요도 설정 방법."}
{"patent_id": "10-2023-0078689", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 설정된 학습중요도를 객체별 특성정보로 저장하는 단계를 더 포함하는, 영상속 객체의 학습중요도 설정 방법."}
{"patent_id": "10-2023-0078689", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 3차원 모델을 구축하는 단계는,객체별 어노테이션(annotation)을 기초로 객체별 3차원 상의 위치 및 각도를 파악하는, 영상속 객체의 학습중요도 설정 방법."}
{"patent_id": "10-2023-0078689", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,상기 중첩영역을 파악하는 단계는,오버레이 마스크(overay mask)를 생성하여 판단하는, 영상속 객체의 학습중요도 설정 방법."}
{"patent_id": "10-2023-0078689", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서,상기 피차폐객체의 관측도는,0 이상 1 이하의 값으로 표현되는, 영상속 객체의 학습중요도 설정 방법."}
{"patent_id": "10-2023-0078689", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서, 상기 학습중요도를 설정하는 단계는,상기 피차폐객체의 관측도가 제1값 미만이면, 상기 피차폐객체의 학습중요도를 제2값으로 설정하고, 상기 방법은,상기 주행영상에서 학습중요도가 상기 제2값인 피차폐객체를 AI학습모델로 학습시 제외시키도록 하는 단계를 더공개특허 10-2024-0177397-3-포함하는, 영상속 객체의 학습중요도 설정 방법."}
{"patent_id": "10-2023-0078689", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에 있어서,상기 학습중요도를 설정하는 단계는,상기 피차폐객체의 관측도가 제3값을 초과하면, 상기 피차폐객체의 학습중요도는 제4값으로 설정하고, 상기 방법은,상기 주행영상에서 학습중요도가 제4값인 피차폐객체를 AI학습모델로 학습시 필수적으로 포함시키도록 하는 단계를 더 포함하는, 영상속 객체의 학습중요도 설정 방법."}
{"patent_id": "10-2023-0078689", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1항에 따른 방법을 실행시키기 위한 프로그램을 저장하고 있는 컴퓨터 판독가능한 기록매체."}
{"patent_id": "10-2023-0078689", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "적어도 하나의 프로그램이 저장된 메모리; 및상기 적어도 하나의 프로그램을 실행함으로써, 연산을 수행하는 프로세서를 포함하고,상기 프로세서는,객체가 인식되어 있는 주행영상을 수신하고,수신된 주행영상에서 객체의 특성정보로 객체의 클래스를 파악하고, 파악된 클래스를 기초로 3차원 모델을 구축하고,상기 구축된 3차원 모델을 칼리브레이션 파라미터를 기초로 2차원 사영(2D projection)시키고,상기 2차원 사영된 두 개의 객체에서 차폐되는 피차폐객체와 상기 피차폐객체를 차폐하는 차폐객체간의 중첩영역을 파악하고,상기 중첩영역을 기초로 피차폐객체의 관측도(visibility)를 산출하고, 산출된 관측도를 기초로 상기 피차폐객체의 학습중요도를 설정하는, 영상속 객체의 학습중요도 설정 장치."}
{"patent_id": "10-2023-0078689", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명의 일 실시예는, 객체가 인식되어 있는 주행영상을 수신하는 단계, 수신된 주행영상에서 객체의 특성정보 로 객체의 클래스를 파악하고, 파악된 클래스를 기초로 3차원 모델을 구축하는 단계, 상기 구축된 3차원 모델을 칼리브레이션 파라미터(calibration parameter)를 기초로 2차원 사영(2D projection)시키는 단계, 상기 2차원 사영된 두 개의 객체에서 차폐되는 피차폐객체와 상기 피차폐객체를 차폐하는 차폐객체간의 중첩영역을 파악하는 단계 및 상기 중첩영역을 기초로 피차폐객체의 관측도(visibility)를 산출하고, 산출된 관측도를 기초로 상기 피 차폐객체의 학습중요도를 설정하는 단계를 포함하는, 영상속 객체의 학습중요도 설정 방법을 개시한다."}
{"patent_id": "10-2023-0078689", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 학습중요도 설정 방법에 관한 것으로서, 보다 구체적으로는, 주행 중에 획득한 영상에서 객체를 인식 하고 학습모델로 학습할 때, 객체별로 학습중요도를 설정하기 위한 방법 및 그 방법을 구현하기 위한 장치에 관 한 것이다."}
{"patent_id": "10-2023-0078689", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "정보통신 기술과 차량 산업의 융합으로 인해 빠르게 차량의 스마트화가 진행되고 있다. 스마트화로 인해, 차량 은 단순한 기계적 장치에서 스마트카로 진화하고 있으며, 특히, 스마트카의 핵심기술로 자율 주행(self- driving)이 주목 받고 있다. 자율 주행이란, 운전자가 핸들과 가속페달, 브레이크 등을 조작하지 않아도 차량에 탑재된 자율 주행 모듈이 차량의 주행상태를 능동적으로 제어함으로써, 차량 스스로 목적지까지 찾아가는 기술 이다. 자율주행 자동차의 안전한 자율주행을 위해서, 자율 주행 과정에서 차량이 보행자나 다른 차량을 정확하게 인식 하고, 인식된 객체와의 거리를 산출하는 방법에 대한 연구가 다양하게 이루어지고 있으나, 차량이 주행 중에 도 로 상에 출현가능한 객체 특성은 사실상 무한에 가깝고, 자율주행 자동차에 탑재되는 모듈의 프로세싱 능력에 한계가 존재하여, 도로 상에 있는 객체를 완벽하게 인식할 수 있는 방법은 현재 알려져 있지 않다. 카메라를 통한 객체 인식 및 거리추정의 경우, 실제 3차원 세계의 객체를 2차원 이미지에 투영하였기 때문에 거 리에 대한 정보가 많이 손실된다. 특히, 보행자 위치 계산에 많이 사용되는 특징들(보행자의 키나 지면에 닿아있는 점)의 편차가 크기 때문에 오차가 크다. 레이더(RADAR)를 통한 객체 인식 및 거리추정의 경우, 레이더가 운용하는 전파 특성상 객체를 빠르게 파악하고 분류하는 능력이 떨어지기 때문에, 보행자인지 또는 차량인지에 대한 판단이 어렵고, 특히, 도로상에 있는 보행 자나 이륜차(자전거나 오토바이)의 경우 신호세기가 작기 때문에 인식결과가 더욱 안 좋은 경향이 있다. 최근에는 라이다(LiDAR)를 이용한 객체 인식 및 거리 추정 기술이 상대적으로 높은 정확도를 갖고 있어서 각광 받고 있으나, 고출력 레이저는 위험성이 있어서 라이다는 출력을 낮춘 레이저를 기반으로 동작할 수 밖에 없고, 레이더가 사용하는 전파와는 다르게 레이저는 주변 환경의 영향을 크게 받고, 라이다 센서의 지나치게 높은 비 용이 한계점으로 지적된다. 한편, 자율주행을 구현하기 위해서, 주행 영상속에서 객체를 인식하고 객체별로 특징정보를 부여하여, 인공지능 모델로 학습시키는 과정에서, 여러 장애물에 차폐되어 있는데도 불구하고, 객체별로 부여되어 있는 특징정보에 의해서, 학습데이터로 사용되어, 학습효과를 낮게 만드는 경우가 자주 발생되므로, 이러한 학습률 저하를 해소 하기 위한 기술이 필요하다."}
{"patent_id": "10-2023-0078689", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 2, "content": "전술한 배경기술은 발명자가 본 발명의 도출을 위해 보유하고 있었거나, 본 발명의 도출 과정에서 습득한 기술 정보로서, 반드시 본 발명의 출원 전에 일반 공중에게 공개된 공지기술이라 할 수는 없다. 선행기술문헌 특허문헌 (특허문헌 0001) 대한민국 등록특허 제10-2438114호 (2022.08.25)"}
{"patent_id": "10-2023-0078689", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명이 해결하고자 하는 기술적 과제는, 영상속 객체의 학습중요도 설정 방법 및 그 방법을 구현하기 위한 장치를 제공하는 데에 있다."}
{"patent_id": "10-2023-0078689", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기 기술적 과제를 해결하기 위한 본 발명의 일 실시예에 따른 방법은, 객체가 인식되어 있는 주행영상을 수신 하는 단계; 수신된 주행영상에서 객체의 특성정보로 객체의 클래스를 파악하고, 파악된 클래스를 기초로 3차원 모델을 구축하는 단계; 상기 구축된 3차원 모델을 칼리브레이션 파라미터(calibration parameter)를 활용하여 2 차원 사영(2D projection)시키는 단계; 상기 2차원 사영된 두 개의 객체에서 차폐되는 피차폐객체와 상기 피차 폐객체를 차폐하는 차폐객체간의 중첩영역을 파악하는 단계; 및 상기 중첩영역을 기초로 피차폐객체의 관측도 (visibility)를 산출하고, 산출된 관측도를 기초로 상기 피차폐객체의 학습중요도를 설정하는 단계를 포함한다. 상기 방법은, 상기 설정된 학습중요도를 객체별 특성정보로 저장하는 단계를 더 포함한다. 상기 방법에 있어서, 상기 3차원 모델을 구축하는 단계는, 객체별 어노테이션(annotation)을 기초로 객체별 3차 원 상의 위치 및 각도를 파악할 수 있다. 상기 방법에 있어서, 상기 중첩영역을 파악하는 단계는, 오버레이 마스크(overay mask)를 생성하여 판단할 수 있다. 상기 방법에 있어서, 상기 피차폐객체의 관측도는, 0 이상 1 이하의 값으로 표현될 수 있다. 상기 방법에 있어서, 상기 학습중요도를 설정하는 단계는, 상기 피차폐객체의 관측도가 제1값 미만이면, 상기 피차폐객체의 학습중요도를 제2값으로 설정하고, 상기 방법은, 상기 주행영상에서 학습중요도가 상기 제2값인 피차폐객체를 AI학습모델로 학습시 제외시키도록 하는 단계를 더 포함할 수 있다. 상기 방법에 있어서, 상기 학습중요도를 설정하는 단계는, 상기 피차폐객체의 관측도가 제3값을 초과하면, 상기 피차폐객체의 학습중요도는 제4값으로 설정하고, 상기 방법은, 상기 주행영상에서 학습중요도가 제4값인 피차폐 객체를 AI학습모델로 학습시 필수적으로 포함시키도록 하는 단계를 더 포함한다.상기 기술적 과제를 해결하기 위한 본 발명의 다른 일 실시예에 따른 장치는, 적어도 하나의 프로그램이 저장된 메모리; 및 상기 적어도 하나의 프로그램을 실행함으로써, 연산을 수행하는 프로세서를 포함하고, 상기 프로세 서는, 객체가 인식되어 있는 주행영상을 수신하고, 수신된 주행영상에서 객체의 특성정보로 객체의 클래스를 파 악하고, 파악된 클래스를 기초로 3차원 모델을 구축하고, 상기 구축된 3차원 모델을 칼리브레이션 파라미터를 활용하여 2차원 사영(2D projection)시키고, 상기 2차원 사영된 두 개의 객체에서 차폐되는 피차폐객체와 상기 피차폐객체를 차폐하는 차폐객체간의 중첩영역을 파악하고, 상기 중첩영역을 기초로 피차폐객체의 관측도 (visibility)를 산출하고, 산출된 관측도를 기초로 상기 피차폐객체의 학습중요도를 설정한다. 본 발명의 일 실시예는 상기 방법을 컴퓨터에서 실행시키기 위한 프로그램을 저장하고 있는 컴퓨터 판독가능한 기록매체를 제공할 수 있다."}
{"patent_id": "10-2023-0078689", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명에 따르면, 객체별로 학습중요도를 설정하여 학습에 활용함으로써, 불필요한 객체는 학습에서 제외시킬 수 있게 되어, AI모델의 학습효율을 현격하게 향상시킬 수 있다."}
{"patent_id": "10-2023-0078689", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명은 다양한 변환을 가할 수 있고 여러 가지 실시예를 가질 수 있는바, 특정 실시예들을 도면에 예시하고"}
{"patent_id": "10-2023-0078689", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "상세한 설명에 상세하게 설명하고자 한다. 본 발명의 효과 및 특징, 그리고 그것들을 달성하는 방법은 도면과 함께 상세하게 후술되어 있는 실시예들을 참조하면 명확해질 것이다. 그러나 본 발명은 이하에서 개시되는 실시 예들에 한정되는 것이 아니라 다양한 형태로 구현될 수 있다. 이하, 첨부된 도면을 참조하여 본 발명의 실시예들을 상세히 설명하기로 하며, 도면을 참조하여 설명할 때 동일 하거나 대응하는 구성 요소는 동일한 도면부호를 부여하고 이에 대한 중복되는 설명은 생략하기로 한다. 이하의 실시예에서, 제1, 제2 등의 용어는 한정적인 의미가 아니라 하나의 구성 요소를 다른 구성 요소와 구별 하는 목적으로 사용되었다. 이하의 실시예에서, 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 이하의 실시예에서, 포함하다 또는 가지다 등의 용어는 명세서상에 기재된 특징, 또는 구성요소가 존재함을 의 미하는 것이고, 하나 이상의 다른 특징을 또는 구성요소가 부가될 가능성을 미리 배제하는 것은 아니다. 어떤 실시예가 달리 구현 가능한 경우에 특정한 공정 순서는 설명되는 순서와 다르게 수행될 수도 있다. 예를 들어, 연속하여 설명되는 두 공정이 실질적으로 동시에 수행될 수도 있고, 설명되는 순서와 반대의 순서로 진행 될 수 있다. 도 1 내지 도 3은 일 실시예에 따른 자율 주행 방식을 설명하기 위한 도면들이다. 도 1을 참조하면, 본 발명의 일 실시예에 따른 자율 주행 장치는, 차량에 장착되어 자율주행 자동차를 구현 할 수 있다. 자율주행 자동차에 장착되는 자율 주행 장치는, 주변의 상황 정보를 수집하기 위한 다양한 센서들을 포함할 수 있다. 일례로, 자율 주행 장치는 자율주행 자동차의 전면에 장착된 이미지 센서 및/또는 이벤트 센서를 통해, 전방에서 운행 중인 선행 차량의 움직임을 감지할 수 있다. 자율 주행 장치는 자율주 행 자동차의 전면은 물론, 옆 차로에서 운행중인 다른 주행 차량과, 자율주행 자동차 주변의 보행 자 등을 감지하기 위한 센서들을 더 포함할 수 있다. 자율주행 자동차 주변의 상황 정보를 수집하기 위한 센서들 중 적어도 하나는, 도 1에 도시한 바와 같이 소정의 화각(FoV)을 가질 수 있다. 일례로, 자율주행 자동차의 전면에 장착된 센서가 도 1에 도시한 바와 같은 화 각(FoV)을 갖는 경우에, 센서의 중앙에서 검출되는 정보가 상대적으로 높은 중요도를 가질 수 있다. 이는, 센서 의 중앙에서 검출되는 정보에, 선행 차량의 움직임에 대응하는 정보가 대부분 포함되어 있기 때문일 수 있 다. 자율 주행 장치는, 자율주행 자동차의 센서들이 수집한 정보를 실시간으로 처리하여 자율주행 자동차의 움직임을 제어하는 한편, 센서들이 수집한 정보 중에 적어도 일부는 메모리 장치에 저장할 수 있다. 도 2를 참조하면, 자율 주행 장치는 센서부, 프로세서, 메모리 시스템, 및 차체 제어 모듈 등을 포함할 수 있다. 센서부는 복수의 센서들(42-45)을 포함하며, 복수의 센서들(42-45)은 이미지 센서, 이벤트 센서, 조도 센서, GPS 장치, 가속도 센서 등을 포함할 수 있다. 센서들(42-45)이 수집한 데이터는 프로세서로 전달될 수 있다. 프로세서는 센서들(42-45)이 수집한 데 이터를 메모리 시스템에 저장하고, 센서들(42-45)이 수집한 데이터에 기초하여 차체 제어 모듈을 제어 하여 차량의 움직임을 결정할 수 있다. 메모리 시스템은 둘 이상의 메모리 장치들과, 메모리 장치들을 제어 하기 위한 시스템 컨트롤러를 포함할 수 있다. 메모리 장치들 각각은 하나의 반도체 칩으로 제공될 수 있다. 메모리 시스템의 시스템 컨트롤러 외에, 메모리 시스템에 포함되는 메모리 장치들 각각은 메모리 컨트 롤러를 포함할 수 있으며, 메모리 컨트롤러는 신경망과 같은 인공지능(AI) 연산 회로를 포함할 수 있다. 메모리 컨트롤러는 센서들(42-45) 또는 프로세서로부터 수신한 데이터에 소정의 가중치를 부여하여 연산 데이터를 생성하고, 연산 데이터를 메모리 칩에 저장할 수 있다. 도 3은 자율 주행 장치가 탑재된 자율주행 자동차의 센서가 획득한 영상 데이터의 예시를 나타낸 도면이다. 도 3을 참조하면, 영상 데이터는 자율주행 자동차의 전면에 장착된 센서가 획득한 데이터일 수 있다. 따라서 영상 데이터에는 자율주행 자동차의 전면부, 자율주행 자동차과 같은 차로의 선행 차량, 자율주행 자동차 주변의 주행 차량 및 비관심영역 등이 포함될 수 있다. 도 3에 도시한 실시예에 따른 영상 데이터에서, 자율주행 자동차의 전면부와 비관심영역이 나타나 는 영역의 데이터는 자율주행 자동차의 운행에 영향을 미칠 가능성이 거의 없는 데이터일 수 있다. 다시 말해, 자율주행 자동차의 전면부와 비관심영역은 상대적으로 낮은 중요도를 갖는 데이터로 간주될 수 있다. 반면, 선행 차량과의 거리, 및 주행 차량의 차로 변경 움직임 등은 자율주행 자동차의 안전한 운행에 있어서 매우 중요한 요소일 수 있다. 따라서, 영상 데이터에서 선행 차량 및 주행 차량 등이 포함 되는 영역의 데이터는 자율주행 자동차의 운행에 있어서 상대적으로 높은 중요도를 가질 수 있다. 자율 주행 장치의 메모리 장치는, 센서로부터 수신한 영상 데이터의 영역별로 가중치를 다르게 부여하여 저 장할 수 있다. 일례로, 선행 차량과 주행 차량 등이 포함되는 영역의 데이터에는 높은 가중치를 부여하 고, 자율주행 자동차의 전면부와 비관심영역이 나타나는 영역의 데이터에는 낮은 가중치를 부여할 수 있다. 도 4a 및 도 4b는 일 실시예에 따른 차량 외부를 촬영하는 카메라와 관련된 도면이다. 카메라는 차량에 탑재되어 차량의 외부를 촬영할 수 있다. 카메라는 차량의 전방, 측방, 후방 등을 촬영할 수 있다. 본 발명에 따른 객체 인식 장치(Object Detector)는 카메라에서 촬영된 복수의 영상을 획득하여, 각 영상 에 포함되어 있는 객체를 인식할 수 있다. 각 영상에는 복수의 객체가 포함되어 있을 수 있고, 본 발명에 따른 객체 인식 장치는 각 영상을 구성하는 최소 단위인 프레임별로 객체를 인식할 수 있다. 객체에 관한 정보는 객체 종류 정보 및 객체 속성 정보를 포함한다. 여기에서, 객체 종류 정보는 객체의 종류를 나타내는 인덱스 정보이며, 큰 범위인 그룹과 세부 범위인 클래스로 구성된다. 그리고, 객체 속성 정보는 객체 의 현재 상태에 대한 속성 정보를 나타내는 것이며, 움직임 정보, 회전 정보, 교통 정보, 색상 정보, 및 가시성 정보 등을 포함한다.일 실시예에서, 객체 종류 정보에 포함되는 그룹 및 클래스는 아래의 표 1과 같을 수 있으나, 이에 제한되지 않 는다. 표 1 Group Class Flat Road, Sidewalk, Parking, Ground, Crosswalk Human Pedestrian, Rider Vehicle Car, Truck, Bus ConstructionBuilding Wall, Guard rail, Tunnel, fence, gas station, pylon Object Pole, Traffic sign, Traffic light, color corn Nature vegetation, terrain, paddy field, river, lake Void Static Lane Dotted line, Solid line, Dotted and Solid line, Double Solid line Sky Sky Animal Dog, Cat, bird 움직임 정보는 객체의 움직임 정보를 표현하며 정차, 주차, 이동 등으로 정의될 수 있다. 차량의 경우 정차, 주 차, 이동이 객체 속성 정보로 결정될 수 있고, 보행자의 경우 이동, 정지, 알 수 없음이 객체 속성 정보로 결정 될 수 있고, 신호등과 같이 움직일 수 없는 객체의 경우 디폴트 값인 정지로 객체 속성 정보가 결정될 수 있다. 회전 정보는 객체의 회전 정보를 표현하며 정면, 후면, 수평(horizontal), 수직(vertical), 측면 등으로 정의될 수 있다. 차량의 경우 정면, 후면, 측면으로 객체 속성 정보가 정해질 수 있고, 가로 또는 세로 방향의 신호등 은 각각 수평 또는 수직으로 객체 속성 정보가 정해질 수 있다. 교통 정보는 객체의 교통정보를 의미하며, 교통표지판의 지시, 주의, 규제, 보조 표지 등으로 정의될 수 있다. 색상 정보는 객체의 색상 정보를 의미하며 객체의 색상, 신호등 및 교통표지판의 색상을 표현할 수 있다. 도 4a를 참조하면, 객체는 보행자일 수 있다. 이미지는 소정의 크기를 가질 수 있다. 복수의 이미지 에는 동일한 객체가 포함될 수 있으나, 차량이 도로를 따라 주행함에 따라 차량과 객체의 상대 적 위치는 계속 변하고, 또한 객체도 시간에 따라 이동을 함으로써, 이에 따라 동일한 객체라도 각 이미지 내에서의 위치가 달라지게 된다. 각 이미지에서 동일한 객체가 어떤 것인지 결정하기 위해 이미지 전체를 이용하는 경우, 데이터 전송량 및 연산 량이 상당히 커지게 된다. 이에 따라, 차량에 탑재되는 장치에서 엣지 컴퓨팅을 통해 처리되기 어렵고, 실시간 분석 또한 어렵다. 도 4b를 참조하면, 이미지에 포함된 바운딩 박스가 도시된다. 바운딩 박스(Bounding box)는 객체 (object)에 대한 메타데이터로서, 바운딩 박스 정보에는 객체 종류 정보(그룹, 클래스 등), 이미지 상의 위치 정보, 크기 정보 등이 포함될 수 있다. 도 4b를 참조하면, 바운딩 박스 정보는 해당 객체가 보행자 클래스에 해당한다는 정보와, 객체의 좌 측 상단 꼭지점이 이미지 상의 (x, y) 에 위치한다는 정보, 객체의 크기가 w x h 라는 정보, 그리고 객체 가 이동 중이라는 현재 상태 정보(즉, 움직임 정보)를 포함할 수 있다. 도 5는 일 실시예에 따른 객체 인식 방법을 설명하는 개략도이다. 객체 인식 장치(Object Detector)는 카메라로부터 획득된 동영상을 프레임별로 분리하여 복수의 프레임을 획득 할 수 있다. 복수의 프레임은 이전 프레임 및 현재 프레임을 포함할 수 있다. 이어서, 객체 인식 장 치는 이전 프레임에서 제1 보행자 객체를 인식할 수 있다. 일 실시예에서, 객체 인식 장치는 프레임을 동일한 크기의 그리드로 나누고, 각 그리드에 대해 그리드 중앙을 중심으로 미리 정의된 형태로 지정된 경계박스의 개수를 예측하며 이를 기반으로 신뢰도를 계산할 수 있다. 객 체 인식 장치는 프레임에 객체가 포함되어 있는지, 또는, 배경만 단독으로 있는지 여부를 결정하고, 높은 객체 신뢰도를 갖는 위치를 선택하여 객체 카테고리를 결정함으로써 결과적으로 객체를 인식할 수 있다. 다만, 본 개 시에서 객체를 인식하는 방법은 이에 제한되지 않는다. 객체 인식 장치는 이전 프레임에서 인식된 제1 보행자 객체의 제1 위치 정보를 획득할 수 있다. 도 4a 및 도 4b에서 상술한 바와 같이, 제1 위치 정보는 이전 프레임 상의 제1 보행자 객체에 대응하는 바운딩 박스의 어느 하나의 꼭지점(예를 들어, 좌측 상단 꼭지점) 좌표 정보 및 가로, 세로 길이 정보를 포함할 수 있다. 또한, 객체 인식 장치는 현재 프레임에서 인식된 제2 보행자 객체의 제2 위치 정보를 획득할 수 있다. 객체 인식 장치는 이전 프레임에서 인식된 제1 보행자 객체의 제1 위치 정보, 및 현재 프레임에 서 인식된 제2 보행자 객체의 제2 위치 정보 간의 유사도를 산출할 수 있다. 도 5를 참조하면, 제1 위치 정보 및 제2 위치 정보를 이용하여, 객체 인식 장치는 제1 보행자 객체 및 제2 보행자 객체간의 교집합 및 합집합을 산출할 수 있다. 객체 인식 장치는 합집합 영역 대비 교집합 영역의 값을 산출하고, 산출된 값이 임계값 이상인 경우, 제1 보행자 객체 및 제2 보행자 객체가 동일한 보 행자 객체인 것으로 결정할 수 있다. 그러나, 객체 간의 동일성을 판별하는 방법은 상술한 방법으로 제한되지 않는다. 도 6은 본 발명에 따른 영상속 객체의 학습중요도 설정 방법의 일 예를 흐름도로 나타낸 도면이다. 본 발명에 따른 영상속 객체의 학습중요도 설정 방법은, 영상속 객체의 학습중요도 설정 장치에 의해 구현될 수 있고, 이하에서는, 영상속 객체의 학습중요도 설정 장치를 학습중요도 설정 장치로 약칭하기로 한다. 학습중요도 설정 장치는 영상속 객체의 학습중요도를 설정하기 위한 첫 단계로서, 객체가 인식되어 있는 주행영 상을 수신하고, 객체 어노테이션(annotation) 기반 3D모델을 생성할 수 있다(S610). 단계 S610에서 주행영상은 카메라가 장착되어 있는 차량이 주행 중에 카메라를 통해 획득한 영상을 의미하며, 주행영상에 포함된 객체들은 도 4 및 도 5에서 설명한 프로세스를 통해서, 차량의 자율주행을 구현하기 위하여 AI학습모델에서 학습되어야 하는 대상을 의미한다. 여기서, 객체에는 승용차, 트럭, 버스, 이륜차, 행인과 같은 이동하는 물체뿐만 아니라, 내부적으로 설정된 값에 따라서, 신호등, 횡단보도 표지판과 같이 정지되어 있는 사 물들도 포함될 수 있다. 주행영상의 객체는 객체 인식 장치(object detector)에 내장되어 있는 객체 인식 알고 리즘을 통해서 인식될 수 있고, 주행영상에서 객체로 인식되고 나면, 해당 객체에는 주행영상에서 2D바운딩 박 스(2D Bounding Box)나 큐보이드(cuboid)와 같은 외곽선이 부가되어, 시각적으로 다른 객체들과 구별될 수 있다. 객체별로 대응되어 저장되어 있는 특징정보에는 어노테이션(annotation)이 있으며, 어노테이션은 객체에 대한 메타데이터로 기능할 수 있다. 객체 어노테이션에는 도 4a 및 도 4b에서 설명한 객체 종류 정보 및 객체 속성 정보 중 적어도 하나가 포함될 수 있고, 특히, 본 발명에서는 객체 어노테이션 중에서 클래스(class)정보 를 이용할 수 있다. 객체의 클래스는 표 1에 기재된 것처럼, 객체를 크게 어느 그룹으로 분류할 수 있는지에 대해서 사전에 정의해 놓은 것을 의미한다. 예를 들어, 객체의 클래스가 Car, Truck, Bus 중 어느 하나일 경우, 그 객체는 차량 (vehicle) 그룹으로 분류되며, 객체의 클래스가 Pedestrian, Rider 중 어느 하나일 경우, 그 객체는 휴먼 (human) 그룹으로 분류될 수 있다. 본 발명에 따른 학습중요도 설정 장치는, 객체들이 인식된 주행영상을 수신하고, 그 주행영상에서의 객체의 어 노테이션에 기재되어 있는 클래스(class)별로 미리 설정되어 있는 캐드 모델(CAD Model)들을 3차원 공간상에 생 성할 수 있다. 예를 들어, 클래스가 Bus인 객체가 주행영상에서 인식되었을 경우, Bus에 대응되는 형태와 크기 를 갖는 캐드 모델이 3차원 공간상에 생성될 수 있다. 주행영상에 포함된 모든 객체들에 대해서 캐드 모델이 생 성될 수 있다. 이어서, 학습중요도 설정 장치는 3차원 공간상에 생성한 객체들의 캐드 모델들의 위치 및 각도를 조정할 수 있 다(S620). 학습중요도 설정 장치는 객체의 어노테이션을 참조하여, 주행영상을 촬영하기 위해 카메라가 탑재되 어 있는 에고 차량(ego vehicle)을 기준으로 각 객체들이 어느 방향으로 어느 거리만큼 이격되어 있는지 확인하 고, 그에 따라서 3차원 공간상에 각 객체들을 배치할 수 있다. 예를 들어, 학습중요도 설정 장치는 어노테이션 에 기재되어 있는 3차원상의 포지션 좌표(x, y, z) 및 각도 좌표(roll, pitch, yaw)를 확인하고, 에고 차량을 기준으로 객체를 3차원 공간상에 배치시킬 수 있다. 도 7은 도 6을 통해 설명한 단계 S610 및 S620을 도식적으로 설명하기 위한 도면이다. 먼저, 도 7의 (a)에는 에고 차량의 카메라를 통해서 보이는 주변 영상이 예시적으로 나타나있다. 도 7에서 대상 차량은 에고 차량의 카메라를 통해서 촬영된 차량으로서, 객체 인식 장치를 통해서 분석되어 이미 객체로 서 인식되었고, 객체 어노테이션 정보가 확보된 상태이다. 학습중요도 설정 장치는 대상차량의 어노테이션 정보 중 하나인 클래스(class)를 참조하여, 대상차량의 클래스가 Car라는 것을 확인하고, 그에 대응되는 캐드 모델을 로드(load)할 수 있다. 도 7의 (b)는 대상차량의 캐드 모델을 예시적으로 나타내고 있다. 도 7에서 대상차량의 클래스 가 Car이므로, 그에 대응되는 대상차량의 캐드 모델은 3차원 형태의 5인승 승용차가 로드되었으며, 실시예에 따라서, 대상차량의 클래스가 Car가 아니라면, 그에 따라 로드되는 3차원 캐드 모델도 5인승 승 용차가 아닌 다른 형태로 달라질 수 있다. 도 7의 (b)와 같이, 대상차량의 어노테이션 중 클래스를 참조하 여 대상차량의 캐드 모델을 로드하는 단계가, 도 6에서의 단계 S610가 될 수 있다. 도 7의 (c)는 대상차량의 캐드 모델을 3차원 공간 상에 배치하는 실시예를 예시적으로 나타내고 있다. 학습중요도 설정 장치는 객체가 인식된 주행영상으로부터 객체별 어노테이션 정보를 확보할 수 있고, 객 체별 어노테이션 정보에는 에고 차량의 위치를 원점으로 하여, 객체별로 3차원 공간상의 포지션 좌표(x, y, z) 및 각도 좌표(roll, pitch, yaw)가 포함되어 있으므로, 학습중요도 설정 장치는 대상차량을 3차원 공간상에 적절하게 배치되도록 조정할 수 있다. 도 7의 (c)에는 에고 차량을 기준으로 3차원 공간상에 배 치된 대상차량의 캐드 모델이 도식적으로 나타나 있다. 다시, 도 6에 대한 설명을 이어서 하기로 한다. 학습중요도 설정 장치는 객체들에 대한 캐드 모델이 로드된 후에, 각 객체별 캐드 모델의 위치 및 각도가 조정 되고 나면, 칼리브레이션 파라미터(calibration parameter)를 이용하여 캐드 모델을 2차원 사영(2D Projection)시킬 수 있다(S630). 단계 S630에서 학습중요도 설정 장치는 수행하는 2차원 사영 프로세스는 3차원 공간 상에서 6개의 좌표값을 기 초로 배치되어 있는 각 객체들을 특성값들을 2개의 좌표값으로 변환하는 프로세스를 의미한다. 예를 들어, 도 7 의 대상차량은 단계 S610, S620을 거쳐서 3차원상에 캐드 모델이 배치되고 나면, 대상차량은 직각좌 표계(cartesian coordinate system)의 좌표값인 x, y, z축에 대한 좌표뿐만 아니라, x축, y축, z축 각각의 회 전량에 대한 좌표값인 r, p, y(각각 roll, pitch, yaw을 의미)에 대한 좌표를 특성값으로 갖게 된다. 여기서, 학습중요도 설정 장치는 칼리브레이션 파라미터를 이용하여, 객체별 6개의 좌표를 2차원으로 사영시키 는 프로세스를 수행함으로써, 객체에 대한 형태 및 위치에 대한 정보를 압축적으로 나타낼 수 있게 된다. 수학식 1"}
{"patent_id": "10-2023-0078689", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "수학식 2"}
{"patent_id": "10-2023-0078689", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "수학식 3"}
{"patent_id": "10-2023-0078689", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "수학식 1 내지 수학식 3은 단계 S630에서 이루어지는 2차원 사영 프로세스를 수학식으로 설명한 것이다. 수학식 1 내지 수학식 3에서, xPr은 학습중요도 설정 장치가 2차원 사영 프로세스를 처리한 결과의 x좌표, yPr은 학습중 요도 설정 장치가 2차원 사영 프로세스를 처리한 결과의 y좌표, P2Dpr은 에고 차량이 바라보는 대상차량의 2차원 사영 결과 좌표를 각각 의미한다. 또한, 수학식 1 및 수학식 2에서 pcalx, pcaly는 대상객체의 6개의 좌표값(x, y, z, r, p, y)으로부터 2차원 사영 결과 좌표인 xPr, yPr을 산출하기 위한 칼리브레이션 파라미터를 각각 의미한다. 칼리브레이션 파라미터는 학습중요도 설정 장치에 미리 정의되어 있는 파라미터로서, 상수(constan t)일수도 있고, 실시예에 따라, 대상차량의 어노테이션 정보에 의존하는 변수(variable)일 수도 있다. 이어서, 학습중요도 설정 장치는 주행영상 속 객체들에 대해서 2차원 사영 프로세스를 처리한 후에, 마스크 (mask) 기반으로 오버레이(overay) 영역을 판정할 수 있다(S640). 보다 구체적으로, 단계 S640는, 학습중요도 설정 장치가, 2차원 사영된 두 개의 객체에서 차폐되는 피차폐객체와 피차폐객체를 차폐하는 차폐객체간의 중첩 영역의 넓이(크기)를 파악한다는 것을 의미하며, 본 단계 S640에 대한 도식적인 설명은 도 8을 통해서 설명하기 로 한다. 도 8은 도 6을 통해 설명한 단계 S630 및 S640을 도식적으로 설명하기 위한 도면이다. 먼저, 도 8의 (a)는 에고 차량의 카메라를 통해서 보이고 있던 주변 영상에서 객체들에 대해서 2차원 사영시킨 결과를 나타내고 있다. 단계 S610, S620을 통해서 3차원 캐드 모델이 생성된 후에, 3차원 공간상에 배치되어 있 던 객체들은 수학식 1 내지 수학식 3을 기반으로 하여 2차원 사영되어 x, y좌표로 표현될 수 있다. 즉, 도 8의 (a)는 학습중요도 설정 장치가 단계 S630을 거쳐서 주행영상 속 객체들을 2차원 좌표상으로 단순화한 결과를 도 시한 것이며, 이 과정에서 불필요한 정보는 제거되어 도 8의 (a)에 도시된 것처럼 각 객체의 경계선만 남고, 객 체의 실제색깔, 음영, 양감 등과 같은 시각적인 효과를 구성하는 정보들은 표시되지 않는다. 이어서, 도 8의 (b)는 단계 S640에 따라서, 마스크 기반 오버레이 영역을 판정한 결과를 도식적으로 나타내고 있다. 도 8의 (b)에는 피차폐객체와 차폐객체가 각각 도시되어 있는데, 피차폐객체는 차폐객체 에 의해서 일부가 가려져서 피차폐객체의 후면은 에고 차량에서 관측되지 않는다. 학습중요도 설정 장치는 도 8의 (b)에 도시된 것처럼, 3차원 공간상에 배치되어 있던 각각의 객체들을 2차원 사영시키면서 획득 한 객체별 어노테이션 정보 및 칼리브레이션 파라미터를 기반으로, 2차원 사영(2D Projection)된 피차폐객체 및 차폐객체간의 중첩영역을 파악할 수 있다. 도 8의 (b)에서 피차폐객체 및 차폐객체간 의 중첩영역은 B영역으로 도시되어 있으며, 피차폐객체의 고유영역은 A영역, 차폐객체의 고유영역은 C영역으로 각각 도시되어 있다. 도 8의 (a) 및 도 8의 (b)와 같이 각 객체들은 경계선만 남고, 다른 시각적인 정보는 제거되어 객체에 마스크 (mask)를 덧씌운 것과 같은 시각적효과를 발현할 수 있으므로, 이하에서는 설명의 편의를 위하여, 피차폐객체의 고유영역과 중첩영역을 더한 영역을 피차폐객체의 마스크, 차폐객체의 고유영역과 중첩영역을 더한 영역을 차폐 객체의 마스크라고 각각 호칭하기로 한다. 학습중요도 설정 장치는, 중첩영역을 기초로 피차폐객체의 관측도(visibility)를 산출하고, 산출된 관측도를 기 초로 피차폐객체의 학습중요도를 설정할 수 있다(S650). 수학식 4"}
{"patent_id": "10-2023-0078689", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "수학식 4는 학습중요도 설정 장치가 관측도를 산출할 때 사용하는 수학식의 일 예이다. 수학식 4에서 V는 관측 도(visibility), Nip는 피차폐객체의 마스크와 차폐객체의 마스크의 중첩영역(intersection)의 픽셀(pixel)의 개수, Nup는 피차폐객체의 마스크 및 차폐객체의 마스크의 결합체(union)의 픽셀의 개수를 각각 의미한다. 본 발 명은, 이미지를 픽셀단위로 처리하는 프로세스는 통상적으로 디지털 장치를 가정하여 고안되었으므로, 피차폐객 체의 마스크 및 차폐객체의 마스크는 모두 이진값인 바이너리 마스크(binary mask)로 표현되어 처리되며, 도 8의 (b)에서 관측도 V는 B/(A+B+C)가 된다. 수학식 4와 같이, 관측도의 수학적인 정의에 의해서, 본 발명에서의 관측도는 0이상 1이하의 값으로만 표현될 수 있다. 즉, 피차폐객체의 관측도가 0이면, 차폐객체에 의해서 피차 폐객체 전체가 가려진 경우이고, 피차폐객체의 관측도가 1이면,피차폐객체를 가리는 차폐객체가 전혀 없는 경우 를 각각 의미한다. 도 9는 주행영상에 본 발명이 적용되어 관측도가 출력되는 일 예를 도식적으로 나타낸 도면이다. 도 9를 참조하면, 에고 차량의 카메라를 기준으로 어떠한 차폐없이 모두 보이는 트럭 1대, 승용차 2대의 관측도 는 1.0이지만, 신호등 아래에서 관측된 피차폐객체의 관측도는 0.429인 것을 알 수 있다. 또한, 도 9에서 각각 의 객체는 객체 인식 장체의 의해서 이미 객체로 인식된 상태이므로, 각각의 객체를 둘러싸고 있는 큐보이드 (cuboid)형태의 외곽선이 생성되어, 객체의 위치 및 방향성이 표시되어 있다. 도 10은 관측도를 기초로 객체의 학습중요도를 설정하고 적용하는 프로세스를 설명하기 위한 도면이다. 학습중요도 설정 장치는 단계 S650에서 객체별로 설정한 관측도를 객체별 특성정보(어노테이션 정보)의 하나로 서 저장하고 관리할 수 있고, 관측도를 기초로 하여, 객체별로 학습중요도를 설정할 수도 있다. 일 예로서, 피차폐객체의 관측도가 제1값 미만이면, 학습중요도 설정 장치는 피차폐객체의 학습중요도를 제2값 으로 설정할 수 있다. 본 실시예에서, 학습중요도 설정 장치는 학습중요도가 제2값인 피차폐객체를 AI학습모델 로 학습할 때에 제외시키도록 제어할 수 있다. 즉, 주행영상에서 관측도가 미리 설정되어 있는 제1값에 미달하 는 객체들은 AI학습모델이 그 주행영상을 학습대상으로 입력받았을 때, 학습에서 제외됨으로써, 본 발명에 따르 면, 주행영상에 대한 객체인식의 학습의 효과를 높이고, 학습하는데에 소요되는 시간을 더 줄일 수 있다. 예를 들어, 제1값이 0.5라면, 도 9에서 관측도가 0.429인 객체는 학습에서 제외되는 객체가 될 수 있다. 다른 일 예로서, 피차폐객체의 관측도가 제3값을 초과하면, 학습중요도 설정 장치는 피차폐객체의 학습중요도를 제4값으로 설정할 수 있다. 본 실시예에서, 학습중요도 설정 장치는 학습중요도가 제4값인 피차폐객체를 AI학습 모델로 학습할 때에 반드시 포함하도록 제어할 수 있다. 즉, 주행영상에서 관측도가 미리 설정되어 있는 제3값 을 초과하는 객체들은 AI학습모델이 그 주행영상을 학습대상으로 입력받았을 때, 학습에 반드시 포함됨으로써, 학습의 효과를 높일 수 있다. 예를 들어, 제3값은 0.9가 될 수 있으나, 이는 예시적인 값이므로, 다양한 값이 될 수 있다. 또 다른 일 예로서, 학습중요도 설정 장치에는 전술한 제1값, 제2값, 제3값, 제4값에 대한 정보 및 그 정보에 따른 분기적 판단 알고리즘이 모두 적용될 수도 있다. 이에 대한 설명은 전술한 설명과 중복되므로 생략하기로 한다. 또한, 실시예에 따라서, 본 발명에서의 제1값 내지 제4값은 적절히 조정될 수 있다. 도 10의 (a)에는 에고 차량의 우측 사이드 카메라로 촬영된 주행영상에 객체 인식 알고리즘을 적용한 결과가 도 식적으로 표현되어 있다. 도 10의 (a)의 박스에는 에고 차량의 프레임(frame)의 굴곡면에 의해서 차폐된 여러 대의 차량들의 외곽선(2D 바운딩 박스)들이 포함되어 있다. 본 발명에 따른 학습중요도 설정 장치는 도 10의 (a)의 박스에 포함된 여러 대의 차들의 관측도를 기초로 학습중요도를 산출하고, 도 10의 (b)와 같이 주행영상을 보정할 수 있다. 도 10의 (b)에는 도 10의 (a)에서 도 시되어 있던 박스가 완전히 삭제되었으며, 박스안에 있던 차량들에 대한 외곽선도 삭제되어 있다. 즉, 본 발명에 따른 학습중요도 설정 장치에 의해서, 도 10의 (a)에 도시되어 있던 외곽선들에 각각 대응되는 차량들의 학습중요도가 각각 산출되었으나, 그 산출된 학습중요도가 모두 미리 설정된 제2값이어서, 도 10의 (b)에서는 해당 객체들이 학습에 사용되지 않도록 제거된 것이다. 본 발명의 선택적 일 실시예로서, 학습중요도 설정 장치는 관측도만으로 주행영상 속 객체의 학습제외여부를 판 단할 수도 있다. 이 경우, 전술한 값들 중에서, 관측도에 대한 제1값 및 제3값만으로 방법을 구현하는 것이 가 능하다. 예를 들어, 본 선택적 일 실시예에 따르면, 관측도가 30%이하인 객체는 전부 AI학습모델을 학습할 때, 학습대상에서 제외되고 외곽선이 생성되지 않도록 조정될 수 있다. 도 11은 일 실시예에 따른 학습중요도 설정 장치의 블록도이다. 도 11을 참조하면, 학습중요도 설정 장치는 통신부, 프로세서 및 DB를 포함할 수 있다. 도 11의 학습중요도 설정 장치에는 실시예와 관련된 구성요소들만이 도시되어 있다. 따라서, 도 11"}
{"patent_id": "10-2023-0078689", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 7, "content": "에 도시된 구성요소들 외에 다른 범용적인 구성요소들이 더 포함될 수 있음을 당해 기술분야의 통상의 기술자라 면 이해할 수 있다.통신부는 외부 서버 또는 외부 장치와 유선/무선 통신을 하게 하는 하나 이상의 구성 요소를 포함할 수 있다. 예를 들어, 통신부는, 근거리 통신부(미도시), 이동 통신부(미도시) 및 방송 수신부(미도시) 중 적 어도 하나를 포함할 수 있다. DB는 학습중요도 설정 장치 내에서 처리되는 각종 데이터들을 저장하는 하드웨어로서, 프로세서 의 처리 및 제어를 위한 프로그램을 저장할 수 있다. DB는 DRAM(dynamic random access memory), SRAM(static random access memory) 등과 같은 RAM(random access memory), ROM(read-only memory), EEPROM(electrically erasable programmable read-only memory), CD-ROM, 블루레이 또는 다른 광학 디스크 스토리지, HDD(hard disk drive), SSD(solid state drive), 또는 플 래시 메모리를 포함할 수 있다. 프로세서는 학습중요도 설정 장치의 전반적인 동작을 제어한다. 예를 들어, 프로세서는 DB에 저장된 프로그램들을 실행함으로써, 입력부(미도시), 디스플레이(미도시), 통신부, DB 등을 전반적으로 제어할 수 있다. 프로세서는, DB에 저장된 프로그램들을 실행함으로써, 학습중요 도 설정 장치의 동작을 제어할 수 있다. 프로세서는 상술한 학습중요도 설정 장치의 동작 중 적어도 일부를 제어할 수 있다. 일 예로서, 프로세서는 도 6 내지 도 10을 통해 설명한 것처럼, 객체가 인식되어 있는 주행영상을 수신하 고, 수신된 주행영상에서 객체의 특성정보로 객체의 클래스를 파악하고, 파악된 클래스를 기초로 3차원 모델을 구축하고, 구축된 3차원 모델을 칼리브레이션 파라미터를 기초로 2차원 사영(2D projection)시키고, 2차원 사영 된 두 개의 객체에서 차폐되는 피차폐객체와 피차폐객체를 차폐하는 차폐객체간의 중첩영역을 파악하고, 중첩영 역을 기초로 피차폐객체의 관측도(visibility)를 산출하고, 산출된 관측도를 기초로 피차폐객체의 학습중요도를 설정할 수 있다. 프로세서는 ASICs(application specific integrated circuits), DSPs(digital signal processors), DSPDs(digital signal processing devices), PLDs(programmable logic devices), FPGAs(field programmable gate arrays), 제어기(controllers), 마이크로 컨트롤러(micro-controllers), 마이크로 프로세서 (microprocessors), 기타 기능 수행을 위한 전기적 유닛 중 적어도 하나를 이용하여 구현될 수 있다. 이상 설명된 본 발명에 따른 실시예는 컴퓨터상에서 다양한 구성요소를 통하여 실행될 수 있는 컴퓨터 프로그램 의 형태로 구현될 수 있으며, 이와 같은 컴퓨터 프로그램은 컴퓨터로 판독 가능한 매체에 기록될 수 있다. 이때, 매체는 하드 디스크, 플로피 디스크 및 자기 테이프와 같은 자기 매체, CD-ROM 및 DVD와 같은 광기록 매 체, 플롭티컬 디스크(floptical disk)와 같은 자기-광 매체(magneto-optical medium), 및 ROM, RAM, 플래시 메 모리 등과 같은, 프로그램 명령어를 저장하고 실행하도록 특별히 구성된 하드웨어 장치를 포함할 수 있다. 한편, 상기 컴퓨터 프로그램은 본 발명을 위하여 특별히 설계되고 구성된 것이거나 컴퓨터 소프트웨어 분야의 당업자에게 공지되어 사용 가능한 것일 수 있다. 컴퓨터 프로그램의 예에는, 컴파일러에 의하여 만들어지는 것 과 같은 기계어 코드뿐만 아니라 인터프리터 등을 사용하여 컴퓨터에 의해서 실행될 수 있는 고급 언어 코드도 포함될 수 있다. 본 발명에서 설명하는 특정 실행들은 일 실시예들로서, 어떠한 방법으로도 본 발명의 범위를 한정하는 것은 아 니다. 명세서의 간결함을 위하여, 종래 전자적인 구성들, 제어 시스템들, 소프트웨어, 상기 시스템들의 다른 기 능적인 측면들의 기재는 생략될 수 있다. 또한, 도면에 도시된 구성 요소들 간의 선들의 연결 또는 연결 부재들 은 기능적인 연결 및/또는 물리적 또는 회로적 연결들을 예시적으로 나타낸 것으로서, 실제 장치에서는 대체 가 능하거나 추가의 다양한 기능적인 연결, 물리적인 연결, 또는 회로 연결들로서 나타내어질 수 있다. 또한, “필 수적인”, “중요하게” 등과 같이 구체적인 언급이 없다면 본 발명의 적용을 위하여 반드시 필요한 구성 요소 가 아닐 수 있다. 본 발명의 명세서(특히 특허청구범위에서)에서 “상기”의 용어 및 이와 유사한 지시 용어의 사용은 단수 및 복 수 모두에 해당하는 것일 수 있다. 또한, 본 발명에서 범위(range)를 기재한 경우 상기 범위에 속하는 개별적인 값을 적용한 발명을 포함하는 것으로서(이에 반하는 기재가 없다면), 발명의 상세한 설명에 상기 범위를 구성하 는 각 개별적인 값을 기재한 것과 같다. 마지막으로, 본 발명에 따른 방법을 구성하는 단계들에 대하여 명백하 게 순서를 기재하거나 반하는 기재가 없다면, 상기 단계들은 적당한 순서로 행해질 수 있다. 반드시 상기 단계 들의 기재 순서에 따라 본 발명이 한정되는 것은 아니다. 본 발명에서 모든 예들 또는 예시적인 용어(예들들어, 등등)의 사용은 단순히 본 발명을 상세히 설명하기 위한 것으로서 특허청구범위에 의해 한정되지 않는 이 상 상기 예들 또는 예시적인 용어로 인해 본 발명의 범위가 한정되는 것은 아니다. 또한, 당업자는 다양한 수정, 조합 및 변경이 부가된 특허청구범위 또는 그 균등물의 범주 내에서 설계 조건 및 팩터에 따라 구성될 수 있음을 알 수 있다."}
{"patent_id": "10-2023-0078689", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1 내지 도 3은 일 실시예에 따른 자율 주행 방식을 설명하기 위한 도면들이다. 도 4a 및 도 4b는 일 실시예에 따른 차량 외부를 촬영하는 카메라와 관련된 도면이다. 도 5는 일 실시예에 따른 객체 인식 방법을 설명하는 개략도이다. 도 6은 본 발명에 따른 영상속 객체의 학습중요도 설정 방법의 일 예를 흐름도로 나타낸 도면이다. 도 7은 도 6을 통해 설명한 단계 S610 및 S620을 도식적으로 설명하기 위한 도면이다. 도 8은 도 6을 통해 설명한 단계 S630 및 S640을 도식적으로 설명하기 위한 도면이다. 도 9는 주행영상에 본 발명이 적용되어 관측도가 출력되는 일 예를 도식적으로 나타낸 도면이다. 도 10은 관측도를 기초로 객체의 학습중요도를 설정하고 적용하는 프로세스를 설명하기 위한 도면이다. 도 11은 일 실시예에 따른 학습중요도 설정 장치의 블록도이다."}
