{"patent_id": "10-2022-0190442", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0108838", "출원번호": "10-2022-0190442", "발명의 명칭": "영상인식 기반 선원 모니터링 시스템 및 영상인식 기반 선원 모니터링 방법", "출원인": "주식회사 랩오투원", "발명자": "강성필"}}
{"patent_id": "10-2022-0190442", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "모니터링 대상 공간을 촬영하는 카메라; 및 상기 카메라가 촬영한 영상을 전송받아서 분석하는 모니터링 장치;를 포함하되, 상기 모니터링 장치는, 상기 모니터링 대상 공간에서의 상기 선원의 존재를 검출하고, 검출된 선원의 자세를 추정하여 선원의 상태를판단한 결과를 출력하는 것을 특징으로 하는 영상인식 기반 선원 모니터링 시스템."}
{"patent_id": "10-2022-0190442", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "청구항 1에 있어서,상기 모니터링 장치는, 입력된 이미지에서 선원을 검출하는 휴먼 디텍션 모듈; 검출된 선원의 자세를 추정하는 포즈 에스티메이션 모듈; 및 행동 인식 모듈;을 포함하며,상기 행동 인식 모듈의 인식 결과를 이용하여 상기 선원의 상태를 분류하되, 상기 선원의 상태는 서있는 상태, 앉아있는 상태, 누워있는 상태 중 어느 한 상태로 분류되는 것을 특징으로 하는 영상인식 기반 선원 모니터링 시스템."}
{"patent_id": "10-2022-0190442", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "청구항 1에 있어서,상기 모니터링 장치는, 입력된 이미지에서 선원을 검출하는 휴먼 디텍션 모듈; 검출된 선원의 자세를 추정하는 포즈 에스티메이션 모듈; 및 안전모 검출 모듈;을 포함하며,선원이 안전모를 머리에 착용하고 있는지의 여부를 판단하는 것을 특징으로 하는 영상인식 기반 선원 모니터링시스템."}
{"patent_id": "10-2022-0190442", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "에 있어서,행동 인식 단계를 더 포함하되, 상기 휴먼 디텍션 단계에서는, 이미지 내의 선원을 포함하는 바운딩 박스로 잘려진 이미지인 Cropped HumanImage를 도출하고, 상기 포즈 에스티메이션 단계에서는, 상기 바운딩 박스 내의 선원의 신체에서 키포인트들을 추출하여 Human 2DPose를 도출하며, 상기 행동 인식 단계는, 인공지능모듈이 상기 바운딩 박스 및 상기 키포인트들을 분석하여 상기 선원의 상태를판단하되, 상기 선원의 상태는 서있는 상태, 앉아있는 상태, 누워있는 상태를 포함하는 것을 특징으로 하는 영상인식 기반선원 모니터링 방법."}
{"patent_id": "10-2022-0190442", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "청구항 5에 있어서,상기 인공지능모듈은 MMHAR 학습모델을 포함하며,상기 MMHAR 학습모델은, Cropped Human Image를 CNN(Convolutional Neural Network) 모델로 학습하고,Human 2D Pose를 MLP(Multi Layer Perceptron) 모델로 학습하고,상기 CNN 모델과 상기 MLP 모델의 특성을 연결하고 FC(Fully Connected Layer)와 Softmax ActivationFunction을 적용해서 도출되는 값으로 상기 선원의 상태를 판단하는 것을 특징으로 하는 영상인식 기반 선원 모니터링 방법."}
{"patent_id": "10-2022-0190442", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "청구항 5에 있어서,안전모 검출 단계를 더 포함하되, 상기 휴먼 디텍션 단계에서는, 이미지 내의 선원을 포함하는 바운딩 박스로 잘려진 이미지인 Cropped HumanImage를 도출하고, 상기 포즈 에스티메이션 단계에서는, 상기 바운딩 박스 내의 선원의 신체에서 키포인트들을 추출하여 Human 2DPose를 도출하되, 상기 키포인트들에는 사람의 머리가 포함되고, 상기 안전모 검출 단계는, 딥러닝 기반의 YOLOv5 모델을 포함하는 인공지능모듈이 상기 Human 2D Pose에서 사람의 머리에 해당하는 위치에서 안전모가 검출되는지를 판단하는 방식으로 수행되는 것을 특징으로 하는 영상인식기반 선원 모니터링 방법."}
{"patent_id": "10-2022-0190442", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명의 예시적인 실시예에 따른 영상인식 기반 선원 모니터링 시스템은, 모니터링 대상 공간을 촬영하는 카메 라; 및 상기 카메라가 촬영한 영상을 전송받아서 분석하는 모니터링 장치;를 포함하되, 상기 모니터링 장치는, 상기 모니터링 대상 공간에서의 상기 선원의 존재를 검출하고, 검출된 선원의 자세를 추정하여 선원의 상태를 판 단한 결과를 출력한다."}
{"patent_id": "10-2022-0190442", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명의 일 실시예는 영상인식 기반 선원 모니터링에 관한 것이다."}
{"patent_id": "10-2022-0190442", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "유럽 해양 안전청 통계에 따르면 연간 약 120척의 대형 선박 사고로 약 12,000명의 사상자가 발생하고 있으며, 지난 3년간 200척의 선박이 오염물질 배출로 적발되어 1,200억원 벌금을 지불하였고, 관련 해운사는 40년 보호 관찰을 받기도 하는 등 피해가 막대하다. 선박에서는 선원의 근무 상태가 소홀한 경우 중대한 사고로 이어질 가능성이 높으며, 해양사고의 대부분은 경계 소홀에 의한 운항과실로 인해 발생되고 있다. 선박 승무원(선원)의 “인적사고”와 “근무태만”으로 인한 선박 사고와 환경오염은 관련 피해규모가 크고 광범위하여 해운사 경영에서 큰 위험요소이다. 따라서, 선원에 대한 근태관리와 피드백의 중요성은 매우 크지만, 선박의 특성상 한계가 있다."}
{"patent_id": "10-2022-0190442", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명의 일 측면은, CCTV 등 선박에 설치되는 카메라로 촬영된 영상을 이용한 선원 근무상태 모니터링을 통해 서 사고를 예방하고 선원 근태 관리의 효율성을 향상시킬 수 있는 영상인식 기반 선원 모니터링 시스템을 제공 할 수 있다. 본 발명의 일 측면은, 선원 근무상태 모니터링을 통해서 사고를 예방하고 선원 근태 관리의 효율성을 향상시킬 수 있는 영상인식 기반 선원 모니터링 방법을 제공할 수 있다."}
{"patent_id": "10-2022-0190442", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 예시적인 실시예에 따른 영상인식 기반 선원 모니터링 시스템은, 모니터링 대상 공간을 촬영하는 카 메라; 및 상기 카메라가 촬영한 영상을 전송받아서 분석하는 모니터링 장치;를 포함하되, 상기 모니터링 장치는, 상기 모니터링 대상 공간에서의 상기 선원의 존재를 검출하고, 검출된 선원의 자세를 추정하여 선원의 상태를 판단한 결과를 출력할 수 있다. 이때, 상기 모니터링 장치는, 입력된 이미지에서 선원을 검출하는 휴먼 디텍션 모듈; 검출된 선원의 자세를 추 정하는 포즈 에스티메이션 모듈; 및 행동 인식 모듈;을 포함하며, 상기 행동 인식 모듈의 인식 결과를 이용하여 상기 선원의 상태를 분류하되, 상기 선원의 상태는 서있는 상태, 앉아있는 상태, 누워있는 상태 중 어느 한 상 태로 분류될 수 있다. 또한, 상기 모니터링 장치는, 입력된 이미지에서 선원을 검출하는 휴먼 디텍션 모듈; 검출된 선원의 자세를 추 정하는 포즈 에스티메이션 모듈; 및 안전모 검출 모듈;을 포함하며, 선원이 안전모를 머리에 착용하고 있는지의 여부를 판단한다. 본 발명의 예시적인 실시예에 따른 영상인식 기반 선원 모니터링 방법은, 카메라가 모니터링 대상 공간을 촬영 한 영상을 처리한 이미지를 입력받는 단계; 입력된 이미지에서 선원을 검출하는 휴먼 디텍션 단계; 및 검출된 선원의 자세를 추정하는 포즈 에스티메이션 단계;를 포함하며, 상기 모니터링 대상 공간에서의 상기 선원의 존 재를 검출하고, 검출된 선원의 자세를 추정하여 선원의 상태를 판단한 결과를 출력할 수 있다. 이때, 행동 인식 단계를 더 포함하되, 상기 휴먼 디텍션 단계에서는, 이미지 내의 선원을 포함하는 바운딩 박스 로 잘려진 이미지인 Cropped Human Image를 도출하고, 상기 포즈 에스티메이션 단계에서는, 상기 바운딩 박스 내의 선원의 신체에서 키포인트들을 추출하여 Human 2D Pose를 도출하며, 상기 행동 인식 단계는, 인공지능모듈 이 상기 바운딩 박스 및 상기 키포인트들을 분석하여 상기 선원의 상태를 판단하되, 상기 선원의 상태는 서있는 상태, 앉아있는 상태, 누워있는 상태를 포함할 수 있다. 또한, 상기 인공지능모듈은 MMHAR 학습모델을 포함하며, 상기 MMHAR 학습모델은, Cropped Human Image를 CNN(Convolutional Neural Network) 모델로 학습하고, Human 2D Pose를 MLP(Multi Layer Perceptron) 모델로 학습하고, 상기 CNN 모델과 상기 MLP 모델의 특성을 연결하고 FC(Fully Connected Layer)와 Softmax Activation Function을 적용해서 도출되는 값으로 상기 선원의 상태를 판단할 수 있다. 또한, 안전모 검출 단계를 더 포함하되, 상기 휴먼 디텍션 단계에서는, 이미지 내의 선원을 포함하는 바운딩 박 스로 잘려진 이미지인 Cropped Human Image를 도출하고, 상기 포즈 에스티메이션 단계에서는, 상기 바운딩 박스 내의 선원의 신체에서 키포인트들을 추출하여 Human 2D Pose를 도출하되, 상기 키포인트들에는 사람의 머리가 포함되고, 상기 안전모 검출 단계는, 딥러닝 기반의 YOLOv5 모델을 포함하는 인공지능모듈이 상기 Human 2D Pose에서 사람의 머리에 해당하는 위치에서 안전모가 검출되는지를 판단하는 방식으로 수행될 수 있다."}
{"patent_id": "10-2022-0190442", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명의 일 실시예에 따르면, 선박의 사고를 예방하고 선원 근태 관리의 효율성을 향상시킬 수 있다."}
{"patent_id": "10-2022-0190442", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명의 이점 및 특징, 그리고 그것들을 달성하는 방법은 첨부되는 도면들과 함께 상세하게 후술되어 있는 실 시예들을 참조하면 명확해질 것이다. 그러나 본 발명은 이하에서 개시되는 실시예들에 한정되는 것이 아니라 서 로 다른 다양한 형태로 구현될 수 있다. 본 실시예들은 본 발명의 개시가 완전하도록 하고, 본 발명이 속하는"}
{"patent_id": "10-2022-0190442", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "기술분야에서 통상의 지식을 가진 자에게 발명의 범주를 완전하게 알려주기 위해 제공될 수 있다. 명세서 전문 에 걸쳐 동일 참조 부호는 동일 구성 요소를 지칭한다.본 명세서에서 사용된 용어들은 실시예들을 설명하기 위한 것이며 본 발명을 제한하고자 하는 단계는 아니다. 본 명세서에서, 단수형은 문구에서 특별히 언급하지 않는 한 복수형도 포함한다. 명세서에서 사용되는 '포함한 다(comprise)', '포함하는(comprising)'은 언급된 구성요소, 단계, 동작 및/또는 소자는 하나 이상의 다른 구성 요소, 단계, 동작 및/또는 소자의 존재 또는 추가를 배제하지 않는다. 이하에서는 첨부된 도면을 참조하여 본 발명의 구성 및 작용효과를 더욱 상세하게 설명한다. 도 1은 본 발명의 일 실시예에 따른 영상인식 기반 선원 모니터링 시스템을 개략적으로 예시한 블 록도이고, 도 2는 본 발명의 일 실시예에 따른 영상인식 기반 선원 모니터링 방법을 개략적으로 예시한 도면이 다. 도면을 참조하면, 본 발명의 일 실시예에 따른 영상인식 기반 선원 모니터링 시스템은, 카메라 및 모니터 링 장치를 포함할 수 있다. 더 나아가, 영상인식 기반 선원 모니터링 시스템은, 제1 단말, 위 성 통신망, 서비스 서버 및 제2 단말 중 어느 하나를 더 포함할 수 있다. 일 실시예에서, 카메라는 통상적으로 사용되고 있는 CCTV 등의 카메라로 구현될 수 있다. 이때, 선박의 주요 모 니터링 대상 공간들을 촬영하기 위하여 복수 개의 카메라(100-1, 100-2, … 100-n)가 구비될 수 있다. 일 실시예에서, 모니터링 장치는 통신 인터페이스부, 제어부 및 데이터베이스부를 포함할 수 있다. 통신 인터페이스부는 카메라와 연결되어 카메라가 촬영한 영상을 전송받을 수 있다. 모니터링 장 치가 선박에 구비되는 경우, 카메라와 모니터링 장치는 유선 통신망으로 연결될 수 있지만, 필요에 따라 카메라와 모니터링 장치가 로컬 무선 통신망으로 연결될 수도 있다. 일 실시예에서, 데이터베이스부는 전송받은 영상을 저장하여 제어부가 해당 영상들을 활용해서 각종 분석 및 처리를 수행할 수 있도록 하며, 제어부가 분석한 결과물들을 저장하는 기능도 수행할 수 있다. 일 실시예에서, 제어부는 카메라가 촬영한 영상을 분석해서 선원의 존재를 검출하고 검출된 선원의 자세를 추정하여 선원의 상태를 판단할 수 있다. 일 실시예에서, 선원의 상태는 서있는 상태, 앉아있는 상태, 누워있는 상태 중 어느 한 상태를 포함할 수 있다. 다른 실시예에서, 제어부는 선원이 안전모를 머리에 착용하고 있는지를 판단할 수 있다. 일 실시예에서, 제어부는 전술한 기능들을 수행하기 위하여 휴먼 디텍션 모듈, 포즈 에스티메이션 모 듈, 행동 인식 모듈, 안전모 검출 모듈 중 어느 하나 이상을 포함할 수 있다. 일 실시예에서, 모니터링 장치에는 인공지능모듈이 포함될 수 있다. 인공지능모듈은 제어부 와 협력하여 휴먼 디텍션, 포즈 에스티메이션, 행동 인식, 안전모 검출 등의 기능이 수행되도록 할 수 있 다. 다른 실시예에서, 인공지능모듈은 제어부에 포함될 수도 있다. 일 실시예에서, 제1 단말은 선박에 구비되는 단말로써, 모니터링 장치와 유선 통신망 또는 로컬 무선 통신망으로 연결될 수 있으며, 모니터링 장치가 출력하는 선원의 상태나 안전모 착용여부 등을 확인할 수 있다. 한편, 제1 단말을 통해서 입력되는 영상이나 명령 등이 모니터링 장치로 전달되어 모니터링 장 치의 작동에 반영되도록 할 수도 있다. 일 실시예에서, 영상인식 기반 선원 모니터링 시스템에는 위성 통신망이 포함될 수 있으며, 위성 통 신망을 통해서 선박이 육지로부터 멀리 떨어진 경우에도 서비스 서버와 모니터링 장치가 연결되 도록 할 수 있다. 일 실시예에서, 서비스 서버는 모니터링 장치와 통신 연결되어 모니터링 장치가 출력하는 선원 의 상태를 수신하며, 이렇게 수신된 정보를 이용해서 선원 모니터링 결과를 제공하는 소정의 GUI를 구축하고, 서비스 서버에 접속하는 제2 단말에게 선원 모니터링 결과를 제공하는 기능을 수행할 수 있다. 여기서 제2 단말은 선박이나 선원을 관리하는 해운사나 선주 등의 관계자가 접속하는 단말을 의미할 수 있다. 또한, 도 3에 예시된 바와 같은 화면구성을 가지는 대시보드 형태의 모니터링 화면이 제2 단말에서 표시될 수 있다. 본 발명의 일 실시예에 따른 영상인식 기반 선원 모니터링 방법은 이미지를 입력받는 단계(S110), 입력된 이미 지에서 선원을 검출하는 휴먼 디텍션 단계(S120), 검출된 선원의 자세를 추정하는 포즈 에스티메이션 단계 (S130)를 포함한다. 더 나아가, 영상인식 기반 선원 모니터링 방법은 행동 인식 단계(S141) 및 안전모 검출 단 계(S142)를 더 포함할 수 있다. 이러한 과정을 수행한 결과물이 대시보드 등의 GUI로 표시되도록 할 수도 있다. 일 실시예에서, 휴먼 디텍션 단계에서는 Cropped Human Image가 도출될 수 있다. 여기서, Cropped Human Image 는 이미지 내의 선원을 포함하는 바운딩 박스로 잘려진 이미지를 의미한다. 또한, 포즈 에스티메이션 단계에서는 Human 2D Pose가 도출될 수 있으며, Human 2D Pose는 사람의 신체에서 키 포인트(keypoint)들을 추출하여 도출되는 선원의 자세 추정 결과를 의미한다. 일 실시예에서, 행동 인식 단계는, 인공지능모듈이 바운딩 박스 및 키포인트들을 분석하여 선원의 상태를 판단할 수 있다. 여기서, 선원의 상태는 서있는 상태, 앉아있는 상태, 누워있는 상태를 포함할 수 있다. 일 실시예에서, 인공지능모듈은 행동 인식 단계를 수행하기 위한 MMHAR 학습모델을 포함할 수 있다. 이 MMHAR 학습모델은, Cropped Human Image를 CNN(Convolutional Neural Network) 모델로 학습하고, Human 2D Pose를 MLP(Multi Layer Perceptron) 모델로 학습하고, CNN 모델과 MLP 모델의 특성을 연결하고 FC(Fully Connected Layer)와 Softmax Activation Function을 적용해서 도출되는 값으로 행동을 인식할 수 있도록 디자 인되고 학습된 모델이다. 일 실시예에서, 안전모 검출단계는, 딥러닝 기반의 학습모델을 포함하는 인공지능모듈에 의하여 수행될 수 있다. 이미지에서 안전모를 검출하기 위한 딥러닝 기반의 학습모델로는 YOLOv5 모델 등이 있다. 도 3은 본 발명의 일 실시예에 따른 영상인식 기반 선원 모니터링 시스템에서 출력되는 모니터링 출력화 면을 설명하기 위한 도면이다, 도 3을 참조하면, 이미지에 안전모가 존재하는가의 여부만 단순히 판단하는 모델 을 사용한다면, 도 3의 (a)에 표시된 바와 같이 선원이 안전모를 손에 들고 있는 경우에도 안전모가 검출된 정 상 상황인 것으로 판단될 위험성이 존재한다. 이러한 문제를 해결하기 위하여, 본 발명의 일 실시예에 따른 영 상인식 기반 선원 모니터링 방법에서는, Hardhat Detection 이전에 Human Detection 및 Pose Estimation Task 를 추가로 프로세스에 접목하여, 알고리즘을 통해 식별된 Head Keypoint가 Hardhat Detection을 통해 검출된 Bounding Box 내에 존재하는 경우 안전모 착용 여부에 대한 최종적인 결과가 도출되도록 할 수 있다. 일 실시예 에서, Human 2D Pose를 분석하여 사람의 머리에 해당하는 위치에서 안전모가 검출되는지를 판단하는 방식으로 안전모 검출단계가 수행되도록 할 수 있다. 이에 따라, 모자가 책상 위에 올려져 있거나, 선원이 모자를 들고 있는 경우 등, 이미지에서 안전모가 검출되기만 하면 모두 안전한 상태인 것으로 판단되는 오류를 감소시킬 수 있다. 도 4는 본 발명의 일 실시예에 따른 영상인식 기반 선원 모니터링 방법에 따른 안전모 검출을 설명하기 위한 도 면이고, 도 5는 선원의 상태 인식 과정을 설명하기 위한 도면이고, 도 6은 선원의 상태 구분을 설명하기 위한 도면이고, 도 7은 행동 인식 오류가 감소되는 원리를 설명하기 위한 도면이고, 도 8은 휴먼 바운딩 박스를 설명 하기 위한 도면이고, 도 9는 휴먼 2차원 포즈를 설명하기 위한 도면이고, 도 10은 데이터셋 구조를 설명하기 위 한 도면이고, 도 11은 데이터 전처리를 설명하기 위한 도면이고, 도 12는 MMHAR을 개략적으로 예시한 도면이다. 이하에서는 인공지능모듈과 제어부가 연계하여 휴먼 디텍션, 포즈 에스티메이션, 행동 인식을 진행하 는 것에 관하여 보다 상세하게 설명한다. 인공지능모듈은 딥러닝 방식으로 학습된 딥러닝 모델을 포함할 수 있다. 딥러닝 모델은 사람의 두뇌를 모 방한 것으로, 실제 사람이 특정 사물, 정보 등을 분석하여 결론을 도출하듯이, 딥러닝 모델이 대량의 데이터를 보고 딥러닝 모델을 통해 학습하여 결론을 도출하는 것이라고 볼 수 있다. 딥러닝을 구현하기 위해서는 대량의 데이터와 딥러닝 모델(Deep Neural Network)이 필요하다. 딥러닝 모델이 특 정 Task에서 데이터를 보고 예측 값을 도출하는 과정을 진행하면서 실제 값과 비교하고 그 차이를 도출한다. 이 렇게 얻어진 차이값을 이용해서 딥러닝 모델에 가중치 업데이트를 진행하게 되며, 이러한 과정을 충분한 횟수만 큼 반복하면서 딥러닝 모델이 도출하는 예측 값과 실제 값과의 차이값이 감소되도록 하는 것이 딥러닝의 학습 원리라고 볼 수 있다. 한편, 현실에서 수집되는 데이터는 우리가 생각하는 형태와는 많이 다른 경우가 있고 Task를 해결하기 위한 데 이터가 많이 부족한 상황이 발생할 수 있다. 따라서, 실제 비즈니스 문제 상황을 잘 표현하며 모델 학습이 잘 이루어질 수 있는 데이터 스킴을 정의하고 학습 데이터셋을 구축하는 작업은 매우 중요하다. 인공지능모듈의 딥러닝 모델 구현 과정은 학습할 데이터를 결정하고(Feature), 학습을 위한 딥러닝 모델을 설계하며(Model), 딥러닝 모델의 학습을 통해서 어떤 결과를 도출할지를 결정(Label)하는 3단계로 구분할 수 있 다. 본 발명의 일 실시예에 따른 영상인식 기반 선원 모니터링 시스템에서 선원의 행동을 인식하기 위한 과정의 전체적인 흐름은 도 5와 같이 모식화될 수 있으며, Feature로 정의한 데이터들은 Model을 통해 승무원이 어떠한 행동을 나타내는지를 Label로 도출하게 된다. 도 5에 예시된 바와 같이, Label 단계에서는 선원에 대한 행동을 총 4가지의 클래스로 분류하여 결과를 도출할 수 있다. 일 실시예에서, 선원의 행동은 Stand(일어서 있는), Sit(앉아 있는), Fall_down(누워있는, 쓰러짐)과 같이 크게 3가지로 분류할 수 있다. Feature 데이터로 정의되는 이미지가 연속적으로 입력되는 구조에서는 현재 이미지와 다음 이미지와의 상관 관계를 통한 분석이 가능하므로 선원의 행동 분류 클래스에 걷거나 뛰는 등의 움직임에 대한 분류도 가능하다. 도 6에 예시된 바와 같이 선박 구조상 선원이 구조물에 의해 가려져 보이는 경우가 많아서, 선원의 행동이 서있 는 자세인지, 앉아 있는 자세인지 명확한 기준을 잡기 곤란한 경우가 많다. 따라서, 이러한 경우는 Unknown(명 확하지 않은 행동) 클래스로 분류하는 것이 바람직하다. 도 7의 (a)를 참조하면, 이미지 내에서 식별된 사람은 누워있는 행동을 취하고 있지만 단순히 Human 2D Pose 데 이터 측면에서만 본다면 서 있는 행동으로 판단하는 오류가 발생될 수 있다. 이와 같은 오류를 감소시키기 위해 서, 본 발명의 일 실시예에 따른 영상인식 기반 선원 모니터링 시스템은, 도 7의 (b)에 예시된 바와 같이 이미지 내에서 식별된 선원의 위치를 박스 형태로 나타낸 데이터로 Human Bounding Box를 추가로 정의할 수 있 다. Bounding Box 데이터를 통해 이미지 내 식별된 선원의 영역을 Box 형태로 이미지를 잘라내어 이미지 정보를 생성하고, 잘라낸 이미지 정보와 Human 2D Pose 데이터를 동시에 보고 식별된 사람의 행동을 판단함으로써 Label 분류 오류를 감소시킬 수 있다. 일 실시예에서, 인공지능모듈의 딥러닝 모델이 학습할 데이터(Feature)에는 이미지(Image), 휴먼 바운딩 박스(Human Bounding Box), 휴먼 2차원 포즈(Human 2D Pose)가 포함될 수 있다. 이미지는 CCTV 등 카메라에 의하여 촬영된 영상으로부터 획득될 수 있다. 휴먼 바운딩 박스는 도 8에 예시된 바와 같이 이미지 내 식별된 선원을 바운딩 박스 형태로 검출한 데이터로써, 바운딩 박스 좌측 상단 좌표 (x1, y1), 바운딩 박스 우측 하단 좌표 (x2, y2)에 의하여 규정될 수 있다. 휴먼 2차원 포즈는 도 9에 예시된 바와 같이 이미지 내 식별된 선원의 자세를 키포인트 형태로 검출 가능한 데 이터로써, 키포인트는 머리, 목, 우측 어깨, 우측 팔꿈치, 우측 손목, 좌측 어깨, 좌측 팔꿈 치, 좌측 손목, 우측 엉덩이, 우측 무릎, 우측 발목, 좌측 엉덩이, 좌측 무릎, 좌측 발목 각각의 키포인트의 x,y 좌표로 규정될 수 있다. 일 실시예에서, 인공지능모듈의 딥러닝을 수행하기 위한 베이스라인 데이터셋을 구축할 수 있으며, 이 베 이스라인 데이터셋을 구축하는 과정은 다음과 같다. 먼저, 여러 오픈 데이터셋을 통해 CCTV 뷰를 포함하여 사람이 식별되는 다양한 이미지를 수집할 수 있다. 이렇 게 수집된 이미지는 Human Detection과 Pose Estimation 알고리즘을 적용하여 Bounding Box와 2D Pose에 대한데이터를 JSON 포맷으로 구성하여 생성할 수 있다. 또한, Action의 경우는 2D Pose를 시각화하고 시각화한 데이 터를 직접 보고 Action에 따라 분류하는 작업을 진행한다. 이러한 과정을 거쳐서 분류 작업이 완료되면, 분류된 Action을 추가로 JSON 포맷에 구성하였으며, JSON 포맷은 이미지 이름 및 이미지 크기, 이미지 내 식별된 사람 의 Action 및 Bounding Box, 2D Pose 데이터를 포함할 수 있다. 행동 분류 작업이 완료된 이후에는 학습 가능한 형태의 파일 구조로 변환될 수 있다. 도 10을 참조하면, 모든 이미지 파일은 images 폴더에 담겨지고, JSON 포맷의 데이터는 CSV 포맷으로 변환하여 모든 이미지에 대한 데이 터를 포함하도록 할 수 있으며, 여기에는, 이미지 이름, 이미지 크기, 이미지 내 식별된 사람의 행동 및 Bounding Box, 2D Pose 데이터가 포함될 수 있다. 일 실시예에서, 선박 내 조명, 구조물, 승무원 행동 등 다양한 조건에 따른 환경을 구성할 수 있는 프로그램을 이용해서 추가적인 데이터를 생성할 수 있으며, 이렇게 생성된 데이터들을 포함하여 베이스라인 데이터셋 구축 과정이 진행될 수 있다. 이에 따라, 행동 인식 모델의 정확도가 향상될 수 있다. 일 실시예에서, 구축된 베이스라인 데이터셋을 전처리하여 인공지능모듈의 딥러닝에 활용될 수 있는 데이 터 포멧으로 변형하는 과정이 수행될 수 있다. 도 11을 참조하면, Feature 데이터의 Image에서 식별된 사람에 대해 Human Bounding Box 데이터를 사용하며, 식별된 사람 주변의 배경 정보를 활용하기 위해서 Bounding Box에 약간의 Padding을 주어 해당 Box 크기만큼 이 미지를 자를 수 있다. 이렇게 자른 이미지(Cropped Human Image) 정보를 학습 모델에 사용할 수 있다. 일 실시 예에서, Human 2D Pose 데이터의 경우 데이터셋 구축 과정에서 나타낸바와 같이 사람의 Pose 정보를 나타내는 Keypoints 형태의 데이터가 사용될 수 있다. 한편, 식별된 선원의 행동을 나타내는 데이터인 Label은 Stand, Sit, Fall_down, Unknown으로 분류된다. 본 발 명의 일 실시예에 따른 영상인식 기반 선원 모니터링 시스템에서는 One-hot 인코딩 방법을 사용하여 Label 데이터를 전처리할 수 있다. 여기서, One-hot 인코딩 방법은 분류하는 값을 컬럼으로 나누고 고유 값에 해당하는 컬럼에 1을 표시하고 나머지 컬럼에는 0을 표시하는 방법이다. 분류 작업 관련 데이터 전처리 방법에 는 One-hot 인코딩 방법과 Label 인코딩 방법이 포함되는데, Label 인코딩은 분류하는 값에 숫자형 카테고리 값을 표시하는 방식이다. 본 발명의 일 실시예에 따른 영상인식 기반 선원 모니터링 시스템에서 다루는 Label 데이터는 Stand, Sit, Fall_down, Unknown 와 같이 분류하는 값들이 서로 순서가 없고 클래스의 개수가 많지 않으므로 One-hot 인코딩 방법을 적용하는 것이 바람직하다. 예컨대, Stand → [1,0,0,0] : 일어서 있는 자세, Sit→[0,1,0,0]: 앉아 있는 자세, Fall_down → [0, 0, 1, 0] : 누워있거나 쓰러진 자세, Unknown → [0, 0, 0, 1] : 구조물에 가려져 명확하지 않은 자세 등으로 Label 데이터가 전처리될 수 있다. 도 11을 참조하면, 일 실시예에서, 인공지능모듈에는 MMHAR 모델이 포함될 수 있다. MMHAR 모델에는 데이 터 전처리 결과물인 Cropped Human Image와 Human 2D Pose 데이터가 입력으로 적용된다. 또한, MMHAR 모델은 Multi Modal Learning을 통해 서로 다른 Feature(Cropped Human Image와 Human 2D Pose) 간의 특징을 학습하고 Human Action(stand, sit, fall_down, unknown)을 예측할 수 있다. 일 실시예에서, MMHAR 모델에서 Cropped Human Image 학습에는 CNN(Convolutional Neural Network) 모델이 적 용되고, Human 2D Pose 학습에는 MLP(Multi Layer Perceptron) 모델이 적용될 수 있다. 그리고 CNN과 MLP 모델 의 특성을 연결하고 FC(Fully Connected Layer)와 Softmax Activation Function를 통해 최종적으로 모델의 Output인 Human Action을 예측할 수 있다."}
{"patent_id": "10-2022-0190442", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일 실시예에 따른 영상인식 기반 선원 모니터링 시스템을 개략적으로 예시한 블록도이고, 도 2는 본 발명의 일 실시예에 따른 영상인식 기반 선원 모니터링 방법을 개략적으로 예시한 도면이고, 도 3은 본 발명의 일 실시예에 따른 영상인식 기반 선원 모니터링 시스템에서 출력되는 모니터링 출력화면을 설 명하기 위한 도면이고, 도 4는 본 발명의 일 실시예에 따른 영상인식 기반 선원 모니터링 방법의 안전모 검출을 설명하기 위한 도면이 고, 도 5는 본 발명의 일 실시예에 따른 영상인식 기반 선원 모니터링 방법의 선원의 상태 인식 과정을 설명하기 위 한 도면이고, 도 6은 본 발명의 일 실시예에 따른 영상인식 기반 선원 모니터링 방법의 선원의 상태 구분을 설명하기 위한 도 면이고, 도 7은 본 발명의 일 실시예에 따른 영상인식 기반 선원 모니터링 방법을 통해서 행동 인식 오류가 감소되는 원 리를 설명하기 위한 도면이고, 도 8은 본 발명의 일 실시예에 따른 영상인식 기반 선원 모니터링 방법의 휴먼 바운딩 박스를 설명하기 위한 도 면이고, 도 9는 본 발명의 일 실시예에 따른 영상인식 기반 선원 모니터링 방법의 휴먼 2차원 포즈를 설명하기 위한 도 면이고, 도 10은 본 발명의 일 실시예에 따른 영상인식 기반 선원 모니터링 방법의 데이터셋 구조를 설명하기 위한 도면 이고, 도 11은 본 발명의 일 실시예에 따른 영상인식 기반 선원 모니터링 방법의 데이터 전처리를 설명하기 위한 도면 이고, 도 12는 본 발명의 일 실시예에 따른 영상인식 기반 선원 모니터링 방법의 MMHAR을 개략적으로 예시한 도면이다."}
