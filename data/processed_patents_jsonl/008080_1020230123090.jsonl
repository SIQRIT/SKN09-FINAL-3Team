{"patent_id": "10-2023-0123090", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2025-0040271", "출원번호": "10-2023-0123090", "발명의 명칭": "멀티모달-스킬을 통한 비정적 환경에서의 원샷 모방 방법과 학습 방법, 그리고 이의 연산 장", "출원인": "성균관대학교산학협력단", "발명자": "우홍욱"}}
{"patent_id": "10-2023-0123090", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "전문가의 비디오 시연을 적응적으로 원샷 모방하는 인공 신경망 모델에 기초한 원샷 모방 방법의 학습 방법에관한 것으로,주어진 전문가 시연에서 세만틱 스킬 배열을 추론하도록 학습하는 제1 단계;상기 주어진 전문가 시연에서 상기 전문가의 액션 궤적을 이루는 최소 단위인 상태-행동 쌍을 토대로 다이나믹스를 추론하도록 학습하는 제2 단계;상기 추론된 세만틱 스킬과 다이나믹스를 주어진 환경 데이터를 기초로 조합해 액션 시퀀스를 만들도록 학습하는 제3 단계;를 포함하는 학습 방법."}
{"patent_id": "10-2023-0123090", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 인공 신경망 모델은, 비전 인코더와 언어 인코더를 포함해 구성된 학습된 비전-언어 모델에 기초하는 학습방법."}
{"patent_id": "10-2023-0123090", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,상기 인공 신경망 모델은 프롬프트에 기반해 학습된, 학습 방법."}
{"patent_id": "10-2023-0123090", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,상기 제1 단계에서, 상기 상태-행동 쌍으로부터 환경에 대한 파라미터를 추론하기 위해 동일한 환경에서 실행된상태-행동 쌍(positive pair)끼리는 같은 곳으로 임베딩하고, 다른 환경(negative environment)에서 실행된 상태-행동 쌍끼리는 멀어지도록 임베딩하는 대조 학습에 기반해 학습되는, 학습 방법."}
{"patent_id": "10-2023-0123090", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서,상기 인공 신경망 모델은,전문가의 비디오 시연을 세만틱 스킬 배열로 변환하기 위해 대조적으로 학습된 세만틱 스킬인코더( )와,상태(state)에 따라 상기 세만틱 스킬 배열로부터 최적의 스킬을 추론하는 세만틱 스킬 디코더( ),를 포함하는 학습 방법."}
{"patent_id": "10-2023-0123090", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5항에 있어서,상기 인공 신경망 모델은,주어진 세만틱 스킬 배열과 추론된 다이나믹스로부터 에이전트의 동작(실행)에 최적화된 액션 배열(actionsequence)을 추론하는 스킬 트랜스퍼()와,공개특허 10-2025-0040271-4-전문가 궤적에서 다이나믹스를 추론하는 다이나믹스 인코더(),를 더 포함하는 학습 방법."}
{"patent_id": "10-2023-0123090", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "전문가의 비디오 시연을 적응적으로 원샷 모방하는 인공 신경망 모델에 기초한 원샷 모방 방법에 관한 것으로,주어진 전문가 시연에서 세만틱 스킬 배열을 추론하는 제1 단계;에이전트를 동작시켜 상태-행동 쌍을 시계열적으로 발생시키고, 이를 기초로 현재 상태의 다이나믹스를 추론하는 제2 단계;추론된 세만틱 스킬 배열과 추론된 다이나믹스를 현재 획득한 환경 데이터를 기초로 조합해 추론된 세만틱 스킬을 재조합하여 새로운 도메인에 맞는 액션을 수행하는 제3 단계;를 포함하는 원샷 모방 방법."}
{"patent_id": "10-2023-0123090", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서,상기 인공 신경망 모델은, 비전 인코더와 언어 인코더를 포함해 구성된 학습된 비전-언어 모델에 기초하는 원샷모방 방법."}
{"patent_id": "10-2023-0123090", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제7항에 있어서,상기 인공 신경망 모델은 프롬프트에 기반해 학습된, 원샷 모방 방법."}
{"patent_id": "10-2023-0123090", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제7항에 있어서,상기 인공 신경망 모델은, 상기 상태-행동 쌍으로부터 환경에 대한 파라미터를 추론하기 위해 동일한 환경에서실행된 상태-행동 쌍(positive pair)끼리는 같은 곳으로 임베딩하고, 다른 환경(negative environment)에서 실행된 상태-행동 쌍끼리는 멀어지도록 임베딩하는 대조 학습에 기반해 학습된, 원샷 모방 방법."}
{"patent_id": "10-2023-0123090", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제7항에 있어서,상기 인공 신경망 모델은,전문가의 비디오 시연을 세만틱 스킬 배열로 변환하기 위해 대조적으로 학습된 세만틱 스킬인코더( )와,상태(state)에 따라 상기 세만틱 스킬 배열로부터 최적의 스킬을 추론하는 세만틱 스킬 디코더( ),를 포함하는 원샷 모방 방법."}
{"patent_id": "10-2023-0123090", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항에 있어서,상기 인공 신경망 모델은,주어진 세만틱 스킬 배열과 추론된 다이나믹스로부터 에이전트의 동작(실행)에 최적화된 액션 배열(actionsequence)을 추론하는 스킬 트랜스퍼()와,공개특허 10-2025-0040271-5-전문가 궤적에서 다이나믹스를 추론하는 다이나믹스 인코더(),를 더 포함하는 원샷 모방 방법."}
{"patent_id": "10-2023-0123090", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "전문가의 비디오 시연을 적응적으로 원샷 모방하는 인공 신경망 모델을 저장하는 메모리; 및상기 인공 신경망 모델을 실행하는 프로세서;를 포함하고,상기 인공 신경망 모델은,학습 과정에서, 주어진 전문가 시연에서 세만틱 스킬 배열을 추론하도록 학습하고, 상기 주어진 전문가 시연에서 상기 전문가의액션 궤적을 이루는 최소 단위인 상태-행동 쌍을 토대로 다이나믹스를 추론하도록 학습하고, 상기 추론된 세만틱 스킬과 다이나믹스를 주어진 환경 데이터에 기초해 조합해 액션 시퀀스를 만들도록 학습하는,연산 장치."}
{"patent_id": "10-2023-0123090", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제13항에 있어서,상기 인공 신경망 모델은,실행 과정에서, 주어진 전문가 시연에서 세만틱 스킬 배열을 추론하고, 에이전트를 동작시켜 상태-행동 쌍을 시계열적으로 발생시켜 현재 상태의 다이나믹스를 추론하고, 추론된 세만틱 스킬 배열과 추론된 다이나믹스를 현재 획득된 환경데이터를 기초로 조합해 추론된 세만틱 스킬을 재조립하여 새로운 도메인에 맞는 액션을 수행하는,연산 장치."}
{"patent_id": "10-2023-0123090", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제13항에 있어서,상기 인공 신경망 모델은, 비전 인코더와 언어 인코더를 포함해 구성된 학습된 비전-언어 모델에 기초하는 연산장치."}
{"patent_id": "10-2023-0123090", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제15항에 있어서,상기 인공 신경망 모델은 프롬프트에 기반해 학습된, 연산 장치."}
{"patent_id": "10-2023-0123090", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제1항에 있어서,상기 인공 신경망 모델은, 상기 상태-행동 쌍으로부터 환경에 대한 파라미터를 추론하기 위해 동일한 환경에서실행된 상태-행동 쌍(positive pair)끼리는 같은 곳으로 임베딩하고, 다른 환경(negative environment)에서 실행된 상태-행동 쌍끼리는 멀어지도록 임베딩하는 대조 학습에 기반해 학습되는, 연산 장치."}
{"patent_id": "10-2023-0123090", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제13항에 있어서,상기 인공 신경망 모델은,전문가의 비디오 시연을 세만틱 스킬 배열로 변환하기 위해 대조적으로 학습된 세만틱 스킬공개특허 10-2025-0040271-6-인코더( )와,상태(state)에 따라 상기 세만틱 스킬 배열로부터 최적의 스킬을 추론하는 세만틱 스킬 디코더( ),를 포함하는 연산 장치."}
{"patent_id": "10-2023-0123090", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제18항에 있어서,상기 인공 신경망 모델은, 주어진 세만틱 스킬 배열과 추론된 다이나믹스로부터 에이전트의 동작(실행)에 최적화된 액션 배열(actionsequence)을 추론하는 스킬 트랜스퍼()와,전문가 궤적에서 다이나믹스를 추론하는 다이나믹스 인코더()를 포함하는, 연산 장치."}
{"patent_id": "10-2023-0123090", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "상기 제1항 내지 제6항 중 어느 한 항의 학습 방법 또는 상기 제7항 내지 12 중 어느 한 항의 원샷 모방 방법을컴퓨터가 실행할 수 있는 프로그램으로 기록한 기록 매체."}
{"patent_id": "10-2023-0123090", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명의 일 실시예는 전문가의 비디오 시연을 적응적으로 원샷 모방하는 인공 신경망 모델에 기초한 원샷 모방 방법의 학습 방법에 관한 것으로, 주어진 전문가 시연에서 세만틱 스킬 배열을 추론하도록 학습하는 제1 단계, 상기 주어진 전문가 시연에서 상기 전문가의 액션 궤적을 이루는 최소 단위인 상태-행동 쌍을 토대로 다이나믹스 를 추론하도록 학습하는 제2 단계, 상기 추론된 세만틱 스킬과 다이나믹스를 주어진 환경 데이터에 기초해 조합 해 액션 시퀀스를 만들도록 학습하는 제3 단계를 포함한다."}
{"patent_id": "10-2023-0123090", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 원샷 모방 방법에 관한 것으로, 사전 학습된 비전-언어 모델을 활용하여 모델을 학습해 적응적으로 단일의 원샷 모방을 통해 에이전트(agent)가 다양한 도메인에서 올바르게 실행될 수 있도록 한 원샷 모방 방법 에 관한 것이다."}
{"patent_id": "10-2023-0123090", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "원샷 모방(one shot imitation)은 한 번의 전문가 시연으로 새로운 태스크(task)에 대한 학습을 가능하게 한다. 동시에, 에이전트(예, 로봇)가 학습된 환경(또는, 도메인)과 다른 환경에서 전문가 시연을 모방하는 것은 높은 실용성을 가지지만, 높은 도메인 다양성을 지닌 비정적 환경(non-stationary environment)에서 태스크를 원샷 모방하는 것은 어렵다. 비디오 또는 언어 지시를 통한 한 번의 전문가 시연을 통해 태스크를 학습하는 원샷 모방학습을 하는 방식은 첫 번째로 시연에 내재된 의미론적인 정보를 활용하기 위하여 비디오와 그에 대한 언어 지시 사이의 유사도를 높이 는 BC-Z 기법이 있고, 두 번째로 트랜스포머의 높은 순차적 예측 능력과 어텐션을 활용하기 위해 전문가 시연을 조건적으로 학습하는 Decision Transformer 기반의 방식이 있다. 하지만 두 방법 모두 모델을 학습된 환경이 아닌 새로운 도메인에서 전문가 시연을 모방할 경우 성능이 저하된 다."}
{"patent_id": "10-2023-0123090", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 이 같은 기술적 배경에 창안된 것으로, 에이전트가 학습하는 과정에서 보지 못 한 새로운 비정적 환 경에서 전문가를 원샷 모방시 성능 저하 없이 효율적이고 안정적인 모방을 가능케 하는 것이다."}
{"patent_id": "10-2023-0123090", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "일 실시예는 전문가의 비디오 시연을 적응적으로 원샷 모방하는 인공 신경망 모델에 기초한 원샷 모방 방법의 학습 방법에 관한 것으로, 주어진 전문가 시연에서 세만틱 스킬 배열을 추론하도록 학습하는 제1 단계, 상기 주 어진 전문가 시연에서 상기 전문가의 액션 궤적을 이루는 최소 단위인 상태-행동 쌍을 토대로 다이나믹스를 추 론하도록 학습하는 제2 단계, 상기 추론된 세만틱 스킬과 다이나믹스를 주어진 환경 데이터에 기초해 스킬을 재 조립해서 액션 시퀀스를 만들도록 학습하는 제3 단계를 포함한다. 일 실시예의 원샷 모방 방법은, 전문가의 비디오 시연을 적응적으로 원샷 모방하는 인공 신경망 모델에 기초한 원샷 모방 방법에 관한 것으로, 주어진 전문가 시연에서 세만틱 스킬 배열을 추론하는 제1 단계, 에이전트를 동 작시켜 상태-행동 쌍을 시계열적으로 발생시키고, 이를 기초로 현재 상태의 다이나믹스를 추론하는 제2 단계, 추론된 세만틱 스킬 배열과 추론된 다이나믹스를 현재 획득한 환경 데이터를 기초로 조합해 추론된 세만틱 스킬 을 재조합하여 새로운 도메인에 맞는 액션을 수행하는 제3 단계를 포함한다. 본 발명의 다른 실시예들에서는 상술한 방법을 구현하는 연산 장치 및 이를 기록한 기록매체를 개시한다."}
{"patent_id": "10-2023-0123090", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명에 따르면, 하나의 전문가 시연만을 통해 태스크를 해결하고, 더 나아가 학습한 과정에서 보지 못한 새 로운 비정적 환경에서 에이전트를 실행할 때 생기는 성능 저하의 문제를 해결하기 때문에, 다양한 환경에서 실 행되어야 하는 실제 세계 모방학습 모델의 문제점을 데이터 효율적으로 해결할 수가 있다."}
{"patent_id": "10-2023-0123090", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하에서는 도면을 참조하여 본 발명의 실시예들을 구체적으로 설명하도록 한다. 다만, 하기의 설명 및 첨부된 도면에서 본 발명의 요지를 흐릴 수 있는 공지 기능 또는 구성에 대한 상세한 설명은 생략한다. 덧붙여, 명세서 전체에서, 어떤 구성 요소를 '포함'한다는 것은, 특별히 반대되는 기재가 없는 한 다른 구성요소를 제외하는 것 이 아니라, 다른 구성요소를 더 포함할 수 있는 것을 의미한다. 또한, 제 1, 제 2 등의 용어는 다양한 구성요소들을 설명하는데 사용될 수 있지만, 상기 구성 요소들은 상기 용 어들에 의해 한정되어서는 안 된다. 상기 용어들은 하나의 구성 요소를 다른 구성 요소로부터 구별하는 목적으 로 사용될 수 있다. 예를 들어, 본 발명의 권리 범위로부터 이탈되지 않은 채 제 1 구성 요소는 제 2 구성 요소 로 명명될 수 있고, 유사하게 제 2 구성 요소도 제 1 구성 요소로 명명될 수 있다. 본 발명에서 사용한 용어는 단지 특정한 실시예를 설명하기 위해 사용된 것으로, 본 발명을 한정하려는 의도가 아니다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 출원에서, \"포함 하다\" 또는 \"구비하다\" 등의 용어는 설시된 특징, 숫자, 단계, 동작, 구성요소, 부분품 또는 이들을 조합한 것 이 존재함을 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성요소, 부분품 또 는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되어야 한다. 특별히 다르게 정의되지 않는 한, 기술적이거나 과학적인 용어를 포함해서 여기서 사용되는 모든 용어들은 본"}
{"patent_id": "10-2023-0123090", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "발명이 속하는 기술분야에서 통상의 지식을 가진 자에 의해 일반적으로 이해되는 것과 동일한 의미이다. 일반적으로 사용되는 사전에 정의되어 있는 것과 같은 용어들은 관련 기술의 문맥상 가지는 의미와 일치하는 의미인 것으로 해석되어야 하며, 본 출원에서 명백하게 정의하지 않는 한, 이상적이거나 과도하게 형식적인 의미로 해 석되지 않는다. 일 실시예의 본 발명에서는 학습된 비전-언어 모델을 활용하여 한 장의 전문가 비디오 시연으로부터 비디오에 내재된 세만틱 스킬(semantic skill)의 배열을 추론하고, 전문가의 상태-행동 쌍(state-action pair)으로부터 환경에 내재된 숨은 파라미터를 찾아낸다. 여기서, 비전-언어 모델은 비전 인코더와 언어 인코더를 포함해 구성되며, 비전 인코더는 입력된 비디오를 임베 딩 공간에 벡터화하여 맵핑하고, 언어 인코더는 텍스트 형태로 주어지는 언어 지시를 같은 임베딩 공간에 맵핑 하여 둘 사이의 유사도를 예측하는 인공신경망 모델이다. 또한, 세만틱 스킬은 전문가 시연에서 시연된 전문가의 행동의 최소 단위로 학습된 비전-언어 모델에서 언어적 으로 표현되는 액션(action)의 최소 단위이기도 하다. 또한, 상태-행동 쌍은 전문가 시연에서 태스크를 행할 때 움직인 전체적인 궤적 상의 최소 단위로, 에이전트가 태스크를 수행할 때의 로그이기도 하다. 따라서, 태스크는 상태-행동 쌍의 배열로 정의할 수도 있다. 본 발명에서는 학습된 비전-언어 모델을 데이터 효율적으로 미세조정 할 수 있도록 프롬프트에 기반한 학습을 진행한다. 이 프롬프트 기반 학습은 비디오 자체의 임베딩이 비디오에 내재된 의미론적 정보와 유사해지도록 대 조 학습을 통해 학습된다. 이를 통해 환경과 무관한 수행해야 하는 태스크에 대한 정보(세만틱 스킬)만을 효과 적으로 분리하고 추론할 수 있도록 한다. 또한, 본 발명에서는 상태-행동 쌍으로부터 환경에 대한 파라미터를 추론하기 위해 대조 학습을 사용하고, 이 학습은 동일한 환경에서 실행된 상태-행동 쌍(positive pair)끼리는 같은 곳으로 임베딩 되도록 하며, 다른 환 경(negative environment)에서 실행된 상태-행동 쌍끼리는 멀어지도록 임베딩된다. 이 같은 프롬프트에 기반한 학습은 전문가 시연으로부터 수행해야 하는 태스크(예: 문을 연다, 서랍을 닫는다) 의 세부 구성 요소인 스킬의 배열을 추론하는 반면, 상태-행동 쌍에 기반한 환경 파라미터 학습을 통해 현재 환 경에 대한 정보(예: 현재 환경에서 불고 있는 바람의 세기)를 추론한다. 이를 통해, 본 발명에서는 에이전트가 새롭게 마주친 비정적 환경에서도 안정적인 원샷 모방학습을 수행할 수가 있다. 도 1은 본 발명을 개념적으로 설명하는 도면이다. 도 1에서, 본 발명은 단일 원샷 모방(single one shot imitation)을 학습 과정(training phase)과 학습된 바에 따라 전문가 시연을 재구성해 에이전트를 구동하는 실행 과정(deployment phase)을 포함한다. 지금까지 제안된 원샷 모방은 환경 마다의 전문가 시연이 반드시 필요한 방식이다. 즉, 문을 연다는 하나의 태 스크를 모방하는 경우에도, 환경이 변화하면 다른 환경에 따른 전문가 시연을 다시 모방해야 했다. 예를 들어서, 바람이 부는 환경과 바람이 불지 않는 환경에서 각각 문을 여는 동일한 태스크를 모방하기 위해서는 바 람이 부는 환경의 전문가 시연과 바람이 불지 않는 환경에서의 전문가 시연을 별도로 모방해야 그 환경에 맞춰 태스크를 실행할 수 있었다. 만약 에이전트가 모방했던 전문가 시연과 다른 환경에 놓이게 되면, 에이전트는 동 일한 태스크여도 해당 태스크를 모방하지 못하였다. 본 발명에서 제안하는 원샷 모방 방법은 이와는 다르게, 한번의 전문가 시연만 가지고도 모든 환경에 대해 적응 적으로 전문가 시연을 모방할 수 있는 방법에 관한 것이다. 이를 위해서, 본 발명에서는 전문가의 시연을 운동 요소인 태스크를 행하는 최소 단위인 세만틱 스킬(semantic skill)과, 환경 요소인 다이나믹스(dynamics)로 분해 학습한다. 실행 단계에서는 태스크에 대한 단일의 전문가의 비디오 시연(또는, 비디오 데모)이 주어지면 전문가 시연을 분 절해서 세만틱 스킬을 추론하고, 또한 학습이 완료된 에이전트를 동작시켜 발생한 상태-행동 쌍의 배열로부터 다이나믹스를 추론한 후 환경 데이터를 기초로 추론된 세만틱 스킬과 다이나믹스를 조합해 환경 패러미터에 따 른 액션 배열을 추론해 에이전트를 실행시킨다.도 1의 학습 과정에서, 본 발명에서는 전문가 시연 영상(video demo)과, 전문가 시연 영상내 궤적(trajectory) 에 따른 상태-행동 쌍이 각각 훈련데이터 셋으로 주어진다. 여기서, 영상내 궤적은 전문가 시연에서 에이전트가 태스크를 수행했었던 로그(log)로 상태-행동 쌍의 시퀀스(sequence)로 기술될 수 있다. 훈련 데이터 셋을 입력받은 인공신경망 모델은 전문가 시연 영상을 기초로 세만틱 스킬을 예측하도록 학습되고, 또한 상태-행동 쌍의 시퀀스를 기초로 다이나믹스를 예측하도록 학습된다. 여기서, 상태-행동 쌍은 특수한 물리 적 환경에서 기록된 에이전트의 상태 변화를 기술하므로, 상태-행동 쌍 배열에서 상태-행동 쌍과 다음 상태-행 동 쌍의 변화를 통해 환경 패러미터를 추론할 수가 있다. 또한, 학습 과정에서는 스킬 배열과 다이나믹스를 조합해 액션 배열을 추론하는데, 이 액션 배열은 환경 패러미 터가 반영된 에이전트의 동작을 말한다. 실행 과정에서는, 주어진 전문가 시연에서 인공신경망 모델은 학습된 바에 따라 스킬 배열을 추론하고, 또한 에 이전트가 움직임에 따라 발생되는 상태-행동 쌍 배열에 근거해 학습된 대로 다이나믹스를 추론해 현재 입력되는 환경 데이터에 기초해 다이나믹스와 스킬을 조합해 새로운 도메인(전문가 시연과 환경적으로 다른 도메인을 말 함)에 맞는 액션 배열을 추론한다. 도 2는 본 발명의 일 실시예에 따른 원샷 모방을 구현하는 인공 신경망 모델의 구성을 보여주는 도면이다. 도 2에서, 인공신경망 모델은 세만틱 스킬 모듈(a)과 스킬 전이 모듈(b)을 포함한다. 세만틱 스킬 모듈(a)은 세만틱 스킬 인코더( )와 세만틱 스킬 디코더( )를 포함하며, 세만틱 스 킬 인코더( )는 사전 학습된 CLIP 비전-언어 모델을 사용하여 오프라인으로 학습된다. 여기서, 세만틱 스킬 인코더는 전문가의 비디오 시연을 세만틱 스킬 배열로 변환하고 대조적으로 학습되며, 세만틱 스킬 디코더 ( )는 상태(state)에 따라 세만틱 스킬 배열로부터 최적의 스킬을 추론하는 방법을 학습한다. 언어 프롬프트( )는 부-레벨 지시(instruction) 케이스에 대해서만 사용되고, 부가적인 인코더인 는 에피소드-레벨 지시 케이스에 대해서만 사용된다. 스킬 전이 모듈(b)은 스킬 트랜스퍼( )와 다이나믹스 인코더( )를 포함하며, 스킬 트랜스퍼와 다이나 믹스 인코더는 오프라인에서 학습된다. 여기서, 여기서 스킬 트랜스퍼( )는 주어진 세만틱 스킬 배열과 추론 된 다이나믹스로부터 에이전트의 동작(실행)에 최적화된 액션 배열(action sequence)을 추론하는 방법을 학습하 고, 다이나믹스 인코더( )는 sub-trajectories에서 다이나믹스를 추론하는 방법을 학습한다. 이처럼 구성되는 인공신경망 모델은, 주어진 전문가 시연에 대해, 세만틱 스킬 인코더( )는 주어진 전문 가 시연에서 학습된 대로 세만틱 스킬 배열을 추론하고, 세만틱 스킬 디코더( )는 현재 실행할 세만틱 스 킬을 추론하며, 다이나믹스 인코더( )는 비정적 실행 환경에서 현재의 다이나믹스를 추론한다. 그런 다음, 스킬 트랜스퍼( )는 현재의 세만틱 스킬과 다이나믹스를 통해 최적화된 액션(action)을 생성한다. 이하, 인공신경망 모델을 구성하는 각 구성에 대해서 보다 자세히 설명하면 아래와 같다. 세만틱 스킬 인코더( ) 세만틱 스킬 인코더는 전문가 시연을 액션 배열(action sequences)인 환경과 무관한 행동 패턴(dynamics- invariant behavior)으로 분절함으로써 전문가 시연( )를 세만틱 스킬의 배열로 맵핑한다. 각각의 행동 패턴 은 전문가 시연의 최소 배열에 해당하고, 환경에서 언어 지시(language instruction)으로 기술될 수 있다. 이러 한 언어 지시와 관련된 전문가의 행동 패턴은 세만틱 스킬(semantice skill)로 기술될 수 있고, 관련된 언어 지 시는 비전-언어 모델의 세만틱 임베딩 공간(semantic embedding space) 상에서 전문가 행동을 나타내는데 이용 된다. 세만틱 스킬 인코더 구현을 위해, 본 발명에서는 사전 학습된 CLIP 비전-언어 모델(CLIP vision-language pretrained model)과 샘플 효과적인 프롬프트 학습(prompt learning techniques)을 이용한다. 구체적으로 본 발명에서는 전문가 궤적(trajectories) 의 데이터셋( )을 활용하며, 각 궤적(τ = {(s1, v1, l1, a1), · · · (sT , vT , lT , aT )}은 길이 T로 표현된다. 궤적의 요소는 상태 s, 시각 관찰 v, 언어 지시 l, 액션 a로 구성된다는 점에서 언어지시 데이터를 포함한다. 각 언어지시는 지시 셋트 (L)의 원소이다. 또한, 본 발명에서는 궤적에 표시된 언어 지시의 다른 2가지 케이스를 고려한다. 하나는 부태스크(subtask) 수 준의 지시, 예를 들어 단일 부태스크(subtask)의 전이(transition, 상태-행동 쌍에서 다음 상태-행동 쌍으로 넘 어가는 과정을 말함)에 표시된 \"push lever\"이고, 다른 하나는 에피소드 수준의 지시, 예를 들어 에피소드에서 모든 전이에 표시된 “Push lever, open door and close the box\"이다. 부태스크 수준의 지시 경우, 본 발명에서는 언어지시가 작은 서브셋(subset) 에 대해서만 존재하다 가정하고, 비전-언어 모델의 비디오 인코더( )와 언어 인코더( )는 아래 수학식 1과 같이 표현할 수 있 다. 수학식 1"}
{"patent_id": "10-2023-0123090", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "이 두 인코더( , )는 타임스텝(t)의 전문가 비디오 시연( )과 언어지시( )를 동일한 임베딩 공간에 맵핑힌다. 적은 숫자의 샘플을 이용해서 두 인코더( , )에 기반한 세만틱 스킬 인코더( ) 구현을 위해, 본 발명에서는 언어 프롬프트를 이용한다. 입력 로 나 가 주어지면, 세만틱 스킬 인코더는 각 입력을 세만틱 스킬의 배열로 변환하는 방법을 아래의 수학식2에 기초해 학습한다. 수학식 2"}
{"patent_id": "10-2023-0123090", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "위 수학식 2에서, ,"}
{"patent_id": "10-2023-0123090", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "이고, L은 언어지시 세트이다. 언어 프롬프트( )는 의 긍정 쌍( )에 대한 대조 학습을 통해 학습되며, 대조 손실 (contrastive loss)( )은 아래의 수학식 ()와 같이 정의된다. 수학식 3"}
{"patent_id": "10-2023-0123090", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "또한, 잠재 벡터(latent vector)(z, z')d은 아래의 수학식 4에 의해 계산된다. 수학식 4"}
{"patent_id": "10-2023-0123090", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 7, "content": "수학식 4에서 α는 온도 계수이다. 이처럼, 부태스크 수준 지시 케이스의 경우, 세만틱 스킬 인코더는 작은 셋트의 비디오 및 텍스트 검색 샘플에 대한 프롬프트 기반 대조 학습을 통해 사전 훈련된 비주얼 및 언어 인코더( , )에 기반해 설정할 수 있 다. 에피소드 수준 지시의 경우, 에서 에피소드의 모든 전이(transition)는 상세한 부태스크 수준 지시없이 단일 지시와만 관련 있다. 때문에, 본 발명에서는 비디오 특징에 대한 대조 학습과 함께 (Garg et al., 2022)에 발표 된 비지도 스킬 학습을 채용한다. 즉, 는 비디오 데모( ) 또는 언어 지시( ) 를 세만틱 스킬 배열로 바꾸는 것을 학습한다. 일 때, 아래의 수학식 5와 같 다. 수학식 5"}
{"patent_id": "10-2023-0123090", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 8, "content": "(Garg et al., 2022)에서 사용된 skill predictor와 유사하게, 아래의 수학식5와 같은 2개의 추가적인 인코더 인, 와 가 학습된다.수학식 6"}
{"patent_id": "10-2023-0123090", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 9, "content": "인코더( )는 positive pair 에서 대조학습되며, 여기서 대조 손실( )는 이고, 이면, 다음의 수학식 7과 같이 다 시 쓸 수 있다. 수학식 7"}
{"patent_id": "10-2023-0123090", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 10, "content": "인코더( )는 액션과 세만틱 스킬 사이이 상호 정보를 최대화하는 행동 복제를 통해 학습되고, 손실은 액션 재 구성 모델( )에 대해 아래 수학식 8과 같다. 수학식 8"}
{"patent_id": "10-2023-0123090", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 11, "content": "세만틱 스킬 디코더( ) 주어진 세만틱 스킬들의 배열에서, 세만틱 스킬 디코더는 현재 상태를 위한 하나의 세만틱 스킬을 추론한다. 이 세만틱 스킬 디코더는 현재의 세만틱 스킬이 종료되었는지 아닌지를 결정하는 2진 모델로 구현된다. 이를 수 학식으로 표현하면 아래의 수학식 9와 같다. 수학식 9"}
{"patent_id": "10-2023-0123090", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 12, "content": "현재 실행되고 있는 세만틱 스킬(zt)에 대해, sto: 초기 상태, 현재 상태: st, 는 아래 수학식 10과 같 은 BCE(binary cross entropy)를 사용하여 에서 학습된다.수학식 10"}
{"patent_id": "10-2023-0123090", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "item": 13, "content": "도 2의 (a)에 예시한 바처럼, 세만틱 스킬 인코더( )는 비디오에서 세만틱 스킬을 추출하기 위해서 대조 학습을 통해 학습된다. 2진 분류기인 세만틱 스킬 디코더( )는 스킬 배열에 따라 조건이 정해지며, 현재 단계에서 적절한 세만틱 스킬을 예측하도록 훈련된다. 스킬 트랜스퍼( ) 주어진 세만틱 스킬 인코더( )에 대해, 스킬 트랜스퍼( )는 세만틱 스킬 ( )을 에이전트가 실행되어야 할 환경에 최적화된 액션 배열로 바꾼다. 스킬 트랜스퍼( )는 아래 수학식 11과 같이 기술된다. 수학식 11"}
{"patent_id": "10-2023-0123090", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 14, "content": "여기서, 는 현재 상태, 는 세만틱 스킬, 는 다이나믹스 임베딩이다. Ho 길이 부궤도(( )에 대해, 수학식 11와 같이 다이나믹스 인코더( )는 입력으로 간주해 양자화된 벡터( )에 맵핑하며, 는 를 연속 잠재 벡터에 맵핑 힌다. 수학식 12"}
{"patent_id": "10-2023-0123090", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 15, "content": "본 발명에서는 후방 붕괴(posterior collapse)를 피하기 위해서 벡터 양자화 연산자 를 사용하였다. 의 출력은 학습용 패러미터들 중에서 가장 근접한 벡터이고, 코드 북(code book, )이라 부른다. 다음으로, 양자화된 다이나믹스의 임베딩( )은 아래의 수학식 13과 같이 구해진다. 수학식 13"}
{"patent_id": "10-2023-0123090", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 16, "content": "세만틱 스킬( )과 다이나믹스 임베딩( )에 대해, 스킬 트랜스 퍼와 다이나믹스 인코더는 수학식 14와 같은 behavior cloning (BC)을 최소화하는 형태로 함께 학습된다. 수학식 14"}
{"patent_id": "10-2023-0123090", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 17, "content": "또한 부궤적에서 태스크와 관련 없는 다이나믹스를 분리하기 위해 다양한 다이나믹스의 부 궤적에 대한 대조 학 습도 사용한다. 구체적으로 H0-length sub-trajectories( )의 서로 다른 타임스텝에서 출발한 동일한 궤적으로부터 온 positive 샘플( )을 포함한다고 가정한다. 그럼, 는 긍정 및 부정 쌍 상에서 학습되고, 대조 손실( )은 수학식 15와 같다. 수학식 15"}
{"patent_id": "10-2023-0123090", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 18, "content": "추론된 임베딩과 다이나믹스 간의 상호 정보를 최대화하기 위해서, 역다이나믹스 디코더 ( )를 사용해 재구성기반 특징 추출(reconstruction-based feature extraction)을 채택하였다. 여기서, 액션 재구성 손실은 수학식 16과 같다. 수학식 16"}
{"patent_id": "10-2023-0123090", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 19, "content": "스킬 트랜스퍼( ), 다이나믹스 인코더( ), 역다이나믹스 디코더( )는 손실 ( )을 최소화하기 위해서 같이 학습된다.한편, 스킬 트랜스퍼를 위한 학습 절차는 하기의 알고리즘 1과 같다."}
{"patent_id": "10-2023-0123090", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 20, "content": "이하, 상술한 구성의 원샷 모방을 위한 인공지능 모델을 평가하기 위해 실험한 결과를 설명한다. 실험은 성능평가를 위하여 mujoco 기반의 로봇 팔 환경 multi-stage Meta-world 시뮬레이션 환경에서 실험을 진 행하였다. 비정적 환경을 묘사하기 위해, 에이전트가 행동 을 할 경우, 시간(t)에 따라 변화하는 변수 를 에 더하여 행동 이 수행되도록 하였다. 해당 비정적 환경에서의 원샷 모방학습 성능 비교를 위해 모방학습 방법론인 BC-Z, Decision Transformer (DT)과 스킬 학습 방법론 Skill prior RL (SPiRL)을 사용 하였다. 실험에서 비디오 프레임별 세만틱 스킬이 주어진 경우의 방법으로 학습한 모델은 S-OnIS로 명명하였으 며, 전체 비디오에 대한 묘사만 주어진 경우의 방법으로 학습한 모델은 U-OnIS로 명명하였다. 1. 전문가 비디오 시연 및 언어 지시에 대한 원샷 모방 표 1"}
{"patent_id": "10-2023-0123090", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 21, "content": "표 에서는 하나의 전문가 비디오가 주어진 경우, 그에 대한 모방 학습 성능을 나타낸 것이다. 본 발명에서 제시한 방법(S-OnIS, U-OnIS)이 다른 비교군에 비해 학습 성능을 향상시켰다는 것을 보이기 위한 실험이며, 본 발명에서 제시한 방법이 가장 강력한 비교군 SPiRL과 비교하여 38.25~54.64%의 성능 향상이 있음을 알 수 있다. 표 는 언어 지시가 주어진 경우, 그에 대한 모방 학습 성능을 나타낸 것이며, 비디오 시연을 모방하는 것과 유사한 성능을 보인다. 표 2"}
{"patent_id": "10-2023-0123090", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 22, "content": "2. 비정적 환경에서의 에이전트 실행 표 과 에서 나타나 있듯이, 본 발명에서 제시한 방법이 다른 비교군에 비해 비정적 환경에서 더욱 강 건한 성능을 보였다. 예를 들어, 표 에서는 비교군의 비정적 환경에서의 성능 저하가 19.72% ~ 57.02%만큼 일어나는 반면, 본 발명이 제시하는 방법은 9.49 ~ 18.13%만큼의 성능 저하만이 나타났다. 이하, 상술한 원샷 모방을 위한 인공지능 모델과 관련한 일 실시예의 학습 방법과 원샷 모방 방법을 기술하면 다음과 같다.일 실시예의 학습 방법은 도 3에 개시된 바와 같다. 도 3을 참조하면, 일 실시예는 전문가의 비디오 시연을 적응적으로 원샷 모방하는 인공 신경망 모델에 기초한 원샷 모방 방법의 학습 방법에 관한 것으로, 주어진 전문가 시연에서 세만틱 스킬 배열을 추론하도록 학습하는 제1 단계(S10), 상기 주어진 전문가 시연에서 상기 전문가의 액션 궤적을 이루는 최소 단위인 상태-행동 쌍을 토대로 다이나믹스를 추론하도록 학습하는 제2 단계(S20), 상기 추론된 세만틱 스킬과 다이나믹스를 주어진 환 경 데이터에 기초해 스킬을 재조립해서 액션 시퀀스를 만들도록 학습하는 제3 단계(S30)를 포함한다. 이 실시예에서, 제1 단계(S10) 및 제2 단계(S20)는 상술한 세만틱 스킬 인코더를 학습시키는 단계에 해당한다. 제1 단계에서, 인공신경망 모델은 전문가 시연을 액션 배열(action sequences)인 환경과 무관한 행동 패턴 (dynamics-invariant behavior)으로 분절하기에 전문가 시연를 세만틱 스킬의 배열로 맵핑한다. 세만틱 스킬 인 코더는 사전 학습된 CLIP 비전-언어 모델(CLIP vision-language pretrained model)을 기반으로 프롬프트 학습 (prompt learning techniques), 대조학습을 통해 학습된다. 제3 단계(S30)는 스킬 트랜스퍼를 학습시키는 단계에 해당한다. 스킬 트랜스퍼는 주어진 세만틱 스킬과 추론된 다이나믹스에서 실행에 최적화된 액션 배열을 추론하는 방법을 학습한다. 일 실시예의 원샷 모방 방법은 도 4에 개시된 바와 같다. 도 4를 참조하면, 일 실시예의 원샷 모방 방법은, 주어진 전문가 시연에서 세만틱 스킬 배열을 추론하는 제1 단 계(S100), 에이전트를 동작시켜 상태-행동 쌍의 시계열적으로 발생시키고, 이를 기초로 현재 상태의 다이나믹스 를 추론하는 제2 단계(S200), 추론된 세만틱 스킬 배열과 추론된 다이나믹스를 현재 획득한 환경 데이터를 기초 로 조합해 새로문 도메인에 맞는 액션을 수행하는 단계(S300)를 포함한다. 도 4는 상술한 원샷 모방과 학습 방법을 위한 연산 장치를 도시한 블록도로, 상술한 일련의 구성을 하드웨어 구 성의 관점에서 재구성한 것이다. 따라서, 여기서는 설명의 중복을 피하고자 각 구성의 기능 및 동작을 중심으로 그 개요만을 약술하도록 한다. 연산 장치는 상술한 구성에 따라 원샷 모방을 학습하고 적응적으로 실행하는 인공신경망 모델을 저장 하는 메모리, 상기 인공신경망 모델을 제어해 원샷 모방을 학습하고 실행하는 프로세서를 포함한다. 훈련 단계에서, 상기 인공신경망 모델은 주어진 전문가 시연에서 세만틱 스킬 배열을 추론하도록 학습하고, 상기 주어진 전문가 시연에서 상기 전문가의 액션 궤적을 이루는 최소 단위인 상태-행동 쌍을 토대로 다이나믹스를 추론하도록 학습하고, 상기 추론된 세만틱 스킬과 다이나믹스를 주어진 환경 데이터에 기초해 조 합해 액션 시퀀스를 만들도록 학습한다. 실행 단계에서, 상기 인공신경망 모델은 주어진 전문가 시연에서 세만틱 스킬 배열을 추론하고, 에이전트 를 동작시켜 상태-행동 쌍의 시계열적으로 발생시키고, 이를 기초로 현재 상태의 다이나믹스를 추론하고, 추론 된 세만틱 스킬 배열과 추론된 다이나믹스를 현재 획득된 환경 데이터를 기초로 조합해 추론된 세만틱 스킬을 재조립한다. 한편, 상술한 본 발명은 컴퓨터로 읽을 수 있는 기록 매체에 컴퓨터가 읽을 수 있는 코드로 구현하는 것이 가능 하다. 컴퓨터가 읽을 수 있는 기록 매체는 컴퓨터 시스템에 의하여 읽혀질 수 있는 데이터가 저장되는 모든 종 류의 기록 장치를 포함한다. 컴퓨터가 읽을 수 있는 기록 매체의 예로는 ROM, RAM, CD-ROM, 자기 테이프, 플로피디스크, 광 데이터 저장장치 등을 포함한다. 또한, 컴퓨터가 읽을 수 있는 기록 매체는 네트워크로 연결된 컴퓨터 시스템에 분산되어, 분산 방식으로 컴퓨터가 읽을 수 있는 코드가 저장되고 실행될 수 있다. 그리고 본 발명을 구현하기 위한 기능적인 (functional) 프로그램, 코드 및 코드 세그먼트들은 본 발명이 속하는 기술 분야의 프로그래머들에 의하여 용이 하게 추론될 수 있다. 이상에서 본 발명에 대하여 그 다양한 실시예들을 중심으로 살펴보았다. 본 발명에 속하는 기술 분야에서 통상 의 지식을 가진 자는 본 발명이 본 발명의 본질적인 특성에서 벗어나지 않는 범위에서 변형된 형태로 구현될 수 있음을 이해할 수 있을 것이다. 그러므로 개시된 실시예들은 한정적인 관점이 아니라 설명적인 관점에서 고려되 어야 한다. 본 발명의 범위는 전술한 설명이 아니라 특허청구범위에 나타나 있으며, 그와 동등한 범위 내에 있 는 모든 차이점은 본 발명에 포함된 것으로 해석되어야 할 것이다.도면 도면1 도면2 도면3 도면4 도면5"}
{"patent_id": "10-2023-0123090", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명을 개념적으로 설명하는 도면이다. 도 2는 본 발명의 일 실시예에 따른 원샷 모방을 구현하는 인공 신경망 모델의 구성을 보여주는 도면이다. 도 3 및 도 4는 본 발명에 따른 원샷 모방을 학습하고 실행하는 방법을 각각 보여주는 도면이다. 도 5는 본 발명에 따른 원샷 모방을 학습하고 실행하는 방법을 실행하는 연산 장치를 보여주는 도면이다."}
