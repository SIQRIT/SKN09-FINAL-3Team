{"patent_id": "10-2025-0050858", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2025-0057756", "출원번호": "10-2025-0050858", "발명의 명칭": "인공지능 기술을 이용한 영상 처리를 위한 방법 및 장치", "출원인": "주식회사 에이온플로우", "발명자": "이상윤"}}
{"patent_id": "10-2025-0050858", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "영상 송신 장치에 의해 수행되는 방법에 있어서,복수의 이미지 프레임을 포함하는 이미지 데이터를 획득하는 동작;상기 이미지 데이터에 대한 전처리를 수행하는 동작;부호화된 이미지 데이터를 생성하기 위하여 상기 전처리된 이미지 데이터를 부호화(encode)하는 동작; 및상기 부호화된 이미지 데이터 및 상기 전처리에 관련된 정보를 전송하는 동작을 포함하는, 방법."}
{"patent_id": "10-2025-0050858", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 개시는 영상 처리 방법을 개시한다. 본 개시의 영상 처리 방법은 복수의 이미지 프레임을 포함하는 이미지 데 이터를 획득하는 동작, 상기 이미지 데이터에 대한 전처리를 수행하는 동작, 부호화된 이미지 데이터를 생성하기 위하여 상기 전처리된 이미지 데이터를 부호화하는 동작 및 상기 부호화된 이미지 데이터 및 상기 전처리에 관련 된 정보를 전송하는 동작을 포함할 수 있다."}
{"patent_id": "10-2025-0050858", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 인공지능 기술을 이용한 영상 처리를 위한 방법 및 장치에 관한 것이다."}
{"patent_id": "10-2025-0050858", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "영상 데이터의 압축/복원을 위해, 표준화된 코덱 기술(예: H.264/AVC(advanced video coding), H.265/HEVC(high efficiency video coding))이 주로 사용된다. 표준화된 코덱 기술은 높은 효율성과 호환성을 가지지만, 고화질 스트리밍 서비스에 수요가 높아져 데이터 트래픽이 급증하는 최근 환경에서는 압축 기술로서 충분한 성능을 보장하기 어려워진다. 이로 인하여, 고화질 영상을 높은 압축효율로 안정적으로 전송하고, 저비용으로 저장하며, 고품질로 재생하기 위한 새로운 방식의 영상 처리 기술에 대한 수요가 증대되고 있다."}
{"patent_id": "10-2025-0050858", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 개시는 원본 영상(예: 고품질 영상)을 높은 압축효율로 안정적으로 전송 및 저장하고, 원본 영상과 실질적으 로 동일한 품질(예: 고품질) 또는 더 높은 품질로 재생하기 위한 방법을 제공한다. 본 개시는 고효율 압축 및 고품질 영상을 제공하기 위한 전처리(pre-processing) 및 후처리(post-processing) 방법을 제공한다. 본 개시의 전처리 및 후처리 방법은 표준화된 코덱 기술을 이용하는 인코딩/디코딩 기술과 높 은 호환성을 가질 수 있다. 본 개시는 프레임 스킵(skip) 기술을 이용하는 전처리 방법과 프레임 보간 기술 및/또는 품질 향상 기술을 이용 하는 후처리 방법을 제공한다. 이를 통해, 높은 압축 효율을 지원하면서도, 원본 영상과 실질적으로 동일한 수 준 또는 더 높은 수준의 품질이 제공될 있다. 본 개시의 전처리 방법과 후처리 방법은 인공지능 모델을 이용하여 구현될 수 있다. 이를 통해, 높은 속도 및 높은 정확도의 영상 처리가 지원될 수 있다."}
{"patent_id": "10-2025-0050858", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 개시의 일 실시예에 따른, 방법은 복수의 이미지 프레임을 포함하는 이미지 데이터를 획득하는 동작; 인공지 능 모델을 이용하여, 상기 복수의 이미지 프레임에 포함되는 제1 이미지 프레임에 대한 프레임 스킵핑(frame skipping)을 적용할지 여부를 결정하는 동작; 상기 제1 이미지 프레임에 대한 프레임 스킵핑을 적용함이 결정되 는 경우, 상기 제1 이미지 프레임을 스킵하고, 압축된 이미지 데이터를 생성하기 위하여 상기 제1 이미지 프레 임이 스킵된 이미지 데이터를 부호화(encode)하는 동작; 및 상기 압축된 이미지 데이터 및 상기 프레임 스킵핑 에 관련된 정보를 전송하는 동작을 포함할 수 있다.본 개시의 일 실시예에 따른, 방법은 복호화된 복수의 이미지 프레임을 포함하는 이미지 데이터를 획득하는 동 작; 프레임 스킵핑에 관련된 정보에 기초하여, 상기 복수의 이미지 프레임에 대한 프레임 보간을 적용할지 여부 를 결정하는 동작; 상기 복수의 이미지 프레임에 대한 프레임 보간을 적용함이 결정되는 경우, 상기 복수의 이 미지 프레임을 기초로 제1 인공지능 모델을 이용하여 제1 이미지 프레임이 보간된 이미지 데이터를 획득하는 동 작을 포함할 수 있다. 본 개시는 영상의 다운 스케일 기술과 이로 인하여 발생하는 손실을 레이턴트 벡터(latent vector)로 표현하는 레이턴트 벡터 기술을 이용하는 전처리 방법과 해상도 향상을 위한 슈퍼 레졸루션(SR, super resolution) 기술 을 이용하는 후처리 방법을 제공한다. 이를 통해, 높은 압축 효율을 지원하면서도, 원본 영상과 실질적으로 동 일한 수준의 또는 더 높은 수준의 품질이 제공될 있다. 본 개시는 프레임 선별 기술, 다운 스케일 기술 및 레이턴트 벡터 기술을 함께 이용하는 전처리 방법과, 프레임 보간 기술, 품질 향상 기술 및 슈퍼 레졸루션 기술을 함께 이용하는 후처리 방법을 제공한다. 이를 통해, 높은 압축 효율을 지원하면서도, 원본 영상과 실질적으로 동일한 수준 또는 더 높은 수준의 품질이 제공될 있다. 본 개시의 전처리 방법과 후처리 방법은 인공지능 모델을 이용하여 구현될 수 있다. 이를 통해, 높은 속도 및 높은 정확도의 영상 처리가 지원될 수 있다. 본 개시의 일 실시예에 따른, 방법은 이미지 데이터를 다운 샘플링하여, 다운 샘플링된 이미지 데이터를 획득하 는 동작; 상기 다운 샘플링된 이미지 데이터에 대한 해상도 보간을 수행하여, 해상도 보간된 이미지 데이터를 획득하는 동작; 상기 이미지 데이터와 상기 해상도 보간된 이미지 데이터에 기초하여, 손실 데이터를 획득하는 동작; 상기 손실 데이터를 기초로, 인공지능 모델을 이용하여, 레이턴트 벡터 데이터를 생성하는 동작; 상기 다 운 샘플링된 이미지 데이터 및 상기 레이턴트 벡터 데이터를 부호화하는 동작; 및 상기 부호화된 이미지 데이터 및 상기 부호화된 레이턴트 벡터 데이터를 전송하는 동작을 포함할 수 있다. 본 개시의 일 실시예에 따른, 방법은 부호화된 이미지 데이터 및 부호화된 레이턴트 벡터 데이터를 수신하는 동 작; 상기 부호화된 이미지 데이터 및 상기 부호화된 레이턴트 벡터 데이터를 복호화하는 동작; 상기 복호화된 이미지 데이터 및 상기 복호화된 레이턴트 벡터 데이터를 기초로, 인공지능 모델을 이용하여, 해상도가 향상된 이미지 데이터를 생성하는 동작을 포함할 수 있다. 본 개시는 원본 영상(예: 고품질 영상)을 높은 압축효율로 안정적으로 전송 및 저장하고, 원본 영상과 실질적으 로 동일한 품질(예: 고품질) 또는 더 높은 품질로 재생하기 위한 방법을 제공한다. 본 개시는 복호화된 프레임을 해당 프레임 그룹의 참조 프레임)(예: I 프레임과, 후행하는 프레임 그룹의 참조 프레임(예: I 프레임)을 이용하여 복원하는 향상 기술을 이용하는 후처리 방법을 제공한다. 이를 통해, 프레임 그룹(예: GoP(group of pictures)) 간의 왜곡을 복원할 수 있다. 본 개시에서, 참조 프레임은 키 프레임으로 지 칭될 수 있다. 본 개시의 전처리 방법과 후처리 방법은 인공지능 모델을 이용하여 구현될 수 있다. 이를 통해, 높은 속도 및 높은 정확도의 영상 처리가 지원될 수 있다. 본 개시의 일 실시예에 따른, 방법은 제1 프레임 그룹의 제1 프레임 및 상기 제1 프레임 그룹에 후행하는 제2 프레임 그룹의 제2 프레임을 획득하는 동작; 및 상기 제1 프레임 및 상기 제2 프레임을 기초로, 상기 제1 프레 임 그룹의 연속된 복수의 프레임에 대한 복수의 복원된(reconstructed) 프레임을 획득하는 동작을 포함하며, 상 기 제1 프레임 및 상기 제2 프레임은 독립적으로(independently) 부호화 및 복호화된 프레임에 해당하고, 상기 복수의 프레임은 상기 제1 프레임을 기초로 예측적으로(predictively) 부호화 및 복호화된 프레임에 해당할 수 있다. 본 개시의 일 실시예에 따른, 영상 수신 장치는 메모리; 통신부; 및 적어도 하나의 프로세서를 포함하며, 상기 적어도 하나의 프로세서는: 제1 프레임 그룹의 제1 프레임 및 상기 제1 프레임 그룹에 후행하는 제2 프레임 그 룹의 제2 프레임을 획득하고, 상기 제1 프레임 및 상기 제2 프레임을 기초로, 상기 제1 프레임 그룹의 연속된 복수의 프레임에 대한 복수의 복원된(reconstructed) 프레임을 획득하도록 설정되며, 상기 제1 프레임 및 상기 제2 프레임은 독립적으로(independently) 부호화 및 복호화된 프레임에 해당하고, 상기 복수의 프레임은 상기 제1 프레임을 기초로 예측적으로(predictively) 부호화 및 복호화된 프레임에 해당할 수 있다."}
{"patent_id": "10-2025-0050858", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하에서는 도면을 참조하여 본 개시의 실시예에 대하여 본 개시가 속하는 기술 분야에서 통상의 지식을 가진 자가 용이하게 실시할 수 있도록 상세히 설명한다. 그러나 본 개시는 여러 가지 상이한 형태로 구현될 수 있으 며 여기에서 설명하는 실시예에 한정되지 않는다. 도면의 설명과 관련하여, 동일하거나 유사한 구성요소에 대해 서는 동일하거나 유사한 참조 부호가 사용될 수 있다. 또한, 도면 및 관련된 설명에서는, 잘 알려진 기능 및 구성에 대한 설명이 명확성과 간결성을 위해 생략될 수 있다. 이때, 처리 흐름도 도면들의 각 블록과 흐름도 도면들의 조합들은 컴퓨터 프로그램 인스트럭션들에 의해 수행될 수 있음을 이해할 수 있을 것이다. 또한, 각 블록은 특정된 논리적 기능(들)을 실행하기 위한 하나 이상의 실행 가능한 인스트럭션들을 포함하는 모듈, 세그먼트 또는 코드의 일부를 나타낼 수 있다. 또, 몇 가지 대체 실행 예들에서는 블록들에서 언급된 기 능들이 순서를 벗어나서 발생하는 것도 가능함을 주목해야 한다. 예컨대, 잇달아 도시되어 있는 두 개의 블록들 은 사실 실질적으로 동시에 수행되는 것도 가능하고 또는 그 블록들이 때때로 해당하는 기능에 따라 역순으로 수행되는 것도 가능하다. 이때, 본 실시예에서 사용되는 '~부'라는 용어는 소프트웨어 또는 FPGA(Field Programmable Gate Array) 또는 ASIC(Application Specific Integrated Circuit)과 같은 하드웨어 구성요소를 의미하며, '~부'는 어떤 역할들 을 수행한다. 그렇지만 '~부'는 소프트웨어 또는 하드웨어에 한정되는 의미는 아니다. '~부'는 어드레싱할 수 있는 저장 매체에 있도록 구성될 수도 있고 하나 또는 그 이상의 패킷 처리 장치들을 재생시키도록 구성될 수도 있다. 따라서, 일 예로서 '~부'는 소프트웨어 구성요소들, 객체지향 소프트웨어 구성요소들, 클래스 구성요소들 및 태스크 구성요소들과 같은 구성요소들과, 프로세스들, 함수들, 속성들, 프로시저들, 서브루틴들, 프로그램 코드의 세그먼트들, 드라이버들, 펌웨어, 마이크로코드, 회로, 데이터, 데이터베이스, 데이터 구조들, 테이블들, 어레이들, 및 변수들을 포함한다. 구성요소들과 '~부'들 안에서 제공되는 기능은 더 작은 수의 구성 요소들 및 '~부'들로 결합되거나 추가적인 구성요소들과 '~부'들로 더 분리될 수 있다. 뿐만 아니라, 구성요소 들 및 '~부'들은 디바이스 또는 보안 멀티미디어카드 내의 하나 또는 그 이상의 중앙처리장치(Central Processing Unit, CPU)들을 재생시키도록 구현될 수도 있다. 또한 실시예에서 '~부'는 하나 이상의 패킷 처리 장치를 포함할 수 있다. 도 1a은 본 개시의 일 실시예에 따른 영상 처리 시스템을 개략적으로 도시한다. 도 1a를 참조하면, 영상 처리 시스템은 영상 송신 장치 및 영상 수신 장치를 포함할 수 있다. 본 개시에서, 영상 송신 장치는 영상 제공 장치로 지칭될 수 있고, 영상 수신 장치는 영상 재생 장치로 지칭될 수 있다. 일 실시예에 따른, 영상 송신 장치는 비디오 및/또는 이미지를 포함하는 영상 신호(또는, 영상 데이터)를 네트워크를 통해 영상 수신 장치에게 전송하고, 영상 수신 장치는 영상 송신 장치로부터 영상 신호를 수신할 수 있다. 일 실시예에 따른, 영상 송신 장치는 압축된 영상 신호를 생성하기 위하여 영상 신호를 부호화(encoding) 할 수 있다. 영상 송신 장치는 예컨대, 미리 설정된 압축률 범위 내에서 영상 신호를 부호화함으로써, 영 상 신호를 효율적으로 저장, 전송 및 관리할 수 있다. 영상 신호는 예컨대, 스트리밍 영상, 카메라 영상, 비디 오 영상, 압축이 해제된 영상, 화상 회의 영상 및/또는 게임 영상을 포함할 수 있으나, 이에 제한되지 않는다. 일 실시예에 따른, 영상 송신 장치는 TV, PC(personal computer), 스마트폰, 태블릿, 셋톱박스, 게임 콘 솔, 서버 등 다양한 영상 소스 장치를 포함할 수 있다. 일 실시예에 따른, 영상 수신 장치는 TV, 스마트폰, 태블릿, PC 등 다양한 영상 재생 장치를 포함할 수 있다. 영상 송신 장치 및 영상 수신 장치 가 특정 유형의 장치에 제한되지 않음은 당업자에게 자명하다. 일 실시예에 따른, 영상 송신 장치 및 영상 수신 장치는 네트워크를 통해 영상 신호를 송수신할 수 있다. 네트워크는, 예컨대, Wi-Fi 등과 같은 근거리 통신 네트워크와 셀룰러 네트워크, 차세대 통신 네 트워크, 인터넷, 또는 컴퓨터 네트워크(예: LAN(local area network) 또는 WAN(wide area network)와 같은 원 거리 통신 네트워크를 포함할 수 있고, IP(internet protocol) 통신 프로토콜 기반으로 통신할 수 있다. 셀룰러 네트워크는 GSM(global system for mobile communications), EDGE(enhanced data GSM environment), CDMA(code division multiple access), TDMA(time division multiplexing access), LTE(long term evolution), LTE-A(LTE advance), 5G NR(new radio), 및 5G 이후의 통신 네트워크(예: 6G 네트워크 또는 그 이 후의 네트워크)를 포함할 수 있다. 네트워크는 허브, 브리지, 라우터, 스위치 및 게이트웨이와 같은 네트 워크 요소들의 연결을 포함할 수 있다. 네트워크는 인터넷과 같은 공용 네트워크 및 기업 사설 네트워크와 같은 사설 네트워크를 비롯한 하나 이상의 연결된 네트워크들, 예컨대 다중 네트워크 환경을 포함할 수 있다. 네트워크에의 액세스는 하나 이상의 유선 또는 무선 액세스 네트워크들을 통해 제공될 수 있다. 네트워크 는 사물 등 분산된 구성 요소들 간에 정보를 주고받아 처리하는 IoT(Internet of Things, 사물인터넷) 망 을 지원할 수 있다. 도 1b는 본 개시의 일 실시예에 따른 영상 송신 장치 및 영상 수신 장치의 개략적인 블록도이다. 도 1b를 참조하면, 영상 송신 장치는 영상 입력부, 전처리부, 부호화부 및 영상 출력부 를 포함할 수 있다. 영상 송신 장치는 도시된 구성요소 외에 추가적인 구성요소를 포함하거나, 도시 된 구성요소 중 적어도 하나를 생략할 수 있다. 예를 들면, 영상 송신 장치는 메모리, 적어도 하나의 프로 세서 및/또는 통신부를 더 포함할 수 있다. 일 실시예에 따르면, 메모리는 하나 이상의 명령어들(instructions)을 포함하는 프로그램 또는 설정 정보와 같 은 데이터를 저장할 수 있다. 메모리는 예컨대, 휘발성 메모리, 비휘발성 메모리 또는 휘발성 메모리와 비휘발 성 메모리의 조합으로 구성될 수 있다. 메모리는 프로세서의 요청에 따라 저장된 데이터를 제공할 수 있다. 일 실시예에 따르면, 통신부는 다른 시스템들 또는 장치와의 통신을 위한 인터페이스를 제공할 수 있다. 통신부 는 네트워크를 통한 통신을 가능하게 하는 네트워크 인터페이스 카드 또는 무선 송/수신부를 포함할 수 있 다. 통신부는 무선 네트워크에 접속하기 위한 신호 처리를 수행할 수 있다. 무선 네트워크는, 예를 들어, 근거 리 통신 네트워크 또는 셀룰러 네트워크(예: LTE, 5G NR)) 중 적어도 하나를 포함할 수 있다. 일 실시예에 따르면, 적어도 하나의 프로세서는 통신부 및 메모리와 전기적으로 연결되고, 메모리에 저장된 프 로그램을 이용하여 영상 송신 장치의 적어도 하나의 다른 구성요소들의 제어 및/또는 통신에 관한 연산이 나 데이터 처리를 실행할 수 있다. 프로세서는 영상 입력부, 전처리부, 부호화부 및 영상 출력 부에 대응하는 적어도 하나의 명령어를 실행할 수 있다. 프로세서는 예컨대, 중앙처리장치(CPU), 그래픽처 리장치(GPU), MCU(micro controller unit), 센서 허브, 보조 프로세서(supplementary processor), 통신 프로세 서(communication processor), 애플리케이션 프로세서(application processor), ASIC(application specific integrated circuit), 또는 FPGA(field programmable gate arrays) 중 적어도 하나를 포함할 수 있으며, 복수 의 코어를 가질 수 있다. 일 실시예에 따르면, 영상 입력부는 영상 신호를 입력 받을 수 있다. 영상 신호는 영상 송신 장치의 외부로부터 수신되거나, 영상 송신 장치에 의해 생성된 것일 수 있다. 영상 입력부는 통신부를 통해유선 또는 무선 방식으로 외부로부터 영상 신호를 수신할 수 있다. 일 실시예에 따르면, 전처리부는 부호화부에 의한 부호화 처리 이전에, 영상 입력부에 의해 입 력된 영상 신호를 전처리(pre-processing)할 수 있다. 예를 들면, 전처리부는 입력된 영상 신호에 대한 프 레임 스킵핑(frame skipping) 처리를 수행할 수 있다. 예를 들면, 전처리부는 입력된 영상 신호에 대한 다 운 샘플링 처리를 수행할 수 있다. 예를 들면, 전처리부는 다운 샘플링 처리에 따른 손실을 레이턴트 벡터 로 표현하는 레이턴트 벡터 처리를 수행할 수 있다. 예를 들면, 전처리부는 프레임 스킵핑 처리, 다운 샘 플링 처리, 및 레이턴트 벡터 처리를 수행할 수 있다. 일 실시예에 따르면, 전처리부는 미리 학습된 모델(예: 인공지능 (AI) 모델)에 의해 구현될 수 있다. 일 실시예에 따르면, 인공지능 모델은 기계 학습을 통해 생성될 수 있다. 이러한 학습은, 예를 들어, 인공지능 모델이 이용되는 전자 장치(예: 영상 송신 장치 또는 영상 수신 장치) 자체에서 수행될 수 있고, 별 도의 전자 장치(예: 서버)를 통해 수행될 수도 있다. 학습 알고리즘은, 예를 들어, 지도형 학습(supervised learning), 비지도형 학습(unsupervised learning), 준지도형 학습(semi-supervised learning) 또는 강화 학습 (reinforcement learning)을 포함할 수 있으나, 이에 한정되지 않는다. 인공지능 모델은, 복수의 인공 신경망 레이어들을 포함할 수 있다. 인공 신경망은 심층 신경망(DNN, deep neural network), CNN(convolutional neural network), RNN(recurrent neural network), RBM(restricted boltzmann machine), DBN(deep belief network), BRDNN(bidirectional recurrent deep neural network), 심층 Q-네트워크(deep Q-networks) 또는 상 기 중 둘 이상의 조합 중 하나일 수 있으나, 전술한 예에 한정되지 않는다. 인공지능 모델은 하드웨어 구조 이 외에, 추가적으로 또는 대체적으로, 소프트웨어 구조를 포함할 수 있다. 한편, 실시예에 따라, 전처리부의 전체 또는 일부 동작이 생략될 수 있다. 예를 들면, 전처리부의 프 레임 스킵핑 처리, 다운 샘플링 처리, 및 레이턴트 벡터 처리의 전부 또는 일부가 생략될 수 있다. 전처리부 의 전체 동작의 생략된 경우, 영상 송신 장치의 입력 영상은 부호화부에 의한 부호화 처리만 거 친 뒤, 영상 수신 장치로 전달될 수 있다. 일 실시예에 따르면, 부호화부는 영상 입력부에 의해 입력된 영상 신호 또는 전처리부에 의해 전처리된 영상 신호를 부호화할 수 있다. 부호화부는 압축 및 부호화 효율을 위하여 예측, 변환, 양자화 등 일련의 절차를 수행할 수 있다. 부호화부의 일 예는 도 2a를 참조하여 이하에서 설명한다. 일 실시예에 따르면, 부호화부는 미리 설정된 부호화 방식 및 부호화 방식과 연관된 부호화 파라미터를 이 용하여, 영상 신호를 부호화할 수 있다. 부호화 방식은, 예컨대, 표준화된 코덱 기술(예: H.264/AVC 표준, H.265/HEVC 표준) 또는 인공지능 기반의 코덱 기술(AI 코덱 기술)을 따르는 방식일 수 있으나, 이에 제한되지 않는다. 부호화 파라미터는, 예컨대, 표준화된 코덱 기술(예: H.264/AVC 표준, H.265/HEVC 표준)에 따라 영상 신호를 부호화(또는, 압축)하기 위해 사용되는(또는, 설정된) 적어도 파라미터를 포함할 수 있다. 적어도 하나 의 파라미터는, 예컨대, 압축률(또는, 압축 품질) 및/또는 비트레이트에 관련된 파라미터(예: 양자화 파라미터 (QP: quantization parameter))를 포함할 수 있다. 일반적으로, QP 값이 낮을수록 더 적은 양자화가 적용되어 더 높은 영상 품질을 제공할 수 있으나, 더 높은 비트레이트를 필요로 하게 된다. 본 개시에서, 부호화 방식은 압축 방식으로 지칭될 수 있고, 부호화 파라미터는 압축 파라미터로 지칭될 수 있다. 일 실시예에 따르면, 부호화부는 부호화된 영상 신호(또는 부호화된 데이터)를 비트스트림(bitstream) 형 태로 영상 출력부에게 제공할 수 있다. 일 실시예에 따르면, 전처리부와 부호화부는 하나의 통합된 구성일 수 있다. 일 예로, 전처리부(11 2)가 부호화부에 포함될 수 있다. 예를 들면, 부호화부가 예컨대, AI 코덱 기술을 이용하는 경우, 전 처리부는 부호화부에 포함되는 구성일 수 있다. 전처리부가 부호화부에 포함되는 경우, 전 처리부의 동작은 부호화부의 부호화 동작(인코딩 동작)의 이전에 수행될 수 있으나, 이에 제한되지 않는다. 예를 들면, 실시예에 따라서는, 전처리부의 동작이 부호화부의 부호화 동작과 함께, 또는 그 이후에 수행될 수도 있다. 일 예로, 적어도 하나의 AI 모델을 통해, 전처리부 및 부호화부의 동작이 함께 수행될 수 있다. 일 실시예에 따르면, 영상 출력부는 부호화된 영상 신호를 통신부를 통해 영상 수신 장치에게 송신할 수 있다. 일 실시예에 따르면, 영상 출력부는 부호화된 영상 신호와 함께, 전처리에 관련된 정보(예: 프레임 스킵 정보)를 통신부를 통해 영상 수신 장치에게 송신할 수 있다. 전처리에 관련된 정보(또는, 프레임 스킵 정보)는 예컨대, 해당 프레임에 프레임 스킵핑이 적용되었는지를 지시하는 정보(프레임 스킵핑에 관련된 정보), 및/또는 프레임 수에 대한 정보(예컨대, 프레임 율(예: FPS(frame per second))에 대한 정보)를 포함할 수 있으 나, 이에 한정되지 않는다. 본 개시에서, 프레임은 이미지 프레임으로 지칭될 수 있다. 이러한 관련 정보는 영상 수신 장치에서의 영상 처리를 위해 사용될 수 있다. 예를 들면, 프레임 스킵핑에 관련된 정보는 영상 수신 장치가 해당 프레임에 대한 프레임 보간을 적용할지 여부를 결정하기 위해 사용 될 수 있다. 예를 들면, 프레임 율에 대한 정보는 영상 수신 장치가 영상 송신 장치에서 프레임 스킵 핑이 적용되었는지 여부를 확인하기 위해 사용될 수 있다. 예컨대, 프레임 율에 대한 정보가 입력 영상에 대한 프레임 율(예: 30 FPS)보다 낮은 경우, 영상 수신 장치가 영상 송신 장치에서 프레임 스킵핑이 적용 됨을 확인할 수 있다. 예컨대, 프레임 율에 대한 정보가 입력 영상에 대한 프레임 율(예: 30 FPS)과 동일한 경 우, 영상 수신 장치가 영상 송신 장치에서 프레임 스킵핑이 적용되지 않음을 확인할 수 있다. 일 실시예에 따른, 전처리에 관련된 정보는 부호화된 데이터를 포함하는 비트스트림에 추가될 수 있다. 일 예로, 전처리에 관련된 정보는 비트스트림 내의 옵셔널 영역에 포함될 수 있다. 예를 들면, 전처리에 관련된 정 보는 비트스트림 내의 디스크립션(description) 영역에 포함될 수 있으나, 이에 제한되지 않는다. 디스크립션 영역은, 예컨대, 해당 비트스트림에 대한 정보와 구조를 설명하기 위한 영역일 수 있다. 일 예로, 디스크립션 영역은 해당 비트스트림이 어떤 코덱으로 압축되었는지를 지시하는 코덱 정보, 해당 비트스트림이 어떤 종류의 미디어 데이터를 포함하는지를 지시를 미디어 정보, 해당 코덱의 부호화 파라미터를 포함하는 부호화 설정 정보 및/또는 해당 비트스트림과 연관된 각 프레임의 타임스탬프 또는 시간 정보를 포함할 수 있다. 영상 수신 장치는 영상 입력부, 복호화부, 후처리부 및 영상 출력부를 포함할 수 있 다. 영상 출력부는 예컨대, 디스플레이부를 포함할 수 있고, 디스플레이부는 별개의 디바이스 또는 외부 컴포넌트로 구성될 수도 있다. 영상 수신 장치는 도시된 구성요소 외에 추가적인 구성요소를 포함하거나, 도시된 구성요소 중 적어도 하나를 생략할 수 있다. 예를 들면, 영상 수신 장치는 메모리, 적어도 하나의 프로세서 및 통신부를 더 포함할 수 있다. 일 실시예에 따르면, 메모리는 하나 이상의 명령어들(instructions)을 포함하는 프로그램 또는 설정 정보와 같 은 데이터를 저장할 수 있다. 메모리는 예컨대, 휘발성 메모리, 비휘발성 메모리 또는 휘발성 메모리와 비휘발 성 메모리의 조합으로 구성될 수 있다. 메모리는 프로세서의 요청에 따라 저장된 데이터를 제공할 수 있다. 일 실시예에 따르면, 통신부는 다른 시스템들 또는 장치와의 통신을 위한 인터페이스를 제공할 수 있다. 통신부 는 네트워크를 통한 통신을 가능하게 하는 네트워크 인터페이스 카드 또는 무선 송/수신부를 포함할 수 있 다. 통신부는 무선 네트워크에 접속하기 위한 신호 처리를 수행할 수 있다. 무선 네트워크는, 예를 들어, 근거 리 통신 네트워크 또는 셀룰러 네트워크(예: LTE, 5G NR)) 중 적어도 하나를 포함할 수 있다. 일 실시예에 따르면, 적어도 하나의 프로세서는 통신부 및 메모리와 전기적으로 연결되고, 메모리에 저장된 프 로그램을 이용하여 영상 수신 장치의 적어도 하나의 다른 구성요소들의 제어 및/또는 통신에 관한 연산이 나 데이터 처리를 실행할 수 있다. 프로세서는 영상 입력부, 복호화부, 후처리부 및 영상 출력 부에 대응하는 적어도 하나의 명령어를 실행할 수 있다. 프로세서는 예컨대, 중앙처리장치(CPU), 그래픽처 리장치(GPU), MCU(micro controller unit), 센서 허브, 보조 프로세서(supplementary processor), 통신 프로세 서(communication processor), 애플리케이션 프로세서(application processor), ASIC(application specific integrated circuit), 또는 FPGA(field programmable gate arrays) 중 적어도 하나를 포함할 수 있으며, 복수 의 코어를 가질 수 있다. 일 실시예에 따르면, 영상 입력부는 영상 신호를 입력 받을 수 있다. 영상 입력부는 통신부를 통해 영상 송신 장치로부터 영상 신호를 수신할 수 있다. 영상 입력부는 통신부를 통해 유선 또는 무선 방 식으로 영상 송신 장치로부터 영상 신호를 수신할 수 있다. 일 실시예에 따른, 영상 입력부는 영상 송신 장치로부터 수신된 비트스트림으로부터, 부호화된 영상 신호 및/또는 전처리에 관련된 정보를 추출(또는, 획득)할 수 있다. 영상 입력부는 획득된 부호화된 영상 신호 및/또는 전처리에 관련된 정보를 복호화부에 전달할 수 있다. 일 실시예에 따르면, 복호화부는 영상 입력부에 의해 입력된 영상 신호를 복호화할 수 있다. 예를 들 면, 복호화부는 부호화부의 동작에 대응하는 역양자화, 역변환, 예측 등 일련의 절차를 수행하여 영 상 신호를 복호화할 수 있다. 복호화부의 일 예는 도 2b를 참조하여 이하에서 설명한다. 일 실시예에 따르면, 복호화부는 미리 설정된 복호화 방식 및 복호화 방식과 연관된 복호화 파라미터를 이 용하여, 영상 신호를 복호화할 수 있다. 일 실시예에 따른, 복호화 방식은 부호화부의 부호화 방식에 대응 할 수 있고, 복호화 파라미터는 부호화부의 부호화 방식에 연관된 부호화 파라미터에 대응할 수 있다. 예 를 들면, 부호화 및 복호화를 위해 동일한 표준 코덱 기술(예: H.264/AVC, H.265/HEVC 표준) 또는 AI 코덱 기술 이 사용될 수 있고, 부호화를 위해 사용된 파라미터(예: QP)에 대응하는 파라미터(예: 역양자화 파라미터)가 복 호화를 위해 사용될 수 있다. 일 실시예에 따른, 복호화를 위한 파라미터(예: 역양자화 파라미터)의 값은, 부호 화를 위한 대응하는 파라미터(예: QP)의 값에 의존하여 설정될 수 있다. 본 개시에서, 복호화 방식은 복원 (reconstruction) 방식으로 지칭될 수 있고, 복호화 파라미터는 복원 파라미터로 지칭될 수 있다. 일 실시예에 따르면, 후처리부는 복호화부에 의해 복호화된 영상 신호를 후처리(post-processing)할 수 있다. 예를 들면, 후처리부는 복호화된 영상 신호에 대한 프레임 보간(frame interpolation) 처리를 수행할 수 있다. 이를 통해, 스킵된 프레임이 다시 생성될 수 있다. 예를 들면, 후처리부는 복호화된 영상 신호에 대 한 품질 향상(enhancement) 처리를 수행할 수 있다. 이를 통해, 열화된 영상 데이터의 품질이 보완(또는, 향 상)될 수 있다. 예를 들면, 복호화된 영상 신호에 대한 프레임 보간 처리를 수행하고, 프레임 보간 처리된 영상 신호에 대한 품질 향상 처리를 수행할 수 있다. 이를 통해, 스킵된 프레임이 다시 생성되고, 열화된 영상 데이 터의 품질이 향상되어, 원본 영상과 실직적으로 동일한 품질의 영상이 제공될 수 있다. 예를 들면, 후처리부는 복호화된 영상 신호에 대한 슈퍼 레졸루션(SR) 처리를 수행할 수 있다. 이를 통해, 다운 스케일된 영상의 해상도가 향상될 수 있다. 예를 들면, 후처리부는 복호화된 영상 신호에 대한 GoP(group of picture) 기반 인핸스먼트(이하, GoP 인 핸스먼트) 처리를 수행할 수 있다. 이를 통해, 시각적으로 스무딩된(temporal smoothing) 영상이 제공될 수 있 다. 실시예로서, GoP 인핸스먼트 처리는 상술한 품질 향상 처리의 일 예일 수 있다. 예를 들면, 후처리부는 복호화된 영상 신호에 대한 프레임 보간 처리, 품질 향상 처리, 및 SR 처리를 수행 할 수 있다. 이를 통해, 압축 효율을 위해 전처리된 영상이 복원되며, 해당 영상의 품질이 향상될 수 있다. 일 실시예에 따른, 후처리부는 전처리에 관련된 정보에 기초하여, 전처리부에 수행된 전처리 동작에 대응하는 후처리 동작을 수행할 수 있다. 예컨대, 프레임 스킵핑에 관련된 정보에 기초하여 프레임 전처리부 에 의해 입력된 영상 신호에 대한 프레임 스킵핑 처리가 수행됨이 식별된 경우, 후처리부는 프레임 스킵핑 처리가 수행된 영상 신호에 대한 프레임 보간 처리를 수행할 수 있다. 예컨대, 전처리부에 의해 입 력된 영상 신호에 대한 다운 스케일 처리 및 레이턴트 벡터 처리가 수행된 경우, 후처리부는 SR 처리를 수 행할 수 있다. 일 실시예에 따르면, 후처리부는 미리 학습된 모델(예: 인공지능 모델)을 이용하여 구현될 수 있다. 한편, 영상 수신 장치는 상술한 후처리부의 기능을 수행하는 후처리부를 포함하지 않을 수 있다. 이 경우, 해당 영상 수신 장치는 영상 송신 장치로부터 수신되는 비트스트림으로부터 전처리에 관련된 정보를 수신하더라 도, 해당 정보에 대응하는 동작을 수행하지 못할 수 있다. 예를 들면, 해당 영상 수신 장치는 비트스트림에 포 함된 프레임 스킵핑에 관련된 정보를 획득하더라도, 해당 정보에 기초하여 해당 프레임에 대한 프레임 보간 적 용 여부에 대한 판단 처리 및 해당 프레임에 대한 보간 처리를 수행하지 못할 수 있다. 다만, 해당 영상 처리 장치는 해당 프레임 스킵에 관련된 정보 및/또는 프레임 수에 대한 정보에 기초하여, 영상 수신 장치에 의해 프 레임 스킵이 수행되었음은 확인할 수 있고, 일반적인 프레임 보간 방식을 이용하여 미리 설정된 고정된 위치에 서 프레임 보간 처리를 수행할 수 있다. 일 실시예에 따르면, 후처리부와 복호화부는 하나의 통합된 구성일 수 있다. 일 예로, 후처리부(12 3)가 복호화부에 포함될 수 있다. 예를 들면, 복호화부가 예컨대, AI 코덱 기술을 이용하는 경우, 후 처리부는 복호화부에 포함되는 구성일 수 있다. 후처리부가 복호화부에 포함되는 경우, 후 처리부의 동작은 복호화부의 복호화 동작(디코딩 동작)의 이후에 수행될 수 있으나, 이에 제한되지 않는다. 예를 들면, 실시예에 따라서는, 후처리부의 동작이 복호화부의 복호화 동작과 함께, 또는 그 이후에 수행될 수도 있다. 일 예로, 적어도 하나의 AI 모델을 통해, 후처리부 및 복호화부의 동작이 함께 수행될 수 있다. 일 실시예에 따르면, 영상 출력부는 복호화부에 의해 복호화된 영상 신호 또는 후처리부에 의해 후처리된 영상 신호를 출력할 수 있다. 예를 들면, 영상 출력부는 복호화된 영상 신호 또는 후처리된 영상신호를 렌더링할 수 있다. 렌더링된 영상 신호는 예컨대, 디스플레이부를 통해 디스플레이될 수 있다. 도 1c는 본 개시의 일 실시예에 따른 영상 송신 장치 및 영상 수신 장치의 개략적인 블록도이다. 도 1c를 참조하면, 영상 송신 장치는 영상 입력부(111a), 전처리부(112a), 코덱 처리부(113a), 영상 출력 부(114a) 및 레이턴트 벡터 처리부(115a)를 포함할 수 있다. 영상 송신 장치는 도시된 구성요소 외에 추가 적인 구성요소를 포함하거나, 도시된 구성요소 중 적어도 하나를 생략할 수 있다. 예를 들면, 영상 송신 장치 는 메모리, 적어도 하나의 프로세서 및/또는 통신부를 더 포함할 수 있다. 영상 송신 장치의 메모리, 적어도 하나의 프로세서 및 통신부에 대한 설명은 도 1b의 설명을 참조할 수 있다. 이에 중복된 설명은 생략한 다. 일 실시예에 따르면, 영상 입력부(111a)는 도 1b의 영상 입력부에 의해 수행되는 동작의 전부 또는 일부를 수행할 수 있고, 나아가, 추가적인 동작을 더 수행할 수 있다. 일 실시예에 따르면, 전처리부(112a)는 도 1b의 전처리부에 의해 수행되는 동작의 전부 또는 일부를 수행 할 수 있고, 나아가, 추가적인 동작을 더 수행할 수 있다. 전처리부(112a)는 코덱 처리부(113a)에 의한 코덱 처 리 이전에, 영상 입력부(111a)에 의해 입력된 영상 신호를 전처리할 수 있다. 예를 들면, 전처리부(112a)는 영상 입력부(111a)에 의해 입력된 영상 신호에 대한 프레임 스킵핑 처리를 수행할 수 있다. 이 경우, 전처리부(112a)는 프레임 스킵 정보를 코덱 처리부(113a), 영상 출력부(114a) 및/또는 레이 턴트 벡터 처리부(115a)로 전달할 수 있다. 예를 들면, 전처리부(112a)는 영상 입력부(111a)에 의해 입력된 영상 신호에 대한 다운 샘플링 처리를 수행할 수 있다. 예를 들면, 전처리부(112a)는 영상 입력부(111a)에 의해 입력된 영상 신호에 대한 프레임 스킵핑 처리 및 다운 샘플링 처리를 함께 수행할 수 있다. 일 실시예에 따르면, 전처리부(112a)는 미리 학습된 모델(예: 인공지능 (AI) 모델)에 의해 구현될 수 있다. 인 공지능 모델에 대한 설명은 도 1b의 인공지능 모델에 대한 설명을 참조할 수 있다. 이에 중복된 설명은 생략한 다. 일 실시예에 따르면, 코덱 처리부(113a)는 영상 입력부에 의해 입력된 영상 신호 또는 전처리부에 의 해 전처리된 영상 신호에 대한 코덱 처리를 수행할 수 있다. 코덱 처리부(113a)의 코덱 처리는, 예컨대, 부호화 처리, 및 부호화/복호화 처리를 포함할 수 있다. 코덱 처리부(113a)의 부호화 처리는 도 1b의 부호화부의 부호화 처리와 동일할 수 있고, 코덱 처리부(113a)의 복호화 처리는 도 1b의 복호화부의 복호화 처리와 동 일할 수 있다. 이에 중복된 설명은 생략한다. 예를 들면, 코덱 처리부(113a)는 전처리부에 의해 전처리된 영상(예: 프레임 스킵핑 처리된 영상, 다운 샘 플링 처리된 영상)에 대한 부호화 처리를 수행하고, 부호화된 영상(예: 코덱 비트스트림)을 영상 출력부(114a) 로 전달할 수 있다. 예를 들면, 코덱 처리부(113a)는 전처리부에 의해 전처리된 영상(예: 프레임 스킵핑 처리된 영상, 다운 샘 플링 처리된 영상)에 대한 부호화 및 복호화를 수행하여, 부호화 및 복호화 처리된 영상을 레이턴트 벡터 처리 부(115a)로 전달할 수 있다. 이 경우, 레이턴트 벡터 처리부(115a)는 부호화 및 복호화 처리된 영상을 이용하여, 레이턴트 벡터를 생성할 수 있다. 이처럼, 레이턴트 벡터 처리부(115a)는 압축 열화가 발생된 영상인, 부호화 및 복호화 처리된 영상을 이용하여 레이턴트 벡터를 생성할 수 있다. 일 실시예에 따르면, 레이턴트 벡터 처리부(115a)는 코덱 처리부(113a)로부터 전달된 부호화 및 복호화 처리된 영상, 및/또는 전처리부(112a)로부터 전달된 프레임 스킵 정보를 이용하여, 레이턴트 벡터를 생성할 수 있다. 예를 들면, 레이턴트 벡터 처리부(115a)는 다운 샘플링 처리된 영상을 부호화 및 복호화 처리한 영상을 이용하 여, 다운 샘플링 처리된 영상에 대한 레이턴트 벡터를 생성할 수 있다. 예를 들면, 레이턴트 벡터 처리부(115 a)는 프레임 스킵핑 처리된 영상을 부호화 및 복호화 처리한 영상, 및 프레임 스킵 정보를 이용하여, 프레임 스 킵핑 처리된 영상에 대한 레이턴트 벡터를 생성할 수 있다. 일 실시예에 따르면, 레이턴트 벡터 처리부(115a)는 생성된 레이턴트 벡터를 영상 출력부(114a)로 전달할 수 있 다. 일 실시예에 따르면, 영상 출력부(114a)는 도 1b의 영상 출력부에 의해 수행되는 동작의 전부 또는 일부를 수행할 수 있고, 나아가 추가적인 동작을 더 수행할 수 있다. 예를 들면, 영상 출력부(114a)는 코덱 처리부(113a)로부터 전달된 부호화된 영상(예: 코덱 비트스트림), 레이턴 트 벡터 처리부(115a)로부터 전달된 레이턴트 벡터 및/또는 전처리부(112a)로부터 전달된 프레임 스킵 정보를 포함하는 신호를 통신부를 통해 영상 수신 장치에게 송신할 수 있다. 부호화된 영상, 레이턴트 벡터 및/또 는 프레임 스킵 정보를 포함하는 최종 비트 스트림은 하나의 컨테이너에 포함되어 전송될 수 있다. 부호화된 영 상, 레이턴트 벡터 및/또는 프레임 스킵 정보의 저장 및 전송 방식에 대한 예시는 도 36 및 37을 참조하여 이하 에서 설명한다. 일 실시예에 따르면, 영상 수신 장치는 영상 입력부(121a), 복호화부(122a), 후처리부(123a) 및 영상 출력 부(124a)를 포함할 수 있다. 영상 수신 장치는 도시된 구성요소 외에 추가적인 구성요소를 포함하거나, 도 시된 구성요소 중 적어도 하나를 생략할 수 있다. 예를 들면, 영상 수신 장치는 메모리, 적어도 하나의 프 로세서 및 통신부를 더 포함할 수 있다. 영상 수신 장치의 메모리, 적어도 하나의 프로세서 및 통신부에 대한 설명은 도 1b의 설명을 참조할 수 있다. 이에 중복된 설명은 생략한다. 일 실시예에 따르면, 영상 입력부(121a)는 도 1b의 영상 입력부에 의해 수행되는 동작의 전부 또는 일부를 수행할 수 있고, 나아가 추가적인 동작을 더 수행할 수 있다. 예를 들면, 영상 입력부(121a)는 영상 송신 장치로부터 수신된 신호로부터 부호화된 영상(예: 코덱 비트스 트림), 레이턴트 벡터 및/또는 프레임 스킵 정보를 획득할 수 있다. 영상 입력부는 부호화된 영상을 코덱 처리부(122a)로 전달하고, 레이턴트 벡터 및/또는 프레임 스킵 정보를 후처리부(123a)로 전달할 수 있다. 일 실시예에 따르면, 코덱 처리부(122a)는 영상 입력부(121a)로부터 전달된 부호화된 영상에 대한 코덱 처리(예: 복호화 처리)를 수행할 수 있다. 코덱 처리부(122a)의 복호화 처리는 도 1b의 복호화부의 복호화 처리와 동일할 수 있다. 이에 중복된 설명은 생략한다. 일 실시예에 따르면, 후처리부(123a)는 도 1b의 후처리부에 의해 수행되는 동작의 전부 또는 일부를 수행 할 수 있고, 나아가 추가적인 동작을 더 수행할 수 있다. 후처리부(123a)는 코덱 처리부(122a)에 의해 복호화된 영상을 후처리할 수 있다. 예를 들면, 후처리부(123a)는 레이턴트 벡터 및/또는 프레임 스킵 정보를 이용하여 복호화된 영상에 대한 프레 임 보간 처리를 수행할 수 있다. 이를 통해, 스킵된 프레임이 다시 생성될 수 있다. 예를 들면, 후처리부(123 a)는 복호화된 영상 신호에 대한 품질 향상 처리를 수행할 수 있다. 이를 통해, 열화된 영상 데이터의 품질이 보완(또는, 향상)될 수 있다. 예를 들면, 복호화된 영상 신호에 대한 프레임 보간 처리를 수행하고, 프레임 보 간 처리된 영상 신호에 대한 품질 향상 처리를 수행할 수 있다. 이를 통해, 스킵된 프레임이 다시 생성되고, 열 화된 영상 데이터의 품질이 향상되어, 원본 영상과 실직적으로 동일한 품질의 영상이 제공될 수 있다. 예를 들면, 후처리부(123a)는 레이턴트 벡터를 이용하여 복호화된 영상 신호에 대한 슈퍼 레졸루션(SR) 처리를 수행할 수 있다. 이를 통해, 다운 스케일된 영상의 해상도가 향상될 수 있다. 예를 들면, 후처리부(123a)는 복호화된 영상 신호에 대한 GoP(group of picture) 기반 인핸스먼트(이하, GoP 인 핸스먼트) 처리를 수행할 수 있다. 이를 통해, 시각적으로 스무딩된(temporal smoothing) 영상이 제공될 수 있 다. 실시예로서, GoP 인핸스먼트 처리는 상술한 품질 향상 처리의 일 예일 수 있다. 예를 들면, 후처리부(123a)는 복호화된 영상 신호에 대한 프레임 보간 처리, 품질 향상 처리, 및 SR 처리를 수 행할 수 있다. 이를 통해, 압축 효율을 위해 전처리된 영상이 복원되며, 해당 영상의 품질이 향상될 수 있다. 일 실시예에 따르면, 후처리부(123a)는 미리 학습된 모델(예: 인공지능 모델)을 이용하여 구현될 수 있다. 일 실시예에 따르면, 영상 출력부(124a)는 도 1b의 영상 출력부에 의해 수행되는 동작의 전부 또는 일부를 수행할 수 있고, 나아가 추가적인 동작을 더 수행할 수 있다. 영상 출력부(124a)는 후처리부(123a)에 의해 후처 리된 영상을 디스플레이를 통해 출력할 수 있다. 도 2a는 본 개시의 일 실시예에 따른, 부호화부의 개략적인 블록도이다. 도 2a를 참조하면, 부호화부는 영상 분할부(210a), 변환부(220a), 양자화부(230a), 엔트로피 인코딩부 (240a), 역양자화부(250a), 역변환부(260a), 필터링부(270a), 버퍼(280a) 및/또는 예측부(290a)를 포함할 수 있다. 영상 부호화부는 도시된 구성요소 외에 추가적인 구성요소를 포함하거나, 도시된 구성요소 중 적어 도 하나를 생략할 수 있다. 부호화부를 구성하는 복수의 구성부들의 전부 또는 적어도 일부는 실시예에 따 라 하나의 하드웨어 컴포넌트(예를 들어, 인코더 또는 프로세서)로 구현될 수 있다.일 실시예에 따르면, 영상 분할부(210a)는 부호화부에 입력된 입력 영상 신호(또는, 픽쳐/프레임)를 하나 이상의 처리 유닛(PU: Processing Unit)으로 분할할 수 있다. 일 예로, 처리 유닛은 코딩 유닛(CU: Coding Unit)이라고 불릴 수 있다. 코딩 유닛은 코딩 트리 유닛(CTU: Coding Tree Unit) 또는 최대 코딩 유닛(LCU: Largest Coding Unit)을 QT/BT/TT (Quad-Tree/Binary- Tree/Ternary-Tree) 구조에 따라 재귀적으로(recursively) 분할함으로써 획득될 수 있다. 예를 들어, 하나의 코 딩 유닛은 쿼드 트리 구조, 바이너리 트리 구조 및/또는 터너리 트리 구조를 기반으로 하위(deeper) 뎁스의 복 수의 코딩 유닛들로 분할될 수 있다. 더 이상 분할되지 않는 최종 코딩 유닛을 기반으로 본 개시에 따른 부호화 절차가 수행될 수 있다. 부호화 절차는 후술하는 예측, 변환 및 양자화 등의 절차를 포함할 수 있다. 다른 예로, 처리 유닛은 예측 유닛(PU: Prediction Unit) 또는 변환 유닛(TU: Transform Unit)일 수 있다. 예 측 유닛 및 변환 유닛은 각각 최종 코딩 유닛으로부터 분할 또는 파티셔닝될 수 있다. 예측 유닛은 샘플 예측의 단위일 수 있고, 변환 유닛은 변환 계수를 유도하는 단위 및/또는 변환 계수로부터 레지듀얼 신호(residual signal)를 유도하는 단위일 수 있다. 본 개시에서 픽셀은 하나의 픽처(또는 영상)를 구성하는 최소 단위를 의미 할 수 있다. 또한, 샘플은 픽셀에 대응하는 용어로서 사용될 수 있고, 픽셀 또는 픽셀의 값을 나타낼 수 있다. 일 실시예에 따르면, 예측부(290a)는 현재 블록(처리 대상 블록)에 대한 예측을 수행하고, 현재 블록에 대한 예 측 샘플들을 포함하는 예측된 블록(Predicted Block)을 생성할 수 있다. 예측부(290a)는 현재 블록 또는 CU 단 위로 인트라 예측이 적용되는지 또는 인터 예측이 적용되는지 결정할 수 있다. 예측부(290a)는 현재 블록의 예 측에 관한 다양한 정보를 생성하여 엔트로피 인코딩부(240a)로 전달할 수 있다. 예측에 관한 정보는 엔트로피 인코딩부(240a)에서 인코딩되어 비트스트림 형태로 출력될 수 있다. 일 실시예에 따르면, 인트라 예측부(291a)는 현재 픽처 내의 샘플들을 참조하여 현재 블록을 예측할 수 있다. 참조되는 샘플들은 인트라 예측 모드 및/또는 인트라 예측 기법에 따라 상기 현재 블록의 주변(neighbor)에 위 치할 수 있고, 또는 떨어져서 위치할 수도 있다. 일 실시예에 따르면, 인터 예측부(292a)는 참조 픽처 상에서 움직임 벡터에 의해 특정되는 참조 블록을 기반으 로, 현재 블록에 대한 예측된 블록을 유도할 수 있다. 이때, 인터 예측 모드에서 전송되는 움직임 정보의 양을 줄이기 위해 주변 블록과 현재 블록 간의 움직임 정보의 상관성에 기초하여 움직임 예측 정보를 블록, 서브블록 또는 샘플 단위로 예측할 수 있다. 예측부(290a)를 통해 생성된 예측 신호는 복원 신호를 생성하기 위해 이용되거나 레지듀얼 신호를 생성하기 위 해 이용될 수 있다. 입력 영상 신호(원본 블록)에서 예측 신호(예측된 블록)를 감산하여 생성된 레지듀얼 신호 (residual signal, 잔여 블록)는 변환부(220a)로 전송될 수 있다. 일 실시예에 따르면, 변환부(220a)는 레지듀얼 신호에 변환 기법을 적용하여 변환 계수들(transform coefficients)을 생성할 수 있다. 예를 들어, 변환 기법은 DCT(Discrete Cosine Transform), DST(Discrete Sine Transform), KLT(Karhunen-Loeve Transform), GBT(Graph-Based Transform), 또는 CNT(Conditionally Non-linear Transform) 중 적어도 하나를 포함할 수 있다. 여기서, GBT는 픽셀 간의 관계 정보를 그래프로 표현 한다고 할 때 이 그래프로부터 얻어진 변환을 의미한다. CNT는 이전에 복원된 모든 픽셀(all previously reconstructed pixel)을 이용하여 예측신호를 생성하고 그에 기초하여 획득되는 변환을 의미한다. 변환 과정은 정사각형의 동일한 크기를 갖는 픽셀 블록에 적용될 수도 있고, 사각형이 아닌 가변 크기의 블록에도 적용될 수 있다. 일 실시예에 따르면, 양자화부(230a)는 변환 계수들을 양자화하여 엔트로피 인코딩부(240a)로 전송할 수 있다. 엔트로피 인코딩부(240a)는 양자화된 신호(양자화된 변환 계수들에 관한 정보)를 인코딩하여 비트스트림으로 출 력할 수 있다. 양자화된 변환 계수들에 관한 정보는 레지듀얼 정보라고 불릴 수 있다. 양자화부(230a)는 계수 스캔 순서(scan order)를 기반으로 블록 형태의 양자화된 변환 계수들을 1차원 벡터 형태로 재정렬할 수 있고, 상기 1차원 벡터 형태의 양자화된 변환 계수들을 기반으로 상기 양자화된 변환 계수들에 관한 정보 등을 생성할 수도 있다. 일 실시예에 따르면, 엔트로피 인코딩부(240a)는 예를 들어 지수 골롬(exponential Golomb), CAVLC(context-adaptive variable length coding), CABAC(context-adaptive binary arithmetic coding) 등과 같은 다양한 인코딩 방법을 수행할 수 있다. 양자화부(230a)로부터 출력된 양자화된 신호는 예측 신호를 생성하기 위해 이용될 수 있다. 예를 들어, 양자화 된 신호는 루프 내의 역양자화부(250a) 및 역변환부(260a)를 통해 역양자화 및 역변환을 적용함으로써 잔여 신 호를 복원할 수 있다. 복원된 잔여 신호를 인트라 예측부(291a) 또는 인터 예측부(292a)로부터 출력된 예측 신호에 더함으로써 복원 신호가 생성될 수 있다. 필터링부(270a)는 복원 신호에 필터링을 적용하여 이를 재생 장치로 출력하거나 버퍼(280a)에 전송한다. 필터링 부(270a)에서 사용되는 필터링 방법은 예컨대, 디블록킹 필터링, 샘플 적응적 오프셋(sample adaptive offset), 적응적 루프 필터(adaptive loop filter), 양방향 필터(bilateral filter) 등을 포함할 수 있다. 버퍼(280a)에 전송된 필터링된 신호는 인터 예측부(292a)에서 참조 픽쳐로 사용될 수 있다. 이처럼, 필터링된 픽쳐를 화면간 예측 모드에서 참조 픽쳐로 이용함으로써 화질 뿐만 아니라 부호화 효율도 향상시킬 수 있다. 버퍼(280a)는 필터링된 픽쳐를 인터 예측부(292a)에서의 참조 픽쳐로 사용하기 위해 저장할 수 있다. 도 2b는 본 개시의 일 실시예에 따른, 복호화부의 개략적인 블록도이다. 도 2b를 참조하면, 복호화부는 엔트로피 디코딩부(220b), 역양자화부(220b), 역변환부(230b), 필터링부 (240b), 버퍼(250b), 및/또는 예측부(260b)를 포함할 수 있다. 복호화부는 도시된 구성요소 외에 추가적인 구성요소를 포함하거나, 도시된 구성요소 중 적어도 하나를 생략할 수 있다. 영상 복호화부를 구성하는 복 수의 구성부들의 전부 또는 적어도 일부는 실시예에 따라 하나의 하드웨어 컴포넌트(예를 들어, 디코더 또는 프 로세서)로 구현될 수 있다. 복호화부는 도 2a을 참조하여 전술한 부호화부에서 수행된 프로세스에 대응하는 프로세스를 수행함으 로써 영상 신호를 복원할 수 있다. 예를 들어, 복호화부는 부호화부에서 적용된 처리 유닛을 이용하 여 복호화를 수행할 수 있다. 따라서 복호화 처리 유닛은 예를 들어 코딩 유닛일 수 있다. 코딩 유닛은 코딩 트 리 유닛이거나 또는 최대 코딩 유닛을 분할하여 획득될 수 있다. 일 실시예에 따르면, 엔트로피 디코딩부(210b)는 비트스트림을 파싱하여 영상 복원(또는 픽처 복원)에 필요한 정보를 도출할 수 있다. 예를 들어, 엔트로피 디코딩부(210b)는 지수 골롬, CAVLC 또는 CABAC 등의 디코딩 방법 을 기초로 비트스트림 내 정보를 디코딩하고, 영상 복원에 필요한 레지듀얼에 관한 양자화된 변환 계수들에 관 한 정보 등을 출력할 수 있다. 엔트로피 디코딩부(210b)에서 디코딩된 정보 중 예측에 관한 정보는 예측부 (260b)로 제공되고, 엔트로피 디코딩부(210b)에서 엔트로피 디코딩이 수행된 레지듀얼 값, 즉 양자화된 변환 계 수들 및 관련 파라미터 정보는 역양자화부(220b)로 입력될 수 있다. 또한, 엔트로피 디코딩부(210b)에서 디코딩 된 정보 중 필터링에 관한 정보는 필터링부(240b)로 제공될 수 있다. 일 실시예에 따르면, 역양자화부(220b)는 양자화된 변환 계수들을 역양자화하여 변환 계수들을 출력할 수 있다. 역양자화부(220b)는 양자화된 변환 계수들을 2차원의 블록 형태로 재정렬할 수 있다. 이 경우 상기 재정렬은 부 호화부에서 수행된 계수 스캔 순서에 기반하여 수행될 수 있다. 역양자화부(220b)는 양자화 파라미터(QP) (예: 양자화 스텝 사이즈 정보)를 이용하여 양자화된 변환 계수들에 대한 역양자화를 수행하고, 변환 계수들 (transform coefficient)을 획득할 수 있다. 일 실시예에 따르면, 역변환부(230b)는 변환 계수들을 역변환하여 레지듀얼 신호(레지듀얼 블록)를 획득할 수 있다. 일 실시예에 따르면, 예측부(260b)는 현재 블록에 대한 예측을 수행하고, 상기 현재 블록에 대한 예측 샘플들을 포함하는 예측된 블록(predicted block)을 생성할 수 있다. 예측부(260b)는 엔트로피 디코딩부(210b)로부터 출 력된 상기 예측에 관한 정보를 기반으로 현재 블록에 인트라 예측이 적용되는지 또는 인터 예측이 적용되는지 결정할 수 있고, 구체적인 인트라/인터 예측 모드(예측 기법)를 결정할 수 있다. 인트라 예측부(261b)는 현재 픽처 내의 샘플들을 참조하여 현재 블록을 예측할 수 있다. 인터 예측부(262b)는 참조 픽처 상에서 움직임 벡터 에 의해 특정되는 참조 블록을 기반으로, 현재 블록에 대한 예측된 블록을 유도할 수 있다. 인트라 예측부 (261b) 및 인터 예측부(262b) 각각의 동작은 부호화부의 인트라 예측부(291a) 및 인터 예측부(292a) 각각 의 동작에 대응된다. 일 실시예에 따르면, 역변환부(230b)로부터 획득된 레지듀얼 신호는 예측부(260b)로부터 출력된 예측 신호(예측 된 블록)에 더해짐으로써, 복원 신호(복원 픽처, 복원 블록)가 생성할 수 있다. 일 실시예에 따르면, 필터링부(240b)는 복원 신호에 필터링을 적용하여 화질을 향상시킬 수 있다. 예를 들어, 필터링부(240b)는 복원 픽처에 다양한 필터링 방법을 적용하여 수정된(modified) 복원 픽처를 생성할 수 있고, 수정된 복원 픽처를 버퍼(250b) 에 저장할 수 있다. 다양한 필터링 방법은, 예컨대, 디블록킹 필터링, 샘플 적 응적 오프셋(sample adaptive offset), 적응적 루프 필터(adaptive loop filter), 양방향 필터(bilateral filter) 등을 포함할 수 있다. 버퍼(250b)에 저장된 복원 픽처는 예측부(260b)에서 참조 픽처로 사용될 수있다. 일 실시예에 따르면, 버퍼(250b)는 현재 픽처 내 움직임 예측 정보가 도출된(또는 디코딩된) 블록의 움직임 예 측 정보 및/또는 이미 복원된 픽처 내 블록들의 움직임 예측 정보를 저장할 수 있다. 저장된 움직임 예측 정보 는 공간적 주변 블록의 움직임 예측 정보 또는 시간적 주변 블록의 움직임 예측 정보로 활용하기 위하여 인터 예측부(262b)에 전달될 수 있다. 버퍼(250b)는 현재 픽처 내 복원된 블록들의 복원 샘플들을 저장할 수 있고, 저장된 복원 샘플들은 인트라 예측부(262b)에 전달될 수 있다. 이하에서는, 프레임 생략 기술을 이용하는 전처리 방법과 프레임 보간 기술 및 품질 향상 기술을 이용하는 후처 리 방법에 대하여 설명한다. 한편, 이러한 전처리 방법/후처리 방법을 수행할지 여부를 판단하기 위해, 프레임 생략 알고리즘이 이용될 수 있다. 프레임 생략 알고리즘은 예컨대, 해당 프레임에 대하여, 일반 압축/복원 방식 (예: 표준 코덱 기술을 이용한 압축/복원 방식)을 이용하는 것이 유리한지, 또는 본 개시의 프레임 생략 기술, 프레임 보간 기술 및 품질 향상 기술을 이용하는 방식(제안되는 방식)을 이용하는 것이 유리한지를 판단하기 위 해 사용되는 알고리즘일 수 있다. 프레임 생략 알고리즘을 이용한 판단을 통해, 해당 프레임에 대하여 제안되는 방식에 따라 영상 송신 장치가 압축 전 프레임 생략 처리를 수행하고, 영상 수신 장치가 복원 후 프레임 보간 및 품질 향상 처리를 수행할지, 또는 해당 프레임을 일반 압축/복원 방식에 따라 처리할지가 결정될 수 있다. 실시예로서, 프레임 생략 알고리즘에 따르는 방법은 AI 모델에 의해 구현될 수 있다. 도 3은 본 개시의 일 실시예에 따른, 전처리부의 프레임 스킵핑 처리 모듈을 나타낸다. 도 4는 본 개시의 일 실 시예에 따른, 프레임 스킵핑 처리 모듈의 동작을 개략적으로 설명한다. 도 5는 본 개시의 일 실시예에 따른, 프 레임 스킵핑 처리 방법의 흐름도이다. 도 3을 참조하면, 전처리부는 프레임 생략 처리를 위한 프레임 스킵핑 처리 모듈을 포함할 수 있다. 본 개시에서, 프레임 스킵핑 처리 모듈의 동작은 영상 송신 장치 또는 영상 송신 장치의 적어도 하나의 프로세서의 동작으로 이해될 수 있다. 일 실시예에 따른, 프레임 스킵핑 처리 모듈은 입력된 영상 신호에 대한 프레임 스킵핑 처리를 수행할 수 있다. 예를 들면, 프레임 스킵핑 처리 모듈은 식별된 복수의 프레임(예: 3개 또는 그 이상의 프레임일 수 있으나, 이에 제한되지 않음)에서 하나의 프레임을 스킵할 수 있다. 예컨대, 도 4에 예시된 것처럼, 프레임 스 킵핑 처리 모듈은 프레임 스킵핑 처리 모듈로 입력된 3개의 시계열적으로 연속된 프레임들 (401,402,403)에서 가운데 프레임인 프레임을 스킵할 수 있다. 이후, 프레임 스킵핑 처리 모듈은 스 킵된 프레임(예: 프레임)을 제외한 나머지 프레임들(예: 프레임들(401,403))을 부호화부로 전달할 수 있다. 이렇게 스킵된 프레임은 부호화부에 의해 인코딩되지 않아, 압축 용량을 줄일 수 있다. 즉, 이러한 프레 임 스킵핑 처리를 통해, 높은 압축 효율이 제공될 수 있다. 일 실시예에 따른, 프레임 스킵핑 처리 모듈은 미리 학습된 AI 모델(또는, 미리 설정된 프레임 생략 알고 리즘)을 이용하여, 입력된 영상 신호에 대한 프레임 스킵핑 처리를 수행할 수 있다. 예를 들면, 프레임 스킵핑 처리 모듈은 미리 학습된 AI 모델을 이용하여, 해당 프레임에 대한 프레임 스킵핑을 적용할지를 결정할 수 있다. 해당 프레임에 대한 프레임 스킵핑이 적용됨이 결정되는 경우, 프레임 스킵핑 처리 모듈은 해당 프 레임을 스킵하고, 스킵된 프레임을 제외한 나머지 프레임들을 부호화부로 전달할 수 있다. 해당 프레임에 대한 프레임 스킵핑이 적용되지 않음이 결정되는 경우, 프레임 스킵핑 처리 모듈은 해당 프레임을 포함하 는 프레임들을 부호화부로 전달할 수 있다. 이러한 AI 모델을 이용한 판단을 통해, 프레임 스킵핑 처리하 는 것이 유리한지 또는 프레임 스킵핑 처리 없이 압축/복원하는 것이 유리한지를 정확하고 빠르게 결정할 수 있 다. 일 실시예에 따른, 프레임 스킵핑 처리 모듈은 해당 프레임에 대하여 프레임 스킵핑을 적용할지를 선택적 으로 결정할 수 있다. 고정된 위치의 프레임을 항상 스킵하는 방식이 아닌, 이러한 판단에 따른 선택적 프레임 스킵핑 처리를 통해, 예컨대, 프레임 보간 및 품질 향상 처리를 통해 품질의 복원이 어려운 프레임이 스킵핑되 는 것을 방지할 수 있다. 이하, 도 5를 참조하여, 프레임 스킵핑 처리 모듈의 프레임 스킵핑 처리 방법의 예시적인 동작들을 설명한 다. 한편, 이하에서 설명할 프레임 스킵핑 처리 모듈의 동작은, 영상 송신 장치 또는 영상 송신 장치 의 적어도 하나의 프로세서에 의해 제어 또는 수행되는 것으로 이해될 수 있다. 도 5를 참조하면, 동작 5010에서, 프레임 스킵핑 처리 모듈은 복수의 프레임을 포함하는 프레임 세트(또는, 프레임 그룹)를 획득할 수 있다. 예를 들면, 도 4에 예시된 것처럼, 제1 프레임에 대한 프레임스킵핑을 적용할지 여부를 결정하기 위해, 프레임 스킵핑 처리 모듈은 제1 프레임, 제1 프레임 의 이전 프레임인 프레임 및 제1 프레임의 이후 프레임인 프레임을 포함하는 프레임 세트를 획 득할 수 있다. 한편, 해당 프레임 세트의 첫 번째 프레임(예: 제1 프레임의 이전 프레임인 프레임)이 I(intra)-프레임이 아닌 경우(예컨대, 인터(inter) 프레임(예: P 프레임)인 경우), 프레임 세트는 프레임 의 이전 프레임(예: I 프레임)을 더 포함할 수 있다. 즉, 프레임 세트는 4개의 프레임을 포함할 수 있다. 이러 한 프레임 세트에 포함된 프레임의 수는 예컨대, 부호화 처리를 위해 필요한 프레임의 수에 대응할 수 있다. 동작 5020에서, 프레임 스킵핑 처리 모듈은 미리 학습된 모델(또는, 미리 설정된 프레임 생략 알고리즘)을 이용하여, 프레임 세트에 포함된 제1 프레임에 대한 프레임 스킵핑을 적용할지 여부를 결정할 수 있다. 예 를 들면, 프레임 스킵핑 처리 모듈은 미리 학습된 모델(예: 도 7의 모델)을 이용하여, 제1 프레임 에 대한 프레임 스킵핑을 적용할지 여부를 결정할 수 있다. 해당 프레임에 대한 프레임 스킵핑을 적용할지 여부를 결정하는 것에 대한 설명은 도 6을 참조하여 이하에서 설명한다. 동작 5030에서, 제1 프레임에 대한 프레임 스킵핑이 적용됨이 결정된 경우, 프레임 스킵핑 처리 모듈(31 0)은 제1 프레임을 스킵할 수 있다. 예를 들면, 도 4에 도시된 것처럼, 프레임 스킵핑 처리 모듈은 프레임 및 프레임 사이의 제1 프레임을 스킵할 수 있다. 이렇게 스킵된 제1 프레임은 부호 화부에 의해 부호화 처리되지 않는다. 동작 5040에서, 프레임 스킵핑 처리 모듈은 제1 프레임이 스킵된 프레임 세트를 부호화부로 전달할 수 있다. 예를 들면, 프레임 스킵핑 처리 모듈은 제1 프레임이 제외된 프레임 및 프레임를 포함하는 프레임 세트를 부호화부로 전달할 수 있다. 한편, 상술한 것처럼, 프레임이 I-프레임이 아닌 경 우, 프레임 스킵핑 처리 모듈은 프레임의 이전 프레임, 프레임 및 프레임를 포함하는 프레 임 세트를 부호화부로 전달할 수 있다. 이렇게 전달된 프레임 세트는 부호화부에 의해 부호화 처리될 수 있다. 동작 5050에서, 제1 프레임에 대한 프레임 스킵핑이 적용되지 않음이 결정된 경우, 프레임 스킵핑 처리 모 듈은 프레임, 제1 프레임 및 프레임을 포함하는 프레임 세트를 부호화부로 전달할 수 있다. 한편, 상술한 것처럼, 프레임이 I-프레임이 아닌 경우, 프레임 스킵핑 처리 모듈은 프레임 의 이전 프레임, 프레임, 제1 프레임 및 프레임를 포함하는 프레임 세트를 부호화부로 전 달할 수 있다. 이렇게 전달된 프레임 세트는 부호화부에 의해 부호화 처리될 수 있다. 이하, 도 6를 참조하여, 프레임 스킵핑 처리 모듈의 프레임 스킵핑 적용 결정 동작을 예시적으로 설명한다. 도 6은 본 개시의 일 실시예에 따른, 프레임 스킵핑 처리 방법의 프레임 스킵핑 적용 결정 동작을 나타낸다. 도 7은 본 개시의 일 실시예에 따른, 프레임 스킵핑 적용 결정을 위한 모델의 일 예를 나타낸다. 도 8a는 본 개시 의 일 실시예에 따른, 율 왜곡 평면 상의 율 왜곡 곡선과 타겟 율 왜곡 지점의 일 예를 나타낸다. 도 8b는 본 개시의 일 실시예에 따른, 율 왜곡 곡선과 타겟 율 왜곡 지점 사이의 거리의 일 예를 나타낸다. 도 6의 프레임 스킵핑 처리 모듈의 동작은, 영상 송신 장치 또는 영상 송신 장치의 적어도 하나 의 프로세서에 의해 제어 또는 수행되는 것으로 이해될 수 있다. 도 6을 참조하면, 동작 6010에서, 프레임 스킵핑 처리 모듈은, 복수의 프레임(예: 부호화 및 복호화된 복 수의 프레임 또는 복수의 원본 프레임)을 획득할 수 있다. 예를 들면, 제1 프레임(예: 도 4의 프레임)에 대한 프레임 스킵핑을 적용할지 여부를 결정하는 경우, 프레임 스킵핑 처리 모듈은 부호화 및 복호화된 복 수의 프레임(예: 도 4의 프레임, 제1 프레임 및 프레임을 부호화 및 복호화하여 생성된, 부호화 및 복호화된 복수의 프레임) 또는 복수의 원본 프레임(예: 도 4의 프레임, 제1 프레임 및 프레임 )을 획득할 수 있다. 본 개시에서, 부호화 및 복호화된 프레임은, 코덱 처리된 프레임으로 지칭될 수도 있 다. 동작 6020에서, 프레임 스킵핑 처리 모듈은, 복수의 프레임(예: 부호화 및 복호화된 복수의 프레임 또는 복수의 원본 프레임)을 기초로, 미리 학습된 모델(또는, 미리 설정된 프레임 생략 알고리즘)을 이용하여, 비트 율(rate) 및 왜곡(distortion)과 연관된 정보(예: 비트 율 및 왜곡과 연관된 거리에 대한 정보(거리 정보)일 수 있으나, 이에 제한되지 않음)를 획득할 수 있다. 예를 들면, 도 7에 예시된 것처럼, 프레임 스킵핑 처리 모듈 은, 부호화 및 복호화된 복수의 프레임(예: 도 4의 프레임, 제1 프레임 및 프레임을 부호 화하고, 복호화하여 생성된, 부호화 및 복호화된 복수의 프레임) 또는 복수의 원본 프레임(예: 도 4의 프레임 , 제1 프레임 및 프레임)을 포함하는 프레임 세트를 포함하는 입력 데이터를 모델(또는, 거리 예측기(distance predictor))에 입력하고, 거리 정보를 출력 데이터로 획득할 수 있다. 본 개시에서, 모델은 거리 예측 모델로 지칭될 수 있다. 일 실시예에 따른, 거리 정보는 동일한 비트 율에서의 제1 왜곡 및 제2 왜곡의 차이와 연관되는 거리를 포함할 수 있다. 제1 왜곡은 제1 프레임(제1 이미지 프레임)에 대한 프레임 스킵핑이 적용된 제1 프레임 세트 (제1 이미지 프레임 세트)와 연관되며, 제2 왜곡은 제1 프레임(제1 이미지 프레임)에 대한 프레임 스킵핑이 적 용되지 않은 제2 프레임 세트(제2 이미지 프레임 세트)와 연관될 수 있다. 일 실시예에 따른, 거리는 제1 왜곡 에서 제2 왜곡을 뺀 값에 대응할 수 있다. 이러한 AI 모델을 이용한 획득된 거리 정보를 통해, 프레임 스킵 처 리하는 것이 유리한지 또는 프레임 스킵 처리 없이 압축/복원하는 것이 유리한지가 정량적으로 확인될 수 있다. 예컨대, 거리 정보를 통해, 일반 압축/복원 방식(예: 표준 코덱 기술을 이용한 압축/복원 방식)을 이용하 는 것이 유리한지, 또는 프레임 생략 기술, 프레임 보간 기술 및 품질 향상 기술을 이용하는 방식(제안되는 방 식)을 이용하는 것이 유리한지가 판단될 수 있다. 일 실시예에 따른, 거리 예측 모델은 복수의 인공 신경망 레이어를 포함하는 인공지능 모델일 수 있다. 인공 신 경망은, 예컨대, DNN, CNN, RNN, RBM, DBN, BRDNN, 심층 Q-네트워크(deep Q-networks) 또는 상기 중 둘 이상의 조합 중 하나일 수 있으나, 전술한 예에 한정되지 않는다. 일 실시예에 따른, 거리 예측 모델은 입력층, 은닉층(들) 및 출력층을 포함할 수 있다. 일 실시예에 따른, 거리 예측 모델은 입력층, 복수의 컨볼루션 레이어(convolution layer), 완전 연결된 레이어(fully connected layer) 및 출력층을 포함할 수 있다. 일 실시예에 따른, 거리 예측 모델은 압축 방식 및/또는 압축 방식과 연관된 압축 파라미터 별로 학습될 수 있 다. 예를 들면, 압축 방식이 HEVC 표준을 따른 방식인 경우, 각 거리 예측 모델은 압축 파라미터(예: QP) 별로 학습될 수 있다. 예를 들면, 해당 압축 방식에 4개의 QP가 사용되는 경우, 4개의 거리 예측 모델이 QP 별로 개 별적으로 학습될 수 있다. 일 실시예에 따른, 프레임 스킵핑 처리 모듈은 압축 방식 및/또는 압축 방식과 연관된 압축 파라미터에 기 초하여, 미리 학습된 복수의 거리 예측 모델 중 한 거리 예측 모델을 선택할 수 있다. 예를 들면, 프레임 스킵 핑 처리 모듈은 타겟 압축 방식(예: HEVC 표준을 따른 방식) 및 타겟 압축 방식과 연관된 타겟 압축 파라 미터(예: QP)에 기초하여, 복수의 거리 예측 모델 중 해당 압축 방식 및 해당 압축 파라미터를 기초로 학습된 거리 예측 모델을 선택할 수 있다. 타겟 압축 방식 및 타겟 압축 파라미터는 해당 프레임들을 부호화하기 위해 부호화부(예: 부호화부)에 의해 사용되는 압축 방식 및 압축 파라미터일 수 있다. 일 실시예에 따른, 거리 예측 모델은 미리 수집된 학습 데이터 세트에 기초하여 학습될 수 있다. 거리 예측 모 델의 학습을 위한 학습 데이터 세트를 수집하기 위한 방법의 일 예는 도 8a/b를 참조하여 이하에서 설명한다. 본 개시에서, 학습 데이터 세트는 트레이닝 데이터 세트로 지칭될 수도 있다. 일 실시예에 따른, 율 왜곡 곡선은 프레임 스킵핑이 적용되지 않은 복수의 프레임(예: 도 4의 프레임, 프 레임, 및 프레임)에 기초하여 획득된 비트 율 값들 및 왜곡 값들을 포함하는 율 왜곡 데이터(예: 도 9의 제1 율 왜곡 데이터)와 연관될 수 있다. 예를 들면, 도 8a에 예시된 것처럼, 율 왜곡 곡선은 프 레임 스킵핑이 적용되지 않은 복수의 프레임(예: 프레임, 프레임, 및 프레임)에 기초하여 복수 의 압축 파라미터(예: QP=0 내지 QP=51)의 각각에 대하여 획득된 비트 율 값 및 왜곡 값의 쌍으로 구성된 지점 들을 연결하는 곡선에 해당할 수 있다. 일 실시예에 따른, 타겟 율 왜곡 지점은 프레임 스킵핑이 적용된 복수의 프레임(예: 도 4의 프레임 및 프 레임)에 기초하여 획득된 비트 율 값 및 왜곡 값을 포함하는 율 왜곡 데이터(예: 도 9의 제2 율 왜곡 데이 터)와 연관될 수 있다. 예를 들면, 도 8a에 예시된 것처럼, 타겟 율 왜곡 지점은 프레임 스킵핑이 적용된 복수의 프레임(예: 도 4의 프레임 및 프레임)에 기초하여, 타겟 압축 파라미터(예: QP=n (0<=n<=51))에 대하여 획득된 비트 율 값( ) 및 왜곡 값( )의 쌍으로 구성된 지점에 해당할 수 있다. 일 실시예에 따른, 거리에 대한 정보는, 율 왜곡 곡선과 타겟 율 왜곡 지점 사이의 거리를 지시할 수 있다. 예 를 들면, 도 8b에 예시된 것처럼, 거리는 동일한 비트 율( )에서 율 왜곡 곡선 내의 제1 직선 과 타겟 율 왜곡 지점 사이의 거리일 수 있다. 일 실시예에 거리는 다음 수학식에 의해 계산될 수 있다.[수학식 1] 거리(distance)= - c( ), 여기서, c(rate)은 제1 직선에 대한 함수임. 이러한 거리는 동일한 비트 율에서의 프레임 스킵핑을 적용하는 경우와 적용하지 않는 경우의 왜곡의 차이에 대 응할 수 있다. 프레임 스킵핑이 적용되는 경우, 왜곡은 3개의 원본 이미지 프레임들과 이에 대응하는 부호화 및 복호화 처리되는 2개의 이미지 프레임들 및 2개의 이미지 프레임을 기초로 보간된 1개의 이미지 프레임에 기초 하여 획득될 수 있고, 비트 율은 부호화 및 복호화 처리되는 2개의 이미지 프레임들에 기초하여 획득될 수 있다. 프레임 스킵핑이 적용되지 않은 경우, 왜곡은 3개의 원본 이미지 프레임들과 이에 대응하는 부호화 및 복 호화 처리되는 3개의 이미지 프레임들에 기초하여 획득될 수 있고, 비트 율은 부호화 및 복호화 처리되는 3개의 이미지 프레임들에 기초하여 획득될 수 있다. 왜곡은 예컨대, 미리 설정된 방식(예: MSE(mean square error) 방 식)일 이용하여 획득될 수 있다. 한편, 실시예에 따라서, 거리는 수학식 1에 의해 계산된 거리가 아닌, 제1 직선과 타겟 율 왜곡 지점 의 수직 거리에 해당할 수 있다. 6030에서, 프레임 스킵핑 처리 모듈은 획득된 거리에 대한 정보를 기초로, 제1 프레임(예: 도 4의 프레임 )에 대한 프레임 스킵핑을 적용할지 여부를 결정할 수 있다. 예를 들면, 수학식 1에 따라 거리가 계산된 경우, 거리의 값이 음수이면, 프레임 스킵핑 처리 모듈은 제1 프레임(예: 도 4의 프레임)에 대한 프 레임 스킵핑을 적용함을 결정할 수 있다. 즉, 이 경우, 동일한 비트 율에서의 프레임 스킵핑을 적용하는 경우의 왜곡이 프레임 스킵핑을 적용하지 않는 경우의 왜곡 보다 작기 때문이다. 예를 들면, 수학식 1에 따라 거리가 계산된 경우, 거리의 값이 양수이면, 프레임 스킵핑 처리 모듈은 제1 프레임(예: 도 4의 프레임)에 대한 프레임 스킵핑을 적용하지 않음을 결정할 수 있다. 즉, 이 경우, 동일한 비트 율에서의 프레임 스킵핑을 적용하는 경우의 왜곡이 프레임 스킵핑을 적용하지 않는 경우의 왜곡 보다 크기 때문이다. 이하에서는, 도 9를 참조하여, 동일 비트율에서의 프레임 스킵핑을 적용하는 경우와 적용하지 않는 경우의 왜곡 의 차이에 대응하는 거리를 획득하기 위한 알고리즘(이하, 프레임 생략 알고리즘)을 설명하고, 이를 기초로 프 레임 스킵핑 처리를 위한 거리 예측 모델의 학습을 위한 학습 데이터 세트를 생성하는 방법의 일 예를 설명한다. 도 9는 본 개시의 일 실시예에 따른, 율 왜곡 곡선과 타겟 율 왜곡 지점 사이의 거리를 획득하기 위한 방법의 일 예를 나타낸다. 도 9의 실시예에서, 거리는 예컨대, 동일한 비트 율에서의 율 왜곡 곡선(예: 도 8a의 율 왜곡 곡선)과 타 겟 율 왜곡 지점(예: 도 8b의 타겟 율 왜곡 지점) 사이의 거리(예: 도 8b의 거리)일 수 있다. 이러 한 거리는 이하에서 설명하는 재귀적 알고리즘에 해당하는 프레임 생략 알고리즘에 따라 획득될 수 있으나, 이 에 제한되지 않는다. 도 9를 참조하면, 동작 901에서, 영상 송신 장치(예: 영상 송신 장치)는 미리 설정된 수(예: 3개 또는 그 이상)의 프레임을 획득할 수 있다. 예를 들면, 영상 송신 장치는 시계열적으로 연속된 3개의 프레임을 획득할 수 있다. 동작 902에서, 영상 송신 장치는 획득된 프레임들 중 한 프레임에 프레임 스킵핑을 적용할 수 있다. 예를 들면, 영상 송신 장치는 획득된 3개의 프레임 중 가운데 프레임을 스킵할 수 있다. 동작 911에서, 영상 송신 장치는 프레임 스킵핑 적용 없이, 획득된 프레임들에 대한 제1 영상 처리를 수행할 수 있다. 예를 들면, 영상 송신 장치는 프레임 스킵핑 적용 없이, 획득된 3개의 프레임에 대한 부호화 처리, 및 복 호화 처리(일반 압축/복원 처리)를 수행할 수 있다. 예컨대, 압축 방식이 HEVC이고, 압축 파라미터가 QP이며, 설정 가능한 QP의 값이 0 에서 51까지인 경우, 영상 송신 장치는 각 QP 별로, 획득된 3개의 프레임에 대한 부호 화 처리 및 복호화 처리를 각각 수행하여, QP 별로 제1 영상 처리된 프레임들의 데이터를 획득할 수 있다. 동작 921에서, 영상 송신 장치는 QP 별로 제1 영상 처리된 프레임들의 데이터를 기초로, 제1 율 왜곡 데이터를 획득할 수 있다. 제1 율 왜곡 데이터는, QP 별로 획득된 비트 율 값 및 왜곡 값을 각각 포함할 수 있다. 즉, 제 1 율 왜곡 데이터는 ( , ), …( , ), …, ( , ) 를 포함할 수 있다. 일 실시예에 따른,QP에 대한 왜곡 값은 원본 프레임들과, 해당 QP에 따라 제1 영상 처리된 프레임들에 기초하여 획득된 MSE 값에 대응할 수 있다. 동작 912에서, 영상 송신 장치는 프레임 스킵핑 적용된 프레임들에 대한 제2 영상 처리를 수행할 수 있다. 예를 들면, 영상 송신 장치는 프레임 스킵핑 적용된 2개의 프레임에 대한 부호화 처리, 복호화 처리, 및 후처리(예: 프레임 보간 및 품질 향상 처리)를 수행할 수 있다. 예컨대, 압축 방식이 HEVC이고, 타겟 압축 파라미터가 QP인 경우, 영상 송신 장치는 타겟 QP에 대하여, 2개의 프레임에 대한 부호화 처리, 복호화 처리 및 후처리를 각각 수행하여, 타겟 QP에 대한 제2 영상 처리된 프레임들의 데이터를 획득할 수 있다. 동작 922에서, 영상 송신 장치는 타겟 QP에 대한 제2 영상 처리된 프레임들의 데이터를 기초로, 제2 율 왜곡 데 이터를 획득할 수 있다. 제2 율 왜곡 데이터는, 타겟 QP에 대하여 획득된 비트 율 값 및 왜곡 값을 포함할 수 있다. 즉, 제2 율 왜곡 데이터는 ( , )를 포함할 수 있다. 일 실시예에 따른, 타겟 QP에 대한 왜곡 값은 원본 프레임들과, 타겟 QP에 따라 제2 영상 처리된 프레임들에 기초하여 획득된 MSE 값에 대응할 수 있다. 동작 930에서, 영상 송신 장치는 제1 율 왜곡 데이터 및 제2 율 왜곡 데이터에 기초하여 거리 데이터를 획득할 수 있다. 일 실시예에 따른, 영상 송신 장치는 제1 율 왜곡 데이터에 기초하여 율 왜곡 평면 상에 율 왜곡 곡선을 표시할 수 있다. 예를 들면, 도 8a에 예시된 것처럼, 영상 송신 장치는 제1 율 왜곡 데이터에 포함되는 율 왜곡 지점들 (예: ( , ), …( , ), …, ( , ))을 율 왜곡 평면 상에 표시하고, 해당 지점들을 연결하 여 율 왜곡 곡선(예: 도 8a의 율 왜곡 곡선)을 표시할 수 있다. 일 실시예에 따른, 영상 송신 장치는 제2 율 왜곡 데이터에 기초하여 율 왜곡 평면 상에 타겟 율 왜곡 지점을 표시할 수 있다. 예를 들면, 도 8a에 예시된 것처럼, 영상 송신 장치는 제2 율 왜곡 데이터에 포함되는 율 왜곡 지점(예: ( , ))을 율 왜곡 평면 상에 타겟 율 왜곡 지점(예: 타겟 율 왜곡 지점)으로 표시할 수 있다. 일 실시예에 따른, 영상 송신 장치는 QP (0,51)과 타겟 QP에 대한 왜곡과 비트율인 와 를 획득할 수 있다. 이후, 영상 송신 장치는 가 두 구간 와 중 어디에 속하는지를 확인한다. 예를 들면, 이고, 를 만족하여, 이 구간 내에 속하는 경우, 영상 송신 장치는 양쪽 QP인 0, 51의 가운데 지점으로 다시 세 개의 QP 를 설정한다. 영상 송신 장치는 상술한 과정을 양쪽 QP 가 연속된 숫자가 될 때까지 재귀적으로 반복할 수 있다. 양쪽 QP 가 연속된 숫자가 된 경우, 영상 송신 장치는 QP 에 대하여, 와 를 획득하고, 이를 직선으로 보간 하여, 직선에 대한 함수 (예: 도 8b의 직선)를 획득한다. 영상 송신 장치는 타겟 지 점(타겟 율 왜곡 지점) ( , )과의 거리를 예컨대, 상술한 수학식 1을 이용하여 계산할 수 있다. 상술한 것처럼, 해당 거리는 동일한 비트 율에서의 왜곡의 차이에 해당할 수 있다. 일 예로, 거리가 음수인 경우, 타겟 지점 이 동일한 비트 율에서 더 적은 왜곡을 보여주며, 반대로, 거리가 양수인 경우, 타겟 지점 이 동일한 비트 율에서 더 적은 왜곡을 보여줄 수 있다. 한편, 타겟 QP를 설정 가능한 모든 QP로 변경하여, 해당 타겟 QP에서 도 9의 상술한 동작을 반복적으로 수행함 으로써, 설정 가능한 모든 타겟 QP에서의 거리를 각각 획득할 수 있다. 또한, 이용 가능한 모든 프레임들에 대 하여, 상술한 것처럼, 미리 설정된 수(3 개)의 프레임들의 세트(프레임 세트)로 묶어서, 도 9의 상술한 동작들 을 반복하여 수행할 수 있다. 다만, 상술한 도 9의 프레임 생략 알고리즘을 이용하는 경우, 영상 송신 장치가 타겟 QP에서의 해당 프레임 세 트에 대한 거리 값을 획득하기 위해, 여러 QP에 대하여 동일한 절차를 반복적으로 수행하여야 한다. 따라서, 긴 인코딩 시간이 소요된다. 이에 거리를 획득하기 위해, 도 9의 프레임 생략 알고리즘을 그대로 이용하기 보다는, 도 9의 프레임 생략 알고리즘을 이용하여 획득된 데이터 세트를 이용하여 QP 별로 인공지능 모델(예: 도 7의 거 리 예측 모델)을 학습하고, QP 별로 학습된 인공지능 모델을 이용하는 것이 더 유용할 수 있다. 예를 들 면, 3개의 프레임들을 QP와 연관된 거리 예측 모델의 입력 데이터로 입력하고, 거리 예측 모델의 출력인 거리 값(제1 거리 값)이 도 9의 프레임 생략 알고리즘을 통해 미리 알고 있는 해당 3개의 프레임에 대응하는 QP와 연 관된 거리 값(제2 거리 값)과 동일해지도록, 해당 거리 예측 모델이 학습될 수 있다. 한편, 인공지능 모델의 학 습은 영상 송신 장치에 의해 수행될 수도 있으나, 다른 전자 장치(예: 서버)에 의해 수행된 뒤, 학습된 인공지 능 모델(또는, 인공지능 모델과 연관된 적어도 하나의 파라미터)이 영상 송신 장치로 전달될 수 있다. 도 10은 본 개시의 일 실시예에 따른, 후처리부의 프레임 보간 처리 모듈 및 품질 향상 처리 모듈을 나타낸다. 도 11은 본 개시의 일 실시예에 따른, 프레임 보간 처리 모듈 및 품질 향상 처리 모듈의 동작을 개략적으로 설 명한다. 도 10을 참조하면, 후처리부는 프레임 보간 처리를 위한 프레임 보간 처리 모듈 및 품질 향상 처리 를 위한 품질 향상 처리 모듈을 포함할 수 있다. 본 개시에서, 프레임 보간 처리 모듈 및 품질 향 상 처리 모듈의 동작은 영상 수신 장치 또는 영상 수신 장치의 적어도 하나의 프로세서의 동작 으로 이해될 수 있다. 일 실시예에 따른, 프레임 보간 처리 모듈은 복호화된 영상 신호에 대한 프레임 보간 처리를 수행할 수 있다. 예를 들면, 프레임 보간 처리 모듈은 복호화된 복수의 프레임을 이용하여 하나의 프레임을 보간할 수 있다. 예컨대, 도 11에 예시된 것처럼, 프레임 보간 처리 모듈은 프레임 보간 처리 모듈로 입력 된 2개의 프레임들(1101,1103)의 사이에 한 프레임을 보간할 수 있다. 보간된 프레임은 예컨대, 시 계열적으로 프레임 및 프레임의 중간 시점에 대응하는 프레임일 수 있다. 일 실시예에 따른, 보간된 프레임은 영상 송신 장치의 프레임 스킵핑 처리 모듈(예: 도 3의 프레임 스킵 핑 처리 모듈)에 의해 스킵된 프레임(예: 도 4의 프레임)에 대응할 수 있다. 이후, 프레임 보간 처리 모듈은 보간된 프레임을 포함하는 프레임들(1101,1102,1103)을 품질 향상 처리 모듈로 전달 할 수 있다. 일 실시예에 따른, 프레임 보간 처리 모듈은 영상 송신 장치로부터 전달된 프레임 스킵핑에 관련된 정보 에 기초하여, 해당 프레임 세트에 대한 프레임 보간을 적용할지 여부를 결정할 수 있다. 해당 프레임 세트에 대 한 프레임 보간이 적용됨이 결정되는 경우, 프레임 보간 처리 모듈은 해당 프레임 세트에 포함된 복수의 프레임을 이용하여 복수의 프레임 사이의 한 프레임(제1 프레임)(예: 도 11의 프레임)을 보간하고, 제1 프레임이 보간된 프레임 세트를 품질 향상 처리 모듈로 전달할 수 있다. 해당 프레임 세트에 대한 프레임 보간이 적용되지 않음이 결정되는 경우, 프레임 보간 처리 모듈은 제1 프레임이 보간되지 않은 프레임 세 트를 품질 향상 처리 모듈로 전달할 수 있다. 또는, 해당 프레임 세트에 대한 프레임 보간이 적용되지 않 음이 결정되는 경우, 품질 향상 처리 모듈에 의한 품질 향상 처리도 생략될 수 있다. 일 실시예에 따른, 프레임 보간 처리 모듈은 미리 학습된 AI 모델(이하, 프레임 보간 모델)을 이용하여, 복호화된 영상 신호에 대한 프레임 보간 처리를 수행할 수 있다. 프레임 보간 모델의 설명 및 학습 방법에 대하 여는 도 13을 참조하여 이하에서 설명한다. 일 실시예에 따른, 품질 향상 처리 모듈은 프레임 보간 처리된 영상 신호 또는 프레임 보간 처리되지 않 은 영상 신호에 대한 품질 향상 처리를 수행할 수 있다. 예를 들면, 품질 향상 처리 모듈은 프레임 보간 처리된 영상 신호에 대한 품질 향상 처리를 수행할 수 있다. 예컨대, 도 11에 예시된 것처럼, 품질 향상 처리 모듈은 프레임 보간 처리된 프레임들(1101, 1102, 1103)에 대한 품질 향상 처리를 수행하여, 품질 향상된 프레임들(1121, 1122, 1123)을 생성할 수 있다. 일 실시예에 따른, 품질 향상 처리 모듈은 미리 학습된 모델(이하, 품질 향상 모델)을 이용하여, 해당 프 레임들에 대한 품질 향상 처리를 수행할 수 있다. 품질 향상 모델을 이용한 품질 향상 처리는 도 14를 참조하여, 이하에서 설명한다. 일 실시예에 따른, 품질 향상 처리 모듈은 GoP 인핸스먼트 처리 모듈(예: 도 19의 GoP 인핸스먼트 처리 모듈)이거나, GoP 인핸스먼트 처리 모듈을 포함할 수 있다. GoP 인핸스먼트 처리 모듈은 예컨대, 프레임보간 처리된 영상 신호 또는 프레임 보간 처리되지 않은 영상 신호에 대한 GoP 인핸스먼트 처리를 수행할 수 있 다. GoP 인핸스먼트 처리 모듈에 대한 설명은 도 17 내지 23을 참조하여 이하에서 설명한다. 이하, 도 12를 참조하여, 프레임 보간 처리 모듈의 프레임 보간 처리 방법의 예시적인 동작들을 설명한다. 도 12는 본 개시의 일 실시예에 따른, 프레임 보간 처리 방법의 흐름도이다. 도 13은 본 개시의 일 실시예에 따 른, 프레임 보간 처리를 위한 모델의 일 예를 나타낸다. 이하에서 설명할 프레임 보간 처리 모듈의 동작은, 영상 수신 장치 또는 영상 수신 장치의 적 어도 하나의 프로세서에 의해 제어 또는 수행되는 것으로 이해될 수 있다. 도 12를 참조하면, 동작 12010에서, 프레임 보간 처리 모듈은 복호화된 복수의 프레임을 포함하는 프레임 세트를 획득할 수 있다. 예를 들면, 도 11에 예시된 것처럼, 프레임 보간 처리 모듈은 복호화된 프레임 및 복호화된 프레임을 포함하는 프레임 세트를 획득할 수 있다. 동작 12020에서, 프레임 보간 처리 모듈은 프레임 스킵핑에 관련된 정보를 이용하여, 프레임 세트에 프레 임 보간을 적용할지 여부를 결정할 수 있다. 예를 들면, 프레임 보간 처리 모듈은 프레임 스킵핑에 관련 된 정보를 이용하여, 프레임 세트에 대한 프레임 보간을 적용할지 여부를 결정할 수 있다. 예를 들면, 프레임 스킵핑에 관련된 정보가 해당 프레임 세트 내의 프레임이 스킵됨을 지시하는 경우, 프레임 보간 처리 모듈 은 해당 프레임에 대한 프레임 보간을 적용함을 결정할 수 있다. 예를 들면, 프레임 스킵핑에 관련된 정 보가 해당 프레임 세트 내의 프레임이 스킵되지 않음을 지시하는 경우, 프레임 보간 처리 모듈은 해당 프 레임에 대한 프레임 보간을 적용하지 않음을 결정할 수 있다. 동작 12030에서, 해당 프레임 세트에 대한 프레임 보간을 적용함이 결정된 경우, 프레임 보간 처리 모듈 은 해당 프레임 세트에 포함된 복수의 프레임을 이용하여 복수의 프레임 사이의 한 프레임을 보간할 수 있다. 예를 들면, 도 11에 도시된 것처럼, 프레임 보간 처리 모듈은 해당 프레임 세트 내의 프레임 및 프 레임를 이용하여, 시계열적으로 중간 시점의 제1 프레임을 보간(또는, 생성)할 수 있다. 일 실시예에 따른, 프레임 보간 처리 모듈은 해당 프레임 세트에 포함된 복수의 프레임을 기초로, 미리 학습된 모델(프레임 보간 모델)을 이용하여, 제1 프레임을 보간할 수 있다. 예를 들면, 도 13에 예시된 것처럼, 프레임 보간 처리 모듈은, 복호화된 복수의 프레임(예: 도 11의 복호화된 프레임 및 복호화된 프레 임)을 포함하는 프레임 세트를 입력 데이터로서 모델에 입력하고, 제1 프레임이 보간된 프레 임 세트를 출력 데이터로서 획득할 수 있다. 본 개시에서, 모델은 프레임 보간 모델로 지칭될 수 있다. 일 실시예에 따른, 프레임 보간 모델은 복수의 인공 신경망 레이어를 포함하는 인공지능 모델일 수 있다. 인공 신경망은, 예컨대, DNN, CNN, RNN, RBM, DBN, BRDNN, 심층 Q-네트워크 또는 상기 중 둘 이상의 조합 중 하나일 수 있으나, 전술한 예에 한정되지 않는다. 일 실시예에 따른, 프레임 보간 모델은 입력층, 은닉층(들) 및 출력층을 포함할 수 있다. 일 실시예에 따른, 프 레임 보간 모델은 입력층, 복수의 컨볼루션 레이어, 완전 연결된 레이어 및 출력층을 포함할 수 있다. 일 실시예에 따른, 프레임 보간 모델은 영상의 시간(또는, 시간 축)을 고려한 유사도를 이용한 알고리즘을 통해 획득된 데이터 세트에 기초하여 학습될 수 있다. 한편, 영상의 움직임 벡터를 이용한 알고리즘을 통해 획득된 데이터 세트에 기초하여 프레임 보간 모델이 학습되는 경우, 압축/복원(또는, 부호화/복호화)을 통해 손상된 영 상에 대해 손상된 움직임 벡터를 획득하기 때문에, 프레임 보간이 어려울 수 있다. 그러나, 영상의 시간 축을 고려한 유사도를 이용한 알고리즘을 통해 획득된 데이터 세트에 기초하여 프레임 보간 모델이 학습되는 경우, 이러한 문제가 해소될 수 있다. 한편, 프레임 보간 모델을 학습하기 위한 데이터 세트는, 압축/복원(또는, 부호화/복호화)에 의한 열화가 발생 되지 않은 데이터 세트뿐만 아니라, 압축/복원(또는, 부호화/복호화)에 의한 열화가 발생된 데이터 세트도 포함 한다. 이를 통해, 열화가 발생된 영상에 대하여도 프레임 보간 모델이 학습될 수 있다. 동작 12040에서, 프레임 보간 처리 모듈은 제1 프레임이 보간된 프레임 세트를 출력할 수 있다. 예 를 들면, 프레임 보간 처리 모듈은 제1 프레임이 보간된 프레임 세트를 품질 향상 처리 모듈(102 0)로 전달할 수 있다. 동작 12050에서, 해당 프레임 세트에 대한 프레임 보간이 적용하지 않음이 결정된 경우, 프레임 보간 처리 모듈 은 제1 프레임이 보간되지 않은 프레임 세트를 출력할 수 있다. 도 14는 본 개시의 일 실시예에 따른, 품질 향상 처리를 위한 모델의 일 예를 나타낸다. 이하에서 설명할 품질 향상 처리 모듈의 동작은, 영상 수신 장치 또는 영상 수신 장치의 적어 도 하나의 프로세서에 의해 제어 또는 수행되는 것으로 이해될 수 있다. 도 14를 참조하면, 품질 향상 처리 모듈은, 보간된 영상 데이터(예: 도 11의 프레임들 (1101,1102,1103)을 포함하는 영상 데이터)를 입력 데이터로서 모델에 입력하고, 품질(또는, 화질) 향상 된 영상 데이터(예: 도 11의 프레임들(1121,1122,1123)을 포함하는 영상 데이터)를 출력 데이터로서 획득 할 수 있다. 본 개시에서, 모델은 품질 향상 모델로 지칭될 수 있다. 일 실시예에 따른, 품질 향상 모델은 복수의 인공 신경망 레이어를 포함하는 인공지능 모델일 수 있다. 인공 신 경망은, 예컨대, DNN, CNN, RNN, RBM, DBN, BRDNN, 심층 Q-네트워크 또는 상기 중 둘 이상의 조합 중 하나일 수 있으나, 전술한 예에 한정되지 않는다. 일 실시예에 따른, 품질 향상 모델은 입력층, 은닉층(들) 및 출력층을 포함할 수 있다. 일 실시예에 따른, 품질 향상 모델은 입력층, 복수의 컨볼루션 레이어, 완전 연결된 레이어 및 출력층을 포함할 수 있다. 일 실시예에 따른, 품질 향상 모델은 영상의 시간(또는, 시간 축)을 고려한 품질 향상을 위한 알고리즘을 통해 획득된 데이터 세트에 기초하여 학습될 수 있다. 한편, 품질 향상 처리는 압축/복원(또는, 부호화/복호화) 처리 뿐만 아니라, 프레임 보간 처리 이후에 수행되므 로, 품질 향상 모델을 학습하기 위한 데이터 세트는, 압축/복원(또는, 부호화/복호화)에 의한 열화가 발생된 데 이터 세트 뿐만 아니라, 프레임 보간에 의해 열화가 발생된 데이터 세트도 포함한다. 즉, 품질 향상 모델은 프 레임 보간과 품질 향상을 동시에 진행하는 전체 네트워크를 end-to-end 방식으로 학습될 수 있다. 도 15는 본 개시의 일 실시예에 따른, 영상 송신 장치의 영상 처리 방법의 흐름도이다. 도 15를 참조하면, 영상 송신 장치(예: 도 1a/b/c의 영상 송신 장치)은 복수의 이미지 프레임을 포함하는 이미지 데이터를 획득할 수 있다. 영상 송신 장치는 인공지능 모델(또는, 프레임 생략 알고리즘)을 이용하여, 복수의 이미지 프레임에 포함되는 제1 이미지 프레임에 대한 프레임 스킵핑을 적용할지 여부를 결정할 수 있다. 영상 송신 장치는 제1 이미지 프레임에 대한 프레임 스킵핑을 적용함이 결정되는 경우, 제1 이미지 프레임을 스 킵하고, 압축된 이미지 데이터를 생성하기 위하여 제1 이미지 프레임이 스킵된 이미지 데이터를 부호화할 수 있 다. 영상 송신 장치는 제1 이미지 프레임에 대한 프레임 스킵핑을 적용함이 결정되지 않는 경우, 영상 송신 장치는 압축된 이미지 데이터를 생성하기 위하여 제1 이미지 프레임을 포함하는 이미지 데이터를 부호화할 수 있다 . 영상 송신 장치는 압축된 이미지 데이터 및/또는 프레임 스킵핑에 관련된 정보를 전송할 수 있다. 일 실시예에 따른, 영상 송신 장치는 이미지 데이터의 부호화를 위한 파라미터에 기초하여, 복수의 인공지능 모 델로부터 인공지능 모델을 선택할 수 있다. 일 실시예에 따른, 영상 송신 장치는 제1 이미지 프레임이 스킵된 이미지 데이터를 부호화하기 위해, 부호화를 위한 파라미터를 이용하여, 제1 이미지 프레임이 스킵된 이미지 데이터를 부호화할 수 있다. 일 실시예에 따른, 부호화를 위한 파라미터(예: 양자화 파라미터(QP))는 이미지 데이터의 압축 률과 연관될 수 있다. 일 실시예에 따른, 인공지능 모델은 동일한 비트 율에서의 제1 왜곡 및 제2 왜곡의 차이와 연관되는 거리를 출 력하도록 설정되며, 제1 왜곡은 제1 이미지 프레임에 대한 프레임 스킵핑이 적용된 제1 이미지 프레임 세트와 연관되며, 제2 왜곡은 제1 이미지 프레임에 대한 프레임 스킵핑이 적용되지 않은 제2 이미지 프레임 세트와 연 관될 수 있다. 일 실시예에 따른, 제1 이미지 프레임 세트는 제1 이미지 프레임의 이전 프레임인 제2 이미지 프레임 및 제1 이 미지 프레임의 이후 이미지 프레임인 제3 이미지 프레임을 포함하며, 제2 이미지 프레임 세트는 제1 이미지 프 레임, 제2 이미지 프레임 및 상기 제3 이미지 프레임을 포함할 수 있다. 일 실시예에 따른, 영상 송신 장치는 제1 이미지 프레임에 대한 프레임 스킵핑을 적용할지 여부를 결정하기 위 해, 제1 이미지 프레임, 제1 이미지 프레임의 이전 프레임인 제2 이미지 프레임 및 제1 이미지 프레임의 이후 이미지 프레임인 제3 이미지 프레임을 부호화 및 복호화하고, 부호화 및 복호화된 제1 이미지 프레임, 부호화 및 복호화된 제2 이미지 프레임 및 부호화 및 복호화된 제3 이미지 프레임을 입력 데이터로서 상기 인공지능 모 델에 입력하고, 인공지능 모델의 출력 데이터로서 거리를 획득하고, 거리에 기초하여, 제1 이미지 프레임에 대 한 프레임 스킵핑을 적용할지 여부를 결정할 수 있다. 일 실시예에 따른, 영상 송신 장치는 제1 이미지 프레임에 대한 프레임 스킵핑을 적용할지 여부를 결정하기 위 해, 제1 이미지 프레임, 제1 이미지 프레임의 이전 프레임인 제2 이미지 프레임 및 제1 이미지 프레임의 이후 이미지 프레임인 제3 이미지 프레임을 입력 데이터로서 상기 인공지능 모델에 입력하고, 인공지능 모델의 출력 데이터로서 거리를 획득하고, 거리에 기초하여 제1 이미지 프레임에 대한 프레임 스킵핑을 적용할지 여부를 결 정할 수 있다. 일 실시예에 따른, 거리는 제1 왜곡에서 제2 왜곡을 뺀 값에 대응할 수 있다. 일 실시예에 따른, 거리에 기초하여 제1 이미지 프레임에 대한 프레임 스킵핑을 적용할지 여부를 결정하기 위해, 영상 송신 장치는 거리가 음수인 경우, 제1 이미지 프레임에 대한 프레임 스킵핑을 적용함을 결정하고, 거리가 양수인 경우, 제1 이미지 프레임에 대한 프레임 스킵핑을 적용하지 않음을 결정할 수 있다. 일 실시예에 따른, 인공지능 모델은 복수의 학습 데이터 세트에 기초하여 학습되고, 복수의 학습 데이터 세트의 각각은, 이미지 프레임 세트를 획득하는 동작, 이미지 프레임 세트를 상기 부호화를 위한 파라미터의 설정 가능 한 값들의 각각에 대하여 제1 영상 처리하여 제1 율 왜곡 데이터를 획득하는 동작, 프레임 스킵핑이 적용된 이 미지 프레임 세트를 부호화를 위한 타겟 파라미터의 값에 대하여 제2 영상 처리하여 제2 율 왜곡 데이터를 획득 하는 동작, 및 제1 율 왜곡 데이터 및 상기 제2 율 왜곡 데이터에 기초하여 거리를 획득하는 동작의 수행에 기 초하여 획득될 수 있다. 일 실시예에 따른, 제1 영상 처리는, 부호화 처리, 및 복호화 처리를 포함하고, 제2 영상 처리는, 부호화 처리, 복호화 처리, 프레임 보간 처리 및 품질 향상 처리를 포함할 수 있다. 도 16은 본 개시의 일 실시예에 따른, 영상 수신 장치의 영상 처리 방법의 흐름도이다. 도 16을 참조하면, 영상 수신 장치(예: 도 1a/b의 영상 수신 장치)는 복호화된 복수의 이미지 프레임을 포 함하는 이미지 데이터를 획득할 수 있다. 영상 수신 장치는 프레임 스킵핑에 관련된 정보에 기초하여, 복수의 이미지 프레임에 대한 프레임 보간을 적용 할지 여부를 결정할 수 있다. 영상 수신 장치는 복수의 이미지 프레임에 대한 프레임 보간을 적용함이 결정되는 경우, 복수의 이미지 프레임 을 기초로 제1 인공지능 모델을 이용하여 제1 이미지 프레임이 보간된 이미지 데이터를 획득할 수 있다. 영상 수신 장치는 복수의 이미지 프레임에 대한 프레임 보간을 적용하지 않음이 결정되는 경우, 제1 이미지 프 레임이 보간되지 않은 이미지 데이터를 식별할 수 있다. 일 실시예에 따른, 영상 수신 장치는 제1 이미지 프레임이 보간된 이미지 데이터를 기초로 제2 인공지능 모델을 이용하여 향상된 이미지 데이터를 획득할 수 있다. 일 실시예에 따른, 프레임 스킵핑에 관련된 정보는, 제1 이미지 프레임에 대한 프레임 스킵핑이 적용됨을 지시 하는 제1 값 또는 제1 이미지 프레임에 대한 프레임 스킵핑이 적용되지 않음을 지시하는 제2 값 중 하나로 설정 될 수 있다. 일 실시예에 따른, 영상 수신 장치는 프레임 보간을 적용할지 여부를 결정하기 위하여, 프레임 스킵핑에 관련된 정보가 상기 제1 값으로 설정된 경우, 복수의 이미지 프레임에 대한 프레임 보간을 적용함을 결정하고, 프레임 스킵핑에 관련된 정보가 상기 제2 값으로 설정된 경우, 복수의 이미지 프레임에 대한 프레임 보간을 적용하지 않음을 결정할 수 있다. 일 실시예에 따른, 복수의 이미지 프레임은 제1 이미지 프레임의 이전 이미지 프레임인 제2 이미지 프레임 및 제1 이미지 프레임의 이후 이미지 프레임인 제3 이미지 프레임을 포함할 수 있다. 일 실시예에 따른, 제1 인공지능 모델을 이용하여 제1 이미지 프레임이 보간된 이미지 데이터를 획득하기 위하 여, 영상 수신 장치는 제2 이미지 프레임 및 제3 이미지 프레임을 입력 데이터로서, 제1 인공지능 모델에 입력 하고, 제1 인공지능 모델로부터 출력 데이터로서, 제1 프레임이 보간된 이미지 데이터를 획득할 수 있다. 일 실시예에 따른, 제1 인공지능 모델은, 영상의 시간 축을 고려한 유사도를 이용한 알고리즘을 통해 획득된 데 이터 세트에 기초하여 학습될 수 있다. 이하에서는 원본 영상의 사이즈 및/또는 품질을 감소시키기 위한 기술(예: 다운 스케일 기술(또는, 다운 샘플링 기술)일 수 있으나, 이에 제한되지 않음)과 이로 인하여 발생하는 손실을 레이턴트 벡터로 압축하여 표현하는 레이턴트 벡터 기술을 이용하는 전처리 방법과 해상도 향상을 위한 기술(예: 슈퍼 레졸루션 기술일 수 있으나, 이에 제한되지 않음)을 이용하는 후처리 방법에 대하여 설명한다. 일 실시예에 따른, 영상 송신 장치는 다운 샘플링 기술을 이용하여 원본 영상(예: 고화질 영상)을 다운 샘플링 하여, 영상의 사이즈 및/또는 품질을 감소시킬 수 있다. 이후, 영상 송신 장치는 다운 샘플링된 영상(예: 저화 질 영상)을 압축함으로써, 압축 용량이 감소될 수 있다. 일 실시예에 따른, 영상 송신 장치는 레이턴트 벡터 기술을 이용하여 다운 샘플링으로 인하여 발생되는 원본 영 상에서의 손실에 대한 정보(손실 정보)를 레이턴트 벡터로 압축할 수 있다. 실시예로서, 레이턴트 벡터 기술은 인공지능 모델(예: 딥러닝 기반의 인공지능 모델)에 의해 구현될 수 있다. 이렇게 손실 정보를 압축한 레이턴트 벡터는 영상과 함께 압축되어 영상 수신 장치로 전달되며, 영상 수신 장치에서 다운 샘플링된 영상에 대한 해상 도를 높여주기 위해 사용될 수 있다. 이처럼, 예컨대, 고화질의 원본 영상을 그대로 압축하여 전송하는 것에 비 해, 다운 샘플링된 저화질의 영상과 손실 정보를 제공하는 레이턴트 벡터를 이용하여 압축하여 전송하는 경우, 압축 용량 및 화질(품질) 면에서 더 효과적일 수 있다. 일 실시예에 따른, 영상 수신 장치는 다운 스케일링된 영상과 손실 정보를 제공하는 레이턴트 벡터를 기초로, 슈퍼 레졸루션 기술을 이용하여 영상을 복원할 수 있다. 실시예로서, 슈퍼 레졸루션 기술은 인공지능 모델(예: 딥러닝 기반의 인공지능 모델)에 의해 구현될 수 있다. 이렇게 복원된 영상은 원본 영상과 실질적으로 동일한 품질을 가지거나, 또는 경우에 따라서는 원본 영상에 비해 더 높은 품질을 가질 수도 있다. 이하에서는 각 도면을 참조하여, 상술한 다운 스케일 기술과 레이턴트 벡터 기술을 이용하는 전처리 방법과 해 상도 향상을 위한 슈퍼 레졸루션 기술을 이용하는 후처리 방법을 예시적으로 설명한다. 도 17은 본 개시의 일 실시예에 따른, 전처리부의 다운 샘플링 처리 모듈 및 레이턴트 벡터 생성 처리 모듈을 나타낸다. 도 18은 본 개시의 일 실시예에 따른, 다운 샘플링 처리 모듈 및 레이턴트 벡터 생성 처리 모듈의 동 작을 개략적으로 설명한다. 도 19는 본 개시의 일 실시예에 따른, 레이턴트 벡터 생성 방법의 흐름도이다. 도 20은 본 개시의 일 실시예에 따른, 레이턴트 벡터 생성 처리를 위한 모델의 일 예를 나타낸다. 도 17을 참조하면, 전처리부는 영상을 다운 스케일 처리(또는, 다운 샘플링 처리)하기 위한 다운 샘플링 처리 모듈 및 영상의 손실 정보를 제공하는 레이턴트 벡터를 생성하기 위한 레이턴트 벡터 생성 처리 모 듈을 포함할 수 있다. 본 개시에서, 다운 샘플링 처리 모듈 및 레이턴트 벡터 생성 처리 모듈 의 동작은, 영상 송신 장치 또는 영상 송신 장치의 적어도 하나의 프로세서에 의해 제어 또는 수행되는 것으로 이해될 수 있다. 한편, 실시예에 따라, 레이턴트 벡터 생성 처리 모듈은 도 1b의 전처리 부 또는 도 1c의 전처리부(112a)에 포함되지 않고, 도 1c의 레이턴트 벡터 처리부(115a)에 포함될 수도 있 다. 일 실시예에 따른, 다운 샘플링 처리 모듈은 적어도 하나의 프레임을 포함하는 이미지 데이터를 다운 샘 플링하여, 다운 샘플링된 이미지 데이터를 생성할 수 있다. 예를 들면, 도 18에 예시된 것처럼, 다운 샘플링 처 리 모듈은 적어도 하나의 원본 프레임을 포함하는 원본 이미지 데이터를 다운 샘플링하여, 다운 샘 플링된 이미지 데이터를 생성할 수 있다. 다운 샘플링된 이미지 데이터는 적어도 하나의 다운 샘플 링된 프레임을 포함할 수 있고, 각 다운 샘플링된 프레임은 해당 원본 프레임에 비해, 사이즈, 화질, 및/또는 해상도가 감소된 프레임일 수 있다. 예를 들면, 다운 샘플링된 프레임은 원본 프레임에 비해 1/4 사이즈로 감소 된 프레임일 수 있다. 일 실시예에 따른, 다운 샘플링 처리 모듈은 프레임 선별 기술을 이용하여 원본 이미지 데이터에서 중요 정보(예: 원본 이미지 데이터의 1/4의 정보)를 추출하고, 추출된 중요 정보를 이용하여 다운 샘플링된 이미지데이터를 획득할 수 있다. 예를 들면, 다운 샘플링 처리 모듈은 추출된 중요 정보를 제외한 정보를 제거 함으로써, 다운 샘플링된 이미지 데이터(예: 원본 이미지 데이터의 1/4 사이즈의 이미지 데이터)를 획득할 수 있다. 일 실시예에 따른, 다운 샘플링 처리 모듈은 다운 샘플링된 이미지 데이터를 부호화부(예: 도 1b의 부호 화부 또는 도 1c의 코덱 처리부(113a))로 전달할 수 있고, 부호화부는 다운 샘플링된 이미지 데이터를 부 호화할 수 있다. 부호화된 이미지 데이터는 영상 수신 장치(예: 도 1b 및 1c의 영상 수신 장치)로 전송될 수 있다. 이러한 다운 샘플링을 통해, 압축 용량이 감소될 수 있고, 전송 트래픽이 절약될 수 있다. 한편, 다운 샘플링에 의해 발생되는 손실에 대한 정보(손실 정보)는 이후 설명할 레이턴트 벡터를 통해 영상 수신 장치로 전달될 수 있고, 영상 수신 장치는 레이턴트 벡터를 이용하여 다운 샘플링된 이미지의 품질을 향상시킬 수 있다. 일 실시예에 따른, 레이턴트 벡터 생성 처리 모듈은 원본 이미지 데이터 및 다운 샘플링된 이미지 데이터 에 기초하여, 레이턴트 벡터 데이터를 생성할 수 있다. 예를 들면, 도 18에 예시된 것처럼, 레이턴트 벡터 생성 처리 모듈은 적어도 하나의 원본 프레임을 포함 하는 원본 이미지 데이터 및 적어도 하나의 다운 샘플링된 프레임을 포함하는 다운 샘플링된 이미지 데이 터에 기초하여, 레이턴트 벡터 데이터를 생성할 수 있다. 일 실시예에 따른, 레이턴트 벡터 데이터 는 다운 샘플링에 의해 생기는 손실에 대한 정보(손실 정보)를 제공할 수 있다. 예를 들면, 도 39a에 예시된 것처럼, 레이턴트 벡터 생성 처리 모듈은 적어도 하나의 원본 프레임을 포함 하는 원본 이미지 데이터 및 적어도 하나의 다운 샘플링된 프레임을 포함하는 다운 샘플링된 이미지 데 이터에 대한 코덱 처리부(예: 도 1c의 코덱 처리부(113a))의 부호화 및 복호화 처리를 통해 생성 된 압축 열화가 발생된 이미지 데이터에 기초하여, 레이턴트 벡터 데이터를 생성할 수 있다. 일 실시예에 따른, 레이턴트 벡터 생성 처리 모듈은 프레임 별로 하나의 레이턴트 벡터를 생성할 수 있으 나, 이에 제한되지 않는다. 예를 들면, 복수의 프레임에 대하여 하나의 레이턴트 벡터가 생성될 수도 있고, 하 나의 프레임에 대해 복수의 레이턴트 벡터가 생성될 수도 있다. 일 실시예에 따른, 레이턴트 벡터 생성 처리 모듈은 미리 학습된 AI 모델을 이용하여, 레이턴트 벡터 데 이터를 생성할 수 있다. 예를 들면, 레이턴트 벡터 생성 처리 모듈은 적어도 하나의 원본 프레임을 포함 하는 원본 이미지 데이터 및 적어도 하나의 다운 샘플링된 프레임을 포함하는 다운 샘플링된 이미지 데이 터에 기초로, 미리 학습된 AI 모델을 이용하여, 레이턴트 벡터 데이터를 생성할 수 있다. 본 개시 에서, 레이턴트 벡터를 생성하기 위해 사용되는 AI 모델은 레이턴트 벡터 생성 모델 또는 레이턴트 인코더 모델 로 지칭될 수 있다. 일 실시예에 따른, 레이턴트 벡터 생성 모델은 복수의 인공 신경망 레이어를 포함하는 인공지능 모델일 수 있다. 인공 신경망은, 예컨대, DNN, CNN, RNN, RBM, DBN, BRDNN, 심층 Q-네트워크 또는 상기 중 둘 이상의 조 합 중 하나일 수 있으나, 전술한 예에 한정되지 않는다. 일 실시예에 따른, 레이턴트 벡터 생성 모델은 입력층, 은닉층(들) 및 출력층을 포함할 수 있다. 일 실시예에 따른, 레이턴트 벡터 생성 모델은 입력층, 복수의 컨볼루션 레이어, 완전 연결된 레이어 및 출력층을 포함할 수 있다. 한편, 레이턴트 벡터 생성 모델은 미리 획득된 데이터 세트에 기초하여 학습될 수 있다. 이하, 도 19를 참조하여, 레이턴트 벡터 생성 처리 모듈의 레이턴트 벡터 생성 방법의 예시적인 동작들을 설명한다. 한편, 이하에서 설명할 레이턴트 벡터 생성 처리 모듈의 동작은, 영상 송신 장치 또는 영 상 송신 장치의 적어도 하나의 프로세서에 의해 제어 또는 수행되는 것으로 이해될 수 있다. 본 개시에서, \"다운 샘플링된 이미지 데이터\"로 표현되는 이미지 데이터는 예컨대, 다운 샘플링 처리 모듈에 의해 생성 된 이미지 데이터(예: 도 18의 이미지 데이터 또는 도 39a의 이미지 데이터) 자체이거나, 다운 샘플링 처리 모듈에 의해 생성된 이미지 데이터(예: 도 39a의 이미지 데이터)를 부호화 및 복호화 처리하 여 획득된 이미지 데이터(예: 도 39a의 이미지 데이터))일 수 있다. 도 19를 참조하면, 동작 19010에서, 레이턴트 벡터 생성 처리 모듈은 다운 샘플링된 이미지 데이터(예: 도 18의 이미지 데이터 또는 도 39a의 이미지 데이터))를 획득할 수 있다. 예를 들면, 도 18에 예 시된 것처럼, 레이턴트 벡터 생성 처리 모듈은 복수의 다운 샘플링된 프레임(예: 3개 또는 4개)을 포함하는 다운 샘플링된 이미지 데이터를 획득할 수 있다. 동작 19020에서, 레이턴트 벡터 생성 처리 모듈은 다운 샘플링된 이미지 데이터에 대한 해상도 보간을 수 행하여, 해상도 보간된 이미지 데이터(예: 도 20의 이미지 데이터 또는 도 39a의 이미지 데이터) 를 획득할 수 있다. 예를 들면, 도 20에 예시된 것처럼, 레이턴트 벡터 생성 처리 모듈은 복수의 다운 샘 플링된 프레임을 포함하는 다운 샘플링된 이미지 데이터에 대한 해상도 보간을 수행하여, 복수의 해상도 보간된 프레임을 포함하는 해상도 보간된 이미지 데이터를 생성할 수 있다. 해상도 보간된 프레임은, 원 본 프레임과 동일한 사이즈를 갖는다. 일 실시예에 따른, 레이턴트 벡터 생성 처리 모듈은 미리 설정된 보간 방식(예: bicubic interpolation) 을 이용하여, 다운 샘플링된 이미지 데이터에 대한 해상도 보간을 수행할 수 있다. 동작 19030에서, 레이턴트 벡터 생성 처리 모듈은 원본 이미지 데이터(예: 도 20의 이미지 데이터 또는 도 39a의 이미지 데이터)와 해상도 보간된 이미지 데이터에 기초하여 손실 데이터를 획득할 수 있 다. 예를 들면, 도 20에 예시된 것처럼, 레이턴트 벡터 생성 처리 모듈은 복수의 원본 프레임을 포함하는 원본 이미지 데이터와 복수의 해상도 보간된 프레임을 포함하는 해상도 보간된 이미지 데이터의 차 이에 기초하여, 손실 데이터를 획득할 수 있다. 일 실시예에 따른, 레이턴트 벡터 생성 처리 모듈은 원본 프레임(예: 제1 프레임)과 이에 대응하는 해상 도 보간된 프레임(예: 제1 프레임을 다운 샘플링하고, 해상도 보간하여 획득된 프레임)으로 구성된 프레임 쌍에 대한, 미리 설정된 단위(예: 화소(pixel) 단위)의 차이를 계산하여, 해당 프레임 쌍에 대한 손실 데이터를 획득 할 수 있다. 이러한, 화소 단위의 차이 계산은 각 프레임 쌍에 대하여 각각 수행될 수 있다. 이러한 방식을 통 해 획득된 전체 손실 데이터는 각 프레임 쌍에 대한 손실 데이터를 포함할 수 있다. 동작 19040에서, 레이턴트 벡터 생성 처리 모듈은 손실 데이터를 기초로, 미리 학습된 모델(예: 도 20의 모델 또는 도 39a의 모델)을 이용하여, 레이턴트 벡터 데이터(예: 도 20의 레이턴트 벡터 데이터 , 또는 도 39a의 레이턴트 벡터 데이터)를 생성할 수 있다. 예를 들면, 도 20에 예시된 것처럼, 레이턴트 벡터 생성 처리 모듈은 복수의 프레임 쌍에 대한 손실 데이터를 레이턴트 벡터 생성 모델 (또는, 레이턴트 벡터 생성 모델을 포함하는 레이턴트 인코더)로 입력할 수 있다. 레이턴트 벡터 생성 처리 모듈은 레이턴트 벡터 생성 모델로부터 출력된 레이턴트 벡터 데이터를 획득할 수 있다. 이를 통해, 각 프레임 쌍에 대한 화소 단위의 차이에 대한 정보(손실 정보)가 레이턴트 벡터로 압축될 수 있다. 이렇게 획득된 레이턴트 벡터 데이터는 각 프레임 쌍에 대한 화소 단위의 차이에 대한 정보(손실 정보)의 압축 정보를 포함할 수 있다. 이처럼 레이턴트 벡터 데이터는 손실 정보 자체가 아닌 손실 정보의 압축 정보를 포함하기 때문에, 손실 정보에 비해 작은 데이터 사이즈를 갖게 된다. 이는 압축 용량을 감소시킬 수 있다. 또 한, 레이턴트 벡터 데이터는 손실 정보를 포함하기 때문에, 레이턴트 벡터 데이터는 다운 샘플링으로 인해 손실 된 정보를 복원하기 위해 영상 수신 장치에서 사용될 수 있다. 동작 19050에서, 레이턴트 벡터 생성 처리 모듈은 생성된 레이턴트 벡터 데이터를 부호화부로 전달할 수 있다. 부호화부로 전달된 레이턴트 벡터 데이터는 다운 샘플링된 영상 데이터와 함께 부호화(또는, 압축)되어, 영상 수신 장치로 전송될 수 있다. 실시예로서, 부호화된 영상 데이터를 포함하는 비트스트림에 부호화된 레이 턴트 벡터 데이터가 추가될 수 있다. 예를 들면, 레이턴트 벡터 데이터를 부호화하여 생성된 제1 비트스트림(예 컨대, 레이턴트 벡터 데이터를 양자화하고, 엔트로피 코딩을 통해 생성된 제1 비트스트림)은, 영상 데이터를 부 호화하여 생성된 제2 비트스트림 내의 일부 영역에 포함될 수 있다. 예컨대, 레이턴트 벡터 데이터를 부호화하 여 생성된 제1 비트스트림은, 영상 데이터를 부호화하여 생성된 제2 비트스트림 내의 디스크립션(description) 영역에 포함될 수 있으나, 이에 제한되지 않는다. 디스크립션 영역은, 예컨대, 해당 비트스트림에 대한 정보와 구조를 설명하기 위한 영역일 수 있다. 한편, 실시예에 따라서, 동작 19050은 생략될 수 있다. 예를 들면, 레이 턴트 벡터 생성 처리 모듈이 도 1c의 레이턴트 벡터 처리부(115a)에 포함되는 경우, 레이턴트 벡터 생성 처리 모듈에 의해 생성된 레이턴트 벡터는 부호화부(예: 도 1c의 코덱 처리부(113a))에 의해 부호화되지 않고, 직접 영상 출력부(예: 도 1c의 영상 출력부(114a))로 전달될 수 있다. 도 21은 본 개시의 일 실시예에 따른, 후처리부의 슈퍼 레졸루션 처리 모듈을 나타낸다. 도 22a는 본 개시의 일 실시예에 따른, 슈퍼 레졸루션 처리 모듈의 동작을 설명한다. 도 22b는 본 개시의 일 실시예에 따른, 슈퍼 레졸 루션 처리를 위한 모델의 일 예를 나타낸다. 도 21을 참조하면, 후처리부는 해상도 향상 처리를 위한 슈퍼 레졸루션 처리 모듈을 포함할 수 있다. 일 실시예에 따른, 슈퍼 레졸루션 처리 모듈은 복호화된 영상 신호에 대한 품질 향상(예: 해상도 향상)을 위한 처리를 수행할 수 있다. 도 22a를 참조하면, 동작 22010에서, 슈퍼 레졸루션 처리 모듈은 복호화된 이미지 데이터 및 레이턴트 벡 터 데이터(예: 도 1b의 복호화부에 의해 복호화된 레이턴트 백터 데이터 또는 도 1c의 영상 입력부(121a) 에 의해 전달된 레이턴트 벡터 데이터)를 획득할 수 있다. 일 실시예에 따르면, 도 23에 예시된 것처럼, 복호화부(예: 도 1b의 복호화부)는 수신된 이미지 데이터 및 레이턴트 벡터 데이터를 복호화하고, 복호화된 이미지 데이터(예: 도 23의 이미지 데이터) 및 복호화된 레이턴트 벡터 데이터(예: 도 23의 레이턴트 벡터 데이터)를 슈퍼 레졸루션 처리 모듈로 전달할 수 있다. 이 경우, 슈퍼 레졸루션 처리 모듈은 복호화부로부터 전달된 복호화된 이미지 데이터 및 복호 화된 레이턴트 벡터 데이터를 획득할 수 있다. 일 실시예에 따른, 도 39a에 예시된 것처럼, 복호화부(예: 도 1c의 코덱 처리부(122a))는 수신된 이미지 데이터 를 복호화하고, 복호화된 이미지 데이터(예: 도 39a의 이미지 데이터)를 슈퍼 레졸루션 처리 모듈(예: 도 39a의 SR 모델)로 전달할 수 있고, 영상 입력부(예: 도 1c의 영상 입력부(121a))는 수신된 레이턴트 벡터 데이터를 슈퍼 레졸루션 처리 모듈(예: 도 39a의 SR 모델)로 전달할 수 있다. 이 경우, 슈퍼 레졸 루션 처리 모듈은 코덱 처리부(122a)로부터 전달된 복호화된 이미지 데이터 및 영상 입력부(121a)로부터 전달된 레이턴트 벡터 데이터를 획득할 수 있다. 동작 22020에서, 슈퍼 레졸루션 처리 모듈은 복호화된 이미지 데이터 및 레이턴트 벡터 데이터(또는, 복 호화된 레이턴트 백터 데이터)를 기초로, 미리 학습된 모델(이하, 슈퍼 레졸루션(SR) 모델)을 이용하여, 해상도 향상된 이미지 데이터를 생성할 수 있다. 예를 들면, 도 22b 및 23에 예시된 것처럼, 슈퍼 레졸루션 처리 모듈은, 복호화된 이미지 데이터 및 복호화된 레이턴트 벡터 데이터를 입력 데이터로서 모델에 입력하고, 향상된(enhanced) 이미지 데이터를 출력 데이터로서 획득할 수 있다. 예를 들면, 도 39a에 예시된 것처럼, 슈퍼 레졸루션 처리 모듈은, 복호화된 이미지 데이터 및 (복호화 처리되지 않은) 레이턴트 벡터 데이터를 입력 데이터로서 모델에 입력하고, 향상된 이미지 데이 터를 출력 데이터로서 획득할 수 있다. 일 실시예에 따른, 슈퍼 레졸루션 모델은 비전 트랜스포머 기반의 인코더와 디코더로 구성될 수 있다. 이 경우, 레이턴트 벡터 데이터는 인코더와 디코더 사이에 작용하여 영상을 복원하기 위한 추가 정보(예: 손실 정보)를 제공할 수 있다. 이를 통해, 복원된 이미지는 원본 이미지와 동일한 크기를 가질 수 있다. 일 실시예에 따른, 슈퍼 레졸루션 모델은 복수의 인공 신경망 레이어를 포함하는 인공지능 모델일 수 있다. 인 공 신경망은, 예컨대, DNN, CNN, RNN, RBM, DBN, BRDNN, 심층 Q-네트워크 또는 상기 중 둘 이상의 조합 중 하 나일 수 있으나, 전술한 예에 한정되지 않는다. 일 실시예에 따른, 슈퍼 레졸루션 모델은 입력층, 은닉층(들) 및 출력층을 포함할 수 있다. 일 실시예에 따른, 슈퍼 레졸루션 모델은 입력층, 복수의 컨볼루션 레이어, 완전 연결된 레이어 및 출력층을 포함할 수 있다. 한편, 슈퍼 레졸루션 처리는 레이턴트 벡터 처리, 압축/복원 처리 이후에 수행되므로, 슈퍼 레졸루션 모델을 학 습하기 위한 데이터 세트는, 레이턴트 벡터 처리에 의해 열화가 발생한 데이터 세트 뿐만 아니라, 압축/복원에 의한 열화가 발생된 데이터 세트도 포함한다. 즉, 슈퍼 레졸루션 모델은 레이턴트 벡터 생성과 압축/복원 처리 를 함께 진행하는 전체 네트워크를 end-to-end 방식으로 학습될 수 있다. 도 23은 본 개시의 일 실시예에 따른, 이미지 처리 절차의 일 예를 나타낸다. 도 23의 이미지 처리 절차는 압축 전 처리를 위한 레이턴트 벡터 기술 및 복원 후 처리를 위한 슈퍼 레졸루션 기술을 이용하는 이미지 처리 절차의 일 예일 수 있다. 예를 들면, 이미지 처리 절차는 레이턴트 벡터 생성 처 리 모듈(예: 도 17의 레이턴트 벡터 생성 처리 모듈), 및 슈퍼 레졸루션 처리 모듈(예: 도 21의 슈퍼 레 졸루션 처리 모듈)을 이용하는 이미지 처리 절차의 일 예일 수 있다. 도 23을 참조하면, 영상 송신 장치(예: 도 1a/b/c의 영상 송신 장치)는 적어도 하나의 원본 프레임을 포함 하는 원본 이미지 데이터를 획득할 수 있다. 일 실시예에 따른, 영상 송신 장치는 원본 이미지 데이터(예컨대, 복수의 프레임(예: 제1 프레임, 제2 프 레임 및 제3 프레임)을 포함하는 원본 이미지 데이터)에 대한 다운 샘플링을 수행하여, 다운 샘플링된 이미지 데이터(예컨대, 복수의 다운 샘플링된 프레임(예: 제1 다운 샘플링된 프레임, 제2 다운 샘플링된 프레임, 제3 다운 샘플링된 프레임)을 포함하는 다운 샘플링된 이미지 데이터)를 획득할 수 있다. 일 실시예에 따른, 영상 송신 장치는 다운 샘플링된 이미지 데이터에 대한 해상도 보간을 수행하여, 해상 도 보간된 이미지 데이터(예컨대, 복수의 해상도 보간된 프레임(예: 제1 해상도 보간된 프레임, 제2 해상 도 보간된 프레임, 제3 해상도 보간된 프레임)을 포함하는 해상도 보간된 이미지 데이터)를 획득할 수 있다. 일 실시예에 따른, 영상 송신 장치는 원본 이미지 데이터와 해상도 보간된 이미지 데이터에 기초하 여, 손실 데이터를 획득할 수 있다. 예를 들면, 영상 송신 장치는 원본 이미지 데이터 내의 원본 프레임 과 해상도 보간된 이미지 데이터 내의 해당 원본 프레임에 대응하는 해상도 보간된 프레임으로 구성된 프 레임 쌍(예: 제1 프레임 및 제1 프레임을 다운 샘플링하고 해상도 보간하여 획득된 제1 해상도 보간된 프레임으 로 구성된 프레임 쌍)에 대한 미리 설정된 단위(예: 화소 단위, 다만, 이에 제한되지는 않음)의 차이를 계산하 여, 해당 프레임 쌍에 대한 손실 데이터를 획득할 수 있다. 이러한 방식으로 전체 프레임 쌍에 대한 손실 데이 터가 획득될 수 있다. 일 실시예에 따른, 영상 송신 장치는 손실 데이터를 레이턴트 벡터 생성 모델(또는, 레이턴트 벡터 생성 모델을 포함하는 레이턴트 인코더)로 입력하고, 레이턴트 벡터 생성 모델(또는, 레이턴트 인코더)로부터 출력된 레이턴트 벡터 데이터를 획득할 수 있다. 일 실시예에 따른, 영상 송신 장치는 다운 샘플링된 이미지 데이터 및 레이턴트 벡터 데이터를 부 호화부로 입력하고, 부호화부로부터 출력된 부호화된 이미지 데이터 및 부호화된 레이턴트 벡터 데이 터를 영상 수신 장치(예: 도 2의 영상 수신 장치)로 전송할 수 있다. 실시예로서, 부호화된 레이턴트 벡터 데이터는 부호화된 이미지 데이터를 포함하는 비트스트림에 추가될 수 있다. 일 실시예에 따른, 영상 수신 장치는 부호화된 이미지 데이터 및 부호화된 레이턴트 벡터 데이터를 수신하고, 복호화부로 전달할 수 있다. 영상 수신 장치는 복호화부로부터 출력된 복호화된 이미지 데이터 및 복호화된 레이턴트 벡터 데이터를 획득할 수 있다. 일 실시예에 따른, 영상 수신 장치는 복호화된 이미지 데이터 및 복호화된 레이턴트 벡터 데이터를 SR 모델에 입력하고, SR 모델로부터 출력된 향상된 이미지 데이터를 획득할 수 있다. 이렇게 획득된 향상된 이미지 데이터에 포함된 프레임들은 원본 이미지 데이터에 포함된 프레임들과 실질 적으로 동일한 품질을 가질 수 있다. 도 24는 본 개시의 일 실시예에 따른, 영상 송신 장치의 영상 처리 방법의 흐름도이다. 도 24를 참조하면, 영상 송신 장치(예: 도 2의 영상 송신 장치)는 이미지 데이터(예: 도 23의 이미지 데이 터 또는 도 39a의 이미지 데이터)를 다운 샘플링하여, 다운 샘플링된 이미지 데이터(예: 도 23의 이미지 데이터 또는 도 39a의 이미지 데이터)를 획득할 수 있다. 영상 송신 장치는 상기 다운 샘플링된 이미지 데이터에 대한 해상도 보간을 수행하여, 해상도 보간된 이미지 데 이터(예: 도 23의 이미지 데이터 또는 도 39a의 이미지 데이터)를 획득할 수 있다. 영상 송신 장치는 상기 이미지 데이터와 상기 해상도 보간된 이미지 데이터에 기초하여, 손실 데이터(예: 도 23 의 손실 데이터 또는 도 39a의 손실 데이터)를 획득할 수 있다. 영상 송신 장치는 상기 손실 데이터를 기초로, 인공지능 모델(예: 도 23의 모델 또는 도 39a의 모델 )을 이용하여, 레이턴트 벡터 데이터(예: 도 23의 레이턴트 벡터 데이터 또는 도 39a의 레이턴트 벡터 데이터)를 생성할 수 있다. 영상 송신 장치는 상기 다운 샘플링된 이미지 데이터 및/또는 상기 레이턴트 벡터 데이터를 부호화할 수 있다 . 예를 들면, 도 23에 예시된 것처럼, 영상 송신 장치는 다운 샘플링된 이미지 데이터 및 레이턴 트 벡터 데이터를 부호화부를 이용하여 부호화할 수 있다. 예를 들면, 도 39a에 예시된 것처럼, 영 상 송신 장치는 다운 샘플링된 이미지 데이터를 부호화부(113a)를 이용하여 부호화하고, 레이턴트 벡터 데이터를 부호화하지 않을 수 있다. 영상 송신 장치는 상기 부호화된 이미지 데이터 및/또는 상기 부호화된 레이턴트 벡터 데이터를 전송할 수 있다 . 예를 들면, 도 23에 예시된 것처럼, 영상 송신 장치는 부호화된 이미지 데이터 및 부호화된 레이턴트벡터 데이터를 영상 수신 장치로 전송할 수 있다. 예를 들면, 도 39a에 예시된 것처럼, 영상 송신 장치는 부호 화된 이미지 데이터 및 (부호화 되지 않은) 레이턴트 벡터 데이터를 영상 수신 장치로 전송할 수 있다. 일 실시예에 따른, 영상 송신 장치는 상기 손실 데이터를 획득하기 위해, 상기 이미지 데이터에 포함되는 제1 프레임과 상기 해상도 보간된 이미지 데이터에 포함되는 상기 제1 프레임에 대응하는 제2 프레임으로 구성된 프 레임 쌍에 대한 미리 설정된 단위의 차이를 계산함으로써 상기 손실 데이터를 획득할 수 있다. 일 실시예에 따른, 상기 미리 설정된 단위는 화소 단위에 해당할 수 있다. 일 실시예에 따른, 영상 송신 장치는 상기 해상도 보간된 이미지 데이터를 획득하기 위해, 바이큐빅 보간 (bicubic interpolation) 방식을 이용하여, 상기 다운 샘플링된 이미지 데이터에 대한 해상도 보간을 수행하여, 해상도 보간된 이미지 데이터를 획득하는 동작을 포함할 수 있다. 일 실시예에 따른, 영상 송신 장치는 표준화된 코덱 기술을 이용하여, 상기 다운 샘플링된 이미지 데이터 및 상 기 레이턴트 벡터 데이터를 부호화함으로써, 부호화된 이미지 데이터 및 부호화된 레이턴트 벡터 데이터를 포함 하는 비트스트림을 생성할 수 있다. 일 실시예에 따른, 영상 송신 장치는 상기 부호화된 이미지 데이터 및 상기 부호화된 레이턴트 벡터 데이터를 포함하는 상기 비트스트림을 전송하는 동작을 포함할 수 있다. 도 25는 본 개시의 일 실시예에 따른, 영상 수신 장치의 영상 처리 방법의 흐름도이다. 도 25를 참조하면, 영상 수신 장치(예: 도 2의 영상 수신 장치)는 부호화된 이미지 데이터 및 레이턴트 벡 터 데이터(예: 도 23의 부호화된 레이턴트 벡터 데이터 또는 도 39a의 (부호화 되지 않은) 레이턴트 벡터 데이 터)를 수신할 수 있다. 영상 수신 장치는 상기 부호화된 이미지 데이터 및/또는 상기 부호화된 레이턴트 벡터 데이터를 복호화할 수 있 다. 예를 들면, 도 23에 예시된 것처럼, 영상 수신 장치는 부호화된 이미지 데이터 및 부호화된 레이턴 트 벡터 데이터를 복호화부를 이용하여 복호화할 수 있다. 예를 들면, 도 39a에 예시된 것처럼, 영상 수신 장치는 부호화된 이미지 데이터를 복호화부(122a)를 이용하여 복호화하고, 레이턴트 벡터 데이터를 복호화하지 않고 SR 모델로 전달할 수 있다. 영상 수신 장치는 상기 복호화된 이미지 데이터 및 상기 레이턴트 벡터 데이터(예: 도 23의 복호화된 레이턴트 벡터 데이터 또는 도 39a의 레이턴트 벡터 데이터)를 기초로, 인공지능 모델(예: 도 23의 모델 또는 도 39a의 모델)을 이용하여, 해상도가 향상된 이미지 데이터(예: 도 23의 이미지 데이터 또는 도 39a의 이미지 데이터)를 생성할 수 있다. 일 실시예에 따른, 상기 레이턴트 벡터 데이터는 복호화된 이미지 데이터의 복원을 위해 사용되는 손실 데이터 에 기초하여 생성되고, 영상 수신 장치는 상기 손실 데이터는 연관되는 프레임 쌍에 대한 미리 설정된 단위의 차이를 계산함으로써 획득할 수 있다. 일 실시예에 따른, 상기 미리 설정된 단위는 화소 단위에 해당할 수 있다. 일 실시예에 따른, 상기 인공지능 모델은 비전 트랜스포머 기반의 인코더와 디코더로 구성될 수 있다. 일 실시예에 따른, 영상 수신 장치는 상기 부호화된 이미지 데이터 및 상기 부호화된 레이턴트 벡터 데이터를 포함하는 비트스트림을 수신할 수 있다. 일 실시예에 따른, 영상 수신 장치는 표준화된 코덱 기술을 이용하여, 상기 부호화된 이미지 데이터 및 상기 부 호화된 레이턴트 벡터 데이터를 복호화할 수 있다. 한편, 도 3 내지 16에서 상술한 실시예(프레임 생략/프레임 보간/품질 향상 기술 관련 실시예(제1 실시예))와 도 17 내지 25에서 상술한 실시예(다운 샘플링/레이턴트 벡터/SR 기술 관련 실시예(제2 실시예))는 모순이 되지 않는 범위 내에서 서로 조합될 수 있다. 예를 들면, 압축(부호화) 전 전처리를 위해 프레임 생략, 다운 샘플링, 및/또는 레이턴트 벡터 기술이 조합되어 함께 사용될 수 있고, 복원(복호화) 후 후처리를 위해 프레임 보간, 품 질 향상 및 SR 기술이 조합되어 함께 사용될 수 있다. 이하에서는 이러한 조합 실시예의 일 예를 설명한다. 다 만, 이는 예시에 불과하고, 다양한 순서 및 방식으로 해당 기술들이 서로 조합되어 사용될 수 있다. 한편, 도 3 내지 25에서 상술한 내용과 동일한 내용은, 이하 도 26 내지 28에서 참조될 수 있다. 도 26은 본 개시의 일 실시예에 따른, 전처리부의 예시적인 구성을 나타낸다. 도 26을 참조하면, 전처리부(또는, 영상 송신 장치(예: 도 1의 영상 송신 장치)는 프레임 스킵핑 처 리 모듈, 다운 샘플링 처리 모듈 및 레이턴트 벡터 처리 모듈을 포함할 수 있다. 일 실시예에 서, 프레임 스킵핑 처리 모듈의 동작은 다운 샘플링 처리 모듈 및 레이턴트 벡터 처리 모듈의 동작 이전에 수행될 수 있으나, 이에 제한되지 않는다. 프레임 스킵핑 처리 모듈에 대한 설명은 예컨대, 상술한 도 3 내지 16의 설명을 참조할 수 있다. 다운 샘플링 처리 모듈 및 레이턴트 벡터 처리 모듈 에 대한 설명은 예컨대, 상술한 도 17 내지 25의 설명을 참조할 수 있다. 한편, 실시예에 따라서, 레이턴 트 벡터 처리 모듈은 전처리부에 포함되지 않고, 영상 송신 장치의 레이턴트 벡터 처리부(예: 도 1c 의 레이턴트 벡터 처리부(115a))에 포함될 수 있다. 도 27은 본 개시의 일 실시예에 따른, 후처리부의 예시적인 구성을 나타낸다. 도 27을 참조하면, 후처리부은 프레임 보간 처리 모듈, 품질 향상 처리 모듈 및 슈퍼 레졸루 션 처리 모듈을 포함할 수 있다. 일 실시예에서, 슈퍼 레졸루션 처리 모듈의 동작은 프레임 보간 처리 모듈 및 품질 향상 처리 모듈의 동작 이후에 수행될 수 있으나, 이에 제한되지 않는다. 프레 임 보간 처리 모듈 및 품질 향상 처리 모듈에 대한 설명은 예컨대, 상술한 도 3 내지 16의 설명을 참조할 수 있다. 슈퍼 레졸루션 처리 모듈에 대한 설명은 예컨대, 상술한 도 17 내지 25의 설명을 참조할 수 있다. 도 28은 본 개시의 일 실시예에 따른, 이미지 처리 절차의 일 예를 나타낸다. 도 28의 실시예에서, 프레임 스킵핑 처리 모듈(예: 도 3의 프레임 스킵핑 처리 모듈)의 동작은 다운 샘플 링 처리 모듈(예: 도 17의 다운 샘플링 처리 모듈) 및 레이턴트 벡터 처리 모듈(예: 도 17의 레이턴트 벡 터 처리 모듈)의 동작 이전에 수행되고, 슈퍼 레졸루션 처리 모듈(예: 도 21의 슈퍼 레졸루션 처리 모듈 )의 동작은 프레임 보간 처리 모듈(예: 도 10의 프레임 보간 처리 모듈) 및 품질 향상 처리 모듈 (예: 도 10의 품질 향상 처리 모듈)의 동작 이후에 수행되는 것으로 가정된다. 다만, 실시예가 이에 한정 되지 않고, 반대의 경우도 가능하다. 도 28을 참조하면, 영상 송신 장치(예: 도 1a, 1b 및 1c의 영상 송신 장치)는 적어도 하나의 원본 프레임 을 포함하는 원본 이미지 데이터를 획득할 수 있다. 일 실시예에 따른, 영상 송신 장치는 프레임 선별 동작(또는, 프레임 스킵핑 동작)을 수행하여, 프레임 스킵된 이미지 데이터를 획득할 수 있다. 프레임 스킵핑 동작에 대한 설명은 도 3 내지 9 및 도 15의 설명을 참 조할 수 있다. 일 실시예에 따른, 영상 송신 장치는 다운 스케일 동작(또는, 다운 샘플링 동작) 및 레이턴트 벡터 추정 동작 (또는, 레이턴트 벡트 생성 동작)을 수행하여, 다운 스케일된 이미지 데이터 및 레이턴트 벡터 데이터를 생성할 수 있다. 일 예로, 다운 샘플링 동작은 레이턴트 벡터 생성 동작 이전에 수행될 수 있다. 다운 샘플링 동 작 및 레이턴트 벡터 생성 동작에 대한 설명은 도 17 내지 20, 및 도 24의 설명을 참조할 수 있다. 일 실시예에 따른, 영상 송신 장치는 예컨대, 표준화된 코덱 기술(예: HEVC, VVC, H.264)을 이용하여 다운 스케 일된 이미지 데이터 및/또는 레이턴트 벡터 데이터를 부호화하고, 부호화된 이미지 데이터 및 레이턴트 벡터 데 이터(또는, 부호화된 레이턴트 벡터 데이터)를 영상 수신 장치(예: 도 1a, 1b 및 1c의 영상 수신 장치)로 전송할 수 있고, 영상 수신 장치는 부호화된 이미지 데이터 및 레이턴트 벡터 데이터(또는, 부호화된 레이턴트 벡터 데이터)를 수신하고, 부호화된 이미지 데이터 및/또는 부호화된 레이턴트 벡터 데이터를 복호화할 수 있다 . 일 실시예에 따른, 영상 수신 장치는 복호화된 이미지 데이터에 대한 보간 동작(또는, 프레임 보간 동작) 및 향 상 동작(또는, 품질 향상 동작)을 수행하여, 프레임 보간/품질 향상된 이미지 데이터를 획득할 수 있다. 일 예로, 프레임 보간 동작은 품질 향상 동작 이전에 수행될 수 있으나, 이에 제한되지 않는다. 프레임 보간 동 작 및 품질 향상 동작에 대한 설명은 도 10 내지 도 14, 및 도 16의 설명을 참조할 수 있다. 일 실시예에 따른, 영상 수신 장치는 레이턴트 벡터 데이터(또는, 복호화된 레이턴트 벡터 데이터)를 이용하여, 프레임 보간/품질 향상된 이미지 데이터에 대한 슈퍼 레졸루션 동작을 수행하여, 해상도가 향상된 이미지 데이 터를 획득할 수 있다. 슈퍼 레졸루션 동작에 대한 설명은 도 21 내지 23, 및 도 25의 설명을 참조할 수 있다. 이렇게 획득된 최종 이미지 데이터는 원본 이미지 데이터와 실질적으로 동일한 품질을 제공할 수 있다. 이하에서는, GoP 인핸스먼트 처리를 이용하는 후처리 방법을 설명한다. 도 29는 본 개시의 일 실시예에 따른, 원본 영상과 부호화 및 복호화된 영상을 나타낸다. 도 29의 (a) 부분은 원본 영상의 일 예이다. 도 29의 (a) 부분을 참조하면, 원본 영상은 제1 부분을 포함 할 수 있다. 도 29의 (b) 부분은 영상 수신 장치(예: 도 1a, 1b 및 1c의 영상 수신 장치)가 도 29의 (a) 부분의 원본 영상을 부호화하여 생성된 부호화된 영상을 수신하고, 이를 복호화하여 생성된 복호화된 영상의 일 예이다. 도 29의 (b) 부분을 참조하면, 부호화 및 복호화된 영상은 원본 영상의 제1 부분에 대응하는 제2 부분(292 0)을 포함할 수 있다. 제1 부분과 제2 부분은 원본 영상의 프레임과 부호화 및 복호화된 영상의 프 레임 내에서 동일한 영역을 포함하는 부분일 수 있다. 본 개시에서, 부호화 및 복호화된 영상은 코덱 처리부(예: 도 1c의 코덱 처리부(113a) 또는 코덱 처리부(122a))에 의해 코덱 처리된 영상으로 지칭될 수도 있 다. 일 실시예에 따르면, 원본 영상에 대한 부호화 처리는 영상 송신 장치의 부호화부(예: 도 1a/b의 영상 송신 장 치의 부호화부 또는 도 1c의 영상 송신 장치의 코덱 처리부(113a))에 의해 수행될 수 있고, 부 호화된 영상에 대한 복호화 처리는 영상 수신 장치의 복호화부(예: 도 1a/b의 영상 수신 장치의 복호화부 또는 도 1c의 영상 수신 장치의 코덱 처리부(122a))에 의해 수행될 수 있다. 일 실시예에 따르면, 영상 송신 장치(또는, 부호화부)는 적어도 하나의 참조 프레임(예: I 프레임)을 포함하는 프레임 그룹의 단위로 부호화 처리를 수행할 수 있다. 프레임 그룹은 예컨대, 하나의 참조 프레임을 포함하는 연속적인 프레임들의 시퀀스를 포함할 수 있다. 참조 프레임은 해당 프레임 그룹 내의 프레임들을 압축(또는, 부호화)하기 위해 사용될 수 있다. 일 예로, 프레임 그룹은 GoP에 대응할 수 있다. 일 실시예에 따르면, 영상 송신 장치(또는, 부호화부)는 프레임 그룹(또는, GoP) 내의 하나의 참조 프레임을 기 초로, 프레임 그룹(또는, GoP) 내의 프레임들을 압축(또는, 부호화)할 수 있다. 이러한 방식으로, 영상 압축(또 는, 부호화)가 프레임 그룹(또는, GoP) 단위로 수행될 수 있다. 이처럼, 프레임 그룹(또는, GoP) 내의 참조 프 레임을 기초로 프레임 그룹(또는, GoP)에 대한 영상 압축이 수행되므로, 압축/복원이 수행되는 경우에 발생되는 열화는 프레임 그룹(또는, GoP) 단위로 발생될 수 있다. 이하에서는, 설명의 편의를 위해, 부호화 처리(또는, 압축 처리)가 수행되는 단위가 GoP인 것으로 가정하고 본 개시의 실시예들을 설명한다. 다만, 본 개시의 실시예에 대한 설명이 후술할 GoP와 동일한 역할/기능을 갖는 프 레임 그룹에도 동일하게 적용될 수 있음은 자명하다. 일 실시예에 따른, GoP는 다양한 유형(type)의 프레임을 포함할 수 있다. 예를 들면, GoP는 I 프레임(intra- coded frame), P 프레임(predictive-coded frame) 및/또는 B 프레임(bi-predictive-coded frame)을 포함할 수 있다. 일 실시예에 따른, I 프레임은 다른 프레임에 의존하지 않고 독립적으로 인코딩되는 프레임일 수 있다. I 프레 임은 예컨대, 비디오 시퀀스의 특정 지점에서의 완전한 이미지를 포함할 수 있다. 본 개시에서, I 프레임은 참 조 프레임 또는 키 프레임으로 지칭될 수도 있다. 일 실시예에 따른, P 프레임은 이전에 부호화된 I 프레임이나 P 프레임을 기초로, 예측적으로 부호화되는 프레 임일 수 있다. P 프레임은 I 프레임이나 다른 P 프레임과 차이 정보(difference information)를 사용하여 부호 화될 수 있다. 일 실시예에 따른, B 프레임은 이전 및 다음 프레임을 기초로, 예측적으로 부호화되는 프레임일 수 있다. B 프 레임은 I 프레임과 P 프레임 사이에 위치하며, 가능한 많은 차이 정보를 활용하여 부호화될 수 있다. 일 실시예에 따른, GoP는 I 프레임을 해당 GoP 내의 첫 프레임으로 포함하고, GoP가 두 개 이상의 프레임을 포 함하는 경우, GoP는 적어도 하나의 B 프레임 및/또는 적어도 하나의 P 프레임을 더 포함할 수 있다. 예를 들면, GoP의 사이즈가 12인 경우, 해당 GoP는 예컨대, IBPPPPBBPBBP와 같은 GoP 패턴을 가질 수 있다. 일 실시예에 따른, GoP의 첫 프레임인 I 프레임은 참조할 프레임이 없기 때문에 이미지 압축(예: intra 압축)을 이용하여 압축될 수 있다. 그러나, GoP의 나머지 프레임들은 다른 인접한 프레임들을 참조하는 비디오 압축(예: inter 압축)을 이용하여 압축될 수 있다. 예를 들면, GoP가 12개의 프레임으로 구성된 경우, 첫 번째 프레임에 는 intra 압축이 적용되고, 나머지 11개의 프레임들에는 inter 압축이 적용될 수 있다. 이때, 11개의 프레임에 적용되는 inter 압축은 첫 번째 프레임을 참조하여 압축된 것을 계속하여 참조하여 압축을 수행하게 된다. 따라 서, 첫 번째 프레임의 압축에 따른 왜곡이 후행하는 11개의 프레임에 전달될 수 있다. 이는 GoP 내의 후행하는프레임들에서 왜곡을 발생시킨다. 이하에서는, 도 30을 참조하여, GoP 내에서 발생되는 왜곡의 일 예를 설명한 다. 도 30은 본 개시의 일 실시예에 따른, 원본 영상의 제1 부분을 시간 순으로 표시한 이미지(제1 이미지) 및 원본 영상의 제1 부분에 대응하는 부호화 및 복호화된 영상의 제2 부분을 시간 순으로 표시한 이미지(제2 이미지)를 나타낸다. 도 30의 (a) 부분은, 원본 영상의 프레임들에서 프레임 별로 제1 부분(예: 도 29의 (a) 부분에 표시된 원본 영 상의 제1 부분)을 추출하여, 시간 순서로 위에서 아래로 쌓아서 표시한 이미지(이하, 제1 이미지)를 보여 준다. 도 30의 (b) 부분은, 부호화 및 복호화된 영상의 프레임들에서 프레임 별로 제2 부분(예: 도 29의 (b) 부분에 표시된 부호화 및 복호화된 영상의 제2 부분)을 추출하여, 시간 순서로 위에서 아래로 쌓아서 표시한 이 미지(이하, 제2 이미지)를 보여준다. 도 30의 (a) 부분을 참조하면, 원본 영상과 연관된 제1 이미지의 경우, 시간 순서에 따라 해당 이미지의 변화가 부드럽게 나타나는 것을 확인할 수 있다. 이에 반하여, 도 30의 (b) 부분을 참조하면, 부호화 및 복호화된 영상과 연관된 제2 이미지의 경우, 시간의 순 서에 따라 해당 이미지의 변화가 부드럽지 않음을 확인할 수 있다. 도시된 것처럼, GoP의 단위로, 큰 변화가 발 생됨이 확인될 수 있다. 즉, GoP의 경계에서 해당 이미지에 대한 급격한 변화가 발생됨이 확인될 수 있다. 이러 한 왜곡은, 상술한 것처럼, 해당 GoP의 첫 번째 프레임인 제1 I 프레임의 압축에 따른 왜곡이 후행하는 11개의 프레임에 전달되고, 그 다음 GoP의 첫 번째 프레임인 제2 I 프레임(제1 I 프레임과 상이함)의 압축에 따른 왜곡 이 후행하는 11개의 프레임에 전달되기 때문에 발생되게 된다. 즉, 각 GoP의 첫 번째 프레임인 I 프레임에서 상 이한 왜곡이 발생하였고, 각 GoP의 나머지 프레임들이 해당 I 프레임을 참조하여 압축을 수행하였기 때문에 I 프레임의 상이한 왜곡의 특성이 나머지 프레임들에도 전달된다. 따라서, GoP 사이에 서로 상이한 왜곡 특성이 존재할 수 있다. 한편, 압축에 따른 왜곡을 복원하기 위한 다양한 방법들이 존재한다. 다만, 이러한 방법들은 한 프레임 내에서 의 일관성(consistency) 유지 등을 위한 것에 해당한다. 또는, 인접한 프레임 사이에서 시간 도메인 상의 일관 성 유지 등을 위한 것에 해당한다. 그러나, 상술한 것처럼, 압축에 따른 왜곡은 GoP(또는, 프레임 그룹) 사이에서도 발생된다. 따라서, GoP 사이에 서 발생되는 왜곡을 복원하기 위한 방법이 새롭게 고려될 필요가 있다. 이하에서는, GoP 사이(예: 인접한 GoP 사이)에서 발생되는 왜곡(이하, GoP 왜곡)을 복원하기 위한 GoP 인핸스먼트 처리를 이용하는 후처리 방법을 설 명한다. 도 31은 본 개시의 일 실시예에 따른, 후처리부의 GoP 인핸스먼트 처리 모듈을 나타낸다. 도 32는 본 개시의 일 실시예에 따른, GoP 인핸스먼트 처리 모듈의 동작을 설명한다. 도 33은 본 개시의 일 실시예에 따른, GoP 인핸 스먼트 처리 모듈의 얼라인먼트 처리를 위한 절차의 일 예를 나타낸다. 도 31을 참조하면, 후처리부는 품질 향상을 위한 GoP 인핸스먼트 처리 모듈을 포함할 수 있다. GoP 인핸스먼트 처리 모듈에 입력되는 프레임들은 예컨대, 후처리부 이전에 동작하는 복호화부에 의해 복호화된 프레임들에 해당할 수 있다. 일 실시예에 따른, GoP 인핸스먼트 처리 모듈은 복호화된 영상 신호에 대한 품질 향상(예: GoP 왜곡 복원)을 위한 처리를 수행할 수 있다. 일 실시예에 따른, GoP 인핸스먼트 처리 모듈은 품질 향상 처리 모듈의 일 예일 수 있다. 일 실시예에 따른, GoP 인핸스먼트 처리 모듈은 미리 설정된 수(예: 3)의 프레임들의 단위로 프레임들을 복원할 수 있다. 예를 들면, GoP 인핸스먼트 처리 모듈은 3개의 프레임 단위로 GoP 왜곡을 복원하기 위한 처리를 수행하여, 해당 프레임들을 복원할 수 있다. 이하에서, GoP 인핸스먼트 처리 모듈 또는 GoP 인핸스먼트 처리 모듈에 포함되는 구성 요소의 동작은 영상 수신 장치(예: 도 1a/b의 영상 수신 장치) 또는 영상 수신 장치의 후처리부(예: 도 1a/b의 영상 수신 장치(12 0)의 후처리부)의 동작으로 이해될 수 있다. 도 32를 참조하면, GoP 인핸스먼트 처리 모듈은 얼라인먼트 처리부 및/또는 인핸스먼트 네트워크 를 포함할 수 있다. 본 개시에서, 인핸스먼트 네트워크는 인핸스먼트 모델로 지칭될 수 있다. 일 실시예에 따른, 얼라인먼트 처리부는 프레임들(예: I 프레임들)에 대한 얼라이먼트 처리를 위한 적어 도 하나의 동작을 수행할 수 있다. 일 실시예에 따른, 얼라인먼트 처리부는 제1 프레임 그룹의 제1 프레임 및 제1 프레임 그룹에 후행하는 제2 프레임 그룹의 제2 프레임을 획득(또는, 식별)할 수 있다. 실시예로서, 제1 프레임 및 제2 프레임은 독립적 으로(independently) 부호화 및 복호화된 프레임에 해당할 수 있다. 이러한 제1 프레임 및 제2 프레임은 각각 부호화 시에 해당 프레임 그룹 내의 적어도 하나의 다른 프레임의 부호화(또는, 압축)을 위해 이용된 프레임일 수 있다. 일 예로, 제1 프레임 및 제2 프레임은 I 프레임일 수 있다. 일 예로, 제2 프레임 그룹은, 제1 프레임 그룹에 바로 다음의 프레임 그룹일 수 있다. 즉, 제2 프레임 그룹은 제1 프레임 그룹에 인접한 프레임 그룹으로 서, 제1 프레임 그룹의 이후에 위치하는 프레임 그룹일 수 있다. 일 실시예에 따른, 얼라인먼트 처리부는 제1 프레임을 제1 프레임 그룹의 연속된 복수의 프레임(예: 3개 의 연속된 프레임)과 얼라인(align)시키기 위한 처리를 수행하여, 복수의 제1 얼라인된(aligned) 프레임(예: 3 개의 제1 얼라인된 프레임)을 생성할 수 있다. 본 개시에서, 제1 프레임을 해당 프레임과 얼라인시키는 것은, 제1 프레임이 해당 프레임과 실질적으로 동일해지도록 제1 프레임을 처리하는 것일 수 있다. 실시예로서, 복수 의 프레임은 예컨대, 제1 프레임을 기초로 예측적으로 부호화 및 복호화된 프레임에 해당할 수 있다. 일 예로, 복수의 프레임은 P 프레임 또는 B 프레임일 수 있다. 일 실시예에 따른, 얼라인먼트 처리부는 픽셀 도메인(pixel domain)에서의 광학 흐름(optical flow) 기법 및/또는 워핑(warping) 기법을 이용하여, 복수의 제1 얼라인된 프레임을 생성할 수 있다. 일 예로, 얼라인먼트 처리부는 광학 흐름 기법 및 워핑 기법을 이용하여 제1 프레임 내의 픽셀들의 위치를 조정함으로써, 제1 프레임을 제1 프레임 그룹의 연속된 복수의 프레임에 맞출(또는, 얼라인시킬) 수 있다. 일 실시예에 따른, 광학 흐름 기법은, 영상에서 픽셀의 이동 패턴을 추정하는 기술일 수 있다. 광학 흐름 기법 은, 예컨대, 픽셀의 밝기 변화를 이용하여 픽셀이 이동한 방향과 속도를 추정하기 위해 사용될 수 있다. 일 실시예에 따른, 얼라인먼트 처리부는 광학 흐름 기법을 이용하여 광학 흐름을 계산함으로써 영상에서 개별 픽셀이 어떻게 이동하는지를 식별할 수 있다. 즉, 얼라인먼트 처리부는 광학 흐름을 계산함으로써, 영상의 모션 정보를 획득할 수 있다. 일 실시예에 따른, 얼라인먼트 처리부는 광학 흐름 기법을 이용하여, 제1 프레임 및/또는 제2 프레임의 각 픽셀을 어떻게 이동(또는, 위치 조정)시켜야 하는지에 대한 정보를 포함하는 흐름 맵(flow map)을 획득할 수 있고, 흐름 맵을 이용하여 제1 프레임 및/또는 제2 프레임을 제1 프레임 그룹의 연속된 복수의 프레임에 얼라인 시킬 수 있다. 일 실시예에 따른, 광학 흐름 기법은 AI 기반의 광학 흐름 기법일 수 있다. 일 실시예에 따른, 워핑 기법은 이미지나 영상에 기초한 좌표 변환 기법에 해당한다. 워핑은 예컨대, 이미지를 특정한 변환 함수를 사용하여 다른 좌표 공간으로 이동시키는 것을 지칭할 수 있다. 일 실시예에 따른, 광학 흐름 기법과 워핑 기법은 함께 이용될 수 있다. 일 예로, 얼라인먼트 처리부는 광학 흐름 기법에 의해 획득된 영상의 모션 정보를 이용하여, 프레임을 변형하기 위해 워핑 기법을 이용할 수 있다. 예를 들면, 얼라인먼트 처리부는 광학 흐름 기법을 이용하여 픽셀의 이동 정보를 획득한 후, 워핑 기법을 이용하여 해당 이동 정보를 기반으로 제1 프레임 및/또는 제2 프레임에 대한 변형(예: 픽셀들의 위치 조 정을 통한 변형)을 수행함으로써, 제1 얼라인된 프레임 및/또는 제2 얼라인된 프레임을 생성할 수 있다. 일 실시예에 따른, 얼라인먼트 처리부는 제2 프레임을 제1 프레임 그룹의 연속된 복수의 프레임(예: 3개 의 연속된 프레임)과 얼라인시키기 위한 처리를 수행하여, 복수의 제2 얼라인된 프레임(예: 3개의 제2 얼라인된 프레임)을 생성할 수 있다. 본 개시에서, 제2 프레임을 해당 프레임과 얼라인시키는 것은, 제2 프레임이 해당 프레임과 실질적으로 동일해지도록 제2 프레임을 처리하는 것일 수 있다. 일 실시예에 따른, 얼라인먼트 처리부는 픽셀 도메인에서의 광학 흐름 기법 및/또는 워핑 기법을 이용하 여, 복수의 제2 얼라인된 프레임을 생성할 수 있다. 일 예로, 얼라인먼트 처리부는 광학 흐름 기법 및 워 핑 기법을 이용하여 제2 프레임 내의 픽셀들의 위치를 조정함으로써, 제2 프레임을 제1 프레임 그룹의 연속된 복수의 프레임에 맞출(또는, 얼라인시킬) 수 있다. 이를 통해, 제1 프레임 그룹(또는, 제1 GoP) 내의 복원될 동일한 복수의 프레임(예: 3개의 프레임)에 대해, 제1 프레임 그룹(또는, 제1 GoP)의 제1 프레임에 기초한 복수의 제1 얼라인된 프레임(예: 3개의 제1 얼라인된 프레임) 및 제2 프레임 그룹(또는, 제2 GoP)의 제2 프레임에 기초한 복수의 제2 얼라인된 프레임(예: 3개의 제2 얼 라인된 프레임)이 각각 생성될 수 있다. 이렇게 생성된 복수의 제1 얼라인된 프레임 및 복수의 제2 얼라인된 프 레임은 해당 복수의 프레임을 복원하기 위해 함께 사용될 수 있다. 일 실시예에 따른, 얼라인먼트 처리부는 제1 프레임 그룹(또는, 제1 GoP)의 제1 프레임을 제1 프레임 그 룹(또는, 제1 GoP) 내의 복수의 프레임과 얼라인시키기 위한 처리를 수행하여, 복수의 제1 얼라인된 프레임과 연관된 제1 특징 데이터를 획득할 수 있다. 일 예로, 얼라인먼트 처리부는 특징 도메인(feature domain) 에서의 어텐션(attention) 메커니즘 기반의 인공지능 모델(이하, 어텐션 기반 인공지능 모델)을 이용하여, 제1 특징 데이터를 획득할 수 있다. 일 실시예에 따른, 얼라인먼트 처리부는 제1 프레임 그룹(또는, 제1 GoP)에 후행하는 제2 프레임 그룹(또 는, 제2 GoP)의 제2 프레임을 제1 프레임 그룹(또는, 제1 GoP) 내의 복수의 프레임과 얼라인시키기 위한 처리를 수행하여, 복수의 제2 얼라인된 프레임과 연관된 제2 특징 데이터를 획득할 수 있다. 일 예로, 얼라인먼트 처리 부는 특징 도메인에서의 어텐션 기반 인공지능 모델을 이용하여, 제2 특징 데이터를 획득할 수 있다. 이 렇게 획득된 제1 특징 데이터 및 제2 특징 데이터는, 제1 얼라인된 프레임 및 제2 얼라인된 프레임을 대신하여, 해당 프레임들에 대한 복원을 위해 사용(예: 인핸스먼트 네트워크에 의해 사용)될 수 있다. 일 실시예에 따른, 어텐션 기반 인공지능 모델은 어텐션 기반 딥 러닝 네트워크일 수 있다. 일 실시예에 따른, 어텐션 기반 인공지능 모델은 주어진 입력에 대해 중요한 정보를 집중적으로 강조하거나 가 중치를 부여하여 학습하는 방법일 수 있다. 이러한 어텐션 기반 인공지능 모델은 네트워크가 입력의 특정 부분 에 더 집중하고 더 중요한 패턴을 학습할 수 있도록 도와준다. 일 실시예에 따른, 얼라인먼트 처리부는 어텐션 기반 인공지능 모델을 통해 어텐션 맵(attention map)을 획득하고, 어텐션 맵을 이용하여 해당 프레임의 제1 부분과 가장 유사한 부분이 참조 프레임(예: 제1 프레임 또 는 제2 프레임)의 어떤 부분인지에 대한 유사도 맵을 획득할 수 있다. 이러한 유사도 맵에 기초한 유사도를 가 중치로 하여, 얼라인먼트 처리부는 가장 높은 유사도를 갖는 참조 프레임(예: 제1 프레임 또는 제2 프레 임)의 부분을 해당 프레임과의 얼라인먼트 처리를 위해 가장 많이 가져오는 방식을 취할 수 있다. 일 실시예에 따른, 인핸스먼트 네트워크는 제1 프레임 그룹(또는, 제1 GoP)의 제1 프레임 및 제2 프레임 그룹(또는, 제2 GoP)의 제2 프레임을 기초로, 제1 프레임 그룹의 연속된 복수의 프레임(예: t-1, t, t+1 프레임)에 대한 복수의 복원된 프레임을 획득할 수 있다. 이처럼, 복원될 복호화된 프레임들이 속하는 프레임 그룹 내의 다른 프레임들의 부호화(또는, 압축)을 위해 사용되는 제1 프레임(예: I 프레임) 뿐만 아니라, 그 다 음 프레임 그룹 내의 다른 프레임들의 부호화(또는, 압축)을 위해 사용되는 제2 프레임(예: I 프레임)을 함께 이용하여 복호화된 프레임들을 복원함으로써, 프레임 그룹 간(예: GoP 간)의 왜곡이 복원될 수 있다. 따라서, 복호화된 프레임들을 이용하여 제공된 영상 비해 시각적으로 스무딩된 영상이 제공될 수 있다. 일 실시예에 따른, 인핸스먼트 네트워크는 복수의 제1 얼라인된 프레임, 복수의 제2 얼라인된 프레임 및 복수의 프레임에 기초하여, 복수의 복원된 프레임을 생성할 수 있다. 일 예로, 인핸스먼트 네트워크는 복 수의 제1 얼라인된 프레임, 복수의 제2 얼라인된 프레임 및 복수의 프레임을 입력 데이터로서 미리 학습된 인공 지능 모델에 입력하고, 인공지능 모델로부터 출력 데이터로서 복수의 프레임의 각각에 대응하는 복원된 프레임 을 각각 획득할 수 있다. 일 실시예에 따른, 인핸스먼트 네트워크는 제1 특징 데이터, 제2 특징 데이터 및 복수의 프레임에 기초하 여, 복수의 복원된 프레임을 생성할 수 있다. 일 실시예에 따른, 인핸스먼트 네트워크는 복수의 인공 신경망 레이어를 포함하는 인공지능 모델(이하, 인핸스먼트 모델)로 구현될 수 있다. 인공 신경망은, 예컨대, DNN, CNN, RNN, RBM, DBN, BRDNN, 심층 Q-네트워 크(deep Q-networks) 또는 상기 중 둘 이상의 조합 중 하나일 수 있으나, 전술한 예에 한정되지 않는다. 일 실시예에 따른, 인핸스먼트 모델은 입력층, 은닉층(들) 및 출력층을 포함할 수 있다. 일 실시예에 따른, 인 핸스먼트 모델은 입력층, 복수의 컨볼루션 레이어, 완전 연결된 레이어 및 출력층을 포함할 수 있다. 한편, 도 21에 예시된 것처럼, 상술한 제1 프레임 그룹은 제1 GoP에 해당하고, 제2 프레임 그룹은 제1 GoP에 후 행하는 제2 GoP(예: 제1 GoP의 바로 다음의(immediately follow) 제2 GoP일 수 있으나, 이에 제한되지 않음)에 해당할 수 있다. 제1 프레임은 제1 GoP의 I 프레임(예: 제1 GoP의 첫 번째 프레임인 I 프레임)에 해당하고, 제2 프레임은 제2 GoP의 I 프레임(예: 제2 GoP의 첫 번째 프레임인 I 프레임)에 해당할 수 있다. 복수의 프레임의각각은 제1 GoP의 P 프레임 또는 B 프레임에 해당할 수 있다. 이하에서는, 도 33을 참조하여, 영상 수신 장치(또는, 영상 수신 장치의 얼라인먼트 처리부)의 동작을 예 시적으로 설명한다. 일 실시예에 따른, 얼라인먼트 처리부는 제1 GoP 내의 I 프레임(이하, 제1 I 프레임) 및 제1 GoP에 후행 하는 제2 GoP 내의 I 프레임(이하, 제2 I 프레임)을 획득할 수 있다. 일 예로, 제2 GoP는 제1 GoP의 바로 다음 의 GoP일 수 있으나, 이에 제한되지 않는다. 일 실시예에 따른, 영상 수신 장치는 각 GoP 내의 I 프레임 및/또 는 I 프레임의 리스트(intra list)를 메모리에 저장하고, 저장된 I 프레임들을 복호화된(decoded) 프레임들을 복원하기 위해 사용할 수 있다. 일 실시예에 따른, 얼라인먼트 처리부는 복원될 복수의 복호화된 프레임들을 획득할 수 있다. 일 예로, 도 33에 예시된 것처럼, 얼라인먼트 처리부는 제1 GoP에 속하는 연속된 3개의 P 프레임(예: 3개의 연속된 P 프레임(t-1, t, t+1의 P 프레임))을 획득할 수 있다. 일 실시예에 따른, 복호화된 프레임들은, 복호화부(예: 도 1b의 복호화부)에 의해 복호화된 후에, 프레임 보간 처리 모듈(예: 도 10의 프레임 보간 처리 모듈)에 의해 프레임 보간 처리된 프레임들일 수 있다. 일 실시예에 따른, 얼라인먼트 처리부는 제1 I 프레임을 제1 GoP의 연속된 복수의 프레임과 얼라인시키기 위한 처리를 수행하여, 복수의 제1 얼라인된 프레임을 생성할 수 있다. 본 개시에서, I 프레임을 해당 P 프레임 과 얼라인시키는 것은, I 프레임이 해당 P 프레임과 실질적으로 동일해지도록 I 프레임을 처리하는 것일 수 있 다. 일 예로, 얼라인먼트 처리부는 광학 흐름 기법 및/또는 워핑 기법을 이용하여 제1 I 프레임 내의 픽 셀들의 위치를 조정함으로써, 제1 I 프레임을 3개의 P 프레임의 각각과 얼라인되는 3개의 제1 얼라인된 프레임 으로 변형시킬 수 있다. 일 실시예에 따른, 얼라인먼트 처리부는 제2 I 프레임을 제1 GoP의 연속된 복수의 프레임과 얼라인시키기 위한 처리를 수행하여, 복수의 제2 얼라인된 프레임을 생성할 수 있다. 본 개시에서, I 프레임을 해당 P 프레임 과 얼라인시키는 것은, I 프레임이 해당 P 프레임과 실질적으로 동일해지도록 I 프레임을 처리하는 것일 수 있 다. 일 예로, 얼라인먼트 처리부는 광학 흐름 기법 및/또는 워핑 기법을 이용하여 제2 프레임 내의 픽셀 들의 위치를 조정함으로써, 제2 I 프레임을 3개의 P 프레임의 각각과 얼라인되는 3개의 제2 얼라인된 프레임으 로 변형시킬 수 있다. 이렇게 생성된 복수의 제1 얼라인된 프레임(예: 3개의 제1 얼라인된 프레임) 및 복수의 제2 얼라인된 프레임(예: 3개의 제2 얼라인된 프레임)은, 복수의 복호화된 프레임(예: 3개의 복호화된 프레임)과 함께, 인핸 스먼트 네트워크로 전달될 수 있다. 인핸스먼트 네트워크는 복수의 제1 얼라인된 프레임, 복수의 제2 얼라인된 프레임 및 복수의 프레임을 입 력 데이터로서 미리 학습된 인공지능 모델에 입력하고, 인공지능 모델로부터 출력 데이터로서 복수의 프레임의 각각에 대응하는 복원된 프레임을 각각 획득할 수 있다. 이처럼, 복원될 복호화된 프레임들이 속하는 GoP 내의 I 프레임 뿐만 아니라, 그 다음(또는, 인접한) GoP 내의 I 프레임 둘 모두를 이용하여, 복호화된 프레임들을 복 원함으로써, GoP 간 왜곡이 복원될 수 있다. 따라서, 복호화된 P 프레임들을 이용하여 제공된 영상 비해 시각적 으로 스무딩된 영상이 제공될 수 있다. 도 34는 본 개시의 일 실시예에 따른, 영상 수신 장치의 영상 처리 방법의 흐름도이다. 도 34의 실시예에서, 영상 처리 방법은 복호화부(예: 도 1b의 복호화부 또는 도 1c의 코덱 처리부(122a)) 의 동작 이후에 동작되는 후처리부(예: 도 1b의 후처리부 또는 도 1c의 후처리부(123a)) 내의 GoP 인핸스 먼트 처리 모듈(예: 도 31의 GoP 인핸스먼트 처리 모듈 )에 의해 수행될 수 있다. 따라서, 도 34의 영상 처리를 위해 입력되는 프레임들은 복호화부에 의해 복호화된 프레임들에 해당할 수 있다. 도 34를 참조하면, 영상 수신 장치(예: 도 1a/b/c의 영상 수신 장치)는 제1 프레임 그룹의 제1 프레임 및 제1 프레임 그룹에 후행하는 제2 프레임 그룹의 제2 프레임을 획득할 수 있다. 영상 수신 장치는 제1 프레임 및 제2 프레임을 기초로, 제1 프레임 그룹의 연속된 복수의 프레임에 대한 복수의 복원된 프레임을 획득할 수 있다. 일 실시예에 따른, 제1 프레임 및 제2 프레임은 독립적으로 부호화 및/또는 복호화된 프레임에 해당하고, 복수 의 프레임은 제1 프레임을 기초로 부호화 및/또는 복호화된 프레임(예: 예측적으로 부호화 및/또는 복호화된 프레임)에 해당할 수 있다. 일 실시예에 따른, 제1 프레임 그룹은 제1 GoP에 대응하고, 제2 프레임 그룹은 제1 GoP의 바로 다음의 제2 GoP 에 해당할 수 있다. 일 실시예에 따른, 제1 프레임은 제1 GoP의 첫 번째 프레임인 I 프레임에 해당하고, 제2 프 레임은 제2 GoP의 첫 번째 프레임인 I 프레임에 해당할 수 있다. 일 실시예에 따른, 복수의 프레임의 각각은 상 기 제1 GoP의 P 프레임 또는 B 프레임에 해당할 수 있다. 일 실시예에 따른, 연속된 복수의 프레임의 수는 3일 수 있다. 도 35는 본 개시의 일 실시예에 따른, 영상 수신 장치의 얼라인먼트 처리 동작의 흐름도이다. 도 35의 실시예에서, 얼라인먼트 처리는 복호화부(예: 도 1b의 복호화부 또는 도 1c의 코덱 처리부(122 a))의 동작 이후에 동작되는 후처리부(예: 도 1b의 후처리부 또는 도 1c의 후처리부(123a)) 내의 얼라인먼 트 처리부(예: 도 32의 얼라인먼트 처리부)에 의해 수행될 수 있다. 따라서, 도 35의 얼라인먼트 처리 동 작을 위해 입력되는 프레임들은 복호화부에 의해 복호화된 프레임들에 해당할 수 있다. 도 35를 참조하면, 영상 수신 장치(예: 도 1a/b/c의 영상 수신 장치)는 제1 프레임 그룹(또는, 제1 GoP)의 제1 프레임을 제1 프레임 그룹 내의 복수의 프레임과 얼라인시키기 위한 처리를 수행하여, 복수의 제1 얼라인된 프레임을 생성할 수 있다. 영상 수신 장치는 제1 프레임 그룹(또는, 제1 GoP)에 후행하는 제2 프레임 그룹(또는, 제2 GoP)의 제2 프레임을 제1 프레임 그룹의 복수의 프레임과 얼라인시키기 위한 처리를 수행하여, 복수의 제2 얼라인된 프레임을 생성할 수 있다. 영상 수신 장치는 복수의 제1 얼라인된 프레임, 복수의 제2 얼라인된 프레임 및 복수의 프레임에 기초하여, 복 수의 프레임에 대한 복수의 복원된 프레임을 생성할 수 있다. 일 실시예에 따른, 복수의 제1 얼라인된 프레임을 생성하는 동작 및 복수의 제2 얼라인된 프레임을 생성하는 동 작은 픽셀 도메인(pixel domain)에서의 광학 흐름(optical flow) 기법 및 워핑(warping) 기법을 이용하여 수행 될 수 있다. 일 실시예에 따른, 영상 수신 장치는, 복수의 제1 얼라인된 프레임을 생성하기 위하여, 광학 흐름 기법 및 상기 워핑 기법을 이용하여 제1 프레임 내의 픽셀들의 위치를 조정함으로써, 제1 프레임을 복수의 프레임의 각각과 얼라인되는 상기 복수의 제1 얼라인된 프레임으로 변형시킬 수 있다. 일 실시예에 따른, 영상 수신 장치는, 복수의 제2 얼라인된 프레임을 생성하기 위하여, 광학 흐름 기법 및 워핑 기법을 이용하여 제2 프레임 내의 픽셀들들의 위치를 조정함으로써, 제2 프레임을 복수의 프레임의 각각과 얼라 인되는 복수의 제2 얼라인된 프레임으로 변형시킬 수 있다. 일 실시예에 따른, 영상 수신 장치는, 복수의 복원된 프레임을 생성하기 위하여, 복수의 제1 얼라인된 프레임, 복수의 제2 얼라인된 프레임 및 복수의 프레임을 입력 데이터로서 미리 학습된 인공지능 모델에 입력하고, 인공 지능 모델로부터 출력 데이터로서 상기 복수의 프레임의 각각에 대응하는 복원된 프레임을 각각 획득할 수 있다. 일 실시예에 따른, 영상 수신 장치는, 상기 복수의 복원된 프레임을 생성하기 위하여, 제1 프레임을 상기 복수 의 프레임과 얼라인시키기 위한 처리를 수행하여, 복수의 제1 얼라인된 프레임과 연관된 제1 특징 데이터를 획 득하고, 제2 프레임을 복수의 프레임과 얼라인시키기 위한 처리를 수행하여, 복수의 제2 얼라인된 프레임과 연 관된 제2 특징 데이터를 생성하고, 제1 특징 데이터, 제2 특징 데이터 및 복수의 프레임에 기초하여, 복수의 복 원된 프레임을 생성할 수 있다. 일 실시예에 따른, 제1 특징 데이터를 획득하는 동작 및 제2 특징 데이터를 획득하는 동작은 특징 도메인 (feature domain)에서의 어텐션(attention) 메커니즘 기반의 인공지능 모델을 이용하여 수행될 수 있다. 한편, 도 3 내지 16에서 상술한 실시예(예: 프레임 생략/프레임 보간/품질 향상 기술 관련 실시예(제1 실시 예)), 도 17 내지 28에서 상술한 실시예(예: 다운 샘플링/레이턴트 벡터/SR 기술 관련 실시예(제2 실시예)), 및 /또는 도 29 내지 35에서 상술한 실시예(예: GoP 인핸스먼트 관련 실시예(제3 실시예))는 모순이 되지 않는 범 위 내에서 서로 조합될 수 있다. 예를 들면, 부호화 전 전처리를 위해 프레임 생략 기술, 다운 샘플링 기술 및/ 또는 레이턴트 벡터 기술이 조합되어 함께 사용될 수 있고, 복호화 후 후처리를 위해 프레임 보간, 품질 향상, SR 및/또는 GoP 인핸스먼트 기술이 조합되어 함께 사용될 수 있다. 예를 들면, 압축 전 전처리를 위해 프레임생략, 다운 샘플링, 및/또는 레이턴트 벡터 기술이 조합되어 함께 사용될 수 있다. 예를 들면, 복원 후 후처리 를 위해 프레임 보간 처리, 품질 향상 처리 및/또는 SR 처리 이후에, GoP 인핸스먼트 처리가 수행될 수 있다. 다만, 이는 예시에 불과하고, 다양한 순서 및 방식으로 해당 기술들이 서로 조합되어 사용될 수 있다. 일 실시예에 따르면, 영상 송신 장치의 방법은 복수의 이미지 프레임을 포함하는 이미지 데이터를 획득하는 동 작; 상기 이미지 데이터에 대한 전처리를 수행하는 동작; 부호화된 이미지 데이터를 생성하기 위하여 상기 전처 리된 이미지 데이터를 부호화(encode)하는 동작; 및 상기 부호화된 이미지 데이터 및 상기 전처리에 관련된 정 보를 전송하는 동작을 포함할 수 있다. 일 실시예에 따르면, 영상 송신 장치는 메모리; 통신부; 및 적어도 하나의 프로세서를 포함하며, 상기 적어도 하나의 프로세서는 복수의 이미지 프레임을 포함하는 이미지 데이터를 획득하는 동작; 상기 이미지 데이터에 대 한 전처리를 수행하는 동작; 부호화된 이미지 데이터를 생성하기 위하여 상기 전처리된 이미지 데이터를 부호화 (encode)하는 동작; 및 상기 부호화된 이미지 데이터 및 상기 전처리에 관련된 정보를 전송하는 동작을 수행하 도록 설정될 수 있다. 일 실시예에 따르면, 상기 전처리를 수행하는 동작은 도 3 내지 16에 상술한 제1 실시예의 동작들 중 적어도 하 나를 포함할 수 있다. 일 실시예에 따르면, 상기 전처리를 수행하는 동작은 도 17 내지 28에 상술한 제2 실시예 의 동작들 중 적어도 하나를 포함할 수 있다. 일 실시예에 따르면, 제1 실시예의 동작들(예: 프레임 스킵핑 처 리 모듈의 동작들)은 제2 실시예의 동작들(예: 다운 샘플링 처리 모듈 및/또는 레이턴트 벡터 생성 처리 모듈)의 동작들) 이전에 수행될 수 있으나, 이에 제한되지 않는다. 일 실시예에 따르면, 영상 수신 장치의 방법은 이미지 데이터를 획득하는 동작; 상기 이미지 데이터를 복호화하 는 동작; 및 전처리에 관련된 정보에 기초하여, 상기 이미지 데이터에 대한 후처리를 수행하는 동작을 포함할 수 있다. 일 실시예에 따르면, 영상 수신 장치는 메모리; 통신부; 및 적어도 하나의 프로세서를 포함하며, 상기 적어도 하나의 프로세서는 이미지 데이터를 획득하는 동작; 상기 이미지 데이터를 복호화하는 동작; 및 전처리에 관련 된 정보에 기초하여, 상기 이미지 데이터에 대한 후처리를 수행하는 동작을 수행하도록 설정될 수 있다. 일 실시예에 따르면, 상기 후처리를 수행하는 동작은 도 3 내지 16에 상술한 제1 실시예의 동작들 중 적어도 하 나를 포함할 수 있다. 일 실시예에 따르면, 상기 후처리를 수행하는 동작은 도 17 내지 28에 상술한 제2 실시예 의 동작들 중 적어도 하나를 포함할 수 있다. 일 실시예에 따르면, 상기 후처리를 수행하는 동작은 도 3 내지 16에 상술한 제1 실시예의 동작들 중 적어도 하나를 포함할 수 있다. 일 실시예에 따르면, 제1 실시예의 동작들(예: 프레임 보간 처리 모듈 및/또는 품질 향상 처리 모듈 의 동작들)은 제2 실시예의 동작들(예: 슈퍼 레졸루션 처리 모듈의 동작들) 이전에 수행될 수 있으 나, 이에 제한되지 않는다. 일 실시예에 따르면, 제2 실시예의 동작들(예: 슈퍼 레졸루션 처리 모듈의 동 작들)은 제3 실시예의 동작들(예: GoP 인핸스먼트 처리 모듈의 동작들) 이전에 수행될 수 있으나, 이에 제한되지 않는다. 도 36은 본 개시의 일 실시예에 따른, 코덱의 메타데이터를 저장하기 위한 포맷을 예시하는 도면이다. 일 실시예에 따르면, 코덱(예: AI 코덱)의 메타데이터는 프레임 스킵 정보 및/또는 레이턴트 벡터의 데이터를 포함할 수 있다. 도 36을 참조하면, 코덱의 메타데이터는 ISO 파일 포맷(예: ISO BMFF(base media file format))의 형식으로 저 장될 수 있다. ISO 파일 포맷은 예컨대, MP4 또는 MOV 파일 포맷과 상호 호환되며, 표준화된 포맷에 해당한다. ISO 파일 포맷은 박스(또는, atom) 단위로 구성되며, 트리(tree) 형태의 구조를 갖는다. 하나의 박스는 최소 8 바이트의 크기를 가질 수 있고, 첫 번째 4 바이트는 박스의 전체 크기를 나타내고, 이후 4 바이트는 각 박스를 구별하기 위한 ID (타입)의 정보가 저장될 수 있다. 아래 표 1은 ISO 파일 포맷의 박스의 일 예를 나타낸다. 표 1 box 이름 (FourCC) 설명 ftyp ISO 파일 포맷의 기본 헤더 mdat 비디오, 오디오 등, 미디어 데이터 자체 (주로 압축된) moov 저장된 미디어 데이터에 대한 메타데이터 (미디어 재생에 필요한 정보)아래 표 2는 표 1의 moov 박스에 포함되는 박스들의 일 예를 나타낸다. 표 2 box 이름 (FourCC) 설명 mvhd 미디어에 대한 기본 정보 (생성 날짜, 전체 재생 시간 등) trak 한개의 미디어를 대표하는 메타 데이터 (여러개의 trak box가 존재 가능) udta 사용자가 저장한 부가 정보 데이터 일 실시예에 따르면, 코덱의 메타데이터는 trak 박스에 포함될 수 있다. 예를 들면, 코덱의 메타데이터를 포함 하며, 비디오와 오디오가 한 개씩 존재하는 미디어 파일인 경우, 비디오 한 개에 대한 trak 박스, 오디오 한 개 에 대한 trak 박스 및 코덱의 메타데이터에 대한 trak 박스, 총 3개의 trak 박스가 moov 박스 내에 포함될 수 있다. 다만, 실시예가 이에 한정되지 않고, 비디오, 오디오 및 메타데이터에 대한 trak 박스의 수는 다양하게 설정될 수 있다. 일 실시예에 따르면, trak 박스는 하나 이상의 박스를 포함할 수 있다. 예를 들면, trak 박스는 해당 trak의 미 디어 정보를 복호화하기 위해 필요한 코덱 정보를 저장하는 stsd 박스를 포함할 수 있다. 코덱의 메타데이터는 stsd 박스에 포함될 수 있다. 예를 들면, 도 36에 예시된 것처럼, trak 박스는 mdia 박스를 포함하고, mdia 박 스는 minf 박스를 포함하고, minf 박스는 stbl 박스를 포함하고, stbl 박스는 stsd 박스 및/또는 stts 박스를 포함하고, stsd 박스는 코덱의 메타데이터를 포함하는 aicm 박스를 포함할 수 있다. 다만, 코덱의 메타데이터를 포함하는 박스의 명칭 및 구조는 다양한 변형이 가능할 수 있다. 일 실시예에 따르면, stts 박스는 타임스탬프 정보를 포함할 수 있다. 예를 들면, 코덱의 메타데이터와 비디오 코덱의 연동이 필요한 경우, 비디오 데이터와 메타데이터의 시간 동기화를 위해 타임스탬프 정보가 코덱 메타데 이터에 대한 trak 내의 stts 박스 및 비디오에 대한 trak 내의 stts 박스 내에 각각 포함될 수 있다. 이 경우, 각 trak 내의 stts 박스에 포함된 타임스탬프 정보는 비디오 데이터와 코덱 메타데이터의 동기화를 위해 동일한 값으로 설정될 수 있다. 일 실시예에 따르면, 코덱 메타데이터(예: AI 코덱 메타데이터)는 예컨대, 전처리에 관련된 정보(예: 프레임 스 킵 정보) 및/또는 레이턴트 벡터 데이터(예: 도 39a 및 39b의 레이턴트 벡터 데이터, 도 40a 및 40b의 레이턴트 벡터 데이터)를 포함할 수 있다. 일 실시예에 따르면, 코덱 메타데이터(예: AI 코덱 메타데이터)는 ISO 파일 포맷의 trak 박스에 저장될 수 있다. 코덱 메타데이터는 비디오 데이터에 대한 trak 및 오디오 데이터에 대한 trak과 별개의 trak에 저장될 수 있다. 예를 들면, 코덱 메타데이터는 메타데이터에 대한 trak 내의 stsd 박스에 포함될 수 있다. 일 예로, 코덱 메타데이터는 메타데이터에 대한 trak 내의 stsd 박스 내의 aicm 박스에 포함될 수 있다. 일 실시예에 따르면, 코덱 메타데이터에 대한 trak 박스의 수는 비디오 데이터에 대한 trak 박스의 수와 동일할 수 있다. 일 실시예에 따르면, 코덱 메타데이터에 대한 trak 박스 내의 stts 박스의 타임스탬프 정보의 값은 대응하는 비 디오 데이터에 대한 trak 박스 내의 stts 박스의 타임스탬프 정보의 값과 동일한 값으로 설정될 수 있다. 일 실시예에 따르면, 영상 수신 장치는 코덱 메타데이터에 대한 trak에 포함된 코덱 메타데이터를 디코딩(또는, 획득)하고, 코덱 메타데이터를 이용하여 미디어 데이터(예: 비디오 데이터)를 재생할 수 있다. 도 37 및 38은 본 개시의 일 실시예에 따른, 미디어 데이터 및 메타 데이터를 전송하는 방법을 예시하는 도면이 다. 도 37을 참조하면, 각 프레임에 대한 미디어 데이터(예: 비디오 데이터) 및 연관된 시그널링 메시지(예: SEI(supplemental enhancement information) 메시지)가 함께 전송될 수 있다. 일 실시예에 따르면, SEI 메시지의 데이터는 해당 프레임에 대한 비디오 데이터 이후에 전송될 수 있다(suffix 케이스). 예를 들면, 도 37의 (a) 부분에 예시된 것처럼, 제1 프레임(예: i 번째 프레임)에 대한 데이터(또는, 컨테이너)는 제1 프레임의 비디오 데이터 및 NUH(NAL unit header)를 포함하는 제1 유닛 및 연관된 SEI 메시지 의 데이터 및 NUH를 포함하는 제2 유닛을 포함하고, 제2 유닛은 제1 유닛에 후행할 수 있다. 제1 프레임(예: i번째 프레임)에 후행하는 제2 프레임(예: i+1 번째 프레임)에 대한 데이터(또는, 컨테이너)는 제2 프레임의 비 디오 데이터 및 NUH(NAL unit header)를 포함하는 제1 유닛 및 연관된 SEI 메시지의 데이터 및 NUH를 포함하는 제2 유닛을 포함하고, 제2 유닛은 제1 유닛에 후행할 수 있다. 일 실시예에 따르면, SEI 메시지의 데이터는 해당 프레임에 대한 비디오 데이터 이전에 전송될 수 있다(prefix 케이스). 예를 들면, 도 37의 (b) 부분에 예시된 것처럼, 제1 프레임(예: i 번째 프레임)에 대한 데이터(또는, 컨테이너)는 제1 프레임의 비디오 데이터 및 NUH(NAL unit header)를 포함하는 제1 NAL 유닛 및 연관된 SEI 메 시지의 데이터 및 NUH를 포함하는 제2 NAL 유닛을 포함하고, 제2 NAL 유닛은 제1 NAL 유닛에 선행할 수 있다. 제1 프레임(예: i 번째 프레임)에 후행하는 제2 프레임(예: i+1 번째 프레임)에 대한 데이터(또는, 컨테이너)는 제2 프레임의 비디오 데이터 및 NUH(NAL unit header)를 포함하는 제1 NAL 유닛 및 연관된 SEI 메시지의 데이터 및 NUH를 포함하는 제2 NAL 유닛을 포함하고, 제2 NAL 유닛은 제1 NAL 유닛에 선행할 수 있다. 일 실시예에 따르면, 코덱(예: AI 코덱)의 메타데이터는 해당 프레임에 대한 미디어 데이터(예: 코덱에 의해 인 코딩된 비디오 데이터(코덱 비트스트림))와 함께 전송 될 수 있다. 예를 들면, 코덱 메타데이터는 SEI 메시지 의 데이터가 전송되는 영역에 포함되어 전송될 수 있다. 코덱의 메타데이터는 예컨대, 프레임 스킵 정보 및/또 는 레이턴트 벡터의 데이터를 포함할 수 있다. 일 실시예에 따르면, 코덱 메타데이터는 해당 프레임에 대한 비디오 데이터(예: 코덱 비트스트림) 이후에 전송 될 수 있다(suffix 케이스). 예를 들면, 도 38의 (a) 부분에 예시된 것처럼, 제1 프레임(예: i 번째 프레임)에 대한 데이터(또는, 컨테이너)는 제1 프레임의 비디오 데이터(예: 제1 프레임의 코덱 비트스트림) 및 NUH(NAL unit header)를 포함하는 제1 NAL 유닛 및 연관된 코덱 메타데이터 및 NUH를 포함하는 제2 NAL 유닛을 포함하고, 제2 NAL 유닛은 제1 NAL 유닛에 후행할 수 있다. 제1 프레임(예: i 번째 프레임)에 후행하는 제2 프 레임(예: i+1 번째 프레임)에 대한 데이터(또는, 컨테이너)는 제2 프레임의 비디오 데이터(예: 제2 프레임의 코 덱 비트스트림) 및 NUH(NAL unit header)를 포함하는 제1 NAL 유닛 및 연관된 코덱 메타데이터 및 NUH를 포함하 는 제2 유닛을 포함하고, 제2 NAL 유닛은 제1 NAL 유닛에 후행할 수 있다. 일 실시예에 따르면, 코덱 메타데이터는 해당 프레임에 대한 비디오 데이터(예: 코덱 비트스트림) 이전에 전송 될 수 있다(prefix 케이스). 예를 들면, 도 37의 (b) 부분에 예시된 것처럼, 제1 프레임(예: i 번째 프레임)에 대한 데이터(또는, 컨테이너)는 제1 프레임의 비디오 데이터(예: 제1 프레임의 코덱 비트스트림) 및 NUH(NAL unit header)를 포함하는 제1 NAL 유닛 및 연관된 코덱 메타데이터 및 NUH를 포함하는 제2 NAL 유닛을 포함하고, 제2 NAL 유닛은 제1 NAL 유닛에 선행할 수 있다. 제1 프레임(예: i 번째 프레임)에 후행하는 제2 프 레임(예: i+1 번째 프레임)에 대한 데이터(또는, 컨테이너)는 제2 프레임의 비디오 데이터(예: 제2 프레임의 코 덱 비트스트림) 및 NUH(NAL unit header)를 포함하는 제1 NAL 유닛 및 연관된 코덱 메타데이터 및 NUH를 포함하 는 제2 NAL 유닛을 포함하고, 제2 NAL 유닛은 제1 NAL 유닛에 선행할 수 있다. 일 실시예에 따르면, 코덱 메타데이터가 코덱 비트스트림 이전에 전송되는 경우(prefix 케이스), 코덱 메타데이 터에 대한 NAL 유닛의 NAL unit type 정보는 제1 값(예: 39)으로 설정될 수 있고, 코덱 메타데이터가 코덱 비트 스트림 이후에 전송되는 경우(suffix 케이스), 코덱 메타데이터에 대한 NAL 유닛의 NAL unit type 정보는 제2 값(예: 40)으로 설정될 수 있다. NAL unit type 정보는, 예컨대, 코덱 메타데이터에 대한 NAL 유닛의 NUH에 포 함될 수 있다. 아래 표 3은 코덱 메타데이터가 포함되는 SEI 메시지의 syntax를 예시한다. 표 3"}
{"patent_id": "10-2025-0050858", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "표 3을 참조하면, SEI 메시지는 payloadType 필드(정보), payloadSize 필드(정보) 및 sei_payload 필드(정보) 를 포함할 수 있다. 일 실시예에 따르면, 코덱 메타데이터(예: AI 코덱 메타데이터)는 예컨대, 전처리에 관련된 정보(예: 프레임 스 킵 정보) 및/또는 레이턴트 벡터 데이터(예: 도 39a 및 39b의 레이턴트 벡터 데이터, 도 40a 및 40b의 레이턴트 벡터 데이터)를 포함할 수 있다. 일 실시예에 따르면, 코덱 메타데이터는 sei_payload 필드에 포함될 수 있다. 코덱 메타데이터가 sei_payload 필드에 포함되는 경우, payloadType 필드는 SEI 메시지(또는, sei_payload 필드)에 코덱 메타데이터가 포함됨을 지시하는 값(예: 500)으로 설정될 수 있고, payloadSize 필드는 sei_payload 필드에 포함되는 코덱 메타데이터 의 크기(예: 바이트 크기)를 지시하는 값으로 설정될 수 있다. 아래 표 4는 코덱 메타데이터(예: AI 코덱 메타데이터)를 포함하는 sei_payload 필드를 예시하고, 표 5는 sei_payload 필드에 포함되는 코덱 메타데이터를 예시한다. 표 4 표 5"}
{"patent_id": "10-2025-0050858", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "표 4를 참조하면, sei_payload 필드는 코덱 메타데이터(예: AI 코덱 메타데이터)를 포함하는 코덱 메타데이터 필드(예: ai_codec_metadata 필드)를 포함할 수 있다. 표 5를 참조하면, ai_codec_metadata 필드는 ai_codec_frame_skip_flag 필드를 포함할 수 있다. ai_codec_frame_skip_flag 필드는 해당 프레임의 비디오 데이터가 스킵되었는지 여부를 지시할 수 있다. ai_codec_frame_skip_flag 필드가 해당 프레임의 비디오 데이터가 스킵됨을 지시하는 경우(예: ai_codec_frame_skip_flag 필드 = 1), ai_codec_metadata 필드는 metadata_block 필드를 포함할 수 있다. metadata_block 필드는 해당 프레임에서 스킵된 적어도 하나의 블록을 지시하는 정보를 포함할 수 있다. 일 실시예에 따르면, 영상 수신 장치는 코덱 메타데이터의 앞 또는 뒤에 있는 SEI 메시지를 디코딩하여, SEI 메 시지에 포함된 코덱 메타데이터를 획득할 수 있다. 일 실시예에 따르면, 코덱 메타데이터가 SEI 메시지에 포함되는 경우, SEI 메시지의 payloadType 필드는 SEI 메 시지(또는, sei_payload 필드)에 코덱 메타데이터가 포함됨을 지시하는 값(예: 500)으로 설정될 수 있다. 일 실시예에 따르면, 영상 수신 장치는 SEI 메시지에 포함된 코덱 메타데이터에 포함된 플래그 필드(예: ai_codec_frame_skip_flag)의 값을 이용하여, 해당 프레임의 비디오 데이터가 스킵되었는지 여부를 판단할 수 있고, metadata_block 필드의 값을 이용하여 해당 프레임에서 스킵된 블록을 식별할 수 있다. 도 39a 및 39b는 본 개시의 일 실시예에 따른, 슈퍼 레졸루션 절차를 예시하는 도면이다. 도 39a 및 39b에서는, 도 1 내지 도 38에서 상술한 설명과 중복된 설명은 생략한다. 일 실시예에 따르면, 슈퍼 레졸루션 절차는 영상 송신 장치(예: 도 1a/b/c의 영상 송신 장치)에 의해 수행 되는 동작 및 영상 수신 장치(예: 도 1a/b/c의 영상 수신 장치)에 의해 수행되는 동작을 포 함할 수 있다. 도 39a를 참조하면, 영상 송신 장치는 다운 샘플링된 비디오 데이터(예: 저화질/저용량 비디오)를 획득 할 수 있다. 영상 송신 장치는 코덱 처리부(예: 도 1c의 코덱 처리부(113a))를 이용하여, 다운 샘플링된 비디오 데이터를 부호화 처리하여, 부호화된 비디오 데이터(예: 코덱 비트스트림)을 획득하고, 부호화된 비디오 데이터를 비트스트림 전달부(예: 도 1c의 영상 출력부(114a))로 전달할 수 있다. 영상 송신 장치 는 코덱 처리부(예: 도 1c의 코덱 처리부(113a))를 이용하여, 다운 샘플링된 비디오 데이터를 부 호화 및 복호화 처리하여, 부호화 및 복호화된 비디오 데이터(예: 압축된 복호화 비디오=디코딩 된 비디 오)를 획득할 수 있다. 영상 송신 장치는 부호화 및 복호화된 비디오 데이터에 대한 해상도 보간을 수행 하여, 해상도 보간된 비디오 데이터를 획득할 수 있다. 영상 송신 장치는 원본 비디오 데이터 및 해상도 보간된 비디오 데이터의 차이를 계산하고, 차이에 기초하여 손실 데이터를 획득할 수 있 다. 영상 송신 장치는 손실 데이터를 기초로, 미리 학습된 모델(예: 레이턴트 인코더)을 이용하 여, 레이턴트 벡터 데이터를 생성하고, 레이턴트 벡터 데이터를 비트스트림 전달부로 전 달할 수 있다. 영상 송신 장치는 비트스트림 전달부를 이용하여 부호화된 비디오 데이터(예: 코덱 비트 스트림) 및 레이턴트 벡터 데이터를 영상 수신 장치로 전송할 수 있다. 비트스트림 전달부는 부 호화된 비디오 데이터, 및 레이턴트 벡터 데이터를 포함하는 최종 비트 스트림을 하나의 컨테이너에 포함되어 전송될 수 있다. 예를 들면, 도 38에 예시된 것처럼, 레이턴트 벡터 데이터는 코덱 메타데이터(예: AI 코덱 메 타데이터)로서 SEI 메시지에 포함되어, 부호화된 비디오 데이터의 이전 또는 이후에 전송될 수 있다. 영상 수신 장치는 부호화된 비디오 데이터(예: 코덱 비트스트림) 및 레이턴트 벡터 데이터를 비트 스트 림 수신부(예: 도 1c의 영상 입력부(221a))를 이용하여 수신할 수 있다. 비트 스트림 수신부는 레이턴트 벡터 데이터를 SR 모델로 전달하고, 부호화된 비디오 데이터(예: 코덱 비트스트림)를 코덱 처리부(예: 도 1c의 코덱 처리부(122a))로 전달할 수 있다. 영상 수신 장치는 코덱 처리부 를 이용하여 부호화된 비디오 데이터를 복호화 처리하여, 복호화된 비디오 데이터를 획득할 수 있다. 영 상 수신 장치는 레이턴트 벡터 데이터 및 복호화된 비디오 데이터를 기초로, SR 모델을 이용하여, 복원된 비디오 데이터(예: 복원된 고해상도 비디오)를 획득할 수 있다 도 39b의 실시예에서는, 도 39a의 실시예와 달리, GoP 인핸스먼트 처리가 슈퍼 레졸루션 절차에서 수행될 수 있 다. 도 39b에서는 도 39a에서 상술한 설명과 중복된 설명은 생략한다. 도 39b를 참조하면, 영상 송신 장치에서 GoP 인핸스먼트 처리는 부호화 및 복호화 처리된 비디오 데이터(3910 5)에 대해 수행될 수 있다. 이를 통해, 영상 수신 장치는 GoP 인핸스먼트 처리된 비디오 데이터를 획득 할 수 있고, GoP 인핸스먼트 처리된 비디오 데이터에 대한 해상도 보간을 수행하여, 해상도 보간된 비디 오 데이터를 획득할 수 있다. 영상 수신 장치에서 GoP 인핸스먼트 처리는 복호화 처리된 비디오 데이터에 대해 수행될 수 있다. 이를 통해, 영상 수신 장치는 GoP 인핸스먼트 처리된 비디오 데이터를 획득할 수 있고, GoP 인핸스먼트 처리 된 비디오 데이터를 SR 모델의 입력 데이터로서 사용할 수 있다. 도 40a 및 40b는 본 개시의 일 실시예에 따른, 프레임 스킵핑 절차를 예시하는 도면이다. 도 40a 및 40b에서는, 도 1 내지 도 38에서 상술한 설명과 중복된 설명은 생략한다. 일 실시예에 따르면, 프레임 스킵핑 절차는 영상 송신 장치(예: 도 1a/b/c의 영상 송신 장치)에 의해 수행 되는 동작 및 영상 수신 장치(예: 도 1a/b/c의 영상 수신 장치)에 의해 수행되는 동작을 포 함할 수 있다. 도 40a을 참조하면, 영상 송신 장치는 복수의 프레임을 포함하는 원본 영상 데이터(예: 원본 비디오)을 획득하고, 획득된 원본 영상 데이터을 프레임 스킵핑 처리부(예: 도 3의 프레임 스킵핑 처리 모 듈)로 전달할 수 있다. 영상 송신 장치는 프레임 스킵 처리부를 이용하여 복수의 프레임 중 적어도 하나의 프레임 또는 적어도 하나의 프레임에 포함된 블록들 중 적어도 하나를 스킵할 수 있다. 프레임 스킵 처 리부는 스킵된 영상 데이터를 레이턴트 벡터 생성 모델로 전달하고, 스킵되고 남은 영상 데이터 를 코덱 처리부(예: 도 1c의 코덱 처리부(113a))로 전달할 수 있다. 프레임 스킵 처리부(4010 3)는 프레임 스킵 정보를 비트 스트림 전달부(예: 도 1c의 영상 출력부(114a))로 전달할 수 있다. 영상 송신 장치는 영상 데이터를 코덱 처리부를 이용하여 부호화 처리하여, 부호화된 영상 데이터(예: 코덱 비트스트림)를 획득하고, 비트 스트림 전달부로 전달할 수 있다. 영상 송신 장치는 영상 데이터 를 코덱 처리부를 이용하여 부호화 및 복호화 처리하여, 부호화 및 복호화된 영상 데이터 (예: 압축되고 복호화된 영상)를 획득할 수 있다. 영상 송신 장치는 스킵된 영상 데이터 및 부호화/복호 화된 영상 데이터를 기초로, 레이턴트 벡터 생성 모델을 이용하여, 레이턴트 벡터 데이터(4011 3)를 획득할 수 있다. 레이턴트 벡터 데이터는 스킵된 프레임 또는 스킵된 블록(들)을 복원하기 위해 사 용되는 정보가 포함될 수 있다. 영상 송신 장치는 비트 스트림 전달부를 이용하여 부호화된 영상 데이터 (예: 코덱 비트스트림), 레이턴트 벡터 데이터 및 프레임 스킵 정보를 영상 수신 장치로 전송할 수 있다. 비트 스트림 전달부는 부호화된 영상 데이터(예: 코덱 비트스트림), 레이턴트 벡터 데이터 및 프레임 스킵 정보를 포함하는 최종 비트 스트림을 하나의 컨테이너에 포함하여 전송할 수 있다. 예를 들면, 도 38에 예시된 것처럼, 레이턴트 벡터 데이터 및 프레임 스킵 정보는 코덱 메타데이터(예: AI 코덱 메타데이터)로서 SEI 메시지에 포함되어, 부호화된 비디오 데이터의 이전 또는 이후에 전송될 수 있다. 영상 수신 장치는 부호화된 영상 데이터(예: 코덱 비트스트림), 프레임 스킵 정보 및 레이턴트 벡터 데이터 를 비트 스트림 수신부(예: 도 1c의 영상 입력부(221a))를 이용하여 수신할 수 있다. 비트 스트 림 수신부는 레이턴트 벡터 데이터 및 프레임 스킵 정보를 프레임 보간 모델로 전달하고, 부호화된 영상 데이터(예: 코덱 비트스트림)를 코덱 처리부(예: 도 1c의 코덱 처리부(122a))로 전달할 수 있다. 영상 수신 장치는 코덱 처리부를 이용하여 부호화된 영상 데이터를 복호화 처리하여, 복호화된 비디오 데이터를 획득할 수 있다. 영상 수신 장치는 프레임 스킵 정보, 레이턴트 벡터 데이터 및 복호화된 영상 데이터를 기초로, 프레임 보간 모델을 이용하여, 복원된 영상 데이터(예: 복원된 고해상도 비디오)를 획득할 수 있다. 프레임 보간 모델은 프레임 보간을 통해 원본 영상을 복원 하기 위해 사용될 수 있다.도 40b의 실시예에서는, 도 40a의 실시예와 달리, GoP 인핸스먼트 처리가 프레임 스킵핑 절차에서 수행될 수 있 다. 도 40b에서는 도 40a에서 상술한 설명과 중복된 설명은 생략한다. 도 40b를 참조하면, 영상 송신 장치에서 GoP 인핸스먼트 처리는 부호화 및 복호화 처리된 영상 데이터에 대해 수행될 수 있다. 이를 통해, 영상 수신 장치는 GoP 인핸스먼트 처리된 영상 데이터를 획득할 수 있 고, GoP 인핸스먼트 처리된 비디오 데이터를 레이턴트 벡터 생성 모델의 입력 데이터로서 사용할 수 있다. 영상 수신 장치에서 GoP 인핸스먼트 처리는 복호화 처리된 영상 데이터에 대해 수행될 수 있다. 이를 통 해, 영상 수신 장치는 GoP 인핸스먼트 처리된 영상 데이터를 획득할 수 있고, GoP 인핸스먼트 처리된 영 상 데이터를 레이턴트 벡터 생성 모델의 입력 데이터로서 사용할 수 있다. 본 개시의 일 실시예에 따른, 영상 송신 장치는 제1 이미지 프레임 및 제2 이미지 프레임을 포함하는 제1 이미 지 데이터를 획득하는 동작; 상기 제1 이미지 프레임에 대한 프레임 스킵핑(frame skipping)을 적용할지 여부를 결정하는 동작; 상기 제1 이미지 프레임에 대한 프레임 스킵핑을 적용함이 결정되는 경우, 상기 제1 이미지 프 레임의 데이터를 스킵하는 동작; 상기 제1 이미지 데이터에서 상기 스킵된 데이터가 제외된 이미지 데이터인 제 2 이미지 데이터를 부호화(encode)하는 동작; 상기 제2 이미지 데이터 및 제3 이미지 데이터를 이용하여, 레이 턴트 벡터 데이터를 생성하는 동작, 상기 제3 이미지 데이터는 상기 스킵된 데이터를 포함하며; 및 상기 부호화 된 제2 이미지 데이터, 프레임 스킵핑 관련 정보 및 상기 레이턴트 벡터 데이터를 전송하는 동작을 수행할 수 있다. 상기 프레임 스킵핑 관련 정보는 상기 제1 이미지 프레임에 대한 프레임 스킵핑이 적용됨을 지시하는 제1 정보를 포함할 수 있다. 일 실시예에 따르면, 상기 부호화된 제2 이미지 데이터는 부호화된 제2 이미지 프레임의 데이터를 포함하고, 상 기 프레임 스킵핑 관련 정보는 상기 제2 이미지 프레임에 대한 프레임 스킵핑이 적용되지 않음을 지시하는 제2 정보를 포함할 수 있다. 상기 전송하는 동작은: 상기 제1 이미지 프레임과 연관된 제1 컨테이너 및 상기 제2 이 미지 프레임과 연관된 제2 컨테이너를 전송하는 동작을 포함하고, 상기 제2 컨테이너는, 상기 부호화된 제2 이 미지 프레임의 데이터를 포함하는 제1 유닛; 및 상기 제2 이미지 프레임과 연관된 시그널링 메시지의 데이터를 포함하는 제2 유닛을 포함하고, 상기 시그널링 메시지는 상기 레이턴트 벡터 데이터의 적어도 일부 및 상기 제2 정보 중 적어도 하나를 포함할 수 있다. 일 실시예에 따르면, 상기 부호화된 제2 이미지 데이터는 상기 제1 이미지 프레임에서 상기 프레임 스킵핑이 적 용되지 않은 적어도 하나의 제1 블록을 부호화하여 생성된 부호화된 블록 데이터를 포함하고, 상기 프레임 스킵 핑 관련 정보는, 상기 제1 이미지 프레임에서 상기 프레임 스킵핑이 적용된 적어도 하나의 제2 블록을 지시하는 제3 정보를 더 포함하고, 상기 제1 컨테이너는, 상기 부호화된 블록 데이터를 포함하는 제1 유닛; 및 상기 제1 이미지 프레임과 연관된 시그널링 메시지의 데이터를 포함하는 제2 유닛을 포함하고, 상기 시그널링 메시지는 상기 레이턴트 벡터 데이터의 적어도 일부 및 상기 제1 정보 및 상기 제3 정보 중 적어도 하나를 포함할 수 있 다. 일 실시예에 따르면, 상기 제1 유닛 및 상기 제2 유닛은, NAL(network abstraction layer) 유닛에 해당하고, 상기 시그널링 메시지는 SEI(supplemental enhancement information) 메시지에 해당하고, 상기 SEI 메시지는: 상기 레이턴트 벡터 데이터의 적어도 일부 및 상기 제1 정보 및 상기 제2 정보 중 적어도 하나를 포함하는 메타 데이터가 상기 SEI 메시지 또는 상기 SEI 메시지의 페이로드에 포함됨을 지시하는 정보를 포함할 수 있다. 일 실시예에 따르면, 상기 프레임 스킵핑을 적용할지 여부를 결정하는 동작은: 이미지 데이터의 부호화를 위해 설정된 파라미터에 기초하여, 복수의 인공지능 모델로부터 인공지능 모델을 선택하는 동작; 및 상기 선택된 인 공지능 모델을 이용하여, 상기 프레임 스킵핑을 적용할지 여부를 결정하는 동작을 포함하고, 상기 제2 이미지 데이터를 부호화하는 동작은: 상기 부호화를 위해 설정된 파라미터를 이용하여, 상기 제2 이미지 데이터를 부호 화하는 동작을 포함하며, 상기 부호화를 위한 파라미터는 상기 이미지 데이터의 압축 률과 연관될 수 있다. 일 실시예에 따르면, 상기 인공지능 모델은 동일한 비트 율(bit rate)에서의 제1 왜곡 및 제2 왜곡의 차이와 연 관되는 거리를 출력하도록 설정되며, 상기 제1 왜곡은 상기 제1 이미지 프레임에 대한 프레임 스킵핑이 적용된 제1 이미지 프레임 세트와 연관되며, 상기 제2 왜곡은 상기 제1 이미지 프레임에 대한 프레임 스킵핑이 적용되 지 않은 제2 이미지 프레임 세트와 연관되며, 상기 제1 이미지 프레임 세트는 상기 제1 이미지 프레임의 이전 프레임인 상기 제2 이미지 프레임 및 상기 제1 이미지 프레임의 이후 이미지 프레임인 제3 이미지 프레임을 포 함하며, 상기 제2 이미지 프레임 세트는 상기 제1 이미지 프레임, 상기 제2 이미지 프레임 및 상기 제3 이미지프레임을 포함할 수 있다. 일 실시예에 따르면, 상기 제1 이미지 프레임에 대한 프레임 스킵핑을 적용할지 여부를 결정하는 동작은: 상기 제1 이미지 프레임, 상기 제1 이미지 프레임의 이전 프레임인 상기 제2 이미지 프레임 및 상기 제1 이미지 프레 임의 이후 이미지 프레임인 제3 이미지 프레임을 부호화 및 복호화하는 동작; 상기 부호화 및 복호화된 제1 이 미지 프레임, 상기 부호화 및 복호화된 제2 이미지 프레임 및 상기 부호화 및 복호화된 제3 이미지 프레임을 입 력 데이터로서 상기 인공지능 모델에 입력하고, 상기 인공지능 모델의 출력 데이터로서 상기 거리를 획득하는 동작; 및 상기 거리에 기초하여, 상기 제1 이미지 프레임에 대한 프레임 스킵핑을 적용할지 여부를 결정하는 동 작을 포함하며, 상기 거리는 상기 제1 왜곡에서 상기 제2 왜곡을 뺀 값에 대응하고, 상기 거리에 기초하여, 상 기 제1 이미지 프레임에 대한 프레임 스킵핑을 적용할지 여부를 결정하는 동작은: 상기 거리가 음수인 경우, 상 기 제1 이미지 프레임에 대한 프레임 스킵핑을 적용함을 결정하고, 상기 거리가 양수인 경우, 상기 제1 이미지 프레임에 대한 프레임 스킵핑을 적용하지 않음을 결정할 수 있다. 일 실시예에 따르면, 상기 인공지능 모델은 복수의 학습 데이터 세트에 기초하여 학습되고, 상기 복수의 학습 데이터 세트의 각각은, 이미지 프레임 세트를 획득하는 동작, 상기 이미지 프레임 세트를 상기 부호화를 위한 파라미터의 설정 가능한 값들의 각각에 대하여 제1 영상 처리하여 제1 율 왜곡 데이터를 획득하는 동작, 상기 프레임 스킵핑이 적용된 이미지 프레임 세트를 상기 부호화를 위한 타겟 파라미터의 값에 대하여 제2 영상 처리 하여 제2 율 왜곡 데이터를 획득하는 동작, 및 상기 제1 율 왜곡 데이터 및 상기 제2 율 왜곡 데이터에 기초하 여 거리를 획득하는 동작의 수행에 기초하여 획득되며, 상기 제1 영상 처리는, 부호화 처리, 및 복호화 처리를 포함하고, 상기 제2 영상 처리는, 부호화 처리, 복호화 처리, 프레임 보간 처리 및 품질 향상 처리를 포함할 수 있다. 일 실시예에 따르면, 상기 레이턴트 벡터 데이터를 생성하는 동작은: 상기 제2 이미지 데이터에 대한 부호화 및 복호화를 수행하는 동작; 상기 제3 이미지 데이터와 상기 부호화 및 복호화된 이미지 데이터에 기초하여, 손실 데이터를 획득하는 동작; 및 상기 손실 데이터를 기초로, 인공지능 모델을 이용하여, 레이턴트 벡터 데이터를 생성하는 동작을 포함할 수 있다. 일 실시예에 따르면, 상기 레이턴트 벡터 데이터를 생성하는 동작은: 상기 제2 이미지 데이터를 다운 샘플링하 여, 다운 샘플링된 이미지 데이터를 획득하는 동작; 상기 다운 샘플링된 이미지 데이터를 부호화 및 복호화하는 동작; 상기 부호화 및 복호화된 이미지 데이터에 대한 해상도 보간을 수행하여, 해상도 보간된 이미지 데이터를 획득하는 동작; 상기 제3 이미지 데이터와 상기 해상도 보간된 이미지 데이터에 기초하여, 손실 데이터를 획득 하는 동작; 및 상기 손실 데이터를 기초로, 인공지능 모델을 이용하여, 레이턴트 벡터 데이터를 생성하는 동작 을 포함할 수 있다. 일 실시예에 따르면, 상기 손실 데이터를 획득하는 동작은: 상기 제1 이미지 데이터에 포함되는 제1 프레임과 상기 해상도 보간된 이미지 데이터에 포함되는 상기 제1 프레임에 대응하는 제2 프레임으로 구성된 프레임 쌍에 대한 미리 설정된 단위의 차이를 계산함으로써 상기 손실 데이터를 획득하는 동작을 포함하며, 상기 미리 설정 된 단위는 화소 단위에 해당할 수 있다. 본 개시의 일 실시예에 따른, 영상 수신 장치는 부호화된 이미지 데이터, 프레임 스킵핑 관련 정보 및 레이턴트 벡터 데이터를 수신하는 동작, 상기 부호화된 이미지 데이터는 제1 이미지 프레임 및 제2 이미지 프레임을 포함 하는 이미지 데이터를 부호화하여 생성되며; 상기 부호화된 이미지 데이터를 복호화하는 동작; 및 상기 프레임 스킵핑 관련 정보 및 상기 레이턴트 벡터 데이터에 기초하여, 상기 복호화된 이미지 데이터를 처리하는 동작을 포함하며, 상기 프레임 스킵핑 관련 정보는 상기 제1 이미지 프레임에 대한 프레임 스킵핑이 적용되는지 여부를 지시하는 제1 정보를 포함할 수 있다. 일 실시예에 따르면, 상기 부호화된 이미지 데이터는 부호화된 제2 이미지 프레임의 데이터를 포함하고, 상기 프레임 스킵핑 관련 정보는 상기 제2 이미지 프레임에 대한 프레임 스킵핑이 적용되지 않음을 지시하는 제2 정 보를 포함하고, 상기 수신하는 동작은: 상기 제1 이미지 프레임과 연관된 제1 컨테이너 및 상기 제2 이미지 프 레임과 연관된 제2 컨테이너를 수신하는 동작을 포함하고, 상기 제2 컨테이너는, 상기 부호화된 제2 이미지 프 레임의 데이터를 포함하는 제1 유닛; 및 상기 제2 이미지 프레임과 연관된 시그널링 메시지의 데이터를 포함하 는 제2 유닛을 포함하고, 상기 시그널링 메시지는 상기 레이턴트 벡터 데이터의 적어도 일부 및 상기 제2 정보 중 적어도 하나를 포함할 수 있다. 일 실시예에 따르면, 상기 부호화된 이미지 데이터는 상기 제1 이미지 프레임에서 상기 프레임 스킵핑이 적용되 지 않은 적어도 하나의 제1 블록을 부호화하여 생성된 부호화된 블록 데이터를 포함하고, 상기 프레임 스킵핑 관련 정보는, 상기 제1 이미지 프레임에서 상기 프레임 스킵핑이 적용된 적어도 하나의 제2 블록을 지시하는 제 3 정보를 더 포함하고, 상기 제1 컨테이너는, 상기 부호화된 블록 데이터를 포함하는 제1 유닛; 및 상기 제1 이 미지 프레임과 연관된 시그널링 메시지의 데이터를 포함하는 제2 유닛을 포함하고, 상기 시그널링 메시지는 상 기 레이턴트 벡터 데이터의 적어도 일부 및 상기 제1 정보 및 상기 제3 정보 중 적어도 하나를 포함할 수 있다. 일 실시예에 따르면, 상기 제1 유닛 및 상기 제2 유닛은, NAL(network abstraction layer) 유닛에 해당하고, 상기 시그널링 메시지는 SEI(supplemental enhancement information) 메시지에 해당하고, 상기 SEI 메시지는: 상기 레이턴트 벡터 데이터의 적어도 일부 및 상기 제1 정보 및 상기 제2 정보 중 적어도 하나를 포함하는 메타 데이터가 상기 SEI 메시지 또는 상기 SEI 메시지의 페이로드에 포함됨을 지시하는 정보를 포함할 수 있다. 일 실시예에 따르면, 상기 복호화된 이미지 데이터를 처리하는 동작은: 상기 프레임 스킵핑 관련 정보에 기초하 여, 상기 이미지 데이터에 포함된 복수의 이미지 프레임에 대한 프레임 보간을 적용할지 여부를 결정하는 동작; 상기 복수의 이미지 프레임에 대한 프레임 보간을 적용함이 결정되는 경우, 상기 복수의 이미지 프레임을 기초 로 제1 인공지능 모델을 이용하여 상기 제1 이미지 프레임이 보간된 이미지 데이터를 획득하는 동작; 및 상기 제1 이미지 프레임이 보간된 이미지 데이터를 기초로 제2 인공지능 모델을 이용하여 향상된 이미지 데이터를 획 득하는 동작을 포함할 수 있다. 일 실시예에 따르면, 상기 복호화된 이미지 데이터를 처리하는 동작은, 상기 레이턴트 벡터 데이터를 기초로, 인공지능 모델을 이용하여, 해상도가 향상된 이미지 데이터를 생성하는 동작을 포함하며, 상기 레이턴트 벡터 데이터는 복호화된 이미지 데이터의 복원을 위해 사용되는 손실 데이터에 기초하여 생성되고, 상기 손실 데이터 는 연관되는 프레임 쌍에 대한 미리 설정된 단위의 차이를 계산함으로써 획득되며, 상기 미리 설정된 단위는 화 소 단위에 해당할 수 있다. 일 실시예에 따르면, 상기 복호화된 이미지 데이터를 처리하는 동작은: 상기 이미지 데이터에 포함된 제1 프레 임 그룹의 제1 프레임 및 상기 제1 프레임 그룹에 후행하는 제2 프레임 그룹의 제2 프레임을 획득하는 동작; 및 상기 제1 프레임 및 상기 제2 프레임을 기초로, 상기 제1 프레임 그룹의 연속된 복수의 프레임에 대한 복수의 복원된(reconstructed) 프레임을 획득하는 동작을 포함하며, 상기 제1 프레임 및 상기 제2 프레임은 독립적으로 (independently) 부호화 및 복호화된 프레임에 해당하고, 상기 복수의 프레임은 상기 제1 프레임을 기초로 예측 적으로(predictively) 부호화 및 복호화된 프레임에 해당할 수 있다. 일 실시예에 따르면, 상기 제1 프레임 그룹은 제1 GoP(group of pictures)에 대응하고, 상기 제2 프레임 그룹은 상기 제1 GoP의 바로 다음의(immediately follow) 제2 GoP에 해당하는, 상기 제1 프레임은 상기 제1 GoP의 첫 번째 프레임인 I 프레임(intra-coded frame)에 해당하고, 상기 제2 프레임은 상기 제2 GoP의 첫 번째 프레임인 I 프레임에 해당하는, 상기 복수의 프레임의 각각은 상기 제1 GoP의 P 프레임(predictive-coded frame) 또는 B 프레임(bi-predictive-coded frame)에 해당할 수 있다. 일 실시예에 따르면, 상기 복수의 복원된 프레임을 생성하는 동작은: 상기 제1 프레임을 상기 복수의 프레임과 얼라인(align)시키기 위한 처리를 수행하여, 복수의 제1 얼라인된 프레임과 연관된 제1 특징 데이터를 획득하는 동작; 상기 제2 프레임을 상기 복수의 프레임과 얼라인시키기 위한 처리를 수행하여, 복수의 제2 얼라인된 프레 임과 연관된 제2 특징 데이터를 생성하는 동작; 및 상기 제1 특징 데이터, 상기 제2 특징 데이터 및 상기 복수 의 프레임에 기초하여, 복수의 복원된 프레임을 생성하는 동작을 포함할 수 있다. 상술한 본 개시의 구체적인 실시 예들에서, 본 개시에 포함되는 구성 요소는 제시된 구체적인 실시 예에 따라 단수 또는 복수로 표현되었다. 그러나, 단수 또는 복수의 표현은 설명의 편의를 위해 제시한 상황에 적합하게 선택된 것으로서, 본 개시가 단수 또는 복수의 구성 요소에 제한되는 것은 아니며, 복수로 표현된 구성 요소라 하더라도 단수로 구성되거나, 단수로 표현된 구성 요소라 하더라도 복수로 구성될 수 있다. 한편 본 개시의 상세한 설명에서는 구체적인 실시 예에 관해 설명하였으나, 본 개시의 범위에서 벗어나지 않는 한도 내에서 여러 가지 변형이 가능함은 물론이다. 그러므로 본 개시의 범위는 설명된 실시 예에 국한되어 정해 져서는 아니 되며 후술하는 특허청구의 범위뿐만 아니라 이 특허청구의 범위와 균등한 것들에 의해 정해져야 한 다.도면 도면1a 도면1b 도면1c 도면2a 도면2b 도면3 도면4 도면5 도면6 도면7 도면8a 도면8b 도면9 도면10 도면11 도면12 도면13 도면14 도면15 도면16 도면17 도면18 도면19 도면20 도면21 도면22a 도면22b 도면23 도면24 도면25 도면26 도면27 도면28 도면29 도면30 도면31 도면32 도면33 도면34 도면35 도면36 도면37 도면38 도면39a 도면39b 도면40a 도면40b"}
{"patent_id": "10-2025-0050858", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1a은 본 개시의 일 실시예에 따른, 영상 처리 시스템을 개략적으로 도시한다. 도 1b는 본 개시의 일 실시예에 따른, 영상 송신 장치 및 영상 수신 장치의 개략적인 블록도이다. 도 1c는 본 개시의 일 실시예에 따른, 영상 송신 장치 및 영상 수신 장치의 개략적인 블록도이다. 도 2a는 본 개시의 일 실시예에 따른, 부호화부의 개략적인 블록도이다. 도 2b는 본 개시의 일 실시예에 따른, 복호화부의 개략적인 블록도이다. 도 3은 본 개시의 일 실시예에 따른, 전처리부의 프레임 스킵핑 처리 모듈을 나타낸다. 도 4는 본 개시의 일 실시예에 따른, 프레임 스킵핑 처리 모듈의 동작을 개략적으로 설명한다. 도 5는 본 개시의 일 실시예에 따른, 프레임 스킵핑 처리 방법의 흐름도이다. 도 6은 본 개시의 일 실시예에 따른, 프레임 스킵핑 처리 방법의 프레임 스킵핑 적용 결정 동작을 나타낸다. 도 7은 본 개시의 일 실시예에 따른, 프레임 스킵핑 적용 결정을 위한 모델의 일 예를 나타낸다. 도 8a는 본 개시의 일 실시예에 따른, 율 왜곡 평면 상의 율 왜곡 곡선과 타겟 율 왜곡 지점의 일 예를 나타낸 다. 도 8b는 본 개시의 일 실시예에 따른, 율 왜곡 곡선과 타겟 율 왜곡 지점 사이의 거리의 일 예를 나타낸다. 도 9는 본 개시의 일 실시예에 따른, 율 왜곡 곡선과 타겟 율 왜곡 지점 사이의 거리를 획득하기 위한 방법의 일 예를 나타낸다. 도 10은 본 개시의 일 실시예에 따른, 후처리부의 프레임 보간 처리 모듈 및 품질 향상 처리 모듈을 나타낸다. 도 11은 본 개시의 일 실시예에 따른, 프레임 보간 처리 모듈 및 품질 향상 처리 모듈의 동작을 개략적으로 설 명한다. 도 12는 본 개시의 일 실시예에 따른, 프레임 보간 처리 방법의 흐름도이다. 도 13은 본 개시의 일 실시예에 따른, 프레임 보간 처리를 위한 모델의 일 예를 나타낸다. 도 14는 본 개시의 일 실시예에 따른, 품질 향상 처리를 위한 모델의 일 예를 나타낸다. 도 15는 본 개시의 일 실시예에 따른, 영상 송신 장치의 영상 처리 방법의 흐름도이다. 도 16은 본 개시의 일 실시예에 따른, 영상 수신 장치의 영상 처리 방법의 흐름도이다. 도 17은 본 개시의 일 실시예에 따른, 전처리부의 다운 샘플링 처리 모듈 및 레이턴트 벡터 생성 처리 모듈을 나타낸다. 도 18은 본 개시의 일 실시예에 따른, 다운 샘플링 처리 모듈 및 레이턴트 벡터 생성 처리 모듈의 동작을 개략 적으로 설명한다. 도 19는 본 개시의 일 실시예에 따른, 레이턴트 벡터 생성 방법의 흐름도이다. 도 20은 본 개시의 일 실시예에 따른, 레이턴트 벡터 생성 처리를 위한 모델의 일 예를 나타낸다. 도 21은 본 개시의 일 실시예에 따른, 후처리부의 슈퍼 레졸루션 처리 모듈을 나타낸다. 도 22a는 본 개시의 일 실시예에 따른, 슈퍼 레졸루션 처리 모듈의 동작을 설명한다. 도 22b는 본 개시의 일 실시예에 따른, 슈퍼 레졸루션 처리를 위한 모델의 일 예를 나타낸다. 도 23은 본 개시의 일 실시예에 따른, 이미지 처리 절차의 일 예를 나타낸다. 도 24는 본 개시의 일 실시예에 따른, 영상 송신 장치의 영상 처리 방법의 흐름도이다. 도 25는 본 개시의 일 실시예에 따른, 영상 수신 장치의 영상 처리 방법의 흐름도이다. 도 26은 본 개시의 일 실시예에 따른, 전처리부의 예시적인 구성을 나타낸다. 도 27은 본 개시의 일 실시예에 따른, 후처리부의 예시적인 구성을 나타낸다.도 28은 본 개시의 일 실시예에 따른, 이미지 처리 절차의 일 예를 나타낸다. 도 29는 본 개시의 일 실시예에 따른, 원본 영상과 부호화된 영상을 나타낸다. 도 30은 본 개시의 일 실시예에 따른, 원본 영상의 제1 부분을 시간 순으로 표시한 이미지 및 원본 영상의 제1 부분에 대응하는 부호화된 영상의 제2 부분을 시간 순으로 표시한 이미지를 나타낸다. 도 31은 본 개시의 일 실시예에 따른, 후처리부의 GoP 인핸스먼트 처리 모듈을 나타낸다. 도 32는 본 개시의 일 실시예에 따른, GoP 인핸스먼트 처리 모듈의 동작을 설명한다. 도 33은 본 개시의 일 실시예에 따른, GoP 인핸스먼트 처리 모듈의 얼라인먼트 처리를 위한 절차의 일 예를 나 타낸다. 도 34는 본 개시의 일 실시예에 따른, 영상 수신 장치의 영상 처리 방법의 흐름도이다. 도 35는 본 개시의 일 실시예에 따른, 영상 수신 장치의 얼라인먼트 처리 동작의 흐름도이다. 도 36은 본 개시의 일 실시예에 따른, 코덱의 메타데이터를 저장하기 위한 포맷을 예시하는 도면이다. 도 37 및 38은 본 개시의 일 실시예에 따른, 미디어 데이터 및 메타 데이터를 전송하는 방법을 예시하는 도면이 다. 도 39a 및 39b는 본 개시의 일 실시예에 따른, 슈퍼 레졸루션 절차를 예시하는 도면이다. 도 40a 및 40b는 본 개시의 일 실시예에 따른, 프레임 스킵핑 절차를 예시하는 도면이다."}
