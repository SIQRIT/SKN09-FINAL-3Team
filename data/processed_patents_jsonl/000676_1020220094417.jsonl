{"patent_id": "10-2022-0094417", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0024835", "출원번호": "10-2022-0094417", "발명의 명칭": "디바이스에서 딥러닝 모델의 레이턴시를 예측하는 방법 및 시스템", "출원인": "주식회사 노타", "발명자": "김정호"}}
{"patent_id": "10-2022-0094417", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "적어도 하나의 프로세서를 포함하는 컴퓨터 장치에 의해 수행되는 레이턴시 예측 방법에 있어서,상기 적어도 하나의 프로세서에 의해, 딥러닝 모델을 입력받는 단계; 및상기 적어도 하나의 프로세서에 의해, 레이턴시 조회 테이블에 기초하여 학습된 레이턴시 예측기를 이용하여 상기 입력된 딥러닝 모델의 온 디바이스 레이턴시를 예측하는 단계;를 포함하고,상기 레이턴시 조회 테이블은,단일 신경망 층의 정보와 단일 신경망 층의 엣지 디바이스상에서의 레이턴시 정보를 포함하는레이턴시 예측 방법."}
{"patent_id": "10-2022-0094417", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 레이턴시 조회 테이블에는,단일 신경망 층 딥러닝 모델에 대해 상기 엣지 디바이스에서 측정된 레이턴시와 상기 단일 신경망 층 딥러닝 모델에 대한 정보가 서로 연계되어 저장되는 것을 특징으로 하는 레이턴시 예측 방법."}
{"patent_id": "10-2022-0094417", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 레이턴시 조회 테이블은, 단일 신경망 층 딥러닝 모델을 상기 엣지 디바이스에 따라 컴파일하고, 상기 컴파일된 단일 신경망 층 딥러닝 모델에 대해 상기 엣지 디바이스에서 측정된 레이턴시를 전달받아, 상기단일 신경망 층 딥러닝 모델에 대한 정보와 연계하여 상기 레이턴시 조회 테이블에 저장함으로써, 생성되는 것을 특징으로 하는 레이턴시 예측 방법."}
{"patent_id": "10-2022-0094417", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,상기 레이턴시 조회 테이블은,엣지 디바이스의 종류마다 복수의 단일 신경망 층 딥러닝 모델들 각각에 대한 레이턴시를 저장하도록 생성되는것을 특징으로 하는 레이턴시 예측 방법."}
{"patent_id": "10-2022-0094417", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "공개특허 10-2023-0024835-3-제1항에 있어서,상기 학습된 레이턴시 예측기는,상기 학습된 레이턴시 예측기가 음의 값을 출력하지 않도록 상기 레이턴시 조회 테이블의 레이턴시의 값과 상기레이턴시 예측기의 출력값에 대한 전처리를 통해 학습되는 것을 특징으로 하는 레이턴시 예측 방법."}
{"patent_id": "10-2022-0094417", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서,상기 온 디바이스 레이턴시를 예측하는 단계는,상기 입력된 딥러닝 모델을 단일 신경망 층 단위로 분해하여 단일 신경망 층 딥러닝 모델을 생성하는 단계;상기 단일 신경망 층 딥러닝 모델 각각을 상기 학습된 레이턴시 예측기에 입력하여 상기 엣지 디바이스에서의레이턴시의 예측값을 생성하는 단계; 및상기 단일 신경망 층 딥러닝 모델 각각의 레이턴시의 예측값들을 더해 상기 입력된 딥러닝 모델의 레이턴시를계산하는 단계를 포함하는 것을 특징으로 하는레이턴시 예측 방법."}
{"patent_id": "10-2022-0094417", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에 있어서,상기 학습된 레이턴시 예측기는,부스팅 알고리즘을 이용한 회귀 분석 모형을 포함하는 것을 특징으로 하는레이턴시 예측 방법."}
{"patent_id": "10-2022-0094417", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1 항에 있어서,상기 온 디바이스 레이턴시를 예측하는 단계는,상기 학습된 레이턴시 예측기를 이용하여, 상기 입력된 딥러닝 모델에 포함된 복수의 단일 신경망 층 각각에 대한 레이턴시 예측값을 획득하는 단계를 포함하고,상기 복수의 단일 신경망 층 중 그 정보가 상기 레이턴시 조회 테이블에 포함되지 않은 제1 단일 신경망 층을식별하고, 상기 제1 단일 신경망 층의 정보와 상기 제1 단일 신경망 층에 대한 레이턴시 예측값을 상기 레이턴시 조회 테이블에 추가하여 저장하는 단계;를 더 포함하는 레이턴시 예측 방법."}
{"patent_id": "10-2022-0094417", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "컴퓨터 장치와 결합되어 제1항 내지 제8항 중 어느 한 항의 방법을 컴퓨터 장치에 실행시키기 위해 컴퓨터 판독가능한 기록매체에 저장된 컴퓨터 프로그램."}
{"patent_id": "10-2022-0094417", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "공개특허 10-2023-0024835-4-제1항 내지 제8항 중 어느 한 항의 방법을 컴퓨터 장치에 실행시키기 위한 프로그램이 기록되어 있는 컴퓨터 판독 가능한 기록매체."}
{"patent_id": "10-2022-0094417", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "컴퓨터 장치에서 판독 가능한 명령을 실행하도록 구현되는 적어도 하나의 프로세서를 포함하고,상기 적어도 하나의 프로세서에 의해,딥러닝 모델을 입력받고,레이턴시 조회 테이블에 기초하여 학습된 레이턴시 예측기를 이용하여 상기 입력된 딥러닝 모델의 온 디바이스레이턴시를 예측하고,상기 레이턴시 조회 테이블은,단일 신경망 층의 정보와 단일 신경망 층의 엣지 디바이스상에서의 레이턴시 정보를 포함하는 것을 특징으로 하는컴퓨터 장치."}
{"patent_id": "10-2022-0094417", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항에 있어서,상기 레이턴시 조회 테이블에는,단일 신경망 층 딥러닝 모델에 대해 상기 엣지 디바이스에서 측정된 레이턴시와 상기 단일 신경망 층 딥러닝 모델에 대한 정보가 서로 연계되어 저장되는 것을 특징으로 하는 컴퓨터 장치."}
{"patent_id": "10-2022-0094417", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제11항에 있어서,상기 레이턴시 조회 테이블은, 단일 신경망 층 딥러닝 모델을 상기 엣지 디바이스에 따라 컴파일하고,상기 컴파일된 단일 신경망 층 딥러닝 모델에 대해 상기 엣지 디바이스에서 측정된 레이턴시를 전달받아, 상기단일 신경망 층 딥러닝 모델에 대한 정보와 연계하여 상기 레이턴시 조회 테이블에 저장함으로써, 생성되는 것을 특징으로 하는 컴퓨터 장치."}
{"patent_id": "10-2022-0094417", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제11항에 있어서,상기 온 디바이스 레이턴시를 예측하기 위해, 상기 적어도 하나의 프로세서에 의해,상기 입력된 딥러닝 모델을 단일 신경망 층 단위로 분해하여 단일 신경망 층 딥러닝 모델을 생성하고,상기 단일 신경망 층 딥러닝 모델 각각을 상기 학습된 레이턴시 예측기에 입력하여 상기 엣지 디바이스에서의레이턴시의 예측값을 생성하고,상기 단일 신경망 층 딥러닝 모델 각각의 레이턴시의 예측값들을 더해 상기 입력된 딥러닝 모델의 레이턴시를공개특허 10-2023-0024835-5-계산하는 것을 특징으로 하는 컴퓨터 장치."}
{"patent_id": "10-2022-0094417", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제11 항에 있어서,상기 적어도 하나의 프로세서에 의해,상기 학습된 레이턴시 예측기를 이용하여, 상기 입력된 딥러닝 모델에 포함된 복수의 단일 신경망 층 각각에 대한 레이턴시 예측값을 획득하고,상기 복수의 단일 신경망 층 중 그 정보가 상기 레이턴시 조회 테이블에 포함되지 않은 제1 단일 신경망 층을식별하고, 상기 제1 단일 신경망 층의 정보와 상기 제1 단일 신경망 층에 대한 레이턴시 예측값을 상기 레이턴시 조회 테이블에 추가하여 저장하는컴퓨터 장치."}
{"patent_id": "10-2022-0094417", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "디바이스에서 딥러닝 모델의 레이턴시를 예측하는 방법 및 시스템을 개시한다. 일실시예에 따른 레이턴시 예측 방법은, 딥러닝 모델을 입력받는 단계, 레이턴시 조회 테이블에 기초하여 학습된 레이턴시 예측기를 이용하여 입 력된 딥러닝 모델의 온 디바이스 레이턴시를 예측하는 단계를 포함하고, 레이턴시 조회 테이블은 단일 신경망 층 의 정보와 단일 신경망 층의 엣지 디바이스상에서의 레이턴시 정보를 포함할 수 있다."}
{"patent_id": "10-2022-0094417", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "아래의 설명은 디바이스에서 딥러닝 모델의 레이턴시를 예측하는 방법 및 시스템에 관한 것이다."}
{"patent_id": "10-2022-0094417", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "현재 딥러닝 모델은 클라우드 서버에서 데이터를 입력받아 실행되고 있지만, 데이터 보안 이슈 및 저비용 서비 스를 위해서 저가용 디바이스에서 추론을 가능하게 하는 온 디바이스(on device) 인공지능(artificial intelligence, AI) 기술이 필수적이다. 이 때, 만들어낸 딥러닝 모델이 자신이 원하는 엣지 디바이스에서 실시간 추론이 가능한지 확인하려면 실제 해 당 디바이스에 딥러닝 모델을 탑재시켜 구동시켜 보아야 한다. 그러나 엣지 디바이스에서 딥러닝 모델을 구동시켜서 딥러닝 모델의 추론속도로서의 레이턴시(latency)를 측정 하려면, 이를 위한 엣지 디바이스를 셋팅하고 파이프라인을 구축하는데 시간 소모가 크고 따라서 하드웨어 쪽 지식이 없는 사람들에겐 진입 장벽이 높다는 문제가 있다. 또한, 딥러닝 모델의 경우 컨볼루션, 풀링 등 어떤 신경망 층들을 사용할 것인지 그리고 각 신경망 층마다 세부 적으로 어떤 설정을 할 것인지에 따라 매우 많은 경우의 수의 모델들이 만들어질 수 있다. 뿐만 아니라, 어떤 엣지 디바이스에서 구동되냐에 따라 레이턴시도 크게 달라지기 때문에 특정 모델의 온 디바이스 레이턴시를 정 확히 예측하기 어렵다는 문제가 있다. [선행문헌번호] 한국공개특허 제10-2020-0109917호"}
{"patent_id": "10-2022-0094417", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "실제 엣지 디바이스를 셋팅하고 파이프라인을 구축할 필요 없이, 딥러닝 모델의 온 디바이스에서의 레이턴시를 예측할 수 있는 레이턴시 예측 방법 및 시스템을 제공한다."}
{"patent_id": "10-2022-0094417", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "적어도 하나의 프로세서를 포함하는 컴퓨터 장치에 의해 수행되는 레이턴시 예측 방법에 있어서, 상기 적어도 하나의 프로세서에 의해, 딥러닝 모델을 입력받는 단계; 상기 적어도 하나의 프로세서에 의해, 레이턴시 조회테이블에 기초하여 학습된 레이턴시 예측기를 이용하여 입력된 딥러닝 모델의 온 디바이스 레이턴시를 예측하는 단계를 포함하고, 상기 레이턴시 조회 테이블은 단일 신경망 층의 정보와 단일 신경망 층의 엣지 디바이스상에 서의 레이턴시 정보를 포함하는 레이턴시 예측 방법이 제공될 수 있다. 본 개시의 일 실시 예에서, 상기 레이턴시 조회 테이블에는, 단일 신경망 층 딥러닝 모델에 대해 상기 엣지 디 바이스에서 측정된 레이턴시와 상기 단일 신경망 층 딥러닝 모델에 대한 정보가 서로 연계되어 저장될 수 있다. 본 개시의 일 실시 예에서, 상기 레이턴시 조회 테이블은, 단일 신경망 층 딥러닝 모델을 상기 엣지 디바이스에 따라 컴파일하고, 상기 컴파일된 단일 신경망 층 딥러닝 모델에 대해 상기 엣지 디바이스에서 측정된 레이턴시 를 전달받아, 상기 단일 신경망 층 딥러닝 모델에 대한 정보와 연계하여 상기 레이턴시 조회 테이블에 저장함으 로써, 생성될 수 있다. 본 개시의 일 실시 예에서, 상기 레이턴시 조회 테이블은, 엣지 디바이스의 종류마다 복수의 단일 신경망 층 딥 러닝 모델들 각각에 대한 레이턴시를 저장하도록 생성될 수 있다. 본 개시의 일 실시 예에서, 상기 학습된 레이턴시 예측기는, 상기 학습된 레이턴시 예측기가 음의 값을 출력하 지 않도록 상기 레이턴시 조회 테이블의 레이턴시의 값과 상기 레이턴시 예측기의 출력값에 대한 전처리를 통해 학습될 수 있다. 본 개시의 일 실시 예에서, 상기 온 디바이스 레이턴시를 예측하는 단계는, 상기 입력된 딥러닝 모델을 단일 신 경망 층 단위로 분해하여 단일 신경망 층 딥러닝 모델을 생성하는 단계; 상기 단일 신경망 층 딥러닝 모델 각각 을 상기 학습된 레이턴시 예측기에 입력하여 상기 엣지 디바이스에서의 레이턴시의 예측값을 생성하는 단계; 및 상기 단일 신경망 층 딥러닝 모델 각각의 레이턴시의 예측값들을 더해 상기 입력된 딥러닝 모델의 레이턴시를 계산하는 단계를 포함할 수 있다. 본 개시의 일 실시 예에서, 상기 학습된 레이턴시 예측기는 부스팅 알고리즘을 이용한 회귀 분석 모형을 포함할 수 있다. 본 개시의 일 실시 예에서, 상기 학습된 레이턴시 예측기를 이용하여, 상기 입력된 딥러닝 모델에 포함된 복수 의 단일 신경망 층 각각에 대한 레이턴시 예측값을 획득하는 단계를 포함하고, 상기 레이턴시 예측 방법은, 상 기 복수의 단일 신경망 층 중 그 정보가 상기 레이턴시 조회 테이블에 포함되지 않은 제1 단일 신경망 층을 식 별하고, 상기 제1 단일 신경망 층의 정보와 상기 제1 단일 신경망 층에 대한 레이턴시 예측값을 상기 레이턴시 조회 테이블에 추가하여 저장하는 단계;를 더 포함할 수 있다. 본 개시의 일 실시 예에서, 상기 레이턴시 예측 방법을 컴퓨터 장치에 실행시키기 위해 컴퓨터 판독 가능한 기 록매체에 저장된 컴퓨터 프로그램이 제공될 수 있다. 본 개시의 일 실시 예에서, 상기 레이턴시 예측 방법을 컴퓨터 장치에 실행시키기 위한 프로그램이 기록되어 있 는 컴퓨터 판독 가능한 기록매체가 제공될 수 있다. 본 개시의 일 실시 예에서, 컴퓨터 장치에서 판독 가능한 명령을 실행하도록 구현되는 적어도 하나의 프로세서 를 포함하고, 상기 적어도 하나의 프로세서에 의해, 딥러닝 모델을 입력받고, 레이턴시 조회 테이블에 기초하여 학습된 레이턴시 예측기를 이용하여 상기 입력된 딥러닝 모델의 온 디바이스 레이턴시를 예측하고, 상기 레이턴 시 조회 테이블은, 단일 신경망 층의 정보와 단일 신경망 층의 엣지 디바이스상에서의 레이턴시 정보를 포함하 는 컴퓨터 장치가 제공될 수 있다."}
{"patent_id": "10-2022-0094417", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "실제 엣지 디바이스를 셋팅하고 파이프라인을 구축할 필요 없이, 딥러닝 모델의 온 디바이스에서의 레이턴시를 예측할 수 있다."}
{"patent_id": "10-2022-0094417", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 실시예를 첨부한 도면을 참조하여 상세히 설명한다. 본 발명의 실시예들에 따른 레이턴시 예측 시스템은 적어도 하나의 컴퓨터 장치에 의해 구현될 수 있다. 이때, 컴퓨터 장치에는 본 발명의 일실시예에 따른 컴퓨터 프로그램이 설치 및 구동될 수 있고, 컴퓨터 장치는 구동된 컴퓨터 프로그램의 제어에 따라 본 발명의 실시예들에 따른 레이턴시 예측 방법을 수행할 수 있다. 상술한 컴 퓨터 프로그램은 컴퓨터 장치와 결합되어 레이턴시 예측 방법을 컴퓨터에 실행시키기 위해 컴퓨터 판독 가능한 기록매체에 저장될 수 있다. 도 1은 본 발명의 일실시예에 따른 네트워크 환경의 예를 도시한 도면이다. 도 1의 네트워크 환경은 복수의 전 자 기기들(110, 120, 130, 140), 복수의 서버들(150, 160) 및 네트워크를 포함하는 예를 나타내고 있다. 이러한 도 1은 발명의 설명을 위한 일례로 전자 기기의 수나 서버의 수가 도 1과 같이 한정되는 것은 아니다. 또한, 도 1의 네트워크 환경은 본 실시예들에 적용 가능한 환경들 중 하나의 예를 설명하는 것일 뿐, 본 실시예 들에 적용 가능한 환경이 도 1의 네트워크 환경으로 한정되는 것은 아니다. 복수의 전자 기기들(110, 120, 130, 140)은 컴퓨터 장치로 구현되는 고정형 단말이거나 이동형 단말일 수 있다. 복수의 전자 기기들(110, 120, 130, 140)의 예를 들면, 스마트폰(smart phone), 휴대폰, 네비게이션, 컴퓨터, 노트북, 디지털방송용 단말, PDA(Personal Digital Assistants), PMP(Portable Multimedia Player), 태블릿 PC 등이 있다. 일례로 도 1에서는 전자 기기의 예로 스마트폰의 형상을 나타내고 있으나, 본 발명의 실시예 들에서 전자 기기는 실질적으로 무선 또는 유선 통신 방식을 이용하여 네트워크를 통해 다른 전자 기 기들(120, 130, 140) 및/또는 서버(150, 160)와 통신할 수 있는 다양한 물리적인 컴퓨터 장치들 중 하나를 의미 할 수 있다. 통신 방식은 제한되지 않으며, 네트워크가 포함할 수 있는 통신망(일례로, 이동통신망, 유선 인터넷, 무선 인터넷, 방송망)을 활용하는 통신 방식뿐만 아니라 기기들간의 근거리 무선 통신 역시 포함될 수 있다. 예를 들어, 네트워크는, PAN(personal area network), LAN(local area network), CAN(campus area network), MAN(metropolitan area network), WAN(wide area network), BBN(broadband network), 인터넷 등의 네트워크 중 하나 이상의 임의의 네트워크를 포함할 수 있다. 또한, 네트워크는 버스 네트워크, 스타 네트워크, 링 네트워크, 메쉬 네트워크, 스타-버스 네트워크, 트리 또는 계층적(hierarchical) 네트워크 등을 포함하는 네트 워크 토폴로지 중 임의의 하나 이상을 포함할 수 있으나, 이에 제한되지 않는다. 서버(150, 160) 각각은 복수의 전자 기기들(110, 120, 130, 140)과 네트워크를 통해 통신하여 명령, 코드, 파일, 컨텐츠, 서비스 등을 제공하는 컴퓨터 장치 또는 복수의 컴퓨터 장치들로 구현될 수 있다. 예를 들어, 서버는 네트워크를 통해 접속한 복수의 전자 기기들(110, 120, 130, 140)로 서비스(일례로, 인 스턴트 메시징 서비스, 소셜 네트워크 서비스, 결제 서비스, 가상 거래소 서비스, 리스크 모니터링 서비스, 게 임 서비스, 그룹 통화 서비스(또는 음성 컨퍼런스 서비스), 메시징 서비스, 메일 서비스, 지도 서비스, 번역 서비스, 금융 서비스, 검색 서비스, 컨텐츠 제공 서비스 등)를 제공하는 시스템일 수 있다. 도 2는 본 발명의 일실시예에 따른 컴퓨터 장치의 예를 도시한 블록도이다. 앞서 설명한 복수의 전자 기기들 (110, 120, 130, 140) 각각이나 서버들(150, 160) 각각은 도 2를 통해 도시된 컴퓨터 장치에 의해 구현될 수 있다. 이러한 컴퓨터 장치는 도 2에 도시된 바와 같이, 메모리, 프로세서, 통신 인터페이스 그리 고 입출력 인터페이스를 포함할 수 있다. 메모리는 컴퓨터에서 판독 가능한 기록매체로서, RAM(random access memory), ROM(read only memory) 및 디스크 드라이브와 같은 비소멸성 대용량 기록장치 (permanent mass storage device)를 포함할 수 있다. 여기서 ROM과 디스크 드라이브와 같은 비소멸성 대용량 기록장치는 메모리와는 구분되는 별도의 영구 저장 장치로서 컴퓨터 장치에 포함될 수도 있다. 또한, 메모리에는 운영체제와 적어도 하나의 프로그램 코드가 저장될 수 있다. 이러한 소프트웨어 구성요 소들은 메모리와는 별도의 컴퓨터에서 판독 가능한 기록매체로부터 메모리로 로딩될 수 있다. 이러 한 별도의 컴퓨터에서 판독 가능한 기록매체는 플로피 드라이브, 디스크, 테이프, DVD/CD-ROM 드라이브, 메모리 카드 등의 컴퓨터에서 판독 가능한 기록매체를 포함할 수 있다. 다른 실시예에서 소프트웨어 구성요소들은 컴 퓨터에서 판독 가능한 기록매체가 아닌 통신 인터페이스를 통해 메모리에 로딩될 수도 있다. 예를 들어, 소프트웨어 구성요소들은 네트워크를 통해 수신되는 파일들에 의해 설치되는 컴퓨터 프로그램에 기 반하여 컴퓨터 장치의 메모리에 로딩될 수 있다. 프로세서는 기본적인 산술, 로직 및 입출력 연산을 수행함으로써, 컴퓨터 프로그램의 명령을 처리하도록 구성될 수 있다. 명령은 메모리 또는 통신 인터페이스에 의해 프로세서로 제공될 수 있다. 예 를 들어 프로세서는 메모리와 같은 기록 장치에 저장된 프로그램 코드에 따라 수신되는 명령을 실행 하도록 구성될 수 있다. 통신 인터페이스는 네트워크를 통해 컴퓨터 장치가 다른 장치(일례로, 앞서 설명한 저장 장치들)와 서로 통신하기 위한 기능을 제공할 수 있다. 일례로, 컴퓨터 장치의 프로세서가 메모리 와 같은 기록 장치에 저장된 프로그램 코드에 따라 생성한 요청이나 명령, 데이터, 파일 등이 통신 인터페 이스의 제어에 따라 네트워크를 통해 다른 장치들로 전달될 수 있다. 역으로, 다른 장치로부터의 신 호나 명령, 데이터, 파일 등이 네트워크를 거쳐 컴퓨터 장치의 통신 인터페이스를 통해 컴퓨터 장치로 수신될 수 있다. 통신 인터페이스를 통해 수신된 신호나 명령, 데이터 등은 프로세서나 메모리로 전달될 수 있고, 파일 등은 컴퓨터 장치가 더 포함할 수 있는 저장 매체(상술한 영구 저장 장치)로 저장될 수 있다. 입출력 인터페이스는 입출력 장치와의 인터페이스를 위한 수단일 수 있다. 예를 들어, 입력 장치는 마이크, 키보드 또는 마우스 등의 장치를, 그리고 출력 장치는 디스플레이, 스피커와 같은 장치를 포함할 수 있 다. 다른 예로 입출력 인터페이스는 터치스크린과 같이 입력과 출력을 위한 기능이 하나로 통합된 장치와 의 인터페이스를 위한 수단일 수도 있다. 입출력 장치 중 적어도 하나는 컴퓨터 장치와 하나의 장치 로 구성될 수도 있다. 예를 들어, 스마트폰과 같이 터치스크린, 마이크, 스피커 등이 컴퓨터 장치에 포함 된 형태로 구현될 수 있다. 또한, 다른 실시예들에서 컴퓨터 장치는 도 2의 구성요소들보다 더 적은 혹은 더 많은 구성요소들을 포함 할 수도 있다. 그러나, 대부분의 종래기술적 구성요소들을 명확하게 도시할 필요성은 없다. 예를 들어, 컴퓨 터 장치는 상술한 입출력 장치 중 적어도 일부를 포함하도록 구현되거나 또는 트랜시버 (transceiver), 데이터베이스 등과 같은 다른 구성요소들을 더 포함할 수도 있다. 본 발명의 실시예들에 따른 레이턴시 예측 시스템은 입력으로 들어온 임의의 딥러닝 모델의 정보들을 토대로 해 당 모델의 특정 엣지 디바이스에서의 레이턴시를 예측할 수 있다. 도 3은 본 발명의 일실시예에 따른 레이턴시 예측 시스템의 내부 구성의 예를 도시한 블록도이고, 도 4는 본 발 명의 일실시예에 따른 레이턴시 예측 방법의 예를 도시한 흐름도이다. 본 실시예에 따른 레이턴시 예측 시스템 은 적어도 하나의 컴퓨터 장치에 의해 구현될 수 있다. 도 3의 레이턴시 예측 시스템은 레이턴 시 조회 테이블 생성부, 레이턴시 예측기 학습부, 레이턴시 예측부를 포함할 수 있다. 이때, 레이턴시 조회 테이블 생성부, 레이턴시 예측기 학습부, 레이턴시 예측부는 레이턴시 예측 시스 템을 구현하는 컴퓨터 장치의 프로세서가 컴퓨터 프로그램의 제어에 따라 동작하는 기능의 기능 적 표현일 수 있다. 일례로, 컴퓨터 장치의 프로세서는 메모리가 포함하는 운영체제의 코드나적어도 하나의 컴퓨터 프로그램의 코드에 따른 제어 명령(instruction)을 실행하도록 구현될 수 있다. 여기서, 프로세서는 컴퓨터 장치에 저장된 코드가 제공하는 제어 명령에 따라 컴퓨터 장치가 도 4의 방 법이 포함하는 단계들(410 내지 430)을 수행하도록 컴퓨터 장치를 제어할 수 있다. 이때, 각 단계들(410 내지 430)의 수행을 위한 프로세서의 기능적 표현으로서 레이턴시 조회 테이블 생성부, 레이턴시 예 측기 학습부, 레이턴시 예측부가 사용될 수 있다. 단계에서 레이턴시 조회 테이블 생성부는 단일 신경망 층의 정보와 단일 신경망 층의 엣지 디바이스 상에서의 레이턴시 정보를 포함하는 레이턴시 조회 테이블을 생성할 수 있다. 일례로, 어떤 종류의 엣지 디바이스를 이용할 것인지가 결정되면, 레이턴시 조회 테이블 생성부는 다양한 단일 신경망 층들 각각에 대해 해당 엣지 디바이스에서의 레이턴시 정보를 담고 있는 레이턴시 조회 테이블을 생성할 수 있다. 보다 구체적인 예로, 레이턴시 조회 테이블 생성부는 레이턴시 예측기의 입력으로 사용될 단일 신경망 층 의 딥러닝 모델을 구성할 수 있다. 이때, 보다 다양한 단일 신경망 층 딥러닝 모델을 구성함으로써, 레이턴시 예측기의 예측 성능을 높일 수 있다. 또한, 레이턴시 조회 테이블 생성부는 구성된 단일 신경망 층 딥러 닝 모델이 사전에 결정된 엣지 디바이스에서 구동될 수 있도록 하기 위해 컴파일 과정을 진행할 수 있다. 이 경우, 레이턴시 조회 테이블 생성부는 컴파일된 단일 신경망 층 딥러닝 모델을 레이턴시를 구하기 위해 해 당 엣지 디바이스로 전송할 수 있다. 엣지 디바이스에서 단일 신경망 층 딥러닝 모델이 동작하여 레이턴시가 측정되면, 측정된 레이턴시 값이 레이턴시 예측 시스템으로 전달될 수 있다. 이 경우, 레이턴시 조회 테 이블 생성부는 해당 단일 신경망 층 딥러닝 모델에 대한 정보와 연계하여 전달된 레이턴시 값을 레이턴시 조회 테이블에 추가함으로써, 레이턴시 조회 테이블을 구축해나갈 수 있다. 레이턴시 조회 테이블 생성부(31 0)는 다양한 단일 신경망 층 딥러닝 모델 각각에 대해 엣지 디바이스에서의 레이턴시를 측정함으로써, 레이턴시 조회 테이블을 생성할 수 있다. 생성된 레이턴시 조회 테이블은 레이턴시 예측기를 학습하는데 사용될 수 있다. 단계에서 레이턴시 예측기 학습부는 레이턴시 조회 테이블을 이용하여 레이턴시 예측기가 입력으로 들어온 신경망 층의 레이턴시를 예측하도록 레이턴시 예측기를 학습시킬 수 있다. 레이턴시 예측기는 부스팅 알고리즘을 이용한 회귀 분석 모형일 수 있다. 부스팅 알고리즘은 여러 개의 약한 학습기를 순차적으로 학습-예측하면서 예측 성능을 높여 나가는 알고리즘이다. 일례로, 그래디언트 부스팅 알 고리즘은 이전 모델에서의 실제값과 예측값의 오차를 그래디언트를 이용하여 줄여나가는 방식을 사용하며 높은 성능을 나타낸다고 알려져 있다. 이러한 부스팅 알고리즘은 효율성과 유연성, 휴대성이 뛰어나며 과적합 문제 를 방지할 수 있다. 학습 데이터로서의 레이턴시 조회 테이블에 충분히 데이터가 쌓인 후, 레이턴시 예측기 학습부는 부스팅 알고리즘을 이용한 회귀 분석 모형인 레이턴시 예측기의 학습을 시작할 수 있다. 이때, 레이턴시 예측기 학습 부는 레이턴시 조회 테이블 중 단일 신경망 층 딥러닝 모델의 정보를 토대로 해당 모델의 레이턴시를 예측 할 수 있도록 레이턴시 예측기를 학습할 수 있다. 한편, 레이턴시 예측기 학습부는 레이턴시 조회 테이블 의 레이턴시 값과 레이턴시 예측기의 출력값을 전처리하여 레이턴시 예측기가 음의 값을 출력하지 않도록 할 수 있다. 단계에서 레이턴시 예측부는 학습된 레이턴시 예측기를 이용하여 입력된 딥러닝 모델의 온 디바이스 레이턴시를 예측할 수 있다. 일례로, 레이턴시 예측부는 입력으로 들어온 딥러닝 모델을 단일 신경망 층 단위로 분해하여 단일 신경망 층 딥러닝 모델을 생성할 수 있다. 이후, 레이턴시 예측부는 분해된 단일 신경망 층 딥러닝 모델 각각을 학습된 레이턴시 예측기에 입력할 수 있다. 레이턴시 예측기는 입력된 단일 신경망 층 딥러닝 모델에 대한 특 정 종류의 엣지 디바이스에서의 레이턴시를 예측하여 출력할 수 있다. 이때, 레이턴시 예측부는 레이턴시 예측기가 출력하는 레이턴시들을 더해서 입력된 딥러닝 모델의 온 디바이스 레이턴시를 예측할 수 있다. 이처럼, 레이턴시 예측 시스템은 입력으로 들어온 딥러닝 모델을 실제 엣지 디바이스로 전달하여 레이턴시 를 측정하지 않고도 딥러닝 모델의 온 디바이스 레이턴시를 예측할 수 있게 된다. 또한, 이미 설명한 바와 같이 레이턴시 예측기가 회귀 분석 모형이기 때문에 학습 과정에서 사용되지 못한 정보 들에 대해서도 높은 예측력을 보이고 있으며, 따라서 입력으로 들어온 다양한 딥러닝 모델에 대해서 신뢰도 높은 온 디바이스 레이턴시의 예측이 가능해진다. 본 실시예에서는 하나의 엣지 디바이스에 대해 설명하였으나, 다양한 종류의 엣지 디바이스들 각각에 대해 도 4 의 단계들(410 내지 430)을 수행함에 따라 다양한 종류의 엣지 디바이스들 각각에 대해 레이턴시 조회 테이블이 생성될 수 있고, 다양한 종류의 엣지 디바이스들 각각에 대해 학습된 레이턴시 예측기들이 생성될 수 있으며, 이 경우 레이턴시 예측부는 입력으로 들어온 딥러닝 모델에 대해 엣지 디바이스의 종류에 따른 온 디바이 스 레이턴시를 예측할 수 있게 된다. 일례로, 레이턴시 예측 시스템은 엣지 디바이스의 종류마다 복수의 단일 신경망 층 딥러닝 모델들 각각에 대한 레이턴시를 저장하도록 레이턴시 조회 테이블을 생성할 수 있다. 도 5는 본 발명의 일실시예에 따른 레이턴시 조회 테이블의 예를 도시한 도면이다. 도 5는 엣지 디바이스 A에 대한 레이턴시 조회 테이블의 예를 나타내고 있다. 레이턴시 조회 테이블에는 단일 신경망 층의 딥러닝 모델 정보와 해당 단일 신경망 층에 대해 엣지 디바이스 A에서 실제로 측정한 레이턴시가 포함될 수 있다. 일례로, 단일 신경망 층의 딥러닝 모델 정보는 해당 신경망 층이 어떤 종류의 딥러닝 모델의 몇 번째 층인가에 대한 정 보가 포함될 수 있다. 레이턴시 조회 테이블은 다양한 종류의 딥러닝 모델에 각각의 신경망 층들 각각에 대한 엣지 디바이스 A에서의 측정된 레이턴시를 서로 연계하여 저장함으로써, 추후 레이턴시 예측기를 위한 학습 데 이터로서 활용될 수 있다. 도 6은 본 발명의 일실시예에 있어서, 학습 데이터를 생성하는 과정의 예를 도시한 도면이다. 레이턴시 예측 시스템 또는 레이턴시 조회 테이블 생성부는 컴파일러를 이용하여 단일 신경망 층 딥러닝 모델 을 엣지 디바이스에 따라 컴파일하여 엣지 디바이스를 위한 컴파일된 단일 신경망 층 딥러닝 모 델을 생성할 수 있다. 이후 레이턴시 예측 시스템 또는 레이턴시 조회 테이블 생성부는 컴파일 된 단일 신경망 층 딥러닝 모델의 엣지 디바이스에서의 레이턴시를 구하기 위해, 컴파일된 단일 신경 망 층 딥러닝 모델을 엣지 디바이스로 전달할 수 있다. 엣지 디바이스에서는 컴파일된 단일 신 경망 층 딥러닝 모델에 대해 레이턴시를 측정할 수 있다. 측정된 레이턴시는 레이턴시 예측 시스템 으로 전달될 수 있으며, 레이턴시 예측 시스템 또는 레이턴시 조회 테이블 생성부는 전달된 레이턴시 를 레이턴시 조회 테이블에 저장할 수 있다. 이때, 레이턴시는 해당하는 단일 신경망 층 딥러닝 모델 에 대한 정보와 연계하여 레이턴시 조회 테이블에 저장될 수 있다. 다양한 딥러닝 모델 각각의 단일 신경망 층들에 대해 레이턴시가 측정되어 레이턴시 조회 테이블이 생성되 면, 레이턴시 조회 테이블은 레이턴시 예측기의 학습 데이터로서 활용될 수 있다. 다시 말해, 레이턴시 예측기는 특정한 단일 신경망 층 딥러닝 모델에 대한 레이턴시 값을 출력하도록 학습될 수 있다. 레이턴시 예 측기가 학습되면, 학습된 레이턴시 예측기를 이용하여 딥러닝 모델의 온 디바이스 레이턴시를 예측할 수 있게 된다. 도 7은 본 발명의 일실시예에 있어서, 레이턴시 예측기를 이용하여 레이턴시를 예측하는 과정의 예를 도시한 도 면이다. 딥러닝 모델이 입력되면, 레이턴시 예측 시스템 또는 레이턴시 예측부는 입력된 딥러 닝 모델을 신경망 층별로 분리하여 복수의 신경망 층들을 얻을 수 있다. 복수의 신경망 층들 각각은 레이턴시 예측기로 입력될 수 있으며, 복수의 신경망 층들에 대한 레이턴시들이 출력될 수 있다. 이때, 출력된 레이턴시들의 합이 딥러닝 모델의 레이턴시로서 계산될 수 있다. 도 7 의 실시예에서는 레이턴시 예측기의 인스턴스들이 복수의 신경망 층들 각각에 대해 병렬로 적용되는 예를 나타내고 있다. 이처럼, 본 발명의 실시예들에 따르면, 실제 엣지 디바이스를 셋팅하고 파이프라인을 구축할 필요 없이, 딥러닝 모델의 온 디바이스에서의 레이턴시를 예측할 수 있다. 한편, 레이턴시 예측기는, 레이턴시 예측기가 디플로이(deploy)되어 실행되는 엣지 디바이스의 특성 에 따라 다르게 생성될 필요가 있다. 이는, 엣지 디바이스의 특성에 따라 레이턴시 예측기의 성능이 현저 히 저하되거나 실행이 불가능할 수 있기 때문이다. 여기서, 엣지 디바이스의 특성은, 엣지 디바이스의 유형(예 를 들어, CPU 또는 GPU) 및 엣지 디바이스의 스포트웨어 버전을 포함할 수 있다. 새로운 엣지 디바이스에서 실행될 레이턴시 예측기를 생성하기 위해서는, 새로운 엣지 디바이스에 대응되 는 새로운 학습 데이터가 필요할 수 있다. 학습 데이터는, 룩업 테이블(또는, 레이턴시 조회 테이블)을 의미할 수 있다. 이하에서는 도 8을 참조하여 새로운 학습 데이터를 획득하는 방법에 대해 설명하도록 한다. 도 8은 본 개시의 일 실시 예에 따른 레이턴시 예측기의 학습에 이용되는 데이터 수에 따른 레이턴시 예측기의 성능을 나타내는 그래프이다.도 8을 참조하면, 그래프의 x축은 레이턴시 예측기의 학습에 이용되는 데이터 수(n)를 나타내며, 그래프 의 y축은 레이턴시 예측기의 성능을 나타낸다. 예로, 레이턴시 예측기의 성능은 정확도를 의미할 수 있다. 제1 성능(p1)은 95%이고 제2 성능(p2)은 100%(즉, 최대 성능)일 수 있다. 제2 개수(n2)는 제1 개수(n1)의 2배 일 수 있다. 즉, 레이턴시 예측기의 성능을 5% 낮춤으로써, 학습 데이터 수가 절반으로 줄어들 수 있다. 컴퓨터 장치는 메모리에 저장된 제1 룩업 테이블을 이용하여 그래프와 관련된 정보를 획득할 수 있다. 컴퓨터 장치는 제1 룩업 테이블에 포함된 데이터 수를 조절하면서 데이터 수에 따른 레이턴시 예측 기의 성능을 획득할 수 있다. 예를 들어, 제1 개수(n1)의 데이터로 학습될 때 레이턴시 예측기는 제1 성능(p1) 을 가질 수 있다. 제2 개수(n2)의 데이터로 학습될 때 레이턴시 예측기는 제2 성능(p2)을 가질 수 있다. 컴퓨터 장치는 그래프에 기초하여 최적의 데이터 개수를 획득하여 메모리에 저장할 수 있다. 예 를 들어, 컴퓨터 장치는 제1 개수(n1)를 최적의 데이터 개수로 획득할 수 있다. 컴퓨터 장치는 레이 턴시 예측기의 성능 또는 학습 데이터의 수 중 적어도 하나를 기초로 최적의 데이터 개수를 결정할 수 있다. 예 로, 컴퓨터 장치는 미리 정해진 타겟 성능에 대응되는 데이터 개수를 최적의 데이터 개수로 결정할 수 있 다. 컴퓨터 장치는 메모리에 저장된 최적의 데이터 개수를 기초로 새로운 레이턴시 예측기의 학습을 위한 새로운 룩업 테이블을 생성할 수 있다. 구체적으로, 컴퓨터 장치는 최적의 데이터 개수를 갖는 룩업 테이 블을 생성할 수 있다. 예를 들어, 컴퓨터 장치는 제1 개수(n1)의 데이터를 포함하는 제2 룩업 테이블을 생 성할 수 있다. 컴퓨터 장치는 제2 룩업 테이블을 기초로 학습된 제2 레이턴시 예측기를 획득할 수 있다. 이처럼, 컴퓨터 장치는 최적의 데이터 개수를 갖는 룩업 테이블을 생성함으로써 룩업 테이블 생성에 소모 되는 리소스를 최소화할 수 있다. 한편, 엣지 디바이스를 이용하여 측정된 레이턴시는 오버헤드(overhead)를 포함할 수 있다. 예로, 도 5의 각 단 일 신경망 층에 대응되는 레이턴시는 오버헤드가 포함된 값일 수 있다. 이 때, 컴퓨터 장치가 각 단일 신 경망 층에 대응되는 레이턴시를 합산하여 딥 러닝 모델 전체 레이턴시를 산출하게 되면, 전체 레이턴시에 오버 헤드가 중복적으로 더해져 전체 레이턴시의 오차가 증가할 수 있다. 예를 들어, 딥 러닝 모델이 제1 신경망 층과 제2 신경망 층으로 구성된다고 가정하면, 제1 신경망 층의 제1 레 이턴시(La)는 [수학식 1]로 표현되고, 제2 신경망 층의 제2 레이턴시(Lb)는 각각 [수학식 2]로 표현될 수 있다. 제1 레이턴시(La) 및 제2 레이턴시(Lb)는 엣지 디바이스에서 측정된 레이턴시이며, L(a) 및 L(b)는 순수 레이턴 시, o.h.는 오버헤드를 의미한다. 수학식 1"}
{"patent_id": "10-2022-0094417", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "수학식 2"}
{"patent_id": "10-2022-0094417", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "컴퓨터 장치가 제1 레이턴시(La) 및 제2 레이턴시(Lb)를 합산하여 딥 러닝 모델의 전체 레이턴시를 산출하 면, 전체 레이턴시는 2개의 오버헤드를 포함하게 된다(즉, ). 반면에, 딥 러닝 모델의 실제 레이턴시는 1개의 오버헤드만 포함할 수 있다(예로, ). 따라서, 각 레이턴시를 합산한 값과 실제 레이턴시가 달라지는 문제가 있다. 이하에서는, 레이턴시 오차를 줄이는 방법에 대해 설명하도록 한 다. 먼저, 컴퓨터 장치는 [수학식 3]에 기초하여 오버헤드를 획득할 수 있다. 수학식 3"}
{"patent_id": "10-2022-0094417", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "수학식 4"}
{"patent_id": "10-2022-0094417", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "제3 레이턴시(Lc)는 엣지 디바이스가 제1 신경망 층 및 제2 신경망 층을 실행하여 측정된 레이턴시이고, L(a+ b)는 제1 신경망 층 및 제2 신경망 층의 순수 레이턴시이다. 컴퓨터 장치는 제1 레이턴시(La) 및 제2 레이 턴시(Lb)를 합산한 값에서 제3 레이턴시(Lc)를 차감하여 오버헤드(o.h.)를 획득할 수 있다. 도 9는 본 개시의 일 실시 예에 따른 레이턴시 오차를 줄이는 방법을 설명하기 위한 도면이다. 도 9를 참조하면, 컴퓨터 장치는 딥러닝 모델의 단일 신경망 층에 대응되는 측정 레이턴시(L1, L2, L3)를 보정할 수 있다. 측정 레이턴시(L1, L2, L3)는, 엣지 디바이스에서 단일 신경망 층을 실행하여 측정된 레이턴시 를 의미한다. 컴퓨터 장치는 측정 레이턴시(L1, L2, L3)에 오버헤드(o.h.)를 차감하여 보정된 룩업 테이블 을 획득할 수 있다. 컴퓨터 장치는 보정된 룩업 테이블을 이용하여 레이턴시 예측기를 학습시킬 수 있다. 이에 따라, 컴 퓨터 장치는 정확도가 향상된 레이턴시 예측기를 획득할 수 있다. 한편, 도 9에서는 레이턴시 예측기의 학습 단계에서 오버헤드(o.h.)를 이용하는 것을 예로 들었다. 다른 일 실 시 예에 따르면, 컴퓨터 장치는 레이턴시 예측기의 추론 단계에서 오버헤드(o.h.)를 이용할 수 있다. 예를 들어, 컴퓨터 장치는 레이턴시 예측기가 출력한 예측 레이턴시에 오버헤드(o.h.)를 차감하여 보정된 레이 턴시를 획득할 수 있다. 도 10은 본 개시의 일 실시 예에 따른 룩업 테이블 생성 방법을 설명하기 위한 도면이다. 도 10을 참조하면, 컴퓨터 장치는 룩업 테이블을 이용하여 레이턴시 예측기를 학습시킬 수 있 다. 예를 들어, 컴퓨터 장치는 신경망 층 1의 딥러닝 모델 정보와 레이턴시(T1), 신경망 층 2의 딥러닝 모 델 정보와 레이턴시(T2), 신경망 층 3의 딥러닝 모델 정보와 레이턴시(T3)를 이용하여 레이턴시 예측기를 학습시킬 수 있다. 한편, 모든 유형의 단일 신경망 층 딥러닝 모델 정보에 대한 레이턴시를 엣지 디바이스에서 실측하는 것은 비효 율적일 수 있다. 이를 해결하기 위해, 컴퓨터 장치는 학습된 레이턴시 예측기가 출력한 예측 레이턴 시를 기초로 룩업 테이블을 구성할 수 있다. 예를 들어, 컴퓨터 장치는 신경망 층 N의 딥러닝 모델 정보를 레이턴시 예측기에 입력하여 레이턴시 (TN)을 획득할 수 있다. 컴퓨터 장치는 레이턴시(TN)을 데이터베이스에 저장할 수 있다. 데이터베이 스에는 레이턴시 예측기로 입력된 단일 신경망 층 딥러닝 모델 정보와 예측 레이턴시가 관련 지어 저장될 수 있다. 데이터베이스는 메모리에 저장될 수 있다. 한편, 컴퓨터 장치는 입력된 신경망 층의 정보가 룩업 테이블에 포함된 정보인 지 판단할 수 있다. 입력된 신경망 층의 정보가 룩업 테이블에 포함되지 않은 정보이면, 컴퓨터 장치는 입력된 신경망 층의 정보와 입력된 신경망 층에 대한 레이턴시를 데이터베이스에 저장할 수 있다. 반면에, 입력된 신경 망 층의 정보가 룩업 테이블에 이미 포함된 정보이면, 컴퓨터 장치는 입력된 신경망 층의 정보와 입 력된 신경망 층에 대한 레이턴시를 데이터베이스에 저장하지 않을 수 있다. 컴퓨터 장치는 데이터베이스에 저장된 예측 레이턴시를 이용하여 룩업 테이블을 생성할 수 있다. 예를 들어, 컴퓨터 장치는 룩업 테이블에 신경망 층 N의 딥러닝 모델 정보와 신경망 층 N 의 딥러닝 모델 정보에 대한 레이턴시(TN)를 추가할 수 있다. 이에 따라, 룩업 테이블에 포함되는 데이터 개수는 증가할 수 있다. 컴퓨터 장치는 신경망 층 N의 딥러닝 모델 정보와 신경망 층 N의 딥러닝 모델 정 보에 대한 레이턴시(TN)를 포함하는 새로운 룩업 테이블을 생성할 수 있다.도 11은 본 개시의 일 실시 예에 따른 레이턴시 예측기의 학습 방법을 설명하기 위한 도면이다. 도 11을 참조하면, 룩업 테이블(LU)은 복수의 단일 신경망 층 각각에 대한 정보를 포함할 수 있다. 단일 신경망 층에 대한 정보는 제1 정보 및 제2 정보를 포함할 수 있다. 제1 정보는 각 레이어에 대한 입 력 데이터의 크기(예로, 이미지 해상도) 및 추론 배치 사이즈(inference batch size)를 포함할 수 있다. 제2 정 보는 각 레이어에 아키텍처 정보를 포함할 수 있다. 예를 들어, 아키텍처 정보는, 레이어의 개수 및 각 레이어의 구조에 대한 정보를 포함할 수 있다. 각 레이어의 구조에 대한 정보는, 각 레이어의 유형(예로, 컨볼 루션 레이어), 커널 사이즈 및 풀링 사이즈를 포함할 수 있다. 컴퓨터 장치는 룩업 테이블(LU)을 이용하여 레이턴시 예측기를 학습시킬 수 있다. 레이턴시 예측기 는 제1 정보를 입력받는 제1 모델 및 제2 정보를 입력받는 제2 모델을 포함할 수 있다. 예를 들어, 제1 모델은 선형 회귀(linear regression) 모델일 수 있다. 제2 모델은 비선 형 모델(예로, XGBoost, DNN)일 수 있다. 제1 모델은 제1 정보를 입력받아 제1 특징값(h1)을 출력 할 수 있다. 제2 모델은 제2 정보를 입력받아 제2 특징값(h2)을 출력할 수 있다. 레이턴시 예측기 는 제1 특징값(h1) 및 제2 특징값(h2)에 기초하여 예측 레이턴시를 획득할 수 있다. 컴퓨터 장치 는 예측 레이턴시와 룩업 테이블(LU)에 저장된 레이턴시의 차이가 최소화되도록 레이턴시 예측기 를 제1 모델 및/또는 제2 모델의 가중치를 업데이트할 수 있다. 도 12는 본 개시의 일 실시 예에 따른 레이턴시 예측기를 이용한 레이턴시 예측 방법을 설명하기 위한 도면이다. 도 12를 참조하면, 컴퓨터 장치는 제1 딥러닝 모델(M1)을 획득할 수 있다. 컴퓨터 장치는 제1 딥러닝 모델(M1)을 분석하여 제1 딥러닝 모델(M1)에 대한 정보를 획득할 수 있다. 제1 딥러닝 모델(M1)에 대한 정보는 제1 정보 및 제2 정보를 포함할 수 있다. 제1 정보는 제1 딥러닝 모델(M1)에 포함된 각 레이어에 대한 입력 데이터의 크기(예로, 이미지 해상도) 및 추론 배치 사이즈(inference batch size)를 포함할 수 있다. 제2 정보는 제1 딥러닝 모델(M1)에 포함된 각 레이어에 아키텍처 정보를 포함할 수 있다. 컴퓨터 장치는 제1 정보 및 제2 정보를 레이턴시 예측기에 입력하여 예측 레이턴시 를 획득할 수 있다. 제1 모델은 제1 정보를 입력받아 제1 특징값(h1)을 출력하고, 제2 모델 은 제2 정보를 입력받아 제2 특징값(h2)을 출력할 수 있다. 레이턴시 예측기는 제1 특징값 (h1) 및 제2 특징값(h2)를 기초로 예측 레이턴시를 획득할 수 있다. 예를 들어, 레이턴시 예측기는 제1 특징값(h1) 및 제2 특징값(h2)에 대해 합성곱 연산을 수행할 수 있다. 한편, 컴퓨터 장치는 제1 딥러닝 모델(M1)에 대한 정보에서 제1 정보 및 제2 정보를 분 류할 수 있다. 그리고, 컴퓨터 장치는 각 정보에 대응되는 모델을 선택하고, 해당 정보를 선택된 모델에 입력할 수 있다. 예를 들어, 컴퓨터 장치는 제1 정보에 대응되는 모델로 제1 모델을 선택하고 제1 정보를 제1 모델에 입력할 수 있다. 또한, 컴퓨터 장치는 제2 정보에 대응되는 모 델로 제2 모델을 선택하고, 제2 정보를 제2 모델에 입력할 수 있다. 또는, 제1 정보 및 제2 정보의 분류는 레이턴시 예측기에 의해 수행될 수 있다. 도시되지 않 았으나, 레이턴시 예측기는 제1 딥러닝 모델(M1)에 대한 정보를 제1 정보 및 제2 정보(120 2)로 분류하기 위한 전처리부를 포함할 수 있다. 레이턴시 예측기는 각 정보에 대응되는 모델을 선택하고, 선택된 모델로 해당 정보를 입력할 수 있다. 이상에서 설명된 시스템 또는 장치는 하드웨어 구성요소, 또는 하드웨어 구성요소 및 소프트웨어 구성요소의 조 합으로 구현될 수 있다. 예를 들어, 실시예들에서 설명된 장치 및 구성요소는, 예를 들어, 프로세서, 콘트롤러, ALU(arithmetic logic unit), 디지털 신호 프로세서(digital signal processor), 마이크로컴퓨터, FPGA(field programmable gate array), PLU(programmable logic unit), 마이크로프로세서, 또는 명령 (instruction)을 실행하고 응답할 수 있는 다른 어떠한 장치와 같이, 하나 이상의 범용 컴퓨터 또는 특수 목적 컴퓨터를 이용하여 구현될 수 있다. 처리 장치는 운영 체제(OS) 및 상기 운영 체제 상에서 수행되는 하나 이상 의 소프트웨어 어플리케이션을 수행할 수 있다. 또한, 처리 장치는 소프트웨어의 실행에 응답하여, 데이터를 접근, 저장, 조작, 처리 및 생성할 수도 있다. 이해의 편의를 위하여, 처리 장치는 하나가 사용되는 것으로 설"}
{"patent_id": "10-2022-0094417", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "명된 경우도 있지만, 해당 기술분야에서 통상의 지식을 가진 자는, 처리 장치가 복수 개의 처리 요소 (processing element) 및/또는 복수 유형의 처리 요소를 포함할 수 있음을 알 수 있다. 예를 들어, 처리 장치는 복수 개의 프로세서 또는 하나의 프로세서 및 하나의 콘트롤러를 포함할 수 있다. 또한, 병렬 프로세서 (parallel processor)와 같은, 다른 처리 구성(processing configuration)도 가능하다. 소프트웨어는 컴퓨터 프로그램(computer program), 코드(code), 명령(instruction), 또는 이들 중 하나 이상의 조합을 포함할 수 있으며, 원하는 대로 동작하도록 처리 장치를 구성하거나 독립적으로 또는 결합적으로 (collectively) 처리 장치를 명령할 수 있다. 소프트웨어 및/또는 데이터는, 처리 장치에 의하여 해석되거나 처리 장치에 명령 또는 데이터를 제공하기 위하여, 어떤 유형의 기계, 구성요소(component), 물리적 장치, 가상 장치(virtual equipment), 컴퓨터 저장 매체 또는 장치에 구체화(embody)될 수 있다. 소프트웨어는 네트워크로 연결된 컴퓨터 시스템 상에 분산되어서, 분산된 방법으로 저장되거나 실행될 수도 있다. 소프트웨어 및 데이터 는 하나 이상의 컴퓨터 판독 가능 기록매체에 저장될 수 있다. 실시예에 따른 방법은 다양한 컴퓨터 수단을 통하여 수행될 수 있는 프로그램 명령 형태로 구현되어 컴퓨터 판 독 가능 매체에 기록될 수 있다. 상기 컴퓨터 판독 가능 매체는 프로그램 명령, 데이터 파일, 데이터 구조 등 을 단독으로 또는 조합하여 포함할 수 있다. 매체는 컴퓨터로 실행 가능한 프로그램을 계속 저장하거나, 실행 또는 다운로드를 위해 임시 저장하는 것일 수도 있다. 또한, 매체는 단일 또는 수개 하드웨어가 결합된 형태의 다양한 기록수단 또는 저장수단일 수 있는데, 어떤 컴퓨터 시스템에 직접 접속되는 매체에 한정되지 않고, 네트 워크 상에 분산 존재하는 것일 수도 있다. 매체의 예시로는, 하드 디스크, 플로피 디스크 및 자기 테이프와 같 은 자기 매체, CD-ROM 및 DVD와 같은 광기록 매체, 플롭티컬 디스크(floptical disk)와 같은 자기-광 매체 (magneto-optical medium), 및 ROM, RAM, 플래시 메모리 등을 포함하여 프로그램 명령어가 저장되도록 구성된 것이 있을 수 있다. 또한, 다른 매체의 예시로, 애플리케이션을 유통하는 앱 스토어나 기타 다양한 소프트웨어 를 공급 내지 유통하는 사이트, 서버 등에서 관리하는 기록매체 내지 저장매체도 들 수 있다. 프로그램 명령의 예에는 컴파일러에 의해 만들어지는 것과 같은 기계어 코드뿐만 아니라 인터프리터 등을 사용해서 컴퓨터에 의 해서 실행될 수 있는 고급 언어 코드를 포함한다."}
{"patent_id": "10-2022-0094417", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 7, "content": "이상과 같이 실시예들이 비록 한정된 실시예와 도면에 의해 설명되었으나, 해당 기술분야에서 통상의 지식을 가 진 자라면 상기의 기재로부터 다양한 수정 및 변형이 가능하다. 예를 들어, 설명된 기술들이 설명된 방법과 다 른 순서로 수행되거나, 및/또는 설명된 시스템, 구조, 장치, 회로 등의 구성요소들이 설명된 방법과 다른 형태 로 결합 또는 조합되거나, 다른 구성요소 또는 균등물에 의하여 대치되거나 치환되더라도 적절한 결과가 달성될 수 있다. 그러므로, 다른 구현들, 다른 실시예들 및 청구범위와 균등한 것들도 후술하는 청구범위의 범위에 속한다. 도면 도면1 도면2 도면3 도면4 도면5 도면6 도면7 도면8 도면9 도면10 도면11 도면12"}
{"patent_id": "10-2022-0094417", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일실시예에 따른 네트워크 환경의 예를 도시한 도면이다. 도 2는 본 발명의 일실시예에 따른 컴퓨터 장치의 예를 도시한 블록도이다.도 3은 본 발명의 일실시예에 따른 레이턴시 예측 시스템의 내부 구성의 예를 도시한 블록도이다. 도 4는 본 발명의 일실시예에 따른 레이턴시 예측 방법의 예를 도시한 흐름도이다. 도 5는 본 발명의 일실시예에 따른 레이턴시 조회 테이블의 예를 도시한 도면이다. 도 6은 본 발명의 일실시예에 있어서, 학습 데이터를 생성하는 과정의 예를 도시한 도면이다. 도 7은 본 발명의 일실시예에 있어서, 레이턴시 예측기를 이용하여 레이턴시를 예측하는 과정의 예를 도시한 도 면이다. 도 8은 본 개시의 일 실시 예에 따른 레이턴시 예측기의 학습에 이용되는 데이터 수에 따른 레이턴시 예측기의 성능을 나타내는 그래프이다. 도 9는 본 개시의 일 실시 예에 따른 레이턴시 오차를 줄이는 방법을 설명하기 위한 도면이다. 도 10은 본 개시의 일 실시 예에 따른 룩업 테이블 생성 방법을 설명하기 위한 도면이다. 도 11은 본 개시의 일 실시 예에 따른 레이턴시 예측기의 학습 방법을 설명하기 위한 도면이다. 도 12는 본 개시의 일 실시 예에 따른 레이턴시 예측기를 이용한 레이턴시 예측 방법을 설명하기 위한 도면이다."}
