{"patent_id": "10-2022-0158321", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0076134", "출원번호": "10-2022-0158321", "발명의 명칭": "집게 크레인 무인 자동화를 위한 3D 물체 위치 추정 장치 및 그 방법", "출원인": "포항공과대학교 산학협력단", "발명자": "김다현"}}
{"patent_id": "10-2022-0158321", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "카메라 및 라이다 센서에 의해 수집된 크레인 주변 영역의 이미지 및 포인트 클라우드를 수신하는 데이터 수신부;학습모델을 이용하여 상기 이미지에서 크레인의 어태치먼트 영역과 어태치먼트가 이동시킬 타겟 영역을 검출하고, 어태치먼트 영역 및 타겟 영역의 좌표 평균값을 이미지 중심점으로 각각 추출하여, 각각의 이미지 중심점에해당하는 어태치먼트 영역 및 타겟 영역의 포인트 클라우드로 어태치먼트와 타겟의 거리를 산출하는 데이터 처리부;상기 거리 정보를 기초로 크레인의 어태치먼트를 제어하여 타겟을 운반하는 제어부;를 포함하며, 상기 카메라와 라이더 센서는 중심점이 같은 곳을 가르키도록 조정된, 3D 물체 위치 추정 장치."}
{"patent_id": "10-2022-0158321", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 데이터 처리부는, 어태치먼트 영역의 이미지 중심점을 기준으로 어태치먼트 영역에 해당하는 포인트 클라우드 좌표 평균값으로 어태치먼트의 거리를 산출하는, 3D 물체 위치 추정 장치."}
{"patent_id": "10-2022-0158321", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서, 상기 데이터 처리부는, 타겟 영역의 이미지 중심점을 기준으로 타겟 영역에 해당하는 포인트 클라우드 좌표 평균값으로 타겟의 거리를산출하는, 3D 물체 위치 추정 장치."}
{"patent_id": "10-2022-0158321", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서, 상기 카메라 및 라이다 센서는 크레인에 설치되는, 3D 물체 위치 추정 장치."}
{"patent_id": "10-2022-0158321", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "카메라 및 라이다 센서에 의해 수집된 크레인 주변 영역의 이미지 및 포인트 클라우드를 수신하는 제1 단계;학습모델을 이용하여 상기 이미지에서 크레인의 어태치먼트 영역과 어태치먼트가 운반해야 하는 타겟 영역을 검출하는 제2 단계;상기 어태치먼트 영역 및 타겟 영역의 좌표 평균값을 이미지 중심점으로 각각 추출하는 제3 단계; 상기 각각의 이미지 중심점에 해당하는 어태치먼트 영역 및 타겟 영역의 포인트 클라우드로 어태치먼트와 타겟의 거리를 산출하는 제4 단계;를 포함하는, 3D 물체 위치 추정 방법."}
{"patent_id": "10-2022-0158321", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5항에 있어서, 상기 제4 단계의 어태치먼트의 거리 산출은, 공개특허 10-2024-0076134-3-상기 어태치먼트 영역의 이미지 중심점을 기준으로 어태치먼트 영역에 해당하는 포인트 클라우드 좌표 평균값으로 산출하는, 3D 물체 위치 추정 방법."}
{"patent_id": "10-2022-0158321", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6항에 있어서, 상기 제4 단계의 타겟의 거리 산출은, 상기 타겟 영역의 이미지 중심점을 기준으로 타겟 영역에 해당하는 포인트 클라우드 좌표 평균값으로 산출하는,3D 물체 위치 추정 방법."}
{"patent_id": "10-2022-0158321", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "카메라 및 라이다 센서에 의해 수집된 크레인 주변 영역의 이미지 및 포인트 클라우드를 수신하는 데이터 수신부; 학습모델을 이용하여 상기 이미지에서 크레인의 어태치먼트 영역과 어태치먼트가 이동시킬 타겟 영역을 검출하고, 어태치먼트 영역 및 타겟 영역의 좌표 평균값을 이미지 중심점으로 각각 추출하여, 각각의 이미지 중 심점에 해당하는 어태치먼트 영역 및 타겟 영역의 포인트 클라우드로 어태치먼트와 타겟의 거리를 산출하는 데이 터 처리부; 상기 거리 정보를 기초로 크레인의 어태치먼트를 제어하여 타겟을 운반하는 제어부;를 포함하며, 상 기 카메라와 라이더 센서는 중심점이 같은 곳을 가르키도록 조정된, 3D 물체 위치 추정 장치가 개시된다."}
{"patent_id": "10-2022-0158321", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 집게 크레인 무인 자동화를 위한 3D 물체 위치 측정 기술로, 카메라 센서에서 촬영된 이미지를 딥러 닝 인공지능 모델 YOLACT(You Only Look At CoefficienTs) 기반으로 구획화하고 이에 라이더(Ridar)센서에서 추출된 포인트 클라우드(Point Cloud) 거리 정보를 퓨전하여 물체가 위치한 3D 공간 좌표를 추출하는 장치 및 방법에 관한 것이다."}
{"patent_id": "10-2022-0158321", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "최근 산업 재해가 증가하는 추세임에 따라 작업자 안전에 대한 관심이 높아졌다. 특히 작업자의 피로 누적은 집 중력 저하를 유발해 산업 재해로 이어질 위험이 있다. 집게 크레인은 중장비이고 고철 등의 고중량 물체를 다루 는 특성상 안전에 대한 주의가 더더욱 필요해 운전자의 환경 개선 및 피로도를 경감하기 위해 무인 자동화 기술 이 필요한 상황이다. 집게 크레인 무인 자동화를 위해서는 들어 올리기 위한 물체에 대한 정확한 좌표 측정이 우선되어야 한다. 기존 카메라와 라이더의 센서 퓨전을 통한 물체 인지 및 거리 측정 기술은 주로 자율 주행 운 송수단(자동차, 비행기 등)에 국한되어 발전되어 왔으며 이는 대상 물체에 대한 정밀한 좌표 추정이 필요치 않 아 크레인 무인 자동화 기술에 적용되기엔 어려움이 있다. 따라서 크레인 무인 자동화를 위해 물체의 위치를 정 확하게 측정할 수 있는 방법이 필요하다. 선행기술문헌 특허문헌 (특허문헌 0001) 등록특허공보 제10-2451791호(공고일자 2022년10월12일) (특허문헌 0002) 등록특허공보 제10-1990482호(공고일자 2019년06월18일)"}
{"patent_id": "10-2022-0158321", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명이 해결하고자 하는 과제는 집게 크레인 무인 자동화를 위해 들고자하는 대상 물체를 인식하고 거리를 측정해 3D 공간상의 물체 위치를 측정하는 기술을 제공하는 것이다. 그러나 본 발명이 해결하고자 하는 과제는 상기에 언급된 과제로 제한되지 않으며, 언급되지 않은 다른 과제들 은 아래의 기재로부터 당업자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2022-0158321", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기 과제의 해결 수단으로서, 본 발명이 제안하는 3D 물체 위치 추정 장치는 카메라 및 라이다 센서에 의해 수 집된 크레인 주변 영역의 이미지 및 포인트 클라우드를 수신하는 데이터 수신부; 학습모델을 이용하여 상기 이 미지에서 크레인의 어태치먼트 영역과 어태치먼트가 이동시킬 타겟 영역을 검출하고, 어태치먼트 영역 및 타겟 영역의 좌표 평균값을 이미지 중심점으로 각각 추출하여, 각각의 이미지 중심점에 해당하는 어태치먼트 영역 및 타겟 영역의 포인트 클라우드로 어태치먼트와 타겟의 거리를 산출하는 데이터 처리부; 상기 거리 정보를 기초로크레인의 어태치먼트를 제어하여 타겟을 운반하는 제어부;를 포함한다. 상기 카메라와 라이더 센서는 중심점이 같은 곳을 가르키도록 조정된다. 상기 데이터 처리부는 어태치먼트 영역의 이미지 중심점을 기준으로 한 어태치먼트 영역에 해당하는 포인트 클 라우드 좌표 평균값으로 어태치먼트의 거리를 산출한다. 또한 상기 데이터 처리부는 타겟 영역의 이미지 중심점을 기준으로 한 타겟 영역에 해당하는 포인트 클라우드 좌표 평균값으로 타겟의 거리를 산출한다. 또한 상기 카메라 및 라이다 센서는 크레인에 설치될 수 있다. 다른 카테고리로서, 본 발명이 제안하는 3D 물체 위치 추정 방법은 카메라 및 라이다 센서에 의해 수집된 크레 인 주변 영역의 이미지 및 포인트 클라우드를 수신하는 제1 단계; 학습모델을 이용하여 상기 이미지에서 크레인 의 어태치먼트 영역과 어태치먼트가 운반해야 하는 타겟 영역을 검출하는 제2 단계; 상기 어태치먼트 영역 및 타겟 영역의 좌표 평균값을 이미지 중심점으로 각각 추출하는 제3 단계; 상기 각각의 이미지 중심점에 해당하는 어태치먼트 영역 및 타겟 영역의 포인트 클라우드로 어태치먼트와 타겟의 거리를 산출하는 제4 단계;를 포함한 다. 상기 제4 단계의 어태치먼트의 거리 산출은 상기 어태치먼트 영역의 이미지 중심점을 기준으로 한 어태치먼트 영역에 해당하는 포인트 클라우드 좌표 평균값으로 산출한다. 또한 상기 제4 단계의 타겟의 거리 산출은 상기 타겟 영역의 이미지 중심점을 기준으로 한 타겟 영역에 해당하 는 포인트 클라우드 좌표 평균값으로 산출한다."}
{"patent_id": "10-2022-0158321", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "크레인 집게와 물체의 위치 좌표가 산출되면 해당 값을 통해 크레인을 무인으로 제어할 수 있게 된다. 이를 통 해 크레인 운전 환경 개선 및 작업 피로도 경감을 기대할 수 있으며 유지보수 비용 절감도 가능하다. 본 발명을 통해 크레인을 무인으로 제어하기 위해 정밀한 목표 물체 위치를 추정하는 방식으로 쓰일 것으로 기대한다."}
{"patent_id": "10-2022-0158321", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 2, "content": "본 발명의 효과는 이상의 효과로 제한되지 않으며, 언급되지 않은 다른 효과들은 아래의 기재로부터 당업자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2022-0158321", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명의 기본 개념은 크레인 전면에 카메라와 라이다 두 센서를 설치하고 중심점이 같은 곳을 가리키도록 조정(Calibration)한다. 이후 카메라와 라이다로부터 각각 이미지와 포인트 클라우드 좌표 정보를 얻는다. 카메라로부터 촬 영된 이미지를 딥러닝 기반 모델인 YOLACT를 활용해 구획화(Segmentation)를 수행해 구획화 결과 평균값을 중심 점으로 횡(x), 종(y) 좌표 추출한다. 해당 구획화 영역 내 존재하는 포인트 클라우드 좌표들을 얻어와 해당 좌 표들의 평균값으로 물체의 거리(z)를 측정한다. 크레인 집게 또한 마찬가지로 횡, 종, 거리 좌표를 측정하며 측 정된 물체와 크레인 집게의 좌표로 두 점 사이의 횡, 종, 거리 벡터를 계산한다. 이를 통해 크레인 집게를 움직 일 방향과 정도를 측정할 수 있다. 이하, 첨부된 도면을 참조하여 본 발명의 바람직한 실시예에 대하여 구체적으로 설명한다. 본 발명이 제안하는 3D 물체 위치 추정 장치는 이미지와 포인트 클라우드 및 YOLACT를 이용하여 타겟(T)과 어태 치먼트의 위치를 추정하고, 추정된 위치를 기초로 크레인의 어태치먼트를 제어하여 타겟(T)을 무 인으로 운반하는데 활용된다.3D 물체 위치 추정 장치의 구성요소는 도 1과 같이 카메라, 라이다, 데이터 수신부, 데이터 처리부 , 제어부가 포함된다. 도 2를 참조하면, 카메라 및 라이다는 크레인 주변 영역의 이미지 및 포인트 클라우드를 수집하고 데이 터 수신부에 전송하는 구성으로, 크레인에 설치되고, 중심점이 같은 곳을 가리키도록 캘리브레이션 된 다. 크레인의 위치 이동이 많지 않은 정적인 작업 환경에서의 카메라 및 라이다의 설치 위치는 크 레인 외에도 작업장의 벽면, 별도로 마련된 거치대에 설치되는 것도 가능하다. 이때 카메라 및 라이다 는 크레인의 어태치먼트와 타겟(T)을 향하도록 배치되고, 어태치먼트와 타겟(T)을 추적하도록 틸팅 각도가 변화되게 구성될 수 있다. 카메라 및 라이다가 어태치먼트와 타겟(T)의 이미지 및 포인트 클라우드를 수집하여 데이터 수신부 에 전송하면, 데이터 수신부는 데이터 처리부에 전달한다. 학습 데이터는 공장 내에서 크레인(20 0)이 들고자 하는 타겟(T)(예, 고철)을 카메라와 라이다로 직접 촬영하여 구축되고, 구축된 학습 데이 터 중 이미지는 라벨미(LabelMe) 프로그램을 사용해 타겟(T)에 대해 폴리곤 포인트(Polygon Point)를 기반으로 마스킹 정보를 레이블링하여 전처리를 수행하였다. 데이터 처리부는 학습모델을 이용하여 이미지에서 크레인의 어태치먼트 영역과 어태치먼트가 이동시킬 타겟 영역(T)을 검출하고, 어태치먼트 영역 및 타겟(T) 영역의 좌표 평균값을 이미지 중심점으로 각각 추출하여, 각각의 이미지 중심점에 해당하는 어태치먼트 영역 및 타겟(T) 영역의 포인트 클라우드로 어태치먼트와 타겟(T)의 거리를 산출하는 구성으로, 적어도 하나의 프로세서, 메모리, 주변장치 인터페이스, 입/출력 서브시스템(I/O subsystem), 전력 회로 및 통신 회로를 적어도 포함할 수 있다. 메모리는 일례로 고속 랜덤 액세스 메모리(high-speed random access memory), 자기 디스크, 에스램(SRAM), 디램(DRAM), 롬(ROM), 플래시 메모리 또는 비휘발성 메모리를 포함할 수 있다. 메모리는 데이터 처리부의 동작에 필요한 학습모듈 즉, YOLACT(You Only Look At CoefficienTs)이 탑재될 수 있다. 또한 그 밖의 소프트웨어 모듈, 명령 어 집합, 다양한 데이터를 포함할 수 있다. YOLACT는 인스턴스 세그먼테이션(Instance Segmentation) 문제를 리얼 타임(real-time)으로 해결하는 모델로서, ICCV(국제 컴퓨터 비전 학회)에서 2019년에 발표된 논문이고 파이토치(PyTorch)로 구현되어 있다. YOLACT는 카메라의 이미지에서 크레인의 어태치먼트 영역과 어태치먼트가 이동시킬 타겟(T) 영역을 검출하는데 이용된다. YOLACT 인공지능 구획화 모델은 구축된 학습 데이터셋과 모델이 예측한 마스킹 정 보의 차이를 줄이는 방향으로 학습이 진행된다. 학습된 YOLACT 모델은 학습 데이터에서 구축된 타겟(T)에 대한 마스킹 정보와 거의 유사한 마스킹 정보를 출력해낸다. 데이터 처리부는 프로세서, 콘트롤러, ALU(arithmetic logic unit), 디지털 신호 프로세서(digital signal processor), 마이크로컴퓨터, FPGA(field programmable gate array), PLU(programmable logic unit), 마이크로 프로세서, 또는 명령(instruction)을 실행하고 응답할 수 있는 다른 어떠한 장치와 같이, 하나 이상의 범용 컴 퓨터 또는 특수 목적 컴퓨터를 이용하여 구현될 수 있다. 소프트웨어는 컴퓨터 프로그램(computer program), 코드(code), 명령(instruction), 또는 이들 중 하나 이상의 조합을 포함할 수 있으며, 원하는 대로 동작하도록 처리 장치를 구성하거나 독립적으로 또는 결합적으로 (collectively) 처리 장치를 명령할 수 있다. 소프트웨어 및/또는 데이터는, 처리 장치에 의하여 해석되거나 처 리 장치에 명령 또는 데이터를 제공하기 위하여, 어떤 유형의 기계, 구성요소(component), 물리적 장치, 가상장 치(virtual equipment), 컴퓨터 저장 매체 또는 장치, 또는 전송되는 신호 파(signal wave)에 영구적으로, 또 는 일시적으로 구체화(embody)될 수 있다. 소프트웨어는 네트워크로 연결된 컴퓨터 시스템 상에 분산되어서, 분 산된 방법으로 저장되거나 실행될 수도 있다. 소프트웨어 및 데이터는 하나 이상의 컴퓨터 판독 가능 기록 매체 에 저장될 수 있다. 제어부는 데이터 처리부 및 어태치먼트를 구동하는 액츄에이터와 연결되고, 데이터 처리부에서 산출된 어태치먼트의 거리, 타겟(T)의 거리 정보를 기초로 크레인의 액츄에이터를 제어하여 어태치먼 트가 타겟(T)을 운반하게 한다. 제어부는 어태치먼트 및 타겟(T)의 제원 정보가 사전에 저장되어 있어서, 어태치먼트 및 타겟(T)의 중심점까지의 거리만 알아도 액츄에이터의 제어가 가능하다. 이하에서는 도 3 및 도 4를 참조하여, 3D 물체 위치 추정 방법을 설명한다. 3D 물체 위치 추정 방법은 카메라 및 라이다 센서에 의해 수집된 크레인 주변 영역의 이미지 및 포인트 클라우드를 수신하는 제1 단계와, 학습모델을 이용하여 상기 이미지에서 크레인의 어태치먼트영역과 어태치먼트가 운반해야 하는 타겟(T) 영역을 검출하는 제2 단계와, 상기 어태치먼트 영역 및 타 겟(T) 영역의 좌표 평균값을 이미지 중심점으로 각각 추출하는 제3 단계와, 상기 각각의 이미지 중심점에 해당 하는 어태치먼트 영역 및 타겟(T) 영역의 포인트 클라우드로 어태치먼트와 타겟(T)의 거리를 산출하는 제4 단계를 포함한다. 즉, 카메라가 ① 어태치먼트 이미지(11a)와 타겟 이미지(11b)가 포함된 이미지를, 라이다가 ② 어태치 먼트 포인트 클라우드(12a)와 타겟 포인트 클라우드(12b)가 포함된 포인트 클라우드를 데이터 수신부에 전 송하고, ③ 데이터 수신부는 이를 데이터 처리부에 전달한다(S10). 데이터 처리부가 YOLACT를 이용하여 이미지에서 어태치먼트 영역과 타겟(T) 영역을 구획화하여 추 출하고(S20), 해당 영역의 좌표 평균값을 중심점으로 하여 횡(x), 종(y) 좌표를 각각 추출한다(S30). 다음 어태 치먼트 영역과 타겟(T) 영역에 해당하는 포인트 클라우드를 추출하고(S41), 좌표 평균값으로 어태치먼트 와 타겟(T)의 거리를 산출한다(S42). ④ 산출된 어태치먼트와 타겟(T)의 거리 값이 제어부에 전송되면, 제어부는 어태치먼트의 액츄 에이터를 제어하여 어태치먼트로 타겟(T)을 운반한다(S50). 한편, 도 5와 같이 3D 물체 위치 추정 장치는 크레인의 붐대에 설치된 제1 접속부와 어태치먼트 에 설치된 제2 접속부가 더 구비될 수 있다. 제1 접속부는 복수의 소켓(211a)이 구비되고, 소켓 (211a) 마다 고유의 ID가 부여되며, 각각의 소켓(211a)은 제어부와 연결된다. 제어부는 각각의 소켓(211a)에 부여된 고유 ID 마다 어태치먼트의 제원이 사전에 저장된다. 제원은 어태치 먼트의 종류, 성능, 치수, 무게, 특성 등일 수 있다. 예를 들어 도 5를 기준으로 제1 접속부의 가장 왼쪽 에 형성된 소켓(211a)부터 어태치먼트의 종류는 흡착판, 제1 집게(size 1), 제2 집게(size 2), 제3 집게(size 3)일 수 있다. 제1,2,3 집게는 크기가 상이하여, 포인트 클라우드로 중심점까지의 거리가 계산되더라도, 액츄에 이터 또한 제1,2,3 집게의 크기를 고려하여 제어되어야 한다. 제1,2 접속부(211,51)의 구성에 의해 타겟(T)의 크기에 따라 그에 맞는 어태치먼트로 운반할 수 있어, 정밀도가 높아지고 작업의 범위가 확장된다."}
{"patent_id": "10-2022-0158321", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "이상과 같이 실시예들이 비록 한정된 실시예와 도면에 의해 설명되었으나, 해당 기술분야에서 통상의 지식을 가 진 자라면 상기의 기재로부터 다양한 수정 및 변형이 가능하다. 예를 들어, 설명된 기술들이 설명된 방법과 다 른 순서로 수행되거나, 및/또는 설명된 시스템, 구조, 장치, 회로 등의 구성요소들이 설명된 방법과 다른 형태 로 결합 또는 조합되거나, 다른 구성요소 또는 균등물에 의하여 대치되거나 치환되더라도 적절한 결과가 달성될 수 있다. 그러므로, 다른 구현들, 다른 실시예들 및 특허청구범위와 균등한 것들도 후술하는 특허청구범위의 범위에 속한 다."}
{"patent_id": "10-2022-0158321", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 3D 물체 위치 추정 장치의 구성을 나타낸 도면, 도 2는 본 발명의 3D 물체 위치 추정 장치의 기본 개념을 설명하기 위한 도면, 도 3 및 도 4는 본 발명의 3D 물체 위치 추정 방법을 설명하기 위한 도면, 도 5는 본 발명의 3D 물체 위치 추정 장치의 어태치먼트와 붐대와의 접속관계를 설명하기 위한 도면."}
