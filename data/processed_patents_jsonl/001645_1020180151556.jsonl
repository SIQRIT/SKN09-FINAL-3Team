{"patent_id": "10-2018-0151556", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2020-0071799", "출원번호": "10-2018-0151556", "발명의 명칭": "딥러닝 인공지능 기술을 이용한 객체인식 및 카운팅 방법", "출원인": "(주)케이아이오티", "발명자": "이재준"}}
{"patent_id": "10-2018-0151556", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "복수의 관심대상에 대한 딥러닝 기반의 객체인식 학습결과를 저장하는 단계;분석대상공간의 영상을 획득하여 일정분석주기로 분석대상 프레임을 추출하고, 상기 추출된 프레임에 카운팅라인으로 구분되는 객체인식영역과 객체추적영역을 포함하는 가상의 관심영역을 설정하는 단계;컨벌루션 네트워크(convolution network)를 통해 상기 객체인식영역에서 관심대상에 대한 객체인식을 수행하고,상기 인식된 관심대상의 일정 픽셀영역에 추적 아이디를 할당하여 상기 일정 픽셀영역의 위치를 추적하여 상기인식된 관심대상에 대한 객체추적을 수행하는 단계; 및상기 일정 픽셀영역이 상기 객체추적영역에서 인식되면 상기 인식된 관심대상이 상기 카운팅 라인을 통과한 것으로 카운팅하고, 상기 카운팅 결과를 서버로 전송하는 단계를 포함하며,객체인식은 신경처리유닛(neural processing unit)에 의하여 수행되며,객체추적 및 카운팅은 중앙처리유닛(central processing unit)에 의하여 수행되는 것을 특징으로 하는, 딥러닝인공지능 기술을 이용한 객체인식 및 카운팅 방법."}
{"patent_id": "10-2018-0151556", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 관심대상에 대한 객체인식을 수행하는 단계는,상기 추출된 프레임의 상기 객체인식영역을 복수의 그리드(grid)로 분할한 다음, 싱글(single) 컨벌루션 네트워크를 통해 복수의 경계박스(bounding box)와 상기 복수의 경계박스에 대한 신뢰도(confidence) 및 객체클래스에대한 확률값(class probability)을 추정하는 YOLO(You Only Look Once) 네트워크 아키텍처(networkarchitecture)에 의하여 실시간으로 수행하는 단계를 포함하는 것을 특징으로 하는, 딥러닝 인공지능 기술을 이용한 객체인식 및 카운팅 방법."}
{"patent_id": "10-2018-0151556", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서, 상기 객체인식 및 카운팅 방법은,상기 분석대상 공간에서의 상기 복수의 관심대상의 통행량을 반영하여 상기 상기 추출된 프레임에 설정되는 상기 가상의 관심영역을 가변하는 단계를 더 포함하며,상기 가상의 관심영역을 가변하는 단계는,상기 객체인식영역과 상기 객체추적영역에 대해 선택가능한 복수의 영역 쌍의 패턴을 미리 설정하는 단계;상기 객체인식영역에 상기 복수의 관심대상이 진입할 가능성을 판단하기 위한 객체감지영역을 설정하는 단계;및상기 객체감지영역에 객체가 인식되면, 상기 인식된 객체의 위치에 따라 상기 복수의 영역 쌍 중 상기 인식된객체에 대응되는 영역 쌍을 선택하여 상기 가상의 관심영역을 가변하는 단계를 포함하되,상기 복수의 영역 쌍 중 가장 큰 영역 쌍의 카운팅 라인은,상기 복수의 영역 쌍 중 나머지 영역 쌍들의 객체인식영역과 객체추적영역을 구분하는 카운팅 라인을 포함하는것을 특징으로 하는, 딥러닝 인공지능 기술을 이용한 객체인식 및 카운팅 방법."}
{"patent_id": "10-2018-0151556", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명에 따른 딥러닝 인공지능 기술을 이용한 객체인식 및 카운팅 방법은, 복수의 관심대상에 대한 딥러닝 기 반의 객체인식 학습결과를 저장하는 단계; 분석대상공간의 영상을 획득하여 일정분석주기로 분석대상 프레임을 추출하고, 상기 추출된 프레임에 카운팅라인으로 구분되는 객체인식영역과 객체추적영역을 포함하는 가상의 관심 영역을 설정하는 단계; 컨벌루션 네트워크(convolution network)를 통해 상기 객체인식영역에서 관심대상에 대한 객체인식을 수행하고, 상기 인식된 관심대상의 일정 픽셀영역에 추적 아이디를 할당하여 상기 일정 픽셀영역의 위치를 추적하여 상기 인식된 관심대상에 대한 객체추적을 수행하는 단계; 및 상기 일정 픽셀영역이 상기 객체추 적영역에서 인식되면 상기 인식된 관심대상이 상기 카운팅 라인을 통과한 것으로 카운팅하고, 상기 카운팅 결과 를 서버로 전송하는 단계를 포함할 수 있다."}
{"patent_id": "10-2018-0151556", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 객체인식 방법에 관한 것으로, 보다 상세하게는, 딥러닝 인공지능 기술을 이용하여 빠르고 정확하게 객체를 인식하고 인식된 객체를 카운팅할 수 있는 방법에 관한 것이다."}
{"patent_id": "10-2018-0151556", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "스마트시티는 다양한 객체에 대한 인식과 통행량 정보의 등을 수집하여 빅데이터화하는 것을 기초로 하여 구현 될 수 있다. 이러한 객체인식과 통행량 정보 등의 수집은 인원계수기, 자전거계수기, 차량계수기, 각종 지능형 CCTV 등을 통하여 이루어질 수 있다. 인원계수기는 적외선 센서를 이용하는 방법, 2D 또는 3D 카메라를 이용하여 촬영된 영상을 분석하여 인원수를 카운팅하는 방법이 주로 이용되고 있다. 더 나아가서는 인원계수 분야에서는 안면인식 계수기능까지 부가되어 중복인원을 체크하거나 특정인에 대한 계수 등 다양한 기능이 추가되고 있다. 그리고 차량계수기는 현재 고속도로(특히, 톨게이트)와 국도 등의 도로에 설치된 CCTV를 통하여 획득되는 영상 을 분석하여 차량을 카운팅하는 방식으로 이미 보편화되어 있으며, 자전거계수기는 최근 법률에 의하여 자전거 통행량 수집이 의무화되어 여러 곳에 설치되어 운영되고 있다. 또한, 지능형 CCTV는 장애인 주차구역을 관리하는 자동감시 장치로 활용되거나, 로봇 작업반경 내로 객체가 접 근하는 것을 알람하여 안전사고를 방지하거나, 우범지역에서의 범죄가능 여부를 분석하거나, 주요지점에서의 교 통정보를 분석하는 등 다양한 용도로 실생활 및 산업현장에서 널리 이용되고 있다. 이러한 장치들을 통한 정보의 수집에서 중요한 점은 획득되는 정보의 실시간성과 빠른 속도 정보 획득의 최적화 또는 효율성에 있다고 할 것이다. 이를 위하여 다양한 실시간 객체인식 기술들이 개발되어 활용되고 있다. 그러 나 이러한 객체인식 기술들은 인간의 비쥬얼 시스템(human visual system)과 같이 어떤 이미지를 보았을 때 이 미지 내에 있는 객체들의 디테일(즉, 객체가 무엇인지, 객체가 어디에 위치하는지, 객체들은 어떤 관계에 있는 지 등)을 한 번에 파악할 수 있는 기술의 구현은 쉽게 이루어지지 않고 있다."}
{"patent_id": "10-2018-0151556", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "이에 본 발명이 해결하고자 하는 기술적 과제는, 컨벌루션 신경 네트워크 아키텍처를 이용하는 딥러닝 인공지능 기술을 통하여 실시간으로 분석대상공간에서의 객체를 인식하고 인식된 객체에 대한 카운팅 기능을 빠르고 효율 적으로, 인간의 비쥬얼 시스템에 준하여 한번에, 수행할 있는 방법을 제공하는 것이다. 본 발명이 이루고자 하는 기술적 과제들은 이상에서 언급한 기술적 과제로 제한되지 않으며, 언급되지 않은 또"}
{"patent_id": "10-2018-0151556", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 2, "content": "다른 기술적 과제들은 아래의 기재로부터 본 발명이 속하는 기술분야에서 통상의 지식을 가진 자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2018-0151556", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기 기술적 과제를 해결하기 위한 본 발명에 따른 딥러닝 인공지능 기술을 이용한 객체인식 및 카운팅 방법은, 복수의 관심대상에 대한 딥러닝 기반의 객체인식 학습결과를 저장하는 단계; 분석대상공간의 영상을 획득하여 일정분석주기로 분석대상 프레임을 추출하고, 상기 추출된 프레임에 카운팅라인으로 구분되는 객체인식영역과 객체추적영역을 포함하는 가상의 관심영역을 설정하는 단계; 컨벌루션 네트워크(convolution network)를 통해 상기 객체인식영역에서 관심대상에 대한 객체인식을 수행하고, 상기 인식된 관심대상의 일정 픽셀영역에 추적 아이디를 할당하여 상기 일정 픽셀영역의 위치를 추적하여 상기 인식된 관심대상에 대한 객체추적을 수행하는 단계; 및 상기 일정 픽셀영역이 상기 객체추적영역에서 인식되면 상기 인식된 관심대상이 상기 카운팅 라인을 통과한 것으로 카운팅하고, 상기 카운팅 결과를 서버로 전송하는 단계를 포함할 수 있다. 이때, 객체인식은 신경처리유닛(neural processing unit)에 의하여 수행되며, 객체추적 및 카운팅은 중앙처리유 닛(central processing unit)에 의하여 수행되는 것이 바람직하다. 상기 관심대상에 대한 객체인식을 수행하는 단계는, 상기 추출된 프레임의 상기 객체인식영역을 복수의 그리드 (grid)로 분할한 다음, 싱글(single) 컨벌루션 네트워크를 통해 복수의 경계박스(bounding box)와 상기 복수의 경계박스에 대한 신뢰도(confidence) 및 객체클래스에 대한 확률값(class probability)을 추정하는 YOLO(You Only Look Once) 네트워크 아키텍처(network architecture)에 의하여 실시간으로 수행하는 단계를 포함할 수 있다. 상기 객체인식 및 카운팅 방법은, 상기 분석대상 공간에서의 상기 복수의 관심대상의 통행량을 반영하여 상기 상기 추출된 프레임에 설정되는 상기 가상의 관심영역을 가변하는 단계를 더 포함할 수 있다. 그리고 상기 가상 의 관심영역을 가변하는 단계는, 상기 객체인식영역과 상기 객체추적영역에 대해 선택가능한 복수의 영역 쌍의 패턴을 미리 설정하는 단계; 상기 객체인식영역에 상기 복수의 관심대상이 진입할 가능성을 판단하기 위한 객체 감지영역을 설정하는 단계; 및 상기 객체감지영역에 객체가 인식되면, 상기 인식된 객체의 위치에 따라 상기 복 수의 영역 쌍 중 상기 인식된 객체에 대응되는 영역 쌍을 선택하여 상기 가상의 관심영역을 가변하는 단계를 포 함할 수 있다. 이때, 상기 복수의 영역 쌍 중 가장 큰 영역 쌍의 카운팅 라인은, 상기 복수의 영역 쌍 중 나머지 영역 쌍들의 객체인식영역과 객체추적영역을 구분하는 카운팅 라인을 포함하는 것이 바람직하다."}
{"patent_id": "10-2018-0151556", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명에 따른 딥러닝 인공지능 기술을 이용한 객체인식 및 카운팅 방법은, 딥러닝 인공지능 기술을 통하여 실 시간으로 분석대상공간에서의 객체를 인식하고 인식된 객체에 대한 카운팅 기능을 빠르고 효율적으로 수행할 수 있는 효과를 제공할 수 있다."}
{"patent_id": "10-2018-0151556", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명과 본 발명의 동작상 또는 기능상의 이점 및 본 발명의 실시에 의하여 달성되는 목적을 충분히 이해하기 위해서는 본 발명의 바람직한 실시예를 예시하는 첨부 도면 및 첨부 도면에 기재된 내용을 참조하여야만 한다. 이하, 첨부한 도면들을 참조하여, 본 발명을 보다 상세하게 설명하고자 한다. 본 발명은 다양한 변경을 가할 수 있고 여러 가지 형태를 가질 수 있는 바, 특정 실시예들을 도면에 예시하고 본문에 상세하게 설명하고자 한다. 그러나, 이는 본 발명을 특정한 개시 형태에 대해 한정하려는 것이 아니며, 본 발명의 사상 및 기술 범위에 포 함되는 모든 변경, 균등물 내지 대체물을 포함하는 것으로 이해되어야 한다. 각 도면을 설명하면서 유사한 참조부호를 유사한 구성요소에 대해 사용하였다. 첨부된 도면에 있어서, 구조물들 의 치수는 본 발명의 명확성을 기하기 위하여 실제보다 확대 또는 축소하여 도시한 것일 수 있다.제1, 제2 등의 용어는 다양한 구성요소들을 설명하는데 사용될 수 있지만, 상기 구성요소들은 상기 용어들에 의 해 한정되어서는 안 된다. 상기 용어들은 하나의 구성요소를 다른 구성요소로부터 구별하는 목적으로만 사용된 다. 예를들어, 본 발명의 권리 범위를 벗어나지 않으면서 제1 구성요소는 제2 구성요소로 명명될 수 있고, 유사 하게 제2 구성요소도 제1 구성요소로 명명될 수 있다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 출원에서, \"포함하다\" 또는 \"가지다\" 등의 용어는 명세서 상에 기재된 특징, 숫자, 단계, 동작, 구성요소, 부분품 또는 이들을 조합한 것이 존재함을 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단 계, 동작, 구성요소, 부분품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되어야 한다. 또한, 다르게 정의되지 않는 한, 기술적이거나 과학적인 용어를 포함해서 여기서 사용되는 모든 용어들은 본 발 명이 속하는 기술 분야에서 통상의 지식을 가진 자에 의해 일반적으로 이해되는 것과 동일한 의미를 가지고 있 다. 일반적으로 사용되는 사전에 정의되어 있는 것과 같은 용어들은 관련 기술의 문맥 상 가지는 의미와 일치하 는 의미를 가지는 것으로 해석되어야 하며, 본 출원에서 명백하게 정의하지 않는 한, 이상적이거나 과도하게 형 식적인 의미로 해석되지 않는다. 도 1은 본 발명에 따른 객체인식 및 카운팅 시스템의 구성도이다. 도 1을 참조하면, 상기 객체인식 및 카운 팅 시스템은 카메라, 분석단말기 및 통합서버로 구성된다. 한편, 상기 객체인식 및 카운팅 시 스템의 구성요소들이 필수적인 것은 아니어서, 상기 객체인식 및 카운팅 시스템은 그보다 많은 구성요 소들을 갖거나 그보다 적은 구성요소들을 가질 수도 있다. 이는 상기 객체인식 및 카운팅 시스템을 구성하 는 각 구성 요소들에 대해서도 마찬가지이다. 이하 각 구성요소들에 대해서 보다 상세히 살펴본다. 상기 카메라는 객체인식 및 카운팅에 필요한 분석대상공간에 대한 영상을 획득할 수 있다. 상기 분석단말기 는 본 시스템의 핵심 구성요소로써 상기 카메라에 의하여 획득된 영상을 분석하여 관심대상에 대한 객 체인식과 카운팅 기능을 수행할 수 있다. 상기 통합서버는 상기 분석단말기로부터 객체인식 및 카운팅 결과를 분석하고 관련 기관 또는 장치(예컨대, 상황실이나 담당자의 PC 등)으로 전송할 수 있다. 상기 분석단말기에는 복수의 관심대상에 대한 딥러닝(deep learning) 기반의 객체인식 학습결과를 저장하고 있어, 상기 분석단말기는 상기 획득된 영상에서 인식되는 관심대상에 대한 객체인식 기능을 수행할 수 있다. 객체인식 방법은 YOLO(You Only Look Once) 신경 네트워크(neural network) 아키텍처에 의하여 수행될 수 있다. 이에 대해서는 향후 도 3 내지 도 6을 참조하여 보다 상세히 살펴본다. 도 2는 본 발명에 따른 객체인식 및 카운팅 시스템에서 수행하는 객체인식 방법을 설명하기 위한 개념도이 다. 먼저, 상기 분석단말기에는 복수의 관심대상에 대한 이미지를 입력받아 딥러닝 기반으로 이들에 대한 객체 인식 학습결과가 저장되어 있다. 이 상태에서 상기 분석단말기는 상기 카메라에 의하여 획득되는 영상 에서 분석대상 프레임을 추출하여 컨벌루션 네트워크(convolution network) 기반의 객체인식을 수행한 다음, 가 장 신뢰도 또는 가능성이 높은 관심객체를 상기 분석대상 프레임에서 인식되는 객체를 선택할 수 있다. 도 2에 서는 객체인식 결과 가장 신뢰도 95%로 가장 높은 차량이 상기 분석대상 프레임에서 인식되는 것으로 판단되었 다. 도 3은 본 발명에 따른 객체인식 및 카운팅 시스템에서 수행되는 객체인식 및 카운팅 방법의 일예를 나타내 는 흐름도이다. 도 4는 본 발명에 따른 객체인식 및 카운팅 시스템이 실제로 구현되어 수행하는 객체인식 및 카운팅 방법의 과정을 나타내는 화면을 나타낸다. 이하 필요한 도면들을 참조하여 상기 객체인식 및 카운팅 방법을 살펴본다. 먼저, 상기 분석단말기에는 복수의 관심대상에 대한 딥러닝 기반의 객체인식 학습결과가 저장된다(S100). 그리고 상기 분석단말기는 상기 카메라에 의하여 획득되는 영상에서 일정주기마다 분석대상 프레임을 추출하고, 상기 추출된 프레임에 카운팅 라인으로 구분되는 객체인식영역과 객체추적 영역을 포함하는 가상의관심영역을 설정한다. 상기 객체인식영역은 관심대상에 대한 객체인식이 이루어지는 영역이며 상기 객체추적영역은 관심대상에 대한 객체인식은 수행되지 않고 인식된 관심대상에 대한 추적만이 이루어지는 영역을 말한다. 도 4을 참조하면, 특정 도로의 한 차선을 분석대상공간으로 하여 가상의 관심영역이 설정되어 있고, 상기 가상의 관심영역의 상부는 객체인식영역이며 상기 가상의 관심영역의 하부는 객체추적영역이며, 상기 객체인식영역 과 상기 객체추적영역이 카운팅 라인에 의하여 구분되어 있는 것을 알 수 있다. 상기 추출된 분석대상 프레임에 상기 가상의 관심영역이 설정된 다음에는, 상기 분석단말기는 상기 객체인 식영역에서 객체가 디텍팅되는지를 체크한다(S120). 객체가 디텍팅되면(YES), 상기 분석단말기는 컨벌루션 네트워크를 통해 상기 객체인식영역에서 관심대상에 대한 객체인식을 수행하고, 상기 인식된 관심대상의 일정 픽셀영역(즉, 일부 픽셀)에 추적 아이디를 할당하고, 상기 일정 픽셀영역의 위치를 추적하여 상기 인식된 관심 대상에 대한 객체추적을 수행한다(S130). 즉, 상기 분석단말기는 상기 인식된 관심대상에 대응되는 전체 픽셀이 아닌 그 일부에 대한 추적만을 수행 하여 상기 인식된 관심대상에 대한 객체추적을 수행할 수 있어, 객체추적에 필요한 연산량을 감소시킴과 동시에 따른 객체추적을 수행할 수 있다. 상기 분석단말기는 상기 인식된 관심대상에 대한 객체추적을 수행하면서 상기 일정 픽셀영역이 상기 객체추 적영역에서 인식되는지를(즉, 상기 인식된 관심대상이 카운팅 라인을 통과하는지를) 판단한다(S140). 만약, 상 기 일정 픽셀영역이 사기 객체추적영역에서 인식되면(YES), 상기 분석단말기는 상기 인식된 관심대상이 상 기 카운팅 라인을 통과한 것으로 카운팅한 다음, 카운팅 결과를 상기 통합서버로 전송한다(S150). 도 4의 (a)에서는 관심대상인 사람, 자전거, 차량 중 차량이 객체인식영역에서 인식되었으나 아직 카운팅 라인을 통과하지 않아 차량 카운팅이 수행되지 않은 상태를 나타낸다. 그리고 도 4의 (b)에서는 인식된 차 량이 상기 카운팅 라인을 통과하였으므로 차량 카운팅 넘버가 16에서 17로 증가한 것을 알 수 있다. 한편, 상기 분석단말기는 객체인식은 신경처리유닛(neural processing unit, 미도시)을 통하여 수행하며, 객체추적 및 카운팅은 중앙처리유닛(central processing unit, 미도시)을 통하여 수행할 수 있다. 이는 상기 분 석단말기는 일정주기(예컨대, 0.1초)마다 상기 카메라에 의하여 획득되는 영상에서 분석대상 프레임을 추출하여 객체인식을 수행하여야 하는데, 관심영역을 객체인식영역과 객체추적영역을 나누고, 데이터 처리를 객 체인식과 추적 및 카운팅으로 이원화함으로써 효율적이면서도 빠른 객체인식 및 카운팅 기능을 수행하기 위함이 다. 한편, 상기 관심대상에 대한 객체인식을 수행하는 단계는 상기 추출된 프레임의 상기 객체인식영역을 복수의 그 리드(grid)로 분할한 다음, 싱글(single) 컨벌루션 네트워크를 통해 복수의 경계박스(bounding box)와 상기 복 수의 경계박스에 대한 신뢰도(confidence) 객체클래스에 대한 확률값(class probability)을 추정하는 YOLO(You Only Look Once) 네트워크 아키텍처(network architecture)에 의하여 실시간으로 수행될 수 있다. 도 5는 본 발명에 따른 객체인식 및 카운팅 시스템에서 객체인식에 이용되는 YOLO 디텍팅을 설명하기 위한 개념도이다. 도 5에서 왼쪽의 그림은 분석대상 프레임을 추출한 다음 추출된 프레임이 복수의 그리드로 분할된 것을 나타낸 다. 도 5에서 가운데 그림 2개는 싱글 컨벌루션 네트워크를 통해 다수의 경계박스와 상기 복수의 경계박스에 대 한 신뢰도 및 객체클래스에 대한 확률값이 추정된 상태를 나타낸다. 도 5에서 오른쪽의 그림은 상기 복수의 경 계박스에 대한 신뢰도 및 객체클래스에 대한 확률값에 기초하여 3개의 경계박스에서 개, 자전거 및 차량이 인식 된 것을 나타낸다. 이와 같이, 본 발명에 따른 객체인식 및 카운팅 시스템은 객체인식을 영상으로부터 경계박스의 좌표와 객체 클래스에 대한 확률값을 추정하는 단순한 구조의 회귀(regression) 문제로 해결하는 YOLO 네트워크 아키텍처를 활용함으로써 실시간 객체인식을 빠르고 효율적으로 수행할 수 있다. 한편, 본 발명에 따른 객체인식 및 카운팅 시스템은 객체인식영역과 객체추적영역을 포함하는 가상의 관심 영역을 분석대상 공간에서의 관심대상들의 통행량에 따라 가변함으로써 보다 효율적이고 빠른 객체인식 및 카운 팅 기능을 수행할 수 있다. 이에 대해서는 아래에서 도 6을 참조하여 보다 상세히 살펴본다.도 6은 본 발명에 따른 객체인식 및 카운팅 시스템에서 가상의 관심영역을 설정하는 방법을 설명하기 위한 개념도이다. 미리 설정되어 있는 객체감지영역(DA1 내지 DA3) 중 1차선에 대응되는 객체감지영역(DA1)에 인식되면, 상기 분 석단말기는 다른 차선에 대해서는 객체인식을 수행할 필요가 없다고 판단하여, 객체인식영역 및 객체추적영 역을 구성하는 영역 중 1차선에 대응되는 영역 쌍(RA1 및 TA1)을 선택하여 가상의 관심영역을 설정한다. 그러면, 상기 분석단말기는 상기 선택된 영역 쌍(RA1 및 TA1)에 대해서만 객체인식과 추적기능을 수행하면 되므로, 연산량이 크게 줄어들 수 있어 더욱 빠르게 실시간 처리가 가능해진다. 그리고 2차선과 3차선에 대응되는 객체감지영역(DA2 및 DA3)에 객체가 인식되는 경우, 상기 분석단말기는 객체인식영역의 RA2, RA3, RA5 및 RA6로 구성되는 영역과 객체추적영역의 TA2, TA3, TA5 및 TA6로 구성되는 영 역의 쌍을 선택하여 가상의 관심영역을 설정함으로써, 객체인식 및 추적에 소요되는 연산량을 줄일 수 있다. 그리고 1차선 내지 3차선 모두에 대해 객체인식 및 추적기능을 수행해야 하는 경우에는, 상기 분석단말기는 객체인식영역 전체(RA1 내지 RA9) 및 객체추적영역 전체(TA1 내지 TA9)를 가상의 관심영역을 이루는 영역 쌍으 로 선택할 수 있다. 이는 상기 객체감지영역(DA1 내지 DA3) 모두에서 특정객체가 인식되는 경우일 수 있다. 한편, 경우에 따라서 상기 분석단말기는 상기 객체감지영역(DA1 내지 DA3)에서 객체가 인식되지 않는 경우 에도 상기 선택가능한 복수의 영역 쌍의 패턴 중 특정 영역 쌍의 패턴을 선택함으로써 가상의 관심영역을 가변 할 수 있다. 이는 관리자가 가상의 관심영역을 강제로 변경하고자 하는 경우일 수 있다. 그러나 본 발명의 범위 가 이에 한정되는 것은 아니다. 이상에서 살펴본 바와 같이, 상기 분석단말기에서 가상의 관심영역을 상기 복수의 관심대상의 통행량을 반 영하여 변경하는 단계는, 객체인식영역과 객체추적영역에 대해 선택가능한 복수의 영역 쌍의 패턴을 미리 설정 하는 제1 단계, 상기 객체인식영역에 상기 복수의 관심대상이 진입할 가능성을 판단하기 위한 객체감지영역을 설정하는 제2 단계 및 상기 객체감지영역에 객체가 인식되면, 상기 인식된 객체의 위치에 따라 상기 복수의 영 역 쌍 중 상기 인식된 객체에 대응되는 영역 쌍을 선택하여 상기 가상의 관심영역을 가변하는 제3 단계로 구현 될 수 있다. 한편, 동일한 분석대상 공간에 대해서는 가상의 관심영역을 구분하는 카운팅 라인은 서로 중첩됨이 바람직하다. 즉, 가상의 관심영역을 가변하기 위한 상기 복수의 영역 쌍 중 가장 큰 영역 쌍의 카운팅 라인은, 상기 복수의 영역 쌍 중 나머지 영역 쌍들의 객체인식영역과 객체추적영역을 구분하는 카운팅 라인을 포함하는 것이 바람직 하다. 이상과 같이 본 발명은 비록 한정된 실시예와 도면에 의해 설명되었으나, 본 발명은 상기의 실시예에 한정되는 것은 아니며, 본 발명이 속하는 분야에서 통상의 지식을 가진 자라면 이러한 기재로부터 다양한 수정 및 변형이 가능하다. 그러므로, 본 발명의 범위는 설명된 실시예에 국한되어 정해져서는 아니되며, 후술하는 특허청구범위뿐 아니라 이 특허청구범위와 균등한 것들에 의해 정해져야 한다."}
{"patent_id": "10-2018-0151556", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명에 따른 객체인식 및 카운팅 시스템의 구성도이다. 도 2는 본 발명에 따른 객체인식 및 카운팅 시스템에서 수행하는 객체인식 방법을 설명하기 위한 개념도이 다. 도 3은 본 발명에 따른 객체인식 및 카운팅 시스템에서 수행되는 객체인식 및 카운팅 방법의 일예를 나타내 는 흐름도이다. 도 4는 본 발명에 따른 객체인식 및 카운팅 시스템이 실제로 구현되어 수행하는 객체인식 및 카운팅 방법의 과정을 나타내는 화면을 나타낸다. 도 5는 본 발명에 따른 객체인식 및 카운팅 시스템에서 객체인식에 이용되는 YOLO 디텍팅을 설명하기 위한 개념도이다. 도 6은 본 발명에 따른 객체인식 및 카운팅 시스템에서 가상의 관심영역을 설정하는 방법을 설명하기 위한 개념도이다."}
