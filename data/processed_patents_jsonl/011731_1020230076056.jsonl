{"patent_id": "10-2023-0076056", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0175851", "출원번호": "10-2023-0076056", "발명의 명칭": "웹툰 또는 애니메이션 캐릭터를 소량의 학습데이터를 통해 생성하기 위한 장치 및 방법", "출원인": "(주)라이언로켓", "발명자": "정승환"}}
{"patent_id": "10-2023-0076056", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "인공 지능 기반 캐릭터 생성 방법으로서,사용자의 프롬프트 입력을 인공 지능 기반 캐릭터 생성 장치에 의해 입력받는 단계;상기 인공 지능 기반 캐릭터 생성 장치의 프롬프트 분석 모듈에 의해 수신된 프롬프트 입력을 구문 분석하여 핵심 단어를 추출하는 단계;추출된 상기 핵심 단어에 기초하여 기본 캐릭터를 생성하는 단계;생성된 상기 기본 캐릭터에 대해 소정 개수의 기본 자세 이미지를 생성하는 단계;상기 소정 개수의 기본 자세 이미지에 기초하여 자세 제어 학습을 수행하여 자세 제어된 캐릭터를 생성하는 단계를 포함하는, 인공 지능 기반 캐릭터 생성 방법."}
{"patent_id": "10-2023-0076056", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명의 일 실시예는 인공 지능 기반 캐릭터 생성 방법에 대한 것으로서, 사용자의 프롬프트 입력을 인공 지능 기반 캐릭터 생성 장치에 의해 입력받는 단계; 상기 인공 지능 기반 캐릭터 생성 장치의 프롬프트 분석 모듈에 의해 수신된 프롬프트 입력을 구문 분석하여 핵심 단어를 추출하는 단계; 추출된 상기 핵심 단어에 기초하여 기 본 캐릭터를 생성하는 단계; 생성된 상기 기본 캐릭터에 대해 소정 개수의 기본 자세 이미지를 생성하는 단계; 상기 소정 개수의 기본 자세 이미지에 기초하여 자세 제어 학습을 수행하여 자세 제어된 캐릭터를 생성하는 단계 를 포함한다."}
{"patent_id": "10-2023-0076056", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 웹툰 또는 애니메이션 캐릭터를 소량의 학습데이터를 통해 생성하기 위한 장치 및 방법에 관한 것이다."}
{"patent_id": "10-2023-0076056", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "전세계적으로 웹툰(webtoon)/애니메이션 시장이 성장하고 있으며, GPT-4를 비롯한 다양한 인공지능 기반 기술이 등장하면서 웹툰/애니메이션 시장에도 이러한 인공지능을 접목하기 위한 시도가 점차 늘어나고 있다. 국내 기업으로는 네이버웹툰에서 2021년 10월 \"웹툰 에이아이 페인터\" 시험 서비스를 시작하였으며, 이 서비스 를 이용하면 작가가 색을 고르고 원하는 곳에 터치하면 자연스럽게 색을 입혀준다. 이 밖에도, 캐릭터와 배경 에 자동으로 채색해주는 기술, 밑그림 수준의 스케치를 정교한 선화로 바꿔주는 기술, 텍스트를 그림 콘티로 바 꿔주는 기술, 실사 사진을 웹툰으로 바꿔주는 기술, 기존 작가 화풍의 웹툰을 그리는 기술 등이 현실화되고 있 다. 이 중에서, 기존의 웹툰 이미지 생성형 인공지능의 경우, 프롬프트를 넣으면 랜덤으로 캐릭터 이미지를 만들어 주게 되는데, 이러한 캐릭터의 자세나 동작이 일관성 있게 묘사되기가 힘들다는 문제점이 존재한다."}
{"patent_id": "10-2023-0076056", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "따라서, 본 발명의 일 목적은 많은 연산 리소스를 소모하지 않고서도 효과적으로 다양한 자세를 취하는 경우에 도 일관성 있는 캐릭터(즉, 다양한 자세를 취해도 동일한 캐릭터로 인식되는 캐릭터)를 생성하여 제공하는 것에 있다. 다만, 본 발명이 해결하고자 하는 과제는 이상에서 언급한 바로 제한되지 않으며, 언급되지는 않았으나 아래의"}
{"patent_id": "10-2023-0076056", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 2, "content": "기재로부터 본 발명이 속하는 기술분야에서 통상의 지식을 가진 자에게 명확하게 이해될 수 있는 목적을 포함할수 있다."}
{"patent_id": "10-2023-0076056", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "이하 본 발명의 목적을 달성하기 위한 구체적 수단에 대하여 설명한다. 본 발명의 일 실시예에 따른 인공 지능 기반 캐릭터 생성 방법은, 사용자의 프롬프트 입력을 인공 지능 기반 캐 릭터 생성 장치에 의해 입력받는 단계; 상기 인공 지능 기반 캐릭터 생성 장치의 프롬프트 분석 모듈에 의해 수 신된 프롬프트 입력을 구문 분석하여 핵심 단어를 추출하는 단계; 추출된 상기 핵심 단어에 기초하여 기본 캐릭 터를 생성하는 단계; 생성된 상기 기본 캐릭터에 대해 소정 개수의 기본 자세 이미지를 생성하는 단계; 상기 소 정 개수의 기본 자세 이미지에 기초하여 자세 제어 학습을 수행하여 자세 제어된 캐릭터를 생성하는 단계를 포 함한다."}
{"patent_id": "10-2023-0076056", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "상기한 바와 같이, 본 발명에 의하면 이하와 같은 효과가 있다. 본 발명의 일 실시예에 따르면, 인공 지능 기반 캐릭터 생성 장치에서 10장 이내의 캐릭터 이미지를 생성하는 것만으로 자세 제어된 캐릭터를 생성할 수 있게 되므로, 많은 리소스의 소모 없이도 효율적으로 일관성 있는 캐 릭터 생성을 할 수 있다는 효과를 가진다. 다만, 본 발명에서 얻을 수 있는 효과는 이상에서 언급한 효과들로 제한되지 않으며, 언급하지 않은 또 다른 효 과들은 아래의 기재로부터 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자에게 명확하게 이해될 수 있 을 것이다."}
{"patent_id": "10-2023-0076056", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하 첨부된 도면을 참조하여 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자가 본 발명을 쉽게 실시할 수 있는 실시예를 상세히 설명한다. 다만, 본 발명의 바람직한 실시예에 대한 동작원리를 상세하게 설명함에 있 어서 관련된 공지기능 또는 구성에 대한 구체적인 설명이 본 발명의 요지를 불필요하게 흐릴 수 있다고 판단되 는 경우에는 그 상세한 설명을 생략한다. 또한, 도면 전체에 걸쳐 유사한 기능 및 작용을 하는 부분에 대해서는 동일한 도면 부호를 사용한다. 명세서 전 체에서, 특정 부분이 다른 부분과 연결되어 있다고 할 때, 이는 직접적으로 연결되어 있는 경우뿐만 아니라, 그 중간에 다른 소자를 사이에 두고, 간접적으로 연결되어 있는 경우도 포함한다. 또한, 특정 구성요소를 포함한다 는 것은 특별히 반대되는 기재가 없는 한 다른 구성요소를 제외하는 것이 아니라, 다른 구성요소를 더 포함할 수 있는 것을 의미한다.인공 지능 기반 캐릭터 생성 장치의 개략 구성 도 1은 본 발명의 일 실시예에 따른 인공 지능 기반 캐릭터 생성 장치를 개략적으로 도시한 블록도이다. 도 1을 참조하면, 본 발명의 일 실시예에 따른 인공 지능 기반 캐릭터 생성 장치는 특수한 형식을 갖춘 콘 티나 특정 형식을 갖추지 않은 문장과 같은 프롬프트 입력을 사용자로부터 입력받으면, 입력된 프롬프트 입 력을 프롬프트 분석 모듈, 캐릭터 생성 모듈 및 캐릭터 자세 제어 모듈에 의해 처리하여 자세 제어된 캐릭터를 생성할 수 있다. 일 실시예에 있어서 자세 제어된 캐릭터라고 함은, 캐릭터가 다양한 자세를 취하는 경우에도 캐릭터 의 일관성이 유지되어 보는 사람에게 동일한 캐릭터로 인식되는 캐릭터를 가리킨다. 달리 말하면, 웹 툰이나 애니메이션에 사용되는 캐릭터의 경우, 사진 등 하나의 프레임에 적용되는 캐릭터와는 달리 복수의 프레 임에 걸쳐서도 동일한 캐릭터로 인식되어야 하므로, 본 발명에서 정의하는 자세 제어된 캐릭터가 요구되는 것이다. 다만, 본 발명의 일 실시예에서는, 자세 제어된 \"캐릭터\"에 대해 설명하고 있지만 캐릭터 뿐만 아니라, \"무기\", \"자동차\"와 같은 아이템에 대해서도 이러한 자세 제어가 적용될 수도 있다. 이러한 자세 제어된 캐릭터를 생성하기 위해서 기존에는 상당히 많은 양의 데이터(예를 들어, 수백장의 캐릭터 이미지)를 이용해 지도 학습을 수행해야 하므로 많은 리소스가 소모된다는 단점이 존재하였다. 또한, 자세 제 어를 위해 컨트롤넷(Controlnet)과 같은 애플리케이션을 이용하는 경우 캐릭터의 일관성(즉, 동일한 캐릭터로 인식되는 것)이 깨지는 문제가 발생하는 경우가 빈번하였다. 이와 비교하여, 본 발명의 일 실시예에 따른 인공 지능 기반 캐릭터 생성 장치에는 10장 이내의 캐릭터 이 미지를 생성하는 것만으로 자세 제어된 캐릭터를 생성할 수 있게 되므로, 많은 리소스의 소모 없이도 효율 적으로 일관성 있는 캐릭터 생성을 할 수 있다는 효과를 가진다. 이하에서는 인공 지능 기반 캐릭터 생성 장치의 구체적인 동작에 대해 설명하도록 한다. 도 2는 본 발명의 일 실시예에 따른 인공 지능 기반 캐릭터 생성 방법을 설명하기 위한 흐름도이다. 도 1 및 도 2를 참조하면, 먼저, 단계 S10에서, 사용자는 프롬프트 입력을 인공 지능 기반 캐릭터 생성 장치에 입력할 수 있다. 프롬프트 입력은 특수한 형식을 갖춘 콘티, 특정 형식을 갖추지 않은 문장 등을 포함할 수 있다. 단계 S20에서, 프롬프트 분석 모듈은 특수한 형식을 갖춘 콘티나 특정 형식을 갖추지 않은 문장과 같은 프 롬프트 입력을 수신하고 이를 구문 분석하여 핵심 단어를 추출할 수 있다. 핵심 단어의 추출은, 전처리된 프롬프트 입력에서 캐릭터의 외형, 유사 캐릭터, 캐릭터의 개성 등과 관련된 핵심 단어를 추출하기 위한 과 정일 수 있다. 프롬프트 입력에 대해 구문 분석을 수행하여 핵심 단어를 추출하기 이전에, 프롬프트 입력에 대해 전처 리를 수행하는 프롬프트 분석 모듈에서 처리되기 적절한 형태로 조정하는 과정이 수반될 수 있다. 일례로, 프롬프트 입력을 ChatGPT와 같은 초대형 인공신경망에 정해진 규칙 또는 형식에 따라 입력함으로써 전처리 할 수 있다. 단계 S30에서, 캐릭터 생성 모듈은 추출된 핵심 단어에 기초하여 기본 캐릭터를 생성할 수 있다. 이러한 기본 캐릭터는 복수 개가 생성될 수 있으며, 생성된 복수 개의 기본 캐릭터 중에서 사용자가 맘에 드는 캐릭터 를 선택하는 과정을 포함할 수 있다. 비제한적인 예로써, 이러한 기본 캐릭터의 생성에는 생성형 AI, 예를 들어, GAN 계열의 인공 신경망이 이용될 수 있다. GAN 계열의 인공 신경망은 생성자와 판별자가 서로의 성능을 개선해 적대적으로 경쟁해 나가는 모델 이다. GAN을 활용한 이미지 생성 및 변환 기술은 인공 신경망이 다양한 입력을 받아 원하는 카테고리의 기존에 존재하지 않는 새로운 이미지를 생성해 내거나 입력 이미지나 비디오를 다른 형태나 정보를 지닌 이미지 또는 비디오로 변환하는 기술로 최근 몇 년간 급속도로 발전하여 많은 관심을 받고 활발하게 연구되고 있는 분야이다. GAN 계열의 인공 신경망은 DCGAN(Deep Convolutional GAN), CGAN(Conditional GAN), Info GAN, WGAN(Wassersten GAN), Attention GAN, cycle GAN, PGGAN, Style GAN 등 다양한 유형을 포함할 수 있으며, 이 에 대해 한정하지는 않는다. 단계 S40에서, 생성된 기본 캐릭터에 대해 소정 개수의 기본 자세 이미지를 생성할 수 있다. 기본 자세 이미지 는 사전에 설정된 자세를 취했을 때 캐릭터의 이미지를 가리킬 수 있다. 예를 들어, 캐릭터가 의자에 앉아 있 을 때의 자세, 팔짱을 끼고 있을 때의 자세, 책상에 걸터앉아 있을 때의 자세, 앞을 응시하고 있을 때의 자세, 턱을 괴고 있을 때의 자세 등을 기본 자세 이미지로 설정할 수 있다. 단계 S50에서, 소정 개수의 기본 자세 이미지에 기초하여 자세 제어 학습을 수행하여 자세 제어된 캐릭터를 생 성할 수 있다. 여기서, 본 발명의 일 실시예에 따른 자세 제어 학습은 트랜스포머 기반 강화 학습을 포함할 수 있다. 이에 대해 도 3을 참조하여 더 자세히 설명하도록 한다. 도 3은 본 개시의 일 실시예에 따른 캐릭터 자세 제어 모듈의 동작 메커니즘을 설명하기 위한 흐름도이다. 도 3을 참조하면, 도 2의 단계 S50, 즉, 소정 개수의 소정 개수의 기본 자세 이미지에 기초하여 자세 제어 학습 을 수행하여 캐릭터에 대한 자세 데이터를 생성하고, 이를 캐릭터에 적용함으로써 자세 제어된 캐릭터를 생성하 는 단계는 도 3의 단계 S52 내지 단계 S54를 포함할 수 있다. 먼저, 단계 S40에서는, 생성된 기본 캐릭터에 대한 소정 개수의 기본 자세 이미지들을 생성할 수 있다. 단계 S52에서는, 소정 개수의 기본 자세 이미지들에 대해 랜드마크를 자동 생성한 후, 랜드마크들을 상호 관계 에 따라 이어서 생성한 소정 개수의 캐릭터 관절 이미지들을 생성할 수 있다. 일 실시예에 따르면, 이러한 관 절 이미지는 사용자 인터페이스를 통해 사용자에게 표시될 수 있으며, 사용자는 표시된 관절 이미지의 랜드마크 를 조정하는 사용자 피드백을 수행할 수 있다. 이러한 과정을 통해, 각 기본 자세 이미지에 대한 사용자 피드 백 및 캘리브레이션을 거쳐 강화 학습의 기초가 될 수 있는 소정 개수의 캐릭터 관절 이미지들이 생성될 수 있 다. 단계 S53에서는, 소정 개수의 캐릭터 관절 이미지들(즉, 사용자 피드백에 의해 정정된 기본 자세 이미지들)이 트랜스포머 기반 인공 신경망에 입력될 수 있다. 단계 S54에서, 트랜스포머 기반 인공 신경망은 입력받은 소정 개수의 캐릭터 관절 이미지들에 기초하여 자세 제 어된 캐릭터를 생성할 수 있다. 도 4는 본 발명의 일 실시예에 따른 트랜스포머 기반 강화 학습을 수행하는 인공 신경망 모듈을 이용하여 자세 제어된 캐릭터를 생성하는 과정을 설명하기 위한 도면이다. 도 4를 참조하면, 캐릭터 자세 제어 모듈은 트랜스포머 기반 인공 신경망 모듈을 포함할 수 있으며, 이 러한 트랜스포머 기반 인공 신경망 모듈을 이용한 강화 학습을 통해 소정 개수의 캐릭터 관절 이미지들에 기초하여 자세 제어된 캐릭터를 생성할 수 있다. 트랜스포머 기반 인공 신경망 모듈에는 미래 기대 보상 (Rt), 상태 정보(St), 및 인공 신경망 모듈에서 이전에 출력한 결과물인 과거 출력 이미지(at-1)가 입력될 수 있다. 여기서, 미래 기대 보상(Rt)은 Return to go로써 캐릭터 자세 제어 모듈에서 특정 액션을 취함으로써, 즉, 캐릭터 자세 제어 모듈에서 자세 제어된 캐릭터를 생성함으로써 미래에 기대되는 보상들의 총합을 나타낸다. 예를 들어, 사용자로부터 캐릭터 정정 요청과 같이 부정적인 피드백을 받는 것 등에 기초하여 미래 기대 보상(Rt)이 설정될 수 있다. 상태 정보(St)는 예를 들어, 기본 캐릭터 이미지에 해당할 수 있다. 과거 출력(at-1)는 트랜스포머 기반 인공 신경망 모듈에 대한 입출력이 실시간으로 또는 시계열적으로 이루 어지는 경우에, 트랜스포머 기반 인공 신경망 모듈에서 이전에 출력한 값(즉, 소정 개수의 캐릭터 관절 이 미지들)을 나타낸다. 이와 같이 미래 기대 보상(Rt), 상태 정보(St), 과거 출력(at-1)이 트랜스포머 기반 인공 신경망 모듈에 입 력되면, 트랜스포머 기반 인공 신경망 모듈는 캐릭터 자세 제어 모듈에서 현 시점에서 선택할, 캐릭터 의 원하는 자세에 대한 최적의 캐릭터 관절 이미지(at)(또는 자세 제어된 캐릭터 이미지)를 출력할 수 있다. 이하에서는, 트랜스포머 기반 인공 신경망 모듈을 통해 입력 데이터를 처리하여 결과 값을 출력하는 과정을 설명하도록 한다. 도 4를 참조하면, 본 발명의 일 실시예에 따르면, 트랜스포머 기반 인공 신경망 모듈은 제1 블록(10a)(예를 들어, 인코더) 및 제2 블록(10b)(예를 들어, 디코더)을 포함할 수 있다.인공 신경망 모듈의 제1 블록(10a)에 미래 기대 보상(Rt) 및 상태 정보(St)(예: 기본 캐릭터 이미지)가 입 력될 수 있다. 그리고, 이처럼 입력된 미래 기대 보상(Rt) 및 상태 정보(St)는 제1 블록(10a)의 임베딩 모듈에 입력되어 벡터화됨으로써 임베딩 정보가 출력되고 출력된 임베딩 정보의 묶음을 서로 다른 Linear Layer를 통해 Linear embedding하여 features dimension을 포함하는 Q(Query feature), K(Key feature), V(Value feature) 로 구성한 뒤, Q(Query feature), K(Key feature), V(Value feature)를 Multi-head Attention Layer의 입력 데이터로 할 수 있다. Q, K, V는 임베딩 정보로부터 서로 다른 Linear embedding을 통해 생성될 수 있다. Q와 K는 1st MatMul operation의 입력 데이터로 입력되어 Scale 및 softmax operation을 통해 Q에 대해서 모든 K에 대한 유사도를 계산하여 일련의 임베딩 정보 사이의 유사도 벡터를 출력하고, 이 유사도 벡터와 V는 2nd MatMul operation의 입력 데이터로 입력될 수 있다. 그리고, Multi-head Attention Layer는 입력 받은 Q, K, V 값에 기초하여 어텐션 정보를 출력하여 Feed Forward Layer로 입력할 수 있다. 이러한 Multi-head Attention Layer 및 Feed Forward Layer는 N번 반복될 수 있으며, 이전 Feed Forward Layer에서 출력된 인코딩 정보가 그 다음 Multi-head Attention Layer의 입력이 되는 방식으로 반복이 이루어질 수 있다. 그리고 마지막 Feed Forward Layer는 최종 인코딩 정보를 출력할 수 있는데, 이러한 최종 인코딩 정보는 트랜스포머 기반 인공 신경망 모듈 의 제2 블록(10b)의 제2 Multi-head Attention Layer에 K(Key), V(Value) 값으로서 입력될 수 있다. 또한, 트랜스포머 기반 인공 신경망 모듈의 제2 블록(10b)에는 과거 출력(at-1)이 입력될 수 있다. 여기서 과거 출력(at-1)은 제2 블록(10b)의 임베딩 모듈에 입력되어 벡터화됨으로써 임베딩 정보가 출력되고 출력된 임 베딩 정보의 묶음을 서로 다른 Linear Layer를 통해 Linear embedding하여 features dimension을 포함하는 Q(Query feature), K(Key feature), V(Value feature)로 구성한 뒤, Q(Query feature), K(Key feature), V(Value feature)를 제1 Multi-head Attention Layer의 입력 데이터로 할 수 있다. 그리고 제1 Multi-head Attention Layer는 Q(Query) 값을 출력할 수 있는데 이 Q 값은 제2 Multi-head Attention Layer로 입력된다. 제2 Multi-head Attention Layer는 K, V 값으로는 제1 블록(10a)으로부터의 최종 인코딩 정보를 입력받을 수 있다. 그리고 제2 Multi-head Attention Layer는 입력 받은 Q, K, V 값에 기초하여 어텐션 정보를 출력하여 Feed Forward Layer로 입력할 수 있다. 이러한 제1 Multi-head Attention Layer, 제2 Multi-head Attention Layer 및 Feed Forward Layer는 N번 반복될 수 있으며, 이전 Feed Forward Layer에서 출력된 디코딩 정보가 그 다음 제1 Multi-head Attention Layer의 입력이 되는 방식으로 반복이 이루어질 수 있다. 그리고 마지막 Feed Forward Layer는 최종 디코딩 정보를 출력할 수 있는데, 이러한 최종 디코딩 정보는 Linear Layer 및 Softmax Layer를 거쳐, 트랜스포머 인공 신경망 모듈은 캐릭터 자세 제어 모듈에서 현 시점에서 선택할, 캐릭터 의 원하는 자세에 대한 최적의 캐릭터 관절 이미지(at)(또는 자세 제어된 캐릭터 이미지)를 출력할 수 있다. 다만, 전술한 것과 같은 트랜스포머 기반 인공 신경망 모듈의 구체적인 구현 방식은 다양하게 달라질 수 있 으며, 이에 대해 한정하지는 않는다. 본 개시에 첨부된 블록도의 각 블록과 흐름도의 각 단계의 조합들은 컴퓨터 프로그램 인스트럭션들에 의해 수행 될 수도 있다. 이들 컴퓨터 프로그램 인스트럭션들은 범용 컴퓨터, 특수용 컴퓨터 또는 기타 프로그램 가능한 데이터 프로세싱 장비의 프로세서에 탑재될 수 있으므로, 컴퓨터 또는 기타 프로그램 가능한 데이터 프로세싱 장비의 프로세서를 통해 수행되는 그 인스트럭션들이 블록도의 각 블록 또는 흐름도의 각 단계에서 설명된 기능 들을 수행하는 수단을 생성하게 된다. 이들 컴퓨터 프로그램 인스트럭션들은 특정 방식으로 기능을 구현하기 위 해 컴퓨터 또는 기타 프로그램 가능한 데이터 프로세싱 장비를 지향할 수 있는 컴퓨터 이용 가능 또는 컴퓨터 판독 가능 메모리에 저장되는 것도 가능하므로, 그 컴퓨터 이용가능 또는 컴퓨터 판독 가능 메모리에 저장된 인 스트럭션들은 블록도의 각 블록 또는 흐름도 각 단계에서 설명된 기능을 수행하는 인스트럭션 수단을 내포하는 제조 품목을 생산하는 것도 가능하다. 컴퓨터 프로그램 인스트럭션들은 컴퓨터 또는 기타 프로그램 가능한 데이 터 프로세싱 장비 상에 탑재되는 것도 가능하므로, 컴퓨터 또는 기타 프로그램 가능한 데이터 프로세싱 장비 상 에서 일련의 동작 단계들이 수행되어 컴퓨터로 실행되는 프로세스를 생성해서 컴퓨터 또는 기타 프로그램 가능 한 데이터 프로세싱 장비를 수행하는 인스트럭션들은 블록도의 각 블록 및 흐름도의 각 단계에서 설명된 기능들 을 실행하기 위한 단계들을 제공하는 것도 가능하다. 또한, 각 블록 또는 각 단계는 특정된 논리적 기능(들)을 실행하기 위한 하나 이상의 실행 가능한 인스트럭션들 을 포함하는 모듈, 세그먼트 또는 코드의 일부를 나타낼 수 있다. 또, 몇 가지 대체 실시예들에서는 블록들 또 는 단계들에서 언급된 기능들이 순서를 벗어나서 발생하는 것도 가능함을 주목해야 한다. 예컨대, 잇달아 도시 되어 있는 두 개의 블록들 또는 단계들은 사실 실질적으로 동시에 수행되는 것도 가능하고 또는 그 블록들 또는단계들이 때때로 해당하는 기능에 따라 역순으로 수행되는 것도 가능하다. 이상에서 설명한 바와 같이, 본 발명이 속하는 기술 분야의 통상의 기술자는 본 발명이 그 기술적 사상이나 필 수적 특징을 변경하지 않고서 다른 구체적인 형태로 실시될 수 있다는 것을 이해할 수 있을 것이다. 그러므로 상술한 실시예들은 모든 면에서 예시적인 것이며 한정적인 것이 아닌 것으로서 이해해야만 한다. 본 발명의 범 위는 상세한 설명보다는 후술하는 특허청구범위에 의하여 나타내어지며, 특허청구범위의 의미 및 범위 그리고 등가 개념으로부터 도출되는 모든 변경 또는 변형된 형태가 본 발명의 범위에 포함하는 것으로 해석되어야 한다. 본 명세서 내에 기술된 특징들 및 장점들은 모두를 포함하지 않으며, 특히 많은 추가적인 특징들 및 장점들이 도면들, 명세서, 및 청구항들을 고려하여 당업자에게 명백해질 것이다. 더욱이, 본 명세서에 사용된 언어는 주 로 읽기 쉽도록 그리고 교시의 목적으로 선택되었고, 본 발명의 주제를 묘사하거나 제한하기 위해 선택되지 않 을 수도 있다는 것을 주의해야 한다. 본 발명의 실시예들의 상기한 설명은 예시의 목적으로 제시되었다. 이는 개시된 정확한 형태로 본 발명을 제한 하거나, 빠뜨리는 것 없이 만들려고 의도한 것이 아니다. 당업자는 상기한 개시에 비추어 많은 수정 및 변형이 가능하다는 것을 이해할 수 있다. 그러므로 본 발명의 범위는 상세한 설명에 의해 한정되지 않고, 이를 기반으로 하는 출원의 임의의 청구항들에 의해 한정된다. 따라서, 본 발명의 실시예들의 개시는 예시적인 것이며, 이하의 청구항에 기재된 본 발명의 범 위를 제한하는 것은 아니다."}
{"patent_id": "10-2023-0076056", "section": "도면", "subsection": "도면설명", "item": 1, "content": "본 명세서에 첨부되는 다음의 도면들은 본 발명의 바람직한 실시예를 예시하는 것이며, 발명의 상세한 설명과 함께 본 발명의 기술사상을 더욱 이해시키는 역할을 하는 것이므로, 본 발명은 그러한 도면에 기재된 사항에만 한정되어 해석되어서는 아니 된다. 도 1은 본 발명의 일 실시예에 따른 인공 지능 기반 캐릭터 생성 장치를 개략적으로 도시한 블록도이다. 도 2는 본 발명의 일 실시예에 따른 인공 지능 기반 캐릭터 생성 방법을 설명하기 위한 흐름도이다. 도 3은 본 개시의 일 실시예에 따른 캐릭터 자세 제어 모듈의 동작 메커니즘을 설명하기 위한 흐름도이다. 도 4는 본 발명의 일 실시예에 따른 트랜스포머 기반 강화 학습을 수행하는 인공 신경망 모듈을 이용하여 자세 제어된 캐릭터를 생성하는 과정을 설명하기 위한 도면이다."}
