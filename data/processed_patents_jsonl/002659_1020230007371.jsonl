{"patent_id": "10-2023-0007371", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0114987", "출원번호": "10-2023-0007371", "발명의 명칭": "인공지능 기반의 브랜드 정보를 생성하는 방법 및 장치", "출원인": "주식회사 플로드엠", "발명자": "강건욱"}}
{"patent_id": "10-2023-0007371", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "브랜드에 대한 정보의 생성을 지원하는 컴퓨팅 장치에 있어서,사용자 단말로부터 상기 브랜드에 대한 검색어를 수신하고, 미리 지정된 네트워크를 통해 상기 브랜드에 대한검색어를 포함하는 복수의 동영상 데이터를 수집하는 통신부; 및프로세서를 포함하고,상기 프로세서에 의해 구현되는:상기 복수의 동영상 데이터 각각에 대해 미리 지정된 조회수 이상을 메타 정보로 갖는 프레임을 추출하는 추출부;상기 추출된 프레임 내에 삽입된 각각의 배경음악 음원 데이터를 멜 스펙트로그램(mel spectrogram)으로 변환하는 변환부;상기 추출된 프레임에 대응하는 배경음악 음원 데이터의 BPM(beat per minute) 및 멜 스펙트로그램을 입력 데이터로서 미리 학습된 인공신경망에 입력함으로써, 상기 배경음악 음원 데이터의 장르(genre)를 출력 데이터로서획득하고 상기 획득된 장르를 이용하여 상기 브랜드에 대한 감성 정보를 출력하는 판단부를 포함하는 컴퓨팅 장치."}
{"patent_id": "10-2023-0007371", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 판단부는,각각의 장르에 대한 후기 데이터로부터 크롤링된 감성 키워드들과 각각의 장르를 매핑하여 저장한 룩-업 테이블을 이용하여 상기 브랜드에 대한 감성 정보를 출력하고,상기 복수의 동영상 데이터 내에 포함되는 배경음악 음원 데이터 각각의 장르 정보와 감성 정보를 출력하는 컴퓨팅 장치."}
{"patent_id": "10-2023-0007371", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 미리 학습된 인공신경망은,내부 노드들을 연결하는 복수의 레이어 중 제1 레이어를 DNN(deep neural network)으로 구현하고, 제2 레이어를CNN(convolution neural network)으로 구현하고,각각의 음원 데이터 별로 라벨링된 BPM, 제로 크로싱 레이트(zero crossing rate), 배음(harmonic),percussive components, 스펙트럴 센트로이드(spectral centroid), 스펙트럴 롤오프(spectral rolloff), 멜 주파수 켑스트럴 계수(Mel-Frequency Cepstral Coefficients), 크로마 주파수(Chroma frequencies)를 입력 데이터로 하고, 상기 각각의 음원 데이터의 장르를 출력 데이터로서 지도 학습된 인공신경망인 것을 특징으로 하는컴퓨팅 장치."}
{"patent_id": "10-2023-0007371", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,상기 판단부는,공개특허 10-2024-0114987-3-상기 추출된 프레임 내의 픽셀 데이터를 미리 지정된 개수의 영역으로 분할하고, 상기 분할된 영역의 픽셀 데이터의 색채 파라미터의 평균값을 상기 브랜드에 대한 색상 정보로서 판단하는 컴퓨팅 장치."}
{"patent_id": "10-2023-0007371", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서,상기 판단부는,상기 색채 파라미터를 복수의 구간으로 나누고, 각각의 구간에 포함되는 상기 분할된 영역의 픽셀 데이터의 색채 파라미터의 평균값들의 개수에 따라 가중치를 결정함으로써 상기 브랜드에 대한 색상 정보를 결정하는 컴퓨팅 장치."}
{"patent_id": "10-2023-0007371", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "인공지능 기반의 브랜드 정보를 생성을 지원하는 컴퓨팅 장치가 제공된다. 상기 컴퓨팅 장치는, 사용자 단말로 부터 상기 브랜드에 대한 검색어를 수신하고, 미리 지정된 네트워크를 통해 상기 브랜드에 대한 검색어를 포함하 는 복수의 동영상 데이터를 수집하는 통신부; 및 프로세서를 포함하고, 상기 프로세서에 의해 구현되는: 상기 복 수의 동영상 데이터 각각에 대해 미리 지정된 조회수 이상을 메타 정보로 갖는 프레임을 추출하는 추출부; 상기 추출된 프레임 내에 삽입된 각각의 배경음악 음원 데이터를 멜 스펙트로그램(mel spectrogram)으로 변환하는 변 환부; 상기 추출된 프레임에 대응하는 배경음악 음원 데이터의 BPM(beat per minute) 및 멜 스펙트로그램을 입력 데이터로서 미리 학습된 인공신경망에 입력함으로써, 상기 배경음악 음원 데이터의 장르(genre)를 출력 데이터로 서 획득하고 상기 획득된 장르를 이용하여 상기 브랜드에 대한 감성 정보를 출력하는 판단부를 포함할 수 있다."}
{"patent_id": "10-2023-0007371", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "이하에서는 인공지능 기반의 브랜드 정보를 생성하는 방법 및 장치가 개시된다. 더욱 상세하게는 브랜드에 대한 동영상을 수집하여 동영상에 삽입된 음원 데이터를 멜 스펙트로그램(mel spectrogram)으로 변환하여 시각화된 음원 데이터를 통해 브랜드 감성 정보를 생성하는 방법 및 장치가 개시된다."}
{"patent_id": "10-2023-0007371", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "인공지능(Artificial Intelligence, AI) 시스템은 인간 수준의 지능을 구현하는 컴퓨터 시스템이며, 기존 규칙 기반 스마트 시스템과 달리 기계가 스스로 학습하고 판단하며 똑똑해지는 시스템이다. 인공지능 시스템은 사용 할수록 인식률이 향상되고 사용자 취향을 보다 정확하게 이해할 수 있게 되어, 기존 규칙 기반 스마트 시스템은 점차 딥러닝 기반 인공지능 시스템으로 대체되고 있다. 최근에는, 하드웨어 기술의 발전에 힘입어 빅데이터의 수집과 저장이 가능해지고, 이를 분석하는 컴퓨터 능력과 기술이 정교해지고 빨라짐에 따라, 인간처럼 사물을 인식하고 정보를 이해할 수 있는 알고리즘인 머신러닝에 대"}
{"patent_id": "10-2023-0007371", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 2, "content": "한 연구가 활발히 진행되고 있다. 특히, 머신 러닝 기술분야에서도 인공신경망을 이용한 자율학습 방식의 딥 러 닝에 대한 연구가 활발하다. 인공신경망 인간의 뇌의 기능을 적극적으로 모방하려는 의도에 기초하여, 복수의 입력에 가중치를 곱한 총합에 대하여 활성 함수가 특정 경계값과 비교하여 최종 출력을 결정하는 알고리즘으로, 일반적으로 복수의 레이어로 구성되어 있다. DNN(deep neural network), CNN(convolutional neural network), RNN(recurrent neural network) 등과 같은 다양한 딥러닝 기법들이 음성 신호 처리, 자연 언어 처리, 비전 처리 등의 분야에 적용되어 우수한 성능의 응용 프로그램들이 개발되고 있다. 브랜드는 특정한 제품 및 서비스를 식별하는데 사용되는 명칭, 기호 및 디자인을 총칭한다. 브랜드는 소비자들 에게 해당 제품 및 서비스를 각인시키기 위한 강력한 수단으로 이용될 수 있다. 이러한 브랜드를 통한 경영은 기술 고도화로 제품의 기술력 차이가 현저히 줄어든 근래의 경영 환경에서 기업의 생존을 좌우하는 핵심 경영수 단으로 자리매김하고 있다. 브랜드를 홍보, 마케팅하기 위해 중요한 것은 경쟁사나 지향하는 기업을 분석하는 것이 중요하다. 이를 위해 온 라인 상에 개시된 브랜드에 대한 광고 영상, 사용후기 영상, 제품 홍보 영상, 서비스 홍보 영상 등 관련 다수의 영상들을 빠른 시간에 분석하여 마케터나 디자이너를 포함하는 사용자에게 브랜드에 대한 정보를 제공할 필요가 있다."}
{"patent_id": "10-2023-0007371", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 개시의 기술적 사상이 해결하려는 과제는, 브랜드와 연관된 동영상에 삽입된 음원 데이터를 멜 스펙트로그램 변환을 통해 시각화하고, 학습된 인공신경망에 입력하여 상기 음원 데이터의 장르를 분류하여 브랜드와 연관된 감성 정보를 제공하는 데 있다.본"}
{"patent_id": "10-2023-0007371", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "이하에서 개시되는 적어도 하나의 실시 예는 상기의 종래 기술의 문제를 해결하기 위한 것으로, 인공지능 기반 의 브랜드 정보 생성 방법 및 장치를 제공하는 것을 목적으로 한다. 일 실시예에 따른 브랜드에 대한 정보의 생성을 지원하는 컴퓨팅 장치에 있어서, 사용자 단말로부터 상기 브랜 드에 대한 검색어를 수신하고, 미리 지정된 네트워크를 통해 상기 브랜드에 대한 검색어를 포함하는 복수의 동 영상 데이터를 수집하는 통신부; 및 프로세서를 포함하고, 상기 프로세서에 의해 구현되는: 상기 복수의 동영상 데이터 각각에 대해 미리 지정된 조회수 이상을 메타 정보로 갖는 프레임을 추출하는 추출부; 상기 추출된 프레 임 내에 삽입된 각각의 배경음악 음원 데이터를 멜 스펙트로그램(mel spectrogram)으로 변환하는 변환부; 상기 추출된 프레임에 대응하는 배경음악 음원 데이터의 BPM(beat per minute) 및 멜 스펙트로그램을 입력 데이터로 서 미리 학습된 인공신경망에 입력함으로써, 상기 배경음악 음원 데이터의 장르(genre)를 출력 데이터로서 획득 하고 상기 획득된 장르를 이용하여 상기 브랜드에 대한 감성 정보를 출력하는 판단부를 포함할 수 있다. 다른 일 실시예에 따른 상기 판단부는, 각각의 장르에 대한 후기 데이터로부터 크롤링된 감성 키워드들과 각각 의 장르를 매핑하여 저장한 룩-업 테이블을 이용하여 상기 브랜드에 대한 감성 정보를 출력하고, 상기 복수의 동영상 데이터 내에 포함되는 배경음악 음원 데이터 각각의 장르 정보와 감성 정보를 출력할 수 있다. 또 다른 일 실시예에 따른 상기 미리 학습된 인공신경망은, 내부 노드들을 연결하는 복수의 레이어 중 제1 레이 어를 DNN(deep neural network)으로 구현하고, 제2 레이어를 CNN(convolution neural network)으로 구현하고, 각각의 음원 데이터 별로 라벨링된 BPM, 제로 크로싱 레이트(zero crossing rate), 배음(harmonic), percussive components, 스펙트럴 센트로이드(spectral centroid), 스펙트럴 롤오프(spectral rolloff), 멜 주 파스 켑스트럴 계수(Mel-Frequency Cepstral Coefficients), 크로마 주파수(Chroma frequencies)를 입력 데이 터로 하고, 상기 각각의 음원 데이터의 장르를 출력 데이터로서 지도 학습된 인공신경망인 것을 특징으로 할 수 있다. 또 다른 일 실시예에 따른 상기 판단부는, 상기 추출된 프레임 내의 픽셀 데이터를 미리 지정된 개수의 영역으 로 분할하고, 상기 분할된 영역의 픽셀 데이터의 색채 파라미터의 평균값을 상기 브랜드에 대한 색상 정보로서 판단할 수 있다. 또 다른 일 실시예에 따른 상기 판단부는, 상기 색채 파라미터를 복수의 구간으로 나누고, 각각의 구간에 포함 되는 상기 분할된 영역의 픽셀 데이터의 색채 파라미터의 평균값들의 개수에 따라 가중치를 결정함으로써 상기 브랜드에 대한 색상 정보를 결정할 수 있다."}
{"patent_id": "10-2023-0007371", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "가 상술한 효과들로 제한되는 것은 아니며, 언급되지 아니한 효과들은 본 명세서 및 첨부된 도면"}
{"patent_id": "10-2023-0007371", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 2, "content": "으로부터 본 발명이 속하는 기술분야에서 통상의 지식을 가진 자에게 명확히 이해될 수 있을 것이다."}
{"patent_id": "10-2023-0007371", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 3, "content": "과제의 해결 수단 이하에서 개시되는 적어도 하나의 실시 예는 상기의 종래 기술의 문제를 해결하기 위한 것으로, 인공지능 기반 의 브랜드 정보 생성 방법 및 장치를 제공하는 것을 목적으로 한다. 일 실시예에 따른 브랜드에 대한 정보의 생성을 지원하는 컴퓨팅 장치에 있어서, 사용자 단말로부터 상기 브랜 드에 대한 검색어를 수신하고, 미리 지정된 네트워크를 통해 상기 브랜드에 대한 검색어를 포함하는 복수의 동 영상 데이터를 수집하는 통신부; 및 프로세서를 포함하고, 상기 프로세서에 의해 구현되는: 상기 복수의 동영상 데이터 각각에 대해 미리 지정된 조회수 이상을 메타 정보로 갖는 프레임을 추출하는 추출부; 상기 추출된 프레 임 내에 삽입된 각각의 배경음악 음원 데이터를 멜 스펙트로그램(mel spectrogram)으로 변환하는 변환부; 상기 추출된 프레임에 대응하는 배경음악 음원 데이터의 BPM(beat per minute) 및 멜 스펙트로그램을 입력 데이터로 서 미리 학습된 인공신경망에 입력함으로써, 상기 배경음악 음원 데이터의 장르(genre)를 출력 데이터로서 획득 하고 상기 획득된 장르를 이용하여 상기 브랜드에 대한 감성 정보를 출력하는 판단부를 포함할 수 있다. 다른 일 실시예에 따른 상기 판단부는, 각각의 장르에 대한 후기 데이터로부터 크롤링된 감성 키워드들과 각각 의 장르를 매핑하여 저장한 룩-업 테이블을 이용하여 상기 브랜드에 대한 감성 정보를 출력하고, 상기 복수의 동영상 데이터 내에 포함되는 배경음악 음원 데이터 각각의 장르 정보와 감성 정보를 출력할 수 있다. 또 다른 일 실시예에 따른 상기 미리 학습된 인공신경망은, 내부 노드들을 연결하는 복수의 레이어 중 제1 레이 어를 DNN(deep neural network)으로 구현하고, 제2 레이어를 CNN(convolution neural network)으로 구현하고, 각각의 음원 데이터 별로 라벨링된 BPM, 제로 크로싱 레이트(zero crossing rate), 배음(harmonic), percussive components, 스펙트럴 센트로이드(spectral centroid), 스펙트럴 롤오프(spectral rolloff), 멜 주 파스 켑스트럴 계수(Mel-Frequency Cepstral Coefficients), 크로마 주파수(Chroma frequencies)를 입력 데이 터로 하고, 상기 각각의 음원 데이터의 장르를 출력 데이터로서 지도 학습된 인공신경망인 것을 특징으로 할 수 있다. 또 다른 일 실시예에 따른 상기 판단부는, 상기 추출된 프레임 내의 픽셀 데이터를 미리 지정된 개수의 영역으 로 분할하고, 상기 분할된 영역의 픽셀 데이터의 색채 파라미터의 평균값을 상기 브랜드에 대한 색상 정보로서 판단할 수 있다. 또 다른 일 실시예에 따른 상기 판단부는, 상기 색채 파라미터를 복수의 구간으로 나누고, 각각의 구간에 포함 되는 상기 분할된 영역의 픽셀 데이터의 색채 파라미터의 평균값들의 개수에 따라 가중치를 결정함으로써 상기 브랜드에 대한 색상 정보를 결정할 수 있다."}
{"patent_id": "10-2023-0007371", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 4, "content": "발명의 효과 본 개시의 기술적 사상의 인공신경망을 이용한 브랜드 정보를 생성하는 방법에 따르면, 정확성이 높은 브랜드와 연상되는 이미지를 포함하는 감성 정보를 파악할 수 있다는 효과가 있다. 본 개시의 기술적 사상의 인공신경망을 이용한 브랜드 정보를 생성하는 방법에 따르면, 브랜드와 관련된 대량의 동영상에 담겨있는 브랜드에 대한 정보를 빠른 시간안에 수요자에게 제공함으로써 브랜드 홍보 및 마케팅에 중 요한 정보를 얻을 수 있다는 효과가 있다."}
{"patent_id": "10-2023-0007371", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "후술하는 본 발명에 대한 상세한 설명은, 본 발명의 목적들, 기술적 해법들 및 장점들을 분명하게 하기 위하여 본 발명이 실시될 수 있는 특정 실시 예를 예시로서 도시하는 첨부 도면을 참조한다. 이들 실시 예는 통상의 기술자가 본 발명을 실시할 수 있도록 상세히 설명된다. 본 발명의 상세한 설명 및 청구항들에 걸쳐, '포함하다'라는 단어 및 그 변형은 다른 기술적 특징들, 부가물들, 구성요소들 또는 단계들을 제외하는 것으로 의도된 것이 아니다. 또한, ‘하나’ 또는 ‘한’은 하나 이상의 의미로 쓰인 것이며, ‘또 다른’은 적어도 두 번째 이상으로 한정된다. 또한, 본 발명의 '제1', '제2' 등의 용어는 하나의 구성요소를 다른 구성요소로부터 구별하기 위한 것으로서, 순서를 나타내는 것으로 이해되지 않는 한 이들 용어들에 의하여 권리범위가 한정되어서는 아니 된다. 예를 들 어, 제1 구성요소는 제2 구성요소로 명명될 수 있고, 이와 유사하게 제2 구성요소도 제1 구성요소로 명명될 수 있다. 어떤 구성요소가 다른 구성요소에 \"연결되어\" 있다고 언급된 때에는 그 다른 구성요소에 직접 연결될 수도 있지 만 중간에 다른 구성요소가 개재할 수도 있다고 이해되어야 할 것이다. 반면에 어떤 구성요소가 다른 구성요소 에 \"직접 연결되어\" 있다고 언급된 때에는 중간에 다른 구성요소가 존재하지 않는 것으로 이해되어야 할 것이다. 한편, 구성요소들 간의 관계를 설명하는 다른 표현들, 즉, \"~사이에\"와 \"바로 ~사이에\" 또는 \"~에 이 웃하는\"과 \"~에 직접 이웃하는\" 등도 마찬가지로 해석되어야 한다. 각 단계들에 있어서 식별부호(예를 들어, a, b, c 등)는 설명의 편의를 위하여 사용된 것으로 식별부호는 논리 상 필연적으로 귀결되지 않는 한 각 단계들의 순서를 설명하는 것이 아니며, 각 단계들은 명기된 순서와 다르게 일어날 수 있다. 즉, 각 단계들은 명기된 순서와 동일하게 일어날 수도 있고 실질적으로 동시에 수행될 수도 있으며, 반대의 순서로 수행될 수도 있다. 통상의 기술자에게 본 발명의 다른 목적들, 장점들 및 특성들이 일부는 본 설명서로부터, 그리고 일부는 본 발 명의 실시로부터 드러날 것이다. 아래의 예시 및 도면은 실례로서 제공되며, 본 발명을 한정하는 것으로 의도된 것이 아니다. 따라서, 특정 구조나 기능에 관하여 본 명세서에 개시된 상세 사항들은 한정하는 의미로 해석되 어서는 아니되고, 단지 통상의 기술자가 실질적으로 적합한 임의의 상세 구조들로써 본 발명을 다양하게 실시하 도록 지침을 제공하는 대표적인 기초 자료로 해석되어야 할 것이다. 더욱이 본 발명은 본 명세서에 표시된 실시 예들의 모든 가능한 조합들을 망라한다. 본 발명의 다양한 실시 예 는 서로 다르지만 상호 배타적일 필요는 없음이 이해되어야 한다. 예를 들어, 여기에 기재되어 있는 특정 형상, 구조 및 특성은 일 실시 예에 관련하여 본 발명의 사상 및 범위를 벗어나지 않으면서 다른 실시 예로 구 현될 수 있다. 또한, 각각의 개시된 실시 예 내의 개별 구성요소의 위치 또는 배치는 본 발명의 사상 및 범위를 벗어나지 않으면서 변경될 수 있음이 이해되어야 한다. 따라서, 후술하는 상세한 설명은 한정적인 의미로서 취하려는 것이 아니며, 본 발명의 범위는, 적절하게 설명된다면, 그 청구항들이 주장하는 것과 균등한 모든 범 위와 더불어 첨부된 청구항에 의해서만 한정된다. 도면에서 유사한 참조부호는 여러 측면에 걸쳐서 동일하거나 유사한 기능을 지칭한다. 본 명세서에서 달리 표시되거나 분명히 문맥에 모순되지 않는 한, 단수로 지칭된 항목은, 그 문맥에서 달리 요 구되지 않는 한, 복수의 것을 아우른다. 또한, 본 발명을 설명함에 있어, 관련된 공지 구성 또는 기능에 대한 구체적인 설명이 본 발명의 요지를 흐릴 수 있다고 판단되는 경우에는 그 상세한 설명은 생략한다. 본 명세서에서의 프로세서(processor)는 하나 이상의 코어로 구성될 수 있으며, 컴퓨팅 장치의 중앙 처리 장치 (CPU: central processing unit), 범용 그래픽 처리 장치 (GPGPU: general purpose graphics processing unit), 텐서 처리 장치(TPU: tensor processing unit) 등의 데이터 분석, 딥러닝을 위한 프로세서를 포함할 수 있다. 프로세서는 메모리에 저장된 컴퓨터 프로그램을 판독하여 본 개시의 일 실시예에 따른 기계 학습을 위한 데이터 처리를 수행할 수 있다. 본 개시의 일실시예에 따라 프로세서는 신경망의 학습을 위한 연산을 수행 할 수 있다. 프로세서는 딥러닝(DL: deep learning)에서 학습을 위한 입력 데이터의 처리, 입력 데이터에서의 피처 추출, 오차 계산, 역전파(backpropagation)를 이용한 신경망의 가중치 업데이트 등의 신경망의 학습을 위 한 계산을 수행할 수 있다. 프로세서의 CPU, GPGPU, 및 TPU 중 적어도 하나가 네트워크 함수의 학습을 처리할 수 있다. 예를 들어, CPU 와 GPGPU가 함께 네트워크 함수의 학습, 네트워크 함수를 이용한 데이터 분류를 처리 할 수 있다. 또한, 본 개시의 일 실시예에서 복수의 컴퓨팅 장치의 프로세서를 함께 사용하여 네트워크 함수의 학습, 네트워크 함수를 이용한 데이터 분류를 처리할 수 있다. 또한, 본 개시의 일 실시예에 따른 컴퓨팅 장치 에서 수행되는 컴퓨터 프로그램은 CPU, GPGPU 또는 TPU 실행가능 프로그램일 수 있다. 다시 말해, 프로세서란 본 발명의 기술적 사상을 수행하기 위한 하드웨어 및/또는 상기 하드웨어를 구동하기 위 한 소프트웨어의 기능적 및/또는 구조적 결합을 의미할 수 있다. 이하, 통상의 기술자가 본 발명을 용이하게 실시할 수 있도록 하기 위하여, 본 발명의 바람직한 실시 예들에 관 하여 첨부된 도면을 참조하여 상세히 설명하기로 한다. 이하, 실시예들을 첨부된 도면을 참조하여 상세하게 설명한다. 그러나, 특허출원의 범위가 이러한 실시예들에 의해 제한되거나 한정되는 것은 아니다. 각 도면에 제시된 동일한 참조 부호는 동일한 부재를 나타낸다. 도 1a는 인공 신경망(Artificial Neural Network)을 이용한 딥러닝 연산 방법을 설명하기 위한 도면이다. 도 1a를 참조하면, 입력 데이터를 입력 받아 출력 데이터를 출력하는 인공 신경망의 구조를 도시한 다. 인공 신경망은 2개 이상의 레이어(layer)를 보유한 딥 뉴럴 네트워크(deep neural network)일 수 있 다. 본 실시예에서 입력 데이터는 음원 데이터의 BPM 또는 멜 스펙트로그램(Mel Spectrogram)으로 정의될 수 있다. 또한, 출력 데이터는 브랜드에 대한 감성 정보 또는 음원 데이터 각각의 장르 정보를 나타낼 수 있다. 딥러닝(Deep Learning) 등을 포함하는 인공지능(AI) 알고리즘은 인공 신경망에 입력 데이터를 입력시키 고, 컨볼루션 등의 연산을 통해 출력 데이터를 학습하고, 학습된 인공 신경망을 이용하여 특징을 추출 할 수 있다. 인공 신경망은 생물학적 뇌를 모델링한 컴퓨터 과학적 아키텍쳐(Computational Architectur e)를 의미할 수 있다. 인공 신경망 내에서, 뇌의 뉴런들에 해당되는 노드들은 서로 연결되어 있고, 입력 데이 터를 처리하기 위하여 집합적으로 동작한다. 인공 신경망(이하, 뉴럴 네트워크)은 기계학습과 인지과학에서 생물학의 신경을 모방한 통계학적 학습 알고리즘 을 포함할 수 있다. 뉴럴 네트워크는 시냅스의 결합으로 네트워크를 형성한 인공 뉴런(노드)이 학습을 통해 시 냅스의 결합 세기를 변화시켜, 문제 해결 능력을 가지는 모델 전반을 의미할 수 있다. 뉴럴 네트워크의 뉴런은 가중치 또는 바이어스의 조합을 포함할 수 있다. 뉴럴 네트워크는 하나 이상의 뉴런 또 는 노드로 구성된 하나 이상의 레이어(layer)를 포함할 수 있다. 뉴럴 네트워크는 뉴런의 가중치를 학습을 통해 변화시킴으로써 임의의 입력으로부터 예측하고자 하는 결과를 추론할 수 있다. 뉴럴 네트워크는 심층 뉴럴 네트워크 (Deep Neural Network)를 포함할 수 있다. 뉴럴 네트워크는 CNN(Convolutional Neural Network), RNN(Recurrent Neural Network), 퍼셉트론(perceptron), 다층 퍼셉트론 (multilayer perceptron), FF(Feed Forward), RBF(Radial Basis Network), DFF(Deep Feed Forward), LSTM(Long Short Term Memory), GRU(Gated Recurrent Unit), AE(Auto Encoder), VAE(Variational AutoEncoder), DAE(Denoising Auto Encoder), SAE(Sparse Auto Encoder), MC(Markov Chain), HN(Hopfield Network), BM(Boltzmann Machine), RBM(Restricted Boltzmann Machine), DBN(Depp Belief Network), DCN(Deep Convolutional Network), DN(Deconvolutional Network), DCIGN(Deep Convolutional Inverse Graphics Network), GAN(Generative Adversarial Network), LSM(Liquid State Machine), ELM(Extreme Learning Machine), ESN(Echo State Network), DRN(Deep Residual Network), DNC(Differentiable Neural Computer), NTM(Neural Turning Machine), CN(Capsule Network), KN(Kohonen Network) 및 AN(Attention Network)를 포함 할 수 있다. 피드-포워드(feed-forward) 뉴럴 네트워크에서, 뉴럴 네트워크의 뉴런들은 다른 뉴런들과의 연결들 (links)을 갖는다. 이와 같은 연결들은 뉴럴 네트워크를 통해, 한 방향으로, 예를 들어 순방향(forward direction)으로 확장될 수 있다. 도 1b는 일 실시예에 따른 인공 신경망을 이용한 브랜드 정보를 생성하는 방법을 설명하기 위한 도면이다. 도 1b를 참조하면, 전자 악보 변환을 위한 인공 신경망 학습 장치 및 브랜드 정보 생성 장치를 포함 할 수 있다. 일 실시 예에 따른 브랜드 정보를 생성하기 위한 인공 신경망 학습 장치는 뉴럴 네트워크를 생성하거나, 뉴럴 네트워크를 훈련(train)(또는 학습(learn))하거나, 뉴럴 네트워크를 재훈련(retrain)하는 기 능들과 같은 다양한 프로세싱 기능들을 갖는 컴퓨팅 디바이스에 해당된다. 예를 들어, 인공 신경망 학습 장치 는 PC(personal computer), 서버 디바이스, 모바일 디바이스 등의 다양한 종류의 디바이스들로 구현될 수 있다. 브랜드 정보를 생성하기 위한 인공 신경망 학습 장치는 주어진 초기 뉴럴 네트워크를 반복적으로 훈련(학 습)시킴으로써, 훈련된 뉴럴 네트워크를 생성할 수 있다. 훈련된 뉴럴 네트워크를 생성하는 것은 뉴 럴 네트워크 파라미터를 결정하는 것을 의미할 수 있다. 여기서, 파라미터들은 예를 들어 뉴럴 네트워크의 입/ 출력 액티베이션들, 웨이트들, 바이어스들 등 뉴럴 네트워크에 입/출력되는 다양한 종류의 데이터를 포함할 수 있다. 뉴럴 네트워크의 반복적인 훈련이 진행됨에 따라, 뉴럴 네트워크의 파라미터들은 주어진 입력에 대해 보 다 정확한 출력을 연산하기 위해 조정될(tuned) 수 있다. 일 실시 예에 따른 훈련된 뉴럴 네트워크는 복수의 뉴럴 네트워크로 구성될 수도 있다. 구체적으로, 훈련 된 뉴럴 네트워크는 제1 뉴럴 네트워크와 제2 뉴럴 네트워크를 포함할 수 있다. 예를 들어, 제1 뉴럴 네 트워크는 입력된 배경음악 음원 데이터의 BPM(beat per minute), 제로 크로싱 레이트(zero crossing rate), 고 조파(harmonic), percussive components, 스펙트럼 센트로이드(spectral centroid), 스펙트럴 롤오프(spectral rolloff), 멜 주파수 켑스트럼 계수들(Mel Frequency Cepstral Coefficients, 이하 MFCCs), Chroma frequencies 중 적어도 하나를 포함하는 데이터로부터 상기 배경음악 음원 데이터의 장르를 결정하도록 학습될 수 있다. 또한, 제2 뉴럴 네트워크는 결정된 배경음악 음원 데이터로부터 미리 정의된 장르와 관련된 브랜드에 대한 감성 정보를 출력하도록 학습될 수 있다. 제1 뉴럴 네트워크와 제2 뉴럴 네트워크는 독립적으로 학습될 수도 있고, 서로 연관되어 학습될 수도 있다. 상기 BPM은, 음악의 속도를 숫자로 표시한 것으로, 분당 몇 비트의 템포로 연주되는지 표시할 수 있으며, 수치 가 높을수록 빠른 속도의 음악을 BPM에 따라 각각의 음악 장르를 대략적으로 설정할 수 있다. 상기 제로 크로싱 레이트(zero-crossing rate)는, 불규칙적인 파형에 있어서 중심선을 가로지른 시점의 간격에 서 주기를 산출하여 주기와 그 빈도와의 관계를 표시한 것으로 음성 인식과 음악 정보 검색 모두에 널리 사용되 어 타악기 소리를 분류하는 핵심 기능일 수 있다. 상기 고조파(harmonic)는, 신호 전체의 주파수를 결정하는 요소로서, 정현파(기본파)에 대해서 정배수인 파 (wave)를 의미하며, 고조파의 주파수는 동일한 음을 연주하는 경우에도 다른 악기로 만들어진 소리의 고유한 음 질을 정확하게 결정하는데 도움을 줄 수 있어서 악기를 구분하기 위한 파(wave)일 수 있다. 상기 percussive components는, 타악기적인 소리를 내는 구성들을 의미하며, 충돌(clash), 노크(knock), 박수 (clap) 및 클릭(click) 소리를 포함할 수 있다. 상기 스펙트럴 센트로이드(spectral centroid)은, 스펙트럼을 특성화하기 위해 디지털 신호 처리에 사용되는 척 도로서, 주파수 성분들의 중심 값을 나타낼 수 있다. 상기 스펙트럴 롤오프(spectral rolloff)는, 주파수 영역에서 저대역 신호부터 85%의 에너지가 분포하는 주파수 의 값을 계산한 것으로서, 주파수 영역의 분포를 파악할 수 있다. 스펙트럴 롤오프는 다음과 같은 수학식 1으로 계산할 수 있다.수학식 1"}
{"patent_id": "10-2023-0007371", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "여기서 는 스펙트럴 롤오프값이고, 는 주파수 영역에서 t번째 주파수 스펙트럼이며, M은 가장 높은 주 파수 영역을 각각 나타낸다. 상기 멜 주파수 켑스트럼 계수들(MFCCs)은, 오디오 신호에서 추출할 수 있는 특징(feature)을 의미하며, 음성 데이터의 고유한 특징을 벡터값을 나타낼 수 있으며, 주로 음성 인식, 화자 인식, 음성 합성, 음악 장르 분류 등의 오디오 도메인 문제를 해결하는 데 사용된다. 좀 더 기술적으로 살펴보면, MFCC는 입력 신호의 주파수 스 펙트럼에 멜 필터 뱅크(Mel filter Bank)를 적용해서 얻은 멜 스펙트럼(Mel spectrum)에서 캡스트럴(Cepstral) 분석을 통해서 추출된 값을 나타낸다. 즉, 멜 스펙트럼에 고조파 구조를 분석하여 소리의 고유한 특징을 찾아낼 수 있는 캡스트럴 분석을 적용하여 얻은 결과이다. 상기 크로마 주파수(chroma frequencies)는, 음악의 음 높이를 피치 클래스(pitch class)로 표현하는 것을 의미 하며 음악의 흥미롭고 강렬한 표현을 특징으로 할 수 있다. 상기 브랜드 정보를 생성하기 위한 인공 신경망 학습 장치는 훈련된 뉴럴 네트워크를 브랜드 정보 생 성 장치에 전달할 수 있다. 브랜드 정보 생성 장치는 모바일 디바이스, 임베이스(embedded) 디바이 스 등에 포함될 수 있다. 브랜드 정보 생성 장치는 뉴럴 네트워크의 구동을 위한 전용 하드웨어일 수 있다. 브랜드 정보 생성 장치는 훈련된 뉴럴 네트워크를 그대로 구동하거나, 훈련된 뉴럴 네트워크가 가동(예를 들어, 양자화)된 뉴럴 네트워크를 구동할 수 있다. 가공된 뉴럴 네트워크를 구동하는 브 랜드 정보 생성 장치는, 브랜드 정보를 생성하기 위한 인공 신경망 학습 장치 와는 별도로 독립적인 디바이스에서 구현될 수 있다. 하지만, 이에 제한되지 않고, 브랜드 정보 생성 장치는 브랜드 정보를 생 성하기 위한 인공 신경망 학습 장치와 동일한 디바이스 내에도 구현될 수 있다. 도 2는 일 실시예에 따른 인공지능 기반의 브랜드 정보를 생성하는 방법이 수행되는 환경을 도시한 개념도이다. 도 2를 참조하면, 본 발명의 일 실시예에 따른 인공지능 기반의 브랜드 정보 생성 방법이 수행되는 환경은 네트 워크, 브랜드 정보 생성 장치, 사용자 단말 및 서버(미도시)를 포함할 수 있다. 즉, 브랜드 정 보 생성 장치와 사용자 단말는 네트워크을 통해 서로 연결된 상태일 수 있다. 네트워크는 전용선 등을 포함하는 유선 인터넷, 무선 인터넷, 이동통신망, 위성통신망 등을 포함할 수 있 다. 네트워크은 브랜드 정보 생성 장치 및 외부서버를 연결하는 망(Network)으로서 유선 네트워크, 무선 네트워크 등을 포함한다. 네트워크는 LAN(Local Area Network), WAN(Wide Area Network)등의 폐쇄형 네트 워크 또는 인터넷(Internet)과 같은 개방형 네트워크일 수 있다. 인터넷은 TCP/IP 프로토콜 및 그 상위계층에 존재하는 여러 서비스, 즉 HTTP(HyperText Transfer Protocol), Telnet, FTP(File Transfer Protocol), DNS(Domain Name System), SMTP(Simple Mail Transfer Protocol), SNMP(Simple Network Management Protocol), NFS(Network File Service), NIS(Network Information Service)를 제공하는 전 세계적인 개방형 컴 퓨터 네트워크 구조를 의미한다. 브랜드 정보 생성 장치는 본 발명의 일 실시예에 따른 브랜드 정보 생성 방법을 주도적으로 수행하는 장치 를 의미할 수 있으며, 인공지능을 이용하여 브랜드에 대한 동영상 데이터에 삽입된 배경음악 음원 데이터로부터 브랜드와 관련된 감성 정보를 생성하는 장치를 의미할 수 있다. 일 실시예에 따른 상기 브랜드 정보 생성 장치에 의하여 실행되는 프로그램 코드는 메모리 장치에 저장될 수 있다. 브랜드 정보 생성 장치는 기타 외부 장치(예를 들어, 퍼스널 컴퓨터 또는 네트워크, 프린터 등) 에 연결되고, 데이터를 교환할 수 있다. 브랜드 정보 생성 장치는 서버에 탑재될 수 있다. 브랜드 정보 생성 장치는 네트워크를 통해 브랜드에 대한 검색어를 포함하는 복수의 동영상 데이터 또는 음원 데이터를 획득할 수 있다. 상기 동영상 데이터는 브랜드 이름이나 제품에 대한 검색어를 미리 지정된 네트워크 상의 URL(universal resource locator 또는 uniform resource locator)에 대응하는 웹 페이지를 크롤링(crawling) 또는 스크레이핑 (scraping)하는 단계를 통해 획득할 수 있다. 본 단계는 브랜드 정보 생성 장치를 이용하여 서버와 통신하 여 연계되어 수행될 수 있다. 상기 미리 지정된 네트워크는 유튜브(youtube), 비메오(vimeo), 데일리모션(dailymotion), 페이스북 (facebook), 인스타그램(instagram), 트위터(twitter), 틱톡(tiktok), 빌리빌리(bilibili), 훌루(hulu), 아프 리카(afreeca) TV, 네이버(naver) TV, 다음(daum) TV 등의 동영상 플랫폼의 웹 페이지 중 적어도 하나를 포함할 수 있다. 여기서, 크롤링(crawling)은 인터넷 상에 공개된 정보를 수집하여 검색 대상의 색인으로 포함시키는 기술로, 브 랜드 정보 생성 장치는 수집된 정보를 텍스트, 이미지, 동영상 등으로 구분하고, 동영상 데이터 각각에 대 해 하나 이상의 프레임(frame)을 획득할 수 있다. 일 실시예에 따른 브랜드 정보 생성 장치는 크롤링을 통해, 동영상을 업로드할 수 있는 웹 페이지에서 브 랜드명 또는 브랜드에 대한 제품명 또는 서비스명을 검색어로 하는 동영상을 추출하고, 추출된 브랜드에 대한 동영상에서 미리 지정된 조회수 이상을 메타 정보로 갖는 프레임 또는 시청 지속 기간이 소정 시간 이상인 프레 임 또는 동영상 데이터의 랜덤(random) 시간에 대한 프레임을 획득할 수 있다. 다른 일 실시예에 따른 브랜드 정보 생성 장치는 크롤링을 통해, 검색된 브랜드에 대한 동영상에 작성된 댓글(comment) 또는 후기 리뷰(review)를 포함하는 텍스트를 획득할 수 있다. 사용자 단말은 본 발명의 일 실시예에 따른 브랜드 정보 생성 방법을 통해 생성된 브랜드 정보를 제공받고 자 하는 대상(즉, 사용자 등)의 장치를 의미할 수 있다. 구체적으로, 사용자 단말은 브랜드 정보를 생성하 고자 하는 사용자의 장치를 의미할 수 있다. 사용자 단말은 네트워크에 접속 가능한 사용자의 장치일 수 있다. 사용자 단말은 스마트폰, 태 블릿 PC, 랩톱, 데스크톱 등을 포함할 수 있으나 이에 제한되는 것은 아니다. 다시 말해, 사용자 단말은 브랜드 정보를 생성하는 서비스를 이용하고자 하는 대상인 사용자의 장치를 의 미할 수 있으며, 브랜드 정보 생성 요청 정보를 브랜드 정보 생성 장치에 제공할 수 있다. 서버(미도시)는 서비스 제공 서버로서, 네트워크를 통해 브랜드 정보 생성 장치와 연결되어 브랜드 정보를 생성하기 위해 필요한 동영상 데이터를 제공할 수 있다. 서버는 사용자에게 브랜드와 관련된 검색어를 검색할 수 있는 서비스를 비롯하여 다양한 검색 서비스를 사용자 단말에 제공할 수 있다. 서버는 사용자에 게 검색 서비스를 제공하기 위해 다양한 종류의 데이터베이스를 구비할 수 있으며, 데이터베이스와의 통신을 통 하여 사용자의 검색 요청에 대응하는 결과를 도출하여 제공할 수 있다. 여기서, 데이터베이스는 서버(미도시) 내에 구비될 수 있으며, 실시예에 따라서는 서버(미도시)와 네트워크를 통하여 연결될 수 있다. 서버(미도시)는 Web Application Server(WAS), Internet Information Server(IIS) 또는 ApacheTomcat 또는 Nginx를 사용하는 인터넷 상의 공지의 웹 서버(Web Server) 또는 캐시 서버(Cache Server)일 수 있다. 또한, 웹 서버는 Linux 또는 Windows와 같은 OS(operating system)을 지원하며, 수신된 제어명령을 실행할 수 있다. 소프트웨어적으로는 C, C++, Java, Visual Basic, Visual C 등과 같은 언어를 통하여 구현되는 프로그램 모듈 (Module)을 포함할 수 있다. 서버(미도시)는 소정의 연산 프로세스 및 통신 프로세스를 수행할 수 있는 서버일 수 있다. 예시적으로, 서버는 전형적인 컴퓨터 하드웨어(예컨대, 컴퓨터 프로세서, 메모리, 스토리지, 입력 장치 및 출력 장치, 기타 기존의 컴퓨팅 장치의 구성요소들을 포함할 수 있는 장치; 라우터, 스위치 등과 같은 전자 통신 장치; 네트워크 부착 스토리지(NAS; network-attached storage) 및 스토리지 영역 네트워크(SAN; storage area network)와 같은 전 자 정보 스토리지 시스템)와 컴퓨터 소프트웨어(즉, 컴퓨팅 장치로 하여금 특정의 방식으로 기능하게 하는 명령 어들)의 조합을 이용하여 원하는 시스템 성능을 달성하는 것일 수 있다. 도 3은 일 실시예에 따른 인공지능 기반의 브랜드 정보를 생성하기 위한 장치를 설명하기 위한 블록도이다. 도 3를 참조하면, 브랜드 정보 생성 장치는 통신부, 추출부, 변환부, 판단부를 포함 할 수 있으며, 크롤링한 동영상 데이터, 배경음악 음원 데이터의 멜 스펙트로그램, 감성 정보, 사용자 정보 중적어도 하나를 저장하는 저장부(미도시)를 더 포함할 수 있다. 상기한 바와 같이 상기 브랜드 정보 생성 장치 는 도시된 구성요소보다 많은 구성요소에 의해 구현될 수 있다. 일 실시예에 따른 통신부는 네트워크 및 사용자 단말과 통신을 수행함으로써 사용자 단말(30 0)로부터 브랜드에 대한 검색어를 수신하고, 미리 지정된 상기 네트워크를 통해 상기 브랜드에 대한 검색 어를 포함하는 복수의 동영상 데이터를 수집할 수 있다. 상기 통신부는, 전자 기기와 외부 기기 또는 전자 기기와 서버 간의 통신을 하게 하는 하 나 이상의 구성요소를 포함할 수 있다. 예를 들어, 통신부는, 근거리 통신부(Short range wireless communication unit), 마이크로폰 등을 포함할 수 있다. 이때, 근거리 통신 기술에는, 무선 랜(Wi-Fi), 블루투 스, 지그비, WFD((Wi-Fi Direct), UWB(ultra-wide band), 적외선 통신(IrDA, infrared Data Association), BLE(Bluetooth Low Energy), NFC(Near Field Communication) 등이 있을 수 있으나, 이에 한정되는 것은 아니다. 상기 추출부는, 상기 통신부에서 수집된 상기 복수의 동영상 데이터 각각에 대해 미리 지정된 조회수 이상을 메타 정보로 갖는 프레임을 추출할 수 있다. 일 실시예에 따른 상기 프레임은, 상기 동영상 데이터를 구성하는 이미지 한 컷을 의미하며, 상기 추출부 는 브랜드에 대한 상기 동영상 데이터에서 미리 지정된 조회수 이상을 메타 정보로 갖는 프레임을 추출할 수 있 다. 다른 일 실시예에 따른 상기 추출부는, 상기 동영상 데이터에서 시청자가 미리 정해진 시간 이상 시청을 지속적으로 수행한 하나 이상의 시간 영역을 메타 정보로 갖는 프레임을 추출할 수 있다. 상기 시간 영역은 상 기 시청자가 소정 시간 건너뛰기(예를 들어, 15초 건너뛰기 또는 30초 건너뛰기) 또는 스킵 없이 지속적으로 시 청한 시간 영역을 의미할 수 있다. 상기 시간 영역은 상기 시청자가 동영상 데이터를 30초 이상 시청을 지속한 시간 영역일 수 있으며, 상기의 시청을 지속한 시간 영역은 상기 동영상 데이터의 재생 시간에 따라 다르게 설 정될 수 있다. 또 다른 일 실시예에 따른 상기 추출부는, 상기 동영상 데이터에서 미리 지정된 조회수 이상인 메타 정보 를 포함하고 있지 않거나, 미리 지정된 시간 이상 시청을 지속한 시간인 메타 정보를 포함하고 있지 않으면 랜 덤(random) 또는 상기 동영상 데이터의 전체 재생 시간 중 소정 비율이 지난 시간에 대응하는 프레임을 추출할 수 있다. 예시적으로 소정 비율은 50%로 설정될 수 있을 것이다. 그러나, 상기 비율에 대한 예시는 이해를 돕기 위한 예시일 뿐, 다른 실시예를 제한하거나 한정하는 것으로 해석되어서는 안 될 것이다. 이를테면, 상기 비율 은 35%로 설정될 수도 있다. 또 다른 일 실시예에 따른 상기 추출부는, 상기 프레임에 삽입된 배경음악 음원 데이터를 추출할 수 있다. 상기 변환부는, 상기 추출부에서 추출된 프레임 내에 삽입된 각각의 배경음악 음원 데이터를 멜 스펙 트로그램(mel spectrogram)으로 변환한다. 일 실시예에 따른, 상기 배경음악 음원 데이터는 상기 프레임에 포함된 메타 데이터와 미리 지정된 네트워크에 서 크롤링한 복수의 음원 데이터들의 메타 정보를 비교하여 상기 프레임 내에 삽입된 상기 배경음악 음원 데이 터를 추출될 수 있다. 상기 미리 지정된 네트워크는 artlist.io, 유튜브(youtube), 멜론(melon), 지니(genie), 벅스(bugs), 플로 (flo), 바이브(vibe) 등 음원 데이터 정보를 제공하는 웹 사이트를 포함할 수 있다. 일 실시예에 따른 상기 변환부는, 푸리에 변환을 통해서 전처리된 배경음악 음원 데이터의 소리나 파동을 시각화하기 위해서 파형(waveform)과 스펙트럼(spectrum)의 특징이 조합되어 있는 이미지로 변환할 수 있다. 상기 판단부는, 상기 추출부에서 추출된 프레임에 대응하는 배경음악 음원 데이터의 BPM(beat per minute) 및 멜 스펙트로그램을 입력데이터로서 미리 학습된 인공신경망에 입력함으로써, 상기 배경음악 음원 데 이터의 장르(genre)를 출력 데이터로서 획득하고 상기 획득된 장르를 이용하여 상기 브랜드에 대한 감성 정보를 출력하여 브랜드 정보를 판단한다. 일 실시예에 따른 상기 판단부는 각각의 장르에 대한 후기 데이터로부터 크롤링된 감성 키워드들과 각각의 장르를 매핑하여 저장한 룩-업 테이블을 이용하여 상기 브랜드에 대한 감성 정보를 생성할 수 있다. 상기 감성 키워드는 희망을 주는(uplifting), 장대한(epic), 강력한(powerful), 흥분되는(exciting), 행복한 (happy), 재미있는(funny), 걱정 없는(carefree), 희망찬(hopeful), 사랑(love), 장난기 많은(playful), 근사 한(groovy), 섹시한(sexy), 평화로운(peaceful), 진지한(serious), 극적인(dramatic), 화난(angry), 긴장시키 는(tense), 슬픈(sad), 무서운(scary), 어두운(dark) 중 적어도 하나를 포함할 수 있다. 판단부는 추출된 상기 프레임 내의 픽셀 데이터를 미리 지정된 개수의 영역으로 분할하고, 분할된 상기 영 역의 픽셀 데이터의 색채 파라미터의 평균값을 상기 브랜드에 대한 색상 정보로서 판단할 수 있다. 일 실시예에 따른 상기 판단부는 상기 색채 파라미터를 복수의 구간으로 나누고, 각각의 구간에 포함되는 상기 픽셀 데이터의 색채 파라미터의 평균값들의 개수에 따라 가중치를 결정함으로써 브랜드에 대한 색상 정보 를 결정할 수 있다. 도 4는 일 실시예에 따른 인공지능 기반의 브랜드 정보를 생성하기 위한 방법을 예시적으로 설명하기 위한 순서 도이다. 도 4를 참조하면, 단계 S410는, 사용자 단말로부터 브랜드에 대한 검색어를 수신한다. 상기 브랜드에 대한 검색어는 브랜드 이름, 브랜드가 판매 또는 실시하고 있는 제품명 및 서비스명을 포함할 수 있다. 단계 S420은, 미리 지정된 네트워크를 통해 브랜드에 대한 검색어를 포함하는 복수의 동영상 데이터를 수 집한다. 단계 S430은, 복수의 동영상 데이터 각각에 대해 미리 지정된 조회수 이상을 메타 정보로 갖는 복수의 프레임을 추출한다. 일 실시예에 따른 단계 S430은, 복수의 동영상 데이터 각각에 대해 미리 지정된 회수 이상 리플레이(replay)된 시간 영역을 메타 정보로 갖는 프레임을 추출할 수 있다. 다른 일 실시예에 따른 단계 S430은, 복수의 동영상 데이터 각각에 대해 시청이 지속된 시간이 미리 지정된 시 간 이상으로 시간 영역을 메타 정보로 갖는 복수의 프레임을 추출할 수 있다. 단계 S440은, 추출된 프레임 내에 삽입된 각각의 배경음악 음원 데이터를 멜 스펙트로그램으로 변환한다. 단계 S450은, 추출된 프레임에 대응하는 상기 배경음악 음원 데이터의 BPM 및 상기 멜 스펙트로그램을 입력 데 이터로서 미리 학습된 인공신경망에 입력한다. 상기 미리 학습된 인공신경망은, 복수의 은닉층을 포함하는 심층 신경망(deep neural network)으로 구현되는 제 1 레이어와 컨볼루션 신경망(convolution neural network)으로 구현되는 제2 레이어로 구현될 수 있다. 상기 컨볼루션 신경망은, 입력 데이터인 멜 스펙트로그램으로부터 테두리, 선, 색 등과 같은 \"특징들 (features)\"을 추출하기 위해 이용될 수 있다. 컨볼루션 신경망은 복수의 레이어를 포함할 수 있다. 각각의 레 이어는 데이터를 수신할 수 있고, 해당 레이어에 입력되는 데이터를 처리하여 해당 레이어에서 출력되는 데이터 를 생성할 수 있다. 레이어에서 출력되는 데이터는, 컨볼루션 신경망에 입력된 이미지 또는 입력된 특징맵 (feature map)을 필터(filter) 웨이트(weight) 값과 컨볼루션 연산하여 생성한 특징맵일 수 있다. 그레디언트들 과 같은 낮은 레벨의 특징들을 추출하도록 동작될 수 있다. 컨볼루션 뉴럴 네트워크의 다음 레이어들은 이 미지 내의 눈, 코 등과 같은 점진적으로 더 복잡한 특징들을 추출할 수 있다. 상기 \"특징들(features)\"는 BPM(beat per minute), 제로 크로싱 레이트(zero crossing rate), 고조파 (harmonic), percussive components, 스펙트럼 센트로이드(spectral centroid), 스펙트럴 롤오프(spectral rolloff), 멜 주파수 켑스트럼 계수들(MFCCs), Chroma frequencies를 포함할 수 있다. 단계 S460은, 배경음악 음원 데이터의 장르를 출력 데이터로서 획득한다. 다른 일 실시예에 따른 단계 S460은, 배경음악 음원 데이터로부터 장르를 포함하는 배경음악 음원 데이터의 속 성을 추출하기 위해 MIR(Music Information Retrieval) 기술을 사용할 수 있다. MIR 기술이란 음악을 신호처리 단계에서 분석해 대용량의 자동화된 정보처리에 필요한 음악의 유용한 의미 정보들을 추출하는 기술을 뜻하며, 음향학, 심리 음향학, 신호처리, 전산학, 음악학, 도서관학, 정보학, 기계학습 등의 광범위한 학문 분야와 기술 분야를 아우르는 학제적 연구가 요구되는 기술이다. MIR 기술은 크게 음악을 기호적인(Symbolic) 분석 또는 신호적(Signal-spectrum) 분석으로 나뉜다. 기호적 분석 은 악보의 음표 정보를 분석하는 것으로, 주된 분석 목적은 음악의 악보를 얼마나 시각적으로 정확하게 묘사해 내고 이를 실제 연주에 활용할 수 있는가에 초점이 맞춰진다. 신호적 분석은 음악이 녹음된 샘플링 신호를 분석하는 기법으로써, 현재 음악 정보검색 기술에서 많은 부분을 차지 하고 있다. 속성 추출부는 MIR 기술을 이용하 여 음악 데이터를 다양한 기준으로 재분류하여 음악 데이터의 검색, 추천, 표절 정보 및 히트 정보 등을 제공할 수 있다. 상기 음원 데이터로부터 추출할 수 있는 속성은 BPM 및 멜 스펙트로그램, 장르(genre), 화음(chord), 템포 (tempo), 키(key), 멜로디(melody), 비트(beat) 및 무드(mood) 중 하나 이상일 수 있다. 단계 S470은, 획득된 장르를 이용하여 브랜드에 대한 감성 정보를 출력한다. 상기 감성 정보는 웃긴, 로맨틱, 드라마틱, 액션, 음산한, SF, 키즈, 다큐, 모험, 스포츠, 게임, 범죄, 패션, 차분한, 밝은, 행복, 신비한, 군대, 휴식, 여행, 종교, 슬픈, 섹시한, 결혼식 등을 포함하는 키워드를 포함할 수 있다. 도 5a는 일 실시예에 따른 인공지능 기반의 브랜드 정보 생성 장치가 프레임을 추출하기 위한 방법을 예시적으 로 설명하기 위한 도면이다. 도 5b는 일 실시예에 따른 미리 지정된 조회수 이상의 프레임을 추출하기 위한 방법을 예시적으로 설명하기 위 한 도면이다. 도 5a 내지 5b를 참조하면, 브랜드에 대한 동영상 데이터에서 미리 지정된 조회수 이상의 메타 정보를 갖 는 복수의 시간 영역(510a, 510b)에 대응하는 적어도 하나 이상의 프레임(520a, 520b)을 추출할 수 있다. 일 실시예에 따른 미리 지정된 조회수는 복수의 동영상 플랫폼에서 설정된 기준 조회수 또는 각각의 동영상 데 이터 시간 영역의 조회수가 기준치 이상인 시간 영역일 수 일 수 있다. 이를테면, 미리 지정된 조회수는 시간 영역의 조회수 중 80% 이상인 구간을 나타낼 수 있다. 상기의 수치에 대한 예시는 이해를 돕기 위한 예시일 뿐, 상기의 수치는 75%로 설정될 수 있다. 다른 일 실시예에 따른 프레임(520a, 520b)는 미리 지정된 시간 이상의 시청이 지속된 횟수에 대한 메타 정보를 포함하는 하나 이상의 프레임을 추출할 수 있다. 또 다른 일 실시예에 따른 프레임(520a, 520b)는 전체 재생 시간에서 미리 지정된 비율만큼 경과된 시간 또는 랜덤(random)한 시간에 대응하는 하나 이상의 프레임을 추출할 수 있다. 일 실시예에 따른 인공지능 기반의 브랜드 정보 생성 장치는 상기 동영상 데이터에서 추출된 프레임(520a)에서 적어도 하나 이상의 영역으로 나누어 각각의 영역에 대응하는 평균 색상 데이터를 추출할 수 있다. 상기 추출된 평균 색상 데이터를 통해서 브랜드 정보를 생성할 수 있다. 예를 들어 상기 추출된 평균 색상 데이터가 초록색 (green)과 관련된 색상 데이터의 범위에 포함되면, 상기 브랜드 정보는 안전, 평화, 번영, 자연, 생명력, 상쾌 함 등의 키워드를 포함할 수 있고, 상기 추출된 평균 색상 데이터가 베이지(beige)와 관련된 색상 데이터의 범 위에 포함되면, 편안함, 차분함, 따뜻함, 안정적, 내츄럴, 풍요로움 등의 키워드를 포함할 수 있다. 도 6a는 일 실시예에 따른 인공지능 기반의 브랜드 정보 생성 장치가 배경음악 음원 데이터를 멜 스펙트로그램 으로 변환하는 방법을 예시적으로 설명하기 위한 도면이다. 도 6b는 일 실시예에 따른 배경음악 음원 데이터로부터 변환된 멜 스펙트로그램을 도시한 예시적인 도면이다. 도 6a 및 도 6b를 참조하면, 단계 S610는 브랜드에 대한 동영상 데이터에 삽입된 배경음악 음원 데이터 파일을 푸리에 변환(fourier transform)를 통해서 신호 처리가 수행될 수 있다. 신호 처리는 예를 들어 STFT(Short Time Fourier Transform)일 수 있다. 일 실시예에 따른 STFT 신호 처리 방법은, 대상 배경음악 음원 데이터를 5초 단위로 나누고 나누어진 구간 별로 고속 푸리에 변환(Fast Fourier Transform, 이하 FFT)를 수행하는 STFT 신호 처리가 수행될 수 있다. 또한 상 기 5초 단위로 나뉜 구간은 STFT 처리됨으로써 50%씩 겹쳐지는 50ms(밀리초)의 프레임으로 변형될 수 있으며, 상기 구간은 5 ~ 50ms(밀리초)로 설정하는 것이 바람직하다. 다른 일 실시예에 따른 배경음악 음원 데이터 파일을 신호 처리하는 방법은 고속 푸리에 변환(FFT) 방식을 사용 하여 주파수 도메인으로 변환한 후 생성된 전력 스펙트럼(power spectrum)을 이용하여 획득할 수 있으며, 이에 제한되지 않고 다양한 방법들을 통해 획득될 수 있다. 상기 주파수 도메인(Frequency Domain)은 오디오의 주어진 세그먼트의 주파수 구성요소를 분석하는 것을 지칭한 다. 오디오를 시간 도메인(PCM)에서 주파수 도메인으로 변환하기 위해, 푸리에 변환이 일반적으로 사용된다. 상기 고속 푸리에 변환은 시간 도메인에서 주파수 도메인으로 세그먼트 오디오를 변환하는 알고리즘으로, 푸리 에 변환은 적분을 사용하는 이론적인 알고리즘이지만, 이산적이지는 않다. (때로는 이산 푸리에 변환(Discrete Fourier Transform) 또는 DFT로 지칭되는) FFT의 결과는 주파수 \"빈\"으로 구성되는 데이터 구조이다. 각각의 주 파수 빈은 주파수 범위에서 크기로의 매핑이다. 예를 들면, 4,000 Hz에서 재생되는 사인파의 1초 FFT는 4,000 Hz에서 단일 빈을 높은 값으로 가질 것이다. 2,000 Hz와 4,000 Hz에서 재생되는 2개의 사인파들은 이론적으로 2,000 Hz에서 하나와 4,000 Hz에서 하나의 각각 대략 동일한 크기를 갖는 2개의 빈들을 갖는다. 실생활의 오디 오는 많은 주파수들로 구성되어 있기 때문에, 일반적으로 주어진 오디오 샘플의 FFT에 대한 많은 주파수 빈들이 있다. 상기 배경음악 음원 데이터 파일은 오디오 형태(audio file format)이다. 예를 들어 비압축 형태인 WAV, AIRR 및 A, 비손실 압축 포맷인 FLAC, TTA 및 WavPack, 손실 압축 포맷인 MP3, AAC와 같은 형태가 있을 수 있다. 단계 S620에서는 상기 신호 처리의 결과를 스펙트로그램(Spectrogram)으로 변환하는 전처리가 수행될 수 있다. 상기 스펙트로그램은 푸리에 변환을 수행한 후 결과값을 시각적인 영역으로 변환하여 작업하는 직관적인 방법으 로, 시간 - 주파수 영역으로 시각화할 수 있다. 단계 S630에서는 상기 스펙트로그램의 주파수 성분을 Mel 곡선에 따라 압축한 멜 스펙트로그램(Mel Spectrogram) 형태의 데이터를 획득할 수 있다. 일 실시예에 따른 단계 S630은 멜 스펙트로그램을 통해서 음악의 장르를 검출할 수 있다. 배경음악 음원 데이터 의 장르가 클래식(classic)이면, 클래식 멜 스펙트로그램과 소정 유사도 이상을 가지는 멜 스펙트로그램을 획득할 수 있고, 상기 배경음악 음원 데이터의 장르가 레게(reggae)면, 레게 멜 스펙트로그램과 소정 유사 도 이상을 가진 멜 스펙트로그램을 획득함으로써 상기 배경음악 음원 데이터의 장르를 인식할 수 있다. 일 실시예에 따른 상기 멜 스펙트로그램을 통해서 배경음악 음원 데이터의 장르를 인식하는 단계는 미리 학습된 인공신경망에 입력하는 과정을 통해서 상기 배경음악 음원 데이터의 장르를 출력할 수 있다. 일 실시예에 따른 상기 장르는 클래식(classic), 디스코(disco), 재즈(jazz), 록(rock), 힙합(hiphop), 메탈 (metal), 레게(reggae), 팝(pop), 어쿠스틱(acoustic), 블루스(blues), 포크(fork), 라틴(latin), 인디 (indie), 레트로(retro), 소울(soul), 알앤비(R&B) 등의 장르를 포함할 수 있다. 도 7a 일 실시예에 따른 인공지능 기반의 브랜드에 대한 동영상을 제공하는 화면을 예시적으로 설명하기 위한 도면이다. 도 7b 일 실시예에 따른 인공지능 기반의 동영상 데이터를 통해 추출된 브랜드 정보를 제공하는 화면을 예시적 으로 설명하기 위한 도면이다. 도 7c 일 실시예에 따른 인공지능 기반의 음원 데이터에 삽입된 음악 정보를 제공하는 화면을 예시적으로 설명 하기 위한 도면이다. 도 7a 내지 도 7c를 참조하면, 감성코드, 색상, 러닝타임, 정렬기준를 통해서 검색된 브랜 드에 대한 동영상 데이터를 필터링(filtering)하는 복수의 필터링 영역을 포함할 수 있다. 상기 감성코드 필터링 영역을 통해서 상기 동영상 데이터에서 추출된 프레임에 삽입된 배경음악 음원 데이터를 통해 생성된 브 랜드에 대한 감성 정보와 매칭하는 과정을 통해 필터링할 수 있다. 상기 색상 필터링 영역은 기준 색상 파라미터의 소정 범위를 설정하고, 생성된 브랜드에 대한 색상 정보가 상기 설정된 기준 색상 파라미터의 소정 범위에 포함되는 브랜드에 대한 동영상 데이터를 필터링할 수 있다. 상기 러닝타임은 검색된 브랜드에 대한 동영상 데이터가 러닝타임의 범위에 기초하여 필터링할 수 있다. 상기 정렬기준은 필터링 영역은 검색된 브랜드에 대한 동영상 데이터가 동영상 플랫폼의 웹 페이지에 업로 드(upload) 된 날짜 또는 각각의 상기 브랜드에 대한 동영상 데이터의 조회수 순으로 정렬할 수 있다. 사용자 단말은 검색된 브랜드에 대한 동영상 데이터를 사용자 라이브러리에 저장할 수 있도록 하는 \"찜하기\" 영 역을 더 포함할 수 있다. 브랜드에 대한 동영상 데이터를 통해 생성된 브랜드 정보에 기반해서 연관어, 컬러사용 빈도, 감성코 드 중 적어도 하나의 항목으로 데이터 시각화(data visualization)를 할 수 있다. 상기 연관어 항목은 검색을 수행한 브랜드의 검색 결과를 크롤링을 통해 연관된 키워드를 추출하여 시각화 할 수 있다. 상기 컬러사용 빈도 항목은 검색된 브랜드에 대한 동영상 데이터를 통해 생성된 브랜드 색상정보가 검색된 횟수를 기반으로 데이터를 시각화 할 수 있다. 상기 감성코드 항목은 검색된 브랜드에 대한 동영상 데이터를 통해 생성된 브랜드 감성정보를 단어의 중요 도 또는 빈도수 등을 고려하여 데이터를 시각화 할 수 있다. 도 7c를 참조하면, 검색된 브랜드에 대한 동영상 데이터의 프레임에 삽입된 배경음악 음원 데이터의 속성을 분 석하여 유사도가 가장 높은 하나 이상의 음원 데이터를 추천해주는 추천 영역을 더 포함할 수 있다. 일 실시예에 따른 상기 속성은 BPM, 멜 스펙트로그램, 장르(genre), 화음(chord), 템포(tempo), 키(key), 멜로 디(melody), 비트(beat) 및 무드(mood) 중 하나를 포함할 수 있다. 다른 일 실시예에 따른 추천 영역은 사용자 단말에게 추천된 음원 데이터를 내려 받기 가능하도록 제 공하거나, \"찜하기\" 영역을 통해서 상기 사용자 라이브러리에 저장할 수 있도록 할 수 있다. 이상에서 설명된 실시 예들은 하드웨어 구성요소, 소프트웨어 구성요소, 및/또는 하드웨어 구성요소 및 소프트 웨어 구성요소의 조합으로 구현될 수 있다. 예를 들어, 실시 예들에서 설명된 장치, 방법 및 구성요소는, 예를 들어, 프로세서, 콘트롤러, ALU(arithmetic logic unit), 디지털 신호 프로세서(digital signal processor), 마이크로컴퓨터, FPGA(field programmable gate array), PLU(programmable logic unit), 마이크로프로세서, 또 는 명령(instruction)을 실행하고 응답할 수 있는 다른 어떠한 장치와 같이, 하나 이상의 범용 컴퓨터 또는 특 수 목적 컴퓨터를 이용하여 구현될 수 있다. 처리 장치는 운영 체제(OS) 및 상기 운영 체제 상에서 수행되는 하나 이상의 소프트웨어 애플리케이션을 수행할 수 있다. 또한, 처리 장치는 소프트웨어의 실행에 응답하여, 데이터를 접근, 저장, 조작, 처리 및 생성할 수도 있다. 이해의 편의를 위하여, 처리 장치는 하나가 사용되는"}
{"patent_id": "10-2023-0007371", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "것으로 설명된 경우도 있지만, 해당 기술분야에서 통상의 지식을 가진 자는, 처리 장치가 복수 개의 처리 요소 (processing element) 및/또는 복수 유형의 처리 요소를 포함할 수 있음을 알 수 있다. 예를 들어, 처리 장치 는 복수 개의 프로세서 또는 하나의 프로세서 및 하나의 콘트롤러를 포함할 수 있다. 또한, 병렬 프로세서 (parallel processor)와 같은, 다른 처리 구성(processing configuration)도 가능하다. 소프트웨어는 컴퓨터 프로그램(computer program), 코드(code), 명령(instruction), 또는 이들 중 하나 이상의 조합을 포함할 수 있으며, 원하는 대로 동작하도록 처리 장치를 구성하거나 독립적으로 또는 결합적으로 (collectively) 처리 장치를 명령할 수 있다. 소프트웨어 및/또는 데이터는, 처리 장치에 의하여 해석되거나 처리 장치에 명령 또는 데이터를 제공하기 위하여, 어떤 유형의 기계, 구성요소(component), 물리적 장치, 가상 장치(virtual equipment), 컴퓨터 저장 매체 또는 장치, 또는 전송되는 신호 파(signal wave)에 영구적으로, 또는 일시적으로 구체화(embody)될 수 있다. 소프트웨어는 네트워크로 연결된 컴퓨터 시스템 상에 분산되어서, 분산된 방법으로 저장되거나 실행될 수도 있다. 소프트웨어 및 데이터는 하나 이상의 컴퓨터 판독 가능 기록 매 체에 저장될 수 있다. 실시 예에 따른 방법은 다양한 컴퓨터 수단을 통하여 수행될 수 있는 프로그램 명령 형태로 구현되어 컴퓨터 판 독 가능 매체에 기록될 수 있다. 컴퓨터 판독 가능 매체는 프로그램 명령, 데이터 파일, 데이터 구조 등을 단 독으로 또는 조합하여 포함할 수 있다. 컴퓨터 판독 가능 매체에 기록되는 프로그램 명령은 실시예를 위하여 특별히 설계되고 구성된 것들이거나 컴퓨터 소프트웨어 당업자에게 공지되어 사용 가능한 것일 수도 있다. 컴 퓨터 판독 가능 기록 매체의 예에는 하드 디스크, 플로피 디스크 및 자기 테이프와 같은 자기 매체(magnetic media), CD-ROM, DVD와 같은 광기록 매체(optical media), 플롭티컬 디스크(floptical disk)와 같은 자기-광 매체(magneto-optical media), 및 롬(ROM), 램(RAM), 플래시 메모리 등과 같은 프로그램 명령을 저장하고 수행 하도록 특별히 구성된 하드웨어 장치가 포함된다. 프로그램 명령의 예에는 컴파일러에 의해 만들어지는 것과 같은 기계어 코드뿐만 아니라 인터프리터 등을 사용해서 컴퓨터에 의해서 실행될 수 있는 고급 언어 코드를 포 함한다. 상기된 하드웨어 장치는 실시예의 동작을 수행하기 위해 하나 이상의 소프트웨어 모듈로서 작동하도록 구성될 수 있으며, 그 역도 마찬가지이다."}
{"patent_id": "10-2023-0007371", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "이상과 같이 실시 예들이 비록 한정된 도면에 의해 설명되었으나, 해당 기술분야에서 통상의 지식을 가진 자라 면 상기를 기초로 다양한 기술적 수정 및 변형을 적용할 수 있다. 예를 들어, 설명된 기술들이 설명된 방법과 다른 순서로 수행되거나, 및/또는 설명된 시스템, 구조, 장치, 회로 등의 구성요소들이 설명된 방법과 다른 형 태로 결합 또는 조합되거나, 다른 구성요소 또는 균등물에 의하여 대치되거나 치환되더라도 적절한 결과가 달성 될 수 있다.도면 도면1a 도면1b 도면2 도면3 도면4 도면5a 도면5b 도면6a 도면6b 도면7a 도면7b 도면7c"}
{"patent_id": "10-2023-0007371", "section": "도면", "subsection": "도면설명", "item": 1, "content": "본 발명의 실시 예의 설명에 이용되기 위하여 첨부된 아래 도면들은 본 발명의 실시 예들 중 단지 일부일 뿐이"}
{"patent_id": "10-2023-0007371", "section": "도면", "subsection": "도면설명", "item": 2, "content": "며, 본 발명의 기술분야에서 통상의 지식을 가진 사람(이하 \"통상의 기술자\"라 함)에게 있어서는 발명에 이르는 추가 노력 없이 이 도면들에 기초하여 다른 도면들이 얻어질 수 있다. 도 1a는 인공 신경망(Artificial Neural Network)을 이용한 딥러닝 연산 방법을 설명하기 위한 도면이다. 도 1b는 일 실시예에 따른 인공 신경망을 이용한 브랜드 정보를 생성하는 방법을 설명하기 위한 도면이다. 도 2는 일 실시예에 따른 인공지능 기반의 브랜드 정보를 생성하는 방법이 수행되는 환경을 도시한 개념도이다. 도 3은 일 실시예에 따른 인공지능 기반의 브랜드 정보를 생성하기 위한 장치를 설명하기 위한 블록도이다. 도 4는 일 실시예에 따른 인공지능 기반의 브랜드 정보를 생성하기 위한 방법을 예시적으로 설명하기 위한 순서 도이다. 도 5a는 일 실시예에 따른 인공지능 기반의 브랜드 정보 생성 장치가 프레임을 추출하기 위한 방법을 예시적으 로 설명하기 위한 도면이다. 도 5b는 일 실시예에 따른 미리 지정된 조회수 이상의 프레임을 추출하기 위한 방법을 예시적으로 설명하기 위 한 도면이다. 도 6a는 일 실시예에 따른 인공지능 기반의 브랜드 정보 생성 장치가 배경음악 음원 데이터를 멜 스펙트로그램 으로 변환하는 방법을 예시적으로 설명하기 위한 도면이다. 도 6b는 일 실시예에 따른 배경음악 음원 데이터로부터 변환된 멜 스펙트로그램을 도시한 예시적인 도면이다. 도 7a 일 실시예에 따른 인공지능 기반의 브랜드에 대한 동영상을 제공하는 화면을 예시적으로 설명하기 위한 도면이다. 도 7b 일 실시예에 따른 인공지능 기반의 동영상 데이터를 통해 추출된 브랜드 정보를 제공하는 화면을 예시적 으로 설명하기 위한 도면이다. 도 7c 일 실시예에 따른 인공지능 기반의 음원 데이터에 삽입된 음악 정보를 제공하는 화면을 예시적으로 설명 하기 위한 도면이다."}
