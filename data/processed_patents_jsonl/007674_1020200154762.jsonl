{"patent_id": "10-2020-0154762", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2022-0067950", "출원번호": "10-2020-0154762", "발명의 명칭": "디스플레이 장치 및 그의 제어 방법", "출원인": "삼성전자주식회사", "발명자": "김대영"}}
{"patent_id": "10-2020-0154762", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "디스플레이 장치에 있어서,제1 디스플레이 패널, 상기 제1 디스플레이 패널 상에 배치된 렌즈 어레이 및 상기 렌즈 어레이 상에 배치된 제2 디스플레이 패널을 포함하는 디스플레이; 및복수의 LF(light field) 영상에 기초하여, 상기 디스플레이를 시분할로 구동하기 위한 L 영상 및 R 영상을 획득하고,상기 R 영상 중 상기 제1 디스플레이 패널을 구동하기 위한 제1 R 영상에 기초하여 상기 L 영상 중 상기 제2 디스플레이 패널을 구동하기 위한 제2 L 영상을 보정하고, 상기 L 영상 중 상기 제1 디스플레이 패널을 구동하기위한 제1 L 영상에 기초하여 상기 R 영상 중 상기 제2 디스플레이 패널을 구동하기 위한 제2 R 영상을보정하고, 상기 제2 L 영상이 보정된 상기 L 영상 및 상기 제2 R 영상이 보정된 상기 R 영상에 기초하여 상기 디스플레이를 시분할로 구동하여, 입체 영상을 표시하는 프로세서;를 포함하는 디스플레이 장치."}
{"patent_id": "10-2020-0154762", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 프로세서는,상기 제1 R 영상에 기초하여 R 크로스톡 영상을 획득하고, 상기 제1 L 영상에 기초하여 L 크로스톡 영상을 획득하며,상기 R 크로스톡 영상의 픽셀 값에 기초하여 상기 제2 L 영상을 보정하고, 상기 L 크로스톡 영상의 픽셀 값에기초하여 상기 제2 R 영상을 보정하는, 디스플레이 장치."}
{"patent_id": "10-2020-0154762", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,상기 프로세서는,동일한 위치의 픽셀에 대해 상기 R 크로스톡 영상의 픽셀 값만큼 감소시킨 픽셀 값을 갖도록 상기 제2 L 영상을보정하고, 동일한 위치의 픽셀에 대해 상기 L 크로스톡 영상의 픽셀 값만큼 감소시킨 픽셀 값을 갖도록 상기 제2 R 영상을 보정하는, 디스플레이 장치."}
{"patent_id": "10-2020-0154762", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제2항에 있어서,상기 프로세서는,상기 제1 R 영상의 픽셀 값에 크로스톡 비율을 곱한 픽셀 값을 갖는 상기 R 크로스톡 영상을 획득하고, 상기 제1 L 영상의 픽셀 값에 상기 크로스톡 비율을 곱한 픽셀 값을 갖는 상기 L 크로스톡 영상을 획득하는, 디스플레이 장치."}
{"patent_id": "10-2020-0154762", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제2항에 있어서,상기 프로세서는,상기 제1 R 영상 및 상기 제2 R 영상을 합성한 제3 R 영상을 획득하고, 상기 합성된 제3 R 영상의 픽셀 값에 크공개특허 10-2022-0067950-3-로스톡 비율을 곱한 픽셀 값을 갖는 상기 R 크로스톡 영상을 획득하며, 상기 제1 L 영상 및 상기 제2 L 영상을 합성한 제3 L 영상을 획득하고, 상기 합성된 제3 L 영상의 픽셀 값에 상기 크로스톡 비율을 곱한 픽셀 값을 갖는 상기 L 크로스톡 영상을 획득하는, 디스플레이 장치."}
{"patent_id": "10-2020-0154762", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서,상기 프로세서는,상기 복수의 LF 영상이 촬영된 시점에 대한 정보에 기초해, 상기 복수의 LF 영상 중에서 좌측 시점을 나타내는LF 영상 및 우측 시점을 나타내는 LF 영상을 추출하고, 상기 제1 및 제2 디스플레이 패널의 수에 대응되는 상기 L 영상을 출력하도록 학습된 제1 팩토리제이션 모델에상기 좌측 시점을 나타내는 LF 영상을 입력하여 상기 L 영상을 획득하며,상기 제1 및 제2 디스플레이 패널의 수에 대응되는 상기 R 영상을 출력하도록 학습된 제2 팩토리제이션 모델에상기 우측 시점을 나타내는 LF 영상을 입력하여 상기 R 영상을 획득하는, 디스플레이 장치."}
{"patent_id": "10-2020-0154762", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6항에 있어서,상기 제1 팩토리제이션 모델은, 좌측 시점을 나타내는 LF 영상 및 L 영상을 통해 복원된 LF 영상에 기초한 손실함수가 기설정된 값 이하가 될때까지 학습된 인공지능 모델이며, 상기 제2 팩토리제이션 모델은, 우측 시점을 나타내는 LF 영상 및 R 영상을 통해 복원된 LF 영상에 기초한 손실함수가 기설정된 값 이하가 될때까지 학습된 인공지능 모델인 것을 특징으로 하는, 디스플레이 장치."}
{"patent_id": "10-2020-0154762", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제6항에 있어서,상기 제1 팩토리제이션 모델 및 상기 제2 팩토리제이션 모델 각각은, DNN(Deep Neural Network) 모델, NTF(Non-negative tensor factorization) 모델 또는 NMF(Non-negativeMatric factorization) 모델 중 하나인 것을 특징으로 하는, 디스플레이 장치."}
{"patent_id": "10-2020-0154762", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1항에 있어서,상기 렌즈 어레이는,상기 제1 디스플레이 패널의 짝수 개의 서브 픽셀 상에 배치되는 단위 렌즈를 포함하는, 디스플레이 장치."}
{"patent_id": "10-2020-0154762", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제1항에 있어서,상기 프로세서는,상기 복수의 LF 영상이 시점에 따라 분류된 LF 영상에 기초하여, 상기 시점에 대응되는 상기 L 영상, M 영상 및상기 R 영상을 획득하고, 상기 M 영상 중 상기 제1 디스플레이 패널을 구동하기 위한 제1 M 영상 및 상기 제1 R 영상에 기초하여, 상기제2 L 영상을 보정하고,상기 제1 M 영상 및 상기 제1 L 영상에 기초하여, 상기 제2 R 영상을 보정하고, 상기 제1 L 영상 및 제1 R 영상에 기초하여, 상기 M 영상 중에서 상기 제2 디스플레이 패널을 구동하기 위한 제공개특허 10-2022-0067950-4-2 M 영상을 보정하며,상기 제2 L 영상이 보정된 상기 L 영상, 상기 제2 M 영상이 보정된 상기 M 영상 및 상기 제2 R 영상이 보정된상기 R 영상에 기초하여, 상기 디스플레이를 시분할로 구동하여, 상기 입체 영상을 표시하는, 디스플레이 장치."}
{"patent_id": "10-2020-0154762", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "디스플레이 장치의 제어 방법에 있어서,복수의 LF(light field) 영상에 기초하여, 제1 디스플레이 패널, 상기 제1 디스플레이 패널 상에 배치된 렌즈어레이 및 상기 렌즈 어레이 상에 배치된 제2 디스플레이 패널을 포함하는 디스플레이를 시분할로 구동하기 위한 L 영상 및 R 영상을 획득하는 단계;상기 R 영상 중 상기 제1 디스플레이 패널을 구동하기 위한 제1 R 영상에 기초하여 상기 L 영상 중 상기 제2 디스플레이 패널을 구동하기 위한 제2 L 영상을 보정하고, 상기 L 영상 중 상기 제1 디스플레이 패널을 구동하기위한 제1 L 영상에 기초하여 상기 R 영상 중 상기 제2 디스플레이 패널을 구동하기 위한 제2 R 영상을 보정하는단계; 및상기 제2 L 영상이 보정된 상기 L 영상 및 상기 제2 R 영상이 보정된 상기 R 영상에 기초하여 상기 디스플레이를 시분할로 구동하여, 입체 영상을 표시하는 단계;를 포함하는 제어 방법."}
{"patent_id": "10-2020-0154762", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항에 있어서,상기 보정하는 단계는,상기 제1 R 영상에 기초하여 R 크로스톡 영상을 획득하고, 상기 제1 L 영상에 기초하여 L 크로스톡 영상을 획득하는 단계; 및상기 R 크로스톡 영상의 픽셀 값에 기초하여 상기 제2 L 영상을 보정하고, 상기 L 크로스톡 영상의 픽셀 값에기초하여 상기 제2 R 영상을 보정하는 단계;를 포함하는, 제어 방법."}
{"patent_id": "10-2020-0154762", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제12항에 있어서,상기 보정하는 단계는,동일한 위치의 픽셀에 대해 상기 R 크로스톡 영상의 픽셀 값만큼 감소시킨 픽셀 값을 갖도록 상기 제2 L 영상을보정하고, 동일한 위치의 픽셀에 대해 상기 L 크로스톡 영상의 픽셀 값만큼 감소시킨 픽셀 값을 갖도록 상기 제2 R 영상을 보정하는, 제어 방법."}
{"patent_id": "10-2020-0154762", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제12항에 있어서,상기 R 크로스톡 영상 및 상기 L 크로스톡 영상을 획득하는 단계는,상기 제1 R 영상의 픽셀 값에 크로스톡 비율을 곱한 픽셀 값을 갖는 상기 R 크로스톡 영상을 획득하고, 상기 제1 L 영상의 픽셀 값에 상기 크로스톡 비율을 곱한 픽셀 값을 갖는 상기 L 크로스톡 영상을 획득하는, 제어방법."}
{"patent_id": "10-2020-0154762", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제12항에 있어서,상기 R 크로스톡 영상 및 상기 L 크로스톡 영상을 획득하는 단계는,상기 제1 R 영상 및 상기 제2 R 영상을 합성한 제3 R 영상을 획득하고, 상기 합성된 제3 R 영상의 픽셀 값에 크로스톡 비율을 곱한 픽셀 값을 갖는 상기 R 크로스톡 영상을 획득하며,상기 제1 L 영상 및 상기 제2 L 영상을 합성한 제3 L 영상을 획득하고, 상기 합성된 제3 L 영상의 픽셀 값에 상공개특허 10-2022-0067950-5-기 크로스톡 비율을 곱한 픽셀 값을 갖는 상기 L 크로스톡 영상을 획득하는, 제어 방법."}
{"patent_id": "10-2020-0154762", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제11항에 있어서,상기 L 영상 및 상기 R 영상을 획득하는 단계는,상기 복수의 LF 영상이 촬영된 시점에 대한 정보에 기초해, 상기 복수의 LF 영상 중에서 좌측 시점을 나타내는LF 영상 및 우측 시점을 나타내는 LF 영상을 추출하는 단계; 상기 제1 및 제2 디스플레이 패널의 수에 대응되는 상기 L 영상을 출력하도록 학습된 제1 팩토리제이션 모델에상기 좌측 시점을 나타내는 LF 영상을 입력하여 상기 L 영상을 획득하는 단계; 및상기 제1 및 제2 디스플레이 패널의 수에 대응되는 상기 R 영상을 출력하도록 학습된 제2 팩토리제이션 모델에상기 우측 시점을 나타내는 LF 영상을 입력하여 상기 R 영상을 획득하는 단계;를 포함하는, 제어 방법."}
{"patent_id": "10-2020-0154762", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제16항에 있어서,상기 제1 팩토리제이션 모델은, 좌측 시점을 나타내는 LF 영상 및 L 영상을 통해 복원된 LF 영상에 기초한 손실함수가 기설정된 값 이하가 될때까지 학습된 인공지능 모델이며, 상기 제2 팩토리제이션 모델은, 우측 시점을 나타내는 LF 영상 및 R 영상을 통해 복원된 LF 영상에 기초한 손실함수가 기설정된 값 이하가 될때까지 학습된 인공지능 모델인 것을 특징으로 하는, 제어 방법."}
{"patent_id": "10-2020-0154762", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제16항에 있어서,상기 제1 팩토리제이션 모델 및 상기 제2 팩토리제이션 모델 각각은, DNN(Deep Neural Network) 모델, NTF(Non-negative tensor factorization) 모델 또는 NMF(Non-negativeMatric factorization) 모델 중 하나인 것을 특징으로 하는, 제어 방법."}
{"patent_id": "10-2020-0154762", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제11항에 있어서,상기 렌즈 어레이는,상기 제1 디스플레이 패널의 짝수 개의 서브 픽셀 상에 배치되는 단위 렌즈를 포함하는, 제어 방법."}
{"patent_id": "10-2020-0154762", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제11항에 있어서,상기 L 영상 및 R 영상을 획득하는 단계는,상기 복수의 LF 영상이 시점에 따라 분류된 LF 영상에 기초하여, 상기 시점에 대응되는 상기 L 영상, M 영상 및상기 R 영상을 획득하고, 상기 보정하는 단계는,상기 M 영상 중 상기 제1 디스플레이 패널을 구동하기 위한 제1 M 영상 및 상기 제1 R 영상에 기초하여, 상기제2 L 영상을 보정하고,상기 제1 M 영상 및 상기 제1 L 영상에 기초하여, 상기 제2 R 영상을 보정하고, 상기 제1 L 영상 및 제1 R 영상에 기초하여, 상기 M 영상 중에서 상기 제2 디스플레이 패널을 구동하기 위한 제공개특허 10-2022-0067950-6-2 M 영상을 보정하며,상기 입체 영상을 표시하는 단계는,상기 제2 L 영상이 보정된 상기 L 영상, 상기 제2 M 영상이 보정된 상기 M 영상 및 상기 제2 R 영상이 보정된상기 R 영상에 기초하여, 상기 디스플레이를 시분할로 구동하여, 상기 입체 영상을 표시하는, 제어 방법."}
{"patent_id": "10-2020-0154762", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 개시에서는 디스플레이 장치 및 그 제어 방법이 제공된다. 본 개시의 디스플레이 장치는 제1 디스플레이 패널, 제1 디스플레이 패널 상에 배치된 렌즈 어레이 및 렌즈 어레이 상에 배치된 제2 디스플레이 패널을 포함하 는 디스플레이, 및 복수의 LF(light field) 영상에 기초하여, 디스플레이를 시분할로 구동하기 위한 L 영상 및 R (뒷면에 계속)"}
{"patent_id": "10-2020-0154762", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 디스플레이 장치 및 그의 제어 방법에 관한 것으로, 보다 상세하게는 LF(Light Field)를 통해 입체 영상을 표시하는 디스플레이 장치 및 그의 제어 방법에 관한 것이다."}
{"patent_id": "10-2020-0154762", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "최근 전자 기술의 발달에 따라, 3차원의 입체 영상을 표시하기 위한 디스플레이 장치가 개발되고 있다. 3차원의 입체 영상을 표시하기 위한 디스플레이 장치는 크게 사용자가 안경을 착용하여야만 입체 영상을 제대로 시청할 수 있는 안경 방식과 사용자가 안경을 착용하지 않고서도 입체 영상을 제대로 시청할 수 있는 무안경 방 식으로 분류될 수 있다. 안경 방식의 경우 사용자에게 만족스러운 입체감을 제공할 수 있으나, 사용자가 반드시 안경을 착용하여야 한다는 점에서 사용자(특히, 시력 보정을 위해 안경을 착용하는 사용자 등)에게 불편함을 주 며, 사용자의 수만큼 안경이 필요하다는 단점이 있다. 이에 비해, 무안경 방식은 안경 없이도 3차원의 입체 영 상을 시청할 수 있다는 점에서 사용자에게 편리함을 제공한다. 특히, 무안경 방식에서, 디스플레이 장치가 서로 다른 시점(view point)으로 촬영한 복수의 LF(Light Field) 영 상을 이용하여 생성된 영상을 표시하여 입체 영상을 재현하는 LF(Light Field) 방식이 있다. LF 방식의 경우 일 반적인 디스플레이 장치와 달리, 빛의 세기와 방향을 달리하여 입체 영상을 표시하며, 이에 따라 사용자는 사용 자가 디스플레이를 보는 시점에 따라 디스플레이에 표시되는 객체의 다른 각도의 모습을 볼 수 있다. 한편, 이러한 LF 방식을 재현하기 위한 디스플레이 장치의 구조는, 크게 빛의 방향을 조절하기 위해 디스플레이 패널 상에 격벽(barrier) 또는 렌즈와 같은 광학층이 형성된 광학층 구조, 각 디스플레피 패널 간 픽셀의 조합 에 따른 빛의 방향과 세기를 조절하기 위해 복수의 디스플레이 패널이 수직으로 적층된 적층형 구조로 분류될 수 있다. 광학층 구조의 디스플레이 장치에서는 광학층의 특성(예: 굴절율, 수차, 배열 등)에 따라 원치 않는 방향으로 빛이 진행하는 현상이 발생하여 입체 영상의 품질이 저하되는 문제가 있으며, 적층형 구조의 디스플레이 장치에 서는 사용자가 볼 수 있는 시야각이 제한되는 문제가 있다."}
{"patent_id": "10-2020-0154762", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 개시의 목적은 시야각이 향상되면서 크로스톡이 저감될 수 있는 디스플레이 장치 및 그의 제어 방법을 제공 함에 있다."}
{"patent_id": "10-2020-0154762", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 개시의 일 실시 예에 따른 디스플레이 장치는 제1 디스플레이 패널, 제1 디스플레이 패널 상에 배치된 렌즈 어레이 및 렌즈 어레이 상에 배치된 제2 디스플레이 패널을 포함하는 디스플레이, 및 복수의 LF(light field) 영상에 기초하여, 디스플레이를 시분할로 구동하기 위한 L 영상 및 R 영상을 획득하고, R 영상 중 제1 디스플레 이 패널을 구동하기 위한 제1 R 영상에 기초하여 L 영상 중 제2 디스플레이 패널을 구동하기 위한 제2 L 영상을 보정하고, L 영상 중 제1 디스플레이 패널을 구동하기 위한 제1 L 영상에 기초하여 R 영상 중 제2 디스플레이 패널을 구동하기 위한 제2 R 영상을 보정하고, 제2 L 영상이 보정된 L 영상 및 제2 R 영상이 보정된 R 영상에 기초하여 디스플레이를 시분할로 구동하여, 입체 영상을 표시하는 프로세서를 포함할 수 있다. 일 예로서, 프로세서는 제1 R 영상에 기초하여 R 크로스톡 영상을 획득하고, 제1 L 영상에 기초하여 L 크로스톡 영상을 획득하며, R 크로스톡 영상의 픽셀 값에 기초하여 제2 L 영상을 보정하고, L 크로스톡 영상의 픽셀 값에기초하여 제2 R 영상을 보정할 수 있다. 일 예로서, 프로세서는 동일한 위치의 픽셀에 대해 R 크로스톡 영상의 픽셀 값만큼 감소시킨 픽셀 값을 갖도록 제2 L 영상을 보정하고, 동일한 위치의 픽셀에 대해 L 크로스톡 영상의 픽셀 값만큼 감소시킨 픽셀 값을 갖도록 제2 R 영상을 보정할 수 있다. 일 예로서, 프로세서는 제1 R 영상의 픽셀 값에 크로스톡 비율을 곱한 픽셀 값을 갖는 R 크로스톡 영상을 획득 하고, 제1 L 영상의 픽셀 값에 크로스톡 비율을 곱한 픽셀 값을 갖는 L 크로스톡 영상을 획득할 수 있다. 일 예로서, 프로세서는 제1 R 영상 및 제2 R 영상을 합성한 제3 R 영상을 획득하고, 합성된 제3 R 영상의 픽셀 값에 크로스톡 비율을 곱한 픽셀 값을 갖는 R 크로스톡 영상을 획득하며, 제1 L 영상 및 제2 L 영상을 합성한 제3 L 영상을 획득하고, 합성된 제3 L 영상의 픽셀 값에 크로스톡 비율을 곱한 픽셀 값을 갖는 L 크로스톡 영상 을 획득할 수 있다. 일 예로서, 프로세서는 복수의 LF 영상이 촬영된 시점에 대한 정보에 기초해, 복수의 LF 영상 중에서 좌측 시점 을 나타내는 LF 영상 및 우측 시점을 나타내는 LF 영상을 추출하고, 제1 및 제2 디스플레이 패널의 수에 대응되 는 L 영상을 출력하도록 학습된 제1 팩토리제이션 모델에 좌측 시점을 나타내는 LF 영상을 입력하여 L 영상을 획득하며, 제1 및 제2 디스플레이 패널의 수에 대응되는 R 영상을 출력하도록 학습된 제2 팩토리제이션 모델에 우측 시점을 나타내는 LF 영상을 입력하여 R 영상을 획득할 수 있다. 일 예로서, 제1 팩토리제이션 모델은, 좌측 시점을 나타내는 LF 영상 및 L 영상을 통해 복원된 LF 영상에 기초 한 손실함수가 기설정된 값 이하가 될 때까지 학습된 인공지능 모델이며, 제2 팩토리제이션 모델은, 우측 시점 을 나타내는 LF 영상 및 R 영상을 통해 복원된 LF 영상에 기초한 손실함수가 기설정된 값 이하가 될 때까지 학 습된 인공지능 모델인 것을 특징으로 할 수 있다. 일 예로서, 제1 팩토리제이션 모델 및 제2 팩토리제이션 모델 각각은, DNN(Deep Neural Network) 모델, NTF(Non-negative tensor factorization) 모델 또는 NMF(Non-negative Matric factorization) 모델 중 하나인 것을 특징으로 할 수 있다. 일 예로서, 렌즈 어레이는 제1 디스플레이 패널의 짝수 개의 서브 픽셀 상에 배치되는 단위 렌즈를 포함할 수 있다. 일 예로서, 프로세서는 복수의 LF 영상이 시점에 따라 분류된 LF 영상에 기초하여, 시점에 대응되는 L 영상, M 영상 및 R 영상을 획득하고, M 영상 중 제1 디스플레이 패널을 구동하기 위한 제1 M 영상 및 제1 R 영상에 기초 하여, 제2 L 영상을 보정하고, 제1 M 영상 및 제1 L 영상에 기초하여, 제2 R 영상을 보정하고, 제1 L 영상 및 제1 R 영상에 기초하여, M 영상 중에서 제2 디스플레이 패널을 구동하기 위한 제2 M 영상을 보정하며, 제2 L 영 상이 보정된 L 영상, 제2 M 영상이 보정된 M 영상 및 제2 R 영상이 보정된 R 영상에 기초하여, 디스플레이를 시 분할로 구동하여, 입체 영상을 표시할 수 있다. 본 개시의 일 실시 예에 따른 디스플레이 장치의 제어 방법은 복수의 LF(light field) 영상에 기초하여, 제1 디 스플레이 패널, 제1 디스플레이 패널 상에 배치된 렌즈 어레이 및 렌즈 어레이 상에 배치된 제2 디스플레이 패 널을 포함하는 디스플레이를 시분할로 구동하기 위한 L 영상 및 R 영상을 획득하는 단계, R 영상 중 제1 디스플 레이 패널을 구동하기 위한 제1 R 영상에 기초하여 L 영상 중 제2 디스플레이 패널을 구동하기 위한 제2 L 영상 을 보정하고, L 영상 중 제1 디스플레이 패널을 구동하기 위한 제1 L 영상에 기초하여 R 영상 중 제2 디스플레 이 패널을 구동하기 위한 제2 R 영상을 보정하는 단계, 및 제2 L 영상이 보정된 L 영상 및 제2 R 영상이 보정된 R 영상에 기초하여 디스플레이를 시분할로 구동하여, 입체 영상을 표시하는 단계를 포함할 수 있다. 일 예로서, 보정하는 단계는, 제1 R 영상에 기초하여 R 크로스톡 영상을 획득하고, 제1 L 영상에 기초하여 L 크 로스톡 영상을 획득하는 단계, 및 R 크로스톡 영상의 픽셀 값에 기초하여 제2 L 영상을 보정하고, L 크로스톡 영상의 픽셀 값에 기초하여 제2 R 영상을 보정하는 단계를 포함할 수 있다. 일 예로서, 보정하는 단계는, 동일한 위치의 픽셀에 대해 R 크로스톡 영상의 픽셀 값만큼 감소시킨 픽셀 값을 갖도록 제2 L 영상을 보정하고, 동일한 위치의 픽셀에 대해 L 크로스톡 영상의 픽셀 값만큼 감소시킨 픽셀 값을 갖도록 제2 R 영상을 보정할 수 있다. 일 예로서, R 크로스톡 영상 및 L 크로스톡 영상을 획득하는 단계는, 제1 R 영상의 픽셀 값에 크로스톡 비율을 곱한 픽셀 값을 갖는 R 크로스톡 영상을 획득하고, 제1 L 영상의 픽셀 값에 크로스톡 비율을 곱한 픽셀 값을 갖는 L 크로스톡 영상을 획득할 수 있다. 일 예로서, R 크로스톡 영상 및 L 크로스톡 영상을 획득하는 단계는, 제1 R 영상 및 제2 R 영상을 합성한 제3 R 영상을 획득하고, 합성된 제3 R 영상의 픽셀 값에 크로스톡 비율을 곱한 픽셀 값을 갖는 R 크로스톡 영상을 획 득하며, 제1 L 영상 및 제2 L 영상을 합성한 제3 L 영상을 획득하고, 합성된 제3 L 영상의 픽셀 값에 크로스톡 비율을 곱한 픽셀 값을 갖는 L 크로스톡 영상을 획득할 수 있다. 일 예로서, L 영상 및 R 영상을 획득하는 단계는, 복수의 LF 영상이 촬영된 시점에 대한 정보에 기초해, 복수의 LF 영상 중에서 좌측 시점을 나타내는 LF 영상 및 우측 시점을 나타내는 LF 영상을 추출하는 단계, 제1 및 제2 디스플레이 패널의 수에 대응되는 L 영상을 출력하도록 학습된 제1 팩토리제이션 모델에 좌측 시점을 나타내는 LF 영상을 입력하여 L 영상을 획득하는 단계, 및 제1 및 제2 디스플레이 패널의 수에 대응되는 R 영상을 출력하 도록 학습된 제2 팩토리제이션 모델에 우측 시점을 나타내는 LF 영상을 입력하여 R 영상을 획득하는 단계를 포 함할 수 있다. 일 예로서, 제1 팩토리제이션 모델은, 좌측 시점을 나타내는 LF 영상 및 L 영상을 통해 복원된 LF 영상에 기초 한 손실함수가 기설정된 값 이하가 될 때까지 학습된 인공지능 모델이며, 제2 팩토리제이션 모델은, 우측 시점 을 나타내는 LF 영상 및 R 영상을 통해 복원된 LF 영상에 기초한 손실함수가 기설정된 값 이하가 될 때까지 학 습된 인공지능 모델인 것을 특징으로 할 수 있다. 일 예로서, 제1 팩토리제이션 모델 및 제2 팩토리제이션 모델 각각은, DNN(Deep Neural Network) 모델, NTF(Non-negative tensor factorization) 모델 또는 NMF(Non-negative Matric factorization) 모델 중 하나인 것을 특징으로 할 수 있다. 일 예로서, 렌즈 어레이는, 제1 디스플레이 패널의 짝수 개의 서브 픽셀 상에 배치되는 단위 렌즈를 포함할 수 있다. 일 예로서, L 영상 및 R 영상을 획득하는 단계는, 복수의 LF 영상이 시점에 따라 분류된 LF 영상에 기초하여, 시점에 대응되는 L 영상, M 영상 및 R 영상을 획득할 수 있다. 여기서, 보정하는 단계는, M 영상 중 제1 디스플 레이 패널을 구동하기 위한 제1 M 영상 및 제1 R 영상에 기초하여, 제2 L 영상을 보정하고, 제1 M 영상 및 제1 L 영상에 기초하여, 제2 R 영상을 보정하고, 제1 L 영상 및 제1 R 영상에 기초하여, M 영상 중에서 제2 디스플 레이 패널을 구동하기 위한 제2 M 영상을 보정할 수 있다. 여기서, 입체 영상을 표시하는 단계는, 제2 L 영상이 보정된 L 영상, 제2 M 영상이 보정된 M 영상 및 제2 R 영상이 보정된 R 영상에 기초하여, 디스플레이를 시분할 로 구동하여, 입체 영상을 표시할 수 있다."}
{"patent_id": "10-2020-0154762", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "이상과 같은 본 개시의 다양한 실시 예에 따르면, 시야각이 향상되면서 크로스톡이 저감될 수 있는 디스플레이 장치 및 그의 제어 방법을 제공할 수 있다."}
{"patent_id": "10-2020-0154762", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 개시를 설명함에 있어서, 관련된 공지 기능 혹은 구성에 대한 구체적인 설명이 본 개시의 요지를 불필요하게 흐릴 수 있다고 판단되는 경우 그에 대한 상세한 설명은 생략한다. 덧붙여, 하기 실시 예는 여러 가지 다른 형 태로 변형될 수 있으며, 본 개시의 기술적 사상의 범위가 하기 실시 예에 한정되는 것은 아니다. 오히려, 이들 실시 예는 본 개시를 더욱 충실하고 완전하게 하고, 당업자에게 본 개시의 기술적 사상을 완전하게 전달하기 위 하여 제공되는 것이다. 본 개시에 기재된 기술을 특정한 실시 형태에 대해 한정하려는 것이 아니며, 본 개시의 실시 예의 다양한 변경 (modifications), 균등물(equivalents), 및/또는 대체물(alternatives)을 포함하는 것으로 이해되어야 한다. 도면의 설명과 관련하여, 유사한 구성요소에 대해서는 유사한 참조 부호가 사용될 수 있다. 본 개시에서 사용된 \"제1,\" \"제2,\" \"첫째,\" 또는 \"둘째,\"등의 표현들은 다양한 구성요소들을, 순서 및/또는 중 요도에 상관없이 수식할 수 있고, 한 구성요소를 다른 구성요소와 구분하기 위해 사용될 뿐 상기 구성요소들을 한정하지 않는다. 본 개시에서, \"A 또는 B,\" \"A 또는/및 B 중 적어도 하나,\" 또는 \"A 또는/및 B 중 하나 또는 그 이상\"등의 표현 은 함께 나열된 항목들의 모든 가능한 조합을 포함할 수 있다. 예를 들면, \"A 또는 B,\" \"A 및 B 중 적어도 하나,\" 또는 \"A 또는 B 중 적어도 하나\"는, 적어도 하나의 A를 포함, 적어도 하나의 B를 포함, 또는 적어도 하나의 A 및 적어도 하나의 B 모두를 포함하는 경우를 모두 지칭할 수 있다. 본 개시에서 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 출원에서, \" 포함하다\" 또는 \"구성되다\" 등의 용어는 명세서상에 기재된 특징, 숫자, 단계, 동작, 구성요소, 부품 또는 이들 을 조합한 것이 존재함을 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성요 소, 부품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되어야 한다. 어떤 구성요소(예: 제1 구성요소)가 다른 구성요소(예: 제2 구성요소)에 \"(기능적으로 또는 통신적으로) 연결되 어((operatively or communicatively) coupled with/to)\" 있다거나 \"접속되어(connected to)\" 있다고 언급된 때에는, 상기 어떤 구성요소가 상기 다른 구성요소에 직접적으로 연결되거나, 다른 구성요소(예: 제3 구성요 소)를 통하여 연결될 수 있다고 이해되어야 할 것이다. 반면에, 어떤 구성요소(예: 제1 구성요소)가 다른 구성 요소(예: 제2 구성요소)에 \"직접 연결되어\" 있다거나 \"직접 접속되어\" 있다고 언급된 때에는, 상기 어떤 구성요 소와 상기 다른 구성요소 사이에 다른 구성요소(예: 제 3 구성요소)가 존재하지 않는 것으로 이해될 수 있다. 도 1은 본 개시의 일 실시 예에 따른 디스플레이 장치의 구조를 설명하기 위한 단면도이다. 도 1을 참조하면, 본 개시의 일 실시 예에 따른 디스플레이 장치는 디스플레이를 포함할 수 있다. 여 기서, 디스플레이 장치는 TV, 모니터, 스마트폰, 휴대용 멀티미디어 장치, 휴대용 통신장치, 스마트 글래 스, 스마트 윈도우, 스마트 워치, HMD(Head Mount Display), 웨어러블 장치(Wearable device), 포터블 장치 (Portable device), 핸즈헬드 장치(Handheld device), 사이니지(Signage), 전광판, 광고판, 시네마 스크린, 비 디오 월 등 다양한 형태로 구현될 수 있으며, 그 형태가 한정되지 않는다. 디스플레이는 복수의 LF(Light Field) 영상을 이용하여 LF(Light Field)로 구현된 입체 영상을 표시할 수 있다. 여기서, 복수의 LF 영상은 특정한 객체에서 나오는 빛을 서로 다른 복수의 시점(view point)에서 촬영한 영상을 말한다. 본 개시의 입체 영상은 사용자의 시점(또는 사용자의 위치)에 따라 객체의 다른 면이 사용자에 게 보이도록 하는 영상을 말한다. 예를 들어, 디스플레이를 바라보는 사용자가 왼쪽으로 위치를 이동할 경 우 입체 영상에서 객체의 더 많은 좌측 부분이 사용자에게 보이게 될 수 있다. 디스플레이는 제1 디스플레이 패널(111-1) 및 제2 디스플레이 패널(111-2)를 포함할 수 있다. 제1 디스플 레이 패널(111-1) 및 제2 디스플레이 패널(111-2) 각각은 개별적인 영상을 표시하도록 구동할 수 있다. 제1 디스플레이 패널(111-1) 및 제2 디스플레이 패널(111-2)은 적층형 구조로 배치될 수 있다. 예를 들어, 제1 디스플레이 패널(111-1)은 제1 레이어로서 제2 디스플레이 패널(111-2) 보다 하부(또는 후면 방향)에 배치되고, 제2 디스플레이 패널(111-2)은 제2 레이어로서 제1 디스플레이 패널(111-1)보다 상부(또는 전면 방향)에 배치될 수 있다. 이는 제1 디스플레이 패널(111-1) 및 제2 디스플레이 패널(111-2) 각각에서 표시되는 영상의 조합을 통해 LF(Light Field)로 구현된 입체 영상을 재현하기 위함이다. 제1 디스플레이 패널(111-1) 및 제2 디스플레이 패널(111-2) 각각은 복수의 서브 픽셀(sub pixel)을 포함할 수 있다. 여기서, 서브 픽셀은 R 서브 픽셀(red 색상), G 서브 픽셀(green 색상) 및 B 서브 픽셀(blue 색상) 중 하 나일 수 있으며, 발생된 빛 또는 입사된 빛이 방출되는 정도를 조절하는 역할을 수행할 수 있다. 서로 인접한 거리에 위치한 R 서브 픽셀, G 서브 픽셀 및 B 서브 픽셀은 하나의 픽셀(pixel)을 구성할 수 있다. 예를 들어, 도 1과 같이 제1 디스플레이 패널(111-1)은 복수의 서브 픽셀(11-1, 12-1, ... n1-1, n2-1, ...)을 포함할 수 있고, 제2 디스플레이 패널(111-1)은 복수의 서브 픽셀(11-2, 12-2, ... n1-2, n2-2, ...)을 포함할 수 있다. 제1 디스플레이 패널(111-1)의 서브 픽셀(11-1, 12-1, ... n1-1, n2-1, ...)에서 방출되는 빛은 제2 디스플레이 패널(111-2)의 서브 픽셀(11-2, 12-2, ... n1-2, n2-2, ...)을 통해 디스플레이의 외부로 방 출될 수 있다. 이때, 외부로 방출된 빛은 서브 픽셀(11-1, 12-1, ... n1-1, n2-1, ...)을 기준으로 일정한 각 도(즉, 시야각) 내에 위치하는 사용자에게 시인될 수 있다. 한편, 제1 디스플레이 패널(111-1) 및 제2 디스플레이 패널(111-2) 각각은 다양한 방식으로 영상을 표시할 수 있다. 일 예를 들어, 제1 디스플레이 패널(111-1) 및 제2 디스플레이 패널(111-2) 각각은 액정(Liquid Crystal)의 배열을 제어함으로써 빛이 통과하는 정도(즉, 투과도)를 조절하는 LCD(Liquid Crystal Display) 패 널로 구성될 수 있다. 이 경우, 디스플레이는 백라이트 유닛(Back Light Unit; BLU)을 포함할 수 있다. 여 기서, 백라이트 유닛은 LCD 패널의 하부(또는 후면 방향)에 배치되어, LCD 패널로 제공되는 빛을 발생시킬 수 있다. 백라이트 유닛은 빛을 발생시키는 CCFL(Cold Cathode Fluorescent. Lamp), LED(Light Emitting Diode) 등과 같은 발광부 및 발생된 빛을 디스플레이에 균일하게 분포시키는 도광판을 포함할 수 있다. 다른 일 예를 들어, 제1 디스플레이 패널(111-1) 및 제2 디스플레이 패널(111-2) 각각은 전자와 정공의 재결합 (recombination) 정도를 제어함으로써 빛이 발생하는 정도를 조절하는 발광 소자(예: OLED(Organic LED), Micro LED, Mini LED, QLED(Quantum dot LED) 등)를 포함하는 LED 패널로 구현될 수 있다. 본 개시의 일 실시 예에 따른 디스플레이는 렌즈 어레이를 포함할 수 있다. 여기서, 렌즈 어레이 는 서브 픽셀에서 방출되는 빛을 굴절시키며, 빛을 관측할 수 있는 시야각을 확장하는 효과가 있다. 구체적으로, 렌즈 어레이는 제1 디스플레이 패널(111-1) 상에 배치될 수 있다. 그리고, 제2 디스플레이 패 널(111-2)은 렌즈 어레이 상에 배치될 수 있다. 즉, 렌즈 어레이는 복수의 디스플레이 패널(111-1, 111-2) 중에서 상대적으로 후면에 위치한 제1 디스플레이 패널(111-1) 상에 배치될 수 있다. 이때, 복수의 서브 픽셀(11-1, 12-1, ... n1-1, n2-1, ...) 및 복수의 서브 픽셀(11-2, 12-2, ... n1-2, n2-2, ...)은 서로 대향 하도록 배치될 수 있다. 복수의 서브 픽셀(11-1, 12-1, ... n1-1, n2-1, ...) 각각에서 방출되는 빛은 복수의 서브 픽셀(11-2, 12-2, ... n1-2, n2-2, ...) 중 적어도 하나를 통해 외부로 방출될 수 있다. 렌즈 어레이는 복수의 단위 렌즈(115-1, ..., 115-n, ...)를 포함할 수 있다. 단위 렌즈(115-1, ..., 115-n, ...)는 빛을 굴절시켜 빛의 진행 방향을 변경시키기 위한 광학적 요소를 말한다. 이를 위해, 단위 렌즈 (115-1, ..., 115-n, ...)는 반원통 형상, 반구 형상 등 다양한 형상을 가지며, 투명한 성질을 갖는 유리, 플라 스틱 수지, 폴리이미드 등 다양한 소재로 구현될 수 있다. 렌즈 어레이는 렌즈 어레이의 각 단위 렌즈(115-1, ..., 115-n, ...)가 제1 디스플레이 패널(111- 1)의 복수의 서브 픽셀(11-1, 12-1, ... n1-1, n2-1, ...) 상에 위치하도록 제1 디스플레이 패널(111-1)상에 배치될 수 있다. 즉, 하나의 단위 렌즈가 제1 디스플레이 패널(111-1)의 복수 개의 서브 픽셀을 커버하도록, 제 1 디스플레이 패널(111-1) 상에 복수의 단위 렌즈가 형성될 수 있다. 일 예를 들어, 하나의 단위 렌즈(예: 115- n)는 제1 디스플레이 패널(111-1)의 짝수 개의 서브 픽셀(예: n1-1, n2-1)을 커버할 수 있다. 한편, 디스플레이는 복수의 단위 영역(110-1, ..., 110-n, ...)으로 구분될 수 있다. 하나의 단위 영역을 예로 들면, n번째 단위 영역(110-n)은 제1 디스플레이 패널(111-1)의 복수의 서브 픽셀(n1-1, n2-1), 렌즈 어레 이의 단위 렌즈(115-n) 및 제2 디스플레이 패널(111-2)의 복수의 서브 픽셀(n1-2, n2-2)를 포함할 수 있다. 제1 디스플레이 패널(111-1)의 서브 픽셀(예: n1-1)에서 방출된 빛은 렌즈 어레이의 복수의 단위 렌즈 (115-1, ..., 115-n, ...) 중에서 동일한 단위 영역(예: 110-n) 내에 위치한 단위 렌즈(예: 115-n)(즉, 서브픽셀(예: n1-1)을 커버하는 단위 렌즈(예: 115-n))에 의해 굴절될 수 있다. 이 경우, 굴절된 빛은 제1 및 제2 디스플레이 패널(111-1, 111-2) 간의 거리 및 빛의 진행 방향(또는 각도)에 따라 제2 디스플레이 패널(111-2)의 복수의 서브 픽셀(11-2, 12-2, ... n1-2, n2-2, ...)중에서 하나의 서브 픽셀(예: n2-2)을 통해 외부로 방출 (또는 방사)될 수 있다. 이때, 빛의 진행 방향(또는 각도)는 단위 렌즈의 특성(예: 굴절율, 수차, 배열 등)에 따라 정해질 수 있다. 예를 들어, 제1 디스플레이 패널(111-1)의 서브 픽셀(예: n1-1)에서 방출된 빛은 단위 렌즈(예: 115-n)에 의해 굴절되며, 굴절된 빛은 제2 디스플레이 패널(111-2)의 서브 픽셀(예: n2-2)을 통해 외부로 방출될 수 있다. 이 때, 외부로 방출된 빛은 우측 시야각(예: θR, 예: 0도 내지 +30도) 범위 내의 방향으로 진행될 수 있으며, 우 측 시야각(예: θR)에 대응되는 우측 시야각 영역(nR)에 위치하는 사용자에게 시인될 수 있다. 이와 유사한 방식으로, 제1 디스플레이 패널(111-1)의 서브 픽셀(예: n1-2)에서 방출된 빛은 단위 렌즈(예: 115-n)에 의해 굴절되며, 굴절된 빛은 제2 디스플레이 패널(111-2)의 서브 픽셀(예: n2-2)을 통해 외부로 방출 될 수 있다. 이때, 외부로 방출된 빛은 좌측 시야각(θL, 예: -30도 내지 0도) 범위 내의 방향으로 진행될 수 있으며, 좌측 시야각(θL)에 대응되는 좌측 시야각 영역(nL)에 위치한 사용자에게 시인될 수 있다. 한편, 상술한 렌즈 어레이는 일 실시 예일 뿐이며, 렌즈 어레이 대신 배리어 층으로 대체될 수 있다. 배리어 층은 제1 디스플레이 패널(111-1) 상에서 제1 디스플레이 패널(111-1)과 평행하게 배치될 수 있다. 배리 어 층에는 일정한 간격마다 빛이 투과할 수 있는 영역 및 빛이 차단될 수 있는 영역이 교대로 형성될 수 있다. 배리어 층은 제1 디스플레이 패널(111-1)의 서브 픽셀에서 방출된 빛을 투과시켜 제2 디스플레이 패널(111-2)의 특정한 서브 픽셀로 전달하거나, 제1 디스플레이 패널(111-1)의 서브 픽셀에서 방출된 빛을 차단시켜 제2 디스 플레이 패널(111-2)의 특정한 서브 픽셀로 전달되지 못하도록 하는 기능을 수행할 수 있다. 한편, 배리어 층은 제2 디스플레이 패널(111-2) 상에 제2 디스플레이 패널(111-2)과 평행하게 배치되는 등 다양한 변형 실시 예가 가능하다. 한편, 본 개시의 일 실시 예에 따른 디스플레이 장치는 시분할(Time-multiplexing) 구동을 통해 입체 영상 을 표시할 수 있다. 이는 도 2a 및 도 2b를 참조하여 함께 설명하도록 한다. 도 2a는 본 개시의 일 실시 예에 따른 디스플레이 장치의 시분할 구동을 설명하기 위한 도면이다. 도 2a를 참조하여, 본 개시의 일 실시 예에 따른 디스플레이는 시분할(Time-multiplexing) 구동을 통해 입 체 영상을 표시할 수 있다. 여기서, 시분할 구동은 디스플레이가 시간(time) 별로 번갈아 가며 다른 시점(view point)의 영상을 표시 하는 것을 말한다. 예를 들어, 디스플레이는 제1 시간(t1)에 제1 시점의 영상(예: L 영상)을 표시하고, 제 1 시간(t1)으로부터 기설정된 시간(예: 5ms 등)이 경과한 제2 시간(t2)에 제2 시점의 영상(예: R 영상)을 표시 할 수 있다. 또한, 디스플레이는 제2 시간(t2)으로부터 기설정된 시간(예: 5ms 등)이 경과한 제3 시간(t 3)에 제1 시점의 영상(예: L 영상)을 표시하며, 제3 시간(t3)으로부터 기설정된 시간(예: 5ms 등)이 경과한 제4 시간(t4)에 제2 시점의 영상(예: R 영상)을 표시할 수 있다. 즉, 디스플레이에 표시되는 영상은 시간의 경 과에 따라 제1 시점의 영상, 제2 시점의 영상, 제1 시점의 영상, 제2 시점의 영상, ... 등과 같이 순차적으로 반복될 수 있다. 디스플레이는 시간 t1에 객체의 좌측 시점을 나타내는 L 영상을 표시할 수 있다. 이후, 디스플레이는 시간 t2에 객체의 우측 시점을 나타내는 R 영상을 표시할 수 있다. 이하에서는 L 영상 및 R 영상에 대해 설명하도록 한다. L 영상은 시간 t1에 제1 디스플레이 패널(111-1)에 표시하기 위한 제1 L 영상 및 제2 디스플레이 패널(111-2)에 표시하기 위한 제2 L 영상을 포함할 수 있다. 여기서, 제1 L 영상 및 제1 R 영상 각각은 제1 디스플레이 패널 (111-1)의 픽셀 위치마다 R, G, B 색상에 대한 픽셀 값(예: 0~255 사이의 값)이 매핑될 수 있다. 한편, R 영상 은 시간 t2에 제1 디스플레이 패널(111-1)에 표시하기 위한 제1 R 영상 및 제2 디스플레이 패널(111-2)에 표시 하기 위한 제2 R 영상을 포함할 수 있다. 여기서, 제2 L 영상 및 제2 R 영상 각각은 제2 디스플레이 패널(111- 2)의 픽셀 위치마다 R, G, B 색상에 대한 픽셀 값(예: 0~255 사이의 값)이 매핑될 수 있다. 보다 구체적으로, 시간 t1 및 시간 t2에서 디스플레이 패널의 서브 픽셀들의 시분할 구동을 단위 영역(예: 110-n)을 기준으로 설명하도록 한다. 먼저, 제1 디스플레이 패널(111-1)에 표시되는 제1 L 영상 및 제1 R 영상은 표 1과 같은 픽셀 값이 매핑될 수 있다. 표 1 제1 디스플레이 패널(111-1)의 서브 픽셀제1 L 영상의 픽셀 값 (시간 t1)제1 R 영상의 픽셀 값 (시간 t2) 제1 서브 픽셀(n1-1) 블랙 (예: 0의 값) 객체의 우측 시점 (예: 0~255 사이의 값) 제2 서브 픽셀(n2-1) 객체의 좌측 시점(예: 0~255 사 이의 값)블랙 (예: 0의 값) 예를 들어, 제1 L 영상은 도 2a의 과 같이 제1 디스플레이 패널(111-1)의 제1 서브 픽셀(예: n1-1)에 대해 블랙 색상을 나타내는 픽셀 값(예: 0)이 매핑되며, 제1 디스플레이 패널(111-1)의 제2 서브 픽셀(예: n2-1)에 대해 좌측 시점의 객체의 색상을 나타내는 픽셀 값(예: 0~255 사이의 값)이 매핑될 수 있다. 한편, 제1 R 영상 은 도 2a의 와 같이 제1 디스플레이 패널(111-1)의 제1 서브 픽셀(예: n1-1)에 객체의 우측 시점을 나타내는 픽셀 값(예: 0~255 사이의 값)이 매핑되며, 제1 디스플레이 패널(111-1)의 제2 서브 픽셀(예: n2-1)에 블랙 색 상을 나타내는 픽셀 값(예: 0)이 매핑될 수 있다. 이하에서는 디스플레이 패널(111-1, 111-2)의 동작을 설명하 도록 한다. 제1 디스플레이 패널(111-1)은 시간 t1에 제1 L 영상을 표시하고, 제2 디스플레이 패널(111-2)은 시간 t1에 제2 L 영상을 표시할 수 있다. 구체적으로, 제1 디스플레이 패널(111-1)의 제2 서브 픽셀(예: n2-1)은 시간 t1에 제1 L 영상의 픽셀 값(예: 0~255 사이의 값)에 대응되는 밝기의 빛을 방출하도록 구동할 수 있다. 또한, 제2 디스플레이 패널(111-2)의 제 1 서브 픽셀(예: n1-2)은 시간 t1에 제2 L 영상의 픽셀 값(예: 0~255 사이의 값)에 대응되는 밝기의 빛을 방출 하도록 구동할 수 있다. 즉, 제1 디스플레이 패널(111-1)의 제2 서브 픽셀(예: n2-1)에서 방출된 빛은 제2 디스 플레이 패널(111-2)의 제1 서브 픽셀(예: n1-2)을 통해 좌측 시야각 영역(nL)으로 방출될 수 있다. 이 경우, 좌 측 시야각 영역(nL)에 위치한 사용자는 제1 L 영상 및 제2 L 영상의 조합에 따른 객체의 좌측 시점을 나타내는 입체 영상을 관측할 수 있다. 여기서, 제1 디스플레이 패널(111-1)의 제1 서브 픽셀(예: n1-1)은 시간 t1에 제1 L 영상의 픽셀 값(예: 블랙 색상을 나타내는 값)에 따라 빛을 방출하지 않도록 구동할 수 있다. 이 경우, 우측 시야각 영역(nR)에 위치한 사용자는 제1 L 영상을 관측할 수 없다. 시간 t2의 경우, 제1 디스플레이 패널(111-1)의 제1 서브 픽셀(예: n1-1)은 시간 t2에 제1 R 영상의 픽셀 값(예: 0~255 사이의 값)에 대응되는 밝기의 빛을 방출하도록 구동할 수 있다. 또한, 제2 디스플레이 패널(111- 2)의 제2 서브 픽셀(예: n2-2)은 시간 t2에 제2 R 영상의 픽셀 값(예: 0~255 사이의 값)에 대응되는 밝기의 빛 을 방출하도록 구동할 수 있다. 즉, 제1 디스플레이 패널(111-1)의 제1 서브 픽셀(예: n1-1)에서 방출된 빛은 제2 디스플레이 패널(111-2)의 제2 서브 픽셀(예: n2-2)을 통해 우측 시야각 영역(예: nR)으로 방출될 수 있다. 이 경우, 우측 시야각 영역(예: nR)에 위치한 사용자는 제1 R 영상 및 제2 R 영상의 조합에 따른 객체의 우측 시점을 나타내는 입체 영상을 관측할 수 있다. 여기서, 제1 디스플레이 패널(111-1)의 제2 서브 픽셀(예: n2-1)은 시간 t2에 제1 R 영상의 픽셀 값(예: 0의 값)에 따라 빛을 방출하지 않도록 구동할 수 있다. 이 경우, 좌측 시야각 영역(예: nL)에 위치한 사용자는 제1 R 영상을 관측할 수 없다. 이와 같이 본 개시의 디스플레이 장치는 시분할 구동을 통해 시점이 좌우로 확장된 입체 영상을 표현할 수 있다. 한편, 본 개시의 일 실시 예에 따르면, 디스플레이가 시분할 구동을 통해 L 영상 및 R 영상을 표시할 때 크로스톡(Crosstalk)이 발생할 수 있다. 크로스톡에 대해서는 도 2b를 참조하여 구체적으로 설명하도록 한다. 도 2b는 본 개시의 일 실시 예에 따른 크로스톡(Crosstalk)을 설명하기 위한 도면이다. 도 2a에서 상술한 내용과 같이, 제1 디스플레이 패널(110-1)은 시간 t1에 객체의 좌측 시점을 나타내는 제1 L 영상을 표시할 수 있다. 구체적으로, 제1 디스플레이 패널(111-1)은 시간 t1에 제1 L 영상의 픽셀에 매핑된 색 상의 픽셀 값에 따라, 제1 디스플레이 패널(111-1)의 제2 서브 픽셀(예: n2-1)이 픽셀 값(예: 0~255 사이의 값)에 대응되는 밝기의 빛을 방출하도록 구동하고, 제1 디스플레이 패널(111-1)의 제1 서브 픽셀(예: n1-1)이 픽셀 값(예: 0의 값)에 따라 빛을 방출하지 않도록 구동할 수 있다. 여기에서, 도 2b의 과 같이 제1 디스플레이 패널(111-1)의 제1 서브 픽셀(예: n1-1)의 주변에 위치한 제1 디 스플레이 패널(111-1)의 제2 서브 픽셀(예: n2-1)에서 방출된 빛은 단위 렌즈(예: 115-n)에 의해 굴절될 수 있 다. 이때, 굴절된 빛의 일부는 제2 디스플레이 패널(111-2)의 제1 서브 픽셀(n1-2)을 통해 좌측 시야각 영역(예: nL)으로 방출될 수 있다. 또한, 굴절된 빛의 일부는 제2 디스플레이 패널(111-2)의 제2 서브 픽셀(n2-2)을 통해 우측 시야각 영역(예: nR)으로 방출될 수 있다. 즉, 시간 t1에서 객체의 좌측 시점을 나타내는 영상은 좌측 시 야각 영역(예: nL)에 위치한 사용자뿐만 아니라 우측 시야각 영역(예: nR)에 위치한 사용자에게 관측될 수 있다. 또한, 디스플레이는 시간 t2에 객체의 우측 시점을 나타내는 R 영상을 표시할 수 있다. 구체적으로, 제1 디스플레이 패널(111-1)은 시간 t2에 제1 R 영상의 픽셀에 매핑된 색상의 픽셀 값에 따라, 제1 디스플레이 패널 (111-1)의 제1 서브 픽셀(예: n1-1)이 픽셀 값(예: 0~255 사이의 값)에 대응되는 밝기의 빛을 방출하도록 구동 하고, 제1 디스플레이 패널(111-1)의 제2 서브 픽셀(예: n2-1)이 픽셀 값(예: 0의 값)에 따라 빛을 방출하지 않 도록 구동할 수 있다. 여기에서, 도 2b의 와 같이 제1 디스플레이 패널(111-1)의 제2 서브 픽셀(예: n2-1)의 주변에 위치한 제1 디 스플레이 패널(111-1)의 제1 서브 픽셀(예: n1-1)에서 방출된 빛은 단위 렌즈(예: 115-n)에 의해 굴절될 수 있 다. 이때, 굴절된 빛의 일부는 제2 디스플레이 패널(111-2)의 제2 서브 픽셀(n2-2)을 통해 우측 시야각 영역(예: nR)으로 방출될 수 있다. 또한, 굴절된 빛의 일부는 제2 디스플레이 패널(111-2)의 제1 서브 픽셀(n1-2)을 통해 좌측 시야각 영역(예: nL)으로 방출될 수 있다. 즉, 시간 t2에서 객체의 우측 시점을 나타내는 영상은 우측 시 야각 영역(예: nR)에 위치한 사용자뿐만 아니라 좌측 시야각 영역(예: nL)에 위치한 사용자에게 관측될 수 있다. 이와 같이, 시간 t1에 제1 디스플레이 패널(111-1)의 제2 서브 픽셀(예: n2-1)에서 방출되는 빛(객체의 좌측 시 점을 나타내는 영상)이 우측 시야각 영역(예: nR)으로 방출되거나, 시간 t2에 제1 디스플레이 패널(111-1)의 제 1 서브 픽셀(예: n1-1)에서 방출되는 빛(객체의 우측 시점을 나타내는 영상)이 좌측 시야각 영역(예: nL)으로 방출되는 현상을 크로스톡(Crosstalk)이라고 정의할 수 있다. 즉, 크로스톡은 특정한 시간 및 특정한 영역에 의 도되지 않은 타 시점(view point)의 영상을 나타내는 빛이 새어나오는 현상을 말한다. 이러한 크로스톡은 입체 영상의 왜곡 또는 아티팩트(Artifact)를 초래할 수 있다. 한편, 크로스톡이 발생할 경우에 타 시점(view poin t)의 영상을 크로스톡 영상이라고 정의할 수 있다. 크로스톡은 제1 디스플레이 패널(111-1)의 특성 및 렌즈 어레이의 특성에 따라 발생할 수 있다. 예를 들어, 제1 디스플레이 패널(111-1)의 특성 및 렌즈 어레이의 특성은 제1 디스플레이 패널(111-1)의 서브 픽셀(또는 픽셀)의 크기, 렌즈 어레이의 단위 렌즈의 피치(pitch), 단위 렌즈의 수차, 단위 렌즈의 초점거 리, 서브 픽셀과 단위 렌즈의 정렬 관계(예: 정렬이 일치하지 않는 경우 등) 등의 다양한 특성을 포함할 수 있 다. 구체적으로, 렌즈의 수차 때문에 상이 정확히 한 점에 모이지 않는 경우, 렌즈의 초점 거리에 서브 픽셀(또 는 픽셀)이 정확히 위치하지 않는 경우, 렌즈 하나에 서브 픽셀(또는 픽셀)의 정수배의 수만큼 정확히 위치하지 않는 경우 등 다양한 요소로 인해 상술한 현상이 발생할 수 있다. 크로스톡이 발생한 정도는 크로스톡 비율()을 통해 나타낼 수 있다. 예를 들어, 크로스톡 비율()은 시간 t1에서 좌측 시야각 영역(예: nL)에 표시되는 영상의 밝기 및 우측 시야각 영역(예: nR)에 표시되는 크로스톡 영상의 밝 기의 비율로 정의될 수 있으며, 크로스톡 비율()은 0에서 1 사이의 값을 가질 수 있다. 또는 크로스톡 비율은 시간 t2에서 우측 시야각 영역(예: nR)에 표시되는 영상의 밝기 및 좌측 시야각 영역(예: nL)에 표시되는 크로스 톡 영상의 밝기의 비율로 정의될 수 있다. 본 개시의 일 실시 예에 따른 디스플레이 장치는 크로스톡 비율()을 이용한 영상 보정을 통해 입체 영상의 왜곡 또는 아티팩트를 저감할 수 있다. 이에 대한 구체적인 내용은 첨부된 도면을 참조하여 설명하도록 한다. 도 3은 본 개시의 일 실시 예에 따른 디스플레이 장치가 복수의 LF 영상을 이용해 보정된 영상을 획득하는 방법을 설명하기 위한 도면이다. 도 3을 참조하면, 디스플레이 장치는 복수의 LF(light field) 영상에 기초하여, 디스플레이를 시분할로 구동하기 위한 L 영상(320L) 및 R 영상(320R)을 획득할 수 있다. 여기서, L 영상(320L)은 제1 디스플레이 패널(111-1)을 구동하기 위한 제1 L 영상 및 제2 디스플레이 패널(111- 2)을 구동하기 위한 제2 영상을 포함하며, R 영상(320R)은 제1 디스플레이 패널(111-1)을 구동하기 위한 제1 R 영상 및 제2 디스플레이 패널(111-2)을 구동하기 위한 제2 R 영상을 포함할 수 있다. 즉, L 영상(320L)은 디스 플레이 패널의 수와 동일한 수의 영상을 포함하고, R 영상(320R)은 디스플레이 패널의 수와 동일한 수의 영상을 포함할 수 있다. 보다 구체적인 내용은 도 4와 함께 설명하도록 한다. 그리고, 디스플레이 장치는 R 영상(320R) 중 제1 디스플레이 패널(111-1)을 구동하기 위한 제1 R 영상에 기초하여, L 영상(320L) 중 제2 디스플레이 패널(111-2)을 구동하기 위한 제2 L 영상을 보정할 수 있다. 또한, 디스플레이 장치는 L 영상(320L) 중 제1 디스플레이 패널(111-1)을 구동하기 위한 제1 L 영상에 기초하여, R 영상(320R) 중 제2 디스플레이 패널(111-2)을 구동하기 위한 제2 R 영상을 보정할 수 있다. 이는 크로스톡이 발생할 경우에, 원 영상에서 크로스톡 영상의 밝기를 보상하여 아티팩트를 저감시키기 위한 것 이다. 본 개시에 따르면, 크로스톡 발생에 따라 외부로 새어나가는 빛을 차단하는 물리적 방식에 비해, 픽셀 단 위로 빛을 차폐시킬 수 있는 별도의 구조물이 요구되지 않는다는 점에서 비용 감소, 전력 감소, 부피 및 두께의 감소, 광추출 효율 향상 등의 장점이 있다. 본 개시의 일 실시 예에 따르면, 디스플레이 장치는 R 영상(320R) 중 제1 R 영상을 이용하여 R 크로스톡 영상(330R)을 획득하고, 획득된 R 크로스톡 영상(330R)을 이용하여 L 영상(320L) 중 제2 L 영상을 보정할 수 있 다. 또한, 디스플레이 장치는 L 영상(320L) 중 제1 L 영상을 이용하여 L 크로스톡 영상(330L)을 획득하고, 획득된 L 크로스톡 영상(330L)을 이용하여 R 영상(320R) 중 제2 R 영상을 보정할 수 있다. 보다 구체적인 내용 은 도 5a 내지 5c와 함께 설명하도록 한다. 그리고, 디스플레이 장치는 제2 L 영상이 보정된 L 영상(340L) 및 제2 R 영상이 보정된 R 영상(340R)에 기 초하여 디스플레이를 시분할로 구동하여 입체 영상을 표시할 수 있다. 이에 대해서는 도 6과 함께 구체적 으로 설명하도록 한다. 도 4는 본 개시의 일 실시 예에 따른 L 영상 및 R 영상을 획득하는 방법을 설명하기 위한 도면이다. 도 4를 참조하여, 먼저 디스플레이 장치는 복수의 LF(light field) 영상을 획득할 수 있다. 여기서, 복수의 LF(light field) 영상은 소스(source) 영상에 해당한다. 여기서, 복수의 LF 영상은 LF 카메라를 통해 획득될 수 있다. LF 카메라는 객체를 서로 다른 시점(view point)(또는 위치)에서 촬영하는 복수의 단위 렌즈를 포함하는 장치를 말한다. LF 카메라는 디스플레이 장치 에 포함되거나, 또는 디스플레이 장치와는 별도의 외부 장치로 구현될 수 있다. 한편, LF 카메라를 통해 획득된 복수의 LF 영상은 디스플레이 장치의 메모리 또는 외부 장치의 메모리에 저장될 수 있다. 디스플레이 장치는 디스플레이 장치의 메모리에 저장된 복수의 LF 영상에 액세스하거나, 외부 장치로부터 복수의 LF 영상을 수신하여 복수의 LF 영상을 획득할 수 있다. 복수의 LF 영상 각각은 촬영된 시점(view point)에 대한 정보를 포함할 수 있다. 여기서, 복수의 LF 영상 각각은 LF 카메라에 의해 서로 다른 시점(view point)으로 객체를 촬영하여 획득된 영상이다. 각 영상은 복수의 픽셀을 포함하고, 각 픽셀은 R, G, B 색상에 대한 픽셀 값이 매핑될 수 있다. 예를 들어, LF 카메라가 10x5의 배열 형태를 갖는 단위 렌즈로 구성된 경우, LF 카메라에 의해 촬영되어 획득되는 복수의 LF 영상 은 10x5의 배열 형태를 가질 수 있다. 이때, 복수의 LF 영상 각각이 배열된 위치(예: (1,1), (1,2) 등)는 해당 LF 영상이 촬영된 시점(view point)을 나타낼 수 있다. 한편, 복수의 LF 영상은 정지 영상이거나, 또는 동영상일 수 있다. 복수의 LF 영상이 동영상인 경우 에는, 복수의 LF 영상에는 촬영된 시간 또는 FPS(Frame Per Second)에 대한 정보가 포함될 수 있다. FPS 는 순차적인 영상을 촬영하거나 재현하는 속도를 말한다. 예를 들어, LF 카메라가 30FPS로 촬영할 경우, 1초 동 안 복수의 LF 영상 1, 복수의 LF 영상 2, ..., 복수의 LF 영상 30이 순차적으로 획득될 수 있다. 이후 디스플레 이가 30FPS의 복수의 LF 영상을 표시할 경우, 1초 동안 복수의 LF 영상 1을 이용해 획득된 L 영상 1 및 R 영상 1, 복수의 LF 영상 2을 이용해 획득된 L 영상 2 및 R 영상 2, ..., 복수의 LF 영상 30을 이용해 획득된 L영상 30 및 R 영상 30을 순차적으로 표시할 수 있다. 이하에서는 설명의 편의를 위해 복수의 LF 영상은 LF 카메라에 의해 동일한 시간(time)에 촬영되어 획득된 영상의 세트로 가정하여 설명하도록 한다. 디스플레이 장치는 복수의 LF(light field) 영상에 기초하여, 디스플레이를 시분할로 구동하기 위한 L 영상(420-L1) 및 R 영상(420-R2)을 획득할 수 있다. 여기서, L 영상(420-L1)은 제1 L 영상(421-L1) 및 제 2 L 영상(422-L1)을 포함하며, R 영상(410-R2)은 제1 R 영상(421-R2) 및 제2 R 영상(422-R2)을 포함할 수 있다. 구체적으로, 디스플레이 장치는 복수의 LF 영상을 시점(또는 배열 영역)에 따라 좌측 시점(또는 좌측 의 배열 위치)을 나타내는 LF 영상(410-L) 및 우측 시점(또는 우측의 배열 위치)을 나타내는 LF 영상(410-R)으 로 구분할 수 있다. 예를 들어, 복수의 LF 영상이 10x5의 LF 영상인 경우, 좌측 시점을 나타내는 LF 영상(410-L)은 좌측에 위 치한 5x5의 LF 영상(즉, (1,1) 내지 (5,5)의 LF 영상)이고, 우측 시점을 나타내는 LF 영상(410-R)은 우측에 위 치한 5x5의 LF 영상(즉, (6,1) 내지 (10,5)의 LF 영상)일 수 있다. 그리고, 디스플레이 장치는 좌측 시점을 나타내는 LF 영상(410-L)을 학습된 팩토리제이션 모델에 입력하여, 학습된 팩토리제이션 모델의 출력으로서 제 1 L 영상(421-L1) 및 제 2 L 영상(422-L1)을 포함하는 L 영상(420-L1)을 획득할 수 있다. 디스플레이 장치는 우측 시점을 나타내는 LF 영상(410-R)을 학습된 팩토 리제이션 모델에 입력하여, 학습된 팩토리제이션 모델의 출력으로서 제1 R 영상(421-R2) 및 제2 R 영상(422- R2)을 포함하는 R 영상(410-R2)을 획득할 수 있다. 여기서, 학습된 팩토리제이션(factorization) 모델은 복수의 LF 영상이 입력되면, 디스플레이 패널(111-1, 111- 2)의 수에 대응되는 수의 영상(즉, 레이어 스택)을 획득하도록 학습된 인공지능 모델일 수 있다. 예를 들어, 학 습된 팩토리제이션 모델은 디스플레이 패널(111-1, 111-2)이 2개이면 이와 동일한 2개의 영상을 획득하도록 학 습된 인공지능 모델일 수 있다. 본 개시에 따른 팩토리제이션 모델은 DNN(Deep Neural Network) 모델, NTF(Non-negative tensor factorization) 모델 또는 NMF(Non-negative Matric factorization) 모델 중 하나일 수 있다. 다만, 이는 일 실시 예일 뿐 팩토리제이션 모델은 다양한 인공지능 모델 중 적어도 하나로 구현될 수 있다. 또한, 본 개시의 일 실시 예에 따른 팩토리제이션 모델은 입출력되는 영상의 시점에 따라 다른 모델일 수 있다. 즉, 좌측 시점을 나타내는 LF 영상(410-L) 및 L 영상(420-L1)을 입출력 데이터로 하는 L 팩토리제이션 모델(또 는 제1 팩토리제이션 모델) 및 우측 시점을 나타내는 LF 영상(410-R) 및 R 영상(420-R2)을 입출력 데이터로 하 는 R 팩토리제이션 모델(또는 제2 팩토리제이션 모델)은 서로 별개의 모델이며, 각기 다른 입출력 데이터를 통 해 학습된 모델일 수 있다. 팩토리제이션 모델의 학습에 대한 구체적인 내용은 도 8을 참조하여 설명하도록 한 다. 도 5a 내지 5c는 본 개시의 일 실시 예에 따른 L 영상 및 R 영상을 보정하는 방법을 설명하기 위한 도면이다. 도 5a를 참조하면, 디스플레이 장치는 R 영상(520-R2) 중 제1 디스플레이 패널(111-1)을 구동하기 위한 제 1 R 영상(521-R2)에 기초하여, L 영상(520-L1) 중 제2 디스플레이 패널(111-2)을 구동하기 위한 제2 L 영상 (522-L1)을 보정할 수 있다. 구체적으로, 디스플레이 장치는 좌측 시점을 나타내는 제2 L 영상(522-L1)을 보정하기 위해, 우측 시점을 나타내는 제1 R 영상(521-R2)에 기초하여, R 크로스톡 영상(530-L2)을 획득할 수 있다. 여기서, R 크로스톡 영 상(530-L2)은 시간 t2에 좌측 시야각 영역에서 크로스톡이 발생할 것으로 예상될 경우의 크로스톡 영상이거나, 시간 t2에 좌측 시야각 영역에서 크로스톡이 발생한 경우에 관측되는 크로스톡 영상일 수 있다. 일 실시 예를 들어, 디스플레이 장치는 우측 시점을 나타내는 제1 R 영상(521-R2)의 각 픽셀의 픽셀 값에 대해 크로스톡 비율(예: 0에서 1 사이의 값)을 곱하여, 이들이 곱해진 픽셀 값을 갖는 R 크로스톡 영상(530- L2)을 획득할 수 있다. 이때, 크로스톡 비율은 우측(또는 좌측) 시야각 영역에서 관측되는 밝기 및 좌측(또는 우측) 시야각 영역에서 관측되는 밝기의 비율이며, 실험적으로 측정된 값일 수 있다. 예를 들어, 제1 R 영상(521-R2)의 (100, 100) 픽 셀의 Red 색상에 대한 픽셀 값이 50이고, 크로스톡 비율이 0.1인 경우를 가정하면, R 크로스톡 영상(530-L2)의 (100, 100) 픽셀의 Red 색상에 대한 픽셀 값은 5 (= 50 * 0.1)가 될 수 있다. 다른 일 실시 예를 들어, 도 5b를 참조하면, 디스플레이 장치는 우측 시점을 나타내는 제1 R 영상(521-R2) 및 제2 R 영상(522-R2)를 합성하여, 합성된 R 영상(525-R2)을 획득할 수 있다. 디스플레이 장치는 합성된 R 영상(525-R2)의 각 픽셀의 픽셀 값에 크로스톡 비율(예: 0에서 1 사이의 값)을 곱하여, 이들이 곱해진 픽셀 값을 갖는 R 크로스톡 영상(530-L2)을 획득할 수 있다. 여기서, 디스플레이 장치는 제1 R 영상(521-R2) 및 제2 R 영상(522-R2)을 동일한 위치의 픽셀(또는 빛의 진행 경로에 있는 픽셀)끼리 픽셀 값을 곱함으로써 합성된 R 영상(525-R2)을 획득할 수 있다. 이때, 합성된 R 영상(525-R2)은 제1 R 영상(521-R2)이 제1 디스플레이 패널(111-1)에 표시되고, 제2 R 영상(522-R2)이 제2 디 스플레이 패널(111-2)에 표시될 경우에 외부의 우측 시야각 영역에서 관측되는 영상을 나타낼 수 있다. 예를 들어, (50, 50) 픽셀에 대해 제1 R 영상(521-R2)의 픽셀 값이 100이고, 제2 R 영상(522-R2)의 픽셀 값이 200인 경우를 가정하면, 디스플레이 장치는 (50, 50) 픽셀에 대해 제1 R 영상(521-R2)의 픽셀 값 100을 (100/255) 와 같이 정규화하고, 제2 R 영상(522-R2)의 픽셀 값 200을 (200/255) 와 같이 정규화하고, 정규화된 값에 픽셀 값의 최대 값 255를 곱하여 합성된 영상의 픽셀 값 78(= (100 / 255) * (200 / 255) * 255)을 산출 할 수 있다. 이때, 소수점 자리의 수는 반올림, 버림, 올림 등 다양한 방식으로 처리될 수 있다. 또 다른 예를 들어, R 크로스톡 영상(530-L2)은 우측 시점을 나타내는 제1 R 영상(521-R2) 및 제2 R 영상(522- R2)가 표시될 경우에 밝기를 측정하는 장치에 의해 외부의 좌측 시야각 영역에서 실제로 관측되는 영상일 수 있 다. 그리고, 디스플레이 장치는 R 크로스톡 영상(530-L2)을 이용하여 제2 L 영상(522-L1)을 보정하고, 보정된 제2 L 영상(542-L1)을 획득할 수 있다. 예를 들어, 도 5c를 참조하면, 디스플레이 장치는 동일한 위치 및 색상의 픽셀(즉, 동일한 위치의 서브 픽 셀)에 대해 제2 L 영상(522-L1)의 픽셀 값 200에서 R 크로스톡 영상(530-L2)의 픽셀 값 20을 빼는 보정을 수행 하여, 동일한 위치 및 색상의 픽셀이 픽셀 값 180을 갖도록 보정된 제2 L 영상(542-L1)을 획득할 수 있다. 이 경우, 디스플레이 장치는 제1 L 영상(521-L1)에 대해서는 보정을 수행하지 않을 수 있다. 즉, 제1 L 영상 (521-L1)의 픽셀 값은 보정 전과 동일하게 50으로 유지될 수 있다. 한편, 디스플레이 장치는 L 영상(520-L1) 중 제1 디스플레이 패널(111-1)을 구동하기 위한 제1 L 영상 (521-L1)에 기초하여, L 크로스톡 영상(530-R1)을 획득할 수 있다. 여기서, L 크로스톡 영상(530-R1)은 시간 t1 에 우측 시야각 영역에서 크로스톡의 발생이 예상될 경우의 크로스톡 영상이거나, 실제로 크로스톡이 발생한 경 우에 관측되는 크로스톡 영상일 수 있다. 그리고, 디스플레이 장치는 L 크로스톡 영상(530-R1)을 이용하여 제2 R 영상(522-R2)을 보정하고, 보정된 제2 R 영상(542-R2)을 획득할 수 있다. 구체적인 내용은 상술한 내용과 중복된다는 점에서 생략하도록 한다. 도 6은 본 개시의 일 실시 예에 따른 디스플레이 장치가 보정된 L 영상 및 R 영상을 표시할 경우에 관측되는 입 체 영상을 설명하기 위한 도면이다. 도 6을 참조하면, 디스플레이 장치는 제2 L 영상(522-L1)이 보정된 L 영상(540-L1) 및 제2 R 영상(522- R2)이 보정된 R 영상(540-R2)에 기초하여 디스플레이를 시분할로 구동하여, 디스플레이에 입체 영상 을 표시할 수 있다. 구체적으로, 제1 디스플레이 패널(111-1)은 시간 t1에 제1 L 영상(521-L1, 541-L1)을 표시하고, 제2 디스플레이 패널(111-2)은 시간 t1에 보정된 제2 L 영상(542-L1)을 표시할 수 있다. 그리고, 제1 디스플레이 패널(111-1)은 시간 t2에 제1 R 영상(521-R2, 541-R2)을 표시하고, 제2 디스플레이 패널(111-2)은 시간 t2에 보정된 제2 R 영 상(542-R2)을 표시할 수 있다. 여기서, 좌측 시야각 영역에서 시간 t1에 제1 L 영상(521-L1, 541-L1) 및 보정된 제2 L 영상(542-L1)이 합쳐진 L 입체 영상(650-L1)이 관측되고, 좌측 시야각 영역에서 시간 t2에는 R 크로스톡 영상(630R-L2)이 관측될 수 있 다. 시간 t1의 L 입체 영상(650-L1) 및 시간 t2의 R 크로스톡 영상(630R-L2)이 매우 짧은 시간 동안 순차적으로 반복 표시됨으로써, 좌측 시야각 영역에 위치한 사용자는 이들을 하나의 최종 입체 영상(660-L)으로 인지할 수 있게 된다. 한편, 우측 시야각 영역에서 시간 t2에 제1 R 영상(521-R2, 541- R2) 및 보정된 제2 R 영상(542-R2)이 합쳐진 입체 영상(650-R2)이 관측되고, 우측 시야각 영역에서 시간 t1에는 L 크로스톡 영상(630L-R1)이 관측될 수 있다. 시간 t2의 R 입체 영상(650-R2) 및 시간 t1의 L 크로스톡 영상(630L-R1)이 매우 짧은 시간 동안 순차적으 로 반복 표시됨으로써, 우측 시야각 영역에 위치한 사용자는 이들을 하나의 최종 입체 영상(660-R)으로 인지할수 있게 된다. 이와 같이 본 개시의 일 실시 예에 따른 디스플레이 장치는 시간 t2(또는 시간 t1)에 좌측 시야각 영역(또 는 우측 시야각 영역)에서 관측될 수 있는 R 크로스톡 영상(630R-L2)(또는 L 크로스톡 영상(630L-R1))의 밝기만 큼 시간 t1(또는 시간 t2)에 좌측 시야각 영역(또는 우측 시야각 영역)에 표시되는 L 영상(또는 R 영상)의 밝기 를 감소시키는 보정을 수행할 수 있다. 이는 디스플레이 장치가 매우 짧은 시간 동안 보정된 영상 및 크로 스톡 영상을 순차적으로 표시할 때, 사용자는 하나의 자연스러운 입체 영상으로 인지할 수 있기 때문에, 결과적 으로 크로스톡이 발생되지 않은 경우와 같은 크로스톡 저감 효과가 있다. 도 7a 및 도 7b는 본 개시의 일 실시 예에 따른 보정 전과 보정 후의 영상을 비교하기 위한 도면이다. 도 7a의 표에서 행은 디스플레이 패널에서 표시되는 영상(즉, 디스플레이 패널 별 영상)을 나타내며, 열은 좌측 시점의 L 영상 및 우측 시점의 R 영상을 나타낸다. 본 개시의 일 실시 예에 따른 제2 디스플레이 패널(111-2)에서 시간 t1에 표시되는 제2 L 영상(722-L1)은 제1 디스플레이 패널(111-1)에서 시간 t2에 표시되는 제1 R영상(721-R2)를 기초로 보정되어, 최종 제2 L 영상(742- L1)이 획득될 수 있다. 한편, 제2 디스플레이 패널(111-2)에서 시간 t2에 표시되는 제2 R 영상(722-R2)은 제1 디스플레이 패널(111-1)에서 시간 t1에 표시되는 제1 L영상(721-L1)를 기초로 보정되어, 최종 제2 R 영상(742- R2)이 획득될 수 있다. 이에 대한 구체적인 내용은 전술한 바와 중복된다는 점에서 생략하기로 한다. 이 경우, 제2 L 영상(722-L1)과 보정된 최종 제2 L 영상(742-L1)을 동일한 위치(즉, 픽셀)에 대해 비교하면, 최 종 제2 L 영상(742-L1)의 밝기는 제2 L 영상(722-L1)에 비해 더 어두울 수 있다. 즉, 최종 제2 L 영상(742- L1)의 픽셀 값이 제2 L 영상(722-L1)의 픽셀 값에 비해 더 낮을 수 있다. 한편, 제2 R 영상(722-R2)과 보정된 최종 제2 R 영상(742-R2)을 동일한 위치(즉, 픽셀)에 대해 비교하면, 최종 제2 R 영상(742-R2)의 밝기는 제2 R 영상(722-R2)에 비해 더 어두울 수 있다. 즉, 최종 제2 R 영상(742-R2)의 픽셀 값이 제2 R 영상(722-R2)의 픽 셀 값에 비해 더 낮을 수 있다. 이는 크로스톡 영상의 밝기(또는 픽셀 값)이 제2 L 영상 및 제2 R 영상에 반영 된 결과이다. 도 7b는 보정 전의 입체 영상과 보정 후의 입체 영상을 나타낸 것이다. 여기서, 보정되지 않은 L 입체 영상(775-L)은 디스플레이의 각 디스플레이 패널(111-1, 111-2)에 시간 t1 에 보정되지 않은 L 영상이 표시되고 시간 t2에 보정되지 않은 R 영상이 표시될 경우에 외부의 좌측 시점 영역 에서 중첩되어 나타나는 입체 영상이다. 또한, 보정된 L 입체 영상(785-L)은 디스플레이의 각 디스플레이 패널(111-1, 111-2)에 시간 t1에 보정된 L 영상이 표시되고 시간 t2에 보정된 R 영상이 표시될 경우에 외부의 좌측 시점 영역에서 중첩되어 나타나는 입체 영상이다. 이와 유사한 방식으로, 보정되지 않은 R 입체 영상(775-R)은 디스플레이의 각 디스플레이 패널(111-1, 111-2)에 시간 t1에 보정되지 않은 L 영상이 표시되고 시간 t2에 보정되지 않은 R 영상이 표시될 경우에 외부의 우측 시점 영역에서 중첩되어 나타나는 입체 영상이다. 또한, 보정된 R 입체 영상(785-R)은 디스플레이의 각 디스플레이 패널(111-1, 111-2)에 시간 t1에 보정된 L 영상이 표시되고 시간 t2에 보정된 R 영상이 표시될 경우에 외부의 우측 시점 영역에서 중첩되어 나타나는 입체 영상이다. 도 7b를 참조하여 보정 전과 보정 후의 영상을 비교하면, 보정 후의 L 입체 영상(785-L)은 보정 전의 L 입체 영 상(775-L)에 비해 최대 신호 대 잡음비(Peak Signal-to-noise ratio, PSNR)가 31.7497에서 39.2026으로 증가하 였으며, 보정 후의 R 입체 영상(785-R)은 보정 전의 R 입체 영상(775-R)에 비해 최대 신호 대 잡음비가 32.2422 에서 39.3431으로 증가하였음을 알 수 있다. 여기서, 최대 신호 대 잡음비는 두 영상의 화질에 대한 손실 정보 를 평가하는 것을 말하며, 그 값이 클수록 영상의 손실이 적으며 영상의 화질이 좋다는 것을 의미한다. 즉, 본 개시의 일 실시 예에 따라 보정된 영상은 보정 전에 비해 최대 신호 대 잡음비가 증가하며, 이는 보정 전에 비 해 손실이 적고 화질이 좋아진다는 것을 알 수 있다. 도 8은 본 개시의 일 실시 예에 따른 팩토리제이션 모델을 학습하는 방법을 설명하기 위한 도면이다. 도 4 및 도 8을 참조하여, 먼저 L 팩토리제이션 모델(또는 제1 팩토리제이션 모델)에 대해 설명하도록 한다. 여 기서, L 팩토리제이션 모델은 복수의 LF 영상 중에서 좌측 시점을 나타내는 LF 영상(410-L)에서 디스플레 이의 디스플레이 패널(111-1, 111-2)의 수에 대응되는 L 영상(420-L1)을 출력하도록 학습되는 인공지능 모 델일 수 있다. 즉, L 팩토리제이션 모델은 좌측 시점을 나타내는 LF 영상(410-L)을 입력 데이터로 하고, L 영상 (420-L1) 출력 데이터로 할 수 있다. 디스플레이 장치는 복수의 LF 영상을 좌측 시점을 나타내는 LF 영상(410-L) 및 우측 시점을 나타내는 LF 영상(410-R)으로 구분할 수 있다. 디스플레이 장치는 복수의 LF 영상 중에서 좌측 시점을 나타내는 복수의 LF 영상(410-L)을 추출하여, 추출된 복수의 LF 영상(410-L)을 학습되지 않은 L 팩토리제이션 모델(또는 학습 중인 L 팩토리제이션 모델)에 입력하여 L 영상(420-L1)을 획득할 수 있다. 이때, L 영상(420-L1)은 디스플레이 패널(111-1, 111-2)의 수(예: 2개)와 동일한 수의 제1 L 영상(421-L1) 및 제2 L 영상(422-L1)을 포함할 수 있다. 그리고, 디스플레이 장치는 L 영상(420-L1)에 포함된 제1 L 영상(421-L1) 및 제2 L 영상(422-L1)에 기초 하여 각각 좌측 시점을 나타내는 복수의 LF 영상을 복원할 수 있다. 이때, 복원된 LF 영상은 실제 또는 가상의 시뮬레이션을 통해 제1 디스플레이 패널(111-1)이 제1 L 영상(421-L1)을 표시하고, 제2 디스플레이 패널(111- 2)이 제2 L 영상(422-L1)을 표시할 때, 외부의 특정 시점에서 보이는(또는 보일 것으로 예측되는) LF 영상일 수 있다. 여기서, 시점(view point) 별로 각 디스플레이 패널(111-1, 111-2)에서 표시되는 영상의 시프팅 파라미터가 매 핑되어 있을 수 있다. 예를 들어, 디스플레이 패널(111-1, 111-2)이 2개인 경우를 가정하면, 각 시점에 대해 제 1 디스플레이 패널(111-1)에 표시되는 영상의 시프팅 파라미터 및 제2 디스플레이 패널(111-2)에 표시되는 영상 의 시프팅 파라미터가 매핑될 수 있으며, 예를 들어, 좌하측 시점은 (0, 0), 중간 시점 (Cx, Cy), 우상측 시점 은 (2Cx, 2Cy) 등과 같은 방식으로 시프팅 파라미터가 매핑될 수 있다. 다만, 이는 일 실시 예일 뿐, 다양한 변 형이 가능하다 할 것이다. 이 경우, 시점에 따른 시프팅 파라미터를 제1 L 영상(421-L1)에 적용하고, 제2 L 영상(422-L1)에 적용하여 LF 영상을 복원할 수 있다. 즉, 특정한 시점에 대해 제1 L 영상(421-L1)에 매핑된 시프팅 파라미터를 적용해 제1 L 영상(421-L1)의 위치를 조정하고, 제2 L 영상(422-L1)에 매핑된 시프팅 파라미터를 적용해 제2 L 영상(422- L1)의 위치를 조정하여, 조정된 위치가 서로 동일한 위치의 픽셀끼리 픽셀 값을 곱할 수 있다. 이때, 정규화를 함께 할 수 있다. 이러한 과정을 통해 디스플레이 장치는 해당 시점의 LF 영상을 복원할 수 있다. 여기에서, 학습된 제1 팩토리제이션 모델은 L 영상(420-L1)을 통해 복원된 LF 영상 및 좌측 시점을 나타내는 LF 영상(410-L1)에 기초한 손실함수가 기설정된 값 이하가 될 때까지 학습될 수 있다. 여기서, 손실함수(loss fuction)란 팩토리제이션 모델의 현재 학습 상태(또는 현재 성능)를 나타내는 지표이며, 손실함수를 바탕으로 팩토리제이션을 수행하기 위한 모델을 학습시킬 수 있다. 구체적으로, 디스플레이 장치는 소스 영상으로 입력된 좌측 시점을 나타내는 복수의 LF 영상(410-L)과 좌 측 시점을 나타내는 복원된 복수의 LF 영상을 비교하여 손실함수(loss fuction)를 획득할 수 있다. 예를 들어, 손실함수를 획득하는 방법은, 평균 제곱의 오차를 이용하여 손실함수를 계산하는 Mean squared error 방법, 영 상에 대한 화질을 측정하여 손실함수를 계산하는 SSIM(structural similarity index) 방법, 최소절대편차 (least absolute deviations) 또는 최소절대오차(least absolute errors)를 이용하여 손실함수를 계산하는 L1 norm 방법 및 최소제곱오차(least squares errors)를 이용하여 손실함수를 계산하는 L2 norm 방법 등이 있다. 다만, 이에 한정되지 않고, 상술한 방법을 조합하여 이용하거나, 다른 방법에 의해서도 손실함수가 획득될 수 있다. 그리고, L 팩토리제이션 모델은 손실함수가 기설정된 값 이하가 될 때까지 학습될 수 있으며, 학습에 따라 L 팩 토리제이션 모델의 가중치(또는 파라미터)는 그 값이 조정되어 업데이트될 수 있다. 즉, L 팩토리제이션 모델은 손실함수가 감소하는 방향으로 학습될 수 있다. 한편, 본 개시의 일 실시 예에 따른 팩토리제이션 모델은 복원된 복수의 LF 영상에 다른 시점의 크로스톡 영상 을 합성한 복수의 LF 영상에 기초하여 학습될 수 있다. 예를 들어, L 팩토리제이션 모델의 경우, 좌측 시점을 나타내는 복원된 복수의 LF 영상에 우측 시점을 나타내는 크로스톡 영상을 합성하여, 합성된 복수의 LF 영상과 좌측 시점을 나타내는 복수의 LF 영상(410-L)을 비교하여 손실함수를 획득하고, 손실함수가 감소하는 방향으로 L 팩토리제이션 모델이 학습될 수 있다. 한편, 우측 시점을 나타내는 LF 영상(410-R) 및 R 영상(420-R2)을 입출력 데이터로 하는 R 팩토리제이션 모델의 경우에도 상술한 내용과 유사한 방식으로 학습될 수 있다. 즉, 디스플레이 장치는 소스 영상으로 입력된 우측 시점을 나타내는 복수의 LF 영상(410-R)과 우측 시점을 나타내는 복원된 복수의 LF 영상을 비교하여 손실 함수(loss fuction)를 획득하고, R 팩토리제이션 모델은 손실함수가 감소하는 방향으로 학습될 수 있다. 즉, R 팩토리제이션 모델의 가중치(또는 파라미터)는 손실함수를 바탕으로 업데이트될 수 있다. 이 경우에도 팩토리제이션 모델은 복원된 복수의 LF 영상에 다른 시점의 크로스톡 영상을 합성한 복수의 LF 영 상에 기초하여 학습될 수 있다. 즉, 우측 시점을 나타내는 복원된 복수의 LF 영상에 좌측 시점을 나타내는 크로 스톡 영상을 합성하여, 합성된 복수의 LF 영상과 우측 시점을 나타내는 복수의 LF 영상(410-R)을 비교하여 손실 함수를 획득하고, 손실함수가 감소하는 방향으로 R 팩토리제이션 모델이 학습될 수 있다. 한편, 상술한 예에서는 디스플레이 장치가 2개의 L 영상 및 R 영상을 번갈아가며 시분할 구동을 수행하였 으나, 이는 일 실시 예일 뿐 다양한 시점으로 분류된 영상을 번갈아 가며 시분할 구동을 수행할 수 있다. 일 실시 예로서, 디스플레이 장치는 복수의 LF 영상이 시점에 따라 분류된 LF 영상에 기초하여, 시점에 대 응되는 L 영상, M 영상 및 R 영상을 획득할 수 있다. 여기서, 복수의 LF 영상에서 각 시점에 대응되는 팩토리제 이션 모델을 통해 L 영상, M 영상 및 R 영상을 획득할 수 있다. 여기서, 팩토리제이션 모델의 학습에 대해서는 도 9를 참조하여 설명하도록 한다. 여기서, L 영상은 좌측 시야각 영역(예: -30도 내지 -10도)에서 관측될 수 있는 좌측 시점을 나타내는 영상이며, M 영상은 중간 시야각 영역(예: -10도 내지 10도)에서 관측될 수 있는 중간 시점을 나타내는 영상이 며, R 영상은 우측 시야각 영역(예: +10도 내지 +30도)에서 관측될 수 있는 우측 시점을 나타내는 영상일 수 있 다. M 영상은 제1 디스플레이 패널(111-1)을 구동하기 위한 제1 M 영상 및 제2 디스플레이 패널(111-2)을 구동 하기 위한 제2 M 영상을 포함할 수 있다. 여기서, M 영상의 경우 인접한 L 영상 및 R 영상에 의해 크로스톡이 발생할 수 있으며, 본 개시의 디스플레이 장치는 이러한 크로스톡을 저감시키기 위해 다음과 같은 동작을 수행할 수 있다. 디스플레이 장치는 제1 M 영상 및 제1 R 영상에 기초하여, 제2 L 영상을 보정할 수 있다. 구체적으로, 디스플레이 장치는 제1 M 영상(또는 제1 M 영상 및 제2 M 영상이 합성된 영상)의 픽셀 값에 크로스톡 비율을 곱해 M 크로스톡 영상을 획득하며, 제1 R 영상(또는 제1 R 영상 및 제2 R 영상이 합성된 영 상)의 픽셀 값에 크로스톡 비율을 곱해 R 크로스톡 영상을 획득할 수 있다. 그리고, 디스플레이 장치는 R 크로스톡 영상의 픽셀 값만큼 감소시킨 픽셀 값을 갖도록 제2 L 영상을 보정할 수 있다. 또한, 디스플레이 장치는 제1 M 영상 및 제1 L 영상에 기초하여, 제2 R 영상을 보정할 수 있다. 디스플레 이 장치는 제1 L 영상 및 제1 R 영상에 기초하여, 제2 M 영상을 보정할 수 있다. 구체적인 내용은 상술한 제2 L 영상을 보정하는 방법과 중복된다는 점에서 생략하기로 한다. 그리고, 디스플레이 장치는 제2 L 영상이 보정된 L 영상, 제2 M 영상이 보정된 M 영상 및 제2 R 영상이 보 정된 R 영상에 기초하여, 디스플레이를 시분할로 구동하여, 입체 영상을 표시할 수 있다. 예를 들어, 디스플레이 장치는 시간 t1에 보정된 L 영상을 표시하도록 디스플레이를 구동하고, 시간 t2에 보정된 M 영상을 표시하도록 디스플레이를 구동하고, 시간 t3에 보정된 R 영상을 표시하도록 디스플 레이를 구동할 수 있다. 즉, 디스플레이 장치는 시간 t1, t2, t3, t1, t2, ... 와 같이 시간에 따라 각 영상을 번갈아 가며 표시할 수 있다. 이와 같이, 본 개시의 디스플레이 장치는 서로 인접한 영역에서 발생하는 크로스톡 영상의 밝기를 보상하 여 시분할 구동한다는 점에서 크로스톡이 발생하지 않은 경우와 유사한 크로스톡 저감 효과가 있다. 도 9는 본 개시의 일 실시 예에 따른 분할된 시점의 수에 따라 팩토리제이션 모델을 학습하는 방법을 설명하기 위한 도면이다. 도 9를 참조하면, 본개시의 일 실시 예에 따라 복수의 LF 영상은 시점에 따라 좌측 시점, 중간 시점, 우측 시점 으로 분류될 수 있다. 이하에서는, 중간 시점에 대응되는 M 팩토리제이션 모델을 학습하는 방법에 대해 설명하 도록 한다. 디스플레이 장치는 디스플레이의 디스플레이 패널(111-1, 111-2)의 수에 대응되는 L 영상(420-L1)을 출력하도록 학습되는 M 팩토리제이션 모델에 중간 시점의 LF 영상을 입력하여, 그 출력으로서 M 영상을 획득할 수 있다. 이때, M 영상은 디스플레이 패널(111-1, 111-2)의 수와 동일한 수의 제1 M 영상 및 제2 M 영상을 포함 할 수 있다. 그리고, 디스플레이 장치는 M 영상에 포함된 제1 M 영상 및 제2 M 영상에 기초하여 중간 시점을 나타내는 복수의 LF 영상을 복원할 수 있다. 이때, 복원된 LF 영상은 실제 또는 가상의 시뮬레이션을 통해 제1 디스플레 이 패널(111-1)이 제1 M 영상을 표시하고, 제2 디스플레이 패널(111-2)이 제2 M 영상을 표시할 때, 외부의 특정시점에서 보이는(또는 보일 것으로 예측되는) LF 영상일 수 있다. 디스플레이 장치는 M 영상을 통해 복원된 LF 영상, L 크로스톡 영상 및 R 크로스톡 영상을 합성한 영상을 획득할 수 있다. 여기서, L 크로스톡 영상의 경우, 전술한 바와 같이, 복수의 LF 영상 중에서 좌측 시점을 나타 내는 LF 영상을 L 팩토리제이션 모델에 입력할 경우에 출력되는 L 영상에 크로스톡 비율을 곱해 획득되는 영상 일 수 있다. 또한, R 크로스톡 영상의 경우, 복수의 LF 영상 중에서 우측 시점을 나타내는 LF 영상을 R 팩토리 제이션 모델에 입력할 경우에 출력되는 R 영상에 크로스톡 비율을 곱해 획득되는 영상일 수 있다. 합성된 영상 은 동일한 위치의 픽셀에 대해 각 영상의 픽셀 값을 합한 영상일 수 있다. 또한, 제1 팩토리제이션 모델은 합성된 영상 및 중간 시점을 나타내는 LF 영상에 기초한 손실함수가 기설정된 값 이하가 될 때까지 학습될 수 있다. 한편, 다른 시점에 대응되는 L 및 R 팩토리제이션 모델은 이와 동일한 방 식이 적용될 수 있다는 점에서 중복되는 내용은 생략하기로 한다. 도 10은 본 개시의 일 실시 예에 따른 디스플레이 장치를 설명하기 위한 블록도이다. 도 10을 참조하면, 본 개시의 일 실시 예에 따른 디스플레이 장치는 디스플레이 및 프로세서를 포함할 수 있다. 디스플레이는 복수의 디스플레이 패널(111-1, 111-2)을 포함할 수 있다. 여기서, 복수의 디스플레이 패널 (111-1, 111-2)은 서로 평행하도록 배치되어, 표면에 수직하는 방향으로 적층되는 구조를 가질 수 있다. 복수의 디스플레이 패널(111-1, 111-2) 각각은 복수의 픽셀을 포함할 수 있다. 각 픽셀은 복수의 서브 픽셀을 포함하며, 각 서브 픽셀은 구동회로에 의해 빛이 방출되는 정도가 조절될 수 있다. 디스플레이는 렌즈 어레이를 포함할 수 있다. 렌즈 어레이는 복수의 디스플레이 패널(111-1, 111-2) 사이에 배치될 수 있다. 예를 들어, 렌즈 어레이는 제1 디스플레이 패널(111-1) 상에 배치될 수 있 다. 렌즈 어레이는 복수의 단위 렌즈를 포함하며, 각 단위 렌즈는 제1 디스플레이 패널(111-1)의 서브 픽 셀(또는 픽셀)을 통해 방출되는 빛을 굴절시켜 빛이 진행하는 방향을 변경시킬 수 있다. 한편, 복수의 디스플레 이 패널의 수는 다양하게 변형될 수 있으며, 이 경우, 복수의 디스플레이 패널은 상술한 바와 같이 적층되는 구 조로 배치될 수 있다. 예를 들어, 복수의 디스플레이 패널은 제1 디스플레이 패널(111-1) 및 제2 디스플레이 패 널(111-2), ..., 및 제n 디스플레이 패널을 포함할 수 있다(n은 3 이상의 자연수). 이 경우, 렌즈 어레이 는 제1 디스플레이 패널(111-1) 및 제2 디스플리에 패널(111-2) 사이에 배치될 수 있다. 이와 다른 실시 예로서, 렌즈 어레이는 제2 디스플레이 패널(111-2) 및 제3 디스플레이 패널 사이에 배치될 수 있다. 이와 같은 방식으로 제n-1 디스플레이 패널 및 제n 디스플레이 패널 사이에 배치될 수 있다(n은 4 이상의 자연수). 프로세서는 디스플레이 장치의 전반적인 동작을 제어할 수 있다. 프로세서는 CPU(Central Processing Unit), AP(Application Processor) 등과 같은 범용 프로세서, GPU(Graphic Processing Unit), VPU(Vision Processing Unit) 등과 같은 그래픽 전용 프로세서, NPU(Neural Processing Unit)와 같은 인공지능 전용 프로세서 등으로 구현될 수 있다. 또한, 프로세서는 적어도 하나의 인스트럭션 또는 모듈을 로드하기 위한 휘발성 메모리를 포함할 수 있다. 프로세서는 RAM(미도시), ROM(미도시), 그래픽 처리부(미도시), 메 인 CPU(미도시), 제1 내지 n 인터페이스(미도시), 버스(미도시)를 포함할 수 있다. 이때, RAM(미도시), ROM(미 도시), 그래픽 처리부(미도시), 메인 CPU(미도시), 제1 내지 n 인터페이스(미도시) 등은 버스(미도시)를 통해 서로 연결될 수 있다. 프로세서는 상술한 디스플레이 장치의 동작을 제어할 수 있다. 구체적으로, 프로세서는 복수의 LF(light field) 영상에 기초하여, 디스플레이를 시분할로 구동 하기 위한 L 영상(320L) 및 R 영상(320R)을 획득할 수 있다. 그리고, 프로세서는 R 영상(320R) 중 제1 디 스플레이 패널(111-1)을 구동하기 위한 제1 R 영상에 기초하여, L 영상(320L) 중 제2 디스플레이 패널(111-2)을 구동하기 위한 제2 L 영상을 보정할 수 있다. 또한, 디스플레이 장치는 L 영상(320L) 중 제1 디스플레이 패널(111-1)을 구동하기 위한 제1 L 영상에 기초하여, R 영상(320R) 중 제2 디스플레이 패널(111-2)을 구동하기 위한 제2 R 영상을 보정할 수 있다. 프로세서는 제2 L 영상이 보정된 L 영상(340L) 및 제2 R 영상이 보정 된 R 영상(340R)에 기초하여 디스플레이를 시분할로 구동하여 입체 영상을 표시할 수 있다. 이와 같이, 프로세서는 상술한 디스플레이 장치 또는 디스플레이 장치가 포함하는 다른 구성의 동작을 제어할 수 있으며, 구체적인 내용은 중복된다는 점에서 생략하기로 한다. 한편, 디스플레이 장치는 메모리, 통신부, 입력 인터페이스 등의 다양한 구성 중 적어도 하나를 더 포함할 수 있다. 메모리는 다양한 정보를 저장할 수 있다. 예를 들어, 메모리에는 디스플레이 장치 또는 프로세서의 동작에 필요한 각종 명령어(instruction), OS(Operational System), 응용프로그램 또는 데이터가 저장될 수 있 다. 이를 위해, 메모리는 S-RAM(Static Random Access Memory), D-RAM(Dynamic Random Access Memory) 등의 휘 발성 메모리와, Flash Memory, ROM(Read Only Memory), EPROM(Erasable Programmable Read Only Memory), EEPROM(Electrically Erasable Programmable Read Only Memory) 등의 비휘발성 메모리, 하드디스크 드라이브 (HDD) 또는 솔리드 스테이트 드라이브(SSD) 등으로 구현될 수 있다. 메모리는 프로세서에 의해 액세스되며, 프로세서에 의한 데이터의 독취/기록/수정/삭제/갱신 등이 수행될 수 있다. 통신부는 외부 장치와 통신을 수행하여 외부 장치와 데이터를 주거나 받을 수 있다. 예를 들어, 통신부는, LTE, LTE-A(LTE Advance), CDMA(code division multiple access), WCDMA(wideband CDMA), UMTS(universal mobile telecommunications system), WiBro(Wireless Broadband), 또는 GSM(Global System for Mobile Communications) 등 중 적어도 하나를 사용하는 셀룰러 통신, WiFi(wireless fidelity), 블루투스, 블루투스 저전력(BLE), 지그비(Zigbee), NFC(near field communication) 등의 다양한 방식 중 적어도 하나의 무선 통신 을 수행할 수 있다. 또한, 통신부는 USB(universal serial bus), HDMI(high definition multimedia interface), DVI(Digital Visual Interface), 썬더볼트, 이더넷, USB 포트, 라이트닝 등의 다양한 방식 중 적 어도 하나의 유선 통신을 수행할 수 있다. 입력 인터페이스는 사용자로부터 다양한 방식의 사용자 명령(command)을 수신할 수 있다. 입력 인터페이스는 수 신된 사용자 명령을 프로세서로 전달할 수 있다. 이를 위해, 입력 인터페이스는 예를 들면, 터치 패널 또 는 키를 포함할 수 있다. 터치 패널은, 예를 들면, 정전식, 감압식, 적외선 방식, 또는 초음파 방식 중 적어도 하나의 방식을 사용할 수 있으며, 이를 위한 제어 회로를 포함할 수 있다. 터치 패널은 택타일 레이어(tactile layer)를 더 포함하여, 사용자에게 촉각 반응을 제공할 수 있다. 키는 예를 들면, 물리적인 버튼 방식, 광학 방 식 또는 터치 패널과 결합된 가상의 키패드 방식을 통해 구현될 수 있다. 도 11은 본 개시의 일 실시 예에 따른 흐름도를 설명하기 위한 도면이다. 도 11을 참조하여, 본 개시의 일 실시 예에 따른 디스플레이 장치의 제어 방법은 복수의 LF(light field) 영상에 기초하여, 디스플레이 장치의 디스플레이를 시분할로 구동하기 위한 L 영상 및 R 영상을 획득 할 수 있다(S1110). 여기서, 디스플레이는 제1 디스플레이 패널(111-1), 제1 디스플레이 패널(111-1) 상에 배치된 렌즈 어레이 및 렌즈 어레이 상에 배치된 제2 디스플레이 패널(111-2)을 포함할 수 있다. 제1 디스플레이 패널 (111-1) 및 제2 디스플레이 패널(111-2)은 각각 복수의 픽셀을 포함하며, 각 픽셀은 복수의 서브 픽셀을 포함할 수 있다. 일 실시 예로서, 렌즈 어레이는 복수의 단위 렌즈를 포함할 수 있다. 여기서, 각 단위 렌즈는 제1 디스플 레이 패널(111-1)의 짝수 개의 서브 픽셀 상에 배치될 수 있다. 이 경우, L 영상은 제1 디스플레이 패널(111-1)을 구동하기 위한 제1 L 영상 및 제2 디스플레이 패널(111-2)을 구동하기 위한 제2 L 영상을 포함할 수 있다. R 영상은 제1 디스플레이 패널(111-1)을 구동하기 위한 제1 R 영 상 및 제2 디스플레이 패널(111-2)을 구동하기 위한 제2 R 영상을 포함할 수 있다. 구체적인 일 실시 예로서, 복수의 LF 영상이 촬영된 시점에 대한 정보에 기초해, 복수의 LF 영상 중에서 좌측 시점을 나타내는 LF 영상을 추출할 수 있다. 그리고, 디스플레이의 디스플레이 패널(111-1, 111-2)의 수에 대응되는 L 영상을 출력하도록 학습된 제1 팩토리제이션 모델에 좌측 시점을 나타내는 추출된 LF 영상을 입력하 여 L 영상을 획득할 수 있다. 한편, 복수의 LF 영상이 촬영된 시점에 대한 정보에 기초해, 복수의 LF 영상 중에서 우측 시점을 나타내는 LF 영상을 추출할 수 있다. 그리고, 디스플레이의 디스플레이 패널(111-1, 111-2)의 수에 대응되는 R 영상을 출력하도록 학습된 제2 팩토리제이션 모델에 우측 시점을 나타내는 추출된 LF 영상을 입력하여 R 영상을 획득할 수 있다. 여기서, 제1 팩토리제이션 모델은 좌측 시점을 나타내는 LF 영상 및 L 영상을 통해 복원된 LF 영상에 기초한 손 실함수가 기설정된 값 이하가 될 때까지 학습된 인공지능 모델일 수 있다. 또한, 제2 팩토리제이션 모델은 우측 시점을 나타내는 LF 영상 및 R 영상을 통해 복원된 LF 영상에 기초한 손실함수가 기설정된 값 이하가 될 때까지학습된 인공지능 모델일 수 있다. 제1 팩토리제이션 모델 및 제2 팩토리제이션 모델 각각은 DNN(Deep Neural Network) 모델, NTF(Non-negative tensor factorization) 모델 또는 NMF(Non-negative Matric factorization) 모델 중 하나일 수 있다. 그리고, R 영상 중 제1 디스플레이 패널(111-1)을 구동하기 위한 제1 R 영상에 기초하여 L 영상 중 제2 디스플 레이 패널(111-2)을 구동하기 위한 제2 L 영상을 보정할 수 있다. 또한, L 영상 중 제1 디스플레이 패널(111- 1)을 구동하기 위한 제1 L 영상에 기초하여 R 영상 중 제2 디스플레이 패널(111-2)을 구동하기 위한 제2 R 영상 을 보정할 수 있다(S1120). 구체적으로, 제1 R 영상에 기초하여 R 크로스톡 영상을 획득할 수 있다. 또한, 제1 L 영상에 기초하여 L 크로스 톡 영상을 획득할 수 있다. 일 실시 예로서, 제1 R 영상의 픽셀 값에 크로스톡 비율을 곱한 픽셀 값을 갖는 R 크로스톡 영상을 획득할 수 있다. 또한, 제1 L 영상의 픽셀 값에 크로스톡 비율을 곱한 픽셀 값을 갖는 L 크로스톡 영상을 획득할 수 있다. 다른 일 실시 예로서, 제1 R 영상 및 제2 R 영상을 합성한 R 영상(제3 R 영상)을 획득하고, 합성된 R 영상의 픽 셀 값에 크로스톡 비율을 곱한 픽셀 값을 갖는 R 크로스톡 영상을 획득할 수 있다. 또한, 제1 L 영상 및 제2 L 영상을 합성한 L 영상(제3 L 영상)을 획득하고, 합성된 L 영상의 픽셀 값에 크로스톡 비율을 곱한 픽셀 값을 갖 는 L 크로스톡 영상을 획득할 수 있다. 일 예로서, 2개의 영상의 픽셀 값을 최대 픽셀 값(예: 255)으로 나누는 정규화를 수행한 후, 동일한 위치의 픽셀끼리 정규화된 값을 곱하고, 곱해진 값에 최대 픽셀 값을 곱하여 산출 된 값을 픽셀 값으로 하는 방식으로 합성된 영상이 획득될 수 있다. 다만, 이는 일 실시 예일 뿐 다양한 방식으 로 합성된 영상을 획득할 수 있다. 이 경우, R 크로스톡 영상의 픽셀 값에 기초하여 제2 L 영상을 보정할 수 있다. 또한, L 크로스톡 영상의 픽셀 값에 기초하여 제2 R 영상을 보정할 수 있다. 구체적으로, 동일한 위치의 픽셀에 대해 R 크로스톡 영상의 픽셀 값만큼 감소시킨 픽셀 값을 갖도록 제2 L 영상을 보정할 수 있다. 또한, 동일한 위치의 픽셀에 대해 L 크로스톡 영상의 픽셀 값만큼 감소시킨 픽셀 값을 갖도록 제2 R 영상을 보정할 수 있다. 그리고, 제2 L 영상이 보정된 L 영상 및 제2 R 영상이 보정된 R 영상에 기초하여 디스플레이를 시분할로 구동하여 입체 영상을 표시할 수 있다(S1130). 구체적으로, 시간 t1에서 제1 디스플레이 패널(111-1)은 제1 L 영상을 표시하고, 제2 디스플레이 패널(111-2)은 제1 R 영상에 기초하여 보정된 제2 L 영상을 표시할 수 있다. 또한, 시간 t2에서 제1 디스플레이 패널(111-1)은 제1 R 영상을 표시하고, 제2 디스플레이 패널(111-2)은 제1 L 영상에 기초하여 보정된 제2 R 영상을 표시할 수 있다. 여기서 시간 t1에서 시간 t2 사이의 간격은 매우 짧은 시간일 수 있다. 예를 들어, 시간 t1에서 시간 t2 사이의 간격은 1ms 이상 30ms 이하의 범위 내 값일 수 있다. 일 예로서, L 영상 및 R 영상을 획득하는 단계는, 복수의 LF 영상이 시점에 따라 분류된 LF 영상에 기초하여, 시점에 대응되는 L 영상, M 영상 및 R 영상을 획득할 수 있다. 여기서, 보정하는 단계는, M 영상 중 제1 디스플 레이 패널(111-1)을 구동하기 위한 제1 M 영상 및 제1 R 영상에 기초하여, 제2 L 영상을 보정하고, 제1 M 영상 및 제1 L 영상에 기초하여, 제2 R 영상을 보정하고, 제1 L 영상 및 제1 R 영상에 기초하여, M 영상 중에서 제2 디스플레이 패널(111-2)을 구동하기 위한 제2 M 영상을 보정할 수 있다. 여기서, 입체 영상을 표시하는 단계는, 제2 L 영상이 보정된 L 영상, 제2 M 영상이 보정된 M 영상 및 제2 R 영상이 보정된 R 영상에 기초하여, 디스플 레이를 시분할로 구동하여, 입체 영상을 표시할 수 있다. 본 개시의 다양한 실시 예들은 기기(machine)(예: 컴퓨터)로 읽을 수 있는 저장 매체(machine-readable storage media에 저장된 명령어를 포함하는 소프트웨어로 구현될 수 있다. 기기는 저장 매체로부터 저장된 명령 어를 호출하고, 호출된 명령어에 따라 동작이 가능한 장치로서, 개시된 실시 예들에 따른 전자 장치(예: 디스플 레이 장치)를 포함할 수 있다. 상기 명령이 프로세서에 의해 실행될 경우, 프로세서가 직접, 또는 상기 프 로세서의 제어 하에 다른 구성요소들을 이용하여 상기 명령에 상기하는 기능을 수행할 수 있다. 명령은 컴파일 러 또는 인터프리터에 의해 생성 또는 실행되는 코드를 포함할 수 있다. 기기로 읽을 수 있는 저장매체는 비일 시적(non-transitory) 저장매체의 형태로 제공될 수 있다. 여기서, '비일시적'은 저장매체가 신호(signal)를 포 함하지 않으며 실재(tangible)한다는 것을 의미할 뿐 데이터가 저장매체에 반영구적 또는 임시적으로 저장됨을 구분하지 않는다. 다양한 실시 예들에 따른 방법은 컴퓨터 프로그램 제품(computer program product)에 포함되어 제공될 수 있다. 컴퓨터 프로그램 제품은 상품으로서 판매자 및 구매자 간에 거래될 수 있다. 컴퓨터 프로그램 제품은 기기로 읽 을 수 있는 저장 매체(예: compact disc read only memory (CD-ROM))의 형태로, 또는 어플리케이션 스토어(예: 플레이 스토어TM)를 통해 온라인으로 배포될 수 있다. 온라인 배포의 경우에, 컴퓨터 프로그램 제품의 적어도 일부는 제조사의 서버, 어플리케이션 스토어의 서버, 또는 중계 서버의 메모리와 같은 저장 매체에 적어도 일시 저장되거나, 임시적으로 생성될 수 있다. 다양한 실시 예들에 따른 구성 요소(예: 모듈 또는 프로그램) 각각은 단수 또는 복수의 개체로 구성될 수 있으 며, 전술한 상기 서브 구성 요소들 중 일부 서브 구성 요소가 생략되거나, 또는 다른 서브 구성 요소가 다양한 실시 예에 더 포함될 수 있다. 대체적으로 또는 추가적으로, 일부 구성 요소들(예: 모듈 또는 프로그램)은 하나 의 개체로 통합되어, 통합되기 이전의 각각의 상기 구성 요소에 의해 수행되는 기능을 동일 또는 유사하게 수행 할 수 있다. 다양한 실시 예들에 따른, 모듈, 프로그램 또는 다른 구성 요소에 의해 수행되는 동작들은 순차적, 병렬적, 반복적 또는 휴리스틱하게 실행되거나, 적어도 일부 동작이 다른 순서로 실행되거나, 생략되거나, 또는 다른 동작이 추가될 수 있다."}
{"patent_id": "10-2020-0154762", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 개시의 일 실시 예에 따른 디스플레이 장치의 구조를 설명하기 위한 단면도이다. 도 2a는 본 개시의 일 실시 예에 따른 디스플레이 장치의 시분할 구동을 설명하기 위한 도면이다. 도 2b는 본 개시의 일 실시 예에 따른 크로스톡(Crosstalk)을 설명하기 위한 도면이다. 도 3은 본 개시의 일 실시 예에 따른 디스플레이 장치가 복수의 LF 영상을 이용해 보정된 영상을 획득하는 방법 을 설명하기 위한 도면이다. 도 4는 본 개시의 일 실시 예에 따른 L 영상 및 R 영상을 획득하는 방법을 설명하기 위한 도면이다. 도 5a 내지 5c는 본 개시의 일 실시 예에 따른 L 영상 및 R 영상을 보정하는 방법을 설명하기 위한 도면이다. 도 6은 본 개시의 일 실시 예에 따른 디스플레이 장치가 보정된 L 영상 및 R 영상을 표시할 경우에 관측되는 입 체 영상을 설명하기 위한 도면이다. 도 7a 및 도 7b는 본 개시의 일 실시 예에 따른 보정 전과 보정 후의 영상을 비교하기 위한 도면이다. 도 8은 본 개시의 일 실시 예에 따른 팩토리제이션 모델을 학습하는 방법을 설명하기 위한 도면이다.도 9는 본 개시의 일 실시 예에 따른 분할된 시점의 수에 따라 팩토리제이션 모델을 학습하는 방법을 설명하기 위한 도면이다. 도 10은 본 개시의 일 실시 예에 따른 디스플레이 장치를 설명하기 위한 블록도이다. 도 11은 본 개시의 일 실시 예에 따른 흐름도를 설명하기 위한 도면이다."}
