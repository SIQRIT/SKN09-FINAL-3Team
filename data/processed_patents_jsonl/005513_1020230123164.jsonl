{"patent_id": "10-2023-0123164", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2025-0040788", "출원번호": "10-2023-0123164", "발명의 명칭": "로봇의 공간 분석 시스템 및 방법", "출원인": "한국전자기술연구원", "발명자": "박민철"}}
{"patent_id": "10-2023-0123164", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "로봇에 장착되는 라이다;로봇에 장착되는 카메라; 및상기 라이다로부터 생성되는 라이다 데이터를 이용하여 공간 지도를 작성하고 공간 내에서 로봇의 위치를 추정하는 공간 분석부;를 포함하며,상기 공간 분석부는,상기 카메라로부터 생성되는 카메라 데이터를 이용해 상기 라이다 데이터 중 연기를 감지한 것에 의한 라이다데이터를 필터링하는 것을 특징으로 하는 로봇의 공간 분석 시스템."}
{"patent_id": "10-2023-0123164", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 공간 분석부는,상기 카메라 데이터에서 특정 위치에 연기가 없는 것으로 확인되면, 대응되는 위치의 상기 라이다 데이터를 공간 지도의 작성에 사용하고,상기 카메라 데이터에서 특정 위치에 연기가 있는 것으로 확인되면, 대응되는 위치의 상기 라이다 데이터를 공간 지도 작성에 사용하지 않는 것을 특징으로 하는 로봇의 공간 분석 시스템."}
{"patent_id": "10-2023-0123164", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,상기 공간 분석부는,상기 카메라 데이터에서 특정 위치와 다른 위치의 선명도 비교를 통해 연기의 유무를 판단하는 것을 특징으로하는 로봇의 공간 분석 시스템."}
{"patent_id": "10-2023-0123164", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서,상기 다른 위치는,로봇을 기준으로 상기 특정 위치보다 더 먼 위치인 것을 특징으로 하는 로봇의 공간 분석 시스템."}
{"patent_id": "10-2023-0123164", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제2항에 있어서,상기 공간 분석부는,연기가 없는 이미지와 연기가 있는 이미지의 학습을 통해 연기의 유무를 판단하는 것을 특징으로 하는 로봇의공간 분석 시스템.공개특허 10-2025-0040788-3-청구항 6 제1항에 있어서,로봇에 장칙되는 3D 스캐너를 더 포함하며,상기 공간 분석부는,필터링된 라이다 데이터, 상기 카메라 데이터 및 상기 3D 스캐너로부터 생성된 스캐너 데이터를 이용하여 공간지도를 작성하는 것을 특징으로 하는 로봇의 공간 분석 시스템."}
{"patent_id": "10-2023-0123164", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6항에 있어서,상기 공간 분석부는,필터링된 라이다 데이터와 상기 카메라 데이터를 입력으로 하고 상기 스캐너 데이터를 정답 데이터로 하여 학습함으로써 고밀도화 모델을 생성하는 제1 학습부,상기 고밀도화 모델이 저장되는 제1 모델 저장부, 및상기 고밀도화 모델에 상기 필터링된 라이다 데이터와 상기 카메라 데이터를 입력하여 추정 스캐너 데이터를 생성하는 제1 추정부를 구비하는 것을 특징으로 하는 로봇의 공간 분석 시스템."}
{"patent_id": "10-2023-0123164", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1항에 있어서,상기 공간 분석부는,상기 라이다 데이터 값이 생성되지 않은 지점인 블랭크 지점의 추정 라이다 데이터를 생성하는 추정 라이다 데이터 생성부를 구비하는 것을 특징으로 하는 로봇의 공간 분석 시스템."}
{"patent_id": "10-2023-0123164", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제7항에 있어서,상기 추정 라이다 데이터 생성부는,상기 블랭크 지점의 생성 이전 및/또는 이후 시간에 생성된 라이다 데이터를 이용하여 상기 추정 라이다 데이터를 생성하는 것을 특징으로 하는 로봇의 공간 분석 시스템."}
{"patent_id": "10-2023-0123164", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9항에 있어서,상기 추정 라이다 데이터 생성부는,T 번째 라이다 데이터를 정답 데이터로 하여 T-1 내지 T-n(n은 자연수) 번째 라이다 데이터 및/또는 T+1 내지T+m(m은 자연수) 번째 라이다 데이터를 학습함으로써 상기 추정 라이다 데이터 생성을 위한 추정 모델을 생성하는 제2 학습부,상기 추정 모델이 저장되는 제2 모델 저장부, 및상기 라이다로부터 t 번째 생성된 데이터에 상기 블랭크 지점이 포함된 경우, 상기 추정 모델에 t-1 내지 t-n(n공개특허 10-2025-0040788-4-은 자연수) 번째 라이다 데이터 및/또는 t+1 내지 t+m(m은 자연수) 번째 라이다 데이터를 입력하여 상기 추정라이다 데이터를 생성하는 제2 추정부를 구비하는 것을 특징으로 하는 로봇의 공간 분석 시스템."}
{"patent_id": "10-2023-0123164", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제10항에 있어서,상기 제2 추정부는,상기 라이다로부터 연속되어 생성된 데이터 각각에 상기 블랭크 지점이 포함된 경우, 생성된 추정 라이다 데이터를 포함하는 라이다 데이터를 상기 추정 모델에 입력하여 다시 추정 라이다 데이터를 생성하는 것을 특징으로하는 로봇의 공간 분석 시스템."}
{"patent_id": "10-2023-0123164", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제9항에 있어서,상기 추정 라이다 데이터 생성부는,상기 블랭크 지점의 생성 이전 및/또는 이후 시간에 생성된 상기 라이다 데이터와 상기 카메라 데이터, 및 상기블랭크 지점 생성시의 카메라 데이터를 이용하여 상기 추정 라이다 데이터를 생성하는 것을 특징으로 하는 로봇의 공간 분석 시스템."}
{"patent_id": "10-2023-0123164", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "로봇에 장착되는 라이다와 카메라로부터 라이다 데이터와 카메라 데이터를 생성하는 데이터 생성단계;상기 카메라 데이터를 이용해 상기 라이데 데이터 중 연기를 감지한 것에 의한 라이다 데이터를 필터링하는 데이터 필터링단계; 및상기 데이터 필터링단계에서 필터링된 라이다 데이터를 이용하여 공간 지도를 작성하고 공간 내에서 로봇의 위치를 추정하는 공간 분석단계;를 포함하는 로봇의 공간 분석 방법."}
{"patent_id": "10-2023-0123164", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제13항에 있어서,상기 데이터 생성단계와 상기 데이터 필터링단계 사이에 진행되는 것으로서,상기 라이다 데이터에서 라이다 데이터 값이 생성되지 않은 지점인 블랭크 지점이 포함되어 있는지 여부를 확인하는 블랭크 지점 확인단계; 및상기 블랭크 지점의 생성 이전 및/또는 이후 시간에 생성된 라이다 데이터를 이용하여 상기 블랭크 지점의 추정라이다 데이터를 생성하는 라이다 데이터 추정단계;를 더 포함하는 것을 특징으로 하는 로봇의 공간 분석 방법."}
{"patent_id": "10-2023-0123164", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 로봇의 공간 분석 시스템 및 방법에 관한 것으로서, 본 발명에 따른 로봇의 공간 분석 시스템은, 로봇 에 장착되는 라이다; 로봇에 장착되는 카메라; 및 상기 라이다로부터 생성되는 라이다 데이터를 이용하여 공간 지도를 작성하고 공간 내에서 로봇의 위치를 추정하는 공간 분석부;를 포함하며, 상기 공간 분석부는, 상기 카메 라로부터 생성되는 카메라 데이터를 이용해 상기 라이다 데이터 중 연기를 감지한 것에 의한 라이다 데이터를 필 터링하는 것을 특징으로 한다."}
{"patent_id": "10-2023-0123164", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 로봇의 공간 분석 시스템 및 방법에 관한 것으로서, 보다 상세하게는 비가시 환경에서 로봇이 위치하 는 공간과 그 공간 내에서의 로봇 위치를 정확하게 파악하는 것이 가능한 로봇의 공간 분석 시스템 및 방법에 관한 것이다."}
{"patent_id": "10-2023-0123164", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "사람이 쉽게 접근하기 어려운 환경에서의 작업에 로봇을 이용하고자 하는 시도가 계속되고 있다. 로봇의 작업이 이루어지는 공간(환경)에 대한 정보가 없는 경우가 많기 때문에 로봇은 예를 들어, SLAM(Simultaneous Localization and Mapping) 기술을 활용하여 미지의 공간 내에서 작업을 진행할 수 있다. 그런데 연기나 안개에 의해 시야 확보가 어려운 경우, 로봇이 공간에 대한 정보 및 공간 내에서 로봇의 위치에 대한 정보를 얻는 것이 쉽지 않다. 비가시 환경에서 공간에 대한 정보 등을 얻기 위하여 계측에 서로 다른 파장대를 이용하는 센서를 결합하는 방 법을 사용할 수 있다. 예를 들어, 레이더 센서와 라이다 센서를 결합하여 비가시 환경에서 공간에 대한 정보 등을 얻을 수 있다. 구체 적으로, 레이더의 측정값과 라이다의 측정값을 비교하여 서로 다른 경우에 라이다가 연기나 안개를 인지한 것으 로 판단하고 레이더의 측정값을 공간을 파악하기 위한 데이터로 활용할 수 있다. 그런데 레이더 센서의 해상도가 라이다 센서의 해상도보다 낮기 때문에 라이다가 연기 등을 인지한 것을 부분적 으로만 판단할 수 있고, 결과적으로 공간에 대한 정보 등을 정확하게 얻는 것이 쉽지 않다. 선행기술문헌 특허문헌 (특허문헌 0001) KR 10-2069094 B1"}
{"patent_id": "10-2023-0123164", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "따라서, 본 발명의 목적은 이와 같은 종래의 문제점을 해결하기 위한 것으로서, 연기 등에 의한 비가시 환경에 서도 공간에 대한 정보 등을 정확하게 파악하는 것이 가능한 로봇의 공간 분석 시스템 및 방법을 제공함에 있다. 본 발명이 해결하고자 하는 과제는 위에서 언급한 과제로 제한되지 않으며, 언급되지 않은 또 다른 과제들은 아 래의 기재로부터 당업자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2023-0123164", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기 목적은, 본 발명에 따라, 로봇에 장착되는 라이다; 로봇에 장착되는 카메라; 및 상기 라이다로부터 생성되 는 라이다 데이터를 이용하여 공간 지도를 작성하고 공간 내에서 로봇의 위치를 추정하는 공간 분석부;를 포함 하며, 상기 공간 분석부는, 상기 카메라로부터 생성되는 카메라 데이터를 이용해 상기 라이다 데이터 중 연기를 감지한 것에 의한 라이다 데이터를 필터링하는 것을 특징으로 하는 로봇의 공간 분석 시스템에 의해 달성된다. 상기 공간 분석부는, 상기 카메라 데이터에서 특정 위치에 연기가 없는 것으로 확인되면, 대응되는 위치의 상기 라이다 데이터를 공간 지도의 작성에 사용하고, 상기 카메라 데이터에서 특정 위치에 연기가 있는 것으로 확인 되면, 대응되는 위치의 상기 라이다 데이터를 공간 지도 작성에 사용하지 않을 수 있다. 상기 공간 분석부는, 상기 카메라 데이터에서 특정 위치와 다른 위치의 선명도 비교를 통해 연기의 유무를 판단 할 수 있다. 상기 다른 위치는, 로봇을 기준으로 상기 특정 위치보다 더 먼 위치일 수 있다. 상기 공간 분석부는, 연기가 없는 이미지와 연기가 있는 이미지의 학습을 통해 연기의 유무를 판단할 수 있다. 본 발명에 의한 로봇의 공간 분석 시스템은, 로봇에 장칙되는 3D 스캐너를 더 포함하며, 상기 공간 분석부는, 필터링된 라이다 데이터, 상기 카메라 데이터 및 상기 3D 스캐너로부터 생성된 스캐너 데이터를 이용하여 공간 지도를 작성할 수 있다. 상기 공간 분석부는, 필터링된 라이다 데이터와 상기 카메라 데이터를 입력으로 하고 상기 스캐너 데이터를 정 답 데이터로 하여 학습함으로써 고밀도화 모델을 생성하는 제1 학습부, 상기 고밀도화 모델이 저장되는 제1 모 델 저장부, 및 상기 고밀도화 모델에 상기 필터링된 라이다 데이터와 상기 카메라 데이터를 입력하여 추정 스캐 너 데이터를 생성하는 제1 추정부를 구비할 수 있다. 상기 공간 분석부는, 상기 라이다 데이터 값이 생성되지 않은 지점인 블랭크 지점의 추정 라이다 데이터를 생성 하는 추정 라이다 데이터 생성부를 구비할 수 있다. 상기 추정 라이다 데이터 생성부는, 상기 블랭크 지점의 생성 이전 및/또는 이후 시간에 생성된 라이다 데이터 를 이용하여 상기 추정 라이다 데이터를 생성할 수 있다. 상기 추정 라이다 데이터 생성부는, T 번째 라이다 데이터를 정답 데이터로 하여 T-1 내지 T-n(n은 자연수) 번 째 라이다 데이터 및/또는 T+1 내지 T+m(m은 자연수) 번째 라이다 데이터를 학습함으로써 상기 추정 라이다 데 이터 생성을 위한 추정 모델을 생성하는 제2 학습부; 상기 추정 모델이 저장되는 제2 모델 저장부; 및 상기 라 이다로부터 t 번째 생성된 데이터에 상기 블랭크 지점이 포함된 경우, 상기 추정 모델에 t-1 내지 t-n(n은 자연 수) 번째 라이다 데이터 및/또는 t+1 내지 t+m(m은 자연수) 번째 라이다 데이터를 입력하여 상기 추정 라이다 데이터를 생성하는 제2 추정부;를 구비할 수 있다. 상기 제2 추정부는, 상기 라이다로부터 연속되어 생성된 데이터 각각에 상기 블랭크 지점이 포함된 경우, 생성 된 추정 라이다 데이터를 포함하는 라이다 데이터를 상기 추정 모델에 입력하여 다시 추정 라이다 데이터를 생 성할 수 있다. 상기 추정 라이다 데이터 생성부는, 상기 블랭크 지점의 생성 이전 및/또는 이후 시간에 생성된 상기 라이다 데 이터와 상기 카메라 데이터, 및 상기 블랭크 지점 생성시의 카메라 데이터를 이용하여 상기 추정 라이다 데이터 를 생성할 수 있다. 본 발명의 다른 실시예에 의하면, 로봇에 장착되는 라이다와 카메라로부터 라이다 데이터와 카메라 데이터를 생 성하는 데이터 생성단계; 상기 카메라 데이터를 이용해 상기 라이데 데이터 중 연기를 감지한 것에 의한 라이다 데이터를 필터링하는 데이터 필터링단계; 및 상기 데이터 필터링단계에서 필터링된 라이다 데이터를 이용하여 공간 지도를 작성하고 공간 내에서 로봇의 위치를 추정하는 공간 분석단계;를 포함하는 로봇의 공간 분석 방법 이 제공된다. 본 발명에 의한 로봇의 공간 분석 방법은, 상기 데이터 생성단계와 상기 데이터 필터링단계 사이에 진행되는 것으로서, 상기 라이다 데이터에서 라이다 데이터 값이 생성되지 않은 지점인 블랭크 지점이 포함되어 있는지 여 부를 확인하는 블랭크 지점 확인단계; 및 상기 블랭크 지점의 생성 이전 및/또는 이후 시간에 생성된 라이다 데 이터를 이용하여 상기 블랭크 지점의 추정 라이다 데이터를 생성하는 라이다 데이터 추정단계;를 더 포함할 수 있다."}
{"patent_id": "10-2023-0123164", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명의 로봇의 공간 분석 시스템에 의하면, 연기 등이 존재하는 환경에서도 정확하고 자세하게 공간 지도를 작성하는 것이 가능하다. 이에 따라, 로봇이 비가시 환경에서도 주어진 임무를 원활하게 수행할 수 있다. 공간 분석을 위해 카메라 데이터와 라이다 데이터 외에 3D 스캐너 데이터를 인공지능으로 학습하여 이용하는 경 우, 실시간으로 보다 정확하고 밀도 높은 공간 지도를 작성하는 것이 가능하다. 그리고 라이다 데이터 값이 일부 생성되지 않은 경우에도 인공지능을 이용하여 라이다 데이터 값을 추정함으로 써 공간 분석의 정확성을 높일 수 있다."}
{"patent_id": "10-2023-0123164", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하에서는 본 발명의 구체적인 실시예에 대하여 도면을 참고하여 자세하게 설명하도록 한다. 도 1에는 본 발명에 의한 로봇의 공간 분석 시스템의 개략적인 구성도가 도시되어 있다. 본 발명에 의한 로봇의 공간 분석 시스템은 크게, 라이다, 카메라 및 공간 분석부를 포함하여 이루어진다. 본 발명에 의한 로봇의 공간 분석 시스템의 구성 중 적어도 라이다와 카메라는 로봇에 장착되어, 이 동하는 로봇을 위해 본 발명에 의한 로봇의 공간 분석 시스템이 실시간으로 동작하도록 할 수 있다. 본 발명 이 적용되는 로봇에는 2족 보행 로봇, 4족 보행 로봇, 자율주행자동차 등 이동 가능한 모든 로봇이 포함될 수 있다. 라이다(LiDar)는 레이저 펄스를 발사하고, 그 빛이 주위의 대상 물체에서 반사되어 돌아오는 것을 받아 물 체까지의 거리 등을 측정함으로써 로봇이 위치하는 공간을 파악한다. 라이다는 예를 들어, 로봇의 상단에 장착될 수 있다. 카메라는 로봇 주변의 이미지를 촬영함으로써 로봇이 위치하는 공간을 파악한다. 카메라는 라이다 와 마찬가지로 로봇의 상단에 장착될 수 있으며, 로봇의 사방을 촬영하도록 형성될 수 있다. 공간 분석부는 센싱 데이터 저장부, 필터링부 및 분석부를 구비할 수 있다. 센싱 데이터 저장부에는 라이다로부터 생성되는 라이다 데이터와 카메라로부터 생성되는 카메라 데 이터가 저장된다. 라이다 데이터와 카메라 데이터는 시간적, 공간적으로 동기화되어 저장될 수 있다. 라이다 데 이터와 카메라 데이터는 서로 상이한 해상도를 가지므로 공간적 동기화시 한 지점을 나타내는 라이다 데이터에 해당 지점을 포함하는 부분-면적을 가짐-을 대응시킬 수 있다. 필터링부는 카메라 데이터를 이용해 라이다 데이터 중 연기 등을 감지한 것에 의한 라이다 데이터를 필터링 한다. 라이다는 연기나 안개를 감지하지만 연기 등과 사물(건물의 구조체 포함)을 구분하지 못하기 때문에 연기 등이 있는 환경에서 라이다 데이터를 그대로 사용하는 경우, 공간 지도를 정확하게 작성할 수 없다. 따라 서, 연기 등과 사물을 구분할 수 있는 카메라 데이터를 이용해 라이다 데이터를 필터링한다. 분석부는 필터링된 라이다 데이터를 이용하여 공간 지도를 작성하고 공간 내에서 로봇의 위치를 추정한다. 즉, SLAM(Simultaneous Localization and Mapping)을 수행한다. 이러한 본 발명의 로봇의 공간 분석 시스템에 의하면, 공간 지도를 비교적 자세하게 작성할 수 있는 라이다 데이터를 이용하되 카메라 데이터를 이용하여 공간 지도 작성에 불필요한 데이터를 필터링함으로써 연기 등이 존재하는 환경에서도 정확하고 자세하게 공간 지도를 작성하는 것이 가능하다. 이에 따라, 로봇이 비가시 환경에서도 주어진 임무를 원활하게 수행할 수 있다. 공간 분석부의 필터링부는 보다 구체적으로 아래와 같이 동작한다. 즉, 카메라 데이터에서 특정 위치에 연기(안개 포함)가 없는 것으로 확인되면 대응되는 위치의 라이다 데이터를 공간 지도 작성에 사용하고, 특정 위치에 연기가 있는 것으로 확인되면 대응되는 위치의 라이다 데이터를 공간 지도 작성에 사용하지 않는다. 참고로, 특정 위치라 함은 연기 여부의 확인 대상이 되는 위치이다. 상기한 바와 같이, 라이다 데이터와 카메라 데이터는 공간적으로 동기화될 수 있으므로, 카메라 데이터에서 연 기가 있는 것이 확인되면 정확하게 연기에 의해 발생한 라이다 데이터를 공간 지도 작성에서 제외하는 것이 가 능하다. 필터링부는 예를 들어, 카메라 데이터에서 특정 위치와 다른 위치의 선명도 비교를 통해 연기의 유무를 판 단할 수 있다. 연기는 보통 흰색이나 회색을 띠며 공기 중에 흩어져 형성되기 때문에 부옇게 보이게 되며, 카메라가 촬영 한 이미지에서 연기가 있는 부분은 전체적으로 선명도가 낮아지게 된다. 이에 따라, 연기가 있는 부분의 선명도 가 연기가 없는 부분의 선명도 보다 낮다. 결과적으로, 특정 위치의 선명도가 다른 위치보다 낮은 경우, 특정 위치에 연기가 있는 것으로 판단할 수 있다. 다른 위치는 로봇을 기준으로 특정 위치보다 더 먼 위치일 수 있다. 연기는 로봇과 벽(또는 사물) 사이의 공간에 위치할 것이고, 보통 로봇과 연기 사이의 거리보다 로봇과 벽 사이 의 거리가 더 길 것이다. 따라서, 특정 위치의 연기 유무를 판단하는 경우, 라이다 데이터 상에서 특정 위치보다 더 멀리 위치하여 특정 위치보다 벽일 가능성이 상대적으로 높은 다른 위치의 선명도를, 특정 위치의 선명도와 비교한다. 라이다 데이터 상에서 가장 먼 위치는 벽이라고 가정할 수 있다. 필터링부는 인공지능 학습을 통해 연기의 유무를 판단하는 것도 가능하다. 즉, 연기가 없는 카메라 이미지 다수와 연기가 있는 카메라 이미지 다수를 학습시켜 필터링 모델을 만든 후 실 시간으로 카메라에서 촬영한 카메라 데이터를 필터링 모델에 입력하여 연기의 유무를 확인할 수 있다. 본 발명에 의한 로봇의 공간 분석 시스템은 3D 스캐너를 더 포함할 수 있다. 도 2에는 이러한 경우에 대 한 설명도가 도시되어 있다. 3D 스캐너는 라이다 및 카메라와 마찬가지로 로봇에 장착되며, 고밀도의 공간 지도를 작성하는 역 할을 한다. 카메라 데이터를 생성하는 카메라는 3D 스캐너의 일부분을 구성할 수 있다. 즉, 3D 스캐너 는 카메라 데이터를 NeRF(Neural Radiance Field) 딥러닝 모델에 적용하여 고밀도의 공간 지도를 작성할 수 있다. 본 발명에 의한 로봇의 공간 분석 시스템이 3D 스캐너를 더 포함하는 경우, 3D 스캐너로부터 생성된 스캐너 데이터, 필터링된 라이다 데이터 및 카메라 데이터를 이용하여 실시간으로 고밀도의 정확한 공간 지도를 작성하는 것이 가능하다. 3D 스캐너에 의한 스캐너 데이터는 밀도는 높은 반면 정확성과 실시간성이 떨어질 수 있는데, 스캐너 데이터 외에 필터링된 라이다 데이터와 카메라 데이터를 이용함으로써 고밀도의 정확한 공간 지도를 실시간으로 작성할 수 있다. 구체적으로, 공간 분석부는 제1 학습부, 제1 모델 저장부 및 제1 추정부를 더 구비할 수 있다. 제1 학습부는 도 3에 도시되어 있는 바와 같이, 필터링된 라이다 데이터와 카메라 데이터를 입력으로 하고 스캐너 데이터를 정답 데이터로 하여 학습함으로써 고밀도화 모델을 생성한다. 참고로, 도 3에서는 스캐너 데이 터가 나타내는 공간이 필터링된 라이다 데이터 및 카메라 데이터가 나타내는 공간과 상이하게 표현되었으나, 필 터링된 라이다 데이터, 카메라 데이터 및 스캐너 데이터는 모두 동일한 공간에 대한 것이어야 함은 당연하다. 학습은 필터링된 라이다 데이터와 카메라 데이터를 이용해 추론되는 데이터가 스캐너 데이터와 일정치 이상의 유사성을 가질 때까지 진행될 수 있다. 제1 학습부는 딥러닝 기술을 이용해 학습을 진행할 수 있다.제1 모델 저장부에는 제1 학습부에서 만들어진 고밀도화 모델이 저장된다. 제1 추정부는 도 4에 도시되어 있는 바와 같이, 고밀도화 모델에 실시간으로 생성되는 필터링된 라이다 데 이터와 카메라 데이터를 입력하여 추정 스캐너 데이터를 생성한다. 추정 스캐너 데이터는 3D 스캐너에 의해 직접 생성된 스캐너 데이터는 아니지만 스캐너 데이터와 마찬가지로 고밀도 특성을 가지며 라이다 데이터 및 카 메라 데이터와 마찬가지로 정확성이 높고 실시간으로 형성되는 특성을 갖는다. 공간 분석부는 추정 라이다 데이터 생성부를 구비할 수 있다. 라이다 데이터는 반사되어 되돌아오는 레이저 펄스에 의해 생성되기 때문에 레이저 펄스의 반사 특성에 따라 라 이다에서 레이저 펄스가 수광되지 않는 경우 일부 지점에서 라이다 데이터 값이 생성되지 않을 수 있다. 추정 라이다 데이터 생성부는 라이다 데이터 값이 생성되지 않은 지점인 블랭크 지점의 추정 라이다 데이터 를 생성하는 역할을 한다. 추정 라이다 데이터에 의해 일부 지점의 라이다 데이터 값이 생성되지 않은 경우에도 정확한 공간 지도를 작성 하는 것이 가능하다. 추정 라이다 데이터 생성부는 블랭크 지점의 생성 이전 및/또는 이후 시간에 생성된 라이다 데이터를 이용 하여 추정 라이다 데이터를 생성할 수 있다. 보다 구체적으로, 추정 라이다 데이터 생성부는 제2 학습부(37a), 제2 모델 저장부(37b) 및 제2 추정부 (37c)를 구비할 수 있다. 제2 학습부(37a)는 도 5에 도시되어 있는 바와 같이, T 번째 라이다 데이터를 정답 데이터로 하여 T-1 내지 T- n(n은 자연수) 번째 라이다 데이터 및/또는 T+1 내지 T+m(m은 자연수) 번째 라이다 데이터를 학습함으로써 상기 추정 라이다 데이터 생성을 위한 추정 모델을 생성한다. 학습은 T 번째 라이다 데이터와 추론되는 데이터가 일 정치 이상의 유사성을 가질 때까지 진행될 수 있다. 제2 학습부(37a)는 딥러닝 기술을 이용해 학습을 진행할 수 있다. 도 5에서는 예시적으로 T-1 내지 T-n 번째 라이다 데이터를 학습하여 추정 모델을 생성하는 경우를 도시 하였다. 제2 모델 저장부(37b)에는 제2 학습부(37a)에서 생성된 추정 모델이 저장된다. 제2 추정부(37c)는 도 6에 도시되어 있는 바와 같이, 추정 모델에 실시간으로 생성되는 라이다 데이터를 입력하 여 추정 라이다 데이터를 생성한다. 제2 추정부(37c)는 라이다로부터 t 번째 생성된 데이터(현재 생성된 데 이터)에 블랭크 지점이 포함된 경우에 동작할 수 있으며, 추정 모델에 t-1 내지 t-n 번째 라이다 데이터 및/또 는 t+1 내지 t+m 번째 라이다 데이터를 입력하여 추정 라이다 데이터를 생성할 수 있다. 제2 학습부(37a)에서 추정 모델 생성에 T-1 내지 T-n 번째 라이다 데이터를 사용한 경우 제2 추정부(37c)에서도 추정 모델에 t-1 내 지 t-n 번째 라이다 데이터를 입력하여 추정 라이다 데이터를 생성하고, 제2 학습부(37a)에서 추정 모델 생성에 T+1 내지 T+m 번째 라이다 데이터를 사용한 경우 제2 추정부(37c)에서도 추정 모델에 t+1 내지 t+m 번째 라이다 데이터를 입력하여 추정 라이다 데이터를 생성한다. 그리고 제2 학습부(37a)에서 추정 모델 생성에 T-1 내지 T- n 번째 라이다 데이터 및 T+1 내지 T+m 번째 라이다 데이터를 사용한 경우 제2 추정부(37c)에서도 추정 모델에 T-1 내지 T-n 번째 라이다 데이터 및 T+1 내지 T+m 라이다 데이터를 입력하여 추정 라이다 데이터를 생성한다. 추정 라이다 데이터 생성의 실시간성을 높이기 위하여 추정 모델의 생성에 T-1 내지 T-n 번째 라이다 데이터를 사용하는 것이 바람직하다. 제2 추정부(37c)는 라이다로부터 연속되어 생성된 데이터 각각에 블랭크 지점이 포함된 경우, 생성된 추정 라이다 데이터를 포함하는 라이다 데이터를 추정 모델에 입력하여 다시 추정 라이다 데이터를 생성할 수 있다. 즉, 예를 들어, t 번째, t+1 번째 라이다 데이터에 블랭크 지점이 포함된 경우, t-1 내지 t-n 번째 라이다 데이 터를 추정 모델에 입력하여 t 번째 추정 라이다 데이터를 생성하고, 다시 t 번째 추정 라이다 데이터, t-1 내지 t-(n-1) 번째 라이다 데이터를 추정 모델에 입력하여 t+1 번째 추정 라이다 데이터를 생성한다. 이에 따라, 연속되어 생성된 라이다 데이터에 블랭크 지점이 포함된 경우에도 추정 라이다 데이터를 생성하는 것이 가능하다.추정 라이다 데이터 생성부는 블랭크 지점의 생성 이전 및/또는 이후 시간에 생성된 라이다 데이터 외에 블 랭크 지점의 생성시의 카메라 데이터와 블랭크 지점의 생성 이전 및/또는 이후 시간에 생성된 카메라 데이터를 이용하여 추정 라이다 데이터를 생성할 수 있다. 이 경우, 추정 라이다 데이터를 보다 정확하게 추론하는 것이 가능하고, 결과적으로 공간 분석부에서 보다 정확하게 공간 지도를 작성할 수 있다. 추정 라이다 데이터의 생성에 카메라 데이터를 더 이용하는 경우, 라이다 데이터와 카메라 데이터가 시간적, 공 간적으로 동기화되어 구축된 데이터 셋을 사용할 수 있다. 구체적으로, 제2 학습부(37a)에서는 도 7에 도시되어 있는 바와 같이, T 번째 데이터 셋(라이다 데이터와 카메라 데이터)을 정답 데이터로 하고, T 번째 카메라 데이 터와 T-1 내지 T-n 번째 데이터 셋 및/또는 T+1 내지 T+m 번째 데이터 셋을 학습함으로써 추정 모델을 생성한다. 그리고 제2 추정부(37c)에서는 도 8에 도시되어 있는 바와 같이, t 번째 생성된 데이터에 블랭크 지 점이 포함된 경우, 추정 모델에 t 번째 카메라 데이터와 t-1 내지 t-n 번째 데이터 셋 및/또는 t+1 내지 t+m 번 째 데이터 셋을 입력하여 t 번째 추정 데이터 셋을 생성할 수 있다. 참고로, t 번째 카메라 데이터는 공간적으 로는 라이다 데이터에서 블랭크 지점에 대응되는 위치 그리고 블랭크 지점에 대응되는 위치 주변부에 대한 데이 터일 수 있다. 도 7에서는 예시적으로 T 번째 카메라 데이터와 T-1 내지 T-n 번째 데이터 셋을 학습하여 추정 모델을 생성한 경우를 도시하였다. 이하에서는 본 발명에 의한 로봇의 공간 분석 방법에 대해 설명한다. 본 발명에 의한 로봇의 공간 분석 방법에 대해 설명하면서 본 발명에 의한 로봇의 공간 분석 시스템의 설명시 언급한 사항에 대해서는 자세한 설명을 생략할 수 있다. 도 9에는 본 발명에 의한 로봇의 공간 분석 방법의 순서도가 도시되어 있다. 본 발명에 의한 로봇의 공간 분석 방법은 데이터 생성단계(S10), 데이터 필터링단계(S40) 및 공간 분석단계 (S50)를 포함하여 이루어진다. 데이터 생성단계(S10)에서는 로봇에 장착되는 라이다와 카메라로부터 라이다 데이터와 카메라 데이터를 생성한다. 생성된 라이다 데이터와 카메라 데이터는 시간적, 공간적으로 동기화되어 저장될 수 있다. 데이터 필터링단계(S40)에서는 카메라 데이터를 이용하여 라이다 데이터 중 연기를 감지한 것에 의한 라이다 데 이터를 필터링한다. 즉, 연기가 있는 환경에서는 라이다 데이터가 공간 지도 작성에 필요한 사물(벽체 등 건물 의 구조체 포함)을 감지하는 것 외에도 공간 지도 작성에 불필요한 연기를 감지할 수 있기 때문에 연기를 감지 한 것에 의한 라이다 데이터를 필터링한다. 카메라로 촬영한 이미지에서는 연기를 구분하는 것이 하므로 카 메라 데이터를 이용하여 연기를 감지한 것에 의한 라이다 데이터를 필터링할 수 있다. 라이다 데이터의 필터링은 카메라 데이터에서 연기 유무의 확인 대상인 특정 위치와 다른 위치의 선명도 비교를 통해 이루어질 수도 있고, 미리 연기가 없는 카메라 이미지 다수와 연기가 있는 카메라 이미지 다수를 학습하여 필터링 모델을 만들고 실시간으로 필터링 모델에 카메라 데이터를 입력함으로써 이루어질 수도 있다. 공간 분석단계(S50)에서는 데이터 필터링단계(S40)에서 필터링된 라이다 데이터를 이용하여 공간 지도를 작성하 고 공간 내에서 로봇의 위치를 추정한다. 라이다 데이터의 필터링에 의해 사물에 의한 라이다 데이터만을 공간 지도 작성 등에 이용하기 때문에 공간 지도 작성 등을 정확하게 수행할 수 있다. 공간 분석단계(S50)에서는 라이다 데이터 외에 카메라 데이터를 이용하여 공간 분석 작업을 수행할 수 있다. 이 경우, 로봇이 3D 스캐너를 더 포함하고, 미리 3D 스캐너로부터 생성되는 스캐너 데이터, 라이다 데이터, 카메라 데이터를 인공지능 학습하여, 라이다 데이터와 카메라 데이터를 입력함으로써 추정 스캐너 데이 터를 생성할 수 있는 고밀도화 모델을 생성한다. 그리고 실시간으로 생성되는 라이다 데이터와 카메라 데이터를 고밀도화 모델에 입력하여 추정 스캐너 데이터를 생성한다. 추정 스캐너 데이터는 공간적으로 정확하고 고밀도 로 형성되며, 실시간으로 신속하게 생성될 수 있다.본 발명에 의한 로봇의 공간 분석 방법은 블랭크 지점 확인단계(S20)와 라이다 데이터 추정단계(S30)를 더 포함 할 수 있다. 블랭크 지점 확인단계(S20)와 라이다 데이터 추정단계(S30)는 데이터 생성단계(S10)와 데이터 필터링단계(S40) 사이에 진행될 수 있다. 블랭크 지점 확인단계(S20)에서는 라이다 데이터에서 라이다 데이터 값이 생성되지 않은 지점인 블랭크 지점이 포함되어 있는지 여부를 확인한다. 블랭크 지점은, 예를 들어 라이다가 방사한 레이저와 반사되어 되돌아온 레이저를 비교함으로써 확인할 수 있다. 라이다 데이터 추정단계(S30)에서는 블랭크 지점의 생성 이전 및/또는 이후 시간에 생성된 라이다 데이터를 이 용하여 블랭크 지점의 추정 라이다 데이터를 생성한다. 라이다 데이터의 추정을 위해, 미리 특정 시점의 라이다 데이터를 정답 데이터로 하고 특정 시점 이전 및/또는 이후 소정 개수의 라이다 데이터를 학습하여 추정 모델을 생성하고, 실시간으로 블랭크 지점이 확인되면 블랭크 지점의 생성 이전 및/또는 이후 소정 개수의 라이다 데이 터를 추정 모델에 입력하여 추정 라이다 데이터를 생성한다. 추정 라이다 데이터의 생성을 위해, 블랭크 지점 생성 이전 및/또는 이후 시간에 생성된 라이다 데이터 외에 블 랭크 지점 생성 이전 및/또는 이후 시간에 생성된 카메라 데이터와 블랭크 지점 생성시의 카메라 데이터가 더 이용될 수 있다. 이 경우, 추정 모델 생성을 위해 라이다 데이터와 카메라 데이터를 함께 학습시키고, 실시간 추정 라이다 데이터 생성을 위해 추정 모델에 라이다 데이터와 카메라 데이터를 함께 입력하여야 함은 당연하다. 본 발명의 권리범위는 상술한 실시예에 한정되는 것이 아니라 첨부된 특허청구범위 내에서 다양한 형태의 실시 예로 구현될 수 있다. 특허청구범위에서 청구하는 본 발명의 요지를 벗어남이 없이 당해 발명이 속하는 기술 분 야에서 통상의 지식을 가진 자라면 누구든지 변형 가능한 다양한 범위까지 본 발명의 청구범위 기재의 범위 내 에 있는 것으로 본다."}
{"patent_id": "10-2023-0123164", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명에 의한 로봇의 공간 분석 시스템의 개략적인 구성도, 도 2는 본 발명의 다른 실시예에 의한 공간 분석 시스템의 개략적인 구성도, 도 3 및 도 4는 본 발명에 의한 로봇의 공간 분석 시스템이 3D 스캐너를 더 포함하는 경우의 공간 분석부의 동 작에 대한 설명도, 도 5 내지 도 8은 본 발명에 의한 로봇의 공간 분석 시스템을 구성하는 추정 라이다 데이터 생성부의 동작에 대 한 설명도, 도 9는 본 발명에 의한 로봇의 공간 분석 방법의 순서도이다."}
