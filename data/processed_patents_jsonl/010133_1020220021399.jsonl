{"patent_id": "10-2022-0021399", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0124287", "출원번호": "10-2022-0021399", "발명의 명칭": "신경망 연산을 위한 처리 장치 및 그의 구동 방법", "출원인": "주식회사 딥이티", "발명자": "조용범"}}
{"patent_id": "10-2022-0021399", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "신경망 연산을 위한 처리 장치에 있어서,신경망의 학습을 수행하는 복수의 프로세서 유닛;상기 신경망을 이루는 복수의 계층 각각에 대응하는 가중치를 저장하도록 구비되는 복수의 가중치 메모리; 및상기 학습이 완료되면, 상기 복수의 가중치 메모리로부터 갱신된 상기 가중치를 획득하여 저장하는 메인메모리,를 포함하는, 처리 장치."}
{"patent_id": "10-2022-0021399", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 복수의 프로세서 유닛 각각은,상기 복수의 계층 중 어느 하나의 계층의 입력 데이터 및 상기 어느 하나의 계층에 대응하여 상기 복수의 가중치 메모리 중 어느 하나의 가중치 메모리로부터 획득되는 대상 가중치에 기초하여 출력 데이터의 생성을 위한연산 프로세스를 수행하는 연산부; 및상기 출력 데이터에 기초한 역전파를 수행하여 상기 대상 가중치를 상기 어느 하나의 가중치 메모리에 갱신하여저장하는 갱신 프로세스를 수행하는 가중치 업데이트부,를 포함하는 것인, 처리 장치."}
{"patent_id": "10-2022-0021399", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,상기 연산부는,가산기 회로 및 곱셈기 회로를 포함하는 것인, 처리 장치."}
{"patent_id": "10-2022-0021399", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제2항에 있어서,상기 복수의 프로세서 유닛은 프로세서 유닛 각각이 상기 연산 프로세스 및 상기 갱신 프로세스를 독립적으로수행하는 PDP(Parallel Distributed Processing) 구조로 구비되는 것을 특징으로 하는, 처리 장치."}
{"patent_id": "10-2022-0021399", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제2항에 있어서,상기 연산 프로세스 및 상기 갱신 프로세스 중 적어도 하나와 연계된 제1제어 신호 및 상기 복수의 가중치 메모리와 상기 메인 메모리 사이의 데이터 전송과 연계된 제2제어 신호를 생성하는 컨트롤러,를 더 포함하는 것인, 처리 장치."}
{"patent_id": "10-2022-0021399", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5항에 있어서,상기 복수의 프로세서 유닛은 프로세서 유닛 각각이 상기 제1제어 신호에 기초하여 서로 다른 상기 입력 데이터에 기초하여 병렬적으로 상기 연산 프로세스를 수행하는 SIMD(Single Instruction Multiple Data) 구조로 구비공개특허 10-2023-0124287-3-되는 것을 특징으로 하는, 처리 장치."}
{"patent_id": "10-2022-0021399", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제5항에 있어서,상기 컨트롤러가 상기 학습이 완료된 후 상기 제2제어 신호를 생성하여 상기 메인 메모리와 상기 복수의 가중치메모리 간의 트랜지션이 상기 학습의 완료 전에 방지되도록 하는 것을 특징으로 하는, 처리 장치."}
{"patent_id": "10-2022-0021399", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "신경망 연산을 위한 처리 장치의 구동 방법에 있어서,복수의 프로세서 유닛이 신경망을 이루는 복수의 계층 각각에 대응하는 가중치를 저장하는 복수의 가중치 메모리로부터 상기 가중치를 획득하여 상기 신경망의 학습을 수행하는 단계; 및상기 학습이 완료되면, 상기 복수의 가중치 메모리로부터 갱신된 상기 가중치를 획득하여 메인 메모리에 저장하는 단계,를 포함하는, 구동 방법."}
{"patent_id": "10-2022-0021399", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서,상기 학습을 수행하는 단계는,상기 복수의 계층 중 어느 하나의 계층의 입력 데이터 및 상기 어느 하나의 계층에 대응하여 상기 복수의 가중치 메모리 중 어느 하나의 가중치 메모리로부터 획득되는 대상 가중치에 기초하여 출력 데이터의 생성을 위한연산 프로세스를 수행하는 단계; 및상기 출력 데이터에 기초한 역전파를 수행하여 상기 대상 가중치를 상기 어느 하나의 가중치 메모리에 갱신하여저장하는 갱신 프로세스를 수행하는 단계,를 포함하는 것인, 구동 방법."}
{"patent_id": "10-2022-0021399", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9항에 있어서,컨트롤러가 상기 연산 프로세스 및 상기 갱신 프로세스 중 적어도 하나와 연계된 제1제어 신호를 생성하는단계; 및상기 컨트롤러가 상기 복수의 가중치 메모리와 상기 메인 메모리 사이의 데이터 전송과 연계된 제2제어 신호를생성하는 단계,를 더 포함하는 것인, 구동 방법."}
{"patent_id": "10-2022-0021399", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제10항에 있어서,상기 제2제어 신호를 생성하는 단계가 상기 학습이 완료된 후 수행되어 상기 메인 메모리와 상기 복수의 가중치메모리 간의 트랜지션이 상기 학습의 완료 전에 방지되는 것을 특징으로 하는, 구동 방법."}
{"patent_id": "10-2022-0021399", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "신경망 연산을 위한 처리 장치 및 그의 구동 방법이 개시되며, 본원의 일 실시예에 따른 신경망 연산을 위한 처 리 장치는, 신경망의 학습을 수행하는 복수의 프로세서 유닛, 상기 신경망을 이루는 복수의 계층 각각에 대응하 는 가중치를 저장하도록 구비되는 복수의 가중치 메모리 및 상기 학습이 완료되면, 상기 복수의 가중치 메모리로 부터 갱신된 상기 가중치를 획득하여 저장하는 메인 메모리를 포함할 수 있다."}
{"patent_id": "10-2022-0021399", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본원은 신경망 연산을 위한 처리 장치 및 그의 구동 방법에 관한 것이다. 예를 들면, 본원은 신경망의 가중치를 저장하는 메모리가 추가된 구조를 가지는 NPU(Neural Processing Unit)에 관한 것이다."}
{"patent_id": "10-2022-0021399", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "종래의 그래픽 카드를 구비한 컴퓨팅 장치에서의 신경망(neural network) 연산은 통상적으로 그래픽 처리 장치 (Graphics Processing Unit, GPU)가 담당하며, 이와 대비하여 중앙 처리 장치(Central Processing Unit, CPU) 에서는 학습 데이터 관리, 입/출력 데이터 관리, 가중치(Weight)의 초기값과 연산값을 저장하고 GPU 측 메모리 에 전달하는 역할 등을 수행하였다. 이와 관련하여, 도 1은 종래의 컴퓨팅 장치의 처리 장치 구조를 나타낸 도면이다. 도 1을 참조하면, GPU 측 메모리(즉, 그래픽 카드의 메모리)의 용량이 충분하면 가중치의 초기값을 CPU 측 메모 리에서 GPU 측 메모리로 옮기는 경우 및 신경망 연산이 완료된 후 갱신된 가중치의 최종값을 GPU 측 메모리에서 CPU 측 메모리로 옮기는 경우에만 데이터 이동이 발생하게 되나, GPU 측 메모리가 충분하지 않은 경우에는 GPU 측 메모리의 중간 결과값을 CPU 측 메모리로 옮기는 작업과 CPU 측 메모리에 존재하는 중간값을 GPU 측 메모리 로 옮기는 작업이 지속적으로 수행되어야 하므로 전체 신경망 연산 능력이 저하되게 된다. 달리 말해, CNN 등의 신경망 알고리즘의 성능은 컴퓨팅 장치(PC)의 메모리와 GPU 측 메모리 간 데이터 이동 횟수에 영향을 받게 된다. 따라서, 신경망 알고리즘의 성능을 개선하기 위하여는 컴퓨팅 장치(PC)의 메모리와 GPU 측 메모리 간의 데이터 이동(전송) 횟수를 줄일 수 있는 구조의 개발이 요구된다. 한편, 신경망 처리 장치(Neural Processing Unit, NPU)는 인공 신경망(ANN: Artificial Neural Network) 알고 리즘의 연산을 고속으로 처리하기 위한 목적으로 개발되는 처리 장치로서, 매우 많은 수의 연산을 동시에 처리 해야 하는 대규모 병렬 연산을 효율적으로 처리할 수 있어 심층 기계 학습(deep learning) 등에 주로 활용된다. 즉, NPU는 GPU보다도 간단한 연산을 행렬 곱셈 방식으로 처리하도록 설계되었다. 특히, 심층 신경망(DNN: Deep Neural Network)을 사용하는 심층 기계 학습(deep learning)은 하나의 입력 데이터를 처리하기 위하여 여러 계 층(layer)으로 이루어진 복잡한 행렬 곱셈 연산을 수행해야 하는데, 이 경우 NPU를 적용하면 GPU보다도 상대적 으로 더 빠른 속도로 연산을 수행할 수 있게 된다. 본원의 배경이 되는 기술은 한국등록특허공보 제10-0779022호에 개시되어 있다."}
{"patent_id": "10-2022-0021399", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본원은 전술한 종래 기술의 문제점을 해결하기 위한 것으로서, 복수의 가중치 메모리를 구비하여 프로세서와 메 모리 사이의 병목 현상의 발생을 감소시킬 수 있는 신경망 연산을 위한 처리 장치 및 그의 구동 방법을 제공하 려는 것을 목적으로 한다. 다만, 본원의 실시예가 이루고자 하는 기술적 과제는 상기된 바와 같은 기술적 과제들로 한정되지 않으며, 또 다른 기술적 과제들이 존재할 수 있다."}
{"patent_id": "10-2022-0021399", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기한 기술적 과제를 달성하기 위한 기술적 수단으로서, 본원의 일 실시예에 따른 신경망 연산을 위한 처리 장 치는, 신경망의 학습을 수행하는 복수의 프로세서 유닛, 상기 신경망을 이루는 복수의 계층 각각에 대응하는 가 중치를 저장하도록 구비되는 복수의 가중치 메모리 및 상기 학습이 완료되면, 상기 복수의 가중치 메모리로부터 갱신된 상기 가중치를 획득하여 저장하는 메인 메모리를 포함할 수 있다. 또한, 상기 복수의 프로세서 유닛 각각은, 상기 복수의 계층 중 어느 하나의 계층의 입력 데이터 및 상기 어느 하나의 계층에 대응하여 상기 복수의 가중치 메모리 중 어느 하나의 가중치 메모리로부터 획득되는 대상 가중치 에 기초하여 출력 데이터의 생성을 위한 연산 프로세스를 수행하는 연산부 및 상기 출력 데이터에 기초한 역전 파를 수행하여 상기 대상 가중치를 상기 어느 하나의 가중치 메모리에 갱신하여 저장하는 갱신 프로세스를 수행 하는 가중치 업데이트부를 포함할 수 있다. 또한, 상기 연산부는, 가산기 회로 및 곱셈기 회로를 포함할 수 있다. 또한, 상기 복수의 프로세서 유닛은 프로세서 유닛 각각이 상기 연산 프로세스 및 상기 갱신 프로세스를 독립적 으로 수행하는 PDP(Parallel Distributed Processing) 구조로 구비될 수 있다. 또한, 본원의 일 실시예에 따른 신경망 연산을 위한 처리 장치는, 상기 연산 프로세스 및 상기 갱신 프로세스 중 적어도 하나와 연계된 제1제어 신호 및 상기 복수의 가중치 메모리와 상기 메인 메모리 사이의 데이터 전송 과 연계된 제2제어 신호를 생성하는 컨트롤러를 포함할 수 있다. 또한, 상기 복수의 프로세서 유닛은 프로세서 유닛 각각이 상기 제1제어 신호에 기초하여 서로 다른 상기 입력 데이터에 기초하여 병렬적으로 상기 연산 프로세스를 수행하는 SIMD(Single Instruction Multiple Data) 구조 로 구비될 수 있다. 또한, 상기 컨트롤러가 상기 학습이 완료된 후 상기 제2제어 신호를 생성하여 상기 메인 메모리와 상기 복수의 가중치 메모리 간의 트랜지션이 상기 학습의 완료 전에 방지되는 것일 수 있다. 한편, 본원의 일 실시예에 따른 신경망 연산을 위한 처리 장치의 구동 방법은, 복수의 프로세서 유닛이 신경망 을 이루는 복수의 계층 각각에 대응하는 가중치를 저장하는 복수의 가중치 메모리로부터 상기 가중치를 획득하 여 상기 신경망의 학습을 수행하는 단계 및 상기 학습이 완료되면, 상기 복수의 가중치 메모리로부터 갱신된 상 기 가중치를 획득하여 메인 메모리에 저장하는 단계를 포함할 수 있다. 또한, 상기 학습을 수행하는 단계는, 상기 복수의 계층 중 어느 하나의 계층의 입력 데이터 및 상기 어느 하나 의 계층에 대응하여 상기 복수의 가중치 메모리 중 어느 하나의 가중치 메모리로부터 획득되는 대상 가중치에 기초하여 출력 데이터의 생성을 위한 연산 프로세스를 수행하는 단계 및 상기 출력 데이터에 기초한 역전파를 수행하여 상기 대상 가중치를 상기 어느 하나의 가중치 메모리에 갱신하여 저장하는 갱신 프로세스를 수행하는 단계를 포함할 수 있다. 또한, 본원의 일 실시예에 따른 신경망 연산을 위한 처리 장치의 구동 방법은, 컨트롤러가 상기 연산 프로세스 및 상기 갱신 프로세스 중 적어도 하나와 연계된 제1제어 신호를 생성하는 단계 및 상기 컨트롤러가 상기 복수 의 가중치 메모리와 상기 메인 메모리 사이의 데이터 전송과 연계된 제2제어 신호를 생성하는 단계를 포함할 수 있다. 또한, 상기 제2제어 신호를 생성하는 단계가 상기 학습이 완료된 후 수행되어 상기 메인 메모리와 상기 복수의 가중치 메모리 간의 트랜지션이 상기 학습의 완료 전에 방지되는 것일 수 있다. 상술한 과제 해결 수단은 단지 예시적인 것으로서, 본원을 제한하려는 의도로 해석되지 않아야 한다. 상술한 예 시적인 실시예 외에도, 도면 및 발명의 상세한 설명에 추가적인 실시예가 존재할 수 있다."}
{"patent_id": "10-2022-0021399", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "전술한 본원의 과제 해결 수단에 의하면, 복수의 가중치 메모리를 구비하여 프로세서와 메모리 사이의 병목 현 상의 발생을 감소시킬 수 있는 신경망 연산을 위한 처리 장치 및 그의 구동 방법을 제공할 수 있다. 전술한 본원의 과제 해결 수단에 의하면, 신경망 연산 과정에서 필요한 프로세서와 메모리 간의 데이터 전송을 위한 병목 현상의 발생을 저감시켜 신경망의 성능을 향상시키고, 데이터 이동에 소모되는 전력을 절약할 수 있 다. 전술한 본원의 과제 해결 수단에 의하면, 신경망의 연산은 연산 동작을 담당하도록 설계된 신경망 처리 장치 (NPU) 측에서 이루어지고, 중앙 처리 장치(CPU)는 신경망과 연계된 데이터의 입출력 부분에만 관여할 수 있어 전체 학습 및 추론 동작이 상대적으로 간단한 프로세스로 수행될 수 있다. 다만, 본원에서 얻을 수 있는 효과는 상기된 바와 같은 효과들로 한정되지 않으며, 또 다른 효과들이 존재할 수 있다."}
{"patent_id": "10-2022-0021399", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "아래에서는 첨부한 도면을 참조하여 본원이 속하는 기술 분야에서 통상의 지식을 가진 자가 용이하게 실시할 수 있도록 본원의 실시예를 상세히 설명한다. 그러나 본원은 여러 가지 상이한 형태로 구현될 수 있으며 여기에서 설명하는 실시예에 한정되지 않는다. 그리고 도면에서 본원을 명확하게 설명하기 위해서 설명과 관계없는 부분 은 생략하였으며, 명세서 전체를 통하여 유사한 부분에 대해서는 유사한 도면 부호를 붙였다. 본원 명세서 전체에서, 어떤 부분이 다른 부분과 \"연결\"되어 있다고 할 때, 이는 \"직접적으로 연결\"되어 있는 경우뿐 아니라, 그 중간에 다른 소자를 사이에 두고 \"전기적으로 연결\" 또는 \"간접적으로 연결\"되어 있는 경우 도 포함한다. 본원 명세서 전체에서, 어떤 부재가 다른 부재 \"상에\", \"상부에\", \"상단에\", \"하에\", \"하부에\", \"하단에\" 위치 하고 있다고 할 때, 이는 어떤 부재가 다른 부재에 접해 있는 경우뿐 아니라 두 부재 사이에 또 다른 부재가 존 재하는 경우도 포함한다. 본원 명세서 전체에서, 어떤 부분이 어떤 구성 요소를 \"포함\"한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다른 구성 요소를 제외하는 것이 아니라 다른 구성 요소를 더 포함할 수 있는 것을 의미한다. 본원은 신경망 연산을 위한 처리 장치 및 그의 구동 방법에 관한 것이다. 예를 들면, 본원은 신경망의 가중치를 저장하는 메모리가 추가된 구조를 가지는 NPU(Neural Processing Unit)에 관한 것이다. 도 2는 본원의 일 실시예에 따른 신경망 연산을 위한 처리 장치의 개략적인 구성도이다. 도 2를 참조하면, 본원의 일 실시예에 따른 신경망 연산을 위한 처리 장치(이하, '처리 장치'라 한다.)는 복수의 프로세서 유닛, 복수의 가중치 메모리(M1, M2, , Mn, 120), 메인 메모리 및 컨 트롤러를 포함할 수 있다. 프로세서 유닛은 신경망의 학습을 수행할 수 있다. 한편, 본원의 실시예에 관한 설명에서 신경망은 시냅스 의 결합으로 네트워크를 형성한 인공 뉴런(노드)이 학습을 통해 시냅스의 결합 세기를 변화시켜, 문제 해결 능 력을 가지는 인공지능 기반의 모델 전반을 지칭하는 용어일 수 있다. 예시적으로, 신경망은 컨볼루션 뉴럴 네트워크(CNN, convolutional neural network)일 수 있으나, 이에만 한정 되는 것은 아니다. 다른 예로, 신경망은 순환 신경망(RNN, Recurrent Neural Network), 심층 신뢰 신경망(DBN, Deep Belief Network), GAN(Generative Adversarial Network. 생성 대립 신경망), 관계형 신경망 네트워크(RL, Relation Networks), 심층 신경망(Deep Neural Network, DNN), 딥러닝 네트워크 등 종래에 이미 공지되었거나 향후 개발되는 다양한 인공지능 기반의 모델을 폭넓게 포함할 수 있다. 또한, 본원의 일 실시예에 따르면, 처리 장치의 복수의 프로세서 유닛은 각각의 프로세서 유닛 이 후술하는 학습을 위한 연산 과정(보다 구체적으로, 연산부의 연산 프로세스 및 가중치 업데이트부(11 2)의 갱신 프로세스를 포함하는 프로세스)를 독립적으로 수행하는 PDP(Parallel Distributed Processing) 구조 로 구비될 수 있다. 이에 따라, 처리 장치에 의할 때, 병렬로 구비되는 개개의 프로세서 유닛이 다른 프로세서 유닛(11 0)과 연관됨이 없이 독자적으로 연산을 수행할 수 있기 때문에 다수의 프로세서 유닛이 배치되더라도 동시 에 신경망 연산을 수행할 수 있다는 이점이 있다. 또한, 본원의 일 실시예에 따르면, 처리 장치의 복수의 프로세서 유닛은 프로세서 유닛 각각이 후술하는 컨트롤러에서 생성한 제어 신호(제1제어 신호)에 기초하여 서로 다른 입력 데이터에 기초하여 병 렬적으로 연산 프로세스를 수행하는 SIMD(Single Instruction Multiple Data) 구조로 구비될 수 있다. 또한, 복수의 가중치 메모리는 신경망을 이루는 복수의 계층 각각에 대응하는 가중치를 저장하도록 구비될 수 있다. 이와 관련하여, 신경망을 이루는 복수의 계층은 입력 계층(Input Layer), 은닉 계층(Hidden Layer), 출력 계층(Output Layer) 등으로 구분될 수 있다. 구체적으로, 전술한 바와 같이 본원에서의 신경망은 다중 레이어(계층)를 포함하는 스택형 신경망으로, 각 계층 은 뉴런(neurons)이라고 불리는 복수의 노드들을 포함하며, 각 노드 또는 뉴런은 하나 이상의 입력 및 출력을 갖는 계산 단위를 의미하는 것일 수 있다. 각 계층의 복수의 뉴런으로부터 각각의 입력 및 각각의 출력(입력 데 이터 또는 특징맵)은 인접한 계층의 각 뉴런에 공급될 수 있다. 한편, 본원의 일 실시예에 따른 신경망은, 은닉 계층 및 출력 계층 사이에 완전 접속 계층을 포함할 수 있다. 본원의 일 실시예에 따른 신경망이 전술한 완전 접속 계층을 포함하는 경우, 완전 접속 계층은 출력 계층의 직 전에 접속된 계층으로 결정될 수 있다. 또한, 본원 명세서 전반에서 신경망의 계층을 지칭하는 용어는, 입력 계층, 은닉 계층 및 출력 계층 외에도, 컨 볼루션 계층(Convolution layer), 서브 샘플링 계층(Sub-Sampling layer), 풀링 레이어(Pooling layer) 등으로 달리 표현될 수 있다. 또한, 본원에서의 하나의 입력 계층 또는 하나의 은닉 계층이 세부적으로 컨볼루션 계층 (Convolution layer), 서브 샘플링 계층(Sub-Sampling layer), 풀링 레이어(Pooling layer) 등을 포함하여 이 루어지는 것으로 이해될 수 있다. 또한, 입력 계층은 처리 장치로 인가되는 입력 데이터를 기초로 하여 특징맵을 출력하는 계층일 수 있다. 여기서, 특징맵이란 입력 데이터에 기 설정된 특징이 포함되는가에 대한 판단을 나타내는 인식 또는 탐색 결과 를 나타내는 데이터일 수 있다. 이와 관련하여 입력 계층의 복수의 입력 뉴런 각각이 입력 데이터로부터 어떠한 기 설정된 특징을 인식 또는 탐색하는지에 대한 정보는 후술할 가중치에 포함되는 것일 수 있다. 예시적으로, 입력 데이터는 처리 장치를 통해 구축(학습)하려는 신경망의 유형이 CNN 등의 유형인 경우, 이미지 데이터일 수 있으나, 이에만 한정되는 것은 아니다. 구체적으로, 이미지 데이터의 경우, 너비(W), 높이 (H), 깊이(D)를 가지는 데이터로 표현될 수 있으며, WxHxD의 형식으로 표기될 수 있다. 여기서, 너비, 높이, 깊 이라는 용어는 각각 칼럼, 로우, 채널 수로 대체될 수 있다. 여기서, 너비(W) 및 높이(H)는 이미지 데이터의 픽 셀 수에 기초하여 결정되는 값일 수 있다. 예를 들어, 가로로 32개의 픽셀을, 세로로 32개의 픽셀을 가지는 이 미지 데이터는 32x32의 행렬(matrix)로 나타낼 수 있고, 행렬의 각 구성 요소는 이미지 데이터의 해당 위치의 픽셀 값일 수 있다. 다른 예로, 그레이 스케일(Gray Scale)을 갖는 이미지 데이터의 경우 각 픽셀의 gray value로 이루어진 단일 행 렬로 표현될 수 있고, 컬러 이미지 데이터의 경우 R 값 행렬, G값 행렬, B값 행렬로 분리된 독립된 3가지 행렬 로 표현될 수 있다(깊이 또는 채널 수 3). 또한, 은닉 계층은 복수의 계층으로 구성될 수 있으며, 입력 계층과 인접한 첫번째 은닉 계층은 입력 계층이 출 력한 특징맵을 입력으로 하여, 해당 특징맵에 포함될 수 있는 또 다른 특징을 인식 또는 탐색한 결과인 새로운 특징맵을 출력할 수 있다. 또한, 이 새로운 특징맵은 다음 순서의 은닉 계층의 입력으로 인가될 수 있다. 종합 하면, 은닉 계층의 입력은 입력 계층 또는 해당 은닉 계층의 직전 단계 은닉 계층의 출력 결과인 특징맵이 되고, 각 은닉 계층은 이 특징맵으로부터 다른 특징을 인식 또는 탐색한 결과인 새로운 특징맵을 출력할 수 있 다. 즉, 입력 계층 및 은닉 계층을 거치면서, 입력 데이터(특히, 이미지 데이터)의 특징들에 대한 인식 결과가 중첩 적으로 출력될 수 있다. 즉, 신경망은 후술할 연산부가 수행하는 연산 프로세스에 기초한 특징맵을 반복적 으로 출력함으로써, 입력 데이터(이미지 등) 전체를 대표할 수 있는 강인한 특징을 탐색하여 출력하고, 처리 장 치는 출력된 특징들을 통해 입력 데이터에 대한 분석 또는 분류 등을 수행하여 결과를 출력할 수 있다. 여기서, 출력 데이터는 예를 들어 입력 데이터로서 인가된 이미지 데이터에 포함된 객체 인식 결과 또는 이미지 데이터의 기 설정된 범주로의 분류 결과를 의미할 수 있고, 나아가, 처리 장치가 출력한 객체 인식 결과 또는 분류 결과의 정확도 정보를 포함하는 개념일 수 있다. 즉, 본원에서의 출력 데이터는 처리 장치가 생 성한 인공지능 기반의 모델을 통해 최종적으로 판단하여 출력한 입력 데이터의 객체 인식 결과 또는 분류 결과 자체 또는 해당 결과의 정확도 정보(정답 여부, 에러 여부, 신뢰도 등)중 적어도 하나를 포함하는 것일 수 있다. 본원의 일 실시예에 따르면, 복수의 가중치 메모리는, 처리 장치에 구비된 단일 메모리를 분할 (partition)한 것일 수 있다. 이 때, 분할(partition) 구조(예를 들면, 분할 메모리의 수, 각각의 메모리 할당 량 등)는 신경망을 이루는 계층의 수, 뉴런의 개수 등에 기초하여 결정되는 것일 수 있다 일 예로, 복수의 가중 치 메모리는 단일 메모리를 복수의 입력 뉴런의 개수, 은닉 계층의 수, 은닉 계층에 포함된 뉴런의 수 등 을 기준으로 하여 분할한 파티션 메모리 각각을 의미하는 것일 수 있다. 한편, 본원에서의 가중치는 신경망 연산에 적용되는 필터(filter), 가중치 행렬과 동일한 것으로 이해될 수 있 다. 예시적으로, 신경망이 CNN인 경우, 가중치는 KxK의 행렬(matrix)로 표기될 수 있고, 이 때의 K 값은 가중치 의 크기 또는 필터 사이즈를 의미할 수 있다. 본원의 일 실시예에 따르면, 복수의 가중치 메모리는, STT(spin-torque transfer) 메모리 또는 비휘발성 이진 메모리를 포함할 수 있으나 이에 한정되는 것은 아니고, DRAM(dynamic random access memory), PCM(phase change memory), 휘발성 메모리, 비휘발성 메모리 등일 수 있으며, 실시예에 따라, 각각의 가중치 메모리 는 복수의 유형의 메모리로 구현될 수 있다. 또한, 본원의 일 실시예에 따르면, 복수의 가중치 메모리는, 은닉 계층의 복수의 은닉 뉴런(미도시)에 대 응하도록 복수 개 마련되고, 복수의 은닉 뉴런(미도시)에 대응되는 가중치를 저장하도록 추가적으로 구비될 수 있다. 이 때, 복수의 가중치 메모리는 은닉 계층과 연계하여 가중치를 저장하는 것으로 표현될 수 있다. 예시적으로, 복수의 가중치 메모리는, 복수의 은닉 뉴런(미도시)의 개수만큼 구비되고, 복수의 은닉 뉴런 (미도시) 각각에 대응되는 가중치를 저장하도록 추가적으로 구비될 수 있다. 또한, 복수의 가중치 메모리 각각에 저장되는 가중치의 초기값은 LeCun Initialization, Xavier Initialization(Glorot Initialization), He Initialization 기법 등에 의해 결정될 수 있다. 또한, 복수의 프로세서 유닛 및 복수의 가중치 메모리를 통해 수행되는 신경망의 학습이 완료되면, 메인 메모리에는 복수의 가중치 메모리로부터 획득된 갱신된 가중치가 저장될 수 있다. 이와 관련하여, 컨트롤러는 프로세서 유닛에서 수행되는 연산 프로세스 및 갱신 프로세스 중 적어도 하나와 연계된 제1제어 신호 및 복수의 가중치 메모리와 메인 메모리 사이의 데이터 전송과 연계된 제2제어 신호를 생성할 수 있다. 또한, 컨트롤러는 신경망의 학습이 수행되는 과정에서는 제1제어 신호를 생성하여 가중치 메모리에 저장된 가중치의 초기값, 학습에 따른 중간 결과값 등을 신경망의 각 계층에 따른 연산을 수행하는 프로세서 유 닛으로 제공하고, 프로세서 유닛의 연산 수행 결과를 기초로 갱신된 가중치를 가중치 메모리에 갱신하여 저장하는 과정을 반복적으로 수행할 수 있다. 한편, 컨트롤러는 전술한 신경망의 학습이 이루어지는 도중에는 메인 메모리와 연계된 제2제어 신호 는 생성하지 않도록 동작하여 메인 메모리와 복수의 가중치 메모리 간의 트랜지션이 신경망의 학습의 완료 전에는 방지되도록 할 수 있다. 또한, 본원의 일 실시예에 따르면, 컨트롤러는 소정의 계층 구조를 가지는 신경망의 학습을 처리 장치 를 통해 수행하기 위하여, 학습(구축)하려는 신경망의 특성 정보에 기초하여 처리 장치에 구비되는 복수의 프로세서 유닛 및 복수의 가중치 메모리 간의 매핑 관계를 사전에 할당하는 매핑 신호를 포함 하는 제1제어 신호를 생성할 수 있다. 보다 구체적으로, 컨트롤러는 신경망의 계층 수, 각 계층에 포함되 는 뉴런의 수, 입력 데이터의 크기 등을 고려하여 신경망의 학습을 위한 연산 프로세스 및 갱신 프로세스를 수 행할 프로세서 유닛을 처리 장치에 탑재되는 복수의 프로세서 유닛 중에서 선정하고, 선정된 프 로세서 유닛 각각에 대응하여 해당 프로세서 유닛에서 사용될 가중치를 저장할 가중치 메모리를 가중치 메모리 중에서 선정할 수 있다. 이와 관련하여, 컨트롤러는 처리 장치에 탑재되는 복수의 프로세서 유닛이 연산 리소스 등의 특 성이 서로 다른 복수의 유형의 프로세서를 포함하는 경우, 상대적으로 연산량이 크거나 높은 연산 복잡도가 요 구되는 신경망 계층의 연산을 복수의 프로세서 유닛의 리소스 정보에 기초하여 연산 리소스가 상대적으로 풍부한 프로세서가 담당하도록 할당하고, 이에 대응하여 메모리 용량이 상대적으로 크거나 데이터 접근 속도가 상대적으로 빠른 가중치 메모리를 할당된 해당 프로세서 유닛에 매핑하도록 전술한 매핑 신호를 생성 할 수 있으나, 이에만 한정되는 것은 아니다. 이후 처리 장치가 신경망의 학습이 완료된 것으로 판단하면, 컨트롤러는 메인 메모리와 연계된 제2제어 신호를 생성하여 메인 메모리로 복수의 가중치 메모리에 신경망의 학습에 따라 갱신된 가중 치를 전송하고, 메인 메모리에 학습 결과에 따른 최종적인 가중치가 저장되도록 할 수 있다. 도 3은 본원의 일 실시예에 따른 신경망 연산을 위한 처리 장치의 구현예를 예시적으로 나타낸 도면이다. 도 3을 참조하면, 처리 장치의 각각의 프로세서 유닛은 연산부 및 가중치 업데이트부를 포 함할 수 있다.연산부는 신경망을 이루는 복수의 계층 중 어느 하나의 계층의 입력 데이터 및 해당 계층(즉, 어느 하나의 계층)에 대응하여 복수의 가중치 메모리 중 어느 하나의 가중치 메모리로부터 획득되는 대상 가중치에 기 초하여 출력 데이터의 생성을 위한 연산 프로세스를 수행할 수 있다. 또한, 본원의 일 실시예에 따르면, 연산부는 가산기 회로(ADDER) 및 곱셈기 회로(MULTIPLIER)를 포함하는 구조로 구비될 수 있다. 이와 관련하여, 신경망의 구조는 통상적으로 출력을 결정하는 뉴런과 뉴런 간을 가중치 로 연결하는 시냅스로 구성되며, 이러한 신경망의 학습 또는 추론을 위한 연산은 대부분 덧셈 연산과 곱셈 연산 으로 이루어지기 때문에 다수의 프로세서를 통한 병렬 구조로 구현되더라도 연산 자체는 가산기 회로(ADDER)와 곱셈기 회로(MULTIPLIER)만으로도 수행될 수 있으나, 기존에 개발(설계)된 대부분의 NPU는 신경망 구현을 목적 으로 하는 것이 아니고, 그래픽 벡터 연산이나 DSP(Digital Signal Processing) 연산 등이 주요 연산으로 고려 되고 해당 연산을 위한 구조를 이용하여 신경망 연산을 하기 때문에 원래의 목적을 달성하기 위해서는 복잡한 구조가 형성되어야 하는 한계가 있었다. 달리 말해, 기 개발된 다수의 NPU가 신경망 연산 이외의 다른 부수 기 능을 제공하기 위한 구조로 설계되기 때문에 하드웨어 복잡도가 높으며, NPU를 구동하기 위한 소프트웨어 역시 공개되지 않기 때문에 구현 난이도가 매우 높은 것으로 평가되는 것과 달리, 본원에서 개시하는 처리 장치(10 0)는 신경망의 학습 또는 추론을 위한 연산을 수행하기 위한 목적으로 설계되는 NPU 구조에 해당하므로 구현 난 이도가 상대적으로 낮은 이점이 있다. 가중치 업데이트부는 연산부가 생성한 출력 데이터에 기초한 역전파(Back Propagation)를 수행하여 대상 가중치(달리 말해, 특정 가중치 메모리로부터 불러온 해당 계층의 가중치)를 해당 가중치 메모리 (즉, 어느 하나의 가중치 메모리)에 갱신하여 저장하는 갱신 프로세스를 수행할 수 있다. 또한, 도 3을 참조하면, 본원에서 개시하는 처리 장치는 프로세서 유닛과 가중치 메모리 사이의 데이터(예를 들면, 가중치 메모리에 저장된 가중치 정보 등)를 송수신(교환)을 수행하기 위한 통로인 버스 를 구비할 수 있다. 다만, 이에만 한정되는 것은 아니며, 버스는 프로세서 유닛, 가중치 메모리 , 메인 메모리, 컨트롤러 등 처리 장치에 탑재되는 하위 모듈 간에 송수신(교환)되는 각종 데이터가 이동하는 경로로 기능할 수 있다. 한편, 도 3의 좌측에 도시된 개념도는 예시적인 신경망 구조를 나타내며, 우측의 도시는 해당 신경망 구조 를 하드웨어적으로 실제 구현했을 때의 모식도를 나타낸다. 이와 관련하여, 처리 장치의 하드웨어 구조 는 설계된 후 한 번 고정되면 재차 수정하는 것이 어렵기 때문에 좌측의 신경망 구조의 개념도에 완전히 대 응되도록 설계하기 어렵고, 만일 신경망 구조의 개념적 구조에 완전히 부합하도록 처리 장치를 구현(설 계)하는 경우, 신경망 연산 외 다른 기능(예를 들면, GPU, CPU 등을 통해 수행 가능한 다른 연산 기능 등)에는 처리 장치가 활용될 수 없을 수 있다. 이를 고려하여 본원의 발명자는 도 3의 우측 모식도와 같이 병렬 구 조의 SIMD(Single Instruction Multiple Data) 처리가 가능한 구조로 처리 장치를 설계하여 다수의 프로 세서 유닛이 동시(실질적으로 동일한 시점으로 간주할 수 있는 허용 오차 범위 이내를 포함한다.)에 연산 동작을 최대한 많이 수행할 수 있도록 설계하였다. 즉, 본원에서 개시하는 처리 장치는 신경망 연산을 위 한 가중치 메모리를 개별적으로 배치하고, 신경망 구조의 학습 연산이 완료(종료)될 때까지 메인 메모 리와의 트랜지션은 발생하지 않도록 하여 데이터 전송에 따른 병목 현상의 발생을 획기적으로 감소시킬 수 있다. 도 4는 종래의 신경망 모델의 구조와 본원에서 개시하는 신경망 연산을 위한 처리 장치에 의해 구축되는 신경망 모델의 구조를 비교하여 나타낸 개념도이다. 도 4를 참조하면, 종래의 신경망 학습을 위한 처리 장치는 도 4의 (a)와 같이 단일 메모리에서 데이터를 읽어와 각 가중치에 할당하고 계산이 끝난 가중치가 해당 단일 메모리에 저장되는 구조로 설계되었던 반면, 본원에서 개시하는 처리 장치는 도 4의 (b)와 같이 가중치 메모리를 신경망을 이루는 각각의 계층 내지 각각의 뉴런에 대하여 배치하여 두고 프로세서 유닛의 계산(연산) 결과를 직접 가중치 메모리에 저장함으로 써 종래의 신경망 구조 대비 병렬적이고 분산된 형태로 신경망의 학습을 위한 연산이 이루어질 수 있으며, 이에 따라 종래 구조 대비 가중치를 메모리에 저장하기 위해 전달하는 과정과 메모리로부터 기 저장된 가중치를 불러 오는 과정이 상대적으로 생략될 수 있어 처리 속도의 향상을 달성할 수 있다. 도 5는 본원의 일 실시예에 따른 신경망 연산을 위한 처리 장치와 중앙 처리 장치의 데이터 이동 흐름을 시계열 적으로 나타낸 도면이다. 도 5를 참조하면, 본원에서 개시하는 처리 장치(NPU, 100)가 중앙 처리 장치(CPU, 200)과 연동하여 동작하는 컴 퓨팅 구조를 가정하면, 처리 장치와 연동하는 중앙 처리 장치는 신경망에 인가되는 입력 데이터를 인 가하는 데이터 흐름(도 5의 a)이나 신경망 모델을 통해 입력 데이터로부터 도출되는 출력 데이터를 획득하는 데 이터 흐름(도 5의 c)에만 관여하거나 처리 장치에서 수행되는 신경망의 학습에 대한 중간 결과를 확인하기 위해 메모리에 접근하는 동작(도 5의 b)에만 관여하도록 동작할 수 있다. 달리 말해, 처리 장치가 중앙 처리 장치와 연동하는 경우에도 신경망의 연산 과정은 처리 장치 의 컨트롤러에서 관리하도록 하여 중앙 처리 장치와의 연계를 최소화할 수 있다. 이하에서는 상기에 자세히 설명된 내용을 기반으로, 본원의 동작 흐름을 간단히 살펴보기로 한다. 도 6은 본원의 일 실시예에 따른 신경망 연산을 위한 처리 장치의 구동 방법에 대한 동작 흐름도이다. 도 6에 도시된 신경망 연산을 위한 처리 장치의 구동 방법은 앞서 설명된 처리 장치에 의하여 수행될 수 있다. 따라서, 이하 생략된 내용이라고 하더라도 처리 장치에 대하여 설명된 내용은 신경망 연산을 위한 처리 장치의 구동 방법에 대한 설명에도 동일하게 적용될 수 있다. 도 6을 참조하면, 단계 S11에서 처리 장치의 복수의 프로세서 유닛 각각은 신경망을 이루는 복수의 계층 각각에 대응하는 가중치를 저장하는 복수의 가중치 메모리로부터 가중치를 획득하여 신경망의 학습을 수행할 수 있다. 다음으로, 단계 S12에서 처리 장치는 단계 S11을 통한 신경망 학습이 완료되었는지 여부를 판단할 수 있다. 만일, 단계 S12의 판단 결과, 신경망의 학습이 완료된 것으로 판단되면, 단계 S13에서 처리 장치는 복수의 가중치 메모리로부터 갱신된 상기 가중치를 획득하여 메인 메모리에 저장할 수 있다. 예를 들어, 단 계 S13에서 처리 장치의 컨트롤러는 가중치 메모리 각각에 저장된 가중치(단계 S11을 통한 학습 을 통하여 그 값이 갱신된 가중치)를 메인 메모리에 저장할 수 있다. 반대로, 단계 S12의 판단 결과, 신경망의 학습이 완료되지 않은 것으로 판단되면, 처리 장치는 전술한 단 계 S11를 통한 신경망 학습을 반복하여 수행할 수 있다. 상술한 설명에서, 단계 S11 내지 S13은 본원의 구현예에 따라서, 추가적인 단계들로 더 분할되거나, 더 적은 단 계들로 조합될 수 있다. 또한, 일부 단계는 필요에 따라 생략될 수도 있고, 단계 간의 순서가 변경될 수도 있다. 본원의 일 실시예에 따른 신경망 연산을 위한 처리 장치의 구동 방법은 다양한 컴퓨터 수단을 통하여 수행될 수 있는 프로그램 명령 형태로 구현되어 컴퓨터 판독 가능 매체에 기록될 수 있다. 상기 컴퓨터 판독 가능 매체는 프로그램 명령, 데이터 파일, 데이터 구조 등을 단독으로 또는 조합하여 포함할 수 있다. 상기 매체에 기록되는 프로그램 명령은 본 발명을 위하여 특별히 설계되고 구성된 것들이거나 컴퓨터 소프트웨어 당업자에게 공지되어 사용 가능한 것일 수도 있다. 컴퓨터 판독 가능 기록 매체의 예에는 하드 디스크, 플로피 디스크 및 자기 테이 프와 같은 자기 매체(magnetic media), CD-ROM, DVD와 같은 광기록 매체(optical media), 플롭티컬 디스크 (floptical disk)와 같은 자기-광 매체(magneto-optical media), 및 롬(ROM), 램(RAM), 플래시 메모리 등과 같 은 프로그램 명령을 저장하고 수행하도록 특별히 구성된 하드웨어 장치가 포함된다. 프로그램 명령의 예에는 컴 파일러에 의해 만들어지는 것과 같은 기계어 코드뿐만 아니라 인터프리터 등을 사용해서 컴퓨터에 의해서 실행 될 수 있는 고급 언어 코드를 포함한다. 상기된 하드웨어 장치는 본 발명의 동작을 수행하기 위해 하나 이상의 소프트웨어 모듈로서 작동하도록 구성될 수 있으며, 그 역도 마찬가지이다. 또한, 전술한 신경망 연산을 위한 처리 장치의 구동 방법은 기록 매체에 저장되는 컴퓨터에 의해 실행되는 컴퓨 터 프로그램 또는 애플리케이션의 형태로도 구현될 수 있다."}
{"patent_id": "10-2022-0021399", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "전술한 본원의 설명은 예시를 위한 것이며, 본원이 속하는 기술분야의 통상의 지식을 가진 자는 본원의 기술적 사상이나 필수적인 특징을 변경하지 않고서 다른 구체적인 형태로 쉽게 변형이 가능하다는 것을 이해할 수 있을 것이다. 그러므로 이상에서 기술한 실시예들은 모든 면에서 예시적인 것이며 한정적이 아닌 것으로 이해해야만 한다. 예를 들어, 단일형으로 설명되어 있는 각 구성 요소는 분산되어 실시될 수도 있으며, 마찬가지로 분산된 것으로 설명되어 있는 구성 요소들도 결합된 형태로 실시될 수 있다. 본원의 범위는 상기 상세한 설명보다는 후술하는 특허청구범위에 의하여 나타내어지며, 특허청구범위의 의미 및 범위 그리고 그 균등 개념으로부터 도출되는 모든 변경 또는 변형된 형태가 본원의 범위에 포함되는 것으로 해석되어야 한다."}
{"patent_id": "10-2022-0021399", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 종래의 컴퓨팅 장치의 처리 장치 구조를 나타낸 도면이다. 도 2는 본원의 일 실시예에 따른 신경망 연산을 위한 처리 장치의 개략적인 구성도이다. 도 3은 본원의 일 실시예에 따른 신경망 연산을 위한 처리 장치의 구현예를 예시적으로 나타낸 도면이다. 도 4는 종래의 신경망 모델의 구조와 본원에서 개시하는 신경망 연산을 위한 처리 장치에 의해 구축되는 신경망 모델의 구조를 비교하여 나타낸 개념도이다. 도 5는 본원의 일 실시예에 따른 신경망 연산을 위한 처리 장치와 중앙 처리 장치의 데이터 이동 흐름을 시계열적으로 나타낸 도면이다. 도 6은 본원의 일 실시예에 따른 신경망 연산을 위한 처리 장치의 구동 방법에 대한 동작 흐름도이다."}
