{"patent_id": "10-2019-0152987", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2021-0064594", "출원번호": "10-2019-0152987", "발명의 명칭": "전자장치 및 그 제어방법", "출원인": "삼성전자주식회사", "발명자": "김상민"}}
{"patent_id": "10-2019-0152987", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "전자장치에 있어서,사용자 발화를 수신하게 마련된 음성입력부와,상기 음성입력부를 통해 수신된 사용자 발화의 키워드를 획득하고,복수의 음성 어시스턴트 및 복수의 키워드 사이의 연관도에 관해 기 정의된 정보에 기초하여, 상기 복수의 음성어시스턴트 중 상기 획득한 키워드와 연관도가 높은 음성 어시스턴트를 식별하고,상기 식별된 음성 어시스턴트에 기초하여 상기 사용자 발화에 관한 음성 인식을 수행하도록 하는 프로세서를 포함하는 전자장치."}
{"patent_id": "10-2019-0152987", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 프로세서는, 상기 획득한 키워드에 대해 상기 정보에 정의된 각각의 상기 음성 어시스턴트의 연관도를 식별하고, 상기 식별된 연관도가 가장 높은 음성 어시스턴트를 선택하는 전자장치."}
{"patent_id": "10-2019-0152987", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,상기 프로세서는, 상기 획득한 키워드가 복수 개이면, 상기 복수의 획득한 키워드 별 상기 음성 어시스턴트의연관도를 합산하며, 상기 복수의 음성 어시스턴트 별 합산된 연관도를 비교하는 전자장치."}
{"patent_id": "10-2019-0152987", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,상기 기 정의된 정보는, 상기 전자장치의 사용 이력에 기반하여 마련되는 전자장치."}
{"patent_id": "10-2019-0152987", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서,상기 사용 이력은, 사용자 발화의 소정 키워드에 대한 상기 복수의 음성 어시스턴트 각각의 처리 이력을 카운트한 정보를 포함하는 전자장치."}
{"patent_id": "10-2019-0152987", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서,상기 프로세서는, 상기 획득한 키워드에 관한 상기 식별된 음성 어시스턴트의 연관도를 조정하는 전자장치."}
{"patent_id": "10-2019-0152987", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6항에 있어서,상기 프로세서는,상기 수행된 음성 인식의 결과에 대한 사용자 만족도를 식별하고,상기 식별된 사용자 만족도에 기초하여 상기 식별된 음성 어시스턴트의 연관도를 증감시키는 전자장치."}
{"patent_id": "10-2019-0152987", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "공개특허 10-2021-0064594-3-제7항에 있어서,상기 프로세서는, 상기 사용자 만족도가 높다고 식별되는 것에 기초하여 상기 연관도에 제1조정값을 추가하고,상기 사용자 만족도가 낮다고 식별되는 것에 기초하여 상기 연관도에 상기 제1조정값보다 낮은 제2조정값을 추가함으로써, 상기 연관도를 조정하는 전자장치."}
{"patent_id": "10-2019-0152987", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1항에 있어서,상기 기 정의된 정보는, 복수의 다른 사용자 발화에 기초하여 획득된 정보를 포함하는 전자장치."}
{"patent_id": "10-2019-0152987", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제1항에 있어서,상기 프로세서는, 상기 기 정의된 정보의 데이터량이 문턱값보다 크지 않다고 식별되는 것에 기초하여 상기 식별된 음성 어시스턴트를 안내하는 UI를 표시하고, 상기 UI를 통해 상기 식별된 음성 어시스턴트가 선택되는 것에 응답하여 상기 사용자 발화에 관한 음성 인식이 수행되도록 하는 전자장치."}
{"patent_id": "10-2019-0152987", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제1항에 있어서,상기 프로세서는, 상기 기 정의된 정보의 데이터량이 문턱값보다 크지 않다고 식별되는 것에 기초하여 상기 복수의 음성 어시스턴트 각각에 의한 상기 음성 인식의 결과를 안내하는 UI를 표시하고, 상기 UI를 통해 선택된어느 하나의 상기 결과를 실행시키는 전자장치."}
{"patent_id": "10-2019-0152987", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "전자장치의 제어방법에 있어서,사용자 발화를 수신하는 단계와,수신된 사용자 발화의 키워드를 획득하는 단계와,복수의 음성 어시스턴트 및 복수의 키워드 사이의 연관도에 관해 기 정의된 정보에 기초하여, 상기 복수의 음성어시스턴트 중 상기 획득한 키워드와 연관도가 높은 음성 어시스턴트를 식별하는 단계와,상기 식별된 음성 어시스턴트에 기초하여 상기 사용자 발화에 관한 음성 인식을 수행하도록 하는 단계를 포함하는 전자장치의 제어방법."}
{"patent_id": "10-2019-0152987", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제12항에 있어서,상기 획득한 키워드에 대해 상기 정보에 정의된 각각의 상기 음성 어시스턴트의 연관도를 식별하고, 상기 식별된 연관도가 가장 높은 음성 어시스턴트를 선택하는 전자장치의 제어방법."}
{"patent_id": "10-2019-0152987", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제13항에 있어서,상기 획득한 키워드가 복수 개이면, 상기 복수의 획득한 키워드 별 상기 음성 어시스턴트의 연관도를 합산하며,상기 복수의 음성 어시스턴트 별 합산된 연관도를 비교하는 전자장치의 제어방법."}
{"patent_id": "10-2019-0152987", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제12항에 있어서,상기 기 정의된 정보는, 상기 전자장치의 사용 이력에 기반하여 마련되는 전자장치의 제어방법."}
{"patent_id": "10-2019-0152987", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "공개특허 10-2021-0064594-4-제15항에 있어서,상기 사용 이력은, 사용자 발화의 소정 키워드에 대한 상기 복수의 음성 어시스턴트 각각의 처리 이력을 카운트한 정보를 포함하는 전자장치의 제어방법."}
{"patent_id": "10-2019-0152987", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제12항에 있어서,상기 획득한 키워드에 관한 상기 식별된 음성 어시스턴트의 연관도를 조정하는 단계를 더 포함하는 전자장치의제어방법."}
{"patent_id": "10-2019-0152987", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제17항에 있어서,상기 수행된 음성 인식의 결과에 대한 사용자 만족도를 식별하고,상기 식별된 사용자 만족도에 기초하여 상기 식별된 음성 어시스턴트의 연관도를 증감시키는 전자장치의 제어방법."}
{"patent_id": "10-2019-0152987", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제18항에 있어서,상기 사용자 만족도가 높다고 식별되는 것에 기초하여 상기 연관도에 제1조정값을 추가하고, 상기 사용자 만족도가 낮다고 식별되는 것에 기초하여 상기 연관도에 상기 제1조정값보다 낮은 제2조정값을 추가함으로써, 상기연관도를 조정하는 전자장치의 제어방법."}
{"patent_id": "10-2019-0152987", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제12항에 있어서,상기 기 정의된 정보는, 복수의 다른 사용자 발화에 기초하여 획득된 정보를 포함하는 전자장치의 제어방법."}
{"patent_id": "10-2019-0152987", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "전자장치는, 사용자 발화를 수신하게 마련된 음성입력부와, 음성입력부를 통해 수신된 사용자 발화의 키워드를 획득하고, 복수의 음성 어시스턴트 및 복수의 키워드 사이의 연관도에 관해 기 정의된 정보에 기초하여, 복수의 음성 어시스턴트 중 상기 획득한 키워드와 연관도가 높은 음성 어시스턴트를 식별하고, 식별된 음성 어시스턴트 에 기초하여 사용자 발화에 관한 음성 인식을 수행하도록 하는 프로세서를 포함한다."}
{"patent_id": "10-2019-0152987", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 사용자 발화를 캡쳐하여 해당 발화의 명령어에 따른 동작을 실행 가능하게 마련된 전자장치 및 그 제 어방법에 관한 것으로서, 상세하게는 사용자 발화를 처리하기 위한 음성 어시스턴트(voice assistant)의 실행에 관련된 전자장치 및 그 제어방법에 관한 것이다."}
{"patent_id": "10-2019-0152987", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "소정의 정보를 특정 프로세스에 따라서 연산 및 처리하기 위해, 연산을 위한 CPU, 칩셋, 메모리 등의 전자부품 들을 기본적으로 포함하는 전자장치는, 처리 대상이 되는 정보 또는 사용 용도가 무엇인지에 따라서 다양한 종 류로 구분될 수 있다. 예를 들면, 전자장치에는 범용의 정보를 처리하는 PC나 서버 등의 정보처리장치, 영상데 이터를 처리하는 영상처리장치, 오디오를 처리하는 오디오장치, 가정 내 잡무를 수행하는 생활가전 등이 있다. 영상처리장치는 처리된 영상데이터를 자체 구비한 디스플레이 패널(display panel) 상에 영상으로 표시하는 디 스플레이장치로 구현될 수 있다. 전자장치는 사용자 입력을 수신하고, 수신된 사용자 입력에 대응하는 커맨드의 지시에 따라서 사전에 지정된 동 작을 수행한다. 사용자 입력의 방식은 인터페이스의 종류에 따라서 다양하다. 예를 들면, 전자장치는 버튼 또는 리모트 컨트롤러로부터 사용자 조작에 따른 제어신호를 수신하거나, 카메라를 통해 사용자의 제스처를 감지하거 나, 카메라를 통해 아이트랙킹(eye-tracking)을 하거나, 마이크로폰을 통해 사용자의 발화에 따른 음성신호를 수신할 수 있다. 특히, 전자장치는 사용자 발화의 음성인식처리 결과에 따른 커맨드를 획득하고, 획득한 커맨드 가 지시하는 동작을 수행할 수 있다. 전자장치가 사용할 수 있는 음성처리 방식 중에는 음성 어시스턴트라는 것 이 있다. 음성 어시스턴트는 사용자 발화를 텍스트로 변환하고, 변환된 텍스트를 딥 러닝 기반으로 그 내용을 분석하여, 분석된 내용에 따른 동작을 수행하도록 마련된다. 이와 같이, 음성 어시스턴트는 단순히 사용자 발화를 음성인식하여 커맨드를 식별하는 것을 넘어서, 보다 발전되고 향상된 발화의 해석 및 분석 결과를 제공하는 인공지능 기반 비서 서비스에 해당한다. 전자장치는 설계 방식에 따라서 복수의 음성 어시스턴트를 구비할 수 있으며, 이들 중에서 어느 하나의 음성 어 시스턴트를 사용하여 사용자 발화가 처리되도록 한다. 예를 들면, 전자장치는 마이크로폰을 통해 사용자 발화가 입력되면, 해당 사용자 발화가 트리거 워드(trigger word)를 포함하는지 여부를 체크한다. 트리거 워드는 음성 어시스턴트를 식별하도록 기 정의된 단어로서, 통상적으로는 사용자가 명령어보다 먼저 발화하도록 안내된다. 전자장치는 트리거 워드에 따라서 음성 어시스턴트가 식별되면, 식별된 음성 어시스턴트에 의해 사용자 발화가 처리되도록 한다. 그런데, 사용자가 트리거 워드를 추가로 말하는 것은 불편하기 때문에, 트리거 워드를 말하지 않고 명령어만 말 하는 경우도 있다. 또는, 각 음성 어시스턴트가 설계 방식에 따라서 특정한 명령어에 최적화될 수도 있는데, 사 용자가 트리거 워드를 통해 지정한 음성 어시스턴트보다 해당 발화 명령어를 처리하기에 적합한 음성 어시스턴 트가 있을 수도 있다. 이러한 점들을 고려하여, 사용자 발화의 처리에 적합한 음성 어시스턴트를, 사용자의 부 가적인 입력 없이도 제공할 수 있는 전자장치가 요구될 수 있다."}
{"patent_id": "10-2019-0152987", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 실시예에 따른 전자장치는, 사용자 발화를 수신하게 마련된 음성입력부와, 상기 음성입력부를 통해 수신된 사용자 발화의 키워드를 획득하고, 복수의 음성 어시스턴트 및 복수의 키워드 사이의 연관도에 관해 기 정의된 정보에 기초하여, 상기 복수의 음성 어시스턴트 중 상기 획득한 키워드와 연관도가 높은 음성 어시스턴 트를 식별하고, 상기 식별된 음성 어시스턴트에 기초하여 상기 사용자 발화에 관한 음성 인식을 수행하도록 하 는 프로세서를 포함한다. 또한, 상기 프로세서는, 상기 획득한 키워드에 대해 상기 정보에 정의된 각각의 상기 음성 어시스턴트의 연관도 를 식별하고, 상기 식별된 연관도가 가장 높은 음성 어시스턴트를 선택할 수 있다. 또한, 상기 프로세서는, 상기 획득한 키워드가 복수 개이면, 상기 복수의 획득한 키워드 별 상기 음성 어시스턴 트의 연관도를 합산하며, 상기 복수의 음성 어시스턴트 별 합산된 연관도를 비교할 수 있다. 또한, 상기 기 정의된 정보는, 상기 전자장치의 사용 이력에 기반하여 마련될 수 있다. 또한, 상기 사용 이력은, 사용자 발화의 소정 키워드에 대한 상기 복수의 음성 어시스턴트 각각의 처리 이력을 카운트한 정보를 포함할 수 있다. 또한, 상기 프로세서는, 상기 획득한 키워드에 관한 상기 식별된 음성 어시스턴트의 연관도를 조정할 수 있다. 또한, 상기 프로세서는, 상기 수행된 음성 인식의 결과에 대한 사용자 만족도를 식별하고, 상기 식별된 사용자 만족도에 기초하여 상기 식별된 음성 어시스턴트의 연관도를 증감시킬 수 있다. 또한, 상기 프로세서는, 상기 사용자 만족도가 높다고 식별되는 것에 기초하여 상기 연관도에 제1조정값을 추가 하고, 상기 사용자 만족도가 낮다고 식별되는 것에 기초하여 상기 연관도에 상기 제1조정값보다 낮은 제2조정값 을 추가함으로써, 상기 연관도를 조정할 수 있다. 또한, 상기 기 정의된 정보는, 복수의 다른 사용자 발화에 기초하여 획득된 정보를 포함할 수 있다. 또한, 상기 프로세서는, 상기 기 정의된 정보의 데이터량이 문턱값보다 크지 않다고 식별되는 것에 기초하여 상 기 식별된 음성 어시스턴트를 안내하는 UI를 표시하고, 상기 UI를 통해 상기 식별된 음성 어시스턴트가 선택되 는 것에 응답하여 상기 사용자 발화에 관한 음성 인식이 수행되도록 할 수 있다. 또한, 상기 프로세서는, 상기 기 정의된 정보의 데이터량이 문턱값보다 크지 않다고 식별되는 것에 기초하여 상 기 복수의 음성 어시스턴트 각각에 의한 상기 음성 인식의 결과를 안내하는 UI를 표시하고, 상기 UI를 통해 선 택된 어느 하나의 상기 결과를 실행시킬 수 있다.또한, 본 발명의 실시예에 따른 전자장치의 제어방법은, 사용자 발화를 수신하는 단계와, 수신된 사용자 발화의 키워드를 획득하는 단계와, 복수의 음성 어시스턴트 및 복수의 키워드 사이의 연관도에 관해 기 정의된 정보에 기초하여, 상기 복수의 음성 어시스턴트 중 상기 획득한 키워드와 연관도가 높은 음성 어시스턴트를 식별하는 단계와, 상기 식별된 음성 어시스턴트에 기초하여 상기 사용자 발화에 관한 음성 인식을 수행하도록 하는 단계 를 포함한다."}
{"patent_id": "10-2019-0152987", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하에서는 첨부도면을 참조하여 본 발명에 따른 실시예들에 관해 상세히 설명한다. 각 도면을 참조하여 설명하 는 실시예들은 특별한 언급이 없는 한 상호 배타적인 구성이 아니며, 하나의 장치 내에서 복수 개의 실시예가"}
{"patent_id": "10-2019-0152987", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "선택적으로 조합되어 구현될 수 있다. 이러한 복수의 실시예의 조합은 본 발명의 기술분야에서 숙련된 기술자가 본 발명의 사상을 구현함에 있어서 임의로 선택되어 적용될 수 있다. 만일, 실시예에서 제1구성요소, 제2구성요소 등과 같이 서수를 포함하는 용어가 있다면, 이러한 용어는 다양한 구성요소들을 설명하기 위해 사용되는 것이며, 용어는 하나의 구성요소를 다른 구성요소와 구별하기 위하여 사 용되는 바, 이들 구성요소는 용어에 의해 그 의미가 한정되지 않는다. 실시예에서 사용하는 용어는 해당 실시예 를 설명하기 위해 적용되는 것으로서, 본 발명의 사상을 한정하지 않는다. 또한, 본 명세서에서의 복수의 구성요소 중 \"적어도 하나(at least one)\"라는 표현이 나오는 경우에, 본 표현은 복수의 구성요소 전체 뿐만 아니라, 복수의 구성요소 중 나머지를 배제한 각 하나 혹은 이들의 조합 모두를 지 칭한다. 도 1은 전자장치가 복수의 음성 어시스턴트를 구비한 환경을 나타내는 예시도이다. 도 1에 도시된 바와 같이, 본 발명의 실시예에 따른 전자장치는 예를 들면 영상을 표시 가능한 디스플레이 장치로 구현될 수 있다. 디스플레이장치로 구현되는 경우에, 전자장치는 TV, 컴퓨터, 태블릿, 휴대용 미디 어 플레이어, 웨어러블 디바이스, 비디오 월, 전자액자 등을 포함한다. 다만, 실제로 전자장치는 디스플레 이장치 뿐만 아니라, 디스플레이를 구비하지 않은 셋탑박스 등의 영상처리장치이거나, 냉장고, 세탁기 등의 생 활가전이거나, 컴퓨터본체와 같은 정보처리장치 등 다양한 종류의 장치로 구현될 수 있다. 또한, 전자장치(10 0)는 하나의 고정된 위치에 설치되어 사용되는 장치일 수 있고, 사용자가 휴대하고 이동하면서 사용이 가능한 모바일기기일 수도 있다.전자장치는 사용자의 음성을 수신할 수 있다. 즉, 전자장치는 사용자가 소정의 명령어를 발화하면, 발화에 따른 음성신호를 획득한다. 발화에 따른 음성신호를 획득하기 위하여, 전자장치는 발화를 수집하는 마이크로폰을 구비하거나, 또는 마이크로폰을 가진 리모트 컨트롤러 또는 별도의 외부장치로부터 음성신호 를 수신할 수도 있다. 전자장치는 복수의 음성 어시스턴트(110, 120, 130)를 구비한다. 음성 어시스턴트(110, 120, 130)는 인공 지능에 기반해서 사용자 발화에 대한 내용 및 문맥의 분석을 통해 해당 발화의 의도를 판단하고, 판단 결과에 대응하는 동작이 수행되도록 처리하는 어플리케이션 서비스이다. 예를 들면, 음성 어시스턴트(110, 120, 130)는 전자장치에 입력되는 사용자 발화의 음성신호를 STT 처리하여 텍스트 데이터를 도출하고, 도출된 텍스트 데이터를 딥 러닝 또는 머신러닝에 기반하여 의미 분석을 수행함으로써 텍스트 데이터의 의미를 판단하며, 판단 한 의미에 맞는 서비스를 제공한다. 음성 어시스턴트(110, 120, 130)는, 전자장치 내부에서 대부분의 동작이 수행되는 On-Device 차원의 음성 어시스턴트일 수도 있고, 전자장치와 통신하는 서버(150, 160) 또는 외부장치와 연계하여 동작이 수 행되는 음성 어시스턴트(120, 130)일 수도 있다. 서버(150, 160)와 연계하여 동작하는 경우의 음성 어시스턴트(120, 130)는, 예를 들면 다음과 같이 동작한다. 음성 어시스턴트(120, 130)는 전자장치에 사용자 발화가 입력되면 사용자 발화의 음성신호를 서버(150, 160)에 전송한다. 서버(150, 160)는 수신되는 음성신호의 STT 처리 및 의미 분석을 수행하고, 분석 결과를 음성 어시스턴트(120, 130)에 전송한다. 음성 어시스턴트(120, 130)는 분석 결과에 대응하는 동작을 수행한다. 전자장치는 사용자 발화가 입력되면, 기 설정된 조건에 따라서 복수의 음성 어시스턴트(110, 120, 130) 중 어느 하나를 선택한다. 기 설정된 조건은 전자장치의 설계 방식에 따라서 여러 가지의 방식이 가능한데, 예를 들면 사용자 발화와 함께 입력되는 트리거 워드에 기초하여 음성 어시스턴트(110, 120, 130)를 선택할 수 있다. 트리거 워드는 각 음성 어시스턴트(110, 120, 130)를 식별하기 위해 사전에 정의된 단어이다. 전자장치 는 사용자 발화의 음성신호에서 트리거 워드를 식별하기 위하여, 사전 STT 처리를 수행할 수 있다. 그런데, 본 실시예에 따른 전자장치는 사용자 발화가 트리거 워드를 포함하지 않는 경우에 대응이 가능한 한편, 해당 사용자 발화에 보다 적절한 음성 어시스턴트(110, 120, 130)를 추천할 수도 있다. 이러한 동작을 위 해, 전자장치는 트리거 워드와는 별도의 기 설정된 조건에 대응하여 음성 어시스턴트(110, 120, 130)를 자 동으로 선택할 수 있는 바, 이러한 실시예에 관해서는 후술한다. 도 2는 전자장치의 구성 블록도이다. 도 2에 도시된 바와 같이, 전자장치은 통신부와, 신호입출력부와, 디스플레이부와, 사용자 입력부와, 저장부와, 마이크로폰과, 프로세서를 포함한다. 이하, 전자장치의 구성에 관해 설명한다. 본 실시예서는 전자장치가 TV인 경우에 관해 설명하지만, 전자장치는 다양한 종류의 장치로 구현될 수 있으므로, 본 실시예가 전자장치의 구성을 한정하는 것 은 아니다. 전자장치가 디스플레이장치로 구현되지 않는 경우도 가능하며, 이 경우의 전자장치는 디 스플레이부와 같은 영상 표시를 위한 구성요소들을 포함하지 않을 수 있다. 예를 들면 전자장치가 셋 탑박스로 구현되는 경우에, 전자장치는 신호입출력부를 통해 외부의 TV에 영상신호를 출력할 수 있다. 통신부는 다양한 종류의 유선 및 무선 통신 프로토콜에 대응하는 통신모듈, 통신칩 등의 구성요소들 중 적 어도 하나 이상을 포함하는 양방향 통신회로이다. 예를 들면, 통신부는 와이파이 방식에 따라서 AP와 무선 통신을 수행하는 무선통신모듈, 블루투스 등과 같은 1대 1 다이렉트 무선통신을 수행하는 무선통신모듈, IR 통 신을 위한 IR 모듈, 라우터 또는 게이트웨이에 유선 접속된 랜카드 등을 포함할 수 있다. 통신부는 네트워 크 상의 서버, 모바일기기 등의 외부장치와 통신할 수 있다. 또는, 통신부는 전자장치의 본체와 분리된 리모트 컨트롤러와 통신함으로써, 리모트 컨트롤러로부터 전송되는 신호를 수신할 수 있다. 신호입출력부는 셋탑박스 또는 광학미디어 재생장치와 같은 외부장치와 1:1 또는 1:N(N은 자연수) 방식으 로 유선 접속됨으로써, 해당 외부장치로부터 데이터를 수신하거나 또는 해당 외부장치에 데이터를 출력한다. 신 호입출력부는 예를 들면 HDMI 포트, DisplayPort, DVI 포트, 썬더볼트, USB 포트 등과 같이, 기 설정된 전송규격에 따른 커넥터 또는 포트 등을 포함한다.디스플레이부는 화면 상에 영상을 표시할 수 있는 디스플레이 패널을 포함한다. 디스플레이 패널은 액정 방식과 같은 수광 구조 또는 OLED 방식과 같은 자발광 구조로 마련된다. 디스플레이부는 디스플레이 패널 의 구조에 따라서 부가적인 구성을 추가로 포함할 수 있는데, 예를 들면 디스플레이 패널이 액정 방식이라면, 디스플레이부는 액정 디스플레이 패널과, 광을 공급하는 백라이트유닛과, 액정 디스플레이 패널의 액정을 구동시키는 패널구동기판을 포함한다. 사용자입력부는 사용자의 입력을 수행하기 위해 사용자가 조작할 수 있도록 마련된 다양한 종류의 입력 인 터페이스 관련 회로를 포함한다. 사용자입력부는 전자장치의 종류에 따라서 여러 가지 형태의 구성이 가능하며, 예를 들면 전자장치의 기계적 또는 전자적 버튼부, 터치패드, 센서, 카메라, 디스플레이부(21 3)에 설치된 터치스크린 등이 있다. 저장부는 디지털화된 데이터를 저장한다. 저장부는 전원의 제공 유무와 무관하게 데이터를 보존할 수 있는 비휘발성 속성의 스토리지(storage)와, 프로세서에 의해 처리되기 위한 데이터가 로딩되며 전원이 제 공되지 않으면 데이터를 보존할 수 없는 휘발성 속성의 메모리(memory)를 포함한다. 스토리지에는 플래시메모리 (flash-memory), HDD(hard-disc drive), SSD(solid-state drive) ROM(Read Only Memory) 등이 있으며, 메모리 에는 버퍼(buffer), 램(RAM; Random Access Memory) 등이 있다. 본 실시예에 따른 저장부는 음성신호를 처리하기 위한 복수의 음성 어시스턴트를 각기 실행시키는 복수의 어플리케이션이 저장될 수 있다. 저장부(21 5)에 저장된 어플리케이션이 프로세서에 의해 구동됨으로써 음성 어시스턴트가 실행된다. 마이크로폰 또는 음성입력부는 사용자 발화를 비롯한 외부 환경의 소리를 수집한다. 마이크로폰은 수 집된 소리의 음성신호를 프로세서에 전달한다. 프로세서는 인쇄회로기판 상에 장착되는 CPU, 칩셋, 버퍼, 회로 등으로 구현되는 하나 이상의 하드웨어 프 로세서를 포함하며, 설계 방식에 따라서는 SOC(system on chip)로 구현될 수도 있다. 프로세서는 전자장치 이 디스플레이장치로 구현되는 경우에 디멀티플렉서, 디코더, 스케일러, 오디오 DSP(Digital Signal Processor), 앰프 등의 다양한 프로세스에 대응하는 모듈들을 포함한다. 여기서, 이러한 모듈들 중 일부 또는 전체가 SOC로 구현될 수 있다. 예를 들면, 디멀티플렉서, 디코더, 스케일러 등 영상처리와 관련된 모듈이 영상 처리 SOC로 구현되고, 오디오 DSP는 SOC와 별도의 칩셋으로 구현되는 것이 가능하다. 본 실시예에 따른 프로세서는 소정의 경로를 통해 사용자 발화의 음성신호가 수신되면, 기 설정된 방법에 따라서 선택된 음성 어시스턴트를 실행시켜 해당 음성신호가 처리되도록 한다. 또는, 복수의 음성 어시스턴트가 백그라운드에서 동작하는 동안, 프로세서는 기 설정된 방법에 따라서 어느 하나의 음성 어시스턴트를 선택하고, 선택된 음성 어시스턴트에 의해 해당 음성신호가 처리되도록 할 수도 있다. 프로세서가 음성 어시스턴트를 선택하는 구체적 방법에 관해서는 후술한다. 전자장치는 다음과 같은 다양한 방법으로 사용자 발화 음성을 획득할 수 있다. 전자장치는 소리를 수집하는 마이크로폰을 구비할 수 있다. 마이크로폰을 통해 수집된 사용자 발화의 음성신호는 디지털신호로 변환되어 프로세서에 전달된다. 또는, 리모트 컨트롤러가 마이크로폰을 구비한 경우에, 전자장치는 마이크로폰을 통해 수 집된 사용자 발화의 음성신호를 리모트 컨트롤러로부터 통신부를 통해 수신할 수도 있다. 리모트 컨 트롤러는 마이크로폰을 통해 수집된 사용자 발화의 음성신호를 디지털신호로 변환하고, 이 디지털신 호를 통신부가 수신 가능한 프로토콜에 따라서 리모컨통신부를 통해 통신부로 전송한다. 또는, 모바일기기와 같은 범용기기의 경우에, 전자장치의 제어를 위해 마련된 어플리케이션을 인스톨 하여 실행시킴으로써 모바일기기는 리모트 컨트롤러와 유사하게 동작할 수 있다. 모바일기기는 상기한 어플리케이션이 실행되는 동안 마이크로폰을 통해 수집된 사용자 발화의 음성신호를 디지털신호로 변환하여, 모바일통신부를 통해 통신부로 전송한다. 이하, 본 발명의 실시예에 따른 프로세서가 복수의 음성 어시스턴트 중 어느 하나를 선택하여 사용자 발화 를 처리하도록 하는 방법에 관해 설명한다. 도 3은 전자장치의 제어방법을 나타내는 플로우차트이다. 도 3에 도시된 바와 같이, 하기 동작은 전자장치의 프로세서에 의해 수행된다. 또한, 본 전자장치는 복수의 음 성 어시스턴트를 구비한다.310 단계에서 전자장치는 사용자 발화를 수신한다. 320 단계에서 전자장치는 수신된 사용자 발화의 텍스트를 획득한다. 330 단계에서 전자장치는 획득한 텍스트로부터 해당 텍스트를 구성하는 하나 이상의 키워드를 획득한다. 340 단계에서 전자장치는 복수의 음성 어시스턴트 및 복수의 키워드 사이의 연관도에 관해 기 정의된 정보를 획 득한다. 본 정보는, 한 가지 예를 들면 각 음성 어시스턴트 별로 복수의 키워드 각각에 대한 스코어(score)가 기록된 테이블을 포함한다. 350 단계에서 전자장치는 획득한 정보에 기초하여, 복수의 음성 어시스턴트 중 상기한 키워드와 연관도가 높은 음성 어시스턴트를 식별한다. 식별 방법의 예를 들면, 전자장치는 테이블에서 사용자 발화의 텍스트에 포함된 키워드의 스코어가 가장 높은 음성 어시스턴트를 선택할 수 있다. 360 단계에서 전자장치는 식별된 음성 어시스턴트에 기초하여 사용자 발화에 관한 음성 인식이 수행되도록 한다. 이로써, 전자장치는 사용자가 트리거 워드를 발화하지 않거나 또는 별도의 UI를 통해 특정한 음성 어시스턴트를 지정하지 않더라도, 사용자 발화를 처리하기에 적절한 음성 어시스턴트를 자동으로 식별할 수 있다. 또는, 전자 장치는 사용자가 사용자 발화를 처리할 음성 어시스턴트를 지정하는 것과 무관하게, 해당 사용자 발화를 처리하 기에 적절한 음성 어시스턴트를 선택하여 사용자에게 맞춤형 서비스를 제공할 수 있다. 한편, 전자장치의 프로세서는 상기와 같이 사용자 발화의 키워드를 획득하고, 복수의 음성 어시스턴트 및 복수 의 키워드 사이의 연관도에 관해 기 정의된 정보에 기초하여, 획득한 키워드와 연관도가 높은 음성 어시스턴트 를 식별하고, 식별된 음성 어시스턴트에 기초하여 사용자 발화에 관한 음성 인식을 수행하도록 하는 동작을 수 행하기 위한 데이터 분석, 처리, 및 결과 정보 생성 중 적어도 일부를 규칙 기반 또는 인공지능(Artificial Intelligence) 알고리즘으로서 기계학습, 신경망 네트워크(neural network), 또는 딥러닝 알고리즘 중 적어도 하나를 이용하여 수행할 수 있다. 일 예로, 전자장치의 프로세서는 학습부 및 인식부의 기능을 함께 수행할 수 있다. 학습부는 학습된 신경망 네 트워크를 생성하는 기능을 수행하고, 인식부는 학습된 신경망 네트워크를 이용하여 데이터를 인식(또는, 추론, 예측, 추정, 판단)하는 기능을 수행할 수 있다. 학습부는 신경망 네트워크를 생성하거나 갱신할 수 있다. 학습 부는 신경망 네트워크를 생성하기 위해서 학습 데이터를 획득할 수 있다. 일 예로, 학습부는 학습 데이터를 전 자장치의 저장부 또는 외부로부터 획득할 수 있다. 학습 데이터는, 신경망 네트워크의 학습을 위해 이용되는 데 이터일 수 있으며, 상기한 동작을 수행한 데이터를 학습데이터로 이용하여 신경망 네트워크를 학습시킬 수 있다. 학습부는 학습 데이터를 이용하여 신경망 네트워크를 학습시키기 전에, 획득된 학습 데이터에 대하여 전처리 작 업을 수행하거나, 또는 복수 개의 학습 데이터들 중에서 학습에 이용될 데이터를 선별할 수 있다. 일 예로, 학 습부는 학습 데이터를 기 설정된 포맷으로 가공하거나, 필터링하거나, 또는 노이즈를 추가/제거하여 학습에 적 절한 데이터의 형태로 가공할 수 있다. 학습부는 전처리된 학습 데이터를 이용하여 상기한 동작을 수행하도록 설정된 신경망 네트워크를 생성할 수 있다. 학습된 신경망 네트워크는, 복수의 신경망 네트워크(또는, 레이어)들로 구성될 수 있다. 복수의 신경망 네트워 크의 노드들은 가중치를 가지며, 복수의 신경망 네트워크들은 일 신경망 네트워크의 출력 값이 다른 신경망 네 트워크의 입력 값으로 이용되도록 서로 연결될 수 있다. 신경망 네트워크의 예로는, CNN (Convolutional Neural Network), DNN (Deep Neural Network), RNN (Recurrent Neural Network), RBM (Restricted Boltzmann Machine), DBN (Deep Belief Network), BRDNN (Bidirectional Recurrent Deep Neural Network) 및 심층 Q-네 트워크 (Deep Q-Networks)과 같은 모델을 포함할 수 있다. 한편 인식부는 상기한 동작을 수행하기 위해, 타겟 데이터를 획득할 수 있다. 타겟 데이터는 전자장치의 저장부 또는 외부로부터 획득된 것일 수 있다. 타겟 데이터는 신경망 네트워크의 인식 대상이 되는 데이터일 수 있다. 인식부는 타겟 데이터를 학습된 신경망 네트워크에 적용하기 전에, 획득된 타겟 데이터에 대하여 전처리 작업을 수행하거나, 또는 복수 개의 타겟 데이터들 중에서 인식에 이용될 데이터를 선별할 수 있다. 일 예로, 인식부는 타겟 데이터를 기 설정된 포맷으로 가공하거나, 필터링 하거나, 또는 노이즈를 추가/제거하여 인식에 적절한 데 이터의 형태로 가공할 수 있다. 인식부는 전처리된 타겟 데이터를 신경망 네트워크에 적용함으로써, 신경망 네 트워크로부터 출력되는 출력값을 획득할 수 있다. 인식부는 출력값과 함께, 확률값 또는 신뢰도값을 획득할 수있다. 이하, 복수의 음성 어시스턴트 및 복수의 키워드 사이의 연관도에 관해 기 정의된 정보의 예시에 관해 구체적으 로 설명한다. 도 4는 전자장치가 참조하게 마련된 테이블의 예시도이다. 도 4에 도시된 바와 같이, 전자장치는 복수의 음성 어시스턴트 및 복수의 키워드 사이의 연관도를 나타내는 테 이블을 획득할 수 있다. 여기서, 테이블에 포함된 여러 가지 키워드는 다양한 방법에 따라서 선정될 수 있다. 예를 들면, 통상적으로 사용자들이 많이 사용하는 단어들이 수집된 이후, 해당 단어들 중에서 사용 빈 도에 따라서 소정 순위 이상의 단어들이 선정될 수 있다. 만일 서버에 의해 단어들이 선정된다면, 서버는 복수 의 클라이언트로부터 명령어의 사용 이력을 획득하고, 획득한 여러 사용 이력으로부터 사용 빈도가 많은 단어들 을 선정할 수 있다. 또는, 단어의 속성 중에서 조사, 부사, 대명사 등을 제외하고 명사 위주로 단어들이 선정될 수 있다. 본 테이블은 사전에 정의된 복수의 단어 각각에 대해, 전자장치에 구비된 복수의 음성 어시스턴트 별로 기 록된 스코어를 포함한다. 본 테이블에 나타난 사항들은 실시예를 간결하고 명확히 설명하기 위한 예시일 뿐이며, 해당 사항들이 복수의 음성 어시스턴트 및 복수의 키워드 사이의 연관도에 관한 정보의 형태, 방식, 내 용을 한정하는 것은 아니다. 예를 들어, \"오늘\", \"날씨\", \"추천\", \"방송\"의 단어들이 있고, 전자장치에 제1어시스턴트 및 제2어시스턴트의 두 가지 음성 어시스턴트가 구비된 경우를 고려할 수 있다. 이러한 경우를 반영하여, 테이블은 각 단어에 대한 제1어시스턴트의 스코어 및 제2어시스턴트의 스코어를 포함한다. 본 테이블에서 \"오늘\"이라는 단어에 대해, 제1어시스턴트는 10의 스코어를 나타내며, 제2어시스턴트는 20의 스코어를 나타낸다. 테이블의 스코어는 여러 가지 방법에 따라서 산정될 수 있다. 예를 들면, 본 스코어는 전자장치의 사용자 이력을 반영하여 마련될 수 있다. 여기서, 사용자 이력은 특정 단어를 사용자가 발화했을 때 특정 음성 어시스 턴트가 처리한 회수 이력의 카운트에 대응한다. 스코어는 단어의 누적된 처리 회수와 동일한 수치로 마련되거나, 단어의 누적된 처리 회수에 기 설정된 가중치를 곱한 수치로 마련될 수 있다. 예를 들어 단어 \"오 늘\"을 제1어시스턴트가 처리한 누적 회수가 10회라고 하면, 테이블에서 \"오늘\"에 대한 제1어시스턴트의 스 코어는 10으로 산정될 수 있다. 또는, 동일한 조건 하에서 사전 정의된 가중치가 3이라고 하면, 테이블에 서 \"오늘\"에 대한 제1어시스턴트의 스코어는 30으로 산정될 수 있다. 즉, 테이블에 기록된 스코어는, 특정 음성 어시스턴트가 특정 단어를 얼마나 많이 처리하였는가를 나타낸 다. 음성 어시스턴트가 AI 기반으로 설계된 경우에는 학습 이력이 많을수록 음성 처리 결과를 사용자 의도에 맞 출 수 있는 정확도가 올라가므로, 스코어가 높은 음성 어시스턴트는 대응 단어를 보다 정확히 처리할 것으로 기 대된다. 이러한 관점에서, 소정 단어에 대한 스코어가 높은 음성 어시스턴트는 해당 단어의 처리에 보다 적합하 다고 간주된다. 여기서, 전자장치는 본 테이블을 초기부터 생성하거나, 제조 단계에서 디폴트로 마련된 테이블을 사 용 이력에 따라서 업데이트하여 사용하거나, 서버로부터 제공받은 테이블을 사용 이력에 따라서 업데이트 하여 사용할 수 있다. 어떠한 경우라도, 전자장치는 사용 이력에 따라서 테이블의 개별 스코어를 업데이트 함으로써, 사용자에 최적화된 테이블을 구현할 수 있다. 이하, 전자장치가 테이블을 사용하여 사용자 발화에 보다 적합한 음성 어시스턴트를 식별하는 방법에 관해 설명한다. 도 5는 도 4의 테이블을 참조하여 전자장치가 음성 어시스턴트를 식별하는 원리를 나타내는 예시도이다. 도 5에 도시된 바와 같이, 하기 동작은 전자장치의 프로세서에 의해 수행된다. 또한, 본 전자장치는 복수의 음 성 어시스턴트를 구비하며, 도 4에 예시된 바와 같은 테이블(400, 도 4 참조)을 획득할 수 있다. 510 단계에서 전자장치는 사용자 발화의 텍스트로부터 하나 이상의 단어를 식별한다. 예를 들어 사용자가 \"오늘 날씨 어때\"라고 발화한 경우를 고려한다. 전자장치는 사용자 발화의 텍스트로부터 하나 이상의 단어를 식별한다. 단어의 식별 기준은 여러 가지가 가능하며, 한 가지 예시로서 전자장치는 텍스트에 포함된 단어들 중 에서 테이블(400, 도 4 참조)에 미리 정의된 단어를 식별한다. 본 예시의 경우에, 전자장치는 \"오늘\" 및 \"날 씨\"의 두 가지 단어를 식별할 수 있다.520 단계에서 전자장치는 복수의 단어에 대한 복수의 음성 어시스턴트의 스코어가 정의된 테이블을 획득한다. 본 실시예에서는 앞선 도 4에서 예시된 테이블을 참조하도록 한다. 530 단계에서 전자장치는 식별된 하나 이상의 단어의 스코어를 테이블로부터 식별한다. 전자장치는 식별한 단어 \"오늘\" 및 \"날씨\" 각각에 대해, 제1어시스턴트의 스코어 및 제2어시스턴트의 스코어를 체크한다. 단어 \"오늘\"에 대한 제1어시스턴트의 스코어는 10, 제2어시스턴트의 스코어는 20이다. 단어 \"날씨\"에 대한 제1어시스턴트의 스 코어는 30, 제2어시스턴트의 스코어는 10이다. 540 단계에서 전자장치는 각 단어 별로 식별된 복수의 음성 어시스턴트의 스코어의 총합을 서로 비교한다. 예를 들면, 제1어시스턴트의 스코어의 총합은 10+30=40이며 제2어시스턴트의 스코어의 총합은 20+10=30이므로, 제1어 시스턴트의 스코어의 총합이 제2어시스턴트의 스코어의 총합보다 크다. 550 단계에서 전자장치는 총합이 가장 높은 음성 어시스턴트를 식별한다. 사용자 발화가 \"오늘 날씨 어때\"인 경 우에는, 제1어시스턴트의 스코어의 총합이 제일 크다. 560 단계에서 전자장치는 식별된 음성 어시스턴트에 의해 사용자 발화가 처리되도록 한다. 예를 들어 제1어시스 턴트가 식별되면, 전자장치는 제1어시스턴트에 의해 사용자 발화의 음성 인식이 수행되도록 한다. 제1어시스턴 트는 필요한 경우에 사용자 발화의 음성신호를 서버에 전송함으로써 음성 인식이 수행되도록 할 수 있다. 570 단계에서 전자장치는 음성 어시스턴트의 식별에 따라서, 테이블에서 식별된 단어에 대한 해당 음성 어시스 턴트의 스코어를 조정한다. 즉, 전자장치는 현재 수행된 동작의 이력을 테이블에 반영하여 업데이트한다. 이상 실시예에서는 전자장치가 사용자 발화로부터 식별된 각 단어 별로 음성 어시스턴트의 스코어를 테이블로부 터 식별하고, 음성 어시스턴트 단위로 스코어의 총합을 비교하여 총합이 가장 높은 음성 어시스턴트를 최종적으 로 선택하는 예시에 관해 설명하였다. 그러나, 전자장치가 스코어에 기초하여 어느 하나의 음성 어시스턴트를 선택하는 방법은 단지 복수의 스코어의 총합을 비교하는 것만으로 한정된 것은 아니며, 다양한 변형 방법이 적 용될 수 있다. 예를 들면, 앞선 실시예에서는 식별된 복수의 단어 사이에서 비중의 차이가 없이 단순히 각 스코어를 합산하였 다. 그러나, 설계 방식에 따라서는 식별된 단어들 사이에 비중의 차이를 두어서, 보다 중요하다고 보이는 단어 에 가중치를 추가적으로 부여하는 방법도 가능하다. 예를 들어 사용자 발화로부터 \"오늘\" 및 \"날씨\"라는 단어가 식별되었고, 단어 \"오늘\"의 스코어에 대해서는 1.2 의 수치를 곱하고 단어 \"날씨\"의 스코어에 대해서는 1.0의 수치를 곱하도록 사전에 설정되어 있다고 가정한다. 이는, 단어 \"오늘\"을 단어 \"날씨\"에 비해 중요도를 높여서 반영한 예시에 해당한다. 도 4의 테이블을 예로 들 경우에, 제1어시스턴트의 결과값은 10*1.2+30*1.0=42가 되고, 제2어시스턴트의 결과값은 20*1.2+10*1.0=34가 된 다. 이러한 방식으로 복수의 음성 어시스턴트의 결과값을 비교하여, 가장 큰 결과값의 음성 어시스턴트가 선택 될 수도 있다. 한편, 앞선 실시예에서의 570 단계는 현재 수행된 동작의 결과를 테이블에 반영함으로써 테이블을 업데이트하는 경우이다. 이하, 이러한 동작의 예시에 관해 설명한다. 도 6은 도 4의 테이블을 전자장치가 사용자 발화의 처리 결과를 반영하여 업데이트한 결과를 나타내는 예시도이 다. 도 6에 도시된 바와 같이, 전자장치는 사용자 발화에 적합한 음성 어시스턴트를 식별하면, 식별한 결과를 반영 하여 테이블을 업데이트할 수 있다. 예를 들어 사용자 발화가 \"오늘 날씨 어때\"이고, 이로부터 식별된 단 어가 \"오늘\" 및 \"날씨\"이고, 복수의 음성 어시스턴트 중에서 최종적으로 제1어시스턴트가 선택된 경우를 고려한 다. 전자장치는 테이블에서, 사용자 발화로부터 식별된 단어에 대해, 최종적으로 선택된 음성 어시스턴트의 스 코어를 체크한다. 식별된 단어는 \"오늘\" 및 \"단어\"이고, 선택된 음성 어시스턴트는 제1어시스턴트이므로, 전자 장치는 테이블에서 \"오늘\"에 대한 스코어 10과 \"날씨\"에 대한 스코어 30을 확인할 수 있다. 전자장치는 식별된 단어는 \"오늘\" 및 \"단어\"에 대한 제1어시스턴트의 스코어에 한하여, 해당 스코어를 기 설정 된 수치만큼 추가시킨다. 이 경우에, \"오늘\"에 대한 제1어시스턴트의 스코어는 10에서 11로 증가하며, \"날씨\"에 대한 제1어시스턴트의 스코어는 30에서 31로 증가한다. 본 실시예에서는 스코어의 증가치가 1인 것으로 설명하 였으나, 증가치의 구체적인 수치는 한정되지 않는다. 스코어의 증가치는 설계 방식에 따라서, 다양한 조건에 대응하여 상이한 수치가 적용될 수 있다. 또한, 스코어의 값이 조정되는 방식은 증가로만 한정할 수 없으며, 조건 에 따라서는 스코어가 차감되는 방식도 가능하다. 스코어의 설계 방식의 예시에 관해서는 후술한다. 이하, 전자장치가 초기 테이블을 획득하는 방식의 실시예에 관해 설명한다. 도 7은 전자장치가 초기 테이블을 획득하는 예시를 나타내는 구성 블록도이다. 도 7에 도시된 바와 같이, 전자장치는 서버와 통신 가능하도록 네트워크에 접속된다. 서버는 다 수의 클라이언트와 통신을 수행한다. 전자장치 또한 이러한 다수의 클라이언트 중 하나이며, 다 만 상호 구별을 위해 용어를 상이하게 지정한 것에 불과하다. 전자장치는 앞선 실시예에서 설명한 바와 같은 테이블을 구축함에 있어서, 초기부터 사용 이력을 누 적시켜 테이블을 생성할 수도 있다. 다만, 이러한 경우에는 테이블의 신뢰도를 보장할 수 있도록 어 느 정도 이상의 데이터량이 확보되기까지, 사용 이력이 누적될 시간이 필요하다. 다른 방법으로서, 전자장치의 제조 단계에서 전자장치의 저장부 내에 초기값을 가진 테이블에 저장되고, 제품으로 출시되는 경우도 가능하다. 또 다른 방법으로서, 전자장치는 서버로부터 테이블을 제공받고, 제공받은 테이블의 초기 값에 사용 이력을 추가 반영하여 업데이트함으로써 테이블을 구축하는 것도 가능하다. 서버는 저장된 테이블을 전자장치에만 일방향으로 제공하는 경우도 가능하다. 또는, 서버는 전자장치로부 터 테이블의 업데이트에 관한 정보를 피드백받아서 기 저장된 테이블을 업데이트하는 것도 가능하다. 서버는 전자장치와 동일하게 통신 가능하게 연결된 다수의 클라이언트로부터 각 클라이언트 가 저장한 테이블에 관한 정보를 수집한다. 각 클라이언트는 개별적으로 테이블을 저장하 고 있으며, 자체적인 사용 이력에 기초하여 개별적으로 가진 테이블을 업데이트한다. 각 테이블의 업 데이트 방법은 앞선 실시예에서 설명한 바와 같다. 각 클라이언트는 주기적으로, 또는 서버로부터의 요청에 응답하여, 테이블의 현재 정보를 서버 에 제공한다. 테이블의 현재 정보는, 예를 들면 사전에 정의된 단어들, 복수의 음성 어시스턴트의 식 별명, 각 단어 별 음성 어시스턴트의 스코어 등을 포함한다. 서버는 각 클라이언트로부터 획득한 테이블의 정보에 기초하여, 테이블을 새로 생성하거나 또는 테이블을 업데이트한다. 테이블의 생성 또는 업데이트 방법은 다양한 설계 방식이 적용될 수 있 다. 예를 들면, 서버는 각 클라이언트로부터 수집한 정보로부터 특정 단어에 대한 동일 음성 어시스 턴트의 스코어들을 획득하고, 획득한 스코어를 합산값을 클라이언트의 수치로 나눈 값을, 해당 단어의 해 당 음성 어시스턴트의 스코어로 도출할 수 있다. 이러한 방법은 하나의 예시일 뿐이며, 테이블의 값을 획 득하기 위한 방법을 한정하는 것이 아니다. 서버는 전자장치의 요청에 응답하여, 또는 전자장치가 서버에 연결된 것으로 감지되는 것 에 응답하여, 이와 같이 구축한 테이블을 전자장치에 제공할 수 있다. 서버는 앞서 클라이언트 의 경우와 동일하게 전자장치로부터 테이블의 업데이트된 정보를 획득하여 테이블에 반영 할 수 있다. 한편, 전자장치가 테이블에 기초하여 음성 어시스턴트를 식별함에 있어서, 식별 결과의 신뢰도를 보장하기 위해 서는 테이블의 데이터량이 소정의 문턱값보다 높아야 한다. 만일 테이블의 데이터량이 문턱값보다 낮다면, 전자 장치는 식별 결과를 UI로 표시할 수도 있다. 이하, 이러한 실시예에 관해 설명한다. 도 8은 전자장치가 식별 결과의 UI를 표시하는 예시도이다. 도 8에 도시된 바와 같이, 전자장치는 수신되는 사용자 발화에 적합한 음성 어시스턴트를 식별하고, 식별 결과를 나타내는 UI를 표시한다. UI는 적어도 식별된 음성 어시스턴트가 무엇인지 나타내는 정보를 포함하며, 수신되는 사용자 발화의 텍스트를 추가적으로 포함할 수 있다. 예를 들어 \"오늘 날씨 어때\"라는 사용 자 발화가 수신되었고, 이에 대하여 복수의 음성 어시스턴트 중 제1어시스턴트가 선택되었다면, 전자장치 는 이러한 선택 결과를 알리는 UI를 표시한다. 본 UI는 전자장치의 설정 여부에 따라서 상황에 무관하게 표시될 수 있고, 선택적으로 표시될 수도 있다. 예를 들면, 전자장치는 기 저장된 테이블에 기초하여 사용자 발화에 적합한 음성 어시스턴트를 식별 함에 있어서, 테이블의 데이터량이 문턱값보다 큰지 여부를 식별한다. 테이블의 데이터량이 문턱값보다 큰 경우는, 본 테이블을 사용한 식별 결과가 충분히 신뢰도를 가진다는 것을 의미한다. 반면에, 테이블의 데이터량이 문턱값보다 크지 않은 경우는, 본 테이블을 사용한 식별 결과에 대한 신뢰도가 높지 않다는 것을 의미한다. 이에, 전자장치는 테이블의 데이터량이 문턱값보다 크면, UI를 표시하지 않고, 식별된 음성 어시스턴 트에 의해 사용자 발화가 처리되도록 한다. 반면에, 전자장치는 테이블의 데이터량이 문턱값보다 크지 않 으면, UI를 표시함으로써 사용자에게 식별 결과가 긍정적인지 여부를 선택하도록 한다. 이를 위하여, UI는 식별 결과를 안내하는 한편, 식별 결과가 사용자에게 있어서 긍정적인지 (즉, 사용자가 식별 결과를 수용할 수 있는지), 아니면 부정적인지 (즉, 사용자는 식별 결과를 수용할 수 없으며, 다른 음성 어시스턴트에 의한 처리를 원하는지) 여부를 선택하도록 하는 옵션을 제공할 수 있다. 전자장치는 UI에서 식별 결과에 대한 긍정적인 옵션이 선택되면, 앞선 실시예와 같이 식별된 음성 어 시스턴트에 의해 사용자 발화가 처리되도록 하고, 테이블의 스코어를 업데이트한다. 반면에, 전자장치는 UI에서 식별 결과에 대한 부정적인 옵션이 선택되면, 다른 음성 어시스턴트를 식별하기 위한 새로운 프로 세스를 진행하거나, 또는 사용자가 원하는 음성 어시스턴트를 지정하도록 마련된 별도의 UI를 제공할 수 있다. 한편, 전자장치는 음성 어시스턴트의 식별 결과에 대한 사용자의 반응(즉, 식별 결과에 대한 긍정적인 반응 또 는 부정적인 반응, 또는 식별 결과에 대한 사용자의 만족도가 높은 경우 또는 낮은 경우)을, 다양한 방법을 통 해 획득할 수 있다. 예를 들면, 전자장치는 본 실시예와 같이 UI를 통해 제공되는 선택 옵션을 통해, 식별 결과에 대해 사용자가 긍정적인지(즉, 사용자의 만족도가 높은지) 또는 부정적인지(즉, 사용자의 만족도가 낮 은지) 여부를 식별할 수 있다. 또는, 전자장치는 사용자의 제1발화에 대해 식별된 음성 어시스턴트에 의해 제1발화의 처리 결과를 제1시점에 제공하고, 제1시점으로부터 기 설정된 시간 이내의 제2시점에, 제1발화와 동일한 내용의 제2발화가 수신되는 것 을 식별할 수도 있다. 이는, 사용자가 제1시점에 제공된 제1발화의 처리 결과에 만족하지 않았다는 것을 의미한 다. 따라서, 이와 같이 식별된 경우에, 전자장치는 사용자가 제1시점에 제공된 제1발화의 처리 결과를 부정적으 로 반응한 것으로 식별할 수 있다. 이와 반대로, 전자장치는 제1발화의 처리 결과를 제1시점에 제공한 이후, 제1시점으로부터 기 설정된 시간 이내 에 제1발화와 동일한 내용의 제2발화가 수신되지 않을 수도 있다. 이러한 경우에, 전자장치는 사용자가 제1시점 에 제공된 제1발화의 처리 결과를 긍정적으로 반응한 것으로 식별할 수 있다. 또는, 전자장치는 제1발화의 처리 결과를 제1시점에 제공한 이후, 제1시점으로부터 기 설정된 시간 이내에 취소 또는 정지 등과 같은 명령어가 입력되면, 사용자가 제1시점에 제공된 제1발화의 처리 결과를 부정적으로 반응한 것으로 식별할 수 있다. 이와 같이 식별되는 사용자의 반응은, 테이블의 스코어를 업데이트함에 있어서 스코어에 대한 가중치를 상이하 게 하는 방식으로 테이블에 대해 반영될 수 있다. 이하, 이러한 실시예에 관해 설명한다. 도 9는 전자장치가 사용자의 반응에 대응하여 테이블의 스코어를 조정하는 원리를 나타내는 예시도이다. 도 9에 도시된 바와 같이, 전자장치는 사용자 발화가 입력되면 사용자 발화로부터 기 정의된 단어를 식별하고, 테이블을 참조하여 해당 단어에 대한 각 음성 어시스턴트의 스코어를 식별하고, 식별 결과에 따라서 음성 어시스턴트를 선택하여 사용자 발화가 처리되도록 하고, 선택 결과에 따라서 테이블의 스코어를 조정한다. 이러한 과정은 앞선 실시예에서 설명한 바와 같다. 예를 들어 \"오늘 날씨 어때\"라는 사용자 발화에 대해 \"오늘\" 및 \"날씨\"의 두 가지 단어가 식별되고, 결과적으로 테이블에 기초하여 복수의 음성 어시스턴트 중 제1어 시스턴트가 선택된 경우를 고려한다. 전자장치는 제1어시스턴트에 의한 \"오늘 날씨 어때\"라는 사용자 발화의 처리 결과에 대한 사용자의 반응을 식별 한다. 전자장치는 앞서 설명한 바와 같은 다양한 방법에 따라서 사용자 반응이 긍정적인지 아니면 부정적인지 여부를 식별할 수 있다. 전자장치는 사용자 발화의 제1어시스턴트에 의한 처리 결과에 대한 사용자 반응이 긍정적이라고 식별되면, 테이 블에서 사용자 발화로부터 식별된 단어에 대한 제1어시스턴트의 스코어에 기 설정된 제1가중치를 추가함으 로써 테이블을 업데이트한다. 예를 들어 테이블에서 제1어시스턴트의 \"오늘\"에 대한 스코어가 100이 고 \"날씨\"에 대한 스코어가 300이라고 가정한다. 사용자 반응이 긍정적인 경우의 제1가중치가 +5라면, 업데이트 된 테이블에서 제1어시스턴트의 \"오늘\"에 대한 스코어는 105이고 \"날씨\"에 대한 스코어는 305가 된다. 반면에, 전자장치는 사용자 발화의 제1어시스턴트에 의한 처리 결과에 대한 사용자 반응이 부정적이라고 식별되 면, 테이블의 해당 스코어에 제1가중치보다 낮은 제2가중치를 추가함으로써 테이블을 업데이트한다. 예를 들어 제2가중치가 +1이라면, 업데이트된 테이블에서 제1어시스턴트의 \"오늘\"에 대한 스코어는 101이 고 \"날씨\"에 대한 스코어는 301이 된다. 또는, 전자장치는 전자장치는 사용자 발화의 제1어시스턴트에 의한 처리 결과에 대한 사용자 반응이 부정적이라 고 식별되면, 테이블의 해당 스코어에 마이너스 값을 가진 제3가중치를 추가함으로써 테이블을 업데 이트할 수도 있다. 예를 들어 제3가중치가 -3이라면, 업데이트된 테이블에서 제1어시스턴트의 \"오늘\"에 대 한 스코어는 97이고 \"날씨\"에 대한 스코어는 297이 된다. 이와 같이 사용자 발화의 처리 결과에 대한 사용자의 반응에 따라서, 테이블의 스코어에 대한 가중치를 상 이하게 적용함으로써, 테이블에 사용자의 취향 및 선호도가 보다 정확하게 반영되도록 할 수 있다. 한편, 본 실시예에서는 처리 결과에 대한 사용자의 반응에 대응하여 스코어에 대한 가중치를 상이하게 적용하는 경우이지만, 단지 사용자의 반응에만 한정하여 스코어에 대한 가중치가 상이하게 마련되는 것은 아니다. 예를 들면 전자장치는 발화를 하는 사용자를 식별하고, 식별된 사용자에 따라서 상기한 스코어의 가중치를 상이하게 적용할 수 있다. 사용자를 식별하는 방법으로는 여러 가지가 가능하다. 전자장치는 현재 로그인된 계정에 기반 하여 사용자를 식별할 수 있고, 또는 사용자 발화의 음성신호의 파형을 분석하여 분석 결과에 대응하는 프로파 일의 사용자를 식별할 수도 있다. 스코어에 대한 가중치를 상이하게 부여하는 방식 중 하나로서, 전자장치는 동의어 관리를 할 수도 있다. 이하, 이러한 실시예에 관해 설명한다. 도 10은 전자장치가 동의어 관리를 통해 테이블의 스코어를 조정하는 원리를 나타내는 예시도이다. 도 10에 도시된 바와 같이, 예를 들어 \"오늘 날씨 어때\"라는 사용자 발화에 대해 \"오늘\" 및 \"날씨\"의 두 가지 단어가 식별되고, 결과적으로 테이블의 스코어에 기초하여 복수의 음성 어시스턴트 중 제1어시스턴트가 선택된 경우를 고려한다. 예를 들어 식별된 단어의 스코어에 대한 제1가중치가 +3으로 지정되어 있다면, 전자장 치는 테이블에서 제1어시스턴트의 \"오늘\"에 대한 스코어인 100을 103으로 조정하고, 제1어시스턴트의 \"날 씨\"에 대한 스코어인 300을 303으로 조정한다. 한편, 전자장치는 테이블에 마련된 단어들 중에, 식별된 단어와의 동의어가 있는지 여부를 식별한다. 예 를 들어 테이블에 기 정의된 단어들 중에는 \"날씨(weather)\"과 동의어로서 \"기후(climate)\"가 있다고 가 정한다. 전자장치는 식별된 단어의 동의어에 대해서는, 식별된 단어의 스코어에 대한 제1가중치보다 작은 제2가중치를 부여하도록 마련될 수 있다. 예를 들어 제2가중치가 +3보다 작은 +1로 지정되어 있다면, 전자장치는 테이블 에서 제1어시스턴트의 \"기후\"에 대한 스코어인 60을 61로 조정한다. 이와 같이, 업데이트된 테이블에서, 식별된 단어에 대한 스코어는 제1가중치가 반영되며, 식별된 단어의 동의어에 대한 스코어는 제1가중치보다 작은 제2가중치가 반영된다. 한편, 전자장치는 테이블의 데이터량이 문턱값보다 낮거나 또는 사용 이력이 테이블을 생성하기에 부족할 정도 로 누적된 양이 적다고 식별되면, UI를 통해 복수의 음성 어시스턴트의 처리 결과에 관한 정보를 사용자에게 제 공할 수도 있다. 이하, 이러한 실시예에 관해 설명한다. 도 11은 전자장치의 제어방법을 나타내는 플로우차트이다. 도 11에 도시된 바와 같이, 하기 동작은 전자장치의 프로세서에 의해 수행된다. 전자장치는 사용자 발화를 각기 처리하기 위한 복수의 음성 어시스턴트를 구비한다. 1110 단계에서 전자장치는 사용자 발화를 수신한다. 1120 단계에서 전자장치는 음성 어시스턴트의 식별을 위한 정보를 획득한다. 본 정보는 복수의 음성 어시스턴트 및 복수의 키워드 사이의 연관도에 관해 기 정의된 정보일 수 있으며, 앞선 실시예에서의 테이블을 나타낼 수 있다. 또는, 본 정보는 테이블을 생성하기 위해 누적된 사용 이력일 수도 있다. 1130 단계에서 전자장치는 획득한 정보의 양이 문턱값보다 낮은지 여부를 식별한다. 획득한 정보의 양이 문턱값보다 낮다고 식별되면, 1140 단계에서 전자장치는 복수의 음성 어시스턴트 각각에 의 해 사용자 발화가 처리되도록 한다.복수의 음성 어시스턴트 각각으로부터 처리된 결과가 나오면, 1150 단계에서 전자장치는 복수의 음성 어시스턴 트 각각의 처리 결과를 안내하는 UI를 표시한다. 1160 단계에서 전자장치는 UI를 통해 선택된 처리 결과를 실행하고, 처리 결과를 상기한 정보에 반영하여 업데 이트한다. 한편, 획득한 정보의 양이 문턱값보다 낮지 않다고 식별되면, 1170 단계에서 전자장치는 획득한 정보에 기초하 여 복수의 음성 어시스턴트 중 어느 하나의 음성 어시스턴트를 선택한다. 1180 단계에서 전자장치는 선택된 음성 어시스턴트에 의해 사용자 발화가 처리되도록 한다. 이와 같이, 전자장치는 음성 어시스턴트의 식별을 위한 정보의 양에 대응하여 선택적인 동작을 수행할 수 있다. 한편, 앞선 실시예에서는 전자장치가 테이블의 스코어에 기반하여 선택된 최적의 음성 어시스턴트에 의해 사용 자 발화의 처리 결과를 제공하는 경우에 관해 설명한 바 있다. 이와 별도의 예시로서, 전자장치가 사용자에게 복수의 음성 어시스턴트의 순위별 리스트를 제공하여 사용자가 음성 어시스턴트를 선택하도록 하는 구성도 가능 하다. 이하, 이러한 실시예에 관해 설명한다. 도 12는 전자장치가 복수의 음성 어시스턴트의 처리 적합성에 관한 정보를 포함하는 UI를 표시하는 경우의 예시 도이다. 도 12에 도시된 바와 같이, 전자장치는 수신된 사용자 발화에 대한 복수의 음성 어시스턴트 각각의 처리 적합성을 나타내는 정보를 포함하는 UI를 표시할 수 있다. 전자장치는 사용자 발화가 입력되면 사용자 발화로부터 기 정의된 단어를 식별하고, 테이블을 참조하여 해당 단어에 대한 각 음성 어시스턴트의 스코어의 총합을 산출하고, 산출된 결과에 따라서 가장 높은 스코어 총 합의 음성 어시스턴트를 선택하여 사용자 발화가 처리되도록 하고, 선택 결과에 따라서 테이블의 스코어를 조정 한다. 이러한 과정은 앞선 실시예에서 설명한 바와 같다. 전자장치는 상기한 과정 중에서, 테이블을 참조하여 해당 단어에 대한 복수의 음성 어시스턴트 각각의 스 코어의 총합이 산출되면, 설계 방식에 따라서는 바로 음성 어시스턴트를 선택하지 않고 본 UI를 표시할 수 있다. 본 UI는 사용자 발화에 대한 복수의 음성 어시스턴트 각각의 스코어의 총합을 순위로 보여준다. 사용자는 UI를 통해 전자장치에 구비된 복수의 음성 어시스턴트가 사용자 발화에 대해 얼마나 적합 한지 비교할 수 있으며, 어느 하나의 음성 어시스턴트를 선택할 수 있다. 전자장치는 \"오늘 날씨 어때\"의 사용자 발화가 수신되고, \"오늘\" 및 \"날씨\"의 두 단어가 식별되면, 테이 블을 기반으로 이들 두 단어에 대한 복수의 음성 어시스턴트 각각의 스코어의 총합을 산출한다. 산출 방식은 앞 선 실시예에서 설명한 바와 같다. 전자장치는 복수의 음성 어시스턴트에 관한 항목 및 각 음성 어시스턴트의 스코어의 총합을 함께 UI에 나타낼 수 있다. 이 때, UI에서는 스코어의 총합이 높은 순서대로 복수의 음성 어시스턴트의 항목이 정렬되어 표시될 수 있다. 본 도면의 예시에 따르면 제2어시스턴트의 스코어 총합이 700으로서 가장 높 으므로, UI 내에서 제2어시스턴트가 가장 상위에 위치하여 표시된다. 이와 같은 UI는 전자장치에 대한 설정에 의해 표시될 수 있고, 또는 테이블의 신뢰도가 높지 않다 고 식별되는 경우에 선택적으로 표시될 수도 있다. 한편, 앞선 도 10 관련 실시예에서는 스코어에 대한 가중치를 상이하게 부여하는 방식 중 하나로서, 전자장치가 동의어 관리를 하는 경우에 관해 설명하였다. 그러나, 식별을 위해 마련된 기 정의된 단어의 동의어만이 해당 단어와 관련성이 있다고 한정할 수는 없으며, 다양한 기준에 따라서 해당 단어와 관련성이 있는 단어 카테고리 가 관리될 수도 있다. 이하, 이러한 실시예에 관해 설명한다. 도 13은 전자장치가 관련어 카테고리의 관리를 통해 테이블의 스코어를 조정하는 원리를 나타내는 예시도이다. 도 13에 도시된 바와 같이, 예를 들어 \"오늘 날씨 어때\"라는 사용자 발화에 대해 \"오늘\" 및 \"날씨\"의 두 가지 단어가 식별되고, 결과적으로 테이블의 스코어에 기초하여 복수의 음성 어시스턴트 중 제1어시스턴트가 선택된 경우를 고려한다. 예를 들어 식별된 단어의 스코어에 대한 제1가중치가 +3으로 지정되어 있다면, 전자장 치는 테이블에서 제1어시스턴트의 \"오늘\"에 대한 스코어인 100을 103으로 조정하고, 제1어시스턴트의 \"날 씨\"에 대한 스코어인 300을 303으로 조정한다.한편, 전자장치는 테이블에 마련된 단어들 중에, 식별된 단어와의 관련성이 있다고 지정된 단어 카테고리 가 있는지 여부를 식별한다. 본 단어 카테고리는 기 정의된 단어들의 그룹으로서, 기준 단어(즉, 식별 대상이 되는 기 정의된 단어)와 동의어이거나(도 10 관련 실시예 참조), 의미가 동일하지 않더라도 관련성이 있다고 간 주되는 단어이거나, SNS 등에서 현재의 트렌드 상으로 다양한 관련성을 가지는 검색어 등을 포함할 수 있다.즉, 기준 단어와 관련성이 있는 카테고리의 단어들은 다양한 방법 및 기준으로 선택될 수 있으며, 예를 들어 AI 모 델을 사용하여 기준 단어와 관련성이 있는 단어들의 카테고리가 지정될 수도 있다. 예를 들어 테이블에 기 정의된 단어들 중에는 \"날씨\"과 관련성이 있는 단어로서 \"지역\"이 있다고 가정한 다. 전자장치는 식별된 단어의 관련성이 있는 카테고리의 단어에 대해서는, 식별된 단어의 스코어에 대한 제1가중치 보다 작은 제2가중치를 부여하도록 마련될 수 있다. 예를 들어 제2가중치가 +3보다 작은 +1로 지정되어 있다면, 전자장치는 테이블에서 제1어시스턴트의 \"지역\"에 대한 스코어인 65를 66으로 조정한다. 이와 같이, 업데이트된 테이블에서, 식별된 단어에 대한 스코어는 제1가중치가 반영되며, 식별된 단어와 관련성 있는 타 단어에 대한 스코어는 제1가중치보다 작은 제2가중치가 반영된다. 한편, 전자장치는 기준 단어와 동의어이거나, 관련성이 있는 단어 카테고리에 관한 기 정의된 DB 또는 리스트를 저장하고, 저장된 DB 또는 리스트로부터 식별된 기준 단어와 관련성 있는 타 단어를 식별할 수 있다. 여기서, 이러한 DB는 서버에 의해 전자장치에 제공됨으로써, 주기적으로 단어들이 업데이트된 DB를 전자장치가 사용할 수 있도록 할 수 있다. 서버가 업데이트된 DB를 여러 전자장치에 제공함에 있어서, 서버는 각 전자장치로부터의 수집된 DB 사용 이력에 기반하여 DB를 업데이트할 수도 있다. 이상 실시예들에서 설명한 바와 같은 장치의 동작은, 해당 장치에 탑재된 인공지능에 의해 수행될 수 있다. 인 공지능은 기계 학습 알고리즘을 활용하여 다양한 제반 시스템에 적용될 수 있다. 인공지능 시스템은 인간 수준 내지는 인간 수준에 버금가는 지능을 구현하는 컴퓨터 시스템으로서, 기계, 장치 또는 시스템이 자율적으로 학 습하고 판단하며, 사용 경험의 누적에 기반하여 인식률 및 판단 정확도가 향상되는 시스템이다. 인공지능 기술 은 입력되는 데이터들의 특징을 스스로 분류하고 학습하는 알고리즘을 이용한 기계학습 기술 및 알고리즘을 활 용하여, 인간의 두뇌의 인지, 판단 등의 기능을 모사하는 요소 기술들로 구성된다. 요소 기술들은, 예를 들면 인간의 언어와 문자를 인식하는 언어적 이해 기술, 사물을 인간의 시각처럼 인식하는 시각적 이해 기술, 정보를 판단하여 논리적으로 추론하고 예측하는 추론 및 예측 기술, 인간의 경험 정보를 지 식 데이터로 처리하는 지식 표현 기술, 차량의 자율 주행이나 로봇의 움직임을 제어하는 동작 제어 기술 중 적 어도 어느 하나를 포함한다. 여기서, 언어적인 이해는 인간의 언어 또는 문자를 인식하고 응용 처리하는 기술로서, 자연어의 처리, 기계 번 역, 대화 시스템, 질의 응답, 음성 인식 및 합성 등을 포함한다. 추론 예측은 정보를 판단하여 논리적으로 예측하는 기술로서, 지식 및 확률 기반 추론, 최적화 예측, 선호 기반 계획, 추천 등을 포함한다. 지식 표현은 인간의 경험 정보를 지식 데이터로 자동화 처리하는 기술로서, 데이터의 생성 및 분류와 같은 지식 구축, 데이터의 활용과 같은 지식 관리 등을 포함한다. 본 발명의 예시적 실시예에 따른 방법들은 다양한 컴퓨터 수단을 통하여 수행될 수 있는 프로그램 명령 형태로 구현되어 컴퓨터 판독 가능 매체에 기록될 수 있다. 이러한 컴퓨터 판독 가능 매체는 프로그램 명령, 데이터 파 일, 데이터 구조 등을 단독으로 또는 조합하여 포함할 수 있다. 예를 들어, 컴퓨터 판독 가능 매체는 삭제 가능 또는 재기록 가능 여부와 상관없이, USB 메모리장치와 같은 비휘발성 저장 장치, 또는 예를 들어 RAM, ROM, 플 래시메모리, 메모리 칩, 집적 회로와 같은 메모리, 또는 예를 들어 CD, DVD, 자기 디스크 또는 자기 테이프 등 과 같은 광학 또는 자기적으로 기록 가능함과 동시에 기계(예를 들어, 컴퓨터)로 읽을 수 있는 저장 매체에 저 장될 수 있다. 이동 단말 내에 포함될 수 있는 메모리는 본 발명의 실시 예들을 구현하는 지시들을 포함하는 프 로그램 또는 프로그램들을 저장하기에 적합한 기계로 읽을 수 있는 저장 매체의 한 예임을 알 수 있을 것이다. 본 저장 매체에 기록되는 프로그램 명령은 본 발명을 위하여 특별히 설계되고 구성된 것들이거나 컴퓨터 소프트 웨어의 기술 분야에서 숙련된 기술자에게 공지되어 사용 가능한 것일 수도 있다. 또는, 본 컴퓨터 프로그램 명 령은 컴퓨터 프로그램 프로덕트에 의해 구현될 수도 있다.부호의 설명 100 : 전자장치 110, 120, 130 : 음성 어시스턴트"}
{"patent_id": "10-2019-0152987", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 전자장치가 복수의 음성 어시스턴트를 구비한 환경을 나타내는 예시도이다. 도 2는 전자장치의 구성 블록도이다. 도 3은 전자장치의 제어방법을 나타내는 플로우차트이다. 도 4는 전자장치가 참조하게 마련된 테이블의 예시도이다. 도 5는 도 4의 테이블을 참조하여 전자장치가 음성 어시스턴트를 식별하는 원리를 나타내는 예시도이다. 도 6은 도 4의 테이블을 전자장치가 사용자 발화의 처리 결과를 반영하여 업데이트한 결과를 나타내는 예시도이 다. 도 7은 전자장치가 초기 테이블을 획득하는 예시를 나타내는 구성 블록도이다. 도 8은 전자장치가 식별 결과의 UI를 표시하는 예시도이다. 도 9는 전자장치가 사용자의 반응에 대응하여 테이블의 스코어를 조정하는 원리를 나타내는 예시도이다. 도 10은 전자장치가 동의어 관리를 통해 테이블의 스코어를 조정하는 원리를 나타내는 예시도이다. 도 11은 전자장치의 제어방법을 나타내는 플로우차트이다. 도 12는 전자장치가 복수의 음성 어시스턴트의 처리 적합성에 관한 정보를 포함하는 UI를 표시하는 경우의 예시 도이다. 도 13은 전자장치가 관련어 카테고리의 관리를 통해 테이블의 스코어를 조정하는 원리를 나타내는 예시도이다."}
