{"patent_id": "10-2022-0182596", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0100695", "출원번호": "10-2022-0182596", "발명의 명칭": "딥 러닝 알고리즘을 활용한 운전자 주행 위험도 판단 방법 및 그 장치", "출원인": "주식회사 에이치엘클레무브", "발명자": "강석준"}}
{"patent_id": "10-2022-0182596", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "딥 러닝 알고리즘을 활용하여 운전자의 주행 위험도를 판단하는 장치로서, 프로세서; 네트워크 인터페이스;메모리; 및 상기 메모리에 로드(Load)되고, 상기 프로세서에 의해 실행되는 컴퓨터 프로그램을 포함하되,상기 프로세서는,라이다 센서 또는 카메라 센서를 탑재한 차량에 의해, 상기 차량의 주행 중 획득한 이미지 데이터 및 CAN 데이터를 수신하고, 상기 차량을 운전하는 운전자의 주행 위험도에 대한 이미지 특징을 출력하도록 기 저장된 이미지 데이터를 통해학습된 제1 딥러닝 알고리즘에 상기 획득한 이미지 데이터와 CAN 데이터를 입력하여, 제1 딥러닝 알고리즘에서 운전자의 주행 위험도와 관련된 이미지 특징을 출력하고, 출력된 이미지 특징과 대응되는 제1 이미지를 캡쳐하여 커넥트 프로그램으로 송신하는, 딥 러닝 알고리즘을 활용한 운전자 주행 위험도 판단 장치."}
{"patent_id": "10-2022-0182596", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 제1 딥 러닝 알고리즘은 CNN(Convolutional Neural Network)의 일종이며, 컨볼루션 레이어, fullyconnected layer, activated function layer 중 적어도 하나를 포함하는 딥 러닝 알고리즘을 활용한 운전자 주행 위험도 판단 장치."}
{"patent_id": "10-2022-0182596", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서, 상기 이미지 특징은 상기 CNN(Convolutional Neural Network)이 포함하는 적어도 하나의 필터에서 추출된 이미지 특징인 딥 러닝 알고리즘을 활용한 운전자 주행 위험도 판단 장치."}
{"patent_id": "10-2022-0182596", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서, 상기 출력된 이미지 특징과 대응되는 제1 이미지를 캡쳐하여 커넥트 프로그램으로 송신하는 것은 상기 커넥트프로그램에서 운전자 위험 상황에 관한 정보를 포함하여 송신하는 딥 러닝 알고리즘을 활용한 운전자 주행 위험도 판단 장치."}
{"patent_id": "10-2022-0182596", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서, 상기 프로세서는 상기 제1 이미지를 기반으로 운전자 안전도를 산출하고, 상기 운전자 위험 상황에 관한 정보와 함께 송신하는공개특허 10-2024-0100695-3-딥 러닝 알고리즘을 활용한 운전자 주행 위험도 판단 장치."}
{"patent_id": "10-2022-0182596", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서, 상기 프로세서는, 출력된 이미지 특징과 대응되는 제1 이미지가 획득된 제1 시점 정보를 산출하고, 상기 차량을 운전하는 운전자의 주행 위험도에 관해 기 저장된 이미지를 획득하는 시점의 특징을 출력하도록 학습된 제2 딥러닝 알고리즘에 상기 제1 이미지와 제1 시점 정보를 입력하고, 상기 제2 딥 러닝 알고리즘에서 이미지를 캡쳐하는 제2 시점 정보에 관해 출력하는 딥 러닝 알고리즘을 활용한 운전자 주행 위험도 판단 장치."}
{"patent_id": "10-2022-0182596", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6항에 있어서, 상기 제2 딥 러닝 알고리즘은 강화학습 알고리즘이며, 상기 강화학습 알고리즘은 DQN, Q-Learning, ASC,Genetic, SARSA 기법을 활용하는 알고리즘 중 적어도 하나를 포함하는 딥 러닝 알고리즘을 활용한 운전자 주행 위험도 판단 장치."}
{"patent_id": "10-2022-0182596", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서, 상기 제2 시점은 상기 제1 시점과 상이하며, 상기 제2 시점에서 획득한 제2 이미지는 제1 딥 러닝 알고리즘에 제2 이미지를 입력하고, 제1 딥 러닝 알고리즘에서 출력한 이미지 특징과 제1 딥 러닝 알고리즘에서 출력한 제1 이미지에 관한 이미지 특징과 상이한 딥 러닝 알고리즘을 활용한 운전자 주행 위험도 판단 장치."}
{"patent_id": "10-2022-0182596", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서, 상기 제2 시점에서 획득한 제2 이미지를 제1 딥 러닝 알고리즘에 입력하여, 제1 딥 러닝 알고리즘에서 제2 이미지에 관한 이미지 특징을 학습하는 딥 러닝 알고리즘을 활용한 운전자 주행 위험도 판단 장치."}
{"patent_id": "10-2022-0182596", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9항에 있어서, 상기 제1 딥 러닝 알고리즘에서 제2 이미지에 관한 이미지 특징 학습 시, 특징 학습에 관한 가중치를 설정하고,상기 가중치는 상기 제1 딥 러닝 알고리즘이 기 저장된 이미지 데이터를 통해 학습하는 과정에서 활용하는 가중치와는 상이한 값인 딥 러닝 알고리즘을 활용한 운전자 주행 위험도 판단 장치."}
{"patent_id": "10-2022-0182596", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "차량으로서, 주행 차량이 주행하는 중에 라이다 데이터 및 이미지 데이터를 획득하는 센서들; 상기 차량의 주행을 물리적으로 제어하는 제어 시스템; 주행 차량의 주행 중에 인식할 수 있는 장애물 및 차량에 관한 신호를 수신 및 송신하기 위한 적어도 하나의 인공개특허 10-2024-0100695-4-터페이스; 및판단 장치를 포함하고, 상기 판단 장치는라이다 센서 또는 카메라 센서를 탑재한 차량에 의해, 상기 차량의 주행 중 획득한 이미지 데이터 및 CAN 데이터를 수신하고, 상기 차량을 운전하는 운전자의 주행 위험도에 대한 이미지 특징을 출력하도록 기 저장된 이미지 데이터를 통해학습된 제1 딥러닝 알고리즘에 상기 획득한 이미지 데이터와 CAN 데이터를 입력하여, 제1 딥러닝 알고리즘에서 운전자의 주행 위험도와 관련된 이미지 특징을 출력하고, 출력된 이미지 특징과 대응되는 제1 이미지를 캡쳐하여 커넥트 프로그램으로 송신하는, 차량."}
{"patent_id": "10-2022-0182596", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항에 있어서, 상기 제1 딥 러닝 알고리즘은 CNN(Convolutional Neural Network)의 일종이며, 컨볼루션 레이어, fullyconnected layer, activated function layer 중 적어도 하나를 포함하는, 차량."}
{"patent_id": "10-2022-0182596", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제12항에 있어서, 상기 이미지 특징은 상기 CNN(Convolutional Neural Network)이 포함하는 적어도 하나의 필터에서 추출된 이미지 특징인, 차량."}
{"patent_id": "10-2022-0182596", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제11항에 있어서, 상기 출력된 이미지 특징과 대응되는 제1 이미지를 캡쳐하여 커넥트 프로그램으로 송신하는 것은 상기 커넥트프로그램에서 운전자 위험 상황에 관한 정보를 포함하여 송신하는, 차량."}
{"patent_id": "10-2022-0182596", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제14항에 있어서, 상기 판단 장치는 상기 제1 이미지를 기반으로 운전자 안전도를 산출하고, 상기 운전자 위험 상황에 관한 정보와 함께 송신하는, 차량."}
{"patent_id": "10-2022-0182596", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제11항에 있어서, 상기 판단 장치는 출력된 이미지 특징과 대응되는 제1 이미지가 획득된 제1 시점 정보를 산출하고, 상기 차량을 운전하는 운전자의 주행 위험도에 관해 기 저장된 이미지를 획득하는 시점의 특징을 출력하도록 학습된 제2 딥러닝 알고리즘에 상기 제1 이미지와 제1 시점 정보를 입력하고, 상기 제2 딥 러닝 알고리즘에서 이미지를 캡쳐하는 제2 시점 정보에 관해 출력하는, 차량."}
{"patent_id": "10-2022-0182596", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제16항에 있어서, 상기 제2 딥 러닝 알고리즘은 강화학습 알고리즘이며, 상기 강화학습 알고리즘은 DQN, Q-Learning, ASC,Genetic, SARSA 기법을 활용하는 알고리즘 중 적어도 하나를 포함하는, 차량."}
{"patent_id": "10-2022-0182596", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제17항에 있어서, 공개특허 10-2024-0100695-5-상기 제2 시점은 상기 제1 시점과 상이하며, 상기 제2 시점에서 획득한 제2 이미지는 제1 딥 러닝 알고리즘에 제2 이미지를 입력하고, 제1 딥 러닝 알고리즘에서 출력한 이미지 특징과 제1 딥 러닝 알고리즘에서 출력한 제1 이미지에 관한 이미지 특징과 상이한, 차량."}
{"patent_id": "10-2022-0182596", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제18항에 있어서, 상기 제2 시점에서 획득한 제2 이미지를 제1 딥 러닝 알고리즘에 입력하여, 제1 딥 러닝 알고리즘에서 제2 이미지에 관한 이미지 특징을 학습하는, 차량."}
{"patent_id": "10-2022-0182596", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제19항에 있어서, 상기 제1 딥 러닝 알고리즘에서 제2 이미지에 관한 이미지 특징 학습 시, 특징 학습에 관한 가중치를 설정하고,상기 가중치는 상기 제1 딥 러닝 알고리즘이 기 저장된 이미지 데이터를 통해 학습하는 과정에서 활용하는 가중치와는 상이한 값인, 차량."}
{"patent_id": "10-2022-0182596", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_21", "content": "딥 러닝 알고리즘을 활용하여 운전자의 주행 위험도를 판단하는 장치에 의해 수행되는 방법에 있어서, 라이다 센서 또는 카메라 센서를 탑재한 차량에 의해, 상기 차량의 주행 중 획득한 이미지 데이터 및 CAN 데이터를 수신하는 단계; 상기 차량을 운전하는 운전자의 주행 위험도에 대한 이미지 특징을 출력하도록 기 저장된 이미지 데이터를 통해학습된 제1 딥러닝 알고리즘에 상기 획득한 이미지 데이터와 CAN 데이터를 입력하는 단계; 제1 딥러닝 알고리즘에서 운전자의 주행 위험도와 관련된 이미지 특징을 출력하는 단계; 및출력된 이미지 특징과 대응되는 제1 이미지를 캡쳐하여 커넥트 프로그램으로 송신하는 단계; 를 포함하는 딥 러닝 알고리즘을 활용한 운전자 주행 위험도 판단 방법."}
{"patent_id": "10-2022-0182596", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_22", "content": "제21항에 있어서, 상기 제1 딥 러닝 알고리즘은 CNN(Convolutional Neural Network)의 일종이며, 컨볼루션 레이어, fullyconnected layer, activated function layer 중 적어도 하나를 포함하는 딥 러닝 알고리즘을 활용한 운전자 주행 위험도 판단 방법."}
{"patent_id": "10-2022-0182596", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_23", "content": "제22항에 있어서, 상기 이미지 특징은 상기 CNN(Convolutional Neural Network)이 포함하는 적어도 하나의 필터에서 추출된 이미지 특징인 딥 러닝 알고리즘을 활용한 운전자 주행 위험도 판단 방법."}
{"patent_id": "10-2022-0182596", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_24", "content": "제21항에 있어서, 상기 출력된 이미지 특징과 대응되는 제1 이미지를 캡쳐하여 커넥트 프로그램으로 송신하는 것은 상기 커넥트프로그램에서 운전자 위험 상황에 관한 정보를 포함하여 송신하는 딥 러닝 알고리즘을 활용한 운전자 주행 위험도 판단 방법."}
{"patent_id": "10-2022-0182596", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_25", "content": "공개특허 10-2024-0100695-6-제24항에 있어서, 상기 제1 이미지를 기반으로 운전자 안전도를 산출하고, 상기 운전자 위험 상황에 관한 정보와 함께 송신하는단계를 더 포함하는 딥 러닝 알고리즘을 활용한 운전자 주행 위험도 판단 방법."}
{"patent_id": "10-2022-0182596", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_26", "content": "제21항에 있어서, 출력된 이미지 특징과 대응되는 제1 이미지가 획득된 제1 시점 정보를 산출하는 단계; 상기 차량을 운전하는 운전자의 주행 위험도에 관해 기 저장된 이미지를 획득하는 시점의 특징을 출력하도록 학습된 제2 딥러닝 알고리즘에 상기 제1 이미지와 제1 시점 정보를 입력하는 단계; 상기 제2 딥 러닝 알고리즘에서 이미지를 캡쳐하는 제2 시점 정보에 관해 출력하는 단계;를 더 포함하는 딥 러닝 알고리즘을 활용한 운전자 주행 위험도 판단 방법."}
{"patent_id": "10-2022-0182596", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_27", "content": "제26항에 있어서, 상기 제2 딥 러닝 알고리즘은 강화학습 알고리즘이며, 상기 강화학습 알고리즘은 DQN, Q-Learning, ASC,Genetic, SARSA 기법을 활용하는 알고리즘 중 적어도 하나를 포함하는 딥 러닝 알고리즘을 활용한 운전자 주행 위험도 판단 방법."}
{"patent_id": "10-2022-0182596", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_28", "content": "제27항에 있어서, 상기 제2 시점은 상기 제1 시점과 상이하며, 상기 제2 시점에서 획득한 제2 이미지는 제1 딥 러닝 알고리즘에 제2 이미지를 입력하고, 제1 딥 러닝 알고리즘에서 출력한 이미지 특징과 제1 딥 러닝 알고리즘에서 출력한 제1 이미지에 관한 이미지 특징과 상이한 딥 러닝 알고리즘을 활용한 운전자 주행 위험도 판단 방법."}
{"patent_id": "10-2022-0182596", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_29", "content": "제28항에 있어서, 상기 제2 시점에서 획득한 제2 이미지를 제1 딥 러닝 알고리즘에 입력하여, 제1 딥 러닝 알고리즘에서 제2 이미지에 관한 이미지 특징을 학습하는 딥 러닝 알고리즘을 활용한 운전자 주행 위험도 판단 방법."}
{"patent_id": "10-2022-0182596", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_30", "content": "제29항에 있어서, 상기 제1 딥 러닝 알고리즘에서 제2 이미지에 관한 이미지 특징 학습 시, 특징 학습에 관한 가중치를 설정하고,상기 가중치는 상기 제1 딥 러닝 알고리즘이 기 저장된 이미지 데이터를 통해 학습하는 과정에서 활용하는 가중치와는 상이한 값인 딥 러닝 알고리즘을 활용한 운전자 주행 위험도 판단 방법."}
{"patent_id": "10-2022-0182596", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 딥 러닝 알고리즘을 활용하여 운전자의 주행 위험도를 판단하는 장치로서, 프로세서, 네트워크 인터페 이스, 메모리 및 상기 메모리에 로드(Load)되고, 상기 프로세서에 의해 실행되는 컴퓨터 프로그램을 포함하되, 상기 프로세서는, 라이다 센서 또는 카메라 센서를 탑재한 차량에 의해, 상기 차량의 주행 중 획득한 이미지 데 이터 및 CAN 데이터를 수신하고, 상기 차량을 운전하는 운전자의 주행 위험도에 대한 이미지 특징을 출력하도록 기 저장된 이미지 데이터를 통해 학습된 제1 딥러닝 알고리즘에 상기 획득한 이미지 데이터와 CAN 데이터를 입력 하여, 제1 딥러닝 알고리즘에서 운전자의 주행 위험도와 관련된 이미지 특징을 출력하고, 출력된 이미지 특징과 대응되는 제1 이미지를 캡쳐하여 커넥트 프로그램으로 송신하는, 딥 러닝 알고리즘을 활용한 운전자 주행 위험도 판단 장치 및 그 방법, 차량에 관한 것이다."}
{"patent_id": "10-2022-0182596", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 딥 러닝 알고리즘을 활용하여 운전자의 주행 위험도를 판단하는 방법 및 그 장치에 관한 것으로서, 보다 구체적으로 이미지 인식 딥 러닝 알고리즘과 강화학습 알고리즘을 활용하여 운전자 주행 위험 이미지와 시 점에 관한 정보를 분석하여 운전자 주행 위험도를 판단하는 방법 및 그 장치에 관한 것이다."}
{"patent_id": "10-2022-0182596", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "최근 자율 주행 차량이 전반적으로 증가하면서, 자율 주행 차량과 관련한 사고 역시 증가하고 있다. 특히 이러 한 자율 주행 차량과 관련한 사고는 운전자의 운전 의도를 정확하게 이해하지 못하고, 미리 정해진 규칙에만 의 존하여 주행하는 한계에서 비롯된 것이 많다. 이러한 자율 주행과 관련한 사고에 대비하기 위해 운전자 및 차량과 관련된 보험 회사 역시도 운전자의 주행 위 험도를 종래 판단하는 방법 보다 더 정확한 방법을 개발하고 있다. 종래, 운전자 및 차량과 관련한 보험 회사는 차량 운행과 관련된 단순한 정보를 기초로 운전자의 주행 위험도를 판단하고 있었다. 그러나 이러한 정보는 자율 주행 차량의 급격한 보급과 4차 산업 혁명으로 인한 인공지능(AI) 기술의 확산으로 인해 보다 진보된 정보로서 탈바꿈되기를 요구받고 있다. 따라서, 인공지능 기술을 활용하여 운전자의 주행 위험도를 보다 정확하게 판단하고, 이를 통해 운전자 및 차량 과 관련된 보험 회사에서 보험 상품과 관련하여 보다 정확한 정보를 제공할 필요가 있으며, 이러한 정보를 통해 운전자 역시 자신의 운전 습관 및 주행 정보를 제공받을 수 있는 획기적인 기술 개발 및 아이디어 필요하다."}
{"patent_id": "10-2022-0182596", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 2, "content": "전술한 배경기술은 발명자가 본 발명의 도출을 위해 보유하고 있었거나, 본 발명의 도출 과정에서 습득한 기술 정보로서, 반드시 본 발명의 출원 전에 일반 공중에게 공지된 기술이라 할 수는 없다."}
{"patent_id": "10-2022-0182596", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명의 몇몇 실시예를 통해 해결하고자 하는 과제는 차량을 운전하는 운전자의 운전 위험도를 산출하여 이를 제공하는 방법 및 장치를 제공하는 것에 있다. 본 발명의 몇몇 실시예를 통해 해결하고자 하는 과제는 2가지 딥 러닝 알고리즘을 활용하여 보다 정확한 운전 위험도 산출에 기초가 되는 정보를 활용하는 방법 및 그 장치를 제공하는 것에 있다. 본 발명의 몇몇 실시예를 통해 해결하고자 하는 또 다른 과제는 2가지 딥 러닝 알고리즘 중 하나인 강화학습 알 고리즘을 활용하여 운전자의 주행 위험 상황을 캡쳐하는 시점을 분석하여 보다 효과적인 딥 러닝 알고리즘을 운 영할 수 있는 방법 및 그 장치를 제공하는 것에 있다."}
{"patent_id": "10-2022-0182596", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기 기술적 과제를 해결하기 위한, 딥 러닝 알고리즘을 활용하여 운전자의 주행 위험도를 판단하는 장치로서, 프로세서, 네트워크 인터페이스, 메모리, 및 상기 메모리에 로드(Load)되고, 상기 프로세서에 의해 실행되는 컴 퓨터 프로그램을 포함하되, 상기 프로세서는, 라이다 센서 또는 카메라 센서를 탑재한 차량에 의해, 상기 차량 의 주행 중 획득한 이미지 데이터 및 CAN 데이터를 수신하고, 상기 차량을 운전하는 운전자의 주행 위험도에 대 한 이미지 특징을 출력하도록 기 저장된 이미지 데이터를 통해 학습된 제1 딥러닝 알고리즘에 상기 획득한 이미 지 데이터와 CAN 데이터를 입력하여, 제1 딥러닝 알고리즘에서 운전자의 주행 위험도와 관련된 이미지 특징을 출력하고, 출력된 이미지 특징과 대응되는 제1 이미지를 캡쳐하여 커넥트 프로그램으로 송신하는, 딥 러닝 알고 리즘을 활용한 운전자 주행 위험도 판단 장치에 관한 것이다. 일 실시 예에 있어서, 제1 딥 러닝 알고리즘은 CNN(Convolutional Neural Network)의 일종이며, 컨볼루션 레이 어, fully connected layer, activated function layer 중 적어도 하나를 포함할 수 있다. 일 실시 예에 있어서, 이미지 특징은 상기 CNN(Convolutional Neural Network)이 포함하는 적어도 하나의 필터 에서 추출된 이미지 특징일 수 있다. 일 실시 예에 있어서, 출력된 이미지 특징과 대응되는 제1 이미지를 캡쳐하여 커넥트 프로그램으로 송신하는 것 은 상기 커넥트 프로그램에서 운전자 위험 상황에 관한 정보를 포함하여 송신할 수 있다. 일 실시 예에 있어서, 프로세서는 상기 제1 이미지를 기반으로 운전자 안전도를 산출하고, 상기 운전자 위험 상 황에 관한 정보와 함께 송신할 수 있다. 일 실시 예에 있어서, 상기 프로세서는, 출력된 이미지 특징과 대응되는 제1 이미지가 획득된 제1 시점 정보를 산출하고, 상기 차량을 운전하는 운전자의 주행 위험도에 관해 기 저장된 이미지를 획득하는 시점의 특징을 출 력하도록 학습된 제2 딥러닝 알고리즘에 상기 제1 이미지와 제1 시점 정보를 입력하고, 상기 제2 딥 러닝 알고 리즘에서 이미지를 캡쳐하는 제2 시점 정보에 관해 출력할 수 있다. 일 실시 예에 있어서, 제2 딥 러닝 알고리즘은 강화학습 알고리즘이며, 상기 강화학습 알고리즘은 DQN, Q- Learning, ASC, Genetic, SARSA 기법을 활용하는 알고리즘 중 적어도 하나를 포함할 수 있다. 일 실시 예에 있어서, 상기 제2 시점은 상기 제1 시점과 상이하며, 상기 제2 시점에서 획득한 제2 이미지는 제1 딥 러닝 알고리즘에 제2 이미지를 입력하고, 제1 딥 러닝 알고리즘에서 출력한 이미지 특징과 제1 딥 러닝 알고 리즘에서 출력한 제1 이미지에 관한 이미지 특징과 상이할 수 있다. 일 실시 예에 있어서, 제2 시점에서 획득한 제2 이미지를 제1 딥 러닝 알고리즘에 입력하여, 제1 딥 러닝 알고 리즘에서 제2 이미지에 관한 이미지 특징을 학습할 수 있다. 일 실시 예에 있어서, 제1 딥 러닝 알고리즘에서 제2 이미지에 관한 이미지 특징 학습 시, 특징 학습에 관한 가 중치를 설정하고, 상기 가중치는 상기 제1 딥 러닝 알고리즘이 기 저장된 이미지 데이터를 통해 학습하는 과정 에서 활용하는 가중치와는 상이한 값일 수 있다."}
{"patent_id": "10-2022-0182596", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "전술한 본 발명의 과제 해결 수단에 의하면, 주행 차량을 주행하는 중 위험 상황에서 그 이미지를 캡쳐하여, 캡 쳐된 이미지를 기반으로 운전자의 위험도를 산출하여 보다 정확하게 운전자의 위험 상황을 판단할 수 있다. 또한, 본 발명의 과제 해결 수단에 의하면 적어도 하나 이상의 딥 러닝 알고리즘이 계속하여 학습하여 시간이 지남에 따라 운전자의 주행 위험도를 판단하는 장치의 정확성을 향상시킬 수 있다. 또한, 본 발명의 과제 해결 수단에 의하면, 강화학습 알고리즘을 통해 이미지를 캡쳐하는 시점에 대해 학습하고, 이를 산출하여 이미지 캡쳐 알고리즘의 정확성을 향상시킬 수 있다."}
{"patent_id": "10-2022-0182596", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 첨부된 도면을 참조하여 본 개시의 바람직한 실시예들을 상세 히 설명한다. 본 개시의 이점 및 특징, 그 리고 그것들을 달성하는 방법은 첨부되는 도면과 함께 상세하게 후술되어 있는 실시예들을 참조하면 명확해질 것이다. 그러나 본 개시의 기술적 사상은 이하의 실시예들에 한정되는 것이 아니라 서로 다른 다양한 형태로 구 현될 수 있으며, 단지 이하의 실시예들은 본 개시의 기술적 사상을 완전하도록 하고, 본 개시가 속하는 기술분 야에서 통상의 지식을 가진 자에게 본 개시의 범주를 완전하게 알려주기 위해 제공되는 것이며, 본 개시의 기술 적 사상은 청구항의 범주에 의해 정의될 뿐이다. 각 도면의 구성 요소들에 참조부호를 부가함에 있어서, 동일한 구성 요소들에 대해서는 비록 다른 도면상에 표 시되더라도 가능한 한 동일한 부호를 가 지도록 하고 있음에 유의해야 한다. 또한, 본 개시를 설명함에 있어, 관련된 공지 구성 또는 기능에 대한 구체적인 설명이 본 개시의 요지를 흐릴 수 있다고 판단되는 경우에는 그 상세한 설명은 생략한다. 다른 정의가 없다면, 본 명세서에서 사용되는 모든 용어(기술 및 과학적 용어를 포함)는 본 개시가 속하는 기술 분야에서 통상의 지식을 가진 자에게 공통적으로 이해될 수 있는 의미로 사용될 수 있다. 또 일반적으로 사용되 는 사전에 정의되어 있는 용어들은 명백하게 특별히 정의되어 있지 않는 한 이상적으로 또는 과도하게 해석되지 않는다. 본 명세서에서 사용된 용어는 실시예들을 설명하기 위한 것이며 본 개시를 제한하고자 하는 것은 아니 다. 본 명세서에서, 단수형은 문 구에서 특별히 언급하지 않는 한 복수형도 포함한다. 또한, 본 개시의 구성 요소를 설명하는 데 있어서, 제1, 제2, A, B, (a), (b) 등의 용어를 사용할 수 있다. 이 러한 용어는 그 구성 요소를 다른 구성 요소와 구별하기 위한 것일 뿐, 그 용어에 의해 해당 구성 요소의 본질 이나 차례 또는 순서 등이 한정되지 않는다. 어떤 구성 요소가 다른 구성 요소에 \"연결\", \"결합\" 또는 \"접속\"된 다고 기재된 경우, 그 구성 요소는 그 다른 구성 요소에 직접적으로 연결되거나 또는 접속될 수 있지만, 각 구 성 요소 사이에 또 다른 구성 요소 가 \"연결\", \"결합\" 또는 \"접속\"될 수도 있다고 이해되어야 할 것이다. 명세서에서 사용되는 \"포함한다(comprises)\" 및/또는 \"포함하는 (comprising)\"은 언급된 구성 요소, 단계, 동작 및/또는 소자는 하나 이상의 다른 구성 요소, 단계, 동작 및/또는 소자의 존재 또는 추가를 배제하지 않는다. 이하, 본 개시의 다양한 실시예들에 대하여 첨부된 도면에 따라 상세하게 설명한다. 또한, 본 발명의 구성 요소를 설명하는 데 있어서, 제 1, 제 2, A, B, (a), (b) 등의 용어를 사용할 수 있다. 이러한 용어는 그 구성 요소를 다른 구성 요소와 구별하기 위한 것일 뿐, 그 용어에 의해 해당 구성 요소의 본 질이나 차례 또는 순서 등이 한정되지 않는다. 명세서 전체에서, 어떤 부분이 어떤 구성요소를 '포함', '구비' 한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다른 구성요소를 제외하는 것이 아니라 다른 구성요소를 더 포함할 수 있는 것을 의미한다. 또한, 명세서에 기재된 '부', '모듈' 등의 용어는 적어도 하나의 기능이나 동작을 처리하는 단위를 의미하며, 이는 하드웨어나 소프트웨어 또는 하드웨어 및 소프트웨어의 결합으로 구현 될 수 있다. 도 1은 본 개시의 몇몇 실시예에 따른 위험도 판단 장치가 적용될 수 있는 예시적인 환경을 도시한다. 도 1에 도시된 주행 차량 및 위험도 판단 장치가 포함된 시스템을 통해 주행 차량을 운전하는 운전자의 주행 위험도를 판단하고, 이를 운전자에게 제공할 수 있다. 이하에서는 상술한 시스템을 통해 주행 차량의 운전자의 주행 위험도 판단 방법과 관련하여 도 1에 도시된 구성 요소들의 동작들에 대해 보다 구체적으로 설명하기로 한다. 도 1은 주행 차량과 위험도 판단 장치가 네트워크를 통해 연결된 예를 도시하고 있으나, 이는 이해의 편의를 제공하기 위한 것일 뿐이고, 네트워크에 연결될 수 있는 장치의 개수는 얼마든지 달라질 수 있다. 한편, 도 1은 본 개시의 목적을 달성하기 위한 바람직한 실시예를 도시하고 있을 뿐이며, 필요에 따라 일부 구 성 요소가 추가되거나 삭제될 수 있다. 이하, 도 1에 도시된 구성 요소들에 대해 보다 구체적으로 설명하기로 한다. 위험도 판단 장치는 주행 차량을 운전하는 운전자의 운전 위험도를 판단하고, 이를 운전자에게 제공 할 수 있다. 여기서 위험도 판단 장치는 주행 차량에서 발생하는 다양한 정보를 수집 및 분석할 수 있다. 다양한 정보는 주행 차량에서 발생하는 모든 데이터를 포함할 수 있으며, 예를 들어 주행 차량의 속도, 스 티어링 장치의 휠 각도, 주행 차량 자체의 스펙 등이 될 수 있으며, 나아가 주행 차량이 주행하고 있는 환경에대한 정보일 수도 있다. 이러한 정보는 주행 차량이 주행하면서 주행 차량 내의 일련의 장치를 활용 하여 수집된 정보일 수 있으며, 상기 일련의 장치는 통상의 지식을 가진 기술자 입장에서 주행 차량이 가 지는 모든 전자기기 장치를 포함할 수 있음은 당연하다. 또한, 이러한 정보는 차량 주행 시가 아닌 정차 시, 수 집된 정보를 포함할 수 있다. 도 1에서 도시하고 있는 주행 차량은 자율 주행 기술을 탑재하고 있는 차량 뿐만 아니라, 일반 자율 주행 기술이 탑재하지 않은 차량도 포함할 수 있다. 상기 주행 차량은 사륜 차량(Vehicle) 및 이륜 오토바이 (Motorcycle)를 모두 포함할 수 있다. 또한 상기 주행 차량은 차량으로, 주행 차량이 주행하는 중에 라이 다 데이터 및 이미지 데이터를 획득하는 센서들, 상기 차량의 주행을 물리적으로 제어하는 제어 시스템, 주행 차량의 주행 중에 인식할 수 있는 장애물 및 차량에 관한 신호를 수신 및 송신하기 위한 적어도 하나의 인터페 이스를 포함할 수 있다. 여기서 라이다 데이터 및 이미지 데이터를 획득한 센서는 2D 라이다 선서, 3D 라이다 센서를 포함할 수 있고, 또한 카메라 및 이미지 데이터를 획득하는 센서를 포함할 수도 있다. 제어 시스템은 주행 차량을 물리적으 로 주행하게 하는 모든 전자기기 및 물리적인 기계, 기구 장치를 포함할 수 있으며, 상기 인터페이스는 주행 차 량에 탑재되어 주행 차량이 포함하고 있는 내부 전자기기 제품 및 장치들이 서로 송수신할 수 있게 하는 통신 기술을 가지고 있는 장치일 수 있다. 또한, 상기 인터페이스는 주행 차량과 다른 외부 차량 및 외부 전자기기와 전자신호를 송수신할 수 있는 장치일 수도 있다. 중복된 설명을 배제하기 위해, 위험도 판단 장치가 수행하는 다양한 동작들에 대해서는 추후 도 2이하의 도면을 참조하여 보다 상세히 설명하도록 한다. 한편, 위험도 판단 장치는 하나 이상의 컴퓨팅 장치로 구현될 수 있다. 예를 들어, 위험도 판단 장치(20 0)의 모든 기능은 단일 컴퓨팅 장치에서 구현될 수 있다. 다른 예로써, 위험도 판단 장치의 제1 기능은 제 1 컴퓨팅 장치에서 구현되고, 제2 기능은 제2 컴퓨팅 장치에서 구현될 수도 있다. 여기서, 컴퓨팅 장치는, 노트 북, 데스크톱(desktop), 랩탑(laptop) 등이 될 수 있으나, 이에 국한되는 것은 아니며 컴퓨팅 기능이 구비된 모 든 종류의 장치를 포함할 수 있다. 다만, 위험도 판단 장치는 고성능의 서버급 컴퓨팅 장치로 구현되는 것 이 바람직할 수 있다. 컴퓨팅 장치의 일례에 대해서는 도 9를 참조하여 설명하기로 한다. 또한, 추가적으로 위험도 판단 장치에서 구현할 수 있는 기능은 주행 차량에 탑재되어 있는 전자기기 장치를 활용하여 구현될 수도 있다. 따라서, 도 1에서는 위험도 판단 장치와 주행 차량을 구분하여 도시하였으나, 일 실시예에 따르면 위험도 판단 장치가 주행 차량에 탑재되어 주행 차량 내에서 위험도 판단 장치가 제1 기능 및 제2 기능 등을 구현할 수 있음은 당연하다. 따라서, 도 1에서 도시된 바 와 같이 주행 차량과 위험도 판단 장치가 외부적으로 구분되어 있는 일 실시예에 한정되어 해석되지 않음에 주의해야 한다. 본 명세서에서는 설명의 편의를 위하여 주행 차량과 위험도 판단 장치가 구분되어 기능을 구현하는 상황에 대해서 설명하기로 한다. 몇몇 실시예에서, 위험도 판단 장치가 적용된 환경에 포함된 구성 요소들은 네트워크를 통해 통신할 수 있 다. 상기 네트워크는 근거리 통신망 (Local Area Network; LAN), 광역 통신망(Wide Area Network; WAN), 이동 통신망 (mobile radio communication network), Wibro(Wireless Broadband Internet) 등과 같은 모든 종류의 유/무선 네트워크로 구현될 수 있다. 한편, 도 1에 도시된 환경은 주행 차량과 위험도 판단 장치를 경유하여 네트워크를 통해 연결된 것을 도시하고 있으나, 본 개시의 범위가 이에 한정되는 것은 아니고, 주행 차량이 위험도 판단 장치와 P2P(Peer to Peer)로 연결될 수도 있음을 유의해야 한다. 지금까지 도 1을 참조하여, 본 개시의 몇몇 실시예에 따른 위험도 판단 장치가 적용될 수 있는 예시적인 환경을 설명하였다. 이하, 도 2이하의 도면들을 참조하여, 본 개시의 다양한 실시예에 따른 방법들에 대하여 상 세하게 설명하기로 한다. 후술될 방법들의 각 단계는 컴퓨팅 장치에 의해 수행될 수 있다. 다시 말하면, 방법들의 각 단계는 컴퓨팅 장치 의 프로세서에 의해 실행되는 하나 이 상의 인스트럭션들로 구현될 수 있다. 이러한 방법들에 포함되는 모든 단 계는 하나의 물리적인 컴퓨팅 장치에 의하여 실행될 수도 있을 것이나, 방법의 제1 단계들은 제1 컴퓨팅 장치에 의하여 수행되고, 방법의 제2 단계들은 제2 컴퓨팅 장치에 의하여 수행될 수도 있다.이하 도 2에서는, 방법들의 각 단계가 도 1에 예시된 위험도 판단 장치에 의해 수행되는 것을 가정하여 설 명을 이어가도록 한다. 다만, 설명의 편의상, 방법들에 포함되는 각 단계의 동작 주체는 그 기재가 생략될 수도 있다. 도 2은 본 개시의 몇몇 실시예에 따라 위험도 판단 장치에서 수행될 수 있는 운전자 주행 위험 상황에 관한 이 미지 데이터를 분석하는 방법에 관한 순서도이다. 단계 S100에서, 위험도 판단 장치는 이미지 데이터와 CAN 데이터를 획득할 수 있다. 여기서 이미지 데이터는 주행 차량이 주행하면서 획득하는 데이터일 수 있다. 예를 들어, 주행 차량 에 탑재된 여러 센서에 따라 획득하는 이미지 데이터일 수 있다. 또는, 주행 차량에 탑재되어 있는 카메라 센서, 이미지 센서, 3D 라이다 장치를 통해 획득되는 이미지 데 이터일 수 있으며, 상기 이미지 데이터는 주행 차량의 전방, 후방, 측방에서 획득되는 이미지 데이터일 수 있다. 본 발명의 이미지 데이터의 저장 형식은 어떠한 형태에 국한되지 아니하며, 확장자가 .png, jpg, jpeg 등 에 형식으로 저장되는 데이터일 수 있다. 위험도 판단 장치에서 획득하는 CAN 데이터는 Controller Area Network 데이터로서, 자동차의 ECU(Electronic Control Unit) 사이의 통신 과정에서 획득되는 데이터일 수 있다. 따라서, 주행 차량이 포함하는 적어도 하나 이상의 전자부품들 간 통신하는 데이터일 수 있다. CAN 데이터는 주행 차량이 포함 하는 전자 부품들이 병렬로 연결되어 데이터를 서로 주고받을 수 있는 구조를 통해 획득되는 데이터일 수 있다. 단계 S200에서, 위험도 판단 장치는 제1 딥러닝 알고리즘에 이미지 데이터와 CAN 데이터를 입력할 수 있다. 위험도 판단 장치는 제1 딥러닝 알고리즘에 이미지 데이터를 입력하고, 제1 딥러닝 알고리즘을 학습할 수 있다. 제1 딥러닝 알고리즘은 이미지 데이터를 입력받고, 이미지 데이터에서 그 특징을 추출하고, 이에 관한 결 과값을 추출하는 딥러닝 알고리즘 중 하나일 수 있다. 또한, 제1 딥러닝 알고리즘은 지도학습 알고리즘의 하나 일 수 있으며, 라벨링 데이터가 입력되어 학습하고, 이를 기반으로 새로운 데이터가 입력될 때 라벨링 데이터와 대응되는 출력값을 출력하는 딥러닝 알고리즘 일 수 있다. 따라서, 제1 딥러닝 알고리즘은 합성곱 신경망(CNN, Convolutional Neural Network), LSTM, RNN 등과 같은 딥러닝 아키텍쳐를 포함하는 알고리즘일 수 있다. 본 발명의 개시에서 제1 딥러닝 알고리즘은 CNN(합성곱 신경망)모델일 수 있다. 상기 CNN 모델은 합성곱 신경망 모델로서, Convolutional layer, pooling layer, fully connected layer, activating function layer을 포함 할 수 있다. Convolutional layer는 적어도 하나 이상의 Filter를 포함하고 있으며, 적어도 하나 이상의 Filter는 각각 특정 모양에 대한 특징을 갖을 수 있다. 예를 들어, 물체의 윤곽을 알아내기 위한 edge Filter의 경우 이미지를 커버 할 수 있는 선과 같은 특정 모양에 대한 특징을 갖을 수 있다. edge Filter를 이미지에 적용시키는 경우, edge Filter에 부합하는 특징 정보를 얻을 수 있다. Convolutional layer에 포함된 적어도 하나 이상의 Filter를 통 해 특징 맵을 추출할 수 있다. Pooling layer는 Convolutional layer의 사이 사이에 구조적으로 위치할 수 있다. 또는 복수의 Convolutional layer가 계층적으로 위치한 후, Pooling layer가 위치할 수도 있다. Pooling layer는 Convolutional layer를 통해 추출된 특징 맵에서 특정 영역에 대한 특정 값을 추출하는 기능을 수행한다. Pooling layer는 여러 가지 종류를 가지고 있으며, 일 예로는 Max Pooling layer, Median Pooling layer 등이 있을 수 있다. Fully Connected Layer는 적어도 하나 이상의 Convolutional Layer와 Pooling Layer를 통해 추출된 특징 맵에 대해서 이미지 분류 기능을 수행할 수 있다. 일 예로 Fully Connected Layer는 특징 맵을 일렬의 형태로 위치한 후 hidden layer를 거쳐 이미지를 분류할 수 있다. Activation Function layer는 활성화 함수(activated function layer) 층으로서 특징 맵에 적용될 수 있다. Activated Function layer는 Fully Connected Layer 이후 정량적 값에 대해, 특징 정보를 포함하고 있는 여부 에 관한 결과로 바꿔 주는 기능을 수행할 수 있다. 또한, 본 발명에서는 Max Pooling layer, 적어도 하나 이상의 Convolutional layer, Fully Connected Layer, Softmax layer로 이루어질 수 있으며 이는 일 예에 해당할 뿐, 이에 국한되어 해석되는 것은 아님에 유의해야한다. 위험도 판단 장치가 포함하는 제1 딥러닝 알고리즘은 이미지 데이터와 CAN 데이터를 제1 딥러닝 알고리즘 에 입력하는 시점 전에 이미 학습된 상태일 수 있다. 따라서, 위험도 판단 장치가 포함하는 제1 딥러닝 알 고리즘은 이미지 데이터와 CAN 데이터 중에 미리 설정한 기준에 따라 운전 위험 상황에 대해 라벨링 데이터가 생성되어 학습된 상태일 수 있다. 보다 구체적으로, 위험도 판단 장치가 포함하는 제1 딥러닝 알고리즘은 이미지 데이터에서 운전 위험도 상황 중 3가지인 위험 상황, 보통 상황, 안전한 상황으로 라벨링 된 데이터를 기초로 학습할 수 있다. 본 예시에서 상술한 3가지는 일 예에 해당할 뿐 이에 한정되지 아니하며, 상기 라벨링 과정 역시 구체적인 일 예로 한정되지 아니한다. 따라서, 위험 상황, 보통 상황, 안전한 상황은 이미지 데이터 의 2, 1, 0의 형태로 라벨링 되어 제1 딥러닝 알고리즘이 학습될 수 있다. 따라서, 제1 딥러닝 알고리즘은 이미지 데이터가 입력되면, 라벨링 된 이미지 데이터의 특징을 학습하고, 이를 기초로 이미지 데이터에서 그 특징을 기초로 출력값을 출력할 수 있다. 이하에서는 도 3을 통해 제1 딥러닝 알고리즘이 학습하는 과정에서 구체적인 또다른 일 예를 상술하도록 한다. 도 3은 본 개시에 따른 제1 딥러닝 알고리즘에서 이미지 데이터와 CAN 데이터에 관한 가중치 설정에 관한 단계 를 설명하기 위한 순서도이다. 단계 S210에서, 위험도 판단 장치는 이미지 데이터의 제1 가중치를 설정할 수 있다. 여기서, 제1 딥러닝 알고리즘을 학습하기 위한 라벨링 데이터를 생성하는 과정에서 위험도 판단 장치는 이 미지 데이터의 제1 가중치를 설정할 수 있다. 상기 제1 가중치는 이미지 데이터에 대응하는 라벨링 데이터를 생 성하는 과정에서 특정 라벨링 데이터의 높은 가중치에 관한 것일 수 있다. 예를 들어, 위험도 판단 장치는 앞서 상술한 3가지 상황으로 라벨링 된 이미지 데이터에서 위험 상황이 라벨링 된 데이터 중, 보행자 중 어린아 이가 포함된 이미지 데이터에는 제1 가중치를 설정하여 보다 위험한 상황으로 판단할 수 있다. 또는 위험도 판 단 장치는 이미지 데이터 중 위험 상황이 라벨링 된 데이터에 대해서 안전 표지판을 포함하고 있는 경우, 제1 가중치를 설정하여 보다 위험한 상황으로 판단할 수 있다. 따라서 제1 가중치가 설정된 라벨링 데이터는 보 다 위험한 상황에 대응하는 이미지 데이터일 수 있다. 이는 일 예에 해당할 뿐, 앞서 상술한 구체적인 예시에 국한되어 해석되는 것은 아니다. 단계 S220에서, 위험도 판단 장치는 CAN 데이터의 제2 가중치를 설정할 수 있다. 위험도 판단 장치는 CAN 데이터 중 제2 가중치를 활용하여 보다 위험한 상황을 판단할 수 있다. 예를 들어, 위험도 판단 장치는 앞서 상술한 3가지 상황으로 라벨링 된 경우에 적어도 하나 이상의 CAN 데이터 에 대해서 3가지 상황으로 라벨링 된 데이터를 생성할 수 있다. 여기서 위험도 판단 장치는 제2 가중치를 활용하여 CAN 데이터 중 위험 상황으로 라벨링 된 데이터에 대해서 보다 높은 위험 상황으로 판단할 수 있다. 보다 구체적으로, 위험도 판단 장치는 CAN 데이터 중 급발진 데이터를 기초로 급발진 속도를 기준으로 기 설정된 제1 임계 속도 이상인 경우 위험 상황으로, 기 설정된 제1 임계 속도 이하이나 제2 임계 속도 이상인 경 우, 보통 상황으로 제2 임계 속도 이하인 경우 안전한 상황으로 라벨링 데이터를 생성할 수 있다. 여기서 위험 도 판단 장치는 제1 임계 속도를 초과하여 위험 상황으로 라벨링 된 데이터에 대해서 CAN 데이터가 생성되 는 시점 및 상기 시점에서 획득되는 이미지 데이터가 포함하는 여러 정보를 기초로 제2 가중치를 설정할 수 있 다. 예를 들어, 상기 CAN 데이터가 생성되는 시점에 대응하는 이미지 데이터에서 보행자가 포함된 경우, 안전 표지판이 포함되어 있는 경우, 보행자 중 어린아이가 있는 경우에는 제2 가중치를 설정하여 보다 위험한 상황으 로 판단할 수 있다. 상기 제1 가중치와 제2 가중치를 서로 상이한 값이거나 같은 값일 수 있다. 다시 도 2로 돌아와, 단계 S300에서, 위험도 판단 장치는 제1 딥러닝 알고리즘의 출력값을 기초로 제1 시 점에 제1 이미지를 캡쳐할 수 있다. 위험도 판단 장치는 이미 학습된 제1 딥러닝 알고리즘을 활용하여 이미지 데이터가 입력되면 라벨링 데이 터와 대응되는 특징을 가지는 이미지를 캡쳐할 수 있다. 예를 들어, 위험도 판단 장치는 앞서 상술한 운전 위험도 상황이 위험 상황, 보통 상황, 안전한 상황인 경우에 있어, 위험 상황으로 라벨링 된 데이터와 특징이 대응되는 제1 이미지를 캡쳐할 수 있다. 따라서 제1 이미지는 주행 차량의 주행 중 위험 상황으로 판단된 라벨링 데이터가 포함하고 있는 이미지 특징과 대응되거나 유사한 특징을 포함하고 있을 수 있다. 위험도 판단 장치는 제1 이미지를 캡쳐한 시점, 즉 제1 이미지가 획득된 시점을 제1 시점으로 기록하고 이 를 제1 이미지와 대응하여 캡쳐할 수 있다. 예를 들어, 제1 이미지가 캡쳐된 경우, 제1 이미지가 획득된 시점을 기록하여 제1 이미지의 획득 시점인 제1 시점을 기록할 수 있다. 단계 S400에서, 위험도 판단 장치는 제1 이미지를 커넥트 프로그램으로 송신할 수 있다. 위험도 판단 장치는 캡쳐된 제1 이미지를 커넥트 프로그램으로 송신할 수 있다. 상기 커넥트 프로그램은 운전자 APP 또는 웹에 설치되어 있는 운전자의 운전 위험도 관련 정보를 제공하는 프로그램일 수 있다. 또는 상 기 커넥트 프로그램은 운전자의 운전 습관 및 위험도 상황을 판단하여 운전자의 보험료를 산정해주는 특정 APP 또는 웹일 수 있다. 위험도 판단 장치는 상기 제1 이미지를 캡쳐된 그대로 커넥트 프로그램으로 제공할 수도 있다. 이하 구체 적인 일 예는 도 4를 통해 보다 상술하도록 한다. 도 4는 본 개시에 따른 제1 이미지를 커넥티드 프로그램으로 송신하는 단계를 구체적으로 설명하기 위한 순서도 이다. 단계 S410에서, 위험도 판단 장치는 커넥트 프로그램을 통해 운전자 위험 상황에 관한 정보를 제공할 수 있다. 위험도 판단 장치는 캡쳐된 제1 이미지에서 제1 이미지에 대응하는 정보를 산출하여 이를 커넥트 프 로그램에 제공할 수 있다. 예를 들어, 위험도 판단 장치는 제1 이미지가 캡쳐된 제1 시점, 제1 이미지에 캡쳐된 시점에서의 주행 차량의 위치, 제1 이미지 내에 차량 여부, 차량 대수, 보행자 여부, 보행자 수, 보행자 중 어린아이의 여부, 어린아이 수 등으로 포함하는 정보를 산출하고 이를 위험 상황에 관한 정보로서 커 넥트 프로그램에 제공할 수 있다. 이를 통해 운전자는 커넥트 프로그램에서 운전자의 주행 위험 상황이 어떤 상 황이었고, 이에 관한 정보를 제공받아, 향후 본인의 운전 습관에 대해 대비하거나 위험한 상황과 유사한 상황에 서 보다 안전한 주행을 하도록 할 수 있다. 단계 S420에서, 위험도 판단 장치는 운전자 위험 상황 정보를 기반으로 운전자 안전도를 산출하여 사용자 에게 제공할 수 있다. 위험도 판단 장치 상기 운전 위험 상황에 관한 정보를 기반으로 운전자의 안전도 점수를 산출하여 사용자 에게 제공할 수 있다. 예를 들어, 위험도 판단 장치는 앞서 상술한 위험 상황에 관한 정보를 기 설정된 기 준에 따라 점수화 하고, 이를 기초로 산출된 운전자의 안전도 점수를 커넥트 프로그램을 통해 제공할 수 있다. 예를 들어, 위험도 판단 장치는 위험 상황으로 판단되어 캡쳐된 제1 이미지에서 보행자 중 어린아이의 수 에 따라 운전자의 위험도를 높게 산정하여 커넥트 프로그램에 제공할 수 있다. 이는 일 예에 해당할 뿐 이에 한 정되어 해석되지 아니한다. 이하에서는 위험도 판단 장치가 포함하는 제2 딥러닝 알고리즘을 활용하여 이미지를 캡쳐하는 시점을 학습 하는 과정에 대해 상술하도록 한다. 도 5는 본 개시에 따른 제2 딥러닝 알고리즘을 학습하는 방법에 관한 순서도이다. 위험도 판단 장치는 제2 딥러닝 알고리즘을 활용하여 제1 이미지를 캡쳐한 제1 시점에 대해, 제1 시점에 제1 이미지를 캡쳐한 수행 프로세스가 보다 효율적으로 진행될 수 있도록 주기적으로 업데이트 할 수 있다. 보 다 구체적으로 상술하면, 위험도 판단 장치는 제1 딥러닝 알고리즘에서 제1 이미지를 캡쳐한 제1 시점이 이미지를 획득한 시점으로서 적절한지 여부에 대해서 지속적으로 판단하고, 이를 조정할 수 있다. 이를 통해, 주행 차량에서 모든 시점에 대응하는 모든 이미지를 획득하는 것이 아니라, 가장 필요한 시점에 대한 이미 지만 획득하여 활용하는 바, 데이터 리소스 측면에서도 이점을 가지며, 데이터 저장 용량 및 데이터 처리 측면 에서도 이점을 가질 수 있다. 이에 대한 구체적인 설명을 아래와 같이 하도록 한다. 단계 S500에서, 위험도 판단 장치는 제1 이미지와 제1 시점 정보를 획득할 수 있다. 위험도 판단 장치는 제1 딥러닝 알고리즘에서 출력된 값을 기초로 캡쳐된 제1 이미지와 상기 제1 이미지가 캡쳐된 제1 시점에 대한 정보를 획득할 수 있다. 단계 S600에서, 위험도 판단 장치는 제2 딥러닝 알고리즘에 제1 이미지와 제1 시점 정보를 입력할 수 있다. 상기 제2 딥러닝 알고리즘은 강화학습 알고리즘 종류 중 하나일 수 있으며, 제2 딥러닝 알고리즘을 통해 위험도 판단 장치는 제1 시점에 관해 제1 이미지를 획득한 제1 시점이 가장 효율적인 데이터 획득 시점인지 여부 를 판단할 수 있다. 여기서, 제2 딥러닝 알고리즘은 강화학습 알고리즘의 하나로서 환경, 행동, 보상에 관해 주어진 환경에서 상호 작용하여 보상이 높은 쪽으로 행동할 수 있게 하는 딥 러닝 알고리즘일 수 있다. 따라서, 상기 제2 딥러닝 알고 리즘은 크게 Model Free 강화학습 알고리즘, Model Based 강화학습 알고리즘으로 분류될 수 있고, DQN, Q- Learning, ASC, Genetic, SARSA 기법을 활용하는 알고리즘을 포함할 수 있다. 강화학습 알고리즘은 레이블 되어 있지 않은 데이터에 대해 학습하는 비지도 학습(Unsupervised Learning)의 일 종으로 환경과의 상호 작용을 통해 보상을 최대화하도록 행동을 취해서 학습하는 방법으로서, 학습하고자 하는 문제에 맞게 주어진 환경, 행동 및 평가에 의해 학습이 이루어진다. 즉, 행동을 취할 때마다 외부 환경에서 보 상이 주어지는데, 이러한 보상을 최대화시키는 방향으로 강화 학습이 진행된다. 강화학습 알고리즘은 에이전트 와 환경으로 이루어지며, 환경은 상태, 행동, 보상으로 이루어진다. 에이전트는 환경에서 상태를 관찰하고 행동 을 선택하는 학습을 수행하는 주체이며, 에이전트가 행하는 행동으로 보상을 받게 되고, 에이전트는 이러한 보 상을 최대화하는 방향으로 행동을 취한다. 환경은 에이전트를 제외한 나머지들로서, 확률적이며 행동을 한 후에 환경의 변화와 보상은 일정하지 않다. 특정한 상태에서 수행해야 할 행동을 선택하는 규정을 정책(Policy)라고 한다. 일 예로, 강화학습 알고리즘은 제어의 주체인 에이전트의 최적화 제어(Optimal Control) 문제를 위하여 Bellman 이 Markov Decision Process(MDP)를 기반으로 만든 Bellman Equation을 기초로 할 수 있다. 먼저 상기 MDP는 처음 시간 t = 0에서 어떠한 상태 S0로부터 시작하여 현재의 상태 St로 도착할 확률이 바로 이전의 상태 St-1에 서 현재의 상태 St까지 올 확률과 같다면 이는 Markov하다고 표현하며, 아래의 수학식 1로 표현할 수 있다. 수학식 1"}
{"patent_id": "10-2022-0182596", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "여기서 액션 At는 에이전트가 취하는 액션을 나타내며, 리워드 Rt는 에이전트가 액션을 취한 후의 환경, 즉 주변 환경을 고려하였을 때 얼마나 의도한대로 움직였는지를 수치적으로 나타낸다. 강화학습은 일반적으로 상태 St가 이전의 상태 St-1과 Markov한 관계를 가진다고 가정하고 학습을 수행하기 때문에 한 에피소드가 끝난 후 받은 리 워드는 이전의 상태들과 관련이 있다고 할 수 있으며, 위의 관계를 이용하여 DQN의 학습을 위한 가치 함수 (Value Function)를 유도한다. 에이전트는 각 스텝마다 액션을 취했을 때 외란 등에 의해 상태 St에 확률적으로 도달하게 되며 이 상태에 따른 리워드를 즉시 얻게 된다. 한 에피소드가 끝났을 때 매 타임 스텝에서 받은 리워 드의 총 합이 높을수록 학습이 잘 되었다고 할 수 있으며, 에이전트의 상태에 따라 얻을 수 있는 리워드 총합의 기댓값은 State Value Function이라 표현한다. State Value Function은 수학식 2와 같이 나타낼 수 있다. 수학식 2"}
{"patent_id": "10-2022-0182596", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "기댓값으로 나타내는 이유는 에이전트가 상태 St에 도달하는 것은 확률에 따르기 때문이며, Gt는 환경으로부터 얻은 리워드의 총합을 나타내고 수학식 3과 같이 나타낼 수 있다. 수학식 3"}
{"patent_id": "10-2022-0182596", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "일 예는 강화학습 알고리즘의 기본 수식을 설명한 것이며, 제2 딥러닝 알고리즘에서 수행될 수 있는 일 예를 상 술한 것인 바, 이에 한정되는 것은 아님에 유의해야 한다. 단계 S700에서, 위험도 판단 장치는 제2 딥러닝 알고리즘에서 이미지를 캡쳐하는 제2 시점 정보에 관해 출 력할 수 있다. 위험도 판단 장치가 포함하는 제2 딥러닝 알고리즘에서 강화학습의 주요 구성요소인 행동은 이미지를 캡쳐 하는 시점의 적어도 하나 이상의 시점으로 변화하는 것 이고, 상태는 제1 딥러닝 알고리즘의 이미지 캡쳐 시점 이며, 보상은 제1 딥러닝 알고리즘의 적어도 하나 이상의 복수의 시점에서 획득한 이미지에 대해 제1 딥러닝 알 고리즘 모델의 딥러닝 모델의 정확도 또는 효용성일 수 있다. 또는 제1 딥러닝 알고리즘 모델의 예측 정확도일 수 있다. 상기 딥러닝 모델의 정확도, 효용성 및 예측 정확도는 본 발명의 주된 기술적 특징은 아니한 바, 통상 의 기술자가 이해할 수 있는 범위에서 딥러닝 모델을 평가하는 평가 척도의 방법이 모두 활용될 수 있다. 즉, 강화학습 알고리즘인 제2 딥러닝 알고리즘을 활용하여 제1 딥러닝 알고리즘에서 출력하여 캡쳐되는 시점인 제1 시점에 대해 가장 최적화된 이미지 캡쳐 시점인지 여부를 판단할 수 있다. 따라서, 강화학습 알고리즘인 제 2 딥러닝 알고리즘을 통해 위험도 판단 장치는 모든 시점에서 이미지를 획득, 저장, 처리하는 것이 아니라, 실제 위험도 판단에 필요한 상황 및 시점에 대해서만 이미지를 획득, 저장, 처리할 수 있어 기존 딥러 닝 알고리즘 모델에 비해 효율성을 확보할 수 있다. 단계 S800에서, 위험도 판단 장치는 제2 시점 정보에 따라 제2 딥러닝 알고리즘을 학습할 수 있다. 즉, 제 2 딥러닝 알고리즘은 이미지를 캡쳐하는 복수의 시점을 지속적으로 업데이트하여 이미지를 캡쳐하여, 이를 제1 딥러닝 알고리즘의 예측 정확도를 향상하는 방향으로 학습할 수 있다. 이를 통해 제2 딥러닝 알고리즘의 학습도 지속적으로 진행되고, 제1 딥러닝 알고리즘 모델의 예측 정확도도 향 상될 수 있다. 이하에서는 도 6을 활용하여 제2 시점에 관한 정보를 출력하는 단계를 구체적으로 상술하도록 한다. 도 6은 본 개시에 따른 제2 딥러닝 알고리즘에서 제2 시점에 정보에 관해 출력하는 단계를 구체적으로 설명하기 위한 순서도이다. 단계 S710에서, 위험도 판단 장치는 제2 시점에서 캡쳐한 제2 이미지를 획득할 수 있다. 앞서 도 5에서 상술한 바와 같이 제2 딥러닝 알고리즘은 복수의 시점에 대해서 강화학습을 수행하여 제1 딥러닝 알고리즘 모델의 예측 정확도를 향상할 수 있는 방향으로 강화학습 주요 인자 중 행동을 수행할 수 있다. 이 때, 제2 딥러닝 알고리즘은 학습하는 시점에서 제1 시점 보다 제2 시점의 이미지를 획득하는 것이 제1 딥러닝 알고리즘의 예측 정확도를 향상하는 방향인 것으로 판단할 수 있다. 단계 S720에서, 위험도 판단 장치는 제2 이미지를 제1 딥러닝 알고리즘에 입력하여 학습할 수 있다. 제2 딥러닝 알고리즘에서 제2 시점의 정보를 획득하고, 제2 시점에서 획득한 이미지를 제2 이미지라 가정하면, 위험 도 판단 장치는 제1 딥러닝 알고리즘에 제2 이미지를 입력하여 학습 과정을 수행할 수 있다. 이 때, 위험 도 판단 장치 제2 이미지를 제1 이미지를 포함한 다른 라벨링 된 이미지 데이터와 동일하기 처리할 수 있 으나 상이하게 처리할 수도 있다. 상기 상이한 처리는 단계 S730을 통해 설명할 수 있다. 단계 S730에서, 위험도 판단 장치는 제2 이미지에 대응하는 제3 가중치와 함께 제2 이미지를 제1 딥러닝 알고리즘에 입력하여 학습할 수 있다. 여기서, 위험도 판단 장치는 제2 이미지에 가해지는 제3 가중치를 설정하여 제1 이미지를 포함한 다른 이 미지 보다 제2 이미지의 특징에 대해서 더 과중하게 처리할 수 있다. 상기 과중하게 처리하는 것의 의미는 제3 가중치를 앞서 상술한 다른 가중치보다 높은 값으로 설정하여 제2 이미지를 보다 잘 활용할 수 있는 것일수 있다. 따라서, 제3 가중치는 제1 가중치와 제2 가중치 값보다 높은 값일 수 있고, 제3 가중치는 제1 가중치와 제2 가중치와 같은 값을 가질 수 있음은 당연하다. 이를 통해, 위험도 판단 장치는 제2 시점에 관한 정보를 기초로 획득된 이미지인 제2 이미지를 제1 딥러닝 알고리즘에서도 활용할 수 있어 보다 효율적이고 정확한 딥러닝 모델을 가져갈 수 있다. 이하에서는 도 7과 8을 활용하여 본 발명의 개시에 따른 위험도 판단 장치가 포함하는 제1 딥러닝 알고리 즘과 제2 딥러닝 알고리즘을 예시도면을 통해 상술하도록 한다. 도 7은 본 개시에 따른 제1 딥러닝 알고리즘에서 이미지 데이터와 CAN 데이터를 입력하여 제1 이미지를 캡쳐하 는 방법에 관한 예시도면이다. 도 7을 살펴보면, 이미지 데이터와 CAN 데이터가 제1 딥러닝 알고리즘(30-1)에 입력되어 제1 시점에 관 한 제1 이미지에 관한 정보를 출력하고, 위험도 판단 장치는 제1 시점에 관한 제1 이미지을 캡쳐 할 수 있다. 여기서 이미지 데이터은 주행 차량이 주행하는 중에 획득하는 이미지 데이터일 수 있으며, 정차 중에 획득할 수 있음은 당연하다. 여기서, 제1 딥러닝 알고리즘(30-1)은 기 학습된 딥러닝 알고리즘일 수 있으며, 제1 딥러닝 알고리즘(30-1)은 복수의 이미지 데이터와 CAN 데이터가 입력되면, 제1 딥러닝 알고리즘 내 특징값을 추출하는 아키텍쳐 를 통해 기 학습된 과정에서 라벨링된 데이터와 대응되어 가장 유사한 이미지 데이터에 관한 정보를 출력할 수 있다. 위험도 판단 장치는 이 과정에서 가장 유사한 이미지 데이터에 관한 정보인 제1 시점을 추출하고, 제1 시점에서 제1 이미지를 캡쳐하여 이를 저장할 수 있다. 앞서 상술한 바와 같이, 제1 딥러닝 알고리즘은 운전 위험 상황에 대해 미리 설정된 라벨링 이미지 데이터를 통 해 학습된 딥러닝 알고리즘 일 수 있으며, 이에 대한 구체적인 설명은 앞서 상술한 바 생략하기로 한다. 도 8은 본 개시에 따른 제2 딥러닝 알고리즘에서 제1 시점 정보를 학습하여 제2 시점 정보를 출력하는 방법에 관한 예시도면이다. 위험도 판단 장치에서 캡쳐한 적어도 하나 이상의 제1 이미지에 대해서 각 제1 이미지에 대응하는 제1 시점 정보을 기초로 강화학습 알고리즘인 제2 딥러닝 알고리즘(30-2)을 통해 제2 시점 정보를 출력할 수 있다. 여기서, 제2 딥러닝 알고리즘(30-2)은 기 학습된 강화학습 알고리즘일 수 있다. 따라서, 제2 딥러닝 알고리즘 (30-2)은 제1 이미지와 제1 시점 정보가 입력되면, 제1 딥러닝 알고리즘의 예측 정확도를 향상시킬 수 있는 방향으로 제2 시점 정보을 출력할 수 있다. 상기 제2 시점 정보은 제1 딥러닝 알고리즘에서 제2 시점을 기초로 이미지를 캡쳐하고, 이를 기초로 제1 딥러닝 알고리즘을 학습한 결과, 제1 딥러닝 알고리즘의 예 측 정확도가 향상되는 방향일 수 있다. 이에, 위험도 판단 장치는 제2 시점 정보와 대응되는 제3 가중 치를 활용할 수 있음은 앞서 상술한 바, 생략하기로 한다. 상기 도 7과 8에서 도시한 것과 같이 제1 딥러닝 알고리즘(30-1), 제2 딥러닝 알고리즘(30-2)를 통해 위험도 판 단 장치는 운전자의 위험 상황을 판단하고, 그에 대한 이미지를 획득하는 과정을 보다 정확하게 향상할 수 있다. 이하에서는, 도 9를 활용하여 본 발명의 실시예가 적용될 수 있는 시스템에 대해서 설명하도록 한다. 도 9는 본 개시의 다양한 실시예에 따른 장치 및/또는 시스템을 구현할 수 있는 예시적인 컴퓨팅 장치 도면이다. 컴퓨팅 장치는 하나 이상의 프로세서, 버스, 통 신 인터페이스, 프로세서에 의 하여 수행되는 컴퓨터 프로그램을 로드(load)하는 메모리와, 컴퓨터 프로그램을 저장하는 스 토리지 를 포함할 수 있다. 다만, 도 9에는 본 개시의 실시예와 관련 있는 구성 요소들 만이 도시되어 있"}
{"patent_id": "10-2022-0182596", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "다. 따라서, 본 개시가 속한 기술분야의 통상의 기술자라면 도 9에 도시된 구성 요소들 외에 다른 범용적인 구 성 요소들이 더 포함될 수 있음을 알 수 있다.프로세서는 컴퓨팅 장치의 각 구성의 전반적인 동작을 제어한다. 프로세서는 CPU(Central Processing Unit), MPU(Micro Processor Unit), MCU(Micro Controller Unit), GPU(Graphic Processing Unit) 또는 본 개시의 기술 분야에 잘 알려진 임의의 형태의 프로세서를 포함하여 구성될 수 있다. 또한, 프로세서 는 본 개시의 실시예들에 따른 방법을 실행하기 위한 적어도 하나의 애플리케이션 또는 프로그램에 대한 연산을 수행할 수 있다. 컴퓨팅 장치 는 하나 이상의 프로세서를 구비할 수 있다. 메모리는 각종 데이터, 명령 및/또는 정보를 저장한다. 메모 리는 본 개시의 실시예들에 따른 방법 을 실행하기 위하여 스토리지로부터 하나 이상의 프로그램을 로드할 수 있다. 메모리는 RAM 과 같은 휘발성 메모리로 구현될 수 있을 것이나, 본 개시의 기술적 범위가 이에 한정되는 것은 아니다. 버스는 컴퓨팅 장치의 구성 요소 간 통신 기능을 제공한다. 버스는 주소 버스(Address Bus), 데이터 버스(Data Bus) 및 제어 버스 (Control Bus) 등 다양한 형태의 버스로 구현될 수 있다. 통신 인터페이스는 컴퓨팅 장치의 유무선 인터넷 통신을 지원한다. 또한, 통신 인터페이스는 인터넷 통신 외의 다양한 통신 방식을 지원할 수도 있다. 이를 위해, 통신 인터페이스는 본 개시의 기술 분야에 잘 알려진 통신 모듈을 포함하여 구성될 수 있다. 몇몇 실시예들에 따르면, 통신 인터페이스는 생략될 수도 있다. 스토리지는 상기 하나 이상의 프로그램과 각종 데이터를 비임시적으로 저장할 수 있다. 스토리지는 ROM(Read Only Memory), EPROM(Erasable Programmable ROM), EEPROM(Electrically Erasable Programmable ROM), 플래시 메 모리 등과 같은 비휘발성 메모리, 하드 디스크, 착탈형 디스크, 또는 본 개시가 속 하는 기술 분야에서 잘 알려진 임의의 형태의 컴퓨터로 읽을 수 있는 기록 매체를 포함하여 구성될 수 있다. 컴퓨터 프로그램은 메모리에 로드 될 때 프로세서로 하여금 본 개시의 다양한 실시예에 따른 방법/동작을 수행하도록 하는 하나 이상의 인스트럭션들을 포함할 수 있다. 즉, 프로세서는 상기 하나 이 상의 인스트럭션들을 실행함으로써, 본 개시의 다양한 실시예에 따른 방법/동작들을 수행할 수 있다. 지금까지 도 1 내지 도 9를 참조하여 본 개시의 다양한 실시예들 및 그 실시예들에 따른 효과들을 언급하였다. 본 개시의 기술적 사상에 따른 효과 들은 이상에서 언급한 효과들로 제한되지 않으며, 언급되지 않은 또 다른 효과들은 명세서의 기재로부터 통상의 기술자에게 명확하게 이해될 수 있을 것이다. 지금까지 도 1 내지 도 9을 참조하여 설명된 본 개시의 기술적 사상은 컴퓨터가 읽을 수 있는 매체 상에 컴퓨터 가 읽을 수 있는 코드로 구현될 수 있다. 상기 컴퓨터로 읽을 수 있는 기록 매체는, 예를 들어 이동형 기록 매 체(CD, DVD, 블루레이 디스크, USB 저장 장치, 이동식 하드 디스크)이거나, 고정식 기록 매체(ROM, RAM, 컴퓨터 구비 형 하드 디스크)일 수 있다. 상기 컴퓨터로 읽을 수 있는 기록 매체에 기록된 상기 컴퓨터 프로그램은 인 터넷 등의 네트워크를 통하여 다른 컴퓨팅 장치에 전송되어 상기 다른 컴퓨팅 장치에 설치될 수 있고, 이로써 상 기 다른 컴퓨팅 장치에서 사용될 수 있다. 이상에서, 본 개시의 실시예를 구성하는 모든 구성 요소들이 하나로 결합되거나 결합되어 동작하는 것으로 설명 되었다고 해서, 본 개시의 기술적 사상이 반드시 이러한 실시예에 한정되는 것은 아니다. 즉, 본 개시의 목적 범위 안에 서라면, 그 모든 구성 요소들이 하나 이상으로 선택적으로 결합하여 동작할 수도 있다. 도면에서 동작들이 특정한 순서로 도시되어 있지만, 반드시 동작들이 도시된 특정한 순서로 또는 순차적 순서로 실행되어야만 하거나 또는 모든 도시 된 동작들이 실행되어야만 원하는 결과를 얻을 수 있는 것으로 이해되어서 는 안 된다. 특정 상황에서는, 멀티태스킹 및 병렬 처리가 유리할 수도 있다. 더욱이, 위에 설명한 실시예들에 서 다양한 구성들의 분리는 그러한 분리가 반드시 필요한 것으로 이해되어서는 안 되고, 설명된 프로그램 컴포 넌트들 및 시스템들은 일반적으로 단일 소프트웨어 제품으로 함께 통합되거나 다수의 소프트웨어 제품으로 패키 지 될 수 있음을 이해하여야 한다."}
{"patent_id": "10-2022-0182596", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "이상 첨부된 도면을 참조하여 본 개시의 실시예들을 설명하였지만, 본 개시가 속하는 기술분야에서 통상의 지식 을 가진 자는 그 기술적 사상이나 필수 적인 특징을 변경하지 않고서 본 개시가 다른 구체적인 형태로도 실시될 수 있다는 것을 이해할 수 있다. 그러므로 이상에서 기술한 실시예들은 모든 면에서 예시적인 것이며 한정적인 것이 아닌 것으로 이해해야만 한다. 본 개시의 보호 범위는 아래의 청구범위에 의하여 해석되어야 하며, 그와 동등한 범위 내에 있는 모든 기술 사 상은 본 개시에 의해 정의되는 기술적 사상의 권리범위에 포함되는 것으로 해석되어야 할 것이다.도면 도면1 도면2 도면3 도면4 도면5 도면6 도면7 도면8 도면9"}
{"patent_id": "10-2022-0182596", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 개시의 몇몇 실시예에 위험도 판단 장치가 적용될 수 있는 예시적인 환경을 도시한다. 도 2은 본 개시의 몇몇 실시예에 따라 위험도 판단 장치에서 수행될 수 있는 운전자 주행 위험 상황에 관한 이 미지 데이터를 분석하는 방법에 관한 순서도이다. 도 3은 본 개시에 따른 제1 딥러닝 알고리즘에서 이미지 데이터와 CAN 데이터에 관한 가중치 설정에 관한 단계 를 설명하기 위한 순서도이다. 도 4는 본 개시에 따른 제1 이미지를 커넥티드 프로그램으로 송신하는 단계를 구체적으로 설명하기 위한 순서도 이다. 도 5는 본 개시에 따른 제2 딥러닝 알고리즘을 학습하는 방법에 관한 순서도이다. 도 6은 본 개시에 따른 제2 딥러닝 알고리즘에서 제2 시점에 정보에 관해 출력하는 단계를 구체적으로 설명하기 위한 순서도이다. 도 7은 본 개시에 따른 제1 딥러닝 알고리즘에서 이미지 데이터와 CAN 데이터를 입력하여 제1 이미지를 캡쳐하 는 방법에 관한 예시도면이다. 도 8은 본 개시에 따른 제2 딥러닝 알고리즘에서 제1 시점 정보를 학습하여 제2 시점 정보를 출력하는 방법에 관한 예시도면이다. 도 9는 본 개시의 다양한 실시예에 따른 장치 및/또는 시스템을 구현할 수 있는 예시적인 컴퓨팅 장치 도면이다."}
