{"patent_id": "10-2021-0060794", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2022-0153341", "출원번호": "10-2021-0060794", "발명의 명칭": "매트 상에서 이동한 학습자의 촬영 영상 분석 방법", "출원인": "김병수", "발명자": "김병수"}}
{"patent_id": "10-2021-0060794", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "(a) 학습자에게 질의 정보를 출력하는 단계;(b) 상기 질의 정보에 따라 매트 상에서 이동하는 상기 학습자를 촬영한 영상을 획득하는 단계;(c) 상기 영상에 대한 분석을 수행하여 상기 질의 정보에 대응하는 답변 정보를 획득하는 단계; (d) 상기 답변 정보가 기 설정된 답안 정보에 해당하는 지 여부를 판별하는 단계; 및(e) 상기 판별 정보를 상기 학습자에게 제공하는 단계;를 포함하는,매트 상에서 이동한 학습자의 촬영 영상 분석 방법."}
{"patent_id": "10-2021-0060794", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1항에 있어서,상기 (c)는,(c-1) 상기 영상에 포함된 전체 프레임들 각각에 대해, 상기 학습자에 해당하는 제2 객체의 제2 영역이 상기 매트에 해당하는 제1 객체의 제1 영역의 분할 영역들 중 어느 하나에 오버랩되는 소정의 조건을 만족한 것인지 여부를 판별하는 단계; 및(c-2) 상기 전체 프레임들 각각 중 상기 소정의 조건을 만족한 프레임들에 기초해 상기 답변 정보를 획득하는단계;를 포함하는,매트 상에서 이동한 학습자의 촬영 영상 분석 방법."}
{"patent_id": "10-2021-0060794", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 2항에 있어서, 상기 (c-2)는,상기 전체 프레임들 각각 중 상기 소정의 조건을 만족한 상기 프레임들 각각을 대상 프레임들로 정의하는 단계;상기 대상 프레임들 중 미리 정해진 시간 구간 이상의 시간 동안 연속되는 대상 프레임들로 구성된 적어도 하나의 대상 프레임 그룹을 선별하는 단계;상기 적어도 하나의 대상 프레임 그룹 각각에 매핑되는 식별 정보들을 추출하는 단계; 및상기 식별 정보를 기초로 상기 답변 정보를 획득하는 단계;를 포함하는,매트 상에서 이동한 학습자의 촬영 영상 분석 방법."}
{"patent_id": "10-2021-0060794", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 3항에 있어서, 상기 식별 정보 추출 단계는,상기 식별 정보를 시간 순서에 따라 추출하는 단계;를 포함하고,공개특허 10-2022-0153341-3-상기 답변 정보 획득 단계는,상기 시간 순서에 따라 추출된 상기 식별 정보들을 조합하여 상기 답변 정보를 획득하는 단계;를 포함하는,매트 상에서 이동한 학습자의 촬영 영상 분석 방법."}
{"patent_id": "10-2021-0060794", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제 3항에 있어서,상기 대상 프레임 그룹 구별 단계는,상기 대상 프레임들 중 상기 미리 정해진 시간 구간의 배수만큼의 시간 동안 연속되는 대상 프레임들로 구성된대상 프레임 그룹을 구별하는 단계;를 포함하고,상기 식별 정보 추출 단계는,상기 대상 프레임 그룹에 매핑되는 식별 정보들을 상기 배수만큼 추출하는 단계;를 포함하는,매트 상에서 이동한 학습자의 촬영 영상 분석 방법."}
{"patent_id": "10-2021-0060794", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제 2항에 있어서,상기 (c-1)은,인공 지능 기반의 학습 모델을 통해 상기 제2 객체가 상기 학습자임을 식별하는 식별 정보와 상기 제1 객체가상기 매트에 해당함을 식별하는 식별 정보를 획득하는 단계;를 포함하는,매트 상에서 이동한 학습자의 촬영 영상 분석 방법."}
{"patent_id": "10-2021-0060794", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제 2항에 있어서,상기 (c-1)은,상기 제2 객체의 상기 제2 영역 중 특정 신체를 나타내는 영역이 상기 제1 객체의 상기 제1 영역의 상기 분할영역들 중 어느 하나에 오버랩되는 소정의 조건을 만족한 것인지 여부를 판별하는, 매트 상에서 이동한 학습자의 촬영 영상 분석 방법."}
{"patent_id": "10-2021-0060794", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "학습자에게 질의 정보를 출력하는 출력부;상기 질의 정보에 따라 매트 상에서 이동하는 상기 학습자를 촬영한 영상을 획득하는 카메라부; 및상기 영상에 대한 분석을 수행하여 상기 질의 정보에 대응하는 답변 정보를 획득하고, 상기 답변 정보가 기 설정된 답안 정보에 해당하는 지 여부를 판별하며, 상기 판별 정보를 상기 학습자에게 제공하는 제어부;를 포함하는,영상 분석 장치."}
{"patent_id": "10-2021-0060794", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "실시예에 따른 매트 상에서 이동한 학습자의 촬영 영상 분석 방법은, (a) 학습자에게 질의 정보를 출력하는 단계; (b) 상기 질의 정보에 따라 매트 상에서 이동하는 상기 학습자를 촬영한 영상을 획득하는 단계; (c) 상기 영상에 대한 분석을 수행하여 상기 질의 정보에 대응하는 답변 정보를 획득하는 단계; (d) 상기 답변 정보가 기 설정된 답안 정보에 해당하는 지 여부를 판별하는 단계; 및 (e) 상기 판별 정보를 상기 학습자에게 제공하는 단 계;를 포함할 수 있다."}
{"patent_id": "10-2021-0060794", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 매트 상에서 이동한 학습자의 촬영 영상 분석 방법에 관한 것으로, 보다 구체적으로 매트 상에서 이 동한 학습자를 촬영하여 획득된 영상에 대한 분석 결과를 기초로 질의 정보에 대응한 답변 정보를 획득하기 위 한, 매트 상에서 이동한 학습자의 촬영 영상 분석 방법에 관한 것이다."}
{"patent_id": "10-2021-0060794", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "최근에는 일반 집안에서 쓰는 매트를 이용하여 아이의 놀이나 학습에 이용하고자 하는 니즈가 있다. 이와 관련하여 대부분의 선행 기술들의 경우, 매트에 센서를 부착하여 아이가 센서를 밟아 감지되는 정보를 이 용하여 단말기와 통신을 함으로써 놀이나 학습에 이용하고자 한다. 하지만, 이와 같이 매트에 센서를 부착하면 매트의 가격도 비싸지고, 매트를 밟게 되면 고장이 발생할 가능성도 높아지게 된다. 더불어, 매트를 유아 및 아동의 학습 및 놀이에 이용하는 경우, 정적인 학습 뿐 아니라 동적인 학습을 수행하고 자 하는 경우, 부딪히거나 넘어지면 안전 사고가 발생할 염려가 있게 된다."}
{"patent_id": "10-2021-0060794", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 전술한 문제점을 해결하기 위해 도출된 것으로, 센서가 장착되지 않은 일반 가정용 매트를 이용하더 라도 촬영 영상을 이용해 학습자의 행동을 분석하여 원하는 정보를 획득하기 위한 방법을 제공하고자 하는 데에 그 목적이 있다."}
{"patent_id": "10-2021-0060794", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "실시예에 따른 매트 상에서 이동한 학습자의 촬영 영상 분석 방법은, (a) 학습자에게 질의 정보를 출력하는 단 계; (b) 상기 질의 정보에 따라 매트 상에서 이동하는 상기 학습자를 촬영한 영상을 획득하는 단계; (c) 상기 영상에 대한 분석을 수행하여 상기 질의 정보에 대응하는 답변 정보를 획득하는 단계; (d) 상기 답변 정보가 기 설정된 답안 정보에 해당하는 지 여부를 판별하는 단계; 및 (e) 상기 판별 정보를 상기 학습자에게 제공하는 단 계;를 포함할 수 있다. 상기 (c)는, (c-1) 상기 영상에 포함된 전체 프레임들 각각에 대해, 상기 학습자에 해당하는 제2 객체의 제2 영 역이 상기 매트에 해당하는 제1 객체의 제1 영역의 특정 분할 영역에 오버랩되는 소정의 조건을 만족한 것인지 여부를 판별하는 단계; 및 (c-2) 상기 전체 프레임들 각각 중 상기 소정의 조건을 만족한 프레임들에 기초해 상 기 답변 정보를 획득하는 단계;를 포함할 수 있다. 상기 (c-2)는, 상기 전체 프레임들 각각 중 상기 소정의 조건을 만족한 상기 프레임들 각각을 대상 프레임들로 정의하는 단계; 상기 대상 프레임들 중 미리 정해진 시간 구간 이상의 시간 동안 연속되는 대상 프레임들로 구 성된 적어도 하나의 대상 프레임 그룹을 선별하는 단계; 상기 적어도 하나의 대상 프레임 그룹 각각에 매핑되는 식별 정보들을 추출하는 단계; 및 상기 식별 정보들을 기초로 상기 답변 정보를 획득하는 단계;를 포함할 수 있 다. 상기 식별 정보 추출 단계는, 상기 식별 정보들을 시간 순서에 따라 추출하는 단계;를 포함하고, 상기 답변 정 보 획득 단계는, 상기 시간 순서에 따라 추출된 상기 식별 정보들을 조합하여 상기 답변 정보를 획득하는 단 계;를 포함할 수 있다. 상기 대상 프레임 그룹 구별 단계는, 상기 대상 프레임들 중 상기 미리 정해진 시간 구간의 배수만큼의 시간 동 안 연속되는 대상 프레임들로 구성된 대상 프레임 그룹을 구별하는 단계;를 포함하고, 상기 식별 정보 추출 단 계는, 상기 대상 프레임 그룹에 매핑되는 식별 정보를 상기 배수만큼 추출하는 단계;를 포함할 수 있다.상기 (c-1)은, 인공 지능 기반의 학습 모델을 통해 상기 제2 객체가 상기 학습자임을 식별하는 식별 정보와 상 기 제1 객체가 상기 매트에 해당함을 식별하는 식별 정보를 획득하는 단계;를 포함할 수 있다. 상기 (c-1)은, 상기 제2 객체의 상기 제2 영역 중 특정 영역이 상기 제1 객체의 상기 제1 영역의 특정 분할 영 역 내에 오버랩되는 소정의 조건을 만족한 것인지 여부를 판별할 수 있다. 실시예에 따른 영상 분석 장치는, 학습자에게 질의 정보를 출력하는 출력부; 상기 질의 정보에 따라 매트 상에서 이동하는 상기 학습자를 촬영한 영상을 획득하는 카메라부; 및 상기 영상에 대한 분석을 수행하여 상기 질의 정보에 대응하는 답변 정보를 획득하고, 상기 답변 정보가 기 설정된 답안 정 보에 해당하는 지 여부를 판별하며, 상기 판별 정보를 상기 학습자에게 제공하는 제어부;를 포함할 수 있다."}
{"patent_id": "10-2021-0060794", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명에 따르면, 센서가 장착되지 않은 일반 가정용 매트를 이용하더라도 촬영 영상을 이용해 학습자의 행동 을 분석하여 원하는 정보를 획득할 수 있게 된다. 본 발명에 따르면, 영상 중 필요한 프레임들만 선별할 수 있게 됨으로써 정확한 답변 정보를 획득할 수 있게 된 다."}
{"patent_id": "10-2021-0060794", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "후술하는 본 발명에 대한 상세한 설명은, 본 발명이 실시될 수 있는 특정 실시예를 예시로서 도시하는 첨부 도 면을 참조한다. 이들 실시예는 당업자가 본 발명을 실시할 수 있기에 충분하도록 상세히 설명된다. 본 발명의 다양한 실시예는 서로 다르지만 상호 배타적일 필요는 없음이 이해되어야 한다. 예를 들어, 여기에 기재되어 있는 특정 형상, 구조 및 특성은 일 실시예에 관련하여 본 발명의 정신 및 범위를 벗어나지 않으면서 다른 실시 예로 구현될 수 있다. 또한, 각각의 개시된 실시예 내의 개별 구성요소의 위치 또는 배치는 본 발명의 정신 및 범위를 벗어나지 않으면서 변경될 수 있음이 이해되어야 한다. 따라서, 후술하는 상세한 설명은 한정적인 의미 로서 취하려는 것이 아니며, 본 발명의 범위는, 적절하게 설명된다면, 그 청구항들이 주장하는 것과 균등한 모 든 범위와 더불어 첨부된 청구항에 의해서만 한정된다. 도면에서 유사한 참조부호는 여러 측면에 걸쳐서 동일하 거나 유사한 기능을 지칭한다. 도 1은 실시예에 따른 매트 상에서 이동한 학습자의 촬영 영상 분석 시스템도이다. 도 1에 도시한 바와 같이, 매트 상에서 이동한 학습자의 촬영 영상 분석 시스템은 영상 분석 장치가 매트 상에서 이동한 학습자를 촬영한 영상을 획득하여 분석함으로써 수행된다. 영상 분석 장치는 영상을 촬영할 수 있는 카메라부와 촬영 영상을 분석하기 위한 제어부를 구비한 스마트폰, 개인용 컴퓨터 등 모든 종류의 전자 장치를 포함한다. 본 발명에 따르면, 영상 분석 장치가 학습자에게 질의 정보를 출력하면, 학습자는 질의 정보를 인식하고 해 당 질의 정보에 대응하여 정답을 맞추기 위해 매트를 이동할 수 있다. 이 때, 매트의 표면에는 표식 (예> 문자, 기호, 도형 등)이 그려져 있고, 학습자는 표식을 인지하여 해당 질의 정보에 매핑하는 표식을 따라 매트 표면 상에서 이동할 수 있다. 특히, 표식은 매트의 분할 부분마다 표시되고, 학습자는 질의 정보에 매핑하는 표식에 일정 시간 머 무름으로써 답변을 할 수 있다. 영상 분석 장치는 이러한 과정들을 촬영한 영상을 분석하여 학습자의 질의 정보에 대응하는 정보를 획득할 수 있다. 도 2는 실시예에 따른 영상 분석 장치의 블록도이고, 도 3은 실시예에 따른 영상 분석 장치의 매트 상에 서 이동한 학습자의 촬영 영상 분석 방법을 설명하는 순서도이며, 도 4 내지 도 7은 도 3의 방법을 설명하기 위 해 참조되는 도면이다. 도 2 내지 도 7을 함께 참조하면, 출력부는 학습자에게 질의 정보를 출력할 수 있다(s31). 질의 정보는 영 상 출력부를 통한 영상 및/또는 음성 출력부를 통한 음성의 형태로 출력되어 학습자에게 제공될 수 있 다. 카메라부는 질의 정보에 따라 매트 상에서 이동하는 학습자를 촬영한 영상을 획득할 수 있다(s32). 제어부는 영상에 대한 분석을 수행하여 질의 정보에 대응하는 답변 정보를 획득할 수 있다(s33). 제어부는 영상에 포함된 전체 프레임들 각각에 대해, 상기 학습자에 해당하는 제2 객체의 제2 영역이 상기 매트에 해당하는 제1 객체의 제1 영역의 분할 영역들 중 어느 하나에 오버랩되는 소정의 조건을 만족한 것인지 여부를 판별하고, 상기 전체 프레임들 각각 중 상기 소정의 조건을 만족한 프레임들에 기초해 상기 답변 정보를 획득할 수 있다. 본 발명에 따르면, 매트는 각 표식마다 대응되는 실제 분할된 영역으로 구성되고, 제1 객체의 제1 영역의 분할 영역들은 이러한 매트의 실제 분할된 영역에 대응되는 부분 이미지로 정의한다. 즉, 제1 객체의 제1 영역의 분할 영역들은 매트의 실제 분할된 영역마다 이에 대응되어 존재할 수 있다. 그리고, 영상이 촬영되는 시간이 경과함에 따라, 각 프레임 이미지에 포함되는 분할 영역의 좌표값은 상이할 수 있다. 예를 들어, 1초에 재생되는 프레임 이미지에 포함되는 분할 영역은 “A”에 대응될 수 있고, 5초에 재생 되는 프레임 이미지에 포함되는 분할 영역은 “P”에 대응될 수 있다. 도 4는 촬영 영상에 포함된 각 프레임 이미지의 예시로, 프레임 이미지는 매트에 해당하는 제1 객체(MO)와 학습 자에 해당하는 제2 객체(BO)를 포함하고, 제1 객체(MO)는 제1 객체 영역(MOA)에 포함되고 제2 객체(BO)는 제2 객체 영역(BOA)에 포함될 수 있다. 이 때, 도 4와 같이 제2 객체 영역(BOA)이 제1 객체 영역(MOA)의 특정 분할 영역(MOAD) 상에 오버랩되는 것으로 판별하면, 제어부는 해당 프레임에 대응하는 식별 정보를 저장부로부터 독출할 수 있다. 즉, 도 4의 경우에는, 제어부는 해당 프레임(F1)에 대응하는 식별 정보 'A'를 저장부로부터 독출할 수 있다. 실시예에 따르면, 해당 프레임(F1)에서 매트를 촬영한 이미지는 매트의 그리드 형태에 대응되도록 복 수의 분할 영역들을 포함할 수 있고, 해당 프레임(F1)이 제2 객체 영역(BOA)이 복수의 분할 영역들 중 특정 분 할 영역(MOAD)에 오버랩된 이미지인 것으로 판별하면, 이에 대응하여 식별 정보 'A'를 저장부로부터 독출할 수 있다. 이를 위하여, 제어부는 미리 매트 상에서 이동하는 학습자를 촬영한 이미지에 대응하는 프레임들을 확 보하고, 각 프레임들에 대응하는 각 식별 정보를 매핑하여 저장부에 기록할 수 있다. 즉, 도 4와 같은 프레임을 획득하여 미리 'A'에 매핑시키고, 도 5와 같은 프레임을 획득하여 미리 'F'에 매핑시 키는 등, 제1 객체 영역(MOA)의 전체 각 분할 영역 각각과 제2 객체 영역(BOA)이 서로 오버랩된 프레임들을 미 리 확보하고, 해당 프레임들에 각각 대응하는 식별 정보를 미리 매핑하여 저장부에 기록할 수 있다. 실시예에 따르면, 제어부는 제1 객체 영역(MOA)의 전체 좌표 정보와 복수의 분할 영역들 각각의 좌표 정보 를 산출하여, 복수의 분할 영역들 중 어떤 영역이 특정 분할 영역(MOAD)에 해당하는 것인가를 판별할 수 있다. 또한, 제1 객체 영역(MOA)의 전체 좌표 정보 및/또는 특정 분할 영역(MOAD)의 좌표 정보와 제2 객체 영역(BOA) 의 좌표 정보를 산출하여 오버랩된 프레임들을 판별하는 데 이용할 수 있다. 그리고, 제2 객체 영역(BOA)의 좌 표 정보와 특정 영역(BOAD)의 좌표 정보를 산출하여 상기 오버랩된 프레임들을 판별하는 데 이용할 수 있다. 또는, 해당 각 좌표 정보들의 상대적인 위치 정보를 이용하여 오버랩된 프레임들을 판별하는 데 이용할 수 있다. 실시예에 따르면, 깊이 카메라(미도시)를 더 구비하여, 3D 공간상의 Z축 좌표를 포함한 3D 좌표를 산출함으로써 오버랩된 프레임들을 판별하는 데 이용할 수 있다. 이를 위하여, 제어부는 제1 객체가 매트에 해당하는 것이고, 제2 객체가 학습자에 해당하는 것임을 식 별하는 식별 정보들과 각 객체와 관련된 좌표 정보들을 인공 지능 기반의 학습 모델을 통해 획득할 수 있다. 예를 들어, 제어부는 도 7과 같은 신경망을 학습하여 생성된 인공 지능 기반의 학습 모델을 통해 식별 정보 들과 좌표 정보들을 획득할 수 있다. 이를 위하여, 우선 제어부는 미리 매트 이미지 및/또는 학습자 이미지에 대한 데이터 셋트를 생성할 수 있 다. 제어부는 생성한 데이터 셋트를 딥러닝 알고리즘에 적용 가능하도록 전처리할 수 있다. 예를 들어, 이미지 자르기(crop), 평행 이동 하기(shift), 뒤집기(flipping), 색상 조정 등의 전처리를 수행할 수 있다. 제어부는 전처리된 데이터 셋트를 미리 준비된 신경망에 입력시키고, 특정 객체의 식별 정보와 좌표 정보들 을 신경망으로부터 출력시키는 기계 학습을 반복적으로 수행하여 학습 모델을 구축할 수 있다. 실시예에 따르면 전처리된 데이터 셋트를 입력으로 하는 합성곱 신경망(Convolutional Neural Networks)과, 합 성곱 신경망의 출력을 입력으로 하는 완전 연결 심층 신경망(Fully Connected Neural Networks)에 대한 기계 학 습을 통해 학습 모델을 구축할 수 있다. 실시예에 따르면, 전처리된 데이터 셋트를 합성곱 신경망이 입력받아 객체의 특징을 분석한 특징 패턴 정보를 출력할 수 있다. 또한, 합성곱 신경망에서 출력된 특징 패턴 정보는 완전 연결 심층 신경망에 입력되어 학습을 수행함으로써 분 류된 객체에 해당하는 식별 정보들과 좌표 정보들을 출력하는 학습 모델이 구축될 수 있다. 구체적으로, 합성곱 신경망은 매트 이미지 및/또는 학습자 이미지에 커널을 이용해 특징 패턴 정보를 나타내는 피쳐맵을 출력할 수 있고, 이 과정에서 매트 이미지 및/또는 학습자 이미지에 대한 풀링과 드롭아웃을 수행할 수 있다. 그리고, 전처리된 데이터 셋트를 이용해 상기 신경망들을 통해 출력된 결과와 트레이닝 데이터를 상기 신경망들 을 통해 출력한 결과와의 오차를 비교하여 신경망의 가중치를 점차적으로 변화시켜주는 역전파 (backpropagation) 과정을 통해 학습될 수 있다. 즉, 특징 패턴 정보가 완전 연결 심층 신경망에 입력되어 상기 학습을 통해 분류된 객체에 해당하는 식별 정보 와 좌표 정보들이 출력될 수 있다. 참고로, 도 7을 참조하면, 합성곱 신경망을 이용해 매트 이미지 및/또는 학습자 이미지로부터 커널을 이용해 특 징 패턴 정보를 출력하고, 특징 패턴 정보가 완전 연결 심층 신경망에 입력되어 식별 정보(매트, 학습자)와 2차 원 좌표값(X,Y 좌표값, Width, Height)인 (x1, y1), (x2, y2)가 출력될 수 있다. 이와 마찬가지로, 특정 분할 영역(MOAD)과 분할 영역(BOAD)도 상기 과정을 통해 식별 정보 및 좌표 정보가 출력 될 수 있다. 본 발명에서는 신경망으로 CNN과 FCNN을 이용한 것을 예시하였으나, 이는 일 실시예에 불과하고, DNN(Deep Neural Network)이나 RNN(Recurrent Neural Network) 등 다양한 신경망을 이용하는 경우에도 본 발명이 동일/ 유사하게 적용될 수 있다. 실시예에 따르면, 제어부는 소프트웨어 모듈로 구현되거나 적어도 하나의 하드웨어 칩 형태로 제작되어 영 상 분석 장치에 탑재될 수 있다. 예를 들어, NPU(Neural Processing Unit)와 같은 인공 지능(AI; artificial intelligence)을 위한 전용 하드웨 어 칩 형태로 제작되거나, 기존의 범용 프로세서(예: CPU 또는 Application Processor) 또는 그래픽 전용 프로 세서(예: GPU(Graphic Processing Unit) 또는 VPU(Visual Processing Unit))의 일부로 제작되어 영상 분석 장 치에 탑재될 수도 있다.한편, 제어부는 제2 객체 영역(BOA) 중 특정 영역(BOAD)이 제1 객체 영역(MOA)의 특정 분할 영역(MOAD) 내 에 오버랩되는 소정의 조건을 만족한 것인지 여부를 판별하여, 상기 소정의 조건을 만족하는 것으로 판별한 경 우 이에 매핑하는 식별 정보를 독출할 수 있다. 예를 들어, 도 5를 참조하면, 제2 객체 영역(BOA)이 일부 분할 영역들에 걸쳐서 오버랩되는 경우, 어떠한 식별 정보를 독출해야할 지 부정확할 수 있으므로, 특히, 제2 객체 영역(BOA) 중 특정 신체를 나타내는 영역(BOAD)이 제1 객체 영역(MOA)의 특정 영역(MOA) 내에 오버랩된 것으로 판별한 경우에 이에 매핑하는 식별 정보를 독출할 수 있다. 실시예에 따르면, 특정 신체를 나타내는 영역(BOAD)은 제2 객체(BO)의 신체 영역 중 일부, 특히 발 영역에 해당 할 수 있다. 즉, 제어부는 특정 신체 영역이 특정 분할 영역(MOA) 내에 오버랩된 것으로 판별하면 이에 매핑하는 식별 정보 'P'를 독출할 수 있다. 한편, 실시예에 따르면, 제어부는 전체 프레임들 각각 중 상기 소정의 조건을 만족하는 프레임들 각각을 대 상 프레임들로 정의하고, 대상 프레임들 중 미리 정해진 시간 구간 이상의 시간 동안(예>1초) 연속되는 대상 프 레임들로 구성된 적어도 하나의 대상 프레임 그룹을 선별함으로써 적어도 하나의 대상 프레임 그룹 각각에 대응 하는 식별 정보를 정확하게 독출할 수 있다. 예를 들어, 학습자가 매트 상을 이동할 때, 'A'를 인식하여 밟고, 다시 다음 답변으로 'P'를 인식하여 매 트의 분할 부분을 밟으려고 하는 경우, 'A'와 'P'의 거리가 가깝지 않아 학습자의 이동 경로가 도 5 의 화살표 같을 수 있다. 이 때, 'B' 나 'E'는 학습자가 원하는 답변을 하기 위한 분할 부분에 위치한 것이 아 니므로, 영상에서 해당 프레임들에 대해서는 답변 정보로 획득하지 않아야 한다. 이를 위하여, 실시예에 따르면, 미리 정해진 시간 구간(예> 1초) 이상의 시간 동안 연속되는 대상 프레임들만을 선별하여, 이에 대응하는 식별 정보만을 추출할 수 있다. 도 6을 참조하면, 도 6의 각 프레임들은 제2 객체 영역이 제1 객체 영역의 특정 분할 영역에 오버랩되는 소정의 조건을 만족한 대상 프레임들이다. 이 때, 제어부는 대상 프레임들 중 미리 정해진 시간 구간 이상의 시간 동안 연속되는 대상 프레임들로 구성된 대상 프레임 그룹(FG1, FG3, FG4, FG5)을 구별하여, 대상 프레임 그룹 (FG1, FG3, FG4, FG5) 각각에 매핑되는 식별 정보(A, P, L, E)를 추출하고, 미리 정해진 시간 구간 미만으로 연 속되는 대상 프레임들로 구성된 프레임 그룹(FG2)에 대해서는 식별 정보를 추출하지 않도록 할 수 있다. 참고로, 본 발명에 따르면, 학습자는 미리 정해진 시간 구간 이상의 시간 동안(예> 1초) 연속하여 매트의 분할 부분에 머물러야 하는 규칙을 미리 학습할 수 있다. 본 발명에 따르면, 이로서, 제어부는 답변 정보에 대응하는 식별 정보를 보다 정확하게 추출할 수 있다. 특히, 본 발명의 경우, 제어부는 대상 프레임 그룹에 대응하는 식별 정보를 시간 순서에 따라 추출하고, 시 간 순서에 따라 추출된 식별 정보들을 조합하여 답변 정보를 획득할 수 있다. 예를 들어, 학습자가 질의 정보에 따라 답변 정보를 'APPLE'로 생성하고자 하여 위 알파벳 순서대로 대응하는 매트의 분할 부분 각각에 머무른 경우(A->P->P->L->E), 제어부는 시간 순서에 따라 상기 알파벳 각각을 추출하여 조합함으로써 답변 정보를 획득할 수 있다. 실시예에 따르면, 제어부는 대상 프레임들 중 상기 미리 정해진 시간 구간의 배수만큼의 시간 동안(예>2초) 연속되는 대상 프레임들로 구성된 대상 프레임 그룹을 구별하고, 대상 프레임 그룹에 매핑되는 식별 정보를 상 기 배수만큼 추출할 수 있다. 예를 들어, 도 6을 참조하면, 대상 프레임 그룹(FG3)은 미리 정해진 시간 구간의 2배의 시간 동안, 내지는 2배 이상의 시간 동안 연속되는 대상 프레임들로 구성되어, 이에 매핑되는 식별 정보를 2배수로 추출하여 'P'가 연 속하여 두 번 추출된 것을 알 수 있다. 이를 위하여, 학습자는 원하는 알파벳을 두 번 답변하기 위해, 미리 정해진 시간 구간의 배수만큼의 시간 동안, 내지는 배수 이상의 시간 동안 매트의 분할 부분에 머물러야 하는 규칙을 미리 학습할 수 있다. 이어서, 제어부는 답변 정보가 기 설정된 답안 정보에 해당하는 지 여부를 판별할 수 있다(s34). 제어부는 질의 정보에 대응하는 답안 정보를 저장부에 미리 기록하고, 답변 정보와 답안 정보를 서로 비교하여 답변의 정/오를 판별한 판별 정보를 생성할 수 있다. 그리고, 제어부는 판별 정보를 학습자에게 제공할 수 있다(s35). 실시예에 따라, 판별 정보를 영상 출력부 및/또는 음성 출력부를 통해 출력할 수 있다. 실시예에 따라, 학습자의 부모 단말기로도 상기 판별 정보를 알람의 형태로 제공할 수 있다. 이상에서 실시예들에 설명된 특징, 구조, 효과 등은 본 발명의 하나의 실시예에 포함되며, 반드시 하나의 실시 예에만 한정되는 것은 아니다. 나아가, 각 실시예에서 예시된 특징, 구조, 효과 등은 실시예들이 속하는 분야의 통상의 지식을 가지는 자에 의해 다른 실시예들에 대해서도 조합 또는 변형되어 실시 가능하다. 따라서 이러한 조합과 변형에 관계된 내용들은 본 발명의 범위에 포함되는 것으로 해석되어야 할 것이다. 또한, 이상에서 실시예를 중심으로 설명하였으나 이는 단지 예시일 뿐 본 발명을 한정하는 것이 아니며, 본 발 명이 속하는 분야의 통상의 지식을 가진 자라면 본 실시예의 본질적인 특성을 벗어나지 않는 범위에서 이상에 예시되지 않은 여러 가지의 변형과 응용이 가능함을 알 수 있을 것이다. 예를 들어, 실시예에 구체적으로 나타 난 각 구성 요소는 변형하여 실시할 수 있는 것이다. 그리고 이러한 변형과 응용에 관계된 차이점들은 첨부된 청구 범위에서 규정하는 본 발명의 범위에 포함되는 것으로 해석되어야 할 것이다."}
{"patent_id": "10-2021-0060794", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 실시예에 따른 매트 상에서 이동한 학습자의 촬영 영상 분석 시스템도이다. 도 2는 실시예에 따른 영상 분석 장치의 블록도이다. 도 3은 실시예에 따른 영상 분석 장치의 매트 상에서 이동한 학습자의 촬영 영상 분석 방법을 설명하는 순서도 이다. 도 4 내지 도 7은 도 3의 방법을 설명하기 위해 참조되는 도면이다."}
