{"patent_id": "10-2019-0146098", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2020-0056342", "출원번호": "10-2019-0146098", "발명의 명칭": "대상 화자 음성과 동일한 음성을 가진 컨텐츠를 검색하는 방법 및 이를 실행하기 위한 장치", "출원인": "네오사피엔스 주식회사", "발명자": "손수원"}}
{"patent_id": "10-2019-0146098", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "대상 화자의 음성과 동일한 음성을 포함한 컨텐츠를 검색하는 방법에 있어서,대상 화자의 음성으로 생성된 사운드(sound)를 수신하는 단계;상기 사운드로부터 상기 대상 화자의 음성을 나타내는 특징을 추출하는 단계;해쉬 함수를 이용하여 상기 대상 화자의 음성을 나타내는 특징에 대응하는 해쉬값을 산출하는 단계; 및 네트워크 상에서 검색 가능한 복수의 컨텐츠 중에서, 상기 산출된 해쉬값과 유사한 해쉬값과 연관된 컨텐츠를검색하는 단계를 포함하는 컨텐츠 검색 방법."}
{"patent_id": "10-2019-0146098", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 사운드로부터 상기 대상 화자의 음성을 나타내는 특징을 추출하는 단계는, 상기 사운드로부터 상기 대상화자의 음성에 대응되는 화자 특징 벡터를 추출하는 단계를 포함하는 컨텐츠 검색 방법."}
{"patent_id": "10-2019-0146098", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서, 상기 해쉬 함수를 이용하여 상기 대상 화자의 음성을 나타내는 특징에 대응하는 해쉬값을 산출하는 단계는, 학습 음성 데이터로부터 랜덤 화자 서브 세트를 미리 결정된 수 만큼 반복하여 선택하는 단계 - 상기 랜덤 화자서브 세트는 복수의 화자 분류(class)와 연관됨 -; 상기 선택된 랜덤 화자 서브 세트를 기초로 판별 변환 함수(discriminative transform function)를 생성하는단계 - 상기 해쉬 함수는 상기 생성된 판별 변환 함수를 이용하여 생성됨 -; 상기 추출된 화자 특징 벡터를 상기 해쉬 함수에 입력하여 상기 대상 화자의 음성을 나타내는 특징에 대응하는해쉬값을 산출하는 단계를 포함하는 컨텐츠 검색 방법."}
{"patent_id": "10-2019-0146098", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서,상기 선택된 랜덤 화자 서브 세트를 기초로 판별 변환 함수를 생성하는 단계는, 상기 선택된 랜덤 화자 서브 세트를 이용하여 상기 랜덤 화자 서브 세트에 연관된 복수의 화자 분류에 대응하는 영역이 판별되도록 인공신경망판별 모델을 학습하는 단계를 포함하는, 컨텐츠 검색 방법."}
{"patent_id": "10-2019-0146098", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서, 상기 인공신경망 판별 모델을 학습하는 단계는, 상기 선택된 랜덤 화자 서브 세트를 이용하여 상기 선택된 랜덤공개특허 10-2020-0056342-3-화자 서브 세트에 연관된 복수의 화자 분류 중 하나의 화자 분류 내의 특징 사이의 거리는 최소화하고 상기 복수의 화자 분류 내의 특징 사이의 거리는 최대화하도록 상기 인공신경망 판별 모델을 학습하는 단계를포함하는.컨텐츠 검색 방법."}
{"patent_id": "10-2019-0146098", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제4항에 있어서,상기 추출된 화자 특징 벡터를 상기 해쉬 함수에 입력하여 상기 대상 화자의 음성을 나타내는 특징에 대응하는해쉬값을 산출하는 단계는,상기 추출된 화자 특징 벡터를 상기 학습된 인공신경망 판별 모델에 입력하여, 상기 복수의 화자 분류에 대응하는 복수의 영역 중에서, 상기 추출된 화자 특징 벡터가 대응하는 적어도 하나의 화자 분류에 대한 영역에 대한정보를 출력하는 단계; 및상기 적어도 하나의 화자 분류에 대한 영역의 각각에 대응하는 값을 이용하여 상기 대상 화자의 음성을 나타내는 특징에 대응하는 해쉬값을 생성하는 단계를 포함하는, 컨텐츠 검색 방법."}
{"patent_id": "10-2019-0146098", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제3항에 있어서, 상기 선택된 랜덤 화자 서브 세트를 기초로 판별 변환 함수를 생성하는 단계는, 상기 선택된 랜덤 화자 서브 세트의 각각을 이용하여 LDA(Linear Discriminant Analysis) 변환 매트릭스를 상기 미리 결정된 수 만큼 반복하여생성하는 단계를 포함하는, 컨텐츠 검색 방법."}
{"patent_id": "10-2019-0146098", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서, 상기 추출된 화자 특징 벡터를 상기 해쉬 함수에 입력하여 상기 대상 화자의 음성을 나타내는 특징에 대응하는해쉬값을 산출하는 단계는, 상기 생성된 LDA 변환 매트릭스의 각각을 이용하여 상기 추출된 화자 특징 벡터를 상기 생성된 LDA 변환 매트릭스의 각각에 대응되는 랜덤 화자-변산도 서브공간(Random Speaker-variability Subspace)에 투영하는 단계;상기 추출된 화자 특징 벡터의 투영 영역의 각각이 상기 랜덤 화자-변산도 서브 공간에 연관된 복수의 화자 분류 중 하나의 화자 분류에 속하는 경우, 상기 하나의 화자 분류에 대응되는 값을 상기 추출된 화자 특징 벡터의투영 영역의 각각에 할당하는 단계; 및상기 할당된 값들을 기초로 상기 추출된 화자 특징 벡터에 대응되는 해쉬값을 생성하는 단계를 포함하는, 컨텐츠 검색 방법."}
{"patent_id": "10-2019-0146098", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제7항에 있어서, 상기 선택된 랜덤 화자 서브 세트의 각각을 이용하여 LDA 변환 매트릭스를 상기 미리 결정된 수만큼 반복하여생성하는 단계는, 공개특허 10-2020-0056342-4-상기 선택된 랜덤 화자 서브 세트의 각각에 대해, 상기 학습 음성 데이터를 이용하여 상기 랜덤 화자 서브 세트와 연관된 복수의 화자 분류 사이의 스캐터 매트릭스를 생성하는 단계; 상기 학습 음성 데이터를 이용하여 상기 랜덤 화자 서브 세트와 연관된 하나의 화자 분류 내의 스캐터 매트릭스를 생성하는 단계; 및상기 복수의 화자 분류 사이의 스캐터 매트릭스 및 상기 하나의 화자 분류 내의 스캐너 매트릭스의 비율(ratio)이 최대화되도록 상기 LDA 변환 매트릭스를 생성하는 단계를 포함하는 컨텐츠 검색 방법."}
{"patent_id": "10-2019-0146098", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제3항에 있어서, 상기 미리 결정된 수는 미리 결정된 해쉬 테이블의 총 수를 포함하는, 컨텐츠 검색 방법."}
{"patent_id": "10-2019-0146098", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제1항에 있어서, 상기 네트워크 상에서 검색 가능한 복수의 컨텐츠의 각각에 포함된 하나 이상의 화자의 음성을 나타내는 특징을추출하는 단계; 및상기 해쉬 함수를 이용하여 상기 추출된 하나 이상의 화자의 음성을 나타내는 특징의 각각에 대응하는 해쉬값을산출하는 단계를 더 포함하는, 컨텐츠 검색 방법."}
{"patent_id": "10-2019-0146098", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항에 있어서, 상기 산출된 해쉬값과 유사한 해쉬값과 연관된 컨텐츠를 검색하는 단계는,상기 네트워크 상에서 검색 가능한 복수의 컨텐츠의 각각에 대해 산출된 복수의 해쉬값의 각각과 상기 대상 화자와 연관된 해쉬값을 비교하는 단계; 및상기 대상 화자의 음성에 대한 해쉬값과 유사한 해쉬값과 연관된 하나 이상의 컨텐츠가 존재한다면, 상기 유사한 해쉬값과 연관된 하나 이상의 컨텐츠를 출력하는 단계 를 포함하는, 컨텐츠 검색 방법."}
{"patent_id": "10-2019-0146098", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제1항의 대상 화자 음성과 동일한 음성을 포함한 컨텐츠를 검색하는 방법에 따른 각각의 단계를 수행하는 명령어를 포함하는 프로그램이 기록된, 컴퓨터 판독가능 저장매체."}
{"patent_id": "10-2019-0146098", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "복수의 컨텐츠 중 대상 화자 음성과 동일한 음성을 가진 컨텐츠를 검색하는 방법은, 대상 화자 음성에 대응되는 특징 벡터를 추출하는 단계, 학습 데이터 세트로부터 임의의 화자 서브 세트를 미리 결정된 수만큼 반복하여 선 택하는 단계, 선택된 임의의 화자 서브 세트의 각각을 이용하여 Linear Discriminant Analysis (LDA) 변환 매트 릭스를 미리 결정된 수만큼 반복하여 생성하는 단계, 생성된 LDA 변환 매트릭스의 각각을 이용하여 추출된 화자 특징 벡터를 선택된 대응 화자 서브 세트에 투영하는 단계, 추출된 화자 특징 벡터의 투영 영역의 각각이 선택된 대응 화자 서브 세트 중 가까운 화자 분류에 대응되는 값을 할당하는 단계, 할당된 값들을 기초로 추출된 특징 벡터에 대응되는 해쉬값을 생성하는 단계 및 복수의 컨텐츠 중, 생성된 해쉬값과 유사한 해쉬값을 가진 컨텐츠를 검색하는 단계를 포함한다."}
{"patent_id": "10-2019-0146098", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 대상 화자 음성과 동일하거나 유사한 음성을 포함한 컨텐츠를 검색하는 방법 및 시스템에 관한 것이다. 보다 상세하게는, 대상 화자의 음성을 나타내는 특징을 추출하고, 해쉬 함수를 이용하여 추출된 특징에 대 응하는 해쉬값을 산출하고, 추출된 해쉬값과 유사한 해시값과 연관된 컨텐츠를 검색할 수 있는 방법 및 시스템 에 관한 것이다."}
{"patent_id": "10-2019-0146098", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "최근, 스마트폰, 컴퓨터 등의 전자 기기를 통해 인터넷을 이용하는 사용자들은 다양한 국가에서, 실시간으로 새 롭게 생성되는 광범위한 비디오 클립, 오디오 클립 및 소셜 미디어 등의 데이터를 네트워크 상에서 손쉽게 접할 수 있다. 예를 들어, 특정 동영상 사이트에는 매 분 수백 내지 수만 시간의 비디오들이 업로드되고, 수억 내지 수십 억명 이상의 사용자가 업로드된 비디오들을 시청하고 있다. 이러한 온라인 비디오에는 화자(speaker)의 음성(voice)으로 생성된 스피치(speech)를 포함한 컨텐츠를 포함할 수 있다. 또한, 사람의 음성을 사전에 녹음해 두지 않고 필요한 음성을 재생시키는 기술인 음성 합성 기술(Text-To- Speech 기술)은 안내방송, 네비게이션, 인공지능 비서, 오디오북, 영상 제작 등과 같이 사람의 음성이 필요한 서비스 또는 어플리케이션에서 최근 각광받고 있다. 특히, deep learning 기반의 음성 합성 기술이 최근 급격 히 발전되어, 특정인(예를 들어, 유명인사)의 음성 또는 목소리가 실제로 녹음된 것처럼 그 특정인에 대한 정교 하게 합성된 음성이 생성될 수 있으며, 특정인의 실제 녹음된 음성인지 합성된 음성인지 구분하기 어려울 수 있 다. 다만, 이러한 환경에서는, 특정인의 허락 없이 추출된 특정인의 음성 또는 음성 합성 기술을 통해 생성된 특정 인의 음성을 이용하여 다양한 컨텐츠가 제작될 수 있다. 이에 따라, 특정인의 음성이 함부로 사용되거나 남용 될 가능성이 있고, 그러한 합성 또는 복제된 음성이 그 특정인의 의도와 달리 사용되거나 범죄 등에 사용될 염 려가 있다. 특정인의 음성이 특정인 자신의 허락없이 사용되는 것을 알아내고 나아가 방지하기 위하여, 자신의 음성 또는 목소리가 사용되는 컨텐츠가 검색될 수 있는 시스템이 요구된다. 한편, 종래의 멀티미디어 검색 기술 환경에서는 음악 검색이나 동영상 검색이 가능하게 하는 플랫폼을 제공하고 있다. 다만, 그러한 플랫폼 하에서 특정 음악 또는 동영상 컨텐츠는 검색될 수 있으나, 그러한 플랫폼을 사용 하는 사용자가 특정인의 음성, 즉 특정인의 음성 특징을 기초로 그러한 음성을 포함한 컨텐츠의 검색할 수 없었 다. 즉, 컨텐츠의 내용 기반이 아니라, 화자의 음성 특징을 기초로 동일한 화자의 음성으로 생성된 상이한 내 용을 가진 컨텐츠는 검색될 수 없었다. 특히, 광범위한 음성이 존재하는 검색 공간(예를 들어, 네트워크) 상에 서는 이러한 음성을 검색하는 것 자체가 실질적으로 어려웠다. 이에 따라, 온라인 상의 광범위한 음성 데이터 상에서 특정인의 음성을 신속하고 정확하게 검색하는 기술이 요구된다."}
{"patent_id": "10-2019-0146098", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 개시에 따른 방법 및 시스템은 화자의 음성을 나타내는 특징에 대응하는 해쉬값을 생성하고, 네트워크 상에 검색가능한 복수의 컨텐츠 중에서, 생성된 해쉬값을 이용하여 화자의 음성과 동일한 음성을 포함한 컨텐츠를 검 색할 수 있다. 또한, 본 개시에 따른 방법 및 시스템은 대한 특정인에 대한 음성의 특징을 나타내는 화자 특징 벡터를 추출하 고, 해쉬 함수를 이용하여 추출된 화자 특징 벡터를 랜덤 화자 변산도 서브 공간에 투영함으로써 해쉬값을 산출 하고, 산출된 해쉬값과 유사한 해쉬값과 연관된 컨텐츠를 검색할 수 있다. 또한, 본 개시에 따른 방법 및 시스템은 특정 화자의 특징을 나타내는 화자 특징 벡터에 대응하는 해쉬값을 생 성하기 위해 이용되는 랜덤 화자 서브 세트를 추출하는데 있어서, 복수의 특정 화자의 음성을 분류하도록 구성 된 미리 학습된 음성 데이터를 이용할 수 있다."}
{"patent_id": "10-2019-0146098", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 개시는 방법, 시스템, 장치, 컴퓨터 프로그램 또는 명령어들을 저장하는 컴퓨터 판독가능 저장 매체를 포함 한 다양한 방식으로 구현될 수 있다. 본 개시의 일 실시예에 따른 대상 화자의 음성과 동일한 음성을 포함한 컨텐츠를 검색하는 방법은, 대상 화자의 음성으로 생성된 사운드를 수신하는 단계, 사운드로부터 대상 화자의 음성을 나타내는 특징을 추출하는 단계,해쉬 함수를 이용하여 대상 화자의 음성을 나타내는 특징에 대응하는 해쉬값을 산출하는 단계 및 네트워크 상에 서 검색 가능한 복수의 컨텐츠 중에서, 산출된 해쉬값과 유사한 해쉬값과 연관된 컨텐츠를 검색하는 단계를 포 함할 수 있다. 본 개시의 일 실시예에 따른 사운드로부터 대상 화자의 음성을 나타내는 특징을 추출하는 단계는, 사운드로부터 대상 화자의 음성에 대응되는 화자 특징 벡터를 추출하는 단계를 포함할 수 있다. 본 개시의 일 실시예에 따른 해쉬 함수를 이용하여 대상 화자의 음성을 나타내는 특징에 대응하는 해쉬값을 산 출하는 단계는, 학습 음성 데이터로부터 랜덤 화자 서브 세트를 미리 결정된 수 만큼 반복하여 선택하는 단계 - 랜덤 화자 서브 세트는 복수의 화자 분류(class)와 연관됨 -, 선택된 랜덤 화자 서브 세트를 기초로 판별 변환 함수(discriminative transform function)를 생성하는 단계 - 해쉬 함수는 생성된 판별 변환 함수를 이용하여 생성됨 -, 추출된 화자 특징 벡터를 해쉬 함수에 입력하여 대상 화자의 음성을 나타내는 특징에 대응하는 해쉬 값을 산출하는 단계를 포함할 수 있다. 본 개시의 일 실시예에 따른 선택된 랜덤 화자 서브 세트를 기초로 판별 변환 함수를 생성하는 단계는, 선택된 랜덤 화자 서브 세트를 이용하여, 랜덤 화자 서브 세트에 연관된 복수의 화자 분류에 대응하는 영역이 판별되도 록 인공신경망 판별 모델을 학습하는 단계를 포함할 수 있다. 본 개시의 일 실시예에 따른 인공신경망 판별 모델을 학습하는 단계는, 선택된 랜덤 화자 서브 세트를 이용하여 선택된 랜덤 화자 서브 세트에 연관된 복수의 화자 분류 중 하나의 화자 분류 내의 특징 사이의 거리는 최소화 하고 복수의 화자 분류 내의 특징 사이의 거리는 최대화하도록 인공신경망 판별 모델을 학습하는 단계를 포함할 수 있다. 본 개시의 일실시예에 따른 추출된 화자 특징 벡터를 해쉬 함수에 입력하여 대상 화자의 음성을 나타내는 특징 에 대응하는 해쉬값을 산출하는 단계는, 추출된 화자 특징 벡터를 학습된 인공신경망 판별 모델에 입력하여, 복 수의 화자 분류에 대응하는 복수의 영역 중에서, 추출된 화자 특징 벡터가 대응하는 적어도 하나의 화자 분류에 대한 영역에 대한 정보를 출력하는 단계 및 적어도 하나의 화자 분류에 대한 영역의 각각에 대응하는 값을 이용 하여 대상 화자의 음성을 나타내는 특징에 대응하는 해쉬값을 생성하는 단계를 포함할 수 있다. 본 개시의 일 실시예에 따른 선택된 랜덤 화자 서브 세트를 기초로 판별 변환 함수를 생성하는 단계는, 선택된 랜덤 화자 서브 세트의 각각을 이용하여 LDA(Linear Discriminant Analysis) 변환 매트릭스를 미리 결정된 수만 큼 반복하여 생성하는 단계를 포함할 수 있다. 본 개시의 일 실시예에 따른 추출된 화자 특징 벡터를 해쉬 함수에 입력하여 대상 화자의 음성을 나타내는 특징 에 대응하는 해쉬값을 산출하는 단계는, 생성된 LDA 변환 매트릭스의 각각을 이용하여 추출된 화자 특징 벡터를 생성된 LDA 변환 매트릭스의 각각에 대응되는 랜덤 화자-변산도 서브공간(Random Speaker-variability Subspace)에 투영하는 단계, 및 추출된 화자 특징 벡터의 투영 영역의 각각이 랜덤 화자-변산도 서브 공간에 연 관된 복수의 화자 분류 중 하나의 화자 분류에 속하는 경우, 하나의 화자 분류에 대응되는 값을 추출된 화자 특 징 벡터의 투영 영역의 각각에 할당하는 단계 및 할당된 값들을 기초로 추출된 화자 특징 벡터에 대응되는 해쉬 값을 생성하는 단계를 포함할 수 있다. 본 개시의 일 실시예에 따른 선택된 랜덤 화자 서브 세트의 각각을 이용하여 LDA 변환 매트릭스를 미리 결정된 수만큼 반복하여 생성하는 단계는, 선택된 랜덤 화자 서브 세트의 각각에 대해, 학습 음성 데이터를 이용하여 랜덤 화자 서브 세트와 연관된 복수의 화자 분류 사이의 스캐터 매트릭스를 생성하는 단계, 학습 음성 데이터를 이용하여 랜덤 화자 서브 세트와 연관된 하나의 화자 분류 내의 스캐터 매트릭스를 생성하는 단계; 및 복수의 화자 분류 사이의 스캐터 매트릭스 및 하나의 화자 분류 내의 스캐너 매트릭스의 비율(ratio)이 최대화되도록 LDA 변환 매트릭스를 생성하는 단계를 포함할 수 있다. 본 개시의 일 실시예에 따른 미리 결정된 수는 미리 결정된 해쉬 테이블의 총 수를 포함할 수 있다. 본 개시의 일 실시예에 따른 대상 화자의 음성과 동일한 음성을 포함한 컨텐츠를 검색하는 방법은 네트워크 상 에서 검색 가능한 복수의 컨텐츠의 각각에 포함된 하나 이상의 화자의 음성을 나타내는 특징을 추출하는 단계 및 해쉬 함수를 이용하여 추출된 하나 이상의 화자의 음성을 나타내는 특징의 각각에 대응하는 해쉬값을 산출하 는 단계를 더 포함할 수 있다. 본 개시의 일 실시예에 따른 산출된 해쉬값과 유사한 해쉬값과 연관된 컨텐츠를 검색하는 단계는, 네트워크 상 에서 검색 가능한 복수의 컨텐츠의 각각에 대해 산출된 복수의 해쉬값의 각각과 대상 화자와 연관된 해쉬값을비교하는 단계; 및 대상 화자의 음성에 대한 해쉬값과 유사한 해쉬값과 연관된 하나 이상의 컨텐츠가 존재한다 면, 유사한 해쉬값과 연관된 하나 이상의 컨텐츠를 출력하는 단계를 포함할 수 있다. 본 개시의 일 실시예에 따른 컴퓨터 판독가능 저장 매체는, 상술한 바와 같은 대상 화자 음성과 동일한 음성을 포함한 컨텐츠를 검색하는 방법에 따른 각각의 단계를 수행하는 명령어를 포함하는 프로그램이 기록될 수 있다. 또한, 상술한 바와 같은 대상 화자 음성과 동일한 음성을 포함한 컨텐츠를 검색하는 방법과 연관된 장치, 시스 템 및 기술적 수단 등이 또한 개시될 수 있다."}
{"patent_id": "10-2019-0146098", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 개시의 일부 실시예에 따르면, 특정인의 음성을 인덱싱하기 위하여 그러한 음성의 특징을 해쉬 형태로 나타 내고, 이러한 해쉬 형태를 이용하여 특정인의 음성의 검색을 가능하게 함으로써, 특정인의 음성이 남용되거나 복제되는 컨텐츠를 찾아내고 이러한 컨텐츠의 무단 사용을 방지할 수 있다. 본 개시의 일부 실시예에 따르면, 음성에 대한 특징에 대응하는 해쉬값을 생성함에 있어서, 비교사 기법인 LSH 기법에 교사 기법을 이용하여 LDA 변환함수를 생성하고 생성된 LDA 변환 함수를 투영 매트릭스로서 사용함으로 써, 선형 검색과 비교하여 검색 속도를 최대화하면서 음성 검색을 위한 성능 저하는 최소화할 수 있다."}
{"patent_id": "10-2019-0146098", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "개시된 실시예의 이점 및 특징, 그리고 그것들을 달성하는 방법은 첨부되는 도면과 함께 후술되어 있는 실시예 들을 참조하면 명확해질 것이다. 그러나 본 개시는 이하에서 개시되는 실시예들에 한정되는 것이 아니라 서로"}
{"patent_id": "10-2019-0146098", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "다른 다양한 형태로 구현될 수 있으며, 단지 본 실시예들은 본 개시가 완전하도록 하고, 본 개시가 속하는 기술분야에서 통상의 지식을 가진 자에게 발명의 범주를 완전하게 알려주기 위해 제공되는 것일 뿐이다. 본 명세서에서 사용되는 용어에 대해 간략히 설명하고, 개시된 실시예에 대해 구체적으로 설명하기로 한다. 본 명세서에서 사용되는 용어는 본 개시에서의 기능을 고려하면서 가능한 현재 널리 사용되는 일반적인 용어들 을 선택하였으나, 이는 관련 분야에 종사하는 기술자의 의도 또는 판례, 새로운 기술의 출현 등에 따라 달라질 수 있다. 또한, 특정한 경우는 출원인이 임의로 선정한 용어도 있으며, 이 경우 해당되는 발명의 설명 부분에 서 상세히 그 의미를 기재할 것이다. 따라서 본 개시에서 사용되는 용어는 단순한 용어의 명칭이 아닌, 그 용 어가 가지는 의미와 본 개시의 전반에 걸친 내용을 토대로 정의되어야 한다. 본 명세서에서의 단수의 표현은 문맥상 명백하게 단수인 것으로 특정하지 않는 한, 복수의 표현을 포함한다. 또한 복수의 표현은 문맥상 명백하게 복수인 것으로 특정하지 않는 한, 단수의 표현을 포함한다. 명세서 전체에서 어떤 부분이 어떤 구성요소를 '포함'한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다른 구성요소를 제외하는 것이 아니라 다른 구성요소를 더 포함할 수 있음을 의미한다. 또한, 명세서에서 사용되는 '부' 또는 '모듈'이라는 용어는 소프트웨어 또는 하드웨어 구성요소를 의미하며, ' 부' 또는 '모듈'은 어떤 역할들을 수행한다. 그렇지만 '부' 또는 '모듈'은 소프트웨어 또는 하드웨어에 한정되 는 의미는 아니다. '부' 또는 '모듈'은 어드레싱할 수 있는 저장 매체에 있도록 구성될 수도 있고 하나 또는 그 이상의 프로세서들을 재생시키도록 구성될 수도 있다. 따라서, 일 예로서 '부' 또는 '모듈'은 소프트웨어 구성요소들, 객체지향 소프트웨어 구성요소들, 클래스 구성요소들 및 태스크 구성요소들과 같은 구성요소들과, 프로세스들, 함수들, 속성들, 프로시저들, 서브루틴들, 프로그램 코드의 세그먼트들, 드라이버들, 펌웨어, 마이 크로 코드, 회로, 데이터, 데이터베이스, 데이터 구조들, 테이블들, 어레이들 및 변수들을 포함한다. 구성요소 들과 '부' 또는 '모듈'들 안에서 제공되는 기능은 더 작은 수의 구성요소들 및 '부' 또는 '모듈'들로 결합되거 나 추가적인 구성요소들과 '부' 또는 '모듈'들로 더 분리될 수 있다. 본 개시의 일 실시예에 따르면 '부' 또는 '모듈'은 프로세서 및 메모리로 구현될 수 있다. 용어 '프로세서' 는 범용 프로세서, 중앙 처리 장치 (CPU), 마이크로프로세서, 디지털 신호 프로세서 (DSP), 제어기, 마이크로제어 기, 상태 머신 등을 포함하도록 넓게 해석되어야 한다. 몇몇 환경에서는, '프로세서' 는 주문형 반도체 (ASIC), 프로그램가능 로직 디바이스 (PLD), 필드 프로그램가능 게이트 어레이 (FPGA) 등을 지칭할 수도 있다. 용어 '프로세서' 는, 예를 들어, DSP 와 마이크로프로세서의 조합, 복수의 마이크로프로세서들의 조합, DSP 코 어와 결합한 하나 이상의 마이크로프로세서들의 조합, 또는 임의의 다른 그러한 구성들의 조합과 같은 처리 디 바이스들의 조합을 지칭할 수도 있다. 용어 '메모리' 는 전자 정보를 저장 가능한 임의의 전자 컴포넌트를 포함하도록 넓게 해석되어야 한다. 용어 메모리는 임의 액세스 메모리 (RAM), 판독-전용 메모리 (ROM), 비-휘발성 임의 액세스 메모리 (NVRAM), 프로그 램가능 판독-전용 메모리 (PROM), 소거-프로그램가능 판독 전용 메모리 (EPROM), 전기적으로 소거가능 PROM (EEPROM), 플래쉬 메모리, 자기 또는 광학 데이터 저장장치, 레지스터들 등과 같은 프로세서-판독가능 매체의 다양한 유형들을 지칭할 수도 있다. 프로세서가 메모리로부터 정보를 판독하고/하거나 메모리에 정보를 기록할 수 있다면 메모리는 프로세서와 전자 통신 상태에 있다고 불린다. 프로세서에 집적된 메모리는 프로세서와 전 자 통신 상태에 있다. 본 개시에서, '음성'은 사람의 발음기관에서 나오는 구체적이고 물리적 소리를 지칭할 수 있으며, 발화하는 사 람, 즉 화자 마다 음성을 나타내는 특징은 서로 상이할 수 있다. 또한, '음성'은 임의의 음성 합성 기술을 통 해 성생된 컨텐츠 내에 포함된 음성을 지칭할 수 있다. 본 개시에서, '컨텐츠'는 디지털 방식으로 제작되어 컨텐츠 검색 시스템에 의해 검색될 수 있는 화자의 음성을 포함한 임의의 정보 또는 그 내용물을 포함할 수 있다. 예를 들어, '컨텐츠'는 화자의 음성으로 생성된 오디오 컨텐츠, 이러한 오디오 컨텐츠를 포함한 영상 컨텐츠를 포함할 수 있다. 본 개시에서, '화자의 음성'은 화자의 발음 기관을 통해 내는 구체적이고 물리적 소리를 나타내거나, 음성 합성 기술을 통해 합성된 소리 내에 포함된, 화자의 음성 특징이 반영된 합성 음성을 포함할 수 있다. 본 개시에서, '해쉬 함수'는 임의의 길이를 가진 데이터 또는 정보를 입력하여 고정된 길이의 해쉬값을 출력하 도록 구성된 함수 또는 네트워크(예를 들어, 뉴럴 네트워크, 딥뉴럴 네트워크)를 지칭할 수 있다. 또한, '해쉬 함수'는 복수의 해쉬 함수를 연결한 해쉬함수를 포함하거나 독립적으로 사용되는 복수의 해쉬 함수 또는 네트워 크를 포함할 수 있다. 본 개시에서, '네트워크 상에' 또는 '네트워크 상에서'라는 용어는 유무선 통신이 가능한 임의의 전자 기기를 통해 검색 또는 접근 가능한 상태를 지칭할수 있다. 예를 들어, '네트워크 상에서'라는 의미는 임의의 전자 기 기와 유무선으로 연결된 임의의 장치 내에 저장된 임의의 컨텐츠를 검색 또는 접근 가능한 상태를 나타낼 수 있 다. 본 개시에서, '유사' 또는 '유사한'은 '동일' 또는 '유사한'을 포함할 수 있다. 아래에서는 첨부한 도면을 참고하여 실시예에 대하여 본 개시가 속하는 기술 분야에서 통상의 지식을 가진 자가 용이하게 실시할 수 있도록 상세히 설명한다. 그리고 도면에서 본 개시를 명확하게 설명하기 위해서 설명과 관 계없는 부분은 생략한다. 도 1은 일 실시예에 따른 네트워크 상에서 검색가능한 복수의 컨텐츠(150_1, 150_2, 150_3, ..., 150_N) 중에서, 화자의 음성으로 생성된 사운드 내에 포함된 음성과 동일한 음성을 포함한 컨텐츠를 검색하는 시스템 을 나타내는 도면이다. 여기서, 사용자 단말은 입력 수단(예를 들어: 마이크로폰 등)을 통해 화자의 음성을 수신할 수 있으며, 통신 모듈을 구비하여 네트워크 상에 유무선으로 연결된 임의의 장치 및/또는 시스템에 접속 가능하고, 컨텐츠 출력이 가능한 임의의 전자 기기(예를 들어, 스마트폰, PC, 태블릿 PC 등)을 포함할 수 있다. 일 실시예에 따르면, 사용자 단말은 화자의 음성으로 생성된 사운드를 입력받을 수 있다. 예를 들어, 사용자 단말은 마이크로폰을 통해 화자의 음성으로 생성된 사운드를 입력받을 수 있다. 이와 달리, 화자의 음성으로 생성된 사운드는 사용자 단말에 저장되거나 사용자 단말에 의해 검색되 거나 접근 가능한 임의의 장치로부터 수신된 사운드를 포함할 수 있다. 또는, 화자의 음성으로 생성된 사운드 는 음성 합성 기술을 이용하여 생성된 합성 음성을 포함한 사운드일 수 있다. 다른 실시예에 따르면, 사용자 단말은 음성으로 생성된 사운드를 적어도 일부분으로서 포함한 오디오 컨텐츠를 수신하거나 이러한 사운드 를 포함한 영상 컨텐츠를 수신할 수 있다. 화자의 음성으로 생성된 사운드 내에 포함된 음성과 동일한 음성을 포함한 컨텐츠를 검색하기 위하여, 이러한 사운드, 오디오 컨텐츠 및/또는 영상 컨텐츠는 컨텐츠 검색 시스템 에 쿼리로서 제공될 수 있다. 컨텐츠 검색 시스템은 수신된 사운드, 오디오 컨텐츠, 및/또는 영상 컨텐츠 내에 포함된 음성을 나타내는 특징을 추출하도록 구성될 수 있다. 또한, 컨텐츠 검색 시스템은 추출된 화자의 음성을 나타내는 특징에 대응하는 해쉬값을 산출하도록 구성될 수 있다. 예를 들어, 이러한 해쉬값은 추출된 특징 및 해쉬 함수를 이용 하여 산출될 수 있다. 여기서, 해쉬값은 복수의 화자의 음성을 구분하고 화자의 음성이 색인화(indexing)되어 저장될 수 있다. 이러한 해쉬값의 특성에 따라, 추출된 화자의 음성을 나타내는 특징에 대응하는 해쉬값과 유 사한 해쉬값과 연관된 복수의 음성은 추출된 화자의 음성과 동일한 음성을 지칭할 수 있다. 여기서, 유사한 해 쉬값은 추출된 화자의 음성을 나타내는 특징에 대응하는 해쉬값과 일정 이상의 유사도를 가진 해쉬값 또는 가장 가까운 해쉬값을 지칭할 수 있다. 컨텐츠 검색 시스템은 네트워크를 통해 복수의 컨텐츠(150_1 내지 150_N)를 검색하거나 접속할 수 있 으며, 복수의 컨텐츠(150_1 내지 150_N )의 각각에 포함된 하나 이상의 화자의 음성을 나타내는 특징을 추출하 도록 구성될 수 있다. 그리고 나서, 컨텐츠 검색 시스템은 추출된 하나 이상의 화자 음성을 나타내는 특 징의 각각에 대응하는 해쉬값을 산출하도록 구성될 수 있다. 여기서, 컨텐츠 검색 시스템은 사운드에 포 함된 화자의 음성에 대한 해쉬값을 산출할 시 사용된 해쉬 함수와 동일한 해쉬 함수를 사용하여 복수의 컨텐츠 (150_1 내지 150_N)의 각각에 포함된 하나 이상의 화자의 음성을 나타내는 특징에 대응하는 해쉬값을 산출할 수 있다. 일 실시예에 따르면, 이렇게 추출된 복수의 컨텐츠(150_1 내지 150_N)의 각각에 포함된 하나 이상의 화 자의 음성에 대한 해쉬값은 컨텐츠 검색 시스템에 의해 검색되거나 접근 가능한 임의의 장치에 저장될 수 있다. 예를 들어, 이러한 해쉬값은 컨텐츠 검색 시스템에 저장되거나 컨텐츠 검색 시스템에 의해 접 근 가능한 서버 또는 클라우딩 시스템에 저장될 수 있다. 다른 실시예에 따르면, 이러한 해쉬값은 복수의 컨텐 츠(150_1 내지 150_N)가 저장된 임의의 장치에 제공되어 복수의 컨텐츠(150_1 내지 150_N)와 연관되어 저장될 수 있다. 컨텐츠 검색 시스템은 수신된 화자의 음성으로 생성된 사운드에 연관된 해쉬값을 복수의 컨텐츠(150_1 내 지 150_N)의 각각에 연관된 복수의 해쉬값의 각각과 비교하도록 구성될 수 있다. 그리고 나서, 수신된 화자의 음성에 대한 해쉬값과 유사한 해쉬값과 연관된 하나 이상의 컨텐츠가 검색된다면, 검색된 하나 이상의 컨텐츠가 출력되도록 구성될 수 있다. 일 실시예에 따르면, 동일한 해쉬값과 연관된 하나 이상의 컨텐츠는 화자의 음성 으로 생성된 사운드를 제공한 사용자 단말로 출력 또는 제공될 수 있다. 예를 들어, 유사한 해쉬값과 연 관된 하나 이상의 컨텐츠의 리스트가 사용자 단말에 제공될 수 있다. 사용자 단말의 사용자는 이렇게 제공된 하나 이상의 컨텐츠를 확인하고, 특정 화자의 음성이 남용되거나 복제된 컨텐츠를 찾아낼 수 있으며, 나아가 이러한 컨텐츠의 무단 사용을 방지하기 위한 조치를 취할 수 있다. 도 2는 본 개시의 일 실시예에 따른 컨텐츠 검색 시스템의 블록도이다. 컨텐츠 검색 시스템은 통신 모듈, 데이터베이스, 프로세서를 포함하도록 구성될 수 있다. 여기서, 프로세서는 화자 음성 특징 추출 모듈, 음성 해쉬값 생성 모듈 및 컨텐츠 추출 모듈을 포함하도록 구성될 수 있 다. 통신 모듈은 컨텐츠 검색 시스템이 네트워크를 통해 외부 장치와 신호 또는 데이터를 송수 신하도록 구성될 수 있다. 여기서, 외부 장치는 특정 화자의 음성으로 생성된 사운드를 쿼리로서 컨텐츠 검색 시스템에 제공하고 특정 화자의 음성과 동일한 음성의 컨텐츠를 제공받을 수 있는 사용자 단말, 하나 이상의 컨텐츠를 저장하고 있는 임의의 전자 기기, 학습 음성 데이터 및/또는 해쉬값 정보 등을 저장하고 있는 임의의 서버 장치, 클라우딩 시스템 등을 포함할 수 있다. 일 실시예에 따르면, 통신 모듈은 사용자 단말로부터 대상(target) 화자의 음성으로 생성된 사운드를 수신하도록 구성될 수 있다. 또한, 통신 모듈은 복수의 외부 장치로부터 복수의 컨텐츠를 수신하도록 구 성될 수 있다. 사용자 단말으로부터 수신된 대상 화자의 음성으로 생성된 사운드 및 복수의 외부 장치로 부터 수신된 컨텐츠는 프로세서의 화자 음성 특징 추출 모듈에 제공될 수 있다. 대상 화자의 음성 으로 생성된 사운드를 수신하는 것에 응답하여, 복수의 외부 장치로부터 수신된 복수의 컨텐츠 중에서 대상 화 자의 음성과 동일하거나 유사한 음성을 포함한 컨텐츠가 통신 모듈을 통해 사용자 단말로 송신하도록 구성될 수 있다. 프로세서의 화자 음성 특징 추출 모듈은 수신된 사운드로부터 대상 화자의 음성을 나타내는 특징을 추출하도록 구성될 수 있다. 일 실시예에 따르면, 화자 음성 특징 추출 모듈은 수신된 사운드로부터 대상 화자의 음성에 대응되는 화자 특징 벡터를 추출하도록 구성될 수 있다. 이러한 화자 특징 벡터는 대상 화자가 복수의 다른 화자들과 구분되도록 대상 화자의 특징을 나타내는 임의의 특징 벡터를 지칭할 수 있다. 일 실시예에 따르면, 이러한 화자 특징 벡터는 수신된 사운드 내에 포함된 화자의 음성을 구분할 수 있도록 단 일 저차원 잠재 벡터(single low-dimensional latent vector)로 나타낼 수 있다. 이러한 단일 저차원 잠재 벡 터는 i-vector를 포함할 수 있다. 이러한 i-vector 기법은 GMM (Gaussian Mixture Model)-UBM (Universal Background Mode) 하에서 고려될 수 있는데, 구체적으로, GMM에서 각 개별적인 평균 벡터가 UBM의 평균 벡터의 변화(shift)를 나타낼 수 있으며, 모든 평균의 변화는 단일의 벡터(즉, i-vector)에 의해 제어될 수 있다는 추 정에 기반될 수 있다. 여기서, i-vector ω (화자 특징 벡터)는 아래와 같은 수식 1로 나타낼 수 있다. [수학식 1]"}
{"patent_id": "10-2019-0146098", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "여기서, M은 화자를 나타내고, m은 화자 의존적 및 독립적 GMM 수퍼 벡터(speaker dependent and independent GMM super-vector)를 나타낼 수 있으며, T는 총 변산도 매트릭스(total variability matrix)를 나타낼 수 있다. 이러한 i-vector는 화자의 음성을 효과적으로 구분할 수 있도록 임의의 학습 음성 데이터 세트를 이용하 여 학습될 수 있다. 다른 실시예에 따르면, 이러한 화자 특징 벡터는 DNN을 이용한 화자 임베딩 벡터를 포함할 수 있다. 화자 임베 딩 벡터는 배경 소음(background noise)와 같은 증강 데이터(augmented data)를 포함한 대용량의 데이터 세트를 이용할 수 있다. 여기서, 화자 임베딩 벡터는 학습 음성 데이터 세트에서 N 화자를 분류하기 위하여 학습된 네 트워크로부터 히든 레이어(hidden layer) 중 하나로부터 추출될 수 있다. 예를 들어, 화자 임베딩 벡터는 TDNN(Time Delayed Neural Network)에 기반한 뉴럴 네트워크 구조로부터 추출된 x-vector를 포함할 수 있다. 이러한 x-vector 또한 배경 소음을 가진 증강 데이터로부터의 장점을 가질 수 있다. 이러한 x-vector는 화자의 음성을 효과적으로 구분할 수 있도록 임의의 학습 음성 데이터 세트를 이용하여 학습될 수 있다. 화자 음성 특 징 추출 모듈은 수신된 사운드로부터 추출된 대상 화자의 음성을 나타내는 특징 또는 화자 특징 벡터를 프 로세서의 음성 해쉬값 생성 모듈에 제공할 수 있다. 화자 음성 특징 추출 모듈은 네트워크 상에서 검색 가능한 복수의 컨텐츠를 통신 모듈을 통해 수신할 수 있다. 화자 음성 특징 추출 모듈은 복수의 컨텐츠의 각각에 포함된 하나 이상의 화자의 음성을 나타내 는 특징을 추출할 수 있다. 예를 들어, 화자 음성 특징 추출 모듈은 수신된 컨텐츠의 일부인 오디오 세그 먼트(audio)에 포함된 음성을 나타내는 특징을 추출할 수 있다. 화자 음성 특징 추출 모듈은 대상 화자의특징 또는 화자 특징 벡터를 추출하는 방식과 동일한 방식으로 수신된 복수의 컨텐츠의 각각에 포함된 하나 이 상의 음성을 나타내는 특징 또는 화자 특징 벡터(예를 들어, i-vector, x-vector 등)를 추출하도록 구성될 수 있다. 복수의 컨텐츠와 연관되어 추출된 특징 또는 화자 특징 벡터는 음성 해쉬값 생성 모듈에 제공될 수 있다. 음성 해쉬값 생성 모듈은 해쉬 함수를 이용하여 화자 음성 특징 추출 모듈로부터 수신된 화자의 음성을 나 타내는 특징에 대응하는 해쉬값을 생성할 수 있다. 여기서 해쉬 함수는 Locality Sensitive Hashing(LSH), Random Speaker-variability Subspace (RSS) projection, Discriminative Transform Function or Network 중 적어도 하나의 기법을 이용하여 생성될 수 있다. 이러한 해쉬 함수는 아래 도 4 내지 도 6을 이용하여 상세히 설명된다. 일 실시예에 따르면, 음성 해쉬값 생성 모듈은 해쉬 함수를 이용하여 대상 화자의 음성을 나타 내는 특징에 대응하는 해쉬값을 산출하도록 구성될 수 있다. 또한, 음성 해쉬값 생성 모듈은 대상 화장에 대한 해쉬값을 산출하는데 사용된 해쉬 함수를 이용하여 수신된 복수의 컨텐츠에 포함된 하나 이상의 화자 음성 을 나타내는 특징의 각각에 대응하는 해쉬값을 산출하도록 구성될 수 있다. 이렇게 산출된 해쉬값은 프로세서 의 컨텐츠 추출 모듈에 제공될 수 있다. 컨텐츠 추출 모듈은 네트워크 상에서 검색 가능한 복수의 컨텐츠 중에서, 수신된 대상 화자의 음성에 대한 해쉬값과 유사한 해쉬값과 연관된 컨텐츠를 검색하도록 구성될 수 있다. 일 실시예에 따르면, 컨텐츠 추출 모 듈은 수신된 대상 화자의 음성에 대한 해쉬값을 검색된 복수의 컨텐츠에 대해 산출된 복수의 해쉬값의 각 각과 비교하여, 대상 화자의 음성에 대한 해쉬값과 유사한 해쉬값과 연관된 하나 이상의 컨텐츠를 추출하도록 구성될 수 있다. 다른 실시예에 따르면, 복수의 컨텐츠는 컨텐츠에 포함된 음성 특징 및/또는 대응 해쉬값에 따라 분류화(classify)될 수 있으며, 컨텐츠 추출 모듈은 대상 화자의 음성에 대응되는 분류를 선택하고, 대상 화자의 음성에 대응하는 해쉬값을 선택된 분류에 포함된 해쉬값들과 비교하여 유사한 해쉬값과 연관된 하 나 이상의 컨텐츠를 추출하도록 구성될 수 있다. 본 개시에서, 대상 화자의 음성의 특징에 대응하는 해쉬값(제1 해쉬값)과 유사한 해쉬값(제2 해쉬값)은 복수의 해쉬값 중에서 미리 결정된 유사도 이상을 가진 해쉬값을 지칭할 수 있다. 여기서, 미리 결정된 유사도는 두 해쉬값이 동일한 음성을 가리키기 위해 요구되는 유사도를 지칭될 수 있으며, 학습 음성 데이터를 이용하여 결 정되거나 학습될 수 있다. 예를 들어, 제1 해쉬값이 복수의 해쉬값의 각각과 비교될 때, 제1 해쉬값의 해쉬 비 트와 상이한 비트의 수가 미리 결정된 개수 이하의 해쉬값이 제2 해쉬값으로서 선택될 수 있다. 또 다른 예로 서, 제1 해쉬값과 유사한 제2 해쉬값은 해쉬값에 포함된 해쉬 비트의 가중치를 고려하여 선택될 수 있다. 이러 한 구성 하에서, 해쉬값에 포함된 해쉬 비트들에는 가중치가 부여될 수 있으며, 컨텐츠 추출 모듈은 제1 해쉬값에 포함된 해쉬 비트와 복수의 해쉬값의 각각에 포함된 해쉬 비트를 비교할 때, 상이한 해쉬 비트와 부여 된 가중치를 고려하여 제1 해쉬값과 복수의 해쉬값의 각각에 대한 유사도를 산출하고, 일정 이상의 유사도를 가 진 하나 이상의 해쉬값을 제2 해쉬값으로 결정할 수 있으며, 제2 해쉬값과 연관된 하나 이상의 컨텐츠를 추출할 수 있다. 추출된 컨텐츠는 통신 모듈을 통해 대상 화자의 음성을 제공한 사용자 단말에 제공될 수 있다. 예를 들어, 이러한 컨텐츠가 복수의 컨텐츠를 포함하는 경우, 복수의 컨텐츠에 대한 정보(예를 들어, 링크 정보, 썸 네일 등)가 리스트의 형태로 생성되어 사용자 단말에 제공될 수 있다. 데이터베이스는 프로세서에 의해 이용되거나 출력된 임의의 데이터 또는 정보를 포함할 수 있다. 일 실시예에 따르면, 데이터베이스는 복수의 음성을 나타내는 특징에 대응하는 해쉬값을 저장하도록 구성될 수 있다. 예를 들어, 데이터베이스는 해쉬값을 산출하는데 사용되는 해쉬 테이블을 포함할 수 있으며, 각 해쉬 테이블은 해쉬비트 뿐만 아니라 각 해쉬비트에 대한 가중치를 포함할 수 있다. 또한, 데이터베이스 는 해쉬 함수를 저장할 수 있으며, 해쉬 함수를 산출하는 데에 사용되는 학습 음성 데이터를 저장하도록 구성될 수 있다. 여기서, 학습 음성 데이터는 복수의 화자의 음성에서 각 화자의 음성을 더욱 효과적으로 구분하기 위 해 학습된 음성 데이터의 임의의 세트를 포함할 수 있다. 예를 들어, 학습 음성 데이터는 화자의 음성 특징을 기초로 생성된 화자를 나타내는 원-핫 화자 ID-벡터 및/또는 임베딩 벡터를 포함할 수 있다. 이와 달리, 학습 음성 데이터는 화자를 구분하기 위해 이용되는 임의의 뉴럴 네트워크를 학습하기 위해 사용되는 임의의 학습 데 이터를 포함할 수 있다. 도 2에서는 컨텐츠 검색 시스템이 데이터베이스를 포함하도록 구성되었으나, 이에 한정되지 않으며, 데이터베이스는 컨텐츠 검색 시스템이 접근 가능한 임의의 장치에 저장될 수 있다. 도 3는 본 개시의 일 실시예에 따른 대상 화자의 음성과 동일한 음성을 포함한 컨텐츠를 검색하는 방법을 나타 내는 흐름도이다. 먼저, 단계 S310에서, 컨텐츠 검색 시스템은 대상 화자의 음성으로 생성된 사운드를 수 신할 수 있다. 예를 들어, 컨텐츠 검색 시스템은 대상 화자의 음성으로 생성된 사운드를 적어도 일부로서 포함한 오디오 컨텐츠 또는 비디오 컨텐츠를 수신할 수 있다. 또한, 이러한 대상 화자의 음성으로 생성된 사운 드는 대상 화자의 음성과 동일한 음성을 가진 컨텐츠를 검색하고자 하는 임의의 전자 기기로부터 수신될 수 있 다. 컨텐츠 검색 시스템은 단계 S320에서, 수신된 사운드로부터 대상 화자의 음성을 나타내는 특징을 추출하도 록 구성될 수 있다. 예를 들어, 대상 화자의 음성을 나타내는 특징은 i-vector, x-vector 등과 같은 화자 특징 벡터로 나타낼 수 있다. 단계 S330에서, 컨텐츠 검색 시스템은 해쉬 함수를 이용하여 대상 화자의 음성을 나타내는 특징에 대응하는 해쉬값을 산출할 수 있다. 그리고 나서, 컨텐츠 검색 시스템은 네트워크 상에 서 검색가능한 복수의 컨텐츠 중에서, 대상 화자의 음성에 대한 해쉬값과 유사한 해쉬값과 연관된 하나 이상의 컨텐츠를 검색할 수 있다. 예를 들어, 컨텐츠 검색 시스템은 네트워 상에서 검색 가능한 복수의 컨텐츠의 각각에 대한 해쉬값을 산출할 수 있으며, 산출된 해쉬값의 각각과 대상 화자의 음성에 대한 해쉬값을 비교하여 유사한 해쉬값(예를 들어, 일정 유사도 이상의 해쉬값)과 연관된 하나 이상의 컨텐츠를 검색할 수 있다. 도 4는 본 개시의 일 실시예에 따른 Locality Sensitive Hashing(LSH) 기법을 이용하여 랜덤하게 추출된 화자 특징 벡터를 랜덤 투영하는 방식을 나타내는 예시도이다. 여기서, LSH 기법은 가장 가까운 인접 서치 알고리즘 (nearest neighbor search algorithm)의 하나로서, i-vector를 이용하여 동일한 음성을 가진 오디오 세그먼트 검색의 정확성을 유지하면서 대용량의 데이터에서 관련 음성을 신속히 검색하는 것이 가능한 알고리즘을 나타낼 수 있다. 또한, LSH 기법은 데이터와 독립적인 비교사(unsupervised) 해쉬 기법으로서 화자의 음성을 나타내는 화자 특징 벡터(여기서, i-vector)를 초평면(hyperplane)에 랜덤 투영할 수 있다. 이러한 해쉬 기법은 동일하 거나 유사한 특징을 가진 동일 또는 유사 벡터를 높은 확률로 동일한 영역(예를 들어, bin, bucket)에 매핑시킬 수 있다. 예를 들어, 아래의 수식, 즉 해쉬 함수를 이용하여 해쉬값을 산출해낼 수 있다. [수학식 2]"}
{"patent_id": "10-2019-0146098", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "여기서, r은 표준 정규 분포로부터 산출된 d-차수 임의 투영 벡터를 나타내고, d는 최초 음성 특징 벡터인 i- vector ω(화자 특징 벡터)의 차수를 나타낼 수 있다. i-vector ω는 위 해쉬함수를 이용하여 매핑되어 해쉬값 으로 나타낼 수 있다. 일 실시예에 따르면, 다양한 해쉬 함수들이 이어질 수 있으며, 복수 및 독립적인 해쉬 함수를 사용함으로써 성 능을 향상시킬 수 있다. 예를 들어, d ⅹ k 차수 랜덤 투영 매트릭스 Rl을 이용할 수 있는데, 여기서 k는 해시 테이블 당 초평면의 수를 나타내고, l은 해쉬 테이블의 색인(1 ≤ l ≤ L)을 나타내며, L은 해쉬 테이블의 인덱 스를 나타낸다. 여기서, k와 L은 성능과 복잡도 등을 고려하여 적절히 선택될 수 있다. 도 4는 위 수학식 2을 이용하여 음성을 나타내는 특징벡터 ω를 r이라는 투영 벡터를 이용하여 랜덤하게 추출된 2차원 벡터를 1차원 벡터로 투영하는 그래프를 보여준다. 도시된 바와 같이, 도 4에서, 2차원의 화자 특징 벡 터(spk1, spk2, spk3)가 임의로 추출된 4개의 초평면(410, 420, 430, 440)의 각각에 랜덤 투영하는 과정을 나 타낸다. 특징 벡터(spk1, spk2, spk3)의 각각이 각 초평면(410, 420, 430, 440)에 투영되기 위하여 위 수학식 2가 이용될 수 있다. 특징 벡터(spk1, spk2, spk3)이 각 초평면(410, 420, 430, 440)에 투영되었을 때 각 특 징 벡터(spk1, spk2, spk3)를 구분할 수 있는 영역이 결정될 수 있다. 그리고 나서, 화자 음성 특징 추출 모듈 으로부터 수신된 화자 음성을 나타내는 특징, 즉 화자 특징 벡터를 r이라는 투영 벡터를 이용하여 각 초평 면(410, 420, 430, 440)에 투영될 수 있고, 각 투영 영역에 부여된 값에 기초하여 화자 특징 벡터에 대응하는 해쉬값이 산출될 수 있다. 화자 특징 벡터가 투영된 초평면에 대응하는 영역이 0이면 해쉬비트가 0이 부여되고, 1이면 해쉬 비트가 1이 부여될 수 있다. 즉, 이러한 방식은 r을 임의로 추출해서 많이 투영하면 해 쉬 값이 생성되는 랜덤 투영에 기초한 LSH 기법을 이용한 방식이다. 본 예시에서는, 4개의 초평면에 화자 특징 벡터가 투영될 수 있으므로, 4bit의 해쉬값으로 표현될 수 있다. 이와 달리, 4개의 초 평면 중 3개의 초평면이 선택됨으로써 3bit의 해쉬값으로 표현될 수 있다. 이러한 해쉬값은 화자 특징 벡터를 인덱싱하는데에 사용될 수 있다.도 5는 본 개시의 일 실시예에 따른 LSH에 대한 판별 변환 함수(discriminative transform function)를 이용하 여 화자의 음성을 나타내는 화자 특징 벡터에 대한 해쉬값을 산출하는 방법을 나타내는 흐름도이다. 일 실시예 에 따르면, 동일한 화자의 음성을 동일한 영역에 더 효과적으로 매핑시키기 위하여, 위에서 설명드린 비교사 해 쉬 기법인 LSH에 화자 라벨을 이용하여, 즉 교사 기법을 이용하여, 판별 변환 함수를 생성할 있으며, 생성된 판 별 변환 함수는 도 4에서 설명된 투영 매트릭스 Rl를 대신하여 사용될 수 있다. 여기서, 판별 변환 함수는 동 일한 화자 분류(class) 내의 특징들 사이의 거리는 최소화하고 상이한 분류 내의 특징 사이의 거리는 최대화할 수 있는 임의의 판별 변환 방법을 지칭할 수 있다. 일 실시예에 따르면, 이러한 판별 변환 함수는 랜덤 화자 서브 세트를 이용하여 랜덤 화자 서브 세트에 연관된 복수의 화자 분류에 대응하는 영역이 판별되도록 인공신경 망 판별 모델(예를 들어, 딥 뉴럴 네트워크)를 학습하여 생성할 수 있다, 비선형 함수(네트워크)를 생성할 수 있다. 다른 실시예에 따르면, 랜덤 화자 서브 세트로부터의 음성 또는 말(utterances)을 이용하여 Linear Discriminant Analysis (LDA) 변환 매트릭스가 이러한 판별 변환 함수로서 생성될 수 있으며, 생성된 매트릭스 는 도 4에서 설명된 투영 매트릭스 Rl를 대신하여 사용될 수 있다. 단계 S510에서, 음성 해쉬값 생성 모듈(S250)은 학습 음성 데이터로부터 랜덤 화자 서브 세트를 미리 결정된 수 만큼 반복하여 선택할 수 있다. 여기서, 학습 음성 데이터는 랜덤 화자 서브 세트를 포함할 수 있으며, 각 화 자의 서브 세트를 구분할 수 있는 화자 라벨에 대한 정보를 포함할 수 있다. 또한, 미리 결정된 수는, 미리 결 정된 해쉬 테이블의 총 수를 나타낼 수 있다. 이에 따라, 랜덤 화자 서브 세트는 복수의 화자 분류와 연관될 수 있다. 일 실시예에 따르면, Sl는 학습 음성 데이터로부터 임의로 선택된 화자 서브세트(S는 speaker)일 수 있으며, 여기서, 화자의 수는 Ns일 수 있다. 그리고 나서, 선택된 랜덤 화자 서브 세트의 각각을 기초로 판별 변환 함수가 생성될 수 있다(단계 S520). 이 러한 판별 변환 함수는 해쉬 함수를 생성하는데에 이용될 수 있다. 일 실시예에 따르면, 학습 음성 데이터로부 터 선택된 랜덤 화자 서브 세트를 이용하여 랜덤 화자 서브 세트에 연관된 복수의 화자 분류에 대응하는 영역이 판별되도록 인공신경망 판별 모델이 학습될 수 있으며, 이러한 학습된 인공신경망 판별 모델은 비선형 함수 또 는 네트워크로서 해쉬 함수를 생성하는데에 사용될 수 있다. 예를 들어, 선택된 랜덤 화자 서브 세트를 이용하 여 학습 음성 데이터로부터 선택된 랜덤 화자 서브 세트와 연관된 화자 분류들 중에서, 동일한 화자 분류 내에 서 거리(distance)는 최소화하고 상이한 화자 분류 내에서의 거리는 최대화하도록 인공신경망 판별 모델이 학습 될 수 있으며, 이러한 인공신경망 판별 모델은 도 4에서 설명된 투영 매트릭스 Rl를 대신하여 대상 화자의 음성 을 나타내는 특징 벡터를 각 랜덤 서브 화자 세트 중 어느 부분에 속하는지 결정하는 데에 사용될 수 있다. 다른 실시예에 따르면, 선택된 랜덤 화자 서브 세트의 각각을 이용하여 LDA 변환 매트릭스는 미리 결정된 수 만 큼 반복하여 생성될 수 있다. 예를 들어, 선택된 랜덤 화자 서브 세트의 각각에 대해 학습 음성 데이터를 이용 하여 랜덤 화자 서브 세트와 연관된 화자 분류(class) 사이의 스캐터 매트릭스가 생성될 수 있다. 또한, 선택 된 랜덤 화자 서브 세트의 각각에 대해 학습 음성 데이터를 이용하여 랜덤 화자 서브 세트와 연관된 하나의 화 자 분류 내의 스캐터 매트릭스가 생성될 수 있다. 그리고 나서, 복수의 화자 사이의 스캐터 매트릭스 및 하나 의 화자 분류 내의 스캐터 매트릭스의 비율이 최대화되도록 LDA 변환 매트릭스가 생성될 수 있다. 그리고 나서, 단계 S530에서, 음성 해쉬값 생성 모듈은 추출된 화자 특징 벡터를 해쉬 함수에 입력하여 대 상 화자의 음성을 나타내는 특징에 대응하는 해쉬값을 산출하도록 구성될 수 있다. 이렇게 생성된 해쉬값은 컨 텐츠 추출 모듈에 전달되어 유사한 해쉬값과 연관된 하나 이상의 컨텐츠를 검색하는데에 사용될 수 있다. 일 실시예에 따르면, 음성 해쉬값 생성 모듈은 추출된 화자 특징 벡터를 학습된 인공신경망 판별 모델에 입력하여, 랜덤 화자 서브 세트와 연관된 복수의 화자 분류에 대응하는 복수의 영역 중에서, 추출된 화자 특징 벡터가 대응하는 적어도 하나의 화자 분류에 대한 영역에 대한 정보를 출력하도록 구성될 수 있다. 그리고 나 서, 적어도 하나의 분류에 대한 영역의 각각에 대응하는 값을 이용하여 대상 화자의 음성을 나타내는 특징에 대 응하는 해쉬값이 산출될 수 있다. 다른 실시예에 따르면, 선형 판별 변환 함수 중 하나인 LDA 변환 함수를 이 용한 해쉬값을 산출하는 방식은 아래 도 6 및 7을 참고하여 상세히 설명된다. 도 6은 선형 판별 분석(LDA, Linear discriminant analysis) 함수를 이용하여 화자의 음성을 나타내는 화자 특 징 벡터를 랜덤 화자-변산도 서브 공간에 투영하여 특징 벡터에 대한 해쉬값을 산출하는 방법을 나타내는 흐름 도이다. 단계 S610에서, 음성 해쉬값 생성 모듈은 미리 결정된 수 만큼 반복하여 생성된 LDA 변환 매트릭 스의 각각을 이용하여 화자 특징 벡터를 LDA 변환 매트릭스에 대응하는 랜덤 화자-변산도 서브공간(RSS, Random Speaker-variability Subspace)에 투영할 수 있다. 여기서, 랜덤 화자-변산도 서브공간은 랜덤 화자 서브 세트와 연관된 변산도 서브공간을 나타낼 수 있다. 이러한 투영 방식은 LSH 기법의 임의 투영 매트릭스 Rl를 대신 할 수 있다. 하이퍼파라미터(hyperparameter) Ns에 대하여, 너무 많은 화자가 선택되는 경우 투영 매트릭스 사이에 많은 중 복검사가 일어날 수 있다. 이러한 점을 고려하여, Ns는 해쉬 비트의 길이 k보다 많도록 선택되고 k 차수로 투 영될 수 있다. 본 실시예에서, 각 해쉬 영역의 크기를 균형있게 유지하기 위하여 아래의 수학식 3이 해쉬 함수 로 이용될 수 있다. [수학식 3]"}
{"patent_id": "10-2019-0146098", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "item": 5, "content": "도 4에서 설명된 변수 또는 상수와 동일하고, 여기서, b는 투영된 데이터의 평균을 나타낼 수 있으며, 로 나타낼 수 있다. 단계 S620에서, 화자 특징 벡터의 투영 영역의 각각에 대응하는 화자 분류에 대응하는 값이 할당될 수 있다. 여기서, 랜덤 화자 서브 세트 및 랜덤 화자-변산도 서브공간의 각각은 복수의 화자 분류(class)와 연관될 수 있 다. 화자 특징 벡터의 투영 영역의 각각이 대응 랜덤 화자-변산도 서브 공간에 포함된 복수의 화자 분류 중 하 나의 분류에 속하는 경우, 하나의 화자 분류에 대응하는 값은 화자 특징 벡터의 투영 영역의 각각에 할당될 수 있다. 그리고 나서, 단계 S630에서, 미리 할당된 값을 기초로 화자 특징 벡터에 대응되는 해쉬값이 생성될 수 있다. 이렇게 RSS 공간에 LDA 변환 매트릭스를 이용하여 투영하는 방식을 이용하여 화자의 음성을 검색해본 결과, 이 러한 방식은 기존의 화자 음성 선형 서치(linear search)보다 100배 빠르고, LSH보다 7배 빠른 화자의 음성 검 색이 제공될 수 있다. 도 7은 본 개시의 일 실시예에 따른 LSH에 대한 LDA 함수를 이용하여 학습 음성 데이터로부터 선택된 랜덤 화자 서브 세트(Spk 1, Spk2, Spk 3)를 랜덤 화자-변산도 서브 공간에 투영하는 방식을 나타내는 예시도이다. 도시 된 바와 같이, 위 수학식 3를 이용하여 음성을 나타내는 특징벡터 ω(화자 특징 벡터)를 LSH 기법을 기초로 RSS 투영하는 방식을 이용하여 2차원 벡터가 1차원 벡터로 투영될 수 있다. 위에서 언급된 LDA 기법을 이용하여 r 이 산출될 수 있다. 즉, 정확히 동일한 음성이 검색되는 것이 아니라 음성이 달라도 같은 분류가 검색되는 것 이기 때문에, 분류가 잘 구분되도록 r이 산출될 수 있다. 도시된 바와 같이, 학습 음성 데이터로부터 선택된 랜덤 화자 서브 세트(Spk1, Spk2, Spk3)는 위에서 언급된 LDA 변환 매트릭스를 통해 산출된 r을 이용하여 초평면(710, 720, 730)에 투영될 수 있다. 초평면(710, 720, 730)은 3개의 해쉬 테이블의 각각과 연관된 초평면을 포함할 수 있다. 랜덤 화자 서브 세트 (Spk1, Spk2, Spk3)는 각 초평면(710, 720, 730)에 투영되었을 때 각 초평면(710, 720, 730)에 각 랜덤 화자 서브 세트를 구 분할 수 있는 영역이 결정될 수 있다. 이러한 구성 하에서, 화자 음성 특징 추출 모듈으로부터 수신된 화 자의 음성을 나타내는 특징 벡터 ω를 LDA 변환 매트릭스를 통해 산출된 r을 이용하여 각 초평면(710, 720, 730)에 투영될 수 있다. 일 실시예에 따르면, 3개의 화자 분류가 있을 때 2개의 초평면을 선택하고, 화자 특징 벡터 ω는 선택된 2개의 초평면에 대해 LDA 변환 매트릭스를 통해 산출된 r을 이용하여 투영함으로써 해쉬값(비 트)이 산출될 수 있다. 예를 들어, 화자 분류 Spk2와 Spk3을 구분할 수 있는 r을 산출한 이후에 r을 이용하여 화자 특징 벡터 ω를 초평면(예를 들어, 730)에 투영했을 때, 화자 분류 2에 가까우면 1로 해쉬 비트가 생성되 고, 화자 분류 3에 가까우면 0으로 해쉬 비트가 생성될 수 있다. 이와 유사한 방식으로 2번 화자 분류를 추출 하여 r을 산출한 이후에 2bit의 해쉬값을 생성될 수 있다. 이러한 해쉬값은 주어진 3명의 화자를 구분할 수 있 다. 도 7에서는 3명의 화자에 대한 LDA 기법이 적용된 예시가 설명되었지만, 4명 이상의 화자인 경우에도 동일 또는 유사한 기법이 적용될 수 있다. 아래 도 8 내지 도 12은 화자 검색 결과에 대한 실험 결과를 보여주는 도면이다. 여기서는, Voxceleb 1 및 2의 화자 음성 데이터 세트를 이용하여 화자 검색 결과가 평가되었다. Voxceleb 1 및 2는 대용량의 화자 식별을 위 하여 자동적으로 수집된 오디오 및 비디오 데이터를 포함할 수 있다. 예를 들어, Voxceleb 1 및 2는 7,365 화 자로부터의 1,281,352의 음성 컨텐츠(예: utterances)를 포함할 수 있다. 각 음성 컨텐츠는 오디오 또는 비디오 클립으로부터 추출될 수 있으며, 각 클립은 10 내지 50 음성 컨텐츠를 포함할 수 있다. 도 8은 일 실시예에 따른 LSH, 랜덤샘플링 LDA 기법 및 제안된 LDA 기법(RSS를 이용한 LDA 기법)에 따른 동일 화자 사이의 평균 해밍 거리(Hamming distance) 및 상이한 화자 사이의 평균 해밍 거리에 따른 결과값을 보여주 는 그래프를 나타내는 도면이다. 여기서, 해밍 거리는 초평면 k의 수가 증가함에 따라 코사인 거리(cosine distance)에 근사화되거나 가까워질 수 있다. 이러한 해밍 거리와 코사인 거리는 아래 수학식 4를 이용하여 표 현될 수 있다. [수학식 4]"}
{"patent_id": "10-2019-0146098", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "여기서, 는 해밍 거리를 나타낼 수 있다. 투영 매트릭스가 원 거리(original distance)를 효과적으로 근사화한 경우, 동일한 화자에 대한 화자 표시, 즉 화자 특징 벡터는 동일한 또는 가까운 영역(bin, bucket 등)에 포함될 가능성이 높으며, 이에 따라 원 거리를 근사화하기 위하여 적은 수의 해쉬 함수가 이용될 수 있다. 이는 동일한 화자에 대한 화자 표시의 해밍 거리가 상이한 화자에 대한 화자 표시의 해밍 거리보다 가깝다는 것을 의미할 수 있다. 이러한 점을 고려하여 새로운 투영 매트릭스의 근사 능력은 동일한 화자 및 상이한 화자의 평균 해밍 거리에 의해 수치화될 수 있다. 도 8에서는 LSH, 랜덤샘플링 LDA 기법 및 제안된 LDA 기법(RSS를 이용한 LDA 기법)에 따른 동일 화자의 평균 해 밍(Hamming) 거리를 다른 화자의 해밍 거리로 나눈 값들을 보여준다. 즉, 도 8에서는 세 가지 기법이 초평면의 비트 수에 따라 동일한 화자가 동일하게 인식되고 다른 화자와의 사이에서의 구분이 얼마나 이루어졌는지 나타 내고 있으며, 더 낮은 값이 더 화자 검색이 잘 이루어지고 있음을 나타낸다. 도 8에서, 제안된 LDA 기법의 결 과값이 다른 두 기법에 비해 동일 화자 사이의 거리가 가깝고, 다른 화자 사이의 거리가 먼 거리임을 나타낸다. 즉, 제안된 LDA 기법의 음성 검색 성능이 다른 두 기법보다 우수할 수 있다. 도 9 및 도 10은 다양한 해쉬 기법에 대해 초평면 및 해쉬 테이블의 수에 따른 결과값을 보여주는 그래프를 나 타내는 도면이다. 여기서, 다양한 해쉬 기법은 i-vector를 이용한 LSH 기법, i-vector를 이용한 랜덤샘플링 LDA 기법, 제안된 기법 중 하나인 i-vector를 이용한 LDA를 통한 RSS 기법, x-vector를 이용한 LSH 기법, x- vector를 이용한 랜덤샘플링 LDA 기법, 제안된 기법 중 하나인 x- vector를 이용한 LDA를 통한 RSS 기법을 포함 할 수 있다. 도 9 및 도 10은 각 해쉬 기법에 대해 초평면의 수에 따른 평균 에러 비율(EER, Equal Error Rate)을 보여준다. 도시된 바와 같이, x-vector를 이용한 LDA를 통한 RSS 기법이 가장 좋은 ERR의 결과값을 가 진다는 것을 보여준다. 즉, x-vector를 이용한 LDA를 통한 RSS 기법이 i-vector를 이용한 LDA를 통한 RSS 기 법보다 더 좋은 결과값을 보여준다. 이는 i-vector 프레임 워크에서 i-vector는 가우시안 분포에 분포되었음에 반하여 x-vector를 추출하는 DNN이 원 핫 화자 라벨을 이용하여 더 효과적으로 학습되었다는 점에 기인될 수 있 다. 이러한 결과를 비추어볼 때, x-vector 뿐만 아니라 DNN으로부터 추출된 임의의 화자 벡터에 LDA를 통한 RSS 기법이 적용되었을 때, 동일 화자 검색에 대한 EER은 더 향상된 결과값이 산출될 수 있다. 도 11 및 12는 다양한 해쉬 기법에 따른 검색 속도 및 성능 사이의 트레이드 오프(trade-off)를 보여주는 그래 프를 나타내는 도면이다. 이 실험은 파라미터 k와 L을 다양하게 설정함으로써 실행되었으며, 속도 및 성능 축 에 따른 결과값이 표시되었다. 화자 검색 및 식별 동작에서, 제안된 기법(i-vector를 이용한 LDA를 통한 RSS 기법)이 다른 기법보다 엄청난 성능 향상을 보여준다. 예를 들어, 화자 음성 선형 서치와 비교하여 95프로 이 상의 화자 식별 성능을 유지하면서 속도를 향상시키는 데 있어서, 제안된 기법은 화자 검색 선형 서치보다 약 100배 이상의 속도 향상을 보여주었으며, KSH보다 7배 이상의 속도 향상을 달성하였다. 참고로, 도 9 내지 11 의 EER은 선형 서치와의 비교 값이 아니라 절대 값이다. 일반적으로, 본 명세서에 설명된 대상 화자 음성과 동일한 음성을 가진 컨텐츠를 검색하는 시스템 및/또는 장치 는, 무선 전화기, 셀룰러 전화기, 랩탑 컴퓨터, 무선 멀티미디어 디바이스, 무선 통신 PC (personal computer) 카드, PDA, 외부 모뎀이나 내부 모뎀, 무선 채널을 통해 통신하는 디바이스 등과 같은 다양한 타입들의 디바이 스들을 나타낼 수도 있다. 디바이스는, 액세스 단말기 (access terminal; AT), 액세스 유닛, 가입자 유닛, 이 동국, 모바일 디바이스, 모바일 유닛, 모바일 전화기, 모바일, 원격국, 원격 단말, 원격 유닛, 유저 디바이스, 유저 장비 (user equipment), 핸드헬드 디바이스 등과 같은 다양한 이름들을 가질 수도 있다. 본 명세서에 설 명된 임의의 디바이스는 명령들 및 데이터를 저장하기 위한 메모리, 뿐만 아니라 하드웨어, 소프트웨어,펌웨어, 또는 이들의 조합들을 가질 수도 있다. 본 명세서에 기술된 기법들은 다양한 수단에 의해 구현될 수도 있다. 예를 들어, 이러한 기법들은 하드웨어, 펌웨어, 소프트웨어, 또는 이들의 조합으로 구현될 수도 있다. 본 명세서의 개시와 연계하여 설명된 다양한 예 시적인 논리적 블록들, 모듈들, 회로들, 및 알고리즘 단계들은 전자 하드웨어, 컴퓨터 소프트웨어, 또는 양자의 조합들로 구현될 수도 있음을 당업자들은 더 이해할 것이다. 하드웨어 및 소프트웨어의 이러한 상호교환성을 명확하게 설명하기 위해, 다양한 예시적인 컴포넌트들, 블록들, 모듈들, 회로들, 및 단계들이 그들의 기능성의 관점에서 일반적으로 위에서 설명되었다. 그러한 기능이 하드웨어로서 구현되는지 또는 소프트웨어로서 구현되 는 지의 여부는, 특정 애플리케이션 및 전체 시스템에 부과되는 설계 제약들에 따라 달라진다. 당업자들은 각 각의 특정 애플리케이션을 위해 다양한 방식들로 설명된 기능을 구현할 수도 있으나, 그러한 구현 결정들은 본 개시의 범위로부터 벗어나게 하는 것으로 해석되어서는 안된다. 하드웨어 구현에서, 기법들을 수행하는 데 이용되는 프로세싱 유닛들은, 하나 이상의 ASIC들, DSP들, 디지털 신 호 프로세싱 디바이스들 (digital signal processing devices; DSPD들), 프로그램가능 논리 디바이스들 (programmable logic devices; PLD들), 필드 프로그램가능 게이트 어레이들 (field programmable gate arrays; FPGA들), 프로세서들, 제어기들, 마이크로제어기들, 마이크로프로세서들, 전자 디바이스들, 본 명세서에 설명된 기능들을 수행하도록 설계된 다른 전자 유닛들, 컴퓨터, 또는 이들의 조합 내에서 구현될 수도 있다. 따라서, 본 명세서의 개시와 연계하여 설명된 다양한 예시적인 논리 블록들, 모듈들, 및 회로들은 범용 프로세 서, DSP, ASIC, FPGA나 다른 프로그램 가능 논리 디바이스, 이산 게이트나 트랜지스터 로직, 이산 하드웨어 컴 포넌트들, 또는 본 명세서에 설명된 기능들을 수행하도록 설계된 것들의 임의의 조합으로 구현되거나 수행될 수 도 있다. 범용 프로세서는 마이크로프로세서일 수도 있지만, 대안에서, 프로세서는 임의의 종래의 프로세서, 제어기, 마이크로제어기, 또는 상태 머신일 수도 있다. 프로세서는 또한 컴퓨팅 디바이스들의 조합, 예를 들면, DSP와 마이크로프로세서, 복수의 마이크로프로세서들, DSP 코어와 연계한 하나 이상의 마이크로프로세서 들, 또는 임의의 다른 그러한 구성의 조합으로써 구현될 수도 있다. 펌웨어 및/또는 소프트웨어 구현에 있어서, 기법들은 랜덤 액세스 메모리 (random access memory; RAM), 판독 전용 메모리 (read-only memory; ROM), 불휘발성 RAM (non-volatile random access memory; NVRAM), PROM (programmable read-only memory), EPROM (erasable programmable read-only memory), EEPROM (electrically erasable PROM), 플래시 메모리, 컴팩트 디스크 (compact disc; CD), 자기 또는 광학 데이터 스토리지 디바이 스 등과 같은 컴퓨터 판독가능 매체 상에 저장된 명령들로써 구현될 수도 있다. 명령들은 하나 이상의 프로세 서들에 의해 실행 가능할 수도 있고, 프로세서(들)로 하여금 본 명세서에 설명된 기능의 특정 양태들을 수행하 게 할 수도 있다. 소프트웨어로 구현되면, 상기 기능들은 하나 이상의 명령들 또는 코드로서 컴퓨터 판독 가능한 매체 상에 저장 되거나 또는 컴퓨터 판독 가능한 매체를 통해 전송될 수도 있다. 컴퓨터 판독가능 매체들은 한 장소에서 다른 장소로 컴퓨터 프로그램의 전송을 용이하게 하는 임의의 매체를 포함하여 컴퓨터 저장 매체들 및 통신 매체들 양자를 포함한다. 저장 매체들은 컴퓨터에 의해 액세스될 수 있는 임의의 이용 가능한 매체들일 수도 있다. 비제한적인 예로서, 이러한 컴퓨터 판독가능 매체는 RAM, ROM, EEPROM, CD-ROM 또는 다른 광학 디스크 스토리지, 자기 디스크 스토리지 또는 다른 자기 스토리지 디바이스들, 또는 소망의 프로그램 코드를 명령들 또 는 데이터 구조들의 형태로 이송 또는 저장하기 위해 사용될 수 있으며 컴퓨터에 의해 액세스될 수 있는 임의의 다른 매체를 포함할 수 있다. 또한, 임의의 접속이 컴퓨터 판독가능 매체로 적절히 칭해진다. 예를 들어, 소프트웨어가 동축 케이블, 광섬유 케이블, 연선, 디지털 가입자 회선 (DSL), 또는 적외선, 무선, 및 마이크로파와 같은 무선 기술들을 사용하여 웹사이트, 서버, 또는 다른 원격 소스로부터 전송되면, 동축 케 이블, 광섬유 케이블, 연선, 디지털 가입자 회선, 또는 적외선, 무선, 및 마이크로파와 같은 무선 기술들은 매 체의 정의 내에 포함된다. 본 명세서에서 사용된 디스크 (disk) 와 디스크 (disc)는, CD, 레이저 디스크, 광 디스크, DVD (digital versatile disc), 플로피디스크, 및 블루레이 디스크를 포함하며, 여기서 디스크들 (disks) 은 보통 자기적으로 데이터를 재생하고, 반면 디스크들 (discs) 은 레이저를 이용하여 광학적으로 데이 터를 재생한다. 위의 조합들도 컴퓨터 판독가능 매체들의 범위 내에 포함되어야 한다. 소프트웨어 모듈은 RAM 메모리, 플래시 메모리, ROM 메모리, EPROM 메모리, EEPROM 메모리, 레지스터들, 하드 디스크, 이동식 디스크, CD-ROM, 또는 공지된 임의의 다른 형태의 저장 매체 내에 상주할 수도 있다. 예시적인 저장 매체는, 프로세가 저장 매체로부터 정보를 판독하거나 저장 매체에 정보를 기록할 수 있도록, 프로세서에 커플링 될 수 있다. 대안으로, 저장 매체는 프로세서에 통합될 수도 있다. 프로세서와 저장 매체는 ASIC 내에존재할 수도 있다. ASIC은 유저 단말 내에 존재할 수도 있다. 대안으로, 프로세서와 저장 매체는 유저 단말에 서 개별 컴포넌트들로써 존재할 수도 있다. 본 개시의 앞선 설명은 당업자들이 본 개시를 행하거나 이용하는 것을 가능하게 하기 위해 제공된다. 본 개시 의 다양한 수정예들이 당업자들에게 쉽게 자명할 것이고, 본 명세서에 정의된 일반적인 원리들은 본 개시의 취 지 또는 범위를 벗어나지 않으면서 다양한 변형예들에 적용될 수도 있다. 따라서, 본 개시는 본 명세서에 설명 된 예들에 제한되도록 의도된 것이 아니고, 본 명세서에 개시된 원리들 및 신규한 특징들과 일관되는 최광의의 범위가 부여되도록 의도된다. 비록 예시적인 구현예들이 하나 이상의 독립형 컴퓨터 시스템의 맥락에서 현재 개시된 주제의 양태들을 활용하 는 것을 언급할 수도 있으나, 본 주제는 그렇게 제한되지 않고, 오히려 네트워크나 분산 컴퓨팅 환경과 같은 임 의의 컴퓨팅 환경과 연계하여 구현될 수도 있다. 또 나아가, 현재 개시된 주제의 양상들은 복수의 프로세싱 칩 들이나 디바이스들에서 또는 그들에 걸쳐 구현될 수도 있고, 스토리지는 복수의 디바이스들에 걸쳐 유사하게 영 향을 받게 될 수도 있다. 이러한 디바이스들은 PC들, 네트워크 서버들, 및 핸드헬드 디바이스들을 포함할 수도 있다. 비록 본 주제가 구조적 특징들 및/또는 방법론적 작용들에 특정한 언어로 설명되었으나, 첨부된 청구항들에서 정의된 주제가 위에서 설명된 특정 특징들 또는 작용들로 반드시 제한되는 것은 아님이 이해될 것이다. 오히려, 위에서 설명된 특정 특징들 및 작용들은 청구항들을 구현하는 예시적인 형태로서 설명된다. 이 명세서에서 언급된 방법은 특정 실시예들을 통하여 설명되었지만, 컴퓨터로 읽을 수 있는 기록매체에 컴퓨터 가 읽을 수 있는 코드로서 구현하는 것이 가능하다. 컴퓨터가 읽을 수 있는 기록매체는 컴퓨터 시스템에 의해 읽힐 수 있는 데이터가 저장되는 모든 종류의 기록장치를 포함한다. 컴퓨터가 읽을 수 있는 기록매체의 예로는 ROM, RAM, CD-ROM, 자기 테이프, 플로피 디스크, 광데이터 저장장치 등이 있다. 또한, 컴퓨터가 읽을 수 있는 기록매체는 네트워크로 연결된 컴퓨터 시스템에 분산되어, 분산방식으로 컴퓨터가 읽을 수 있는 코드가 저장되 고 실행될 수 있다. 그리고, 실시예들을 구현하기 위한 기능적인(functional) 프로그램, 코드 및 코드 세그먼"}
{"patent_id": "10-2019-0146098", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 7, "content": "트들은 본 발명이 속하는 기술분야의 프로그래머들에 의해 용이하게 추론될 수 있다."}
{"patent_id": "10-2019-0146098", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 8, "content": "본 명세서에서는 본 개시가 일부 실시예들과 관련하여 설명되었지만, 본 발명이 속하는 기술분야의 통상의 기술 자가 이해할 수 있는 본 개시의 범위를 벗어나지 않는 범위에서 다양한 변형 및 변경이 이루어질 수 있다는 점 을 알아야 할 것이다. 또한, 그러한 변형 및 변경은 본 명세서에 첨부된 특허청구의 범위 내에 속하는 것으로 생각되어야 한다. 도면 도면1 도면2 도면3 도면4 도면5 도면6 도면7 도면8 도면9 도면10 도면11 도면12"}
{"patent_id": "10-2019-0146098", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 일 실시예에 따른 네트워크 상에서 검색 가능한 복수의 컨텐츠 중에서, 음성으로 생성된 사운드 내에 포 함된 음성과 동일한 음성을 포함한 컨텐츠를 검색하는 시스템을 나타내는 도면이다. 도 2는 본 개시의 일 실시예에 따른 컨텐츠 검색 시스템의 블록도이다. 도 3은 본 개시의 일 실시예에 따른 대상 화자의 음성과 동일한 음성을 포함한 컨텐츠를 검색하는 방법을 나타 내는 흐름도이다. 도 4은 본 개시의 일 실시예에 따른 Locality Sensitive Hashing(LSH) 기법을 이용하여 랜덤하게 추출된 화자 특징 벡터를 랜덤 투영하는 방식을 나타내는 예시도이다. 도 5는 본 개시의 일 실시예에 따른 LSH에 대한 판별 변환 함수(discriminative transform function)를 이용하 여 화자의 음성을 나타내는 화자 특징 벡터에 대한 해쉬값을 산출하는 방법을 나타내는 흐름도이다. 도 6은 선형 판별 분석(LDA, Linear discriminant analysis) 함수를 이용하여 화자의 음성을 나타내는 화자 특 징 벡터를 랜덤 화자-변산도 서브 공간에 투영하여 특징 벡터에 대한 해쉬값을 산출하는 방법을 나타내는 흐름 도이다. 도 7는 본 개시의 일 실시예에 따른 LSH에 대한 LDA 함수를 이용하여 학습 음성 데이터로부터 선택된 랜덤 화자 서브 세트를 랜덤 화자-변산도 서브 공간에 투영하는 방식을 나타내는 예시도이다. 도 8은 LSH, 랜덤샘플링 LDA 기법 및 제안된 LDA 기법(RSS를 이용한 LDA 기법)에 따른 동일 화자의 평균 해밍 거리(Hamming distance) 및 상이한 화자 사이의 평균 해밍 거리에 따른 결과값을 보여주는 그래프를 나타내는 도면이다. 도 9 및 도 10은 다양한 해쉬 기법에 대해 초평면 및 해쉬 테이블의 수에 따른 결과값을 보여주는 그래프를 나 타내는 도면이다. 도 10 및 11은 다양한 해쉬 기법에 따른 검색 속도 및 성능 사이의 트레이드 오프(trade-off)를 보여주는 그래 프를 나타내는 도면이다."}
