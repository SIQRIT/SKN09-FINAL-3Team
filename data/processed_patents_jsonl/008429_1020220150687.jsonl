{"patent_id": "10-2022-0150687", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0069301", "출원번호": "10-2022-0150687", "발명의 명칭": "깊이 정보 추정 방법 및 장치", "출원인": "삼성전자주식회사", "발명자": "김지환"}}
{"patent_id": "10-2022-0150687", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "제1 깊이 맵(depth map)을 시뮬레이터(simulator)에 입력하여, 제1 시뮬레이션 영상을 획득하는 단계;상기 제1 깊이 맵과 상기 제1 시뮬레이션 영상에 기초하여, 인공 신경망 모델을 학습하는 단계;실제 영상을 상기 인공 신경망 모델에 입력하여, 제2 깊이 맵을 획득하는 단계; 및상기 제2 깊이 맵을 상기 시뮬레이터에 입력하여, 제2 시뮬레이션 영상을 획득하는 단계를 포함하는 깊이 정보 추정 방법."}
{"patent_id": "10-2022-0150687", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 제2 깊이 맵과 상기 제2 시뮬레이션 영상에 기초하여, 상기 인공 신경망 모델을 학습하는 단계를 더 포함하는, 깊이 정보 추정 방법."}
{"patent_id": "10-2022-0150687", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 제2 깊이 맵으로부터 랜덤 노이즈 부가, 이미지 회전, 스케일 조정, 이미지 이동, 랜덤 크롭, 및 색상 왜곡 중 하나 또는 둘 이상의 조합을 포함하는 데이터 증강(data augmentation)에 기초하여 복수의 변형 깊이 맵들을 생성하는 단계; 및상기 복수의 변형 깊이 맵들 및 상기 제2 시뮬레이션 영상에 기초하여, 상기 인공 신경망 모델을 학습하는 단계를 더 포함하는, 깊이 정보 추정 방법."}
{"patent_id": "10-2022-0150687", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,상기 실제 영상은SEM 영상을 포함하는, 깊이 정보 추정 방법."}
{"patent_id": "10-2022-0150687", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서,상기 SEM 영상에 기초하여, 상기 제1 깊이 맵을 획득하는 단계를 더 포함하는, 깊이 정보 추정 방법."}
{"patent_id": "10-2022-0150687", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "공개특허 10-2024-0069301-3-제4항에 있어서,상기 SEM 영상 및 TEM 영상에 기초하여, 상기 제1 깊이 맵을 획득하는 단계를 더 포함하는, 깊이 정보 추정 방법."}
{"patent_id": "10-2022-0150687", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "실제 영상을 인공 신경망 모델에 입력하여, 상기 실제 영상에 대응하는 깊이 맵을 획득하는 단계를 포함하고,상기 인공 신경망 모델은상기 깊이 맵을 시뮬레이터에 입력하여 획득한 시뮬레이션 영상과 상기 깊이 맵에 기초하여 학습되는, 깊이 정보 추정 방법."}
{"patent_id": "10-2022-0150687", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "하드웨어와 결합되어 제1항 내지 제7항 중 어느 하나의 항의 방법을 실행시키기 위하여 매체에 저장된 컴퓨터프로그램."}
{"patent_id": "10-2022-0150687", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "적어도 하나의 명령어를 저장하는 메모리; 및상기 메모리에 저장된 명령어를 실행함으로써,제1 깊이 맵(depth map)을 시뮬레이터(simulator)에 입력하여, 제1 시뮬레이션 영상을 획득하고,상기 제1 깊이 맵과 상기 제1 시뮬레이션 영상에 기초하여, 인공 신경망 모델을 학습하고,실제 영상을 상기 인공 신경망 모델에 입력하여, 제2 깊이 맵을 획득하고,상기 제2 깊이 맵을 상기 시뮬레이터에 입력하여, 제2 시뮬레이션 영상을 획득하는 프로세서를 포함하는 전자장치."}
{"patent_id": "10-2022-0150687", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9항에 있어서,상기 프로세서는상기 제2 깊이 맵과 상기 제2 시뮬레이션 영상에 기초하여, 상기 인공 신경망 모델을 학습하는, 전자 장치."}
{"patent_id": "10-2022-0150687", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제9항에 있어서,상기 프로세서는상기 제2 깊이 맵으로부터 랜덤 노이즈 부가, 이미지 회전, 스케일 조정, 이미지 이동, 랜덤 크롭, 및 색상 왜곡 중 하나 또는 둘 이상의 조합을 포함하는 데이터 증강(data augmentation)에 기초하여 복수의 변형 깊이 맵들을 생성하고, 상기 복수의 변형 깊이 맵들 및 상기 제2 시뮬레이션 영상에 기초하여, 상기 인공 신경망 모델을 학습하는, 전자 장치.공개특허 10-2024-0069301-4-청구항 12 제9항에 있어서,상기 실제 영상은SEM 영상을 포함하는, 전자 장치."}
{"patent_id": "10-2022-0150687", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제12항에 있어서,상기 SEM 영상에 기초하여, 상기 제1 깊이 맵을 획득하는, 전자 장치."}
{"patent_id": "10-2022-0150687", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제12항에 있어서,상기 SEM 영상 및 TEM 영상에 기초하여, 상기 제1 깊이 맵을 획득하는, 전자 장치."}
{"patent_id": "10-2022-0150687", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "적어도 하나의 명령어를 저장하는 메모리; 및상기 메모리에 저장된 명령어를 실행함으로써,실제 영상을 인공 신경망 모델에 입력하여, 상기 실제 영상에 대응하는 깊이 맵을 획득하는 프로세서를 포함하고,인공 신경망 모델은상기 깊이 맵을 시뮬레이터에 입력하여 획득한 시뮬레이션 영상과 상기 깊이 맵에 기초하여 학습되는 전자장치."}
{"patent_id": "10-2022-0150687", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "깊이 정보 추정 방법이 개시된다. 일 실시예에 따른 깊이 정보 추정 방법은 제1 깊이 맵(depth map)을 시뮬레이 터(simulator)에 입력하여, 제1 시뮬레이션 영상을 획득하는 단계; 제1 깊이 맵과 제1 시뮬레이션 영상에 기초하 여, 인공 신경망 모델을 학습하는 단계; 실제 영상을 인공 신경망 모델에 입력하여, 제2 깊이 맵을 획득하는 단 계; 및 제2 깊이 맵을 시뮬레이터에 입력하여, 제2 시뮬레이션 영상을 획득하는 단계를 포함한다."}
{"patent_id": "10-2022-0150687", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "아래의 개시는 깊이 정보 추정 방법 및 장치에 관한 것으로, 구체적으로 영상 데이터를 추정하는 시뮬레이터를 활용하여, 역으로 영상 데이터로부터 깊이 정보를 추정하는 방법에 관한 것이다."}
{"patent_id": "10-2022-0150687", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "주사 전자 현미경(SEM: scanning electron microscope)은 집속된 전자빔을 샘플(sample)로 주사(scan)하고 샘 플로부터 방출되는 2차 전자들 또는 후방 산란 전자들에 관련된 전자 신호를 이용하여 샘플의 표면 상태를 관찰 하거나 시료의 성분을 분석하는 장치이다. 반도체 공정의 미세화에 따라, 기존 광학 설비를 통해 해석할 수 없는 영역이 점차 증가하게 되었고, 이에 따라, 주사 전자 현미경의 활용 영역이 증가하고 있다. 반도체 미세 공정 시에, 주사 전자 현미경을 이용하여, 샘플의 표면 상태, 즉 2차원적 평면 이미지를 획득할 수 있다. 샘플의 2차원적 이미지만으로 반도체 장치를 포 함하는 샘플의 구조를 해석하기에는 충분하지 않으며, 샘플의 3차원적인 이미지의 추출이 요구되고 있다."}
{"patent_id": "10-2022-0150687", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 2, "content": "발명의 내용"}
{"patent_id": "10-2022-0150687", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "일 실시예에 따른 깊이 정보 추정 방법은 제1 깊이 맵(depth map)을 시뮬레이터(simulator)에 입력하여, 제1 시 뮬레이션 영상을 획득하는 단계; 상기 제1 깊이 맵과 상기 제1 시뮬레이션 영상에 기초하여, 인공 신경망 모델 을 학습하는 단계; 실제 영상을 상기 인공 신경망 모델에 입력하여, 제2 깊이 맵을 획득하는 단계; 및 상기 제2 깊이 맵을 상기 시뮬레이터에 입력하여, 제2 시뮬레이션 영상을 획득하는 단계를 포함한다. 일 실시예에 따른 깊이 정보 추정 방법은 상기 제2 깊이 맵과 상기 제2 시뮬레이션 영상에 기초하여, 상기 인공 신경망 모델을 학습하는 단계를 더 포함할 수 있다. 일 실시예에 따른 깊이 정보 추정 방법은 상기 제2 깊이 맵으로부터 랜덤 노이즈 부가, 이미지 회전, 스케일 조 정, 이미지 이동, 랜덤 크롭, 및 색상 왜곡 중 하나 또는 둘 이상의 조합을 포함하는 데이터 증강(data augmentation)에 기초하여 복수의 변형 깊이 맵들을 생성하는 단계; 및 일 실시예에 따른 깊이 정보 추정 방법 은 상기 복수의 변형 깊이 맵들 및 상기 제2 시뮬레이션 영상에 기초하여, 상기 인공 신경망 모델을 학습하는 단계를 더 포함할 수 있다. 상기 실제 영상은 SEM 영상을 포함할 수 있다. 일 실시예에 따른 깊이 정보 추정 방법은 상기 SEM 영상에 기초하여, 상기 제1 깊이 맵을 획득하는 단계를 더 포함할 수 있다. 일 실시예에 따른 깊이 정보 추정 방법은 상기 SEM 영상 및 TEM 영상상에 기초하여, 상기 제1 깊이 맵을 획득하 는 단계를 더 포함할 수 있다. 일 실시예에 따른 깊이 정보 추정 방법은 실제 영상을 인공 신경망 모델에 입력하여, 상기 실제 영상에 대응하 는 깊이 맵을 획득하는 단계를 포함하고, 상기 인공 신경망 모델은 상기 깊이 맵을 시뮬레이터에 입력하여 획득 한 시뮬레이션 영상과 상기 깊이 맵에 기초하여 학습될 수 있다. 일 실시예에 따른 전자 장치는 적어도 하나의 명령어를 저장하는 메모리; 및 상기 메모리에 저장된 명령어를 실 행함으로써, 지도 정보, 출발 정보 및 도착 정보 중 적어도 하나를 포함하는 초기 제1 깊이 맵(depth map)을 시 뮬레이터(simulator)에 입력하여, 제1 시뮬레이션 영상을 획득하고, 상기 제1 깊이 맵과 상기 제1 시뮬레이션 영상에 기초하여, 인공 신경망 모델을 학습하고, 실제 영상을 상기 인공 신경망 모델에 입력하여, 제2 깊이 맵 을 획득하고, 상기 제2 깊이 맵을 상기 시뮬레이터에 입력하여, 제2 시뮬레이션 영상을 획득할 수 있다. 상기 프로세서는 상기 제2 깊이 맵과 상기 제2 시뮬레이션 영상에 기초하여, 상기 인공 신경망 모델을 학습할 수 있다. 상기 프로세서는 상기 제2 깊이 맵으로부터 랜덤 노이즈 부가, 이미지 회전, 스케일 조정, 이미지 이동, 랜덤 크롭, 및 색상 왜곡 중 하나 또는 둘 이상의 조합을 포함하는 데이터 증강(data augmentation)에 기초하여 복수 의 변형 깊이 맵들을 생성하고, 상기 복수의 변형 깊이 맵들 및 상기 제2 시뮬레이션 영상에 기초하여, 상기 인 공 신경망 모델을 학습할 수 있다. 상기 실제 영상은 SEM 영상을 포함할 수 있다. 일 실시예에 따른 전자 장치는 상기 SEM 영상에 기초하여, 상기 제1 깊이 맵을 획득할 수 있다. 일 실시예에 따른 전자 장치는 상기 SEM 영상 및 TEM 영상상에 기초하여, 상기 제1 깊이 맵을 획득할 수 있다. 일 실시예에 따른 전자 장치는 적어도 하나의 명령어를 저장하는 메모리; 및 상기 메모리에 저장된 명령어를 실 행함으로써, 실제 영상을 인공 신경망 모델에 입력하여, 상기 실제 영상에 대응하는 깊이 맵을 획득하는 프로세 서를 포함하고, 인공 신경망 모델은 상기 깊이 맵을 시뮬레이터에 입력하여 획득한 시뮬레이션 영상과 상기 깊 이 맵에 기초하여 학습될 수 있다."}
{"patent_id": "10-2022-0150687", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 명세서에서 개시되어 있는 특정한 구조적 또는 기능적 설명들은 단지 기술적 개념에 따른 실시예들을 설명하 기 위한 목적으로 예시된 것으로서, 실제로 구현된 형태는 다양한 다른 모습을 가질 수 있으며 본 명세서에 설 명된 실시예로만 한정되지 않는다. 제1 또는 제2 등의 용어는 다양한 구성요소들을 설명하는데 사용될 수 있지만, 이런 용어들은 하나의 구성요소 를 다른 구성요소로부터 구별하는 목적으로만 이해되어야 한다. 예를 들어 제1 구성요소는 제2 구성요소로 명명 될 수 있고, 유사하게 제2 구성요소는 제1 구성요소로도 명명될 수 있다. 어떤 구성요소가 다른 구성요소에 \"연결되어\" 있다거나 \"접속되어\" 있다고 언급된 때에는, 그 다른 구성요소에 직접적으로 연결되어 있거나 또는 접속되어 있을 수도 있지만, 중간에 다른 구성요소가 존재할 수도 있다고 이 해되어야 할 것이다. 반면에, 어떤 구성요소가 다른 구성요소에 \"직접 연결되어\" 있다거나 \"직접 접속되어\" 있 다고 언급된 때에는, 중간에 다른 구성요소가 존재하지 않는 것으로 이해되어야 할 것이다. 구성요소들 간의 관계를 설명하는 표현들, 예를 들어 \"~간의\"와 \"바로~간의\" 또는 \"~에 이웃하는\"과 \"~에 직접 이웃하는\" 등도 마찬가지로 해석되어야 한다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 명세서에서, \"포함하다\" 또는 \"가지다\" 등의 용어는 실시된 특징, 숫자, 단계, 동작, 구성요소, 부분품 또는 이들을 조합한 것이 존재함 을 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성요소, 부분품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되어야 한다. 다르게 정의되지 않는 한, 기술적이거나 과학적인 용어를 포함해서 여기서 사용되는 모든 용어들은 해당 기술 분야에서 통상의 지식을 가진 자에 의해 일반적으로 이해되는 것과 동일한 의미를 가진다. 일반적으로 사용되 는 사전에 정의되어 있는 것과 같은 용어들은 관련 기술의 문맥상 가지는 의미와 일치하는 의미를 갖는 것으로 해석되어야 하며, 본 명세서에서 명백하게 정의하지 않는 한, 이상적이거나 과도하게 형식적인 의미로 해석되지 않는다. 실시예들은 퍼스널 컴퓨터, 랩톱 컴퓨터, 태블릿 컴퓨터, 스마트 폰, 텔레비전, 스마트 가전 기기, 지능형 자동 차, 키오스크, 웨어러블 장치 등 다양한 형태의 제품으로 구현될 수 있다. 이하, 실시예들을 첨부된 도면을 참 조하여 상세하게 설명한다. 각 도면에 제시된 동일한 참조 부호는 동일한 부재를 나타낸다. 도 1은 인공 신경망(Artificial Neural Network)를 이용한 딥러닝 연산 방법을 설명하기 위한 도면이다. 딥러닝(Deep Learning) 등을 포함하는 인공지능(AI) 알고리즘은 인공 신경망(Artificial Neural Network, ANN) 모델에 입력 데이터를 입력시키고, 컨볼루션 등의 연산을 통해 출력 데이터를 학습하는 것을 특징으로 한다. 인공 신경망 모델은 생물학적 뇌를 모델링한 컴퓨터 과학적 아키텍쳐(Computational Architecture)를 의미할 수 있다. 인공 신경망 모델 내에서, 뇌의 뉴런들에 해당되는 노드들은 서로 연결되어 있고, 입력 데이터를 처리하 기 위하여 집합적으로 동작한다. 다양한 종류의 뉴럴 네트워크들을 예로 들면, 컨볼루션 뉴럴 네트워크 (Convolutional Neural Network, CNN), 회귀 뉴럴 네트워크(Recurrent Neural Network, RNN), 딥 빌리프 네트 워크(Deep Belief Network, DBN), 제한된 볼츠만 기계(Restricted Boltzman Machine, RBM) 방식 등이 있으나, 이에 제한되지 않는다. 피드-포워드(feed-forward) 뉴럴 네트워크에서, 뉴럴 네트워크의 뉴런들은 다른 뉴런들 과의 연결들(links)을 갖는다. 이와 같은 연결들은 뉴럴 네트워크를 통해, 한 방향으로, 예를 들어 순방향 (forward direction)으로 확장될 수 있다. 도 1을 참조하면, 인공 신경망 모델에 입력 데이터가 입력되고, 하나 이상의 레이어(layer)를 포함하는 인공 신 경망 모델(예를 들어, 컨볼루션 뉴럴 네트워크(Convolution Neural Network, CNN))를 통해 출력 데이터가 출력 되는 구조가 도시된다. 인공 신경망 모델은 2개 이상의 레이어를 보유한 딥 뉴럴 네트워크(deep neural network)일 수 있다. 인공 신경망 모델은 입력 데이터로부터 테두리, 선 색 등과 같은 \"특징들(features)\"을 추출하기 위해 이용될 수 있다. 인공 신경망 모델은 복수의 레이어를 포함할 수 있다. 각각의 레이어는 데이터를 수신할 수 있고, 해당 레이어에 입력되는 데이터를 처리하여 해당 레이어에서 출력되는 데이터를 생성할 수 있다. 레이어에서 출력되는 데이터는, 인공 신경망 모델에 입력된 이미지 또는 입력된 특징맵(feature map)을 하나 이상의 필터 (filter)의 웨이트(weight) 값과 컨볼루션 연산하여 생성한 특징맵일 수 있다. 인공 신경망 모델의 초기 레이 어들은 입력으로부터 에지들 또는 그레디언트들과 같은 낮은 레벨의 특징들을 추출하도록 동작될 수 있다. 인 공 신경망 모델의 다음 레이어들은 이미지 내의 눈, 코 등과 같은 점진적으로 더 복잡한 특징들을 추출할 수 있 다. 도 2는 일 실시예에 따른 깊이 정보를 추정하는 시스템을 설명하기 위한 도면이다. 도 2를 참조하면, 일 실시예에 따른 깊이 정보 추정 시스템은 영상을 수신하여, 영상에 대응하 는 깊이 정보(depth information)를 추정할 수 있다. 깊이 정보는 깊이 맵(depth map) 형태로 표현 될 수 있다. 깊이 맵은 영상에 존재하는 픽셀들의 상대적인 거리를 미리 정해진 형식(예를 들어, 그레이 스케일(gray scale))으로 구분하여 나타낸 영상일 수 있다. 예를 들어, 깊이 맵은 거리가 가까운 부분은 밝은 픽셀로, 거리가 먼 부분은 어두운 픽셀로 영상의 깊이 정보를 표현할 수 있다. 아래에서, 깊이 정보 추정 시스템은 반도체 시료의 깊이 계측을 위한 시스템일 수 있다. 웨이퍼의 수율 최적화를 위한 공정 제조 제어에 있어서 반도체 시료의 정확한 깊이 계측이 필수적일 수 있다. 반도체 시료의 깊이 계측을 위한 시스템에서, 영상으로 주사 전자 현미경을 통해 획득된 영상(이하, SEM 영상으로 지칭), 투과 전자 현미경(TEM: Transmision Electron Microscope)을 통해 획득된 영상(이하, TEM 영 상으로 지칭), 주사 탐침 현미경을 통해 획득된 영상(AFM: Atomic Force Microscope)(이하, AFM 영상으로 지칭) 등을 사용할 수 있다. 예를 들어, 반도체 시료의 깊이 계측을 위한 시스템은 SEM 영상, TEM 영상, 및/또 는 AFM 영상을 수신하여 반도체 시료의 깊이 정보를 추정할 수 있다. SEM 영상에 기초하여 깊이 정보를 추정하는 것은 비용이 저렴하고 빠르게 수행할 수 있다는 장점이 있지만, 정 확도가 낮을 수 있다. TEM 영상에 기초하여 깊이 정보를 추정하는 것은 정확도가 높지만 웨이퍼 절단이 필요하 기 때문에 비용이 높아 대량으로 데이터를 취득하기 어려울 수 있다. AFM 영상에 기초하여 깊이 정보를 추정하 는 것은 일부 로컬 영역에서는 높은 정확도를 갖지만, 해당 영역 이외의 영역에서는 낮은 정확도를 갖을 수 있 다. 깊이 정보 추정 시스템은 영상을 수신하여, 영상에 대응하는 깊이 정보를 추정하는 인공 신경망 모델을 포함할 수 있다. 일반적으로, 인공 신경망 모델은 입력 학습 데이터와, 입력 학습 데이터에 대 응하는 정답 데이터 쌍(pair)에 기초하여 학습될 수 있다. 그러나, 경우에 따라 입력 학습 데이터에 대응하는 정답 데이터를 확보하기 어려울 수 있다. 예를 들어, 반도체 시료의 깊이 계측을 위한 시스템의 경우 SEM 영상에 대응하는 깊이 맵을 인공 신경망 모델을 학습하기에 충분할 정도로 확보하기 어려울 수 있다. 아래에서 상세히 설명하겠지만, 일 실시예에 따른 깊이 정보 추정 방법은 인공 신경망 모델의 학습을 위한 깊이 정보를 충분하게 확보하기 어려운 상황에서도 깊이 정보를 수신하여 영상을 추정하는 시뮬레이 터의 출력을 인공 신경망 모델에 입력하고, 다시 인공 신경망 모델의 출력을 시뮬레이터에 입력하는 방법을 통 해 신뢰도 높은 깊이 정보를 추정할 수 있다. 도 3은 일 실시예에 따른 깊이 정보 추정 방법을 설명하기 위한 도면이다. 도 2를 참조하여 설명한 내용은 도 3에 동일하게 적용될 수 있고, 중복되는 내용은 생략될 수 있다. 예를 들어, 도 2를 참조하여 설명한 깊이 정보 추정 시스템은 도 3의 깊이 정보 추정 시스템에 동일하게 적용될 수 있다. 도 3을 참조하면, 일 실시예에 따른 깊이 정보 추정 시스템(예: 도 2의 깊이 정보 추정 시스템)은 시 뮬레이터 및 인공 신경망 모델을 포함할 수 있다. 그러나 도시된 구성요소 모두가 필수구성요소인 것은 아니다. 설계에 따라, 도 3에 도시된 구성 중 일부가 생략되거나 새로운 구성이 더 추가될 수 있음을 본실시 예와 관련된 기술 분야에서 통상의 지식을 가진 자라면 이해할 수 있다. 아래에서 설명의 편의를 위해 깊이 정보 추정 시스템은 반도체 시료의 깊이 계측을 위한 시스템인 것을 기 준으로 설명하나, 반드시 이로 한정하는 것은 아니다. 시뮬레이터는 깊이 맵을 수신하여 깊이 맵에 대응하는 영상(예를 들어, SEM 영상)을 추정하는 모듈일 수 있다. 용어 \"모듈\"은, 예를 들면, 하드웨어, 소프트웨어 또는 펌웨어(firmware) 중 하나 또는 둘 이상의 조합 을 포함하는 단위(unit)를 의미할 수 있다. \"모듈\"은 기계적으로 또는 전자적으로 구현될 수 있다. 예를 들면,\"모듈\"은, 알려졌거나 앞으로 개발될, 어떤 동작들을 수행하는 ASIC(application-specific integrated circuit) 칩, FPGAs(field-programmable gate arrays) 또는 프로그램 가능 논리 장치(programmable-logic device) 중 적어도 하나를 포함할 수 있다. 깊이 정보 추정 시스템은 시뮬레이터로 Nebula 시뮬레이 터를 사용할 수 있으나, 이에 한정되지는 않는다. 시뮬레이터에 입력하기 위한 깊이 맵이 준비되지 않을 수 있기 때문에, 깊이 정보 추정 시스템은 초 기 깊이 맵을 생성할 수 있다. 초기 깊이 맵을 생성하는 구체적인 방법은 아래에서 도 4를 참조하여 설명된다. 도 4는 일 실시예에 따른 초기 깊이 맵을 생성하는 방법을 설명하기 위한 도면이다. 도 3을 참조하여 설명한 내용은 도 4에 동일하게 적용될 수 있고, 중복되는 내용은 생략될 수 있다. 초기 깊이 맵은 시뮬레이터에 입력하기 위한 별도의 깊이 맵이 준비되지 않았을 때 사용되는 깊이 맵 일 수 있다. 초기 깊이 맵은 인공 신경망 모델에 의해 생성된 깊이 맵보다 깊이 정보의 정확도가 떨어질 수 있지만, 시뮬레이터에 입력될 수 있을 정도의 깊이 정보(예를 들어, 대략적인 모양(shape) 정보)를 갖 는 깊이 맵일 수 있다. 초기 깊이 맵은 SEM 영상 및/또는 TEM 영상에 기초하여 생성될 수 있으 나, 이에 한정되지는 않는다. 다시 도 3을 참조하면, 시뮬레이터는 초기 깊이 맵을 수신하여, 초기 깊이 맵에 대응되는 시뮬 레이션 영상(예를 들어, 시뮬레이션 SEM 영상을 추정할 수 있다. 설명의 편의를 위하여 시뮬레이터 는 깊이 맵을 수신하여 시뮬레이션 SEM 영상을 추정하는 것으로 기술되나, 이에 한정되는 것은 아니다. 시뮬레 이션 SEM 영상은 simulated SEM으로 지칭될 수 있다. 시뮬레이터는 복수의 초기 깊이 맵들을 이용하 여 복수의 시뮬레이션 SEM 영상들을 생성할 수도 있다. 초기 깊이 맵과 초기 깊이 맵(들)에 대응하는 시뮬레이션 SEM 영상(들)을 획득한 깊이 정보 추 정 시스템은 초기 깊이 맵과 시뮬레이션 SEM 영상 쌍에 기초하여 인공 신경망 모델을 학습 할 수 있다. 깊이 정보 추정 시스템은 시뮬레이션 SEM 영상을 인공 신경망 모델에 피드 포워드(feed- forward)하여 획득한 결과 데이터와 초기 깊이 맵 사이의 차이가 최소가 되도록 인공 신경망 모델을 학습할 수 있다. 인공 신경망 모델은 영상을 수신하여 영상에 대응하는 깊이 맵을 추정하도록 학습되는 점에서 역 시뮬레이터(inverse simulator)로 지칭될 수도 있다. 초기 깊이 맵과 시뮬레이션 SEM 영상에 기초하여 인공 신경망 모델을 학습 후, 깊이 정보 추정 시스템은 인공 신경망 모델에 실제 SEM 영상을 입력하여 실제 SEM 영상에 대응하는 깊이 맵을 획득할 수 있다. 실제 SEM 영상은 시뮬레이터를 통해 획득된 SEM 영상이 아닌, 주사 전자 현미 경을 통해 획득된 영상을 의미할 수 있다. 인공 신경망 모델을 통해 획득된 깊이 맵은 의사 깊이 맵 (Pseudo depth map)으로 지칭될 수 있다. 깊이 맵을 시뮬레이터에 입력하여 시뮬레이션 SEM 영상을 획득하고, 깊이 맵과 시뮬레이션 SEM 영상에 기 초하여 인공 신경망 모델을 학습하고, 인공 신경망 모델에 실제 SEM 영상 또는 시뮬레이션 SEM 영상 을 입력하여 의사 깊이 맵을 생성하는 과정을 하나의 이터레이션(iteration)으로 정의할 수 있고, 이터레이션에 서 입력으로 사용되는 깊이 맵을 제1 깊이 맵, 의사 깊이 맵을 제2 깊이 맵으로 정의할 수 있다. 깊이 정보 추정 시스템은 이터레이션을 반복하여 인공 신경망 모델의 성능을 점차 향상시킬 수 있다. 예를 들어, 깊이 정보 추정 시스템은 두 번째 이터레이션에서, 깊이 맵을 다시 시뮬레이터에 입 력하여 깊이 맵에 대응하는 시뮬레이션 SEM 영상을 획득할 수 있고, 해당 시뮬레이션 SEM 영상과 깊이 맵 을 이용하여 인공 신경망 모델을 다시 학습할 수 있다. 두 번째 이터레이션에서 인공 신경망 모델 을 학습하는데 사용된 깊이 맵은 첫 번째 이터레이션에서 사용된 초기 깊이 맵 보다 정확도가높을 것이고, 따라서 이터레이션을 반복할수록 보다 정확도가 높은 데이터로 인공 신경망 모델이 학습되기 때문에 이터레이션을 반복하여 인공 신경망 모델의 성능이 향상될 수 있다. 깊이 정보 추정 시스템은 학습된 인공 신경망 모델을 이용하여 영상에 대응하는 깊이 맵을 획득할 수 있다. 예를 들어, 학습이 완료된 인공 신경망 모델은 실제 SEM 영상을 수신하여, 해당 영상에 대응하는 깊이 맵을 출력할 수 있다. 도 5는 일 실시예에 따른 데이터 증강 방법을 설명하기 위한 도면이다. 도 3을 참조하여 설명한 내용은 도 5에 동일하게 적용될 수 있고, 중복되는 내용은 생략될 수 있다. 도 5를 참조하면, 일 실시예에 따른 깊이 정보 추정 시스템(예: 도 3의 깊이 정보 추정 시스템)은 깊이 맵 (예: 도 3의 깊이 맵)에 데이터 증강(data augmentation)을 수행하여 복수의 변형 깊이맵들을 생성할 수 있다. 깊이 정보 추정 시스템은 인공 신경망 모델(예: 도 3의 인공 신경망 모델)을 통해 획득된 의사 깊이 맵에 으로부터 랜덤 노이즈 부가, 이미지 회전, 스케일 조정, 이미지 이동, 랜덤 크롭 또는 색상 왜곡과 같은 데이터 증강을 수행할 수 있고, 이를 통해 생성된 복수의 변형 깊이맵들을 이용하여 더욱 다양한 영상-깊이 맵 쌍 데이터를 획득할 수 있다. 깊이 정보 추정 시스템은 복수의 변형 깊이맵들을 시뮬레이터(예: 도 3의 시뮬레이터)에 입력하여 시 뮬레이션 SEM 영상을 획득하고, 변형 깊이 맵들과 시뮬레이션 SEM 영상에 기초하여 인공 신경망 모델을 학습할 수 있다. 도 6은 일 실시예에 따른 깊이 정보 스케일링 방법을 설명하기 위한 도면이다. 도 3을 참조하여 설명한 내용은 도 6에 동일하게 적용될 수 있고, 중복되는 내용은 생략될 수 있다. 도 6을 참조하면, 일 실시예에 따른 깊이 정보 추정 시스템은 제1 인공 신경망 모델 및 제2 인공 신경망 모델을 포함할 수 있다. 제1 인공 신경망 모델(예: 도 3의 인공 신경망 모델)은 제1 영상을 수신하여 제1 영상에 대응하는 제 1 깊이 맵을 추정할 수 있다. 제2 인공 신경망 모듈은 제1 인공 신경망 모델에 사용된 영상과 동일 대상을 다른 방식을 통해 획득된 제2 영상에 기초하여 제2 깊이 맵을 추정하는 인공 신경망 모델일 수 있다. 예를 들어, 제1 영상은 SEM 영상일 수 있고, 제2 영상은 AFM 영상일 수 있으나, 이에 한정되지는 않는다. 전술한 바와 같이 AFM 영상에 기초하여 깊이 정보를 추정할 경우 일부 로컬 영역에서는 높은 정확도를 갖을 수 있다. 깊이 정보 추정 시스템은 AFM 영상에 기초하여 추정된 제2 깊이 맵에서 정확도가 높은 영역을 검출하고, 해당 영역에서 제2 깊이 맵에 대응하는 제1 깊이 맵을 특정하여 제1 깊이 맵과 제2 깊이 맵의 차이가 작아지도 록 제1 인공 신경망 모델을 학습할 수 있다. 깊이 정보 추정 시스템은 SEM 영상 뿐만 아니라 AFM 영상을 추가로 활용하여 깊이 맵을 스케일링(예를 들어, 나 노미터 단위로 스케일링)하여 정확도를 향상시킬 수 있다. 도 7은 일 실시예에 따른 깊이 정보 추정 방법을 설명하기 위한 순서도이다. 도 3을 참조하여 설명한 내용은 도 7에 동일하게 적용될 수 있고, 중복되는 내용은 생략될 수 있다. 설명의 편 의를 위해, 단계들(710 내지 740)은 도 3에 도시된 깊이 정보 추정 시스템을 사용하여 수행되는 것으로 기술된 다. 그러나 이 단계들(710 내지 740)은 어떤 다른 적절한 전자 기기를 통해, 그리고 어떤 적절한 시스템 내에서 도 사용될 수 있을 것이다. 나아가, 도 7의 동작은 도시된 순서 및 방식으로 수행될 수 있지만, 도시된 실시예의 사상 및 범위를 벗어나지 않으면서 일부 동작의 순서가 변경되거나 일부 동작이 생략될 수 있다. 도 7에 도시된 다수의 동작은 병렬로 또는 동시에 수행될 수 있다. 도 7을 참조하면, 단계에서, 깊이 정보 추정 시스템은 제1 깊이 맵을 시뮬레이터에 입력하여, 제1 시뮬레 이션 영상을 획득할 수 있다. 제1 깊이 맵은 이터레이션에서 입력으로 사용되는 깊이 맵으로, 초기 깊이 맵을 포함할 수 있다. 단계에서, 깊이 정보 추정 시스템은 제1 깊이 맵과 제1 시뮬레이션 영상에 기초하여, 인공 신경망 모델을 학습할 수 있다. 단계에서, 깊이 정보 추정 시스템은 실제 영상을 인공 신경망 모델에 입력하여, 제2 깊이 맵을 획득할 수 있다. 단계에서, 깊이 정보 추정 시스템은 제2 깊이 맵을 시뮬레이터에 입력하여, 제2 시뮬레이션 영상을 획득할 수 있다. 나아가, 깊이 정보 추정 시스템은 제2 깊이 맵과 상기 제2 시뮬레이션 영상에 기초하여, 상기 인공 신경망 모델 을 학습할 수 있다. 도 8은 일 실시예에 따른 전자 장치의 구성을 도시하는 도면이다. 도 8을 참조하면, 일 실시예에 따른 전자 장치는 하나 이상의 프로세서, 메모리 및 센서 (들)를 포함할 수 있다. 도 1 내지 도 7을 참조하여 설명한 내용은 도 8에도 동일하게 적용될 수 있다. 깊이 정보 추정 시스템은 전자 장치를 포함할 수 있다. 일 실시예에 따른 메모리는 컴퓨터에서 읽을 수 있는 명령어들(instructions)을 저장할 수 있다. 메모리 에 저장된 명령어들이 프로세서에 의해 실행되면, 프로세서는 명령어들에 의해 정의되는 동작들 을 처리할 수 있다. 메모리는 예를 들어 RAM(random access memories), DRAM(dynamic random access memories), SRAM(static random access memories) 또는 이 기술 분야에서 알려진 다른 형태의 비휘발성 메모리 를 포함할 수 있다. 메모리는 기 학습된 인공 신경망 모델을 저장할 수 있다. 일 실시예에 따른 센서(들)는 주사 전자 현미경, 투과 전자 현미경, 주사 탐침 현미경을 포함할 수 있으나, 기재된 예들로 제한되는 것은 아니다. 각 센서들의 기능은 그 명칭으로부터 당업자가 직관적으로 추론 할 수 있으므로, 구체적인 설명은 생략하기로 한다. 일 실시예에 따른 하나 이상의 프로세서는 전자 장치의 전체적인 동작을 제어한다. 프로세서는 목적하는 동작들(desired operations)을 실행시키기 위한 물리적인 구조를 갖는 회로를 가지는 하드웨어로 구현 된 장치일 수 있다. 목적하는 동작들은 프로그램에 포함된 코드(code) 또는 명령어들을 포함할 수 있다. 하드 웨어로 구현된 장치는 마이크로프로세서(microprocessor), 중앙 처리 장치(Central Processing Unit; CPU), 그 래픽 처리 장치(Graphic Processing Unit; GPU), 프로세서 코어(processor core), 멀티-코어 프로세서(multi- core processor), 멀티프로세서(multiprocessor), ASIC(Application-Specific Integrated Circuit), FPGA(Field Programmable Gate Array), NPU(Neural Processing Unit) 등을 포함할 수 있다 일 실시예에 따른 프로세서는 제1 깊이 맵(depth map)을 시뮬레이터(simulator)에 입력하여, 제1 시뮬레이 션 영상을 획득하고, 제1 깊이 맵과 제1 시뮬레이션 영상에 기초하여, 인공 신경망 모델을 학습하고, 실제 영상 을 인공 신경망 모델에 입력하여, 제2 깊이 맵을 획득하고, 제2 깊이 맵을 시뮬레이터에 입력하여, 제2 시뮬레 이션 영상을 획득할 수 있다. 이상에서 설명된 실시예들은 하드웨어 구성요소, 소프트웨어 구성요소, 및/또는 하드웨어 구성요소 및 소프트웨 어 구성요소의 조합으로 구현될 수 있다. 예를 들어, 실시예들에서 설명된 장치, 방법 및 구성요소는, 예를 들 어, 프로세서, 콘트롤러, ALU(arithmetic logic unit), 디지털 신호 프로세서(digital signal processor), 마 이크로컴퓨터, FPGA(field programmable gate array), PLU(programmable logic unit), 마이크로프로세서, 또는 명령(instruction)을 실행하고 응답할 수 있는 다른 어떠한 장치와 같이, 범용 컴퓨터 또는 특수 목적 컴퓨터를 이용하여 구현될 수 있다. 처리 장치는 운영 체제(OS) 및 상기 운영 체제 상에서 수행되는 소프트웨어 애플리 케이션을 수행할 수 있다. 또한, 처리 장치는 소프트웨어의 실행에 응답하여, 데이터를 접근, 저장, 조작, 처 리 및 생성할 수도 있다. 이해의 편의를 위하여, 처리 장치는 하나가 사용되는 것으로 설명된 경우도 있지만,"}
{"patent_id": "10-2022-0150687", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "해당 기술분야에서 통상의 지식을 가진 자는, 처리 장치가 복수 개의 처리 요소(processing element) 및/또는 복수 유형의 처리 요소를 포함할 수 있음을 알 수 있다. 예를 들어, 처리 장치는 복수 개의 프로세서 또는 하 나의 프로세서 및 하나의 콘트롤러를 포함할 수 있다. 또한, 병렬 프로세서(parallel processor)와 같은, 다른 처리 구성(processing configuration)도 가능하다. 소프트웨어는 컴퓨터 프로그램(computer program), 코드(code), 명령(instruction), 또는 이들의 조합을 포함 할 수 있으며, 원하는 대로 동작하도록 처리 장치를 구성하거나 독립적으로 또는 결합적으로(collectively) 처 리 장치를 명령할 수 있다. 소프트웨어 및/또는 데이터는, 처리 장치에 의하여 해석되거나 처리 장치에 명령 또는 데이터를 제공하기 위하여, 어떤 유형의 기계, 구성요소(component), 물리적 장치, 가상 장치(virtualequipment), 컴퓨터 저장 매체 또는 장치, 또는 전송되는 신호 파(signal wave)에 영구적으로, 또는 일시적으로 구체화(embody)될 수 있다. 소프트웨어는 네트워크로 연결된 컴퓨터 시스템 상에 분산되어서, 분산된 방법으로 저장되거나 실행될 수도 있다. 소프트웨어 및 데이터는 컴퓨터 판독 가능 기록 매체에 저장될 수 있다. 실시예에 따른 방법은 다양한 컴퓨터 수단을 통하여 수행될 수 있는 프로그램 명령 형태로 구현되어 컴퓨터 판 독 가능 매체에 기록될 수 있다. 컴퓨터 판독 가능 매체는 프로그램 명령, 데이터 파일, 데이터 구조 등을 단독 으로 또는 조합하여 포함할 수 있다. 매체에 기록되는 프로그램 명령은 실시예를 위하여 특별히 설계되고 구성 된 것들이거나 컴퓨터 소프트웨어 당업자에게 공지되어 사용 가능한 것일 수도 있다. 컴퓨터 판독 가능 기록 매체의 예에는 하드 디스크, 플로피 디스크 및 자기 테이프와 같은 자기 매체(magnetic media), CD-ROM, DVD와 같은 광기록 매체(optical media), 플롭티컬 디스크(floptical disk)와 같은 자기-광 매체(magneto-optical media), 및 롬(ROM), 램(RAM), 플래시 메모리 등과 같은 프로그램 명령을 저장하고 수행하도록 특별히 구성된 하드웨어 장치가 포함된다. 프로그램 명령의 예에는 컴파일러에 의해 만들어지는 것과 같은 기계어 코드뿐만 아니라 인터프리터 등을 사용해서 컴퓨터에 의해서 실행될 수 있는 고급 언어 코드를 포함한다."}
{"patent_id": "10-2022-0150687", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "이상과 같이 실시예들이 비록 한정된 도면에 의해 설명되었으나, 해당 기술분야에서 통상의 지식을 가진 자라면 상기를 기초로 다양한 기술적 수정 및 변형을 적용할 수 있다. 예를 들어, 설명된 기술들이 설명된 방법과 다 른 순서로 수행되거나, 및/또는 설명된 시스템, 구조, 장치, 회로 등의 구성요소들이 설명된 방법과 다른 형태 로 결합 또는 조합되거나, 다른 구성요소 또는 균등물에 의하여 대치되거나 치환되더라도 적절한 결과가 달성될 수 있다. 그러므로, 다른 구현들, 다른 실시예들 및 특허청구범위와 균등한 것들도 후술하는 특허청구범위의 범위에 속한 다."}
{"patent_id": "10-2022-0150687", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 인공 신경망(Artificial Neural Network)를 이용한 딥러닝 연산 방법을 설명하기 위한 도면이다. 도 2는 일 실시예에 따른 깊이 정보를 추정하는 시스템을 설명하기 위한 도면이다. 도 3은 일 실시예에 따른 깊이 정보 추정 방법을 설명하기 위한 도면이다. 도 4는 일 실시예에 따른 초기 깊이 맵을 생성하는 방법을 설명하기 위한 도면이다. 도 5는 일 실시예에 따른 데이터 증강 방법을 설명하기 위한 도면이다. 도 6은 일 실시예에 따른 깊이 정보 스케일링 방법을 설명하기 위한 도면이다. 도 7은 일 실시예에 따른 깊이 정보 추정 방법을 설명하기 위한 순서도이다. 도 8은 일 실시예에 따른 전자 장치의 구성을 도시하는 도면이다."}
