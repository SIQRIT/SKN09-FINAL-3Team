{"patent_id": "10-2020-0055141", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2021-0014065", "출원번호": "10-2020-0055141", "발명의 명칭": "인공 지능 심층 학습 타겟 탐지 및 속도 퍼텐셜 필드 알고리즘 기반 장애물 회피 및 자율 주", "출원인": "군산대학교산학협력단", "발명자": "이덕진"}}
{"patent_id": "10-2020-0055141", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "주행 영상에서 객체의 인식 여부를 판단하는 제1단계;복수의 각도들에 대응하여 센싱되는 거리 값들 및 상기 각도들에 기초하여 제1 조향 파라미터를 결정하는 제2단계;상기 주행 영상에서 상기 객체가 인식된 위치에 따른 오류와 PID 제어의 비례 이득(proportional gain)에 기초하여 제2 조향 파라미터를 결정하는 제3단계; 및상기 객체의 인식 여부에 따라, 상기 제1 조향 파라미터 및 상기 제2 조향 파라미터 중 적어도 하나에 기초하여조향 파라미터를 결정하는 제4단계를 포함하는,자율 주행 방법."}
{"patent_id": "10-2020-0055141", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 제2단계는 상기 객체가 인식되지 않았다는 판단에 따라 상기 제1 조향 파라미터를 결정하는 단계이고,상기 제3단계는 상기 객체가 인식되었다는 판단에 따라 상기 제2 2 조향 파라미터를 결정하는 단계인,자율 주행 방법."}
{"patent_id": "10-2020-0055141", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 제4단계는상기 객체가 인식되었다는 판단에 따라, 상기 제1 조향 파라미터와 상기 제2 조향 파라미터 사이의 차이에 기초하여 상기 조향 파라미터를 결정하는 단계; 및상기 객체가 인식되지 않았다는 판단에 따라, 상기 제1 조향 파라미터에 기초하여 상기 조향 파라미터를 결정하는 단계를 포함하는,자율 주행 방법."}
{"patent_id": "10-2020-0055141", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,상기 제2단계는레이저 센서를 이용하여 상기 복수의 각도들에 대응하여 상기 거리 값들을 센싱하는 단계;상기 거리 값들과 상기 복수의 각도들의 코사인 값들에 기초하여 제1 축의 값들의 합을 계산하는 단계;상기 거리 값들과 상기 복수의 각도들의 사인 값들에 기초하여 제2 축의 값들의 합을 계산하는 단계; 및상기 제1 축의 값들의 합과 상기 제2 축의 값들의 합 사이의 비율에 기초하여 상기 제1 조향 파라미터를 계산하는 단계를 포함하는,공개특허 10-2021-0014065-3-자율 주행 방법."}
{"patent_id": "10-2020-0055141", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서,상기 제3단계는상기 주행 영상에서 상기 객체가 인식된 위치가 상기 주행 영상의 중심을 기준으로 왼쪽 영역 혹은 오른쪽 영역중 어느 영역에 있는지 확인하는 단계;상기 주행 영상에서 상기 객체가 인식된 위치가 속한 영역의 반대 영역에서 미리 설정된 지점과 상기 주행 영상의 중심 지점 사이의 차이에 기초하여 상기 오류를 계산하는 단계; 및상기 오류와 상기 비례 이득에 기초하여 상기 제2 조향 파라미터를 계산하는 단계를 포함하는,자율 주행 방법."}
{"patent_id": "10-2020-0055141", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서,속도 파라미터를 변경하지 않고 유지하는 단계를 더 포함하는,자율 주행 방법."}
{"patent_id": "10-2020-0055141", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에 있어서,상기 제3단계는상기 인식된 객체가 정지 사인에 해당하는지 판단하는 단계; 및상기 인식된 객체가 정지 사인에 해당한다는 판단에 따라, 상기 조향 파라미터와 속도 파라미터를 0으로 결정하는 단계를 포함하는,자율 주행 방법."}
{"patent_id": "10-2020-0055141", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "작업장 내 로봇의 현재 위치, 상기 로봇의 목표 위치 및 적어도 하나의 장애물의 위치에 기초하여 포텐셜 필드를 생성하는 단계;상기 포텐셜 필드에 기초하여, 상기 로봇의 이동 방향에 관한 제1 정보를 생성하는 단계;거리 센서의 센싱 정보에 기초하여 생성된 주변 장애물의 인식 정보에 따라, 상기 로봇의 이동 방향에 관한 제2정보를 생성하는 단계; 및상기 제1 정보 및 상기 제2 정보에 기초하여, 상기 로봇의 이동 방향을 포함하는 주행 경로를 결정하는 단계를 포함하는, 자율 주행 방법."}
{"patent_id": "10-2020-0055141", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서,상기 포텐셜 필드를 생성하는 단계는공개특허 10-2021-0014065-4-상기 로봇의 현재 위치 및 상기 로봇의 목표 위치에 기초하여 흡인 포텐셜 필드(attractive potential field)를생성하는 단계; 상기 적어도 하나의 장애물의 위치에 기초하여 반발 포텐셜 필드(repulsive potential field)를 생성하는 단계;및 상기 흡인 포텐셜 필드 및 상기 반발 포텐셜 필드를 혼합함으로써 상기 포텐셜 필드를 생성하는 단계를 포함하는, 자율 주행 방법."}
{"patent_id": "10-2020-0055141", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제8항에 있어서,상기 포텐셜 필드를 생성하는 단계는상기 로봇의 목표 위치를 음전하로 모델링하고, 상기 장애물을 양전하로 모델링하며, 상기 로봇을 양전하로 모델링 함으로써 상기 포텐셜 필드를 생성하는 단계를 포함하는, 자율 주행 방법."}
{"patent_id": "10-2020-0055141", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제8항에 있어서,상기 인식 정보는기 학습된 신경망을 이용하여 생성되며, 상기 거리 센서에 의하여 센싱된 영상 내 상기 주변 장애물을 포함하는영역을 지시하는 정보를 포함하는,자율 주행 방법."}
{"patent_id": "10-2020-0055141", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제8항에 있어서,상기 제1 정보 및 상기 제2 정보 각각은 상기 로봇이 상기 현재 위치에서 이동 가능한 방향 후보들의 점수들 중 적어도 일부를 포함하는,자율 주행 방법."}
{"patent_id": "10-2020-0055141", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제8항에 있어서,상기 제1 정보를 생성하는 단계는상기 로봇이 상기 현재 위치에서 이동 가능한 방향 후보들 중 상기 포텐셜 필드 상의 포텐셜 값이 낮은 후보일수록 더 큰 점수를 할당하는 단계를 포함하는,자율 주행 방법."}
{"patent_id": "10-2020-0055141", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제8항에 있어서,상기 제2 정보를 생성하는 단계는상기 로봇이 상기 현재 위치에서 이동 가능한 방향 후보들 중 상기 인식 정보에 대응하는 영역을 회피하는 후보공개특허 10-2021-0014065-5-일수록 더 큰 점수를 할당하는 단계를 포함하는, 자율 주행 방법."}
{"patent_id": "10-2020-0055141", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제8항에 있어서,상기 주행 경로를 결정하는 단계는상기 제1 정보를 위한 제1 가중치 및 상기 제2 정보를 위한 제2 가중치에 기초하여, 상기 제1 정보 및 상기 제2정보를 가중 합산함으로써, 상기 로봇의 이동 방향을 결정하는 단계를 포함하는,자율 주행 방법."}
{"patent_id": "10-2020-0055141", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제8항에 있어서,상기 주행 경로가 결정됨에 따라 상기 로봇을 상기 이동 방향으로 이동시키는 단계; 및상기 로봇이 상기 이동 방향으로 이동함에 따라, 상기 로봇의 현재 위치를 갱신하는 단계를 더 포함하는, 자율 주행 방법."}
{"patent_id": "10-2020-0055141", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제16항에 있어서, 상기 로봇의 현재 위치를 갱신하는 단계는상기 로봇이 상기 목표 위치에 도달할 때까지, 상기 제1 정보를 결정하는 단계, 상기 제2 정보를 결정하는 단계, 및 상기 주행 경로를 결정하는 단계를 반복적으로 수행함으로써 상기 로봇의 현재 위치를 갱신하는 단계를 포함하는, 자율 주행 방법."}
{"patent_id": "10-2020-0055141", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "하드웨어와 결합되어 제1항 내지 제17항 중 어느 하나의 항의 방법을 실행시키기 위하여 컴퓨터 판독 가능한 기록 매체에 저장된 컴퓨터 프로그램."}
{"patent_id": "10-2020-0055141", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "로봇의 주행 영상을 촬영하는 비전 센서;상기 로봇과 주변 객체와의 거리를 센싱하는 거리 센서; 및 상기 주행 영상에서 객체의 인식 여부를 판단하고, 복수의 각도들에 대응하여 센싱되는 거리 값들 및 상기 각도들에 기초하여 제1 조향 파라미터를 결정하며, 상기 주행 영상에서 상기 객체가 인식된 위치에 따른 오류와 PID제어의 비례 이득(proportional gain)에 기초하여 제2 조향 파라미터를 결정하고, 상기 객체의 인식 여부에 따라, 상기 제1 조향 파라미터 및 상기 제2 조향 파라미터 중 적어도 하나에 기초하여 조향 파라미터를 결정하는적어도 하나의 프로세서를 포함하는,자율 주행 장치.공개특허 10-2021-0014065-6-청구항 20 작업장 내 로봇의 현재 위치, 상기 로봇의 목표 위치 및 적어도 하나의 장애물의 위치를 포함하는 영상을 촬영하는 비전 센서;상기 로봇과 주변 장애물과의 거리를 감지하여 센싱 정보를 생성하는 거리 센서; 및 상기 영상에 기초하여 포텐셜 필드를 생성하고, 상기 포텐셜 필드에 기초하여 상기 로봇의 이동 방향에 관한 제1 정보를 생성하고, 상기 센싱 정보에 기초하여 생성된 주변 장애물의 인식 정보에 따라 상기 로봇의 이동 방향에 관한 제2 정보를 생성하며, 상기 제1 정보 및 상기 제2 정보에 기초하여, 상기 로봇의 이동 방향을 포함하는주행 경로를 결정하는 적어도 하나의 프로세서를 포함하는, 자율 주행 장치."}
{"patent_id": "10-2020-0055141", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "일 실시예에 따른 자율 주행 방법은 복수의 각도들에 대응하여 센싱되는 거리 값들 및 각도들에 기초하여 제1 조 향 파라미터를 결정하는 단계; 주행 영상에서 객체가 인식된 위치에 따른 오류와 PID 제어의 비례 이득 (proportional gain)에 기초하여 제2 조향 파라미터를 결정하는 단계; 및 제1 조향 파라미터 및 제2 조향 파라미 터 중 적어도 하나에 기초하여 조향 파라미터를 결정하는 단계를 포함한다."}
{"patent_id": "10-2020-0055141", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "아래 실시예들은 인공 지능 심층 학습 타겟 탐지 및 속도 퍼텐셜 필드 알고리즘 기반 장애물 회피 및 자율 주행 방법 및 장치에 관한 것이다."}
{"patent_id": "10-2020-0055141", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "자율 로봇 내비게이션(Autonomous robot navigation)은 일반적으로 환경 인식, 경로 계획 및 계획에 따라 도출 된 경로에 대한 로봇의 모션을 제어하는 과정을 통해 수행될 수 있다. 경로 계획은 장애물이 있는 환경에서 장 애물을 탐지하여 회피함으로써 장애물과의 충돌없이 최적 또는 최단 경로를 찾는 것이다. 장애물 탐지는 로봇 또는 차량 등과 같은 이동체의 주변(예를 들어, 전방)에 위치한 장애물을 탐지하는 것을 의미하고, 장애물 회피 는 탐지된 장애물을 피하여 이동하는 것을 의미한다."}
{"patent_id": "10-2020-0055141", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "일 실시예에 따르면, 카메라 영상에 기초한 포텐셜 필드와 라이다 센서의 센싱 정보에 기초한 장애물 인식 정보 를 융합함으로써 장애물을 회피하는 로봇의 주행 경로를 더욱 빠르고 정확하게 결정할 수 있다."}
{"patent_id": "10-2020-0055141", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "일 측에 따른 자율 주행 방법은 주행 영상에서 객체의 인식 여부를 판단하는 제1단계; 복수의 각도들에 대응하 여 센싱되는 거리 값들 및 상기 각도들에 기초하여 제1 조향 파라미터를 결정하는 제2단계; 상기 주행 영상에서 상기 객체가 인식된 위치에 따른 오류와 PID 제어의 비례 이득(proportional gain)에 기초하여 제2 조향 파라미 터를 결정하는 제3단계; 및 상기 객체의 인식 여부에 따라, 상기 제1 조향 파라미터 및 상기 제2 조향 파라미터 중 적어도 하나에 기초하여 조향 파라미터를 결정하는 제4단계를 포함한다. 상기 제2단계는 상기 객체가 인식되지 않았다는 판단에 따라 상기 제1 조향 파라미터를 결정하는 단계이고, 상 기 제3단계는 상기 객체가 인식되었다는 판단에 따라 상기 제2 2 조향 파라미터를 결정하는 단계일 수 있다. 상기 제4단계는 상기 객체가 인식되었다는 판단에 따라, 상기 제1 조향 파라미터와 상기 제2 조향 파라미터 사 이의 차이에 기초하여 상기 조향 파라미터를 결정하는 단계; 및 상기 객체가 인식되지 않았다는 판단에 따라, 상기 제1 조향 파라미터에 기초하여 상기 조향 파라미터를 결정하는 단계를 포함할 수 있다. 상기 제2단계는 레이저 센서를 이용하여 상기 복수의 각도들에 대응하여 상기 거리 값들을 센싱하는 단계; 상기 거리 값들과 상기 복수의 각도들의 코사인 값들에 기초하여 제1 축의 값들의 합을 계산하는 단계; 상기 거리 값 들과 상기 복수의 각도들의 사인 값들에 기초하여 제2 축의 값들의 합을 계산하는 단계; 및 상기 제1 축의 값들 의 합과 상기 제2 축의 값들의 합 사이의 비율에 기초하여 상기 제1 조향 파라미터를 계산하는 단계를 포함할수 있다. 상기 제3단계는 상기 주행 영상에서 상기 객체가 인식된 위치가 상기 주행 영상의 중심을 기준으로 왼쪽 영역 혹은 오른쪽 영역 중 어느 영역에 있는지 확인하는 단계; 상기 주행 영상에서 상기 객체가 인식된 위치가 속한 영역의 반대 영역에서 미리 설정된 지점과 상기 주행 영상의 중심 지점 사이의 차이에 기초하여 상기 오류를 계 산하는 단계; 및 상기 오류와 상기 비례 이득에 기초하여 상기 제2 조향 파라미터를 계산하는 단계를 포함할 수 있다. 상기 자율 주행 방법은 속도 파라미터를 변경하지 않고 유지하는 단계를 더 포함할 수 있다. 상기 제3단계는 상기 인식된 객체가 정지 사인에 해당하는지 판단하는 단계; 및 상기 인식된 객체가 정지 사인 에 해당한다는 판단에 따라, 상기 조향 파라미터와 속도 파라미터를 0으로 결정하는 단계를 포함할 수 있다. 일 측에 따른 자율 주행 방법은 작업장 내 로봇의 현재 위치, 상기 로봇의 목표 위치 및 적어도 하나의 장애물 의 위치에 기초하여 포텐셜 필드를 생성하는 단계; 상기 포텐셜 필드에 기초하여, 상기 로봇의 이동 방향에 관 한 제1 정보를 생성하는 단계; 거리 센서의 센싱 정보에 기초하여 생성된 주변 장애물의 인식 정보에 따라, 상 기 로봇의 이동 방향에 관한 제2 정보를 생성하는 단계; 및 상기 제1 정보 및 상기 제2 정보에 기초하여, 상기 로봇의 이동 방향을 포함하는 주행 경로를 결정하는 단계를 포함할 수 있다. 상기 포텐셜 필드를 생성하는 단계는 상기 로봇의 현재 위치 및 상기 로봇의 목표 위치에 기초하여 흡인 포텐셜 필드(attractive potential field)를 생성하는 단계; 상기 적어도 하나의 장애물의 위치에 기초하여 반발 포텐 셜 필드(repulsive potential field)를 생성하는 단계; 및 상기 흡인 포텐셜 필드 및 상기 반발 포텐셜 필드를 혼합함으로써 상기 포텐셜 필드를 생성하는 단계를 포함할 수 있다. 상기 포텐셜 필드를 생성하는 단계는 상기 로봇의 목표 위치를 음전하로 모델링하고, 상기 장애물을 양전하로 모델링하며, 상기 로봇을 양전하로 모델링 함으로써 상기 포텐셜 필드를 생성하는 단계를 포함할 수 있다. 상기 인식 정보는 기 학습된 신경망을 이용하여 생성되며, 상기 거리 센서에 의하여 센싱된 영상 내 상기 주변 장애물을 포함하는 영역을 지시하는 정보를 포함할 수 있다. 상기 제1 정보 및 상기 제2 정보 각각은 상기 로봇이 상기 현재 위치에서 이동 가능한 방향 후보들의 점수들 중 적어도 일부를 포함할 수 있다. 상기 제1 정보를 생성하는 단계는 상기 로봇이 상기 현재 위치에서 이동 가능한 방향 후보들 중 상기 포텐셜 필 드 상의 포텐셜 값이 낮은 후보일수록 더 큰 점수를 할당하는 단계를 포함할 수 있다. 상기 제2 정보를 생성하는 단계는 상기 로봇이 상기 현재 위치에서 이동 가능한 방향 후보들 중 상기 인식 정보 에 대응하는 영역을 회피하는 후보일수록 더 큰 점수를 할당하는 단계를 포함할 수 있다. 상기 주행 경로를 결정하는 단계는 상기 제1 정보를 위한 제1 가중치 및 상기 제2 정보를 위한 제2 가중치에 기 초하여, 상기 제1 정보 및 상기 제2 정보를 가중 합산함으로써, 상기 로봇의 이동 방향을 결정하는 단계를 포함 할 수 있다. 상기 자율 주행 방법은 상기 주행 경로가 결정됨에 따라 상기 로봇을 상기 이동 방향으로 이동시키는 단계; 및 상기 로봇이 상기 이동 방향으로 이동함에 따라, 상기 로봇의 현재 위치를 갱신하는 단계를 더 포함할 수 있다. 상기 로봇의 현재 위치를 갱신하는 단계는 상기 로봇이 상기 목표 위치에 도달할 때까지, 상기 제1 정보를 결정 하는 단계, 상기 제2 정보를 결정하는 단계, 및 상기 주행 경로를 결정하는 단계를 반복적으로 수행함으로써 상 기 로봇의 현재 위치를 갱신하는 단계를 포함할 수 있다. 일 측에 따른 자율 주행 장치는 로봇의 주행 영상을 촬영하는 비전 센서; 상기 로봇과 주변 객체와의 거리를 센 싱하는 거리 센서; 및 상기 주행 영상에서 객체의 인식 여부를 판단하고, 복수의 각도들에 대응하여 센싱되는 거리 값들 및 상기 각도들에 기초하여 제1 조향 파라미터를 결정하며, 상기 주행 영상에서 상기 객체가 인식된 위치에 따른 오류와 PID 제어의 비례 이득(proportional gain)에 기초하여 제2 조향 파라미터를 결정하고, 상기 객체의 인식 여부에 따라, 상기 제1 조향 파라미터 및 상기 제2 조향 파라미터 중 적어도 하나에 기초하여 조향 파라미터를 결정하는 적어도 하나의 프로세서를 포함한다. 일 측에 따른 자율 주행 장치는 작업장 내 로봇의 현재 위치, 상기 로봇의 목표 위치 및 적어도 하나의 장애물 의 위치를 포함하는 영상을 촬영하는 비전 센서; 상기 로봇과 주변 장애물과의 거리를 감지하여 센싱 정보를 생성하는 거리 센서; 및 상기 영상에 기초하여 포텐셜 필드를 생성하고, 상기 포텐셜 필드에 기초하여 상기 로봇 의 이동 방향에 관한 제1 정보를 생성하고, 상기 센싱 정보에 기초하여 생성된 주변 장애물의 인식 정보에 따라 상기 로봇의 이동 방향에 관한 제2 정보를 생성하며, 상기 제1 정보 및 상기 제2 정보에 기초하여, 상기 로봇의 이동 방향을 포함하는 주행 경로를 결정하는 적어도 하나의 프로세서를 포함한다."}
{"patent_id": "10-2020-0055141", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "일 측에 따르면, 카메라 영상에 기초한 포텐셜 필드와 라이다 센서의 센싱 정보에 기초한 장애물 인식 정보를 융합함으로써 장애물을 회피하는 로봇의 주행 경로를 더욱 빠르고 정확하게 결정할 수 있다."}
{"patent_id": "10-2020-0055141", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하에서, 첨부된 도면을 참조하여 실시예들을 상세하게 설명한다. 그러나, 실시예들에는 다양한 변경이 가해 질 수 있어서 특허출원의 권리 범위가 이러한 실시예들에 의해 제한되거나 한정되는 것은 아니다. 실시예들에 대한 모든 변경, 균등물 내지 대체물이 권리 범위에 포함되는 것으로 이해되어야 한다. 실시예에서 사용한 용어는 단지 설명을 목적으로 사용된 것으로, 한정하려는 의도로 해석되어서는 안된다. 단 수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 명세서에서, \"포함하다\" 또 는 \"가지다\" 등의 용어는 명세서 상에 기재된 특징, 숫자, 단계, 동작, 구성요소, 부품 또는 이들을 조합한 것 이 존재함을 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성요소, 부품 또는이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되어야 한다. 다르게 정의되지 않는 한, 기술적이거나 과학적인 용어를 포함해서 여기서 사용되는 모든 용어들은 실시예가 속 하는 기술 분야에서 통상의 지식을 가진 자에 의해 일반적으로 이해되는 것과 동일한 의미를 가지고 있다. 일 반적으로 사용되는 사전에 정의되어 있는 것과 같은 용어들은 관련 기술의 문맥 상 가지는 의미와 일치하는 의 미를 가지는 것으로 해석되어야 하며, 본 출원에서 명백하게 정의하지 않는 한, 이상적이거나 과도하게 형식적 인 의미로 해석되지 않는다. 또한, 첨부 도면을 참조하여 설명함에 있어, 도면 부호에 관계없이 동일한 구성 요소는 동일한 참조부호를 부여 하고 이에 대한 중복되는 설명은 생략하기로 한다. 실시예를 설명함에 있어서 관련된 공지 기술에 대한 구체적 인 설명이 실시예의 요지를 불필요하게 흐릴 수 있다고 판단되는 경우 그 상세한 설명을 생략한다. 도 1은 일 실시예에 따른 자율 주행 방법이 수행되는 주행 환경을 도시한 도면이다. 도 1을 참조하면, 일 실시 예에 따른 비전 센서를 이용하여 캡쳐된 작업장 환경이 도시된다. 주행 환경은 예를 들어, 실내일 수도 있고, 또는 실외일 수도 있다. 예를 들어, 주행 환경 내에 로봇 및 다양한 장애물들이 존재한다고 하자. 이때, 로봇은 예를 들어, 미끄러지지 않고 움직이며 바퀴가 변형되지 않는다고 가정한다. 로봇은 예를 들어, 자율차, 특장차, 무인 로봇 등 지상에서 자율로 움직이는 모든 로봇을 포괄하는 의미로 이해될 수 있다. 로봇의 위치는 예를 들어, 로봇의 휠 축 중심의 위치를 기준으로 주어질 수 있다. 로봇의 위치 는 예를 들어, 도 1에 도시된 것과 같은 (x, y) 형태로 주어질 수도 있고, 또는 (I, j)의 형태로 주어질 수도 있으며, 반드시 이에 한정되지 않는다. 로봇의 초기 위치는 시작 위치(start position)에 해당할 수 있다. 로봇의 시작 위치는 '시작 지점(start point)'으로 설정될 수 있다. 로봇이 도달하고자 하는 최종 목적지는 대상 위치(target position)일 수 있다. 대상 위치는 '목표 위치(goal position)' 또는 '목표 지점(target point)'으로 설정될 수 있다. 일 실시예에 따른 자율 주행 장치는 로봇의 시작 위치와 목표 위치 사이의 장애물들을 회피하면서 자 율 로봇이 대상 위치로 이동하기 위한 주행 경로를 결정할 수 있다. 자율 주행 장치는 로봇이 목표 위치, 다시 말해 대상 위치에 도달할 때까지 로봇의 현재 위치를 반복적으로 갱신하면서 주행 경로를 결정하고, 이에 따라 로봇이 이동 방향으로 이동하도록 할 수 있다. 도면에 도시하지 않았으나, 일 실시예에 따른 자율 주행 장치는 작업장의 내부 또는 외부에서 전체 환경을 관찰 하고, 특정한 순간에 비전 센서를 통해 작업 공간의 영상을 캡처할 수 있다. 자율 주행 장치는 필요한 경 우 로봇의 변위(displacement)에 대한 새로운 궤적(trajectory) 또는 경로(path)를 계획하고, 각 영상의 처리 후 제어 신호를 로봇으로 전송할 수 있다. 예를 들어, 환경의 모든 지점(point)은 시작 위치 및 대 상 위치와 관련한 포텐셜 값(potential value)을 가질 수 있다. 일 실시예에서는 포텐셜 필드 방법에 의해 주 행 경로를 결정할 수 있다. 포텐셜 필드 방법은 일단 목표 지점을 중심으로 가상의 포텐셜 필드(Potential field)를 생성할 수 있다. 포텐셜 필드에서 로봇은 하나의 지점으로 간주될 수 있다. 또한, 포텐셜 필드 방법에서 장애물은 가장 높은 포텐셜 값을 갖는 지점으로 간주되고, 목표 지점은 가장 낮은 포텐셜 값을 갖는 지점으로 간주될 수 있다. 포텐셜 필드에서는 예를 들어, 목표 지점을 중심으로 거리가 멀어질수록 포텐셜이 증가하고, 목표 지점을 중심으로 거리가 가까워질수록 포텐셜이 감소할 수 있다. 로봇은 이러한 포텐셜 필드에서 물이 위에서 아래로 흐르는 것처럼 자연스럽게, 포텐셜이 높은 지점에서 가장 낮은 지점으로 이동함으 로써 목표 지점에 도달할 수 있다. 포텐셜 필드에서 목표는 로봇을 끌어당기고, 장애물은 반발력을 생성하 여 로봇을 밀어낼 수 있다. 궤적 또는 경로 계획 시에, 자율 주행 장치는 작업장 내 한 지점 주변의 모든 주변 이웃 지점들(neighbor points)의 포텐셜 값에 대한 최소 검색(minimum search)을 수행하고, 최소값이 가장 작은 이웃 지점(neighbor point)을 로봇의 다음 위치(next location)로 선택할 수 있다. 전술한 과정은 로봇이 목표 지점에 도달할 때까지 반복될 수 있다. 도 2는 일 실시예에 따른 자율 주행 방법을 나타낸 흐름도이다. 도 2를 참조하면, 일 실시예에 따른 자율 주행 장치는 작업장 내 로봇의 현재 위치, 로봇의 목표 위치 및 적어도 하나의 장애물의 위치에 기초하여 포텐셜 필드를 생성한다. 자율 주행 장치는 예를 들어, 작업장 내, 외에 설치된 카메라 또는 자율 주행 로봇에 장 착된 카메라 센서로부터 작업장 내 로봇의 현재 위치, 로봇의 목표 위치 및 적어도 하나의 장애물의 위치를 포 함하는 영상을 획득하고, 영상을 기초로 포텐셜 필드를 생성할 수 있다. 이때, 영상은 예를 들어, M (column) × N (row)의 해상도를 갖는 이산 영상(discrete image)에 해당할 수 있다. 자율 주행 장치는 로봇의 목표 위 치를 음전하(negative charge)로 모델링하고, 장애물 및 로봇을 양전하(positive charge)으로 모델링 함으로써 포텐셜 필드를 생성할 수 있다. 자율 주행 장치가 포텐셜 필드를 생성하는 방법은 아래의 도 2를 참조하여 구 체적으로 설명한다. 자율 주행 장치는 단계에서 생성한 포텐셜 필드에 기초하여, 로봇의 이동 방향에 관한 제1 정보를 생성한 다. 자율 주행 장치는 예를 들어, 로봇이 현재 위치에서 이동 가능한 방향 후보들 중 포텐셜 필드 상의 포텐셜 값이 낮은 후보일수록 더 큰 점수를 할당하여 제1 정보를 생성할 수 있다. 자율 주행 장치가 제1 정보 를 생성하는 방법은 아래의 도 6을 참조하여 구체적으로 설명한다. 자율 주행 장치는 거리 센서의 센싱 정보에 기초하여 생성된 주변 장애물의 인식 정보에 따라, 로봇의 이동 방 향에 관한 제2 정보를 생성한다. 거리 센서는 예를 들어, 라이다 센서(Lidar sensor) 및 스테레오 카메라 (Stereo Camera) 등을 포함할 수 있다. 인식 정보는 컴퓨터 비전 영상 처리 또는 학습된 인공 신경망을 이용 하여 생성될 수 있다. 신경망은 예를 들어, 거리 센서의 센싱 정보가 입력되면, 주변 장애물을 인식하여 인식 정보를 출력하도록 학습된 신경망일 수 있다. 신경망은 예를 들어, 딥 러닝(deep learning)에 의해 학습될 수 있다. 인식 정보는 영상 내 주변 장애물을 포함하는 영역을 지시하는 정보를 포함할 수 있다. 신경망은 예를 들어, YOLO(You Only Look Once)일 수 있다. YOLO는 영상 내의 바운딩 박스(bounding box)와 클래스 확률 (class probability)을 단일 회귀 문제(single regression problem)로 간주하여, 영상을 한 번 보는 것으로 객 체의 종류와 위치를 추측할 수 있다. YOLO는 단일 컨볼루션 네트워크(single convolutional network)를 통해 다수 개의 바운딩 박스들에 대한 클래스 확률을 계산하여 영상에 포함된 객체의 종류와 위치를 추측할 수 있다. 일 실시예에서는 설명의 편의를 위하여 YOLO를 예로 들어 설명하였으나, 반드시 이에 한정되는 것은 아니며, YOLO외에도 사물 인식을 위한 다양한 신경망 기반의 인식 기법들이 활용될 수 있다. 제1 정보 및 제2 정보 각 각은 예를 들어, 로봇이 현재 위치에서 이동 가능한 방향 후보들의 점수들 중 적어도 일부를 포함할 수 있다. 자율 주행 장치는 주변 장애물의 인식 정보에 따라, 주변 장애물을 회피하는 로봇의 이동 방향에 관한 제2 정보 를 생성할 수 있다. 자율 주행 장치는 예를 들어, 로봇이 현재 위치에서 이동 가능한 방향 후보들 중 인식 정 보에 대응하는 영역을 회피하는 후보일수록 더 큰 점수를 할당하여 제2 정보를 생성할 수 있다. 자율 주행 장치는 단계에서 생성된 제1 정보 및 단계에서 생성된 제2 정보에 기초하여, 로봇의 이동 방향을 포함하는 주행 경로를 결정한다. 자율 주행 장치는 예를 들어, 제1 정보를 위한 제1 가중치 및 제 2 정보를 위한 제2 가중치에 기초하여, 제1 정보 및 제2 정보를 가중 합산함으로써, 로봇의 이동 방향을 결정할 수 있다. 이때, 제2 가중치는 제1 가중치보다 크게 설정될 수 있다. 일 실시예에서는 포텐셜 필드에 기초한 제1 정보보다 거리 센서의 센싱 정보에 기초한 제2 정보에 더 많은 가중치를 부여함으로써 거리 센서에 의해 이 동 방향을 보다 정확하게 결정할 수 있다. 자율 주행 장치는 주행 경로가 결정됨에 따라 로봇을 단계에서 결정된 이동 방향으로 이동시킬 수 있다. 자율 주행 장치는 로봇이 이동 방향으로 이동함에 따라, 로봇의 현재 위치를 갱신할 수 있다. 자율 주행 장치 는 로봇이 목표 위치에 도달할 때까지, 제1 정보를 결정하는 단계, 제2 정보를 결정하는 단계, 및 주 행 경로를 결정하는 단계를 반복적으로 수행함으로써 로봇의 현재 위치를 갱신할 수 있다. 도 3은 일 실시예에 따른 포텐셜 필드를 생성하는 방법을 나타낸 흐름도이다. 도 3을 참조하면, 일 실시예에 따른 자율 주행 장치는 로봇의 현재 위치 및 로봇의 목표 위치에 기초하여 흡인 포텐셜 필드(attractive potential field)를 생성할 수 있다. 일 실시예에 따른 자율 주행 장치는 예를 들어, 아래의 수학식 1과 같은 흡인 포텐셜 필드 함수 를 이용하여 흡인 포텐셜 필드를 생성할 수 있다. 수학식 1"}
{"patent_id": "10-2020-0055141", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "여기서, k는 양의 스케일링 팩터(scaling factor)이고, 는 영상에서 목표 지점과 로봇의 위치 사 이의 유클리드 거리(Euclidian distance)를 나타낼 수 있다. 수학식 1로부터, 흡인 포텐셜 필드는 시작 지점과 목표 지점만을 고려하고, 그 위의 장애물을 고려하지 않고 생 성될 수 있다. 일 실시예에 따라 생성되는 흡인 포텐셜 필드의 예시는 아래의 도 4를 참조할 수 있다. 예를 들어, 목표 지점을 라 하면, 시작 지점과 목표 지점 간의 는 아래의 수학식 2와 같은 거 리 함수(distance function)에 의해 구할 수 있다. 수학식 2"}
{"patent_id": "10-2020-0055141", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "수학식 2의 거리 함수는 임의의 지점에서 목표 지점까지의 거리를 결정하는 데에 사용될 수 있다. 포텐셜 필드에서는 두 점 사이의 거리 자체가 포텐셜이 될 수 있다. 예를 들어, 목표 지점에서 흡인 포텐셜 필 드 값은 최소가 될 수 있다. 흡인 포텐셜 필드 값은 목표 지점과의 거리에 비례하여 증가할 수 있다. 수학식 2의 거리 함수는 수학식 1을 사용하여 흡입 포텐셜 필드 함수를 도출하기 위해 추가로 사용될 수 있다. 자율 주행 장치는 적어도 하나의 장애물의 위치에 기초하여 반발 포텐셜 필드(repulsive potential field)를 생 성할 수 있다. 일 실시예에 따른 자율 주행 장치는 아래의 수학식 3과 같은 반발 포텐셜 필드 함수 를 이용하여 흡인 포텐셜 필드를 생성할 수 있다. 수학식 3"}
{"patent_id": "10-2020-0055141", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "여기서, 는 임의의 지점을 나타내고, 는 장애물 지점을 나타낼 수 있다. 수학식 3의 반발 포텐셜 필드 함수 는 예를 들어, 아래의 수학식 4 및 5에 의해 표현되는 작업 공간에 서 장애물(들)로부터의 반발력(repulsive force)을 나타낼 수 있다. 수학식 4 수학식 5"}
{"patent_id": "10-2020-0055141", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "반발 포텐셜 필드에 대해 수학식 4의 조건 1 및 수학식 5의 조건 2가 모두 충족되어야 한다. 여기서, n은 양의 정수를 나타내고, q는 장애물 위치 주변의 반지름을 나타낸다. 수학식 4의 조건 1로부터, 임의의 지점 이 장애물 지점 과 정확하게 유사한 경우, 반발 포텐셜 필드 값 이 최대가 된다는 것을 명확하게 파악할 수 있다. 수학식 5의 조건 2로부터, 임의의 지점 이 장애물 지점 을 갖는 반경 변수(radius variable) q의 범위 내에 있지 않은 경우, 반발 포텐셜 값은 임의의 지점 및 장애물 지점 의 역 거리 값(inverse distance value)의 두 배를 곱한 양의 정수 n이 될 수 있다. 자율 주행 장치는 흡인 포텐셜 필드 및 반발 포텐셜 필드를 혼합함으로써 포텐셜 필드를 생성할 수 있다. 일 실시예에 따른 자율 주행 장치는 흡인 포텐셜 필드 및 반발 포텐셜 필드를 혼합하여 아래의 수학식 6과 같이 혼합된 포텐셜 필드(Combined potential field)를 생성할 수 있다. 혼합 아래의 수학식 6과 같이 혼합된 포텐셜 필드 함수 를 생성할 수 있다. 수학식 6"}
{"patent_id": "10-2020-0055141", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "여기서, 이고, 일 수 있다. 일 실시예에 따라 포텐셜 필드 함수를 결합하는 방법은 아래의 알고리즘 1과 같이 나타낼 수 있다."}
{"patent_id": "10-2020-0055141", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 7, "content": "자율 주행 장치는 알고리즘 1과 같이 행 j에 대해, 영상의 최대 행 길이(maximum row length)까지 초기화를 반 복하고(j는 행 값(row value)임), 열 i에 대해, 영상의 최대 열 길이(maximum column length)까지 초기화를 반 복할 수 있다(i는 열 값(column value) 임). 이후, 자율 주행 장치는 이전의 흡인 필드 함수 와 반발 필드 함수 의 합에 의해 결합된 포텐셜 필드 함수 를 생성할 수 있다. 이후, 자율 주행 장치는 결합된 포텐셜 필드 함수 를 표시할 수 있다. 일실시예에 따라 생성되는 포텐셜 필드는 아래의 도 5를 참조할 수 있다. 도 4는 일 실시예에 따른 흡인 포텐셜 필드를 도시한 도면이다. 도 4를 참조하면, 일 실시예에 따라 생성된 흡 인 포텐셜 필드가 도시된다. 흡인 포텐셜 필드에서 x축과 y축은 포텐셜 필드의 크기를 나타낼 수 있다. 흡인 포텐셜 필드는 예를 들어, 시작 지점(35,18), 목표 지점(130,175), 및 스케일링 팩터 k=5를 갖는 흡인 포텐셜 필드를 나타낼 수 있 다. 도 5는 일 실시예에 따라 생성된 포텐셜 필드를 도시한 도면이다. 도 5를 참조하면, 전술한 알고리즘 1에 의해 결합된 포텐셜 필드가 도시된다. 포텐셜 필드는 예를 들어, 시작 지점(35,18) 및 목표 지점 (130,175)에 대하여 생성된 포텐셜 필드에 해당 할 수 있다. 자율 주행 장치는 포텐셜 필드를 기반으로 로봇의 시작 지점의 포텐셜 값과 주변 지점들의 포텐셜 값을 비 교함으로써 로봇이 목표 지점으로 안내되도록 할 수 있다. 예를 들어, 포텐셜 필드에서 목표 지점(130,175)은 가장 낮은 결합된 포텐셜 값 0을 가질 수 있다. 포텐 셜 필드에서 시작 지점(35,18)은 결합된 포텐셜 값 45.8762를 가질 수 있고, 목표 지점(130,175)에서 가장 먼 거리에 있는 코너 픽셀은 가장 높은 결합된 포텐셜 값 60.8153을 가질 수 있다. 포텐셜 필드에서 높은 포텐셜 값을 갖는 영역들은 장애물에 해당할 수 있다. 자율 주행 장치는 포텐 셜 필드에서 장애물에 해당하는 영역들을 회피하여 이동 가능한 방향 후보들에 높은 점수를 부여함으 로써 장애물과의 충돌 없이 목표 지점(130, 175)까지 도달 가능한 주행 경로를 결정할 수 있다. 도 6은 일 실시예에 따라 로봇의 이동 방향에 관한 제1 정보를 생성하는 방법을 설명하기 위한 도면이다. 도 6 을 참조하면, 로봇의 현재 위치에 해당하는 지점 (j,i) 주변의 이웃 지점들(N, S, E, W, NE, NW, SE, SW)을 나 타낸 도면이 도시된다. 자율 주행 장치는 먼저 로봇의 초기 위치를 결정한 다음, 로봇의 초기 위치와 주변 지점들의 포텐셜 필드 값을 비교하고, 최소 포텐셜 필드 값을 결정함으로써 로봇의 다음 이동 위치를 결정할 수 있다. 이는 도 6과 같이 그래픽적으로 설명될 수 있다. 예를 들어, 도 6에 도시된 지점 (j,i)가 로봇의 현재 위치를 나타낸다고 하자. 자율 주행 장치는 로봇의 현재 위치에 해당하는 지점 (j,i)을 중심으로 이동 가능한 방향 후보들에 해당하는 주 변의 인접 지점들(N, S, E, W, NE, NW, SE, SW)의 포텐셜 필드 값들을 산출할 수 있다. 자율 주행 장치는 포텐 셜 필드 값들에 따라 이동 가능한 방향 후보들에게 점수를 할당할 수 있다. 이때, 이동 가능한 방향 후보들은 지점(j,i) 주변의 이웃 지점들(N, S, E, W, NE, NW, SE, SW)에 해당할 수 있다. 자율 주행 장치는 주변 인접 지점들의 포텐셜 필드 값들 중 포텐셜 값이 가장 낮은 지점, 다시 말해 최소 포텐 셜 필드 값을 갖는 후보에게 더 큰 점수를 할당하는 방식으로 제1 정보를 생성할 수 있다. 자율 주행 장치는 최소 포텐셜 필드 값을 확인함으로써 목표 지점을 향한 로봇의 다음 이동 방향에 대한 제1 정보를 생성할 수 있 다. 이때, 최소 포텐셜 필드 값을 가진 지점이 다음 번 이동 위치를 찾을 때까지의 로봇의 현재 위치가 될 수 있다. 전술한 과정은 아래의 수학식 7의 최소 검색 함수(minimum search function)와 같이 간략하게 나타낼 수 있다. 수학식 7 수학식 7은 아래의 알고리즘 2과 같이 풀어서 표현할 수 있다."}
{"patent_id": "10-2020-0055141", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 8, "content": "일 실시예에 따른 자율 주행 장치는 알고리즘 2에 의해 로봇의 이동 방향에 관한 제1 정보를 생성할 수 있다. 도 7은 일 실시예에 따라 2차원 공간에 생성된 포텐셜 필드의 일 예시를 도시한 도면이다. 도 7을 참조하면, 일 실시예에 따른 포텐셜 필드 내에 포함된 장애물 및 목표 노드(goal node)가 도시된다. 포텐셜 필드은 라플라스 방정식(Laplace's equation)을 따르는 물리적 필드이다. 포텐셜 필드는 예를 들 어, 전기장(electrical field), 자기장(magnetic field) 및 중력장(gravitational fields)을 포함할 수 있다. 일 실시예에서는 특정 공간에서 로봇 등과 같은 자율 주행 장치를 조정하기 위해 가상의 인공 포텐셜 필드를 사 용할 수 있다. 자율 주행 장치는 특정 공간을 적어도 하나의 장애물 및 목표 노드(goal node)가 있는 셀들 (cells)의 그리드(grid)로 구분할 수 있다. 아래에서 보다 구체적으로 설명하겠지만, 자율 주행 장치는 포텐셜 필드 기능들을 사용하여 인공 포텐셜 필드를 2차원 공간의 모든 지점들에 할당할 수 있다. 자율 주행 장치는 포텐셜 필드에서 포텐셜이 가장 높은 지점부터 포텐셜이 가장 낮은 지점까지 시뮬레이션 할 수 있다. 포텐셜 필드에서 목표 노드가 최소 포텐셜을 가지는 것과 달리, 시작 노드는 최대 포텐 셜을 가질 수 있다. 이때, 포텐셜 필드에서 목표 위치는 음전하(negative charge)로 모델링되고, 장애물 및 자율 주행 장치는 양전하(positive charge)로 모델링될 수 있다. 따라서, 자율 주행 장치는 최대 포텐셜에 서 최소 포텐셜로 이동할 수 있다. 도 8은 일 실시예에 따른 자율 주행 장치를 도시한 도면이다. 도 8을 참조하면, 일 실시예에 따른 시뮬레이션 에 사용된 라이다(lidar)와 카메라를 포함하는 자율 주행 차량(예를 들어, Ackermann vehicle)이 도시된다. 일 실시예에서는 알려지지 않은 환경을 특정 인스턴스화(specific instantiation)하여 탐색하고, 맵핑할 수 있 다. 자율 주행 차량은 예를 들어, 해당 차량으로부터의 특정 위치와 함께 지피유-레이저 라이브러리(GPU- laser library)가 저장된 xarco 파일을 포함할 수 있다. xarco 파일에는 예를 들어, 620x480의 해상도를 가지 는 라이다(lidar)보다 낮은 해상도의 카메라 라이브러리(camera library)가 더 포함될 수 있다. 이러한 해상도 는 객체 회피 모듈 및 객체 추적 모듈로부터 적절한 오차 값을 얻기 위해 고정될 수 있다. 도 8에서 자율 주행 차량의 진행 방향이 동남쪽이라고 가정하면, 자율 주행 차량은 라이다(lidar)를 통해 예를 들어, 동남쪽 방향을 기준으로 좌우로 -3/4 π부터 +3/4 π까지 레이를 투사하여 로컬 포텐셜 필드를 생성 하는 한편, 카메라를 통해 동남쪽 방향의 영상을 촬영하여 장애물 탐색을 수행할 수 있다. 도 9는 일 실시예에 따른 3차원 공간에서 모델링되는 자율 주행 장치의 구조를 도시한 도면이다. 도 9를 참조 하면, 일 실시예에 따라 가제보 월드(Gazebo world)의 Building Editor를 이용하여 모델링되는 자율 주행 장치 의 구성 요소들이 도시된다. 일 실시예에서는 가제보 월드를 일 예시로 활용하여 설명하였으나, 반드시 이에 한정되는 것은 아니고, 이 밖에도 다양한 장치 구조가 활용될 수 있다. 일 실시예에 따른 자율 주행 장치 모델은 예를 들어, 복수의 센서들(Sensor), 몸체(Body), 연결부들(Joints), 및 동적 엔진(Dynamic engine) 등을 포함할 수 있다. 복수의 센서들은 예를 들어, 카메라(Camera), 레이저(Laser) 및 IMU(Inertial Measurement Unit), 등을 포함할 수 있다. 몸체는 예를 들어, 자율 주행 차량의 형태(Shape) 및 구조(Structure)를 포함할 수 있다. 연결부들은 예를 들어, 차축 캐리어(Axle carrier), 조향 조인트(Steering joint), 휠 쇼크(Wheel Shock), 및 조향 링크 (Steering Link) 등을 포함할 수 있다. 이때, 복수의 센서들에 의해 감지된 데이터는 자율 주행 장치 모델로 전달되고, 연결부들에 대한 명령(Comman d)은 예를 들어, 인터페이스부를 통한 사용자와의 통신을 통해 전달될 수 있다. 복수의 센서들에 의해 감지된 데이터는 예를 들어, 각 센서에서 자율 주행 장치 모델로 바로 전달될 수도 있고, 또는 엔코더(Encoder) 등을 통해 암호화되어 자율 주행 장치 모델로 전달될 수도 있다. 또한, 동적 엔진은 센서들 및 연결부들에 대한 제 어를 수행할 수 있다. 도 10은 일 실시예에 따라 레이저 광선들의 조합을 이용하여 생성되는 포텐셜 필드의 일 예시를 도시한 도면이 다. 일 실시예에 따른 자율 주행 장치가 포텐셜 필드 알고리즘을 이용하여 경로를 발견하는 방법은 다음과 같다. 자율 주행 장치는 2차원 레이저 센서로부터, 레이저 거리(laser distance)를 갖는 1081개의 광선들(rays)을 획 득할 수 있다. 이때, 광선들의 레이저 투사 라인은 예를 들어, -3/4 π라디안(radians)에서 3/4 π 라이안 범 위의 의 상대 각도들을 가질 수 있다. 해당 레이저 센서는 예를 들어, 와 같이 표 현할 수 있는 모든 거리의 벡터를 제공할 수 있다. 여기서, 거리는 레이저 센서로 광선들을 투사한 각도들에 따라 측정된 거리들에 해당할 수 있다. 이때, 벡터 의 각 값은 상대적인 투사 각도(relative projection angle) 를 가질 수 있으며, 아래의 수학 식 8과 같이 표현할 수 있다. 수학식 8 자율 주행 장치는 벡터 의 값들을 이용하여 예를 들어, 500 ×500 pixels의 의사 포텐셜 필드(pseudo potential field)에서 투사된 광선들( )의 꼬리(tail)에 대한 좌표(x, y)를 계산할 수 있다. 이때, 좌표의 x 값은 예를 들어, 아래의 수학식 9를 통해 구할 수 있다. 수학식 9"}
{"patent_id": "10-2020-0055141", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 9, "content": "여기서, 이고, 일 수 있다. 이 경우, 는 일 수 있다. 이때, 모든 x 좌표들의 합산(summation)은 자율 주행 장치를 안내하기 위한 포텐셜 경로의 X 좌표에 해당하며, 예를 들어, 아래의 수학식 10과 같이 나타낼 수 있다. 수학식 10"}
{"patent_id": "10-2020-0055141", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 10, "content": "마찬가지로, 좌표의 y 값은 예를 들어, 아래의 수학식 11을 통해 구할 수 있다. 수학식 11"}
{"patent_id": "10-2020-0055141", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 11, "content": "여기서, 이고, 일 수 있다. 이 경우, 는 일 수 있다. 이때, 모든 y 좌표들의 합산(summation)은 자율 주행 장치를 안내하기 위한 포텐셜 경로의 Y 좌표에 해당하며, 예를 들어, 아래의 수학식 12와 같이 나타낼 수 있다. 수학식 12"}
{"patent_id": "10-2020-0055141", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 12, "content": "자율 주행 장치는 전술한 합산을 통해 얻은 결과 좌표(X,Y)에서 해당 장치의 조향 각도(steering angle) 를 산출할 수 있다. 조향 각도 는 예를 들어, 아래의 수학식 13을 통해 산출할 수 있다. 수학식 13"}
{"patent_id": "10-2020-0055141", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 13, "content": "여기서, 조향 각도 는 레이저 맵(laser map)의 포텐셜 필드에서의 최종 결과 및 헤딩 각도(heading angle)를 나타낼 수 있다. 도 11은 일반적인 포텐셜 알고리즘에 의한 자율 주행 장치의 동작을 설명하기 위한 도면이다. 도 11을 참조하 면, 자율 주행 장치의 조향 조작에 따른 서로 다른 이동 방향들이 도시된다. 일 실시예에 따른 자율 주행 장치는 조향 조작을 통해 포텐셜이 높은 영역으로 이동할 수 있다. 예를 들어, 1110와 같이 전방에 아무런 장애물이 없다고 하자. 이 경우, 자율 주행 장치는 포텐셜이 낮은 영역 (low potential areas), 다시 말해 장애물이 없는 전방 영역으로 이동할 수 있다. 예를 들어, 1120과 같이 장애물이 전방 경로의 왼쪽에 위치하는 경우, 장애물이 존재하는 왼쪽 경로에는 포텐셜 이 높은 영역(high potential areas)이 생성될 수 있다. 따라서, 자율 주행 장치는 포텐셜이 낮은 영역, 다시 말해 오른쪽 영역으로 이동하도록 조향을 조작할 수 있다. 예를 들어, 1130과 같이 장애물이 전방 경로의 오른쪽에 위치하는 경우, 장애물이 존재하는 오른쪽 경로에 포텐 셜이 높은 영역이 생성될 수 있다. 따라서, 자율 주행 장치는 포텐셜이 낮은 영역, 다시 말해 왼쪽 영역으로 이동하도록 조향을 조작할 수 있다. 예를 들어, 1140과 같이 장애물이 전방 경로의 가운데에 위치하는 경우, 장애물이 존재하는 가운데에 포텐셜이 높은 영역이 생성될 수 있다. 하지만, 대칭적 포텐셜 필드로 인하여 자율 주행 장치는 왼쪽, 또는 오른쪽의 포 텐셜이 낮은 영역을 선택하는 대신에, 포텐셜이 높은 전방 영역으로 이동할 수 있다. 일 실시예에서는 포텐셜 알고리즘에 객체 감지 및 회피 기능을 통합함으로써 1140과 같은 포텐셜 알고리즘의 취 약점을 극복할 수 있다. 포텐셜 알고리즘에 객체 감지 및 회피 기능을 통합하는 방법은 아래의 도 12 내지 도 15를 참조하여 구체적으로 설명한다. 도 12는 일 실시예에 따른 비례 이득(proportional gain)에 대한 에러를 를 산출하는 방법을 설명하기 위한 도 면이다. 일 실시예에서는 충돌 회피를 위해 예를 들어, YOLOv2 알고리즘을 사용할 수 있다. YOLO는 높은 정확도의 실시 간 처리를 제공하지만 지역 기반 탐지 알고리즘들(region-based detector algorithms)에 비해 더 높은 지역화 오차(localization errors)와 낮은 리콜 응답(recall response)을 가질 수 있다. YOLOv2는 낮은 리콜 응답을 극복하고 빠른 탐지로 정확도를 높이는 업그레이드된 YOLO 버전이다. YOLOv2의 변 경 사항은 다음과 같다. YOLOv2에서는 신경망에서 경계 상자(boundary box)를 예측하는 완전 연결된 레이어들(fully connected layer s)이 제거될 수 있다. 하나의 풀링 레이어가 제거되어 네트워크의 공간 출력을 7×7 대신 13×13으로 만들 수 있다. 클래스 예측은 셀 레벨에서 경계 상자 레벨로 이동될 수 있다. 각 예측에는 경계 상자에 대한 네 개의 매개 변수들이 존재할 수 있다. 입력 영상의 크기는 448 × 448에서 416 × 416로 변경될 수 있다. 이에 따라, 예를 들어, 7×7 vs 8×8 격자 셀(grid cell)들과 같이 홀수 개수의 공간 차원들(spatial dimensions)이 생성될 수 있다. 예를 들어, 도 12에 도시된 것과 같이 공간의 중앙은 종종 큰 객체에 의해 점유될 수 있다. 이 경우, 홀수 개 수의 격자 셀들을 사용하면, 해당 객체가 속한 위치를 더 정확하게 파악할 수 있다. 일 실시예에서 신경망의 마지막 컨볼루션 레이어(convolution layer)를 3개의 3 × 3의 컨볼루션 레이어들 (convolutional layers)로 대체할 수 있으며, 각각의 레이어들은 1024개의 출력 채널들을 출력하여 예를 들어, 7 × 7 × 125의 크기(dimensions)로 예측을 생성할 수 있다. 이후, 신경망에 최종 1 Х 1 컨볼루션 레이어를 적용하여 7 × 7 × 1024 출력들을 7 × 7 × 125로 변환할 수 있다. 일 실시예에 따른 회피 알고리즘은 다음과 같이 수행될 수 있다. 도 12에서 카메라로 촬영한 영상 프레임의 중심을 C_frame으로 표시하고, 감지된 객체의 중심을 C_object로 표 시할 수 있다. 또한, 자율 주행 장치의 좌회전 또는 우회전을 위한 실행 가능한 설정 포인트(set point)를 표 시할 수 있다. 예를 들어, 왼쪽에 대한 설정 포인트는 S_left 와 같이 표시하고, 오른쪽에 대한 설정 포인트는 S_right와 같이 표시할 수 있다. 이 경우, 오차(Error), 다시 말해 조향 오차는 아래의 수학식 14와 같이 표현될 수 있다. 수학식 14"}
{"patent_id": "10-2020-0055141", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 14, "content": "일 실시예에서는 카메라로 촬영한 영상 프레임의 중심(C_frame)과 설정 포인트 사이의 거리를 줄이기 위해 오차 값을 사용할 수 있다. 신경망의 출력 값(Output)은 자율 주행 장치의 조향각(steering angle)으로 간주될 수 있으며, 아래의 수학식 15와 같이 표현될 수 있다. 수학식 15"}
{"patent_id": "10-2020-0055141", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 15, "content": "여기서, K는 PID의 비례 이득(proportional gain) 성분을 나타낼 수 있다. P는 Proportional에 해당하고, I는 integration에 해당하며, D는 differential에 해당할 수 있다. 비례 이득은 비례 성분의 입력의 백분율 값에 대한 출력의 백분율 값의 비율을 나타낼 수 있다. 자동 제어계에서 일정 동작으로 제어 동작 신호를 0부터 단 위량(예를 들어, '1') 만큼 변화시켰을 때 해당 동작에 입각하는 조작량의 변화분을 비례 이득이라 부를 수 있 다. 만약, K가 올바르게 설정되면, 자율 주행 장치는 도 12에서와 같이 프로세스를 이동시킬 수 있다. 예를 들어, 객체가 포텐셜 영역의 중간에 있는 경우, 일 실시예에 따른 자율 주행 장치는 포텐셜 필드 알고리즘 을 객체 회피 알고리즘으로 전환하여 장애물을 회피할 수 있다. 예를 들어, 장애물이 \"정지 신호(Stop sign)\"인 경우, 객체 회피 알고리즘 및 주행 조작이 종료될 수 있다. 도 13은 일 실시예에 따라 경로를 탐색하고, 충돌을 회피하는 자율 주행 방법을 나타낸 흐름도이고, 도 14는 13 과 같은 자율 주행을 위한 알고리즘을 도시한 도면이다. 도 13을 참조하면, 도 12를 통해 전술한 동작을 수행 하는 전체적인 흐름이 도시된다. 일 실시예에 따른 자율 주행 장치는 해당 장치에 설치된 레이저 및 카메라에 대한 레이저 데이터 및 다크넷 (darknet)의 객체 검출 분류(object detection classification) 정보를 획득할 수 있다. 여기서, 다크넷의 객 체 검출 분류 정보는 예를 들어, YOLO 알고리즘에서 객체 분류(또는 예측)을 위해 사용되는 코드에 해당할 수 있다. 자율 주행 장치는 알고리즘들을 사용하여 조향 각도를 산출할 수 있다. 자율 주행 장치는 해당 장치의 스로틀을 위한 모터(motor) 및 조향을 위한 서보 모터(servo motor)를 초기화 한 후, 구동시킬 수 있다. 여기서, '서보'는 자율 주행 장치의 상태를 기준 값과 비교하고, 비교 결과를 해당 장치가 안정되는 방향으로 피드백 함으로써 가장 적합하도록 자동 제어하는 것 또는 서보 모터(servo motor)로 이해될 수 있다. 자율 주행 장치는 해당 장치의 구동에 의해 일정 공간 혹은 경로 상에서 객체에 검출되는지 여부를 판단할 수 있다. 단계에서, N=1은 객체가 검출된 경우를 나타내고, N=0은 객체가 검출되지 않은 경우를 나타 낼 수 있다. 단계에서 객체가 검출된 것('N=1')으로 판단되면, 자율 주행 장치는 검출된 객체가 \"정지 신호(stop sign)\"인지를 결정할 수 있다. 단계에서 검출된 객체가 \"정지 신호\"라면, 자율 주행 장치는 해당 장치의 모터 및 서보의 동작을 종료시킬 수 있다. 이와 달리, 단계에서 검출된 객체가 \"정지 신호\"가 아니라면, 자율 주행 장치는 충돌 회피를 위한 동작들 을 수행할 수 있다. 보다 구체적으로, 검출된 객체가 정지 신호가 아니라면, 자율 주행 장치는 검출된 객체의 중심( )이 영상 프레임의 중심( )보다 큰지 여부를 결정할 수 있다. 이때, 단계(131 1)에서 객체의 중심( )이 영상 프레임의 중심( )보다 크다는 것은 해당 객체가 영상 프레임에서 오른 쪽에 있다는 의미로 이해될 수 있다. 또한, 객체의 중심( )이 영상 프레임의 중심( )보다 작거나 같 다는 것은 해당 객체가 영상 프레임에서 왼쪽에 있다는 의미로 이해될 수 있다. 단계에서 객체의 중심( )이 영상 프레임의 중심( )보다 큰 경우, 다시 말해, 해당 객체가 영상 프레임에서 오른쪽에 있는 경우, 자율 주행 장치는 예를 들어, 수학식 14에 개시된 수학식 에 의해 조향 오차를 산출할 수 있다. 자율 주행 장치는 단계(131 3)에서 산출된 조향 오차에 해당 장치를 왼쪽으로 조향하여 객체를 회피할 수 있다. 이와 달리, 단계에서 객체의 중심( )이 영상 프레임의 중심( )보다 작거나 같은 경우, 다시 말 해, 해당 객체가 영상 프레임에서 왼쪽에 있는 경우, 자율 주행 장치는 예를 들어, 수학식 14에 개시된 수학식 에 의해 조향 오차를 산출할 수 있다. 자율 주행 장치는 단계 에서 산출된 조향 오차에 해당 장치를 오른쪽으로 조향하여 객체를 회피할 수 있다. 단계에서 객체가 검출되지 않은 것('N=0')으로 판단되면, 자율 주행 장치는 자율 주행 장치의 주행을 위 한 안내(guidance) 및 부분적인 회피를 위한 동작들을 수행할 수 있다. 단계에서 객체가 검출되지 않은 것('N=0')으로 판단되면, 자율 주행 장치는 해당 공간에 레이저를 투사하 고, 투사된 광선들( )의 좌표(x, y)들을 산출할 수 있다. 단계에서, 자율 주행 장치는 예를 들 어, 수학식 9 및 수학식 11을 통해 투사된 1081개의 광선들의 좌표(x, y)들을 산출할 수 있다. 이후, 자율 주행 장치는 단계에서 산출된 광선들( )의 모든 x 좌표들을 합산하고, 광선들( )의 모든 y 좌표들을 합산할 수 있다. 단계에서, 자율 주행 장치는 예를 들어, 전술한 수학식 10과 같이 모든 x 좌표들을 합산하고, 전술한 수학식 12와 같이 모든 y 좌표들을 합산할 수 있다. 자율 주행 장치는 단계에서의 합산을 통해 얻은 결과(좌표(X, Y))로부터 해당 장치의 조향을 위한 각도 (steering angle) 를 산출할 수 있다. 자율 주행 장치는 예를 들어, 전술한 수학식 13을 통해 조향을 위한 각도, 다시 말해 조향 각도 를 산출할 수 있다. 자율 주행 장치는 단계에서 산출된 조향 각도에 따라 해당 장치의 주행을 안내하고, 부분적인 회피를 수 행할 수 있다. 도 13을 통해 전술한 과정은 아래의 도 14의 알고리즘과 같이 표현할 수 있다. 도 15는 다른 실시예에 따른 자율 주행 방법을 나타낸 흐름도이다. 도 15를 참조하면, 일 실시예에 따른 자율 주행 장치는 해당 장치의 모터(motor) 및 서보(servo)를 초기화한 후, 구동시킬 수 있다. 이후, 자율 주 행 장치는 도 13에서와는 달리, 해당 장치의 구동에 의해 일정 공간 혹은 경로 상에서 바로 \"정지 신호(stop sign)\"가 검출되는지 여부를 결정할 수 있다. 단계에서 검출된 객체가 \"정지 신호\"라면, 자율 주 행 장치는 해당 장치의 모터 및 서보의 동작을 중지시킬 수 있다. 단계에서 검출된 객체가 \"정지 신호\"가 아니라면, 자율 주행 장치는 충돌 회피를 위한 동작들을 수 행할 수 있다. 아울러, 자율 주행 장치는 \"정지 신호(stop sign)\"가 검출되는지 여부를 결정하는 것과 함께 자 율 주행 장치의 주행을 위한 안내 및 부분적인 회피를 위한 동작들을 수행할 수 있다. 충돌 회피를 위한 동작들 및 안내 및 부분적인 회피를 위한 동작들은 병렬적으로 수행될 수 있다. 도 15에서 충돌 회피를 위한 동작들은 도 13의 충돌 회피를 위한 동작들과 동일하고, 도 15에서 안 내 및 부분적인 회피를 위한 동작들은 도 13의 안내 및 부분적인 회피를 위한 동작들과 동일하므로 이하에서는 도 13과 상이한 동작에 대하여 설명하기로 한다. 자율 주행 장치는 충돌 회피를 위한 동작들을 수행한 결과에 따라 객체와의 충돌을 회피하기 위해 결정된 조향 각도( )를 출력하고, 자율 주행 장치의 안내(guidance) 및 부분적인 회피를 위한 동작들(133 0)을 수행한 결과에 따라 결정된 조향 각도( )를 출력할 수 있다. 자율 주행 장치는 단계에서 출력된 조향 각도( )와 단계에서 출력된 조향 각도( )에 의 해 최종적인 조향 각도( )를 결정할 수 있다. 예를 들어, 경로 상에서 객체가 된 경우에는 조향 각도는 와 같이 충돌 회피를 위해 결정된 조향 각도( )와 안내 및 부분적인 회피를 위한 조향 각도( ) 간의 오차에 의해 결정될 수 있다. 이와 달리, 경로 상에서 객체가 검출되지 않은 경우에 조향 각도는 와 같이 안내 및 부분적인 회피를 위한 조향 각도( )로 결정될 수 있다. 도 16은 일 실시예에 따른 3차원 환경에서의 자율 주행 장치의 움직임을 설명하기 위한 도면이다. 도 16에 도 시된 자율 주행 장치는 예를 들어, 지상 차량(ground vehicle) 또는 무인 지상 차량(unmanned ground vehicl e)일 수 있다. 또한, 3차원 환경은 예를 들어, 미로 환경(maze environment)일 수 있다. 도 16을 참조하면, 일 실시예에 따른 자율 주행 장치가 장애물을 회피하면서 앞으로 진행하는 상황이 단계별로 도시된다. 자율 주행 장치는 1610과 같이 미로의 우측 하단에 있는 입구에서 출발할 수 있다. 자율 주행 장치 는 미로의 우측 하단으로부터 시작하여 전술한 알고리즘들을 사용하여 경로 진행 방향에 따라 1620, 1630, 1640, 1650, 1660, 1670와 같이 단계별로 장애물을 회피하고 경로를 안내하여 1680과 같이 미로의 출구로 탈출 할 수 있다. 도 17은 일 실시예에 따른 자율 주행 장치의 하드웨어 구조(hardware architecture)를 도시한 도면이다. 도 17 을 참조하면, 일 실시예에 따른 자율 주행 장치의 일 예시인 스마트 임베디드 차량의 구조가 도시된다. 스마트 임베디드 차량은 예를 들어, 다양한 사용자의 요구를 충족시키기 위해 실제 차량의 1/10 크기로 제작된 동키 카(donkey car)에 해당할 수 있다. 스마트 임베디드 차량에는 예를 들어, 비전 센서 및 라이다 센서와 같은 다양한 센서들이 장착될 수 있다. 비전 센서는 예를 들어, 카메라 또는 이 미지 센서로 대체될 수 있고, 라이다 센서는 예를 들어, 레이저 센서로 대체될 수 있다. 신경망 처리 장 치는 예를 들어, 실시간 컴퓨터 비전을 위한 프로그래밍 라이브러리인 OpenCV(Open Source Computer Vision)에 의해 비전 센서의 감지 결과를 처리할 수 있으며 또는 심층 학습 신경망을 기법을 활용하여 직 접 처리할 수도 있다. 또한, 스마트 임배디드 차량에는 신경망 처리 장치 혹은 신경망 전용 프로세서가 장착될 수 있다. 신경망 처리 장치는 예를 들어, 전력 효율이 높은 임베디드 AI 컴퓨팅 장치인 Jetson AGX Xavier 또는 TX2 등과 같은 다양한 엣지 컴퓨팅 모듈을 포함할 수 있다. 또한, 신경망 처리 장치는 차량의 조향 (steering) 및 스로틀(throttle)을 제어하도록 설계 및 장착된 제어 회로 보드(control circuit board)(미도시)를 포함할 수 있다. 제어 회로 보드는 예를 들어, Teensy 일 수 있다. 스마트 임배디드 차량는 신경망 처리 장치에 의해 생성된 제1 펄스폭 변조(Pulse Width Modulation; PWM)에 의해 스마트 임배디드 차량의 전자식 주행 안정 장치(Electronic Stability Control; ESC) 및 스로틀을 위한 모터를 제어할 수 있다. 또한, 스마트 임배디드 차량는 신경망 처리 장치에 의해 생성된 제2 펄스폭 변조(PWM)에 의해 스마 트 임배디드 차량의 조향을 위한 서보 모터를 제어할 수 있다. 도 18은 일 실시예에 따른 포텐셜 필드를 이용하여 자율 주행하는 방법을 위한 소프트웨어 구조(software architecture)를 도시한 도면이다. 일 실시예에 따르면 전술한 알고리즘에서 충돌 회피 및 경로 안내를 위해 레이저 노드(LASER_NODE)의 데이터가 지속적으로 사용될 수 있다. 알고리즘은 예를 들어, 신경망 처리 장치에 장착되어 이용될 수 있으며, 도 18에 도시된 것과 같은 구조를 가질 수 있다. 예를 들어 설명해보면, 알고리즘은 카메라 노드(CAMERA_NODE)로부터 카메라 데이터(\"usb_cam\")를 획득하고, 레 이저 노드(LASER_NODE)로부터 레이저 데이터(\"/scan\")를 획득할 수 있다. 카메라 데이터(\"usb_cam\")는 다크넷_ 노드(DARKNET_NODE)로 전달되고, 레이저 데이터(\"/scan\")는 알고리즘 노드(ALGORITHM_NODE)로 전달될 수 있다. 알고리즘은 카메라 노드(CAMERA_NODE)를 사용하여 동작하는 \"/object_detection\"라는 이름의 토픽(topic)을 획 득할 수 있다. 만약, 해당 토픽에서 사용 가능한 데이터가 있다면, 해당 데이터는 전술한 흐름도에 따라 알고리 즘에서 사용될 수 있다. 알고리즘의 최종 출력은 차량의 순간을 조작할 수 있는 \"/cmd_vel\"라는 이름의 토픽을 이용하여 주어질 수 있다. 토픽 \"/cmd_vel\"는 TEENSY ARDUINO 하드웨어인 파이시리얼 노드(PYSERIAL_NODE)로 전달될 수 있다. TEENSY ARDUINO로부터, 맵핑(mapped)된, 적절한 펄스폭 변조(PWM) 값들(예를 들어, 전자식 주행 안정 장치 (ESC) 및 스로틀을 위한 모터를 위한 제1 펄스폭 변조 값 및 서보 모터를 위한 제2 펄스폭 변조 값 등)이 작업 을 완료하기 위해 주어질 수 있다. 도 19는 일 실시예에 따른 자율 주행 장치에 내장된 운영 체제(OS)에 따른 통신 셋업(communication setup) 과 정을 도시한 도면이다. 일 실시예에 따른 알고리즘은 자율 주행 장치에 내장된 운영 체제(OS)를 기반으로 동작할 수 있다. 운영 체제는 예를 들어, Ubuntu OS 일 수 있다. 일 실시예에 따른 알고리즘은 예를 들어, ROS 운영 체제(OS)에서 전체가 실행되는 반면, 조향 제어는 예 를 들어, Arduino IDE를 사용하여 수행될 수 있다. 인터페이스에 이용되는 파이시리얼(Pyserial)통신 프로토콜은 ROS 운영 체제(OS)에서 Arduino IDE로 메시지를 전송하는 데에 사용될 수 있다. 도 20은 일 실시예에 따른 자율 주행 장치의 블록도이다. 도 20을 참조하면, 일 실시예에 따른 자율 주행 장치 는 비전 센서, 거리 센서, 및 프로세서를 포함한다. 자율 주행 장치는 통신 인터페이스 및 메모리를 더 포함할 수 있다. 비전 센서, 거리 센서, 프로세서 , 통신 인터페이스 및 메모리는 통신 버스를 통해 서로 통신할 수 있다. 자율 주행 장 치는 예를 들어, 자율 주행 로봇, 또는 자율 주행 차량 자체이거나 또는 자율 주행 로봇 또는 자율 주행 차량을 위한 별도의 장치로 구성될 수 있다. 비전 센서는 작업장 내 로봇의 현재 위치, 로봇의 목표 위치 및 적어도 하나의 장애물의 위치를 포함하는 영상을 촬영한다. 비전 센서는 예를 들어, 카메라 센서이거나 또는 영상 센서일 수 있으며, 반드시 이에 한정 되지 않는다. 거리 센서는 로봇과 주변 장애물과의 거리를 감지하여 센싱 정보를 생성한다. 거리 센서는 예를 들어, 라이다 센서일 수 있다. 프로세서는 영상에 기초하여 포텐셜 필드를 생성한다. 프로세서는 포텐셜 필드에 기초하여 로봇의 이동 방향에 관한 제1 정보를 생성한다. 프로세서는 센싱 정보에 기초하여 생성된 주변 장애물의 인식 정보에 따라 로봇의 이동 방향에 관한 제2 정보를 생성한다. 프로세서는 제1 정보 및 제2 정보에 기초하 여, 로봇의 이동 방향을 포함하는 주행 경로를 결정한다. 여기서, 인식 정보는 기 학습된 신경망을 이용하여 생성되며, 거리 센서에 의하여 센싱된 영상 내 주변 장애물을 포함하는 영역을 지시하는 정보를 포함할 수 있다. 신경망은 예를 들어, YOLO(You Only Look Once)이며 딥 러닝에 의해 학습될 수 있다. 또한, 제1 정보 및 제2 정보 각각은 로봇이 현재 위치에서 이동 가능한 방향 후보들의 점수들 중 적어도 일부를 포함할 수 있다. 프로세서는 로봇의 현재 위치 및 로봇의 목표 위치에 기초하여 흡인 포텐셜 필드를 생성하고, 적어도 하 나의 장애물의 위치에 기초하여 반발 포텐셜 필드를 생성하며, 흡인 포텐셜 필드 및 반발 포텐셜 필드를 혼합함 으로써 포텐셜 필드를 생성할 수 있다. 프로세서는 로봇의 목표 위치를 음전하로 모델링하고, 장애물을 양전하로 모델링하며, 로봇을 양전하로 모델링 함으로써 포텐셜 필드를 생성할 수 있다. 프로세서는 예를 들어, 로봇이 현재 위치에서 이동 가능한 방향 후보들 중 포텐셜 필드 상의 포텐셜 값이 낮은 후보일수록 더 큰 점수를 할당할 수 있다. 프로세서는 예를 들어, 로봇이 현재 위치에서 이동 가능한 방향 후보들 중 인식 정보에 대응하는 영역을 회피하는 후보일수록 더 큰 점수를 할당할 수 있다. 프로세서는 제1 정보를 위한 제1 가중치 및 제2 정보를 위한 제2 가중치에 기초하여, 제1 정보 및 제2 정 보를 가중 합산함으로써, 로봇의 이동 방향을 결정할 수 있다. 이때, 제2 가중치는 예를 들어, 제1 가중치보 다 크게 설정될 수 있다. 프로세서는 주행 경로가 결정됨에 따라 로봇을 이동 방향으로 이동시킬 수 있다. 프로세서는 로봇이 이동 방향으로 이동함에 따라, 로봇의 현재 위치를 갱신할 수 있다. 프로세서 는 로봇이 이동 방향으로 이동함에 따라, 로봇이 목표 위치에 도달할 때까지, 제1 정보를 결정하고, 제2 정보를 결정하고, 주행 경로를 결정하는 과정을 반복적으로 수행함으로써 로봇의 현재 위치를 갱신할 수 있다. 또한, 프로세서는 도 1 내지 도 19를 통해 전술한 적어도 하나의 방법 또는 적어도 하나의 방법에 대응되 는 알고리즘을 수행할 수 있다. 프로세서는 목적하는 동작들(desired operations)을 실행시키기 위한 물 리적인 구조를 갖는 회로를 가지는 하드웨어로 구현된 데이터 처리 장치일 수 있다. 예를 들어, 목적하는 동작 들은 프로그램에 포함된 코드(code) 또는 인스트럭션들(instructions)을 포함할 수 있다. 예를 들어, 하드웨어 로 구현된 데이터 처리 장치는 마이크로프로세서(microprocessor), 중앙 처리 장치(central processing unit), 프로세서 코어(processor core), 멀티-코어 프로세서(multi-core processor), 멀티프로세서(multiprocessor), ASIC(Application-Specific Integrated Circuit), FPGA(Field Programmable Gate Array)를 포함할 수 있다. 프로세서는 프로그램을 실행하고, 자율 주행 장치를 제어할 수 있다. 프로세서에 의하여 실 행되는 프로그램 코드는 메모리에 저장될 수 있다. 통신 인터페이스는 자율 주행 장치 외부의 별도의 촬영 장치로부터 촬영된 영상을 수신할 수 있다. 또한, 통신 인터페이스는 프로세서에 의해 결정된 주행 경로를 자율 주행 장치의 외부로 전 송할 수 있다. 메모리는 상술한 프로세서에서의 처리 과정에서 생성되는 다양한 정보들을 저장할 수 있다. 이 밖 에도, 메모리는 각종 데이터와 프로그램 등을 저장할 수 있다. 메모리는 휘발성 메모리 또는 비휘 발성 메모리를 포함할 수 있다. 메모리는 하드 디스크 등과 같은 대용량 저장 매체를 구비하여 각종 데 이터를 저장할 수 있다. 실시예에 따른 방법은 다양한 컴퓨터 수단을 통하여 수행될 수 있는 프로그램 명령 형태로 구현되어 컴퓨터 판 독 가능 매체에 기록될 수 있다. 상기 컴퓨터 판독 가능 매체는 프로그램 명령, 데이터 파일, 데이터 구조 등 을 단독으로 또는 조합하여 포함할 수 있다. 상기 매체에 기록되는 프로그램 명령은 실시예를 위하여 특별히 설계되고 구성된 것들이거나 컴퓨터 소프트웨어 당업자에게 공지되어 사용 가능한 것일 수도 있다. 컴퓨터 판 독 가능 기록 매체의 예에는 하드 디스크, 플로피 디스크 및 자기 테이프와 같은 자기 매체(magnetic media), CD-ROM, DVD와 같은 광기록 매체(optical media), 플롭티컬 디스크(floptical disk)와 같은 자기-광 매체 (magneto-optical media), 및 롬(ROM), 램(RAM), 플래시 메모리 등과 같은 프로그램 명령을 저장하고 수행하도 록 특별히 구성된 하드웨어 시스템이가 포함된다. 프로그램 명령의 예에는 컴파일러에 의해 만들어지는 것과 같은 기계어 코드뿐만 아니라 인터프리터 등을 사용해서 컴퓨터에 의해서 실행될 수 있는 고급 언어 코드를 포 함한다. 상기된 하드웨어 장치는 실시예의 동작을 수행하기 위해 하나 이상의 소프트웨어 모듈로서 작동하도록 구성될 수 있으며, 그 역도 마찬가지이다. 소프트웨어는 컴퓨터 프로그램(computer program), 코드(code), 명령(instruction), 또는 이들 중 하나 이상의 조합을 포함할 수 있으며, 원하는 대로 동작하도록 처리 장치를 구성하거나 독립적으로 또는 결합적으로 (collectively) 처리 장치를 명령할 수 있다. 소프트웨어 및/또는 데이터는, 처리 시스템에 의하여 해석되거나 처리 시스템에 명령 또는 데이터를 제공하기 위하여, 어떤 유형의 기계, 구성요소(component), 물리적 시스템, 가상 시스템(virtual equipment), 컴퓨터 저장 매체 또는 시스템에 영구적으로, 또는 일시적으로 구체화 (embody)될 수 있다. 소프트웨어는 네트워크로 연결된 컴퓨터 시스템 상에 분산되어서, 분산된 방법으로 저장 되거나 실행될 수도 있다. 소프트웨어 및 데이터는 하나 이상의 컴퓨터 판독 가능 기록 매체에 저장될 수 있다."}
{"patent_id": "10-2020-0055141", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 16, "content": "이상과 같이 실시예들이 비록 한정된 도면에 의해 설명되었으나, 해당 기술분야에서 통상의 지식을 가진 자라면 상기를 기초로 다양한 기술적 수정 및 변형을 적용할 수 있다. 예를 들어, 설명된 기술들이 설명된 방법과 다 른 순서로 수행되거나, 및/또는 설명된 시스템, 구조, 시스템, 회로 등의 구성요소들이 설명된 방법과 다른 형 태로 결합 또는 조합되거나, 다른 구성요소 또는 균등물에 의하여 대치되거나 치환되더라도 적절한 결과가 달성 될 수 있다. 그러므로, 다른 구현들, 다른 실시예들 및 특허청구범위와 균등한 것들도 후술하는 청구범위의 범위에 속한다."}
{"patent_id": "10-2020-0055141", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 일 실시예에 따른 자율 주행 방법이 수행되는 주행 환경을 도시한 도면. 도 2는 일 실시예에 따른 자율 주행 방법을 나타낸 흐름도. 도 3은 일 실시예에 따른 포텐셜 필드를 생성하는 방법을 나타낸 흐름도. 도 4는 일 실시예에 따른 흡인 포텐셜 필드를 도시한 도면. 도 5는 일 실시예에 따라 생성된 포텐셜 필드를 도시한 도면. 도 6은 일 실시예에 따라 로봇의 이동 방향에 관한 제1 정보를 생성하는 방법을 설명하기 위한 도면. 도 7은 일 실시예에 따라 2차원 공간에 생성된 포텐셜 필드의 일 예시를 도시한 도면. 도 8은 일 실시예에 따른 자율 주행 장치를 도시한 도면. 도 9는 일 실시예에 따른 3차원 공간을 생성하는 자율 주행 장치의 일반적인 구조를 도시한 도면. 도 10은 일 실시예에 따라 레이저 광선들의 조합을 이용하여 생성되는 포텐셜 필드의 일 예시를 도시한 도면. 도 11은 일반적인 포텐셜 알고리즘에 의한 자율 주행 장치의 동작을 설명하기 위한 도면. 도 12는 일 실시예에 따른 비례 이득(proportional gain)에 대한 에러를 산출하는 방법을 설명하기 위한 도면. 도 13은 일 실시예에 따른 자율 주행 방법을 나타낸 흐름도. 도 14는 일 실시예에 따라 경로를 탐색하고, 충돌을 회피하는 알고리즘의 일 예시를 도시한 도면. 도 15는 다른 실시예에 따른 자율 주행 방법을 나타낸 흐름도. 도 16은 일 실시예에 따른 3차원 환경에서의 자율 주행 장치의 움직임을 설명하기 위한 도면. 도 17은 일 실시예에 따른 자율 주행 장치의 하드웨어 구조(hardware architecture)를 도시한 도면. 도 18은 일 실시예에 따른 포텐셜 필드를 이용하여 자율 주행하는 방법을 위한 소프트웨어 구조(software architecture)를 도시한 도면. 도 19는 일 실시예에 따른 자율 주행 장치에 내장된 운영 체제(OS)에 따른 통신 셋업(communication setup)과정 을 도시한 도면. 도 20은 일 실시예에 따른 자율 주행 장치의 블록도."}
