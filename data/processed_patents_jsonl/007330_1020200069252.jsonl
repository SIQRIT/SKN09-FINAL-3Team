{"patent_id": "10-2020-0069252", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2021-0152314", "출원번호": "10-2020-0069252", "발명의 명칭": "매장 픽업 서비스를 제공하기 위한 로봇 시스템 및 그 방법", "출원인": "롯데정보통신 주식회사", "발명자": "이희재"}}
{"patent_id": "10-2020-0069252", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "매장 픽업 서비스를 제공하기 위한 로봇 시스템에 있어서,상품 특성 정보 및 상품 수령 매장 정보에 기초하여 가상 환경을 구축하고, 상기 가상 환경 내에서 포장재 내상품을 적재하는 순서 및 배치 위치 좌표값을 출력하는 인공지능 스케줄 모델을 학습하고, 또한 상품을 파지,적출, 적재하는 로봇의 각 구성요소들의 동작값 및 동작속도를 출력하는 인공지능 동작 모델을 학습하는 시뮬레이터;상기 시뮬레이터의 학습을 제어하고, 사용자의 주문 상품들의 정보 및 주문 상품들을 수령할 매장의 정보를 포함하는 주문 상품 리스트를 수신하며, 수신된 주문 상품 리스트에 기초하여 상기 학습된 인공지능 스케줄 모델및 상기 인공지능 동작 모델을 로봇 제어부로 전달하는 중앙 통제부; 및상기 학습된 인공지능 스케줄 모델을 통해 상기 주문 상품들의 포장재 내 적재 순서 및 배치 위치 좌표값을 생성하고, 상기 학습된 인공지능 동작 모델을 통해 상기 주문 상품들의 포장재 내 적재 순서 및 배치 위치 좌표값에 따른 상기 주문 상품들을 파지, 적출, 적재하는 로봇의 각 구성요소들의 동작값 및 동작속도를 생성하여, 상기 주문 상품들을 수령할 매장의 로봇을 제어하는 상기 로봇 제어부를 포함하는 로봇 시스템."}
{"patent_id": "10-2020-0069252", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1 항에 있어서,상기 시뮬레이터는,상기 가상 환경 내에서 가상의 상품, 선반, 포장재 및 장애물을 포함하는 가상 모델을 촬영하는 가상 카메라;상기 가상 카메라의 촬영 영상을 분석하여 상기 가상 모델의 정보를 분석하는 가상 영상 분석부;전체 상품들의 상품 특성 정보를 분석하여 상품들의 훼손이 없는 제1임시 상품 적재 순서를 생성하는 가상 상품분석부;상기 가상 모델의 분석 결과와, 상기 제1임시 상품 적재 순서, 상기 상품 특성 정보 및 상기 상품 수령 매장 정보를 이용하여, 포장재 내 상품을 적재하는 순서 및 배치 위치 좌표값을 출력하는 인공지능 스케줄 모델을 학습하는 AI 스케줄 모델 학습부; 및상기 가상 모델의 분석 결과와, 상기 상품 특성 정보 및 상기 상품 수령 매장 정보를 이용하여, 상품을 파지,적출, 적재하는 로봇의 각 구성요소들의 동작값 및 동작속도를 출력하는 인공지능 동작 모델을 학습하는 AI 동작 모델 학습부;를 포함하는 것을 특징으로 하는 로봇 시스템."}
{"patent_id": "10-2020-0069252", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 2 항에 있어서,상기 인공지능 스케줄 모델은, 복수의 로봇에 대해 로봇 간 동작 시간 순서를 더 출력하고,상기 인공지능 동작 모델은, 상기 동작 시간 순서에 따른 각 로봇의 구성요소들의 최적의 동작값 및 동작속도를출력하는 것을 특징으로 하는 로봇 시스템."}
{"patent_id": "10-2020-0069252", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 3 항에 있어서,상기 가상 환경에 대해 하나의 인공지능 스케줄 모델이 생성되어 학습되고, 상기 가상 환경 내의 각 로봇의 종류별로 인공지능 동작 모델이 생성되어 학습되며, 상기 하나의 인공지능 스케줄 모델이 각 인공지능 동작 모델로 대응하는 로봇의 동작 시간 순서를 출력하는 것을 특징으로 하는 로봇 시스템.공개특허 10-2021-0152314-3-청구항 5 제 2 항에 있어서,상기 가상 영상 분석부는,가상 상품의 경우, 상품 종류, 위치, 크기, 2차원 또는 3차원 자세, 무게 중심점을 분석하고,가상 포장재의 경우, 포장재의 종류, 위치, 크기, 2차원 또는 3차원 자세, 공간 점유율을 분석하며, 가상 선반의 경우, 선반의 위치, 2차원 또는 3차원 크기를 분석하고,가상 장애물의 경우, 장애물의 위치, 2차원 또는 3차원 크기를 분석하는 것을 특징으로 하는 로봇 시스템."}
{"patent_id": "10-2020-0069252", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제 2 항에 있어서,상기 상품 특성 정보는, 상품의 상품명, 상품 이미지, 가격, 크기, 형태, 무게, 강도, 포장 재질 및 재고량을포함하고,상기 상품 수령 매장 정보는, 각 매장별 정보로서, 포장재 정보, 로봇 정보, 카메라 정보 및 선반 정보를 포함하는 것을 특징으로 하는 로봇 시스템."}
{"patent_id": "10-2020-0069252", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제 2 항에 있어서,상기 로봇 제어부는,상기 주문 상품들을 수령할 매장에 설치된 카메라로부터 촬영 영상을 수신하고, 수신된 촬영 영상에서 상품, 선반, 포장재 및 장애물을 분석하는 영상 분석부;상기 주문 상품들의 상품 특성 정보를 분석하여 제2임시 상품 적재 순서를 생성하는 상품 분석부;상기 영상 분석부의 분석 결과와, 상기 제2임시 상품 적재 순서와, 상기 주문 상품들의 상품 특성 정보 및 상기주문 상품들을 수령할 매장의 정보를 이용하여, 상기 학습된 인공지능 스케줄 모델을 통해 포장재 내 상품을 적재하는 순서 및 배치 위치 좌표값을 출력하는 AI 스케줄 모델 추론부; 상기 영상 분석부의 분석 결과와, 상기 주문 상품들의 상품 특성 정보 및 상기 주문 상품들을 수령할 매장의 정보와, 상기 학습된 인공지능 스케줄 모델의 출력값에 기초하여, 상기 주문 상품들을 파지, 적출, 적재하는 로봇의 각 구성요소들의 동작값 및 동작속도를 출력하는 상기 학습된 인공지능 동작 모델을 통해 출력하는 AI 동작모델 추론부; 및상기 AI 동작 모델 추론부의 출력값에 따라 상기 상품을 수령할 매장의 로봇을 제어하는 로봇 조작부를 포함하는 것을 특징으로 하는 로봇 시스템."}
{"patent_id": "10-2020-0069252", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제 7 항에 있어서,상기 학습된 인공지능 스케줄 모델은, 복수의 로봇에 대해 로봇 간 동작 시간 순서를 더 출력하고,상기 학습된 인공지능 동작 모델은, 상기 동작 시간 순서에 따른 각 로봇의 구성요소들의 최적의 동작값 및 동작속도를 출력하는 것을 특징으로 하는 로봇 시스템."}
{"patent_id": "10-2020-0069252", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "로봇 시스템에서 매장 픽업 서비스를 제공하는 방법에 있어서,상품 특성 정보 및 상품 수령 매장 정보에 기초하여 가상 환경을 구축하고, 상기 가상 환경 내에서 포장재 내상품을 적재하는 순서 및 배치 위치 좌표값을 출력하는 인공지능 스케줄 모델을 학습하고, 또한 상품을 파지,적출, 적재하는 로봇의 각 구성요소들의 동작값 및 동작속도를 출력하는 인공지능 동작 모델을 학습하는 단계;공개특허 10-2021-0152314-4-사용자의 주문 상품들의 정보 및 상품을 수령할 매장의 정보를 포함하는 주문 상품 리스트를 수신하고, 수신된주문 상품 리스트에 기초하여 상기 학습된 인공지능 스케줄 모델 및 상기 인공지능 동작 모델을 선택하는 단계;선택된 상기 학습된 인공지능 스케줄 모델을 통해 상기 주문 상품들의 포장재 내 적재 순서 및 배치 위치 좌표값을 생성하고, 선택된 상기 학습된 인공지능 동작 모델을 통해 상기 주문 상품들의 포장재 내 적재 순서 및 배치 위치 좌표값에 따른 상기 주문 상품들을 파지, 적출, 적재하는 로봇의 각 구성요소들의 동작값 및 동작속도를 생성하는 단계; 및상기 동작값 및 동작속도에 따라 상기 주문 상품들을 수령할 매장의 로봇을 제어하는 단계를 포함하는 방법."}
{"patent_id": "10-2020-0069252", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제 9 항에 있어서,상기 학습하는 단계는,가상 카메라를 이용하여 상기 가상 환경 내에서 가상의 상품, 선반, 포장재 및 장애물을 포함하는 가상 모델을촬영하는 단계;상기 가상 카메라의 촬영 영상을 분석하여 상기 가상 모델의 정보를 분석하는 단계;전체 상품들의 상품 특성 정보를 분석하여 상품들의 훼손이 없는 제1임시 상품 적재 순서를 생성하는 단계;상기 가상 모델의 분석 결과와, 상기 제1임시 상품 적재 순서와, 상기 상품 특성 정보 및 상기 상품 수령 매장정보를 이용하여, 포장재 내 상품을 적재하는 순서 및 배치 위치 좌표값을 출력하는 인공지능 스케줄 모델을 학습하는 단계; 및상기 가상 모델의 분석 결과와, 상기 상품 특성 정보 및 상기 상품 수령 매장 정보를 이용하여, 상품을 파지,적출, 적재하는 로봇의 각 구성요소들의 동작값 및 동작속도를 출력하는 인공지능 동작 모델을 학습하는 단계를포함하는 것을 특징으로 하는 방법."}
{"patent_id": "10-2020-0069252", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제 10 항에 있어서,상기 인공지능 스케줄 모델은, 복수의 로봇에 대해 로봇 간 동작 시간 순서를 더 출력하고,상기 인공지능 동작 모델은, 상기 동작 시간 순서에 따른 각 로봇의 구성요소들의 최적의 동작값 및 동작속도를출력하는 것을 특징으로 하는 방법."}
{"patent_id": "10-2020-0069252", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제 11 항에 있어서,상기 가상 환경에 대해 하나의 인공지능 스케줄 모델이 생성되어 학습되고, 상기 가상 환경 내의 각 로봇의 종류별로 인공지능 동작 모델이 생성되어 학습되며, 상기 하나의 인공지능 스케줄 모델이 각 인공지능 동작 모델로 대응하는 로봇의 동작 시간 순서를 출력하는 것을 특징으로 하는 방법."}
{"patent_id": "10-2020-0069252", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제 10 항에 있어서,상기 가상 모델의 정보를 분석하는 단계는,가상 상품의 경우, 상품 종류, 위치, 크기, 2차원 또는 3차원 자세, 무게 중심점을 분석하고,가상 포장재의 경우, 포장재의 종류, 위치, 크기, 2차원 또는 3차원 자세, 공간 점유율을 분석하며, 가상 선반의 경우, 선반의 위치, 2차원 또는 3차원 크기를 분석하고,가상 장애물의 경우, 장애물의 위치, 2차원 또는 3차원 크기를 분석하는 것을 특징으로 하는 방법."}
{"patent_id": "10-2020-0069252", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "공개특허 10-2021-0152314-5-제 10 항에 있어서,상기 상품 특성 정보는, 상품의 상품명, 상품 이미지, 가격, 크기, 형태, 무게, 강도, 포장 재질 및 재고량을포함하고,상기 상품 수령 매장 정보는, 각 매장별 정보로서, 포장재 정보, 로봇 정보, 카메라 정보 및 선반 정보를 포함하는 것을 특징으로 하는 방법."}
{"patent_id": "10-2020-0069252", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제 10 항에 있어서,상기 생성하는 단계는,상기 주문 상품들을 수령할 매장에 설치된 카메라로부터 촬영 영상을 수신하고, 수신된 촬영 영상에서 상품, 선반, 포장재 및 장애물을 분석하여 제1분석 결과를 출력하는 단계;상기 주문 상품들의 상품 특성 정보를 분석하여 제2임시 상품 적재 순서를 생성하는 단계;상기 제1분석 결과와, 상기 제2임시 상품 적재 순서와, 상기 주문 상품들의 상품 특성 정보 및 상기 주문 상품들을 수령할 매장의 정보를 이용하여, 상기 학습된 인공지능 스케줄 모델을 통해 포장재 내 상품을 적재하는 순서 및 배치 위치 좌표값을 출력하는 단계; 및상기 제1분석 결과와, 상기 주문 상품들의 상품 특성 정보 및 상기 주문 상품들을 수령할 매장의 정보와, 상기학습된 인공지능 스케줄 모델의 출력값에 기초하여, 상기 주문 상품들을 파지, 적출, 적재하는 로봇의 각 구성요소들의 동작값 및 동작속도를 출력하는 상기 학습된 인공지능 동작 모델을 통해 출력하는 단계를 포함하는 것을 특징으로 하는 방법."}
{"patent_id": "10-2020-0069252", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제 15 항에 있어서,상기 학습된 인공지능 스케줄 모델은, 복수의 로봇에 대해 로봇 간 동작 시간 순서를 더 출력하고,상기 학습된 인공지능 동작 모델은, 상기 동작 시간 순서에 따른 각 로봇의 구성요소들의 최적의 동작값 및 동작속도를 출력하는 것을 특징으로 하는 방법."}
{"patent_id": "10-2020-0069252", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "일 실시예에 따른 매장 픽업 서비스를 제공하기 위한 로봇 시스템은, 상품 특성 정보 및 상품 수령 매장 정보에 기초하여 가상 환경을 구축하고, 상기 가상 환경 내에서 포장재 내 상품을 적재하는 순서 및 배치 위치 좌표값을 출력하는 인공지능 스케줄 모델을 학습하고, 또한 상품을 파지, 적출, 적재하는 로봇의 각 구성요소들의 동작값 (뒷면에 계속)"}
{"patent_id": "10-2020-0069252", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 매장 픽업 서비스를 제공하기 위한 로봇 시스템 및 그 방법에 관한 것으로, 보다 구체적으로 사용자 가 미리 상품을 주문하면 매장에서 로봇을 이용하여 주문 상품을 포장 준비해 놓고 사용자가 매장에 방문하여 직접 수령해가는 픽업 서비스를 제공하기 위한 로봇 시스템 및 그 방법에 관한 것이다."}
{"patent_id": "10-2020-0069252", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "미국 최대 전자상거래 기업 아마존(Amazon)은 세계 최로로 무인 매장을 운영하고 있다. 사용자들이 매장에 들어 가 본인이 원하는 상품을 바구니에 담으면 천장에 설치된 수많은 카메라와 센서들이 사용자가 어떤 상품을 선택 했는지 자동 감지하고 사용자의 모바일 단말의 어플리케이션에 연결된 결제수단으로 비용이 자동 청구된다. 그 러나 이러한 무인 매장은 사용자가 매장에 방문하여 원하는 상품을 바구니에 담아 직접 포장을 해야 한다. 여기에 더하여, 사용자가 미리 온라인으로 상품들을 주문하면, 매장 내에서 근로자가 사용자가 주문한 상품들을 픽업하여 미리 포장해 놓고, 사용자는 매장에 방문하여 미리 포장된 제품을 수령하기만 하면 되는 픽업 서비스 가 제안되고 있다. 이러한 픽업 서비스의 전반적인 과정들은 자동화가 이루어져 있으나 상품 포장 단계는 인력 을 투입하는데 종래의 포장 로봇은 미리 정해진 적재 순서에 따라 상품을 픽업하여 포장할 뿐 상품의 부피, 형 태, 무게, 강도, 포장 재질을 고려하지 않고 포장재에 담아 상품이 훼손되기 때문이다. 특히, 로봇이 동작을 수행하는 행동 반경이나 상품의 적출/적재 위치를 전문가들이 직접 사전에 입력하거나 티 칭(teaching)하는 방식을 사용해야 하기 때문에 비용과 시간이 많이 소요된다. 또한 다수의 로봇이 운영되는 경우 로봇 간 충돌이 발생하는 등 해결해야 하는 과제가 산적하기 때문이다."}
{"patent_id": "10-2020-0069252", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 상술한 문제점을 해결하기 위해 제안된 것으로, 인공지능을 이용하여 상품의 훼손 없이 그리고 다수 의 로봇 간 충돌없이 신속하고 정확하게 상품을 픽업하고 포장하여 매장 픽업 서비스를 제공하기 위한 로봇 시 스템 및 그 방법을 제공하는데 그 목적이 있다."}
{"patent_id": "10-2020-0069252", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "일 실시예에 따른 매장 픽업 서비스를 제공하기 위한 로봇 시스템은, 상품 특성 정보 및 상품 수령 매장 정보에 기초하여 가상 환경을 구축하고, 상기 가상 환경 내에서 포장재 내 상품을 적재하는 순서 및 배치 위치 좌표값 을 출력하는 인공지능 스케줄 모델을 학습하고, 또한 상품을 파지, 적출, 적재하는 로봇의 각 구성요소들의 동 작값 및 동작속도를 출력하는 인공지능 동작 모델을 학습하는 시뮬레이터; 상기 시뮬레이터의 학습을 제어하고, 사용자의 주문 상품들의 정보 및 주문 상품들을 수령할 매장의 정보를 포함하는 주문 상품 리스트를 수신하며, 수신된 주문 상품 리스트에 기초하여 상기 학습된 인공지능 스케줄 모델 및 상기 인공지능 동작 모델을 로봇 제 어부로 전달하는 중앙 통제부; 및 상기 학습된 인공지능 스케줄 모델을 통해 상기 주문 상품들의 포장재 내 적 재 순서 및 배치 위치 좌표값을 생성하고, 상기 학습된 인공지능 동작 모델을 통해 상기 주문 상품들의 포장재 내 적재 순서 및 배치 위치 좌표값에 따른 상기 주문 상품들을 파지, 적출, 적재하는 로봇의 각 구성요소들의 동작값 및 동작속도를 생성하여, 상기 주문 상품들을 수령할 매장의 로봇을 제어하는 상기 로봇 제어부를 포함 한다. 상기 시뮬레이터는, 상기 가상 환경 내에서 가상의 상품, 선반, 포장재 및 장애물을 포함하는 가상 모델을 촬영 하는 가상 카메라; 상기 가상 카메라의 촬영 영상을 분석하여 상기 가상 모델의 정보를 분석하는 가상 영상 분 석부; 전체 상품들의 상품 특성 정보를 분석하여 상품들의 훼손이 없는 제1임시 상품 적재 순서를 생성하는 가 상 상품 분석부; 상기 가상 모델의 분석 결과와, 상기 제1임시 상품 적재 순서와, 상기 상품 특성 정보 및 상기 상품 수령 매장 정보를 이용하여, 포장재 내 상품을 적재하는 순서 및 배치 위치 좌표값을 출력하는 인공지능 스케줄 모델을 학습하는 AI 스케줄 모델 학습부; 및 상기 가상 모델의 분석 결과와, 상기 상품 특성 정보 및 상 기 상품 수령 매장 정보를 이용하여, 상품을 파지, 적출, 적재하는 로봇의 각 구성요소들의 동작값 및 동작속도 를 출력하는 인공지능 동작 모델을 학습하는 AI 동작 모델 학습부;를 포함할 수 있다. 상기 인공지능 스케줄 모델은, 복수의 로봇에 대해 로봇 간 동작 시간 순서를 더 출력하고, 상기 인공지능 동작 모델은, 상기 동작 시간 순서에 따른 각 로봇의 구성요소들의 최적의 동작값 및 동작속도를 출력할 수 있다. 상기 가상 환경에 대해 하나의 인공지능 스케줄 모델이 생성되어 학습되고, 상기 가상 환경 내의 각 로봇의 종 류별로 인공지능 동작 모델이 생성되어 학습되며, 상기 하나의 인공지능 스케줄 모델이 각 인공지능 동작 모델 로 대응하는 로봇의 동작 시간 순서를 출력할 수 있다. 상기 가상 영상 분석부는, 가상 상품의 경우, 상품 종류, 위치, 크기, 2차원 또는 3차원 자세, 무게 중심점을 분석하고, 가상 포장재의 경우, 포장재의 종류, 위치, 크기, 2차원 또는 3차원 자세, 공간 점유율을 분석하며, 가상 선반의 경우, 선반의 위치, 2차원 또는 3차원 크기를 분석하고, 가상 장애물의 경우, 장애물의 위치, 2차 원 또는 3차원 크기를 분석할 수 있다. 상기 상품 특성 정보는, 상품의 상품명, 상품 이미지, 가격, 크기, 형태, 무게, 강도, 포장 재질 및 재고량을 포함하고, 상기 상품 수령 매장 정보는, 각 매장별 정보로서, 포장재 정보, 로봇 정보, 카메라 정보 및 선반 정 보를 포함할 수 있다. 상기 로봇 제어부는, 상기 주문 상품들을 수령할 매장에 설치된 카메라로부터 촬영 영상을 수신하고, 수신된 촬 영 영상에서 상품, 선반, 포장재 및 장애물을 분석하는 영상 분석부; 상기 주문 상품들의 상품 특성 정보를 분 석하여 제2임시 상품 적재 순서를 생성하는 상품 분석부; 상기 영상 분석부의 분석 결과와, 상기 제2임시 상품 적재 순서와, 상기 주문 상품들의 상품 특성 정보 및 상기 주문 상품들을 수령할 매장의 정보를 이용하여, 상기 학습된 인공지능 스케줄 모델을 통해 포장재 내 상품을 적재하는 순서 및 배치 위치 좌표값을 출력하는 AI 스케 줄 모델 추론부; 상기 영상 분석부의 분석 결과와, 상기 주문 상품들의 상품 특성 정보 및 상기 주문 상품들을 수령할 매장의 정보와, 상기 학습된 인공지능 스케줄 모델의 출력값에 기초하여, 상기 주문 상품들을 파지, 적출, 적재하는 로봇의 각 구성요소들의 동작값 및 동작속도를 출력하는 상기 학습된 인공지능 동작 모델을 통해 출력하는 AI 동작 모델 추론부; 및 상기 AI 동작 모델 추론부의 출력값에 따라 상기 상품을 수령할 매장의 로봇 을 제어하는 로봇 조작부를 포함할 수 있다. 상기 학습된 인공지능 스케줄 모델은, 복수의 로봇에 대해 로봇 간 동작 시간 순서를 더 출력하고, 상기 학습된 인공지능 동작 모델은, 상기 동작 시간 순서에 따른 각 로봇의 구성요소들의 최적의 동작값 및 동작속도를 출력 할 수 있다. 일 실시예에 따른 로봇 시스템에서 매장 픽업 서비스를 제공하는 방법은, 상품 특성 정보 및 상품 수령 매장 정 보에 기초하여 가상 환경을 구축하고, 상기 가상 환경 내에서 포장재 내 상품을 적재하는 순서 및 배치 위치 좌 표값을 출력하는 인공지능 스케줄 모델을 학습하고, 또한 상품을 파지, 적출, 적재하는 로봇의 각 구성요소들의 동작값 및 동작속도를 출력하는 인공지능 동작 모델을 학습하는 단계; 사용자의 주문 상품들의 정보 및 상품을 수령할 매장의 정보를 포함하는 주문 상품 리스트를 수신하고, 수신된 주문 상품 리스트에 기초하여 상기 학습 된 인공지능 스케줄 모델 및 상기 인공지능 동작 모델을 선택하는 단계; 선택된 상기 학습된 인공지능 스케줄 모델을 통해 상기 주문 상품들의 포장재 내 적재 순서 및 배치 위치 좌표값을 생성하고, 선택된 상기 학습된 인 공지능 동작 모델을 통해 상기 주문 상품들의 포장재 내 적재 순서 및 배치 위치 좌표값에 따른 상기 주문 상품 들을 파지, 적출, 적재하는 로봇의 각 구성요소들의 동작값 및 동작속도를 생성하는 단계; 및 상기 동작값 및 동작속도에 따라 상기 주문 상품들을 수령할 매장의 로봇을 제어하는 단계를 포함한다. 상기 학습하는 단계는, 가상 카메라를 이용하여 상기 가상 환경 내에서 가상의 상품, 선반, 포장재 및 장애물을 포함하는 가상 모델을 촬영하는 단계; 상기 가상 카메라의 촬영 영상을 분석하여 상기 가상 모델의 정보를 분석 하는 단계; 전체 상품들의 상품 특성 정보를 분석하여 상품들의 훼손이 없는 제1임시 상품 적재 순서를 생성하 는 단계; 상기 가상 모델의 분석 결과와, 상기 제1임시 상품 적재 순서와, 상기 상품 특성 정보 및 상기 상품 수령 매장 정보를 이용하여, 포장재 내 상품을 적재하는 순서 및 배치 위치 좌표값을 출력하는 인공지능 스케줄 모델을 학습하는 단계; 및 상기 가상 모델의 분석 결과와, 상기 상품 특성 정보 및 상기 상품 수령 매장 정보를 이용하여, 상품을 파지, 적출, 적재하는 로봇의 각 구성요소들의 동작값 및 동작속도를 출력하는 인공지능 동작 모델을 학습하는 단계를 포함할 수 있다. 상기 인공지능 스케줄 모델은, 복수의 로봇에 대해 로봇 간 동작 시간 순서를 더 출력하고, 상기 인공지능 동작 모델은, 상기 동작 시간 순서에 따른 각 로봇의 구성요소들의 최적의 동작값 및 동작속도를 출력할 수 있다. 상기 가상 환경에 대해 하나의 인공지능 스케줄 모델이 생성되어 학습되고, 상기 가상 환경 내의 각 로봇의 종 류별로 인공지능 동작 모델이 생성되어 학습되며, 상기 하나의 인공지능 스케줄 모델이 각 인공지능 동작 모델 로 대응하는 로봇의 동작 시간 순서를 출력할 수 있다. 상기 가상 모델의 정보를 분석하는 단계는, 가상 상품의 경우, 상품 종류, 위치, 크기, 2차원 또는 3차원 자세, 무게 중심점을 분석하고, 가상 포장재의 경우, 포장재의 종류, 위치, 크기, 2차원 또는 3차원 자세, 공간 점유 율을 분석하며, 가상 선반의 경우, 선반의 위치, 2차원 또는 3차원 크기를 분석하고, 가상 장애물의 경우, 장애 물의 위치, 2차원 또는 3차원 크기를 분석할 수 있다. 상기 상품 특성 정보는, 상품의 상품명, 상품 이미지, 가격, 크기, 형태, 무게, 강도, 포장 재질 및 재고량을 포함하고, 상기 상품 수령 매장 정보는, 각 매장별 정보로서, 포장재 정보, 로봇 정보, 카메라 정보 및 선반 정 보를 포함할 수 있다. 상기 생성하는 단계는, 상기 주문 상품들을 수령할 매장에 설치된 카메라로부터 촬영 영상을 수신하고, 수신된 촬영 영상에서 상품, 선반, 포장재 및 장애물을 분석하여 제1분석 결과를 출력하는 단계; 상기 주문 상품들의 상품 특성 정보를 분석하여 제2임시 상품 적재 순서를 생성하는 단계; 상기 제1분석 결과와, 상기 제2임시 상품 적재 순서와, 상기 주문 상품들의 상품 특성 정보 및 상기 주문 상품들을 수령할 매장의 정보를 이용하여, 상기 학습된 인공지능 스케줄 모델을 통해 포장재 내 상품을 적재하는 순서 및 배치 위치 좌표값을 출력하는 단계; 및 상기 제1분석 결과와, 상기 주문 상품들의 상품 특성 정보 및 상기 주문 상품들을 수령할 매장의 정보와, 상 기 학습된 인공지능 스케줄 모델의 출력값에 기초하여, 상기 주문 상품들을 파지, 적출, 적재하는 로봇의 각 구 성요소들의 동작값 및 동작속도를 출력하는 상기 학습된 인공지능 동작 모델을 통해 출력하는 단계를 포함할 수 있다. 상기 학습된 인공지능 스케줄 모델은, 복수의 로봇에 대해 로봇 간 동작 시간 순서를 더 출력하고, 상기 학습된 인공지능 동작 모델은, 상기 동작 시간 순서에 따른 각 로봇의 구성요소들의 최적의 동작값 및 동작속도를 출력할 수 있다."}
{"patent_id": "10-2020-0069252", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명은, 가상 환경 내에서 다양한 환경에 대해 인공지능 모델을 학습함으로써 명령 입력이나 티칭 과정 없이 실제 환경에 적용이 수월하다는 이점이 있다. 또한, 본 발명은 상품 훼손을 방지하기 위해서 상품 특성 정보를 고려하여 상품의 적재 순서를 결정하고 또한 로봇의 파지 위치나 파지력을 결정함으로써 자동화된 매장 픽업 서비스에서 상품 훼손을 방지한다. 본 발명은 인공지능 모델을 통해 다수의 로봇이 동선이 겹치지 않도록 상품의 적재/적출의 순서를 결정하거나 동작 수행 속도를 제어하여 다수의 로봇을 이용하여 빠른 상품 포장이 가능하다. 본 발명은 인공지능 스케줄 모델과 인공지능 동작 모델로 태스크를 분리하여 학습하고 분산 수행하기 때문에 신 경망의 층이 상대적으로 얕아 학습 속도 및 추론 속도가 상대적으로 빠른 이점이 있다. 본 발명은 인공지능 스케줄 모델과 인공지능 동작 모델을 분리하여 학습하고 실행하기 때문에 종래의 통합 모델 에 비해 학습 속도를 높일 수 있고 다양한 환경에 유연하게 대처할 수 있다. 본 발명은, 인공지능 스케줄 모델과 인공지능 동작 모델을 분리하고, 각 로봇의 종류에 대응하는 각 인공지능 동작 모델 간에 보상을 공유하지 않으며, 하나의 인공지능 스케줄 모델에서 각 로봇의 동작 순서를 결정하는 방 식으로 학습하기 때문에, 픽업 서비스를 제공하는 환경이 변하더라도 추가적으로 인공지능 동작 모델을 학습하 지 않고 인공지능 스케줄 모델만을 학습을 수행하므로 학습 수행 시간을 줄이고 빠른 수행 환경 적용이 가능하 다."}
{"patent_id": "10-2020-0069252", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "상술한 목적, 특징 및 장점은 첨부된 도면과 관련한 다음의 상세한 설명을 통하여 보다 분명해 질 것이며, 그에"}
{"patent_id": "10-2020-0069252", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "따라 본 발명이 속하는 기술분야에서 통상의 지식을 가진 자가 본 발명의 기술적 사상을 용이하게 실시할 수 있 을 것이다. 또한, 본 발명을 설명함에 있어서 본 발명과 관련된 공지 기술에 대한 구체적인 설명이 본 발명의 요지를 불필요하게 흐릴 수 있다고 판단되는 경우에 그 상세한 설명을 생략하기로 한다. 이하, 첨부된 도면을 참조하여 본 발명에 따른 바람직한 일 실시예를 상세히 설명하기로 한다. 도 1은 본 발명의 일 실시예에 따른 매장 픽업 서비스의 전체 시스템의 구성을 나타낸 도면이다. 도 1을 참조하 면, 본 실시예에 따른 전체 시스템은, 명령부, 로봇 시스템, 동작부, 스캐너 및 상품 수령 부를 포함할 수 있다. 명령부는, 모바일 단말, 퍼스널 컴퓨터, 태블릿 PC, 키오스크 등의 사용자가 상품을 주문하는데 활용되는 장치이다. 명령부는, 구매하려는 상품의 종류와 수량을 선택, 취소 및 결제를 수행할 수 있고, 상품을 수 령할 매장을 선택할 수 있는 기능을 제공한다. 명령부는, 결제가 완료된 상품들의 상품 정보와 수령 매장 정보를 포함하는 주문 상품 리스트를 로봇 시스템으로 전송한다. 명령부는, 매장 내 로컬 서버와 연 결되어 재고 정보를 실시간으로 업데이트하는 상품 정보 서버 또는 로봇 시스템과 통신하여 각 매장의 상 품 정보를 저장하고 사용자에게 각 매장별 상품 정보를 제공할 수 있고, 온라인 결제를 수행할 수 있다.로봇 시스템은, 전체 상품 특성 정보와 상품 수령 매장 정보에 따라 구축된 가상 환경 내에서 상품 분석 모델과 영상 분석 모델, 그리고 인공지능 스케줄 모델 및 인공지능 동작 모델을 학습하고, 학습이 완료된 상품 분석 모델과 영상 분석 모델, 그리고 인공지능 스케줄 모델 및 인공지능 동작 모델을 이용하여, 상기 명령부 로부터 수신된 상기 주문 상품 리스트에 기초하여 상기 동작부의 로봇을 제어하여 사용자가 주 문한 상품들이 포장재에 포장되도록 한다. 상기 상품 분석 모델은, 전체 상품들의 상품 특성 정보(예, 수량, 크기, 형태, 무게, 강도, 무게 중심점, 포장 재질 등)를 분석하여 상품들의 훼손이 없는 상품 적재 순서를 출력한다. 상기 영상 분석 모델은 가상 모델들, 즉 가상 상품들, 가상 포장재, 가상 선반 그리고 가상 장애물을 분석한다. 구체적으로 가상 상품들의 경우, 상품 종류, 위치, 크기, 2차원 또는 3차원 자세, 무게 중심점을 분석한다. 가 상 포장재의 경우, 포장재의 종류, 위치, 크기, 2차원 또는 3차원 자세, 공간 점유율을 분석한다. 가상 선반의 경우, 선반의 위치, 2차원 또는 3차원 크기를 분석한다. 가상 장애물의 경우, 장애물의 위치, 2차원 또는 3차원 크기를 분석한다. 상기 인공지능 스케줄 모델은, 상품 적재 순서, 포장재 내 상품 배치 위치, 복수의 로봇 간 동작 시간 순서 등 을 포함하는 최적의 스케줄을 생성한다. 상기 인공지능 동작 모델은, 상품을 파지, 적출, 적재하는 최적의 동작값 및 동작속도를 생성한다. 여기서 동작 값은, 로봇을 구성하는 구성요소들(예, 구동부, 몸체, 링크, 엔드 이펙터 등)의 회전력, 회전 범위, 구동 범위, 파지력, 흡착력 등을 포함한다. 로봇 시스템은 전체 구성요소가 인터넷 상의 서버(예, 클라우드)를 활용하여 구축되어 RaaS(Robot as a service) 방식으로 동작하거나 일부 구성요소만 인터넷 상의 서버를 활용하여 구축되고 나머지 구성요소는 매장 의 로컬 서버에서 동작하도록 구현될 수도 있다. 동작부는, 하나 또는 둘 이상의 카메라와, 하나 또는 둘 이상의 로봇을 포함하여 상기 로봇 시 스템의 제어에 따라 사용자가 주문한 상품들을 픽업하여 포장재에 포장한다. 카메라는 상품, 선반, 포장재, 장애물, 로봇 등을 실시간 촬영하여 로봇 시스템으로 전송하고, 로봇은 로봇 시스템 으로부터 수신되는 로봇 제어 명령에 따라 상품 포장의 태스크(task)를 수행한다. 카메라는 단안 또 는 스테레오 형태의 카메라로서, 매장 내에 고정된 위치에 적어도 하나 이상 설치될 수 있고, 또는 로봇에 설치될 수도 있다. 명령부, 로봇 시스템 및 동작부는 상호 간에 이동통신(4G/5G 등), 와이파이(Wi-Fi), 블루투스 등의 무선 통신으로 통신할 수 있고, 또는 유선 통신으로 통신할 수 있으나 그 통신 방식은 특별히 제한되지 않 는다. 스캐너는 예를 들어 QR 스캐너 또는 바코드 스캐너 등의 사용자 식별정보를 스캔하여 인증하는 장비이다. 스캐너는 사용자가 휴대하는 카드나 모바일 단말에서 QR 코드 또는 바코드 등의 사용자 식별정보를 읽어, 상품을 주문한 사용자가 맞는지 확인한다. 상품 수령부는 도 1에 도시된 바와 같이, 로봇에 의해 포 장된 상품을 수령할 수 있는 상품 보관 용기 등을 포함한다. 이하에서 도면을 참조하여 도 1에 도시된 각 구성요소를 보다 자세히 설명한다. 도 2는 도 1의 명령부의 구성을 나타낸 도면이다. 도 2를 참조하면, 명령부는, 통신부, 사용자 인터 페이스부 및 리스트 생성부를 포함한다. 통신부는, 로봇 시스템 또는 상품 정보 서버와 통신하여, 로봇 시스템 또는 상품 정보 서버로부 터 전체 상품명, 상품 이미지, 상품 가격, 재고량, 상품 수령 가능 매장명, 매장 위치 정보 등을 수신하고, 사 용자에 의해 선택되고 결제가 완료된 상품들의 상품 정보와 수령 매장 정보를 포함하는 주문 상품 리스트를 로 봇 시스템으로 전송한다. 통신부는, 외부 포트를 통한 통신 또는 RF 신호에 의한 통신을 수행한다. 통신 회로는 전기 신호를 RF 신 호로 또는 그 반대로 변환하며 이 RF 신호를 통하여 통신 네트워크, 다른 이동형 게이트웨이 장치 및 통신 장치 와 통신할 수 있다. 사용자 인터페이스부는, 상기 통신부에서 수신한 전체 상품명, 상품 이미지, 상품 가격, 재고량, 상 품 수령 가능 매장명, 매장 위치 정보 등을 화면에 표시하고 결제 기능을 제공한다. 화면은 상품 이미지를 표시하는 상품 디스플레이 레이어, 상품의 수량을 선택하는 추가/삭제 버튼, 선택한 상품들의 리스트 및 총 금액을 표시하는 선택 상품 리스트 레이어, 선택 상품을 확정하는 확인 버튼, 선택 상품을 취소하는 취소 버튼, 선택 상품 리스트를 수정하는 수정 버튼 및 결제를 위한 기능으로 구현될 수 있다. 본 실시예에서는 결제와 관련하여 특별히 설명하지 않는다. 공지된 다양한 결제 시스템 및 추후 개발된 다양한 결제 시스템을 사용자 인터페이스 부와 연동할 수 있다. 리스트 생성부는, 사용자가 상기 사용자 인터페이스부를 통해 선택한 상품명과 그 수량, 사용자 식별 자(ID), 상품 수령 매장 정보를 문자 자료형 또는 숫자 자료형으로 표현한 주문 상품 리스트를 생성한다. 상기 사용자 인터페이스부와 상기 리스트 생성부는 프로그램으로 구현되어 메모리에 저장되고, 적어도 하 나 이상의 프로세서에 의해 실행될 수 있고, 또는 하드웨어와 소프트웨어의 조합에 의해 구현되어 동작할 수 있 다. 도 3은 도 1의 로봇 시스템의 구성을 나타낸 도면이다. 도 3을 참조하면, 로봇 시스템은, 저장부, 시 뮬레이터, 중앙 통제부 및 로봇 제어부를 포함한다. 로봇 시스템은, 메모리, 적어도 하나 이상의 프로세서, 통신 회로를 포함할 수 있고, 상기 저장부, 시뮬레이터, 중앙 통제부 및 로봇 제어부는 프로그램으로 구현되어 메모리에 저장되고 적어도 하나 이상의 프로세서에 의해 실행되어 동작하 거나, 하드웨어 및 소프트웨어의 조합으로 구현되어 동작할 수 있다. 저장부는, 상품 특성 정보 및 상품 수령 매장 정보를 저장한다. 상기 상품 특성 정보는, 전체 상품의 상품 명, 상품 이미지, 가격, 크기, 형태, 무게, 강도, 포장 재질 및 재고량을 포함한다. 상기 상품 수령 매장 정보 는, 각 매장별 정보로서, 포장재 정보, 로봇 정보, 카메라 정보 및 선반 정보를 포함한다. 포장재 정보는, 매장 에 구비되는 전체 포장재 종류(예, 장바구니, 종이백, 플라스틱백, 비닐 봉지 등), 규격을 포함한다. 로봇 정보 는 매장에 설치된 로봇의 타입(예, 고정형 매니퓰레이터, 직교 좌표 로봇, 바퀴형 이동 로봇, 매니퓰레이터 장 착 바퀴형 이동 로봇 등), 규격, 수량 및 장착 센서 사양을 포함한다. 카메라 정보는 매장에 구비되는 전체 카 메라의 종류, 수량 및 설치 위치를 포함한다. 선반 정보는, 매장에 구비되는 선반의 규격, 형태, 칸 수, 수량, 매장 내 위치를 포함한다. 또한, 저장부는, 학습된 상품 분석 모델과 영상 분석 모델, 그리고 학습된 인공지능 스케줄 모델과 인공지 능 동작 모델을 저장한다. 바람직하게, 저장부는, 인공지능 동작 모델에 대해서는 로봇별로 학습된 인공지 능 동작 모델을 저장할 수 있다. 인공지능 스케줄 모델과 인공지능 동작 모델은, 숫자 자료형으로 표현된 것으 로, 예컨대 심층 신경망 가중치를 포함할 수 있다. 시뮬레이터는, 상품 수령 매장의 픽업 서비스 환경을 표현한 가상 환경 내에서 상품 분석 모델과 영상 분 석 모델, 그리고 인공지능 스케줄 모델 및 인공지능 동작 모델을 학습한다. 바람직하게, 시뮬레이터는, 상 기 저장부에 저장된 상품 특성 정보 및 상품 수령 매장 정보에 기초하여 3차원 가상 환경을 구축하고, 3차 원 가상 환경 내에서 상품 분석 모델과 영상 분석 모델을 학습하고, 또한 로봇에 대한 인공지능 스케줄 모 델과 인공지능 동작 모델을 학습한다. 인공지능 동작 모델의 경우, 시뮬레이터는 각 로봇별로 인공지능 동 작 모델을 학습한다. 중앙 통제부는 로봇 시스템의 전반적인 동작을 제어한다. 중앙 통제부는, 상기 저장부에 저장된 상품 특성 정보 및 상품 수령 매장 정보를 상기 시뮬레이터로 전달하여 학습을 명령하고, 학습이 완료된 상품 분석 모델과 영상 분석 모델, 그리고 인공지능 스케줄 모델과 인공지능 동작 모델을 저장부에 저장한다. 중앙 통제부는, 명령부로부터 사용자의 주문 상품 리스트를 수신하면, 수신된 주문 상품 리스트에 포 함된 상품 수령 매장 정보에 기초하여 저장부에서 사용자가 방문할 매장과 동일 또는 가장 유사한 가상 환 경에서 학습된 상품 분석 모델과 영상 분석 모델 그리고 인공지능 스케줄 모델과 인공지능 동작 모델을 검색하 고, 검색된 상품 분석 모델과 영상 분석 모델 그리고 인공지능 스케줄 모델과 인공지능 동작 모델 그리고 주문 상품 리스트를 로봇 제어부로 전달한다. 중앙 통제부는, 로봇이 복수인 경우, 로봇별 인공지능 동작 모델을 로봇 제어부로 전달할 수 있다. 중앙 통제부는, 로봇 제어부로부터 사용자의 주문 상품들에 대한 매장 픽업 서비스의 실제 동작 결과 인 로봇 피드백 정보를 수신하고, 수신된 로봇 피드백 정보를 시뮬레이터로 전달하여, 시뮬레이터에 서 상품 분석 모델과 영상 분석 모델 그리고 인공지능 스케줄 모델과 인공지능 동작 모델을 재학습하도록 제어 한다.로봇 제어부는, 상기 중앙 통제부로부터 전달된 상품 분석 모델, 영상 분석 모델, 인공지능 스케줄 모델과, 인공지능 동작 모델 그리고 주문 상품 리스트를 이용하여, 상품들의 적재 순서, 포장재 내 상품 배치 위치, 복수의 로봇 간 동작 시간 순서 등을 포함하는 최적의 스케줄, 그리고, 상품을 파지, 적출, 적재하는 최 적의 동작값 및 동작속도를 생성한다. 여기서 동작값은, 로봇을 구성하는 구성요소들(예, 구동부, 몸체, 링크, 엔드 이펙터 등)의 회전력, 회전 범위, 구동 범위, 파지력, 흡착력 등을 포함한다. 로봇 제어부는, 상기 생성한 최적의 스케줄과, 상기 최적의 동작값 및 동작속도를 이용하여 동작부의 단일 또는 다수의 로봇의 스케줄 및 동작을 제어하기 위한 로봇 제어 명령을 동작부로 전달한다. 또한 로 봇 제어부는, 동작부의 실제 동작 결과인 로봇 피드백 정보를 상기 중앙 통제부로 전달한다. 도 4는 도 3의 시뮬레이터의 구성을 나타낸 도면이다. 도 4를 참조하면, 본 실시예에 따른 시뮬레이터는, 가상 카메라, 가상 영상 분석부, 가상 상품 분석부, AI 스케줄 모델 학습부 및 AI 동작 모 델 학습부 및 가상 로봇를 포함한다. 가상 카메라는, 시뮬레이터에 의해 구축된 3차원 가상 환경 내에서 가상의 상품, 선반, 포장재, 장애 물, 로봇 등의 가상 모델을 실시간으로 촬영한 영상을 생성한다. 여기서 가상 카메라는 단안 또는 스테레 오 형태의 실제 로봇 장착 카메라 또는 매장 내 고정된 위치에 장착되는 카메라와 동일한 해상도, 초당 프레임 수(fps), 수량, 장착 위치를 가상 모델로 표현한 가상 카메라 모델이다. 가상 영상 분석부는, 상기 가상 카메라에 의해 실시간 촬영된 영상을 기초로 가상 모델들, 즉 가상 상품들, 가상 포장재, 가상 선반 그리고 가상 장애물을 분석하는 영상 분석 모델을 학습한다. 구체적으로 가상 상품들의 경우, 상품 종류, 위치, 크기, 2차원 또는 3차원 자세, 무게 중심점을 분석한다. 가상 포장재의 경우, 포장재의 종류, 위치, 크기, 2차원 또는 3차원 자세, 공간 점유율을 분석한다. 가상 선반의 경우, 선반의 위치, 2차원 또는 3차원 크기를 분석한다. 가상 장애물의 경우, 장애물의 위치, 2차원 또는 3차원 크기를 분석한다. 바람직하게, 가상 영상 분석부는, 머신 러닝(Machine Learning) 또는 딥 러닝(Deep Learning) 기술로 가 상 영상 분석 모델을 학습한다. 가상 상품 분석부는, 전체 상품들의 상품 특성 정보(예, 수량, 크기, 형태, 무게, 강도, 무게 중심점, 포 장 재질 등)를 분석하여 상품들의 훼손이 없는 상품 적재 순서를 생성하는 상품 분석 모델을 학습한다. 상품 분 석 모델은, 전체 상품들에 대해 여러 조합으로 결정되는 상품들의 상품 적재 순서를 생성한다. 바람직하게, 가 상 상품 분석부는, 머신 러닝(Machine Learning) 또는 딥 러닝(Deep Learning) 기술로 가상 상품 분석 모 델을 학습할 수 있다. 가상 상품 분석부에서 상품 분석 모델을 통해 생성되는 상품 적재 순서는 임시적인 것으로, AI 스케줄 모 델 학습부에서 최종 조정되어 결정된다. 즉, 적재 순서에 상관 없는 유사 특성을 갖는 상품들이 있을 경우, 가상 상품 분석부는 그 상품들의 적재 순서를 동일 순서로 정하지만, AI 스케줄 모델 학습부에 서는 로봇 팔의 위치 등을 고려하여 적재 순서를 최종 결정하게 된다. 가상 상품 분석부는 AI 스케줄 모델 학습부에서 상품 적재 순서를 학습하는데 있어 부하를 줄여주기 위해 사전에 먼저 상품 적재 순서를 학습 하여 AI 스케줄 모델 학습부로 제공하므로, 실시예에 따라서는 가상 상품 분석부는 생략되어도 무방 하다. AI 스케줄 모델 학습부는, 단일 가상 로봇의 경우, 상기 가상 영상 분석부에서 영상 분석 모델을 통 해 분석한 가상 모델들의 분석 결과와, 상기 가상 상품 분석부에서 생성된 상품 적재 순서, 그리고 상품 특성 정보 및 상품 수령 매장 정보를 이용하여, 상품 훼손 및 포장재 공간을 고려하여 포장재 내 상품을 적재하 는 순서와 포장재 내 상품 배치 위치 좌표값을 예측 및 출력하는 인공지능 스케줄 모델을 생성하고 학습한다. AI 스케줄 모델 학습부는, 다수의 가상 로봇의 경우, 상품의 적재 순서 및 포장재 내 상품 배치 위치 좌표 값 이외에, 복수의 로봇 간 동작 시간 순서를 더 예측 및 출력하는 인공지능 스케줄 모델을 생성하고 학습한다. AI 스케줄 모델 학습부는, 인공지능 스케줄 모델의 학습시, 각 인공지능 동작 모델들의 행동(Action)에 대 한 보상(Reward)을 가상 환경으로부터 전달받아 AI 동작 모델 학습부로 정보를 공유하여 심층 강화 학습을 한다. 예컨대, AI 스케줄 모델 학습부는, AI 동작 모델 학습부로 상품 적재 순서, 포장재 내 상품 배 치 위치 좌표값, 그리고 복수의 로봇 간 동작 시간 순서를 전달하여 공유한다. AI 동작 모델 학습부는, 단일 가상 로봇의 경우, 상기 가상 영상 분석부의 분석한 가상 모델들의 분 석 결과와, 그리고 상품 특성 정보 및 상품 수령 매장 정보를 이용하여, 상품을 파지, 적출, 적재하는 로봇의 각 구성요소들의 최적의 동작값 및 동작속도를 예측 및 출력하는 인공지능 동작 모델을 생성하고 학습한다. 여기서 동작값은, 로봇을 구성하는 구성요소들(예, 구동부, 몸체, 링크, 엔드 이펙터 등)의 회전력, 회전 범위, 구동 범위, 파지력, 흡착력 등을 포함한다. AI 동작 모델 학습부는, 복수의 가상 로봇의 경우, 로봇의 각 구성요소들의 최적의 동작값 및 동작속도를, 상기 AI 스케줄 모델 학습부에서 공유하는 복수의 로봇 간 동작 시간 순서를 더 고려하여, 동작 시간 순서 에 따른 각 로봇의 구성요소들의 최적의 동작값 및 동작속도를 예측 및 출력하는 인공지능 동작 모델을 각 로봇 의 종류별로 생성하고 학습한다. 바람직하게, AI 스케줄 모델 학습부 및 AI 동작 모델 학습부는, 사람의 개입 없이 사전 상태 (Previous State), 행동(Action), 사후 상태(Next State), 보상(Reward)를 통해 스스로 학습하는 심층 강화 학 습(Reinforcement Learning) 기반으로 학습한다. 여기서 상태(State)는 상품의 훼손이 없으며 포장재 내 공간 효율성을 고려한 적재 순서와, 가상 상품들의 종류, 위치, 크기, 2차원 또는 3차원 자세, 무게 중심점, 포장재 의 종류/위치/크기/2차원 또는 3차원 자세/공간 점유율, 선반의 위치/2차원 또는 3차원 크기 및, 장애물의 위치 /2차원 또는 3차원 크기 정보이다. 행동은 상품의 피킹, 적재, 스캔, 장애물 회피 등 로봇의 임무 수행시 매니 퓰레이터 각 관절 및 엔드 이팩터의 동작뿐만 아니라 바퀴형 이동 로봇의 이동을 포함하는 최적의 2차원 또는 3 차원 연속 동작 경로 및 시간 정보와, 상품의 피킹, 적재, 스캔 등 로봇의 임무를 수행하기 위한 스케줄 관리, 에러 확인 등 운용 계획 및 시간 정보이다. 보상은 행동에 대한 평가로써 소요 시간, 상품 훼손 정도, 최적 동 작 경로, 포장재 내 공간 효율 등을 임무에 따라 평가 요소로 선택할 수 있다. 가상 로봇은, 상기 AI 스케줄 모델 학습부에서 출력되는 상품 적재 순서와 포장재 내 상품 배치 위치 좌표값, 그리고 상기 AI 동작 모델 학습부에서 출력되는 로봇의 각 구성요소들의 최적의 동작값 및 동작속 도을 기초로 상품 포장의 태스크를 수행하고, 그 수행 결과를 AI 스케줄 모델 학습부 및 AI 동작 모델 학 습부로 피드백한다. AI 스케줄 모델 학습부 및 AI 동작 모델 학습부는 피드백 결과에 따라 학습 을 반복 수행함으로써, 최적의 모델을 생성한다. 도 5는 도 3의 로봇 제어부의 구성을 나타낸 도면이다. 도 5를 참조하면, 본 실시예에 따른 로봇 제어부는, 영상 분석부, 상품 분석부, AI 스케줄 모델 추론부, AI 동작 모델 추론부 및 로봇 조작부를 포함한다. 영상 분석부는, 상기 시뮬레이터 내 가상 영상 분석부에서 학습한 영상 분석 모델을 통해 매장 내 카메라에 의해 실시간 촬영된 영상을 분석하여 사용자가 주문한 상품들, 포장재, 선반 그리고 장애물을 분석한다. 구체적으로 사용자가 주문한 상품들의 경우, 상품 종류, 위치, 크기, 2차원 또는 3차원 자세, 무게 중심점을 분석한다. 포장재의 경우, 포장재의 종류, 위치, 크기, 2차원 또는 3차원 자세, 공간 점유율을 분석한 다. 선반의 경우, 선반의 위치, 2차원 또는 3차원 크기를 분석한다. 장애물의 경우, 장애물의 위치, 2차원 또는 3차원 크기를 분석한다. 상품 분석부는, 시뮬레이터 내 가상 상품 분석부에서 학습한 상품 분석 모델을 통해, 주문 상품 리스트에 기초하여 사용자가 주문한 상품들의 상품 특성 정보(예, 수량, 크기, 형태, 무게, 강도, 포장 재질 등)를 분석하여 상품 적재 순서를 생성한다. 여기서의 상품 적재 순서는 임시 상품 적재 순서이다. 시뮬레이터 내의 가상 상품 분석부와 마찬가지로, 상품 분석부는 AI 스케줄 모델 추론부에서 주문 상 품들의 최종 상품 적재 순서를 생성하는데 있어 부하를 줄여주기 위해 사전에 먼저 상품 적재 순서를 생성하는 것으로 실시 형태에 따라서는 상품 분석부는 없어도 무방하다. AI 스케줄 모델 추론부는, 사용자가 상품을 수령할 매장에 대응하는 인공지능 스케줄 모델을 중앙 통제부 로부터 수신하고, 그 수신된 인공지능 스케줄 모델에 기초하여, 단일 로봇의 경우, 상기 영상 분석부(24 1)의 상품들, 포장재, 선반 그리고 장애물의 분석 결과와, 상기 상품 분석부에서 생성된 상품 적재 순서, 그리고 상품 특성 정보 및 상품 수령 매장 정보를 이용하여, 상품 훼손 및 포장재 공간을 고려하여 포장재 내 상품을 적재하는 순서와 포장재 내 상품 배치 위치 좌표값을 AI 동작 모델 추론부로 출력한다. AI 스케줄 모델 추론부는, 다수의 로봇의 경우, 상품의 적재 순서 및 포장재 내 상품 배치 위치 좌표값 이외에, 복수 의 로봇 간 동작 시간 순서를 더 출력한다. AI 동작 모델 추론부는, 사용자가 상품을 수령할 매장의 각 로봇의 종류에 대응하는 인공지능 동작 모델을 중앙 통제부로부터 수신하고, 그 수신된 인공지능 동작 모델에 기초하여, 상기 AI 스케줄 모델 추론부 로부터 수신되는 상품 적재 순서 및 포장재 내 상품 배치 위치 좌표값에 따라, 상품을 파지, 적출, 적재하 는 로봇의 각 구성요소들의 최적의 동작값 및 동작속도를 출력한다. 여기서 동작값은, 로봇을 구성하는 구성요소들(예, 구동부, 몸체, 링크, 엔드 이펙터 등)의 회전력, 회전 범위, 구동 범위, 파지력, 흡착력 등을 포함한 다. 구체적으로, AI 동작 모델 추론부는, 단일 가상 로봇의 경우, 상기 영상 분석부의 상품들, 포장재, 선반 그리고 장애물의 분석 결과와, 그리고 상품 특성 정보 및 상품 수령 매장 정보를 이용하여, 상기 AI 스케 줄 모델 추론부로부터 수신되는 상품 적재 순서 및 포장재 내 상품 배치 위치 좌표값에 따라, 상품을 파지, 적출, 적재하는 로봇의 각 구성요소들의 최적의 동작값 및 동작속도를 출력한다. AI 동작 모델 추론부는, 복수의 로봇의 경우, 로봇의 각 구성요소들의 최적의 동작값 및 동작속도를, 상기 AI 스케줄 모델 추론부로부터 수신되는 복수의 로봇 간 동작 시간 순서를 더 고려하여, 동작 시간 순서에 따른 각 로봇의 구성요소들의 최적의 동작값 및 동작속도를 출력한다. 로봇 조작부는, 상기 AI 동작 모델 추론부에서 출력되는 로봇의 구성요소들의 최적의 동작값 및 동작 속도에 기초하여, 동작부의 로봇을 제어한다. 로봇 조작부는 로봇 제어 명령을 로봇으로 전송한다. 매장 내에 복수의 로봇이 있는 경우, 로봇 조작부는, 상기 AI 동작 모델 추론부에서 출력 되는 동작 시간 순서에 따른 각 로봇의 구성요소들의 최적의 동작값 및 동작속도에 기초하여, 동작부의 복 수의 로봇을 제어한다. 로봇 조작부는, 로봇으로부터 상품 포장 태스크 수행 결과의 피드백 정 보를 수신하고, 피드백 정보를 중앙 통제부로 전달한다. 이상의 실시예에 따르면, 종래의 주문 상품을 인력을 통해 포장재에 적재하는 방식과 다르게 본 발명의 실시예 에 따르면, 로봇이 상품을 포장재에 적재함으로써 인력 투입을 절약할 수 있다. 종래의 적재 로봇들과 다르게 본 발명의 실시예에 따른 로봇 시스템은 상품 특성 정보(크기, 형태, 무게, 강도, 포장 재질, 수량 등)와 포장재(장바구니, 종이백, 플라스틱백, 비닐봉지 등)의 규격 및 공간 정보, 상품 파지 자세를 고려하여 상품들 이 훼손되지 않는 최적의 적재 순서 및 배치 위치를 자동으로 연산하여 포장재 내에 상품들을 적재한다. 종래에는 로봇이 상품을 적출/적재하기 위해서 전문가가 동작에 대한 명령을 입력하거나 티칭(Teaching)하는 방 식을 쓰거나 또는 자동으로 동작을 수행하더라도 수행 환경에 따라 동작 가능 범위 및 장애물의 위치를 입력하 거나 티칭하는 반면 본 발명의 로봇 시스템은, 시뮬레이터 내에서 다양한 환경에 대해 학습한 인공지 능 모델을 사용하기 때문에 명령 입력이나 티칭 과정 없이 실제 환경에 적용이 수월하다는 이점이 있다. 상품을 자동으로 적출하기 위해 실제 환경 내에서 다수의 로봇을 통해 인공지능 모델을 학습하는 종래 기술이 존재하지만 자동으로 파지 위치만을 연산할 뿐 본 발명과 같이 상품 훼손을 방지하기 위해서 상품 특성 정보를 고려하여 파지 위치나 파지력을 고려하지 않는다. 또한 포장재 내 빈 공간을 최대한 줄이기 위해 적재 순서를 연산하는 종래 기술이 존재하지만 본 발명과 같이 상품의 훼손을 방지하기 위해 상품 특성 정보를 고려하여 인 공 지능 스케줄 모델이 적재 순서를 결정지 않는다. 종래에는 다수 로봇이 동일한 태스크(task)를 수행하기 위해서 로봇 간 충돌이 없도록 전문가가 스케줄링하거나 또는 자동으로 스케줄링하는 경우 어떤 로봇이 동작하는 동안 다른 로봇이 동작을 멈추도록 한다. 반면, 본 발 명은 인공지능 스케줄 모델을 통해 다수의 로봇이 동선이 겹치지 않도록 상품의 적재/적출의 순서를 결정하거나 동작 수행 속도를 제어하여 다수의 로봇을 이용하여 빠른 상품 포장이 가능하다. 로봇이 파지 태스크를 수행하기 위한 동작을 인공지능 모델을 통해 자동으로 생성하는 종래 기술이 존재하지만 단일 심층 신경망을 사용하기 때문에 다양한 상품을 파지하는 순서까지 학습시 많은 태스크를 고려해야하기 때 문에 신경망의 층이 깊어짐으로써 학습 속도 및 추론 속도가 느려진다. 반면 본 발명의 경우 인공지능 스케줄 모델과 인공지능 동작 모델로 태스크를 분리하여 학습하고 분산 수행하기 때문에 신경망의 층이 상대적으로 얕 아 학습 속도 및 추론 속도가 상대적으로 빠른 이점이 있다. 도 6은 본 발명의 일 실시예에 따른 로봇 시스템의 학습 방법을 설명하는 흐름도이다. 도 6을 참조하면, 단계 S601에서, 로봇 시스템은, 상품 특성 정보 및 상품 수령 매장 정보를 저장한다. 상기 상품 특성 정보는, 전체 상품의 상품명, 상품 이미지, 가격, 크기, 형태, 무게, 강도, 포장 재질 및 재고량을 포함한다. 상기 상품 수령 매장 정보는, 각 매장별 정보로서, 포장재 정보, 로봇 정보, 카메라 정보 및 선반 정보를 포함한다. 포장 재 정보는, 매장에 구비되는 전체 포장재 종류(예, 장바구니, 종이백, 플라스틱백, 비닐 봉지 등), 규격을 포함 한다. 로봇 정보는 매장에 설치된 로봇의 타입(예, 고정형 매니퓰레이터, 직교 좌표 로봇, 바퀴형 이동 로봇, 매니퓰레이터 장착 바퀴형 이동 로봇 등), 규격, 수량 및 장착 센서 사양을 포함한다. 카메라 정보는 매장에 구 비되는 전체 카메라의 종류, 수량 및 설치 위치를 포함한다. 선반 정보는, 매장에 구비되는 선반의 규격, 형태, 칸 수, 수량, 매장 내 위치를 포함한다. 단계 S602에서, 로봇 시스템은, 상기 단계 S601에서 저장된 상품 특성 정보 및 상품 수령 매장 정보에 기 초하여 3차원 가상 환경을 구축한다. 3차원 가상 환경에는, 가상의 상품, 선반, 포장재, 장애물, 로봇 등의 가 상 모델이 생성되어 배치된다. 단계 S603에서, 로봇 시스템은, 상기 3차원 가상 환경 내에서 인공지능 스케줄 모델을 학습한다. 보다 구 체적으로, 로봇 시스템은, 가상 환경 내의 가상 카메라에 의해 실시간 촬영된 영상을 학습된 영상 분 석 모델을 통해 가상 모델들, 즉 가상 상품들, 가상 포장재, 가상 선반 그리고 가상 장애물을 분석한다. 가상 상품들의 경우, 상품 종류, 위치, 크기, 2차원 또는 3차원 자세, 무게 중심점을 분석한다. 가상 포장재의 경우, 포장재의 종류, 위치, 크기, 2차원 또는 3차원 자세, 공간 점유율을 분석한다. 가상 선반의 경우, 선반의 위치, 2차원 또는 3차원 크기를 분석한다. 가상 장애물의 경우, 장애물의 위치, 2차원 또는 3차원 크기를 분석한다. 바람직하게, 가상 카메라로부터 수신되는 실시간 촬영 영상을 머신 러닝(Machine Learning) 또는 딥 러닝 (Deep Learning) 기술로 학습된 영상 분석 모델로 분석한다. 로봇 시스템은, 학습된 상품 분석 모델을 통해 전체 상품들의 상품 특성 정보(예, 수량, 크기, 형태, 무게, 강도, 무게 중심점, 포장 재질 등)를 분석하여 상품들의 훼손이 없는 임시 상품 적재 순서를 생성한다. 전체 상품들에 대해 여러 조합으로 결정되는 상품들의 임시 상품 적재 순서를 생성한다. 로봇 시스템은, 단일 가상 로봇의 경우, 가상 모델들의 분석 결과와, 상기 임시 상품 적재 순서, 그리고 상품 특성 정보 및 상 품 수령 매장 정보를 이용하여, 상품 훼손 및 포장재 공간을 고려하여 포장재 내 상품을 적재하는 순서와 포장 재 내 상품 배치 위치 좌표값을 예측 및 출력하는 인공지능 스케줄 모델을 생성하고 학습한다. 다수의 가상 로 봇의 경우, 로봇 시스템은, 상품 적재 순서 및 포장재 내 상품 배치 위치 좌표값 이외에, 복수의 로봇 간 동작 시간 순서를 더 예측 및 출력하는 인공지능 스케줄 모델을 생성하고 학습한다. 단계 S604에서, 로봇 시스템은, 가상 모델들의 분석 결과와, 상품 특성 정보 및 상품 수령 매장 정보를 이 용하여, 상기 3차원 가상 환경 내에서 상품을 파지, 적출, 적재하는 로봇의 각 구성요소들의 최적의 동작값 및 동작속도를 예측 및 출력하는 인공지능 동작 모델을 각 로봇의 종류별로 생성하고 학습한다. 여기서 동작값은, 로봇을 구성하는 구성요소들(예, 구동부, 몸체, 링크, 엔드 이펙터 등)의 회전력, 회전 범위, 구동 범위, 파지 력, 흡착력 등을 포함한다. 로봇 시스템은, 복수의 가상 로봇의 경우, 로봇의 각 구성요소들의 최적의 동 작값 및 동작속도를, 상기 인공지능 스케줄 모델을 학습하는 과정에서 생성되는 복수의 로봇 간 동작 시간 순서 를 더 고려하여, 동작 시간 순서에 따른 각 로봇의 구성요소들의 최적의 동작값 및 동작속도를 예측 및 출력하 는 인공지능 동작 모델을 각 로봇의 종류별로 생성하고 학습한다. 단계 S605에서, 로봇 시스템은, 상기 단계 S603 및 상기 단계 S604에서 학습한 인공지능 스케줄 모델과 인 공지능 동작 모델을 이용하여 가상 환경 내의 로봇을 조작하여 상품 포장의 태스크를 수행한다. 보다 구체적으 로, 로봇 시스템은, 상기 인공지능 스케줄 모델을 통해 출력되는 상품 적재 순서와 포장재 내 상품 배치 위치 좌표값, 그리고 상기 인공지능 동작 모델에서 출력되는 로봇의 각 구성요소들의 최적의 동작값 및 동작속 도을 기초로 상품 포장의 태스크를 수행한다. 단계 S606에서, 로봇 시스템은, 인공지능 스케줄 모델과 인공지능 동작 모델의 학습이 완료되었는지 확인 하고, 학습 미완료시, 상기 단계 S605에서 수행된 수행 결과를 다시 인공지능 스케줄 모델과 인공지능 동작 모 델의 학습 과정으로 피드백하고, 학습을 반복 수행함으로써, 최적의 모델을 생성한다. 학습이 완료된 경우, 로 봇 시스템은 인공지능 스케줄 모델과 인공지능 동작 모델을 저장한다. 바람직하게, 하나의 가상 환경에 대 해 하나의 인공지능 스케줄 모델을 저장하고, 인공지능 동작 모델은 로봇의 종류별로 저장할 수 있다. 도 7은 본 발명의 일 실시예에 따른 로봇 시스템의 매장 픽업 서비스 제공 방법을 설명하는 흐름도이다. 도 7을 참조하면, 단계 S701에서, 로봇 시스템은, 명령부로부터 주문 상품 리스트를 수신한다. 여기서 주문 상품 리스트는 사용자가 주문한 상품들의 종류, 개수, 그리고 상품 수령 매장 정보를 포함한다. 단계 S702에서, 로봇 시스템은, 상품 수령 매장 내의 카메라로부터 실시간 촬영 영상을 수신하고, 학습된 영상 분석 모델을 통해 촬영 영상을 분석한다. 구체적으로, 사용자가 주문한 상품들, 포장재, 선반 그리고 장애 물을 분석한다. 사용자가 주문한 상품들의 경우, 상품 종류, 위치, 크기, 2차원 또는 3차원 자세, 무게 중심점 을 분석한다. 포장재의 경우, 포장재의 종류, 위치, 크기, 2차원 또는 3차원 자세, 공간 점유율을 분석한다. 선 반의 경우, 선반의 위치, 2차원 또는 3차원 크기를 분석한다. 장애물의 경우, 장애물의 위치, 2차원 또는 3차원 크기를 분석한다. 바람직하게, 머신 러닝(Machine Learning) 또는 딥 러닝(Deep Learning) 기술로 분석한다. 단계 S703에서, 로봇 시스템은, 사용자가 상품을 수령할 매장에 대응하는 인공지능 스케줄 모델을 통해, 사용자가 주문한 상품들의 적재 순서와 포장재 내 상품 배치 위치값을 생성한다. 보다 구체적으로, 로봇 시스템 은, 단계 S702에서 분석한 상품들, 포장재, 선반 그리고 장애물의 분석 결과와, 상품 특성 정보 및 상품 수령 매장 정보를 이용하여, 상품 훼손 및 포장재 공간을 고려하여 포장재 내 상품을 적재하는 순서와 포장재 내 상품 배치 위치 좌표값을 학습이 완료된 인공지능 스케줄 모델을 통해 생성한다. 바람직하게는, 로봇 시스템 은, 학습된 상품 분석 모델을 통해 단계 S702에서 분석한 상품들의 상품 특성 정보를 이용하여 주문 상품 들의 임시 상품 적재 순서를 생성하고, 이어서 상기 학습된 인공지능 스케줄 모델을 통해 최종적인 상품의 적재 순서와 포장재 내 상품 배치 위치 좌표값을 생성할 수 있다. 로봇이 복수일 경우, 로봇 시스템은, 상품의 적재 순서 및 포장재 내 상품 배치 위치 좌표값 이외에, 복수의 로봇 간 동작 시간 순서를 더 출력한다. 단계 S704에서, 로봇 시스템은, 사용자가 상품을 수령할 매장의 각 로봇의 종류별 인공지능 동작 모델을 통해, 수신되는 상품 적재 순서 및 포장재 내 상품 배치 위치 좌표값에 따라, 상품을 파지, 적출, 적재하는 로 봇의 각 구성요소들의 최적의 동작값 및 동작속도를 생성한다. 여기서 동작값은, 로봇을 구성하는 구성요소들 (예, 구동부, 몸체, 링크, 엔드 이펙터 등)의 회전력, 회전 범위, 구동 범위, 파지력, 흡착력 등을 포함한다. 복수의 로봇의 경우, 복수의 로봇 간 동작 시간 순서를 더 고려하여, 동작 시간 순서에 따른 각 로봇의 구성요 소들의 최적의 동작값 및 동작속도를 생성한다. 단계 S705에서, 로봇 시스템은, 상기 단계 S704에서 생성된 스케줄에 따른 각 로봇의 동작값 및 동작속도 에 기초하여, 사용자가 상품을 수령할 매장의 로봇을 제어한다. 로봇 시스템은, 로봇 제어 명령을 로 봇으로 전송한다. 그리고 단계 S706에서, 로봇 시스템은, 로봇으로부터 상품 포장 태스크 수행 결과의 피드백 정보를 수신하고, 피드백 정보를 이용하여 기 학습된 인공지능 스케줄 모델과 인공지능 동작 모 델을 재학습하여 강화한다. 도 8은 본 발명의 일 실시예에 따른 로봇 시스템의 시뮬레이터의 기능적 구성을 나타낸 도면이다. 도 8을 참조 하면, 시뮬레이터의 스케줄 에이전트는 AI 스케줄 모델 학습부를 실행하는 프로그램으로 이해될 수 있고, 로봇 에이전트들은 AI 동작 모델 학습부를 실행하는 프로그램으로 이해될 수 있다. 환경 은 시뮬레이터에서 생성되는 3차원 가상 환경이다. 도 8에 도시된 바와 같이, 하나의 3차원 가상 환경에 대해 하나의 스케줄 에이전트, 즉 하나의 인공지능 스케줄 모델이 생성되어 학습되고, 로봇의 종류별로 각각 하나씩 로봇 에이전트, 즉 인공지능 동작 모델이 생성되어 학습된다. 스케줄 에이전트 내의 스케줄 상태는, 가상 상품 분석부 및 가상 영상 분석부에서 분석된 상품 의 훼손이 없으며 포장재 내 공간 효율성을 고려한 적재 순서와, 가상 상품들의 종류, 위치, 크기, 2차원 또는 3차원 자세, 무게 중심점, 포장재의 종류/위치/크기/2차원 또는 3차원 자세/공간 점유율, 선반의 위치/2차원 또 는 3차원 크기 및, 장애물의 위치/2차원 또는 3차원 크기 정보이고, 인공지능 스케줄 모델에서 출력되는 스케줄 정책은 최종적인 상품의 적재 순서 등을 포함한다. 로봇 에이전트 내의 로봇 상태는 스케줄 에이전트로부터 출력되어 수신되는 상품 적재 순서와, 현재 로봇의 상태 등을 포함하고, 로봇 정책은 인공지능 동작 모델에 의해 출력되는 상품의 피킹, 적재, 스캔, 장애 물 회피 등 로봇의 임무 수행시 매니퓰레이터 각 관절 및 엔드 이팩터의 동작뿐만 아니라 바퀴형 이동 로봇의 이동을 포함하는 최적의 2차원 또는 3차원 연속 동작 경로 및 시간 정보 등을 포함한다. 로봇 에이전트에 서 출력되는 값에 따라 가상 환경 내에서 가상 로봇이 제어된다. 가상 환경에서 수행된 각 로봇의 수행 결과, 즉 로봇 상태 값과 보상은 각 대응하는 로봇 에이전트로 피드백된다.그리고 전체적인 로봇들의 스케줄에 대한 수행 결과, 즉 스케줄 상태 값 및 전체 로봇 에이전트 에 대한 보상은 스케줄 에이전트로 피드백된다. 여기서 보상은, 행동에 대한 평가로서 소요 시간, 상품 훼손 정도, 최적 동작 경로, 포장재 내 공간 효율 등을 임무에 따라 평가 요소로서 선택할 수 있다. 종래의 멀티 에이전트 강화 학습 방법에 따르면, 로봇 에이전트 간에 커뮤니케이션을 통해 보상을 공유하 여 학습을 한다. 따라서, 환경이나 적용 로봇이 변경되는 경우, 예를 들어 로봇의 개수 또는 로봇의 종류 가 변경되는 경우, 로봇 에이전트 내의 인공지능 동작 모델의 재학습이 필요하고, 또한 인공지능 동작 모 델의 심층 신경망이 깊어짐으로써 학습/추론 속도가 느리도 정확도가 낮아질 수 있다. 하지만, 본 발명에서는 도 8에 도시된 바와 같이, 스케줄 에이전트와 로봇 에이전트를 분리하여, 즉 인공지능 스케줄 모델과 인공지능 동작 모델을 분리하여, 하나의 스케줄 에이전트, 즉 하나의 인공지능 스케줄 모델이 각각의 로봇 의 동작 순서를 결정하기 때문에, 한번 학습한 로봇 에이전트, 즉 인공지능 동작 모델은 환경이나 적용 로봇이 변경되어도 동작값이나 동작 속도와 관련된 재학습이 필요하지 않으며, 추가 학습이 필요한 경우에도 인공지능 스케줄 모델만 학습하면 된다. 그리고 인공지능 동작 모델의 심층 신경망을 얕게 하여 학습/추론 속도 및 정확도를 향상시킨다. 이러한 이유로 빠른 추가 학습 및 수행 환경 적용이 가능하다. 본 명세서는 많은 특징을 포함하는 반면, 그러한 특징은 본 발명의 범위 또는 특허청구범위를 제한하는 것으로 해석되어서는 안 된다. 또한, 본 명세서에서 개별적인 실시예에서 설명된 특징들은 단일 실시예에서 결합되어 구현될 수 있다. 반대로, 본 명세서에서 단일 실시예에서 설명된 다양한 특징들은 개별적으로 다양한 실시예에 서 구현되거나, 적절히 결합되어 구현될 수 있다. 상술한 바와 같은 본 발명의 방법은 프로그램으로 구현되어 컴퓨터로 읽을 수 있는 형태로 기록매체(시디롬, 램, 롬, 플로피 디스크, 하드 디스크, 광자기 디스크 등)에 저장될 수 있다. 이러한 과정은 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자가 용이하게 실시할 수 있으므로 더 이상 상세히 설명하지 않기로 한다."}
{"patent_id": "10-2020-0069252", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "이상에서 설명한 본 발명은, 본 발명이 속하는 기술분야에서 통상의 지식을 가진 자에게 있어 본 발명의 기술적 사상을 벗어나지 않는 범위 내에서 여러 가지 치환, 변형 및 변경이 가능하므로 전술한 실시예 및 첨부된 도면 에 의해 한정되는 것이 아니다."}
{"patent_id": "10-2020-0069252", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일 실시예에 따른 매장 픽업 서비스의 전체 시스템의 구성을 나타낸 도면이다. 도 2는 도 1의 명령부의 구성을 나타낸 도면이다. 도 3은 도 1의 로봇 시스템의 구성을 나타낸 도면이다. 도 4는 도 3의 시뮬레이터의 구성을 나타낸 도면이다. 도 5는 도 3의 로봇 제어부의 구성을 나타낸 도면이다. 도 6은 본 발명의 일 실시예에 따른 로봇 시스템의 학습 방법을 설명하는 흐름도이다. 도 7은 본 발명의 일 실시예에 따른 로봇 시스템의 매장 픽업 서비스 제공 방법을 설명하는 흐름도이다. 도 8은 본 발명의 일 실시예에 따른 로봇 시스템의 시뮬레이터의 기능적 구성을 나타낸 도면이다."}
