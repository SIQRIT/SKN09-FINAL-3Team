{"patent_id": "10-2018-0100647", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2020-0027072", "출원번호": "10-2018-0100647", "발명의 명칭": "인공지능 이동 로봇의 제어 방법", "출원인": "엘지전자 주식회사", "발명자": "이성훈"}}
{"patent_id": "10-2018-0100647", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "이동하며 청소를 수행하는 단계;이전의 청소 수행으로 획득된 기존 데이터에 기반하여, 특수지역을 판별하는 단계; 및,상기 판별된 특수지역에 도착한 경우에, 상기 특수지역에 대한 음성 안내 메시지를 출력하는 단계;를 포함하는이동 로봇의 제어 방법."}
{"patent_id": "10-2018-0100647", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 특수지역은, 주행 불능 상태가 발생했었던 위험지역, 또는, 주행 속도 또는 청소율이 평균값보다 낮았거나, 회전 횟수가 기준 횟수보다 많았던 저효율지역인 것을 특징으로하는 이동 로봇의 제어 방법."}
{"patent_id": "10-2018-0100647", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 이전의 청소 수행으로 획득된 기존 데이터는, 주행 이력 데이터(driving history data) 및 청소 이력 데이터(cleaning history data)를 포함하는 것을 특징으로 하는 이동 로봇의 제어 방법."}
{"patent_id": "10-2018-0100647", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서,상기 이전의 청소 수행으로 획득된 기존 데이터는,상기 특수지역에 등록된 장애물 정보를 더 포함하고,상기 음성 안내 메시지는, 상기 특수지역에 존재하는 장애물에 대한 안내 메시지를 포함하는 것을 특징으로 하는 이동 로봇의 제어 방법."}
{"patent_id": "10-2018-0100647", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서,상기 음성 안내 메시지는, 상기 특수지역에 대한 청소 여부 확인을 요청하는 메시지를 포함하는 것을 특징으로 하는 이동 로봇의 제어 방법."}
{"patent_id": "10-2018-0100647", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5항에 있어서,상기 음성 안내 메시지는, 상기 특수지역으로 판별한 이유에 대한 설명, 또는 사용자가 음성 입력할 수 있는 명령어의 예시에 대한 안내중 적어도 하나를 더 포함하는 것을 특징으로 하는 이동 로봇의 제어 방법."}
{"patent_id": "10-2018-0100647", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "공개특허 10-2020-0027072-3-제1항에 있어서,상기 음성 안내 메시지에 대한 사용자의 음성 피드백을 수신하는 단계;상기 수신된 음성 피드백에 포함되는 음성 명령을 식별하는 단계; 및,상기 식별된 음성 명령에 대응하는 동작을 수행하는 단계;를 더 포함하는 이동 로봇의 제어 방법."}
{"patent_id": "10-2018-0100647", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서,상기 음성 명령을 식별하는 단계는, 입력되는 데이터에 포함되는 음성을 인식하도록 학습된 인공신경망을 포함하는 음성 인식 서버로 상기 수신된음성 피드백 데이터를 송신하는 단계, 및,상기 음성 인식 서버로부터 상기 수신된 음성 피드백 데이터의 음성 인식 결과를 수신하는 단계를 포함하는 것을 특징으로 하는 이동 로봇의 제어 방법."}
{"patent_id": "10-2018-0100647", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제7항에 있어서,상기 이동 로봇은, 입력되는 데이터에 포함되는 음성을 인식하도록 학습된 인공신경망을 포함하고, 상기 음성 명령을 식별하는 단계는, 상기 인공신경망이 상기 수신된 음성 피드백에 포함되는 음성 명령을 인식하는 것을 특징으로 하는 이동 로봇의제어 방법."}
{"patent_id": "10-2018-0100647", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제7항에 있어서,상기 음성 명령을 식별하는 단계는, 상기 수신된 음성 피드백이 기설정된 키워드(keyword)를 포함하는 경우에, 상기 키워드에 대응하는 음성 명령을식별하는 단계,상기 수신된 음성 피드백이 기설정된 키워드(keyword)를 포함하지 않는 경우에, 입력되는 데이터에 포함되는 음성을 인식하도록 학습된 인공신경망을 포함하는 음성 인식 서버로 상기 수신된 음성 피드백 데이터를 송신하는단계, 및,상기 음성 인식 서버로부터 상기 수신된 음성 피드백 데이터의 음성 인식 결과를 수신하는 단계를 포함하는 것을 특징으로 하는 이동 로봇의 제어 방법."}
{"patent_id": "10-2018-0100647", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "사용자의 음성 명령을 수신하는 단계;사용 기록에 기초하여, 기준 횟수 미만으로 사용된 기능 중 적어도 하나를 추천하는 음성 안내 메시지를 출력하는 단계; 상기 음성 안내 메시지에 대한, 상기 사용자의 음성 피드백이 수신되면, 상기 수신된 음성 피드백에 포함되는피드백 음성 명령을 식별하는 단계; 및,상기 식별된 피드백 음성 명령에 기초하여 소정 기능을 설정하는 단계;를 포함하는 이동 로봇의 제어 방법."}
{"patent_id": "10-2018-0100647", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항에 있어서,상기 사용 기록은, 공개특허 10-2020-0027072-4-일반 청소 완료 횟수, 충전대 복귀 횟수, 영역별 청소 기능 완료 횟수, 운용 시간, 영역별 청소 세기 평균, 영역별 먼지량, 영역별 청소 모드 사용 빈도, 영역별 청소 모드 사용 비율, 청소 기능 및 부가 기능별 사용 횟수중 적어도 하나를 포함하는 것을 특징으로 하는 이동 로봇의 제어 방법."}
{"patent_id": "10-2018-0100647", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제11항에 있어서,상기 음성 안내 메시지 출력 단계는,기설정된 우선 순위에 따라, 기준 횟수 미만으로 사용된 기능 중 적어도 하나를 선택하여 추천하는 것을 특징으로 하는 이동 로봇의 제어 방법."}
{"patent_id": "10-2018-0100647", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제13항에 있어서,상기 기설정된 우선 순위는, 기설정된 기능별 중요도가 높은 순서 또는 사용 횟수가 작은 순서인 것을 특징으로하는 이동 로봇의 제어 방법."}
{"patent_id": "10-2018-0100647", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제11항에 있어서,상기 사용자의 음성 명령을 식별하는 단계;를 더 포함하는 이동 로봇의 제어 방법."}
{"patent_id": "10-2018-0100647", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제15항에 있어서,상기 식별된 사용자의 음성 명령에 대응하는 동작을 수행하는 단계;를 더 포함하는 이동 로봇의 제어 방법."}
{"patent_id": "10-2018-0100647", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제15항에 있어서,상기 음성 안내 메시지 출력 단계는,상기 기준 횟수 미만으로 사용된 기능 중 상기 식별된 사용자의 음성 명령과 연관된 기능을 선택하여 추천하는것을 특징으로 하는 이동 로봇의 제어 방법."}
{"patent_id": "10-2018-0100647", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제11항에 있어서,상기 피드백 음성 명령을 식별하는 단계는, 입력되는 데이터에 포함되는 음성을 인식하도록 학습된 인공신경망을 포함하는 음성 인식 서버로 상기 수신된음성 피드백 데이터를 송신하는 단계, 및,상기 음성 인식 서버로부터 상기 수신된 음성 피드백 데이터의 음성 인식 결과를 수신하는 단계를 포함하는 것을 특징으로 하는 이동 로봇의 제어 방법."}
{"patent_id": "10-2018-0100647", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제11항에 있어서,상기 이동 로봇은, 입력되는 데이터에 포함되는 음성을 인식하도록 학습된 인공신경망을 포함하고, 상기 음성 명령을 식별하는 단계는, 상기 인공신경망이 상기 수신된 음성 피드백에 포함되는 상기 피드백 음성 명령을 인식하는 것을 특징으로 하는이동 로봇의 제어 방법.공개특허 10-2020-0027072-5-"}
{"patent_id": "10-2018-0100647", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명의 일 측면에 따른 이동 로봇은, 사용자에게 음성을 발화할 수 있어, 음성을 매개로 사용자와 대화하고 인터랙션할 수 있으며, 요청하기 전에 먼저 능동적으로 정보를 제공하고, 서비스, 기능 등을 추천함으로써, 사용 자의 신뢰도, 선호도 및 제품 활용도를 높일 수 있다."}
{"patent_id": "10-2018-0100647", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 이동 로봇 및 그 제어 방법에 관한 것으로서, 더욱 상세하게는 능동적으로 사용자에게 정보 및 서비 스를 제공할 수 있는 이동 로봇 및 그 제어 방법에 관한 것이다."}
{"patent_id": "10-2018-0100647", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "로봇은 산업용으로 개발되어 공장 자동화의 일 부분을 담당하여 왔다. 최근에는 로봇을 응용한 분야가 더욱 확 대되어, 의료용 로봇, 우주 항공 로봇 등이 개발되고, 일반 가정에서 사용할 수 있는 가정용 로봇도 만들어지고 있다. 이러한 로봇 중에서 자력으로 주행이 가능한 것을 이동 로봇이라고 한다. 가정에서 사용되는 이동 로봇의 대표적인 예는 로봇 청소기로, 로봇 청소기는 일정 영역을 스스로 주행하면서, 주변의 먼지 또는 이물질을 흡입함으로써, 해당 영역을 청소하는 기기이다. 이동 로봇은, 스스로 이동이 가능하여 이동이 자유롭고, 주행중 장애물 등을 피하기 위한 다수의 센서가 구비되 어 장애물을 피해 주행할 수 있다. 한편, 사용자의 사용 편의성을 향상하기 위하여 다양한 기기에 음성 인식 기술이 적용되고 있고, 음성 인식 기 술을 이용하여 이동 로봇을 제어하는 방안에 대한 연구가 증가하고 있다. 예를 들어, 선행 문헌 1(한국 공개특허공보 10-2012-0114670호, 공개일자 2012년 10월 17일)은 로봇 청소기가 음성 인식 유닛을 구비하고 사용자의 음성 신호를 인식하여 대응하는 제어 명령을 실행하고 있다. 선행 문헌 1에서는, 음성 입력이 사용자에서 로봇 청소기로 단방향으로 이루어져서, 버튼을 누르거나 리모콘으 로 조작하는 제어동작의 추가적인 수단에서 머무르고 있다. 따라서, 음성 인식 기능이 사용자에게 단순한 제어 이상의 의미를 주기 힘들고, 제어 입력 수단의 추가 이외에 다른 기능 및 서비스를 제공하지 못한다는 문제점이 있었다."}
{"patent_id": "10-2018-0100647", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "음성 인식을 하나의 제어 입력 수단으로만 이용하는데 그치는 선행 문헌1의 한계를 넘어, 본 발명의 목적은 음 성을 매개로 사용자와 인터랙션(interaction)할 수 있는 이동 로봇 및 그 제어 방법을 제공함에 있다. 본 발명의 목적은 이동 로봇이 능동적으로 사용자에게 다양한 정보와 서비스를 사용자에게 제공함에 있다. 본 발명의 목적은 사용자의 제품 신뢰도 및 선호도를 향상할 수 있도록 사용자 친화적인 동작을 할 수 있는 이 동 로봇 및 그 제어 방법을 제공함에 있다."}
{"patent_id": "10-2018-0100647", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기 또는 다른 목적을 달성하기 위해 본 발명의 일 측면에 따른 이동 로봇은, 사용자에게 소정 정보, 서비스를 안내하는 음성을 발화할 수 있어, 음성을 매개로 사용자와 대화하고 인터랙션(interaction)할 수 있다. 상기 또는 다른 목적을 달성하기 위해 본 발명의 일 측면에 따른 이동 로봇은, 요청하기 전에 먼저 능동적으로 소정 정보를 제공하고, 소정 서비스, 기능 등을 추천함으로써, 사용자의 신뢰도, 선호도 및 제품 활용도를 높일 수 있다. 상기 또는 다른 목적을 달성하기 위해 본 발명의 일 측면에 따른 이동 로봇의 동작 방법은, 이동하며 청소를 수 행하는 단계, 이전의 청소 수행으로 획득된 기존 데이터에 기반하여, 특수지역을 판별하는 단계, 및, 판별된 특 수지역에 도착한 경우에, 상기 특수지역에 대한 음성 안내 메시지를 출력하는 단계를 포함함으로써, 사용자의 요청 전에 능동적으로 정보 제공의 필요성이 있는 특수지역에 대한 안내를 음성으로 제공할 수 있다. 여기서, 특수지역은, 주행 불능 상태가 발생했었던 위험지역, 또는, 주행 속도 또는 청소율이 평균값보다 낮았 거나, 회전 횟수가 기준 횟수보다 많았던 저효율지역일 수 있다. 또한, 이전의 청소 수행으로 획득된 기존 데이터는, 주행 이력 데이터(driving history data) 및 청소 이력 데 이터(cleaning history data)를 포함할 수 있다. 또한, 이전의 청소 수행으로 획득된 기존 데이터는, 특수지역에 등록된 장애물 정보를 더 포함할 수 있고, 이 경우에, 음성 안내 메시지는, 특수지역에 존재하는 장애물에 대한 안내 메시지를 포함할 수 있다. 한편, 음성 안내 메시지는, 특수지역에 대한 청소 여부 확인을 요청하는 메시지를 포함할 수 있다. 이 경우에, 음성 안내 메시지는, 특수지역으로 판별한 이유에 대한 설명, 또는 사용자가 음성 입력할 수 있는 명령어의 예 시에 대한 안내 중 적어도 하나를 더 포함할 수 있다. 본 발명의 일 측면에 따른 이동 로봇의 동작 방법은, 상기 음성 안내 메시지에 대한 사용자의 음성 피드백을 수 신하는 단계, 수신된 음성 피드백에 포함되는 음성 명령을 식별하는 단계, 및, 식별된 음성 명령에 대응하는 동 작을 수행하는 단계를 더 포함할 수 있다. 이 경우에, 음성 명령의 식별은 이동 로봇에서 자체적으로 수행되거나, 서버에서 수행되거나, 이동 로봇과 서버 에서 단계적으로 수행될 수 있다. 상기 또는 다른 목적을 달성하기 위해 본 발명의 일 측면에 따른 이동 로봇의 동작 방법은, 사용자의 음성 명령 을 수신하는 단계, 사용 기록에 기초하여, 기준 횟수 미만으로 사용된 기능 중 적어도 하나를 추천하는 음성 안 내 메시지를 출력하는 단계, 음성 안내 메시지에 대한, 사용자의 음성 피드백이 수신되면, 수신된 음성 피드백 에 포함되는 피드백 음성 명령을 식별하는 단계, 및, 식별된 피드백 음성 명령에 기초하여 소정 기능을 설정하 는 단계를 포함함으로써, 사용자가 자주 사용하지 않는 기능 중 유용한 기능을 능동적으로 추천할 수 있다. 여기서, 사용 기록은, 일반 청소 완료 횟수, 충전대 복귀 횟수, 영역별 청소 기능 완료 횟수, 운용 시간, 영역 별 청소 세기 평균, 영역별 먼지량, 영역별 청소 모드 사용 빈도, 영역별 청소 모드 사용 비율, 청소 기능 및 부가 기능별 사용 횟수 중 적어도 하나를 포함할 수 있다. 또한, 이동 로봇은, 기설정된 우선 순위에 따라, 기준 횟수 미만으로 사용된 기능 중 적어도 하나를 선택하여 추천할 수 있다. 이 경우에, 기설정된 우선 순위는, 기설정된 기능별 중요도가 높은 순서 또는 사용 횟수가 작 은 순서일 수 있다. 본 발명의 일 측면에 따른 이동 로봇의 동작 방법은, 사용자의 음성 명령을 식별하는 단계를 더 포함할 수 있다. 이 경우에, 식별된 사용자의 음성 명령에 대응하는 동작을 수행할 수 있고, 기준 횟수 미만으로 사용된 기능 중 식별된 사용자의 음성 명령과 연관된 기능을 선택하여 추천할 수 있다. 한편, 음성 명령, 피드백 음성 명령의 식별은 이동 로봇에서 자체적으로 수행되거나, 서버에서 수행되거나, 이 동 로봇과 서버에서 단계적으로 수행될 수 있다."}
{"patent_id": "10-2018-0100647", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명의 실시예들 중 적어도 하나에 의하면, 이동 로봇은, 사용자에게 음성을 발화할 수 있어, 음성을 매개로 사용자와 대화하고 인터랙션할 수 있다. 또한, 본 발명의 실시예들 중 적어도 하나에 의하면, 요청하기 전에 먼저 이동 로봇이 능동적으로 정보를 제공 하고, 서비스, 기능 등을 추천함으로써, 사용자의 신뢰도, 선호도 및 제품 활용도를 높일 수 있다. 또한, 본 발명의 실시예들 중 적어도 하나에 의하면, 이동 로봇에게 위험한 위험지역, 청소가 쉽지 않은 저효율 지역을 능동적으로 안내함으로써, 이동 로봇의 안정성 및 사용자의 편의성을 제고하고, 운전 효율, 청소 효율 등을 향상시킬 수 있다. 또한, 본 발명의 실시예들 중 적어도 하나에 의하면, 사용자가 자주 사용하지 않는 기능 중 유용한 기능을 능동 적으로 추천함으로써, 사용자의 신뢰도, 선호도 및 제품 활용도를 높일 수 있다. 또한, 본 발명의 실시예들 중 적어도 하나에 의하면, 사용자의 음성 명령과 연관된 다른 기능을 추천함으로써, 사용자가 추가적인 노력을 하지 않고서도 연관된 기능을 간편하게 설정하고 이용할 수 있다. 또한, 본 발명의 실시예들 중 적어도 하나에 의하면, 음성 인식이 이동 로봇에서 자체적으로 수행되거나, 서버 에서 수행되거나, 이동 로봇과 서버에서 단계적으로 수행됨으로써, 효과적인 음성 인식을 수행할 수 있다. 또한, 본 발명의 실시예들 중 적어도 하나에 의하면, 음성 인식, 장애물 인식, 제품 데이터 분석 등에 인공지능 과 머신 러닝을 활용함으로써, 진화하는 사용자 경험(ux)을 제공할 수 있다. 한편, 그 외의 다양한 효과는 후술될 본 발명의 실시예에 따른 상세한 설명에서 직접적 또는 암시적으로 개시될 것이다."}
{"patent_id": "10-2018-0100647", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하에서는 첨부한 도면을 참조하여 본 발명의 실시예를 상세하게 설명한다. 그러나 본 발명이 이러한 실시예에 한정되는 것은 아니며 다양한 형태로 변형될 수 있음은 물론이다. 도면에서는 본 발명을 명확하고 간략하게 설명하기 위하여 설명과 관계없는 부분의 도시를 생략하였으며, 명세 서 전체를 통하여 동일 또는 극히 유사한 부분에 대해서는 동일한 도면 참조부호를 사용한다. 한편, 이하의 설명에서 사용되는 구성요소에 대한 접미사 \"모듈\" 및 \"부\"는 단순히 본 명세서 작성의 용이함만 이 고려되어 부여되는 것으로서, 그 자체로 특별히 중요한 의미 또는 역할을 부여하는 것은 아니다. 따라서, 상 기 \"모듈\" 및 \"부\"는 서로 혼용되어 사용될 수도 있다. 본 발명의 일 실시예에 따른 이동 로봇은 바퀴 등을 이용하여 스스로 이동이 가능한 로봇을 의미하고, 가 정 도우미 로봇 및 로봇 청소기 등이 될 수 있다. 이하에서는, 도면들을 참조하여, 이동 로봇 중 청소 기능을 가지는 로봇 청소기를 예로 들어 설명하나, 본 발명은 이에 한정되지 않는다. 도 1은 본 발명의 일 실시예에 따른 홈 어플라이언스 네트워크 시스템 구성도이다. 도 1을 참조하면, 홈 어플라이언스 네트워크 시스템은, 통신 모듈을 구비하여 다른 기기, 서버와 통신하거 나 네트워크에 접속할 수 있는 홈 어플라이언스(home appliance)들을 포함하여 구성될 수 있다. 예를 들어, 홈 어플라이언스에는 통신 모듈을 구비한 공조 기기, 청소기, 냉장고, 세탁기 등이 해당될 수 있다. 한편, 상기 공조 기기는 공기조화기, 공기 청정기(12, 13), 가습기, 후드(Hood, 15) 중 적어도 하 나를 포함할 수 있다. 또한, 상기 청소기는, 진공 청소기, 로봇 청소기 등일 수 있다. 한편, 홈 어플라이언스(10, 20, 31, 32)가 구비하는 통신 모듈은 와이파이(wi-fi) 통신 모듈일 수 있으며, 본 발명은 통신 방식에 한정되지 않는다. 또는, 홈 어플라이언스(10, 20, 31, 32)는 다른 종류의 통신 모듈을 구비하거나 복수의 통신 모듈을 구비할 수 있다. 예를 들어, 홈 어플라이언스(10, 20, 31, 32)는 NFC 모듈, 지그비(zigbee) 통신 모듈, 블루투스 (Bluetooth™) 통신 모듈 등을 포함할 수 있다. 홈 어플라이언스(10, 20, 31, 32)는 와이파이(wi-fi) 통신 모듈 등을 통해 소정 서버와 연결 가능하고, 원 격 모니터링, 원격 제어 등 스마트 기능을 지원할 수 있다. 본 발명의 일 실시예에 따른 홈 어플라이언스 네트워크 시스템은, 스마트 폰(smart phone), 태블릿(Tablet) PC 등 휴대 단말기를 포함할 수 있다. 사용자는 휴대 단말기를 통하여 홈 어플라이언스 네트워크 시스템 내의 홈 어플라이언스(10, 20, 31, 32)에 관한 정보를 확인하거나 홈 어플라이언스(10, 20, 31, 32)를 제어할 수 있다. 한편, 본 발명의 일 실시예에 따른 홈 어플라이언스 네트워크 시스템은, 복수의 사물인터넷(IoT) 기기(미도시) 를 포함하여 구성될 수 있다. 따라서, 홈 어플라이언스 네트워크 시스템은, 홈 어플라이언스(10, 20, 31, 32), 휴대 단말기, 사물인터넷(IoT) 기기들을 포함할 수 있다. 본 발명의 일 실시예에 따른 홈 어플라이언스 네트워크 시스템은, 네트워크를 구성하는 통신 방식에 한정되지 않는다. 예를 들어, 홈 어플라이언스(10, 20, 31, 32), 휴대 단말기, 사물인터넷(IoT) 기기들은, 유/무선 공유기(미 도시)를 통하여, 통신 연결될 수 있다. 또한, 홈 어플라이언스 네트워크 시스템 내의 기기들은 각각 개별적으로 통신 연결되는 메쉬 토폴로지(mesh topology)를 구성할 수 있다. 홈 어플라이언스 네트워크 시스템 내의 홈 어플라이언스(10, 20, 31, 32)는 유/무선 공유기(미도시)를 경유하여 서버나 휴대 단말기와 통신할 수 있다. 또한, 홈 어플라이언스 네트워크 시스템 내의 홈 어플라이언스 (10, 20, 31, 32)는 이더넷(Ethernet)에 의해서 서버나 휴대 단말기와 통신할 수 있다. 도 2는 본 발명의 일 실시예에 따른 이동 로봇을 도시하는 사시도이고, 도 3은 도 2의 이동 로봇의 평면도이며, 도 4는 도 2의 이동 로봇의 측면도이다. 도 2 내지 도 4를 참고하여, 이동 로봇은 일정 영역을 스스로 주행할 수 있다. 이동 로봇은 바닥을 청소하는 기능을 수행할 수 있다. 여기서 말하는 바닥의 청소에는, 바닥의 먼지(이물질을 포함한다)를 흡입하거 나 바닥을 걸레질하는 것이 포함된다. 이동 로봇은 본체를 포함한다. 본체는 외관을 형성하는 케비닛을 포함한다. 이동 로봇은, 본체에 구비된 흡입 유닛 및 먼지통을 포함할 수 있다. 이동 로봇은 이동 로봇 주변의 환 경과 관련된 정보를 감지하는 영상획득부를 포함한다. 이동 로봇은 상기 본체를 이동시키는 주행부 를 포함한다. 이동 로봇은 이동 로봇의 제어를 위한 제어부를 포함한다. 제어부는 본 체에 구비된다. 주행부는 이동 로봇의 주행을 위한 휠 유닛을 포함한다. 휠 유닛은 본체에 구비된다. 휠 유닛에 의해 이동 로봇은 전후좌우로 이동되거나 회전될 수 있다. 제어부가 휠 유닛의 구동 을 제어함으로써, 이동 로봇은 바닥을 자율 주행할 수 있다. 휠 유닛은 메인 휠(111a) 및 서브 휠 (111b)을 포함한다. 메인 휠(111a)은 본체의 양측에 각각 구비되어, 제어부의 제어 신호에 따라 일 방향 또는 타 방향으로 회 전 가능하게 구성된다. 각각의 메인 휠(111a)은 서로 독립적으로 구동 가능하게 구성될 수 있다. 예를 들어, 각 각의 메인 휠(111a)은 서로 다른 모터에 의해서 구동될 수 있다. 서브 휠(111b)은 메인 휠(111a)과 함께 본체를 지지하며, 메인 휠(111a)에 의한 이동 로봇의 주행을 보조하도록 이루어진다. 이러한 서브 휠(111b)은 후술하는 흡입 유닛에도 구비될 수 있다. 흡입 유닛은 본체의 전방(F)으로부터 돌출된 형태로 배치될 수 있다. 흡입 유닛은 먼지가 포함 된 공기를 흡입하도록 구비된다. 흡입 유닛이 본체의 전방에서 좌우 양측방으로 돌출된 형태를 가질 수 있다. 흡입 유닛의 전단 부는 본체의 일측으로부터 전방으로 이격된 위치에 배치될 수 있다. 흡입 유닛의 좌우 양단부는 본체 로부터 좌우 양측으로 각각 이격된 위치에 배치될 수 있다. 본체는 원형으로 형성되고, 흡입 유닛의 후단부 양측이 본체로부터 좌우 양측으로 각각 돌출 형 성됨에 따라, 본체와 흡입 유닛 사이에는 빈 공간, 즉 틈이 형성될 수 있다. 상기 빈 공간은 본체 의 좌우 양단부와 흡입 유닛의 좌우 양단부 사이의 공간으로서, 이동 로봇의 내측으로 함몰된 형태를 가진다. 흡입 유닛은 본체에 착탈 가능하게 결합될 수 있다. 흡입 유닛이 본체로부터 분리되면, 분 리된 흡입 유닛을 대체하여 걸레 모듈(미도시)이 본체에 착탈 가능하게 결합될 수 있다. 영상획득부는 본체에 배치될 수 있다. 영상획득부는 본체의 전방(F)에 배치될 수 있다. 영 상획득부는 본체의 상하 방향으로 흡입 유닛과 오버랩(overlap)되도록 배치될 수 있다. 영상획 득부는 흡입 유닛의 상부에 배치될 수 있다. 영상획득부는 이동 로봇 주변의 장애물을 감지할 수 있다. 영상획득부는 이동 로봇의 가장 앞쪽에 위치하는 흡입 유닛이 장애물과 부딪히지 않도록 전방의 장애물이나 지형지물 등을 감지할 수 있다. 영상획득부는 이러한 감지 기능 외의 후술할 다른 센싱 기능을 추가로 수행할 수 있다. 본체에는 먼지통 수용부(미도시)가 구비될 수 있다. 먼지통 수용부에는 흡입된 공기 중의 먼지를 분리하여 집진하는 먼지통이 착탈 가능하게 결합된다. 먼지통 수용부는 본체의 후방(R)에 형성될 수 있다. 먼 지통의 일부는 먼지통 수용부에 수용되되, 먼지통의 다른 일부는 본체의 후방(R)을 향하여 돌출 되게 형성될 수 있다. 먼지통에는 먼지가 포함된 공기가 유입되는 입구(미도시)와 먼지가 분리된 공기가 배출되는 출구(미도시) 가 형성된다. 먼지통 수용부에 먼지통이 장착시 먼지통의 상기 입구와 상기 출구는 먼지통 수용부의 내측벽에 형성된 제1 개구(미도시) 및 제2 개구(미도시)와 각각 연통되도록 구성된다. 흡입 유닛의 흡입구부터 상기 제1 개구까지 공기를 안내하는 흡입 유로(미도시)가 구비된다. 상기 제2 개 구부터 외부를 향해 열린 배기구(미도시)까지 공기를 안내하는 배기 유로(미도시)가 구비된다. 흡입 유닛을 통하여 유입된 먼지가 포함된 공기는 본체 내부의 상기 흡기유로를 거쳐, 먼지통으 로 유입되고, 먼지통의 필터 내지는 사이클론을 거치면서 공기와 먼지가 상호 분리된다. 먼지는 먼지통 에 집진되며, 공기는 먼지통에서 배출된 후 본체 내부의 상기 배기유로를 거쳐 최종적으로 상기 배기구를 통하여 외부로 배출된다. 도 5는 본 발명의 일 실시예에 따른 이동 로봇의 주요 구성들 간의 제어관계를 도시한 블록도이다. 도 2 내지 도 5를 참조하면, 이동 로봇은, 본체와, 본체 주변의 영상을 획득하는 영상획득부 를 포함한다. 이동 로봇은 본체를 이동시키는 주행부를 포함한다. 주행부는 본체를 이동시키는 적 어도 하나의 휠 유닛을 포함한다. 주행부는 휠 유닛에 연결되어 휠 유닛을 회전시키는 구 동 모터(미도시)를 포함한다. 영상획득부는 주행구역을 촬영하는 것으로, 카메라 모듈을 포함할 수 있다. 상기 카메라 모듈은 디지털 카 메라를 포함할 수 있다. 디지털 카메라는 적어도 하나의 광학렌즈와, 광학렌즈를 통과한 광에 의해 상이 맺히는 다수개의 광다이오드(photodiode, 예를 들어, pixel)를 포함하여 구성된 이미지센서(예를 들어, CMOS image sensor)와, 광다이오드들로부터 출력된 신호를 바탕으로 영상을 구성하는 디지털 신호 처리기(DSP: Digital Signal Processor)를 포함할 수 있다. 디지털 신호 처리기는 정지영상은 물론이고, 정지영상으로 구성된 프레임 들로 이루어진 동영상을 생성하는 것도 가능하다. 이러한 카메라는 촬영 효율을 위해 각 부위별로 여러 개가 설치될 수도 있다. 카메라에 의해 촬상된 영상은 해 당 공간에 존재하는 먼지, 머리카락, 바닥 등과 같은 물질의 종류 인식, 청소 여부, 또는 청소 시점을 확인하는 데 사용할 수 있다. 카메라는 이동 로봇의 주행 방향 전면에 존재하는 장애물 또는 청소 영역의 상황을 촬영할 수 있다. 본 발명의 일 실시예에 따르면, 상기 영상획득부는 본체 주변을 연속적으로 촬영하여 복수의 영상을 획득할 수 있고, 획득된 복수의 영상은 저장부에 저장될 수 있다. 이동 로봇은 복수의 영상을 이용하여 공간 인식, 위치 인식, 장애물 인식의 정확성을 높이거나, 복수의 영 상 중 하나 이상의 영상을 선택하여 효과적인 데이터를 사용함으로써 공간 인식, 위치 인식, 장애물 인식의 정 확성을 높일 수 있다. 또한, 이동 로봇은 이동 로봇의 동작, 상태와 관련된 각종 데이터를 센싱하는 센서들을 포함하는 센서부 를 포함할 수 있다. 예를 들어, 상기 센서부는 전방의 장애물을 감지하는 장애물 감지 센서를 포함할 수 있다. 또한, 상기 센 서부는 주행구역 내 바닥에 낭떠러지의 존재 여부를 감지하는 낭떠러지 감지센서와, 바닥의 영상을 획득하 는 하부 카메라 센서를 더 포함할 수 있다. 상기 장애물 감지 센서는, 적외선 센서, 초음파 센서, RF 센서, 지자기 센서, PSD(Position Sensitive Device) 센서 등을 포함할 수 있다. 한편, 상기 장애물 감지 센서에 포함되는 센서의 위치와 종류는 이동 로봇의 기종에 따라 달라질 수 있고, 상기 장애물 감지 센서는 더 다양한 센서를 포함할 수 있다. 한편, 상기 센서부는 본체의 구동에 따른 이동 로봇의 동작을 감지하고 동작 정보를 출력하는 동작 감지 센서를 더 포함할 수 있다. 예를 들어, 동작 감지 센서로는, 자이로 센서(Gyro Sensor), 휠 센서 (Wheel Sensor), 가속도 센서(Acceleration Sensor) 등을 사용할 수 있다. 자이로 센서는, 이동 로봇이 운전 모드에 따라 움직일 때 회전 방향을 감지하고 회전각을 검출한다. 자이 로 센서는, 이동 로봇의 각속도를 검출하여 각속도에 비례하는 전압 값을 출력한다. 제어부는 자이로 센서로부터 출력되는 전압 값을 이용하여 회전 방향 및 회전각을 산출한다. 휠 센서는, 휠 유닛에 연결되어 바퀴의 회전수를 감지한다. 여기서, 휠 센서는 로터리 엔코더(Rotary Encoder)일 수 있다. 가속도 센서는, 이동 로봇의 속도 변화, 예를 들어, 출발, 정지, 방향 전환, 물체와의 충돌 등에 따른 이 동 로봇의 변화를 감지한다. 또한, 가속도 센서는 제어부에 내장되어 이동 로봇의 속도 변화를 감지할 수 있다. 제어부는 동작 감지 센서로부터 출력된 동작 정보에 기초하여 이동 로봇의 위치 변화를 산출할 수 있 다. 이러한 위치는 영상 정보를 이용한 절대 위치에 대응하여 상대 위치가 된다. 이동 로봇은 이러한 상대 위치 인식을 통해 영상 정보와 장애물 정보를 이용한 위치 인식의 성능을 향상시킬 수 있다. 한편, 이동 로봇은 충전 가능한 배터리를 구비하여 이동 로봇 내로 전원을 공급하는 전원 공급부(미도시) 를 포함할 수 있다. 상기 전원 공급부는 이동 로봇의 각 구성 요소들에 구동 전원과, 동작 전원을 공급하며, 전원 잔량이 부족 하면 충전대(미도시)에서 전원을 공급받아 충전될 수 있다. 이동 로봇은 배터리의 충전 상태를 감지하고, 감지 결과를 제어부에 전송하는 배터리 감지부(미도 시)를 더 포함할 수 있다. 배터리는 배터리 감지부와 연결되어 배터리 잔량 및 충전 상태가 제어부에 전달 된다. 배터리 잔량은 출력부의 디스플레이에 표시될 수 있다. 또한, 이동 로봇은 온/오프(On/Off) 또는 각종 명령을 입력할 수 있는 입력부를 포함한다. 입력부 는 버튼이나 다이얼, 터치 스크린 등을 포함할 수 있다. 입력부는 사용자의 음성 지시를 입력 받기 위한 마이크를 포함할 수 있다. 입력부를 통해 이동 로봇의 작동 전반에 필요한 각종 제어명령을 입 력받을 수 있다. 또한, 이동 로봇은 출력부를 포함하여, 예약 정보, 배터리 상태, 동작모드, 동작상태, 에러상태 등을 이미지로 표시하거나 음향으로 출력할 수 있다. 출력부는 오디오 신호를 출력하는 음향 출력부를 포함할 수 있다. 음향 출력부는 제어부의 제어에 따라 경고음, 동작모드, 동작상태, 에러상태 등의 알림 메시지 등을 음향으로 출력할 수 있다. 음향 출 력부는, 제어부로부터의 전기 신호를 오디오 신호로 변환하여 출력할 수 있다. 이를 위해, 스피커 등 을 구비할 수 있다. 또한, 출력부는 예약 정보, 배터리 상태, 동작모드, 동작상태, 에러상태 등을 이미지로 표시하는 디스플레 이를 더 포함할 수 있다. 도 5를 참조하면, 이동 로봇은 현재 위치를 인식하는 등 각종 정보를 처리하고 판단하는 제어부, 및 각종 데이터를 저장하는 저장부를 포함한다. 또한, 이동 로봇은 외부 단말기와 데이터를 송수신하는 통신부를 더 포함할 수 있다. 외부 단말기는 이동 로봇을 제어하기 위한 애플리케이션을 구비하고, 애플리케이션의 실행을 통해 이동 로 봇이 청소할 주행구역에 대한 맵을 표시하고, 맵 상에 특정 영역을 청소하도록 영역을 지정할 수 있다. 외 부 단말기는 맵 설정을 위한 애플리케이션(application)이 탑재된 리모콘, PDA, 랩탑(laptop), 스마트 폰, 태블 릿 등을 예로 들 수 있다. 외부 단말기는 이동 로봇과 통신하여, 맵과 함께 이동 로봇의 현재 위치를 표시할 수 있으며, 복수의 영역 에 대한 정보가 표시될 수 있다. 또한, 외부 단말기는 이동 로봇의 주행에 따라 그 위치를 갱신하여 표시한다. 제어부는 이동 로봇를 구성하는 영상획득부, 입력부, 주행부, 흡입 유닛 등을 제어하여, 이동 로봇의 동작 전반을 제어한다. 제어부는 입력부의 마이크를 통해 수신되는 사용자의 음성 입력 신호를 처리하고 음성 인식 과정을 수행할 수 있다. 실시예에 따라서, 이동 로봇은 제어부 내부 또는 외부에 음성 인식을 수행하는 음성 인식 모듈을 구비할 수 있다. 실시예에 따라서, 간단한 음성 인식은 이동 로봇이 자체적으로 수행하고, 자연어 처리 등 고차원의 음성 인식은 서버에서 수행될 수 있다. 저장부는 이동 로봇의 제어에 필요한 각종 정보들을 기록하는 것으로, 휘발성 또는 비휘발성 기록 매 체를 포함할 수 있다. 기록 매체는 마이크로 프로세서(micro processor)에 의해 읽힐 수 있는 데이터를 저장한 것으로, HDD(Hard Disk Drive), SSD(Solid State Disk), SDD(Silicon Disk Drive), ROM, RAM, CD-ROM, 자기 테이프, 플로피 디스크, 광 데이터 저장 장치 등을 포함할 수 있다. 또한, 저장부에는 주행구역에 대한 맵(Map)이 저장될 수 있다. 맵은 이동 로봇과 유선 또는 무선 통 신을 통해 정보를 교환할 수 있는 외부 단말기, 서버 등에 의해 입력된 것일 수도 있고, 이동 로봇이 스스 로 학습을 하여 생성한 것일 수도 있다. 맵에는 주행구역 내의 방들의 위치가 표시될 수 있다. 또한, 이동 로봇의 현재 위치가 맵 상에 표시될 수 있으며, 맵 상에서의 이동 로봇의 현재의 위치는 주행 과정에서 갱신될 수 있다. 외부 단말기는 저장부 에 저장된 맵과 동일한 맵을 저장한다. 상기 저장부는 청소 이력 정보를 저장할 수 있다. 이러한 청소 이력 정보는 청소를 수행할 때마다 생성될 수 있다. 상기 저장부에 저장되는 주행구역에 대한 맵은, 청소 중 주행에 사용되는 내비게이션 맵(Navigation map), 위치 인식에 사용되는 SLAM(Simultaneous localization and mapping) 맵, 장애물 등에 부딪히면 해당 정보를 저장하여 학습 청소시 사용하는 학습 맵, 전역 위치 인식에 사용되는 전역 위치 맵, 인식된 장애물에 관한 정보 가 기록되는 장애물 인식 맵 등일 수 있다. 한편, 상술한 바와 같이 용도별로 상기 저장부에 맵들을 구분하여 저장, 관리할 수 있지만, 맵이 용도별로 명확히 구분되지 않을 수도 있다. 예를 들어, 적어도 2 이상의 용도로 사용할 수 있도록 하나의 맵에 복수의 정 보를 저장할 수도 있다. 제어부는 주행제어모듈, 지도생성모듈, 위치인식모듈 및 장애물인식모듈을 포함할 수 있다. 도 1 내지 도 5를 참조하면, 주행제어모듈은 이동 로봇의 주행을 제어하는 것으로, 주행 설정에 따라 주행부의 구동을 제어한다. 또한, 주행제어모듈은 주행부의 동작을 바탕으로 이동 로봇의 주행경로를 파악할 수 있다. 예를 들어, 주행제어모듈은 휠 유닛의 회전속도를 바탕으로 이동 로봇 의 현재 또는 과거의 이동속도, 주행한 거리 등을 파악할 수 있으며, 이렇게 파악된 이동 로봇의 주 행 정보를 바탕으로, 맵 상에서 이동 로봇의 위치가 갱신될 수 있다. 지도생성모듈은 주행구역의 맵을 생성할 수 있다. 지도생성모듈은 영상획득부를 통해 획득한 영 상을 처리하여 맵을 작성할 수 있다. 즉, 청소 영역과 대응되는 청소 맵을 작성할 수 있다. 또한, 지도생성모듈은 각 위치에서 영상획득부를 통해 획득한 영상을 처리하여 맵과 연계시켜 전역위 치를 인식할 수 있다. 위치인식모듈은 현재 위치를 추정하여 인식한다. 위치인식모듈은 영상획득부의 영상 정보를 이 용하여 지도생성모듈과 연계하여 위치를 파악함으로써, 이동 로봇의 위치가 갑자기 변경되는 경우에 도 현재 위치를 추정하여 인식할 수 있다. 또한, 위치인식모듈은 현재 위치하는 영역의 속성을 인식할 수 있다, 즉, 위치인식모듈는 공간을 인 식할 수 있다. 이동 로봇은 위치인식모듈을 통해 연속적인 주행 중에 위치 인식이 가능하고 또한, 위치인식모듈 없이 지도생성모듈 및 장애물인식모듈을 통해, 맵을 학습하고 현재 위치 등을 추정할 수 있다. 이동 로봇이 주행하는 중에, 영상획득부는 이동 로봇 주변의 영상들을 획득한다. 이하, 영상획 득부에 의해 획득된 영상을 '획득영상'이라고 정의한다. 획득영상에는 천장에 위치하는 조명들, 경계(edge), 코너(corner), 얼룩(blob), 굴곡(ridge) 등의 여러가지 특 징(feature)들이 포함된다. 지도생성모듈은 획득영상들 각각으로부터 특징을 검출하고, 각 특징점을 근거로 디스크립터를 산출한다. 지도생성모듈은 각 위치의 획득영상을 통해 얻은 디스크립터 정보를 바탕으로, 획득영상마다 적어도 하나 의 디스크립터를 소정 하위 분류규칙에 따라 복수의 군으로 분류하고, 소정 하위 대표규칙에 따라 같은 군에 포 함된 디스크립터들을 각각 하위 대표 디스크립터로 변환할 수 있다. 다른 예로, 실(room)과 같이 소정 구역내의 획득영상들로부터 모인 모든 디스크립터를 소정 하위 분류규칙에 따 라 복수의 군으로 분류하여 상기 소정 하위 대표규칙에 따라 같은 군에 포함된 디스크립터들을 각각 하위 대표 디스크립터로 변환할 수도 있다. 지도생성모듈은 이 같은 과정을 거쳐, 각 위치의 특징분포를 구할 수 있다. 각 위치 특징분포는 히스토그 램 또는 n차원 벡터로 표현될 수 있다. 또 다른 예로, 지도생성모듈은 소정 하위 분류규칙 및 소정 하위 대표규칙을 거치지 않고, 각 특징점으로부터 산출된 디스크립터를 바탕으로 미지의 현재위치를 추정할 수 있다. 또한, 위치 도약 등의 이유로 이동 로봇의 현재 위치가 미지의 상태가 된 경우에, 기 저장된 디스크립터 또는 하위 대표 디스크립터 등의 데이터를 근거로 현재 위치를 추정할 수 있다. 이동 로봇은, 미지의 현재 위치에서 영상획득부를 통해 획득영상을 획득한다. 영상을 통해 천장에 위 치하는 조명들, 경계(edge), 코너(corner), 얼룩(blob), 굴곡(ridge) 등의 여러가지 특징(feature)들이 확인된 다. 위치인식모듈은 획득영상으로부터 특징들을 검출하고, 디스크립터를 산출한다. 위치인식모듈은 미지의 현재 위치의 획득영상을 통해 얻은 적어도 하나의 디스크립터 정보를 근거로, 소정 하위 변환규칙에 따라 비교대상이 되는 위치 정보(예를 들면, 각 위치의 특징분포)와 비교 가능한 정보(하위 인 식 특징분포)로 변환한다. 소정 하위 비교규칙에 따라, 각각의 위치 특징분포를 각각의 인식 특징분포와 비교하여 각각의 유사도를 산출할 수 있다. 각각의 위치에 해당하는 상기 위치 별로 유사도(확률)를 산출하고, 그 중 가장 큰 확률이 산출되는 위 치를 현재위치로 결정할 수 있다.이와 같이, 제어부는 주행구역을 구분하고 복수의 영역으로 구성된 맵을 생성하거나, 기저장된 맵을 바탕 으로 본체의 현재 위치를 인식할 수 있다. 제어부는 맵이 생성되면, 생성된 맵을 통신부를 통해 외부 단말기, 서버 등으로 전송할 수 있다. 또 한, 제어부는 앞서 설명한 바와 같이, 외부 단말기, 서버 등으로부터 맵이 수신되면, 저장부에 저장 할 수 있다. 이때, 맵은 청소 영역을 복수의 영역으로 구분되고, 복수의 영역을 연결하는 연결통로가 포함하며, 영역 내의 장애물에 대한 정보를 포함할 수 있다. 제어부는 청소명령이 입력되면, 맵 상의 위치와 이동 로봇의 현재위치가 일치하는지 여부를 판단한다. 청 소명령은 리모컨, 입력부 또는 외부 단말기로부터 입력될 수 있다. 제어부는 현재 위치가 맵 상의 위치와 일치하지 않는 경우, 또는 현재 위치를 확인할 수 없는 경우, 현재 위치를 인식하여 이동 로봇의 현재 위치를 복구한 한 후, 현재 위치를 바탕으로 지정영역으로 이동하도록 주행부를 제어할 수 있다. 현재 위치가 맵 상의 위치와 일치하지 않는 경우 또는 현재 위치를 확인 할 수 없는 경우, 위치인식모듈은 영상획득부로부터 입력되는 획득영상을 분석하여 맵을 바탕으로 현재 위치를 추정할 수 있다. 또한, 장애 물인식모듈 또는 지도생성모듈 또한, 같은 방식으로 현재 위치를 인식할 수 있다. 위치를 인식하여 이동 로봇의 현재 위치를 복구한 후, 주행제어모듈은 현재 위치로부터 지정영역으로 주행경로를 산출하고 주행부를 제어하여 지정영역으로 이동한다. 서버로부터 청소 패턴 정보를 수신하는 경우, 주행제어모듈은 수신한 청소 패턴 정보에 따라, 전체 주행구 역을 복수의 영역으로 나누고, 하나 이상의 영역을 지정영역으로 설정할 수 있다. 또한, 주행제어모듈은 수신한 청소 패턴 정보에 따라 주행경로를 산출하고, 주행경로를 따라 주행하며, 청 소를 수행할 수 있다. 제어부는 설정된 지정영역에 대한 청소가 완료되면, 청소기록을 저장부에 저장할 수 있다. 또한, 제어부는 통신부를 통해 이동 로봇의 동작상태 또는 청소상태를 소정 주기로 외부 단말기, 서버로 전송할 수 있다. 그에 따라 외부 단말기는 수신되는 데이터를 바탕으로, 실행중인 애플리케이션의 화면상에 맵과 함께 이동 로봇 의 위치를 표시하고, 또한 청소 상태에 대한 정보를 출력한다. 본 발명의 실시예에 따른 이동 로봇은 일방향으로 장애물이나 벽면이 감지될 때까지 이동하다가, 장애물인 식모듈이 장애물을 인식하면, 인식된 장애물의 속성에 따라 직진, 회전 등 주행 패턴을 결정할 수 있다. 한편, 제어부는 인식된 장애물의 속성에 기초하여 다른 패턴으로 회피주행을 수행하도록 제어할 수 있다. 제어부는 비위험 장애물(일반 장애물), 위험 장애물, 이동 가능한 장애물 등 장애물의 속성에 따라 다른 패턴으로 회피 주행하도록 제어할 수 있다. 예를 들어, 제어부는 위험 장애물은 더 긴 거리의 안전 거리를 확보한 상태에서 우회하여 회피하도록 제어 할 수 있다. 또한, 제어부는 이동 가능한 장애물의 경우에 소정 대기 시간 후에도 장애물이 이동하지 않으면, 일반 장 애물에 대응하는 회피 주행 또는 위험 장애물에 대응하는 회피 주행을 수행하도록 제어할 수 있다. 또는, 제어 부는 이동 가능한 장애물에 대응하는 회피 주행 패턴이 별도로 설정된 경우에는 이에 따라 주행하도록 제 어할 수 있다. 본 발명의 실시예에 따른 이동 로봇은, 머신 러닝(machine learning) 기반의 장애물 인식 및 회피를 수행 할 수 있다. 상기 제어부는, 입력 영상에서 머신 러닝(machine learning)으로 기학습된 장애물을 인식하는 장애물인식 모듈과 상기 인식된 장애물의 속성에 기초하여, 상기 주행부의 구동을 제어하는 주행제어모듈을 포함할 수 있다. 한편, 도 5에서는 복수의 모듈(151, 152, 153, 154)이 제어부 내에 별도로 구비되는 예를 도시하였으나, 본 발명은 이에 한정되지 않는다. 예를 들어, 위치인식모듈과 장애물인식모듈은 하나의 인식기로써 통합되어 하나의 인식모듈로 구성될 수 있다. 이 경우에, 머신 러닝 등의 학습 기법을 이용하여 인식기를 학습시키고, 학습된 인식기는 이후 에 입력되는 데이터를 분류하여 영역, 사물 등의 속성을 인식할 수 있다. 실시예에 따라서, 지도생성모듈, 위치인식모듈, 및, 장애물인식모듈이 하나의 통합모듈로 구성 될 수도 있다. 이하에서는, 위치인식모듈과 장애물인식모듈은 하나의 인식기로써 통합되어 하나의 인식모듈로 구성되는 실시예를 중심으로 설명하지만, 위치인식모듈과 장애물인식모듈이 각각 구비되는 경우에도 동일한 방식으로 동작할 수 있다. 본 발명의 실시예에 따른 이동 로봇은, 머신 러닝으로 사물, 공간의 속성이 학습된 인식모듈을 포함 할 수 있다. 머신 러닝은 컴퓨터에게 사람이 직접 로직(Logic)을 지시하지 않아도 데이터를 통해 컴퓨터가 학습을 하고 이를 통해 컴퓨터가 알아서 문제를 해결하게 하는 것을 의미한다. 딥러닝(Deep Learning)은. 인공지능(artificial intelligence)을 구성하기 위한 인공신경망(Artificial Neural Networks: ANN)에 기반으로 해 컴퓨터에게 사람의 사고방식을 가르치는 방법으로 사람이 가르치지 않아도 컴퓨 터가 스스로 사람처럼 학습할 수 있는 인공지능 기술이다. 상기 인공신경망(ANN)은 소프트웨어 형태로 구현되거나 칩(chip) 등 하드웨어 형태로 구현될 수 있다. 인식모듈은 공간의 속성, 장애물 등 사물의 속성이 학습된 소프트웨어 또는 하드웨어 형태의 인공신경망 (ANN)을 포함할 수 있다. 예를 들어, 인식모듈은 딥러닝(Deep Learning)으로 학습된 CNN(Convolutional Neural Network), RNN(Recurrent Neural Network), DBN(Deep Belief Network) 등 심층신경망(Deep Neural Network: DNN)을 포함 할 수 있다. 인식모듈은 상기 심층신경망(DNN)에 포함된 노드들 사이의 가중치(weight)들에 기초하여 입력되는 영상 데 이터에 포함되는 공간, 사물의 속성을 판별할 수 있다. 한편, 상기 주행제어모듈은 상기 인식된 공간, 장애물의 속성에 기초하여 상기 주행부의 구동을 제어 할 수 있다. 한편, 인식모듈은, 머신 러닝(machine learning)으로 기학습된 데이터에 기초하여 상기 선택된 특정 시점 영상에 포함되는 공간, 장애물의 속성을 인식할 수 있다. 한편, 저장부에는 공간, 사물 속성 판별을 위한 입력 데이터, 상기 심층신경망(DNN)을 학습하기 위한 데이 터가 저장될 수 있다. 저장부에는 영상획득부가 획득한 원본 영상과 소정 영역이 추출된 추출 영상들이 저장될 수 있다. 또한, 실시예에 따라서는, 저장부에는 상기 심층신경망(DNN) 구조를 이루는 웨이트(weight), 바이어스 (bias)들이 저장될 수 있다. 또는, 실시예에 따라서는, 상기 심층신경망 구조를 이루는 웨이트(weight), 바이어스(bias)들은 인식모듈 의 임베디드 메모리(embedded memory)에 저장될 수 있다. 한편, 상기 인식모듈은 상기 영상획득부가 영상을 획득하거나 영상의 일부 영역을 추출할 때마다 소 정 영상을 트레이닝(training) 데이터로 사용하여 학습 과정을 수행하거나, 소정 개수 이상의 영상이 획득된 후 학습 과정을 수행할 수 있다. 또는, 이동 로봇은 통신부를 통하여 상기 소정 서버로부터 머신 러닝과 관련된 데이터를 수신할 수 있다. 이 경우에, 이동 로봇은, 상기 소정 서버로부터 수신된 머신 러닝과 관련된 데이터에 기초하여 인식모듈 을 업데이트(update)할 수 있다.도 6은 본 발명의 일 실시예에 따른 제품 데이터(product data)를 이용한 학습(Learning)에 대한 설명에 참조되 는 도면이다. 도 6을 참조하면, 이동 로봇 등 소정 기기의 동작으로 획득되는 제품 데이터(product data)가 서버로 전송될 수 있다. 예를 들어, 이동 로봇은, 서버로 공간(space), 사물(Object), 사용(Usage) 관련 데이터(Data)를 서버 로 전송할 수 있다. 여기서, 공간(space), 사물(Object) 관련 데이터는 이동 로봇이 인식한 공간(space)과 사물(Object)의 인 식 관련 데이터이거나, 영상획득부가 획득한 공간(space)과 사물(Object)에 대한 이미지 데이터일 수 있다. 또한, 사용(Usage) 관련 데이터(Data)는 소정 제품, 예를 들어, 이동 로봇의 사용에 따라 획득되는 데이터 로, 사용 이력 데이터, 센서부에서 획득된 센싱 데이터 등이 해당될 수 있다. 한편, 이동 로봇의 제어부, 더욱 상세하게는 인식모듈에는 CNN(Convolutional Neural Network) 등 심층신경망 구조(DNN)가 탑재될 수 있다. 상기 학습된 심층신경망 구조(DNN)는 인식용 입력 데이터를 입력받고, 입력 데이터에 포함된 사물, 공간의 속성 을 인식하여, 그 결과를 출력할 수 있다. 또한, 상기 학습된 심층신경망 구조(DNN)는 인식용 입력 데이터를 입력받고, 이동 로봇의 사용(Usage) 관 련 데이터(Data)를 분석하고 학습하여 사용 패턴, 사용 환경 등을 인식할 수 있다. 한편, 공간(space), 사물(Object), 사용(Usage) 관련 데이터(Data)는 통신부를 통하여 서버로 전송될 수 있다. 서버는 학습된 웨이트(weight)들의 구성을 생성할 수 있고, 서버는 심층신경망(DNN) 구조를 트레이닝 (training) 데이터를 사용하여 학습할 수 있다. 서버는 수신한 데이터에 기초하여, 심층신경망(DNN)을 학습시킨 후, 업데이트된 심층신경망(DNN) 구조 데이 터를 이동 로봇으로 전송하여 업데이트하게 할 수 있다. 이에 따라, 이동 로봇 등 홈 어플라이언스 제품이 점점 더 똑똑해지고, 사용할수록 진화되는 사용자 경험 (UX)을 제공할 수 있다. 도 7은 본 발명의 일 실시예에 따른 서버의 간략한 내부 블록도의 일예이다 도 7을 참조하면, 서버는, 통신부, 저장부, 학습모듈, 및 프로세서를 구비할 수 있다. 프로세서는, 서버의 전반적인 동작을 제어할 수 있다. 한편, 서버는, 상기 이동 로봇 등 홈 어플라이언스 제조사가 운영하는 서버 또는 서비스 제공자가 운 영하는 서버일 수 있고, 일종의 클라우드(Cloud) 서버일 수 있다. 통신부는, 휴대 단말기, 이동 로봇 등 홈 어플라이언스, 게이트웨이 등으로부터 상태 정보, 동작 정 보, 조작 정보 등 각종 데이터를 수신할 수 있다. 그리고 통신부는 수신되는 각종 정보에 대응하는 데이터를 휴대 단말기, 이동 로봇 등 홈 어플라이언 스, 게이트웨이 등으로 송신할 수 있다. 이를 위해, 통신부는 인터넷 모듈, 이동 통신 모듈 등 하나 이상의 통신 모듈을 구비할 수 있다. 저장부는, 수신되는 정보를 저장하고, 이에 대응하는 결과 정보 생성을 위한 데이터를 구비할 수 있다. 또한, 저장부는, 머신 러닝에 사용되는 데이터, 결과 데이터 등을 저장할 수 있다. 학습모듈은 상기 이동 로봇 등 홈 어플라이언스의 학습기 역할을 수행할 수 있다. 상기 학습모듈에는 인공신경망, 예를 들어, CNN(Convolutional Neural Network), RNN(Recurrent Neural Network), DBN(Deep Belief Network) 등 심층신경망(Deep Neural Network: DNN)을 포함될 수 있고, 심층신경망 을 학습할 수 있다.한편, 상기 제어부는 설정에 따라 학습 후 상기 이동 로봇 등 홈 어플라이언스의 인공신경망 구조를 학습된 인공신경망 구조로 업데이트시키도록 제어할 수 있다. 또한, 상기 학습모듈은, 인식용 입력 데이터를 입력받고, 입력 데이터에 포함된 사물, 공간의 속성을 인식 하여, 그 결과를 출력할 수 있다. 이 경우에, 통신부는 이동 로봇으로 인식 결과를 송신할 수 있다. 또한, 상기 학습모듈은, 이동 로봇의 사용(Usage) 관련 데이터(Data)를 분석하고 학습하여 사용 패턴, 사용 환경 등을 인식하여, 그 결과를 출력할 수 있다. 이 경우에, 통신부는 이동 로봇으로 인 식 결과를 송신할 수 있다. 이에 따라, 이동 로봇 등 홈 어플라이언스 제품들은 서버로부터 인식 결과를 수신하고, 수신된 인식 결과를 활용하여 동작할 수 있다. 또한, 서버가 제품 데이터를 이용하여 학습하여 점점 더 똑똑해지므로, 홈 어플라이언스 제품을 사용할수록 진화되는 사용자 경험(UX)을 제공할 수 있다. 한편, 이동 로봇 및 서버는 외부 정보(external information)도 이용할 수 있다. 예를 들어, 이동 로봇 및 서버는, 이동 로봇 등 특정 홈 어플라이언스 제품의 공간 정보, 사물 정보, 사용 패턴 등의 내부 정보 및 다른 제품으로부터 획득하거나, 서버가 다른 연계 서비스 서버로부터 획득한 외부 정보를 종합적으로 사용하여 우수한 사용자 경험을 제공할 수 있다. 본 발명의 일실시예에 따르면, 인공지능을 통한 와이파이(Wi-Fi)로 연결된 홈 어플라이언스 네트워크 시스템 내 의 제품 운전 순서를 최적화하고, 최적 운전 순서를 사용자에게 제시할 수 있다. 예를 들어, 이동 로봇으로 집안 청소를 수행하고, 공기 청정기(12, 13)로 청소 중 생긴 먼지 관리를 수행 하며, 공기조화기로 집안 습도 및 온도 관리하고, 세탁기가 사용자가 집에 도착하는 시간에 맞추어 세 탁이 종료되도록 세탁을 수행할 수 있다. 상기 서버는 사용자가 발화한 음성 입력 신호를 수신하여 음성 인식을 수행할 수 있다. 이를 위해, 상기 서 버는 음성 인식 모듈을 포함할 수 있고, 음성 인식 모듈은 입력 데이터에 대하여 음성 인식을 수행하여 음 성 인식 결과를 출력하도록 학습된 인공신경망을 포함할 수 있다. 한편, 상기 서버는 음성 인식을 위한 음성 인식 서버를 포함할 수 있다. 또한, 음성 인식 서버도 음성 인식 과정 중 소정 과정을 분담하여 수행하는 복수의 서버를 포함할 수 있다. 예를 들어, 음성 인식 서버는, 음성 데 이터를 수신하고, 수신한 음성 데이터를 텍스트(text) 데이터로 변환하는 자동 음성 인식(Automatic Speech Recognition: ASR) 서버, 및, 상기 자동 음성 인식 서버로부터 상기 텍스트 데이터를 수신하고, 수신한 텍스트 데이터를 분석하여 음성 명령을 판별하는 자연어 처리(Natural Language Processing: NLP) 서버를 포함할 수 있 다. 경우에 따라서, 음성 인식 서버는, 자연어 처리 서버가 출력한 텍스트 음성 인식 결과를 음성 데이터로 변 환하여 다른 서버 또는 홈 어플라이언스로 송신하는 텍스트 음성 변환(Text to Speech: TTS) 서버를 더 포함할 수 있다. 본 발명에 따르면, 이동 로봇 및/또는 서버가 음성 인식을 수행할 수 있어, 이동 로봇의 제어를 위한 입력을 사용자 음성을 사용할 수 있다. 종래의 음성 인식을 지원하는 로봇 청소기에서 음성 인식은 단순히 제어를 위한 수단에 불과하였다. 그로 인해 로봇 청소기는 인식된 제어 명령만 수행하게 되므로, 사용자가 현재 어떤 기능을 많이 사용하고 어떤 부분이 청 소가 덜 되는지에 대한 분석은 음성이 아닌 다른 방법을 통해 알아봐야 하는 단점이 있었다. 하지만, 본 발명은, 이동 로봇이 발화하여 단순한 단말 제어보다 간단한 인터랙션(Interaction) 기능을 제 공할 수 있다. 또한, 본 발명에 따르면, 이동 로봇이 능동적으로 먼저 정보를 제공하거나 기능, 서비스를 추천하는 음성 을 출력함으로써 사용자에게 더욱 다양하고 적극적인 제어 기능을 제공할 수 있다. 또한, 본 발명에 따르면, 이동 로봇이 사용자의 사용패턴을 학습하고 이해할 수 있다. 이에 따라, 이동 로 봇이 사용자에게 먼저 소정 기능을 제안하면서 상호작용할 수 있어, 더 효율적이고 사용자 친화적인 동작 을 수행할 수 있다. 도 8은 본 발명의 일 실시예에 따른 이동 로봇의 제어 방법을 도시한 순서도이고, 도 9는 본 발명의 실시예에 따른 이동 로봇의 제어 방법에 관한 설명에 참조되는 도면이다. 도 8을 참조하면, 이동 로봇은 명령 또는 설정에 따라서 이동하며 청소를 시작할 수 있다(S810). 예를 들 어, 이동 로봇은 청소 시작 명령 또는 청소 예약 설정에 따라서, 저장부에 저장된 내비게이션 (navigation) 맵 또는 SLAM(Simultaneous localization and mapping) 맵에 기반하여 이동할 수 있다. 이동 로봇은 이동하며 청소를 수행할 수 있고, 센서부에서 획득되는 센싱 데이터, 영상획득부에 서 획득되는 이미지 데이터 등을 저장부에 저장할 수 있다. 또한, 이동 로봇은 주행 이력 데이터(driving history data), 청소 이력 데이터(cleaning history data) 등 청소 수행으로 획득되는 데이터를 저장부에 저장할 수 있다. 여기서 청소 수행으로 획득되는 데이터는, 이동 로봇의 사용 기록일 수 있다. 예를 들어, 일반 청소 완료 횟수, 충전대 복귀 횟수, 영역별 청소 기능 완료 횟수, 운용 시간, 영역별 청소 세기 평균, 영역별 먼지량, 영 역별 청소 모드(꼼꼼청소, 퀵(quick) 청소, 일반 청소 등) 빈도 및 비율, 모니터링, 지정 청소, 집중 청소, 가 상벽(virtual wall) 포함 청소 등 기능 사용 횟수, 상기 언급된 기록의 시간대별 집중도 중 적어도 하나를 포함 할 수 있다. 또한, 이동 로봇이 수행하는 청소 기능뿐만 아니라 다른 기능에 관한 사용 기록도 저장될 수 있다. 예를 들어, 지정 청소, 집중 청소, 가상벽(virtual wall) 포함 청소 등의 청소 사용 이력, 지정된 영역에 대한 모니터링(monitoring), 움직이는 오브젝트를 인식하고, 인식된 오브젝트를 촬영하여 지정된 기기로 전송해주는 홈가드 기능, 맵핑(mapping) 등 이동 로봇이 제공할 수 있는 기능, 물건 찾기, 온도, 습도, 공기질 먼지 측정 등 환경 센싱 및 주행 전략으로 사용될 수 있는 것을 사용 기록으로 저장할 수 있다. 이러한 주행으로 획득되는 데이터를 이용하여, 이동 로봇 및/또는 서버는 사용자의 이동 로봇 사 용 패턴, 집 등 사용 환경 내의 각 영역별 공간 정보, 사용 환경 내에 존재하는 사물 정보를 분석하고 학습할 수 있다. 또한, 이동 로봇은 이전의 청소 수행으로 획득된 기존 데이터에 기반하여, 특수지역을 판별할 수 있다 (S820). 이동 로봇은 영상획득부로부터 획득된 영상에 기초하여 현재 위치 및 공간을 식별할 수 있고 특수지역 여부를 판별할 수 있다. 또한, 이동 로봇은, 현재 식별된 위치 및 공간 정보에 기초하여 해당 공 간의 영역별 정보 등을 추가적으로 확인하여 특수지역 여부를 판별할 수 있다. 여기서, 상기 특수지역은, 주행 불능 상태가 발생했었던 위험지역일 수 있다. 예를 들어, 위험지역은, 스턱, 트 랩, 낙하, 전원 오프(off) 등 주행 불능 상황이 발생한 지역일 수 있다. 또는, 상기 특수지역은, 주행 속도 또는 청소율이 평균값보다 낮았거나, 회전 횟수가 기준 횟수보다 많았던 저 효율지역일 수 있다. 예를 들어, 저효율지역은, 영역내 일정 면적 지정된 평균 속도 이하 주행 지역, 터닝 횟수 잦은 지역, 모든 대응 모션 일정 횟수 이상 발생 지역 등이 해당될 수 있다. 이동 로봇은, 이동 중에, 상기 판별된 특수지역에 도착하면(S830), 상기 특수지역에 대한 알림 정보를 출 력할 수 있다(S840). 바람직하게는 이동 로봇의 음향 출력부가 상기 특수지역에 대한 음성 안내 메시지를 출력할 수 있다 (S840). 이에 따라, 사용자의 주의를 끌고, 사용자가 소리가 들리는 방향으로 고개를 돌리거나 움직이면 자연스 럽게 상기 특수지역의 상황을 확인하게 할 수 있다. 한편, 이전의 청소 수행으로 획득된 기존 데이터는, 상기 특수지역에 등록된 장애물 정보를 더 포함할 수 있다. 이 경우에, 이동 로봇이 발화하는 음성 안내 메시지는, 상기 특수지역에 존재하는 장애물에 대한 안내 메 시지를 포함할 수 있다. 이에 따라, 사용자는 장애물의 종류, 위험 정도를 즉각 판단하여, 이동 로봇의 다 음 동작을 지시할 수 있다. 상기 음성 안내 메시지는, 상기 특수지역에 대한 청소 여부 확인을 요청하는 메시지를 포함할 수 있다. 또한, 상기 음성 안내 메시지는, 상기 특수지역으로 판별한 이유에 대한 설명, 또는 사용자가 음성 입력할 수 있는 명령어의 예시에 대한 안내 중 적어도 하나를 더 포함할 수 있다. 상기 특수지역으로 판별한 이유에 대한 설명을 제공함으로써, 사용자가 특수지역에 대해 더 빠르게 이해하는데 도움을 줄 수 있다.사용자가 음성 입력할 수 있는 명령어의 예시에 대한 안내를 제공함으로써, 사용자가 정확하게 피드백 음성을 입력하는데 도움을 줄 수 있다. 또한, 사용자가 예시된 명령어를 발화하는 경우에, 이동 로봇 및/또는 서 버는 더 빠르고 정확하게 사용자의 음성 명령을 인식할 수 있다. 또한, 음성으로 왜 위험 지역인지, 어떤 명령어를 쓸 수 있는지 등의 정보를 동시에 안내할 수 있다. 예를 들어, 이동 로봇이 \"과거 운행이 정지되었던 지역입니다. 청소를 원하시면 “청소”라고 답해주세요.\"라고 발화할 수 있다. 이동 로봇은, 위험지역, 저효율지역 등 특수지역을 판별할 수 있고(S820). 특수지역에 도착한 경우에 (S830), 특수지역에 대해서 청소를 수행할 지 여부를 먼저 문의할 수 있다(S840). 도 9를 참조하면, 전선이 많이 존재하는 위험지역에 도착한 이동 로봇은 위험지역을 안내하는 음성 안내 메시지를 발화할 수 있다. 음성 안내 메시지는 전선이 복잡하다는 내용과 청소가 어렵다는 내용 등을 포함할 수 있다. 본 발명의 일 실시예에 따른 이동 로봇은, 다수의 청소를 통해 인지된, 위험 장애물이 존재하는 청소 위험 지역, 청소 실패 이력이 있는 청소 실패 지역 등 특수지역에 진입 시, 음성을 통해 청소 위험 지역 등을 알릴 수 있다. 예를 들어, 전선 등의 위험 장애물이 존재하는 댁내 주행 환경에서 이동 로봇의 이동이 구속(Stuck)되는 상황 발생 가능성 있고, 한번 구속 상황이 발생한 장소에서는 지속적인 구속 상황이 발생할 확률이 높다. 지속적인 구속 상황 발생은 사용자의 불만 증가와 제품 신뢰도 하락을 야기할 수 있다. 따라서, 본 발명의 일 실시예에 따른 이동 로봇은, 위험 구간 진입 시 발화를 통해 위험 상황 인지를 하고 있음을 사용자에게 알릴 수 있다. 이에 따라, 사용자의 신뢰도, 선호도를 증대할 수 있다. 또한, 너무 복잡해 도저히 주행을 할 수 없는 영역에 대해, 사용자가 직접 정리를 하도록 유도해서, 청소를 완 료할 수 있도록 부가적 도움을 제공할 수 있다. 예를 들어, 특수지역 진입 시 이동 로봇이“여기는 제가 청소하기 어려워요”와 같은 음성 안내 메시지를 발화하고, 사용자는 해당지역에 복잡한 전선이나 장난감 등이 없는 지 확인하고 치울 수 있다. 이후, 이동 로봇 은 해당지역데 대한 청소를 안전하게 수행할 수 있다. 한편, 사용자의 피드백 응답에 따라, 특수지역에 대한 청소를 스킵(skip)하여, 다른 영역에 대한 청소에 지장이 없게 하거나 전체 청소 시간을 감소시킬 수 있다. 예를 들어, 사용자가“거긴 청소하지마\" 라고 하면 이동 로봇 은 해당지역을 청소하지 않는다. 한편, 발화 시 청소 소음으로 사용자가 음성 안내 메시지를 못알아 들어“뭐라고?”라고 말하면, 이동 로봇 은 방금 출력한 음성 안내 메시지를 반복하여 말해 줄 수 있다. 한편, 이동 로봇은, 청소 수행시 구속, 전원 오프 등 주행 불능 상황이 발생된 장소를 기록할 수 있고, 특 정 횟수 이상 주행 불능 상황이 발생되면 해당 지역을 위험 지역으로 분류할 수 있다. 이 경우에, 주행 불능 상황의 발생 빈도에 따라 음성 안내 메시지의 안내 강도 등을 증가시킬 수 있다. 예를 들어, 청소를 시작할 때, 이동 로봇은 상습적으로 주행 불능 상황이 발생하는 위험지역에 대해“주인 님, 이리와 보세요. 여기는 제가 정말 청소하기 어려워요. 조금만 치워주시면, 더 열심히 청소하겠습니다.\" 등 안내의 표현 강도 단계를 높힐 수 있다. 또한, 이동 로봇이 비효율적인 동작(주행 속도 또는 청소율이 평균값보다 낮거나, 회전 횟수가 기준 횟수 보다 많음)을 하는 구간에서 비효율적인 행동을 하지 않아도 되는지 먼저 음성으로 물어보면서 사용자와 상호작 용할 수 있다. 특수지역은 이동 로봇의 이동이 구속되는 등 안전의 위험과 다른 영역의 청소 수행에까지 악영향을 줄 수 있는 위험 지역이거나 청소를 수행하기 어려워 효율이 떨어지는 저효율지역이다. 따라서, 사용자에게 특수지역의 청소 여부를 물어보고(S840), 사용자 피드백이 수신되면(S850), 수신된 피드백 에 따라 동작할 수 있다(S860). 이동 로봇은, 소정 음성 대기 시간 동안에, 상기 음성 안내 메시지에 대한 사용자의 음성 피드백을 수신할 수 있다(S850), 사용자의 음성 피드백이 수신되면, 상기 수신된 음성 피드백에 포함되는 음성 명령을 식별할 수 있고 상기 식별 된 음성 명령에 대응하는 동작을 수행할 수 있다(S860). 사용자의 피드백 응답은 청소해, 진행해, 계속해, 괜찮아, 어, 응 등 긍정 어휘가 사용된 경우에, 청소를 원하 는 것으로 판별될 수 있다. 사용자의 피드백 응답은 아니, 청소하지마, 하지마 등 부정 어휘를 포함하는 경우에, 청소를 원하는 것으로 판 별될 수 있다. 실시예에 따라서, 상기 사용자의 음성 피드백에 대한 음성 명령의 식별은, 이동 로봇이 자체적으로 수행할 수 있다. 예를 들어, 이동 로봇은, 입력되는 데이터에 포함되는 음성을 인식하도록 학습된 인공신경망을 포함하고, 상기 인공신경망이 상기 수신된 음성 피드백에 포함되는 음성 명령을 인식할 수 있다. 또는, 상기 사용자의 음성 피드백에 대한 음성 명령의 식별은, 서버에서 수행할 수 있다. 이 경우에, 상기 수신된 음성 피드백에 포함되는 음성 명령을 식별하는 단계는, 입력되는 데이터에 포함되는 음 성을 인식하도록 학습된 인공신경망을 포함하는 음성 인식 서버로 상기 수신된 음성 피드백 데이터를 송신하는 단계, 및, 상기 음성 인식 서버로부터 상기 수신된 음성 피드백 데이터의 음성 인식 결과를 수신하는 단계를 포 함할 수 있다. 여기서, 상기 음성 인식 서버는 상기 서버의 일부로써 구성될 수 있지만, 상기 서버와 별도로 음성 인 식을 위한 전용 서버로서 구성되는 것도 가능하다. 또는, 이동 로봇과 서버에서 단계적으로 수행될 수 있다. 간단한 음성 명령의 경우에 1차적으로 이동 로봇이 인식하고, 이동 로봇이 인식하지 못하는 경우에는 서버를 이용할 수 있다. 이 경우에, 상기 음성 명령을 식별하는 단계는, 상기 수신된 음성 피드백이 기설정된 키워드(keyword)를 포함하 는 경우에, 상기 키워드에 대응하는 음성 명령을 식별하는 단계, 상기 수신된 음성 피드백이 기설정된 키워드 (keyword)를 포함하지 않는 경우에, 입력되는 데이터에 포함되는 음성을 인식하도록 학습된 인공신경망을 포함 하는 음성 인식 서버로 상기 수신된 음성 피드백 데이터를 송신하는 단계, 및, 상기 음성 인식 서버로부터 상기 수신된 음성 피드백 데이터의 음성 인식 결과를 수신하는 단계를 포함할 수 있다. 즉, 이동 로봇은 긍정 어휘, 부정 어휘, 또는 명령어의 예시로 안내되는 특정 어휘와 같이 간단한 키워드 (keyword)를 인식하고, 인식된 키워드에 따라 동작할 수 있다. 또한, 이동 로봇은 키워드가 인식되지 않으면, 사용자의 음성 피드백 데이터를 서버로 송신하여, 서버 로부터 음성 인식 결과를 수신할 수 있다. 한편, 사용자의 피드백이 일정 시간 수신되지 않으면(S850), 이동 로봇은 기설정되 회피 동작을 수행할 수 있다(S870). 실시예에 따라서, 사용자의 피드백이 일정 시간 수신되지 않으면(S850), 이동 로봇은 청소를 강행하도록 설정될 수 있다. 본 발명의 일 실시예에 따르면, 이동 로봇이 초기에는 아무말 없이 청소만 하다가 일정 시간이 경과한 후 에 사용자에게 말을 걸어오기 시작할 수 있다. 즉, 이동 로봇은 복수의 청소 수행으로 획득되는 데이터로 딥러닝을 수행할 수 있고, 딥러닝을 통해 위험 장애물 혹은 그 위치의 상황을 인식하여, 해당 상황을 복합적으로 설명할 수 있다. 또한, 변화하는 가정 환경 내 위험지역, 저효율지역을 지속적으로 업데이트 하여 사용자와 소통할 수 있다. 본 발명에 따르면, 음성을 통해 이동 로봇의 단순제어뿐 아닌 사용자와의 인터랙션(Interaction)으로 음성 인식 기능 및 제품 전체의 만족도를 향상할 수 있다. 또한, 청소가 어려운 지역을 음성으로 사용자의 입력을 받도록 제어하고. 사용자의 음성 입력에 따라 청소하거 나 청소하지 않음으로써, 청소 효율도 향상할 수 있다.도 10은 본 발명의 일 실시예에 따른 이동 로봇의 제어 방법을 도시한 순서도이다. 도 10을 참조하면, 본 발명의 일 실시예에 따른 이동 로봇은, 사용자의 음성 명령을 수신할 수 있다 (S1010). 종래의 음성 인식 이동 로봇은, 수신되는 음성 명령을 인식하여 대응하는 동작을 바로 수행할 뿐이다. 하지만, 본 발명의 일 실시예에 따른 이동 로봇은, 사용자의 음성 명령 수신(S1010)에 따라, 사용 기록 등 저장된 기존 데이터를 점검하고 확인할 수 있다(S1020). 여기서, 상기 사용 기록은, 일반 청소 완료 횟수, 충전대 복귀 횟수, 영역별 청소 기능 완료 횟수, 운용 시간, 영역별 청소 세기 평균, 영역별 먼지량, 영역별 청소 모드 사용 빈도, 영역별 청소 모드 사용 비율, 청소 기능 및 부가 기능별 사용 횟수 중 적어도 하나를 포함할 수 있다. 또한, 상기 언급된 사용 기록에 포함되는 항목들 의 시간대별 집중도를 더 포함할 수 있다. 또한, 이동 로봇이 수행하는 청소 기능뿐만 아니라 다른 기능에 관한 사용 기록도 저장되고 추후 확인될 수 있다. 예를 들어, 지정 청소, 집중 청소, 가상벽(virtual wall) 포함 청소 등의 청소 사용 이력, 지정된 영역에 대한 모니터링(monitoring), 움직이는 오브젝트를 인식하고, 인식된 오브젝트를 촬영하여 지정된 기기로 전송해주는 홈가드 기능, 맵핑(mapping) 등 이동 로봇이 제공할 수 있는 기능, 물건 찾기, 온도, 습도, 공기질 먼지 측정 등 환경 센싱 및 주행 전략으로 사용될 수 있는 것을 사용 기록으로 저장할 수 있다. 이러한 주행으로 획득되는 데이터를 이용하여, 이동 로봇 및/또는 서버는 사용자의 이동 로봇 사 용 패턴, 집 등 사용 환경 내의 각 영역별 공간 정보, 사용 환경 내에 존재하는 사물 정보를 분석하고 학습할 수 있다. 이동 로봇은, 사용 기록에 기초하여, 기준 횟수 미만으로 사용된 기능 중 적어도 하나를 추천하는 음성 안 내 메시지를 출력할 수 있다(S1030). 본 발명의 일 실시예에 따르면, 이동 로봇이 평상시에 사용되지 않았던 기능들에 대해서 사용자에게 음성 으로 제안함으로써 다른 기능도 사용할 수 있게 유도할 수 있다. 또한, 소정 음성을 입력한 사용자는 이동 로봇과 대화하기에 적절한 근거리에 위치하고 있다. 따라서, 이 동 로봇은 사용자의 음성에 대응하는 명령을 수행하기에 앞서, 근거리에 위치하는 사용자에게 소정 기능을 추천하거나 정보를 제공할 수 있고, 자연스러운 상호작용이 가능하다. 또한, 이동 로봇이 사용자의 판단이 필요하다고 생각되는 기능 및 케이스(case)에 대해서 먼저 물어보면서 향상된 청소 서비스 제공이 가능하다. 제어부는, 기설정된 우선 순위에 따라, 기준 횟수 미만으로 사용된 기능 중 적어도 하나를 선택하여 추천 하는 음성 안내 메시지를 출력하도록 음향 출력부를 제어할 수 있다. 여기서, 상기 기설정된 우선 순위는, 기설정된 기능별 중요도가 높은 순서일 수 있다. 예를 들어, SLAM 성공율 저하시 맵핑(mapping) 기능을 1순위, 미청소 영역 청소 기능을 2순위, 부재중 청소, 홈가드 등 스케줄에 따른 기능을 3순위, 상시 미청소 영역 가상벽(virtual wall) 추가, 위험지역 설정 기능 등을 4순위로 설정할 수 있다. 이 경우에, 사용자가 자주 사용하지 않는 기능들 중 우선 순위가 가장 높은 기능을 추천할 수 있다. 또는, 상기 기설정된 우선 순위는, 사용 횟수가 작은 순서일 수 있다. 즉, 사용을 안하거나 빈도수가 낮은 기능 을 추천할 수 있다. 이 경우에, 사용 횟수가 동일한 기능의 경우에는 랜덤(random)하게 추천하거나, 일정의 추 천 기능 풀(pool)을 설정하고 풀(pool)에 포함되는 기능을 우선적으로 추천할 수 있다. 또한, 제어부는 상기 기설정된 우선 순위에 따라 필요한 데이터를 점검하고 확인하여 추천 기능을 판별할 수 있다. 한편, 사용자 음성 명령의 수신(S1010)에 따라, 이동 로봇 및/또는 서버는 상기 사용자의 음성 명령을 식별할 수 있다. 이 경우에, 상기 기준 횟수 미만으로 사용된 기능 중 상기 식별된 사용자의 음성 명령과 연관된 기능을 선택하 여 추천할 수 있다.이를 위해, 이동 로봇 및/또는 서버는 사용 기록의 점검(S1020) 전 또는 후에 상기 수신된 음성 명령 을 인식할 수 있다. 본 발명의 일 실시예에 따르면, 음성 인식으로 판별된 제어 명령을 바탕으로 유사한 청소 기능 혹은 도움이 될 만한 기능을 추천할 수 있다. 예를 들어, 사용자의 음성 명령이, 꼼꼼청소 명령으로 판별되면 먼지량 많은 지역 집중청소 수행 기능을 추천하고, 퀵 청소 명령으로 판별되면 자주 청소하지 않는 지역 스킵(skip)을 추천할 수 있다. 한편, 상기 음성 안내 메시지에 대한, 소정 시간 이내에 상기 사용자의 음성 피드백이 수신되면(S1040), 상기 수신된 음성 피드백에 포함되는 피드백 음성 명령을 식별하고, 상기 식별된 피드백 음성 명령에 기초하여 소정 기능을 설정할 수 있다(S1050). 이후, 이동 로봇은 사용자 음성 명령의 수신(S1010)에 대응하여 식별된 사용자의 음성 명령에 대응하는 동 작을 수행할 수 있다(S0160). 한편, 도 8을 참조하여 설명한 것과 같이, 상기 사용자의 음성 피드백에 대한 음성 명령의 식별은, 이동 로봇 이 자체적으로 수행할 수 있다. 예를 들어, 이동 로봇은, 입력되는 데이터에 포함되는 음성을 인식하도록 학습된 인공신경망을 포함하고, 상기 인공신경망이 상기 수신된 음성 피드백에 포함되는 음성 명령을 인식할 수 있다. 또는, 상기 사용자의 음성 피드백에 대한 음성 명령의 식별은, 서버에서 수행할 수 있다. 이 경우에, 상기 수신된 음성 피드백에 포함되는 음성 명령을 식별하는 단계는, 입력되는 데이터에 포함되는 음 성을 인식하도록 학습된 인공신경망을 포함하는 음성 인식 서버로 상기 수신된 음성 피드백 데이터를 송신하는 단계, 및, 상기 음성 인식 서버로부터 상기 수신된 음성 피드백 데이터의 음성 인식 결과를 수신하는 단계를 포 함할 수 있다. 본 발명에 따르면, 이동 로봇이 사용자의 사용패턴을 인식하고 분석해서 평상시에 사용되지 않는 기능들에 대해서 먼저 제안을 하면서 사용자와 대화할 수 있다. 본 발명에 따르면, 음성을 통한 이동 로봇의 제어뿐만 아니라 사용자와의 인터랙션(Interaction)으로 음성 인식 기능 및 제품 만족도를 향상할 수 있다. 또한, 이동 로봇이 판단할 때 더 뛰어난 청소 전략(청소 모드, 스케줄)이 판별되는 경우에 판별된 청소 전 략 등을 음성으로 추천할 수 있다. 그리고 사용자의 피드백 음성 입력에 따라 해당 기능을 설정하고 사용할 수 있다. 이하에서는 도면들을 참조하여 이동 로봇이 능동적으로 사용자와 인터랙션하는 다양한 실시예를 설명한다. 도 11은 본 발명의 일 실시예에 따른 이동 로봇의 제어 방법을 도시한 순서도이고, 도 12는 본 발명의 실시예에 따른 이동 로봇의 제어 방법에 관한 설명에 참조되는 도면이다. 도 11을 참조하면, 이동 로봇은 현관 도어(door)가 열리는 것을 인식할 수 있다(S1110). 현관 도어 오픈 (open)의 인식은 현관 도어에 부착된 센서, 서버 등 다른 기기로부터 수신되는 신호에 기초하여 인식될 수 있다. 현관 도어 오픈(open)이 인식되면, 이동 로봇은 현관 도어로 이동하여(S1120), 사용자를 인식할 수 있다 (S1130). 예를 들어, 사용자 인식은 영상획득부를 통하여 획득되는 이미지를 인식하여 수행될 수 있다. 또는 다른 홈 어플라이언스, 서버로부터 관련 정보를 수신할 수 있다. 사용자가 인식되면(S1130), 이동 로봇은 사용자 부재시 이동 로봇의 동작 상황을 음성으로 브리핑할 수 있다(S1140). 이동 로봇은 사용자 부재시 이동 로봇의 동작 상황을 음성으로 브리핑할 수 있다(S1140). 도 12를 참조하면, 이동 로봇의 현관에서 들어오고 있는 사용자에게 접근하여, 사용자 부재시 이동 로봇 의 동작 상황을 브리핑하는 음성 안내 메시지를 음향 출력부를 통하여 출력할 수 있다.집안에 없을 때, 사람이 들어오면 이동 로봇이 마중을 나가 현관에서 음성 피드백을 제공할 수 있다. 브리 핑 후, 미세먼지가 많거나 사용자의 요청이 있을 경우 이동 로봇은 주변 청소를 진행할 수 있다. 또한, 이동 로봇은 와이파이 통신으로 연결된 홈 어플라이언스 네트워크 시스템에 포함되는 홈 어플라이언 스의 사용자 부재 시 동작 상황 및 결과를 브리핑할 수 도 있다. 사용자의 귀가를 감지하여, 이동 로봇은 당일 홈 어플라이언스들의 동작 기록을 먼저 안내할 수 있다. 이동 로봇은 사용자의 움직임에 추종하며 음성 브리핑을 제공할 수 있다. 예를 들어, 반려동물이 집에 돌아온 사람을 반겨주는 것처럼, 이동 로봇이 집에 들어온 사용자를 인식 후 사용자를 따라다니면서 그날의 청소 기록을 이야기할 수 있다. 한편, 이동 로봇은“로보킹, 이리와!”등 사용자의 발화에 대응하여 사용자 추종 주행 모드로 동작할 수 있다. 또한, 이동 로봇은 사용자 부재 중 집안 청소 시 청소하지 못한 미청소영역의 사진 등 소정 데이터를 애플 리케이션을 통해 사용자에게 제공할 수 있다. 본 발명의 일 실시예에 따르면, 이동 로봇이‘반려동물’과 유사하게 행동하여 사용자가 호감과 재미를 느 끼도록 할 수 있다. 또한, 사용자가 가정 내 홈 어플라이언스들의 상태를 확인할 필요 없이, 귀가 후 사용자 자신에게 접근한 이동 로봇의 음성으로 부재시 홈 어플라이언스들의 동작 상황을 알 수 있다. 또한, 사용자를 적극적으로 인식한다는 피드백을 주어 제품의 만족도를 상승시킬 수 있다. 만약 사용자가 인식되지 않으면(S1130), 시간 또는 횟수 기준으로 설정되는 실패 기준을 만족할 때까지(S1150), 사용자 인식을 수행할 수 있다. 실패 기준을 만족할 때까지 사용자가 인식되지 않으면(S1150), 충전대 복귀 후 대기, 홈가드 등 기설정된 동작 을 수행할 수 있다(S1160). 도 13은 본 발명의 일 실시예에 따른 이동 로봇의 제어 방법을 도시한 순서도이고, 도 14는 본 발명의 실시예에 따른 이동 로봇의 제어 방법에 관한 설명에 참조되는 도면이다. 도 13과 도 14를 참조하면, 이동 로봇은 홈 어플라이언스 네트워크 시스템에 포함되는 다른 기기로부터 소 정 데이터를 수신할 수 있다(S1810). 예를 들어, 공기 청청기는 실내 공기 센서를 통해 공간/영역 별 먼지 또는 공기 질 지수 데이터화할 수 있 다, 또한, 공기 청청기는 먼지 또는 공기 질 지수 데이터를 이동 로봇과 공유할 수 있다. 공기 청청기는 먼지 발생 유무를 감지하거나, 사람들이 많이 모여있다가 떠난 공간을 감지할 수 있다. 공기 청청기는 먼지 발생을 감지하면 운전을 시작하고, 이동 로봇에 먼지 발생 위치 데이터 등을 전 송할 수 있다. 한편, 이동 로봇은 공기 청청기로부터 수신한 데이터와 기존에 학습된 데이터에 기초하여 청소 계획 을 수립하고 추천할 수 있다(S1320). 예를 들어, 이동 로봇은 먼지가 많은 공간의 집중 청소를 추천하여 유도, 공기 청정기의 방향 전환을 추천하여 유도할 수 있다. 또한, 이동 로봇은 먼지 발생 정도, 감지되는 사람의 수 등을 고려하여 사용자에게 일정 시간 이후의 청소 계획을 제안할 수 있다. 이 때 이동 로봇은 현재 상태, 한 시간 뒤 청소 등 청소 계획을 포함하는 음성 안 내 메시지를 발화할 수 있다. 이동 로봇은 사용자의 응답 여부에 따라 청소를 진행할 수 있다. 만약 두 시간 뒤의 청소 시작을 포함하는 사용자의 음성 응답이 있으면, 이동 로봇은 두 시간 뒤에 청소를 시작할 수 있다. 본 발명의 일 실시예에 따르면, 홈 어플라이언스 간 연동 사용 시나리오를 통해 긍정적인 시너지 효과를 제공할 수 있다. 또한, 청소가 필요한 상황을 홈 어플라이언스들이 먼저 감지하여 사용자에게 제안함으로써 제품 신뢰성을 높일 수 있다. 본 발명의 실시예들 중 적어도 하나에 의하면, 이동 로봇은, 사용자에게 음성을 발화할 수 있어, 음성을 매개로 사용자와 대화하고 인터랙션할 수 있다. 또한, 본 발명의 실시예들 중 적어도 하나에 의하면, 요청하기 전에 먼저 이동 로봇이 능동적으로 정보를 제공 하고, 서비스, 기능 등을 추천함으로써, 사용자의 신뢰도, 선호도 및 제품 활용도를 높일 수 있다. 또한, 본 발명의 실시예들 중 적어도 하나에 의하면, 이동 로봇에게 위험한 위험지역, 청소가 쉽지 않은 저효율 지역을 능동적으로 안내함으로써, 이동 로봇의 안정성 및 사용자의 편의성을 제고하고, 운전 효율, 청소 효율 등을 향상시킬 수 있다. 또한, 본 발명의 실시예들 중 적어도 하나에 의하면, 사용자가 자주 사용하지 않는 기능 중 유용한 기능을 능동 적으로 추천함으로써, 사용자의 신뢰도, 선호도 및 제품 활용도를 높일 수 있다. 또한, 본 발명의 실시예들 중 적어도 하나에 의하면, 사용자의 음성 명령과 연관된 다른 기능을 추천함으로써, 사용자가 추가적인 노력을 하지 않고서도 연관된 기능을 간편하게 설정하고 이용할 수 있다. 또한, 본 발명의 실시예들 중 적어도 하나에 의하면, 음성 인식이 이동 로봇에서 자체적으로 수행되거나, 서버 에서 수행되거나, 이동 로봇과 서버에서 단계적으로 수행됨으로써, 효과적인 음성 인식을 수행할 수 있다. 또한, 본 발명의 실시예들 중 적어도 하나에 의하면, 음성 인식, 장애물 인식, 제품 데이터 분석 등에 인공지능 과 머신 러닝을 활용함으로써, 진화하는 사용자 경험(ux)을 제공할 수 있다. 본 발명에 따른 이동 로봇은 상기한 바와 같이 설명된 실시예들의 구성과 방법이 한정되게 적용될 수 있는 것이 아니라, 상기 실시예들은 다양한 변형이 이루어질 수 있도록 각 실시예들의 전부 또는 일부가 선택적으로 조합 되어 구성될 수도 있다. 한편, 본 발명의 실시예에 따른 이동 로봇의 제어 방법은, 프로세서가 읽을 수 있는 기록매체에 프로세서가 읽 을 수 있는 코드로서 구현하는 것이 가능하다. 프로세서가 읽을 수 있는 기록매체는 프로세서에 의해 읽혀질 수 있는 데이터가 저장되는 모든 종류의 기록장치를 포함한다. 프로세서가 읽을 수 있는 기록매체의 예로는 ROM, RAM, CD-ROM, 자기 테이프, 플로피디스크, 광 데이터 저장장치 등이 있으며, 또한, 인터넷을 통한 전송 등과 같 은 캐리어 웨이브의 형태로 구현되는 것도 포함한다. 또한, 프로세서가 읽을 수 있는 기록매체는 네트워크로 연 결된 컴퓨터 시스템에 분산되어, 분산방식으로 프로세서가 읽을 수 있는 코드가 저장되고 실행될 수 있다. 또한, 이상에서는 본 발명의 바람직한 실시예에 대하여 도시하고 설명하였지만, 본 발명은 상술한 특정의 실시"}
{"patent_id": "10-2018-0100647", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "예에 한정되지 아니하며, 청구범위에서 청구하는 본 발명의 요지를 벗어남이 없이 당해 발명이 속하는 기술분야 에서 통상의 지식을 가진자에 의해 다양한 변형실시가 가능한 것은 물론이고, 이러한 변형실시들은 본 발명의 기술적 사상이나 전망으로부터 개별적으로 이해되어서는 안될 것이다."}
{"patent_id": "10-2018-0100647", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일 실시예에 따른 홈 어플라이언스 네트워크 시스템 구성도이다. 도 2는 본 발명의 일 실시예에 따른 이동 로봇을 도시하는 사시도이다. 도 3은 도 2의 이동 로봇의 평면도이다. 도 4는 도 2의 이동 로봇의 측면도이다. 도 5는 본 발명의 일 실시예에 따른 이동 로봇의 주요 구성들 간의 제어관계를 도시한 블록도이다. 도 6은 본 발명의 일 실시예에 따른 제품 데이터(product data)를 이용한 학습(Learning)에 대한 설명에 참조되 는 도면이다. 도 7은 본 발명의 일 실시예에 따른 서버의 간략한 내부 블록도의 일예이다. 도 8은 본 발명의 일 실시예에 따른 이동 로봇의 제어 방법을 도시한 순서도이다. 도 9는 본 발명의 실시예에 따른 이동 로봇의 제어 방법에 관한 설명에 참조되는 도면이다. 도 10은 본 발명의 일 실시예에 따른 이동 로봇의 제어 방법을 도시한 순서도이다. 도 11은 본 발명의 일 실시예에 따른 이동 로봇의 제어 방법을 도시한 순서도이다. 도 12는 본 발명의 실시예에 따른 이동 로봇의 제어 방법에 관한 설명에 참조되는 도면이다. 도 13은 본 발명의 일 실시예에 따른 이동 로봇의 제어 방법을 도시한 순서도이다. 도 14는 본 발명의 실시예에 따른 이동 로봇의 제어 방법에 관한 설명에 참조되는 도면이다."}
