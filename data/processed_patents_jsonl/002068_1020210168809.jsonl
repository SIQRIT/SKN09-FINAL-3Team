{"patent_id": "10-2021-0168809", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0081091", "출원번호": "10-2021-0168809", "발명의 명칭": "고성능 딥페이크 비디오 검출 방법", "출원인": "부경대학교 산학협력단", "발명자": "권기룡"}}
{"patent_id": "10-2021-0168809", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "비디오에서 주요 인물을 식별하고, MTCNN(Multitask Cascaded Convolutional Network)을 사용하여 상기 인물의얼굴을 추출하는 단계;오픈 소스 툴박스를 사용하여 상기 추출된 각 얼굴에서 랜드마크를 추출하여 관심영역(ROI)을 수집하는 단계;상기 랜드마크를 추출한 후 얼굴의 적어도 하나 이상의 부분에서 얼굴 패치를 잘라내는 단계;분류기 네트워크에 입력할 증류 세트를 추출하는 단계; 및상기 증류 세트가 입력된 상기 분류기 네트워크의 출력을 분석하고 평가하여 상기 비디오의 인물 이미지에 대한딥페이크 감지를 수행하는 단계를 포함하는 것을 특징으로 하는 고성능 딥페이크 비디오 검출 방법."}
{"patent_id": "10-2021-0168809", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1 항에 있어서,상기 증류 세트는,상기 추출된 얼굴, 얼굴 증강, 진짜 또는 가짜 레이블 및 상기 얼굴 패치 중 적어도 하나를 포함하는 것을 특징으로 하는 고성능 딥페이크 비디오 검출 방법."}
{"patent_id": "10-2021-0168809", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 1 항에 있어서,상기 증류 세트를 획득하는 단계는,Inception V3 네트워크를 얼굴 전체와 얼굴 확대 결과를 훈련하는데 사용하고, MobileNet를 얼굴 패치를 훈련하는데 사용하며, 상기 두 출력이 전역 평균 풀링에 공급되는 것을 특징으로 하는 고성능 딥페이크 비디오 검출방법."}
{"patent_id": "10-2021-0168809", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 1 항에 있어서,상기 딥페이크 감지를 수행하는 단계 이후,상기 비디오에서 프레임의 기능 세트를 선택 후 얼굴 영역을 합성하고, 가상 임계값 수준을 변경하여 비디오에대한 최종 결정을 내리는 단계를 더 포함하는 것을 특징으로 하는 고성능 딥페이크 비디오 검출 방법."}
{"patent_id": "10-2021-0168809", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 고성능 딥페이크 비디오 검출 방법에 관한 것으로, 보다 상세하게는 적절한 가중치를 유지하면서 모델 의 정확도를 보장하는 고성능 딥페이크 비디오 검출 방법에 관한 것이다."}
{"patent_id": "10-2021-0168809", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 고성능 딥페이크 비디오 검출 방법에 관한 것으로, 보다 상세하게는 적절한 가중치를 유지하면서 모 델의 정확도를 보장하는 고성능 딥페이크 비디오 검출 방법에 관한 것이다."}
{"patent_id": "10-2021-0168809", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "딥페이크는 사진, 오디오 및 비디오 위조를 생성하는데 사용되는 일종의 인공지능 기술이다. 딥페이크를 구성하 는 데 사용되는 주요 방법은 딥 러닝 및 상관학습 GAN(Generative neural networks) 아키텍처를 기반으로 한다. GAN은 합성 이미지 생성에 가장 일반적으로 사용되는 생성 모델 학습을 위한 딥 러닝 기술이다. GAN 모델 아키 텍처에는 두 가지 하위 모델이 포함된다. 하나는 새로운 예를 생성하기 위한 생성기 모델이고, 다른 하나는 생 성된 예가 실제인지 가짜인지를 분류하기 위한 판별기 모델이다. GAN의 성장은 일련의 응용 프로그램과 얼굴 교환, 얼굴 조작, 얼굴 합성과 같은 정교한 기술의 개발로 이어지며 가짜 비디오의 수가 급격히 증가하는데 한몫하고 있다. 딥페이크 탐지 솔루션은 일반적으로 멀티 모달 탐지 접근 방식을 사용하여 대상 물질이 변경되었거나 합성적으 로 생성되었는지 여부를 평가한다. 기존의 탐지 접근 방식은 비젼 트랜스포머, 2-스트림 신경망, Afchar 등이 제안한 MesoNet 등과 같은 알고리즘 탐지 방법에서 AI 기반 알고리즘을 개발하는 데 중점을 두는 경우가 많다. 그러나 이미지의 중요한 영역을 강조 표시하는 데 초점을 맞추기 위해 수동 이미지 처리에는 주의를 덜 기울인 다. 이로 인해 모델이 모든 비디오를 처리해야 하므로 모델이 무거워지는 경우가 많다. 딥페이크 탐지 방식을 개선하기 위해 본 발명에서는 수동 처리와 AI 기반 알고리즘을 모두 사용했다. 가장 중요 한 정보, 지역 및 특징은 심층 신경망에 들어가기 전에 주의 깊게 집중되고 처리된다. 학습에 가장 관련성이 높은 요소에 집중하면 이런 네트워크에 대한 불필요한 학습 부담이 줄어들 뿐만 아니라 전체 모델의 정확도가 향상된다."}
{"patent_id": "10-2021-0168809", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "따라서, 본 발명은 상기한 바와 같은 문제점을 해결하기 위하여 제안된 것으로, 가장 대중적인 몇 가지 분류 모 델을 활용하여 가짜 비디오를 식별하고, 딥페이크 감지를 더 간단한 분류 문제로 변환할 수 있는 고성능 딥페이 크 비디오 검출 방법을 제공함에 있다. 본 발명의 목적은 이상에서 언급한 것으로 제한되지 않으며, 언급되지 않은 또 다른 목적들은 아래의 기재로부 터 본 발명이 속하는 기술 분야의 통상의 지식을 가진 자에게 명확히 이해될 수 있을 것이다."}
{"patent_id": "10-2021-0168809", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기와 같은 목적을 달성하기 위한 본 발명에 따른 고성능 딥페이크 비디오 검출 방법은, 비디오에서 주요 인물 을 식별하고, MTCNN(Multitask Cascaded Convolutional Network)을 사용하여 상기 인물의 얼굴을 추출하는 단 계; 오픈 소스 툴박스를 사용하여 상기 추출된 각 얼굴에서 랜드마크를 추출하여 관심영역(ROI)을 수집하는 단 계; 상기 랜드마크를 추출한 후 얼굴의 적어도 하나 이상의 부분에서 얼굴 패치를 잘라내는 단계; 분류기 네트 워크에 입력할 증류 세트를 추출하는 단계; 및 상기 증류 세트가 입력된 상기 분류기 네트워크의 출력을 분석하 고 평가하여 상기 비디오의 인물 이미지에 대한 딥페이크 감지를 수행하는 단계를 포함한다."}
{"patent_id": "10-2021-0168809", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명에 의하면, 가장 대중적인 소정의 분류 모델을 활용하여 가짜 비디오를 식별하고, 딥페이크 감지를 더 간단한 분류 문제로 변환함으로써, 적절한 가중치를 유지하면서 모델의 정확도를 높일 수 있다."}
{"patent_id": "10-2021-0168809", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 2, "content": "본 발명의 효과는 이상에서 언급한 것으로 제한되지 않으며, 언급되지 않은 또 다른 효과들은 아래의 기재로부 터 본 발명이 속하는 기술 분야의 통상의 지식을 가진 자에게 명확히 이해될 수 있을 것이다."}
{"patent_id": "10-2021-0168809", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명의 목적 및 효과, 그리고 그것들을 달성하기 위한 기술적 구성들은 첨부되는 도면과 함께 상세하게 후술 되어 있는 실시예들을 참조하면 명확해질 것이다. 본 발명을 설명함에 있어서 공지 기능 또는 구성에 대한 구체 적인 설명이 본 발명의 요지를 불필요하게 흐릴 수 있다고 판단되는 경우에는 그 상세한 설명을 생략할 것이다. 그리고 후술되는 용어들은 본 발명에서의 기증을 고려하여 정의된 용어들로서 이는 사용자, 운용자의 의도 또는 관례 등에 따라 달라질 수 있다. 그러나, 본 발명은 이하에서 개시되는 실시예들에 한정되는 것이 아니라 서로 다른 다양한 형태로 구현될 수 있"}
{"patent_id": "10-2021-0168809", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "다. 단지 본 실시예들은 본 발명의 개시가 완전하도록 하고, 본 발명이 속하는 기술분야에서 통상의 지식을 가 진 자에게 발명의 범주를 완전하게 알려주기 위해 제공되는 것이며, 본 발명은 청구항의 범주에 의해 정의될 뿐 이다. 그러므로 그 정의는 본 명세서 전반에 걸친 내용을 토대로 내려져야 할 것이다. 한편, 명세서 전체에서, 어떤 부분이 다른 부분과 \"연결\"되어 있다고 할 때, 이는 \"직접적으로 연결\"되어 있는 경우뿐 아니라, 그 중간에 다른 부재를 사이에 두고 \"간접적으로 연결\"되어 있는 경우도 포함한다. 또한 어떤 부분이 어떤 구성요소를 \"포함\"한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다른 구성요소를 제외하는 것이 아니라 다른 구성요소를 더 구비할 수 있다는 것을 의미한다. 본 발명에서는 신경망을 사용하여 분류의 정확도를 향상시킬 뿐만 아니라, 더 가벼운 백본을 사용할 수 있도록 하는 증류 세트를 생성하기 위한 수동 주의집중 대상 특정 영역이 있는 분류기 네트워크를 기반으로 하는 딥페 이크 탐지 아키텍처를 개시한다. 도 1은 본 발명의 실시예에 따른 고성능 딥페이크 비디오 검출을 위한 전체 네트워크를 도시한다. 이 발명에서 수동 증류 세트라고 하는 중요한 데이터 세트를 수동으로 생성하기 위한 이미지 처리의 몇 가지 단계를 개시하 고, 특별 영역에 중점을 둔다. 또한, 다음 단계의 합성을 용이하게 하기 위해 각 도메인에 대한 특징을 생성할 수 있는 일반 이미지 분류 모델로 사용한 모델 구조도 개시한다. <이미지 전처리> - 얼굴 추출 다음 단계로 넘어가기 전에 이미지를 전처리한다. 이미지 전처리는 앞으로 나아가는 전체 프로세스의 품질에 영 향을 미치기 때문에 중요하다. 또한 데이터 처리를 통해 전체 프로세스의 품질을 향상시킬 수 있다. 이미지 프로세스의 첫번째 단계는 오픈 라이브러리인 OpenCV로 구현된 사람 탐지이다. 이는 실제 사람의 얼굴을 식별하는데 도움이 되기 때문에 필요하다. 또한 얼굴이 실제가 아닌 사람이나 물체(조각상과 같이 사람과 같은 것)의 얼굴인 상황을 피하는데 도움이 된다. 이 이미지 전처리 단계는 얼굴 감지 실수도 최대한 줄이는 것을 목 표로 한다. 그런 다음 MTCNN(Multitask Cascaded Convolutional Networks)을 사용하여 얼굴을 추출한다. 이러 한 단계를 수행하면 모델을 속이는데 사용되는 데이터 세트의 오해의 소지가 있는 데이터의 양이 크게 줄어든다. 이러한 가상 사진을 포함하는 예가 도 2에 도시되어 있다. 일반적으로 일부 모델의 접근 방식은 얼굴 추출에만 집중한다. 이러한 모델은 때때로 실제가 아닌 사람의 얼굴을 식별할 수 있으며, 이는 모델의 품질에 심각한 영향을 미칠 수 있다. 사람 탐지는 현재 고수준 의미 특징 탐지, 원거리 필드에 대한 사람 탐지와 같이 “OpenCV” 모델보다 훨씬 우 수한 여러 모델들로 매우 인기가 있다. 다만, 인물 감지에 그다지 효과적이지 않은 라이브러리를 선택한 이유는 향후 출력에서 양질의 추출된 얼굴을 얻기 위해 인물 탐지에 입력 데이터를 엄격하게 제한하기 때문이다. 그 때문에 MTCNN 얼굴 추출 라이브러리를 사용하는 동안 해당 얼굴을 인식하기 위한 신뢰 수준도 마찬가지로 높게 설정된다. - 얼굴 증강 과적합 문제는 DFDC 데이터셋에서 항상 신중하게 고려되며, 과적합은 모델이 학습 데이터의 정보와 노이즈를 특 정 지점까지 학습하면 새 데이터에 대한 모델의 성능이 저하되는 것을 말한다. 이는 모델이 DFDC 데이터셋의 훈 련 데이터로 너무 잘 학습하지만 테스트 데이터의 결과가 예상만큼 좋지 않음을 의미한다. 이 문제를 해결하는 한 가지 방법은 증강을 사용하는 것이다. 이 품질을 높이는 측면에서 이전 연구에서는 데이터 증강이 이러한 부정적인 영향을 완화하는데 도움이 될 수 있음을 발견했다. 도 3의 a는 보정없는 원본 얼굴이며, b, c, d는 각각 얼굴에서 입, 눈, 코를 절단한 세 가지 유형의 증강을 도시하는 예시도이다. - 패치 추출 표현하기 어려운 눈, 코, 입과 같은 얼굴의 몇 가지 필수 특성을 사용하여 가짜 얼굴과 실제 얼굴을 구별한다. 이 문제를 전처리 단계에서 해결하기 위해 “OpenFace2” 오픈 소스 툴박스를 사용하여 추출된 각 얼굴에서 랜 드마크를 추출한다. 네트워크에 대한 입력으로 관심 영역(ROI)을 수집한다. 가짜 얼굴과 주변 사이에 존재하는 아티팩트를 드러내는 것이 목표이다. 얼굴과 주변 영역을 모두 포함하는 직사각형 영역이 RoI로 선택된다. 특히 얼굴 랜드마크를 사 용하여 RoI를 결정한다. 직사각형 영역 상자는 수학식 1과 같이 정의할 수 있다. 수학식 1"}
{"patent_id": "10-2021-0168809", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "여기서 은 모든 얼굴 랜드마크를 덮을 수 있는 가장 작은 경계 상자를 나타낸다. 변수"}
{"patent_id": "10-2021-0168809", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "은 [0, ] 과 [0 , ] 사이의 임의 값이며, 여기서 h와 w는 각각 추출된 얼굴 상자의 높이와 너비이다. 얼굴 랜드마크를 추출한 후 왼쪽 눈, 오른쪽 눈, 코, 입 등 얼굴의 여러 부분에서 얼굴 패치를 잘라낸다. RoI는 32×32로 크기가 조정된다. 도 3은 얼굴의 특정 영역에 할당된 중요한 정보를 도시한다. 'Origianl' 행에는 원본 얼굴 이미지가 포함되며, 두 번째 행은 FF++ 테스트 세트에서 무작위로 선택 조작된 얼굴 샘플 세트이다. 그리고 마지막 행은 조작된 얼 굴 샘플의 어텐션 맵을 보여준다. - 증류 세트 페이스북 AI는 어텐션 방법을 통한 증류법 아이디어를 고안했으며, 교사-학생 기법의 특정 트랜스포머를 소개했 다. 이는 학생이 어텐션을 통해 교사로부터 배울 수 있도록 하는 증류 토큰을 기반으로 한다. 셀프-어텐션을 통 해 다른 임베딩과 상호 작용한다는 점에서 클래스 토큰과 유사하게 작동하는 증류 토큰을 자동으로 생성한다. 그것은 그들의 모델이 셀프 어텐션 레이어를 통해 교사의 결과물로부터 배울 수 있도록 한다. 중요한 영역에 초 점을 맞춘 모델을 지시하기 위해 훈련 과정 전반에 걸쳐 모델 셀프 어텐션을 사용하는 대신 실제 훈련 과정 전 전처리 단계에서 로컬로 학습할 수 있는 모델을 개발하는 아이디어를 사용했다. 증류 세트는 어떤 얼굴 부분이 어떤 분류기 네트워크 입력에서 학습될 것인지 뿐만 아니라 얼굴의 어떤 부분이 훈련될 지 지정하기 위해 세트 로 그룹화되는 많은 패치를 포함한다. 이러한 증류 세트로의 배열은 훈련 정확도를 높이고 지역 앙상블에 편리 하다. <분류기 네트워크 아키텍처> 이전 단계를 통해 학습 및 추론에 유용한 정보가 많이 포함된 특수 특징 및 증류 세트를 얻는다. 대부분 얼굴과 그 안의 중요한 부위에 집중된 프레임에서 진짜와 가짜를 구별하는데 사용되는 이러한 재료는 전체 프레임을 훈 련할 필요가 없을 것이다. 이미지의 모든 정보를 사용하면 모델이 집중해야 하는 필수 정보가 희석된다. 이는 모델의 품질에 부정적인 영향을 미치거나 모델의 크기를 증가시키는 원인이 될 수 있다. 분류기 네트워크의 입 력에는 증류 세트가 있으며 각 증류 세트에는 추출된 얼굴, 얼굴 증강, “진짜” 또는 “가짜” 레이블과 함께 패치의 다중 영역이 포함된다. 이 단계에서 문제는 본질적으로 이진 클래스 분류 문제가 된다.도 4는 본 발명의 딥페이크 감지 방법의 설계를 도시한다. 두 개의 중 백본인 InceptionV3과 MobileNet이 마지 막 fully connected layer 없이 활용된다. InceptionV3 네트워크는 얼굴 전체와 얼굴 확대 결과를 훈련하는데 사용되며 MobileNet 구성요소는 얼굴 패치를 훈련한다. 이 두 구성요소의 출력은 연결되어 전역 평균 풀링에 공 급된다. 이제 실제 얼굴과 가짜 얼굴을 구별하는 정보와 중요한 영역이 포함된 특징 세트가 있다. 분류기 네트워크의 출력(특징 세트)을 분석하고 평가하여 “실제” 또는 “가짜”로 결정하면 이미지에 대한 딥 페이크 감지가 수행된다. 그러나 프레임과 영역이 결합되지 않기 때문에 결합 및 분류 모델이 있는 모델보다 결 과가 낮은 경우가 많다. <조합 및 분류 모듈> 이 부분은 도 4에 도시된 바와 같이 비디오에서 프레임의 기능 세트를 선택 후 합성하고, 얼굴의 영역을 합성하 고, 가상 임계값 수준을 변경하여 비디오에 대한 최종 결정을 내린다. 프레임 앙상블. 이 모델은 비디오당 N개 프레임의 특징 세트를 수집했다. 프레임의 부분 집합만 사용하여 입력 크기를 줄인다. 비디오 길이의 큰 변화로 인해 초당 N개의 프레임을 추출하면 입력 길이의 큰 변화가 발생한다. 이것은 패딩으로 해결할 수 있지만 대부분 0으로 구성된 입력으로 끝나게 하여 결국 훈련 성능이 저하될 수 있 다. 따라서 비디오 길이에 의존하지 않는 비디오당 N프레임이 선택되었다. 두 가지 비디오 샘플링 방법의 비교 에 대한 예가 도 5에 도시되어 있다. - 다중 지역 앙상블 합성 후 N개의 프레임은 합성 및 평가를 위해 다중 영역 앙상블에 배치되고, 영역 정보도 특징 세트에서 수집된 다음 풀링되어 비디오가 진짜인지 가짜인지 평가하는 동안 비디오 분류 결과를 도출한다. 대부분의 선행 연구는 비디오가 진짜인지 가짜인지에 대한 최종 결정을 내리기 위해 비디오의 프레임 간에 정보 를 합성하는 가짜 비디오의 확률을 나타내는 임계값 매개변수에 의존했습니다. 이 임계값 매개변수는 일반적으 로 고정 값으로 설정되어 모델이 가짜 또는 실제 비디오에 더 민감하게 되어 전체 모델 품질이 저하될 수 있다. 이 문제를 해결하기 위해 진짜와 가짜를 구별하는 이 임계값을 훈련된 매개변수와 일치하도록 동적으로 변경시 키는 것을 제안한다. 이는 결과를 적절하게 예측하는 능력을 향상시킨다. 도 6은 본 발명의 실시예에 따른 고성능 딥페이크 비디오 검출 방법을 설명하기 위한 순서도이다. 도 6을 참조 하면, 본 발명의 실시예에 따른 고성능 딥페이크 비디오 검출 방법은 비디오에서 주요 인물을 식별하고, MTCNN(Multitask Cascaded Convolutional Network)을 사용하여 상기 인물의 얼굴을 추출하는 단계(S110), 오픈 소스 툴박스를 사용하여 상기 추출된 각 얼굴에서 랜드마크를 추출하여 관심영역(ROI)을 수집하는 단계(S120), 상기 랜드마크를 추출한 후 얼굴의 적어도 하나 이상의 부분에서 얼굴 패치를 잘라내는 단계(S130), 분류기 네 트워크에 입력할 증류 세트를 추출하는 단계(S140) 및 상기 증류 세트가 입력된 상기 분류기 네트워크의 출력을 분석하고 평가하여 상기 비디오의 인물 이미지에 대한 딥페이크 감지를 수행하는 단계(S150)를 포함한다. 본 명세서와 도면에는 본 발명의 바람직한 실시예에 대하여 개시하였으며, 비록 특정 용어들이 사용되었으나, 이는 단지 본 발명의 기술 내용을 쉽게 설명하고 발명의 이해를 돕기 위한 일반적인 의미에서 사용된 것이지, 본 발명의 범위를 한정하고자 하는 것은 아니다. 여기에 개시된 실시예 외에도 본 발명의 기술적 사상에 바탕을 둔 다른 변형예들이 실시 가능하다는 것은 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자에게 자명한 것이다.도면 도면1 도면2 도면3 도면4 도면5 도면6"}
{"patent_id": "10-2021-0168809", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 실시예에 따른 고성능 딥페이크 비디오 검출을 위한 전체 네트워크를 도시하는 도면. 도 2는 가상 사진을 포함하는 예시도. 도 3은 얼굴에서 일부분을 절단한 증강을 도시하는 예시도. 도 4는 얼굴의 특정 영역에 할당된 중요한 정보를 도시하는 도면. 도 5는 두 가지 비디오 샘플링 방법의 비교에 대한 예를 도시하는 도면. 도 6은 본 발명의 실시예에 따른 고성능 딥페이크 비디오 검출 방법을 설명하기 위한 순서도."}
