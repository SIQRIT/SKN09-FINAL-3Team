{"patent_id": "10-2021-0115930", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0012945", "출원번호": "10-2021-0115930", "발명의 명칭": "입 모양을 생성하는 전자 장치 및 그 동작 방법", "출원인": "삼성전자주식회사", "발명자": "김주영"}}
{"patent_id": "10-2021-0115930", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "전자 장치에 있어서,적어도 하나의 프로세서, 및상기 적어도 하나의 프로세서에 동작적으로 연결된 적어도 하나의 메모리를 포함하고,상기 적어도 하나의 메모리는, 실행 시에 상기 적어도 하나의 프로세서가:상기 적어도 하나의 메모리에 저장된 적어도 하나의 제 1 이미지에 합성을 하도록 지정된 음성 데이터를 획득하고,상기 음성 데이터를 이용하여 복수 개의 입 모양 후보들을 생성하고,상기 복수 개의 입 모양 후보들 중 선택된 입 모양과 상기 적어도 하나의 제 1 이미지 각각의 적어도 일부를 이용하여, 상기 선택된 입 모양을 포함하는 적어도 하나의 제 2 이미지를 생성하고, 및상기 적어도 하나의 제 2 이미지에 대하여 적어도 하나의 super-resolution 모델을 적용하여 적어도 하나의 제3 이미지를 생성하도록 야기하는 적어도 하나의 인스트럭션을 저장하는 전자 장치."}
{"patent_id": "10-2021-0115930", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1 항에 있어서,상기 적어도 하나의 인스트럭션은, 실행 시에, 상기 적어도 하나의 프로세서가, 상기 음성 데이터를 이용하여상기 복수 개의 입 모양 후보들을 생성하는 동작의 적어도 일부로서,상기 음성 데이터에 대하여 적어도 하나의 아날로그 처리를 수행함으로써, 적어도 하나의 처리된 음성 데이터를생성하고,상기 음성 데이터 및 상기 적어도 하나의 처리된 음성 데이터를, 입 모양 생성 모델에 입력하고,상기 입 모양 생성 모델로부터의 복수 개의 출력 값을, 상기 복수 개의 입 모양 후보들로서 생성하도록 야기하는 전자 장치."}
{"patent_id": "10-2021-0115930", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 2 항에 있어서,상기 적어도 하나의 아날로그 처리는, 상기 음성 데이터의 진폭의 증가, 상기 음성 데이터의 상기 진폭의 감소,상기 음성 데이터의 재생 속력의 증가, 상기 음성 데이터의 상기 재생 속력의 감소, 상기 음성 데이터에 대한제 1 노이즈 추가, 상기 음성 데이터에 대한 제 2 노이즈 억제, 상기 음성 데이터에 대한 제 1 배경음 분리, 또는 상기 음성 데이터에 대한 제 2 배경음 추가 중 적어도 하나를 포함하는 전자 장치."}
{"patent_id": "10-2021-0115930", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 1 항에 있어서,상기 적어도 하나의 인스트럭션은, 실행 시에, 상기 적어도 하나의 프로세서가, 상기 음성 데이터를 이용하여상기 복수 개의 입 모양 후보들을 생성하는 동작의 적어도 일부로서,상기 음성 데이터를, 복수 개의 입 모양 생성 모델에 입력하고,상기 복수 개의 입 모양 생성 모델들 각각으로부터의 복수 개의 출력 값을, 상기 복수 개의 입 모양 후보들로서생성하도록 야기하는 전자 장치.공개특허 10-2023-0012945-3-청구항 5 제 4 항에 있어서,상기 복수 개의 입 모양 생성 모델은, 상이한 영역에 대하여 특화되도록 트레이닝된 전자 장치."}
{"patent_id": "10-2021-0115930", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제 1 항에 있어서,상기 적어도 하나의 인스트럭션은, 실행 시에, 상기 적어도 하나의 프로세서가,상기 복수 개의 입 모양 후보들 중 하나를 선택할 수 있는 사용자 인터페이스를 제공하고,상기 사용자 인터페이스를 통하여 입력되는 사용자 입력에 기반하여, 상기 복수 개의 입 모양 후보들 중 하나를선택하도록 야기하는 전자 장치."}
{"patent_id": "10-2021-0115930", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제 6 항에 있어서,상기 사용자 인터페이스는, 상기 복수 개의 입 모양 후보들 중 적어도 일부 또는 상기 복수 개의 입 모양 후보들 중 적어도 일부 각각을 포함하는 얼굴 영역의 적어도 일부 영역을 재생하면서, 상기 음성 데이터에 대응하는음성을 출력하는 기능을 제공하는 전자 장치."}
{"patent_id": "10-2021-0115930", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제 1 항에 있어서,상기 적어도 하나의 인스트럭션은, 실행 시에, 상기 적어도 하나의 프로세서가,상기 음성 데이터를 합성할 시간 구간을 선택할 수 있는 사용자 인터페이스를 제공하고,상기 사용자 인터페이스를 통하여 입력되는 사용자 입력에 기반하여, 상기 음성 데이터를 합성할 상기 시간 구간에 대응하는 상기 적어도 하나의 제 1 이미지를 확인하도록 야기하는 전자 장치."}
{"patent_id": "10-2021-0115930", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제 1 항에 있어서,상기 적어도 하나의 인스트럭션은, 실행 시에, 상기 적어도 하나의 프로세서가,상기 복수 개의 입 모양 후보들 각각을 평가 모델에 입력하고,상기 평가 모델로부터 출력되는 복수 개의 스코어들에 기반하여, 상기 복수 개의 입 모양 후보들 중 하나를 선택하도록 야기하는 전자 장치."}
{"patent_id": "10-2021-0115930", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제 1 항에 있어서,상기 적어도 하나의 인스트럭션은, 실행 시에, 상기 적어도 하나의 프로세서가, 상기 적어도 하나의 제 2 이미지에 대하여 적어도 하나의 super-resolution 모델을 적용하여 상기 적어도 하나의 제 3 이미지를 생성하는 동작의 적어도 일부로,상기 적어도 하나의 제 2 이미지 각각을, 입에 대응하는 적어도 하나의 제 1 영역과, 상기 제 1 영역을 제외한나머지 영역 또는 전체 영역인 적어도 하나의 제 2 영역으로 분할하고,상기 적어도 하나의 제 1 영역을, 상기 적어도 하나의 제 1 영역에 특화된 제 1 super-resolution 모델에 적용함으로써, 적어도 하나의 제 1 고해상도 영역을 생성하고,상기 적어도 하나의 제 2 영역을, 상기 적어도 하나의 제 1 영역에 특화된 제 2 super-resolution 모델에 적용함으로써, 적어도 하나의 제 2 고해상도 영역을 생성하고,상기 제 1 고해상도 영역 각각을 상기 제 2 고해상도 영역 각각과 합성함으로써, 상기 적어도 하나의 제 3 이미공개특허 10-2023-0012945-4-지 각각을 생성하도록 야기하는 전자 장치."}
{"patent_id": "10-2021-0115930", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제 1 항에 있어서,상기 적어도 하나의 인스트럭션은, 실행 시에, 상기 적어도 하나의 프로세서가,상기 적어도 하나의 제 3 이미지의 적어도 일부 각각을 상기 적어도 하나의 제 1 이미지 각각에 합성함으로써,적어도 하나의 합성이 완료된 이미지를 생성하도록 야기하는 전자 장치."}
{"patent_id": "10-2021-0115930", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제 11 항에 있어서,상기 적어도 하나의 인스트럭션은, 실행 시에, 상기 적어도 하나의 프로세서가, 상기 적어도 하나의 합성이 완료된 이미지를 생성하는 동작의 적어도 일부로, 상기 적어도 하나의 제 3 이미지 각각에 대하여 세그먼테이션을 수행하고,상기 세그먼테이션 결과에 기반하여, 상기 적어도 하나의 제 3 이미지 각각의 적어도 하나의 합성 대상 영역을각각 확인하고,상기 적어도 하나의 합성 대상 영역 각각을 상기 적어도 하나의 제 1 이미지 각각에 합성함으로써, 상기 적어도하나의 합성이 완료된 이미지를 생성하도록 야기하는 전자 장치."}
{"patent_id": "10-2021-0115930", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제 1 항에 있어서,상기 적어도 하나의 인스트럭션은, 실행 시에, 상기 적어도 하나의 프로세서가, 음성 데이터를 획득하는 동작의적어도 일부로, 상기 전자 장치의 마이크를 통하여 수신되는 음성에 기반하여 상기 음성 데이터를 생성하거나, 또는 텍스트를상기 음성 데이터로 변환하도록 야기하는 전자 장치."}
{"patent_id": "10-2021-0115930", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "적어도 하나의 인스트럭션을 저장하는 컴퓨터로 독출가능한 저장 매체에 있어서,상기 적어도 하나의 인스트럭션은, 실행 시에, 적어도 하나의 프로세서가:상기 적어도 하나의 메모리에 저장된 적어도 하나의 제 1 이미지에 합성을 하도록 지정된 음성 데이터를 획득하고,상기 음성 데이터를 이용하여 복수 개의 입 모양 후보들을 생성하고,상기 복수 개의 입 모양 후보들 중 선택된 입 모양과 상기 적어도 하나의 제 1 이미지 각각의 적어도 일부를 이용하여, 상기 선택된 입 모양을 포함하는 적어도 하나의 제 2 이미지를 생성하고, 및상기 적어도 하나의 제 2 이미지에 대하여 적어도 하나의 super-resolution 모델을 적용하여 적어도 하나의 제3 이미지를 생성하도록 야기하는 저장 매체."}
{"patent_id": "10-2021-0115930", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제 14 항에 있어서,상기 적어도 하나의 인스트럭션은, 실행 시에, 상기 적어도 하나의 프로세서가, 상기 음성 데이터를 이용하여상기 복수 개의 입 모양 후보들을 생성하는 동작의 적어도 일부로서,상기 음성 데이터에 대하여 적어도 하나의 아날로그 처리를 수행함으로써, 적어도 하나의 처리된 음성 데이터를생성하고,상기 음성 데이터 및 상기 적어도 하나의 처리된 음성 데이터를, 입 모양 생성 모델에 입력하고,공개특허 10-2023-0012945-5-상기 입 모양 생성 모델로부터의 복수 개의 출력 값을, 상기 복수 개의 입 모양 후보들로서 생성하도록 야기하는 저장 매체."}
{"patent_id": "10-2021-0115930", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제 14 항에 있어서,상기 적어도 하나의 인스트럭션은, 실행 시에, 상기 적어도 하나의 프로세서가, 상기 음성 데이터를 이용하여상기 복수 개의 입 모양 후보들을 생성하는 동작의 적어도 일부로서,상기 음성 데이터를, 복수 개의 입 모양 생성 모델에 입력하고,상기 복수 개의 입 모양 생성 모델들 각각으로부터의 복수 개의 출력 값을, 상기 복수 개의 입 모양 후보들로서생성하도록 야기하는 저장 매체."}
{"patent_id": "10-2021-0115930", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제 14 항에 있어서,상기 적어도 하나의 인스트럭션은, 실행 시에, 상기 적어도 하나의 프로세서가,상기 복수 개의 입 모양 후보들 중 하나를 선택할 수 있는 사용자 인터페이스를 제공하고,상기 사용자 인터페이스를 통하여 입력되는 사용자 입력에 기반하여, 상기 복수 개의 입 모양 후보들 중 하나를선택하도록 야기하는 저장 매체."}
{"patent_id": "10-2021-0115930", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제 14 항에 있어서,상기 적어도 하나의 인스트럭션은, 실행 시에, 상기 적어도 하나의 프로세서가, 상기 적어도 하나의 제 2 이미지에 대하여 적어도 하나의 super-resolution 모델을 적용하여 상기 적어도 하나의 제 3 이미지를 생성하는 동작의 적어도 일부로,상기 적어도 하나의 제 2 이미지 각각을, 입에 대응하는 적어도 하나의 제 1 영역과, 상기 제 1 영역을 제외한나머지 영역 또는 전체 영역인 적어도 하나의 제 2 영역으로 분할하고,상기 적어도 하나의 제 1 영역을, 상기 적어도 하나의 제 1 영역에 특화된 트레이닝된 제 1 super-resolution모델에 적용함으로써, 적어도 하나의 제 1 고해상도 영역을 생성하고,상기 적어도 하나의 제 2 영역을, 상기 적어도 하나의 제 2 영역에 특화된 제 2 super-resolution 모델에 적용함으로써, 적어도 하나의 제 2 고해상도 영역을 생성하고,상기 제 1 고해상도 영역 각각을 상기 제 2 고해상도 영역 각각과 합성함으로써, 상기 적어도 하나의 제 3 이미지 각각을 생성하도록 야기하는 저장 매체."}
{"patent_id": "10-2021-0115930", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제 1 항에 있어서,상기 적어도 하나의 인스트럭션은, 실행 시에, 상기 적어도 하나의 프로세서가,상기 적어도 하나의 제 3 이미지 각각에 대하여 세그먼테이션을 수행하고,상기 세그먼테이션 결과에 기반하여, 상기 적어도 하나의 제 3 이미지 각각의 적어도 하나의 합성 대상 영역을각각 확인하고,상기 적어도 하나의 합성 대상 영역 각각을 상기 적어도 하나의 제 1 이미지 각각에 합성함으로써, 상기 적어도하나의 합성이 완료된 이미지를 생성하도록 야기하는 저장 매체."}
{"patent_id": "10-2021-0115930", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "전자 장치에 있어서,공개특허 10-2023-0012945-6-적어도 하나의 프로세서,상기 적어도 하나의 프로세서에 동작적으로 연결된 표시 모듈, 및상기 적어도 하나의 프로세서에 동작적으로 연결된 적어도 하나의 메모리를 포함하고,상기 적어도 하나의 메모리는, 실행 시에 상기 적어도 하나의 프로세서가:상기 적어도 하나의 메모리에 저장된 적어도 하나의 제 1 이미지에 합성을 하도록 지정된 음성 데이터를 획득하고,상기 음성 데이터를 이용하여 생성된 복수 개의 입 모양 후보들을 상기 표시 모듈에 표시하고,상기 표시 모듈에 표시되는 상기 복수 개의 입 모양 후보들 중 제 1 입 모양 후보의 선택을 확인하고,상기 제 1 입 모양 후보와 상기 적어도 하나의 제 1 이미지 각각의 적어도 일부를 이용하여, 상기 제 1 입 모양후보를 포함하는 적어도 하나의 제 2 이미지를, 상기 표시 모듈에 표시하도록 적어도 하나의 인스트럭션을 저장하는 전자 장치."}
{"patent_id": "10-2021-0115930", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "다양한 실시예에 따라서, 전자 장치는, 적어도 하나의 프로세서, 및 상기 적어도 하나의 프로세서에 동작적으로 연결된 적어도 하나의 메모리를 포함하고, 상기 적어도 하나의 메모리는, 실행 시에 상기 적어도 하나의 프로세 서가, 상기 적어도 하나의 메모리에 저장된 적어도 하나의 제 1 이미지에 합성을 하도록 지정된 음성 데이터를 획득하고, 상기 음성 데이터를 이용하여 복수 개의 입 모양 후보들을 생성하고, 상기 복수 개의 입 모양 후보들 중 선택된 입 모양과 상기 적어도 하나의 제 1 이미지 각각의 적어도 일부를 이용하여, 상기 선택된 입 모양을 포함하는 적어도 하나의 제 2 이미지를 생성하고, 상기 적어도 하나의 제 2 이미지에 대하여 적어도 하나의 super-resolution 모델을 적용하여 적어도 하나의 제 3 이미지를 생성하도록 야기하는 적어도 하나의 인스트럭션 을 저장할 수 있다. 그 밖의 다양한 실시예가 가능하다."}
{"patent_id": "10-2021-0115930", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시의 다양한 실시예는 입 모양을 생성하는 전자 장치 및 그 동작 방법에 관한 것으로, 예를 들어 음성 데 이터에 대응하는 입 모양을 생성하는 전자 장치 및 그 동작 방법에 관한 것이다."}
{"patent_id": "10-2021-0115930", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "인공지능 기술은 다양한 분야에 적용되고 있다. 예를 들어, 음성 데이터에 대응하는 입 모양을 생성하기 위한 인공지능 모델의 개발이 진행되고 있다. 워싱턴 대학교의 폴 G. 알렌(Paul G. Allen) 연구팀은, 음성 데이터를 사실적인 립-싱크된 비디오(lip-synced video)로 변환하는 인공지능 모델을 개발하였다. 인공지능 모델에 의하 여 음성 데이터를 발화하기 위한 입 모양이 생성될 수 있으며, 생성된 입 모양이 기존의 이미지의 머리 부분에 합성될 수 있다. 이에 따라, 동영상의 사람이 음성 데이터에 대응하는 입 모양으로 입력 데이터를 발화하는 것 과 같이, 재생될 수 있다. 예를 들어, RNN(recurrent neural network) 기반의 인공지능 모델에 음성 데이터가 입력되면, 입 모양을 나타내 는(또는, 입 모양을 표현하기 위한) sparse shape이 생성될 수 있다. Sparse shape에 기반하여 입 모양 텍스처 가 생성될 수 있으며, 해당 입 모양 텍스처가 타겟 비디오에 포함된 이미지 각각에 합성될 수 있다. 한편, RNN 기반의 인공지능 모델 이외에도 다양한 인공 신경망 기반의 인공지능 모델에 기반한 입 모양 생성 기술이 연구 되고 있다."}
{"patent_id": "10-2021-0115930", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "상술한 바와 같이, 보다 실제에 가까운 입 모양이 생성되기 위하여서는, 인공지능 모델(예를 들어, RNN 기반의 인공지능 모델)에 대한 적절한 트레이닝이 요구된다. 만약, 트레이닝이 적절하지 못한 경우에는, 부자연스러운 입 모양이 생성될 수 있다. 특히, 사람들은 부자연스러운 입 부분에 상당히 민감한 것으로 알려져 있고, 예를 들어 치아가 부자연스럽게 렌더링되거나, 또는 턱이 잘못된 시간에 움직이는 경우, 비디오가 가짜임이 쉽게 인 지될 수 있다. 하지만, 다수의 트레이닝 데이터를 이용하더라도, 모든 경우에 대하여 완벽한 합성 이미지가 생 성될 가능성은 낮을 수 있다. 아울러, 기존의 입 모양 생성을 위하여서는 하나의 인공지능 모델만이 적용 및/ 또는 실행된다. 이에 따라, 트레이닝이 완벽하지 못하여 부자연스러운 입 모양이 생성된 경우에도, 해당 비디 오가 수정이 불가능하거나, 수정에 많은 리소스가 투입되어야 한다. 이는, 입 모양 생성 모델을 하나만을 이용 하는 것으로부터 기인한다. 다양한 실시예에 따른 전자 장치 및 그 동작 방법은, 하나의 음성 데이터로부터 복수 개의 입 모양 후보들을 생 성하고, 복수 개의 입 모양 후보들 중 선택된 입 모양 후보를 포함한 이미지를 생성할 수 있다."}
{"patent_id": "10-2021-0115930", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "다양한 실시예에 따라서, 전자 장치는, 적어도 하나의 프로세서, 및 상기 적어도 하나의 프로세서에 동작적으로 연결된 적어도 하나의 메모리를 포함하고, 상기 적어도 하나의 메모리는, 실행 시에 상기 적어도 하나의 프로세 서가, 상기 적어도 하나의 메모리에 저장된 적어도 하나의 제 1 이미지에 합성을 하도록 지정된 음성 데이터를 획득하고, 상기 음성 데이터를 이용하여 복수 개의 입 모양 후보들을 생성하고, 상기 복수 개의 입 모양 후보들 중 선택된 입 모양과 상기 적어도 하나의 제 1 이미지 각각의 적어도 일부를 이용하여, 상기 선택된 입 모양을 포함하는 적어도 하나의 제 2 이미지를 생성하고, 상기 적어도 하나의 제 2 이미지에 대하여 적어도 하나의 super-resolution 모델을 적용하여 적어도 하나의 제 3 이미지를 생성하도록 야기하는 적어도 하나의 인스트럭 션을 저장할 수 있다. 다양한 실시예에 따라서, 적어도 하나의 인스트럭션을 저장하는 컴퓨터로 독출가능한 저장 매체가 제공된다. 상기 적어도 하나의 인스트럭션은, 실행 시에, 적어도 하나의 프로세서가, 상기 적어도 하나의 메모리에 저장된 적어도 하나의 제 1 이미지에 합성을 하도록 지정된 음성 데이터를 획득하고, 상기 음성 데이터를 이용하여 복 수 개의 입 모양 후보들을 생성하고, 상기 복수 개의 입 모양 후보들 중 선택된 입 모양과 상기 적어도 하나의 제 1 이미지 각각의 적어도 일부를 이용하여, 상기 선택된 입 모양을 포함하는 적어도 하나의 제 2 이미지를 생 성하고, 상기 적어도 하나의 제 2 이미지에 대하여 적어도 하나의 super-resolution 모델을 적용하여 적어도 하 나의 제 3 이미지를 생성하도록 야기할 수 있다. 다양한 실시예에 따라서, 전자 장치에 있어서, 적어도 하나의 프로세서, 상기 적어도 하나의 프로세서에 동작적 으로 연결된 표시 모듈, 및 상기 적어도 하나의 프로세서에 동작적으로 연결된 적어도 하나의 메모리를 포함하 고, 상기 적어도 하나의 메모리는, 실행 시에 상기 적어도 하나의 프로세서가, 상기 적어도 하나의 메모리에 저 장된 적어도 하나의 제 1 이미지에 합성을 하도록 지정된 음성 데이터를 획득하고, 상기 음성 데이터를 이용하 여 생성된 복수 개의 입 모양 후보들을 상기 표시 모듈에 표시하고, 상기 표시 모듈에 표시되는 상기 복수 개의 입 모양 후보들 중 제 1 입 모양 후보의 선택을 확인하고, 상기 제 1 입 모양 후보와 상기 적어도 하나의 제 1 이미지 각각의 적어도 일부를 이용하여, 상기 제 1 입 모양 후보를 포함하는 적어도 하나의 제 2 이미지를, 상 기 표시 모듈에 표시하도록 야기하는 적어도 하나의 인스트럭션을 저장할 수 있다. 다양한 실시예에 따라서, 적어도 하나의 인스트럭션을 저장하는 컴퓨터로 독출가능한 저장 매체가 제공된다. 상기 적어도 하나의 인스트럭션은, 실행 시에, 적어도 하나의 프로세서가, 상기 적어도 하나의 메모리에 저장된 적어도 하나의 제 1 이미지에 합성을 하도록 지정된 음성 데이터를 획득하고, 상기 음성 데이터를 이용하여 생 성된 복수 개의 입 모양 후보들을 표시 모듈에 표시하고, 상기 표시 모듈에 표시되는 상기 복수 개의 입 모양 후보들 중 제 1 입 모양 후보의 선택을 확인하고, 상기 제 1 입 모양 후보와 상기 적어도 하나의 제 1 이미지 각각의 적어도 일부를 이용하여, 상기 제 1 입 모양 후보를 포함하는 적어도 하나의 제 2 이미지를, 상기 표시 모듈에 표시하도록 야기할 수 있다."}
{"patent_id": "10-2021-0115930", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "다양한 실시예에 따라서, 하나의 음성 데이터로부터 복수 개의 입 모양 후보들을 생성하고, 복수 개의 입 모양 후보들 중 선택된 입 모양 후보를 포함한 이미지를 생성할 수 있는 전자 장치 및 그 동작 방법이 제공될 수 있 다. 이에 따라, 하나의 인공지능 모델에 기반하여 하나의 입 모양만이 생성되는 기존 기술과는 달리, 보다 자 연스러운 입 모양 생성이 가능할 수 있다."}
{"patent_id": "10-2021-0115930", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "item": 1, "content": "도 1은 다양한 실시예에 따른 전자 장치의 블록도를 도시한다. 다양한 실시예에 따라서, 전자 장치는, 프로세서, 메모리, 입/출력 모듈, 또는 표시 모듈 중 적어도 하나를 포함할 수 있다. 다양한 실시예에 따라서, 프로세서는, 예를 들면, 소프트웨어(예: 프로그램)를 실행하여 프로세서에 연결된 전자 장치의 적어도 하나의 다른 구성요소(예: 하드웨어 또는 소프트웨어 구성요소)를 제어할 수 있고, 다양한 데이터 처리 또는 연산을 수행할 수 있다. 소프트웨어는, 예를 들어 얼굴 검출 모델, 입 모양 생 성 모델, 랜드마크 검출 모델, super-resolution 모델, 이미지 합성 모델, 이미지 분리 모델, 음성 데이터 생성 모델, 아바타(또는, 캐릭터) 생성 모델 등과 같은 다양한 모델(또는, 알고리즘)을 저장할 수 있으며, 본 개시에 의한 동작을 수행하기 위한 소프트웨어라면 제한이 없다. 다양한 모델의 적어도 일부는 트레이닝에 따라 생성 된 인공지능 모델일 수도 있으나, 인공지능 모델 이외에도 입력 값을 처리하여 목적하는 출력 값을 출력할 수 있는 알고리즘을 포함할 수도 있음을 당업자는 이해할 것이다. 데이터 처리 또는 연산의 적어도 일부로서, 프 로세서는 다른 구성요소로부터 수신된 명령 또는 데이터를 메모리에 저장하고, 메모리에 저장된 명령 또는 데이터를 처리하고, 결과 데이터를 메모리에 저장할 수 있다. 일실시예에 따르면, 프로세서 는, 중앙 처리 장치, 어플리케이션 프로세서, 신경망 처리 장치(NPU: neural processing unit), 또는 커 뮤니케이션 프로세서 중 적어도 일부를 포함할 수 있으나, 프로세서의 종류에는 제한이 없다. 신경망 처 리 장치는 인공지능 모델의 처리에 특화된 하드웨어 구조를 포함할 수 있다. 인공지능 모델에 포함되거나, 또 는 실행되는 모델은 기계 학습(예를 들어, 지도형 학습(supervised learning), 비지도형 학습(unsupervisedlearning), 준지도형 학습(semi-supervised learning), 또는 강화 학습을 포함할 수 있으나, 전술한 예에 한정 되지 않는다. 인공지능 모델은, 복수의 인공 신경망 레이어들을 포함할 수 있다. 인공 신경망은 심층 신경망 (DNN: deep neural network), GAN(generative adversarial network), CNN(convolutional neural network), RNN(recurrent neural network), RBM(restricted boltzmann machine), DBN(deep belief network), BRDNN(bidirectional recurrent deep neural network), 심층 Q-네트워크(deep Q-networks) 또는 상기 중 둘 이 상의 조합 중 하나에 기반한 모델일 수 있으나, 전술한 예에 한정되지 않는다. 인공지능 모델은 하드웨어 구조 이외에, 추가적으로 또는 대체적으로, 소프트웨어 구조를 포함할 수 있다. 예를 들어, 인공지능 모델은 적어도 하나의 입력 데이터를 수신하고 적어도 하나의 출력 데이터를 출력하기 위한 적어도 하나의 레이어 및/또는 노 드 별 파라미터의 값을 포함하는 뉴럴 네트워크를 의미하거나, 또는 뉴럴 네트워크에 의한 출력 데이터를 출력 하는 알고리즘 또는 복수의 알고리즘의 집합, 이러한 알고리즘 또는 그의 집합을 실행하기 위한 프로세서 (processor), 이러한 알고리즘 또는 그의 집합을 실행하기 위한 소프트웨어, 또는 이러한 알고리즘 또는 그의 집합을 실행하기 위한 하드웨어를 의미할 수 있다. 다양한 실시예에 따라서, 메모리는, 플래시 메모리 타입(flash memory type), 하드디스크 타입(hard disk type), 멀티미디어 카드 마이크로 타입(multimedia card micro type), 카드 타입의 메모리(예를 들어 SD 또는 XD 메모리 등), 램(RAM, Random Access Memory) SRAM(Static Random Access Memory), 롬(ROM, Read-Only Memory), EEPROM(Electrically Erasable Programmable Read-Only Memory), PROM(Programmable Read-Only Memory), 자기 메모리, 자기 디스크, 광디스크 중 적어도 하나의 타입의 저장매체를 포함할 수 있으며, 데이터 를 저장할 수 있는 장치라면 제한이 없음을 당업자는 이해할 것이다. 메모리의 적어도 일부는 프로세서 로부터 분리될 수 있고, 및/또는 적어도 일부는 프로세서 내에 위치할 수도 있다. 다양한 실시예에 서, 전자 장치에 의하여 수행되는 동작은, 프로세서에 의한 동작, 또는 프로세서의 제어에 의한 다른 하드웨어(예를 들어, 메모리, 표시 모듈, 및/또는 입/출력 모듈)에 의한 동작으로 이해될 수도 있다. 또는, 전자 장치에 의하여 특정 동작이 수행되는 것은, 메모리에 저장된 인스트럭션이 실행됨에 따라 전자 장치의 적어도 하나의 하드웨어에 의하여 특정 동작이 수행되는 것을 의미할 수도 있 다. 다양한 실시예에 따라서, 메모리는, 전자 장치의 적어도 하나의 구성요소(예: 프로세서, 입/출 력 모듈 및/또는 표시 모듈)에 의해 사용되는 다양한 데이터를 저장할 수 있다. 데이터는, 예를 들어, 소프트웨어 및, 이와 관련된 명령에 대한 입력 데이터 또는 출력 데이터를 포함할 수 있다. 다양한 실시예에 따라서, 입/출력 모듈은, 전자 장치의 구성요소(예: 프로세서)에 사용될 명령 또는 데이터를 전자 장치의 외부(예: 사용자)로부터 수신할 수 있다. 입/출력 모듈은, 예를 들면, 마이크, 마우스, 키보드, 키(예: 버튼), 또는 디지털 펜(예: 스타일러스 펜) 중 적어도 하나를 포함할 수 있다. 한편, 입/출력 모듈은, 터치 패널 및 TSP IC(touch screen panel integrated circuit)을 포함할 수도 있 다. 이 경우에는, 터치 패널 및 TSP IC가 후술할 표시 모듈과 일체인 구조(예를 들어, on-cell 구조 또는 in-cell 구조)로 구현되거나, 표시 모듈에 인접하여 배치될 수도 있다. 음향 출력 모듈은, 예를 들 면, 스피커 또는 리시버를 포함할 수 있으며, 이 경우 음향 신호를 전자 장치의 외부로 출력할 수 있다. 스피커는 멀티미디어 재생 또는 녹음 재생과 같이 일반적인 용도로 사용될 수 있다. 리시버는 착신 전화를 수신 하기 위해 사용될 수 있다. 일실시예에 따르면, 리시버는 스피커와 별개로, 또는 그 일부로서 구현될 수 있다. 표시 모듈은 전자 장치의 외부(예: 사용자)로 정보를 시각적으로 제공할 수 있다. 표시 모듈은, 예를 들면, 디스플레이, 홀로그램 장치, 또는 프로젝터 및 해당 장치를 제어하기 위한 제어 회로를 포함할 수 있다. 일실시예에 따르면, 표시 모듈은 상술한 바와 같이, 터치 패널 및 TSP IC와 일체로 구현될 수도 있 고, 및/또는 터치에 의해 발생되는 힘의 세기를 측정하도록 설정된 압력 센서를 포함하도록 구현될 수도 있다. 한편, 도시되지는 않았지만, 전자 장치는, 외부 전자 장치와의 통신을 위한 통신 모듈(미도시)을 더 포함 할 수도 있으며, 통신의 종류에는 제한이 없다. 도 2는 다양한 실시예에 따른 전자 장치의 동작 방법을 설명하기 위한 흐름도를 도시한다. 도 2의 실시예는 도 3을 참조하여 설명하도록 한다. 도 3은 다양한 실시예에 따른 생성된 입 모양을 포함하는 동영상의 생성 과정 을 설명하기 위한 도면이다. 도 2 및 도 3을 함께 참조하면, 다양한 실시예에 따라서, 전자 장치(예를 들어, 프로세서)는, 201 동 작에서, 적어도 하나의 제 1 이미지(예를 들어, 도 3에서의 적어도 하나의 제 1 이미지(310a, 310b, 310c, 310n)에 대응하는 음성 데이터를 획득할 수 있다. 여기에서, 적어도 하나의 제 1 이미지(예를 들어, 도 3에서의 적어도 하나의 제 1 이미지(310a, 310b, 310c, 310n)에 대응하는 음성 데이터는, 적어도 하나의 제 1 이미지에 합성될 것으로 지정되는 음성 데이터를 의미할 수 있다. 즉, 기존에는 적어도 하나의 제 1 이미지 (310a, 310b, 310c, 310n)로부터 음성 데이터는 독립적인 음성 데이터일 수 있지만, 전자 장치는 합 성될 것으로 지정되는 음성 데이터를 적어도 하나의 제 1 이미지(310a, 310b, 310c, 310n)에 연관시킬 수 있으며, 이를 \"제 1 이미지에 대응하는 음성 데이터\"로서 명명할 수 있다. 이와 같은 설명은, 다른 실시예들에 서의 \"적어도 하나의 이미지에 대응하는 음성 데이터\"에도 적용될 수 있다. 하나의 예에서, 적어도 하나의 제 1 이미지(310a, 310b, 310c, 310n)는, 동영상을 구성하는 복수 개의 프레임일 수 있다. 전자 장치는, 메 모리에 저장되어 있는 동영상 파일을 로드할 수 있다. 동영상 파일은, 도 3의 합성을 위한 음성 데이터와 는 상이한 원본 음성 데이터를 포함하거나, 또는 음성 데이터를 포함하지 않을 수도 있다. 원본 음성 데이터는, 입 모양 합성 이후의 동영상 파일에는 포함되지 않으며, 입 모양 합성 이후의 동영상 파일에는 음성 데이터가 포함될 수 있다. 복수 개의 프레임을 포함하는 동영상 파일은, 통신 모듈을 통하여 다른 전자 장치로부터 수신하거나, 또는 전자 장치에 포함된 카메라를 이용하여 생성할 수 있다. 또는, 전자 장치 가 적어도 하나의 이미지를 이용하거나, 또는 이미지 생성 알고리즘(예를 들어, 아바타 생성 알고리즘)을 이용하여, 동영상을 구성하는 복수 개의 프레임들을 생성할 수도 있으며, 동영상을 구성하는 복수 개의 프레임 의 획득 방식에는 제한이 없다. 다른 예에서, 전자 장치는, 도 3에서와 같은 복수 개의 이미지들 (310a,310b,310c,310n)을 로드하기 보다, 하나의 이미지를 로드할 수도 있다. 이 경우, 전자 장치는, 복 수 개의 입 모양들 각각을 하나의 이미지와의 합성을 복수 회 수행함에 따라, 복수 개의 프레임의 동영상을 생 성할 수도 있으며, 이는 도 18a 내지 18c를 참조하여 더욱 상세하게 설명하도록 한다. 상술한 획득 동작들 중 하나, 또는 둘 이상의 조합에 의하여 적어도 하나의 제 1 이미지(310a,310b,310c,310n)가 획득될 수 있다. 한 편, 도 3에서는, 제 1 이미지(310a,310b,310c,310n)가 예를 들어 n개인 것으로 도시되어 있으나, 그 개수에는 제한이 없다. n개는, 예를 들어 하나의 사용자 선택, 또는 하나의 적합성 평과 결과에 기반하여 선택되는 입 모양 후보가 적용되는 개수일 수 있으나, 이 또한 예시적인 것이다. 제 1 이미지(310a,310b,310c,310n)는, 예 를 들어 제 1 해상도(예를 들어, 1920 X 1080의 해상도)를 가지는 것을 상정하도록 한다. 제 1 이미지 (310a,310b,310c,310n)는, 원본 이미지라 명명될 수도 있다. 다양한 실시예에 따라서, 전자 장치는, 합성을 위한 음성 데이터를 획득할 수 있다. 또는, 전자 장 치는, 메모리에 저장된 음성 데이터를 로드할 수 있다. 예를 들어, 전자 장치는, 입/출력 모듈에 포함된 마이크를 통하여 음성 데이터를 획득하여 메모리에 저장할 수 있다. 다른 예에 서, 전자 장치는, 다른 전자 장치로부터 음성 데이터를 통신 모듈을 통하여 수신하여 메모리에 저장할 수도 있다. 또 다른 예에서, 전자 장치는, 음성 데이터를 생성할 수도 있다. 전자 장치 는, 다른 음성 데이터의 적어도 일부를 변경하여 음성 데이터를 생성할 수 있다. 또는, 전자 장치 는, 텍스트로부터 음성 데이터를 합성할 수도 있으며, 음성 데이터의 획득 방식에는 제한이 없 으며, 상술한 획득 동작들 중 하나, 또는 둘 이상의 조합에 의하여 음성 데이터가 획득될 수 있다. 다시 도 2 및 도 3을 함께 참조하면, 전자 장치는, 203 동작에서, 음성 데이터에 대응하는 입 모양 (330a,330b,330c,330n)을 포함하는 적어도 하나의 제 2 이미지를 생성할 수 있다. 예를 들어, 전자 장치 는, 원본 이미지인 제 1 이미지(310a) 각각으로부터 얼굴 영역(311a)을 추출할 수 있다. 도 3에서는 설명의 편 의상 제 1 이미지(310a)에서만 얼굴 영역(311a)을 추출하는 것과 같이 도시되어 있지만, 이는 설명의 편의를 위 한 것이며 나머지 제 1 이미지(310b,310c,310n) 각각에서도 얼굴 영역 각각이 추출될 수 있다. 얼굴 영역의 인 식 및/또는 추출하기 위한 모델(또는, 알고리즘)에는 제한이 없다. 검출된 얼굴 영역(311a)은, 인물 식별 정보 에 매핑되어 관리될 수 있다. 예를 들어, 하나의 이미지에 복수 개의 인물들이 포함된 경우도 있으며, 전자 장 치는 이 경우 이미지로부터 복수의 얼굴들을 검출할 수 있고, 복수의 얼굴들 각각은 복수의 인물 식별 정 보 각각에 매핑하여 관리할 수 있다. 전자 장치는, 후술할 입 모양 합성의 동작들을, 각 인물 식별 정보 별로 독립적으로 수행할 수도 있다. 한편, 얼굴 영역이 잘못 분류될 가능성도 있으므로, 전자 장치는 얼 굴 분류의 결과를 수정할 수 있는 사용자 인터페이스를 제공할 수도 있다. 하나의 예에서, 전자 장치는, 추출된 얼굴 영역(311a)을 다운-샘플링하여 제 2 해상도(예를 들어, 100 X 100의 해상도)를 가지는 저해상도 이미지를 생성할 수 있다. 저해상도 이미지의 제 2 해상도는, 예를 들어 입 모양(330a,330b,330c,330n)의 해상도에 기반하여 설정될 수 있으나 제한은 없다. 도 3의 예시에서는, 얼굴 영 역(311a)의 해상도가 예를 들어, 제 2 해상도보다 큰 경우로서, 다운 샘플링이 수행됨으로써, 입 모양 (330a,330b,330c,330n)에 대응하는 제 2 해상도의 저해상도 이미지가 생성될 수 있다. 또는, 만약 추출된 얼굴 영역(311a)의 해상도가 제 2 해상도보다 작은 경우에는, 전자 장치는 추출된 얼굴 영역(311a)을 업샘플링 하여 제 2 해상도를 가지는 저해상도 이미지를 생성할 수도 있다. 다른 예에서, 전자 장치는 추출된 얼굴영역(311a)을 다운샘플링하지 않고 그대로 이용할 수도 있다. 전자 장치는, 음성 데이터를 이용하여 적어도 하나의 입 모양(330a,330b,330c,330d)을 생성할 수 있 다. 예를 들어, 음성 데이터는, 예를 들어 시계열적으로 진폭이 변경되는 음성 파형(waveform)의 형식으 로 표현될 수 있다. 적어도 하나의 입 모양(330a,330b,330c,330d)은, 시계열적으로 변화하는 음성에 대응될 수 있다. 전자 장치는, 음성 데이터로부터 입 모양 키 포인트를 확인할 수 있다. 예를 들어, 전자 장 치는, MFCC(mel frequency cepstral coefficient)를 음성 데이터로부터 추출할 수 있다. 전자 장치 는, 인공지능 모델(예를 들어, LSTM(long short term memory) 기반의 모델)을 이용하여 추출된 MFCC로부 터 PCA(principal component analysis) 계수(coefficient)를 확인할 수 있으며, PCA 계수에 기반하여 입 모양 키 포인트를 확인할 수 있다. 입 모양 키 포인트는, 예를 들어 특징점으로 구현되거나, 또는 메쉬(mesh) 정보 로 구현될 수도 있다. 전자 장치는, 확인된 입 모양 키 포인트를 인공지능 모델(예를 들어, GAN 기반의 모델)에 적용하여, 입 모양들(330a,330b,330c,330d)을 생성할 수 있다. GAN 기반의 모델은, generator에 의하 여 생성된 이미지를 discriminator가 구분하지 못하도록 트레이닝된 모델일 수 있으며, 예를 들어, Pix2pix 모 델 또는 wav2lip에 기반한 모델을 포함할 수 있으나, 입 모양을 생성하는 모델의 종류에는 제한이 없다. 한편, GAN 기반의 모델은 단순히 예시적인 것으로, 입 모양을 생성하기 위한 인공지능 모델의 기반이 되는 인공 신경 망의 종류에는 제한이 없음을 당업자는 이해할 것이다. 한편, 도 3에서는, 전자 장치가 입 모양들(330a,330b,330c,330d)만을 생성하는 것과 같이 도시되어 있지만, 이는 하나의 예시일 뿐이다. 전자 장치는, 입 모양을 포함하는 하관 영역을 생성하는 인공 지능 모델을 이용하여, 음성 데이터에 대응하는 복수 개의 하관 모양들을 생성할 수도 있다. 또는, 전자 장치 는, 입 모양과는 별개로 턱 모양, 및/또는 입 주위 영역의 모양을 생성할 수도 있으며, 이를 입 모양과 함 께 합성되도록 이용할 수도 있다. 본 개시에서 기재되는 \"입 모양\"은, 입 모양만을 의미할 수도 있고, 또는 입 모양 이외의 다른 영역(예를 들어, 턱, 입 주위 영역)도 함께 포함할 수도 있다. 예를 들어, \"입 모양\"은, \"입 모양을 포함하는 영역\"을 의미할 수 있다. 입 모양(330a,330b,330c,330n)의 개수는, 원본 이미지의 개수와 동 일한 것과 도시되었지만, 이는 예시적으로, 입 모양 중 적어도 일부가 복수 개의 이미지에서 중복되어 사용될 수도 있고, 이 경우에는 입 모양(330a,330b,330c,330n)의 개수가 원본 이미지의 개수보다 작을 수도 있다. 전 자 장치는, 제 1 이미지(310a)의 얼굴 영역(311a)에 대응하는 저해상도 이미지에 입 모양(330a)을 합성함 으로써, 제 2 이미지(320a)를 생성할 수 있다. 동일한 과정에 따라, 전자 장치는, 제 1 이미지 (310b,310c,310n) 각각의 얼굴 영역에 대응하는 저해상도 이미지들 각각에, 입 모양들(330b,330c,330n) 각각을 합성함으로써, 제 2 이미지(320b,320c,320d)를 생성할 수 있다. 적어도 하나의 제 2 이미지 (320a,320b,320c,320d)는 제 2 해상도(예를 들어, 100 X 100의 해상도)를 가질 수 있다. 한편, 도 3의 예시에서는, 하나의 얼굴 영역(311a) (또는, 다운샘플링된 이미지)에 하나의 입 모양(330a)이 대 응하는 것과 같이 도시되어 있다. 다양한 실시예에 따른 전자 장치는, 하나의 얼굴 영역(311a)(또는, 다 운샘플링된 이미지)에 대하여 복수 개의 입 모양 후보들을 생성하고, 이 중 하나의 입 모양 후보를 선택할 수 있다. 도 3에서의 입 모양(330a)은 하나의 얼굴 영역(311a) (또는, 다운샘플링된 이미지)에 대한 복수 개의 입 모양 후보들 중 선택된 하나일 수 있다. 다른 입 모양들(330b,330c,330n) 또한 각각, 복수 개의 후보들로부터 선택된 하나들일 수 있다. 복수 개의 후보들의 생성 및 선택에 대하여서는 도 4 및 도 5를 참조하여 후술하도 록 한다. 한편, 다른 실시예에서는, 전자 장치는, 하나의 얼굴 영역(311a) (또는, 다운샘플링된 이미지) 에 대하여 복수 개의 후보 생성 없이, 곧 바로 하나의 입 모양(330a)을 생성하도록 구현될 수도 있다. 다시, 도 2 및 도 3을 함께 참조하면, 다양한 실시예에 따라서 전자 장치는, 205 동작에서, 적어도 하나의 제 2 이미지(320a,320b,320c,320n) 각각에 대하여 super-resolution 모델을 적용하여 적어도 하나의 제 3 이미 지(340a,340b,340c,340n) 각각을 생성할 수 있다. super-resolution 모델은, 예를 들어 SISR(single image super resolution) 기반의 모델 및/또는 MISR(multi image super resolution) 기반의 모델을 포함할 수 있으며, 그 종류에는 제한이 없다. 하나의 실시예에서, 전자 장치는, 하나의 저 해상도 이미지인 제 2 이 미지(320a)를 복수 개의 영역들로 분할하고, 분할된 영역들 각각에 대하여 상이한 super-resolution 모델을 적 용하여 복수 개의 고해상도 영역들을 획득하고, 이를 합성하여 하나의 고 해상도 이미지인 제 3 이미지(340a)를 생성할 수 있다. 이에 대하여서는, 도 13 및 도 14를 참조하여 더욱 상세하게 설명하도록 한다. 또 다른 실시 예에서는, 전자 장치는 하나의 저 해상도 이미지인 제 2 이미지(320a)에 하나의 super-resolution 모델을 적용하여 하나의 고해상도 이미지인 제 3 이미지(340a)를 생성할 수도 있다. 고 해상도 이미지들 (340a,340b,340c,340n)은 제 3 해상도를 가질 수 있다. 여기에서, 제 3 해상도는 제 2 해상도보다 높은 값이면 제한이 없다. 하나의 예에서, 제 3 해상도는 원본 이미지인 제 1 이미지(310a)의 얼굴 영역(311a)과 동일한 해상도를 가질 수 있으나, 상이한 해상도를 가질 수도 있다. 다시, 도 2 및 도 3을 함께 참조하면, 다양한 실시예에 따라서 전자 장치는, 207 동작에서, 적어도 하나의 제 3 이미지(340a,340b,340c,340n) 각각의 적어도 일부를 적어도 하나의 제 1 이미지(310a,310b,310c,310n)에 합성할 수 있다. 하나의 실시예에서, 전자 장치는, 제 3 이미지(340a)의 전체가 아닌 일부 영역만을 원본 이미지인 제 1 이미지(310a)에 합성할 수 있다. 얼굴 전체를 합성하는 경우에 부자연스러울 가능성이 있어, 전 자 장치는 제 3 이미지(340a) 중 하관 영역을 추출하여, 해당 영역만을 제 1 이미지(310a)에 합성할 수도 있으며, 이에 대하여서는 도 15 및 도 16을 참조하여 더욱 상세하게 설명하도록 한다. 다른 실시예에서는, 전 자 장치는 제 3 이미지(340a) 전체를 제 1 이미지(310a)에 합성할 수도 있다. 한편, 적어도 하나의 제 3 이미지(340a,340b,340c,340n)가, 적어도 하나의 제 1 이미지(310a,310b,310c,310n)의 얼굴 영역(예를 들어, 311a)와 실질적으로 동일한 해상도를 가진 경우에는, 전자 장치는 적어도 하나의 제 3 이미지 (340a,340b,340c,340n)의 적어도 일부를 적어도 하나의 제 1 이미지(310a,310b,310c,310n)에 합성할 수 있으나, 구현에 따라서는 super-resolution 모델을 적용한 후 다운 샘플링한 결과물을 합성할 수도 있다. 또는, 적어도 하나의 제 3 이미지(340a,340b,340c,340n)가, 적어도 하나의 제 1 이미지(310a,310b,310c,310n) 의 얼굴 영역(예를 들어, 311a)와 실질적으로 상이한 해상도를 가진 경우에는, 전자 장치는 적어도 하나의 제 3 이미지(340a,340b,340c,340n)의 적어도 일부에 대한 해상도 조정을 수행한 후, 적어도 하나의 제 1 이미지 (310a,310b,310c,310n)에 합성할 수 있다. 상술한 바에 따라서, 전자 장치는, 음성 데이터에 대응하여 시계열적으로 변경되는 입 모양 (330a,330b,330c,330d)이 합성된 적어도 하나의 이미지(350a,350b,350c,350n)를 생성할 수 있다. 전자 장치 는, 합성된 적어도 하나의 이미지(350a,350b,350c,350n)를 음성 데이터와 매핑하여 저장할 수 있으며, 예를 들어 하나의 동영상 파일로 저장할 수도 있으며, 파일 형식에는 제한이 없다. 하나의 예시에서는, 음성 데이터만이 합성된 적어도 하나의 이미지(350a,350b,350c,350n)와 매핑되어 저장될 수 있다. 다른 예시에서는, 음성 데이터와 추가 음성 데이터(미도시)가 합성된 음성 데이터가 적어도 하나의 이미지(350a,350b,350c,350n)와 매핑되어 저장될 수 있다. 예를 들어, 추가 음성 데이터(미도시)는, 원본 동영 상 파일에 포함되어 있던 음성 데이터의 적어도 일부일 수 있다. 만약, 원본 동영상 파일에 시계열적으로 변경 되는 입 모양(330a,330b,330c,330d)이 재생되는 시간 기간 중 발화에 대응하는 음성 데이터가 포함된 경우에는, 추가 음성 데이터(미도시)는 원본 동영상의 음성 데이터로부터 발화에 대응하는 음성 데이터가 배제된 음성 데 이터(예를 들어, 배경음으로도 명명됨)일 수 있다. 만약, 원본 동영상 파일에 시계열적으로 변경되는 입 모양 (330a,330b,330c,330d)이 재생되는 시간 기간 중 발화에 대응하는 음성 데이터가 포함되지 않은 경우에는, 원본 음성 데이터가 추가 음성 데이터로 이용될 수도 있다. 전자 장치는, 음성 데이터 및 추가 음성 데이 터(미도시)의 합성 시에 추가적인 처리(예를 들어, 추가 음성 데이터(미도시)의 진폭 조정)를 수행할 수도 있다. 본 개시에서의 음성 데이터와 이미지들의 연관 저장은, 입 모양 생성을 위하여 이용된 음성 데이터 만의 이미지들의 연관 저장 의미할 수도 있고, 또는 입 모양 생성을 위하여 이용된 음성 데이터와 추 가 음성 데이터의 이미지들의 연관 저장을 의미할 수도 있음을 당업자는 이해할 것이다. 음성 데이터는, 합성된 적어도 하나의 이미지(350a,350b,350c,350n)와 시간적으로 동기화될 수 있다. 전자 장 치는, 추후 동영상 파일을 재생할 수 있으며, 이에 따라 합성된 적어도 하나의 이미지 (350a,350b,350c,350n)가 순차적으로 표시될 수 있으며, 이와 동시에 시간적으로 동기화된 음성 데이터가 출력될 수 있다. 이에 따라, 사용자는, 원본 이미지에 포함된 인물이 음성 데이터를 발화하는 것과 같은 동영상을 시청할 수 있다. 한편, 상술한 바에서는, 음성 데이터가 입 모양 생성을 위한 발화에 대응한 음 성 데이터만을 포함하는 것과 같이 설명되었지만, 이 또한 예시적인 것이다. 음성 데이터는 발화에 대응 한 음성 데이터만을 포함할 수도 있거나, 또는 발화에 대응한 음성 데이터와 배경음을 포함하는 음성 데이터를 포함할 수도 있다. 다양한 실시예에서, 전자 장치는, 입 모양을 합성한 동영상을 저장하고 있다가, 재생 요청에 따라, 출력 장치(예를 들어, 표시 모듈 및/또는 스피커)를 통하여 출력할 수 있다. 또는, 전자 장치는, 외부 장치로 부터의 요청에 따라서, 합성된 동영상을 전송할 수도 잇다. 예를 들어, 외부 장치는, 구독형 VOD 서비스에 가 입한 클라이언트 장치일 수 있으며, 전자 장치는 서버로 구현될 수 있다. 전자 장치는, 클라이언트 장치로부터의 VOD 제공에 따라, 합성된 동영상을 전송할 수 있다. 또는, 전자 장치는, 스트리밍 서비스를 제공하도록 구현될 수도 있으며, 외부 장치로부터의 요청에 따라 합성된 동영상을 전송할 수 있다. 예를 들어, 전자 장치는, 재생 요청 언어에 대응하는 입 모양으로 합성된 동영상을 전송할 수도 있으며, 이에 대하여 서는 도 20을 참조하여 더욱 상세하게 설명하도록 한다. 또는, 전자 장치는, 일반적인 동영상 파일을 제 공하는 서버로 구현될 수도 있으며, 일반적인 동영상 파일을 제공하다가, 입 모양 합성 동영상의 요청(예를 들어, 클라이언트 장치에서 제공되는 아이콘의 지정에 따른 요청)이 확인되면, 이에 대응하여 합성된 동영상을 제 공하도록 설정될 수도 있으며, 합성된 동영상을 제공하는 방식에는 제한이 없다. 한편, 도 2의 흐름도 및, 이하에서 설명되는 흐름도에서 도시된 동작들의 수행 순서는, 도시된 바에 따라 한정 되지 않으며 수행 순서가 변경될 수 있다. 두 개 이상의 동작이 실질적으로 동시에(또는, 병렬적으로) 수행될 수도 있다. 인접하는 동작들 사이, 첫 동작의 이전, 또는 마지막 동작 이후에 다른 동작이 추가적으로 수행될 수도 있다. 도시된 동작들 중 적어도 일부가 생략될 수도 있다. 도 4는 다양한 실시예에 따른 전자 장치의 동작 방법을 설명하기 위한 흐름도를 도시한다. 도 4의 실시예는 도 5를 참조하여 설명하도록 한다. 도 5는 다양한 실시예에 따른 복수 개의 입 모양 후보들 중 하나가 선택되는 과정을 설명하기 위한 도면이다. 본 실시예 및 이하의 실시예들을 설명함에 있어서, 도 2 및 도 3을 참조하여 설명된 부분에 대하여서는, 그 설명을 간략히 하거나, 또는 생략하도록 한다. 도 4 및 도 5를 함께 참조하면, 다양한 실시예에 따라서, 전자 장치(예를 들어, 프로세서)는, 401 동 작에서, 적어도 하나의 제 1 이미지(510a,510b,510c,510n) 각각의 적어도 하나의 얼굴 영역, 예를 들어 제 1 이 미지(510a)의 얼굴 영역(511a)(다른, 제 1 이미지(510b,510c,510n)의 얼굴 영역은 설명의 편의를 위하여 생략됨)을 확인할 수 있다. 상술한 바와 같이, 전자 장치는, 적어도 하나의 제 1 이미지 (510a,510b,510c,510n) 각각의 적어도 하나의 얼굴 영역을 이용하여(예를 들어, 다운 샘플링하거나, 업 샘플링 하거나, 또는 샘플링을 수행하지 않고), 적어도 하나의 저해상도 이미지를 생성할 수 있다. 다양한 실시예에 따라서, 전자 장치는, 403 동작에서, 하나의 음성 데이터에 기반하여 복수 개의 입 모양 후보(531,532,533,534)를 생성할 수 있다. 여기에서, 입 모양 후보는, 시계열적인 순서를 가지는 복수 개 의 입 모양을 포함할 수 있다. 예를 들어, 제 1 입 모양 후보는, 제 1 시점에 대응하는 입 모양(531a), 제 2 시점에 대응하는 입 모양(531b), 제 3 시점에 대응하는 입 모양(531c), 제 4 시점에 대응하는 입 모양 (531d)을 포함할 수 있다. 제 2 입 모양 후보는, 제 1 시점에 대응하는 입 모양(532a), 제 2 시점에 대응 하는 입 모양(532b), 제 3 시점에 대응하는 입 모양(532c), 제 4 시점에 대응하는 입 모양(532d)을 포함할 수 있다. 즉, 제 1 입 모양 후보 및 제 2 입 모양 후보는, 음성 데이터의 동일한 시간 기간에 대 응하는 복수 개의 입 모양들을 포함할 수 있다. 제 3 입 모양 후보 및 제 4 입 모양 후보 또한, 제 1 시점에 대응하는 입 모양(533a,534a), 제 2 시점에 대응하는 입 모양(533b,534b), 제 3 시점에 대응하는 입 모양(533c,534c), 제 4 시점에 대응하는 입 모양(533d,533d)을 포함할 수 있다. 하나의 실시예에서, 전자 장치 는, 하나의 음성 데이터를 복수 개의 방식으로 처리하여 복수 개의 입력값을 생성하고, 생성된 원본 음성 데이터와 복수 개의 입력값 각각을, 입 모양을 생성하기 위한 인공지능 모델에 입력함으로써, 복수 개의 입 모양 후보들(531,532,533,534)를 생성할 수 있으며, 이에 대하여서는 도 6 및 도 7을 참조하여 더욱 상 세하게 설명하도록 한다. 또 다른 실시예에서, 전자 장치는, 하나의 음성 데이터를 복수 개의 입 모 양을 생성하기 위한 인공지능 모델에 입력함으로써, 복수 개의 입 모양 후보들(531,532,533,534)를 생성할 수 있으며, 이에 대하여서는 도 8 및 도 9를 참조하여 더욱 상세하게 설명하도록 한다. 한편, 복수 개의 입 모양 후보들(531,532,533,534)은, 다른 후보와는 적어도 하나의 상이한 입 모양을 포함할 수 있다. 다양한 실시예에 따라서, 전자 장치는, 405 동작에서, 복수 개의 입 모양 후보(531,532,533,534) 중 하나 를 선택할 수 있다. 도 5의 예시에서는, 전자 장치는, 제 2 입 모양 후보를 선택한 것을 상정하도록 한다. 하나의 실시예에서, 전자 장치는, 사용자의 입력에 기반하여 복수 개의 입 모양 후보 (531,532,533,534) 중 하나를 선택할 수 있으며, 이에 대하여서는 도 10, 도 11a 내지 도 11f를 참조하여 더욱 상세하게 설명하도록 한다. 또는, 전자 장치는, 사용자의 입력 없이, 복수 개의 입 모양 후보 (531,532,533,534) 중 하나를 선택할 수도 있다. 전자 장치는, 예를 들어, 입 모양 평가 모델을 이용하여, 복수 개의 입 모양 후보(531,532,533,534) 중 하나를 선택할 수도 있으며, 이에 대하여서는 도 12a를 참조하여 더욱 상세하게 설명하도록 한다. 다양한 실시예에 따라서, 전자 장치는, 407 동작에서, 적어도 하나의 얼굴 영역에 기반하여 생성된 적어도 하나의 이미지, 예를 들어 상술한 저해상도 이미지 각각에, 선택된 입 모양을 적용하여 적어도 하나의 제 2 이미지(520a,520b,520c,520n)를 생성할 수 있다. 전자 장치는, 선택된 입 모양에 포함된 시점 별 입 모양들(532a,532b,532c,532n) 각각을 적어도 하나의 제 1 이미지(510a,510b,510c,510n) 각각의 얼굴 영역에 기반하여 생성된 적어도 하나의 이미지에 합성함으로써, 적어도 하나의 제 2 이미지(520a,520b,520c,520n)를 생 성할 수 있다. 이후, 전자 장치는, 적어도 하나의 제 2 이미지(520a,520b,520c,520n)에 대하여 super- resolution 모델을 적용함으로써, 적어도 하나의 제 3 이미지(540a,540b,540c,540n)를 생성할 수 있다. 도시되지는 않았지만, 전자 장치는, 적어도 하나의 제 3 이미지(540a,540b,540c,540n) 각각의 적어도 일부를, 원본 이미지인 적어도 하나의 제 1 이미지(510a,510b,510c,510n) 각각에 합성함으로써, 입 모양이 합성된 동영 상 파일을 생성할 수 있다. 한편, 전자 장치가 입 모양이 합성된 저해상도 이미지, 예를 들어, 적어도 하나의 제 2 이미지 (520a,520b,520c,520n)에 대한 super-resolution 모델 적용 이전에 복수 개의 입 모양 후보들 중 어느 하나를 선택하는 것은 단순히 예시적인 것이다. 하나의 대안적인 실시예에서는, 전자 장치는, 적어도 하나의 저 해상도 이미지를 생성한 이후에 선택을 수행할 수도 있다. 예를 들어, 전자 장치는, 복수 개의 입 모양 후보들(531,532,533,534) 각각이 합성된 복수 개의 저해상도 이미지 후보들을 생성할 수도 있다. 예를 들어, 도 5에서의 적어도 하나의 제 2 이미지(520a,520b,520c,520n)은 복수 개의 저해상도 이미지 후보들 중 하나의 후보일 수 있다. 복수 개의 저해상도 이미지 후보들 각각은, 복수 개의 입 모양 후보들(531,532,533,534) 각각 을 포함할 수 있으며, 전자 장치는 사용자의 입력에 기반하거나, 또는 평가 모델의 평가 결과에 기반하여 복수 개의 저해상도 이미지 후보들 중 어느 하나를 선택할 수도 있다. 또는, 다른 대안적인 실시예에서는, 적어도 하나의 고해상도 이미지를 생성한 이후에 선택을 수행할 수도 있다. 예를 들어, 전자 장치는, 복수 개의 입 모양 후보들(531,532,533,534) 각각이 합성된 복수 개의 저해상도 이미지들을 생성할 수도 있다. 복수 개의 저해상도 이미지들 각각은, 복수 개의 입 모양 후보들 (531,532,533,534) 각각을 포함할 수 있다. 예를 들어, 도 5에서의 적어도 하나의 제 2 이미지 (520a,520b,520c,520n)은 복수 개의 저해상도 이미지들 중 하나의 이미지 셋트일 수 있다. 전자 장치는 복수 개의 저해상도 이미지 후보들 각각에 대하여 super-resolution 모델을 적용할 수 있다. 전자 장치는, 이에 따라 복수 개의 고해상도 이미지 후보들을 생성할 수 있다. 예를 들어, 도 5에서의 적어도 하나의 제 3 이미지(540a,540b,540c,540n)은 복수 개의 고해상도 이미지 후보들 중 하나의 후보일 수 있다. 전 자 장치는, 사용자의 입력에 기반하거나, 또는 평가 모델의 평가 결과에 기반하여 복수 개의 고해상도 이 미지 후보들 중 어느 하나를 선택할 수도 있다. 또는, 또 다른 대안적인 실시예에서는, 전자 장치는, 적어도 하나의 고해상도 이미지를 적어도 하나의 원 본 이미지에 합성까지 한 이후에, 어느 하나를 선택할 수도 있다. 예를 들어, 전자 장치는, 복수 개의 입 모양 후보들(531,532,533,534) 각각이 합성된 복수 개의 저해상도 이미지들을 생성할 수도 있다. 복수 개의 저 해상도 이미지들 각각은, 복수 개의 입 모양 후보들(531,532,533,534) 각각을 포함할 수 있다. 예를 들어, 도 5에서의 적어도 하나의 제 2 이미지(520a,520b,520c,520n)은 복수 개의 저해상도 이미지들 중 하나의 이미지 셋 트일 수 있다. 전자 장치는 복수 개의 저해상도 이미지 후보들 각각에 대하여 super-resolution 모델을 적용할 수 있다. 전자 장치는, 이에 따라 복수 개의 고해상도 이미지들을 생성할 수 있다. 예를 들어, 도 5에서의 적어도 하나의 제 3 이미지(540a,540b,540c,540n)은 복수 개의 고해상도 이미지들 중 하나일 수 있 다. 전자 장치는, 복수 개의 고해상도 이미지들 각각을, 적어도 하나의 원본 이미지에 합성할 수 있으며, 이에 따라 복수 개의 합성이 완료된 이미지 후보들이 생성될 수 있다. 예를 들어, 도 2의 적어도 하나의 제 4 이미지(350a,350b,350c,350n)은, 복수 개의 합성이 완료된 이미지 후보들 중 어느 하나일 수 있다. 전자 장치 는, 사용자의 입력에 기반하거나, 또는 평가 모델의 평가 결과에 기반하여 복수 개의 합성이 완료된 이미 지 후보들 중 어느 하나를 선택할 수도 있다. 상술한 바와 같이, 후보들 중 어느 하나를 선택하는 시점에는 제 한이 없다. 도 6은 다양한 실시예에 따른 전자 장치의 동작 방법을 설명하기 위한 흐름도를 도시한다. 도 6의 실시예는 도 7을 참조하여 설명하도록 한다. 도 7은 다양한 실시예에 따른 복수 개의 입 모양 후보들을 생성하는 과정을 설 명하기 위한 도면이다. 도 6 및 도 7을 함께 참조하면, 다양한 실시예에 따라서, 전자 장치(예를 들어, 프로세서)는, 601 동 작에서, 하나의 음성 데이터를 획득할 수 있다. 전자 장치는, 603 동작에서, 하나의 음성 데이터에 대하여 복수 개의 아날로그 처리(711,712,713)를 수행함으로써, 복수 개의 변경된 음성 데이터(702,703,704)를 획득할 수 있다. 상술한 바와 같이, 음성 데이터는, 음성 파형으로 표현될 수 있거나, 또는 음성 파형으 로 변환될 수 있다. 아날로그 처리(711,712,713)는, 음성 파형에 대한 진폭 조정(감소 또는 증가)를 포함할 수 있다. 진폭 조정의 정도에는 제한이 없다. 아울러, 조정의 정도에 따라 아날로그 처리가 구분될 수도 있으며, 예를 들어 1.5배 증가 및 1.8배 증가가 상이한 아날로그 처리로서 구분될 수도 있다. 아날로그 처리 (711,712,713)는, 음성 파형에 대한 재생 속력 조정을 포함할 수 있다. 재생 속력 조정의 정도에는 제한이 없다. 아울러, 조정의 정도에 따라 아날로그 처리가 구분될 수도 있으며, 예를 들어 1.5배 증가 및 1.8배 증가 가 상이한 아날로그 처리로서 구분될 수도 있다. 아날로그 처리(711,712,713)는, 음성 파형에 대한 노이즈 추가 또는 노이즈 감소(또는, 억제)를 포함할 수 있다. 노이즈에는 제한이 없으며, 노이즈의 종류에 따라 아날로 그 처리가 구분될 수도 있으며, 예를 들어 제 1 노이즈의 추가 및 제 1 노이즈와 상이한 제 2 노이즈 추가가 상 이한 아날로그 처리로서 구분될 수도 있다. 아날로그 처리(711,712,713)는, 음성 파형에 대한 배경음 분리를 포함할 수 있다. 배경음의 종류 및/또는 배경음의 크기에는 제한이 없으며, 배경음의 종류 및/또는 배경음의 크기에 따라 아날로그 처리가 구분될 수도 있다. 한편, 아날로그 처리(711,712,713)은, 상술한 방식 이외에도, 상대적으로 부드러운 음성을 위한 스펙트럼 변환을 포함할 수도 있으며, 그 종류에는 제한이 없으며, 아날로그 처리(711,712,713)는, 필터로 명명될 수도 있다. 다양한 실시예에 따른 전자 장치는, 605 동작에서, 입 모양 생성 모델에, 음성 데이터 및 복수 개의 변경된 음성 데이터(702,703,704) 각각을 입력할 수 있다. 607 동작에서, 전자 장치는, 입 모양 생 성 모델로부터 복수 개의 입 모양 후보들(731,732,733,734) 각각을 획득할 수 있다. 입 모양 생성 모델 은, 복수 개의 변경된 음성 데이터(702,703,704) 각각을 순차적으로, 또는 적어도 동시에 입력받아, 그 출 력값인 입 모양 후보들(731,732,733,734) 각각을 순차적으로, 또는 적어도 동시에 출력할 수 있다. 각각의 입 모양 후보들(731,732,733,734)은 서로 적어도 일부 상이한 입 모양을 포함할 수 있으며, 이는 그 입력값(예를 들어, 701,702,703,704)가 서로 적어도 일부 상이함에서 기인할 수 있다. 예를 들어, 제 2 처리가 음성 파형에 대한 진폭 증가인 것을 상정하도록 한다. 입 모양 생성 모델은, 제 2 처리에 기반한 제 2 변 경된 음성 데이터를 입력받고, 이에 대응하는 제 2 입 모양 후보를 출력할 수 있다. 아울러, 입 모 양 생성 모델은, 원본 음성 데이터를 입력받고, 이에 대응하는 제 4 입 모양 후보를 출력할 수 있다. 입 모양 생성 모델은, 예를 들어 상대적으로 큰 진폭의 음성 파형에 대하여서는, 상대적으로 입을 더 크게 벌린 입 모양을 출력하도록 트레이닝될 수도 있다. 이 경우에는, 제 2 입 모양 후보에 포함된 각 각의 입 모양들이, 제 4 입 모양 후보에 비하여, 상대적으로 더 크게 벌린 입 모양을 가질 수 있다. 이와 같이, 하나의 입 모양 생성 모델에 의하여서도, 그 입력값을 복수 개로 생성함에 따라 복수 개의 입 모양 후보들(731,732,733,734)이 생성될 수 있다. 이후에는, 도 4 및 도 5를 참조하여 설명한 바와 같이, 복수 개의 입 모양 후보들(731,732,733,734) 중 어느 하 나가 선택될 수 있다. 예를 들어, 사용자가 입 모양을 선택하는 경우에는, 복수 개의 입 모양 후보들 (731,732,733,734) 중 가장 자연스러운 입 모양을 선택할 수 있으며, 이에 대하여서는 도 10 및 도 11a 내지 도 11f를 참조하여 더욱 상세하게 설명하도록 한다. 예를 들어, 전자 장치가 평가 모델을 이용하여 입 모양 을 선택하는 경우에는, 복수 개의 입 모양 후보들(731,732,733,734) 중 가장 평가 결과와 연관된 스코어가 높은 입 모양을 선택할 수 있으며, 이에 대하여서는 도 12a를 참조하여 더욱 상세하게 설명하도록 한다. 이에 따라, 하나의 입 모양 생성 모델에 따라 하나의 결과만이 출력되는 기존 입 모양 합성 기술과 비교하여, 더욱 자 연스러운 입 모양 생성이 가능할 수 있다. 도 8은 다양한 실시예에 따른 전자 장치의 동작 방법을 설명하기 위한 흐름도를 도시한다. 도 8의 실시예는 도 9를 참조하여 설명하도록 한다. 도 9는 다양한 실시예에 따른 복수 개의 입 모양 후보들을 생성하는 과정을 설 명하기 위한 도면이다. 도 8 및 도 9를 함께 참조하면, 다양한 실시예에 따라서, 전자 장치(예를 들어, 프로세서)는, 801 동 작에서, 하나의 음성 데이터를 획득할 수 있다. 전자 장치는, 803 동작에서, 하나의 음성 데이터 를 복수 개의 입 모양 생성 모델들(911,912,913,914) 각각에 입력할 수 있다. 전자 장치는, 805 동 작에서, 복수 개의 입 모양 생성 모델들(911,912,913,914) 각각으로부터 복수 개의 입 모양 후보 (921,922,923,924) 각각을 획득할 수 있다. 예를 들어, 복수 개의 입 모양 생성 모델들(911,912,913,914) 각 각은 서로 상이한 트레이닝 데이터를 이용한 트레이닝 결과에 따라 획득될 수 있다. 하나의 예에서, 제 1 입 모양 생성 모델은, 제 1 언어(예를 들어, 한국어)의 트레이닝 데이터를 이용한 트레이닝 결과에 따라 획득 된 모델일 수 있고, 제 2 입 모양 생성 모델은, 제 2 언어(예를 들어, 영어)의 트레이닝 데이터를 이용한 트레이닝 결과에 따라 획득된 모델일 수 있다. 동일한 신경망 구조에 대하여서도 상이한 트레이닝 데이터를 이 용하여 트레이닝을 수행한다면 상이한 입 모양 생성 모델들이 생성될 수 있다. 만약, 제 1 언어의 음성 데이터 가, 제 2 언어에 따라 트레이닝된 제 2 입 모양 생성 모델에 입력된다 하더라도, 해당 음성 데이터 에 대응하는 제 2 입 모양 후보가 생성될 수 있다. 제 2 입 모양 후보는, 제 1 입 모양 후보 와 상이할 수 있으며, 경우에 따라 더욱 자연스러울 수도 있다. 다른 예에서, 제 3 입 모양 생성 모델 은, 제 1 감정(예를 들어, 기쁨)의 트레이닝 데이터를 이용한 트레이닝 결과에 따라 획득된 모델일 수 있 고, 제 4 입 모양 생성 모델은, 제 2 감정(예를 들어, 분노)의 트레이닝 데이터를 이용한 트레이닝 결과에 따라 획득된 모델일 수 있다. 제 3 입 모양 후보는, 예를 들어 제 1 감정에 기반하여 학습된 제 3 입 모양 생성 모델으로부터 출력됨에 따라서, 제 1 감정 시의 입 모양을 모사하는 형태를 가질 수 있다. 제 4 입 모양 후보는, 예를 들어 제 2 감정에 기반하여 학습된 제 4 입 모양 생성 모델으로부터 출력됨에 따라서, 제 2 감정 시의 입 모양을 모사하는 형태를 가질 수 있다. 이에 따라, 제 4 입 모양 후보는, 제 3 입 모양 후보와 상이할 수 있다. 한편, 도 9의 예시에서와 같이, 일부의 입 모양 생성 모델은 상이한 언어 트레이닝 데이터에 기반하여 트레이닝된 모델이고, 일부의 입 모양 생성 모델은 상이한 감정 트레이닝 데 이터에 기반하여 트레이닝된 모델인 것은 단순히 설명을 위한 것이며, 서로 상이한 파라미터 및/또는 서로 상이 한 신경망 구조의 모델들이라면 제한이 없다는 것을 당업자는 이해할 것이다. 예를 들어, 모델은, 인종별 특성 (예를 들어, 백인, 흑인, 황인 별 특성)에 따라 트레이닝된 모델 또는 장르별 특성(실사 영화, 3D 애니메이션, 2D 애니메이션)에 따라 트레이닝된 모델을 포함할 수도 있다. 입 모양 생성 모델들(911,912,913,914)에 기반 한 동작(연산)은, 적어도 일부 동시에 수행되거나, 또는 순차적으로 수행될 수도 있다. 각각의 입 모양 후보들 (921,922,923,924)은 서로 적어도 일부 상이한 입 모양을 포함할 수 있으며, 이는 입 모양 생성 모델들 (911,912,913,914)가 서로 적어도 일부 상이함에서 기인할 수 있다. 이후에는, 도 4 및 도 5를 참조하여 설명 한 바와 같이, 복수 개의 입 모양 후보들(921,922,923,924) 중 어느 하나가 선택될 수 있다. 이에 따라, 하나 의 입 모양 생성 모델에 따라 하나의 결과만이 출력되는 기존 입 모양 합성 기술과 비교하여, 더욱 자연스 러운 입 모양 생성이 가능할 수 있다. 다양한 실시예에 따라서, 전자 장치는, 음성 데이터를 아날로그 처리하여 복수 개의 입력값을 생성할 수 있으며, 생성된 복수 개의 입력값들 각각을 복수 개의 모델들에 입력할 수도 있다. 예를 들어, 전자 장치(10 1)가, 4개의 모델들을 저장하고 있으며, 아날로그 처리 방식이 2개인 것을 상정하도록 한다. 이 경우, 전자 장 치는, 음성 데이터 원본, 아날로그 처리된 음성 데이터 2개까지 총 3개의 입력값을 생성할 수 있다. 전자 장치는, 총 3개의 입력값 각각을 4개의 모델들에 입력할 수 있다. 이에 따라, 전자 장치는, 12개의 입 모양 후보를 생성할 수도 있다. 도 10은 다양한 실시예에 따른 전자 장치의 동작 방법을 설명하기 위한 흐름도를 도시한다. 도 10의 실시예는 도 11a 내지 11f를 참조하여 설명하도록 한다. 도 11a 내지 11f는 다양한 실시예에 따른 복수 개의 입 모양 후 보들을 생성하는 과정을 설명하기 위한 도면이다. 도 10을 참조하면, 다양한 실시예에 따라서, 전자 장치(예를 들어, 프로세서)는, 1001 동작에서, 적 어도 하나의 제 1 이미지에 대응하는 음성 데이터를 획득할 수 있다. 적어도 하나의 제 1 이미지는, 상술하였 던 적어도 하나의 원본 이미지일 수 있다. 예를 들어, 도 11a에서와 같이, 전자 장치는, 표시 모듈 상에 적어도 하나의 동영상 파일의 재생을 위한 적어도 하나의 아이콘(또는, 썸네일)(1111,1112,1113,1114)을 표시할 수 있다. 전자 장치는, 적어도 하나의 동영상 파일 중 음성 데이터를 합성할 동영상 파일을 선택 할 수 있다. 예를 들어, 전자 장치는, 적어도 하나의 아이콘(1111,1112,1113,1114) 중 어느 하나에 대한 사용자 입력(예를 들어, 아이콘에 대한 터치 입력, 또는 음성 입력)을 확인할 수 있으며, 사용자 입력에 기반하 여 합성 대상의 동영상 파일을 선택할 수 있다. 예를 들어, 제 1 아이콘이 선택되면, 도 11b에서와 같이, 전자 장치는, 표시 모듈 상에 해당 동영상 파일에 포함된 적어도 하나의 제 1 이미지를 순차적 으로 표시할 수 있다. 제 1 이미지는, 해당 동영상 파일에 포함된 적어도 하나의 제 1 이미지 중 하나일 수 있다. 전자 장치는, 해당 동영상 파일에 포함된 음성 데이터에 대응하는 음성을 입/출력 모듈 을 통하여 출력할 수도 있다. 하나의 예에서, 전자 장치는, 동영상 파일 재생 구간 전체에 대하여 음성 데이터를 합성할 수 있다. 또는, 전자 장치는, 사용자 입력에 기반하여 동영상 파일이 재생되는 중 음성 데이터 합성을 수행할 재생 구간을 확인할 수도 있다. 하나의 예에서, 전자 장치는 동영상 재생 중 입/출력 모듈(예를 들어, 터치 패널)을 통한 제 1 터치 입력을 확인할 수 있으며, 이후 일정 시간 재생이 진행된 이후에, 제 2 터치 입력을 확인할 수 있다. 이 경우, 전자 장치는, 제 1 터치 입력이 확인된 제 1 재생 시점으로부터 제 2 터치 입력이 확인된 제 2 재생 시점을, 음성 데이터 합성을 수행할 재생 구간으로서 확 인할 수 있다. 다른 예에서, 전자 장치는, 프로그레스 바와 프로그레스 바 상에 위치하는 적어도 하나의 제어 오브젝트를 표시할 수도 있다. 제어 오브젝트는, 예를 들어 사용자 입력(예를 들어, 제어 오브젝트 상의 터치 입력)을 통하여 이동될 수 있다. 사용자는, 원하는 특정 재생 구간을 음성 데이터 합성 구간으로서 설정 할 수 있도록 적어도 하나의 제어 오브젝트를 이동시키기 위한 사용자 입력을 조작할 수 있다. 한편, 동영상 파일의 전체 재생 구간 중 합성 대상의 재생 구간을 설정하는 방식에는 제한이 없음을 당업자는 이해할 것이다. 다양한 실시예에 따라서, 전자 장치는, 하나의 동영상 파일에서, 복수 개의 시간 구간 별 각각에 대하여 각각 복수 개의 입 모양 후보들 중 어느 하나를 선택될 수도 있다. 예를 들어, 전자 장치는, 하나의 동영 상 파일의 제 1 시간 구간에 대하여서, 제 1 시간 구간에 대하여 합성할 음성 데이터에 대응하는 복수 개의 제1 입 모양 후보들을 선택할 수 있으며, 복수 개의 제 1 입 모양 후보들 중 어느 하나를 선택할 수 있다. 아울 러, 전자 장치는, 하나의 동영상 파일의 제 2 시간 구간에 대하여서, 제 2 시간 구간에 대하여 합성할 음 성 데이터에 대응하는 복수 개의 제 2 입 모양 후보들을 선택할 수 있으며, 복수 개의 제 2 입 모양 후보들 중 어느 하나를 선택할 수 있다. 제 2 시간 구간은, 제 1 시간 구간과 연속하는 시간 구간일 수도 있고, 또는 이 격된 시간 구간일 수도 있다. 다양한 실시예에 따라서, 전자 장치는, 1003 동작에서, 음성 데이터를 이용하여 생성된 복수 개의 입 모양 후보들을 표시할 수 있다. 예를 들어, 도 11c에서와 같이, 전자 장치는, 음성 입력을 요청하는 화면 을 표시할 수 있다. 예를 들어, 전자 장치는, 영화의 명장면과 같은 동영상을 제공할 수 있다. 예 를 들어, 도 11b에서 제공되는 동영상은, 영화의 명장면과 같은 동영상일 수 있다. 전자 장치는, 동영상에 합성할 음성의 녹음이 요청되면(예를 들어, 녹음 수행을 위한 버튼의 지정이 확인되면), 이에 대응하여 음성 입 력을 요청하는 화면)을 표시할 수 있다. 사용자는, 해당 화면을 확인함에 따라, 합성 대상의 음성 을 발화할 수 있으며, 전자 장치는, 입/출력 모듈을 통하여 수신되는 음성을 음성 데이 터로 변환할 수 있다. 이에 따라, 기존의 영화의 명장면에 사용자가 직접 입력한 음성이 합성되면서, 입 모양 까지 해당 음성에 따라 합성되는 밈(meme) 동영상이 생성될 수 있다. 예를 들어, 밈 동영상은, 기존의 영화의 명장면의 영상이 재생되되, 사용자가 직접 합성한 목소리가 재생될 수 있다. 전자 장치는, 음성 데이터를 이용하여 복수 개의 입 모양 후보들을 생성할 수 있다. 상술한 바와 같이, 전자 장치는, 하나의 음성 데 이터에 대하여 적어도 하나의 아날로그 처리를 수행하여 복수 개의 입력값을 생성할 수 있으며, 생성된 복수 개 의 입력값을 하나의 입 모양 생성 모델에 입력함으로써, 복수 개의 입 모양 후보들을 생성할 수 있다. 또는, 전자 장치는, 복수 개의 입 모양 생성 모델들 각각에 음성 데이터를 입력함으로써, 복수 개의 입 모양 후 보들을 생성할 수 있다. 전자 장치는, 도 11d에서와 같이, 생성된 복수 개의 입 모양 후보 각각에 대응하 는 복수 개의 스틸 이미지(1041,1042,1043,1044)를 표시할 수 있다. 상술한 바와 같이, 음성 데이터를 재생하 기 위한 입 모양은 복수 개로 표현되어야 하며, 이에 따라 복수 개의 입 모양 후보는 복수 개의 입 모양을 포함 할 수 있다. 하나의 예에서, 전자 장치는, 입 모양 후보에 포함된 스틸 이미지(1041,1042,1043,1044)들을 포함하는 선택 화면을 표시할 수 있다. 만약, 스틸 이미지(1041,1042,1043,1044) 중 어느 하나가 선택되 면, 전자 장치는 도 11e에서와 같이, 음성 데이터에 대응하는 음성을 출력하면서, 입 모양 후보에 포함된 복수 개의 입 모양을 순차적으로 표시, 즉 입 모양의 변경 과정을 재생할 수 있다. 도 11e에서는, 입 모양을 포함하는 하관을 포함하는 선택 화면이 표시된다. 선택 화면은 선택 아이콘 및 취소 아이콘이 포함될 수도 있다. 전자 장치는, 선택 아이콘의 지정이 확인되면, 해당 입 모양 후보를 합성 대상 입 모양으로 선택할 수 있다. 만약, 취소 아이콘이 선택되면, 전자 장치는, 스틸 이미지(1041,1042,1043,1044)들을 포함하는 선택 화면을 표시할 수도 있다. 또는, 다른 예시에서는, 전자 장치는, 동시에 복수 개의 입 모양 후보들을 재생하면서, 음성 데이터에 대응하는 음성 을 출력할 수도 있다. 예를 들어, 전자 장치는, 도 11d와 같이 구획된 영역 별로, 복수 개의 입 모양 후보 들을 재생할 수 있고, 사용자는 복수 개의 후보들의 재생을 비교하여 선택할 수도 있다. 다시 도 10을 참조하면, 다양한 실시예에 따라서, 전자 장치는, 1005 동작에서, 복수 개의 입 모양 후보들 중 제 1 입 모양 후보의 선택을 확인할 수 있다. 전자 장치는, 1007 동작에서, 제 1 입 모양 후보와 적어 도 하나의 제 1 이미지 각각의 적어도 일부를 이용하여, 제 1 입 모양 후보를 포함하는 적어도 하나의 제 2 이 미지를, 표시 모듈에 표시할 수 있다. 여기에서의 적어도 하나의 제 2 이미지는, 입 모양 후보가 선택된 이후에 적어도 하나의 원본 이미지에 합성까지 완료한 적어도 하나의 이미지(예를 들어, 도 3의 적어도 하나의 이미지(350a,350b,350c,350n))를 의미할 수 있다. 간소한 설명을 위하여 super-resolution 모델의 적용 및 원 본 이미지의 합성 과정에 대한 설명은 생략하였으며, 구현에 따라 super-resolution 모델의 적용 과정은 생략될 수도 있다. 도 11f에서와 같이, 전자 장치는, 적어도 하나의 제 2 이미지 중 하나의 제 2 이미지를 표시할 수 있으며, 합성 대상 음성 데이터에 대응하는 음성을 출력할 수 있다. 상술한 바에 따라서, 사 용자는, 복수 개의 입 모양 후보들의 재생을 확인함으로써, 더욱 자연스러운 입 모양을 선택할 수 있다. 한편, 도 11a 내지 11f에서와 같이, 전자 장치가 입 모양이 합성된 저해상도 이미지(예를 들어, 도 5의 적 어도 하나의 제 2 이미지(520a,520b,520c,520n))에 대한 super-resolution 모델 적용 이전에 복수 개의 입 모 양 후보들 중 어느 하나를 선택하는 것은 단순히 예시적인 것이다. 도 4 및 도 5를 참조하여, 설명한 다양한 대안적인 실시예에서와 같이, 전자 장치가 복수 개의 후보들 중 어느 하나를 선택하는 시점에는 제한이 없 다. 만약, 전자 장치가 복수 개의 저해상도 이미지 후보들을 생성한 이후 선택을 수행하는 경우에는, 도 11d와 연관되어 설명된 바와 같이 입 모양(또는, 하관)이 재생되는 사용자 인터페이스가 아닌, 복수 개의 저해 상도 이미지들 후보가 각각 또는 적어도 동시에, 음성 데이터에 대응하는 음성과 재생될 수 있다. 만약, 전자장치가 복수 개의 고해상도 이미지 후보들을 생성한 이후 선택을 수행하는 경우에는, 도 11d와 연관되어 설명된 바와 같이 입 모양(또는, 하관)이 재생되는 사용자 인터페이스가 아닌, 복수 개의 고해상도 이미지들 후 보가 각각 또는 적어도 동시에, 음성 데이터에 대응하는 음성과 재생될 수 있다. 만약, 전자 장치가 복수 개의 합성이 완료된 이미지 후보들을 생성한 이후 선택을 수행하는 경우에는, 도 11d와 연관되어 설명된 바와 같이 입 모양(또는, 하관)이 재생되는 사용자 인터페이스가 아닌, 복수 개의 합성이 완료된 이미지들 후보가 각 각 또는 적어도 동시에, 음성 데이터에 대응하는 음성과 재생될 수 있으며, 상술한 바와 같이 사용자의 선택 시 점이 다양하게 구현되는 바에 따라, 사용자 인터페이스 또한 다양하게 구현될 수 있음을 당업자는 이해할 것이다. 도 11g는 다양한 실시예에 따른 전자 장치의 화면을 도시한다. 다양한 실시예에 따라서, 전자 장치는, 도 11g와 같은 동영상의 구간 별 입모양을 선택할 수 있는 화면을 표시할 수 있다. 화면에는, 합성 대상의 음성 데이터의 파일 리스트가 포함될 수 있다. 화면에는, 합성 대상의 음성 데이터에 대응하는 텍스트가 포함될 수 있다. 화면에는, 동영상에 포함된 하나의 이미지 가 포함될 수 있다. 이미지는, 프로그레스 바 상의 현재 시점을 나타내는 인디케이터(118 3)에 대응하는 이미지일 수 있다. 이미지에는, 음성 데이터가 합성되는 입 부분을 나타내기 위한 오브젝 트가 포함될 수 있으며, 해당 부분은 자동 검출되거나, 또는 사용자 선택에 의하여 검출될 수 있다. 화 면에는, 복수 개의 입 모양 후보들을 나타낼 수 있는 컬러들에 대응하는 오브젝트들(1161,1162,1163,1164)이 포 함될 수 있다. 프로그레스 바 상에는, 선택된 입 모양을 나타내는 오브젝트들 (1171,1173,1175,1176,1177,1181)이 표시될 수 있다. 아울러, 용이한 식별을 위하여, 입 모양 후보 별 프로그 레스 바(1191,1192,1193,1194) 상에도, 선택됨을 나타내는 오브젝트(1172,1174,1178,1179,1180,1182)가 표시될 수 있다. 예를 들어, 도 11g에서와 같이, 하나의 음성 데이터(예를 들어, \"동해물과 백두산이 마르고 닳도록\" 에 대응하는 음성 데이터)에도, 복수 개의 입 모양 후보들(예를 들어, 1175,1176,1177)이 선택될 수 있다. 도 12a는 다양한 실시예에 따른 전자 장치의 동작 방법을 설명하기 위한 흐름도를 도시한다. 다양한 실시예에 따라서, 전자 장치(예를 들어, 프로세서)는, 1201 동작에서, 적어도 하나의 제 1 이 미지에 대응하는 음성 데이터를 획득할 수 있다. 적어도 하나의 제 1 이미지는, 상술하였던 적어도 하나의 원 본 이미지일 수 있다. 전자 장치는, 1203 동작에서, 음성 데이터를 이용하여 생성된 복수 개의 입 모양 후보들을 생성할 수 있다. 전자 장치는, 1205 동작에서, 평가 모델을 이용하여, 복수 개의 입 모양 후보 들 각각을 평가할 수 있다. 여기에서, 평가 모델은, 입 모양 및/또는 원본 이미지를 입력 값으로 하고, 입 모 양이 원본 이미지와 어울리는 정도를 나타내는 스코어를 출력 값으로 할 수 있다. 전자 장치는, 복수 개 의 입 모양 후보들 각각에, 순차적으로 및/또는 적어도 동시에 평가 모델을 적용할 수 있으며, 복수 개의 입 모 양 후보들 각각에 대응하는 적어도 하나의 평가 결과(예를 들어, 스코어)를 확인할 수 있다. 전자 장치는, 1207 동작에서, 평가 결과에 기반하여, 복수 개의 입 모양 후보 중 제 1 입 모양 후보를 선택할 수 있으며, 이 경우에는 사용자 입력이 요구되지 않을 수 있다. 대안적인 실시예에서는, 전자 장치는, 복 수 개의 입 모양 후보들 중, 지정된 조건을 만족하는 입 모양 후보들을 선택할 수 있는 사용자 인터페이스를 제 공할 수도 있다. 예를 들어, 전자 장치는, 복수 개의 입 모양 후보들 전체 중 임계값 이상의 스코어를 가 지는 일부 입 모양 후보들을 선택할 수 있는 사용자 인터페이스를 제공할 수도 있다. 이 경우에는, 지정된 조 건을 만족하는 일부 입 모양 후보들 중 하나를 선택하는 사용자 입력에 기반하여, 전자 장치는 하나의 입 모양을 선택할 수도 있다. 전자 장치는, 1209 동자에서, 제 1 입 모양 후보와 적어도 하나의 제 1 이미지 각각의 적어도 일부를 이용하여, 제 1 입 모양 후보를 포함하는 적어도 하나의 제 2 이미지를, 표시 모듈 에 표시할 수 있다. 도 12b는 다양한 실시예에 따른 평가 모델을 설명하기 위한 도면이다. 다양한 실시예에 따른 평가 모델는, 음성 데이터 및 입 모양을 입력값들로서 수신할 수 있다. 평가 모델은, 오디오 특징 임베딩 모듈을 포함할 수 있으며, 오디오 특징 임베딩 모듈 은 음성 데이터으로부터 특징 데이터를 추출할 수 있다. 평가 모델은, 비디오 특징 임베딩 모듈을 포함할 수 있으며, 비디오 특징 임베딩 모듈은 입 모양으로부터 특징 데이터를 추출 할 수 있다. 평가 모델은, DNN을 포함할 수 있으며, DNN은, 오디오 데이터에 대응하는 특징 데이터의 차원을 감소하여 출력할 수 있다. 평가 모델은, DNN을 포함할 수 있으며, DNN은, 비디오 데이터에 대응하는 특징 데이터의 차원을 감소하여 출력할 수 있다. 차원이 감소된 오디오에 대응하는 특징 데이터 및 차원이 감소된 비디오에 대응하는 특징 데이터는, 음성-영상 동기 손실(sync loss) 모듈로 입력될 수 있다. 음성-영상 동기 손실 모듈은, 차원이 감소된 오디오에 대응하는 특징 데이터 및 차 원이 감소된 비디오에 대응하는 특징 데이터를 이용하여, 제 1 손실 값을 출력할 수 있다. 제 1 손실 값은, 음 성-영상 사이의 매칭되지 않는 수준을 나타낼 수 있는 값일 수 있다. 한편, 영상 퀄리티 평가 손실 모듈(123 9)은, 차원이 감소된 비디오에 대응하는 특징 데이터를 이용하여, 제 2 손실 값을 출력할 수 있다. 예를 들어, 영상내에 아티팩트가 존재하는지 여부에 기반하여, 제 2 손실 값이 결정될 수 있다. 최종 평가 모델 손실 모듈 은, 제 1 손실 값 및 제 2 손실 값을 이용하여, 최종 손실 값을 출력할 수 있다. 예를 들어, 최종 평가 모델 손실 모듈은, 제 1 손실 값 및 제 2 손실 값의 가중치 합으로 최종 손실 값을 결정할 수 있으나, 그 결정 방식에는 제한이 없다. 평가 모델의 DNN들(1235,1236)은, 트레이닝용 데이터를 이용하여 트레이닝 될 수 있다. 전자 장치는, 복수 개의 입 모양 후보들 각각과 원본 음성 데이터를 평가 모델에 입력 할 수 있으며, 평가 모델의 출력 값(예를 들어, 최종 손실 값)에 기반하여, 복수 개의 입 모양 후보들 중 어느 하나를 선택할 수도 있다. 한편, 도 12b와 같은 평가 모델은 단순히 예시적인 것으로, 음성 및 영상 사이 의 sync를 평가하기 위한 모델이라면 제한이 없음을 당업자는 이해할 것이다. 도 13은 다양한 실시예에 따른 전자 장치의 동작 방법을 설명하기 위한 흐름도를 도시한다. 도 13의 실시예는 도 14를 참조하여 설명하도록 한다. 도 14는 다양한 실시예에 따른 하나의 이미지에 대한 복수 개의 super- resolution 모델들의 적용을 설명하기 위한 도면이다. 도 13 및 도 14를 함께 참조하면, 다양한 실시예에 따라서, 전자 장치(예를 들어, 프로세서)는, 1301 동작에서, 저해상도 이미지를 제 1 영역 및 제 2 영역으로 분할할 수 있다. 예를 들어, 전 자 장치는, 입을 포함하는 영역을 검출할 수 있으며, 입을 포함하는 영역을 제 2 영역으로 확인할 수 있다. 한편, 도 14의 예시에서는, 제 1 영역이 제 2 영역을 제외하는 영역으로 도시되었지만, 이는 하나의 예시이며, 제 1 영역은 저해상도 이미지 전체 영역으로 구현될 수도 있다. 한편, 입 을 포함하는 영역의 검출 모델에는 제한이 없다. 전자 장치는, 예를 들어 랜드마크 검출 모델을 이용하여, 확인된 랜드마크에 기반하여 입을 포함하는 영역을 검출할 수 있으나, 제한은 없다. 한편, 대안적인 실시예에서는, 전자 장치는, 복수 개의 입 모양 후보들 중 선택된 입 모양을 제 2 영역으로서 확인 하고, 입 모양이 합성되지 않은 저해상도 이미지의 일부 또는 전체를 제 1 영역으로서 확인할 수도 있다. 다양한 실시예에 따라서, 전자 장치는, 1303 동작에서, 제 1 영역에 대하여 제 1 super-resolution 모델을 적용하여 제 1 고해상도 이미지를 획득할 수 있다. 전자 장치는, 1305 동작에서, 제 2 영역에 대하여 제 2 super-resolution 모델을 적용하여 제 2 고해상도 이미지를 획득할 수 있다. 제 1 super-resolution 모델은, 예를 들어 저해상도의 얼굴 이미지를 고해상도의 얼굴 이미지 로 업 스케일링하도록 트레이닝된 인공지능 모델일 수 있으며, 예를 들어 얼굴 이미지를 트레이닝 데이터로서 이용하여 트레이닝된 인공지능 모델일 수 있다. 제 1 super-resolution 모델은, 제 1 영역(즉, 제 1 영역에 포함된 오브젝트(예를 들어, 얼굴))에 특화된 모델이라 명명될 수도 있다. 한편, 얼굴 이미 지를 업 스케일링하기 위한 인공지능 모델을 적용한 경우에는, 얼굴 이미지의 전반적인 영역에 대한 해상도가 높아지기는 하나, 입 모양, 특히 치아 부분이 부자연스럽게 생성되는 경우가 발생할 수 있다. 제 2 super- resolution 모델은, 예를 들어 저해상도의 입 모양 이미지를 고해상도의 입 모양 이미지로 업 스케일링하 도록 트레이닝된 인공지능 모델일 수 있으며, 예를 들어 입 모양 이미지를 트레이닝 데이터로서 이용하여 트레 이닝된 인공지능 모델일 수 있다. 제 2 super-resolution 모델이 적용되는 경우, 입 모양, 특히 치아 부 분이 제 1 super-resolution 모델이 적용되는 경우에 비하여, 자연스럽게 생성될 수 있다. 제 2 super- resolution 모델은, 제 2 영역(즉, 제 2 영역에 포함된 오브젝트(예를 들어, 입 및/또는 치 아))에 특화된 모델이라 명명될 수도 있다. 상술한 바와 같이, 제 1 super-resolution 모델 및/또는 제 2 super-resolution 모델은, SISR 및/또는 MISR 기반의 인공지능 모델일 수 있으며, 신경망의 구조는, 예 를 들어, SRCNN, FSRCNN, ESPCN, VDSR, DRCN, SRResNet, DRRN, EDSR, DensseSR, MemNet, GAN, DBVSR, LGFN, DynaVSR, iSeeBetter 등 다양한 구조를 가질 수 있으며 제한이 없음을 당업자는 이해할 것이다. 전자 장치 는, 1307 동작에서, 제 1 고해상도 이미지 및 제 2 고해상도 이미지를 합성하여 고해상도 이 미지를 획득할 수 있다. 저해상도 이미지에 얼굴 이미지와 연관된 제 1 super-resolution 모델 은 적용한 결과와 비교하여, 고해상도 이미지는 더욱 자연스러운 입 모양을 가질 수 있다. 전자 장치는, 적어도 하나의 제 2 이미지(예를 들어, 도 3의 적어도 하나의 제 2 이미지 (320a,320b,320c,320n)) 각각에 상술한 복수 개의 super-resolution 모델들을 적용함에 따라, 적어도 하나의 제 3 이미지(예를 들어, 도 3의 적어도 하나의 제 2 이미지(340a,340b,340c,340n))를 생성할 수 있다. 도 15는 다양한 실시예에 따른 전자 장치의 동작 방법을 설명하기 위한 흐름도를 도시한다. 도 15의 실시예는 도 16을 참조하여 설명하도록 한다. 도 16은 다양한 실시예에 따른 고해상도 이미지의 일부 영역을 원본 이미 지에 합성하는 과정을 설명하기 위한 도면이다. 도 15 및 도 16을 함께 참조하면, 다양한 실시예에 따라서, 전자 장치(예를 들어, 프로세서)는, 1501 동작에서, 고해상도 이미지에 대하여 세그먼테이션(예를 들어, 얼굴 세그먼테이션)을 수행할 수 있다. 예를 들어, 전자 장치는, 고해상도 이미지에 랜드마크 검출 모델을 적용함으로써, 복수 개의 랜드마 크들(1611,1612,1613,1614,1615)을 세그먼테이션할 수 있다. 랜드마크는, 얼굴을 구성하는 요소로서 예를 들 어, 코, 눈, 입, 눈썹, 턱 등을 의미할 수 있으며, 제한은 없다. 랜드마크들(1611,1612,1613,1614,1615)은, 예를 들어, 복수 개의 좌표들로서 표현될 수도 있다. 1503 동작에서, 전자 장치는, 세그먼테이션 결과에 기반하여, 고해상도 이미지 중 합성 대상 영역을 확인할 수 있다. 예를 들어, 전자 장치 는, 복수 개의 좌표들에 기반하여 합성 대상 영역을 확인할 수 있다. 하나의 예에서, 전자 장치는, 입에 대응하는 좌표들을 연결한 연결 선의 내측 공간과, 턱에 대응하는 좌표들을 연결한 연결 선, 턱에 대응하는 연결 선의 양 단들을 연결하되 코에 대응하는 연결 선과 적어도 일부 겹치는 연결 선에 의하여 구성되는 내측 공간을, 합성 대상 영역으로서 확인할 수 있으나, 합성 대상 영역에는 제한이 없다. 전자 장치는, 1505 동작에서, 합성 대상 영역을 분리할 수 있다. 전자 장치는, 1507 동작에서, 원본 이미지에 합성 대상 영역을 합성할 수 있다. 이에 따라, 합성 대상 영역이 원본 이미지에 합성된, 합성 완료된 이미지가 획득될 수 있다. 얼굴 영역 전체를 합성하는 경우에 는 다소 부자연스러운 합성이 수행될 가능성이 있으며, 이에 따라 합성 대상 영역을 가능한 축소시킴으로 써, 보다 자연스러운 합성이 가능할 수 있다. 도 17a는 다양한 실시예에 따른 전자 장치의 동작 방법을 설명하기 위한 도면이다. 다양한 실시예에 따라서, 전자 장치는, 이미지를 합성할 동영상 파일을 로딩할 수 있으며, 동영상 파일은, 적어도 하나의 이미지 및 음성 데이터를 포함할 수 있다. 도 17a에서는, 하나의 이미지가 표시되는 것과 같이 도시되어 있지만, 전자 장치는 동영상 파일의 재생에 따라 적어도 하나의 이미지 를 순차적으로 표시하고, 동시에 음성 데이터에 대응하는 음성을 출력할 수 있다. 다양한 실시예에 따라서, 전자 장치는, 합성 대상의 음성인, 외국어 음성을 입/출력 모듈을 수 신할 수 있다. 전자 장치는, 외국어 음성을 처리하여 외국어 음성 및 원본 배경음이 포함되 는 음성 데이터를 생성할 수 있다. 전자 장치는, 원본 음성 데이터로부터 발화 데이터를 제 거함으로써 원본 배경음을 획득할 수 있다. 전자 장치는, 획득한 원본 배경음에 외국어 음성을 합 성하여 음성 데이터를 생성할 수 있다. 한편, 도 17a에서는, 전자 장치가 외국어 음성을 입/ 출력 모듈을 통하여 획득하는 것으로 설명되었지만, 이는 예시적인 것이다. 전자 장치는, 텍스트를 획득 할 수도 있으며, 텍스트에 기반하여 외국어 음성을 생성할 수도 있다. 예를 들어, 전자 장치는, 원 본 음성 데이터의 화자의 목소리를 모사한 외국어 음성을 생성할 수도 있다. 화자가, 두 개 이상 의 언어를 능숙하게 발화하기는 어려울 가능성이 있으므로, 전자 장치는, 텍스트에 기반하여 외국어 음성 을 생성하는 기능을 지원할 수도 있다. 예를 들어, 전자 장치는, 원본 음성의 특징 정보(예를 들어, 발음적 특징, 음색적 특징, 속력적 특징 등)에 기반하여 트레이닝된 인공지능 모델에, 텍스트를 입력할 수 있다. 인공지능 모델은, 텍스트를 입력값으로 수신하여, 이에 대응하는 음성 및/또는 스펙토그램 (spectrogram)으로 변환할 수 있다. 다양한 실시예에 따라서, 전자 장치는, 음성 데이터를, 상술한 다양한 실시예들 중 적어도 일부에 기반하여 생성된 입 모양이 합성된 적어도 하나의 이미지들과 매핑하여(또는, 시간-동기화하여), 더빙된 동영상 파일을 생성할 수 있다. 더빙된 동영상 파일이 재생됨에 따라서, 입 모양이 합성된 이미지 및 음성 데이터에 대응하는 음성이 시간-동기화되어 출력될 수 있다. 도 17b는 다양한 실시예에 따른 전자 장치의 동작 방법을 설명하기 위한 도면이다. 다양한 실시예에 따라서, 전자 장치는, 이미지를 합성할 동영상 파일을 로딩할 수 있으며, 동영상 파일은, 적어도 하나의 이미지 및 음성 데이터를 포함할 수 있다. 도 17b에서는, 하나의 이미지가 표시되는 것과 같이 도시되어 있지만, 전자 장치는 동영상 파일의 재생에 따라 적어도 하나의 이미지 를 순차적으로 표시하고, 동시에 음성 데이터에 대응하는 음성을 출력할 수 있다. 다양한 실시예에 따라서, 전자 장치는, 합성 대상의 음성인, 변경된 음성을 입/출력 모듈을 수 신할 수 있다. 전자 장치는, 변경된 음성을 처리하여 변경된 음성 및 원본 배경음이 포함되는 음성 데이터를 생성할 수 있다. 전자 장치는, 원본 음성 데이터로부터 발화 데이터를 제 거함으로써 원본 배경음을 획득할 수 있다. 전자 장치는, 획득한 원본 배경음에 변경된 음성을 합 성하여 음성 데이터를 생성할 수 있다. 한편, 도 17b에서는, 전자 장치가 변경된 음성을 입/ 출력 모듈을 통하여 획득하는 것으로 설명되었지만, 이는 예시적인 것이다. 전자 장치는, 텍스트를 획득 할 수도 있으며, 텍스트에 기반하여 변경된 음성을 생성할 수도 있다. 예를 들어, 전자 장치는, 원 본 음성 데이터에 대한 캡션 결과인 텍스트 파일을 제공할 수도 있으며, 사용자는 텍스트 파일 중 수정이 요구되는 부분에 변경 텍스트를 대체하여 입력할 수 있다. 예를 들어, 전자 장치는, 원본 음성 데이터 의 화자의 목소리를 모사한 변경된 음성을 생성할 수도 있다. 전자 장치는, 음성 데이터 를, 상술한 다양한 실시예들 중 적어도 일부에 기반하여 생성된 입 모양이 합성된 적어도 하나의 이미지 들과 매핑하여(또는, 시간-동기화하여), 더빙된 동영상 파일을 생성할 수 있다. 더빙된 동영상 파 일이 재생됨에 따라서, 입 모양이 합성된 이미지 및 음성 데이터에 대응하는 음성이 시간-동기화되어 출력될 수 있다. 도 18a는 다양한 실시예에 따른 전자 장치의 동작 방법을 설명하기 위한 흐름도를 도시한다. 도 18a의 실시예 는 도 18b를 참조하여 설명하도록 한다. 도 18b는 다양한 실시예에 따른 영상 통화를 수행하는 전자 장치의 동 작 방법을 설명하기 위한 도면이다. 도 18a 및 도 18b를 함께 참조하면, 다양한 실시예에 따라서, 전자 장치(예를 들어, 프로세서)는, 1801 동작에서, 음성 데이터를 획득할 수 있다. 음성 데이터는, 예를 들어 시계열적인 음성 데이 터로 구성될 수 있다. 예를 들어, 전자 장치는, 영상 통화 어플리케이션을 실행할 수 있으며, 표시 모듈에 영상 통화 어플리케이션의 실행 화면을 표시할 수 있다. 영상 통화 어플리케이션의 실행 화 면에는, 예를 들어 통화 상대방의 전자 장치, 즉 다른 전자 장치에서 송신한 이미지가 포함될 수 있다. 영상 통화 어플리케이션은, 전자 장치의 카메라 모듈을 통하여 획득되는 이미지를 음성 데이터 와 함께 상대방의 전자 장치로 송신하는 일반 기능을 지원할 수 있다. 한편, 다양한 실시예에 따른 영상 통화 어플리케이션은, 지정된 조건이 만족되는 경우에, 음성 데이터와, 기본 이미지에 음성 데이터(181 2)에 기반하여 생성되는 입 모양을 합성하여 생성한 합성 완료된 이미지를 상대방의 전자 장치로 송신하는 기능 을 지원할 수 있다. 예를 들어, 지정된 조건은, 사용자의 입력에 따라 지정된 모드(예를 들어, 프라이버시 강 화 모드, 데이터 사용 절약 모드)가 활성화되거나, 통신 환경이 불량한 경우(예를 들어, 약전계)일 수 있거나, 및/또는 저속 네트워크 시스템으로 폴백(fallback)(예를 들어, CS fallback)한 경우일 수 있으나, 지정된 조건 의 종류에는 제한이 없다. 다양한 실시예에 따라서, 전자 장치는, 1803 동작에서, 음성 데이터에 대응하는 입 모양을 포함하는 적어 도 하나의 제 2 이미지(예를 들어, 적어도 하나의 저해상도 이미지)를 생성할 수 있다. 예를 들어, 기존에 존 재하였던 동영상 파일에 음성 데이터를 합성하는 경우에는, 복수 개의 원본 이미지들에 따라 복수 개의 제 2 이 미지들(예를 들어, 저해상도 이미지들)이 생성되었다. 전자 장치는, 음성 데이터의 발화를 모사하기 위한 복수 개의 입 모양들을 생성하고, 하나의 이미지에 복수 개의 입 모양들을 합성함으로써 복수 개의 제 2 이미지들(예를 들어, 저해상도 이미지들)을 생성할 수 있다. 전자 장치는, 1805 동작에서, 적어도 하나의 제 2 이미지 각각에 대하여 복수 개의 super-resolution 모델을 적용하여 적어도 하나의 제 3 이미지를 생성할 수 있다. 전자 장치는, 1805 동작에서, 적어도 하나의 제 3 이미지 각각의 적어도 일부를 하나의 제 1 이미지에 합성하여, 복수 개의 이미지를 생성할 수 있다. 1803 동작, 1805 동작, 및/또는 1807 동 작은, 상술한 다양한 실시예들 중 적어도 일부에 따라 수행될 수 있다. 전자 장치는, 1807 동작에서, 복 수 개의 이미지 및 음성 데이터를 다른 전자 장치, 즉 상대방 전자 장치로 송신할 수 있다. 상대방 전자 장치에서는, 복수 개의 이미지 및 음성 데이터에 대응하는 음성이 시간-동기화되어 재생될 수 있으 며, 이에 따라 스틸 이미지에서 입 모양만이 음성에 따라 움직이는 효과가 제공될 수 있다. 한편, 다른 실시예에서는, 전자 장치는, 화상 통화가 수행중인 경우가 아닌, 음성 메시지를 송신하는 경우 에, 상술한 바와 같은 하나의 이미지로부터 복수 개의 합성 완료된 이미지를 생성할 수도 있다. 전자 장치 는, 음성 데이터를 포함하는 음성 데이터를 송신하는 경우, 음성 데이터에 대응하는 복수 개의 입 모양을 생성할 수 있다. 전자 장치는, 하나의 이미지에 복수 개의 입 모양 각각을 합성함으로써, 복수 개의 합성 완료된 이미지를 생성할 수 있다. 복수 개의 합성 완료된 이미지를 생성하는 상세한 과정은 다양한 실시예들의 적어도 일부에 기초할 수 있다. 이에 따라, 기존에는 하나의 음성 메시지에 하나의 스틸 이미지가 첨부되어 송 신한 것에 비하여, 전자 장치는 음성 메시지에 입 모양 재생을 위한 복수 개의 이미지들을 첨부하여 송신 할 수 있다.도 18c는 다양한 실시예에 따른 전자 장치의 동작 방법을 설명하기 위한 흐름도를 도시한다. 다양한 실시예에 따라서, 전자 장치(예를 들어, 프로세서)는, 1831 동작에서, 다른 전자 장치로부터 음성 데이터를 수신할 수 있다. 전자 장치는, 1833 동작에서, 화자에 대응하는 이미지를 확인할 수 있다. 예를 들어, 이미지가 화자의 정보(예를 들어, 전화 번호 및/또는 이름)에 연관되어 전자 장치에 미리 저장 될 수 있다. 또는, 전자 장치는, 음성 데이터와 함께 하나의 이미지만을 다른 전자 장치로부터 수신할 수 도 있다. 전자 장치는, 1835 동작에서, 음성 데이터에 대응하는 입 모양을 포함하는 적어도 하나의 제 2 이미지를 생성할 수 있다. 전자 장치는, 음성 데이터의 발화를 모사하기 위한 복수 개의 입 모양들을 생 성하고, 하나의 이미지에 복수 개의 입 모양들을 합성함으로써 복수 개의 제 2 이미지들(예를 들어, 저해상도 이미지들)을 생성할 수 있다. 1837 동작에서, 전자 장치는, 적어도 하나의 제 2 이미지에 대하여 super- resolution 모델을 적용하여 적어도 하나의 제 3 이미지를 생성할 수 있다. 1839 동작에서, 전자 장치는, 적어도 하나의 제 3 이미지 각각의 적어도 일부를 하나의 제 1 이미지에 합성하여, 복수 개의 이미지를 생성할 수 있다. 1835 동작, 1837 동작, 및/또는 1839 동작은, 상술한 다양한 실시예들 중 적어도 일부에 따라 수행될 수 있다. 전자 장치는, 1841 동작에서, 복수 개의 이미지 및 음성 데이터를 재생할 수 있다. 이에 따라 스틸 이미지에서 입 모양만이 음성에 따라 움직이는 효과가 제공될 수 있다. 도 19는 다양한 실시예에 따른 전자 장치의 동작 방법을 설명하기 위한 흐름도를 도시한다. 다양한 실시예에 따라서, 전자 장치(예를 들어, 프로세서)는, 1901 동작에서, 음성 데이터를 획득할 수 있다. 1903 동작에서, 전자 장치는, 음성 데이터에 기반하여 복수 개의 입 모양 후보를 생성할 수 있 다. 전자 장치는, 1905 동작에서, 복수 개의 입 모양 후보 중 하나를 선택할 수 있다. 복수 개의 입 모 양 후보 생성 및 선택에 대하여서는 상술한 다양한 실시예들 중 적어도 일부가 이용될 수 있다. 전자 장치 는, 1907 동작에서, 선택된 입 모양을 적용하여 아바타 모델을 생성할 수 있다. 아바타 모델은, 예를 들 어 가상 환경(예를 들어, VR 가상 회의, 구연동화, 스트리머 목소리 모사 아바타가 활동하는 공간 등에서 동작 할 수 있으며, 입 모양을 포함한 전체 아바타 모델을 생성할 수 있는 알고리즘이 전자 장치에 저장될 수 있다. 한편, 생성된 입 모양이 부자연스러울 가능성은 존재하면, 본 실시예에서와 같이 복수 개의 입 모양 후 보 생성 및 선택이 수행됨에 따라 보다 자연스러운 입 모양이 생성될 수 있다. 전자 장치는, 1909 동작에 서, 생성된 아바타 모델을 재생할 수 있다. 도 20은 다양한 실시예에 따른 전자 장치의 동작 방법을 설명하기 위한 흐름도를 도시한다. 다양한 실시예에 따라서, 전자 장치(예를 들어, 프로세서)는, 2001 동작에서, 하나의 원본 동영상에 대하여 복수 개의 언어 별 입 모양을 생성할 수 있다. 전자 장치는, 예를 들어 하나의 원본 동영상에 대 응하는 복수 개의 언어 별 음성 데이터 및/또는 텍스트를 획득할 수 있다. 전자 장치는, 복수 개의 언어 별 음성 데이터 및/또는 텍스트에 기반하여, 복수 개의 언어 별 입 모양을 생성할 수 있으며, 입 모양의 생성 과정에 대하여서는 상세하게 설명하였으므로 여기에서의 설명은 생략하도록 한다. 다양한 실시예에 따라서, 전자 장치는, 2003 동작에서, 복수 개의 언어 별 입 모양과 메타데이터를 저장할 수 있다. 메타데이터는, 예를 들어 입 모양을 원본 동영상과 합성하기 위하여 이용되는 데이터로서, 예를 들어, 원본 동영상의 이미지 내의 입 모양 합성 위치와 연관된 정보를 포함할 수 있으나, 그 종류에는 제한이 없다. 만약, 언어 별로 입 모양을 전부 합성하는 경우에는, 원본 동영상과 실질적으로 동일한 크기의 파일이 언어의 개수만큼 생성되어 저장되어야 하며, 이는 상대적으로 큰 리소스를 요구할 수 있다. 전자 장치는, 언어 별 입 모양과 메타데이터만을 저장함으로써, 저장에 요구되는 리소스가 감소할 수 있다. 다양한 실시예에 따라서, 전자 장치 2005 동작에서 재생 요청 언어를 확인할 수 있다. 전자 장치는, 2007 동작에서, 재생 요청 언어에 대응하는 입 모양을 메타데이터를 이용하여, 원본 동영상에 합성할 수 있다. 즉, 전자 장치는, 재생 요청 시점 이후에, 원본 동영상에 대한 합성을 수행할 수 있다. 전자 장치는, 2009 동작에서, 합성된 동영상을 재생할 수 있다. 만약, 재생 도중 재생 요청 언어가 변경되는 경우에는, 전자 장치는, 변경된 언어에 대응하는 입 모양을 원본 동영상에 합성하여 제공할 수도 있다. 도 21은 다양한 실시예에 따른 전자 장치의 동작 방법을 설명하기 위한 도면이다. 다양한 실시예에 따라서, 전자 장치(예를 들어, 프로세서)는, 인물의 형상이 아닌 오브젝트에 대한 입 모양을 포함한 얼굴 생성을 수행할 수도 있다. 예를 들어, 전자 장치는, 이미지에 대하여 얼굴 을 합성할 오브젝트에 대한 사용자 선택을 확인하거나 또는 자동으로 검출할 수 있다. 사용자가 선택한 오브젝트에서 눈, 코, 입과 같은 랜드마크가 검출되지 않는 경우, 전자 장치는, 눈(2122,2123) 및입과 같은 오브젝트를 추가적으로 생성하여 기존 오브젝트에 합성함으로써, 합성된 오브젝트(212 1)를 포함하는 이미지를 생성할 수 있다. 예를 들어, 전자 장치는, 입의 오브젝트를 생성하 는 과정에서, 상술한 입 모양 생성을 위한 방법들 중 적어도 일부를 이용함으로써, 합성 대상의 음성 데이터에 대응하는 입의 오브젝트를 생성할 수 있다. 전자 장치는, 상술한 방식에 따라 합성된 동영상을 생 성할 수 있으며, 눈과 입을 가지는 오브젝트가 음성 데이터를 말하는 것과 같은 동영상이 재생될 수 있다. 한 편, 이미지에 포함되는 오브젝트(눈, 입)의 종류는 예시적인 것으로, 추가적인 오브젝트를 더 포함할 수 도 있다. 도 22a 내지 22c는 다양한 실시예에 따른 전자 장치의 화면을 도시한다. 도 22a를 참조하면, 전자 장치는, 제 1 후보 동영상과 연관된 이미지를 표시할 수 있다. 만약, 제 1 후보 동영상과 연관된 이미지가 표시되는 도중에, 선택을 위한 버튼이 선택되는 경우에는 제 1 후보 동영상이 음성 합성 대상으로 선택될 수 있다. 전자 장치는, 후보 동영상 변경을 위한 사용자 입력 (예를 들어, 상측 방향의 스와이프 제스처)의 검출에 기반하여, 제 2 후보 동영상과 연관된 이미지를 표 시할 수 있다. 만약, 제 2 후보 동영상과 연관된 이미지가 표시되는 도중에, 선택을 위한 버튼이 선택되는 경우에는 제 2 후보 동영상이 음성 합성 대상으로 선택될 수 있다. 본 예시에서는, 제 2 후보 동영상 과 연관된 이미지가 표시되는 도중에, 선택을 위한 버튼이 선택되는 것을 상정하도록 한다. 제 2 후보 동영상과 연관된 이미지가 표시되는 도중에, 선택을 위한 버튼이 선택되는 것에 기반하 여, 전자 장치는, 도 22b에서와 같이, 제 2 동영상의 제 1 이미지(2221a)를 표시할 수 있다. 전자 장치 는, 추가적으로 재생 시점을 나타내는 프로그레스 바(2222a) 및 녹음을 개시하기 위한 버튼도 표시 할 수 있다. 만약, 버튼이 선택되는 경우, 전자 장치는, 제 2 동영상에 포함된 이미지들 (2221a,2221b,2221c)을 순차적으로 표시, 즉 동영상을 재생할 수 있다. 이에 따라, 프로그레스 바(2222b) 또한 재생 시점이 변경되는 것과 같이 표시가 변경될 수 있다. 전자 장치는, 동영상을 재생하는 동안, 녹음의 중단을 위한 버튼을 표시할 수도 있으며, 버튼이 중단되는 경우에는 녹음을 중단할 수 있다. 녹음 을 개시하기 위한 버튼의 선택에 따라서, 전자 장치는 마이크를 활성화하고, 마이크를 통하여 합성 대상의 음성 데이터를 획득할 수 있다. 전자 장치는, 동영상 재생이 완료되거나, 또는 녹음의 중단을 위 한 버튼의 선택에 기반하여, 동영상의 마지막 이미지(2221c)를 표시할 수 있다. 프로그레스 바(2222c) 또한 동영상의 재생 시점의 마지막 부분을 표시하도록 그 표시가 변경될 수 있다. 전자 장치는, 다시 녹 음을 위한 버튼 및 재생을 위한 버튼을 표시할 수도 있다. 다시 녹음을 위한 버튼이 선택되 면, 전자 장치는 녹음을 다시 시작할 수 있으며, 마이크를 통하여 합성 대상의 음성 데이터를 다시 획득할 수도 있다. 재생을 위한 버튼이 선택되면, 전자 장치는, 녹음된 음성을 재생할 수도 있다. 다양한 실시예에 따라서, 전자 장치는, 상술한 바와 같이 자동으로, 또는 사용자의 선택에 따라, 복수 개 의 입 모양 후보들 중 하나를 선택하여 동영상에 합성할 수 있다. 복수 개의 입 모양 후보들 중 어느 하나에 대한 선택에 대하여서는, 상술하였으므로 여기에서의 더 이상의 상세한 설명은 생략하도록 한다. 전자 장치 는, 해당 과정이 수행되는 동안에는, 예를 들어 도 22c에서와 같은 프로세싱 중임을 나타내는 화면 을 표시할 수도 있으며, 이는 광고와 같은 영상으로 대체될 수도 있다. 전자 장치는, 입 모양 합성이 완 료된 경우, 동영상 재생을 위한 이미지를 표시할 수 있다. 동영상 재생을 위한 이미지가 선택되면, 전자 장치는 합성된 동영상을 획득한 음성 데이터에 대응하는 음성과 함께 재생할 수도 있다. 한편, 지우기 버튼이 선택되면, 전자 장치는, 해당 동영상을 삭제할 수 있다. 한편, 업 로드 버튼 이 선택되면, 전자 장치는, 해당 동영상을 업 로드할 수 있다. 한편, 업 로드된 동영상을 관리하는 서버는, 사용자 별로 업 로드된 동영상을 관리할 수도 있다. 예를 들어, 클라이언트 장치로부터, 특정 사용자 에 의하여 업로드된 다른 동영상이 요청되는 경우에는, 특정 사용자가 업 로드한 다른 동영상을 제공할 수도 있 다. 예를 들어, 서버는, 특정 사용자가 업 로드한 동영상과 함께, 해당 사용자가 업 로드한 동영상의 총 개수 까지 함께 표시할 수 있는 데이터를 클라이언트 장치로 제공할 수 있다. 클라이언트 장치는, 특정 사용자와 연 관된 화면이 표시되는 중, 사용자의 입력(예를 들어, 스와이프 입력)이 검출되면, 이에 대응하여 다른 동영상의 요청을 서버로 송신할 수 있다. 서버는, 해당 요청에 대응하여, 특정 사용자가 업 로드한 다른 동영상을 클라 이언트 장치로 제공할 수 있다. 한편, 전자 장치는, 동영상의 이미지를 표시하면서, 동영상의 제목 을 입력할 수 있는 SIP을 더 제공할 수도 있다. SIP을 통한 입력에 기반하여, 전자 장치는, 해당 동영상에 대한 명칭을 저장 및/또는 관리할 수 있다. 본 문서에 개시된 다양한 실시예들에 따른 전자 장치는 다양한 형태의 장치가 될 수 있다. 전자 장치는, 예를 들면, 휴대용 통신 장치(예: 스마트폰), 컴퓨터 장치, 휴대용 멀티미디어 장치, 휴대용 의료 기기, 카메라, 웨어러블 장치, 또는 가전 장치를 포함할 수 있다. 본 문서의 실시예에 따른 전자 장치는 전술한 기기들에 한정되 지 않는다. 본 문서의 다양한 실시예들 및 이에 사용된 용어들은 본 문서에 기재된 기술적 특징들을 특정한 실시예들로 한 정하려는 것이 아니며, 해당 실시예의 다양한 변경, 균등물, 또는 대체물을 포함하는 것으로 이해되어야 한다. 도면의 설명과 관련하여, 유사한 또는 관련된 구성요소에 대해서는 유사한 참조 부호가 사용될 수 있다. 아이템 에 대응하는 명사의 단수 형은 관련된 문맥상 명백하게 다르게 지시하지 않는 한, 상기 아이템 한 개 또는 복수 개를 포함할 수 있다. 본 문서에서, \"A 또는 B\", \"A 및 B 중 적어도 하나\", \"A 또는 B 중 적어도 하나\", \"A, B 또는 C\", \"A, B 및 C 중 적어도 하나\", 및 \"A, B, 또는 C 중 적어도 하나\"와 같은 문구들 각각은 그 문구들 중 해당하는 문구에 함께 나열된 항목들 중 어느 하나, 또는 그들의 모든 가능한 조합을 포함할 수 있다. \"제 1\", \"제 2\", 또는 \"첫째\" 또는 \"둘째\"와 같은 용어들은 단순히 해당 구성요소를 다른 해당 구성요소와 구분하기 위 해 사용될 수 있으며, 해당 구성요소들을 다른 측면(예: 중요성 또는 순서)에서 한정하지 않는다. 어떤(예: 제 1) 구성요소가 다른(예: 제 2) 구성요소에, \"기능적으로\" 또는 \"통신적으로\"라는 용어와 함께 또는 이런 용어 없이, \"커플드\" 또는 \"커넥티드\"라고 언급된 경우, 그것은 상기 어떤 구성요소가 상기 다른 구성요소에 직접적 으로(예: 유선으로), 무선으로, 또는 제 3 구성요소를 통하여 연결될 수 있다는 것을 의미한다. 본 문서의 다양한 실시예들에서 사용된 용어 \"모듈\"은 하드웨어, 소프트웨어 또는 펌웨어로 구현된 유닛을 포함 할 수 있으며, 예를 들면, 로직, 논리 블록, 부품, 또는 회로와 같은 용어와 상호 호환적으로 사용될 수 있다. 모듈은, 일체로 구성된 부품 또는 하나 또는 그 이상의 기능을 수행하는, 상기 부품의 최소 단위 또는 그 일부 가 될 수 있다. 예를 들면, 일실시예에 따르면, 모듈은 ASIC(application-specific integrated circuit)의 형 태로 구현될 수 있다. 본 문서의 다양한 실시예들은 기기(machine)(예: 전자 장치) 의해 읽을 수 있는 저장 매체(storage medium)(예: 내장 메모리 또는 외장 메모리)에 저장된 하나 이상의 명령어들을 포함하는 소프트웨어 (예: 프로그램)로서 구현될 수 있다. 예를 들면, 기기(예: 전자 장치)의 프로세서(예: 프로세서 )는, 저장 매체로부터 저장된 하나 이상의 명령어들 중 적어도 하나의 명령을 호출하고, 그것을 실행할 수 있다. 이것은 기기가 상기 호출된 적어도 하나의 명령어에 따라 적어도 하나의 기능을 수행하도록 운영되는 것 을 가능하게 한다. 상기 하나 이상의 명령어들은 컴파일러에 의해 생성된 코드 또는 인터프리터에 의해 실행될 수 있는 코드를 포함할 수 있다. 기기로 읽을 수 있는 저장 매체는, 비일시적(non-transitory) 저장 매체의 형 태로 제공될 수 있다. 여기서, ‘비일시적’은 저장 매체가 실재(tangible)하는 장치이고, 신호(signal)(예: 전 자기파)를 포함하지 않는다는 것을 의미할 뿐이며, 이 용어는 데이터가 저장 매체에 반영구적으로 저장되는 경 우와 임시적으로 저장되는 경우를 구분하지 않는다. 일실시예에 따르면, 본 문서에 개시된 다양한 실시예들에 따른 방법은 컴퓨터 프로그램 제품(computer program product)에 포함되어 제공될 수 있다. 컴퓨터 프로그램 제품은 상품으로서 판매자 및 구매자 간에 거래될 수 있 다. 컴퓨터 프로그램 제품은 기기로 읽을 수 있는 저장 매체(예: compact disc read only memory(CD-ROM))의 형태로 배포되거나, 또는 어플리케이션 스토어(예: 플레이 스토어TM)를 통해 또는 두 개의 사용자 장치들(예: 스마트 폰들) 간에 직접, 온라인으로 배포(예: 다운로드 또는 업로드)될 수 있다. 온라인 배포의 경우에, 컴퓨 터 프로그램 제품의 적어도 일부는 제조사의 서버, 어플리케이션 스토어의 서버, 또는 중계 서버의 메모리와 같 은 기기로 읽을 수 있는 저장 매체에 적어도 일시 저장되거나, 임시적으로 생성될 수 있다. 다양한 실시예들에 따르면, 상기 기술한 구성요소들의 각각의 구성요소(예: 모듈 또는 프로그램)는 단수 또는 복수의 개체를 포함할 수 있으며, 복수의 개체 중 일부는 다른 구성요소에 분리 배치될 수도 있다. 다양한 실시 예들에 따르면, 전술한 해당 구성요소들 중 하나 이상의 구성요소들 또는 동작들이 생략되거나, 또는 하나 이상 의 다른 구성요소들 또는 동작들이 추가될 수 있다. 대체적으로 또는 추가적으로, 복수의 구성요소들(예: 모듈 또는 프로그램)은 하나의 구성요소로 통합될 수 있다. 이런 경우, 통합된 구성요소는 상기 복수의 구성요소들 각각의 구성요소의 하나 이상의 기능들을 상기 통합 이전에 상기 복수의 구성요소들 중 해당 구성요소에 의해 수행되는 것과 동일 또는 유사하게 수행할 수 있다. 다양한 실시예들에 따르면, 모듈, 프로그램 또는 다른 구성 요소에 의해 수행되는 동작들은 순차적으로, 병렬적으로, 반복적으로, 또는 휴리스틱하게 실행되거나, 상기 동 작들 중 하나 이상이 다른 순서로 실행되거나, 생략되거나, 또는 하나 이상의 다른 동작들이 추가될 수 있다.도면 도면1 도면2 도면3 도면4 도면5 도면6 도면7 도면8 도면9 도면10 도면11a 도면11b 도면11c 도면11d 도면11e 도면11f 도면11g 도면12a 도면12b 도면13 도면14 도면15 도면16 도면17a 도면17b 도면18a 도면18b 도면18c 도면19 도면20 도면21 도면22a 도면22b 도면22c"}
{"patent_id": "10-2021-0115930", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 다양한 실시예에 따른 전자 장치의 블록도를 도시한다. 도 2는 다양한 실시예에 따른 전자 장치의 동작 방법을 설명하기 위한 흐름도를 도시한다. 도 3은 다양한 실시예에 따른 생성된 입 모양을 포함하는 동영상의 생성 과정을 설명하기 위한 도면이다. 도 4는 다양한 실시예에 따른 전자 장치의 동작 방법을 설명하기 위한 흐름도를 도시한다. 도 5는 다양한 실시예에 따른 복수 개의 입 모양 후보들 중 하나가 선택되는 과정을 설명하기 위한 도면이다. 도 6은 다양한 실시예에 따른 전자 장치의 동작 방법을 설명하기 위한 흐름도를 도시한다.도 7은 다양한 실시예에 따른 복수 개의 입 모양 후보들을 생성하는 과정을 설명하기 위한 도면이다. 도 8은 다양한 실시예에 따른 전자 장치의 동작 방법을 설명하기 위한 흐름도를 도시한다. 도 9는 다양한 실시예에 따른 복수 개의 입 모양 후보들을 생성하는 과정을 설명하기 위한 도면이다. 도 10은 다양한 실시예에 따른 전자 장치의 동작 방법을 설명하기 위한 흐름도를 도시한다. 도 11a 내지 11g는 다양한 실시예에 따른 복수 개의 입 모양 후보들을 생성하는 과정을 설명하기 위한 도면이다. 도 12a는 다양한 실시예에 따른 전자 장치의 동작 방법을 설명하기 위한 흐름도를 도시한다. 도 12b는 다양한 실시예에 따른 평가 모델을 설명하기 위한 도면이다. 도 13은 다양한 실시예에 따른 전자 장치의 동작 방법을 설명하기 위한 흐름도를 도시한다. 도 14는 다양한 실시예에 따른 하나의 이미지에 대한 복수 개의 super-resolution 모델들의 적용을 설명하기 위 한 도면이다. 도 15는 다양한 실시예에 따른 전자 장치의 동작 방법을 설명하기 위한 흐름도를 도시한다. 도 16은 다양한 실시예에 따른 고해상도 이미지의 일부 영역을 원본 이미지에 합성하는 과정을 설명하기 위한 도면이다. 도 17a는 다양한 실시예에 따른 전자 장치의 동작 방법을 설명하기 위한 도면이다. 도 17b는 다양한 실시예에 따른 전자 장치의 동작 방법을 설명하기 위한 도면이다. 도 18a는 다양한 실시예에 따른 전자 장치의 동작 방법을 설명하기 위한 흐름도를 도시한다. 도 18b는 다양한 실시예에 따른 영상 통화를 수행하는 전자 장치의 동작 방법을 설명하기 위한 도면이다. 도 18c는 다양한 실시예에 따른 전자 장치의 동작 방법을 설명하기 위한 흐름도를 도시한다. 도 19는 다양한 실시예에 따른 전자 장치의 동작 방법을 설명하기 위한 흐름도를 도시한다. 도 20은 다양한 실시예에 따른 전자 장치의 동작 방법을 설명하기 위한 흐름도를 도시한다. 도 21은 다양한 실시예에 따른 전자 장치의 동작 방법을 설명하기 위한 도면이다. 도 22a 내지 22c는 다양한 실시예에 따른 전자 장치의 화면을 도시한다."}
