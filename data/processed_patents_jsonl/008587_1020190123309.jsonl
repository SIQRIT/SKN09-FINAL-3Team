{"patent_id": "10-2019-0123309", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2021-0040702", "출원번호": "10-2019-0123309", "발명의 명칭": "모자이크 생성 장치 및 방법", "출원인": "삼성전자주식회사", "발명자": "아그라왈 비벡"}}
{"patent_id": "10-2019-0123309", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "모자이크 생성 장치에 있어서, 영상을 출력하는 디스플레이;하나 이상의 인스트럭션을 저장하는 메모리; 및상기 메모리에 저장된 상기 하나 이상의 인스트럭션을 실행하는 프로세서를 포함하고,상기 프로세서는 상기 하나 이상의 인스트럭션을 실행함으로써, 베이스 이미지에 포함된 복수의 서브 베이스 영역 중 하나로부터 제1 특징 값을 추출하고, 복수의 소스 이미지 중 선택된 하나의 소스 이미지로부터 제2 특징값을 추출하고, 상기 제1 특징 값과 상기 제2 특징 값을 이용하여 상기 하나의 서브 베이스 영역에 대응하는 서브 모자이크를 생성하는, 모자이크 생성 장치."}
{"patent_id": "10-2019-0123309", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1 항에 있어서, 상기 프로세서는 상기 복수의 서브 베이스 영역 모두에 대해, 대응하는 서브 모자이크를 생성하고 이를 이용하여 상기 베이스 이미지에 대응하는 모자이크를 생성하는, 모자이크 생성 장치."}
{"patent_id": "10-2019-0123309", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1 항에 있어서, 상기 하나의 소스 이미지는 복수의 서브 베이스 영역에 대하여 중복하여 선택될 수 있는 모자이크 생성 장치."}
{"patent_id": "10-2019-0123309", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1 항에 있어서, 상기 프로세서는 하위 레벨 및 상위 레벨을 포함하는 AI 모델을 이용하여, 상기 하위 레벨로부터 상기 제1 특징 값을 추출하고, 상기 상위 레벨로부터 상기 제2 특징 값을 추출하는, 모자이크 생성 장치."}
{"patent_id": "10-2019-0123309", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4 항에 있어서, 상기 서브 모자이크는 상기 서브 모자이크와 상기 서브 베이스 영역의 상기 하위 레벨에서의특징 값 차이와, 상기 서브 모자이크와 상기 베이스 영역의 상기 상위 레벨에서의 특징 값 차이의 합이 최소가되는, 모자이크 생성 장치."}
{"patent_id": "10-2019-0123309", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제4 항에 있어서, 상기 제1 특징 값은 상기 서브 베이스 이미지의 화풍, 회화 양식, 텍스쳐, 분위기, 콘트라스트, 광택, 명도, 색도, 채도에 대한 정보 중 하나 이상을 포함하는, 모자이크 생성 장치."}
{"patent_id": "10-2019-0123309", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제4 항에 있어서, 상기 제2 특징 값은 상기 소스 이미지의 모양, 형태 중 하나 이상을 포함하는 콘텐츠 정보인,모자이크 생성 장치."}
{"patent_id": "10-2019-0123309", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제2 항에 있어서, 상기 장치는 유저 인터페이스; 및통신부를 더 포함하고,상기 유저 인터페이스는 사용자로부터 상기 하나의 서브 베이스 영역 및 상기 하나의 소스 이미지를 선택 받고,상기 프로세서가 상기 베이스 이미지에 대응하는 모자이크를 복수 개 생성하는 것에 기반하여 상기 사용자로부터 상기 복수 개의 모자이크 중 하나를 선택 받고, 공개특허 10-2021-0040702-3-상기 통신부는 상기 선택된 모자이크를 외부 디스플레이로 전송하는, 모자이크 생성 장치."}
{"patent_id": "10-2019-0123309", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "모자이크 생성 방법에 있어서, 복수의 서브 베이스 영역들을 포함하는 베이스 이미지로부터 선택된 하나의 서브 베이스 영역으로부터 제1 특징값을 추출하는 단계;복수의 소스 이미지들 중 랜덤으로 선택된 하나의 소스 이미지로부터 제2 특징 값을 추출하는 단계; 및상기 제1 특징 값과 상기 제2 특징 값을 이용하여 상기 선택된 하나의 서브 베이스 영역에 대응하는 서브 모자이크를 생성하는 단계를 포함하는 모자이크 생성 방법."}
{"patent_id": "10-2019-0123309", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9 항에 있어서, 상기 복수의 서브 베이스 영역들 각각에 대해 생성된 서브 모자이크들을 이용하여 상기 베이스 이미지에 대응하는 모자이크를 생성하는 단계를 더 포함하는 모자이크 생성 방법."}
{"patent_id": "10-2019-0123309", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제9 항에 있어서, 상기 하나의 소스 이미지는 복수의 서브 베이스 영역에 대하여 중복하여 선택될 수 있는 모자이크 생성 방법."}
{"patent_id": "10-2019-0123309", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제9 항에 있어서, 상기 모자이크를 생성하는 단계는 하위 레벨 및 상위 레벨을 포함하는 AI 모델을 이용하여,상기 하위 레벨로부터 상기 제1 특징 값을 추출하고, 상기 상위 레벨로부터 상기 제2 특징 값을 추출하는 단계를 포함하는, 모자이크 생성 방법."}
{"patent_id": "10-2019-0123309", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제12 항에 있어서, 상기 서브 모자이크를 생성하는 단계는 상기 서브 모자이크와 상기 서브 베이스 영역의 상기하위 레벨에서의 특징 값 차이와, 상기 서브 모자이크와 상기 베이스 영역의 상기 상위 레벨에서의 특징 값 차이의 합이 최소가 되도록 상기 서브 모자이크를 생성하는 단계를 포함하는, 모자이크 생성 방법."}
{"patent_id": "10-2019-0123309", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제12 항에 있어서, 상기 제1 특징 값은 상기 서브 베이스 이미지의 화풍, 회화 양식, 텍스쳐, 분위기, 콘트라스트, 광택, 명도, 색도, 채도에 대한 정보 중 하나 이상을 포함하는, 모자이크 생성 방법."}
{"patent_id": "10-2019-0123309", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제13 항에 있어서, 상기 제2 특징 값은 상기 소스 이미지의 모양, 형태 중 하나 이상을 포함하는 콘텐츠정보인, 모자이크 생성 방법."}
{"patent_id": "10-2019-0123309", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "복수의 서브 베이스 영역들을 포함하는 베이스 이미지로부터 선택된 하나의 서브 베이스 영역으로부터 제1 특징값을 추출하는 단계;복수의 소스 이미지들 중 랜덤으로 선택된 하나의 소스 이미지로부터 제2 특징 값을 추출하는 단계; 및상기 제1 특징 값과 상기 제2 특징 값을 이용하여 상기 선택된 하나의 서브 베이스 영역에 대응하는 서브 모자이크를 생성하는 단계를 포함하는 모자이크 생성 방법을 구현하기 위한 프로그램이 기록된 컴퓨터로 판독 가능한 기록 매체."}
{"patent_id": "10-2019-0123309", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 개시는 딥러닝 등의 기계 학습 알고리즘을 활용하여 인간 두뇌의 인지, 판단 등의 기능을 모사하는 인공지능 (AI) 시스템 및 그 응용에 관련된 것이다. 일 실시 예에 따른 모자이크 생성 장치는 영상을 출력하는 디스플레이, 하나 이상의 인스트럭션을 저장하는 메모리 및 메모리에 저장된 하나 이상의 인스트럭션을 실행하는 프로세서를 포함하고, 프로세서는 하나 이상의 인스트럭션을 실행함으로써, 베이스 이미지에 포함된 복수의 서브 베이스 영역 중 하나로부터 제1 특징 값을 추출하고, 복수의 소스 이미지 중 선택된 하나의 소스 이미지로부터 제2 특징 값을 추출하고, 제1 특징 값과 제2 특징 값을 이용하여 하나의 서브 베이스 영역에 대응하는 서브 모자 이크를 생성할 수 있다."}
{"patent_id": "10-2019-0123309", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "개시된 다양한 실시 예들은 모자이크 생성 장치 및 그 동작 방법에 관한 것으로서, 보다 상세하게는 랜덤으로 소스 이미지를 선택하고 베이스 이미지의 특성을 기반으로 소스 이미지를 강화하여 모자이크를 생성하는 방법 및 장치에 관한 것이다."}
{"patent_id": "10-2019-0123309", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "모자이크는 여러 조각들을 붙여서 무늬나 회화를 만드는 기법이다. 모자이크를 생성하기 위해서는 모자이크를 생성하고자 하는 사진이나 그림을 작은 영역들로 나누고, 각 영역들을 다른 사진이나 그림 등으로 대체하는 방 법 등이 이용될 수 있다. 인공지능(Artificial Intelligence, 이하, AI) 시스템은 기계가 스스로 학습(training)하고 판단하며 목적하는 결과를 도출하거나 목적하는 동작을 수행하는 시스템이다."}
{"patent_id": "10-2019-0123309", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "다양한 실시 예들은 뉴럴 네트워크를 이용하여 랜덤으로 선택된 소스 이미지와 베이스 이미지로부터 다양한 모 자이크를 생성하는 방법 및 장치를 제공하기 위한 것이다."}
{"patent_id": "10-2019-0123309", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "일 실시 예에 따른 모자이크 생성 장치는 영상을 출력하는 디스플레이, 하나 이상의 인스트럭션을 저장하는 메 모리 및 상기 메모리에 저장된 상기 하나 이상의 인스트럭션을 실행하는 프로세서를 포함하고, 상기 프로세서는 상기 하나 이상의 인스트럭션을 실행함으로써, 베이스 이미지에 포함된 복수의 서브 베이스 영역 중 하나로부터 제1 특징 값을 추출하고, 복수의 소스 이미지 중 선택된 하나의 소스 이미지로부터 제2 특징 값을 추출하고, 상 기 제1 특징 값과 상기 제2 특징 값을 이용하여 상기 하나의 서브 베이스 영역에 대응하는 서브 모자이크를 생 성할 수 있다. 실시 예에서, 상기 프로세서는 기 복수의 서브 베이스 영역 모두에 대해, 대응하는 서브 모자이크를 생성하고 이를 이용하여 상기 베이스 이미지에 대응하는 모자이크를 생성할 수 있다. 실시 예에서, 상기 하나의 서브 베이스 영역은 상기 복수의 서브 베이스 영역 중 랜덤으로 선택될 수 있다. 실시 예에서, 상기 하나의 소스 이미지는 상기 복수의 소스 이미지 중 랜덤으로 선택될 수 있다. 실시 예에서, 상기 하나의 소스 이미지는 복수의 서브 베이스 영역에 대하여 중복하여 선택될 수 있다. 실시 예에서, 상기 프로세서는 하위 레벨 및 상위 레벨을 포함하는 AI 모델을 이용하여, 상기 하위 레벨로부터 상기 제1 특징 값을 추출하고, 상기 상위 레벨로부터 상기 제2 특징 값을 추출할 수 있다. 실시 예에서, 상기 서브 모자이크는 상기 서브 모자이크와 상기 서브 베이스 영역의 상기 하위 레벨에서의 특징 값 차이와, 상기 서브 모자이크와 상기 베이스 영역의 상기 상위 레벨에서의 특징 값 차이의 합이 최소가 될 수 있다. 실시 예에서, 상기 제1 특징 값은 상기 서브 베이스 이미지의 화풍, 회화 양식, 텍스쳐, 분위기, 콘트라스트, 광택, 명도, 색도, 채도에 대한 정보 중 하나 이상을 포함할 수 있다. 실시 예에서, 상기 제2 특징 값은 상기 소스 이미지의 모양, 형태 중 하나 이상을 포함하는 콘텐츠 정보일 수 있다. 실시 예에서, 상기 장치는 유저 인터페이스 및 통신부를 더 포함하고, 상기 유저 인터페이스는 사용자로부터 상 기 하나의 서브 베이스 영역 및 상기 하나의 소스 이미지를 선택 받고, 상기 프로세서가 상기 베이스 이미지에 대응하는 모자이크를 복수 개 생성하는 것에 기반하여 상기 사용자로부터 상기 복수 개의 모자이크 중 하나를 선택 받고, 상기 통신부는 상기 선택된 모자이크를 외부 디스플레이로 전송할 수 있다. 일 실시 예에 따른 모자이크 생성 방법은 복수의 서브 베이스 영역들을 포함하는 베이스 이미지로부터 선택된 하나의 서브 베이스 영역으로부터 제1 특징 값을 추출하는 단계, 복수의 소스 이미지들 중 랜덤으로 선택된 하 나의 소스 이미지로부터 제2 특징 값을 추출하는 단계 및 상기 제1 특징 값과 상기 제2 특징 값을 이용하여 상 기 선택된 하나의 서브 베이스 영역에 대응하는 서브 모자이크를 생성하는 단계를 포함할 수 있다. 일 실시 예에 따른 컴퓨터로 판독 가능한 기록 매체는 복수의 서브 베이스 영역들을 포함하는 베이스 이미지로 부터 선택된 하나의 서브 베이스 영역으로부터 제1 특징 값을 추출하는 단계, 복수의 소스 이미지들 중 랜덤으 로 선택된 하나의 소스 이미지로부터 제2 특징 값을 추출하는 단계 및 상기 제1 특징 값과 상기 제2 특징 값을 이용하여 상기 선택된 하나의 서브 베이스 영역에 대응하는 서브 모자이크를 생성하는 단계를 포함하는 모자이 크 생성 방법을 구현하기 위한 프로그램이 기록된 컴퓨터로 판독 가능한 기록 매체일 수 있다."}
{"patent_id": "10-2019-0123309", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "일 실시 예에 따른 모자이크 생성 장치 및 방법은, 소스 이미지를 중복하여 선택하여 이용할 수 있어 동일한 소 스 이미지로부터 복수의 모자이크를 생성할 수 있다. 일 실시 예에 따른 모자이크 생성 장치 및 방법은, 베이스 이미지를 기반으로 소스 이미지를 변형하여 이용함으 로써 임의의 소스 이미지로도 다양한 모자이크를 생성할 수 있다. 일 실시 예에 따른 모자이크 생성 장치 및 방법은, 베이스 이미지의 특징과 소스 이미지의 특징으로 소스 이미 지를 변형하여 이용함으로써 고 퀄러티의 모자이크를 생성할 수 있다."}
{"patent_id": "10-2019-0123309", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "아래에서는 첨부한 도면을 참조하여 본 개시가 속하는 기술 분야에서 통상의 지식을 가진 자가 용이하게 실시할 수 있도록 본 개시의 실시 예를 상세히 설명한다. 그러나 본 개시는 여러 가지 상이한 형태로 구현될 수 있으며 여기에서 설명하는 실시 예에 한정되지 않는다. 본 개시에서 사용되는 용어는, 본 개시에서 언급되는 기능을 고려하여 현재 사용되는 일반적인 용어로 기재되었 으나, 이는 당 분야에 종사하는 기술자의 의도 또는 판례, 새로운 기술의 출현 등에 따라 다양한 다른 용어를 의미할 수 있다. 따라서 본 개시에서 사용되는 용어는 용어의 명칭만으로 해석되어서는 안되며, 용어가 가지는 의미와 본 개시의 전반에 걸친 내용을 토대로 해석되어야 한다. 또한, 본 개시에서 사용된 용어는 단지 특정한 실시 예를 설명하기 위해 사용된 것이며, 본 개시를 한정하려는 의도로 사용되는 것이 아니다. 명세서 전체에서, 어떤 부분이 다른 부분과 \"연결\"되어 있다고 할 때, 이는 \"직접적으로 연결\"되어 있는 경우뿐 아니라, 그 중간에 다른 소자를 사이에 두고 \"전기적으로 연결\"되어 있는 경우도 포함한다. 본 명세서, 특히, 특허 청구 범위에서 사용된 “상기” 및 이와 유사한 지시어는 단수 및 복수 모두를 지시하는 것일 수 있다. 또한, 본 개시에 따른 방법을 설명하는 단계들의 순서를 명백하게 지정하는 기재가 없다면, 기 재된 단계들은 적당한 순서로 행해질 수 있다. 기재된 단계들의 기재 순서에 따라 본 개시가 한정되는 것은 아 니다. 본 명세서에서 다양한 곳에 등장하는 \"일부 실시 예에서\" 또는 \"일 실시 예에서\" 등의 어구는 반드시 모두 동일 한 실시 예를 가리키는 것은 아니다. 본 개시의 일부 실시 예는 기능적인 블록 구성들 및 다양한 처리 단계들로 나타내어질 수 있다. 이러한 기능 블록들의 일부 또는 전부는, 특정 기능들을 실행하는 다양한 개수의 하드웨어 및/또는 소프트웨어 구성들로 구 현될 수 있다. 예를 들어, 본 개시의 기능 블록들은 하나 이상의 마이크로프로세서들에 의해 구현되거나, 소정 의 기능을 위한 회로 구성들에 의해 구현될 수 있다. 또한, 예를 들어, 본 개시의 기능 블록들은 다양한 프로 그래밍 또는 스크립팅 언어로 구현될 수 있다. 기능 블록들은 하나 이상의 프로세서들에서 실행되는 알고리즘으 로 구현될 수 있다. 또한, 본 개시는 전자적인 환경 설정, 신호 처리, 및/또는 데이터 처리 등을 위하여 종래 기술을 채용할 수 있다. “매커니즘”, “요소”, “수단” 및 “구성”등과 같은 용어는 넓게 사용될 수 있으 며, 기계적이고 물리적인 구성들로서 한정되는 것은 아니다. 또한, 도면에 도시된 구성 요소들 간의 연결 선 또는 연결 부재들은 기능적인 연결 및/또는 물리적 또는 회로적 연결들을 예시적으로 나타낸 것일 뿐이다. 실제 장치에서는 대체 가능하거나 추가된 다양한 기능적인 연결, 물 리적인 연결, 또는 회로 연결들에 의해 구성 요소들 간의 연결이 나타내어질 수 있다. 또한, 명세서에 기재된 \"...부\", \"모듈\" 등의 용어는 적어도 하나의 기능이나 동작을 처리하는 단위를 의미하며, 이는 하드웨어 또는 소프트웨어로 구현되거나 하드웨어와 소프트웨어의 결합으로 구현될 수 있다. 또한, 명세서에서 “사용자”라는 용어는 영상 생성 장치를 이용하여 영상 생성 장치의 기능 또는 동작을 제어 하는 사람을 의미하며, 시청자, 관리자 또는 설치 기사를 포함할 수 있다. 이하 첨부된 도면을 참고하여 본 개시를 상세히 설명하기로 한다. 도 1은 일 실시 예에 따라, 모자이크를 생성하는 기술을 설명하기 위한 도면이다. 도 1을 참조하면, 실시 예에 따른 모자이크는 베이스 이미지와 소스 이미지를 이용하여 생성될 수 있다. 베이스 이미지는 모자이크를 생성하는데 있어서 바탕이 되는 이미지로, 모자이크로 변환할 대상이 되는 이미지일 수 있다. 베이스 이미지는 그림이나 사진 등의 정지 영상일 수 있다. 베이스 이미지 는 디지털 카메라나 스캐너로 디지털화된 사진이나 그림 등일 수 있고, 또는 그림을 그리는 프로그램을 이 용해 새롭게 창조된 이미지일 수 있다. 사용자는, 실시 예에 따라 모자이크를 생성하는 전자 장치(미도시)를 이 용하여 영상을 직접 촬영하거나, 포토 샵 등을 이용하여 그림을 그리는 방법 등을 이용하여 새로 이미지를 생성 하고 이를 베이스 이미지로 이용할 수 있다. 또는 베이스 이미지는 외부 장치나 외부 서버 등으로부 터 수신하거나 다운로드하여 전자 장치에 저장된 이미지일 수 있다. 베이스 이미지는 복수의 서브 베이스 이미지로 나뉠 수 있다. 서브 베이스 이미지는 타일로도 불릴 수 있 다. 서브 베이스 이미지, 즉, 타일 단위로 작은 서브 모자이크가 생성되어 전체 모자이크가 생성될 수 있 다. 도 1에서 베이스 이미지는 복수 개, 예컨대 N개의 타일로 분할될 수 있다. 타일은 소정 개수의 픽셀들을 포함하는 영역일 수 있다. 타일의 수나 사이즈는 미리 설정되어 있을 수도 있고, 사용자가 타일의 수나 사이즈 를 변경할 수도 있다. 사용자는 타일의 수나 타일의 사이즈를 조절하여 모자이크가 더 촘촘하게 생성되도록 하 거나 또는 반대로 더 굵직굵직한 타일들이 모자이크에 포함되도록 설정할 수 있다. 타일, 즉, 서브 베이스 이미지 단위로 서브 모자이크가 생성될 수 있다. 복수개의 서브 모자이크가 모여, 베이 스 이미지에 대응하는 모자이크를 형성하게 된다. 서브 베이스 이미지의 수가 많을수록 서브 모자이 크가 더 촘촘해지므로 기본 바탕이 되는 베이스 이미지의 사진 또는 그림이 더 잘 인식되고, 반대로 서브 베이스 이미지 수가 적어질수록 베이스 이미지의 사진 또는 그림을 인식하는 것이 어려워진다. 소스 이미지는 베이스 이미지에 포함된 각각의 서브 베이스 이미지에 위치할 서브 모자이크를 생성하 는 데 사용될 수 있다. 소스 이미지는 사진 또는 그림 등의 이미지일 수 있다. 소스 이미지는 사용자 가 전자 장치를 이용하여 촬영하거나 포토 샵 등을 이용하여 새로 생성한 이미지일 수 있다. 또는 소스 이미지 는 외부 장치로부터 수신하거나 외부 서버 등으로부터 다운로드 받아 전자 장치에 저장되어 있는 이미지일수 있다. 실시 예에서, 모자이크를 생성하는 전자 장치는 인공지능(Artificial Intelligence, AI) 기술을 이용할 수 있다. AI 기술은 기계학습(딥러닝) 및 기계학습을 활용한 요소 기술들로 구성될 수 있다. AI 기술은 신경망, 즉, 뉴럴 네트워크를 통하여 입력 데이터에 대응되는 출력 데이터를 출력하도록 하는 알고리즘의 집합, 알 고리즘의 집합을 실행하는 소프트웨어 및/또는 알고리집의 집합을 실행하는 하드웨어일 수 있다. 실시 예에서, 뉴럴 네트워크는 베이스 이미지와 소스 이미지로부터 모자이크를 생성할 수 있다. 뉴럴 네트워크는 베이스 이미지에 포함된 복수 개의 서브 베이스 이미지 중 임의로 한 개, 예 컨대 도면부호 111을 가진 서브 베이스 이미지를 선택할 수 있다. 설명의 편의를 위해 이 서브 베이스 이미지를 제1 서브 베이스 이미지라 부르기로 한다. 뉴럴 네트워크는 선택된 제1 서브 베이스 이미지로부 터 특징 값을 추출할 수 있다. 뉴럴 네트워크는 복수 개의 소스 이미지 중 하나를 임의로 선택할 수 있다. 실시 예에서, 소스 이미 지는 사용자가 정한 이미지들일 수도 있고, 뉴럴 네트워크가 전자 장치에 저장된 이미지들 중 임의로 선택한 이미지일 수도 있다. 뉴럴 네트워크는 선택된 소스 이미지로부터 특징 값을 추출할 수 있다. 뉴럴 네트워크는 제1 서브 베이스 이미지로부터 추출한 특징 값과 소스 이미지로부터 추출한 특 징 값을 이용하여 제1 서브 베이스 이미지에 위치할 서브 모자이크를 생성할 수 있다. 편의상 제1 서브 베 이스 이미지에 위치할 서브 모자이크를 제1 서브 모자이크라 부르기로 한다. 이후, 뉴럴 네트워크는 베이스 이미지에 포함된 서브 베이스 이미지 중, 제1 서브 베이스 이미지 를 제외하고 나머지 서브 베이스 이미지 중 하나를 임의로 선택할 수 있다. 실시 예에서, 뉴럴 네트워크 는 서브 베이스 이미지를 정해진 순서대로 선택할 수도 있고, 또는 임의의 순서대로 선택할 수도 있다. 예 컨대, 뉴럴 네트워크는 서브 베이스 이미지 중 임의로 도면부호 112를 가진 서브 베이스 이미지를 선택할 수 있다. 설명의 편의를 위해 이 서브 베이스 이미지를 제2 서브 베이스 이미지라 부르기로 한다. 실시 예에서, 뉴럴 네트워크는 복수 개의 소스 이미지 중 또 다시 하나의 소스 이미지를 임의로 선택 할 수 있다. 이때 뉴럴 네트워크가 선택하는 소스 이미지는 이전에 선택된 소스 이미지와 동일할 수 도 있고 그렇지 않을 수도 있다. 뉴럴 네트워크는 제2 서브 베이스 이미지와 선택한 소스 이미지 로부터 각각 특징 값을 추출하고 이를 이용하여 제2 서브 베이스 이미지에 위치할 서브 모자이크, 즉, 제2 서브 모자이크를 생성할 수 있다. 뉴럴 네트워크는 베이스 이미지에 포함된 N개의 서브 베이 스 이미지 각각에 대하여 위 동작을 반복함으로써 베이스 이미지에 포함된 N개의 서브 베이스 이미지 전체 에 대하여 N개의 서브 모자이크를 생성하고, 이들을 합쳐 하나의 모자이크를 생성할 수 있다. 도 2는 실시 예에 따라, 뉴럴 네트워크가 베이스 이미지와 소스 이미지의 특징을 이용하여 모자이크를 생성하는 것을 설명하기 위한 도면이다. 도 2를 참조하면, 뉴럴 네트워크에는 베이스 이미지가 입력될 수 있다. 베이스 이미지는 사용자 가 모자이크로 만들고자 하는 기본 영상이나 그림 등의 이미지일 수 있다. 뉴럴 네트워크는 베이스 이미지에 포함된 복수의 서브 베이스 이미지 중 하나를 정해진 순서대로 선택하거나, 또는 랜덤으로 선택 할 수 있다. 뉴럴 네트워크에는 소스 이미지가 입력될 수 있다. 뉴럴 네트워크는 복수의 이미지들 중 하나를 랜덤으로 선택하여 이를 소스 이미지로 이용할 수 있다. 베이스 이미지와 소스 이미지는 뉴럴 네트워크에 순서대로 하나씩 입력되어 각각 처리될 수 있 다. 또는 베이스 이미지와 소스 이미지는 뉴럴 네트워크에 함께 입력되어 처리될 수도 있다. 실시 예에서, 뉴럴 네트워크는 인공지능(AI) 기술을 구현하기 위한 알고리즘 또는 알고리즘의 집합인 신경 망(Neural Network)일 수 있다. 뉴럴 네트워크는 신경망을 이용하여 AI 기술에 따른 이미지 생성 동작을 수행하여 모자이크를 생성할 수 있다. 신경망은 로우 레벨 레이어(low level layer)부터 하이 레벨 레이어(high level layer)까지 복수 개의 계층들을 포함할 수 있다. 뉴럴 네트워크는 CNN(Convolution Neural Network) 기반의 신경망을 통하여 출력 이미지 를 생성할 수 있다. CNN 기반의 신경망은 복수의 컨볼루션 계층(convolution layer)을 포함할 수 있다. 뉴럴 네트워크는 입력되는 두 이미지 중 하나로부터 콘텐츠 특징을 추출하고 다른 이미지로부터 스타일 특 징을 추출하여, 하나의 이미지의 내용은 유지한 채 스타일이 다른 이미지의 스타일로 변환된 출력 이미지를 생 성할 수 있다. 뉴럴 네트워크는 베이스 이미지에서 하나의 서브 베이스 이미지를 선택하고 선택한 서브 베이스 이미 지로부터 특징을 추출할 수 있다. 실시 예에서, 뉴럴 네트워크는 서브 베이스 이미지로부터 스타일 특징을 추출할 수 있다. 스타일 특징은 이미지가 가진 스타일을 표현한 값으로, 이미지의 고유한 특징이나 회화 양식을 표현하는 화풍일 수 있다. 스타일은 수채화, 유화, 수묵화, 점묘화, 입체화와 같이 그림을 그리는 방식이나 양식을 나타내거나 반 고흐 풍, 모네 풍, 마네 풍, 피카소 풍 등과 같은 특정한 화가의 경향과 특징을 지칭할 수도 있다. 또한 스 타일 특징은 중세 시대, 르네상스 시대, 근대시대, 현대 시대 회화와 같이 시대별로 분류되는 특징이거나, 동양 화, 서양화, 등과 같은 지역별로 분류되는 특징이거나, 인상파, 추상파, 사실주의 등과 같은 회화 양식의 특징 을 포함할 수 있다. 또한, 스타일 특징은 이미지가 갖는 질감, 색감, 분위기, 콘트라스트, 광택 또는 색의 3요 소인 명도(Intensity), 색도(Hue), 채도(Saturation) 등에 대한 정보를 포함할 수 있다. 뉴럴 네트워크는 복수의 이미지 중 하나를 임의로 선택하고, 이를 소스 이미지로 이용할 수 있다. 뉴 럴 네트워크는 소스 이미지로부터 특징을 추출할 수 있다. 실시 예에서, 뉴럴 네트워크는 소스 이미지로부터 콘텐츠 특징을 추출할 수 있다. 콘텐츠 특징은 형태나 모양 등과 같이 이미지에 포함된 콘텐 츠의 정체성(identity)에 대한 정보를 포함할 수 있다. 뉴럴 네트워크는 생성할 출력 이미지의 특징을 획득할 수 있다. 출력 이미지의 특징은 서브 베이스 이미지 를 대체할 서브 모자이크를 생성하기 위해 필요한 특징일 수 있다. 실시 예에서, 뉴럴 네트워크는 스타일 손실(loss)과 콘텐츠 손실의 합이 최소가 되는 특징을 갖는 출력 이 미지를 생성하도록 미리 학습된 모델일 수 있다. 즉, 뉴럴 네트워크는 입력되는 소스 이미지와 서브 베이 스 이미지로부터 특징, 또는 특징 맵을 추출하고, 서브 베이스 이미지의 특징을 기반으로 소스 이미지의 콘텐츠 특징을 변형하여 서브 모자이크를 생성할 수 있다. 이 때 생성되는 서브 모자이크는 서브 베이스 이미지의 스타 일 특징과 소스 이미지의 콘텐츠 특징을 가질 수 있다. 스타일 손실은 스타일 특징과 출력 이미지 특징으로부터 구해질 수 있다. 스타일 손실은 뉴럴 네트워크에 포함된 복수개의 레이어들 중 하나 이상의 레이어로부터 추출되는 특징, 또는 특징 맵에 대해 구해진 매트릭스 를 이용하여 연산될 수 있다. 뉴럴 네트워크는 복수개의 계층들을 포함하며, 복수의 계층들 각각은 서브 베이스 이미지로부터 특징 값을 획득하고 이를 출력 이미지의 특징 값과 비교하여 그 차이를 계산하고, 각 레이어 별 차이 값에 가중치를 부가 하여 합친 값으로 스타일 손실을 구할 수 있다. 뉴럴 네트워크는 스타일 손실을 feed forward로 다시 입력 받을 수 있다. 보다 구체적으로, 뉴럴 네트워크는 서브 베이스 이미지에 대해 소정의 레이어에서 다른 레이어와의 관계를 고려하여 특징 값을 추출할 수 있다. 뉴럴 네트워크는 추출한 특징 값을 이용하여 매트릭스를 구할 수 있 다. 뉴럴 네트워크는 출력할 이미지에 대해서도 동일한 소정 레이어에서, 다른 레이어와의 관계를 고려하 여 특징 값을 추출하고, 추출한 특징 값을 이용하여 매트릭스를 구할 수 있다. 뉴럴 네트워크는 동일한 레 이어 별로, 서브 베이스 이미지에 대해 구한 매트릭스와 출력 이미지에 대해 구한 매트릭스를 이용하여 서브 베 이스 이미지와 출력 이미지의 특징 값의 차이를 구하고, 각 레이어에 대해 가중치를 적용한 값을 구한 후, 이들 을 모두 합쳐 스타일 손실을 구할 수 있다. 다른 실시 예에서, 뉴럴 네트워크는 복수의 레이어 중 소정의 로우 레벨 레이어로부터 추출한 매트릭스만 을 이용하여 서브 베이스 이미지와 출력 이미지의 스타일 손실을 구할 수도 있다. 이는, 일반적으로 레이어가 깊어질수록 픽셀 수준의 정보가 사라지므로, 스타일 정보는 로우 레벨 레이어에서 추출될 수 있기 때문이다. 뉴럴 네트워크는 콘텐츠 특징과 출력 이미지의 특징으로부터 콘텐츠 손실을 구할 수 있다. 콘텐츠 손실은 정보의 추상화가 많이 이루어지는 하이 레벨 레이어의 특징 맵을 이용하여 구해질 수 있다. 이는, 입력 이미지 가 갖는 형태 등의 정체성이 하이 레벨 레이어에서 유지되기 때문이다. 뉴럴 네트워크는 신경망에 포함된 복수개의 계층들 중 소정의 하이 레벨 레이어로부터 추출한, 소스 이미지의 특징 맵과 출력 이미지의 특징 맵 간의 차이를 이용하여 콘텐츠 손실을 구할 수 있다. 뉴럴 네트워크는 콘텐츠 손실을 다시 입력받을 수 있 다. 뉴럴 네트워크는 스타일 손실과 콘텐츠 손실의 합이 최소가 되도록 이 과정을 여러 번 수행하여 출력 이미 지의 픽셀들을 최적화함으로써 원하는 최종 출력 이미지를 구하고 이를 서브 모자이크로 이용할 수 있다. 이 때 생성되는 서브 모자이크는 서브 베이스 이미지의 스타일 특징과 소스 이미지의 콘텐츠 특징 을 함께 가지는 이미지일 수 있다. 뉴럴 네트워크는 모든 서브 베이스 이미지에 대해 위 과정을 수행 하여 모자이크를 생성할 수 있다. 도 3은 실시 예에서 사용할 수 있는 뉴럴 네트워크가 이미지로부터 특징을 추출하는 것을 설명하기 위한 도면이 다. 도 3을 참조하면, 뉴럴 네트워크는 CNN(Convolution Neural Network), DCNN(Deep Convolution Neural Network) 또는 캡스넷(Capsnet) 신경망등과 같은 CNN 기반 신경망일 수 있다. CNN 기반 신경망은 이미지에 포함 되는 정보들끼리의 상관 관계가 지역적(local)인 경우, 특정 지역만을 비추는 필터의 개념을 도입하고 이 필터 내에서의 정보들을 컨볼루션(convolution)하여 새로운 특징 맵을 생성할 수 있다. 도 3의 뉴럴 네트워크는 복수의 심도(depth)를 갖는 DCNN(Deep Convolution Neural Network)일 수 있다. 즉, 뉴럴 네트워크는 연산을 수행하는 내부의 계층(layer)이 복수 개일 수 있다. 연산을 수행하는 신경망 의 심도(depth)가 증가하는 경우, 이는 딥 신경망(DNN)으로 분류될 수 있다. 딥 신경망(DNN) 연산은 컨볼루션 신경망(CNN: Convolution Neural Network) 연산 등을 포함할 수 있다. 컨볼루션 계층(convolution layer) 뒤에는 풀링 계층(pooling layer)이 배치될 수 있다. 컨볼루션 계층은 컨볼 루션 연산에 따라서 생성되는 데이터들의 계층이며, 풀링 계층은 서브 샘플링(subsampling) 또는 풀링이라는 연 산을 통하여 데이터의 숫자 또는 크기를 줄이기 위한 계층이다. 컨볼루션 계층(convolution layer)과 풀링 계층 (pooling layer)을 통과하면서, 입력된 이미지의 특징을 나타내는 데이터들, 예를 들어, 특징 맵(feature map) 이 생성되게 된다. 컨볼루션 계층 및 풀링 계층의 심도(depth)는 가변될 수 있다. 또한, 컨볼루션 계층 및 풀링 계층의 심도에 따 라 다른 특징 데이터들이 추출될 수 있다. 예를 들어, 컨볼루션 계층 및 풀링 계층의 심도가 깊어질수록 입력된 이미지의 특징들을 나타내는 정보들이 더욱 세밀한 형태를 가질 수 있다. 심도 및 형태는 결과의 정확도, 결과 의 신뢰도, 프로세서의 연산 처리 속도 및 용량 등을 고려하여 매우 다양하게 설계될 수 있다. 도 3에서 뉴럴 네트워크는 영상이 입력되면 입력된 영상에 대해 각 계층들로부터 특징 맵을 추출할 수 있 다. 이 때, 계층 필터(filter)의 심도가 바뀌면서 출력되는 특징 맵 또한 달라지게 된다. 도 3의 뉴럴 네트워크 의 각 계층 필터의 심도는 왼쪽에서 오른쪽으로 갈수록 증가한다. 뉴럴 네트워크의 좌측으로 베이스 이미지가 입력되면, 뉴럴 네트워크는 베이스 이미지에 포함된 복수의 타이들 중 하나의 타일, 즉, 하나의 서브 베이스 이미지를 각 레이어에 통과시키면서 서브 베이스 이미지로부터 스타일 특징을 추출할 수 있다. 도 3에서 도면부호 311, 312, 313, 314, 315는 뉴럴 네트워크가 서브 베이스 이미지를 각 각의 레이어에 통과시키면서 추출하는 특징 맵을 도시한다. 뉴럴 네트워크에서 출력되는 특징 맵(311, 312, 313, 314, 315)은 레이어를 통과하면서 서브 베이스 이미지가 가진 전체 레이아웃 정보가 아닌, 서브 베이스 이 미지가 마치 확대되는 것과 같은 스타일을 가진 이미지로 변형되는 것을 알 수 있다. 뉴럴 네트워크는 뉴럴 네트워크에 포함된 레이어들 중 단일 레이어를 통해 출력되는 값을 스타일 특 징으로 이용할 수 있다. 또는 뉴럴 네트워크는 하나의 레이어가 아닌 복수 개의 레이어들의 특징 맵의 상 관 관계를 함께 고려함으로써 복수 개의 레이어들로부터 추출되는 특징 맵을 스타일 특징으로 이용할 수도 있다. 유사하게, 뉴럴 네트워크는 소스 이미지가 입력되면, 각 레이어를 통과시키면서 소스 이미지로 부터 콘텐츠 특징을 추출할 수 있다. 도 3에서 뉴럴 네트워크는 소스 이미지를 좌측으로부터 우측 방 향으로 레이어를 통과시키면서 재 구성하여 특징 맵(321, 322, 323, 324, 325)을 추출한다. 낮은 레이어의 경우, 입력된 소스 이미지와 거의 동일한 특징 맵(321, 322, 323)이 출력되게 된다. 레이어가 깊어질수록 픽셀 수준의 정보는 사라지게 되고 소스 이미지가 가진 sementic 정보는 유지된 상태의 이미지(324, 325) 가 출력되게 된다. 따라서, 뉴럴 네트워크는 심도가 깊은 레이어에서 콘텐츠 특징을 추출할 수 있다. 뉴럴 네트워크는 출력 이미지를 이용하여, 출력 이미지와 서브 베이스 이미지로부터 심도가 낮은 레이어에 서 추출한 스타일 특징을 비교하여 스타일 손실을 구하고, 출력 이미지와 소스 이미지로부터 심도가 높은 레이 어에서 추출한 콘텐츠 특징을 비교하여 콘텐츠 손실을 구할 수 있다. 뉴럴 네트워크는 콘텐츠 손실과 스타 일 손실이 최소가 되는 출력 이미지를 생성하고 이를 서브 모자이크로 이용할 수 있다. 도 4는 실시 예에 따른 모자이크 생성 장치의 내부 블록도이다. 도 4를 참조하면, 모자이크 생성 장치는 프로세서, 메모리, 디스플레이 및 사용자 인터페이스를 포함할 수 있다. 실시 예에서, 모자이크 생성 장치는 모자이크를 생성할 수 있는 다양한 전자 장치로 구현될 수 있다. 모자 이크 생성 장치는 고정형 또는 이동형일 수 있다. 예를 들어, 모자이크 생성 장치는 데스크탑, 디지 털 TV, 스마트 폰(smartphone), 태블릿 PC(tablet personal computer), 화상전화기, 전자북 리더기(e-book reader), 랩탑 PC(laptop personal computer), 넷북 컴퓨터(netbook computer), 디지털 카메라, PDA(Personal Digital Assistants), PMP(Portable Multimedia Player), 캠코더, 네비게이션, 웨어러블 장치(wearable device), 스마트 와치(smart watch)중 적어도 하나를 포함할 수 있다. 프로세서는 모자이크 생성 장치의 전반적인 동작을 제어한다. 프로세서는 메모리에 저장된 하나 이상의 인스트럭션을 실행함으로써, 모자이크 생성 장치가 기능하도록 제어할 수 있다. 실시 예에서, 모자이크 생성 장치는 기계학습 및 기계학습을 활용한 요소 기술들로 구성되는 AI 기술을 이 용할 수 있다. 이를 위해 프로세서는 AI 기술을 구현하기 위한 알고리즘 또는 알고리즘의 집합인 뉴럴 네 트워크, 즉, 신경망을 이용할 수 있다. 신경망은 입력 데이터를 입력 받고, 전술한 분석 및 분류를 위한 연산을 수행하여, 결과 데이터를 출력할 수 있다. 신경망이 입력 데이터에 대응되는 결과 데이터를 정확하게 출력하기 위해서는, 신경망을 트레이닝 시킬 필요가 있다. 여기서, ‘트레이닝(training)’은 신경망으로 다양한 데이터들을 입력시키고, 입력된 데이터들을 분석하 는 방법, 입력된 데이터들을 분류하는 방법, 및/또는 입력된 데이터들에서 결과 데이터 생성에 필요한 특징을 추출하는 방법 등을 신경망이 스스로 발견 또는 터득할 수 있도록 신경망을 훈련시키는 것을 의미할 수 있다. 여기서, 학습을 통해 다수의 학습 데이터들에 학습 알고리즘을 적용함으로써, 원하는 특성의 인공지능 모델이 만들어질 수 있다. 이러한 학습은 인공지능이 수행되는 기기 자체, 즉, 모자이크 생성 장치에서 이루어질 수도 있고, 별도의 서버/시스템을 통해 이루어 질 수도 있다. 여기서, 학습 알고리즘은, 다수의 학습 데이터들을 이용하여 소정의 대상 기기(예컨데, 로봇)를 훈련시켜 소정 의 대상 기기 스스로 결정을 내리거나 예측을 할 수 있도록 하는 방법이다. 학습 알고리즘의 예로는, 지도형 학 습(supervised learning), 비지도형 학습(unsupervised learning), 준지도형 학습(semi-supervised learning) 또는 강화 학습(reinforcement learning)이 있으며, 본 발명에서의 학습 알고리즘은 명시한 경우를 제외하고 전 술한 예에 한정되지 않는다. 실시 예에서, 신경망은 두 개의 이미지로부터 하나의 출력 이미지를 생성할 때, 두 이미지 중 하나의 이미지로 부터 스타일 특징을 추출하고, 나머지 이미지로부터 콘텐츠 특징을 추출하여 스타일 특징과 콘텐츠 특징이 믹스 된 출력 이미지를 생성하도록 학습된 것일 수 있다. 이를 위해, 신경망은 첫 번째 이미지로부터 추출한 스타일 특징과 출력 이미지의 스타일 특징의 차이 값을 입력 받고, 이를 이용하여 첫 번째 이미지의 스타일 특징과 출 력 이미지의 스타일 특징의 차이 값이 최소가 되도록 출력 이미지를 생성하거나 변형하는 것으로 학습될 수 있 다. 또한, 신경망은 두 번째 이미지로부터 추출한 콘텐츠 특징과 출력 이미지의 콘텐츠 특징의 차이 값을 입력 받고, 이를 이용하여 두 번째 이미지의 콘텐츠 특징과 출력 이미지의 콘텐츠 특징의 차이 값이 최소가 되도록 출력 이미지를 생성하거나 변형하는 것으로 학습될 수 있다. 결과적으로, 신경망은, 두 개의 이미지에 대해, 하 나의 이미지의 스타일 특징과 나머지 이미지의 콘텐츠 특징을 갖는 출력 이미지를 생성하도록 미리 학습된 것일 수 있다. 프로세서는 AI 모델을 이용하여 입력 데이터를 처리하여 모자이크를 생성하도록 모자이크 생성 장치 를 제어할 수 있다. 실시 예에서, 프로세서는 사용자가 선택한 베이스 이미지에 대해 모자이크를 생성할 수 있다. 사용자는 메모리에 저장되어 있는 복수의 이미지 중 하나를 베이스 이미지로 선택하거나, 또는 외부 장치로부터 수신하거나 다운로드받은 이미지를 베이스 이미지로 선택할 수 있다. 프로세서는 사용자 가 선택한 베이스 이미지를 복수의 서브 베이스 이미지로 분할하고, 복수의 서브 베이스 이미지 중 하나의 서브 베이스 이미지를 랜덤으로 선택할 수 있다. 프로세서는 선택된 하나의 서브 베이스 이미지로부터 뉴럴 네 트워크에 포함된 계층 별로 각각 특징 값, 또는 특징 맵을 추출할 수 있다. 프로세서는 서브 베이스 이미 지에 대해 추출하는 계층 별 특징 값 중 스타일에 대한 특징만을 이용하거나, 또는 계층 별로 스타일에 대한 특 징만을 추출하여 서브 모자이크를 생성하는데 이용할 수 있다. 전술한 바와 같이, 스타일에 대한 특징은 신경망에 포함된 각 레이어의 특징 맵 사이의 상관 관계를 함께 고려 하여 획득될 수 있다. 또는 실시 예에서, 스타일에 대한 특징은 레이어들 중 심도가 낮은 하나 또는 복수 개의 레이어들로부터 추출될 수도 있다. 스타일에 대한 특징은 이미지가 가진 스타일을 표현한 값으로, 그림을 그린 특정한 시대나 지역 별 회화 양식이 나 화가의 경향과 특징을 나타내는 화풍 등이 될 수도 있고, 이미지의 텍스쳐, 분위기, 콘트라스트, 광택, 명도, 색도, 채도 등이 될 수 있다. 프로세서는 서브 베이스 이미지로부터 추출한 스타일 정보를 이용하여 서브 베이스 모자이크를 생성하는 데 이용할 수 있다. 이하, 프로세서가 서브 베이스 모자이크를 생성하기 위해 서브 베이스 이미지로부터 추출하는 특징 정보를 제1 특징 값으로 부르기로 한다. 실시 예에서, 프로세서는 복수의 서브 베이스 이미지에 대해 랜덤한 순서대로 서브 모자이크를 생성할 수 있다. 즉, 프로세서는 선택된 서브 베이스 이미지에 대해 서브 모자이크를 생성한 후, 아직 선택되지 않은 서브 베이스 이미지 중 하나를 새로 랜덤으로 선택하고, 이에 대한 서브 모자이크를 생성할 수 있다. 실시 예에서, 프로세서는 복수의 소스 이미지 중 하나의 소스 이미지를 랜덤으로 선택할 수 있다. 소스 이 미지는 메모리에 기 저장되어 있는 복수의 이미지 중에서 선택되거나 또는 외부 장치로부터 수신하거나 다 운로드받은 이미지 중에서 임의로 선택될 수 있다. 실시 예에서, 프로세서는 서로 다른 서브 베이스 이미 지에 대해 서브 모자이크를 생성 시, 동일한 소스 이미지를 중복하여 선택할 수도 있다. 프로세서가 서로 다른 서브 베이스 이미지에 대해 서브 모자이크를 생성할 때 동일한 소스 이미지를 중복하여 선택하여 이용하는 경우라도, 서브 베이스 이미지와 소스 이미지를 이용하여 생성되는 서브 모자이크는 서로 달라질 수 있다. 즉, 서브 베이스 이미지가 동일하지 않은 경우 각 서브 베이스 이미지의 특징 값 또한 다르므로 동일한 소스 이미지 를 이용하여 서브 모자이크가 생성되더라도 생성되는 서브 모자이크는 서로 다른 특징 값을 가질 수 있다. 프로세서는 복수의 소스 이미지 중 선택된 하나의 소스 이미지로부터 특징 값을 추출할 수 있다. 이때, 프 로세서는 소스 이미지로부터 소스 이미지의 모양이나 형태와 같이 소스 이미지를 식별할 수 있는 콘텐츠 특징을 추출할 수 있다. 콘텐츠 특징은 신경망에 포함된 레이어들 중 특정한 레벨의 레이어에서 추출될 수 있다. 또는 실시 예에서, 콘 텐츠에 대한 특징은 레이어들 중 심도가 높은 하나 또는 복수 개의 상위 레벨 레이어들로부터 추출될 수도 있다. 프로세서는 소스 이미지로부터 추출한 콘텐츠 정보를 이용하여 서브 베이스 모자이크를 생성하는 데 이용 할 수 있다. 이하, 프로세서가 서브 베이스 모자이크를 생성하기 위해 소스 이미지로부터 추출하는 특징 정보를 제2 특징 값으로 부르기로 한다. 프로세서는 선택된 서브 베이스 이미지로부터 추출한 제1 특징 값과 선택된 소스 이미지로부터 추출한 제2 특징 값을 이용하여 선택된 서브 베이스 이미지에 대응하는 서브 모자이크를 생성할 수 있다. 프로세서는 복수의 서브 베이스 이미지 모두에 대해 대응하는 서브 모자이크를 생성하고, 이를 이용하여 베이스 이미지 전 체에 대응하는 모자이크를 생성할 수 있다. 메모리는 적어도 하나의 인스트럭션을 저장할 수 있다. 메모리는 프로세서가 실행하는 적어도 하나의 프로그램을 저장하고 있을 수 있다. 또한 메모리는 모자이크 생성 장치로 입력되거나 모자이 크 생성 장치로부터 출력되는 데이터를 저장할 수 있다. 실시 예에서, 메모리는 전술한 AI 모델을 저장하고 있을 수 있다. 메모리는 플래시 메모리 타입 (flash memory type), 하드디스크 타입(hard disk type), 멀티미디어 카드 마이크로 타입(multimedia card micro type), 카드 타입의 메모리(예를 들어 SD 또는 XD 메모리 등), 램(RAM, Random Access Memory) SRAM(Static Random Access Memory), 롬(ROM, Read-Only Memory), EEPROM(Electrically Erasable Programmable Read-Only Memory), PROM(Programmable Read-Only Memory), 자기 메모리, 자기 디스크, 광디스크 중 적어도 하나의 타입의 저장매체를 포함할 수 있다. 메모리에는 미디어 신호가 저장되어 있을 수 있다. 미디어 신호는 베이스 이미지나 소스 이미지로 사용될 그림이나 사진과 같은 이미지를 포함할 수 있다. 또한, 미디어 신호는 비디오 신호, 텍스트 신호 등을 포함할 수 있다. 미디어 신호는 모자이크 생성 장치를 이용하여 사용자가 촬영하거나 편집하여 생성한 사진이나 그림 등의 이미지일 수도 있고, 외부 장치로부터 다운로드받거나, 외부 매체로부터 수신한 이미지일 수도 있다. 실시 예에서, 프로세서는 프로세서의 내부에 또 다른 메모리(미도시)를 구비할 수 있다. 프로세서 는 내부에 구비되는 메모리에 하나 이상의 인스트럭션을 저장하고, 내부에 구비되는 메모리에 저장된 하나 이상의 인스트럭션을 실행하여 전술한 동작들이 수행되도록 제어할 수 있다. 즉, 프로세서는 프로세서 의 내부에 구비되는 내부 메모리 또는 메모리에 저장된 적어도 하나의 인스트럭션 또는 프로그램을실행하여 소정 동작을 수행할 수 있다. 실시 예에 따른 디스플레이는, 그림이나 사진과 같은 이미지나 비디오 신호, 텍스트 신호 등을 출력할 수 있다. 디스플레이가 터치 스크린으로 구현되는 경우, 디스플레이는 출력 장치 이외에 입력 장치로 사 용될 수 있다. 예를 들어, 디스플레이는 액정 디스플레이(liquid crystal display), 박막 트랜지스터 액정 디스플레이(thin film transistor-liquid crystal display), 유기 발광 다이오드(organic light-emitting diode), 플렉서블 디스플레이(flexible display), 3차원 디스플레이(3D display), 전기 영동 디스플레이 (electrophoretic display) 중에서 적어도 하나를 포함할 수 있다. 실시 예에서, 디스플레이는 베이스 이미지로 이용될 수 있는 복수의 그림이나 사진 등의 이미지를 출력할 수 있다. 디스플레이는 인터페이스 화면을 출력할 수 있다. 사용자는 인터페이스 화면을 이용하여, 복수의 이미지 중 원하는 이미지를 베이스 이미지로 선택할 수 있다. 프로세서는 사용자가 선택한 베이스 이미지 에 대해, 임의로 소스 이미지를 선택하여 모자이크를 생성할 수 있다. 디스플레이는 프로세서가 생성 한 모자이크를 출력할 수 있다. 실시 예에서 프로세서는 동일한 베이스 이미지에 대해 복수의 모자이크를 생성할 수 있다. 프로세서는 서브 베이스 이미지와 소스 이미지를 랜덤으로 선택하여 이용하므로, 동일한 베이스 이미지에 대해서 복수의 모자이크가 만들어질 수 있다. 프로세서가 복수의 모자이크를 생성한 경우, 디스플레이는 복수 개의 모자이크를 디스플레이에 출력하고, 이 중 하나를 사용자로부터 선택 받을 수 있는 인터페이스 화면을 출력할 수 있다. 사용자 인터페이스는 모자이크 생성 장치를 제어하기 위한 사용자 입력을 수신할 수 있다. 사용자 인 터페이스는 사용자의 터치를 감지하는 터치 패널, 사용자의 푸시 조작을 수신하는 버튼, 사용자의 회전 조 작을 수신하는 휠, 키보드(key board), 및 돔 스위치 (dome switch), 음성 인식을 위한 마이크, 모션을 센싱하 는 모션 감지 센서 등을 포함하는 다양한 형태의 사용자 입력 디바이스를 포함할 수 있으나 이에 제한되지 않는 다. 또한, 모자이크 생성 장치가 원격 제어 장치(remote controller)(미도시)에 의해서 조작되는 경우, 사 용자 인터페이스는 원격 제어 장치로부터 수신되는 제어 신호를 수신할 수도 있을 것이다. 사용자는 사용자 인터페이스를 통하여 모자이크를 생성하고자 하는 베이스 이미지를 선택할 수 있다. 또한, 사용자는 사용자 인터페이스를 통하여 프로세서가 하나의 베이스 이미지로부터 하나의 모자이 크를 생성하도록 할지, 또는 복수 개의 모자이크를 생성하도록 할지를 선택할 수 있다. 프로세서는 사용자 의 제어 신호에 따라 하나 또는 복수 개의 모자이크를 생성할 수 있다. 사용자는 복수 개의 모자이크가 출력된 경우, 이 중 하나를 선택하여 모자이크 생성 장치에 저장시키거나 또는 외부 장치로 전송하도록 할 수 있 다. 도 5는 다른 실시 예에 따른 모자이크 생성 장치의 내부 블록도이다. 도 5의 모자이크 생성 장치는 도 4의 모자이크 생성 장치를 포함하는 장치 일 수 있다. 이하, 도 5의 모자이크 생성 장치를 설명하는데 있 어서 도 4에서와 중복되는 설명은 생략한다. 도 5에 도시된 모자이크 생성 장치는 도 4에 도시된 모자이크 생성 장치에 비하여 통신부, 뉴럴 네트워크 프로세서, 및 촬영부를 더 포함할 수 있다. 통신부는 유무선의 네트워크를 통하여 외부 장치(미도시)들과 통신할 수 있다. 구체적으로, 통신부는 프로세서의 제어에 따라서 유무선의 네트워크를 통하여 연결되는 외부 장치와 신호를 송수신할 수 있다. 외부 장치는 디스플레이를 통하여 출력되는 이미지 등의 미디어 신호를 공급하는 데이터베이스나 전자 장 치 등이 될 수 있고 또는 USB 등과 같은 정보 저장 매체일 수도 있다. 또한 외부 장치는 통신부와 데이터 를 송수신하는 데이터를 처리하는 서버, 서버 시스템, 서버 기반의 장치 등을 포함할 수 있다. 또한 외부 장치 는 모자이크 생성 장치가 생성한 모자이크를 화면에 출력할 수 있는 디스플레이 장치일 수 있다. 통신부는 근거리 통신 모듈, 유선 통신 모듈, 이동 통신 모듈, 방송 수신 모듈 등과 같은 적어도 하나의 통신 모듈을 포함할 수 있다. 통신 모듈은 방송 수신을 수행하는 튜너, 블루투스, WLAN(Wireless LAN)(Wi-Fi), Wibro(Wireless broadband), Wimax(World Interoperability for Microwave Access), CDMA, WCDMA 등과 같은 통신 규격을 따르는 네트워크를 통하여 데이터 송수신을 수행할 수 있는 통신 모듈을 포함할 수 있다. 실시 예에서, 통신부는 외부 장치로부터 그림이나 회화 등의 이미지를 수신할 수 있다. 실시 예에서, 통신 부는 각종 인스트럭션이나, 프로세서가 이용하는 알고리즘, 알고리즘들로 구현되는 AI 모델 등을 외 부 장치로부터 수신할 수도 있다. 통신부는 프로세서에 의해 생성된 모자이크를 외부 장치로 전송할 수도 있다. 촬영부는 피사체를 촬영하여 영상을 생성하고, 이를 신호 처리 할 수 있다. 실시 예에서, 촬영부는 카메라(미도시)를 포함할 수 있다. 카메라는 피사체에 대한 정보를 CCD나 CMOS 등의 이미지 센서(미도시)에 상 이 맺히도록 할 수 있고, 이미지 센서는 카메라를 통해 들어온 빛을 전기적인 신호로 변환할 수 있다. 촬영부 는 촬영한 영상에 대해 AE(Auto Exposure), AWB(Auto White Balance), Color recovery, correction, Sharpening, Gamma, Lens shading correction 중 하나 이상의 신호 처리를 수행할 수 있다. 사용자가 촬영부 를 이용하여 촬영한 영상은 이후 포토샵 등과 같은 각종 어플리케이션 등으로 편집될 수도 있다. 촬영부 로부터 촬영된 영상 또는 이후 편집된 영상은 메모리에 저장될 수 있고, 소스 이미지나 베이스 이미 지로 이용될 수 있다. 도 5의 모자이크 생성 장치는 도 4의 모자이크 생성 장치에 비하여 뉴럴 네트워크 프로세서를 더 포함할 수 있다. 도 5의 모자이크 생성 장치는 도 4의 모자이크 생성 장치와 달리, 뉴럴 네트워크 를 통하여 연산을 수행하는 것을 프로세서와는 별도로 뉴럴 네트워크 프로세서를 통하여 수행할 수 있다. 뉴럴 네트워크 프로세서는 하나 이상의 인스트럭션을 실행하여 뉴럴 네트워크를 통한 연산이 수행되도록 할 수 있다. 구체적으로, 뉴럴 네트워크 프로세서는 AI 모델을 이용하여 사용자가 원하는 베이스 이미지를 복수의 서브 베이스 이미지로 나누고, 각 서브 베이스 이미지로부터 스타일 특징 값을 추출할 수 있다. 뉴럴 네 트워크 프로세서는 복수의 소스 이미지 중 하나를 랜덤으로 선택하고, 선택된 소스 이미지에 대한 콘텐츠 특징 값을 추출할 수 있다. 뉴럴 네트워크 프로세서는 서브 베이스 이미지로부터 추출한 스타일 특징 값과 소스 이미지로부터 추출한 콘텐츠 특징 값을 이용하여, 서브 베이스 이미지에 대응하는 서브 모자이크를 생성할 수 있다. 디스플레이는 뉴럴 네트워크 프로세서가 AI 모델을 이용하여 생성한 모자이크를 출력할 수 있다. 뉴 럴 네트워크 프로세서가 동일한 베이스 이미지에 대해 복수 개의 모자이크를 생성한 경우, 디스플레이 는 복수 개의 모자이크를 출력하여 사용자가 원하는 모자이크를 선택할 수 있도록 할 수 있다. 도 6은 실시 예에 따라, 사용자가 모자이크 생성 장치를 이용하여 원하는 모자이크를 생성할 때 이용할 수 있는 사용자 인터페이스를 설명하기 위한 도면이다. 도 6을 참조하면, 사용자는 모자이크 생성 장치를 이용하여 원하 는 영상에 대해 모자이크를 생성할 수 있다. 모자이크 생성 장치는 사용자의 명령에 따라 모자이크 생성을 위한 인터페이스 화면을 생성하고 이를 출력할 수 있다. 전술한 바와 같이, 모자이크 생성 장치는 모자이크를 생성할 수 있는 다양한 전자 장치로 구현될 수 있으며 예 를 들어, 데스크탑, 디지털 TV, 스마트 폰(smartphone), 태블릿 PC(tablet personal computer), 랩탑 PC(laptop personal computer), 넷북 컴퓨터(netbook computer), PDA(Personal Digital Assistants), PMP(Portable Multimedia Player) 등이 될 수 있다. 사용자는 다양한 형태의 사용자 입력 디바이스를 이용하여 모자이크 생성을 위한 인터페이스 화면에 출력 된 여러 제어 정보를 선택하거나 입력할 수 있다. 모자이크 생성을 위한 인터페이스 화면은 베이스 이미지 선택, 타일 사이즈 선택, 소스 이미지 선택, 동일 소스 이미지 사용 여부, 이미지 편집 도구, 모자이크 생성과 같이 다양한 제어 정보를 포함할 수 있다. 베이스 이미지 선택은 사용자가 모자이크 생성 장치에 기 저장되어 있거나 외부 장치로부터 실시간으로 수 신하여 이용할 수 있는 이미지들 중 원하는 이미지를 선택하기 위해 구비된 정보이다. 사용자가 마우스나 손가 락, 패드 등을 이용하여 베이스 이미지 선택을 위한 버튼 등을 선택하면 모자이크 생성을 위한 인터페이스 화면에는 사용자가 선택할 수 있는 복수 개의 이미지들이 출력될 수 있다. 사용자는 이 중 원하는 이 미지를 선택할 수 있다. 사용자가 선택한 이미지는 확대된 사이즈로 모자이크 생성을 위한 인터페이스 화 면에 출력될 수 있다. 실시 예에서, 사용자는 타일 사이즈 선택 버튼을 이용하여, 타일 사이즈나 타일의 개수를 선택하거나 직접 입력할 수 있다. 타일 사이즈는 하나의 베이스 영역을 몇 개로 분할할 것인지를 결정하는 데 사용될 수 있다. 모자이크 생성 장치는 랜덤으로 소스 이미지를 선택하여 이용할 수도 있지만, 인터페이스 화면을 통해 사 용자로부터 소스 이미지를 선택 받을 수도 있다. 이 경우, 사용자는 소스 이미지 선택을 위한 버튼 등을 이용하여 소스 이미지를 선택할 수 있다. 하나의 베이스 이미지에 대해 모자이크를 생성하기 위해서는 복수 개의 소스 이미지가 필요하다. 사용자는 소정 폴더를 선택하여, 그 폴더에 들어 있는 이미지들을 소스 이미지로 이용하는 등의 방법으로 복수의 소스 이미지를 선택할 수 있다. 사용자는 복수 개의 소스 이미지를 모두 선택하 거나, 일부만을 선택하고 나머지는 모자이크 생성 장치가 랜덤으로 선택하도록 설정할 수도 있다. 또는 사용자 는 모자이크 생성 장치가 필요한 소스 이미지를 모두 선택하여 이용하도록 설정할 수도 있다. 소스 이미지는 중복하여 사용될 수도 있고 그렇지 않을 수도 있다. 사용자는 동일 소스 이미지 사용 여부 를 위한 버튼 등을 이용하여, 모자이크를 생성할 때, 서로 다른 타일, 즉, 서로 다른 서브 베이스 이미지에 대 해 동일한 소스 이미지를 중복하여 사용할 것인지 여부를 선택할 수 있다. 실시 예에서, 서로 다른 서브 베이스 이미지에 대해 동일한 소스 이미지를 사용하여 서브 모자이크를 생성하더라도, 서브 모자이크는 서브 베이스 이 미지의 특징을 갖게 되므로, 서로 다른 서브 베이스 이미지에 대응하여 생성되는 서브 모자이크 또한 다른 특징 을 갖게 된다. 이미지 편집 도구는 스타일 트랜스퍼, 컬러 강화, 자르기 등과 같은 다양한 이미지 편집 툴을 포함할 수 있다. 사용자는 모자이크를 생성할 때, 스타일 트랜스퍼 버튼을 이용하여 모자이크를 생성 할 때 원하는 특정 스타일이 추가로 반영되도록 할 수 있다. 예컨대, 사용자는 컬러 강화 버튼을 이용하여 컬러감을 변경할 수도 있다. 사용자는 화면 자르기 버튼을 이용하여 영상의 특정 부분만을 선택하여 이용 할 수도 있다. 이는 하나의 실시 예에 불과하며, 이외에도 이미지 편집 도구는 다양한 형태의 이미지 편집 을 위한 도구들이 포함될 수 있다. 사용자는 모자이크 생성 버튼을 선택하여 모자이크가 생성되도록 할 수 있다. 도 7은 실시 예에 따라, 사용자가 모자이크 생성 장치를 이용하여 모자이크를 생성할 때 출력될 수 있는 사용자 인터페이스를 설명하기 위한 도면이다. 도 7을 참조하면, 사용자가 도 6에서와 같이 모자이크 생성을 위한 인터 페이스 화면에 출력된 버튼들을 선택하거나 원하는 정보를 입력한 후 모자이크 생성 버튼을 선택한 경우, 도 7과 같은 사용자 인터페이스가 출력될 수 있다. 도 7은 동일한 베이스 이미지에 대해 생성된 복수의 모자이크를 출력하는 것을 도시한다. 실시 예에서, 모자이크 생성 장치는 동일한 베이스 이미지로부터 모자이크를 생성할 때, 이용하는 소스 이미지 를 달리 선택함으로써 서로 다른 복수의 모자이크를 생성할 수 있다. 즉, 모자이크 생성 장치는 랜덤으로 소스 이미지를 선택하여 이용하기 때문에, 동일한 베이스 이미지에 대해 모자이크를 생성할 때에도 선택된 소스 이미 지가 무엇인지에 따라 서로 다른 모자이크를 생성할 수 있다. 또한, 모자이크 생성 장치는 베이스 이미지 내의 각 타일과, 각 타일에 대해 이용할 소스 이미지를 선택하는 순서를 랜덤으로 할 수 있으므로, 동일한 베이스 이 미지와 동일한 소스 이미지를 이용하는 경우라도 베이스 이미지 내의 타일 선택 순서와 소스 이미지의 선택 순 서에 따라 생성되는 모자이크는 달라질 수 있다. 사용자는 출력된 복수의 모자이크 중 원하는 모자이크를 선택할 수 있다. 사용자는 선택된 모자이크를 모 자이크 생성 장치에 저장시키기 위해 저장 버튼을 선택할 수 있다. 사용자는 모자이크를 다시 생성하고자 하는 경우, 이전화면 버튼을 선택하여, 모자이크 생성을 위한 인터페이스 화면이 다시 출력되도록 할 수 있다. 실시 예에서, 사용자는 외부장치에 전송을 위한 버튼을 이용하여, 사용자가 선택한 모자이크가 외부의 텔 레비전 등과 같은 디스플레이 장치에 전송되어 이용되도록 할 수 있다. 도 8은 실시 예에 따라, 디스플레이 장치가 모자이크 생성 장치로부터 모자이크를 수신하여 이를 화면에 출력하 는 것을 설명하기 위한 도면이다. 도 8을 참조하면, 모자이크 생성 장치는 개인용 컴퓨터, 서버 컴퓨터, 랩톱 컴퓨터, 휴대용 전자 기기 등과 같은 다양한 기기로 구현될 수 있다. 모자이크 생성 장치는 생성된 모자이크를 유선 또는 무선 통신망을 통하여 외부의 디스플레이 장치로 전송할 수 있다. 디스플레이 장치 는 디스플레이를 포함하는 컴퓨터나 텔레비전, 휴대용 전자 기기 등과 같은 다양한 기기로 구현될 수 있다. 디스플레이 장치는 사진 또는 명화 등의 소정 화면을 디스플레이 하기 위한 액자(picture frame)처럼 이용 할 수 있는 제품일 수 있다. 디스플레이 장치는 사용자가 디스플레이 장치를 통하여 소정의 작업을 하거나, 콘텐츠를 이용하고 있는 경우가 아니면, 소정의 화면, 예를 들어, 명화 또는 사진을 포함하는 화면을 출력할 수 있다. 이 경우, 사용자는 디스플레이 장치를 명화 액자 또는 대형 사진 액자처럼 이용할 수 있 다. 사용자는 취향이나 또는 디스플레이 장치가 위치하는 장소의 분위기 등을 고려하여, 원하는 이미지가 디스플레이 장치를 통하여 디스플레이 되도록 할 수 있다. 실시 예에서, 사용자는 모자이크 생성 장치를 이용하여 원하는 모자이크를 생성하고, 생성된 모자이크를 디스플레이 장치로 전송하여, 디스플레이 장치에 원하는 모자이크가 마치 액자와 같이 이용되도록 할 수 있다. 또는 사용자는 모자이크 생성 장치를 이용하여 생성한 모자이크를 서버(미도시) 등에 업로드할 수 있다. 사용자는 향후, 디스플레이 장치를 이용하여 서버에 접속하여 서버에 저장되어 있는 모자이크를 다운로드 받아 이를 출력하여 이용할 수도 있다. 도 9는 실시 예에 따른 모자이크 생성 방법을 도시한 순서도이다. 도 9를 참조하면, 모자이크 생성 장치는 베이스 이미지를 복수의 타일로 분할할 수 있다(단계 910). 사용자는 베이스 이미지를 몇 개의 타일로 분할 할 것인지 또는 타일의 사이즈를 얼만큼으로 할 것인지를 선택할 수 있다. 모자이크 생성 장치는 복수의 타일 중 하나를 랜덤으로 선택할 수 있다(단계 920). 모자이크 생성 장치는 선택된 타일로부터 제1 특징 값을 추출할 수 있다(단계 930). 제1 특징 값은 모자이크 생성 장치가 타일로부터 추출하는, 서브 모자이크를 생성할 때 이용하는 특징일 수 있다. 실시 예에서, 제1 특징 값은 베이스 이미지의 스타일 특징일 수 있다. 모자이크 생성 장치는 소스 이미지를 랜덤으로 선택할 수 있다(단계 940). 모자이크 생성 장치는 선 택된 소스 이미지로부터 제2 특징 값을 추출할 수 있다(단계 950). 제2 특징 값은 모자이크 생성 장치가 소스 이미지로부터 추출하는, 서브 모자이크를 생성할 때 이용하는 특징일 수 있다. 실시 예에서, 제2 특징 값 은 소스 이미지의 콘텐츠 특징일 수 있다. 모자이크 생성 장치는 제1 특징 값과 제2 특징 값을 이용하여 서브 모자이크를 생성할 수 있다(단계 960). 이 후 모자이크 생성 장치는 베이스 이미지에서 선택되지 않은 타일들 중 하나를 임의로 선택하고, 동일한 과정을 반복할 수 있다. 이 때 모자이크 생성 장치는 이전 타일에 대응하는 서브 모자이크를 생성할 때 이 미 이용한 소스 이미지를 다시 선택하여 이용할 수도 있다. 모자이크 생성 장치는 모든 타일에 대해 각각 서브 모자이크를 생성하고 이를 이용하여 전체 베이스 이미지에 대한 모자이크를 생성할 수 있다. 도 10은 실시 예에 따라 뉴럴 네트워크가 모자이크를 생성하기 위해 미리 학습되는 것을 설명하는 도면이다. 실 시 예에서, 모자이크 생성 장치에 포함된 프로세서는 뉴럴 네트워크를 이용하여 모자이크를 생성할 수 있다. 이 때 뉴럴 네트워크는 스타일 손실(loss)과 콘텐츠 손실의 합이 최소가 되는 출력 이미지를 출력하도 록 미리 학습될 수 있다. 이를 위해 뉴럴 네트워크는 입력되는 두 이미지를 이용하여 생성할 출력 이미지의 특 징을 추출할 수 있다(단계 1020). 뉴럴 네트워크는 입력되는 제1 이미지로부터 스타일 특징을 추출하고(단계 1010), 이를 출력되어야 할 출력 이 미지의 스타일 특징과 비교할 수 있다(단계 1040). 뉴럴 네트워크에는 복수개의 레이어들이 포함될 수 있고, 각 각의 레이어는 제1 이미지에 대해 서로 다른 특징 값을 추출할 수 있다. 뉴럴 네트워크는 동일한 계층에서 추출 된, 제1 이미지에 대한 특징 값과 출력 이미지에 대한 특징 값의 차이를 구할 수 있다. 뉴럴 네트워크는 복수의 계층들 각각에서 제1 이미지와 출력 이미지 사이의 특징 값 간의 손실을 계산하고, 이들에 가중치를 부가하여 합친 값으로 스타일 손실을 구할 수 있다. 뉴럴 네트워크는 스타일 손실을 feed forward로 다시 입력 받을 수 있다. 뉴럴 네트워크는 제1 이미지와 출력 이미지의 스타일 특징에 차이가 있는 경우, 그 차이가 0이 되도록 출력 이미지를 변형할 수 있다(단계 1060). 뉴럴 네트워크는 입력되는 제2 이미지로부터 콘텐츠 특징을 추출할 수 있다(단계 1030). 뉴럴 네트워크는 콘텐 츠 특징과 출력 이미지의 특징으로부터 콘텐츠 손실을 구할 수 있다(단계 1050). 콘텐츠 손실은 정보의 추상화 가 많이 이루어지는 하이 레벨 레이어의 특징 맵을 이용하여 구해질 수 있다. 뉴럴 네트워크는 신경망에 포함된 복수개의 계층들 중 소정의 하이 레벨 레이어로부터 추출한 소스 이미지의 특징 맵과 출력 이미지의 특징 맵 간 의 차이를 이용하여 콘텐츠 손실을 구할 수 있다. 뉴럴 네트워크는 콘텐츠 손실을 다시 입력받을 수 있다. 뉴럴 네트워크는 제2 이미지의 콘텐츠 특징과 출력 이미지의 콘텐츠 특징에 차이가 있는 경우, 그 차이가 0이 되도록 출력 이미지를 변형할 수 있다(단계 1060). 뉴럴 네트워크는 스타일 손실과 콘텐츠 손실의 합 이 최소가 되도록 이 과정을 여러 번 수행하여 출력 이미지를 변형하도록 학습될 수 있다. 이 때 변형되는 출력 이미지는 서브 베이스 이미지의 스타일 특징과 소스 이미지의 콘텐츠 특징을 함께 가지는 이미지일 수 있다. 본 개시에 따른 인공지능과 관련된 기능은 프로세서와 메모리를 통해 동작된다. 프로세서는 하나 또는 복수의 프로세서로 구성될 수 있다. 이때, 하나 또는 복수의 프로세서는 CPU, AP, DSP(Digital Signal Processor) 등 과 같은 범용 프로세서, GPU, VPU(Vision Processing Unit)와 같은 그래픽 전용 프로세서 또는 NPU와 같은 인 공지능 전용 프로세서일 수 있다. 하나 또는 복수의 프로세서는, 메모리에 저장된 기 정의된 동작 규칙 또는 인 공지능 모델에 따라, 입력 데이터를 처리하도록 제어한다. 또는, 하나 또는 복수의 프로세서가 인공지능 전용프로세서인 경우, 인공지능 전용 프로세서는, 특정 인공지능 모델의 처리에 특화된 하드웨어 구조로 설계될 수 있다. 기 정의된 동작 규칙 또는 인공지능 모델은 학습을 통해 만들어진 것을 특징으로 한다. 여기서, 학습을 통해 만 들어진다는 것은, 기본 인공지능 모델이 학습 알고리즘에 의하여 다수의 학습 데이터들을 이용하여 학습됨으로 써, 원하는 특성(또는, 목적)을 수행하도록 설정된 기 정의된 동작 규칙 또는 인공지능 모델이 만들어짐을 의미 한다. 이러한 학습은 본 개시에 따른 인공지능이 수행되는 기기 자체에서 이루어질 수도 있고, 별도의 서버 및/ 또는 시스템을 통해 이루어 질 수도 있다. 학습 알고리즘의 예로는, 지도형 학습(supervised learning), 비지도 형 학습(unsupervised learning), 준지도형 학습(semi-supervised learning) 또는 강화 학습(reinforcement learning)이 있으나, 전술한 예에 한정되지 않는다. 인공지능 모델은, 복수의 신경망 레이어들로 구성될 수 있다. 복수의 신경망 레이어들 각각은 복수의 가중치들 (weight values)을 갖고 있으며, 이전(previous) 레이어의 연산 결과와 복수의 가중치들 간의 연산을 통해 신경 망 연산을 수행한다. 복수의 신경망 레이어들이 갖고 있는 복수의 가중치들은 인공지능 모델의 학습 결과에 의 해 최적화될 수 있다. 예를 들어, 학습 과정 동안 인공지능 모델에서 획득한 손실(loss) 값 또는 코스트(cost) 값이 감소 또는 최소화되도록 복수의 가중치들이 갱신될 수 있다. 인공 신경망은 심층 신경망(DNN:Deep Neural Network)를 포함할 수 있으며, 예를 들어, CNN (Convolutional Neural Network), DNN (Deep Neural Network), RNN (Recurrent Neural Network), RBM (Restricted Boltzmann Machine), DBN (Deep Belief Network), BRDNN(Bidirectional Recurrent Deep Neural Network) 또는 심층 Q-네트워크 (Deep Q-Networks) 등이 있으나, 전술한 예에 한정되지 않는다. 일부 실시 예에 따른 영상 표시 장치 및 그 동작 방법은 컴퓨터에 의해 실행되는 프로그램 모듈과 같은 컴퓨터 에 의해 실행 가능한 명령어를 포함하는 기록 매체의 형태로도 구현될 수 있다. 컴퓨터 판독 가능 매체는 컴퓨 터에 의해 액세스될 수 있는 임의의 가용 매체일 수 있고, 휘발성 및 비휘발성 매체, 분리형 및 비분리형 매체 를 모두 포함한다. 또한, 컴퓨터 판독가능 매체는 컴퓨터 저장 매체 및 통신 매체를 모두 포함할 수 있다. 컴퓨 터 저장 매체는 컴퓨터 판독가능 명령어, 데이터 구조, 프로그램 모듈 또는 기타 데이터와 같은 정보의 저장을 위한 임의의 방법 또는 기술로 구현된 휘발성 및 비휘발성, 분리형 및 비분리형 매체를 모두 포함한다. 통신 매 체는 전형적으로 컴퓨터 판독가능 명령어, 데이터 구조, 프로그램 모듈, 또는 반송파와 같은 변조된 데이터 신 호의 기타 데이터, 또는 기타 전송 메커니즘을 포함하며, 임의의 정보 전달 매체를 포함한다. 또한, 본 명세서에서, “부”는 프로세서 또는 회로와 같은 하드웨어 구성(hardware component), 및/또는 프로 세서와 같은 하드웨어 구성에 의해 실행되는 소프트웨어 구성(software component)일 수 있다. 또한, 전술한 본 개시의 실시 예에 따른 영상 표시 장치 및 그 동작 방법은 다중언어로 구성된 문장을 획득하는 동작; 및 다중언어 번역 모델을 이용하여, 상기 다중언어로 구성된 문장에 포함되는 단어들 각각에 대응하는 벡 터 값들을 획득하고, 상기 획득한 벡터 값들을 목표 언어에 대응하는 벡터 값들로 변환하며, 상기 변환된 벡터 값들에 기초하여, 상기 목표 언어로 구성된 문장을 획득하는 동작을 수행하도록 하는 프로그램이 저장된 기록매 체를 포함하는 컴퓨터 프로그램 제품으로 구현될 수 있다."}
{"patent_id": "10-2019-0123309", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "전술한 설명은 예시를 위한 것이며, 발명이 속하는 기술분야의 통상의 지식을 가진 자는 발명의 기술적 사상이 나 필수적인 특징을 변경하지 않고서 다른 구체적인 형태로 쉽게 변형이 가능하다는 것을 이해할 수 있을 것이다. 그러므로 이상에서 기술한 실시 예들은 모든 면에서 예시적인 것이며 한정적이 아닌 것으로 이해해야만 한 다. 예를 들어, 단일형으로 설명되어 있는 각 구성 요소는 분산되어 실시될 수도 있으며, 마찬가지로 분산된 것으로 설명되어 있는 구성 요소들도 결합된 형태로 실시될 수 있다.도면 도면1 도면2 도면3 도면4 도면5 도면6 도면7 도면8 도면9 도면10"}
{"patent_id": "10-2019-0123309", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 일 실시 예에 따라, 모자이크를 생성하는 기술을 설명하기 위한 도면이다. 도 2는 실시 예에 따라, 뉴럴 네트워크가 베이스 이미지와 소스 이미지의 특징을 이용하여 모자이크를 생성하는 것을 설명하기 위한 도면이다. 도 3은 실시 예에서 사용할 수 있는 뉴럴 네트워크가 이미지로부터 특징을 추출하는 것을 설명하기 위한 도면이 다. 도 4는 실시 예에 따른 모자이크 생성 장치의 내부 블록도이다. 도 5는 다른 실시 예에 따른 모자이크 생성 장치의 내부 블록도이다. 도 6은 실시 예에 따라, 사용자가 모자이크 생성 장치를 이용하여 원하는 모자이크를 생성할 때 이용할 수 있는 사용자 인터페이스를 설명하기 위한 도면이다. 도 7은 실시 예에 따라, 사용자가 모자이크 생성 장치를 이용하여 모자이크를 생성할 때 출력될 수 있는 사용자 인터페이스를 설명하기 위한 도면이다. 도 8은 실시 예에 따라, 디스플레이 장치가 모자이크 생성 장치로부터 모자이크를 수신하여 이를 화면에 출력하 는 것을 설명하기 위한 도면이다. 도 9는 실시 예에 따른 모자이크 생성 방법을 도시한 순서도이다. 도 10은 실시 예에 따라 뉴럴 네트워크가 모자이크를 생성하기 위해 미리 학습되는 것을 설명하는 도면이다."}
