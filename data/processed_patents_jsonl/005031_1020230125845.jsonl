{"patent_id": "10-2023-0125845", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2025-0042576", "출원번호": "10-2023-0125845", "발명의 명칭": "프로젝션 장치 및 그 동작 방법", "출원인": "삼성전자주식회사", "발명자": "신형종"}}
{"patent_id": "10-2023-0125845", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "프로젝션 장치(100)에 있어서,프로젝션부(140);하나 이상의 인스트럭션들을 저장하는 메모리(130); 및상기 하나 이상의 인스트럭션들을 실행하는 적어도 하나의 프로세서(120)를 포함하고,상기 적어도 하나의 프로세서(120)는, 상기 하나 이상의 인스트럭션들을 실행함으로써,제1 영상을 획득하고,스크린의 공간 정보 및 사용자의 위치 정보를 획득하고,상기 스크린의 공간 정보 및 상기 사용자의 위치 정보에 기초하여, 3차원 객체 영상 및 배경 영상을 생성하고,상기 제1 영상, 상기 3차원 객체 영상 및 상기 배경 영상을 합성한 제2 영상을 프로젝션하도록 상기 프로젝션부를 제어하는, 프로젝션 장치."}
{"patent_id": "10-2023-0125845", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 적어도 하나의 프로세서(120)는, 상기 하나 이상의 인스트럭션들을 실행함으로써,사용자 입력에 기초하여, 상기 3차원 객체 영상 및 상기 배경 영상을 설정하고,상기 사용자의 위치 정보 및 상기 스크린의 공간 정보에 기초하여, 설정된 상기 3차원 객체 영상 및 상기 배경영상을 조정하는, 프로젝션 장치."}
{"patent_id": "10-2023-0125845", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 적어도 하나의 프로세서(120)는, 상기 하나 이상의 인스트럭션들을 실행함으로써,상기 제1 영상의 카테고리 정보를 획득하고,상기 카테고리 정보에 기초하여, 상기 배경 영상을 결정하는, 프로젝션 장치."}
{"patent_id": "10-2023-0125845", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항 내지 제3항 중 어느 한 항에 있어서,상기 적어도 하나의 프로세서(120)는, 상기 하나 이상의 인스트럭션들을 실행함으로써,상기 사용자의 위치 정보 및 상기 스크린의 공간 정보에 기초하여, 상기 3차원 객체 영상에 포함되는 적어도 하나의 객체에 대한 깊이 정보를 결정하는, 프로젝션 장치."}
{"patent_id": "10-2023-0125845", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항 내지 제4항 중 어느 한 항에 있어서,상기 적어도 하나의 프로세서(120)는, 상기 하나 이상의 인스트럭션들을 실행함으로써,상기 사용자의 위치 정보가 변경되는 것에 기초하여, 상기 사용자의 시선 방향에 따라 상기 3차원 객체 영상 및상기 배경 영상 중 적어도 하나를 조정하는, 프로젝션 장치.공개특허 10-2025-0042576-3-청구항 6 제1항 내지 제5항 중 어느 한 항에 있어서,상기 적어도 하나의 프로세서(120)는, 상기 하나 이상의 인스트럭션들을 실행함으로써,시간 정보 및 날씨 정보 중 적어도 하나를 획득하고,상기 시간 정보 및 날씨 정보 중 적어도 하나에 기초하여, 상기 3차원 객체 영상 및 상기 배경 영상 중 적어도하나를 조정하는 프로젝션 장치."}
{"patent_id": "10-2023-0125845", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6항에 있어서,상기 적어도 하나의 프로세서(120)는, 상기 하나 이상의 인스트럭션들을 실행함으로써,프로젝션 방향을 획득하고,상기 시간 정보 및 상기 프로젝션 방향에 기초하여, 상기 3차원 객체 영상 및 상기 배경 영상 중 적어도 하나에나타나는 그림자 효과를 조정하는, 프로젝션 장치."}
{"patent_id": "10-2023-0125845", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1항 내지 제7항 중 어느 한 항에 있어서,상기 적어도 하나의 프로세서(120)는, 상기 하나 이상의 인스트럭션들을 실행함으로써,상기 3차원 객체 영상에 포함되는 적어도 하나의 객체의 모양 및 크기에 기초하여, 상기 제1 영상을 상기 적어도 하나의 객체에 합성하는, 프로젝션 장치."}
{"patent_id": "10-2023-0125845", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1항 내지 제8항 중 어느 한 항에 있어서,상기 적어도 하나의 프로세서(120)는, 상기 하나 이상의 인스트럭션들을 실행함으로써,상기 스크린의 공간 정보에 기초하여, 상기 제2 영상의 프로젝션 방향, 프로젝션 위치 및 프로젝션 크기 중 적어도 하나를 결정하는 프로젝션 장치."}
{"patent_id": "10-2023-0125845", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제1항 내지 제9항 중 어느 한 항에 있어서,상기 프로젝션 장치는,적어도 하나의 카메라를 더 포함하고,상기 적어도 하나의 카메라로부터 촬영된 영상에 기초하여, 상기 스크린의 공간 정보 및 상기 사용자의 위치 정보를 획득하는, 프로젝션 장치."}
{"patent_id": "10-2023-0125845", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "프로젝션 장치의 동작 방법에 있어서,제1 영상을 획득하는 단계(S310);스크린의 공간 정보를 획득하는 단계(S320);사용자의 위치 정보를 획득하는 단계(S330);상기 스크린의 공간 정보 및 상기 사용자의 위치 정보에 기초하여, 3차원 객체 영상 및 배경 영상을 생성하는단계(S340); 및상기 제1 영상, 상기 3차원 객체 영상 및 상기 배경 영상을 합성한 제2 영상을 프로젝션하는 단계(S360);를 포공개특허 10-2025-0042576-4-함하는 프로젝션 장치의 동작 방법."}
{"patent_id": "10-2023-0125845", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항에 있어서,상기 동작 방법은,사용자 입력에 기초하여, 상기 3차원 객체 영상 및 상기 배경 영상을 설정하는 단계를 더 포함하고,상기 3차원 객체 영상 및 배경 영상을 생성하는 단계는,상기 사용자의 위치 정보 및 상기 스크린의 공간 정보에 기초하여, 설정된 상기 3차원 객체 영상 및 상기 배경영상을 조정하는 단계를 포함하는, 프로젝션 장치의 동작 방법."}
{"patent_id": "10-2023-0125845", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제11항에 있어서,상기 동작 방법은,상기 제1 영상의 카테고리 정보를 획득하는 단계; 및상기 카테고리 정보에 기초하여, 상기 배경 영상을 결정하는 단계를 더 포함하는, 프로젝션 장치의 동작 방법."}
{"patent_id": "10-2023-0125845", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제11항 내지 제13항 중 어느 한 항에 있어서,상기 3차원 객체 영상 및 배경 영상을 생성하는 단계는,상기 사용자의 위치 정보 및 상기 스크린의 공간 정보에 기초하여, 상기 3차원 객체 영상에 포함되는 적어도 하나의 객체에 대한 깊이 정보를 결정하는 단계를 포함하는, 프로젝션 장치의 동작 방법."}
{"patent_id": "10-2023-0125845", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제11항 내지 제14항 중 어느 한 항에 있어서,상기 3차원 객체 영상 및 배경 영상을 생성하는 단계는,상기 사용자의 위치 정보가 변경되는 것에 기초하여, 상기 사용자의 시선 방향에 따라 상기 3차원 객체 영상 및상기 배경 영상 중 적어도 하나를 조정하는 단계를 포함하는, 프로젝션 장치의 동작 방법."}
{"patent_id": "10-2023-0125845", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제11항 내지 제15항 중 어느 한 항에 있어서,상기 동작 방법은,시간 정보 및 날씨 정보 중 적어도 하나를 획득하는 단계; 및상기 시간 정보 및 날씨 정보 중 적어도 하나에 기초하여, 상기 3차원 객체 영상 및 상기 배경 영상 중 적어도하나를 조정하는 단계를 더 포함하는 프로젝션 장치의 동작 방법."}
{"patent_id": "10-2023-0125845", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제16항에 있어서,상기 동작 방법은,프로젝션 방향을 획득하는 단계를 더 포함하고,상기 시간 정보 및 날씨 정보 중 적어도 하나에 기초하여, 상기 3차원 객체 영상 및 상기 배경 영상 중 적어도하나를 조정하는 단계는,상기 시간 정보 및 상기 프로젝션 방향에 기초하여, 상기 3차원 객체 영상 및 상기 배경 영상 중 적어도 하나에공개특허 10-2025-0042576-5-나타나는 그림자 효과를 조정하는 단계를 포함하는, 프로젝션 장치의 동작 방법."}
{"patent_id": "10-2023-0125845", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제11항 내지 제17항 중 어느 한 항에 있어서,상기 동작 방법은,상기 3차원 객체 영상에 포함되는 적어도 하나의 객체의 모양 및 크기에 기초하여, 상기 제1 영상을 상기 적어도 하나의 객체에 합성하는 단계를 더 포함하는, 프로젝션 장치의 동작 방법."}
{"patent_id": "10-2023-0125845", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제11항 내지 제18항 중 어느 한 항에 있어서,상기 동작 방법은,상기 스크린의 공간 정보에 기초하여, 상기 제2 영상의 프로젝션 방향, 프로젝션 위치 및 프로젝션 크기 중 적어도 하나를 결정하는 단계를 더 포함하는, 프로젝션 장치의 동작 방법."}
{"patent_id": "10-2023-0125845", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제11항 내지 제19항 중 어느 한 항의 방법을 수행하도록 하는 프로그램이 저장된 하나 이상의 컴퓨터로 읽을 수있는 기록매체."}
{"patent_id": "10-2023-0125845", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "일 실시예에 따른 프로젝션 장치는, 프로젝션부, 하나 이상의 인스트럭션들을 저장하는 메모리, 및 하나 이상의 인스트럭션들을 실행하는 적어도 하나의 프로세서를 포함하고, 적어도 하나의 프로세서는, 하나 이상의 인스트럭 션들을 실행함으로써, 제1 영상을 획득하고, 스크린의 공간 정보 및 사용자의 위치 정보를 획득하고, 스크린의 공간 정보 및 사용자의 위치 정보에 기초하여, 3차원 객체 영상 및 배경 영상을 생성하고, 제1 영상, 3차원 객체 영상 및 배경 영상을 합성한 제2 영상을 프로젝션하도록 프로젝션부를 제어할 수 있다."}
{"patent_id": "10-2023-0125845", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "다양한 실시예들은 영상을 프로젝션하는 프로젝션 장치 및 그 동작 방법에 관한 것이다."}
{"patent_id": "10-2023-0125845", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "프로젝션 장치는 스크린 또는 공간에 영상을 프로젝션하는 장치이다. 프로젝션 장치는, 프로젝터, 가상현실(VR: Virtual Reality), 증강현실(AR: Augmented Reality), 또는 혼합현실(MR: Mixed Reality)을 제공하는 기기 등 을 포함할 수 있다. 프로젝션 장치는 다양한 분야에서 활용되고 있으며, 예를 들어, 교실이나 회의실 등에서 강 의나 프레젠테이션을 할 때 이용될 수 있으며, 영화관에서 스크린에 영화를 프로젝션할 때 이용될 수 있다. VR, AR, 또는 MR을 제공하는 기기는 기기를 착용했을 때, 사용자의 눈 근처에 위치하는 스크린(디스플레이)에 영상 을 표시함으로써 영화관에서 영화를 시청하는 경험을 제공할 수 있다. 최근에는 프로젝터를 이용하여 홈 시어터를 구성함으로써, 큰 화면에서 영화를 감상하거나 게임을 즐기는 등 영 상 컨텐츠를 큰 화면으로 시청하는 경우가 많아지고 있다. 프로젝터를 이용하여 영상 컨텐츠를 시청함에 있어서, 영상 컨텐츠의 높은 해상도와 프로젝션 성능뿐 아니라, 시청하는 환경도 중요해지고 있다."}
{"patent_id": "10-2023-0125845", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "일 실시예에 따른 프로젝션 장치는, 프로젝션부, 하나 이상의 인스트럭션들을 저장하는 메모리, 및 상기 하나 이상의 인스트럭션들을 실행하는 적어도 하나의 프로세서를 포함할 수 있다. 상기 적어도 하나의 프로세서는, 상기 하나 이상의 인스트럭션들을 실행함으로써, 제1 영상을 획득할 수 있다. 상기 적어도 하나의 프로세서는, 상기 하나 이상의 인스트럭션들을 실행함으로써, 스크린의 공간 정보 및 사용 자의 위치 정보를 획득할 수 있다. 상기 적어도 하나의 프로세서는, 상기 하나 이상의 인스트럭션들을 실행함으로써, 상기 스크린의 공간 정보 및 상기 사용자의 위치 정보에 기초하여, 3차원 객체 영상 및 배경 영상을 생성할 수 있다. 상기 적어도 하나의 프로세서는, 상기 하나 이상의 인스트럭션들을 실행함으로써, 상기 제1 영상, 상기 3차원 객체 영상 및 상기 배경 영상을 합성한 제2 영상을 프로젝션하도록 상기 프로젝션부를 제어할 수 있다.일 실시예에 따른 프로젝션 장치의 동작 방법은, 제1 영상을 획득하는 단계를 포함할 수 있다. 일 실시예에 따른 프로젝션 장치의 동작 방법은, 스크린의 공간 정보를 획득하는 단계를 포함할 수 있다. 일 실시예에 따른 프로젝션 장치의 동작 방법은, 사용자의 위치 정보를 획득하는 단계를 포함할 수 있다. 일 실시예에 따른 프로젝션 장치의 동작 방법은, 상기 스크린의 공간 정보 및 상기 사용자의 위치 정보에 기초 하여, 3차원 객체 영상 및 배경 영상을 생성하는 단계를 포함할 수 있다. 일 실시예에 따른 프로젝션 장치의 동작 방법은, 상기 제1 영상, 상기 3차원 객체 영상 및 상기 배경 영상을 합 성한 제2 영상을 프로젝션하는 단계를 포함할 수 있다."}
{"patent_id": "10-2023-0125845", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 명세서에서 사용되는 용어에 대해 간략히 설명하고, 본 발명에 대해 구체적으로 설명하기로 한다. 본 발명에서 사용되는 용어는 본 발명에서의 기능을 고려하면서 가능한 현재 널리 사용되는 일반적인 용어들을 선택하였으나, 이는 당 분야에 종사하는 기술자의 의도 또는 판례, 새로운 기술의 출현 등에 따라 달라질 수 있 다. 또한, 특정한 경우는 출원인이 임의로 선정한 용어도 있으며, 이 경우 해당되는 발명의 설명 부분에서 상세 히 그 의미를 기재할 것이다. 따라서 본 발명에서 사용되는 용어는 단순한 용어의 명칭이 아닌, 그 용어가 가지 는 의미와 본 발명의 전반에 걸친 내용을 토대로 정의되어야 한다. 명세서 전체에서 어떤 부분이 어떤 구성요소를 \"포함\"한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다른 구성요소를 제외하는 것이 아니라 다른 구성요소를 더 포함할 수 있음을 의미한다. 또한, 명세서에 기재된 \"...부\", \"모듈\" 등의 용어는 적어도 하나의 기능이나 동작을 처리하는 단위를 의미하며, 이는 하드웨어 또는 소프트웨어로 구현되거나 하드웨어와 소프트웨어의 결합으로 구현될 수 있다. 아래에서는 첨부한 도면을 참고하여 실시예들에 대하여 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자 가 용이하게 실시할 수 있도록 상세히 설명한다. 그러나 본 발명은 여러 가지 상이한 형태로 구현될 수 있으며 여기에서 설명하는 실시예에 한정되지 않는다. 그리고 도면에서 본 발명을 명확하게 설명하기 위해서 설명과 관 계없는 부분은 생략하였으며, 명세서 전체를 통하여 유사한 부분에 대해서는 유사한 도면 부호를 붙였다. 본 명세서의 실시예에서 \"사용자\"라는 용어는 시스템, 기능 또는 동작을 제어하는 사람을 의미하며, 개발자, 관 리자 또는 설치 기사를 포함할 수 있다. 또한, 본 명세서의 실시예에서, '영상(image)' 또는 '픽처'는 정지영상, 복수의 연속된 정지영상(또는 프레임) 으로 구성된 동영상, 또는 비디오를 나타낼 수 있다. 도 1은 일 실시예에 따른 프로젝션 환경을 나타내는 도면이다. 도 1을 참조하면, 일 실시예에 따른 프로젝션 장치는 영상 컨텐츠와 가상의 공간을 나타내는 영상(10, 이하, 가상 공간 영상)을 스크린에 프로젝션할 수 있다. 이때, 영상이 프로젝션되는 스크린은 다양한 형태로 구 성될 수 있다. 프로젝션 장치가 프로젝터인 경우, 스크린은 영상 컨텐츠가 프로젝션되는 물리적인 공간을 의미할 수 있다. 예를 들어, 스크린은 벽 또는 천 소재로 된 스크린 등을 포함할 수 있다. 프로젝션 장치가 VR, AR, 또는 MR을 제공하는 기기인 경우, 스크린은 프로젝션 장치에 포함되는 디스 플레이를 의미할 수 있다. 예를 들어, VR, AR, 또는 MR을 제공하는 기기는 머리 부분에 장착 가능한 헤드 마운 트 디스플레이(HMD: Head mounted display)를 포함하는 안경형 웨어러블 디바이스 형태로 구현될 수 있으며, 디 스플레이를 포함할 수 있다. 디스플레이는 투명 디스플레이 또는 불투명 디스플레이일 수 있다. VR, AR, 또는 MR을 제공하는 기기는 영상 컨텐츠를 디스플레이로 출력(표시)할 수 있다. 이하에서는, 설명의 편의를 위해 프로젝션 장치가 프로젝터인 경우를 예로 들어 도시하고 설명하나, 프로 젝션 장치가 VR, AR, 또는 MR을 제공하는 기기인 경우에도 동일하게 적용될 수 있다. 일 실시예에 따른 프로젝션 장치는 영상 컨텐츠 뿐만 아니라 가상 공간 영상을 스크린에 함께 프 로젝션함으로써, 사용자(시청자)에게 다양한 환경에서 영상 컨텐츠를 시청하는 경험을 제공할 수 있다. 예를 들어, 가상 공간 영상은 도 1에 도시된 바와 같이, 거실의 한 벽면에 프로젝션될 수 있다. 가상 공간 영상은 윈도우, 커튼, 디스플레이 장치 등을 포함할 수 있으며, 윈도우를 통해 보여지는 바다, 도시, 산 등 의 배경 영상을 포함할 수 있다. 다만, 이에 한정되지 않는다. 이때, 프로젝션 장치는 가상 공간 영상에 포함되는 윈도우, 커튼, 디스플레이 장치 등의 객체들을 사 용자의 위치 및 시선 방향에 따라 3차원(3D) 영상(3차원 객체 영상, 30)으로 생성할 수 있다. 또한, 프로젝션 장치는 사용자가 실제로 윈도우를 통해 바다를 보는 것과 같이, 가상 공간 영상에 포함되는 배경 영상 을 사용자의 위치 및 시선 방향에 따라 생성할 수 있다. 이에 따라, 사용자에게 현실감을 제공할 수 있다. 일 실시예에 따른 프로젝션 장치는 배경 영상에 3차원 객체 영상을 오버랩시켜 합성하고, 3차원 객체 영상에 포함되는 디스플레이 장치에 영상 컨텐츠를 합성함으로써, 프로젝션할 최종 영상을 생성할 수 있다. 프로젝션 장치는 최종 영상을 스크린에 프로젝션함으로써, 사용자에게 바다뷰를 가지는 공간에서 영상 컨 텐츠를 시청하는 것과 같은 환경을 제공할 수 있다. 도 2는 일 실시예에 따른 가상 공간 영상의 구성을 나타내는 도면이다. 도 2를 참조하면, 가상 공간 영상은 배경 영상 및 3차원 객체 영상을 포함할 수 있다. 예를 들어, 일 실시예에 따른 배경 영상은 바다, 하늘, 해변, 도시, 산, 우주 등 배경을 나타내는 영상을 포함할 수 있 다. 일 실시예에 따른 3차원 객체 영상은 창문, 커튼, 선반, 의자 등의 객체들을 3차원으로 나타내는 영상을 포 함할 수 있다. 프로젝션 장치는 3차원 객체 영상에 포함되는 객체들에 사용자의 시선 방향에 따른 3차원 효과를 적용할 수 있다. 또한, 3차원 객체 영상은 영상 컨텐츠를 표시할 객체(예를 들어, 디스플레이)를 포함할 수 있다. 다만, 이에 한정되지 않는다. 일 실시예에 따른 프로젝션 장치는 3차원 객체 영상과 배경 영상을 합성하여, 가상 공간 영상(1 0)을 생성할 수 있다. 이때, 프로젝션 장치는 3차원 객체 영상을 배경 영상 상에 오버랩시킬 수있다. 일 실시예에 따른 프로젝션 장치는 가상 공간 영상과 영상 컨텐츠를 합성하여, 프로젝션할 최종 영상을 생성할 수 있다. 일 실시예에 따른 영상 컨텐츠는 사용자가 시청하기 위한 컨텐츠를 포함할 수 있다. 예를 들어, 영상 컨텐 츠는 영화, TV 프로그램, 비디오, 동영상, 온라인 스트리밍 서비스, 광고 컨텐츠 등 다양한 컨텐츠를 포함 할 수 있다. 다만, 이에 한정되지 않는다. 일 실시예에 따른 프로젝션 장치는 가상 공간 영상에 포함되는 디스플레이 객체에 영상 컨텐츠를 오버랩시킴으로써, 최종 영상을 생성할 수 있다. 이하 도면들을 참조하여, 일 실시예에 따른 프로젝션 장치가 스크린과 사용자의 시선 방향(시청 방 향)에 맞추어 가상 공간 영상을 생성하고, 가상 공간 영상에 영상 컨텐츠를 합성하여 프로젝션하는 동작들을 자세히 설명하기로 한다. 도 3은 일 실시예에 따른 프로젝션 장치의 동작 방법을 나타내는 흐름도이다. 도 3을 참조하면, 일 실시예에 따른 프로젝션 장치는 프로젝션할 영상(영상 컨텐츠)을 획득할 수 있다 (S310). 일 실시예에 따른 영상은 프로젝션 장치에 기 저장된 영상이거나, 외부 디바이스로부터 수신한 영상일 수 있다. 다만, 이에 한정되지 않는다. 또한, 일 실시예에 따른 영상은 비디오 처리부에서 디코딩, 스케일링, 노이 즈 필터링, 프레임 레이트 변환, 해상도 변환 등과 같은 다양한 영상 처리가 수행된 영상일 수 있다. 일 실시예에 따른 프로젝션 장치는 스크린의 공간 정보를 획득할 수 있다(S320). 일 실시예에 따른 프로젝션 장치는 적어도 하나의 카메라(예를 들어, 이미지 센서, 깊이 센서 등)를 이용 하여, 스크린의 공간 정보를 획득할 수 있다. 예를 들어, 프로젝션 장치는 이미지 센서로부터 스크린을 촬 영한 영상을 획득할 수 있으며, 깊이 센서로부터 스크린의 깊이 정보를 획득할 수 있다. 다만, 이에 한정되지 않는다. 또는, 일 실시예에 따른 프로젝션 장치는 외부 디바이스로부터 스크린을 촬영한 영상 및 스크린의 깊이 정 보를 수신할 수 있다. 이때, 외부 디바이스는 적어도 하나의 이미지 센서 및 깊이 센서를 포함할 수 있다. 외부 디바이스는 이미지 센서를 이용하여, 스크린을 촬영한 영상을 획득하고, 깊이 센서를 이용하여, 스크린의 깊이 정보를 획득할 수 있다. 외부 디바이스는 프로젝션 장치로 스크린을 촬영한 영상 및 스크린의 깊이 정보를 전송할 수 있다. 다만, 이에 한정되지 않는다. 프로젝션 장치는 촬영한 영상 및 깊이 정보에 기초하여, 스크린의 공간 정보를 획득할 수 있다. 스크린의 공간 정보는 스크린의 형태, 프로젝션 장치로부터 스크린까지의 거리 정보, 스크린의 위치 정보, 크기 정보, 스크린의 모서리(경계)에 대한 위치 정보 등을 포함할 수 있다. 예를 들어, 프로젝션 장치는 촬영한 영상 및 깊이 정보에 기초하여, 벽의 모서리를 인식하고, 인식된 모서 리에 기초하여, 스크린의 크기, 형태, 프로젝션 장치로부터 스크린까지의 거리 등을 식별할 수 있다. 일 실시예에 따른 프로젝션 장치는 사용자의 위치 정보를 획득할 수 있다(S330). 일 실시예에 따른 프로젝션 장치는 적어도 하나의 카메라(예를 들어, 이미지 센서, 적외선 센서 등)를 이 용하여, 사용자의 위치 정보를 획득할 수 있다. 예를 들어, 프로젝션 장치는 사용자의 존재 여부, 사용자 와 프로젝션 장치 사이의 거리, 프로젝션 장치를 기준으로 사용자가 위치한 방향 등을 식별할 수 있 다. 다만, 이에 한정되지 않는다. 일 실시예에 따른 프로젝션 장치는 스크린의 공간 정보 및 사용자의 위치 정보에 기초하여, 3D 객체 영상 및 배경 영상을 생성할 수 있다(S340). 프로젝션 장치는 사용자 입력에 기초하여, 3D 객체 영상과 배경 영상을 설정할 수 있다. 예를 들어, 프로 젝션 장치는 기 저장된 후보 템플릿 영상들 중 어느 하나를 선택하는 사용자 입력에 기초하여, 3D 객체 영 상을 설정할 수 있다. 프로젝션 장치는 영상에 포함되는 윈도우의 형태, 크기, 위치 등이 서로 다른 후보 템플릿 영상들을 기 저장할 수 있다.또는, 프로젝션 장치는 기 저장된 후보 배경 영상들 중 어느 하나를 선택하는 사용자 입력에 기초하여, 배 경 영상을 설정할 수 있다. 프로젝션 장치는 바다, 해변, 산, 도시 등의 후보 배경 영상들을 기 저장할 수 있다. 사용자 입력에 기초하여, 3D 객체 영상과 배경 영상을 설정하는 방법에 대해서는 도 5를 참조하여, 자세 히 설명하기로 한다. 또는, 프로젝션 장치는 프로젝션할 영상의 카테고리 정보에 기초하여, 배경 영상을 설정할 수 있다. 일 실시예에 따른 프로젝션 장치는 3D 객체 영상과 배경 영상이 설정되면, 스크린의 공간 정보와 사용자의 위치 정보에 기초하여, 3D 객체 영상과 배경 영상을 조정할 수 있다. 예를 들어, 프로젝션 장치는 스크린의 공간 정보에 기초하여, 3D 객체 영상과 배경 영상의 크기를 결정할 수 있다. 프로젝션 장치는 인식된 벽의 모서리에 기초하여, 벽 전체에 3D 객체 영상과 배경 영상이 프로젝 션되도록 3D 객체 영상과 배경 영상의 크기를 조절할 수 있다. 다만, 이에 한정되지 않는다. 또한, 프로젝션 장치는 스크린의 공간 정보 및 사용자의 위치 정보에 기초하여, 3D 객체 영상에 포함되는 객체들의 깊이 정보를 조절할 수 있다. 예를 들어, 사용자의 위치가 변경되면, 3D 객체 영상을 시청하는 사용자 의 시점, 시야, 시선 방향 등이 변경될 수 있다. 프로젝션 장치는 변경된 사용자의 시점, 시야, 시선 방향 등에 따라 3D 객체 영상에 나타나는 3차원 효과를 변경할 수 있다. 예를 들어, 프로젝션 장치는 변경된 사 용자의 시점, 시야, 시선 방향 등에 기초하여, 3차원 객체 영상에 포함되는 객체들의 위치, 방향, 깊이 정보 등 을 조절할 수 있다. 또한, 프로젝션 장치는 스크린의 공간 정보 및 사용자의 위치 정보에 기초하여, 배경 영상을 조정할 수 있 다. 예를 들어, 사용자의 위치 정보에 기초하여, 스크린에 프로젝션되는 배경 영상의 뷰를 조절할 수 있다. 사 용자가 왼쪽으로 이동한 경우, 프로젝션 장치는 기존 배경 영상의 오른쪽으로 영상이 추가되고, 왼쪽 일부 영역이 삭제되도록, 배경 영상을 조정할 수 있다. 이에 대해서는 도 9를 참조하여 자세히 설명하기로 한다. 일 실시예에 따른 프로젝션 장치는 프로젝션할 영상, 3D 객체 영상 및 배경 영상을 합성할 수 있다(S350). 예를 들어, 프로젝션 장치는 3D 객체 영상과 배경 영상을 합성하여, 가상 공간 영상을 생성할 수 있다. 프 로젝션 장치는 3D 객체 영상을 배경 영상 상에 오버랩시켜, 3D 객체 영상과 배경 영상을 합성할 수 있다. 또한, 프로젝션 장치는 가상 공간 영상에 프로젝션할 영상(영상 컨텐츠)를 오버랩시킴으로써, 최종 영상을 생성할 수 있다. 예를 들어, 3D 객체 영상은 프로젝션할 영상을 표시하기 위한 객체(예를 들어, 디스플레이)를 포함할 수 있다. 프로젝션 장치는 해당 객체(예를 들어, 디스플레이)에 프로젝션할 영상(영상 컨텐츠)을 오버랩시킬 수 있다. 일 실시예에 따른 프로젝션 장치는 최종 영상을 스크린 또는 공간에 프로젝션할 수 있다(S360). 일 실시예에 따른 프로젝션 장치는 시청할 영상 컨텐츠 뿐만 아니라 가상 공간 영상을 함께 스크린 또는 공간에 프로젝션함으로써, 사용자에게 다양한 환경에서 영상 컨텐츠를 시청하는 경험을 제공할 수 있다. 또한, 프로젝션 장치는 사용자(시청자)의 위치에 따라 3D 객체 영상과 배경 영상을 조정할 수 있다. 이에 따라, 가상 공간 영상에 대해 사용자가 느끼는 현실감이 향상될 수 있다. 도 4는 일 실시예에 따른 프로젝션 장치가 스크린의 공간 정보 및 사용자의 위치 정보를 획득하는 동작을 나타 내는 도면이다. 도 4를 참조하면, 일 실시예에 따른 프로젝션 장치는 적어도 하나의 센서를 포함할 수 있다. 적어도 하나 의 센서는 이미지 센서, 깊이 센서 및 적외선 센서를 포함할 수 있다. 다만, 이에 한정되지 않으며, 방향 센서, 조도 센서 등을 더 포함할 수 있다. 일 실시예에 따른 프로젝션 장치는 이미지 센서 및 깊이 센서를 이용하여, 스크린의 공간 정보를 획득할 수 있다. 이때, 이미지 센서 및 깊이 센서는 프로젝션 장치의 전방에 배치될 수 있다. 이미지 센서는 적어도 하나의 카메라를 포함할 수 있으며, 카메라의 FOV(Field of view)에 포함되는 실제 공간 을 촬영한 영상을 획득할 수 있다. 깊이 센서는 적어도 하나의 카메라를 포함할 수 있으며, 카메라의 FOV에 포함되는 실제 공간에 대한 깊이 정보 를 획득할 수 있다. 예를 들어, 깊이 센서는 프로젝션 장치와 스크린까지의 거리 등을 센싱할 수 있 다.또는, 프로젝션 장치는 외부 디바이스로부터 스크린을 포함하는 공간을 촬영한 영상 및 깊이 정보를 수신할 수 있다. 일 실시예에 따른 프로젝션 장치는 공간 정보 획득 모듈을 포함할 수 있다. 공간 정보 획득 모듈은 스크린 의 공간 정보를 획득하는 기능을 수행하는 모듈일 수 있다. 일 실시예에 따른 공간 정보 획득 모듈은 스크린의 공간 정보를 획득할 수 있도록 하는 적절한 로직, 회로, 인터페이스, 및/또는 코드를 포함할 수 있다. 공간 정보 획득 모듈은 이미지 센서에서 촬영된 영상 및 깊이 센서에서 획득한 깊이 정보 중 적어도 하나에 기 초하여, 스크린의 공간 정보를 획득할 수 있다. 예를 들어, 공간 정보 획득 모듈은 복수의 면들로 이루어진 공간에서 복수의 면들 사이의 모서리를 인식하고, 인식된 모서리에 기초하여, 영상을 프로젝션할 스크린의 경계를 결정할 수 있다. 스크린의 경계가 결 정되면, 공간 정보 획득 모듈은 스크린의 형태, 특성, 크기, 위치 등에 대한 정보를 획득할 수 있다. 다만, 이에 한정되지 않는다. 또한, 공간 정보 획득 모듈은 규칙 기반 또는 인공지능 알고리즘으로서 기계학습, 신경망 네트워크 또는 딥러닝 알고리즘 중 적어도 하나를 이용하여, 이미지 센서에서 촬영된 영상 및 깊이 센서에서 획득한 깊이 정보 중 적 어도 하나를 분석함으로써, 스크린의 공간 정보를 획득할 수 있다. 예를 들어, 공간 정보 획득 모듈은 공 간에 대한 영상 또는 깊이 정보로부터 모서리를 인식하도록 훈련된 신경망 네트워크를 이용하여, 복수의 면들로 이루어진 공간에서 모서리를 인식하여, 스크린의 공간 정보를 획득할 수 있다. 다만, 이에 한정되지 않는 다. 또한, 일 실시예에 따른 프로젝션 장치는 이미지 센서 또는 적외선 센서를 이용하여, 사용자를 인식 할 수 있다. 프로젝션 장치는 이미지 센서에서 촬영된 영상을 분석함으로써, 영상에 사용자가 존재하는 지 여부, 및 사용자가 존재하는 경우, 사용자의 위치 정보를 획득할 수 있다. 또는 프로젝션 장치는 적외선 센서를 이용하여, 사용자의 존재를 식별하고, 사용자까지의 거리 를 획득할 수 있다. 일 실시예에 따른 프로젝션 장치는 사용자 인식 모듈을 포함할 수 있다. 사용자 인식 모듈은 사용자 의 위치 정보를 획득하는 기능을 수행하는 모듈일 수 있다. 일 실시예에 따른 사용자 인식 모듈은 사용자 의 위치 정보를 획득할 수 있도록 하는 적절한 로직, 회로, 인터페이스, 및/또는 코드를 포함할 수 있다. 사용자 인식 모듈은 이미지 센서 및 적외선 센서에서 촬영된 영상 중 적어도 하나에 기초하여, 사용자의 위치 정보를 획득할 수 있다. 도 5 및 도 6은 일 실시예에 따른 프로젝션 장치가 배경 영상 및 3D 객체 영상을 생성하는 방법을 설명하기 위 한 도면이다. 도 5를 참조하면, 일 실시예에 따른 프로젝션 장치는 사용자 입력에 기초하여, 배경 영상 및 3D 객체 영상 을 설정할 수 있다. 또한, 프로젝션 장치는 사용자 입력에 기초하여, 3D 객체 영상에 포함할 디스플레이 장치(예를 들어, TV)의 종류 또는 형태를 설정할 수 있다. 일 실시예에 따른 프로젝션 장치는 설정 메뉴 화면을 스크린 또는 공간에 프로젝션할 수 있다. 일 실 시예에 따른 설정 메뉴 화면은 배경 영상, 3D 객체 영상, 디스플레이 장치의 종류 또는 형태를 설정하기 위한 메뉴들을 포함할 수 있다. 일 실시예에 따른 프로젝션 장치는 제어 장치를 통하여 메뉴들을 선택하는 사용자 입력을 수신할 수 있으 며, 사용자 입력에 기초하여, 배경 영상, 3D 객체 영상, 디스플레이 장치의 종류 또는 형태를 설정할 수 있다. 예를 들어, 설정 메뉴 화면은 기 저장된 후보 배경 영상들 중 어느 하나를 선택할 수 있는 제1 메뉴 를 포함할 수 있다. 사용자 입력에 기초하여, 기 저장된 후보 배경 영상들 중 어느 하나가 선택되는 경우, 프로 젝션 장치는 선택된 배경 영상에 기초하여, 프로젝션할 배경 영상을 생성할 수 있다. 또한, 설정 메뉴 화면은 기 저장된 후보 템플릿 영상들 중 어느 하나를 선택할 수 있는 제2 메뉴를 포함할 수 있다. 사용자 입력에 기초하여, 기 저장된 후보 템플릿 영상들 중 어느 하나가 선택되는 경우, 프로 젝션 장치는 선택된 템플릿 영상에 기초하여, 프로젝션할 3D 객체 영상을 생성할 수 있다. 또한, 도시하지는 않았지만, 설정 메뉴 화면은 프로젝션할 영상 컨텐츠를 표시하기 위한 디스플레이 객체 의 종류 또는 형태를 설정할 수 있는 메뉴를 포함할 수 있다. 다만, 이에 한정되지 않는다. 또한, 설정 메뉴 화면은 사용자 입력에 기초하여, 선택된 제1 배경 영상, 제1 템플릿 영상이 합 성된 가상 공간 영상을 나타내는 프리뷰를 포함할 수 있다. 한편, 도 5에서는 설정 메뉴 화면이 프로젝션 장치에 의해 프로젝션되는 것으로 설명하였지만, 이에 한정되지 않으며, 설정 메뉴 화면은 프로젝션 장치와 통신 연결된 외부 장치에 디스플레이될 수 있다. 예를 들어, 프로젝션 장치와 통신 연결된 외부 장치는 디스플레이를 포함할 수 있으며, 외부 장치의 디스플레이에 도 5의 설정 메뉴 화면이 디스플레이될 수 있다. 외부 장치는 사용자 입력에 기초하여 배경 영상, 템플릿 영상이 선택되면, 선택된 배경 영상 및 템플릿 영상에 대한 정보를 프로젝션 장치로 전송할 수 있다. 다만, 이에 한정되지 않는다. 도 6을 참조하면, 일 실시예에 따른 프로젝션 장치는 사용자 입력에 기초하여, 선택된 배경 영상 및 템플 릿 영상(3D 객체 영상)을 합성하여, 가상 공간 영상을 생성할 수 있다. 일 실시예에 따른 프로젝션 장치는 스크린의 공간 정보와 사용자의 위치 정보에 기초하여, 선택된 배 경 영상 및 템플릿 영상(3D 객체 영상)을 조정하고, 조정된 배경 영상과 3D 객체 영상이 합성된 가상 공간 영상을 생성할 수 있다. 예를 들어, 프로젝션 장치는 스크린의 크기, 형태, 스크린까지의 거리에 기초하여, 배경 영상과 3D 객체 영상의 크기나 형태를 결정할 수 있다. 또한, 프로젝션 장치는 스크린의 위치 정보 및 사용자의 위치 정보에 기초하여, 3D 객체 영상을 조정 할 수 있다. 예를 들어, 사용자의 위치가 변경되면, 사용자의 시점, 시선 방향, 시야 등이 변경될 수 있다. 프 로젝션 장치는 변경된 사용자의 시점, 시야, 시선 방향 등에 기초하여, 3차원 객체 영상에 포함되는 객체들의 위치, 방향, 깊이 정보 등을 조절할 수 있다. 또한, 프로젝션 장치는 변경된 사용자의 시점, 시야, 시선 방향 등에 따라 배경 영상을 조정할 수 있 다. 프로젝션 장치는 조정된 배경 영상과 3D 객체 영상을 합성한 가상 공간 영상에 프로젝션할 영상 (영상 컨텐츠)을 합성하여, 최종 영상을 생성할 수 있다. 프로젝션 장치는 최종 영상을 스크린 또는 공간 에 프로젝션할 수 있다. 도 7은 일 실시예에 따른 프로젝션 장치가 프로젝션할 영상에 기초하여, 배경 영상을 결정하는 동작을 설명하기 위한 도면이다. 도 7을 참조하면, 일 실시예에 따른 프로젝션 장치는 프로젝션할 영상(영상 컨텐츠)의 카테고리 정보에 기 초하여, 배경 영상을 결정할 수 있다. 일 실시예에 따른 프로젝션될 영상 컨텐츠는 TV 방송 프로그램일 수 있다. 프로젝션 장치는 EPG(Electronic Program Guide) 정보 또는 TV 편성표 정보를 획득할 수 있다. 프 로젝션 장치는 획득한 EPG 정보 또는 TV 편성표 정보에 기초하여, TV 방송 프로그램의 카테고리 정보를 획 득할 수 있다. 프로젝션 장치는 TV 방송 프로그램의 카테고리 정보에 기초하여, 배경 영상을 결정할 수 있 다. 예를 들어, 도 7에 도시된 바와 같이, 영상 컨텐츠가 뉴스 방송인 경우, 프로젝션 장치는 배경 영상 을 도시 뷰 영상으로 결정할 수 있다. 또는, 프로젝션 장치는 영상 컨텐츠가 자연 다큐멘터리 프로그램인 경우, 배경 영상을 숲 뷰 영상 또는 바다 뷰 영상으로 결정할 수 있다. 또는, 프로젝션 장치는 영상 컨텐츠가 예능 프로그램인 경우, 배경 영상을 테마파크 뷰 영상으로 결정할 수 있다. 또는, 프로젝션 장치는 영상 컨텐츠의 이름, 제목 등에 기초하여, 배경 영상을 결정할 수 있다. 예를 들어, 프로젝션 장치는 영상 컨텐츠의 제목에 \"동물\"이 포함되거나, 영상 컨텐츠가 동물과 관련된 컨텐츠 인 경우, 배경 영상을 숲 뷰 영상으로 결정할 수 있다. 다만, 이에 한정되지 않는다. 또는, 프로젝션 장치는 프로젝션할 영상 컨텐츠를 분석하여, 영상의 분위기나 테마 등에 대한 정보를 획득 할 수 있다. 예를 들어, 프로젝션 장치는 영상을 분석하여, 영상의 카테고리, 분위기나 테마 등에 대한 정보를 획득할 수 있도록 동작하는 적절한 로직, 회로, 인터페이스, 및/또는 코드를 포함하는 영상 분석 모듈을 포함할 수 있다. 영상 분석 모듈은 하나 이상의 뉴럴 네트워크들을 이용하여, 영상의 카테고리, 분위기나 테마 등에 대한 정보를 획득할 수 있다. 프로젝션 장치는 영상의 분위기나 테마 등에 대한 정보에 기초하여, 배 경 영상을 결정할 수 있다. 도 8은 일 실시예에 따른 프로젝션 장치의 동작 방법을 나타내는 흐름도이다. 도 8을 참조하면, 일 실시예에 따른 프로젝션 장치는 프로젝션할 영상을 획득할 수 있다(S810). 일 실시예에 따른 영상은 프로젝션 장치에 기 저장된 영상이거나, 외부 디바이스로부터 수신한 영상일 수 있다. 다만, 이에 한정되지 않는다. 또한, 일 실시예에 따른 영상은 비디오 처리부에서 디코딩, 스케일링, 노이 즈 필터링, 프레임 레이트 변환, 해상도 변환 등과 같은 다양한 영상 처리가 수행된 영상일 수 있다. 또한, 프로젝션 장치가 비디오 컨텐츠를 프로젝션하는 경우, 프로젝션 장치는 비디오 컨텐츠에 포함 되는 비디오 프레임 영상들을 순차적으로 획득할 수 있다. 일 실시예에 따른 프로젝션 장치는 사용자 위치의 변경 여부를 식별할 수 있다(S820). 예를 들어, 프로젝션 장치는 적어도 하나의 카메라(예를 들어, 이미지 센서, 적외선 센서 등)를 이용하여, 프로젝션 장치 주변의 사용자를 인식하고, 사용자의 위치가 변경되는 지 여부를 식별할 수 있다. 일 실시예에 따른 프로젝션 장치는 사용자의 위치 변경이 없는 경우, 이전 프레임 영상을 프로젝션할 때 이용된 가상 공간 영상을 변경하지 않고 유지할 수 있다(S830). 예를 들어, 프로젝션 장치는 사용자의 위치가 변경되지 않는 경우, 이전 프레임 영상과 함께 프로젝션된 3 차원 객체 영상과 배경 영상을 계속해서 유지할 수 있다. 반면에, 프로젝션 장치는 사용자의 위치 변경이 있는 경우, 3차원 객체 영상 및 배경 영상을 변경할 수 있 다(S840). 예를 들어, 사용자의 위치가 변경되면, 스크린에 프로젝션되는 3차원 객체 영상 및 배경 영상을 시청하는 사용 자의 시점, 시야, 시선 방향 등이 변경될 수 있다. 프로젝션 장치는 변경된 사용자의 시점, 시야, 시선 방 향 등에 따라 3차원 객체 영상에 나타나는 3차원 효과를 변경할 수 있다. 예를 들어, 프로젝션 장치는 변 경된 사용자의 시점, 시야, 시선 방향 등에 기초하여, 3차원 객체 영상에 포함되는 객체들의 위치, 방향, 깊이 정보 등을 조절할 수 있다. 또한, 프로젝션 장치는 변경된 사용자의 시점, 시야, 시선 방향 등에 따라 배경 영상을 조정할 수 있다. 일 실시예에 따른 프로젝션 장치는 프로젝션할 영상, 3D 객체 영상 및 배경 영상을 합성할 수 있다(S850). 예를 들어, 프로젝션 장치는 3D 객체 영상과 배경 영상을 합성하여, 가상 공간 영상을 생성할 수 있다. 프 로젝션 장치는 3D 객체 영상을 배경 영상 상에 오버랩시켜, 3D 객체 영상과 배경 영상을 합성할 수 있다. 또한, 프로젝션 장치는 가상 공간 영상에 프로젝션할 영상(영상 컨텐츠)을 오버랩시킴으로써, 최종 영상을 생성할 수 있다. 예를 들어, 3D 객체 영상은 프로젝션할 영상을 표시하기 위한 객체(예를 들어, 디스플레이)를 포함할 수 있다. 프로젝션 장치는 해당 객체(예를 들어, 디스플레이)에 프로젝션할 영상(영상 컨텐츠)을 오버랩시킬 수 있다. 일 실시예에 따른 프로젝션 장치는 최종 영상을 스크린 또는 공간에 프로젝션할 수 있다(S860). 일 실시예에 따른 프로젝션 장치는 시청할 영상 컨텐츠 뿐만 아니라 가상 공간 영상을 함께 스크린 또는 공간에 프로젝션함으로써, 사용자에게 다양한 환경에서 영상 컨텐츠를 시청하는 경험을 제공할 수 있다. 또한, 프로젝션 장치는 사용자(시청자)의 위치에 따라 3D 객체 영상과 배경 영상을 조정할 수 있다. 이에 따라, 가상 공간 영상에 대해 사용자가 느끼는 현실감이 향상될 수 있다. 도 9는 일 실시예에 따른 프로젝션 장치가 사용자 위치가 변경됨에 따라, 가상 공간 영상을 변경하는 동작을 설 명하기 위한 도면이다. 도 9를 참조하면, 일 실시예에 따른 프로젝션 장치는 스크린의 공간 정보 및 사용자의 위치 정 보를 획득할 수 있다. 프로젝션 장치는 스크린의 공간 정보 및 사용자의 위치 정보에 기초하여, 제1 3차원 객체 영상 및 제1 배경 영상을 생성할 수 있다.프로젝션 장치는 제1 3차원 객체 영상과 제1 배경 영상을 합성하여, 제1 가상 공간 영상을 생성 할 수 있다. 프로젝션 장치는 제1 3차원 객체 영상을 제1 배경 영상 상에 오버랩시켜, 제1 3차 원 객체 영상과 제1 배경 영상을 합성할 수 있다. 또한, 프로젝션 장치는 제1 가상 공간 영상에 프로젝션할 영상을 오버랩시킴으로써, 제1 최종 영상을 생성 할 수 있다. 프로젝션 장치는 스크린 또는 공간에 제1 최종 영상을 프로젝션할 수 있다. 일 실시예에 따른 프로젝션 장치는 사용자의 위치 변경을 감지할 수 있다. 예를 들어, 프로젝션 장치 는 적어도 하나의 카메라를 이용하여, 사용자의 위치가 제1 지점에서 제2 지점으로 변경된 것을 감지 할 수 있다. 사용자의 위치가 제1 지점에서 제2 지점으로 변경된 경우, 프로젝션 장치는 제1 가상 공간 영상을 변 경할 수 있다. 예를 들어, 사용자가 왼쪽으로 이동한 경우, 사용자의 시점, 시선 방향, 시야 등이 변경될 수 있다. 프로젝션 장치는 변경된 사용자의 시점, 시야, 시선 방향 등에 기초하여, 제1 3차원 객체 영상 에 포함되는 객체들의 위치, 방향, 깊이 정보 등을 조절할 수 있다. 예를 들어, 프로젝션 장치는 제1 3차 원 객체 영상에 포함되는 윈도우의 왼쪽 벽면의 깊이가 감소하고, 윈도우의 오른쪽 벽면의 깊이가 증가하 도록 제2 3차원 객체 영상을 생성할 수 있다. 다만, 이에 한정되지 않는다. 또한, 프로젝션 장치는 변경된 사용자의 시점, 시야, 시선 방향 등에 기초하여, 제1 배경 영상을 조 정할 수 있다. 프로젝션 장치는 변경된 사용자의 시점, 시야, 시선 방향 등에 따라 윈도우를 통해 보여지 는 뷰가 변경되도록 제1 배경 영상을 조정할 수 있다. 예를 들어, 사용자가 왼쪽으로 이동한 경우, 프로젝션 장치는 제1 배경 영상의 오른쪽으로 영상이 추가되고, 제1 배경 영상의 왼쪽 일부 영 역이 삭제된 제2 배경 영상을 생성할 수 있다. 다만, 이에 한정되지 않는다. 도 10은 일 실시예에 따른 프로젝션 장치의 동작 방법을 나타내는 흐름도이다. 도 10을 참조하면, 일 실시예에 따른 프로젝션 장치는 프로젝션할 영상을 획득할 수 있다(S1010). 일 실시예에 따른 영상은 프로젝션 장치에 기 저장된 영상이거나, 외부 디바이스로부터 수신한 영상일 수 있다. 다만, 이에 한정되지 않는다. 또한, 일 실시예에 따른 영상은 비디오 처리부에서 디코딩, 스케일링, 노이 즈 필터링, 프레임 레이트 변환, 해상도 변환 등과 같은 다양한 영상 처리가 수행된 영상일 수 있다. 또한, 프로젝션 장치가 비디오 컨텐츠를 프로젝션하는 경우, 프로젝션 장치는 비디오 컨텐츠에 포함 되는 비디오 프레임 영상들을 순차적으로 획득할 수 있다. 일 실시예에 따른 프로젝션 장치는 시간 정보 또는 날씨 정보의 변경 여부를 식별할 수 있다(S1020). 예를 들어, 프로젝션 장치는 외부 디바이스 또는 서버로부터 시간 정보 또는 날씨 정보를 획득할 수 있다. 또는, 프로젝션 장치는 내부 타이머를 이용하여, 시간 정보를 획득할 수 있다. 다만, 이에 한정되지 않는 다. 일 실시예에 따른 프로젝션 장치는 시간 정보 또는 날씨 정보의 변경이 없는 경우, 프로젝션 중인 가상 공 간 영상을 변경하지 않고 유지할 수 있다(S1030). 예를 들어, 프로젝션 장치는 시간 정보 또는 날씨 정보가 변경되지 않는 경우, 이전 프레임 영상과 함께 프로젝션된 3차원 객체 영상과 배경 영상을 계속해서 유지할 수 있다. 반면에, 프로젝션 장치는 시간 정보 또는 날씨 정보의 변경이 있는 경우, 3차원 객체 영상 및 배경 영상을 변경할 수 있다(S1040). 예를 들어, 프로젝션 장치는 시간 정보가 낮 시간대에서 밤 시간대로 변경되면, 배경 영상을 야경을 나타 내는 영상으로 변경할 수 있다. 또는, 프로젝션 장치는 시간 정보에 기초하여, 배경 영상 및 3차원 객체 영상에 나타나는 그림자 효과를 조절할 수 있다. 또한, 프로젝션 장치는 날씨 정보에 기초하여, 현재 날씨가 배경 영상에 나타나도록 배경 영상을 변경할 수 있다. 예를 들어, 현재 날씨가 비나 눈이 내리는 날씨인 경우, 프로젝션 장치는 배경 영상을 비나 눈이 내리는 배경 영상으로 변경할 수 있다. 다만, 이에 한정되지 않는다.일 실시예에 따른 프로젝션 장치는 프로젝션할 영상, 3차원 객체 영상 및 배경 영상을 합성할 수 있다 (S1050). 예를 들어, 프로젝션 장치는 3D 객체 영상과 배경 영상을 합성하여, 가상 공간 영상을 생성할 수 있다. 프 로젝션 장치는 3D 객체 영상을 배경 영상 상에 오버랩시켜, 3D 객체 영상과 배경 영상을 합성할 수 있다. 또한, 프로젝션 장치는 가상 공간 영상에 프로젝션할 영상(영상 컨텐츠)을 오버랩시킴으로써, 최종 영상을 생성할 수 있다. 예를 들어, 3D 객체 영상은 프로젝션할 영상을 표시하기 위한 객체(예를 들어, 디스플레이)를 포함할 수 있다. 프로젝션 장치는 해당 객체(예를 들어, 디스플레이)에 프로젝션할 영상(영상 컨텐츠)을 오버랩시킬 수 있다. 일 실시예에 따른 프로젝션 장치는 최종 영상을 스크린 또는 공간에 프로젝션할 수 있다(S1060). 일 실시예에 따른 프로젝션 장치는 시청할 영상 컨텐츠 뿐만 아니라 가상 공간 영상을 함께 스크린 또는 공간에 프로젝션함으로써, 사용자에게 다양한 환경에서 영상 컨텐츠를 시청하는 경험을 제공할 수 있다. 또한, 프로젝션 장치는 시간 정보 또는 날씨 정보에 따라 3D 객체 영상과 배경 영상을 조정할 수 있다. 이에 따 라, 가상 공간 영상에 대해 사용자가 느끼는 현실감이 향상될 수 있다. 도 11은 일 실시예에 따른 프로젝션 장치가 시간 정보가 변경됨에 따라, 가상 공간 영상을 변경하는 동작을 설 명하기 위한 도면이다. 도 11을 참조하면, 일 실시예에 따른 프로젝션 장치는 현재 시간 정보를 획득할 수 있다. 예를 들어, 프로 젝션 장치는 외부 디바이스 또는 외부 서버로부터 현재 시간 정보를 수신할 수 있다. 또는, 프로젝션 장치 는 내부 타이머를 이용하여, 시간 정보를 획득할 수 있다. 다만, 이에 한정되지 않는다. 일 실시예에 따른 프로젝션 장치는 현재 시간 정보를 배경 영상에 적용할 수 있다. 예를 들어, 도 11에 도 시된 바와 같이, 현재 시간이 낮 시간대(예를 들어, 오후 1시)인 경우, 프로젝션 장치는 배경 영상을 낮의 도시뷰로 설정할 수 있다. 또한, 프로젝션 장치는 현재 시간 정보에 기초하여, 해당 시간의 해의 위 치와 프로젝션 방향 등에 기초하여, 배경 영상 및 3차원 객체 영상에 나타나는 그림자 효과를 조절할 수 있다. 반면에, 현재 시간이 밤 시간대(예를 들어, 오후 10시)인 경우, 프로젝션 장치는 배경 영상을 밤의 도시뷰 로 변경할 수 있다. 또한, 프로젝션 장치는 현재 시간 정보에 기초하여, 3차원 객체 영상의 색감이 나 밝기 등을 조절할 수 있다. 다만, 이에 한정되지 않는다. 일 실시예에 따른 프로젝션 장치는 현재 시간 정보에 따라 3D 객체 영상과 배경 영상을 조정함으로써, 가 상 공간 영상에 대해 사용자가 느끼는 현실감을 향상시킬 수 있다. 도 12 및 도 13은 일 실시예에 따른 프로젝션 장치가 다양한 가상 공간 영상을 제공하는 예시들을 나타내는 도 면들이다. 도 12를 참조하면, 일 실시예에 따른 프로젝션 장치는 동굴을 포함하는 객체 영상 및 해안 뷰를 나타내는 배경 영상을 포함하는 가상 공간 영상을 프로젝션할 수 있다. 프로젝션 장치는 스크린의 공간 정보 및 사용자의 위치 정보에 기초하여, 사용자는 동굴 내부에 위 치하고, 사용자의 시각에서 동굴 외부를 바라보는 느낌을 가지도록 가상 공간 영상을 생성할 수 있 다. 예를 들어, 프로젝션 장치는 사용자가 스크린에 가까이 이동할수록 동굴 외부를 향해 이동하는 느낌 이 들도록 동굴을 나타내는 영상의 밝기를 조절할 수 있다. 또한, 프로젝션 장치는 사용자가 스크린 에 가까이 이동할수록 배경 영상에서 표시되지 않았던 부분도 더 표시되도록 해안 뷰도 조정할 수 있다. 다만, 이에 한정되지 않는다. 또한, 도 13을 참조하면, 일 실시예에 따른 프로젝션 장치는 차원 변경 효과를 나타내는 가상 공간 영상 을 프로젝션할 수 있다. 예를 들어, 프로젝션 장치는 도 13에 도시된 바와 같이, 다른 시공간과의 연결 통로를 나타내는 객체(1330, 예를 들어, 웜홀(wormhole))를 포함하는 객체 영상과 연결 통로 안에 배경 영 상이 나타나는 가상 공간 영상을 생성할 수 있다. 또한, 프로젝션 장치는 연결 통로를 나타내는 객 체 내에 영상 컨텐츠를 프로젝션할 수 있다. 다만, 이에 한정되지 않는다. 일 실시예에 따른 프로젝션 장치는 다양한 가상 공간 영상을 생성하여, 영상 컨텐츠와 함께 프로젝션함으 로써, 사용자에게 다양한 시청 경험을 제공할 수 있다. 도 14는 복수의 사용자가 인식되는 경우, 일 실시예에 따른 프로젝션 장치의 동작을 설명하기 위한 도면이다. 일 실시예에 따른 프로젝션 장치는 제1 사용자를 인식할 수 있다. 프로젝션 장치는 인식된 제1 사용자의 위치 정보 및 스크린의 공간 정보에 기초하여, 3차원 객체 영상과 배경 영상을 생성할 수 있다. 프로젝션 장치는 3차원 객체 영상과 배경 영상을 합성하여 가상 공간 영상을 생성하고, 가상 공간 영상에 프로젝션할 영상을 합성하여 최종 영상을 생성할 수 있다. 프로젝션 장치는 스크린에 최종 영상을 프로젝 션할 수 있다. 프로젝션 장치는 제1 사용자의 위치에 기초하여, 최종 영상을 프로젝션하는 도중에 제2 사용자 를 추가로 인식할 수 있다. 프로젝션 장치는 제2 사용자가 추가로 인식되는 경우, 가상 공간 영상 프로젝션을 종료할 지 여부를 묻는 알림 메시지를 스크린 또는 공간에 프로젝션할 수 있다. 가상 공간 영상 프로젝션을 종료시키는 경 우, 프로젝션 장치는 프로젝션할 영상(영상 컨텐츠)만 스크린 또는 공간에 프로젝션할 수 있다. 또는, 프로젝션 장치는 제2 사용자가 위치한 지점과 제1 사용자가 위치한 지점 사이의 거리가 기 설정된 값 미만인 경우, 알림 메시지를 프로젝션하지 않고, 계속해서 최종 영상을 프로젝션할 수 있다. 또는, 프로젝션 장치는 제2 사용자의 위치를 제1 사용자 근처로 이동하라는 알림 메시지를 스 크린 또는 공간에 프로젝션할 수 있다. 다만, 이에 한정되지 않는다. 도 15는 일 실시예에 따른 프로젝션 장치가 가상 공간 영상을 프로젝션하는 동작을 설명하기 위한 도면이다. 도 15를 참조하면, 일 실시예에 따른 프로젝션 장치는 프로젝션할 스크린 또는 공간에 디스플레이 장치 가 존재할 수 있다. 일 실시예에 따른 디스플레이 장치는 디스플레이를 포함하는 TV, 스마트 모니 터, 비디오 월(Video wall), 디지털 사이니지(Digital Signage) 등과 같은 다양한 형태로 구현될 수 있다. 또한, 디스플레이 장치는 고정된 위치에 배치되는 고정형 전자 장치일 수 있다. 다만, 이에 한정되는 것 은 아니다. 프로젝션 장치는 스크린 또는 공간에 도 1 내지 도 14에서 설명한 방법으로 생성된 가상 공간 영상을 프로 젝션할 수 있다. 이때, 가상 공간 영상에 포함되는 3D 객체 영상에는 디스플레이 객체가 포함되지 않을 수 있다. 영상 컨텐츠는 디스플레이 장치를 통해 디스플레이될 수 있다. 일 실시예에 따른 프로젝션 장치는 디스플레이 장치의 위치, 크기, 형상 등을 인식하고, 인식된 디 스플레이 장치의 위치, 크기, 형상 등에 기초하여, 가상 공간 영상을 생성할 수 있다. 다만, 이에 한정되 지 않는다. 또한, 일 실시예에 따른 프로젝션 장치와 디스플레이 장치는 서로 통신 연결될 수 있다. 디스플레이 장치는 디스플레이되는 영상 컨텐츠에 대한 정보를 프로젝션 장치로 전송할 수 있다. 프로젝션 장치 는 영상 컨텐츠에 대한 정보에 기초하여, 가상 공간 영상을 생성할 수 있다. 예를 들어, 프로젝션 장치 는 영상 컨텐츠의 카테고리 정보, 분위기나 테마 등에 대한 정보에 기초하여, 3D 객체 영상 또는 배경 영 상을 결정할 수 있다. 다만, 이에 한정되지 않는다.한편, 도 1 내지 도 15에서는 일 실시예에 따른 프로젝션 장 치의 동작들을 설명하였으나, 상기 설명한 동작들은 프로젝션 장치의 동작들로 한정되지 않는다. 예 를 들어, 도 1 내지 도 15에서 설명한 일 실시예에 따른 프로젝션 장치의 동작들은 디스플레이를 포함하는 디스플레이 장치에 의해 수행될 수 있다. 디스플레이 장치는 대형 디스플레이를 포함할 수 있다. 디스플레이 장 치는 도 1 내지 도 15에서 설명한 3차원 객체 영상 및 배경 영상을 포함하는 가상 공간 영상을 생성할 수 있다. 또한, 디스플레이 장치는 가상 공간 영상에 영상 컨텐츠를 합성하여 디스플레이에 표시할 수 있다. 예를 들어, 디스플레이 장치는 적어도 하나의 카메라를 이용하여, 사용자의 위치 정보를 획득할 수 있다. 디스 플레이 장치는 디스플레이의 크기 및 사용자의 위치 정보에 기초하여, 배경 영상 및 3차원 객체 영상을 생성 또 는 조절할 수 있다. 디스플레이 장치는 사용자의 위치가 변경되면, 3차원 객체 영상에 나타나는 3차원 효과를 변경할 수 있다. 또한, 디스플레이 장치는 사용자의 위치 정보에 기초하여, 디스플레이에 표시되는 배경 영상의 뷰를 조절할 수 있다. 또는, 디스플레이 장치는 시간 정보 또는 날씨 정보에 기초하여, 3차원 객체 영상 및 배 경 영상을 변경 또는 조절할 수 있다. 디스플레이 장치는 상기 도 1 내지 도 15에서 설명한 프로젝션 장치의 동작들을 적용함으로써, 상기 예시 한 동작들을 수행할 수 있다. 또한, 상기 예시한 동작들 이외에도 도 1 내지 도 15에서 설명한 프로젝션 장치 의 동작들은 디스플레이 장치에 의해 수행될 수 있다. 디스플레이 장치는 시청할 영상 컨텐츠 뿐만 아니라 가상 공간 영상을 함께 디스플레이함으로써, 사용자에게 다 양한 환경에서 영상 컨텐츠를 시청하는 경험을 제공할 수 있다. 또한, 디스플레이 장치는 사용자(시청자)의 위 치에 따라 3차원 객체 영상과 배경 영상을 조정함으로써, 가상 공간 영상에 대해 사용자가 느끼는 현실감이 향 상될 수 있다. 도 16은 일 실시예에 따른 프로젝션 장치의 구성을 나타내는 블록도이다. 도 16을 참조하면, 일 실시예에 따른 프로젝션 장치는 센서부, 프로세서, 메모리, 프로젝 션부, 및 통신부를 포함할 수 있다. 일 실시예에 따른 센서부는 프로젝션 장치 주변의 상태를 감지하고, 감지된 정보를 프로세서로 전달할 수 있다. 센서부는 이미지 센서, 깊이 센서, 적외선 센서 등을 포함할 수 있다. 일 실시예에 따른 이미지 센서는 정지 영상 또는 동영상 등의 화상 프레임을 획득할 수 있다. 예를 들어, 이미 지 센서는 프로젝션 장치 외부의 이미지를 촬영할 수 있다. 이때, 이미지 센서를 통해 촬영된 이미지는 프 로세서 또는 별도의 이미지 프로세서를 통해 처리될 수 있다. 일 실시예에 따른 깊이 센서는 공간에 포함되는 하나 이상의 객체들에 대한 깊이 정보를 획득할 수 있다. 깊이 정보는 깊이 센서로부터 특정 객체까지의 거리에 대응할 수 있으며, 깊이 센서로부터 특정 객체까지의 거리가 멀수록 깊이 값은 커질 수 있다. 일 실시예에 따른 깊이 센서는 다양한 방식으로 객체의 깊이 정보를 획득할 수 있으며, 예를 들어, TOF(Time of flight) 방식, 스테레오 이미지(Stereo Image) 방식, 구조화된 광(Structured Light) 방식 중 적어도 하나의 방식을 이용하여, 깊이 정보를 획득할 수 있다. 일 실시예에 따른 깊이 센서는 적어도 하나의 카메라를 포함할 수 있으며, 깊이 센서에 포함되는 카메라의 FOV 에 포함되는 실제 공간에 대한 깊이 정보를 획득할 수 있다. 또한, 센서부는 이미지 센서, 깊이 센서, 적외선 센서 이외에도 가속도 센서, 위치 센서, 온/습도 센서, 조도 센서, 지자기 센서, 자이로스코프 센서, 및 마이크로폰 등을 포함할 수 있다. 다만, 이에 한정되지 않는다. 일 실시예에 따른 통신부는 외부 장치 또는 서버와 데이터 또는 신호를 송수신할 수 있다. 예를 들어, 통 신부는 와이- 파이(Wi-Fi) 모듈, 블루투스 모듈, 적외선 통신 모듈 및 무선 통신 모듈, LAN 모듈, 이더넷 (Ethernet) 모듈, 유선 통신 모듈 등을 포함할 수 있다. 이때, 각 통신 모듈은 적어도 하나의 하드웨어 칩 형태 로 구현될 수 있다. 와이 파이 모듈, 블루투스 모듈은 각각 Wi-Fi 방식, 블루투스 방식으로 통신을 수행한다. 와이 파이 모듈이나 블루투스 모듈을 이용하는 경우에는 SSID 및 세션 키 등과 같은 각종 연결 정보를 먼저 송수신하고, 이를 이용 하여 통신 연결한 후 각종 정보들을 송수신할 수 있다. 무선 통신 모듈은 지그비(zigbee), 3G(3rd Generation), 3GPP(3rd Generation Partnership Project), LTE(Long Term Evolution), LTE-A(LTE Advanced), 4G(4th Generation), 5G(5th Generation) 등과 같은 다양한 무선 통신 규격에 따라 통신을 수행하는 적어도 하나의 통 신 칩을 포함할 수 있다. 일 실시예에 따른 통신부는 외부 장치로부터 프로젝션할 영상 또는 영상 컨테츠를 수신할 수 있다. 또한, 일 실시예에 따른 통신부는 외부 장치 또는 외부 서버로부터 시간 정보, 날씨 정보 등을 수신할 수 있다. 또한, 일 실시예에 따른 통신부는 제어 장치와 통신을 수행할 수 있다. 통신부는 제어 장치로부터 사 용자 입력에 대응하는 신호를 수신할 수 있다. 일 실시예에 따른 프로세서는 프로젝션 장치의 전반적인 동작 및 프로젝션 장치의 내부 구성 요 소들 사이의 신호 흐름을 제어하고, 데이터를 처리하는 기능을 수행한다. 프로세서는 싱글 코어, 듀얼 코어, 트리플 코어, 쿼드 코어 및 그 배수의 코어를 포함할 수 있다. 또한, 프로세서는 복수의 프로세서들을 포함할 수 있다. 예를 들어, 프로세서는 메인 프로세서(main processor, 도시되지 아니함) 및 서브 프로세서(sub processor, 도시되지 아니함)로 구현될 수 있다.또한, 프로세서는 CPU(Cetral Processing Unit), GPU (Graphic Processing Unit) 및 VPU(Video Processing Unit) 중 적어도 하나를 포함할 수 있다. 또는, 실시예에 따라, CPU, GPU 및 VPU 중 적어도 하나를 통합한 SoC(System On Chip) 형태로 구현될 수 있다. 또는, 프로세서는 NPU(Neural Processing Unit)를 더 포함할 수 있다. 일 실시예에 따른 메모리는 프로젝션 장치를 구동하고 제어하기 위한 다양한 데이터, 프로그램 또는 어플리케이션을 저장할 수 있다. 또한, 메모리에 저장되는 프로그램은 하나 이상의 인스트럭션들을 포함할 수 있다. 메모리에 저장된 프로그램(하나 이상의 인스트럭션들) 또는 어플리케이션은 프로세서에 의해 실행될 수 있다. 일 실시예에 따른 프로세서는 상기 메모리에 저장된 하나 이상의 인스트럭션들을 실행함으로써, 프로 젝션할 영상을 획득할 수 있다. 일 실시예에 따른 영상은 메모리에 기 저장된 영상이거나, 통신부를 통해 외부 디바이스로부터 수신한 영상일 수 있다. 또한, 영상은 비디오 처리부에서 디코딩, 스케일링, 노이즈 필터링, 프레임 레이트 변환, 해상도 변환 등과 같은 다양한 영상 처리가 수행된 영상일 수 있다. 일 실시예에 따른 프로세서는 메모리에 저장된 하나 이상의 인스트럭션들을 실행함으로써, 프로젝션 할 영상(영상 컨텐츠)을 획득할 수 있다. 일 실시예에 따른 영상은 메모리에 기 저장된 영상이거나, 통신 부를 통하여, 외부 디바이스로부터 수신한 영상일 수 있다. 다만, 이에 한정되지 않는다. 또한, 일 실시예 에 따른 영상은 비디오 처리부에서 디코딩, 스케일링, 노이즈 필터링, 프레임 레이트 변환, 해상도 변환 등과 같은 다양한 영상 처리가 수행된 영상일 수 있다. 일 실시예에 따른 프로세서는 메모리에 저장된 하나 이상의 인스트럭션들을 실행함으로써, 스크린의 공간 정보를 획득할 수 있다. 예를 들어, 프로세서는 센서부에 포함된 이미지 센서로부터 스크린을 촬영한 영상을 획득할 수 있으며, 센서부에 포함된 깊이 센서로부터 스크린의 깊이 정보를 획득할 수 있다. 다만, 이에 한정되지 않는다. 또는, 프로세서는 통신부를 통해, 외부 디바이스로부터 스크린을 촬영한 영상 및 스크린의 깊이 정보 를 수신할 수 있다. 프로세서는 촬영한 영상 및 깊이 정보에 기초하여, 스크린의 공간 정보를 획득할 수 있다. 스크린의 공간 정보는 스크린의 형태, 프로젝션 장치로부터 스크린까지의 거리 정보, 스크린의 위치 정보, 크기 정보, 스 크린의 모서리(경계)에 대한 위치 정보 등을 포함할 수 있다. 일 실시예에 따른 프로세서는 메모리에 저장된 하나 이상의 인스트럭션들을 실행함으로써, 사용자의 위치 정보를 획득할 수 있다. 예를 들어, 프로세서는 센서부에 포함된 이미지 센서 또는 적외선 센서를 이용하여, 사용자의 위치 정보를 획득할 수 있다. 프로세서는 사용자의 존재 여부, 사용자와 프로젝션 장치 사이의 거리, 프로 젝션 장치를 기준으로 사용자가 위치한 방향 등을 식별할 수 있다. 다만, 이에 한정되지 않는다. 일 실시예에 따른 프로세서는 메모리에 저장된 하나 이상의 인스트럭션들을 실행함으로써, 스크린의 공간 정보 및 사용자의 위치 정보에 기초하여, 3D 객체 영상 및 배경 영상을 생성할 수 있다. 프로세서는 사용자 입력에 기초하여, 3D 객체 영상과 배경 영상을 설정할 수 있다. 예를 들어, 프로세서 는 메모리에 기 저장된 후보 템플릿 영상들 중 어느 하나를 선택하는 사용자 입력에 기초하여, 3D 객 체 영상을 설정할 수 있다. 메모리는 영상에 포함되는 윈도우의 형태, 크기, 위치 등이 서로 다른 후보 템 플릿 영상들을 기 저장할 수 있다. 또는, 프로세서는 메모리에 기 저장된 후보 배경 영상들 중 어느 하나를 선택하는 사용자 입력에 기초하여, 배경 영상을 설정할 수 있다. 메모리는 바다, 해변, 산, 도시 등의 후보 배경 영상들을 기 저장할 수 있다. 또는, 프로세서는 프로젝션할 영상의 카테고리 정보에 기초하여, 배경 영상을 설정할 수 있다. 일 실시예에 따른 프로세서는 메모리에 저장된 하나 이상의 인스트럭션들을 실행함으로써, 3D 객체 영상과 배경 영상이 설정되면, 스크린의 공간 정보와 사용자의 위치 정보에 기초하여, 3D 객체 영상과 배경 영 상을 조정할 수 있다. 예를 들어, 프로세서는 스크린의 공간 정보에 기초하여, 3D 객체 영상과 배경 영상의 크기를 결정할 수 있 다. 프로세서는 인식된 벽의 모서리에 기초하여, 벽 전체에 3D 객체 영상과 배경 영상이 프로젝션되도록3D 객체 영상과 배경 영상의 크기를 조절할 수 있다. 다만, 이에 한정되지 않는다. 또한, 프로세서는 스크린의 공간 정보 및 사용자의 위치 정보에 기초하여, 3D 객체 영상에 포함되는 객체 들의 깊이 정보를 조절할 수 있다. 예를 들어, 사용자의 위치가 변경되면, 3D 객체 영상을 시청하는 사용자의 시점, 시야, 시선 방향 등이 변경될 수 있다. 프로세서는 변경된 사용자의 시점, 시야, 시선 방향 등에 따 라 3D 객체 영상에 나타나는 3차원 효과를 변경할 수 있다. 예를 들어, 프로세서는 변경된 사용자의 시점, 시야, 시선 방향 등에 기초하여, 3차원 객체 영상에 포함되는 객체들의 위치, 방향, 깊이 정보 등을 조절할 수 있다. 또한, 프로세서는 스크린의 공간 정보 및 사용자의 위치 정보에 기초하여, 배경 영상을 조정할 수 있다. 예를 들어, 사용자의 위치 정보에 기초하여, 스크린에 프로젝션되는 배경 영상의 뷰를 조절할 수 있다. 사용자 가 왼쪽으로 이동한 경우, 프로세서는 기존 배경 영상의 오른쪽으로 영상이 추가되고, 왼쪽 일부 영역이 삭제되도록, 배경 영상을 조정할 수 있다. 일 실시예에 따른 프로세서는 메모리에 저장된 하나 이상의 인스트럭션들을 실행함으로써, 프로젝션 할 영상, 3D 객체 영상 및 배경 영상을 합성할 수 있다. 예를 들어, 프로세서는 3D 객체 영상과 배경 영상을 합성하여, 가상 공간 영상을 생성할 수 있다. 프로세 서는 3D 객체 영상을 배경 영상 상에 오버랩시켜, 3D 객체 영상과 배경 영상을 합성할 수 있다. 또한, 프로세서는 가상 공간 영상에 프로젝션할 영상(영상 컨텐츠)를 오버랩시킴으로써, 최종 영상을 생성 할 수 있다. 예를 들어, 3D 객체 영상은 프로젝션할 영상을 표시하기 위한 객체(예를 들어, 디스플레이)를 포함 할 수 있다. 프로세서는 해당 객체(예를 들어, 디스플레이)에 프로젝션할 영상(영상 컨텐츠)를 오버랩시킬 수 있다. 프로세서는 배경 영상과 프로젝션할 영상을 합성한 최종 영상을 스크린 또는 공간에 프로젝션하도록 프로 젝션부를 제어할 수 있다. 일 실시예에 따른 프로젝션부는 광을 발생시키는 광원, 렌즈 등을 포함할 수 있으며, 프로젝션의 방향이나 위치, 각도 등을 조절하는 구동부를 더 포함할 수 있다. 프로젝션부는 프로세서로부터 수신되는 제어 신호에 따라 광원을 구동시키거나 프로젝션의 방향이나 위치, 각도 등을 조절함으로써, 최종 영상의 프로젝션을 수행할 수 있다. 한편, 도 16에 도시된 프로젝션 장치의 블록도는 일 실시예를 위한 블록도이다. 블록도의 각 구성요소는 실제 구현되는 프로젝션 장치의 사양에 따라 통합, 추가, 또는 생략될 수 있다. 즉, 필요에 따라 2 이상의 구성요소가 하나의 구성요소로 합쳐지거나, 혹은 하나의 구성요소가 2 이상의 구성요소로 세분되어 구성될 수 있다. 또한, 각 블록에서 수행하는 기능은 실시예들을 설명하기 위한 것이며, 그 구체적인 동작이나 장치는 본 발명의 권리범위를 제한하지 아니한다. 한편, 일 실시예에 따른 프로젝션 장치가 디스플레이 장치로 구현되는 경우, 디스플레이를 더 포함할 수 있다. 디스플레이는 프로세서에서 생성된 가상 공간 영상과 영상 컨텐츠를 포함하는 최종 영상을 디스플레 이할 수 있다. 일 실시예에 따른 프로젝션 장치는, 프로젝션부, 하나 이상의 인스트럭션들을 저장하는 메모리, 및 상기 하나 이상의 인스트럭션들을 실행하는 적어도 하나의 프로세서를 포함할 수 있다. 상기 적어도 하나의 프로세서는, 상기 하나 이상의 인스트럭션들을 실행함으로써, 제1 영상을 획득할 수 있다. 상기 적어도 하나의 프로세서는, 상기 하나 이상의 인스트럭션들을 실행함으로써, 스크린의 공간 정보 및 사용 자의 위치 정보를 획득할 수 있다. 상기 적어도 하나의 프로세서는, 상기 하나 이상의 인스트럭션들을 실행함으로써, 상기 스크린의 공간 정보 및 상기 사용자의 위치 정보에 기초하여, 3차원 객체 영상 및 배경 영상을 생성할 수 있다. 상기 적어도 하나의 프로세서는, 상기 하나 이상의 인스트럭션들을 실행함으로써, 상기 제1 영상, 상기 3차원 객체 영상 및 상기 배경 영상을 합성한 제2 영상을 프로젝션하도록 상기 프로젝션부를 제어할 수 있다. 상기 적어도 하나의 프로세서는, 상기 하나 이상의 인스트럭션들을 실행함으로써, 사용자 입력에 기초하여, 상 기 3차원 객체 영상 및 상기 배경 영상을 설정할 수 있다.상기 적어도 하나의 프로세서는, 상기 하나 이상의 인스트럭션들을 실행함으로써, 상기 사용자의 위치 정보 및 상기 스크린의 공간 정보에 기초하여, 설정된 상기 3차원 객체 영상 및 상기 배경 영상을 조정할 수 있다. 상기 적어도 하나의 프로세서는, 상기 하나 이상의 인스트럭션들을 실행함으로써, 상기 제1 영상의 카테고리 정 보를 획득할 수 있다. 상기 적어도 하나의 프로세서는, 상기 하나 이상의 인스트럭션들을 실행함으로써, 상기 카테고리 정보에 기초하 여, 상기 배경 영상을 결정할 수 있다. 상기 적어도 하나의 프로세서는, 상기 하나 이상의 인스트럭션들을 실행함으로써, 상기 사용자의 위치 정보 및 상기 스크린의 공간 정보에 기초하여, 상기 3차원 객체 영상에 포함되는 적어도 하나의 객체에 대한 깊이 정보 를 결정할 수 있다. 상기 적어도 하나의 프로세서는, 상기 하나 이상의 인스트럭션들을 실행함으로써, 상기 사용자의 위치 정보가 변경되는 것에 기초하여, 상기 사용자의 시선 방향에 따라 상기 3차원 객체 영상 및 상기 배경 영상 중 적어도 하나를 조정할 수 있다. 상기 적어도 하나의 프로세서는, 상기 하나 이상의 인스트럭션들을 실행함으로써, 시간 정보 및 날씨 정보 중 적어도 하나를 획득할 수 있다. 상기 적어도 하나의 프로세서는, 상기 하나 이상의 인스트럭션들을 실행함으로써, 상기 시간 정보 및 날씨 정보 중 적어도 하나에 기초하여, 상기 3차원 객체 영상 및 상기 배경 영상 중 적어도 하나를 조정할 수 있다. 상기 적어도 하나의 프로세서는, 상기 하나 이상의 인스트럭션들을 실행함으로써, 프로젝션 방향을 획득할 수 있다. 상기 적어도 하나의 프로세서는, 상기 하나 이상의 인스트럭션들을 실행함으로써, 상기 시간 정보 및 상기 프로 젝션 방향에 기초하여, 상기 3차원 객체 영상 및 상기 배경 영상 중 적어도 하나에 나타나는 그림자 효과를 조 정할 수 있다. 상기 적어도 하나의 프로세서는, 상기 하나 이상의 인스트럭션들을 실행함으로써, 상기 3차원 객체 영상에 포함 되는 적어도 하나의 객체의 모양 및 크기에 기초하여, 상기 제1 영상을 상기 적어도 하나의 객체에 합성할 수 있다. 상기 적어도 하나의 프로세서는, 상기 하나 이상의 인스트럭션들을 실행함으로써, 상기 스크린의 공간 정보에 기초하여, 상기 제2 영상의 프로젝션 방향, 프로젝션 위치 및 프로젝션 크기 중 적어도 하나를 결정할 수 있다. 상기 프로젝션 장치는, 적어도 하나의 카메라를 더 포함할 수 있다. 상기 적어도 하나의 프로세서는, 상기 하나 이상의 인스트럭션들을 실행함으로써, 상기 적어도 하나의 카메라로 부터 촬영된 영상에 기초하여, 상기 스크린의 공간 정보 및 상기 사용자의 위치 정보를 획득할 수 있다. 일 실시예에 따른 프로젝션 장치의 동작 방법은, 제1 영상을 획득하는 단계를 포함할 수 있다. 일 실시예에 따른 프로젝션 장치의 동작 방법은, 스크린의 공간 정보를 획득하는 단계를 포함할 수 있다. 일 실시예에 따른 프로젝션 장치의 동작 방법은, 사용자의 위치 정보를 획득하는 단계를 포함할 수 있다. 일 실시예에 따른 프로젝션 장치의 동작 방법은, 상기 스크린의 공간 정보 및 상기 사용자의 위치 정보에 기초 하여, 3차원 객체 영상 및 배경 영상을 생성하는 단계를 포함할 수 있다. 일 실시예에 따른 프로젝션 장치의 동작 방법은, 상기 제1 영상, 상기 3차원 객체 영상 및 상기 배경 영상을 합 성한 제2 영상을 프로젝션하는 단계를 포함할 수 있다. 일 실시예에 따른 프로젝션 장치의 동작 방법은, 사용자 입력에 기초하여, 상기 3차원 객체 영상 및 상기 배경 영상을 설정하는 단계를 더 포함할 수 있다. 상기 3차원 객체 영상 및 배경 영상을 생성하는 단계는, 상기 사용자의 위치 정보 및 상기 스크린의 공간 정보 에 기초하여, 설정된 상기 3차원 객체 영상 및 상기 배경 영상을 조정하는 단계를 포함할 수 있다. 일 실시예에 따른 프로젝션 장치의 동작 방법은, 상기 제1 영상의 카테고리 정보를 획득하는 단계를 더 포함할 수 있다.일 실시예에 따른 프로젝션 장치의 동작 방법은, 상기 카테고리 정보에 기초하여, 상기 배경 영상을 결정하는 단계를 더 포함할 수 있다. 상기 3차원 객체 영상 및 배경 영상을 생성하는 단계는, 상기 사용자의 위치 정보 및 상기 스크린의 공간 정보 에 기초하여, 상기 3차원 객체 영상에 포함되는 적어도 하나의 객체에 대한 깊이 정보를 결정하는 단계를 포함 할 수 있다. 상기 3차원 객체 영상 및 배경 영상을 생성하는 단계는, 상기 사용자의 위치 정보가 변경되는 것에 기초하여, 상기 사용자의 시선 방향에 따라 상기 3차원 객체 영상 및 상기 배경 영상 중 적어도 하나를 조정하는 단계를 포함할 수 있다. 상기 동작 방법은, 시간 정보 및 날씨 정보 중 적어도 하나를 획득하는 단계를 포함할 수 있다. 상기 동작 방법은, 상기 시간 정보 및 날씨 정보 중 적어도 하나에 기초하여, 상기 3차원 객체 영상 및 상기 배 경 영상 중 적어도 하나를 조정하는 단계를 더 포함할 수 있다. 상기 동작 방법은, 프로젝션 방향을 획득하는 단계를 더 포함할 수 있다. 상기 시간 정보 및 날씨 정보 중 적어도 하나에 기초하여, 상기 3차원 객체 영상 및 상기 배경 영상 중 적어도 하나를 조정하는 단계는, 상기 시간 정보 및 상기 프로젝션 방향에 기초하여, 상기 3차원 객체 영상 및 상기 배 경 영상 중 적어도 하나에 나타나는 그림자 효과를 조정하는 단계를 포함할 수 있다. 상기 동작 방법은, 상기 3차원 객체 영상에 포함되는 적어도 하나의 객체의 모양 및 크기에 기초하여, 상기 제1 영상을 상기 적어도 하나의 객체에 합성하는 단계를 더 포함할 수 있다. 상기 동작 방법은, 상기 스크린의 공간 정보에 기초하여, 상기 제2 영상의 프로젝션 방향, 프로젝션 위치 및 프 로젝션 크기 중 적어도 하나를 결정하는 단계를 더 포함할 수 있다. 일 실시예에 따른 프로젝션 장치는 다양한 가상 공간 영상을 생성하여, 영상 컨텐츠와 함께 프로젝션함으로써, 사용자에게 다양한 시청 경험을 제공할 수 있다. 프로젝션 장치는 사용자의 위치에 따라 3D 객체 영상과 배경 영상을 조정함으로써, 가상 공간 영상에 대해 사용 자가 느끼는 현실감을 향상시킬 수 있다. 또한, 일 실시예에 따른 프로젝션 장치는 시간 정보 또는 날씨 정보에 따라 3D 객체 영상과 배경 영상을 조정함 으로써, 가상 공간 영상에 대해 사용자가 느끼는 현실감을 향상시킬 수 있다. 일 실시예에 따른 프로젝션 장치의 동작 방법은 다양한 컴퓨터 수단을 통하여 수행될 수 있는 프로그램 명령 형 태로 구현되어 컴퓨터 판독 가능 매체에 기록될 수 있다. 상기 컴퓨터 판독 가능 매체는 프로그램 명령, 데이터 파일, 데이터 구조 등을 단독으로 또는 조합하여 포함할 수 있다. 상기 매체에 기록되는 프로그램 명령은 본 발 명을 위하여 특별히 설계되고 구성된 것들이거나 컴퓨터 소프트웨어 당업자에게 공지되어 사용 가능한 것일 수 도 있다. 컴퓨터 판독 가능 기록 매체의 예에는 하드 디스크, 플로피 디스크 및 자기 테이프와 같은 자기 매체 (magnetic media), CD-ROM, DVD와 같은 광기록 매체(optical media), 플롭티컬 디스크(floptical disk)와 같은 자기-광 매체(magneto-optical media), 및 롬(ROM), 램(RAM), 플래시 메모리 등과 같은 프로그램 명령을 저장 하고 수행하도록 특별히 구성된 하드웨어 장치가 포함된다. 프로그램 명령의 예에는 컴파일러에 의해 만들어지 는 것과 같은 기계어 코드뿐만 아니라 인터프리터 등을 사용해서 컴퓨터에 의해서 실행될 수 있는 고급 언어 코 드를 포함한다. 또한, 개시된 실시예들에 따른 프로젝션 장치의 동작 방법은 컴퓨터 프로그램 제품(computer program product) 에 포함되어 제공될 수 있다. 컴퓨터 프로그램 제품은 상품으로서 판매자 및 구매자 간에 거래될 수 있다. 컴퓨터 프로그램 제품은 S/W 프로그램, S/W 프로그램이 저장된 컴퓨터로 읽을 수 있는 저장 매체를 포함할 수 있다. 예를 들어, 컴퓨터 프로그램 제품은 전자 장치의 제조사 또는 전자 마켓(예, 구글 플레이 스토어, 앱 스 토어)을 통해 전자적으로 배포되는 S/W 프로그램 형태의 상품(예, 다운로더블 앱)을 포함할 수 있다. 전자적 배 포를 위하여, S/W 프로그램의 적어도 일부는 저장 매체에 저장되거나, 임시적으로 생성될 수 있다. 이 경우, 저 장 매체는 제조사의 서버, 전자 마켓의 서버, 또는 SW 프로그램을 임시적으로 저장하는 중계 서버의 저장매체가 될 수 있다. 컴퓨터 프로그램 제품은, 서버 및 클라이언트 장치로 구성되는 시스템에서, 서버의 저장매체 또는 클라이언트 장치의 저장매체를 포함할 수 있다. 또는, 서버 또는 클라이언트 장치와 통신 연결되는 제3 장치(예, 스마트폰)가 존재하는 경우, 컴퓨터 프로그램 제품은 제3 장치의 저장매체를 포함할 수 있다. 또는, 컴퓨터 프 로그램 제품은 서버로부터 클라이언트 장치 또는 제3 장치로 전송되거나, 제3 장치로부터 클라이언트 장치로 전 송되는 S/W 프로그램 자체를 포함할 수 있다. 이 경우, 서버, 클라이언트 장치 및 제3 장치 중 하나가 컴퓨터 프로그램 제품을 실행하여 개시된 실시예들에 따른 방법을 수행할 수 있다. 또는, 서버, 클라이언트 장치 및 제3 장치 중 둘 이상이 컴퓨터 프로그램 제품을 실행하여 개시된 실시예들에 따른 방법을 분산하여 실시할 수 있다. 예를 들면, 서버(예로, 클라우드 서버 또는 인공 지능 서버 등)가 서버에 저장된 컴퓨터 프로그램 제품을 실행 하여, 서버와 통신 연결된 클라이언트 장치가 개시된 실시예들에 따른 방법을 수행하도록 제어할 수 있다. 이상에서 실시예들에 대하여 상세하게 설명하였지만 본 발명의 권리범위는 이에 한정되는 것은 아니고 다음의 청구범위에서 정의하고 있는 본 발명의 기본 개념을 이용한 당업자의 여러 변형 및 개량 형태 또한 본 발명의 권리범위에 속한다."}
{"patent_id": "10-2023-0125845", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 일 실시예에 따른 프로젝션 환경을 나타내는 도면이다. 도 2는 일 실시예에 따른 가상 공간 영상의 구성을 나타내는 도면이다. 도 3은 일 실시예에 따른 프로젝션 장치의 동작 방법을 나타내는 흐름도이다. 도 4는 일 실시예에 따른 프로젝션 장치가 스크린의 공간 정보 및 사용자의 위치 정보를 획득하는 동작을 나타 내는 도면이다. 도 5 및 도 6은 일 실시예에 따른 프로젝션 장치가 배경 영상 및 3D 객체 영상을 생성하는 방법을 설명하기 위 한 도면들이다. 도 7은 일 실시예에 따른 프로젝션 장치가 프로젝션할 영상에 기초하여, 배경 영상을 결정하는 동작을 설명하기 위한 도면이다. 도 8은 일 실시예에 따른 프로젝션 장치의 동작 방법을 나타내는 흐름도이다. 도 9는 일 실시예에 따른 프로젝션 장치가 사용자 위치가 변경됨에 따라, 가상 공간 영상을 변경하는 동작을 설 명하기 위한 도면이다. 도 10은 일 실시예에 따른 프로젝션 장치의 동작 방법을 나타내는 흐름도이다. 도 11은 일 실시예에 따른 프로젝션 장치가 시간 정보가 변경됨에 따라, 가상 공간 영상을 변경하는 동작을 설 명하기 위한 도면이다. 도 12 및 도 13은 일 실시예에 따른 프로젝션 장치가 다양한 가상 공간 영상을 제공하는 예시들을 나타내는 도 면들이다. 도 14는 복수의 사용자가 인식되는 경우, 일 실시예에 따른 프로젝션 장치의 동작을 설명하기 위한 도면이다. 도 15는 일 실시예에 따른 프로젝션 장치가 가상 공간 영상을 프로젝션하는 동작을 설명하기 위한 도면이다. 도 16은 일 실시예에 따른 프로젝션 장치의 구성을 나타내는 블록도이다."}
