{"patent_id": "10-2019-0108468", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2021-0026962", "출원번호": "10-2019-0108468", "발명의 명칭": "보이스 어시스턴트 서비스를 제공하는 장치 및 방법", "출원인": "삼성전자주식회사", "발명자": "황인철"}}
{"patent_id": "10-2019-0108468", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "전자 장치가 보이스 어시스턴트 서비스를 제공하는 방법에 있어서,사용자의 음성을 획득하는 단계;상기 사용자의 음성을 자연어 이해 모델에 입력함으로써, 상기 사용자의 음성에 대한 음성 해석 정보를 획득하는 단계;상기 획득된 음성 해석 정보에 기초하여, 기 설정된 기준에 따라, 상기 사용자의 음성에 대한 응답 동작을 수행할 수 있는지 여부를 결정하는 단계; 및상기 응답 동작을 수행할 수 없는 것으로 결정됨에 따라, 상기 사용자의 음성에 관련된 응답 동작을 학습하기위한 일련의 안내 메시지를 출력하는 단계; 를 포함하는, 방법."}
{"patent_id": "10-2019-0108468", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 방법은상기 출력된 안내 메시지에 따라 상기 사용자로부터 입력되는 입력 시퀀스를 수신하는 단계; 를 더 포함하는,방법."}
{"patent_id": "10-2019-0108468", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서, 상기 방법은상기 입력 시퀀스를 이용하여 상기 응답 동작을 학습하기 위한 보이스 어시스턴트 서비스 모델을 학습시키는 단계; 를 더 포함하는, 방법."}
{"patent_id": "10-2019-0108468", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서, 상기 입력 시퀀스는상기 사용자로부터 입력된 음성 입력, 키 입력, 터치 입력, 또는 모션 입력 중 적어도 하나를 포함하는 것을 특징으로 하는, 방법."}
{"patent_id": "10-2019-0108468", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서, 상기 음성 해석 정보는상기 사용자의 의도에 관련된 의도(intent) 정보, 또는 상기 사용자의 의도에 매칭되는 응답 동작을 제공하기위해 필요한 슬롯(slot) 정보 중 적어도 하나를 포함하는, 방법."}
{"patent_id": "10-2019-0108468", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제3항에 있어서, 상기 방법은상기 입력 시퀀스의 의도를 추론하기 위한 추론 모델을 이용하여, 상기 입력 시퀀스를 기 설정된 단위에 따라분할하는 단계; 상기 분할된 입력 시퀀스가 나타내는 의도 정보에 기초하여, 상기 분할된 입력 시퀀스를 복수의 입력 그룹으로그룹핑(grouping)하는 단계; 및상기 추론 모델을 이용하여, 상기 복수의 입력 그룹 별 의도 정보를 식별하는 단계; 를 더 포함하고,상기 보이스 어시스턴트 서비스 모델을 학습시키는 단계는,상기 복수의 입력 그룹 및 상기 복수의 입력 그룹 별 의도 정보에 기초하여 상기 보이스 어시스턴트 서비스 모공개특허 10-2021-0026962-3-델을 학습시키는 단계; 를 더 포함하는, 방법."}
{"patent_id": "10-2019-0108468", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6항에 있어서, 상기 방법은상기 입력 시퀀스를 유사 시퀀스 생성 모델에 입력함으로써 상기 입력 시퀀스와 관련된 유사 시퀀스를 생성하는단계; 및상기 생성된 유사 시퀀스, 상기 복수의 입력 그룹, 및 상기 복수의 입력 그룹 별 의도 정보에 기초하여 상기 보이스 어시스턴트 서비스 모델을 학습시키는 단계; 를 더 포함하는, 방법."}
{"patent_id": "10-2019-0108468", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제3항에 있어서, 상기 보이스 어시스턴트 서비스 모델은 인공지능 알고리즘으로서, 기계학습, 신경망, 유전자, 딥러닝, 분류 알고리즘 중 적어도 하나를 이용하여 학습되는 것을 특징으로 하는, 방법."}
{"patent_id": "10-2019-0108468", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1항에 있어서, 상기 안내 메시지를 출력하는 단계는상기 사용자로부터 미리 설정된 트리거 입력이 수신되는 경우, 상기 안내 메시지를 출력하는 것을 특징으로 하는, 방법."}
{"patent_id": "10-2019-0108468", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제7항에 있어서, 상기 사용자의 음성에 대한 응답 동작을 수행할 수 있는지 여부를 결정하는 단계는,상기 생성된 유사 시퀀스, 상기 복수의 입력 그룹 및 상기 복수의 입력 그룹 별 의도 정보에 기초하여 학습된보이스 어시스턴트 서비스 모델을 이용하여, 상기 사용자의 음성에 대한 응답 동작을 수행할 수 있는지 여부를결정하는 단계; 를 더 포함하는, 방법."}
{"patent_id": "10-2019-0108468", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "보이스 어시스턴트 서비스를 제공하는 전자 장치에 있어서,하나 이상의 인스트럭션을 저장하는 메모리; 및상기 하나 이상의 인스트럭션을 실행하는 적어도 하나의 프로세서; 를 포함하고,상기 적어도 하나의 프로세서는 상기 하나 이상의 인스트럭션을 실행함으로써,사용자의 음성을 획득하고,상기 사용자의 음성을 자연어 이해 모델에 입력함으로써, 상기 사용자의 음성에 대한 음성 해석 정보를 획득하고,상기 획득된 음성 해석 정보에 기초하여, 기 설정된 기준에 따라, 상기 사용자의 음성에 대한 응답 동작을 수행할 수 있는지 여부를 결정하고,상기 응답 동작을 수행할 수 없는 것으로 결정됨에 따라, 상기 사용자의 음성에 관련된 응답 동작을 학습하기위한 일련의 안내 메시지를 출력하는 전자 장치."}
{"patent_id": "10-2019-0108468", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항에 있어서, 상기 적어도 하나의 프로세서는 상기 하나 이상의 인스트럭션을 실행함으로써,상기 출력된 안내 메시지에 따라 상기 사용자로부터 입력되는 입력 시퀀스를 수신하는 하는 전자 장치."}
{"patent_id": "10-2019-0108468", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제12항에 있어서, 상기 적어도 하나의 프로세서는 상기 하나 이상의 인스트럭션을 실행함으로써,공개특허 10-2021-0026962-4-상기 입력 시퀀스를 이용하여 상기 응답 동작을 학습하기 위한 보이스 어시스턴트 서비스 모델을 학습시키는,전자 장치."}
{"patent_id": "10-2019-0108468", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제11항에 있어서, 상기 입력 시퀀스는 상기 사용자로부터 입력된 음성 입력, 키 입력, 터치 입력, 또는 모션 입력 중 적어도 하나를 포함하는 것을 특징으로 하는, 전자 장치."}
{"patent_id": "10-2019-0108468", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제11항에 있어서, 상기 음성 해석 정보는상기 사용자의 의도에 관련된 의도(intent) 정보, 또는 상기 사용자의 의도에 매칭되는 응답 동작을 제공하기위해 필요한 슬롯(slot) 정보 중 적어도 하나를 포함하는, 전자 장치."}
{"patent_id": "10-2019-0108468", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제13항에 있어서, 상기 적어도 하나의 프로세서는 상기 하나 이상의 인스트럭션을 실행함으로써,상기 입력 시퀀스의 의도를 추론하기 위한 추론 모델을 이용하여, 상기 입력 시퀀스를 기 설정된 단위에 따라분할하고,상기 분할된 입력 시퀀스가 나타내는 의도 정보에 기초하여, 상기 분할된 입력 시퀀스를 복수의 입력 그룹으로그룹핑하고,상기 추론 모델을 이용하여, 상기 복수의 입력 그룹 별 의도 정보를 식별하며,상기 복수의 입력 그룹 및 상기 복수의 입력 그룹 별 의도 정보에 기초하여 상기 응답 동작을 학습하기 위한 상기 보이스 어시스턴트 서비스 모델을 학습시키는 전자 장치."}
{"patent_id": "10-2019-0108468", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제16항에 있어서, 상기 적어도 하나의 프로세서는 상기 하나 이상의 인스트럭션을 실행함으로써,상기 입력 시퀀스를 유사 시퀀스 생성 모델에 입력함으로써 상기 입력 시퀀스와 관련된 유사 시퀀스를생성하고,상기 생성된 유사 시퀀스, 상기 복수의 입력 그룹, 및 상기 복수의 입력 그룹 별 의도 정보에 기초하여 상기 보이스 어시스턴트 서비스 모델을 학습시키는, 전자 장치."}
{"patent_id": "10-2019-0108468", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제13항에 있어서, 상기 보이스 어시스턴트 서비스 모델은 인공지능 알고리즘으로서, 기계학습, 신경망, 유전자, 딥러닝, 분류 알고리즘 중 적어도 하나를 이용하여 학습되는 것을 특징으로 하는, 전자 장치."}
{"patent_id": "10-2019-0108468", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제11항에 있어서, 상기 적어도 하나의 프로세서는 상기 하나 이상의 인스트럭션을 실행함으로써,상기 사용자로부터 미리 설정된 트리거 입력이 수신되는 경우, 상기 안내 메시지를 출력하는 것을 특징으로 하는, 전자 장치."}
{"patent_id": "10-2019-0108468", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "사용자의 음성을 획득하는 단계; 상기 사용자의 음성을 자연어 이해 모델에 입력함으로써, 상기 사용자의 음성에 대한 음성 해석 정보를 획득하는 단계;상기 획득된 음성 해석 정보에 기초하여, 기 설정된 기준에 따라, 상기 사용자의 음성에 대한 응답 동작을 수행공개특허 10-2021-0026962-5-할 수 있는지 여부를 결정하는 단계; 및상기 응답 동작을 수행할 수 없는 것으로 결정됨에 따라, 상기 사용자의 음성에 관련된 응답 동작을 학습하기위한 일련의 안내 메시지를 출력하는 단계; 를 수행하도록 하는 프로그램이 저장된 컴퓨터로 읽을 수 있는 기록매체."}
{"patent_id": "10-2019-0108468", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 개시는 보이스 어시스턴트 서비스를 제공하는 전자 장치 및 방법에 관한 것이다. 전자 장치가 보이스 어시스 턴트 서비스를 제공하는 방법은, 사용자의 음성을 획득하는 단계; 상기 사용자의 음성을 자연어 이해 모델에 입 력함으로써, 상기 사용자의 음성에 대한 음성 해석 정보를 획득하는 단계; 상기 획득된 음성 해석 정보에 기초하 여, 기 설정된 기준에 따라, 상기 사용자의 음성에 대한 응답 동작을 수행할 수 있는지 여부를 결정하는 단계; 및 상기 응답 동작을 수행할 수 없는 것으로 결정됨에 따라, 상기 사용자의 음성에 관련된 응답 동작을 학습하기 위한 일련의 안내 메시지를 출력하는 단계; 를 포함할 수 있다."}
{"patent_id": "10-2019-0108468", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 보이스 어시스턴트 서비스를 제공하는 장치 및 방법에 관한 것이다. 보다 상세하게는, 보이스 어시스 턴트 서비스를 제공하는 보이스 어시스턴트 서비스 모델을 학습하기 위한 장치 및 방법에 관한 것이다."}
{"patent_id": "10-2019-0108468", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "인공지능(Artificial Intelligence, AI) 시스템은 기존 Rule 기반 스마트 시스템과 달리 기계가 스스로 학습하 고 판단하며 똑똑해지는 시스템이다. 인공지능 시스템은 사용할수록 인식률이 향상되고 사용자 취향을 보다 정 확하게 이해할 수 있게 되어, 기존 Rule 기반 스마트 시스템은 점차 딥러닝 기반 인공지능 시스템으로 대체되고 있다. 인공지능 기술은 기계학습(딥러닝) 및 기계학습을 활용한 요소 기술들로 구성된다. 기계학습은 입력 데이터들의 특징을 스스로 분류/학습하는 알고리즘 기술이며, 요소기술은 딥러닝 등의 기계학 습 알고리즘을 활용하는 기술로서, 언어적 이해, 시각적 이해, 추론/예측, 지식 표현, 동작 제어 등의 기술 분 야로 구성된다. 인공지능 기술이 응용되는 다양한 분야는 다음과 같다. 언어적 이해는 인간의 언어/문자를 인식하고 응용/처리 하는 기술로서, 자연어 처리, 기계 번역, 대화시스템, 질의 응답, 음성 인식/합성 등을 포함한다. 시각적 이해 는 사물을 인간의 시각처럼 인식하여 처리하는 기술로서, 객체 인식, 객체 추적, 영상 검색, 사람 인식, 장면 이해, 공간 이해, 영상 개선 등을 포함한다. 추론 예측은 정보를 판단하여 논리적으로 추론하고 예측하는 기술 로서, 지식/확률 기반 추론, 최적화 예측, 선호 기반 계획, 추천 등을 포함한다. 지식 표현은 인간의 경험정보 를 지식데이터로 자동화 처리하는 기술로서, 지식 구축(데이터 생성/분류), 지식 관리(데이터 활용) 등을 포함 한다. 동작 제어는 차량의 자율 주행, 로봇의 움직임을 제어하는 기술로서, 움직임 제어(항법, 충돌, 주행), 조 작 제어(행동 제어) 등을 포함한다. 한편, 인공지능 기술을 이용하면서도, 보이스 어시스턴트 서비스를 효과적으로 제공할 수 있도록 하는 기술이 요구되고 있다. 구체적으로, 보이스 어시스턴트 서비스를 제공하는 경우에, 개인의 프라이버시를 효과적으로 보 호할 수 있는 기술이 요구되고 있다."}
{"patent_id": "10-2019-0108468", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "일 실시 예에 따르면, 어시스턴트 서비스를 제공하는 장치 및 방법이 제공될 수 있다. 또한, 일 실시 예에 따르면, 동작의 수행이 불가능한 것으로 결정되는 사용자 음성이 수신되는 경우, 수신된 사 용자 음성에 대한 동작을 학습할 수 있는 보이스 어시스턴트 서비스를 제공하는 장치 및 방법이 제공될 수 있다."}
{"patent_id": "10-2019-0108468", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상술한 기술적 과제를 달성하기 위한 본 개시의 일 실시 예에 따라, 전자 장치가 보이스 어시스턴트 서비스를 제공하는 방법은, 사용자의 음성을 획득하는 단계; 상기 사용자의 음성을 음성 해석 모델에 입력함으로써, 상기 사용자의 음성에 대한 음성 해석 정보를 획득하는 단계; 상기 획득된 해석 정보에 기초하여, 기 설정된 기준에 따라, 상기 사용자의 음성에 대한 응답 동작을 수행할 수 있는지 여부를 결정하는 단계; 및 상기 응답 동작을 수행할 수 없는 것으로 결정됨에 따라, 상기 사용자의 음성에 관련된 응답 동작을 학습하기 위한 일련의 안내 메시지를 출력하는 단계; 를 포함할 수 있다.일 실시 예에 따라, 상기 방법은 상기 출력된 안내 메시지에 따라 상기 사용자로부터 입력되는 입력 시퀀스를 수신하는 단계; 를 더 포함할 수 있다. 일 실시 예에 따라, 상기 방법은 상기 입력 시퀀스를 이용하여 상기 응답 동작을 학습하기 위한 보이스 어시스 턴트 서비스 학습 모델을 학습시키는 단계; 를 더 포함할 수 있다. 일 실시 예에 따라, 상기 입력 시퀀스는 상기 사용자로부터 입력된 음성 입력, 키 입력, 터치 입력, 또는 모션 입력 중 적어도 하나를 포함할 수 있다. 일 실시 예에 따라, 상기 음성 해석 정보는 상기 사용자의 발화 의도에 관련된 의도(intent) 정보, 또는 상기 사용자의 발화 의도에 매칭되는 응답 동작을 제공하기 위해 필요한 슬롯(slot) 정보 중 적어도 하나를 포함할 수 있다. 일 실시 예에 따라, 상기 방법은 상기 입력 시퀀스의 의도를 추론하기 위한 추론 모델을 이용하여, 상기 입력 시퀀스를 기 설정된 의도(intent) 단위에 따라 복수의 입력 그룹으로 분할하는 단계; 및 상기 추론 모델을 이용 하여, 상기 복수의 입력 그룹 별로 상기 사용자의 의도를 식별하는 단계; 를 더 포함하고, 상기 어시스턴트 학 습 모델을 학습시키는 단계는, 상기 복수의 입력 그룹, 및 상기 복수의 입력 그룹 별로 식별된 의도에 기초하여 상기 응답 동작을 학습하기 위한 상기 어시스턴트 학습 모델을 학습시키는 단계; 를 더 포함할 수 있다. 일 실시 예에 따라, 상기 방법은 상기 입력 시퀀스를 언어 모델에 입력함으로써 상기 입력 시퀀스와 관련된 유 사 시퀀스를 생성하는 단계; 및 상기 생성된 유사 시퀀스, 상기 복수의 입력 그룹, 및 상기 복수의 입력 그룹 별로 식별된 의도에 기초하여 상기 어시스턴트 학습 모델을 학습시키는 단계; 를 더 포함할 수 있다. 일 실시 예에 따라, 상기 보이스 어시스턴트 서비스 모델은 인공지능 알고리즘으로서, 기계학습, 신경망, 유전 자, 딥러닝, 분류 알고리즘 중 적어도 하나를 이용하여 학습될 수 있다. 일 실시 예에 따라, 상기 안내 메시지를 출력하는 단계는 상기 사용자로부터 미리 설정된 트리거 입력이 수신되 는 경우, 상기 안내 메시지를 출력할 수 있다. 일 실시 예에 따라, 상기 사용자의 음성에 대한 응답 동작을 수행할 수 있는지 여부를 결정하는 단계는, 상기 생성된 유사 시퀀스, 상기 복수의 입력 그룹, 및 상기 복수의 입력 그룹 별로 식별된 의도에 기초하여 학 습된 상기 보이스 어시스턴트 서비스 모델을 이용하여, 상기 사용자의 음성에 대한 응답 동작을 수행할 수 있는 지 여부를 결정하는 단계; 를 더 포함할 수 있다. 또한, 상기 기술적 과제를 해결하기 위한 본 개시의 또 다른 실시 예에 따라, 보이스 어시스턴트 서비스를 제공 하는 전자 장치는 하나 이상의 인스트럭션을 저장하는 메모리; 및 상기 하나 이상의 인스트럭션을 실행하는 적 어도 하나의 프로세서; 를 포함하고, 상기 적어도 하나의 프로세서는 상기 하나 이상의 인스트럭션을 실행함으 로써, 사용자의 음성을 획득하고, 상기 사용자의 음성을 음성 해석 모델에 입력함으로써, 상기 사용자의 음성에 대한 음성 해석 정보를 획득하고, 상기 획득된 해석 정보에 기초하여, 기 설정된 기준에 따라, 상기 사용자의 음성에 대한 응답 동작을 수행할 수 있는지 여부를 결정하고, 상기 응답 동작을 수행할 수 없는 것으로 결정됨 에 따라, 상기 사용자의 음성에 관련된 응답 동작을 학습하기 위한 일련의 안내 메시지를 출력할 수 있다. 일 실시 예에 따라, 상기 적어도 하나의 프로세서는 상기 하나 이상의 인스트럭션을 실행함으로써, 상기 출력된 안내 메시지에 따라 상기 사용자로부터 입력되는 입력 시퀀스를 수신할 수 있다. 일 실시 예에 따라, 상기 적어도 하나의 프로세서는 상기 하나 이상의 인스트럭션을 실행함으로써, 상기 입력 시퀀스를 이용하여 상기 응답 동작을 학습하기 위한 보이스 어시스턴트 서비스 모델을 학습시킬 수 있다. 일 실시 예에 따라, 상기 입력 시퀀스는 상기 사용자로부터 입력된 음성 입력, 키 입력, 터치 입력, 또는 모션 입력 중 적어도 하나를 포함할 수 있다. 일 실시 예에 따라, 상기 음성 해석 정보는 상기 사용자의 발화 의도에 관련된 의도(intent) 정보, 또는 상기 사용자의 발화 의도에 매칭되는 응답 동작을 제공하기 위해 필요한 슬롯(slot) 정보 중 적어도 하나를 포함할 수 있다. 일 실시 예에 따라, 상기 적어도 하나의 프로세서는 상기 하나 이상의 인스트럭션을 실행함으로써, 상기 입력 시퀀스의 의도를 추론하기 위한 추론 모델을 이용하여, 상기 입력 시퀀스를 기 설정된 의도(intent) 단위에 따 라 복수의 입력 그룹으로 분할하고, 상기 추론 모델을 이용하여, 상기 복수의 입력 그룹 별로 상기 사용자의 의도를 식별하며, 상기 복수의 입력 그룹, 및 상기 복수의 입력 그룹 별로 식별된 의도에 기초하여 상기 응답 동 작을 학습하기 위한 상기 보이스 어시스턴트 서비스 모델을 학습시킬 수 있다. 일 실시 예에 따라, 상기 프로세서는 상기 하나 이상의 인스트럭션을 실행함으로써, 상기 입력 시퀀스를 언어 모델에 입력함으로써 상기 입력 시퀀스와 관련된 유사 시퀀스를 생성하고, 상기 생성된 유사 시퀀스, 상기 복수 의 입력 그룹, 및 상기 복수의 입력 그룹 별로 식별된 의도에 기초하여 상기 보이스 어시스턴트 서비스 모델을 학습시킬 수 있다. 일 실시 예에 따라, 상기 보이스 어시스턴트 서비스 모델은 인공지능 알고리즘으로서, 기계학습, 신경망, 유전 자, 딥러닝, 분류 알고리즘 중 적어도 하나를 이용하여 학습될 수 있다. 일 실시 예에 따라, 상기 적어도 하나의 프로세서는 상기 하나 이상의 인스트럭션을 실행함으로써, 상기 사용자 로부터 미리 설정된 트리거 입력이 수신되는 경우, 상기 안내 메시지를 출력할 수 있다. 또한, 상기 기술적 과제를 해결하기 위한 본 개시의 또 다른 실시 예에 따라, 사용자의 음성을 획득하는 단계; 상기 사용자의 음성을 음성 해석 모델에 입력함으로써, 상기 사용자의 음성에 대한 음성 해석 정보를 획득하는 단계; 상기 획득된 음성 해석 정보에 기초하여, 기 설정된 기준에 따라, 상기 사용자의 음성에 대한 응답 동작 을 수행할 수 있는지 여부를 결정하는 단계; 및 상기 응답 동작을 수행할 수 없는 것으로 결정됨에 따라, 상기 사용자의 음성에 관련된 응답 동작을 학습하기 위한 일련의 안내 메시지를 출력하는 단계; 를 수행하도록 하는, 프로그램이 저장된 컴퓨터로 읽을 수 있는 기록매체가 제공될 수 있다."}
{"patent_id": "10-2019-0108468", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 명세서에서 사용되는 용어에 대해 간략히 설명하고, 본 개시에 대해 구체적으로 설명하기로 한다. 본 개시에서 사용되는 용어는 본 개시에서의 기능을 고려하면서 가능한 현재 널리 사용되는 일반적인 용어들을 선택하였으나, 이는 당 분야에 종사하는 기술자의 의도 또는 판례, 새로운 기술의 출현 등에 따라 달라질 수 있 다. 또한, 특정한 경우는 출원인이 임의로 선정한 용어도 있으며, 이 경우 해당되는 발명의 설명 부분에서 상세 히 그 의미를 기재할 것이다. 따라서 본 개시에서 사용되는 용어는 단순한 용어의 명칭이 아닌, 그 용어가 가지 는 의미와 본 개시의 전반에 걸친 내용을 토대로 정의되어야 한다. 명세서 전체에서 어떤 부분이 어떤 구성요소를 \"포함\"한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다른 구성요소를 제외하는 것이 아니라 다른 구성요소를 더 포함할 수 있음을 의미한다. 또한, 명세서에 기재된 \"...부\", \"모듈\" 등의 용어는 적어도 하나의 기능이나 동작을 처리하는 단위를 의미하며, 이는 하드웨어 또는 소프트웨어로 구현되거나 하드웨어와 소프트웨어의 결합으로 구현될 수 있다. 아래에서는 첨부한 도면을 참고하여 본 개시의 실시예에 대하여 본 개시가 속하는 기술 분야에서 통상의 지식을 가진 자가 용이하게 실시할 수 있도록 상세히 설명한다. 그러나 본 개시는 여러 가지 상이한 형태로 구현될 수 있으며 여기에서 설명하는 실시예에 한정되지 않는다. 그리고 도면에서 본 개시를 명확하게 설명하기 위해서 설 명과 관계없는 부분은 생략하였으며, 명세서 전체를 통하여 유사한 부분에 대해서는 유사한 도면 부호를 붙였다. 도 1은 일 실시 예에 따른 보이스 어시스턴트 서비스를 제공하는 과정을 나타내는 도면이다. 일 실시 예에 의하면, 전자 장치는 보이스 어시스턴트 서비스를 제공할 수 있다. 전자 장치는 보이 스 어시스턴트 서비스를 이용하여 사용자의 음성에 대한 응답 동작을 수행할 수 있다. 예를 들어, 전자 장치 는 보이스 어시스턴트 서비스를 이용하여 사용자의 음성이 획득되면, 사용자의 음성에 대한 응답 동작으 로써, 전자 장치가 수행할 수 있는 적어도 하나의 기능을 수행할 수 있다. 또한, 전자 장치는 획득된 사 용자의 음성에 대한 응답 동작으로써, 응답 메시지를 시각적 정보 또는 청각적 정보로 출력할 수 있다. 전자 장치는 보이스 어시스턴트 서비스를 제공하기 위해, ASR(automatic speech recognition), NLU, DM, AP, NLG, TTS 등 다양한 모델을 포함하고 있다. 예를 들어, 자동 음성 인식(ASR) 모델은 사용자 음성을 입력 받 고, 입력된 사용자 음성을 텍스트로 변환할 수 있다. 일 실시 예에 의하면, 자동 음성 인식 모델은 사용자 음성 의 음소(phonemes) 단위가 나타내는 음향(acoustic) 패턴을 식별함으로써 사용자 음성을 텍스트로 변환할 수 있 다. 자연어 이해 모델(Natural Language Understanding, NLU)은 사용자 음성이 변환된 텍스트를 입력 받고, 입력된 텍스트를 문법적 단위(예컨대 단어, 구, 형태소 등)에서 분석함으로써 사용자 음성에 대한 의도(intent) 정보 또는 슬롯(slot) 정보를 출력할 수 있다. 대화 관리(Dialog Management, DM) 모델은 전자 장치가 출력한 일련의 안내 메시지들 및 상기 출력된 일련의 안 내 메시지들에 대한 사용자 입력 시퀀스의 관계에서 나타나는 문맥적 의미를 분석함으로써 대화 관리 맵을 생성 하고, 생성된 대화 관리 맵 내 적어도 하나의 대화 경로를 이용하여 전자 장치가 출력한 일련의 안내 메시지들 및 출력된 일련의 안내 메시지들에 대한 사용자 입력 시퀀스들 사이의 문맥적 의미를 관리할 수 있다. 액션 플래닝(Action Planning, AP) 모델은 보이스 어시스턴트 서비스를 제공하기 위한 응답 동작들의 전반적인 순서를 관리할 수 있다. 보이스 어시스턴트 서비스는 액션 플래닝 모델에서 결정된 응답 동작들의 순서에 기초 하여 사용자 음성에 대한 응답 동작들을 수행할 수 있다. 자연어 생성 모델(Natural Language Generator, NLG)은 이미 등록된 텍스트 정보 및 자연어 이해 모델이 의도 정보 또는 슬롯 정보에 기초하여 새롭게 식별한 텍스트 정보를 이용하여 소정의 문장 규칙을 따르는 새로운 텍 스트를 출력할 수 있다. 텍스트 음성 변환(Text to Speech, TTS) 모델은 텍스트 정보를 입력 받고, 입력된 텍스트 정보를 음성 형태의 정보로 변환할 수 있다. 예를 들어, 텍스트 음성 변환(TTS)모델은 자연어 생성 모델이 새로 생성한 텍스트를 사 용자가 인식할 수 있는 음성 형태의 정보로 변환하고, 변환된 음성 형태의 정보를 전자 장치의 출력부로 전달할 수 있다. 전자 장치는 사용자의 음성을 획득하고, 획득된 사용자의 음성에 대한 응답 동작을 수행할 수 있는지 여 부를 결정할 수 있다. 예를 들어, 전자 장치는 NLU 모델을 이용하여, 획득된 사용자의 음성으로부터 응답 동작을 결정하는 데 필요한 의도(intent) 정보 또는 의도에 매칭되는 응답 동작과 관련된 파라미터를 결정하기 위해 필요한 슬롯(slot) 정보 중 적어도 하나를 식별하고, 식별된 의도 정보 또는 슬롯 정보 중 적어도 하나를 이용하여 응답 동작을 수행할 수 있는지 여부를 결정할 수 있다. 일 실시 예에 의하면, 전자 장치는 사용자 음성이 획득되면 ASR 모델을 이용하여 사용자 음성을 텍스트로 변환한다. 전자 장치는 변환된 텍스트와 함께, 변환된 텍스트에 대한 신뢰도 점수(Confidence score)를 획득할 수 있다. 신뢰도 점수는, 획득된 사용자 음성이 변환된 텍스트에 대응할 확률을 나타낼 수 있다. 전자 장치는 신뢰도 점수에 기초하여 획득된 사용자 음성에 대한 응답 동작을 수행할 수 있는지 여부를 결정할 수 있다. 즉, 신뢰도 점수가 기 설정된 임계치 이하인 경우, 전자 장치가 응답 동작을 수행할 수 없다고 판단할 수 있다.일 실시 예에 의하면, 전자 장치는 획득된 사용자 음성에 대응하는 변환된 텍스트를 NLU모델을 이용하여 분석하여, 획득된 사용자 음성에 대한 의도(intent) 정보 또는 슬롯(slot) 정보 중 적어도 하나를 결정할 수 있다. 전자 장치는 의도 정보 또는 슬롯 정보와 함께, 의도 정보 또는 슬롯 정보에 대한 확률 값을 획득 할 수 있다. 여기서, 확률 값은, 변환된 텍스트가 결정된 의도 정보 또는 슬롯 정보에 대응할 확률을 나타낼 수 있다. 전자 장치는 확률 값에 기초하여 획득된 사용자 음성에 대한 응답 동작을 수행할 수 있는지 여부를 결정할 수 있다. 즉, 확률 값이 기설정된 임계치 이하인 경우, 전자 장치가 응답 동작을 수행할 수 없다 고 판단할 수 있다. 다른 실시 예에 의하면, 전자 장치는 현재 전자 장치의 동작 상태에 기초하여 사용자 음성에 대한 응답 동작을 수행할 수 있는지 여부를 결정할 수 있다. 전자 장치는 NLU 모델을 통해 결정한 사용자 음성의 의 도(intent) 정보 및 슬롯(slot) 정보에 대응되는 컴퓨터 판독 가능한 명령이, 현재 전자 장치의 동작 상태에서 수행 가능한 동작에 관한 명령인지 여부를 결정하고, 현재 전자 장치의 동작 상태에서 수행 가능한 동작에 관한 명령인 경우, 사용자 음성에 대한 응답 동작을 수행할 수 있는 것으로 결정할 수 있다. 또 다른 실시 예에 의하면, 전자 장치는 상기 인식된 사용자 음성에서 획득된 의도 정보 및 슬롯 정보에 대응되는 컴퓨터 판독 가능한 명령이, 현재 전자 장치의 동작 상태에서 수행 가능한 동작에 관한 명령이 아닌 경우, 사용자 음성에 대한 응답 동작을 수행할 수 없는 것으로 결정할 수 있다. 일 실시 예에 의하면, 의도 정보 및 슬롯 정보에 대응되는 컴퓨터 판독 가능한 명령이 현재 전자 장치의 동작 상태에서 수행 가능한 동작에 관한 명령인지 여부는 보이스 어시스턴트 서비스 제공자에 의해 미리 설정될 수 있다. 즉, 전자 장치는, 현재 전자 장치의 동작 상태에서 수행 가능한 명령어로써, 보이스 어시스턴트 서비스 제공자가 미리 정의한 동작에 관한 명령(instruction)들을 메모리 또는 데이터 베이스에 미리 저장할 수 도 있다. 예를 들어, 전자 장치는 사용자의 음성에 대응하는 응답 동작을 수행할 수 있는 것으로 결정하 는 경우, 사용자 음성에 대응하는 응답 동작과 관련한 전자 장치의 적어도 하나의 기능을 수행할 수 있다. 일 실시 예에 의하면, 전자 장치는 사용자 음성에 대한 하나의 응답 동작을 출력할 수도 있지만, 이에 한정 되는 것은 아니며, 전자 장치의 2이상의 기능에 관한 일련의 응답 동작들을 함께 출력할 수도 있고, 전자 장치 의 2이상의 기능에 관한 일련의 응답 동작들을 미리 설정된 순서대로 출력할 수도 있다. 일 실시 예에 의하면, 전자 장치는 사용자의 음성이 획득되면, ASR 모델을 이용하여 \"날씨 알려줘\"와 같 은 텍스트로 변환한다. 이 때, 변환된 텍스트와 함께 획득되는 신뢰도 값이 기설정된 임계치 이상인 경우, 전자 장치는 사용자 음성을 인식할 수 있고, 사용자 음성에 대한 응답 동작을 수행할 수 있는 것으로 판단할 수 있다. 전자 장치는 신뢰도 값이 기설정된 임계치 이상인 경우 \"날씨 알려줘\"와 같은 텍스트를 NLU모델에 적용하 여, 의도(intent) 정보 또는 슬롯(slot) 정보 중 적어도 하나를 결정할 수 있다. 전자 장치는 NLU 모델을 통해, 의도 정보 및 의도 정보에 대한 확률값을 획득할 수 있으며, 획득된 확률값이 기설정된 임계치 이상인 경 우 의도 정보를 결정할 수 있다고 판단할 수 있다. 또한, 전자 장치는 의도 정보와 유사하게, \"날씨 알려 줘\"와 같은 사용자 음성으로부터 슬롯 정보를 결정할 수 있다고 판단하는 경우, 사용자 음성에 대한 응답 동작 을 수행할 수 있는 것으로 결정할 수 있다. 일 실시 예에 의하면, 전자 장치는 NLU모델에 의해 \"날씨 알려줘\"와 같은 사용자 음성으로부터 의도 정보 및 슬롯 정보가 모두 결정되는 경우, \"날씨 알려줘\"와 같은 사용자 음성에 대한 응답 동작을 수행할 수 있는 것으로 결정할 수 있다. 전자 장치가 \"날씨 알려줘\"와 같은 인식 가능한 사용자 음성에 대한 응답 동작을 수행할 수 있는 것으로 결정하는 경우, 전자 장치는 날씨 서비스에 접속하여, 오늘 날씨에 대한 정보를 요청하고, 요청에 대한 응답으로 날씨 서비스로부터 오늘 날씨에 대한 정보를 획득할 수 있다. 전자 장치(100 0)는 날씨 서비스로부터 획득된 오늘 날씨에 대한 정보를 이용하여 \"오늘의 날씨는 맑습니다. 22도 입니다\"와 같은 응답 메시지를 생성하고, 생성된 응답 메시지에 대한 정보를 출력할 수 있다. 일 실시 예에 의하면, 전자 장치는 생성된 복수의 응답 메시지들을 함께 출력할 수도 있지만, 미리 설정된 순서에 따라 차례대로 출 력할 수도 있다. 좀 더 상세히 설명하면, 전자 장치는 NLU 모델을 통해, 의도 정보는 \"날씨정보검색\", 슬롯 정보는 \"오늘 날씨\"로 결정하고, 결정된 의도 정보와 슬롯 정보에 대응하는 컴퓨터 판독 가능한 명령을 획득할 수 있다. \"날 씨정보검색\"에 대응하는 컴퓨터 판독 가능한 명령은, \"날씨 서비스에 접속(access)\", \"날씨 검색 요청\", \"검색 결과 획득\" 및 \"검색 결과 제공\"으로 판단될 수 있다. 슬롯 정보에 대응하는 컴퓨터 판독 가능한 명령은, 의도 정보에 대응한 명령 중 \"날씨 검색 요청\"을 수행할 때, 쿼리 정보로 \"오늘 날씨\"를 사용하도록 하는 명령일 수있다. 일 실시 예에 의하면, 전자 장치는 사용자로부터, \"나 이모티콘 실행해줘\"와 같은 사용자의 음성을 획득 할 수 있다. 전자 장치는 \"나 이모티콘 실행해줘\"와 같은 사용자 음성에 대한 응답 동작을 수행할 수 있 는지 여부를 결정할 수 있다. 예를 들어, 전자 장치는 \"나 이모티콘 실행해줘\"와 같은 사용자의 음성을 ASR 모델에 입력함으로써 사용 자 음성에 대응하는 \"나 이모티콘 실행해줘\"와 같은 텍스트 및 텍스트에 대한 신뢰도 값을 획득하여, 사용자 음 성을 인식할 수 있는지 여부를 결정할 수 있다. 전자 장치는 \"나 이모티콘 실행해줘\"에 대응하는 신뢰도 값이 기설정된 임계치 이하인 경우, 사용자 음성에 대한 응답 동작을 수행할 수 없는 것으로 결정할 수 있다. 일 실시 예에 의하면, 전자 장치는 \"나 이모티콘 실행해줘\"와 같은 텍스트 및 텍스트에 대한 신뢰도 값을 획득하여, 상기 신뢰도 값이 기 설정된 임계치 이상이더라도, NLU모델을 이용하여 \"나 이모티콘 실행해줘\"와 같 은 사용자 음성에 대한 응답 동작을 수행할 수 없는 것으로 결정할 수 있다. 전자 장치는 신뢰도 값이 기 설정된 임계치 이상인 경우 \"나 이모티콘 실행해줘\"와 같은 텍스트를 NLU모델에 적용하여, 의도(intent) 정보 또는 슬롯(slot) 정보 중 적어도 하나를 결정할 수 있다. 전자 장치는 NLU 모델을 통해, 의도 정보 및 의 도 정보에 대한 확률값을 획득할 수 있으며, 획득된 확률값이 기설정된 임계치 이하인 경우 의도 정보를 결정할 수 없다고 판단할 수 있다. 전자 장치는 \"나 이모티콘 실행해줘\"와 같은 사용자 음성으로부터 의도 정보 를 결정할 수 없다고 판단하는 경우, 사용자 음성에 대한 응답 동작을 수행할 수 없는 것으로 결정할 수 있다. 또한, 전자 장치는 의도 정보와 유사하게, \"나 이모티콘 실행해줘\"와 같은 사용자 음성으로부터 슬롯 정 보를 결정할 수 없다고 판단하는 경우, 사용자 음성에 대한 응답 동작을 수행할 수 없는 것으로 결정할 수 있다. 좀 더 상세히 설명하면, 전자 장치는 NLU 모델을 통해, 의도 정보는 \"이모지 실행\", 슬롯 정보는 \"이모지\"로 결정하였지만, 결정된 의도 정보 및 슬롯 정보에 대응하는 확률값이 기설정된 임계치 이하인 것으로 판단될 수 있다. NLU모델을 학습하는 데 사용한 학습데이터에 입력된 텍스트 및 텍스트와 유사한 유사 텍스트와 관련된 정보가 누락되어 있었던 경우, 입력된 텍스트에 대응한 의도 정보 및 슬롯 정보가 출력되더라도 각각의 확률값이 낮은 값으로 획득될 수 있다. 즉, 이모티콘이라는 텍스트가 NLU모델을 학습할 때 학습데이터로 사용되 지 않았기 때문에 이모티콘과 유사한 텍스트인 이모지가 의도 정보 및 슬롯 정보를 결정하는 데 영향을 미쳤고, 이모지가 이모티콘과 유사한 텍스트이나 동일한 텍스트가 아니기 때문에 확률 값이 낮은 값으로 출력될 수 있다. 전자 장치는 \"나 이모티콘 실행해줘\"에 대응하는 의도 정보 및 슬롯 정보의 확률값이 기 설정된 임계치 이상이더라도, 전자 장치는 현재 전자 장치의 동작 상태를 고려하여, 사용자 음성에 대한 응답 동작을 수행할 수 없는 것으로 결정할 수 있다. 전자 장치는 의도 정보 및 슬롯 정보의 확률값이 기설정된 임계 치 이상인 경우 \"나 이모티콘 실행해줘\"와 같은 텍스트에 대응하는 컴퓨터 판독 가능 명령을 식별할 수 있다. 전자 장치는 현재 전자 장치의 동작 상태를 고려할 때, 식별된 컴퓨터 판독 가능 명령이 전자 장치가 수 행 가능한 응답 동작에 관한 명령이 아닌 경우, 사용자 음성에 대한 응답 동작을 수행할 수 없는 것으로 결정할 수도 있다. 전자 장치가 사용자 음성에 대한 응답 동작을 수행할 수 있는지 여부는 현재 전자 장치의 동작 상태에 따 라 달라질 수 있다. 예를 들어, 전자 장치의 동작 상태는, 전자 장치가 현재 디스플레이에 표시하 고 있는 화면, 현재 전자 장치가 실행하고 있는 애플리케이션의 종류, 실행 중인 애플리케이션이 포함하고 있는 기능, 실행 중인 애플리케이션의 업데이트 상태, 전자 장치에 입력된 일련의 사용자 입력에 기초하여 현 재 전자 장치가 수행하고 있는 전자 장치의 기능 중 적어도 하나에 따라 달라질 수 있다. 예를 들어, 전자 장치는 \"나 이모티콘 실행해줘\"에 대응하는 의도 정보와 슬롯 정보가 결정되더라도, 현 재 전자 장치에 설치되어 있는 애플리케이션 중 이모티콘과 관련된 기능을 포함하고 있는 애플리케이션이 없는 경우, 전자 장치는 \"나 이모티콘 실행해줘\"와 같은 사용자 음성에 대한 응답 동작을 수행할 수 없는 것으로 결정할 수 있다. 일반적인 보이스 어시스턴트 서비스를 제공하는 전자 장치는, 획득된 사용자의 음성에 대한 응답 동작을 수행할 수 없는 것으로 결정하는 경우, \"죄송합니다. 제공하지 않는 서비스 입니다\"와 같은 에러 메시지만을 출력할 수 있었다. 그러나, 본 개시에 따른 전자 장치는 사용자의 음성에 대한 응답 동작을 수행할 수 없는 것으로 결정됨에 따라, 사용자의 음성에 관련된 응답 동작을 학습하기 위한 일련의 안내 메시지를 출력할 수 있다. 일실시 예에 의하면, 전자 장치는 사용자의 음성에 대한 응답 동작을 수행할 수 없는 것으로 결정하는 경우, \"죄송합니다. 제공하지 않는 서비스 입니다.\"와 같은 에러 메시지 및 \"학습할까요?\"와 같은 안내 메시지 를 함께 출력할 수도 있고, 에러 메시지 출력 후에 응답 동작을 학습하기 위한 일련의 안내 메시지를 차례대로 출력할 수도 있다. 일 실시 예에 의하면, 전자 장치가 에러 메시지 출력 후, 응답 동작을 학습하기 위한 일련의 안내 메시지 들은 \"학습 할까요\"와 같은 학습 확인 요청 메시지, \"학습 시작할게요. 동작을 알려주세요\"와 같은 학습 시작 안내 메시지, \"구체적으로 말씀해주세요\"(미도시)와 같은 학습 보충 메시지, \"네, 어떤 명령을 사용하실까요\" (미도시)와 같은 명령어 지정 요청 메시지를 포함할 수 있으나 이에 한정되는 것은 아니고, 사용자와 상호 작용 함으로써 사용자 음성에 대한 응답 동작을 학습하기 위해 필요한 기타 메시지들을 포함할 수 있다. 또한, 전자 장치는 \"학습할까요?\"와 같은 학습 확인 메시지 출력 후, 출력된 학습 확인 메시지에 대하여 사용자로부터 \"그래\"와 같은 단답형 사용자 음성이 입력되면, \"학습 시작 할게요. 동작을 알려주세요\"와 같이 학습 시작 안내 메시지를 출력할 수 있다. 그러나, 전자 장치는 \"학습할까요\"와 같은 학습 확인 메시지 출력 후, \"학습을 시작하자\"와 같은 사용자 음성이 획득되는 경우 \"네. 학습 시작할게요. 먼저 기능 알려주세요\" 와 같은 학습 시작 안내 메시지를 출력할 수도 있다. 보이스 어시스턴트의 질의에 대한 사용자의 응답은, 사용자 음성으로 입력될 수도 있고, 전자 장치에 표시되는 아이콘 등 GUI에 대한 사용자의 터치 를 통해서도 입력될 수 있다. 일 실시 예에 의하면, 전자 장치는 음성 입력 외에도, 전자 장치의 사용자 입력 인터페이스(미도시) 또는 전자 장치와 유선 또는 무선으로 연결되는 리모트 콘트롤(Remote Control)를 통하여 미리 설정된 트리거 입력이 획득되는 경우에도, \"학습 시작할게요. 먼저 기능 알려주세요\"와 같은 학습 시작 안내 메시지를 출력할 수도 있 다. 일 실시 예에 의하면, 전자 장치는 사용자로부터 미리 설정된 트리거 입력이 수신되는 경우, \"네. 학 습 시작 할게요. 먼저 기능 알려주세요\"와 같은 학습 시작 안내 메시지를 출력하지 않고도, 사용자로부터 입력 시퀀스의 수신을 대기할 수도 있다. 전자 장치는 미리 설정된 트리거 입력이 획득되는 경우, 또는 \"학습 할까요\"와 같은 학습 확인 요청 메시 지 출력 후 \"그래\" 또는 \"학습을 시작 하자\"와 같은 사용자의 응답이 수신되면, 전자 장치는 수행할 수 없었던 응답 동작을 학습하기 위한 학습 모드로 전환된다. 일 실시 예에 의하면, 전자 장치는 \"학습 시작 할게요, 먼저 기능 알려주세요\"와 같은 학습 시작 안내 메시지 출력과 함께 수행할 수 없는 것으로 결정된 사용 자 음성에 대한 응답 동작을 학습하기 위한 학습 모드로 전환될 수 있다. 예를 들어, 전자 장치는 학습 모드로 전환됨에 따라, 보이스 어시스턴트 서비스를 제공하기 위한 SW 모델 들(예컨대 ASR 모델, NLU 모델, AP 모델, NLG 모델, TTS 모델)중 적어도 하나를 활성화(Activation) 할 수 있 다. 또한, 전자 장치는 보이스 어시스턴트 서비스를 제공하기 위한 모델들을 활성화 함과 함께 보이스 어 시스턴트 서비스 학습을 위한 사용자 입력을 수신하는데 필요한 마이크로폰 모듈, 터치 스크린 모듈, UI 모듈 등을 활성화 할 수도 있다. 일 실시 예에 의하면, 전자 장치는 현재 전자 장치의 동작 상태에 기초하여, 보이스 어시스턴트 서비스를 제공하기 위한 SW 모델들 및 상기 보이스 어시스턴트 서비스 학습을 위한 사용자 입력을 수신하는데 필요한 모 듈을 결정할 수도 있다. 예를 들어, 전자 장치는 현재 전자 장치의 동작 상태가 사용자의 필요에 의해 터 치 잠금 기능이 설정된 상태인 경우, 사용자 입력을 수신하는데 필요한 마이크로폰 모듈, 터치 스크린 모듈 및 UI 모듈 중, 마이크로폰 모듈만을 실행할 수 도 있다. 또 다른 실시 예에 의하면, 전자 장치는 현재 전자 장치에서 영상이 재생 중인 경우, 사용자 터치로 인한 영상 재생의 중단을 방지하기 위해 마이크로폰 모듈, 터 치 스크린 모듈 및 UI 모듈 중, 마이크로폰 모듈만을 실행할 수도 있다. 즉, 전자 장치는 현재 전자 장치의 동작 상태에 기초하여 필요한 SW 모듈만을 실행함으로써 불필요한 SW 모듈 실행으로 인하여 발생할 수 있는 SW 자원 비용(cost)를 줄이고, 최적의 보이스 어시스턴트 서비스를 제공할 수 있다. 또한, 전자 장치는 단순히 학습 시작 안내 메시지만 출력하는 것이 아니라, 보이스 어시스턴트 서비스 학 습을 위해 필요하다고 결정된 어시스턴트 서비스를 제공하기 위한 모델, 사용자 입력을 수신하는데 필요한 기타 전자 장치의 기능을 지원하는 SW 모듈 등을 미리 활성화 함으로써, 보이스 어시스턴트 서비스 학습을 위해 수신 되는 사용자 입력의 수신이 지연되지 않도록 할 수 있다. 전자 장치는 학습 시작 안내 메시지 출력 후, 사용자로부터 보이스 어시스턴트 서비스를 이용하여 수행할 수 있는 전자 장치의 적어도 하나의 기능에 관한 사용자 음성들을 입력 시퀀스로써 획득할 수 있다. 예를 들어, 전자 장치는 학습 시작 안내 메시지 출력 후 \"카메라 실행해\" 및 \"AR 이모지 실행해\"와 같은 사용자 음성 을 입력 시퀀스로 획득할 수 있다. 전자 장치는 학습 시작 안내 메시지 출력 후, 획득된 사용자 입력 시퀀스들을 전자 장치의 기능 단위로 구분하여 메모리에 저장할 수 있을 뿐만 아니라, 학습 시작 안내 메시지 출력 후 획득되는 사용자 입력 시퀀스 들의 입력 순서를 메모리에 기록(recording)할 수도 있다. 또한, 전술한 바와 같이, 전자 장치는 사용자 입력 시퀀스 및 상기 사용자 입력 시퀀스에 응답하여 출력한 \"구체적으로 말씀해주세요\"(미도시)와 같은 일련의 안내 메시지들과의 순서를 메모리에 더 저장할 수도 있다. 전자 장치는 학습 시작 안내 메시지 출력 후, 획득된 사용자 입력 시퀀스들, 사용자 입력 시퀀스들이 입 력된 입력 순서 또는 사용자 입력 시퀀스 및 일련의 안내 메시지들과의 순서 중 적어도 하나에 기초하여 보이스 어시스턴트 서비스를 학습할 수 있다. 전자 장치는 학습된 보이스 어시스턴트 서비스를 이용하여 \"나 이 모티콘 실행해줘\"와 같은 사용자 음성이 획득되면, 사용자 음성에 대한 응답 동작의 수행이 가능한 것으로 결정 하고, \"나 이모티콘 실행해줘\"와 관련된 일련의 응답 동작들(예컨대, 카메라 애플리케이션 실행, AR 이모지 실 행, 나 이모티콘 실행)을 수행할 수 있다. 일 실시 예에 의하면, 전자 장치는 보이스 어시스턴트 서비스의 학습을 위한 사용자 입력 시퀀스의 수신 이 종료되는 경우,\"네, 어떤 명령을 사용하실까요?\"와 같은 명령어 지정 요청 메시지를 출력할 수 있다. 전자 장치는 명령어 지정 요청 메시지 출력 후, 사용자로부터 \"나 이모티콘 실행해줘\"와 같은 사용자 음성을 획득하고, 획득된 사용자 음성에 대응되는 명령어를, 새로 학습된 보이스 어시스턴트 서비스를 호출하기 위한 명령어로 지정할 수 있다. 전자 장치는 명령어 지정 요청 메시지에 대한 사용자 음성이 획득되면, \"학습 되었습니다\"와 같은 학습 종료 안내 메시지를 출력할 수 있다. 일 실시 예에 의하면, 전자 장치는 사용자로부터 \"학습 종료\"(미도시)와 같이 학습 동작의 종료를 나타내 는 입력 시퀀스가 획득되는 경우, 보이스 어시스턴트 서비스의 학습을 종료하고 \"네, 어떤 명령을 사용하실까요?\"와 같은 명령어 지정 요청 메시지를 출력할 수도 있다. 하지만, 전자 장치는 사용자로부터 학습 동작의 종료를 나타내는 입력 시퀀스가 획득되지 않더라도, 전자 장치가 응답 동작의 수행이 불가능 한 것으로 결정한 사용자 음성 \"나 이모티콘 실행해줘\"와 같은 사용자 음성이 재 수신되는 경우, 보이스 어시스 턴트 서비스의 학습을 종료하고 \"네, 어떤 명령을 사용하실까요?\"와 같은 명령어 지정 요청 메시지를 출력할 수 도 있다. 일 실시 예에 의하면, 전자 장치는 \"학습 종료\"(미도시)와 같이 학습 동작의 종료를 나타내는 음성 입력 외에도 전자 장치의 사용자 입력 인터페이스(미도시) 또는 전자 장치와 유선 또는 무선으로 연결되는 리모트 콘 트롤(Remote Control)를 통하여 학습 동작의 종료를 나타내는 미리 설정된 종료 시퀀스가 수신되는 경우에도, 학습을 종료하고 \"네, 어떤 명령을 사용하실까요?\"와 같은 명령어 지정 요청 메시지를 출력할 수도 있다. 보이스 어시스턴트 서비스를 학습하기 전, 전자 장치는, 카메라 애플리케이션이 실행되어 있지 않은 상태 에서 \"나 이모티콘 실행해줘\"와 같은 사용자 음성이 획득되면, 사용자 음성에 대한 응답 동작의 수행이 불가능 한 것으로 결정하고, 획득된 사용자 음성에 대한 응답 동작을 수행할 수 없었다. 그러나, 본 개시에 따른 보이 스 어시스턴트 서비스를 학습한 전자 장치는 카메라 애플리케이션이 실행되어 있지 않은 상태(에컨대, 홈 화면을 표시하고 있는 상태)에서도, \"나 이모티콘 실행해줘\"와 같은 사용자 음성이 획득되는 경우, \"나 이모티 콘 실행해줘\"와 같은 사용자 음성에 대한 일련의 응답 동작으로써, 카메라 애플리케이션을 실행하고, 카메라 애 플리케이션에서 제공하는 AR 이모지 서비스를 선택함으로써 AR 이모티콘을 실행할 수 있다. 일 실시 예에 의하면, 전자 장치는 AI 프로그램이 탑재되고 음성 인식 기능을 포함하는 스마트폰, 태블릿 PC, PC, 스마트 TV, 휴대폰, PDA(personal digital assistant), 랩톱, 미디어 플레이어, 서버, 마이크로 서버, GPS(global positioning system) 장치, 전자책 단말기, 디지털방송용 단말기, 네비게이션, 키오스크, MP3 플레 이어, 디지털 카메라, 스피커 기타 모바일 또는 비모바일 컴퓨팅 장치일 수 있으나, 이에 제한되지 않는다. 일 실시 예에 의하면, 전자 장치는 사용자의 음성을 서버로 전송할 수 있다. 서버는 보이스 어시스턴트 서비스를 이용하여, 전자 장치로부터 수신된 사용자의 음성에 대한 응답 동작을 출력할 수 있 다. 예를 들어, 서버는 수신된 사용자의 음성에 대한 응답 동작을 수행할 수 있는지 여부를 결정하고, 사용자 의 음성에 대한 응답 동작을 수행할 수 있는 것으로 결정하는 경우, 사용자의 음성에 대한 응답 동작과 관련된정보를 전자 장치로로 전송할 수 있다. 일 실시 예에 의하면, 서버는 수신된 사용자의 음성에 대한 응답 동작을 수행할 수 없는 것으로 결정하는 경우, 사용자 음성에 대한 응답 동작을 수행할 수 없다는 결정과 관련된 정보를 전자 장치로 전송할 수 있다. 전자 장치는 서버로부터 사용자 음성에 대한 응답 동작을 수행할 수 없다는 결정이 수신되면, \"죄 송합니다. 제공하지 않는 서비스 입니다.\"와 같은 에러 메시지 출력 후에 응답 동작을 학습하기 위한 일련의 안 내 메시지들로써, \"학습 할까요\"와 같은 학습 확인 요청 메시지, \"학습 시작할게요. 동작을 알려주세요\"와 같은 학습 시작 안내 메시지, \"구체적으로 말씀해주세요\"(미도시)와 같은 학습 보충 메시지, \"네, 어떤 명령을 사용 하실까요\"(미도시)와 같은 명령어 지정 요청 메시지들을 출력할 수 있다. 전자 장치는 학습 시작 안내 메시지 출력 후, 사용자로부터 보이스 어시스턴트 서비스를 이용하여 수행할 수 있는 전자 장치의 적어도 하나의 기능에 관한 사용자 음성들을 입력 시퀀스로써 획득하고, 획득된 입력 시퀀 스들을 서버로 전송할 수 있다. 또한, 전자 장치는 학습 시작 안내 메시지 출력 후, 획득된 사용자 입력 시퀀스들을 전자 장치의 기능 단위로 구분하고, 전자 장치의 기능 단위로 구분된 입력 시퀀스들 및 상기 입력 시퀀스들의 입력 순서를 서버로 더 전송할 수도 있다. 서버는 획득된 사용자 입력 시퀀스들, 사용자 입력 시퀀스들이 입력된 입력 순서 또는 사용자 입력 시퀀스 및 일련의 안내 메시지들과의 순서 중 적어 도 하나에 기초하여 보이스 어시스턴트 서비스를 학습할 수 있다. 서버가 전자 장치로부터 수신된 사용자 음성에 대해, 보이스 어시스턴트 서비스를 이용하여 사용자 음성 에 대한 일련의 응답 동작들을 수행하는 구체적인 방법은, 전술한 일부 실시 예에 따른 전자 장치가 획득 된 사용자 음성에 대해 보이스 어시스턴트 서비스를 이용하여 사용자 음성에 대한 응답 동작들을 수행하는 방법 과 대응될 수 있으므로, 구체적인 설명은 생략하기로 한다. 일 실시 예에 의하면, 서버는 본원 전자 장치와 통신 가능한 다른 전자 장치일 수 있다. 서버 는 상기 전자 장치와 연결되는 다른 장치와 네트워크를 통하여 통신 연결되고, 데이터를 송수신할 수 있 는 기타 컴퓨팅 장치를 포함할 수 있다. 일 실시 예에 의하면, 네트워크는 근거리 통신망(Local Area Network; LAN), 광역 통신망(Wide Area Network; WAN), 부가가치 통신망(Value Added Network; VAN), 이동 통 신망(mobile radio communication network), 위성 통신망 및 이들의 상호 조합을 포함하며, 도 1에 도시된 각 네트워크 구성 주체가 서로 원활하게 통신을 할 수 있도록 하는 포괄적인 의미의 데이터 통신망이며, 유선 인터 넷, 무선 인터넷 및 모바일 무선 통신망을 포함할 수 있다. 도 2는 일 실시 예에 따른 전자 장치가 보이스 어시스턴트 서비스를 제공하는 방법의 흐름도이다. S210에서, 전자 장치는 사용자로부터 사용자의 음성을 획득할 수 있다. 예를 들어, 전자 장치는 전 자 장치에 포함된 적어도 하나의 마이크를 통하여 사용자의 음성을 획득할 수 있다. 또 다른 실시 예에 의하면, 전자 장치는 사용자 입력 인터페이스를 통하여, 사용자로부터 음성 입력, 키(Key) 입력, 터치 입력 또는 모션 입력 중 적어도 하나를 획득할 수 있다. 또한, 전자 장치는 전자 장치와 통신 가능한 주변 전자 장 치에서 수신된 사용자의 음성 입력을 획득할 수도 있다. 일 실시 예에 의하면, 본 개시에 따른 입력 시퀀스는 사용자로부터 입력된 음성 입력, 키 입력, 터치 입력, 또는 모션 입력 중 적어도 하나를 포함할 수 있다. S220에서, 전자 장치는 획득된 사용자의 음성에 대한 음성 해석 정보를 획득할 수 있다. 예를 들어, 전자 장치는 ASR 모델을 이용하여 사용자 음성이 변환된 텍스트에 대한 신뢰도 값이 기설정된 임계치 이하인 경우, 응답 동작을 수행할 수 없다고 판단할 수 있다. 그러나, 전자 장치는 ASR 모델을 이용하여 사용자 음성이 변환된 텍스트에 대한 신뢰도 값이 기설정된 임계치 이상인 경우, NLU 모델을 이용하여 변환된 텍스트로 부터 응답 동작을 결정하는데 필요한 음성 해석 정보를 획득할 수 있다. 일 실시 예에 의하면, 음성 해석 정보 는 사용자의 음성으로부터 응답 동작을 결정하는데 필요한 의도(intent) 정보, 또는 상기 의도에 매칭되는 응답 동작과 관련된 파라미터를 결정하기 위해 필요한 슬롯(slot) 정보 중 적어도 하나를 포함할 수 있다. 예를 들어, 전자 장치가 사용자의 음성을 NLU 모델에 입력함으로써 획득하는 의도(intent) 정보는 자연어 를 발화한 사용자의 발화 의도를 나타낼 수 있다. 또한, 슬롯(slot) 정보는 사용자의 발화 의도에 매칭되는 응 답 동작(예컨대 정답)을 제공하기 위해서 필요한 정보로써, 슬롯 채우기(slot filling)를 위한 정보일 수 있다. 일 실시 예에 의하면, 전자 장치는 슬롯 정보가 모두 만족될 때까지, 의도 정보에 매칭되는 응답 동작에 필요한 슬롯 정보의 입력을 요청할 수도 있다. S230에서, 전자 장치는 사용자의 음성에 대한 응답 동작을 수행할지 여부를 결정할 수 있다. 일 실시 예 에 의하면, 전자 장치는 사용자의 음성에 대응하는 변환된 텍스트를 NLU 모델을 이용하여 분석함으로써, 의도 정보, 슬롯 정보 및 상기 의도 정보 및 슬롯 정보에 대한 확률 값을 획득할 수 있다. 전자 장치는 의도 정보 및 슬롯 정보에 대한 확률 값에 기초하여, 사용자 음성에 대한 응답 동작을 수행할 수 있는지 여부를 결정할 수 있다. 즉, 전자 장치는 ASR 모델을 이용하여 사용자 음성이 변환된 텍스트에 대한 신뢰도 값이 기 설정된 임계 치 보다 작은 경우 사용자 음성에 대한 응답 동작을 수행할 수 없다고 결정할 수 있다. 하지만, 전자 장치 는 사용자 음성이 변환된 텍스트에 대한 신뢰도 값이 기 설정된 임계치 이상인 경우에도, NLU 모델을 통 해 획득된 의도 정보에 대한 확률 값 또는 슬롯 정보에 대한 확률 값이 기 설정된 임계치 이하인 경우에도, 사 용자 음성에 대한 응답 동작을 수행할 수 없는 것으로 결정할 수 있다. 예를 들어, 전자 장치는 ASR 모델을 이용하여 사용자 음성이 변환된 \"영화 예매 해줘\"와 같은 텍스트와 함께 텍스트에 대한 신뢰도 값을 획득할 수 있다. 전자 장치는 \"영화 예매 해줘\"와 같은 텍스트에 대한 신뢰도 값이 기 설정된 임계치 보다 작은 경우, 사용자 음성의 인식이 불가능한 것으로 결정하고, 사용자 음성 의 인식이 불가능한 것으로 결정됨에 따라 사용자 음성에 대한 응답 동작을 수행할 수 없는 것으로 결정할 수 있다. 그러나, 전자 장치는 \"영화 에매 해줘\"와 같은 텍스트에 대한 신뢰도 값이 기 설정된 임계치 보다 큰 경 우, NLU 모델을 이용하여 \"영화 예매 해줘\"에 대한 의도 정보 또는 슬롯 정보를 결정하고, 의도 정보 또는 슬롯 정보에 대한 확률 값이 기 설정된 임계치 보다 작은 경우, 기초하여 사용자 음성에 대한 응답 동작을 수행할 수 없는 것으로 결정할 수 있다. 예를 들어, 전자 장치는 \"영화 예매 해줘\"와 같은 사용자 음성을 획득하고, 획득된 사용자 음성으로부터 적어도 하나의 후보 의도(intent) 정보들을 식별할 수 있다. 후보 의도 정보는, 전자 장치가 식별한 적어 도 하나의 후보 의도(intent)와 상기 후보 의도 각각에 대해 0-1사이의 값을 갖는 확률값을 포함할 수 있다. 여 기서 확률값은, 획득된 사용자 음성이 식별한 후보 의도에 대응할 가능성(likelihood)을 의미한다. 전자 장치 는 적어도 하나의 후보 의도 정보들 중 가장 높은 확률 값을 가지는 후보 의도 (예컨대, '예매' 또는 '예 약')를 \"영화 예매 해줘\"와 같은 사용자 음성의 의도 정보로 결정할 수 있다. 일 실시 예에 의하면, 전자 장치는 \"영화 예매 해줘\"와 같은 사용자 음성으로부터 식별되는 적어도 하나 의 후보 의도 정보들의 확률값이 기 설정된 임계치(threshold) 보다 낮은 경우, \"영화 예매 해줘\"와 같은 사용 자 음성으로부터 의도 정보를 식별할 수 없는 것으로 결정할 수 있다. 일 실시 예에 의하면, 전자 장치는 \"영화 예매 해줘\"와 같은 사용자 음성으로부터 식별되는 모든 후보 의도들의 확률 값이 기 설정된 임계치 (threshold) 보다 낮을 경우, 사용자 음성으로부터 의도 정보를 식별할 수 없는 것으로 결정할 수 있다. 또한, 전자 장치는 \"AR 이모지 실행해줘\"와 같은 사용자 음성을 획득하고, 획득된 사용자 음성에서 의도 정보를 '실행'으로 결정할 수 있으나, 사용자 음성의 슬롯 정보를 결정하지 못할 수 있다. 예를 들어, 전자 장 치는 \"AR 이모지 실행해줘\"와 같은 사용자 음성의 의도 정보 '실행'에 매칭되는 복수의 후보 슬롯(slot) 정보들을 식별할 수 있다. 후보 슬롯 정보는, 전자 장치가 식별한 적어도 하나의 후보 슬롯(slot)과 상기 후보 슬롯 각각에 대해 0-1사이의 값은 갖는 확률값을 포함할 수 있다. 여기서 확률값은, 획득된 사용자 음성이 식별한 후보 슬롯에 대응할 가능성(likelihood)을 의미한다. 전자 장치는 적어도 하나의 후보 슬롯들(예 컨대, 'AR 이모지', '이모티콘', '이미지') 중 가장 높은 확률 값을 가지는 후보 슬롯 (예컨대 'AR 이모지')을 \"AR 이모지 실행해줘\"와 같은 사용자 음성의 슬롯 정보로 결정할 수 있다. 일 실시 예에 의하면, 전자 장치는 \"AR 이모지 실행해줘\"와 같은 사용자 음성의 의도 정보 '실행'에 매칭 되는 적어도 하나의 후보 슬롯 정보들(예컨대, 'AR 이모지', '이모티콘', '이미지')의 확률값이 기 설정된 임계 치 보다 낮은 경우, \"AR 이모지 실행해줘\"와 같은 사용자 음성으로부터 슬롯 정보를 식별할 수 없는 것으로 결 정할 수 있다. 일 실시 예에 의하면, 전자 장치는 \"AR 이모지 실행해줘\"와 같은 사용자 음성으로부터 식별되는 모든 후 보 슬롯 정보들의 확률값이 기 설정된 임계치(threshold) 보다 낮을 경우, 사용자 음성으로부터 슬롯 정보를 식 별할 수 없는 것으로 결정할 수도 있다. 즉, 전자 장치는 NLU 모델을 이용하여 획득된 의도 정보에 대한 확률 값 또는 슬롯 정보에 대한 확률 값 이 기 설정된 임계치 보다 작은 경우, 사용자 음성에 대한 응답 동작을 수행할 수 없는 것으로 결정할 수 있다. 그러나, 전자 장치는 의도 정보에 대한 확률 값 및 슬롯 정보에 대한 확률 값이 기 설정된 임계치 보다큰 경우, 사용자 음성에 대한 응답 동작을 수행할 수 있는 것으로 결정할 수 있다. 반대로, 전자 장치는 의도 정보에 대한 확률 값 및 슬롯 정보에 대한 확률 값이 기 설정된 임계치 보다 큰 경우, 의도 정보 및 슬롯 정보에 대응되는 컴퓨터 판독 가능한 명령을 식별하고, 식별된 컴퓨터 판독 가능한 명령을 수행할 수도 있다. 또 다른 실시 예에 의하면, 전자 장치는 의도 정보에 대한 확률 값 및 슬롯 정보에 대한 확률 값이 기 설 정된 임계치 보다 큰 경우, 상기 식별된 의도 정보 및 슬롯 정보에 대응되는 컴퓨터 판독 가능한 명령 (instruction)이, 현재 전자 장치의 동작 상태에서 전자 장치가 수행 가능한 응답 동작에 관한 명령인지 여부에 기초하여, 사용자 음성에 대한 응답 동작을 수행할 수 있는지 여부를 결정할 수도 있다. 예를 들어, 전자 장치 는 인식 가능한 것으로 결정된 사용자 음성의 의도 정보 및 슬롯 정보에 대응되는 컴퓨터 판독 가능한 명 령이 현재 전자 장치의 동작 상태에서 수행할 수 없는 응답 동작에 관한 명령인 경우, 인식 가능한 사용자 음성 에 대한 응답 동작을 수행할 수 없는 것으로 결정할 수 있다. 즉, 도 1에서 전술한 바와 같이, 전자 장치가 사용자 음성에 대한 응답 동작을 수행할 수 있는지 여부는 현재 전자 장치의 동작 상태에 따라 달라질 수 있다. 예를 들어, 전자 장치의 동작 상태는 현재 디스플레이 상 에 표시되는 화면, 전자 장치에서 실행 중인 애플리케이션의 종류, 실행 중인 애플리케이션에서 선택 가능한 서 비스의 종류, 현재 실행 중인 애플리케이션의 업데이트 상태 등에 따라 달라질 수 있다. 일 실시 예에 의하면, 전자 장치는 전자 장치가 잠금 상태에 있는 경우 인식 가능한 사용자 음성에 대한 응답 동작을 수행할 수 없는 것으로 결정할 수 있다. 또한, 일 실시 예에 의하면 전자 장치는 인식 가능 한 사용자 음성 으로부터 획득된 의도 정보 및 슬롯 정보에 대응되는 컴퓨터 판독 가능한 명령 또는 컴퓨터 판 독 가능한 명령어를 이용하여 실행되는 애플리케이션이 현재 전자 장치의 메모리에 저장되어 있지 않은 경우 사 용자 음성에 대한 응답 동작을 수행할 수 없는 것으로 결정할 수도 있다. 또한 전자 장치는 사용자 음성으로부터 획득된 의도 정보 및 슬롯 정보에 대응되는 컴퓨터 판독 가능한 명령어로 실행되는 애플리케이션이 최신 상태로 업데이트 되어 있지 않은 경우, 사용자 음성에 대한 응답 동작 을 수행할 수 없는 것으로 결정할 수도 있다. 일 실시 예에 의하면, 전자 장치는 가상의 전자 장치 화면을 생성하고, 생성된 가상의 전자 장치 화면 또 는 전자 장치의 가상의 사용자 입력 인터페이스를 통하여 입력되는 사용자 입력을 기록하는 렌더링 모델 (Rendering Model)을 이용하여, 현재 전자 장치의 동작 상태를 결정할 수 있다. 전자 장치가 사용자 음성에 대 한 응답 동작을 수행할 수 있는지 여부를 결정하는 기준은 도 1 내지 도 2 관련 상세한 설명에서 언급한 예에 한정되지 않으며, 보이스 어시스턴트 서비스 제공자의 편의에 따라 다른 기준으로 설정될 수 있다. S240에서, 전자 장치는 응답 동작을 수행할 수 없는 것으로 결정됨에 따라, 사용자의 음성에 관련된 응답 동작을 학습하기 위한 일련의 안내 메시지를 출력할 수 있다. 일 실시 예에 의하면, 전자 장치는 사용자 의 음성에 대한 응답 동작을 수행할 수 없는 것으로 결정하는 경우, \"죄송합니다. 제공하지 않는 서비스 입니다.\"와 같은 에러 메시지 및 \"학습 할까요?\"와 같은 안내 메시지를 함께 출력할 수도 있고, 에러 메시지 출 력 후에 응답 동작을 학습하기 위한 일련의 안내 메시지를 단계 별로 출력할 수 있다. 또한, 전자 장치는 사용자 음성에 대한 응답 동작을 수행할 수 없는 것으로 결정됨에 따라, 제공되는 \"학습 할까요\"와 같은 학습 확인 요청 메시지 출력 후 \"그래\" 또는 \"학습을 시작 하자\"와 같은 단답형 사용자의 응답이 수신되면, 전자 장 치는 수행할 수 없었던 응답 동작을 학습하기 위한 학습 모드로 전환될 수 있다. 전자 장치가 학습 모드 에서 보이스 어시스턴트 서비스 학습을 위한 사용자 입력을 수신하는데 필요한 터치 스크린 모듈, UI 모듈, 마 이크로폰 모듈 등을 실행하는 방법은 도 1에서 전술한 바와 같으므로 구체적인 설명은 생략하기로 한다. 일 실 시 예에 의하면, 전자 장치가 에러 메시지 출력 후, 응답 동작을 학습하기 위한 일련의 안내 메시지들은 \"학습 할까요\"와 같은 학습 확인 요청 메시지, \"학습 시작할게요. 동작을 알려주세요\"와 같은 학습 시작 안내 메시지, \"구체적으로 말씀해주세요\"(미도시)와 같은 학습 보충 메시지, \"네, 어떤 명령을 사용하실까요\"(미도시)와 같은 명령어 지정 요청 메시지를 포함할 수 있으나 이에 한정되는 것은 아니고, 사용 자와 상호 작용함으로써 사용자 음성에 대한 응답 동작을 학습하기 위해 필요한 기타 메시지들을 포함할 수 있 다. 도 2에 도시된 전자 장치가 보이스 어시스턴트 서비스를 제공하는 방법 중 적어도 일부는 전자 장치또는 서버에 의해 실행될 수 있고, 전자 장치 및 서버에 의해 함께 실행될 수도 있다. 예를 들어, 전자 장치는 사용자의 음성을 획득하고, 획득된 사용자의 음성을 서버로 전송할 수 있 다. 서버는 ASR 모델을 이용하여 사용자의 음성을 텍스트로 변환하고, NLU 모델을 이용하여 변환된 텍스트로부터 획득되는 의도 정보 또는 슬롯 정보의 확률 값에 기초하여, 사용자의 음성에 대한 응답 동작을 수행할 수 있는지 여부를 결정할 수 있다. 서버가 사용자 음성에 대한 응답 동작을 수행할 수 있는지 여부를 결 정하는 방법은 전자 장치가 사용자 음성에 대한 응답 동작을 수행할 수 있는지 여부를 결정하는 구체적인 방법에 대응될 수 있다. 서버는 사용자의 음성에 대한 응답 동작을 수행할 수 있는 것으로 결정하는 경우, 사용자의 음성에 대한 응답 동작과 관련된 정보를 전자 장치로 전송할 수 있다. 그러나 서버는 사용자의 음성에 대한 응답 동작을 수행할 수 없는 것으로 결정하는 경우, 사용자의 음성 에 대한 응답 동작을 수행할 수 없다는 결정과 관련된 정보를 전자 장치로 전송할 수 있다. 일 실시 예에 의하면, 서버는 \"죄송합니다. 제공하지 않는 서비스 입니다\"(미도시)와 같은 에러 메시지, 또는 \"학습할 까요?\"(미도시)와 같은 학습 확인 요청 메시지와 함께 사용자 음성에 대한 응답 동작을 학습하기 위해 사용자의 입력 시퀀스를 전송해줄 것을 전자 장치로 요청할 수도 있다. 서버는 전자 장치로부터 전자 장치의 적어도 하나의 기능에 관한 사용자 음성들을 입력 시퀀스로써 획득할 수 있다. 일 실시 예에 의하면 서버는 사용자 입력 시퀀스 외 사용자 입력 시퀀스들의 순서 및 전 자 장치가 제공한 일련의 안내 메시지들 및 사용자 입력 시퀀스들과의 순서에 대한 정보를 수신할 수도 있다. 도 3은 일 실시 예에 따른 전자 장치가 보이스 어시스턴트 서비스를 제공하는 방법의 흐름도이다. S310에서, 전자 장치는 사용자로부터 사용자의 음성을 획득할 수 있다. S310은 도 2의 S210에 대응될 수 있으므로 구체적인 설명은 생략하기로 한다. S320에서, 전자 장치는 ASR 모델을 이용하여 사용자 음성이 변환된 텍스트에 대한 확률 값을 획득하고, 획득된 확률 값이 기 설정된 임계치 이상인지 여부를 결정할 수 있 다. S330에서, 전자 장치는 ASR 모델을 이용하여 사용자 음성이 변환된 텍스트에 대한 확률 값이 기 설정된 임계치 이상인 경우, NLU 모델을 통해 의도 정보에 대한 확률 값 또는 슬롯 정보에 대한 확률 값이 기 설정된 임계치 이상인지 여부를 결정할 수 있다. S320 내지 S330은 도 2의 S220에 대응될 수 있으므로 구체적인 설명은 생략하기로 한다. S340에서, 전자 장치는 의도 정보에 대한 확률 값 및 슬롯 정보에 대한 확률 값이 기 설정된 임계치 이상 인 경우, NLU 모델을 통해 획득된 의도 정보 및 슬롯 정보에 대응되는 컴퓨터 판독 가능한 명령이 현재 전자 장 치의 동작 상태에서 수행 가능한 명령인지 여부를 결정할 수 있다. S350에서, 전자 장치는 S340에서, 의도 정보 및 슬롯 정보에 대응되는 컴퓨터 판독 가능 명령이 현재 전 자 장치의 동작 상태에서 수행 가능한 응답 동작에 관한 명령으로 결정되는 경우, 사용자 음성에 대한 응답 동 작을 수행할 수 있다. 그러나, S360에서, 전자 장치는 ASR 모델을 통해 획득되는 사용자 음성이 변환된 텍스트에 대한 신뢰도 값이 기 설정된 임계치 보다 작은 경우, NLU 모델을 통해 획득된 의도 정보에 대한 확률 값 또는 슬롯 정보에 대한 확률 값이 기 설정된 임계치 보다 작은 경우, 또는 식별된 의도 정보 및 슬롯 정보에 대응되는 컴퓨터 판독 가능한 명령이 현재 전자 장치의 동작 상태에서 수행 가능한 응답 동작에 관한 명령이 아 닌 경우, 사용자 음성에 대한 응답 동작의 수행이 불가능한 것으로 결정할 수 있다. S370에서, 전자 장치는 응답 동작을 수행할 수 없는 것으로 결정됨에 따라, 사용자의 음성에 대한 응답 동작을 학습하기 위한 일련의 안내 메시지들을 출력할 수 있다. 예를 들어, 전자 장치가 에러 메시지 출 력 후, 응답 동작을 학습하기 위한 일련의 안내 메시지들은 \"학습 할까요\"와 같은 학습 확인 요청 메시지, \"학 습 시작할게요. 동작을 알려주세요\"와 같은 학습 시작 안내 메시지, \"구체적으로 말씀해주세요\"(미도시)와 같은 학습 보충 메시지, \"네, 어떤 명령을 사용하실까요\"(미도시)와 같은 명령어 지정 요청 메시지를 포함할 수 있고, 전자 장치는 출력된 안내 메시지 및 상기 출력된 안내 메시지 각각에 대한 사용자 입력 시퀀스의 관계를 분석함으로써 현재 상황에 필요한 일련의 메시지들을 출력할 수 있다. 일 실시 예에 의하면, 전자 장치는 현재 전자 장치의 동작 상태에 기초하여, 현재 출력된 안내 메시지 및 상기 출력된 안내 메시지에 대한 사용자 입력 시퀀스의 관계에서 나타나는 문맥적 의미를 분석함으로써 컨텍스 트(context) 정보를 결정하고, 컨텍스트(context) 정보를 이용하여 현재 입력된 사용자 입력 시퀀스에 필요한 기타 안내 메시지들을 출력할 수도 있다. S380에서, 전자 장치는 사용자로부터 입력 시퀀스들을 수신할 수 있다. 예를 들어, 전자 장치는 출 력된 안내 메시지에 따라 사용자로부터 입력되는 입력 시퀀스를 수신할 수 있다. 전자 장치가 수신하는 입력 시퀀스는 사용자의 음성 입력, 전자 장치를 조작하기 위한 키(Key) 입력, 터치 입력, 또는 모션 입력 중 적어도 하나를 포함할 수 있다. S390에서, 전자 장치는 사용자로부터 입력된 사용자 입력 시퀀스를 이용하여 보이스 어시스턴트 서비스를 학습할 수 있다. 일 실시 예에 의하면, 전자 장치는 보이스 어시스턴트 서비스를 제공하기 위한 서비스 모델을 이용하여 보이스 어시스턴트 서비스를 제공할 수 있다. 보이스 어시스턴트 서비스를 제공하기 위한 서비스 모델은 인공지능 알고리즘으로서, 기계학습, 신경망, 유전자, 딥러닝, 분류 알고리즘 중 적어도 하나를 이용하여 학습되는 서비스 모델일 수 있다. 또한, 일 실시 예 에 의하면, 보이스 어시스턴트 서비스 모델은 자동 음성 인식 모델(ASR), 자연어 이해 모델(Natural Language Understanding Model, NLU), 대화 관리 모델(Dialog Management Model, DM), 또는 액션 플랜 모델(Action Plan Model, AP), 자연어 생성 모델(NLG), 텍스트 음성 변환(Text to Speech, TTS)모델을 포함할 수 있고, 도 4의 S450단계를 참조하여 구체적으로 설명하기로 한다. 전자 장치는 획득된 사용자 입력 시퀀스들을 전자 장치의 기능 단위로 구분하여 메모리에 저장할 수 있을 뿐만 아니라, 학습 시작 안내 메시지 출력 후 획득되는 사용자 입력 시퀀스들의 입력 순서를 메모리에 기록 (recording)할 수도 있다. 전자 장치는 사용자 입력 시퀀스 및 상기 사용자 입력 시퀀스에 응답하여 출력 한 \"구체적으로 말씀해주세요\"(미도시)와 같은 일련의 안내 메시지들과의 순서를 메모리에 더 저장할 수도 있고, 사용자로부터 획득된 사용자 입력 시퀀스들, 사용자 입력 시퀀스들이 입력된 입력 순서 또는 사용자 입력 시퀀스 및 일련의 안내 메시지들과의 순서 중 적어도 하나에 기초하여 보이스 어시스턴트 서비스 모델을 학습할 수 있다. 전자 장치는 사용자로부터 획득된 사용자 입력 시퀀스들, 사용자 입력 시퀀스들이 입력된 입력 순서 또는 사용자 입력 시퀀스 및 일련의 안내 메시지들과의 순서 중 적어도 하나에 기초하여 학습된 보이스 어 시스턴트 서비스 모델을 이용하여, 새로 수신된 사용자의 음성에 대한 음성 인식이 가능한지 여부를 결정하고, 음성 인식이 가능한 것으로 결정됨에 따라 사용자 음성에 대한 응답 동작을 수행할 수 있는지 여부를 결정하며, 사용자의 음성에 대한 응답 동작을 수행할 수 있는 것으로 결정됨에 따라, 새로 수신된 사용자의 음성에 대한 응답 동작을 수행할 수 있다. 도 4는 일 실시 예에 따른 보이스 어시스턴트 서비스를 학습하는 과정을 설명하기 위한 도면이다. S410에서, 전자 장치는 사용자로부터 입력된 사용자 입력 시퀀스를 기 설정된 단위에 따라 복수의 입력으 로 분할한다. 사용자의 입력 시퀀스는 사용자의 입력을 기준으로 분할할 수 있다. 예를 들어, 전자 장치가 사용 자로부터 수신한 입력 시퀀스는 시간의 흐름에 따라 수신된 복수의 입력들을 포함할 수 있고, 각각의 입력 그룹 은 적어도 하나의 입력을 포함할 수 있다. 예를 들어, 입력 시퀀스가 4번의 사용자의 입력을 통해 획득되었다면, 입력 시퀀스는 4개로 분할된다. 이모티콘을 실행하는 입력 시퀀스는, '메시지 앱 실행', '새 메 시지 입력 기능 선택', '문자 입력 영역 선택' 및 '이모티콘 아이콘 선택'와 같이 4개의 입력으로 분할될 수 있 다. 예를 들어, 전자 장치는 분할된 입력 시퀀스가 입력되면, 의도 정보에 따라 복수의 입력 그룹으로 구분한 다. 전자 장치는 추론 모델을 이용하여 분할된 입력 시퀀스를 복수의 입력그룹으로 그룹한다. 추론 모델 은 복수의 입력 그룹 및 입력 그룹별 의도 정보에 기초하여 학습된 모델이다. . 즉, 전자 장치는 S410에 서 분할된 복수의 입력을, 추론 모델을 이용하여 의도 정보를 기준으로 복수의 입력 그룹으로 구분할 수 있다. 일 실시 예에 의하면, 추론 모델은 베이지안 네트워크(Bausian Network) 또는 1차 논리(First Order Logic, FOL)를 이용하여 입력 그룹별 추론의 적절한 정도에 관한 추론 가중치를 계산하고, 계산된 추론 가중치에 따라 현재의 추론 가중치를 업데이트할 수 있다. 추론 모델은 상기 복수의 입력을 포함하는 입력 시퀀스가 입력되면, 입력 시퀀스를 임의의 그룹으로 구분하여 추론 가중치를 계산한다. 추론 모델은, 임의의 그룹으로 구분하고 추 론 가중치를 계산하는 것은 그룹을 변경하면서 여러 차례 반복 수행한다. 추론모델은, 임의의 그룹별 추론 가중 치가 기 설정된 기준치 이상인 경우, 그 시점의 입력 시퀀스의 그룹을 입력 그룹으로 출력된다. 추론 모델은 복 수의 입력으로 구분된 입력 시퀀스와 각 시퀀스별 복수의 입력 그룹으로 학습된 모델 및 입력 그룹과 입력그룹 별 의도(intent) 정보를 이용하여 학습된 모델을 모두 포함한다. 추론 모델은 두 개의 모델이 조합된 형태일 수 도 있지만, 하나의 모델로 구성될 수도 있다. 전자 장치는 분할된 4개의 입력을 추론 모델을 이용하여 2개의 그룹으로 구분할 수 있다. 또한, 전자 장 치는 구분된 각 그룹에 대응하는 의도 정보를 출력할 수 있다. 예를 들면, '메시지 앱 실행' 및 '새 메시 지 입력 기능 선택'은 '메시지 입력 실행'이라는 의도(intent) 정보에 관련된 일련의 입력으로 제1 그룹으로 구 분할 수 있다. '문자 입력 영역 선택' 및 '이모티콘 아이콘 선택'은 '이모티콘 기능 실행'이라는 의도 정보와관련된 일련의 입력으로 제2 그룹으로 구분할 수 있다. 또 다른 실시 예에 의하면, 전자 장치는 사용자로부터, 홈 화면(예컨대, 잠금 해제 후 표시되는 첫 화 면)을 실행하고, 사진 또는 영상을 저장 및 관리하기 위한 갤러리 앱(Gallery app)을 실행하며, 갤러리 앱이 실 행된 상태에서 갤러리 앱이 검색 서비스를 위해 제공하는 검색바를 터치 하고, 검색바에 검색어 '웃는 얼굴'을 입력하는 일련의 사용자 입력 시퀀스들를 수신하는 경우, 전자 장치는 수신된 입력 시퀀스들을 의도 (intent) 단위에 따라 다음과 같이 복수의 입력 그룹으로 분할할 수 있다. 예를 들어, 전자 장치는, '홈 화면 실행' 및 '갤러리 앱(Gallery app) 실행' 을 '앱 실행' 이라는 의도(intent) 정보에 관련된 일련의 입력을 포함하는 제1 입력 그룹으로 결정하고, '갤러리 앱 실행' 및 '검색바 터치 입력' 을 '갤러리 검색' 이라는 의 도(intent)정보와 관련된 제2 입력 그룹으로 결정하며, '검색바 터치 입력' 및 '검색어 웃는 얼굴 을 입력하기 위한 일련의 터치 입력'을 '사진 검색' 이라는 의도(intent)정보와 관련된 제2 입력 그룹으로 결정할 수 있다. 즉, 전자 장치는 일련의 사용자 입력 시퀀스들을 복수의 입력 으로 분할하고, 분할된 복수의 입력들을 소 정의 입력 그룹으로 그룹핑하며, 입력 그룹 별 사용자 의도(intent) 정보를 식별할 수 있다. S420에서, 전자 장치는 입력 시퀀스와 관련된 유사 시퀀스들을 생성할 수 있다. 예를 들어, 전자 장치 는 소정의 입력 시퀀스가 입력되면, 입력된 유사 시퀀스와 유사한 유사 시퀀스들을 출력하는 유사 시퀀스 생성 모델을 이용하여, 사용자가 입력한 입력 시퀀스와 유사한 유사 시퀀스들을 생성할 수 있다. 일 실시 예에 의하면, 전자 장치가 생성한 유사 시퀀스들은 입력된 시퀀스와 동일한 의도 정보에 대응하 나 다른 동작을 수행하는 시퀀스들로써, 사용자로부터 입력된 음성 입력, 키 입력, 터치 입력, 모션 입력 각각 에 관한 유사 음성 입력, 유사 키 입력, 유사 터치 입력, 유사 모션 입력 중 적어도 하나를 포함할 수 있다. 예를 들어, 유사 시퀀스 생성 모델은 추론 모델을 통해 획득된 적어도 하나의 사용자 입력을 포함하는 입력 그 룹, 상기 입력 그룹 별 사용자 의도 정보에 기초하여 유사 시퀀스들을 생성할 수 있다. 예를 들어, 유사 시퀀스 생성 모델은 추론 모델로부터 '메시지 입력 실행'이라는 의도(intent) 정보 및 의도 정보와 관련된 입력 그룹으 로써, '메시지 앱 실행'과 관련된 시퀀스(예컨대, 홈 화면 선택, 메시지 앱 선택이라는 복수의 사용자 입력을 포함)를 수신할 수 있다. 유사 시퀀스 생성 모델은 '메시지 입력 실행'이라는 의도 정보와 관련하여, '메시지 앱 실행'과 관련된 시퀀스 만을 기초로 학습된 상태이므로, '메시지 입력 실행'이라는 의도 정보와 관련한 시퀀스로써, 홈 화면 선택 및 메시지 앱 선택 입력을 포함하는 '메시지 앱 실행'과 관련된 시퀀스만을 생성할 수 있다. 하지만, 유사 시퀀스 생성 모델은 추론 모델로부터 '메시지 입력 실행'이라는 의도 정보 및 의도 정보와 관련된 새로운 시퀀스인 '새 메시지 입력 기능 선택'을 하나의 입력 그룹(예컨대, 메시지 앱 선택, 새 메시지 메뉴 선택이라는 복수의 입력 을 포함)으로 수신하고, 수신된 '메시지 입력 실행'이라는 의도 정보 및 의도 정보와 관련된 새로운 입력 그룹 '새 메시지 입력 기능 선택'을 기초로 학습됨으로써, 사용자로부터 '메시지 앱 실행'과 관련된 입력 시퀀스가 수신될 경우, 동일한 의도 정보를 가지지만 다른 시퀀스인 '새 메시지 입력 기능 선택'을 유사 시퀀스로 생성할 수 있다. 즉, 전자 장치는 추론 모델로부터 출력되는 사용자 입력 그룹 및 입력 그룹 별 사용자의 의도 정보에 기 초하여 유사 시퀀스 생성 모델을 학습 시킬 수 있다. 전자 장치는 사용자로부터 수신된 입력 시퀀스에 더 하여, 유사 시퀀스 생성 모델을 이용하여 생성되는, 유사 시퀀스를 학습 데이터로 하여 보이스 어시스턴트 서비 스를 학습시킴으로써 사용자 음성에 대한 최적의 응답 동작을 제공할 수 있다. S430에서, 전자 장치는 유사 시퀀스 생성 모델을 이용하여 생성된, 사용자로부터 입력된 사용자 입력 시 퀀스와 관련된 유사 시퀀스를 S410의 방식으로 복수의 그룹으로 구분한다. 일 실시 예에 의하면, 전자 장치는 유사 시퀀스 생성 모델을 이용하여 생성된 유사 시퀀스를, 추론 모델로 전달할 수 있다. 전자 장치는 추 론 모델을 이용하여 S410의 방식과 유사하게 유사 시퀀스들을 복수의 입력 그룹으로 구분할 수 있다. S440에서, 전자 장치는 입력 그룹 별 사용자의 의도 정보를 식별한다. 예를 들어, 전자 장치는 추론 모델을 이용하여 현재 사용자로부터 입력된 입력 시퀀스의 입력 그룹, 또는 유사 시퀀스의 입력 그룹 별 의도 정보를 식별할 수 있다. S450에서, 전자 장치는 입력 시퀀스 또는 유사 시퀀스 중 적어도 하나에 포함된 복수의 입력 그룹 및 입력 그룹 별 의도 정보에 기초하여 보이스 어시스턴트 서비스를 학습할 수 있다. 전자 장치가 입력 시퀀스 및 상기 입력 시퀀스와 관련된 유사 시퀀스를 이용하여 보이스 어시스턴트 서비 스를 제공하는 과정을 구체적으로 설명한다. 예를 들어, 사진 또는 영상을 저장 및 관리하기 위한 갤러리 앱을 실행하며, 갤러리 앱이 실행된 상태에서 갤러리 앱이 제공하는 사진 중 하나를 선택하고, 선택된 사진을 공유하기 위한 공유 메뉴와 메시지 앱을 순차적으로 선택하는 일련의 시퀀스가 사용자에 의해 입력된다. 전자 장치 는 사용자에 의해 입력된 일련의 시퀀스에 대한 유사 시퀀스로, 메시지 앱을 실행하고, 새 메시지 작성 메뉴를 선택하고, 새 메시지 작성 기능이 실행된 상태에서 사진 첨부 메뉴와 갤러리 앱을 순차적으로 선택하는 시퀀스를 생성할 수 있다. 전자 장치에 의해 생성된 유사 시퀀스는 '사진을 메시지로 전송'하는 의도에 대응하 나, 사용자에 의해 입력된 시퀀스와는 다른 시퀀스이다. 즉, 일 실시 예에 따른 전자 장치는 일련의 사용자 입력 시퀀스들 외에도 상기 사용자 입력 시퀀스에 관 한 유사 시퀀스를 더 이용하여 보이스 어시스턴트 서비스를 학습함으로써, 사용자의 음성 입력이 수신될 시점의 전자 장치의 상태에 따라 최적의 시퀀스로 음성 입력에 대응되는 응답 동작을 수행할 수 있다. 예를 들면, 전자 장치가 갤러리 앱을 실행하고 있는 상태에서 사용자의 음성 입력이 수신되면, 갤러리 앱의 공유 메 뉴 및 메시지 앱을 순차적으로 선택하는 시퀀스로 응답 동작을 수행한다. 또한, 전자 장치가 메시지 앱을 실행하고 있는 상태에서 사용자의 음성 입력이 수신되면, 메시지 앱의 사진 첨부 메뉴와 갤러리 앱을 순차적으 로 선택하는 시퀀스로 응답 동작을 수행한다.. 또한, 전자 장치는 복수의 입력 그룹 별 대응하는 의도와 사용자 음성에 대응하는 텍스트 정보를 이용하 여 보이스 어시스턴트 서비스 모델의 자연어 이해 모델을 학습시킨다. 예를 들어, 전자 장치는 '웃는 얼 굴 사진 보여줘'와 같은 사용자 음성에 대한 응답 동작의 수행이 불가능한 것으로 결정하고, 사용자 음성에 대 한 응답 동작의 학습을 위해, 홈 화면 실행, 갤러리 앱 실행, 갤러리 앱이 실행된 상태에서 갤러리 앱이 검색 서비스를 위해 제공하는 검색바 터치, 검색바에 검색어 '웃는 얼굴'을 입력하는 일련의 사용자 입력 시퀀스들을 수신함으로써 자연어 이해 모델을 학습시킬 수 있다. 구체적으로, 전자 장치는 수신된 일련의 사용자 입력 시퀀스들을 '홈 화면 실행' 및 '갤러리 앱 실행' 입 력을 포함하는 제1 입력 그룹, '갤러리 앱 실행' 및 '검색바 터치'를 포함하는 제2 입력 그룹으로 구분하고, 제 1 입력 그룹 및 제2 입력 그룹 각각의 의도 정보 '앱 실행' 및 '갤러리 검색'에 기초하여 자연어 이해 모델을 학습 시킨다. 그러면, 보이스 어시스턴트 서비스 모델 내의 자연어 이해 모델은 사용자로부터 '웃는 얼굴 사진 보여줘'와 같은 사용자 음성에 대응되는 텍스트가 수신되는 경우, '앱 실행' 및 '갤러리 검색'과 같은 의도 정 보와 '갤러리' 및 '웃는 얼굴'과 같은 슬롯 정보를 출력할 수 있다. 본 개시에 따른 보이스 어시스턴트 서비스 모델의 자연어 이해 모델과 달리 일반적인 자연어 이해(NLU) 모델의 경우, '웃는 얼굴 사진 보여줘'와 같은 사용자 음성에 대응된 텍스트를 기초로 학습된 상태에서, '수원에서 찍 은 사진 보여줘'와 같은 사용자 음성에 대응되는 텍스트가 수신되는 경우, '앱 실행' 및 '갤러리 검색'과 같은 의도 정보 및 '갤러리'와 같은 슬롯 정보를 식별할 수는 있지만, '수원'과 같은 슬롯 정보는 식별하지 못할 수 있다. 그러나 본 개시에 따른 보이스 어시스턴트 서비스 모델 내의 자연어 이해 모델은, '웃는 얼굴 사진 보여줘'와 같은 사용자 음성에 대응되는 텍스트와 다른 '수원에서 찍은 사진 보여줘'와 같은 사용자 음성에 대응되는 텍스 트가 수신되는 경우에도, '웃는 얼굴 사진 보여줘'와 같은 사용자 음성에 대한 응답 동작을 학습하기 위해 수신 되었던, 일련의 사용자 입력 시퀀스에 포함된 복수의 입력 그룹 및 그룹 별 사용자 의도 정보에 기초하여, '수 원에서 찍은 사진 보여줘'와 같은 텍스트 역시 동일한 의도 정보를 포함한다는 것을 결정할 수 있다. 따라서, 본 개시에 따른 자연어 이해 모델은 '웃는 얼굴 사진 보여줘'는 다른 텍스트이지만, 동일한 의도 정보 를 포함하는 사용자 음성에 대응되는 텍스트(='수원에서 찍은 사진 보여줘')가 수신되는 경우, 동일한 의도 정 보를 포함하는 과거 수신되었던 텍스트 '웃는 얼굴 사진 보여줘'의 슬롯 정보 '웃는 얼굴'에 기초하여, '수원에 서 찍은 사진 보여줘'의 슬롯 정보를 '수원'으로 결정할 수 있다. 일 실시예에서, 전자 장치는 사용자 음성 및 사용자 음성에 대응하는 텍스트 정보를 각각 입력받아, 보이 스 어시스턴트 서비스 모델의 ASR 모델을 학습시킬 수도 있다. 예를 들어, 자동 음성 인식(ASR) 모델은 사용자 음성 신호를 수신하면, 수신된 음성 신호의 음향 패턴을 기준 음향 패턴들과 비교(음소(phonemes) 단위 비교)함으로써 기준 음향 패턴들 중, 가장 유사한 패턴에 대응되는 텍 스트를 출력한다. 이때 자동 음성 인식 모델(ASR)이 학습하는 복수의 기준 음향 패턴들은 다수의 후보 텍스트들 을 나타내고, 자동 음성 인식(ASR) 모델은 다수의 후보 텍스트 들 중, 획득된 사용자 음성의 음향 패턴과 가장 유사한 음향 패턴을 나타내는 후보 텍스트에 기초하여, 사용자 음성을 변환한다. 본 개시에 따른 전자 장치는 사용자 음성 및 사용자 음성에 대응하는 텍스트 정보에 기초하여, 사용자 음 성의 음향 패턴을 잘 나타내는 복수의 기준 패턴들을 학습함으로써, 음성 인식의 정확도를 향상시킬 수 있다.예를 들어, 전자 장치는 '웃는 얼굴 사진 보여줘'와 같은 사용자 음성에 대한 응답 동작의 수행이 불가능 한 것으로 결정하고, 사용자 음성에 대한 응답 동작의 학습을 위해 일련의 사용자 입력 시퀀스들을 수신할 수 있다. 이때, 전자 장치는 응답 동작의 수행이 불가능한 것으로 결정된 사용자 음성인 '웃는 얼굴 사진 보 여줘' 를 음소 단위로 분할하고, 분할된 음소 단위 별 음향 패턴을 정의하는 벡터를, 미리 저장된 ASR 데이터 베이스의 기준 음향 패턴을 구성하는 음소 단위 별 벡터와 비교함으로써 음성 인식 점수를 결정할 수 있다. 음 성 인식 점수는 사용자 음성의 음향 패턴이 기준 음향 패턴에 대응될 확률 값을 나타낼 수 있다. 전자 장치는 '웃는 얼굴 사진 보여줘'와 같은 사용자 음성에 대한 음소 단위 별 벡터를, 미리 저장된 ASR 데이터 베이스의 기준 음향 패턴을 구성하는 음소 단위 벡터들과 비교함으로써 획득된 음성 인식 점수가 기 설 정된 임계 점수(score) 이하인 경우, '웃는 얼굴 사진 보여줘'와 같은 사용자 음성에 대한 음소 단위 별 벡터를 ASR 데이터 베이스에 추가하고, 이미 저장된 ASR 데이터 베이스 내 기준 음향 패턴들의 순위를 재조정할 수 있 다. 기준 음향 패턴들의 순위는 사용자 음성의 음소 단위 별 벡터와 기준 음향 패턴 내 음소 단위 별 벡터의 유 사 정도에 기초하여 결정될 수 있고, 유사 정도는 음소의 피치, 에너지, 지속 시간 등에 따라 달라질 수 있다. 또한, 전자 장치는 사용자 음성에 대응하는 텍스트 정보의 일부를 이용하여 보이스 어시스턴트 서비스 모 델의 자연어 생성 모델을 학습시킬 수도 있다. 예를 들면, 사용자 음성에 대응하는 텍스트 정보 중 기능을 지칭 하는 단어를 선택하여, 자연어 생성 모델에 선택된 단어를 추가할 수 있다. 사용자 음성에 대응하는 텍스트 정 보가 '사진 선택해서 메시지로 전송해줘'인 경우, '사진 선택해서 메시지로 전송'을 선택하여 자연어 생성 모델 에 등록할 수 있다. 그러면 자연어 생성 모델은 이미 등록되어 있는 텍스트 정보와 새롭게 등록된 텍스트 정보 를 이용하여 '사진 선택해서 메시지로 전송 완료했습니다.'라는 응답 메시지를 출력할 수 있다. 또한, 전자 장치는 사용자 음성에 대한 응답 동작을 학습하기 위해 수신된 일련의 사용자 입력 시퀀스의 입력 그룹, 입력 그룹 별 의도 정보 또는 슬롯 정보에 기초하여 대화 관리(DM) 모델을 학습시킬 수 있다. 예를 들어, 전자 장치는 '웃는 얼굴 사진 보여줘'와 같은 사용자 음성에 대한 응답 동작의 수행이 불가능 한 것으로 결정하고, 사용자 음성에 대한 응답 동작의 학습을 위해 일련의 사용자 입력 시퀀스들(예컨대 홈 화 면 실행, 갤러리 앱 실행, 갤러리 앱이 실행된 상태에서 갤러리 앱이 검색 서비스를 위해 제공하는 검색바 터치, 검색바에 검색어 '웃는 얼굴'을 입력하는 일련의 사용자 입력)을 수신할 수 있다. 전자 장치는 사용자 음성에 대한 응답 동작의 학습 과정에서 수신되었던 사용자 입력 시퀀스 내 입력 그 룹별 의도 정보 및 상기 의도 정보에 대응하는 슬롯 정보를 매칭함으로써 대화 관리(DM)모델을 학습한다. 예를 들어, 전자 장치는 '웃는 얼굴 사진 보여줘'와 같은 사용자 음성에 대한 응답 동작의 학습 과정에서 수신된 사용자 입력 시퀀스의 제1 입력 그룹(예컨대, '홈 화면 실행' 및 '갤러리 앱 실행')의 의도 정보 '앱 실 행'과 상기 제1 입력 그룹의 슬롯 정보 '갤러리'를 매칭함으로써 제1 대화 경로를 생성하고, 사용자 입력 시퀀 스의 제2 입력 그룹(예컨대, '갤러리 앱 실행' 및 '검색바 터치' 입력)의 의도 정보 '갤러리 검색'과 상기 제2 입력 그룹의 슬롯 정보 '검색바'를 매칭함으로써 제2 대화 경로를 생성하며, 사용자 입력 시퀀스의 제3 입력 그 룹(예컨대, '검색바 터치' 및 '검색어 '웃는 얼굴' 입력)의 의도 정보 '갤러리 검색'과 제3 입력 그룹의 슬롯 정보'웃는 얼굴'을 매칭함으로써 제3 대화 경로를 결정할 수 있다. 전자 장치는 사용자 입력 시퀀스 내 입력 그룹 별 의도 정보 및 상기 의도 정보에 대응되는 슬롯 정보를 매칭함으로써 생성된 복수의 대화 경로를 이용하여 대화 관리 맵(map)을 생성하고, 생성된 대화 관리 맵을 갱신 함으로써 대화 관리(DM) 모델을 학습할 수 있다. 예를 들어, '웃는 얼굴 사진 보여줘'와 같은 사용자 음성에 대한 응답 동작의 학습 과정에서 수신된 사용자 입 력 시퀀스에 기초하여 학습된 대화 관리(DM)모델은 '얼굴 사진 보여줘'와 같은 텍스트가 수신되는 경우, NLU 모 델을 통하여 '얼굴 사진 보여줘'와 관련된 의도 정보를 '앱 실행' '갤러리 검색' 및 '검색바 터치'로 결정하고, '웃는 얼굴 사진 보여줘'와 같은 사용자 음성에 대한 응답 동작 학습 과정에서 수신된 일련의 사용자 입력 시퀀 스들 중, 가장 마지막으로 식별된 의도 정보인 '검색바 터치'와 관련된 제3 대화 경로의 슬롯 정보에 기초하여, '웃는 얼굴 사진 보여드릴까요'와 같은 응답 동작을 전자 장치가 출력하도록 할 수 있다. 즉, 대화 관리(DM) 모델은 사용자 입력 시퀀스 내 입력 그룹, 상기 입력 그룹별 의도 정보 및 슬롯 정보에 기초 하여, 대화 관리 모델을 학습함으로써, 새로 수신된 사용자 입력 시퀀스 내 의도 정보 또는 슬롯 정보를 포함하 는 대화 경로를 식별하고, 식별된 대화 경로에 따라 사용자 음성에 대한 자연스러운 응답 동작을 제공하도록 할 수 있다.또한, 전자 장치는 복수의 입력 그룹 및 의도 정보는 보이스 어시스턴트 서비스 모델의 액션 플랜(AP) 모 델을 학습시킨다. 예를 들어, 전자 장치는 '웃는 얼굴 사진 보여줘'와 같은 사용자 음성에 대한 응답 동작의 수행이 불가능 한 것으로 결정하고, 사용자 음성에 대한 응답 동작의 학습을 위해 일련의 사용자 입력 시퀀스들(예컨대 홈 화 면 실행, 갤러리 앱 실행, 갤러리 앱이 실행된 상태에서 갤러리 앱이 검색 서비스를 위해 제공하는 검색바 터치, 검색바에 검색어 '웃는 얼굴'을 입력하는 일련의 사용자 입력)을 수신할 수 있다. 전자 장치는 '웃는 얼굴 사진 보여줘'와 같은 사용자 음성에 대한 응답 동작의 학습 과정에서 수신된 사 용자 입력 시퀀스 내, 의도 정보에 의해 식별되는 입력 그룹들이 입력된 순서에 기초하여 보이스 어시스턴트 서 비스 모델의 서비스 동작 순서를 결정하기 위한 액션 플랜 모델을 학습 시킨다. 예를 들어, 전자 장치는 사용자 음성에 대한 응답 동작의 학습 과정에서 수신된 사용자 입력 시퀀스로써, '앱 실행' 이라는 의도 정보를 나타내는 제1 입력 그룹(예컨대, '홈 화면 실행' 및 '갤러리 앱 실행'), '갤러리 앱 실행' 이라는 의도 정보를 나타내는 제2 입력 그룹 (예컨대, '갤러리 앱 실행' 및 '검색바 터치' 입력) 및 '갤 러리 검색' 이라는 의도 정보를 나타내는 제3 입력 그룹(예컨대, '검색바 터치' 및 '검색어 '웃는 얼굴' 입력) 을 순서대로 수신하고, 입력 그룹, 입력 그룹 별 의도 정보 및 의도 정보 단위로 식별되는 입력 그룹의 순서에 기초하여 액션 플랜 모델을 학습 시킬 수 있다. 또한, 전자 장치는 사용자 입력 시퀀스 내 입력 그룹이 수신될 때 전자 장치의 동작 상태에 기초하여, 액션 플랜 모델을 학습 시킬 수도 있다. 전자 장치는 학습된 액션 플랜 모델을 이용하여 결정된 사용자 음성에 대한 응답 동작의 순서에 따라 사 용자 음성에 대한 응답 동작을 수행한다. 예를 들어, '웃는 얼굴 사진 보여줘'와 같은 사용자 음성에 대한 응답 동작을 학습한 전자 장치는 현재 홈 화면이 표시된 상태에서, '웃는 얼굴 사진 보여줘'와 같은 사용자 음 성에 대응되는 텍스트의 의도 정보 '앱 실행', '갤러리 앱 실행' 및 '갤러리 검색'을 식별하고, 대화 관리(DM) 모델을 이용하여 식별된 의도 정보가 나타내는 대화 경로에 기초하여, '갤러리 앱을 실행할까요?' '웃는 얼굴 검색어를 입력할까요'와 같은 응답 동작들을 생성할 수 있다. 전자 장치는 '갤러리 앱을 실행할까요?' '웃는 얼굴 검색어를 입력할까요'와 같은 응답 동작들 중, 현재 전자 장치의 동작 상태는 홈 화면이 표시된 상태이므로, '웃는 얼굴 사진 보여줘'와 같은 사용자 음성에 대한 응답 동작으로써, '갤러리 앱을 실행할까요?'를 출력할 수 있다. 즉, 전자 장치는 사용자 입력 시퀀스 내 복수의 입력 그룹 및 입력 그룹 별 사용자의 의도에 기초하여 액션 플랜 모델을 학습함으로써, 사용자로부터 입 력된 사용자 음성에 대한 일련의 응답 동작들의 순서를 관리할 수 있다. 일 실시 예에 의하면, 전자 장치는 사용자 음성 및 사용자 음성에 대응하는 텍스트 정보에 기초하여 텍스 트 음성 변환(Text to Speech, TTS) 모델을 학습 시킬 수도 있다. TTS 모델은 사용자 음성에 대한 응답 동작으 로써 전자 장치가 생성한 텍스트의 음향 패턴을 TTS 데이터 베이스 내의 기준 음향 패턴들과 비교함으로써 기준 음향 패턴들 중 가장 유사한 기준 음향 패턴에 대응되는 사용자 음성 신호를 출력할 수 있다. 예를 들어, TTS 모델은, '수원에서 찍은 사진 보여줘'와 같은 사용자 음성이 변환된 텍스트를 단어 단위로 분할 하고, 분할된 단어 단위를 다시 음소 단위로 분할한다. TTS 모델은 음소 단위 별 음향 패턴을 정의하는 벡터를, 미리 저장된 TTS 데이터 베이스의 기준 음향 패턴을 구성하는 음소 단위 별 벡터와 비교함으로써 텍스트 인식 점수를 결정할 수 있다. 텍스트 인식 점수는 응답 동작으로써 생성된 텍스트의 음향 패턴이 기준 음향 패턴에 대응될 확률 값을 나타낼 수 있다. 전자 장치는 응답 동작으로써 생성된 '수원에서 찍은 사진 보여줘'와 같은 텍스트에 대한 음소 단위 별 벡터를 미리 저장된 TTS 데이터 베이스의 기준 음향 패턴을 구성하는 음소 단위 벡터들과 비교함으로써 획득된 텍스트 인식 점수가 기설정된 임계 점수(score) 이하인 경우, '수원에서 찍은 사진 보여줘'와 같은 텍스트에 대 한 음소 단위 별 벡터를 TTS 데이터 베이스에 추가함으로써, 이미 저장된 TTS 데이터 베이스 내 기준 음향 패턴 들의 순위를 재조정할 수 있다. 기준 음향 패턴들의 순위는 응답 동작으로써 생성된 텍스트의 음소 단위 별 벡 터와 기준 음향 패턴 내 음소 단위 별 벡터의 유사 정도를 나타낼 수 있고, 유사 정도는 음소의 피치, 에너지, 지속 시간 등에 따라 달라질 수 있다. TTS 모델은 기준 음향 패턴들의 순위가 재조정된 TTS 데이터 베이스 내 기준 음향 패턴을 이용하여, 응답 동작 으로써 새로 생성된 '수원에서 찍은 사진 보여줘'와 같은 텍스트의 음향 패턴에 가장 유사한 기준 음향 패턴을 식별함으로써, 사용자 음성 신호를 출력할 수 있다.도 5는 일 실시 예에 따른 전자 장치가 보이스 어시스턴트 서비스를 학습하는 과정을 설명하기 위한 도면이다. 전자 장치의 보이스 어시스턴트 서비스 모델이, \"xx 중국집으로 전화 연결 해줘\"와 같은 사용자 음성에 대한 응답 동작을 학습하기 전 전자 장치의 동작을 먼저 설명한다. 전자 장치와 사용자와의 대화 예 가 도시된 박스를 참조하면, 전자 장치는 사용자로부터, \"xx 중국집으로 전화 연결 해줘\"와 같은 사 용자의 음성을 획득할 수 있다. 전자 장치는 ASR 모델을 이용하여 획득된 사용자 음성을 텍스트로 변환하 고, NLU 모델을 이용하여 변환된 텍스트의 의도 정보를 '전화 연결' 결정하나, 'XX 중국집'과 같은 슬롯 정보를 식별하지 못할 수 있다. 또 다른 실시 예에 의하면, 전자 장치는 의도 정보 및 슬롯 정보를 식별하였으나, 전자 장치의 메모리 내 XX 중국집의 전화 번호를 미리 저장하고 있지 않기 때문에, \"XX 중국집으 로 전화 연결 해줘\"와 같은 사용자의 음성에 대한 응답 동작을 수행할 수 없는 것으로 결정하고, \"죄송합니다. 제공하지 않는 서비스 입니다.\"와 같은 에러 메시지를 출력할 수 있다. 또한, 전자 장치는 \"xx 중국집으로 전화 연결 해줘\"와 같은 사용자의 음성에서 결정된 의도 정보 및 슬롯 정보에 대응되는 컴퓨터 판독 가능한 명령(instruction)이, 현재 전자 장치의 동작 상태(예컨대 게임 애플리케 이션을 실행 중인 상태)에서 수행 가능한 동작에 관한 명령이 아닌 경우, 상기 사용자 음성에 대한 응답 동작을 수행할 수 없는 것으로 결정할 수도 있다. 전자 장치는 사용자의 음성에 대한 응답 동작을 수행할 수 없는 것으로 결정됨에 따라, \"죄송합니다. 제공하지 않는 서비스 입니다\"와 같은 에러 메시지를 출력함과 함께, \"학 습 할까요?\"와 같은 학습 확인 요청 메시지를 출력할 수 있다. 일 실시 예에 의하면, 전자 장치는 학습 확인 메시지 출력 후, 출력된 학습 확인 메시지에 대하여 사용자 로부터 \"그래\"와 같은 단답형 사용자 음성이 입력되면, \"학습 시작할게요. 동작을 알려주세요\"와 같이 학습 시 작 안내 메시지를 출력함과 함께 보이스 어시스턴트 서비스 학습을 위한 사용자 입력을 수신하는데 필요한 마이 크로폰 모듈, 터치 스크린 모듈, UI 모듈등을 활성화 할 수 있다. 일 실시 예에 의하면, 전자 장치는 사 용자로부터 \"학습을 시작하자\"와 같은 미리 설정된 트리거 음성 입력이 수신되는 경우에도 학습 시작 안내 메시 지를 출력 후, 일련의 응답 동작 학습을 위한 사용자 입력 시퀀스의 수신을 대기할 수도 있다. 전자 장치와 사용자와의 대화 예가 도시된 박스를 참조하면, \"학습 시작할게요. 동작을 알려주세 요\"와 같이 출력된 학습 시작 안내 메시지에 따라, 사용자로부터 응답 동작을 학습하기 위한 일련의 입력 시퀀 스들을 수신할 수 있다. 예를 들어, 전자 장치는 학습 시작 안내 메시지에 따라 입력되는 \"웹브라우저 실 행해\", \"검색창에 '중국집' 입력하고 검색 결과 보여줘\"와 같은 사용자 음성들을 입력 시퀀스로써 획득할 수 있 다. 예를 들어, 전자 장치는 홈 화면을 표시한 상태에서 수행 가능한 명령어로써, \"웹 브라우저 실행해\"와 같 은 사용자 음성에 대한 응답 동작인 '웹 브라우저 애플리케이션 실행'이라는 응답 동작을 수행하기 위한 명령 (instruction)을 전자 장치의 메모리에 미리 저장할 수 있다. 또한, 전자 장치는 웹 브라우저를 실행한 상태에서 수행 가능한 명령어로써 \"검색창에 중국집 입력하고 검색 결과 보여줘\"와 같은 사용자 음성에 대한 응 답 동작으로써 '검색창 실행' 및 '검색창에 중국집 텍스트 입력'과 같은 응답 동작을 수행하기 위한 명령들 (instructions)을 전자 장치의 메모리에 미리 저장할 수 있다. 전자 장치는 학습 시작 안내 메시지에 따라 입력되는 \"웹브라우저 실행해\", \"검색창에 '중국집' 입력하고 검색 결과 보여줘\"와 같은 사용자 음성들에 대한 응답 동작의 수행이 가능한 것으로 결정하고, 웹 브라우저 애 플리케이션을 실행하고, 웹 브라우저를 실행한 상태에서 검색창에 '중국집'을 입력함으로써 검색되는 중국집 전 화 번호 리스트를 사용자에게 출력할 수 있다. 일 실시 예에 의하면, 전자 장치는 사용자로부터 \"xx 중국집 전화 번호 보여줘\"와 같은 사용자 음성을 획 득되면, 검색된 중국집 전화 번호 리스트 중, xx 중국집 전화 번호를 검색한 후, \"xx 중국집 전화 번호는 xx- xx-xxx 입니다\"와 같은 메시지를 출력할 수 있다. 일 실시 예에 의하면, 전자 장치는 전자 장치가 응답 동작의 수행이 불가능한 것으로 결정한 사용 자 음성 \"xx 중국집으로 전화 연결 해줘\"와 같은 사용자 음성이 재 수신되는 경우, 학습 동작을 종료하고, \"학 습 되었습니다.\" 및 \"명령어는 어떻게 지정할까요?\"와 같은 학습 종료 안내 메시지를 출력할 수 있다. 일 실시 예에 의하면, 전자 장치는 \"학습 종료\"(미도시)와 같이 학습 동작의 종료를 나타내는 미리 설정된 음성 입력이 수신되는 경우, 또는 전자 장치의 사용자 입력 인터페이스(미도시) 또는 전자 장치와 유선 또는 무선으 로 연결되는 리모트 콘트롤(Remote Control)를 통하여 학습 동작의 종료를 나타내는 미리 설정된 종료 시퀀스가 수신되는 경우에도, 학습 동작을 종료하고 학습 종료 안내 메시지를 출력할 수도 있다. 도 5의 박스 및 박스를 참조하여, 전자 장치의 보이스 어시스턴트 서비스 모델이 \"xx 중국집으 로 전화 연결 해줘\"와 같은 사용자 음성에 대한 응답 동작을 학습한 후 전자 장치의 동작을 일 실시 예로 설명한다. \"xx 중국집으로 전화 연결 해줘\"와 같은 사용자 음성에 대한 응답 동작을 학습한 전자 장치는 전자 장치는 사용자로부터 'xx 중국집으로 전화 연결 해줘\"와 같은 제1 사용자 음성을 획득할 수도 있지 만, \"주변 중국집으로 전화 연결 해줘\"와 같은 제2 사용자 음성을 획득할 수도 있다. 여기에서, 제1 사용자 음 성이 변환된 텍스트의 의도 정보는 제2 사용자 음성이 변환된 텍스트의 의도 정보와 동일할 수 있다. 일 실시 예에 의하면, 전자 장치는 \"xx 중국집으로 전화 연결 해줘\"와 같은 사용자 음성에 대한 응답 동 작을 학습하는 과정에서, 사용자로부터 입력되었던 \"웨브라우저 실행해\" 또는 \"검색창에 '중국집' 입력하고 검 색 결과 보여줘\"와 같은 사용자 음성에 대한 응답 동작들 역시 학습할 수 있다. 따라서, 전자 장치는 \"xx 중국집으로 전화 연결 해줘\"와 동일하지는 않지만, 의도 정보가 동일하지만, 음성 시퀀스가 다른 \"주변 중국집 으로 전화 연결 해줘\"와 같은 사용자 음성이 획득되는 경우, 웹 브라우저 애플리케이션 실행 후, 웹 브라우저 애플리케이션이 제공하는 검색창에 '중국집'을 입력함으써 검색되는 결과를 출력할 수 있다. 또한, 전자 장치는 \"주변 중국집으로 전화 연결 해줘\"와 같은 사용자 음성을 사용자 의도 단위에 따라, 일련의 사용자 입력 시퀀스들을 포함하는 복수의 입력 그룹 \"주변\" \"중국집\" \"전화 연결 해줘\" 와 같이 분할하 고, \"xx 중국집으로 전화 연결 해줘\"와 같은 사용자 음성 내 입력 그룹 중 일부와 유사한, \"중국집\" \"전화 연결 해줘\"와 같은 입력 그룹 각각의 의도(intent)에 기초하여, \"xx로 전화 연결 할까요?\"와 같은 응답 메시지를 출 력할 수 있다. 즉, 본 개시에 따른 전자 장치는 사용자 음성의 시퀀스별 의도에 기초하여 보이스 어시스턴트 서비스를 학습할 수 있기 때문에, \"xx 중국집으로 전화 연결 해줘\"와 동일하지는 않지만, 시퀀스별 사용자 의도가 일부 유사한 \"주변 중국집으로 전화 연결 해줘\"와 같은 사용자 음성이 획득되는 경우에도 \"xx 중국집으로 전화 연결 할까요?\"와 같은 응답 메시지를 출력함으로써, 사용자의 편의를 향상시킬 수 있다. 도 6은 일 실시 예에 따른 전자 장치가 보이스 어시스턴트 서비스를 학습하는 과정을 설명하기 위한 도면이다. 전자 장치는 \"xx 걸그룹 2018년도 앨범 재생해줘\"와 같은 사용자 음성이 획득되면, ASR 모델을 이용하여 \"xx 걸그룹 2018년도 앨범 재생해줘\"와 같은 사용자 음성의 인식이 가능한지 여부를 결정할 수 있다. 전자 장치 는 사용자의 음성 인식이 가능한 경우, NLU 모델을 이용하여, 사용자 음성이 변환된 텍스트로부터 획득된 의도 정보 또는 슬롯 정보에 대한 확률 값에 기초하여 사용자 음성에 대한 응답 동작의 수행이 가능한지 여부를 결정할 수 있다. 또한, 전자 장치는 \"xx 걸그룹 2018년도 앨범 재생해줘\"와 같은 사용자 음성이 변환된 텍스트에 대한 의도 정보에 대한 확률 값 및 슬롯 정보에 대한 확률 값이 기 설정된 임계치 이상인 경우에도, 현재 전자 장치의 동작 상태에서 수행 가능한 응답 동작에 관한 명령이 아닌 경우, 미리 정의한 응답 동작에 관 한 명령이 아닌 경우, 사용자 음성에 대한 응답 동작을 수행할 수 없는 것으로 결정할 수 있다. 전자 장치는 획득된 사용자 음성에 대한 응답 동작이 수행할 수 없는 것으로 결정됨에 따라 \"죄송합니다. 제공하지 않는 서비스 입니다.\"와 같은 에러 메시지를 출력할 수 있다. 또한, 전자 장치는 에러 메시지 출력 후, \"학습할까요\"와 같은 응답 동작과 관련된 사용자 입력 시퀀스를 요청하는 학습 확인 요청 메시지를 출 력할 수 있다. 전자 장치는 학습 확인 요청 메시지 출력 후, 출력된 학습 확인 메시지에 대하여 사용자로 부터 \"그래\"와 같은 단답형 사용자 음성이 획득되면, \"학습 시작할게요. 동작을 알려주세요\"와 같은 학습 시작 안내 메시지를 출력함과 함께 학습 모드로 전환할 수 있다. 도 6의 박스에 도시된 전자 장치의 동작 은 도 5의 박스에 도시된 전자 장치의 동작에 대응될 수 있다. 일 실시 예에 의하면, 전자 장치는 학습 시작 안내 메시지 출력 후에도, 사용자로부터 \"xx 걸 그룹 2018 년도 앨범 재생해줘\"와 같이, 현재 전자 장치의 동작 상태에서 전자 장치가 수행 가능한 응답 동작에 관한 명령 이 아닌 사용자 음성을 획득할 수도 있다. 전자 장치는 학습 시작 안내 메시지 출력과 함께 학습 모드로 전환된 후에도, 여전히 응답 동작의 수행이 불가능한 것으로 결정되는 사용자 음성이 획득되는 경우, 대화 관리 모델의 대화 관리 맵 및 보이스 어시스턴트 서비스 동작 순서를 결정하는 액션 플랜 모델에 기초하여, \"구체적 으로 말씀해주세요\"와 같은 학습 보충 메시지를 출력할 수도 있다. 전자 장치는 \"구체적으로 말씀해주세요\"와 같은 학습 보충 메시지 출력 후 사용자로부터 \"음악 애플리케 이션 실행해줘\", \"검색 창에 xx 걸그룹 2018 앨범 입력 해줘\"와 같은 사용자 음성을 획득할 수 있다. 또한, 전자 장치는 홈 화면(예컨대, 잠금 장치 해제 후 첫 화면)이 표시된 상태에서, \"음악 애플리케이션 실행해\"와 같은 사용자 음성에 대한 응답 동작인 '음악 애플리케이션 실행'이라는 응답 동작을 수행하기 위한명령(instruction)을, 현재 전자 장치의 동작 상태에서 수행 가능한 명령어로 미리 저장할 수 있다. 또한, 전자 장치는 음악 애플리케이션을 실행한 상태에서 수행 가능한 명령어로써, \"검색창에 xx 걸그룹 2018 앨범 입력 해줘\"와 같은 사용자 음성에 대한 응답 동작으로써 '검색창 실행' 및 '검색창에 xx 걸그룹 2018 앨범 입력'과 같은 응답 동작을 수행하기 위한 명령들(instructions)을 보이스 어시스턴트 서비스가 수행 가능한 응 답 동작에 관한 명령으로 설정할 수 있다. 따라서, 전자 장치는 학습 보충 메시지 출력 후 \"음악 애플리케이션 실행해줘\", \"검색 창에 xx 걸그룹 2018 앨범 입력 해줘\"와 같은 사용자 음성에 대한 응답 동작을 수행할 수 있는 것으로 결정하고, \"xx 걸그룹 2018 앨범은 3장입니다. 앨범 목록을 모두 표시할 까요?\"와 같은 메시지를 출력할 수도 있다. 전자 장치는 \"xx 걸그룹 2018 앨범은 3장입니다. 앨범 목록을 모두 표시할 까요?\"와 같이 출력된 메시지 에 따라, 사용자로부터 \"그래\", \"2018년도 두번째 앨범 재생해줘\"와 같은 사용자 음성을 획득할 수 있다. 전자 장치는 \"xx 걸그룹 2018 앨범은 3장입니다. 앨범 목록을 모두 표시할 까요?\"와 같이 출력된 메시지에 따 라, 사용자로부터, 처음 획득한 \"xx 걸그룹 2018년도 앨범 재생 해줘\"와 다른 \"2018년도 두 번째 앨범 재생해줘\"와 같은 사용자 음성을 획득할 수도 있다. 일 실시 예에 의하면, 전자 장치는 \"xx 걸 그룹 2018 년도 앨범 재생해줘\"와 같이, 처음 획득한 사용자 음성과 동일한 사용자 음성이 재 수신되는 경우, 보이스 어시 스턴트 서비스의 학습을 종료하고, \"학습 되었습니다.\" 와 같은 학습 종료 안내 메시지 및 \"명령어는 어떻게 지 정할까요\"와 같은 명렁어 지정 요청 메시지를 출력할 수도 있다. 그러나, 전자 장치는 \"xx 걸 그룹 2018 년도 앨범 재생해줘\"와 다른 \"2018년도 두 번째 앨범 재생해줘\"와 같은 사용자 음성이 획득되는 경우에는, 사용 자로부터 학습 동작의 종료를 나타내는 \"학습 종료\"와 같은 사용자 음성이 수신되는 경우에만 \"학습 되었습니다.\" 및 \"명령어는 어떻게 지정할까요?\"와 같은 학습 종료 안내 메시지 및 명령어 지정 요청 메시지를 출력할 수도 있다. 도 7은 일 실시 예에 따른 전자 장치가 보이스 어시스턴트 모델을 학습하는 과정을 설명하기 위한 도면이다. 도 7의 박스에 도시된 전자 장치의 동작들은 도 5에 도시된 박스의 동작에 대응될 수 있으므로 구체적인 설명은 생략하기로 한다. 도 7의 박스를 참조하면, 전자 장치는 학습 확인 요청 메시지 출력 후, 사용자로부터 \"그래\"와 같은 단답형 사용자 음성이 획득됨에 따라 \"학습 시작 할게요. 동작을 알려주세요\"와 같은 학습 시작 안내 메시지를 출력할 수 있다. 도 7의 박스를 참조하면, 전자 장치는 출력된 안내 메시지 \"학습 시작할게요. 동작을 알려주세요\" 와 같이 출력된 학습 시작 안내 메시지에 따라, 사용자로부터 응답 동작을 학습하기 위한 일련의 입력 시퀀스들 을 수신할 수 있다. 예를 들어, 전자 장치는 학습 시작 안내 메시지에 따라 입력되는 \"웹브라우저 실행해\", \"검색창에 '중국집' 입력하고 검색 결과 보여줘\"와 같은 사용자 음성들을 입력 시퀀스로써 획득할 수 있다. 예를 들어, 전자 장치는 홈 화면을 표시한 상태에서 수행 가능한 명령어로써, \"웹 브라우저 실행해\"와 같 은 사용자 음성에 대한 응답 동작인 '웹 브라우저 애플리케이션 실행'이라는 응답 동작을 수행하기 위한 명령 (instruction)을 보이스 어시스턴트 서비스가 수행할 수 있는 응답 동작에 관한 명령으로 미리 설정할 수 있다. 또한, 전자 장치는 웹 브라우저를 실행한 상태에서 수행 가능한 명령어로써 \"검색창에 중국집 입력하고 검색 결과 보여줘\"와 같은 사용자 음성에 대한 응답 동작으로써 '검색창 실행' 및 '검색창에 중국집 텍스트 입 력'과 같은 응답 동작을 수행하기 위한 명령들(instructions)을 전자 장치의 메모리에 미리 저장할 수 있다. 따라서, 전자 장치는 학습 시작 안내 메시지에 따라 입력되는 \"웹브라우저 실행해\", \"검색창에 '중국집' 입력하고 검색 결과 보여줘\"와 같은 사용자 음성들에 대한 응답 동작의 수행이 가능한 것으로 결정하고, 웹 브 라우저 애플리케이션을 실행하고, 웹 브라우저를 실행한 상태에서 검색창에 '중국집'을 입력함으로써 검색되는 중국집 전화 번호 리스트를 사용자에게 출력할 수 있다. 또한, 전자 장치는 사용자로부터 \"xx 중국집 전 화 번호 보여줘\"와 같은 사용자 음성이 획득되면, 검색된 중국집 전화 번호 리스트 중, xx 중국집 전화 번호를 검색한 후, \"xx 중국집 전화 번호는 xx-xx-xxx 입니다\"와 같은 메시지를 출력할 수 있다. 일 실시 예에 의하면, 전자 장치는 전자 장치가 응답 동작의 수행이 불가능한 것으로 결정한 사용 자 음성 \"xx 중국집으로 전화 연결 해줘\"와 같은 사용자 음성이 재 수신되는 경우, 학습 동작을 종료하고, \"학 습 되었습니다.\" 및 \"명령어는 어떻게 지정할까요?\"와 같은 학습 종료 안내 메시지를 출력할 수 있다. 그러나, 도 7의 박스를 참조하면, 전자 장치는 \"학습 종료\"(미도시)와 같이 학습 동작의 종료를 나 타내는 미리 설정된 음성 입력이 수신되는 경우 학습 동작을 종료하고, \"학습 되었습니다.\" 및 \"명령어는 어떻 게 지정할까요?\"와 같은 학습 종료 안내 메시지를 출력할 수도 있다. 또 다른 실시 예에 의하면, 전자 장치 는 전자 장치의 사용자 입력 인터페이스(미도시) 또는 전자 장치와 유선 또는 무선으로 연결되는 리모트 콘트롤(Remote Control)를 통하여 학습 동작의 종료를 나타내는 미리 설정된 종료 시퀀스가 사용자로부터 수신 되는 경우에도, 학습 동작을 종료하고 학습 종료 안내 메시지를 출력할 수도 있다. 도 8은 일 실시 예에 따른 전자 장치 및 서버가 보이스 어시스턴트 서비스를 제공하는 과정을 설명하기 위한 도 면이다. 도 8을 참조하면, 전자 장치는 서버와 서로 연동함으로써 보이스 어시스턴트 서비스를 제공할 수도 있다. S810에서, 서버는 사용자의 음성에 관련된 응답 동작을 수행하기 위한 보이스 어시스턴트 서비스 모델을 미리 생성하고, 생성된 보이스 어시스턴트 서비스 모델을 메모리 또는 데이터 베이스에 저장할 수 있다. S812에 서, 전자 장치는 사용자의 음성을 획득할 수 있다. S812는 도 2의 S210에 대응될 수 있으므로 구체적인 설명은 생략하기로 한다. S813에서, 전자 장치는 획득된 사용자의 음성을 서버로 전송한다. 전자 장치는 유선 또는 무선 네트워크를 이용하여 획득된 사용자 음성이 변환된 텍스트에 대한 정보를 서버로 전송할 수도 있다. S814에서, 서버는 ASR 모델을 통해 사용자 음성이 변환된 텍스트에 대한 신뢰도 값을 결정할 수 있다. S816에서, 서버는 NLU 모델을 통해 사용자 음성이 변환된 텍스트로부터 의도 정보에 대한 확률 값 및 슬 롯 정보에 대한 확률 값을 결정할 수 있다. S818에서, 서버는 전자 장치로부터 현재 전자 장치의 동작 상 태에 대한 정보를 수신할 수 있다. 현재 전자 장치의 동작 상태는 전자 장치가 현재 디스플레이에 표시하 고 있는 화면, 현재 전자 장치가 실행하고 있는 애플리케이션의 종류, 실행 중인 애플리케이션이 포함하고 있는 기능, 실행 중인 애플리케이션의 업데이트 상태, 전자 장치에 입력된 일련의 사용자 입력에 기초하여 현 재 전자 장치가 수행하고 있는 전자 장치의 기능에 대한 정보를 포함할 수 있다. S820에서, 서버는 수신 된 사용자의 음성에 대한 응답 동작을 수행할 수 있는지 여부를 결정할 수 있다. 일 실시 예에 의하면 서버 는 ASR 모델을 통해 획득된 사용자 음성이 변환된 텍스트에 대한 신뢰도 값이 기 설정된 임계치 보다 작 은 경우 사용자 음성에 대한 응답 동작의 수행이 불가능한 것으로 결정할 수 있다. 또한, 서버는 사용자 음성이 변환된 텍스트의 의도 정보에 대한 확률 값이 기 설정된 임계치 보다 작은 경우, 사용자 음성에 대한 응 답 동작의 수행이 불가능한 것으로 결정할 수도 있다. 또한, 서버는 사용자 음성이 변환된 텍스트의 슬롯 정보에 대한 확률 값이 기 설정된 임계치 보다 작은 경우, 사용자 음성에 대한 응답 동작의 수행이 불가능한 것으로 결정할 수도 있다. 또 다른 실시 예에 의하면, 서버는 사용자 음성이 변환된 텍스트의 의도 정보에 대한 확률 값 및 슬롯 정 보에 대한 확률 값이 기 설정된 임계치 보다 큰 경우에도, 의도 정보 및 슬롯 정보에 대응되는 컴퓨터 판독 가 능한 명령이 현재 전자 장치의 동작 상태에 기초하여 전자 장치가 수행 가능한 응답 동작에 관한 명령이 아닌 경우, 사용자 음성에 대한 응답 동작의 수행이 불가능한 것으로 결정할 수도 있다. 전술한 실시 예에서, 서버는 ASR 모델 및 NLU 모델을 이용하여 전자장치로부터 수신된 사용자 음성을 텍 스트로 변환하고, 변환된 텍스트로부터 의도 정보 및 슬롯 정보에 대한 확률 값을 결정하지만, ASR 모델을 통한 사용자 음성의 변환 과정 및 NLU 모델을 이용하여 사용자 음성이 변환된 텍스트로부터 의도 정보 및 슬롯 정보 에 대한 확률 값을 결정하는 과정은 전자 자치에서 수행될 수도 있다. S820은 도 2의 전자 장치가 수행하는 S230에 대응될 수 있다. S822에서, 서버는 사용자 음성에 대한 응답 동작의 수행이 가능한 것으로 결정한 경우, 사용자 음성에 대 한 응답 동작에 관한 정보를 전자 장치로 전송할 수 있다. 전자 장치는 서버로부터 수신한 사용자의 응답 동작에 관한 정보를 이용하여 사용자의 음성에 대한 응답 동작을 수행할 수 있다. S824에서, 서버는 사용자 음성에 대한 응답 동작의 수행이 불가능한 것으로 결정됨에 따라, 사용자 음성 에 대한 응답 동작을 수행할 수 없다는 결정과 관련된 정보를 전자 장치로 전송할 수 있다. S826에서, 전자 장 치는 사용자의 음성에 관련된 응답 동작을 학습하기 위한 \"학습 시작 할게요. 동작을 알려주세요\"와 같은 학습 시작 안내 메시지를 출력함과 함께 학습 모드로 전환됨으로써 사용자 입력 시퀀스를 수신하기 위해 필요한 소정 의 SW 모듈등을 활성화 할 수 있다. 일 실시 예에 의하면, 전자 장치는 학습 시작 안내 메시지를 출력하 기 전, \"죄송합니다. 제공하지 않는 서비스 입니다.\"와 같은 에러 메시지를 먼저 출력할 수도 있다. S828에서,전자 장치는 학습 시작 안내 메시지 출력 후, 사용자로부터 보이스 어시스턴트 서비스를 이용하여 수행할 수 있는 전자 장치의 적어도 하나의 기능에 관한 사용자 음성들을 일련의 입력 시퀀스들로써 획득할 수 있다. S830에서, 전자 장치는 사용자로부터 획득된 일련의 입력 시퀀스들을 서버로 전송할 수 있다. 일 실시 예에 의하면, 전자 장치는 학습 시작 안내 메시지 출력 후, 획득된 일련의 사용자 입력 시퀀스들을 전자 장치의 기능 단위로 구분하고, 전자 장치의 기능 단위로 구분된 입력 시퀀스들 및 상기 입력 시퀀스들의 입력 순서를 서버로 더 전송할 수도 있다. 서버가 획득된 사용자 입력 시퀀스들, 사용자 입력 시퀀 스들이 입력된 입력 순서 또는 사용자 입력 시퀀스 및 일련의 안내 메시지들과의 순서 중 적어도 하나에 기초하 여 보이스 어시스턴트 서비스를 학습하는 과정은 도 2 내지 도 3에 기재된 전자 장치가 보이스 어시스턴트 서비 스 모델을 학습하는 과정에 대응될 수 있으므로 구체적인 설명은 생략하기로 한다. 도 9는 일 실시 예에 따른 보이스 어시스턴트 서비스를 제공하는 전자 장치의 블록도이다. 일 실시 예에 의하면, 전자 장치는 VPA 모듈, 입출력부, 렌더링 모듈, 추론 모듈 및 학습 모듈을 포함할 수 있다. 그러나, 도시된 구성 요소가 모두 필수구성요소인 것은 아니고, 도시된 구성 요소보다 많은 구성 요소에 의해 전자 장치가 구현될 수도 있고, 그보다 적은 구성 요소에 의해서도 전자 장치는 구현될 수도 있다. 예를 들어, 전자 장치는 입, 출력부, 렌더링 모듈, 추론 모듈 및 학습 모듈을 포함할 수도 있다. 일 실시 예에 의하면 VPA 모듈은 개인 가상 비서(Virtual Personal Assistant, VPA) 모델을 이용하여 사 용자 입력 시퀀스에 관한 유사 시퀀스들을 생성할 수 있다. 일 실시 예에 의하면, 개인 가상 비서(Virtual Personal Assistant, VPA) 모델은 사용자로부터 입력된 일련의 사용자 입력 시퀀스를, 사용자 입력 시퀀스를 입 력으로 하고, 입력된 사용자 입력 시퀀스에 관한 유사 시퀀스들을 출력으로 하는 언어 모델(Language Model)에 입력함으로써 유사 시퀀스들을 생성할 수 있다. 일 실시 예에 의하면, VPA 모듈은 개인 가상 비서 모델을 이용하여, 사용자로부터 학습 동작의 시작 또는 학습 동작의 종료에 관한 사용자의 음성, 응답 동작을 학습하기 위한 사용자의 음성, 전자 장치와 유선 또는 무선으 로 연결되는 리모트 콘트롤을 통한 사용자의 기타 입력 등을 수신하도록 입출력부를 제어할 수 있다. 또한, VPA 모듈은 사용자 음성에 대한 응답 동작에 관한 시각적 또는 청각적 정보를 학습 모듈로부터 수신하고, 응답 동작에 관한 시각적 또는 청각적 정보들을 사용자에게 출력하도록 입출력부를 제어할 수 있다. 일 실시 예에 의하면, VPA 모듈이 수행하는 적어도 하나의 기능들은 학습 모듈, 렌더링 모듈, 또는 추론 모듈 중 적어도 하나에 의해 분산되어 수행될 수도 있다. 예를 들어, 전자 장치가 VPA 모 듈을 포함하지 않는 경우, 사용자로부터 수신된 사용자 입력 시퀀스와 유사한 유사 시퀀스를 생성하는 기능은 학습 모듈의 유사 시퀀스 생성 모델에 의해 수행될 수 있다. 본 개시에 따른 VPA 모듈이 이용하는 개인 가 상 비서 모델은 전자 장치의 사용자가 요구하는 작업을 처리하고, 사용자에게 보이스 어시스턴트 서비스를 제공 하기 위해 프로세서에 의해 수행될 수 있는 모든 유형의 소프트웨어 에이전트를 포함할 수 있다. 입출력부는 VPA 모듈, 렌더링 모듈의 제어에 의해 사용자의 음성 입력, 키 입력, 터치 입력 또 는 모션 입력 중 적어도 하나를 포함하는 사용자 입력 시퀀스를 획득할 수 있고, 획득된 사용자 입력 시퀀스에 대한 응답 동작을 출력할 수 있다. 렌더링 모듈은 가상의 전자 장치 화면을 생성하고, 생성된 가상의 전자 장치 화면 또는 전자 장치의 가상의 사용자 입력 인터페이스를 통하여 입력되는 사용자 입력을 기록함으로써 현 재 전자 장치의 동작 상태를 결정할 수 있다. 일 실시 예에 의하면, 렌더링 모듈은 현재 전자 장치의 디스플레이 상에 표시되는 화면, 전자 장치에서 실 행 중인 애플리케이션의 종류, 실행 중인 애플리케이션에서 선택 가능한 서비스의 종류, 실행 중인 애플리케이 션이 포함하고 있는 기능, 실행 중인 애플리케이션의 업데이트 상태, 현재 실행 중인 애플리케이션에 대한 사용 자 입력 기록, 현재 전자 장치의 적어도 하나의 기능을 조작하기 위해, 사용자 입력 인터페이스를 통하여 입력 된 사용자 입력의 기록 중 적어도 하나에 기초하여 현재 전자 장치의 동작 상태를 결정할 수 있다. 일 실시 예에 의하면, 렌더링 모듈은 현재 전자 장치의 동작 상태 또는 동작 상태를 결정하기 위해 사용한, 현재 전자 장치의 디스플레이 상에 표시되는 화면, 전자 장치에서 실행 중인 애플리케이션의 종류, 실 행 중인 애플리케이션이 포함하고 있는 기능, 실행 중인 애플리케이션의 업데이트 상태, 현재 실행 중인 애플리 케이션에 대한 사용자 입력 기록, 현재 전자 장치의 적어도 하나의 기능을 조작하기 위해, 사용자 입력 인터페 이스를 통하여 입력된 사용자 입력의 기록에 관한 정보를 추론 모듈 및 학습 모듈로 전송할 수 있다. 일 실시 예에 의하면, 추론 모듈은 적어도 하나의 추론 모델을 사용하여 사용자로부터 수신된 일련의 사용 자 입력 시퀀스를 사용자 입력을 기준으로 분할한다. 추론 모듈은 추론 모델을 이용하여 분할된 입력 시퀀 스를 복수의 입력 그룹으로 그룹핑하고, 복수의 입력 그룹 및 입력 그룹 별 사용자의 의도 정보를 식별할 수 있 다. 일 실시 예에 의하면, 추론 모델은 베이지안 네트워크(Bausian Network) 모델을 이용하여 분할된 사용자 입력 시퀀스의 입력 그룹 별 사용자 의도를 식별할 수도 있으나, 이에 한정되는 것은 아니며, 기타 1차 논리(First Order Logic, FOL) 모델을 이용하여 입력 그룹 별 사용자 의도를 식별할 수도 있다. 추론 모듈 은 입력 그 룹 및 입력 그룹 별로 식별된 사용자의 의도 정보를 학습 모듈로 전송함으로써, 학습 모듈이 입력 그 룹 및 입력 그룹 별 사용자 의도(intent) 정보에 기초하여, 보이스 어시스턴트 서비스 모델을 학습하도록 할 수 있다. 추론 모듈이 이용하는 추론 모델의 구체적인 학습 방법은 도 4에 기재된 특징에 대응되므로 구체적 인 설명은 생략하기로 한다. 학습 모듈은 보이스 어시스턴트 서비스를 제공하기 위한 서비스 모델을 이용 하여, 사용자의 음성에 대한 음성 해석 정보를 획득하거나, 획득된 음성 해석 정보에 기초하여 사용자의 음성에 대한 응답 동작을 수행할 수 있다. 일 실시 예에 의하면, 보이스 어시스턴트 서비스 모델은 자동 음성 인식 모델(Automatic Speech Recognition, ASR) 모델, 자연어 이해(Natural Language Understanding, NLU) 모델, 대화 관리 (Dialog Management)모델, 또는 액션 플랜(Action Plan, AP)모델, 자연어 생성 모델(Natural Language Generator, NLG), 텍스트 음성 변환(Text to Speech, TTS) 모델을 포함할 수 있다. 학습 모듈이 이용하는 보이스 어시스턴 트 서비스 모델의 학습 방법, 보이스 어시스턴트 서비스 모델 내의 ASR 모델, NLU 모델, DM 모델, AP 모델, TTS 모델의 구체적인 학습 방법은 도 1 내지 도 4에 기재된 바에 대응되므로 구체적인 설명은 생략하기로 한다. 도 10은 일 실시 예에 따른 보이스 어시스턴트 서비스를 제공하는 전자 장치의 블록도이다. 도 11은 일 실시 예에 따른 보이스 어시스턴트 서비스를 제공하는 전자 장치의 블록도이다. 도 10에 도시된 바와 같이, 보이스 어시스턴트 서비스를 제공하는 전자 장치는 프로세서 및 메모리 를 포함할 수 있다. 그러나, 도시된 구성 요소가 모두 필수구성요소인 것은 아니고, 도시된 구성 요소보 다 많은 구성 요소에 의해 전자 장치가 구현될 수도 있고, 그보다 적은 구성 요소에 의해서도 전자 장치 는 구현될 수도 있다. 예를 들어, 도 11에 도시된 바와 같이, 일 실시 예에 따른 전자 장치는 사용자 입력 인터페이스, 출력부, 프로세서, 및 통신부 이외에 센싱부, A/V 입력부, 및 메모리를 더 포함할 수도 있다. 사용자 입력 인터페이스는, 사용자가 전자 장치를 제어하기 위한 시퀀스를 입력하는 수단을 의미한 다. 예를 들어, 사용자 입력 인터페이스에는 키 패드(key pad), 돔 스위치 (dome switch), 터치 패드(접 촉식 정전 용량 방식, 압력식 저항막 방식, 적외선 감지 방식, 표면 초음파 전도 방식, 적분식 장력 측정 방식, 피에조 효과 방식 등), 조그 휠, 조그 스위치 등이 있을 수 있으나 이에 한정되는 것은 아니다. 사용자 입력 인터페이스는, 전자 장치가 디스플레이 상에 출력한 안내 메시지에 따라, 입력되는 입 력 시퀀스를 사용자로부터 수신할 수 있다. 또한, 사용자 입력 인터페이스는 도 1 내지 도 8에 도시된 사 용자의 음성을 획득하거나, 사용자로부터 키 입력, 터치 입력 또는 모션 입력 중 적어도 하나를 수신할 수 있다. 출력부는, 오디오 신호 또는 비디오 신호 또는 진동 신호를 출력할 수 있으며, 출력부는 디스플레 이부, 음향 출력부, 및 진동 모터를 포함할 수 있다. 디스플레이부는 전자 장치에서 처리되는 정보를 표시 출력하기 위한 화면을 포함한다. 또한, 화면 은 안내 메시지, 에러 메시지 등 사용자의 음성에 대한 응답 동작을 문자 이미지, 또는 영상 이미지로 디스플레 이할 수 있다. 음향 출력부는 통신부로부터 수신되거나 메모리에 저장된 오디오 데이터를 출력한다. 또한, 음향 출력부는 전자 장치에서 수행되는 기능(예를 들어, 도 6에서 도시된 에러 메시지, 학습 시작 안내 메시지, 학습 종료 안내 메시지, 명령어 지정 요청 메시지와 관련된 오디오 신호를 출력한다. 진동 모터는 진동 신호를 출력할 수 있다. 예를 들어, 진동 모터는 전자 장치에서 수행되는 기능들(예를 들어, 도 6에서 도시된 에러 메시지, 학습 시작 안내 메시지, 학습 종료 안내 메시지, 명령어 지정요청 메시지의 출력과 함께진동 신호를 출력할 수 있다. 프로세서는, 통상적으로 전자 장치의 전반적인 동작을 제어한다. 예를 들어, 프로세서는, 메 모리에 저장된 프로그램들을 실행함으로써, 사용자 입력부, 출력부, 센싱부, 통신부 , A/V 입력부 등을 전반적으로 제어할 수 있다. 또한, 프로세서는 메모리에 저장된 프 로그램들을 실행함으로써, 도 1 내지 도 10에 기재된 전자 장치의 기능을 수행할 수 있다. 또한, 프로세 서는 하나 또는 복수의 프로세서로 구성될 수 있고, 하나 또는 복수의 프로세서는 CPU, AP, DSP(Digital Signal Processor) 등과 같은 범용 프로세서, GPU, VPU(Vision Processing Unit)와 같은 그래픽 전용 프로세서 또는 NPU와 같은 인공지능(AI) 전용 프로세서일 수 있다. 일 실시 예에 의하면, 프로세서가 범용 프로세서, 인공지능 프로세서 및 그래픽 전용 프로세서를 포함하 는 경우, 인공지능 프로세서는 범용 프로세서 또는 그래픽 전용 프로세서와 별도의 칩으로 구현될 수도 있다. 예를 들어, 하나 또는 복수의 프로세서는, 메모리에 저장된 기 정의된 동작 규칙 또는 인공지능 모델에 따라, 입력 데이터를 처리하도록 제어할 수 있다. 또는, 하나 또는 복수의 프로세서가 인공지능 전용 프로세서인 경우, 인공지능 전용 프로세서는, 특정 인공지능 모델의 처리에 특화된 하드웨어 구조로 설계될 수 있다. 일 실시 예에 의하면, 프로세서가 복수의 프로세서 또는 그래픽 전용 프로세서 또는 NPU와 같은 인공 지 능 전용 프로세서로 구현될 때, 복수의 프로세서 또는 그래픽 전용 프로세서 또는 NPU와 같은 인공 지능 전용 프로세서 중 적어도 일부는 전자 장치 및 전자 장치와 연결된 다른 전자 장치 또는 서버에 탑재될 수도 있다. 프로세서는 사용자 입력부를 제어함으로써 사용자의 음성을 획득할 수 있다. 일 실시 예에 의 하면, 프로세서는 사용자의 음성을 획득하도록 마이크로폰을 제어할 수 있다. 프로세서는 사용자 입력에 기초하여 전자 장치의 동작을 수행하는 애플리케이션을 실행할 수 있으며, 실행된 애플리케이션을 통하 여 사용자 음성을 획득할 수 있다. 예를 들면, 프로세서는, 보이스 어시스턴트 애플리케이션 (Voice Assistant Application)을 실행하고, 실행된 애플리케이션에 의해 제공되는 보이스 어시스턴트 서비스를 이용하 여 마이크로폰을 제어함으로써 사용자의 음성 입력을 수신하도록 할 수 있다. 일 실시 예에 의하면, 프로세서는 사용자의 음성을 ASR 모델에 입력함으로써 사용자 음성이 변환된 텍스 트를 획득하고, 텍스트를 NLU 모델이 입력함으로써 사용자의 의도에 관한 의도 정보 및 슬롯 정보를 획득할 수 있다. 프로세서는 획득된 의도 정보, 슬롯 정보 및 상기 의도 정보 또는 슬롯 정보에 대한 확률 값에 기 초하여, 상기 사용자의 음성에 대한 응답 동작을 수행할 수 있는지 여부를 결정할 수 있다. 예를 들어, 프로세서는 NLU 모델을 통해 획득된 의도 정보에 대한 확률 값이 기 설정된 임계치 보다 작은 경우, 사용자 음성에 대한 응답 동작을 수행할 수 없는 것으로 결정할 수 있다. 또한, 프로세서는 NLU 모 델을 통해 획득된 슬롯 정보에 대한 확률 값이 기 설정된 임계치 보다 작은 경우, 사용자 음성에 대한 응답 동 작을 수행할 수 없는 것으로 결정할 수 있다. 또 다른 실시 예에 의하면, 프로세서는 사용자 음성이 변환된 텍스트 정보의 의도 정보에 대한 확률 값 및 슬롯 정보에 대한 확률 값이 기 설정된 임계치 이상인 경우에도, 사용자 음성의 의도(intent) 정보 및 슬롯 (slot) 정보에 대응되는 컴퓨터 판독 가능한 명령이, 현재 전자 장치의 동작 상태에서 수행 가능한 응답 동작에 관한 명령이 아닌 경우, 사용자 음성에 대한 응답 동작을 수행할 수 없는 것으로 결정할 수 있다. 프로세서 는 사용자 음성에 대한 응답 동작을 수행할 수 없는 것으로 결정됨에 따라, 상기 사용자의 음성에 관련된 응답 동작을 학습하기 위한 일련의 안내 메시지를 출력할 수 있다. 하지만, 프로세서는 사용자의 음성의 의도 정보 및 슬롯 정보에 대응되는 컴퓨터 판독 가능한 명령 (instruction)이, 현재 전자 장치의 동작 상태에서, 보이스 어시스턴트 서비스 제공자가 수행 가능한 것으로 미 리 설정한 응답 동작에 관한 명령인 경우, 사용자 음성에 대한 응답 동작을 수행할 수 있는 것으로 결정할 수 있다. 의도 정보 및 슬롯 정보에 대응되는 컴퓨터 판독 가능한 명령이 현재 전자 장치의 동작 상태에서 수행 가 능한 응답 동작에 관한 명령인지 여부는 보이스 어시스턴트 서비스 제공자에 의해 미리 설정될 수 있다. 일 실시 예에 의하면, 전자 장치의 동작 상태는 전자 장치가 현재 디스플레이에 표시하고 있는 화면, 현 재 전자 장치가 실행하고 있는 애플리케이션의 종류, 실행 중인 애플리케이션이 포함하고 있는 기능, 실행 중인 애플리케이션의 업데이트 상태, 전자 장치에 입력된 일련의 사용자 입력에 기초하여 현재 전자 장치가 수 행하고 있는 전자 장치의 기능 중 적어도 하나에 따라 달라질 수 있다. 또한, 프로세서는 출력된 일련의 안내 메시지에 따라 상기 사용자로부터 입력되는 입력 시퀀스를 수신할 수 있다. 또한 프로세서는 입력 시퀀스를 이용하여 상기 응답 동작을 학습하기 위한 보이스 어시스턴트서비스 모델을 학습시킬 수 있다. 전자 장치가 사용자 음성에 대한 응답 동작을 제공하기 위해 이용하는 보이스 어시스턴트 서비스 모델은 자동 음성 인식(ASR) 모델, 자연어 이해 모델(Natural Language Understanding, NLU), 대화 관리(Dialog Management, DM) 모델, 액션 플랜(Action Planning, AP) 모델, 자연어 생성 모델 (Natural Language Generator, NLG), 텍스트 음성 변환(Text to Speech, TTS) 모델 을 포함할 수 있다. 프로세 서는 사용자로부터 입력된 음성 입력, 키 입력, 터치 입력, 또는 모션 입력 중 적어도 하나를 포함하는 입력 시퀀스를 수신하고, 수신된 입력 시퀀스를 이용하여 자동 음성 인식(ASR) 모델, 자연어 이해 모델(Natural Language Understanding, NLU), 대화 관리(Dialog Management, DM) 모델, 액션 플랜(Action Planning, AP) 모 델, 자연어 생성 모델(Natural Language Generator, NLG), 텍스트 음성 변환(Text to Speech, TTS) 모델을 학 습시킬 수 있다. 일 실시 예에 의하면, 프로세서는 입력 시퀀스를 추론 모델에 입력함으로써, 분할된 입력 시퀀스를 복수 의 입력 그룹으로 분할한다. 프로세서는 분할된 입력 시퀀스의 입력 그룹 및 입력 그룹 별 사용자의 의도 정보에 기초하여, 보이스 어시스턴트 서비스 모델은 자동 음성 인식(ASR) 모델, 자연어 이해 모델(Natural Language Understanding, NLU), 대화 관리(Dialog Management, DM) 모델, 액션 플랜(Action Planning, AP) 모 델, 자연어 생성 모델(Natural Language Generator, NLG), 텍스트 음성 변환(Text to Speech, TTS) 모델을 학 습시킬 수 있다. 프로세서는 상기 입력 시퀀스를 언어 모델에 입력함으로써 상기 입력 시퀀스와 관련된 유사 시퀀스를 생 성하고, 상기 생성된 유사 시퀀스의 입력 그룹 및 입력 그룹 별 사용자의 의도 정보와 사용자 입력 시퀀스의 입력 그룹 및 상기 입력 그룹 별로 식별된 사용자의 의도정보에 기초하여 상기 보이스 어시스턴트 서비스 모델 을 학습시킬 수 있다. 전자 장치가 입력 그룹 및 입력 그룹 별 사용자의 의도에 기초하여 자동 음성 인식 (ASR) 모델, 자연어 이해 모델(Natural Language Understanding, NLU), 대화 관리(Dialog Management, DM) 모 델, 액션 플랜(Action Planning, AP) 모델, 자연어 생성 모델(Natural Language Generator, NLG), 텍스트 음성 변환(Text to Speech, TTS) 모델을 학습시키는 방법은 도 4의 기재된 S450에 대응될 수 있으므로 구체적인 설명 은 생략하기로 한다. 또한, 프로세서는 서버와 연동함으로써 사용자 음성에 대한 응답 동작을 수행하기 위하여, 획득된 사용자의 음성을 서버로 전송할 수 있고, 출력된 안내 메시지에 대해 사용자로부터 수신된 입력 시퀀스를 서버 로 전송할 수 있으며, 서버로부터 사용자의 음성에 대한 응답 동작에 관한 정보를 수신하도록 통신부를 제어할 수도 있다. 전술한 바와 같이, 프로세서는 보이스 어시스턴트 서비스를 제공하기 위한 인공지능(AI)프로세서 또는 그 래픽 전용 프로세서 또는 범용 프로세서 중 적어도 하나를 사용하여, 보이스 어시스턴트 서비스를 제공할 수 있 다. 일 실시 예에 의하면, 전자 장치는 범용 프로세서를 이용하여, 사용자의 음성을 획득하는 동작, 사용자의 음성에 대한 응답 동작으로써 생성된 일련의 안내 메시지들을 디스플레이에 표시하는 동작 또는 출력된 일련의 안내 메시지들에 대한 사용자 음성 또는 사용자 입력 인터페이스 등을 통하여 수신되는 사용자 입력을 수신하는 동작과 같은, 전자 장치의 일반적인 동작들을 수행하고, 인공지능 프로세서를 이용하여, 사용자 음성에 대한 응 답 동작의 수행이 가능한지 여부를 결정하는 동작, 현재 전자 장치의 동작 상태를 결정하는 동작, 사용자로부터 수신된 사용자 입력 시퀀스에 기초하여 보이스 어시스턴트 서비스 모델을 학습하는 동작 등을 수행할 수 있으나, 이에 한정되는 것은 아니다. 즉, 전자 장치는 효율적으로 사용자 인터페이스를 제공하는 방법을 수행함에 있어, 필요한 프로세싱 자원 들을 결정하고, 결정된 프로세싱 자원들에 기초하여, 범용 프로세서, 그래픽 전용 프로세서 또는 인공지능 프로 세서 중 적어도 하나를 사용할 수 있다. 일 실시 예에 의하면, 전자 장치가 동작하기 위한 기 정의된 동작 규칙 또는 인공지능 모델은 학습을 통 해 만들어진 것을 특징으로 한다. 여기서, 학습을 통해 만들어진다는 것은, 기본 인공지능 모델이 학습 알고리 즘에 의하여 다수의 학습 데이터들을 이용하여 학습됨으로써, 원하는 특성(또는, 목적)을 수행하도록 설정된 기 정의된 동작 규칙 또는 인공지능 모델이 만들어짐을 의미한다. 이러한 학습은 본 개시에 따른 인공지능이 수행 되는 기기 자체에서 이루어질 수도 있고, 별도의 서버 및/또는 시스템을 통해 이루어 질 수도 있다. 학습 알고 리즘의 예로는, 지도형 학습(supervised learning), 비지도형 학습(unsupervised learning), 준지도형 학습 (semi-supervised learning) 또는 강화 학습(reinforcement learning)이 있으나, 전술한 예에 한정되지 않는다.일 실시 예에 의하면, 프로세서는 인공지능 모델 학습을 위해 입력된 일련의 사용자 입력 시퀀스들, 사용 자 입력 시퀀스들의 순서와 같은 데이터들을 전처리할 수 있다. 예를 들어, 프로세서는 획득된 데이터들을 미리 설정된 포맷으로 가공할 수 있다. 일 실시 예에 의하면, 프로세서는 인공지능 모델 학습을 위한 학습 데이터들 을 기 설정된 기준(예컨대, 학습 데이터가 생성된 지역, 학습 데이터가 생성된 시간, 학습 데이터의 크기, 학습 데이터의 장르, 학습 데이터의 생성자, 학습 데이터 내의 오브젝트의 종류 등)에 따라 선택할 수 있고, 인공지 능 모델 학습을 위한 학습 데이터들을 선택하기 위한 기준을 선택하는 방법 역시 학습할 수도 있다. 예를 들어, 전자 장치가 이용하는 인공지능 모델은, 복수의 신경망 레이어들로 구성될 수 있다. 복수의 신경망 레이어들 각각은 복수의 가중치들(weight values)을 갖고 있으며, 이전(previous) 레이어의 연산 결과와 복수의 가중치들 간의 연산을 통해 신경망 연산을 수행한다. 복수의 신경망 레이어들이 갖고 있는 복수의 가중 치들은 인공지능 모델의 학습 결과에 의해 최적화될 수 있다. 예를 들어, 학습 과정 동안 인공지능 모델에서 획 득한 로스(loss) 값 또는 코스트(cost) 값이 감소 또는 최소화되도록 복수의 가중치들이 갱신될 수 있다. 인공 신경망은 심층 신경망(DNN:Deep Neural Network)를 포함할 수 있으며, 예를 들어, CNN (Convolutional Neural Network), DNN (Deep Neural Network), RNN (Recurrent Neural Network), RBM (Restricted Boltzmann Machine), DBN (Deep Belief Network), BRDNN(Bidirectional Recurrent Deep Neural Network) 또는 심층 Q-네 트워크 (Deep Q-Networks) 등이 있으나, 전술한 예에 한정되지 않는다. 센싱부는, 전자 장치의 상태 또는 전자 장치 주변의 상태를 감지하고, 감지된 정보를 프로세 서로 전달할 수 있다. 센싱부는 전자 장치의 사양 정보, 전자 장치의 상태 정보, 전자 장치의 주변 환경 정보, 사용자의 상태 정보, 사용자의 모션 입력 및 사용자의 디바이스 사용 이력 정보 중 일부를 생성하는데 이용될 수 있다. 센싱부는, 지자기 센서(Magnetic sensor), 가속도 센서(Acceleration sensor), 온/습도 센 서, 적외선 센서, 자이로스코프 센서, 위치 센서(예컨대, GPS), 기압 센서, 근 접 센서, 및 RGB 센서(illuminance sensor) 중 적어도 하나를 포함할 수 있으나, 이에 한정되는 것은 아니다. 각 센서들의 기능은 그 명칭으로부터 당업자가 직관적으로 추론할 수 있으므로, 구체적인 설명은 생략하기로 한다. 통신부는, 전자 장치가 다른 장치(미도시) 및 서버와 통신을 하게 하는 하나 이상의 구성요 소를 포함할 수 있다. 다른 장치(미도시)는 전자 장치와 같은 컴퓨팅 장치이거나, 센싱 장치일 수 있으나, 이에 제한되지 않는다. 예를 들어, 통신부는, 근거리 통신부, 이동 통신부, 방송 수 신부를 포함할 수 있다. 근거리 통신부(short-range wireless communication unit)는, 블루투스 통신부, BLE(Bluetooth Low Energy) 통신부, 근거리 무선 통신부(Near Field Communication unit), WLAN(와이파이) 통신부, 지그비 (Zigbee) 통신부, 적외선(IrDA, infrared Data Association) 통신부, WFD(Wi-Fi Direct) 통신부, UWB(ultra wideband) 통신부, Ant+ 통신부 등을 포함할 수 있으나, 이에 한정되는 것은 아니다. 이동 통신부는, 이동 통신망 상에서 기지국, 외부의 단말, 서버 중 적어도 하나와 무선 신호를 송수신한 다. 여기에서, 무선 신호는, 음성 신호, 화상 통화 호 신호 또는 문자/멀티미디어 메시지 송수신에 따른 다양한 형태의 데이터를 포함할 수 있다. 방송 수신부는, 방송 채널을 통하여 외부로부터 방송 신호 및/또는 방송 관련된 정보를 수신한다. 방송 채널은 위성 채널, 지상파 채널을 포함할 수 있다. 구현 예에 따라서 전자 장치가 방송 수신부를 포함하지 않을 수도 있다. 일 실시 예에 의하면, 통신부는 프로세서의 제어에 의하여, 서버로 사용자의 음성, 음성 해석 정보, 입력 시퀀스를 전송할 수 있고, 서버로부터 응답 동작을 수행하지 않는다는 결정과 관련된 정보 또는 응답 동작을 수 행하기로 결정한 경우, 응답 동작에 관한 정보를 수신할 수 있다. A/V(Audio/Video) 입력부는 오디오 신호 또는 비디오 신호 입력을 위한 것으로, 이에는 카메라와 마이크로폰 등이 포함될 수 있다. 카메라는 화상 통화모드 또는 촬영 모드에서 이미지 센서를 통해 정지영상 또는 동영상 등의 화상 프레임을 얻을 수 있다. 이미지 센서를 통해 캡쳐된 이미지는 프로세서 또는 별도의 이미지 처리부(미도시)를 통해 처리될 수 있다. 카메라에 의해 촬영된 이미지는 사용자의 컨 텍스트 정보로 활용될 수 있다.마이크로폰은, 외부의 음향 신호를 입력 받아 전기적인 음성 데이터로 처리한다. 예를 들어, 마이크로폰 은 외부 디바이스 또는 사용자로부터 음향 신호를 수신할 수 있다. 마이크로폰은 사용자의 음성 입 력을 수신할 수 있다. 마이크로폰은 외부의 음향 신호를 입력 받는 과정에서 발생 되는 잡음(noise)을 제 거하기 위한 다양한 잡음 제거 알고리즘을 이용할 수 있다. 메모리는, 프로세서의 처리 및 제어를 위한 프로그램을 저장할 수 있고, 전자 장치로 입력되 거나 전자 장치로부터 출력되는 데이터를 저장할 수도 있다. 또한, 메모리는 보이스 어시스턴트 서비스를 제공하기 위한 인공 지능 모델을 저장할 수 있다. 일 실시 예에 의하면, 메모리에 저장된 인공지능 모델은 자동 음성 인식(ASR) 모델, 자연어 이해 모델(Natural Language Understanding, NLU), 대화 관리(Dialog Management, DM) 모델, 액션 플랜(Action Planning, AP) 모 델, 자연어 생성 모델(Natural Language Generator, NLG), 텍스트 음성 변환(Text to Speech, TTS) 모델을 포 함하는 보이스 어시스턴트 서비스 모델을 포함할 수 있다. 또한, 보이스 어시스턴트 서비스 모델 외에, 가상 개 인 비서 모델, 추론 모델 또는 현재 전자 장치의 동작 상태를 관리하기 위한 렌더링 모델을 포함할 수 있다. 또 한, 메모리는 텍스트 음성 변환(Text to Speech, TTS) 모델 학습을 위한 TTS 데이터 베이스, 자동 음성 인식 (ASR) 모델 학습을 위한 ASR 데이터 베이스를 저장할 수도 있다. 또한, 메모리는 신경망, 신경망의 구조를 특정하기 위한 레이어들 및 레이어들 간의 가중치에 관한 정보 를 더 저장할 수 있다. 예를 들면, 메모리는 학습된 신경망뿐만 아니라, 획득된 입력 시퀀스에 기초하여 이미 생성된 신경망에 기초한 모델들이 수정되는 경우, 수정된 모델들의 레이어들, 레이어들 간의 가중치에 관 한 정보를 더 저장할 수 있다. 메모리는 플래시 메모리 타입(flash memory type), 하드디스크 타입(hard disk type), 멀티미디어 카드 마이크로 타입(multimedia card micro type), 카드 타입의 메모리(예를 들어 SD 또는 XD 메모리 등), 램(RAM, Random Access Memory) SRAM(Static Random Access Memory), 롬(ROM, Read-Only Memory), EEPROM(Electrically Erasable Programmable Read-Only Memory), PROM(Programmable Read-Only Memory), 자기 메모리, 자기 디스크, 광디스크 중 적어도 하나의 타입의 저장매체를 포함할 수 있다. 메모리에 저장된 프로그램들은 그 기능에 따라 복수 개의 모듈들로 분류할 수 있는데, 예를 들어, UI 모 듈, 터치 스크린 모듈, 알림 모듈 등으로 분류될 수 있다. UI 모듈은, 애플리케이션 별로 전자 장치와 연동되는 특화된 UI, GUI 등을 제공할 수 있다. 터치 스크린 모듈은 사용자의 터치 스크린 상의 터치 제스처를 감지하고, 터치 제스처에 관한 정보를 프로세서 로 전달할 수 있다. 일부 실시예에 따른 터치 스크린 모듈은 터치 코드를 인식하고 분석할 수 있다. 터치 스크린 모듈은 컨트롤러를 포함하는 별도의 하드웨어로 구성될 수도 있다. 알림 모듈은 전자 장치의 이벤트 발생을 알리기 위한 신호를 발생할 수 있다. 전자 장치에서 발생되는 이벤트의 예로는 호 신호 수신, 메시지 수신, 키 신호 입력, 일정 알림 등이 있다. 알림 모듈은 디스플레이부를 통해 비디오 신호 형태로 알림 신호를 출력할 수도 있고, 음향 출력부를 통해 오디 오 신호 형태로 알림 신호를 출력할 수도 있고, 진동 모터를 통해 진동 신호 형태로 알림 신호를 출력할 수도 있다. 도 12는 일 실시 예에 따른 보이스 어시스턴트 서비스를 제공하는 서버의 블록도이다. 일 실시 예에 따르면, 서버는 통신부, 데이터 베이스(Data Base, 2200) 및 프로세서를 포함 할 수 있다. 통신부는 도 11에 도시된 전자 장치의 통신부에 대응될 수 있다. 예를 들어, 통신부는 전자 장치로부터 사용자의 음성, 사용자의 음성에 관련된 응답 동작을 학습하기 위한 사용자 입력 시퀀스 를 수신할 수 있다. 또한, 통신부는 수신된 사용자의 음성에 대한 응답 동작을 수행할 수 있는 것으로 결 정하는 경우, 사용자 음성에 대한 응답 동작에 관한 정보를 전자 장치로 전송할 수 있다. 또한, 통신부는 수신된 사용자의 음성에 대한 응답 동작을 수행할 수 없는 것으로 결정하는 경우, 응답 동작을 수행하지 않는다 는 결정과 관련된 정보를 전자 장치로 전송할 수 있다. 일 실시 예에 의하면 통신부는 전자 장치가 학습 시작 안내 메시지 출력 후 수신한, 보이스 어시스 턴트 서비스를 이용하여 수행할 수 있는 전자 장치의 적어도 하나의 기능에 관한 사용자 음성들을 더 수신할 수 도 있다. 또한, 통신부는 전자 장치가 학습 시작 안내 메시지 출력 후, 획득한 전자 장치의 기능단위로 구분된 사용자 입력 시퀀스들 및 상기 입력 시퀀스들의 입력 순서를 더 수신할 수도 있다. 데이터 베이스는 도 11에 도시된 전자 장치의 메모리에 대응될 수 있다. 예를 들어, 데이터 베이스 는 자동 음성 인식(ASR) 모델, 자연어 이해 모델(Natural Language Understanding, NLU), 대화 관리 (Dialog Management, DM) 모델, 액션 플랜(Action Planning, AP) 모델, 자연어 생성 모델(Natural Language Generator, NLG), 텍스트 음성 변환(Text to Speech, TTS) 모델을 포함하는 보이스 어시스턴트 서비스 모델을 저장할 수 있다. 또한, 데이터 베이스는 보이스 어시스턴트 서비스를 제공하기 위한 가상 개인 비서 모델, 추론 모델 또는 현재 전자 장치의 동작 상태를 관리하기 위한 렌더링 모델을 더 저장할 수도 있다. 프로세서는 통상적으로 서버의 전반적인 동작을 제어한다. 예를 들어, 프로세서는, 서버 의 DB에 저장된 프로그램들을 실행함으로써, DB 및 통신부 등을 전반적으로 제어할 수 있다. 또한, 프로세서는 DB에 저장된 프로그램들을 실행함으로써, 도 1 내지 도11에서의 전자 장치 의 동작의 일부를 수행할 수 있다. 예를 들어, 프로세서는 보이스 어시스턴트 서비스를 이용하여, 전자 장치로부터 수신된 사용자의 음성에 대한 응답 동작을 출력할 수 있다. 예를 들어, 프로세서는 수신된 사용자의 음성에 대한 응답 동 작을 수행할 수 있는지 여부를 결정하고, 사용자의 음성에 대한 응답 동작을 수행할 수 있는 것으로 결정하는 경우, 사용자의 음성에 대한 응답 동작과 관련된 정보를 전자 장치로로 전송할 수도 있다. 또한, 프로세서는 수신된 사용자의 음성에 대한 응답 동작을 수행할 수 없는 것으로 결정하는 경우, 사용 자 음성에 대한 응답 동작을 수행할 수 없다는 결정과 관련된 정보를 전자 장치로 전송할 수 있다. 일 실 시 예에 의하면, 프로세서는 도 1 내지 도 10에 기재된 전자 장치의 프로세서의 기능 중 적어도 일 부를 수행할 수도 있다. 일 실시예에 따른 방법은 다양한 컴퓨터 수단을 통하여 수행될 수 있는 프로그램 명령 형태로 구현되어 컴퓨터 판독 가능 매체에 기록될 수 있다. 상기 컴퓨터 판독 가능 매체는 프로그램 명령, 데이터 파일, 데이터 구조 등 을 단독으로 또는 조합하여 포함할 수 있다. 상기 매체에 기록되는 프로그램 명령은 본 개시를 위하여 특별히 설계되고 구성된 것들이거나 컴퓨터 소프트웨어 당업자에게 공지되어 사용 가능한 것일 수도 있다. 또한, 상기 일 실시 예에 다른 방법을 수행하도록 하는 프로그램이 저장된 기록매체를 포함하는 컴퓨터 프로그 램 장치가 제공될 수 있다. 컴퓨터 판독 가능 기록 매체의 예에는 하드 디스크, 플로피 디스크 및 자기 테이프 와 같은 자기 매체(magnetic media), CD-ROM, DVD와 같은 광기록 매체(optical media), 플롭티컬 디스크 (floptical disk)와 같은 자기-광 매체(magneto-optical media), 및 롬(ROM), 램(RAM), 플래시 메모리 등과 같 은 프로그램 명령을 저장하고 수행하도록 특별히 구성된 하드웨어 장치가 포함된다. 프로그램 명령의 예에는 컴 파일러에 의해 만들어지는 것과 같은 기계어 코드뿐만 아니라 인터프리터 등을 사용해서 컴퓨터에 의해서 실행 될 수 있는 고급 언어 코드를 포함한다. 이상에서 본 개시의 실시예에 대하여 상세하게 설명하였지만 본 개시의 권리범위는 이에 한정되는 것은 아니고 다음의 청구범위에서 정의하고 있는 본 개시의 기본 개념을 이용한 당업자의 여러 변형 및 개량 형태 또한 본 개시의 권리범위에 속한다.도면 도면1 도면2 도면3 도면4 도면5 도면6 도면7 도면8 도면9 도면10 도면11 도면12"}
{"patent_id": "10-2019-0108468", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 일 실시 예에 따른 보이스 어시스턴트 서비스를 제공하는 과정을 나타내는 도면이다. 도 2는 일 실시 예에 따른 전자 장치가 보이스 어시스턴트 서비스를 제공하는 방법의 흐름도이다. 도 3은 일 실시 예에 따른 전자 장치가 보이스 어시스턴트 서비스를 제공하는 방법의 흐름도이다. 도 4는 일 실시 예에 따른 전자 장치가 보이스 어시스턴트 서비스를 학습하는 과정을 설명하기 위한 도면이다. 도 5는 일 실시 예에 따른 전자 장치가 보이스 어시스턴트 서비스를 학습하는 과정을 설명하기 위한 도면이다. 도 6은 일 실시 예에 따른 전자 장치가 보이스 어시스턴트 서비스를 학습하는 과정을 설명하기 위한 도면이다. 도 7은 일 실시 예에 따른 전자 장치가 보이스 어시스턴트 서비스를 학습하는 과정을 설명하기 위한 도면이다. 도 8은 일 실시 예에 따른 전자 장치 및 서버가 보이스 어시스턴트 서비스를 제공하는 과정을 설명하기 위한 도 면이다. 도 9는 일 실시 예에 따른 보이스 어시스턴트 서비스를 제공하는 전자 장치의 블록도이다. 도 9는 일 실시 에에 따른 전자 장치 및 서버가 보이스 어시스턴트 서비스를 제공하는 과정을 설명하기 위한 도 면이다. 도 10은 일 실시 예에 따른 보이스 어시스턴트 서비스를 제공하는 전자 장치의 블록도이다. 도 11은 일 실시 예에 따른 보이스 어시스턴트 서비스를 제공하는 전자 장치의 블록도이다. 도 12는 일 실시 예에 따른 보이스 어시스턴트 서비스를 제공하는 서버의 블록도이다."}
