{"patent_id": "10-2022-0178582", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0004391", "출원번호": "10-2022-0178582", "발명의 명칭": "비디오 처리 방법 및 장치, 비디오 조회 방법 및 장치, 비디오 처리 모델의 트레이닝 방법 및", "출원인": "베이징 바이두 넷컴 사이언스 테크놀로지 컴퍼니", "발명자": "허 둥량"}}
{"patent_id": "10-2022-0178582", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "처리하고자 하는 비디오에 대해 복수의 수용야에서의 복수의 비디오 특징을 추출하는 것,상기 복수의 수용야 중 목표 수용야에서의 비디오 특징에 따라, 상기 처리하고자 하는 비디오의 국소적 특징을추출하는 것,상기 복수의 수용야 중 최대 수용야에서의 비디오 특징에 따라, 상기 처리하고자 하는 비디오의 전역적 특징을얻는 것, 및상기 국소적 특징과 상기 전역적 특징을 융합하여, 상기 처리하고자 하는 비디오의 목표 특징을 얻는 것을 포함하는비디오 처리 방법."}
{"patent_id": "10-2022-0178582", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 복수의 수용야 중 목표 수용야에서의 비디오 특징에 따라, 상기 처리하고자 하는 비디오의 국소적 특징을추출하는 것은,소정의 크기의 슬라이딩 윈도우에 따라 상기 목표 수용야에서의 비디오 특징을 캡처하여, 복수의 비디오 서브특징을 얻는 것,상기 복수의 비디오 서브 특징 중 각 서브 특징에 대해, 주의력 알고리즘을 이용하여 상기 각 서브 특징을 처리하여 처리된 서브 특징을 얻는 것, 및상기 복수의 비디오 서브 특징에 대해 얻은 복수의 처리된 서브 특징에 따라, 상기 국소적 특징을 얻는 것을 포함하는비디오 처리 방법."}
{"patent_id": "10-2022-0178582", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,상기 복수의 비디오 서브 특징에 대해 얻은 복수의 처리된 서브 특징에 따라, 상기 국소적 특징을 얻는 것은,상기 복수의 처리된 서브 특징을 융합하여 융합된 특징을 얻는 것,3차원 컨볼루션을 이용하여 상기 융합된 특징의 가중치 특징을 추출하는 것, 및상기 가중치 특징에 따라 상기 융합된 특징에 대해 가중치를 부여하여, 상기 국소적 특징을 얻는 것을 포함하는비디오 처리 방법."}
{"patent_id": "10-2022-0178582", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제2항에 있어서,상기 소정의 크기의 슬라이딩 윈도우에 따라 상기 목표 수용야에서의 비디오 특징을 캡처하여, 복수의 비디오서브 특징을 얻는 것은,공간 차원의 제1 소정 스텝과 시간 차원의 제2 소정 스텝에 따라 상기 슬라이딩 윈도우를 이동하여, 상기 복수의 비디오 서브 특징을 캡처하는 것을 포함하고,상기 제1 소정 스텝은 상기 슬라이딩 윈도우의 상기 공간 차원에서의 길이보다 작고, 상기 제2 소정 스텝은 상공개특허 10-2023-0004391-3-기 슬라이딩 원도우의 상기 시간 차원에서의 길이보다 작은비디오 처리 방법."}
{"patent_id": "10-2022-0178582", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서,상기 국소적 특징과 상기 전역적 특징을 융합하여, 상기 처리하고자 하는 비디오의 목표 특징을 얻는 것은,교차 주의력 알고리즘을 이용하여 상기 국소적 특징과 상기 전역적 특징을 융합하여, 상기 목표 특징을 얻는 것을 포함하는비디오 처리 방법."}
{"patent_id": "10-2022-0178582", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5항에 있어서,상기 교차 주의력 알고리즘을 이용하여 상기 국소적 특징과 상기 전역적 특징을 융합하여, 상기 목표 특징을 얻는 것은,상기 전역적 특징에 따라, 조회 특징을 취득하는 것,상기 국소적 특징에 따라, 키 특징 및 값 특징을 취득하는 것, 및상기 조회 특징, 상기 키 특징 및 상기 값 특징에 따라, 상기 교차 주의력 알고리즘을 이용하여 상기 목표 특징을 얻는 것을 포함하는비디오 처리 방법."}
{"patent_id": "10-2022-0178582", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "조회 텍스트의 텍스트 특징을 추출하는 것,복수의 후보 비디오 중 각 비디오의 목표 특징을 취득하는 것, 및상기 텍스트 특징과 상기 목표 특징에 따라, 상기 복수의 후보 비디오에서 상기 조회 텍스트에 매칭되는 비디오를 확정하는 것을 포함하고,상기 목표 특징은 제1항 내지 제6항 중 어느 한 항의 비디오 처리 방법에 의해 취득된 것인비디오 조회 방법."}
{"patent_id": "10-2022-0178582", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "비디오 특징 추출 네트워크, 국소적 특징 추출 네트워크 및 특징 융합 네트워크를 포함하는 비디오 처리 모델의트레이닝 방법으로서,샘플 데이터에 포함된 샘플 비디오를 상기 비디오 특징 추출 네트워크에 입력하여, 복수의 수용야에서의 복수의비디오 특징을 얻는 것,상기 복수의 수용야 중 목표 수용야에서의 비디오 특징을 상기 국소적 특징 추출 네트워크에 입력하여, 상기 샘플 비디오의 국소적 특징을 얻는 것,상기 복수의 수용야 중 최대 수용야에서의 비디오 특징에 따라, 상기 샘플 비디오의 전역적 특징을 얻는 것,상기 국소적 특징 및 상기 전역적 특징을 상기 특징 융합 네트워크에 입력하여, 상기 샘플 비디오의 목표 특징을 얻는 것,상기 샘플 데이터 중의 샘플 텍스트의 텍스트 특징을 취득하는 것, 및상기 목표 특징과 상기 텍스트 특징에 따라, 상기 비디오 처리 모델을 트레이닝하는 것을 포함하는비디오 처리 모델의 트레이닝 방법.공개특허 10-2023-0004391-4-청구항 9 제8항에 있어서,상기 텍스트 특징은 상기 샘플 텍스트의 문장 레벨 특징을 포함하고,상기 목표 특징과 상기 텍스트 특징에 따라, 상기 비디오 처리 모델을 트레이닝하는 것은,상기 목표 특징 및 상기 문장 레벨 특징 사이의 유사도에 따라, 상기 비디오 처리 모델을 트레이닝하는 것을 포함하는비디오 처리 모델의 트레이닝 방법."}
{"patent_id": "10-2022-0178582", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9항에 있어서,상기 텍스트 특징은 상기 샘플 텍스트의 단어 레벨 특징을 더 포함하고,상기 방법은,상기 국소적 특징과 상기 단어 레벨 특징에 따라, 상기 비디오 처리 모델을 트레이닝하는 것을 더 포함하는비디오 처리 모델의 트레이닝 방법."}
{"patent_id": "10-2022-0178582", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제10항에 있어서,상기 단어 레벨 특징은 상기 샘플 텍스트에 포함된 복수의 엔티티 워드에 각각 대응하는 복수의 단어 특징을 포함하고,상기 국소적 특징과 상기 단어 레벨 특징에 따라, 상기 비디오 처리 모델을 트레이닝하는 것은,상기 복수의 단어 특징 중 각 단어 특징과 상기 국소적 특징 사이의 유사도를 확정하여 복수의 제1 유사도를 얻는 것, 및상기 복수의 제1 유사도에 따라, 상기 비디오 처리 모델을 트레이닝하는 것을 포함하는비디오 처리 모델의 트레이닝 방법."}
{"patent_id": "10-2022-0178582", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항에 있어서,상기 국소적 특징과 상기 단어 레벨 특징에 따라, 상기 비디오 처리 모델을 트레이닝하는 것은,상기 각 단어 특징에 대해, 상기 각 단어 특징과 목표 샘플 데이터 중 샘플 비디오의 국소적 특징 사이의 유사도를 확정하여, 상기 복수의 단어 특징에 각각 대응하는 복수의 제2 유사도를 얻는 것,상기 복수의 제1 유사도 및 상기 복수의 제2 유사도에 따라, 상기 비디오 처리 모델의 손실을 확정하는 것, 및상기 손실에 따라, 상기 비디오 처리 모델을 트레이닝하는 것을 더 포함하고,상기 목표 샘플 데이터에서의 샘플 텍스트에는 상기 복수의 단어 특징에 대응하는 단어를 포함하지 않는비디오 처리 모델의 트레이닝 방법."}
{"patent_id": "10-2022-0178582", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "처리하고자 하는 비디오에 대해 복수의 수용야에서의 복수의 비디오 특징을 추출하기 위한 비디오 특징 추출모듈,상기 복수의 수용야 중 목표 수용야에서의 비디오 특징에 따라, 상기 처리하고자 하는 비디오의 국소적 특징을추출하기 위한 국소적 특징 추출모듈,상기 복수의 수용야 중 최대 수용야에서의 비디오 특징에 따라, 상기 처리하고자 하는 비디오의 전역적 특징을공개특허 10-2023-0004391-5-얻기 위한 전역적 특징 확정모듈, 및상기 국소적 특징과 상기 전역적 특징을 융합하여, 상기 처리하고자 하는 비디오의 목표 특징을 얻기 위한 특징융합모듈을 포함하는비디오 처리 장치."}
{"patent_id": "10-2022-0178582", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제13항에 있어서,상기 국소적 특징 추출모듈은,소정의 크기의 슬라이딩 윈도우에 따라 상기 목표 수용야에서의 비디오 특징을 캡처하여, 복수의 비디오 서브특징을 얻기 위한 특징 캡처 서브모듈,상기 복수의 비디오 서브 특징 중 각 서브 특징에 대해, 주의력 알고리즘을 이용하여 상기 각 서브 특징을 처리하여 처리된 서브 특징을 얻기 위한 특징 처리 서브모듈, 및상기 복수의 비디오 서브 특징에 대해 얻은 복수의 처리된 서브 특징에 따라, 상기 국소적 특징을 얻기 위한 국소적 특징 취득 서브모듈을 포함하는비디오 처리 장치."}
{"patent_id": "10-2022-0178582", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제14항에 있어서,상기 국소적 특징 취득 서브모듈은,상기 복수의 처리된 서브 특징을 융합하여 융합된 특징을 얻기 위한 융합유닛,3차원 컨볼루션을 이용하여 상기 융합된 특징의 가중치 특징을 추출하기 위한 가중치 추출유닛, 및상기 가중치 특징에 따라 상기 융합된 특징에 대해 가중치를 부여하여, 상기 국소적 특징을 얻기 위한 가중치부여유닛을 포함하는비디오 처리 장치."}
{"patent_id": "10-2022-0178582", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제14항에 있어서,상기 특징 캡처 서브모듈은,공간 차원의 제1 소정 스텝과 시간 차원의 제2 소정 스텝에 따라 상기 슬라이딩 윈도우를 이동하여, 상기 복수의 비디오 서브 특징을 캡처하기 위한 것이고,상기 제1 소정 스텝은 상기 슬라이딩 윈도우의 상기 공간 차원에서의 길이보다 작고, 상기 제2 소정 스텝은 상기 슬라이딩 원도우의 상기 시간 차원에서의 길이보다 작은비디오 처리 장치."}
{"patent_id": "10-2022-0178582", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제13항에 있어서,상기 특징 융합모듈은,교차 주의력 알고리즘을 이용하여 상기 국소적 특징과 상기 전역적 특징을 융합하여, 상기 목표 특징을 얻는비디오 처리 장치."}
{"patent_id": "10-2022-0178582", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제17항에 있어서,공개특허 10-2023-0004391-6-상기 특징 융합모듈은,상기 전역적 특징에 따라, 조회 특징을 취득하기 위한 제1 취득 서브모듈,상기 국소적 특징에 따라, 키 특징 및 값 특징을 취득하기 위한 제2 취득 서브모듈, 및상기 조회 특징, 상기 키 특징 및 상기 값 특징에 따라, 상기 교차 주의력 알고리즘을 이용하여 상기 목표 특징을 얻기 위한 주의력 서브모듈을 포함하는비디오 처리 장치."}
{"patent_id": "10-2022-0178582", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "조회 텍스트의 텍스트 특징을 추출하기 위한 텍스트 특징 추출모듈,복수의 후보 비디오 중 각 비디오의 목표 특징을 취득하기 위한 목표 특징 취득모듈, 및상기 텍스트 특징과 상기 목표 특징에 따라, 상기 복수의 후보 비디오에서 상기 조회 텍스트에 매칭되는 비디오를 확정하기 위한 비디오 확정모듈을 포함하고,상기 목표 특징은 제13항 내지 제18항 중 어느 한 항의 비디오 처리 장치에 의해 취득되는비디오 조회 장치."}
{"patent_id": "10-2022-0178582", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "비디오 특징 추출 네트워크, 국소적 특징 추출 네트워크 및 특징 융합 네트워크를 포함하는 비디오 처리 모델의트레이닝 장치로서,샘플 데이터에 포함된 샘플 비디오를 비디오 특징 추출 네트워크에 입력하여, 복수의 수용야에서의 복수의 비디오 특징을 얻기 위한 비디오 특징 추출모듈,상기 복수의 수용야 중 목표 수용야에서의 비디오 특징을 상기 국소적 특징 추출 네트워크에 입력하여, 상기 샘플 비디오의 국소적 특징을 얻기 위한 국소적 특징 추출모듈,상기 복수의 수용야 중 최대 수용야에서의 비디오 특징에 따라, 상기 샘플 비디오의 전역적 특징을 얻기 위한전역적 특징 확정모듈,상기 국소적 특징 및 상기 전역적 특징을 상기 특징 융합 네트워크에 입력하여, 상기 샘플 비디오의 목표 특징을 얻기 위한 특징 융합모듈,상기 샘플 데이터 중의 샘플 텍스트의 텍스트 특징을 취득하기 위한 텍스트 특징 취득모듈, 및상기 목표 특징과 상기 텍스트 특징에 따라, 상기 비디오 처리 모델을 트레이닝하기 위한 제1 트레이닝모듈을포함하는비디오 처리 모델의 트레이닝 장치."}
{"patent_id": "10-2022-0178582", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_21", "content": "제20항에 있어서,상기 텍스트 특징은 상기 샘플 텍스트의 문장 레벨 특징을 포함하고, 상기 제1 트레이닝모듈은,상기 목표 특징과 상기 문장 레벨 특징 사이의 유사도에 따라, 상기 비디오 처리 모델을 트레이닝하는비디오 처리 모델의 트레이닝 장치."}
{"patent_id": "10-2022-0178582", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_22", "content": "제21항에 있어서,상기 텍스트 특징은 상기 샘플 텍스트의 단어 레벨 특징을 더 포함하고,공개특허 10-2023-0004391-7-상기 장치는,상기 국소적 특징과 상기 단어 레벨 특징에 따라, 상기 비디오 처리 모델을 트레이닝하기 위한 제2 트레이닝모듈을 더 포함하는비디오 처리 모델의 트레이닝 장치."}
{"patent_id": "10-2022-0178582", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_23", "content": "제22항에 있어서,상기 단어 레벨 특징은 상기 샘플 텍스트에 포함된 복수의 엔티티 워드에 각각 대응하는 복수의 단어 특징을 포함하고,상기 제2 트레이닝모듈은,상기 복수의 단어 특징 중 각 단어 특징과 상기 국소적 특징 사이의 유사도를 확정하여 복수의 제1 유사도를 얻기 위한 제1 확정 서브모듈, 및상기 복수의 제1 유사도에 따라, 상기 비디오 처리 모델을 트레이닝하기 위한 트레이닝 서브모듈을 더 포함하는비디오 처리 모델의 트레이닝 장치."}
{"patent_id": "10-2022-0178582", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_24", "content": "제23항에 있어서,상기 제2 트레이닝모듈은,상기 각 단어 특징에 대해, 상기 각 단어 특징과 목표 샘플 데이터 중 샘플 비디오의 국소적 특징 사이의 유사도를 확정하여, 상기 복수의 단어 특징에 각각 대응하는 복수의 제2 유사도를 얻기 위한 제2 확정 서브모듈을더 포함하고,상기 트레이닝 서브모듈은,상기 복수의 제1 유사도 및 상기 복수의 제2 유사도에 따라, 상기 비디오 처리 모델의 손실을 확정하기 위한 손실 확정유닛, 및상기 손실에 따라, 상기 비디오 처리 모델을 트레이닝하기 위한 트레이닝유닛을 포함하고,상기 목표 샘플 데이터에서의 샘플 텍스트에는 상기 복수의 단어 특징에 대응하는 단어를 포함하지 않는비디오 처리 모델의 트레이닝 장치."}
{"patent_id": "10-2022-0178582", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_25", "content": "적어도 하나의 프로세서, 및상기 적어도 하나의 프로세서에 통신가능하게 연결되는 메모리를 포함하는 전자장비로서,상기 메모리에는 상기 적어도 하나의 프로세서에 의해 실행 가능한 명령이 저장되어 있고, 상기 명령은 상기 적어도 하나의 프로세서에 의해 실행됨으로써, 상기 적어도 하나의 프로세서로 하여금 제1항 내지 제6항 중 어느한 항의 방법을 실행하도록 하는전자장비."}
{"patent_id": "10-2022-0178582", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_26", "content": "적어도 하나의 프로세서, 및상기 적어도 하나의 프로세서에 통신가능하게 연결되는 메모리를 포함하는 전자장비로서,상기 메모리에는 상기 적어도 하나의 프로세서에 의해 실행 가능한 명령이 저장되어 있고, 상기 명령은 상기 적어도 하나의 프로세서에 의해 실행됨으로써, 상기 적어도 하나의 프로세서로 하여금 제7항의 방법을 실행하도록하는공개특허 10-2023-0004391-8-전자장비."}
{"patent_id": "10-2022-0178582", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_27", "content": "적어도 하나의 프로세서, 및상기 적어도 하나의 프로세서에 통신가능하게 연결되는 메모리를 포함하는 전자장비로서,상기 메모리에는 상기 적어도 하나의 프로세서에 의해 실행 가능한 명령이 저장되어 있고, 상기 명령은 상기 적어도 하나의 프로세서에 의해 실행됨으로써, 상기 적어도 하나의 프로세서로 하여금 제8항 내지 제12항 중 어느한 항의 방법을 실행하도록 하는전자장비."}
{"patent_id": "10-2022-0178582", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_28", "content": "컴퓨터 프로그램이 저장되어 있는 비 일시적 컴퓨터 판독가능 저장매체로서,상기 컴퓨터 프로그램이 프로세서에 의해 실행될 경우, 제1항 내지 제6항 중 어느 한 항의 방법을 구현하는비 일시적 컴퓨터 판독가능 저장매체."}
{"patent_id": "10-2022-0178582", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_29", "content": "컴퓨터 프로그램이 저장되어 있는 비 일시적 컴퓨터 판독가능 저장매체로서,상기 컴퓨터 프로그램이 프로세서에 의해 실행될 경우, 제7항의 방법을 구현하는비 일시적 컴퓨터 판독가능 저장매체."}
{"patent_id": "10-2022-0178582", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_30", "content": "컴퓨터 프로그램이 저장되어 있는 비 일시적 컴퓨터 판독가능 저장매체로서,상기 컴퓨터 프로그램이 프로세서에 의해 실행될 경우, 제8항 내지 제12항 중 어느 한 항의 방법을 구현하는비 일시적 컴퓨터 판독가능 저장매체."}
{"patent_id": "10-2022-0178582", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_31", "content": "컴퓨터 판독가능 저장 매체에 저장된 컴퓨터 프로그램으로서,상기 컴퓨터 프로그램이 프로세서에 의해 실행될 경우, 제1항 내지 제6항 중 어느 한 항의 방법을 구현하는컴퓨터 판독가능 저장 매체에 저장된 컴퓨터 프로그램."}
{"patent_id": "10-2022-0178582", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_32", "content": "컴퓨터 판독가능 저장 매체에 저장된 컴퓨터 프로그램으로서,상기 컴퓨터 프로그램이 프로세서에 의해 실행될 경우, 제7항의 방법을 구현하는컴퓨터 판독가능 저장 매체에 저장된 컴퓨터 프로그램."}
{"patent_id": "10-2022-0178582", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_33", "content": "컴퓨터 판독가능 저장 매체에 저장된 컴퓨터 프로그램으로서,상기 컴퓨터 프로그램이 프로세서에 의해 실행될 경우, 제8항 내지 제12항 중 어느 한 항의 방법을 구현하는컴퓨터 판독가능 저장 매체에 저장된 컴퓨터 프로그램."}
{"patent_id": "10-2022-0178582", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 개시는 비디오 처리 방법 및 장치, 비디오 조회 방법 및 장치, 비디오 처리 모델의 트레이닝 방법 및 장치, 전자장비, 저장매체 및 컴퓨터 프로그램을 제공하고, 인공 지능 분야에 관한 것으로서, 구체적으로는 컴퓨터 비 전, 비디오 이해 및 딥 러닝"}
{"patent_id": "10-2022-0178582", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "에 관한 것으로서, 스마트 도시 및 스마트 교통 등 장면에 적용할 수 있다. 비디오 처리 방법은, 처리하고자 하는 비디오에 대해 복수의 수용야에서의 복수의 비디오 특징을 추출하는 것, 복수의 수용야 중 목표 수용야에서의 비디오 특징에 따라, 처리하고자 하는 비디오의 국소적 특징을 추출하는 것, 복수의 수용야 중 최대 수용야에서의 비디오 특징에 따라, 처리하고자 하는 비디오의 전역적 특징을 얻는 것, 및 국소적 특징과 전역적 특징을 융합하여, 처리하고자 하는 비디오의 목표 특징을 얻는 것을 포함한다. 대 표 도 - 도2"}
{"patent_id": "10-2022-0178582", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 2, "content": "공개특허10-2023-0004391 CPC특허분류 G06F 16/78 (2019.01) G06N 3/0442 (2023.01) G06V 10/42 (2023.01) G06V 10/44 (2023.01) G06V 10/774 (2023.01) G06V 10/80 (2023.01) G06V 10/82 (2022.01) G06V 20/41 (2022.01)명 세 서 청구범위 청구항 1 처리하고자 하는 비디오에 대해 복수의 수용야에서의 복수의 비디오 특징을 추출하는 것, 상기 복수의 수용야 중 목표 수용야에서의 비디오 특징에 따라, 상기 처리하고자 하는 비디오의 국소적 특징을 추출하는 것, 상기 복수의 수용야 중 최대 수용야에서의 비디오 특징에 따라, 상기 처리하고자 하는 비디오의 전역적 특징을 얻는 것, 및 상기 국소적 특징과 상기 전역적 특징을 융합하여, 상기 처리하고자 하는 비디오의 목표 특징을 얻는 것을 포함 하는 비디오 처리 방법. 청구항 2 제1항에 있어서, 상기 복수의 수용야 중 목표 수용야에서의 비디오 특징에 따라, 상기 처리하고자 하는 비디오의 국소적 특징을 추출하는 것은, 소정의 크기의 슬라이딩 윈도우에 따라 상기 목표 수용야에서의 비디오 특징을 캡처하여, 복수의 비디오 서브 특징을 얻는 것, 상기 복수의 비디오 서브 특징 중 각 서브 특징에 대해, 주의력 알고리즘을 이용하여 상기 각 서브 특징을 처리 하여 처리된 서브 특징을 얻는 것, 및 상기 복수의 비디오 서브 특징에 대해 얻은 복수의 처리된 서브 특징에 따라, 상기 국소적 특징을 얻는 것을 포 함하는 비디오 처리 방법. 청구항 3 제2항에 있어서, 상기 복수의 비디오 서브 특징에 대해 얻은 복수의 처리된 서브 특징에 따라, 상기 국소적 특징을 얻는 것은, 상기 복수의 처리된 서브 특징을 융합하여 융합된 특징을 얻는 것, 3차원 컨볼루션을 이용하여 상기 융합된 특징의 가중치 특징을 추출하는 것, 및 상기 가중치 특징에 따라 상기 융합된 특징에 대해 가중치를 부여하여, 상기 국소적 특징을 얻는 것을 포함하는 비디오 처리 방법. 청구항 4 제2항에 있어서, 상기 소정의 크기의 슬라이딩 윈도우에 따라 상기 목표 수용야에서의 비디오 특징을 캡처하여, 복수의 비디오 서브 특징을 얻는 것은, 공간 차원의 제1 소정 스텝과 시간 차원의 제2 소정 스텝에 따라 상기 슬라이딩 윈도우를 이동하여, 상기 복수 의 비디오 서브 특징을 캡처하는 것을 포함하고, 상기 제1 소정 스텝은 상기 슬라이딩 윈도우의 상기 공간 차원에서의 길이보다 작고, 상기 제2 소정 스텝은 상기 슬라이딩 원도우의 상기 시간 차원에서의 길이보다 작은 비디오 처리 방법. 청구항 5 제1항에 있어서, 상기 국소적 특징과 상기 전역적 특징을 융합하여, 상기 처리하고자 하는 비디오의 목표 특징을 얻는 것은, 교차 주의력 알고리즘을 이용하여 상기 국소적 특징과 상기 전역적 특징을 융합하여, 상기 목표 특징을 얻는 것 을 포함하는 비디오 처리 방법. 청구항 6 제5항에 있어서, 상기 교차 주의력 알고리즘을 이용하여 상기 국소적 특징과 상기 전역적 특징을 융합하여, 상기 목표 특징을 얻 는 것은, 상기 전역적 특징에 따라, 조회 특징을 취득하는 것, 상기 국소적 특징에 따라, 키 특징 및 값 특징을 취득하는 것, 및 상기 조회 특징, 상기 키 특징 및 상기 값 특징에 따라, 상기 교차 주의력 알고리즘을 이용하여 상기 목표 특징 을 얻는 것을 포함하는 비디오 처리 방법. 청구항 7 조회 텍스트의 텍스트 특징을 추출하는 것, 복수의 후보 비디오 중 각 비디오의 목표 특징을 취득하는 것, 및 상기 텍스트 특징과 상기 목표 특징에 따라, 상기 복수의 후보 비디오에서 상기 조회 텍스트에 매칭되는 비디오 를 확정하는 것을 포함하고, 상기 목표 특징은 제1항 내지 제6항 중 어느 한 항의 비디오 처리 방법에 의해 취득된 것인 비디오 조회 방법. 청구항 8 비디오 특징 추출 네트워크, 국소적 특징 추출 네트워크 및 특징 융합 네트워크를 포함하는 비디오 처리 모델의 트레이닝 방법으로서, 샘플 데이터에 포함된 샘플 비디오를 상기 비디오 특징 추출 네트워크에 입력하여, 복수의 수용야에서의 복수의 비디오 특징을 얻는 것, 상기 복수의 수용야 중 목표 수용야에서의 비디오 특징을 상기 국소적 특징 추출 네트워크에 입력하여, 상기 샘 플 비디오의 국소적 특징을 얻는 것, 상기 복수의 수용야 중 최대 수용야에서의 비디오 특징에 따라, 상기 샘플 비디오의 전역적 특징을 얻는 것, 상기 국소적 특징 및 상기 전역적 특징을 상기 특징 융합 네트워크에 입력하여, 상기 샘플 비디오의 목표 특징 을 얻는 것, 상기 샘플 데이터 중의 샘플 텍스트의 텍스트 특징을 취득하는 것, 및 상기 목표 특징과 상기 텍스트 특징에 따라, 상기 비디오 처리 모델을 트레이닝하는 것을 포함하는 비디오 처리 모델의 트레이닝 방법.청구항 9 제8항에 있어서, 상기 텍스트 특징은 상기 샘플 텍스트의 문장 레벨 특징을 포함하고, 상기 목표 특징과 상기 텍스트 특징에 따라, 상기 비디오 처리 모델을 트레이닝하는 것은, 상기 목표 특징 및 상기 문장 레벨 특징 사이의 유사도에 따라, 상기 비디오 처리 모델을 트레이닝하는 것을 포 함하는 비디오 처리 모델의 트레이닝 방법. 청구항 10 제9항에 있어서, 상기 텍스트 특징은 상기 샘플 텍스트의 단어 레벨 특징을 더 포함하고, 상기 방법은, 상기 국소적 특징과 상기 단어 레벨 특징에 따라, 상기 비디오 처리 모델을 트레이닝하는 것을 더 포함하는 비디오 처리 모델의 트레이닝 방법. 청구항 11 제10항에 있어서, 상기 단어 레벨 특징은 상기 샘플 텍스트에 포함된 복수의 엔티티 워드에 각각 대응하는 복수의 단어 특징을 포 함하고, 상기 국소적 특징과 상기 단어 레벨 특징에 따라, 상기 비디오 처리 모델을 트레이닝하는 것은, 상기 복수의 단어 특징 중 각 단어 특징과 상기 국소적 특징 사이의 유사도를 확정하여 복수의 제1 유사도를 얻 는 것, 및 상기 복수의 제1 유사도에 따라, 상기 비디오 처리 모델을 트레이닝하는 것을 포함하는 비디오 처리 모델의 트레이닝 방법. 청구항 12 제11항에 있어서, 상기 국소적 특징과 상기 단어 레벨 특징에 따라, 상기 비디오 처리 모델을 트레이닝하는 것은, 상기 각 단어 특징에 대해, 상기 각 단어 특징과 목표 샘플 데이터 중 샘플 비디오의 국소적 특징 사이의 유사 도를 확정하여, 상기 복수의 단어 특징에 각각 대응하는 복수의 제2 유사도를 얻는 것, 상기 복수의 제1 유사도 및 상기 복수의 제2 유사도에 따라, 상기 비디오 처리 모델의 손실을 확정하는 것, 및 상기 손실에 따라, 상기 비디오 처리 모델을 트레이닝하는 것을 더 포함하고, 상기 목표 샘플 데이터에서의 샘플 텍스트에는 상기 복수의 단어 특징에 대응하는 단어를 포함하지 않는 비디오 처리 모델의 트레이닝 방법. 청구항 13 처리하고자 하는 비디오에 대해 복수의 수용야에서의 복수의 비디오 특징을 추출하기 위한 비디오 특징 추출모 듈, 상기 복수의 수용야 중 목표 수용야에서의 비디오 특징에 따라, 상기 처리하고자 하는 비디오의 국소적 특징을 추출하기 위한 국소적 특징 추출모듈, 상기 복수의 수용야 중 최대 수용야에서의 비디오 특징에 따라, 상기 처리하고자 하는 비디오의 전역적 특징을얻기 위한 전역적 특징 확정모듈, 및 상기 국소적 특징과 상기 전역적 특징을 융합하여, 상기 처리하고자 하는 비디오의 목표 특징을 얻기 위한 특징 융합모듈을 포함하는 비디오 처리 장치. 청구항 14 제13항에 있어서, 상기 국소적 특징 추출모듈은, 소정의 크기의 슬라이딩 윈도우에 따라 상기 목표 수용야에서의 비디오 특징을 캡처하여, 복수의 비디오 서브 특징을 얻기 위한 특징 캡처 서브모듈, 상기 복수의 비디오 서브 특징 중 각 서브 특징에 대해, 주의력 알고리즘을 이용하여 상기 각 서브 특징을 처리 하여 처리된 서브 특징을 얻기 위한 특징 처리 서브모듈, 및 상기 복수의 비디오 서브 특징에 대해 얻은 복수의 처리된 서브 특징에 따라, 상기 국소적 특징을 얻기 위한 국 소적 특징 취득 서브모듈을 포함하는 비디오 처리 장치. 청구항 15 제14항에 있어서, 상기 국소적 특징 취득 서브모듈은, 상기 복수의 처리된 서브 특징을 융합하여 융합된 특징을 얻기 위한 융합유닛, 3차원 컨볼루션을 이용하여 상기 융합된 특징의 가중치 특징을 추출하기 위한 가중치 추출유닛, 및 상기 가중치 특징에 따라 상기 융합된 특징에 대해 가중치를 부여하여, 상기 국소적 특징을 얻기 위한 가중치 부여유닛을 포함하는 비디오 처리 장치. 청구항 16 제14항에 있어서, 상기 특징 캡처 서브모듈은, 공간 차원의 제1 소정 스텝과 시간 차원의 제2 소정 스텝에 따라 상기 슬라이딩 윈도우를 이동하여, 상기 복수 의 비디오 서브 특징을 캡처하기 위한 것이고, 상기 제1 소정 스텝은 상기 슬라이딩 윈도우의 상기 공간 차원에서의 길이보다 작고, 상기 제2 소정 스텝은 상 기 슬라이딩 원도우의 상기 시간 차원에서의 길이보다 작은 비디오 처리 장치. 청구항 17 제13항에 있어서, 상기 특징 융합모듈은, 교차 주의력 알고리즘을 이용하여 상기 국소적 특징과 상기 전역적 특징을 융합하여, 상기 목표 특징을 얻는 비디오 처리 장치. 청구항 18 제17항에 있어서,상기 특징 융합모듈은, 상기 전역적 특징에 따라, 조회 특징을 취득하기 위한 제1 취득 서브모듈, 상기 국소적 특징에 따라, 키 특징 및 값 특징을 취득하기 위한 제2 취득 서브모듈, 및 상기 조회 특징, 상기 키 특징 및 상기 값 특징에 따라, 상기 교차 주의력 알고리즘을 이용하여 상기 목표 특징 을 얻기 위한 주의력 서브모듈을 포함하는 비디오 처리 장치. 청구항 19 조회 텍스트의 텍스트 특징을 추출하기 위한 텍스트 특징 추출모듈, 복수의 후보 비디오 중 각 비디오의 목표 특징을 취득하기 위한 목표 특징 취득모듈, 및 상기 텍스트 특징과 상기 목표 특징에 따라, 상기 복수의 후보 비디오에서 상기 조회 텍스트에 매칭되는 비디오 를 확정하기 위한 비디오 확정모듈을 포함하고, 상기 목표 특징은 제13항 내지 제18항 중 어느 한 항의 비디오 처리 장치에 의해 취득되는 비디오 조회 장치. 청구항 20 비디오 특징 추출 네트워크, 국소적 특징 추출 네트워크 및 특징 융합 네트워크를 포함하는 비디오 처리 모델의 트레이닝 장치로서, 샘플 데이터에 포함된 샘플 비디오를 비디오 특징 추출 네트워크에 입력하여, 복수의 수용야에서의 복수의 비디 오 특징을 얻기 위한 비디오 특징 추출모듈, 상기 복수의 수용야 중 목표 수용야에서의 비디오 특징을 상기 국소적 특징 추출 네트워크에 입력하여, 상기 샘 플 비디오의 국소적 특징을 얻기 위한 국소적 특징 추출모듈, 상기 복수의 수용야 중 최대 수용야에서의 비디오 특징에 따라, 상기 샘플 비디오의 전역적 특징을 얻기 위한 전역적 특징 확정모듈, 상기 국소적 특징 및 상기 전역적 특징을 상기 특징 융합 네트워크에 입력하여, 상기 샘플 비디오의 목표 특징 을 얻기 위한 특징 융합모듈, 상기 샘플 데이터 중의 샘플 텍스트의 텍스트 특징을 취득하기 위한 텍스트 특징 취득모듈, 및 상기 목표 특징과 상기 텍스트 특징에 따라, 상기 비디오 처리 모델을 트레이닝하기 위한 제1 트레이닝모듈을 포함하는 비디오 처리 모델의 트레이닝 장치. 청구항 21 제20항에 있어서, 상기 텍스트 특징은 상기 샘플 텍스트의 문장 레벨 특징을 포함하고, 상기 제1 트레이닝모듈은, 상기 목표 특징과 상기 문장 레벨 특징 사이의 유사도에 따라, 상기 비디오 처리 모델을 트레이닝하는 비디오 처리 모델의 트레이닝 장치. 청구항 22 제21항에 있어서, 상기 텍스트 특징은 상기 샘플 텍스트의 단어 레벨 특징을 더 포함하고,상기 장치는, 상기 국소적 특징과 상기 단어 레벨 특징에 따라, 상기 비디오 처리 모델을 트레이닝하기 위한 제2 트레이닝모 듈을 더 포함하는 비디오 처리 모델의 트레이닝 장치. 청구항 23 제22항에 있어서, 상기 단어 레벨 특징은 상기 샘플 텍스트에 포함된 복수의 엔티티 워드에 각각 대응하는 복수의 단어 특징을 포 함하고, 상기 제2 트레이닝모듈은, 상기 복수의 단어 특징 중 각 단어 특징과 상기 국소적 특징 사이의 유사도를 확정하여 복수의 제1 유사도를 얻 기 위한 제1 확정 서브모듈, 및 상기 복수의 제1 유사도에 따라, 상기 비디오 처리 모델을 트레이닝하기 위한 트레이닝 서브모듈을 더 포함하는 비디오 처리 모델의 트레이닝 장치. 청구항 24 제23항에 있어서, 상기 제2 트레이닝모듈은, 상기 각 단어 특징에 대해, 상기 각 단어 특징과 목표 샘플 데이터 중 샘플 비디오의 국소적 특징 사이의 유사 도를 확정하여, 상기 복수의 단어 특징에 각각 대응하는 복수의 제2 유사도를 얻기 위한 제2 확정 서브모듈을 더 포함하고, 상기 트레이닝 서브모듈은, 상기 복수의 제1 유사도 및 상기 복수의 제2 유사도에 따라, 상기 비디오 처리 모델의 손실을 확정하기 위한 손 실 확정유닛, 및 상기 손실에 따라, 상기 비디오 처리 모델을 트레이닝하기 위한 트레이닝유닛을 포함하고, 상기 목표 샘플 데이터에서의 샘플 텍스트에는 상기 복수의 단어 특징에 대응하는 단어를 포함하지 않는 비디오 처리 모델의 트레이닝 장치. 청구항 25 적어도 하나의 프로세서, 및 상기 적어도 하나의 프로세서에 통신가능하게 연결되는 메모리를 포함하는 전자장비로서, 상기 메모리에는 상기 적어도 하나의 프로세서에 의해 실행 가능한 명령이 저장되어 있고, 상기 명령은 상기 적 어도 하나의 프로세서에 의해 실행됨으로써, 상기 적어도 하나의 프로세서로 하여금 제1항 내지 제6항 중 어느 한 항의 방법을 실행하도록 하는 전자장비. 청구항 26 적어도 하나의 프로세서, 및 상기 적어도 하나의 프로세서에 통신가능하게 연결되는 메모리를 포함하는 전자장비로서, 상기 메모리에는 상기 적어도 하나의 프로세서에 의해 실행 가능한 명령이 저장되어 있고, 상기 명령은 상기 적 어도 하나의 프로세서에 의해 실행됨으로써, 상기 적어도 하나의 프로세서로 하여금 제7항의 방법을 실행하도록 하는전자장비. 청구항 27 적어도 하나의 프로세서, 및 상기 적어도 하나의 프로세서에 통신가능하게 연결되는 메모리를 포함하는 전자장비로서, 상기 메모리에는 상기 적어도 하나의 프로세서에 의해 실행 가능한 명령이 저장되어 있고, 상기 명령은 상기 적 어도 하나의 프로세서에 의해 실행됨으로써, 상기 적어도 하나의 프로세서로 하여금 제8항 내지 제12항 중 어느 한 항의 방법을 실행하도록 하는 전자장비. 청구항 28 컴퓨터 프로그램이 저장되어 있는 비 일시적 컴퓨터 판독가능 저장매체로서, 상기 컴퓨터 프로그램이 프로세서에 의해 실행될 경우, 제1항 내지 제6항 중 어느 한 항의 방법을 구현하는 비 일시적 컴퓨터 판독가능 저장매체. 청구항 29 컴퓨터 프로그램이 저장되어 있는 비 일시적 컴퓨터 판독가능 저장매체로서, 상기 컴퓨터 프로그램이 프로세서에 의해 실행될 경우, 제7항의 방법을 구현하는 비 일시적 컴퓨터 판독가능 저장매체. 청구항 30 컴퓨터 프로그램이 저장되어 있는 비 일시적 컴퓨터 판독가능 저장매체로서, 상기 컴퓨터 프로그램이 프로세서에 의해 실행될 경우, 제8항 내지 제12항 중 어느 한 항의 방법을 구현하는 비 일시적 컴퓨터 판독가능 저장매체. 청구항 31 컴퓨터 판독가능 저장 매체에 저장된 컴퓨터 프로그램으로서, 상기 컴퓨터 프로그램이 프로세서에 의해 실행될 경우, 제1항 내지 제6항 중 어느 한 항의 방법을 구현하는 컴퓨터 판독가능 저장 매체에 저장된 컴퓨터 프로그램. 청구항 32 컴퓨터 판독가능 저장 매체에 저장된 컴퓨터 프로그램으로서, 상기 컴퓨터 프로그램이 프로세서에 의해 실행될 경우, 제7항의 방법을 구현하는 컴퓨터 판독가능 저장 매체에 저장된 컴퓨터 프로그램. 청구항 33 컴퓨터 판독가능 저장 매체에 저장된 컴퓨터 프로그램으로서, 상기 컴퓨터 프로그램이 프로세서에 의해 실행될 경우, 제8항 내지 제12항 중 어느 한 항의 방법을 구현하는 컴퓨터 판독가능 저장 매체에 저장된 컴퓨터 프로그램. 발명의 설명"}
{"patent_id": "10-2022-0178582", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 3, "content": "기 술 분 야본 개시는 인공지능 분야에 관한 것으로서, 구체적으로는, 컴퓨터 비전, 비디오 이해 및 딥 러닝 기술분야에 관 한 것으로서, 스마트 도시 및 스마트 교통 등 장면에 적용할 수 있다."}
{"patent_id": "10-2022-0178582", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "컴퓨터 기술 및 네트워크 기술의 발전에 따라, 딥 러닝 기술은 많은 분야에서 광범위하게 응용되고 있다. 예를 들어, 딥 러닝 기술을 이용하여 비디오 특징을 추출하고, 비디오의 검색 및 비디오의 분류 등을 실행할 수 있다. 관련 기술은 특허 공고번호가 CN109977793B인 중국 발명 특허를 참조할 수 있다. 본 개시는 비디오 처리 방법 및 장치, 비디오 조회 방법 및 장치, 비디오 처리 모델의 트레이닝 방법 및 장치, 전자장비, 저장매체, 및 컴퓨터 프로그램을 제공하여, 특징 표현 능력을 향상시키는 것을 목적으로 한다. 본 개시의 일 측면에 의하면, 처리하고자 하는 비디오에 대해 복수의 수용야에서의 복수의 비디오 특징을 추출 하는 것, 복수의 수용야 중 목표 수용야에서의 비디오 특징에 따라, 처리하고자 하는 비디오의 국소적 특징을 추출하는 것, 복수의 수용야 중 최대 수용야에서의 비디오 특징에 따라, 처리하고자 하는 비디오의 전역적 특징 을 얻는 것, 및 국소적 특징과 전역적 특징을 융합하여, 처리하고자 하는 비디오의 목표 특징을 얻는 것을 포함 하는 비디오 처리 방법을 제공한다. 본 개시의 다른 측면에 의하면, 조회 텍스트의 텍스트 특징을 추출하는 것, 복수의 후보 비디오 중 각 비디오의 목표 특징을 취득하는 것, 및 텍스트 특징과 목표 특징에 따라, 복수의 후보 비디오에서 조회 텍스트에 매칭되 는 비디오를 확정하는 것을 포함하고, 목표 특징은 본 개시에 의해 제공되는 비디오 처리 방법에 의해 취득된 것인 비디오 조회 방법을 제공한다. 본 개시의 다른 측면에 의하면, 비디오 특징 추출 네트워크, 국소적 특징 추출 네트워크 및 특징 융합 네트워크 를 포함하는 비디오 처리 모델의 트레이닝 방법으로서, 샘플 데이터에 포함된 샘플 비디오를 비디오 특징 추출 네트워크에 입력하여, 복수의 수용야에서의 복수의 비디오 특징을 얻는 것, 복수의 수용야 중 목표 수용야에서 의 비디오 특징을 국소적 특징 추출 네트워크에 입력하여, 샘플 비디오의 국소적 특징을 얻는 것, 복수의 수용 야 중 최대 수용야에서의 비디오 특징에 따라, 샘플 비디오의 전역적 특징을 얻는 것, 국소적 특징 및 전역적 특징을 특징 융합 네트워크에 입력하여, 샘플 비디오의 목표 특징을 얻는 것, 샘플 데이터 중의 샘플 텍스트의 텍스트 특징을 취득하는 것, 및 목표 특징과 텍스트 특징에 따라, 비디오 처리 모델을 트레이닝하는 것을 포함 하는 비디오 처리 모델의 트레이닝 방법을 제공한다. 본 개시의 다른 측면에 의하면, 처리하고자 하는 비디오에 대해 복수의 수용야에서의 복수의 비디오 특징을 추 출하기 위한 비디오 특징 추출모듈, 복수의 수용야 중 목표 수용야에서의 비디오 특징에 따라, 처리하고자 하는 비디오의 국소적 특징을 추출하기 위한 국소적 특징 추출모듈, 복수의 수용야 중 최대 수용야에서의 비디오 특 징에 따라, 처리하고자 하는 비디오의 전역적 특징을 얻기 위한 전역적 특징 확정모듈, 및 국소적 특징과 전역 적 특징을 융합하여, 처리하고자 하는 비디오의 목표 특징을 얻기 위한 특징 융합모듈을 포함하는 비디오 처리 장치를 제공한다. 본 개시의 다른 측면에 의하면, 조회 텍스트의 텍스트 특징을 추출하기 위한 텍스트 특징 추출모듈, 복수의 후 보 비디오 중 각 비디오의 목표 특징을 취득하기 위한 목표 특징 취득모듈, 및 텍스트 특징과 목표 특징에 따라, 복수의 후보 비디오에서 조회 텍스트에 매칭되는 비디오를 확정하기 위한 비디오 확정모듈을 포함하고, 목표 특징은 본 개시에 의해 제공되는 비디오 처리 장치에 의해 취득되는 비디오 조회 장치를 제공한다. 본 개시의 다른 측면에 의하면, 비디오 특징 추출 네트워크, 국소적 특징 추출 네트워크 및 특징 융합 네트워크 를 포함하는 비디오 처리 모델의 트레이닝 장치로서, 샘플 데이터에 포함된 샘플 비디오를 비디오 특징 추출 네 트워크에 입력하여, 복수의 수용야에서의 복수의 비디오 특징을 얻기 위한 비디오 특징 추출모듈, 복수의 수용 야 중 목표 수용야에서의 비디오 특징을 국소적 특징 추출 네트워크에 입력하여, 샘플 비디오의 국소적 특징을 얻기 위한 국소적 특징 추출모듈, 복수의 수용야 중 최대 수용야에서의 비디오 특징에 따라, 샘플 비디오의 전 역적 특징을 얻기 위한 전역적 특징 확정모듈, 국소적 특징 및 전역적 특징을 특징 융합 네트워크에 입력하여, 샘플 비디오의 목표 특징을 얻기 위한 특징 융합모듈, 샘플 데이터 중의 샘플 텍스트의 텍스트 특징을 취득하기 위한 텍스트 특징 취득모듈, 및 목표 특징과 텍스트 특징에 따라, 비디오 처리 모델을 트레이닝하기 위한 제1트레이닝모듈을 포함하는 비디오 처리 모델의 트레이닝 장치를 제공한다. 본 개시의 다른 측면에 의하면, 적어도 하나의 프로세서, 및 적어도 하나의 프로세서와 통신가능하게 연결되는 메모리를 포함하는 전자장비로서, 메모리에는 적어도 하나의 프로세서에 의해 실행 가능한 명령이 저장되어 있 고, 명령이 상기 적어도 하나의 프로세서에 의해 실행될 경우, 적어도 하나의 프로세서로 하여금 본 개시에 의 해 제공하는 비디오 처리 방법, 비디오 조회 방법 및 비디오 처리 모델의 트레이닝 방법 중 적어도 하나를 실행 하도록 하는 전자장비를 제공한다. 본 개시의 다른 측면에 의하면, 컴퓨터 프로그램이 저장되어 있는 비 일시적 컴퓨터 판독가능 저장매체로서, 상 기 컴퓨터 프로그램이 프로세서에 의해 실행될 경우, 본 개시에 의해 제공하는 비디오 처리 방법, 비디오 조회 방법 및 비디오 처리 모델의 트레이닝 방법 중 적어도 하나를 구현하는 비 일시적 컴퓨터 판독가능 저장매체를 제공한다. 본 개시의 다른 측면에 의하면, 컴퓨터 판독가능 저장 매체에 저장된 컴퓨터 프로그램으로서, 상기 컴퓨터 프로 그램이 프로세서에 의해 실행될 경우, 본 개시에 의해 제공하는 비디오 처리 방법, 비디오 조회 방법 및 비디오 처리 모델의 트레이닝 방법 중 적어도 하나를 구현하는 컴퓨터 프로그램 제품을 제공한다. 본 명세서에 기술된 내용은 그 목적이 본 개시의 실시예의 핵심 또는 중요한 특징을 지정하기 위한 것이 아니고, 또한, 본 개시의 범위는 이에 한정되지 아니함을 이해하여야 한다. 본 개시의 다른 특징들은 하기 설명 으로부터 용이하게 이해할 수 있을 것이다."}
{"patent_id": "10-2022-0178582", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 도면을 참조하여 본 개시의 예시적인 실시예들을 설명한다. 쉽게 이해할 수 있도록, 본 개시의 실시예들 의 세부사항을 포함하게 되는데, 이들은 단지 예시적인 것에 불과하다. 따라서, 당업자라면 본 개시의 범위 및 취지를 벗어나지 않으면서 본 개시의 실시예에 대해 여러가지 변경 및 수정이 이루어질 수 있음을 이해할 것이다. 또한, 명확성과 간결성을 위해 하기의 설명에 있어서, 공지된 기능 및 구성에 대한 설명은 생략한다. 본 개시는 비디오 특징 추출 단계, 국소적 특징 추출 단계, 전역적 특징 확정 단계 및 특징 융합 단계를 포함하 는 비디오 처리 방법을 제공한다. 비디오 특징 추출 단계에서는, 처리하고자 하는 비디오에 대해 복수의 수용야 에서의 복수의 비디오 특징을 추출한다. 국소적 특징 추출 단계에서는, 복수의 수용야 중 목표 수용야에서의 비 디오 특징에 따라, 처리하고자 하는 비디오의 국소적 특징을 추출한다. 전역적 특징 확정 단계에서는, 복수의 수용야 중 최대 수용야에서의 비디오 특징에 따라, 처리하고자 하는 비디오의 전역적 특징을 얻는다. 특징 융합단계에서는, 국소적 특징과 전역적 특징을 융합하여, 처리하고자 하는 비디오의 목표 특징을 얻는다. 이하, 도 1을 참조하여 본 개시에 의해 제공되는 방법 및 장치의 응용장면을 설명하기로 한다. 도 1은 본 개시의 실시예에 따른 비디오 처리 방법 및 장치, 비디오 조회 방법 및 장치, 그리고 비디오 처리 모 델의 트레이닝 방법 및 장치의 응용장면의 개략도이다. 도 1에 도시된 바와 같이, 본 실시예의 응용장면은 전자장비를 포함할 수 있고, 전자장비는 스 마트 폰, 태블릿 컴퓨터, 랩탑형 휴대용 컴퓨터, 데스크탑 컴퓨터 및 서버 등과 같은 처리 기능을 구비한 다양 한 전자장비일 수 있는데, 이에 대해 한정되지는 않는다. 전자장비는 예를 들어 입력된 비디오를 처리함으로써, 해당 비디오를 표현하는 특징을 추출할 수 있다. 추출된 특징은 스마트 교통, 스마트 추천 및 스마트 선별 등과 같은 다양한 장면에서의 비디오 분류, 비디오 조회, 비디오 중복 제거 등 응용에 대한 근거로 사용될 수 있고, 본 개시는 상기 장면에 대해 한 정하지 않는다. 일 실시예에 의하면, 전자장비는 비디오 처리 모델을 이용하여 입력된 비디오를 처리할 수 있다. 여기서, 비디오 처리 모델은 CNN(Convolutional Neural Network)모델 또는 주의력에 기반한 Transformer모델 등일 수 있고, 본 개시는 이에 대해 한정하지 않는다. 일 실시예에 의하면, 비디오 처리 모델은 예를 들어 서버에 의해 트레이닝되어 얻을 수 있다. 전자장 비는 네트워크를 통해 서버에 통신가능하게 연결되어, 서버로 모델 취득 청구를 송신할수 있다. 이에 대응하여, 서버는 해당 청구에 응답하여 트레이닝된 비디오 처리 모델을 전자장비로 송신 할 수 있다. 일 실시예에 의하면, 전자장비는 입력된 비디오를 서버로 송신할 수도 있는데, 서버는 상 기 비디오를 처리함으로써, 비디오를 표현하는 특징을 얻을 수 있다. 지적해두어야 할 것은, 비디오 조회 응용에서, 조회 정보의 특징과 비디오의 특징 사이의 유사도에 따라, 비디 오가 조회 정보에 매칭되는지 확정할 수 있다. 비디오 중복 제거 응용에서, 2개의 비디오의 2개의 특징 사이의 유사도에 따라, 상기 2개의 비디오가 서로 중복되는지 확정할 수 있다. 지적해두어야 할 것은, 본 개시에 의해 제공되는 비디오 처리 방법 및 비디오 조회 방법은 전자장비에 의 해 실행될 수도 있고, 서버에 의해 실행될 수도 있다. 이에 대응하여, 본 개시에 의해 제공되는 비디오 처 리 장치 및 비디오 조회 장치는 전자장비에 설치될 수도 있고, 서버에 설치될 수도 있다. 본 개시에 의해 제공되는 비디오 처리 모델의 트레이닝 방법은 서버에 의해 실행될 수 있다. 이에 대응하여, 본 개시 에 의해 제공되는 비디오 처리 모델의 트레이닝 장치는 서버에 설치될 수 있다. 지적해두어야 할 것은, 도 1에 도시된 전자장비 및 서버의 수 및 유형은 단지 예시적인 것에 지나지 않는다. 실제 수요에 따라, 임의의 수 및 유형의 전자장비 및 서버를 포함할 수 있다. 이하, 도 2 내지 도 5를 참조하여 본 개시에 의해 제공되는 비디오 처리 방법을 상세하게 설명하기로 한다. 도 2는 본 개시의 실시예에 따른 비디오 처리 방법의 개략적인 흐름도이다. 도 2에 도시된 바와 같이, 본 실시예에 따른 비디오 처리 방법은 동작 S210 내지 동작 S230을 포함할 수 있다. 동작 S210에서는, 처리하고자 하는 비디오에 대해 복수의 수용야에서의 복수의 비디오 특징을 추출한다. 본 개시의 실시예에 의하면, 처리하고자 하는 비디오는 예를 들어 복수의 비디오 프레임을 포함할 수 있고, 각 비디오 프레임의 크기를 H×W×3로 설정하고, 복수의 비디오 프레임의 개수를 T로 설정할 경우, 본 실시예에서 는, 처리하고자 하는 비디오를 크기가 T×H×W×3인 데이터로 표시할 수 있다. 여기서, H는 비디오 프레임의 높 이이고, W는 비디오 프레임의 폭이다. 일 실시예에 의하면, 복수의 3차원 컨볼루션을 이용하여 처리하고자 하는 비디오를 나타내는 데이터를 한단계 한단계씩 차례로 다운 샘플링하여, 복수의 수용야에서의 복수의 비디오 특징을 얻을 수 있다. 일 실시예에 의하면, Video Swin-Transformer모델을 이용하여 복수의 비디오 특징을 추출할 수 있다. 구체적으 로는, 크기가 T×H×W×3인 데이터를 분할하여 크기가 T/2×H/4×W/4×96인 데이터를 얻을 수 있다. 크기가 T/2 ×H/4×W/4×96인 데이터는 Video Swin-Transformer모델에서 순차적으로 연결된 다단계 네트워크(복수의 stage)에 의해 차례로 처리되고, 상기 순차적으로 연결된 복수의 stage는 각각 복수의 수용야에서의 복수의 비디오 특징을 출력하고, 각 stage는 하나의 수양야에서의 비디오 특징을 출력하는데, 출력되는 비디오 특징의 수용야 는 복수의 stage의 연결 순서에 따라 차례로 증가된다. 동작 S220에서는, 복수의 수용야 중 목표 수용야에서의 비디오 특징에 따라, 처리하고자 하는 비디오의 국소적 특징을 추출한다. 본 개시의 실시예에 의하면, 목표 수용야는 예를 들어 복수의 수용야 중 최대 수용야와 최소 수용야 사이의 임 의의 수용야일 수 있다. 이렇게 함으로써, 처리 효율을 향상시킴과 동시에 목표 수용야에서의 비디오 특징으로 하여금 처리하고자 하는 비디오의 국소적 정보를 보다 많이 유지하도록 할 수 있다. 예를 들어, 복수의 수양야 의 수가 4개이고, 복수의 수용야에서의 비디오 특징이 순차적으로 연결된 4개의 stage에 의해 차례로 출력되는 경우, 목표 수용야에서의 비디오 특징은 순차적으로 연결된 4개의 stage 중 두번째 stage 또는 세번째 stage에 의해 출력될 수 있고, 본 개시는 이에 대해 한정하지 않는다. 본 개시의 실시예에 의하면, 목표 수용야에서의 비디오 특징을 복수의 특징 블록으로 분할한 다음, 복수의 특징 블록 중의 각 특징 블록에 대해 컨볼루션 연산을 실행하여 하나의 처리된 특징 블록을 얻을 수 있다. 본 실시예 에서는, 복수의 특징 블록에 대해 컨볼루션 연산을 실행하여 얻은 복수의 처리된 특징 블록을 융합함으로써, 처 리하고자 하는 비디오의 국소적 특징을 얻을수 있다. 동작 S230에서는, 복수의 수용야 중 최대 수용야에서의 비디오 특징에 따라, 처리하고자 하는 비디오의 전역적 특징을 얻는다. 동작 S240에서는, 국소적 특징과 전역적 특징을 융합하여, 처리하고자 하는 비디오의 목표 특징을 얻는다. 본 개시의 실시예에 의하면, 순차적으로 연결된 복수의 stage에 의해 복수의 비디오 특징을 출력하는 경우, 최 대 수용야에서의 비디오 특징은 복수의 stage 중 마지막 stage에서 출력되는 비디오 특징이다. 본 실시예에서는, 마지막 stage에서 출력된 비디오 특징을 처리하고자 하는 비디오의 전역적 특징으로 할 수 있다. 본 개시의 실시예에 의하면, 전역적 특징과 국소적 특징을 융합하고, 융합된 특징을 목표 특징으로 할 수 있다. 또는, 본 실시예에서는, 융합된 특징을 완전 연결 계층(fully connected layer)을 통해 처리하고, 완전 연결 계 층을 의해 처리된 특징을 목표 특징으로 할 수 있다. 본 개시의 실시예에 따른 비디오 처리 방법은, 복수의 수용야 중 목표 수용야에서의 비디오 특징에 따라 국소적 특징을 추출하고, 국소적 특징과 최대 수용야의 전역적 특징을 융합하여 비디오를 표현하는 목표 특징을 얻음으 로써, 상기 목표 특징으로 하여금 비디오의 전역적 정보뿐만 아니라 국소적 정보도 표현할 수 있도록 한다. CNN 에 기초하여 특징을 추출하는 방법 및 Transformer에 기초하여 End to End 방식으로 특징을 추출하는 방법에 비 해, 추출된 비디오 특징의 표현 능력을 향상시킬 수 있고, 하류의 응용(예를 들어, 앞에서 설명한 비디오 분류, 비디오 조회 및 비디오 중복 제거 등)의 정확도를 향상시킬 수 있다. 도 3은 본 개시의 실시예에 따른 비디오 처리 방법의 개략적인 원리도이다. 도 3에 도시된 바와 같이, 본 실시예에서는 Video Swin-Transformer 모델을 이용하여 비디오 처리 방법을 구현할 수 있다. 본 실시예에서, Video Swin-Transformer 모델은 4개의 Stage를 포함하여, 추출된 비디오 특징의 수용야를 한단계 한단계씩 차례로 확대할 수 있다. 구체적으로, 앞에서 설명한 처리하고자 하는 비디오를 나타내는 데이 터를 분할하여 얻은 크기가 T/2×H/4×W/4×96인 데이터는, 우선 제1 stage에 입력되고, 제1 stage 에 의해 제1 수용야에서의 제1 비디오 특징을 출력한다. 제1 비디오 특징을 제2 stage의 입력으로 하여, 제2 stage에 의해 처리된 후 제2 수용야에서의 제2 비디오 특징을 출력한다. 이와 같이, 제3 stage에 의해 제3 수용야에서의 제3 비디오 특징을 출력하고, 제4 stage에 의해 제4 수용야에서의 제4 비디오 특징 을 출력한다. 제1 비디오 특징 내지 제4 비디오 특징의 수용야는 차례로 증가하는데, 예를 들어, 제1 비디오 특 징 내지 제4 비디오 특징의 크기는 각각 T/2×H/4×W/4×C, T/2×H/8×W/8×2C, T/2×H/16×W/16×4C, T/2× H/32×W/32×8C이다. 여기서, C는 제1 stage의 채널 수이다. 지적해두어야 할 것은, Video Swin- Transformer모델이 4개의 stage를 포함하는 구조는 단지 예시로서 본 개시에 대한 이해를 돕기 위한 것이고, 본 개시는 이에 대해 한정하지 않는다. 여기서, 제1 stage는 리니어 임베딩(Linear Embedding)층 및 Swin Transformer 블록(Swin Transformer Block)을 포함할 수 있다. 여기서, 크기가 T/2×H/4×W/4×96인 데이터는 리니어 임베딩층의 처리를 거쳐, 입력데이터의 특징 차원을 C로 변경할 수 있다. 즉, 리니어 임베딩층이 출력하는 데이터 크기는 T/2×H/4×W/4×C이 다. Video Transformer 블록은 2개의 부분으로 나뉘어질 수 있는데, 그 중 하나는 Video W-MSA이고, 다른 하나 는 Video SW-MSA이다. 여기서, MSA는 멀티 헤드 셀프 주의력(Multi-head Self Attention)이고, Video W-MSA 부 분은 우선 입력 데이터에 대해 층 정규화 처리를 실행한다. 이어서, 층 정규화 처리를 거친 데이터에 대해, 좌 측 상단 화소로부터 시작하여, 통상적인 윈도우 분할 전략에 따라 T/2×H/4×W/4×C 데이터를 크기가 T/2×H/8 ×W/8×C인 2×2 개의 특징으로 균일하게 분할하고, 각 특징에 대해 멀티 헤드 셀프 주의력 연산을 실행하여, 멀티 헤드 셀프 주의력 연산을 거친 2×2 개의 특징을 융합하고, 융합된 특징은 층 정규화 처리 및 완전 연결 처리를 거친 후, Video SW-MSA 부분의 입력 특징을 얻는다. Video SW-MSA 부분의 처리 로직은 Video W-MSA 부 분과 비슷하고, 단지 Video SW-MSA 부분은 서로 다른 윈도우 분할 전략을 사용한다는 점에서 차이가 있고, Video SW-MSA 부분은 입력된 데이터를 슬라이딩 윈도우의 동작을 통해 분할함으로써, 위치가 이동된 후의 윈도 우 내의 특징으로 하여금 인접한 윈도우의 특징을 포함하도록 하여, Video W-MSA 부분에서 서로 인접한 중복되 지 않는 윈도우의 데이터 사이에 연결을 도입하여 데이터의 수용야를 증가시킬 수 있다. 제2 stage 내지 제4 stage는 모두 블록 융합(Patch Merging)층 및 Swin Transformer블록을 포함할 수 있다. 여기서, 블록 융합층은 입력된 데이터를 병합한 후, 리니어 층을 이용하여 병합된 데이터를 차원 축소하기 위한 것이다. 상기 차원 축소는 데이터의 공간 크기를 변화시키고, 채널 수도 변화시킨다. 도 3에 도시된 바와 같이, 본 실시예에서는 제4 비디오 특징을 전역적 특징으로 하고, 제2 stage에 의해 출력되는 제2 비디오 특징을 목표 수용야에서의 비디오 특징으로 할 수 있다. 제2 비디오 특징에 따라 국소적 특징을 추출하는 경우, 본 실시예에서는, 목표 수용야에서의 비디오 특징을 국소적 특징 추출 브랜치(Local Branch)에 입력할 수 있다. 상기 국소적 특징 추출 브랜치는 우선 소정의 크기의 슬라이딩 윈도우에 따라 목표 수용야에서의 비디오 특징을 캡처하여, 복수의 비디오 서브 특징을 얻을 수 있다. 이어서, 주의력 알 고리즘을 이용하여 복수의 비디오 서브 특징 중의 각 서브 특징을 처리하여, 복수의 처리된 서브 특징을 얻는다. 마지막으로, 복수의 처리된 서브 특징에 따라, 처리하고자 하는 비디오의 국소적 특징을 얻는다. 본 개시의 실시예에 의하면, 국소적 특징 추출 브랜치는 슬라이딩 윈도우층 및 주의력층을 포함한다. 여기 서, 슬라이딩 윈도우층은 소정의 크기의 슬라이딩 윈도우에 따라 크기가 T/2×H/8×W/8×2C인 비디오 특징을 분 할할 수 있다. 분할하여 얻은 복수의 비디오 서브 특징은 서로 중첩되지 않을 수 있다. 또는, 분할하여 얻은 복 수의 비디오 서브 특징 중 서로 인접한 서브 특징은 부분적으로 중첩됨으로써, 추출된 국소적 특징으로 하여금 서로 인접한 화소 특징 사이의 연관성을 충분히 고려하도록 할 수 있어, 국소적 특징의 표현 능력을 향상시킬 수 있다. 주의력층은 분할하여 얻은 각 비디오 서브 특징에 대해 셀프 주의력 연산을 실행함으로써, 각 비디오 서브 특징 중 복수의 화소 특징 사이의 연관성을 러닝할 수 있다. 예를 들어, 슬라이딩 윈도우층에 사용되는 슬라이딩 윈도우의 크기는 공간 차원의 크기 W_s 및 시간 차원의 크 기W_t일 수 있고, 여기서, 공간 차원은 폭 방향과 높이 방향이고, 시간 차원은 T가 위치한 방향이다. 이렇게 되 면, 크기가 T/2×H/8×W/8×2C인 비디오 특징에 대해, 캡처하여 얻은 각 비디오 서브 특징의 크기는 W_t×W_s× W_s×2C이다. 지적해두어야 할 것은, 공간 차원에서의 슬라이딩 윈도우의 폭 방향과 높이 방향의 크기는 동일하 지 않을 수도 있고, 본 개시는 이에 대해 한정하지 않는다. 비디오 서브 특징을 캡처할 경우, 본 실시예에서는, 공간 차원의 제1 소정 스텝과 시간 차원의 제2 소정 스텝에 따라 슬라이딩 윈도우를 이동할 수 있다. 여기서, 제1 소정 스텝은 공간 차원에서의 슬라이딩 윈도우의 길이보다 작고, 제2 소정 스텝은 시간 차원에서의 슬라이 딩 윈도우의 길이보다 작다. 상기 제1 소정 스텝 및 제2 소정 스텝의 설정을 통해, 캡처된 복수의 비디오 서브 특징 중 인접한 서브 특징에 중첩되는 화소점을 존재하도록 함으로써, 추출된 국소적 특징으로 하여금 인접한 화소 특징 사이의 연관성을 충분히 고려하여, 국소적 특징의 표현 능력을 향상시킬 수 있다. 예를 들어, 제1 소정 스텝은 W_s/2일 수 있고, 제2 소정 스텝은 W_t/2일 수 있다. 이렇게 되면, 공간 차원에서 의 슬라이딩 윈도우의 중합 비율은 1/2이고, 시간 차원에서의 슬라이딩 윈도우의 중합 비율도 1/2이다. 캡처하 여 얻은 비디오 서브 특징의 개수는 N_h*N_w*N_t로 표시할 수 있다. 여기서, N_h=H/8/W_s*2, N_w=W/8/W_s*2, N_t=W/2/W_t*2이다. 본 실시예에서는, 복수의 처리된 서브 특징을 얻은 후, 상기 복수의 처리된 서브 특징을 융합하여 국소적 특징 으로 할 수 있다. 또는, 아래에서 설명하는 방법을 통해 국소적 특징을 얻을 수도 있는데, 여기서는 설명을 생략한다. 본 실시예에서는는, 국소적 특징을 얻은 후, 교차 주의력(cross attention) 알고리즘을 이용하여 국소적 특징 및 전역적 특징을 처리함으로써 목표 특징을 얻을 수 있다. 여기서, 전역적 특징은,예를 들어 복수의 비디오 특징 중 최대 수용야의 특징에 대해 풀링(Pooling) 처리를 실행하여 얻을 수 있다. 지 적해두어야 할 것은, 상기 전역적 특징은 직접 Video Swin-Transformer에 의해 출력된 수용야가 최대인 특징일 수 있다. 예를 들어, 국소적 특징 및 전역적 특징을 교차 주의력 네트워크에 입력하고, 상기 교 차 주의력 네트워크에 의해 교차 주의력 연산을 실행할 수 있다. 교차 주의력 연산의 구현 원리는 아래의 설명 을 참조할 수 있고, 여기서는 설명을 생략한다. 여기서, 수용야가 최대인 특징에 대한 풀링 처리는 예를 들어 전역 평균 풀링 처리일 수 있다. 도 4는 본 개시의 실시예에 따른 처리하고자 하는 비디오의 국소적 특징을 추출하는 개략적인 원리도이다. 본 개시의 실시예에 의하면, 국소적 특징 추출 네트워크를 이용하여 처리하고자 하는 비디오의 국소적 특징을 추출할 수 있다. 도 4에 도시된 바와 같이, 본 실시예에서, 국소적 특징 추출 네트워크에 입력되는 특징은 앞에서 설명한 크기가 T/2×H/8×W/8×2C인 비디오 특징 f_2일 수 있다. 상기 비디오 특징 f_2은 중첩 윈도우 분할층에 의해 처리된 후, 복수의 비디오 서브 특징을 얻을 수 있다. 상기 복수의 비디오 서브 특징은 N_t*N_h*N_w 개의 비디오 서브 특징을 포함하는 비디오 그룹f_w를 구성할 수 있고, 각 비디오 서브 특징의 크기 는 W_s*W_s*W_t이고, 각 비디오 서브 특징의 깊이는 2C이다. 도 4에 도시된 바와 같이, 본 실시예에서는, 셀프 주의력 네트워크를 이용하여 각 비디오 서브 특징 을 처리할 수 있다. 여기서, 상기 셀프 주의력 네트워크는 예를 들어 4개의 순차적으로 연결된 셀프 주의 력 블록으로 구성될 수 있고, 각 셀프 주의력 블록은 하나의 멀티 헤드 주의력 메커니즘 층(Win-MSA) 및 하나의 FFN(Feed-Forward Network)로 구성될 수 있다. 각 비디오 서브 특징은 상기 셀프 주의력 네트워크 에 의해 처리된 후, 하나의 처리된 서브 특징을 얻을 수 있다. 따라서, 총 N_t*N_h*N_w 개의 처리된 서브 특징을 얻을 수 있다. N_t*N_h*N_w 개의 처리된 서브 특징을 얻은 후, 윈도우 융합층을 이용하여 이들 처리된 서브 특징을 융합 하여 융합된 특징을 얻을 수 있다. 이어서, 본 실시예에서는, 3차원 컨볼루션을 이용하여 상기 융합된 특징의 가중치 특징을 추출할 수 있고, 마지막으로 상기 가중치 특징에 따라 융합된 특징에 가중치를 부여하여 국소적 특징을 얻을 수 있다. 이렇게 되면, 국소적 특징 추출 네트워크를 사용하여, 융합된 특징 중 각 화소점 특징의 중요도에 대한 점수를 자기 적응적으로 러닝할 수 있고, 이를 통해, 융합된 특징 중 중요도가 높은 특징이 부각 되는 반면, 중요도가 낮은 특징은 억제되어, 추출된 국소적 특징의 정밀도를 향상시킬 수 있다. 여기서, 윈도우 융합층에 의해 이들 처리된 서브 특징을 융합하여 얻은 특징의 크기는 예를 들어 T/2×H/8×W/8×2C일 수 있다. 일 실시예에 의하면, 도 4에 도시된 바와 같이, 윈도우 융합층에 의해 복수의 처리된 서브 특징을 융합한 후, 변환 & 매핑층에 의해 융합하여 얻은 특징에 대해 차원 변환 및 매핑을 실행할 수 있다. 본 실시예에 서는, 변환 & 매핑층에 의해 처리되어 얻은 특징 f_r를 융합된 특징으로 할 수 있다. 예를 들어, 변환 & 매핑층은 우선 윈도우 융합층에서 출력되는 특징을 공간으로부터 깊이(Space to Depth)로 변환하여, 크기가 T/2×H/16×W/16×8C인 특징을 얻을 수 있다. 이어서, 상기 변환 & 매핑층은 컨볼루션 커널이 1인 3차원 컨볼루션(3D-Conv)을 이용하여 크기가 T/2×H/16×W/16×8C인 특징을 매핑하여 융합 된 특징 f_r를 얻을 수 있고, 상기 융합된 특징의 크기는 T/2×H/16×W/16×8C이다. 일 실시예에 의하면, 가중치 특징을 추출할 때, 도 4에 도시된 컨볼루션 네트워크를 이용하여 가중치 특징 을 추출할 수 있다. 여기서, 상기 컨볼루션 네트워크는, 예를 들어 순차적으로 연결된 3D-Conv층, 활 성화층ReLU 및 3D-Conv층을 포함할 수 있다. 본 실시예에서는, 융합된 특징 f_r를 상기 컨볼루션 네 트워크에 입력하여, 상기 컨볼루션 네트워크를 통해 처리한 후, 가중치 특징 S_a를 출력할 수 있고, 상기 가중치 특징 S_a의 크기는 T/2×H/16×W/16이다. 상기 가중치 특징 S_a와 융합된 특징 f_r 중 각 깊이의 특징을 내적하면 처리하고자 하는 비디오의 국소적 특징 f_local을 얻을 수 있고, 상기 국소적 특징 f_local의 크기는 예를 들어 T/2×H/16×W/16×8C일 수 있다. 지적해두어야 할 것은, 도 4에서 설명한 국소적 특징 추출 네트워크의 구성은 단지 본 개시에 대한 이해를 돕기 위한 예시일 뿐, 실제 수요에 따라, 임의의 구성의 국소적 특징 추출 네트워크를 사용할 수 있고, 본 개시는 이 에 대해 한정하지 않는다. 도 5는 본 개시의 실시예에 따른 전역적 특징 및 국소적 특징을 융합하는 개략적인 원리도이다. 본 개시의 실시예에 의하면, 교차 주의력 알고리즘을 이용하여 국소적 특징 f_local과 전역적 특징 f_global을 융합할 수 있다. 이러한 방식을 통해, 국소적 특징과 전역적 특징 사이에 서로 연관되는 모델링을 실행할 수 있으므로, 얻어지는 목표 특징의 표현 능력을 향상시키는데 유리하다. 예를 들어, 본 실시예에서는, 전역적 특징과 국소적 특징을 융합할 때, 우선 전역적 특징 f_global에 따라 조회 특징 Q를 취득하고, 동시에 국소적 특징 f_local에 따라 키 특징 K 및 값 특징 V를 취득할 수 있다. 마지막으로, 상기 조회 특징 Q, 키 특징 K 및 값 특징 V에 따라, 교차 주의력 알고리즘을 이용하여 처리하고자 하는 비디오의 목표 특징을 얻는다. 예를 들어, 우선 조회 특징 Q와 키 특징 K를 내적하고, 내적하여 얻은 결과를 정규화 처리하고, 정규화 처리된 특징을 가중치로 하여 값 특징 V에 가중치를 부여할 수 있는데, 상기 가중치를 부여하여 얻은 특징은 목표 특징 일 수 있다. 일 실시예에 의하면, 멀티 헤드 주의력 메커니즘을 이용하여 교차 주의력 알고리즘을 구현할 수도 있다. 구체적 으로는, 도 5에 도시된 특징 융합 네트워크를 이용하여 국소적 특징 f_local과 전역적 특징 f_global을 융합할 수 있다. 예를 들어, 도 5에 도시된 바와 같이, 본 실시예에 의하면, 특징 융합 네트워크는 복수의 주의력 모듈을 설치할 수 있고, 각 주의력 모듈은 매핑층~매핑층 및 정규화층(Softmax)을 포함할 수 있다. 매핑층은 전역적 특징 f_global을 매핑하여 조회 특징 Q를 얻기 위한 것이고, 매핑층 및 매핑층은 국소적 특징을 매핑하여 각각 키 특징 K 및 값 특징 V를 얻기 위한 것이다. 각 주의력 모듈을 통해 하나의 주의력 특징을 얻을 수 있고, 상기 주의력 특징은 바로 값 특징 V에 가중치를 부여하여 얻 은 특징이다. 본 실시예에서는, 복수의 주의력 모듈로부터 얻은 복수의 주의력 특징을 융합할 수 있 고, 매핑층에 의해 처리된 특징을 목표 특징으로 할 수 있다. 이러한 방식을 통해, 전역적 특징 및 국소적 특징에 대해 보다 충분하게 러닝하여, 목표 특징의 정밀도를 향상시킬 수 있다. 일 실시예에 의하면, 스택된 M개의 특징 융합 네트워크를 이용하여 국소적 특징 f_local과 전역적 특징 f_global의 융합을 실현함으로써, 얻어지는 목표 특징의 정밀도를 보다 향상시킬 수 있다. 예를 들어, 앞에서 설명한 최대 수용야에서의 비디오 특징을 풀링 처리하여, 크기가 1×8C인 전역적 특징을 얻을 수 있고, 앞에서 얻은 크기가 T/2×H/16×W/16×8C인 국소적 특징에 대해, 본 실시예에서는, 상기 국소적 특징을 변환하여 T/2*H/16*W/16 개의 특징을 포함하는 하나의 특징 시퀸스로 변환할 수 있고, 각 특징의 채널 수는 8C이다. 본 실시예에서는, 전역적 특징을 스택된 M개의 특징 융합 네트워크 중 첫번째 네트워크의 입력으로 하고, 첫번째 네트워크의 출력으로 전역적 특징을 대체하여 2번째 네트워크의 입력으로 할 수 있으며, 이러한 방식으로 M번째 네트워크에서 목표 특징을 출력할 수 있다. 여기서, M는 1보다 큰 정수이다. 여기서, M개의 특징 융합 네트워크 중의 각 네트워크는 앞에서 설명한 복수의 주의력 모델, 매핑층 이외에도, FFN 층을 더 포함할 수 있다. 각 네트워크에서는, 매핑층에서 출력된 특징과 상기 각 네트워크에 입력된 전역적 특징을 융합한 후, 융합된 특징을 FFN 층를 통해 처리한 다음, 상기 각 네트워크에 입력된 전역적 특징과 합산하여 각 네 트워크의 다음 네트워크의 전역적 특징을 얻을 수 있다. 예를 들어, M개의 특징 융합 네트워크 중의 m번째 네트워크의 경우, 출력되는 전역적 특징은 하기 수식을 통해 계산할 수 있다."}
{"patent_id": "10-2022-0178582", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "여기서, f_globalm는 m번째 네트워크에서 출력된 전역적 특징이고, MCAm(f_global(m-1), f_local)는 f_global(m-1) 및 f_local을 상기 m번째 네트워크의 입력으로 하여, m번째 네트워크 중 매핑층에 의해 출력되는 특징을 나타낸다. FFNm는 상기 m번째 네트워크 중 FFN 층의 처리를 나타낸다. ||는 융합 동작을 나타낸다. 여기서, MCAm(f_global(m-1), f_local)는 하기 수식으로 표시할 수 있다."}
{"patent_id": "10-2022-0178582", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "여기서, W(m)는 매핑층에서 러닝을 통해 얻은 매핑 매트릭스 파라미터이다. 는 상기 m번째 네트워크 중 i번째 주의력 모듈에서 출력된 특징을 나타낸다. n은 상기 m번째 네트워크에 포함된 주의력 모델의 총 개수이다. 는 예를 들어 하기 수식을 통해 계산할 수 있다. 여기서,"}
{"patent_id": "10-2022-0178582", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "이다. 여기서, , , 는 각각 m번째 네트워크 중 i번째 주의력 모델의 매핑층, 매핑층 및 매핑층에서 러닝한 매트릭스 파라미터를 나타낸다. 본 개시에 의해 제공되는 비디오 처리 방법에 기초하여, 본 개시는 비디오 조회 방법을 더 제공한다. 이하, 도 6을 참조하여 비디오 조회 방법에 대해 상세하게 설명하기로 한다. 도 6은 본 개시의 실시예에 따른 비디오 조회 방법의 개략적인 흐름도이다. 도 6에 도시된 바와 같이, 본 실시예에 따른 비디오 조회 방법은 동작 S610 내지 동작 S630을 포함할 수 있다. 동작 S610에서는, 조회 텍스트의 텍스트 특징을 추출한다. 본 개시의 실시예에 의하면, 조회 텍스트는 예를 들어 사용자가 전자장비를 통해 입력하는 조회 키워드를 포함 할 수 있다. 상기 실시예는 시맨틱 정보를 추출할 수 있는 텍스트 특징 추출 모델을 이용하여 텍스트 특징을 추 출할 수 있다. 여기서, 텍스트 특징 추출 모델은 예를 들어 순환 신경망 모델 또는 Transformer 모델을 포함할 수 있고, 구체적으로는, LSTM(Long-Short Term Memory) 네트워크 또는 ERNIE 모델 등을 이용할 수 있으며, 본 개시는 이에 대해 한정하지 않는다. 동작 S620에서는, 복수의 후보 비디오 중 각 비디오의 목표 특징을 취득한다. 본 개시의 실시예에 의하면, 비디오 라이브러리의 비디오를 후보 비디오로 하고, 앞에서 설명한 비디오 처리 방 법에 따라 각 비디오를 처리하여 각 비디오의 목표 특징을 얻을 수 있다. 본 실시예에서는, 각 비디오의 목표 특징을 미리 저장하고, 또한, 상기 각 비디오와 매핑 관계를 구축할수 있으며, 상기 동작 S620에서는, 저장된 목표 특징을 직접 취득하면 된다. 동작 S630에서는, 텍스트 특징과 목표 특징에 따라, 복수의 후보 비디오에서 조회 텍스트에 매칭되는 비디오를 확정한다. 본 실시예에서는, 텍스트 특징과 목표 특징을 동일한 특징 공간에 매핑하고, 동일한 특징 공간에 매핑된 2개의 특징 사이의 유사도를 계산하여 텍스트 특징과 목표 특징 사이의 유사도로 할 수 있다. 본 실시예에서는, 텍스 트 특징 과의 유사도가 가장 큰 목표 특징에 대응하는 후보 비디오를 조회 텍스트에 매칭하는 비디오로 할 수 있다. 또는, 텍스트 특징과의 유사도가 임계치보다 큰 목표 특징에 대응하는 후보 비디오를 조회 텍스트에 매칭 하는 비디오로 할 수 있다. 여기서, 임계치는 실제 수요에 따라 설정할 수 있고, 특징 사이의 유사도는 피어슨 상관계수, 코사인 유사도 등으로 나타낼 수 있는데, 본 개시는 이에 대해 한정하지 않는다. 일 실시예에 의하면, 동작 S610에서 추출한 텍스트 특징은 단어 레벨 특징과 문장 레벨 특징을 포함할 수 있다. 본 실시예에서는, 문장 레벨 특징과 목표 특징에 따라 유사도를 계산할 수 있다. 여기서, 단어 레벨 특징은 조 회 텍스트 중의 복수의 단어에 각각 대응하는 복수의 단어 특징을 포함할 수 있다.예를 들어, 텍스트 특징을 추출할 경우, 우선 조회 텍스트에 대해 단어 분리 처리를 실행하고, 미리 생성된 사 전에 따라 단어 분리하여 얻은 복수의 단어에 각각 대응하는 복수의 단어 표기를 얻을 수 있으며, 각 단어 표기 를 하나의 단어 Token으로 하고, Tx로 표시되는 Token을 설정하여 조회 텍스트의 전체 문장을 표시할 수 있다. 상기 Tx를 첫번째 Token으로 하고, 복수의 단어 표기를 조회 텍스트에서의 단어의 순서에 따라 차례로 첫번째 Token 뒤에 배열하여 Token 시퀸스를 얻는다. 본 실시예에서는, 상기 Token 시퀀스를 ERNIE2.0 모델의 입력으로 하고, 상기 ERNIE2.0 모델을 통해 처리한 후 Tx에 대응하는 문장 레벨 특징 및 복수의 단어 Token에 대응하는 단어 특징을 출력할 수 있다. 여기서, 문장 레벨 특징은 ERNIE2.0 모델 중의 복수층의 멀티 헤드 주의력 메커니 즘을 통해 복수의 단어 Token의 특징에 대해 주의력 가중치를 부여하고 융합하여 얻은 것이다. 지적해두어야 할 것은, 조회 텍스트에 대해 글자를 분리하고, 각 글자에 따라 하나의 Token 을 얻을 수 있다. 글자를 분리하여 Token을 얻는 방법을 사용하는 것에 비해, 단어를 분리하여 Token을 확정하는 방법을 사용함으로써, 얻어지는 단어 특징으로 하여금 시맨틱 정보를 보다 잘 보류하도록 할 수 있다. 비디오 처리 방법의 실행을 용이하게 하기 위해, 본 개시는 비디오 처리 모델의 트레이닝 방법을 더 제공한다. 이하, 도 7 을 참조하여 비디오 처리 모델의 트레이닝 방법에 대해 상세하게 설명하기로 한다. 도 7은 본 개시의 실시예에 따른 비디오 처리 모델의 트레이닝 방법의 개략적인 흐름도이다. 도 7에 도시된 바와 같이, 본 실시예에 따른 비디오 처리 모델의 트레이닝 방법은 동작 S710 내지 동작 S750을 포함할 수 있다. 동작 S710에서는, 샘플 데이터에 포함된 샘플 비디오를 비디오 특징 추출 네트워크에 입력하여, 복수의 수용야 에서의 복수의 비디오 특징을 얻는다. 본 개시의 실시예에 의하면, 샘플 데이터는 배치(Batch) 데이터일 수 있다. 배치 데이터 중의 각 샘플 데이터는 모두 샘플 비디오 및 샘플 텍스트를 포함한다. 본 실시예에서는, 상기 배치 데이터 중의 모든 샘플 데이터를 크 기가 B×T×H×W×3인 데이터로 정리하여 비디오 특징 추출 네트워크로 입력할 수 있고, 비디오 특징 추출 네트 워크에 의해 각 샘플 비디오에 대응하는 복수의 비디오 특징을 추출할 수 있다. 상기 동작 S710의 실현 방식은 앞에서 설명한 동작 S210의 실현 방식과 유사하고, 비디오 특징 추출 네트워크는 앞에서 설명한 Video Swin- Transformer 모델일 수 있으며, 본 개시는 이에 대해 한정하지 않는다. 동작 S720에서는, 복수의 수용야 중 목표 수용야에서의 비디오 특징을 국소적 특징 추출 네트워크에 입력하여, 샘플 비디오의 국소적 특징을 얻는다. 본 개시의 실시예에 의하면, 상기 동작 S720의 실현 방식은 앞에서 설명한 동작 S220의 실현 방식과 유사하다. 배치 데이터 중의 샘플 비디오에 대해, 목표 수용야에서의 비디오 특징은 B개의 크기가 T/2×H/8×W/8×2C인 데 이터를 이용하여 나타낼 수 있다. 본 실시예에서는 상기 B개의 크기가 T/2×H/8×W/8×2C인 데이터를 국소적 특 징 추출 네트워크에 입력하여, B개의 크기가 T/2×H/16×W/16×4C인 국소적 특징을 얻을 수 있다. 여기서, 국소적 특징 추출 네트워크는 도 3 또는 도 4에 도시된 구성일 수 있는데, 본 개시는 이에 대해 한정하 지 않는다. 동작 S730에서는, 복수의 수용야 중 최대 수용야에서의 비디오 특징에 따라, 샘플 비디오의 전역적 특징을 얻는 다. 이 동작은 앞에서 설명한 동작 S230과 유사하므로, 여기서는 설명을 생략한다. 동작 S740에서는, 국소적 특징 및 전역적 특징을 특징 융합 네트워크에 입력하여, 샘플 비디오의 목표 특징을 얻는다. 본 개시의 실시예에 의하면, 상기 동작 S740의 실현 방식은 앞에서 설명한 동작 S240의 실현 방식과 유사하므로, 여기서는 설명을 생략한다. 배치 데이터의 샘플 비디오에 대해, B개의 목표 특징을 얻을 수 있다. 동작 S750에서는, 샘플 데이터 중의 샘플 텍스트의 텍스트 특징을 취득한다. 본 개시의 실시예에 의하면, 상기 동작 S750의 실현 방식은 앞에서 설명한 동작 S610의 실현 방식과 유사하므로, 여기서는 설명을 생략한다. 본 실시예에서는, 비디오 처리 모델을 트레이닝하기 전에, 샘플 텍스트 의 텍스트 특징을 미리 추출하여 얻을 수 있고, 상기 동작 S750은 저장된 상기 텍스트 특징을 취득할 수 있다. 배치 데이터 중의 샘플 텍스트에 대해, B개의 텍스트 특징을 얻을 수 있다. 배치 데이터 중의 각 데이터에 포함 된 샘플 비디오 및 샘플 텍스트에 대응하여, 추출된 목표 특징과 텍스트 특징은 하나의 특징 페어를 구성할 수 있다.동작 S760에서는, 목표 특징과 텍스트 특징에 따라, 비디오 처리 모델을 트레이닝한다. 본 개시의 실시예에 의하면, 위크 모니터링 방식을 이용하여 비디오 처리 모델을 트레이닝할 수 있다. 예를 들 어, 각 샘플 데이터 중의 샘플 비디오와 샘플 텍스트가 매칭되도록 설정한다. 상기 각 샘플 데이터 중의 샘플 비디오와 샘플 텍스트는 예를 들어 조회 이력에 따라 취득된 조회 텍스트 및 재생된 비디오일 수 있고, 또는, 상기 각 샘플 데이터 중의 샘플 텍스트는 상기 각 샘플 데이터 중의 샘플 비디오의 타이틀일 수 있다. 따라서, 모델의 트레이닝 코스트를 감소시킬 수 있다. 예를 들어, 하나의 샘플 데이터 중의 샘플 비디오와 샘플 텍스트에 있어서, 샘플 비디오의 목표 특징과 샘플 텍 스트의 텍스트 특징 사이의 유사도는 1에 접근해야 하므로, 상기 목표 특징과 텍스트 특징 사이의 실제 유사도 를 1로 설정할 수 있다. 본 실시예에서는, 목표 특징과 텍스트 특징 사이의 유사도를 예측 유사도로 하고, 예측 유사도와 실제 유사도 사이의 차이에 따라 비디오 처리 모델의 손실을 확정하고, 손실을 최소화함으로써 비디오 처리 모델을 트레이닝할 수 있다. 또한, 본 실시예에서는 목표 특징과 텍스트 특징 사이의 거리에 따라 비디오 처리 모델을 트레이닝할 수도 있는데, 상기 거리에 따라 모텔을 트레이닝하는 목표는, 하나의 샘플 데이터에 대 해, 샘플 비디오의 목표 특징과 샘플 텍스트의 텍스트 특징 사이의 거리가 0에 접근하도록 하는 것이다. 일 실시예에 의하면, 비디오 처리 모델을 트레이닝하는 과정에 네거티브 샘플을 러닝함으로써 모델의 수렴 효율 을 향상시킬 수도 있다. 예를 들어, 2개의 서로 다른 샘플 데이터로부터의 샘플 비디오와 샘플 텍스트일 경우, 샘플 비디오의 목표 특징과 샘플 텍스트의 텍스트 특징 사이의 유사도는 0에 접근해야 하므로, 2개의 다른 샘플 데이터로부터의 샘플 비디오와 샘플 텍스트로 네거티브 샘플을 구성하고, 네거티브 샘플 중 샘플 비디오의 목표 특징과 샘플 텍스트의 텍스트 특징 사이의 실제 유사도를 0으로 설정할 수 있다. 이에 대응하여, 하나의 샘플 데이터 중의 샘플 비디오와 텍스트 비디오는 포지티브 샘플을 구성할 수 있다. 예를 들어, 상기 실시예는 교차 엔트로피(entropy) 손실 함수를 이용하여 비디오 처리 모델의 손실을 확정함으 로써, 포지티브 샘플 중의 비디오와 텍스트의 특징이 더 접근하도록 하고, 네거티브 샘플 중의 비디오와 텍스트 의 특징이 더 멀어지도록 한다. 일 실시예에 의하면, 하나의 샘플 데이터 중의 샘플 비디오를 vj, 샘플 텍스트를 tj, 샘플 비디오 vj의 목표 특 징을 fj, 샘플 텍스트 tj의 텍스트 특징을 gj로 설정하면, 본 실시예에서는, 하기 비교 손실 함수를 이용하여 비 디오 처리 모델의 손실을 확정할 수 있다."}
{"patent_id": "10-2022-0178582", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "여기서, 는 하이퍼 파리미터이고, 는 fj와 gj의 내적을 나타낸다. 일 실시예에 의하면, 동작 S750에서 취득한 텍스트 특징은 샘플 텍스트의 문장 레벨 특징을 포함할 수 있다. 본 실시예에서 앞에서 설명한 목표 특징과 텍스트 특징 사이의 유사도는 목표 특징과 샘플 텍스트의 문장 레벨 특 징 사이의 유사도일 수 있다. 이렇게 되면, 비디오의 국소적 특징과 전역적 특징을 융합한 목표 특징이 텍스트 의 문장 레벨 특징과 정렬하도록 할 수 있어, 조회 텍스트에 따라 매칭되는 비디오를 쉽게 조회할 수 있다. 이 는 텍스트의 문장 레벨 특징이 텍스트의 시맨틱을 보다 잘 표현할 수 있기 때문이다. 도 8은 본 개시의 실시예에 따른 비디오 처리 모델의 트레이닝 방법의 개략적인 원리도이다. 본 개시의 실시예에 의하면, 앞에서 취득한 텍스트 특징은 예를 들어 문장 레벨 특징 이외에도, 샘플 텍스트의 단어 레벨 특징을 더 포함할 수 있다. 상기 단어 레벨 특징은 샘플 텍스트에 대해 단어를 분리하여 얻은 복수의 단어에 각각 대응하는 복수의 단어 특징을 포함할 수 있다. 본 실시예에서는, 문장 레벨 특징과 목표 특징에 따 라 비디오 처리 모델을 트레이닝하는 외에도 샘플 비디오의 국소적 특징과 샘플 텍스트의 단어 레벨 특징에 따 라 비디오 처리 모델을 트레이닝할 수 있다. 이렇게 되면, 비디오의 국소적 특징과 텍스트의 국소적 특징을 보 다 잘 정렬할 수 있으므로, 트레이닝하여 얻어지는 비디오 처리 모델의 강건성(Robustness)을 향상시킬 수 있다. 이는, 비디오의 타이틀 텍스트 등과 같은 텍스트 내용에는 일부 엔티티 정보가 포함되어 있는데, 이러한 엔티티 정보는 비디오 프레임의 국소적 이미지에 비교적 쉽게 대응할 수 있기 때문이다. 또한, 본 실시예에서는, 글자급 특징에 비해 시맨틱 정보를 보다 잘 표현할 수 있는 단어 레벨 특징을 이용하여 비디오 처리 모델을 트레이닝하므로, 트레이닝하여 얻은 모델의 정밀도를 향상시키는데 유리하다.도 8에 도시된 바와 같이, 실시예에 의하면, 비디오 처리 모델을 트레이닝할 때, 비디오 특징 추출 네트워 크를 통해 샘플 비디오를 처리할 수 있고, 제2 stage에서 출력한 특징을 목표 수용야에서의 비디오 특징으 로 할 수 있다. 상기 목표 수용야에서의 비디오 특징은 국소적 특징 추출 네트워크(앞에서 설명한 국소적 특징 추출 브랜치일 수 있음)에 의해 처리되어 국소적 특징을 얻는다. 순차적으로 연결된 복수의 stage 중 마지막 stage에서 출력된 비디오 특징은 전역 평균 풀링 동작을 거쳐 샘플 비디오의 전역적 특징을 얻는다. 전역적 특징과 국소적 특징은 특징 융합 네트워크에 의해 융합되어 목표 특징을 얻는다. 여기서, 특징 융합 네트워크는 교차 주의력 알고리즘을 이용하여 특징을 융합한다. 또한, 샘플 텍 스트는 단어 분리 처리를 거친 후, 각 단어의 표기를 Token으로 하여 Token1 내지 TokenN을 얻고, 상기 N개의 Token과 맨 앞에 배열된 Tx를 ERNIE2.0 모델에 입력하여, 샘플 텍스트의 문장 레벨 특징과 단어 레벨 특징을 얻을 수 있다. 문장 레벨 특징은 Tx에 대응한다. 단어 레벨 특징은 Token1 내지 TokenN 에 각각 대응하는 N개의 단어 특징을 포함한다. 이어서, 본 실시예에서는, 목표 특징과 문장 레벨 특징 사이의 유사도에 따라 비디오 처리 모델의 전 역적 손실을 얻을 수 있다. 국소적 특징과 단어 레벨 특징에 따라 비디오 처리 모델의 국소적 손실을 얻을 수 있다. 마지막으로, 전역적 손실과 국소적 손실의 가중 합을 전체 손실로 하여 비디오 처리 모델을 트레이닝한다. 또는, 전역적 손실에 따라 전체 비디오 처리 모델을 트레이닝하고, 국 소적 손실에 따라 국소적 특징 추출 네트워크를 트레이닝할 수 있다. 일 실시예에 의하면, 하나의 샘플 데이터에 대해, 단어 레벨 특징 중의 각 단어 특징에 대해, 상기 각 단어 특 징과 샘플 비디오의 국소적 특징 사이의 제1 유사도를 확정할 수 있다. 복수의 단어 특징에 대해, 복수의 제1 유사도를 얻을 수 있다. 본 실시예에서는, 상기 복수의 제1 유사도에 따라 비디오 처리 모델의 국소적 손실 을 확정하고, 비디오 처리 모델을 트레이닝할 수 있다. 예를 들어, 본 실시예에서는, 복수의 제1 유사도의 평균 값 또는 복수의 제1 유사도 중 가장 높은 유사도를 단어 레벨 특징과 국소적 특징 사이의 예측 유사도로 할 수 있다. 하나의 샘플 데이터의 국소적 손실에 대해, 앞에서 설명한 교차 엔트로피 손실 함수 등을 이용할 수 있다. 본 실시예에서는, 배치 데이터 중 모든 데이터에 대한 국소적 손실의 합을 비디오 처리 모델의 국소적 손실로 할 수 있다. 일 실시예에 의하면, 비디오 처리 모델을 트레이닝하는 과정에 네거티브 샘플을 러닝함으로써 모델의 수렴 효율 을 향상시킬 수 있다. 이렇게 되면, 본 실시예에서는, 네거티브 샘플 중 샘플 텍스트의 각 단어 특징에 대해, 상기 각 단어 특징과 네거티브 샘플 중 샘플 비디오의 국소적 특징 사이의 유사도를 계산할 수 있고, 상기 유사 도에 따라 네거티브 샘플에 대한 국소적 손실을 확정할 수 있다. 일 실시예에 의하면, 임의의 샘플 텍스트에 대해, 배치 샘플 데이터에서 샘플 텍스트에 상기 임의의 샘플 텍스 트를 단어 분리하여 얻은 임의의 단어를 포함하지 않는 샘플 데이터를 상기 임의의 샘플 텍스트의 목표 샘플 데 이터로 하고, 상기 임의의 샘플 텍스트와 목표 샘플 데이터 중의 샘플 비디오로 하나의 네거티브 샘플을 구성할 수 있다. 이는, 어느 샘플 데이터의 샘플 텍스트에 상기 임의의 샘플 텍스트와 동일한 단어가 포함되는 경우, 상기 어느 샘플 데이터 중 샘플 비디오의 국소적 특징에는 상기 임의의 샘플 텍스트의 어느 단어 특징에 매칭되 는 부분 특징이 존재할 수 있기 때문이다. 이러한 방식으로 네거티브 샘플를 구축하면, 네거티브 샘플의 참고 가치를 향상시킬 수 있어, 비디오 처리 모델의 수렴 속도를 향상시키기 쉽다. 구체적으로, 본 실시예에서는, 복수의 단어 특징 중의 각 단어 특징에 대해, 상기 각 단어 특징과 목표 샘플 데 이터 중 샘플 비디오의 국소적 특징 사이의 제2 유사도를 확정하여, 복수의 단어 특징에 각각 대응하는 복수의 제2 유사도를 얻을 수 있다. 이어서, 앞에서 얻은 복수의 제1 유사도와 상기 복수의 제2 유사도에 따라, 비디오 처리 모델의 국소적 손실을 확정한다. 마지막으로, 상기 국소적 손실에 따라 비디오 처리 모델을 트레이닝한다. 일 실시예에 의하면, 복수의 단어 특징을 얻은 후, 상기 복수의 단어 특징으로부터 엔티티 워드에 대응하는 특 징을 선택해낼 수도 있다. 이는, 엔티티 워드 이외의 다른 단어들은 일반적으로 비디오의 국소적 이미지에 대응 할 수 없기 때문이다. 일 실시예에 의하면, 텍스트 tj에 대해, 추출하여 얻은 단어 특징은 예를 들어 시퀸스 로 나타낼수 있고, 여기서, Nj는 텍스트 tj에 포함된 엔티티 워드의 개수이다. 본 실시예에서는, 샘플 비디오의 국소적 특징을 변환하여 특징 시퀸스 로 나타낼 수 있다. 본 실시예에 의하면, 국소적 손실은 예를 들어 하기 수식을 통해 계산할 수 있다."}
{"patent_id": "10-2022-0178582", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "여기서,"}
{"patent_id": "10-2022-0178582", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 7, "content": "이다. 여기서, Neg(n, j）는 앞에서 설명한 임의의 샘플 텍스트와 상기 임의의 샘플 텍스트에 대한 목표 샘플 데이터 중의 샘플 비디오로 구성된 네거티브 샘플을 나타낸다. 본 개시에 의해 제공되는 비디오 처리 방법에 기초하여, 본 개시는 비디오 처리 장치를 더 제공한다. 이하, 도 9를 참조하여 비디오 처리 장치에 대해 상세하게 설명하기로 한다. 도 9는 본 개시의 실시예에 따른 비디오 처리 장치의 구성 블록도이다. 도 9에 도시된 바와 같이, 본 실시예에 따른 비디오 처리 장치는 비디오 특징 추출모듈, 국소적 특징 추출모듈, 전역적 특징 확정모듈 및 특징 융합모듈을 포함한다. 비디오 특징 추출모듈은 처리하고자 하는 비디오에 대해 복수의 수용야에서의 복수의 비디오 특징을 추출 한다. 일 실시예에 의하면, 비디오 특징 추출모듈은 앞에서 설명한 동작 S210을 실행할 수 있는데, 여기서 는 설명을 생략한다. 국소적 특징 추출모듈은 복수의 수용야 중 목표 수용야에서의 비디오 특징에 따라, 처리하고자 하는 비디 오의 국소적 특징을 추출한다. 일 실시예에 의하면, 국소적 특징 추출모듈은 앞에서 설명한 동작 S220을 실행할 수 있는데, 여기서는 설명을 생략한다. 전역적 특징 확정모듈은 복수의 수용야 중 최대 수용야에서의 비디오 특징에 따라, 처리하고자 하는 비디 오의 전역적 특징을 얻는다. 일 실시예에 의하면, 전역적 특징 확정모듈은 앞에서 설명한 동작 S230을 실 행할 수 있는데, 여기서는 설명을 생략한다. 특징 융합모듈은 국소적 특징과 상기 전역적 특징을 융합하여, 상기 처리하고자 하는 비디오의 목표 특징 을 얻는다. 일 실시예에 의하면, 특징 융합모듈은 앞에서 설명한 동작 S240을 실행할 수 있는데, 여기서는 설명을 생략한다. 본 개시의 실시예에 의하면, 국소적 특징 추출모듈은 특징 캡처 서브모듈, 특징 처리 서브모듈 및 국소적 특징 취득 서브모듈을 포함할 수 있다. 특징 캡처 서브모듈은 소정의 크기의 슬라이딩 윈도우에 따라 목표 수용 야에서의 비디오 특징을 캡처하여, 복수의 비디오 서브 특징을 얻는다. 특징 처리 서브모듈은 복수의 비디오 서 브 특징 중 각 서브 특징에 대해, 주의력 알고리즘을 이용하여 각 서브 특징을 처리하여 처리된 서브 특징을 얻 는다. 국소적 특징 취득 서브모듈은 복수의 비디오 서브 특징에 대해 얻은 복수의 처리된 서브 특징에 따라, 처 리하고자 하는 비디오의 국소적 특징을 얻는다. 본 개시의 실시예에 의하면, 국소적 특징 취득 서브모듈은 융합유닛, 가중치 추출유닛 및 가중치 부여유닛을 포 함할 수 있다. 융합유닛은 복수의 처리된 서브 특징을 융합하여 융합된 특징을 얻는다. 가중치 추출유닛은 3차 원 컨볼루션을 이용하여 융합된 특징의 가중치 특징을 추출한다. 가중치 부여유닛은 가중치 특징에 따라 융합된 특징에 대해 가중치를 부여하여, 국소적 특징을 얻는다. 본 개시의 실시예에 의하면, 상기 특징 캡처 서브모듈은, 공간 차원의 제1 소정 스텝과 시간 차원의 제2 소정 스텝에 따라 슬라이딩 윈도우를 이동하여, 복수의 비디오 서브 특징을 캡처한다. 여기서, 제1 소정 스텝은 슬라 이딩 윈도우의 공간 차원에서의 길이보다 작고, 제2 소정 스텝은 슬라이딩 원도우의 시간 차원에서의 길이보다 작다.본 개시의 실시예에 의하면, 상기 특징 융합모듈은 교차 주의력 알고리즘을 이용하여 국소적 특징과 전역 적 특징을 융합하여, 목표 특징을 얻는다. 본 개시의 실시예에 의하면, 상기 특징 융합모듈은 제1 취득 서브모듈, 제2 취득 서브모듈 및 주의력 서브 모듈을 포함할 수 있다. 제1 취득 서브모듈은 전역적 특징에 따라, 조회 특징을 취득한다. 제2 취득 서브모듈은 국소적 특징에 따라, 키 특징 및 값 특징을 취득한다. 주의력 서브모듈은 조회 특징, 키 특징 및 값 특징에 따 라, 교차 주의력 알고리즘을 이용하여 목표 특징을 얻는다. 본 개시에 의해 제공되는 비디오 조회 방법에 기초하여, 본 개시는 비디오 조회 장치를 더 제공한다. 이하, 도 10을 참조하여 비디오 조회 장치에 대해 상세하게 설명하기로 한다. 도 10은 본 개시의 실시예에 따른 비디오 조회 장치의 구성 블록도이다. 도 10에 도시된 바와 같이, 본 실시예에 따른 비디오 조회 장치는 텍스트 특징 추출모듈, 목표 특 징 취득모듈 및 비디오 확정모듈을 포함할 수 있다. 텍스트 특징 추출모듈은 조회 텍스트의 텍스트 특징을 추출한다. 일부 실시예에 의하면, 텍스트 특징 추 출모듈은 앞에서 설명한 동작 S610을 실행할 수 있는데, 여기서는 설명을 생략한다. 목표 특징 취득모듈은 복수의 후보 비디오 중 각 비디오의 목표 특징을 취득한다. 여기서, 목표 특징은 본 개시에 의해 제공되는 비디오 처리 장치를 이용하여 취득한 것이다. 일부 실시예에 의하면, 목표 특징 취득 모듈은 앞에서 설명한 동작 S620을 실행할 수 있는데, 여기서는 설명을 생략한다. 비디오 확정모듈은 텍스트 특징과 목표 특징에 따라, 복수의 후보 비디오에서 조회 텍스트에 매칭되는 비 디오를 확정한다. 일 실시예에 의하면, 비디오 확정모듈은 앞에서 설명한 동작 S630을 실행할 수 있는데, 여기서는 설명을 생략한다. 본 개시에 의해 제공되는 비디오 처리 모델의 트레이닝 방법에 기초하여, 본 개시는 비디오 처리 모델의 트레이 닝 장치를 더 제공한다. 이하, 도 11을 참조하여 비디오 처리 모델의 트레이닝 장치에 대해 상세하게 설명하기 로 한다. 도 11은 본 개시의 실시예에 따른 비디오 처리 모델의 트레이닝 장치의 구성 블록도이다. 도 11에 도시된 바와 같이, 본 실시예에 따른 비디오 처리 모델의 트레이닝 장치는 비디오 특징 추출모듈 , 국소적 특징 추출모듈, 전역적 특징 확정모듈, 특징 융합모듈, 텍스트 특징 취득모 듈 및 제1 트레이닝모듈을 포함할 수 있다. 여기서, 비디오 처리 모델은 비디오 특징 추출 네트워 크, 국소적 특징 추출 네트워크 및 특징 융합 네트워크를 포함한다. 비디오 특징 추출모듈은 샘플 데이터에 포함된 샘플 비디오를 비디오 특징 추출 네트워크에 입력하여, 복 수의 수용야에서의 복수의 비디오 특징을 얻는다. 일 실시예에 의하면, 비디오 특징 추출모듈은 앞에서 설명한 동작 S710을 실행할 수 있는데, 여기서는 설명을 생략한다. 국소적 특징 추출모듈은 복수의 수용야 중 목표 수용야에서의 비디오 특징을 국소적 특징 추출 네트워크 에 입력하여, 샘플 비디오의 국소적 특징을 얻는다. 일 실시예에 의하면, 국소적 특징 추출모듈은 앞에서 설명한 동작 S720을 실행할 수 있는데, 여기서는 설명을 생략한다. 전역적 특징 확정모듈은, 복수의 수용야 중 최대 수용야에서의 비디오 특징에 따라, 샘플 비디오의 전역 적 특징을 얻는다. 일 실시예에 의하면, 전역적 특징 확정모듈은 앞에서 설명한 동작 S730을 실행할 수 있는데, 여기서는 설명을 생략한다. 특징 융합모듈은 국소적 특징 및 전역적 특징을 특징 융합 네트워크에 입력하여, 샘플 비디오의 목표 특 징을 얻는다. 일 실시예에 의하면, 특징 융합모듈은 앞에서 설명한 동작 S740을 실행할 수 있는데, 여기 서는 설명을 생략한다. 텍스트 특징 취득모듈은 샘플 데이터 중의 샘플 텍스트의 텍스트 특징을 취득한다. 일 실시예에 의하면, 텍스트 특징 취득모듈은 앞에서 설명한 동작 S750을 실행할 수 있는데, 여기서는 설명을 생략한다. 제1 트레이닝모듈은 목표 특징과 텍스트 특징에 따라 비디오 처리 모델을 트레이닝한다. 일 실시예에 의 하면, 제1 트레이닝모듈은 앞에서 설명한 동작 S760을 실행할 수 있는데, 여기서는 설명을 생략한다.본 개시의 실시예에 의하면, 텍스트 특징은 샘플 텍스트의 문장 레벨 특징을 포함한다. 상기 제1 트레이닝모듈 은 목표 특징과 문장 레벨 특징 사이의 유사도에 따라, 비디오 처리 모델을 트레이닝할 수 있다. 본 개시의 실시예에 의하면, 텍스트 특징은 샘플 텍스트의 단어 레벨 특징을 더 포함한다. 상기 비디오 처리 모 델의 트레이닝 장치는 국소적 특징과 단어 레벨 특징에 따라, 비디오 처리 모델을 트레이닝하기 위한 제2 트레이닝모듈을 더 포함할 수 있다. 본 개시의 실시예에 의하면, 단어 레벨 특징은 샘플 텍스트에 포함된 복수의 엔티티 워드에 각각 대응하는 복수 의 단어 특징을 포함한다. 상기 제2 트레이닝모듈은 제1 확정 서브모듈 및 트레이닝 서브모듈을 포함할 수 있다. 제1 확정 서브모듈은 복수의 단어 특징 중 각 단어 특징과 국소적 특징 사이의 유사도를 확정하여 복수의 제1 유사도를 얻는다. 트레이닝 서브모듈은 복수의 제1 유사도에 따라, 비디오 처리 모델을 트레이닝한다. 본 개시의 실시예에 의하면, 상기 제2 트레이닝모듈은 각 단어 특징에 대해, 각 단어 특징과 목표 샘플 데이터 중 샘플 비디오의 국소적 특징 사이의 유사도를 확정하여, 복수의 단어 특징에 각각 대응하는 복수의 제2 유사 도를 얻기 위한 제2 확정 서브모듈을 더 포함할 수 있다. 상기 트레이닝 서브모듈은 손실 확정유닛 및 트레이닝 유닛을 포함할 수 있다. 손실 확정유닛은 복수의 제1 유사도 및 복수의 제2 유사도에 따라, 비디오 처리 모델의 손실을 확정한다. 트레이닝유닛은 손실에 따라, 비디오 처리 모델을 트레이닝한다. 여기서, 목표 샘플 데이터에 서의 샘플 텍스트에는 복수의 단어 특징에 대응하는 단어를 포함하지 않는다. 지적해두어야 할 것은, 본 개시의 기술방안에서 언급한 사용자 개인 정보의 수집, 저장, 사용, 가공, 전송, 제 공, 공개 및 응용 등은 모두 관련 법률과 법규의 규정에 부합되고, 필요한 보안조치를 취하였으며, 공중도덕에 위배되지 않는다. 본 개시의 기술방안에 있어서, 사용자의 개인 정보를 취득하거나 수집하기 전에 모두 사용자 의 승인 또는 동의를 취득하였다. 본 개시의 실시예에 의하면, 본 개시는 전자장비, 컴퓨터 판독가능 저장 매체 및 컴퓨터 프로그램을 더 제공한 다. 도 12는 본 개시의 실시예 중 어느 한 방법을 실시할 수 있는 예시적인 전자장비의 개략적인 블록도를 나 타낸다. 전자장비는 예를 들어, 랩탑 컴퓨터, 데스크 탑 컴퓨터, 워크스테이션, PDA (Personal Digital Assistants), 서버, 블레이드 서버, 메인프레임 컴퓨터, 및 기타 적절한 컴퓨터와 같은 다양한 형태의 디지털 컴퓨터를 포함할 수 있다. 전자장비는 예를 들어, PDA (Personal Digital Assistants), 셀룰러 전화기, 스마트 폰, 웨어러블 장비, 및 기타 유사한 계산 장비와 같은 다양한 형태의 모바일 장비를 포함할 수 있다. 본 명세서 에 기재된 부품, 이들의 연결 및 관계, 그리고 이들의 기능은 단지 예시적인 것에 불과하며, 본 명세서에서 설 명 및/또는 요구하는 본 개시의 범위를 한정하는 것이 아니다. 도 12에 도시된 바와 같이, 전자장비는ROM(Read Only Memory)에 저장된 컴퓨터 프로그램 또는 저 장수단으로부터 RAM(Random Access Memory)에 로딩된 컴퓨터 프로그램에 따라 각종 적당한 동작 및 처리를 실행할 수 있는 계산수단을 포함한다. 또한, RAM에는 전자장비의 동작에 필요한 다양한 프로그램 및 데이터가 더 저장될 수 있다. 계산수단, ROM 및 RAM은 버스라인를 통해 서로 연결된다. 입력/출력(I/O) 인터페이스도 버스라인에 연결된다. 전자장비중의 복수의 부품은 I/O 인터페이스에 연결되고, 상기 부품에는, 예를 들어 키보드, 마우 스 등과 같은 입력수단, 예를 들어 각종 유형의 디스플레이, 스피커 등과 같은 출력수단, 예를 들 어 자기 디스크, 광 디스크 등과 같은 저장수단, 및 예를 들어 네트워크 카드, 모뎀, 무선 통신 송수신기 등과 같은 통신수단이 포함된다. 통신수단에 의해, 전자장비는 인터넷과 같은 컴퓨터 네트워 크 및/또는 각종 전자통신망을 통해 다른 장비와 정보/데이터를 교환할 수 있다. 계산수단은 처리 기능 및 계산 기능을 가진 각종 범용 및/또는 주문형 처리 어셈블리일 수 있다. 계산수 단의 일부 실시예로서는, 중앙 처리 장치(CPU), 그래픽 처리 장치(GPU), 각종 주문형 인공지능(AI) 컴퓨 팅 칩, 각종 머신 러닝 모델 알고리즘을 운행하는 계산수단, 디지털 신호 프로세서(DSP), 및 임의의 적합한 프 로세서, 컨트롤러, 마이크로 컨트롤러 등이 포함될 수 있는데, 이에 한정되지는 않는다. 계산수단은 앞에 서 설명한 각 방법 및 처리를 실행하는데, 예를 들어 비디오 처리 방법, 비디오 조회 방법 및 비디오 처리 모델 의 트레이닝 방법 중 적어도 하나를 실행한다. 예를 들어, 일부 실시예에 의하면, 비디오 처리 방법, 비디오 조 회 방법 및 비디오 처리 모델의 트레이닝 방법 중 적어도 하나는 예를 들어 저장수단과 같은 기계 판독가 능 매체에 포함되는 컴퓨터 소프트웨어 프로그램의 형태로 실현될 수 있다. 일부 실시예에 의하면, 컴퓨터 프로 그램의 일부 또는 전부는 ROM 및/또는 통신수단을 거쳐 전자장비에 로딩 및/또는 설치될 수있다. 컴퓨터 프로그램이 RAM에 로딩되고 계산수단에 의해 실행될 경우, 앞에서 설명한 비디오 처 리 방법, 비디오 조회 방법 및 비디오 처리 모델의 트레이닝 방법 중 적어도 하나의 하나 또는 복수의 단계를 실행할 수 있다. 선택적으로, 다른 실시예에 의하면, 계산수단은 다른 임의의 적합한 방식(예를 들어, 펌 웨어)을 통해 비디오 처리 방법, 비디오 조회 방법 및 비디오 처리 모델의 트레이닝 방법 중 적어도 하나를 실 행하도록 구성될 수 있다. 상기에서 설명한 시스템 및 기술의 다양한 실시 형태는 디지털 전자 회로 시스템, 집적 회로 시스템, FPGA(Field Programmable Gate Array), ASIC(Application Specific Integrated circuit), ASSP(Application Specific Standard Product), SOC(System on Chip), CPLD(Complex Programmable Logic Device), 컴퓨터 하드 웨어, 펌웨어, 소프트웨어, 및/또는 이들의 조합으로 구현될 수 있다. 이러한 다양한 실시형태는 하나 또는 복 수의 컴퓨터 프로그램을 통해 구현될 수 있고, 상기 하나 또는 복수의 컴퓨터 프로그램은 적어도 하나의 프로그 램 가능 프로세서를 포함하는 프로그램 가능 시스템에서 실행 및/또는 해석될 수 있으며, 상기 프로그램 가능 프로세서는 주문형 또는 범용 프로그램 가능 프로세서일 수 있고, 저장 시스템, 적어도 하나의 입력장치, 및 적 어도 하나의 출력장치로부터 데이터 및 명령을 수신하고, 데이터 및 명령을 저장 시스템, 적어도 하나의 입력장 치, 및 적어도 하나의 출력장치로 전송할 수 있다. 본 개시의 방법을 실시하는 프로그램 코드는 하나 또는 복수의 프로그래밍 언어의 임의의 조합을 통해 프로그래 밍을 실행할 수 있다. 이러한 프로그램 코드는 범용 컴퓨터, 주문형 컴퓨터 또는 다른 프로그래밍 가능한 데이 터 처리 장치의 프로세서 또는 컨트롤러에 제공되어, 프로그램 코드가 프로세서 또는 컨트롤러에 의해 실행됨으 로써, 흐름도 및/또는 블록도에서 규정한 기능/동작을 실시하도록 할 수 있다. 프로그램 코드는 전부 머신에 의 해 실행되거나 부분적으로 머신에 의해 실행될 수 있고, 또는 독립적인 소프트웨어 패키지로서 부분적으로 머신 에 의해 실행됨과 동시에 부분적으로 원격 머신에 의해 실행되거나, 또는 전부 원격 머신 또는 서버에 의해 실 행될 수 있다. 본 명세서에 있어서, 기계 판독가능 매체는 실체적인 매체일 수 있고, 상기 매체에는 명령 실행 시스템, 장치 또는 장비에 의해 사용되거나 r명령 실행 시스템, 장치 또는 장비와 결합하여 사용되는 프로그램이 포함되거나 저장될 수 있다. 기계 판독가능 매체는 기계 판독가능 신호 매체 또는 기계 판독가능 저장매체일 수 있다. 기계 판독가능 신호 매체는, 전자적, 자기적, 광학적, 전자기적, 적외선적 반도체 시스템, 장치 또는 장비, 또는 이 들의 임의의 적합한 조합을 포함할 수 있는데, 이에 한정되지는 않는다. 기계 판독가능 저장매체의 보다 구체적 인 실시예로는, 하나 또는 복수의 라인에 의해 전기적으로 연결되는 휴대용 컴퓨터 디스크, 하드 디스크, RAM, ROM, EPROM(Erasable Programming ROM), 플래시 메모리, 광 파이버, CD-ROM, 광학적 저장 장비, 자기적 저장 장비, 또는 이들의 임의의 적합한 조합일 수 있다. 사용자와의 인터랙션을 제공하기 위해서는, 컴퓨터를 통해 본 명세서에서 설명한 시스템 및 기술을 구현할 수 있는데, 상기 컴퓨터는, 사용자에게 정보를 표시하는 표시 장치(예를 들어, CRT(음극선관) 또는 LCD(액정 디스 플레이) 모니터), 및 사용자가 상기 컴퓨터에 입력을 제공할 수 있는 키보드 및 포인팅 디바이스(예를 들어, 마 우스 또는 트랙 볼)를 포함한다. 기타 유형의 디바이스도 사용자와의 인터랙션을 제공하는데 사용될 수 있다. 예를 들어, 사용자에게 제공되는 피드백은 임의의 형태의 센싱 피드백(예를 들어, 시각 피드백, 청각 피드백, 또는 촉각 피드백)일 수 있고, 임의의 형태(소리 입력, 음성 입력, 또는 촉각 입력을 포함)로 사용자로부터의 입력을 수신할 수 있다. 본 명세서에서 설명한 시스템 및 기술은, 백 그라운더 부품을 포함하는 컴퓨팅 시스템(예를 들어, 데이터 서 버), 또는 미들웨어 부품을 포함하는 컴퓨팅 시스템(예를 들어, 애플리케이션 서버), 또는 프론트 앤드 부품을 포함하는 컴퓨팅 시스템(예를 들어, GUI 또는 웹 브라우저를 갖는 사용자 컴퓨터로서, 사용자는 상기 GUI 또는 상기 웹 브라우저를 통하여 본 명세서에서 설명한 상기 시스템 및 기술의 실시 형태와 인터랙션을 할 수 있음), 또는 이러한 백 그라운더 부품, 미들웨어 부품, 또는 프론트 앤드 부품의 임의의 조합을 포함하는 컴퓨팅 시스 템에서 구현될 수 있다. 시스템의 부품은 임의의 형태 또는 매체의 디지털 데이터 통신(예를 들어, 통신 네트워 크)을 통해 서로 연결될 수 있다. 통신 네트워크는 예를 들어 근거리 통신망(LAN), 광역 통신망(WAN) 및 인터넷 을 포함할 수 있다. 컴퓨터 시스템은 클라이언트 및 서버를 포함할 수 있다. 클라이언트 및 서버는 일반적으로 서로 멀리 떨어져 있 고, 통상적으로 통신 네트워크를 통해 인터랙션을 진행한다. 클라이언트와 서버의 관계는 대응하는 컴퓨터에서 실행되고 서로 클라이언트-서버의 관계를 갖는 컴퓨터 프로그램에 의해 생성된다. 여기서, 서버는 클라우드 서 버일 수도 있는데, 클라우드 컴퓨팅 서버 또는 클라우드 호스트라고도 하며, 클라우드 컴퓨팅 서비스 체계에 속하는 호스트 제품으로서, 기존의 물리적 호스트 및 VPS(\"Virtual Private Server\", VPS라고도 함) 서비스에 존 재하는 관리 난이도가 높고, 업무 확정성이 약한 문제점을 극복하기 위한 것이다. 서버는 분포식 시스템의 서버 또는 블록체인과 결합된 서버일 수도 있다. 상기에서 설명한 다양한 프로세스를 사용하여 각 단계의 순서를 조정하거나, 일부 단계를 추가 또는 삭제 할 수 있다는 점을 이해하여야 한다. 예를 들어, 본 개시에 개시된 기술방안이 원하는 결과를 구현할 수 있는 한, 본 개시에 기재된 다양한 단계는 병렬적으로 또는 순차적으로, 또는 서로 다른 순서로 실행될 수 있고, 본 개시는 이에 대해 특별히 한정하지 않는다. 본 개시의 보호범위는 상기 다양한 실시 형태에 의해 제한되지 않는다. 당업자라면, 설계 요구 및 기타 요소에 의해, 다양한 수정, 조합, 서브 조합 및 교체가 이루어질 수 있음을 이해할 것이다. 본 개시의 취지 및 원칙내 에서 이루어진 임의의 수정, 등가 교체 및 개선 등은 모두 본 개시의 보호범위에 속한다."}
{"patent_id": "10-2022-0178582", "section": "도면", "subsection": "도면설명", "item": 1, "content": "첨부 도면은 본 기술방안을 보다 쉽게 이해하도록 하기 위한 것이고, 본 개시는 이에 한정되지 않는다. 도 1은 본 개시의 실시예에 따른 비디오 처리 방법 및 장치, 비디오 조회 방법 및 장치, 그리고 비디오 처리 모 델의 트레이닝 방법 및 장치의 응용장면의 개략도이다. 도 2는 본 개시의 실시예에 따른 비디오 처리 방법의 개략적인 흐름도이다. 도 3은 본 개시의 실시예에 따른 비디오 처리 방법의 개략적인 원리도이다. 도 4는 본 개시의 실시예에 따른 처리하고자 하는 비디오의 국소적 특징을 추출하는 개략적인 원리도이다. 도 5는 본 개시의 실시예에 따른 전역적 특징과 국소적 특징을 융합하는 개략적인 원리도이다. 도 6은 본 개시의 실시예에 따른 비디오 조회 방법의 개략적인 흐름도이다. 도 7은 본 개시의 실시예에 따른 비디오 처리 모델의 트레이닝 방법의 개략적인 흐름도이다. 도 8은 본 개시의 실시예에 따른 비디오 처리 모델의 트레이닝 방법의 개략적인 원리도이다. 도 9는 본 개시의 실시예에 따른 비디오 처리 장치의 구성 블록도이다. 도 10은 본 개시의 실시예에 따른 비디오 조회 장치의 구성 블록도이다. 도 11은 본 개시의 실시예에 따른 비디오 처리 모델의 트레이닝 장치의 구성 블록도이다. 도 12는 본 개시의 실시예 중 어느 한 방법을 실시하기 위한 전자장비의 블록도이다."}
