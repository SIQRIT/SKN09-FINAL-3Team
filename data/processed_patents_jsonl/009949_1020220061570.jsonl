{"patent_id": "10-2022-0061570", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0161782", "출원번호": "10-2022-0061570", "발명의 명칭": "이동 로봇 및 이동 로봇의 제어방법", "출원인": "엘지전자 주식회사", "발명자": "이헌철"}}
{"patent_id": "10-2022-0061570", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "본체;상기 본체를 이동시키는 주행부;상기 본체 외부의 지형 정보를 획득하는 센싱부; 및상기 센싱부에서 획득한 지형 정보를 통해 상기 본체의 현재 위치가 주행 영역의 코너인지 판단하고, 상기 본체가 상기 코너에 위치된 경우, 상기 코너에서 상기 센싱부를 통해 상기 코너 주변의 지형 정보를 획득하는 코너주변정보 획득 모션을 하도록 제어하는 제어부를 포함하는 이동 로봇."}
{"patent_id": "10-2022-0061570", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 코너 주변정보 획득 모션은,상기 본체가 상기 코너에서 회전하면서 상기 센싱부를 통해 외부의 지형 정보를 획득하는 이동 로봇."}
{"patent_id": "10-2022-0061570", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 코너 주변정보 획득 모션은,상기 본체가 상기 코너에서 제1 방향으로 회전한 후 상기 제1 방향과 반대 방향인 제2 방향으로 회전하면서 상기 센싱부를 통해 외부의 지형 정보를 획득하는 이동 로봇."}
{"patent_id": "10-2022-0061570", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서,상기 제1 방향 및 상기 제2 방향은 상기 본체의 진행 방향과 직교하는 이동 로봇."}
{"patent_id": "10-2022-0061570", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제3항에 있어서,상기 제2 방향은 상기 본체가 코너를 통과한 후 진행방향과 일치되는 이동 로봇."}
{"patent_id": "10-2022-0061570", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서,상기 센싱부는 상기 본체의 진행 방향을 기준으로 일정 각도 내의 지형 정보를 획득하는 레이저 센서를 포함하는 이동 로봇."}
{"patent_id": "10-2022-0061570", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6항에 있어서,상기 코너 주변정보 획득 모션은,상기 코너에서 일정 거리 이내 및 일정 각도 이내의 벽의 특징점 들과의 거리를 추출하여 상기 지형 정보를 획득하는 이동 로봇."}
{"patent_id": "10-2022-0061570", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "공개특허 10-2023-0161782-3-제7항에 있어서,상기 제어부는, 상기 벽의 특징점 들과의 거리를 바탕으로 상기 벽의 기울기를 추정하고, 상기 벽의 기울기를 맵에 업데이트하는 이동 로봇."}
{"patent_id": "10-2022-0061570", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제7항에 있어서,상기 제어부는, 상기 벽의 특징점 들과의 거리를 바탕으로 상기 본체의 현재 위치를 추정하는 이동 로봇."}
{"patent_id": "10-2022-0061570", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9항에 있어서,상기 제어부는, 상기 벽의 특징점 들과의 거리를 바탕으로 상기 벽의 기울기를 추정하고, 상기 벽의 기울기를 바탕으로 상기 본체의 헤딩 방향을 결정하는 이동 로봇."}
{"patent_id": "10-2022-0061570", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제1항에 있어서,상기 제어부는, 상기 코너 주변정보 획득 모션에서 획득한 상기 코너 주변 지형 정보를 기반으로 상기 본체의 현재 위치를 추정하는 이동 로봇."}
{"patent_id": "10-2022-0061570", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제1항에 있어서,데이터를 저장하는 저장부를 더 포함하고,상기 제어부는,상기 코너 주변정보 획득 모션에서 획득한 상기 코너 주변 지형 정보를 기반으로 맵을 업데이트하는 이동 로봇."}
{"patent_id": "10-2022-0061570", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제1항에 있어서,데이터를 저장하는 저장부를 더 포함하고,상기 제어부는,상기 코너 주변정보 획득 모션에서 획득한 복수의 코너 주변 지형 정보와 복수의 코너의 위치 정보를 기반으로맵을 생성하는 이동 로봇."}
{"patent_id": "10-2022-0061570", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제13항에 있어서,상기 제어부는,상기 코너 주변정보 획득 모션에서 획득한 상기 코너 주변 지형 정보를 기반으로 상기 본체의 현재 위치를 추정하는 이동 로봇."}
{"patent_id": "10-2022-0061570", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제1항에 있어서,공개특허 10-2023-0161782-4-상기 제어부는,상기 코너 주변정보 획득 모션을 상기 본체의 월 팔로잉 주행 중에 실행하는 이동 로봇."}
{"patent_id": "10-2022-0061570", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "센싱부가 주변 지형 정보를 획득하는 지형 정보 획득 단계;상기 본체의 현재 위치가 주행 영역의 코너인지 판단하는 코너 판단 단계; 및상기 본체의 현재 위치가 상기 코너인 경우, 상기 코너에서 상기 코너 주변의 지형 정보를 획득하는 코너 주변지형 정보 획득단계를 포함하는 이동 로봇의 제어방법."}
{"patent_id": "10-2022-0061570", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제16항에 있어서,상기 코너 주변 지형 정보 획득단계는,상기 본체가 상기 코너에서 회전하면서 상기 센싱부를 통해 외부의 지형 정보를 획득하는 이동 로봇의제어방법."}
{"patent_id": "10-2022-0061570", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제16항에 있어서,상기 코너 주변 지형 정보를 기반으로 상기 본체의 현재 위치를 추정하는 현재 위치 추정단계를 더 포함하는 이동 로봇의 제어방법."}
{"patent_id": "10-2022-0061570", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제16항에 있어서,상기 코너 주변 지형 정보를 기반으로 맵을 업데이트하는 지도 업데이트 단계를 더 포함하는 이동 로봇의 제어방법."}
{"patent_id": "10-2022-0061570", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제16항에 있어서,상기 코너 주변 지형 정보 획득단계는,상기 코너에서 일정 거리 이내 및 일정 각도 이내의 벽의 특징점 들과의 거리를 추출하는 이동 로봇의제어방법."}
{"patent_id": "10-2022-0061570", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 본체, 상기 본체를 이동시키는 주행부, 상기 본체 외부의 지형 정보를 획득하는 센싱부 및 상기 센싱 부에서 획득한 지형 정보를 통해 상기 본체의 현재 위치가 주행 영역의 코너인지 판단하고, 상기 본체가 상기 코 너에 위치된 경우, 상기 코너에서 상기 센싱부를 통해 상기 코너 주변의 지형 정보를 획득하는 코너 주변정보 획 득 모션을 하도록 제어하는 제어부를 포함하는 것을 특징으로 한다."}
{"patent_id": "10-2022-0061570", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은, 로봇 청소기 및 로봇 청소기의 제어방법에 관한 것으로, 보다 자세하게는 슬램 주행 기술에 관한 것 이다."}
{"patent_id": "10-2022-0061570", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "로봇은 산업용으로 개발되어 공장 자동화의 일 부분을 담당하여 왔다. 최근에는 로봇을 응용한 분야가 더욱 확대되어, 의료용 로봇, 우주 항공 로봇 등이 개발되고, 일반 가정에서 사 용할 수 있는 가정용 로봇도 만들어지고 있다. 이러한 로봇 중에서 자력으로 주행이 가능한 것을 이동 로봇이라 고 한다. 가정에서 사용되는 이동 로봇의 대표적인 예는 로봇 청소기이다.로봇 청소기에 구비된 여러 센서를 통하여 로봇 청소기 주변의 환경 및 사용자를 감지하는 여러 기술들이 알려 져 있다. 또한, 로봇 청소기가 스스로 청소 구역을 학습하여 맵핑하고, 맵 상에서 현재 위치를 파악하는 기술들 이 알려져 있다. 청소 구역을 기설정된 방식으로 주행하며 청소하는 로봇 청소기가 알려져 있다. 또한, 종래 기술(한국특허공개번호 10-2008-0090925)에는, 청소하고자 하는 구역을 스스로 주행하면서 구역의 외곽을 주행하는 벽면을 따라 지그재그로 패턴 주행을 수행하는 기술이 개시되어 있다. 한편, 로봇 청소기가 맵핑을 수행할 때, 장애물이 있는 경우 장애물을 판단하여 장애물을 회피하여 주행하는 방 안이 요구되었다. 종래 기술(미국 등록 특허 US7211980B1)에서는 로봇이 목표 방향을 받아 정면에 장애물이 있는지 센싱하여, 정 면에 장애물이 있는 경우, 회전 방향, 회전속도, 전환 방향, 전환 속도 중 적어도 하나를 조정하여 가장 가까운 장애물을 회피하는 기술이 개시되어 있다. 그러나, 이러한 종래 기술의 경우, 인식된 장애물의 위치에 따라 단 순한 로직으로 이동하여 로봇이 인식하지 못한 장애물이나 방향성이 없는 장애물에 대하여는 대응이 어렵다. 또 한, 종래 기술의 경우, 장애물의 회피에 초점을 두어 장애물이 복잡한 경우, 효율적이지 못한 움직임을 보일 수 있는 문제가 있다. 선행기술문헌 특허문헌 (특허문헌 0001) 한국공개특허공보 공개번호 10-2008-0090925 (공개일자 : 2008년 10월 19일) (특허문헌 0002) 미국등록특허공보 등록번호 US7211980B1 (공개일자: 2007년 01년 05일)"}
{"patent_id": "10-2022-0061570", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명의 제1 과제는 이동 로봇에 센서의 개수를 줄이고, 레이저 기반의 센서만 사용하면서도, 정확한 슬램이 가능한 이동 로봇을 제공하는 것이다. 본 발명의 제2 과제는 맵이 없는 상황에서 로봇 청소기가 맵을 그리는 주행을 할 때 최소한의 센서로 정확한 맵 을 그리는데 있다. 본 발명의 제3 과제는 맵이 있는 상태에서, 이동 로봇의 현재 위치를 코너에서 정확하게 추정하여서, 이동 로봇 의 주행을 보정하는 데 있다. 본 발명의 제4 과제는 이동 로봇이 현재 위치를 추정하고, 맵을 생성하는 센싱 요소가 적고, 제어부의 제어부담 도 적은 이동 로봇을 제공하는 데 있다."}
{"patent_id": "10-2022-0061570", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명은 본체, 상기 본체를 이동시키는 주행부, 상기 본체 외부의 지형 정보를 획득하는 센싱부 및 상기 센싱 부에서 획득한 지형 정보를 통해 상기 본체의 현재 위치가 주행 영역의 코너인지 판단하고, 상기 본체가 상기 코너에 위치된 경우, 상기 코너에서 상기 센싱부를 통해 상기 코너 주변의 지형 정보를 획득하는 코너 주변정보 획득 모션을 하도록 제어하는 제어부를 포함하는 것을 특징으로 한다. 상기 코너 주변정보 획득 모션은, 상기 본체가 상기 코너에서 회전하면서 상기 센싱부를 통해 외부의 지형 정보 를 획득할 수 있다. 상기 코너 주변정보 획득 모션은, 상기 본체가 상기 코너에서 제1 방향으로 회전한 후 상기 제1 방향과 반대 방 향인 제2 방향으로 회전하면서 상기 센싱부를 통해 외부의 지형 정보를 획득할 수 있다. 상기 제1 방향 및 상기 제2 방향은 상기 본체의 진행 방향과 직교할 수 있다. 상기 제2 방향은 상기 본체가 코너를 통과한 후 진행방향과 일치될 수 있다. 상기 센싱부는 상기 본체의 진행 방향을 기준으로 일정 각도 내의 지형 정보를 획득하는 레이저 센서를 포함할 수 있다. 상기 코너 주변정보 획득 모션은, 상기 코너에서 일정 거리 이내 및 일정 각도 이내의 벽의 특징점 들과의 거리 를 추출하여 상기 지형 정보를 획득할 수 있다. 상기 제어부는, 상기 벽의 특징점 들과의 거리를 바탕으로 상기 벽의 기울기를 추정하고, 상기 벽의 기울기를 맵에 업데이트할 수 있다. 상기 제어부는, 상기 벽의 특징점 들과의 거리를 바탕으로 상기 본체의 현재 위치를 추정할 수 있다. 상기 제어부는, 상기 벽의 특징점 들과의 거리를 바탕으로 상기 벽의 기울기를 추정하고, 상기 벽의 기울기를 바탕으로 상기 본체의 헤딩 방향을 결정할 수 있다. 상기 제어부는, 상기 코너 주변정보 획득 모션에서 획득한 상기 코너 주변 지형 정보를 기반으로 상기 본체의 현재 위치를 추정할 수 있다. 또한, 본 발명은 데이터를 저장하는 저장부를 더 포함하고, 상기 제어부는, 상기 코너 주변정보 획득 모션에서 획득한 상기 코너 주변 지형 정보를 기반으로 맵을 업데이트할 수 있다. 상기 제어부는, 상기 코너 주변정보 획득 모션에서 획득한 복수의 코너 주변 지형 정보와 복수의 코너의 위치 정보를 기반으로 맵을 생성할 수 있다. 상기 제어부는, 상기 코너 주변정보 획득 모션에서 획득한 상기 코너 주변 지형 정보를 기반으로 상기 본체의 현재 위치를 추정할 수 있다. 상기 제어부는 상기 코너 주변정보 획득 모션을 상기 본체의 월 팔로잉 주행 중에 실행할 수 있다. 또한, 본 발명은 센싱부가 주변 지형 정보를 획득하는 지형 정보 획득 단계, 상기 본체의 현재 위치가 주행 영 역의 코너인지 판단하는 코너 판단 단계 및 상기 본체의 현재 위치가 상기 코너인 경우, 상기 코너에서 상기 코 너 주변의 지형 정보를 획득하는 코너 주변 지형 정보 획득단계를 포함할 수 있다. 상기 코너 주변 지형 정보 획득단계는, 상기 본체가 상기 코너에서 회전하면서 상기 센싱부를 통해 외부의 지형 정보를 획득할 수 있다. 또한, 본 발명은 상기 코너 주변 지형 정보를 기반으로 상기 본체의 현재 위치를 추정하는 현재 위치 추정단계 를 더 포함할 수 있다. 또한, 본 발명은 상기 코너 주변 지형 정보를 기반으로 맵을 업데이트하는 지도 업데이트 단계를 더 포함할 수 있다. 상기 코너 주변 지형 정보 획득단계는, 상기 코너에서 일정 거리 이내 및 일정 각도 이내의 벽의 특징점 들과의 거리를 추출할 수 있다."}
{"patent_id": "10-2022-0061570", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명은 본체의 설치된 1-3개의 레이저 기반의 장애물 감지센서만으로, 슬램이 가능하므로, 이동 로봇의 제조비용은 줄이면서, 코너에서 이동 로봇의 현재위치를 정확하게 추정하므로, 정확하고 신속한 주행이 가능한 이점이 존재한다. 또한, 본 발명은 맵이 없는 상황에서 로봇 청소기가 맵을 그리는 주행을 할 때 최소한의 센서로 정확한 맵을 제 공할 수 있고 맵을 그리는 시간을 줄이는 이점이 존재한다. 또한, 본 발명은 이동 로봇이 코너에서 270도 회전하면서, 코너 주변정보를 획득하게 되므로, 360도 회전보다 청소시간 및 센싱 시간이 줄게 되는 이점과, 이동 로봇이 회전을 마친 방향각이 이동 로봇의 헤딩 방향이 되므 로, 청소 효율이 증가되는 이점이 존재한다. 또한, 본 발명은 이동 로봇이 현재 위치를 추정하고, 맵을 생성하는 센싱 요소가 적고, 제어부의 제어부담도 적 은 이점이 존재한다. 한편, 그 외의 다양한 효과는 후술될 본 발명의 실시예에 따른 상세한 설명에서 직접적 또는 암시적으로 개시될 것이다."}
{"patent_id": "10-2022-0061570", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하에서는 첨부한 도면을 참조하여 본 발명의 실시예를 상세하게 설명한다. 그러나 본 발명이 이러한 실시예에 한정되는 것은 아니며 다양한 형태로 변형될 수 있음은 물론이다. 한편, 이하의 설명에서 사용되는 구성요소에 대한 접미사 \"모듈\" 및 \"부\"는 단순히 본 명세서 작성의 용이함만 이 고려되어 부여되는 것으로서, 그 자체로 특별히 중요한 의미 또는 역할을 부여하는 것은 아니다. 따라서, 상 기 \"모듈\" 및 \"부\"는 서로 혼용되어 사용될 수도 있다. 또한, 본 명세서에서, 다양한 요소들을 설명하기 위해 제1, 제2 등의 용어가 이용될 수 있으나, 이러한 요소들 은 이러한 용어들에 의해 제한되지 아니한다. 이러한 용어들은 한 요소를 다른 요소로부터 구별하기 위해서만 이용된다. 본 발명의 일 실시예에 따른 이동 로봇은 바퀴 등을 이용하여 스스로 이동이 가능한 로봇을 의미하고, 가 정 도우미 로봇 및 로봇 청소기 등이 될 수 있다. 이하에서는, 도면들을 참조하여, 이동 로봇 중 청소 기 능을 가지는 로봇 청소기를 예로 들어 설명하나, 본 발명은 이에 한정되지 않는다. 이동 로봇은 바퀴 등을 이용하여 스스로 이동이 가능한 로봇을 의미한다. 따라서, 이동 로봇은 스스 로 이동 가능한 안내 로봇, 청소 로봇, 엔터테인먼트(Entertainment) 로봇, 가정 도우미 로봇, 경비 로봇 등일 수 있고, 본 발명은 이동 로봇의 종류에 한정되지 않는다. 도 1은 본 발명의 일 실시예로서, 청소 로봇인 이동 로봇을 도시한다. 이동 로봇은 브러시 등 청소 기구를 구비하여 스스로 이동하면서 특정 공간을 청소할 수 있다. 이동 로봇은 주변에 대한 정보를 감지할 수 있는 센싱부(170:171, 175)를 포함한다. 이동 로봇은 카메라를 이용하는 비전 기반의 위치 인식과 레이저를 이용하는 라이다 기반의 위치 인식 기 술을 효과적으로 융합하여 조도 변화, 물품 위치 변경 등 환경 변화에 강인한 위치 인식 및 맵 생성을 수행할 수 있다. 또한, 이동 로봇은 레이저를 이용하는 라이다 기반의 위치 인식 기술을 사용하여 위치 인식 및 맵 생성을 수행할 수 있다. 영상획득부는 주행 구역을 촬영하는 것으로, 본체 외부의 영상을 획득하는 하나 이상의 카메라 센서 를 포함할 수 있다. 또한, 영상획득부는 카메라 모듈을 포함할 수 있다. 카메라 모듈은 디지털 카메라를 포함할 수 있다. 디지 털 카메라는 적어도 하나의 광학렌즈와, 광학렌즈를 통과한 광에 의해 상이 맺히는 다수개의 광다이오드 (photodiode, 예를 들어, pixel)를 포함하여 구성된 이미지센서(예를 들어, CMOS image sensor)와, 광다이오드 들로부터 출력된 신호를 바탕으로 영상을 구성하는 디지털 신호 처리기(DSP: Digital Signal Processor)를 포함 할 수 있다. 디지털 신호 처리기는 정지영상은 물론이고, 정지영상으로 구성된 프레임들로 이루어진 동영상을 생성하는 것도 가능하다. 본 실시예에서 영상획득부는, 본체 전방의 영상을 획득하도록 구비되는 전면 카메라 센서를 구비하나, 영상획득부의 위치와 촬영범위가 반드시 이에 한정되어야 하는 것은 아니다. 예를 들어, 이동 로봇은 주행 구역 내의 전방에 대한 영상을 획득하는 카메라 센서만 구비하여, 비전 (vision) 기반의 위치 인식 및 주행을 수행할 수 있다. 또는, 본 발명의 일 실시예에 따른 이동 로봇의 영상획득부는, 본체의 일면에 대하여 경사지게 배치되어 전방과 상방을 함께 촬영하도록 구성된 카메라 센서(미도시)를 포함할 수 있다. 즉, 하나의 카메라 센 서로 전방과 상방을 함께 촬영할 수 있다. 이 경우에 제어부는 카메라가 촬영하여 획득한 영상에서 전방 영상과 상방 영상을 화각을 기준으로 분리할 수 있다. 분리된 전방 영상은 전면 카메라 센서에서 획득된 영상과 같이 비전(vision) 기반의 사물 인식에 사용될 수 있 다. 또한, 분리된 상방 영상은 상부 카메라 센서에서 획득된 영상과 같이 비전(vision) 기반의 위치 인식 및 주 행에 사용될 수 있다. 본 발명에 따른 이동 로봇은 주변의 이미지를 이미지 기반의 기 저장된 정보와 비교하거나 획득되는 이미 지들을 비교하여 현재 위치를 인식하는 비전 슬램을 수행할 수 있다. 한편, 영상획득부는 전면 카메라 센서 및/또는 상부 카메라 센서를 복수개 구비하는 것도 가능하다. 또는 영상획득부는 전방과 상방을 함께 촬영하도록 구성된 카메라 센서(미도시)를 복수개 구비하는 것도 가능하 다. 본 실시예의 경우, 이동 로봇의 일부 부위(ex, 전방, 후방, 저면)에 카메라가 설치되어 있으며, 청소 시에 촬상 영상을 지속적으로 획득할 수 있다. 이러한 카메라는 촬영 효율을 위해 각 부위별로 여러 개가 설치될 수 도 있다. 카메라에 의해 촬상된 영상은 해당 공간에 존재하는 먼지, 머리카락, 바닥 등과 같은 물질의 종류 인 식, 청소 여부, 또는 청소 시점을 확인하는데 사용할 수 있다. 전면 카메라 센서는 이동 로봇의 주행 방향 전면에 존재하는 장애물 또는 청소 영역의 상황을 촬영할 수 있다. 본 발명의 일 실시예에 따르면, 영상획득부는 본체 주변을 연속적으로 촬영하여 복수의 영상을 획득 할 수 있고, 획득된 복수의 영상은 저장부에 저장될 수 있다. 이동 로봇은 복수의 영상을 이용하여 장애물 인식의 정확성을 높이거나, 복수의 영상 중 하나 이상의 영상 을 선택하여 효과적인 데이터를 사용함으로써 장애물 인식의 정확성을 높일 수 있다. 센싱부는 레이저를 이용하여 본체 외부의 지형 정보를 획득하는 라이다 센서를 포함할 수 있다. 라이다 센서는 레이저를 출력하여 레이저를 반사시킨 객체의 거리, 위치 방향, 재질 등의 정보를 제공하며 주행 구역의 지형 정보를 획득할 수 있다. 이동 로봇은 라이다 센서로 360도의 지형(Geometry) 정보 를 얻을 수 있다. 본 발명의 일 실시예에 따른 이동 로봇은 라이다 센서가 센싱한 객체들의 거리와 위치, 방향 등을 파 악하고, 그에 따라 주행하면서 맵을 생성할 수 있다. 본 발명의 일 실시예에 따른 이동 로봇은 외부에서 반사되어 수신되는 레이저의 시간차 또는 신호 강도 등 레이저 수신 패턴을 분석하여 주행 구역의 지형 정보를 획득할 수 있다. 또한, 이동 로봇은 라이다 센서 를 통하여 획득한 지형 정보를 이용하여 맵을 생성할 수 있다. 예를 들어, 본 발명에 따른 이동 로봇은 라이다 센서를 통하여 현재 위치에서 획득된 주변 지형 정보 를 라이다 센서 기반의 기 저장된 지형 정보와 비교하거나 획득되는 지형 정보들을 비교하여 현재 위치를 인식 하는 라이다 슬램을 수행할 수 있다. 더욱 바람직하게는, 본 발명에 따른 이동 로봇은 카메라를 이용하는 비전 기반의 위치 인식과 레이저를 이 용하는 라이다 기반의 위치 인식 기술을 효과적으로 융합하여 조도 변화, 물품 위치 변경 등 환경 변화에 강인 한 위치 인식 및 맵 생성을 수행할 수 있다. 한편, 센싱부는 이동 로봇의 동작, 상태와 관련된 각종 데이터를 센싱하는 센서들을 포함할 수 있다. 예를 들어, 센싱부는 전방의 장애물을 감지하는 장애물 감지센서를 포함할 수 있다. 또한, 센싱부 는 주행 구역 내 바닥에 낭떠러지의 존재 여부를 감지하는 낭떠러지 감지센서와, 바닥의 영상을 획득하는하부 카메라 센서를 더 포함할 수 있다. 도 1을 참조하면, 장애물 감지센서는 이동 로봇의 외주면에 일정 간격으로 설치되는 복수의 센서를 포함할 수 있다. 장애물 감지센서는, 레이저 센서, 적외선 센서, 초음파 센서, RF 센서, 지자기 센서, PSD(Position Sensitive Device) 센서 등을 포함할 수 있다. 특히, 본 발명의 경우, 장애물 감지센서는, 본체의 진행 방향을 기준으로 일정 각도 내의 지형 정보 를 획득하는 레이저 센서를 포함할 수 있다. 한편, 장애물 감지센서에 포함되는 센서의 위치와 종류는 이동 로봇의 기종에 따라 달라질 수 있고, 장애물 감지센서는 더 다양한 센서를 포함할 수 있다. 장애물 감지센서는 실내의 벽이나 장애물과의 거리를 감지하는 센서로, 본 발명은 그 종류에 한정되지 않 으나, 이하에서는 초음파 센서를 예시하여 설명한다. 장애물 감지센서는 이동 로봇의 주행(이동) 방향에 존재하는 물체, 특히 장애물을 감지하여 장애물 정보를 제어부에 전달한다. 즉, 장애물 감지센서는, 이동 로봇의 이동 경로, 전방이나 측면에 존재하는 돌출물, 집안의 집기, 가구, 벽면, 벽 모서리 등을 감지하여 그 정보를 제어 유닛에 전달할 수 있다. 이러한 이동 로봇은 디스플레이(도시하지 않음)를 구비하여 유저 인터페이스 화면 등 소정 영상을 표시할 수 있다. 또한, 디스플레이는 터치스크린으로 구성되어 입력 수단으로도 사용될 수 있다. 또한, 이동 로봇은, 터치, 음성 입력 등으로 사용자 입력을 수신하여, 사용자 입력에 대응하는 물체, 장소 에 대한 정보를 디스플레이 화면에 표시할 수 있다. 이러한 이동 로봇은 특정 공간을 주행하면서 부여된 임무, 즉 청소를 수행할 수 있다. 이동 로봇은 스스로 소정 목적지까지의 경로를 생성하여 이동하는 자율 주행, 사람 또는 다른 로봇을 따라가며 이동하는 추 종 주행을 수행할 수 있다. 안전사고 발생을 방지하기 위해서, 이동 로봇은 영상획득부를 통하여 획 득되는 영상 데이터, 센싱부에서 획득되는 감지 데이터 등에 기초하여 이동 중 장애물을 감지하여 회피하 면서 주행할 수 있다. 도 1의 이동 로봇은 다양한 공간, 예를 들어, 공항, 호텔, 마트, 의류매장, 물류, 병원 등의 공간, 특히 상업 공간과 같은 대면적의 공간에서 청소 서비스를 제공할 수 있는 청소 로봇일 수 있다. 이동 로봇은 이를 관리하고 제어할 수 있는 서버(도시하지 않음)와 연동될 수 있다. 서버는 원격에서 복수의 로봇의 상태를 모니터링하고, 제어할 수 있으며 효과적인 서비스 제공이 가능하다. 이동 로봇 및 서버는 하나 이상의 통신 규격을 지원하는 통신 수단(미도시)을 구비하여, 상호 통신할 수 있다. 또한, 이동 로봇 및 서버는 PC, 이동 단말기, 외부의 다른 서버와 통신할 수 있다. 예를 들어, 이동 로봇 및 서버\\는 MQTT(Message Queueing Telemetry Transport) 방식 또는 HTTP(HyperText Transfer Protocol) 방식으로 통신할 수 있다. 또한, 이동 로봇 및 서버는 HTTP 또는 MQTT 방식으로 PC, 이동 단말 기, 외부의 다른 서버와 통신할 수 있다. 경우에 따라서, 이동 로봇 및 서버는 2이상의 통신 규격을 지원하고, 통신 데이터의 종류, 통신에 참여하 는 기기의 종류에 따라 최적의 통신 규격을 사용할 수 있다. 서버는 클라우드(cloud) 서버로 구현되어, 사용자는 PC, 이동 단말기 등 다양한 기기로 통신 연결된 서버에 저 장된 데이터와 서버가 제공하는 기능, 서비스를 이용할 수 있다. 사용자는 PC, 이동 단말기 등을 통하여 로봇 시스템 내의 이동 로봇에 관한 정보를 확인하거나 제어할 수 있다. 본 명세서에서 '사용자'는 적어도 하나의 로봇을 통한 서비스를 이용하는 사람으로, 로봇을 구매 또는 대여하여 가정 등에서 사용하는 개인 고객, 및, 로봇을 이용하여 직원 또는 고객에게 서비스를 제공하는 기업의 관리자, 직원들과 이러한 기업이 제공하는 서비스를 이용하는 고객들을 포함할 수 있다. 따라서, '사용자'는 개인 고객(Business to Consumer : B2C)과 기업 고객(Business to Business : B2B)을 포함할 수 있다. 사용자는 PC, 이동 단말기 등을 통하여 이동 로봇의 상태, 위치를 모니터링하고, 콘텐츠 및 작업 스케줄을 관리할 수 있다. 한편, 서버는, 이동 로봇, 기타 기기로부터 수신되는 정보를 저장 및 관리할 수 있다. 이동 로봇 및 서버는 하나 이상의 통신 규격을 지원하는 통신 수단(미도시)을 구비하여, 상호 통신할 수 있다. 이동 로봇은, 서버로 공간(space), 사물(Object), 사용(Usage) 관련 데이터(Data)를 서버로 전송할 수 있다. 여기서, 공간(space), 사물(Object) 관련 데이터는 로봇이 인식한 공간(space)과 사물(Object)의 인식 관 련 데이터이거나, 영상획득부가 획득한 공간(space)과 사물(Object)에 대한 이미지 데이터일 수 있다. 실시예에 따라서, 이동 로봇 및 서버는 사용자, 음성, 공간의 속성, 장애물 등 사물의 속성 중 적어도 하 나를 인식하도록 학습된 소프트웨어 또는 하드웨어 형태의 인공신경망(Artificial Neural Networks: ANN)을 포 함할 수 있다. 본 발명의 일 실시예에 따르면, 로봇 및 서버는 딥러닝(Deep Learning)으로 학습된 CNN(Convolutional Neural Network), RNN(Recurrent Neural Network), DBN(Deep Belief Network) 등 심층신경망(Deep Neural Network: DNN)을 포함할 수 있다. 예를 들어, 로봇의 제어부(도 2의 140 참조)에는 CNN(Convolutional Neural Network) 등 심층신경망 구조(DNN)가 탑재될 수 있다. 서버는 이동 로봇으로부터 수신한 데이터, 사용자에 의해 입력되는 데이터 등에 기초하여, 심층신경망 (DNN)을 학습시킨 후, 업데이트된 심층신경망(DNN) 구조 데이터를 로봇으로 전송할 수 있다. 이에 따라, 이동 로봇이 구비하는 인공지능(artificial intelligence)의 심층신경망(DNN) 구조를 업데이트할 수 있다. 또한, 사용(Usage) 관련 데이터(Data)는 소정 제품, 예를 들어, 로봇의 사용에 따라 획득되는 데이터로, 사용 이력 데이터, 센싱부에서 획득된 센싱 데이터 등이 해당될 수 있다. 학습된 심층신경망 구조(DNN)는 인식용 입력 데이터를 입력 받고, 입력 데이터에 포함된 사람, 사물, 공간의 속 성을 인식하여, 그 결과를 출력할 수 있다. 또한, 학습된 심층신경망 구조(DNN)는 인식용 입력 데이터를 입력 받고, 이동 로봇의 사용(Usage) 관련 데 이터(Data)를 분석하고 학습하여 사용 패턴, 사용 환경 등을 인식할 수 있다. 한편, 공간(space), 사물(Object), 사용(Usage) 관련 데이터(Data)는 통신부(도 2의 190 참조)를 통하여 서버 로 전송될 수 있다. 서버는 수신한 데이터에 기초하여, 심층신경망(DNN)을 학습시킨 후, 업데이트된 심층신경망(DNN) 구조 데이터를 이동 로봇으로 전송하여 업데이트하게 할 수 있다. 이에 따라, 이동 로봇이 점점 더 똑똑해지고, 사용할수록 진화되는 사용자 경험(UX)을 제공할 수 있다. 로봇 및 서버는 외부 정보(external information)도 이용할 수 있다. 예를 들어, 서버가 다른 연 계 서비스 서버(20, 30)로부터 획득한 외부 정보를 종합적으로 사용하여 우수한 사용자 경험을 제공할 수 있다. 본 발명에 따르면, 이동 로봇 및/또는 서버가 음성 인식을 수행할 수 있어, 로봇의 제어를 위한 입력 을 사용자 음성을 사용할 수 있다. 또한, 본 발명에 따르면, 이동 로봇이 능동적으로 먼저 정보를 제공하거나 기능, 서비스를 추천하는 음성 을 출력함으로써 사용자에게 더욱 다양하고 적극적인 제어 기능을 제공할 수 있다. 도 2은 본 발명의 실시예에 따른 이동 로봇의 주요 구성들 간의 제어관계를 도시한 블록도이다. 도 2의 블 록도는 도 1의 이동 로봇 및 도 1의 이동 로봇에 모두 적용 가능하며, 이하에서는 도 1의 이동 로봇 의 구성과 함께 설명한다. 도 1을 참고하면, 이동 로봇은 본체를 이동시키는 주행부를 포함한다. 주행부는 본체(11 0)를 이동시키는 적어도 하나의 구동 바퀴를 포함한다. 주행부는 구동 바퀴에 연결되어 구동 바 퀴를 회전시키는 구동 모터(미도시)를 포함한다. 예를 들어, 구동 바퀴는 본체의 좌, 우 측에 각각 구비될 수 있으며, 이하, 각각 좌륜(L)과 우륜(R)이라고 한다. 좌륜(L)과 우륜(R)은 하나의 구동 모터에 의해 구동될 수도 있으나, 필요에 따라 좌륜(L)을 구동시키는 좌륜 구 동 모터와 우륜(R)을 구동시키는 우륜 구동 모터가 각각 구비될 수도 있다. 좌륜(L)과 우륜(R)의 회전 속도에 차이를 두어 좌측 또는 우측으로 본체의 주행방향을 전환할 수 있다. 이동 로봇은 소정의 서비스를 제공하기 위한 서비스부를 포함한다. 도 1 및 도 1에서는 서비스부 가 청소 작업을 수행하는 것으로 예를 들어 본 발명을 설명하나, 본 발명은 이에 한정되지 않는다. 예를 들어, 서비스부는 청소(비질, 흡입청소, 걸레질 등), 설거지, 요리, 빨래, 쓰레기 처리 등의 가사 서비스 를 사용자에게 제공하도록 구비될 수 있다. 또 다른 예로, 서비스부는 주변의 외부 침입자나 위험 상황 등 을 감지하는 보안 기능을 수행할 수 있다. 이동 로봇은 주행 구역을 이동하며 서비스부에 의해 바닥을 청소할 수 있다. 서비스부는, 이물 질을 흡입하는 흡입 장치, 비질을 수행하는 브러시(135, 155), 흡입장치나 브러시에 의해 수거된 이물질을 저장 하는 먼지통(미도시) 및/또는 걸레질을 수행하는 걸레부(미도시) 등을 포함할 수 있다. 도 1의 이동 로봇의 본체의 저면부에는 공기의 흡입이 이루어지는 흡입구가 형성될 수 있으며, 본체 내에는 흡입구를 통해 공기가 흡입될 수 있도록 흡입력을 제공하는 흡입장치(미도시)와, 흡입구를 통해 공기와 함께 흡입된 먼지를 집진하는 먼지통(미도시)이 구비될 수 있다. 본체는 이동 로봇을 구성하는 각종 부품들이 수용되는 공간을 형성하는 케이스를 포함할 수 있 다. 케이스에는 먼지통의 삽입과 탈거를 위한 개구부가 형성될 수 있고, 개구부를 여닫는 먼지통 커버 가 케이스에 대해 회전 가능하게 구비될 수 있다. 흡입구를 통해 노출되는 솔들을 갖는 롤형의 메인 브러시와, 본체의 저면부 전방측에 위치하며, 방사상으 로 연장된 다수개의 날개로 이루어진 솔을 갖는 보조 브러시가 구비될 수 있다. 이들 브러시들의 회 전에 의해 주행 구역 내 바닥으로부터 먼지들이 분리되며, 이렇게 바닥으로부터 분리된 먼지들은 흡입구를 통해 흡입되어 먼지통에 모인다. 배터리는 구동 모터뿐만 아니라, 이동 로봇의 작동 전반에 필요한 전원을 공급한다. 배터리가 방전될 시, 이동 로봇은 충전을 위해 충전대로 복귀하는 주행을 실시할 수 있으며, 이러한 복귀 주행 중, 이동 로봇은 스스로 충전대의 위치를 탐지할 수 있다. 충전대는 소정의 복귀 신호를 송출하는 신호 송출부(미도시)를 포함할 수 있다. 복귀 신호는 초음파 신호 또는 적외선 신호일 수 있으나, 반드시 이에 한정되는 것은 아니다. 도 1의 이동 로봇은 복귀 신호를 수신하는 신호 감지부(미도시)를 포함할 수 있다. 충전대는 신호 송 출부를 통해 적외선 신호를 송출하고, 신호 감지부는 적외선 신호를 감지하는 적외선 센서를 포함할 수 있다. 이동 로봇은 충전대로부터 송출된 적외선 신호에 따라 충전대의 위치로 이동하여 충전대와 도킹(docking)한다. 이러한 도킹에 의해 이동 로봇의 충전 단자와 충전대의 충전 단자 간 에 충전에 이루어진다. 이동 로봇은 이동 로봇의 내/외부의 정보를 감지하는 센싱부를 포함할 수 있다. 예를 들어, 센싱부는 주행 구역에 대한 각종 정보를 감지하는 하나 이상의 센서(171, 175), 주행 구역에 대한 영상 정보를 획득하는 영상획득부를 포함할 수 있다. 실시예에 따라서, 영상획득부는 센싱부 외부에 별도로 구비될 수 있다. 이동 로봇은 센싱부가 감지한 정보를 통해, 주행 구역을 맵핑(Mapping)할 수 있다. 예를 들어, 이동 로봇은 영상획득부가 획득한 주행 구역의 천장 영상에 기초하여 비전(vision) 기반의 위치 인식 및 맵 생성을 수행할 수 있다. 또한, 이동 로봇은 레이저를 이용하는 라이다(Light Detection And Ranging: LiDAR) 센서 기반의 위치 인식 및 맵 생성을 수행할 수 있다. 더욱 바람직하게는 본 발명에 따른 이동 로봇은 카메라를 이용하는 비전 기반의 위치 인식과 레이저를 이 용하는 라이다 기반의 위치 인식 기술을 효과적으로 융합하여 조도 변화, 물품 위치 변경 등 환경 변화에 강인 한 위치 인식 및 맵 생성을 수행할 수 있다. 한편, 영상획득부는 주행 구역을 촬영하는 것으로, 본체 외부의 영상을 획득하는 하나 이상의 카메라 센서를 포함할 수 있다. 또한, 영상획득부는 카메라 모듈을 포함할 수 있다. 카메라 모듈은 디지털 카메라를 포함할 수 있다. 디지 털 카메라는 적어도 하나의 광학렌즈와, 광학렌즈를 통과한 광에 의해 상이 맺히는 다수개의 광다이오드(photodiode, 예를 들어, pixel)를 포함하여 구성된 이미지센서(예를 들어, CMOS image sensor)와, 광다이오드 들로부터 출력된 신호를 바탕으로 영상을 구성하는 디지털 신호 처리기(DSP: Digital Signal Processor)를 포함 할 수 있다. 디지털 신호 처리기는 정지영상은 물론이고, 정지영상으로 구성된 프레임들로 이루어진 동영상을 생성하는 것도 가능하다. 본 실시예에서 영상획득부는, 본체 전방의 영상을 획득하도록 구비되는 전면 카메라 센서(120a)와 본 체의 상면부에 구비되어, 주행 구역 내의 천장에 대한 영상을 획득하는 상부 카메라 센서(120b)를 구비하 나, 영상획득부의 위치와 촬영범위가 반드시 이에 한정되어야 하는 것은 아니다. 예를 들어, 이동 로봇은 주행 구역 내의 천장에 대한 영상을 획득하는 상부 카메라 센서(120b)만 구비하여, 비전(vision) 기반의 위치 인식 및 주행을 수행할 수 있다. 또는, 본 발명의 일 실시예에 따른 이동 로봇의 영상획득부는, 본체의 일면에 대하여 경사지게 배치되어 전방과 상방을 함께 촬영하도록 구성된 카메라 센서(미도시)를 포함할 수 있다. 즉, 하나의 카메라 센 서로 전방과 상방을 함께 촬영할 수 있다. 이 경우에 제어부는 카메라가 촬영하여 획득한 영상에서 전방 영상과 상방 영상을 화각을 기준으로 분리할 수 있다. 분리된 전방 영상은 전면 카메라 센서(120a)에서 획득된 영상과 같이 비전(vision) 기반의 사물 인식에 사용될 수 있다. 또한, 분리된 상방 영상은 상부 카메라 센서 (120b)에서 획득된 영상과 같이 비전(vision) 기반의 위치 인식 및 주행에 사용될 수 있다. 본 발명에 따른 이동 로봇은 주변의 이미지를 이미지 기반의 기저장된 정보와 비교하거나 획득되는 이미지 들을 비교하여 현재 위치를 인식하는 비전 슬램을 수행할 수 있다. 한편, 영상획득부는 전면 카메라 센서(120a) 및/또는 상부 카메라 센서(120b)를 복수개 구비하는 것도 가 능하다. 또는 영상획득부는 전방과 상방을 함께 촬영하도록 구성된 카메라 센서(미도시)를 복수개 구비하 는 것도 가능하다. 본 실시예의 경우, 이동 로봇의 일부 부위(ex, 전방, 후방, 저면)에 카메라가 설치되어 있으며, 청소 시에 촬상영상을 지속적으로 획득할 수 있다. 이러한 카메라는 촬영 효율을 위해 각 부위별로 여러 개가 설치될 수도 있다. 카메라에 의해 촬상된 영상은 해당 공간에 존재하는 먼지, 머리카락, 바닥 등과 같은 물질의 종류 인식, 청소 여부, 또는 청소 시점을 확인하는데 사용할 수 있다. 전면 카메라 센서(120a)는 이동 로봇의 주행 방향 전면에 존재하는 장애물 또는 청소 영역의 상황을 촬영 할 수 있다. 본 발명의 일 실시예에 따르면, 영상획득부는 본체 주변을 연속적으로 촬영하여 복수의 영상을 획득 할 수 있고, 획득된 복수의 영상은 저장부에 저장될 수 있다. 이동 로봇은 복수의 영상을 이용하여 장애물 인식의 정확성을 높이거나, 복수의 영상 중 하나 이상의 영상 을 선택하여 효과적인 데이터를 사용함으로써 장애물 인식의 정확성을 높일 수 있다. 센싱부는 레이저를 이용하여 본체 외부의 지형 정보를 획득하는 라이다 센서를 포함할 수 있다. 라이다 센서는 레이저를 출력하여 레이저를 반사시킨 객체의 거리, 위치 방향, 재질 등의 정보를 제공하며 주행 구역의 지형 정보를 획득할 수 있다. 이동 로봇은 라이다 센서로 360도의 지형(Geometry) 정보 를 얻을 수 있다. 본 발명의 일 실시예에 따른 이동 로봇은 라이다 센서가 센싱한 객체들의 거리와 위치, 방향 등을 파 악하여 맵을 생성할 수 있다. 본 발명의 일 실시예에 따른 이동 로봇은 외부에서 반사되어 수신되는 레이저의 시간차 또는 신호 강도 등 레이저 수신 패턴을 분석하여 주행 구역의 지형 정보를 획득할 수 있다. 또한, 이동 로봇은 라이다 센서 를 통하여 획득한 지형 정보를 이용하여 맵을 생성할 수 있다. 예를 들어, 본 발명에 따른 이동 로봇은 라이다 센서를 통하여 현재 위치에서 획득된 주변 지형 정보 를 분석하여 이동 방향을 결정하는 라이다 슬램을 수행할 수 있다. 더욱 바람직하게는, 본 발명에 따른 이동 로봇은 카메라를 이용하는 비전 기반의 위치 인식과 레이저를 이 용하는 라이다 기반의 위치 인식 기술 및 초음파 센서를 통해 장애물을 효과적으로 인식하고 변화량이 작은 최 적의 이동 방향을 추출하여 맵 생성을 수행할 수 있다.한편, 센싱부는 이동 로봇의 동작, 상태와 관련된 각종 데이터를 센싱하는 센서들(171, 172, 179)을 포함할 수 있다. 예를 들어, 센싱부는 전방의 장애물을 감지하는 장애물 감지센서를 포함할 수 있다. 또한, 센싱부 는 주행 구역 내 바닥에 낭떠러지의 존재 여부를 감지하는 낭떠러지 감지센서와, 바닥의 영상을 획득 하는 하부 카메라 센서를 더 포함할 수 있다. 장애물 감지센서는 이동 로봇의 외주면에 일정 간격으로 설치되는 복수의 센서를 포함할 수 있다. 장애물 감지센서는, 적외선 센서, 초음파 센서, RF 센서, 지자기 센서, PSD(Position Sensitive Device) 센서 등을 포함할 수 있다. 한편, 장애물 감지센서에 포함되는 센서의 위치와 종류는 이동 로봇의 기종에 따라 달라질 수 있고, 장애물 감지센서는 더 다양한 센서를 포함할 수 있다. 장애물 감지센서는 실내의 벽이나 장애물과의 거리를 감지하는 센서로, 본 발명은 그 종류에 한정되지 않 으나, 이하에서는 초음파 센서를 예시하여 설명한다. 장애물 감지센서는 이동 로봇의 주행(이동) 방향에 존재하는 물체, 특히 장애물을 감지하여 장애물 정보를 제어부에 전달한다. 즉, 장애물 감지센서는, 이동 로봇의 이동 경로, 전방이나 측면에 존재하는 돌출물, 집안의 집기, 가구, 벽면, 벽 모서리 등을 감지하여 그 정보를 제어부에 전달할 수 있다. 이때, 제어부는 초음파 센서를 통해 수신된 적어도 1 이상의 신호에 기초하여 장애물의 위치를 감지하고, 감지된 장애물의 위치에 따라 이동 로봇의 움직임을 제어하여 맵 생성 시에 최적의 이동 경로를 제공한다. 실시예에 따라서는, 케이스의 외측면에 구비되는 장애물 감지 센서는 발신부와 수신부를 포함하여 구 성될 수 있다. 예를 들어, 초음파 센서는 적어도 하나 이상의 발신부 및 적어도 1 이상의 수신부가 서로 엇갈리도록 구비될 수 있다. 이에 따라, 다양한 각도로 신호를 방사하고, 장애물에 반사된 신호를 다양한 각도에서 수신할 수 있다. 실시예에 따라서는, 장애물 감지센서에서 수신된 신호는, 증폭, 필터링 등의 신호 처리 과정을 거칠 수 있 고, 이후 장애물까지의 거리 및 방향이 산출될 수 있다. 한편, 센싱부는 본체의 구동에 따른 이동 로봇의 주행 동작을 감지하고 동작 정보를 출력하는 주행 감지 센서를 더 포함할 수 있다. 주행 감지 센서로는, 자이로 센서(Gyro Sensor), 휠 센서(Wheel Sensor), 가속도 센서(Acceleration Sensor) 등을 사용할 수 있다. 이동 로봇은 배터리의 충전 상태를 감지하고, 감지 결과를 제어부에 전송하는 배터리 감지부(미도 시)를 더 포함할 수 있다. 배터리는 배터리 감지부와 연결되어 배터리 잔량 및 충전 상태가 제어부에 전달 된다. 배터리 잔량은 출력부(미도시)의 화면에 표시될 수 있다. 또한, 이동 로봇은 온/오프(On/Off) 또는 각종 명령을 입력할 수 있는 조작부를 포함한다. 조작부 를 통해 이동 로봇의 작동 전반에 필요한 각종 제어명령을 입력 받을 수 있다. 또한, 이동 로봇(10 0)은 출력부(미도시)를 포함하여, 예약 정보, 배터리 상태, 동작모드, 동작상태, 에러상태 등을 표시할 수 있다. 도 2을 참조하면, 이동 로봇은 현재 위치를 인식하는 등 각종 정보를 처리하고 판단하는 제어부, 및 각종 데이터를 저장하는 저장부를 포함한다. 또한, 이동 로봇은 다른 기기와 데이터를 송수신하는 통 신부를 더 포함할 수 있다. 이동 로봇과 통신하는 기기 중 외부 단말기는 이동 로봇을 제어하기 위한 애플리케이션을 구비하고, 애플리케이션의 실행을 통해 이동 로봇이 청소할 주행 구역에 대한 맵을 표시하고, 맵 상에 특정 영역을 청소하도록 영역을 지정할 수 있다. 사용자 단말기는 이동 로봇과 통신하여, 맵과 함께 이동 로봇의 현재 위치를 표시할 수 있으며, 복수의 영역에 대한 정보가 표시될 수 있다. 또한, 사용자 단말기는 이동 로봇 의 주행에 따라 그 위치를 갱신하여 표시한다. 제어부는 이동 로봇을 구성하는 센싱부, 조작부, 주행부를 제어하여, 이동 로봇(10 0)의 동작 전반을 제어한다. 저장부는 이동 로봇의 제어에 필요한 각종 정보들을 기록하는 것으로, 휘발성 또는 비휘발성 기록 매 체를 포함할 수 있다. 기록 매체는 마이크로 프로세서(microprocessor)에 의해 읽힐 수 있는 데이터를 저장한 것으로, 그 종류나 구현 방식에 한정되지 않는다. 또한, 저장부에는 주행 구역에 대한 맵(Map)이 저장될 수 있다. 맵은 이동 로봇과 유선 또는 무선 통 신을 통해 정보를 교환할 수 있는 사용자 단말기, 서버 등에 의해 입력된 것일 수도 있고, 이동 로봇이 스 스로 학습을 하여 생성한 것일 수도 있다. 맵에는 주행 구역 내의 방들의 위치가 표시될 수 있다. 또한, 이동 로봇의 현재 위치가 맵 상에 표시될 수 있으며, 맵 상에서의 이동 로봇의 현재의 위치는 주행 과정에서 갱신될 수 있다. 외부 단말기는 저장부 에 저장된 맵과 동일한 맵을 저장한다. 저장부는 청소 이력 정보를 저장할 수 있다. 이러한 청소 이력 정보는 청소를 수행할 때마다 생성될 수 있 다. 저장부에 저장되는 주행 구역에 대한 맵(Map)은, 청소 중 주행에 사용되는 내비게이션 맵(Navigation map), 위치 인식에 사용되는 슬램(Simultaneous localization and mapping: SLAM) 맵, 장애물 등에 부딪히면 해당 정보를 저장하여 학습 청소 시 사용하는 학습 맵, 전역 위치 인식에 사용되는 전역 위치 맵, 인식된 장애 물에 관한 정보가 기록되는 장애물 인식 맵 등일 수 있다. 한편, 상술한 바와 같이 용도별로 저장부에 맵들을 구분하여 저장, 관리할 수 있지만, 맵이 용도별로 명확 히 구분되지 않을 수도 있다. 예를 들어, 적어도 1 이상의 용도로 사용할 수 있도록 하나의 맵에 복수의 정보를 저장할 수도 있다. 제어부는 주행제어모듈, 위치인식모듈, 지도생성모듈 및 장애물인식모듈을 포함할 수 있다. 주행제어모듈은 이동 로봇의 주행을 제어하는 것으로, 주행 설정에 따라 주행부의 구동을 제어 한다. 또한, 주행제어모듈은 주행부의 동작을 바탕으로 이동 로봇의 주행경로를 파악할 수 있다. 예를 들어, 주행제어모듈은 구동 바퀴의 회전속도를 바탕으로 이동 로봇의 현재 또는 과거의 이동속도, 주행한 거리 등을 파악할 수 있으며, 각 구동 바퀴의 회전 방향에 따라 현재 또는 과거의 방향 전환 과정 또한 파악할 수 있다. 이렇게 파악된 이동 로봇의 주행 정보를 바탕으로, 맵 상에서 이동 로봇 의 위치가 갱신될 수 있다. 지도생성모듈은 주행 구역의 맵을 생성할 수 있다. 지도생성모듈은 영상획득부를 통해 획득한 영상을 처리하여 맵을 작성할 수 있다. 예를 들어, 주행 구역에 대응하는 맵, 청소 영역과 대응되는 청소 맵을 작성할 수 있다. 또한, 지도생성모듈은 각 위치에서 영상획득부를 통해 획득한 영상을 처리하여 맵과 연계시켜 전역위 치를 인식할 수 있다. 또한, 지도생성모듈은 라이다 센서를 통해 획득한 정보에 기초하여 맵을 작성하고, 각 위치에서 라이 다 센서를 통해 획득한 정보에 기초하여 위치를 인식할 수 있다. 또한, 지도생성모듈은 장애물 감지센서를 통해 획득한 정보에 기초하여 맵을 작성하고, 각 위치에서 장애물 감지센서를 통해 획득한 정보에 기초하여 위치를 인식할 수 있다 더욱 바람직하게는, 지도생성모듈은 영상획득부와 라이다 센서를 통해 획득한 정보에 기초하여 맵을 작성하고 위치 인식을 수행할 수 있다. 위치인식모듈은 현재 위치를 추정하여 인식한다. 위치인식모듈은 영상획득부의 영상 정보를 이 용하여 지도생성모듈과 연계하여 위치를 파악함으로써, 이동 로봇의 위치가 갑자기 변경되는 경우에 도 현재 위치를 추정하여 인식할 수 있다. 이동 로봇은 위치인식모듈을 통해 연속적인 주행 중에 위치 인식이 가능하고 또한, 위치인식모듈 없이 주행제어모듈, 지도생성모듈, 장애물인식모듈을 통해, 맵을 학습하고 현재 위치를 추정할 수 있다. 이동 로봇은 미지의 현재 위치에서 영상획득부를 통해 획득영상을 획득한다. 영상을 통해 천장에 위 치하는 조명들, 경계(edge), 코너(corner), 얼룩(blob), 굴곡(ridge) 등의 여러가지 특징(feature)들이 확 인된다. 이와 같이, 제어부는 주행 구역을 구분하고 복수의 영역으로 구성된 맵을 생성하거나, 기저장된 맵을 바탕 으로 본체의 현재 위치를 인식할 수 있다. 또한, 제어부는 영상획득부와 라이다 센서를 통해 획득한 정보를 융합하여 맵을 작성하고 위치 인식을 수행할 수 있다. 제어부는 맵이 생성되면, 생성된 맵을 통신부를 통해 외부 단말기, 서버 등으로 전송할 수 있다. 또 한, 제어부는 앞서 설명한 바와 같이, 외부 단말기, 서버 등으로부터 맵이 수신되면, 저장부에 저장 할 수 있다. 또한 제어부는 주행 중 맵이 갱신되는 경우 갱신된 정보를 외부 단말기로 전송하여 외부 단말기와 이동 로 봇에 저장되는 맵이 동일하도록 한다. 외부 단말기와 이동 로봇에 저장된 맵이 동일하게 유지됨에 따 라 이동 단말기로부터의 청소명령에 대하여, 이동 로봇이 지정된 영역을 청소할 수 있으며, 또한, 외부 단 말기에 이동 로봇의 현재 위치가 표시될 수 있도록 하기 위함이다. 이때, 맵은 청소 영역을 복수의 영역으로 구분되고, 복수의 영역을 연결하는 연결통로가 포함하며, 영역 내의 장애물에 대한 정보를 포함할 수 있다. 제어부는 청소명령이 입력되면, 맵 상의 위치와 이동 로봇의 현재 위치가 일치하는지 여부를 판단한 다. 청소명령은 리모컨, 조작부 또는 외부 단말기로부터 입력될 수 있다. 제어부는 현재 위치가 맵 상의 위치와 일치하지 않는 경우, 또는 현재 위치를 확인할 수 없는 경우, 현재 위치를 인식하여 이동 로봇의 현재 위치를 복구한 한 후, 현재 위치를 바탕으로 지정영역으로 이동하도록 주행부를 제어할 수 있다. 현재 위치가 맵 상의 위치와 일치하지 않는 경우 또는 현재 위치를 확인할 수 없는 경우, 위치인식모듈은 영상획득부로부터 입력되는 획득영상 및/또는 라이다 센서를 통해 획득된 지형 정보를 분석하여 맵을 바탕으로 현재 위치를 추정할 수 있다. 또한, 장애물인식모듈 또는 지도생성모듈 또한, 같은 방식으 로 현재 위치를 인식할 수 있다. 위치를 인식하여 이동 로봇의 현재 위치를 복구한 후, 주행제어모듈은 현재 위치로부터 지정영역으로 주행경로를 산출하고 주행부를 제어하여 지정영역으로 이동한다. 서버로부터 청소 패턴 정보를 수신하는 경우, 주행제어모듈은 수신한 청소 패턴 정보에 따라, 전체 주행 구역을 복수의 영역으로 나누고, 하나 이상의 영역을 지정영역으로 설정할 수 있다. 또한, 주행제어모듈은 수신한 청소 패턴 정보에 따라 주행경로를 산출하고, 주행경로를 따라 주행하며, 청 소를 수행할 수 있다. 제어부는 설정된 지정영역에 대한 청소가 완료되면, 청소기록을 저장부에 저장할 수 있다. 또한, 제어부는 통신부를 통해 이동 로봇의 동작상태 또는 청소상태를 소정 주기로 외부 단말기, 서버로 전송할 수 있다. 그에 따라 외부 단말기는 수신되는 데이터를 바탕으로, 실행중인 애플리케이션의 화면상에 맵과 함께 이동 로봇 의 위치를 표시하고, 또한 청소 상태에 대한 정보를 출력한다. 본 발명의 실시예에 따른 이동 로봇은 일방향으로 장애물이나 벽면이 감지될 때까지 이동하다가, 장애물인 식모듈이 장애물을 인식하면, 인식된 장애물의 속성에 따라 직진, 회전 등 주행 패턴을 결정할 수 있다. 예를 들어, 인식된 장애물의 속성이 넘어갈 수 있는 종류의 장애물이면, 이동 로봇은 계속 직진할 수 있다. 또는, 인식된 장애물의 속성이 넘어갈 수 없는 종류의 장애물이면, 이동 로봇은 회전하여 일정거리 이동하고, 다시 최초 이동 방향의 반대방향으로 장애물이 감지되는 거리까지 이동하여 지그재그 형태로 주행할 수 있다 본 발명의 실시예에 따른 이동 로봇은, 머신 러닝(machine learning) 기반의 사람, 사물 인식 및 회피를 수행할 수 있다. 제어부는, 입력 영상에서 머신 러닝(machine learning)으로 기 학습된 장애물을 인식하는 장애물인식모듈 과 인식된 장애물의 속성에 기초하여, 주행부의 구동을 제어하는 주행제어모듈을 포함할 수 있 다. 장애물인식모듈은 장애물의 속성이 학습된 소프트웨어 또는 하드웨어 형태의 인공신경망(ANN)을 포함할 수 있다. 예를 들어, 장애물인식모듈은 딥러닝(Deep Learning)으로 학습된 CNN(Convolutional Neural Network), RNN(Recurrent Neural Network), DBN(Deep Belief Network) 등 심층신경망(Deep Neural Network: DNN)을 포함 할 수 있다. 장애물인식모듈은 심층신경망(DNN)에 포함된 노드들 사이의 가중치(weight)들에 기초하여 입력되는 영상 데이터에 포함되는 장애물의 속성을 판별할 수 있다. 한편, 이동 로봇은 출력부를 더 포함하여, 소정 정보를 영상으로 표시하거나 음향으로 출력할 수 있 다. 출력부는 사용자의 명령 입력에 대응하는 정보, 사용자의 명령 입력에 대응하는 처리 결과, 동작모드, 동 작상태, 에러상태 등을 영상으로 표시하는 디스플레이(미도시)를 포함할 수 있다. 실시예에 따라서는, 디스플레이는 터치패드와 상호 레이어 구조를 이루어 터치스크린으로 구성될 수 있다. 이 경우에, 터치스크린으로 구성되는 디스플레이는 출력 장치 이외에 사용자의 터치에 의한 정보의 입력이 가능한 입력 장치로도 사용될 수 있다. 또한, 출력부는 오디오 신호를 출력하는 음향 출력부(미도시)를 포함할 수 있다. 음향 출력부는 제어부 의 제어에 따라 경고음, 동작모드, 동작상태, 에러상태 등의 알림 메시지, 사용자의 명령 입력에 대응하는 정보, 사용자의 명령 입력에 대응하는 처리 결과 등을 음향으로 출력할 수 있다. 음향 출력부는, 제어부로 부터의 전기 신호를 오디오 신호로 변환하여 출력할 수 있다. 이를 위해, 스피커 등을 구비할 수 있다. 이하에서는 도 2의 구성도를 가지는 도 1의 이동 로봇의 맵 생성을 위한 제어 방법을 설명한다. 도 3는 본 발명의 일 실시예에 따른 이동 로봇의 제어 방법을 도시한 순서도이다. 도 3를 참고하면, 본 발명의 일 실시예에 따른 이동 로봇은 제어부의 명령에 의해 청소나 서비스를 위한 주행 명령을 수신한다. 이동 로봇은 주행 명령에 따라 청소 구역 내를 주행하면서 주변 환경에 지형 정보를 수득한다(S10, S11). 제어부는 센싱부를 제어하여 주변 환경에 지형 정보를 수득하도록 한다. 본 발명은 레이저(Laser) 기반 슬램 기술에서 사용될 수 있다. 더욱 구체적으로, 본 발명의 경우, 주행 구역이 어두워서 비전 기반 슬램을 사용할 수 없는 경우나, 비용을 줄이기 위해, 라이다 센서나 카메라 센서가 없는 경 우 사용될 수 있다. 슬램 기술은 비전(Vision) 기반, 레이저(Laser) 기반, 슬램으로 나눌 수 있다. 이 중 비전(Vision) 기반 슬램은 영상에서 특징점을 추출한 후 매칭을 하여 3차원 좌표를 계산하고, 이를 토대 로 슬램을 한다. 영상에 많은 정보가 있어 환경이 밝을 경우 자기 위치 인식을 하는데 뛰어난 성능을 가지지만 어두운 곳에서는 동작이 어렵고, 작은 크기의 물체가 가까운 곳에 있는 것과 큰 크기의 물체가 먼 곳에 있는 것 을 비슷하게 인식하는 등의 스케일 드리프트(Scale Drift) 문제가 있다. 그리고 레이저(Laser) 기반 슬램은 레이저를 활용하여 각도 별 거리를 측정하여 주변 환경의 지형(geometry)을 계산하는 원리로 동작을 한다. 레이저 기반 슬램은 어두운 환경에서도 동작이 잘된다. 하지만, 지형(geometry) 정보만을 가지고 위치를 인식하므로 오피스(Office) 환경같이 반복되는 영역이 많은 공간에서는 초기 위치 조건 이 없을 경우 자기 위치를 찾기 어려운 경우가 많다. 또한 가구가 옮겨지는 등 동적 환경에 대응이 어렵다. 즉, 비전(Vision) 기반 슬램의 경우 어두운 환경(불빛이 없는 환경)에서는 정확한 동작이 어렵다. 또한 레이저 (Laser) 기반 슬램의 경우 동적 환경(움직이는 물체 등)과 반복되는 환경(비슷한 패턴)에서 자기 위치 인식이 어렵고, 기존 맵과 현재 프레임의 매칭 및 루프 클로징(loop closing)의 정확도가 떨어지며, 랜드마크를 만들기 힘들기 때문에, 납치(kidnap) 문제와 같은 상황에 대처하기 힘들다.이동 로봇은 센싱부에서 획득한 지형 정보를 통해 본체의 현재 위치가 주행 영역의 코너인 지 판단한다(S13). 도 4를 참조하면, 이동 로봇은 청소 모드에 따라 주행 구역을 주행한다. 이동 로봇은 장애물 감지센서에서 입력된 에지, 벽 및 장애물과의 거리 정보를 바탕으로 이동 로봇 의 현재 위치가 코너인지 판단한다. 구체적으로, 제어부는 2개의 벽이 만나는 지점을 코너로 정의하고, 본체가 코너에서 일정한 거리 이내에 위치되는 본체의 현재 위치가 코너라고 판단 한다. 이동 로봇은 현재 위치가 본체의 현재 위치가 코너인 경우, 코너에서 코너 주변의 지형 정보를 획득한다(S14). 구체적으로, 제어부는 본체가 코너에 위치된 경우, 코너에서 센싱부를 통해 코너 주변의 지형 정보를 획득하는 코너 주변정보 획득 모션을 하도록 제어한다. 제어부는 코너 주변정보 획득 모션을 본체의 월 팔로잉 주행 중에 본체가 코너에 위치되는 경우, 실행할 수 있다. 또한, 제어부는 이동 로봇의 청소 주행 중에 본체가 코너에 위치되 는 경우, 실행할 수 있다. 제어부는 이동 로봇이 코너에 위치할 때 마다 코너 주변정보 획득 모션을 하도록 이동 로봇(10 0)을 제어한다. 도 5를 참조하면, 코너 주변정보 획득 모션은, 본체가 코너에서 회전하면서 센싱부 를 통해 외부의 지형 정보를 획득할 수 있다. 구체적으로, 제어부는 본체가 코너에 위치된 경우, 본체를 제자리에서 시계방향 또는 반 시 계방향으로 회전하게 제어하면서 동시에, 센싱부라 외부의 지형 정보를 획득하게 제어한다. 제어부는 본체를 제자리에서 360도 회전하게 할 수도 있지만, 이렇게 회전하면, 청소시간이 늘어나는 단점이 존재한 다. 이러한 단점을 극복하기 위해, 도 5를 참조하면, 코너 주변정보 획득 모션은 본체가 코너에서 제1 방 향으로 회전한 후 제1 방향과 반대 방향인 제2 방향으로 회전하면서 센싱부를 통해 외부의 지형 정보를 획 득할 수 있다. 더욱 구체적으로, 제1 방향 및 제2 방향은 본체의 진행 방향(헤딩 방향과)과 직교하고, 제2 방향은 본체 가 코너를 통과한 후 진행방향(헤딩 방향)과 일치될 수 있다. 따라서, 본체는 코너에서 270 도 회전하면서, 코너 주변정보를 획득하게 되므로, 360도 회전보다 청소시간 및 센싱 시간이 줄게 되는 이 점과, 이동 로봇이 회전을 마친 방향각이 이동 로봇의 헤딩 방향이 되므로, 청소 효율이 증가되는 이 점이 존재한다. 즉, 도 5에서 도시하는 바와 같이, 이동 로봇은 Y축 방향으로 진행하다가 코너를 만나게 되면, -X 축 방향(제1 방향)까지 제자리에서 시계방향으로 90도 회전한 후, X축 방향까지 반 시계방향으로 180도 회전하면서, 코너 주변의 지형 정보를 획득하게 된다. 장애물 감지센서는 전방을 중심으로 일정 각도(대략 2도 내지 8도) 범위 내에서 장애물이나 벽과의 거리를 감지하도록 본체의 전방에 설치되는 것이 보통이다. 또한, 장애물 감지센서는 설치 비용을 줄이고, 센싱의 효율성은 향상시키기 위해 2개 내지 3개가 설치되는 것이 보통이다. 코너 주변의 지형 정보를 회득하는 것은, 이러한 장애물 감지센서의 센싱 각도의 한계를 본체의 회전으로 극복하는 것이다. 제어부는 코너 주변의 지형 정보를 획득할 때, 본체를 상술한 바와 같이 시계방향과 반 시계 방향으로 회전하면서, 코너에 인접한 장애물(예를 들면, 벽)의 특징점 들을 추출하고, 추출한 특징점들의 각도 값과 본체와의 거리 값을 획득한다. 또한, 코너 주변정보 획득 모션은 코너에서 일정 거리 이내 및 일정 각도 이내의 벽의 특징점 들과의 거리를 추출하여 지형 정보를 획득할 수 있다. 제어부는 코너 주변정보 획득 모션에서 획득한 코너 주변 지형 정보를 기반으로 본체의 현재 위 치를 추정할 수 있다(S14).제어부는, 벽의 특징점 들과의 거리를 바탕으로 본체의 현재 위치를 추정할 수 있다. 구체적으로, 도 7을 참조하면, 제어부는 맵에 저장된 코너 주변의 벽의 위치 정보와 코너 주변정보 회득 모션에서 획득한 코너 주변 지형 정보를 매칭하여 이동 로봇의 현재 위치를 추정할 수 있다. 더욱 구체적으로, 제어부는, 코너에서, 벽의 특징점 들과의 거리를 바탕으로 벽의 기울기를 추정하고, 벽의 기울기를 맵 상에 저장된 벽의 기울기와 매칭시켜서, 이동 로봇의 현재 위치를 추정할 수 있다. 또는, 제어부는, 코너에서, 코너에서 인접한 벽의 특징점 들의 위치정보를 맵 상에 저장된 벽이 특징점 들의 위치정보와 매칭시켜서, 이동 로봇의 현재 위치를 추정할 수 있다. 매칭 방법은 제한이 없지 만, PSO(Particle Swarm Optimization) 또는 ICP(Iterative Closest Point)이 사용될 수 있다. 더더욱 구체적으로, 제어부는, 코너 주변정보 획득모션에서 코너에 대응되는 코너 획득 특징점 과, 제1 벽의 제1 획득 특징점들과, 제2 벽의 제2 회득 특징점들을 맵에 저장된 코너 특징 점과, 제1 특징점 및 제2 특징점을 매칭하여 이동 로봇의 현재 위치를 추정할 수 있다. 따라서, 본원 발명은 본체의 설치된 1-3개의 레이저 기반의 장애물 감지센서만으로, 슬램이 가능하므 로, 이동 로봇의 제조비용은 줄이면서, 코너에서 이동 로봇의 현재위치를 정확하게 추정하므로, 정확하고 신속한 주행이 가능한 이점이 존재한다. 제어부는 추정된 이동 로봇의 현재 위치와, 방향각을 바탕으로 코너 주변정보 획득 모션 이후의 이동 로봇의 헤딩 방향을 결정한다(S16). 구체적으로, 제어부는 벽의 특징점 들과의 거리를 바탕으로 벽의 기울기를 추정하고, 벽의 기울기와 나란한 방향으로 이동 로봇의 헤딩 방향을 결정할 수 있다. 도 6에서 도시하는 바와 같이, 제어부는 코너 주변정보 획득 모션 이후의 이동 로봇의 헤딩 방향을 제1 벽(1 1)과 나란한 X축 방향으로 결정한다. 제어부는 결정된 이동 로봇의 헤딩 방향으로 본체가 주행하도록 주행부를 제어한다(S17). 제어부는 코너 주변정보 획득 모션에서 획득한 코너 주변 지형 정보를 기반으로 기 저장된 맵(Map)를 업데이트할 수 있다(S18). 제어부는 벽의 특징점 들과의 거리를 바탕으로 벽의 기울기를 추정하고, 벽의 기울기를 맵에 업데이트하고, 각 코너의 위치 정보를 맵에 업데이트할 수 있다. 도 8는 본 발명의 다른 실시예에 따른 이동 로봇의 제어 방법을 도시하는 도면이다. 도 8을 참조하면, 본 발명의 일 실시예에 따른 이동 로봇은 제어부의 명령에 의해 맵 생성을 위한 주 행 명령을 수신한다. 이동 로봇은 주행 명령에 따라 청소 구역 내를 주행하면서 주변 환경에 대한 감지 정보를 수득한다. 구체 적으로, 이동 로봇은 맵 생성을 위해 월 팔로잉 주행을 수행할 수 있다(S20, S21). 이동 로봇은 센싱부에서 획득한 지형 정보를 통해 본체의 현재 위치가 주행 영역의 코너인 지 판단한다(S23). 이동 로봇은 장애물 감지센서에서 입력된 에지, 벽 및 장애물과의 거리 정보를 바탕으로 이동 로봇 의 현재 위치가 코너인지 판단한다. 구체적으로, 제어부는 2개의 벽이 만나는 지점을 코너로 정의하고, 본체가 코너에서 일정한 거리 이내에 위치되는 본체의 현재 위치가 코너라고 판단 한다. 이동 로봇은 현재 위치가 본체의 현재 위치가 코너인 경우, 코너에서 코너 주변의 지형 정보를 획득한다(S24). 구체적으로, 제어부는 본체가 코너에 위치된 경우, 코너에서 센싱부를 통해 코너 주변의 지형 정보를 획득하는 코너 주변정보 획득 모션을 하도록 제어한다. 제어부는 이동 로봇이 코너에 위치할 때 마다 코너 주변정보 획득 모션을 하도록 이동 로봇(10 0)을 제어한다. 또한, 코너 주변정보 획득 모션은 코너에서 일정 거리 이내 및 일정 각도 이내의 벽의 특징점 들과의 거리 를 추출하고, 각 코너의 위치정보를 출출하여 지형 정보를 획득할 수 있다. 제어부는 코너 주변정보 획득 모션에서 획득한 코너 주변 지형 정보를 기반으로 본체의 현재 위 치를 추정할 수 있다(S25). 코너 주변 지형 정보를 기반으로 본체의 현재 위치를 추정하는 방법은 도 3의 실시예와 동일하다. 제어부는 추정된 이동 로봇의 현재 위치와, 방향각을 바탕으로 코너 주변정보 획득 모션 이후의 이동 로봇의 헤딩 방향을 결정한다(S26). 제어부는 결정된 이동 로봇의 헤딩 방향으로 본체가 주행하도록 주행부를 제어한다(S27). 제어부는 이동 로봇의 현재 위치가 초기 위치인지 판단한다(S28). 도 9 및 도 10을 참조하면, 제어부는 이동 로봇의 현재 위치가 초기 위치인 경우, 각 코너의 위 치 정보와 각 코너에서 획득한 코너 주변 지형 정보를 바탕으로, 루프 디텍션(Loop detection) 및 루프 클로징(Loop closing)을 실행한다(S29). 루프 클로징(Loop closing)은 ELCH(Explicit Loop Closing Heuristics) 또 ICP(Iterative Closest Points) 방 법으로 루프 보정양을 통해 실행된다(S30). 루프 클로징을 통해 4개의 코너(21, 22, 23, 24)를 가지는 루프 가 생성되게 된다. 제어부는 루프 클로징(Loop closing) 바탕으로 새로운 맵을 생성하고, 새로운 맵을 저장부에 저장하거나 서버로 전송한다. 따라서, 본 발명은 본체의 전방에 2-3개 장애물 감지센서만 사용하여서, 구조가 간단하고, 제조 비용 이 저렴하며, 새로운 주행 구역에 대해 정확하고 비교적 신속하게 새로운 맵을 생성할 수 있다. 또한, 이상에서는 본 발명의 바람직한 실시예에 대하여 도시하고 설명하였지만, 본 발명은 상술한 특정의 실시"}
{"patent_id": "10-2022-0061570", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "예에 한정되지 아니하며, 청구범위에서 청구하는 본 발명의 요지를 벗어남이 없이 당해 발명이 속하는 기술분야 에서 통상의 지식을 가진 자에 의해 다양한 변형실시가 가능한 것은 물론이고, 이러한 변형실시들은 본 발명의 기술적 사상이나 전망으로부터 개별적으로 이해되어서는 안될 것이다."}
{"patent_id": "10-2022-0061570", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1는 본 발명의 다른 실시예에 따른 이동 로봇 및 이동 로봇을 충전시키는 충전대를 도시한 사시도이다. 도 2은 본 발명의 실시예에 따른 이동 로봇의 주요 구성들 간의 제어관계를 도시한 블록도이다. 도 3는 본 발명의 일 실시예에 따른 이동 로봇의 제어 방법을 도시한 순서도이다. 도 4 내지 도 6은 도 3의 제어 방법에 관한 설명에 참조되는 도면이다. 도 7은 코너 주변의 지형 정보를 통해 이동 로봇의 위치를 업데이트 하는 개념을 도시한 도면이다. 도 8는 본 발명의 다른 실시예에 따른 이동 로봇의 제어 방법을 도시하는 도면이다. 도 9는 본 발명의 루프 클로징 방법을 설명하는 도면이다."}
