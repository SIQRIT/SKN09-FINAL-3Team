{"patent_id": "10-2023-0100950", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2025-0019859", "출원번호": "10-2023-0100950", "발명의 명칭": "캐릭터 얼굴 생성방법 및 장치", "출원인": "에스케이텔레콤 주식회사", "발명자": "신승호"}}
{"patent_id": "10-2023-0100950", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "캐릭터 얼굴 생성장치가 캐릭터의 얼굴을 생성하는 방법에 있어서, 사용자의 얼굴이 포함된 영상, 상기 사용자의 음성, 및 상기 사용자가 입력한 텍스트 중 적어도 하나를 입력받는 과정;상기 영상, 상기 음성, 및 상기 텍스트 중 적어도 하나를 이용하여 상기 사용자의 감정을 인식하는 과정;상기 사용자의 감정을 이용하여, 상기 캐릭터의 감정을 수치로서 나타내는 감정확률을 생성하는 과정;상기 감정확률을 이용하여, 감정에 따른 캐릭터의 표정을 나타내는 캐릭터 블렌드쉐입(blendshape)의 수치를 계산하는 과정; 및상기 수치를 포함하는 캐릭터 블렌드쉐입을 이용하여 상기 캐릭터의 얼굴을 렌더링하는 과정을 포함하는, 방법."}
{"patent_id": "10-2023-0100950", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1 항에 있어서,상기 캐릭터의 감정확률을 생성하는 과정은,상기 영상을 이용하여 인식한 상기 사용자의 감정을 이용하여 캐릭터의 제1 감정확률을 생성하는 과정; 및상기 음성 및 상기 텍스트 중 적어도 어느 하나를 이용하여 인식한 상기 사용자의 감정을 이용하여 상기 캐릭터의 제2 감정확률을 생성하는 과정을 포함하는, 방법,"}
{"patent_id": "10-2023-0100950", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2 항에 있어서,상기 제1 감정확률을 생성하는 과정은, 사용자의 감정을 입력받아 캐릭터의 감정확률을 생성하도록 기 학습된 인공지능을 이용하여 상기 제1 감정확률을 생성하는 과정을 포함하는, 방법."}
{"patent_id": "10-2023-0100950", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제2 항에 있어서,상기 제1 감정확률을 생성하는 과정은, 기 입력된 감정표를 이용하여 상기 제1 감정확률을 생성하는 과정을 포함하는, 방법."}
{"patent_id": "10-2023-0100950", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제2 항에 있어서,상기 캐릭터의 감정확률을 생성하는 방법은,상기 제1 감정확률 및 상기 제2 감정확률을 이용하여 보간된 감정확률을 생성하는 과정을 더 포함하는 방법."}
{"patent_id": "10-2023-0100950", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제2 항에 있어서,공개특허 10-2025-0019859-3-상기 제2 감정확률을 생성하는 방법은, 대화형 인공지능이 생성한 상기 캐릭터의 감정확률을 이용하여 상기 제2감정확률을 생성하는, 방법."}
{"patent_id": "10-2023-0100950", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제5 항에 있어서,상기 캐릭터 블렌드쉐입의 수치를 계산하는 방법은,상기 보간된 감정확률, 및 가중치를 이용하여 캐릭터 블렌드쉐입의 수치를 계산하는, 방법."}
{"patent_id": "10-2023-0100950", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "명령어들을 저장하는 메모리; 및 적어도 하나의 프로세서를 포함하되,상기 적어도 하나의 프로세서는 상기 명령어들을 실행함으로써,사용자의 얼굴이 포함된 영상, 상기 사용자의 음성, 및 상기 사용자가 입력한 텍스트 중 적어도 하나를 입력받고,상기 영상, 상기 음성, 및 상기 텍스트 중 적어도 하나를 이용하여 상기 사용자의 감정을 인식하고,상기 사용자의 감정을 이용하여, 캐릭터의 감정을 수치로서 나타내는 감정확률을 생성하고,상기 감정확률을 이용하여, 감정에 따른 캐릭터의 표정을 나타내는 캐릭터 블렌드쉐입의 수치를 계산하고,상기 캐릭터 블렌드쉐입을 이용하여 상기 캐릭터의 얼굴을 렌더링하는 장치."}
{"patent_id": "10-2023-0100950", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "명령어가 저장된, 컴퓨터로 읽을 수 있는 기록매체로서, 상기 명령어는 상기 컴퓨터에 의해 실행될 때 상기 컴퓨터로 하여금, 제1 항 내지 제7 항 중 어느 한 항에 따른 방법이 포함하는 각 과정을 실행하도록 하는, 컴퓨터로 읽을 수 있는 기록매체."}
{"patent_id": "10-2023-0100950", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "캐릭터 얼굴 생성방법 및 장치를 개시한다. 본 개시의 일 측면에 의하면, 캐릭터 얼굴 생성장치가 캐릭터의 얼굴을 생성하는 방법에 있어서, 사용자의 얼굴 이 포함된 영상, 사용자의 음성, 및 사용자가 입력한 텍스트 중 적어도 하나를 입력받는 과정; 영상, 음성, 및 텍스트 중 적어도 하나를 이용하여 사용자의 감정을 인식하는 과정; 사용자의 감정을 이용하여, 캐릭터의 감정을 수치로서 나타내는 감정확률을 생성하는 과정; 감정확률을 이용하여, 감정에 따른 캐릭터의 표정을 나타내는 캐 릭터 블렌드쉐입의 수치를 계산하는 과정; 및 수치를 포함하는 캐릭터 블렌드쉐입을 이용하여 캐릭터의 얼굴을 렌더링하는 과정을 포함하는, 방법을 제공한다."}
{"patent_id": "10-2023-0100950", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 캐릭터 얼굴 생성방법 및 장치에 관한 것이다. 더욱 상세하게는, 캐릭터의 감정을 기반으로 한 캐릭 터 얼굴 생성방법 및 장치에 관한 것이다."}
{"patent_id": "10-2023-0100950", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "이하에 기술되는 내용은 단순히 본 실시예와 관련되는 배경 정보만을 제공할 뿐 종래기술을 구성하는 것이 아니 다. 인공지능 기술 발전에 따라, 사용자와 대화할 수 있는 대화형 인공지능 기술이 대두되고 있다. 대화형 인공지능 모델(conservational artificial intelligence model)은 사용자가 입력한 문장으로부터 문맥(context) 및 사용 자의 감정(emotion)을 파악하고, 상황에 맞는 대답을 생성함으로써 사용자와 대화할 수 있는 인공지능 모델을 말한다. 현재 대화형 인공지능 기술은 단순히 텍스트를 이용하여 사용자와 대화하는 것에 그치지 않고, tts(text-to-speech)등의 기술을 융합시켜 사용자와 음성 대화를 수행할 수 있다. 또한, 화면에 캐릭터를 표시 하여 캐릭터와 대화를 할 수도 있다. 화면에 캐릭터를 표시하여 사용자와 캐릭터 간 음성 대화를 수행하는 경우, 캐릭터와 사용자 간의 상호작용 (interaction)이 중요하다. 예컨대, 사용자의 발화에 따른 캐릭터의 반응이 필요하다. 이를 위해 캐릭터의 감정 상태를 파악하고, 감정 상태에 따른 캐릭터의 얼굴 표정을 생성하여 화면에 표시하여야 한다. 종래 캐릭터의 얼굴 표정을 생성하는 방법으로는, 미리 제작된 블렌드쉐입(blendshape)을 조합하여 캐릭터의 얼 굴 표정을 생성하는 방법이 있다. 블렌드쉐입을 이용하여 캐릭터의 얼굴 표정을 생성하는 방법을 캐릭터에 적용 하기 위하여 캐릭터가 표현해야 하는 감정을 생성하여야 한다. 종래 캐릭터의 감정을 생성하는 방법으로는, 대화형 인공지능과 사용자 간 대화 중 인공지능의 답변에 따른 감 정 상태를 생성하는 기술이 있다. 그러나 단순히 대화형 인공지능이 생성한 답변에 따라 감정 상태를 생성하는 경우, 대화형 인공지능이 사용자의 발화 의도(utterance intent)를 잘못 파악하는 등 오류를 일으킬 수 있다. 예컨대, 사용자가 슬픔에 대한 공감 을 바라고 발화를 하였음에도 대화형 인공지능이 이에 대해 잘못된 반응을 할 수 있다. 이러한 오류는 사용자 경험을 악화시킬 수 있다. 따라서, 대화형 인공지능 모델이 생성한 감정 상태만을 이용하여 캐릭터의 감정을 생성하지 않는 캐릭터의 감정 및 얼굴 표정을 생성하는 방법이 요구된다."}
{"patent_id": "10-2023-0100950", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 개시는, 캐릭터의 답변 및 사용자의 얼굴을 이용하여 캐릭터의 감정을 생성하고, 이에 따른 캐릭터의 얼굴 표정을 생성하는 방법을 제공하는 데 주된 목적이 있다. 본 발명이 해결하고자 하는 과제들은 이상에서 언급한 과제들로 제한되지 않으며, 언급되지 않은 또 다른 과제 들은 아래의 기재로부터 통상의 기술자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2023-0100950", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 개시의 일 측면에 의하면, 본 개시의 일 측면에 의하면, 캐릭터 얼굴 생성장치가 캐릭터의 얼굴을 생성하는 방법에 있어서, 사용자의 얼굴이 포함된 영상, 사용자의 음성, 및 사용자가 입력한 텍스트 중 적어도 하나를 입 력받는 과정; 영상, 음성, 및 텍스트 중 적어도 하나를 이용하여 사용자의 감정을 인식하는 과정; 사용자의 감 정을 이용하여, 캐릭터의 감정을 수치로서 나타내는 감정확률을 생성하는 과정; 감정확률을 이용하여, 감정에 따른 캐릭터의 표정을 나타내는 캐릭터 블렌드쉐입의 수치를 계산하는 과정; 및 캐릭터 블렌드쉐입을 이용하여 캐릭터의 얼굴을 렌더링하는 과정을 포함하는, 방법을 제공한다. 본 개시의 다른 측면에 의하면, 명령어들을 저장하는 메모리; 및 적어도 하나의 프로세서를 포함하되, 적어도 하나의 프로세서는 명령어들을 실행함으로써, 사용자의 얼굴이 포함된 영상, 사용자의 음성, 및 사용자가 입력 한 텍스트 중 적어도 하나를 입력받고, 영상, 음성, 및 텍스트 중 적어도 하나를 이용하여 사용자의 감정을 인 식하고, 사용자의 감정을 이용하여, 캐릭터의 감정을 수치로서 나타내는 감정확률을 생성하고, 감정확률을 이용 하여, 감정에 따른 캐릭터의 표정을 나타내는 캐릭터 블렌드쉐입의 수치를 계산하고, 캐릭터 블렌드쉐입을 이용 하여 캐릭터의 얼굴을 렌더링하는 장치를 제공한다."}
{"patent_id": "10-2023-0100950", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 개시의 실시예에 의하면, 캐릭터의 답변 및 사용자의 얼굴을 이용하여 캐릭터의 감정 및 감정확률을 생성하 고, 캐릭터의 감정확률을 보간하고 가중치를 적용함으로써 더욱 상황에 맞는 캐릭터의 얼굴 표정을 생성하는 방 법을 제공할 수 있다는 효과가 있다. 본 개시의 효과들은 이상에서 언급한 효과들로 제한되지 않으며, 언급되지 않은 또 다른 효과들은 아래의 기재 로부터 통상의 기술자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2023-0100950", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 본 개시의 일부 실시예들을 예시적인 도면을 이용해 상세하게 설명한다. 각 도면의 구성 요소들에 참조 부호를 부가함에 있어서, 동일한 구성 요소들에 대해서는 비록 다른 도면 상에 표시되더라도 가능한 한 동일한 부호를 가지도록 하고 있음에 유의해야 한다. 또한, 본 개시를 설명함에 있어, 관련된 공지 구성 또는 기능에대한 구체적인 설명이 본 개시의 요지를 흐릴 수 있다고 판단되는 경우에는 그 상세한 설명은 생략한다. 본 개시에 따른 실시예의 구성요소를 설명하는 데 있어서, 제1, 제2, i), ii), a), b) 등의 부호를 사용할 수 있다. 이러한 부호는 그 구성요소를 다른 구성 요소와 구별하기 위한 것일 뿐, 그 부호에 의해 해당 구성요소의 본질 또는 차례나 순서 등이 한정되지 않는다. 명세서에서 어떤 부분이 어떤 구성요소를 '포함' 또는 '구비'한 다고 할 때, 이는 명시적으로 반대되는 기재가 없는 한 다른 구성요소를 제외하는 것이 아니라 다른 구성요소를 더 포함할 수 있는 것을 의미한다. 첨부된 도면과 함께 이하에 개시될 상세한 설명은 본 개시의 예시적인 실시형태를 설명하고자 하는 것이며, 본 개시가 실시될 수 있는 유일한 실시형태를 나타내고자 하는 것이 아니다. 도 1은 본 개시의 일 실시예에 따른 캐릭터 얼굴 생성장치를 개략적으로 나타낸 블록구성도이다. 도 1을 참조하면, 캐릭터 얼굴 생성장치(character face generation apparatus, 10)은 입력부(input unit, 100), 감정생성부(emotion generation unit, 110), 블렌드쉐입부(blendshape unit, 140), 및 얼굴생성부(face generation unit, 150)를 전부 또는 일부 포함한다. 한편, 도 1에 도시된 구성요소들은 기능적으로 구분되는 요 소들을 나타낸 것으로서, 적어도 하나의 구성요소가 실제 물리적 환경에서는 서로 통합되는 형태로 구현될 수도 있다. 입력부는 영상(image), 음성(voice) 및 텍스트(text)를 전부 또는 일부 입력받는다. 여기서, 대화 텍스트 란 대화 내용이 포함된 텍스트를 의미한다. 입력부는 영상을 촬영하기 위한 카메라를 포함할 수 있다. 입력부는 사용자와 인공지능 간의 대화를 입력받을 수 있다. 예컨대, 입력부는 사용자의 음성을 입력 받기 위한 마이크를 포함할 수 있다. 입력부는 마이크를 이용하여 입력받은 음성을 텍스트로 변환할 수 있 다. 감정생성부는 입력받은 영상 및/또는 텍스트를 이용하여 감정을 생성한다. 여기서 감정은, 사용자의 감정 및 캐릭터의 감정을 포함한다. 감정생성부는 제1 생성부(first generation unit, 120) 및/또는 제2 생성 부(second generation unit, 130)를 포함한다. 제1 생성부는 사용자 감정(user's emotion)을 인식할 수 있다. 제1 생성부는 영상으로부터 사용자 감 정을 인식(recognize)할 수 있다. 제1 생성부는 인공지능 모델(artificial intelligence model, 이하 “ ai model”)을 이용하여 사용자 감정을 인식할 수 있다. 예컨대, 제1 생성부는 제1 인공지능 모델(first ai model)을 이용하여 사용자의 감정을 인식할 수 있다. 여기서 제1 인공지능 모델은 사람의 얼굴이 포함된 영 상을 입력하면 사람의 감정을 출력하도록 기 학습된 인공지능 모델이다. 본 개시의 일 실시예에 따르면, 감정(emotion)은 수치로서 표현될 수 있다. 예컨대, '기쁨(delight)' 감정은 0.0 내지 1.0 사이의 수치로서 표현될 수 있다. 감정을 표현하는 수치를 감정확률(probability of emotion)이라 고 한다. 기쁨을 느끼지 않는 경우, 기쁨의 감정확률은 0.0으로 표현될 수 있다. 가장 큰 기쁨을 느끼는 경우, 기쁨의 감정확률은 1.0으로 표현될 수 있다. 감정은 기쁨, 슬픔(sad), 놀람(surprise), 분노(angry), 공포 (fear), 싫음(dislike) 등을 포함할 수 있다. 감정은 예컨대, 벡터 또는 행렬로서 표현될 수 있다. 모든 감정확 률의 합계는 1이다. 제1 생성부는 인식한 사용자 감정을 이용하여 캐릭터의 감정 및 감정확률을 생성할 수 있다. 제1 생성부 가 생성한 캐릭터의 감정확률을 제1 감정확률(first probability of emotion)이라고 한다. 제1 생성부 는 일반적인 대화를 할 때, 대화의 양 당사자의 감정이 유사한 것을 이용하여 캐릭터의 감정 및 감정확률 을 생성할 수 있다. 본 개시의 일 실시예에 따르면, 제1 생성부는 기 입력된 감정표(emotion table)를 이용하여 캐릭터의 감정 확률을 생성할 수 있다. 여기서, 감정표는 대화의 당사자들 중 일방과 이에 대응하는 상대방의 감정 및 감정확 률을 표시한 것이다. 즉, 제1 생성부는 감정표를 이용하여, 인식한 사용자의 감정에 대응하는 캐릭터의 감 정확률을 생성할 수 있다. 본 개시의 다른 실시예에 따르면, 제1 생성부는 제2 인공지능 모델(second ai model)을 포함할 수 있다. 여기서 제2 인공지능 모델은, 대화 상대방, 즉 사용자의 감정을 입력받아 캐릭터의 감정확률을 생성하도록 기 학습된 인공지능 모델이다. 제2 인공지능 모델은 대화 영상 데이터를 이용하여 학습될 수 있다. 도 2는 사용자의 감정을 입력받아 그에 대응하는 캐릭터의 감정과 이에 대응하는 감정확률을 생성하는 제2 인공 지능 모델을 학습시키는 방법을 도시한 순서도이다. 도 2를 참조하면, 제1 인공지능 모델은 대화 영상 데이터셋을 입력받는다(S200). 여기서 대화 영상 데이터셋은 적어도 두 사람이 대화하는 영상 및 음성 데이터를 포함할 수 있다. 제1 인공지능 모델은 대화 영상 데이터셋을 입력받아, 대화하는 사람들의 감정을 인식한다(S210). 제2 인공지능 모델은 대화 당사자들 중 일방의 감정을 입력받으면, 대화 상대방의 감정을 추정하도록 학습된다. 제2 인공지능 모델은 제1 인공지능 모델이 출력한 대화 당사자들 중 일방의 감정을 입력받는다(S220). 제2 인공 지능 모델은 입력된 일방의 감정을 이용하여, 대화 상대방의 감정을 추정한다. 제2 인공지능 모델은 가중치 및 입력받은 감정을 이용하여 대화 상대방의 감정 및 감정확률을 추정한다(S230). 즉, 제2 인공지능 모델은 대화하는 사람 중 일방의 얼굴을 입력으로 하여, 대화 상대방의 감정을 추정하도록 학 습된다. 제2 인공지능 모델은 추정한 대화 상대방의 감정을 제1 인공지능 모델이 출력한 대화 상대방의 감정과 비교한다 (S240). 제2 인공지능 모델이 추정한 감정과 제1 인공지능 모델이 추정한 감정이 동일하다면, 제2 인공지능 모 델의 학습을 종료한다. 두 감정이 동일하지 않다면, 가중치(weight)를 변경하고 대화 상대방의 감정을 다시 추 정한다(S250). 다시 말해, 제2 인공지능 모델은 추정한 감정과 제1 인공지능 모델이 인식한 감정의 차이를 이용 하여 가중치를 변경하는 방법으로 학습된다. 즉, 제2 인공지능 모델은 제1 인공지능 모델이 출력한 감정을 정답 으로서 지도학습(supervised learning)된다. 제1 생성부는 학습된 제2 인공지능 모델이 추정한 대화 상대방의 감정 및 감정확률을 캐릭터의 감정 및 감 정확률로서 생성할 수 있다. 다시 말해, 제1 생성부는 대화 상대방, 즉 사용자의 얼굴을 입력받아 캐릭터 의 감정을 생성하도록 기 학습된 제2 인공지능 모델이 추정한 상대방의 감정 및 감정확률을 캐릭터의 감정 및 감정확률로서 생성할 수 있다. 제2 생성부는 사용자의 음성 및/또는 사용자가 입력한 텍스트로부터 캐릭터의 감정 및 감정확률을 생성한 다. 제2 생성부는 사용자와 대화할 수 있는 대화형 인공지능 모델(conservational ai model)을 포함할 수 있다. 대화형 인공지능 모델이란, 사용자와 대화를 나눌 수 있는 인공지능 모델을 말한다. 대화형 인공지능 모 델은 사용자가 음성 및/또는 텍스트를 이용하여 입력한 문장 및/또는 단어의 문맥(context) 및 사용자의 감정을 파악한다. 대화형 인공지능 모델은 파악한 문맥 및 감정에 맞는 답변을 생성할 수 있다. 또한, 대화형 인공지능 모델은 답변 생성과 동시에 캐릭터의 감정 및 감정확률을 생성할 수 있다. 제2 생성부 가 생성한 캐릭터의 감정확률을 제2 감정확률(second probability of emotion)이라 한다. 대화형 인공지 능 모델은 텍스트를 이용하여 답변을 출력할 수 있다. 대화형 인공지능 모델은 tts(text-to-speech)기술을 이용 하여 생성한 답변을 음성을 이용하여 출력할 수 있다. 다시 말해, 제2 생성부는 사용자의 음성 및/또는 텍스트를 입력받아 사용자의 감정을 인식하고, 인식한 사 용자의 감정을 이용하여 감정에 맞는 답변, 캐릭터의 감정 및 감정확률을 생성할 수 있다. 본 개시의 일 실시예에 따른, 인공지능 모델은 다양한 방법으로 구현될 수 있다. 예컨대, 인공지능 모델은 CNN(convolutional neural network) 또는 RNN(recurrent neural network)과 같은 인공신경망(artificial neural network)을 포함하는 인공지능 모델일 수 있다. 감정생성부는 제1 감정확률 및 제2 감정확률을 이용하여 캐릭터의 감정을 생성할 수 있다. 감정생성부 는 제1 감정확률 및 제2 감정확률을 보간함으로써 보간된 감정(interpolated emotion)을 생성할 수 있다. 보간된 감정은 기쁨, 슬픔, 놀람 등의 감정 및 각 감정의 정도를 나타내는 수치인 감정확률을 포함한다. 보간된 감정확률은 수학식 1과 같이 계산할 수 있다. 수학식 1"}
{"patent_id": "10-2023-0100950", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "여기서, a 및 b는 각각 제1 생성부 및 제2 생성부가 추정한 캐릭터의 감정을 보간하기 위한 계수 (coefficient)이다. 및 는 각각 제1 생성부가 추정한 캐릭터의 감정확률, 및 제2 생성부가 추 정한 캐릭터의 감정확률을 의미한다. 아래첨자 i는, 기쁨, 슬픔 등과 같은 감정을 나타낸다. 예컨대, i=1은 기 쁨, i=2는 슬픔, i=3은 놀람에 대응될 수 있다. 계수 a 및 b는 사용자에 의해 입력될 수 있다. 다시 말해, 계수 a 및 b는 변경될 수 있다. 계수 a 및 b는 각각 0 내지 1 사이의 실수값을 가질 수 있다. 그러나, 계수 a 와 b 의 합은 1 이어야 한다. 블렌드쉐입부는 보간된 감정확률 및 기 설정된 블렌드쉐입을 이용하여 캐릭터 블렌드쉐입의 각 수치들을 계산한다. 캐릭터 블렌드쉐입이란, 캐릭터의 얼굴 애니메이션을 생성하기 위한 블렌드쉐입을 말한다. 여기서 블 렌드쉐입이란, 미리 생성해 놓은 표정 애니메이션을 결합하여 캐릭터의 얼굴을 생성하기 위한 정보를 의미한다. 블렌드쉐입은 복수의 표정들(facial expressions)을 포함할 수 있다. 예를 들어, 하나의 블렌드쉐입은 (smile, eyeblink) 등의 복수의 표정들, 및 표정들 중 하나에 각각 대응하는 복수의 표정값들(facial expression values)을 포함할 수 있다. 표정값은 대응하는 표정의 강도(intensity)를 의미한다. 하나의 블렌드쉐입은 벡터 또는 행렬을 이용하여 수학적으로 표현될 수 있다. 다시 말해, 블렌드쉐입은 수치로서 표현될 수 있다. 하나의 표정 애니메이션이 하나의 표정 및 표정값에 대응할 수 있다. 예를 들어 표정 smile의 표정값이 0.0 인 경우, 웃지 않는 표정 애니메이션에 대응된다. 표정 smile의 표정값이 1.0인 경우, 활짝 웃는 표정 애니메이션 에 대응된다. 각 표정값은 0.0 내지 1.0 사이의 실수값이다. 다시 말해, 각 표정값의 최대값은 1.0이고, 최소값 은 0.0이다. 하나의 감정마다 하나의 대응하는 블렌드쉐입이 존재할 수 있다. 예컨대, '기쁨' 감정에 대응하는 블렌드쉐입은 (smile 1.0, eyeblink 0.7, …)과 같은 표정 및 표정값으로서 표현될 수 있다. 블렌드쉐입부는 보간된 감정확률을 이용하여 캐릭터 블렌드쉐입(character blendshape)을 계산할 수 있다. 블렌드쉐입부는 각 감정의 보간된 감정확률과 해당 감정에 대응하는 블렌드쉐입을 곱하여 캐릭터 블렌드쉐 입을 계산할 수 있다. 즉, 캐릭터 블렌드쉐입은 각 감정마다 계산될 수 있다. 감정별 캐릭터 블렌드쉐입을 계산 하는 방법은 수학식 2와 같다. 수학식 2"}
{"patent_id": "10-2023-0100950", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "여기서, 아래첨자 i는 각 감정을 나타낸다. 는 가중치를, 는 해당 감정에 대응하는 블렌드쉐입을, 는 보간된 감정확률을 각각 나타낸다. 여기서 블렌드쉐입 는 벡터 또는 행렬으로서 표현될 수 있다. 가중치( )는 각 감정마다 다를 수 있다. 다시 말해, 가중치를 각 감정별로 다르게 함으로써 감정의 중요도에 따라 비중을 달리하여 캐릭터 블렌드쉐입을 생성할 수 있다. 가중치는 0.0 내지 1.0 사이의 어떤 실수값일 수 있다. 가중치의 총 합은 1이다. 다시 말해, 이다. 가중치는 사용자에 의해 입력될 수 있다. 캐릭터 블렌드쉐입은 감정별 캐릭터 블렌드쉐입을 모두 더함으로써 계산할 수 있다. 캐릭터생성부는 블렌드쉐입부가 계산한 캐릭터 블렌드쉐입을 이용하여 캐릭터의 얼굴 애니메이션을 렌더링 (rendering)한다. 예컨대 캐릭터생성부는 캐릭터 블렌드쉐입에 포함된 각 표정값에 대응하는 표정 애니메이션을 이용하여 캐릭터의 얼굴 애니메이션을 렌더링할 수 있다. 블렌드쉐입을 이용하여 얼굴 애니메이션을 렌더링하는 방법은 공지된 것으로서, 이에 대한 자세한 설명은 생략한다. 도 3은 본 개시의 일 실시예에 따른 캐릭터의 얼굴을 생성하기 위한 방법을 도시한 순서도이다. 도 3을 참조하면, 입력부는 영상, 음성, 및 텍스트 데이터를 전부 또는 일부 입력받는다(S300). 입력부 는 카메라 및/또는 마이크를 이용하여 영상 및/또는 음성 데이터를 입력받을 수 있다. 제1 생성부는 영상으로부터 사용자의 감정을 인식한다. 제1 생성부는 인식한 사용자의 감정을 이용하 여, 제1 감정확률을 생성한다(S310). 제1 생성부는 감정표를 이용하여 제1 감정확률을 생성할 수 있다. 또는, 제1 생성부는 기 학습된 인공지능 모델, 즉 제2 인공지능 모델을 이용하여 제1 감정확률을 생성할 수 있다. 제2 생성부는 대화형 인공지능 모델이 생성한 텍스트로부터 제2 감정확률을 생성한다(S320). 감정생성부는 제1 감정확률 및 제2 감정확률로부터 보간된 감정을 생성한다(S330). 감정생성부는 계 수 a 및 b를 이용하여 보간된 감정을 생성할 수 있다. 즉, 감정생성부는 영상 및 텍스트를 모두 이용하여 캐릭터의 감정을 생성할 수 있다. 블렌드쉐입부는 보간된 감정으로부터 캐릭터 블렌드쉐입을 계산한다(S340). 블렌드쉐입부는 가중치와 보간된 감정확률 및 기 설정된 블렌드쉐입을 이용하여 캐릭터 블렌드쉐입을 계산할 수 있다. 얼굴생성부는 캐릭터 블렌드쉐입을 이용하여 캐릭터의 얼굴 애니메이션을 렌더링함으로써 캐릭터의 얼굴 및 얼굴 표정을 생성할 수 있다(S350). 본 발명에 따른 장치 또는 방법의 각 구성요소는 하드웨어 또는 소프트웨어로 구현되거나, 하드웨어 및 소프트 웨어의 결합으로 구현될 수 있다. 또한, 각 구성요소의 기능이 소프트웨어로 구현되고 마이크로프로세서가 각 구성요소에 대응하는 소프트웨어의 기능을 실행하도록 구현될 수도 있다. 본 명세서에 설명되는 시스템들 및 기법들의 다양한 구현예들은, 디지털 전자 회로, 집적회로, FPGA(field programmable gate array), ASIC(application specific integrated circuit), 컴퓨터 하드웨어, 펌웨어, 소프 트웨어, 및/또는 이들의 조합으로 실현될 수 있다. 이러한 다양한 구현예들은 프로그래밍가능 시스템 상에서 실 행 가능한 하나 이상의 컴퓨터 프로그램들로 구현되는 것을 포함할 수 있다. 프로그래밍가능 시스템은, 저장 시 스템, 적어도 하나의 입력 디바이스, 그리고 적어도 하나의 출력 디바이스로부터 데이터 및 명령들을 수신하고 이들에게 데이터 및 명령들을 전송하도록 결합되는 적어도 하나의 프로그래밍가능 프로세서(이것은 특수 목적 프로세서일 수 있거나 혹은 범용 프로세서일 수 있음)를 포함한다. 컴퓨터 프로그램들(이것은 또한 프로그램들, 소프트웨어, 소프트웨어 애플리케이션들 혹은 코드로서 알려져 있음)은 프로그래밍가능 프로세서에 대한 명령어 들을 포함하며 \"컴퓨터가 읽을 수 있는 기록매체\"에 저장된다. 컴퓨터가 읽을 수 있는 기록매체는, 컴퓨터 시스템에 의하여 읽혀질 수 있는 데이터가 저장되는 모든 종류의 기 록장치를 포함한다. 이러한 컴퓨터가 읽을 수 있는 기록매체는 ROM, CD-ROM, 자기 테이프, 플로피디스크, 메모 리 카드, 하드 디스크, 광자기 디스크, 스토리지 디바이스 등의 비휘발성(non-volatile) 또는 비일시적인(non- transitory) 매체일 수 있으며, 또한 데이터 전송 매체(data transmission medium)와 같은 일시적인 (transitory) 매체를 더 포함할 수도 있다. 또한, 컴퓨터가 읽을 수 있는 기록매체는 네트워크로 연결된 컴퓨터 시스템에 분산되어, 분산방식으로 컴퓨터가 읽을 수 있는 코드가 저장되고 실행될 수도 있다. 본 명세서의 흐름도/타이밍도에서는 각 과정들을 순차적으로 실행하는 것으로 기재하고 있으나, 이는 본 개시의 일 실시예의 기술 사상을 예시적으로 설명한 것에 불과한 것이다. 다시 말해, 본 개시의 일 실시예가 속하는 기 술 분야에서 통상의 지식을 가진 자라면 본 개시의 일 실시예의 본질적인 특성에서 벗어나지 않는 범위에서 흐 름도/타이밍도에 기재된 순서를 변경하여 실행하거나 각 과정들 중 하나 이상의 과정을 병렬적으로 실행하는 것으로 다양하게 수정 및 변형하여 적용 가능할 것이므로, 흐름도/타이밍도는 시계열적인 순서로 한정되는 것은 아니다. 이상의 설명은 본 실시예의 기술 사상을 예시적으로 설명한 것에 불과한 것으로서, 본 실시예가 속하는 기술 분 야에서 통상의 지식을 가진 자라면 본 실시예의 본질적인 특성에서 벗어나지 않는 범위에서 다양한 수정 및 변 형이 가능할 것이다. 따라서, 본 실시예들은 본 실시예의 기술 사상을 한정하기 위한 것이 아니라 설명하기 위 한 것이고, 이러한 실시예에 의하여 본 실시예의 기술 사상의 범위가 한정되는 것은 아니다. 본 실시예의 보호 범위는 아래의 청구범위에 의하여 해석되어야 하며, 그와 동등한 범위 내에 있는 모든 기술 사상은 본 실시예의 권리범위에 포함되는 것으로 해석되어야 할 것이다."}
{"patent_id": "10-2023-0100950", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 개시의 일 실시예에 따른 캐릭터 얼굴 생성장치를 개략적으로 나타낸 블록구성도이다. 도 2는 사용자의 감정을 입력받아 그에 대응하는 캐릭터의 감정과 이에 대응하는 감정확률을 생성하는 제2 인공 지능 모델을 학습시키는 방법을 도시한 순서도이다. 도 3은 본 개시의 일 실시예에 따른 캐릭터의 얼굴을 생성하기 위한 방법을 도시한 순서도이다."}
