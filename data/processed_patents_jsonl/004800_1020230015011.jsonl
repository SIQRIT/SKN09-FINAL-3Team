{"patent_id": "10-2023-0015011", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0122167", "출원번호": "10-2023-0015011", "발명의 명칭": "CXL 기반 컴퓨팅 시스템, 그리고 인공지능 모델 훈련을 위한 동작 방법", "출원인": "한국과학기술원", "발명자": "정명수"}}
{"patent_id": "10-2023-0015011", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "CXL(Compute Express Link)을 지원하는 GPU(CXL-GPU), 그리고상기 CXL-GPU와 캐시 일관성 도메인으로 통합되고, 적어도 하나의 메모리 모듈을 포함하는 메모리 확장기(CXL-MEM)를 포함하는 CXL 컴퓨팅 시스템."}
{"patent_id": "10-2023-0015011", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에서,상기 CXL-GPU 및 상기 CXL-MEM은 CXL.io, CXL.cache, 그리고 CXL.mem 프로토콜들을 지원하는 유형2의 CXL 장치이고,상기 CXL-GPU 및 상기 CXL-MEM은 상기 CXL.cache를 통해 서로 데이터를 주고받는, CXL 컴퓨팅 시스템."}
{"patent_id": "10-2023-0015011", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에서,상기 CXL-GPU와 상기 CXL-MEM 중 어느 장치가 데이터를 플러시(flush)하면, 상기 데이터는 다른 장치의 지정된메모리로 자동 이동하여 저장되는, CXL 컴퓨팅 시스템."}
{"patent_id": "10-2023-0015011", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에서,상기 CXL-MEM은모델 훈련의 작업들 중, 배치마다의 임베딩 작업을 수행하는, CXL 컴퓨팅 시스템."}
{"patent_id": "10-2023-0015011", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에서,상기 CXL-MEM은이전 배치의 임베딩 테이블을 사용한 임베딩 룩업 작업을 통해 현재 배치의 임베딩 벡터를 임시로 생성하고, 상기 이전 배치의 훈련 결과를 기초로 상기 임베딩 벡터를 업데이트하여 상기 현재 배치의 임베딩 벡터를 생성하는, CXL 컴퓨팅 시스템."}
{"patent_id": "10-2023-0015011", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제4항에서,상기 CXL-MEM은현재 배치에 대한 임베딩 작업의 체크포인트를 위해, 상 상기 임베딩 작업의 임베딩 로그를 메모리 모듈에 저장하는, CXL 컴퓨팅 시스템."}
{"patent_id": "10-2023-0015011", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6항에서,상기 CXL-MEM은메모리 매핑된 레지스터에 설정된 현재 배치 정보를 참조해서 상기 메모리 모듈의 데이터 영역에 있는 임베딩공개특허 10-2024-0122167-3-벡터를 로그 영역으로 복사하여 현재 배치에 대한 상기 임베딩 로그를 저장하고, 상기 임베딩 로그에 대한 영구플래그를 설정하는, CXL 컴퓨팅 시스템."}
{"patent_id": "10-2023-0015011", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1항에서,상기 CXL-MEM은 메모리 매핑된 레지스터에 설정된 모델 매개변수들의 메모리 주소와 크기를 참조하여, 상기 CXL-GPU로CXL.cache 요청을 보내고, 상기 CXL-GPU로부터, 현재 배치에 대한 모델 훈련을 통해 저장된 모델 매개변수들을응답받으면, 상기 모델 매개변수들을 메모리 모듈의 로그 영역에 저장하고, 모델 로그에 대한 영구 플래그를 설정하는, CXL 컴퓨팅 시스템."}
{"patent_id": "10-2023-0015011", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에서,상기 CXL-MEM은 여러 배치에 걸쳐 상기 모델 로그를 저장하도록 스케줄링하는, CXL 컴퓨팅 시스템."}
{"patent_id": "10-2023-0015011", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제1항에서,상기 CXL-MEM은상기 적어도 하나의 메모리 모듈 및 해당 메모리 모듈을 제어하는 메모리 컨트롤러, 메모리 매핑된 레지스터, 그리고 내부 캐시라인 상태들을 관리하는 장치 일관성 엔진(Device Coherency Engine,DCOH)을 포함하는 CXL 컨트롤러, 그리고모델 훈련을 위한 컴퓨팅 로직 및 체크포인트 로직을 포함하는, CXL 컴퓨팅 시스템."}
{"patent_id": "10-2023-0015011", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "적어도 하나의 메모리 모듈 및 해당 메모리 모듈을 제어하는 메모리 컨트롤러, 메모리 매핑된 레지스터, 그리고 내부 캐시라인 상태들을 관리하는 장치 일관성 엔진(Device Coherency Engine,DCOH)을 포함하는 CXL(Compute Express Link) 컨트롤러, 모델 훈련의 작업들 중에서, 배치마다의 임베딩 작업을 수행하는 컴퓨팅 로직, 그리고모델 훈련의 장애 허용성 관리를 위해, 상기 임베딩 작업으로 얻은 임베딩 로그 및 모델 훈련을 통해 저장된 모델 매개변수들을 상기 메모리 모듈에 저장하는 체크포인트 로직을 포함하는 CXL 기반 메모리 확장기."}
{"patent_id": "10-2023-0015011", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항에서,상기 CXL 컨트롤러는CXL.io, CXL.cache, 그리고 CXL.mem 프로토콜들을 실행하는 유형2의 컨트롤러인, CXL 기반 메모리 확장기."}
{"patent_id": "10-2023-0015011", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제11항에서,상기 CXL 컨트롤러가 상기 임베딩 작업으로 생성된 축소된 임베딩 벡터의 캐시라인을 플러시(flush)하면, 상기축소된 임베딩 벡터는 캐시 일관성 도메인으로 통합된 CXL 장치로 자동 이동하여 저장되는, CXL 기반 메모리 확장기.공개특허 10-2024-0122167-4-청구항 14 제11항에서,상기 체크포인트 로직은상기 메모리 매핑된 레지스터에 설정된 현재 배치 정보를 참조해서 상기 메모리 모듈의 데이터 영역에 있는 임베딩 벡터를 로그 영역으로 복사하여 현재 배치에 대한 상기 임베딩 로그를 저장하고, 상기 임베딩 로그에 대한영구 플래그를 설정하는, CXL 기반 메모리 확장기."}
{"patent_id": "10-2023-0015011", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제11항에서,상기 체크포인트 로직은상기 메모리 매핑된 레지스터에 설정된 모델 매개변수들의 메모리 주소와 크기를 참조하여, CXL 장치로CXL.cache 요청을 보내고, 상기 CXL 장치로부터, 현재 배치에 대한 모델 훈련을 통해 저장된 상기 모델 매개변수들을 응답받으면, 상기 모델 매개변수들을 상기 메모리 모듈의 로그 영역에 저장하고, 모델 로그에 대한 영구플래그를 설정하는, CXL 기반 메모리 확장기."}
{"patent_id": "10-2023-0015011", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제15항에서,상기 CXL 장치는상기 모델 훈련의 주된 훈련을 수행하는 CXL 기반의 GPU(CXL-GPU)인, CXL 기반 메모리 확장기."}
{"patent_id": "10-2023-0015011", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제15항에서,상기 체크포인트 로직은여러 배치에 걸쳐 상기 모델 로그를 저장하도록 스케줄링하는, CXL 기반 메모리 확장기."}
{"patent_id": "10-2023-0015011", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "CXL(Compute Express Link)을 지원하는 GPU(CXL-GPU)와 연동하여 모델 훈련을 수행하는 CXL 기반 메모리 확장기의 동작 방법으로서,현재 배치에 대한 임베딩 룩업 작업을 수행하여, 상기 현재 배치의 임베딩 벡터를 생성하는 단계,상기 현재 배치의 임베딩 벡터를 캐시 일관성 도메인에 통합된 상기 CXL-GPU의 메모리로 플러시(flush)하는 단계, 그리고상기 CXL-GPU에서의 모델 훈련 결과를 반영하여, 상기 메모리 모듈에 저장된 임베딩 테이블을 업데이트하는 단계를 포함하는 동작 방법."}
{"patent_id": "10-2023-0015011", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제18항에서,상기 임베딩 테이블을 업데이트 전에, 메모리 매핑된 레지스터에 설정된 현재 배치 정보를 참조해서 상기 임베딩 룩업 작업으로 얻은 임베딩 로그를 메모리 모듈에 저장함으로써, 상기 현재 배치의 임베딩 작업에 대한 체크포인트를 생성하는 단계를 더 포함하는 동작 방법."}
{"patent_id": "10-2023-0015011", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "공개특허 10-2024-0122167-5-제18항에서,메모리 매핑된 레지스터에 설정된 모델 매개변수들의 메모리 주소와 크기를 참조하여, 상기 현재 배치에 대한모델 훈련을 통해 저장된 모델 매개변수들을 상기 CXL-GPU로부터 응답받으면, 상기 모델 매개변수들을 상기 메모리 모듈의 로그 영역에 저장함으로써, 상기 현재 배치로 훈련된 모델에 대한 체크포인트를 생성하는 단계를 더 포함하는 동작 방법."}
{"patent_id": "10-2023-0015011", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "CXL 컴퓨팅 시스템은 CXL을 지원하는 GPU(CXL-GPU), 그리고 상기 CXL-GLU와 캐시 일관성 도메인으로 통합되고, 적어도 하나의 메모리 모듈을 포함하는 메모리 확장기(CXL-MEM)를 포함한다. CXL-MEM는 적어도 하나의 메모리 모 듈 및 해당 메모리 모듈을 제어하는 메모리 컨트롤러, 메모리 매핑된 레지스터, 그리고 내부 캐시라인 상태들을 관리하는 장치 일관성 엔진(Device Coherency Engine, DCOH)을 포함하는 CXL(Compute Express Link) 컨트롤러, 모델 훈련의 작업들 중에서, 배치마다의 임베딩 작업을 수행하는 컴퓨팅 로직, 그리고 모델 훈련의 장애 허용성 관리를 위해, 상기 임베딩 작업으로 얻은 임베딩 로그 및 모델 훈련을 통해 저장된 모델 매개변수들을 상기 메모 리 모듈에 저장하는 체크포인트 로직을 포함한다."}
{"patent_id": "10-2023-0015011", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 컴퓨트 익스프레스 링크(Compute Express Link, CXL)에 관한 것이다."}
{"patent_id": "10-2023-0015011", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "추천 시스템은 사용자가 관심을 가질 만한 정보(영화, 음악, 책, 뉴스, 이미지, 웹 페이지 등)를 먼저 제시하는 시스템으로서, 유튜브, 페이스북, 아마존 등의 다양한 서비스들이 딥러닝 기반의 추천 시스템을 활용하고 있다. 추천 시스템을 활용하는 서비스들은 사용자의 만족도를 높일 수 있고, 결과적으로 매출을 늘릴 수 있다. 이처럼, 추천 시스템은 비즈니스에 가장 광범위하게 적용이 가능한 실용적인 기술이다. 오늘날의 딥러닝 기반 추천 시스템은 다양한 프로덕션 서버(production server) 및 데이터 센터에서 머신 리소 스의 대부분을 사용한다. 실제로 광범위한 프로덕션 수준의 추천 모델(production-level recommendation model, RM)은, 사용자 유치 및 수익에서의 손실을 방지하기 위해, 매우 정확한 서비스가 필요하다. 이를 위해, RM은 학습을 위한 대형 모델과 특징 벡터가 필요한데, 이는 트랜스포머(Transformers)와 같이 가장 큰 심층 신 경망 모델보다도 훨씬 더 큰 모델일 수 있다. 여러 연구에 따르면 프로덕션 수준의 RM은 종종 수십 테라바이트 또는 페타바이트 이상의 메모리 공간을 소비한 다. 또한, RM은 정확도 저하 없이 며칠 또는 몇 주 동안 학습되어야 하므로 장애 허용성(failure tolerant)이 있어야 한다. 이를 위해, RM은 훈련 스냅샷(training snapshots)을 영구 저장소에 주기적으로 저장해서 체크포 인트로 사용한다. 체크포인트는 시스템 장애 복구에 필수적이지만 RM을 포함하여 다양한 컴퓨팅 도메인에서 성 능 병목을 일으키게 된다."}
{"patent_id": "10-2023-0015011", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 개시는 CXL 기반 컴퓨팅 시스템, 인공지능 모델 훈련을 위한 동작 방법에 관한 것이다. 본 개시는 캐시 일관성 도메인으로 통합된 GPU(CXL-GPU) 및 비휘발성 메모리 확장기(CXL-MEM)를 제공한다. 본 개시는 CXL 장치 간 자동 데이터 이동을 지원하는 CXL 기반 컴퓨팅 시스템을 제공한다. 본 개시는 언두로그(undo log) 기반의 배치 인지 체크포인트 방법을 제공한다. 본 개시는 완화된 임베딩 룩업 및 완화된 배치 인지 체크포인트를 제공한다."}
{"patent_id": "10-2023-0015011", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "한 실시예에 따른 CXL 컴퓨팅 시스템은, CXL(Compute Express Link)을 지원하는 GPU(CXL-GPU), 그리고 상기 CXL-GPU와 캐시 일관성 도메인으로 통합되고, 적어도 하나의 메모리 모듈을 포함하는 메모리 확장기(CXL-MEM)를 포함한다. 상기 CXL-GPU 및 상기 CXL-MEM은 CXL.io, CXL.cache, 그리고 CXL.mem 프로토콜들을 지원하는 유형2의 CXL 장치 이고, 상기 CXL-GPU 및 상기 CXL-MEM은 상기 CXL.cache를 통해 서로 데이터를 주고받을 수 있다. 상기 CXL-GPU와 상기 CXL-MEM 중 어느 장치가 데이터를 플러시(flush)하면, 상기 데이터는 다른 장치의 지정된 메모리로 자동 이동하여 저장될 수 있다.상기 CXL-MEM은 모델 훈련의 작업들 중, 배치마다의 임베딩 작업을 수행할 수 있다. 상기 CXL-MEM은 이전 배치의 임베딩 테이블을 사용한 임베딩 룩업 작업을 통해 현재 배치의 임베딩 벡터를 임시 로 생성하고, 상기 이전 배치의 훈련 결과를 기초로 상기 임베딩 벡터를 업데이트하여 상기 현재 배치의 임베딩 벡터를 생성할 수 있다. 상기 CXL-MEM은 현재 배치에 대한 임베딩 작업의 체크포인트를 위해, 상 상기 임베딩 작업의 임베딩 로그를 메 모리 모듈에 저장할 수 있다. 상기 CXL-MEM은 메모리 매핑된 레지스터에 설정된 현재 배치 정보를 참조해서 상기 메모리 모듈의 데이터 영역 에 있는 임베딩 벡터를 로그 영역으로 복사하여 현재 배치에 대한 상기 임베딩 로그를 저장하고, 상기 임베딩 로그에 대한 영구 플래그를 설정할 수 있다. 상기 CXL-MEM은 메모리 매핑된 레지스터에 설정된 모델 매개변수들의 메모리 주소와 크기를 참조하여, 상기 CXL-GPU로 CXL.cache 요청을 보내고, 상기 CXL-GPU로부터, 현재 배치에 대한 모델 훈련을 통해 저장된 모델 매 개변수들을 응답받으면, 상기 모델 매개변수들을 메모리 모듈의 로그 영역에 저장하고, 모델 로그에 대한 영구 플래그를 설정할 수 있다. 상기 CXL-MEM은 여러 배치에 걸쳐 상기 모델 로그를 저장하도록 스케줄링할 수 있다. 상기 CXL-MEM은 상기 적어도 하나의 메모리 모듈 및 해당 메모리 모듈을 제어하는 메모리 컨트롤러, 메모리 매 핑된 레지스터, 그리고 내부 캐시라인 상태들을 관리하는 장치 일관성 엔진(Device Coherency Engine, DCOH)을 포함하는 CXL 컨트롤러, 그리고 모델 훈련을 위한 컴퓨팅 로직 및 체크포인트 로직을 포함할 수 있다. 한 실시예에 따른 CXL 기반 메모리 확장기는 적어도 하나의 메모리 모듈 및 해당 메모리 모듈을 제어하는 메모 리 컨트롤러, 메모리 매핑된 레지스터, 그리고 내부 캐시라인 상태들을 관리하는 장치 일관성 엔진(Device Coherency Engine, DCOH)을 포함하는 CXL(Compute Express Link) 컨트롤러, 모델 훈련의 작업들 중에서, 배치 마다의 임베딩 작업을 수행하는 컴퓨팅 로직, 그리고 모델 훈련의 장애 허용성 관리를 위해, 상기 임베딩 작업 으로 얻은 임베딩 로그 및 모델 훈련을 통해 저장된 모델 매개변수들을 상기 메모리 모듈에 저장하는 체크포인 트 로직을 포함한다. 상기 CXL 컨트롤러는 CXL.io, CXL.cache, 그리고 CXL.mem 프로토콜들을 실행하는 유형2의 컨트롤러일 수 있다. 상기 CXL 컨트롤러가 상기 임베딩 작업으로 생성된 축소된 임베딩 벡터의 캐시라인을 플러시(flush)하면, 상기 축소된 임베딩 벡터는 캐시 일관성 도메인으로 통합된 CXL 장치로 자동 이동하여 저장될 수 있다. 상기 체크포인트 로직은 상기 메모리 매핑된 레지스터에 설정된 현재 배치 정보를 참조해서 상기 메모리 모듈의 데이터 영역에 있는 임베딩 벡터를 로그 영역으로 복사하여 현재 배치에 대한 상기 임베딩 로그를 저장하고, 상 기 임베딩 로그에 대한 영구 플래그를 설정할 수 있다. 상기 체크포인트 로직은 상기 메모리 매핑된 레지스터에 설정된 모델 매개변수들의 메모리 주소와 크기를 참조 하여, CXL 장치로 CXL.cache 요청을 보내고, 상기 CXL 장치로부터, 현재 배치에 대한 모델 훈련을 통해 저장된 상기 모델 매개변수들을 응답받으면, 상기 모델 매개변수들을 상기 메모리 모듈의 로그 영역에 저장하고, 모델 로그에 대한 영구 플래그를 설정할 수 있다. 상기 CXL 장치는 상기 모델 훈련의 주된 훈련을 수행하는 CXL 기반의 GPU(CXL-GPU)일 수 있다. 상기 체크포인트 로직은 여러 배치에 걸쳐 상기 모델 로그를 저장하도록 스케줄링할 수 있다. 한 실시예에 따라 CXL(Compute Express Link)을 지원하는 GPU(CXL-GPU)와 연동하여 모델 훈련을 수행하는 CXL 기반 메모리 확장기의 동작 방법으로서, 현재 배치에 대한 임베딩 룩업 작업을 수행하여, 상기 현재 배치의 임 베딩 벡터를 생성하는 단계, 상기 현재 배치의 임베딩 벡터를 캐시 일관성 도메인에 통합된 상기 CXL-GPU의 메 모리로 플러시(flush)하는 단계, 그리고 상기 CXL-GPU에서의 모델 훈련 결과를 반영하여, 상기 메모리 모듈에 저장된 임베딩 테이블을 업데이트하는 단계를 포함한다. 상기 동작 방법은 상기 임베딩 테이블을 업데이트 전에, 메모리 매핑된 레지스터에 설정된 현재 배치 정보를 참 조해서 상기 임베딩 룩업 작업으로 얻은 임베딩 로그를 메모리 모듈에 저장함으로써, 상기 현재 배치의 임베딩 작업에 대한 체크포인트를 생성하는 단계를 더 포함할 수 있다. 상기 동작 방법은 메모리 매핑된 레지스터에 설정된 모델 매개변수들의 메모리 주소와 크기를 참조하여, 상기 현재 배치에 대한 모델 훈련을 통해 저장된 모델 매개변수들을 상기 CXL-GPU로부터 응답받으면, 상기 모델 매개 변수들을 상기 메모리 모듈의 로그 영역에 저장함으로써, 상기 현재 배치로 훈련된 모델에 대한 체크포인트를 생성하는 단계를 더 포함할 수 있다."}
{"patent_id": "10-2023-0015011", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 개시에 따르면, CXL-GPU와 CXL-MEM을 동일한 캐시 일관성 도메인에 통합하여, 호스트 CPU에서 실행되는 소프 트웨어의 개입 없이 두 CXL 장치간의 데이터 교환을 지원할 수 있다. 본 개시에 따르면, 영구 메모리 모듈 근처에서 임베딩 작업이 가능하고, 체크포인트 기반 장애 허용성 관리를 능동적으로 수행할 수 있다. 본 개시에 따르면, 배치 훈련의 맨 마지막에 수행되는 체크포인트 작업을 없앨 수 있어서, 훈련 시간을 좀 더 단축할 수 있다. 본 개시에 따르면, 완화된 임베딩 룩업 작업을 통해, 인접한 배치 사이의 임베딩 업데이트와 입베딩 룩업 간의 연산 종속성을 완화하고, 영구 메모리 모듈이 RAW 현상을 경험하는 것을 방지할 수 있다. 본 개시에 따르면, 배치 인지 체크포인트 완화 및 임베딩 룩업 완화를 통해, CXL-GPU와 CXL-MEM의 훈련 작업을 완전히 중첩할 수 있어서, 훈련 대역을 향상할 수 있다. 본 개시에 따르면, 장애 허용성이 요구되는 모델 훈련을 지원할 수 있고, 특히, 추천 모델을 사용하는 모든 분 야와 응용 모두에 자유롭게 적용될 수 있다."}
{"patent_id": "10-2023-0015011", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "아래에서는 첨부한 도면을 참고로 하여 본 개시의 실시예에 대하여 본 개시가 속하는 기술 분야에서 통상의 지 식을 가진 자가 용이하게 실시할 수 있도록 상세히 설명한다. 그러나 본 개시는 여러 가지 상이한 형태로 구현 될 수 있으며 여기에서 설명하는 실시예에 한정되지 않는다. 그리고 도면에서 본 개시를 명확하게 설명하기 위 해서 설명과 관계없는 부분은 생략하였으며, 명세서 전체를 통하여 유사한 부분에 대해서는 유사한 도면 부호를 붙였다. 설명에서, 도면 부호 및 이름은 설명의 편의를 위해 붙인 것으로서, 장치들이 반드시 도면 부호나 이름으로 한 정되는 것은 아니다. 설명에서, 어떤 부분이 어떤 구성요소를 \"포함\"한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다른 구성 요소를 제외하는 것이 아니라 다른 구성요소를 더 포함할 수 있는 것을 의미한다. 또한, 명세서에 기재된 \"…부\", \"…기\", \"모듈\" 등의 용어는 적어도 하나의 기능이나 동작을 처리하는 단위를 의미하며, 이는 하드웨어 나 소프트웨어 또는 하드웨어 및 소프트웨어의 결합으로 구현될 수 있다.설명에서, 단수로 기재된 표현은 \"하나\" 또는 \"단일\" 등의 명시적인 표현을 사용하지 않은 이상, 단수 또는 복 수로 해석될 수 있다. 제1, 제2 등과 같이 서수를 포함하는 용어는 다양한 구성요소를 설명하는데 사용될 수 있 지만, 구성요소는 이러한 용어에 의해 한정되지는 않는다. 이들 용어는 하나의 구성요소를 다른 구성요소로부터 구별하는 목적으로 사용될 수 있다. 도면을 참고하여 설명한 흐름도에서, 동작 순서는 변경될 수 있고, 여러 동작들이 병합되거나, 어느 동작이 분 할될 수 있고, 특정 동작은 수행되지 않을 수 있다. 도 1은 딥러닝 기반 추천 모델의 단일 배치 훈련을 설명하는 도면이다. 도 1을 참고하면, Meta AI의 DLRM(deep learning recommendation model)과 같은 추천 모델(Recommendation model, RM)은 더 높은 정확도와 더 나은 표현 능력을 달성하기 위해 희소 특징(sparse features)(예를 들면, 사용자/항목 색인과 같은 범주 정보)과 밀집 특징(dense features)(예를 들면, 사용자/항목 프로필과 같 은 연속 정보)을 모두 활용해서 훈련한다. 이때, 희소 특징과 밀집 특징은 뚜렷한 특성 차이를 가지기 때문에, 상위 MLP(Top-Multi-Layer Perceptron, Top-MLP)라는 메인 훈련 절차를 수행하기 전에 다양한 유형의 방식으로 인코딩된다. 즉, 밀집 특징은 하위 MLP(Bottom-MLP)라고 하는 행렬 곱셈 연산(matrix multiplication operation)을 통해 인코딩되고, 희소 특징은 임베딩 테이블 룩업의 임베딩 작업에 의해 인코딩된 후, 인코딩된 희소 특징과 밀집 특징을 통해 메인 훈련 절차가 진행될 수 있다. 다양한 수준의 컴퓨팅 집약도를 고려하면 하위 MLP 작업은 GPU(Graphics Processing Unit)에서 수행고, 임베딩 작업은 호스트 CPU(Central Processing Unit)에서 처리된다. 희소 특징의 임베딩 작업을 위해, 호스트 CPU는 희 소 특징에 존재하는 테이블 인덱스를 참조하여 기본 스토리지의 임베딩 테이블에서 임베딩 벡터를 읽는다. 호스 트 CPU는 더하기 또는 빼기와 같은 간단한 산술 연산을 통해, 검색된 임베딩 벡터를 통합해서, 상위 MLP의 입력 을 위한 새로운 임베딩 벡터를 생성한다. 하위 MLP 작업과 임베딩 작업이 서로 다른 위치에서 동시에 처리되기 때문에, 상위 MLP의 입력들이 병렬로 준비될 수 있다. 주된 훈련을 위해, 하위 MLP 작업과 임베딩 작업을 통해 인코딩된 입력들이 동일한 벡터 공간에 배치되어야 한 다. GPU는 전파 단계(forward propagation, FWP)에서, 인코딩된 입력들을 기능 상호 작용(feature interaction, FI)을 통해 통합(concatenation)하고, 상위 MLP를 통해 기능 상호 작용의 결과를 훈련한다. 역전파 단계(backward propagation, BWP)는 전파 단계와 유사하지만 모든 연산이 역순으로 처리된다. 역전파 단 계에서, 그래디언트 오류가 입력으로 사용되고, 모델 정확도를 개선하기 위해 모델(상위 MLP 및 하위 MLP)의 매 개변수들 및 임베딩 정보가 업데이트된다. 그래디언트 오류는 전파 단계의 결과와 정답 레이블 간의 차이로 계 산될 수 있다. 업데이트된 모델 매개변수들(예를 들면, MLP의 가중치들) 및 임베딩 정보는 모든 배치 절차의 끝에서 영구적으 로 스토리지에 저장된다. 이때, 추천 모델은 정확도 저하 없이 며칠 또는 몇 주 동안 학습되어야 하므로, 스토리지에 체크포인트를 저장하고, 장애 발생 시 체크포인트를 사용해서 복구한다. 여기서, 체크포인트는 시스 템 장애 복구에 필수적이지만 다양한 컴퓨팅 도메인에서 성능 병목을 일으키는 요인이기도 하다. 한편, 수십에서 수백 테라바이트(TB)를 초과하는 임베딩 테이블 사이즈 때문에, 기존의 추천 모델은 시스템 로컬 메모리 대신, 스토리지에 대규모의 임베딩 테이블을 저장한다. 따라서, 기존의 추천 모델은 고성능 솔 리드 스테이트 드라이브(solid-state drive, SSD)를 백엔드 스토리지 미디어로 사용하여 호스트 메모리를 확장 한다. 이러한 SSD 통합 메모리 확장은 대용량 입력 데이터를 성공적으로 처리할 수 있지만 심각한 성능 저하를 겪을 수 있다. 임베딩 룩업 작업은 종종 무작위 패턴으로 작은 크기의 읽기를 수행해야 하는데, SSD는 대량 I/O 작업에 최적화되어 있기 때문이다. 또한, SSD의 쓰기 시간은 모든 기존 메모리 작업의 대기 시간보다 수십 배 더 느리며, 쓰기는 가비지 컬렉션과 같은 많은 내부 작업을 야기한다. 따라서, 장애 복구를 위해 주기적으로 저 장되어야 하는 체크포인트를 SSD에 저장하는 경우, SSD의 특성에 의해 훈련 성능이 심각하게 저하될 수 있다. 결국, SSD는 체크포인트에 의한 성능 병목 문제까지 해결하지는 못하고, 메모리 확장 목적으로만 활용될 수 있 다. 도 2는 CXL 컴퓨팅 시스템 구조 및 장치 종류를 설명하는 도면이다. 도 2를 참고하면, CXL(Compute Express Link)은 캐쉬 일관성 연결(cache coherent interconnect)을 통해 여러 이기종 장치들이 메모리 공간을 공유하도록 만드는 개방형 산업 표준이다. CXL 표준을 메모리 분산(memory disaggregation)에 활용될 수 있을 것으로 검토되고 있으나, 메모리 분산을 위한 하드웨어 구조 및 메모리 분산방법이 구체화되지 않은 상태이다. 이러한 CXL 기반 컴퓨팅 시스템은 CXL을 지원하는 호스트 CPU(CXL-enabled CPU), CXL 스위치, 그 리고 CXL 장치들(25: 25-1, 25-2, 25-3)로 구성될 수 있다. 호스트는 호스트 CPU와 호스트 메모리 장치 를 포함할 수 있다. 호스트 메모리 장치는 동적 랜덤 액세스 메모리(dynamic random-access memory, DRA M)을 포함할 수 있다. CXL 스위치는 호스트 CPU와 CXL 장치들을 상호 연결한다. CXL 장치들은 CXL 프로토콜 인터페이스를 제공하는 노드로서, 예를 들면, 가속기나 메모리 확장기 등의 기존 주변 장치의 설 계를 활용하여 구현될 수 있다. 호스트 CPU는 호스트 물리주소공간(host physical address space, HPA space) 또는 물리 메모리 맵 (Physical memory map)이라고 불리는 공간을 가지고, 로컬 메모리 그리고 내부 메모리를 가지는 CXL 장치들이 HPA 공간에 매핑될 수 있다. 이를 위해 CXL은 CXL.io, CXL.cache, CXL.mem라는 세 가지 하위 프로토콜들을 지 원한다. 하위 프로토콜을 결합하는 방법에 따라 CXL 장치들은 유형1(Type 1)의 CXL 장치(25-1), 유형2(Type 2)의 CXL 장치(25-2), 유형3(Type 3)의 CXL 장치(25-3)으로 분류된다. 먼저, CXL.io는 모든 유형의 하드웨어에 필수적인 프로토콜이다. CXL 장치는 CXL.io를 사용해서, 장치 레지스터 를 메모리 매핑된 IO(Memory-Mapped IO, MMIO)로서, HPA에 노출할 수 있다. 호스트 CPU는 CXL.io를 사용해 서, CXL 장치를 검색(discover)하거나 필요한 값들을 설정(configure)할 수 있다. 유형1의 CXL 장치(25-1)는 CXL.io 이외에, CXL.cache를 더 지원하고, 유형3의 CXL 장치(25-3)는 CXL.io 이외에, CXL.mem을 더 지원할 수 있다. 유형2의 CXL 장치(25-2)는 컴퓨팅 및 메모리 리소스를 모두 갖도록 설계 되었으므로 CXL.io, CXL.cache, CXL.mem을 모두 지원할 수 있다. CXL.mem을 사용하여 CXL 장치(25-2, 25-3)의 내부 메모리(Dev mem)를 HPA에 등록하는 경우, 호스트 CPU는 기존의 load/store 명령을 통해 원격의 CXL 장치(25-2, 25-3)의 메모리에 접근할 수 있다. CXL.cache를 사용하면, CXL 장치(25-1, 25-2)가 캐시 일관성 도메인(cache coherent domain)에 포함될 수 있어 HPA 공간의 데이터를 내부의 캐시에 저장할 수 있다. CXL 3.0에 따르면, CXL 장치 내부의 캐시라인 상태들은 장 치 일관성 엔진(Device Coherency Engine, DCOH)에 의해 관리된다. 또한, 호스트 CPU는 모든 장치를 CXL이 관리하는 캐시 일관성 도메인에 배치하기 위해, CHA(caching/home agent)라는 캐시 일관성 엔진을 내장한다. 유형2의 CXL 장치(25-2)가 HPA 공간에 접근할 때, 호스트 CPU의 캐시 일관성 엔진(CHA)은 호스트 캐시의 캐 시라인 상태들을 적절하게 수정함과 동시에, 메모리 주소에 해당하는 장치(예를 들면, 로컬 메모리 컨트롤러 또 는 다른 CXL 장치)로 CXL.cache 요청을 라우팅해야한다. 다음에서, 이러한 CXL 프로토콜을 활용한 컴퓨팅 시스템 및 이의 동작에 대해 자세히 설명한다. 본 개시의 컴퓨 팅 시스템은 모델 훈련에 사용되는 점을 강조하여 TrainingCXL 시스템이라고 부를 수도 있다. 도 3은 한 실시예에 따른 CXL 컴퓨팅 시스템을 설명하는 도면이다. 도 3을 참고하면, CXL 컴퓨팅 시스템은 CXL을 사용하여 분산된 메모리 풀(disaggregated memory pool)을 구축하고, 인공지능 모델(artificial model)의 훈련에 사용될 수 있다. 설명에서는 추천 모델(RM)의 훈련을 예 로 들어 설명하나, 다양한 종류의 인공지능 모델 훈련에 사용될 수 있다. CXL 컴퓨팅 시스템은 CXL을 지원 하는 호스트 CPU, CXL 스위치, 그리고 CXL 장치들(130, 140)로 구성될 수 있다. 여기서, CXL 장치는 CXL을 지원하는 GPU(CXL-GPU)로 구현되고, CXL 장치는 CXL을 지원하는 비휘발성 메모리 확장기(CXL-MEM)로 구현될 수 있다. 따라서, 두 CXL 장치를 구분하기 위해, CXL-GPU과 CXL- MEM로 설명한다. 복수 개의 CXL-MEM이 CXL 스위치에 연결될 수 있다. CXL-GPU과 CXL- MEM는 CXL.io, CXL.cache, CXL.mem을 모두 지원하는 유형2의 CXL 장치일 수 있다. CXL-GPU와 CXL- MEM은 CXL 스위치를 통해 호스트 CPU에 연결될 수 있다. CXL-GPU는 GPU에 장치 일관성 엔진(DCOH)를 도입한 CXL 장치이다. CXL-MEM은 비휘발성 메모리 모듈 을 가지는 지능형 메모리 확장기로서, 메모리 모듈은 예를 들면, 영구 메모리 모듈(persistent memory module, PMEM)일 수 있고, 다음에서는 주로 PMEM을 예로 들어 설명할 수 있다. CXL-GPU와 CXL-MEM은 유형2의 CXL 장치이므로, CXL-MEM의 내부 메모리는 CXL-GPU의 로컬 메모리에 노출될 수 있고, 마찬가지로 CXL-GPU의 로컬 메모리는 CXL-MEM의 내부 메모리에 노출될 수 있다. CXL-GPU는 추천 모델(RM)의 주된 훈련을 실행할 수 있다. 주된 훈련은 예를 들면, 다층 퍼셉트론(MLP) 구 조의 인공지능 모델에서, 입력으로부터 지정된 태스크의 출력을 추론하는 훈련일 수 있다. 설명에서는 간단히, CXL-GPU가 MLP 작업을 실행한다고 설명한다. 그리고, 호스트 CPU 대신, CXL-MEM이 희소 특징들 의 임베딩 작업을 수행할 수 있어서, 추천 모델(RM)의 임베딩 작업을 가속화할 수 있다. CXL 컴퓨팅 시스템 은 임베딩 테이블에서 임베딩 벡터를 읽고 쓸 때, 메모리 수준 성능(memory-level performance)을 충분히 활용할 수 있고, CXL-GPU와 CXL-MEM 사이의 데이터 이동량을 줄일 수 있다. 이처럼, CXL-MEM이 임베딩 작업을 담당하므로, 호스트 CPU는 추천 모델(RM) 훈련을 위한 소프트웨어 프레임워크(예를 들면, PyTorch 또는 TensorFlow)만 실행해도 되고, 이기종 컴퓨팅 장치를 관리하고 스케줄링하 는 역할을 수행할 수 있다. CXL-MEM은 프론트엔드와 백엔드로 구성될 수 있다. CXL-MEM의 벡엔드는 복수의 메모리 모듈들(141-1, …, 141-n), 그리고 해당 메모리 모듈을 제어하는 복수 의 메모리 컨트롤러들(142-1, …, 142-n)로 구성될 수 있다. 각 메모리 모듈은 영구 메모리 모듈(PMEM)로 구현 될 수 있다. 각 메모리 모듈은 높은 수준의 데이터 병렬 처리에 활용되고, 각 메모리 컨트롤러는 모델의 체크포 인트 뿐만 아니라 대규모 임베딩 테이블을 다루는데 사용될 수 있다. 복수의 메모리 모듈들(141-1, …, 141- n)이 통합된 대규모 메모리 공간은 상호 연결 프로토콜(예를 들면, AXI 상호연결)을 통해, CXL-MEM의 프론 트엔드에 노출될 수 있다. CXL-MEM의 프론트엔드는 CXL 컨트롤러(CXL controller), 컴퓨팅 로직(computing logic) 모듈(간단히, 컴퓨팅 로직이라고 함), 그리고 체크포인트 로직(checkpoint logic) 모듈(간단히 체크포인트 로직이라고 함)로 구현될 수 있다. CXL 컨트롤러는 CXL의 세 가지 하위 프로토콜들(CXL.io, CXL.cache, CXL.mem)을 실행하는 유형2 컨트롤러로서, CXL.io를 사용해서 CXL 장치를 검색하거나 설정하는 MMIO 레지스터, 그리고 내부 캐시라인 상태들을 관리하는 장치 일관성 엔진(DCOH)을 포함할 수 있다. 컴퓨팅 로직 은 임베딩 룩업 작업에 필요한 임베딩 테이블 룩업 및 산술 연산을 처리할 수 있다. 체크포인트 로직(14 5)은 CXL-MEM의 내부에서 체크포인트를 자동으로 생성할 수 있다. 이때, 체크포인트 로직은 배치 정 보를 활용하여 백그라운드에서 언두로그(undo log)을 수행하는 배치 인지 체크포인트(batch-aware checkpoint) 작업을 통해, 업데이트될 데이터를 미리 저장함으로써, 체크포인트를 생성할 수 있다. 장치 초기화 시, CXL-MEM의 MMIO 레지스터는 호스트 CPU에 의해, 컴퓨팅 로직 및 체크포인트 로 직을 위한 적절한 값으로 설정된다. 예를 들어, MMIO 레지스터는 컴퓨팅 로직에서의 임베딩 작업에 필요한 임베딩 벡터 길이와 학습률(learning rate)을 저장할 수 있다. 체크포인트 로직에서의 체크포인트 자동 생성을 위해, MMIO 레지스터는 MLP 매개변수들의 메모리 주소와 MLP 매개변수들의 크기를 저장할 수 있다. 즉, 모든 MLP 매개변수들이 CXL-GPU에 있으므로, CXL-MEM의 내부에서 체크포인트를 자동 생성하기 위 해서, MLP 매개변수들의 메모리 주소와 MLP 매개변수들의 크기를 저장하는 것이 중요하다. CXL 컴퓨팅 시스템은 CXL-GPU와 CXL-MEM을 동일한 캐시 일관성 도메인에 통합하여, 호스트 CPU에서 실행되는 소프트웨어의 개입 없이 CXL-GPU와 CXL-MEM 간의 데이터 교환을 지원할 수 있 다. 그리고 영구 메모리 모듈(PMEM)을 포함하는 CXL-MEM은 CXL 컨트롤러와 함께, 모델 훈련을 위한 컴퓨팅 로직 및 체크포인트 로직을 채용하여, 영구 메모리 모듈(PMEM) 근처에서 임베딩 작업 및 체크 포인트 기반 장애 허용성 관리를 능동적으로 수행할 수 있다. 따라서, 지능형 메모리 확장기인 CXL-MEM과 GPU에 장치 일관성 엔진(DCOH)를 도입한 CXL-GPU를 통해, SSD 메모리 확장에 의한 추천 모델 훈련의 단점 을 해결함으로써, 훈련 성능을 향상시킬 수 있다. 도 4는 추천 모델 훈련 과정에서의 데이터 이동 방법을 비교하는 도면이고, 도 5는 한 실시예에 따른 CXL 컴퓨 팅 시스템의 자동 데이터 이동을 설명하는 도면이고, 도 6은 한 실시예에 따른 CXL 컴퓨팅 시스템의 캐시 플러 시(cache flush)를 설명하는 도면이다. 도 4를 참고하면, CXL 컴퓨팅 시스템은 이기종 컴퓨팅 시스템을 채택하고 있으므로, 추천 모델 훈련 과정에서 생성되는 중간 데이터를 CXL 장치간에 이동해야 한다. 예를 들어 CXL-MEM에서 수행된 임베딩 작업 결과가 CXL- GPU로 이동되어 기능 상호 작용의 입력으로 사용되어야 한다. 추천 모델 훈련은 도 1을 참고로 설명한 작업 (operations)을 거치는데, 임베딩 룩업 작업(Lookup으로 표시), 하위 MLP 작업(B-MLP로 표시), 기능 상호 작용 (FI로 표시), 상위 MLP 작업(T-MLP로 표시), 임베딩 및 모델 업데이트 작업(update로 표시), 그리고 체크포인트 작업(CHKPT로 표시)으로 진행될 수 있다. 도 4의 (a)를 참고하면, 종래의 경우, 호스트 CPU에서 실행되는 소프트웨어 프레임워크에 의해 데이터 이동이 관리된다. 추천 모델 훈련 과정을 살펴보면, 호스트 CPU는 하위 MLP(bottom-MLP) 작업을 CXL-GPU로 오프로드하 고, 임베딩 룩업 작업을 CXL-MEM로 오프로드한 후, 두 작업이 완료될 때까지 기다린다. CXL-GPU와 CXL-MEM의 작 업이 모두 완료되면, 호스트 CPU의 소프트웨어는 CXP-MEM에서 연산된 새로운 임베딩 벡터를 CXL-GPU의 내부 메 모리에 복사하고, 이후에 기능 상호 작용 및 상위 MLP(Top-MLP) 작업도 CXL-GPU로 전송한다. 역전파 단계(BWP) 에서도, 호스트 CPU의 소프트웨어가 장치 간 데이터 이동에 관여한다. 이처럼, 소프트웨어 기반으로 데이터를 이용하는 경우, 호스트 CPU가 추천 모델 훈련에 자주 개입해야 한다. 도 4의 (b)를 참고하면, 본 개시의 CXL 컴퓨팅 시스템은 CXL.cache를 통해 CXL-GPU와 CXL-MEM 간 자동 데 이터 이동을 구현할 수 있다. 추천 모델 훈련 과정을 살펴보면, 모든 데이터 이동이 CXL 하드웨어 구성 요소 간 에 의해 이루어지기 때문에, 호스트 CPU의 소프트웨어는 CXL-GPU와 CXL-MEM이 동시에 처리해야 하는 모든 작업 을 한번에 오프로드하면 되고, 이후에 모든 입력 데이터가 준비되었는지 여부에 따라 내부 작업은 동기화된다. 이처럼, 소프트웨어 기반의 데이터 이동을 하드웨어 기반의 데이터 이동으로 변경하면, CXL 컴퓨팅 시스템(10 0)은 호스트 CPU의 소프트웨어가 CXL-GPU와 CXL-MEM 사이의 데이터 이동에 빈번히 개입하는 오버헤드를 제거할 수 있고, 결과적으로 추천 모델 훈련 시간을 단축할 수 있다. 도 5를 참고하면, 예를 들어 CXL-MEM이 임베딩 룩업 작업을 수행하여 축소된 임베딩 벡터(reduced embedding vector)를 생성한 경우, 축소된 임베딩 벡터가 CXL.cache를 통해 CXL-GPU로 자동 이동한다. CXL.cache를 통한 자동 데이터 이동을 위해, 데이터(예를 들면, 축소된 임베딩 벡터)가 작업 입력(예를 들면, 기능 상호 작용의 입력)으로 사용할 위치에 저장되도록, 데이터 배치(data placement)가 설계되어야 한다. 예를 들면, 축소된 임 베딩 벡터는 CXL-MEM의 일관된 캐시(coherent cache)에 캐싱되고, CXL.cache를 통해 CXL-GPU의 기능 상호 작용 입력에 해당하는 장치 메모리에 저장된다. 기능 상호 작용에 의해, 인코딩된 희소 특징과 밀집 특징이 결합되어 상위 MLP로 입력된다. 도 6을 참고하면, CXL-MEM의 장치 일관성 엔진(DCOH)이 축소된 임베딩 벡터의 모든 캐시라인을 플러시(flush)하 면, 축소된 임베딩 벡터가 CXL-GPU의 장치 메모리로 자동 이동하고, CXL-MEM의 컴퓨팅 로직은 임베딩 룩업 (embedding lookup) 작업으로 업데이트된다. 역전파 단계(BWP)의 경우, 임베딩 업데이트 작업의 입력(예를 들면, 임베딩 그래디언트)은 CXL-MEM의 장치 메모 리에 저장되고, CXL-GPU의 일관된 캐시에 캐싱되어야 한다. 임베딩 그래디언트는 CXL-GPU의 장치 일관성 엔진 (DCOH)에 의해 플러시되고, CXL-MEM의 메모리로 전달된다. 도 7은 한 실시예에 따른 배치 인지 체크포인트 작업을 설명하는 도면이고, 도 8과 도 9는 한 실시예에 따른 CXL-MEM의 체크포인트 자동 생성을 설명하는 도면이다. 도 7을 참고하면, CXL 컴퓨팅 시스템은 높은 학습 대역폭을 달성하기 위해 CXL-GPU에서의 MLP 작업과 CXL- MEM에서의 임베딩 작업을 동시에 수행할 수 있다. 하지만 배치마다 마지막에서 실행되는 모델/임베딩 업데이트 및 체크포인트 생성으로 인해 훈련 시간이 길어진다. 이를 해결하기 위해 CXL-MEM이 배치 정보를 활용하여 백그라운드에서 언두로깅(undo log)을 수행하는 배치 인지 체크포인트(batch-aware checkpoint) 작업을 실행한 다. 호스트 CPU는 각 배치의 시작을 위해, 임베딩 작업에 필요한 희소 특징, MLP 매개변수들의 메모리 주소 등 의 배치 입력값을 MMIO 레지스터에 설정에 하므로, CXL-MEM의 체크포인트 로직은 이를 참조하여, CXL-MEM의 유휴 시간(예를 들면, CXL-GPU만 작업을 처리하는 시간)동안 임베딩 로그 및 MLP 로그를 영구적으로 저장할 수 있다. 대부분의 응용 프로그램의 경우, 계산이 완료되기 전에 업데이트해야 하는 데이터를 알 수 없기 때문에, 백그라 운드 언두로그 작업을 할 수 없다. 하지만, 추천 모델 훈련에서는 업데이트될 데이터를 미리 알 수 있기 때문에, CXL-MEM이 백그라운드에서 임베딩 로그를 영구 저장할 수 있고, 임베딩 로그의 영구 저장을 나타내는 플래그를 설정할 수 있다. 한편, MLP 매개변수들은 CXL-GPU의 장치 메모리에 저장되므로, CXL-MEM은 CXL.cache를 통해 CXL-GPU로부터 MLP 매개변수들을 전달받고, 이를 MLP 로그로 저장함으로써, MLP 로그에 대한 영구 저장을 나타내는 플래그를 설정할 수 있다. 이렇게 업데이트 전에 미리 진 행되는 배치 인지 체크포인트 작업을 통해, CXL 컴퓨팅 시스템은 배치 훈련의 맨 마지막에 수행되는 체크 포인트 작업을 없앨 수 있어서, 훈련 시간을 좀 더 단축할 수 있다. 참고로, 기존 SSD 기반의 컴퓨팅 시스템은 완료된 계산을 업데이트하는 리두로그(redo) 방식으로 장애 허용성 관리를 한다. 즉, 단일 배치 훈련이 완료되면 업데이트된 임베딩 벡터와 MLP 매개변수들이 SSD에 영구적으로 저장되므로, CXL 컴퓨팅 시스템보다 훈련 시간이 길어질 수밖에 없다. 도 8을 참고하면, 먼저, CXL-MEM에서의 체크포인트 자동 생성을 위해, 영구 메모리 모듈의 메모리 공 간은 컴퓨팅 로직을 위한 데이터 영역과, 체크포인트 로직를 위한 로그 영역으로 구분될 수 있다. 컴 퓨팅 로직이 임베딩 작업을 수행할 수 있도록 하는 임베딩 테이블이 데이터 영역에 저장된다. 체크포인트 로직은 임베딩 로그 및 MLP 로그를 로그 영역에 저장한다. 체크포인트 로직은 로그 영역의 시작 주소 를 참조하여 임베딩 테이블과 하위 MLP 및 상위 MLP를 복구할 수 있다. 각 배치의 시작을 위해 희소 특징이 CXL 컨트롤러의 MMIO 레지스터에 설정되면, 체크포인트 로직은 해당 배치(예를 들면, N번째 배치)의 희소 특징에 해당하는 임베딩 벡터 인덱스를 참조해서(①), 영구 메모리 모듈의 데이터 영역에 있는 임베딩 벡터를 로그 영역으로 복사하여 N번째 배치의 임베딩 로그를 생성할 수 있다(②). N번째 배치의 임베딩 로그가 영구적으로 저장되면, 체크포인트 로직은 임베딩 로그에 대한 영구 플래그(persistent flag)를 true로 설정한다(③). 임베딩 벡터는 체크포인트 로직에 의해 백그라운드에서 이미 영구 저장되었고, 데이터 영역의 임베딩 테이블은 이후 업데이트될 수 있다(④). 따라서, CXL-MEM의 임베딩 업데이트 중에 정전이 발생하더라도, N번째 배치의 영구 플래그가 설정되어 있다면, 체크포인트를 통해 해당 배치에서 임베딩 업데이트가 재개될 수 있다. 도 9를 참고하면, N번째 배치로 생성된 모델 매개변수들(하위 MLP 및 상위 MLP의 매개변수들) 역시, 모델 로그 (MLP 로그)로 저장되어야 하는데, MLP 매개변수들은 CXL-GPU의 장치 메모리에 저장되어 있다. 따라서, 체 크포인트 로직은 MMIO 레지스터에 저장된 MLP 매개변수들의 메모리 주소와 크기를 참조하여, CXL- GPU로 CXL.cache 요청을 보낸다(①). 체크포인트 로직은 CXL-GPU로부터 전달된 MLP 매개변수들 을 영구 메모리 모듈의 로그 영역에 저장한다(②). 체크포인트 로직은 MMIO 레지스터에 저장된 MLP 매개변수들의 크기와, CXL-GPU로부터 전달된 MLP 매개변수들을 크기를 비교하여, 저장된 MLP 로그가 체크 포인트되었는지 추적하고, 모든 MLP 매개변수들이 저장되면 MLP 로그에 대해 영구 플래그를 true로 설정한다(③). N번째 배치에 대한 임베딩 로그 및 MLP 로그가 영구 저장되어 영구 플래그가 설정된 경우, 체크포인트 로직 은 이전 N-1번째 배치에 대해 작성된 체크포인트를 삭제한다(④) 호스트 CPU는 각 배치의 시작을 위해 희소 특징을 MMIO 레지스터에 설정에 하므로, CXL-MEM의 체크포 인트 로직은 이를 참조하여, CXL-MEM의 유휴 시간(예를 들면, CXL-GPU만 작업을 처리하는 시간)동안 임베 딩 로그 및 MLP 로그를 영구적으로 저장할 수 있다. 도 10은 한 실시예에 따른 완화된 임베딩 룩업을 설명하는 도면이다. 도 10의 (a)를 참고하면, 일반적인 임베딩 작업의 경우, N번째 배치의 임베딩 업데이트와 N+1번째 배치의 임베 딩 룩업 간에 작업 종속성이 있다. 따라서, 컴퓨팅 장치는 N번째 배치의 훈련 결과인 그래디언트(gradient)와 학습률(learning rate)을 통해, N번째 배치의 임베딩 테이블을 업데이트해서 다음 배치에서의 훈련을 위한 N+1 번째 임베딩 테이블을 준비한다(S110). 그리고, 컴퓨팅 장치는 N+1번째 배치에서, 준비된 임베딩 테이블을 이용 한 임베딩 룩업을 통해 임베딩 벡터들을 검색하고, 이들을 통합한 임베딩 벡터(aggregated embedding vector)를 생성할 수 있다(S120). 한편, 영구 메모리 모듈(PMEM)의 경우, 쓰기 직후 바로 읽기가 요청되면 읽기 성능이 저하될 수 있는데, 이를 RAW(Read-After-Write) 현상이라고 한다. 도 10의 (a)에서 설명한 바와 같이, N번째 배치의 임베딩 업데이트를 통해 임베딩 테이블을 쓴 후, 곧바로 N+1번째 배치의 임베딩 룩업을 위해 임베딩 테이블을 읽는 과정이 연결된 다. 따라서, 인접한 배치 사이의 임베딩 작업으로 인해 영구 메모리 모듈이 RAW 현상을 경험하게 됨으로써, 훈 련 성능이 저하될 수 있다. 이를 해결하기 위해, CXL 컴퓨팅 시스템은 덧셈의 교환 법칙을 활용하여, 임베딩 업데이트(임베딩 테이블 업데이트)와 입베딩 룩업 간의 연산 종속성을 완화(relax)할 수 있다. 임베딩 업데이트와 입베딩 룩업은 덧셈/ 뺄셈의 산술 연산이므로, 덧셈의 교환 법칙을 활용하여 작업 순서를 바꿀 수 있다. 도 10의 (b)를 참고하면, CXL-MEM의 컴퓨팅 로직은 N+1번째 배치의 임베딩 룩업 작업을 위해, 먼저 N 번째 배치의 임베딩 테이블을 사용하여 N+1번째 배치에 대한 임베딩 룩업 작업을 수행한다(S210). 즉, 컴퓨팅 로직은 N번째 배치의 임베딩 테이블을 통해, N+1번째 배치에 대한 임베딩 벡터들을 검색하고, 이들을 통합 해서 축소된 임베딩 벡터를 임시로 생성할 수 있다.그리고, N번째 배치의 훈련 결과인 그래디언트와 학습률이 준비되면, 컴퓨팅 로직은 업데이트 전 임베딩 테이블로 생성된 임베딩 벡터를 그래디언트와 학습률로 업데이트하여, 최종적으로 N+1번째 배치의 임베딩 벡터 를 생성할 수 있다(S220). 도 11은 한 실시예에 따른 완화된 배치 인지 체크포인트를 설명하는 도면이다. 도 11을 참고하면, 임베딩 작업을 수행하는 CXL-MEM은 유휴 시간 동안 백드라운드 언두로그 방식으로, 임 베딩 로그 및 MLP 로그를 영구적으로 저장하는 배치 인지 체크포인트 작업을 실행한다. 이때, MLP 매개변수들은 CXL-GPU의 훈련 과정에서 저장되므로, CXL-MEM은 CXL-GPU로 CXL.cache 요청을 보내서, MLP 매 개변수들을 전달받는다. 이러한, 배치 인지 체크포인트를 통해, CXL-GPU의 기능 상호 작용(FI) 및 상위 MLP 작업과 체크포인트를 중첩시킴으로써, 영구 메모리 모듈(PMEM)의 느린 쓰기가 완화될 수 있다. 하지만, MLP 로그를 저장하는 체크포인트 시간이 CXL-MEM의 유휴 시간보다 길면 체크포인트 오버헤드가 발 생한다. 임베딩 로그는 모든 배치에 대해 영구적으로 저장해야 하지만, MLP 로그는 모든 배치에 대해 체크포인 트할 필요가 없다. 따라서, CXL-MEM은 배치마다 MLP 로그를 영구 저장하는 대신, 여러 배치에 걸쳐 MLP 로 그를 저장하도록 스케쥴링함으로써, 배치 인지 체크포인트 작업을 완화할 수 있다. CXL-MEM은 CXL-GPU에서 상위 MLP 작업을 완료하면 MLP 로깅을 중지해야 하는데, 상위 MLP 작업 완료 를 알기 어렵다. 따라서, CXL-GPU는 기능 상호 작용(FI) 및 상위 MLP 작업을 처리할 때만 CXL-MEM의 CXL.cache 요청에 응답함으로써 완화된 배치 인지 체크포인트를 지원할 수 있다. 이러한 배치 인지 체크포인트 완화 및 임베딩 룩업 완화를 통해, CXL-GPU와 CXL-MEM의 훈련 작업을 완전히 중첩할 수 있어서, 훈련 대역폭을 향상할 수 있다. 도 12는 한 실시예에 따른 모델 훈련을 위한 CXL-MEM의 동작 방법을 나타내는 흐름도이다. 도 12를 참고하면, CXL-MEM은 현재 배치에 대한 임베딩 룩업 작업을 수행하여, 현재 배치의 임베딩 벡터를 생성한다(S310). 이때, CXL-MEM은 현재 배치의 임베딩 룩업 작업을 위해, 이전 배치의 임베딩 테이블을 사 용하여 현재 배치에 대한 임베딩 룩업 작업을 미리 수행한 후, CXL-GPU에서 현재 배치의 훈련 결과인 그래 디언트와 학습률이 준비되면, 미리 생성된 임베딩 벡터를 그래디언트와 학습률로 업데이트하여, 최종적으로 현 재 배치의 임베딩 벡터를 생성할 수 있다. 이와 같이, CXL-MEM은 도 10에서 설명한 완화된 임베딩 룩업 작 업을 통해, 인접한 배치 사이의 임베딩 업데이트와 입베딩 룩업 간의 연산 종속성을 완화하고, 영구 메모리 모 듈이 RAW 현상을 경험하는 것을 방지할 수 있다. CXL-MEM은 CXL.cache를 통해, 현재 배치의 임베딩 벡터를, 캐시 일관성 도메인에 통합된 CXL-GPU의 메모리로 플러시한다(S320). CXL-MEM의 장치 일관성 엔진(DCOH)이 축소된 임베딩 벡터의 모든 캐시라인을 플러시하면, 축소된 임베딩 벡터가 CXL-GPU의 장치 메모리로 자동 이동할 수 있다. CXL.cache를 통한 자동 데이터 이동을 위해, 하드웨어 구성 요소 간의 데이터 배치가 설계되어야 한다. 이를 통해 호스트 CPU에서 실행되는 소프트웨어의 개입 없이 CXL-GPU와 CXL-MEM는 서로 데이터를 주고받을 수 있다 CXL-MEM은 현재 배치에 대한 임베딩 업데이트 전에, MMIO 레지스터에 설정된 현재 배치 정보를 참조해서 영구 메모리 모듈의 데이터 영역에 있는 임베딩 벡터를 로그 영역으로 복사하여 현재 배치의 임베딩 로그 를 저장함으로써, 현재 배치에 대한 체크포인트를 생성한다(S330). 이를 통해, CXL 컴퓨팅 시스템은 배치 훈련의 맨 마지막에 수행되는 체크포인트 작업을 없앨 수 있어서, 훈련 시간을 좀 더 단축할 수 있다. CXL-MEM은 CXL-GPU에서의 모델 훈련 결과를 반영하여, 임베딩 테이블을 업데이트한다(S340). 한편, CXL-MEM은 CXL-GPU로 CXL.cache 요청을 보내서, CXL-GPU의 장치 메모리에 저장된 MLP 매 개변수들을 응답받고, MLP 매개변수들을 영구 메모리 모듈의 로그 영역에 저장한다. 이때, MLP 로그는 모 든 배치에 대해 체크포인트할 필요가 없으므로, CXL-MEM은 배치마다 MLP 로그를 영구 저장하는 대신, 여러 배치에 걸쳐 MLP 로그를 저장하도록 스케쥴링함으로써, 배치 인지 체크포인트 작업을 완화할 수 있다. 이상에서 설명한 본 개시의 실시예는 장치 및 방법을 통해서만 구현이 되는 것은 아니며, 본 개시의 실시예의 구성에 대응하는 기능을 실현하는 프로그램 또는 그 프로그램이 기록된 기록 매체를 통해 구현될 수도 있다. 이상에서 본 개시의 실시예에 대하여 상세하게 설명하였지만 본 개시의 권리범위는 이에 한정되는 것은 아니고 다음의 청구범위에서 정의하고 있는 본 개시의 기본 개념을 이용한 당업자의 여러 변형 및 개량 형태 또한 본 개시의 권리범위에 속하는 것이다.도면 도면1 도면2 도면3 도면4 도면5 도면6 도면7 도면8 도면9 도면10 도면11 도면12"}
{"patent_id": "10-2023-0015011", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 딥러닝 기반 추천 모델의 단일 배치 훈련을 설명하는 도면이다. 도 2는 CXL 컴퓨팅 시스템 구조 및 장치 종류를 설명하는 도면이다. 도 3은 한 실시예에 따른 CXL 컴퓨팅 시스템을 설명하는 도면이다. 도 4는 추천 모델 훈련 과정에서의 데이터 이동 방법을 비교하는 도면이다. 도 5는 한 실시예에 따른 CXL 컴퓨팅 시스템의 자동 데이터 이동을 설명하는 도면이다. 도 6은 한 실시예에 따른 CXL 컴퓨팅 시스템의 캐시 플러시(cache flush)를 설명하는 도면이다. 도 7은 한 실시예에 따른 배치 인지 체크포인트 작업을 설명하는 도면이다. 도 8과 도 9는 한 실시예에 따른 CXL-MEM의 체크포인트 자동 생성을 설명하는 도면이다. 도 10은 한 실시예에 따른 완화된 임베딩 룩업을 설명하는 도면이다. 도 11은 한 실시예에 따른 완화된 배치 인지 체크포인트를 설명하는 도면이다. 도 12는 한 실시예에 따른 모델 훈련을 위한 CXL-MEM의 동작 방법을 나타내는 흐름도이다."}
