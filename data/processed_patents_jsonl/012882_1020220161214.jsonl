{"patent_id": "10-2022-0161214", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0079241", "출원번호": "10-2022-0161214", "발명의 명칭": "메타버스 공간 구성을 이용한 원격 XR 협업 시스템", "출원인": "주식회사 인터포", "발명자": "조용만"}}
{"patent_id": "10-2022-0161214", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "작업 현장에 위치하는 현장 작업자와 원격지에 위치하는 원격 작업자간 작업 현장의 작업대상에 대한 협업 서비스를 제공하는 원격 XR 협업 시스템에 있어서,현장 작업자가 구비하는 것으로, 작업대상을 포함하는 현장 이미지와 라이다 센서를 통해 획득한 작업 현장의깊이 이미지를 서비스 서버로 전송하고, 서비스 서버로부터 제공되는 협업 서비스를 위한 XR 콘텐츠를 표시출력함과 더불어, 현장 작업자에 의해 조작되는 작업대상 조작 정보를 서비스 서버로 전송하는 현장 단말과,원격 작업자가 구비하는 것으로, 서비스 서버로부터 제공되는 협업 서비스를 위한 XR 콘텐츠를 표시출력함과 더불어, 원격 작업자에 의해 조작되는 작업대상 조작 정보를 서비스 서버로 전송하는 원격 단말 및,상기 현장 단말과 원격 단말로 협업 서비스를 위한 XR 콘텐츠를 AR 또는 VR 모드로 동기화하여 제공하되, 작업대상에 대해서는 3D 모델을 생성하여 작업자의 조작에 대응되게 변화되는 3D 모델을 제공하고, 작업대상을 제외한 작업 현장의 배경 영역은 메타버스 공간으로 재구성하여, AR 모드의 단말로는 작업대상 3D 모델을 배경 영역에 증강시켜 출력하고, VR 모드의 단말로는 메타버스 공간에 작업대상 3D 모델을 위치시켜 가상현실 형태로 출력하도록 제공하는 서비스 서버를 포함하여 구성되는 것을 것을 특징으로 하는 메타버스 공간 구성을 이용한 원격 XR 협업 시스템."}
{"patent_id": "10-2022-0161214", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 서비스 서버는 현장 단말로부터 수신된 현장 이미지와 깊이 이미지를 이용하여 작업대상 영역을 추출함과더불어 작업대상 영역의 작업대상을 3D 모델링하여, 메타버스 공간의 작업대상 영역 위치에 작업대상 3D 모델이배치된 구조의 XR 콘텐츠를 생성하여 현장 단말과 원격 단말로 제공하는 것을 특징으로 하는 메타버스 공간 구성을 이용한 원격 XR 협업 시스템."}
{"patent_id": "10-2022-0161214", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 서비스 서버는 작업 현장별 스트리밍 토큰을 부여하고,작업 현장에 대한 협업 서비스를 제공받는 현장 단말 또는 원격 단말 중 하나의 단말로 스트리밍 토큰을 제공하여 스트리밍 토큰을 제공받은 단말로 XR 콘텐츠를 제공하고,스트리밍 토큰을 제공받은 단말에서 XR 콘텐츠를 타 단말로 스트리밍하는 것을 특징으로 하는 메타버스 공간 구성을 이용한 원격 XR 협업 시스템."}
{"patent_id": "10-2022-0161214", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,상기 서비스 서버는 VR 모드의 원격 단말로부터 작업대상 3D 모델을 이용한 원격 작업자의 작업대상 시연 정보를 AR 모드의 현장 단말로 제공하고,이에 대해 현장 단말로부터 제공되는 현장 작업자의 실제 작업대상 조작 정보를 VR 모드의 원격 단말로 제공하는 것을 특징으로 하는 메타버스 공간 구성을 이용한 원격 XR 협업 시스템. 공개특허 10-2024-0079241-3-청구항 5 제1항에 있어서,상기 서비스 서버는 현장 단말로부터 실시간 제공되는 현장 이미지로부터 배경 영역에 대한 메타버스 공간을 실시간 재구성하여 XR 콘텐츠를 생성하는 것을 특징으로 하는 메타버스 공간 구성을 이용한 원격 XR 협업 시스템."}
{"patent_id": "10-2022-0161214", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 작업대상과 배경정보를 분리하여 작업대상은 3D 모델로 제공하고, 배경정보는 작업 현장을 메타버스 공간으로 재구성하여 현장 작업자의 단말과 원격 작업자의 단말로 제공함으로써, 협업을 위한 3D 모델링 작업을 최소화하면서 보다 몰입도 있는 원격 XR 협업 서비스를 제공하는 기술에 관한 것이다. (뒷면에 계속)"}
{"patent_id": "10-2022-0161214", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 작업대상과 배경정보를 분리하여 작업대상은 3D 모델로 제공하고, 배경정보는 작업 현장을 메타버스 공간으로 재구성하여 현장 작업자의 단말과 원격 작업자의 단말로 제공함으로써, 협업을 위한 3D 모델링 작업을 최소화하면서 보다 몰입도 있는 원격 XR 협업 서비스를 제공하는 기술에 관한 것이다."}
{"patent_id": "10-2022-0161214", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "현대에는 기술의 빠른 발전과 고도의 전문화로 인해 협업의 중요성이 주목받고 있다. 협업을 위한 커뮤니케이션 에는 전화, 이메일 등의 다양한 수단이 이용될 수 있는데, 시장에는 마이크로소프트 팀즈나 네이버웍스처럼 다 양한 협업 커뮤니케이션 채널들을 체계적으로 이용할 수 있도록 만든 여러 솔루션이 공급되고 있다. 새로운 HTML5 웹 표준의 제정은 ActiveX와 같은 별도의 플러그인이나 프로그램의 설치 없이 웹 브라우저만으로 도 실시간 영상 및 음성, 데이터 통신이 가능하게 되었으며, 이를 기반으로 한 사용자 접근성이 뛰어난 웹 기반 의 협업 솔루션이 주목되기 시작하였다. 최근에는 회의를 마친 후에 주요 회의 내용의 분석이나 회의록 자동 작성 · 배포, 회의 중 잡음 처리 등 인공 지능 기술을 활용하여 원격 협업을 효과적으로 지원할 수 있는 다양한 사용자 맞춤형 서비스가 개발되고 있다. 또한, 원격 협업 기술은 인공지능 기술뿐만 아니라 5G 무선통신기술이나 Virtual Reality (VR)/Augmented Reality (AR)/Extended Reality (XR) 등의 신기술과 융합하여 원격 협업의 실제감과 몰입도를 극대화하는 방향 으로 발전하고 있다. 현재 주류가 되는 원격 XR 협업 방식은 현장 작업자가 원격 작업자에게 작업 현장을 비디오로 스트리밍해주고, 원격 작업자는 2D 모니터로 현장 작업자의 비디오 스트리밍을 관찰하며 그 위에 드로잉 또는 텍스트 코멘트 등 의 방법으로 필요한 작업 지시를 현장 작업자에게 전달하는 방식으로, 현재의 상용 서비스 수준에서의 원격 XR 협업은 비효율적인 부분이 있으며 생각만큼 편리하기만은 하지 않다. 즉, 이러한 비디오 스트리밍 기반 XR 협업은 사용법이 단순하고 구현이 간단해 많이 이용되고 있지만, 원격 작 업자의 수동적인 현장 관찰 등의 한계점을 가지고 있다. 또한, 비디오 스트리밍 기반 XR 협업은 2D 모니터 위에 그림을 그리는 것이므로 원격 작업자가 깊이감을 혼동하 여 잘못된 위치에 그림을 그리는 문제가 있으며, 드로잉을 통해 정보를 전달하므로 원격 작업자의 그림 묘사 능 력에 따라 현장 작업자와의 협업 효율이 달라질 수 있다. 그리고, 이러한 원격 작업자의 부정확한 정보 전달은 원격 작업자의 입장에서는 비디오를 촬영하는 카메라의 위 치를 제어할 권한이 없기 때문에 카메라를 들고 있는 현장 작업자에게 의존하여 현장의 상황을 수동적으로만 살 피거나, 작업 현장을 다른 위치에서 보고 싶으면 그러한 의도와 의사를 현장 작업자에게 전달해야 하는 바, 원 격 작업자가 정확히 자신이 원하는 위치로 카메라를 옮기기 위하여 현장 작업자와 여러 번의 소모적인 의사소통 이 오가야하기 때문에, 전체적인 작업 시간이 지연되는 문제가 있다."}
{"patent_id": "10-2022-0161214", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 2, "content": "선행기술문헌특허문헌 (특허문헌 0001) 1. 한국등록특허 제10-2388442호 (명칭 : 증강현실 기반의 메타버스 서비스 장치 및 그 장치의 구동방법) (특허문헌 0002) 2. 한국등록특허 제10-2402580호 (명칭 : 메타버스 환경에서의 영상 처리 시스템 및 방법)"}
{"patent_id": "10-2022-0161214", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "이에, 본 발명은 상기한 사정을 감안하여 창출된 것으로, 작업대상에 대해서만 3D 모델링을 수행하여 3D 모델을 통해 작업대상에 대한 협업 처리를 수행함으로써 작업대상에 대한 원격 작업자의 요구를 현장 작업자가 보다 정 확하게 인지하여 효율적인 협업이 가능하고, 작업 현장을 원격 작업자 단말의 가상 배경으로 제공하여 원격 작 업자에게 작업 현장의 실제감과 몰입감을 제공할 수 있도록 해 주는 메타버스 공간 구성을 이용한 원격 XR 협업 시스템을 제공함에 그 기술적 목적이 있다."}
{"patent_id": "10-2022-0161214", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기 목적을 달성하기 위한 본 발명의 일측면에 따르면, 작업 현장에 위치하는 현장 작업자와 원격지에 위치하 는 원격 작업자간 작업 현장의 작업대상에 대한 협업 서비스를 제공하는 XR 협업 시스템에 있어서, 현장 작업자 가 구비하는 것으로, 작업대상을 포함하는 현장 이미지와 라이다 센서를 통해 획득한 작업 현장의 깊이 이미지 를 서비스 서버로 전송하고, 서비스 서버로부터 제공되는 협업 서비스를 위한 XR 콘텐츠를 표시출력함과 더불어, 현장 작업자에 의해 조작되는 작업대상 조작 정보를 서비스 서버로 전송하는 현장 단말과, 원격 작업자 가 구비하는 것으로, 서비스 서버로부터 제공되는 협업 서비스를 위한 XR 콘텐츠를 표시출력함과 더불어, 원격 작업자에 의해 조작되는 작업대상 조작 정보를 서비스 서버로 전송하는 원격 단말 및, 상기 현장 단말과 원격 단말로 협업 서비스를 위한 XR 콘텐츠를 AR 또는 VR 모드로 동기화하여 제공하되, 작업대상에 대해서는 3D 모델 을 생성하여 작업자의 조작에 대응되게 변화되는 3D 모델을 제공하고, 작업대상을 제외한 작업 현장의 배경 영 역은 메타버스 공간으로 재구성하여, AR 모드의 단말로는 작업대상 3D 모델을 배경 영역에 증강시켜 출력하고, VR 모드의 단말로는 메타버스 공간에 작업대상 3D 모델을 위치시켜 가상현실 형태로 출력하도록 제공하는 서비 스 서버를 포함하여 구성되는 것을 것을 특징으로 하는 메타버스 공간 구성을 이용한 원격 XR 협업 시스템이 제 공된다. 또한, 상기 서비스 서버는 현장 단말로부터 수신된 현장 이미지와 깊이 이미지를 이용하여 작업대상 영역을 추 출함과 더불어 작업대상 영역의 작업대상을 3D 모델링하여, 메타버스 공간의 작업대상 영역 위치에 작업대상 3D 모델이 배치된 구조의 XR 콘텐츠를 생성하여 현장 단말과 원격 단말로 제공하는 것을 특징으로 한다. 또한, 상기 서비스 서버는 작업 현장별 스트리밍 토큰을 부여하고, 작업 현장에 대한 협업 서비스를 제공받는 현장 단말 또는 원격 단말 중 하나의 단말로 스트리밍 토큰을 제공하여 스트리밍 토큰을 제공받은 단말로 XR 콘 텐츠를 제공하며, 스트리밍 토큰을 제공받은 단말에서 XR 콘텐츠를 타 단말로 스트리밍하는 것을 특징으로 한다. 또한, 상기 서비스 서버는 VR 모드의 원격 단말로부터 작업대상 3D 모델을 이용한 원격 작업자의 작업대상 시연 정보를 AR 모드의 현장 단말로 제공하고, 이에 대해 현장 단말로부터 제공되는 현장 작업자의 실제 작업대상 조 작 정보를 VR 모드의 원격 단말로 제공하는 것을 특징으로 한다. 또한, 상기 서비스 서버는 현장 단말로부터 실시간 제공되는 현장 이미지로부터 배경 영역에 대한 메타버스 공 간을 실시간 재구성하여 XR 콘텐츠를 생성하는 것을 특징으로 한다."}
{"patent_id": "10-2022-0161214", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명에 의하면, 작업대상에 대해서만 3D 모델링을 수행하여 3D 모델을 통해 작업대상에 대한 협업 처리를 수 행함으로써 작업대상에 대한 원격 작업자의 요구를 현장 작업자가 보다 정확하게 인지하여 효율적인 협업이 가 능하고, 작업 현장을 원격 작업자 단말의 가상 배경으로 제공하여 원격 작업자에게 작업 현장의 실제감과 몰입 감을 제공할 수 있다."}
{"patent_id": "10-2022-0161214", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명에 기재된 실시예 및 도면에 도시된 구성은 본 발명의 바람직한 실시예에 불과할 뿐이고, 본 발명의 기 술적 사상을 모두 표현하는 것은 아니므로, 본 발명의 권리범위는 본문에 설명된 실시예 및 도면에 의하여 제한 되는 것으로 해석되어서는 아니 된다. 즉, 실시예는 다양한 변경이 가능하고 여러 가지 형태를 가질 수 있으므 로 본 발명의 권리범위는 기술적 사상을 실현할 수 있는 균등물들을 포함하는 것으로 이해되어야 한다. 또한, 본 발명에서 제시된 목적 또는 효과는 특정 실시예가 이를 전부 포함하여야 한다거나 그러한 효과만을 포함하여 야 한다는 의미는 아니므로, 본 발명의 권리범위는 이에 의하여 제한되는 것으로 이해되어서는 아니 될 것이다. 여기서 사용되는 모든 용어들은 다르게 정의되지 않는 한, 본 발명이 속하는 분야에서 통상의 지식을 가진 자에 의해 일반적으로 이해되는 것과 동일한 의미를 가진다. 일반적으로 사용되는 사전에 정의되어 있는 용어들은 관 련 기술의 문맥상 가지는 의미와 일치하는 것으로 해석되어야 하며, 본 발명에서 명백하게 정의하지 않는 이상 적이거나 과도하게 형식적인 의미를 지니는 것으로 해석될 수 없다. 도1은 본 발명의 제1 실시예에 따른 메타버스 공간 구성을 이용한 원격 XR 협업 시스템의 개략적인 구성도이다. 도1을 참조하면, 본 발명에 따른 메타버스 공간 구성을 이용한 원격 XR 협업 시스템은, 적어도 하나의 현장 단 말과 적어도 하나의 원격 단말 및, 서비스 서버를 포함하여 구성된다. 이때, 현장 단말은 작업 현장에 위치하는 현장 작업자의 단말이고, 원격 단말은 현장 작업자와 현장 에 위치하는 작업대상에 대한 협업을 수행하는 원격 작업자의 단말로서, 디스플레이 수단과 카메라가 구비된 AR 단말이거나 VR단말이 될 수 있다. 그리고, 현장 단말은 라이다 센서(미도시 됨)를 구비하여 현장에 위치한 작업대상을 포함한 현장의 깊이 이미지를 서비스 서버로 제공한다. 서비스 서버는 이미지 트래킹을 바탕으로 현장 단말과 원격 단말간 작업대상에 대한 협업 서비 스를 제공하되, 협업 서비스시 현장 배경을 메타버스 공간으로 실시간 재구성하여 원격 단말로 제공한다. 이때, 서비스 서버는 현장 단말 또는 원격 단말로 스트리밍 토큰을 제공하여, 작업대상 3D 모델 은 서비스 서버에서 제공하고, 배경 정보는 스트리밍 토큰을 제공받은 현장 단말 또는 원격 단말 에서 협업 대상인 타 단말로 실시간 스트리밍하도록 실시할 수 있다. 바람직하게는 배경 정보에 대한 스트 리밍 토큰은 현장 단말에 제공될 수 있다. 또한, 서비스 서버는 현장 단말과 원격 단말로 협업 서비스를 위한 XR 콘텐츠를 생성하여 제공 하는데, 작업 단말의 인터랙션 모드에 따라 VR 또는 AR 형태로 렌더링하여 해당 단말로 제공한다. 이하에서는 현장 단말로 AR 형태로 협업 서비스를 위한 XR 컨텐츠가 제공되고, 원격 단말로 VR 형태 로 협업 서비스를 위한 XR 컨텐츠가 제공되는 구성에 대해 설명한다. 또한, 본 발명에서는 VR 모드와 AR 모드에서 자유롭게 인터랙션 환경을 제공하기 위해 XR 콘텐츠 표현인 Webized XR (WXR)태그를 도2와 같이 정의한다. 도2에는 XR 콘텐츠를 구성하는 기본요소인 WXR 태그와 그 계층구 조가 도시되어 있다. 도2에서 wxr-element 태그는 브라우저에 의해 생성된 XR 콘텐츠의 DOM트리와 3차원 씬 그래프를 동기화하는 기 본적인 역할을 수행하며, wxr-world 태그는 HTML 문서 내에서 XR 콘텐츠의 시작을 알리는 역할을 하고 wxr- space 태그는 하나의 XR콘텐츠 내에서 논리적인 공간을 구분하는 역할을 한다. 이때, 하나의 wxr-world 태그 내 에는 wxr-space 태그로 나타내어지는 다수의 space가 포함될 수 있다. wxr-camera태그는 작업 단말의 추상 엘리먼트를 나타내는 것으로, VR 모드에서는 HMD를 나타내며, AR 모드에서 는 작업자의 AR 장치를 나타낸다. wxr-light 태그는 다양한 형태의 광원을 시뮬레이션하는 추상 엘리먼트이다. 이때, 실제 광원 역할을 하는 엘리 먼트는 wxr-lightambient, wxr-light-directional, wxr-ligth-spot, wxr-light-point 태그이다. wxr-group 태그는 콘텐츠에 기술된 여러 엘리먼트를 하나로 묶는 역할을 한다. wxr-geometry 태그는 XR 콘텐츠를 구성하는 여러 프리미티브들의 추상 엘리먼트로서, wxr-geoemetry를 상속하는 엘리먼트는 큐브 형태의 가상 물체를 나타내는 wxr-box, 평면 형태의 가상 물체를 나타내는 wxr-plane, 구체 형 태의 가상 물체를 나타내는 wxr-sphere 등이 있다. 여기서, wxr-geometry 태그를 상속하는 것들과 wxr-group 태그는 ar-target 속성을 가질 수 있고, ar-target 속성은 Uniform Resource Locator (URL)을 값을 가지며, 이 URL은 AR 모듈이 실존 물체를 인식하기 위한 특징 정보를 가리킨다. 즉, AR 모드에서 이 특징 정보를 가지고 현재의 비디오 프레임에서의 실존 물체의 존재 여부 판별과 위치 및 회전의 상태 정보를 트래킹한다. 도3은 도1에 도시된 서비스 서버의 내부구성을 기능적으로 분리하여 나타낸 도면이다. 도3을 참조하면, 서비스 서버는 정보 수집부와 작업대상 처리부, 동기화 처리부, 메타버스 공간 생성부 및, XR협업 처리부를 포함한다. 정보 수집부는 현장 단말 및 원격 단말로부터 XR 협업관련 정보를 수집한다. 정보 수집부 는 현장 단말로부터 작업대상 정보와, 인터랙션 모드 정보(AR 모드), 현장 이미지 및, 현장 작업자의 작업 대상 조작정보를 포함한 현장 정보를 수집하고, 원격 단말로부터 인터랙션 모드 정보(VR 모드)와, 원격 작 업자의 작업대상 조작정보를 포함하는 원격 정보를 수집한다. 작업대상 처리부는 현장 단말 및 원격 단말을 통해 수집된 이미지에서 작업대상이 포함된 협업 영역을 트레킹하여 3D 모델로 렌더링한다. 동기화 처리부는 스페이스 마커를 이용하여 단말의 카메라와 작업대상의 움직임을 구분할 기준이 되는 카 메라 좌표계와 월드 좌표계간 변환을 수행하여 VR 모드와 AR 모드에서의 좌표계를 월드 좌표계로 동기화한다. 여기서, 스페이스 마커는 wxr-space 태그에 arbase라는 속성으로 기록되며, 이 속성은 ar-target 속성과 마찬 가지로 스페이스 마커 역할을 하는 실존 물체 대한 특징 정보를 URL로 가리킨다. 그리고, 콘텐츠 코드에 스페이스 마커의 transform 정보를 특정하지 않기 때문에 관리자는 스페이스 마커를 메 타버스 공간상의 임의의 위치에 배치하여 사용할 수 있으며, 스페이스 마커의 transform 정보가 정해지는 시점 은 AR 모듈이 처음으로 스페이스 마커와 협업 대상 물체를 동시에 탐지할 때로 설정될 수 있다. 도4는 작업대상 물체의 모델 매트리스를 산출하는 과정을 나타내는 모식도로서, 동기화 처리부는 수학식1 을 이용하여 카메라 좌표계를 월드 좌표계로 변환할 수 있다.수학식 1"}
{"patent_id": "10-2022-0161214", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "여기서, C'는 카메라 매트릭스이고, Mo'는 작업대상 물체의 모델 매트릭스이다. 메타버스 공간 생성부는 현장 단말의 라이다(LiDAR) 센서로부터 수집한 깊이 이미지를 근거로 포인트 클라우드를 생성하고, 이 포인트 클라우드 데이터에서 작업대상이 포함된 협업 영역을 마스킹하여 제거함으로써, 현장 작업자와 원격 작업자가 공유하는 현장 작업장에 해당하는 메타버스 공간 즉, 배경정보를 생성한다. 이러한 메타버스 공간 생성부는 포인트 클라우드 재구성 모듈과 작업대상 마스킹 모듈을 포함한 다. 포인트 클라우드 재구성 모듈은 현장 단말로부터 수집한 현장의 깊이 이미지를 하기 수학식2를 이용 하여 3차원의 포인트 클라우드로 재구성한다. 여기서, 수학식2는 월드 좌표계상의 점을 계산하는 수식이다. 수학식 2"}
{"patent_id": "10-2022-0161214", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "이때, 포인트 클라우드 재구성 모듈은 깊이 이미지로부터 3차원 공간상의 점 좌표를 구하는 작업뿐만 아니 라 각 포인트가 나타내는 컬러 정보를 RGB 포맷으로 변환하게 되는데, 이는 먼저 YUV420p 포맷으로 컬러 정보를 담고 있는 ARKit의 capturedImage 객체로부터 이를 래핑하는 CIImage 객체를 생성하고, 이를 RGB 포맷으로 버퍼 를 관리하는 CGImage 객체로 변환함으로써 깊이 이미지로부터 3차원 점의 위치를 계산하고 RGB 컬러 샘플링을 통해 컬러 정보를 더하여 최종적으로 포인트 클라우드 데이터를 재구성할 수 있다. 작업대상 마스킹 모듈은 협업시 발생하는 포인트 클라우드의 잔상을 없애기 위해 작업 영역을 마스킹하고 제거한다. 즉, 작업대상 마스킹 모듈은 작업대상 처리부에서 전달받은 작업대상 물체에 대한 버텍스 배열과 인 덱스 배열을 3D 모델로 변환하여 관리하며, 렌더러를 이용하여 off-screen렌더링하여 가상 카메라의 뎁스 맵(z- buffer)을 생성한다. 이때, 3D 모델의 뎁스 맵을 얻는 데에는 3D 모델의 형상과 가상 카메라의 위치 및 방향 정 보만이 필요하므로, 작업대상 마스킹 모듈은 작업대상 물체의 지오메트리 정보(버텍스 배열과 인덱스 배열)만을 수집한다. 그리고, 작업대상 마스킹 모듈은 가상 카메라의 z-buffer를 재구성한 포인트 클라우드 데이터의 z-buffer 값과 비교하여 작업대상 물체가 포함된 작업 영역의 포인트들을 마스킹함으로써, 포인트 클라우드의 잔상이 제 거된 메타버스 공간을 생성한다. XR 협업 처리부는 작업 현장에 대응하여 현장 작업자의 적어도 하나의 현장 단말과 적어도 한 명 이 상의 원격 작업자의 원격 단말을 협업 그룹으로 설정하고, 협업 그룹으로 설정된 현장 단말과 원격 단말로 3D 모델 형태의 작업대상 정보와 메타버스 공간정보로 이루어지는 XR 콘텐츠를 AR 또는 VR 형태로 제공함으로써, 작업대상에 대한 협업 서비스를 제공한다. 이때, XR 협업 처리부는 작업대상에 대한 3D 모델을 포함하는 XR 콘텐츠를 현장 단말 및 원격 단말 로 제공하되, WXR 렌더러(Renderer)를 이용하여 기 설정된 인터랙션 모드에 따라 현장 단말로는 작업 대상 3D 모델을 AR 형태로 제공하고, 원격 단말로는 XR 콘텐츠와 작업대상에 대한 3D 모델을 VR 형태로 제공한다. XR 콘텐츠를 화면으로 제공하는 WXR Renderer의 렌더링 루프는 작업 단말(100,200)의 인터랙션 모드에 대응되게 가상 물체를 렌더링하도록 구성된다. 즉, WXR Renderer는 인터랙션 모드가 VR 인 경우, 가상 배경을 포함한 모든 가상 물체의 렌더링 속성을 visible 로 설정하여 몰입적인 VR 콘텐츠를 제공한다. 또한, WXR Renderer는 인터랙션 모드가 AR 인 경우, 가상 배경을 포함한 모든 가상 물체의 렌더링 속성을 invisible로 설정하여, 가상 배경이 카메라 영상을 가려 AR 장치의 화면을 통해 앞으로 볼 수 없었던 문제를 회 피할 수 있다. 이와 같이 모든 가상 물체가 invisible로 설정된 후, 이미지를 분석하여 기 설정된 실존 물체로 인식되는 것이 있는지 확인하고, 인식된 실존 물체가 있다면 이에 해당하는 가상 물체만 렌더링 속성을 visible 로 변경한다. 그리고, 최종적으로 렌더러는 렌더링 속성이 visible인 해당 가상 물체만 표현되도록 한다. 결과적으로 XR 코드를 해석하는 렌더러에서 하나의 XR 콘텐츠를 VR 환경과 AR 환경 모두에서 사용할 수 있도록 만들어 준다. 또한, XR 협업 처리부는 겹침 협업 방지를 위해 작업 현장마다 포인트 클라우드 데이터를 스트리밍할 수 있는 \"스트리밍 토큰\"을 하나씩 생성하여 관리할 수 있다. 이때, 스트리밍 토큰은 현장 작업자가 AR 모드로 동작되는 현장 단말로부터의 요청에 따라 해당 작업 현장 에 현재 스트리밍 토큰을 소유하고 있는 다른 작업자가 없을 경우 요청한 해당 현장 단말로 스트리밍 토큰 을 전달하고, 이는 포인트 클라우드 데이터 스트리밍을 종료하거나 혹은 해당 현장 단말의 작업자가 작업 현장에서 나갈 때 회수될 수 있다. 한편, 현장 단말은 스트리밍 토큰을 수신함으로써, 자신이 포인트 클라우드 데이터 즉, XR 콘텐츠를 중계 할 권한이 있음을 인지하고, SDP를 XR 협업 처리부로 전달하여 해당 협업 그룹의 원격 단말과 WebRTC 연결을 설정한다. 이때, 현장 단말은 XR 협업 처리부를 통해 협업 그룹의 원격 단말과 WebRTC 연결을 설정하거나, 또는 협업 그룹의 원격 단말과 직접 WebRTC 연결을 설정하여 XR 콘텐츠를 실시간 제공할 수 있다."}
{"patent_id": "10-2022-0161214", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "이어, 상기한 구성으로 된 실시간 메타버스 공간 구성을 이용한 원격 XR 협업 시스템의 동작을 도5에 도시된 흐 름도를 참조하여 설명한다. 먼저, 서비스 서버는 해당 작업 현장에 대해 협업 작업을 수행할 적어도 하나의 현장 단말과 적어도 하나의 원격 단말을 하나의 협업 그룹으로 설정한다. 상기한 상태에서, 서비스 서버는 본 발명에 따른 XR 협업 서비스를 제공하기 위해 현장 단말과 원격 단말로부터 각종 정보를 수집한다(ST100). 이때, 서비스 서버는 현장 단말과 원격 단말의 인터랙션 모드 정보와, 현장 이미지 및, 협업할 작업대상 정보를 수집할 수 있다. 그리고, 인터랙션 모드는 해 당 작업자가 자신의 단말에 대응되게 선택할 수 있다. 이어, 서비스 서버는 현장 이미지에서 작업대상을 트래킹하여 해당 영역의 작업대상을 3D 모델링한다 (ST200). 이때, 서비스 서버는 작업대상이 포함된 협업 영역의 위치와, 작업대상 3D 모델을 포함한 작업대 상 3D 모델 정보를 저장한다. 또한, 서비스 서버는 현장 이미지에서 협업 영역을 제외한 나머지 배경 영역을 메타버스 공간으로 재구성 한다 (ST300). 즉, 서비스 서버는 현장 이미지의 배경영역에 해당하는 포인트 클라우드 데이터를 생성한다. 이어, 서비스 서버는 상기 ST100 단계에서 협업 그룹내 현장 단말과 원격 단말의 인터랙션 모드 에 대응되는 XR 콘텐츠를 생성하고, 이를 상호 동기화하여 제공한다(ST400). 즉, 서비스 서버는 AR 모드로 설정된 현장 단말로는 현장 이미지의 협업 영역에 작업대상 3D 모델을 증강시켜 AR 형태의 XR 콘텐츠를 제공하고, VR 모드로 설정된 원격 단말로는 현장 이미지의 배경 영역과 작업대상 3D 모델을 VR 변환하여 XR 콘텐츠를 제공한다. 도6은 현장 작업자와 원격 작업자의 작업대상 조작시의 XR 콘텐츠 제공을 통한 협업 서비스 과정을 예시한 도면 이다. 도6에서 (A)는 원격작업자가 VR 모드의 원격 단말을 구비한 상태에서, 원격 단말을 통해 제공되는 XR 화면이다. VR 모드의 원격 단말로 현장 배경과 작업대상 3D 모델이 가상현실 형태로 출력된다. 상기한 상태에서, 원격 작업자가 자신의 원격 단말을 이용하여 출력 화면에서 작업대상을 조작하게 되면, 서비스 서버에서 원격 작업자의 작업대상 조작정보를 실시간 수집하고 (B)에 도시된 바와 같이 이를 현장 단말의 출력 화면의 작업대상 영역에 동기화하여 증강현실 형태로 출력되도록 한다. 이때, 원격 작업자는 위치가 동기화된 3D 모델의 작업대상을 볼 수 있기 때문에, 현장 작업자에 의지하지 않고 자신이 원하는 시점에서 작업대상을 관찰하는 것이 가능하며, 현장 작업자에게 작업대상에 대한 지시 사항을 3D 모델의 작업대상을 조작(시연)하는 방법으로 제공할 수 있다. 또한, 현장 작업자는 자신의 현장 단말을 통해 현장 이미지의 작업대상 위치에 증강된 가상 물체(작업대상 의 3D 모델)의 움직임으로 출력되는 바, 직관적으로 작업 방법을 정확하게 인지할 수 있다. 이에 대해, 현장 작업자가 작업 현장에서 실제 작업대상을 조작하게 되면, 이러한 작업대상을 포함한 현장 이미 지가 현장 단말을 통해 서비스 서버로 전송되고, 서비스 서버는 현장 이미지에서 작업대상의 위 치를 이미지 트래킹하여 기 저장된 해당 작업대상 3D 모델에 반영한 후, 이를 원격 작업자의 원격 단말로 전송한다. 즉, (C)에 도시된 바와 같이, 현장 작업자의 작업대상에 대한 조작상황이 원격 작업자의 원격 단말 을 통해 가상 현실 형태로 출력된다. 이에 따라 원격 작업자는 현장 작업자가 자신이 지시한 작업대상에 대한 지시 사항을 제대로 실행하는지를 용이하게 확인할 수 있다."}
{"patent_id": "10-2022-0161214", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도1은 본 발명의 제1 실시예에 따른 메타버스 공간 구성을 이용한 원격 XR 협업 시스템의 개략적인 구성도. 도2는 본 발명에서 제공되는 XR 콘텐츠를 구성하는 기본요소인 WXR 태그와 그 계층구조를 도시한 도면. 도3은 도1에 도시된 서비스 서버의 내부구성을 기능적으로 분리하여 나타낸 도면. 도4는 도3에 도시된 동기화 처리부에서 작업대상 물체의 모델 매트리스를 산출하는 과정을 나타내는 모식 도. 도5는 도1에 도시된 메타버스 공간 구성을 이용한 원격 XR 협업 시스템의 동작을 설명하기 위한 흐름도. 도6은 현장 작업자와 원격 작업자의 작업대상 조작에 따른 협업 서비스 과정을 예시한 도면"}
