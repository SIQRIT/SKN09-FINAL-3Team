{"patent_id": "10-2024-7006856", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0039178", "출원번호": "10-2024-7006856", "발명의 명칭": "인코딩 및 디코딩 방법 그리고 장치", "출원인": "후아웨이 테크놀러지 컴퍼니 리미티드", "발명자": "류 지아잉"}}
{"patent_id": "10-2024-7006856", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "인코딩 방법으로서, 상기 인코딩 방법은,인코딩 대상 데이터를 획득하는 단계;상기 인코딩 대상 데이터를 제1 인코딩 네트워크에 입력하여 타깃 파라미터를 획득하는 단계;상기 타깃 파라미터에 기반하여 제2 인코딩 네트워크를 구성하는 단계;상기 인코딩 대상 데이터를 상기 제2 인코딩 네트워크에 입력하여 제1 특징을 획득하는 단계; 및상기 제1 특징을 인코딩하여 인코딩된 비트스트림을 획득하는 단계를 포함하는 인코딩 방법."}
{"patent_id": "10-2024-7006856", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 타깃 파라미터는 상기 제2 인코딩 네트워크의 콘볼루션 및 비선형 활성화를 위한 파라미터 가중치의 전부또는 일부인, 인코딩 방법."}
{"patent_id": "10-2024-7006856", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항 또는 제2항에 있어서, 상기 제1 특징을 인코딩하여 인코딩된 비트스트림을 획득하는 단계는, 상기 제1 특징을 반올림하여 상기 제1 특징의 정수 값을 획득하는 단계;상기 제1 특징의 정수 값에 대해 확률 추정을 수행하여 상기 제1 특징의 정수 값의 추정된 확률 분포를 획득하는 단계; 및상기 제1 특징의 정수 값의 추정된 확률 분포에 기반하여 상기 제1 특징의 정수 값에 대해 엔트로피 인코딩을수행하여 상기 인코딩된 비트스트림을 획득하는 단계를 포함하는, 인코딩 방법."}
{"patent_id": "10-2024-7006856", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서, 상기 제1 특징의 정수 값에 대해 확률 추정을 수행하여 상기 제1 특징의 정수 값의 추정된 확률 분포를 획득하는 단계는,제1 정보에 기반하여 상기 제1 특징의 정수 값에 대해 확률 추정을 수행하여 상기 제1 특징의 정수 값의 추정된확률 분포를 획득하는 단계 - 상기 제1 정보는 콘텍스트 정보 및 부가 정보 중 적어도 하나를 포함함 -를 포함하는, 인코딩 방법."}
{"patent_id": "10-2024-7006856", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "디코딩 방법으로서,상기 디코딩 방법은,디코딩 대상 비트스트림을 획득하는 단계;공개특허 10-2024-0039178-3-상기 디코딩 대상 비트스트림을 디코딩하여 제1 특징의 정수 값 및 제2 특징의 정수 값을 획득하는 단계 - 상기제1 특징의 정수 값은 디코딩된 데이터를 획득하는 데 사용되고, 상기 제2 특징의 정수 값은 타깃 파라미터를획득하는 데 사용됨 -;상기 제2 특징의 정수 값을 제1 디코딩 네트워크에 입력하여 상기 타깃 파라미터를 획득하는 단계;상기 타깃 파라미터에 기반하여 제2 디코딩 네트워크를 구성하는 단계; 및상기 제1 특징의 정수 값을 상기 제2 디코딩 네트워크에 입력하여 상기 디코딩된 데이터를 획득하는 단계를 포함하는 디코딩 방법."}
{"patent_id": "10-2024-7006856", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5항에 있어서, 상기 타깃 파라미터는 상기 제2 인코딩 네트워크의 콘볼루션 및 비선형 활성화를 위한 파라미터 가중치의 전부또는 일부인, 디코딩 방법."}
{"patent_id": "10-2024-7006856", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제5항 또는 제6항에 있어서, 상기 디코딩 대상 비트스트림은 제1 디코딩 대상 비트스트림과 제2 디코딩 대상 비트스트림을 포함하고, 상기 디코딩 대상 비트스트림을 디코딩하여 제1 특징의 정수 값 및 제2 특징의 정수 값을 획득하는 단계는,상기 제1 디코딩 대상 비트스트림을 디코딩하여 상기 제1 특징의 정수 값을 획득하는 단계; 및상기 제2 디코딩 대상 비트스트림을 디코딩하여 상기 제2 특징의 정수 값을 획득하는 단계를 포함하는, 디코딩 방법."}
{"patent_id": "10-2024-7006856", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서, 상기 제1 디코딩 대상 비트스트림을 디코딩하여 상기 제1 특징의 정수 값을 획득하는 단계는, 상기 제1 디코딩 대상 비트스트림에서의 상기 제1 특징의 정수 값에 대해 확률 추정을 수행하여 상기 제1 특징의 정수 값의 추정된 확률 분포를 획득하는 단계; 및상기 제1 특징의 정수 값의 추정된 확률 분포에 기반하여 상기 제1 디코딩 대상 비트스트림에 대해 엔트로피 디코딩을 수행하여 상기 제1 특징의 정수 값을 획득하는 단계를 포함하는, 디코딩 방법."}
{"patent_id": "10-2024-7006856", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서, 상기 제1 디코딩 대상 비트스트림에서의 상기 제1 특징의 정수 값에 대해 확률 추정을 수행하여 상기 제1 특징의 정수 값의 추정된 확률 분포를 획득하는 단계는,제1 정보에 기반하여 상기 제1 디코딩 대상 비트스트림에서의 상기 제1 특징의 정수 값에 대해 확률 추정을 수행하여 상기 제1 특징의 정수 값의 추정된 확률 분포를 획득하는 단계 - 상기 제1 정보는 콘텍스트 정보 및 부가 정보 중 적어도 하나를 포함함 -를 포함하는, 디코딩 방법."}
{"patent_id": "10-2024-7006856", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제7항 내지 제9항 중 어느 한 항에 있어서, 상기 제2 디코딩 대상 비트스트림을 디코딩하여 상기 제2 특징의 정수 값을 획득하는 단계는,공개특허 10-2024-0039178-4-상기 제2 디코딩 대상 비트스트림에서의 상기 제2 특징의 정수 값에 대해 확률 추정을 수행하여 상기 제2 특징의 정수 값의 추정된 확률 분포를 획득하는 단계; 및상기 제2 특징의 정수 값의 추정된 확률 분포에 기반하여 상기 제2 디코딩 대상 비트스트림에 대해 엔트로피 디코딩을 수행하여 상기 제2 특징의 정수 값을 획득하는 단계를 포함하는, 디코딩 방법."}
{"patent_id": "10-2024-7006856", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제10항에 있어서, 상기 제2 디코딩 대상 비트스트림에서의 상기 제2 특징의 정수 값에 대해 확률 추정을 수행하여 상기 제2 특징의 정수 값의 추정된 확률 분포를 획득하는 단계는, 상기 제1 정보에 기반하여 상기 제2 디코딩 대상 비트스트림에서의 상기 제2 특징의 정수 값에 대해 확률 추정을 수행하여 상기 제2 특징의 정수 값의 추정된 확률 분포를 획득하는 단계 - 상기 제1 정보는 콘텍스트 정보및 부가 정보 중 적어도 하나를 포함함 -를 포함하는, 디코딩 방법."}
{"patent_id": "10-2024-7006856", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "디코딩 방법으로서,상기 디코딩 방법은,디코딩 대상 비트스트림을 획득하는 단계;상기 디코딩 대상 비트스트림을 디코딩하여 제1 특징의 정수 값을 획득하는 단계 - 상기 제1 특징의 정수 값은디코딩된 데이터 및 타깃 파라미터를 획득하는 데 사용됨 -;상기 제1 특징의 정수 값을 제1 디코딩 네트워크에 입력하여 상기 타깃 파라미터를 획득하는 단계;상기 타깃 파라미터에 기반하여 제2 디코딩 네트워크를 구성하는 단계; 및상기 제1 특징의 정수 값을 상기 제2 디코딩 네트워크에 입력하여 상기 디코딩된 데이터를 획득하는 단계를 포함하는 디코딩 방법."}
{"patent_id": "10-2024-7006856", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제12항에 있어서, 상기 타깃 파라미터는 상기 제2 인코딩 네트워크의 콘볼루션 및 비선형 활성화를 위한 파라미터 가중치의 전부또는 일부인, 디코딩 방법."}
{"patent_id": "10-2024-7006856", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제12항 또는 제13항에 있어서, 상기 디코딩 대상 비트스트림을 디코딩하여 제1 특징의 정수 값을 획득하는 단계는,상기 디코딩 대상 비트스트림에서의 상기 제1 특징의 정수 값에 대해 확률 추정을 수행하여 상기 제1 특징의 정수 값의 추정된 확률 분포를 획득하는 단계; 및상기 제1 특징의 정수 값의 추정된 확률 분포에 기반하여 상기 디코딩 대상 비트스트림에 대해 엔트로피 디코딩을 수행하여 상기 제1 특징의 정수 값을 획득하는 단계를 포함하는, 디코딩 방법."}
{"patent_id": "10-2024-7006856", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제14항에 있어서, 공개특허 10-2024-0039178-5-상기 디코딩 대상 비트스트림에서의 상기 제1 특징의 정수 값에 대해 확률 추정을 수행하여 상기 제1 특징의 정수 값의 추정된 확률 분포를 획득하는 단계는, 제1 정보에 기반하여 상기 디코딩 대상 비트스트림에서의 상기 제1 특징의 정수 값에 대해 확률 추정을 수행하여 상기 제1 특징의 정수 값의 추정된 확률 분포를 획득하는 단계 - 상기 제1 정보는 콘텍스트 정보 및 부가 정보 중 적어도 하나를 포함함 -를 포함하는, 디코딩 방법."}
{"patent_id": "10-2024-7006856", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "처리 회로를 포함하는 인코딩 장치로서,상기 처리 회로는, 인코딩 대상 데이터를 획득하고;상기 인코딩 대상 데이터를 제1 인코딩 네트워크에 입력하여 타깃 파라미터를 획득하며;상기 타깃 파라미터에 기반하여 제2 인코딩 네트워크를 구성하고;상기 인코딩 대상 데이터를 상기 제2 인코딩 네트워크에 입력하여 제1 특징을 획득하며; 그리고상기 제1 특징을 인코딩하여 인코딩된 비트스트림을 획득하도록 구성되는, 인코딩 장치."}
{"patent_id": "10-2024-7006856", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제16항에 있어서, 상기 타깃 파라미터는 상기 제2 인코딩 네트워크의 콘볼루션 및 비선형 활성화를 위한 파라미터 가중치의 전부또는 일부인, 인코딩 장치."}
{"patent_id": "10-2024-7006856", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제16항 또는 제17항에 있어서,상기 처리 회로는 구체적으로,상기 제1 특징을 반올림하여 상기 제1 특징의 정수 값을 획득하고;상기 제1 특징의 정수 값에 대해 확률 추정을 수행하여 상기 제1 특징의 정수 값의 추정된 확률 분포를 획득하며; 그리고상기 제1 특징의 정수 값의 추정된 확률 분포에 기반하여 상기 제1 특징의 정수 값에 대해 엔트로피 인코딩을수행하여 상기 인코딩된 비트스트림을 획득하도록 구성되는, 인코딩 장치."}
{"patent_id": "10-2024-7006856", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제18항에 있어서, 상기 처리 회로는 구체적으로,제1 정보에 기반하여 상기 제1 특징의 정수 값에 대해 확률 추정을 수행하여 상기 제1 특징의 정수 값의 추정된확률 분포를 획득하도록 구성되고, 상기 제1 정보는 콘텍스트 정보 및 부가 정보 중 적어도 하나를 포함하는,인코딩 장치."}
{"patent_id": "10-2024-7006856", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "처리 회로를 포함하는 디코딩 장치로서,상기 처리 회로는,디코딩 대상 비트스트림을 획득하고;상기 디코딩 대상 비트스트림을 디코딩하여 제1 특징의 정수 값 및 제2 특징의 정수 값을 획득하며 - 상기 제1공개특허 10-2024-0039178-6-특징의 정수 값은 디코딩된 데이터를 획득하는 데 사용되고, 상기 제2 특징의 정수 값은 타깃 파라미터를 획득하는 데 사용됨 -;상기 제2 특징의 정수 값을 제1 디코딩 네트워크에 입력하여 상기 타깃 파라미터를 획득하고;상기 타깃 파라미터에 기반하여 제2 디코딩 네트워크를 구성하며; 그리고상기 제1 특징의 정수 값을 상기 제2 디코딩 네트워크에 입력하여 상기 디코딩된 데이터를 획득하도록구성되는, 디코딩 장치."}
{"patent_id": "10-2024-7006856", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_21", "content": "제20항에 있어서, 상기 타깃 파라미터는 상기 제2 인코딩 네트워크의 콘볼루션 및 비선형 활성화를 위한 파라미터 가중치의 전부또는 일부인, 디코딩 장치."}
{"patent_id": "10-2024-7006856", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_22", "content": "제20항 또는 제21항에 있어서, 상기 디코딩 대상 비트스트림은 제1 디코딩 대상 비트스트림과 제2 디코딩 대상 비트스트림을 포함하고, 상기 처리 회로는 구체적으로,상기 제1 디코딩 대상 비트스트림을 디코딩하여 상기 제1 특징의 정수 값을 획득하고; 그리고상기 제2 디코딩 대상 비트스트림을 디코딩하여 상기 제2 특징의 정수 값을 획득하도록 구성되는, 디코딩 장치."}
{"patent_id": "10-2024-7006856", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_23", "content": "제22항에 있어서, 상기 처리 회로는 구체적으로,상기 제1 디코딩 대상 비트스트림에서의 상기 제1 특징의 정수 값에 대해 확률 추정을 수행하여 상기 제1 특징의 정수 값의 추정된 확률 분포를 획득하고; 그리고상기 제1 특징의 정수 값의 추정된 확률 분포에 기반하여 상기 제1 디코딩 대상 비트스트림에 대해 엔트로피 디코딩을 수행하여 상기 제1 특징의 정수 값을 획득하도록 구성되는, 디코딩 장치."}
{"patent_id": "10-2024-7006856", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_24", "content": "제23항에 있어서, 상기 처리 회로는 구체적으로,제1 정보에 기반하여 상기 제1 디코딩 대상 비트스트림에서의 상기 제1 특징의 정수 값에 대해 확률 추정을 수행하여 상기 제1 특징의 정수 값의 추정된 확률 분포를 획득하도록 구성되며, 상기 제1 정보는 콘텍스트 정보및 부가 정보 중 적어도 하나를 포함하는, 디코딩 장치."}
{"patent_id": "10-2024-7006856", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_25", "content": "제22항 내지 제24항 중 어느 한 항에 있어서, 상기 처리 회로는 구체적으로,상기 제2 디코딩 대상 비트스트림에서의 상기 제2 특징의 정수 값에 대해 확률 추정을 수행하여 상기 제2 특징의 정수 값의 추정된 확률 분포를 획득하고; 그리고상기 제2 특징의 정수 값의 추정된 확률 분포에 기반하여 상기 제2 디코딩 대상 비트스트림에 대해 엔트로피 디코딩을 수행하여 상기 제2 특징의 정수 값을 획득하도록 구성되는, 디코딩 장치."}
{"patent_id": "10-2024-7006856", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_26", "content": "공개특허 10-2024-0039178-7-제25항에 있어서, 상기 처리 회로는 구체적으로,상기 제1 정보에 기반하여 상기 제2 디코딩 대상 비트스트림에서의 상기 제2 특징의 정수 값에 대해 확률 추정을 수행하여 상기 제2 특징의 정수 값의 추정된 확률 분포를 획득하도록 구성되고, 상기 제1 정보는 콘텍스트정보 및 부가 정보 중 적어도 하나를 포함하는, 디코딩 장치."}
{"patent_id": "10-2024-7006856", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_27", "content": "처리 회로를 포함하는 디코딩 장치로서,상기 처리 회로는, 디코딩 대상 비트스트림을 획득하고;상기 디코딩 대상 비트스트림을 디코딩하여 제1 특징의 정수 값을 획득하며 - 상기 제1 특징의 정수 값은 디코딩된 데이터 및 타깃 파라미터를 획득하는 데 사용됨 -;상기 제1 특징의 정수 값을 제1 디코딩 네트워크에 입력하여 상기 타깃 파라미터를 획득하고;상기 타깃 파라미터에 기반하여 제2 디코딩 네트워크를 구성하며; 그리고상기 제1 특징의 정수 값을 상기 제2 디코딩 네트워크에 입력하여 상기 디코딩된 데이터를 획득하도록구성되는, 디코딩 장치."}
{"patent_id": "10-2024-7006856", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_28", "content": "제27항에 있어서, 상기 타깃 파라미터는 상기 제2 인코딩 네트워크의 콘볼루션 및 비선형 활성화를 위한 파라미터 가중치의 전부또는 일부인, 디코딩 장치."}
{"patent_id": "10-2024-7006856", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_29", "content": "제27항 또는 제28항에 있어서, 상기 처리 회로는 구체적으로,상기 디코딩 대상 비트스트림에서의 상기 제1 특징의 정수 값에 대해 확률 추정을 수행하여 상기 제1 특징의 정수 값의 추정된 확률 분포를 획득하고; 그리고상기 제1 특징의 정수 값의 추정된 확률 분포에 기반하여 상기 디코딩 대상 비트스트림에 대해 엔트로피 디코딩을 수행하여 상기 제1 특징의 정수 값을 획득하도록 구성되는, 디코딩 장치."}
{"patent_id": "10-2024-7006856", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_30", "content": "제29항에 있어서, 상기 처리 회로는 구체적으로,제1 정보에 기반하여 상기 디코딩 대상 비트스트림에서의 상기 제1 특징의 정수 값에 대해 확률 추정을 수행하여 상기 제1 특징의 정수 값의 추정된 확률 분포를 획득하도록 구성되고, 상기 제1 정보는 콘텍스트 정보 및 부가 정보 중 적어도 하나를 포함하는, 디코딩 장치."}
{"patent_id": "10-2024-7006856", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_31", "content": "인코더로서,하나 이상의 프로세서; 및상기 프로세서에 결합되고, 상기 프로세서에 의해 실행되는 프로그램을 저장하는, 컴퓨터가 판독 가능한 비일시적 저장 매체를 포함하고, 공개특허 10-2024-0039178-8-상기 프로그램이 상기 프로세서에 의해 실행될 때, 상기 인코더는 제1항 내지 제4항 중 어느 한 항에 따른 방법을 수행하도록 이네이블되는, 인코더."}
{"patent_id": "10-2024-7006856", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_32", "content": "디코더로서,하나 이상의 프로세서; 및상기 프로세서에 결합되고, 상기 프로세서에 의해 실행되는 프로그램을 저장하는, 컴퓨터가 판독 가능한 비일시적 저장 매체를 포함하고, 상기 프로그램이 상기 프로세서에 의해 실행될 때, 상기 디코더는 제5항 내지 제11항 중 어느 한 항 또는 제12항 내지 제15항 중 어느 한 항에 따른 방법을 수행하도록 이네이블되는, 디코더."}
{"patent_id": "10-2024-7006856", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_33", "content": "컴퓨터 프로그램을 포함하는, 컴퓨터가 판독 가능한 저장 매체로서, 상기 컴퓨터 프로그램이 컴퓨터에서 실행될 때, 상기 컴퓨터는 제1항 내지 제4항, 제5항 내지 제11항, 또는 제12항 내지 제15항 중 어느 한 항에 따른 방법을 수행하도록 이네이블되는, 컴퓨터가 판독 가능한 저장 매체."}
{"patent_id": "10-2024-7006856", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_34", "content": "컴퓨터 프로그램 제품으로서, 상기 컴퓨터 프로그램 제품은 컴퓨터 프로그램 코드를 포함하고, 상기 컴퓨터 프로그램 코드가 컴퓨터에서 실행될 때, 상기 컴퓨터는 제1항 내지 제4항, 제5항 내지 제11항, 또는 제12항 내지 제15항 중 어느 한 항에 따른방법을 수행하도록 이네이블되는, 컴퓨터 프로그램 제품."}
{"patent_id": "10-2024-7006856", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 출원은 데이터 인코딩 및 디코딩 방법의 레이트 왜곡 성능을 개선하기 위한 인코딩 및 디코딩 방법 그리고 장 치를 개시하며, 인공 지능"}
{"patent_id": "10-2024-7006856", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "에 관한 것이다. 이 방법은, 먼저 인코딩 대상 데이터를 획득하는 단계, 그 런 다음, 인코딩 대상 데이터를 제1 인코딩 네트워크에 입력하여 타깃 파라미터를 획득하는 단계; 그 다음, 타깃 파라미터에 기반하여 제2 인코딩 네트워크를 구성하는 단계; 다음으로, 인코딩 대상 데이터를 제2 인코딩 네트워 크에 입력하여 제1 특징을 획득하는 단계; 및 최종적으로 제1 특징을 인코딩하여 인코딩된 비트스트림을 획득하 는 단계를 포함한다. 대 표 도 - 도8"}
{"patent_id": "10-2024-7006856", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 2, "content": "공개특허10-2024-0039178 CPC특허분류 G06N 3/0464 (2023.01) G06N 3/047 (2023.01) G06N 3/048 (2023.01) H04N 19/136 (2015.01) H04N 19/147 (2015.01) H04N 19/184 (2015.01) 발명자 왕 징 중국 518129 광동성 셴젠 롱강 디스트릭트 반티안 후아웨이 어드미니스트레이션 빌딩 궈 티안셩 중국 518129 광동성 셴젠 롱강 디스트릭트 반티안 후아웨이 어드미니스트레이션 빌딩추이 저 중국 518129 광동 셴젠 롱강 디스트릭트 반티안 후 아웨이 어드미니스트레이션 빌딩 게 유닝 중국 518129 광동성 셴젠 롱강 디스트릭트 반티안 후아웨이 어드미니스트레이션 빌딩명 세 서 청구범위 청구항 1 인코딩 방법으로서, 상기 인코딩 방법은, 인코딩 대상 데이터를 획득하는 단계; 상기 인코딩 대상 데이터를 제1 인코딩 네트워크에 입력하여 타깃 파라미터를 획득하는 단계; 상기 타깃 파라미터에 기반하여 제2 인코딩 네트워크를 구성하는 단계; 상기 인코딩 대상 데이터를 상기 제2 인코딩 네트워크에 입력하여 제1 특징을 획득하는 단계; 및 상기 제1 특징을 인코딩하여 인코딩된 비트스트림을 획득하는 단계 를 포함하는 인코딩 방법. 청구항 2 제1항에 있어서, 상기 타깃 파라미터는 상기 제2 인코딩 네트워크의 콘볼루션 및 비선형 활성화를 위한 파라미터 가중치의 전부 또는 일부인, 인코딩 방법. 청구항 3 제1항 또는 제2항에 있어서, 상기 제1 특징을 인코딩하여 인코딩된 비트스트림을 획득하는 단계는, 상기 제1 특징을 반올림하여 상기 제1 특징의 정수 값을 획득하는 단계; 상기 제1 특징의 정수 값에 대해 확률 추정을 수행하여 상기 제1 특징의 정수 값의 추정된 확률 분포를 획득하 는 단계; 및 상기 제1 특징의 정수 값의 추정된 확률 분포에 기반하여 상기 제1 특징의 정수 값에 대해 엔트로피 인코딩을 수행하여 상기 인코딩된 비트스트림을 획득하는 단계 를 포함하는, 인코딩 방법. 청구항 4 제3항에 있어서, 상기 제1 특징의 정수 값에 대해 확률 추정을 수행하여 상기 제1 특징의 정수 값의 추정된 확률 분포를 획득하 는 단계는, 제1 정보에 기반하여 상기 제1 특징의 정수 값에 대해 확률 추정을 수행하여 상기 제1 특징의 정수 값의 추정된 확률 분포를 획득하는 단계 - 상기 제1 정보는 콘텍스트 정보 및 부가 정보 중 적어도 하나를 포함함 - 를 포함하는, 인코딩 방법. 청구항 5 디코딩 방법으로서, 상기 디코딩 방법은, 디코딩 대상 비트스트림을 획득하는 단계;상기 디코딩 대상 비트스트림을 디코딩하여 제1 특징의 정수 값 및 제2 특징의 정수 값을 획득하는 단계 - 상기 제1 특징의 정수 값은 디코딩된 데이터를 획득하는 데 사용되고, 상기 제2 특징의 정수 값은 타깃 파라미터를 획득하는 데 사용됨 -; 상기 제2 특징의 정수 값을 제1 디코딩 네트워크에 입력하여 상기 타깃 파라미터를 획득하는 단계; 상기 타깃 파라미터에 기반하여 제2 디코딩 네트워크를 구성하는 단계; 및 상기 제1 특징의 정수 값을 상기 제2 디코딩 네트워크에 입력하여 상기 디코딩된 데이터를 획득하는 단계 를 포함하는 디코딩 방법. 청구항 6 제5항에 있어서, 상기 타깃 파라미터는 상기 제2 인코딩 네트워크의 콘볼루션 및 비선형 활성화를 위한 파라미터 가중치의 전부 또는 일부인, 디코딩 방법. 청구항 7 제5항 또는 제6항에 있어서, 상기 디코딩 대상 비트스트림은 제1 디코딩 대상 비트스트림과 제2 디코딩 대상 비트스트림을 포함하고, 상기 디코딩 대상 비트스트림을 디코딩하여 제1 특징의 정수 값 및 제2 특징의 정수 값을 획득하는 단계는, 상기 제1 디코딩 대상 비트스트림을 디코딩하여 상기 제1 특징의 정수 값을 획득하는 단계; 및 상기 제2 디코딩 대상 비트스트림을 디코딩하여 상기 제2 특징의 정수 값을 획득하는 단계 를 포함하는, 디코딩 방법. 청구항 8 제7항에 있어서, 상기 제1 디코딩 대상 비트스트림을 디코딩하여 상기 제1 특징의 정수 값을 획득하는 단계는, 상기 제1 디코딩 대상 비트스트림에서의 상기 제1 특징의 정수 값에 대해 확률 추정을 수행하여 상기 제1 특징 의 정수 값의 추정된 확률 분포를 획득하는 단계; 및 상기 제1 특징의 정수 값의 추정된 확률 분포에 기반하여 상기 제1 디코딩 대상 비트스트림에 대해 엔트로피 디 코딩을 수행하여 상기 제1 특징의 정수 값을 획득하는 단계 를 포함하는, 디코딩 방법. 청구항 9 제8항에 있어서, 상기 제1 디코딩 대상 비트스트림에서의 상기 제1 특징의 정수 값에 대해 확률 추정을 수행하여 상기 제1 특징 의 정수 값의 추정된 확률 분포를 획득하는 단계는, 제1 정보에 기반하여 상기 제1 디코딩 대상 비트스트림에서의 상기 제1 특징의 정수 값에 대해 확률 추정을 수 행하여 상기 제1 특징의 정수 값의 추정된 확률 분포를 획득하는 단계 - 상기 제1 정보는 콘텍스트 정보 및 부 가 정보 중 적어도 하나를 포함함 - 를 포함하는, 디코딩 방법. 청구항 10 제7항 내지 제9항 중 어느 한 항에 있어서, 상기 제2 디코딩 대상 비트스트림을 디코딩하여 상기 제2 특징의 정수 값을 획득하는 단계는,상기 제2 디코딩 대상 비트스트림에서의 상기 제2 특징의 정수 값에 대해 확률 추정을 수행하여 상기 제2 특징 의 정수 값의 추정된 확률 분포를 획득하는 단계; 및 상기 제2 특징의 정수 값의 추정된 확률 분포에 기반하여 상기 제2 디코딩 대상 비트스트림에 대해 엔트로피 디 코딩을 수행하여 상기 제2 특징의 정수 값을 획득하는 단계 를 포함하는, 디코딩 방법. 청구항 11 제10항에 있어서, 상기 제2 디코딩 대상 비트스트림에서의 상기 제2 특징의 정수 값에 대해 확률 추정을 수행하여 상기 제2 특징 의 정수 값의 추정된 확률 분포를 획득하는 단계는, 상기 제1 정보에 기반하여 상기 제2 디코딩 대상 비트스트림에서의 상기 제2 특징의 정수 값에 대해 확률 추정 을 수행하여 상기 제2 특징의 정수 값의 추정된 확률 분포를 획득하는 단계 - 상기 제1 정보는 콘텍스트 정보 및 부가 정보 중 적어도 하나를 포함함 - 를 포함하는, 디코딩 방법. 청구항 12 디코딩 방법으로서, 상기 디코딩 방법은, 디코딩 대상 비트스트림을 획득하는 단계; 상기 디코딩 대상 비트스트림을 디코딩하여 제1 특징의 정수 값을 획득하는 단계 - 상기 제1 특징의 정수 값은 디코딩된 데이터 및 타깃 파라미터를 획득하는 데 사용됨 -; 상기 제1 특징의 정수 값을 제1 디코딩 네트워크에 입력하여 상기 타깃 파라미터를 획득하는 단계; 상기 타깃 파라미터에 기반하여 제2 디코딩 네트워크를 구성하는 단계; 및 상기 제1 특징의 정수 값을 상기 제2 디코딩 네트워크에 입력하여 상기 디코딩된 데이터를 획득하는 단계 를 포함하는 디코딩 방법. 청구항 13 제12항에 있어서, 상기 타깃 파라미터는 상기 제2 인코딩 네트워크의 콘볼루션 및 비선형 활성화를 위한 파라미터 가중치의 전부 또는 일부인, 디코딩 방법. 청구항 14 제12항 또는 제13항에 있어서, 상기 디코딩 대상 비트스트림을 디코딩하여 제1 특징의 정수 값을 획득하는 단계는, 상기 디코딩 대상 비트스트림에서의 상기 제1 특징의 정수 값에 대해 확률 추정을 수행하여 상기 제1 특징의 정 수 값의 추정된 확률 분포를 획득하는 단계; 및 상기 제1 특징의 정수 값의 추정된 확률 분포에 기반하여 상기 디코딩 대상 비트스트림에 대해 엔트로피 디코딩 을 수행하여 상기 제1 특징의 정수 값을 획득하는 단계 를 포함하는, 디코딩 방법. 청구항 15 제14항에 있어서, 상기 디코딩 대상 비트스트림에서의 상기 제1 특징의 정수 값에 대해 확률 추정을 수행하여 상기 제1 특징의 정 수 값의 추정된 확률 분포를 획득하는 단계는, 제1 정보에 기반하여 상기 디코딩 대상 비트스트림에서의 상기 제1 특징의 정수 값에 대해 확률 추정을 수행하 여 상기 제1 특징의 정수 값의 추정된 확률 분포를 획득하는 단계 - 상기 제1 정보는 콘텍스트 정보 및 부가 정 보 중 적어도 하나를 포함함 - 를 포함하는, 디코딩 방법. 청구항 16 처리 회로를 포함하는 인코딩 장치로서, 상기 처리 회로는, 인코딩 대상 데이터를 획득하고; 상기 인코딩 대상 데이터를 제1 인코딩 네트워크에 입력하여 타깃 파라미터를 획득하며; 상기 타깃 파라미터에 기반하여 제2 인코딩 네트워크를 구성하고; 상기 인코딩 대상 데이터를 상기 제2 인코딩 네트워크에 입력하여 제1 특징을 획득하며; 그리고 상기 제1 특징을 인코딩하여 인코딩된 비트스트림을 획득하도록 구성되는, 인코딩 장치. 청구항 17 제16항에 있어서, 상기 타깃 파라미터는 상기 제2 인코딩 네트워크의 콘볼루션 및 비선형 활성화를 위한 파라미터 가중치의 전부 또는 일부인, 인코딩 장치. 청구항 18 제16항 또는 제17항에 있어서, 상기 처리 회로는 구체적으로, 상기 제1 특징을 반올림하여 상기 제1 특징의 정수 값을 획득하고; 상기 제1 특징의 정수 값에 대해 확률 추정을 수행하여 상기 제1 특징의 정수 값의 추정된 확률 분포를 획득하 며; 그리고 상기 제1 특징의 정수 값의 추정된 확률 분포에 기반하여 상기 제1 특징의 정수 값에 대해 엔트로피 인코딩을 수행하여 상기 인코딩된 비트스트림을 획득하도록 구성되는, 인코딩 장치. 청구항 19 제18항에 있어서, 상기 처리 회로는 구체적으로, 제1 정보에 기반하여 상기 제1 특징의 정수 값에 대해 확률 추정을 수행하여 상기 제1 특징의 정수 값의 추정된 확률 분포를 획득하도록 구성되고, 상기 제1 정보는 콘텍스트 정보 및 부가 정보 중 적어도 하나를 포함하는, 인코딩 장치. 청구항 20 처리 회로를 포함하는 디코딩 장치로서, 상기 처리 회로는, 디코딩 대상 비트스트림을 획득하고; 상기 디코딩 대상 비트스트림을 디코딩하여 제1 특징의 정수 값 및 제2 특징의 정수 값을 획득하며 - 상기 제1특징의 정수 값은 디코딩된 데이터를 획득하는 데 사용되고, 상기 제2 특징의 정수 값은 타깃 파라미터를 획득 하는 데 사용됨 -; 상기 제2 특징의 정수 값을 제1 디코딩 네트워크에 입력하여 상기 타깃 파라미터를 획득하고; 상기 타깃 파라미터에 기반하여 제2 디코딩 네트워크를 구성하며; 그리고 상기 제1 특징의 정수 값을 상기 제2 디코딩 네트워크에 입력하여 상기 디코딩된 데이터를 획득하도록 구성되는, 디코딩 장치. 청구항 21 제20항에 있어서, 상기 타깃 파라미터는 상기 제2 인코딩 네트워크의 콘볼루션 및 비선형 활성화를 위한 파라미터 가중치의 전부 또는 일부인, 디코딩 장치. 청구항 22 제20항 또는 제21항에 있어서, 상기 디코딩 대상 비트스트림은 제1 디코딩 대상 비트스트림과 제2 디코딩 대상 비트스트림을 포함하고, 상기 처리 회로는 구체적으로, 상기 제1 디코딩 대상 비트스트림을 디코딩하여 상기 제1 특징의 정수 값을 획득하고; 그리고 상기 제2 디코딩 대상 비트스트림을 디코딩하여 상기 제2 특징의 정수 값을 획득하도록 구성되는, 디코딩 장치. 청구항 23 제22항에 있어서, 상기 처리 회로는 구체적으로, 상기 제1 디코딩 대상 비트스트림에서의 상기 제1 특징의 정수 값에 대해 확률 추정을 수행하여 상기 제1 특징 의 정수 값의 추정된 확률 분포를 획득하고; 그리고 상기 제1 특징의 정수 값의 추정된 확률 분포에 기반하여 상기 제1 디코딩 대상 비트스트림에 대해 엔트로피 디 코딩을 수행하여 상기 제1 특징의 정수 값을 획득하도록 구성되는, 디코딩 장치. 청구항 24 제23항에 있어서, 상기 처리 회로는 구체적으로, 제1 정보에 기반하여 상기 제1 디코딩 대상 비트스트림에서의 상기 제1 특징의 정수 값에 대해 확률 추정을 수 행하여 상기 제1 특징의 정수 값의 추정된 확률 분포를 획득하도록 구성되며, 상기 제1 정보는 콘텍스트 정보 및 부가 정보 중 적어도 하나를 포함하는, 디코딩 장치. 청구항 25 제22항 내지 제24항 중 어느 한 항에 있어서, 상기 처리 회로는 구체적으로, 상기 제2 디코딩 대상 비트스트림에서의 상기 제2 특징의 정수 값에 대해 확률 추정을 수행하여 상기 제2 특징 의 정수 값의 추정된 확률 분포를 획득하고; 그리고 상기 제2 특징의 정수 값의 추정된 확률 분포에 기반하여 상기 제2 디코딩 대상 비트스트림에 대해 엔트로피 디 코딩을 수행하여 상기 제2 특징의 정수 값을 획득하도록 구성되는, 디코딩 장치. 청구항 26 제25항에 있어서, 상기 처리 회로는 구체적으로, 상기 제1 정보에 기반하여 상기 제2 디코딩 대상 비트스트림에서의 상기 제2 특징의 정수 값에 대해 확률 추정 을 수행하여 상기 제2 특징의 정수 값의 추정된 확률 분포를 획득하도록 구성되고, 상기 제1 정보는 콘텍스트 정보 및 부가 정보 중 적어도 하나를 포함하는, 디코딩 장치. 청구항 27 처리 회로를 포함하는 디코딩 장치로서, 상기 처리 회로는, 디코딩 대상 비트스트림을 획득하고; 상기 디코딩 대상 비트스트림을 디코딩하여 제1 특징의 정수 값을 획득하며 - 상기 제1 특징의 정수 값은 디코 딩된 데이터 및 타깃 파라미터를 획득하는 데 사용됨 -; 상기 제1 특징의 정수 값을 제1 디코딩 네트워크에 입력하여 상기 타깃 파라미터를 획득하고; 상기 타깃 파라미터에 기반하여 제2 디코딩 네트워크를 구성하며; 그리고 상기 제1 특징의 정수 값을 상기 제2 디코딩 네트워크에 입력하여 상기 디코딩된 데이터를 획득하도록 구성되는, 디코딩 장치. 청구항 28 제27항에 있어서, 상기 타깃 파라미터는 상기 제2 인코딩 네트워크의 콘볼루션 및 비선형 활성화를 위한 파라미터 가중치의 전부 또는 일부인, 디코딩 장치. 청구항 29 제27항 또는 제28항에 있어서, 상기 처리 회로는 구체적으로, 상기 디코딩 대상 비트스트림에서의 상기 제1 특징의 정수 값에 대해 확률 추정을 수행하여 상기 제1 특징의 정 수 값의 추정된 확률 분포를 획득하고; 그리고 상기 제1 특징의 정수 값의 추정된 확률 분포에 기반하여 상기 디코딩 대상 비트스트림에 대해 엔트로피 디코딩 을 수행하여 상기 제1 특징의 정수 값을 획득하도록 구성되는, 디코딩 장치. 청구항 30 제29항에 있어서, 상기 처리 회로는 구체적으로, 제1 정보에 기반하여 상기 디코딩 대상 비트스트림에서의 상기 제1 특징의 정수 값에 대해 확률 추정을 수행하 여 상기 제1 특징의 정수 값의 추정된 확률 분포를 획득하도록 구성되고, 상기 제1 정보는 콘텍스트 정보 및 부 가 정보 중 적어도 하나를 포함하는, 디코딩 장치. 청구항 31 인코더로서, 하나 이상의 프로세서; 및 상기 프로세서에 결합되고, 상기 프로세서에 의해 실행되는 프로그램을 저장하는, 컴퓨터가 판독 가능한 비일시 적 저장 매체 를 포함하고, 상기 프로그램이 상기 프로세서에 의해 실행될 때, 상기 인코더는 제1항 내지 제4항 중 어느 한 항에 따른 방법 을 수행하도록 이네이블되는, 인코더. 청구항 32 디코더로서, 하나 이상의 프로세서; 및 상기 프로세서에 결합되고, 상기 프로세서에 의해 실행되는 프로그램을 저장하는, 컴퓨터가 판독 가능한 비일시 적 저장 매체 를 포함하고, 상기 프로그램이 상기 프로세서에 의해 실행될 때, 상기 디코더는 제5항 내지 제11항 중 어느 한 항 또는 제12 항 내지 제15항 중 어느 한 항에 따른 방법을 수행하도록 이네이블되는, 디코더. 청구항 33 컴퓨터 프로그램을 포함하는, 컴퓨터가 판독 가능한 저장 매체로서, 상기 컴퓨터 프로그램이 컴퓨터에서 실행될 때, 상기 컴퓨터는 제1항 내지 제4항, 제5항 내지 제11항, 또는 제 12항 내지 제15항 중 어느 한 항에 따른 방법을 수행하도록 이네이블되는, 컴퓨터가 판독 가능한 저장 매체. 청구항 34 컴퓨터 프로그램 제품으로서, 상기 컴퓨터 프로그램 제품은 컴퓨터 프로그램 코드를 포함하고, 상기 컴퓨터 프로그램 코드가 컴퓨터에서 실행 될 때, 상기 컴퓨터는 제1항 내지 제4항, 제5항 내지 제11항, 또는 제12항 내지 제15항 중 어느 한 항에 따른 방법을 수행하도록 이네이블되는, 컴퓨터 프로그램 제품. 발명의 설명 기 술 분 야 본 출원은 2021년 8월 5일에 중국 특허청에 출원되고 명칭이 \"인코딩 및 디코딩 방법 그리고 장치\"인 중국 특허 출원 번호 제202110898667.8호에 대한 우선권을 주장하는 바이며, 이러한 문헌의 내용은 원용에 의해 전체적으 로 본 명세서에 포함된다. 본 출원은 인공 지능 분야에 관한 것으로, 특히 인코딩 및 디코딩 방법 그리고 장치에 관한 것이다."}
{"patent_id": "10-2024-7006856", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "과학 및 기술의 발달로 픽처의 수량과 해상도가 증가하고 있다. 픽처의 수량이 많으면 더 큰 용량의 저장 매체 가 필요할 뿐만 아니라 더 넓은 전송 주파수 대역과 더 긴 전송 시간이 필요하며, 이는 또한 픽처 처리의 기본 적인 문제가 된다. 픽처의 저장 효율성과 전송 효율성을 높이기 위해서는 데이터 양이 많은 픽처를 인코딩하여 픽처를 압축해야 한다. 신경망 기반의 픽처 압축은 픽처 압축 효율성을 향상시킬 수 있다. 기존의 신경망 기반 픽처 압축 방법은 주로, 온라인 트레이닝(online training)이 필요한 신경망 기반 픽처 압축 방법(간단히 방법 1이라 함)과 온라인 트레 이닝이 필요하지 않은 신경망 기반 픽처 압축 방법(간단히 방법 2라고 함)으로 분류된다. 방법 1은 레이트 왜곡 성능은 좋지만 온라인 트레이닝이 필요하므로 픽처 압축 속도가 낮다. 방법 2는 레이트 왜곡 성능은 떨어지지만, 픽처 압축 속도는 높다. 본 출원은 온라인 트레이닝 없이 데이터 인코딩 및 디코딩 방법의 레이트 왜곡 성능을 향상시키기 위한 인코딩 및 디코딩 방법 그리고 장치를 제공한다. 전술한 목표를 달성하기 위해 본 출원은 다음과 같은 기술 솔루션을 사용한다.제1 측면에 따르면, 본 출원은 인코딩 방법을 제공한다. 이 방법은 먼저 인코딩 대상 데이터(to-be-encoded data)를 획득한 다음, 인코딩 대상 데이터를 제1 인코딩 네트워크에 입력하여 타깃 파라미터를 획득하는 단계; 그 다음, 타깃 파라미터에 기반하여 제2 인코딩 네트워크를 구성하는(constructing) 단계; 다음으로, 인코딩 대 상 데이터를 제2 인코딩 네트워크에 입력하여 제1 특징(feature)을 획득하는 단계; 및 최종적으로 제1 특징을 인코딩하여 인코딩된 비트스트림을 획득하는 단계를 포함한다. 기존 인코딩 방식에서는 인코딩 네트워크(즉, 제2 인코딩 네트워크)가 고정된 파라미터 가중치에 기반하여 인코 딩 대상 데이터의 콘텐츠 특징(즉, 제1 특징)을 추출한 후, 콘텐츠 특징을 비트스트림(즉, 인코딩된 비트스트림)으로 인코딩하고 비트스트림을 디코더 측으로 송신한다(send). 디코더 측은 비트스트림에 대한 디코 딩 및 재구성을 수행하여 디코딩된 데이터를 획득한다. 종래 기술에서는 인코딩 네트워크의 파라미터 가중치가 인코딩 대상 데이터와 관련이 없음을 알 수 있다. 다만, 본 출원에서 제공하는 인코딩 방법에서는, 인코딩 대상 데이터가 먼저 제1 인코딩 네트워크에 입력되고, 제1 인코딩 네트워크는 인코딩 대상 데이터에 기반하여 제2 인 코딩 네트워크의 파라미터 가중치를 생성하며, 그런 다음 획득된 가중치에 기반하여 제2 인코딩 네트워크의 파 라미터 가중치가 동적으로 조정됨으로써, 제2 인코딩 네트워크의 파라미터 가중치가 인코딩 대상 데이터와 관련 되며, 제2 인코딩 네트워크의 표현 능력(expression capability)이 증가되고, 그리고 제1 특징을 인코딩하는 것 에 의해 획득된 비트스트림에 대한 디코딩 및 재구성을 통해 디코더 측에서 획득된 디코딩된 데이터가 인코딩 대상 데이터에 더 가까워진다. 이는 인코딩 및 디코딩 네트워크의 레이트 왜곡 성능을 향상시킨다. 선택적으로, 타깃 파라미터는 제2 인코딩 네트워크의 콘볼루션(convolution) 및 비선형 활성화(non-linear activation)를 위한 파라미터 가중치의 전부 또는 일부이다. 가능한 구현에서, 제1 특징을 인코딩하여 인코딩된 비트스트림을 획득하는 단계는, 제1 특징을 반올림하여 (rounding) 제1 특징의 정수 값을 획득하는 단계, 제1 특징의 정수 값에 대해 확률 추정(probability estimation)을 수행하여 제1 특징의 정수 값의 추정된 확률 분포(probability distribution)를 획득하는 단계 및 제1 특징의 정수 값의 추정된 확률 분포에 기반하여 제1 특징의 정수 값에 대해 엔트로피 인코딩을 수행하여 인코딩된 비트스트림을 획득하는 단계를 포함한다. 제1 특징의 정수 값에 대한 추정된 확률 분포에 기반하여 제1 특징의 정수 값에 대해 엔트로피 인코딩을 수행하 여 비트스트림을 형성한다. 이는 제1 특징을 출력하기 위한 인코딩 중복(redundancy)을 줄일 수 있고, 데이터 인코딩 또는 디코딩(압축) 프로세스에서 데이터 전송량을 더욱 줄일 수 있다. 가능한 구현에서, 제1 특징의 정수 값에 대해 확률 추정을 수행하여 제1 특징의 정수 값의 추정된 확률 분포를 획득하는 단계는, 제1 정보에 기반하여 제1 특징의 정수 값에 대해 확률 추정을 수행하여 제1 특징의 정수 값의 추정된 확률 분포를 획득하는 단계 - 제1 정보는 콘텍스트 정보 및 부가(side) 정보 중 적어도 하나를 포함함 - 를 포함한다. 콘텍스트 정보와 부가 정보에 기반하여 확률 분포를 추정함으로써, 획득된 추정된 확률 분포의 정확도를 높일 수 있다. 이는 엔트로피 인코딩 프로세스에서 비트 레이트를 줄이고 엔트로피 인코딩 오버헤드를 줄인다. 제2 측면에 따르면, 본 출원은 디코딩 방법을 제공한다. 이 방법은: 먼저 디코딩 대상 비트스트림을 획득하는 단계; 그 다음, 디코딩 대상 비트스트림을 디코딩하여 제1 특징의 정수 값 및 제2 특징의 정수 값을 획득하는 단계; 또한, 제2 특징의 정수 값을 제1 디코딩 네트워크에 입력하여 타깃 파라미터를 획득하는 단계; 다음으로, 타깃 파라미터에 기반하여 제2 디코딩 네트워크를 구성하는 단계; 및 최종적으로 제1 특징의 정수 값을 제2 디 코딩 네트워크에 입력하여 디코딩된 데이터를 획득하는 단계를 포함한다. 제1 특징의 정수 값은 디코딩된 데이 터를 획득하는 데 사용되며, 제2 특징의 정수 값은 타깃 파라미터를 획득하는 데 사용된다. 기존의 디코딩 방법에서는 디코딩 네트워크(즉, 제2 디코딩 네트워크)가 고정된 파라미터 가중치에 기반하여 인 코딩 대상 데이터의 콘텐츠 값 특징(즉, 제1 특징의 정수 값)에 대한 디코딩 및 재구성을 수행하여 디코딩된 데 이터를 획득한다. 종래 기술에서는 디코딩 네트워크의 파라미터 가중치가 디코딩 대상 데이터와 관련이 없음을 알 수 있다. 그러나 본 출원에서는 디코딩 대상 데이터의 콘텐츠 특징과 모델 특징(즉, 제1 특징과 제2 특징)이 디코딩 대상 비트스트림으로 인코딩된 다음, 디코더 측이 디코딩 대상 비트스트림을 디코딩하여 제2 특징의 정 수 값을 획득하며, 제2 특징의 정수 값이 제1 디코딩 네트워크에 입력되어 제2 디코딩 네트워크의 파라미터 가 중치를 획득하고, 그런 다음, 제2 디코딩 네트워크의 파라미터 가중치가 파라미터 가중치에 기반하여 동적으로 조정됨으로써, 제2 디코딩 네트워크의 파라미터 가중치가 디코딩 대상 데이터와 관련되고, 제2 디코딩 네트워크 의 표현 능력이 향상되며, 디코딩 및 재구성을 통해 제2 네트워크에 의해 획득된 디코딩된 데이터는 인코딩 대상 데이터에 더 가까워진다. 이는 인코딩 및 디코딩 네트워크의 레이트 왜곡 성능을 향상시킨다. 선택적으로, 타깃 파라미터는 제2 인코딩 네트워크의 콘볼루션 및 비선형 활성화를 위한 파라미터 가중치의 전 부 또는 일부이다. 선택적으로, 디코딩 대상 비트스트림은 제1 디코딩 대상 비트스트림 및 제2 디코딩 대상 비트스트림을 포함한다. 가능한 구현에서, 디코딩 대상 비트스트림을 디코딩하여 제1 특징의 정수 값 및 제2 특징의 정수 값을 획득하는 단계는, 제1 디코딩 대상 비트스트림을 디코딩하여 제1 특징의 정수 값을 획득하는 단계 및 제2 디코딩 대상 비 트스트림을 디코딩하여 제2 특징의 정수 값을 획득하는 단계를 포함한다. 가능한 구현에서, 제1 디코딩 대상 비트스트림을 디코딩하여 제1 특징의 정수 값을 획득하는 단계는, 제1 디코 딩 대상 비트스트림에서의 제1 특징의 정수 값에 대해 확률 추정을 수행하여 제1 특징의 정수 값의 추정된 확률 분포를 획득하는 단계 및 제1 특징의 정수 값의 추정된 확률 분포에 기반하여 제1 디코딩 대상 비트스트림에 대 해 엔트로피 디코딩을 수행하여 제1 특징의 정수 값을 획득하는 단계를 포함한다. 가능한 구현에서, 제1 디코딩 대상 비트스트림에서의 제1 특징의 정수 값에 대해 확률 추정을 수행하여 제1 특 징의 정수 값의 추정된 확률 분포를 획득하는 단계는: 제1 정보에 기반하여 제1 디코딩 대상 비트스트림에서의 제1 특징의 정수 값에 대해 확률 추정을 수행하여 제1 특징의 정수 값의 추정된 확률 분포를 획득하는 단계 - 제1 정보는 콘텍스트 정보 및 부가 정보 중 적어도 하나를 포함함 - 를 포함한다. 가능한 구현에서, 제2 디코딩 대상 비트스트림을 디코딩하여 제2 특징의 정수 값을 획득하는 단계는, 제2 디코 딩 대상 비트스트림에서의 제2 특징의 정수 값에 대해 확률 추정을 수행하여 제2 특징의 정수 값의 추정된 확률 분포를 획득하는 단계 및 제2 특징의 정수 값의 추정된 확률 분포에 기반하여 제2 디코딩 대상 비트스트림에 대 해 엔트로피 디코딩을 수행하여 제2 특징의 정수 값을 획득하는 단계를 포함한다. 가능한 구현에서, 제2 디코딩 대상 비트스트림에서의 제2 특징의 정수 값에 대해 확률 추정을 수행하여 제2 특 징의 정수 값의 추정된 확률 분포를 획득하는 단계는: 제1 정보에 기반하여 제2 디코딩 대상 비트스트림에서의 제2 특징의 정수 값에 대해 확률 추정을 수행하여 제2 특징의 정수 값의 추정된 확률 분포를 획득하는 단계 - 제1 정보는 콘텍스트 정보 및 부가 정보 중 적어도 하나를 포함함 - 를 포함한다. 제3 측면에 따르면, 본 출원은 디코딩 방법을 제공한다. 이 방법은: 먼저 디코딩 대상 비트스트림을 획득하는 단계; 그 다음, 디코딩 대상 비트스트림을 디코딩하여 제1 특징의 정수 값을 획득하는 단계; 또한, 제1 특징의 정수 값을 제3 디코딩 네트워크에 입력하여 타깃 파라미터를 획득하는 단계; 다음으로, 타깃 파라미터에 기반하 여 제2 디코딩 네트워크를 구성하는 단계; 및 최종적으로 제1 특징의 정수 값을 제2 디코딩 네트워크에 입력하 여 디코딩된 데이터를 획득하는 단계를 포함한다. 제1 특징은 디코딩된 데이터와 타깃 파라미터를 획득하는 데 사용된다. 기존의 디코딩 방법에서는 디코딩 네트워크(즉, 제2 디코딩 네트워크)가 고정된 파라미터 가중치에 기반하여 인 코딩 대상 데이터의 콘텐츠 값 특징(즉, 제1 특징의 정수 값)에 대한 디코딩 및 재구성을 수행하여 디코딩된 데 이터를 획득한다. 종래 기술에서는 디코딩 네트워크의 파라미터 가중치가 디코딩 대상 데이터와 관련이 없음을 알 수 있다. 그러나 본 출원에서는 디코딩 대상 데이터의 특징(즉, 제1 특징)을 인코딩하는 것에 의해 획득된 디코딩 대상 프레임이 디코딩되어 제1 특징의 정수 값을 획득하며, 제1 특징의 정수 값이 제1 디코딩 네트워크 에 입력되어 제2 디코딩 네트워크의 파라미터 가중치를 획득하고, 그런 다음, 제2 디코딩 네트워크의 파라미터 가중치가 파라미터 가중치에 기반하여 동적으로 조정됨으로써, 제2 디코딩 네트워크의 파라미터 가중치가 디코 딩 대상 데이터와 관련되고, 제2 디코딩 네트워크의 표현 능력이 향상되며, 디코딩 및 재구성을 통해 제2 네트 워크에 의해 획득된 디코딩된 데이터는 인코딩 대상 데이터에 더 가까워진다. 이는 인코딩 및 디코딩 네트워크 의 레이트 왜곡 성능을 향상시킨다. 선택적으로, 타깃 파라미터는 제2 인코딩 네트워크의 콘볼루션 및 비선형 활성화를 위한 파라미터 가중치의 전 부 또는 일부이다. 가능한 구현에서, 디코딩 대상 비트스트림을 디코딩하여 제1 특징의 정수 값을 획득하는 단계는: 디코딩 대상 비트스트림에서의 제1 특징의 정수 값에 대해 확률 추정을 수행하여 제1 특징의 정수 값의 추정된 확률 분포를 획득하는 단계 및 제1 특징의 정수 값의 추정된 확률 분포에 기반하여 디코딩 대상 비트스트림에 대해 엔트로피 디코딩을 수행하여 제1 특징의 정수 값을 획득하는 단계를 포함한다.가능한 구현에서, 디코딩 대상 비트스트림에서의 제1 특징의 정수 값에 대해 확률 추정을 수행하여 제1 특징의 정수 값의 추정된 확률 분포를 획득하는 단계는: 제1 정보에 기반하여 디코딩 대상 비트스트림에서의 제1 특징 의 정수 값에 대해 확률 추정을 수행하여 제1 특징의 정수 값의 추정된 확률 분포를 포함하는 단계 - 제1 정보 는 콘텍스트 정보 및 부가 정보 중 적어도 하나를 포함함 - 를 포함한다. 제4 측면에 따르면, 본 출원은 인코딩 장치를 제공한다. 인코딩 장치는 처리 회로를 포함한다. 처리 회로는 인 코딩 대상 데이터를 획득하고; 인코딩 대상 데이터를 제1 인코딩 네트워크에 입력하여 타깃 파라미터를 획득하 고; 타깃 파라미터에 기반하여 제2 인코딩 네트워크를 구성하며; 인코딩 대상 데이터를 제2 인코딩 네트워크에 입력하여 제1 특징을 획득하고; 제1 특징을 인코딩하여 인코딩된 비트스트림을 획득하도록 구성된다. 선택적으로, 타깃 파라미터는 제2 인코딩 네트워크의 콘볼루션 및 비선형 활성화를 위한 파라미터 가중치의 전 부 또는 일부이다. 가능한 구현에서, 처리 회로는 구체적으로, 제1 특징을 반올림하여 제1 특징의 정수 값을 획득하고, 제1 특징의 정수 값에 대해 확률 추정을 수행하여 제1 특징의 정수 값의 추정된 확률 분포를 획득하며, 제1 특징의 정수 값 의 추정된 확률 분포에 기반하여 제1 특징의 정수 값에 대해 엔트로피 인코딩을 수행하여 인코딩된 비트스트림 을 획득하도록 구성된다. 가능한 구현에서, 처리 회로는 제1 정보에 기반하여 제1 특징의 정수 값에 대해 확률 추정을 수행하여 제1 특징 의 정수 값의 추정된 확률 분포를 획득하도록 구성되고, 제1 정보는 콘텍스트 정보 및 부가 정보 중 적어도 하 나를 포함한다. 제5 측면에 따르면, 본 출원은 디코딩 장치를 제공한다. 디코딩 장치는 처리 회로를 포함한다. 처리 회로는 디 코딩 대상 비트스트림을 획득하고; 디코딩 대상 비트스트림을 디코딩하여 제1 특징의 정수 값과 제2 특징의 정 수 값을 획득하고 - 제1 특징의 정수 값은 디코딩된 데이터를 획득하는 데 사용되며, 제2 특징의 정수 값은 타 깃 파라미터를 획득하는 데 사용됨 -, 제2 특징의 정수 값을 제1 디코딩 네트워크에 입력하여 타깃 파라미터를 획득하며; 타깃 파라미터에 기반하여 제2 디코딩 네트워크를 구성하고; 그리고 제1 특징의 정수 값을 제2 디코 딩 네트워크에 입력하여 디코딩된 데이터를 획득하도록 구성된다. 선택적으로, 타깃 파라미터는 제2 인코딩 네트워크의 콘볼루션 및 비선형 활성화를 위한 파라미터 가중치의 전 부 또는 일부이다. 선택적으로, 디코딩 대상 비트스트림은 제1 디코딩 대상 비트스트림 및 제2 디코딩 대상 비트스트림을 포함한다. 가능한 구현에서, 처리 회로는 구체적으로, 제1 디코딩 대상 비트스트림을 디코딩하여 제1 특징의 정수 값을 획 득하고, 제2 디코딩 대상 비트스트림을 디코딩하여 제2 특징의 정수 값을 획득하도록 구성된다. 가능한 구현에서, 처리 회로는 구체적으로, 제1 디코딩 대상 비트스트림에서의 제1 특징의 정수 값에 대해 확률 추정을 수행하여 제1 특징의 정수 값의 추정된 확률 분포를 획득하고, 제1 특징의 정수 값의 추정된 확률 분포 에 기반하여 제1 디코딩 대상 비트스트림에 대해 엔트로피 디코딩을 수행하여 제1 특징의 정수 값을 획득하도록 구성된다. 가능한 구현에서, 처리 회로는 구체적으로, 제1 정보에 기반하여 제1 디코딩 대상 비트스트림에서의 제1 특징의 정수 값에 대해 확률 추정을 수행하여 제1 특징의 정수 값의 추정된 확률 분포를 획득하도록 구성되며, 제1 정 보는 콘텍스트 정보 및 부가 정보 중 적어도 하나를 포함한다. 가능한 구현에서, 처리 회로는 구체적으로, 제2 디코딩 대상 비트스트림에서의 제2 특징의 정수 값에 대해 확률 추정을 수행하여 제2 특징의 정수 값의 추정된 확률 분포를 획득하고, 제2 특징의 정수 값의 추정된 확률 분포 에 기반하여 제2 디코딩 대상 비트스트림에 엔트로피 디코딩을 수행하여 제2 특징의 정수 값을 획득하도록 구성 된다. 가능한 구현에서, 처리 회로는 구체적으로, 제1 정보에 기반하여 제2 디코딩 대상 비트스트림에서의 제2 특징의 정수 값에 대해 확률 추정을 수행하여 제2 특징의 정수 값의 추정된 확률 분포를 획득하도록 구성되며, 제1 정 보는 콘텍스트 정보 및 부가 정보 중 적어도 하나를 포함한다. 제6 측면에 따르면, 본 출원은 디코딩 장치를 제공한다. 디코딩 장치는 처리 회로를 포함한다. 처리 회로는 디 코딩 대상 비트스트림을 획득하고; 디코딩 대상 비트스트림을 디코딩하여 제1 특징의 정수 값을 획득하며 - 제1특징의 정수 값은 디코딩된 데이터 및 타깃 파라미터를 획득하는 데 사용됨 -; 제1 특징의 정수 값을 제1 디코 딩 네트워크에 입력하여 타깃 파라미터를 획득하고; 타깃 파라미터에 기반하여 제2 디코딩 네트워크를 구성하고; 그리고 제1 특징의 정수 값을 제2 디코딩 네트워크에 입력하여 디코딩된 데이터를 획득하도록 구성된 다. 선택적으로, 타깃 파라미터는 제2 인코딩 네트워크의 콘볼루션 및 비선형 활성화를 위한 파라미터 가중치의 전 부 또는 일부이다. 가능한 구현에서, 처리 회로는 구체적으로, 디코딩 대상 비트스트림에서의 제1 특징의 정수 값에 대해 확률 추 정을 수행하여 제1 특징의 정수 값의 추정된 확률 분포를 획득하고, 제1 특징의 정수 값의 추정된 확률 분포에 기반하여 디코딩 대상 비트스트림에 대해 엔트로피 디코딩을 수행하여 제1 특징의 정수 값을 획득하도록 구성된 다. 가능한 구현에서, 처리 회로는 구체적으로, 제1 정보에 기반하여 디코딩 대상 비트스트림에서의 제1 특징의 정 수 값에 대해 확률 추정을 수행하여 제1 특징의 정수 값의 추정된 확률 분포를 획득하도록 구성되고, 제1 정보 는 콘텍스트 정보 및 부가 정보 중 적어도 하나를 포함한다. 제7 측면에 따르면, 본 출원의 실시예는 인코더를 더 제공한다. 인코더는 적어도 하나의 프로세서를 포함하고, 적어도 하나의 프로세서가 프로그램 코드 또는 명령어를 실행할 때, 제1 측면 또는 제1 측면의 가능한 구현 중 어느 하나의 방법이 구현된다. 선택적으로, 인코더는 적어도 하나의 메모리를 더 포함할 수 있고, 적어도 하나의 메모리는 프로그램 코드 또는 명령어를 저장하도록 구성된다. 제8 측면에 따르면, 본 출원의 실시예는 디코더를 더 제공한다. 디코더는 적어도 하나의 프로세서를 포함하고, 적어도 하나의 프로세서가 프로그램 코드 또는 명령어를 실행할 때, 제2 측면 또는 제2 측면의 가능한 구현 중 어느 하나의 방법이 구현된다. 선택적으로, 디코더는 적어도 하나의 메모리를 더 포함할 수 있고, 적어도 하나의 메모리는 프로그램 코드 또는 명령어를 저장하도록 구성된다. 제9 측면에 따르면, 본 출원의 실시예는 입력 인터페이스, 출력 인터페이스 및 적어도 하나의 프로세서를 포함 하는 칩을 추가로 제공한다. 선택적으로, 칩은 메모리를 더 포함한다. 적어도 하나의 프로세서는 메모리의 코드 를 실행하도록 구성된다. 적어도 하나의 프로세서가 코드를 실행할 때, 칩은 제1 측면 또는 제1 측면의 가능한 구현 중 어느 하나의 방법을 구현한다. 선택적으로, 칩은 집적 회로일 수 있다. 제10 측면에 따르면, 본 출원의 실시예는 단말을 더 제공한다. 단말은 전술한 인코딩 장치, 디코딩 장치, 인코 더, 디코더 또는 칩을 포함한다. 제11 측면에 따르면, 본 출원은 컴퓨터 프로그램을 저장하도록 구성된 컴퓨터가 판독 가능한 저장 매체를 추가 로 제공한다. 컴퓨터 프로그램은 제1 측면 또는 제1 측면의 가능한 구현 중 어느 하나의 방법을 구현하도록 구 성된다. 제12 측면에 따르면, 본 출원의 실시예는 명령어를 포함하는 컴퓨터 프로그램 제품을 추가로 제공한다. 컴퓨터 프로그램 제품이 컴퓨터에서 실행될 때, 컴퓨터는 제1 측면 또는 제1 측면의 가능한 구현 중 어느 하나의 방법 을 구현한다. 실시예에 제공된 인코딩 장치, 디코딩 장치, 인코더, 디코더, 컴퓨터 저장 매체, 컴퓨터 프로그램 제품 및 칩은 모두 위에 제공된 방법을 수행하도록 구성된다. 따라서 획득할 수 있는 유익한 효과에 대해서는 위에 제공된 방 법의 유익한 효과를 참조한다. 자세한 내용은 여기서 다시 설명하지 않는다."}
{"patent_id": "10-2024-7006856", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "다음은 본 출원의 실시예의 첨부 도면을 참조하여 본 출원의 실시예의 기술적 솔루션을 명확하고 완전하게 설명 한다. 설명된 실시예는 본 출원의 실시예의 전부가 아닌 일부일 뿐임이 분명하다. 당업자가 창의적인 노력 없이 본 출원의 실시예에 기반하여 획득한 다른 모든 실시예는 본 출원의 보호 범위에 속한다. 본 명세서에서 \"및/또는\"이라는 용어는 연관된 객체를 설명하기 위한 연관 관계만을 기술하며, 세 가지 관계가 존재할 수 있음을 나타낸다. 예를 들어, A 및/또는 B는 A만 존재하는 경우, A와 B가 모두 존재하는 경우, B만 존재하는 경우인 세 가지 경우를 나타낼 수 있다. 본 출원의 명세서 및 첨부 도면에서 \"제1\", \"제2\" 등의 용어는 서로 다른 객체를 구별하거나 동일한 객체에 대 한 서로 다른 처리를 구별하기 위한 것이며, 객체의 특정 순서를 지시하는 것은 아니다. 또한, 본 출원의 설명에서 \"포함하는\", \"갖는\"이라는 용어 또는 그 밖의 다른 변형은 비배타적 포함을 포함하도 록 의도된다. 예를 들어, 일련의 단계 또는 유닛을 포함하는 프로세스, 방법, 시스템, 제품 또는 디바이스는 나 열된 단계 또는 유닛에 제한되지 않으며, 선택적으로 리스트에 없는 다른 단계 또는 유닛을 더 포함하거나, 선 택적으로 프로세스, 방법, 제품 또는 디바이스의 또 다른 고유 단계 또는 유닛을 더 포함한다. 본 출원의 실시예의 설명에서, \"예\" 또는 \"예를 들어\"라는 단어는 예, 예시 또는 설명을 제공하는 것을 나타내 는 데 사용된다는 점에 유의해야 한다. 본 출원의 실시예에서 \"예\" 또는 \"예를 들어\"로 설명된 임의의 실시예 또는 설계 방식은 다른 실시예 또는 설계 방식보다 더 바람직하거나 더 많은 이점을 갖는 것으로 설명되어서는 안 된다. 정확히 말하면, \"예\", \"예를 들어\" 등의 용어를 사용하는 것은 상대적인 개념을 특정 방식으로 제시하려는 의도이다. 본 출원의 설명에 있어서, 달리 명시하지 않는 한, \"복수\"는 2개 또는 2개 이상을 의미한다. 본 출원의 실시예는 AI 기반 데이터 압축/압축 해제(decompression) 기술을 제공하며, 특히 신경망 기반 데이터 압축/압축 해제 기술을 제공하고, 구체적으로는 기존 하이브리드 데이터 인코딩 및 디코딩 시스템을 개선하기 위해 인코딩 및 디코딩 기술을 제공한다. 데이터 인코딩 및 디코딩에는 데이터 인코딩 및 데이터 디코딩이 포함된다. 데이터 인코딩은 소스(source) 측 (또는 일반적으로 인코더 측이라고 함)에서 수행되며, 일반적으로(보다 효율적인 저장 및/또는 전송을 위해) 원 시 데이터를 표현하는 데 필요한 데이터 양을 줄이기 위해 원시 데이터를 처리하는 것(예를 들어 압축)을 포함 한다. 데이터 디코딩은 목적지(destination) 측(또는 일반적으로 디코더 측이라고 함)에서 수행되며, 일반적으 로 원시 데이터를 재구성하기 위해 인코더 측에 대한 역 처리(inverse processing)를 포함한다. 본 출원의 실시 예에서 데이터의 \"인코딩 및 디코딩\"은 데이터의 \"인코딩\" 또는 \"디코딩\"으로 이해되어야 한다. 인코딩 부분과 디코딩 부분의 조합을 CODEC(encoding and decoding, CODEC)이라고도 한다. 무손실 데이터 코딩의 경우, 원시 데이터를 재구성할 수 있다. 달리 말하면, 재구성된 원시 데이터는 원시 데이 터와 동일한 품질을 갖는다(저장 또는 전송 중에 전송 손실이나 기타 데이터 손실이 발생하지 않는다고 가정). 손실 데이터 코딩의 경우, 디코더 측에서 완전히 재구성할 수 없는 원시 데이터를 표현하는 데 필요한 데이터의 양을 줄이기 위해 예를 들어 양자화를 통해 추가 압축을 수행한다. 달리 말하면, 재구성된 원시 데이터의 품질 은 원시 데이터의 품질보다 낮거나 나쁘다. 본 출원의 실시예는 비디오 데이터, 픽처 데이터, 오디오 데이터, 정수 데이터 및 기타 압축/압축 해제 요건이 있는 기타 데이터에 적용될 수 있다. 다음은 비디오 데이터의 코딩(간단히 비디오 코딩이라고 함)을 예로 사용 하여 본 출원의 실시예를 설명한다. 다른 유형의 데이터(예를 들어, 픽처 데이터, 오디오 데이터, 정수 데이터 및 압축/압축 해제 요건이 있는 기타 데이터)에 대해서는 다음 설명을 참조한다. 본 출원의 실시예에서는 세부 사항이 설명되지 않는다. 또한, 비디오 코딩과 비교하여, 오디오 데이터, 정수 데이터 등의 데이터를 코딩하는 프로세스에서, 데이터를 블록으로 나눌 필요는 없고 데이터를 직접 코딩할 수도 있다는 점에 유의해야 한다. 비디오 코딩은 일반적으로 비디오 또는 비디오 시퀀스를 형성하는 픽처의 시퀀스를 처리하는 것을 지시한다 (indicate). 비디오 코딩 분야에서는 \"픽처(picture)\", \"프레임(frame)\", \"이미지(image)\"라는 용어가 동의어 로 사용될 수 있다. \"손실 하이브리드 비디오 코딩\"에는 여러 가지 비디오 코딩 표준이 사용된다(즉, 변환 도메인에서 양자화를 적 용하기 위해 픽셀 도메인의 공간적 및 시간적 예측이 2D 변환 코딩과 조합됨). 비디오 시퀀스의 각 픽처는 일반 적으로 중첩되지 않는(non-overlapping) 블록의 세트로 파티셔닝(partition)되며, 코딩은 일반적으로 블록 레벨 에서 수행된다. 달리 말하면, 인코더에서는 일반적으로 비디오를 블록(비디오 블록) 레벨로 처리 즉, 인코딩한 다. 예를 들어, 공간적(인트라 픽처) 예측과 시간적(인터 픽처) 예측을 통해 예측 블록을 생성하고, 현재 블록 (처리 중이거나 처리 예정인 블록)에서 예측 블록을 빼서 잔차(residual) 블록을 획득하며, 잔차 블록은 변환 도메인에서 변환되고 양자화되어 전송(압축)될 데이터의 양을 줄인다. 디코더 측에서는 인코더와 비교하여 역 처리 부분이 인코딩된 블록이나 압축된 블록에 적용되어 현재 블록을 재구성하여 표현한다. 또한, 인코더는 디 코더 처리 단계를 복제함으로써, 인코더와 디코더가 처리, 즉 후속 블록 코딩을 위해 동일한 예측(예를 들어, 인트라 예측 및 인터 예측) 및/또는 픽셀 재구성을 생성한다. 코딩 시스템의 다음 실시예에서, 인코더 및 디코더는 도 1a 내지 도 3에 기반하여 설명된다. 도 1a는 본 출원의 실시예에 따른 코딩 시스템, 예를 들어 본 출원의 기술을 활용할 수 있는 비디오 코딩 시스템(또는 줄여서 코딩 시스템)의 예시적인 블록도이다. 비디오 코딩 시스템의 비디오 인코더 (또는 줄여서 인코더) 및 비디오 디코더(또는 줄여서 디코더)는 본 출원에 설명된 다양한 예에 따른 기술을 수행하도록 구성될 수 있는 디바이스를 나타낸다. 도 1a에 도시된 바와 같이, 코딩 시스템은 인코딩된 픽처 데이터를 디코딩하기 위해, 인코딩된 픽처와 같은 인코딩된 픽처 데이터를 목적지 디바이스에 제공하도록 구성된 소스 디바이스를 포함한다. 소스 디바이스는 인코더를 포함하고, 추가적으로, 즉 선택적으로 픽처 소스, 전처리기 (preprocessor)(또는 전처리 유닛), 예를 들어 픽처 전처리기, 및 통신 인터페이스(또는 통신 유닛를 포함할 수 있다.픽처 소스는 임의의 유형의 픽처 캡처 디바이스, 예를 들어 현실 세계의 픽처를 캡처하기 위한 카메라 및/ 또는 임의의 유형의 픽처 생성 디바이스, 예를 들어 컴퓨터 애니메이션 픽처를 생성하기 위한 컴퓨터 그래픽 프 로세서, 또는 현실 세계의 픽처, 컴퓨터로 생성된 픽처(예를 들어, 화면 콘텐츠, 가상 현실(virtual reality, VR) 픽처) 및/또는 이들의 임의의 조합(예를 들어, 증강 현실(augmented reality, AR) 픽처)를 획득하거나 및/ 또는 제공하는 임의 유형의 다른 디바이스이거나 이를 포함할 수 있다. 픽처 소스는 앞서 언급한 픽처 중 임의 의 픽처를 저장하는 임의의 유형의 메모리 또는 스토리지(storage)일 수 있다. 전처리기(또는 전처리 유닛)에 의해 수행되는 처리를 구별하기 위해, 픽처(또는 픽처 데이터)는 원시 픽처(또는 원시 픽처 데이터)로 지칭될 수도 있다. 전처리기는 원시 픽처 데이터를 수신하고 원시 픽처 데이터를 전처리하여 전처리된 픽처(또는 전처 리된 픽처 데이터)를 획득하도록 구성된다. 전처리기에 의해 수행되는 전처리에는 트리밍(trimming), 색상 포맷 변환(예를 들어, RGB에서 YCbCr로), 색상 보정, 노이즈 제거(de-noising) 등이 포함될 수 있다. 전처 리 유닛은 선택적인 컴포넌트일 수 있다는 것이 이해될 수 있다. 비디오 인코더(또는 인코더)는 전처리된 픽처 데이터를 수신하고 인코딩된 픽처 데이터를 제공하도 록 구성된다(자세한 세부 사항은 예를 들어 도 2에 기반하여 아래에 설명됨). 소스 디바이스의 통신 인터페이스는 인코딩된 픽처 데이터를 수신하고, 인코딩된 픽처 데이터 (또는 그 임의의 추가 처리된 버전)를 저장 또는 직접 재구성을 위해, 통신 채널을 통해 다른 디바이스, 예 를 들어 목적지 디바이스, 또는 임의의 기타 디바이스로 전송하도록 구성될 수 있다. 목적지 디바이스는 디코더를 포함하고, 추가적으로, 즉 선택적으로 통신 인터페이스(또는 통신 유 닛), 후처리기(post-processor)(또는 후처리 유닛) 및 디스플레이 디바이스를 포함할 수 있다. 목적지 디바이스의 통신 인터페이스는 소스 디바이스 또는 저장 디바이스와 같은 임의의 다른 소스 디바이스로부터 인코딩된 픽처 데이터(또는 그 임의의 추가 처리된 버전)를 직접 수신하고, 인코딩된 픽처 데이터를 디코더로 제공하도록 구성된다. 예를 들어, 저장 디바이스는 인코딩된 픽처 데이터 저장 디바 이스이다. 통신 인터페이스와 통신 인터페이스는 소스 디바이스와 목적지 디바이스 사이의 직접 통신 링 크, 예를 들어 직접 유선 또는 무선 연결을 통해, 또는 임의의 유형의 네트워크, 예를 들어, 유선 또는 무선 네 트워크 또는 이들의 조합, 또는 임의의 유형의 개인 및 공용 네트워크, 또는 이들의 임의의 유형의 조합을 통해, 인코딩된 픽처 데이터(또는 인코딩된 데이터)를 전송 또는 수신하도록 구성될 수 있다. 통신 인터페이스는 예를 들어 인코딩된 픽처 데이터를 적절한 포맷, 예를 들어 패킷으로 패키징하거나, 및/또는 통신 링크 또는 통신망을 통한 전송을 위해 임의의 유형의 전송 인코딩 또는 처리를 사용하여, 인코딩 된 픽처 데이터를 처리하도록 구성될 수 있다. 통신 인터페이스에 대응하는 통신 인터페이스는 예를 들어 전송된 데이터를 수신하고, 임의의 유형의 대응하는 전송 디코딩 또는 처리 및/또는 디패키징(de-packaging)을 사용하여 전송 데이터를 처리하여 인코딩된 픽처 데이터를 획득하도록 구성될 수 있다. 통신 인터페이스와 통신 인터페이스 모두는 소스 디바이스로부터 목적지 디바이스를 가리키는 도 1a의 통신 채널에 대한 화살표로 지시된 바와 같이 단방향 통신 인터페이스 또는 양방향 통신 인터페이 스로서 구성될 수 있으며, 예를 들어 메시지를 송신하고 수신하여, 예를 들어 연결을 설정하고, 통신 링크 및/ 또는 데이터 전송, 예를 들어 인코딩된 픽처 데이터 전송과 관련된 임의의 다른 정보를 확인하고(acknowledge) 교환하도록 구성될 수 있다. 비디오 디코더(또는 디코더)는 인코딩된 픽처 데이터를 수신하고 디코딩된 픽처 데이터(또는 디코딩된 픽처 데이터)를 제공하도록 구성된다(추가 세부 사항은 예를 들어 도 3에 기반하여 아래에 설명됨). 후처리기는 디코딩된 픽처 데이터(재구성된 픽처 데이터라고도 함), 예를 들어 디코딩된 픽처를 후처리 하여 후처리된 픽처 데이터, 예를 들어 후처리된 픽처를 획득하도록 구성된다. 후처리 유닛에 의해 수 행되는 후처리는 예를 들어 색상 포맷 변환(예를 들어, YCbCr에서 RGB로), 색상 보정, 트리밍 또는 재샘플링, 또는 예를 들어 디스플레이 디바이스에 의한 디스플레이를 위해 디코딩된 픽처 데이터를 준비하는 것과 같은 임의의 다른 처리를 포함할 수 있다.디스플레이 디바이스는 예를 들어 사용자 또는 뷰어(viewer)에게 픽처를 디스플레이하기 위해 후처리된 픽 처 데이터를 수신하도록 구성된다. 디스플레이 디바이스는 재구성된 픽처를 나타내기 위한 임의의 유형 의 디스플레이, 예를 들어 통합형 또는 외부 디스플레이 또는 모니터일 수 있거나 이를 포함할 수 있다. 예를 들어, 디스플레이는 액정 디스플레이(liquid crystal display, LCD), 유기 발광 다이오드(organic light emitting diode, OLED) 디스플레이, 플라즈마 디스플레이, 프로젝터, 마이크로 LED 디스플레이, 실리콘 액정 (liquid crystal on silicon, LCoS), 디지털 조명 프로세서(digital light processor, DLP) 또는 임의의 유형 의 기타 디스플레이를 포함할 수 있다. 코딩 시스템은 트레이닝 엔진을 더 포함한다. 트레이닝 엔진은 인코더(특히 인코더의 엔트 로피 인코딩 유닛) 또는 디코더(특히 디코더의 엔트로피 디코딩 유닛)을 트레이닝하여, 추정 을 통해 획득된 추정된 확률 분포에 기반하여 인코딩 대상 픽처 블록에 대해 엔트로피 인코딩을 수행하도록 구 성된다. 트레이닝 엔진에 대한 자세한 설명은 다음의 방법 실시예를 참조한다. 비록 도 1a는 소스 디바이스와 목적지 디바이스를 별도의 디바이스로 도시하지만, 디바이스 실시예는 다르게는 소스 디바이스와 목적지 디바이스 모두를 포함하거나, 소스 디바이스와 목적지 디바이스 모두의 기능, 즉 소스 디바이스 또는 대응하는 기능과 목적지 디바이스 또는 대응하는 기능을 포 함할 수도 있다. 이들 실시예에서, 소스 디바이스 또는 대응하는 기능과 목적지 디바이스 또는 대응하 는 기능은 동일한 하드웨어 및/또는 소프트웨어에 의해 또는 별도의 하드웨어 및/또는 소프트웨어 또는 이들의 임의의 조합에 의해 구현될 수 있다. 설명에 기반하여 당업자에게 명백한 바와 같이, 도 1a에 도시된 소스 디바이스 및/또는 목적지 디바이스 의 존재 및 서로 다른 유닛 또는 기능으로의(정확한) 분할은 실제 디바이스 및 애플리케이션에 따라 다를 수 있다. 도 1b는 본 출원의 실시예에 따른 비디오 코딩 시스템의 예시적인 블록도이다. 인코더(예를 들어, 비디 오 인코더) 또는 디코더(예를 들어, 비디오 디코더) 또는 인코더와 디코더 모두는 도 1a에 도시된 비디오 코딩 시스템의 처리 회로, 예를 들어 하나 이상의 마이크로프로세서, 디지털 신호 프로세서 (digital signal processor, DSP), 주문형 집적 회로(application-specific integrated circuit, ASIC), 필드 프로그래밍 가능한 게이트 어레이(field-programmable gate array, FPGA), 이산 로직, 하드웨어, 비디오 코딩 전용 프로세서 또는 이들의 조합에 의해 구현될 수 있다. 도 2 및 도 3을 참조한다. 도 2는 본 출원의 실시예에 따른 비디오 인코더의 예시적인 블록도이고, 도 3은 본 출원의 실시예에 따른 비디오 디코더의 예시적인 블록도 이다. 인코더는 본 명세서에 설명된 임의의 다른 인코더 시스템 또는 서브 시스템 및/또는 도 2의 인코더 를 참조하여 설명된 다양한 모듈을 실시하기 위해 처리 회로에 의해 구현될 수 있다. 디코더는 본 명세서에 기술된 임의의 다른 디코더 시스템 또는 서브 시스템 및/또는 도 3의 디코더를 참조하여 설명된 다양한 모듈을 실시하기 위해 처리 회로에 의해 구현될 수 있다. 처리 회로는 아래에 설명된 다양한 작 동을 수행하도록 구성될 수 있다. 도 5에 도시된 바와 같이, 기술이 부분적으로 소프트웨어로 구현되면, 디바이 스는 소프트웨어에 대한 명령어를 적합한 컴퓨터가 판독 가능한 비일시적 저장 매체에 저장할 수 있고, 하나 이 상의 프로세서를 사용하여 하드웨어에서 명령어를 실행하여 본 출원의 기술을 수행할 수 있다. 비디오 인코더 및 비디오 디코더 중 어느 하나는 예를 들어 도 1b에 도시된 바와 같이 단일 디바이스에서 조합된 인 코더/디코더(encoder/decoder, CODEC)의 일부로서 통합될 수 있다. 소스 디바이스 및 목적지 디바이스는 임의의 유형의 핸드헬드 또는 고정식 디바이스, 예를 들어 노트북 또는 랩톱 컴퓨터, 모바일폰, 스마트폰, 태블릿 또는 태블릿 컴퓨터, 카메라, 데스크톱 컴퓨터, 셋톱 박스, 텔 레비전, 디스플레이 디바이스, 디지털 미디어 플레이어, 비디오 게임 콘솔, 비디오 스트리밍 디바이스(예컨대, 콘텐츠 서비스 서버 또는 콘텐츠 전달 서버), 방송 수신기 디바이스, 방송 송신기 디바이스, 모니터 디바이스 등을 포함하는 임의의 광범위한 디바이스를 포함할 수 있으며, 운영 체제를 사용하지 않거나 임의의 유형의 운 영 체제를 사용할 수 있다. 소스 디바이스 및 목적지 디바이스는 또한 클라우드 컴퓨팅 시나리오의 디 바이스, 예를 들어 클라우드 컴퓨팅 시나리오의 가상 머신일 수 있다. 일부 경우에, 소스 디바이스 및 목적 지 디바이스는 무선 통신을 위한 컴포넌트를 구비할 수 있다. 따라서, 소스 디바이스 및 목적지 디바이 스는 무선 통신 디바이스일 수 있다. 가상 현실(virtual reality, VR) 애플리케이션, 증강 현실(augmented reality, AR) 애플리케이션, 혼합 현실 (mixed reality, MR) 애플리케이션과 같은 가상 시나리오 애플리케이션(application, APP)이 소스 디바이스 와 목적지 디바이스에 각각 설치될 수 있으며, VR 애플리케이션, AR 애플리케이션, 또는 MR 애플리케이션은 사용자 조작(예를 들어, 태핑(tapping), 터칭(touching), 슬라이딩, 지터링(jittering), 음성 컨트롤)에 기반하여 실행될 수 있다. 소스 디바이스와 목적지 디바이스는 각각 카메라 및/또는 센서를 사용하여 환경 내의 임의의 객체의 픽처/비디오를 캡처하고, 캡처된 픽처/비디오에 기반하여 디스플레이 디바이스에 가상 객체를 디스플레이할 수 있다. 가상 객체는 VR 시나리오, AR 시나리오, 또는 MR 시나리오에서의 가상 객체(즉, 가상 환경 내의 객체)일 수 있다. 본 출원의 실시예에서, 소스 디바이스와 목적지 디바이스의 가상 시나리오 애플리케이션은 소스 디바이 스와 목적지 디바이스의 내장 애플리케이션일 수 있거나, 제3자 서비스 제공업체가 제공한 애플리케이 션이면서 또한 사용자가 설치한 애플리케이션일 수 있다는 점에 유의해야 한다. 이는 여기에서 특별히 제한되지 않는다. 또한, 소스 디바이스와 목적지 디바이스 각각에는 실시간 비디오 전송 애플리케이션, 예를 들어 라이브 방송 애플리케이션이 설치될 수 있다. 소스 디바이스와 목적지 디바이스는 각각 카메라를 사용하여 픽 처/비디오를 캡처하고, 캡처된 픽처/비디오를 디스플레이 디바이스에 디스플레이할 수 있다. 일부 경우에, 도 1a에 도시된 비디오 코딩 시스템은 단지 예일 뿐이며, 본 출원의 기술은 인코딩 디바이스 와 디코딩 디바이스 사이의 어떠한 데이터 통신도 반드시 포함하지 않는 비디오 코딩 설정(예를 들어, 비디오 인코딩 또는 비디오 디코딩)에 적용 가능하다. 다른 예에서, 데이터는 로컬 메모리로부터 검색되거나 네트워크 등을 통해 스트리밍된다. 비디오 인코딩 디바이스는 데이터를 인코딩하고 인코딩된 데이터를 메모리에 저장할 수 있거나 및/또는 비디오 디코딩 디바이스는 메모리로부터 데이터를 검색하고 데이터를 디코딩할 수 있다. 일 부 예에서, 인코딩 및 디코딩은, 서로 통신하지 않지만 단순히 데이터를 메모리로 인코딩하거나 및/또는 메모리 로부터 데이터를 검색하고 데이터를 디코딩하는 디바이스에 의해 수행된다. 도 1b는 본 출원의 실시예에 따른 비디오 코딩 시스템의 예시적인 블록도이다. 도 1b에 도시된 바와 같이, 비디오 코딩 시스템은 이미징 디바이스, 비디오 인코더 및 비디오 디코더(및/또는 처리 회로 에 의해 구현되는 비디오 인코더/디코더), 안테나, 하나 이상의 프로세서, 하나 이상의 메모리 , 및/또는 디스플레이 디바이스를 포함할 수 있다. 도 1b에 도시된 바와 같이, 이미징 디바이스, 안테나, 처리 회로, 비디오 인코더, 비디오 디코 더, 프로세서, 메모리 및/또는 디스플레이 디바이스는 서로 통신할 수 있다. 비디오 코딩 시스 템은 서로 다른 예에서 비디오 인코더만을 포함하거나 비디오 디코더만을 포함할 수도 있다. 일부 예에서, 안테나는 비디오 데이터의 인코딩된 비트스트림을 송신 또는 수신하도록 구성될 수 있다. 또 한, 일부 예에서, 디스플레이 디바이스는 비디오 데이터를 제시(present)하도록 구성될 수 있다. 처리 회로 는 주문형 집적 회로(application-specific integrated circuit, ASIC) 로직, 그래픽 처리 유닛, 범용 프 로세서 등을 포함할 수 있다. 비디오 코딩 시스템은 또한 선택적 프로세서를 포함할 수 있다. 선택적 프로세서는 유사하게 주문형 집적 회로(application-specific integrated circuit, ASIC) 로직, 그래픽 처 리 유닛, 범용 프로세서 등을 포함할 수 있다. 또한, 메모리는 임의의 유형의 메모리일 수 있으며, 예를 들 어 휘발성 메모리(예를 들어, 정적 랜덤 액세스 메모리(static random-access memory, SRAM) 또는 동적 랜덤 액세스 메모리(dynamic random-access memory, DRAM)) 또는 비휘발성 메모리(예를 들어, 플래시 메모리)일 수 있다. 비제한적인 예에서, 메모리는 캐시 메모리로 구현될 수 있다. 다른 예에서, 처리 회로는 픽처 버 퍼를 구현하기 위한 메모리(예를 들어, 캐시)를 포함할 수 있다. 일부 예에서, 로직 회로에 의해 구현되는 비디오 인코더는 픽처 버퍼(예를 들어, 처리 회로 또는 메모 리에 의해 구현됨) 및 그래픽 처리 유닛(예를 들어, 처리 회로에 의해 구현됨)를 포함할 수 있다. 그래 픽 처리 유닛은 픽처 버퍼에 통신 가능하게 결합될 수 있다. 그래픽 처리 유닛은 본 명세서에 설명된 임의의 다 른 인코더 시스템 또는 서브 시스템 또는 도 2를 참조하여 설명한 다양한 모듈을 구현하기 위해, 처리 회로(4 6)에 의해 구현되는 비디오 인코더에 포함될 수 있다. 로직 회로는 본 명세서에서 설명되는 다양한 작동을 수행하도록 구성될 수 있다. 일부 예에서, 비디오 디코더는 유사한 방식으로 처리 회로에 의해 구현되어, 본 명세서에 기술된 임의 의 다른 디코더 시스템 또는 서브 시스템 및/또는 도 3의 비디오 디코더를 참조하여 설명된 다양한 모듈을 구현할 수 있다. 일부 예에서, 로직 회로에 의해 구현되는 비디오 디코더는 픽처 버퍼(처리 회로 또는 메모리에 의해 구현됨) 및 그래픽 처리 유닛(예를 들어, 처리 회로에 의해 구현됨)을 포함할 수 있다. 그래픽 처리 유닛은 픽처 버퍼에 통신 가능하게 결합될 수 있다. 그래픽 처리 유닛은 본 명세서에 기술된 임의의 다른 디코더 시스템 또는 서브 시스템 및/또는 도 3을 참조하여 설명한 다양한 모듈을 구현하기 위해, 처리 회로에 의해 구현되는 비디오 디코더에 포함될 수 있다. 일부 예에서, 안테나는 비디오 데이터의 인코딩된 비트스트림을 수신하도록 구성될 수 있다. 설명한 바와 같이, 인코딩된 비트스트림은 본 명세서에서 설명하는 비디오 프레임 인코딩과 관련된 데이터, 지시자 (indicator), 인덱스 값, 모드 선택 데이터 등을 포함할 수 있으며, 예를 들어, 인코딩 파티셔닝과 관련된 데이 터(예를 들어, 변환 계수 또는 양자화된 변환 계수, 선택적인 지시자(설명된 바와 같음), 및/또는 인코딩 파티 셔닝을 정의하는 데이터)를 포함할 수 있다. 비디오 코딩 시스템은, 안테나에 결합되면서 또한 인코딩 된 비트스트림을 디코딩하도록 구성된 비디오 디코더를 더 포함할 수 있다. 디스플레이 디바이스는 비 디오 프레임을 제시하도록 구성된다. 본 출원의 이 실시예에서, 비디오 인코더를 참조하여 설명된 예에 대해, 비디오 디코더는 역 프로세스 를 수행하도록 구성될 수 있다는 것이 이해되어야 한다. 시그널링 신택스 엘리먼트와 관련하여, 비디오 디코더 는 그러한 신택스 엘리먼트를 수신 및 파싱하고 그에 따라 관련된 비디오 데이터를 디코딩하도록 구성될 수 있다. 일부 예에서, 비디오 인코더는 신택스 엘리먼트를 인코딩된 비디오 비트스트림으로 엔트로피 인코딩 할 수도 있다. 그러한 예에서, 비디오 디코더는 그러한 신택스 엘리먼트를 파싱하고 그에 따라 관련된 비디 오 데이터를 디코딩할 수 있다. 설명의 편의를 위해, 본 출원의 실시예는 ITU-T 비디오 코딩 전문가 그룹(video coding experts group, VCEG) 과 ISO/IEC 모션 픽처 전문가 그룹(motion picture experts group, MPEG)의 비디오 코딩에 대한 공동 협력 팀 (joint collaboration team on video coding, JCT-VC)에 의해 개발된 다목적 비디오 코딩(versatile video coding, VVC) 참조 소프트웨어 또는 고효율 비디오 코딩(high-efficiency video coding, HEVC)을 참조하여 설 명된다. 당업자는 본 출원의 실시예가 HEVC 또는 VVC에 제한되지 않는다는 것을 이해한다. 인코더 및 인코딩 방법 도 2에 도시된 바와 같이, 비디오 인코더는 입력단(또는 입력 인터페이스), 잔차 계산 유닛, 변 환 처리 유닛, 양자화 유닛, 역 양자화(inverse quantization) 유닛, 역 변환 처리 유닛, 재구성 유닛, 루프 필터, 디코딩된 픽처 버퍼(decoded picture buffer, DPB), 모드 선택 유닛 , 엔트로피 인코딩 유닛 및 출력단(또는 출력 인터페이스)을 포함한다. 모드 선택 유닛은 인터 예측 유닛, 인트라 예측 유닛 및 파티셔닝 유닛을 포함할 수 있다. 인터 예측 유닛은 모션 추정 유닛 및 모션 보상 유닛(도시되지 않음)를 포함할 수 있다. 도 2에 도시된 비디오 인코더는 하이 브리드(hybrid) 비디오 인코더 또는 하이브리드 비디오 코덱 기반의 비디오 인코더라고도 지칭될 수 있다. 도 2를 참조한다. 인터 예측 유닛은 트레이닝된 타깃 모델(신경망이라고도 함)이다. 신경망은 입력 픽처, 픽처 영역(area) 또는 픽처 블록을 처리하여 입력 픽처 블록의 예측자(predictor)를 생성하도록 구성된다. 예를 들어, 인터 예측을 위한 신경망은 입력 픽처, 픽처 영역 또는 픽처 블록을 수신하고, 입력 픽처, 픽처 영역 또 는 픽처 블록의 예측자를 생성하도록 구성된다. 잔차 계산 유닛, 변환 처리 유닛, 양자화 유닛 및 모드 선택 유닛은 인코더의 순방향 (forward) 신호 경로를 형성하고, 역 양자화 유닛, 역 변환 처리 유닛, 재구성 유닛, 버퍼 , 루프 필터, 디코딩된 픽처 버퍼(decoded picture buffer, DPB), 인터 예측 유닛 및 인 트라 예측 유닛은 인코더의 역방향(backward) 신호 경로를 형성한다. 인코더의 역방향 신호 경로는 디 코더(도 3의 디코더를 참조)의 신호 경로에 대응된다. 역 양자화 유닛, 역 변환 처리 유닛, 재구 성 유닛, 루프 필터, 디코딩된 픽처 버퍼, 인터 예측 유닛 및 인트라 예측 유닛도 비 디오 인코더의 \"내장 디코더\"를 구성한다. 픽처 및 픽처 파티셔닝(픽처 및 블록) 인코더는 입력단을 통해 픽처(또는 픽처 데이터), 예를 들어 비디오 또는 비디오 시퀀스를 형성하 는 픽처 시퀀스의 픽처를 수신하도록 구성될 수 있다. 수신된 픽처 또는 픽처 데이터는 전처리된 픽처(또는 전 처리된 픽처 데이터)일 수도 있다. 설명의 편의를 위해, 다음에는 픽처를 참조하여 설명한다. 픽처(1 7)는 또한 현재 픽처 또는 인코딩 대상 픽처(특히, 현재 픽처를 다른 픽처, 예를 들어 동일한 비디오 시퀀스 즉, 현재 픽처도 포함하는 비디오 시퀀스의 이전에 인코딩 및/또는 디코딩된 픽처와 구별하기 위한 비디오 코딩 에서)로 지칭될 수 있다. (디지털) 픽처는 강도(intensity) 값이 있는 샘플의 2차원 어레이 또는 행렬로 간주될 수 있다. 어레이의 샘플 은 픽셀(픽셀 또는 펠(pel))(픽처 엘리먼트의 약어)이라고도 할 수 있다. 어레이의 수평 및 수직 방향(또는 축)의 샘플 수량은 픽처의 크기 및/또는 해상도를 정의한다. 색상을 표현하기 위해서는 일반적으로 3가지 색상 컴포넌트가 사용되며, 구체적으로 픽처는 3가지 샘플 어레이로 표현되거나 이를 포함할 수 있다. RBG 포맷 또는 색상 공간에서, 픽처는 대응하는 빨간색, 녹색 및 파란색 샘플 어레이를 포함한다. 그러나 비디오 코딩에서, 각 픽셀은 일반적으로 휘도/색차(luminance/chrominance) 포맷 또는 색상 공간, 예를 들어 YCbCr으로 나타내며, 이 는 Y(때때로 L로 지시됨)로 지시되는 휘도 컴포넌트와 Cb 및 Cr로 지시되는 2개의 색차 컴포넌트를 포함한다. 휘도(루마) 컴포넌트 Y는 휘도 또는 그레이 레벨 강도(예를 들어, 둘 다 그레이-스케일 픽처에서 동일함)를 나 타내고, 2개의 색차(chrominance, 줄여서 크로마(chroma)) 컴포넌트 Cb 및 Cr은 색차 또는 색상 정보 컴포넌트 를 나타낸다. 따라서, YCbCr 포맷의 픽처는 휘도 샘플 값의 휘도 샘플 어레이(Y)와 색차 값의 2개의 색차 샘플 어레이(Cb 및 Cr)를 포함한다. RGB 포맷의 픽처는 YCbCr 포맷으로 컨버전되거나 변환될 수 있으며 그 반대의 경 우도 마찬가지이다. 이 프로세스를 색상 변환 또는 컨버전(conversion)이라고도 한다. 픽처가 단색이면, 이 픽 처에는 휘도 샘플 어레이만 포함될 수 있다. 따라서 픽처는 예를 들어 단색 포맷의 휘도 샘플 어레이일 수 있으 며, 또는 휘도 샘플의 어레이와 4:2:0, 4:2:2 및 4:4:4 색상 포맷의 2개의 대응하는 색차 샘플 어레이일 수 있 다. 일 실시예에서, 비디오 인코더의 실시예는 픽처를 복수의(전형적으로는 중첩되지 않는) 픽처 블록(20 3)으로 파티셔닝하도록 구성된 픽처 파티셔닝 유닛(도 2에 도시되지 않음)을 포함할 수 있다. 이러한 블록은 H.265/HEVC 및 VVC 표준에서 루트(root) 블록, 매크로 블록(H.264/AVC), 코딩 트리 블록(coding tree block, CTB) 또는 코딩 트리 유닛(coding tree unit, CTU)이라고도 할 수 있다. 파티셔닝 유닛은 비디오 시퀀스의 모든 픽처에 대해 동일한 블록 크기와 블록 크기를 정의하는 대응하는 그리드를 사용하거나, 픽처 또는 픽처의 서브 세트 또는 픽처 그룹 간의 블록 크기를 변경하고, 각 픽처를 대응하는 블록으로 파티셔닝하도록 구성될 수 있다. 다른 실시예에서, 비디오 인코더는 픽처의 블록, 예를 들어 픽처를 형성하는 하나, 몇몇 또는 모 든 블록을 직접 수신하도록 구성될 수 있다. 픽처 블록은 현재 픽처 블록 또는 인코딩 대상 픽처 블록이라 고도 지칭될 수 있다. 픽처와 마찬가지로, 픽처 블록은 비록 픽처보다 차원(dimension)이 작지만, 강도 값(샘플 값)을 갖는 샘플의 2차원 어레이 또는 행렬이거나 그렇게 간주될 수 있다. 달리 말하면, 블록은 하나의 샘플 어 레이(예를 들어, 단색 픽처의 경우 휘도 어레이, 또는 컬러 픽처의 경우 휘도 또는 색차 어레이) 또는 3개 의 샘플 어레이(예를 들어, 컬러 픽처의 경우 하나의 휘도 어레이와 2개의 색차 어레이), 또는 사용된 색상 포 맷에 따른 다른 수량 및/또는 유형의 어레이를 포함할 수 있다. 블록의 수평 및 수직 방향(또는 축)의 샘 플 수량이 블록의 크기를 정의한다. 따라서, 블록은 M×N(M개의 열 × N개의 행)의 샘플 어레이일 수도 있 고, M×N 변환 계수 어레이일 수도 있다. 일 실시예에서, 도 2에 도시된 비디오 인코더는 픽처를 블록별로 인코딩하도록 구성될 수 있으며, 예를 들어 인코딩 및 예측은 각 블록에 대해 수행된다. 일 실시예에서, 도 2에 도시된 비디오 인코더는 추가로, 슬라이스(비디오 슬라이스라고도 함)를 사용하여 픽처를 파티셔닝 및/또는 인코딩하도록 구성될 수 있으며, 여기서 픽처는 하나 이상의 슬라이스(일반적으로 중 첩되지 않음)를 사용하여 파티셔닝되거나 인코딩될 수 있다. 각 슬라이스는 하나 이상의 블록(예를 들어, 코딩 트리 유닛(CTU)) 또는 하나 이상의 블록 그룹(예를 들어, H.265/HEVC/VVC 표준의 타일들(tile) 및 VVC 표준의 브릭(brick)들)을 포함할 수 있다. 일 실시예에서, 도 2에 도시된 비디오 인코더는 추가로, 슬라이스/타일 그룹(비디오 타일 그룹이라고도 함) 및/또는 타일(비디오 타일이라고도 함)을 사용하여 픽처를 파티셔닝 및/또는 인코딩하도록 구성될 수 있다. 픽 처는 하나 이상의 슬라이스/타일 그룹(일반적으로 중첩되지 않음)을 사용하여 파티셔닝되거나 인코딩될 수 있으 며, 각 슬라이스/타일 그룹은 하나 이상의 블록(예를 들어, CTU) 또는 하나 이상의 타일을 포함할 수 있다. 각 타일은 직사각형 모양일 수 있으며 하나 이상의 블록(예를 들어, CTU), 예를 들어 완전 블록 또는 분수 (fractional) 블록을 포함할 수 있다. 잔차 계산 잔차 계산 유닛은 픽처 블록(원본 블록)과 예측 블록(예측 블록에 대한 자세한 내용은 후 술됨)에 기반하여 잔차 블록를 계산하며, 예를 들어 샘블별로(픽셀별로) 픽처 블록의 샘플 값으로부터 예측 블록의 샘플 값을 감산하는 것에 의해 샘플 도메인에서 잔차 블록을 획득하도록 구성될 수 있다. 변환 처리 유닛은 잔차 블록의 샘플 값에 대해 변환, 예를 들어 이산 코사인 변환(discrete cosine transform, DCT) 또는 이산 사인 변환(discrete sine transform, DST)을 적용하여, 변환 도메인의 변환 계수 를 획득하도록 구성된다. 변환 계수는 변환 잔차 계수라고도 지칭될 수 있으며, 변환 도메인에서 잔 차 블록을 나타낼 수 있다. 변환 처리 유닛은 H.265/HEVC에 명시된 변환과 같은 DCT/DST의 정수 근사치를 적용하도록 구성될 수 있다. 직교 DCT 변환과 비교할 때, 이러한 정수 근사치는 일반적으로 팩터(factor)를 기반으로 스케일링된다. 순방향 및 역방향 변환을 사용하여 처리되는 잔차 블록의 놈(norm)을 보존하기 위해, 추가 스케일 팩터가 변환 프로세 스의 일부로서 적용된다. 스케일 팩터는 일반적으로 일부 제약 조건(constraint), 예를 들어, 시프트 연산을 위 한 2의 거듭제곱인 스케일 팩터, 변환 계수의 비트 깊이, 정확도와 구현 비용 간의 균형에 기반하여 선택된다. 예를 들어, 특정 스케일 팩터는 예를 들어 인코더 측의 역 변환 처리 유닛에 의해 역 변환 (및 예를 들어 디코더 측의 역 변환 처리 유닛에 의한 대응하는 역 변환)에 대해 명시되며, 이에 따라 대응하는 스케일 팩터는 예를 들어 인코더 측의 변환 처리 유닛에 의해 순방향 변환에 대해 명시될 수 있다. 일 시예에서, 비디오 인코더(대응적으로, 변환 처리 유닛)는 예를 들어 바로 또는 엔트로피 인코딩 유 닛에 의해 수행된 인코딩 또는 압축 후에 변환 파라미터, 예를 들어 하나 이상의 변환의 유형을 출력하도 록 구성될 수 있으므로, 예를 들어 비디오 디코더는 디코딩을 위한 변환 파라미터들을 수신하고 사용할 수 있다. 양자화 양자화 유닛은 예를 들어 스칼라 양자화 또는 벡터 양자화를 적용하는 것에 의해, 변환 계수를 양자 화하여 양자화된 변환 계수를 획득하도록 구성될 수 있다. 양자화된 변환 계수는 양자화된 잔차 계수 라고도 지칭될 수 있다. 양자화 프로세스는 변환 계수 중 일부 또는 전부와 관련된 비트 깊이를 줄일 수 있다. 예를 들어, n-비트 변환 계수는 양자화 동안 m-비트 변환 계수로 반내림(rounded down)될 수 있으며, 여기서 n은 m보다 크다. 양자 화 파라미터(quantization parameter, QP)를 조절하여 양자화 정도를 수정할 수 있다. 예를 들어, 스칼라 양자 화의 경우, 더 미세하거나(finer) 더 거친(coarser) 양자화를 달성하기 위해 서로 다른 스케일이 적용될 수 있 다. 양자화 단계가 작을수록 양자화는 정밀해지고, 양자화 단계가 클수록 양자화는 거칠어진다. 적절한 양자화 단계는 양자화 파라미터(quantization parameter, QP)로 지시될 수 있다. 예를 들어, 양자화 파라미터는 미리 정의된 적절한 양자화 단계 세트에 대한 인덱스일 수 있다. 예를 들어, 더 작은 양자화 파라미터는 더 미세한 양자화(더 작은 양자화 단계)에 대응할 수 있고 더 큰 양자화 파라미터는 더 거친 양자화(더 큰 양자화 단계)에 대응할 수 있으며, 그 반대도 마찬가지이다. 양자화는 양자화 단계에 의한 나눗셈(division)을 포함할 수 있고, 예를 들어 역 양자화 유닛에 의한 대응하는 및/또는 역 역양자화(dequantization)는 양자화 단계에 의한 곱셈을 포함할 수 있다. HEVC와 같은 일부 표준에 따른 실시예는 양자화 파라미터를 사용하여 양자화 단계를 결 정하도록 구성될 수 있다. 일반적으로, 양자화 단계는 나눗셈을 포함하는 수식의 고정점 근사화를 사용하여 양 자화 파라미터에 기반하여 계산될 수 있다. 잔차 블록의 놈(norm)을 복원하기 위해 양자화 및 역양자화를 위해 추가적인 스케일 팩터가 도입될 수 있으며, 여기서 잔차 블록의 놈은 양자화 단계에 대한 수식의 고정 소수점 근사화에 사용되는 스케일 및 양자화 파라미터로 인해 수정될 수 있다. 하나의 예시적인 구현에서, 역 변환의 스케일은 역양자화의 스케일과 조합될 수 있다. 다르게는, 맞춤화된 양자화 테이블이 사용될 수 있으며, 예를 들어 비트스트림에서 인코더에서 디코더로 시그널링될 수 있다. 양자화는 손실이 많은 연산으로, 양자화 단계가 클수록 손실도 커진다. 일 실시예에서, 비디오 인코더(대응적으로, 양자화 유닛)는 예를 들어 직접 또는 엔트로피 인코딩 유 닛에 의해 수행된 인코딩 또는 압축 후에 양자화 파라미터(quantization parameter, QP)를 출력하도록 구 성될 수 있다. 예를 들어, 비디오 디코더는 디코딩을 위해 양자화 파라미터를 수신하고 사용할 수 있다. 역 양자화 역 양자화 유닛은 양자화된 계수에 양자화 유닛의 역 양자화를 적용하여, 예를 들어, 양자화 유닛 과 동일한 양자화 단계에 기반하거나 이를 사용하여, 양자화 유닛에 의해 적용되는 양자화 방식의 역 을 적용하여, 역양자화된 계수(dequantized coefficient)를 획득하도록 구성된다. 역양자화된 계수는역양자화된 잔차 계수라고도 지칭될 수 있으며, 일반적으로 양자화에 의한 손실로 인한 변환 계수와는 상 이하지만 변환 계수에 대응한다. 역 변환 역 변환 처리 유닛은 변환 처리 유닛에 의해 적용된 변환의 역 변환, 예를 들어 역 이산 코사인 변환 (discrete cosine transform, DCT) 또는 역 이산 사인 변환(discrete sine transform, DST)를 수행하여 샘플 도메인에서 재구성된 잔차 블록(또는 대응하는 역양자화된 계수)을 획득한다. 재구성된 잔차 블록 은 변환 블록이라고도 지칭될 수 있다. 재구성 재구성 유닛(예를 들어, 합산기)는 변환 블록(즉, 재구성된 잔차 블록)을 예측 블록 에 추가하여, 예를 들어 재구성된 잔차 블록의 샘플 값과 예측 블록의 샘플 값을 더하여, 샘플 도메 인에서 재구성된 블록을 획득하도록 구성된다. 필터링 루프 필터 유닛(또는 줄여서 \"루프 필터\")은 재구성된 블록을 필터링하여 필터링된 블록을 획득하거나, 일반적으로 재구성된 샘플을 필터링하여 필터링된 샘플 값을 획득하도록 구성된다. 예를 들어, 루 프 필터 유닛은 픽셀 전환을 스무스하게(smooth) 하거나 비디오 품질을 향상시키도록 구성된다. 루프 필터 유닛 은 디블로킹 필터, 샘플 적응형 오프셋(sample-adaptive offset, SAO) 필터와 같은 하나 이상의 루프 필 터 또는 하나 이상의 다른 필터, 예를 들어 적응형 루프 필터(adaptive loop filter, ALF), 노이즈 억제 필터 (noise suppression filter, NSF), 또는 이들의 임의의 조합을 포함할 수 있다. 일 예에서, 루프 필터 유닛 은 디블로킹 필터, SAO 필터, ALF 필터를 포함할 수 있다. 필터링 프로세스의 순서는 디블로킹 필터, SAO 필터, ALF 필터 순일 수 있다. 또 다른 예에서는 색차 스케일링을 사용한 휘도 매핑(luma mapping with chroma scaling, LMCS)(즉, 적응형 인루프 리쉐이퍼(in-loop reshaper))이라는 프로세스가 추가된다. 이 프로세스는 디 블로킹 전에 수행된다. 다른 예에서, 디블로킹 필터 프로세스는 내부 서브 블록 에지, 예를 들어 아핀 서브 블 록 에지, ATMVP 서브 블록 에지, 서브 블록 변환(sub-block transform, SBT) 에지 및 인트라 서브 파티션 (intra sub-partition, ISP) 에지에도 적용될 수 있다. 도 2에는 루프 필터 유닛이 루프 필터인 것으로 도시되었으나, 다른 구성에서 루프 필터 유닛은 포스트 루프 필터로 구현될 수도 있다. 필터링된 블록 은 필터링된 재구성된 블록이라고도 지칭될 수 있다. 일 실시예에서, 비디오 인코더(대응적으로, 루프 필터 유닛)는 루프 필터 파라미터(예컨대, SAO 필터 파라미터, ALF 필터 파라미터, 또는 LMCS 파라미터)를 예를 들어 직접적으로 또는 엔트로피 인코딩 유닛에 의해 수행된 엔트로피 인코딩 후에 출력하도록 구성될 수 있으므로, 예를 들어 디코더는 디코딩을 위해 동 일하거나 서로 다른 루프 필터 파라미터를 수신하고 사용할 수 있다. 디코딩된 픽처 버퍼 디코딩 픽처 버퍼(decoded picture buffer, DPB)는 비디오 인코더에 의한 비디오 데이터 인코딩에 사 용되는 참조 픽처 데이터를 저장하는 참조 픽처 메모리일 수 있다. DPB는 동기식 DRAM(synchronous DRAM, SDRAM), 자기 저항 RAM(magnetoresistive RAM, MRAM)을 포함하는 동적 랜덤 액세스 메모리(dynamic random- access memory, DRAM), 저항성 RAM(resistive RAM, RRAM) 또는 다른 유형의 메모리 디바이스와 같은 다양한 메 모리 디바이스 중 어느 하나로 형성될 수 있다. 디코딩된 픽처 버퍼는 하나 이상의 필터링된 블록을 저장하도록 구성될 수 있다. 디코딩된 픽처 버퍼는 추가로, 동일한 현재 픽처 또는 서로 다른 픽처, 예를 들어 이전에 재구성된 픽처의 다른 이전에 필터링된 블록, 예를 들어 이전에 재구성되고 필터링된 블록을 저장하도록 구성될 수 있으며, 예를 들어 인터 예측을 위해, 이전에 재구성된 완전한 픽처 예를 들어, 디코딩된 픽처(및 대응하는 참조 블록 및 샘플) 및/또는 부분적으로 재구성된 현재 픽처(및 대응하는 참조 블록 및 샘 플)를 제공할 수 있다. 디코딩된 픽처 버퍼는 추가로, 하나 이상의 필터링되지 않은 재구성된 블록, 또는 예를 들어 재구성된 블록이 루프 필터 유닛에 의해 필터링되지 않으면, 일반적으로 필터링되지 않은 재구성된 샘플, 또는 임의의 다른 추가 처리된 버전의 재구성된 블록 또는 샘플을 저장하도록 구성될 수 있다. 모드 선택(파티셔닝 및 예측) 모드 선택 유닛은 파티셔닝 유닛, 인터 예측 유닛 및 인트라 예측 유닛를 포함하고, 원시 픽처 데이터, 예를 들어 원본 블록(현재 픽처의 현재 블록) 그리고 재구성된 픽처 데이터, 예를 들어 동일한(현재) 픽처의 필터링된 및/또는 필터링되지 않은 재구성된 샘플 또는 블록, 및/또는 하나 또는 복 수의 이전에 디코딩된 픽처로부터, 예를 들어 디코딩된 픽처 버퍼 또는 다른 버퍼(예를 들어, 도 2에 도시 되지 않은 라인 버퍼)로부터의 재구성된 픽처 데이터를 수신하거나 획득하도록 구성된다. 재구성된 픽처 데이터 가 예측, 예를 들어, 인터 예측 또는 인트라 예측을 위한 참조 픽처 데이터로 사용되어 예측 블록 또는 예 측 유닛을 획득한다. 모드 선택 유닛은 현재 블록에 대한 파티셔닝(비파티셔닝을 포함)과 예측 모드(예를 들어, 인트라 또는 인 터 예측 모드)를 결정 또는 선택하여, 잔차 블록의 계산 및 재구성된 블록의 재구성에 사용되는, 대 응하는 예측 블록을 생성하도록 구성될 수 있다. 일 실시예에서, 모드 선택 유닛은 파티셔닝 및 예측 모드(예를 들어, 모드 선택 유닛에 의해 지원되 거나 모드 선택 유닛에 이용 가능한 모드 중에서)를 선택하도록 구성될 수 있다. 예측 모드는 최상(best) 의 매치(match) 또는 최소 잔차(최소 잔차는 전송 또는 저장을 위한 더 나은 압축을 의미)를 제공하거나, 최소 시그널링 오버헤드(최소 시그널링 오버헤드는 전송 또는 저장을 위한 더 나은 압축을 의미)를 제공하거나, 두 가지를 모두 고려하거나 균형을 유지한다. 모드 선택 유닛는 레이트 왜곡 최적화(rate distortion optimization, RDO)에 기반하여 파티셔닝 및 예측 모드를 결정하도록 구성될 수 있으며, 예를 들어 최소 레이트 왜곡 최적화를 제공하는 예측 모드를 선택하도록 구성될 수 있다. 본 명세서에서 사용되는 \"최상\", \"최저\", \"최 적\" 등의 용어는 일반적으로 반드시 \"최상\", \"최저\", \"최적\"을 의미하는 것은 아니며, 종료 또는 선택 기준이 충족되는 상황을 의미할 수도 있다. 예를 들어 임계값 또는 기타 제한 사항을 초과하거나 미만인 값은 \"최적화 되지 않은(suboptimal) 선택\"을 초래할 수 있지만 복잡성과 처리 시간을 줄일 수 있다. 달리 말하면, 파티셔닝 유닛은 비디오 시퀀스로부터의 픽처를 코딩 트리 유닛(coding tree units, CTU)의 시퀀스로 파티셔닝하도록 구성될 수 있고, CTU는 예를 들어 쿼드 트리 파티셔닝(quad-tree partitioning, QT), 이진 트리 파티셔닝(binary-tree partitioning, BT) 또는 삼중 트리 파티셔닝(triple-tree partitioning, TT) 또는 이들의 임의의 조합을 반복적으로 사용하여, 그리고 예를 들어 각각의 블록 파티션 또는 서브 블록에 대한 예측을 수행하기 위해, 더 작은 블록 파티션 또는 서브 블록(블록을 다시 형성함)으로 추가로 파티셔닝될 수 있으며, 여기서 모드 선택은 파티셔닝된 블록의 트리 구조의 선택과 각각의 블록 파티션 또는 서브 블 록에 적용되는 예측 모드를 포함한다. 이하에서는 비디오 인코더에 의해 수행되는 파티셔닝(예를 들어, 파티셔닝 유닛에 의한) 및 예측(예를 들어, 인터 예측 유닛 및 인트라 예측 유닛에 의한)을 구체적으로 설명한다. 파티셔닝 파티셔닝 유닛은 픽처 블록(또는 CTU)을 더 작은 파티션, 예를 들어 정사각형 또는 직사각형의 더 작 은 블록으로 파티셔닝(또는 분할(split))할 수 있다. 세 개의 샘플 어레이가 있는 픽처의 경우, CTU에는 색차 샘플의 2개의 대응하는 블록과 함께 휘도 샘플의 N×N 블록이 포함된다. 현재 개발 중인 다목적 비디오 코딩 (Versatile Video Coding, VVC) 표준에서는 CTU 내 휘도 블록의 최대 허용 크기를 128×128로 명시하고 있으나, 향후에는 128×128이 아닌 값, 예를 들어 256×256으로 명시될 수도 있다. 픽처의 CTU는 슬라이스/타일 그룹, 타일 또는 브릭으로 클러스터링/그룹화될 수 있다. 타일은 픽처의 직사각형 영역을 덮고 있으며, 타일은 하나 이상의 브릭으로 나뉠 수 있다. 브릭은 타일에서 복수의 CTU 행을 포함한다. 복수의 브릭으로 파티셔닝되 지 않은 타일을 브릭이라고 할 수 있다. 그러나 브릭은 타일의 참(true) 서브 세트이며 타일이라고 지칭되지 않 는다. VVC에서는 두 가지 타일 그룹 모드, 즉 래스터 스캔 슬라이스/타일 그룹 모드와 직사각형 슬라이스 모드 가 지원된다. 래스터 스캔 타일 그룹 모드에서, 슬라이스/타일 그룹은 픽처의 타일 래스터 스캔에 있는 타일의 시퀀스를 포함한다. 직사각형 슬라이스 모드에서, 슬라이스는 픽처의 직사각형 영역을 집합적으로 형성하는 픽 처의 복수의 브릭을 포함한다. 직사각형 슬라이스 내의 브릭은 슬라이스의 브릭 래스터 스캔의 순서에 있다. 이 러한 더 작은 블록(서브 블록이라고도 함)은 더 작은 파티션으로 추가로 파티셔닝될 수 있다. 이는 트리 파티셔 닝 또는 계층적 트리 파티셔닝이라고도 하며, 예를 들어 루트 트리 레벨 0(계층 레벨(hierarchy-level) 0 또는 깊이 0)의 루트 블록이 반복적으로 파티셔닝될 수 있으며, 예를 들어 다음 하위 트리 레벨의 두 개 이상의 블록, 예를 들어 트리 레벨 1(계층 레벨 1 또는 깊이 1)의 노드로 파티셔닝될 수 있다. 이러한 블록은 파티셔닝 이 종료될 때까지(종료 기준이 충족되기 때문에, 예를 들어 최대 트리 깊이 또는 최소 블록 크기에 도달함), 다 음 하위 레벨, 예를 들어 트리 레벨 2(계층 레벨 2 또는 깊이 2)의 두 개 이상의 블록으로 다시 파티셔닝될 수 있다. 추가로 파티셔닝되지 않는 블록은 트리의 리프 블록 또는 리프 노드라고도 한다. 2개의 파티션으로 파티셔닝하는 트리를 이진 트리(binary-tree, BT)라고 하고, 3개의 파티션으로 파티셔닝하는 트리를 삼진 트리 (ternary-tree, TT)라고 하며, 4개의 파티션으로 파티셔닝하는 것을 쿼드 트리(quad-tree, QT)라고 한다. 예를 들어, 코딩 트리 유닛(CTU)은 휘도 샘플의 CTB, 3개의 샘플 어레이를 갖는 픽처의 색차 샘플의 대응하는 2 개의 CTB, 또는 단색 픽처 또는 세 가지의 개별 색상 평면과 신택스 구조(샘플을 코딩하는 데 사용됨)를 사용하 여 코딩된 픽처의 샘플의 CTB이거나 이를 포함할 수 있다. 이에 대응하여, 코딩 트리 블록(CTB)은 컴포넌트를 CTB로 분할하는 것이 파티셔닝이 되도록 N의 일부 값에 대한 샘플의 N×N 블록일 수 있다. 코딩 유닛(coding unit, CU)은 휘도 샘플의 코딩 블록, 3개의 샘플 어레이를 갖는 픽처의 색차 샘플의 대응하는 2개의 코딩 블록, 또는 단색 픽처 또는 세 가지의 개별 색상 평면과 신택스 구조(샘플을 코딩하는 데 사용됨)를 사용하여 코딩된 픽처의 샘플의 코딩 블록이거나 이를 포함할 수 있다. 이에 대응하여, 코딩 블록(CB)은 CTB를 코딩 블록으로 분 할하는 것이 파티셔닝되도록, M 및 N의 일부 값에 대한 샘플의 M×N 블록일 수 있다. 일 실시예에서, 예를 들어 HEVC에 따르면, 코딩 트리 유닛(CTU)은 코딩 트리로 표시되는 쿼드 트리 구조를 사용 하여 복수의 CU로 분할될 수 있다. 픽처 영역을 인터(시간) 예측 또는 인트라(공간) 예측으로 코딩할지의 여부 는 리프 CU 레벨에서 결정된다. 각 리프 CU는 PU 분할 유형에 기반하여 1개, 2개 또는 4개의 PU로 추가로 분할 될 수 있다. 하나의 PU 내에서 동일한 예측 프로세스가 적용되며 관련 정보는 PU 단위로 디코더로 전송된다. PU 분할 유형에 기반하여 예측 프로세스를 적용하여 잔차 블록을 획득된 후, 리프 CU는 CU에 대한 코딩 트리와 유 사한 또 다른 쿼드 트리 구조에 기반하여 변환 유닛(transform unit, TU)으로 파티셔닝될 수 있다. 일 실시예에서, 예를 들어, 현재 개발 중인 최신 비디오 코딩 표준(VVC(Versable Video Coding)라고도 함)에 따 라, 조합된 쿼드 트리 중첩(nested) 다중 유형 트리(예를 들어, 이진 트리 및 삼진 트리)가 코딩 트리 유닛을 파티셔닝하는 데 사용되는 세그멘테이션 구조를 분할한다. 코딩 트리 유닛 내 코딩 트리 구조에서, CU는 정사각 형 또는 직사각형 모양을 가질 수 있다. 예를 들어, 코딩 트리 유닛(CTU)은 먼저 쿼드 트리 구조로 파티셔닝된 다. 그런 다음 쿼드 트리 리프 노드는 다중 유형 트리 구조로 추가로 파티셔닝될 수 있다. 다중 유형 트리 구조 에는 수직 이진 트리 파티셔닝(SPLIT_BT_VER), 수평 이진 트리 파티셔닝(SPLIT_BT_HOR), 수직 삼진 트리 파티셔 닝(SPLIT_TT_VER), 수평 삼진 트리 파티셔닝(SPLIT_TT_HOR)의 네 가지 분할 유형이 있다. 다중 유형 트리 리프 노드를 코딩 유닛(CU)이라고 하며, CU가 최대 변환 길이에 비해 지나치게 크지 않는 한, 이 세그멘테이션은 임 의의 추가 파티셔닝없이 예측 및 변환 처리에 사용된다. 이는 대부분의 경우, 중첩 다중 유형 트리 코딩 블록 구조를 갖는 쿼드 트리에서 CU, PU 및 TU가 동일한 블록 크기를 갖는다는 것을 의미한다. 지원되는 최대 변환 길이가 CU의 색상 컴포넌트의 너비 또는 높이보다 작을 때 예외가 발생한다. VVC는 중첩 다중 유형 트리 코딩 구조를 갖는 쿼드 트리에서 분할 정보를 파티셔닝하는 고유한 시그널링 메커니즘을 개발한다. 시그널링 메커니 즘에서, 코딩 트리 유닛(CTU)은 쿼드 트리의 루트로 처리되며 먼저 쿼드 트리 구조에 의해 파티셔닝된다. 각 쿼 드 트리 리프 노드(허용할 만큼 충분히 클 때)는 다중 유형 트리 구조에 의해 추가로 파티셔닝된다. 다중 유형 트리 구조에서, 노드가 추가로 파티셔닝되는지를 지시하기 위해 제1 플래그(mtt_split_cu_flag)가 시그널링되며; 노드가 추가로 파티셔될 때, 분할 방향을 지시하기 위해 제2 플래그 (mtt_split_cu_vertical_flag)가 시그널링되고, 그런 다음, 분할이 이진 트리 분할인지 삼진 트리 분할인지를 지시하기 위해 제3 플래그(mtt_split_cu_binary_flag)가 시그널링된다. mtt_split_cu_vertical_flag과 mtt_split_cu_binary_flag의 값에 기반하여, CU의 다중 유형 트리 분할 모드(MttSplitMode)가 미리 정의된 규 칙 또는 테이블에 기반하여 디코더에 의해 도출될 수 있다. 특정 설계, 예를 들어, VVC 하드웨어 디코더의 64× 64 루마 블록 및 32×32 크로마 파이프라이닝 설계의 경우, 휘도 코딩 블록의 너비 또는 높이가 64보다 클 때 TT 분할이 금지된다. 색차 코딩 블록의 너비 또는 높이가 32보다 클 때에도 TT 분할이 금지된다. 파이프라이닝 설계는 픽처를 픽처에서 중첩되지 않는 유닛으로 정의되는 가상 파이프라인 데이터 유닛(virtual pipeline data unit, VPDU)로 나눈다. 하드웨어 디코더에서, 연속적인 VPDU는 복수의 파이프라인 스테이지에 의해 동시에 처리 된다. VPDU 크기는 대부분의 파이프라인 스테이지에서 버퍼 크기에 대략 비례하므로, VPDU 크기를 작게 유지하 는 것이 중요하다. 대부분의 하드웨어 디코더에서, VPDU 크기는 최대 변환 블록(TB) 크기로 설정될 수 있다. 그 러나 VVC에서는 삼진 트리(TT) 및 이진 트리(BT) 파티셔닝으로 인해 VPDU 크기가 증가할 수 있다. 또한, 트리 노드 블록의 일부가 하단 또는 우측 픽처 경계를 초과할 때, 모든 코딩된 CU의 모든 샘플이 픽처 경 계 내부에 위치할 때까지 트리 노드 블록이 강제로 분할된다는 점에 유의해야 한다. 예를 들어, 인트라 서브 파티션(Intra sub-partition, ISP) 도구는 루마 인트라 예측된 블록을 블록 크기에 따 라 수직 또는 수평으로 2개 또는 4개의 서브 파티션으로 나눌 수 있다. 일 예에서, 비디오 인코더의 모드 선택 유닛은 위에서 설명된 파티셔닝 기술의 임의의 조합을 수행하 도록 구성될 수도 있다. 위에서 설명한 바와 같이, 비디오 인코더는 (미리 결정된) 예측 모드 세트로부터 최상의 또는 최적의 예측 모드를 결정하거나 선택하도록 구성된다. 예측 모드 세트는, 예를 들어, 인트라 예측 모드 및/또는 인터 예측 모드를 포함할 수 있다. 인트라 예측 인트라 예측 모드 세트는 35개의 서로 다른 인트라 예측 모드, 예를 들어 HEVC에서 정의된 지향성 모드나 DC(또 는 평균) 모드 및 평면(planar) 모드와 같은 비지향성 모드를 포함할 수 있으며, 또는 67개의 서로 다른 인트라 예측 모드, 예를 들어 VVC에서 정의된 지향성 모드나 DC(또는 평균) 모드 및 평면 모드와 같은 비지향성 모드를 포함할 수 있다. 예를 들어, 여러 기존 각도 인트라 예측 모드는 VVC에 정의된 바와 같이 정사각형이 아닌 블록 에 대한 광각 인트라 예측 모드로 적응적으로 대체된다. 또 다른 예로, DC 예측에 대한 나눗셈 연산(division operation)을 피하기 위해, 정사각형이 아닌 블록의 평균을 계산하는 데 더 긴 변(side)만 사용된다. 또한, 위 치 의존적 인트라 예측 조합(position dependent intra prediction combination, PDPC) 방법을 사용하여 평면 모드의 인트라 예측 결과를 추가로 수정할 수도 있다. 인트라 예측 유닛은 인트라 예측 모드 세트 중 인트라 예측 모드에 기반하여 동일한 현재 픽처의 이웃 블 록의 재구성된 샘플을 사용하여 인트라 예측 블록을 생성하도록 구성된다. 인트라 예측 유닛(또는 일반적으로 모드 선택 유닛)은 추가로, 인트라 예측 파라미터(또는 일반적으 로 블록에 대해 선택된 인트라 예측 모드를 지시하는 정보)를 인코딩된 픽처 데이터에 포함시키기 위해 신 택스 엘리먼트의 형태로 엔트로피 인코딩 유닛에 출력하도록 구성됨으로써, 예를 들어, 비디오 디코 더가 디코딩을 위해 예측 파라미터를 수신하고 사용할 수 있다. HEVC의 인트라 예측 모드에는 직접 현재(direct current) 예측 모드, 평면 예측 모드, 33개의 각도 예측 모드가 포함된다. 즉, 총 35개의 후보 예측 모드가 있다. 현재 블록은 좌측과 위쪽(upper)의 재구성된 픽처 블록의 픽 셀을 참조로 사용하여 인트라 예측을 수행할 수 있다. 현재 블록의 주변 영역에 있는 픽처 블록이면서 또한 현 재 블록에 대한 인트라 예측에 사용되는 픽처 블록이 참조 블록이 되고, 참조 블록의 픽셀을 참조 픽셀이라고 한다. 35개의 후보 예측 모드 중, 직접 현재 예측 모드는 현재 블록에서 텍스처가 플랫(flat)한 영역에 적용 가 능하며, 이 영역의 모든 픽셀은 참조 블록 내 참조 픽셀의 평균값을 예측으로 사용한다. 평면 예측 모드는 텍스 처가 원활하게 변화하는 픽처 블록에 적용 가능하다. 조건을 만족하는 현재 블록에 대해서는, 참조 블록 내 참 조 픽셀을 현재 블록 내 모든 픽셀에 대한 예측으로 사용하여 쌍선형 보간(bilinear interpolation)을 수행한다. 각도 예측 모드에서, 현재 블록의 텍스처가 이웃의 재구성된 픽처 블록의 텍스처와 높은 상관 관계를 가지고 있다는 특징을 이용하여, 대응하는 참조 블록의 참조 픽셀의 값을 현재 블록의 모든 픽셀의 예측으로서 각도에 따라 복사한다. HEVC 인코더는 현재 블록에 대한 35개의 후보 예측 모드로부터 최적의 인트라 예측 모드를 선택하고, 최적의 인 트라 예측 모드를 비디오 비트스트림에 기록한다. 인트라 예측의 코딩 효율을 높이기 위해, 인코더/디코더는 주 변 영역에서 인트라 예측을 사용하는 재구성된 픽처 블록의 개개의 최적의 인트라 예측 모드로부터 3개의 가장 가능성이 높은 모드를 도출한다. 현재 블록에 대해 선택된 최적의 인트라 예측 모드가 3개의 가능성이 가장 높 은 모드 중 하나이면, 선택된 최적의 인트라 예측 모드가 3개의 가능성이 가장 높은 모드 중 하나임을 지시하기 위해 제1 인덱스가 인코딩된다. 선택된 최적의 인트라 예측 모드가 3개의 가장 가능성이 높은 모드 중 하나가 아니면, 선택된 최적의 인트라 예측 모드가 다른 32개의 모드(35개의 후보 예측 모드에서 위의 3개의 가장 가능 성이 높은 모드 이외의 모드) 중 하나임을 지시하기 위해 제2 인덱스가 인코딩된다. HEVC 표준은 5비트 고정 길 이 코드를 전술한 제2 인덱스로 사용한다. HEVC 인코더가 3개의 가장 가능성 높은 모드를 도출하는 방법은: 현재 블록의 좌측 이웃 픽처 블록과 위쪽 이웃 픽처 블록의 최적의 인트라 예측 모드를 선택하고, 최적의 인트라 예측 모드를 세트로 만드는 것을 포함한다. 2 개의 최적의 인트라 예측 모드가 동일하면, 세트에서 하나의 인트라 예측 모드만 예약된다(reserved). 2개의 최 적의 인트라 예측 모드가 동일하고 모두 각도 예측 모드이면, 각도 방향에 인접한 2개의 각도 예측 모드를 추가 로 선택하여 세트에 추가한다. 그렇지 않으면, 세트 내 모드의 수량이 3이 될 때까지 평면 예측 모드, 직접 현 재 모드, 수직 예측 모드를 순차적으로 선택하여 세트에 추가한다. HEVC 디코더는 비트스트림에 대해 엔트로피 디코딩을 수행한 후 현재 블록의 모드 정보를 획득한다. 모드 정보 는 현재 블록의 최적의 인트라 예측 모드가 3개의 가능성이 가장 높은 모드 중에 있는지를 지시하는 식별자, 3개의 가능성이 가장 높은 모드 중 현재 블록의 최적의 인트라 예측 모드의 인덱스, 또는 나머지 32개 모드 중 현재 블록의 최적의 인트라 예측 모드의 인덱스를 포함한다. 인터 예측 가능한 구현에서, 인터 예측 모드 세트는 이용 가능한 참조 픽처(즉, 예를 들어 DBP에 저장된 이전의 적어 도 부분적으로 디코딩된 픽처) 및 다른 인터 예측 파라미터, 예를 들어 전체 참조 픽처 또는 참조 픽처의 일부 만 예를 들어, 참조 픽처의 현재 블록 영역 주변의 탐색 윈도우 영역이 최상의 매칭 참조 블록을 탐색하는 데 사용되는지의 여부, 및/또는 예를 들어 픽셀 보간이 적용되는지의 여부, 예를 들어 절반-픽셀, 1/4픽셀 및/또는 1/16픽셀 보간이 적용되는지의 여부에 따라 달라진다. 전술한 예측 모드 외에 스킵 모드 및/또는 직접(direct) 모드가 더 적용될 수 있다. 예를 들어, 확장된 병합 예측 모드의 병합 후보 리스트에는 공간적 이웃 CU로부터의 공간적 MVP, 동일 위치에 있는(collocated) CU로부터의 시간적 MVP, FIFO 테이블로부터의 히스토리 기반 MVP, 쌍별(pairwise) 평균 MVP, 제로 MVP의 5가지 유형의 후보가 순서대로 포함된다. 병합 모드의 MV의 정확도를 높이기 위해 양방향 매칭 기반 디코더 측 모션 벡터 개선(decoder side motion vector refinement, DMVR)이 사용될 수 있다. MVD가 있는 병합 모드(merge mode with an MVD, MMVD)는 모션 벡터 차이가 있는 병합 모드에서 비롯된다. CU에 MMVD 모드를 사 용할지를 명시하기 위해 스킵 플래그와 병합 플래그가 송신된 직후에 MMVD 플래그가 송신된다. CU 레벨의 적응 형 모션 벡터 해상도(adaptive motion vector resolution, AMVR) 방식이 사용될 수 있다. AMVR을 사용하면 CU 의 MVD를 서로 다른 정밀도로 코딩할 수 있다. 현재 CU의 예측 모드에 기반하여 현재 CU의 MVD가 적응적으로 선 택될 수 있다. CU가 병합 모드로 코딩될 때, 조합된 인터/인트라 예측(combined inter/intra prediction, CIIP) 모드가 현재 CU에 적용될 수 있다. CIIP 예측을 획득하기 위해 인터 및 인트라 예측 신호의 가중 평균화 가 수행된다. 아핀(affine) 모션 보상 예측을 위해서는 2개의 제어점(4-파라미터) 모션 벡터 또는 3개의 제어점 (6-파라미터) 모션 벡터의 모션 정보에 기반하여 블록의 아핀 모션 필드를 기술한다. 서브 블록 기반 시간적 모 션 벡터 예측(subblock-based temporal motion vector prediction, SbTMVP)은 HEVC에서의 시간적 모션 벡터 예 측(temporal motion vector prediction, TMVP)과 유사하지만, 현재 CU에서 서브 CU의 모션 벡터를 예측한다. 이전에 BIO라고 지칭된 양방향 광학적 플로(bi-direction optical flow, BDOF)는 특히 곱셈의 수량과 곱셈기의 값 측면에서 훨씬 적은 계산이 필요한 간단한 버전이다. 삼각형 분할 모드에서는 CU가 대각선 분할과 안티대각 선(anti-diagonal) 분할을 통해 2개의 삼각형 부분으로 균등하게 분할된다. 또한, 양방향 예측 모드는 단순 평 균을 넘어 두 예측 신호의 가중 평균을 허용하도록 확장된다. 인터 예측 유닛은 모션 추정(motion estimation, ME) 유닛과 모션 보상(motion compensation, MC) 유닛 (도 2에서는 도시되지 않음)을 포함할 수 있다. 모션 추정 유닛은 픽처 블록(현재 픽처의 현재 픽처 블록) 및 디코딩된 픽처, 또는 모션 추정을 위해 적어도 하나 이상의 이전에 재구성된 블록, 예를 들 어 하나 이상의 다른/서로 다른 이전에 디코딩된 픽처의 재구성된 블록을 수신하거나 획득하도록 구성될 수 있다. 예를 들어, 비디오 시퀀스는 현재 픽처와 이전에 디코딩된 픽처를 포함할 수 있고, 즉, 현재 픽 처와 이전에 디코딩된 픽처는 비디오 시퀀스를 형성하는 픽처의 시퀀스의 일부이거나 이를 형성할 수 있다. 예를 들어, 인코더는 동일한 픽처 또는 복수의 다른 픽처의 서로 다른 픽처의 복수의 참조 블록으로부터 참 조 블록을 선택하고, 참조 픽처(또는 참조 픽처 인덱스) 및/또는 참조 블록의 위치(position)(x 및 y 좌표)와 현재 블록의 위치 사이의 공간적 오프셋(spatial offset)을 인터 예측 파라미터로서 모션 추정 유닛에 제공한다. 이 오프셋을 모션 벡터(motion vector, MV)라고도 한다. 모션 보상 유닛은 인터 예측 파라미터를 획득 예를 들어 수신하고 인터 예측 파라미터에 기반하거나 이를 사용 하여 인터 예측을 수행하여 인터 예측 블록을 획득하도록 구성된다. 모션 보상 유닛이 수행하는 모션 보상 은 모션 추정을 통해 결정된 모션/블록 벡터에 기반하여 예측 블록을 추출 또는 생성하는 것을 포함할 수 있으 며, 서브 픽셀 정밀도에 대한 보간을 수행하는 것을 더 포함할 수 있다. 보간 필터링은 알려진 픽셀 샘플로부터 추가 픽셀 샘플을 생성할 수 있으므로, 잠재적으로 픽처 블록을 코딩하는 데 사용될 수 있는 후보 예측 블록의 수량이 증가한다. 모션 보상 유닛은 현재 픽처 블록의 PU에 대응하는 모션 벡터를 수신하면, 참조 픽처 리스트 중 하나에서 모션 벡터가 가리키는 예측 블록을 찾을 수 있다. 모션 보상 유닛은 추가로, 비디오 슬라이스의 픽처 블록을 디코딩할 때 비디오 디코더가 사용하기 위해 블 록 및 비디오 슬라이스와 연관된 신택스 엘리먼트를 생성할 수 있다. 슬라이스 및 개개의 신택스 엘리먼트에 추가로 또는 대안으로, 타일 그룹 및/또는 타일 및 개개의 신택스 엘리먼트가 생성되거나 사용될 수 있다. 고급 모션 벡터 예측(advanced motion vector prediction, AMVP) 모드의 후보 모션 벡터 리스트를 획득하는 프 로세스에서, 후보 모션 벡터 리스트에 대안으로 추가될 수 있는 모션 벡터(motion vector, MV)는 현재 블록의 공간적으로 이웃한 픽처 블록의 MV와 현재 블록의 시간적으로 이웃한 픽처 블록의 MV를 포함한다. 공간적으로 이웃한 픽처 블록의 모션 벡터는 현재 블록의 좌측 후보 픽처 블록의 MV와 현재 블록의 위쪽 후보 픽처 블록의 MV를 포함할 수 있다. 예를 들어, 도 4는 본 출원의 실시예에 따른 후보 픽처 블록의 예에 대한 개략도이다. 도 4에 도시된 바와 같이, 좌측 후보 픽처 블록의 세트는 {A0, A1}을 포함하고, 상단(top) 후보 픽처 블록의 세트 는 {B0, B1, B2}를 포함하며, 시간적으로 이웃한 후보 픽처 블록의 세트는 {C, T}를 포함한다. 3개의 세트 모두 대안으로 후보 모션 벡터 리스트에 추가될 수 있다. 그러나 기존 코딩 표준에 따르면, AMVP의 후보 모션 벡터 리스트의 최대 길이는 2이다. 따라서 최대 2개의 픽처 블록의 MV를 지정된 순서로 3개의 세트로부터 결정하여 후보 모션 벡터 리스트에 추가해야 한다. 순서는 다음과 같을 수 있다. 현재 블록의 좌측 후보 픽처 블록 세트 {A0, A1}가 우선적으로 고려되고(여기서 A0이 먼저 고려되고 A0을 이용 가능하지 않으면 A1이 고려됨); 그런 다 음 현재 블록의 상단 후보 픽처 블록 세트 {B0, B1, B2}가 고려되며(여기서 B0이 먼저 고려되고 B0이 이용 가능 하지 않으면 B1이 고려되고 B1이 이용 가능하지 않으면 B2가 마지막으로 고려됨); 마지막으로, 현재 블록의 시 간적으로 이웃한 후보 픽처 블록 세트 {C, T}가 고려된다(여기서 T가 먼저 고려되고, T가 이용 가능하지 않으면 C가 고려됨). 후보 모션 벡터 리스트를 획득한 후, 레이트 왜곡 비용(rate distortion cost, RD Cost)에 기반하여 후보 모션 벡터 리스트로부터 최적의 MV를 결정하고, RD 비용이 최소인 후보 모션 벡터를 모션 벡터 예측자(motion vector predictor, MVP)로 사용한다. 레이트 왜곡 비용은 다음 수식에 따라 계산된다:"}
{"patent_id": "10-2024-7006856", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "J는 RD 비용을 나타내고, SAD는 후보 모션 벡터에 기반하여 모션 추정을 통해 획득된, 예측 블록의 픽셀값과 현 재 블록의 픽셀값 사이의 절대차의 합(sum of absolute differences, SAD)이며, R은 비트 레이트를 나타내고, λ는 라그랑주 승수를 나타낸다. 인코더 측은 후보 모션 벡터 리스트에서의 결정된 MVP의 인덱스를 디코더 측으로 전달한다. 또한, MVP 중심의 이웃 도메인에서 모션 탐색을 수행하여 현재 블록의 실제 모션 벡터를 획득한다. 인코더 측에서는 MVP와 실제 모션 벡터 간의 모션 벡터 차이(motion vector difference, MVD)를 계산하고, MVD를 디코더 측에 전달한다. 디 코더 측은 인덱스를 파싱하고, 인덱스에 기반하여 후보 모션 벡터 리스트에서 대응하는 MVP를 찾고, MVD를 파싱 하며, MVD와 MVP를 합산하여 현재 블록의 실제 모션 벡터를 획득한다. 병합(Merge) 모드에서 후보 모션 정보 리스트를 획득하는 프로세스에서, 후보 모션 정보 리스트에 대안으로 추 가될 수 있는 모션 정보는, 현재 블록의 공간적으로 이웃한 픽처 블록 또는 시간적으로 이웃한 픽처 블록의 모 션 정보를 포함한다. 공간적으로 이웃한 픽처 블록과 시간적으로 이웃한 픽처 블록은 도 4에 도시될 수 있다. 후보 모션 정보 리스트에서 공간적 픽처 블록에 대응하는 후보 모션 정보는 5개의 공간적으로 이웃한 블록(A0, A1, B0, B1, B2)으로부터 온다. 공간적으로 이웃한 블록이 이용 가능하지 않거나 인트라 프레임 예측 모드에 있 으면, 공간적으로 이웃한 블록의 모션 정보는 후보 모션 정보 리스트에 추가되지 않는다. 현재 블록의 시간적 후보 모션 정보는 참조 프레임의 픽처 순서 카운트(picture order count, POC)와 현재 프레임의 픽처 순서 카운 트(picture order count, POC)에 기반하여 참조 프레임에서 대응하는 위치에 있는 블록의 MV를 스케일링한 후 획득된다. 참조 프레임에서 T 위치의 블록이 이용 가능한지를 먼저 판정한다. 이용 가능하지 않으면, C 위치의 블록이 선택된다. 후보 모션 정보 리스트를 획득한 후, RD 비용에 기반하여 후보 모션 정보 리스트로부터 최적 의 모션 정보를 현재 블록의 모션 정보로 결정한다. 인코더 측에서는 후보 모션 정보 리스트 내 최적의 모션 정 보 위치의 인덱스 값(병합 인덱스라고 표시됨)을 디코더 측으로 전송한다. 엔트로피 코딩 엔트로피 인코딩 유닛은 엔트로피 인코딩 알고리즘이나 방식(예를 들어, 가변 길이 코딩(variable length coding, VLC) 방식, 콘텍스트 적응형 VLC(context-adaptive VLC, CALVC) 방식, 산술 코딩 방식, 이진화, 콘텍 스트 적응형 이진 산술 코딩(context-adaptive binary arithmetic coding, CABAC), 신택스 기반 콘텍스트 적응 형 이진 산술 코딩(syntax-based context-adaptive binary arithmetic coding, SBAC), 확률 간격 파티셔닝 엔 트로피(probability interval partitioning entropy, PIPE) 코딩 또는 다른 엔트로피 인코딩 방법 또는 기술) 을 양자화된 잔차 계수, 인터 예측 파라미터, 인트라 예측 파라미터, 루프 필터 파라미터 및/또는 다른 신택스 엘리먼트에 적용하여 인코딩된 픽처 데이터를 획득하도록 구성될 수 있으며, 인코딩된 픽처 데이터 는 예를 들어, 인코딩된 비트스트림의 형태로 출력단을 통해 출력될 수 있으므로, 비디오 디코더 등이 디코딩을 위해 파라미터를 수신하여 사용할 수 있다. 인코딩된 비트스트림은 비디오 디코더 로 전송될 수도 있고, 비디오 디코더에 의한 나중의 전송 또는 검색을 위해 메모리에 저장될 수도 있다. 비디오 인코더의 다른 구조적 변형이 비디오 스트림을 인코딩하는 데 사용될 수 있다. 예를 들어, 비변환 기반 인코더는 일부 블록 또는 프레임에 대해 변환 처리 유닛 없이 직접 잔차 신호를 양자화할 수 있 다. 다른 구현에서, 인코더에서는 양자화 유닛 및 역양자화 유닛이 단일 유닛으로 조합될 수 있 다. 디코더 및 디코딩 방법 도 3에 도시된 바와 같이, 비디오 디코더는, 예를 들어 인코더에 의해 인코딩된 인코딩된 픽처 데이터 (예를 들어, 인코딩된 비트스트림)을 수신하여 디코딩된 픽처을 획득하도록 구성된다. 인코딩된 픽처 데이터 또는 비트스트림은 인코딩된 픽처 데이터를 디코딩하기 위한 정보, 예를 들어 인코딩된 비디오 슬 라이스(및/또는 타일 그룹 또는 타일)의 픽처 블록을 나타내는 데이터 및 연관된 신택스 엘리먼트를 포함한다. 도 3의 예에서, 디코더는 엔트로피 디코딩 유닛, 역 양자화 유닛, 역 변환 처리 유닛, 재구 성 유닛(예를 들어, 합산기), 루프 필터, 디코딩된 픽처 버퍼(decoded picture buffer, DBP), 모드 애플리케이션 유닛, 인터 예측 유닛 및 인트라 예측 유닛를 포함한다. 인터 예 측 유닛은 모션 보상 유닛이거나 이를 포함할 수 있다. 일부 예에서, 비디오 디코더는 도 2에 도시된 비디오 인코더를 참조하여 설명된 인코딩 프로세스와 일반적으로 상반되는 디코딩 프로세스를 수행할 수 있다. 인코더에 대해 설명한 바와 같이, 역 양자화 유닛, 역 변환 처리 유닛, 재구성 유닛, 루프 필터, 디코딩된 픽처 버퍼(DPB), 인터 예측 유닛 및 인트라 예측 유닛은 또한 비디오 인코 더의 \"내장 디코더\"를 형성한다. 따라서, 역 양자화 유닛은 역 양자화 유닛과 기능이 동일할 수 있고, 역 변환 처리 유닛은 역 변환 처리 유닛과 기능이 동일할 수 있으며, 재구성 유닛은 재구 성 유닛과 기능이 동일할 수 있고, 루프 필터는 루프 필터와 기능이 동일할 수 있으며, 디코딩 된 픽처 버퍼는 디코딩된 픽처 버퍼와 기능이 동일할 수 있다. 따라서, 비디오 인코더의 각 유닛 및 기능에 대해 제공된 설명은 비디오 디코더의 각 유닛 및 기능에도 대응적으로 적용될 수 있다. 엔트로피 디코딩 엔트로피 디코딩 유닛은 비트스트림(또는 일반적으로 인코딩된 픽처 데이터)을 파싱하고, 예를 들 어 인코딩된 픽처 데이터에 대해 엔트로피 디코딩을 수행하여 양자화된 계수 및/또는 디코딩된 코딩 파라미터(도 3에 도시되지 않음)를 예를 들어 인터 예측 파라미터(예를 들어 참조 픽처 인덱스 및 모션 벡터), 인트라 예측 파라미터(예를 들어 인트라 예측 모드 또는 인덱스), 변환 파라미터, 양자화 파라미터, 루프 필터 파라미터 및/또는 기타 신택스 엘리먼트 중 일부 또는 전부를 획득하도록 구성된다. 엔트로피 디코딩 유닛(30 4)은 인코더의 엔트로피 인코딩 유닛에서 설명한 인코딩 방식에 대응하는 디코딩 알고리즘 또는 방식 을 적용하도록 구성될 수 있다. 엔트로피 디코딩 유닛은 추가로, 인터 예측 파라미터, 인트라 예측 파라미 터 및/또는 기타 신택스 엘리먼트를 모드 애플리케이션 유닛에 제공하고 다른 파라미터를 디코더의 다 른 유닛에 제공하도록 구성될 수 있다. 비디오 디코더는 비디오 슬라이스 레벨 및/또는 비디오 블록 레벨에 서 신택스 엘리먼트를 수신할 수도 있다. 슬라이스 및 개개의 신택스 엘리먼트에 추가로 또는 대안으로, 타일 그룹 및/또는 타일 및 개개의 신택스 엘리먼트가 수신되거나 사용될 수 있다. 역 양자화 역 양자화 유닛은 (예를 들어, 엔트로피 디코딩 유닛에 의한 파싱 및/또는 디코딩에 의해) 인코딩된 픽처 데이터로부터 양자화 파라미터(quantization parameter, QP)(또는 역 양자화와 관련된 일반적인 정보) 및 양자화된 계수를 수신하고, 양자화 파라미터에 기반하여 디코딩된 양자화된 계수에 대해 역 양자화를 수행하여, 변환 계수라고도 지칭될 수 있는 역양자화된 계수를 획득하도록 구성된다. 역 양자화 프로 세스는 양자화 정도, 및 마찬가지로 적용되어야 하는 역양자화 정도를 결정하기 위해, 비디오 슬라이스의 각각 의 비디오 블록에 대한 비디오 인코더에 의해 결정된 양자화 파라미터의 사용을 포함할 수도 있다. 역 변환 역 변환 처리 유닛은 변환 계수라고도 지칭되는 역양자화된 계수를 수신하고, 역양자화된 계수 에 변환을 적용하여 샘플 도메인에서 재구성된 잔차 블록을 획득하도록 구성될 수 있다. 재구성된 잔 차 블록은 변환 블록이라고도 지칭될 수 있다. 변환은 역 변환, 예를 들어 역 DCT, 역 DST, 역 정수 변환, 또는 개념적으로 유사한 역 변환 프로세스일 수 있다. 역 변환 처리 유닛은 추가로, (예를 들어, 엔 트로피 디코딩 유닛에 의한 파싱 및/또는 디코딩에 의해) 인코딩된 픽처 데이터로부터 변환 파라미터 또는 대응하는 정보를 수신하여, 역양자화 계수에 적용될 변환을 결정하도록 구성될 수 있다. 재구성 재구성 유닛(예를 들어, 합산기)은 재구성된 잔차 블록을 예측 블록에 추가하여, 예를 들 어 재구성된 잔차 블록의 샘플 값 및 예측 블록의 샘플 값을 합산하는 것에 의해, 샘플 도메인에서의 재구성된 블록을 획득하도록 구성된다. 필터링 루프 필터 유닛(코딩 루프 내에서 또는 코딩 루프 이후)은 재구성된 블록을 필터링하여 필터링된 블 록을 획득하고, 픽셀 전환(pixel transition)을 스무스하게 하거나 비디오 품질을 향상시키도록 구성된다. 루프 필터 유닛은 디블로킹 필터, 샘플 적응형 오프셋(sample-adaptive offset, SAO) 필터와 같은 하나 이상의 루프 필터, 또는 하나 이상의 다른 필터, 예를 들어 적응형 루프 필터(adaptive loop filter, ALF), 노 이즈 억제 필터(noise suppression filter, NSF), 또는 이들의 임의의 조합을 포함할 수 있다. 일 예에서, 루 프 필터 유닛은 디블로킹 필터, SAO 필터, ALF 필터를 포함할 수 있다. 필터링 프로세스의 순서는 디블로 킹 필터, SAO 필터, ALF 필터 순으로 이루어질 수 있다. 또 다른 예에서, 색차 스케일링을 사용한 휘도 매핑 (luma mapping with chroma scaling, LMCS)(즉, 적응형 인루프 리쉐이퍼)이라는 프로세스가 추가된다. 이 프로 세스는 디블로킹 전에 수행된다. 다른 예에서, 디블로킹 필터 프로세스는 내부 서브 블록 에지, 예를 들어 아핀 서브 블록 에지, ATMVP 서브 블록 에지, 서브 블록 변환(sub-block transform, SBT) 에지 및 인트라 서브 파티 션(intra sub-partition, ISP) 에지에도 적용될 수 있다. 도 3에는 루프 필터 유닛이 루프 필터인 것으로 도시되었으나, 다른 구성에서 루프 필터 유닛은 포스트 루프 필터로 구현될 수도 있다. 디코딩된 픽처 버퍼 픽처의 디코딩된 비디오 블록은 디코딩된 픽처 버퍼에 저장되고, 디코딩된 픽처 버퍼는 디코딩 된 픽처를 다른 픽처에 대한 후속 모션 보상 및/또는 출력 각각의 디스플레이를 위한 참조 픽처로서 저장 한다. 디코더는 사용자에게 프리젠테이션(presentation) 또는 보기(viewing)를 위해, 디코딩된 픽처을 예를 들어 출력단을 통해 출력하도록 구성된다. 예측 인터 예측 유닛은 인터 예측 유닛(특히 모션 보상 유닛)과 기능이 동일할 수 있고, 인트라 예측 유닛 은 인터 예측 유닛과 기능이 동일할 수 있으며, (예를 들어, 엔트로피 디코딩 유닛에 의한 파싱 및/또는 디코딩에 의해) 인코딩된 픽처 데이터로부터 수신된 개개의 정보 또는 파티셔닝 및/또는 예측 파라 미터에 기반하여 분할 또는 파티셔닝 결정 그리고 예측을 수행한다. 모드 애플리케이션 유닛은 재구성된 픽처, 블록 또는 개개의 샘플(필터링된 또는 필터링되지 않은)에 기반하여 블록당 예측(인트라 예측 또는 인터 예측)을 수행하여 예측 블록을 획득하도록 구성될 수 있다. 비디오 슬라이스가 인트라 코딩된(intra coded, I) 슬라이스로 코딩될 때, 모드 애플리케이션 유닛의 인트 라 예측 유닛은 시그널링된 인트라 예측 모드 및 현재 픽처의 이전에 디코딩된 블록으로부터의 데이터에 기반하여, 현재 비디오 슬라이스의 픽처 블록에 대한 예측 블록을 생성하도록 구성된다. 비디오 픽처가 인 터 코딩된(예를 들어, B 또는 P) 슬라이스로 코딩될 때, 모드 애플리케이션 유닛의 인터 예측 유닛 (예를 들어, 모션 보상 유닛)은 엔트로피 디코딩 유닛으로부터 수신된 모션 벡터 및 기타 신택스 엘리먼트 에 기반하여 현재 비디오 슬라이스의 비디오 블록에 대한 예측 블록을 생성하도록 구성된다. 인터 예측의 경우, 참조 픽처 리스트 내의 참조 픽처로부터 예측 블록이 생성될 수 있다. 비디오 디코더는 DPB에 저장된 참조 픽처에 기반하여 디폴트 구성 기술을 사용하여 참조 프레임 리스트인 리스트 0과 리스트 1을 구성 할 수 있다. 동일하거나 유사한 프로세스가, 슬라이스(예를 들어, 비디오 슬라이스)에 대해 추가로 또는 다르게 는 타일 그룹(예를 들어, 비디오 타일 그룹) 및/또는 타일(예를 들어, 비디오 타일)을 사용하는 실시예에 대해또는 실시예에 의해 적용될 수 있으며, 예를 들어, 비디오는 I, P 또는 B 타일 그룹 및/또는 타일을 사용하여 코딩될 수 있다. 모드 애플리케이션 유닛은 모션 벡터나 기타 신택스 엘리먼트를 파싱하여 현재 비디오 슬라이스의 비디오 블록에 대한 예측 정보를 결정하고, 예측 정보를 사용하여 디코딩 중인 현재 비디오 블록에 대한 예측 블록을 생성하도록 구성된다. 예를 들어, 모드 애플리케이션 유닛은 수신된 신택스 엘리먼트 중 일부를 사용하여, 비디오 슬라이스의 비디오 블록을 코딩하는 데 사용되는 예측 모드(예를 들어 인트라 예측 또는 인터 예측), 인 터 예측 슬라이스 유형(예를 들어 B 슬라이스, P 슬라이스 또는 GPB 슬라이스), 슬라이스에 대한 참조 픽처 리 스트 중 하나 이상에 대한 구성 정보, 슬라이스의 각 인터 코딩된 비디오 블록에 대한 모션 벡터, 슬라이스의 각 인터 코딩된 비디오 블록에 대한 인터 예측 상태 및 현재 비디오 슬라이스의 비디오 블록을 디코딩하기 위한 기타 정보를 결정한다. 동일하거나 유사한 프로세스가, 슬라이스(예를 들어, 비디오 슬라이스)에 대해 추가로 또는 다르게는 타일 그룹(예를 들어, 비디오 타일 그룹) 및/또는 타일(예를 들어, 비디오 타일)을 사용하는 실 시예에 대해 또는 실시예에 의해 적용될 수 있으며, 예를 들어, 비디오는 I, P 또는 B 타일 그룹 및/또는 타일 을 사용하여 코딩될 수 있다. 일 실시예에서, 도 3의 비디오 인코더는 추가로, 슬라이스(비디오 슬라이스라고도 함)를 사용하여 픽처를 파티셔닝하거나 및/또는 디코딩하도록 구성될 수 있으며, 여기서 픽처는 하나 이상의 슬라이스(일반적으로 중첩 되지 않음)를 사용하여 파티셔닝되거나 디코딩될 수 있다. 각 슬라이스는 하나 이상의 블록(예를 들어, CTU) 또 는 하나 이상의 블록 그룹(예를 들어, H.265/HEVC/VVC 표준의 타일 및 VVC 표준의 브릭)을 포함할 수 있다. 일 실시예에서, 도 3에 도시된 비디오 디코더는 추가로, 슬라이스/타일 그룹(비디오 타일 그룹이라고도 함) 및/또는 타일(비디오 타일이라고도 함)을 사용하여 픽처를 파티셔닝하거나 및/또는 디코딩하도록 구성될 수 있 다. 픽처는 하나 이상의 슬라이스/타일 그룹(일반적으로 중첩되지 않음)을 사용하여 파티셔닝되거나 디코딩될 수 있으며, 각 슬라이스/타일 그룹은 하나 이상의 블록(예를 들어, CTU) 또는 하나 이상의 타일을 포함할 수 있 다. 각 타일은 직사각형 모양일 수 있으며 하나 이상의 블록(예를 들어, CTU), 예를 들어 완전 블록 또는 분수 블록을 포함할 수 있다. 비디오 디코더의 다른 변형이 인코딩된 픽처 데이터를 디코딩하는 데 사용될 수 있다. 예를 들어, 디코 더는 루프 필터 유닛 없이 출력 비디오 스트림을 생성할 수 있다. 예를 들어, 비변환 기반 디코더(3 0)는 일부 블록 또는 프레임에 대해 역 변환 처리 유닛 없이 직접적으로 잔차 신호를 역으로 양자화할 수 있다. 다른 구현에서, 비디오 디코더는 역 양자화 유닛 및 역 변환 처리 유닛이 단일 유닛으로 조합될 수 있다. 인코더 및 디코더에서는 현재 단계의 처리 결과가 추가로 처리되어 다음 단계로 출력될 수 있음을 이해 해야 한다. 예를 들어, 보간 필터링, 모션 벡터 도출 또는 루프 필터링 이후, 클립(clip) 또는 시프트(shift)와 같은 추가 작동이 보간 필터링, 모션 벡터 도출 또는 루프 필터링의 처리 결과에 대해 수행될 수 있다. 추가 작동이 현재 블록의 도출된 모션 벡터(아핀 모드의 제어점 모션 벡터, 아핀 모드, 평면 모드 및 ATMVP 모 드의 서브 블록 모션 벡터, 시간적 모션 벡터 등을 포함하지만 이에 제한되지 않음)에 적용될 수 있다는 점에 유의해야 한다. 예를 들어, 모션 벡터의 값은 모션 벡터의 표현 비트(representing bit)에 기반하여 미리 정의 된 범위로 제한된다. 모션 벡터의 표현 비트가 bitDepth이면, 범위는 -2^(bitDepth-1) ~ 2^(bitDepth-1)-1이며, 여기서 \"^\"는 지수를 나타낸다. 예를 들어, bitDepth가 16으로 설정되면 범위는 -32768 ~ 32767이고, bitDepth가 18로 설정되면 범위는 -131072 ~ 131071이다. 예를 들어, 도출된 모션 벡터의 값(예 를 들어, 하나의 8×8 블록에 있는 4개의 4×4 서브 블록의 MV)이, 4개의 4×4 서브 블록의 MV의 정수 부분 간 의 최대 차이가 N개의 픽셀을 초과하지 않도록, 예를 들어 하나의 픽셀을 초과하지 않도록 제한된다. bitDepth 에 기반하여 모션 벡터를 제한하는 두 가지 방법이 여기에 제공된다. 실시예는 주로 비디오 코딩에 기반하여 설명되었지만, 코딩 시스템, 인코더 및 디코더의 실시예와 본 명세서에 설명된 다른 실시예는 정지 픽처 처리 또는 코딩, 즉, 비디오 코딩의 임의의 선행하는 또는 연속하 는 픽처와 관계없이 개별 픽처를 처리하거나 코딩하는 것을 위해 구성될 수도 있다는 점에 유의해야 한다. 일반 적으로, 픽처 처리가 단일 픽처로 제한되는 경우에 인터 예측 유닛(244(인코더) 및 344(디코더))만이 이용 가능하지 않을 수 있다. 비디오 인코더와 비디오 디코더의 다른 모든 기능(도구 또는 기술이라고도 함)은 정지 픽처 처리, 예를 들어 잔차 계산(204/304), 변환, 양자화, 역 양자화(210/310), (역) 변 환(212/312), 파티셔닝(262/362), 인트라 예측(254/354), 및/또는 루프 필터링(220/320), 엔트로피 인코딩 및 엔트로피 디코딩을 위해 동일하게 사용될 수 있다.도 5는 본 출원의 실시예에 따른 비디오 코딩 디바이스의 예시적인 블록도이다. 비디오 코딩 디바이스 는 본 명세서에 설명된 바와 같은 개시된 실시예를 구현하는 데 적합하다. 일 실시예에서, 비디오 코딩 디 바이스는 도 1a의 비디오 디코더와 같은 디코더 또는 도 1a의 비디오 인코더와 같은 인코더일 수 있다. 비디오 코딩 디바이스는 데이터를 수신하기 위한 입구(ingress) 포트(또는 입력 포트) 및 수신 기 유닛(receiver unit, Rx); 데이터를 처리하기 위한 프로세서, 로직 유닛, 또는 중앙 처리 유닛 (central processing unit, CPU) - 예를 들어, 여기서 프로세서는 신경망 처리 유닛일 수 있음 -; 데이터를 전송하기 위한 송신기 유닛(transmitter unit, Tx) 및 출구(egress) 포트(또는 출력 포 트); 및 데이터를 저장하기 위한 메모리를 포함한다. 비디오 코딩 디바이스는 또한 광 또는 전 기 신호의 입구 또는 출구를 위해, 입구 포트, 수신기 유닛, 송신기 유닛, 및 출구 포트에 결합된, 광-전기(optical-to-electrical, OE) 컴포넌트 및 전기-광(electrical-to-optical, EO) 컴포넌트를 포 함할 수 있다. 프로세서는 하드웨어와 소프트웨어로 구현된다. 프로세서는 하나 이상의 프로세서 칩, 코어(예를 들 어, 멀티 코어 프로세서), FPGA, ASIC, DSP 등으로 구현될 수 있다. 프로세서는 입구 포트, 수신기 유닛, 송신기 유닛, 출구 포트 및 메모리와 통신한다. 프로세서는 코딩 모듈(예 를 들어, 신경망 기반 코딩 모듈)을 포함한다. 코딩 모듈은 위에서 설명된 개시된 실시예를 구현한다. 예를 들어, 코딩 모듈은 다양한 코딩 작동을 구현, 처리, 준비 또는 제공할 수 있다. 따라서, 코딩 모듈은 비디오 코딩 디바이스의 기능에 실질적인 개선을 제공하고 비디오 코딩 디바이스의 상이한 상태로의 전환에 영향을 준다. 다르게는, 코딩 모듈은 메모리에 저장되고 프로세서에 의 해 실행되는 명령어로서 구현된다. 메모리는 하나 이상의 디스크, 테이프 드라이브 및 솔리드 스테이트 드라이브를 포함할 수 있으며, 오버플 로 데이터 저장 디바이스로 사용되어, 프로그램이 실행을 위해 선택될 때의 프로그램을 저장하고, 프로그램 실 행 중에 판독되는 명령어 및 데이터를 저장할 수 있다. 메모리는 휘발성 및/또는 비휘발성일 수 있으며, 읽기 전용 메모리(read-only memory, ROM), 랜덤 액세스 메모리(random access memory, RAM), 터너리 콘텐츠 주소 지정 가능 메모리(ternary content-addressable memory, TCAM) 및/또는 정적 랜덤 액세스 메모리(static random-access memory, SRAM)일 수 있다. 도 6은 본 출원의 실시예에 따른 장치의 예시적인 블록도이다. 장치는 도 1a의 소스 디바이스 및 목적지 디바이스 중 하나 또는 둘 다로서 사용될 수 있다. 장치의 프로세서는 중앙 처리 유닛일 수 있다. 다르게는, 프로세서는 현재 존재하거나 향후 개 발될 정보를 조작하거나 처리할 수 있는 임의의 다른 유형의 디바이스 또는 복수의 디바이스일 수 있다. 개시된 구현은 도면에 도시된 프로세서와 같은 단일 프로세서를 사용하여 구현될 수 있지만, 하나 이상의 프로세 서를 사용함으로써 속도 및 효율성의 이점을 획득할 수 있다. 장치의 메모리는 구현에 있어서 읽기 전용 메모리(ROM) 디바이스 또는 랜덤 액세스 메모리(RAM) 디바 이스일 수 있다. 임의의 다른 적절한 유형의 저장 디바이스가 메모리로 사용될 수 있다. 메모리는 버 스를 통해 프로세서에 의해 액세스되는 코드 및 데이터를 포함할 수 있다. 메모리는 운영 체제 및 애플리케이션을 더 포함할 수 있다. 애플리케이션은 프로세서가 본 명세서에 설명 된 방법을 수행하도록 허용하는 적어도 하나의 프로그램을 포함한다. 예를 들어, 애플리케이션은 애플리케 이션 1 내지 애플리케이션 N을 포함할 수 있으며, 본 명세서에서 설명하는 방법을 수행하는 비디오 코딩 애플리 케이션을 더 포함할 수 있다. 장치는 디스플레이와 같은 하나 이상의 출력 디바이스를 더 포함할 수 있다. 디스플레이는 일 예에서 터치 입력을 감지하도록 작동 가능한 터치 감지 엘리먼트와 디스플레이를 조합한 터치 감지 디스플레이 일 수 있다. 디스플레이는 버스를 통해 프로세서에 결합될 수 있다. 본 명세서에서는 단일 버스로 도시되어 있지만, 장치의 버스는 복수의 버스를 포함할 수 있다. 또한, 보조 스토리지는 장치의 다른 컴포넌트에 직접 결합되거나 네트워크를 통해 액세스될 수 있으며, 메모리 카드와 같은 단일 통합 유닛 또는 복수의 메모리 카드와 같은 복수의 유닛을 포함할 수 있다. 따라서 장치(60 0)는 매우 다양한 구성으로 구현될 수 있다. 본 출원의 실시예는 신경망의 애플리케이션에 관한 것이다. 이해의 편의를 위해, 다음에서는 먼저 본 출원의 실 시예에서 사용되는 일부 명사 또는 용어를 설명한다. 대응하는 명사 또는 용어도 본 발명의 콘텐츠의 일부로 사 용된다. 신경망 신경망(neural network, NN)은 기계 학습 모델이다. 신경망은 뉴런을 포함할 수 있다. 뉴런은 xs와 1의 절편 (intercept)을 입력으로 사용하는 연산 유닛(operation unit)일 수 있으며, 연산 유닛의 출력은 다음과 같을 수 있다:"}
{"patent_id": "10-2024-7006856", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "s=1, 2, ... 또는 n이며, n은 1보다 큰 자연수이고, Ws는 xs의 가중치이며, b는 뉴런의 바이어스(bias)이다. f 는 뉴런의 활성화 함수(activation function)로, 신경망에 비선형 특징(non-linear feature)을 도입하여 뉴런 의 입력 신호를 출력 신호로 변환하는 데 사용된다. 활성화 함수의 출력 신호는 다음 콘볼루션 레이어의 입력으 로 사용될 수 있다. 활성화 함수는 시그모이드 함수일 수 있다. 신경망은 복수의 단일 뉴런을 연결하여 형성된 네트워크이다. 구체적으로 뉴런의 출력은 다른 뉴런의 입력이 될 수 있다. 각 뉴런의 입력은 이전 레이어의 로 컬 수용 필드(local receptive field)와 연결되어 로컬 수용 필드의 특징을 추출할 수 있다. 로컬 수용 필드는 여러 뉴런을 포함하는 영역일 수 있다. 심층 학습 신경망 심층 학습 신경망(deep neural network, DNN)은 다층 신경망(multi-layer neural network)이라고도 하며, 복수 의 은닉(hidden) 레이어를 갖는 신경망으로 이해될 수 있다. 여기서는 '복수'에 대한 특별한 측정 기준은 없다. DNN은 서로 다른 레이어의 위치(location)에 따라 나눠지며, DNN의 신경망은 입력 레이어, 은닉 레이어, 출력 레이어의 세 가지 유형으로 나뉠 수 있다. 일반적으로 첫 번째 레이어는 입력 레이어이고, 마지막 레이어는 출 력 레이어이며, 중간 레이어는 은닉 레이어이다. 레이어가 완전히 연결된다. 구체적으로 말하자면, i번째 레이 어의 임의의 뉴런은 (i+1)번째 레이어의 임의의 뉴런과 확실히 연결되어 있다. DNN은 복잡해 보이지만, 각 레이 어의 작업(work) 측면에서는 복잡하지 않다. 간단히 말하면, DNN은 다음: 선형 관계식으로 도시 되며; 는 입력 벡터이고, 는 출력 벡터이며, 는 바이어스 벡터이고, W는 가중치 행렬(계수라고도 함)이며, 는 활성화 함수이다. 각 레이어에서는 입력 벡터 에 대해 이러한 간단한 연산만 수행하여 출력 벡터 를 획득한다. DNN에는 많은 수량의 레이어가 포함되어 있기 때문에, 많은 수량의 계수 W와 많은 수량의 오프셋 벡 터 가 있다. DNN의 이러한 파라미터의 정의는 다음과 같다: 계수 W가 예로 사용된다. 3레이어 DNN에서는 2번 째 레이어의 4번째 뉴런에서 3번째 레이어의 2번째 뉴런까지의 선형 계수를 으로 정의한다고 가정한다. 위 첨자 3은 계수 W가 위치된 레이어를 나타내고, 아래 첨자는 출력 3번째-레이어 인덱스 2와 입력 2번째-레이어 인덱스 4에 대응한다. 결론적으로, (L-1)번째 레이어의 k번째 뉴런부터 L번째 레이어의 j번째 뉴런까지의 계수 를 로 정의한다. 입력 레이어에는 파라미터 W가 없다는 점에 유의해야 한다. 심층 학습 신경망에서는 은닉 레이어가 많을수록 네트워크가 현실 세계의 복잡한 사례를 더 잘 설명할 수 있다. 이론적으로 파라미터가 더 많 은 모델은 더 높은 복잡성과 더 큰 \"용량(capacity)\"을 가지며, 이는 모델이 더 복잡한 학습 태스크를 완료할 수 있음을 의미한다. 심층 학습 신경망을 트레이닝하는 것은 가중치 행렬을 학습하는 프로세스이며, 트레이닝의 최종 목표는 트레이닝된 심층 학습 신경망의 모든 레이어의 가중치 행렬(복수의 레이어에서 벡터 W로 형성된 가 중치 행렬)을 획득하는 것이다. 콘볼루션 신경망 콘볼루션 신경망(convolutional neuron network, CNN)은 콘볼루션 구조와 심층 학습(deep learning) 아키텍처 를 갖춘 심층 학습 신경망이다. 심층 학습 아키텍처에서는 기계 학습 알고리즘에 따라 서로 다른 추상 (abstract) 레벨에서 다층 학습(multi-layer learning)이 수행된다. 심층 학습 아키텍처로서 CNN은 피드포워드 (feed-forward) 인공 신경망이다. 피드포워드 인공 신경망의 각 뉴런은 신경망에 입력된 픽처에 응답할 수 있다. 콘볼루션 신경망은 콘볼루션 레이어와 풀링 레이어를 통합하는 특징 추출기를 포함한다. 특징 추출기는 필터로 간주될 수 있다. 콘볼루션 프로세스는 트레이닝 가능한 필터를 사용하여, 입력 픽처 또는 콘볼루션 특징맵(feature map)에 대해 콘볼루션을 수행하는 것으로 간주할 수 있다. 콘볼루션 레이어는 콘볼루션 신경망에 존재하는 뉴런 레이어이면서 또한 콘볼루션 처리가 입력 신호에 대해 수 행되는 뉴런 레이어이다. 콘볼루션 레이어는 복수의 콘볼루션 연산자(operator)를 포함할 수 있다. 콘볼루션 연 산자는 커널(kernel)이라고도 한다. 픽처 처리에서, 콘볼루션 연산자는 입력 픽처 행렬로부터 특정 정보를 추출 하는 필터로서 기능한다. 콘볼루션 연산자는 본질적으로 가중치 행렬일 수 있으며, 가중치 행렬은 일반적으로 미리 정의된다. 픽처에 대해 콘볼루션 연산을 수행하는 프로세스에서, 일반적으로 가중치 행렬은 입력 픽처에 대한 가로 방향으로 하나의 픽셀(또는 스트라이드(stride) 값에 따라 2개의 픽셀)의 그래뉼래러티(granularit y)로 픽셀을 처리하여 픽처로부터 특정 특징을 추출하는 데 사용된다. 가중치 행렬의 크기는 픽처의 크기와 관 련이 있어야 한다. 가중치 행렬의 깊이 차원(depth dimension)은 입력 픽처의 깊이 차원과 동일하다는 점에 유 의해야 한다. 콘볼루션 연산 동안에 가중치 행렬은 입력 픽처의 전체 깊이로 확장된다. 따라서 단일 가중치 행 렬을 이용한 콘볼루션을 통해 단일 깊이 차원의 콘볼루션 출력이 생성된다. 그러나 대부분의 경우, 단일 가중치 행렬을 사용하지 않지만 동일한 크기(행×열)의 복수의 가중치 행렬, 즉 동일한 유형의 복수의 행렬이 적용된다. 가중치 행렬의 출력은 누적되어 콘볼루션 픽처의 깊이 차원을 형성한다. 여기에서 차원은 전술한 \"복 수성\"에 기반하여 결정되는 것으로 이해될 수 있다. 픽처로부터 서로 다른 특징을 추출하기 위해 서로 다른 가 중치 행렬이 사용될 수 있다. 예를 들어, 하나의 가중치 행렬은 픽처의 에지 정보를 추출하는 데 사용되고, 다 른 가중치 행렬은 픽처의 특정 색상을 추출하는 데 사용되며, 추가 가중치 행렬은 픽처에서 불필요한 노이즈를 흐리게(blur) 하는 데 사용된다. 복수의 가중치 행렬(행×열)의 크기는 동일하다. 동일한 크기를 갖는 복수의 가중치 행렬로부터 추출된 특징 맵의 크기도 동일하며, 추출된 동일한 크기의 복수의 특징 맵을 조합하여 콘볼 루션 연산의 출력을 형성한다. 이러한 가중치 행렬의 가중치 값은 실제 애플리케이션시 대규모 트레이닝을 통해 획득되어야 한다. 트레이닝을 통해 획득된 가중치 값을 포함하는 각 가중치 행렬을 사용하여 입력 픽처로부터 정보를 추출함으로써, 콘볼루션 신경망이 정확한(correct) 예측을 수행할 수 있다. 콘볼루션 신경망이 복수의 콘볼루션 레이어를 가질 때, 일반적으로 초기 콘볼루션 레이어에서 많은 수량의 일반 특징이 추출된다. 일반 특 징은 하위 레벨 특징(low-level feature)이라고도 한다. 콘볼루션 신경망의 깊이가 깊어질수록, 후속 콘볼루션 레이어에서 추출되는 특징은 더 복잡해지며, 예를 들어 상위 레벨 의미론적 특징(high-level semantic featur e)이다. 더 높은 레벨 의미가 있는 특징은 해결해야 할 문제에 더 적합하다. 일반적으로 트레이닝 파라미터의 수량을 줄여야 하기 때문에, 일반적으로 풀링 레이어는 콘볼루션 레이어 이후 에 주기적으로 도입되어야 한다. 하나의 콘볼루션 레이어 뒤에 하나의 풀링 레이어가 올 수도 있고, 복수의 콘 볼루션 레이어 뒤에 하나 이상의 풀링 레이어가 올 수도 있다. 픽처 처리 중에 풀링 레이어는 픽처의 공간 크기 를 줄이는 데만 사용된다. 풀링 레이어는 평균 풀링 연산자 및/또는 최대 풀링 연산자를 포함하여, 입력 픽처에 대해 샘플링을 수행하여 작은 크기의 픽처를 획득할 수 있다. 평균 풀링 연산자는 특정 범위의 픽처에서 픽셀 값을 계산하여 평균 값을 생성하는 데 사용될 수 있다. 평균값은 평균 풀링의 결과로 사용된다. 최대값 풀링 연 산자는 특정 범위 내에서 최대값을 갖는 픽셀을 최대값 풀링 결과로 선택하는 데 사용될 수 있다. 또한 콘볼루 션 레이어의 가중치 행렬의 크기가 픽처의 크기와 관련되어야 하는 것과 유사하게, 풀링 레이어의 연산자도 픽 처의 크기와 관련이 있어야 한다. 풀링 레이어로부터 출력되는 처리된 픽처의 크기는 풀링 레이어로 입력되는 픽처의 크기보다 작을 수 있다. 풀링 레이어로부터 출력되는 픽처의 각 픽셀은 풀링 레이어에 입력된 픽처의 대 응하는 서브 영역의 평균값 또는 최대값을 나타낸다. 콘볼루션 레이어/풀링 레이어에서 처리가 수행된 후에도 콘볼루션 신경망은 여전히 필요한 출력 정보를 출력할 수 없다. 위에서 설명한 바와 같이, 콘볼루션 레이어/풀링 레이어는 특징만 추출하고 입력 픽처에서 가져온 파 라미터를 줄인다. 그러나 최종 출력 정보(필요한(required) 클래스 정보 또는 기타 관련 정보)를 생성하려면 콘 볼루션 신경망은 신경망 레이어를 사용하여 하나의 필요한 클래스 출력 또는 필요한 클래스 그룹의 출력을 생성 해야 한다. 따라서 신경망 레이어는 복수의 은닉 레이어를 포함할 수 있다. 복수의 은닉 레이어에 포함된 파라 미터는 특정 태스크 유형의 관련 트레이닝 데이터에 기반한 사전 트레이닝을 통해 획득될 수 있다. 예를 들어, 태스크 유형에는 픽처 인식, 픽처 분류, 초해상도(super-resolution) 픽처 재구성 등이 포함될 수 있다. 선택적으로, 신경망 레이어에서는 복수의 은닉 레이어 뒤에 전체 콘볼루션 신경망의 출력 레이어가 온다. 출력 레이어에는 범주형 교차 엔트로피(categorical cross entropy)와 유사한 손실 함수가 있으며, 손실 함수는 구체 적으로 예측 에러를 계산하는 데 사용된다. 전체 콘볼루션 신경망의 순방향 전파가 완료되면 위에서 언급한 각 레이어의 가중치와 편차를 업데이트하기 위해 역전파를 시작하여, 콘볼루션 신경망의 손실과 출력 레이어를 사 용하는 콘볼루션 신경망에 의해 출력되는 결과와 이상적인 결과 간의 에러를 감소시킨다. 순환 신경망 순환 신경망(recurrent neural network, RNN)은 시퀀스 데이터를 처리하는 데 사용된다. 기존 신경망 모델은 입 력 레이어에서 시작하여 은닉 레이어, 출력 레이어로 이어지며, 레이어들은 완전 연결되어 있고, 각 레이어의 노드는 연결되어 있지 않다. 이러한 일반적인 신경망은 복수의 문제를 해결하지만, 여전히 복수의 문제를 처리 할 능력이 없다. 예를 들어, 문장의 단어를 예측하려면, 일반적으로 문장의 인접한 단어들이 관련되어 있기 때 문에, 이전 단어를 사용해야 한다. RNN을 순환 신경망이라고 부르는 이유는 시퀀스의 현재 출력이 시퀀스의 이 전 출력과도 관련되어 있기 때문이다. 구체적인 표현 형태는 네트워크가 이전 정보를 기억하고 이전 정보를 현 재 출력의 계산에 적용하는 것이다. 구체적으로 은닉 레이어의 노드들은 연결되어 있으며, 은닉 레이어의 입력 에는 입력 레이어의 출력뿐만 아니라 이전 순간(moment)의 은닉 레이어의 출력도 포함된다. 이론적으로 RNN은 임의의 길이의 시퀀스 데이터를 처리할 수 있다. RNN의 트레이닝은 기존 CNN이나 DNN의 트레이닝과 동일하다. 에러 역전파(error back propagation) 알고리즘도 사용되지만 차이점이 있다: RNN을 확장하면 RNN의 W와 같은 파라미터를 공유한다는 점이다. 이는 앞선 예에서 설명한 기존의 신경망과 상이하다. 또한, 경사하강법 알고리 즘을 사용하는 동안, 각 단계의 출력은 현재 단계의 네트워크뿐만 아니라 이전 여러 단계의 네트워크 상태에도 영향을 받는다. 학습 알고리즘을 시간에 따른 역전파(Back propagation Through Time, BPTT) 알고리즘이라고 한다. 콘볼루션 신경망을 사용할 수 있는데 왜 순환 신경망이 여전히 필요한가요? 이유는 간단하다. 콘볼루션 신경망 에는 엘리먼트가 서로 독립적이며, 고양이와 개와 같이 입력과 출력도 독립적이라는 전제가 있다. 그러나 현실 세계에서는 복수의 엘리먼트가 상호 연결되어 있다. 예를 들어, 주식은 시간에 따라 변한다. 또 다른 예를 들면, 어떤 사람이 \"나는 여행을 좋아하며, 가장 좋아하는 곳은 운남성이다. 앞으로 기회가 되면(__)에 가보겠 다\". 여기서 사람들은 그 사람이 \"운남성\"에 갈 것이라는 것을 알아야 한다. 사람들은 콘텍스트로부터 추론을 수행하기 때문이다. 그런데 기계는 어떻게 그렇게 합니까? 그런 다음 RNN이 나타난다. RNN은 기계가 인간처럼 기억할 수 있도록 만들기 위한 것이다. 따라서 RNN의 출력은 현재 입력 정보와 과거에 기억된 정보에 의존해야 한다. 손실 함수 심층 학습 신경망을 트레이닝하는 프로세스에서, 심층 학습 신경망의 출력이 실제로 예상되는(expected) 예측자 에 최대한 근접할 것으로 예상되기 때문에, 현재 네트워크의 예측자는 실제로 예상되는 타깃값(target value)과 비교될 수 있으며, 그리고 예측값(predicted value)과 타깃값의 차이에 기반하여 신경망 각 레이어의 가중치 벡 터를 업데이트한다(물론 일반적으로 제1 업데이트 전에 초기화 프로세스를 거치는데, 구체적으로는 파라미터는 심층 학습 신경망의 각 레이어에 대해 사전 구성됨). 예를 들어, 네트워크의 예측자가 크면, 가중치 벡터를 조 정하여 예측값을 낮추고, 심층 학습 신경망이 실제로 예상되는 타깃값이나 실제로 예상되는 타깃값에 매우 가까 운 값을 예측할 수 있을 때까지 계속해서 조정을 수행한다. 따라서 \"비교를 통해 예측자와 타깃값의 차이를 어 떻게 구하는지\"를 미리 정의할 필요가 있다. 이는 손실 함수(loss function) 또는 목적 함수(objective function)이다. 손실 함수와 목적 함수는 예측자와 타깃값의 차이를 측정하는 데 사용되는 중요한 수식이다. 손 실 함수가 예로 사용된다. 손실 함수의 출력값(손실)이 클수록 차이가 크다는 것을 지시한다. 따라서 심층 학습 신경망의 트레이닝은 손실을 최대한 최소화하는 프로세스이다. 역전파 알고리즘 콘볼루션 신경망은 초해상도 모델의 재구성 에러 손실이 작아지도록, 에러 역전파(back propagation, BP) 알고 리즘에 따라 트레이닝 프로세스에서 초기 초해상도 모델의 파라미터 값을 보정할 수 있다. 구체적으로, 출력에 서 에러 손실이 발생할 때까지 입력 신호를 순방향으로 전달하고, 역전파 에러 손실 정보에 기반하여 초기 초해 상도 모델의 파라미터를 업데이트하여 에러 손실이 수렴되도록 한다. 역전파 알고리즘은 초해상도 모델의 가중 치 행렬과 같은 최적의 파라미터를 획득하기 위한 에러 손실 중심의 역전파 모션이다. 생성적 대립 네트워크 생성적 대립 네트워크(generative adversarial network, GAN)는 심층 학습 모델이다. 모델에는 적어도 2개의 모듈이 포함된다: 하나의 모듈은 생성적 모델(Generative Model)이고 다른 모듈은 판별 모델(Discriminative Model)이다. 2개의 모듈은 더 나은 결과를 생성하기 위해 서로 게임(gaming)을 통해 학습하는 데 사용된다. 생 성적 모델과 판별 모델 모두 신경망일 수 있으며, 구체적으로 심층 학습 신경망 또는 콘볼루션 신경망일 수 있 다. GAN의 기본 원리는 다음과 같다: 픽처를 생성하는 GAN을 예로 사용한다. G(Generator)와 D(Discriminator)의 두 가지 네트워크가 있다고 가정한다. G는 픽처를 생성하기 위한 네트워크이다. G는 랜덤 노이즈 z를 수신 하고 노이즈에 기반하여 픽처를 생성하며. 픽처는 G(z)로 표시된다. D는 픽처가 \"진짜(real)\"인지를 결정하는 데 사용되는 판별기 네트워크이다. D의 입력 파라미터는 x이고, x는 픽처를 나타내고, 출력 D(x)는 x가 진짜 픽 처일 확률을 나타낸다. D(x)의 값이 1이면, 픽처가 100% 진짜라는 것을 지시한다. D(x)의 값이 0이면, 픽처가 진짜일 수 없음을 지시한다. 생성적 대립 네트워크를 트레이닝하는 프로세스에서, 생성적 네트워크 G의 목적은 판별 네트워크 D를 속이기 위해 최대한 진짜와 같은 픽처를 생성하는 것이고, 판별 네트워크 D의 목적은 최대한 많이, G에 의해 생성된 픽처와 진짜 픽처를 최대한 구별하는 것이다. 이러한 방식으로 동적 \"게임\" 프로세스, 구체적으로 \"생성적 대립 네트워크\"의 \"대립자(adversary)\"가 G와 D 사이에 존재한다. 최종 게임 결과는 이상적 인 상태에서 G가 진짜 픽처와 구별하기 어려운 픽처 G(z)를 생성할 수 있으며, D는 G가 생성한 픽처가 진짜인지 를 판정하기 어려우며, 구체적으로 D(G(z))=0.5이다. 이러한 방식으로, 우수한 생성적 모델 G가 획득되며 이를 사용하여 픽처를 생성할 수 있다. 도 7a는 본 출원의 실시예에 따른 애플리케이션 시나리오의 개략도이다. 도 7a에 도시된 바와 같이, 애플리케이 션 시나리오에서 디바이스는 데이터를 획득하고, 획득한 데이터를 압축한 후, 압축된 데이터를 저장한다. 디바 이스는 전술한 소스 디바이스와 목적지 디바이스의 기능을 통합할 수 있다. 1. 디바이스가 데이터를 획득한다. 2. 디바이스가 데이터를 압축하여 압축된 데이터를 획득한다. 3. 디바이스가 압축된 데이터를 저장한다. 디바이스는 저장 공간을 절약하기 위해 데이터를 압축한다는 점을 이해해야 한다. 선택적으로, 디바이스는 압축 된 데이터를 앨범이나 클라우드 앨범에 저장할 수 있다. 4. 디바이스가 압축된 데이터의 압축을 해제하여 데이터를 획득한다. 도 7b는 본 출원의 실시예에 따른 애플리케이션 시나리오의 개략도이다. 도 7b에 도시된 바와 같이, 애플리케이 션 시나리오에서, 소스 디바이스는 데이터를 획득하고, 획득된 데이터를 압축하여 압축된 데이터를 획득한 후, 압축된 데이터를 목적지 디바이스로 송신한다. 본 출원의 실시예에서, 소스 디바이스는 획득된 데이터를 압축한 후 압축된 데이터를 목적지 디바이스로 전송할 수 있다. 이는 전송 대역폭을 감소시킬 수 있다. 1. 소스 디바이스가 데이터를 획득한다. 2. 소스 디바이스가 데이터를 압축하여 압축된 데이터를 획득한다. 3. 소스 디바이스가 압축된 데이터를 목적지 디바이스로 송신한다. 소스 디바이스는 데이터를 압축한 후 데이터를 전송한다. 이는 전송 대역폭을 줄이고 전송 효율을 향상시킬 수 있다. 4. 목적지 디바이스가 압축된 데이터의 압축을 해제하여 데이터를 획득한다. 도 8은 본 출원의 실시예에 따른 인코딩 및 디코딩 방법의 흐름도이다. 인코딩 및 디코딩 방법은 인 코더 및 디코더에 의해 수행될 수 있다. 인코딩 및 디코딩 방법은 일련의 단계 또는 작동으로 설명된다. 인코딩 및 디코딩 방법은 다양한 시퀀스로 및/또는 동시에 수행될 수 있으며, 도 8에 도시된 실행 시퀀스 로 제한되지 않는다는 것이 이해되어야 한다. 도 8에 도시된 바와 같이, 인코딩 및 디코딩 방법은 다음과 같은 단계를 포함할 수 있다. 단계 801: 인코더가 인코딩 대상 데이터를 획득한다. 예를 들어, 인코더는 인코딩 대상 데이터 x를 획득한다. 단계 802: 인코더가 인코딩 대상 데이터를 제1 인코딩 네트워크에 입력하여 타깃 파라미터를 획득한다. 타깃 파라미터는 제2 인코딩 네트워크의 전체 또는 부분 콘볼루션 및 비선형 활성화를 위한 파라미터 가중치일 수 있다. 선택적으로, 제1 인코딩 네트워크는 콘볼루션 커널 생성기(콘볼루션 그룹 또는 완전 연결 그룹)를 포함할 수 있 다. 콘볼루션 커널 생성기는 인코딩 대상 데이터에 기반하여 타깃 파라미터를 생성하도록 구성된다.예를 들어, 인코더는 인코딩 대상 데이터 x를 제1 인코딩 네트워크에 입력하여 타깃 파라미터 를 획득한다. 단계 803: 인코더는 타깃 파라미터에 기반하여 제2 인코딩 네트워크를 구성한다. 예를 들어, 인코더는 타깃 파라미터 에 기반하여 제2 인코딩 네트워크 를 구성한다. 단계 804: 인코더가 인코딩 대상 데이터를 제2 인코딩 네트워크에 입력하여 제1 특징을 획득한다. 제1 특징은 인코딩 대상 데이터를 재구성하는데 사용되며, 제1 특징은 콘텐츠 특징이라고도 지칭될 수 있다. 예 를 들어, 제1 특징은 인코딩 대상 데이터 x의 3차원 특징 맵일 수 있다. 예를 들어, 인코더는 인코딩 대상 데이터 x를 제2 인코딩 네트워크 에 입력하여 제1 특징 y를 획득한다. y는 를 충족한다. 단계 805: 인코더가 제1 특징을 인코딩하여 인코딩된 비트스트림(즉, 디코딩 대상 비트스트림)을 획득한다. 가능한 구현에서, 인코더가 제1 특징을 인코딩하여 인코딩된 비트스트림을 획득하는 것은 다음을 포함할 수 있 다: 인코더는 먼저 제1 특징을 반올림하여 제1 특징의 정수 값을 획득된 다음, 제1 특징의 정수 값에 대해 확률 추정을 수행하여 제1 특징의 정수 값의 추정된 확률 분포를 획득하고, 다음으로, 제1 특징의 정수 값의 추정된 확률 분포에 기반하여 제1 특징의 정수 값에 대해 엔트로피 인코딩을 수행하여 인코딩된 비트스트림을 획득한다. 제1 특징의 정수 값은 제1 값 특징 또는 콘텐츠 반올림 특징으로 지칭될 수 있다. 예를 들어, 인코더는 먼저 제1 특징 y를 반올림하여 제1 특징의 정수 값 를 획득한다. 이후 인코더는 제1 특징 의 정수 값 에 대해 확률 추정을 수행하여 제1 특징의 정수 값에 대한 추정된 확률 분포 를 획득한다. 다 음으로, 인코더는 제1 특징의 정수 값의 추정된 확률 분포 에 기반하여 제1 특징의 정수 값 에 대해 엔트 로피 인코딩을 수행하여 인코딩된 비트스트림을 획득한다."}
{"patent_id": "10-2024-7006856", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "는 를 충족하고, round는 반올림이다. 는 를 충족하고, 는 엔트로피 추정 네트워크이다. 선택적으로, 인코더가 제1 특징의 정수 값에 대해 확률 추정을 수행하여 제1 특징의 정수 값의 추정된 확률 분 포를 획득하는 것은 다음을 포함할 수 있다: 인코더가 제1 정보에 기반하여 제1 특징의 정수 값에 대해 확률 추 정을 수행하여 제1 특징의 정수 값에 대한 추정된 확률 분포를 획득한다. 제1 정보는 콘텍스트 정보 및 부가 정 보 중 적어도 하나를 포함한다. 여기서, 콘텍스트 정보와 부가 정보에 기반하여 확률 분포를 추정함으로써, 획득된 추정된 확률 분포의 정확도 를 높일 수 있다는 점에 유의해야 한다. 이는 엔트로피 인코딩 프로세스에서 비트 레이트를 줄이고 엔트로피 인 코딩 오버헤드를 줄인다. 단계 806: 인코더가 인코딩된 비트스트림을 디코더에 송신한다. 단계 807: 디코더가 인코딩된 비트스트림을 디코딩하여 제1 특징의 정수 값을 획득한다. 가능한 구현에서, 디코더가 인코딩된 비트스트림을 디코딩하여 제1 특징의 정수 값을 획득하는 것은 다음을 포 함할 수 있다: 디코더는 먼저 인코딩된 비트스트림에서의 제1 특징의 정수 값에 대해 확률 추정을 수행하여 제1 특징의 정수 값의 추정된 확률 분포를 획득하고, 그리고, 제1 특징의 정수 값의 추정된 확률 분포에 기반하여 인코딩된 비트스트림에 대해 엔트로피 디코딩을 수행하여 제1 특징의 정수 값을 획득한다. 단계 808: 디코더가 제1 특징의 정수 값을 디코딩 네트워크에 입력하여 디코딩된 데이터를 획득한다. 예를 들어, 디코더는 제1 특징의 정수 값 를 디코딩 네트워크 에 입력하여 디코딩된 데이터 를 획득 한다. 여기서 디코딩된 데이터 는 를 충족하며, 는 인코딩 네트워크의 콘볼루션 및 비선형 활성 화를 위한 파라미터 가중치의 전부 또는 일부이다.기존 인코딩 방식에서는 인코딩 네트워크(즉, 제2 인코딩 네트워크)가 고정된 파라미터 가중치에 기반하여 인코 딩 대상 데이터의 콘텐츠 특징(즉, 제1 특징)을 추출한 후, 대응하는 콘텐츠 특징을 비트스트림(즉, 인코딩된 비트스트림)으로 인코딩하고 대응하는 비트스트림을 디코더 측으로 송신한다. 디코더 측은 비트스트림에 대한 디코딩 및 재구성을 수행하여 디코딩된 데이터를 획득한다. 종래 기술에서는 인코딩 네트워크의 파라미터 가중 치가 인코딩 대상 데이터와 관련이 없음을 알 수 있다. 그러나, 본 출원의 실시예에서 제공하는 인코딩 방법에 서는, 인코딩 대상 데이터가 먼저 제1 인코딩 네트워크에 입력되고, 제1 인코딩 네트워크는 인코딩 대상 데이터 에 기반하여 제2 인코딩 네트워크의 파라미터 가중치를 생성하며, 그 후, 획득된 가중치에 기반하여 제2 인코딩 네트워크의 파라미터 가중치가 동적으로 조정됨으로써, 제2 인코딩 네트워크의 파라미터 가중치가 인코딩 대상 데이터에 관련되고, 제2 인코딩 네트워크의 표현 능력이 증가되며, 제1 특징을 인코딩하는 것에 의해 획득된 비 트스트림에 대한 디코딩 및 재구성을 통해 디코더 측에서 획득된 디코딩된 데이터가 인코딩 대상 데이터에 더 가까워진다. 이는 인코딩 및 디코딩 네트워크의 레이트 왜곡 성능을 향상시킨다. 본 출원의 실시예에서 제공되는 인코딩 및 디코딩 방법은 도 9에 도시된 인코딩 및 디코딩 시스템에 적용 가능하다. 도 9에 도시된 바와 같이, 인코딩 및 디코딩 시스템은 제1 인코딩 네트워크, 제2 인코딩 네트워 크, 반올림 모듈, 엔트로피 추정 네트워크, 엔트로피 인코딩 모듈, 엔트로피 디코딩 모듈 및 디코딩 네트워크를 포함한다. 도 9에 도시된 바와 같이, 인코딩 대상 데이터가 먼저 제1 인코딩 네트워크에 입력되어 타깃 파라미터를 획득한 후, 제2 인코딩 네트워크의 파라미터가 타깃 파라미터에 기반하여 조정된다(즉, 제2 인코딩 네트워 크의 콘볼루션 및 비선형 활성화를 위한 파라미터 가중치의 전부 또는 일부가 타깃 파라미터에 기반하여 조정된다). 인코딩 대상 데이터가 제2 인코딩 네트워크에 입력되어 제1 특징을 획득한다. 반올림 모듈은 제1 특징을 반올림하여 제1 특징의 정수 값을 획득한다. 엔트로피 추정 네트워크는 제1 특징의 정수 값에 대해 확률 추정을 수행하여 제1 특징의 정수 값의 추정된 확률 분포를 획득한다. 엔트로피 인코딩 모듈은 제1 특징의 정수 값의 추정된 확률 분포에 기반하여 제1 특징의 정수 값에 대해 엔트로피 인코딩을 수행하여 인코딩된 비트스트림을 획득한다. 엔트로피 디코딩 모듈은 제1 특징의 정수 값의 추정된 확률 분포에 기반하여 인코딩된 비트스트림에 대해 엔트로피 디코딩을 수행하여 제1 특징의 정수 값을 획득한다. 제1 특징의 정수 값을 디코딩 네트워크에 입력하여 디코딩된 데이터를 획득한다. 도 10은 본 출원의 실시예에 따른 인코딩 및 디코딩 방법의 흐름도이다. 인코딩 및 디코딩 방법은 인코더 및 디코더에 의해 수행될 수 있다. 인코딩 및 디코딩 방법은 일련의 단계 또는 작동으로 설명된다. 인코딩 및 디코딩 방법은 다양한 시퀀스로 및/또는 동시에 수행될 수 있으며, 도 10에 도시된 실행 시퀀스로 제한되지 않는다는 것이 이해되어야 한다. 도 10에 도시된 바와 같이, 인코딩 및 디코딩 방법 은 다음과 같은 단계를 포함할 수 있다. 단계 1001: 인코더가 인코딩 대상 데이터를 획득한다. 단계 1002: 인코더가 인코딩 대상 데이터를 제2 인코딩 네트워크에 입력하여 제1 특징을 획득한다. 제1 특징은 인코딩 대상 데이터를 재구성하는 데 사용된다. 단계 1003: 인코더가 인코딩 대상 데이터를 제1 인코딩 네트워크에 입력하여 제2 특징을 획득한다. 제2 특징은 타깃 파라미터를 재구성하는데 사용되며, 제2 특징은 모델 특징이라고도 지칭될 수 있으며, 타깃 파 라미터는 제2 디코딩 네트워크의 콘볼루션 및 비선형 활성화를 위한 파라미터 가중치의 전부 또는 일부이다. 가능한 구현에서, 인코더는 먼저 제1 특징을 채널 차원에서 2개의 부분(제1 서브 특징 및 제2 서브 특징)으로 나눌 수 있다. 한 부분은 인코딩 대상 데이터(제1 서브 특징)를 재구성하는 데 사용되며, 다른 부분은 타깃 파 라미터(제2 서브 특징)를 재구성하는 데 사용된다. 그런 다음 인코더는 제2 서브 특징을 제1 인코딩 네트워크에 입력하여 제2 특징을 획득한다. 선택적으로, 제2 특징이 작은 비트스트림으로 압축될 수 있도록 하기 위해, 제2 서브 특징이 제3 인코딩 네트워 크에 입력되기 전에, 제2 서브 특징은 콘볼루션 네트워크 및 완전 연결 네트워크를 통해 추가로 변환될 수 있다. 변환 전의 제2 서브 특성을 초기 모델 특징이라 하고, 변환을 통해 획득된 제2 서브 특성을 모델 특징이 라 할 수 있다. 단계 1004: 인코더가 제1 특징을 인코딩하여 제1 디코딩 대상 비트스트림을 획득한다. 단계 1005: 인코더가 제2 특징을 인코딩하여 제2 디코딩 대상 비트스트림을 획득한다. 가능한 구현에서, 인코더는 디코딩 대상 비트스트림을 획득하기 위해 제1 특징 및 제2 특징을 인코딩할 수 있다. 단계 1006: 인코더가 제1 디코딩 대상 비트스트림 및 제2 디코딩 대상 비트스트림을 디코더에 송신한다. 단계 1007: 디코더가 제1 디코딩 대상 비트스트림을 디코딩하여 제1 특징의 정수 값을 획득한다. 가능한 구현에서, 디코더가 제1 디코딩 대상 비트스트림을 디코딩하여 제1 특징의 정수 값을 획득하는 것은 다 음을 포함할 수 있다: 디코더는 제1 디코딩 대상 비트스트림에서의 제1 특징의 정수 값에 대해 확률 추정을 수 행하여 제1 특징의 정수 값의 추정된 확률 분포를 획득하고, 제1 특징의 정수 값의 추정된 확률 분포에 기반하 여 디코딩 대상 비트스트림에 대해 엔트로피 디코딩을 수행하여 제1 특징의 정수 값을 획득한다. 가능한 구현에서, 제1 디코딩 대상 비트스트림에서의 제1 특징의 정수 값에 대해 확률 추정을 수행하여 제1 특 징의 정수 값의 추정된 확률 분포를 획득하는 것은: 제1 정보에 기반하여 제1 디코딩 대상 비트스트림에서의 제 1 특징의 정수 값에 대해 확률 추정을 수행하여 제1 특징의 정수 값의 추정된 확률 분포를 획득하는 것 - 제1 정보는 콘텍스트 정보 및 부가 정보 중 적어도 하나를 포함함 -을 포함한다. 단계 1008: 디코더가 제2 디코딩 대상 비트스트림을 디코딩하여 제2 특징의 정수 값을 획득한다. 제2 특징의 정수 값은 모델 반올림 특징이라고도 지칭될 수 있다. 가능한 구현에서, 디코더가 제2 디코딩 대상 비트스트림을 디코딩하여 제2 특징의 정수 값을 획득하는 것은 다 음을 포함한다: 디코더는 제2 디코딩 대상 비트스트림에서의 제2 특징의 정수 값에 대해 확률 추정을 수행하여 제2 특징의 정수 값의 추정된 확률 분포를 획득하고, 제2 특징의 정수 값의 추정된 확률 분포에 기반하여 제2 디코딩 대상 비트스트림에 대해 엔트로피 디코딩을 수행하여 제2 특징의 정수 값을 획득한다. 가능한 구현에서, 제2 디코딩 대상 비트스트림에서의 제2 특징의 정수 값에 대해 확률 추정을 수행하여 제2 특 징의 정수 값의 추정된 확률 분포를 획득하는 것은: 제1 정보에 기반하여 제2 디코딩 대상 비트스트림에서의 제 2 특징의 정수 값에 대해 확률 추정을 수행하여 제2 특징의 정수 값의 추정된 확률 분포를 획득하는 것 - 제1 정보는 콘텍스트 정보 및 부가 정보 중 적어도 하나를 포함함 -을 포함한다. 단계 1009: 디코더가 제2 특징의 정수 값을 제1 디코딩 네트워크에 입력하여 타깃 파라미터를 획득한다. 단계 1010: 디코더가 타깃 파라미터에 기반하여 제2 디코딩 네트워크를 구성한다. 단계 1011: 디코더가 제1 특징의 정수 값을 제2 디코딩 네트워크에 입력하여 디코딩된 데이터를 획득한다. 기존의 디코딩 방법에서는 디코딩 네트워크(즉, 제2 디코딩 네트워크)가 고정된 파라미터 가중치에 기반하여 인 코딩 대상 데이터의 콘텐츠 값 특징(즉, 제1 특징의 정수 값)에 대한 디코딩 및 재구성을 수행하여 디코딩된 데 이터를 획득한다. 종래 기술에서는 디코딩 네트워크의 파라미터 가중치가 디코딩 대상 데이터와 관련이 없음을 알 수 있다. 그러나 본 출원의 실시예에서는 디코딩 대상 데이터의 콘텐츠 특징 및 모델 특징(즉, 제1 특징 및 제2 특징)이 디코딩 대상 비트스트림으로 인코딩되며, 그런 다음 디코더 측이 디코딩 대상 비트스트림을 디코딩 하여 제2 특징의 정수 값을 획득하고, 제2 특징의 정수 값이 제1 디코딩 네트워크에 입력되어 제2 디코딩 네트 워크의 파라미터 가중치를 획득한 다음, 제2 디코딩 네트워크의 파라미터 가중치가 파라미터 가중치에 기반하여 동적으로 조정됨으로써, 제2 디코딩 네트워크의 파라미터 가중치가 디코딩 대상 데이터와 관련되고, 제2 디코딩 네트워크의 표현 능력이 향상되며, 디코딩 및 재구성을 통해 제2 디코딩 네트워크에 의해 획득된 디코딩된 데이 터가 인코딩 대상 데이터에 더 가까워진다. 이는 인코딩 및 디코딩 네트워크의 레이트 왜곡 성능을 향상시킨다. 본 출원의 실시예에서 제공되는 인코딩 및 디코딩 방법은 도 11에 도시된 인코딩 및 디코딩 시스템에 적 용 가능하다. 도 11에 도시된 바와 같이, 인코딩 및 디코딩 시스템은 제1 인코딩 네트워크, 제2 인코딩 네트워크, 제1 반올림 모듈, 제2 반올림 모듈, 엔트로피 추정 네트워크, 제1 엔트로피 인코딩 모듈, 제2 엔트로피 인코딩 모듈, 제1 엔트로피 디코딩 모듈, 제2 엔트로피 디코딩모듈, 제1 디코딩 네트워크 및 제2 디코딩 네트워크를 포함한다. 도 11에 도시된 바와 같이, 인코딩 대상 데이터가 제2 인코딩 네트워크에 먼저 입력되어 제1 특징을 획득 하고, 그러 다음 인코딩 대상 데이터가 제1 인코딩 네트워크에 입력되어 제2 특징을 획득한다. 제1 반올림 모듈은 제1 특징을 반올림하여 제1 특징의 정수 값을 획득한다. 제2 반올림 모듈은 제2 특징을 반올림하여 제2 특징의 정수 값을 획득한다. 엔트로피 추정 네트워크는 먼저 제1 특징의 정수 값에 대해 확률 추정을 수행하여 제1 특징의 정수 값의 추정된 확률 분포를 획득하고, 그런 다음 제2 특징의 정수 값에 대해 확률 추정을 수행하여 제2 특성의 정수 값 의 추정된 확률 분포를 획득한다. 제1 엔트로피 인코딩 모듈은 제1 특징의 정수 값의 추정된 확률 분포에 기반하여 제1 특징의 정수 값에 대해 엔트로피 인코딩을 수행하여 제1 디코딩 대상 비트스트림을 획득한다. 제2 엔트로피 인코딩 모듈은 제2 특징의 정수 값의 추정된 확률 분포에 기반하여 제2 특징의 정수 값에 대해 엔트로피 인코딩을 수행하여 제2 디코딩 대상 비트스트림을 획득한다. 제1 엔트로피 디코딩 모듈은 제1 특징의 정수 값의 추정된 확률 분포에 기반하여 제1 디코딩 대상 비트스 트림에 대해 엔트로피 디코딩을 수행하여 제1 특징의 정수 값을 획득한다. 제2 엔트로피 디코딩 모듈은 제2 특징의 정수 값의 추정된 확률 분포에 기반하여 제2 디코딩 대상 비트스 트림에 대해 엔트로피 디코딩을 수행하여 제2 특징의 정수 값을 획득한다. 제2 특징의 정수 값이 제1 디코딩 네트워크에 먼저 입력되어 타깃 파라미터를 획득한 후, 제2 디코딩 네 트워크의 파라미터는 타깃 파라미터에 기반하여 조정된다(즉, 제2 디코딩 네트워크의 콘볼루션 및 비선형 활성화를 위한 파라미터 가중치의 전부 또는 일부는 타깃 파라미터에 기반하여 조정된다). 제1 특징의 정수 값이 제2 디코딩 네트워크에 입력되어 디코딩된 데이터를 획득한다. 본 출원의 실시예에서 제공되는 인코딩 및 디코딩 방법은 도 12에 도시된 인코딩 및 디코딩 시스템에도 적용 가능하다. 도 12에 도시된 바와 같이, 인코딩 및 디코딩 시스템은 제1 인코딩 네트워크, 제2 인코딩 네트워크, 채널 분할(channel division) 모듈, 제1 반올림 모듈, 제2 반올림 모듈, 엔트로피 추정 네트워크, 제1 엔트로피 인코딩 모듈, 제2 엔트로피 인코딩 모듈, 제1 엔트로 피 디코딩 모듈, 제2 엔트로피 디코딩 모듈, 제1 디코딩 네트워크 및 제2 디코딩 네트워크 를 포함한다. 도 12에 도시된 바와 같이, 인코딩 대상 데이터가 먼저 제2 인코딩 네트워크에 입력되어 제1 특징을 획득 한다. 제1 특징은 채널 분할 모듈에 입력되어 채널 차원에서 제1 서브 특징과 제2 서브 특징으로 분할된다. 제2 서브 특징이 제1 인코딩 네트워크에 입력되어 제2 특징을 획득한다. 제1 반올림 모듈은 제1 서브 특징을 반올림하여 제1 특징의 정수 값을 획득한다. 제2 반올림 모듈은 제2 특징을 반올림하여 제2 특징의 정수 값을 획득한다. 엔트로피 추정 네트워크는 먼저 제1 특징의 정수 값에 대해 확률 추정을 수행하여 제1 특징의 정수 값의 확률 분포를 추정하고, 그런 다음 제2 특징의 정수 값에 대해 확률 추정을 수행하여 제2 특성의 정수 값의 추정 된 확률 분포를 획득한다. 제1 엔트로피 인코딩 모듈은 제1 특징의 정수 값의 추정된 확률 분포에 기반하여 제1 특징의 정수 값에 대해 엔트로피 인코딩을 수행하여 제1 디코딩 대상 비트스트림을 획득한다. 제2 엔트로피 인코딩 모듈은 제2 특징의 정수 값의 추정된 확률 분포에 기반하여 제2 특징의 정수 값에 대해 엔트로피 인코딩을 수행하여 제2 디코딩 대상 비트스트림을 획득한다. 제1 엔트로피 디코딩 모듈은 제1 특징의 정수 값의 추정된 확률 분포에 기반하여 제1 디코딩 대상 비트스 트림에 대해 엔트로피 디코딩을 수행하여 제1 특징의 정수 값을 획득한다. 제2 엔트로피 디코딩 모듈은 제2 특징의 정수 값의 추정된 확률 분포에 기반하여 제2 디코딩 대상 비트스 트림에 대해 엔트로피 디코딩을 수행하여 제2 특징의 정수 값을 획득한다. 제2 특징의 정수 값이 제1 디코딩 네트워크에 먼저 입력되어 타깃 파라미터를 획득한 후, 제2 디코딩 네 트워크의 파라미터는 타깃 파라미터에 기반하여 조정된다(즉, 제2 디코딩 네트워크의 콘볼루션 및 비선형 활성화를 위한 파라미터 가중치의 전부 또는 일부는 타깃 파라미터에 기반하여 조정된다). 제1 특징의 정수 값이 제2 디코딩 네트워크에 입력되어 디코딩된 데이터를 획득한다. 도 13은 본 출원의 실시예에 따른 인코딩 및 디코딩 방법의 흐름도이다. 인코딩 및 디코딩 방법은 인코더 및 디코더에 의해 수행될 수 있다. 인코딩 및 디코딩 방법은 일련의 단계 또는 작동으로 설명된다. 인코딩 및 디코딩 방법은 다양한 시퀀스로 및/또는 동시에 수행될 수 있으며, 도 13에 도시된 실행 시퀀스에 제한되지 않는다는 것이 이해되어야 한다. 도 13에 도시된 바와 같이, 인코딩 및 디코딩 방법 은 다음과 같은 단계를 포함할 수 있다. 단계 1301: 인코더가 인코딩 대상 데이터를 획득한다. 단계 1302: 인코더가 인코딩 대상 데이터를 인코딩 네트워크에 입력하여 제1 특징을 획득한다. 단계 1303: 인코더가 제1 특징을 인코딩하여 디코딩 대상 비트스트림을 획득한다. 단계 1304: 인코더가 디코딩 대상 비트스트림을 디코더에 송신한다. 단계 1305: 디코더가 디코딩 대상 비트스트림을 디코딩하여 제1 특징의 정수 값을 획득한다. 가능한 구현에서, 디코더가 디코딩 대상 비트스트림을 디코딩하여 제1 특징의 정수 값을 획득하는 것은 다음을 포함할 수 있다: 디코더는 디코딩 대상 비트스트림에서의 제1 특징의 정수 값에 대해 확률 추정을 수행하여 제1 특징의 정수 값의 추정된 확률 분포를 획득하고, 제1 특징의 정수 값의 추정된 확률 분포에 기반하여 디코딩 대 상 비트스트림에 대해 엔트로피 디코딩을 수행하여 제1 특징의 정수 값을 획득한다. 가능한 구현에서, 디코딩 대상 비트스트림에서의 제1 특징의 정수 값에 대해 확률 추정을 수행하여 제1 특징의 정수 값의 추정된 확률 분포를 획득하는 것은: 제1 정보에 기반하여 디코딩 대상 비트스트림에서의 제1 특징의 정수 값에 대해 확률 추정을 수행하여 제1 특징의 정수 값의 추정된 확률 분포를 획득하는 것 - 제1 정보는 콘 텍스트 정보 및 부가 정보 중 적어도 하나를 포함함 -을 포함한다. 단계 1306: 디코더가 제1 특징의 정수 값을 제1 디코딩 네트워크에 입력하여 타깃 파라미터를 획득한다. 선택적으로, 제1 디코딩 네트워크는 콘볼루션 커널 생성기(콘볼루션 그룹 또는 완전 연결 그룹)를 포함할 수 있 다. 콘볼루션 커널 생성기는 인코딩 대상 데이터의 제1 특징의 정수 값에 기반하여 타깃 파라미터를 생성하도록 구성된다. 단계 1307: 디코더가 타깃 파라미터에 기반하여 제2 디코딩 네트워크를 구성한다. 단계 1308: 디코더가 제1 특징의 정수 값을 제2 디코딩 네트워크에 입력하여 디코딩된 데이터를 획득한다. 기존의 디코딩 방법에서는 디코딩 네트워크(즉, 제2 디코딩 네트워크)가 고정된 파라미터 가중치에 기반하여 인 코딩 대상 데이터의 콘텐츠 값 특징(즉, 제1 특징의 정수 값)에 대해 디코딩 및 재구성을 수행하여 디코딩된 데 이터를 획득한다. 종래 기술에서는 디코딩 네트워크의 파라미터 가중치가 디코딩 대상 데이터와 관련이 없음을 알 수 있다. 그러나 본 출원의 실시예에서는 디코딩 대상 데이터의 특징(즉, 제1 특징)을 인코딩하는 것에 의해 획득된 디코딩 대상 비트스트림을 디코딩하여 제1 특징의 정수 값을 획득하고, 제1 특징의 정수 값이 제1 디코 딩 네트워크에 입력되어 제2 디코딩 네트워크의 파라미터 가중치를 획득한 후, 제2 디코딩 네트워크의 파라미터 가중치가 파라미터 가중치에 기반하여 동적으로 조정됨으로써, 제2 디코딩 네트워크의 파라미터 가중치가 디코 딩 대상 데이터와 관련되며, 제2 디코딩 네트워크의 표현 능력이 향상되고, 제2 디코딩 네트워크가 디코딩 및 재구성을 통해 획득한 디코딩 데이터가 인코딩 대상 데이터에 더 가까워진다. 이는 인코딩 및 디코딩 네트워크 의 레이트 왜곡 성능을 향상시킨다. 본 출원의 실시예에서 제공되는 인코딩 및 디코딩 방법은 도 14에 도시된 인코딩 및 디코딩 시스템에 적 용 가능하다. 도 14에 도시된 바와 같이, 인코딩 및 디코딩 시스템은 인코딩 네트워크, 반올림 모듈 , 엔트로피 추정 네트워크, 엔트로피 인코딩 모듈, 엔트로피 디코딩 모듈, 제1 디코딩 네트워크 및 제2 디코딩 네트워크를 포함한다. 도 14에 도시된 바와 같이, 인코딩 대상 데이터가 먼저 인코딩 네트워크에 입력되어 제1 특징을 획득한다. 반올림 모듈은 제1 특징을 반올림하여 제1 특징의 정수 값을 획득한다. 엔트로피 추정 네트워크는 제1 특징의 정수 값에 대해 확률 추정을 수행하여 제1 특징의 정수 값의 추정 된 확률 분포를 획득한다. 엔트로피 인코딩 모듈은 제1 특징의 정수 값의 추정된 확률 분포에 기반하여 제1 특징의 정수 값에 대해 엔트로피 인코딩을 수행하여 디코딩 대상 비트스트림을 획득한다. 엔트로피 디코딩 모듈은 제1 특징의 정수 값의 추정된 확률 분포에 기반하여 디코딩 대상 비트스트림에 대해 엔트로피 디코딩을 수행하여 제1 특징의 정수 값을 획득한다. 제1 특징의 정수 값이 제1 디코딩 네트워크에 입력되어 타깃 파라미터를 획득하고, 제2 디코딩 네트워크 의 파라미터는 타깃 파라미터에 기반하여 조정된다(즉, 제2 디코딩 네트워크의 콘볼루션 및 비선형 활성화를 위한 파라미터 가중치의 전부 또는 일부 타깃 파라미터에 기반하여 조정된다). 제1 특징의 정수 값이 제2 디코딩 네트워크에 입력되어 디코딩된 데이터를 획득한다. 도 15는 본 출원의 실시예에 따른 인코딩 및 디코딩 방법의 성능의 개략도이다. 도 15의 좌표계는 본 출원의 실 시예와 기존 기술을 사용하고 피크 신호 대 노이즈 비(Peak Signal-to-Noise Ratio, PSNR) 지시자에 기반하여 테스트 세트를 개별적으로 인코딩 및 디코딩하는 성능을 도시한다. 테스트 세트는 코닥(Kodak) 테스트 세트이다. 코닥 테스트 세트에는 휴대용 네트워크 그래픽(Portable Network Graphics, PNG) 포맷의 픽처 24장이 포함되어 있다. 24개의 픽처의 해상도는 768×512 또는 512×768일 수 있다. 도 15의 좌표계에서, 수평 좌표는 비트 레이트(bits per pixel, BPP)를 지시하고, 수직 좌표는 PSNR을 지시한다. BPP는 각 픽셀을 저장하는 데 사 용되는 비트의 수량을 지시한다. 값이 작을수록 압축 비트 레이트가 낮다는 것을 지시한다. PSNR은 픽처를 평가 하기 위한 객관적인 표준이다. PSNR이 높을수록 픽처 품질이 좋아짐을 지시한다. 도 15에 도시된 좌표계의 선분(line segment) A는 본 출원의 실시예를 나타내고, 선분 B는 기존 기술을 나타낸 다. 도 15로부터, BPP 지시자가 동일할 때, 본 출원의 실시예에서의 PSNR 지시자는 기존 기술의 PSNR 지시자 보 다 모두 크고, 픽처 압축 품질(즉, PSNR 지시자)이 동일할 때, 본 출원의 실시예에서의 BPP 지시자는 기존 기술 의 BPP 지시자보다 모두 적음을 알 수 있다. 본 출원의 실시예의 레이트 왜곡 성능이 기존 기술의 레이트 왜곡 성능이 더 높고, 본 출원의 실시예에서는 데이터 인코딩 및 디코딩 방법의 레이트 왜곡 성능을 향상시킬 수 있 음을 알 수 있다. 본 출원의 실시예에서 제공하는 인코딩 및 디코딩 방법이 적용될 수 있는 시나리오는 전자 디바이스에서 픽처, 비디오, 음성 등의 데이터를 캡처, 저장, 전송하는 것에 관련된 서비스, 클라우드 서비스, 비디오 감시(예를 들 어, 전자 디바이스의 촬영 및 비디오 또는 오디오 서비스, 앨범, 클라우드 앨범, 비디오 감시, 화상 회의, 모델 압축)를 포함하지만 이에 제한되지는 않는다. 도 16은 본 출원의 실시예에 따른 애플리케이션 시나리오의 개략도이다. 도 16에 도시된 바와 같이, 애플리케이 션 시나리오에서는 전자 디바이스가 촬영을 통해 픽처 데이터(압축 대상 데이터)를 획득된 후, 촬영을 통해 획 득된 픽처 데이터(예를 들어, RAW 포맷, YUV 포맷, RGB 포맷의 픽처 데이터)를 전자 디바이스의 AI 인코딩 유닛 에 입력한다. 전자 디바이스의 AI 인코딩 유닛은 제1 인코딩 네트워크, 제2 인코딩 네트워크 및 엔트로피 추정 네트워크를 호출하여 픽처 데이터를 중복성이 낮은 출력 특징으로 변환하고, 출력 특징의 추정된 확률 분포를 생성한다. 전자 디바이스의 산술 인코딩 유닛은 엔트로피 인코딩 모듈을 호출하여, 출력 특징의 추정된 확률 분 포에 기반하여 출력 특징을 데이터 파일로 인코딩한다. 파일 저장 유닛은 엔트로피 인코딩 모듈에 의해 생성된 데이터 파일을 전자 디바이스의 대응하는 저장 위치에 저장한다. 전자 디바이스가 데이터 파일을 사용해야 할 때, 파일 로딩 유닛은 전자 디바이스의 대응하는 저장 위치로부터 데이터 파일을 로딩하며, 데이터 파일은 산술 디코딩 유닛에 입력된다. 산술 디코딩 유닛은 엔트로피 디코딩 모듈을 호출하여, 데이터 파일을 디코딩하여 출 력 특징을 획득하며, 출력 특징은 AI 디코딩 유닛에 입력된다. AI 디코딩 유닛은 제1 디코딩 네트워크, 제2 디 코딩 네트워크 및 제3 디코딩 네트워크를 호출하여, 출력 특징에 대해 역 변환을 수행하고 출력 특징을 픽처 데 이터(예를 들어, RGB 픽처 데이터), 즉 압축된 데이터로 파싱한다. AI 인코딩 유닛 및 AI 디코딩 유닛은 전자 디바이스의 신경망 처리 유닛(neural network processing unit, NPU) 또는 그래픽 처리 유닛(graphics processing unit, GPU)에 배치될 수 있다. 산술 인코딩 유닛, 파일 저장 유닛, 파일 로딩 유닛, 산술 디코딩 유 닛은 전자 디바이스의 CPU에 배치될 수 있다.도 17은 본 출원의 실시예에 따른 또 다른 애플리케이션 시나리오의 개략도이다. 도 17에 도시된 바와 같이, 애 플리케이션 시나리오에서는 전자 디바이스가 바로 업로드하거나 클라우드(예를 들어, 서버)에 업로드하기 전에 저장된 픽처 데이터(압축 대상 데이터)를 인코딩(예를 들어, JPEG 인코딩)한다. 클라우드는 수신된 픽처 데이터 를 바로 입력하거나 클라우드의 AI 인코딩 유닛에 입력하기 전에 수신된 픽처 데이터를 디코딩(예를 들어, JPEG 디코딩)한다. 클라우드의 AI 인코딩 유닛은 제1 인코딩 네트워크, 제2 인코딩 네트워크 및 엔트로피 추정 네트 워크를 호출하여, 픽처 데이터를 중복성이 낮은 출력 특징으로 변환하고 출력 특징의 추정된 확률 분포를 생성 한다. 클라우드의 산술 인코딩 유닛은 엔트로피 인코딩 모듈을 호출하여, 출력 특징의 추정된 확률 분포에 기반 하여 출력 특징을 데이터 파일로 인코딩한다. 파일 저장 유닛은 엔트로피 인코딩 모듈에 의해 생성된 데이터 파 일을 클라우드의 대응하는 저장 위치에 저장한다. 전자 디바이스가 데이터 파일을 사용해야 할 때, 다운로드 요 청을 클라우드에 송신한다. 클라우드가 다운로드 요청을 수신한 후, 파일 로딩 유닛은 클라우드의 대응하는 저 장 위치로부터 데이터 파일을 로딩하고, 데이터 파일은 산술 디코딩 유닛에 입력된다. 산술 디코딩 유닛은 엔트 로피 디코딩 모듈을 호출하여, 데이터 파일을 디코딩하여 출력 특징을 획득하며, 출력 특징은 AI 디코딩 유닛에 입력된다. AI 디코딩 유닛은 제1 디코딩 네트워크, 제2 디코딩 네트워크 및 제3 디코딩 네트워크를 호출하여, 출력 특징에 대한 역 변환을 수행하고 출력 특징을 픽처 데이터로 파싱한다. 클라우드는 픽처 데이터(압축된 데 이터)를 바로 송신하거나 전자 디바이스에 송신하기 전에 픽처 데이터를 인코딩한다. 다음은 도 18 및 도 19를 참조하여, 전술한 인코딩 및 디코딩 방법을 수행하도록 구성된 인코딩 및 디코딩 장치 를 설명한다. 전술한 기능을 구현하기 위해, 인코딩 및 디코딩 장치는 각 기능을 수행하는 대응하는 하드웨어 및/또는 소프트 웨어 모듈을 포함하는 것으로 이해될 수 있다. 본 명세서에 개시된 실시예에 설명된 각 예의 알고리즘 단계를 참조하면, 본 출원은 하드웨어 또는 하드웨어와 컴퓨터 소프트웨어의 조합 형태로 구현될 수 있다. 기능이 하드 웨어 또는 컴퓨터 소프트웨어로 구동되는 하드웨어에 의해 수행되는 지는 기술 솔루션의 특정 애플리케이션과 설계 제약에 따라 달라진다. 당업자는 실시예를 참조하여 각각의 특정 애플리케이션에 대해 설명된 기능을 구현 하기 위해 다양한 방법을 사용할 수 있지만, 구현이 본 출원의 범위를 벗어나는 것으로 간주되어서는 안 된다. 본 출원의 실시예에서, 인코딩 및 디코딩 장치는 전술한 방법 예시에 기반하여 기능 모듈로 분할될 수 있다. 예 를 들어, 각 기능 모듈은 각각의 대응하는 기능에 기반한 분할을 통해 획득될 수도 있고, 2개 이상의 기능이 하 나의 처리 모듈에 통합될 수도 있다. 전술한 통합 모듈은 하드웨어 형태로 구현될 수 있다. 본 실시예에서, 모 듈로의 분할은 예시일 뿐이고, 단지 논리적인 기능 분할일 뿐이며, 실제 구현 중에 다른 분할일 수 있다는 점에 유의해야 한다. 각각의 기능 모듈을 각각의 대응하는 기능에 기반한 분할을 통해 획득할 때, 도 18은 전술한 실시예의 인코딩 및 디코딩 장치의 구성에 대한 가능한 개략도이다. 도 18에 도시된 바와 같이, 장치는 트랜시버 유닛 및 처리 유닛을 포함할 수 있다. 처리 유닛은 전술한 방법 실시예의 인코딩 장치, 디코딩 장치, 인코더 또는 디코더에 의해 수행되는 방법 및/또는 본 명세서에서 설명되는 기술의 다른 프로세스를 구현 할 수 있다. 전술한 방법 실시예의 단계와 관련된 모든 내용은 대응하는 기능 모듈의 기능 설명에서 인용될 수 있다는 점에 유의해야 한다. 자세한 내용은 여기서 다시 설명하지 않는다. 통합 유닛이 사용될 때, 장치는 처리 유닛, 저장 유닛 및 통신 유닛을 포함할 수 있다. 처리 유닛은 장치 의 작동을 제어하고 관리하도록 구성될 수 있으며, 예를 들어 전술한 유닛들에 의해 수행되는 단계들을 수행함에 있어서 장치를 지원하도록 구성될 수 있다. 저장 유닛은 프로그램 코드, 데이터 및/또는 유사한 것을 저장하는 데 있어서 장치를 지원하도록 구성될 수 있다. 통신 유닛은 장치와 다른 디바이스 간의 통신을 지원하도록 구성될 수 있다. 처리 유닛은 프로세서 또는 컨트롤러일 수 있다. 프로세서는 본 출원에 개시된 내용을 참조하여 설명된 다양한 예시적인 로직 블록, 모듈 및 회로를 구현하거나 실행할 수 있다. 프로세서는 다르게는 컴퓨팅 기능을 구현하기 위한 조합, 예를 들어, 하나 이상의 마이크로프로세서를 포함하는 조합, 디지털 신호 프로세서(digital signal processing, DSP)와 마이크로프로세서의 조합일 수도 있다. 저장 유닛은 메모리일 수 있다. 통신 유닛은 구체적 으로 다른 전자 디바이스와 상호작용하는 디바이스, 예를 들어 무선 주파수 회로, 블루투스 칩, Wi-Fi 칩 등일 수 있다. 가능한 구현에서, 본 출원의 실시예에서의 인코딩 및 디코딩 장치는 도 19에 도시된 구조를 갖는 장치일 수 있다. 장치는 프로세서 및 트랜시버를 포함한다. 도 18의 트랜시버 유닛 및 처리 유닛에 의해 구현되는 관련 기능이 프로세서에 의해 구현될 수 있다. 선택적으로, 장치는 메모리를 더 포함할 수 있다. 프로세서와 메모리는 내부 연결 경 로를 통해 서로 통신한다. 도 18의 저장 유닛에 의해 구현되는 관련 기능은 메모리에 의해 구현될 수 있 다. 본 출원의 실시예는 컴퓨터 저장 매체를 더 제공한다. 컴퓨터 저장 매체는 컴퓨터 명령어를 저장한다. 컴퓨터 명령어가 전자 디바이스에서 실행될 때, 전자 디바이스는 전술한 관련 방법 단계를 수행하여 전술한 실시예의 인코딩 및 디코딩 방법을 구현하도록 이네이블(enable)된다. 본 출원의 실시예는 컴퓨터 프로그램 제품을 더 제공한다. 컴퓨터 프로그램 제품이 컴퓨터에서 실행될 때, 컴퓨 터는 전술한 관련 단계를 수행하여 전술한 실시예의 인코딩 및 디코딩 방법을 구현하도록 이네이블된다. 본 출원의 실시예는 인코딩 및 디코딩 장치를 더 제공한다. 장치는 구체적으로 칩, 집적 회로, 컴포넌트 또는 모듈일 수 있다. 구체적으로, 장치는 연결된 프로세서 및 명령어를 저장하도록 구성된 메모리를 포함할 수 있거 나, 장치는 외부 메모리로부터 명령어를 획득하도록 구성된 적어도 하나의 프로세서를 포함할 수 있다. 장치가 실행될 때, 프로세서는 명령어를 실행함으로써, 칩이 전술한 방법 실시예의 인코딩 및 디코딩 방법을 수행한다. 도 20은 칩의 구조의 개략도이다. 칩은 하나 이상의 프로세서 및 인터페이스 회로를 포함한다. 선택적으로, 칩은 버스를 더 포함할 수 있다. 프로세서는 집적 회로 칩일 수 있고, 신호 처리 능력을 갖는다. 구현 프로세스에서, 전술한 인코딩 방법 의 각 단계는 프로세서에 있는 하드웨어의 집적 로직 회로를 사용하거나 소프트웨어 형태의 명령어를 사 용하여 완료될 수 있다. 프로세서는 범용 프로세서, 디지털 신호 프로세서(digital signal processing, DSP), 주문형 집적 회로 (application-specific integrated circuit, ASIC), 필드 프로그래밍 가능한 게이트 어레이(field- programmable gate array, FPGA) 또는 다른 프로그래밍 가능 로직 디바이스, 이산 게이트 또는 트랜지스터 로직 디바이스 또는 이산 하드웨어 컴포넌트일 수 있다. 프로세서는 본 출원의 실시예에 개시된 방법 및 단계를 구현 하거나 수행할 수 있다. 범용 프로세서는 마이크로프로세서일 수도 있고, 프로세서는 임의의 기존 프로세서 등 일 수도 있다. 인터페이스 회로는 데이터, 명령어, 또는 정보를 송신하거나 수신할 수 있다. 프로세서는 인터페이 스 회로를 통해 수신된 데이터, 명령어, 기타 정보를 처리하고, 처리를 통해 획득된 정보를 인터페이스 회로를 통해 송신할 수 있다. 선택적으로, 칩은 메모리를 더 포함한다. 메모리는 읽기 전용 메모리와 랜덤 액세스 메모리를 포함할 수 있으며, 작동 명령어 및 데이터를 프로세서에 제공할 수 있다. 메모리의 일부는 비휘발성 랜덤 액세스 메모리 (non-volatile random access memory, NVRAM)를 더 포함할 수 있다. 선택적으로, 메모리는 실행 가능한 소프트웨어 모듈 또는 데이터 구조를 저장하고, 프로세서는 메모리에 저장된 작동 명령어(작동 명령어는 운영 체제에 저장될 수 있음)를 호출하여 대응하는 작동을 수행할 수 있다. 선택적으로, 칩은 본 출원의 실시예에서 전자 디바이스 또는 DOP에 사용될 수 있다. 선택적으로, 인터페이스 회 로는 프로세서의 실행 결과를 출력하도록 구성될 수 있다. 본 출원의 하나 이상의 실시예에서 제공 되는 인코딩 방법에 대해서는 앞선 실시예를 참조한다. 자세한 내용은 여기서 다시 설명하지 않는다. 프로세서 및 인터페이스 회로 각각에 대응되는 기능은 하드웨어 설계로 구현될 수도 있고, 소프트 웨어 설계로 구현될 수도 있으며, 소프트웨어와 하드웨어의 조합으로 구현될 수도 있다. 이는 여기에 제한되지 않는다. 실시예에 제공된 전자 디바이스, 컴퓨터 저장 매체, 컴퓨터 프로그램 제품 또는 칩은 위에 제공된 대응하는 방 법을 수행하도록 구성된다. 따라서 획득할 수 있는 유익한 효과에 대해서는 위에 제공된 대응하는 방법의 유익 한 효과를 참조한다. 자세한 내용은 여기서 다시 설명하지 않는다. 전술한 프로세스의 시퀀스 번호는 본 출원의 실시예에서 실행 시퀀스를 의미하지 않는다는 것을 이해해야 한다. 프로세스의 실행 시퀀스는 프로세스의 기능 및 내부 로직에 따라 결정되어야 하며, 본 출원의 실시예의 구현 프 로세스에 대한 어떠한 제한도 구성해서는 안 된다.당업자는 본 명세서에 개시된 실시예에 설명된 예와 조합하여, 유닛 및 알고리즘 단계가 전자 하드웨어 또는 컴 퓨터 소프트웨어와 전자 하드웨어의 조합에 의해 구현될 수 있다는 것을 인식할 수 있다. 기능이 하드웨어로 수 행되는지 아니면 소프트웨어로 수행되는지는 기술 솔루션의 특정 애플리케이션과 설계 제약에 따라 달라진다. 당업자는 각각의 특정 애플리케이션에 대해 설명된 기능을 구현하기 위해 서로 다른 방법을 사용할 수 있지만, 구현이 본 출원의 범위를 벗어나는 것으로 간주되어서는 안 된다. 기술의 용이성과 간결함을 위해, 전술한 시스템, 장치 및 유닛의 상세한 워킹(working) 프로세스에 대해 전술한 방법 실시예의 대응하는 프로세스를 참조한다는 것이 당업자에 의해 명확하게 이해될 수 있다. 자세한 내용은 여기서 다시 설명하지 않는다. 본 출원에 제공된 여러 실시예에서, 개시된 시스템, 장치 및 방법은 다른 방식으로 구현될 수 있다는 것이 이해 되어야 한다. 예를 들어, 설명된 장치 실시예는 단지 예일 뿐이다. 예를 들어, 유닛으로 분할하는 것은 단지 논 리적인 기능 분할일 뿐이며, 실제 구현 시에는 다른 분할이 될 수도 있다. 예를 들어, 복수의 유닛이나 컴포넌 트가 다른 시스템에 조합되거나 통합될 수 있거나, 일부 기능이 무시되거나 수행되지 않을 수 있다. 또한, 디스 플레이되거나 논의된 상호 결합이나 직접 결합 또는 통신 연결은 일부 인터페이스를 통해 구현될 수 있다. 장치 또는 유닛 사이의 간접 결합 또는 통신 연결은 전기적, 기계적 또는 기타 형태로 구현될 수 있다. 전술한 별도의 부분으로 설명된 유닛들은 물리적으로 분리되어 있을 수도 있고 아닐 수도 있고, 유닛으로 디스 플레이된 부분들은 물리적인 유닛일 수도 있고 아닐 수도 있으며, 한 위치에 위치될 수도 있고, 복수의 네트워 크 유닛으로 분산되어 있을 수도 있다. 유닛 중 일부 또는 전부는 실시예의 솔루션의 목적을 달성하기 위해 실 제 요건에 기반하여 선택될 수 있다. 또한, 본 출원의 실시예에서의 기능 유닛은 하나의 처리 유닛으로 통합될 수도 있고, 각 유닛이 물리적으로 단 독으로 존재할 수도 있고, 2개 이상의 유닛이 하나의 유닛으로 통합될 수도 있다. 그 기능이 소프트웨어 기능 유닛의 형태로 구현되어 독립된 제품으로 판매되거나 사용될 때, 그 기능은 컴퓨터 가 판독 가능한 저장 매체에 저장될 수 있다. 이러한 이해에 기반하여, 본 출원의 기술 솔루션은 본질적으로 또 는 기존 기술에 기여하는 부분, 기술 솔루션의 전부 또는 일부가 소프트웨어 제품의 형태로 구현될 수 있다. 컴 퓨터 소프트웨어 제품은 저장 매체에 저장되며, 컴퓨터 디바이스(개인용 컴퓨터, 서버, 네트워크 디바이스 등일 수 있음)가 본 출원의 실시예에 설명된 방법에서 전술한 단계 중 전부 또는 일부를 수행하도록 명령하기 위한 여러 명령어를 포함한다. 저장 매체에는 USB 플래시 드라이브, 착탈식 하드 디스크, 읽기 전용 메모리(Read- Only Memory, ROM), 랜덤 액세스 메모리(Random Access Memory, RAM), 자기 디스크 또는 콤팩트 디스크와 같은, 프로그램 코드를 저장할 수 있는 임의의 매체가 포함된다. 앞의 설명은 단지 본 출원의 특정 구현일 뿐이며 본 출원의 보호 범위를 제한하려는 의도는 없다. 본 출원에 개 시된 기술적 범위 내에서 당업자가 쉽게 알아낼 수 있는 모든 변형 또는 교체는 본 출원의 보호 범위에 속한다. 따라서 본 출원의 보호 범위는 청구 범위의 보호 범위에 따른다.도면 도면1a 도면1b 도면2 도면3 도면4 도면5 도면6 도면7a 도면7b 도면8 도면9 도면10 도면11 도면12 도면13 도면14 도면15 도면16 도면17 도면18 도면19 도면20"}
{"patent_id": "10-2024-7006856", "section": "도면", "subsection": "도면설명", "item": 1, "content": "본 출원 실시예의 기술 솔루션을 보다 명확하게 설명하기 위해, 이하에서는 실시예를 설명하기 위한 첨부 도면 을 간략하게 설명한다. 다음 설명의 첨부 도면은 단지 본 출원의 일부 실시예를 도시할 뿐이며, 당업자는 창의 적인 노력 없이도 이러한 첨부 도면으로부터 다른 도면을 도출할 수 있다는 것이 분명하다.도 1a는 본 출원의 실시예에 따른 코딩 시스템의 예시적인 블록도이다. 도 1b는 본 출원의 실시예에 따른 비디오 코딩 시스템의 예시적인 블록도이다. 도 2는 본 출원의 실시예에 따른 비디오 인코더의 예시적인 블록도이다. 도 3은 본 출원의 실시예에 따른 비디오 디코더의 예시적인 블록도이다. 도 4는 본 출원의 실시예에 따른 후보 픽처 블록의 예에 대한 개략도이다. 도 5는 본 출원의 실시예에 따른 비디오 코딩 디바이스의 예시적인 블록도이다. 도 6은 본 출원의 실시예에 따른 장치의 예시적인 블록도이다. 도 7a는 본 출원의 실시예에 따른 애플리케이션 시나리오의 개략도이다. 도 7b는 본 출원의 실시예에 따른 애플리케이션 시나리오의 개략도이다. 도 8은 본 출원의 실시예에 따른 인코딩 및 디코딩 방법의 개략적인 흐름도이다. 도 9는 본 출원의 실시예에 따른 인코딩 및 디코딩 시스템의 구조의 개략도이다. 도 10은 본 출원의 실시예에 따른 다른 인코딩 및 디코딩 방법의 개략적인 흐름도이다. 도 11은 본 출원의 실시예에 따른 다른 인코딩 및 디코딩 시스템의 구조의 개략도이다. 도 12는 본 출원의 실시예에 따른 또 다른 인코딩 및 디코딩 시스템의 구조의 개략도이다. 도 13은 본 출원의 실시예에 따른 또 다른 인코딩 및 디코딩 방법의 개략적인 흐름도이다. 도 14는 본 출원의 실시예에 따른 또 다른 인코딩 및 디코딩 시스템의 구조의 개략도이다. 도 15는 본 출원의 실시예에 따른 인코딩 및 디코딩 방법의 성능의 개략도이다. 도 16은 본 출원의 실시예에 따른 애플리케이션 시나리오의 개략도이다. 도 17은 본 출원의 실시예에 따른 또 다른 애플리케이션 시나리오의 개략도이다. 도 18은 본 출원의 실시예에 따른 인코딩 및 디코딩 장치의 구조의 개략도이다. 도 19는 본 출원의 실시예에 따른 다른 인코딩 및 디코딩 장치의 구조의 개략도이다. 도 20은 본 출원의 실시예에 따른 칩의 구조의 개략도이다."}
