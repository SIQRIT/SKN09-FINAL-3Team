{"patent_id": "10-2024-0007745", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0033689", "출원번호": "10-2024-0007745", "발명의 명칭": "인공 신경망 기반 해상도 향상 방법, 프로그램 및 장치", "출원인": "주식회사 에어스 메디컬", "발명자": "김현수"}}
{"patent_id": "10-2024-0007745", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "적어도 하나의 프로세서를 포함하는 컴퓨팅 장치에 의해 수행되는, 인공 신경망 기반 해상도 향상 방법으로서,복수의 획득 행렬 크기를 갖는 복수의 학습 데이터를 획득하는 단계; 및상기 복수의 학습 데이터를 기초로, 상기 복수의 학습 데이터에 포함된 라벨(label)들 중 획득 행렬 크기가 최대값인 제 1 라벨의 획득 행렬 크기 이상인 이미지 크기를 갖는 데이터를 출력하는 신경망 모델을 학습시키는단계;를 포함하는,방법."}
{"patent_id": "10-2024-0007745", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 개시의 일 실시예에 따른 인공 신경망 기반 해상도 향상 방법, 프로그램 및 장치가 개시된다. 상기 방법은, 복수의 획득 행렬 크기를 갖는 복수의 학습 데이터를 획득하는 단계; 및 상기 복수의 학습 데이터를 기초로, 상 기 복수의 학습 데이터에 포함된 라벨(label)들 중 획득 행렬 크기가 최대값인 제 1 라벨의 획득 행렬 크기 이상 인 이미지 크기를 갖는 데이터를 출력하는 신경망 모델을 학습시키는 단계를 포함할 수 있다."}
{"patent_id": "10-2024-0007745", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 영상 처리 기술에 관한 것으로, 구체적으로 다양한 해상도로 구성된 데이터를 활용하여 인공 신경망 을 학습시키고, 학습된 인공 신경망을 사용하여 데이터의 해상도를 향상시키는 방법 및 장치에 관한 것이다."}
{"patent_id": "10-2024-0007745", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "해상도 향상(super-resolution)이라는 태스크(task)를 수행하는 인공 신경망을 학습시키기 위해서, 통상적으로 저해상도(low resolution)의 이미지와 고해상도(high resolution)의 이미지 쌍이 학습 데이터로 사용된다. 저해 상도 이미지를 입력, 고해상도 이미지를 라벨(label)로 하여 인공 신경망을 학습시키면, 해당 인공 신경망은 입 력의 해상도를 라벨에 가깝게 높이도록 학습된다. 한편, 현실적으로 단일한 해상도를 갖는 고해상도의 학습 데이터를 얻기 어려운 경우가 많다. 그리고, 학습이 완료된 인공신경망에 입력으로 들어오게 될 저해상도 이미지의 해상도도 실제로 단일하지 않은 경우가 더 일반 적이다. 예를 들어, 자기 공명 영상의 경우, 이미지의 해상도는 장비의 종류, 촬영 부위, 펄스 시퀀스(pulse sequence), 또는 병원 및 의료진의 기호 등에 따라 달라지게 된다. 이와 같이 단일한 해상도로 구성된 학습 데이터를 확보하지 못하는 현실적 상황에서 다양한 해상도로 구성된 학 습 데이터를 이용해 인공 신경망을 학습시키면. 학습 데이터 중 최대값에 해당하는 해상도의 데이터를 출력하도 록 인공 신경망이 학습되지 못하고, 인공 신경망이 저해상도의 학습 데이터의 영향을 받아 최대값보다 작은 해 상도의 데이터를 출력한다는 단점이 발생할 수 있다. 예를 들어, 해상도가 동일하진 않고 비슷한 학습 이미지 두 장이 있다고 가정한다. 이때, 두 장의 이미지 중 A 이미지는 해상도가 512x512이고 B이미지는 해상도가 256x256이라고 하면, 일반적인 종래의 학습 방법을 통해 인 공 신경망을 학습시킬 경우에 인공 신경망은 최대값인 512x512에 해당하는 해상도의 이미지를 출력한다고 보장 할 수 없다. 해상도가 512x512인 A데이터와 해상도가 256x256인 B데이터가 각각 라벨로 사용될 것이므로, 인공 신경망을 통해 두 장의 이미지 사이의 해상도를 갖는 이미지가 출력되거나 아티팩트(artifact)가 있는 비정상적 인 이미지가 출력될 수 있다. 선행기술문헌 특허문헌(특허문헌 0001) 대한민국 공개특허공보 제10-2018-0114488호(2018.10.18)"}
{"patent_id": "10-2024-0007745", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 개시는 전술한 배경기술에 대응하여 안출된 것으로, 다양한 해상도를 가진 데이터 중 최대 해상도에 가까운 데이터를 출력하도록 인공 신경망을 학습시키고, 학습된 인공 신경망을 통해 데이터의 해상도를 향상시키는 방 법 및 장치를 제공하고자 한다. 다만, 본 개시에서 해결하고자 하는 과제는 이상에서 언급된 과제로 제한되지 않으며, 언급되지 않은 또 다른 과제들은 아래의 기재를 근거로 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2024-0007745", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "전술한 바와 같은 과제를 실현하기 위한 본 개시의 일 실시예에 따라 컴퓨팅 장치에 의해 수행되는, 인공 신경 망 기반 해상도 향상 방법이 개시된다. 상기 방법은, 복수의 획득 행렬 크기를 갖는 복수의 학습 데이터를 획득 하는 단계; 및 상기 복수의 학습 데이터를 기초로, 상기 복수의 학습 데이터에 포함된 라벨(label)들 중 획득 행렬 크기가 최대값인 제 1 라벨의 획득 행렬 크기 이상인 이미지 크기를 갖는 데이터를 출력하는 신경망 모델 을 학습시키는 단계를 포함할 수 있다. 대안적으로, 상기 복수의 학습 데이터를 기초로, 상기 복수의 학습 데이터에 포함된 라벨들 중 획득 행렬 크기 가 최대값인 제 1 라벨의 획득 행렬 크기 이상인 이미지 크기를 갖는 데이터를 출력하는 신경망 모델을 학습시 키는 단계는, 상기 신경망 모델을 사용하여, 상기 복수의 학습 데이터에 포함된 입력을 기초로, 상기 제 1 라벨 의 획득 행렬 크기 이상인 이미지 크기를 갖는 출력 데이터를 생성하는 단계; 상기 출력 데이터를 생성하기 위 해 사용된 입력에 매칭되는 제 2 라벨의 이미지 크기에 대응되도록, 상기 출력 데이터의 이미지 크기를 조절하 는 단계; 및 제 1 손실 함수를 통해 상기 이미지 크기가 조절된 출력 데이터과 상기 제 2 라벨 간의 오차를 연 산하는 단계를 포함할 수 있다. 대안적으로, 상기 출력 데이터를 생성하기 위해 사용된 입력에 매칭되는 제 2 라벨의 이미지 크기에 대응되도록, 상기 출력 데이터의 이미지 크기를 조절하는 단계는, 상기 출력 데이터에 대한 보간 (interpolation)을 수행함으로써, 상기 제 2 라벨의 이미지 크기에 대응되도록, 상기 출력 데이터의 이미지 크 기를 축소하는 단계를 포함할 수 있다. 대안적으로, 상기 제 1 손실 함수는, 상기 이미지 크기가 축소된 출력 데이터의 획득 행렬 크기와 상기 제 2 라 벨의 획득 행렬 크기를 기초로, 상기 이미지 크기가 축소된 출력 데이터와 상기 제 2 라벨 간의 유사도를 연산 하기 위한 손실 함수일 수 있다. 대안적으로, 상기 복수의 학습 데이터를 기초로, 상기 복수의 학습 데이터에 포함된 라벨들 중 획득 행렬 크기 가 최대값인 제 1 라벨의 획득 행렬 크기 이상인 이미지 크기를 갖는 데이터를 출력하는 신경망 모델을 학습시 키는 단계는, 상기 생성된 출력 데이터의 이미지 크기에 대응되도록, 상기 제 2 라벨의 이미지 크기를 조절하는 단계; 및 제 2 손실 함수를 통해 상기 생성된 출력 데이터와 상기 이미지 크기가 조절된 제 2 라벨 간의 오차를 연산하는 단계를 더 포함할 수 있다. 대안적으로, 상기 생성된 출력 데이터의 이미지 크기에 대응되도록, 상기 제 2 라벨의 이미지 크기를 조절하는 단계는, 상기 제 2 라벨에 대한 보간을 수행함으로써, 상기 생성된 출력 데이터의 이미지 크기에 대응되도록, 상기 제 2 라벨의 이미지 크기를 확대하는 단계를 포함할 수 있다. 대안적으로, 상기 제 2 손실 함수는, 상기 생성된 출력 데이터의 획득 행렬 크기와 상기 이미지 크기가 확대된 제 2 라벨의 획득 행렬 크기를 기초로, 상기 생성된 출력 데이터와 상기 이미지 크기가 확대된 제 2 라벨 간의 유사도를 연산하기 위한 손실 함수일 수 있다. 대안적으로, 상기 복수의 학습 데이터를 기초로, 상기 복수의 학습 데이터에 포함된 라벨들 중 획득 행렬 크기 가 최대값인 제 1 라벨의 획득 행렬 크기 이상인 이미지 크기를 갖는 데이터를 출력하는 신경망 모델을 학습시키는 단계는, 상기 제 1 손실 함수를 통한 연산 결과와 상기 제 2 손실 함수를 통한 연산 결과의 가중합을 기초 로, 상기 신경망 모델을 학습시키는 단계를 더 포함할 수 있다. 전술한 바와 같은 과제를 실현하기 위한 본 개시의 일 실시예에 따라 컴퓨팅 장치에 의해 수행되는, 인공 신경 망 기반 해상도 향상 방법이 개시된다. 상기 방법은, 저해상도의 의료 영상을 획득하는 단계; 및 사전 학습된 신경망 모델을 사용하여, 상기 저해상도의 의료 영상 대비 해상도가 개선된 고해상도의 의료 영상을 생성하는 단계를 포함할 수 있다. 이때, 상기 신경망 모델은, 복수의 획득 행렬 크기를 갖는 복수의 학습 데이터에 포함 된 라벨들 중 획득 행렬 크기가 최대값인 제 1 라벨의 획득 행렬 크기 이상인 이미지 크기를 갖는 데이터를 출 력하는 신경망을 포함할 수 있다. 전술한 바와 같은 과제를 실현하기 위한 본 개시의 일 실시예에 따라 컴퓨터 판독가능 저장 매체에 저장된 컴퓨 터 프로그램(program)이 개시된다. 상기 컴퓨터 프로그램은 하나 이상의 프로세서에서 실행되는 경우, 인공 신 경망을 기반으로 데이터의 해상도를 향상시키기 위한 동작들을 수행하도록 한다. 이때, 상기 동작들은, 복수의 획득 행렬 크기를 갖는 복수의 학습 데이터를 획득하는 동작; 및 상기 복수의 학습 데이터를 기초로, 상기 복수 의 학습 데이터에 포함된 라벨들 중 획득 행렬 크기가 최대값인 제 1 라벨의 획득 행렬 크기 이상인 이미지 크 기를 갖는 데이터를 출력하는 신경망 모델을 학습시키는 동작을 포함할 수 있다. 전술한 바와 같은 과제를 실현하기 위한 본 개시의 일 실시예에 따라 인공 신경망을 기반으로 데이터의 해상도 를 향상시키는 컴퓨팅 장치가 개시된다. 상기 장치는, 적어도 하나의 코어(core)를 포함하는 프로세서; 상기 프 로세서에서 실행 가능한 프로그램 코드(code)들을 포함하는 메모리(memory); 및 복수의 획득 행렬 크기를 갖는 복수의 학습 데이터를 획득하는 네트워크부(network unit)를 포함할 수 있다. 이때, 상기 프로세서는, 상기 복 수의 학습 데이터를 기초로, 상기 복수의 학습 데이터에 포함된 라벨들 중 획득 행렬 크기가 최대값인 제 1 라 벨의 획득 행렬 크기 이상인 이미지 크기를 갖는 데이터를 출력하는 신경망 모델을 학습시킬 수 있다."}
{"patent_id": "10-2024-0007745", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 개시는 현실적으로 단일한 해상도를 갖는 학습 데이터를 확보하지 못하더라도, 다양한 해상도로 구성된 학습 데이터를 활용하여 인공 신경망을 효과적으로 학습시킴으로써, 임의의 데이터에 대한 인공 신경망의 해상도 향 상 성능을 보장할 수 있다."}
{"patent_id": "10-2024-0007745", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "아래에서는 첨부한 도면을 참조하여 본 개시의 기술 분야에서 통상의 지식을 가진 자(이하, 당업자)가 용이하게 실시할 수 있도록 본 개시의 실시예가 상세히 설명된다. 본 개시에서 제시된 실시예들은 당업자가 본 개시의 내 용을 이용하거나 또는 실시할 수 있도록 제공된다. 따라서, 본 개시의 실시예들에 대한 다양한 변형들은 당업자 에게 명백할 것이다. 즉, 본 개시는 여러 가지 상이한 형태로 구현될 수 있으며, 이하의 실시예에 한정되지 않 는다. 본 개시의 명세서 전체에 걸쳐 동일하거나 유사한 도면 부호는 동일하거나 유사한 구성요소를 지칭한다. 또한, 본 개시를 명확하게 설명하기 위해서, 도면에서 본 개시에 대한 설명과 관계없는 부분의 도면 부호는 생략될 수 있다. 본 개시에서 사용되는 \"또는\" 이라는 용어는 배타적 \"또는\" 이 아니라 내포적 \"또는\" 을 의미하는 것으로 의도 된다. 즉, 본 개시에서 달리 특정되지 않거나 문맥상 그 의미가 명확하지 않은 경우, \"X는 A 또는 B를이용한다\"는 자연적인 내포적 치환 중 하나를 의미하는 것으로 이해되어야 한다. 예를 들어, 본 개시에서 달리 특정되지 않거나 문맥상 그 의미가 명확하지 않은 경우, \"X는 A 또는 B를 이용한다\" 는 X가 A를 이용하거나, X 가 B를 이용하거나, 혹은 X가 A 및 B 모두를 이용하는 경우 중 어느 하나로 해석될 수 있다. 본 개시에서 사용되는 \"및/또는\" 이라는 용어는 열거된 관련 개념들 중 하나 이상의 개념의 가능한 모든 조합을 지칭하고 포함하는 것으로 이해되어야 한다. 본 개시에서 사용되는 \"포함한다\" 및/또는 \"포함하는\" 이라는 용어는, 특정 특징 및/또는 구성요소가 존재함을 의미하는 것으로 이해되어야 한다. 다만, \"포함한다\" 및/또는 \"포함하는\" 이라는 용어는, 하나 이상의 다른 특 징, 다른 구성요소 및/또는 이들에 대한 조합의 존재 또는 추가를 배제하지 않는 것으로 이해되어야 한다. 본 개시에서 달리 특정되지 않거나 단수 형태를 지시하는 것으로 문맥상 명확하지 않은 경우에, 단수는 일반적 으로 \"하나 또는 그 이상\" 을 포함할 수 있는 것으로 해석되어야 한다. 본 개시에서 사용되는 \"제 N(N은 자연수)\" 이라는 용어는 본 개시의 구성요소들을 기능적 관점, 구조적 관점, 혹은 설명의 편의 등 소정의 기준에 따라 상호 구별하기 위해 사용되는 표현으로 이해될 수 있다. 예를 들어, 본 개시에서 서로 다른 기능적 역할을 수행하는 구성요소들은 제 1 구성요소 혹은 제 2 구성요소로 구별될 수 있다. 다만, 본 개시의 기술적 사상 내에서 실질적으로 동일하나 설명의 편의를 위해 구분되어야 하는 구성요소 들도 제 1 구성요소 혹은 제 2 구성요소로 구별될 수도 있다. 한편, 본 개시에서 사용되는 용어 \"모듈(module)\", 또는 \"부(unit)\" 는 컴퓨터 관련 엔티티(entity), 펌웨어 (firmware), 소프트웨어(software) 혹은 그 일부, 하드웨어(hardware) 혹은 그 일부, 소프트웨어와 하드웨어의 조합 등과 같이 컴퓨팅 자원을 처리하는 독립적인 기능 단위를 지칭하는 용어로 이해될 수 있다. 이때, \"모듈\" 또는 \"부\"는 단일 요소로 구성된 단위일 수도 있고, 복수의 요소들의 조합 혹은 집합으로 표현되는 단위일 수도 있다. 예를 들어, 협의의 개념으로서 \"모듈\" 또는 \"부\"는 컴퓨팅 장치의 하드웨어 요소 또는 그 집합, 소프트웨 어의 특정 기능을 수행하는 응용 프로그램, 소프트웨어 실행을 통해 구현되는 처리 과정(procedure), 또는 프로 그램 실행을 위한 명령어 집합 등을 지칭할 수 있다. 또한, 광의의 개념으로서 \"모듈\" 또는 \"부\"는 시스템을 구 성하는 컴퓨팅 장치 그 자체, 또는 컴퓨팅 장치에서 실행되는 애플리케이션 등을 지칭할 수 있다. 다만, 상술한 개념은 하나의 예시일 뿐이므로, \"모듈\" 또는 \"부\"의 개념은 본 개시의 내용을 기초로 당업자가 이해 가능한 범 주에서 다양하게 정의될 수 있다. 본 개시에서 사용되는 \"모델(model)\" 이라는 용어는 특정 문제를 해결하기 위해 수학적 개념과 언어를 사용하여 구현되는 시스템, 특정 문제를 해결하기 위한 소프트웨어 단위의 집합, 혹은 특정 문제를 해결하기 위한 처리 과정에 관한 추상화 모형으로 이해될 수 있다. 예를 들어, 신경망(neural network) \"모델\" 은 학습을 통해 문제 해결 능력을 갖는 신경망으로 구현되는 시스템 전반을 지칭할 수 있다. 이때, 신경망은 노드(node) 혹은 뉴런 (neuron)을 연결하는 파라미터(parameter)를 학습을 통해 최적화하여 문제 해결 능력을 가질 수 있다. 신경망 \"모델\" 은 단일 신경망을 포함할 수도 있고, 복수의 신경망들이 조합된 신경망 집합을 포함할 수도 있다. 본 개시에서 사용되는 \"영상\" 이라는 용어는 이산적 이미지 요소들로 구성된 다차원 데이터를 지칭할 수 있다. 다시 말해, \"영상\"은 사람의 눈으로 볼 수 있는 대상의 디지털 표현물을 지칭하는 용어로 이해될 수 있다. 예를 들어, \"영상\" 은 2차원 이미지에서 픽셀에 해당하는 요소들로 구성된 다차원 데이터를 지칭할 수 있다. \"영상\" 은 3차원 이미지에서 복셀에 해당하는 요소들로 구성된 다차원 데이터를 지칭할 수 있다. 본 개시에서 사용되는 \"이미지 크기(size)\" 라는 용어는 이미지의 높이 축, 너비 축, 및/또는 깊이 축을 구성하 는 절대적인 픽셀 수를 의미할 수 있다. 그리고, 본 개시에서 사용되는 \"획득 행렬 크기(acquisition matrix size)\" 라는 용어는 이미지를 촬영할 때 획득되는 픽셀 단위의 크기로서, 이미지의 정보를 모두 포함할 수 있는 최소 크기로 이해될 수 있다. 다시 말해서, \"획득 행렬 크기\" 라는 용어는 원본 이미지가 갖는 해상도와 관련된 용어로서, 원본 이미지를 정보의 손실없이 분해하기 위한 최소 픽셀 수를 의미할 수 있다. 예를 들어, 획득 행렬 크기가 800x600인 이미지는 높이가 800픽셀, 너비가 600픽셀로 얻어진 이미지를 의미할 수 있다. 이때, 획득 행렬 크기 800x600는 이미지 크기와 비교하여 같거나 작을 수 있다. 획득 행렬 크기가 800x600 인 이미지를 2배 확대하여 이미지 크기가 1600x1200이 되도록 확대한다고 가정하자. 이때, 확대된 이미 지의 이미지 크기는 1600x1200이지만, 획득 행렬 크기는 800x600이다. 상술한 획득 행렬 크기의 설명에 따르면, 확대된 이미지의 높이 축 신호 값들은 최소한 800 픽셀로 분해 혹은 표현할 수 있으며, 그 미만의 픽셀로는 분 해할 수 없기 때문이다. 반대로, 획득 행렬 크기와 이미지 크기가 800x600인 이미지를 이미지 크기가 400x300이 되도록 축소한다고 가정하자. 이때, 축소된 이미지는 최소 400x300픽셀로 분해 가능하므로, 획득 행렬 크기는400x300으로 감소한다. 또한, 이미지 크기는 400x300이 된다. 본 개시에서 \"가속화 촬영\"은 일반적인 촬영 대비 자기 공명 신호에 대한 여기 횟수(NEX: number of excitations)를 감소시켜 촬영 시간을 단축시키는 촬영 기법으로 이해될 수 있다. 여기 횟수는 케이-스페이스 도메인에서 자기 공명 신호의 라인들을 반복 획득할 때의 반복된 횟수로 이해될 수 있다. 따라서, 여기 횟수가 증가함에 따라 자기 공명 영상의 촬영 시간이 비례하여 증가할 수 있다. 즉, 자기 공명 영상의 촬영 시에 여기 횟수를 감소시키는 경우, 자기 공명 영상의 촬영 시간이 단축된 가속화 촬영이 구현될 수 있다. 본 개시에서 \"가속화 촬영\"은 케이-스페이스 도메인에서 위상 인코딩(phase encoding) 방향으로 더 좁은 범위의 신호를 얻음으로써, 해상도가 상대적으로 낮은 영상을 획득하는 촬영 기법으로 이해될 수 있다. 다시 말해, 본 개시의 가속화 촬영은 일반적인 촬영 대비 위상 레졸루션(resolution)을 감소시킨 촬영 기법으로 이해될 수 있 다. 위상 레졸루션은 케이-스페이스 도메인에서 위상 인코딩 방향으로 샘플링 된 라인의 개수를 미리 설정된 기 준 값으로 나눈 값으로 이해될 수 있다. 따라서, 위상 레졸루션이 증가함에 따라, 자기 공명 영상의 촬영 시간 이 비례하여 증가할 수 있다. 즉, 자기 공명 영상의 촬영 시에 위상 레졸루션을 감소시키는 경우, 자기 공명 영 상의 촬영 시간이 단축된 가속화 촬영이 구현될 수 있다. 본 개시에서 \"가속화 촬영\"은 일반적인 촬영에 비해 가속화 지수(acceleration factor)를 높여 촬영 시간을 단 축시키는 촬영 기법으로 이해될 수 있다. 가속화 지수는 병렬 영상 기법에서 사용되는 용어로서, 케이-스페이스 에서 풀 샘플링(full sampling)된 신호 라인의 개수를 촬영을 통해 샘플링 된 신호 라인의 개수로 나눈 값으로 이해될 수 있다. 예를 들어, 가속화 지수가 2 라는 것은, 위상 인코딩 방향으로 자기 공명 신호를 샘플링 하여 라인을 획득할 때, 풀 샘플링 된 신호 라인의 개수 대비 절반의 신호 라인의 개수를 획득하는 것으로 이해될 수 있다. 따라서, 가속화 지수가 증가함에 따라, 자기 공명 영상의 촬영 시간이 비례하여 감소할 수 있다. 즉, 자 기 공명 영상의 촬영 시에 가속화 지수를 증가시키는 경우, 자기 공명 영상의 촬영 시간이 단축된 가속화 촬영 이 구현될 수 있다. 본 개시에서 \"가속화 촬영\"은 서브 샘플링(sub sampling) 된 자기 공명 신호를 획득하여 자기 공명 영상을 생성 하는 촬영 기법으로 이해될 수 있다. 이때, 서브 샘플링은 나이키스트 샘플링 레이트(nyquist sampling rate)보 다 낮은 샘플링 레이트로 자기 공명 신호를 샘플링 하는 작업으로 이해될 수 있다. 따라서, 본 개시의 의료 데 이터는 나이키스트 샘플링 레이트보다 낮은 샘플링 레이트로 자기 공명 신호를 샘플링 하여 획득된 영상일 수 있다. 다만, 상술한 \"가속화 촬영\"의 설명은 하나의 예시일 뿐이므로, 가속화 촬영의 개념은 본 개시의 내용을 기초로 당업자가 이해 가능한 범주에서 다양하게 정의될 수 있다. 전술한 용어의 설명은 본 개시의 이해를 돕기 위한 것이다. 따라서, 전술한 용어를 본 개시의 내용을 한정하는 사항으로 명시적으로 기재하지 않은 경우, 본 개시의 내용을 기술적 사상을 한정하는 의미로 사용하는 것이 아 님을 주의해야 한다. 도 1은 본 개시의 일 실시예에 따른 컴퓨팅 장치의 블록도다. 본 개시의 일 실시예에 따른 컴퓨팅 장치는 데이터의 종합적인 처리 및 연산을 수행하는 하드웨어 장치 혹 은 하드웨어 장치의 일부일 수도 있고, 통신 네트워크로 연결되는 소프트웨어 기반의 컴퓨팅 환경일 수도 있다. 예를 들어, 컴퓨팅 장치는 집약적 데이터 처리 기능을 수행하고 자원을 공유하는 주체인 서버일 수도 있고, 서버와의 상호 작용을 통해 자원을 공유하는 클라이언트(client)일 수도 있다. 또한, 컴퓨팅 장치는 복수의 서버들 및 클라이언트들이 상호 작용하여 데이터를 종합적으로 처리하는 클라우드 시스템(cloud syste m)일 수도 있다. 상술한 기재는 컴퓨팅 장치의 종류와 관련된 하나의 예시일 뿐이므로, 컴퓨팅 장치 의 종류는 본 개시의 내용을 기초로 당업자가 이해 가능한 범주에서 다양하게 구성될 수 있다. 도 1을 참조하면, 본 개시의 일 실시예에 따른 컴퓨팅 장치는 프로세서(processor), 메모리 (memory), 및 네트워크부(network unit)를 포함할 수 있다. 다만, 도 1은 하나의 예시일 뿐이므로, 컴퓨팅 장치는 컴퓨팅 환경을 구현하기 위한 다른 구성들을 포함할 수 있다. 또한, 상기 개시된 구성들 중 일부만이 컴퓨팅 장치에 포함될 수도 있다. 본 개시의 일 실시예에 따른 프로세서는 컴퓨팅 연산을 수행하기 위한 하드웨어 및/또는 소프트웨어를 포 함하는 구성 단위로 이해될 수 있다. 예를 들어, 프로세서는 컴퓨터 프로그램을 판독하여 기계 학습을 위 한 데이터 처리를 수행할 수 있다. 프로세서는 기계 학습을 위한 입력 데이터의 처리, 기계 학습을 위한 특징 추출, 역전파(backpropagation)에 기반한 오차 계산 등과 같은 연산 과정을 처리할 수 있다. 이와 같은 데이터 처리를 수행하기 위한 프로세서는 중앙 처리 장치(CPU: central processing unit), 범용 그래픽 처 리 장치(GPGPU: general purpose graphics processing unit), 텐서 처리 장치(TPU: tensor processing unit), 주문형 반도체(ASIC: application specific integrated circuit), 혹은 필드 프로그래머블 게이트 어레이 (FPGA: field programmable gate array) 등을 포함할 수 있다. 상술한 프로세서의 종류는 하나의 예시일 뿐이므로, 프로세서의 종류는 본 개시의 내용을 기초로 당업자가 이해 가능한 범주에서 다양하게 구성될 수 있다. 프로세서는 데이터의 해상도 향상을 위한 신경망 모델을 학습시킬 수 있다. 프로세서는 다양한 획득 행렬 크기를 갖는 복수의 학습 데이터를 기초로 신경망 모델이 입력의 획득 행렬 크기를 개선시키도록, 신경망 모델을 학습시킬 수 있다. 이때, 신경망 모델은 입력과 대비하여 획득 행렬 크기가 증가되고 일정한 이미지 크 기를 갖는 출력을 생성하는 신경망을 포함할 수 있다. 그리고, 신경망이 생성하는 출력의 이미지 크기는 다양한 획득 행렬 크기를 갖는 복수의 학습 데이터에 포함된 라벨(label)들 중 획득 행렬 크기가 최대값인 특정 라벨의 획득 행렬 크기 이상일 수 있다. 즉, 프로세서는 다양한 획득 행렬 크기를 갖는 복수의 학습 데이터 중 획 득 행렬 크기가 최대값인 데이터에 가까운 이미지를 출력하도록 신경망 모델을 학습시킬 수 있다. 예를 들어, 프로세서는 후술할 네트워크부를 통해 확보된 학습 데이터에서 입력에 해당하는 데이터를 신경망 모 델에 입력하여 학습 데이터의 라벨의 획득 행렬 크기를 기준으로 결정된 일정한 이미지 크기의 출력을 생성할 수 있다. 프로세서는 신경망 모델의 입력에 대응되는 라벨과 신경망 모델의 입력을 기초로 생성된 출력 간 의 획득 행렬 크기를 비교할 수 있다. 프로세서는 비교 결과를 토대로 신경망 모델에 포함된 신경망의 파 라미터를 업데이트함으로써, 신경망 모델이 입력과 대비하여 획득 행렬 크기가 증가된 데이터를 출력하도록 신 경망 모델을 학습시킬 수 있다. 프로세서는 신경망 모델의 학습 과정에서 신경망 모델의 출력의 이미지 크기를 조절할 수 있다. 예를 들어, 프로세서는 신경망 모델의 출력의 이미지 크기를 출력을 생성하기 위해 사용된 입력에 대응되는 라 벨의 획득 행렬 크기에 맞춰 조절할 수 있다. 신경망 모델의 출력의 이미지 크기는 일정한 반면, 라벨은 이미지 크기가 획득 행렬 크기에 맞춰 다양하게 구성될 수 있다. 따라서, 신경망 모델의 출력과 라벨 간 획득 행렬 크 기의 비교가 쉽고 정확하게 이루어질 수 있도록 하기 위해, 프로세서는 라벨의 획득 행렬 크기의 최대값을 기준으로 결정된 출력의 이미지 크기를, 출력과 비교할 라벨의 획득 행렬 크기에 맞춰 축소할 수 있다. 프로세서는 신경망 모델의 학습 과정에서 학습 데이터의 이미지 크기를 조절할 수 있다. 예를 들어, 프로 세서는 복수의 학습 데이터에 포함된 라벨들 중 이미지 크기가 획득 행렬 크기보다 큰 라벨의 이미지 크기 를 조절할 수 있다. 프로세서는 이미지 크기가 획득 행렬 크기보다 큰 라벨의 이미지 크기를 획득 행렬 크 기에 대응되도록 축소할 수 있다. 이미지 크기가 획득 행렬 크기보다 크다면, 이미지 크기를 축소하더라도 이미 지를 표현하는 정보량은 동일할 수 밖에 없다. 따라서, 신경망 모델의 출력과 라벨 간 획득 행렬 크기의 비교가 쉽고 정확하게 이루어질 수 있도록 하기 위해, 프로세서는 라벨의 이미지 크기를 라벨의 획득 행렬 크기에 맞춰 조절할 수 있다. 프로세서는 상술한 바에 따라 사전 학습된 신경망 모델을 사용하여, 저해상도 데이터를 사용자가 원하는 수준의 고해상도 데이터로 변환할 수 있다. 프로세서는 사전 학습된 신경망 모델을 통해 저해상도 데이터 의 획득 행렬 크기를 개선함으로써, 저해상도 데이터 대비 해상도가 향상된 데이터를 생성할 수 있다. 예를 들 어, 프로세서는 의료 영상을 신경망 모델에 입력하여 병원에서 요구하는 품질 수준에 맞춰 의료 영상의 해 상도를 개선시킬 수 있다. 이때, 신경망 모델은 학습 데이터에 존재하는 다양한 획득 행렬 크기 중 최대값에 가 까운 데이터를 출력하도록 학습되므로, 프로세서는 신경망 모델이 학습한 최대값에 맞춰 해상도가 개선된 영상을 생성할 수 있다. 본 개시의 일 실시예에 따른 메모리는 컴퓨팅 장치에서 처리되는 데이터를 저장하고 관리하기 위한 하드웨어 및/또는 소프트웨어를 포함하는 구성 단위로 이해될 수 있다. 즉, 메모리는 프로세서가 생 성하거나 결정한 임의의 형태의 데이터 및 네트워크부가 수신한 임의의 형태의 데이터를 저장할 수 있다. 예를 들어, 메모리는 플래시 메모리 타입(flash memory type), 하드디스크 타입(hard disk type), 멀티미 디어 카드 마이크로 타입(multimedia card micro type), 카드 타입의 메모리, 램(RAM: random access memory), 에스램(SRAM: static random access memory), 롬(ROM: read-only memory), 이이피롬(EEPROM: electrically erasable programmable read-only memory), 피롬(PROM: programmable read-only memory), 자기 메모리, 자기 디스크, 또는 광디스크 중 적어도 하나의 타입의 저장매체를 포함할 수 있다. 또한, 메모리 는 데이터를 소정의 체제로 통제하여 관리하는 데이터베이스(database) 시스템을 포함할 수도 있다. 상술한 메 모리의 종류는 하나의 예시일 뿐이므로, 메모리의 종류는 본 개시의 내용을 기초로 당업자가 이해 가능한 범주에서 다양하게 구성될 수 있다. 메모리는 프로세서가 연산을 수행하는데 필요한 데이터, 데이터의 조합, 및 프로세서에서 실행 가능한 프로그램 코드(code) 등을 구조화 및 조직화 하여 관리할 수 있다. 예를 들어, 메모리는 후술할 네 트워크부를 통해 획득된 학습 데이터를 저장할 수 있다. 메모리는 신경망 모델이 학습 데이터를 기초 로 학습하도록 동작시키는 프로그램 코드, 신경망 모델이 데이터에 대한 특징 해석(혹은 추론)을 수행하도록 동 작시키는 프로그램 코드 및 프로그램 코드가 실행됨에 따라 산출된 각종 데이터 등을 저장할 수 있다. 본 개시의 일 실시예에 따른 네트워크부는 임의의 형태의 공지된 유무선 통신 시스템을 통해 데이터를 송 수신하는 구성 단위로 이해될 수 있다. 예를 들어, 네트워크부는 근거리 통신망(LAN: local area network), 광대역 부호 분할 다중 접속(WCDMA: wideband code division multiple access), 엘티이(LTE: long term evolution), 와이브로(WiBro: wireless broadband internet), 5세대 이동통신(5G), 초광역대 무선통신 (ultra wide-band), 지그비(ZigBee), 무선주파수(RF: radio frequency) 통신, 무선랜(wireless LAN), 와이파이 (wireless fidelity), 근거리 무선통신(NFC: near field communication), 또는 블루투스(Bluetooth) 등과 같은 유무선 통신 시스템을 사용하여 데이터 송수신을 수행할 수 있다. 상술한 통신 시스템들은 하나의 예시일 뿐이 므로, 네트워크부의 데이터 송수신을 위한 유무선 통신 시스템은 상술한 예시 이외에 다양하게 적용될 수 있다. 네트워크부는 임의의 시스템 혹은 임의의 클라이언트 등과의 유무선 통신을 통해, 프로세서가 연산을 수행하는데 필요한 데이터를 수신할 수 있다. 또한, 네트워크부는 임의의 시스템 혹은 임의의 클라이언트 등과의 유무선 통신을 통해, 프로세서의 연산을 통해 생성된 데이터를 송신할 수 있다. 예를 들어, 네트워 크부는 의료 영상 저장 전송 시스템 등과 통신을 통해, 신체 부위를 촬영한 의료 영상을 수신할 수 있다. 네트워크부는 전술한 시스템 등과 통신을 통해, 프로세서의 연산을 통해 생성된 각종 데이터를 송신 할 수 있다. 도 2는 본 개시의 일 실시예에 따른 신경망 모델의 학습 과정을 나타낸 블록도이다. 본 개시의 일 실시예에 따른 컴퓨팅 장치의 프로세서는 다양한 획득 행렬 크기를 갖는 이미지들을 해 상도 향상을 위한 신경망 모델의 학습 데이터로 사용할 수 있다. 이때, 학습 데이터로 사용되는 이미지들은 신 경망 모델의 입력 혹은 라벨로 구별될 수 있다. 그리고, 학습 데이터로 사용되는 이미지의 획득 행렬 크기는 이 미지 크기와 동일하거나 작을 수 있다. 획득 행렬 크기가 이미지 크기보다 작은 경우, 신경망 모델의 원활한 학 습을 위해서, 프로세서는 학습 데이터로 사용되는 이미지의 이미지 크기를 획득 행렬 크기에 맞춰 축소할 수 있다. 예를 들어, 도 2를 참조하면, 프로세서는 서로 다른 획득 행렬 크기를 갖는 이미지들을 신경망 모델 의 입력 세트 혹은 라벨 세트로 구별하여 사용할 수 있다. 신경망 모델의 학습을 위해, 프로세서 는 입력 A를 신경망 모델로 입력할 수 있다. 그리고, 프로세서는 입력 A를 수신한 신경 망 모델의 출력을 검증하기 위해 입력 A에 매칭되는 라벨 A를 사용할 수 있다. 한편, 신경망 모델은 신경망 모델의 입력으로 사용될 이미지를 수신하여, 일정한 이미지 크기를 갖는 출력 을 생성하는 신경망을 포함할 수 있다. 이때, 일정한 이미지 크기는 라벨로 사용될 이미지들 중 획득 행렬 크기 가 최대값인 이미지의 획득 행렬 크기 이상일 수 있다. 즉, 신경망 모델은 라벨로 사용될 이미지들을 기준 으로 최대 획득 행렬 크기 이상인 이미지 크기를 갖는 출력을 생성하는 신경망을 포함할 수 있다. 신경망 모델 은 이러한 신경망을 통해 어떠한 획득 행렬 크기를 갖는 학습 데이터가 입력되더라도 출력이 획득 행렬 크 기의 최대값을 표현할 수 있도록 학습될 수 있다. 예를 들어, 도 2에서 라벨 세트 중 획득 행렬 크기가 최대인 라벨을 라벨 B, 라벨 B의 획득 행렬 크기를 R이라고 가정하자. 이때, R은 이미지의 너비(x) 축 방향의 최대값, 높이(y) 축 방향의 최대값, 및/또는 깊이(z) 축 방향의 최대값일 수 있다. 신경망 모델에 포함된 신경망은 어떠한 입력을 획득하더라도 출력의 이미지 크기가 C라는 일정한 값을 갖는 출력을 생성할 수 있다. 이때, C는 R 이상인 값일 수 있다. 즉, 신경망 모델은 입력 A가 입력되든지 혹은 입력 B가 입력되든지 관계없이 라벨 B의 획득 행렬 크기 R 이상인 C라는 일정한 값의 이미지 크기를 갖는 출력을 생성할 수 있다. 프로세서는 학습 데이터 중 신경망 모델의 입력으로 사용될 이미지를 신경망 모델로 입력하여 입력과 대비 하여 획득 행렬 크기가 증가된 출력을 생성할 수 있다. 이때, 신경망 모델로부터 생성된 출력은 라벨들의 획득 행렬 크기 중 최대값 이상인 이미지 크기를 가질 수 있다. 신경망 모델의 학습을 위해서, 프로세서는 출력과 비교할 라벨의 획득 행렬 크기에 맞춰 출력의 이미지 크기를 조절할 수 있다. 그리고, 프로세서는 손실 함수를 통해 이미지 크기가 조절된 출력과 라벨 간의 오차를 연산하고, 연산된 오차를 기반으로 신경망 모델을 학습시킬 수 있다. 예를 들어, 도 2와 같이 학습 데이터 중에서 입력 A 및 획득 행렬 크기가 r1인 라벨 A를 사용하여 신경 망 모델의 학습을 진행한다고 가정하자. 프로세서는 입력 A를 신경망 모델로 입력하여 이미 지 크기가 C인 출력 A를 생성할 수 있다. 프로세서는 신경망 모델을 사용하여 생성된 출력 A(3 1)의 이미지 크기를 라벨 A의 획득 행렬 크기인 r1으로 축소하기 위해 출력 A에 대한 보간 (interpolation)을 수행할 수 있다. 프로세서는 제 1 손실 함수를 사용하여, 출력 A에 대한 축소 보간 을 통해 생성된 출력 A'와 라벨 A 간 오차를 연산할 수 있다. 이때, 제 1 손실 함수는 이미지 크기가 r1인 출력 A'의 획득 행렬 크기와 획득 행렬 크기가 r1인 라벨 A의 획득 행렬 크기를 기초로, 출력 A'와 라벨 A 간의 유사도를 연산하는 손실 함수일 수 있다. 제 1 손실 함수로는 SSIM(structural similarity) 손실 함수, (MSE mean squared error) 손실 함수 등이 사용될 수 있으나, 본 개시는 이러한 예시 에 제한되지 않는다. 프로세서는 제 1 손실 함수를 통해 도출된 유사도 연산 결과를 토대로 신경망 모델 이 C라는 일정한 이미지 크기를 가지면서 최대 행렬 획득 크기 R을 갖는 이미지를 생성하도록, 신경망 모 델을 학습시킬 수 있다. 상술한 과정을 입력 B 등에 대해서도 반복 수행함으로써, 다양한 획득 행렬 크기를 갖는 이미지를 가지고도 신경망 모델을 안정적으로 학습시킬 수 있다. 보다 구체적으로 살펴보면, 신경망 모델의 학습에 사용 될 이미지는 다음과 같은 획득 행렬 크기를 갖는 것으로 가정하자. - 입력 A: 320x320 / 라벨 A: 400X400 - 입력 B: 320x320 / 라벨 B: 512x512 이때, 각 이미지의 획득 행렬 크기와 이미지 크기가 동일한 것으로 가정한다. 그리고, 라벨 B의 획득 행렬 크기는 최대값인 512x512를 가지므로, 신경망 모델은 640x640인 이미지를 입력받아 이미지 크기가 512x512 보다 큰 640x640인 이미지를 출력하는 신경망을 포함한다고 가정한다. 이러한 가정에 따르면, 프로세서는 입력 A를 신경망 모델로 입력하여 640x640의 이미지 크기를 갖는 출력 A를 생성할 수 있다. 이때, 입력 A를 신경망 모델로 입력시키기 위해서, 프로세서(11 0)는 입력 A의 이미지 크기를 보간을 통해 320x320에서 640x640으로 확대할 수 있다. 프로세서는 보간 을 통해 출력 A의 이미지 사이즈를 라벨 A의 획득 행렬 크기인 400x400으로 축소하여, 출력 A'를 생성할 수 있다. 프로세서는 이미지 사이즈가 400x400인 출력 A'와 획득 행렬 크기가 400x400인 라벨 A를 기반으로 손실 값을 계산함으로써, 신경망 모델을 학습시킬 수 있다. 입력 A에 대한 학습 이후, 프로세서는 입력 B를 신경망 모델로 입력하여 640x640의 이미지 크기를 갖는 출력 B를 생성할 수 있다. 이때, 입력 B를 신경망 모델로 입력시키기 위해서, 프로세서 는 입력 B의 이미지 크기를 보간을 통해 320x320에서 640x640으로 확대할 수 있다. 프로세서는 보간을 통해 출력 B의 이미지 사이즈를 라벨 B의 획득 행렬 크기인 512x512로 축소하여, 출력 B'를 생성할 수 있다. 프로세서는 이미지 사이즈가 512x512인 출력 B'와 획득 행렬 크기가 512x512인 라벨 B를 기 반으로 손실 값을 계산하고, 손실 값이 최소가 되도록 신경망 모델을 학습시킬 수 있다. 상술한 바와 같이 라벨의 최대 획득 행렬 크기에 맞춰 이미지 크기가 일정한 출력을 생성하고, 출력의 이미지 크기를 조절하여 출력에 대응되는 라벨과 획득 행렬 크기를 비교하는 학습이 수행되면, 신경망 모델이 라 벨 A와 라벨 B를 모두 적절히 예측할 수 있도록 학습이 수행될 수 있다. 즉, 상술한 바와 같이 학습이 수행되면, 640x640의 이미지 크기를 갖는 출력의 획득 행렬 크기는 512x512 이상이 되도록 신경망 모델이 학습되므로, 신경망 모델이 학습 데이터에 포함된 어떠한 라벨도 예측할 수 있다. 상술한 바와 같이 학습 이 수행되지 못하는 경우, 신경망 모델은 라벨 A의 획득 행렬 크기인 400x400과 라벨 B의 획득 행 렬 크기인 512x512 사이인 획득 행렬 크기를 갖는 출력을 생성하거나, 아티팩트를 포함하는 출력을 생성할 수 밖에 없다. 다시 말해, 상술한 바와 같이 학습이 수행되지 못하는 경우, 신경망 모델은 획득 행렬 크기가 400x400인 라벨 A는 예측할 수 있지만, 획득 행렬 크기가 512x512인 라벨 B는 예측할 수 없다. 한편, 라벨 A 혹은 라벨 B의 이미지 크기가 획득 행렬 크기보다 크다면, 프로세서는 라벨 A 혹은 라벨 B의 이미지 크기를 획득 행렬 크기만큼 축소할 수 있다. 이미지의 정보를 모두 포함할 수 있는 최소 크기이므로, 이미지 크기를 획득 행렬 크기만큼 축소하더라도 라벨에 포함된 정보량은 동일하다. 따라서,신경망 모델이 불필요하게 중복되는 정보를 배제하고 효율적으로 학습을 수행할 수 있도록, 프로세서는 라 벨 A 혹은 라벨 B의 이미지 크기를 획득 행렬 크기만큼 축소할 수 있다. 대안적으로, 신경망 모델의 학습을 위해서, 프로세서는 출력과 비교할 라벨의 획득 행렬 크기에 맞춰, 출 력의 이미지 크기를 조절할 수 있다. 그리고, 프로세서는 출력 원본의 이미지 크기에 맞춰, 출력과 비교할 라벨의 이미지 크기를 조절할 수도 있다. 프로세서는 손실 함수를 통해 이미지 크기가 조절된 출력과 라벨 간의 오차와 함께 이미지 크기가 조절된 라벨과 출력 원본 간의 오차를 연산하고, 연산된 오차들을 기반으로 신 경망 모델을 학습시킬 수 있다. 예를 들어, 도 2와 같이 학습 데이터 중에서 입력 A 및 획득 행렬 크기가 r1인 라벨 A를 사용하여 신경 망 모델의 학습을 진행한다고 가정하자. 프로세서는 입력 A를 신경망 모델로 입력하여 이미 지 크기가 C인 출력 A를 생성할 수 있다. 프로세서는 신경망 모델을 사용하여 생성된 출력 A(3 1)의 이미지 크기를 라벨 A의 획득 행렬 크기인 r1으로 축소하기 위해 출력 A에 대한 보간 (interpolation)을 수행할 수 있다. 그리고, 프로세서는 라벨 A의 이미지 크기를 출력의 이미지 크기인 C로 확대하기 위해 라벨 A에 대한 보간을 수행할 수 있다. 프로세서는 제 1 손실 함수를 사용 하여, 출력 A에 대한 축소 보간을 통해 생성된 출력 A'와 라벨 A 간 오차를 연산할 수 있다. 그리 고, 프로세서는 제 2 손실 함수를 사용하여, 라벨 A에 대한 확대 보간을 통해 생성된 라벨 A'과 출력 A 간의 오차를 연산할 수 있다. 이때, 제 2 손실 함수는 이미지 크기가 C인 출력 A의 획득 행렬 크기와 획득 행렬 크기가 r1이고 이미지 크기가 C인 라벨 A'의 획득 행렬 크기를 기초로, 출력 A와 라 벨 A' 간의 유사도를 연산하는 손실 함수일 수 있다. 제 2 손실 함수로는 SSIM(structural similarity) 손 실 함수, (MSE mean squared error) 손실 함수 등이 사용될 수 있으나, 본 개시는 이러한 예시에 제한되지 않는 다. 프로세서는 제 1 손실 함수를 통해 도출된 유사도 연산 결과와 제 2 손실 함수를 통해 도출된 유사도 연산 결과를 토대로 신경망 모델이 C라는 일정한 이미지 크기를 가지면서 최대 행렬 획득 크기 R을 갖는 이미지를 생성하도록, 신경망 모델을 학습시킬 수 있다. 보다 구체적으로 살펴보면, 프로세서는 제 1 손실 함수와 제 2 손실 함수의 가중합으로 표현되는 손실 함 수를 이용하여 신경망 모델을 학습시킬 수 있다. 이때, 제 1 손실 함수는 640x640의 이미지 크기를 갖는 출력 A를 라벨 A의 획득 행렬 크기인 400X400으로 축소 보간하여 생성된 출력 A'와 라벨 A 간 의 획득 행렬 크기를 기초로, 출력 A'와 라벨 A 간의 유사도를 연산하기 위한 손실 함수일 수 있다. 그 리고, 제 2 손실 함수는 640x640의 이미지 크기를 갖는 출력 A와 라벨 A의 이미지 크기를 출력 A의 이미지 크기인 640x640으로 확대 보간하여 생성된 라벨 A' 간의 획득 행렬 크기를 기초로, 출력 A와 라 벨 A' 간의 유사도를 연산하기 위한 손실 함수일 수 있다. 따라서, 제 1 손실 함수와 제 2 손실 함수의 가 중합으로 표현되는 손실 함수는 다음과 같은 [수학식 1]과 같이 나타낼 수 있다. [수학식 1] Ltotal = L1(출력 A', 라벨 A) + α*L2(출력 A, 라벨 A') 이때, L1은 제 1 손실 함수, L2는 제 2 손실 함수를 나타낸다. 그리고, 가중치 α는 제 2 손실 함수 L2에 적용되 어 전체 손실 함수에서 제 2 손실 함수 L2의 비율을 조절할 수 있다. 이와 같이 제 1 손실 함수 L1에 더해 가중 치 α로 비중을 조절 가능한 제 2 손실 함수 L2를 추가적으로 고려함으로써, 프로세서는 신경망 모델(20 0)이 출력에 발생할 수 있는 아티팩트를 최소화 하도록 신경망 모델을 학습시킬 수 있다. 즉, 프로세서 는 제 2 손실 함수를 추가적으로 손실 값 계산에 반영함으로써, 신경망 모델을 보다 효과적으로 학습 시킬 수 있다. 도 3은 본 개시의 일 실시예에 따른 해상도 향상 방법을 나타낸 순서도이다. 그리고, 도 4는 본 개시의 일 실시 예에 따른 신경망 모델의 학습 과정을 나타낸 순서도이다. 도 3을 참조하면, 본 개시의 일 실시예에 따른 컴퓨팅 장치는 복수의 획득 행렬 크기를 갖는 복수의 학습 데이터를 획득할 수 있다(S110). 여기서, 학습 데이터의 획득은 외부 단말, 장치 혹은 시스템과의 무선 통신 네 트워크를 통해 학습 데이터를 수신하는 것 뿐만 아니라, 온-디바이스(on-device) 형태로 학습 데이터를 생성 혹 은 수신하는 것을 지칭하는 것으로 이해될 수 있다. 예를 들어, 컴퓨팅 장치는 영상 촬영 장치와의 클라우 드 통신을 통해 영상 촬영 장치에서 생성된 이미지를 학습 데이터로서 수신할 수 있다. 컴퓨팅 장치는 영 상 촬영 장치에 탑재되어 촬영 이미지를 학습 데이터로서 직접 수집할 수도 있다. 현실적으로 영상 촬영 장치의촬영 조건, 촬영 환경, 사용자의 선호도 등에 따라 획득 행렬 크기가 균일하게 분포된 이미지를 학습 데이터로 획득하는 것은 힘들기 때문에, 컴퓨팅 장치는 다양한 획득 행렬 크기를 갖는 이미지들을 학습 데이터로 획 득할 수 있다. 컴퓨팅 장치는 복수의 학습 데이터에 포함된 라벨들 중 획득 행렬 크기가 최대값인 제 1 라벨의 획득 행렬 크기 이상인 이미지 크기를 갖는 데이터를 출력하는 신경망 모델을 학습시킬 수 있다(S120). 즉, N개(N은 자연 수)의 라벨들이 확보된 상태라고 가정하면, 신경망 모델의 출력의 이미지 크기는 N개의 라벨들 중 획득 행렬 크 기가 가장 큰 제 1 라벨의 획득 행렬 크기보다 클 수 있다. 예를 들어, 제 1 라벨의 획득 행렬 크기가 128x128 이라고 하면, 신경망 모델의 출력은 128x128 이상인 256x256, 512x512 등과 같은 이미지 크기를 가질 수 있다. 컴퓨팅 장치는 이와 같은 신경망 모델의 출력을 그에 대응되는 라벨과 오차를 연산하고, 연산된 오차가 최 소가 되도록 신경망 모델을 학습시킬 수 있다. 보다 구체적으로, 도 4를 참조하면, 컴퓨팅 장치는 신경망 모델을 사용하여, 복수의 학습 데이터에 포함된 입력을 기초로, 제 1 라벨의 획득 행렬 크기 이상인 이미지 크기를 갖는 출력 데이터를 생성할 수 있다(S121). 이때, 신경망 모델은 입력 데이터의 획득 행렬 크기보다 증가된 획득 행렬 크기를 가지면서 제 1 라벨의 획득 행렬 크기 이상인 이미지 크기를 갖는 출력 데이터를 생성할 수 있다. 예를 들어, 입력 데이터의 획득 행렬 크 기가 64x64, 제 1 라벨의 획득 행렬 크기가 128x128, 신경망 모델의 출력의 이미지 크기가 256x256이라고 가정 하면, 신경망 모델은 64x64 이상인 획득 행렬 크기를 가지면서 256x256의 이미지 크기를 갖는 출력 데이터를 생 성할 수 있다. 이때, 컴퓨팅 장치는 신경망 모델의 입력 크기에 맞추어 입력 데이터의 이미지 크기를 조절 할 수 있다. 컴퓨팅 장치는 출력 데이터를 생성하기 위해 사용된 입력에 매칭되는 제 2 라벨의 이미지 크기에 대응되도 록, 출력 데이터의 이미지 크기를 조절할 수 있다(S122). 컴퓨팅 장치는 출력 데이터에 대한 보간을 수행 함으로써, 제 2 라벨의 이미지 크기에 대응되도록, 출력 데이터의 이미지 크기를 축소할 수 있다. 예를 들어, 제 2 라벨의 획득 행렬 크기가 100x100이라고 가정하면, 신경망 모델은 보간을 통해 출력 데이터의 이미지 크기 를 256x256에서 100x100으로 축소할 수 있다. 컴퓨팅 장치는 제 1 손실 함수를 사용하여, S122 단계를 통해 이미지 크기가 조절된 출력 데이터과 제 2 라벨 간의 오차를 연산할 수 있다(S123). 이때, 제 1 손실 함수는, 이미지 크기가 축소된 출력 데이터의 획득 행렬 크기와 제 2 라벨의 획득 행렬 크기 간의 차이를 연산하기 위한 손실 함수일 수 있다. 예를 들어, S122 단 계를 통해 출력 데이터의 이미지 크기와 제 2 라벨의 이미지 크기는 100x100으로 동일할 수 있으나, 출력 데이 터의 획득 행렬 크기와 제 2 라벨의 획득 행렬 크기는 다를 수 있다. 따라서, 컴퓨팅 장치는 제 1 손실 함 수를 사용하여, 출력 데이터의 획득 행렬 크기와 제 2 라벨의 획득 행렬 크기를 기초로, 출력 데이터와 제 2 라 벨 간의 유사도를 손실 값으로 계산할 수 있다. 컴퓨팅 장치는 신경망 모델을 통해 생성된 출력 데이터의 이미지 크기에 대응되도록, 제 2 라벨의 이미지 크기를 조절할 수 있다(S124). 제 2 라벨에 대한 보간을 수행함으로써, 출력 데이터의 이미지 크기에 대응되도 록, 제 2 라벨의 이미지 크기를 확대할 수 있다. 예를 들어, 제 2 라벨의 이미지 크기가 100x100이라고 가정하 면, 신경망 모델은 보간을 통해 제 2 라벨의 이미지 크기를 100x100에서 256x256으로 확대할 수 있다. 한편, S122 단계에서 수행되는 이미지 크기를 축소 혹은 S124 단계에서 수행되는 이미지 크기를 확대하기 위한 보간 기법으로 이중선형 보간법(bilinear interpolation), 바이큐빅 보간법(bicubic interpolation), 최근린 보간법(nearest interpolation) 등과 같은 기법들이 사용될 수 있으나, 본 개시는 이러한 예시에 제한되지 않는 다. 컴퓨팅 장치는 제 2 손실 함수를 통해 상기 생성된 출력 데이터와 이미지 크기가 조절된 제 2 라벨 간의 오차를 연산할 수 있다(S125). 제 2 손실 함수는, 출력 데이터의 획득 행렬 크기와 이미지 크기가 확대된 제 2 라벨의 획득 행렬 크기 간의 차이를 연산하기 위한 손실 함수일 수 있다. 제 2 손실 함수에 따른 오차 연산 결 과는 제 1 손실 함수에 따른 오차 연산 결과에 더해 학습에 함께 활용됨으로써, 신경망 모델이 출력 데이터에서 나타날 수 있는 아티팩트 등을 제거하는데 도움을 줄 수 있다. 컴퓨팅 장치는 제 1 손실 함수를 통한 오차 연산 결과를 기초로 신경망 모델의 파라미터를 업데이트할 수 있다(S126). 컴퓨팅 장치는 제 1 손실 함수를 통해 도출된 오차가 최소가 되도록 신경망 모델의 파라미터 를 업데이트할 수 있다. 컴퓨팅 장치는 제 1 손실 함수를 통한 연산 결과와 제 2 손실 함수를 통한 연산 결과의 가중합을 기초로, 신경망 모델의 파라미터를 업데이트할 수도 있다(S126). 컴퓨팅 장치는 제 1 손실 함수와 제 2 손실 함수의 가중합을 통해 도출된 오차가 최소가 되도록 신경망 모델의 파라미터를 업데이트할 수도 있다. 이와 같이 제 2 손실 함수를 함께 활용하는 경우, 신경망 모델의 출력에서 아티팩트가 생성되지 않 도록 신경망 모델의 특징 해석(혹은 추론)을 효과적으로 유도할 수 있다. 도 5는 본 개시의 대안적 실시예에 따른 해상도 향상 방법을 나타낸 순서도이다. 도 5를 참조하면, 본 개시의 대안적 실시예에 따른 컴퓨팅 장치는 저해상도의 의료 영상을 획득할 수 있다 (S210). 예를 들어, 컴퓨팅 장치는 는 의료 영상 저장 전송 시스템 혹은 자기 공명 영상 장치와 클라우드 통신을 통해 가속화 촬영을 통해 획득된 자기 공명 영상을 수신할 수 있다. 컴퓨팅 장치는 가속화 촬영된 자기 공명 영상을 복원하는 인공지능 기반 장치와 통신을 통해 일반 촬영 수준으로 복원되었으나 저해상도인 자 기 공명 영상을 수신할 수도 있다. 또한, 컴퓨팅 장치는 가속화 촬영된 자기 공명 영상을 복원하는 인공지 능 기반 장치에 탑재되어 저해상도인 자기 공명 영상을 직접 획득할 수도 있다. 컴퓨팅 장치는 사전 학습된 신경망 모델을 사용하여, 저해상도의 의료 영상 대비 해상도가 개선된 고해상 도의 의료 영상을 생성할 수 있다(S220). 이때, 신경망 모델은, 서로 다른 획득 행렬 크기를 갖는 복수의 학습 데이터를 기초로, 복수의 학습 데이터에 포함된 라벨들 중 획득 행렬 크기가 최대값인 제 1 라벨의 획득 행렬 크기 이상인 이미지 크기를 갖는 데이터를 출력하는 신경망을 포함할 수 있다. 컴퓨팅 장치는 상술한 도 4 를 통해 설명한 학습 과정을 통해 학습된 신경망 모델에 저해상도의 의료 영상을 입력하여 고해상도의 의료 영 상을 생성할 수 있다. 예를 들어, 컴퓨팅 장치는 가속화 촬영 후 복원 과정을 통해 획득한 자기 공명 영상을 신경망 모델로 입력 하여 해상도를 개선시킬 수 있다. 이때, 신경망 모델을 통한 해상도의 개선 정도는 신경망 모델을 학습시키기 위해 사용한 학습 데이터의 획득 행렬 크기에 따라 달라질 수 있다. 신경망 모델은 복수의 학습 데이터에 포함 된 라벨들의 획득 행렬 크기 중 최대값에 가깝게 출력을 생성하도록 학습되므로, 자기 공명 영상의 해상도는 신 경망 모델이 학습한 최대 획득 행렬 크기를 기준으로 개선될 수 있다. 앞서 설명된 본 개시의 다양한 실시예는 추가 실시예와 결합될 수 있고, 상술한 상세한 설명에 비추어 당업자가 이해 가능한 범주에서 변경될 수 있다. 본 개시의 실시예들은 모든 면에서 예시적인 것이며, 한정적이 아닌 것으로 이해되어야 한다. 예를 들어, 단일형으로 설명되어 있는 각 구성요소는 분산되어 실시될 수도 있으며, 마 찬가지로 분산된 것으로 설명되어 있는 구성요소들도 결합된 형태로 실시될 수 있다. 따라서, 본 개시의 특허청 구범위의 의미, 범위 및 그 균등 개념으로부터 도출되는 모든 변경 또는 변형된 형태가 본 개시의 범위에 포함 되는 것으로 해석되어야 한다."}
{"patent_id": "10-2024-0007745", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 개시의 일 실시예에 따른 컴퓨팅 장치의 블록도이다. 도 2는 본 개시의 일 실시예에 따른 신경망 모델의 학습 과정을 나타낸 블록도이다. 도 3은 본 개시의 일 실시예에 따른 해상도 향상 방법을 나타낸 순서도이다. 도 4는 본 개시의 일 실시예에 따른 신경망 모델의 학습 과정을 나타낸 순서도이다. 도 5는 본 개시의 대안적 실시예에 따른 해상도 향상 방법을 나타낸 순서도이다."}
