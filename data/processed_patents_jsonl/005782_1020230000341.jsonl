{"patent_id": "10-2023-0000341", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0108710", "출원번호": "10-2023-0000341", "발명의 명칭": "인공지능을 이용한 자세 분류 방법", "출원인": "광주과학기술원", "발명자": "김혜선"}}
{"patent_id": "10-2023-0000341", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "사용자가 촬영된 영상을 수집하는 단계;상기 영상에서 상기 사용자의 관절들을 식별하는 단계;상기 관절들 중 인접한 세 관절이 이루는 사잇각들을 산출하는 단계; 및상기 산출된 사잇각들을 미리 학습된 분류 신경망에 입력하여 상기 사용자의 자세를 분류하는 단계를 포함하는자세 분류 방법."}
{"patent_id": "10-2023-0000341", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 관절들을 식별하는 단계는, 상기 영상을 BlazePose 모델에 입력하여 상기 관절들을 식별하는 단계를 포함하는자세 분류 방법."}
{"patent_id": "10-2023-0000341", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 사잇각들을 산출하는 단계는, 상기 인접한 세 관절의 좌표에 기초하여 사잇각들을 산출하는 단계를 포함하는자세 분류 방법."}
{"patent_id": "10-2023-0000341", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,상기 관절들을 식별하는 단계는, 상기 영상의 뎁스 정보에 기초하여 상기 관절들의 3차원 좌표를 식별하는 단계를 포함하고,상기 사잇각들을 산출하는 단계는, 인접한 제1 내지 제3 관절이 이루는 사잇각을 하기 [수학식]에 따라 산출하는 단계를 포함하는[수학식] (여기서 는 상기 사잇각, a, b, c는 각각 상기 제1, 제2 및 제3 관절의 3차원 좌표)자세 분류 방법."}
{"patent_id": "10-2023-0000341", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "공개특허 10-2024-0108710-3-제4항에 있어서,상기 영상을 깊이 추정(depth estimation) 모델에 입력하여 상기 뎁스 정보를 생성하는 단계를 더 포함하는자세 분류 방법."}
{"patent_id": "10-2023-0000341", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서,상기 분류 신경망은 상기 사용자의 상체 관절에 기초하여 산출된 사잇각들의 특징에 대응하는 상체 클래스와,상기 사용자의 하체 관절에 기초하여 산출된 사잇각들의 특징에 대응하는 하체 클래스를 함께 출력하고,상기 사용자의 자세를 분류하는 단계는, 상기 상체 및 하체 클래스에 따라 상기 사용자의 자세를 분류하는 단계를 포함하는자세 분류 방법."}
{"patent_id": "10-2023-0000341", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에 있어서,상기 사용자의 자세를 분류하는 단계는상기 사잇각들 중 상기 사용자의 상체 관절에 기초하여 산출된 사잇각들을 제1 분류 신경망에 입력하고, 상기사용자의 하체 관절에 기초하여 산출된 사잇각들을 제2 분류 신경망에 입력하는 단계와,상기 제1 및 제2 분류 신경망의 출력에 기초하여 상기 사용자의 자세를 분류하는 단계를 포함하는자세 분류 방법."}
{"patent_id": "10-2023-0000341", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1항에 있어서,상기 사용자의 자세를 분류하는 단계는상기 사용자의 상체 및 하체 중 어느 하나의 관절에 기초하여 산출된 사잇각들을 제1 분류 신경망에 입력하여제1 클래스를 획득하는 단계와,데이터베이스를 참조하여 상기 제1 클래스에 대응하는 제2 분류 신경망을 식별하는 단계와,상기 상체 및 하체 중 다른 하나의 관절에 기초하여 산출된 사잇각들을 상기 제2 분류 신경망에 입력하여 제2클래스를 획득하는 단계와,상기 제1 및 제2 클래스에 따라 상기 사용자의 자세를 분류하는 단계를 포함하는자세 분류 방법."}
{"patent_id": "10-2023-0000341", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서,상기 제1 클래스를 획득하는 단계는, 상기 사용자의 상체 및 하체 중 상기 식별된 관절의 수가 더 적은 어느 하나의 관절에 기초하여 산출된 사잇각들을 상기 제1 분류 신경망에 입력하는 단계를 포함하는자세 분류 방법.공개특허 10-2024-0108710-4-"}
{"patent_id": "10-2023-0000341", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 사용자 관절의 각도에 기초하여 자세를 분류하는 방법에 관한 것이다. 본 발명의 일 실시예에 따른 인 공지능을 이용한 자세 분류 방법은 사용자가 촬영된 영상을 수집하는 단계, 상기 영상에서 상기 사용자의 관절들 을 식별하는 단계, 상기 관절들 중 인접한 세 관절이 이루는 사잇각들을 산출하는 단계 및 상기 산출된 사잇각들 을 미리 학습된 분류 신경망에 입력하여 상기 사용자의 자세를 분류하는 단계를 포함하는 것을 특징으로 한다."}
{"patent_id": "10-2023-0000341", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 사용자 관절의 각도에 기초하여 자세를 분류하는 방법에 관한 것이다."}
{"patent_id": "10-2023-0000341", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "컴퓨터를 통해 사용자의 자세를 추정하는 기술은, 사용자의 의도를 파악하거나 사용자가 처한 상황을 이해하거 나 사용자에게 닥칠 미래 상황을 예측하는데 활용될 수 있어 현재까지 활발하게 연구되어 왔다. 특히, 최근 컴퓨터 비전(computer vision) 기술이 비약적으로 발전하고, 딥러닝의 방법론이 컴퓨터 비전 기술에 접목되면서, 보다 빠르고 정확하게 사용자의 자세를 추정할 수 있는 방법론들이 연구되고 있다. 그러나, 종래의 자세 추정 방법은, 사용자의 일상적인 자세와 비정상적인 자세를 구별하는 등 극단적으로 구분 되는 자세들을 추정하는데 이용되고 있을 뿐이므로 매우 유사한 동작, 예컨대 전통 춤사위 중 걸음사위와 발디 딤사위 간의 차이를 구별해내기 어렵다는 한계가 있다. 선행기술문헌 특허문헌 (특허문헌 0001) 대한민국 등록특허공보 제10-2198470호"}
{"patent_id": "10-2023-0000341", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 영상에서 식별된 사용자 관절의 각도에 기초하여 전통 춤사위를 분류하는 것을 목적으로 한다. 본 발명의 목적들은 이상에서 언급한 목적으로 제한되지 않으며, 언급되지 않은 본 발명의 다른 목적 및 장점들 은 하기의 설명에 의해서 이해될 수 있고, 본 발명의 실시예에 의해 보다 분명하게 이해될 것이다. 또한, 본 발 명의 목적 및 장점들은 특허 청구 범위에 나타낸 수단 및 그 조합에 의해 실현될 수 있음을 쉽게 알 수 있을 것 이다."}
{"patent_id": "10-2023-0000341", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "전술한 목적을 달성하기 위한 본 발명의 일 실시예에 따른 인공지능을 이용한 자세 분류 방법은 사용자가 촬영 된 영상을 수집하는 단계, 상기 영상에서 상기 사용자의 관절들을 식별하는 단계, 상기 관절들 중 인접한 세 관 절이 이루는 사잇각들을 산출하는 단계 및 상기 산출된 사잇각들을 미리 학습된 분류 신경망에 입력하여 상기 사용자의 자세를 분류하는 단계를 포함하는 것을 특징으로 한다. 일 실시예에서, 상기 관절들을 식별하는 단계는, 상기 영상을 BlazePose 모델에 입력하여 상기 관절들을 식별하 는 단계를 포함하는 것을 특징으로 한다. 일 실시예에서, 상기 사잇각들을 산출하는 단계는, 상기 인접한 세 관절의 좌표에 기초하여 사잇각들을 산출하 는 단계를 포함하는 것을 특징으로 한다. 일 실시예에서, 상기 관절들을 식별하는 단계는, 상기 영상의 뎁스 정보에 기초하여 상기 관절들의 3차원 좌표 를 식별하는 단계를 포함하고, 상기 사잇각들을 산출하는 단계는, 인접한 제1 내지 제3 관절이 이루는 사잇각을 하기 [수학식]에 따라 산출하는 단계를 포함하는 것을 특징으로 한다. [수학식] (여기서 는 상기 사잇각, a, b, c는 각각 상기 제1, 제2 및 제3 관절의 3차원 좌표) 일 실시예에서, 상기 영상을 깊이 추정(depth estimation) 모델에 입력하여 상기 뎁스 정보를 생성하는 단계를 더 포함하는 것을 특징으로 한다. 일 실시예에서, 상기 분류 신경망은 상기 사용자의 상체 관절에 기초하여 산출된 사잇각들의 특징에 대응하는 상체 클래스와, 상기 사용자의 하체 관절에 기초하여 산출된 사잇각들의 특징에 대응하는 하체 클래스를 함께 출력하고, 상기 사용자의 자세를 분류하는 단계는, 상기 상체 및 하체 클래스에 따라 상기 사용자의 자세를 분 류하는 단계를 포함하는 것을 특징으로 한다. 일 실시예에서, 상기 사용자의 자세를 분류하는 단계는, 상기 사잇각들 중 상기 사용자의 상체 관절에 기초하여 산출된 사잇각들을 제1 분류 신경망에 입력하고, 상기 사용자의 하체 관절에 기초하여 산출된 사잇각들을 제2 분류 신경망에 입력하는 단계와, 상기 제1 및 제2 분류 신경망의 출력에 기초하여 상기 사용자의 자세를 분류하 는 단계를 포함하는 것을 특징으로 한다. 일 실시예에서, 상기 사용자의 자세를 분류하는 단계는, 상기 사용자의 상체 및 하체 중 어느 하나의 관절에 기 초하여 산출된 사잇각들을 제1 분류 신경망에 입력하여 제1 클래스를 획득하는 단계와, 데이터베이스를 참조하 여 상기 제1 클래스에 대응하는 제2 분류 신경망을 식별하는 단계와, 상기 상체 및 하체 중 다른 하나의 관절에 기초하여 산출된 사잇각들을 상기 제2 분류 신경망에 입력하여 제2 클래스를 획득하는 단계와, 상기 제1 및 제2 클래스에 따라 상기 사용자의 자세를 분류하는 단계를 포함하는 것을 특징으로 한다. 일 실시예에서, 상기 제1 클래스를 획득하는 단계는, 상기 사용자의 상체 및 하체 중 상기 식별된 관절의 수가 더 적은 어느 하나의 관절에 기초하여 산출된 사잇각들을 상기 제1 분류 신경망에 입력하는 단계를 포함하는 것 을 특징으로 한다."}
{"patent_id": "10-2023-0000341", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명은 영상에서 식별된 사용자 관절의 각도에 기초하여 전통 춤사위를 분류함으로써, 사용자가 스스로 전통 춤을 학습하도록 하여 전통춤을 쉽게 계승할 수 있는 환경을 조성할 수 있다. 상술한 효과와 더불어 본 발명의 구체적인 효과는 이하"}
{"patent_id": "10-2023-0000341", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "전술한 목적, 특징 및 장점은 첨부된 도면을 참조하여 상세하게 후술되며, 이에 따라 본 발명이 속하는 기술분 야에서 통상의 지식을 가진 자가 본 발명의 기술적 사상을 용이하게 실시할 수 있을 것이다. 본 발명을 설명함 에 있어서 본 발명과 관련된 공지 기술에 대한 구체적인 설명이 본 발명의 요지를 불필요하게 흐릴 수 있다고판단되는 경우에는 상세한 설명을 생략한다. 이하, 첨부된 도면을 참조하여 본 발명에 따른 바람직한 실시예를 상세히 설명하기로 한다. 도면에서 동일한 참조부호는 동일 또는 유사한 구성요소를 가리키는 것으로 사용된다. 본 명세서에서 제1, 제2 등이 다양한 구성요소들을 서술하기 위해서 사용되나, 이들 구성요소들은 이들 용어에 의해 제한되지 않음은 물론이다. 이들 용어들은 단지 하나의 구성요소를 다른 구성요소와 구별하기 위하여 사용 하는 것으로, 특별히 반대되는 기재가 없는 한, 제1 구성요소는 제2 구성요소일 수도 있음은 물론이다. 또한, 본 명세서에서 \"상부 (또는 하부)\" 또는 구성요소의 \"상 (또는 하)\"에 임의의 구성이 배치된다는 것은, 임의의 구성이 상기 구성요소의 상면 (또는 하면)에 접하여 배치되는 것뿐만 아니라, 상기 구성요소와 상기 구 성요소 상에 (또는 하에) 배치된 임의의 구성 사이에 다른 구성이 개재될 수 있음을 의미할 수 있다. 또한, 본 명세서에서 어떤 구성요소가 다른 구성요소에 \"연결\", \"결합\" 또는 \"접속\"된다고 기재된 경우, 상기 구성요소들은 서로 직접적으로 연결되거나 또는 접속될 수 있지만, 각 구성요소 사이에 다른 구성요소가 \"개 재\"되거나, 각 구성요소가 다른 구성요소를 통해 \"연결\", \"결합\" 또는 \"접속\"될 수도 있는 것으로 이해되어야 할 것이다. 또한, 본 명세서에서 사용되는 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 출원에서, \"구성된다\" 또는 \"포함한다\" 등의 용어는 명세서 상에 기재된 여러 구성 요소들, 또는 여러 단계들을 반드시 모두 포함하는 것으로 해석되지 않아야 하며, 그 중 일부 구성 요소들 또는 일부 단계들 은 포함되지 않을 수도 있고, 또는 추가적인 구성 요소 또는 단계들을 더 포함할 수 있는 것으로 해석되어야 한 다. 또한, 본 명세서에서, \"A 및/또는 B\" 라고 할 때, 이는 특별한 반대되는 기재가 없는 한, A, B 또는 A 및 B를 의미하며, \"C 내지 D\" 라고 할 때, 이는 특별한 반대되는 기재가 없는 한, C 이상이고 D 이하인 것을 의미한다 본 발명은 사용자 관절의 각도에 기초하여 자세를 분류하는 방법에 관한 것이다. 이하, 도 1 내지 도 9를 참조 하여 본 발명의 일 실시예에 따른 인공지능을 이용한 자세 분류 방법(이하, 자세 분류 방법)을 구체적으로 설명 하도록 한다. 도 1은 본 발명의 일 실시예에 따른 인공지능을 이용한 자세 분류 방법을 도시한 순서도이다. 도 2는 본 발명의 일 실시예에 따라 식별되는 관절을 도시한 도면이고, 도 3은 인접한 세 관절이 이루는 사잇각 을 산출하는 과정을 설명하기 위한 도면이다. 도 4는 분류 신경망을 이용한 자세 분류 동작을 설명하기 위한 도면이고, 도 5는 분류 신경망의 일 예시를 도시 한 도면이다. 도 6 및 도 7은 상체 관절 및 하체 관절 각각으로부터 산출된 사잇각들에 따라 상체 자세 및 하체 자세를 분류 하는 과정을 설명하기 위한 도면이다. 도 8 및 도 9는 상체 자세 및 하체 자세에 대한 클래스를 예시적으로 도시한 도면이다. 도 1을 참조하면, 본 발명의 일 실시예에 따른 자세 분류 방법은 사용자가 촬영된 영상을 수집하는 단계(S10), 영상에서 사용자의 관절들을 식별하는 단계(S20), 인접한 세 관절이 이루는 사잇각들을 산출하는 단계(S30), 사 잇각들을 분류 신경망에 입력하는 단계(S40) 및 분류 신경망의 출력에 따라 자세를 분류하는 단계(S50)를 포함 할 수 있다. 다만, 도 1에 도시된 자세 분류 방법은 일 실시예에 따른 것이고, 발명을 이루는 각 단계들이 도 1에 도시된 실 시예에 한정되는 것은 아니며, 필요에 따라 일부 단계들이 부가, 변경 또는 삭제될 수 있다. 한편, 본 발명의 자세 분류 방법은 프로세서에 의해 수행될 수 있으며, 후술하는 동작을 위해 프로세서는 CPU(central processing unit), GPU(graphics processing unit) 등으로 구현될 수 있으며, ASICs(application specific integrated circuits), DSPs(digital signal processors), DSPDs(digital signal processing devices), PLDs(programmable logic devices), FPGAs(field programmable gate arrays), 제어기(controller), 마이크로 컨트롤러(micro-controllers) 중 적어도 하나의 물리적인 요소를 포함할 수 있다. 이하, 도 1에 도시된 각 단계들을 구체적으로 설명하도록 한다. 프로세서는 사용자가 촬영된 영상을 수집할 수 있다(S10). 여기서 영상은 적어도 한 프레임의 이미지를 포함할 수 있다. 프로세서는 카메라와 데이터 통신을 수행하여 실시간으로 영상을 수집할 수도 있으며, 데이터베이스로부터 영상을 불러오는 방식으로 영상을 수집할 수도 있다. 프로세서와 데이터 통신을 수행하는 카메라는 가시광 카메라이거나 3D 뎁스 카메라일 수 있고, 카메라가 3D 뎁 스(depth) 카메라인 경우 프로세서에 제공되는 영상에는 영상 내 촬영된 객체의 뎁스 정보가 더 포함될 수 있다. 이어서, 프로세서는 영상에서 사용자의 관절들을 식별할 수 있다(S20). 구체적으로, 프로세서는 영상에 다양한 이미지 프로세싱 기법을 적용하여 사용자 신체의 각 관절들을 식별할 수 있다. 일 실시예에서, 프로세서는 관절 검출(skeleton detection) 태스크를 수행하는 객체 검출(object detection) 신경망에 영상을 입력하여 관절의 위치를 식별할 수 있다. 이 때, 객체 검출 신경망은 자세 추정 (pose estimation)을 위해 이용되는 다양한 아키텍처를 포함할 수 있고, 예컨대 BlazePose(On-device Real- time Body Pose Tracking) 모델로 구현될 수 있다. 도 2를 참조하면, 프로세서가 BlazePose 모델에 영상을 입력한 경우, 총 33개의 관절이 식별될 수 있고, 구체적 으로는 상체 관절 14개와 하체 관절 8개가 식별될 수 있다. 한편, 관절 검출 정확도를 향상시키기 위하여, 프로세서는 관절 검출에 앞서 영상을 전처리(pre-processing)할 수 있고, 이를 위해 크로핑(cropping), 히스토그램 평활화(histogram equalization), 정규화(normalization), 감마 보정(gamma correction) 등의 알고리즘이 이용될 수 있다. 이어서, 프로세서는 단계(S20)에서 식별된 관절들 중 인접한 세 관절이 이루는 사잇각들을 산출할 수 있다 (S30). 후술하는 바와 같이 본 발명의 자세 분류 방법은 전통 춤사위를 인식하는데 이용될 수 있는데, 춤사위의 경우 관절의 절대적인 위치보다는 관절의 각도가 각 춤사위를 구별할 수 있는 요소이므로 본 발명에서 프로세서 는 관절들이 이루는 사잇각들을 산출할 수 있다. 구체적으로, 프로세서는 인접한 세 관절의 좌표에 기초하여 사잇각들을 산출할 수 있다. 이 때, 좌표는 관절 검 출 태스크를 수행하는 객체 검출 신경망에 의해 특정될 수도 있으며, 프로세서가 각 관절의 영상 내 위치에 기 초하여 각 관절의 좌표를 결정할 수도 있다. 한편, 프로세서는 3차원 좌표에 기초하여 사잇각들을 산출할 수도 있다. 앞서 설명한 바와 같이, 영상에는 뎁스 정보가 더 포함될 수 있고, 프로세서는 뎁스 정보에 기초하여 각 관절의 3차원 좌표를 식별할 수 있다. 이와 달리, 영상에 뎁스 정보가 포함되지 않는 경우 프로세서는 해당 영상을 깊이 추정(depth estimation) 모델 에 입력하여 각 관절의 뎁스 정보를 생성할 수도 있다. 깊이 추정 모델로는 FCRN(Deeper Depth Prediction with Fully Convolutional Residual Networks), DORN(Deep Ordinal Regression Network for Monocluar Depth Estimation), Monodepth(Unsupervised Monocular Depth Estimation with Left-Right Consistency), Monodepth2(Digging into Self-Supervised Monocluar Depth Prediction) 등이 이용될 수 있다. 도 3을 예로 들어 설명하면, 프로세서는 2차원 영상을 이용하여 인접한 제1 내지 제3 관절(a, b, c)의 x, y 좌 표를 식별할 수 있고, 뎁스 정보를 더 이용하여 제1 내지 제3 관절(a, b, c)의 z 좌표를 추가 식별할 수 있다. 이에 따라, 제1 내지 제3 관절(a, b, c)의 3차원 좌표는 각각 (xa, ya, za), (xb, yb, zb), (zc, yc, zc)로 결정 될 수 있다. 이어서, 프로세서는 아래 [수학식 1]에 따라 제1 내지 제3 관절(a, b, c)이 이루는 사잇각( )을 산출할 수 있다. [수학식 1]"}
{"patent_id": "10-2023-0000341", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "구체적으로, 프로세서는 제1 및 제2 관절(a, b)을 연결하는 선과, 제2 및 제3 관절(b, c)을 연결하는 선을 아래 [수학식 2]에 따라 벡터화하고, 이를 [수학식 1]에 대입하여 제1 내지 제3 관절(a, b, c)이 이루는 사잇각을 산 출할 수 있다. [수학식 2]"}
{"patent_id": "10-2023-0000341", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "이러한 방식에 따라 프로세서는 단계(S20)에서 식별된 모든 관절 중 인접한 임의의 세 관절이 이루는 사잇각들 을 산출할 수 있다. 이와 같이 산출된 관절의 각도는 영상에 촬영된 사용자의 크기에 관계없이 일정하므로, 본 발명에 의하면 영상의 전처리 과정을 간소하게 할 수 있으며, 후술하는 분류 신경망의 강건성(robustness) 을 높일 수 있다는 장점이 있다. 이어서, 프로세서는 사잇각들을 미리 학습된 분류 신경망에 입력할 수 있다(S40). 여기서 분류 신경망 은 사잇각들의 특징을 추출하고, 추출된 특징에 기초하여 사용자의 자세에 대한 클래스(class)를 출력할 수 있 다. 본 발명에서 분류 신경망은 CNN(Convolutional Neural Network), LSTM(Long Short-Term Menory), Bi- LSTM(Bi-directional LSTM) 등으로 구현될 수 있다. 구체적으로, 분류 신경망은 사용자의 상체 관절에 기초하여 산출된 사잇각들의 특징에 대응하는 제1 클래스 와, 사용자의 하체 관절에 기초하여 산출된 사잇각들의 특징에 대응하는 제2 클래스를 함께 출력할 수 있다. 도 4를 참조하여 설명하면, 일 예에서 프로세서는 단계(S30)에서 산출된 사잇각들( )을 분류 신경 망에 입력할 수 있고, 분류 신경망은 상체 자세 및 하체 자세에 대응하는 클래스(CU, CL)를 각각 출력할 수 있다. 이러한 동작을 위해, 분류 신경망은 미리 지도 학습(supervised learning)될 수 있다. 구체적으로, 분류 신경망은 다양한 상체 및 하체 자세가 표현된 학습 영상에서 산출된 관절의 사잇각들을 입력 데이터로 하고, 상체 및 하체 자세에 대응하는 실측값(Ground Truth; GT), 즉 클래스(class)를 출력 데이 터로 하는 훈련 데이터셋(training dataset)에 기초하여 지도 학습될 수 있다. 여기서 실측값은 사용자에 의해 미리 라벨링(labeling)될 수 있다. 예컨대, 도 8을 참조하면 프로세서는 18가지의 상체 춤사위를 표현하는 복수의 학습 영상으로부터 산출된 사잇 각들을 분류 신경망의 입력 데이터로 설정할 수 있고, 해당 춤사위에 대응하는 클래스(CU1 내지 CU18)를 분 류 신경망의 출력 데이터로 설정하여 분류 신경망을 지도 학습시킬 수 있다. 또한, 도 9를 참조하면, 프로세서는 6가지의 하체 춤사위를 표현하는 복수의 학습 영상으로부터 산출된 사잇각 들을 분류 신경망의 입력 데이터로 설정할 수 있고, 해당 춤사위에 대응하는 클래스(CL1 내지 CL6)를 분류 신경망의 출력 데이터로 설정하여 분류 신경망을 지도 학습시킬 수 있다. 이러한 지도 학습을 통해 분류 신경망은 학습 영상에서 산출된 상체 관절 및 하체 관절들의 사잇각과 춤사 위의 클래스(CU1 내지 CU18, CL1 내지 CL6) 간의 상관관계를 학습할 수 있고, 학습이 완료된 이후에는, 학습에 이용되지 않은 사잇각들( )에 대해서도 사용자의 춤사위가 무엇인지 분류할 수 있다. 도 5를 참조하면, 프로세서는 사잇각들( )을 앞서 설명한 방법에 따라 지도 학습된 Bi-LSTM(Bi- directional LSTM) 분류 신경망에 입력할 수 있다. 분류 신경망은 순차 연결된 셀을 통해 정방향 및 역 방향으로 사잇값들( )에 대한 은닉값을 추출할 수 있고, 정방향 및 역방향 셀에서 추출된 은닉값 들은 결합(concatenation)될 수 있다. 결합된 은닉값들은 소프트맥스(softmax) 함수에 적용될 수 있고, 결과적 으로 분류 신경망은 상체 및 하체 자세에 대응하는 두 클래스(이하, 상체 클래스(CU) 및 하체 클래스(CL))를 출력할 수 있다. 프로세서는 분류 신경망에서 출력되는 클래스에 기초하여 사용자의 자세를 분류할 수 있으며(S50), 앞선 예 에서 프로세서는 상체 및 하체 클래스(CU, CL)에 따라 사용자의 자세를 분류할 수 있다. 예를 들어, 프로세서는 분류 신경망에서 출력된 상체 클래스(CU)에 기초하여 사용자의 윗몸사위가 무엇인지 분류할 수 있고, 분류 신경망에서 출력된 하체 클래스(CL)에 기초하여 사용자의 아랫몸사위가 무엇인지 분류 할 수 있다. 구체적으로 도 8 및 도 9를 참조하면, 분류 신경망에서 출력된 상체 및 하체 클래스(CU, CL)가 각각 CU2, CL6인 경우 프로세서는 사용자의 윗몸사위를 팔뻗음사위로, 아랫몸사위를 발건넘사위로 분류할 수 있 다. 한편, 전술한 바와 같이 본 발명이 전통 춤사위를 분류하는 데 이용되는 경우, 윗몸사위와 아랫몸사위는 서로 독립적으로 분류될 수 있으므로, 프로세서는 두 개의 분류 신경망(10a, 10b)을 각각 이용하여 자세를 분류할 수 있다. 도 6을 참조하면, 프로세서는 사용자의 상체 관절에 기초하여 산출된 사잇각들( )을 제1 분류 신 경망(10a)에 입력하고, 사용자의 하체 관절에 기초하여 산출된 사잇각들( )을 제2 분류 신경망 (10b)에 입력할 수 있다. 제1 및 제2 분류 신경망(10a, 10b)은 각각 상체 클래스(CU) 및 하체 클래스(CL)를 출 력할 수 있고, 프로세서는 상체 및 하체 클래스(CU, CL)에 따라 사용자의 자세를 분류할 수 있다. 이 경우, 제1 분류 신경망(10a)은 상체 춤사위를 표현하는 복수의 학습 영상으로부터 산출된 사잇각과, 이에 대 응하는 상체 클래스에 의해서만 학습될 수 있고, 제2 분류 신경망(10b)은 하체 춤사위를 표현하는 복수의 학습 영상으로부터 산출된 사잇각과, 이에 대응하는 하체 클래스에 의해서만 학습될 수 있다. 제1 및 제2 분류 신경망(10b)은 독립적으로 동작하며 병렬적으로 학습되므로, 도 4에 도시된 분류 신경망에 비해 도 6에 도시된 제1 및 제2 분류 신경망(10a, 10b)은 더욱 빠른 속도로 학습될 수 있다. 한편, 본 발명이 전통 춤사위를 분류함으로써 사용자가 전통 춤사위를 정확하게 따라하고 있는지 판단하는데 이 용되는 경우, 상체 및 하체 중 어느 하나의 동작이 전통 춤사위가 아니라고 판단되면 다른 하나의 동작에 대한 분류 동작을 수행하지 않을 수 있다. 이를 위해, 프로세서는 제1 분류 신경망(10a)을 통해 상체 및 하체 동작 중 어느 하나를 분류하고, 분류된 클래 스가 전통 춤사위에 해당되는 경우에 한해 다른 하나에 대한 분류 동작을 수행할 수 있다. 구체적으로, 프로세서는 사용자의 상체 및 하체 중 어느 하나의 관절에 기초하여 산출된 사잇각들을 제1 분류 신경망(10a)에 입력하여 제1 클래스 및 신뢰도를 획득할 수 있다. 프로세서는 제1 분류 신경망(10a)에서 출력된 신뢰도가 기준값(예컨대, 90%) 이상이면 사용자의 상체 및 하체 중 어느 하나의 동작이 전통 춤사위에 해당하는 것으로 판단할 수 있고, 상체 및 하체 중 다른 하나의 관절에 기초하여 산출된 사잇각들을 제2 분류 신경망(10b)에 입력하여 제2 클래스를 획득할 수 있다. 이어서, 프로세서 는 제 1 및 제2 클래스에 따라 사용자의 윗몸사위 및 아랫몸사위를 분류할 수 있다. 한편, 전통 춤사위의 경우 윗몸사위와 아랫몸사위의 조합이 미리 정의될 수 있다. 도 8 및 도 9를 예로 들면, '발디딤사위와 발돋움사위'의 아랫몸사위에는 '인사위, 팔뻗음사위, 손모양사위, 손바닥모둠사위, 안음사위, 성주사위'가 조합될 수 있다. 즉, 아랫몸사위가 발디딤사위 또는 발돋움사위일 때 윗몸사위가 앞서 나열된 것들 이 아닌 경우 사용자의 자세가 전통 춤사위에 해당되지 않을 수 있다. 이러한 특수성을 고려하여, 프로세서는 전통 춤사위에 따라 조합될 수 있는 윗몸사위-아랫몸사위에 대한 분류 신경망을 각각 학습시켜 데이터베이스에 저장할 수 있고, 윗몸사위 및 아랫몸사위 중 어느 하나에 대한 분 류 동작을 먼저 수행한 뒤, 분류 결과에 대응하는 분류 신경망을 선택하여 나머지 하나에 대한 분류 동작을 수행할 수 있다. 구체적으로, 프로세서는 사용자의 상체 및 하체 중 어느 하나의 관절에 기초하여 산출된 사잇각들을 제1 분류 신경망(10a)에 입력하여 제1 클래스를 획득할 수 있다. 이어서, 프로세서는 제1 클래스에 대응하는 제2 분류 신 경망(10b)을 데이터베이스를 참조하여 식별한 뒤, 다른 하나의 관절에 기초하여 산출된 사잇각들을 제2 분류 신 경망(10b)에 입력하여 제2 클래스를 획득할 수 있다. 이 때, 프로세서는 사용자의 상체 및 하체 중 단계(S20)에서 식별된 관절의 수가 더 적은 어느 하나의 관절에 기초하여 분류 동작을 먼저 수행할 수 있다. 즉, 본 실시예에서 프로세서는 두 번의 연속적은 분류 동작을 수행 하여 사용자의 동작이 전통 춤사위에 해당하는지 판단하는데, 상체 및 하체 중 어느 하나의 동작이라도 전통 춤 사위에 해당하지 않으면 다른 하나에 대한 분류 동작을 수행할 필요가 없으므로, 프로세서는 입력 데이터의 수 가 더 적은, 다시 말해, 파라미터(가중치(weight), 바이어스(bias))의 수가 더 적어 빠르게 학습되고 신뢰도가 높은 분류 신경망을 통해 우선적으로 분류 동작을 수행할 수 있다. 도 7을 참조하면, 프로세서는 관절의 수가 더 적은 하체의 관절에 기초하여 산출된 사잇각들( ) 을 제1 분류 신경망(10a)에 입력하여 하체 클래스(CL)를 획득할 수 있다. 이어서, 프로세서는 데이터베이스를 인덱싱하여 앞서 획득된 하체 클래스(CL)에 대응하는 제2 분류 신경망(10b)을 식별할 수 있다.예를 들어, 제1 분류 신경망(10a)에서 출력된 하체 클래스(CL)가 '발디딤사위'에 대응하는 경우, 프로세서는 ' 발디딤사위'에 조합될 수 있는 '윗몸사위, 예컨대 팔뻗음사위, 손모양사위, 손바닥모둠사위, 안음사위, 성주사 위'를 분류할 수 있는 제2 분류 신경망(10b)을 데이터베이스에서 식별할 수 있다. 이어서, 프로세서는 상체 관절에 기초하여 산출된 사잇각들( )을 제2 분류 신경망(10b)에 입력하 여 상체 클래스(CU)를 획득할 수 있고, 상체 및 하체 클래스(CU, CL)에 따라 사용자의 자세를 분류할 수 있다. 전술한 바와 같이, 본 발명은 영상에서 식별된 사용자 관절의 각도에 기초하여 전통 춤사위를 분류함으로써, 사 용자가 스스로 전통춤을 학습하도록 하여 전통춤을 쉽게 계승할 수 있는 환경을 조성할 수 있다. 이상과 같이 본 발명에 대해서 예시한 도면을 참조로 하여 설명하였으나, 본 명세서에 개시된 실시 예와 도면에 의해 본 발명이 한정되는 것은 아니며, 본 발명의 기술사상의 범위 내에서 통상의 기술자에 의해 다양한 변형이 이루어질 수 있음은 자명하다. 아울러 앞서 본 발명의 실시 예를 설명하면서 본 발명의 구성에 따른 작용 효과 를 명시적으로 기재하여 설명하지 않았을 지라도, 해당 구성에 의해 예측 가능한 효과 또한 인정되어야 함은 당 연하다."}
{"patent_id": "10-2023-0000341", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일 실시예에 따른 인공지능을 이용한 자세 분류 방법을 도시한 순서도. 도 2는 본 발명의 일 실시예에 따라 식별되는 관절을 도시한 도면. 도 3은 인접한 세 관절이 이루는 사잇각을 산출하는 과정을 설명하기 위한 도면. 도 4는 분류 신경망을 이용한 자세 분류 동작을 설명하기 위한 도면. 도 5는 분류 신경망의 일 예시를 도시한 도면. 도 6 및 도 7은 상체 관절 및 하체 관절 각각으로부터 산출된 사잇각들에 따라 상체 자세 및 하체 자세를 분류 하는 과정을 설명하기 위한 도면. 도 8 및 도 9는 상체 자세 및 하체 자세에 대한 클래스를 예시적으로 도시한 도면."}
