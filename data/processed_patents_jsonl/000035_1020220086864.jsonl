{"patent_id": "10-2022-0086864", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0090981", "출원번호": "10-2022-0086864", "발명의 명칭": "최적 치료경로를 계획하고 탐색하기 위한 인공지능 장치 및 그 동작 방법", "출원인": "한국전자통신연구원", "발명자": "최재훈"}}
{"patent_id": "10-2022-0086864", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "EMR 데이터베이스로부터 환자의 전자 의무 기록(EMR)을 제공 받아 상기 환자의 상태, 상기 환자에게 적용된 치료방법, 및 상기 환자의 치료경과를 포함하는 에피소드로 변환하여 에피소드 데이터베이스에 저장하는 에피소드변환 모듈;상기 환자에게 치료방법을 적용한 후 상기 환자의 다음 상태를 예측하는 환자상태 예측지능을 학습하는 환자상태 예측지능 딥러닝 모듈;상기 에피소드 데이터베이스에 저장된 에피소드에 기반하여 상기 환자에 대한 최적 치료경로 탐색을 위한 정책지능을 강화학습하는 로컬 정책지능 강화학습 모듈;상기 정책지능을 이용하여 상기 환자에 대한 최적 치료경로를 출력하는 최적 치료경로 탐색 모듈; 및상기 정책지능에 기반하여 최적 치료경로 탐색을 위한 글로벌 정책지능을 업데이트하는 글로벌 정책지능 관리모듈을 포함하는 인공지능 장치."}
{"patent_id": "10-2022-0086864", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1 항에 있어서,상기 에피소드는 상기 환자의 제 1 상태, 상기 환자에게 적용된 치료방법, 상기 치료방법을 적용한 후 상기 환자의 제 2 상태, 및 상기 환자의 치료경과의 순서를 갖는 시계열인 인공지능 장치."}
{"patent_id": "10-2022-0086864", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 1 항에 있어서,상기 환자상태 예측지능은 상기 환자에게 치료방법을 적용한 경우 전이될 수 있는 복수의 상태들 및 상기 복수의 상태들 각각으로 전이될 수 있는 확률을 예측하는 시계열 혼합 확률분포 모델인 인공지능 장치."}
{"patent_id": "10-2022-0086864", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 1 항에 있어서,상기 정책지능은 상기 환자의 상태에 기반한 예측을 통해 적합한 치료방법을 계획하는 치료방법 계획지능 및 상기 환자의 상태 및 상기 예측된 치료방법에 기반하여 상기 환자의 치료경과를 판단하는 치료경과 판단지능을 포함하고,상기 글로벌 정책지능은 글로벌 치료방법 계획지능 및 글로벌 치료경과 판단지능을 포함하는 인공지능 장치."}
{"patent_id": "10-2022-0086864", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제 1 항에 있어서,상기 글로벌 정책지능 관리 모듈은 외부 의료 기관으로부터 페더레이션 메시지 또는 동기화 메시지를 수신하거나, 또는 외부 의료 기관으로 페더레이션 메시지 또는 동기화 메시지를 발신하는 인공지능 장치."}
{"patent_id": "10-2022-0086864", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제 5 항에 있어서,상기 글로벌 정책지능 관리 모듈은:상기 페더레이션 메시지에 응답하여, 상기 외부 의료 기관으로부터 상기 외부 의료 기관의 정책지능의 학습 결과를 제공 받아 상기 글로벌 정책지능을 업데이트하고, 그리고공개특허 10-2023-0090981-3-상기 동기화 메시지에 응답하여, 상기 외부 의료 기관으로 상기 글로벌 정책지능을 제공하는 인공지능 장치."}
{"patent_id": "10-2022-0086864", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "환자의 전자 의무 기록(EMR)을 제공 받아 상기 환자의 상태, 상기 환자에게 적용된 치료방법, 및 상기 환자의치료경과를 포함하는 에피소드로 변환하는 단계;상기 환자에게 치료방법을 적용한 후 상기 환자의 다음 상태를 예측하는 환자상태 예측지능을 학습하는 단계;상기 에피소드에 기반하여 상기 환자에 대한 최적 치료경로 탐색을 위한 정책지능을 강화학습하는 단계;상기 정책지능에 기반하여 정책지능 강화학습을 위한 글로벌 정책지능을 업데이트하는 단계; 및상기 정책지능을 이용하여 상기 환자에 대한 최적 치료경로를 출력하는 단계를 포함하는 인공지능 장치의 동작방법."}
{"patent_id": "10-2022-0086864", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제 7 항에 있어서,상기 에피소드로 변환하는 단계는:EMR 데이터베이스로부터 상기 환자에 대한 EMR을 읽어오고, 에피소드를 초기화하는 단계;상기 환자에 대한 상기 EMR을 검사기록 테이블 및 치료기록 테이블로 분리하고, 상기 검사기록 테이블 및 상기치료기록 테이블을 각각 시간 순서대로 정렬하는 단계;상기 치료기록 테이블에 기반하여 상기 환자에게 적용되는 치료방법 식별자를 생성하는 단계;상기 검사기록 테이블에 기반하여 상기 치료방법을 적용하기 전 상기 환자의 제 1 상태 식별자, 및 상기 치료방법을 적용한 후 상기 환자의 제 2 상태 식별자를 생성하는 단계;상기 검사기록 테이블에 기반하여 상기 치료방법을 적용한 후 상기 환자의 치료경과 식별자를 생성하는 단계;및상기 치료 식별자, 상기 제 1 상태 식별자, 상기 제 2 상태 식별자, 및 상기 치료경과 식별자에 기반하여 상기에피소드를 업데이트하는 단계를 포함하는 인공지능 장치의 동작 방법."}
{"patent_id": "10-2022-0086864", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제 7 항에 있어서,상기 환자상태 예측지능은 상기 환자에게 치료방법을 적용한 경우 전이될 수 있는 복수의 상태들 및 상기 복수의 상태들 각각으로 전이될 수 있는 확률을 예측하는 시계열 확률분포 모델인 인공지능 장치의 동작 방법."}
{"patent_id": "10-2022-0086864", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제 7 항에 있어서,상기 정책지능은 상기 환자의 상태에 기반한 예측을 통해 적합한 치료방법을 계획하는 치료방법 계획지능 및 상기 환자의 상태 및 상기 예측된 치료방법에 기반하여 상기 환자의 치료경과를 판단하는 치료경과 판단지능을 포함하고,상기 글로벌 정책지능은 글로벌 치료방법 계획지능 및 글로벌 치료경과 판단지능을 포함하는 인공지능 장치의동작 방법."}
{"patent_id": "10-2022-0086864", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제 10 항에 있어서,상기 정책지능을 강화학습하는 단계는:에피소드 데이터베이스로부터 상기 환자에 대한 에피소드를 샘플링하는 단계;상기 치료방법 계획지능 및 상기 치료경과 판단지능을 상기 글로벌 치료방법 계획지능 및 상기 글로벌 치료경과공개특허 10-2023-0090981-4-판단지능으로 동기화하는 단계;상기 치료방법 계획지능에 대한 제 1 가중치 및 상기 치료경과 판단지능에 대한 제 2 가중치를 조절하는 단계;상기 치료방법 계획지능을 통해 상기 환자에 대한 치료방법을 예측하는 단계;상기 환자상태 예측지능을 통해 상기 환자에게 상기 치료방법을 적용하였을 때 상기 환자의 상태 및 상기 환자의 치료경과를 예측하는 단계;상기 치료방법, 상기 상태, 및 상기 치료경과에 기반하여 제 1 에피소드를 생성하는 단계; 및상기 제 1 단위배치에 기반하여 상기 치료방법 계획지능 및 상기 치료경과 판단지능의 파라미터들을 업데이트하는 단계를 포함하되,상기 제 1 가중치는 상기 글로벌 치료방법 계획지능의 파라미터들이 상기 치료방법 계획지능에 반영되는 비율을나타내고, 상기 제 2 가중치는 상기 글로벌 치료경과 판단지능의 파라미터들이 상기 치료경과 판단지능에 반영되는 비율을 나타내는 인공지능 장치의 동작 방법."}
{"patent_id": "10-2022-0086864", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제 11 항에 있어서,상기 파라미터들을 업데이트하는 단계는:상기 에피소드 데이터베이스로부터 상기 제 1 에피소드와 유사한 제 2 에피소드를 샘플링하는 단계; 및상기 제 2 에피소드에 기반하여 상기 치료경과 판단지능의 파라미터들을 업데이트하는 단계를 포함하는 인공지능 장치의 동작 방법."}
{"patent_id": "10-2022-0086864", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제 7 항에 있어서,상기 글로벌 정책지능을 업데이트하는 단계는:외부 의료 기관으로부터 메시지를 수신하는 단계;상기 메시지가 동기화 메시지인 경우, 상기 외부 의료 기관으로 상기 글로벌 정책지능을 전송하는 단계; 및상기 메시지가 페더레이션 메시지인 경우, 상기 외부 의료 기관으로부터 제공 받은 상기 외부 의료 기관의 정책지능을 이용하여 상기 글로벌 정책지능을 업데이트하는 단계를 포함하는 인공지능 장치의 동작 방법."}
{"patent_id": "10-2022-0086864", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "프로그램 코드를 포함하는 비일시적 컴퓨터 판독 가능 매체에 있어서, 프로세서에 의해 상기 프로그램 코드가실행될 때, 상기 프로세서는:환자의 전자 의무 기록(EMR)을 제공 받아 상기 환자의 상태, 상기 환자에게 적용된 치료방법, 및 상기 환자의치료경과를 포함하는 에피소드로 변환하고,상기 환자에게 치료방법을 적용한 후 상기 환자의 다음 상태를 예측하는 환자상태 예측지능을 학습하고,상기 에피소드에 기반하여 상기 환자에 대한 최적 치료경로 탐색을 위한 정책지능을 강화학습하고,상기 정책지능을 이용하여 상기 환자에 대한 최적 치료경로를 출력하고, 그리고상기 정책지능에 기반하여 최적 치료경로 탐색을 위한 글로벌 정책지능을 업데이트하는 비일시적 컴퓨터 판독가능 매체."}
{"patent_id": "10-2022-0086864", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제 14 항에 있어서,상기 에피소드로 변환하는 것은:EMR 데이터베이스로부터 상기 환자에 대한 EMR을 읽어오고, 에피소드를 초기화하고,공개특허 10-2023-0090981-5-상기 환자에 대한 상기 EMR을 검사기록 테이블 및 치료기록 테이블로 분리하고, 상기 검사기록 테이블 및 상기치료기록 테이블을 각각 시간 순서대로 정렬하고,상기 치료기록 테이블에 기반하여 상기 환자에게 적용되는 치료방법 식별자를 생성하고,상기 검사기록 테이블에 기반하여 상기 치료방법을 적용하기 전 상기 환자의 제 1 상태 식별자, 및 상기 치료방법을 적용한 후 상기 환자의 제 2 상태 식별자를 생성하고,상기 검사기록 테이블에 기반하여 상기 치료방법을 적용한 후 상기 환자의 치료경과 식별자를 생성하고, 그리고상기 치료 식별자, 상기 제 1 상태 식별자, 상기 제 2 상태 식별자, 및 상기 치료경과 식별자에 기반하여 상기에피소드를 업데이트하는 것을 포함하는 비일시적 컴퓨터 판독 가능 매체."}
{"patent_id": "10-2022-0086864", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제 14 항에 있어서,상기 환자상태 예측지능은 상기 환자에게 치료방법을 적용한 경우 전이될 수 있는 복수의 상태들 및 상기 복수의 상태들 각각으로 전이될 수 있는 확률을 예측하는 시계열 확률분포 모델인 비일시적 컴퓨터 판독 가능 매체."}
{"patent_id": "10-2022-0086864", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제 14 항에 있어서,상기 정책지능은 상기 환자의 상태에 기반한 예측을 통해 치료방법을 계획하는 치료방법 계획지능 및 상기 환자의 상태 및 상기 예측된 치료방법에 기반하여 상기 환자의 치료경과를 판단하는 치료경과 판단지능을 포함하고,상기 글로벌 정책지능은 글로벌 치료방법 계획지능 및 글로벌 치료경과 판단지능을 포함하는 비일시적 컴퓨터판독 가능 매체."}
{"patent_id": "10-2022-0086864", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제 17 항에 있어서,상기 정책지능을 강화학습하는 것은:에피소드 데이터베이스로부터 상기 환자에 대한 에피소드를 샘플링하고,상기 치료방법 계획지능 및 상기 치료경과 판단지능을 상기 글로벌 치료방법 계획지능 및 상기 글로벌 치료경과판단지능으로 동기화하고,상기 치료방법 계획지능에 대한 제 1 가중치 및 상기 치료경과 판단지능에 대한 제 2 가중치를 조절하고,상기 치료방법 계획지능을 통해 상기 환자에 대한 치료방법을 예측하고,상기 환자상태 예측지능을 통해 상기 환자에게 상기 치료방법을 적용하였을 때 상기 환자의 상태 및 상기 환자의 치료경과를 예측하고,상기 치료방법, 상기 상태, 및 상기 치료경과에 기반하여 제 1 에피소드를 생성하고, 그리고상기 제 1 단위배치에 기반하여 상기 치료방법 계획지능 및 상기 치료경과 판단지능의 파라미터들을 업데이트하는 것을 포함하되,상기 제 1 가중치는 상기 글로벌 치료방법 계획지능의 파라미터들이 상기 치료방법 계획지능에 반영되는 비율을나타내고, 상기 제 2 가중치는 상기 글로벌 치료경과 판단지능의 파라미터들이 상기 치료경과 판단지능에 반영되는 비율을 나타내는 비일시적 컴퓨터 판독 가능 매체."}
{"patent_id": "10-2022-0086864", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제 18 항에 있어서,상기 파라미터들을 업데이트하는 것은:상기 에피소드 데이터베이스로부터 상기 제 1 에피소드와 유사한 제 2 에피소드를 샘플링하고, 그리고공개특허 10-2023-0090981-6-상기 제 2 에피소드에 기반하여 상기 치료경과 판단지능의 파라미터들을 업데이트하는 것을 포함하는 비일시적컴퓨터 판독 가능 매체."}
{"patent_id": "10-2022-0086864", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제 14 항에 있어서,상기 글로벌 정책지능을 업데이트하는 것은:외부 의료 기관으로부터 메시지를 수신하고,상기 메시지가 동기화 메시지인 경우, 상기 외부 의료 기관으로 상기 글로벌 정책지능을 전송하고, 그리고상기 메시지가 페더레이션 메시지인 경우, 상기 외부 의료 기관으로부터 제공 받은 상기 외부 의료 기관의 정책지능을 이용하여 상기 글로벌 정책지능을 업데이트하는 것을 포함하는 비일시적 컴퓨터 판독 가능 매체."}
{"patent_id": "10-2022-0086864", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 개시의 실시 예에 따른 인공지능 장치는 EMR 데이터베이스로부터 환자의 전자의무기록(EMR)을 제공 받아 상기 환자의 상태, 상기 환자에게 적용된 치료방법, 및 상기 환자의 치료경과를 포함하는 에피소드로 변환하여 에피소 드 데이터베이스에 저장하는 에피소드 변환 모듈, 상기 환자에게 치료방법을 적용한 후 상기 환자의 다음 상태를 예측하는 환자상태 예측지능을 학습하는 환자상태 예측지능 딥러닝 모듈, 상기 에피소드 데이터베이스에 저장된 에피소드에 기반하여 상기 환자에 대한 최적 치료경로 계획을 위한 정책지능(치료방법 계획, 치료경과 판단지 능)을 강화학습하는 로컬 정책지능 강화학습 모듈, 상기 정책지능을 이용하여 상기 환자에 대한 최적 치료경로를 계획하는 최적 치료경로 탐색 모듈, 및 상기 정책지능에 기반하여 최적 치료경로 계획하고 탐색하기 위한 글로벌 정책지능을 업데이트하는 글로벌 정책지능 관리 모듈을 포함한다."}
{"patent_id": "10-2022-0086864", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 인공지능 장치에 관한 것으로, 좀 더 상세하게는 최적 치료경로를 계획하고 탐색하기 위한 인공지능 장치 및 그 동작 방법에 관한 것이다."}
{"patent_id": "10-2022-0086864", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "의료 인공지능 기술은 질병 유무 진단, 환자상태 예측, 그리고 치료방법 탐색의 순서로 발전하고 있다. 현재 일 반적인 의료 인공지능은 질병 유무 진단에 적용되고 있으며, 최근에는 지도(supervised) 또는 비지도 (unsupervised) 딥러닝 기술이 활용되고 있다. 특히 의료 인공지능 기술은 CT, X-ray, MRI 등과 같은 의료영상 에서 이상 부위를 탐지하거나, 연속적인 생체 신호를 분석하는 데 많이 활용되고 있으며, CNN(convolutional neural network), 순환 신경망(recurrent neural network), LSTM(long short-term memory) 등의 인공지능 기술 이 주로 사용된다. 국내에서는 GCN(graph convolution network)을 이용하여 전자 의료 기록(electronic medical record; EMR)으로 부터 패혈증 발병을 예측하였고, LSTM과 ANN(artificial neural network)을 이용하여 심혈관 생체 신호로부터 심장질환 발병을 예측하였고, 오토인코더(AutoEncoder)와 CNN을 이용하여 혈관 생체 신호로부터 부정맥, 고혈압 등을 진단하였다. 국외에서도 질병 진단, 의사결정 지원, 치료, 관리, 예방, 수술 등에 딥러닝 기술들을 적용함 으로써, 초음파 영상을 분석하는 인공지능을 통해 건강 상태를 수치화하였고, 뇌졸중, 치매, 편두통 등 뇌 질환 을 진단하였고, 흉부 의료영상의 분석을 통해 유방암을 진단의 척도인 HRD 점수를 예측할 수 있는 모델을 개발 하였으며, MRI, 유방 촬영술(mammography), 초음파 등을 분석하여 유방 병변의 종합적인 이상 징후를 평가하였 다. 또한, 국외에서는 의료영상에서 간 병변, 폐 결절, 심장혈류 등 영상 내 관심 영역을 분할하고 시각화하는 인공지능을 개발하였고, 현재 환자들의 방사선 스캔 데이터에서 암 및 종양 병변을 진단하는 인공지능을 개발하 고 있다. 허가된 의료기기들 중에서도 질병 진단 또는 병변 검사 분석 관련 인공지능 기술들이 적용된 의료기기들이 늘어 나고 있으며, 의료기관에서는 심전도 데이터로 미래 심부전 발병 가능성을 예측하는 기술을 개발하고 있는 등, 미래 건강 예측 기술들이 연구 및 개발되고 있다. 특히, 의료 인공지능 기술은 환자에게 가장 효과가 있는 치료 방법이 무엇인지 찾는 치료방법 탐색에 적용될 수 있다. 치료방법 탐색의 목적은 환자를 최종적으로 가장 좋은 상태로 호전시키는 일련의 치료경로를 탐색하는 것인데, 이를 위해 강화학습(reinforcement learning) 기술이 이용될 수 있다. 강화학습은 자율주행, 보험금 부당 청구 탐지, 교통량 제어 등 다양한 산업 분야에서 이용되고 있으나, 의료 인공지능 분야에서는 많이 연구되고 있지 않다."}
{"patent_id": "10-2022-0086864", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 개시는 환자에게 가장 적합한 최적 치료경로를 계획하고 탐색하는 인공지능 장치 및 그 동작 방법을 제공한 다."}
{"patent_id": "10-2022-0086864", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 개시의 실시 예에 따른 인공지능 장치는 EMR 데이터베이스로부터 환자의 전자 의무 기록(EMR)을 제공 받아 상기 환자의 상태, 상기 환자에게 적용된 치료방법, 및 상기 환자의 치료경과를 포함하는 에피소드로 변환하여 에피소드 데이터베이스에 저장하는 에피소드 변환 모듈, 상기 환자에게 치료방법을 적용한 후 상기 환자의 다음 상태를 예측하는 환자상태 예측지능 딥러닝 모듈, 개발 의료기관에서 상기 에피소드 데이터베이스에 저장된 에 피소드에 기반하여 상기 환자에 대한 최적 치료경로 계획을 위한 정책지능을 강화학습하는 로컬 정책지능 강화 학습 모듈, 상기 정책지능을 이용하여 상기 환자에 대해 가장 적합한 치료경로를 탐색하는 최적 치료경로 탐색 모듈, 및 상기 정책지능에 기반하여 최적 치료경로 계획을 위한 글로벌 정책지능을 업데이트하는 글로벌 정책지 능 관리 모듈을 포함한다. 본 개시의 실시 예에 따른 인공지능 장치의 동작 방법은 환자의 전자 의무 기록(EMR)을 제공 받아 상기 환자의 상태, 상기 환자에게 적용된 치료방법, 및 상기 환자의 치료경과를 포함하는 에피소드로 변환하는 단계, 상기 환자에게 치료방법을 적용한 후 상기 환자의 다음 상태를 예측하는 환자상태 예측지능을 딥러닝하는 단계, 상기 에피소드에 기반하여 상기 환자에 대한 최적 치료경로 계획을 위한 정책지능을 강화학습하는 단계, 상기 정책지 능을 이용하여 상기 환자에 대한 최적 치료경로를 탐색하는 단계, 및 상기 정책지능에 기반하여 최적 치료경로 계획을 강화학습 하기 위한 글로벌 정책지능을 업데이트하는 단계, 상기 정책지능에 기반하여 정책지능 강화학 습을 위한 글로벌 정책지능을 업데이트하는 단계, 및 상기 정책지능을 이용하여 상기 환자에 대한 최적 치료경 로를 출력하는 단계를 포함한다. 본 개시의 실시 예에 따른 비일시적 컴퓨터 판독 가능 매체는 프로그램 코드를 포함하며, 프로세서에 의해 상기 프로그램 코드가 실행될 때, 상기 프로세서는 환자의 전자 의무 기록(EMR)을 제공 받아 상기 환자의 상태, 상기 환자에게 적용된 치료방법, 및 상기 환자의 치료경과를 포함하는 에피소드로 변환하고, 상기 환자에게 치료방법 을 적용한 후 상기 환자의 다음 상태를 예측하는 환자상태 예측지능을 딥러닝하고, 상기 에피소드에 기반하여 상기 환자에 대한 최적 치료경로를 계획하기 위한 정책지능을 강화학습하고, 상기 정책지능을 이용하여 상기 환 자에 대한 최적 치료경로를 탐색하고, 그리고 상기 정책지능에 기반하여 최적 치료경로 계획을 강화학습 하기 위한 글로벌 정책지능을 업데이트한다."}
{"patent_id": "10-2022-0086864", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 개시의 실시 예에 따르면, 전자 의료 기록(EMR)을 보유하는 여러 의료기관들이 서로 협력하여 최적 치료경로 를 계획하고 탐색하기 위한 정책지능을 강화학습할 수 있다. 나아가 본 개시의 실시 예에 따르면, 여러 의료기관들이 원격으로 최적 치료경로를 계획하고 탐색하기 위한 글 로벌 정책지능을 공유하고 활용할 수 있다."}
{"patent_id": "10-2022-0086864", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "아래에서는, 본 개시의 기술 분야에서 통상의 지식을 가진 자가 본 개시를 쉽게 실시할 수 있을 정도로, 본 개 시의 실시 예들이 명확하고 상세하게 기재될 것이다. 상세한 설명에서 사용되는 부 또는 유닛(unit), 모듈(module), 블록(block), ~기(~or, ~er) 등의 용어들을 참 조하여 설명되는 구성 요소들 및 도면에 도시된 기능 블록들은 소프트웨어, 또는 하드웨어, 또는 그것들의 조합 의 형태로 구현될 수 있다. 예시적으로, 소프트웨어는 기계 코드, 펌웨어, 임베디드 코드, 및 애플리케이션 소 프트웨어일 수 있다. 예를 들어, 하드웨어는 전기 회로, 전자 회로, 프로세서, 컴퓨터, 집적 회로, 집적 회로 코어들, 압력 센서, 관성 센서, 멤즈 (microelectromechanical system; MEMS), 수동 소자, 또는 그것들의 조합 을 포함할 수 있다. 질병의 치료경로는 환자가 완치될 때까지 또는 사망할 때까지 환자상태의 검사 및 환자상태를 개선하기 위한 의 료행위(치료)를 반복하는 일련의 과정으로 정의될 수 있다. 딥러닝 기술은 현재 환자상태와 비교하여 다음 환자 상태를 가장 크게 개선시킬 수 있는 치료방법을 추천할 수 있다. 그러나, 추천된 치료방법에 따라 다음 환자상 태가 많이 개선될지라도, 후속적인 치료가 환자의 상태를 악화시킨다면 추천된 치료방법은 최적 치료방법이 아 니다. 따라서, 최적의 치료방법은 당장의 개선 정도를 최대화하는 치료가 아닌, 환자의 최종 상태를 최선의 상 태로 만드는 치료방법이다. 환자의 최종 상태를 최선의 상태로 만들기 위해, 환자상태의 변화에 따라 단계적으로 수행될 수 있는 여러 치료 들의 연속적인 경로가 필요하며, 본 개시에서는 이러한 연속적인 경로를 환자에 대한 최적 치료경로라고 정의한 다. 예를 들어, 치료경로는 <현재 환자상태, 치료방법, 다음 환자상태, 치료경과>에 대한 시계열적 나열로 표현 될 수 있다. 최적 치료경로 계획은 누적 보상을 최대화하는 순차적 의사결정의 탐색에 대응할 수 있다. 즉, 최적 치료경로 계획은 환자에 대해 치료방법을 적용할 때마다 발생하는 시행착오를 통해 치료방법을 교정하는 과정을 반복 학 습함으로써 환자의 최종 상태를 최선의 상태로 만들 수 있는(즉, 누적 보상을 최대화할 수 있는) 연속적인 치료 방법들을 학습하는 것으로, 이를 위해 강화학습(reinforcement learning) 방법이 이용될 수 있다. 도 1은 최적 치료경로 계획을 위한 강화학습 메커니즘을 나타낸다. 여기서, Si는 시간 i에서 환자의 상태를 나타 내고, Ti는 시간 i에서 환자에게 적용할 치료방법(단위치료)을 나타내며, Ri는 시간 i에서 환자의 치료경과(즉, 시간 i-1에 비해 시간 i에서 환자의 상태가 어떠한지)를 나타낸다. 예를 들어, 환자상태는 체온, 심박수, 호흡 수 등을 포함할 수 있고, 치료방법은 약물 투여를 포함할 수 있고, 치료경과는 '생존', '완치', '사망' 등 중 어느 하나로 표현될 수 있다. 도 1에서 의사 에이전트(doctor agent)는 환자의 상태(Si)에 따라 하나의 치료방법(Ti)을 선택하여 환자에게 적 용할 수 있고, 환자의 상태는 다음 상태(Si+1)로 전이될 수 있다. 상기 다음 환자상태(Si+1)는 치료의 의해 변화 된 환자의 상태이며, 이 변화된 상태는 의료기기로 환자를 검사하여 정량화될 수 있다. 그 후, 의사 에이전트는 시간 i 및 시간 i+1에서의 환자의 상태들(Si, Si+1)을 비교하여 치료경과(Ri+1)를 파악할 수 있다. 예를 들어, e- SOFA score와 같은 수단을 통해 치료경과를 정량화할 수 있다. 이와 같이 의사 에이전트는 시간 i에서 환자의 상태(Si)가 시간 i+1에서 환자의 상태(Si+1)로 변화함에 따른 치 료경과(Ri)에 기반하여 시간 i에서의 치료방법(Ti)을 결정하는 과정을 반복하여, 누적되는 치료경과가 최대가 되 도록(즉, 누적되는 보상이 최대가 되도록) 최적의 치료경로를 계획할 수 있는 정책지능을 학습할 수 있다. 예를 들어, 최적 치료경로는 환자의 상태가 안정 상태(G)에 도달하도록 하는 치료경로일 수 있다. 이 경우, 안정 상 태(G)에 도달하도록 하는 치료경로의 최종 보상은 이전 단계들로 역전파(backpropragate)될 수 있다.도 2는 환자에 대한 최적 치료경로의 예를 나타낸다. S1, S2, S3, S4는 각 시간 별 환자의 상태를 나타내고, T1, T2, T3, T4는 각 시간 별 환자에게 적용되는 치료방법을 나타낸다. 예를 들어, 도 2의 환자는 패혈증 환자일 수 있고, 각 시간 별 환자상태는 환자의 체온, 심박수, 호흡수, 평균동맥압 등의 척도들을 통해 표현될 수 있고, 각 시간 별 환자에게 적용되는 치료방법은 생리식염수, 노르에피네프린, 바소프레신, pRBC의 투여일 수 있다. 또한, 치료경과는 환자가 생존하였는지, 환자가 완치되었는지, 환자가 사망하였는지, 또는 e-SOFA score의 차이 중 어느 하나로 표현될 수 있다. 환자는 T1, T2, T3, T4로 이루어진 최적 치료경로를 통해 안정 상태(G)에 도달 할 수 있다. 도 1에 따른 최적 치료경로 계획을 위한 강화학습을 수행하는 데 있어서, 여러 치료방법들을 실제 환자들에게 직접 적용한 후 환자상태 변화를 검사할 수 없기 때문에, 실제 환자를 대신할 수 있는 인공지능 모델이 요구된 다. 이를 위해, 본 개시의 실시 예에 따른 최적 치료경로 계획 강화학습을 수행하기 전에 환자들의 전자 의료 기록(electronic medical record; EMR)에 기반한 딥러닝을 통해 환자모델을 환자상태 예측지능으로 생성할 수 있다. 도 3은 EMR에 기반한 딥러닝을 통해 환자상태 예측지능을 생성하고 최적 치료경로 계획을 위한 정책지능을 강화 학습하는 과정을 개념적으로 나타낸다. 이 정책지능에는 환자에게 가장 적합한 하나의 치료를 결정하는 정책이 학습되기 때문에 정책지능은 의사모델이 된다. 예를 들어, 환자모델은 EMR에 기반한 스토캐스틱 딥러닝 (stochastic deep learning; 확률적 딥러닝)을 통해 생성될 수 있다. 예를 들어, 시간 i에서 상태 Si인 환자에 치료 Ti를 수행하면 시간 i+1에서 환자상태가 Si+1로 전이될 확률은 P(Si+1)과 같이 표현될 수 있다. 즉, 환자상 태가 Si로 동일한 여러 환자들에게 동일한 치료 Ti를 수행하면 일부의 환자만 Si+1로 전이되고, 나머지는 다른 여 러 상태로 전이될 수 있기 때문에 환자모델은 확률 분포 딥러닝으로 모델링 될 수 있다. 이때, 치료경과 Ri은 Si+1를 통해 평가될 수 있다. 이와 같이 구현된 환자모델은 본 개시의 실시 예에 따른 최적 치료경로 계획을 위 한 강화학습에서 환자로서 역할을 수행할 수 있다. 의사모델은 이 환자모델에서 다시 환자상태 Si+1에서 최적의 치료방법을 찾는 시도를 반복함으로써 정책지능을 강화학습할 것이다. 따라서, 의사모델은 본 개시의 실시 예에 따른 최적 치료경로 계획을 위한 강화학습에서 의사로서 역할을 수행할 수 있다. 한편 EMR은 의료기관의 특성에 따라 특정 환자군으로 편향될 수 있기 때문에, 이러한 편향을 최소화할 수 있는 방법이 요구된다. 도 4는 복수의 의료기관들의 EMR을 통합하여 통합 EMR을 구축하고, 통합 EMR에 기반한 딥러닝 을 통해 환자모델을 생성하고, 최적 치료경로 계획을 위한 정책지능을 강화학습하는 의사모델을 개념적으로 나 타낸다. 도 4를 참조하면, 복수의 의료기관들(예를 들어, 의료기관 1 내지 의료기관 3) 각각의 EMR을 통합하여 생성하는 통합 EMR에 기반한 스토캐스틱 딥러닝을 통해 확률분포를 가지는 환자모델이 생성될 수 있다. 그러나, 현실적으로 복수의 의료기관들 각각의 EMR을 통합하는 것은 쉽지 않을 수 있기 때문에, 본 개시에서는 통합 EMR을 이용하는 대신 각 의료기관에서 개별적으로 최적 치료경로 계획을 위한 정책지능을 강화학습한 후, 의료기관들 각각의 정책지능에 대해 페더레이션(federation) 및 동기화(synchronization)를 수행하여 학습 결과 를 통합하는 방법을 사용할 수 있다. 여기서, 각 의료기관에서 개별적으로 강화학습된 최적 치료경로 계획을 위 한 정책지능을 로컬 정책지능(local policy intelligence)이라고 한다. 도 5는 복수의 의료기관들 각각의 최적 치료경로 계획을 위한 로컬 정책지능에 기반한 글로벌 정책지능 강화학 습 방법을 나타낸다. 도 5에는 상급의료기관, 종합의료기관을 포함한 N개의 의료기관들이 나타나 있으며, 각 의 료기관들은 개별적으로 EMR에 기반하여 최적 치료경로 계획을 위한 정책지능(로컬 정책지능)을 학습할 수 있다. 각 의료기관에서 학습된 로컬 정책지능들에 대해 페더레이션 및 동기화가 반복적으로 수행되어 특정 의료기관의 환자군에 대해 편향되지 않는 최적 치료경로 계획을 위한 글로벌 정책지능(global policy intelligence)이 학습 될 수 있다. 예를 들어, 글로벌 정책지능은 클라우드와 같은 저장소에 저장되어 관리될 수 있다. 나아가 도 5를 참조하면, 이와 같이 학습된 글로벌 정책지능은 인터넷과 같은 통신망을 통해 여러 지역의료기관 들로 제공될 수 있다. 이로써, 상급의료기관 및 종합의료기관뿐만 아니라 여러 지역에 소규모 의료기관 환자들 에 대해서도 상급의료기관 및 종합의료기관에서 계획된 최적 치료경로를 탐색하도록 할 수 있다. 도 6은 본 개시의 실시 예에 따른 최적 치료경로 계획을 위한 인공지능 장치의 구성의 예를 나타낸다. 예 를 들어, 의료기관(예를 들어, 의료기관)은 하나의 인공지능 장치를 포함할 수 있다. 인공지능 장치 는 EMR 데이터베이스(DB), 에피소드 DB, 에피소드 변환 모듈, 환자상태 예측지능 딥러닝 모듈, 로컬 정책지능 강화학습 모듈, 글로벌 정책지능 관리 모듈, 및 최적 치료경로 탐색 모듈(17 0)을 포함할 수 있다. 예를 들어, 인공지능 장치의 기능들은, 임의의 유형의 메모리(예를 들어, NAND 플래시 메모리, 로우-레이 턴시 NAND 플래시 메모리와 같은 플래시 메모리, 크로스-그리드 불휘발성 메모리와 같은 PMEM(persistent memory), 대량 저항 변화가 있는 메모리, PCM(phase change memory) 등 또는 이들의 결합)에 저장된 명령들을 실행하는 결합 로직, 순차 로직, 하나 이상의 타이머들, 카운터들, 레지스터들, 및/또는 상태 머신들, 하나 이 상의 CPLD(complex programmable logic device), FPGA(field programmable gate array), ASIC(application specific integrated circuit), x86 프로세서들과 같은 CSIC(complex instruction set computer) 프로세서들 및/또는 ARM 프로세서들과 같은 RISC(reduced instruction set computer)과 같은 CPU(central processing unit), GPU(graphics processing unit), NPU(neural processing unit), TPU(tensor processing unit), APU(accelerated processing unit) 등 또는 이들의 결합을 포함하는 하드웨어, 소프트웨어 또는 이들의 결합을 이용하여 구현될 수 있다. EMR DB는 모든 환자들의 전자의료기록(EMR)을 저장하는 데이터베이스이다. EMR은 의료기관을 방문한 모든 환자들의 검사 및 치료에 관한 기록들을 시간에 따라 시계열 형태로 저장한다. 에피소드 변환 모듈은 EMR DB에 저장된 환자들 각각의 EMR을 <현재 환자상태, 치료방법, 다음 환자상태, 개선정도>의 형태를 갖는 시 계열 에피소드로 변환할 수 있다. 에피소드 DB는 에피소드 변환 모듈에 의해 변환된 에피소드를 저장 하는 데이터베이스이다. 환자상태 예측지능 딥러닝 모듈은 환자에게 치료방법을 적용했을 때(즉, 단위치료를 수행했을 때) 환자의 다음 상태를 예측할 수 있는 지능모델을 딥러닝할 수 있다. 이하의 설명에서, 환자의 다음 상태를 예측할 수 있 는 지능모델은 환자상태 예측지능이라고 나타내기로 한다. 예를 들어, 환자상태 예측지능은 시계열 확률분포 모 델일 수 있다. 먼저, 현재 환자상태는 과거의 상태들 및 과거의 치료방법들에 대한 결과이기 때문에 과거 상태와 치료방법에 의존적일 수 있다. 따라서, 환자상태 예측지능은 시계열 딥러닝 모델(time series deep learning model)일 수 있다. 그리고, 환자는 의사의 치료에 따라 다양한 후보 상태들로 전이될 수 있고, 환자의 상태가 각 후보 상태 들로 전이될 확률은 서로 다를 수 있다. 또한, 환자상태가 각 후보 상태로 전이될 확률은 환자에 따라서도 서로 다를 수 있다. 예를 들어, 현재 상태가 동일한 두 환자에게 동일한 치료를 수행하더라도, 두 환자들의 다음 상 태는 서로 다를 수 있다. 따라서, 환자상태 예측지능은 환자 별로 각 후보 상태의 출현 분포를 학습하는 확률분 포 모델(probability distribution model; 예를 들어, 베이지언(Bayesian) 확률분포 모델)일 수 있다. 로컬 정책지능 강화학습 모듈은 의료기관의 에피소드 DB에 저장된 에피소드들에 기반하여 최적 치료 경로를 계획하기 위한 정책지능(즉, 로컬 정책지능)을 강화학습할 수 있다. 또한, 로컬 정책지능 강화학습 모듈 은 각 의료기관의 로컬 정책지능을 강화학습을 통해 페더레이션함으로써, 최적 치료경로를 계획하기 위한 글로벌 정책지능을 업데이트하는 데 기여할 수 있다. 예를 들어, 최적 치료경로를 계획하기 위한 정책지능은 치료방법 계획지능 및 치료경과 판단지능을 포함할 수 있고, 최적 치료경로를 계획하기 위한 글로벌 정책지능은 글로벌 치료방법 계획지능 및 글로벌 치료경과 판단지 능을 포함할 수 있다. 로컬 정책지능 강화학습 모듈에서 수행되는 강화학습은 도 1 및 도 5를 참조하여 설 명한 바와 같다. 글로벌 정책지능 관리 모듈은 로컬 정책지능 강화학습 모듈을 통해 강화학습된 로컬 정책지능에 기반 하여 최적 치료경로를 계획하고 탐색하기 위한 글로벌 정책지능을 업데이트할 수 있다. 이를 위해, 글로벌 정책 지능 관리 모듈은 외부 의료기관으로부터 페더레이션 메시지 및 동기화 메시지를 수신할 수 있고, 외부 의 료기관으로 글로벌 정책지능을 발신할 수 있다. 예를 들어, 글로벌 정책지능 관리 모듈은 페더레이션 메시지에 응답하여 외부 의료기관으로부터 전송 받은 로컬 정책지능의 학습 결과를 글로벌 정책지능이 위치하는 저장소로 전송하고, 글로벌 정책지능을 업데이트할 수 있다. 또한, 글로벌 정책지능 관리 모듈은 동기화 메시지에 응답하여 동기화를 요청한 의료기관으로 업 데이트된 글로벌 정책지능을 전송할 수 있다. 최적 치료경로 탐색 모듈은 로컬 정책지능 강화학습 모듈을 통해 학습된 정책지능 또는 글로벌 정책 지능을 이용하여 환자에 대한 최적 치료경로를 계획하고 탐색할 수 있다. 구체적으로, 최적 치료경로 탐색 모듈 은 환자상태가 가장 좋은 상태(예를 들어, 안정 상태)에 도달하기 위한 치료경로를 탐색할 수 있다. 예를들어, 최적 치료경로 계획이 학습된 정책지능은 환자의 현재 상태를 입력 받을 수 있고, 최적 치료경로를 출력 할 수 있다. 또한, 최적 치료경로 탐색 모듈은 탐색된 치료경로를 여러 의료기관들로 제공할 수 있다. 또한 실시 예에 따라, 상술한 인공지능 장치의 동작들은 비일시적(non-transistory) 컴퓨터 판독 가능 매 체에 저장되는 프로그램 코드로서 구현될 수도 있다. 예를 들어, 비일시적 컴퓨터 판독 가능 매체는 자기 매체, 광학 매체, 또는 이들의 결합(예를 들어, CD-ROM, 하드 드라이브, 읽기 전용 메모리, 플래시 드라이브 등)을 포 함할 수 있다. 도 7은 본 개시의 실시 예에 따른 인공지능 장치들의 통신 및 원격 탐색 서비스를 나타낸다. 도 7을 참조하면, 의료기관들(의료기관 1, 의료기관 2, …의료기관 n)은 각각 인공지능 장치(100_1, 100_2, …100_n)를 가질 수 있다. 인공지능 장치들(100_1, 100_2, …100_n) 각각의 구성 및 동작은 도 6의 인공지능 장치와 동일할 수 있다. 각 의료기관(의료기관 1, 의료기관 2, …의료기관 n)은 통신망(예를 들어, 인터넷)을 통해 연결될 수 있고, 인 공지능 장치들(100_1, 100_2, …, 100_n)도 통신망을 통해 서로 통신할 수 있다. 예를 들어, 글로벌 정책지능은 인터넷 상의 클라우드에 저장될 수 있다. 도 6을 참조하여 설명한 바와 같이, 각 인공지능 장치(100_1, 100_2, …100_n)는 최적 치료경로 계획을 위한 로컬 정책지능을 강화학습할 수 있고, 각 로컬 정책지능은 글로벌 정책 지능을 강화학습하고 업데이트하는 데 이용될 수 있다. 의료기관들(의료기관 1, 의료기관 2, …의료기관 n)과 직접적으로 통신망을 통해 원격 의료기관은 원격 탐색 서 비스를 통해 환자의 EMR을 각 의료기관으로 전송할 수 있다. 그 후 각 의료기관의 인공지능 장치는 전송 받은 환자에 대한 정책지능을 기반으로 최적 치료경로를 탐색하고, 탐색 결과를 원격 탐색 서비스를 통해 다시 원격 의료기관으로 전송할 수 있으며, 원격 의료기관의 의사는 전송 받은 최적 치료경로에 따라 환자를 치 료할 수 있다. 도 8은 도 6의 에피소드 변환 모듈의 동작 방법의 예를 나타낸다. 이하 도 8과 함께, 도 6을 참조하여 설 명한다. 단계 S101에서, 에피소드 변환 모듈은 EMR DB에 있는 환자 ID 각각에 대한 단계 S102에서 EMR을 읽어오고, 환자상태, 치료방법, 치료경과, 및 에피소드 목록을 초기화할 수 있다. 예를 들어, 초기화된 환자상태, 치료방 법, 치료경과, 및 에피소드는 각각 식별자 s1, t1, r1, ep1로 표현될 수 있다. 단계 S103에서, 에피소드 변환 모 듈은 EMR을 검사기록 테이블 및 치료기록 테이블로 분리하고, 두 테이블에 레코드들을 시간 순서대로 정렬 하고, 검사기록 테이블의 결측 항목의 값들을 처리할 수 있다. 예를 들어, 검사기록 테이블의 결측치들은 대응 하는 EMR 항목의 평균값, 최빈값, 보간값 등으로 대체될 수 있다. 에피소드 변환 모듈이 단계 S104에서, 에피소드 변환 모듈은 치료기록 테이블로부터 유사한 시간 대 에 있는 치료기록들을 추출하고 통합하여 , 모든 치료방법에 식별자 t1,…을 부여하여 생성할 수 있다. 단계 S105 에서, 에피소드 변환 모듈은 검사기록 테이블로부터 치료방법 ti 이전에 있는(즉, 치료방법 ti에 대응하는 시간보다 앞서는) 검사기록들을 추출하고, 추출한 검사기록들을 하나로 통합하여 환자상태 식별자 si을 생성할 수 있다. 단계 S106에서, 에피소드 변환 모듈은 검사기록 테이블로부터 치료방법 ti 와 ti+1 이전에 있는 검사기록들을 추출하고, 추출한 검사기록들을 하나로 통합하여 환자상태 식별자 si+1을 생성할 수 있다. 예를 들 어 검사기록 통합에서 혈압 측정 값이 2회(\"150 mmHG\",\"140 mmHG\") 기록이 있을 경우, 최근값/최초값/평균값 등 으로 통합될 수 있다. 단계 S107에서, 에피소드 변환 모듈은 검사기록 테이블로부터 치료경과를 판단할 수 있고 식별자 ri 을 생성할 수 있다. 이때, 치료경과는 '생존', '완치, '사망', e-SOFA score 등이 될 수 있다. 단계 S108에서, 에피소드 변환 모듈은 하나의 에피소드 <si,ti,si+1,ri>에 식별자 epi를 생성하여, 에피소드 목록 epID에 해당 에피소드를 추가할 수 있다. 예를 들어, 에피소드 epID는 {<s1, t1, s2, r1>,<s2, t2, s3, r2> …} 와 같이 표현될 수 있다. 단계 S109에서, 에피소드 변환 모듈은 다음 에피소드 생성을 위해 i가 i+1이 된다. 단계 S110에서 모든 치료방법에 대해 반복해서 처리될 수 있다. 단계 S111에서, 에피소드 변환 모듈은 모든 에피소드 목록을 에피소드 DB에 저장할 수 있다. 에피소 드 변환 모듈은 모든 환자들의 EMR에 기반하여 상술한 단계 S101 내지 단계 S111을 수행할 수 있고, 모든 환자들의 EMR은 대응하는 에피소드 목록으로 변환될 수 있다.도 9는 도 8의 방법에 따라 EMR을 에피소드로 변환하는 예를 나타낸다. EMR은 검사기록 데이터 및 치료기록 데 이터를 포함할 수 있다. 검사기록 데이터는 검사 받은 환자의 상태를 나타낸 기록이고, 치료기록 데이터는 투약, 처치 등 환자에게 적용한 의료적인 치료행위를 나타낸 기록이다. 이하 도 9와 함께, 도 6 및 도 8을 참조 하여 설명한다. 도 8을 참조하여 설명한 바와 같이, 에피소드 변환 모듈은 EMR을 검사기록 데이터를 포함하는 검사기록 테 이블과, 치료기록 데이터를 포함하는 치료기록 테이블로 분리할 수 있고, 각 테이블을 시간 순서대로 정렬할 수 있다. 여기서, 환자의 상태는 치료기록 테이블의 치료 시간을 기준으로 검사기록 테이블로부터 추출될 수 있다. 예를 들어, 환자 20001의 경우 치료방법 t1(수액 투여)에 대응하는 치료시간(2019-09-12 13:24)을 기준으로, 검 사기록 테이블에서 이전 시간(2019-09-12 09:15)에 측정된 체온 38, 심박수 110 등이 상태 s1이 된다. 마찬가지 로, 치료방법 t2(승압제 투여)에 대응하는 치료시간(2019-09-12 21:00)을 기준으로, 검사기록 테이블에서 이전 시간(2019-09-12 15:10, 17:40)에 측정된 체온 39, 심박수 130 등이 상태 s2가 된다. 치료경과는 '생존', '완치', '사망' 중 하나로 기록될 수 있는데, r1, r2는 모두 '생존'으로 기록될 수 있다. 이와 같이 생성된 상태, 치료방법, 및 치료경과에 기반하여 에피소드가 생성될 수 있으며, 에피소드는 <현재 환 자상태, 치료방법, 다음 환자상태, 치료경과>의 시계열적 목록으로 표현될 수 있다. 예를 들어, 환자 20001에 대한 에피소드 ep1은 <s1, t1, s2, r1>와 같이 표현될 수 있고, 에피소드 ep2는 <s2, t2, s3, r2>과 같이 표현될 수 있다. 도 10은 도 6의 환자상태 예측지능 딥러닝 모듈의 동작 방법의 예를 나타낸다. 도 6을 참조하여 설명한 바 와 같이, 환자상태 예측지능 딥러닝 모듈은 환자상태 예측지능을 학습할 수 있다. 이하 도 10과 함께, 도 6을 참조하여 설명한다 단계 S210에서, 환자상태 예측지능 딥러닝 모듈은 환자상태 예측지능을 위한 딥러닝 모델을 구성할 수 있 다. 환자 상태 예측지능은 딥러닝 되지 않은 환자상태에 대해서도 불확실성을 포함하는 예측이 가능하고, 유사 한 환자상태 시계열에 대해 다른 확률분포로 예측될 수 있도록 구성할 수 있다. 예를 들어, 시계열 모델로는 RNN, LSTM 등이 사용될 수 있고, 확률분포 모델로는 다중 베이지언 모델 등이 사용될 수 있으나, 본 개시는 이 에 한정되지 않는다. 단계 S220에서, 환자상태 예측지능 딥러닝 모듈은 에피소드 DB로부터 에피소드들을 읽어올 수 있고, 샘플링할 수 있다. 단계 S230에서, 환자상태 예측지능 딥러닝 모듈은 에피소드를 기반으로 입력 데이터 및 학습 목표 데이터를 생성할 수 있다. 예를 들어, 도 9와 같이 환자의 에피소드 ep1, ep2, …epn이 <s1, t1, s2, r1>, <s2, t2, s3, r2>, …<sn, tn, sn+1, rn>과 같이 표현된다고 가정하면, 입력 데이터는 <s1, t1, s2, r1>, <s2, t2, s3, r32>, …<sn, tn, -, ->이고, 학습 목표 데이터는 sn과이고 이를 통해 rn를 e-SOFA socre 등을 계산할 수 있다. 단계 S240에서, 환자상태 예측지능 딥러닝 모듈은 효율적인 딥러닝을 위한 학습 데이터 미니배치를 구성할 수 있다. 단계 S250에서, 환자상태 예측지능 딥러닝 모듈은 미니배치 단위로 학습을 하여 환자상태 예측지 능의 시계열 확률분포 딥러닝 파라미터들을 업데이트할 수 있다. 단계 S260에서, 환자상태 예측지능 딥러닝 모 듈은 환자생태 예측지능의 학습 정도를 평가할 수 있고, 단계 S270에서, 환자상태 예측지능 딥러닝 모듈 은 학습 정도를 미리 정해진 임계치(alpha)와 비교할 수 있다. 학습 정도가 미리 정해진 임계치(alpha) 이 하인 경우, 환자상태 예측지능 딥러닝 모듈은 단계 S220 내지 단계 S260을 다시 수행할 수 있고, 학습 정 도가 미리 정해진 임계치(alpha)보다 높은 경우, 환자상태 예측지능 딥러닝 모듈은 단계 S280에서 도 6의 로컬 정책지능 강화학습 모듈의 환자모델로서 이 환자상태 예측지능을 저장할 수 있다. 도 11은 도 6의 로컬 정책지능 강화학습 모듈의 동작 방법의 예를 나타낸다. 이하 도 11과 함께, 도 6을 참조하여 설명한다. 단계 S305에서, 로컬 정책지능 강화학습 모듈은 에피소드 DB로부터 환자상태 s와 치료경과 r를 임의 로 샘플링할 수 있고, 강화학습의 대상이 되는 에피소드를 저장하기 위한 버퍼를 초기화할 수 있다. 단계 S310 에서, 로컬 정책지능 강화학습 모듈은 글로벌 정책지능 관리 모듈을 통해 로컬 정책지능(즉, 치료방 법 계획지능 및 치료경과 판단지능)을 글로벌 정책지능(즉, 글로벌 치료방법 계획지능 및 글로벌 치료경과 판단지능)으로 동기화할 수 있다. 이로써, 로컬 정책지능 강화학습 모듈은 최신의 치료방법 계획지능 및 치료 경과 판단지능에 기반하여 강화학습을 수행할 수 있다. 단계 S315에서, 로컬 정책지능 강화학습 모듈은 글로벌 정책지능에 일정한 가중치(w)만큼 반영 비율을 조 절할 수 있다. 여기서, 가중치 w는 글로벌 정책지능을 로컬 정책지능에 반영하는 비율을 나타낼 수 있으며, 0≤ w≤1이다. 가중치의 값이 1인 경우 글로벌 정책지능을 구성하는 파라미터들이 그대로 반영되고, 가중치의 값이 0인 경우 글로벌 정책지능을 구성하는 파라미터들은 전혀 반영되지 않고, 로컬 정책지능의 파라미터를 그대로 사용한다. 단계 320에서, 로컬 정책지능 강화학습 모듈은 치료방법 계획지능은 환자의 현재 상태 s를 입력하여 여러 치료방법 t를 계획할 수 있고, 치료경과 판단지능은 이 치료가 얼마나 절절한 치료인지 판단할 수 있다. 단계 S325에서, 로컬 정책지능 강화학습 모듈은 도 6의 환자상태 예측지능 딥러닝 모듈에 환자의 현재 상 태 s 및 계획된 치료방법 t를 입력하여 환자의 다음 상태 s' 및 치료경과 r 을 예측한 s, t, s', r에 기반하여 에피소드 ep=< s, t, s', r>를 생성하고 버퍼에 저장할 수 있다. 다음 환자상태 s'에 대한 에피소드를 생성하기 위해 s=s'으로 한다. 따라서, 버퍼에 생성된 에피소드들이 계속하여 누적될 수 있다. 환자상태에 대한 치료 에 피소드 목록을 생성하는 과정 단계 330에서는 단계에서 단계에서 에피소드를 생성하는 과정의 종료조 건으로 치료경과가 '사망', '완치' 또는 일정한 반복 횟수 이상인 경우 종료할 수 있다. 환자상태에 대한 치료 에피소드 목록을 생성하는 과정이다. 단계 S335에서, 로컬 정책지능 강화학습 모듈은 버퍼로부터 에피소드를 샘플링하여, 학습 미니배치 M을 구 성할 수 있다. 즉, 미니배치 M은 복수의 에피소드들을 포함할 수 있다. 단계 S340에서, 로컬 정책지능 강화학습 모듈은 미니배치 M에 포함된 에피소드를 학습하여 로컬 정책지능(치료방법 계획지능 및 치료경과 판단지능)의 파라미터를 업데이트할 수 있다. 이 미니배치 M은 글로벌 정책지능에 의해 동기화된 로컬 정책지능 에 의해 계획된 치료경로에 대한 에피소드들이기 때문에 이 로컬 정책지능 파라미터 업데이트는 새로운 로컬 정 책지능을 학습하게 된다. 구체적으로, 미니배치 M에 포함된 에피소드는 단계 S320에서 계획한 결과에 기반할 수 있다. 따라서, 단계 S315 에서 설정한 치료방법 계획지능 및 치료경과 판단지능에 대한 가중치들(즉, 글로벌 정책지능의 파라미터들의 반 영 비율)이 적합하다고 판단되면 로컬 정책지능 강화학습 모듈은 치료방법 계획지능 및 치료경과 판단지능 의 파라미터들을 강화시킬 수 있고, 적합하지 않다고 판단되면 파라미터들을 약화시킬 수 있다. 예를 들어, 치료방법 계획지능은 치료경과 판단지능을 목표로 하는 방향으로 업데이트될 수 있고, 치료경과 판 단지능은 환자가 완치되도록 하는 치료경로를 계획할 수 있도록 업데이트될 수 있다. 예를 들어, 단계 S340에서 치료방법 계획지능 및 치료경과 판단지능에 대한 파라미터 업데이트는 액터 및 크리틱(actor and critic) 등 다 양한 강화학습 방법에 따라 수행될 수 있으나, 본 개시는 이에 한정되지 않는다. 한편, 단계 S340의 치료경과 판단지능에 대한 업데이트 결과는 단계 S325의 환자상태 예측지능에 의존적일 수 있다. 따라서, 로컬 정책지능 강화학습 모듈은 업데이트된 치료경과 판단지능이 현재까지 학습된 의사모델 에서 수행했던 치료에 부합하는지 여부도 추가적으로 판단해야 한다. 이를 위해 단계 S345에서, 로컬 정책지능 강화학습 모듈은 에피소드 DB로부터 미니배치 M에 포함된 에피소드 ep와 유사한 에피소드 ep'을 샘플링할 수 있고, 다른 미니배치 P를 구성할 수 있다. 에피소드 ep'은 해당 에피소드 ep에서와 유사한 환자상태에 대해 의료기관에서 의사가 수행한 실제 치료방법과 그 치료결과를 나타낼 수 있다. 그 후, 단계 S350에서 로컬 정책지능 강화학습 모듈은 미니배치 P의 에피소드를 통해 치료경과 판단지능의 파라미터들을 추가로 업데이트할 수 있다. 따라서, 업데이트된 치료경과 판단지능은 치료방법 계획지능이 향후 치료방법을 의사와 유사하게 계획할 수 있게 할 것이다. 미니배치 P는 의사의 실제 진료 기록에 기반하기 때문 에, 치료경과 판단지능의 파라미터들은 실제 의사가 수행했던 치료에 부합하는 방향으로 업데이트될 수 있다. 예를 들어, 치료경과 판단지능의 파라미터들은 아래와 같은 수학식 1을 통해 업데이트될 수 있다. 수학식 1에서, 치료경과 판단지능은 강화학습 모델 Q로서 나타내어질 수 있다.수학식 1"}
{"patent_id": "10-2022-0086864", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "여기서 α는 조절될 수 있는 임의의 가중치이고, M은 복수의 에피소드들을 포함하는 학습 미니배치이고, P는 실 제 의료기관에서 의사가 치료한 기록들 중 미니배치 M에 포함된 에피소드들과 유사한 에피소드들을 포함하는 미 니배치이다. S는 환자상태 예측지능을 통해 예측된 환자상태이고, 는 S와 유사한 환자상태로서 실제 의료기관 에서 관찰된 환자상태이다. 는 환자상태 S에 대해 치료 t를 시도했을 때 강화학습 Q를 통해 계산된 보상의 기대값이고, 는 환자상태 S와 유사한 실제 환자상태 에 대해 치료 t를 시도했 을 때 강화학습 Q를 통해 계산된 보상의 기대값이다. 예를 들어, 보상은 환자상태가 호전된 정도에 대응할 수 있다. 즉, 는 강화학습 Q를 통한 환자상태 S 및 치료 t에 대응하는 보상의 기대값에서, 유사한 환자상태 및 치료 에 대응하는 보상의 기대값의 차이를 나 타낸다. 강화학습 Q가 환자상태 S에 대해 치료 t를 계획했을 때, 실제 의료기관에서도 환자상태 에 대해 치료 t를 계획한 경우, 두 기대값의 차이가 최소화될 수 있어, 해당 강화학습 Q가 선택의 방향으로 강화되도록 파라 미터들이 업데이트될 수 있다. 반대로 강화학습 Q가 S 상태에서 치료 t를 계획하였지만, 실제 의료기관에서는 환자상태 에 대해 치료 t를 수 행하지 않은 경우, 두 기대값의 차이는 증가할 수 있고, 해당 강화학습 Q는 선택되지 않는 방향으로 강화되도록 파라미터들이 업데이트될 수 있다. 는 강화학습 알고리즘 중 n 시간차(temporal difference) 학습을 나타낸다. 따라서, 수학식 1에 따르면 강화학습을 통해 환자상태에 대해 치료를 계획했을 때 보상의 기대값과, 실제 환자상태에 대해 의료기관 이 치료를 계획했을 때 보상의 기대값 차이가 최소화시킬 수 있는 강화학습 Q가 선택될 수 있다(즉, 두 차이를 모두 최소화시킬 수 있는 Q를 선택하는 것, ). 단계 S355에서, 로컬 정책지능 강화학습 모듈은 글로벌 정책지능 관리 모듈로 페더레이션 메시지와 함께 업데이트된 로컬 정책지능(치료방법 계획지능과 치료경과 판단지능)을 전송할 수 있다. 전송된 로컬 정책 지능은 글로벌 정책지능을 최신 상태로 업데이트하는 데 사용될 수 있다. 단계 S360에서, 로컬 정책지능 강화학습 모듈은 치료방법 계획지능 및 치료경과 판단지능에 대한 학습정도 를 미리 정해진 임계치(alpha)와 비교할 수 있다. 강화 학습 정도가 미리 정해진 임계치(alpha) 이하인 경우, 로컬 정책지능 강화학습 모듈은 단계 S305로 되돌아가 치료방법 계획지능 및 치료경과 판단지능에 대한 강 화학습을 다시 수행할 수 있고, 학습 정도가 미리 정해진 임계치(alpha)보다 높은 경우, 로컬 정책지능 강화학 습 모듈은 학습을 종료할 수 있다. 도 12는 도 6의 글로벌 정책지능 관리 모듈의 동작 방법의 예를 나타낸다. 도 6을 참조하여 설명한 바와 같이, 최적 치료경로 계획 및 탐색을 위한 글로벌 정책지능은 글로벌 치료방법 계획지능 및 글로벌 치료경과 판 단지능으로 구분되어 관리될 수 있다. 이하 도 12와 함께, 도 6을 참조하여 설명한다.단계 S410에서, 글로벌 정책지능 관리 모듈은 최적 치료경로 계획 및 탐색을 위한 글로벌 정책지능 및 메 시지를 초기화하고, 초기화한 글로벌 정책지능을 저장소(예를 들어, 통신망의 클라우드)에 저장할 수 있다. 단 계 S410은 최초로 글로벌 정책지능을 학습할 때만 수행될 수 있으며, 이미 글로벌 정책지능이 학습된 경우 수행 되지 않는다. 단계 S420에서, 글로벌 정책지능 관리 모듈은 다른 의료기관의 로컬 정책지능으로부터 메시지를 수신할 수 있다. 먼저 단계 S430에서, 글로벌 정책지능 관리 모듈은 수신한 메시지가 동기화 메시지인지 여부를 확인 할 수 있다. 수신한 메시지가 동기화 메시지인 경우, 단계 S440에서, 글로벌 정책지능 관리 모듈은 동기화 를 요청한 의료기관으로 글로벌 치료방법 계획지능 및 글로벌 치료경과 판단지능을 전송할 수 있다. 수신한 메 시지가 동기화 메시지가 아닌 경우, 단계 S450에서 글로벌 정책지능 관리 모듈은 수신한 메시지가 페더레 이션 메시지인지 여부를 확인할 수 있다. 수신한 메시지가 페더레이션 메시지인 겨우, 단계 S460에서, 글로벌 정책지능 관리 모듈은 의료기관으로부 터 제공 받은 치료방법 계획지능 및 치료경과 판단지능을 저장소로 전송하여 글로벌 정책지능을 업데이트할 수 있다. 그 후, 단계 S470에서, 글로벌 정책지능 관리 모듈은 페더레이션 메시지에 응답하여 업데이트된 글 로벌 치료방법 계획지능 및 글로벌 치료경과 판단지능을 모든 의료기관들로 브로드캐스트할 수 있다. 이로써, 모든 의료기관들에게 최적 치료경로 계획을 위한 글로벌 정책지능이 최신 상태로 업데이트되었음을 알린다. 이 메시지를 수신한 의료기관에서는 로컬 정책지능 강화학습 모듈을 수행할 수 있다. 수신한 메시지가 페더레 이션 메시지가 아닌 경우, 글로벌 정책지능 관리 모듈의 동작은 종료될 수 있다. 도 13은 글로벌 정책지능을 이용하여 환자에 대한 최적 치료경로를 계획하고 탐색하는 방법의 예를 나타낸다. 이하 도 13과 함께, 도 6을 참조하여 설명한다. 단계 S510에서, 의료기관은 환자의 검사기록을 통신망을 통해 수신할 수 있고, 인공지능 장치에서 최적 치 료경로 P를 초기화할 수 있다. 단계 S520에서, 의료기관은 글로벌 정책지능 관리 모듈을 통해 글로벌 정책 지능(치료방법 계획지능 및 치료경과 판단지능)으로 동기화할 수 있다. 즉, 의료기관은 최적 치료경로의 계획을 위해 최신의 글로벌 정책지능을 활용할 수 있다. 단계 S530에서, 의료기관은 로컬 정책지능 강화학습 모듈을 통해 로컬 정책지능(치료방법 계획지능 및 치 료경과 판단지능)에 대한 가중치 w를 조절할 수 있다. 여기서, 가중치 w 는 각각 글로벌 치료방법 계획지능 및 글로벌 치료경과 판단지능을 로컬 정책지능에 반영하는 비율을 나타낼 수 있으며, 0≤w ≤1이다. 가중치의 값이 1인 경우 글로벌 정책지능을 구성하는 파라미터들이 그대로 반영되고, 가중치의 값이 0인 경우 글로벌 정책지능 을 구성하는 파라미터들은 전혀 반영되지 않는다. 단계 S540에서, 의료기관은 강화학습된 치료방법 계획지능을 통해 환자의 현재 상태 s에 적합한 치료방법 ti를 계획할 수 있고, si 및 ti를 최적 치료경로 목록 P에 추가할 수 있다. 예를 들어, P는 <si, ti, -, ->와 같이 나 타날 수 있다. 이 때, 치료경과 판단지능은 치료방법 계획지능이 치료방법을 계획할 때, 치료경과가 가장 좋게 나타날 수 있는 치료방법을 계획하도록 치료경과를 판단할 수 있다. 단계 S550에서, 의료기관은 환자상태 예측지능 딥러닝 모듈을 통해 학습된 환자상태 예측지능을 이용하여 다음 환자 상태 si+1를 예측하고 치료경과 ri을 계산할 수 있다. 예를 들어, 환자상태 예측지능의 입력 데이터는 <s1, t1, s2, r1>, <s2, t2, s3, r2>, …<sn-1, tn-1, sn, rn>과 tn이고, 학습 목표 데이터는 sn+1과 rn이다. 이것은 과거의 치료경로 에피소드가 <s1, t1, s2, r1>, <s2, t2, s3, r2>, …<sn-1, tn-1, sn, rn>인 환자에게 치료 tn을 수 행했을 때 sn+1과 rn로 전이되는 환자의 경우를 환자상태 예측지능이 학습하는 것을 의미한다. 단계 S540에서 최 적 치료경로 목록 P에 있는 하나의 <si, ti, -, ->이 <si, ti, si+1, ri>로 업데이트될 수 있다. 단계 S560에서, 의료기관은 치료가 더 수행되는지 여부를 판단할 수 있다. 예를 들어, 치료경과 ri이 '사망' 또 는 '완치'인 경우 치료는 더 수행되지 않으며, 단계 S570에서 인공지능 장치는 최적 치료경로 P를 출력하 거나 의료기관에 전송할 수 있다. 반면, 치료경과 ri이 '생존'인 경우 치료는 더 수행되며, 의료기관은 단계 S540부터 다시 수행할 수 있고, i는 i+1이 된다. 도 14는 원격 의료기관에서 환자에 대한 최적 치료경로를 탐색하는 방법의 예를 나타낸다. 단계 S610에서, 원격 의료기관은 환자의 상태를 검사할 수 있고, 검사 결과를 원격 탐색 서비스(도 7의 200)을 통해 통신망(예를 들어, 인터넷)으로 전송할 수 있다. 단계 S620에서, 원격 의료기관은 통신망과 연결된 다른 의료기관들로 최적 치 료경로 탐색을 요청할 수 있다. 단계 S630에서, 원격 의료기관은 원격 탐색 서비스를 통해 글로벌 정책지능 또 는 다른 의료기관의 로컬 정책지능으로부터 계획된 최적 치료경로를 수신할 수 있고, 출력할 수 있다. 본 개시의 실시 예에 따르면, 환자에 대한 최적 치료경로를 의료 인공지능을 통해 자동으로 탐색할 수 있다. 또 한, 전자 의료 기록(EMR)을 보유하는 여러 의료기관들이 서로 협력하여 최적 치료경로 계획을 위한 글로벌 정책 지능을 강화학습할 수 있다. 나아가 본 개시의 실시 예에 따르면, 여러 의료기관들이 원격으로 최적 치료경로 계획 및 탐색을 위한 글로벌 정책지능을 공유하고 활용할 수 있다. 본 개시의 실시 예에 따르면, 다음과 같은 장점들이 있다. 첫째, 여러 의료기관들의 치료기록을 바탕으로 최적 치료경로 계획지능을 학습할 수 있고 이 계획지능을 바탕으로 환자에게 가장 적합한 치료 계획 경로를 탐색할 수 있다. 둘째, 이 계획 및 탐색은 의료인력 및 인프라 부족으로 인한 지역 간 의료 서비스 불균형을 완화시킬 수 있다. 둘째, 의원급 의료기관에서도 원격으로 고품질의 글로벌 정책지능을 공유하고 활용할 수 있어, 특정 의료기관에 환자가 편중되는 현상을 최소화할 수 있다. 셋째, 본 개시의 실시 예에 따른 최적 치료경로를 계획 하고 탐색하기 위한 지능은 종합의료기관, 중소형의료기관, 의원급 의료기관 등의 역할 분담을 통해 서로 상생 할 수 있는 의료 서비스 모델로 활용될 수 있어 의료의 공공성이 강화될 수 있다. 넷째, 환자 한 명당 평균 진 료시간이 단축될 수 있고, 및 의사 한 명당 평균 진료 환자 수를 증가시킬 수 있어, 의료자원의 활용 및 효율을 극대화할 수 있다. 다섯째, 국내 의료 빅데이터를 활용한 인공지능 의료 서비스를 국제화할 수 있다. 상술된 내용은 본 개시를 실시하기 위한 구체적인 실시 예들이다. 본 개시는 상술된 실시 예들뿐만 아니라, 단 순하게 설계 변경되거나 용이하게 변경할 수 있는 실시 예들 또한 포함할 것이다. 또한, 본 개시는 실시 예들을 이용하여 용이하게 변형하여 실시할 수 있는 기술들도 포함될 것이다. 따라서, 본 개시의 범위는 상술된 실시 예들에 국한되어 정해져서는 안 되며 후술하는 특허청구범위뿐만 아니라 본 개시의 특허청구범위와 균등한 것들 에 의해 정해져야 할 것이다."}
{"patent_id": "10-2022-0086864", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 치료경로를 계획하기 위한 강화학습의 메커니즘을 나타낸다. 도 2는 패혈증 환자에 대한 최적 치료경로의 예를 나타낸다. 도 3은 EMR을 통해 환자모델에 해당하는 환자상태 예측지능을 딥러닝하고, 최적 치료경로를 계획하기 위한 정책 지능을 강화학습하는 과정을 개념적으로 나타낸다. 도 4는 복수의 의료기관들의 EMR을 통합하여 통합 EMR을 구축하고, 통합 EMR을 통해 환자모델에 해당하는 환자 상태 예측지능을 딥러닝하고, 최적 치료경로를 계획하기 위한 정책지능을 강화학습하는 과정을 개념적으로 나타 낸다. 도 5는 복수의 의료기관들 각각의 최적 치료경로 계획을 위한 로컬 정책지능을 강화학습 하는 방법을 나타낸다. 도 6은 본 개시의 실시 예에 따른 최적 치료경로 계획을 위한 정책지능을 학습하고, 최적 치료경로를 탐색하기 위한 인공지능 장치의 구성의 예를 나타낸다 도 7은 본 개시의 실시 예에 따른 인공지능 장치들의 통신 및 원격 탐색 서비스를 나타낸다. 도 8은 도 6의 에피소드 변환 모듈의 동작 방법의 예를 나타낸다. 도 9는 도 8의 방법에 따라 EMR을 에피소드로 변환하는 예를 나타낸다.도 10은 도 6의 환자상태 예측지능 딥러닝 모듈의 동작 방법의 예를 나타낸다. 도 11은 도 6의 로컬 정책지능 강화학습 모듈의 동작 방법의 예를 나타낸다. 도 12는 도 6의 글로벌 정책지능 관리 모듈의 동작 방법의 예를 나타낸다. 도 13은 글로벌 정책지능을 이용하여 환자에 대한 최적 치료경로를 계획하고 탐색하는 방법의 예를 나타낸다. 도 14는 원격 의료기관에서 환자에 대한 최적 치료경로를 탐색하는 방법의 예를 나타낸다."}
