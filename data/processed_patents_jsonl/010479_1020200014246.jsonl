{"patent_id": "10-2020-0014246", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2021-0080143", "출원번호": "10-2020-0014246", "발명의 명칭": "다자 간 협업 기반 객체 인식 시스템 및 그 방법", "출원인": "주식회사 코이노", "발명자": "장 민"}}
{"patent_id": "10-2020-0014246", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "동일한 입력 데이터를 대상으로 각각 기계학습을 수행하여 객체를 인식하는 다수의 학습자 단말; 및각 학습자 단말로부터 객체 인식 결과 값을 수신하여 이로부터 단일의 최종 객체 인식 결과 값을 결정한 후 각학습자 단말에 최종 객체 인식 결과 값을 전송하여 학습자 단말 간에 객체 인식 결과를 동기화 시키는 관리 서버;를 포함하는 것을 특징으로 하는 다자 간 협업 기반 객체 인식 시스템."}
{"patent_id": "10-2020-0014246", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1 항에 있어서, 관리 서버는각 학습자 단말로부터 수신된 객체 인식 결과 값들을 비교 분석하여 서로 동일한 객체 인식 결과 값의 수가 가장 많이 나오는 조건 또는 학습 정확도가 가장 높은 조건 중 적어도 하나를 충족하는 객체 인식 결과 값을 최종객체 인식 결과 값으로 결정하는 것을 특징으로 하는 다자 간 협업 기반 객체 인식 시스템."}
{"patent_id": "10-2020-0014246", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 1 항에 있어서, 관리 서버는각 학습자 단말로부터 수신된 객체 인식 결과 값을 조합하고 조합된 데이터를 대상으로 학습을 수행하여 조합데이터의 학습 결과를 최종 객체 인식 결과 값으로 결정하는 것을 특징으로 하는 다자 간 협업 기반 객체 인식시스템."}
{"patent_id": "10-2020-0014246", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 1 항에 있어서, 관리 서버는각 학습자 단말로부터 수신된 객체 인식 결과 값을 조합하고 조합된 데이터를 대상으로 학습을 수행한 후, 조합데이터의 학습 결과와 각 학습자 단말의 객체 인식 결과를 종합적으로 비교 분석하여 최종 객체 인식 결과 값을결정하는 것을 특징으로 하는 다자 간 협업 기반 객체 인식 시스템."}
{"patent_id": "10-2020-0014246", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제 1 항에 있어서, 관리 서버는각 학습자 단말로부터 객체 인식 결과 값을 수신하는 수신부;각 객체 인식 결과 값을 비교 분석하는 분석부;각 객체 인식 결과 값을 조합하고 조합된 데이터를 대상으로 학습을 수행하는 학습부;분석부의 각 객체 인식 결과 값에 대한 비교 분석 결과와, 학습부의 조합 데이터에 대한 학습 수행 결과 값을종합적으로 판단하여 단일의 최종 객체 인식 결과 값을 결정하는 최종 결정부; 및학습자 단말 간 객체 인식 결과 동기화를 위해 각 학습자 단말에 최종 객체 인식 결과 값을 전송하는 전송부;를 포함하는 것을 특징으로 하는 다자 간 협업 기반 객체 인식 시스템."}
{"patent_id": "10-2020-0014246", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제 5 항에 있어서, 분석부는각 학습자 단말로부터 수신된 객체 인식 결과 값들을 비교 분석하여 서로 동일한 객체 인식 결과 값이 있는지여부를 판단하고,공개특허 10-2021-0080143-3-최종 결정부는동일한 객체 인식 결과 값이 있으면 동일한 객체 인식 결과 값의 수가 가장 많이 나오는 조건 또는 학습 정확도가 가장 높은 조건 중 적어도 하나를 충족하는 객체 인식 결과 값을 중간 객체 인식 결과 값으로 1차 결정하는제1 결정부; 및제1 결정부의 중간 객체 인식 결과 값과 학습부의 조합 데이터의 학습 수행 결과 값을 비교하여 서로 동일한 객체인지 여부를 판단하고 동일하면 중간 객체 인식 결과 값을 최종 객체 인식 결과 값으로 확정하고, 서로 상이하면 중간 인식 결과 값과 조합 데이터의 학습 수행 결과 값을 함께 전송부에 전달하는 제2 결정부;를 포함하는 것을 특징으로 하는 다자 간 협업 기반 객체 인식 시스템."}
{"patent_id": "10-2020-0014246", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제 6 항에 있어서, 제2 결정부는학습부의 학습 수행 결과 학습 정확도가 미리 설정된 역치 값이 넘으면 학습부의 학습 수행 결과 값을 최종 객체 인식 결과 값으로 결정하여 제공하고, 미리 설정된 역치 값이 넘지 않으면 중간 인식 결과 값과 학습부의 학습 수행 결과 값을 함께 전송부에 전달하는 것을 특징으로 하는 다자 간 협업 기반 객체 인식 시스템."}
{"patent_id": "10-2020-0014246", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제 6 항에 있어서, 관리 서버는전송부가 최종 객체 인식 결과 값을 각 학습자 단말에 전송하면서 재 학습을 요청하고, 수신부가 각 학습자 단말로부터 재 학습된 객체 인식 결과 값을 수신하는 과정을 반복함에 따라 각 학습자 단말의 학습을 훈련 시키는것을 특징으로 하는 다자 간 협업 기반 객체 인식 시스템."}
{"patent_id": "10-2020-0014246", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제 1 항에 있어서, 다자 간 협업 기반 객체 인식 시스템은입력 데이터를 기계학습 과제로서 다수의 학습자 단말에 제공하는 가이드 단말; 을 더 포함하며,각 학습자 단말은 과제로 할당된 기계학습을 수행하는 교육용 단말인 것을 특징으로 하는 다자 간 협업 기반 객체 인식 시스템."}
{"patent_id": "10-2020-0014246", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제 1 항에 있어서, 각 학습자 단말은기계학습 명령어가 저장되는 메모리;기계학습 명령어를 이용하여 입력 데이터에 대해 기계학습을 수행하고 수행에 따른 학습된 객체 정보와 학습 기록을 포함한 객체 인식 결과 값을 생성하고, 관리 서버로부터 최종 객체 인식 결과 값을 수신하면 객체 인식 결과 값을 최종 객체 인식 결과 값으로 변경하거나 최종 객체 인식 결과 값을 참조하여 새로 기계학습을 수행하여객체를 인식하는 과정을 반복하는 프로세서; 및객체 인식 결과 값을 관리 서버에 전송하고, 관리 서버로부터 최종 객체 인식 결과 값을 수신하는 통신부;를 포함하는 것을 특징으로 하는 다자 간 협업 기반 객체 인식 시스템."}
{"patent_id": "10-2020-0014246", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제 1 항에 있어서, 각 학습자 단말은사용자의 신체에 착용하는 본체에 장착되어 외부 영상을 촬영하여 촬영 영상을 획득하는 시력 보조장치를 포함하는 것을 특징으로 하는 다자 간 협업 기반 객체 인식 시스템."}
{"patent_id": "10-2020-0014246", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "동일한 입력 데이터를 대상으로 다수의 학습자 단말로부터 각각 객체 인식 결과 값을 수신하는 단계;공개특허 10-2021-0080143-4-수신된 객체 인식 결과 값들로부터 단일의 최종 객체 인식 결과 값을 결정하는 단계; 및각 학습자 단말에 최종 객체 인식 결과 값을 전송하여 학습자 단말 간에 객체 인식 결과를 동기화 시키는 단계;를 포함하는 것을 특징으로 하는 다자 간 협업 기반 객체 인식 방법."}
{"patent_id": "10-2020-0014246", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제 12 항에 있어서, 최종 객체 인식 결과 값을 결정하는 단계는각 객체 인식 결과 값을 비교 분석하는 단계;각 객체 인식 결과 값을 조합하고 조합된 데이터를 대상으로 학습을 수행하는 단계; 및각 객체 인식 결과 값에 대한 비교 분석 결과와, 조합된 데이터에 대한 학습 수행 결과 값을 종합적으로 판단하여 단일의 최종 객체 인식 결과 값을 결정하는 단계;를 포함하는 것을 특징으로 하는 다자 간 협업 기반 객체 인식 방법."}
{"patent_id": "10-2020-0014246", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제 13 항에 있어서, 종합적으로 판단하여 단일의 최종 객체 인식 결과 값을 결정하는 단계는각 학습자 단말로부터 수신된 객체 인식 결과 값들을 비교 분석하여 서로 동일한 객체 인식 결과 값의 수가 가장 많이 나오는 조건 또는 학습 정확도가 가장 높은 조건 중 적어도 하나를 충족하는 객체 인식 결과 값을 중간객체 인식 결과 값으로 결정하는 단계; 및중간 객체 인식 결과 값과 조합 데이터의 학습 수행 결과 값을 비교하여 서로 동일한 객체인지 여부를 판단하고동일하면 중간 객체 인식 결과 값을 최종 객체 인식 결과 값으로 확정하고, 서로 상이하면 중간 인식 결과 값과조합 데이터의 학습 수행 결과 값을 함께 제공하는 단계;를 포함하는 것을 특징으로 하는 다자 간 협업 기반 객체 인식 방법."}
{"patent_id": "10-2020-0014246", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제 14 항에 있어서, 종합적으로 판단하여 단일의 최종 객체 인식 결과 값을 결정하는 단계는학습 수행 결과 학습 정확도가 미리 설정된 역치 값이 넘으면 조합 데이터의 학습 수행 결과 값을 최종 객체 인식 결과 값으로 결정하는 단계; 및학습 수행 결과 학습 정확도가 미리 설정된 역치 값을 넘지 않으면 중간 인식 결과 값과 조합 데이터의 학습 수행 결과 값을 함께 제공하는 단계;를 더 포함하는 것을 특징으로 하는 다자 간 협업 기반 객체 인식 방법."}
{"patent_id": "10-2020-0014246", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "다자 간 협업 기반 객체 인식 시스템 및 그 방법이 개시된다. 일 실시 예에 따른 다자 간 협업 기반 객체 인식 시스템은 동일한 입력 데이터를 대상으로 각각 기계학습을 수행하여 객체를 인식하는 다수의 학습자 단말과, 각 학습자 단말로부터 객체 인식 결과 값을 수신하여 이로부터 단일의 최종 객체 인식 결과 값을 결정한 후 각 학습 자 단말에 최종 객체 인식 결과 값을 전송하여 학습자 단말 간에 객체 인식 결과를 동기화 시키는 관리 서버를 포함한다."}
{"patent_id": "10-2020-0014246", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 데이터 처리기술에 관한 것으로, 보다 상세하게는 객체인식 기술에 관한 것이다."}
{"patent_id": "10-2020-0014246", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "기계학습(machine learning) 방식은 인공지능의 한 분야로, 음성과 영상 등에서 사용되고 있으며, 특히 이미지 분류 및 대조와 비교분석 등에 많이 사용되고 있다. 대상 데이터가 이미지(image)일 경우, 처리 방식은 이미지 라이브러리 등을 확보하고 이를 카테고리화 한 후 콘볼루션 신경망(Convolutional Neural Network: CNN, 이하, 'CNN'이라 칭함)과 같은 인공신경망으로 특징을 추출하고 이를 학습시킴으로써 정확도를 높여가는 방식을 사용 한다."}
{"patent_id": "10-2020-0014246", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "일 실시 예에 따라, 다수의 학습자 단말과 관리 서버 간 협업을 통해 기계학습의 정확도 및 효율성을 높이는 다 자 간 협업 기반 객체 인식 시스템 및 그 방법을 제안한다."}
{"patent_id": "10-2020-0014246", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "일 실시 예에 따른 다자 간 협업 기반 객체 인식 시스템은, 동일한 입력 데이터를 대상으로 각각 기계학습을 수 행하여 객체를 인식하는 다수의 학습자 단말과, 각 학습자 단말로부터 객체 인식 결과 값을 수신하여 이로부터 단일의 최종 객체 인식 결과 값을 결정한 후 각 학습자 단말에 최종 객체 인식 결과 값을 전송하여 학습자 단말 간에 객체 인식 결과를 동기화 시키는 관리 서버를 포함한다. 관리 서버는, 각 학습자 단말로부터 수신된 객체 인식 결과 값들을 비교 분석하여 서로 동일한 객체 인식 결과 값의 수가 가장 많이 나오는 조건 또는 학습 정확도가 가장 높은 조건 중 적어도 하나를 충족하는 객체 인식 결 과 값을 최종 객체 인식 결과 값으로 결정할 수 있다. 관리 서버는, 각 학습자 단말로부터 수신된 객체 인식 결과 값을 조합하고 조합된 데이터를 대상으로 학습을 수 행하여 조합 데이터의 학습 결과를 최종 객체 인식 결과 값으로 결정할 수 있다. 관리 서버는, 각 학습자 단말로부터 수신된 객체 인식 결과 값을 조합하고 조합된 데이터를 대상으로 학습을 수 행한 후, 조합 데이터의 학습 결과와 각 학습자 단말의 객체 인식 결과를 종합적으로 비교 분석하여 최종 객체 인식 결과 값을 결정할 수 있다. 관리 서버는, 각 학습자 단말로부터 객체 인식 결과 값을 수신하는 수신부와, 각 객체 인식 결과 값을 비교 분 석하는 분석부와, 각 객체 인식 결과 값을 조합하고 조합된 데이터를 대상으로 학습을 수행하는 학습부와, 분석 부의 각 객체 인식 결과 값에 대한 비교 분석 결과와, 학습부의 조합 데이터에 대한 학습 수행 결과 값을 종합 적으로 판단하여 단일의 최종 객체 인식 결과 값을 결정하는 최종 결정부와, 학습자 단말 간 객체 인식 결과 동 기화를 위해 각 학습자 단말에 최종 객체 인식 결과 값을 전송하는 전송부를 포함할 수 있다. 분석부는 각 학습자 단말로부터 수신된 객체 인식 결과 값들을 비교 분석하여 서로 동일한 객체 인식 결과 값이 있는지 여부를 판단하고, 최종 결정부는 동일한 객체 인식 결과 값이 있으면 동일한 객체 인식 결과 값의 수가 가장 많이 나오는 조건 또는 학습 정확도가 가장 높은 조건 중 적어도 하나를 충족하는 객체 인식 결과 값을 중 간 객체 인식 결과 값으로 1차 결정하는 제1 결정부와, 제1 결정부의 중간 객체 인식 결과 값과 학습부의 조합 데이터의 학습 수행 결과 값을 비교하여 서로 동일한 객체인지 여부를 판단하고 동일하면 중간 객체 인식 결과 값을 최종 객체 인식 결과 값으로 확정하고, 서로 상이하면 중간 인식 결과 값과 조합 데이터의 학습 수행 결과 값을 함께 전송부에 전달하는 제2 결정부를 포함할 수 있다. 제2 결정부는, 학습부의 학습 수행 결과 학습 정확도가 미리 설정된 역치 값이 넘으면 학습부의 학습 수행 결과 값을 최종 객체 인식 결과 값으로 결정하여 제공하고, 미리 설정된 역치 값이 넘지 않으면 중간 인식 결과 값과 학습부의 학습 수행 결과 값을 함께 전송부에 전달할 수 있다. 관리 서버는, 전송부가 최종 객체 인식 결과 값을 각 학습자 단말에 전송하면서 재 학습을 요청하고, 수신부가 각 학습자 단말로부터 재 학습된 객체 인식 결과 값을 수신하는 과정을 반복함에 따라 각 학습자 단말의 학습을 훈련 시킬 수 있다. 다자 간 협업 기반 객체 인식 시스템은, 입력 데이터를 기계학습 과제로서 다수의 학습자 단말에 제공하는 가이 드 단말을 더 포함하며, 각 학습자 단말은 과제로 할당된 기계학습을 수행하는 교육용 단말일 수 있다. 각 학습자 단말은, 기계학습 명령어가 저장되는 메모리와, 기계학습 명령어를 이용하여 입력 데이터에 대해 기 계학습을 수행하고 수행에 따른 학습된 객체 정보와 학습 기록을 포함한 객체 인식 결과 값을 생성하고, 관리 서버로부터 최종 객체 인식 결과 값을 수신하면 객체 인식 결과 값을 최종 객체 인식 결과 값으로 변경하거나 최종 객체 인식 결과 값을 참조하여 새로 기계학습을 수행하여 객체를 인식하는 과정을 반복하는 프로세서와, 객체 인식 결과 값을 관리 서버에 전송하고, 관리 서버로부터 최종 객체 인식 결과 값을 수신하는 통신부를 포 함할 수 있다. 각 학습자 단말은 사용자의 신체에 착용하는 본체에 장착되어 외부 영상을 촬영하여 촬영 영상을 획득하는 시력 보조장치를 포함할 수 있다. 다른 실시 예에 따른 다자 간 협업 기반 객체 인식 방법은, 동일한 입력 데이터를 대상으로 다수의 학습자 단말 로부터 각각 객체 인식 결과 값을 수신하는 단계와, 수신된 객체 인식 결과 값들로부터 단일의 최종 객체 인식결과 값을 결정하는 단계와, 각 학습자 단말에 최종 객체 인식 결과 값을 전송하여 학습자 단말 간에 객체 인식 결과를 동기화 시키는 단계를 포함한다. 최종 객체 인식 결과 값을 결정하는 단계는, 각 객체 인식 결과 값을 비교 분석하는 단계와, 각 객체 인식 결과 값을 조합하고 조합된 데이터를 대상으로 학습을 수행하는 단계와, 각 객체 인식 결과 값에 대한 비교 분석 결 과와, 조합된 데이터에 대한 학습 수행 결과 값을 종합적으로 판단하여 단일의 최종 객체 인식 결과 값을 결정 하는 단계를 포함할 수 있다. 종합적으로 판단하여 단일의 최종 객체 인식 결과 값을 결정하는 단계는, 각 학습자 단말로부터 수신된 객체 인 식 결과 값들을 비교 분석하여 서로 동일한 객체 인식 결과 값의 수가 가장 많이 나오는 조건 또는 학습 정확도 가 가장 높은 조건 중 적어도 하나를 충족하는 객체 인식 결과 값을 중간 객체 인식 결과 값으로 결정하는 단계 와, 중간 객체 인식 결과 값과 조합 데이터의 학습 수행 결과 값을 비교하여 서로 동일한 객체인지 여부를 판단 하고 동일하면 중간 객체 인식 결과 값을 최종 객체 인식 결과 값으로 확정하고, 서로 상이하면 중간 인식 결과 값과 조합 데이터의 학습 수행 결과 값을 함께 제공하는 단계를 포함할 수 있다. 종합적으로 판단하여 단일의 최종 객체 인식 결과 값을 결정하는 단계는, 학습 수행 결과 학습 정확도가 미리 설정된 역치 값이 넘으면 조합 데이터의 학습 수행 결과 값을 최종 객체 인식 결과 값으로 결정하는 단계와, 학 습 수행 결과 학습 정확도가 미리 설정된 역치 값을 넘지 않으면 중간 인식 결과 값과 조합 데이터의 학습 수행 결과 값을 함께 제공하는 단계를 더 포함할 수 있다."}
{"patent_id": "10-2020-0014246", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "일 실시 예에 따른 다자 간 협업 기반 객체 인식 시스템 및 그 방법은 다수의 학습자 단말 별로 서로 상이한 단 말 능력을 고려하여 관리 서버와의 협업 기능을 통해 각 학습자 단말의 학습을 가이드 하고 가이드를 통해 객체 인식 결과를 동기화 시켜 학습 정확도를 높일 수 있다. 특히, 이와 같은 협업 기능을 교육에 접목시켰을 때 협 업하는 형태로 객체를 인식하여 형태 파악에 더 정확한 결과를 도출하거나 새로운 관찰형태를 보고하도록 가이 드 할 수 있다."}
{"patent_id": "10-2020-0014246", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명의 이점 및 특징, 그리고 그것들을 달성하는 방법은 첨부되는 도면과 함께 상세하게 후술되어 있는 실시 예들을 참조하면 명확해질 것이다. 그러나 본 발명은 이하에서 개시되는 실시 예들에 한정되는 것이 아니라 서 로 다른 다양한 형태로 구현될 수 있으며, 단지 본 실시 예들은 본 발명의 개시가 완전하도록 하고, 본 발명이"}
{"patent_id": "10-2020-0014246", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "속하는 기술분야에서 통상의 지식을 가진 자에게 발명의 범주를 완전하게 알려주기 위해 제공되는 것이며, 본 발명은 청구항의 범주에 의해 정의될 뿐이다. 명세서 전체에 걸쳐 동일 참조 부호는 동일 구성 요소를 지칭한다. 본 발명의 실시 예들을 설명함에 있어서 공지 기능 또는 구성에 대한 구체적인 설명이 본 발명의 요지를 불필요 하게 흐릴 수 있다고 판단되는 경우에는 그 상세한 설명을 생략할 것이며, 후술되는 용어들은 본 발명의 실시 예에서의 기능을 고려하여 정의된 용어들로서 이는 사용자, 운용자의 의도 또는 관례 등에 따라 달라질 수있다. 그러므로 그 정의는 본 명세서 전반에 걸친 내용을 토대로 내려져야 할 것이다. 첨부된 블록도의 각 블록과 흐름도의 각 단계의 조합들은 컴퓨터 프로그램명령어들(실행 엔진)에 의해 수행될 수도 있으며, 이들 컴퓨터 프로그램 명령어들은 범용 컴퓨터, 특수용 컴퓨터 또는 기타 프로그램 가능한 데이터 프로세싱 장비의 프로세서에 탑재될 수 있으므로, 컴퓨터 또는 기타 프로그램 가능한 데이터 프로세싱 장비의 프로세서를 통해 수행되는 그 명령어들이 블록도의 각 블록 또는 흐름도의 각 단계에서 설명된 기능들을 수행하 는 수단을 생성하게 된다. 이들 컴퓨터 프로그램 명령어들은 특정 방식으로 기능을 구현하기 위해 컴퓨터 또는 기타 프로그램 가능한 데이 터 프로세싱 장비를 지향할 수 있는 컴퓨터 이용가능 또는 컴퓨터 판독 가능 메모리에 저장되는 것도 가능하므 로, 그 컴퓨터 이용가능 또는 컴퓨터 판독 가능 메모리에 저장된 명령어들은 블록도의 각 블록 또는 흐름도의 각 단계에서 설명된 기능을 수행하는 명령어 수단을 내포하는 제조 품목을 생산하는 것도 가능하다. 그리고 컴퓨터 프로그램 명령어들은 컴퓨터 또는 기타 프로그램 가능한 데이터 프로세싱 장비 상에 탑재되는 것 도 가능하므로, 컴퓨터 또는 기타 프로그램 가능한 데이터 프로세싱 장비 상에서 일련의 동작 단계들이 수행되 어 컴퓨터로 실행되는 프로세스를 생성해서 컴퓨터 또는 기타 프로그램 가능한 데이터 프로세싱 장비를 수행하 는 명령어들은 블록도의 각 블록 및 흐름도의 각 단계에서 설명되는 기능들을 실행하기 위한 단계들을 제공하는 것도 가능하다. 또한, 각 블록 또는 각 단계는 특정된 논리적 기능들을 실행하기 위한 하나 이상의 실행 가능한 명령어들을 포 함하는 모듈, 세그먼트 또는 코드의 일부를 나타낼 수 있으며, 몇 가지 대체 실시 예들에서는 블록들 또는 단계 들에서 언급된 기능들이 순서를 벗어나서 발생하는 것도 가능함을 주목해야 한다. 예컨대, 잇달아 도시되어 있 는 두 개의 블록들 또는 단계들은 사실 실질적으로 동시에 수행되는 것도 가능하며, 또한 그 블록들 또는 단계 들이 필요에 따라 해당하는 기능의 역순으로 수행되는 것도 가능하다. 본 발명에 의해 학습 되는 신경망은 다양한 복잡한 계산 업무에 사용될 수 있다. 예를 들면, 신경망은 이미지 데이터가 주어졌을 때 사물 인식에 사용될 수 있다. 사물 인식은 안면 인식, 손 글씨 분석, 의료 이미지 분석, 그리고 이미지에 포함된 물체나 특징의 분석에 요구되는 일이나 그와 유사한 일들을 포함한다. 신경망은 환경 감시, 제조 및 생산 제어, 의료 진단 보조, 그리고 그와 유사한 다양한 절차에 사용될 수 있다. 신경망은 음성 인식, 언어 번역, 음성 데이터가 주어졌을 때 언어 작업들을 수행할 수 있다. 이하, 본 발명의 이해를 돕기 위해 여기에 게시되는 용어들에 대한 의미를 정의한다. 여기서 언급되는 용어 “신경망”은 일반적으로 적응적 특징을 갖는 통계적 학습 알고리즘을 수행하는, 기계 학 습에 유용한 소프트웨어를 의미한다. 신경망은 생체의 신경망을 모사하여 서로 상호 연결되어 네트워크를 형성 하는“뉴런”, “처리 요소”, “유닛” 또는 다른 유사한 용어들로 알려진 복수의 인공적 노드들을 포함한다. 일반적으로, 신경망은 적응적 가중치(학습 알고리즘에 의해서 조정되는 숫자 파라미터)의 셋들을 포함하고, 그 것들의 입력에 대해 근사적 비선형 함수 기능을 갖는다. 적응적 가중치는 훈련이나 예측 기간 동안 활성화되는 뉴런들 간의 연결 강도를 의미한다. 일반적으로, 신경망은 비선형, 분산, 병렬, 그리고 지역 처리 및 적응 원칙 에 따라 동작한다. 인공신경망 중 하나로 콘볼루션 신경망(CNN)이 있다. 일반적으로, 콘볼루션은 두 개의 함수(f, g)에 대한 수학 연산으로, 원래 함수의 변형된 버전의 제3 함수를 생성한다. 제3 함수는 두 함수 중 어느 하나의 원래 함수가 변형되는 양의 함수로서, 두 함수들의 영역 중첩을 포함한다. 일반적으로 콘볼루션 신경망(CNN)은 각각의 뉴런들이 타일 형태로 배치되고, 가시 필드에서의 중첩 영역에 응답 하는 형태의 신경망 타입을 의미한다. 콘볼루션 신경망(CNN)은 입력 계층과 중간 계층 및 출력 계층을 포함한다. 입력 계층은 입력 데이터를 입력 받은 계층이고, 출력 계층은 입력 데이터에 대한 최종 분류 결과를 출력하는 계층이다. 중간 계층은 콘볼루션 계층(convolution layer), 풀링 계층(pooling layer) 및 상층의 완 전 연결 계층(fully connected layer), 3종류의 계층으로 표현될 수 있다. 콘볼루션 계층은 콘볼루션 특징을 추 출하는 계층으로, 의미있는 특징들을 추출하기 위한 층이다. 각각의 콘볼루션 계층은 콘볼루션 필터 (convolution filter)에 의해서 파라미터화될 수 있다. 콘볼루션 신경망(CNN)의 파워는 입력 데이터를 대상으로 단순 특성으로 시작하는 계층들로부터 오며, 후속되는 계층이 고 레벨 의미를 가지도록 각 계층들을 통하여 점 점 복잡한 특성들을 학습한다. 풀링 계층은 콘볼루션 계층 이후에 즉시 사용된다. 풀링 계층은 콘볼루션 계층의 출력을 단순화시킨다. 완전 연결 계층은 콘볼루션 계층과 풀링 계층에서 나온 특징을 이용하여 분류하는 층이다.여기서 언급되는 용어 “서브 샘플링” 또는 “다운 샘플링”은 신호의 전체 사이즈를 줄이는 것을 의미한다. “최대 풀링”으로 언급된 기술은, 감소된 행렬의 각각의 요소들의 최대값을 취하는 과정을 의미한다. 예시적인 실시 예에서, 여기에 게시되는 방법과 장치는 신경망을 훈련하는데 유용하다. 신경망은 이미지 데이터 로부터 사물 인식을 수행하도록 설정될 수 있다. 하지만, 예시적인 실시 예들은 설명을 위한 것일 뿐 본 발명은 여기에 국한되지 않는다. 따라서, 여기에 게시되는 방법과 장치는 신경망을 사용하는 다른 응용에서도 동일하게 사용될 수 있다. 이하, 첨부 도면을 참조하여 본 발명의 실시 예를 상세하게 설명한다. 그러나 다음에 예시하는 본 발명의 실시 예는 여러 가지 다른 형태로 변형될 수 있으며, 본 발명의 범위가 다음에 상술하는 실시 예에 한정되는 것은 아"}
{"patent_id": "10-2020-0014246", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "니다. 본 발명의 실시 예는 이 발명이 속하는 기술분야에서 통상의 지식을 가진 자에게 본 발명을 보다 완전하 게 설명하기 위하여 제공된다. 도 1은 본 발명의 이해를 돕기 위한 콘볼루션 신경망(CNN)의 구조를 도시한 도면이다. 도 1을 참조하면, 콘볼루션 신경망(CNN)은 특징 추출(feature extraction) 단계와 분류(classification) 단계 로 이루어진다. 특징 추출단계는 콘볼루션 계층과 풀링 계층으로 구성된 특징 추출 계층이 복수 개로 이루어진 다. 분류 단계는 완전 연결된 하나의 계층을 생성하고 추출된 특징들을 이용하여 결과치를 내는 단계이다. 콘볼루션 계층은 콘볼루션 기능을 수행하여 입력 이미지의 특징을 나타낸다. 콘볼루션 기능은 입력 유닛에 k×k 크기의 콘볼루션 필터를 적용하여 출력 유닛을 계산하는 기능이다. 출력 유닛은 이미지의 특징(Feature) 정보를 가진다. 콘볼루션 계산은 입력 유닛의 전 영역에서 가능한 모든 k×k 크기의 부분 영역을 추출하고, 그 다음 입 력 유닛과 출력 유닛 사이에 고유하게 지정된 콘볼루션 필터의 각 단위요소들과 n×n 크기의 부분 영역의 각 값 을 각각 곱한 후 합산하는 것(즉, 필터와 부분 영역 간의 내적의 곱의 합)을 의미한다. 여기서 콘볼루션 필터는 k×k 개의 파라미터로 구성되며, 커널(kernel)이라고도 지칭한다. 하나의 커널은 입력 유닛(즉, 채널)의 모든 부분 영역에 공통적으로 적용된다. 한 계층의 출력 유닛이 다음 계층을 위한 입력 유닛으로 이용될 수 있다. 한 계층의 입력 유닛으로 이용되면 그 유닛을 채널(channel)이라고도 지칭하며, 한 계층의 출력 유닛으로 이용되면 그 유닛을 특징 맵(feature map) 이라고도 지칭한다. 풀링 계층은 콘볼루션 계층의 출력을 단순화시킨다. 예를 들어, 풀링 계층은 공간적으로 입력을 다운 샘플링 한 다. 이미지 데이터는 많은 픽셀이 존재하기 때문에 특징을 줄이기 위해 서브 샘플링 한다. 풀링 방식 중 하나는 최대 풀링 방식의 서브 샘플링으로, 각 윈도에서 가장 큰 자극만을 선택하는 것이다. 마지막 특징 추출 계층의 출력 유닛은 완전 연결 계층(fully connected layer)과 추가로 연결된다. 완전 연결 계층에서는 복수의 특징 추출 계층을 통해 추출된 특징을 이용하여 이미지 데이터에서, 개, 고양이, 새 등을 분 류한다. 도 2는 본 발명의 일 실시 예에 따른 콘볼루션 신경망(CNN)에서의 기계학습 프로세스를 실제 처리하는 예를 도 시한 신경망 구조를 도시한 도면이다. 도 2를 참조하면, 특징 추출 단계에서, 32×32 픽셀 입력 이미지 데이터(Input)를 대상으로 5×5 콘볼루션 필터 를 통해 특징을 추출하여 28×28 이미지 4장(C1)을 추출하고, 이를 대상으로 2×2 서브 샘플링(크기를 줄이기 위한 액션)을 수행하여 동일한 4장의 14×14 이미지(S1)를 생성한다. 그리고 다시 5×5 콘볼루션 필터를 통해 특징을 추출하여 10×10 이미지 12장(C2)을 추출하고, 이를 대상으로 2×2 서브 샘플링 하여 동일한 12장의 5× 5 이미지(S2)를 생성하는 프로세스를 반복한다. 이어서, 분류 단계에서, 완전 연결된 하나의 행렬(n1)을 만들고 이를 신경망에 입력하여 값을 비교한 뒤 결과치(Output)를 얻는다. 도 3은 본 발명의 일 실시 예에 따른 다자 간 협업 기반 객체 인식 시스템의 구성을 도시한 도면이다. 도 3을 참조하면, 다자 간 협업 기반 객체 인식 시스템은 학습자 단말, 관리 서버 및 네트워크를 포함하며, 가이드 단말을 더 포함할 수 있다. 학습자 단말은 n(n은 정수)개로서, 서로 상이한 사용자가 소지하며, 객체 인식이 가능한 지능형 단말이다. 화면에 표시되는 객체의 종류를 파악하여 객체를 인식한 후 인식된 객체에 대한 부가 서비스 제공이 가능하다. 부가 서비스는 예를 들어, 객체에 대한 설명자료나 연계되는 제안이 가능한 웹 사이트 등으로 연결되는 서비스등이 있다. 학습자 단말은 인공지능 기반 기계학습을 위한 컴퓨터 자원을 가진다. 예시적인 자원은, 기계학습을 수행하 기 위한 메모리, 처리 능력, 데이터 스토리지 등을 포함한다. 각 학습자 단말(2-1, 2-2, …, 2-n) 별로 단말 능 력에 따라 학습 정도가 상이하게 마련이다. 예를 들어, 각 학습자 단말(2-1, 2-2, …, 2-n)의 단말 능력에 따라 학습에 의해 인식된 객체의 크기가 서로 상이하거나 방향에 따라서 모양이 크게 상이해질 수 있는데, 이 경우 객체 인식이 어려울 수 있다. 단말 능력은 학습자 단말의 기계학습을 처리할 수 있는 성능을 나타내는 파라 미터로서, 예를 들어, CPU의 개수, 클록 속도, 캐쉬 메모리의 크기 등이 될 수 있다. 또는 학습자 단말의 운 영체제(OS), 웹 브라우저 등이 될 수도 있다. 일 실시 예에 따른 다자 간 협업 기반 객체 인식 시스템은 전술한 개별 학습자 단말(2-1, 2-2, …, 2-n) 별 상이한 단말 능력을 고려하여 관리 서버와의 협업 기능을 통해 각 학습자 단말(2-1, 2-2, …, 2-n)의 학습을 가이드 하고 가이드를 통해 객체 인식 결과를 동기화 시켜 학습 정확도를 높이는 기능을 제안한다. 특히, 이와 같은 협업 기능을 교육에 접목시켰을 때 협업하는 형태로 객체를 인식하여 형태 파악에 더 정확한 결과를 도출 하거나 새로운 관찰형태를 보고하도록 가이드 할 수 있다. 개별 학습자 단말(2-1, 2-2, …, 2-n)의 인공지능을 이용하여 객체를 인식하고, 각 객체 인식 결과 값을 네트워 크를 거쳐 관리 서버에 전송한다. 각 객체 인식 결과 값은 학습된 객체 정보와 학습 기록을 포함한다. 예 를 들어, 객체 인식 대상으로서 '공 이미지'를 학습한다고 가정할 때, 학습된 객체 정보는 학습 대상이 되는 이 미지, 이미지를 학습한 결과인 '포케몬 볼', 이미지 개수 '50장'이고, 학습 기록은 '학습 정확도 80%'이다. 관리 서버는 개별 학습자 단말(2-1, 2-2, …, 2-n)로부터 수신된 객체 인식 결과 값들을 비교하여 가장 가능 성 높은 객체 인식 결과 값을 최종 객체 인식 결과 값으로 결정할 수 있다. 이때, 관리 서버가 결정된 최종 객체 인식 결과 값을 네트워크를 거쳐 개별 학습자 단말(2-1, 2-2, …, 2-n)에 전송하며, 개별 학습자 단말 (2-1, 2-2, …, 2-n)은 각각 자신의 객체 인식 결과 값을 최종 객체 인식 결과 값으로 변경하거나, 최종 객체 인식 결과 값을 참조하여 새로 객체를 인식하는 과정을 반복 수행함에 따라 개별 학습자 단말(2-1, 2-2, …, 2- n) 간 객체 인식 동기화를 달성할 수 있다. 개별 학습자 단말(2-1, 2-2, …, 2-n)에서는 관리 서버에서 확정 된 객체에 대해서는 수신하여 개별 학습자 단말(2-1, 2-2, …, 2-n)에서도 동일하게 동기를 맞추는 형태로 최종 객체 인식 결과 값을 서로 공유할 수 있다. 관리 서버는 개별 학습자 단말(2-1, 2-2, …, 2-n)로부터 수신된 객체 인식 결과 값들을 비교 분석함과 함께, 각 객체 인식 결과값들을 종합하여 구성해 보고 이에 대해 재검토를 할 수 있다. 관리 서버는 재검토 단계에서, 수신된 객체 인식 결과 값들이 서로 상이한지 여부를 파악하고 가장 가능성이 높은 단일의 최종 객체 인식 결과 값을 확정한 후 확정된 최종 객체 인식 결과 값을 개별 학습자 단말(2-1, 2-2, …, 2-n)에 전송하여 객체 인식 결과를 동기화 한다. 화면에 한 눈에 들어오는 객체라 하더라도 개별 학습자 단말(2-1, 2-2, …, 2-n)의 인식수준 및 학습 정도 등을 포함한 단말 성능에 따라 서로 상이한 객체 인식 결과 값이 도출될 수 있다. 서로 다른 개별 학습자 단말(2-1, 2-2, …, 2-n)에서 서로 상이한 이미지를 인식한 후 각 객체 인식 결과를 관리 서버로 전송하면, 관리 서버 에서 이를 확인하여 정상적인 객체 인식 결과 값인지를 파악해 보고, 아닐 경우 개별 학습자 단말(2-1, 2-2, …, 2-n)의 객체 인식 결과 값이 다 다른지 확인해 볼 수 있다. 이때, 다 다를 경우 인식한 객체가 동일한 숫자 가 많을수록 이를 최종 객체 인식 결과 값으로 확정할 수 있다. 다른 예로, 관리 서버는 개별 학습자 단말(2-1, 2-2, …, 2-n)로부터 수신된 객체 인식 결과 값을 조합하고 조합된 데이터를 대상으로 학습을 수행한 후, 관리 서버의 학습 결과 값을 최종 객체 인식 결과 값을 결정할 수 있다. 예를 들어, 큰 개체인 코끼리 같은 경우, 다리, 코, 몸통 등을 따로 따로 인식할 때는 다리, 코, 몸통 으로 인식하지만, 하나의 객체로 볼 때는 코끼리로 인식한다. 관리 서버는 개별 학습자 단말(2-1, 2-2, …, 2-n)로부터 수신된 객체 인식 결과 값(다리 이미지, 코 이미지, 몸통 이미지)를 조합하여 이를 학습한 후 최종 객체 인식 결과 값(코끼리)을 도출할 수 있다. 나아가, 관리 서버는 개별 학습자 단말(2-1, 2-2, …, 2-n)의 객체 인식 결과 값이 서로 상이한 경우 인식한 객체가 동일한 숫자가 많을수록 이를 중간 객체 인식 결과 값으로 잠정적으로 결정한 후, 개별 학습자 단말(2- 1, 2-2, …, 2-n)로부터 수신된 객체 인식 결과 값을 조합하고 조합된 데이터를 대상으로 학습을 수행한 후, 관 리 서버의 학습 결과와 개별 학습자 단말(2-1, 2-2, …, 2-n)의 학습 결과를 종합적으로 비교 분석한 후 최 종 객체 인식 결과 값을 결정할 수도 있다.일 실시 예에 따른 학습자 단말은 모바일 장치이다. 모바일 장치는 모바일 환경에서 사용 가능한 컴퓨팅 자 원을 가진다. 모바일 장치는 컴퓨팅 자원의 축소된 셋을 가질 수 있다. 모바일 장치의 예로서, 스마트폰, 태블 릿 컴퓨터 등이 있다. 모바일 장치는 애플사의 iOS 환경에서 동작하는 아이폰, 구글사의 안드로이드 환경에서 동작하는 안드로이드폰, 마이크로소프트사의 윈도 환경에서 동작하는 윈도폰을 모두 지원할 수 있다. 학습자 단 말은 헤드 마운트 디스플레이 (HMD), 스마트 글래스(smart glass) 등과 같이 사용자가 신체에 착용할 수 있 는 웨어러블 단말일 수도 있다. 학습자 단말은 원거리의 관리 서버에서 동작하는 자원들과 네트워크를 통해 통신할 수 있다. 다른 실시 예에 따른 학습자 단말은 사물 인터넷(Internet of Things, IoT)이 가능한 사물 인터넷 장치이다. 사물은 웹캠(webcam), 보안 카메라(security camera), 감시 카메라(surveillance camera), 온도 조절 장치 (thermostat), 심박 모니터(heart rate monitor), 스마트 가전(smart appliance), 스마트 자동차(smart car), 필드 구동 장치(field operation device), 다양한 센서들과 같은 다양한 장치들일 수 있다. 일 실시 예에서, 관리 서버는 블레이드 관리 서버와 같은 통상의 관리 서버를 포함할 수 있고, 메인 프레임, 개인용 컴퓨터의 네트워크 또는 단순한 개인용 컴퓨터일 수 있다. 관리 서버는 학습자 단말로부터 원거리 에 위치할 수 있다. 관리 서버는 집중형 데이터 스토리지(centralized data storage) 프로세싱(processing) 및 분석을 수행하는데, 딥 러닝(deep learning)을 수행할 수 있다. 딥 러닝은 높은 연산력과 많은 양의 데이터 저장용량을 요구한다. 관리 서버는 학습자 단말을 원격 제어할 수 있다. 이때, 학습자 단말의 실행 화 면을 모니터링 및 제어할 수 있다. 관리 서버는 신경망에 입력되는 입력 이미지를 조합하기 위한 이미지 처 리 능력을 포함할 수 있다. 가이드 단말은 동일한 입력 데이터를 기계학습 과제로서 개별 학습자 단말(2-1, 2-2, …, 2-n)에 제공한다. 이때, 개별 학습자 단말(2-1, 2-2, …, 2-n)은 과제로 할당된 기계학습을 수행하여 학습률을 높이기 위해 훈련 하는 교육용 단말로 기능할 수 있다. 도 4는 본 발명의 일 실시 예에 따른 학습자 단말의 구조를 도시한 도면이다. 도 4의 (a)에 도시된 바와 같이, 학습자 단말은 시력 보조장치와 제어장치로 분리된 형태일 수 있다. 시력 보조장치는 사용자 안경의 안경 다리에 탈부착하는 형태의 웨어러블 디바이스일 수 있다. 연결 부는 시력 보조장치와 제어장치를 연결한다. 연결부는 유선으로 시력 보조장치와 제어장치 를 연결할 수 있다. 무선방식을 이용하여 연결하거나 무선방식을 병행하여 사용할 수도 있다. 시력 보조장 치에 외부 영상을 촬영할 수 있는 촬영부가 장착되고 제어장치에 배터리가 장착될 수 있다. 시력 보조장치는 사용자가 착용 및 소지가 용이한 웨어러블 디바이스이다. 웨어러블 디바이스의 예로는 사 용자가 착용한 안경의 안경 테 또는 안경 다리 등에 탈부착하는 형태가 있다. 전면 또는 측면에 촬영부가 장착 되어, 촬영부를 통해 영상을 실시간 촬영할 수 있다. 이러한 웨어러블 디바이스는 기존의 일반적인 안경에 탈부 착 가능하며, 무게를 최소화하여 착용하기 편리하도록 한다. 도 4의 (b)에 도시된 바와 같이, 학습자 단말은 시력 보조장치가 스마트 기기과 연동된 형태일 수 있다. 스마트 기기는 스마트폰 등이 있다. 연결부는 시력 보조장치와 스마트 기기를 연결한다. 연결부는 유선으로 시력 보조장치와 스마트 기기를 연결할 수 있다. 무선방식을 이용하여 연결하거 나 무선방식을 병행하여 사용할 수도 있다. 시력 보조장치에 외부 영상을 촬영할 수 있는 촬영부가 장착되 고 스마트 기기의 배터리를 이용할 수 있다. 스마트 기기는 화면에 표시되는 시각정보를 인식할 수 있 다. 도 4의 (c)에 도시된 바와 같이, 학습자 단말은 시력 보조장치 없이 스마트 기기일 수 있다. 예를 들어, 시력 보조장치를 착용하는 것 없이, 스마트 기기만을 이용하여 전술한 기능들을 수행할 수 있다. 이때, 스마트 기기 자체에 장착된 촬영부를 이용하여 외부영상을 촬영할 수 있고, 촬영된 영상 또는 표시 화면을 인식할 수 있다. 도 5는 본 발명의 일 실시 예에 따른 학습자 단말의 세부 구성을 도시한 도면이다. 도 3 및 도 5를 참조하면, 학습자 단말은 입력부, 프로세서, 출력부, 메모리, 통신부 및 배터리를 포함한다. 촬영부는 실시간으로 외부영상을 촬영한다. 촬영부는 카메라일 수 있다. 입력부는 사용자로부터 조 작신호를 입력 받는다. 예를 들어, 키보드나 마우스 등의 입력장치를 통해 사용자 조작신호를 입력 받을 수 있다. 또한, 입력부는 기계학습 대상이 되는 입력 데이터를 획득한다. 이때, 입력 데이터는 사용자로부터 입 력 받을 수 있고, 촬영부를 통해 촬영된 이미지 데이터를 입력 받을 수 있으며, 외부장치(예를 들어, 가이 드 단말)로부터 입력 받을 수도 있다. 입력 데이터는 이미지, 영상, 음성 등일 수 있다. 메모리는 데이터와 기계학습 명령어가 저장된다. 기계학습 명령어는 컴퓨팅 리소스 및 관련된 컴포넌트의 제어를 통해서 구현되는 본 발명의 방법을 실행하기 위한 것이다. 프로세서는 학습자 단말의 각 구성요소를 제어한다. 일 실시 예에 따른 프로세서는 메모리에 저 장된 기계학습 명령어를 이용하여 입력부를 통해 입력 받은 데이터에 대해 기계학습을 수행하여 객체를 인 식하고 객체 인식 결과 값을 통신부를 통해 관리 서버에 전송한다. 프로세서의 기계학습 프로세스는 도 1 및 도 2를 참조로 하여 전술한 바와 같다. 프로세서는 관리 서버로부터 통신부를 통해 최종 객 체 인식 결과 값을 수신하면, 객체 인식 결과 값을 최종 객체 인식 결과 값으로 변경하거나, 최종 객체 인식 결 과 값을 참조하여 새로 기계학습을 수행하여 객체를 인식하는 과정을 반복함에 따라 객체 인식 결과를 다른 학 습자 단말들과 동기화 한다. 통신부는 유무선 인터페이스를 통해 관리 서버와 통신한다. 무선 인터페이스는 셀룰러, 블루투스, Wi- Fi, NFC, ZigBee 등의 프로토콜을 사용할 수 있다. 통신 서비스는 블루투스, Wi-Fi, 이더넷, DSL, LTE, PCS, 2G, 3G, 4G, 5G, LAN, CDMA, TDMA, GSM, WDM, WLAN 등을 포함하는 무선 통신 인터페이스를 통해서 제공될 수 있다. 통신 인터페이스는 음성 채널을 포함할 수 있다. 일 실시 예에 따른 통신부는 프로세서에서 생성 된 객체 인식 결과 값을 관리 서버에 전송하고, 관리 서버로부터 생성된 최종 객체 인식 결과 값을 수신 한다. 통신부는 서브 샘플링을 거쳐 그 크기가 줄어든 중간 데이터를 관리 서버에 전송할 수 있다. 이 경우, 입력 데이터가 통으로 관리 서버에 전송되는 경우에 비해 훨씬 작은 데이터가 관리 서버에 전송되 므로 데이터 대역폭도 줄고 이후 프로세스를 관리 서버에서 신속하게 처리할 수 있기 때문에 정확도와 효율 성이 향상된다. 출력부는 학습자 단말의 동작 수행을 위해 필요한 정보나 동작 수행에 따라 생성되는 정보를 출력한다. 출력부는 디스플레이나 터치패널 등의 출력장치거나 이와 연결될 수 있다. 통신부가 관리 서버로부 터 최종 객체 인식 결과 값을 수신하면, 출력부는 이를 화면에 출력할 수 있고, 청각정보 형태로 출력할 수 도 있다. 청각정보는 음성신호, 경고음 등이다. 도 6은 본 발명의 일 실시 예에 따른 관리 서버의 구성을 도시한 도면이다. 도 3 및 도 6을 참조하면, 관리 서버는 수신부, 분석부, 학습부, 최종 결정부 및 전송부 를 포함한다. 수신부는 각 학습자 단말(2-1, 2-2, …, 2-n)로부터 객체 인식 결과 값을 수신한다. 분석부는 수신부를 통해 수신된 각 객체 인식 결과 값을 비교 분석한다. 분석부는 각 학습자 단말 (2-1, 2-2, …, 2-n)로부터 수신된 객체 인식 결과 값이 정상적인 값인지를 판단하고, 객체 인식 결과 값들을 비교 분석하여 서로 동일한 객체 인식 결과 값이 있는지 여부를 판단할 수 있다. 학습부는 수신부를 통해 수신된 각 객체 인식 결과 값을 조합하고 조합된 데이터를 대상으로 학습을 수 행한다. 이때, 조합은 수신 이미지들을 서로 겹치는 방식, 한 장에 수신 이미지를 모으는 방식 등이 있다. 예를 들어, 서로 겹치는 방식은 각 학습자 단말이 포케몬 볼, 요가볼, 볼링 볼과 같이 '공'이라는 공통된 객체를 인 식한 경우에 해당하고, 한 장에 수신 이미지를 모으는 방식은 각 학습자 단말이 코끼리의 부분에 해당하는 다리, 코, 몸통 등을 인식한 경우에 해당한다. 최종 결정부는 각 학습자 단말로부터 수신된 객체 인식 결과 값들을 비교 분석하여 서로 동일한 객체 인식 결과 값의 수가 가장 많이 나오는 조건 또는 학습 정확도가 가장 높은 조건 중 적어도 하나를 충족하는 객체 인 식 결과 값을 최종 객체 인식 결과 값을 결정할 수 있다. 예를 들어, 학습자 단말1(2-1)의 객체 인식 결과 값이 학습 이미지 50장, 학습 정확도 80%, '포케몬 볼'이고, 학습자 단말2(2-2)의 객체 인식 결과 값이 학습 이미지 70장, 학습 정확도 85%, '요가 볼'이며, 학습자 단말3(2-3)의 객체 인식 결과 값이 학습 이미지 100장, 학습 정 확도 90%, '볼링 볼'이면, 학습 이미지 장수가 가장 많고 학습 정확도가 가장 높은 '볼링 볼'을 최종 객체 인식 결과 값으로 결정한다. 다른 예로, 최종 결정부는 각 학습자 단말(2-1, 2-2, …, 2-n)로부터 수신된 객체 인식 결과 값을 조합하고 조합된 데이터를 대상으로 학습을 수행하여 조합 데이터의 학습 결과를 최종 객체 인식 결과 값을 결정할 수 있다. 예를 들어, 학습자 단말1(2-1)의 객체 인식 결과 값이 '다리'이고, 학습자 단말2(2-2)의 객체 인식 결과 값 이 '코'이며, 학습자 단말3(2-3)의 객체 인식 결과 값이 '몸통'이면 '다리', '코', '몸통'을 조합한 조합 데이 터의 학습 수행 결과인 '코끼리'를 최종 객체 인식 결과 값으로 결정한다. 또 다른 예로, 최종 결정부는 각 학습자 단말(2-1, 2-2, …, 2-n)로부터 수신된 객체 인식 결과 값을 조합 하고 조합된 데이터를 대상으로 학습을 수행한 후, 조합 데이터의 학습 결과와 각 학습자 단말(2-1, 2-2, …, 2-n)의 학습 결과를 종합적으로 비교 분석한 후 최종 객체 인식 결과 값을 결정할 수 있다. 이를 위해, 최종 결 정부는 제1 결정부와 제2 결정부를 포함할 수 있다. 제1 결정부는 각 학습자 단말(2-1, 2-2, …, 2-n)의 학습 결과를 비교 분석한 결과 동일한 객체 인식 결과 값이 있으면 동일한 객체 인식 결과 값의 수가 가장 많이 나오는 조건 또는 학습 정확도가 가장 높은 조건 중 적어도 하나를 충족하는 객체 인식 결과 값을 중간 객체 인식 결과 값으로 1차 결정한다. 제2 결정부는 제 1 결정부의 중간 객체 인식 결과 값과 학습부의 조합 데이터의 학습 수행 결과 값을 비교하여 서로 동 일한 객체인지 여부를 판단한다. 이때, 동일하면 중간 객체 인식 결과 값을 최종 객체 인식 결과 값으로 확정한 다. 서로 상이하면 중간 인식 결과 값과 조합 데이터의 학습 수행 결과 값을 함께 제공한다. 이때, 학습부의 조합 데이터의 학습 수행 결과 학습 정확도가 미리 설정된 역치 값, 예를 들어 95%를 넘으 면 제2 결정부는 학습부의 학습 수행 결과 값을 최종 객체 인식 결과 값으로 결정할 수 있다. 이에 비해, 학습 수행 결과 학습 정확도가 미리 설정된 역치 값, 예를 들어 95% 이하이면 제2 결정부는 중간 인 식 결과 값과 조합 데이터의 학습 수행 결과 값을 함께 전송부에 전달할 수 있다. 학습부의 학습 수행 결과가 미리 설정된 역치 값을 넘는 경우는 관리 서버의 학습을 신뢰할 수 있는 경우이다. 미리 설정된 역치 값을 넘지 못하는 경우는 관리 서버의 학습을 신뢰하기 어려운 경우에 해당하므로, 중간 인식 결과 값과 조 합 데이터의 학습 수행 결과 값을 함께 각 학습자 단말(2-1, 2-2, …, 2-n)에 제공한 후 미리 설정된 역치 값이 넘도록 학습부를 통해 학습을 추가로 수행할 수 있다. 전송부는 학습자 단말(2-1, 2-2, …, 2-n) 간 객체 인식 결과 동기화를 위해 각 학습자 단말(2-1, 2-2, …, 2-n)에 최종 객체 인식 결과 값을 전송한다. 관리 서버는 전송부가 최종 객체 인식 결과 값을 각 학습자 단말(2-1, 2-2, …, 2-n)에 전송하면서 재 학습을 요청하고, 수신부가 각 학습자 단말(2-1, 2-2, …, 2- n)로부터 재 학습된 객체 인식 결과 값을 수신하는 과정을 반복함에 따라 학습자 단말(2-1, 2-2, …, 2-n)의 학 습을 교육시킬 수 있다. 도 7은 본 발명의 일 실시 예에 따른 다자 간 협업 기반 객체 인식 시나리오를 도시한 도면이다. 도 3 및 도 7을 참조하면, 가이드 단말이 새로운 객체 인지 과제인 '포케몬 볼 이미지'를 10개의 학습자 단 말(2-1, 2-2, …, 2-10)에 제공한다. 학습 과제에 대해 10개의 학습자 단말(2-1, 2-2, …, 2-10)이 각각 학습 을 수행한다. 학습 수행 결과, 학습자1이 소지한 학습자 단말1(2-1)의 객체 인식 결과 값이 학습 이미지 50장, 학습 정확도 80%, '포케몬 볼'이고, 학습자2가 소지한 학습자 단말2(2-2)의 객체 인식 결과 값이 학습 이미지 70장, 학습 정확도 85%, '요가 볼'이며, 학습자10이 소지한 학습자 단말10(2-10)의 객체 인식 결과 값이 학습 이미지 100장, 학습 정확도 90%, '볼링 볼'이면, 이를 각각 관리 서버에 전송한다. 관리 서버는 학습 이미지 장수가 가장 많고 학습 정확도가 가장 높은 '볼링 볼'을 최종 객체 인식 결과 값으 로 결정할 수 있다. 그러나 도 7의 예에 도시된 바와 같이 '볼링 볼'은 가이드 단말이 제공한 새로운 객체 인지 과제인 '포케몬 볼'이 아니므로 잘못된 결과에 해당한다. 이와 같은 오류를 회피하기 위해, 관리 서버 는 각 학습자 단말(2-1, 2-2, …, 2-10)로부터 수신된 객체 인식 결과 값을 조합하고 조합된 데이터를 대상으로 학습을 수행한 후, 조합 데이터의 학습 결과와 각 학습자 단말(2-1, 2-2, …, 2-10)의 학습 결과를 종합적으로 비교 분석한 후 최종 객체 인식 결과 값을 결정할 수 있다. 예를 들어, 학습자 단말1(2-1)의 학습 이미지 50장 과, 학습자 단말2(2-2)의 학습 이미지 70장과, 학습자10의 학습자 단말10(2-10)의 학습 이미지 100장을 조합한 220장을 대상으로 학습을 수행한 후, 조합 데이터의 학습 결과인 '포케몬 볼'을 최종 객체 인식 결과 값으로 결 정한다. 관리 서버는 최종 객체 인식 결과 값 '포케몬 볼'을 각 학습자 단말(2-1, 2-2, …, 2-10)에 전송함 으로써, 각 학습자 단말(2-1, 2-2, …, 2-10)이 '포케몬 볼'로 객체 인식 결과를 변경하도록 재 학습을 시켜서 최종적으로 각 학습자 단말(2-1, 2-2, …, 2-10)이 '포케몬 볼'로 객체 인식 결과를 동기화 시킨다. 도 8은 본 발명의 일 실시 예에 따른 다자 간 협업 기반 객체 인식 방법의 프로세스를 도시한 도면이다. 도 3 및 도 8을 참조하면, 관리 서버는 동일한 입력 데이터를 대상으로 다수의 학습자 단말(2-1, 2-2, …, 2-n)로부터 각각 객체 인식 결과 값을 수신한다.이어서, 관리 서버는 수신된 객체 인식 결과 값들로부터 단일의 최종 객체 인식 결과 값을 결정한다. 최종 객체 인식 결과 값을 결정하는 단계에서, 관리 서버는 각 객체 인식 결과 값을 비교 분석하고, 각 객체 인식 결과 값을 조합하고 조합된 데이터를 대상으로 학습을 수행한 후, 각 객체 인식 결과 값에 대한 비교 분석 결과와, 조합된 데이터에 대한 학습 수행 결과 값을 종합적으로 판단하여 단일의 최종 객체 인식 결과 값 을 결정할 수 있다. 이때, 각 학습자 단말(2-1, 2-2, …, 2-n)로부터 수신된 객체 인식 결과 값들을 비교 분석 하여 서로 동일한 객체 인식 결과 값의 수가 가장 많이 나오는 조건 또는 학습 정확도가 가장 높은 조건 중 적 어도 하나를 충족하는 객체 인식 결과 값을 중간 객체 인식 결과 값으로 결정할 수 있다. 나아가, 관리 서버는 중간 객체 인식 결과 값과 조합 데이터의 학습 수행 결과 값을 비교하여 서로 동일한 객체인지 여부를 판단할 수 있다. 이때, 동일하면 중간 객체 인식 결과 값을 최종 객체 인식 결과 값으로 확정 하고, 서로 상이하면 중간 인식 결과 값과 조합 데이터의 학습 수행 결과 값을 함께 각 각 학습자 단말(2-1, 2- 2, …, 2-n)에 제공할 수 있다. 이어서, 관리 서버는 각 학습자 단말(2-1, 2-2, …, 2-n)에 최종 객체 인식 결과 값을 전송하여 학습자 단말 (2-1, 2-2, …, 2-n) 간에 객체 인식 결과를 동기화 시킨다. 관리 서버는 최종 객체 인식 결과 값을 각 학습자 단말(2-1, 2-2, …, 2-n)에 전송하면서 재 학습을 요청하고, 각 학습자 단말(2-1, 2-2, …, 2-n)이 최종 객체 인식 결과 값을 참조하여 재 학습을 수행하면, 각 학습자 단말(2-1, 2-2, …, 2-n)로부터 재 학습된 객체 인식 결과 값을 수신하는 과정을 반복함에 따라 각 학습자 단말(2-1, 2-2, …, 2-n)의 학습을 훈련 시킬 수 있 다."}
{"patent_id": "10-2020-0014246", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "이제까지 본 발명에 대하여 그 실시 예들을 중심으로 살펴보았다. 본 발명이 속하는 기술분야에서 통상의 지식 을 가진 자는 본 발명이 본 발명의 본질적인 특성에서 벗어나지 않는 범위에서 변형된 형태로 구현될 수 있음을 이해할 수 있을 것이다. 그러므로 개시된 실시 예들은 한정적인 관점이 아니라 설명적인 관점에서 고려되어야 한다. 본 발명의 범위는 전술한 설명이 아니라 특허청구범위에 나타나 있으며, 그와 동등한 범위 내에 있는 모 든 차이점은 본 발명에 포함된 것으로 해석되어야 할 것이다.도면 도면1 도면2 도면3 도면4 도면5 도면6 도면7 도면8"}
{"patent_id": "10-2020-0014246", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 이해를 돕기 위한 콘볼루션 신경망(CNN)의 구조를 도시한 도면, 도 2는 본 발명의 일 실시 예에 따른 콘볼루션 신경망(CNN)에서의 기계학습 프로세스를 실제 처리하는 예를 도 시한 신경망 구조를 도시한 도면, 도 3은 본 발명의 일 실시 예에 따른 다자 간 협업 기반 객체 인식 시스템의 구성을 도시한 도면, 도 4는 본 발명의 일 실시 예에 따른 학습자 단말의 구조를 도시한 도면, 도 5는 본 발명의 일 실시 예에 따른 학습자 단말의 세부 구성을 도시한 도면, 도 6은 본 발명의 일 실시 예에 따른 관리 서버의 구성을 도시한 도면, 도 7은 본 발명의 일 실시 예에 따른 다자 간 협업 기반 객체 인식 시나리오를 도시한 도면, 도 8은 본 발명의 일 실시 예에 따른 다자 간 협업 기반 객체 인식 방법의 프로세스를 도시한 도면이다."}
