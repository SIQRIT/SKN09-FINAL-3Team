{"patent_id": "10-2021-0176065", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0087691", "출원번호": "10-2021-0176065", "발명의 명칭": "가상 공간의 다양한 작업 콘텐츠를 이용하여 원격에서 로봇을 제어하는 원격제어장치 및 시스", "출원인": "한국전자기술연구원", "발명자": "문종술"}}
{"patent_id": "10-2021-0176065", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "로봇과 사용자 단말과 통신을 하는 통신부; 및상기 로봇으로부터 영상정보 및 3차원 공간정보를 수신하면 상기 수신된 정보를 이용하여 객체를 검출하고, 상기 검출된 객체를 기반으로 상기 로봇의 이동경로를 생성하며, 상기 영상정보를 기초로 상기 사용자 단말에서상기 로봇의 작업을 선택하여 제어할 수 있는 사용자 인터페이스, 상기 객체 및 상기 이동경로가 표시되는 콘텐츠를 생성하고, 상기 생성된 콘텐츠를 상기 사용자 단말로 전송시키는 제어부;를 포함하는 가상 공간의 다양한 작업 콘텐츠를 이용하여 원격에서 로봇을 제어하는 원격제어장치."}
{"patent_id": "10-2021-0176065", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1항에 있어서,상기 제어부는,딥러닝 기반의 인공지능 모델을 이용하여 상기 객체를 검출하는 것을 특징으로 하는 가상 공간의 다양한 작업콘텐츠를 이용하여 원격에서 로봇을 제어하는 원격제어장치."}
{"patent_id": "10-2021-0176065", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 1항에 있어서,상기 제어부는,상기 사용자 단말로부터 수신된 객체 선택과 관련된 사용자 입력에 따라 원하는 객체만이 선택적으로 표시되도록 상기 콘텐츠를 생성하는 것을 특징으로 하는 가상 공간의 다양한 작업 콘텐츠를 이용하여 원격에서 로봇을제어하는 원격제어장치."}
{"patent_id": "10-2021-0176065", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 1항에 있어서,상기 제어부는,상기 사용자 단말로부터 수신된 작업 선택과 관련된 사용자 입력에 따라 상기 작업과 관련된 객체만이 선택적으로 표시되도록 상기 콘텐츠를 생성하는 것을 특징으로 하는 가상 공간의 다양한 작업 콘텐츠를 이용하여 원격에서 로봇을 제어하는 원격제어장치."}
{"patent_id": "10-2021-0176065", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제 1항에 있어서,상기 제어부는,상기 3차원 공간정보를 이용하여 상기 객체와 상기 로봇의 상대거리가 표시되도록 상기 콘텐츠를 생성하는 것을특징으로 하는 가상 공간의 다양한 작업 콘텐츠를 이용하여 원격에서 로봇을 제어하는 원격제어장치."}
{"patent_id": "10-2021-0176065", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제 1항에 있어서,상기 제어부는,상기 로봇에 장착된 작업 도구의 자세 정보를 더 수신하고, 상기 작업 도구가 상기 객체에 향하는 경우, 연장선을 통해 상기 객체를 조작하는 가이드라인이 표시되도록 상기 콘텐츠를 생성하는 것을 특징으로 하는 가상 공간공개특허 10-2023-0087691-3-의 다양한 작업 콘텐츠를 이용하여 원격에서 로봇을 제어하는 원격제어장치."}
{"patent_id": "10-2021-0176065", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제 1항에 있어서,상기 제어부는,1인칭 영상정보 및 3인칭 로봇 상태를 동시에 표현되도록 상기 콘텐츠를 생성하는 것을 특징으로 하는 가상 공간의 다양한 작업 콘텐츠를 이용하여 원격에서 로봇을 제어하는 원격제어장치."}
{"patent_id": "10-2021-0176065", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "이동이 가능하고, 기 설정된 작업을 수행하는 로봇;상기 로봇을 원격지에서 제어하는 사용자 단말; 및상기 로봇 및 상기 사용자 단말 사이에서 상기 사용자 단말이 상기 로봇을 원격 제어하도록 지원하는 원격제어장치;를 포함하되,상기 원격제어장치는,상기 로봇과 상기 사용자 단말과 통신을 하는 통신부; 및상기 로봇으로부터 영상정보 및 3차원 공간정보를 수신하면 상기 수신된 정보를 이용하여 객체를 검출하고, 상기 검출된 객체를 기반으로 상기 로봇의 이동경로를 생성하며, 상기 영상정보를 기초로 상기 사용자 단말에서상기 로봇의 작업을 선택하여 제어할 수 있는 사용자 인터페이스, 상기 객체 및 상기 이동경로가 표시되는 콘텐츠를 생성하고, 상기 생성된 콘텐츠를 상기 사용자 단말로 전송시키는 제어부;를 포함하는 것을 특징으로 하는 원격제어시스템."}
{"patent_id": "10-2021-0176065", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 가상 공간의 다양한 작업 콘텐츠를 이용하여 원격에서 로봇을 제어하는 원격제어장치 및 시스템이 개 시된다. 본 발명의 원격제어장치는 로봇과 사용자 단말과 통신을 하는 통신부 및 로봇으로부터 영상정보 및 3차 원 공간정보를 수신하면 수신된 정보를 이용하여 객체를 검출하고, 검출된 객체를 기반으로 로봇의 이동경로를 생성하며, 영상정보를 기초로 사용자 단말에서 로봇의 작업을 선택하여 제어할 수 있는 사용자 인터페이스, 객체 및 이동경로가 표시되는 콘텐츠를 생성하고, 생성된 콘텐츠를 사용자 단말로 전송시키는 제어부를 포함한다."}
{"patent_id": "10-2021-0176065", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 로봇의 원격 제어 기술에 관한 것으로, 더욱 상세하게는 원격지에서 실제 영상의 작업 대상물 종류와 영역 등을 가상 공간에 표현하여 원활한 로봇 제어를 할 수 있도록 지원하는 가상 공간의 다양한 작업 콘텐츠를 이용하여 원격에서 로봇을 제어하는 원격제어장치 및 시스템에 관한 것이다."}
{"patent_id": "10-2021-0176065", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "산불, 지진, 해일 등과 같은 재난은 그 자체만으로 사람에게 큰 피해를 주기도 하지만 그로 인한 산업 시설의 파손으로 인해 2차 피해가 발생할 뿐만 아니라, 2차 피해로 인한 인명 피해가 발생하는 경우가 많다. 일 예로 2011년 3월 11일에 일본의 동일본해에서 발생한 9.0 강도의 지진은 14m 이상의 쓰나미를 발생시켜 많은 인명 피해를 야기시키고, 후쿠시마 원전에 손상을 입혀 방사능 누출이라는 심각한 피해를 발생시켰다. 이와 같은 재난 상황에서는 후쿠시마 원전에 손상을 입혀 방사능 누출이라는 심각한 피해를 발생시켰다. 이와 같은 후쿠시마 원전 사고에서는 원전 내부의 상태를 파악하거나 방사능 누출을 차단하기 위한 수리 등의 작업에 사람이 직접 투입되는 것 자체가 큰 위험 요소를 안고 있으므로 사람을 대신할 이동 로봇이 필요하게 되 고, 이동 로봇이 재난 상황에서 재난의 확산을 방지하고 피해를 최소화하며 사고 처리를 수행하는 등 다양한 기 능을 수행하게 된다. 한편 사람이 투입되기 힘든 상황에서 제어되는 로봇의 경우, 대부분 사람에 의해 원격 제어가 이루어지는 특징 이 있다. 따라서 원격지에 위치한 조정자가 로봇의 주변 환경을 확인하면서 조정이 가능하도록 로봇에 카메라를 설치하고, 카메라에 의해 전송된 촬영 영상을 주시하면서 로봇을 제어한다. 하지만 이러한 제어는 조정자가 원 격 제어를 하는데 있어서 제약이 많으며, 제어 자체가 어려운 점을 가지고 있다. 선행기술문헌특허문헌 (특허문헌 0001) 한국등록특허공보 제10-1478908호 (2015.01.02.)"}
{"patent_id": "10-2021-0176065", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명이 이루고자 하는 기술적 과제는 원격지에서의 작업이 쉬워지도록 가상 공간에서 실제 영상의 작업 대상 물 종류와 영역 등을 표현하는 가상 공간의 다양한 작업 콘텐츠를 이용하여 원격에서 로봇을 제어하는 원격제어 장치 및 시스템을 제공하는데 목적이 있다. 본 발명이 이루고자 하는 다른 기술적 과제는 사용자가 원하는 객체만을 선택적으로 인식할 수 있는 가상 공간 에서 다양한 작업 콘텐츠를 제공하여 원격에서 로봇을 제어하는 원격제어장치 및 시스템을 제공하는데 목적이 있다."}
{"patent_id": "10-2021-0176065", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기 목적을 달성하기 위해 본 발명에 따른 가상 공간의 다양한 작업 콘텐츠를 이용하여 원격에서 로봇을 제어 하는 원격제어장치는 로봇과 사용자 단말과 통신을 하는 통신부 및 상기 로봇으로부터 영상정보 및 3차원 공간 정보를 수신하면 상기 수신된 정보를 이용하여 객체를 검출하고, 상기 검출된 객체를 기반으로 상기 로봇의 이 동경로를 생성하며, 상기 영상정보를 기초로 상기 사용자 단말에서 상기 로봇의 작업을 선택하여 제어할 수 있 는 사용자 인터페이스, 상기 객체 및 상기 이동경로가 표시되는 콘텐츠를 생성하고, 상기 생성된 콘텐츠를 상기 사용자 단말로 전송시키는 제어부를 포함한다. 또한 상기 제어부는, 딥러닝 기반의 인공지능 모델을 이용하여 상기 객체를 검출하는 것을 특징으로 한다. 또한 상기 제어부는, 상기 사용자 단말로부터 수신된 객체 선택과 관련된 사용자 입력에 따라 원하는 객체만이 선택적으로 표시되도록 상기 콘텐츠를 생성하는 것을 특징으로 한다. 또한 상기 제어부는, 상기 사용자 단말로부터 수신된 작업 선택과 관련된 사용자 입력에 따라 상기 작업과 관련 된 객체만이 선택적으로 표시되도록 상기 콘텐츠를 생성하는 것을 특징으로 한다. 또한 상기 제어부는, 상기 3차원 공간정보를 이용하여 상기 객체와 상기 로봇의 상대거리가 표시되도록 상기 콘 텐츠를 생성하는 것을 특징으로 한다. 또한 상기 제어부는, 상기 로봇에 장착된 작업 도구의 자세 정보를 더 수신하고, 상기 작업 도구가 상기 객체에 향하는 경우, 연장선을 통해 상기 객체를 조작하는 가이드라인이 표시되도록 상기 콘텐츠를 생성하는 것을 특징 으로 한다. 또한 상기 제어부는, 1인칭 영상정보 및 3인칭 로봇 상태를 동시에 표현되도록 상기 콘텐츠를 생성하는 것을 특 징으로 한다. 본 발명에 따른 원격제어시스템은 이동이 가능하고, 기 설정된 작업을 수행하는 로봇, 상기 로봇을 원격지에서 제어하는 사용자 단말 및 상기 로봇 및 상기 사용자 단말 사이에서 상기 사용자 단말이 상기 로봇을 원격 제어 하도록 지원하는 원격제어장치를 포함하되, 상기 원격제어장치는, 상기 로봇과 상기 사용자 단말과 통신을 하는 통신부 및 상기 로봇으로부터 영상정보 및 3차원 공간정보를 수신하면 상기 수신된 정보를 이용하여 객체를 검 출하고, 상기 검출된 객체를 기반으로 상기 로봇의 이동경로를 생성하며, 상기 영상정보를 기초로 상기 사용자 단말에서 상기 로봇의 작업을 선택하여 제어할 수 있는 사용자 인터페이스, 상기 객체 및 상기 이동경로가 표시 되는 콘텐츠를 생성하고, 상기 생성된 콘텐츠를 상기 사용자 단말로 전송시키는 제어부를 포함하는 것을 특징으 로 한다."}
{"patent_id": "10-2021-0176065", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명의 가상 공간의 다양한 작업 콘텐츠를 이용하여 원격에서 로봇을 제어하는 원격제어장치 및 시스템은 격 지에서의 작업이 쉬워지도록 가상 공간에서 실제 영상의 작업 대상물 종류와 영역 등을 표현함으로써, 객체의정보를 다양하고 정확하게 표현할 수 있다. 또한 사용자가 원하는 객체만을 선택적으로 인식할 수 있도록 별도의 사용자 인터페이스(UI)를 제공하여 작업 편의성을 극대화할 수 있다."}
{"patent_id": "10-2021-0176065", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하 본 발명의 실시예를 첨부된 도면들을 참조하여 상세히 설명한다. 우선 각 도면의 구성요소들에 참조부호를 부가함에 있어서, 동일한 구성요소들에 대해서는 비록 다른 도면상에 표시되더라도 가능한 한 동일한 부호를 가 지도록 하고 있음에 유의한다. 또한 본 발명을 설명함에 있어, 관련된 공지 구성 또는 기능에 대한 구체적인 설 명이 당업자에게 자명하거나 본 발명의 요지를 흐릴 수 있다고 판단되는 경우에는 그 상세한 설명은 생략한다. 도 1은 본 발명의 실시예에 따른 원격제어시스템을 설명하기 위한 구성도이다. 도 1을 참조하면, 원격제어시스템은 원격지에서의 작업이 쉬워지도록 가상 공간에서 실제 영상의 작업 대 상물 종류와 영역 등을 표현한다. 원격제어시스템은 사용자가 원하는 객체만을 선택적으로 인식할 수 있는 가상 공간에서 다양한 작업 콘텐츠를 제공하여 원격에서 로봇을 제어한다. 원격제어시스템는 원격제어장치 , 로봇 및 사용자 단말을 포함한다. 원격제어장치는 로봇 및 사용자 단말 사이에서 사용자 단말이 로봇을 원격 제어하도 록 지원한다. 원격제어장치는 로봇으로부터 수신된 영상정보 및 3차원 공간정보를 기반으로 사용자 단말에서 출력하는 콘텐츠를 생성하고, 생성된 콘텐츠를 사용자 단말로 전송한다. 여기서 콘텐츠는 가상 공간에서 로봇이 다양한 작업을 수행하도록 지원하는 콘텐츠로써, 사용자 입력에 따라 작업, 객체, 이동경로 등을 선택할 수 있는 사용자 인터페이스를 포함한다. 원격제어장치는 데스크톱, 서버 컴퓨터, 클 러스터 컴퓨터 등을 포함하는 서버용 컴퓨터일 수 있다. 로봇은 원격제어장치와의 통신을 하고, 원격제어장치로부터 수신된 사용자 입력에 따라 이동 또 는 작업을 수행한다. 이를 위해 로봇는 이동을 가능하게 하는 이동수단과, 기 설정된 작업을 수행하기 위 한 로봇 관절, 암 등을 포함한다. 기 설정된 작업은 작업 도구를 통한 객체 조작, 객체 이동 등이 포함될 수 있 다. 또한 로봇은 스테레오 카메라(stereo camera) 및 라이다(LiDAR)를 포함하여 영상정보 및 깊이정보를 측정함으로써, 3차원 공간정보를 수집할 수 있으며, 각 관절에 대한 상태를 감지하는 관절 정보도 수집할 수 있 다. 로봇는 수집된 정보를 원격제어장치로 전송한다. 사용자 단말은 원격제어장치와의 통신을 하고, 원격제어장치로부터 로봇과 관련된 콘텐츠 를 수신하고, 수신된 콘텐츠를 출력한다. 사용자 단말은 출력된 콘텐츠에 대응되는 사용자 입력이 입력되 면 입력된 사용자 입력을 원격제어장치로 전송하여 사용자 입력에 따라 로봇이 제어되도록 한다. 사 용자 단말은 HMD(Head Mounted Display), 스마트폰, 랩톱, 데스크톱, 테블릿 PC, 핸드헬드 PC 등을 포함 하는 개인용 컴퓨팅 시스템일 수 있고, 바람직하게는 가상 공간을 출력하기에 특화된 HMD일 수 있다. 한편 원격제어시스템은 원격제어장치, 로봇 및 사용자 단말 간의 통신을 수행하기 위한 통 신망을 포함한다. 통신망은 백본망과 가입자망으로 구성될 수 있다. 백본망은 X.25 망, Frame Relay 망, ATM망, MPLS(Multi Protocol Label Switching) 망 및 GMPLS(Generalized Multi Protocol Label Switching) 망 중 하나 또는 복수의 통합된 망으로 구성될 수 있다. 가입자망은 FTTH(Fiber To The Home), ADSL(Asymmetric Digital Subscriber Line), 케이블망, 지그비(zigbee), 블루투스(bluetooth), WirelessLAN(IEEE 802.11b, IEEE 802.11a, IEEE 802.11g, IEEE 802.11n), Wireless Hart(ISO/IEC62591-1), ISA100.11a(ISO/IEC 62734), CoAP(Constrained Application Protocol), MQTT(Message Queuing Telemetry Transport), WIBro(Wireless Broadband), Wimax, 3G, HSDPA(High Speed Downlink Packet Access), 4G 및 5G일 수 있다. 일부 실시예로, 통신망은 인터넷망일 수 있고, 이동 통신망일 수 있다. 또한 통신망은 기타 널리 공지되었거나 향후 개발될 모든 무선통신 또는 유선통신 방식을 포함할 수 있다. 도 2는 본 발명의 실시예에 따른 원격제어장치를 설명하기 위한 블록도이다. 도 1 및 도 2를 참조하면, 원격제어장치는 통신부 및 제어부를 포함하고, 저장부를 더 포함할 수 있다. 통신부는 로봇과 사용자 단말과 통신을 한다. 통신부는 로봇으로부터 영상정보, 3차원 공간정보, 관절 정보 등을 수신하고, 로봇을 제어하는 사용자 입력을 로봇에 전송한다. 통신부는 로봇 과 관련된 콘텐츠를 사용자 단말로 전송하고, 사용자 단말로부터 로봇을 제어하는 사용자 입력을 수 신한다. 제어부는 원격제어장치의 전반적인 제어를 수행한다. 제어부는 로봇으로부터 영상정보 및 3 차원 공간정보를 수신하면 수신된 정보를 이용하여 객체를 검출한다. 이때 제어부는 딥러닝 기반의 객체 영 역 검출(instance segmentation)을 수행하여 객체를 검출할 수 있다. 제어부는 검출된 객체를 기반으로 로 봇의 이동경로를 생성한다. 또한 제어부는 사용자 단말에서 로봇의 작업을 선택하여 제어할 수 있는 사용자 인터페이스, 객체 및 이동경로가 표시되는 콘텐츠를 생성한다. 제어부는 생성된 콘텐츠를 사용 자 단말로 전송시킨다. 제어부는 사용자 단말로부터 전송된 콘텐츠에 대응되는 사용자 입력이 수 신되면 사용자 입력에 따라 콘텐츠를 제어하고, 로봇 제어에 대한 사용자 입력이 수신되면 해당 사용자 입 력을 로봇으로 전달한다. 이를 통해 제어부는 로봇이 사용자 입력에 따라 동작할 수 있도록 할 수 있다. 저장부는 원격제어장치가 구동하기 위한 프로그램 또는 알고리즘이 저장된다. 저장부는 로봇(20 0)으로부터 수신된 영상정보, 3차원 공간정보, 관절 정보가 저장된다. 저장부는 제어부로부터 생성된 콘텐츠가 저장된다. 또한 저장부는 사용자 단말로부터 수신된 사용자 입력이 저장된다. 저장부는 플래시 메모리 타입(flash memory type), 하드디스크 타입(hard disk type), 미디어 카드 마이크로 타입 (multimedia card micro type), 카드 타입의 메모리(예를 들어 SD 또는 XD 메모리 등), 램(Random Access Memory, RAM), SRAM(Static Random Access Memory), 롬(Read-Only Memory, ROM), EEPROM(Electrically Erasable Programmable Read-Only Memory), PROM(Programmable Read-Only Memory), 자기메모리, 자기 디스크 및 광디스크 중 적어도 하나의 저장매체를 포함할 수 있다. 도 3은 도 2의 제어부를 설명하기 위한 블록도이고, 도 4는 도 3의 가상환경 생성부를 설명하기 위한 블록도이 며, 도 5는 본 발명의 실시예에 따른 가상 공간에서 사용자 인터페이스를 표시한 콘텐츠를 설명하기 위한 도면 이고, 도 6은 도 5의 콘텐츠가 HMD에서 출력되는 모습을 설명하기 위한 도면이다. 도 1 내지 도 5를 참조하면, 제어부는 객체 검출부, 이동경로 생성부 및 가상환경 생성부를 포 함한다. 객체 검출부는 로봇으로부터 영상정보 및 3차원 공간정보를 이용하여 객체를 검출한다. 객체 검출부 는 딥러닝 기반으로 구현된 을 이용하여 객체 영역을 검출하고, 검출된 객체 영역에 포함된 객체를 인식한 다. 여기서 인공지능 모델은 R-CNN, Fast R-CNN, Faster R-CNN, R-FCN, YOLO, SSD 등을 포함할 수 있으나, 이 에 한정하지 않는다. 이동경로 생성부는 사용자 단말로부터 수신된 사용자 입력에 따라 로봇이 이동하는 이동경로를 생성한다. 즉 이동경로 생성부는 로봇의 현재 위치에서 사용자 입력에 포함된 목적지까지 최적의 경로 로 이동하는 이동경로를 생성할 수 있다. 예를 들어 이동경로 생성부는 로봇이 위치한 환경에 있는 다 양한 장애물을 회피하면서 최종 목적지로 이동하도록 이동경로를 생성할 수 있다. 이때 이동경로 생성부는 검출된 객체, 3차원 공간정보를 기반으로 SLAM(Simultaneous Localization And Mapping) 기술을 접목하여 이동 경로를 생성할 수 있다.가상환경 생성부는 영상정보를 기초로 로봇의 작업을 선택하여 제어할 수 있는 사용자 인터페이스, 객체 및 이동경로가 표시되는 콘텐츠를 생성한다. 가상환경 생성부는 사용자 단말로부터 수신된 객체 선태과 관련된 사용자 입력에 따라 원하는 객체만이 선택적으로 표시되도록 콘텐츠를 생성할 수 있다. 가상환경 생성부 는 사용자 단말로부터 수신된 작업 선택과 관련된 사용자 입력에 따라 작업과 관련된 객체만을 선택적 으로 표시되도록 콘텐츠를 생성할 수 있다. 예를 들어 작업이 소방 작업인 경우, 소방 물체와 관련된 소화기, 호스, 수돗가 등과 같은 객체만 표시되도록 콘텐츠를 생성할 수 있다. 가상환경 생성부는 3차원 공간정보를 이용하여 객체와 로봇의 상대거리가 표시되도록 콘텐츠를 생성할 수 있다. 또한 가상환경 생성부는 로 봇으로부터 로봇에 장착된 작업 도구의 자세 정보를 더 수신하고, 작업 도구가 객체에 향하는 경우, 연장선을 통해 객체를 조작하는 가이드라인이 표시되도록 콘텐츠를 생성할 수 있다. 여기서 가상환경 생성부 는 1인칭 영상정보 및 3인칭 로봇 상태를 동시에 표현되도록 콘텐츠를 생성할 수 있다. 이러한 콘텐츠를 제 공하기 위해 가상환경 생성부는 개별적인 사용자 인터페이스를 제공하는 모듈을 포함할 수 있고, 바람직하 게는 로봇 상태 표시 UI, 객체 검출 표시 UI, 이동 경로 표시 UI, 작업 유형 선택 UI를 포함한 다. 예를 들어 가상환경 생성부는 영상정보를 기초로 작업종류를 선택하는 UI, 객체인식 물체를 선택하는 UI, 출력 데이터를 선택하는 UI 등을 표시하고, 3차원 로봇 자세, 이동경로, 상대거리, 객체, 물체조작 가이드 라인 등을 표시하는 콘텐츠를 생성할 수 있다(도 4). 특히 가상환경 생성부는 사용자 단말이 HMD인 경 우, 콘텐츠가 출력되는 HMD에 맞도록 콘텐츠를 생성함으로써(도 5), 사용자가 현재 로봇의 상태를 간편하면서도 정확하게 인지할 수 있도록 도와준다. 이상으로 본 발명의 기술적 사상을 예시하기 위한 바람직한 실시예와 관련하여 설명하고 도시하였지만, 본 발명 은 이와 같이 도시되고 설명된 그대로의 구성 및 작용에만 국한되는 것은 아니며, 기술적 사상의 범주를 이탈함 없이 본 발명에 대해 다수의 변경 및 수정이 가능함을 당업자들은 잘 이해할 수 있을 것이다. 따라서 그러한 모 든 적절한 변경 및 수정과 균등물들도 본 발명의 범위에 속하는 것으로 간주되어야 할 것이다."}
{"patent_id": "10-2021-0176065", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 실시예에 따른 원격제어시스템을 설명하기 위한 구성도이다. 도 2는 본 발명의 실시예에 따른 원격제어장치를 설명하기 위한 블록도이다. 도 3은 도 2의 제어부를 설명하기 위한 블록도이다. 도 4는 도 3의 가상환경 생성부를 설명하기 위한 블록도이다. 도 5는 본 발명의 실시예에 따른 가상 공간에서 사용자 인터페이스를 표시한 콘텐츠를 설명하기 위한 도면이다. 도 6은 도 5의 콘텐츠가 HMD에서 출력되는 모습을 설명하기 위한 도면이다."}
