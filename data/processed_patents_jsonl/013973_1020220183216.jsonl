{"patent_id": "10-2022-0183216", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0049102", "출원번호": "10-2022-0183216", "발명의 명칭": "3차원", "출원인": "삼성전자주식회사", "발명자": "신재욱"}}
{"patent_id": "10-2022-0183216", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "3차원(3D) 모델을 생성하는 방법에 있어서,적어도 하나의 객체 이미지에 기초하여, 객체에 대한 기초 3D 모델을 생성하는 단계(1410);복수의 3D 모델이 저장된 3D 모델 데이터 베이스 중에서 상기 기초 3D 모델과 유사한 제1 타겟 3D 모델을 결정하는 단계(1420);상기 기초 3D 모델과 상기 제1 타겟 3D 모델에 기초하여, 제1 합성 3D 모델을 생성하는 단계(1430);상기 제1 합성 3D 모델과 상기 적어도 하나의 객체 이미지의 제1 유사도를 결정하는 단계(1440);상기 제1 유사도가 임계 값보다 작거나 같은 것에 기초하여, 상기 제1 합성 3D 모델과 상기 적어도 하나의 객체이미지 사이에 유사도가 낮은 구성을 결정하는 단계(1450);상기 3D 모델 데이터 베이스 중에서 상기 유사도가 낮은 구성에 대하여 상기 제1 합성 3D 모델과 유사도가 높은3D 모델을 제2 타겟 3D 모델로 결정하는 단계(1460); 및상기 제1 합성 3D 모델과 상기 제2 타겟 3D 모델에 기초하여, 제2 합성 3D 모델을 생성하는 단계(1470)를 포함하는, 3차원 모델 생성 방법."}
{"patent_id": "10-2022-0183216", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 기초 3D 모델을 생성하는 단계는,상기 적어도 하나의 객체 이미지를 이용하여, 상기 적어도 하나의 객체 이미지의 깊이 정보를 획득하는 단계;및상기 적어도 하나의 객체 이미지 및 상기 획득된 깊이 정보를 이용하여, 상기 객체의 적어도 일부에 관한 3차원위치 정보를 포함하는 상기 기초 3D 모델을 생성하는 단계를 포함하는, 3차원 모델 생성 방법."}
{"patent_id": "10-2022-0183216", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항 내지 제2항 중 어느 한 항에 있어서, 상기 제1 타겟 3D 모델을 결정하는 단계는,상기 기초 3D 모델과 상기 복수의 3D 모델 사이의 제2 유사도를 결정하는 단계; 및상기 복수의 3D 모델 중에서 상기 제2 유사도가 높은 3D 모델을 상기 제1 타겟 3D 모델로 결정하는 단계를 포함하는, 3차원 모델 생성 방법."}
{"patent_id": "10-2022-0183216", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항 내지 제3항 중 어느 한 항에 있어서, 상기 제1 합성 3D 모델을 생성하는 단계는,상기 타겟 3D 모델을 상기 기초 3D 모델에 대응되도록 변형을 수행하는 단계; 및공개특허 10-2024-0049102-3-상기 기초 3D 모델과 상기 변형된 타겟 3D 모델을 병합하는 단계를 포함하는, 3차원 모델 생성 방법."}
{"patent_id": "10-2022-0183216", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항 내지 제4항 중 어느 한 항에 있어서,상기 기초 3D 모델을 상기 객체에 대한 복수의 구성으로 분류하는 단계를 더 포함하는, 3차원 모델 생성 방법."}
{"patent_id": "10-2022-0183216", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5항에 있어서,상기 유사도가 낮은 구성을 결정하는 단계는,상기 분류된 복수의 구성 각각에 대하여, 상기 제1 합성 3D 모델과 상기 적어도 하나의 객체 이미지 사이의 제3유사도를 결정하는 단계; 및상기 복수의 구성 중에서, 상기 제3 유사도가 소정의 값보다 작은 구성을 상기 유사도가 낮은 구성으로 결정하는 단계를 포함하는, 3차원 모델 생성 방법."}
{"patent_id": "10-2022-0183216", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항 내지 제6항 중 어느 한 항에 있어서, 상기 제1 유사도를 결정하는 단계는,상기 제1 합성 3D 모델을 렌더링하는 단계;상기 렌더링된 제1 합성 3D 모델의 포즈를 상기 적어도 하나의 객체 이미지에 대응되도록 수정하는 단계; 및상기 수정된 렌더링된 제1 합성 3D 모델과 상기 적어도 하나의 객체 이미지 사이의 제1 유사도를 결정하는 단계를 포함하는, 3차원 모델 생성 방법."}
{"patent_id": "10-2022-0183216", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1항 내지 제7항 중 어느 한 항에 있어서,상기 적어도 하나의 객체 이미지에 기초하여, 상기 객체의 종류를 식별하는 단계를 더 포함하고,상기 3D 모델 데이터 베이스는 상기 객체의 종류에 관한 3D 모델을 포함하는 것을 특징으로 하는, 3차원 모델생성 방법."}
{"patent_id": "10-2022-0183216", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1항 내지 제8항 중 어느 한 항에 있어서, 상기 제1 합성 3D 모델을 생성하는 단계는,상기 기초 3D 모델의 위치에 관한 정보 및 상기 제1 타겟 3D 모델의 위치에 관한 정보에 기초하여, 상기 제1 합성 3D 모델의 위치에 관한 정보를 생성하는 단계; 및상기 기초 3D 모델의 색상에 관한 정보에 기초하여, 상기 제1 합성 3D 모델의 색상에 관한 정보를 생성하는 단계를 포함하는, 3차원 모델 생성 방법.공개특허 10-2024-0049102-4-청구항 10 제1항 내지 제9항 중 어느 한 항에 있어서, 상기 합성 3D 모델은 포인트 클라우드 모델, 폴리곤 메시 모델, 삼각형 메시 모델, NURBS(Non-Uniform RationalB-spline) 모델 또는 스컬핑(Sculpting) 모델 중 적어도 하나를 포함하는, 3차원 모델 생성 방법."}
{"patent_id": "10-2022-0183216", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "3차원(3D) 모델을 생성하는 전자 장치에 있어서,적어도 하나의 프로세서(1520); 및적어도 하나의 인스트럭션을 저장하는 메모리(1510)를 포함하고,상기 적어도 하나의 프로세서(1520)가 상기 적어도 하나의 인스트럭션을 실행함으로써, 적어도 하나의 객체 이미지에 기초하여, 객체에 대한 기초 3D 모델을 생성하고,복수의 3D 모델이 저장된 3D 모델 데이터 베이스 중에서 상기 기초 3D 모델과 유사한 제1 타겟 3D 모델을 결정하고,상기 기초 3D 모델과 상기 제1 타겟 3D 모델에 기초하여, 제1 합성 3D 모델을 생성하고,상기 제1 합성 3D 모델과 상기 적어도 하나의 객체 이미지의 제1 유사도를 결정하고,상기 제1 유사도가 임계 값보다 작거나 같은 것에 기초하여, 상기 제1 합성 3D 모델과 상기 적어도 하나의 객체이미지 사이에 유사도가 낮은 구성을 결정하고,상기 3D 모델 데이터 베이스 중에서 상기 유사도가 낮은 구성에 대하여 상기 제1 합성 3D 모델과 유사도가 높은3D 모델을 제2 타겟 3D 모델로 결정하고,상기 제1 합성 3D 모델과 상기 제2 타겟 3D 모델에 기초하여, 제2 합성 3D 모델을 생성하는, 전자 장치."}
{"patent_id": "10-2022-0183216", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항에 있어서, 상기 적어도 하나의 프로세서(1520)가 상기 적어도 하나의 인스트럭션을 실행함으로써,상기 적어도 하나의 객체 이미지를 이용하여, 상기 적어도 하나의 객체 이미지의 깊이 정보를 획득하고,상기 적어도 하나의 객체 이미지 및 상기 획득된 깊이 정보를 이용하여, 상기 객체의 적어도 일부에 관한 3차원위치 정보를 포함하는 상기 기초 3D 모델을 생성하는, 전자 장치."}
{"patent_id": "10-2022-0183216", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제11항 내지 제12항 중 어느 한 항에 있어서, 상기 적어도 하나의 프로세서(1520)가 상기 적어도 하나의 인스트럭션을 실행함으로써,상기 적어도 하나의 객체 이미지와 상기 복수의 3D 모델 사이의 제2 유사도를 결정하고,상기 복수의 3D 모델 중에서 상기 제2 유사도가 높은 3D 모델을 상기 제1 타겟 3D 모델로 결정하는, 전자 장치."}
{"patent_id": "10-2022-0183216", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제11항 내지 제13항 중 어느 한 항에 있어서, 공개특허 10-2024-0049102-5-상기 적어도 하나의 프로세서(1520)가 상기 적어도 하나의 인스트럭션을 실행함으로써,상기 타겟 3D 모델을 상기 기초 3D 모델에 대응되도록 변형을 수행하고,상기 기초 3D 모델과 상기 변형된 타겟 3D 모델을 병합하는, 전자 장치."}
{"patent_id": "10-2022-0183216", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제11항 내지 제14항 중 어느 한 항에 있어서,상기 적어도 하나의 프로세서(1520)가 상기 적어도 하나의 인스트럭션을 실행함으로써, 상기 기초 3D 모델을 상기 객체에 대한 복수의 구성으로 분류하는, 전자 장치."}
{"patent_id": "10-2022-0183216", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제15항에 있어서,상기 적어도 하나의 프로세서(1520)가 상기 적어도 하나의 인스트럭션을 실행함으로써,상기 분류된 복수의 구성 각각에 대하여, 상기 제1 합성 3D 모델과 상기 적어도 하나의 객체 이미지 사이의 제3 유사도를 결정하고,상기 복수의 구성 중에서, 상기 제3 유사도가 소정의 값보다 작은 구성을 상기 유사도가 낮은 구성으로 결정하는, 전자 장치."}
{"patent_id": "10-2022-0183216", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제11항 내지 제16항 중 어느 한 항에 있어서, 상기 적어도 하나의 프로세서(1520)가 상기 적어도 하나의 인스트럭션을 실행함으로써, 상기 제1 합성 3D 모델을 렌더링하고,상기 렌더링된 제1 합성 3D 모델의 포즈를 상기 적어도 하나의 객체 이미지에 대응되도록 수정하고,상기 수정된 렌더링된 제1 합성 3D 모델과 상기 적어도 하나의 객체 이미지 사이의 제1 유사도를 결정하는, 전자 장치."}
{"patent_id": "10-2022-0183216", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제11항 내지 제17항 중 어느 한 항에 있어서,상기 적어도 하나의 프로세서(1520)가 상기 적어도 하나의 인스트럭션을 실행함으로써, 상기 적어도 하나의 객체 이미지에 기초하여, 상기 객체의 종류를 식별하고,상기 3D 모델 데이터 베이스는 상기 객체의 종류에 관한 3D 모델을 포함하는 것을 특징으로 하는, 전자 장치."}
{"patent_id": "10-2022-0183216", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제11항 내지 제18항 중 어느 한 항에 있어서, 상기 적어도 하나의 프로세서(1520)가 상기 적어도 하나의 인스트럭션을 실행함으로써, 상기 기초 3D 모델의 위치에 관한 정보 및 상기 제1 타겟 3D 모델의 위치에 관한 정보에 기초하여, 상기 제1 합성 3D 모델의 위치에 관한 정보를 생성하고,공개특허 10-2024-0049102-6-상기 기초 3D 모델의 색상에 관한 정보에 기초하여, 상기 제1 합성 3D 모델의 색상에 관한 정보를 생성하는, 전자 장치."}
{"patent_id": "10-2022-0183216", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제1항 내지 제10항 중 어느 한 항의 방법을 수행하도록 하는 프로그램이 저장된 하나 이상의 컴퓨터로 읽을 수있는 기록매체."}
{"patent_id": "10-2022-0183216", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "적어도 하나의 객체 이미지에 기초하여, 객체에 대한 기초 3D 모델을 생성하고, 복수의 3D 모델이 저장된 3D 모 델 데이터 베이스 중에서 기초 3D 모델과 유사한 제1 타겟 3D 모델을 결정하고, 기초 3D 모델과 제1 타겟 3D 모 델에 기초하여, 제1 합성 3D 모델을 생성하고, 제1 합성 3D 모델과 적어도 하나의 객체 이미지의 제1 유사도를 결정하고, 제1 유사도가 임계 값보다 작거나 같은 것에 기초하여, 제1 합성 3D 모델과 상기 적어도 하나의 객체 이미지 사이에 유사도가 낮은 구성을 결정하고, 상기 3D 모델 데이터 베이스 중에서 상기 유사도가 낮은 구성에 대하여 상기 제1 합성 3D 모델과 유사도가 높은 3D 모델을 제2 타겟 3D 모델로 결정하고, 제1 합성 3D 모델과 제 2 타겟 3D 모델에 기초하여, 제2 합성 3D 모델을 생성하는 3D 모델 생성 방법 및 3D 모델 생성 장치가 개시된다."}
{"patent_id": "10-2022-0183216", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 3차원 모델을 생성하는 방법 및 전자 장치에 관한 것이다. 구체적으로는, 3차원 모델 데이터 베이스 를 이용하여 3차원 모델을 생성하는 방법 및 전자 장치에 관한 것이다."}
{"patent_id": "10-2022-0183216", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "증강 현실(Augmented Reality; AR), 가상 현실(Virtual Reality; VR) 및 메타 버스(Metaverse) 등에 대한 발전 이 지속되면서, 3차원 공간 상에 객체를 표시하기 위한 3차원 모델을 생성하는 3D 모델링 기술이 대두되고 있다. 최근에는 컴퓨터 비전 분야의 비약적인 발전에 따라, 수십 장의 2차원 사진을 이용하여 3차원 모델을 생성하는 인공 지능 모델이 개발되고 있다. 이러한 인공 지능 모델은 소정의 위치에서 촬영된 수십 장의 사진을 이용하여 3차원 모델을 추론하도록 학습된다. 다만, 이러한 인공 지능 모델은 소정의 위치에서 촬영된 많은 이미지들이 필요하므로, 사용자의 편의를 위하여 적은 이미지를 이용한 3D 모델링 기술이 필요할 수 있다."}
{"patent_id": "10-2022-0183216", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 개시의 일 양태에 따르면, 3차원(3D) 모델을 생성하는 방법이 제공된다. 3차원 모델을 생성하는 방법은 객체 에 대한 적어도 하나의 객체 이미지에 기초하여, 상기 객체에 대한 기초 3D 모델을 생성하는 단계를 포함할 수 있다. 3차원 모델을 생성하는 방법은 복수의 3D 모델이 저장된 3D 모델 데이터 베이스 중에서 상기 기초 3D 모 델과 유사한 제1 타겟 3D 모델을 결정하는 단계를 포함할 수 있다. 3차원 모델을 생성하는 방법은 상기 기초 3D 모델과 상기 제1 타겟 3D 모델에 기초하여, 제1 합성 3D 모델을 생성하는 단계를 포함할 수 있다. 3차원 모델을 생성하는 방법은 상기 제1 합성 3D 모델과 상기 적어도 하나의 객체 이미지의 제1 유사도를 결정하는 단계를 포 함할 수 있다. 3차원 모델을 생성하는 방법은 상기 제1 유사도가 임계 값보다 작거나 같은 것에 기초하여, 상기 제1 합성 3D 모델과 상기 적어도 하나의 객체 이미지 사이에 유사도가 낮은 구성을 결정하는 단계를 포함할 수 있다. 3차원 모델을 생성하는 방법은 상기 3D 모델 데이터 베이스 중에서 상기 유사도가 낮은 구성에 대하여 상 기 제1 합성 3D 모델과 유사도가 높은 3D 모델을 제2 타겟 3D 모델로 결정하는 단계를 포함할 수 있다. 3차원 모델을 생성하는 방법은 상기 제1 합성 3D 모델과 상기 제2 타겟 3D 모델에 기초하여, 제2 합성 3D 모델을 생성 하는 단계를 포함할 수 있다. 본 개시의 일 양태에 따라서, 전술한 방법을 수행하도록 하는 프로그램이 저장된 하나 이상의 컴퓨터로 읽을 수 있는 기록매체가 제공된다. 본 개시의 일 양태에 따라서 3차원(3D) 모델을 생성하는 전자 장치가 제공된다. 전자 장치는 적어도 하나의 프 로세서를 포함할 수 있다. 전자 장치는 적어도 하나의 인스트럭션을 저장하는 메모리를 포함할 수 있다. 적어도 하나의 프로세서가 상기 적어도 하나의 인스트럭션을 실행함으로써, 객체에 대한 적어도 하나의 객체 이미지에 기초하여, 상기 객체에 대한 기초 3D 모델을 생성할 수 있다. 적어도 하나의 프로세서가 상기 적어도 하나의 인 스트럭션을 실행함으로써, 복수의 3D 모델이 저장된 3D 모델 데이터 베이스 중에서 상기 기초 3D 모델과 유사한제1 타겟 3D 모델을 결정할 수 있다. 적어도 하나의 프로세서가 상기 적어도 하나의 인스트럭션을 실행함으로써, 상기 기초 3D 모델과 상기 제1 타겟 3D 모델에 기초하여, 제1 합성 3D 모델을 생성할 수 있다. 적어도 하나의 프로세서가 상기 적어도 하나의 인스트럭션을 실행함으로써, 상기 제1 합성 3D 모델과 상기 적어 도 하나의 객체 이미지의 제1 유사도를 결정할 수 있다. 적어도 하나의 프로세서가 상기 적어도 하나의 인스트 럭션을 실행함으로써, 상기 제1 유사도가 임계 값보다 작거나 같은 것에 기초하여, 상기 제1 합성 3D 모델과 상 기 적어도 하나의 객체 이미지 사이에 유사도가 낮은 구성을 결정할 수 있다. 적어도 하나의 프로세서가 상기 적어도 하나의 인스트럭션을 실행함으로써, 상기 3D 모델 데이터 베이스 중에서 상기 유사도가 낮은 구성에 대 하여 상기 제1 합성 3D 모델과 유사도가 높은 3D 모델을 제2 타겟 3D 모델로 결정할 수 있다.적어도 하나의 프 로세서가 상기 적어도 하나의 인스트럭션을 실행함으로써, 상기 제1 합성 3D 모델과 상기 제2 타겟 3D 모델에 기초하여, 제2 합성 3D 모델을 생성할 수 있다."}
{"patent_id": "10-2022-0183216", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 개시에서, \"a, b 또는 c 중 적어도 하나\" 표현은 \" a\", \" b\", \" c\", \"a 및 b\", \"a 및 c\", \"b 및 c\", \"a, b 및 c 모두\", 혹은 그 변형들을 지칭할 수 있다. 본 개시에서 사용되는 용어는 본 개시에서의 기능을 고려하면서 가능한 현재 널리 사용되는 일반적인 용어들을 선택하였으나, 이는 당 분야에 종사하는 기술자의 의도 또는 판례, 새로운 기술의 출현 등에 따라 달라질 수 있 다. 또한, 특정한 경우는 출원인이 임의로 선정한 용어도 있으며, 이 경우 해당되는 설명 부분에서 상세히 그 의미를 기재할 것이다. 따라서 본 개시에서 사용되는 용어는 단순한 용어의 명칭이 아닌, 그 용어가 가지는 의 미와 본 개시의 전반에 걸친 내용을 토대로 정의되어야 한다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함할 수 있다. 기술적이거나 과학적인 용어를 포함해서 여기서 사용되는 용어들은 본 명세서에 기재된 기술 분야에서 통상의 지식을 가진 자에 의해 일반적으로 이해되는 것과 동일한 의미를 가질 수 있다. 또한, 본 명세서에서 사용되는 '제1' 또는 '제2' 등과 같이 서수를 포함하는 용어는 다양한 구성 요소들을 설명하는데 사용할 수 있지만, 상기 구성 요소들은 상기 용 어들에 의해 한정되어서는 안 된다. 상기 용어들은 하나의 구성 요소를 다른 구성 요소로부터 구별하는 목적으 로만 사용된다. 명세서 전체에서 어떤 부분이 어떤 구성요소를 \"포함\"한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다른 구성요소를 제외하는 것이 아니라 다른 구성요소를 더 포함할 수 있음을 의미한다. 또한, 명세서에 기재된 \"부\", \"모듈\" 등의 용어는 적어도 하나의 기능이나 동작을 처리하는 단위를 의미하며, 이는 하드웨어 또는 소 프트웨어로 구현되거나 하드웨어와 소프트웨어의 결합으로 구현될 수 있다. 본 개시는 다양한 변경을 가할 수 있고 여러 가지 실시예를 가질 수 있는 바, 특정 실시예들을 도면에 예시하고, 이를 상세한 설명을 통해 상세히 설명하고자 한다. 그러나, 이는 본 개시의 실시 형태에 대해 한정하 려는 것이 아니며, 본 개시는 여러 실시예들의 사상 및 기술 범위에 포함되는 모든 변경, 균등물 내지 대체물을 포함하는 것으로 이해되어야 한다. 실시예를 설명함에 있어서, 관련된 공지 기술에 대한 구체적인 설명이 본 개시의 요지를 불필요하게 흐릴 수 있 다고 판단되는 경우 그 상세한 설명을 생략한다. 또한, 명세서의 설명 과정에서 이용되는 숫자(예를 들어, 제 1, 제 2 등)는 하나의 구성요소를 다른 구성요소와 구분하기 위한 식별 기호에 불과하다. 또한, 본 명세서에서, 일 구성요소가 다른 구성요소와 \"연결된다\" 거나 \"접속된다\" 등으로 언급된 때에는, 상기 일 구성요소가 상기 다른 구성요소와 직접 연결되거나 또는 직접 접속될 수도 있지만, 특별히 반대되는 기재가 존재하지 않는 이상, 중간에 또 다른 구성요소를 매개하여 연결되거나 또는 접속될 수도 있다고 이해되어야 할 것이다. 또한, 본 명세서에서 '~부(유닛)', '모듈' 등으로 표현되는 구성요소는 2개 이상의 구성요소가 하나의 구성요소 로 합쳐지거나 또는 하나의 구성요소가 보다 세분화된 기능별로 2개 이상으로 분화될 수도 있다. 또한, 이하에 서 설명할 구성요소 각각은 자신이 담당하는 주기능 이외에도 다른 구성요소가 담당하는 기능 중 일부 또는 전 부의 기능을 추가적으로 수행할 수도 있으며, 구성요소 각각이 담당하는 주기능 중 일부 기능이 다른 구성요소 에 의해 전담되어 수행될 수도 있음은 물론이다. 본 개시에 따른 인공지능과 관련된 기능은 프로세서와 메모리를 통해 동작된다. 프로세서는 하나 또는 복수의 프로세서로 구성될 수 있다. 이때, 하나 또는 복수의 프로세서는 CPU, AP, DSP(Digital Signal Processor) 등 과 같은 범용 프로세서, GPU, VPU(Vision Processing Unit)와 같은 그래픽 전용 프로세서 또는 NPU와 같은 인 공지능 전용 프로세서일 수 있다. 하나 또는 복수의 프로세서는, 메모리에 저장된 기 정의된 동작 규칙 또는 인 공지능 모델에 따라, 입력 데이터를 처리하도록 제어한다. 또는, 하나 또는 복수의 프로세서가 인공지능 전용 프로세서인 경우, 인공지능 전용 프로세서는, 특정 인공지능 모델의 처리에 특화된 하드웨어 구조로 설계될 수 있다. 기 정의된 동작 규칙 또는 인공지능 모델은 학습을 통해 만들어진 것을 특징으로 한다. 여기서, 학습을 통해 만 들어진다는 것은, 기본 인공지능 모델이 학습 알고리즘에 의하여 다수의 학습 데이터들을 이용하여 학습됨으로 써, 원하는 특성(또는, 목적)을 수행하도록 설정된 기 정의된 동작 규칙 또는 인공지능 모델이 만들어짐을 의미 한다. 이러한 학습은 본 개시에 따른 인공지능이 수행되는 기기 자체에서 이루어질 수도 있고, 별도의 서버 및/ 또는 시스템을 통해 이루어 질 수도 있다. 학습 알고리즘의 예로는, 지도형 학습(supervised learning), 비지도형 학습(unsupervised learning), 준지도형 학습(semi-supervised learning) 또는 강화 학습(reinforcement learning)이 있으나, 전술한 예에 한정되지 않는다. 인공지능 모델은, 복수의 신경망 레이어들로 구성될 수 있다. 복수의 신경망 레이어들 각각은 복수의 가중치들 (weight values)을 갖고 있으며, 이전(previous) 레이어의 연산 결과와 복수의 가중치들 간의 연산을 통해 신경 망 연산을 수행한다. 복수의 신경망 레이어들이 갖고 있는 복수의 가중치들은 인공지능 모델의 학습 결과에 의 해 최적화될 수 있다. 예를 들어, 학습 과정 동안 인공지능 모델에서 획득한 로스(loss) 값 또는 코스트(cost) 값이 감소 또는 최소화되도록 복수의 가중치들이 갱신될 수 있다. 인공 신경망은 심층 신경망(DNN:Deep Neural Network)를 포함할 수 있으며, 예를 들어, CNN (Convolutional Neural Network), DNN (Deep Neural Network), RNN (Recurrent Neural Network), RBM (Restricted Boltzmann Machine), DBN (Deep Belief Network), BRDNN(Bidirectional Recurrent Deep Neural Network) 또는 심층 Q-네트워크 (Deep Q-Networks) 등이 있으나, 전술한 예에 한정되지 않는다. 본 명세서에서 \"객체 이미지\"는 생성하려는 3D 모델의 객체가 포함된 이미지를 의미할 수 있다. 예를 들면, 전 자 장치는 의자를 촬영한 객체 이미지에 기초하여, 의자에 관한 3D 모델을 생성할 수 있다. 본 명세서에서 \"기초 3D 모델\"은 객체 이미지에 기초하여 생성된 객체에 관한 3D 모델을 의미할 수 있다. 예를 들면, 기초 3D 모델은 3D 모델 데이터 베이스를 참조하지 않고, 객체 이미지에 기초하여 추론된 3D 모델을 의미 할 수 있다. 기초 3D 모델은 객체 이미지에 포함된 객체에 관한 정보를 포함할 수 있다. 예를 들면, 객체 이미 지가 객체의 정면에서 촬영된 이미지인 경우, 기초 3D 모델은 객체의 정면에 관한 정보를 포함할 수 있다. 복수 의 객체 이미지가 객체에 대한 다른 복수의 시점에서 촬영된 이미지인 경우, 기초 3D 모델은 객체의 다른 복수 의 시점에 관한 정보를 포함할 수 있다. 본 명세서에서 \"타겟 3D 모델\"은 3D 모델 데이터 베이스 중에서 합성 3D 모델을 생성하기 위하여 이용되는 3D 모델을 의미할 수 있다. 예를 들면, 전자 장치는 기초 3D 모델 혹은 합성 3D 모델을 보완하기 위하여 3D 모델 데이터 베이스에 포함된 타겟 3D 모델을 이용할 수 있다. 타겟 3D 모델은 정보의 수가 소정의 값 이상인 3D 모 델일 수 있다. 예를 들면, 타겟 3D 모델은 렌더링하여 객체를 표현하기 충분한 정보를 포함하는 3D 모델일 수 있다. 본 명세서에서 \"합성 3D 모델\"은 타겟 3D 모델에 기초하여 생성된 3D 모델을 의미할 수 있다. 예를 들면, 전자 장치는 기초 3D 모델과 타겟 3D 모델을 이용하여 합성 3D 모델을 생성할 수 있다. 예를 들면, 전자 장치는 기생 성된 합성 3D 모델과 타겟 3D 모델을 이용하여 새로운 합성 3D 모델을 생성할 수 있다. 전자 장치는 타겟 3D 모 델의 정보에 기초하여, 기초 3D 모델의 정보의 양 또는 기생성된 합성 3D 모델의 정보의 양을 증가함으로써, 합 성 3D 모델을 생성할 수 있다. 도 1은 본 개시의 일 실시예에 따른 3차원(3D) 모델을 생성하는 방법을 설명하기 위한 도면이다. 도 1을 참조하면, 전자 장치는 객체에 관한 객체 이미지를 획득할 수 있다. 3차원 모델의 종류 는 다양한 방식이 존재하나, 설명의 편의를 위하여 포인트 클라우드 방식을 기준으로 설명하도록 한다. 3차원 모델의 종류는 도 3을 참조하여 보다 상세히 설명하도록 한다. 전자 장치는 객체를 촬영하거나 객체 이미지를 외부로부터 수신함으로써 획득할 수 있다. 예를 들면, 전자 장치는 객체를 다양한 각도에서 촬영함으로써 객체 이미지를 획득할 수 있다. 예를 들면, 객체 이미지는 전자 장치로부터 촬영된 2차원(2D) 이미지 혹은 3차원(3D) 이미지일 수도 있고, 전자 장치로부터 촬영된 2D 이미지에 기초하여 생성된 3D 이미지일 수 있다. 객체 이미지는 색상 정 보를 포함하는 2D 이미지 혹은 색상 정보 및 깊이 정보를 포함하는 3D 이미지일 수 있다. 예를 들면, 객체 이미 지는 RGB 이미지와 같은 색상 정보를 포함하는 2D 이미지 혹은 RGBD 이미지와 같은 색상 정보와 깊이 정보 를 포함하는 이미지일 수 있지만, 이에 제한되지 않고 다양한 색상 공간 이미지일 수 있다. 본 개시의 일 실시예에 따른 전자 장치는 객체 이미지에 기초하여 기초 3D 모델을 생성할 수 있 다. 기초 3D 모델은 객체 이미지를 이용하여 추론된 3D 모델일 수 있다. 본 개시의 일 실시예에 따른 기초 3D 모델을 생성하는 방법은 도 5를 참조하여 상세하게 설명하도록 한다. 본 개시의 일 실시예에 따른 전자 장치는 3D 모델 데이터 베이스 중에서 제1 타겟 3D 모델(135-1)을 결정할 수 있다. 3D 모델 데이터 베이스는 전자 장치 혹은 외부 전자 장치에 저장되어 있는 3D 모델 에 관한 정보일 수 있다. 전자 장치는 3D 모델 데이터 베이스 중에서 기초 3D 모델과 유사한 3D모델을 제1 타겟 3D 모델(135-1)로 결정할 수 있다. 본 개시의 일 실시예에 따른 전자 장치는 기초 3D 모델 및 제1 타겟 3D 모델(135-1)에 기초하여, 제1 합성 3D 모델을 생성할 수 있다. 전자 장치는 제1 타겟 3D 모델(135-1)에 대하여 변형 과정을 수행하 고, 변형된 제1 타겟 3D 모델(135-1)과 기초 3D 모델을 합성함으로써, 제1 합성 3D 모델을 생성할 수 있다. 전자 장치는 3D 모델에 관한 정보(예: 포인트, 꼭지점 등 3D 모델에 관한 정보)가 적은 기초 3D 모 델을 제1 타겟 3D 모델(135-1)을 이용하여 합성함으로써 3D 모델에 관한 정보의 양이 많은 제1 합성 3D 모 델을 생성할 수 있다. 본 개시의 일 실시예에 따른 전자 장치가 변형 및 합성을 수행하는 과정은 도 8 내지 도 10을 참조하여 보다 상세하게 설명한다. 본 개시의 일 실시예에 따른 전자 장치는 3D 모델 데이터 베이스 중에서 제2 타겟 3D 모델(135-2)을 결정할 수 있다. 전자 장치는 3D 모델 데이터 베이스 중에서 제1 합성 3D 모델과 유사한 3D 모 델을 제2 타겟 3D 모델(135-2)로 결정할 수 있다. 전자 장치는 제1 합성 3D 모델을 복수의 구성들로 분류할 수 있다. 예를 들면, 제1 합성 3D 모델의 구성은 제1 합성 3D 모델에 포함된 복수의 포인트들 중에서 유사한 특징을 갖는 포인트들의 집합을 의미할 수 있다. 예를 들면, 제1 합성 3D 모델이 의자에 관 한 3D 모델인 경우, 구성은 등받이, 좌판, 다리 및 팔걸이를 포함할 수 있으며, 같은 구성에 속한 포인트들은 유사한 특징을 나타내고, 다른 구성에 속한 포인트들은 서로 다른 특징을 나타낼 수 있다. 전자 장치는 제1 합성 3D 모델과 객체 이미지를 비교함으로써 제1 합성 3D 모델로부터 분 류된 복수의 구성들 중에서 객체 이미지와의 차이가 큰 구성을 결정할 수 있다. 전자 장치는 3D 모델 데이터 베이스 중에서 제1 합성 3D 모델의 구성 중에서 객체 이미지와의 차이가 큰 구성과 유사 한 구성을 포함하는 3D 모델을 제2 타겟 3D 모델(135-2)로 결정할 수 있다. 예를 들면, 제1 합성 3D 모델 은 팔걸이에 대한 3D 모델 정보의 양이 부족하므로, 전자 장치는 팔걸이에 대하여 제1 합성 3D 모델 과 객체 이미지 사이의 차이가 크다고 결정하고, 전자 장치는 제1 합성 3D 모델의 팔걸이와 유 사한 팔걸이를 가진 3D 모델을 제2 타겟 3D 모델(135-2)로 결정할 수 있다. 본 개시의 일 실시예에 따른 전자 장치는 제1 합성 3D 모델과 제2 타겟 3D 모델(135-2)을 합성함으로 써, 제2 합성 3D 모델을 생성할 수 있다. 본 개시의 일 실시예에 따라, 전자 장치가 제2 합성 3D 모델 이 생성하는 과정에 대하여 설명하였지만, 객체 이미지와 합성 3D 모델이 소정의 유사도를 만족할 때 까지 반복하여 수행될 수 있다. 전자 장치는 데이터 베이스에 저장된 3D 모델을 이용하여 3D 모델에 관한 정보를 보완함으로써 적은 수의 객체 이미지로부터 3D 모델을 생성할 수 있다. 예를 들면, 전자 장치는 데이터 베이스에 저장된 3D 모델을 이용하여 적은 수의 객체 이미지로부터 생성된 정보의 양이 적은 3D 모델로부터 정보의 양이 많은 3D 모델을 생 성할 수 있다. 정보의 양이 적은 3D 모델은 렌더링되는 경우 구현하고자 하는 목표 3D 모델과 차이가 클 수 있 으나, 정보의 양이 많은 3D 모델은 목표 3D 모델과 차이가 적을 수 있다. 전자 장치가 3D 모델을 생성하기 위하여 필요한 이미지의 수가 관련 기술에서 필요한 이미지의 수보다 적을 수 있다. 도 2는 본 개시의 일 실시예에 따른 3차원 모델(3D 모델)을 생성하는 방법을 설명하기 위한 도면이다. 도 2를 참조하면, 전자 장치는 기초 3D 모델 생성부, 타겟 3D 모델 결정부, 합성 3D 모델 생성 부, 이미지 렌더링부 및 이미지 비교부를 포함할 수 있다. 전자 장치는 참조 3D 모델 DB를 더 포함할 수 있다. 본 개시의 일 실시예에 따라, 기초 3D 모델 생성부는 객체 이미지로부터 기초 3D 모델을 생성할 수 있다. 도 1을 참조하면, 기초 3D 모델 생성부는 객체 이미지에 기초하여, 객체에 관한 기초 3D 모델을 생성할 수 있다. 본 개시의 일 실시예에 따라, 타겟 3D 모델 결정부는 참조 3D 모델 DB에 저장된 3D 모델 중에서 기초 3D 모델과 유사한 타겟 3D 모델을 결정할 수 있다. 본 개시의 일 실시예에 따라, 합성 3D 모델 생성부는 기초 3D 모델 및 타겟 3D 모델을 이용하여 합성 3D 모델을 생성할 수 있다. 3D 모델 변형부는 타겟 3D 모델에 대한 변형 과정을 수행할 수 있다. 3D 모델 병 합부는 타겟 3D 모델과 기초 3D 모델을 병합(merge)할 수 있다. 본 개시의 일 실시예에 따라, 이미지 렌더링부는 합성 3D 모델을 렌더링할 수 있다. 본 개시의 일 실시예에 따라, 이미지 비교부는 객체 이미지와 합성 이미지를 비교하여 유사도를 판단할 수 있다. 이미지 비교부는 객체 이미지와 합성 이미지가 소정의 유사도 이상인 경우, 합성 3D 모델을 최종 3D 모델로 결정할 수 있다. 본 개시의 일 실시예에 따라, 이미지 비교부는 객체 이미지와 합성 이미지 사이의 유사도가 소정의 유사도 미만인 경우, 타겟 3D 모델 결정부는 합성 3D 모델과 유사한 타겟 3D 모델을 결정할 수 있다. 합성 3D 모 델 생성부는 결정된 타겟 3D 모델과 이전에 생성된 합성 3D 모델을 합성함으로써 새로운 합성 3D 모델을 생성할 수 있다. 전자 장치는 합성 3D 모델과 객체 이미지 사이의 유사도가 소정의 유사도 미만인 경우, 타겟 3D 모델을 결정하고 합성 3D 모델을 생성하는 과정을 반복적으로 수행할 수 있다. 본 개시의 일 실시예에 따라, 전자 장치가 합성 3D 모델을 생성하는 방법은 도 3을 참조하여 보다 상세하게 설명한다. 도 3은 본 개시의 일 실시예에 따른 3차원 모델을 생성하는 방법에 관한 순서도이다. 도 3을 참조하면, 3D 모델을 생성하는 방법은 단계 310으로 시작될 수 있다. 본 개시의 일 실시예에 따른, 3D 모델을 생성하는 방법은 전자 장치에 의하여 수행될 수 있지만, 이에 제한되지 않고, 일부 단계는 전자 장치가 수행하고, 일부 단계는 외부 전자 장치가 수행할 수 있다. 단계 310에서, 전자 장치는 기초 3D 모델을 생성할 수 있다. 본 개시의 일 실시예에 따라, 전자 장치(10 0)는 객체 이미지를 이용하여 기초 3D 모델을 생성할 수 있다. 예를 들면, 전자 장치는 RGBD 이미지를 이 용하여 포인트 클라우드 기초 3D 모델을 생성할 수 있다. 본 개시의 일 실시예에 따라, 전자 장치는 복수 의 RGB 이미지를 이용하여 RGBD 이미지를 생성할 수 있다. 단계 320에서, 전자 장치는 타겟 3D 모델을 결정할 수 있다. 전자 장치는 3D 모델 데이터 베이스 중 에서 기초 3D 모델과 가장 유사한 3D 모델을 타겟 3D 모델로 결정할 수 있다. 본 개시의 일 실시예에 따라, 전 자 장치는 기초 3D 모델의 특정 구성이 가장 유사한 3D 모델을 타겟 3D 모델로 결정할 수 있다. 예를 들면, 전자 장치는 의자의 팔걸이 구성이 가장 유사한 3D 모델을 타겟 3D 모델로 결정할 수 있다. 단계 330에서, 전자 장치는 합성 3D 모델을 생성할 수 있다. 전자 장치는 기초 3D 모델과 타겟 3D 모 델에 기초하여 합성 3D 모델을 생성할 수 있다. 전자 장치는 타겟 3D 모델에 대한 변형을 수행하고, 합성 3D 모델을 생성할 수 있다. 단계 340에서, 전자 장치는 합성 3D 모델과 객체 이미지가 유사한지 여부를 결정한다. 전자 장치는 합성 3D 모델을 렌더링하고, 객체 이미지의 포즈와 유사하게 렌더링된 합성 3D 모델을 수정할 수 있다. 전자 장 치는 수정된 3D 모델과 객체 이미지에 기초하여 유사도를 결정할 수 있다. 만약, 전자 장치가 유사하 지 않다고 판단하는 경우(예: 유사도가 소정의 값 미만), 단계 350으로 진행한다. 만약, 전자 장치가 유사 하다고 판단하는 경우(예: 유사도가 소정의 값 이상), 단계를 종료한다. 단계 350에서, 전자 장치는 합성 3D 모델과 객체 이미지 사이에 유사하지 않은 영역을 판단할 수 있다. 일 실시예에 따라, 영역은 합성 3D 모델의 구성을 의미할 수 있다. 전자 장치는 합성 3D 모델을 객체의 구성 들로 분류하고, 각 구성 별로 객체 이미지와의 유사도를 결정할 수 있다. 예를 들면, 전자 장치는 의자를 등받이, 팔걸이 등의 구성들로 분류할 수 있다. 전자 장치는 합성 3D 모델과 객체 이미지가 의자의 구성들 중에서 등받이는 유사하지만, 팔걸이는 유사하지 않다고 결정할 수 있다. 전자 장치는 합성 3D 모델과 객체 이미지 사이에 유사하지 않은 구성을 결정하고, 단계 320으로 진행한다. 단계 320에서, 전자 장치는 합성 3D 모델과 유사한 3D 모델을 타겟 3D 모델로 결정할 수 있다. 전자 장치 는 단계 350에서 객체 이미지의 구성과 유사하지 않다고 판단된 합성 3D 모델의 구성에 대하여, 합성 3D 모델의 구성과 유사한 구성을 포함하는 3D 모델을 타겟 3D 모델로 결정할 수 있다. 예를 들면, 전자 장치 는 유사하지 않다고 판단된 팔걸이 구성에 있어서, 합성 3D 모델과 유사한 팔걸이 구성을 포함하는 3D 모델을 타겟 3D 모델로 결정할 수 있다. 본 개시의 일 실시예에 따라, 유사하지 않다고 판단된 구성이 복수인 경우, 전 자 장치는 각 구성 별로 타겟 3D 모델을 결정할 수 있다. 본 개시의 일 실시예에 따라, 유사하지 않다고 판단된 구성이 복수인 경우, 전자 장치는 유사하지 않다고 판단된 복수의 구성에 대하여 가장 유사도가 높 은 구성을 포함하는 하나의 타겟 3D 모델을 결정할 수 있다. 단계 330에서, 전자 장치는 이전에 생성된 합 성 3D 모델과 타겟 3D 모델을 이용하여 새로운 합성 3D 모델을 생성할 수 있다. 전자 장치는 단계 320 내 지 단계 350을 반복하여, 객체 이미지와 유사한 합성 3D 모델을 생성할 수 있다. 도 4는 본 개시의 일 실시예에 따른 3차원 모델(3D 모델)의 종류를 설명하기 위한 도면이다. 도 4를 참조하면, 3차원 모델의 종류는 포인트 클라우드 혹은 메쉬를 포함할 수 있다. 포인트 클라우드는 한 객체를 3D 공간 안에 시각적으로 규정하는 디지털화된 데이터이다. 도시된 바와 같 이, 포인트 클라우드는 다수의 포인트들을 포함할 수 있다. 각각의 포인트는 객체의 외부 지점의 좌표를 나타낼 수 있다. 예를 들면, 각각의 포인트는 객체의 경계 중 한 지점을 의미할 수 있다. 각각의 포인트는 3차 원 좌표계에 대응되는 객체의 외부 좌표 값을 포함할 수 있다. 예를 들면, 각각의 포인트는 (x, y, z)의 좌표 값으로 표현될 수 있다. 각각의 포인트는 하나 이상의 속성들을 포함할 수 있다. 예를 들면, 각각의 포인트의 속성들은 지리적 위치와 같은 기하학적 구조를 포함할 수 있다. 예를 들면, 각각의 포인트의 속성들은 컬러, 밝 기, 텍스처, 모션, 재료 특성 등을 포함할 수 있다. 기하학적 구조 이외의 속성들을 텍스처라 칭할 수 있으며, 텍스처는 포인트 클라우드의 각각의 포인트와 관련된 다양한 양태들과 특성들을 나타낸다. 메쉬는 한 객체를 3D 공간 안에 시각적으로 규정하는 디지털화된 데이터이다. 도시된 바와 같이, 메쉬 는 다수의 점들과 다수의 점들 사이의 연결 관계를 포함할 수 있다. 메쉬의 회화적 묘사는 다양한 점들 간 정보의 여러 다각형 또는 삼각형 모양의 상호연결로 정의된다. 예를 들면, 다양한 점들이 다각형 모양으로 상호 연결된 경우, 폴리곤 메쉬로 지칭될 수 있다. 예를 들면, 다양한 점 들이 삼각형 모양으로 상호 연결된 경우, 삼각형 메쉬로 지칭될 수 있다. 각각의 다각형은 한 속성(attribute) 과 같은 다양한 정보를 포함할 수 있다. 속성은 기하학적 구조와 텍스처를 포함할 수 있다. 텍스처는 컬러 반사, 모션 등을 포함한다. 예를 들면, 지형 데이터는 꼭지점들, 모서리들 및 면들의 인접성과 같은, 꼭지점들 간 연결 정보를 제공한다. 기하학적 정보는 각각의 꼭지점의 3D 공간 내에서의 기하학적 위치를 제공한다. 속성 정보는 각각의 개별 꼭지점에 대한 법선, 컬러, 및 응용 종속적인 정보를 제공한다. 각각의 다각형의 꼭지점들 은 포인트 클라우드 내 포인트들과 유사하다. 메쉬의 각각의 다각형은 객체의 외부 표면을 나타낸다. 설명의 편의를 위하여, 3차원 모델의 종류 중에서 포인트 클라우드 및 메쉬를 예시로 설명하였지만, 이에 제한 되지 않고, 본 개시에 따른 3차원 모델 생성 방법은 NURBS(Non-Uniform Rational B-spline) 또는 스컬핑 (Sculpting) 등 다양한 방식의 3차원 모델 종류를 이용하여 수행될 수 있다. 도 5는 본 개시의 일 실시예에 따른 객체 이미지에 기초하여 기초 3D 모델을 생성하는 과정을 설명하기 위한 도 면이다. 도 5를 참조하면, 기초 3D 모델은 적어도 하나의 객체 이미지에 기초하여 생성될 수 있다. 본 개시의 일 실시예에 따른 객체 이미지 및 기초 3D 모델은 도 1의 객체 이미지 및 기초 3D 모델에 각각 대응될 수 있다. 본 개시의 일 실시예에 따른 전자 장치는 객체 이미지에 기초하여 깊이 정보를 획득할 수 있다. 전자 장치는 깊이 정보를 포함하는 깊이 정보 이미지를 생성할 수 있다. 예를 들면, 깊이 정보 이미지는 각 픽셀의 깊이 정보를 픽셀 값으로 나타내는 깊이 이미지(Depth Image)일 수 있다. 본 개시의 일 실시예에 따라, 깊이 정보 이미지는 객체 이미지의 일부일 수 있다. 예를 들면, 객체 이미지가 RGBD 이미지인 경우, 깊이 정보 이미지는 객체 이미지 중에서 깊이 정보의 이미지를 의미할 수 있다. 본 개시의 일 실시예에 따라, 깊이 정보 이미지는 객체 이미지에 기초하여 생성될 수 있다. 예를 들면, 객체 이미지가 2차원 이미지인 경우, 객체 이미지에 대응하는 깊이 정보는 복수 의 이미지를 이용하여 추정될 수 있고, 깊이 정보 이미지는 추정된 깊이 정보에 기초하여 생성될 수 있다. 본 개시의 일 실시예에 따른 전자 장치는 깊이 정보 이미지에 기초하여 기초 3D 모델을 생성할 수 있다. 전자 장치는 깊이 정보를 이용하여, 각각의 포인트에서의 3차원 좌표 값을 획득할 수 있다. 전자 장치는 각각의 포인트의 좌표 값에 기초하여 기초 3D 모델을 생성할 수 있다. 기초 3D 모델은 포인트 클라우드 혹은 메쉬 등 다양한 방식으로 표현될 수 있다. 객체 이미지의 개수가 많을수록 기초 3D 모델의 포인트의 수가 많아지고, 기초 3D 모델이 객체를 정확하게 표현할 수 있다. 도 6은 본 개시의 일 실시예에 따른 3D 모델을 구성 단위로 분류하는 과정을 설명하기 위한 도면이다. 도 6를 참조하면, 3D 모델은 복수의 구성(610, 620, 630, 640, 650)을 포함할 수 있다. 의자에 관한 3D 모델은 등받이, 좌판, 다리 및 팔걸이(640, 650)를 포함할 수 있다. 3D 모델은 기초 3D 모델, 타겟 3D 모델 또는 합성 3D 모델일 수 있다. 본 개시의 일 실시예에 따른 전자 장치는 3D 모델을 복수의 구성(610, 620, 630, 640, 650)으로 분 류할 수 있다. 전자 장치는, 3D 모델을 의미론적 단위로 분류하는 인공 지능 모델을 이용하여, 3D 모델을 복수의 구성(610, 620, 630, 640, 650)으로 분류할 수 있다. 인공 지능 모델은 3D 모델이 입력 되면, 3D 모델에 포함된 복수의 포인트들을 구성에 따라 분류하도록 학습된 것일 수 있다. 인공 지능 모델은 3D 모델 의 각 포인트 혹은 각 셀 단위에 대하여 구성 라벨이 지정된 데이터를 포함하는 학습 데이터를 이용하여 학습된 것일 수 있다. 전자 장치는, 클러스터링에 기반하여, 3D 모델을 복수의 구성(610, 620, 630, 640, 650)으로 분류할 수 있다. 전자 장치는 3D 모델의 각 포인트 혹은 각 셀 단위에 대한 정보를 유사한 특징을 가진 집합으로 분류하는 클러스터링 알고리즘을 수행할 수 있다. 일 실시예에 따라, 3D 모델의 유사한 성격을 가진 집합은 3D 모델의 구성으로 지칭될 수 있다. 본 개시의 일 실시예에 따라, 전자 장치가 3D 모델에 기초하여 복수의 구성(610, 620, 630, 640, 650)으로 분류하는 과정을 설명하였지만, 이에 제한되지 않고, 전자 장치가 객체 이미지에 기초하여, 3D 모델을 생성하고 구성에 따라 분류하는 동작을 동시에 수행하는 것도 가능하다. 전자 장치는 3D 모델을 복수의 구성(610, 620, 630, 640, 650)으로 분류함으로써, 3D 모델에서 객체 이미지와 유사도가 낮은 구성을 식별할 수 있다. 전자 장치는 3D 모델의 유사도가 낮은 구성에 대한 정보를 보완함으로써, 3D 모델과 객체 사이의 유사도를 높일 수 있다. 예를 들면, 전자 장치는 3D 모델의 유사도가 낮은 구성에 대한 정보의 양을 많게 함으로써 정보를 보완할 수 있다. 도 7은 본 개시의 일 실시예에 따른 3D 모델 사이의 유사도를 결정하는 과정을 설명하기 위한 도면이다. 도 7을 참조하면, 제1 3D 모델, 제2 3D 모델은 각각 기초 3D 모델, 타겟 3D 모델, 합성 3D 모델 또 는 3D 모델 데이터 베이스에 저장된 3D 모델 중 하나일 수 있다. 설명의 편의를 위하여, 제1 3D 모델은 기 초 3D 모델이고, 제2 3D 모델은 3D 데이터 베이스에 포함된 3D 모델인 경우를 가정한다. 전자 장치는 유사도 결정부를 포함할 수 있다. 유사도 결정부는 제1 3D 모델과 제2 3D 모 델 사이의 유사도를 결정할 수 있다. 본 개시의 일 실시예에 따라, 유사도 결정부는 제1 3D 모 델과 제2 3D 모델의 외부 파라미터(extrinsic parameter) 또는 내부 파라미터(intrinsic parameter) 중 적어도 하나에 기초하여 유사도를 결정할 수 있다. 외부 파라미터(extrinsic parameter)는 3D 모델의 곡률(Curvature) 또는 이방성(Anisotropy)과 같은 특성을 포함할 수 있다. 예를 들면, 유사도 결정부는 제 1 3D 모델의 곡률과 제2 3D 모델의 곡률을 비교함으로써, 유사도를 결정할 수 있다. 대안적으로 또는 추가적으로, 유사도 결정부는 제1 3D 모델에 포함된 포인트 위치와 제2 3D 모델의 포인트 위치 에 기초하여 유사도를 결정할 수 있다. 예를 들면, 유사도 결정부는 제1 3D 모델에 포함된 제1 포인 트와 제1 포인트에 대응되는 제2 3D 모델의 제2 포인트 사이의 거리(예: Euclidean distance)에 기초하여, 유사도를 판단할 수 있다, 제2 포인트는 제2 3D 모델에 포함된 포인트 중에서 제1 포인트와 위치가 가장 유사한 포인트 일 수 있다. 대응되는 포인트 사이의 거리가 작을수록 유사도가 높게 결정될 수 있다. 본 개시의 일 실시예에 따라, 유사도 결정부는 제1 3D 모델과 외부 파라미터(extrinsic parameter) 또는 내부 파라미터(intrinsic parameter) 중 적어도 하나를 포함하는 제2 3D 모델의 특성을 예측하도록 학습된 인공 지능 모델을 포함할 수 있다. 인공 지능 모델은 제1 3D 모델과 제2 3D 모델이 유사할수 록 높은 유사도를 나타내도록 학습된 것일 수 있다. 유사도 결정부는 제1 3D 모델과 제2 3D 모델 전체를 비교함으로써 유사도를 결정하거나 제 1 3D 모델과 제2 3D 모델의 일부를 비교함으로써 유사도를 결정할 수 있다. 예를 들면, 유사도 결정부는 제1 3D 모델의 '팔걸이' 구성과 제2 3D 모델의 '팔걸이' 구성을 비교함으로써 유사도 를 결정할 수 있다. 전자 장치는 3D 모델 데이터 베이스에 포함된 복수의 3D 모델을 제2 3D 모델로 하여 제1 3D 모델 과의 유사도를 결정할 수 있다. 유사도는 0~1 사이의 값을 나타낼 수 있지만, 이에 제한되지 않고, 다양한 방식으로 평가될 수 있다. 유사도 결정부는 제1 3D 모델과 제2 3D 모델을 비교하여 차이 가 적을수록 유사도가 크다고 결정할 수 있다. 본 개시의 일 실시예에 따라, 전자 장치는 유사도가 가장 높은 제2 3D 모델을 타겟 3D 모델로 결정할 수 있다. 예를 들면, 3D 데이터 베이스에 포함된 복수의 3D 모델(후보 3D 모델) 중에서 유사도가 제일 높은 제1 후보 3D 모델을 타겟 3D 모델로 결정할 수 있다. 전자 장치는 기 생성된 3D 모델 중에 가장 유사한 3D 모델을 이용하여 적은 데이터를 보완할 수 있다. 예를 들면, 전자 장치는 데이터(예: 포인트 정보, 꼭지점 정보 등)가 적은 기초 3D 모델에 타겟 3D 모델에 포함된 데이터를 이용하여 데이터의 양을 증가함으로써 데이터를 보완할 수 있다. 본 개시의 일 실시예에 따라, 유사도 결정부는 도 2의 타겟 3D 모델 결정부에 포함될 수 있다. 타겟 3D 모델 결정부는 유사도 결정부에 의하여 결정된 유사도에 기초하여 타겟 3D 모델을 결정할 수 있다. 본 개시의 일 실시예에 따라, 제1 3D 모델은 기초 3D 모델이고, 제2 3D 모델은 3D 데이터 베이스에 포함된 3D 모델인 경우 유사도를 결정하는 방법을 설명하였지만, 이에 제한되지 않고, 제1 3D 모델은 합성 3D 모델이고, 제2 3D 모델은 3D 데이터 베이스에 포함된 3D 모델인 경우 등 제1 3D 모델 및 제2 3D 모델은 다양한 경우로 나타날 수 있다. 도 8은 본 개시의 일 실시예에 따른 3D 모델의 변형(Deformation) 과정을 설명하기 위한 도면이다. 본 개시에서 \"변형(Deformation)\"은 3D 모델의 각 포인트의 위치를 변경하는 과정을 의미할 수 있다. 예를 들면, 3D 모델의 임의의 포인트의 좌표 (x0, y0, z0)를 (x1, y1, z1)으로 변경하는 것을 의미한다. 3D 모델에 대한 변형이 수행됨으로써, 3D 모델은 회전(rotation), 이동(translation) 또는 크기변환(scaling) 등이 수행 된 것과 유사한 효과를 얻을 수 있다. 본 개시에서 \"오프셋(offset)\"은 변형이 수행되기 전과 후의 위치 변화에 대한 정보를 의미할 수 있다. 예를 들 면, 3D 모델의 임의의 포인트의 좌표 (x0, y0, z0)가 변형에 의하여 (x1, y1, z1)로 이동한 경우, 오프 셋은 (x1-x0, y1-y0, z1-z0)의 3차원 벡터로 표현될 수 있다. 오프 셋은 3D 모델의 각 포인트에 대하여 개별적으로 결정될 수 있다. 도 8을 참조하면, 변형 후 3D 모델은 변형 전 3D 모델에 포함된 포인트들의 위치가 변경됨으로써 생 성될 수 있다. 본 개시의 일 실시예에 따른, 전자 장치는 3D 모델을 변형할 수 있다. 예를 들면, 전자 장치는 기초 3D 모델 혹은 합성 3D 모델과 타겟 3D 모델을 합성하기 위하여, 타겟 3D 모델에 대한 변형을 수행할 수 있 다. 본 개시의 일 실시예에 따른 전자 장치는 3D 모델을 다른 3D 모델(미도시)의 포인트들 사이의 분포와 유사하도록 타겟 3D 모델을 변형할 수 있다. 예를 들면, 복수의 3D 모델의 사이즈가 다른 경우(예: 하나의 3D 모델의 포인트들은 640 x 640 x 640의 정육면체에 포함되고, 다른 3D 모델의 포인트들은 40 x 40 x 40의 정육면 체에 포함되는 경우), 복수의 3D 모델의 각 포인트들 사이에 분포되어 있는 간격은 서로 다르다. 위의 예시에서, 복수의 3D 모델을 합성하면 부정확한 정보들이 포함된 3D 모델이 생성될 수 있다. 따라서, 전자 장치 가 변형 과정을 수행함으로써 복수의 3D 모델이 대응되도록 3D 모델을 수정할 수 있다. 도 9a은 본 개시의 일 실시예에 따른 3D 모델에 대한 변형을 수행하기 위한 정보를 획득하는 과정을 설명하기 위한 도면이다. 도 9a을 참조하면, 특징 추출부(930, 935) 및 구성 비교부를 이용하여 기초 3D 모델 및 타겟 3D 모델 에 대한 오프셋 및 구성 유사도가 결정될 수 있다. 전자 장치는 특징 추출부(930, 935) 및 구성 비교부(940a, 945a)를 포함할 수 있다. 본 개시의 일 실시예에 따라, 도 2의 3D 모델 병합부는 특징 추출부(930, 935) 및 구성 비교부(940a, 945a)를 포함할 수 있다. 설명의 편의를 위하여, 전자 장치가 기초 3D 모델에 기초하여 타겟 3D 모델을 변형하는 과정을 설명하지만, 전자 장치가 합성 3D 모델에 기초하여 타겟 3D 모델을 변형하는 과정도 동일하게 수행될 수 있다. 타겟 3D 모델은 3D 모델 데이터 베이스 중에서 기초 3D 모델과 가장 유사도가 높은 3D 모델일 수 있 다. 본 개시의 일 실시예에 따라, 타겟 3D 모델은 기초 3D 모델 전부와 가장 유사도가 높은 3D 모델 일 수 있다. 전자 장치는 기초 3D 모델 및 타겟 3D 모델을 복수의 구성(920a, 925a)으로 분류할 수 있다. 혹은, 전자 장치는 복수의 구성(920a, 925a)으로 분류된 3D 모델을 획득할 수 있다. 특징 추출부(930, 935)는 복수의 구성으로 분류된 기초 3D 모델(920a) 및 복수의 구성으로 분류된 타겟 3D 모델 (925a)을 입력으로 하여, 기초 3D 모델의 각 구성의 특징(940a) 및 타겟 3D 모델의 각 구성의 특징(945a)을 출 력할 수 있다. 예를 들면, 특징 추출부(930, 935)는 복수의 구성으로 분류된 포인트 클라우드 혹은 메쉬로 표현 된 3D 모델을 입력으로 하여, 기초 3D 모델의 각 구성의 특징(940a) 및 타겟 3D 모델의 각 구성의 특징(945a)에 관한 1차원 임베딩 벡터를 출력할 수 있다. 본 개시의 일 실시예에 따른 특징 추출부(930, 935)는 CNN(Convolutional Neural Network)으로 구현될 수 있다. 구성 비교부는 기초 3D 모델의 특징들(940a) 중에서 하나의 구성의 특징(예: part Sa) 및 타겟 3D 모델의 특징들(945a) 중에서 하나의 구성의 특징(예: part Ta)에 기초하여 오프셋 및 구성 유사도를 출력할 수 있다. 본 개시의 일 실시예에 따라, 구성 비교부는 기초 3D 모델의 하나의 구성에 대응되는 3D 모델 (예: part Sa에 대응되는 3D 모델)을 추가로 입력으로 할 수 있다. 예를 들면, 기초 3D 모델이 포인트 클라우드 인 경우, 구성 비교부는 기초 3D 모델의 하나의 구성에 대응되는 3D 모델의 포인트들의 위치 정보를 획득할 수 있다. 예를 들면, 기초 3D 모델이 메쉬인 경우, 구성 비교부는 기초 3D 모델의 하나의 구 성에 대응되는 3D 모델의 포인트들의 위치 정보 및 포인트들 사이의 연결 정보를 획득할 수 있다. 본 개시의 일 실시예에 따라, 구성 비교부는 기초 3D 모델의 모든 구성의 특징(예: part Sa, Sb, Sc) 및 타겟 3D 모델의 모든 구성의 특징(예: part Ta, Tb, Tc)에 대하여 비교할 수 있다. 예를 들면, 도 9의 경우 기초 3D 모델 및 타겟 3D 모델의 구성이 각각 3개라면, 총 9번의 구성 비교가 수행될 수 있다. 오프셋은 타겟 3D 모델(920a)을 기초 3D 모델에 대응되도록 변경하기 위한 벡터일 수 있다. 구성 비교부는 입력된 3D 모델 사이의 구성 유사도를 결정할 수 있다. 구성 유사도는 입력된 기 초 3D 모델의 구성과 타겟 3D 모델(920a)의 구성 사이의 유사도를 의미할 수 있다. 입력된 기초 3D 모델 의 구성이 타겟 3D 모델(920a)의 구성에 대응되면 구성 유사도는 높은 값을 나타낼 수 있다. 예를 들 면, 입력된 기초 3D 모델의 구성과 타겟 3D 모델(920a)의 구성이 모두 의자의 팔걸이를 나타내는 경우, 구 성 유사도는 높은 값을 나타낼 수 있다. 입력된 기초 3D 모델의 구성이 타겟 3D 모델(920a)의 구성에 대응되지 않으면 구성 유사도는 낮은 값을 나타낼 수 있다. 예를 들면, 입력된 기초 3D 모델의 구성 은 의자의 팔걸이고, 타겟 3D 모델(920a)의 구성은 의자의 등받이인 경우, 구성 유사도는 낮은 값을 나타 낼 수 있다. 타겟 3D 모델(920a)과 기초 3D 모델 사이의 구성 유사도가 낮은 경우, 전자 장치는 변형을 수행 하지 않을 수 있다. 예를 들면, 구성 유사도가 0부터 1 사이의 정규화된 값이고 구성 유사도가 0.5 보다 작은 경우, 전자 장치는 타겟 3D 모델(920a)과 기초 3D 모델 사이의 변형을 수행하지 않을 수 있다. 본 개시의 일 실시예에 따라, 구성 비교부가 기초 3D 모델의 모든 구성(940a) 및 타겟 3D 모델 의 모든 구성(945a)에 대하여 구성 유사도를 결정함으로써, 전자 장치는 타겟 3D 모델에 대한 변형을 수행하는 구성을 결정할 수 있다. 예를 들면, 전자 장치는 {Part Sa, Part Ta}의 구성 유사도(97 0)가 0.5 이상인 것에 기초하여, 타겟 3D 모델의 등받이 구성(Part Ta)에 대한 변형을 기초 3D 모델 의 등받이 구성(Part Sa)을 참조하여 수행하는 것으로 결정할 수 있다. 예를 들면, 전자 장치는 {Part Sa, Part Tb}의 구성 유사도가 0.5 미만인 것에 기초하여, 타겟 3D 모델의 등받이 구성(Part Ta)에 대한 변형을 기초 3D 모델의 등받이 구성(Part Sb)을 참조하여 수행하지 않는 것으로 결정할 수 있다. 본 개시의 일 실시예에 따른 전자 장치는 특징 추출부(930, 935) 및 구성 비교부를 복수의 3D 모델과 복수의 모델의 구성 사이의 오프셋 및 구성 유사도를 포함하는 학습 데이터 셋으로 훈련할 수 있다. 본 개시의 일 실시예에 따라, 특징 추출부(930, 935)는 CNN으로 구현되고, 구성 비교부는 MLP(Multi Layer Perceptron)로 구현될 수 있다. 도 9b은 본 개시의 일 실시예에 따른 3D 모델에 대한 변형을 수행하기 위한 정보를 획득하는 과정을 설명하기 위한 도면이다. 도 9b을 참조하면, 기초 3D 모델(910b) 및 타겟 3D 모델의 구성 중 일부는 변형을 수행하지 않을 수 있다. 예를 들면, 기초 3D 모델(910b) 및 타겟 3D 모델의 구성 중 다리 구성은 변형을 수행하지 않고, 기초 3D 모델(910b) 및 타겟 3D 모델의 다리에 대응되는 3D 모델은 특징 추출부(930, 935)에 입력되지 않을 수 있 다. 설명의 편의를 위하여, 전자 장치가 기초 3D 모델(910b)에 기초하여 타겟 3D 모델을 변형하는 과정을 설명하지만, 전자 장치가 합성 3D 모델에 기초하여 타겟 3D 모델을 변형하는 과정도 동일하게 수행될수 있다. 설명의 편의를 위하여, 도 9a와 중복되는 내용은 생략하도록 한다. 전자 장치는 기초 3D 모델 및 타겟 3D 모델을 복수의 구성(920a, 925a)으로 분류할 수 있다. 혹은, 전자 장치는 복수의 구성(920a, 925a)으로 분류된 3D 모델을 획득할 수 있다. 특징 추출부(930, 935)는 복수의 구성으로 분류된 기초 3D 모델(920a) 및 복수의 구성으로 분류된 타겟 3D 모델 (925a)을 입력으로 하여, 기초 3D 모델의 각 구성의 특징(940a) 및 타겟 3D 모델의 각 구성의 특징(945a)을 출 력할 수 있다. 다만, 전자 장치가 변형하지 않는 구성에 대하여는 특징 추출부(930, 935)에 입력되지 않을 수 있다. 본 개시의 일 실시예에 따라, 구성 비교부는 기초 3D 모델의 변형의 대상에 해당하는 구성의 특징(예: part Sa, Sb) 및 타겟 3D 모델의 변형의 대상에 해당하는 구성의 특징(예: part Ta, Tb)에 대하 여 비교할 수 있다. 예를 들면, 도 9의 경우 기초 3D 모델 및 타겟 3D 모델의 구성이 각각 3개라면, 의자에 관한 구성 1개씩을 제외하고 총 4번의 구성 비교가 수행될 수 있다. 본 개시의 일 실시예에 따른 전자 장치가 변형을 수행하려는 구성에 대하여만 특징 추출 및 구성 비교를 수행함으로써 연산량이 줄어드는 효과를 얻을 수 있다. 이전에 생성된 합성 3D 모델과 객체 이미지가 특정 구성 에 있어서 유사도가 높은 경우, 전자 장치는 해당 구성에 대한 변형을 수행하지 않는 것으로 결정할 수 있 다. 전자 장치는 유사도가 낮은 구성에 대하여 우선적으로 보완하여 객체에 대한 3D 모델을 생성할 수 있 다. 도 10은 본 개시의 일 실시예에 따른 복수의 3D 모델을 병합하는 과정을 설명하기 위한 도면이다. 도 10을 참조하면, 기초 3D 모델 및 타겟 3D 모델을 병합함으로써, 합성 3D 모델이 생성될 수 있다. 도 10은 기초 3D 모델을 기초로 설명하지만, 기초 3D 모델을 대신하여 이전에 생성된 합 성 3D 모델에 기초하여 합성 3D 모델을 생성할 수 있다. 본 개시의 일 실시예에 따라, 전자 장치는 기초 3D 모델과 타겟 3D 모델을 병합할 수 있다. 합성 3D 모델은 기초 3D 모델의 정보와 타겟 3D 모델의 정보를 합침으로써 생성될 수 있다. 예를 들면, 기초 3D 모델에 포함된 포인트의 집합을 A라고 하고, 타겟 3D 모델에 포함된 포인트의 집합을 B라고 하면, 합성 3D 모델의 포인트의 집합은 A 합집합 B로 결정될 수 있다. 본 개시의 일 실시예에 따라, 타겟 3D 모델은 변형이 수행된 것일 수 있다. 전자 장치는 기초 3D 모 델에 대응되도록 타겟 3D 모델을 변경하는 변형을 수행할 수 있다. 변형이 수행된 타겟 3D 모델 의 정보량은 기초 3D 모델과 정보량과 동일할 수 있다. 예를 들면, 기초 3D 모델이 3000개의 포인 트들을 포함하는 경우, 3000개를 초과하는 타겟 3D 모델의 포인트들 중에서 3000개를 선택하는 다운샘플링이 수 행된 변형된 타겟 3D 모델이 생성될 수 있다. 도 11은 본 개시의 일 실시예에 따른 객체 이미지와 합성 3D 모델을 비교하는 과정을 설명하기 위한 도면이다. 도 11을 참조하면, 합성 3D 모델의 포즈가 객체 이미지의 포즈에 대응되도록 변환될 수 있다. 본 개시에서 \"포즈(pose)\"는 객체가 이미지 내에 존재하는 방향을 의미할 수 있다. 예를 들면, 객체 이미지 는 이미지 내에 오른쪽 팔걸이가 나타나지만, 합성 3D 모델은 오른쪽 팔걸이가 보이므로, 객체 이미지 와 합성 3D 모델의 포즈는 다르다. 본 개시의 일 실시예에 따른 전자 장치는 포즈 결정부 및 포즈 변환부를 포함할 수 있다. 포 즈 결정부는 객체 이미지와 합성 3D 이미지를 입력으로 하여, 객체 이미지의 포즈를 결정할 수 있 다. 본 개시의 일 실시예에 따라 포즈 결정부는 객체 이미지를 이용하여, 이미지의 포즈를 획득할 수 있다. 예를 들면, 포즈 결정부는 객체의 포즈에 대한 3차원 벡터를 획득할 수 있다. 본 개시의 일 실 시예에 따라 포즈 결정부는 객체 이미지 와 합성 3D 모델을 이용하여, 포즈의 차이를 획득할 수 있다. 예를 들면, 포즈 결정부는 객체 이미지 와 합성 3D 모델의 포즈가 동일하도록 변환 하기 위한 3차원 벡터를 획득할 수 있다. 본 개시의 일 실시예에 따른 포즈 변환부는 객체 이미지와 동일한 포즈가 되도록 합성 3D 모델 의 포즈를 변환할 수 있다. 포즈가 동일하도록 변환된 합성 3D 모델과 객체 이미지를 비교함 으로써 합성 3D 모델과 객체 이미지가 유사한지 여부를 명확하게 결정할 수 있다. 본 개시의 일 실시예에 따른 전자 장치는 합성 3D 모델과 객체 이미지 사이의 유사도를 결정 할 수 있다. 전자 장치는 포즈가 변환된 합성 3D 모델을 렌더링할 수 있다. 전자 장치는 렌더링된 합 성 3D 모델을 객체 이미지와 비교함으로써, 유사도를 결정할 수 있다. 예를 들면, 전자 장치는 렌더링된 합성 3D 모델과 객체 이미지 사이의 차이에 기초하여, 유사도를 결정할 수 있다. 대안적으로 혹은 추가적으로, 전자 장치는 렌더링된 합성 3D 모델의 특징과 객체 이미지의 특징에 기초하여 유 사도를 결정할 수 있다. 예를 들면, 전자 장치는 렌더링된 합성 3D 모델과 객체 이미지로부터 특징을 추출하고, 추출된 특징을 비교함으로써 유사도를 결정할 수 있다. 도 11은 렌더링되지 않은 합성 3D 모델에 기초하여 포즈를 변환하는 방법을 설명하였으나, 이에 제한되지 않고, 렌더링된 합성 3D 모델을 이용하여 포즈 변환이 수행될 수 있다. 도 12는 본 개시의 일 실시예에 따른 유사도가 낮은 구성을 보완하는 과정을 설명하기 위한 도면이다. 도 12를 참조하면, 이전에 생성된 합성 3D 모델의 팔걸이에 대한 정보는 부족하므로, 객체 이미지와 비교 하여 차이가 클 수 있다. 본 개시의 일 실시예에 따른 전자 장치는 이전에 생성된 합성 3D 모델 중에서 팔걸이에 대한 정보를 보완하기 위하여 타겟 3D 모델을 결정할 수 있다. 전자 장치는 보완하기 위한 구성에 대한 유사도 판단에 의하여 타겟 3D 모델을 결정할 수 있다. 예를 들면, 팔걸이 구성에 대한 유사도가 제일 높은 3D 모델을 타겟 3D 모델로 결정할 수 있다. 전체적으로 판단하면 더 유사한 3D 모델이 존재할 수 있지만, 특정 구 성에 대한 유사도만 판단함으로써, 해당 구성에 대한 정보를 보완할 수 있다. 전자 장치는 타겟 3D 모델의 팔걸이에 대응되는 3D 모델을 분리할 수 있다. 전자 장치는 이전에 생성된 합성 3D 모델과 팔걸이에 대응되는 3D 모델을 이용하여, 합성 3D 모델을 생성 할 수 있다. 도 13은 본 개시의 일 실시예에 따른 3D 모델의 색상 정보를 설명하기 위한 도면이다. 도 13을 참조하면, 객체 이미지는 색상 정보를 포함하는 이미지다. 예를 들면, 객체 이미지는 RGB- D 이미지일 수 있다. 기초 3D 모델은 객체 이미지의 3차원 위치 정보를 이용하여 포인트가 결정되 고, 각 포인트에 대응되는 색상 정보를 객체 이미지로부터 획득할 수 있다. 타겟 3D 모델은 위치 정보를 포함할 수 있다. 본 개시의 일 실시예에 따른 전자 장치는 기초 3D 모델의 위치에 관한 정보 및 타겟 3D 모델 의 위치에 관한 정보에 기초하여, 합성 3D 모델의 위치에 관한 정보를 생성하고, 기초 3D 모델의 색상에 관한 정보에 기초하여, 합성 3D 모델의 색상에 관한 정보를 생성할 수 있다. 3D 모델의 위치에 관 한 정보는 3D 모델의 포인트의 위치 정보를 의미하고, 3D 모델의 색상에 관한 정보는 3D 모델의 포인트의 위치 정보를 의미할 수 있다. 합성 3D 모델은 기초 3D 모델의 포인트들과 타겟 3D 모델의 포인트들을 포함할 수 있다. 합 성 3D 모델 중 타겟 3D 모델의 포인트들은 기초 3D 모델의 포인트들의 색상 정보로부터 결정될 수 있다. 예를 들면, 합성 3D 모델 중 타겟 3D 모델의 포인트들은 기초 3D 모델의 포인트들의 위치 정 보 및 색상 정보에 기초하여 보간을 통해 생성될 수 있다. 전자 장치는 합성 3D 모델의 색상 정보는 기초 3D 모델로부터 결정됨으로써, 객체 이미지와 유사한 3D 모델을 생성할 수 있다. 도 13은 기초 3D 모델인 경우로 설명하였지만, 이에 제한되지 않고, 합성 3D 모델인 경우에도 동일하게 이해될 수 있다. 즉, 이전에 생성된 합성 3D 모델의 위치 정보 및 색상 정보와 타겟 3D 모델의 위치 정보를 이 용하여, 새로운 합성 3D 모델의 위치 정보 및 색상 정보가 결정될 수 있다. 도 14는 본 개시의 일 실시예에 따른 합성 3D 모델을 생성하는 방법에 관한 순서도이다. 도 14을 참조하면, 합성 3D 모델을 생성하는 방법은 단계 1410으로 시작될 수 있다. 본 개시의 일 실시예 에 따른, 합성 3D 모델을 생성하는 방법은 전자 장치에 의하여 수행될 수 있다. 단계 1410에서, 전자 장치는 적어도 하나의 객체 이미지에 기초하여, 객체에 대한 기초 3D 모델을 생성할 수 있다. 기초 3D 모델은 객체 이미지에 기초하여 추론된 3차원 정보를 포함할 수 있다. 3차원 정보는 객체의 경계를 나타내는 포인트의 위치 정보를 포함할 수 있다. 단계 1420에서, 전자 장치는 복수의 3D 모델이 저장된 3D 모델 데이터 베이스 중에서 기초 3D 모델과 유사 한 제1 타겟 3D 모델을 결정할 수 있다. 본 개시의 일 실시예에 따라, 전자 장치는 객체 이미지에 기초하여, 객체의 종류를 식별하고, 3D 모델 데이터 베이스는 식별된 객체의 종류에 관한 3D 모델 데이터 베이스일 수 있다. 예를 들면, 전자 장치가 객체를 의자로 식별한 경우, 3D 모델 데이터 베이스는 의자 3D 모델에 관한 데이터 베이스일 수 있다. 단계 1430에서, 전자 장치는 기초 3D 모델과 제1 타겟 3D 모델에 기초하여, 제1 합성 3D 모델을 생성할 수 있다. 제1 합성 3D 모델은 기초 3D 모델과 제1 타겟 3D 모델을 병합함으로써 생성될 수 있다. 단계 1440에서, 전자 장치는 제1 합성 3D 모델과 적어도 하나의 객체 이미지의 제1 유사도를 결정할 수 있 다. 전자 장치는 렌더링된 제1 합성 3D 모델과 적어도 하나의 객체 이미지를 비교함으로써 제1 유사도를 결정할 수 있다. 예를 들면, 제1 유사도는 0 내지 1 사이의 값으로 결정될 수 있다. 단계 1450에서, 전자 장치는 제1 유사도가 임계 값보다 작거나 같은 것에 기초하여, 제1 합성 3D 모델과 객체 이미지 사이의 유사도가 낮은 구성을 결정할 수 있다. 전자 장치는 합성 3D 모델을 복수의 구성으로 분류하고, 각 구성 별로 유사도를 결정할 수 있다. 일 실시예에 따라, 전자 장치는 분류된 복수의 구성 각 각에 대하여, 제1 합성 3D 모델과 적어도 하나의 객체 이미지 사이의 제3 유사도가 낮은 구성을 결정하고, 복수 의 구성 중에서, 제3 유사도가 소정의 값보다 작은 구성을 상기 유사도가 낮은 구성으로 결정할 수 있다. 예를 들면, 전자 장치는 객체 \"의자\"의 복수의 구성 \"팔걸이\", \"등받이\" 등에 대하여 제1 합성 3D 모델과 적어 도 하나의 객체 이미지 사이의 유사도를 결정하고, 복수의 구성에 대한 유사도 각각(예: \"팔걸이\"에 대한 유사 도, \"등받이\"에 대한 유사도)을 임계 값과 비교하여, 유사도가 낮은 구성을 결정할 수 있다. 유사도가 낮은 구 성은 하나 이상으로 결정될 수 있다. 단계 1460에서, 전자 장치는 3D 모델 데이터 베이스 중에서 상기 유사도가 낮은 구성에 대하여 상기 제1 합성 3D 모델과 유사도가 높은 3D 모델을 제2 타겟 3D 모델로 결정할 수 있다. 전자 장치는 단계 1470에서, 전자 장치는 제1 합성 3D 모델과 제2 타겟 3D 모델에 기초하여, 제2 합성 3D 모델을 생성 할 수 있다. 전자 장치는 합성 3D 모델을 복수의 구성으로 분류하여, 정보량이 부족하여 객체 이미지와 유 사도가 낮은 구성에 대한 보완을 할 수 있다. 전자 장치는 구성 별로 3D 모델 데이터 베이스를 이용하여 보완할 수 있고, 따라서 적은 수의 객체 이미지를 이용하여 3D 모델을 생성할 수 있다. 도 15는 본 개시의 일 실시예에 따른 전자 장치의 구성을 설명하기 위한 블록도이다. 도 15를 참조하면, 본 개시의 일 실시예에 따른 전자 장치는 메모리와 프로세서를 포함할 수 있으나, 이에 한정되는 것은 아니며, 범용적인 구성이 더 추가될 수 있다. 일 실시예에 따른 메모리는, 프로세서의 처리 및 제어를 위한 프로그램을 저장할 수 있고, 전자 장 치로 입력되거나 혹은 전자 장치로부터 출력되는 데이터를 저장할 수 있다. 메모리는 프로세서 가 판독할 수 있는 명령어들, 데이터 구조, 및 프로그램 코드(program code)가 저장될 수 있다. 개시된 실시예들에서, 프로세서가 수행하는 동작들은 메모리에 저장된 프로그램의 명령어들 또는 코드들을 실행함으로써 구현될 수 있다. 일 실시예에 따른 메모리는 플래시 메모리 타입(flash memory type), 하드디스크 타입(hard disk type), 멀티미디어 카드 마이크로 타입(multimedia card micro type), 카드 타입의 메모리(예를 들어 SD 또는 XD 메모 리 등)를 포함할 수 있으며, 롬(ROM, Read-Only Memory), EEPROM(Electrically Erasable Programmable Read- Only Memory), PROM(Programmable Read-Only Memory), 자기 메모리, 자기 디스크, 광디스크 중 적어도 하나를 포함하는 비 휘발성 메모리 및 램(RAM, Random Access Memory) 또는 SRAM(Static Random Access Memory)과 같 은 휘발성 메모리를 포함할 수 있다. 일 실시예에 따른 메모리는 3D 모델을 생성하는 전자 장치가 태스크를 수행할 수 있도록 제어하는 하나 이상의 인스트럭션 및/또는 프로그램을 저장할 수 있다. 예를 들어, 메모리에는 기초 3D 모델 생성 부, 타겟 3D 모델 결정부, 합성 3D 모델 생성부, 이미지 렌더링부, 이미지 비교부, 유사도 결정부, 구성 비교부, 포즈 결정부, 포즈 변환부 등이 저장될 수 있다. 일 실시예에 따른 프로세서는 메모리에 저장된 명령어들이나 프로그램화된 소프트웨어 모듈을 실행 함으로써, 전자 장치가 태스크를 수행할 수 있도록 동작이나 기능을 제어할 수 있다. 프로세서는 산 술, 로직 및 입출력 연산과 시그널 프로세싱을 수행하는 하드웨어 구성 요소로 구성될 수 있다. 프로세서(152 0)는 메모리에 저장된 하나 이상의 인스트럭션(instructions)을 실행함으로써, 전자 장치가 합성 3D 를 생성하는 태스크를 수행하는 전반적인 동작들을 제어할 수 있다. 일 실시예에 따른 프로세서는 예를 들어, 중앙 처리 장치(Central Processing Unit), 마이크로 프로세서 (microprocessor), 그래픽 처리 장치(Graphic Processing Unit), ASICs(Application Specific Integrated Circuits), DSPs(Digital Signal Processors), DSPDs(Digital Signal Processing Devices), PLDs(Programmable Logic Devices), FPGAs(Field Programmable Gate Arrays), 애플리케이션 프로세서 (Application Processor), 신경망 처리 장치(Neural Processing Unit) 또는 인공지능 모델의 처리에 특화된 하 드웨어 구조로 설계된 인공지능 전용 프로세서 중 적어도 하나로 구성될 수 있으나, 이에 제한되는 것은 아니다. 프로세서를 구성하는 각 프로세서는 소정의 기능을 수행하기 위한 전용 프로세서일 수 있다. 일 실시예에 따른 인공 지능(AI; artificial intelligence) 프로세서는, 인공지능(AI) 모델을 이용하여, 전자 장치가 수행하도록 설정된 태스크의 처리를 위해, 연산 및 제어를 수행할 수 있다. AI 프로세서는, 인공 지능(AI)을 위한 전용 하드웨어 칩 형태로 제작될 수도 있고, 또는 범용 프로세서(예: CPU 또는 application processor) 또는 그래픽 전용 프로세서(예: GPU)의 일부로 제작되어 전자 장치에 탑재될 수도 있다. 본 개시의 일 실시예에 따르면 프로세서는 메모리에 저장된 하나 이상의 인스트럭션을 실행함으로 써, 적어도 하나의 객체 이미지에 기초하여, 객체에 대한 기초 3D 모델을 생성할 수 있다. 프로세서는 메 모리에 저장된 하나 이상의 인스트럭션을 실행함으로써, 복수의 3D 모델이 저장된 3D 모델 데이터 베이스 중에서 기초 3D 모델과 유사한 제1 타겟 3D 모델을 결정할 수 있다. 프로세서는 메모리에 저장된 하나 이상의 인스트럭션을 실행함으로써, 기초 3D 모델과 제1 타겟 3D 모델에 기초하여, 제1 합성 3D 모델을 생 성할 수 있다. 프로세서는 메모리에 저장된 하나 이상의 인스트럭션을 실행함으로써, 제1 합성 3D 모델과 적어도 하나의 객체 이미지의 제1 유사도를 결정할 수 있다. 프로세서는 메모리에 저장된 하나 이상의 인스트럭션을 실행함으로써, 제1 유사도가 임계 값보다 작거나 같은 것에 기초하여, 제1 합성 3D 모델과 상기 적어도 하나의 객체 이미지 사이에 유사도가 낮은 구성을 결정할 수 있다. 프로세서는 상기 3D 모델 데이터 베이스 중에서 상기 유사도가 낮은 구성에 대하여 상기 제1 합성 3D 모델과 유사도가 높은 3D 모델을 제2 타겟 3D 모델로 결정할 수 있다. 프로세서는 메모리에 저장된 하나 이상의 인스트럭션 을 실행함으로써, 제1 합성 3D 모델과 제2 타겟 3D 모델에 기초하여, 제2 합성 3D 모델을 생성할 수 있다. 본 개시의 일 실시예에 따라서, 프로세서는 메모리에 저장된 하나 이상의 인스트럭션을 실행함으로 써, 적어도 하나의 객체 이미지를 이용하여, 적어도 하나의 객체 이미지의 깊이 정보를 획득할 수 있다. 적어도 하나의 프로세서가 적어도 하나의 인스트럭션을 실행함으로써, 적어도 하나의 객체 이미지 및 획득된 깊이 정보 를 이용하여, 객체의 적어도 일부에 관한 3차원 위치 정보를 포함하는 기초 3D 모델을 생성할 수 있다. 본 개시의 일 실시예에 따라서, 프로세서는 메모리에 저장된 하나 이상의 인스트럭션을 실행함으로 써, 적어도 하나의 객체 이미지와 복수의 3D 모델 사이의 제2 유사도를 결정할 수 있다. 프로세서는 메모 리에 저장된 하나 이상의 인스트럭션을 실행함으로써, 복수의 3D 모델 중에서 제2 유사도가 높은 3D 모델 을 제1 타겟 3D 모델로 결정할 수 있다. 본 개시의 일 실시예에 따라서, 프로세서는 메모리에 저장된 하나 이상의 인스트럭션을 실행함으로 써, 타겟 3D 모델을 기초 3D 모델에 대응되도록 변형을 수행할 수 있다. 프로세서는 메모리에 저장 된 하나 이상의 인스트럭션을 실행함으로써, 기초 3D 모델과 변형된 타겟 3D 모델을 병합할 수 있다. 본 개시의 일 실시예에 따라서, 프로세서는 메모리에 저장된 하나 이상의 인스트럭션을 실행함으로 써, 기초 3D 모델을 객체에 대한 복수의 구성으로 분류할 수 있다. 본 개시의 일 실시예에 따라서, 프로세서는 메모리에 저장된 하나 이상의 인스트럭션을 실행함으로 써, 분류된 복수의 구성 각각에 대하여제1 합성 3D 모델과 적어도 하나의 객체 이미지 사이의 유사도가 낮은 구 성을 결정할 수 있다. 프로세서는 메모리에 저장된 하나 이상의 인스트럭션을 실행함으로써, 복수 의 구성 중에서, 제3 유사도가 소정의 값보다 작은 구성을 유사도가 낮은 구성으로 결정할 수 있다. 본 개시의 일 실시예에 따라서, 프로세서는 메모리에 저장된 하나 이상의 인스트럭션을 실행함으로 써, 제1 합성 3D 모델을 렌더링할 수 있다. 프로세서는 메모리에 저장된 하나 이상의 인스트럭션을 실행함으로써, 렌더링된 제1 합성 3D 모델의 포즈를 적어도 하나의 객체 이미지에 대응되도록 수정할 수 있다. 프로세서는 메모리에 저장된 하나 이상의 인스트럭션을 실행함으로써, 수정된 렌더링된 제1 합성 3D 모델과 적어도 하나의 객체 이미지 사이의 제1 유사도를 결정할 수 있다. 본 개시의 일 실시예에 따라서, 프로세서는 메모리에 저장된 하나 이상의 인스트럭션을 실행함으로 써, 적어도 하나의 객체 이미지에 기초하여, 객체의 종류를 식별할 수 있다. 프로세서는 메모리에저장된 하나 이상의 인스트럭션을 실행함으로써, 3D 모델 데이터 베이스는 객체의 종류에 관한 3D 모델을 포함 할 수 있다. 본 개시의 일 실시예에 따라, 프로세서는 메모리에 저장된 하나 이상의 인스트럭션을 실행함으로써, 기초 3D 모델의 위치에 관한 정보 및 제1 타겟 3D 모델의 위치에 관한 정보에 기초하여, 제1 합 성 3D 모델의 위치에 관한 정보를 생성할 수 있다. 프로세서는 메모리에 저장된 하나 이상의 인스 트럭션을 실행함으로써, 기초 3D 모델의 색상에 관한 정보에 기초하여, 제1 합성 3D 모델의 색상에 관한 정보를 생성할 수 있다. 한편, 본 개시의 실시예들은 컴퓨터에 의해 실행되는 프로그램 모듈과 같은 컴퓨터에 의해 실행 가능한 명령어 를 포함하는 기록 매체의 형태로도 구현될 수 있다. 컴퓨터 판독 가능 매체는 컴퓨터에 의해 액세스 될 수 있는 임의의 가용 매체일 수 있고, 휘발성 및 비휘발성 매체, 분리형 및 비분리형 매체를 모두 포함한다. 또한, 컴퓨 터 판독 가능 매체는 컴퓨터 저장 매체 및 통신 매체를 포함할 수 있다. 컴퓨터 저장 매체는 컴퓨터 판독 가능 명령어, 데이터 구조, 프로그램 모듈 또는 기타 데이터와 같은 정보의 저장을 위한 임의의 방법 또는 기술로 구 현된 휘발성 및 비휘발성, 분리형 및 비분리형 매체를 모두 포함한다. 통신 매체는 전형적으로 컴퓨터 판독 가 능 명령어, 데이터 구조, 또는 프로그램 모듈과 같은 변조된 데이터 신호의 기타 데이터를 포함할 수 있다. 도 16은 본 개시의 일 실시예에 따른 아바타 3D 모델을 생성하는 방법을 설명하기 위한 도면이다. 도 16을 참조하면, 사용자 아바타 3D 모델 DB는 과거에 생성된 사용자 아바타 3D 모델을 포함한다. 예를 들면, 사용자 아바타 3D 모델 DB는 19년 6월 3일에 생성된 사용자 아바타 3D 모델, 20년 1월 13일에 생성 된 사용자 아바타 3D 모델 및 21년 4월 9일에 생성된 사용자 아바타 3D 모델을 포함할 수 있다. 각 날짜에 생성 된 사용자 아바타 3D 모델은 해당 날짜의 사용자 착장을 반영하여 생성된 것일 수 있다. 본 개시의 일 실시예에 따른 전자 장치는 사용자 이미지를 획득할 수 있다. 전자 장치는 사용 자 이미지에 기초하여, 사용자의 착장이 반영된 합성 아바타 3D 모델을 생성할 수 있다. 본 개시의 일 실시예에 따른 전자 장치는 사용자 이미지에 기초하여, 기초 3D 모델을 생성하고, 사용자 아바타 3D 모델에 포함된 타겟 3D 모델과 기초 3D 모델을 이용하여 합성 아바타 3D 모델을 생성할 수 있다. 전자 장치는 유사하지 않은 구성을 보완하기 위하여 반복적으로 타겟 3D 모델을 이용하여 합성 3D 모델을 생성할 수 있다. 전자 장치가 구성의 일부를 보완한 합성 3D 모델을 생성하는 방법은 도 1 내지 도 14를 참조하여 설명하였으므로 생략하도록 한다. 본 개시의 일 실시예에 따라, 합성 3D 모델의 구성은 사용자 외모 및 사용자 착장을 포함할 수 있다. 또한, 보다 구체적으로 사용자 착장은 상의, 하의, 신발 등으로 분류될 수 있다. 전자 장치는 합성 3D 모델을 이용하여 메타버스 등 온라인에서 활용할 수 있다. 예를 들면, 전자 장치는 사용자의 착장이 반영된 합성 3D 모델을 이용하여 메타버스 내에서의 사용자 아바타를 변경할 수 있다. 도 17은 본 개시의 일 실시예에 따른 아바타 3D 모델을 생성하는 방법을 설명하기 위한 도면이다. 도 17을 참조하면, 사용자 아바타 3D 모델 DB는 과거에 생성된 사용자 아바타 3D 모델을 포함한다. 본 개 시의 일 실시예에 따라, 사용자 아바타 3D 모델 DB는 다양한 사람들에 의하여 생성된 사용자 아바타 3D 모델을 포함할 수 있다. 본 개시의 일 실시예에 따른 전자 장치는 사용자 이미지를 획득할 수 있다. 전자 장치는 사용 자 이미지에 기초하여, 사용자의 외관이 반영된 합성 아바타 3D 모델을 생성할 수 있다. 본 개시의 일 실시예에 따른 전자 장치는 사용자 이미지에 기초하여, 기초 3D 모델을 생성하고, 사용자 아바타 3D 모델에 포함된 타겟 3D 모델(1735-1)과 기초 3D 모델을 이용하여 합성 아바타 3D 모델을 생성할 수 있다. 전자 장치는 유사하지 않은 구성을 보완하기 위하여 새로운 타겟 3D 모델(1735-2)을 이용하여 새로운 합성 3D 모델을 생성할 수 있다. 전자 장치가 구성의 일부를 보완한 합성 3D 모델을 생성하는 방법은 도 1 내지 도 14를 참조하여 설명하였으므로 생략하도록 한다. 본 개시의 일 실시예에 따라, 합성 3D 모델의 구성은 사용자 외모 및 사용자 착장을 포함할 수 있다. 또한, 보다 구체적으로 사용자 외모는 얼굴, 팔, 다리 등으로 분류될 수 있다.전자 장치는 합성 3D 모델을 이용하여 메타버스 등 온라인에서 활용할 수 있다. 예를 들면, 전자 장 치는 사용자의 착장이 반영된 합성 3D 모델을 이용하여 메타버스 내에서의 사용자 아바타를 변경할 수 있다. 도 18은 본 개시의 일 실시예에 따른 실내 공간 3D 모델을 생성하는 방법을 설명하기 위한 도면이다. 도 18을 참조하면, 실내 공간 3D 모델 DB는 과거에 생성된 인테리어 3D 모델을 포함한다. 본 개시의 일 실시예에 따른 전자 장치는 실내 공간 이미지를 획득할 수 있다. 전자 장치는 실 내 공간 이미지에 기초하여, 합성 실내 공간 3D 모델을 생성할 수 있다. 본 개시의 일 실시예에 따 른 전자 장치는 실내 공간 이미지에 기초하여, 기초 실내 공간 3D 모델을 생성하고, 실내 공간 3D 모델에 포함된 타겟 실내 공간 3D 모델(1835-1)과 기초 실내 공간 3D 모델을 이용하여 합성 실내 공간 3D 모델을 생성할 수 있다. 전자 장치는 유사하지 않은 구성을 보완하기 위하여 새로운 타겟 실내 공간 3D 모델(1835-2)을 이용하여 새로운 합성 실내 공간 3D 모델을 생성할 수 있다. 예를 들면, 외벽에 포함된 액자에 관한 정보를 보완하 기 위하여, 전자 장치는 액자와 유사한 구성을 포함하는 타겟 실내 공간 3D 모델을 이용할 수 있다. 전자 장치가 구성의 일부를 보완한 합성 3D 모델을 생성하는 방법은 도 1 내지 도 14를 참조하여 설명하였으므 로 생략하도록 한다. 전자 장치는 합성 3D 모델을 이용하여 IoT(Internet of Things) 장치 등에서 활용할 수 있다. 예를 들면, 전자 장치는 합성 실내 공간 3D 모델을 이용하여 사용자에게 가구 배치를 추천하거나, 로봇 청소기의 경로를 설정하는 등의 태스크를 수행할 수 있다. 도 19a 및 도 19b는 공간 맵을 설명하기 위한 흐름도이다. 도 19a를 참조하면, 공간 맵과 공간 맵을 구성하는 복수의 레이어들 간의 계층적 구조를 나타내고 있다. 도 19a 에 도시된 바와 같이, 공간 맵은 베이스 레이어, 시맨틱 맵 레이어, 실시간 레이어로 구성될 수 있으나, 이에 한정되는 것은 아니며, 태스크의 특성에 따라 레이어가 가감될 수 있다. 베이스 레이어는 벽, 기둥, 통로 등 공간 전체의 기본 구조에 관한 정보를 제공한다. 3차원 포인트 클라우드 데 이터를 처리하여, 좌표계를 정합하고, 위치를 저장함으로써, 베이스 레이어는 공간의 3차원 정보, 객체의 위치 정보, 이동 궤적 정보 등을 제공할 수 있다. 베이스 레이어는 베이스 맵과 지오메트릭 맵의 역할을 수행한다. 시멘틱 맵 레이어는 베이스 레이어 위에 시멘틱 정보를 제공하는 레이어이다. 사용자는 베이스 레이어의 공간 전체의 기본 구조에 'Room 1', 'Room 2', '접근 제한 구역' 등과 같은 시멘틱 정보를 부여하여, 전자 장치의 태 스크 수행에 활용할 수 있다. 예를 들어, 전자 장치가 로봇 청소기인 경우, 사용자는 'Room 2'만 청소하게 하거 나, '접근 제한 구역'은 로봇 청소기가 청소하지 않도록, 시멘틱 맵 레이어에 시멘틱 정보를 설정할 수 있다. 실시간 레이어는 공간 내의 적어도 하나의 객체 정보를 제공하는 레이어이다. 객체는 정적 객체와 동적 객체 모 두 포함될 수 있다. 본 개시에서 실시간 레이어는 객체의 속성 정보에 기초한 복수의 레이어들을 포함할 수 있 으며, 레이어들 간의 계층적 구조를 가질 수 있다. 도 19a에 도시된 바와 같이, 실시간 레이어는 제1 레이어, 제2 레이어, 제3 레이어를 포함할 수 있으나, 이에 한정되는 것은 아니며, 객체의 속성 정보의 분류 기준에 따 라 레이어의 개수가 가감될 수 있다. 도 19a를 보면, 제1 레이어에는 시스템 옷장, 붙박이 장이 포함되고, 제2 레이어에는 테이블과 소파가 포함되고, 제3 레이어에는 의자가 포함됨을 알 수 있다. 도 19b를 참조하면, 객체의 속성 정보에 기초한 복수의 레이어들을 포함하는 실시간 레이어의 다양한 예를 나타 내고 있다. 객체의 속성 정보는 객체의 종류, 형상, 사이즈, 높이 등과 같은 객관적인 기준이나 복수의 기준을 조합하여 분 류될 수 있는 정보일 수 있다. 또한, 객체의 속성 정보는 사용자 및 환경에 따라 달라질 수 있으므로, 객체 별 로 레이블링하여 속성 정보를 입력해 둘 수있다. 본 개시의 일 실시예에 따르면, 객체의 속성 정보가 객체의 이동성 레벨(ML, Mobability Level)인 경우, 제1 레 이어에는 ML 1에 해당하는 객체가 포함되고, 제2 레이어에는 ML 2와 ML 3에 해당하는 객체가 포함되며, 제3 레 이어에는 ML 4에 해당하는 객체가 포함될 수 있다. 객체의 이동성 레벨은 객체의 객관적인 특징을 이동성을 평 가하는 소정의 분류 기준에 적용함으로써 정해질 수 있다. 예를 들어, ML 1은 이동이 불가능한 객체, ML 2는 이 동이 가능하지만, 주로 고정된 상태로 있는 객체, ML 3는 이동이 가능하지만, 가끔 이동하는 객체, ML 4는 이동가능하며, 자주 이동하는 객체에 각각 대응된다. 본 개시의 일 실시예에 따르면, 객체의 속성 정보가 객체의 위치 이동 주기(Position Movement Cycle)인 경우, 제1 레이어에는 1개월 내로 위치 이동이 없었던 객체가 포함되고, 제2 레이어에는 1개월 내로 위치 이동이 있었 던 객체가 포함되며, 제3 레이어에는 1주일 내로 위치 이동이 있었던 객체가 포함될 수 있다. 객체의 객관적 특 징에 기초하여 분류되는 이동성 레벨과 달리, 위치 이동 주기는 객체를 사용하는 사용자나 객체가 위치하는 환 경에 따라 동일한 객체라 하더라도, 위치 이동 주기는 다를 수 있다. 예를 들어, 'A'라는 객체는 제1 사용자가 자주 사용되는 객체인 반면, 제2 사용자는 거의 사용되지 않는 객체일 수 있다. 'B'라는 객체는 제1 장소에서는 자주 사용되는 객체인 반면, 제2 장소에서는 거의 사용되지 않는 객체일 수 있다. 본 개시의 일 실시예에 따르면, 객체의 속성 정보가 객체가 위치하는 높이(Height)인 경우, 제1 레이어에는 1m 이하에 해당하는 객체가 포함되고, 제2 레이어에는 1m 이상 2m 이하에 해당하는 객체가 포함되며, 제3 레이어에 는 2m를 초과하는 객체가 포함될 수 있다. 본 개시의 일 실시예에 따르면, 실시간 레이어에 포함되는 복수의 레이어들의 분류 기준은 사용자에 의해 정의 될 수 있다. 예를 들어, 사용자는 분류 기준에 대해 복수의 종류의 객체의 속성 정보를 조합하여 설정해둠으로 써, 태스크의 특성을 반영한 공간 맵을 생성할 수 있다. 예를 들어, 로봇 청소기의 경우, 일반적으로 50cm 높이 보다 아래에서 이동하기 때문에 1m 보다 높은 곳에 위치하는 객체들, 예를 들어, 전등이나 벽에 걸린 액자 등은 고려할 필요가 없다. 따라서, 사용자는 각 레이어를 구분하는 분류 기준을 직접 설정하여, 제1 레이어는 ML 1이 고 1m 이하에 위치하는 객체가 포함되고, 제2 레이어는 ML 2 또는 ML 3이고 1m 이하에 위치하는 객체가 포함되 며, 제3 레이어는 ML 4이고 1m 이하에 위치하는 객체가 포함되도록 할 수 있다. 도 20a, 도 20b, 도 20c, 도 20d는 공간 맵을 구성하는 레이어를 활용하는 방식을 설명하기 위한 도면이다. 전자 장치와 IoT 기기들의 종류나 태스크의 특성에 따라, 각 장치에서 이용되는 공간 맵이 서로 다를 수 있다. 전자 장치는 전자 장치에 저장된 기존의 공간 맵을 그대로 활용할 수도 있지만, 태스크를 수행할 공간에 변화가 생긴 경우, 해당 변화를 반영하기 위해 공간 맵을 업데이트할 수 있다. 전자 장치는 공간에 생긴 변화를 이미 반영하고 있는 공간 맵을 적어도 하나의 외부 장치로부터 수신하여, 기존의 공간 맵을 업데이트 할 수 있다. 전 자 장치는 기존의 공간 맵을 기초로, 새로운 공간 맵을 생성할 수 있다. 도 20a를 보면, 전자 장치는 저장되어 있던 기존의 공간 맵(이하, 제1 공간 맵)을 불러올 수 있다. 제1 공간 맵 은 베이스 레이어, 제1 레이어, 제2 레이어, 및 제3 레이어로 구성되어 있다. 이하, 설명의 편의상, 제1 레이어 내지 제3 레이어가 도 19b의 임의의 분류 기준에 따라 객체를 포함하는 것을 전제로 설명한다. 제1 공간 맵이 불과 몇분 전에 생성되었거나 제1 공간 맵이 이용된 후로 공간 내에 변화가 없는 경우, 전자 장치는 제1 공간 맵을 그대로 활용하여, 새로운 공간 맵(이하, 제2 공간 맵)을 획득하고, 새로운 태스크를 수행하는데 제2 공간 맵을 이용할 수 있다. 도 20b를 보면, 전자 장치는 저장되어 있던 제1 공간 맵을 불러올 수 있다. 전자 장치가 태스크를 수행함에 있 어서, 자주 이동하는 ML 4의 객체 정보는 필요하지 않거나, 1주일 이상 이동이 없었던 객체 정보만 이용하는 경 우, 제1 공간 맵을 구성하는 레이어들 중에 베이스 레이어, 제1 레이어, 및 제2 레이어를 선별하거나 제1 공간 맵에서 제3 레이어를 제거하여, 제2 공간 맵을 획득할 수 있다. 도 20c를 보면, 전자 장치는 저장되어 있던 제1 공간 맵을 불러올 수 있다. 전자 장치가 새로운 태스크를 수행 함에 있어서, ML 1의 객체 정보만 필요하거나, 1개월 이상 이동이 없었던 객체 정보만 이용하는 경우, 제1 공간 맵을 구성하는 레이어들 중에 베이스 레이어 및 제1 레이어를 선별하거나 제1 공간 맵에서 제2 레이어와 제3 레 이어를 제거하여, 제2 공간 맵을 획득할 수 있다. 도 20d를 보면, 전자 장치는 저장되어 있던 제1 공간 맵을 불러올 수 있다. 전자 장치가 새로운 태스크를 수행 함에 있어서, 이동이 가능한 ML 2, ML 3, 및 ML 4에 해당하는 객체들의 최신 정보를 반영할 필요가 경우, 제1 공간 맵을 구성하는 레이어들 중에 베이스 레이어 및 제1 레이어를 선별하거나 제1 공간 맵에서 제2 레이어와 제3 레이어를 제거하여, 제2 공간 맵을 획득할 수 있다. 이후, 전자 장치는 외부 장치로부터 수신된 공간 맵에 서 제2 레이어와 제3 레이어를 추출하여, 제2 공간 맵에 반영하여, 제3 공간 맵을 획득할 수 있다. 또는, 전자 장치에 구비된 적어도 하나의 센서를 이용하여, ML 2, ML 3, 및 ML 4에 해당하는 객체들을 검출하여, 제2 공간 맵에 반영하여, 제3 공간 맵을 획득할 수 있다. 기기로 읽을 수 있는 저장매체는, 비일시적(non-transitory) 저장매체의 형태로 제공될 수 있다. 여기서, ‘비 일시적 저장매체'는 실재(tangible)하는 장치이고, 신호(signal)(예: 전자기파)를 포함하지 않는다는 것을 의미할 뿐이며, 이 용어는 데이터가 저장매체에 반영구적으로 저장되는 경우와 임시적으로 저장되는 경우를 구분하 지 않는다. 예로, '비일시적 저장매체'는 데이터가 임시적으로 저장되는 버퍼를 포함할 수 있다. 일 실시예에 따르면, 본 문서에 개시된 다양한 실시예들에 따른 방법은 컴퓨터 프로그램 제품(computer program product)에 포함되어 제공될 수 있다. 컴퓨터 프로그램 제품은 상품으로서 판매자 및 구매자 간에 거래될 수 있 다. 컴퓨터 프로그램 제품은 기기로 읽을 수 있는 저장 매체(예: compact disc read only memory (CD-ROM))의 형태로 배포되거나, 또는 어플리케이션 스토어를 통해 또는 두개의 사용자 장치들(예: 스마트폰들) 간에 직접, 온라인으로 배포(예: 다운로드 또는 업로드)될 수 있다. 온라인 배포의 경우에, 컴퓨터 프로그램 제품(예: 다운 로더블 앱(downloadable app))의 적어도 일부는 제조사의 서버, 어플리케이션 스토어의 서버, 또는 중계 서버의 메모리와 같은 기기로 읽을 수 있는 저장 매체에 적어도 일시 저장되거나, 임시적으로 생성될 수 있다. 본 개시의 일 양태에 따르면, 3차원(3D) 모델을 생성하는 방법이 제공된다. 3차원 모델을 생성하는 방법은 객체 에 대한 적어도 하나의 객체 이미지에 기초하여, 상기 객체에 대한 기초 3D 모델을 생성하는 단계를 포함할 수 있다. 3차원 모델을 생성하는 방법은 복수의 3D 모델이 저장된 3D 모델 데이터 베이스 중에서 상기 기초 3D 모 델과 유사한 제1 타겟 3D 모델을 결정하는 단계를 포함할 수 있다. 3차원 모델을 생성하는 방법은 상기 기초 3D 모델과 상기 제1 타겟 3D 모델에 기초하여, 제1 합성 3D 모델을 생성하는 단계를 포함할 수 있다. 3차원 모델을 생성하는 방법은 상기 제1 합성 3D 모델과 상기 적어도 하나의 객체 이미지의 제1 유사도를 결정하는 단계를 포 함할 수 있다. 3차원 모델을 생성하는 방법은 상기 제1 유사도가 임계 값보다 작거나 같은 것에 기초하여, 상기 제1 합성 3D 모델과 상기 적어도 하나의 객체 이미지 사이에 유사도가 낮은 구성을 결정하는 단계를 포함할 수 있다. 3차원 모델을 생성하는 방법은 상기 3D 모델 데이터 베이스 중에서 상기 유사도가 낮은 구성에 대하여 상 기 제1 합성 3D 모델과 유사도가 높은 3D 모델을 제2 타겟 3D 모델로 결정하는 단계를 포함할 수 있다. 3차원 모델을 생성하는 방법은 상기 제1 합성 3D 모델과 상기 제2 타겟 3D 모델에 기초하여, 제2 합성 3D 모델을 생성 하는 단계를 포함할 수 있다. 본 개시의 일 실시예에 따른 기초 3D 모델을 생성하는 단계는 상기 적어도 하나의 객체 이미지를 이용하여, 상 기 적어도 하나의 객체 이미지의 깊이 정보를 획득하는 단계를 포함할 수 있다. 기초 3D 모델을 생성하는 단계 는 상기 적어도 하나의 객체 이미지 및 상기 획득된 깊이 정보를 이용하여, 상기 객체의 적어도 일부에 관한 3 차원 위치 정보를 포함하는 상기 기초 3D 모델을 생성하는 단계를 포함할 수 있다. 본 개시의 일 실시예에 따른 제1 타겟 3D 모델을 결정하는 단계는 상기 적어도 하나의 객체 이미지와 상기 복수 의 3D 모델 사이의 제2 유사도를 결정하는 단계를 포함할 수 있다. 제1 타겟 3D 모델을 결정하는 단계는 상기 복수의 3D 모델 중에서 상기 제2 유사도가 높은 3D 모델을 상기 제1 타겟 3D 모델로 결정하는 단계를 포함할 수 있다. 본 개시의 일 실시예에 따른 상기 제1 합성 3D 모델을 생성하는 단계는 상기 타겟 3D 모델을 상기 기초 3D 모델 에 대응되도록 변형을 수행하는 단계를 포함할 수 있다. 상기 제1 합성 3D 모델을 생성하는 단계는 상기 기초 3D 모델과 상기 변형된 타겟 3D 모델을 병합하는 단계를 포함할 수 있다. 본 개시의 일 실시예에 따른 3차원 모델 생성 방법은 상기 기초 3D 모델을 상기 객체에 대한 복수의 구성으로 분류하는 단계를 포함할 수 있다. 본 개시의 일 실시예에 따른 상기 제2 타겟 3D 모델을 결정하는 단계는 상기 분류된 복수의 구성 각각에 대하여,상기 제1 합성 3D 모델과 상기 적어도 하나의 객체 이미지 사이의 제3 유사도를 결정하는 단계를 포함할 수 있다. 상기 제2 타겟 3D 모델을 결정하는 단계는 상기 복수의 구성 중에서, 상기 제3 유사도가 소정의 값보 다 작은 구성을 상기 유사도가 낮은 구성으로 결정하는 단계를 포함할 수 있다. 본 개시의 일 실시예에 따른 상기 제1 유사도를 결정하는 단계는 상기 제1 합성 3D 모델을 렌더링하는 단계를 포함할 수 있다. 상기 제1 유사도를 결정하는 단계는 상기 렌더링된 제1 합성 3D 모델의 포즈를 상기 적어도 하 나의 객체 이미지에 대응되도록 수정하는 단계를 포함할 수 있다. 상기 제1 유사도를 결정하는 단계는 상기 수 정된 렌더링된 제1 합성 3D 모델과 상기 적어도 하나의 객체 이미지 사이의 제1 유사도를 결정하는 단계를 포함 할 수 있다. 본 개시의 일 실시예에 따른 3차원 모델 생성 방법은 상기 적어도 하나의 객체 이미지에 기초하여, 상기 객체의 종류를 식별하는 단계를 포함할 수 있다. 상기 3D 모델 데이터 베이스는 상기 객체의 종류에 관한 3D 모델일 수 있다. 본 개시의 일 실시예에 따른 상기 제1 합성 3D 모델을 생성하는 단계는 상기 기초 3D 모델의 위치에 관한 정보 및 상기 제1 타겟 3D 모델의 위치에 관한 정보에 기초하여, 상기 제1 합성 3D 모델의 위치에 관한 정보를 생성 하는 단계를 포함할 수 있다. 상기 제1 합성 3D 모델을 생성하는 단계는 상기 기초 3D 모델의 색상에 관한 정보 에 기초하여, 상기 제1 합성 3D 모델의 색상에 관한 정보를 생성하는 단계를 포함할 수 있다. 본 개시의 일 실시예에 따른 상기 합성 3D 모델은 포인트 클라우드 모델, 폴리곤 메시 모델, 삼각형 메시 모델, NURBS(Non-Uniform Rational B-spline) 모델 또는 스컬핑(Sculpting) 모델 중 적어도 하나를 포함할 수 있다. 본 개시의 일 양태에 따라서, 전술한 방법을 수행하도록 하는 프로그램이 저장된 하나 이상의 컴퓨터로 읽을 수 있는 기록매체가 제공된다. 본 개시의 일 양태에 따라서 3차원(3D) 모델을 생성하는 전자 장치가 제공된다. 전자 장치는 적어도 하나의 프 로세서를 포함할 수 있다. 전자 장치는 적어도 하나의 인스트럭션을 저장하는 메모리를 포함할 수 있다. 적어도 하나의 프로세서가 상기 적어도 하나의 인스트럭션을 실행함으로써, 적어도 하나의 객체 이미지에 기초하여, 객 체에 대한 기초 3D 모델을 생성할 수 있다. 적어도 하나의 프로세서가 상기 적어도 하나의 인스트럭션을 실행함 으로써, 복수의 3D 모델이 저장된 3D 모델 데이터 베이스 중에서 상기 기초 3D 모델과 유사한 제1 타겟 3D 모델 을 결정할 수 있다. 적어도 하나의 프로세서가 상기 적어도 하나의 인스트럭션을 실행함으로써, 상기 기초 3D 모델과 상기 제1 타겟 3D 모델에 기초하여, 제1 합성 3D 모델을 생성할 수 있다. 적어도 하나의 프로세서가 상 기 적어도 하나의 인스트럭션을 실행함으로써, 상기 제1 합성 3D 모델과 상기 적어도 하나의 객체 이미지의 제1 유사도를 결정할 수 있다. 적어도 하나의 프로세서가 상기 적어도 하나의 인스트럭션을 실행함으로써, 상기 제1 유사도가 임계 값보다 작거나 같은 것에 기초하여, 상기 제1 합성 3D 모델과 상기 적어도 하나의 객체 이미지 사이에 유사도가 낮은 구성을 결정할 수 있다. 적어도 하나의 프로세서가 상기 적어도 하나의 인스트럭션을 실 행함으로써, 상기 3D 모델 데이터 베이스 중에서 상기 유사도가 낮은 구성에 대하여 상기 제1 합성 3D 모델과 유사도가 높은 3D 모델을 제2 타겟 3D 모델로 결정할 수 있다. 적어도 하나의 프로세서가 상기 적어도 하나의 인스트럭션을 실행함으로써, 상기 제1 합성 3D 모델과 상기 제2 타겟 3D 모델에 기초하여, 제2 합성 3D 모델을 생성할 수 있다. 본 개시의 일 실시예에 따라서, 상기 적어도 하나의 프로세서가 상기 적어도 하나의 인스트럭션을 실행함으로써, 상기 적어도 하나의 객체 이미지를 이용하여, 상기 적어도 하나의 객체 이미지의 깊이 정보를 획 득할 수 있다. 적어도 하나의 프로세서가 상기 적어도 하나의 인스트럭션을 실행함으로써, 상기 적어도 하나의 객체 이미지 및 상기 획득된 깊이 정보를 이용하여, 상기 객체의 적어도 일부에 관한 3차원 위치 정보를 포함하 는 상기 기초 3D 모델을 생성할 수 있다. 본 개시의 일 실시예에 따라서, 상기 적어도 하나의 프로세서가 상기 적어도 하나의 인스트럭션을 실행함으로써, 상기 적어도 하나의 객체 이미지와 상기 복수의 3D 모델 사이의 제2 유사도를 결정할 수 있다. 적어도 하나의 프로세서가 상기 적어도 하나의 인스트럭션을 실행함으로써, 상기 복수의 3D 모델 중에서 상기 제2 유사도가 높은 3D 모델을 상기 제1 타겟 3D 모델로 결정할 수 있다. 본 개시의 일 실시예에 따라서, 적어도 하나의 프로세서가 상기 적어도 하나의 인스트럭션을 실행함으로써, 상 기 타겟 3D 모델을 상기 기초 3D 모델에 대응되도록 변형을 수행할 수 있다. 적어도 하나의 프로세서가 상기 적 어도 하나의 인스트럭션을 실행함으로써, 상기 기초 3D 모델과 상기 변형된 타겟 3D 모델을 병합할 수 있다. 본 개시의 일 실시예에 따라서, 상기 적어도 하나의 프로세서가 상기 적어도 하나의 인스트럭션을 실행함으로써, 상기 기초 3D 모델을 상기 객체에 대한 복수의 구성으로 분류할 수 있다. 본 개시의 일 실시예에 따라서, 상기 적어도 하나의 프로세서가 상기 적어도 하나의 인스트럭션을 실행함으로써, 상기 분류된 복수의 구성 각각에 대하여, 상기 제1 합성 3D 모델과 상기 적어도 하나의 객체 이 미지 사이의 제3 유사도를 결정할 수 있다. 적어도 하나의 프로세서가 상기 적어도 하나의 인스트럭션을 실행함 으로써, 상기 복수의 구성 중에서, 상기 제3 유사도가 소정의 값보다 작은 구성을 상기 유사도가 낮은 구성으로 결정할 수 있다. 본 개시의 일 실시예에 따라서, 상기 적어도 하나의 프로세서가 상기 적어도 하나의 인스트럭션을 실행함으로써, 상기 제1 합성 3D 모델을 렌더링할 수 있다. 적어도 하나의 프로세서가 상기 적어도 하나의 인스 트럭션을 실행함으로써, 상기 렌더링된 제1 합성 3D 모델의 포즈를 상기 적어도 하나의 객체 이미지에 대응되도 록 수정할 수 있다. 적어도 하나의 프로세서가 상기 적어도 하나의 인스트럭션을 실행함으로써, 상기 수정된 렌 더링된 제1 합성 3D 모델과 상기 적어도 하나의 객체 이미지 사이의 제1 유사도를 결정할 수 있다. 본 개시의 일 실시예에 따라서, 상기 적어도 하나의 프로세서가 상기 적어도 하나의 인스트럭션을 실행함으로써, 상기 적어도 하나의 객체 이미지에 기초하여, 상기 객체의 종류를 식별할 수 있다. 적어도 하나 의 프로세서가 상기 적어도 하나의 인스트럭션을 실행함으로써, 상기 3D 모델 데이터 베이스는 상기 객체의 종 류에 관한 3D 모델을 포함할 수 있다. 본 개시의 일 실시예에 따라, 상기 적어도 하나의 프로세서가 상기 적어도 하나의 인스트럭션을 실행함으로써, 상기 기초 3D 모델의 위치에 관한 정보 및 상기 제1 타겟 3D 모델의 위치에 관한 정보에 기초하여, 상기 제1 합 성 3D 모델의 위치에 관한 정보를 생성할 수 있다. 적어도 하나의 프로세서가 상기 적어도 하나의 인스트럭션을 실행함으로써, 상기 기초 3D 모델의 색상에 관한 정보에 기초하여, 상기 제1 합성 3D 모델의 색상에 관한 정보 를 생성할 수 있다.도면 도면1 도면2 도면3 도면4 도면5 도면6 도면7 도면8 도면9a 도면9b 도면10 도면11 도면12 도면13 도면14 도면15 도면16 도면17 도면18 도면19a 도면19b 도면20a 도면20b 도면20c 도면20d"}
{"patent_id": "10-2022-0183216", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 개시의 일 실시예에 따른 3차원(3D) 모델을 생성하는 방법을 설명하기 위한 도면이다. 도 2는 본 개시의 일 실시예에 따른 3차원(3D) 모델을 생성하는 방법을 설명하기 위한 도면이다. 도 3은 본 개시의 일 실시예에 따른 3차원 모델을 생성하는 방법에 관한 순서도이다. 도 4는 본 개시의 일 실시예에 따른 3차원 모델의 종류를 설명하기 위한 도면이다. 도 5는 본 개시의 일 실시예에 따른 객체 이미지에 기초하여 기초 3D 모델을 생성하는 과정을 설명하기 위한 도 면이다. 도 6은 본 개시의 일 실시예에 따른 3D 모델을 구성 단위로 분류하는 과정을 설명하기 위한 도면이다. 도 7은 본 개시의 일 실시예에 따른 3D 모델 사이의 유사도를 결정하는 과정을 설명하기 위한 도면이다. 도 8은 본 개시의 일 실시예에 따른 3D 모델의 변형(Deformation) 과정을 설명하기 위한 도면이다. 도 9a는 본 개시의 일 실시예에 따른 3D 모델에 대한 변형을 수행하기 위한 정보를 획득하는 과정을 설명하기 위한 도면이다. 도 9b는 본 개시의 일 실시예에 따른 3D 모델에 대한 변형을 수행하기 위한 정보를 획득하는 과정을 설명하기 위한 도면이다. 도 10은 본 개시의 일 실시예에 따른 복수의 3D 모델을 병합하는 과정을 설명하기 위한 도면이다. 도 11은 본 개시의 일 실시예에 따른 객체 이미지와 합성 3D 모델을 비교하는 과정을 설명하기 위한 도면이다. 도 12는 본 개시의 일 실시예에 따른 유사도가 낮은 구성을 보완하는 과정을 설명하기 위한 도면이다. 도 13은 본 개시의 일 실시예에 따른 3D 모델의 색상 정보를 설명하기 위한 도면이다. 도 14는 본 개시의 일 실시예에 따른 합성 3D 모델을 생성하는 방법에 관한 순서도이다. 도 15는 본 개시의 일 실시예에 전자 장치의 구성을 설명하기 위한 블록도이다. 도 16은 본 개시의 일 실시예에 따른 아바타 3D 모델을 생성하는 방법을 설명하기 위한 도면이다. 도 17은 본 개시의 일 실시예에 따른 아바타 3D 모델을 생성하는 방법을 설명하기 위한 도면이다. 도 18은 본 개시의 일 실시예에 따른 인테리어 3D 모델을 생성하는 방법을 설명하기 위한 도면이다. 도 19a는 본 개시의 일 실시예에 따른 공간 맵을 설명하기 위한 흐름도이다. 도 19b는 본 개시의 일 실시예에 따른 공간 맵을 설명하기 위한 흐름도이다. 도 20a는 본 개시의 일 실시예에 따른 공간 맵을 구성하는 레이어를 활용하는 방식을 설명하기 위한 도면이다. 도 20b는 본 개시의 일 실시예에 따른 공간 맵을 구성하는 레이어를 활용하는 방식을 설명하기 위한 도면이다. 도 20c는 본 개시의 일 실시예에 따른 공간 맵을 구성하는 레이어를 활용하는 방식을 설명하기 위한 도면이다. 도 20d는 본 개시의 일 실시예에 따른 공간 맵을 구성하는 레이어를 활용하는 방식을 설명하기 위한 도면이다."}
