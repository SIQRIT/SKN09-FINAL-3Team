{"patent_id": "10-2023-0096716", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2025-0015375", "출원번호": "10-2023-0096716", "발명의 명칭": "인공지능 모델을 통해 생성된 의류 디자인 이미지를 다른 이미지에 합성하는 시스템", "출원인": "이태연", "발명자": "이태연"}}
{"patent_id": "10-2023-0096716", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "시스템에 있어서:서버; 및사용자 단말을 포함하고,상기 서버는:프로세서;텍스트, 및 이미지 중 적어도 하나에 기초하여 의류 이미지를 생성하도록 학습된 제1 인공지능 모델, 및 합성대상인 이미지에 포함된 오브젝트에 상기 의류 이미지를 합성하도록 학습된 제2 인공지능 모델이 저장된메모리; 및통신모듈을 포함하고,상기 메모리는 상기 프로세서로 하여금 이하의 이미지 생성 단계들을 수행하기 위한 명령들을 포함하며, 상기이미지 생성 단계들은:상기 사용자 단말로부터 제1 텍스트, 및 제1 이미지 중 적어도 하나를 포함하는 제1 요청 데이터를 수신하여,상기 제1 요청 데이터를 상기 제1 인공지능 모델에 입력하는 단계;상기 사용자 단말로부터 제2 텍스트, 및 제2 이미지 중 적어도 하나를 포함하는 제2 요청 데이터를 수신하여,상기 제1 인공지능 모델로부터 획득된 제1 결과 데이터, 및 상기 제2 요청 데이터를 상기 제2 인공지능 모델에입력하는 단계; 및상기 제2 인공지능으로부터 획득된 제2 결과 데이터를 상기 사용자 단말로 전송하는 단계를 포함하고,상기 제1 텍스트는, 의류 디자인에 대한 적어도 하나의 키워드이고,상기 제2 텍스트는, 상기 제2 이미지에 포함된, 합성 대상인 오브젝트에 대한 적어도 하나의 키워드인,시스템."}
{"patent_id": "10-2023-0096716", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 제1 인공지능 모델은:의류를 착용한 피사체를 오브젝트로 포함하는 이미지, 의류를 오브젝트로 포함하는 이미지, 및 의류에 매칭되는텍스트 정보 중 적어도 하나를 포함하는 학습 데이터에 기초하여, 상기 의류 이미지를 생성하도록 학습된 인공지능 모델인,시스템."}
{"patent_id": "10-2023-0096716", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 제2 인공지능 모델은:상기 의류 이미지, 합성 대상인 오브젝트에 매칭되는 텍스트, 및 합성 대상인 오브젝트를 포함하는 이미지 중적어도 하나를 포함하는 학습 데이터에 기초하여, 상기 의류 이미지가 합성된 상기 합성 대상인 오브젝트를 포함하는 이미지를 생성하도록 학습된 인공지능 모델인,공개특허 10-2025-0015375-3-시스템."}
{"patent_id": "10-2023-0096716", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,상기 이미지 생성 단계들은:상기 제2 요청 데이터를 수신하면, 상기 제2 이미지에 포함된 적어도 하나의 제1 오브젝트를 식별하는 단계;상기 제2 텍스트에 기초하여, 상기 제1 오브젝트 중, 합성 대상인 제2 오브젝트를 식별하는 단계; 및상기 제2 요청 데이터 중, 상기 제2 이미지를 상기 제2 오브젝트로 변경하는 단계를 포함하는,시스템."}
{"patent_id": "10-2023-0096716", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서,상기 이미지 생성 단계들은:상기 제2 결과 데이터를 획득하면, 상기 제1 오브젝트 중, 상기 제2 오브젝트를 제외한, 제3 오브젝트를 식별하는 단계;상기 제3 오브젝트 중 적어도 하나가, 상기 제2 오브젝트의 앞에 위치하는 것으로 식별되면, 상기 제3 오브젝트를 상기 제2 결과 데이터에 따른 합성 이미지에 오버랩한, 제1 합성 이미지를 생성하는 단계;상기 제1 합성 이미지를 상기 제2 이미지에 오버랩한, 제2 합성 이미지를 생성하는 단계; 및상기 제2 합성 이미지를 상기 사용자 단말로 전송하는 단계를 포함하는,시스템."}
{"patent_id": "10-2023-0096716", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5항에 있어서,상기 이미지 생성 단계들은:상기 제3 오브젝트, 및 상기 제2 오브젝트 간의 위치 관계를 식별함에 있어서, 상기 제2 오브젝트에 대한 적어도 하나의 관절 위치를 식별하는 단계;상기 관절 위치, 및 기 설정된 복수의 신체 특징점에 기초하여, 상기 제2 오브젝트의 신체 특징점을 식별하는단계;상기 제2 오브젝트의 신체 특징점의 개수가 상기 기 설정된 복수의 신체 특징점의 개수와 불일치하는 경우, 상기 제3 오브젝트 중 적어도 하나가, 상기 제2 오브젝트의 앞에 위치하는 것으로 판단하고, 상기 제2 오브젝트의신체 특징점의 개수가 상기 기 설정된 복수의 신체 특징점의 개수와 일치하는 경우, 상기 제2 오브젝트의 경계선 좌표를 식별하는 단계;상기 관절 위치, 및 상기 제2 오브젝트의 신체 특징점에 기초하여, 상기 제2 오브젝트의 뼈대 이미지를 생성하는 단계; 및상기 뼈대 이미지로부터 상기 경계선 좌표까지의 거리에 기초하여, 상기 제3 오브젝트에 의해 상기 제2 오브젝트의 일부 영역이 미획득된 것으로 판단되면, 상기 제3 오브젝트 중 적어도 하나가, 상기 제2 오브젝트의 앞에위치하는 것으로 판단하는 단계를 포함하는,시스템."}
{"patent_id": "10-2023-0096716", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제4항에 있어서,상기 이미지 생성 단계들은:공개특허 10-2025-0015375-4-상기 제2 오브젝트가 사람 이외의 동물인 경우, 상기 제2 오브젝트에 포함된 색상 데이터를 획득하는 단계;상기 색상 데이터에 기초하여, 상기 제2 오브젝트의 경계선 좌표를 생성하는 단계;상기 제1 결과 데이터에 기초하여, 상기 경계선 좌표 중, 합성되는 영역을 선택하는 단계;상기 선택된 영역에 기초하여, 상기 경계선 좌표를 편집한 제4 오브젝트를 생성하는 단계; 및상기 제4 오브젝트에 기초하여, 상기 제2 요청 데이터를 편집하는 단계를 포함하는,시스템."}
{"patent_id": "10-2023-0096716", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1항에 있어서,상기 메모리는 상기 프로세서로 하여금 이하의 텍스트 추가 단계들을 수행하기 위한 명령들을 포함하며, 상기텍스트 추가 단계들은:상기 사용자 단말에 대해 기 등록된 합성 이미지 수신 이력에 대한 사용자 데이터를 식별하는 단계;상기 사용자 데이터에 기초하여, 선호 데이터, 및 비선호 데이터를 식별하는 단계;상기 선호 데이터에 기초하여, 상기 제1 텍스트에 매칭되는 적어도 하나의 디자인 데이터를 식별하는 단계;상기 디자인 데이터에 매칭되는 적어도 하나의 유사 키워드를 식별하는 단계;상기 비선호 데이터에 기초하여, 상기 유사 키워드 중, 추가 키워드를 선택하는 단계; 및상기 추가 키워드가 적어도 하나 선택되면, 상기 선택된 추가 키워드를 상기 제1 요청 데이터에 포함시키는 단계를 포함하는,시스템."}
{"patent_id": "10-2023-0096716", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 인공지능모델을 통해 생성된 의류 디자인 이미지를 다른 이미지에 합성하는 시스템에 관한 것으로, 본 원의 다양한 실시예에 따른 시스템에 있어서, 서버, 및 사용자 단말을 포함하고, 상기 서버는, 프로세서, 텍스트, 및 이미지 중 적어도 하나에 기초하여 의류 이미지를 생성하도록 학습된 제1 인공지능 모델, 및 합성 대 상인 이미지에 포함된 오브젝트에 상기 의류 이미지를 합성하도록 학습된 제2 인공지능 모델이 저장된 메모리, 및 통신모듈을 포함한다."}
{"patent_id": "10-2023-0096716", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 인공지능 모델을 통해 생성된 의류 디자인 이미지를 다른 이미지에 합성하는 시스템에 대한 것으로, 상세하게는, 입력된 텍스트와 이미지에 기초하여 생성된 의류 디자인을, 다른 이미지에 포함된, 지정된 오브젝 트에 합성하여 제공하는 기술이다."}
{"patent_id": "10-2023-0096716", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "개인의 개성이 중요시되는 흐름에서, 자신만의 개성을 살려서 의복, 신발, 액세서리등의 물품을 커스터마이징하 는 과정, 및 물품의 제작 과정에 소비자가 직접 참여하는 서비스가 인기를 끌고 있다. 한편, 자신만의 개성을 표현하는데 서툰 소비자들의 경우, 완성도 높은 나만의 물품을 생산하는데 있어 전문가 의 대면 도움이 필요한 현실이나, 핸드메이드 클래스의 경우, 오프라인 상에서의 만남에 필요한 시공간적 제약 과 더불어 수업료에 의한 비용적 부담 또한 존재해서 쉽게 접근하기 어렵다. 또한, 원하는 종목의 수업을 진행하는 업자와의 물리적 거리로 인해, 이동시간에 대한 부담이 존재한다. 본원은 다양한 실시예를 통해, 이러한 소비자들의 개성을 표출하고자 하는 욕구를, 원하는 정보(ex. 패션 분야, 참고할 디자인, 색상 등을 나타내는 이미지, 문자 등)만 제공하면 온라인 상에서 손쉽게 디자인을 제작하여, 제 작된 디자인의 의류를 착용한 사진을 합성해주는 서비스를 통해 해소하고자 한다."}
{"patent_id": "10-2023-0096716", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 2, "content": "한편, 상기의 배경기술로서 설명된 사항들은 본원의 배경에 대한 이해 증진을 위한 것일 뿐, 이 기술분야에서"}
{"patent_id": "10-2023-0096716", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 3, "content": "통상의 지식을 가진 자에게 이미 알려진 종래기술에 해당함을 인정하는 것으로 받아들여져서는 안 될 것이다.발명의 내용"}
{"patent_id": "10-2023-0096716", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본원은 전술한 문제를 해결하기 위한 것으로, 인공지능모델을 통해 생성된 의류 디자인 이미지를 다른 이미지에 합성하는 시스템을 제공하는 것을 목적으로 한다. 본원이 해결하고자 하는 과제들은 이상에서 언급된 과제로 제한되지 않으며, 언급되지 않은 또 다른 과제들은 아래의 기재로부터 통상의 기술자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2023-0096716", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본원의 다양한 실시예에 따른 시스템에 있어서, 서버, 및 사용자 단말을 포함하고, 상기 서버는, 프로세서, 텍 스트, 및 이미지 중 적어도 하나에 기초하여 의류 이미지를 생성하도록 학습된 제1 인공지능 모델, 및 합성 대 상인 이미지에 포함된 오브젝트에 상기 의류 이미지를 합성하도록 학습된 제2 인공지능 모델이 저장된 메모리, 및 통신모듈을 포함하고, 상기 메모리는 상기 프로세서로 하여금 이하의 이미지 생성 단계들을 수행하기 위한 명령들을 포함하며, 상기 이미지 생성 단계들은, 상기 사용자 단말로부터 제1 텍스트, 및 제1 이미지 중 적어도 하나를 포함하는 제1 요청 데이터를 수신하여, 상기 제1 요청 데이터를 상기 제1 인공지능 모델에 입력하는 단 계, 상기 사용자 단말로부터 제2 텍스트, 및 제2 이미지 중 적어도 하나를 포함하는 제2 요청 데이터를 수신하 여, 상기 제1 인공지능 모델로부터 획득된 제1 결과 데이터, 및 상기 제2 요청 데이터를 상기 제2 인공지능 모 델에 입력하는 단계, 및 상기 제2 인공지능으로부터 획득된 제2 결과 데이터를 상기 사용자 단말로 전송하는 단 계를 포함하고, 상기 제1 텍스트는, 의류 디자인에 대한 적어도 하나의 키워드이고, 상기 제2 텍스트는, 상기 제2 이미지에 포함된, 합성 대상인 오브젝트에 대한 적어도 하나의 키워드이다. 본원의 다양한 실시예에 따른 상기 제1 인공지능 모델은, 의류를 착용한 피사체를 오브젝트로 포함하는 이미지, 의류를 오브젝트로 포함하는 이미지, 및 의류에 매칭되는 텍스트 정보 중 적어도 하나를 포함하는 학습 데이터 에 기초하여, 상기 의류 이미지를 생성하도록 학습된 인공지능 모델일 수 있다. 본원의 다양한 실시예에 따른 상기 제2 인공지능 모델은, 상기 의류 이미지, 합성 대상인 오브젝트에 매칭되는 텍스트, 및 합성 대상인 오브젝트를 포함하는 이미지 중 적어도 하나를 포함하는 학습 데이터에 기초하여, 상기 의류 이미지가 합성된 상기 합성 대상인 오브젝트를 포함하는 이미지를 생성하도록 학습된 인공지능 모델일 수 있다. 본원의 다양한 실시예에 따른 상기 이미지 생성 단계들은, 상기 제2 요청 데이터를 수신하면, 상기 제2 이미지 에 포함된 적어도 하나의 제1 오브젝트를 식별하는 단계, 상기 제2 텍스트에 기초하여, 상기 제1 오브젝트 중, 합성 대상인 제2 오브젝트를 식별하는 단계, 및 상기 제2 요청 데이터 중, 상기 제2 이미지를 상기 제2 오브젝 트로 변경하는 단계를 포함할 수 있다. 본원의 다양한 실시예에 따른 상기 이미지 생성 단계들은, 상기 제2 결과 데이터를 획득하면, 상기 제1 오브젝 트 중, 상기 제2 오브젝트를 제외한, 제3 오브젝트를 식별하는 단계, 상기 제3 오브젝트 중 적어도 하나가, 상 기 제2 오브젝트의 앞에 위치하는 것으로 식별되면, 상기 제3 오브젝트를 상기 제2 결과 데이터에 따른 합성 이 미지에 오버랩한, 제1 합성 이미지를 생성하는 단계, 상기 제1 합성 이미지를 상기 제2 이미지에 오버랩한, 제2 합성 이미지를 생성하는 단계, 및 상기 제2 합성 이미지를 상기 사용자 단말로 전송하는 단계를 포함할 수 있다. 본원의 다양한 실시예에 따른 상기 이미지 생성 단계들은, 상기 제3 오브젝트, 및 상기 제2 오브젝트 간의 위치 관계를 식별함에 있어서, 상기 제2 오브젝트에 대한 적어도 하나의 관절 위치를 식별하는 단계, 상기 관절 위치, 및 기 설정된 복수의 신체 특징점에 기초하여, 상기 제2 오브젝트의 신체 특징점을 식별하는 단계, 상기 제2 오브젝트의 신체 특징점의 개수가 상기 기 설정된 복수의 신체 특징점의 개수와 불일치하는 경우, 상기 제3 오브젝트 중 적어도 하나가, 상기 제2 오브젝트의 앞에 위치하는 것으로 판단하고, 상기 제2 오브젝트의 신체 특징점의 개수가 상기 기 설정된 복수의 신체 특징점의 개수와 일치하는 경우, 상기 제2 오브젝트의 경계선 좌 표를 식별하는 단계, 상기 관절 위치, 및 상기 제2 오브젝트의 신체 특징점에 기초하여, 상기 제2 오브젝트의 뼈대 이미지를 생성하는 단계, 및 상기 뼈대 이미지로부터 상기 경계선 좌표까지의 거리에 기초하여, 상기 제3 오브젝트에 의해 상기 제2 오브젝트의 일부 영역이 미획득된 것으로 판단되면, 상기 제3 오브젝트 중 적어도 하나가, 상기 제2 오브젝트의 앞에 위치하는 것으로 판단하는 단계를 포함할 수 있다. 본원의 다양한 실시예에 따른 상기 이미지 생성 단계들은, 상기 제2 오브젝트가 사람 이외의 동물인 경우, 상기 제2 오브젝트에 포함된 색상 데이터를 획득하는 단계, 상기 색상 데이터에 기초하여, 상기 제2 오브젝트의 경계 선 좌표를 생성하는 단계, 상기 제1 결과 데이터에 기초하여, 상기 경계선 좌표 중, 합성되는 영역을 선택하는 단계, 상기 선택된 영역에 기초하여, 상기 경계선 좌표를 편집한 제4 오브젝트를 생성하는 단계, 및 상기 제4 오브젝트에 기초하여, 상기 제2 요청 데이터를 편집하는 단계를 포함할 수 있다. 본원의 다양한 실시예에 따른 상기 메모리는 상기 프로세서로 하여금 이하의 텍스트 추가 단계들을 수행하기 위 한 명령들을 포함하며, 상기 텍스트 추가 단계들은, 상기 사용자 단말에 대해 기 등록된 합성 이미지 수신 이력 에 대한 사용자 데이터를 식별하는 단계, 상기 사용자 데이터에 기초하여, 선호 데이터, 및 비선호 데이터를 식 별하는 단계, 상기 선호 데이터에 기초하여, 상기 제1 텍스트에 매칭되는 적어도 하나의 디자인 데이터를 식별 하는 단계, 상기 디자인 데이터에 매칭되는 적어도 하나의 유사 키워드를 식별하는 단계, 상기 비선호 데이터에 기초하여, 상기 유사 키워드 중, 추가 키워드를 선택하는 단계, 및 상기 추가 키워드가 적어도 하나 선택되면, 상기 선택된 추가 키워드를 상기 제1 요청 데이터에 포함시키는 단계를 포함할 수 있다. 본원의 기타 구체적인 사항들은 상세한 설명 및 도면들에 포함되어 있다."}
{"patent_id": "10-2023-0096716", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "다양한 실시예들이 이제 도면을 참조하여 설명된다. 본 명세서에서, 다양한 설명들이 본원의 이해를 제공하기 위해서 제시된다. 그러나, 이러한 실시예들은 이러한 구체적인 설명 없이도 실행될 수 있음이 명백하다. 본 명세서에서 사용되는 용어 \"컴포넌트\", \"모듈\", \"시스템\" 등은 컴퓨터-관련 엔티티, 하드웨어, 펌웨어, 소프 트웨어, 소프트웨어 및 하드웨어의 조합, 또는 소프트웨어의 실행을 지칭한다. 예를 들어, 컴포넌트는 프로세서 상에서 실행되는 처리과정(procedure), 프로세서, 객체, 실행 스레드, 프로그램, 및/또는 컴퓨터일 수 있지만, 이들로 제한되는 것은 아니다. 예를 들어, 전자 장치에서 실행되는 애플리케이션 및 전자 장치 모두 컴포넌트일 수 있다. 하나 이상의 컴포넌트는 프로세서 및/또는 실행 스레드 내에 상주할 수 있다. 일 컴포넌트는 하나의 컴퓨터 내에 로컬화 될 수 있다. 일 컴포넌트는 2개 이상의 컴퓨터들 사이에 분배될 수 있다. 또한, 이러한 컴포넌트들은 그 내부에 저장된 다양한 데이터 구조들을 갖는 다양한 컴퓨터 판독가능한 매체로부터 실행할 수 있 다. 컴포넌트들은 예를 들어 하나 이상의 데이터 패킷들을 갖는 신호(예를 들면, 로컬 시스템, 분산 시스 템에 서 다른 컴포넌트와 상호작용하는 하나의 컴포넌트로부터의 데이터 및/또는 신호를 통해 다른 시스템과 인터넷 과 같은 네트워크를 통해 전송되는 데이터)에 따라 로컬 및/또는 원격 처리들을 통해 통신할 수 있다. 더불어, 용어 \"또는\"은 배타적 \"또는\"이 아니라 내포적 \"또는\"을 의미하는 것으로 의도된다. 즉, 달리 특정되지 않거나 문맥상 명확하지 않은 경우에, \"X는 A 또는 B를 이용한다\"는 자연적인 내포적 치환 중 하나를 의미하는 것으로 의도된다. 즉, X가 A를 이용하거나; X가 B를 이용하거나; 또는 X가 A 및 B 모두를 이용하는 경우, \"X는 A 또는 B를 이용한다\"가 이들 경우들 어느 것으로도 적용될 수 있다. 또한, 본 명세서에 사용된 \"및/또는\"이라 는 용어는 열거된 관련 아이템들 중 하나 이상의 아이템의 가능한 모든 조합을 지칭하고 포함하는 것으로 이해 되어야 한다. 또한, \"포함한다\" 및/또는 \"포함하는\"이라는 용어는, 해당 특징 및/또는 구성요소가 존재함을 의미하는 것으로 이해되어야 한다. 다만, \"포함한다\" 및/또는 \"포함하는\"이라는 용어는, 하나 이상의 다른 특징, 구성요소 및/또 는 이들의 그룹의 존재 또는 추가를 배제하지 않는 것으로 이해되어야 한다. 또한, 달리 특정되지 않거나 단수 형태를 지시하는 것으로 문맥상 명확하지 않은 경우에, 본 명세서와 청구범위에서 단수는 일반적으로 \"하나 또 는 그 이상\"을 의미하는 것으로 해석되어야 한다. 그리고, \"A 또는 B 중 적어도 하나\"이라는 용어는, \"A만을 포함하는 경우\", \"B 만을 포함하는 경우\", \"A와 B의 구성으로 조합된 경우\"를 의미하는 것으로 해석되어야 한다. 당업자들은 추가적으로 여기서 개시된 실시예들과 관련되어 설명된 다양한 예시적 논리적 블록들, 구성들, 모듈 들, 회로들, 수단들, 로직들, 및 알고리즘 단계들이 전자 하드웨어, 컴퓨터 소프트웨어, 또는 양쪽 모두의 조합 들로 구현될 수 있음을 인식해야 한다. 하드웨어 및 소프트웨어의 상호교환성을 명백하게 예시하기 위해, 다양 한 예시적 컴포넌트들, 블록들, 구성들, 수단들, 로직들, 모듈들, 회로들, 및 단계들은 그들의 기능성 측면에서 일반적으로 위에서 설명되었다. 그러한 기능성이 하드웨어로 또는 소프트웨어로서 구현되는지 여부는 전반적인 시스템에 부과된 특정 어플리케이션(application) 및 설계 제한들에 달려 있다. 숙련된 기술자들은 각각의 특정 어플리케이션들을 위해 다양한 방법들로 설명된 기능성을 구현할 수 있다. 다만, 그러한 구현의 결정들이 본 개 시내용의 영역을 벗어나게 하는 것으로 해석되어서는 안 된다. 제시된 실시예들에 대한 설명은 본원의 기술 분야에서 통상의 지식을 가진 자가 본원을 이용하거나 또는 실시할 수 있도록 제공된다. 이러한 실시예들에 대한 다양한 변형들은 본원의 기술 분야에서 통상의 지식을 가진 자에 게 명백할 것이다. 여기에 정의된 일반적인 원리들은 본원의 범위를 벗어남이 없이 다른 실시예들에 적용될 수 있다. 그리하여, 본원은 여기에 제시된 실시예 들로 한정되는 것이 아니다. 본원은 여기에 제시된 원리들 및 신 규한 특징들과 일관되는 최광의의 범위에서 해석되어야 할 것이다. 본원에서 네트워크 함수와 인공 신경망 및 뉴럴 네트워크(neural network)는 상호교환 가능하게 사용될 수 있다. 여기에 설명되는 다양한 실시예는 예를 들어, 소프트웨어, 하드웨어 또는 이들의 조합된 것을 이용하여 컴퓨터 또는 이와 유사한 장치로 읽을 수 있는 기록매체 및 저장매체 내에서 구현될 수 있다. 하드웨어적인 구현에 의하면, 여기에 설명되는 실시예는 ASICs (application specific integrated circuits), DSPs (digital signal processors), DSPDs (digital signal processing devices), PLDs (programmable logic devices), FPGAs (field programmable gate arrays, 프로세서(processors), 제어기(controllers), 마이크로 컨 트롤러(micro-controllers), 마이크로 프로세서(microprocessors), 기타 기능 수행을 위한 전기적인 유닛 중 적어도 하나를 이용하여 구현될 수 있다. 일부의 경우에 본 명세서에서 설명되는 실시예들이 전자 장치의 프로 세서 자체로 구현될 수 있다. 도 1은 본원의 실시예에 따른 시스템 구성도이고, 도 2는 본원의 실시예에 따른 서버 구성도이고, 도 3은 본원 의 실시예에 따른 이미지 생성 단계 흐름도이고, 도 4는 본원의 실시예에서 참조되는, 제1 인공지능 모델의 제1 결과 데이터 생성 프로세스를 설명하기 위한 개념도이고, 도 5는 본원의 실시예에 따른 학습된 조건 기반의 디 자인 생성 방법의 흐름도이고, 도 6은 본원의 실시예에 따른 제1 이미지, 및 제1 텍스트 간 매칭 방법의 흐름도 이고, 도 7은 본원의 실시예에서 참조되는, 제1 인공지능 모델의 이미지와 텍스트 쌍(Pair)의 학습 방법 예시도 이고, 도 8은 본원의 실시예에서 참조되는, 제1 인공지능 모델의 트렌드 단어의 선정 프로세스 예시도이고, 도9는 본원의 실시예에서 참조되는, 사용자 단말을 통해 표시된 사용자 인터페이스의 예시도이고, 도 10은 본원의 실시예에서 참조되는, 사용자 단말을 통해 표시된 제2 결과 데이터의 예시도이다. 도 1에 도시된 바와 같이, 본원의 다양한 실시예에 따른 시스템은, 서버, 및 사용자 단말을 포함한다. 도 2에 도시된 바와 같이, 서버는, 프로세서, 텍스트, 및 이미지 중 적어도 하나에 기초하여 의류 이 미지를 생성하도록 학습된 제1 인공지능 모델, 및 합성 대상인 이미지에 포함된 오브젝트에 의류 이미지를 합성하도록 학습된 제2 인공지능 모델이 저장된 메모리, 및 통신모듈을 포함한다. 사용자 단말은 사용자의 모바일 단말, 랩탑, 또는 데스크탑 등 다양한 전자 장치를 포함할 수 있다. 도2에 도시된 서버의 구성은 간략화하여 나타낸 예시일 뿐이다. 본원의 일 실시예에서 서버(10 0)는 서버의 컴퓨팅 환경을 수행하기 위한 다른 구성들이 포함될 수 있고, 개시된 구성들 중 일부만이 서버를 구성할 수도 있다. 서버는 프로세서, 메모리, 및 통신모듈을 포함할 수 있다. 프로세서는 하나 이상의 코어로 구성될 수 있으며, 서버의 중앙 처리 장치(CPU: Central Processing Unit), 범용 그래픽 처리 장치 (GPGPU: General Purpose Graphics Processing Uni t), 텐서 처리 장치(TPU: Tensor Processing Unit) 등의 데이터 분석, 딥러닝을 위한 프로세서(11 0)를 포함할 수 있다. 프로세서는 메모리에 저장된 컴퓨터 프로그램을 판독하여 본원의 일 실시예에 따른 기계 학습을 위한 데이터 처리를 수행할 수 있다. 또한, 프로세서는 서버 의 구성이 동작하도록 제어하며, 전반적인 시스템의 동작을 구현할 수 있다. 예를 들어, 프로세서는 통상적으로 서버의 전반적인 동작을 제어할 수 있다. 프로세서는 위에서 살펴본 구성요소들을 통해 입력 또는 출력되는 신호, 데이터, 정보 등을 처리하거나 메모리에 저장된 응용 프로그램을 구동함으로써, 사용자에게 적절한 정보 또는 기능을 제공 또는 처리할 수 있다. 또한, 프로세서는 메모리에 저장된 응용 프로그램을 구동하기 위하여, 서버의 구성요소들 중 적 어도 일부를 제어할 수 있다. 나아가, 프로세서는 상기 응용 프로그램의 구동을 위하여, 서버에 포함 된 구성요소들 중 적어도 둘 이상을 서로 조합하여 동작시킬 수 있다. 본원의 일실시예에 따라 프로세서는 신경망의 학습을 위한 연산을 수행할 수 있다. 프로세서(1 10)는 딥러닝(DL: deep learning)에서 학습을 위한 입력 데이터의 처리, 입력 데이터에서의 피처 추출, 오차 계산, 역전파(backpropagation)를 이용한 신경망의 가중치 업데이트 등의 신경망의 학습 을 위한 계산을 수행할 수 있다. 프로세서의 CPU, GPGPU, 및 TPU 중 적어도 하나가 네트워 크 함수의 학습을 처리할 수 있다. 예를 들어, CPU 와 GPGPU가 함께 네트워크 함수의 학습, 네 트워크 함수를 이용한 데이터 분류를 처리할 수 있다. 사용자 단말은, 프로세서, 메모리, 통신모듈, 및 디스플레이로 구성될 수 있다. 프로세서 , 메모리, 통신모듈에 대한 설명은 도 2에서 자세히 하였으므로, 생략하기로 한다. 디스플레이 는 다양한 디스플레이를 포함할 수 있고, 터치 스크린 디스플레이를 포함할 수 있다. 도 3에 도시된 바와 같이, 메모리는 프로세서로 하여금 이하의 이미지 생성 단계들을 수행하기 위한 명령들을 포함하며, 이미지 생성 단계들을 수행함에 있어, 서버는, 사용자 단말로부터 제1 텍스트 , 및 제1 이미지 중 적어도 하나를 포함하는 제1 요청 데이터를 수신하여, 제1 요청 데이터를 제1 인공지능 모델에 입력(S310)한다. 이에 따라, 서버는, 제1 인공지능 모델로부터, 도 4에 도시된 바와 같이, 적어도 하나의 의류 디자인 이미지로 구성된, 제1 결과 데이터를 획득하고, 사용자 단말로부터 제2 텍스트, 및 제2 이미지 중 적어도하나를 포함하는 제2 요청 데이터를 수신하여, 제1 인공지능 모델로부터 획득된 제1 결과 데이터, 및 제2 요청 데이터를 제2 인공지능 모델에 입력(S320)한다. 이후, 서버는, 제2 인공지능으로부터 획득된 제2 결과 데이터를 사용자 단말로 전송(S330)한다. 제2 결과 데이터는, 도 10에 도시된 바와 같이, 제2 이미지에 포함된 제1 오브젝트 중, 제2 텍스트에 기초하여 지정된 제2 오브젝트에 제1 결과 데이터가 합성된, 적어도 하나의 합성 이미지로 구성될 수 있다. 이때, 서버에의해, 제1 결과 데이터를 구성하는 의류 디자인 이미지의 수에 비례하는 수만큼의 합성 이미 지가 생성될 수 있다. 이때, 제1 텍스트는, 의류 디자인에 대한 적어도 하나의 키워드이고, 제2 텍스트는, 제2 이미지에 포함된, 합성 대상인 오브젝트에 대한 적어도 하나의 키워드이다. 예컨대, 제1 텍스트는, 도 4에 도시된 바와 같이, Coat, Jacket, Long sleeve, black, down coat, zip-up, pockets, no print 등 적어도 하나의 키워드로 구성될 수 있고, 도시되지는 않았으나, 제2 텍스트는, 오른쪽에 서 두 번째, 여성, 소녀, 갈색 머리카락, 블랙진, 화이트셔츠, 블로퍼 등 적어도 하나의 키워드될 수 있다. 한편, 도시되지는 않았으나, 본원의 다양한 실시예에 따른 메모리는 프로세서로 하여금 이하의 텍스 트 추가 단계들을 수행하기 위한 명령들을 포함할 수 있으며, 이에 따라, 텍스트 추가 단계들을 수행함에 있어 서, 서버는, 사용자 단말에 대해 기 등록된 합성 이미지 수신 이력에 대한 사용자 데이터를 식별할 수 있다. 서버는, 사용자 데이터에 기초하여, 선호 데이터, 및 비선호 데이터를 식별하고, 선호 데이터에 기초하여, 제1 텍스트에 매칭되는 적어도 하나의 디자인 데이터를 식별할 수 있다. 이에 따라, 서버는, 디자인 데이터에 매칭되는 적어도 하나의 유사 키워드를 식별하고, 비선호 데이터에 기초하여, 유사 키워드 중, 추가 키워드를 선택하여, 추가 키워드가 적어도 하나 선택되면, 선택된 추가 키워드 를 제1 요청 데이터에 포함시킬 수 있다. 텍스트 추가 단계들은, 단계 S310의 하위 단계일 수 있다. 실시예로, 서버는, 선호 데이터, 및 비선호 데이터를 식별함에 있어서, 단계 S330을 수행한 이후, 제2 결 과 데이터에 대해 사용자 단말로부터 반응 데이터를 수신할 수 있다. 반응 데이터는, 제2 결과 데이터에 포함된 적어도 하나의 합성 이미지 각각에 대해 사용자 단말이 수신한 사용자 입력에 따른 선호 이미지 또는 비선호 이미지로의 분류 결과일 수 있다. 서버는, 반응 데이터에 기초하여, 선호 이미지, 및 비선호 이미지를 각각 식별하고, 선호 이미지에 매칭되 는 제1 텍스트의 키워드, 및 추가 키워드를 선호 이미지와 함께 선호 데이터로 저장할 수 있다. 또한, 서버는, 비선호 이미지에 매칭되는 제1 텍스트의 키워드, 및 추가 키워드를 비선호 이미지와 함께 비선호 데이터로 저장할 수 있다. 이때, 서버는, 선호 데이터, 및 비선호 데이터를 비교하여, 텍스트, 및 이미지 중 적어도 하나의 일치하는, 중복 데이터가 식별되면, 중복 데이터를 별도로 저장할 수 있다. 이후, 서버는, 사용자 단말로부터 의류 디자인 생성을 요청하는, 제3 이미지(제1 이미지에 대응), 및 제3 텍스트(제1 텍스트에 대응) 중 적어도 하나를 포함하는, 제3 요청 데이터(제1 요청 데이터에 대응)를 수신 한 경우, 단계 S310을 수행하기 위해, 제3 요청 데이터를 제1 인공지능 모델에 입력하여, 제1 인공지능 모 델로부터 제3 요청 데이터에 따른 제3 결과 데이터(제1 결과 데이터에 대응)를 획득할 수 있다. 이때, 서버는, 도시되지는 않았으나, 제3 결과 데이터를 메모리에 저장된 제3 인공지능 모델에 입력 하여, 제3 인공지능 모델로부터, 사용자 개인의 선호도에 맞는 이미지만으로 구성된 제4 결과 데이터를 획득할 수 있다. 이후, 서버는, 제4 결과 데이터로 제3 결과 데이터를 대체하여 제2 인공지능 모델에 입력하여, 단계 S330을 수행할 수 있다. 이때, 제3 인공지능 모델은, 의류 이미지, 비선호 데이터, 및 중복 데이터 중 적어도 하나를 포함하는 학습 데 이터에 기초하여, 비선호 데이터 및 중복 데이터에 대해 의류 이미지를 군집화하여, 중복 데이터와 비선호 데이 터의 중앙에 위치하거나, 중복 데이터에 가까운 이미지, 및 비선호 데이터에 포함되지 않는 이미지를 출력하도 록 학습된 인공지능 모델일 수 있다. 한편, 본원의 다양한 실시예에 따른 제1 인공지능 모델은, 의류를 착용한 피사체를 오브젝트로 포함하는 이미지, 의류를 오브젝트로 포함하는 이미지, 및 의류에 매칭되는 텍스트 정보 중 적어도 하나를 포함하는 학습 데이터에 기초하여, 의류 이미지를 생성하도록 학습된 인공지능 모델일 수 있다. 한편, 도 5 및 도 6에 도시된 바와 같이, 서버는 제1 요청 데이터를 획득(S510)하면, 획득된 제1 이미 지로부터 트렌드 단어에 해당하는 적어도 하나의 키워드를 포함하는 텍스트를 추출하여, 추출된 텍스트를 제1 이미지에 매칭할 수 있다. 서버는, 제1 인공지능 모델이 학습됨에 따라 분석된, 원피스의 적어도 일부를 구성하는 디자인 특징 에 대하여, 높은 빈도로 추출되는 텍스트를 추출할 수 있다. 예를 들어, 서버는 학습된 다양한 문서에서 원피스 이미지와 이에 매칭되는 키워드 \"도트\"가 높은 빈도로 추출되는 경우, 원피스 이미지 상의 디자인 요소가 \"도트\"인 것으로 해석할 수 있다. 이에 따라, 제1 이미지의 원피스와 관련하여 \"도트\"라는 키워드가 매칭될 수 있다. 본 발명의 실시예는, 크롤링, 스크래핑 및/또는 파싱의 대상이 되는 문서에서 획득된 이미지와 추출된 텍스트 쌍에 대한 학습 결과, 미리 설정된 기준 횟수 이상의 추출 빈도를 보이는 단어를 식별하고, 이를 트렌드 단어로 결정할 수 있다. 단계 S520의 하위 단계로써, 서버는 단계 S610의 학습 과정에서 트렌드 단어의 추출이 이뤄지는지 판단 (S620)할 수 있다. 트렌드 단어가 존재하고, 추출된 경우, 서버는 트렌드 단어와 이미지 쌍에 대한 학습(S630)을 수행할 수 있다. 예를 들어, 도 1의 제1 요청 데이터와 유사한 페이지에 대한 크롤링이 다수 이뤄지거나, 파싱 결과 상기 페 이지 상의 제1 이미지가 다수 획득된 다면, 웹 페이지 상에 도트 무늬의 원피스 정보량이 많기 때문일 수 있다. 이는, 원피스 디자인 중, 도트 무늬의 디자인에 대한 제작 및 판매 증가, 소비자 관심 증가 등 트렌드 반영에 의한 결과일 수 있다. 이 경우, 키워드 \"도트\"는 페이지 상의 제품 설명 또는 사용자 후기 등의 기재 상에서 빈번히 등장할 것이며, 텍스트 추출 시, 높은 순위의 추출 횟수로 나타날 수 있다. 서버는 단계 S630에서, 획득된 원피스 이미지와 트렌드 단어인 \"도트\" 쌍을 학습할 수 있으며, 이 과정에 서 원피스 이미지 상의 도트 디자인 특징을 식별(S640)할 수 있다. 즉, \"도트\"에 대한 원피스 이미지는 도트 무늬가 디자인되어 있으므로, 학습 결과, 서버는 원피스의 디자 인 요소인 도트 무늬를 특징 정보로 식별하게 된다. 나아가, 서버는, 단계 S630의 학습을 통해, 도트 무늬 중, 도트의 배치, 도트의 개수, 도트의 면적(크기), 도트의 색상에 대한 특징을 식별할 수도 있다. 이를 통해, 도트 무늬의 원피스 중에서도 최신의 트렌드에 따른 디자인 특징 정보를 식별할 수 있다. 또 다른 실시예로, 서버는, 높은 순위의 추출 횟수뿐만 아니라, 추출 증가율이 높은 텍스트를 트렌드 단어 로 결정할 수도 있다. 한편, 단계 S620에서 트렌드 단어가 추출되지 않는 경우가 발생할 수 있다. 이는, 시장을 주도하는 디자인 트렌드가 형성되지 않았거나, 특정 제품의 디자인을 표현하는 용어가 정립되지 않은 경우일 수 있다.이와 같은 경우, 서버는, 트렌드 단어를 추출하는 기준을 조정(S650)할 수 있다. 일 예로, 서버는 텍스트의 추출에 대한 미리 설정된 기준 횟수를 변경할 수 있다. 다른 예로 서버는 추출 텍스트 간의 관계에 따라 트렌드 단어를 추출하도록 기준을 조정할 수도 있다. 예를 들어, 단독으로 추출되는 횟수는 낮으나, 추출되는 횟수가 상대적으로 높은 복수의 키워드가 존재하는 경 우, 서버는 복수의 키워드를 각각 트렌드 단어로 결정하고 추출할 수도 있다. 상기 예에서, 원피스의 무늬로 \"도트\"가 추출되는 횟수가 낮으나, \"도트\"와 \"물방울\"이 비교적 빈번하게 추출되 는 경우, 서버는 도트와 물방울이 동일한 디자인 특징을 표현하는 것으로 판단하고, 단계 S630의 학습을 수행할 수도 있다. 또 다른 예로, 서버는 단계 S610의 텍스트 이미지 쌍에 대한 학습량이 증가되도록 트렌드 단어의 추출 스 케줄을 조절함으로써, 트렌드 단어 추출 기준을 조정할 수도 있다. 단계 S640의 디자인 특징 정보 식별을 통해, 서버는 디자인의 특징 정보를 의미하는 텍스트를 디자인 생성 의 조건으로 학습할 수 있다. 서버는 생성의 대상이 되는 디자인에 대한 조건을 학습(S530)할 수 있다. 단계 S530의 학습을 통해, 서버는, 디자인의 카테고리를 생성할 수 있다. 예를 들어, 서버는, 원피스, 자켓, 바지 등과 같은 의류의 종류를 의미하는 텍스트를 식별하고, 상기 텍스 트를 카테고리로 생성할 수 있다. 또한, 서버는 의류의 종류에 속하는 세부 디자인 분류가 카테고리에 종속되는 것을 학습할 수 있다. 예를 들어, 서버는 도 1의 제1 이미지 상의 도트 무늬 원피스는, 카테고리 \"원피스\"에 속하는 것으로 학습할 수 있다. 이로써, 원피스 카테고리를 선택하고, \"도트\"가 식별되면, 서버는 제1 이미지 상의 도트 무늬 원피스 와 같은 디자인을 생성할 수 있다. 서버는 입력 텍스트에 대응하는 조건을 식별(S540)할 수 있다. 상기 예에서, \"도트\"가 식별되면, 서버 가 도트에 대응하는 디자인 조건을 식별할 수 있다. 즉, 서버는 \"도트\"가 속한 카테고리 및 텍스트에 대한 벡터 정보를 식별할 수 있다. 서버는 식별된 조건에 기반하여 디자인 셋을 생성(S550)할 수 있다. 이때, 생성된 디자인 셋이 사용자 단말로 전송되어, 사용자 단말의 디스플레이를 통해 출력될 수 있 으며, 도 6의 단계 S630에서 학습된 트렌드를 반영하여 표시되는 생성된 디자인이 위치하는 순서가 결정될 수 있다. 디자인 셋은 생성된 디자인을 포함하는 디자인 이미지의 그룹으로, 사용자 단말의 디스플레이 표시 영역, 또는 미리 설정된 사용자 인터페이스에 따라 화면에 표시되는 디자인 이미지의 개수가 결정될 수 있다. 서버는 생성된 디자인을 고해상도의 이미지로 변환(S560)할 수 있다. 이를 위해, 서버는 픽셀 기반의 유사도 아닌, 디자인 특징 정보의 유사도를 바탕으로 생성 디자인의 해상도를 변환할 수 있다. 한편, 본원의 다양한 실시예에 따른 제2 인공지능 모델은, 의류 이미지, 합성 대상인 오브젝트에 매칭되는 텍스트, 및 합성 대상인 오브젝트를 포함하는 이미지 중 적어도 하나를 포함하는 학습 데이터에 기초하여, 의류 이미지가 합성된 합성 대상인 오브젝트를 포함하는 이미지를 생성하도록 학습된 인공지능 모델일 수 있다. 이때, 제2 인공지능 모델은, 의류 이미지의 스케일을 오브젝트의 크기에 맞춰 편집하여 합성할 수 있다. 한편, 본원의 다양한 실시예에 따른 이미지 생성 단계들을 수행함에 있어서, 단계 S320에서, 서버는, 제2 요청 데이터를 수신하면, 제2 이미지에 포함된 적어도 하나의 제1 오브젝트를 식별할 수 있다. 이후, 서버는, 제2 텍스트에 기초하여, 제1 오브젝트 중, 합성 대상인 제2 오브젝트를 식별하고, 제2 요청 데이터 중, 제2 이미지를 제2 오브젝트로 변경할 수 있다.이에 따라, 제2 오브젝트에 따른 제2 결과 데이터를 획득하면, 서버는, 제1 오브젝트 중, 제2 오브젝트를 제외한, 제3 오브젝트를 식별할 수 있다. 제3 오브젝트 중 적어도 하나가, 제2 오브젝트의 앞에 위치하는 것으로 식별되면, 서버는, 제3 오브젝트를 제2 결과 데이터에 따른 합성 이미지에 오버랩한, 제1 합성 이미지를 생성하여, 제1 합성 이미지를 제2 이미지 에 오버랩한, 제2 합성 이미지를 생성함으로써, 제2 합성 이미지를 사용자 단말로 전송할 수 있다. 예컨대, 제2 오브젝트의 피사체인 A와, A와 카메라 렌즈 사이에 위치한, 제3 오브젝트의 피사체인 B가 식별된 경우, 서버는, A의 이미지에 드레스 이미지를 합성하고, 그 위에 B의 이미지를 오버랩하여, 실제로 B의 이 미지에 의해 가려지는 부분을 표현하고, 이를 원본인 이미지에 오버랩함으로써 실제 원근감과 위치 관계가 반영 된 합성 이미지를 생성할 수 있다. 이때, 제3 오브젝트, 및 제2 오브젝트 간의 위치 관계(제2 오브젝트와 카메라 렌즈 사이에 위치하는 제3 오브젝 트의 존재 여부)를 식별함에 있어서, 서버는, 제2 오브젝트에 대한 적어도 하나의 관절 위치를 식별할 수 있다. 서버는, 관절 위치, 및 기 설정된 복수의 신체 특징점에 기초하여, 제2 오브젝트의 신체 특징점을 식별하 고, 제2 오브젝트의 신체 특징점의 개수가 기 설정된 복수의 신체 특징점의 개수와 불일치하는 경우, 제3 오브 젝트 중 적어도 하나가, 제2 오브젝트의 앞에 위치하는 것으로 판단할 수 있다. 반면, 제2 오브젝트의 신체 특징점의 개수가 기 설정된 복수의 신체 특징점의 개수와 일치하는 경우, 서버(10 0)는, 제2 오브젝트의 경계선 좌표를 식별하고, 관절 위치, 및 제2 오브젝트의 신체 특징점에 기초하여, 제2 오 브젝트의 뼈대 이미지를 생성함으로써, 뼈대 이미지로부터 경계선 좌표까지의 거리에 기초하여, 제3 오브젝트에 의해 제2 오브젝트의 일부 영역이 미획득된 것으로 판단되면, 제3 오브젝트 중 적어도 하나가, 제2 오브젝트의 앞에 위치하는 것으로 판단할 수 있다. 한편, 본원의 다양한 실시예에 따른 이미지 생성 단계들을 수행함에 있어서, 제2 오브젝트가 사람 이외의 동물 인 경우, 서버는, 제2 요청 데이터에 기초하여, 제2 오브젝트에 포함된 색상 데이터를 획득할 수 있다. 이후, 서버는, 색상 데이터에 기초하여, 제2 오브젝트의 경계선 좌표를 생성하고, 제1 결과 데이터에 기초 하여, 경계선 좌표 중, 합성되는 영역을 선택할 수 있다. 이에 따라, 서버는, 선택된 영역에 기초하여, 경계선 좌표를 편집한 제4 오브젝트를 생성하고, 제4 오브젝 트에 기초하여, 제2 요청 데이터를 편집할 수 있다. 실시예로써, 서버는 제2 오브젝트의 경계선 좌표인 제1 라인, 및 합성되는 영역의 경계선 좌표인 제2 라인 을 비교하여, 제1 라인, 및 제2 라인의 교차점인, 복수의 제1 포인트를 식별할 수 있다. 서버는, 이웃하는 제1 포인트 사이의 제2 라인을 기준으로, 제1 라인을 구성하는 점 중, 제2 라인의 바깥 에 위치하는 점인 적어도 하나의 제2 포인트가 존재하는 경우, 제2 포인트의 안쪽에 위치하는 제2 라인의 점 중, 가장 가까운 점으로 변경함으로써, 경계선 좌표를 편집할 수 있다. 이에 따라, 서버는, 의류 이미지가 제2 오브젝트에 오버랩된 상태에서, 의류 바깥으로 털이 삐져나옴에 의 한 부자연스러운 합성 이미지를, 실제로 의류를 착장하여 의류 내측에 털이 수납된 것과 같은 형태인, 제4 오브 젝트로 편집하여, 사용자 단말의 사용자에게 자연스러운 합성 이미지를 제공할 수 있다. 한편, 도 7에 도시된 바와 같이, 서버는 다수의 이미지 셋를 획득할 수 있다. 서버는 도 1의 제 1 데이터와 같은 페이지 상의 이미지를 다수 획득하여, 이로부터 이미지 셋을 구축하고, 이를 디자인 의 특징 추출을 위한 이미지 학습 대상으로 결정할 수 있다. 서버는 이미지 셋 상의 이미지(701, 702, 703, 704)를 학습함에 따라, 원피스의 디자인 특징을 식별 할 수 있다. 서버는 상기 제1 요청 데이터에 기초하여 검색된 사이트에 대해, 페이지 상의 텍스트를 다수 추출할 수 있다. 상기 페이지가 블로그, 쇼핑몰과 같은 페이지로, 디자인 대상 제품에 대한 설명 정보가 존재하는 경우, 서버 는 설명 정보에서 텍스트를 추출하여 텍스트 셋을 생성할 수 있으며, 쇼핑몰의 후기 정보가 존 재하는 경우, 후기 정보 상에서도 텍스트를 추출할 수도 있다. 서버는 텍스트 셋과 후기 정보에서 추출된 텍스트 상에서 미리 설정된 기준 횟수 이상의 추출 텍스트를 식별할 수 있다. 도 7에서, 원피스(ONE PIECE), 드레스(DRESS, 원피스 드레스(ONE PIECE DRESS), 슬리브(Sleeve), 슬리브리스 (Sleeveless), 검정(Black), 검회색(Dark Gray), 면(Cotton), 린넨(Linen), AA 스타일(AA Style), AA 라인(AA Line)과 같은 단어가 추출된 경우가 예시되었다. 서버는, 설명 정보를 통해 추출된 텍스트 셋을 후기 정보와 함께 학습할 수 있다. 학습 결과 제품의 설명을 위한 정보에 있는 키워드가 후기에도 사용되고 있는지, 제품 설명에 기재된 키워드가 후기에 반영된 키워드와 유사도가 높은지 여부를 확인하여, 서버는 해당 키워드를 제품 카테고리로 학습할 수 있다. 도 7을 참조하면, 원피스 카테고리에 대하여, AA, Double A, A1과 같은 키워드가 빈번하게 추출되거나, 추출량 이 증가하는 것으로 판정되어, 트렌드 단어로 결정될 수 있다. 예를 들어, 상기 AA, Double A, A1 등은, \"도트\"와 같이 원피스 디자인 특징에 관련된 디자인 용어일 수 있다, 도 8에 도시된 바와 같이, 이미지에 대하여 시간(T1)에 원피스 카테고리에 대해 Black, DRESS, Sleeveless, AA, A1, Double A이 미리 설정된 기준 횟수(x) 이상 추출된 경우가 그래프에서 예시되었다. 특히, 시간(T1)에서 AA, A1, Double A가 트렌드 단어로 결정되었다. 이후, 시간(T2)에서, 서버가 이미지에 대하여, Green, DRESS Sleeveless, AA, DA, G.Pattern이 미리 설정된 기준 횟수(x) 이상 추출한 경우가 그래프에서 예시되었다. 서버 특히, 시간(T2)에서 Green, DA, G.Pattern이 트렌드 단어로 결정되었다. 시간(T1)에서 시간(T2)의 변화로 Black의 텍스트는 추출 횟수 상위 텍스트에서 제외되고, Green이 추가되었다. AA는 추출량이 줄었으며, A1은 제외되었으며, 이는, AA, A1의 용어가 지속적으로 사용되지 않고 있음을 의미할 수 있도, 또한, Double A는 DA로 변경되었는데, 이는 사용자에 의한 사용 디자인 용어가 변경되고 있음을 의미 할 수 있다. 서버는 이 같은 추출 텍스트 변화를 학습하여, 이미지의 카테고리 원피스에 대한 트렌드 변화를 식별 할 수 있다. 또한, 서버는 신규 추가된 Green 및 G.Pattern의 신규 추출을 통해, 이미지의 원피스 카테고리에 대 한 트렌드 변화를 감지해 낼 수도 있다. 예를 들어, 시간(T1)에서 시간(T2)의 변화에 계절의 변화로 인한 유행 색상이 반영될 수 있으며, 이 같은 트렌 드 변화를 서버가 추출 텍스트의 변화를 바탕으로 학습할 수 있다. 도 9에 도시된 바와 같이, 서버는 인터페이스을 생성하고 사용자 단말의 디스플레이를 통 해 출력할 수 있으며, 도 9에서 인터페이스는 텍스트 입력창과 디자인 이미지 출력부를 포함할 수 있다. 서버는 텍스트 입력창의 텍스트를 조건으로 반영한 디자인 이미지를 생성할 수 있다. 도 10에 도시된 바와 같이, 원본 이미지 (ex. 제1 이미지, 제2 이미지 등), 생성된 디자인 이미지 (ex. 제1 결과 데이터, 제2 결과 데이터 등) 및 해상도 변환 디자인 이미지가 예시되었다. 도 10을 참조하면, 원본 이미지는 구성요소로 배경1, 배경2, 디자인요소1 및 디자인요 소2를 포함할 수 있다. 생성된 디자인 이미지은 배경1, 배경, 디자인요소1 및 디자인요소2를 포함할 수 있다. 해상도 변환 디자인 이미지는 배경1, 배경, 디자인요소1 및 디자인요소2를 포함 할 수 있다. 서버는 원본 이미지를 학습하여, 디자인 이미지를 생성할 수 있다. 이때, 이미지에서 보듯이, 배경1 및 배경2이 해상도 문제로 왜곡(smoothing)되었고, 디자인 요소1 및 디자인요소2 역시 원본과 차이가 발생한 것을 확인할 수 있다. 생성 디자인 이미지 은 원본 이미지 대비 생성된 것으로 디자인 적인 면의 차이는 발생할 수 있으 나, 해상도 문제는 디자인 이미지이 실제 존재하는 원본 이미지로 보이지 않고, 사용자로 하여금 이미지 처리를 통해 생성된 것으로 식별하게 한다. 해상도 변환 이미지를 참조하면, 배경2과 같은 해상도 문제가 있으나, 원본 이미지를 바탕으 로 생성된 이미지 임에도, 실제 원본 이미지와 유사한 해상도를 나타낸다. 서버는 이미지 변환 모듈을 이용하여, 원본 이미지의 픽셀 단위 비교가 아닌 디자인 특징의 비 교를 통한 학습을 수행함으로써 해상도 변환 이미지를 생성할 수 있다. 본원의 기술 분야에서 통상의 지식을 가진 자는 여기에 개시된 실시예들과 관련하여 설명된 다양한 예시적인 논 리 블록들, 모듈들, 프로세서들, 수단들, 회로들 및 알고리즘 단계들이 전자 하드웨어, (편의를 위해, 여기에 서 소프트웨어로 지칭되는) 다양한 형태들의 프로그램 또는 설계 코드 또는 이들 모두의 결합에 의해 구현될 수 있다는 것을 이해할 것이다. 하드웨어 및 소프트웨어의 이러한 상호 호환성을 명확하게 설명하기 위해, 다양한 예시적인 컴포넌트들, 블록들, 모듈들, 회로들 및 단계들이 이들의 기능과 관련하여 위에서 일반적으로 설명되 었다. 이러한 기능이 하드웨어 또는 소프트웨어로서 구현되는지 여부는 특정한 애플리케이션 및 전체 시스템에 대하여 부과되는 설계 제약들에 따라 좌우된다. 본원의 기술 분야에서 통상의 지식을 가진 자는 각각의 특정 한 애플리케이션에 대하여 다양한 방식들로 설명된 기능을 구현할 수 있으나, 이러한 구현 결정들은 본원의 범위를 벗어나는 것으로 해석되어서는 안 될 것이다. 여기서 제시된 다양한 실시예들은 방법, 장치, 또는 표준 프로그래밍 및/또는 엔지니어링 기술을 사용한 제조 물품(article)으로 구현될 수 있다. 용어 제조 물품은 임의의 컴퓨터-판독가능 저장장치로부터 액세스 가능한 컴퓨터 프로그램, 캐리어, 또는 매체(media)를 포함한다. 예를 들어, 컴퓨터-판독가능 저장매체는 자기 저장 장 치(예를 들면, 하드 디스크, 플로피 디스크, 자기 스트립, 등), 광학 디스크(예를 들면, CD, DVD, 등), 스마트 카드, 및 플래쉬 메모리 장치(예를 들면, EEPROM, 카드, 스틱, 키 드라이브, 등)를 포함하지만, 이들로 제한되 는 것은 아니다. 또한, 여기서 제시되는 다양한 저장 매체는 정보를 저장하기 위한 하나 이상의 장치 및/또는 다른 기계-판독가능한 매체를 포함한다. 제시된 프로세스들에 있는 단계들의 특정한 순서 또는 계층 구조는 예시적인 접근들의 일례임을 이해하도록 한 다. 설계 우선순위들에 기반하여, 본원의 범위 내에서 프로세스들에 있는 단계들의 특정한 순서 또는 계층 구조 가 재배열될 수 있다는 것을 이해하도록 한다. 첨부된 방법 청구항들은 샘플 순서로 다양한 단계들의 엘리먼트 들을 제공하지만 제시된 특정한 순서 또는 계층 구조에 한정되는 것을 의미하지는 않는다. 제시된 실시예들에 대한 설명은 임의의 본원의 기술 분야에서 통상의 지식을 가진 자가 본원을 이용하거나 또는 실시할 수 있도록 제공된다. 이러한 실시예들에 대한 다양한 변형들은 본원의 기술 분야에서 통상의 지식을 가 진 자에게 명백할 것이며, 여기에 정의된 일반적인 원리들은 본원의 범위를 벗어남이 없이 다른 실 시예들에 적 용될 수 있다. 그리하여, 본원은 여기에 제시된 실시예들로 한정되는 것이 아니라, 여기에 제시된 원리들 및 신 규한 특징들과 일관되는 최광의의 범위에서 해석되어야 할 것이다.도면 도면1 도면2 도면3 도면4 도면5 도면6 도면7 도면8 도면9 도면10"}
{"patent_id": "10-2023-0096716", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본원의 실시예에 따른 시스템 구성도이다. 도 2는 본원의 실시예에 따른 서버 구성도이다. 도 3은 본원의 실시예에 따른 이미지 생성 단계 흐름도이다. 도 4는 본원의 실시예에서 참조되는, 제1 인공지능 모델의 제1 결과 데이터 생성 프로세스를 설명하기 위한 개 념도이다. 도 5는 본원의 실시예에 따른 학습된 조건 기반의 디자인 생성 방법의 흐름도이다. 도 6은 본원의 실시예에 따른 제1 이미지, 및 제1 텍스트 간 매칭 방법의 흐름도이다. 도 7은 본원의 실시예에서 참조되는, 제1 인공지능 모델의 이미지와 텍스트 쌍(Pair)의 학습 방법 예시도이다. 도 8은 본원의 실시예에서 참조되는, 제1 인공지능 모델의 트렌드 단어의 선정 프로세스 예시도이다. 도 9는 본원의 실시예에서 참조되는, 사용자 단말을 통해 표시된 사용자 인터페이스의 예시도이다. 도 10은 본원의 실시예에서 참조되는, 사용자 단말을 통해 표시된 제2 결과 데이터의 예시도이다. 이상의 도면들은 당업자에게 본원의 사상이 충분히 전달될 수 있도록 하기 위해 예로서 제공되는 것이다. 따라서, 본원은 이하 제시되는 도면들에 한정되지 않고 다른 형태로 구체화될 수도 있다. 또한, 명세서 전반에 걸쳐서 동일한 참조번호들은 동일한 구성요소들을 나타낸다. 또한, 이상의 도면에서는 이해를 돕기 위해서, 축척에 비례하지 않고 특정 부분을 확대하거나 축소한 점에 유의 해야 한다."}
