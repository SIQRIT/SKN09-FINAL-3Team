{"patent_id": "10-2023-0038496", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0143338", "출원번호": "10-2023-0038496", "발명의 명칭": "다중 신경망 가속을 위한 확장가능 벡터-어레이 이종 가속기 구조 및 스케쥴링 기법", "출원인": "한국과학기술원", "발명자": "김주영"}}
{"patent_id": "10-2023-0038496", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "복수의 벡터-어레이 클러스터; 및외부로부터 수신한 신경망 요청을 상기 복수의 벡터-어레이 클러스터에 분배하는 신경망 요청 분배기를 포함하되,상기 복수의 벡터-어레이 클러스터 각각은,복수의 벡터 레인을 포함하여 벡터 연산을 수행하는 복수의 벡터 프로세서;어레이 구조로 배열된 복수의 프로세싱 유닛을 포함하여 어레이 연산을 수행하는 복수의 어레이 프로세서; 및분배된 신경망 요청을 테스크로 분리하고, 테스크 정보 및 스케쥴링 상태 정보에 기초하여 상기 테스크를 상기복수의 어레이 프로세서 또는 벡터 프로세서에 할당하는 테스크 컨트롤러 프로세서를 포함하는,다중 신경망을 위한 확장 가능한 벡터 어레이 이종 가속 장치."}
{"patent_id": "10-2023-0038496", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1 항에 있어서,상기 신경망 요청은, 딥러닝 프레임워크로부터 추출된 정보를 이용하여 패킷 형식으로 압축된 딥러닝 모델 기술통합 포맷으로 구성되는,다중 신경망을 위한 확장 가능한 벡터 어레이 이종 가속 장치."}
{"patent_id": "10-2023-0038496", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 2항에 있어서, 상기 딥러닝 모델 기술 통합 포맷은,프레임 헤더, 정보 메시지 헤더, 정보 패킷 그룹, 데이터 메시지 헤더 및 데이터 패킷 그룹을 포함하는,다중 신경망을 위한 확장 가능한 벡터 어레이 이종 가속 장치."}
{"patent_id": "10-2023-0038496", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 1항에 있어서,상기 복수의 벡터 프로세서 각각은,상기 테스크 컨트롤러 프로세서에 의해 행렬 곱 및 컨볼루션 연산을 수행하도록 스케쥴링되는,다중 신경망을 위한 확장 가능한 벡터 어레이 이종 가속 장치."}
{"patent_id": "10-2023-0038496", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제 4항에 있어서,상기 복수의 벡터 레인 각각은, 단일 곱셈 누산기, 산술 논리 장치, 특수 연산 유닛 및 순람표(LUT) 연산자 유닛을 포함하는,다중 신경망을 위한 확장 가능한 벡터 어레이 이종 가속 장치."}
{"patent_id": "10-2023-0038496", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제 1항에 있어서,공개특허 10-2024-0143338-3-상기 복수의 프로세싱 유닛은 2D 시스톨릭 어레이 구조로 배열되는,다중 신경망을 위한 확장 가능한 벡터 어레이 이종 가속 장치."}
{"patent_id": "10-2023-0038496", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제 1항에 있어서,상기 테스크 컨트롤러 프로세서는 스케쥴링 요청에 대하여,스케쥴링 테이블과 후보 작업으로부터 메모리가 준비되는 시간을 계산하고,상기 스케쥴링 테이블로부터 이전 작업의 완료 시간과 상기 벡터 프로세서 및 어레이 프로세서가 준비되는 시간을 확인하고,상기 메모리, 벡터 프로세서 및 어레이 프로세서의 준비되는 시간과 상기 이전 작업의 완료 시간 중 최대값으로부터 상기 벡터 프로세서 및 어레이 프로세서에서 상기 후보 작업을 수행할 수 있는 시간을 계산하고,성능 모델로부터 상기 후보 작업의 소요 시간을 추정하여 상기 후보 작업의 완료 시간을 계산하고,상기 벡터 프로세서 및 어레이 프로세서 중 상기 후보 작업의 완료 시간이 빠른 프로세서를 선택하여 프로세서-작업 짝을 지정하고 상기 후보 작업을 선택된 프로세서에 할당할 때 발생하는 유휴 시간을 계산하고,상기 유휴 시간이 가장 짧은 후보 작업을 선택하여 스케쥴링하는,다중 신경망을 위한 확장 가능한 벡터 어레이 이종 가속 장치."}
{"patent_id": "10-2023-0038496", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제 7항에 있어서,상기 복수의 벡터-어레이 클러스터 각각은 상기 복수의 벡터 프로세서 및 어레이 프로세서가 공유하는 공유 메모리를 포함하고,상기 테스크 컨트롤러 프로세서는 상기 메모리가 준비되는 시간을 계산하기 위하여,상기 스케쥴링 테이블로부터 상기 메모리의 이전 접근 완료 시간을 임시 메모리 준비 시간으로 지정하는 단계;상기 메모리로부터 가져올 데이터가 있는 경우 상기 공유 메모리의 남은 용량을 고려하여 필요한 데이터를 가져오고 상기 임시 메모리 준비 시간을 지정하고,상기 메모리로부터 가져올 데이터가 있는 경우 상기 임시 메모리 준비 시간을 상기 메모리가 준비되는 시간으로지정하는,다중 신경망을 위한 확장 가능한 벡터 어레이 이종 가속 장치."}
{"patent_id": "10-2023-0038496", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제 8항에 있어서,상기 테스크 컨트롤러 프로세서는,상기 공유 메모리에 저장된 데이터가 다른 테스크에 의하여 사용되지 않는 경우 삭제하는,다중 신경망을 위한 확장 가능한 벡터 어레이 이종 가속 장치."}
{"patent_id": "10-2023-0038496", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제 2항에 있어서,상기 신경망 요청 분배기는,상기 딥러닝 모델 통합 기술 포맷을 디코딩하는 딥러닝 모델 통합 기술 포맷 해독기를 포함하는.다중 신경망을 위한 확장 가능한 벡터 어레이 이종 가속 장치.공개특허 10-2024-0143338-4-"}
{"patent_id": "10-2023-0038496", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "다중 신경망을 위한 확장 가능한 벡터 어레이 이종 가속 장치가 제공된다. 다중 신경망을 위한 확장 가능한 벡터 어레이 이종 가속 장치는, 복수의 벡터-어레이 클러스터; 및 외부로부터 수신한 신경망 요청을 상기 복수의 벡터 -어레이 클러스터에 분배하는 신경망 요청 분배기를 포함하되, 상기 복수의 벡터-어레이 클러스터 각각은, 복수 의 벡터 레인을 포함하여 벡터 연산을 수행하는 복수의 벡터 프로세서; 어레이 구조로 배열된 복수의 프로세싱 유닛을 포함하여 어레이 연산을 수행하는 복수의 어레이 프로세서; 및 분배된 신경망 요청을 테스크로 분리하고, 테스크 정보 및 스케쥴링 상태 정보에 기초하여 상기 테스크를 상기 복수의 어레이 프로세서 또는 벡터 프로세서 에 할당하는 테스크 컨트롤러 프로세서를 포함한다."}
{"patent_id": "10-2023-0038496", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 다중 신경망을 위한 확장 가능한 벡터 어레이 이종 가속 장치에 관한 것으로, 더욱 구체적으로는 독 립적인 벡터 프로세서와 어레이 프로세서로 구성된 클러스터를 포함하고. 효율적인 스케쥴링을 통해 다양한 기 계학습용 워크로드를 실행할 수 있는 벡터 어레이 이종 가속 장치에 관한 것이다."}
{"patent_id": "10-2023-0038496", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "인공 지능(Artificial Intelligence; AI) 및 기계 학습(Machine Learning; ML) 기술은 컴퓨터 비전, 음성 인식, 자연어 처리 등과 같은 다양한 애플리케이션 분야에서 빠르게 도입되고 있다. 특히 다중 신경망(Multi- Deep Neural Network; DNN)과 같은 인공지능 모델은 더 높은 정확도를 얻기 위하여 다양하고 복잡한 연산을 필 요로 하며, 하드웨어 가속 장치는 다양한 DNN 모델의 처리를 위해 동적으로 변화하는 기계학습 워크로드를 동시 에 실행할 필요가 있다. 그러나 기존의 기계학습용 하드웨어 가속 장치들은 특정한 학습 모델에서 높은 효율성을 얻기 위해 최적화되어 있는 경우가 많아 주어진 데이터플로(dataflow)에 맞지 않는 모델에 대해서는 연산 요소와 메모리 대역폭의 사 용율이 떨어지는 문제가 발생한다. 이에 따라 재구성 가능하고 이종의 데이터플로를 지원하는 가속 장치가 최근 제안된 바 있다. 데이터플로를 재 구성 가능한 가속 장치는 높은 실행 효율을 가질 수 있으나 재구성을 위한 면적 및 전력 오버헤드가 불가피하며, 이종의 데이터플로를 지원하는 가속 장치는 동일한 연산 특성을 갖는 일련의 작업에 대해 하드웨어 활용도가 낮은 경향을 보인다."}
{"patent_id": "10-2023-0038496", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명이 해결하고자 하는 기술적 과제는 독립적인 벡터 프로세서와 어레이 프로세서를 포함하는 클러스터로 구성되어 다중의 기계학습 워크로드를 효율적으로 실행할 수 있는 확장 가능한 벡터 어레이 이종 가속 장치를 제공하는 것이다. 본 발명의 기술적 과제들은 이상에서 언급한 기술적 과제로 제한되지 않으며, 언급되지 않은 또 다른 기술적 과 제들은 아래의 기재로부터 당업자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2023-0038496", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기 기술적 과제를 해결하기 위한 본 발명의 실시예에 따른 다중 신경망을 위한 확장 가능한 벡터 어레이 이종 가속 장치는, 복수의 벡터-어레이 클러스터; 및 외부로부터 수신한 신경망 요청을 상기 복수의 벡터-어레이 클 러스터에 분배하는 신경망 요청 분배기를 포함하되, 상기 복수의 벡터-어레이 클러스터 각각은, 복수의 벡터 레 인을 포함하여 벡터 연산을 수행하는 복수의 벡터 프로세서; 어레이 구조로 배열된 복수의 프로세싱 유닛을 포 함하여 어레이 연산을 수행하는 복수의 어레이 프로세서; 및 분배된 신경망 요청을 테스크로 분리하고, 테스크 정보 및 스케쥴링 상태 정보에 기초하여 상기 테스크를 상기 복수의 어레이 프로세서 또는 벡터 프로세서에 할 당하는 테스크 컨트롤러 프로세서를 포함한다. 기타 실시예들의 구체적인 사항들은 상세한 설명 및 도면들에 포함되어 있다."}
{"patent_id": "10-2023-0038496", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명의 실시예에 따른 다중 신경망을 위한 확장 가능한 벡터 어레이 이종 가속 장치는, 같이 본 발명의 벡터 어레이 이종 가속 장치는 기존의 ONNX 포맷으로부터 추출된 정보로부터 컴팩트한 패킷 형식으로 압축된 딥러닝 모델 기술 통합 포맷을 이용함으로써 벡터 어레이 이종 가속 장치의 빠른 디코딩이 가능하며 데이터 중복성에 따른 오버헤드나 다수의 사용자 정보 부재에 관한 문제가 해결될 수 있다. 또한, 본 발명의 벡터 어레이 이종 가속 장치는 어레이 프로세서와 벡터 프로세서 사이의 최적화된 스케쥴링을"}
{"patent_id": "10-2023-0038496", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 2, "content": "통해 다중 신경망 모델 계산에 필요한 작업 속도를 향상시킬 수 있다.본 발명의 효과들은 이상에서 언급한 효과들로 제한되지 않으며, 언급되지 않은 또 다른 효과들은 청구범위의 기재로부터 당업자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2023-0038496", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명의 이점 및 특징, 그리고 그것들을 달성하는 방법은 첨부되는 도면과 함께 상세하게 후술되어 있는 실시 예들을 참조하면 명확해질 것이다. 그러나 본 발명은 이하에서 개시되는 실시예들에 한정되는 것이 아니라 서로 다른 다양한 형태로 구현될 것이며, 단지 본 실시예들은 본 발명의 개시가 완전하도록 하며, 본 발명이 속하는"}
{"patent_id": "10-2023-0038496", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "기술분야에서 통상의 지식을 가진 자에게 발명의 범주를 완전하게 알려주기 위해 제공되는 것이며, 본 발명은 청구항의 범주에 의해 정의될 뿐이다. 명세서 전체에 걸쳐 동일 참조 부호는 동일 구성 요소를 지칭한다. 하나의 구성 요소가 다른 구성 요소와 \"연결된(connected to)\" 또는 \"커플링된(coupled to)\" 이라고 지칭되는 것은, 다른 구성 요소와 직접 연결 또는 커플링된 경우 또는 중간에 다른 구성 요소를 개재한 경우를 모두 포함 한다. 반면, 하나의 구성 요소가 다른 구성 요소와 \"직접 연결된(directly connected to)\" 또는 \"직접 커플링된 (directly coupled to)\"으로 지칭되는 것은 중간에 다른 구성 요소를 개재하지 않은 것을 나타낸다. \"및/또는\" 은 언급된 아이템들의 각각 및 하나 이상의 모든 조합을 포함한다. 본 명세서에서 사용된 용어는 실시예들을 설명하기 위한 것이며 본 발명을 제한하고자 하는 것은 아니다. 본 명 세서에서, 단수형은 문구에서 특별히 언급하지 않는 한 복수형도 포함한다. 명세서에서 사용되는 \"포함한다 (comprises)\" 및/또는 \"포함하는(comprising)\"은 언급된 구성 요소, 단계, 동작 및/또는 소자는 하나 이상의 다 른 구성 요소, 단계, 동작 및/또는 소자의 존재 또는 추가를 배제하지 않는다. 비록 제1, 제2 등이 다양한 구성 요소들을 서술하기 위해서 사용되나, 이들 구성 요소들은 이들 용어에 의해 제 한되지 않음은 물론이다. 이들 용어들은 단지 하나의 구성 요소를 다른 구성 요소와 구별하기 위하여 사용하는 것이다. 따라서, 이하에서 언급되는 제1 구성 요소는 본 발명의 기술적 사상 내에서 제2 구성 요소 일 수도 있 음은 물론이다. 다른 정의가 없다면, 본 명세서에서 사용되는 모든 용어(기술 및 과학적 용어를 포함)는 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자에게 공통적으로 이해될 수 있는 의미로 사용될 수 있을 것이다. 또 일반적으로 사용되는 사전에 정의되어 있는 용어들은 명백하게 특별히 정의되어 있지 않는 한 이상적으로 또는 과도하게 해석되지 않는다. 도 1은 본 발명의 실시예에 따른 다중 신경망을 위한 확장 가능한 벡터 어레이 이종 가속 장치를 설명하기 위한 도면이다. 도 1을 참조하면, 본 발명의 실시예에 따른 다중 신경망을 위한 확장 가능한 벡터 어레이 이종 가속 장치는, 신경망 요청 분배기, 복수의 벡터-어레이 클러스터 등을 포함할 수 있다. 복수의 벡터-어레이 클러스터 각각은 내부에 복수의 어레이 프로세서 및 벡터 프로세서를 포함 함으로써 벡터 연산 및 어레이 연산을 수행할 수 있다. 구체적으로, 복수의 벡터-어레이 클러스터 각각은 프로세싱 유닛이 1차원 배열로 배치되어 프로그램 가능성을 가지고 있는 복수의 벡터 프로세서와, 프로세 싱 유닛이 2차원으로 배치되어 있어 어레이 연산에 대한 높은 쓰루풋(throughput)을 갖는 복수의 어레이 프로세 서를 포함할 수 있다. 특히 복수의 벡터-어레이 클러스터는 신경망 요청 분배기로부터 분배된 신경망 요청에 대하여 현재 테스크 정보와 스케쥴링 상태 정보에 따라 복수의 어레이 프로세서 및 벡터 프로세서에 할당함으로써 벡터 연산과 어레이 연산이 병렬로 처리되는 구조를 가질 수 있다. 도 1에는 벡터 어레이 이종 가속 장치에 4개의 벡터-어레이 클러스터가 포함된 것으로 도시되었으나 본 발명이 이에 제한되는 것은 아니며, 하드웨어 구성에 따라 얼마든지 4개 이상 또는 이하의 벡터-어레이 클러 스터가 포함될 수 있음은 물론이다. 신경망 요청 분배기는 외부로부터 신경망 요청을 수신하고, 신경망 요청에 포함된 요청 정보 상태와 현재 복수의 벡터-어레이 클러스터의 상태에 기초하여 적절한 클러스터에 신경망 요청을 분배할 수 있다. 신경망 요청 분배기는 분배 컨트롤러 프로세서, 딥 러닝 모델 기술 통합 포맷 해독기, 라우터 등을 포함할 수 있다. 본 발명의 몇몇 실시예에서, 신경망 요청 분배기가 처리하는 신경망 요청은 인공지능 가속 하드웨어에 최 적화된 경량 포맷인 딥러닝 모델 기술 통합 포맷을 포함할 수 있다. 해당 포맷은 딥러닝 모델로부터 필수적인 데이터만 추출하고 빠른 하드웨어 디코딩이 가능하도록 컴팩트한 패킷 형식으로 압축된 파일일 수 있다. 신경망 요청 분배기는 딥러닝 모델 기술 통합 포맷으로 구성된 신경망 요청을 수신하고 이를 디코딩하여 모델 연 산에 필요한 정보를 이용할 수 있다. 상기 딥러닝 모델 기술 통합 포맷에 관한 설명을 도 2를 이용하여 설명한 다. 도 2a 및 2b는 본 발명의 실시예에 따른 다중 신경망을 위한 확장 가능한 벡터 어레이 이종 가속 장치가 처리하 는 신경망 요청이 포함된 딥러닝 모델 기술 통합 포맷을 설명하기 위한 도면이다. 도 2a 및 2b를 참조하면, 딥러닝 모델 기술 통합 포맷은 Pytorch, TensorFllow, MxNet과 같은 프레임워크가 변 환된 ONNX(Open Neural Network Exchange) 포맷으로부터 생성될 수 있다. 알려진 것과 같이 각각 다른 소프트 웨어 프레임워크 사이의 부족한 상호 호환성을 해결하고자 ONNX 포맷이 도입되었으나, ONNX 포맷을 하드웨어 가 속 장치에 직접 적용하기에는 문제점이 많았다. 예를 들어 ONNX의 Protobuf 프로토콜에는 동적 바인딩을 지원하 기 위한 데이터 중복성(redundancy)이 있어 디코딩에 따른 오버헤드가 발생하고 하드웨어 효율성이 떨어진다. 또한 ONNX 포맷은 사용자 설명 필드가 포함되어 있지 않아 복수의 사용자에 의한 복수의 신경망 요청이 제공되 는 경우 사용자 정보를 설명하기 위한 또 다른 수준의 추상화를 필요로 한다. 이와 같은 문제를 해결하기 위하여 본 발명의 벡터 어레이 이종 가속 장치는 ONNX 포맷으로부터 추출된 정 보를 이용하여 재구성된 딥러닝 모델 기술 통합 포맷을 이용하여 신경망 요청을 수신하고, 각각의 벡터-어레이 클러스터에 작업을 할당할 수 있다. 구체적으로, 딥러닝 모델 기술 통합 포맷 구조는, 프레임 헤더, 정보 메시지 헤더, 정보 패킷 그룹(정보 패킷 #1~#N), 데이터 메시지 헤더와 데이터 패킷 그룹(데이터 패킷 #1~#N)으로 구성될 수 있다. 먼저 프레임 헤더는 패킷 타입, 포맷 버전 정보와 같은 딥러닝 모델 기술 통합 포맷의 속성을 포함하고, 사용자 ID, 트랜잭선 ID 및 모델 ID의 정보도 포함할 수 있다. 신경망 요청 분배기는 프레임 헤더에 포함된 딥러닝 모델 기술 통합 포 맷의 속성을 디코딩하여 전체 딥러닝 모델 기술 통합 포맷을 어떻게 디코딩할지 결정할 수 있다. 정보 메시지 헤더는 전체 정보 패킷의 길이(개수)에 관한 정보를 포함할 수 있다. 정보 패킷 그룹은 복수의 정보 패킷은 딥러닝 모델에서 하나의 동작 레이어를 기술하는 정보를 포함하며, 정보 패킷 헤더와 정보 패킷 페이로드로 구성된다. 정보 패킷 헤더는 현재와 다음 정보 패킷 길이와, 동작, 출력, 입력 및 특성의 타입과, 레이어 ID를 포함할 수 있다. 현재와 다음 정보 패킷 길이는 벡터-어레이 클러스터의 큐에 넣을 데이터의 크기를 결정한다. 동작 타입은 딥러닝 모델에서 하나의 레이어에서 수행하는 컨볼루션, GEMM(General Matrix to Matrix Multiplication)과 같은 계산 관련 동작이나 Concat, Reshape와 같은 데이터 관련 동작을 포함할 수 있다. 입력, 출력 타입은 각각 레이어의 입력의 유형 및 개수, 출력의 개수에 관한 정보를 포함할 수 있다. 특성 타입 은 정보 패킷 페이로드에 어떠한 특성(예를 들어 커널 크기 및 패딩 타입)이 기술되는지에 관한 정보를 포함할 수 있다. 정보 패킷 페이로드는 하나의 레이어가 동작하는데 있어 필요한 모든 정보를 포함하며, 각각의 레이어는 고유한 레이어 ID에 의해 구분될 수 있다. 데이터 메시지 헤더는 전체 데이터 패킷의 개수, 길이를 포함할 수 있다. 데이터 패킷 헤더는 딥러닝 모델에서 하나의 동작 레이어에서 사용되는 파라미터와 관련된 정보를 포함하며, 데 이터 패킷 페이로드 플릿(flit)의 길이, 텐서 ID, 데이터 타입, 정확성 및 차원 정보를 포함할 수 있다. 텐서 ID는 모델 파라미터를 저장하는 데이터 패킷 페이로드를 구분하기 위한 고유 ID로, 정보 패킷 페이로드의 연산 정보가 텐서 ID를 참조하여 주어진 연산에 사용되는 텐서 값을 얻을 수 있다. 데이터 패킷 헤더는 그 밖에 데이터 패킷 페이로드의 차원, 부동 소수점 또는 고정 소수점에 관한 데이터 타입, 정밀도(precision) 등에 관한 정보를 포함할 수 있으며, 데이터 패킷 헤더에 기술된 데이터 타입 및 정밀도를 기반으로 딥러닝 모델의 레이어에서 사용되는 파라미터를 포함하는 데이터 패킷 페이로드가 디코딩될 수 있다. 딥러닝 모델 기술 통합 포맷은 벡터 어레이 이종 가속 장치의 동작 상황에 따라 크게 세 가지로 구성이 변 경될 수 있다. 먼저 사용자가 벡터 어레이 이종 가속 장치에 딥러닝 모델을 로드하는 경우, 딥러닝 모델 기 술 통합 포맷의 구성은 프레임 헤더, 정보 메시지 헤더, 정보 패킷 그룹, 데이터 메시지 헤더와 데이터 패킷 그 룹으로 구성될 수 있다. 또한 사용자가 딥러닝 모델 추론을 벡터 어레이 이종 가속 장치가 결과를 반환하는 경우 딥러닝 모델 기술 통합 포맷은 프레임 헤더, 데이터 메시지 헤더 및 데이터 패킷 그룹으로 구성될 수 있다. 마지막으로 딥러닝 모델이 벡터 어레이 이종 가속 장치에 정상적으로 로드되어 있는지 상태를 반환하는 경 우, 딥러닝 모델 기술 통합 포맷은 프레임 헤더만으로 구성될 수 있다. 이와 같이 본 발명의 벡터 어레이 이종 가속 장치는 기존의 ONNX 포맷으로부터 추출된 정보로부터 컴팩트한 패킷 형식으로 압축된 딥러닝 모델 기술 통합 포맷을 이용함으로써 벡터 어레이 이종 가속 장치의 빠른 디 코딩이 가능하며 데이터 중복성에 따른 오버헤드나 다수의 사용자 정보 부재에 관한 문제가 해결될 수 있다. 도 3은 본 발명의 실시예에 따른 다중 신경망을 위한 확장 가능한 벡터 어레이 이종 가속 장치에 포함된 신경망 요청 분배기의 동작을 설명하기 위한 순서도이다. 도 1 및 도 3을 참조하면, 신경망 요청 분배기는 외부로부터 신경망 요청이 제공되면 해당 요청을 디코딩 한다(S110). 신경망 요청은 앞서 도 2에서 설명한 딥러닝 모델 기술 통합 포맷으로 구성되며 딥러닝 모델 기술 통합 포맷 해독기에 의해 디코딩될 수 있다. 신경망 요청 분배기는 요청 정보 상태에 해당 신경망 요청이 입력되었음을 기록할 수 있다(S120). 신 경망 요청 분배기가 수신한 신경망 요청이 딥러닝 모델 추론인 경우 요청 정보 상태에 저장되는 정보 는 딥러닝 모델 기술 통합 포맷에 포함된 사용자 ID와 대상 모델 정보를 포함할 수 있다. 분배 컨트롤 프로세서는 요청 정보 상태와 클러스터 상태를 확인하고(S130), 적절한 벡터-어레 이 클러스터에 신경망 요청의 처리를 지정하고(S140) 요청 대기 큐를 갱신할 수 있다. 이때 분배 컨트롤 프로세서는 예를 들어 라운드 로빈(Round Robin), FIFO(First-in-First-out), 최단 작업 우선 스케줄링 (Shortest Job First) 등의 다양한 알고리즘을 이용하여 신경망 요청의 처리를 지정할 수 있다. 벡터-어레이 클 러스터로부터 연산이 완료되면 종료 신호를 수신하고 결과값을 반환할 수 있다(S150). 도 4는 본 발명의 실시예에 따른 다중 신경망을 위한 확장 가능한 벡터 어레이 이종 가속 장치에 포함된 벡터- 어레이 클러스터의 동작을 설명하기 위한 순서도이다.도 1 및 도 4를 참조하면, 벡터-어레이 클러스터는 신경망 요청 분배기로부터 분배된 신경망 요청에 포함된 모델 정보를 딥러닝 모델 정보 저장소에 저장할 수 있다(S210). 이어서 딥러닝 모델 정보 저장소 에 저장된 모델을 레이어 단위 테스크로 쪼개어 테스크 다중 큐에 등록할 수 있다(S220). 이때 테스 크 다중 큐에는 딥러닝 모델 정보 저장소에 신경망 요청의 연산이 남아있는지에 대한 정보도 같이 저 장될 수 있다. 테스크 컨트롤러 프로세서가 테스크 다중 큐에 있는 테스크의 정보와 스케쥴링 상태 정보에 있 는 프로세서와 메모리의 상태를 확인하고(S230, S240) 각각의 어레이 및 벡터 프로세서(300, 400)에 테스크를 할당하여 연산을 수행한다(S250). 이때 테스크 컨트롤러 프로세서는 테스크 할당을 위해 라운드 로빈, FIFO, 최단 작업 우선 스케줄링 등의 다양한 알고리즘을 이용할 수 있다. 테스크 컨트롤러 프로세서가 테 스크 다중 큐에 남은 연산이 없는 것을 확인하면 신경망 요청 분배기로 종료된 모델의 정보와 함께 종료 신호를 전송할 수 있다. 복수의 어레이 및 벡터 프로세서(300, 400)는 공유 메모리를 통해 데이터를 읽고 쓸 수 있다. 예를 들어 공유 메모리에 저장된 출력 액티베이션(output activation)을 다음 계층의 입력으로 직접 사용하거나, 동 일한 딥러닝 모델에 대하여 가중치를 공유함으로써 메모리에 대한 액세스를 줄일 수 있다. 도 5는 본 발명의 실시예에 따른 다중 신경망을 위한 확장 가능한 벡터 어레이 이종 가속 장치에 포함된 벡터 프로세서의 구조를 설명하기 위한 도면이다. 도 5를 참조하면, 벡터 프로세서는 벡터 레인 컨트롤러, 벡터 레인, 마이크로코드 생성기, 메모리 등을 포함할 수 있다. 벡터 프로세서는 복수의 벡터 레인을 포함하는 순차 SIMD(Single Instruction Multiple Data) 프로세서로, 예를 들어 DNN 모델에서의 풀링, 비선형 활성화 함수 및 요소별 벡터 연산과 같은 비행렬 연산을 실행할 수 있다. 또한, 벡터 프로세서는 프로그램을 통해 행렬 연산인 행렬 곱 및 컨볼루션 연산을 수행할 수 있어 어레이 프로세서의 연산을 돕도록 스케쥴링될 수도 있다. 테스크 컨트롤러 프로세서가 벡터 프로세서로 테스크를 할당하면 마이크로코드 생성기는 해당 테스크의 정보에 기초하여 벡터 레인에서 수행되는 이진 명령어을 생성할 수 있다. 이러한 이진 명령은 벡 터 처리에 최적화되어 프로그래밍 오버헤드 및 명령어 페치 주기를 경감시킬 수 있다. 벡터 레인 컨트롤러는 생성된 이진 명령어에 기초하여 벡터 레인과 메모리를 제어할 수 있다. 구체적으로, 벡터 레인 컨트롤러는 벡터 레인에 포함된 연산 유닛의 제어 신호를 생성하고, 데이터 해저드(data hazard)를 감지하는 한편 멀티 사이클 동작을 제어할 수 있다. 각각의 벡터 레인은 도 5에 도시된 것과 같이 단일 곱셈 누산기, 산술 논리 장치, 특수 연산 유 닛 및 순람표(LUT) 연산자 유닛 등을 포함하며 딥러닝 모델의 다양한 연산을 수행할 수 있다. 특수 연산 유닛은 역수 및 지수 연산을 수행할 수 있으며, 순람표 연산자 유닛은 비선형 활성화 함수 를 연산할 수 있으며, LUT의 값을 바꿔 다양한 비선형 함수 연산을 수행할 수 있다. 이와 같은 연산 유닛의 동 작을 통해 벡터 레인에서 소프트맥스 연산과 같은 하이레벨 연산을 효과적으로 구현할 수 있다. 한편, 벡터 레인의 데이터 입출력을 위해 버퍼인 메모리가 이용될 수 있으며, 몇몇 실시예에서 메모 리의 이중 버퍼링을 통해 입출력의 대기 시간을 노출시키지 않을 수 있다. 도 6은 본 발명의 실시예에 따른 다중 신경망을 위한 확장 가능한 벡터 어레이 이종 가속 장치에 포함된 어레이 프로세서의 구조를 설명하기 위한 도면이다. 도 6을 참조하면, 어레이 프로세서는 어레이 컨트롤러, 복수의 프로세싱 유닛, 가중치, 입력 및 출력 데이터를 저장하는 메모리(430, 440, 450), 축적기 유닛 등을 포함할 수 있다. 어레이 컨트롤러는 가중치 데이터 메모리, 입력 데이터 메모리로부터 프로세싱 유닛에 데 이터를 공급할 수 있다. 복수의 프로세싱 유닛은 2D 시스톨릭 어레이 구조로 배열될 수 있다. 각각의 프로세싱 유닛은 가중치 데이터를 저장하는 가중치 레지스터와 곱셈-덧셈을 수행하는 연산기를 포함할 수 있다. 프로세싱 유닛의 활용율을 높이기 위하여 프로세싱 유닛은 연산에 참여하는 가중치를 저장하는 레지스터와 새로운 가중치를프리페치하는 두 종류의 가중치 레지스터를 포함하여 이중 버퍼링을 수행할 수 있다. 복수의 프로세싱 유닛이 연산하여 생성한 부분합은 축적기 유닛에 의해 지속적으로 축적되어 출력 데 이터 메모리에 저장될 수 있다. 메모리(430, 440, 450)은 예를 들어 온칩(On-chip) 메모리를 포함할 수 있으며, 지연 감소를 위해 이중 버퍼링 을 수행할 수 있다. 도 7은 본 발명의 실시예에 따른 다중 신경망을 위한 확장 가능한 벡터 어레이 이종 가속 장치의 이종 구조 인 식 스케쥴링을 설명하기 위한 순서도이다. 이종 구조 인식 스케쥴링(Heterogenous-Aware Scheduling Algorithm)은 실행 시간 추정을 기반으로 각각의 프 로세서의 유휴 시간을 최소화하여 전체 하드웨어 활용도를 극대화하는 알고리즘이다. 이는 기존의 라운드 로빈 (Round Robin)과 같이 스케쥴링에 작업 및 프로세서의 특성을 고려하지 않아 벡터 프로세서가 어레이 연산 을 수행할 수 있음에도 유휴 상태로 남는 스케쥴링 알고리즘보다 프로세서들의 하드웨어 활용도를 높일 수 있다. 구체적으로, 도 7을 참조하면, 이종 구조 인식 스케쥴링은 스케쥴러로부터 스케쥴링 요청을 입력되면, 테스크 컨트롤러 프로세서가 스케쥴링 테이블과 후보 작업으로부터 메모리가 준비되는 시간을 계산하는 단계 (S310)를 포함한다. 테스크 컨트롤러 프로세서는 스케쥴링 상태 정보에 스케쥴링 테이블을 기록하며, 이후 자세하게 설명할 외부 메모리 접근 알고리즘을 사용하여 주어진 작업에 필요한 파라미터 및 액티베이션이 공유 메모리에 준비되는 시간을 계산할 수 있다. 이어서 스케쥴링 테이블로부터 이전 작업의 완료 시간과 벡터 프로세서 및 어레이 프로세서가 준비되는 시간을 확인하는 단계(S320)가 수행된다. 테스크 컨트롤러 프로세서는 스케쥴링 상태 정보의 스케쥴링 테이 블에 각각의 후보 작업에 대한 종속 작업의 종료 시간과 벡터 및 어레이 프로세서(300, 400)의 가장 빠른 사용 가능 시간을 확인할 수 있다. 테스크 컨트롤러 프로세서는 메모리, 작업, 프로세서가 준비되는 시간 중 최대값으로부터 각각의 프로세서 에서 다음 작업을 수행할 수 있는 시작 시간을 얻는 단계(S330)를 수행한다. 테스크 컨트롤러 프로세서는 성능 모델을 이용하여 각각의 프로세서(300, 400)에서 작업을 수행할 때 걸리는 시간을 추정하여 완료 시간을 계산하는 단계(S340)를 수행하며, 프로세서 가운데 완료 시간이 빠른 프로세서를 선택하여 프로세서-작업 짝을 지정하고 해당 작업을 프로세서에 할당할 때 발생하는 유휴 시간을 계산하는 단계(S350) 및 모든 프로세서-작업 짝 중 유휴 시간이 가장 짧은 작업을 선택하여 스케쥴링하는 단계(S360)를 수행할 수 있다. 테스크 컨트롤러 프 로세서는 후보 작업이 프로세서에 예약되면 스케쥴링 테이블을 업데이트할 수 있다. 도 8은 본 발명의 실시예에 따른 본 발명의 실시예에 따른 다중 신경망을 위한 확장 가능한 벡터 어레이 이종 가속 장치의 외부 메모리 접근 알고리즘을 설명하기 위한 순서도이다. 도 8을 참조하면, 외부 메모리 접근 알고리즘은 테스크 컨트롤러 프로세서가 스케쥴링 테이블로부터 이전 외부 메모리 접근 완료 시간을 확인하여 임시 메모리 준비 시간을 지정하는 단계(S410)를 포함한다. 테스크 컨트롤러 프로세서는 후보 작업으로부터 연산에 필요한 파라미터 및 액티베이션의 크기를 확인하는 단계(S420)를 수행하고, 공유 메모리를 확인하여 실제 외부 메모리로부터 가져와야 할 파라미터와 액 티베이션의 크기를 확인한다(S430). 이어서 임시 메모리 준비 시간을 지정하는 일련의 단계가 수행되는데, 임시 메모리 준비 시간은 메모리로 부터 가장 최근에 데이터를 가져온 시간으로 설정된다. 테스크 컨트롤러 프로세서는 외부 메모리로부 터 가져올 데이터가 있는지 여부를 확인한다(S440). 만약 외부 메모리로부터 가져올 데이터가 있다면 공유 메모리의 남은 용량을 고려하여 필요한 데이터를 가져오고 해당 시간을 임시 메모리 준비 시간으로 지정한 다(S450). 만약 외부 메모리로부터 가져올 데이터가 없다면 임시 메모리 준비 시간을 메모리 준비 시간으 로 지정할 수 있다(S480). 한편, 테스크 컨트롤러 프로세서는 공유 메모리의 남은 용량으로 인해 외부 메모리로부터 가져 올 데이터가 남아 있는지 여부를 판단하여(S460), 스케쥴링된 작업이 완료될 때까지 기다리고 해당 시간을 임시 메모리 준비 시간으로 지정한다(S470). 이때 완료된 작업에서 사용한 파라미터 및 액티베이션이 다른 스케쥴링 된 작업에서 사용되는지 여부에 따라 해당 파라미터 및 액티베이션은 공유 메모리로부터 삭제되어 여유 공 간이 확보될 수 있다. 상술한 과정을 반복하여 작업에 필요한 모든 메모리를 외부 메모리로부터 가져오면,그때의 임시 메모리 준비 시간을 메모리 준비 시간으로 지정하고(S480) 메모리 준비 시간의 계산을 완료할 수 있다. 도 9는 본 발명의 실시예에 따른 다중 신경망을 위한 확장 가능한 벡터 어레이 이종 가속 장치가 이종 구조 인 식 스케쥴링 및 외부 메모리 접근 알고리즘을 이용하는 경우의 효과를 설명하기 위한 도면이다. 도 9를 참조하면, 기존의 라운드 로빈 방식에 의한 스케쥴링과 본 발명의 이종 구조 인식 스케쥴링 및 외 부 메모리 접근 알고리즘에 의한 스케쥴링의 예시적인 시나리오가 비교된다. 기존의 라운드 로빈 방식에 의한 스케쥴링에서 어레이 프로세서와 벡터 프로세서의 그래프가 포함되며, 본 발명의 스케쥴링 에서 어레이 프로세서와 벡터 프로세서의 그래프가 포함된다. 각각의 요청(Request1~3)는 각각 다른 색으로 표시되며 숫자는 각 요청에 포함된 작업의 순서를 의미한다. 본 발명의 스케쥴링의 경우 요청 1의 두번째 작업보다 요청 3의 두번째 작업을 먼저 스케쥴링하여 벡터 프 로세서의 유휴 시간을 감소시킬 수 있다. 요청 3의 세번째 작업이 필요한 파라미터가 많은 경우를 가정할 때, 라운드 로빈 스케쥴링에서는 요청 2의 세번째 작업의 파라미터를 가져올 수 없어서 벡터 프로세서 는 요청 3의 세번째 작업이 완료될 때까지 기다리게 된다. 한편, 본 발명의 스케쥴링의 경우 요청 3의 세번째 작업을 하위 작업으로 나누어 각각의 하위 작업으로 나 누어 각각의 하위 작업에 대한 메모리 요구 용량을 감소시킬 수 있다. 하위 작업이 완료될 때마다 이후 스케쥴 링된 작업에서 사용되지 않는 파라미터들은 삭제되어 공유 메모리의 오버헤드를 감소시킬 수 있다. 또한, 요청 3의 네번째 작업은 프로세서-작업 짝 중 유휴 시간이 가장 짧은 작업을 기준으로 어레이 프로세서 대 신 벡터 프로세서에 할당함으로써 어레이 프로세서의 부하 및 총 소요 시간을 감소시킬 수 있다. 이 와 같이, 본 발명의 벡터 어레이 이종 가속 장치는 스케쥴링을 통해 다중 신경망 모델 계산에 필요한 작업 속도를 향상시킬 수 있다."}
{"patent_id": "10-2023-0038496", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "이상 첨부된 도면을 참조하여 본 발명의 실시예를 설명하였지만, 본 발명이 속하는 기술분야에서 통상의 지식을 가진 자는 본 발명이 그 기술적 사상이나 필수적인 특징을 변경하지 않고서 다른 구체적인 형태로 실시될 수 있 다는 것을 이해할 수 있을 것이다. 그러므로 이상에서 기술한 실시예들은 모든 면에서 예시적인 것이며 한정적 이 아닌 것으로 이해해야만 한다."}
{"patent_id": "10-2023-0038496", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 실시예에 따른 다중 신경망을 위한 확장 가능한 벡터 어레이 이종 가속 장치를 설명하기 위한 도면이다. 도 2a 및 2b는 본 발명의 실시예에 따른 다중 신경망을 위한 확장 가능한 벡터 어레이 이종 가속 장치가 처리하 는 신경망 요청이 포함된 딥러닝 모델 기술 통합 포맷을 설명하기 위한 도면이다. 도 3은 본 발명의 실시예에 따른 다중 신경망을 위한 확장 가능한 벡터 어레이 이종 가속 장치에 포함된 신경망 요청 분배기의 동작을 설명하기 위한 순서도이다. 도 4는 본 발명의 실시예에 따른 다중 신경망을 위한 확장 가능한 벡터 어레이 이종 가속 장치에 포함된 벡터- 어레이 클러스터의 동작을 설명하기 위한 순서도이다. 도 5는 본 발명의 실시예에 따른 다중 신경망을 위한 확장 가능한 벡터 어레이 이종 가속 장치에 포함된 벡터 프로세서의 구조를 설명하기 위한 도면이다. 도 6은 본 발명의 실시예에 따른 다중 신경망을 위한 확장 가능한 벡터 어레이 이종 가속 장치에 포함된 어레이 프로세서의 구조를 설명하기 위한 도면이다. 도 7은 본 발명의 실시예에 따른 다중 신경망을 위한 확장 가능한 벡터 어레이 이종 가속 장치의 이종 구조 인 식 스케쥴링을 설명하기 위한 순서도이다. 도 8은 본 발명의 실시예에 따른 본 발명의 실시예에 따른 다중 신경망을 위한 확장 가능한 벡터 어레이 이종 가속 장치의 외부 메모리 접근 알고리즘을 설명하기 위한 순서도이다. 도 9는 본 발명의 실시예에 따른 다중 신경망을 위한 확장 가능한 벡터 어레이 이종 가속 장치가 이종 구조 인 식 스케쥴링 및 외부 메모리 접근 알고리즘을 이용하는 경우의 효과를 설명하기 위한 도면이다."}
