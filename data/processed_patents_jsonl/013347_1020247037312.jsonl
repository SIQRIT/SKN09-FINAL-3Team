{"patent_id": "10-2024-7037312", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0167091", "출원번호": "10-2024-7037312", "발명의 명칭": "디지털 휴먼의 생성 방법, 모델의 트레이닝 방법, 장치, 기기 및 매체", "출원인": "베이징 바이두 넷컴 사이언스 테크놀로지 컴퍼니", "발명자": "우 톈"}}
{"patent_id": "10-2024-7037312", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "디지털 휴먼의 생성 방법으로서,소재 콘텐츠를 획득하는 단계; 사전 트레이닝된 장면 분할 모델에 기반하여, 상기 소재 콘텐츠에서 복수의 장면을 결정하되, 상기 복수의 장면들 중 각 장면은 상기 소재 콘텐츠 중 완전한 시맨틱 정보를 구비하는 하나의 콘텐츠 프래그먼트에 각각 대응되는 단계; 및 상기 복수의 장면들 중 각 장면에 대해, 대응되는 콘텐츠 프래그먼트에 기반하여, 상기 장면에 대응되는 타겟 콘텐츠를 결정하는 단계; 상기 대응되는 타겟 콘텐츠에 기반하여, 상기 장면의 장면 태그 정보를 결정하는 단계; 및 상기 장면 태그 정보에 기반하여, 상기 장면에 특정되는 디지털 휴먼을 구성하는 단계를 포함하는 디지털 휴먼의 생성 방법."}
{"patent_id": "10-2024-7037312", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 소재 콘텐츠를 획득하는 단계는,웹사이트에 기반하여, 상기 소재 콘텐츠를 획득하는 단계; 또는검색 키워드에 기반하여, 상기 소재 콘텐츠를 획득하는 단계 중 적어도 하나에 기반하여 상기 소재 콘텐츠를 획득하는 단계를 포함하는 디지털 휴먼의 생성 방법."}
{"patent_id": "10-2024-7037312", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항 또는 제2항에 있어서,상기 소재 콘텐츠는 이미지 데이터 및 비디오 데이터 중 적어도 하나 및 텍스트 데이터를 포함하는 디지털 휴먼의 생성 방법."}
{"patent_id": "10-2024-7037312", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항 내지 제3항 중 어느 한 항에 있어서, 사전 트레이닝된 장면 분할 모델에 기반하여, 상기 소재 콘텐츠에서 복수의 장면을 결정하는 단계는,상기 소재 콘텐츠에 대해 섹션 구조 분석 및 섹션 시맨틱 분할을 수행하여, 상기 소재 콘텐츠에서 복수의 서브테마를 결정하고, 상기 복수의 서브 테마 사이의 구조 관계를 결정하는 단계; 및 상기 구조 관계에 기반하여, 상기 복수의 서브 테마를 상기 복수의 장면으로 분할하는 단계를 포함하는 디지털휴먼의 생성 방법."}
{"patent_id": "10-2024-7037312", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서,상기 복수의 장면들 중 각 장면에 대해, 대응되는 콘텐츠 프래그먼트에 기반하여, 상기 장면에 대응되는 타겟콘텐츠를 결정하는 단계는, 상기 장면과 바로 전 장면 사이의 구조 관계에 기반하여, 상기 장면을 위한 제1 콘텐츠를 생성하는 단계를 포함하는 디지털 휴먼의 생성 방법. 공개특허 10-2024-0167091-3-청구항 6 제4항 또는 제5항에 있어서, 상기 복수의 장면들 중 각 장면에 대해, 대응되는 콘텐츠 프래그먼트에 기반하여, 상기 장면에 대응되는 타겟콘텐츠를 결정하는 단계는,사전 트레이닝된 스타일 변환 모델에 기반하여, 상기 대응되는 콘텐츠 프래그먼트를 상기 대응되는 타겟 콘텐츠로 변환시키는 단계를 포함하되, 상기 스타일 변환 모델은 프롬프트 러닝에 기반하여 트레이닝되어 얻은 것인디지털 휴먼의 생성 방법."}
{"patent_id": "10-2024-7037312", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6항에 있어서,상기 복수의 장면들 중 각 장면에 대해, 대응되는 콘텐츠 프래그먼트에 기반하여, 상기 장면에 대응되는 타겟콘텐츠를 결정하는 단계는,상기 대응되는 콘텐츠 프래그먼트에 대해 텍스트 다시 쓰기 및 텍스트 압축 중 적어도 하나의 처리를 수행하여,상기 대응되는 콘텐츠 프래그먼트를 업데이트하는 단계; 및 변환된 상기 타겟 콘텐츠에 대해 텍스트 다시 쓰기 및 텍스트 압축 중 적어도 하나의 처리를 수행하여, 상기 대응되는 타겟 콘텐츠를 업데이트하는 단계 중 적어도 하나를 더 포함하는 디지털 휴먼의 생성 방법."}
{"patent_id": "10-2024-7037312", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1항 내지 제7항 중 어느 한 항에 있어서,상기 장면 태그 정보는 시맨틱 태그를 포함하고, 상기 복수의 장면들 중 각 장면에 대해, 상기 대응되는 타겟콘텐츠에 기반하여, 상기 장면의 장면 태그 정보를 결정하는 단계는,상기 대응되는 타겟 콘텐츠에 대해 감성 분석을 수행하여, 상기 시맨틱 태그를 획득하는 단계를 포함하는 디지털 휴먼의 생성 방법."}
{"patent_id": "10-2024-7037312", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서,상기 시맨틱 태그는 상기 대응되는 타겟 콘텐츠가 표현하는 긍정, 중립 또는 부정을 포함하는 감정을 마킹하기위한 것인 디지털 휴먼의 생성 방법."}
{"patent_id": "10-2024-7037312", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제8항 또는 제9항에 있어서,상기 복수의 장면들 중 각 장면에 대해, 상기 태그 정보에 기반하여, 상기 장면에 특정되는 디지털 휴먼을 구성하는 단계는,상기 시맨틱 태그에 기반하여, 상기 디지털 휴먼의 복식, 표정 및 동작 중 적어도 하나를 구성하는 단계를 포함하는 디지털 휴먼의 생성 방법."}
{"patent_id": "10-2024-7037312", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제10항에 있어서,상기 타겟 콘텐츠를 음성으로 변환하여 상기 디지털 휴먼이 재생하도록 하는 단계를 더 포함하는 디지털 휴먼의생성 방법."}
{"patent_id": "10-2024-7037312", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항에 있어서,상기 복수의 장면들 중 각 장면에 대해, 상기 장면 태그 정보에 기반하여, 상기 장면에 특정되는 디지털 휴먼을공개특허 10-2024-0167091-4-구성하는 단계는,상기 시맨틱 태그에 기반하여, 상기 디지털 휴먼 음성의 톤을 구성하는 단계를 더 포함하는 디지털 휴먼의 생성방법."}
{"patent_id": "10-2024-7037312", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제1항 내지 제12항 중 어느 한 항에 있어서,홀로그램 이미지의 형태로 상기 디지털 휴먼을 나타내는 단계를 더 포함하는 디지털 휴먼의 생성 방법."}
{"patent_id": "10-2024-7037312", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제1항 내지 제12항 중 어느 한 항에 있어서,비디오의 형태로 상기 디지털 휴먼을 나타내는 단계를 더 포함하는 디지털 휴먼의 생성 방법."}
{"patent_id": "10-2024-7037312", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제14항에 있어서,상기 복수의 장면들 중 각 장면에 대해, 상기 소재 콘텐츠 및 상기 장면에 대응되는 타겟 콘텐츠에 기반하여, 상기 장면과 관련되는 비디오 소재를 서칭하는 단계; 및 상기 비디오 소재와 상기 디지털 휴먼을 결합하는 단계를 더 포함하는 디지털 휴먼의 생성 방법."}
{"patent_id": "10-2024-7037312", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제15항에 있어서,상기 복수의 장면들 중 각 장면에 대해, 상기 소재 콘텐츠 및 상기 장면에 대응되는 타겟 콘텐츠에 기반하여,상기 장면과 관련되는 비디오 소재를 서칭하는 단계는,장면 키워드를 추출하는 단계; 및 상기 장면 키워드에 기반하여, 상기 장면과 관련되는 비디오 소재를 서칭하는 단계를 포함하는 디지털 휴먼의생성 방법."}
{"patent_id": "10-2024-7037312", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제15항 또는 제16항에 있어서,상기 복수의 장면들 중 각 장면에 대해, 상기 소재 콘텐츠 및 상기 장면에 대응되는 타겟 콘텐츠에 기반하여,상기 장면과 관련되는 비디오 소재를 서칭하는 단계는,문장 수준 키워드를 추출하는 단계; 및 상기 문장 수준 키워드에 기반하여, 상기 장면과 관련되는 비디오 소재를 서칭하는 단계를 포함하는 디지털 휴먼의 생성 방법."}
{"patent_id": "10-2024-7037312", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제17항에 있어서,상기 문장 수준 키워드에 기반하여, 서칭된 비디오 소재와 상기 타겟 콘텐츠를 정렬하는 단계를 더 포함하는 디지털 휴먼의 생성 방법."}
{"patent_id": "10-2024-7037312", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제15항 내지 제18항 중 어느 한 항에 있어서,상기 비디오 소재에 특정 소재가 포함되는 것으로 결정된 것에 응답하여, 상기 비디오 소재에서 상기 특정 소재의 디스플레이 위치에 기반하여, 상기 디지털 휴먼의 동작을 결정하는 단계를 더 포함하는 디지털 휴먼의 생성공개특허 10-2024-0167091-5-방법."}
{"patent_id": "10-2024-7037312", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제14항 내지 제19항 중 어느 한 항에 있어서,상기 복수의 장면들 중 각 장면에 대해, 상기 장면에 대응되는 타겟 콘텐츠에서 키-값 형태의 정보를 추출하는 단계; 및 상기 키-값 형태의 정보에 기반하여, 상기 비디오를 위한 보조 소재를 생성하는 단계를 더 포함하는 디지털 휴먼의 생성 방법."}
{"patent_id": "10-2024-7037312", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_21", "content": "제15항 내지 제20항 중 어느 한 항에 있어서,상기 비디오 소재에 대응되는 장면에 소요되는 재생 시간의 점유율을 결정하는 단계; 및 상기 점유율에 기반하여, 상응한 장면에서 상기 디지털 휴먼이 트리거되는지 여부를 결정하는 단계를 더 포함하는 디지털 휴먼의 생성 방법."}
{"patent_id": "10-2024-7037312", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_22", "content": "장면 분할 모델의 트레이닝 방법으로서,샘플 소재 콘텐츠 및 상기 샘플 소재 콘텐츠 중의 복수의 샘플 장면을 획득하는 단계; 기설정 장면 분할 모델에 기반하여, 상기 샘플 소재 콘텐츠에서 복수의 예측 장면을 결정하는 단계; 및 상기 복수의 샘플 장면 및 상기 복수의 예측 장면에 기반하여 상기 기설정 장면 분할 모델의 파라미터를 조정하여, 트레이닝된 장면 분할 모델을 얻는 단계를 포함하는 장면 분할 모델의 트레이닝 방법."}
{"patent_id": "10-2024-7037312", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_23", "content": "제22항에 있어서,상기 기설정 장면 분할 모델은 섹션 시맨틱 분할 모델 및 섹션 구조 분석 모델을 포함하되, 기설정 장면 분할모델에 기반하여, 상기 샘플 소재 콘텐츠에서 복수의 예측 장면을 결정하는 단계는,상기 섹션 시맨틱 분할 모델 및 상기 섹션 구조 분석 모델을 이용하여 상기 샘플 소재 콘텐츠를 처리하여, 상기소재 콘텐츠 중 복수의 예측 서브 테마 및 상기 복수의 예측 서브 테마 사이의 예측 구조 관계를 결정하는단계; 및 상기 예측 구조 관계에 기반하여, 상기 복수의 예측 서브 테마를 상기 복수의 예측 장면으로 분할하는 단계를포함하는 장면 분할 모델의 트레이닝 방법."}
{"patent_id": "10-2024-7037312", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_24", "content": "디지털 휴먼의 생성 장치로서,소재 콘텐츠를 획득하도록 구성되는 제1 획득 유닛; 사전 트레이닝된 장면 분할 모델에 기반하여, 상기 소재 콘텐츠에서 복수의 장면을 결정하도록 구성되되, 상기복수의 장면들 중 각 장면은 상기 소재 콘텐츠 중 완전한 시맨틱 정보를 구비하는 하나의 콘텐츠 프래그먼트에각각 대응되는 제1 결정 유닛; 상기 복수의 장면들 중 각 장면에 대해, 대응되는 콘텐츠 프래그먼트에 기반하여, 상기 장면에 대응되는 타겟콘텐츠를 결정하도록 구성되는 제2 결정 유닛; 상기 대응되는 타겟 콘텐츠에 기반하여, 상기 장면의 장면 태그 정보를 결정하도록 구성되는 제3 결정 유닛; 및 상기 장면 태그 정보에 기반하여, 상기 장면에 특정되는 디지털 휴먼을 구성하도록 구성되는 디지털 휴먼 구성유닛을 포함하는 디지털 휴먼의 생성 장치. 공개특허 10-2024-0167091-6-청구항 25 제24항에 있어서,상기 제1 획득 유닛은 또한,웹사이트에 기반하여, 상기 소재 콘텐츠를 획득하는 것; 또는검색 키워드에 기반하여, 상기 소재 콘텐츠를 획득하는 것 중 적어도 하나의 방식에 기반하여, 상기 소재 콘텐츠를 획득하도록 구성되는 디지털 휴먼의 생성 장치."}
{"patent_id": "10-2024-7037312", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_26", "content": "제24항 또는 제25항에 있어서,상기 소재 콘텐츠는 이미지 데이터 및 비디오 데이터 중 적어도 하나 및 텍스트 데이터를 포함하는 디지털 휴먼의 생성 장치."}
{"patent_id": "10-2024-7037312", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_27", "content": "제24항 내지 제26항 중 어느 한 항에 있어서,상기 제1 결정 유닛은,상기 소재 콘텐츠에 대해 섹션 구조 분석 및 섹션 시맨틱 분할을 수행하여, 상기 소재 콘텐츠에서 복수의 서브테마를 결정하고, 상기 복수의 서브 테마 사이의 구조 관계를 결정하도록 구성되는 제1 결정 서브 유닛; 및 상기 구조 관계에 기반하여, 상기 복수의 서브 테마를 상기 복수의 장면으로 분할하도록 구성되는 제1 분할 서브 유닛을 포함하는 디지털 휴먼의 생성 장치."}
{"patent_id": "10-2024-7037312", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_28", "content": "제27항에 있어서, 상기 제2 결정 유닛은,상기 장면과 바로 전 장면 사이의 구조 관계에 기반하여, 상기 장면을 위한 제1 콘텐츠를 생성하도록 구성되는생성 서브 유닛을 포함하는 디지털 휴먼의 생성 장치."}
{"patent_id": "10-2024-7037312", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_29", "content": "제27항 또는 제28항에 있어서,상기 제2 결정 유닛은,사전 트레이닝된 스타일 변환 모델에 기반하여, 상기 대응되는 콘텐츠 프래그먼트를 상기 대응되는 타겟 콘텐츠로 변환시키도록 구성되는 변환 서브 유닛을 포함하고, 상기 스타일 변환 모델은 프롬프트 러닝에 기반하여 트레이닝되어 얻은 것인 디지털 휴먼의 생성 장치."}
{"patent_id": "10-2024-7037312", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_30", "content": "제29항에 있어서,상기 제2 결정 유닛은,상기 대응되는 콘텐츠 프래그먼트에 대해 텍스트 다시 쓰기 및 텍스트 압축 중 적어도 하나의 처리를 수행하여,상기 대응되는 콘텐츠 프래그먼트를 업데이트하도록 구성되는 제1 업데이트 서브 유닛; 및 변환된 상기 타겟 콘텐츠에 대해 텍스트 다시 쓰기 및 텍스트 압축 중 적어도 하나의 처리를 수행하여, 상기 대응되는 타겟 콘텐츠를 업데이트하도록 구성되는 제2 업데이트 서브 유닛 중 적어도 하나를 포함하는 디지털 휴먼의 생성 장치."}
{"patent_id": "10-2024-7037312", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_31", "content": "공개특허 10-2024-0167091-7-제24항 내지 제30항 중 어느 한 항에 있어서,상기 제3 결정 유닛은,상기 대응되는 타겟 콘텐츠에 대해 감성 분석을 수행하여, 상기 시맨틱 태그를 획득하도록 구성되는 감성 분석서브 유닛을 포함하는 디지털 휴먼의 생성 장치."}
{"patent_id": "10-2024-7037312", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_32", "content": "제31항에 있어서,상기 시맨틱 태그는 상기 대응되는 타겟 콘텐츠가 표현하는 긍정, 중립 또는 부정을 포함하는 감정을 마킹하기위한 것인 디지털 휴먼의 생성 장치."}
{"patent_id": "10-2024-7037312", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_33", "content": "제31항 또는 제32항에 있어서,상기 디지털 휴먼 구성 유닛은,상기 시맨틱 태그에 기반하여, 상기 디지털 휴먼의 복식, 표정 및 동작 중 적어도 하나를 구성하도록 구성되는제1 구성 서브 유닛을 포함하는 디지털 휴먼의 생성 장치."}
{"patent_id": "10-2024-7037312", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_34", "content": "제33항에 있어서,상기 타겟 콘텐츠를 음성으로 변환하여 상기 디지털 휴먼이 재생하도록 구성되는 음성 변환 유닛을 더 포함하는디지털 휴먼의 생성 장치."}
{"patent_id": "10-2024-7037312", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_35", "content": "제34항에 있어서,상기 디지털 휴먼 구성 유닛은,상기 시맨틱 태그에 기반하여, 상기 디지털 휴먼 음성의 톤을 구성하도록 구성되는 제2 구성 서브 유닛을 더 포함하는 디지털 휴먼의 생성 장치."}
{"patent_id": "10-2024-7037312", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_36", "content": "제24항 내지 제35항 중 어느 한 항에 있어서,홀로그램 이미지의 형태로 상기 디지털 휴먼을 나타내도록 구성되는 홀로그램 이미지 표현 유닛을 더 포함하는디지털 휴먼의 생성 장치."}
{"patent_id": "10-2024-7037312", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_37", "content": "제24항 내지 제35항 중 어느 한 항에 있어서,비디오의 형태로 상기 디지털 휴먼을 나타내도록 구성되는 비디오 표현 유닛을 더 포함하는 디지털 휴먼의 생성장치."}
{"patent_id": "10-2024-7037312", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_38", "content": "제37항에 있어서,상기 복수의 장면들 중 각 장면에 대해, 상기 소재 콘텐츠 및 상기 장면에 대응되는 타겟 콘텐츠에 기반하여,상기 장면과 관련되는 비디오 소재를 서칭하도록 구성되는 서치 유닛; 및 상기 비디오 소재와 상기 디지털 휴먼을 결합하도록 구성되는 결합 유닛을 더 포함하는 디지털 휴먼의 생성 장치."}
{"patent_id": "10-2024-7037312", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_39", "content": "공개특허 10-2024-0167091-8-제38항에 있어서, 상기 서치 유닛은,장면 키워드를 추출하도록 구성되는 제1 추출 서브 유닛; 및 상기 장면 키워드에 기반하여, 상기 장면과 관련되는 비디오 소재를 서칭하도록 구성되는 제1 서치 서브 유닛을포함하는 디지털 휴먼의 생성 장치."}
{"patent_id": "10-2024-7037312", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_40", "content": "제38항 또는 제39항에 있어서,상기 서치 유닛은,문장 수준 키워드를 추출하도록 구성되는 제2 추출 서브 유닛; 및 상기 문장 수준 키워드에 기반하여, 상기 장면과 관련되는 비디오 소재를 서칭하도록 구성되는 제2 서치 서브유닛을 포함하는 디지털 휴먼의 생성 장치."}
{"patent_id": "10-2024-7037312", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_41", "content": "제40항에 있어서,상기 문장 수준 키워드에 기반하여, 서칭된 비디오 소재와 상기 타겟 콘텐츠를 정렬하도록 구성되는 정렬 유닛을 더 포함하는 디지털 휴먼의 생성 장치."}
{"patent_id": "10-2024-7037312", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_42", "content": "제38항 내지 제41항 중 어느 한 항에 있어서,상기 비디오 소재에 특정 소재가 포함되는 것으로 결정된 것에 응답하여, 상기 비디오 소재에서 상기 특정 소재의 디스플레이 위치에 기반하여, 상기 디지털 휴먼의 동작을 결정하도록 구성되는 제4 결정 유닛을 더 포함하는디지털 휴먼의 생성 장치."}
{"patent_id": "10-2024-7037312", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_43", "content": "제37항 내지 제42항 중 어느 한 항에 있어서,상기 복수의 장면들 중 각 장면에 대해, 상기 장면에 대응되는 타겟 콘텐츠에서 키-값 형태의 정보를 추출하도록 구성되는 추출 유닛; 및 상기 키-값 형태의 정보에 기반하여, 상기 비디오를 위한 보조 소재를 생성하도록 구성되는 생성 유닛을 더 포함하는 디지털 휴먼의 생성 장치."}
{"patent_id": "10-2024-7037312", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_44", "content": "제38항 내지 제43항 중 어느 한 항에 있어서,상기 비디오 소재에 대응되는 장면에 소요되는 재생 시간의 점유율을 결정하도록 구성되는 제5 결정 유닛; 및 상기 점유율에 기반하여, 상응한 장면에서 상기 디지털 휴먼이 트리거되는지 여부를 결정하도록 구성되는 제6결정 유닛을 더 포함하는 디지털 휴먼의 생성 장치."}
{"patent_id": "10-2024-7037312", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_45", "content": "장면 분할 모델의 트레이닝 장치로서,샘플 소재 콘텐츠 및 상기 샘플 소재 콘텐츠 중의 복수의 샘플 장면을 획득하도록 구성되는 제2 획득 유닛; 기설정 장면 분할 모델에 기반하여, 상기 샘플 소재 콘텐츠에서 복수의 예측 장면을 결정하도록 구성되는 제7결정 유닛; 및 상기 복수의 샘플 장면 및 상기 복수의 예측 장면에 기반하여 상기 기설정 장면 분할 모델의 파라미터를 조정하공개특허 10-2024-0167091-9-여, 트레이닝된 장면 분할 모델을 얻도록 구성되는 트레이닝 유닛을 포함하는 장면 분할 모델의 트레이닝 장치."}
{"patent_id": "10-2024-7037312", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_46", "content": "제45항에 있어서,상기 기설정 장면 분할 모델은 섹션 시맨틱 분할 모델 및 섹션 구조 분석 모델을 포함하되, 상기 제7 결정 유닛은,상기 섹션 시맨틱 분할 모델 및 상기 섹션 구조 분석 모델을 이용하여 상기 샘플 소재 콘텐츠를 처리하여, 상기소재 콘텐츠 중 복수의 예측 서브 테마 및 상기 복수의 예측 서브 테마 사이의 예측 구조 관계를 결정하도록 구성되는 제2 결정 서브 유닛; 및 상기 예측 구조 관계에 기반하여, 상기 복수의 예측 서브 테마를 상기 복수의 예측 장면으로 분할하도록 구성되는 제2 분할 서브 유닛을 포함하는 장면 분할 모델의 트레이닝 장치."}
{"patent_id": "10-2024-7037312", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_47", "content": "전자 기기로서,적어도 하나의 프로세서; 및상기 적어도 하나의 프로세서와 통신 연결되는 메모리를 포함하되;상기 메모리에는 상기 적어도 하나의 프로세서에 의해 실행 가능한 명령이 저장되며, 상기 명령은 상기 적어도하나의 프로세서에 의해 실행되어, 상기 적어도 하나의 프로세서가 제1항 내지 제23항 중 어느 한 항에 따른 방법을 수행할 수 있도록 하는 전자 기기."}
{"patent_id": "10-2024-7037312", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_48", "content": "컴퓨터 명령이 저장되는 비일시적 컴퓨터 판독 가능 저장 매체로서,상기 컴퓨터 명령은 상기 컴퓨터가 제1항 내지 제23항 중 어느 한 항에 따른 방법을 수행하도록 하는 비일시적컴퓨터 판독 가능 저장 매체."}
{"patent_id": "10-2024-7037312", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_49", "content": "컴퓨터 프로그램 제품으로서, 컴퓨터 프로그램을 포함하되, 상기 컴퓨터 프로그램이 프로세서에 의해 실행될 경우 제1항 내지 제23항 중 어느 한 항에 따른 방법을 구현하는 컴퓨터 프로그램 제품."}
{"patent_id": "10-2024-7037312", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 디지털 휴먼의 생성 방법, 모델의 트레이닝 방법, 장치, 기기 및 매체를 제공하는 바, 인공 지능 분야 에 관한 것으로, 구체적으로 자연 언어 처리, 딥러닝, 컴퓨터 비전, 이미지 처리, 증강 현실 및 가상 현실 등"}
{"patent_id": "10-2024-7037312", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "에 관한 것이며, 메타버스 등 장면에 응용될 수 있다. 실시 형태는 아래와 같은 바, 소재 콘텐츠를 획득 하고; 사전 트레이닝된 장면 분할 모델에 기반하여, 소재 콘텐츠에서 복수의 장면을 결정하되, 여기서, 복수의 장면들 중 각 장면은 소재 콘텐츠 중 완전한 시맨틱 정보를 구비하는 하나의 콘텐츠 프래그먼트에 각각 대응되고; 복수의 장면들 중 각 장면에 대해, 대응되는 콘텐츠 프래그먼트에 기반하여, 상기 장면에 대응되는 타 겟 콘텐츠를 결정하고; 대응되는 타겟 콘텐츠에 기반하여, 상기 장면의 장면 태그 정보를 결정하며; 장면 태그 정보에 기반하여, 상기 장면에 특정되는 디지털 휴먼을 구성한다. 대 표 도 - 도2"}
{"patent_id": "10-2024-7037312", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 2, "content": "공개특허10-2024-0167091 CPC특허분류 G06F 40/30 (2020.01) G06T 13/205 (2013.01) G06V 10/774 (2023.08) G06V 10/82 (2022.01) 발명자 샤오 신옌 중국 100085 베이징 하이뎬 디스트릭트 샹디 10티 에이치 스트리트 넘버 10, 바이두 캠퍼스 2층 류 하오 중국 100085 베이징 하이뎬 디스트릭트 샹디 10티 에이치 스트리트 넘버 10, 바이두 캠퍼스 2층 류 자천 중국 100085 베이징 하이뎬 디스트릭트 샹디 10티 에이치 스트리트 넘버 10, 바이두 캠퍼스 2층서 차오차오 중국 100085 베이징 하이뎬 디스트릭트 샹디 10티 에이치 스트리트 넘버 10, 바이두 캠퍼스 2층 엘브이 야쥐안 중국 100085 베이징 하이뎬 디스트릭트 샹디 10티 에이치 스트리트 넘버 10, 바이두 캠퍼스 2층명 세 서 청구범위 청구항 1 디지털 휴먼의 생성 방법으로서, 소재 콘텐츠를 획득하는 단계; 사전 트레이닝된 장면 분할 모델에 기반하여, 상기 소재 콘텐츠에서 복수의 장면을 결정하되, 상기 복수의 장면 들 중 각 장면은 상기 소재 콘텐츠 중 완전한 시맨틱 정보를 구비하는 하나의 콘텐츠 프래그먼트에 각각 대응되 는 단계; 및 상기 복수의 장면들 중 각 장면에 대해, 대응되는 콘텐츠 프래그먼트에 기반하여, 상기 장면에 대응되는 타겟 콘텐츠를 결정하는 단계; 상기 대응되는 타겟 콘텐츠에 기반하여, 상기 장면의 장면 태그 정보를 결정하는 단계; 및 상기 장면 태그 정보에 기반하여, 상기 장면에 특정되는 디지털 휴먼을 구성하는 단계를 포함하는 디지털 휴먼 의 생성 방법. 청구항 2 제1항에 있어서, 소재 콘텐츠를 획득하는 단계는, 웹사이트에 기반하여, 상기 소재 콘텐츠를 획득하는 단계; 또는 검색 키워드에 기반하여, 상기 소재 콘텐츠를 획득하는 단계 중 적어도 하나에 기반하여 상기 소재 콘텐츠를 획 득하는 단계를 포함하는 디지털 휴먼의 생성 방법. 청구항 3 제1항 또는 제2항에 있어서, 상기 소재 콘텐츠는 이미지 데이터 및 비디오 데이터 중 적어도 하나 및 텍스트 데이터를 포함하는 디지털 휴먼 의 생성 방법. 청구항 4 제1항 내지 제3항 중 어느 한 항에 있어서, 사전 트레이닝된 장면 분할 모델에 기반하여, 상기 소재 콘텐츠에서 복수의 장면을 결정하는 단계는, 상기 소재 콘텐츠에 대해 섹션 구조 분석 및 섹션 시맨틱 분할을 수행하여, 상기 소재 콘텐츠에서 복수의 서브 테마를 결정하고, 상기 복수의 서브 테마 사이의 구조 관계를 결정하는 단계; 및 상기 구조 관계에 기반하여, 상기 복수의 서브 테마를 상기 복수의 장면으로 분할하는 단계를 포함하는 디지털 휴먼의 생성 방법. 청구항 5 제4항에 있어서, 상기 복수의 장면들 중 각 장면에 대해, 대응되는 콘텐츠 프래그먼트에 기반하여, 상기 장면에 대응되는 타겟 콘텐츠를 결정하는 단계는, 상기 장면과 바로 전 장면 사이의 구조 관계에 기반하여, 상기 장면을 위한 제1 콘텐츠를 생성하는 단계를 포함 하는 디지털 휴먼의 생성 방법. 청구항 6 제4항 또는 제5항에 있어서, 상기 복수의 장면들 중 각 장면에 대해, 대응되는 콘텐츠 프래그먼트에 기반하여, 상기 장면에 대응되는 타겟 콘텐츠를 결정하는 단계는, 사전 트레이닝된 스타일 변환 모델에 기반하여, 상기 대응되는 콘텐츠 프래그먼트를 상기 대응되는 타겟 콘텐츠 로 변환시키는 단계를 포함하되, 상기 스타일 변환 모델은 프롬프트 러닝에 기반하여 트레이닝되어 얻은 것인 디지털 휴먼의 생성 방법. 청구항 7 제6항에 있어서, 상기 복수의 장면들 중 각 장면에 대해, 대응되는 콘텐츠 프래그먼트에 기반하여, 상기 장면에 대응되는 타겟 콘텐츠를 결정하는 단계는, 상기 대응되는 콘텐츠 프래그먼트에 대해 텍스트 다시 쓰기 및 텍스트 압축 중 적어도 하나의 처리를 수행하여, 상기 대응되는 콘텐츠 프래그먼트를 업데이트하는 단계; 및 변환된 상기 타겟 콘텐츠에 대해 텍스트 다시 쓰기 및 텍스트 압축 중 적어도 하나의 처리를 수행하여, 상기 대 응되는 타겟 콘텐츠를 업데이트하는 단계 중 적어도 하나를 더 포함하는 디지털 휴먼의 생성 방법. 청구항 8 제1항 내지 제7항 중 어느 한 항에 있어서, 상기 장면 태그 정보는 시맨틱 태그를 포함하고, 상기 복수의 장면들 중 각 장면에 대해, 상기 대응되는 타겟 콘텐츠에 기반하여, 상기 장면의 장면 태그 정보를 결정하는 단계는, 상기 대응되는 타겟 콘텐츠에 대해 감성 분석을 수행하여, 상기 시맨틱 태그를 획득하는 단계를 포함하는 디지 털 휴먼의 생성 방법. 청구항 9 제8항에 있어서, 상기 시맨틱 태그는 상기 대응되는 타겟 콘텐츠가 표현하는 긍정, 중립 또는 부정을 포함하는 감정을 마킹하기 위한 것인 디지털 휴먼의 생성 방법. 청구항 10 제8항 또는 제9항에 있어서, 상기 복수의 장면들 중 각 장면에 대해, 상기 태그 정보에 기반하여, 상기 장면에 특정되는 디지털 휴먼을 구성 하는 단계는, 상기 시맨틱 태그에 기반하여, 상기 디지털 휴먼의 복식, 표정 및 동작 중 적어도 하나를 구성하는 단계를 포함 하는 디지털 휴먼의 생성 방법. 청구항 11 제10항에 있어서, 상기 타겟 콘텐츠를 음성으로 변환하여 상기 디지털 휴먼이 재생하도록 하는 단계를 더 포함하는 디지털 휴먼의 생성 방법. 청구항 12 제11항에 있어서, 상기 복수의 장면들 중 각 장면에 대해, 상기 장면 태그 정보에 기반하여, 상기 장면에 특정되는 디지털 휴먼을구성하는 단계는, 상기 시맨틱 태그에 기반하여, 상기 디지털 휴먼 음성의 톤을 구성하는 단계를 더 포함하는 디지털 휴먼의 생성 방법. 청구항 13 제1항 내지 제12항 중 어느 한 항에 있어서, 홀로그램 이미지의 형태로 상기 디지털 휴먼을 나타내는 단계를 더 포함하는 디지털 휴먼의 생성 방법. 청구항 14 제1항 내지 제12항 중 어느 한 항에 있어서, 비디오의 형태로 상기 디지털 휴먼을 나타내는 단계를 더 포함하는 디지털 휴먼의 생성 방법. 청구항 15 제14항에 있어서, 상기 복수의 장면들 중 각 장면에 대해, 상기 소재 콘텐츠 및 상기 장면에 대응되는 타겟 콘텐츠에 기반하여, 상기 장면과 관련되는 비디오 소재를 서칭 하는 단계; 및 상기 비디오 소재와 상기 디지털 휴먼을 결합하는 단계를 더 포함하는 디지털 휴먼의 생성 방법. 청구항 16 제15항에 있어서, 상기 복수의 장면들 중 각 장면에 대해, 상기 소재 콘텐츠 및 상기 장면에 대응되는 타겟 콘텐츠에 기반하여, 상기 장면과 관련되는 비디오 소재를 서칭하는 단계는, 장면 키워드를 추출하는 단계; 및 상기 장면 키워드에 기반하여, 상기 장면과 관련되는 비디오 소재를 서칭하는 단계를 포함하는 디지털 휴먼의 생성 방법. 청구항 17 제15항 또는 제16항에 있어서, 상기 복수의 장면들 중 각 장면에 대해, 상기 소재 콘텐츠 및 상기 장면에 대응되는 타겟 콘텐츠에 기반하여, 상기 장면과 관련되는 비디오 소재를 서칭하는 단계는, 문장 수준 키워드를 추출하는 단계; 및 상기 문장 수준 키워드에 기반하여, 상기 장면과 관련되는 비디오 소재를 서칭하는 단계를 포함하는 디지털 휴 먼의 생성 방법. 청구항 18 제17항에 있어서, 상기 문장 수준 키워드에 기반하여, 서칭된 비디오 소재와 상기 타겟 콘텐츠를 정렬하는 단계를 더 포함하는 디 지털 휴먼의 생성 방법. 청구항 19 제15항 내지 제18항 중 어느 한 항에 있어서, 상기 비디오 소재에 특정 소재가 포함되는 것으로 결정된 것에 응답하여, 상기 비디오 소재에서 상기 특정 소재 의 디스플레이 위치에 기반하여, 상기 디지털 휴먼의 동작을 결정하는 단계를 더 포함하는 디지털 휴먼의 생성방법. 청구항 20 제14항 내지 제19항 중 어느 한 항에 있어서, 상기 복수의 장면들 중 각 장면에 대해, 상기 장면에 대응되는 타겟 콘텐츠에서 키-값 형태의 정보를 추출하는 단계; 및 상기 키-값 형태의 정보에 기반하여, 상기 비디오를 위한 보조 소재를 생성하는 단계를 더 포함하는 디지털 휴 먼의 생성 방법. 청구항 21 제15항 내지 제20항 중 어느 한 항에 있어서, 상기 비디오 소재에 대응되는 장면에 소요되는 재생 시간의 점유율을 결정하는 단계; 및 상기 점유율에 기반하여, 상응한 장면에서 상기 디지털 휴먼이 트리거되는지 여부를 결정하는 단계를 더 포함하 는 디지털 휴먼의 생성 방법. 청구항 22 장면 분할 모델의 트레이닝 방법으로서, 샘플 소재 콘텐츠 및 상기 샘플 소재 콘텐츠 중의 복수의 샘플 장면을 획득하는 단계; 기설정 장면 분할 모델에 기반하여, 상기 샘플 소재 콘텐츠에서 복수의 예측 장면을 결정하는 단계; 및 상기 복수의 샘플 장면 및 상기 복수의 예측 장면에 기반하여 상기 기설정 장면 분할 모델의 파라미터를 조정하 여, 트레이닝된 장면 분할 모델을 얻는 단계를 포함하는 장면 분할 모델의 트레이닝 방법. 청구항 23 제22항에 있어서, 상기 기설정 장면 분할 모델은 섹션 시맨틱 분할 모델 및 섹션 구조 분석 모델을 포함하되, 기설정 장면 분할 모델에 기반하여, 상기 샘플 소재 콘텐츠에서 복수의 예측 장면을 결정하는 단계는, 상기 섹션 시맨틱 분할 모델 및 상기 섹션 구조 분석 모델을 이용하여 상기 샘플 소재 콘텐츠를 처리하여, 상기 소재 콘텐츠 중 복수의 예측 서브 테마 및 상기 복수의 예측 서브 테마 사이의 예측 구조 관계를 결정하는 단계; 및 상기 예측 구조 관계에 기반하여, 상기 복수의 예측 서브 테마를 상기 복수의 예측 장면으로 분할하는 단계를 포함하는 장면 분할 모델의 트레이닝 방법. 청구항 24 디지털 휴먼의 생성 장치로서, 소재 콘텐츠를 획득하도록 구성되는 제1 획득 유닛; 사전 트레이닝된 장면 분할 모델에 기반하여, 상기 소재 콘텐츠에서 복수의 장면을 결정하도록 구성되되, 상기 복수의 장면들 중 각 장면은 상기 소재 콘텐츠 중 완전한 시맨틱 정보를 구비하는 하나의 콘텐츠 프래그먼트에 각각 대응되는 제1 결정 유닛; 상기 복수의 장면들 중 각 장면에 대해, 대응되는 콘텐츠 프래그먼트에 기반하여, 상기 장면에 대응되는 타겟 콘텐츠를 결정하도록 구성되는 제2 결정 유닛; 상기 대응되는 타겟 콘텐츠에 기반하여, 상기 장면의 장면 태그 정보를 결정하도록 구성되는 제3 결정 유닛; 및 상기 장면 태그 정보에 기반하여, 상기 장면에 특정되는 디지털 휴먼을 구성하도록 구성되는 디지털 휴먼 구성 유닛을 포함하는 디지털 휴먼의 생성 장치. 청구항 25 제24항에 있어서, 상기 제1 획득 유닛은 또한, 웹사이트에 기반하여, 상기 소재 콘텐츠를 획득하는 것; 또는 검색 키워드에 기반하여, 상기 소재 콘텐츠를 획득하는 것 중 적어도 하나의 방식에 기반하여, 상기 소재 콘텐 츠를 획득하도록 구성되는 디지털 휴먼의 생성 장치. 청구항 26 제24항 또는 제25항에 있어서, 상기 소재 콘텐츠는 이미지 데이터 및 비디오 데이터 중 적어도 하나 및 텍스트 데이터를 포함하는 디지털 휴먼 의 생성 장치. 청구항 27 제24항 내지 제26항 중 어느 한 항에 있어서, 상기 제1 결정 유닛은, 상기 소재 콘텐츠에 대해 섹션 구조 분석 및 섹션 시맨틱 분할을 수행하여, 상기 소재 콘텐츠에서 복수의 서브 테마를 결정하고, 상기 복수의 서브 테마 사이의 구조 관계를 결정하도록 구성되는 제1 결정 서브 유닛; 및 상기 구조 관계에 기반하여, 상기 복수의 서브 테마를 상기 복수의 장면으로 분할하도록 구성되는 제1 분할 서 브 유닛을 포함하는 디지털 휴먼의 생성 장치. 청구항 28 제27항에 있어서, 상기 제2 결정 유닛은, 상기 장면과 바로 전 장면 사이의 구조 관계에 기반하여, 상기 장면을 위한 제1 콘텐츠를 생성하도록 구성되는 생성 서브 유닛을 포함하는 디지털 휴먼의 생성 장치. 청구항 29 제27항 또는 제28항에 있어서, 상기 제2 결정 유닛은, 사전 트레이닝된 스타일 변환 모델에 기반하여, 상기 대응되는 콘텐츠 프래그먼트를 상기 대응되는 타겟 콘텐츠 로 변환시키도록 구성되는 변환 서브 유닛을 포함하고, 상기 스타일 변환 모델은 프롬프트 러닝에 기반하여 트 레이닝되어 얻은 것인 디지털 휴먼의 생성 장치. 청구항 30 제29항에 있어서, 상기 제2 결정 유닛은, 상기 대응되는 콘텐츠 프래그먼트에 대해 텍스트 다시 쓰기 및 텍스트 압축 중 적어도 하나의 처리를 수행하여, 상기 대응되는 콘텐츠 프래그먼트를 업데이트하도록 구성되는 제1 업데이트 서브 유닛; 및 변환된 상기 타겟 콘텐츠에 대해 텍스트 다시 쓰기 및 텍스트 압축 중 적어도 하나의 처리를 수행하여, 상기 대 응되는 타겟 콘텐츠를 업데이트하도록 구성되는 제2 업데이트 서브 유닛 중 적어도 하나를 포함하는 디지털 휴 먼의 생성 장치. 청구항 31 제24항 내지 제30항 중 어느 한 항에 있어서, 상기 제3 결정 유닛은, 상기 대응되는 타겟 콘텐츠에 대해 감성 분석을 수행하여, 상기 시맨틱 태그를 획득하도록 구성되는 감성 분석 서브 유닛을 포함하는 디지털 휴먼의 생성 장치. 청구항 32 제31항에 있어서, 상기 시맨틱 태그는 상기 대응되는 타겟 콘텐츠가 표현하는 긍정, 중립 또는 부정을 포함하는 감정을 마킹하기 위한 것인 디지털 휴먼의 생성 장치. 청구항 33 제31항 또는 제32항에 있어서, 상기 디지털 휴먼 구성 유닛은, 상기 시맨틱 태그에 기반하여, 상기 디지털 휴먼의 복식, 표정 및 동작 중 적어도 하나를 구성하도록 구성되는 제1 구성 서브 유닛을 포함하는 디지털 휴먼의 생성 장치. 청구항 34 제33항에 있어서, 상기 타겟 콘텐츠를 음성으로 변환하여 상기 디지털 휴먼이 재생하도록 구성되는 음성 변환 유닛을 더 포함하는 디지털 휴먼의 생성 장치. 청구항 35 제34항에 있어서, 상기 디지털 휴먼 구성 유닛은, 상기 시맨틱 태그에 기반하여, 상기 디지털 휴먼 음성의 톤을 구성하도록 구성되는 제2 구성 서브 유닛을 더 포 함하는 디지털 휴먼의 생성 장치. 청구항 36 제24항 내지 제35항 중 어느 한 항에 있어서, 홀로그램 이미지의 형태로 상기 디지털 휴먼을 나타내도록 구성되는 홀로그램 이미지 표현 유닛을 더 포함하는 디지털 휴먼의 생성 장치. 청구항 37 제24항 내지 제35항 중 어느 한 항에 있어서, 비디오의 형태로 상기 디지털 휴먼을 나타내도록 구성되는 비디오 표현 유닛을 더 포함하는 디지털 휴먼의 생성 장치. 청구항 38 제37항에 있어서, 상기 복수의 장면들 중 각 장면에 대해, 상기 소재 콘텐츠 및 상기 장면에 대응되는 타겟 콘텐츠에 기반하여, 상기 장면과 관련되는 비디오 소재를 서칭하도록 구성되는 서치 유닛; 및 상기 비디오 소재와 상기 디지털 휴먼을 결합하도록 구성되는 결합 유닛을 더 포함하는 디지털 휴먼의 생성 장 치. 청구항 39 제38항에 있어서, 상기 서치 유닛은, 장면 키워드를 추출하도록 구성되는 제1 추출 서브 유닛; 및 상기 장면 키워드에 기반하여, 상기 장면과 관련되는 비디오 소재를 서칭하도록 구성되는 제1 서치 서브 유닛을 포함하는 디지털 휴먼의 생성 장치. 청구항 40 제38항 또는 제39항에 있어서, 상기 서치 유닛은, 문장 수준 키워드를 추출하도록 구성되는 제2 추출 서브 유닛; 및 상기 문장 수준 키워드에 기반하여, 상기 장면과 관련되는 비디오 소재를 서칭하도록 구성되는 제2 서치 서브 유닛을 포함하는 디지털 휴먼의 생성 장치. 청구항 41 제40항에 있어서, 상기 문장 수준 키워드에 기반하여, 서칭된 비디오 소재와 상기 타겟 콘텐츠를 정렬하도록 구성되는 정렬 유닛 을 더 포함하는 디지털 휴먼의 생성 장치. 청구항 42 제38항 내지 제41항 중 어느 한 항에 있어서, 상기 비디오 소재에 특정 소재가 포함되는 것으로 결정된 것에 응답하여, 상기 비디오 소재에서 상기 특정 소재 의 디스플레이 위치에 기반하여, 상기 디지털 휴먼의 동작을 결정하도록 구성되는 제4 결정 유닛을 더 포함하는 디지털 휴먼의 생성 장치. 청구항 43 제37항 내지 제42항 중 어느 한 항에 있어서, 상기 복수의 장면들 중 각 장면에 대해, 상기 장면에 대응되는 타겟 콘텐츠에서 키-값 형태의 정보를 추출하도 록 구성되는 추출 유닛; 및 상기 키-값 형태의 정보에 기반하여, 상기 비디오를 위한 보조 소재를 생성하도록 구성되는 생성 유닛을 더 포 함하는 디지털 휴먼의 생성 장치. 청구항 44 제38항 내지 제43항 중 어느 한 항에 있어서, 상기 비디오 소재에 대응되는 장면에 소요되는 재생 시간의 점유율을 결정하도록 구성되는 제5 결정 유닛; 및 상기 점유율에 기반하여, 상응한 장면에서 상기 디지털 휴먼이 트리거되는지 여부를 결정하도록 구성되는 제6 결정 유닛을 더 포함하는 디지털 휴먼의 생성 장치. 청구항 45 장면 분할 모델의 트레이닝 장치로서, 샘플 소재 콘텐츠 및 상기 샘플 소재 콘텐츠 중의 복수의 샘플 장면을 획득하도록 구성되는 제2 획득 유닛; 기설정 장면 분할 모델에 기반하여, 상기 샘플 소재 콘텐츠에서 복수의 예측 장면을 결정하도록 구성되는 제7 결정 유닛; 및 상기 복수의 샘플 장면 및 상기 복수의 예측 장면에 기반하여 상기 기설정 장면 분할 모델의 파라미터를 조정하여, 트레이닝된 장면 분할 모델을 얻도록 구성되는 트레이닝 유닛을 포함하는 장면 분할 모델의 트레이닝 장치. 청구항 46 제45항에 있어서, 상기 기설정 장면 분할 모델은 섹션 시맨틱 분할 모델 및 섹션 구조 분석 모델을 포함하되, 상기 제7 결정 유닛 은, 상기 섹션 시맨틱 분할 모델 및 상기 섹션 구조 분석 모델을 이용하여 상기 샘플 소재 콘텐츠를 처리하여, 상기 소재 콘텐츠 중 복수의 예측 서브 테마 및 상기 복수의 예측 서브 테마 사이의 예측 구조 관계를 결정하도록 구 성되는 제2 결정 서브 유닛; 및 상기 예측 구조 관계에 기반하여, 상기 복수의 예측 서브 테마를 상기 복수의 예측 장면으로 분할하도록 구성되 는 제2 분할 서브 유닛을 포함하는 장면 분할 모델의 트레이닝 장치. 청구항 47 전자 기기로서, 적어도 하나의 프로세서; 및 상기 적어도 하나의 프로세서와 통신 연결되는 메모리를 포함하되; 상기 메모리에는 상기 적어도 하나의 프로세서에 의해 실행 가능한 명령이 저장되며, 상기 명령은 상기 적어도 하나의 프로세서에 의해 실행되어, 상기 적어도 하나의 프로세서가 제1항 내지 제23항 중 어느 한 항에 따른 방 법을 수행할 수 있도록 하는 전자 기기. 청구항 48 컴퓨터 명령이 저장되는 비일시적 컴퓨터 판독 가능 저장 매체로서, 상기 컴퓨터 명령은 상기 컴퓨터가 제1항 내지 제23항 중 어느 한 항에 따른 방법을 수행하도록 하는 비일시적 컴퓨터 판독 가능 저장 매체. 청구항 49 컴퓨터 프로그램 제품으로서, 컴퓨터 프로그램을 포함하되, 상기 컴퓨터 프로그램이 프로세서에 의해 실행될 경 우 제1항 내지 제23항 중 어느 한 항에 따른 방법을 구현하는 컴퓨터 프로그램 제품. 발명의 설명 기 술 분 야 관련 출원에 대한 상호 참조 본 발명은 2022년 6월 15일에 제출된 중국 특허 출원 202210681368.3의 우선권을 주장하며, 그 전체 내용은 참 조로 여기에 포함된다. 본 발명은 인공 지능 분야에 관한 것으로, 구체적으로 자연 언어 처리, 딥러닝, 컴퓨터 비전, 이미지 처리, 증 강 현실 및 가상 현실 등 기술 분야에 관한 것이며, 메타버스 등 장면에 응용될 수 있고, 특히는 디지털 휴먼의 생성 방법, 신경망의 트레이닝 방법, 비디오 생성 장치, 신경망의 트레이닝 장치, 전자 기기, 컴퓨터 판독 가능 저장 매체 및 컴퓨터 프로그램 제품에 관한 것이다."}
{"patent_id": "10-2024-7037312", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "인공 지능은 컴퓨터를 사용하여 하드웨어 수준과 소프트웨어 수준에서 인간의 특정 사고 프로세스와 지능적 행 동(예컨대 학습, 추론, 사고, 계획 등)을 시뮬레이션하는 학문이다. 인공 지능 하드웨어 기술은 일반적으로 센 서, 인공 지능 전용칩, 클라우드 컴퓨팅, 분산식 저장, 빅데이터 처리 등의 기술을 포함하고; 인공 지능 소프트 웨어는 주요하게 컴퓨터 비전 기술, 음성 인식 기술, 자연어 처리 기술 및 머신 러닝/딥러닝, 빅데이터 처리 기 술, 지식 스펙트럼 기술 등 몇 가지 방향을 포함한다. 디지털 휴먼은 컴퓨터 기술을 이용하여 인체의 형태와 기능을 시뮬레이션하는 기술이다. 디지털 휴먼은 애플리 케이션의 상호 작용성을 뚜렷하게 향상하고, 스마트 정보 서비스의 지능화 수준을 강화시킨다. 인공 지능 기술 의 지속적인 혁신으로 인해, 디지털 휴먼의 형상, 표정, 표현은 점차 실제 사람에 가까워지고 있으며, 디지털 휴먼의 응용 장면도 계속 확장되고 디지털 휴먼은 점차 디지털 세계의 중요한 업무 형태로 되어간다. 여기서 설명된 방식은 반드시 이전에 구상되거나 또는 채택된 방법이 아니다. 달리 명시되지 않는 한, 이 부분 에 설명된 방식이 이 부분에 포함된다는 이유만으로 선행 기술로 인정되는 것으로 간주해서는 안된다. 마찬가지 로, 달리 명시되지 않는 한, 이 부분에서 설명된 문제는 임의의 선행 기술에서 공인된 것으로 간주하여서는 아 니된다."}
{"patent_id": "10-2024-7037312", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명에서는 디지털 휴먼의 생성 방법, 신경망의 트레이닝 방법, 비디오 생성 장치, 신경망의 트레이닝 장치, 전자 기기, 컴퓨터 판독 가능 저장 매체 및 컴퓨터 프로그램 제품을 제공한다."}
{"patent_id": "10-2024-7037312", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 일 양태에 따르면, 디지털 휴먼의 생성 방법을 제공하는 바, 방법은, 소재 콘텐츠를 획득하는 단계; 사전 트레이닝된 장면 분할 모델에 기반하여, 소재 콘텐츠에서 복수의 장면을 결정하되, 복수의 장면들 중 각 장면은 소재 콘텐츠 중 완전한 시맨틱 정보를 구비하는 하나의 콘텐츠 프래그먼트에 각각 대응되는 단계; 및 복 수의 장면들 중 각 장면에 대해, 대응되는 콘텐츠 프래그먼트에 기반하여, 상기 장면에 대응되는 타겟 콘텐츠를 결정하는 단계; 대응되는 타겟 콘텐츠에 기반하여, 상기 장면의 장면 태그 정보를 결정하는 단계; 및 장면 태그 정보에 기반하여, 상기 장면에 특정되는 디지털 휴먼을 구성하는 단계를 포함한다. 본 발명의 다른 양태에 따르면, 장면 분할 모델의 트레이닝 방법을 제공하는 바, 방법은, 샘플 소재 콘텐츠 및 샘플 소재 콘텐츠 중의 복수의 샘플 장면을 획득하는 단계; 기설정 장면 분할 모델에 기반하여, 샘플 소재 콘텐 츠에서 복수의 예측 장면을 결정하는 단계; 및 복수의 샘플 장면 및 복수의 예측 장면에 기반하여 기설정 장면 분할 모델의 파라미터를 조정하여, 트레이닝된 장면 분할 모델을 얻는 단계를 포함한다. 본 발명의 다른 양태에 따르면, 디지털 휴먼의 생성 장치를 제공하는 바, 장치는, 소재 콘텐츠를 획득하도록 구 성되는 제1 획득 유닛; 사전 트레이닝된 장면 분할 모델에 기반하여, 소재 콘텐츠에서 복수의 장면을 결정하도 록 구성되되, 복수의 장면들 중 각 장면은 소재 콘텐츠 중 완전한 시맨틱 정보를 구비하는 하나의 콘텐츠 프래 그먼트에 각각 대응되는 제1 결정 유닛; 복수의 장면들 중 각 장면에 대해, 대응되는 콘텐츠 프래그먼트에 기반 하여, 상기 장면에 대응되는 타겟 콘텐츠를 결정하도록 구성되는 제2 결정 유닛; 대응되는 타겟 콘텐츠에 기반 하여, 상기 장면의 장면 태그 정보를 결정하도록 구성되는 제3 결정 유닛; 및 장면 태그 정보에 기반하여, 상기 장면에 특정되는 디지털 휴먼을 구성하도록 구성되는 디지털 휴먼 구성 유닛을 포함한다. 본 발명의 다른 양태에 따르면, 장면 분할 모델의 트레이닝 장치를 제공하는 바, 장치는, 샘플 소재 콘텐츠 및 샘플 소재 콘텐츠 중의 복수의 샘플 장면을 획득하도록 구성되는 제3 획득 유닛; 기설정 장면 분할 모델에 기반 하여, 샘플 소재 콘텐츠에서 복수의 예측 장면을 결정하도록 구성되는 제7 결정 유닛; 및 복수의 샘플 장면 및 복수의 예측 장면에 기반하여 기설정 장면 분할 모델의 파라미터를 조정하여, 트레이닝된 장면 분할 모델을 얻 도록 구성되는 트레이닝 유닛을 포함한다. 본 발명의 다른 양태에 따르면, 전자 기기를 제공하는 바, 전자 기기는, 적어도 하나의 프로세서; 및 적어도 하 나의 프로세서와 통신 연결되는 메모리를 포함하되; 여기서 메모리에는 적어도 하나의 프로세서에 의해 실행 가 능한 명령이 저장되며, 이러한 명령은 적어도 하나의 프로세서에 의해 실행되어, 적어도 하나의 프로세서가 상 기 방법을 수행할 수 있도록 한다. 본 발명의 다른 양태에 따르면, 컴퓨터 명령이 저장되는 비일시적 컴퓨터 판독 가능 저장 매체를 제공하는 바, 여기서, 컴퓨터 명령은 컴퓨터가 상기 방법을 수행하도록 한다. 본 발명의 다른 양태에 따르면, 컴퓨터 프로그램을 포함하는 컴퓨터 프로그램 제품을 제공하는 바, 상기 컴퓨터 프로그램이 프로세서에 의해 실행될 경우 상기 방법을 구현한다."}
{"patent_id": "10-2024-7037312", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명의 하나 이상의 실시예에 따르면, 소재 콘텐츠에 대해 장면 분할을 수행하고, 장면을 입도로 디지털 휴 먼의 구성을 수행함으로써, 디지털 휴먼과 장면 및 타겟 콘텐츠의 일치성을 확보하여, 소재 콘텐츠와 디지털 휴 먼 사이의 융합을 개선하여, 사용자가 디지털 휴먼을 관람하는 체험감을 향상시킨다. 본 부분에서 설명된 내용은 본 발명의 실시예의 주요하거나 중요한 특징을 나타내려는 것이 아니고, 본 발명의 범위를 한정하기 위한 것도 아님을 반드시 이해해야 한다. 본 발명의 다른 특징은 하기의 명세서를 통해 쉽게 이해될 것이다."}
{"patent_id": "10-2024-7037312", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "아래 도면과 결부시켜 본 발명의 예시적 실시예를 설명하되, 여기에 이해를 돕기 위한 본 발명의 실시예의 다양"}
{"patent_id": "10-2024-7037312", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "한 세부사항들이 포함되지만, 이들은 단지 예시적인 것으로 이해해야 한다. 따라서, 본 기술분야의 통상의 기술 자는 본 발명의 범위 및 정신을 벗어나지 않는 전제 하에 여기서 설명된 실시예에 대해 다양한 변형 및 수정을 진행할 수 있음을 이해해야 한다. 마찬가지로, 명확 및 간략을 위해, 아래의 설명에서 공지 기능 및 구조에 대 한 설명을 생략한다. 본 발명에서, 달리 명시하지 않는 한, 용어 \"제1\", \"제2\" 등을 사용하여 다양한 요소가 이러한 요소의 위치 관 계, 시간 관계 또는 중요성 관계를 한정하도록 의도하지 않음을 서술하며, 이러한 용어는 단지 하나의 요소와 다른 하나의 요소를 구분하기 위한 것이다. 일부 구현예에서, 제1 요소와 제2 요소는 상기 요소의 동일한 실례 를 가리키며, 일부 경우, 상하 문장의 서술에 기반하여 이들은 상이한 실례를 가리킬 수도 있다. 본 발명 중 다양한 상기 예시된 설명에서 사용되는 용어는 단지 특정 구현예를 설명하기 위한 목적으로, 이를 한정하지 않는다. 앞뒤 문장에서 명시하지 않는 한, 요소의 수를 특별히 제한하지 않는다면 상기 요소는 하나일 수도 있고 복수일 수도 있다. 또한, 본 발명에서 사용되는 용어 \"및/또는\"은 열거된 항목 중의 임의의 하나 및 전부의 가능한 조합 방식을 포함한다. 비디오는 디지털 세계에서 가장 중요한 정보 매체 중 하나이며, 디지털 휴먼은 자연스레 비디오 생산에서 중요 한 응용 공간을 갖는다. 현재, 디지털 휴먼은 이미 비디오 생산에 사용되는 바, 예컨대 디지털 휴먼을 통해 뉴 스를 재생하고, 디지털 휴먼 형상을 이용하여 홍보한다. 그러나, 관련 기술에서, 비디오에서 디지털 휴먼의 활용은 주요하게 템플릿에 기반하여 수행되는 바, 예컨대 디지털 휴먼을 고정하여 재생하고, 디지털 휴먼이 재생 될 시 디지털 휴먼과 콘텐츠가 분리되는 것이 발생할 수 있으며, 재생 콘텐츠와 디지털 휴먼의 형상이 매칭되지 않아 사용자 체험감이 떨어질 수 있다. 다른 일부 관련 기술에서는 디지털 휴먼의 아이콘에 대한 정밀한 구축을 중점적으로 주목하며, 그 목적은 디지털 휴먼의 형상을 전시하는 것을 위주로 한다. 이러한 방식은 일부 허구 및 공상 과학 장면을 지향하며, 실제 정보의 재생에서는 응용하기 어렵다. 또한, 이러한 장면은 주요하게 형상 을 전시하는 것으로, 디지털 휴먼의 다양한 속성은 재생되는 콘텐츠와 무관하다. 상기 과제를 해결하기 위해, 본 발명 소재 콘텐츠에 대해 장면 분할을 수행하고, 장면을 입도로 디지털 휴먼의 구성을 수행함으로써, 디지털 휴먼과 장면 및 타겟 콘텐츠의 일치성을 확보하여, 소재 콘텐츠와 디지털 휴먼 사 이의 융합을 개선하여, 사용자가 디지털 휴먼을 관람하는 체험감을 향상시킨다. 아래 도면과 결부하여 본 발명의 실시예를 상세하게 설명하도록 한다. 도 1은 본 발명의 실시예에 따라 그중에서 본문에서 설명된 다양한 방법을 실시하는 예시적 시스템의 모식 도이다. 도 1을 참조하면, 상기 시스템은 하나 이상의 클라이언트 기기(101, 102, 103, 104, 105 및 106), 서버 및 하나 이상의 클라이언트 기기를 서버에 커플링시키는 하나 이상의 통신 네트워크(11 0)를 포함한다. 클라이언트 기기(101, 102, 103, 104, 105 및 106)는 하나 이상의 응용 프로그램을 실행하도록 구성될 수 있다. 본 발명의 실시예에서, 서버는 디지털 휴먼의 생성 방법 및/또는 장면 분할 모델의 트레이닝 방법을 수행 할 수 있는 하나 이상의 서비스 또는 소프트웨어 애플리케이션을 실행할 수 있다. 일부 실시예에서, 서버는 다른 서비스 또는 소프트웨어 애플리케이션을 더 제공할 수 있으며, 이러한 서비 스 또는 소프트웨어 애플리케이션은 비가상 환경 및 가상 환경을 포함할 수 있다. 일부 실시예에서, 이러한 서 비스는 web 기반 서비스 또는 클라우드 서비스로 제공될 수 있는 바, 예를 들면 서비스형 소프트웨어(SaaS) 모 델 하에 클라이언트 기기(101, 102, 103, 104, 105 및/또는 106)의 사용자에 제공된다. 도 1에 도시된 구성에서, 서버는 서버에 의해 실행되는 기능을 구현하는 하나 이상의 컴포넌트를 포 함할 수 있다. 이러한 컴포넌트는 하나 이상의 프로세서에 의해 실행되는 소프트웨어 컴포넌트, 하드웨어 컴포 넌트 또는 그 조합을 포함할 수 있다. 클라이언트 기기(101, 102, 103, 104, 105 및/또는 106)를 작동하는 사용 자는 하나 이상의 클라이언트 응용 프로그램을 순차적으로 이용하여 서버와 인터랙팅하여 이러한 컴포넌트 에 의해 제공되는 서비스를 이용한다. 반드시 이해해야 하는 바, 다양한 상이한 시스템 구성은 가능한 것이며, 이는 시스템과 상이할 수 있다. 따라서, 도 1은 본문에 설명되는 다양한 방법의 시스템의 하나의 구현예를 실시하기 위한 것으로 이를 한정하지 않는다. 사용자는 클라이언트 기기(101, 102, 103, 104, 105 및/또는 106)를 사용하여 디지털 휴먼의 생성과 관련되는 파라미터를 입력할 수 있다. 클라이언트 기기는 클라이언트 기기의 사용자가 클라이언트 기기와 인터랙팅하도록 하는 인터페이스를 제공할 수 있다. 클라이언트 기기는 상기 인터페이스를 거쳐 사용자에게 정보를 출력할 수도 있는 바, 예를 들면, 사용자에게 디지털 휴먼 생성 결과를 출력한다. 비록 도 1에서는 단지 6가지 클라이언트 기기를 서술하였으나, 본 발명은 임의의 수의 클라이언트 기기를 지원할 수 있음을 당업자는 이해할 수 있다. 클라이언트 기기(101, 102, 103, 104, 105 및/또는 106)는 예를 들면 휴대용 핸드헬드 기기, 범용 컴퓨터(예컨 대 개인 컴퓨터 및 랩톱 컴퓨터), 워크 스테이션 컴퓨터, 웨어러블 기기, 스마트 스크린 기기, 셀프 서비스 단 말 기기, 서비스 로봇, 게임 시스템, 신 클라이언트, 다양한 메세지 송수신 기기, 센서 또는 다른 센싱 기기 등 과 같은 다양한 유형의 컴퓨터 기기를 포함할 수 있다. 이러한 컴퓨터 기기는 예를 들면 MICROSOFT Windows, APPLE iOS, UNIX 계열 운영 체제, Linux 또는 Linux 계열 운영 체제(예를 들면 GOOGLE Chrome OS); 또는 예를 들면 MICROSOFT Windows Mobile OS, iOS, Windows Phone, Android와 같은 다양한 모바일 운영 체제를 포함하는 다양한 유형 및 버전의 소프트웨어 응용 프로그램 및 운영 체제를 운영시킬 수 있다. 휴대용 핸드헬드 기기는 셀룰러폰, 스마트폰, 태블릿 PC, 개인 휴대 정보 단말기(PDA) 등을 포함할 수 있다. 웨어러블 기기는 헤드 마운 트 디스플레이(예컨대 스마트 안경) 및 다른 기기를 포함할 수 있다. 게임 시스템은 다양한 핸드헬드 게임 기기, 인터넷 지원의 게임 기기 등을 포함할 수 있다. 클라이언트 기기는 예를 들면 Internet과 관련된 응용 프 로그램, 통신 응용 프로그램(예를 들면 이메일 응용 프로그램), 숏 메세지 서비스(SMS) 응용 프로그램과 같은 다양한 상이한 응용 프로그램을 실행할 수 있으며, 다양한 통신 프로토콜을 사용할 수 있다. 네트워크는 당업자에게 잘 알려진 임의의 유형의 네트워크일 수 있고, 이는 다양한 이용 가능한 프로토콜 중의 임의의 하나(TCP/IP, SNA, IPX 등을 포함하지만 이에 한하지 않음)를 이용하여 데이터 통신을 지원할 수있다. 단지 구현예로서, 하나 이상의 네트워크는 랜(LAN), 이더넷 기반 네트워크, 토큰 링, 광역 네트워크 (WAN), 인터넷, 가상 네트워크, 가상 전용 네트워크(VPN), 인트라넷, 엑스트라넷, 블록체인 네트워크, 공중전화 교환망(PSTN), 적외선 네트워크, 무선 네트워크(예를 들면 블루투스, WIFI) 및/또는 이들 및/또는 다른 네트워 크의 임의의 조합일 수 있다. 서버는 하나 이상의 범용 컴퓨터, 전용 서버 컴퓨터(예를 들면 PC(개인 컴퓨터)서버, UNIX서버, 중급 서버), 블레이드 서버, 대형 컴퓨터, 서버 클러스터 또는 임의의 적절한 배치 및/또는 조합을 포함할 수 있다. 서버는 가상 운영 체제를 실행하는 하나 이상의 가상 머신, 또는 가상화에 관련된 다른 컴퓨팅 아키텍처 (예를 들면 서버의 가상 저장 장치를 유지하기 위해 가상화될 수 있는 논리적 저장 장치의 하나 이상의 플렉시 블 풀)를 포함할 수 있다. 다양한 실시예에서, 서버는 아래에 기술된 기능을 제공하는 하나 이상의 서비스 또는 소프트웨어 애플리케이션을 실행할 수 있다. 서버 중 컴퓨팅 유닛은 상기 임의의 운영 체제 및 임의의 상업적으로 이용 가능한 서버 운영 체제를 포함 하는 하나 이상의 운영 체제를 실행할 수 있다. 서버는 다양한 부가 서버 응용 프로그램 및/또는 중간 계 층 응용 프로그램 중의 임의의 하나를 실행할 수도 있는 바, HTTP 서버, FTP 서버, CGI 서버, JAVA 서버, 데이 터 베이스 서버 등을 포함한다. 일부 실시형태에서, 서버는 하나 이상의 응용 프로그램을 포함하여, 클라이언트 기기(101, 102, 103, 104, 105 및/또는 106)의 사용자로부터 수신된 데이터 피드 및/또는 이벤트 업데이트를 분석 및 병합할 수 있다. 서 버는 하나 이상의 응용 프로그램을 포함하여, 클라이언트 기기(101, 102, 103, 104, 105 및/또는 106)의 하나 이상의 디스플레이 기기를 거쳐 데이터 피드 및/또는 실시간 이벤트를 디스플레이할 수도 있다. 일부 실시형태에서, 서버는 분산형 시스템의 서버, 또는 블록체인에 결합된 서버일 수 있다. 서버는 클라우드 서버일 수도 있고, 인공 지능 기술이 적용된 스마트 클라우드 컴퓨팅 서버 또는 스마트 클라우드 호스 트일 수 있다. 클라우드 서버는 클라우드 컴퓨팅 서비스 체계 중의 하나의 호스트 제품이며, 기존의 물리적 호 스트와 가상 전용 서버(VPS, Virtual Private Server) 서비스에 존재하는 관리 난이도가 높고 업무 확장성이 약 한 흠결을 해결한다. 시스템은 하나 이상의 데이터 베이스를 포함할 수도 있다. 일부 실시예에서, 이러한 데이터 베이스는 데이터 및 다른 정보를 저장할 수 있다. 예를 들면, 데이터 베이스 중의 하나 이상은 예컨대 오디오 파일 및 비디오 파일의 정보를 저장할 수 있다. 데이터 베이스는 다양한 위치에 상주할 수 있다. 예를 들면, 서 버에 의해 사용되는 데이터 베이스는 서버 로컬일 수 있거나, 서버로부터 원격일 수 있으며 네 트워크 기반 또는 전용 연결을 통해 서버와 통신할 수 있다. 데이터 베이스는 상이한 유형일 수 있다. 일부 실시예에서, 서버에 의해 사용되는 데이터 베이스는 예를 들면 관계 데이터 베이스일 수 있다. 이러한 데이터 베이스 중의 하나 이상은 명령에 응답하여 데이터 베이스 및 데이터 베이스에서 비롯된 데이터를 저장, 업데이트 및 서치할 수 있다. 일부 실시예에서, 데이터 베이스 중 하나 이상은 응용 프로그램의 사용으로 응용 프로그램 데이터를 저장 할 수도 있다. 응용 프로그램에 의해 사용되는 데이터 베이스는 예를 들면 키-값 저장소, 객체 저장소 또는 파 일 시스템에 의해 지원되는 일반 저장소와 같은 상이한 유형의 데이터 베이스일 수 있다. 도 1의 시스템은 다양한 방식으로 구성 및 작동되어 본 발명에 기술된 다양한 방법 및 장치를 응용하도록 할 수 있다. 본 발명의 일 양태에 따르면, 디지털 휴먼의 생성 방법을 제공한다. 도 2에 도시된 바와 같이, 상기 방법은 하 기의 단계를 포함하는 바, 단계 S201에서, 소재 콘텐츠를 획득하고; 단계 S202에서, 사전 트레이닝된 장면 분할 모델에 기반하여, 소재 콘텐츠에서 복수의 장면을 결정하며, 여기서, 복수의 장면들 중 각 장면은 소재 콘텐츠 중 완전한 시맨틱 정보를 구비하는 하나의 콘텐츠 프래그먼트에 각각 대응되고; 단계 S203에서, 복수의 장면들 중 각 장면에 대해, 대응되는 콘텐츠 프래그먼트에 기반하여, 상기 장면에 대응되는 타겟 콘텐츠를 결정하며; 단계 S204에서, 대응되는 타겟 콘텐츠에 기반하여, 상기 장면의 장면 태그 정보를 결정하고; 단계 S205에서, 장 면 태그 정보에 기반하여, 상기 장면에 특정되는 디지털 휴먼을 구성한다. 이로써, 소재 콘텐츠에 대해 장면 분할을 수행하고, 장면을 입도로 디지털 휴먼의 구성을 수행함으로써, 디지털 휴먼과 장면 및 타겟 콘텐츠의 일치성을 확보하여, 소재 콘텐츠와 디지털 휴먼 사이의 융합을 개선하여, 사용자 가 디지털 휴먼을 관람하는 체험감을 향상시킨다. 일부 실시예에 따르면, 디지털 휴먼의 생성을 시작하기 전에, 사용자가 운영 단말(예를 들면, 도 1 중의 클라이 언트 101-106 중의 어느 하나)을 통해 기본 구성 옵션을 설정하도록 지원할 수 있다. 구체적인 설정 내용은 아 래와 같다. 본 발명의 방법은 예를 들면 재생 장면, 해설 장면, 진행 장면 등과 같은 다양한 장면에 응용될 수 있다. 이해 할 수 있는 것은, 본 발명에서는 재생 장면을 예시로서 본 발명의 다양한 방법을 설명하지만, 본 발명의 보호 범위를 한정하려는 것이 아니다. 일부 실시예에서, 사용자가 소재 콘텐츠의 유형에 대해 선택 및 구성하도록 지원할 수 있다. 소재 콘텐츠의 유 형 및 대응되는 파일, 주소 또는 콘텐츠는, 텍스트 서류, 즉 구체적으로 텍스트 콘텐츠 또는 그래픽 콘텐츠 가 포함되는 서류; 문장 URL, 즉 디지털 휴먼의 생성을 희망하는 그래픽 콘텐츠에 대응되는 웹 사이트; 테마 키워드와 설명, 디지털 휴먼의 생성을 희망하는 테마 설명, 예컨대 엔티티 워드, 검색 키워드, 검색 문제 등 형식을 포함할 수 있다. 일부 예시적인 실시예에서, 소재 콘텐츠는 이미지 데이터 및 비디오 데이터 중 적어 도 하나 및 텍스트 데이터를 포함하여, 디지털 휴먼 재생, 진행, 또는 해설되는 콘텐츠를 풍부하게 할 수 있다. 일부 실시예에서, 사용자가 음성 재생(TTS, Text to Speech) 기능을 구성하도록 지원할 수 있고, 음성 재생 기 능의 활성화 여부, 음성 재생의 소리(예를 들면, 성별, 억양 등), 음색, 음량 및 어속 등을 포함한다. 일부 실시예에서, 사용자가 배경 음악을 구성할 수 있도록 지원하고, 배경 음악의 추가 여부, 추가된 배경 음악 의 유형 등을 포함한다. 일부 실시예에서, 사용자가 디지털 휴먼 자산을 설정할 수 있도록 지원하고, 기설정된 디지털 휴먼 자산 중 나 타나기를 희망하거나 사용되는 디지털 휴먼의 형상을 포함하거나, 맞춤화 방식을 통해 디지털 휴먼의 형상을 생 성하여, 디지털 휴먼 자산을 풍부하게 한다. 일부 실시예에서, 사용자가 디지털 휴먼 배경을 구성할 수 있도록 지원하고, 디지털 휴먼 배경의 추가 여부, 디 지털 휴먼 배경의 유형(예를 들면, 이미지 또는 비디오) 등을 포함한다. 일부 실시예에서, 사용자가 최종적으로 나타난 결과로서의 생성 방식을 구성할 수 있도록 지원하고, 완전 자동 비디오 생성, 인간-컴퓨터 상호작용 지원 비디오 생성 등을 선택하는 것 등을 포함한다. 이해할 수 있는 것은, 상기 콘텐츠 외에도, 입력 구성은 상황에 따라 사용자에게 더 많은 시스템 제어를 제공할 수도 있는 바, 예컨대 문안 압축의 비율, 최종적으로 프레젠테이션된 결과에서 사용되는 동적 소재 점유율 등이 며, 이로 한정되지 않는다. 일부 실시예에 따르면, 소재 콘텐츠를 획득하는 단계 S201은, 웹사이트에 기반하여, 소재 콘텐츠를 획득하는 것; 또는 검색 키워드에 기반하여, 소재 콘텐츠를 획득하는 것 중 적어도 하나의 방식에 기반하여, 소재 콘텐츠 를 획득하는 단계를 포함할 수 있다. 상기 몇 가지 상이한 유형의 소재 콘텐츠에 대해, 구체적으로 하기의 방식 을 사용하여 획득할 수 있도록 한다. 텍스트 서류에 대해, 로컬 또는 원격 저장된 텍스트 서류 중의 콘텐츠를 직접 판독한다. 문장 URL에 대해, 주요하게 예컨대 뉴스 문장, 게시판 문장, Q&A 페이지, 공식 계정 문장 등 콘텐츠의 URL과 같 은 인터넷에 이미 존재하는 그래픽 콘텐츠를 가리키는 바, 기존의 웹페이지 해석 오픈 소스 방안에 기반하여, URL에 대응되는 웹페이지 데이터를 획득하며, URL 웹페이지 중의 주체 텍스트 및 사진 콘텐츠를 해석하고 획득 하며, 동시에 제목, 본문, 단락, 볼드, 그래픽 위치 관계, 도표 등 중요한 원시 정보를 기록한다. 이러한 정보 는 후속적인 디지털 휴먼 생성 과정에서 사용되는 바, 예를 들면, 제목은 시각 소재를 서치하는 query로 사용될 수 있고, 본문, 단락, 및 볼트 콘텐츠는 재생 콘텐츠를 생성할 수 있고, 장면 키워드 추출 및 문장 수준 키워드 를 추출하며, 그래픽 위치 관계는 원문 중의 이미지 소재와 재생함 콘텐츠 사이의 대응 관계를 제공할 수 있고, 도표는 디지털 휴먼의 프레젠테이션된 결과 중의 콘텐츠 표현 형식을 풍부하게 할 수 있으며, 이러한 콘텐츠는 아래에서 상세하게 소개한다. 테마 키워드와 서술에 대해, 본 시스템은 사용자가 입력한 테마에 기반하여 최종적인 디지털 휴먼의 프레젠테이 션된 결과를 생성할 수도 있다. 사용자가 입력한 테마 키워드와 설명은 백과 사전의 엔티티 워드와 유사할 수 있고, 복수의 키워드일 수도 있으며, 이벤트 설명 또는 문제의 설명과 유사한 형식이다. 테마 키워드에 따라 그 래픽 콘텐츠를 획득하는 방식은 아래와 같다. 테마 키워드 또는 설명을 검색 엔진에 입력하고, 복수의 검색 피드백 결과를 획득하며, 검색 결과에서 연관성 순위가 높은 것을 선택하고, 동시에 시각 소재가 더 풍부한 그래픽 결과를 생성할 비디오 주체 URL로 사용하며, URL콘텐츠 추출 방식에 따라 URL 내의 그래픽콘텐츠 등 정보를 추출한다. 소재 콘텐츠를 획득한 후, 상기 소재 콘텐츠에 기반하여 디지털 휴먼이 재생하는 문안을 생성할 수 있다. 앞서 획득된 소재 콘텐츠에 따라, 시맨틱 이해 및 텍스트 생성 등 기술을 통해, 디지털 휴먼의 재생 요구에 결부하여 장면 분할, 문자 전환 및 생성을 수행해야 하며, 디지털 휴먼 비디오/홀로그램을 출력하여 필요한 스크립트 문 안을 투영 제작하고, 동시에 장면의 분할 및 시맨틱 분석 정보를 제공해야 한다. 소재 콘텐츠에 대한 상기 처리 는 디지털 휴먼 융합 방식을 결정하는 관건적인 기초이다. 구체적으로 말하자면, 하기의 방식을 통해 디지털 휴 먼 재생의 타겟 콘텐츠를 생성할 수 있다. 일부 실시예에서, 단계 S202에서, 사전 트레이닝된 장면 분할 모델에 기반하여, 소재 콘텐츠에서 복수의 장면을 결정한다. 복수의 장면들 중 각 장면은 소재 콘텐츠 중의 하나의 완전한 시맨틱 정보를 갖는 콘텐츠 프래그먼트 에 각각 대응될 수 있다. 소재 콘텐츠를 복수의 장면으로 분할하여, 후속적으로 디지털 휴먼이 재생할 경우, 상 이한 장면에 대해 상이한 처리를 간편하게 수행한다. 본 발명에서, 디지털 휴먼 융합은 장면을 입도로 하여 융 합을 수행하는 것이다. 일부 실시예에 따르면, 도 3에 도시된 바와 같이, 사전 트레이닝된 장면 분할 모델에 기반하여, 소재 콘텐츠에 서 복수의 장면을 결정하는 단계 S202는 하기의 단계를 포함할 수 있다. 단계 S301에서, 소재 콘텐츠에 대해 섹 션 구조 분석 및 섹션 시맨틱 분할을 수행하여, 소재 콘텐츠에서 복수의 서브 테마를 결정하고, 복수의 서브 테 마 사이의 구조 관계를 결정하며; 단계 S302에서, 구조 관계에 기반하여, 복수의 서브 테마를 복수의 장면으로 분할한다. 이로써, 섹션 구조 분석 및 섹션 시맨틱 분할의 방법을 통해, 소재 콘텐츠에서 시맨틱이 완전한 복수 의 서브 테마 및 그 사이의 구조 관계를 정확하게 결정할 수 있으며, 서브 테마 사이의 구조 관계(예를 들면, 일반적인 부제 구조, 병렬 구조, 점진적 구조 등)를 이용하여, 복수의 서브 테마를 디지털 휴먼 재생 작업에 적 합한 복수의 장면을 더 분할할 수 있다. 일부 실시예에서, 장면 분할 모델은 미리 트레이닝되어 얻은 것이며, 섹션 구조 분석 모델, 섹션 시맨틱 분할 모델, 및 서브 테마를 장면으로 분할하는 모델을 더 포함할 수 있다. 이러한 모델은 규칙에 기반한 모델일 수 있고, 딥러닝에 기반한 모델일 수도 있으며, 이로 한정되지 않는다. 일 예시적인 실시예에서, 섹션 시맨틱 분할 모델은 시맨틱이 완전한 콘텐츠 프래그먼트와 인접한 콘텐츠 프래그먼트 사이의 시맨틱 관계(예를 들면, 각 그 룹의 인접한 두 개 구절 사이의 시맨틱 유사도)를 출력할 수 있고, 섹션 구조 분석 모델은 콘텐츠 프래그먼트 사이의 관계(예를 들면, 일반적인 부제, 병렬, 점진적 등)를 출력할 수 있으며, 양자의 결합은 소재 콘텐츠를 복수의 서브 테마로 분할할 때 획득한 분할 경계 위치와 서브 테마 사이의 관계를 얻을 수 있다. 부가적으로, 상기 방법은 단지 텍스트(자연 언어 처리)에 기반하여 소재 콘텐츠를 분할하며, 획득된 분할 결과는 재생되는 장면에 직접 사용하기 적절하지 않을 수 있다. 예를 들면, 일부 서브 테마 대응되는 콘텐츠 프래그먼트는 단지 한 구절으로 매우 짧을 수 있으며, 이러한 서브 테마를 장면으로 하면 빈번한 장면 변환이 초래될 수 있다. 따 라서, 복수의 서브 테마를 복수의 장면으로 부가적으로 분할할 수 있다. 일부 실시예에서, 서브 테마 사이의 구 조 관계를 사용하여 복수의 서브 테마를 부가적으로 분할할 수 있고, 다른 방식(예를 들면 규칙에 기반한 방법 또는 시퀀스에 기반하여 태깅된 신경망 방법)을 사용하여 복수의 서브 테마를 부가적으로 분할할 수도 있으며, 이로 한정되지 않는다. 복수의 장면을 얻은 후, 각 장면의 타겟 콘텐츠(예를 들면, 재생 멘트, 해설 멘트, 진행 멘트)를 결정할 수 있 다. 일부 실시예에서, 소재 콘텐츠 중의 완전한 시맨틱 정보를 가진 콘텐츠 프래그먼트를 직접 타겟 콘텐츠로 사용할 수 있다. 다른 일부 실시예에서, 소재 콘텐츠의 출처가 복잡하고, 콘텐츠가 비교적 많으며 통상적으로 서면어이므로, 각 장면의 콘텐츠 프래그먼트를 디지털 휴먼의 타겟 콘텐츠로 직접 사용하면 효과가 떨어질 수 있다. 소재 콘텐츠 및/또는 콘텐츠 프래그먼트를 통해 하기와 같이 처리하여 상응한 타겟 콘텐츠를 얻을 수 있 다. 일부 실시예에 따르면, 소재 콘텐츠 및/또는 콘텐츠 프래그먼트에 대해 텍스트 압축, 텍스트 다시 쓰기, 스타일 전환 등 처리를 수행할 수 있다. 일부 실시예에서, 도 4에 도시된 바와 같이, 복수의 장면들 중 각 장면에 대해, 대응되는 콘텐츠 프래그먼트에 기반하여, 상기 장면에 대응되는 타겟 콘텐츠를 결정하는 단계 S203은, 대 응되는 콘텐츠 프래그먼트에 대해 텍스트 다시 쓰기 및 텍스트 압축 중 적어도 하나의 처리를 수행하여, 대응되 는 콘텐츠 프래그먼트를 업데이트하는 단계 S401을 포함할 수 있다. 사용자가 설정한 시간, 콘텐츠의 특징에 따 라, 소재 콘텐츠 전체 및/또는 각 콘텐츠 프래그먼트의 콘텐츠에 따라, 각 장면에 대해 간단하지만 정보량이 많"}
{"patent_id": "10-2024-7037312", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "은 문자 결과를 출력하여 타겟 콘텐츠로 사용한다. 일부 실시예에서, 추출형 요약 알고리즘을 사용하여 타겟 콘"}
{"patent_id": "10-2024-7037312", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "텐츠를 결정할 수 있고, 생성형 요약 알고리즘을 사용하여 타겟 콘텐츠를 결정할 수도 있으며, 다른 방법을 사용하여 타겟 콘텐츠를 결정할 수도 있고, 이로 한정되지 않는다. 일부 실시예에 따르면, 도 4에 도시된 바와 같이, 복수의 장면들 중 각 장면에 대해, 대응되는 콘텐츠 프래그먼 트에 기반하여, 상기 장면에 대응되는 타겟 콘텐츠를 결정하는 단계 S203은, 상기 장면과 바로 전 장면 사이의 구조 관계에 기반하여, 상기 장면을 위한 제1 콘텐츠를 생성하는 단계 S402를 더 포함할 수 있다. 이로써, 장면 사이의 구조 관계에 기반하여 상응한 제1 콘텐츠를 생성하고, 장면 사이의 변환이 더 연관되도록 하며, 전환이 더 자연스러워진다. 일부 실시예에서, 제1 콘텐츠는 예를 들면 장면 전환 멘트일 수 있고, 전환 문장일 수도 있으며, 복수의 장면 또는 지시 장면 사이의 관계를 연결할 수 있는 다른 콘텐츠일 수도 있고, 이로 한정되지 않는다. 일부 실시예에 따르면, 도 4에 도시된 바와 같이, 복수의 장면들 중 각 장면에 대해, 대응되는 콘텐츠 프래그먼 트에 기반하여, 상기 장면에 대응되는 타겟 콘텐츠를 결정하는 단계 S203은, 사전 트레이닝된 스타일 변환 모델 에 기반하여, 대응되는 콘텐츠 프래그먼트를 대응되는 타겟 콘텐츠로 변환시키는 단계 S403을 더 포함할 수 있 으며, 여기서, 스타일 변환 모델은 프롬프트 러닝에 기반하여 트레이닝되어 얻은 것이다. 이로써, 스타일 변환 을 통해, 소재 콘텐츠 및/또는 콘텐츠 프래그먼트를 디지털 휴먼 재생에 적절한 스타일로 변환할 수 있고, 프롬 프트 러닝(prompt learning)에 기반한 방법을 사용하여, 사전 트레이닝된 스타일 변환 모델이 디지털 휴먼의 다 양한 특징 및 수요(예를 들면, 구어화 요구, 디지털 휴먼 특징(성별, 억양 설정 등), 콘텐츠 장면 변환 수요)에 따라, 자연스러운 타겟 콘텐츠를 자동으로 출력할 수 있도록 한다. 일부 실시예에서, 상기 다양한 특정 및 수요 를 속성 제어로 변환할 수 있고, 스타일 변환을 수행해야 할 텍스트(및 선택 가능하게, 텍스트의 콘텍스트)와 함께 공동으로 프롬프트 러닝에 기반한 스타일 변환 모델의 입력을 구축하며, 상기 구조(속성 제어와 텍스트)를 갖는 샘플을 이용하여 모델을 트레이닝하여, 원하는 스타일 변환 결과를 모델이 출력할 수 있도록 한다. 일부 실시예에서, 규칙 기반 방법(구어체 멘트, 장면 전환 멘트 등을 추가함)과 학습 기반 방법을 결합하여, 각 장면 의 콘텐츠 프래그먼트를 디지털 휴먼 재생 상황에 부합되는 타겟 콘텐츠로 변환할 수도 있다. 일부 실시예에 따르면, 도 4에 도시된 바와 같이, 복수의 장면들 중 각 장면에 대해, 대응되는 콘텐츠 프래그먼 트에 기반하여, 상기 장면에 대응되는 타겟 콘텐츠를 결정하는 단계 S203은, 변환된 타겟 콘텐츠에 대해 텍스트 다시 쓰기 및 텍스트 압축 중 적어도 하나의 처리를 수행하여, 대응되는 타겟 콘텐츠를 업데이트하는 단계 S404 를 더 포함할 수 있다. 단계 S404의 동작과 단계 S401의 동작은 일치할 수 있다. 이해할 수 있는 것은, 단계 S401과 단계 S404는 택일 수행 가능하고 양자 모두 수행될 수도 있으며, 이로 한정되지 않는다. 일 예시적인 실시예에서, 명칭이 \"'박물관의 도시'로 만들자！ X시에 6곳의 박물관 건설을 추진\"인 한 편의 글 에 대해 상기 단계를 수행하면 예를 들면 표 1과 같은 복수의 장면 및 대응되는 타겟 콘텐츠를 얻을 수 있다. 표 1 장면 번호 장면 문안 0 '박물관의 도시'로 만들자！X시에 6곳의 박물관 건설을 추진 1 3월 2일, X시에서는 \"'박물관 도시' 건설을 추진하고 전국 문화 중심 건설을 돕는 것\"에 대해 정치 회의 상황에 대한 브리핑을 가졌다. 시청 관련 책임자의 소개에 따 르면, A 박물관, B 박물관 등 6곳의 박물관 건설을 추진중이다. 2 시청 관련 책임자의 소개에 따르면, 2021년 말까지, X시에는 모두 204개의 박물관이 있고, 무료로 개방하는 박물관은 94개이다. X시 박물관의 총 소장품 수는 1625만 세 트에 이르렀고, 이동 가능 문화재 수와 3급 이상의 귀중품 문화재는 모두 전국 1위를 기록하며, 기본 전시는 520개로 지속적으로 개방되고, 매년 평균 600회 이상의 전시 회가 열리며, 수천건의 활동이 진행되고, 매년 관객 수는 5000만 명이 넘는다. 3 시청 관련 책임자의 소개에 따르면, 시청에서는 고정 자산 투자에 적극 나서고 자원 통합과 협업 혁신을 강화하며 박물관 건립에 대한 지원을 강화한다. 4 현재 건설 중인 X시 박물관 동관은 이미 외관이 완성되었고, 2022년 말까지 기본적으 로 완공될 예정이며, 성벽 유적 보호 및 전시 프로젝트 건설에 박차를 가하고 있고, 2023년부터 실용화할 예정이며, XX 박물관 재건축 공정, XX 유적 보호 공정, A 박물 관 재건축 향상 공정, B 자연 박물관 항목의 예비 작업이 현재 박차를 가하고 있다. 5 이러한 박물관의 실시는 X시의 박물관 배치를 최적화하고, 배치가 합리적이고 구조가 최적화되며 특징이 뚜렷하고 기능이 완전한 박물관 사업 발전을 촉진한다. 각 장면에 대응되는 타겟 콘텐츠를 얻은 후, 각 장면 및 대응되는 타겟 콘텐츠에 대해 부가적인 시맨틱 분석을 수행하여, 비디오 소재 서치 및 리콜, 비디오 소재 및 문안 정렬, 관건 정보 전시, 및/또는 디지털 휴먼의 생성 과정을 제어하는 풍부한 장면 관련 정보를 얻을 수 있다. 구체적으로, 하기의 몇 가지 시맨틱 분석 방식을 포함할 수 있다. 일부 실시예에서, 장면 키워드 추출을 수행할 수 있는 바, 즉 전체 장면의 핵심 콘텐츠를 설명하는 키워드를 자동으로 추출할 수 있다. 상기 예에서, 장면 1의 경우, 상기 장면에 대한 키워드 \"박물관의 도시\", \"X시\" 등을 추출할 수 있다. 이러한 장면 키워드는 관련 비디오 소재를 리콜하여 \"X시 박물관의 도시\" 등과 같 은 소재 서치 query를 구축한다. 일부 실시예에서, 문장 수준 키워드 추출을 수행할 수 있는 바, 즉 문장 수준 에서 출발하여 더 미세한 입도의 키워드를 추출한다. 상기 예에서, 장면 4 중의 구절 \"현재 건설 중인 X시 박물 관 동관은 이미 외관이 완성되었고, 2022년 말까지 기본적으로 완공될 예정\"의 경우, 문장 수준의 키워드 \"X시 박물관 동관\"을 자동으로 추출할 수 있고, 상기 문장 수준 키워드는 소재 서치 query의 구축에 응용되는 외에도, 더 정밀한 비디오 소재와 콘텐츠(문안)의 정렬에 응용될 수도 있다. 일부 실시예에서, 정보 추출을 수행하여, 콘텐츠 중 표현되는 키-값 형태의 결과(즉, Key-Value 쌍)를 얻을 수 있다. 상기 예에서, 장면 2의 경우, 복수의 Key-Value 쌍을 자동으로 추출할 수 있는 바, 예컨대 \"X시에는 모두 204개의 박물관이 있고\", \"무료로 개방하는 박물관은 94개\", \"X시 박물관의 총 소장품 수는 1625만 세트\" 등이 다. 추출된 이러한 관건 정보를 이용하여, 더 정확하고 풍부한 디지털 휴먼 재생 소재를 자동으로 생성할 수 있 는 바, 예를 들면 디지털 휴먼 재생 장면의 배경 중의 디스플레이 보드는 디지털 휴먼 재생의 전반적인 품질 및 프레젠테이션 효과를 크게 향상시킬 수 있다. 일부 실시예에 따르면, 디지털 휴먼의 생성 방법은, 복수의 장면 들 중 각 장면에 대해, 상기 장면에 대응되는 타겟 콘텐츠에서 키-값 형태의 정보를 추출하는 단계; 및 키-값 형태의 정보에 기반하여, 최종적인 디지털 휴먼 프레젠테이션 결과의 보조 소재를 생성하는 단계를 더 포함할 수 있다. 이로써, 더 정확하고 풍부한 디지털 휴먼 시각 소재를 얻을 수 있다. 일부 실시예에서, 감성 분석을 수행하여, 각 소재에 의해 표현되는 핵심 감정 경향을 출력할 수 있다. 상기 예 에서, 장면 5의 경우, 전체 장면에서는 X시 박물관 사업의 융성한 발전 상황을 소개하고, 전반적으로 기조, 감 정 및 정서가 긍정적이다. 이러한 감성 분석결과를 이용하여, 디지털 휴먼의 표정, 톤, 동작을 더 풍부하게 제 어할 수 있다. 일부 실시예에 따르면, 장면 태그 정보는 시맨틱 태그를 포함할 수 있고, 대응되는 타겟 콘텐츠 에 기반하여, 상기 장면의 장면 태그 정보를 결정하는 단계 S204는, 대응되는 타겟 콘텐츠에 대해 감성 분석을 수행하여, 시맨틱 태그를 획득하는 단계를 포함할 수 있다. 이로써, 타겟 콘텐츠에 대해 감성 분석을 수행하여, 장면의 기조와 감정 등 정보를 얻을 수 있다. 일부 실시예에서, 시맨틱 태그는 대응되는 타겟 콘텐츠에 의해 표현되는 감정을 마킹하기 위한 것이며, 감정은 긍정, 중립 또는 부정을 포함할 수 있다. 이해할 수 있는 것은, 시맨틱 태그는 더 풍부한 감정을 마킹할 수도 있는 바, 예를 들면 긴장, 즐거움, 분노 등이다. 이로 한정되지 않는다. 일부 실시예에서, 시맨틱 태그는 다른 콘텐츠를 포함할 수도 있는 바, 예를 들면 타겟 콘텐츠의 텍스트 시맨틱 특징을 직접적으로 추출, 타겟 콘텐츠 의 유형(예컨대 서술형, 평논형, 서정형 등), 및 장면 및 대응되는 타겟 콘텐츠의 시맨틱과 관련된 정보를 나타 낼 수 있는 태그를 포함할 수 있으며, 이로 한정되지 않는다. 일부 실시예에서, 상기 방식 외에도, 다른 방식으로 장면 및 대응되는 타겟 콘텐츠에 대해 감성 분석을 수행하 여, 관련 정보를 얻을 수도 있다. 예를 들면, 타겟 콘텐츠의 텍스트 시맨틱 특징을 직접 추출하여, 후속적인 디 지털 휴먼 속성 계획의 입력 정보로 사용한다. 각 장면에 대응되는 타겟 콘텐츠를 얻은 후, 음성 합성을 수행할 수도 있다. 음성 합성의 목적은 디지털 휴먼 장면의 소리를 생성하기 위한 것으로, 즉 앞서 획득한 타겟 콘텐츠를 음성으로 변환하고, 또한 선택 가능하게, 디지털 휴먼의 재생을 위해 배경 음악을 추가하는 것이다. 텍스트가 음성으로 변환되는 것은 TTS 서비스를 호출 하여 구현될 수 있다. 일부 실시예에서, 도 5에 도시된 바와 같이, 디지털 휴먼의 생성 방법은, 타겟 콘텐츠를 음성으로 변환하여, 디지털 휴먼이 재생하도록 하는 단계 S505를 더 포함할 수 있다. 이해할 수 있는 것은, 도 5 중 단계 S501~단계 S504, 및 단계 S507는 도 2 중 단계 S201~단계 S205의 동작과 유사하므로, 여기서 서술하 지 않는다. 배경 음악에 대해, 시스템은 타겟 콘텐츠의 유형(예컨대 서술형, 평논형, 서정형 등)에 따라, 상이한 음정, 음 색의 TTS 능력 및 상이한 스타일의 배경 음악을 호출할 수 있다. 또한, 상기와 같은 본 발명의 방법은 사용자 지정 TTS, 배경 음악 등을 지원한다. 시스템은 다양한 음정, 음색, 어속의 TTS 및 배경 음악을 제공하여 사용자 가 자주적으로 선택하도록 하며, 사용자가 능동적으로 전속 TTS 음색을 제작할 수 있다. 풍부한 시각 소재를 포함한 디지털 휴먼 재생 프레젠테이션 결과를 제조하기 위해, 소재 확충을 수행하여, 디지 털 휴먼 재생에 대해 비디오, 이미지 등 소재를 보충할 수 있다. 비디오 및 이미지 소재의 보충은 하기의 콘텐 츠를 포함한다. 일부 실시예에 따르면, 도 5에 도시된 바와 같이, 디지털 휴먼의 생성 방법은, 복수의 장면들 중 각 장면에 대 해, 소재 콘텐츠 및 상기 장면에 대응되는 타겟 콘텐츠에 기반하여, 상기 장면과 관련되는 비디오 소재를 서칭 하는 단계 S506; 및 비디오 소재와 디지털 휴먼을 결합하는 단계 S508을 더 포함할 수 있다. 이로써, 이러한 방 식을 통해, 장면 및 대응되는 타겟 콘텐츠와 일치하고 밀접하게 연관되는 소재를 서칭함으로써, 디지털 휴먼 재 생함 프레젠테이션 결과 중의 시각 콘텐츠를 풍부하게 만들어, 사용자의 관람 체험감을 향상시킨다. 일부 실시예에서, 소재 콘텐츠의 제목 및 앞서 서술한 장면 키워드, 문장 수준 키워드 등에 기반하여, 하나 이 상의 검색 키워드를 구축하여, 온라인 전체 네트워크 사진/비디오 검색 및 오프라인 사진/비디오 라이브러리를 통해 콘텐츠와 관련된 비디오를 획득할 수 있다. 그 다음 획득된 비디오 콘텐츠는 예를 들어 비디오 스트리핑 알고리즘에 의해 분할되어 후보 시각 소재 프래그먼트를 획득할 수 있다. 이해할 수 있는 것은, 본 발명의 방법 을 실시할 경우, 다양한 방식을 사용하여 비디오 서치 및 비디오 스트리핑을 수행하여, 후보 시각 소재 프래그 먼트를 획득할 수 있으며, 이로 한정되지 않는다. 일부 실시예에 따르면, 복수의 장면들 중 각 장면에 대해, 소재 콘텐츠 및 상기 장면에 대응되는 타겟 콘텐츠에 기반하여, 상기 장면과 관련되는 비디오 소재를 서칭하는 단계 S506은, 장면 키워드를 추출하는 단계; 및 장면 키워드에 기반하여, 상기 장면과 관련되는 비디오 소재를 서칭하는 단계를 포함할 수 있다. 이로써, 상기 방식 을 통해, 장면 전체와 관련되는 비디오 소재를 획득함으로써, 사용 가능한 비디오 소재를 풍부하게 만들었다. 일부 실시예에 따르면, 복수의 장면들 중 각 장면에 대해, 소재 콘텐츠 및 상기 장면에 대응되는 타겟 콘텐츠에 기반하여, 상기 장면과 관련되는 비디오 소재를 서칭하는 단계 S506은, 문장 수준 키워드를 추출하는 단계; 및 문장 수준 키워드에 기반하여, 상기 장면과 관련되는 비디오 소재를 서칭하는 단계를 포함할 수 있다. 이로써, 상기 방식을 통해, 타겟 콘텐츠 중의 구절과 관련되는 비디오 소재를 획득함으로써, 사용 가능한 비디오 소재를 풍부하게 만들었다. 일부 실시예에서, 타겟 콘텐츠 중의 구조화된 데이터에 따라 동적 보고서가 생성될 수 있고, 또한 딥러닝 모델 을 토대로 문자로부터 사진 및/또는 비디오를 생성하는 방법으로 타겟 콘텐츠를 처리하여, 비디오의 소재의 풍 부함을 향상시켰다. 일부 실시예에서, 타겟 콘텐츠, 음성, 및 장면 및 타겟 콘텐츠에 대응되는 이미지, 비디오 소재를 얻은 후, 이 러한 시각 소재 및 문자, 음성을 정렬하여, 렌더링 생성 단계에서 합성되도록 한다. 구체적인 구현에서, 주요하 게는 사전 트레이닝 모델의 그래픽 매칭에 기반하여, 텍스트 및 시각 소재에 대해 연관성 컴퓨팅 및 순서 배열 을 수행하고, 각 단락의 텍스트에 대해 대응되는 자막, TTS 음성 시간대 내에서 매칭되는 비디오 및 사진 콘텐 츠를 찾아, 음성-자막-비디오 시간축을 정렬한다. 이해할 수 있는 것은, 사용자는 이 과정에서 시간축을 조정하 여 수동 정렬을 구현할 수 있다. 일부 실시예에 따르면, 디지털 휴먼의 생성 방법은, 문장 수준 키워드에 기반하여, 서칭된 비디오 소재와 타겟 콘텐츠를 정렬하는 단계를 더 포함할 수 있다. 문장 수준 키워드에 기반하여 서칭된 비디오 소재가 타겟 콘텐츠 중의 어느 한 구절에 대응될 수 있으므로, 한 단락의 타겟 콘텐츠는 문장 수준 키워드에 기반하여 서칭된 복수 의 비디오 소재에 대응될 수 있다. 이러한 실시예에서, 타겟 콘텐츠 중의 복수의 문장 수준 키워드를 이용하여 각자 대응되는 비디오 소재 및 각자 대응되는 구절을 정렬할 수 있다. 일 예시적인 실시예에서, 표 1에 시사된 예에서, 장면 4 중의 복수의 구절의 문장 수준 키워드는 각각 \"X시 박 물관 동관\", \"성벽 유적\", \"XX 박물관; XX 유적; A 박물관; B 자연 박물관\"이며, 각 구절에 대응되는 문장 수준 키워드에 기반하여 서치한 후, 상응한 이미지 또는 비디오 소재를 얻을 수 있다. 나아가, 문장 수준 키워드와 복수의 구절 사이의 대응 관계, 및 문장 수준 키워드와 이러한 비디오 소재 사이의 대응 관계에 기반하여, 비디 오 소재와 구절을 정렬하여, 디지털 휴먼이 각 구절을 읽을 때, 장면에 상응한 비디오 소재가 마킹되고, 구절 사이의 간격에서 비디오 소재의 전환을 완성하도록 한다. 이해할 수 있는 것은, 원시적인 소재 콘텐츠에 충분한 소재가 있거나, 디지털 휴먼 생성 결과가 시각 소재에 결 합될 필요가 없는 것으로 결정되면, 소재 확충을 수행하지 않을 수 있다. 이로써, 디지털 휴먼의 선작업이 모두 수행 완료되었다. 디지털 휴먼 합성은 앞의 장면 분석, 및 선택 가능하게, 소재 보충의 결과에 따라, 각 장면에 대해 적절한 디지털 휴먼 프레젠테이션 방식을 계획함으로써, 최종적인 프레젠테이션의 결과가 양호한 상호성을 갖도록 하며, 사용자에게 양호한 실감형 체험감을 선사한다. 디지털 휴먼 합성은 구체적으로 아래와 같은 콘텐츠를 포함한다. 일부 실시예에서, 디지털 휴먼의 트리거 여부를 판정할 수 있는 바, 즉, 현재 장면에서 생성된 디지털 휴먼인지 의 여부이다. 트리거의 핵심 고려 요소는 주요하게 비디오에서 장면의 위치 및 장면에 대응되는 소재의 풍부함 이다. 여기서 소재의 풍부함은 주로 높은 관련도의 동적 소재가 전체 장면 재생 시간에 대한 점유율이다. 상기 요소 외에도, 소재의 선명함, 연관성, 소재와 장면의 관련도는 모두 디지털 휴먼을 트리거하는지 여부로 사용될 수 있다. 상기 이러한 요소에 기반하여, 시스템은 사용자가 정의한 규칙을 수용할 수 있고, 머신 러닝 방법에 기반하여 트리거의 여부를 자동으로 판정하는 것도 지원할 수 있다. 이해할 수 있는 것은, 본 발명은 구체적인 트리거 논리에 대해 한정하지 않고, 본 발명의 방법을 실시할 경우 수요에 따라 상기 방식으로 상응한 트리거 논리를 설정하거나, 또는 상응한 트리거 논리를 만족하는 샘플을 사용하여 머신 러닝 모델을 트레이닝할 수 있 으며, 이로 한정되지 않는다. 일부 실시예에 따르면, 디지털 휴먼의 생성 방법은, 비디오 소재에 대응되는 장면에 소요되는 재생 시간의 점유 율을 결정하는 단계; 및 점유율에 기반하여, 상응한 장면에서 디지털 휴먼이 트리거되는지 여부를 결정하는 단 계를 더 포함한다. 이로써, 비디오 소재의 풍부함에 기반하여 디지털 휴먼의 트리거 여부를 판정하는 것을 구현 하였다. 일부 실시예에서, 디지털 휴먼이 트리거되는 것으로 결정되면, 디지털 휴먼의 속성 계획을 수행할 수 있다. 디 지털 휴먼 속성 계획은 주요하게 일련의 콘텐츠 특징에 따라 디지털 휴먼의 복식, 제스처, 동작, 표정, 배경 등 속성을 결정하는 것이다. 콘텐츠 특징은 장면의 시맨틱 태그(예를 들면, 타겟 콘텐츠의 기조, 감정, 시맨틱 특 징, 유형 등), 재생 콘텐츠 중의 관건적인 트리거 워드, 시각 소재의 콘텐츠 특징 등을 포함할 수 있다. 구체적 인 구현에서, 규칙에 기반한 방법을 사용하고, 상기 콘텐츠 특징에 따라 디지털 휴먼 속성을 결정할 수 있고, 동시에 딥러닝 방법에 기반하여 콘텐츠 특징을 입력으로 하여 디지털 휴먼 속성 구성을 예측하도록 지원할 수도 있다. 일부 실시예에서, 관건적인 트리거 워드와 특정된 디지털 휴먼 제스처, 동작, 또는 표정 사이의 매핑 관계를 구 축하여, 관건적인 트리거 워드를 검출한 후, 디지털 휴먼이 상응한 제스처, 동작, 또는 표정을 수행하거나 일정 한 확률로 수행하도록 할 수 있다. 이해할 수 있는 것은, 규칙에 기반한 방식으로 관건적인 트리거 워드를 검출 한 후, 디지털 휴먼은 반드시 특정된 반응을 행하게 되고, 모델이 대량의 샘플을 학습하여, 관건적인 트리거 워 드와 특정된 디지털 휴먼 제스처, 동작, 또는 표정 사이의 관계를 학습하도록 하며, 이로 한정되지 않는다. 일부 실시예에서, 시각 소재의 콘텐츠 특징, 예를 들면 소재의 선명함, 연관성, 소재와 장면의 연관성 역시 디 지털 휴먼의 속성 계획으로 사용할 시 고려해야 할 콘텐츠 특징일 수 있다. 이 외에, 시각 소재 중의 특정 콘텐 츠는 디지털 휴먼의 특정 제스처, 동작, 표정 등을 트리거할 수 있다. 일부 실시예에 따르면, 디지털 휴먼의 생 성 방법은, 비디오 소재에 특정 소재가 포함되는 것으로 결정된 것에 응답하여, 비디오 소재에서 특정 소재의 디스플레이 위치에 기반하여, 디지털 휴먼의 동작을 결정하는 단계를 더 포함할 수 있다. 이로써, 비디오 소재 중의 콘텐츠를 분석하는 것을 통해, 비디오 소재의 특정 소재와 디지털 휴먼의 동작을 결합하여, 비디오 소재, 타겟 콘텐츠, 디지털 휴먼 삼자 사이의 일치성을 더 향상시켜, 사용자의 관람 체험감을 향상시킬 수 있다. 일부 실시예에서, 특정 소재는 예를 들면 도표, 범례, 화면 속 화면 등을 포함할 수 있다. 일부 실시예에서, 섹션 분석의 결과를 이용하여, 소재 콘텐츠(원시 텍스트 콘텐츠 또는 그래픽 콘텐츠)에서 예 컨대 주지 단락, 총정리 단락 등과 같은 각 장면의 작용을 더 획득할 수 있다. 이러한 정보에 따라 우리는 디지 털 휴먼의 렌즈 이동, 동작, 및 디지털 휴먼의 구체적인 프레젠테이션 형식(스튜디오, 화면 속 화면 등)을 더 풍부하게 제어할 수 있다. 일부 실시예에서, 감성 분석을 통해 획득된 장면의 시맨틱 태그(예를 들면, 장면의 기조 및 감정)를 디지털 휴 먼 속성 계획 시 고려되는 콘텐츠 특징으로 사용할 수 있다. 일부 실시예에 따르면, 복수의 장면들 중 각 장면 에 대해, 장면 태그 정보에 기반하여, 상기 장면에 특정되는 디지털 휴먼을 구성하는 단계 S507은, 시맨틱 태그 에 기반하여, 디지털 휴먼의 복식, 표정 및 동작 중 적어도 하나를 구성하는 단계를 포함할 수 있다. 장면의 시맨틱 태그로 디지털 휴먼의 톤을 결정할 수도 있다. 일부 실시예에 따르면, 복수의 장면들 중 각 장면 에 대해, 장면 태그 정보에 기반하여, 상기 장면에 특정되는 디지털 휴먼을 구성하는 단계 S507은, 시맨틱 태그 에 기반하여, 디지털 휴먼 음성의 톤을 구성하는 단계를 포함한다. 일부 실시예에서, 디지털 휴먼 음성의 톤은 예를 들면 디지털 휴먼 음성의 음량, 음고, 어조 등을 포함할 수 있다. 이 외에, 이러한 시맨틱 태그는 디지털 휴먼 구성 과정에서 다른 용도를 생성할 수도 있는 바, 예를 들면 장면에 대해 스타일이 더 적절한 스튜디오 배 경 등을 구성할 수 있다. 일부 실시예에서, 디지털 휴먼의 속성은 디지털 휴먼의 복식, 제스처, 동작, 표정, 배경 등 속성을 포함할 수 있고, 구체적으로 각 속성 계획에 대해, 우선 인위적으로 각 종류의 디지털 휴먼 속성에 옵션을 설정할 수 있다. 예를 들면 \"복식\" 속성에 대해, 각각 상이한 옵션 \"정장\", \"캐주얼\", \"셔츠\" 등을 각각 정의한다. 인위적 으로 정해진 이러한 종류별 체계에 기반하여, 우리는 머신 러닝 중의 분류 알고리즘을 사용하고, 인위적으로 태 깅된 트레이닝 데이터에서, 각 종류의 특징을 구축하는 것을 통해, 예컨대 텍스트 특징(단어 특징, 어구 특징, 문장 특징 등), 디지털 휴먼 ID, 디지털 휴먼 성별 등은, 모델 트레이닝이 수렴될 때까지 상기 특징에 따라 인 위적으로 태깅 신호를 모델에 피팅한다. 예측 단계에서, 추출된 특징에서 모델 예측을 수행하여 상이한 속성에 대한 계획을 얻을 수 있다. 일부 실시예에서, 디지털 휴먼의 생성 결과를 얻은 후, 디지털 휴먼 생성 결과의 프레젠테이션을 수행할 수 있 다. 디지털 휴먼의 생성 방법은 홀로그램 이미지의 형태로 디지털 휴먼을 나타내는 단계를 더 포함할 수 있다. 이로써, 디지털 휴먼과 타겟 콘텐츠가 일치한 디지털 휴먼 생성 결과를 제공할 것을 보장할 수 있다. 일부 실시예에서, 비디오 소재 및 디지털 휴먼 생성 결과를 얻은 후, 비디오 소재와 디지털 휴먼을 결합하는 단 계 S508을 수행하여, 비디오 렌더링을 수행하여, 최종적인 비디오를 얻을 수 있다. 도 5에 도시된 바와 같이, 디지털 휴먼의 생성 방법은, 비디오의 형태로 디지털 휴먼을 나타내는 단계 S509를 더 포함할 수 있다. 이로써, 디지털 휴먼과 타겟 콘텐츠가 일치하도록 보장하는 또 다른 디지털 휴먼 생성 결과를 제공하고, 비디오 생성 결 과의 생동감을 향상시켰으며, 사용자 체험감의 몰입감을 향상시켜, 아울러 디지털 휴먼의 강점을 충분히 발휘하 고, 디지털 휴먼 및 비디오 소재의 인터랙션을 이용하여 관련 소재의 부족한 문제를 보완한다. 이 외에, 본 발 명의 방법은 일반적인 장면을 위해 설계되고, 다양한 콘텐츠 유형과 호환되며, 모든 분야에서 보편적으로 사용 될 수 있다. 일부 실시예에서, 본 발명은 단대단 자동 생성을 지원할 뿐만 아니라, 아울러 사용자에 의한 인터랙션 생성도 지원한다. 즉 사용자는 생성된 비디오 결과를 조정할 수 있다. 인터랙션 생성 장면에서, 사용자는 비디오의 각 요소를 조정할 수 있는 바, 예컨대 문자, 음성, 소재, 가상 인물 구성 등이다. 인터랙션 생성 방식은, 한편으로 사용자 보정을 지원하여 품질이 더 좋은 결과를 생성한다. 아울러, 사용자 인터랙션에 의해 생성된 데이터 역시 기록되어 시스템 최적화의 피드백 데이터로 사용됨으로써, 각 단계 모델의 학습을 지도하여 시스템의 효과를 부 단히 향상시킨다. 본 발명의 다른 양태에 따르면, 장면 분할 모델의 트레이닝 방법을 제공한다. 도 6에 도시된 바와 같이, 트레이 닝 방법은, 샘플 소재 콘텐츠 및 샘플 소재 콘텐츠 중의 복수의 샘플 장면을 획득하는 단계 S601; 기설정 장면 분할 모델에 기반하여, 샘플 소재 콘텐츠에서 복수의 예측 장면을 결정하는 단계 S602; 및 복수의 샘플 장면 및 복수의 예측 장면에 기반하여 기설정 장면 분할 모델의 파라미터를 조정하여, 트레이닝된 장면 분할 모델을 얻 는 단계 S603을 포함한다. 이로써, 상기 방식을 통해 장면 분할 모델에 대한 트레이닝을 구현함으로써, 트레이 닝된 모델을 이용하여 정확한 장면 분할 결과를 출력할 수 있어, 상기 장면 분할 결과를 이용하여 디지털 휴먼 생성을 수행하여 얻어진 최종 프레젠테이션 결과의 사용자 관람 체험감이 향상된다. 이해할 수 있는 것은, 샘플 소재 콘텐츠와 단계 S201에서 획득된 소재 콘텐츠는 유사하다. 샘플 소재 콘텐츠 중 의 복수의 샘플 장면은 인위적으로 또는 템플릿 또는 신경망 모델에 기반한 방법으로 샘플 소재 콘텐츠를 분할 하여 얻어진 것일 수 있고, 샘플 소재 콘텐츠를 분할한 진실한 결과(ground truth)로 사용할 수 있다. 예측 결 과 및 진실한 결과를 이용하여 트레이닝하여, 트레이닝된 장면 분할 모델이 소재 콘텐츠에 대해 장면 분할 능력 을 가질 수 있도록 한다. 이해할 수 있는 것은, 본 발명의 방법을 실시할 경우, 수요에 따라 상응한 신경망을 선택하여 장면 분할 모델로 사용할 수 있고, 상응한 손실 함수를 사용하여 트레이닝하며, 이로 한정되지 않는다. 일부 실시예에 따르면, 기설정 장면 분할 모델은, 섹션 시맨틱 분할 모델 및 섹션 구조 분석 모델을 포함할 수 있다. 기설정 장면 분할 모델에 기반하여, 샘플 소재 콘텐츠에서 복수의 예측 장면을 결정하는 단계 S602는, 섹 션 시맨틱 분할 모델 및 섹션 구조 분석 모델을 이용하여 샘플 소재 콘텐츠를 처리하여, 소재 콘텐츠 중 복수의 예측 서브 테마 및 복수의 예측 서브 테마 사이의 예측 구조 관계를 결정하는 단계; 및 예측 구조 관계에 기반 하여, 복수의 예측 서브 테마를 복수의 예측 장면으로 분할하는 단계를 포함한다. 이로써, 섹션 구조 분석 모델 및 섹션 시맨틱 분할 모델을 트레이닝하는 것을 통해, 트레이닝된 모델이 소재 콘텐츠에서 시맨틱이 완전한 복 수의 서브 테마 및 그 사이의 구조 관계를 정확하게 결정하도록 하고, 서브 테마 사이의 구조 관계(예를 들면, 일반적인 부제 구조, 병렬 구조, 점진적 구조 등)를 이용하여, 복수의 서브 테마를 더 디지털 휴먼의 재생 태스 크에 더 적절한 복수의 장면을 분할할 수 있도록 한다. 이해할 수 있는 것은, 장면 분할 모델 외에도, 도 1 또는 도 5 중의 방법에서 사용되는 다른 모델을 트레이닝할 수도 있는 바, 예를 들면, 서브 테마를 장면으로 분할하는 모델, 타겟 콘텐츠를 생성하는 모델(텍스트 다시 쓰 기, 텍스트 압축, 및/또는 스타일 변환을 위한 모델), 장면을 감성 분석하는 모델, 장면 키워드/문장 수준 키워 드 추출 모델, 디지털 휴먼 속성 계획 모델 등 모델을 트레이닝한다. 일부 실시예에서, 말뭉치 주석(Corpus Annotation) 또는 사용자 인터랙션 데이터를 사용하여 장면 분할 모델을 포함한 이러한 모델을 트레이닝할 수 있다. 본 발명의 다른 양태에 따르면, 디지털 휴먼의 생성 장치를 제공한다. 도 7에 도시된 바와 같이, 디지털 휴먼의 생성 장치는 소재 콘텐츠를 획득하도록 구성되는 제1 획득 유닛(); 사전 트레이닝된 장면 분할 모델에 기 반하여, 소재 콘텐츠에서 복수의 장면을 결정하도록 구성되되, 복수의 장면들 중 각 장면은 소재 콘텐츠 중 완 전한 시맨틱 정보를 구비하는 하나의 콘텐츠 프래그먼트에 각각 대응되는 제1 결정 유닛; 복수의 장면들 중 각 장면에 대해, 대응되는 콘텐츠 프래그먼트에 기반하여, 상기 장면에 대응되는 타겟 콘텐츠를 결정하도록 구성되는 제2 결정 유닛; 대응되는 타겟 콘텐츠에 기반하여, 상기 장면의 장면 태그 정보를 결정하도록 구 성되는 제3 결정 유닛; 및 장면 태그 정보에 기반하여, 상기 장면에 특정되는 디지털 휴먼을 구성하도록 구성되는 디지털 휴먼 구성 유닛을 포함한다. 이해할 수 있는 것은, 장치 중의 유닛()~유닛의 동작은 각각 도 2 중의 단계 S201-단계 S205의 동작과 유사하므로, 여기서 서술하지 않는다. 일부 실시예에 따르면, 소재 콘텐츠는 이미지 데이터 및 비디오 데이터 중 적어도 하나 및 텍스트 데이터를 포 함할 수 있다. 일부 실시예에 따르면, 제1 획득 유닛()은 또한, 웹사이트에 기반하여, 소재 콘텐츠를 획득하는 것; 또는 검색 키워드에 기반하여, 소재 콘텐츠를 획득하는 것 중 적어도 하나의 방식에 기반하여, 소재 콘텐츠를 획득하도록 구성될 수 있다. 일부 실시예에 따르면, 도 8에 도시된 바와 같이, 제1 결정 유닛은, 소재 콘텐츠에 대해 섹션 구조 분석 및 섹션 시맨틱 분할을 수행하여, 소재 콘텐츠에서 복수의 서브 테마를 결정하고, 복수의 서브 테마 사이의 구 조 관계를 결정하도록 구성되는 제1 결정 서브 유닛; 및 구조 관계에 기반하여, 복수의 서브 테마를 복수 의 장면으로 분할하도록 구성되는 제1 분할 서브 유닛을 포함한다. 일부 실시예에 따르면, 도 9에 도시된 바와 같이, 제2 결정 유닛은, 대응되는 콘텐츠 프래그먼트에 대해 텍스트 다시 쓰기 및 텍스트 압축 중 적어도 하나의 처리를 수행하여, 대응되는 콘텐츠 프래그먼트를 업데이트 하도록 구성되는 제1 업데이트 서브 유닛; 및 변환된 콘텐츠에 대해 텍스트 다시 쓰기 및 텍스트 압축 중 의 적어도 한 가지 처리를 수행하여, 대응되는 콘텐츠를 업데이트하도록 구성되는 제2 업데이트 서브 유닛 중 적어도 하나를 포함할 수 있다. 일부 실시예에 따르면, 도 9에 도시된 바와 같이, 제2 결정 유닛은, 상기 장면과 바로 전 장면 사이의 구 조 관계에 기반하여, 상기 장면을 위한 제1 콘텐츠를 생성하도록 구성되는 생성 서브 유닛을 포함할 수 있 다. 일부 실시예에 따르면, 도 9에 도시된 바와 같이, 제2 결정 유닛은, 사전 트레이닝된 스타일 변환 모델에 기반하여, 대응되는 콘텐츠 프래그먼트를 대응되는 타겟 콘텐츠로 변환시키도록 구성되는 변환 서브 유닛 을 포함할 수 있고, 여기서, 스타일 변환 모델은 프롬프트 러닝에 기반하여 트레이닝되어 얻은 것이다. 일부 실시예에 따르면, 디지털 휴먼의 생성 장치는, 복수의 장면들 중 각 장면에 대해, 상기 장면에 대응 되는 타겟 콘텐츠에서 키-값 형태의 정보를 추출하도록 구성되는 추출 유닛; 및 키-값 형태의 정보에 기반하여, 비디오를 위한 보조 소재를 생성하도록 구성되는 생성 유닛을 더 포함할 수 있다. 일부 실시예에 따르면, 제3 결정 유닛은, 대응되는 타겟 콘텐츠에 대해 감성 분석을 수행하여, 시맨틱 태 그를 획득하도록 구성되는 감성 분석 서브 유닛을 포함할 수 있다. 일부 실시예에 따르면, 시맨틱 태그는 대응되는 타겟 콘텐츠에 의해 표현되는 긍정, 중립 또는 부정을 포함하는 감정을 마킹할 수 있다. 일부 실시예에 따르면, 도 10에 도시된 바와 같이, 디지털 휴먼의 생성 장치는 타겟 콘텐츠를 음성으로 변환하여, 디지털 휴먼이 재생하도록 구성되는 음성 변환 유닛을 포함할 수 있다. 장치 중의 유닛 ~유닛, 및 유닛의 동작은 각각 장치 중의 유닛()~유닛의 동작과 유사하므로, 여기 서 서술하지 않는다. 일부 실시예에 따르면, 도 10에 도시된 바와 같이, 디지털 휴먼의 생성 장치는, 복수의 장면들 중 각 장 면에 대해, 소재 콘텐츠 및 상기 장면에 대응되는 타겟 콘텐츠에 기반하여, 상기 장면과 관련되는 비디오 소재 를 서칭하도록 구성되는 서치 유닛; 및 비디오 소재와 디지털 휴먼을 결합하도록 구성되는 결합 유닛 을 포함할 수 있다. 일부 실시예에 따르면, 서치 유닛은, 장면 키워드를 추출하도록 구성되는 제1 추출 서브 유닛; 및 장면 키워드에 기반하여, 상기 장면과 관련되는 비디오 소재를 서칭하도록 구성되는 제1 서치 서브 유닛을 포함할 수 있다. 일부 실시예에 따르면, 서치 유닛은, 문장 수준 키워드를 추출하도록 구성되는 제2 추출 서브 유닛; 및 문장 수준 키워드에 기반하여, 상기 장면과 관련되는 비디오 소재를 서칭하도록 구성되는 제2 서치 서브 유닛을 더 포함할 수 있다. 일부 실시예에 따르면, 디지털 휴먼의 생성 장치는, 문장 수준 키워드에 기반하여, 서칭된 비디오 소재와 타겟 콘텐츠를 정렬하도록 구성되는 정렬 유닛을 더 포함할 수 있다. 일부 실시예에 따르면, 디지털 휴먼의 생성 장치는, 비디오 소재에 대응되는 장면에 소요되는 재생 시간 의 점유율을 결정하도록 구성되는 제5 결정 유닛; 및 점유율에 기반하여, 상응한 장면에서 디지털 휴먼이 트리 거되는지 여부를 결정하도록 구성되는 제6 결정 유닛을 더 포함할 수 있다. 일부 실시예에 따르면, 디지털 휴먼의 생성 장치는, 비디오 소재에 특정 소재가 포함되는 것으로 결정된 것에 응답하여, 비디오 소재에서 특정 소재의 디스플레이 위치에 기반하여, 디지털 휴먼의 동작을 결정하도록 구성되는 제4 결정 유닛을 더 포함할 수 있다. 일부 실시예에 따르면, 디지털 휴먼 구성 유닛은, 시맨틱 태그에 기반하여, 디지털 휴먼의 복식, 표정 및 동작 중 적어도 하나를 구성하도록 구성되는 제1 구성 서브 유닛을 포함할 수 있다. 일부 실시예에 따르면, 디지털 휴먼 구성 유닛은, 시맨틱 태그에 기반하여, 디지털 휴먼 음성의 톤을 구 성하도록 구성되는 제2 구성 서브 유닛을 더 포함할 수 있다. 일부 실시예에 따르면, 디지털 휴먼의 생성 장치는, 홀로그램 이미지의 형태로 디지털 휴먼을 나타내도록 구성되는 홀로그램 이미지 표현 유닛을 더 포함할 수 있다. 일부 실시예에 따르면, 디지털 휴먼의 생성 장치는, 비디오의 형태로 디지털 휴먼을 나타내도록 구성되는 비디오 표현 유닛을 더 포함할 수 있다. 본 발명의 다른 양태에 따르면, 장면 분할 모델의 트레이닝 장치를 제공한다. 도 11에 도시된 바와 같이, 트레 이닝 장치는, 샘플 소재 콘텐츠 및 샘플 소재 콘텐츠 중의 복수의 샘플 장면을 획득하도록 구성되는 제2 획득 유닛; 기설정 장면 분할 모델에 기반하여, 샘플 소재 콘텐츠에서 복수의 예측 장면을 결정하도록 구 성되는 제7 결정 유닛; 및 복수의 샘플 장면 및 복수의 예측 장면에 기반하여 기설정 장면 분할 모델의 파라미터를 조정하여, 트레이닝된 장면 분할 모델을 얻도록 구성되는 트레이닝 유닛을 포함한다. 일부 실시예에 따르면, 기설정 장면 분할 모델은, 섹션 시맨틱 분할 모델 및 섹션 구조 분석 모델을 포함할 수 있다. 제7 결정 유닛은, 섹션 시맨틱 분할 모델 및 섹션 구조 분석 모델을 이용하여 샘플 소재 콘텐츠를 처리하여, 소재 콘텐츠 중 복수의 예측 서브 테마 및 복수의 예측 서브 테마 사이의 예측 구조 관계를 결정하도 록 구성되는 제2 결정 서브 유닛; 및 예측 구조 관계에 기반하여, 복수의 예측 서브 테마를 복수의 예측 장면으 로 분할하도록 구성되는 제2 분할 서브 유닛을 포함할 수 있다. 본 발명의 기술적 해결수단에서, 관련된 사용자 개인 정보의 수집, 저장, 사용, 처리, 가공, 전송, 제공 및 공 개 등 처리는 모두 관련 법률 규정에 부합되며 공서양속에 위배되지 않는다. 본 발명의 실시예에 따르면, 전자 기기, 판독 가능 저장 매체 및 컴퓨터 프로그램 제품을 더 제공한다. 도 12를 참조하면, 본 발명의 서버 또는 클라이언트로서의 전자 기기의 구조 블록도를 설명하는 바, 이는 본 발명의 각 양태의 하드웨어 기기의 구현예에 응용될 수 있다. 전자 기기는 랩톱 컴퓨터, 데스크톱 컴퓨터, 운영 플랫폼, 개인 정보 단말기, 서버, 블레이드 서버, 대형 컴퓨터, 및 다른 적합한 컴퓨터와 같은 다양한 형 태의 디지털 컴퓨터를 의미한다. 전자 기기는 개인 디지털 처리, 셀룰러폰, 스마트폰, 웨어러블 기기 및 다른 유사한 컴퓨팅 장치와 같은 다양한 형태의 이동 장치를 의미할 수도 있다. 본문에서 나타낸 부재, 이들의 연결 과 관계, 및 이들의 기능은 단지 예시적인 것으로, 본문에서 설명 및/또는 요구된 본 발명의 구현을 한정하지않는다. 도 12에 도시된 바와 같이, 전자 기기는 판독 전용 메모리(ROM)에 저장된 프로그램 또는 저장 유닛 으로부터 랜덤 액세스 메모리(RAM)에 로딩된 컴퓨터 프로그램에 따라 다양하고 적절한 동작 및 처 리를 수행할 수 있는 컴퓨팅 유닛을 포함한다. RAM에는 또한 기기의 조작에 필요한 다양한 프로그램 및 데이터가 저장된다. 컴퓨팅 유닛, ROM 및 RAM은 버스를 통해 서로 연결된 다. 입/출력(I/O) 인터페이스 역시 버스에 연결된다. 전자 기기 중의 복수의 부재는 입/출력(I/O) 인터페이스에 연결되고, 입력 유닛, 출력 유닛 , 저장 유닛 및 통신 유닛을 포함한다. 입력 유닛은 전자 기기에 정보를 입력할 수 있는 임의의 유형의 기기일 수 있고, 입력 유닛은 입력된 숫자 또는 문자 정보를 수신하며, 전자 기기 의 사용자 설정 및/또는 기능 제어와 관련된 키 신호 입력을 생성하는데 사용될 수 있고, 마우스, 키보드, 터치 스크린, 트랙 보드, 트랙 볼, 작동 로드, 마이크 및/또는 리모컨을 포함하지만 이에 한하지 않는다. 출력 유닛 은 정보를 마킹할 수 있는 임의의 유형의 기기일 수 있고, 디스플레이, 스피커, 비디오/오디오 출력 단말 기, 진동기 및/또는 프린터를 포함하지만 이에 한하지 않는다. 저장 유닛은 자기 디스크, 광 디스크를 포 함하지만 이에 한하지 않는다. 통신 유닛은 전자 기기가 예컨대 인터넷과 같은 컴퓨터 네트워크 및 /또는 다양한 전기 신호 네트워크를 통해 다른 기기와 정보/데이터를 교환하도록 허용하는 바, 모뎀, 랜 카드, 적외선 통신 기기, 무선 통신 송수신기 및/또는 칩셋을 포함하지만 이에 한하지 않고, 예를 들면 블루투스 TM 기기, 802.11 기기, WiFi 기기, WiMax 기기, 셀룰러 통신 기기 및/또는 유사물이다. 컴퓨팅 유닛은 처리 및 컴퓨팅 능력을 구비하는 범용 및/또는 전용 처리 어셈블리일 수 있다. 컴퓨팅 유 닛의 일부 구현예는 중앙 처리 유닛(CPU), 그래픽 처리 유닛(GPU), 다양한 전용 인공 지능(AI) 컴퓨팅 칩, 다양한 머신 러닝 모델 알고리즘을 실행하는 컴퓨팅 유닛, 디지털 신호 프로세서(DSP), 및 임의의 적절한 프로세서, 컨트롤러, 마이크로 컨트롤러 등을 포함하지만 이에 한정되지 않는다. 컴퓨팅 유닛은 상하문에 서 서술되는 각 방법 및 처리를 수행하는 바, 예를 들면 디지털 휴먼의 생성 방법 및 장면 분할 모델의 트레이 닝 방법이다. 예를 들면, 일부 실시예에서, 디지털 휴먼의 생성 방법 및 장면 분할 모델의 트레이닝 방법은 컴 퓨터 소프트웨어 프로그램에 의해 구현될 수 있고, 이는 기계 판독 가능 매체에 유형적으로 포함되는 바, 예를 들어 저장 유닛이다. 일부 실시예에서, 컴퓨터 프로그램의 일부 또는 전부는 ROM 및/또는 통신 유 닛을 거쳐 전자 기기에 다운로드 및/또는 설치될 수 있다. 컴퓨터 프로그램이 RAM에 로딩되 고 컴퓨팅 유닛에 의해 실행될 경우, 상기와 같이 서술된 디지털 휴먼의 생성 방법 및 장면 분할 모델의 트레이닝 방법의 하나 이상의 단계를 수행할 수 있다. 대안적으로, 다른 실시예에서, 컴퓨팅 유닛은 다른 임의의 적절한 방식(예를 들어, 펌웨어를 통함)을 통해 디지털 휴먼의 생성 방법 및 장면 분할 모델의 트레이닝 방법을 수행하도록 구성된다. 여기서 설명된 시스템 및 기술의 다양한 실시형태는 디지털 전자 회로 시스템, 집적 회로 시스템, 필드 프로그 램 가능 게이트 어레이(FPGA), 전용 집적 회로(ASIC), 전용 표준 제품(ASSP), 시스템 온 칩의 시스템(SOC), 복 잡 프로그램 가능 논리 소자(CPLD), 컴퓨터 하드웨어, 펌웨어, 소프트웨어, 및/또는 이들의 조합에서 구현될 수 있다. 이러한 다양한 실시형태는 하나 이상의 컴퓨터 프로그램에서의 구현을 포함할 수 있고, 상기 하나 이상의 컴퓨터 프로그램은 적어도 하나의 프로그램 가능 프로세서를 포함하는 프로그램 가능 시스템에서 실행 및/또는 해석될 수 있으며, 상기 프로그램 가능 프로세서는 전용 또는 범용 프로그램 가능 프로세서일 수 있고, 저장 시 스템, 적어도 하나의 입력 장치, 및 적어도 하나의 출력 장치로부터 데이터 및 명령을 수신할 수 있으며, 데이 터 및 명령을 상기 저장 시스템, 상기 적어도 하나의 입력 장치, 및 상기 적어도 하나의 출력 장치에 전송할 수 있다. 본 발명의 방법을 구현하는 프로그램 코드는 하나 이상의 프로그래밍 언어의 임의의 조합으로 편집할 수 있다. 이러한 프로그램 코드는 범용 컴퓨터, 전용 컴퓨터 또는 다른 프로그램 가능 데이터 처리 장치의 프로세서 또는 제어기에 제공될 수 있으며, 프로그램 코드는 프로세서 또는 제어기에 의해 실행될 경우, 흐름도 및/또는 블록 도에 지정된 기능/작동이 구현되도록 할 수 있다. 프로그램 코드는 완전히 기계에서 실행되거나, 부분적으로 기 계에서 실행되거나, 독립형 소프트웨어 패키지로서 기계에서 실행되며, 일부는 원격 기계에서 실행되거나 완전 히 원격 기계 또는 서버에서 실행될 수 있다. 본 발명의 컨텍스트에서, 기계 판독 가능 매체는 명령 실행 시스템, 장치 또는 기기에 의해 또는 명령 실행 시 스템, 장치 또는 기기와 결합하여 사용하기 위한 프로그램을 포함하거나 저장할 수 있는 유형 매체일 수 있다. 기계 판독 가능 매체는 기계 판독 가능 신호 매체 또는 기계 판독 가능 저장 매체일 수 있다. 기계 판독 가능매체는 전자, 자기, 광학, 전자기, 적외선 또는 반도체 시스템, 장치 또는 기기, 또는 상기 내용의 임의의 적절 한 조합을 포함할 수 있지만 이에 한정되지 않는다. 기계 판독 가능 저장 매체의 보다 구체적인 예는 하나 이상 의 와이어에 기반한 전기 연결, 휴대용 컴퓨터 디스크, 하드 디스크, 랜덤 액세스 메모리(RAM), 판독 전용 메모 리(ROM), 소거 가능 프로그램 가능 판독 전용 메모리(EPROM 또는 플래시 메모리), 광섬유, CD-ROM, 광학 저장 기기, 자기 저장 기기 또는 상술한 내용의 임의의 적절한 조합을 포함한다. 사용자와의 인터랙션을 제공하기 위하여, 컴퓨터에서 여기서 설명된 시스템 및 기술을 실시할 수 있고, 상기 컴 퓨터는 사용자에게 정보를 표시하기 위한 표시 장치(예를 들어, CRT(음극선관) 또는 LCD(액정 표시 장치) 모니 터); 및 키보드 및 지향 장치(예를 들어, 마우스 또는 트랙 볼)를 구비하며, 사용자는 상기 키보드 및 상기 지 향 장치를 통해 컴퓨터에 입력을 제공한다. 다른 타입의 장치는 또한 사용자와의 인터랙션을 제공할 수 있는데, 예를 들어, 사용자에게 제공된 피드백은 임의의 형태의 감지 피드백(예를 들어, 시각 피드백, 청각 피드백, 또 는 촉각 피드백)일 수 있고; 임의의 형태(소리 입력, 음성 입력, 또는 촉각 입력)로 사용자로부터의 입력을 수 신할 수 있다. 여기서 설명된 시스템 및 기술을 백그라운드 부재를 포함하는 컴퓨팅 시스템(예를 들어, 데이터 서버), 또는 미 들웨어 부재를 포함하는 컴퓨팅 시스템(예를 들어, 응용 서버), 또는 프론트 엔드 부재를 포함하는 컴퓨팅 시스 템(예를 들어, 그래픽 사용자 인터페이스 또는 웹 브라우저를 구비하는 사용자 컴퓨터이고, 사용자는 상기 그래 픽 사용자 인터페이스 또는 웹 브라우저를 통해 여기서 설명된 시스템 및 기술의 실시형태와 인터랙션할 수 있 음), 또는 이러한 백그라운드 부재, 미들웨어 부재, 또는 프론트 엔드 부재의 임의의 조합을 포함하는 컴퓨팅 시스템에서 실시할 수 있다. 임의의 형태 또는 매체의 디지털 데이터 통신(예를 들어, 통신 네트워크)을 통해 시스템의 부재를 서로 연결시킬 수 있다. 통신 네트워크의 예시로 근거리 통신망(LAN), 광역 통신망(WAN), 인터 넷, 블록체인 네트워크를 포함한다. 컴퓨터 시스템은 클라이언트 및 서버를 포함할 수 있다. 클라이언트 및 서버는 일반적으로 서로 멀리 떨어져 있 고 일반적으로 통신 네트워크를 통해 서로 인터랙션한다. 대응되는 컴퓨터에서 실행되고 또한 서로 클라이언트- 서버 관계를 가지는 컴퓨터 프로그램을 통해 클라이언트 및 서버의 관계를 생성한다. 서버는 클라우드 서버일 수 있고, 분산형 시스템의 서버일 수도 있으며, 블록체인에 결합된 서버일 수도 있다. 위에서 설명한 다양한 형태의 프로세스를 사용하여 단계를 재배열, 추가 또는 삭제할 수 있음을 이해해야 한다. 예를 들어, 본 발명에 기재된 각 단계는 동시에 수행될 수 있거나 순차적으로 수행될 수 있거나 상이한 순서로 수행될 수 있고, 본 발명에서 공개된 기술적 해결수단이 이루고자 하는 결과를 구현할 수만 있으면, 본문은 이 로 한정되지 않는다. 본 발명의 실시예 또는 예가 첨부된 도면을 참조하여 설명되었지만, 전술한 방법, 시스템 및 기기는 단지 예시 적인 실시예 또는 예일 뿐이며, 본 발명의 범위는 이들 실시예 또는 예에 의해 제한되지 않고, 첨부된 청구범위 및 그 등가물에 의해서만 제한된다. 실시예 또는 예의 다양한 구성요소는 생략되거나 그와 동등한 구성요소로 대체될 수 있다. 또한, 본 발명에서 설명한 것과 다른 순서로 단계들이 수행될 수도 있다. 또한, 실시예 또는 예의 다양한 요소는 다양한 방식으로 조합될 수 있다. 중요한 것은 기술이 발전함에 따라 여기에 설명된 많은 요소가 본 발명 이후에 나타나는 등가 요소로 대체될 수 있다는 것이다.도면 도면1 도면2 도면3 도면4 도면5 도면6 도면7 도면8 도면9 도면10 도면11 도면12"}
{"patent_id": "10-2024-7037312", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도면에서는 실시예를 예시적으로 시사하고 명세서의 일 부분을 구성하며, 명세서의 문자 설명과 함께 실시예의 예시적인 실시형태를 설명한다. 사시된 실시예는 단지 예시적인 목적으로서, 특허청구범위를 한정하지 않는다. 모든 도면에서, 동일한 도면 부호는 유사하지만 반드시 동일한 것은 아닌 요소를 지칭한다. 도 1은 본 발명의 실시예에 따라 그중에서 본문에서 설명된 다양한 방법을 실시하는 예시적 시스템의 모식도이 다. 도 2는 본 발명의 실시예에 따른 디지털 휴먼의 생성 방법의 흐름도이다. 도 3은 본 발명의 실시예에 따른 소재 콘텐츠에서 복수의 장면을 결정하는 단계의 흐름도이다. 도 4는 본 발명의 실시예에 따라 각 장면에 대응되는 타겟 콘텐츠를 결정하는 단계의 흐름도이다. 도 5는 본 발명의 실시예에 따른 디지털 휴먼의 생성 방법의 흐름도이다. 도 6은 본 발명의 실시예에 따른 장면 분할 모델의 트레이닝 방법의 흐름도이다. 도 7은 본 발명의 실시예에 따른 디지털 휴먼의 생성 장치의 구조 블록도이다. 도 8은 본 발명의 실시예에 따른 제1 결정 유닛의 구조 블록도이다. 도 9는 본 발명의 실시예에 따른 제2 결정 유닛의 구조 블록도이다. 도 10은 본 발명의 실시예에 따른 디지털 휴먼의 생성 장치의 구조 블록도이다. 도 11은 본 발명의 실시예에 따른 장면 분할 모델의 트레이닝 장치의 구조 블록도이다. 도 12는 본 발명의 실시예를 구현하기 위한 예시적인 전자 기기의 구조 블록도이다."}
