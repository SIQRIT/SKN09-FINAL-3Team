{"patent_id": "10-2022-7031148", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2022-0145848", "출원번호": "10-2022-7031148", "발명의 명칭": "집적 회로 아키텍처 내에서 최적화된 데이터흐름을 위한 지능형 버퍼 추적 시스템 및 방법", "출원인": "미씩 인크", "발명자": "우 페이-시"}}
{"patent_id": "10-2022-7031148", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "하나 이상의 데이터 버퍼들의 상태 데이터에 기초하여 집적 회로에서 데이터 흐름을 최적화하는 방법에 있어서,상기 방법은,(A) 애플리케이션에 대한 최적화된 네트워크 그래프를 변환하는 것에 기초하여 태스크 그래프를 생성하는 단계로서, 상기 태스크 그래프를 생성하는 단계는,(i-a) 상기 최적화된 네트워크 그래프의 복수의 네트워크 동작들 각각의 분해에 기초하여 복수의 개별 태스크들을 열거하는 단계; 및(ii-a) 상기 최적화된 네트워크 그래프의 상기 복수의 네트워크 동작들 각각의 상기 분해에 기초하여 상기 복수의 개별 태스크들의 종속 태스크들의 하나 이상의 개별 쌍들 각각에 데이터 버퍼를 할당하는 단계를 포함하는,상기 (A) 단계;(B) 상기 태스크 그래프의 분해에 기초하여 토큰 정보 태스크 스케줄러를 인코딩하는 단계로서, 상기 토큰 정보태스크 스케줄러를 인코딩하는 단계는,상기 종속 태스크들의 하나 이상의 개별 쌍들 각각 사이의 각각의 데이터 버퍼의 상태를 식별하는 것에 기초하여 상기 복수의 개별 태스크들 중 하나 이상의 실행을 야기하도록 상기 토큰 정보 태스크 스케줄러를 프로그래밍하는 단계를 포함하는, 상기 (B) 단계를 포함하는, 방법."}
{"patent_id": "10-2022-7031148", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 토큰 정보 태스크 스케줄러를 인코딩하는 단계는,상기 토큰 정보 태스크 스케줄러를 프로그래밍하여, (1) 상기 집적 회로의 하나 이상의 개별 컴포넌트들에 의해 방출된 복수의 개별 토큰들을 추적하고; (2) 상기 복수의 개별 토큰들의 수집이 상기 복수의 개별 태스크들 중 하나 이상과 연관된 하나 이상의 태스크런칭 조건들을 충족하는지를 식별하는 단계를 포함하는, 방법."}
{"patent_id": "10-2022-7031148", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,(1) 상기 복수의 네트워크 동작들 각각의 상기 분해는,상기 최적화된 네트워크 그래프의 상기 복수의 네트워크 동작들 각각을 시간 종속 순서로 배열된 상기 복수의개별 태스크들의 세트를 포함하는 태스크 시퀀스 세트로 변환하는 단계를 포함하고;(2) 상기 데이터 버퍼를 할당하는 단계는,상기 태스크 시퀀스 세트에서 태스크들의 각각의 순차적인 쌍 사이에서 상기 데이터 버퍼의 인스턴스를 할당하는 단계를 포함하는, 방법."}
{"patent_id": "10-2022-7031148", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,상기 각각의 데이터 버퍼의 상기 상태를 식별하는 단계는,상기 각각의 데이터 버퍼에 대한 판독 동작 및 기록 동작 중 하나를 수행하는 상기 종속 태스크들의 상기 복수의 개별 쌍들 중 하나 이상의 종속 태스크들의 실행에 기초하여 상기 집적 회로의 컴포넌트에 의해 방출되는 하공개특허 10-2022-0145848-3-나 이상의 토큰들을 식별하는 단계를 포함하는, 방법."}
{"patent_id": "10-2022-7031148", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서,상기 종속 태스크들의 상기 복수의 개별 쌍들의 개별 쌍의 종속 태스크들 중 제1 종속 태스크 및 제2 종속 태스크 각각은 상기 종속 태스크들의 개별 쌍 사이에 할당된 상기 각각의 데이터 버퍼를 통해 인터페이싱하는,방법."}
{"patent_id": "10-2022-7031148", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서,상기 토큰 정보 태스크 스케줄러를 인코딩하는 단계는,상기 복수의 개별 태스크들 각각에 대한 개별 태스크 런칭 조건을 프로그래밍하는 단계를 포함하며, 상기 개별태스크 런칭 조건은 하나 이상의 태스크들의 완료에 기초하여 상기 집적 회로 내에서 하나 이상의 개별 토큰들이 관찰된다는 요건을 포함하는, 방법."}
{"patent_id": "10-2022-7031148", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6항에 있어서,상기 개별 태스크 런칭 조건에 대한 하나 이상의 토큰 카운터들을 프로그래밍하는 단계를 더 포함하고, 상기 하나 이상의 토큰 카운터들은 상기 집적 회로의 하나 이상의 컴포넌트들에 의해 방출된 하나 이상의 개별 토큰들을 카운팅하는, 방법."}
{"patent_id": "10-2022-7031148", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서,상기 각각의 타겟 버퍼의 상기 상태를 식별하는 단계는,상기 복수의 태스크들 각각에 대한 상기 개별 태스크 런칭 조건에 대해 상기 하나 이상의 토큰 카운터들의 값을평가하는 단계를 포함하는, 방법."}
{"patent_id": "10-2022-7031148", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1항에 있어서,상기 토큰 정보 태스크 스케줄러는 상기 개별 태스크 쌍과 연관된 상기 각각의 데이터 버퍼에 대한 판독 동작및 기록 동작 중 하나 이상을 수행하는 개별 태스크 쌍에 기초하여 생성된 판독 토큰 및 기록 토큰 중 하나 이상을 추적하는, 방법."}
{"patent_id": "10-2022-7031148", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제1항에 있어서,상기 종속 태스크들의 하나 이상의 개별 쌍들 각각은,(1) 상기 적어도 하나의 데이터 버퍼에 대한 기록 동작을 수행하는 제1 태스크; 및(2) 상기 제1 태스크의 완료 후에만 상기 적어도 하나의 데이터 버퍼에 대한 판독 동작 및 기록 동작 중 하나를수행하는 제2 태스크를 포함하는, 방법."}
{"patent_id": "10-2022-7031148", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제1항에 있어서,상기 종속 태스크들의 하나 이상의 개별 쌍들 각각은,(1) 상기 적어도 하나의 데이터 버퍼에 대한 판독 동작을 수행하는 제1 태스크; 및공개특허 10-2022-0145848-4-(2) 상기 제1 태스크의 완료 후에만 상기 적어도 하나의 데이터 버퍼에 대한 판독 동작 및 기록 동작 중 하나를수행하는 제2 태스크를 포함하는, 방법."}
{"patent_id": "10-2022-7031148", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제1항에 있어서,상기 각각의 데이터 버퍼와 인터페이싱하는 상기 종속 태스크들의 하나 이상의 개별 쌍들의 제1 종속 태스크는상기 개별 토큰이 상기 제2 종속 태스크의 태스크 런칭 조건의 충족을 야기하는 경우 상기 하나 이상의 개별 쌍들의 제2 종속 태스크의 자동 실행을 야기하는 상기 토큰 정보 태스크 스케줄러에 의해 추적되는 개별 토큰의방출을 야기하는, 방법."}
{"patent_id": "10-2022-7031148", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "데이터 흐름 및 집적 회로의 집적 회로 태스크들의 실행을 최적화하기 위한 시스템에 있어서, 상기 시스템은,메모리의 데이터 버퍼;토큰 정보 태스크 스케줄러;신경망 애플리케이션에 대한 최적화된 네트워크 그래프를 변환하는 것에 기초하여 태스크 그래프를 생성하는 지능형 컴파일러 프로그램을 구현하는 컴퓨터를 포함하며, 상기 태스크 그래프를 생성하는 단계는,(i-a) 상기 최적화된 네트워크 그래프의 복수의 네트워크 동작들 각각의 분해에 기초하여 복수의 개별 집적 회로 태스크들을 열거하는 단계; 및(ii-a) 상기 최적화된 네트워크 그래프의 상기 복수의 네트워크 동작들 각각의 상기 분해에 기초하여 상기 복수의 개별 집적 회로 태스크들의 종속 집적 회로 태스크들의 하나 이상의 개별 쌍들 각각에 상기 메모리의 상기데이터 버퍼의 데이터 버퍼 슬라이스를 할당하는 단계를 포함하고;상기 컴퓨터는 상기 태스크 그래프의 분해에 기초하여 토큰 정보 태스크 스케줄러를 인코딩하고, 상기 토큰 정보 태스크 스케줄러를 인코딩하는 단계는,상기 종속 집적 회로 태스크들의 하나 이상의 개별 쌍들 각각 사이의 각각의 데이터 버퍼의 상태를 식별하는 것에 기초하여 상기 복수의 개별 집적 회로 태스크들 중 하나 이상의 실행을 야기하도록 상기 토큰 정보 태스크스케줄러를 프로그래밍하는 단계를 포함하는, 시스템."}
{"patent_id": "10-2022-7031148", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제14항에 있어서,상기 토큰 정보 태스크 스케줄러를 인코딩하는 것은,상기 토큰 정보 태스크 스케줄러를 프로그래밍하여, (1) 상기 집적 회로의 하나 이상의 개별 컴포넌트들에 의해 방출된 복수의 개별 토큰들을 추적하고; (2) 상기 복수의 개별 토큰들의 수집이 상기 복수의 개별 집적 회로 태스크들 중 하나 이상과 연관된 하나 이상의 태스크 런칭 조건들을 충족하는지를 식별하도록 하는, 시스템."}
{"patent_id": "10-2022-7031148", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제13항에 있어서,상기 컴퓨터는 상기 집적 회로 내에서 하나 이상의 개별 태스크 토큰들의 하나 이상의 발생에 기초하여 증가 또는 감소하도록 태스크 토큰 카운터를 인코딩하고;상기 토큰 정보 태스크 스케줄러를 인코딩하는 것은 상기 하나 이상의 개별 태스크 토큰들의 하나 이상의 발생에 의해 충족될 때, 상기 토큰 정보 태스크 스케줄러가 상기 복수의 개별 집적 회로 태스크들 중 하나 이상을자동으로 런칭하도록 하는 하나 이상의 태스크 런칭 조건들을 인코딩하는 것을 포함하는, 시스템."}
{"patent_id": "10-2022-7031148", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "집적 회로에서 데이터 흐름을 최적화하기 위한 시스템들 및 방법들은 신경망 애플리케이션에 대한 최적화된 네트 워크 그래프를 변환하는 것에 기초하여 태스크 그래프를 생성하는 단계를 포함하며, 태스크 그래프를 생성하는 단계는, 최적화된 네트워크 그래프의 복수의 네트워크 동작들 각각의 분해에 기초하여 복수의 개별 태스크들을 열거하는 단계; 및 최적화된 네트워크 그래프의 복수의 네트워크 동작들 각각의 분해에 기초하여 복수의 개별 태 스크들의 종속 태스크들의 쌍들 각각에 데이터 버퍼를 할당하는 단계; 태스크 그래프의 분해에 기초하여 토큰 정 보 태스크 스케줄러를 인코딩하는 단계를 포함하고; 토큰 정보 태스크 스케줄러를 인코딩하는 단계는, 종속 태스 크들의 쌍들 각각 사이의 각각의 데이터 버퍼의 상태를 식별하는 것에 기초하여 복수의 개별 태스크들의 실행을 야기하도록 토큰 정보 태스크 스케줄러를 프로그래밍하는 단계를 포함한다."}
{"patent_id": "10-2022-7031148", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "관련 출원들에 대한 상호 참조 본 출원은 2020년 3월 4일에 출원된 미국 가출원 번호 제62/984,934호 및 2020년 5월 21일에 출원된 미국 가출 원 번호 제63/028,180호의 이익을 주장하며, 둘 다 본 참조에 의해 그 전체가 본원에 통합된다."}
{"patent_id": "10-2022-7031148", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 2, "content": "기술분야 본원에 기술된 발명들은 일반적으로 집적 회로 아키텍처 분야에 관한 것으로, 보다 구체적으로는 새롭고 유용한 지능형 집적 회로 및 집적 회로 아키텍처 분야에서 지능형 집적 회로를 사용하여 컴퓨팅하는 방법에 관한 것이다."}
{"patent_id": "10-2022-7031148", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "오늘날, 인공 지능과 기계 학습의 다양한 구현들은 많은 기술 분야에서 혁신을 주도하고 있다. 인공지능 (artificial intelligence; AI) 시스템과 인공지능 모델(알고리즘 포함)은 기계 학습(딥러닝(deep learning)), 추론(reasoning), 추론 능력(inferential capacities) 및 기계(예를 들어, 컴퓨터 및/또는 컴퓨팅 서버)의 대 규모 데이터 처리 능력을 가능하게 하는 많은 시스템 아키텍처와 모델에 의해 정의된다. 이러한 AI 시스템 및 모델은 종종 자연어 처리, 이미지 인식, 플래닝(planning), 의사 결정(decision-making) 등과 같은 하나 이상의 특정 태스크(task)들을 수행하기 위해 집중적으로 훈련된다. 예를 들어, 이러한 AI 시스템 및 모델의 서브셋은 인공 신경망 모델을 포함한다. 인공 신경망 모델의 훈련은 많은 경우에 훈련 주기에 걸쳐 수천 시간이 필요하고 사용 전에 모델의 관련 신경망 알고리즘(들)을 미세 조정하기 위해 수 테라바이트의 훈련 데이터가 필요할 수 있다. 그러나, 일단 훈련되면, 훈련 주기 동안 사용되는 더 큰 훈련 데이터 세트와 비교할 때 상대적으로 더 작은 데 이터 세트를 기반으로 특정 태스크들(예를 들어, 음성 입력 데이터로부터 음성 인식 등)을 달성하기 위한 추론 이 이루어지도록 신경망 모델 또는 알고리즘이 빠르게 배포될 수 있다. 더 작은 데이터 세트를 기반으로 하는 신경망 모델 또는 알고리즘에 의해 이루어진 추론은 신경망 모델이 상황에 대한 정답 또는 표시로 계산하는 것 에 대한 예측일 수 있다. 또한, 이상의 신경망 알고리즘을 구현하는 신경망 모델은 훈련 단계에서 요구되는 것과 같은 양의 컴퓨팅 리소 스들을 필요로 하지 않을 수 있지만, 현장에서 신경망 모델을 배포하는 것은 데이터를 분류하고 결과를 추론하 거나 예측하기 위해 상당한 회로 영역, 에너지 및 컴퓨팅 능력을 계속 필요로 한다. 예를 들어, 가중 합 계산은 신경망 애플리케이션들을 포함한 패턴 일치 및 기계 학습 애플리케이션에서 일반적으로 사용된다. 가중 합 계산 에서, 집적 회로는 입력 세트(xi)에 가중치 세트(wi)를 곱하고 각 곱셈 연산의 결과를 합산하여 최종 결과(z)를 계산하는 기능을 할 수 있다. 그러나 기계 학습 애플리케이션을 위한 일반적인 가중 합 계산에는 수백 또는 수 천 개의 가중치가 포함되어 있어 가중 합 계산이 기존 디지털 회로로 계산하는 데 계산 비용이 많이 듭니다. 특 히, 디지털 메모리에서 수백 또는 수천 개의 가중치에 액세스하려면 상당한 컴퓨팅 시간(즉, 레이턴시 증가)과 상당한 에너지가 필요하다. 따라서, 신경망 모델 등의 가중 합 계산을 계산하는 데 필요한 기존 디지털 회로부는 신경망 모델에 필요한 수 백만 개의 가중치를 저장하는 데 필요한 많은 양의 디지털 메모리 회로부를 수용하기 위해 큰 경향이 있다. 회 로부의 크기가 크기 때문에, 많은 기존 컴퓨터들 및 회로들의 컴퓨팅 능력을 활성화하려면 더 많은 에너지가 필 요하다. 추가로, 인공 지능 모델, 즉 신경망 모델을 구현하기 위한 이러한 기존 컴퓨터들 및 회로들은, 분산 컴퓨팅 시 스템(예를 들어, 클라우드)에서 또는 많은 현장의 컴퓨팅 서버 등을 사용할 때와 같은, 원격 컴퓨팅 프로세스들 에 적합할 수 있다. 그러나, 레이턴시 문제는 이러한 원격 인공 지능 처리 시스템들이 원격, 에지 컴퓨팅 장치 들 또는 필드 장치들에 대한 컴퓨팅 추론 등에 사용될 때 명백하다. 즉, 이러한 전통적인 원격 시스템이 원격 필드 장치들에서 사용될 추론을 생성하기 위한 신경망 모델을 구현하려고 할 때, 입력 데이터가 종종 다양한 대 역폭의 네트워크를 통해 전송되어야 하기 때문에 원격 필드 장치들로부터 입력 데이터를 수신하는 데 피할 수 없는 지연이 있으며, 이후, 원격 컴퓨팅 시스템에 의해 생성된 추론은 동일하거나 유사한 네트워크를 통해 원격 필드 장치들로 다시 전송되어야 한다. 추가로, 이러한 전통적인 회로는 종종 컴퓨팅 부하(예를 들어, 제한된 스 토리지 및/또는 제한된 컴퓨팅)를 관리할 수 없으며, 종종 클라우드와 같은 원격 컴퓨팅 시스템들에 따라 컴퓨팅 집약적인 계산을 수행하고 계산 데이터(예를 들어, 원시 입력들 및 출력들)를 저장할 수 있다. 따라서, 원격 컴퓨팅 시스템들(예를 들어, 클라우드)에 대한 지속적 및/또는 지속적인 액세스(예를 들어, 24 × 7 액세스)는 지속적인 동작을 위해 필요하며, 이는 비용, 인프라 제한(예를 들어, 제한된 대역폭, 저급 통신 시스템 등) 등 으로 인해 많은 애플리케이션들에 적합하지 않을 수 있다. 필드 레벨에서(예를 들어, 원격 필드 장치에서 로컬로) AI 처리 시스템들을 구현하는 것은 일부 레이턴시 문제 들을 해결하기 위한 제안된 솔루션일 수 있다. 그러나, 에지 장치(예를 들어, 원격 필드 장치)에서 이러한 전통 적인 AI 컴퓨터들 및 시스템들 중 일부를 구현하려는 시도들은, 위에서 언급된 바와 같이, 데이터를 처리하고 추론을 생성하는 데 사용되는 컴퓨팅 시스템의 요구되는 복잡한 아키텍처로 인해 상당한 양의 에너지를 소비하 는 많은 회로들이 있는 부피가 큰 시스템이 될 수 있다. 따라서, 그 이상이 없는 이러한 제안은 현재 기술로는 실현 가능하지 않거나 지속 가능하지 않을 수 있다. 따라서, 인공 지능 모델을 필드에서 로컬로 구현하기 위한 배치 가능한 시스템(예를 들어, 로컬 AI)이 필요하며, 바람직하게는 레이턴시를 줄이고 실시간 또는 실질적으로 실시간으로 예측 또는 추론을 수행하는 데 필요한 컴퓨팅 능력을 갖추고 있으면서도 에너지 효율적인, 크고 부피가 큰 (에지) 장치들을 초래하지 않는, 에 지 장치들에서 사용된다."}
{"patent_id": "10-2022-7031148", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 출원의 후술되는 실시예들은 AI 및 기계 학습을 구현하기 위한 집적 회로 아키텍처들 및 전통적인 시스템들 의 결점들을 해결할 수 있는 이러한 진보되고 개선된 집적 회로들 및 구현 기술들을 제공한다."}
{"patent_id": "10-2022-7031148", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "일 실시예에서, 하나 이상의 데이터 버퍼들의 상태 데이터에 기초하여 집적 회로에서 데이터 흐름을 최적화하는 방법은, ((A) 신경망 애플리케이션에 대한 최적화된 네트워크 그래프를 변환하는 것에 기초하여 태스크 그래프 를 생성하는 단계로서, 태스크 그래프를 생성하는 단계는, (i-a) 최적화된 네트워크 그래프의 복수의 네트워크 동작들 각각의 분해에 기초하여 복수의 개별 태스크들을 열거하는 단계; 및 (ii-a) 최적화된 네트워크 그래프의 복수의 네트워크 동작들 각각의 분해에 기초하여 복수의 개별 태스크들의 종속 태스크들의 하나 이상의 개별 쌍 들 각각에 데이터 버퍼를 할당하는 단계를 포함하는, 상기 (A) 단계; (B) 태스크 그래프의 분해에 기초하여 토 큰 정보 태스크 스케줄러(token-informed task scheduler)를 인코딩하는 단계로서, 토큰 정보 태스크 스케줄러 를 인코딩하는 단계는, 종속 태스크들의 하나 이상의 개별 쌍들 각각 사이의 각각의 데이터 버퍼의 상태를 식별 하는 것에 기초하여 복수의 개별 태스크들 중 하나 이상의 실행을 야기하도록 토큰 정보 태스크 스케줄러를 프 로그래밍하는 단계를 포함하는, 상기 (B) 단계를 포함한다. 일 실시예에서, 토큰 정보 태스크 스케줄러를 인코딩하는 단계는, 토큰 정보 태스크 스케줄러를 프로그래밍하여, 상기 집적 회로의 하나 이상의 개별 컴포넌트들에 의해 방출된 복수의 개별 토큰들을 추적 하고; 복수의 개별 토큰들의 수집이 복수의 개별 태스크들 중 하나 이상과 연관된 하나 이상의 태스크 런칭 조건들을 충족하는지를 식별하는 단계를 포함한다. 일 실시예에서, 복수의 네트워크 동작들 각각의 분해는, 최적화된 네트워크 그래프의 복수의 네트워크 동작 각각을 시간 종속 순서로 배열된 복수의 개별 태스크들의 세트를 포함하는 태스크 시퀀스 세트로 변환하는 단계 를 포함하고, 데이터 버퍼를 할당하는 단계는, 태스크 시퀀스 세트에서 태스크들의 각각의 순차적인 쌍 사 이에서 데이터 버퍼의 인스턴스를 할당하는 단계를 포함한다. 일 실시예에서, 각각의 데이터 버퍼의 상태를 식별하는 단계는, 각각의 데이터 버퍼에 대한 판독 동작 및 기록 동작 중 하나를 수행하는 종속 태스크들의 복수의 개별 쌍들 중 하나 이상의 종속 태스크들의 실행에 기초하여 집적 회로의 컴포넌트에 의해 방출되는 하나 이상의 토큰들을 식별하는 단계를 포함한다. 일 실시예에서, 종속 태스크들의 복수의 개별 쌍들의 개별 쌍의 종속 태스크들 중 제1 종속 태스크 및 제2 종속 태스크 각각은 종속 태스크들의 개별 쌍 사이에 할당된 각각의 데이터 버퍼를 통해 인터페이싱한다. 일 실시예에서, 토큰 정보 태스크 스케줄러를 인코딩하는 단계는, 복수의 개별 태스크들 각각에 대한 개별 태스 크 런칭 조건을 프로그래밍하는 단계를 포함하며, 개별 태스크 런칭 조건은 하나 이상의 태스크들의 완료에 기초하여 집적 회로 내에서 하나 이상의 개별 토큰들이 관찰된다는 요건을 포함한다. 일 실시예에서, 상기 방법은 개별 태스크 런칭 조건에 대한 하나 이상의 토큰 카운터들을 프로그래밍하는 단계 를 포함하고, 하나 이상의 토큰 카운터들은 집적 회로의 하나 이상의 컴포넌트들에 의해 방출된 하나 이상의 개 별 토큰들을 카운팅한다. 일 실시예에서, 각각의 타겟 버퍼의 상태를 식별하는 단계는, 복수의 태스크들 각각에 대한 개별 태스크 런칭 조건에 대해 하나 이상의 토큰 카운터들의 값을 평가하는 단계를 포함한다. 일 실시예에서, 토큰 정보 태스크 스케줄러는 개별 태스크 쌍과 연관된 각각의 데이터 버퍼에 대한 판독 동작 및 기록 동작 중 하나 이상을 수행하는 개별 태스크 쌍에 기초하여 생성된 판독 토큰 및 기록 토큰 중 하나 이 상을 추적한다. 일 실시예에서, 종속 태스크의 하나 이상의 개별 쌍들 각각은, 적어도 하나의 데이터 버퍼에 대한 기록 동 작을 수행하는 제1 태스크; 및 제1 태스크의 완료 이후에만 적어도 하나의 데이터 버퍼에 대한 판독 동작 및 기록 동작을 수행하는 제2 태스크를 포함한다. 일 실시예에서, 종속 태스크의 하나 이상의 개별 쌍들 각각은, 적어도 하나의 데이터 버퍼에 대한 판독 동 작을 수행하는 제1 태스크; 및 제1 태스크의 완료 이후에만 적어도 하나의 데이터 버퍼에 대한 판독 동작 및 기록 동작을 수행하는 제2 태스크를 포함한다. 일 실시예에서, 각각의 데이터 버퍼와 인터페이싱하는 종속 태스크들의 하나 이상의 개별 쌍들의 제1 종속 태스 크는 개별 토큰이 제2 종속 태스크의 태스크 런칭 조건의 충족을 야기하는 경우 하나 이상의 개별 쌍들의 제2 종속 태스크의 자동 실행을 야기하는 토큰 정보 태스크 스케줄러에 의해 추적되는 개별 토큰의 방출을 야기한다. 일 실시예에서, 데이터 흐름 및 집적 회로의 집적 회로 태스크들의 실행을 최적화하기 위한 시스템은, 메인 데 이터 버퍼; 토큰 정보 태스크 스케줄러; 신경망 애플리케이션에 대한 최적화된 네트워크 그래프를 변환하는 것 에 기초하여 태스크 그래프를 생성하는 지능형 컴파일러 프로그램을 구현하는 컴퓨터를 포함하며, 태스크 그래 프를 생성하는 단계는, (i-a) 상기 최적화된 네트워크 그래프의 복수의 네트워크 동작들 각각의 분해에 기초하 여 복수의 개별 집적 회로 태스크들을 열거하는 단계; 및 (ii-a) 상기 최적화된 네트워크 그래프의 복수의 네 트워크 동작들 각각의 분해에 기초하여 복수의 개별 집적 회로 태스크들의 종속 집적 회로 태스크들의 하나 이 상의 개별 쌍들 각각에 메인 데이터 버퍼의 데이터 버퍼의 데이터 버퍼 슬라이스를 할당하는 단계를 포함하고; 컴퓨터는 태스크 그래프의 분해에 기초하여 토큰 정보 태스크 스케줄러를 인코딩하고, 토큰 정보 태스크 스케줄 러를 인코딩하는 단계는, 종속 집적 회로 태스크들의 하나 이상의 개별 쌍들 각각 사이의 각각의 데이터 버퍼의 상태를 식별하는 것에 기초하여 복수의 개별 집적 회로 태스크들 중 하나 이상의 실행을 야기하도록 토큰 정보 태스크 스케줄러를 프로그래밍하는 단계를 포함한다. 일 실시예에서, 토큰 정보 태스크 스케줄러를 인코딩하는 단계는, 토큰 정보 태스크 스케줄러를 프로그래밍하여, 상기 집적 회로의 하나 이상의 개별 컴포넌트들에 의해 방출된 복수의 개별 토큰들을 추적 하고; 상기 복수의 개별 토큰들의 수집이 상기 복수의 개별 집적 회로 태스크들 중 하나 이상과 연관된 하 나 이상의 태스크 런칭 조건들을 충족하는지를 식별하도록 하는 단계를 포함한다. 일 실시예에서, 컴퓨터는 집적 회로 내에서 하나 이상의 개별 태스크 토큰들의 하나 이상의 발생에 기초하여 증 가 또는 감소하도록 태스크 토큰 카운터를 인코딩하고; 토큰 정보 태스크 스케줄러를 인코딩하는 것은 하나 이 상의 개별 태스크 토큰들의 하나 이상의 발생에 의해 충족될 때, 토큰 정보 태스크 스케줄러가 복수의 개별 집 적 회로 태스크들 중 하나 이상을 자동으로 런칭하도록 하는 하나 이상의 태스크 런칭 조건들을 인코딩하는 것 을 포함한다."}
{"patent_id": "10-2022-7031148", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 출원의 바람직한 실시예들에 대한 이하의 설명은 본 발명들을 이러한 바람직한 실시예들로 제한하려는 것이 아니라, 오히려 당업자가 이러한 발명들을 만들고 사용할 수 있도록 하기 위한 것이다. 1. 지능형 처리 개요 본 출원의 실시예들은 다양한 컴퓨팅 집약적 애플리케이션들 또는 다양한 복잡성 및 크기의 프로그램들을 수용 하도록 프로그래밍될 수 있는 유연하고 재프로그래밍 가능한 시스템을 제공한다. 본 출원의 하나 이상의 실시예 들에 따른 집적 회로 아키텍처의 물리적 구성은 동일하거나 실질적으로 동일하게 유지될 수 있지만, 아키텍처 내의 이종의 처리 요소들은 다수의 애플리케이션들 또는 단일 애플리케이션의 하나 이상의 섹션들을 처리하도록 프로그래밍될 수 있다. 또한, 본 출원의 하나 이상의 실시예들 내에서 구현된 저장 장치들의 구현 및 특정 배열은 데이터 집약적 애플 리케이션들 또는 프로그램들을 처리하는 데 필요한 메모리 또는 스토리지의 전체 요구 사항을 줄이는 것을 포함 하여, 최신 집적 회로들에 비해 여러 기술적 이점들을 제공한다. 예를 들어, 일 실시예에서, 분산형 메모리는 입력 데이터(예를 들어, 원시 입력 데이터 또는 업스트림 계층 또는 소스로부터의 데이터)를 수신하기 위해 제 공될 수 있는 메인(대형) 버퍼를 포함할 수 있으며, 복수의 개별 로컬 버퍼들 각각은 컴퓨팅 요소(예를 들어, 행렬 곱셈 가속기)와 함께 배열될 수 있다. 이러한 실시예에서, 각 로컬 버퍼는 빠른 액세스 및 따라서 메 인 버퍼로부터의 입력 데이터의 효율적인 처리를 위해 컴퓨팅 요소에 인접하거나 바로 근처에 배열될 수 있다. 추가로, 이러한 배열은 데이터 처리 파이프라인을 따라 데이터의 비동기식 처리를 허용할 수 있으므로 데이터의 다수의 세그먼트들이 파이프라인을 따라 가능한 한 다른 단계들에서 동시에 처리될 수 있도록 한다. 즉, 일부 실시예들에서, 집적 회로의 하나 이상의 컴포넌트들에 의한 데이터의 비동기 처리는 데이터 처리 파이프라인의 개별 컴포넌트들에 따라 동시 및/또는 병렬 워크플로들을 가능하게 하는 동시에 완벽한 잠금 상태에 있지 않을 수 있는 복수의 개별 데이터 세트들의 처리를 가능하게 할 수 있다. 이러한 실시예들에서는 데이터 복제에 대한 요구 사항이 상당히 감소될 수 있다. 추가로, 본 출원의 하나 이상의 실시예들은 중앙 처리 제어가 요구되지 않을 수 있는 토큰 구동(token-driven) 데이터 처리 시스템을 구현하도록 기능할 수 있다. 구체적으로, 하나 이상의 실시예들에서, 본 출원의 집적 회로는 마이크로프로세서(예를 들어, 집적 회로의 각 컴퓨팅 타일(compute tile)에 국부적일 수 있는 마이크로컨트롤러를 포함할 수 있는 나노 프로세서) 프로그램들 및/또는 토큰(token)들을 사용하는 애플리케이션들을 트리거할 수 있는 아키텍처를 포함할 수 있다. 본원에 언 급된 토큰은 바람직하게는 컴퓨팅 이벤트 또는 트랜잭션(transaction)의 발생 또는 존재를 입증하거나 나타내는 데이터 조각에 관한 것이고, 추가적으로 또는 대안적으로, 집적 회로의 하나 이상의 컴포넌트들의 상태를 입증 하거나 나타낼 수 있다. 비제한적인 예에서, 토큰이 집적 회로 컴포넌트의 상태를 나타내는 상황들에서, 토큰은 버퍼가 비어 있는지 또는 가득 찼는지, 사용중인지 또는 비어 있는지, 프로세서가 켜져 있는지 꺼져 있는지, 사 용 중인지(처리 중인지) 사용 중이 아닌지(처리하지 않는지), 항목이 처리 또는 미처리되었는지 여부 등을 나타 낼 수 있다. 본원에 설명된 많은 실시예들에서, 토큰들은 프로그램들 또는 애플리케이션들의 실행 및/또는 구현 을 자동으로 트리거하는 데 사용될 수 있지만, 다양한 구현들에서 토큰들은 다른 유닛들을 트리거하는 데 사용 될 수 있다. 몇 가지 예들은, 하나 이상의 인스턴스들 또는 하나 이상의 토큰들의 조합을 사용하면 집적 회로의 동작 또는 트랜잭션이 진행할 수 있는 권한이 있음을 나타낼 수 있다; 가능하면, 동작 또는 트랜잭션의 모든 종 속 동작들이 발생했음을 의미한다. 따라서, 토큰들은 유한 상태 머신들을 트리거하고, 패킷 또는 작업 큐 항목 (work-queue item)의 릴리스(release)를 트리거하고, 다른 토큰의 생성을 트리거하는 등에 사용될 수 있다. 집 적 회로를 사용하여 임의의 유형 및/또는 임의 개수의 기능들/동작들을 자동으로 트리거하기 위해, 몇몇 실시예 들에서 설명된 토큰 기반 거버넌스(token-based governance) 모듈(본원에서 플로우 스코어보드 모듈(flow scoreboard module)이라고도 함)의 무한한 애플리케이션들이 있을 수 있다. 본 출원의 바람직한 실시예에서, 집적 회로 아키텍처는 집적 회로의 별개의 컴포넌트들 사이에서 토큰들의 통신 및/또는 전달을 가능하게 하는 네트워크-온-칩(network-on-chip) 시스템을 포함할 수 있다. 따라서, 일부 실시 예들에서, 토큰들은 집적 회로의 컴포넌트들이 하나 이상의 토큰들의 적절한 조합 및/또는 카운트에 의해 트리 거되는 새로운 작업 부하를 수신할 수 있게 하는 종속성의 조각들을 나타낼 수 있다. 그러나, 이에 제한되는 것은 아니나, 직렬 통신 버스 등을 포함하는 임의의 적절한 토큰 통신 방식 및/또는 상호 연결이 사용될 수 있음 에 유의해야 한다. 예를 들어, 본 출원의 일 실시예에서, 토큰은 관련 트리거링 이벤트가 완료될 때까지(예를 들어, 로컬 데이터 버퍼 비우기, 입력 데이터에 대한 MMA 등에 의한 계산, 및/또는 임의의 모든 적절한 이벤트) (상호 연결과 관계없이) 릴리스 및/또는 생성하지 않을 수 있다. 또 다른 실시예에서, 토큰의 조기 릴리스가 주 문 제약 조건을 위반하지 않을 경우, 토큰은 관련 트리거링 이벤트보다 먼저 생성 및/또는 릴리스될 수 있다. 따라서, 본 출원의 몇몇 실시예들에서, 토큰들은 데이터 흐름의 토큰 기반 제어 및/또는 집적 회로 전체의 데이 터 처리를 달성하기 위해 임의의 적절한 방식으로 배포될 수 있다는 점에 유의해야 한다. 추가로, 본원에 설명된 토큰 기반 거버넌스 모듈은 일반적으로 토큰들 및 토큰 트리거링 조건들 등을 추적하여 토큰 기반 제어를 가능하게 하도록 기능할 수 있다. 토큰 기반 거버넌스 모듈은 구성 가능한 제약 조건들을 가 질 수 있으므로 트리거링은 또한 로컬 유닛 또는 회로의 상태뿐만 아니라 식별되거나 수신된 토큰들의 수에 의 존할 수 있다. 즉, 본 출원의 몇몇 실시예들에서, 데이터 흐름, 데이터 처리, 하나 이상의 동작들/기능들 등은 토큰들의 릴리스 또는 생성을 기반으로 관리될 수 있으며, 단순히 집적 회로의 컴포넌트의 상태를 결정 및/또는 식별하고/하거나 집적 회로 내에서 처리 또는 동작의 상태를 식별하는 것은 또 다른 동작, 기능, 처리 또는 흐 름을 자동화하기 위한 트리거링 이벤트의 역할을 할 수 있다. 예를 들어, 하나 이상의 작업 큐의 활용도(예를 들어, 깊이) 및/또는 용량의 상태가 트리거링 이벤트로 기능할 수 있다. 이러한 실시예들의 기술적 이점은 필요 할 수 있는 컴퓨팅 리소스들(예를 들어, 하나 이상의 작업 큐가 있는 공간)이 사용 가능한 경우에만 동작이 실 행될 수 있다는 것이다. 따라서, 본 출원의 실시예들은 자동화된 동작, 기능 또는 처리를 트리거하는 이벤트들 및/또는 종속성들이 구성되는 방식에 유연성을 제공할 수 있으며, 따라서 더 많은 리소스들을 사용하거나 또는 리소스들을 보다 효율적으로 사용하는 보다 복잡한 프로그램들 또는 애플리케이션들의 생성을 허용할 수 있으며, 이는 일부 동작을 수행하기 위해 생성되어야 하는 이벤트들의 수를 줄임으로써 본원에 설명된 하나 이 상의 시스템들의 동작 효율성을 개선한다. 일부 실시예들에서, 이 참조에 의해 전체가 본원에 통합된 본원에 포함된 미국 특허 번호 제10,606,797호에서와 같이, 보다 상세하게 설명된 바와 같이, 토큰 기반 데이터 처리 집적 회로에 의해 다양한 및/또는 상이한 토큰 들이 구현될 수 있음에 유의해야 한다. 일부 실시예들에서, 집적 회로 내에서 동작을 수행하기 위한 트리거링 조건은 여러 고유한 토큰 유형들 각각의 최소 카운트 수에 의해 달성될 수 있다. 1.1 데이터흐름 아키텍처에 대한 버퍼 추적 개요 혼합 신호 컴퓨팅 타일 어레이에는 제한된 컴퓨팅 리소스들(예를 들어, 사용 가능한 처리, 메모리 등)에 주어진 태스크를 할당하는 방법, 타일들 간의 제한된 통신 대역폭, 동시 실행 태스크들의 데이터 흐름 관리, 태스크 실 행의 전제 조건이 될 수 있는 태스크에 대한 종속성이 충족되었을 수 있는 시점 결정, 및 태스크가 여러 타일들 로 분할되고 결과들을 결합할 수 있도록 단일 타일에 맞추기에는 너무 큰 태스크들의 분해를 포함할 수 있는 여 러 가지 문제들이 있을 수 있다. 시스템 성능은 타일 내의 다양한 타일들과 회로들 간의 효율적인 통신에 의해, 사용 가능한 컴퓨팅 리소스들과 함께 태스크 종속성이 충족되면 가능한 한 빨리 실행되도록 태스크를 스케줄링 함으로써, 충분한 양의 데이터가 도착하면 태스크를 시작함으로써 향상될 수 있다. 하나 이상의 바람직한 실시예들에서, 태스크들은 시스템 내에서 이동되는 데이터의 양을 줄일 수 있는 공유 버 퍼들을 통해 통신할 수 있다. 태스크가 버퍼에 액세스 및/또는 기록할 수 있는 시점 및 태스크가 실행할 수 있 는 시점을 스케줄링하는 것은 플로우 스코어 보드(flow score board; FSB)으로 제어될 수 있다. FSB는 입력 버 퍼들 및/또는 출력 버퍼들의 상태에 기초하여 태스크 실행을 트리거할 수 있다. FSB는 버퍼의 다른 섹션이 그에 기록된 다음 데이터 세트를 갖는 동안 버퍼의 일부가 판독되도록 허용하기 위해 큐(queue), 예를 들어, 선입선 출(first-in first-out; FIFO) 큐를 활용할 수 있다. FSB 및 버퍼들이 구성될 때, 태스크들이 시스템이 통신 및 계산을 중첩하도록 할 수 있는 버퍼에 기록하고 그로부터 판독할 수 있도록 버퍼들이 크기 조절될 수 있다. FSB 의 일 예의 경우, \"SYSTEM AND METHODS FOR IMPLEMENTING AN INTELLIGENCE PROCESSING COMPUTING ARCHITECTURE\"이라는 명칭의 미국 특허 번호 제10,521,395호에 대한 참조가 이루어 지며, 이는 이 참조에 의해 그 전체가 통합된다. 하나 이상의 바람직한 실시예들에서, 단일 타일에 맞추기에는 너무 큰 태스크는 추가 타일 들에서 실행될 다수의 태스크들로 분할될 수 있고, 이러한 다수의 태스크들 각각의 결과는 모든 처리가 완료되 면 결합될 수 있으며, FSB는 동시 처리를 동기화하고 동시 처리의 결과를 최종 결과로 결합할 수 있다. 2. 지능형 처리 컴퓨팅 아키텍처 도 1 내지 1a에 도시된 바와 같이, 컴퓨팅 집약적 프로그램들 및/또는 애플리케이션들(예를 들어, 기계 학습 애 플리케이션들, 신경망들 등)을 처리하기 위한 지능형 처리 컴퓨팅 아키텍처(또는 본원에서 대안적으로 지능형 처리 집적 회로라고 함)는 복수의 지능형(컴퓨팅) 처리(타일) 유닛들을 포함하는 지능형 처리 어레이, 복수의 네트워크 온 칩 라우터들을 포함하는 네트워크 온 칩 시스템, 집적 회로 컨트롤 러 회로, 타일 섹터(tile sector) 컨트롤러 회로, 및 직렬 연결 버스를 포함한다. 바람직하게는, 복수의 지능형 처리 유닛들 각각은 행렬 곱셈 가속기(본원에서는 가속기 회로로도 지 칭될 수 있음), 컴퓨터 처리 회로(예를 들어, 마이크로프로세서, 나노프로세서 등), 플로우 스코어보드(토 큰 기반 거버넌스) 모듈, 단일 명령어 다중 데이터(single instruction multiple data; SIMD) 유닛 (예를 들어, 스트리밍 산술 논리 유닛 등), 및 로컬 버퍼(예를 들어, 정적 랜덤 액세스 메모리(static random access memory; SRAM) 등)를 포함한다. 일부 실시예들에서, 로컬 데이터 버퍼는 적어도 SRAM 스토리 지 또는 회로, 데이터를 SRAM 및 다른 컴퓨팅 리소스들로 및/또는 로부터 이동하는 데 사용될 수 있는 하나 이 상의 데이터 전송 엔진들 또는 회로들(예를 들어, DMA 컨트롤러), 주어진 시간에 SRAM에 액세스할 수 있는 컨트 롤러를 선택하는 중재 방식을 포함할 수 있는 SRAM 컨트롤러로 구현될 수 있다. 추가로, 하나의 바람직한 실시 예에서, 130, 140 및 150 각각은 컴퓨터 처리 회로, 플로우 스코어보드 모듈, SIMD, 및 로컬 데이터 버퍼를 포함할 수 있다. 하나 이상의 실시예들에서, 로컬 데이터 버퍼는 때때로 본원에서는 로컬 데이터 버퍼가 지능형 처리 타일 내에 배열될 수 있고 다양한 또는 하나 이상의 회로들, 컴포넌 트들 및/또는 지능형 처리 타일 내의 모듈들과 직접 통신할 수 있음을 나타내는 온-타일(on-tile) 메모리 또는 온-타일 버퍼로 지칭될 수 있다. 도 1a는 지능형 처리 컴퓨팅 아키텍처의 더 상세한 실시예를 포함하 고 지능형 처리 어레이와 인터페이싱하기 위한 추가적인 주변 상호 연결들을 포함한다. 예를 들어, 테스트 구조들, 모니터들, 아날로그 프로브들, 및/또는 임의의 적절한 주변 장치는 지능형 컴퓨팅 아키텍처의 지 능형 처리 어레이의 주변을 따라 연결되거나 배열될 수 있다. 하나 이상의 바람직한 실시예들에서 지능형 처리 유닛은 행렬 곱셈 가속기, 컴퓨터 처리 회로, 플로우 스코어보드 모듈, SIMD 유닛, 및 로컬 버퍼를 포함할 수 있지만, 지능형 처리 유닛(11 0)은 회로들 및 모듈들의 임의의 적절한 조합을 포함할 수 있으며, 따라서 전술한 회로들 및 모듈들 중 하나 이 상을 제외할 수 있고/있거나 본 출원에 설명된 본 발명의 범위를 의미 있게 벗어나지 않고 전술한 회로들 및 모 듈들의 임의의 조합을 포함할 수 있음에 유의해야 한다. 예를 들어, 일부 실시예들에서, 지능형 처리 유닛(11 0)은 계산 회로부 등(예를 들어, 컴퓨터 처리 회로) 없이 플로우 스코어보드 모듈 및 로컬 버퍼 (SRAM)를 포함하거나 이로 구성될 수 있다. 다른 예에서, 지능형 처리 유닛은 플로우 스코어보드 모 듈, 로컬 버퍼(SRAM), 및 오프칩 인터페이스(예를 들어, USB, PCIe, HDMI, MIPI-CSI, I2C, 이더넷, 블루투스, 및 /또는 임의의 적절한 오프칩 인터페이스 컴포넌트)를 포함하거나 이로 구성될 수 있다. 추가로 또는 대안으로, 아키텍처 내의 처리는 아날로그 처리 컴포넌트들 등을 포함할 수 있지만, 아키텍처 의 실시예들은 또한 이에 제한되는 것은 아니나, 임베디드 필드 프로그램 가능 게이트 어레이(embedded Field Programmable Gate Arrays; eFPGA), Systolic 배열, 부동 소수점 유닛 등을 포함하는 임의의 적절한 회 로부로 디지털 처리를 가능하게 할 수 있음에 유의해야 한다. 지능형 처리 어레이(지능형 가속기)는 바람직하게는 컴퓨팅 집약적 애플리케이션 등을 실행하기 위해 협력 하도록 기능할 수 있는 복수의 별개의 지능형 처리 유닛들을 포함한다. 일부 실시예들에서, 지능형 처리 어레이는 원시 입력 데이터 및/또는 업스트림 장치로부터의 데이터의 처리를 가능하게 하거나 최종 출력 상태로 처리하는 것을 가능하게 하는 하나 이상의 지능형 처리 파이프라인들을 정의하는 기능을 할 수 있다. 이 러한 실시예에서, 지능형 처리 파이프라인의 각 단계(예를 들어, 하나 이상의 이종의 지능형 처리 유닛들 등에 의해)는 애플리케이션 또는 프로그램의 부분(fraction)을 실행하도록 구체적으로 프로그래밍될 수 있는 이 종의 지능형 처리 유닛에 의해 정의될 수 있다. 지능형 처리 어레이의 이종의 지능형 처리 유닛들 각각은 바람직하게는 지능형 처리 어레이 내의 다른 또는 이종 지능형 처리 유닛들과 독립적으 로 동작하거나 계산하도록 기능한다. 따라서, 지능형 처리 파이프라인의 각 단계는 자체 처리 섹션(예를 들어, 지능형 처리 장치)으로 구성될 수 있기 때문에, 각 지능형 처리 파이프라인은 파이프라인 내의 각 단계를 따라 독립적으로 입력 데이터를 처리하는 기능을 할 수 있으므로 입력 처리 시 상당한 효율성을 가능하게 한다. 즉, 데이터 또는 원시 입력 데이터의 비동기식 처리는 각각의 지능형 처리 유닛들의 독립적인 처리 및/또 는 계산에 기초하여 달성될 수 있다. 추가로 또는 대안으로, 지능형 처리 어레이 내에 정의된 하나 이상의 지능형 처리 파이프라인들 각각은 단 일 어레이 내에서 이종의(비의존적) 애플리케이션들 또는 프로그램들의 실행을 가능하게 하도록 유연하게 구성되거나 어레이 내의 다양한 지능형 처리 유닛들에 따른 단일 애플리케이션 또는 단일 프로그램의 이종의 섹션들의 실행을 가능하게 하도록 유연하게 구성될 수 있다. 예를 들어, 제1 신경망 애플리케이션은 지능형 처리 유닛들의 제1 컬렉션을 포함하는 지능형 처리 어레이의 제1 섹션을 따라 프로그래밍될 수 있고 제2 신경망 애플리케이션은 지능형 처리 유닛들의 제2의 이종 컬렉션을 포함하는 지능형 처리 어레이 의 제2 섹션을 따라 프로그래밍될 수 있다. 제2 예에서, 단일 컴퓨팅 집약적 애플리케이션(예를 들어, 신 경망 등)은 서브 애플리케이션들(또는 프로그램들)로 분할될 수 있고 각 섹션은 어레이 내의 다른 지능형 처리 유닛에 프로그래밍될 수 있다. 추가로 또는 대안으로, 이 제2 예에서, 애플리케이션의 다수의 섹션들 또는 다수의 서브 애플리케이션들이 동일한 지능형 처리 유닛에 프로그래밍될 수 있다. 또 다른 예에서, 복수의 지능형 처리 유닛들은 단일 애플리케이션 또는 단일 프로그램의 하나 이상의 서브 섹션들을 수행하 기 위해 복합화될 수 있다. 즉, 개별 지능형 처리 유닛들은 애플리케이션 또는 프로그램의 섹션만 구현하 는 데 사용될 수 있고, 따라서 애플리케이션 또는 프로그램 전체는 전체 애플리케이션 또는 프로그램의 섹션만 각각 처리하는 복수의 지능형 처리 장치들에 의해 처리된다. 집적 회로 어레이 및/또는 각각의 지능 형 처리 유닛들은 병렬로(즉, 동시에), 동시대적으로(즉, 공통 시간 기간 내에 처리, 거의 동시에 등) 또 는 같은 시간에(즉, 다른 프로세스들 및/또는 처리 유닛들과 독립적으로 처리) 단일 애플리케이션 또는 단 일 프로그램의 다수의 개별 파티션들 및/또는 다수의 개별 애플리케이션들을 계산하도록 기능할 수 있음에 유의 해야 한다. 추가로, 임의의 적합한 및/또는 유형의 애플리케이션 또는 프로그램은 토큰들로 표시될 수 있는 종 속성을 가질 수 있는 다수의 동작 단계들로 분할될 수 있는 애플리케이션들 및/또는 프로그램들을 포함하는 지 능형 처리 어레이를 따라 분할될 수 있음에 유의해야 한다. 복수의 지능형 처리(타일) 유닛들은 바람직하게는 버퍼 또는 다른 지능형 처리 유닛과 같은 업스트림 장치 또는 업스트림 계층으로부터 수신된 일부 입력 데이터에 대해 애플리케이션 또는 프로그램을 실행하는 기 능을 한다. 상기에 언급된 바와 같이, 복수의 지능 처리 유닛들 각각은 행렬 곱셈 가속기(예를 들어, 데이 터 처리 회로 등), 컴퓨터 처리 회로(예를 들어, 마이크로프로세서), 플로우 스코어보드 모듈, SIMD 유닛 및 복수의 지능형 처리 유닛들 각각이 데이터를 출력 및/또는 애플리케이션 또는 프로그램 을 실행하기 위한 입력 데이터의 처리를 달성 및/또는 완료할 수 있게 하는 로컬 데이터 버퍼를 포함한다. 복수의 지능 처리 유닛 각각은 바람직하게는 로컬 버퍼로부터 입력 데이터를 끌어 당기고/당기거나 액세스하고, 행렬 곱셈 가속기에서 입력 데이터에 대해 계산하고, 입력 데이터에 대한 계산 결과(출력 데 이터)를 다시 그 로컬 버퍼로(또는 가능하게는 다운스트림 컴포넌트 또는 처리 섹션의 로컬 버퍼로) 출력 하는 기능을 한다. 본 출원의 부가적 및/또는 대안적인 실시예들에서, 지능형 어레이의 복수의 지능형 처리 유닛들의 하나 이 상의 별개의 서브세트들(즉, 둘 이상)는 클러스터링되고/되거나 전체 아키텍처에 비해 더 작은 칩(예를 들 어, 칩렛(chiplet), 시스템-인-패키지(system-in-a-package; SIP), 3D 패키징 등)으로 복합화될 수 있다. 이러 한 실시예들에서, 칩렛은 전체 및/또는 독립형 칩을 만들기 위해 전체 아키텍처 내에서 구성될 수 있다. 이러한 실시예들의 기술적 이점은 아키텍처의 향상된 레벨의 맞춤화가 달성될 수 있게 한다. 추가 실시예들에서, 다수의 집적 회로 아키텍처들은 다중-칩 아키텍처에서 함께 결합 및/또는 패키징될 수 있다. 이러한 실시예들에서, 다수의 아키텍처들은 시스템 또는 회로 기판(패널) 레벨에서 구성될 수 있다. 다수의 칩들 간의 상호 연결은 PCIe 또는 특별히 생성된 브리지 인터페이스들을 포함하여, 임의의 적절한 상호 연결 기술 또는 인터페이스를 사용하여 이루어질 수 있다. 플로우 스코어보드 모듈은 바람직하게는 하나 이상의 컴퓨팅 처리 회로들 및 플로우 스코어보드 서브-모듈 들의 조합에 의해 구현된다. 추가로, 플로우 스코어보드 모듈은 지능형 처리 어레이의 하나 이상의 지능형 처리 파이프라인들을 통해 흐르는 데이터의 흐름 제어 및 하나 이상의 지능형 처리 파이프라인들에 의해 처리되는 프로그램들 또는 애플리케이션들의 실행 제어를 구현하기 위한 복수의 인터페이스들을 포함할 수 있다. 바람직한 실시예에서, 플로우 스코어보드 모듈은 구성 인터페이스, 토큰 인터페이스 및 통지 인터페이스를 포함할 수 있다. 플로우 스코어보드의 구성 인터페이스는 일부 실시예들에서 충족될 때 나노프로세서 등을 통한 집적 회로가 워크로드를 개시하도록 하는 트리거 조건들을 프로그래밍하는 것과 같이, 플로우 스코어보드 모듈의 내부 상태를 판독 및 기록하는 데 사용될 수 있다. 플로우 스코어보드의 토큰 인터페이스는 지능형 집적 회로가 플로우 스코어보드에 토큰을 제시하는 것을 가능하게 할 수 있다. 토큰 인터페이 스를 통한 토큰의 제시에 응답하여, 플로우 스코어보드는 그 내부 상태를 업데이트하는 기능을 할 수 있고, 필요한 경우, 토큰 파라미터 값들(예를 들어, 방법에서 더 상세히 논의되는 바와 같이 토큰 카운트 값들 등) 및 플로우 스코어보드의 구성에 따라 통지 인터페이스를 업데이트한다. 플로우 스코어보드의 통지 인터페이스는 하나 이상의 프로그램들을 실행하기 위한 하나 이상의 조건들(또는 전제조건들)이 충족되었음 을 지능형 집적 회로에 나타내기 위해 플로우 스코어보드 모듈에 의해 구현될 수 있다. 플로우 스코 어보드 모듈의 통지 인터페이스는 지능형 집적 회로 내의 임의 개수의 동작들, 예를 들어 명시적 프 로그램 실행 없이 데이터 전송을 트리거하도록 기능할 수 있음에 유의해야 한다. 구성 인터페이스, 토큰 인터페이스, 및/또는 통지 인터페이스는 마이크로프로세서와 같은 하나 이상의 처리 회 로들에 의해 실행되는 모듈들의 조합을 포함하는 임의의 적절한 방식으로 구현될 수 있다는 점에 유의해야 한다. 지능형 집적 회로의 이종의 컴포넌트들 사이에 통신 네트워크를 설정하도록 기능하는 복수의 네트워크 온 칩 라우터들을 포함하는 네트워크 온 칩 시스템. 일 실시예에서, 칩 라우터들 각각은 아키텍처 를 따라, 특히 지능형 처리 어레이 내에서 북쪽, 남쪽, 동쪽 및 서쪽 방향들로 통신을 수신 및 송신 하기 위한 전용 입력 및 출력 링크들을 포함할 수 있다. 일부 실시예들에서, 네트워크 온 칩 시스템은 이 종의 지능형 처리 유닛들 각각이 그들 사이에서 데이터를 전달할 수 있게 하여, 하나의 지능형 처리 유닛 이 출력을 생성하기 위한 입력 데이터 처리를 완료할 때, 하나의 지능형 처리 유닛은 네트워크 온 칩 시스템의 네트워크 라우터들 중 하나 이상을 통해 다른 지능형 처리 유닛으로 출력을 전달하고/하거나 다른 지 능형 처리 유닛이 출력 데이터를 잡도록 하는(grab) 기능을 할 수 있다. 일 예로서, 디지털 토큰들 및/또 는 데이터 패킷들은 네트워크 온 칩 시스템의 복수의 네트워크 라우터들을 따라 운반될 수 있다. 집적 회로 컨트롤러는 바람직하게는 부트 로직, 보안 기능, 클로킹(clocking) 로직 등을 포함하는 칩 레벨 제어 로직을 포함한다. 타일 섹터 컨트롤러 회로는 행렬 곱셈 가속기 내에서 재프로그래밍 가능한 비휘발성 메모리들을 활성 화시키는 지능형 처리 컴퓨팅 아키텍처의 고전압 부분 또는 회로를 포함하는 것이 바람직하다. 직렬 연결 버스는 바람직하게는 범용 직렬 버스(universal serial bus; USB) 포트 및 주변 컴포넌트 상호 연결 익스프레스(PCI Express) 인터페이스 및/또는 임의의 적절한 고속 중 하나를 포함한다. 바람직한 실시예에 서, 원시 입력 데이터(예를 들어, 원시 이미지 데이터 등) 및/또는 처리된 입력 데이터(예를 들어, 업스트림 장 치, 업스트림 계층 등으로부터의)는 직렬 연결 버스에서 수신되고 기본 또는 메인 버퍼 컴포넌트를 통해 시스템으로 전달될 수 있다. 추가로 또는 대안으로, 직렬 연결 버스에서 수신된 입력 데이터는 지능형 처 리 집적 회로의 1차 버퍼로 전달되거나 네트워크 온 칩 시스템을 통해 지능형 처리 유닛의 로컬 버퍼로 직접 전달될 수 있다. 추가로 또는 대안으로, 본원에서 때때로 메인 버퍼로 지칭되는 1차 버퍼는 또한 오프 타일(off-tile)(오프-유닛(off-unit)) 메모리 또는 버퍼로 지칭될 수 있다. 특히, 아키텍처와 함께 동작하는 메인 버퍼는 지능형 처리 타일과 원격으로 떨어져 배치될 수 있으므로, 오프 타일 컴포넌트 로 간주될 수 있다. 추가로 또는 대안으로, 지능형 처리 어레이로 및/또는 로부터 및/또는 지능형 집적 회로 전체에 걸쳐 데이터를 송신하기 위해 임의의 적절한 오프-칩 연결이 구현될 수 있다. 예를 들어, 이에 제한되는 것은 아니나, 이미징 장치(예를 들어, 카메라 또는 이미지 센서), 호스트 시스템(예를 들어, 시스템 온 칩) 또는 워 크스테이션, 다른 지능형 집적 회로 등을 포함하는 임의의 적절한 주변 장치. 따라서, 토큰들을 포함하는 임의의 유형 또는 종류의 데이터는 직렬 연결 버스 또는 다른 적절한 오프칩 연결/인터페이스를 따라 전달될 수 있다는 점에 유의해야 한다. 예를 들어, 지능형 집적 회로로부터의 데 이터(예를 들어, 계산 결과들 또는 다른 출력들 등)는 직렬 연결 버스 또는 오프-칩 연결을 통해 다른 장 치 또는 시스템으로 보내질 수 있다. 따라서, 본원의 하나 이상의 실시예들에서 설명된 바와 같은 흐름 제어는 어떤 방식으로 동작 가능하게 연결되거나 인터페이싱될 때 지능형 집적 회로로부터 다른 장치들로 확장될 수 있다. 즉, 일부 실시예들에서, 토큰 기반 흐름 제어는 다수의 지능형 집적 회로들 사이 또는 장치와 호 스트 사이에서 활성화될 수 있다. 3. 데이터흐름 아키텍처에 대한 버퍼 추적 구현 방법 도 2에 도시된 바와 같이, 혼합 신호 컴퓨팅 아키텍처에서 데이터 흐름에 대한 버퍼 추적을 구현하기 위한 방법 은, 지향 계산 그래프를 구축 또는 수신하는 단계(S210), 지향 계산 그래프를 최적화하는 단계(S220), 태 스크 그래프를 구축하는 단계(S230), 태스크 그래프를 최적화하는 단계(S240), FSB에 대한 구성 파라미터를 식 별하는 단계(S250), 태스크, 버퍼 및 FSB 프로그램 코드를 생성하는 단계(S260)를 포함할 수 있다. 방법의 각 단계는 동일한 집적 회로 또는 집적 회로 컴포넌트들의 네트워크에서 병렬로 실행될 수 있음에 유의해야 한다. 하나 이상의 실시예들에서, 방법 중 어느 하나 또는 일부는 소프트웨어, 하드웨어(예를 들 어, 집적 회로), 및 펌웨어의 임의의 조합에 의해 수행될 수 있다. 하나 이상의 실시예들에서, S260에서 생성된 태스크, 버퍼 및 FSB 프로그램 코드를 생성하는 것은 혼합 신호 컴 퓨팅 장치에 의해 로드될 수 있으며, 여기서 로드는 호스트 장치에 의한 푸시, 혼합 신호 컴퓨팅 장치로부터의 풀(pull) 요청, 자동 업데이트 또는 혼합 신호 컴퓨팅 장치가 태스크, 버퍼 및/또는 FSB 프로그램 코드를 생성 하는 것을 로드하도록 하려는 다른 이벤트일 수 있다. 3.1 자동 네트워크 그래프 구축 지향 그래프 등의 입력을 식별하는 단계를 포함하는 S210는 신경망 애플리케이션, 컴퓨팅 집약적 알고리즘 등과 같은, 애플리케이션 또는 프로그램의 하나 이상의 특징들 및/또는 동작들을 예시하는 그래프를 수신하거나 새로 운 그래프를 구축하는 기능을 할 수 있다. 일부 실시예들에서, 그래프는 연결 지점들 및 네트워크의 동작(예를 들어, 노드들 간의 데이터 입력 및 출력의 흐름)을 식별하는 노드들 및 에지들을 포함하는 신경망 애플리케이션 을 나타낼 수 있다. 이러한 실시예들에서, 노드들은 별개의 네트워크 동작들을 나타낼 수 있고 노드들 간의 에 지들은 네트워크 동작들 간의 종속성, 예를 들어 노드들의 입력들 및 출력들을 나타낼 수 있다. 하나 이상의 실 시예들에서, 네트워크 연산 피연산자들은 랭크-n 텐서(rank-n tensor)들일 수 있다. 일부 실시예들에서, 그래프 는 임의의 적절한 데이터 구조 또는 언어, 예를 들어, ONNX(Open Neural Network Exchange) 형식, NNEF(Neural Network Exchange Format), C++ 프로그램, 기계어 코드 등으로 설명될 수 있음에 유의해야 한다. 추가로 또는 대안으로, 그래프는 도메인 특정 언어(domain specific language; DSL)로 설명될 수 있다. 바람직하게는, 하나 이상의 실시예들에서, S210 또는 S210의 서브셋은 그래프 컴파일러 또는 심층 신경망 컴파 일러(deep neural network compiler; dnn-complier)와 같은 컴파일러에 의해 수행될 수 있다. 일부 실시예들에 서, 컴파일러는 컴퓨팅 장치 또는 네트워크 컴퓨팅 장치, 예를 들어 서버, 클라우드 컴퓨팅 등에 상주할 수 있 다. 이러한 실시예들에서, 컴파일러는 관리자와 인터랙티브하게 기능하거나 다른 애플리케이션 또는 인터랙티브 및 다른 애플리케이션의 조합에 의해 제어될 수 있다. 일부 실시예들에서, 컴파일러는 네트워크 그래프의 수명, 신경망 내 이벤트, 다른 애플리케이션들에서 발생하는 이벤트들 또는 임의의 적절한 이벤트 또는 조건과 같은 특정 조건들에 기초하여 자동으로 실행되도록 구성될 수 있다. 바람직하게는, 계산 그래프를 판독한 후, 컴파일러는 계산 그래프를 중간 표현(intermediate representation; IR)으로 변환할 수 있으며, 여기서 IR은 주어진 애플리케이션의 계산 그래프의 시멘틱스(semantics)를 캡처한다. IR은 나머지 단계들, 예를 들어, 단계 S220, S230, S240, S250, 및 S260 또는 본원에 설명된 임의의 다른 방법 또는 기술 중 어느 하나에 대해 완전히 또는 부분적으로 사용될 수 있다. 추가로 또는 대안으로, IR 은 도메인 특정 언어(DSL)로 설명될 수 있다. 3.2 동작 변환 최적화 변환을 통해 준최적(suboptimal)(예를 들어, 저정밀도) 서브 그래프 컴포넌트들을 최적(예를 들어, 고정 밀) 서브 그래프들로 변환하는 것을 포함하는 S220은 그래프 노드들 및 에지들을 확장된 용량 및/또는 향상된 성능으로 실행될 수 있는 노드들 및 에지들로 변환하는 기능을 할 수 있다. 변환을 수행할 때, 시스템 성능에 영향을 미치는 파라미터들 예를 들어, 타일 제약 조건, 정확도, 성능, 메모리 사용량, 통신 오버헤드 등이 고려 될 수 있다. 네트워크 변환을 수행하기 위해, 2020년 3월 17일에 출원된 \"SYSTEMS AND METHODS FOR IMPLEMENTING OPERATIONAL TRANSFORMATIONS FOR RESTRICTED COMPUTATIONS OF A MIXED-SIGNAL INTEGRATED CIRCUIT\"이라는 명칭의 미국 특허 번호 제10,929,748호에 대한 참조가 이루어지며, 이는 그 전체가 본원에 참조 로서 통합된다. 모든 최적화는 하나 이상의 시스템 레벨 성능 메트릭들을 개선하는 한 사용될 수 있다. 일 실시 예에 따르면, S210에서 생성된 그래프 표현이 최적화된 상태에 있을 때, 단계 S220은 실행되지 않을 수 있고 알 고리즘은 S230으로 스킵(skip)될 수 있다. 3.3 태스크 그래프 구축 및 주석달기 | 감등 절차 태스크 그래프(task graph)를 구축하는 단계를 포함하는 S230은 태스크들 및 버퍼들을 할당하는 단계, 및 태스 크 그래프를 통해 이의 그래픽 표현을 구축하는 단계를 포함하는 기능을 할 수 있다. 바람직한 실시예에서, S230은 최적화된 네트워크 그래프(즉, 고-중 표현(High-Intermediate Representation))를 네트워크 그래프에 포함된 태스크들 및 버퍼들 및 각 동작에 대한 주석들을 포함하는 태스크 그래프(즉, 저-중 표현(Low- Intermediate representation) 또는 기계어 코드)로 변환하는 기능을 할 수 있다. 본원에 언급된 태스크는 바람 직하게는 집적 회로(예를 들어, 집적 회로)의 계산 유닛에 의해 실행 가능한 작업 유닛에 관한 것이다. 본출원의 몇몇 실시예들에서, 태스크들은 컴퓨팅 유닛들에서 실행되는 스레드(thread)들에 의해 실행될 수 있다. 하나 이상의 바람직한 실시예들에서, 태스크들의 상대적 실행 순서를 나타낼 수 있는 태스크 그래프는 태스크들 이 네트워크 동작을 구현할 수 있는 태스크들을 나타내는 노드들, 태스크들 간의 종속성을 나타낼 수 있는 에지 들, 및 버퍼들, 예를 들어, 랭크-N 버퍼들일 수 있는 태스크 피연산자들을 포함할 수 있다. 비제한 예에서, 신 경망의 도메인 특정 언어 설명 또는 그래프(S210에서 구성됨)는 태스크 그래프로 변환될 수 있다. 하나 이상의 바람직한 실시예들에서, 태스크들 및/또는 버퍼들 중 하나 이상이 컴퓨팅 타일들에 할당될 수 있다. 하나 이상의 실시예들에서, S230은 버퍼들(예를 들어, |B|), 태스크들(예를 들어, (T)), 데이터 흐름 에지들(예 를 들어, (T1) → |B| → (T2)) 등 중 하나 이상을 나타내는 기능을 할 수 있는 복수의 별개의 기호들 및 문자 들로 지향 태스크 그래프에 주석을 다는 기능을 할 수 있다. S230은 태스크 그래프의 실행 동작들을 전달하는 임의의 적절한 주석을 구성하고 태스크 그래프에 증강시키는 기능을 할 수 있다. 추가로 또는 대안으로, S230은 별개의(복잡한) 태스크들을 서브 태스크들 및 로컬 버퍼들의 시퀀스로 분해하는 기능을 할 수 있다. 이러한 실 시예들에서, S230은 각각의 서브 태스크가 태스크(예를 들어, T1)로 시작하여 태스크(Tn)로 끝나는 것을 보장하 는 기능을 할 수 있다. 추가로 또는 대안으로, 네트워크 그래프의 하나 이상의 네트워크 동작들의 변환은, 네트 워크 동작들을 시간 종속 순서(chronologically dependent order)로 정렬되고, 일부 실시예들에서는, 하나 이상 의 데이터 버퍼들이 시퀀스를 따라 종속 태스크들 사이에 주입된, 복수의 별개의 태스크들의 세트를 포함하는 태스크 시퀀스 세트로 분해하는 것을 포함할 수 있다. 따라서, 일부 실시예들에서, S230은 태스크 시퀀스 세트 에서 태스크들의 순차적인 각각의 쌍 사이에 데이터 버퍼의 인스턴스(instance)를 할당하는 기능을 할 수 있다. 따라서, 하나 이상의 실시예들에서, S230은 네트워크 그래프의 태스크 분해를 수행하여 태스크 그래프를 구축하 는 기능을 할 수 있다. 일부 실시예들에서, 태스크 분해는 네트워크 그래프의 신경망 계층과 같은 그래프 컴포 넌트를 특정 태스크들 및/또는 버퍼들의 스크링 또는 시퀀스로 단순 변환하는 것을 포함할 수 있다. 즉, S230은 네트워크 그래프의 주어진 네트워크 동작을 집적 회로에 의해 주어진 네트워크 동작을 수행하는 데 필요한 실행 가능한 태스크들 및 버퍼들의 스트링으로 변환하는 기능을 할 수 있다. S230은 한 번에 하나의 그래프 컴포넌트 또는 다수의 상호 연결된 그래프 컴포넌트들(예를 들어, 신경망의 두 개 이상의 계층들 또는 노드들)의 단순 변 환을 수행하는 기능을 할 수 있음을 인식해야 한다. 추가로 또는 대안으로, 네트워크 그래프의 네트워크 동작의 복잡성과 집적 회로의 처리 제약에 기초하여, S230 은 네트워크 작업(또는 신경망 계층)에서 작업을 로컬 작업 시퀀스 세트에 걸쳐 분배하는 기능을 할 수 있다. 즉, 일부 실시예들에서, 태스크 분해는 단일 네트워크 그래프 동작(예를 들어, 신경망 계층)을 다수의 태스크들 의 스트링들로 변환하는 것을 포함한다. 바람직한 실시예에 따르면, 감등 프로세스는 태스크들 간의 통신을 위해 이터레이터(iterator)들 및 물리적 버 퍼들을 할당할 수 있다. 본원에 인용된 바와 같이, 이터레이터는 바람직하게는 버퍼 슬라이스들의 순서화된 시 퀀스를 생성할 수 있는 루프 네스트(loop nest)의 반복 공간을 정의하는 디스크립터(descriptor)에 관한 것이다. 하나 이상의 실시예들에서, 디스크립터는 예를 들어, buffer_shape_view, 도메인, 오프셋, 윈도우, 스 트라이드(stride), 패딩(padding), num_steps 등을 포함하는 양의 정수의 다양한 별개의 튜플(tuple)들을 포함 할 수 있다. 따라서, 하나 이상의 실시예들에서, 루프의 각 반복은 버퍼 슬라이스를 생성할 수 있으며, 이는 버 퍼의 할당된 공간에 기록된 루프의 반복 출력을 포함할 수 있다. 이러한 실시예들에서, 버퍼 슬라이스의 하나 이상의 요소들은 플랫 어레이 뷰 등에서와 같이 버퍼 슬라이스가 나타나는 순서대로 관련 런처(launcher)에 대 한 입력 또는 관련 런처로부터의 출력으로서 서비스될 수 있다. 본원에 인용되는 물리적 버퍼는 바람직하게는 버퍼의 물리적 뷰와 관련되며 이는 물리적으로 메모리에 상주한다. 일부 실시예들에서, 물리적 버퍼는 논리적 버퍼보다 작을 수 있다. 추가로 또는 대안으로, 이에 제한 되는 것은 아니나, 원형 버퍼(circular buffer) 및 라인 버퍼(line buffer)를 포함하는 물리적 버퍼의 변형들이 태스크들 간의 통신을 위해 구현될 수 있다. 원형 버퍼는 바람직하게는 요소들이 물리적 버퍼의 헤드(head)에 추가되고 물리적 버퍼의 테일(tail)로부터 제거되는 헤드 및 테일 인덱스들을 갖는 물리적 버퍼에 관한 것이다. 라인 버퍼는 바람직하게는 논리 버퍼의 서브셋을 나타내는 데 사용되는 원형 버퍼에 관한 것이다. 3.4 태스크 그래프 최적화 태스크 그래프를 최적화하는 것을 포함하는 S240은 하나 이상의 태스크 그래프 요소들을 새로운 태스크 서브 그 래프들 및 로컬 버퍼들로 변환하여 태스크 그래프를 수정하는 기능을 할 수 있으며, 이는 혼합 신호 타일 컴퓨 팅 아키텍처(mixed-signal tiled computing architecture)에 대한 매핑을 개선하고 혼합 신호 타일 컴퓨팅 아키텍처 전반에 걸쳐 동시 처리를 개선할 수 있다. 하나 이상의 바람직한 실시예들에서, 태스크 리소스 요구 사 항이 타일에서 사용 가능한 리소스들을 초과할 때, 태스크가 다수의 추가 타일들에 걸쳐 실행되도록 분해될 수 있으며, 모든 계산이 완료되면 다수의 타일들의 결과들이 결합될 수 있다. 비제한적인 예로서, 태스크 리소스 요구 사항은 태스크를 성공적으로 완료하는 데 필요한 메모리, 태스크를 성공적으로 완료하는 데 필요한 컴퓨팅 대역폭, 태스크를 성공적으로 완료하는 데 필요한 컴퓨팅 시간, 태스크를 성공적으로 완료하는 데 필요한 정확 도, 및/또는 태스크가 실행될 때 태스크를 성공적으로 실행하기 위해 충족되어야 하는 임의의 태스크 제약 조건 일 수 있다. 또 다른 비제한적인 예로서, 주어진 컨볼루션 연산이 타일의 가용 리소스들을 초과하는 경우, 컨볼 루션 연산은 다수의 타일들에서 실행될 수 있는 행렬 곱셈 가속기(MMA) 연산 그룹으로 변환될 수 있으며, 각 MMA의 결과는 함께 추가되거나 연결되어 컨볼루션 연산의 결과를 생성할 수 있다. 이러한 예에서, 타일의 가용 성 임계값을 초과하는 태스크는 MMA 그룹의 MMA와 같은 하나의 컴퓨팅 타일 또는 컴퓨팅 서브 시스템에 각 서브 태스크가 할당될 수 있는 다수의 서브 태스크들로 분해되거나 분할될 수 있다. 이 방식으로, 병렬 처리 및 컴퓨 팅 효율성은 MMA 그룹에 걸쳐 서브 태스크들을 동시에 실행하여 달성될 수도 있다. 또 다른 비제한적인 예로서, 주어진 컨볼루션 연산이 타일의 가용 리소스들을 초과하는 경우, 컨볼루션 연산은 단일 타일에서 직렬로 실행될 수 있는 MMA 연산 그룹으로 변환될 수 있고, 중간 결과가 저장되고, 최종 결과가 함께 추가되거나 연결될 수 있 다. 하나 이상의 실시예들에서, 하나 이상의 컴퓨팅 성능 튜닝 파라미터들은 단계(S240)에서 사용될 수 있다. 비제 한적인 예로서, 파라미터들은 저전력 모드, 이미지 및/또는 비디오 처리 신경망이 처리되는 데 필요한 프레임 속도, 신경망을 제한할 타일 수, 하나 이상의 가용 타일들의 가용 리소스들, 및 혼합 신호 컴퓨팅 환경에서 태 스크 그래프의 성능에 영향을 미치는 임의의 기타 파라미터를 포함할 수 있다. 하나 이상의 바람직한 실시예들에서, 태스크들 및/또는 버퍼들 중 하나 이상이 타일들에 할당될 수 있다. 추가 로, 태스크들은 프로그래밍 언어, 예를 들어 C, C++, 어셈블리 코드 등으로 출력될 수 있다. 3.5 버퍼 추적 | 토큰 기반 태스크 스케줄러(FSB) 인코딩 구성 파라미터들(프로그래밍 코드) 식별하고 토큰 정보 태스크 스케줄러를 인코딩하는 것을 포함하는 S250는, 그 전체가 참조로서 본원에 통합된 미국 특허 번호 제10,606,797호에 설명된 바와 같은, 토큰 정보 태스크 스케 줄러를 활용하여 버퍼 추적 파라미터들 및 태스크 스케줄링 구성들을 생성하는 기능을 할 수 있다. 토큰 정보 태스크 스케줄러는 본원에서 때때로 \"플로우 스코어보드\" 모듈, \"FSB\" 등으로 지칭될 수 있다. 하나 이상의 실 시예들에서, 토큰 정보 스케줄러는 복수의 별개의 레지스터들, 전용 메모리 회로들, 및/또는 하나 이상의 처리 회로들(예를 들어, 나노 프로세서 등)을 포함하는 집적 회로(예를 들어, 집적 회로)의 하나 이상의 하드웨 어 회로들에 의해 구현될 수 있다. 하나 이상의 바람직한 실시예들에 따르면, 태스크들은 타일링된 컴퓨팅 유닛들에서 실행될 수 있고, 태스크들은 공유 버퍼 또는 집적 회로 상의 복수의 별개의 컴퓨팅 타일들에 의해 액세스 가능한 공용 데이터 버퍼를 갖는 메모리에 데이터를 판독 및 기록함으로써 서로 통신할 수 있다. 이러한 실시예들에서, 태스크들은 태스크가 실 행되기 전에 충족해야 하는 데이터 종속성이 있을 수 있으며, 태스크들은 데이터 종속성을 충족시키기 위해 공 유 버퍼들에 대한 액세스를 스케줄링해야 할 수 있다. 하나 이상의 실시예들에서, S350은 복수의 태스크들 각각 에 대한 데이터 및/또는 태스크 종속성을 식별하고, 종속성을 추적하기 위해 토큰 정보 스케줄러와 관련된 하나 이상의 하드웨어 또는 회로 컴포넌트들을 인코딩하기 위한 프로그래밍을 컴파일러 프로그램을 통해 자동으로 생 성하고, 종속 태스크의 실행 또는 런치를 자동으로 유발하는 것에 대한 만족을 식별하는 기능을 할 수 있다. 하나 이상의 바람직한 실시예들에서, 데이터 종속성이 충족된 후 가능한 한 빨리 태스크가 실행되면 집적 회로 의 성능이 향상될 수 있다. 하나 이상의 바람직한 실시예들에 따르면, 태스크는 그 데이터 버퍼에 충분한 양의 데이터가 기록되면 데이터 처리를 시작할 수 있다. 이러한 실시예들에서, 처리를 시작하기 위한 데이터의 양은 태스크가 처리되는 단계에 따라 달라질 수 있다. 비제한적인 예로서, 태스크 실행을 시작하는 데 많은 양의 데 이터가 필요할 수 있지만 태스크 처리를 계속하는 데 필요한 후속 데이터 양은 적을 수 있다. 하나 이상의 바람직한 실시예들에 따르면, 공유 버퍼는 버퍼가 컴퓨팅 유닛의 메모리 내에 맞도록 크기가 조정 될 수 있으며, 실행 중인 태스크가 버퍼로부터 판독될 수 있고 실행될 다음 태스크에 대한 데이터가 버퍼의 별 도 위치에 기록될 수 있도록 통신과 계산을 오버랩될 수 있을 만큼 충분히 큰 크기로 조정될 수 있다. 하나 이 상의 바람직한 실시예들에 따르면, 버퍼는 실행 중인 태스크가 원형 버퍼의 테일과 헤드 사이에서 판독 또는 기 록될 수 있는 원형 버퍼일 수 있다.하나 이상의 바람직한 실시예들에 따르면, 블록 데이터 분할은 버퍼를 다수의 태스크들에 할당하여 네트워크 동 작을 분해할 수 있다. 할당은 행 단위, 열 단위, 2D 블록 단위, ND 블록 단위(N은 임의의 적절한 정수임) 또는 태스크들이 버퍼에 할당될 수 있도록 하는 고차원 일반화를 포함하는 임의의 기타 할당일 수 있다. 도 3a 내지 3c에 도시된 바와 같이, 태스크 세트(T)는 음영 영역으로 예시된 버퍼를 공유할 수 있다. 도 3a는 행 단위 할당 을 예시할 수 있고, 도 3b는 열 단위 할당을 예시할 수 있고, 도 3c는 2D-블록 단위 할당을 예시할 수 있다. 하 나 이상의 바람직한 실시예들에 따르면, 하나 이상의 태스크들은 동일한 버퍼 또는 버퍼의 서브 섹션을 판독할 수 있다. 하나 이상의 바람직한 실시예들에 따르면, 트리거 조건 또는 태스크 런칭은 태스크의 하나 이상의 종속성이 충 족될 때일 수 있다. 일부 실시예들에서, 본원에서 때때로 트리거 조건으로 지칭되는 런칭 조건은 하나 이상의 태스크들의 완료에 기초하여 집적 회로 또는 집적 회로의 주어진 컴퓨팅 타일 내에서 하나 이상의 별개의 토큰 들이 관찰되어야 한다는 요건과 관련될 수 있다. 판독 토큰, 기록 토큰, 계산 토큰, 복사(입력/출력) 토큰 등과 같은 토큰 또는 태스크 토큰은, 이에 제한되는 것은 아니나, 나노 처리 회로, SRAM 컨트롤러 회로, 스트리밍 산 술 로직 유닛(streaming arithmetic logic unit; SALU) 회로, MMA 등을 포함하는 집적 회로의 하나 이상의 컴 포넌트들 중 어느 하나에 의해 방출될 수 있다. 이러한 실시예들에서, 트리거 조건은 하나 이상의 토큰들의 방 출로 표현되는 바와 같이 임계 데이터 양이 버퍼에 기록되었거나 태스크가 버퍼로부터 다른 임계 데이터 양을 판독했을 때 충족될 수 있다. 앞의 임계 양은 동일할 수 있으며 시스템의 임의의 컴포넌트의 상태에 기초하여 변경될 수 있다. 하나 이상의 바람직한 실시예들에 따르면, 연관된 입력 버퍼들이 소모하기에 충분한 입력 데이 터를 가질 수 있고/있거나 출력 버퍼들이 출력 데이터를 생성하기에 충분한 공간을 가질 수 있을 때 하나 이상 의 트리거 조건들이 충족될 수 있다. 하나 이상의 바람직한 실시예들에 따르면, 태스크 스케줄링은 하나 이상의 트리거 조건 세트가 충족된 경우 태 스크가 실행될 수 있는 시기를 결정할 수 있다. 이러한 바람직한 실시예들에서, 자동화된 태스크 스케줄링은 토 큰 정보 스케줄러에 의해 그리고 복수의 실행 가능한 태스크들 각각에 대한 하나 이상의 토큰 런칭 조건들 및 토큰 카운터들을 인코딩하는 것에 기초하여 구현될 수 있다. 하나 이상의 바람직한 실시예들에 따르면, 실행할 태스크에 대한 런칭 조건은 해당 태스크에 대한 모든 태스크 런칭 조건이 충족되었을 때 충족될 수 있다. 하나 이상의 바람직한 실시예들에 따르면, 버퍼로부터 판독 및 기록하는 다른 태스크들이 다른 태스크의 각각의 기록 또는 판독을 완료할 때 트리거 조건들이 충족될 수 있다. 하나 이상의 다른 태스크들이 버퍼에 기록하고/하거나 버퍼로부터 판독할 때, 기록 및/또는 판독 태스크들의 완료에 기초하여 하나 이상의 토큰들이 생성 및/또는 방 출될 수 있다. 이러한 실시예에서, 방출된 토큰들은 하나 이상의 태스크 런칭 조건들과 구체적으로 연관될 수 있는 토큰 카운터들에 의해 추적 및/또는 계산될 수 있다. 따라서, 하나 이상의 실시예들에서, 하나 이상의 토 큰 카운터들의 하나 이상의 값들은 하나 이상의 태스크 런칭 조건들(예를 들어, 토큰 카운터 값 = 0 등)을 충족 하고, 토큰 정보 태스크 스케줄러가 충족된 주어진 태스크 런칭 조건에 연관되거나 매핑된 태스크의 실행을 자 동으로 시그널링하도록 할 수 있다. 하나 이상의 바람직한 실시예들에 따르면, 런처 태스크는 태스크 스케줄링 동작들을 수행하고 작업 큐, 예를 들 어 계산 유닛을 위한 FIFO 큐에 태스크를 배치할 수 있다. 하나 이상의 바람직한 실시예들에 따르면, 이터레이터는 버퍼의 하나 이상의 슬라이스들의 순서화된 시퀀스를 생성할 수 있다. 이러한 실시예들에서, 이터레이터는 런처 태스크의 인스턴스의 피연산자가 될 수 있는 일련의 버퍼 슬라이스들을 설명할 수 있다. 이와 같이, 이터레이터의 각 반복은 런처 태스크의 호출(invocation)일 수 있다. 하나 이상의 바람직한 실시예들에 따르면, 플로우 스코어보드는 트리거 조건들을 추적할 수 있고 적어도 부분적 으로 태스크가 실행되도록 할 수 있다. 플로우 스코어보드는 미국 특허 번호 제10,606,797호 및 제10,521,395호 에 기술된 바와 같이, 동시에 실행하는 태스크들이 공유 버퍼에 액세스하고 트리거 조건들이 충족되도록 보장하 는 방법을 조정할 수 있으며, 이 둘은 모두 이 참조에 의해 그들 전체가 본원에 통합된다. 하나 이상의 바람직한 실시예들에 따르면, 버퍼 추적은 입력 버퍼 및/또는 출력 버퍼 트리거 조건들의 해당 상 태가 충족되면 태스크의 실행을 트리거하기 위해 플로우 스코어보드의 구성 파라미터들을 결정할 수 있다. 하나 이상의 바람직한 실시예들에 따르면, 태스크 그래프는 블록 데이터 분할, 예를 들어 도 3에 예로서 도시된 바와 같이 열 단위 블록 데이터 분할을 사용하여 하나 이상의 런처 태스크들로 분해될 수 있다. 도 4a 및 도 4b에 대 안으로 도시된 바와 같이. 블록 데이터 분할은 동일한 블록 데이터 분할 유형 또는 다른 블록 데이터 분할 유형, 예를 들어 행 단위 블록 데이터 분할로 반복될 수 있다. 추가로 또는 대안으로, 도 4a 및 4b의 예로서 예시된 바와 같이, 태스크 그래프가 다수의 버퍼들 및 런처들 입력으로 분해될 수 있는 경우, 데이터 종속성이 중 첩될 수 있다(예를 들어, 소비자 도메인이 다수의 생산자 도메인과 오버랩되고 그 반대의 경우도 마찬가지임). 예를 들어, 도 4b에서, 런처 태스크(Co)의 반복은 런처 태스크(To 및 T1)의 반복에 따라 달라지므로, Co 및 To 는 토큰을 통해 데이터 종속성과 통신하고 Co 및 T1도 마찬가지이다. 추가로 또는 대안으로, 하나 이상의 바람직한 실시예들에서, 런처 태스크가 실행되면, 컴퓨팅 태스크, 및 관련 입력 및 출력 피연산자들을 생성할 수 있다. 컴퓨팅 태스크는 컴퓨팅 태스크의 해당 계산 유닛의 큐, 예를 들어 FIFO 큐에 배치될 수 있다. 적절한 토큰이 계산 및/또는 수집될 때, 관련 런처 태스크가 자동으로 트리거되거나 실행되하게 되도록 각 런처 태스크는 플로우 스코어보드 프로그램 테이블의 프로그램 엔트리가 할당될 수 있다. 하나 이상의 바람직한 실시예들에 따르면, 태스크들은 컴퓨팅 유닛들에 할당될 수 있다. 3.6 코드 생성 태스크, 버퍼 및 FSB 프로그램 코드를 생성하는 단계를 포함하는 S260은 최적화된 태스크 그래프, 태스크 스케 줄링 파라미터들 및 FSB 구성 파라미터들에 기초하여 프로그램 코드를 구축하는 기능을 할 수 있다. 하나 이상 의 바람직한 실시예들에 따르면, 생성된 코드는 C, C++ 등과 같은 고급 프로그래밍 언어일 수 있다. 하나 이상 의 바람직한 실시예들에 따르면, 버퍼로부터 판독 및/또는 기록되는 바이트 수는 태스크 실행 간에 다를 수 있 다. 버퍼로부터 판독 및/또는 기록하는 바이트 수는 태스크가 실행되도록 스케줄링될 때 참조되는 정적 테이블 에 저장될 수 있다. 하나 이상의 바람직한 실시예들에 따르면, S260은 코드를 생성하고 하나 이상의 메모리 회로들(예를 들어, 레지 스터 파일들, 메인 데이터 버퍼 등) 및/또는 토큰 정보 스케줄러 및 주어진 집적 회로의 하나 이상의 컴퓨팅 타 일들 내에서 복수의 별개의 태스크들의 자동 실행을 최적화하기 위해 구현된 버퍼들의 하나 이상의 상태들의 지 능형 추적을 구현하기 위한 그 연관된 컴포넌트들을 구현하는 하나 이상의 처리 회로들 또는 모듈을 포함하는 복수의 개별 회로들 각각을 인코딩하는 기능을 할 수 있다. 예를 들어, 생성된 코드/명령어/프로그래밍은 토큰 카운터들 및 그 관련 값들, 태스크 런칭 조건들, 태스크 런칭 조건들로부터 실행 가능한 태스크들 또는 프로그 램들까지의 포인터들, 나노 프로세서들 및 기타 토큰 방출 회로들 등을 인코딩하는 데 사용될 수 있다. 바람직한 실시예들의 시스템들과 방법들 및 그 변형들은 컴퓨터 판독가능 명령어들을 저장하는 컴퓨터 판독가능 매체를 수용하도록 구성된 기계로서 적어도 부분적으로 구현 및/또는 구현될 수 있다. 명령어들은 바람직하게는 시스템 그리고 프로세서들 및/또는 컨트롤러들의 하나 이상의 부분들과 바람직하게 통합되는 컴퓨터 실행 가능 컴포넌트들에 의해 실행된다. 컴퓨터 판독 가능 매체는 RAM들, ROM들, 플래시 메모리, EEPROM들, 광학 장치들 (CD 또는 DVD), 하드 드라이브들, 플로피 드라이브들 또는 임의의 적절한 장치와 같은 임의의 적절한 컴퓨터 판 독 가능 매체들에 저장될 수 있다. 컴퓨터 실행 가능 컴포넌트는 바람직하게는 범용 또는 애플리케이션별 프로 세서이지만, 임의의 적절한 전용 하드웨어 또는 하드웨어/펌웨어 조합 장치가 대안적으로 또는 추가로 명령어들 을 실행할 수 있다. 간결함을 위해 생략되었지만, 바람직한 실시예들은 본원에 설명된 다양한 방법들의 모든 조합 및 순열을 포함한 다. 당업자는 이전의 상세한 설명과 도면들 및 청구범위로부터 인식할 수 있는 바와 같이, 다음의 청구범위에 정의 된 본 발명의 범위를 벗어나지 않고 본 발명의 바람직한 실시예들에 대한 수정 및 변경이 이루어질 수 있다.도면 도면1 도면1a 도면2 도면3a 도면3b 도면3c 도면4a 도면4b"}
{"patent_id": "10-2022-7031148", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1 내지 1a는 본 출원의 하나 이상의 실시예들에 따른 지능형 집적 회로의 개략도를 예시한다; 도 2는 본 출원의 하나 이상의 실시예들에 따른 혼합 신호 컴퓨팅 아키텍처에서 데이터흐름에 대한 버퍼 추적을 구현하는 방법을 예시한다; 도 3a 내지 3c는 본 출원의 하나 이상의 실시예에 따른 집적 회로를 사용한 자동 데이터 흐름 및 처리 방법을 위한 버퍼의 별개의 블록 데이터 분할 개략도들을 예시한다; 그리고도 4a 내지 4b는 본 출원의 하나 이상의 실시예들에 따른 별개의 블록 데이터 분할 개략도 및 종속 플로어 (dependency flor)에 대한 개략도를 예시한다."}
