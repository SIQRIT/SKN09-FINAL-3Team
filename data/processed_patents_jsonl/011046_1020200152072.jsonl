{"patent_id": "10-2020-0152072", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2021-0095547", "출원번호": "10-2020-0152072", "발명의 명칭": "전자 장치 및 이의 제어 방법", "출원인": "삼성전자주식회사", "발명자": "신다가타 크리슈나파 프라딥 쿠마르"}}
{"patent_id": "10-2020-0152072", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "전자 장치에 있어서,메모리;제1 이미지 센서(image sensor)를 포함하는 제1 카메라; 및적어도 하나의 프로세서;를 포함하고,상기 적어도 하나의 프로세서는,상기 제1 카메라를 통해 상기 전자 장치의 주변을 촬영하여 복수의 이미지 프레임을 획득하고,상기 복수의 이미지 프레임 상에 관심 영역을 설정하고,상기 복수의 이미지 프레임 각각에 대응되는 모션 식별 맵을 획득하고, 상기 획득된 모션 식별 맵에 기초하여상기 복수의 이미지 프레임 중 적어도 하나의 이미지 프레임을 선택하고,상기 선택된 적어도 하나의 이미지 프레임 상에 설정된 상기 관심 영역 상에서 객체의 움직임이 존재하는지 여부를 식별하고,상기 식별 결과에 기초하여 상기 제1 카메라를 통해 SSM(Super Slow Motion) 기능을 수행하고,상기 모션 식별 맵은 상기 복수의 이미지 프레임 각각에서 검출된 모션 데이터에 기초하여 생성되는 것을 특징으로 하는 전자 장치."}
{"patent_id": "10-2020-0152072", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 프로세서는,상기 복수의 이미지 프레임 각각을 복수의 세그먼트(segment)로 분할하고,상기 복수의 이미지 프레임 각각의 상기 복수의 세그먼트 각각에서 상기 모션 데이터를 검출하고,상기 복수의 이미지 프레임 각각의 상기 복수의 세그먼트 각각에서 검출된 모션 데이터의 평균(average)을 산출하여 상기 복수의 이미지 프레임 각각에 대한 상기 모션 식별 맵을 획득하는 전자 장치."}
{"patent_id": "10-2020-0152072", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,상기 프로세서는,상기 복수의 이미지 프레임과 관련된 메타 데이터에 기초하여 상기 복수의 이미지 프레임을 획득하는 동안 상기전자 장치가 기설정된 범위를 초과하여 움직이는지 여부를 식별하고,상기 전자 장치가 상기 기설정된 범위를 초과하여 움직인다고 식별되면, 상기 복수의 이미지 프레임을삭제하고,상기 전자 장치가 상기 기설정된 범위를 초과하여 움직이지 않는다고 식별되면, 상기 복수의 이미지 프레임 각각을 상기 복수의 세그먼트로 분할하는 전자 장치."}
{"patent_id": "10-2020-0152072", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서,상기 복수의 이미지 프레임과 관련된 메타 데이터는 상기 복수의 이미지 프레임의 안정화 정도를 나타내는 수치공개특허 10-2021-0095547-3-및 상기 복수의 이미지 프레임을 획득하는 동안 상기 전자 장치에 포함된 관성 센서 값 중 적어도 하나를 포함하는 전자 장치."}
{"patent_id": "10-2020-0152072", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서,상기 프로세서는,상기 복수의 이미지 프레임 각각에 대응되는 모션 식별 맵과 모션 임계값을 비교하고,상기 복수의 이미지 프레임 중 상기 모션 임계값을 충족하는 모션 식별 맵에 대응되는 이미지 프레임을 식별하고, 상기 식별된 이미지 프레임 중 적어도 하나의 이미지 프레임을 선택하는 전자 장치."}
{"patent_id": "10-2020-0152072", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5항에 있어서,상기 프로세서는,기설정된 지속 시간 동안 산출된 상기 복수의 세그먼트 각각 상기 모션 데이터를 평균화하고,상기 복수의 이미지 프레임이 포함된 영상의 유형 및 상기 모션 데이터의 평균에 기초하여 상기 모션 임계값을결정하는 전자 장치."}
{"patent_id": "10-2020-0152072", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에 있어서,상기 프로세서는,상기 선택된 적어도 하나의 프레임을 객체를 인식하도록 학습된 인공 지능 모델에 입력하여 상기 선택된 적어도하나의 프레임 상에 포함된 객체에 대한 정보를 획득하고,상기 획득된 객체에 대한 정보에 기초하여 상기 객체를 움직이는 객체 및 정적 객체로 분류하고, 상기 분류된움직이는 객체를 식별된 객체를 후보 객체로 할당하고,상기 관심 영역 상에서 상기 후보 객체의 움직임이 존재하는지 여부에 기초하여 상기 제1 카메라를 통해 SSM 기능을 수행하는 전자 장치."}
{"patent_id": "10-2020-0152072", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서,상기 프로세서는,상기 후보 객체를 통계 모델에 입력하여 상기 후보 객체의 속도 또는 움직임 궤적 중 적어도 하나에 대한 정보를 획득하고,상기 획득된 후보 객체의 속도 또는 움직임 궤적 중 적어도 하나에 대한 정보를 이용하여 상기 관심 영역 상에상기 후보 객체의 움직임이 존재하는지 여부를 식별하는 전자 장치."}
{"patent_id": "10-2020-0152072", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1항에 있어서,상기 프로세서는,상기 적어도 하나의 관심 영역 내에 상기 객체의 움직임이 존재한다고 식별되면, 상기 제1 카메라를 이용하여상기 SSM 기능을 수행하고,상기 적어도 하나의 관심 영역 내에 상기 객체의 움직임이 기설정된 시간 내에 존재하지 않는다고 식별되면, 상기 복수의 이미지 프레임 이후에 상기 제1 카메라를 통해 획득된 이미지 프레임를 이용하여 상기 SSM 기능을 수행할지 여부를 식별하는 전자 장치.공개특허 10-2021-0095547-4-청구항 10 제1항에 있어서,제2 이미지 센서를 포함하는 제2 카메라;를 더 포함하고,상기 프로세서는,상기 적어도 하나의 관심 영역 내에 상기 객체의 움직임이 존재한다고 식별되면, 상기 제1 카메라에서 상기 제2카메라로 스위칭하고 상기 제2 카메라를 통해 상기 SSM 기능을 수행하고,상기 제2 이미지 센서의 시야(Field of View, FOV)는 상기 제1 이미지 센서의 시야보다 넓은 것을 특징으로 하는 전자 장치."}
{"patent_id": "10-2020-0152072", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "전자 장치의 제어 방법에 있어서,제1 이미지 센서를 포함하는 제1 카메라를 포함하는 전자 장치의 제어 방법에 있어서,상기 제1 카메라를 통해 상기 전자 장치의 주변을 촬영하여 복수의 이미지 프레임을 획득하는 단계;상기 복수의 이미지 프레임 상에 관심 영역을 설정하는 단계;상기 복수의 이미지 프레임 각각에 대응되는 모션 식별 맵을 획득하고, 상기 획득된 모션 식별 맵에 기초하여상기 복수의 이미지 프레임 중 적어도 하나의 이미지 프레임을 선택하는 단계;상기 선택된 적어도 하나의 이미지 프레임 상에 설정된 상기 관심 영역 상에서 객체의 움직임이 존재하는지 여부를 식별하는 단계; 및상기 식별 결과에 기초하여 상기 제1 카메라를 통해 SSM 기능을 수행하는 단계;를 포함하고,상기 모션 식별 맵은 상기 복수의 이미지 프레임 각각에서 검출된 모션 데이터에 기초하여 생성되는 것을 특징으로 하는 제어 방법."}
{"patent_id": "10-2020-0152072", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항에 있어서,상기 모션 식별 맵을 획득하는 단계는,상기 복수의 이미지 프레임 각각을 복수의 세그먼트(segment)로 분할하는 단계;상기 복수의 이미지 프레임 각각의 상기 복수의 세그먼트 각각에서 상기 모션 데이터를 검출하는 단계; 및상기 복수의 이미지 프레임 각각의 상기 복수의 세그먼트 각각에서 검출된 모션 데이터의 평균(average)을 산출하여 상기 복수의 이미지 프레임 각각에 대한 상기 모션 식별 맵을 획득하는 단계;를 포함하는 제어 방법."}
{"patent_id": "10-2020-0152072", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제12항에 있어서,상기 모션 식별 맵을 획득하는 단계는,상기 복수의 이미지 프레임과 관련된 메타 데이터에 기초하여 상기 복수의 이미지 프레임을 획득하는 동안 상기전자 장치가 기설정된 범위를 초과하여 움직이는지 여부를 식별하는 단계;상기 전자 장치가 상기 기설정된 범위를 초과하여 움직인다고 식별되면, 상기 복수의 이미지 프레임을 삭제하는단계; 및상기 전자 장치가 상기 기설정된 범위를 초과하여 움직이지 않는다고 식별되면, 상기 복수의 이미지 프레임 각각을 상기 복수의 세그먼트로 분할하는 단계;를 포함하는 제어 방법."}
{"patent_id": "10-2020-0152072", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "공개특허 10-2021-0095547-5-제13항에 있어서,상기 복수의 이미지 프레임과 관련된 메타 데이터는 상기 복수의 이미지 프레임의 안정화 정도를 나타내는 수치및 상기 복수의 이미지 프레임을 획득하는 동안 상기 전자 장치에 포함된 관성 센서 값 중 적어도 하나를 포함하는 것을 특징으로 하는 제어 방법."}
{"patent_id": "10-2020-0152072", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제11항에 있어서,상기 선택하는 단계는,상기 복수의 이미지 프레임 각각에 대응되는 모션 식별 맵과 모션 임계값을 비교하는 단계; 및상기 복수의 이미지 프레임 중 상기 모션 임계값을 충족하는 모션 식별 맵에 대응되는 이미지 프레임을 식별하고, 상기 식별된 이미지 프레임 중 적어도 하나의 이미지 프레임을 선택하는 단계;를 포함하는 제어 방법."}
{"patent_id": "10-2020-0152072", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제15항에 있어서,기설정된 지속 시간 동안 산출된 상기 복수의 세그먼트 각각 상기 모션 데이터를 평균화하고,상기 복수의 이미지 프레임이 포함된 영상의 유형 및 상기 모션 데이터의 평균에 기초하여 상기 모션 임계값을결정하는 단계;를 더 포함하는 제어 방법."}
{"patent_id": "10-2020-0152072", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제11항에 있어서,상기 관심 영역 상에서 객체의 움직임이 존재하는지 여부를 식별하는 단계는,상기 선택된 적어도 하나의 프레임을 객체를 인식하도록 학습된 인공 지능 모델에 입력하여 상기 선택된 적어도하나의 프레임 상에 포함된 객체에 대한 정보를 획득하는 단계;상기 획득된 객체에 대한 정보에 기초하여 상기 객체를 움직이는 객체 및 정적 객체로 분류하고, 상기 분류된움직이는 객체를 식별된 객체를 후보 객체로 할당하는 단계; 및상기 관심 영역 상에서 상기 후보 객체의 움직임이 존재하는지 여부에 기초하여 상기 제1 카메라를 통해 SSM 기능을 수행하는 단계;를 포함하는 제어 방법."}
{"patent_id": "10-2020-0152072", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제17항에 있어서,상기 관심 영역 상에서 객체의 움직임이 존재하는지 여부를 식별하는 단계는,상기 후보 객체를 통계 모델에 입력하여 상기 후보 객체의 속도 또는 움직임 궤적 중 적어도 하나에 대한 정보를 획득하는 단계; 및상기 획득된 후보 객체의 속도 또는 움직임 궤적 중 적어도 하나에 대한 정보를 이용하여 상기 관심 영역 상에상기 후보 객체의 움직임이 존재하는지 여부를 식별하는 단계;를 더 포함하는 제어 방법."}
{"patent_id": "10-2020-0152072", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제11항에 있어서,상기 SSM 기능을 수행하는 단계는,상기 적어도 하나의 관심 영역 내에 상기 객체의 움직임이 존재한다고 식별되면, 상기 제1 카메라를 이용하여상기 SSM 기능을 수행하고,상기 적어도 하나의 관심 영역 내에 상기 객체의 움직임이 기설정된 시간 내에 존재하지 않는다고 식별되면, 상기 복수의 이미지 프레임 이후에 상기 제1 카메라를 통해 획득된 이미지 프레임를 이용하여 상기 SSM 기능을 수공개특허 10-2021-0095547-6-행할지 여부를 식별하는 단계;를 포함하는 제어 방법."}
{"patent_id": "10-2020-0152072", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제11항에 있어서,상기 SSM 기능을 수행하는 단계는,상기 적어도 하나의 관심 영역 내에 상기 객체의 움직임이 존재한다고 식별되면, 상기 제1 카메라에서 상기 전자 장치의 제2 카메라로 스위칭하고 상기 제2 카메라를 통해 상기 SSM 기능을 수행하는 단계;를 포함하고,상기 제2 카메라에 포함된 제2 이미지 센서의 시야(Field of View, FOV)는 상기 제1 이미지 센서의 시야보다 넓은 것을 특징으로 하는 제어 방법."}
{"patent_id": "10-2020-0152072", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "전자 장치 및 이의 제어 방법이 개시된다. 전자 장치는 메모리, 제1 이미지 센서를 포함하는 제1 카메라 및 적어 도 하나의 프로세서를 포함하고, 적어도 하나의 프로세서는 제1 카메라를 통해 전자 장치의 주변을 촬영하여 복 수의 이미지 프레임을 획득하고, 복수의 이미지 프레임 상에 관심 영역을 설정하고, 복수의 이미지 프레임 각각 에 대응되는 모션 식별 맵을 획득하고, 획득된 모션 식별 맵에 기초하여 복수의 이미지 프레임 중 적어도 하나의 이미지 프레임을 선택하고, 선택된 적어도 하나의 이미지 프레임 상에 설정된 상기 관심 영역 상에서 객체의 움 직임이 존재하는지 여부를 식별하고, 식별 결과에 기초하여 제1 카메라를 통해 SSM 기능을 수행할 수 있다."}
{"patent_id": "10-2020-0152072", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 전자 장치 및 이의 제어 방법에 관한 것으로서, 더욱 상세하게는 자동으로 SSM(Super Slow Motion) 기능을 트리거(trigger)하는 전자 장치 및 이의 제어 방법에 관한 것이다."}
{"patent_id": "10-2020-0152072", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "SSM 비디오는 일반적으로 한 장면(scene) 상에서 고속 움직임을 기록하기 위해 캡쳐(capture)된 영상을 의미한 다. SSM 비디오를 생성하기 위한 이미지 캡쳐의 프레임 속도(또는, 프레임 률(frame rate))는 480 Frames Per Second (fps), 또는 960 fps 등으로 매우 높다. 단 1분의 지속 시간을 가지는 SSM 비디오를 생성하기 위해서 많 은 양의 컴퓨팅 리소스, 스토리지 리소스 및 전력이 소모된다. 따라서, 한 장면에서 관련 이벤트에 대해서만 짧 은 지속 시간을 가지는 SSM 비디오를 생성하는 것이 선호된다. 사용자는 상기 장면에서 관련 이벤트를 리코딩(recording)할 필요가 있을 때만 SSM 비디오 녹화(또는, 리코딩) 동작을 수동으로 활성화할 수 있다. SSM 비디오 녹화 동작을 수동으로 활성화하는 경우, 예상하지 못한 장면이 빠르게 움직일 때, 사용자는 SSM 비디오 녹화 동작을 적절한 타이밍 보다 일찍 또는 늦게 활성화 할 가능성이 존재한다. 따라서, 사용자는 장면에서 관련 이벤트의 SSM 비디오를 캡처하지 못할 수 있다. 또한, 사용자는 장 면에서 관련없는 이벤트의 이미지를 캡쳐함에 따라 크기가 매우 큰 SSM 비디오를 생성할 수 있다. 상술한 문제점을 해결하기 위하여, 기존의 이미지 센서는 움직임 감지를 기반으로 SSM 비디오 리코딩 동작을 수 행하기 위해 장면에서 관련된 이벤트를 감지하도록 설계되었다. 이미지 센서는 최대한 넓은 시야를 처리하도록 제한된다. 또한, SSM 비디오 레코딩 동작을 자동으로 트리거하는 기능을 갖춘 이미지 센서를 설계하기 때문에 이미지 센서의 제조 비용이 증가한다. 이미지 센서에서 사용할 수 있는 내장 스토리지 리스소(inbuilt storage resources)는 60fps와 같은 낮은 프레임 속도로만 비디오를 레코딩하는데 적합하다. 이에 따라, 전술한 단점을 해결하거나 적어도 유용한 대안을 제공하는 것이 요구되고 있다."}
{"patent_id": "10-2020-0152072", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 개시는 상술한 문제점을 해결하기 위해 안출된 것으로서, 본 개시의 목적은 장면(scene) 상의 모션에 기초하 여 SSM 비디오 캡쳐 동작을 자동으로 트리거링하는 전자 장치 및 이의 제어 방법을 개시함에 있다."}
{"patent_id": "10-2020-0152072", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 개시의 일 실시예에 따른, 전자 장치는 메모리, 제1 이미지 센서를 포함하는 제1 카메라 및 적어도 하나의 프로세서를 포함하고, 상기 적어도 하나의 프로세서는, 상기 제1 카메라를 통해 상기 전자 장치의 주변을 촬영 하여 복수의 이미지 프레임을 획득하고, 상기 복수의 이미지 프레임 상에 관심 영역을 설정하고, 상기 복수의 이미지 프레임 각각에 대응되는 모션 식별 맵을 획득하고, 상기 획득된 모션 식별 맵에 기초하여 상기 복수의 이미지 프레임 중 적어도 하나의 이미지 프레임을 선택하고, 상기 선택된 적어도 하나의 이미지 프레임 상에 설 정된 상기 관심 영역 상에서 객체의 움직임이 존재하는지 여부를 식별하고, 상기 식별 결과에 기초하여 상기 제1 카메라를 통해 SSM(Super Slow Motion) 기능을 수행하고, 상기 모션 식별 맵은 상기 복수의 이미지 프레임 각 각에서 검출된 모션 데이터에 기초하여 생성될 수 있다. 본 개시의 일 실시예로, 제1 이미지 센서를 포함하는 제1 카메라를 포함하는 전자 장치의 제어 방법에 있어서, 상기 제1 카메라를 통해 상기 전자 장치의 주변을 촬영하여 복수의 이미지 프레임을 획득하는 단계, 상기 복수 의 이미지 프레임 상에 관심 영역을 설정하는 단계, 상기 복수의 이미지 프레임 각각에 대응되는 모션 식별 맵 을 획득하고, 상기 획득된 모션 식별 맵에 기초하여 상기 복수의 이미지 프레임 중 적어도 하나의 이미지 프레 임을 선택하는 단계, 상기 선택된 적어도 하나의 이미지 프레임 상에 설정된 상기 관심 영역 상에서 객체의 움 직임이 존재하는지 여부를 식별하는 단계, 상기 식별 결과에 기초하여 상기 제1 카메라를 통해 SSM 기능을 수행 하는 단계를 포함할 수 있다."}
{"patent_id": "10-2020-0152072", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 실시 예들은 다양한 변환을 가할 수 있고 여러 가지 실시 예를 가질 수 있는바, 특정 실시 예들을 도면에 예 시하고 상세한 설명에 상세하게 설명하고자 한다. 그러나 이는 특정한 실시 형태에 대해 범위를 한정하려는 것 이 아니며, 본 개시의 실시 예의 다양한 변경(modifications), 균등물(equivalents), 및/또는 대체물 (alternatives)을 포함하는 것으로 이해되어야 한다. 도면의 설명과 관련하여, 유사한 구성요소에 대해서는 유 사한 참조 부호가 사용될 수 있다. 본 개시를 설명함에 있어서, 관련된 공지 기능 혹은 구성에 대한 구체적인 설명이 본 개시의 요지를 불필요하게 흐릴 수 있다고 판단되는 경우 그에 대한 상세한 설명은 생략한다. 덧붙여, 하기 실시 예는 여러 가지 다른 형태로 변형될 수 있으며, 본 개시의 기술적 사상의 범위가 하기 실시 예에 한정되는 것은 아니다. 오히려, 이들 실시 예는 본 개시를 더욱 충실하고 완전하게 하고, 당업자에게 본개시의 기술적 사상을 완전하게 전달하기 위하여 제공되는 것이다. 본 개시에서 사용한 용어는 단지 특정한 실시 예를 설명하기 위해 사용된 것으로, 권리범위를 한정하려는 의도 가 아니다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 개시에서, \"가진다,\" \"가질 수 있다,\" \"포함한다,\" 또는 \"포함할 수 있다\" 등의 표현은 해당 특징(예: 수치, 기능, 동작, 또는 부품 등의 구성요소)의 존재를 가리키며, 추가적인 특징의 존재를 배제하지 않는다. 본 개시에서, \"A 또는 B,\" \"A 또는/및 B 중 적어도 하나,\" 또는 \"A 또는/및 B 중 하나 또는 그 이상\"등의 표현 은 함께 나열된 항목들의 모든 가능한 조합을 포함할 수 있다. 예를 들면, \"A 또는 B,\" \"A 및 B 중 적어도 하나,\" 또는 \"A 또는 B 중 적어도 하나\"는, 적어도 하나의 A를 포함, 적어도 하나의 B를 포함, 또는 적어도 하나의 A 및 적어도 하나의 B 모두를 포함하는 경우를 모두 지칭할 수 있다. 본 개시에서 사용된 \"제1,\" \"제2,\" \"첫째,\" 또는 \"둘째,\"등의 표현들은 다양한 구성요소들을, 순서 및/또는 중 요도에 상관없이 수식할 수 있고, 한 구성요소를 다른 구성요소와 구분하기 위해 사용될 뿐 해당 구성요소들을 한정하지 않는다. 어떤 구성요소(예: 제1 구성요소)가 다른 구성요소(예: 제2 구성요소)에 \"(기능적으로 또는 통신적으로) 연결되 어((operatively or communicatively) coupled with/to)\" 있다거나 \"접속되어(connected to)\" 있다고 언급된 때에는, 상기 어떤 구성요소가 상기 다른 구성요소에 직접적으로 연결되거나, 다른 구성요소(예: 제3 구성요 소)를 통하여 연결될 수 있다고 이해되어야 할 것이다. 반면에, 어떤 구성요소(예: 제1 구성요소)가 다른 구성요소(예: 제2 구성요소)에 \"직접 연결되어\" 있다거나 \"직 접 접속되어\" 있다고 언급된 때에는, 상기 어떤 구성요소와 상기 다른 구성요소 사이에 다른 구성요소(예: 제3 구성요소)가 존재하지 않는 것으로 이해될 수 있다. 본 개시에서 사용된 표현 \"~하도록 구성된(또는 설정된)(configured to)\"은 상황에 따라, 예를 들면, \"~에 적합 한(suitable for),\" \"~하는 능력을 가지는(having the capacity to),\" \"~하도록 설계된(designed to),\" \"~하도 록 변경된(adapted to),\" \"~하도록 만들어진(made to),\" 또는 \"~를 할 수 있는(capable of)\"과 바꾸어 사용될 수 있다. 용어 \"~하도록 구성된(또는 설정된)\"은 하드웨어적으로 \"특별히 설계된(specifically designed to)\" 것만을 반드시 의미하지 않을 수 있다. 대신, 어떤 상황에서는, \"~하도록 구성된 장치\"라는 표현은, 그 장치가 다른 장치 또는 부품들과 함께 \"~할 수 있는\" 것을 의미할 수 있다. 예를 들면, 문구 \"A, B, 및 C를 수행하도록 구성된(또는 설정된) 프로세서\"는 해당 동작을 수행하기 위한 전용 프로세서(예: 임베디드 프로세서), 또는 메모리 장치에 저장된 하나 이상의 소프트 웨어 프로그램들을 실행함으로써, 해당 동작들을 수행할 수 있는 범용 프로세서(generic-purpose processor)(예: CPU 또는 application processor)를 의미할 수 있다. 실시 예에 있어서 '모듈' 혹은 '부'는 적어도 하나의 기능이나 동작을 수행하며, 하드웨어 또는 소프트웨어로 구현되거나 하드웨어와 소프트웨어의 결합으로 구현될 수 있다. 또한, 복수의 '모듈' 혹은 복수의 '부'는 특정 한 하드웨어로 구현될 필요가 있는 '모듈' 혹은 '부'를 제외하고는 적어도 하나의 모듈로 일체화되어 적어도 하 나의 프로세서로 구현될 수 있다. 한편, 도면에서의 다양한 요소와 영역은 개략적으로 그려진 것이다. 따라서, 본 발명의 기술적 사상은 첨부한 도면에 그려진 상대적인 크기나 간격에 의해 제한되지 않는다. 본 개시는, 장면(scene) 상의 모션에 기초하여, 장면의 SSM 비디오의 캡처를 자동으로 트리거링하기 전자 장치 및 이의 제어 방법을 개시한다. 기존 시스템과 달리, 본 개시의 전자 장치는 장면 상의 모션에 기초하여 SSM 비 디오가 녹화될 필요가 있는 정확한 순간을 식별할 수 있다. 따라서, SSM 비디오는 관련 있는 이미지 프레임만을 포함할 수 있다. 본 개시의 또 다른 실시예로, 전자 장치는, 장면의 이미지 프레임상의 ROI에서의 모션을 검출되면, 장면의 SSM 비디오의 캡처를 트리거할 수 있다. 본 개시의 또 다른 실시예로, 전자 장치는 장면에서 이동 가능한 후보 객체의 모션을 추적하고, 이동 가능한 후 보 객체의 모션에 기초하여 SSM 비디오를 캡처하기 위한 트리거를 예측하기 위해 장면의 이미지 프레임을 분석 할 수 있다. 기존 시스템과 달리, 본 개시의 전자 장치는 예측에 기초하여 장면의 SSM 비디오의 녹화를 트리거링하기 위해 설정(또는, 준비)될 수 있다. 따라서, 전자 장치는 SSM 비디오 녹화를 적시에 개시함으로써 장면의 관련된 이미지 프레임을 녹화하는 것을 놓치지 않을 수 있다. 본 개시의 또 다른 실시예로, 전자 장치는, 이동 가능한 후보 객체와 연관된 관련 이벤트를 녹화하기 위하여, 더 작은 시야(Field of View, FOV)를 갖는 이미지 센서를 통한 이미지 프레임의 녹화에서 더 큰 시야를 갖는 이 미지 센서를 통한 이미지 프레임의 녹화로 자동 스위칭할 수 있다. 기존 시스템과는 달리, 전자 장치는, 더 작은 FOV의 이미지 프레임을 녹화하는 동안 이동 가능한 후보 객체가 더 작은 FOV로부터 이동하는 것을 검출하는 것에 응답하여 더 큰 FOV의 이미지 프레임을 녹화하도록 스위칭할 수 있다. 따라서, 전자 장치는 이동 가능한 후보 객체가 더 작은 FOV 외부로 이동하더라도 장면에서 이동 가능 한 후보 객체를 포함하는 SSM 비디오를 캡처할 수 있다. 본 개시는 전자 장치를 이용하여 장면의 슈퍼 슬로우 모션(SSM: Super Slow Motion) 비디오의 캡처를 자동으로 제어하는 방법을 제공한다. 본 개시에 따른, 전자 장치의 제어 방법은 전자 장치의 제1 이미지 센서의 시야 (FOV: Field of View)에 표시된 장면의 복수의 이미지 프레임을 수신하는 단계를 포함하며, 이 때 복수의 이미 지 프레임의 각각에는 적어도 하나의 ROI가 포함될 수 있다. 또한, 전자 장치의 제어 방법은 복수의 이미지 프 레임의 각각에 대한 신뢰도 맵(또는, 모션 검출맵)을 결정하는 단계를 포함하고, 이 때, 신뢰도 맵은 상기 적어 도 하나의 관심 영역(ROI: Region of Interest)의 각각의 모션 데이터에 대응될 수 있으며, 신뢰도 맵은 모션 식별 맵이라는 용어로 표현될 수 있다. 또한, 전자 장치의 제어 방법은 신뢰도 맵에 기초하여 복수의 이미지 프 레임 중 적어도 하나의 이미지 프레임을 선택하는 단계 및 적어도 하나의 선택된 이미지 프레임에서 적어도 하 나의 ROI의 모션을 검출하는 단계를 포함할 수 있다. 그리고, 전자 장치의 제어 방법은 적어도 하나의 선택된 이미지 프레임에서 적어도 하나의 ROI에서의 모션의 검출에 기초하여 SSM 비디오의 캡처를 트리거링하는 단계를 포함한다. 기존의 제어 방법 및 시스템과 달리, 본 개시의 전자 장치는, 장면을 미리 보기 하는 동안, 전자 장치에 영향을 미치는 글로벌 모션(예를 들어, 핸드 쉐이크(handshake)) 및 조명 조건(lighting condition)의 급격한 변화를 검출할 수 있다. 또한, 전자 장치는 전자 장치에 영향을 미치는 글로벌 모션과 조명 조건의 급격한 변화로 인해 발생될 수 있는 SSM 비디오 캡처에 대한 잘못된 트리거를 제거할 수 있다. 따라서, SSM 비디오를 녹화하기 위한 트리거 동작은 전자 장치의 성능의 손상 없이 정확할 수 있다. 또한, 본 개시를 통해 제안하는 방법은 SSM 비디오를 캡처하기 위해 30 fps, 120 fps, 480 fps, 960 fps 등과 같은 임의의 유형의 프레임 레이트를 갖는 와이드 이미지 센서, 텔레(tele) 이미지 센서, 울트라-와이드(UW: Ultra-Wide) 이미지 센서 등과 같은 임의의 유형의 기존 이미지 센서를 사용하여 구현하는 데 적합할 수 있다. 이하에서는, 도 1 내지 도 15를 참조하여 본 개시에 대해 구체적으로 설명하도록 한다. 도 1은 본 개시의 일 실시예로, 장면(scene)의 SSM 비디오의 캡처를 자동으로 제어하기 위한 전자 장치의 블록도이다. 여기서, 전자 장치는 스마트 폰, 태블릿 컴퓨터, 퍼스널 디지털 어시스턴스(PDA: Personal Digital Assistance), 웨어러블 디바이스(wearable device), 사물 인터넷(IoT: Internet of Things), 카메라, 로봇 등으로 구현될 수 있으나, 이에 한정되지 않는다. 도 1에 도시된 바와 같이, 전자 장치는 SSM 비디오 컨트롤러, 메모리, 프로세서, 적어도 하나의 이미지 센서 및 통신부를 포함할 수 있다. 다만, 도 1에 도시된 구성은 본 개시의 실시 예들 을 구현하기 위한 예시도이며, 통상의 기술자에게 자명한 수준의 적절한 하드웨어 및 소프트웨어 구성들이 전자 장치에 추가로 포함될 수 있다. SSM 비디오 컨트롤러는 메모리, 프로세서 및 적어도 하나의 이미지 센서에 연결(또는, 커 플링(coupling))될 수 있다. 적어도 하나의 이미지 센서에 대한 예는 와이드 이미지(Wide image) 센서, 텔레 이미지(tele-image) 센서 및 울트라-와이드 이미지(Ultra-Wide image) 센서 등이 있으나 이에 한정되지 않는다. 본 개시의 일 실시예로, 적어도 하나의 이미지 센서는 제1 이미지 센서(140A) 및 제2 이미지 센서(140B)가 포함될 수 있다. 이 때, 제2 이미지 센서(140B)의 FOV는 제1 이미지 센서(140A)의 FOV(Field of View)보다 클 수 있다. 예를 들면, 제1 이미지 센서(140A)는 장면의 와이드 FOV를 캡처하도록 설계되고, 제2 이미지 센서 (140B)는 장면의 울트라 와이드(Ultra-Wide, UW) FOV를 캡처하도록 설계될 수 있다. 실시예에서, 이미지 센서 는 전하-결합 소자(CCD: Charge-Coupled Device) 모듈 또는 상보형 금속 산화물 반도체(CMOS:Complementary Metal Oxide Semiconductor) 모듈로 이루어질 수 있다. SSM 비디오 컨트롤러는 전자 장치의 제1 이미지 센서(140A)의 FOV에 표시된 장면의 복수의 이미지 프 레임을 수신하도록 구성될 수 있다. 이 때, 복수의 이미지 프레임의 각각에는 적어도 하나의 ROI가 포함될 수 있다. 다른 실시예에서, FOV가 ROI일 수 있다. SSM 비디오 컨트롤러는 제1 이미지 센서(140A)의 FOV 상에 표시된 장면의 미리 보기 화면을 표시하도록 전자 장치의 디스플레이를 제어할 수 있다. 일 실시예로, 사 용자는 전자 장치의 디스플레이 상에 ROI를 마킹(marking)함으로써 적어도 하나의 ROI를 전자 장치에 입력할 수 있다. 일 실시예로, 전자 장치는 사용자로부터 입력이 수신되지 않으면, 제1 이미지 센서(140 A)의 FOV를 ROI로 식별(또는, 간주)할 수 있다. SSM 비디오 컨트롤러는 복수의 이미지 프레임의 각각에 대한 신뢰도 맵(confidence map)(또는, 모션 식별 맵)을 결정할 수 있다. 이 때, 신뢰도 맵은 적어도 하나의 ROI의 각각의 모션 데이터에 대응될 수 있다. 구체적 으로, SSM 비디오 컨트롤러는 복수의 이미지 프레임의 각각을 복수의 세그먼트(예를 들어, 직사각형 블 록)로 분할(또는, 세그먼트화)할 수 있다. 또한, SSM 비디오 컨트롤러는 통계 변수의 세트(예를 들어, 평 균(mean), 분산 등)를 이용하여 복수의 이미지 프레임 각각의 복수의 세그먼트의 각각의 세그먼트의 모션 데이 터를 산출(또는, 컴퓨팅(computing))함으로써 입력 모델링(input modeling)을 수행할 수 있다. 또한, SSM 비디 오 컨트롤러는 복수의 이미지 프레임 각각의 복수의 세그먼트의 모션 데이터의 평균(average)을 산출(또는, 컴퓨팅)함으로써 복수의 이미지 프레임 각각에 대한 신뢰도 맵을 결정할 수 있다. 본 개시의 일 실시로, SSM 비디오 컨트롤러는 이미지 프레임과 연관된 메타 데이터(meta data)에 기초하여 전자 장치의 글로벌 모션(예를 들어, 핸드 쉐이크)에 의해 복수의 이미지 프레임의 이미지 프레임이 영향 을 받는지를 식별하도록 구성된다. 예를 들어, 이미지 프레임과 연관된 메타데이터는 이미지 프레임의 줌 (zoom), 이미지 프레임의 이미지 안정화, 이미지 프레임의 폭 및 높이, 이미지 프레임의 속성, 및 이미지 프레 임을 미리 보기하는 동안 생성된 관성 센서 값 중 적어도 하나가 포함될 수 있다. SSM 비디오 컨트롤러는, 글로벌 모션에 의해 이미지 프레임이 영향을 받는 것으로 식별되면, 이미지 프레 임을 폐기하고, 글로벌 모션이 후속 이미지 프레임에 영향을 미치는지를 여부를 식별하기 위해 복수의 이미지 프레임 중 후속 이미지 프레임을 선택할 수 있다. SSM 비디오 컨트롤러는, 글로벌 모션에 의해 이미지 프 레임이 영향을 받지 않는 것으로 식별되면, 이미지 프레임을 복수의 세그먼트로 분할(또는, 세그먼트화)할 수 있다. SSM 비디오 컨트롤러는 신뢰도 맵에 기초하여 복수의 이미지 프레임 중 적어도 하나의 이미지 프레임을 선 택할 수 있다. 일 실시예로, SSM 비디오 컨트롤러는 복수의 이미지 프레임 각각의 신뢰도 맵을 페어(fair) 신뢰도 임계값과 비교할 수 있다 또한, SSM 비디오 컨트롤러는 신뢰도 맵이 페어 신뢰도 임계값을 충족하 는 복수의 이미지 프레임 중 적어도 하나의 이미지 프레임을 선택할 수 있다. 일 실시예로, SSM 비디오 컨트롤러는 제1 이미지 센서(140A)의 FOV에 표시된 장면의 이미지 프레임들을 수 신할 수 있다. 또한, SSM 비디오 컨트롤러는 이미지 프레임 각각을 복수의 영역으로 분할(또는, 세그먼트 화)할 수 있다. 또한, SSM 비디오 컨트롤러는 이미지 프레임 각각의 세그먼트화된 영역 각각에서 모션 데 이터를 산출(또는, 컴퓨팅)할 수 있다. 또한, SSM 비디오 컨트롤러는 고정된 지속 시간 동안(예를 들어, 5 초) 모델링된 이미지 프레임의 세그먼트화된 영역에서 모션 데이터를 평균화할 수 있다. 또한, SSM 비디오 컨트 롤러는 적어도 하나의 인공 지능 모델을 이용하여 장면의 유형 및 모션 데이터의 평균에 기초하여 페어 신 뢰도 임계값을 결정할 수 있다. 장면의 유형은 일 예로 더 빠른 모션을 포함하는 장면, 슬로우 모션을 포함하는 장면 등이 포함될 수 있다. 일 실시예에서, 장면의 유형은 장면을 분석함으로써 결정될 수 있다. SSM 비디오 컨트롤러는 적어도 하나의 선택된 이미지 프레임에서 적어도 하나의 ROI의 모션을 검출할 수 있다. 일 실시예로, SSM 비디오 컨트롤러는 적어도 하나의 선택된 프레임을 인공 지능(AI: Artificial Intelligence) 모델에 입력함으로써 적어도 하나의 선택된 프레임에서 이용 가능한 적어도 하나의 객체를 식별 하기 위해 AI 장면 분석을 수행할 수 있다. 또한, SSM 비디오 컨트롤러는 통계 모델에 기초하여 적어도 하 나의 식별된 객체의 속도를 결정하기 위하여 이미지 프레임에 대한 통계 분석을 수행할 수 있다. SSM 비디오 컨 트롤러는 적어도 하나의 식별된 객체의 속도에 기초하여 적어도 하나의 선택된 이미지 프레임에서 적어도 하나의 ROI의 모션을 검출할 수 있다. 복수의 모듈 중 적어도 하나는 AI 모델을 통해 구현될 수 있다. AI와 연관된 기능은 메모리 및 프로세서 를 통해 수행될 수 있다.프로세서는 하나 또는 복수의 프로세서를 포함할 수 있다. 이 때, 하나 또는 복수의 프로세서는 중앙 처리 장치(CPU: Central Processing Unit), 어플리케이션 프로세서(AP: Application Processor) 등과 같은 범용 프 로세서, 그래픽 프로세싱 유닛(GPU: Graphics Processing Unit), 비주얼 프로세싱 유닛(VPU)과 같은 그래픽-전 용 프로세싱 유닛 및/또는 신경 프로세싱 유닛(NPU: Neural Processing Unit)과 같은 AI-전용 프로세서일 수 있 다. 일 실시예로, 하나 또는 복수의 프로세서는 메모리에 저장된 사전 규정된 동작 규칙 또는 AI 모델에 따라 입력 데이터의 프로세싱을 제어할 수 있다. 사전 규정된 동작 규칙 또는 AI 모델은 훈련 또는 학습을 통 해 제공된다. 여기서, 학습을 통해 제공된다는 것은 학습 방법을 복수의 학습 데이터에 적용하여 사전 규정된 동작 규칙 또는 원하는 특성의 AI 모델이 만들어진다는 것을 의미한다. 학습은 실시예에 따라 AI가 수행되는 전자 장치 자 체에서 수행될 수 있으며, 및/또는 별도의 서버/시스템을 통해 구현될 수 있다. AI 모델은 복수의 신경망 계층으로 구성될 수 있다. 각각의 계층은 복수의 가중치를 가지며, 이전 계층의 계산 과 복수의 가중치의 연산을 통해 계층 연산을 수행한다. 신경망의 예는 컨벌루션 신경망(CNN: Convolutional Neural Network), 심층 신경망(DNN: Deep Neural Network), 순환 신경망(RNN: Recurrent Neural Network), 제 한적 볼츠만 머신(RBM: Restricted Boltzmann Machine), 심층 신뢰망(DBN: Deep Belief Network), 양방향 순환 심층 신경망(BRDNN: Bidirectional Recurrent Deep Neural Network), 생성적 적대망(GAN: Bidirectional Recurrent Deep Neural Network) 및 심층 Q-네트워크를 포함하지만, 이에 한정되지 않는다. 학습 방법은 결정 또는 예측을 하도록 타겟 장치를 유도, 허용 또는 제어하기 위해 복수의 학습 데이터를 사용 하여 사전 결정된 타겟 장치(예를 들어, 로봇, 전자 장치)를 훈련시키기 위한 방법이다. 학습 방법의 예는 감독 학습, 비감독 학습, 반-감독(semi-supervised) 학습 또는 강화 학습을 포함하지만, 이에 한정되지 않는다. 일 실시예로, SSM 비디오 컨트롤러는 적어도 하나의 선택된 프레임에서 이용 가능한 적어도 하나의 객체를 식별하기 위해 AI 모델을 훈련시킬 수 있다. SSM 비디오 컨트롤러는 전자 장치의 제2 이미지 센서 (140B)로부터 복수의 이미지 프레임을 수신할 수 있다. SSM 비디오 컨트롤러는 AI 모델에서 학습된 지식을 사용하여 제2 이미지 센서(140B)로부터 수신된 각각의 프레임에서 적어도 하나의 객체를 인식할 수 있다. SSM 비디오 컨트롤러는 인식에 기초하여 적어도 하나의 객체를 이동 가능한 객체 또는 정적 객체로서 분류할 수 있다. SSM 비디오 컨트롤러는 적어도 하나의 분류된 객체에 기초하여 신경망 노드 각각에 대한 가중치 를 결정할 수 있다. 또한, SSM 비디오 컨트롤러는 각각의 신경망 노드에 대한 가중치에 기초하여 AI 모델 을 훈련시킬 수 있다. 일 실시예로, SSM 비디오 컨트롤러는 적어도 하나의 식별된 객체의 속도를 결정하기 위해 적어도 하나의 통계 모델을 훈련시킬 수 있다. SSM 비디오 컨트롤러는 적어도 하나의 객체와 연관된 복수의 파라미터를 획득할 수 있다. 일 실시예로, 복수의 파라미터는 객체 유형, 경계 박스(bounding box) 및 객체 간 관계를 포함 할 수 있다. SSM 비디오 컨트롤러는 복수의 파라미터에 기초하여 적어도 하나의 객체의 속도를 결정할 수 있다. SSM 비디오 컨트롤러는 적어도 하나의 선택된 이미지 프레임에서 적어도 하나의 ROI에서의 모션의 검출에 기초하여 SSM 비디오의 캡처를 트리거할 수 있다. 일 실시예로, SSM 비디오 컨트롤러는 적어도 하나의 선 택된 이미지 프레임에서 적어도 하나의 ROI의 모션이 검출되는지 여부를 식별할 수 있다. SSM 비디오 컨트롤러 는, 적어도 하나의 ROI의 모션이 적어도 하나의 선택된 이미지 프레임 상에서 검출되면, SSM 비디오를 캡 처할 수 있다. SSM 비디오 컨트롤러는, 적어도 하나의 ROI의 모션이 적어도 하나의 선택된 이미지 프레임 에서 검출되지 않는 것으로 식별되면, 적어도 하나의 ROI의 모션을 검출하기 위해 이미지 프레임의 다음 세트를 수신할 수 있다. SSM 비디오 컨트롤러는 적어도 하나의 선택된 이미지 프레임에서 적어도 하나의 ROI의 검 출된 모션이 모션 임계값을 충족하는지 여부를 식별할 수 있다. SSM 비디오 컨트롤러는, 적어도 하나의 ROI의 검출된 모션이 모션 임계값을 충족하지 않는다고 식별되면, 제1 이미지 센서(140A)를 사용하여 SSM 비디 오를 캡처할 수 있다. SSM 비디오 컨트롤러는, 적어도 하나의 ROI의 검출된 모션이 모션 임계값을 충족하 는 것으로 식별되면, 제1 이미지 센서(140A)에서 제2 이미지 센서(140B)로 자동으로 스위칭할 수 있다. 또한, SSM 비디오 컨트롤러는 제2 이미지 센서(140B)를 사용하여 SSM 비디오를 캡처할 수 있다. 메모리는 녹화된 SSM 비디오를 저장할 수 있다. 메모리에는 비휘발성 저장 요소(element)가 포함될 수 있다. 비휘발성 저장 요소는 예를 들어, 자기 하드 디스크, 광 디스크, 플로피 디스크, 플래시 메모리 또는전기적 프로그래머블 메모리(EPROM: Electrically Programmable Memory) 또는 전기적 소거 가능 및 프로그래머 블 메모리(EEPROM: Electrically Erasable and Programmable Memory)의 형태를 포함할 수 있다. 일 실시예로, 메모리는 비일시적 저장 매체로 구현(또는, 간주)될 수 있다. \"비일시적\"이라는 용어는 저장 매체가 반송파 또는 전파된 신호로 구현되지 않음을 나타낼 수 있다. 그러나, \"비일시적\"이라는 용어는 메모리 가 이동될 수 없는 것으로 해석되어서는 안 된다. 일부 예에서, 메모리는 각각 메모리보다 더 많은 양의 정보를 저장하도록 구성될 수 있다. 특정 예에서, 비일시적 저장 매체는 시간이 지남에 따라 변할 수 있는 데이터를 (예를 들어, 랜덤 액세스 메모리(RAM: Random Access Memory) 또는 캐시에) 저장할 수 있다. 프 로세서는 메모리에 저장된 명령을 실행하도록 구성될 수 있다. 이미지 신호 프로세서(ISP: Image Signal Processor)는 프로세서의 일 예시이다. 통신부는 전자 장치의 하드웨어 구성 요소 사이 에서 내부적으로 통신하도록 구성된다. 도 1은 전자 장치의 하드웨어 구성 요소를 도시하고 있으나, 다른 실시예가 이에 한정되지 않는다. 다른 실시예에서, 전자 장치는 도 1에 도시된 것보다 더 적은 혹은 더 많은 수의 구성 요소를 포함할 수 있다. 또한, 구성 요소의 라벨 또는 이름은 예시의 목적으로만 사용되며 본 개시의 범위를 한정하지 않는다. 하나 이 상의 구성 요소가 함께 조합되어 장면의 SSM 비디오의 캡처를 자동으로 제어하는 동일하거나 실질적으로 유사한 기능을 수행할 수 있다. 도 2는 본 개시의 일 실시예에 따른, 장면의 SSM 비디오의 캡처를 트리거링(triggering)하기 위한 SSM 비디오 컨트롤러의 블록도이다. 일 실시예로, SSM 비디오 컨트롤러에는 이미지 프레임 수신기(Image frame receiver), 신뢰도 맵 생성기(Confidence map generator), 모션 검출기(Motion detector), AI 장면 분석기(AI scene analyzer), 통계 분석기(Statistical analyzer) 및 SSM 트리거링 엔진(SSM triggering engine)이 포함될 수 있다. 이미지 프레임 수신기는 전자 장치의 제1 이미지 센서(140A)의 FOV에 표시된 장면의 복수의 이미지 프레임을 수신한다. 신뢰도 맵 생성기는 복수의 이미지 프레임 각각에 대한 신뢰도 맵을 판단(또는, 획득)할 수 있다. 일 실시 예로, 신뢰도 맵 생성기는 복수의 이미지 프레임 각각을 복수의 세그먼트(예를 들어, 직사각형 블록)로 분 할(또는, 세그먼트화)할 수 있다. 또한, 신뢰도 맵 생성기는 통계 변수(statistical variables)의 세트(예 를 들어, 평균(mean), 분산 등)를 이용하여 복수의 이미지 프레임 각각의 복수의 세그먼트의 각각의 모션 데이 터(즉, 세그먼트의 모션 데이터)를 산출(또는, 컴퓨팅)함으로써 입력 모델링을 수행할 수 있다. 또한, 신뢰도 맵 생성기는 복수의 이미지 프레임 각각의 복수의 세그먼트의 모션 데이터의 평균(average)을 산출(또는, 컴퓨팅)함으로써 복수의 이미지 프레임 각각에 대한 신뢰도 맵을 결정할 수 있다. 일 실시예로, 모션 검출기는 이미지 프레임과 연관된 메타 데이터에 기초하여 전자 장치의 글로벌 모 션이 복수의 이미지 프레임의 이미지 프레임에 의해 영향을 받는지 여부를 식별할 수 있다. 또한, 이미지 프레 임 수신기는, 글로벌 모션이 이미지 프레임에 영향을 미치는 것으로 식별되면, 이미지 프레임을 폐기하고, 글로벌 모션이 후속 이미지 프레임에 영향을 미치는지 여부를 식별하기 위해 복수의 이미지 프레임 중 후속 이 미지 프레임을 선택할 수 있다. 또한, 신뢰도 맵 생성기는, 글로벌 모션이 이미지 프레임에 영향을 받지 않는 것으로 식별되면, 이미지 프레임을 복수의 세그먼트로 분할(또는, 세그먼트화)할 수 있다. 이미지 프레임 수신기는 신뢰도 맵에 기초하여 복수의 이미지 프레임 중 적어도 하나의 이미지 프레임을 선택할 수 있다. 일 실시예로, 이미지 프레임 수신기는 복수의 이미지 프레임의 각각의 신뢰도 맵을 페어 신뢰도 임계값과 비교할 수 있다. 또한, 이미지 프레임 수신기는 신뢰도 맵이 페어 신뢰도 임계값을 충족 하는 복수의 이미지 프레임 중 적어도 하나의 이미지 프레임을 선택할 수 있다. 일 실시예로, 이미지 프레임 수신기는 제1 이미지 센서(140A)의 FOV에 표시된 장면의 이미지 프레임을 수 신할 수 있다. 또한, 신뢰도 맵 생성기는 이미지 프레임 각각을 복수의 영역으로 분할(또는, 세그먼트화) 할 수 있다. 또한, 신뢰도 맵 생성기는 이미지 프레임의 각각의 세그먼트화된 영역 각각에서 모션 데이터 를 산출(또는, 컴퓨팅)할 수 있다. 또한, 신뢰도 맵 생성기는 고정된 지속 시간(예를 들어, 5초)동안 모델링된 이미지 프레임의 세그먼트화된 영역에서 모션 데이터를 평균화할 수 있다. 또한, 신뢰도 맵 생성기는 적어도 하나의 인공 지능 모델을 이용하여 장면의 유형 및 모션 데이터의 평균에 기초하여 페어 신뢰도 임계값을 결정할 수 있다. 모션 검출기(motion detector)는 적어도 하나의 선택된 이미지 프레임에서 적어도 하나의 ROI의 모션을 검 출할 수 있다. 일 실시예로, AI 장면 분석기(AI scene analyzer)는 적어도 하나의 선택된 프레임을 AI 모 델에 입력함으로써 적어도 하나의 선택된 프레임에서 이용 가능한 적어도 하나의 객체를 식별하기 위해 AI 장면 분석을 수행할 수 있다. 또한, 통계 분석기는 통계 모델에 기초하여 적어도 하나의 식별된 객체의 속도를 결정하기 위해 이미지 프레임에 대한 통계 분석을 수행할 수 있다. 모션 검출기는 적어도 하나의 식별된 객체의 속도에 기초하여 적어도 하나의 선택된 이미지 프레임에서 적어도 하나의 ROI의 모션을 검출할 수 있다. 일 실시예로, AI 장면 분석기는 적어도 하나의 선택된 프레임에서 이용 가능한 적어도 하나의 객체를 식별 하기 위해 AI 모델을 학습시킬 수 있다. AI 장면 분석기는 전자 장치의 제2 이미지 센서(140B)로부터 복수의 이미지 프레임을 수신할 수 있다. AI 장면 분석기는 AI 모델에서 학습된 지식을 이용하여 제2 이미 지 센서(140B)로부터 수신된 각각의 프레임에서 적어도 하나의 객체를 인식할 수 있다. AI 장면 분석기는 인식 결과에 기초하여 적어도 하나의 객체를 이동 가능한 객체(movable object) 또는 정적 객체(static objec t)로 분류할 수 있다. AI 장면 분석기는 적어도 하나의 분류된 객체에 기초하여 신경망 노드 각각에 대한 가중치를 판단할 수 있다. AI 장면 분석기는 각각의 신경망 노드에 대한 가중치에 기초하여 AI 모델을 학 습시킬 수 있다. 일 실시예로, 통계 분석기(statistical analyzer)는 적어도 하나의 식별된 객체의 속도를 결정하기 위해 적어도 하나의 통계 모델을 학습시킬 수 있다. 통계 분석기는 적어도 하나의 객체와 연관된 복수의 파라미 터를 획득할 수 있다. 통계 분석기는 복수의 파라미터에 기초하여 적어도 하나의 객체의 속도를 결정할 수 있다. SSM 트리거링 엔진(SSM triggering engine)은 적어도 하나의 선택된 이미지 프레임 상의 적어도 하나의 ROI에서의 모션의 검출에 기초하여 SSM 비디오 캡처를 트리거링할 수 있다. 일 실시예로, SSM 트리거링 엔진 은 적어도 하나의 선택된 이미지 프레임에서 적어도 하나의 ROI의 모션이 검출되는지 여부를 식별할 수 있 다. SSM 트리거링 엔진은, 적어도 하나의 ROI의 모션이 적어도 하나의 선택된 이미지 프레임에서 검출된다 고 식별되면, SSM 비디오를 캡쳐할 수 있다. SSM 트리거링 엔진은, 적어도 하나의 ROI의 모션이 적어도 하나의 선택된 이미지 프레임에서 검출되지 않는 것으로 식별되면, 적어도 하나의 ROI의 모션을 검출하기 위해 이미지 프레임의 다음 세트를 수신할 수 있다. SSM 트리거링 엔진은 적어도 하나의 선택된 이미지 프레임에서 적어도 하나의 ROI의 검출된 모션이 모션 임계값을 충족하는지 여부를 식별할 수 있다. SSM 트리거링 엔진은, 적어도 하나의 ROI의 검출된 모션이 모션 임계값을 충족하지 않는 것으로 식별되면, 제1 이미지 센서(140A)를 사용하여 SSM 비디오를 캡처할 수 있 다. SSM 트리거링 엔진은, 적어도 하나의 ROI의 검출된 모션이 모션 임계값을 충족하는 것으로 식별되면, 제1 이미지 센서(140A)에서 제2 이미지 센서(140B)로 자동 스위칭할 수 있다. 또한, SSM 트리거링 엔진은 제2 이미지 센서(140B)를 이용하여 SSM 비디오를 캡처할 수 있다. 도 2는 SSM 비디오 컨트롤러의 하드웨어 구성 요소를 도시하고 있으나, 다른 실시예가 이에 한정되지 않을 수 있다. 다른 실시예에서, SSM 비디오 컨트롤러에는 더 적거나 더 많은 구성 요소가 포함될 수 있다. 또 한, 구성 요소의 라벨 또는 이름은 예시적인 목적으로만 사용되며 본 개시의 범위를 한정하지 않는다. 하나 이 상의 구성 요소가 함께 조합되어 장면의 SSM 비디오 캡처를 트리거링하기 위해 동일하거나 실질적으로 유사한 기능을 수행할 수 있다. 도 3은 본 개시의 일 실시예로, 전자 장치를 이용하여 장면의 SSM 비디오의 캡처를 트리거링하기 위한 방 법을 나타내는 흐름도이다. 본 개시의 방법은 제1 이미지 센서(140A)의 FOV에 표시된 장면의 복수의 이미 지 프레임을 수신하는 단계(S301)를 포함할 수 있다. 일 실시예로, 본 개시의 방법은 이미지 프레임 수신기 가 전자 장치의 제1 이미지 센서(140A)의 FOV에 표시된 장면의 복수의 이미지 프레임을 수신할 수 있 게 할 수 있다. 본 개시의 방법은 복수의 이미지 프레임 각각에 대한 신뢰도 맵을 결정하는 단계(S302)를 포함할 수 있다. 일 실시예로, 본 개시의 방법은 신뢰도 맵 생성기가 복수의 이미지 프레임 각각에 대한 신뢰도 맵을 결정할 수 있게 할 수 있다, 본 개시의 방법은 신뢰도 맵에 기초하여 복수의 이미지 프레임 중 적어도 하나의 이미지 프레임을 선택하는 단계(S303)를 포함할 수 있다. 일 실시예로, 본 개시의 방법은 이미지 프레임 수신기가신뢰도 맵에 기초하여 복수의 이미지 프레임 중 적어도 하나의 이미지 프레임을 선택할 수 있게 할 수 있다. 본 개시의 방법은 적어도 하나의 선택된 이미지 프레임에서 적어도 하나의 ROI의 모션을 검출하는 단계(S304)를 포함할 수 있다. 일 실시예로, 본 개시의 방법은 모션 검출기가 적어도 하나의 선택된 이미지 프레임에서 적어도 하나의 ROI의 모션을 검출할 수 있게 할 수 있다. 본 개시의 방법은 적어도 하나의 선택된 이미지 프레임 상의 적어도 하나의 ROI에서의 모션 검출에 기초하여 SSM 비디오의 캡처를 트리거링하는 단계(S305)를 포함할 수 있다. 일 실시예로, 본 개시의 방법은 SSM 트리거링 엔진이 적어도 하나의 선택된 이미지 프레임에서 적어도 하나의 ROI에서의 모션의 검출에 기초하여 SSM 비 디오의 캡처를 트리거링할 수 있게 할 수 있다. 도 3에 도시된 흐름도에서 다양한 액션, 동작, 블록, 단계 등은 제시된 순서로, 상이한 순서로 또는 동시 에 수행될 수 있다. 또한, 일부 실시예에서, 액션, 동작, 블록, 단계 등의 일부는 본 발명의 범위를 벗어나지 않고 생략, 추가, 수정, 건너 뛰기 등이 될 수 있다. 도 4A 및 도 4B는 본 개시의 일 실시예에 따른, 전자 장치를 사용하여 장면의 SSM 비디오 캡처를 자동으로 제어하기 위한 방법을 나타내는 흐름도이다. 본 개시의 일 실시예로, 전자 장치는 SSM 비디오 컨트롤 러, 메모리, ISP(130A), ISP(130B), 와이드(Wide) 이미지 센서(140A), 울트라 와이드(Ultra-Wide, UW) 이미지 센서(140B), 통신부, 카메라 하드웨어 추상화 계층(HAL: Hardware Abstraction Layer), 카메라 앱, 디스플레이, 프레임 레이트 컨버터(FRC: frame rate converter)(190A) 및 인코더(190B) 를 포함할 수 있다. ISP(130A)는 와이드 이미지 센서(140A) 및 카메라 HAL와 연결될 수 있다. ISP(130B)는 UW 이미지 센서 (140B) 및 카메라 HAL와 연결(또는, 커플링)될 수 있다. 또한, 카메라 HAL은 카메라 앱, 디스 플레이, FRC(190A) 및 SSM 비디오 컨트롤러와 연결될 수 있다. 인코더(190B)는 FRC(190A) 및 메모리 와 연결될 수 있다. 사용자가 전자 장치 상에 명령을 입력하여 카메라 앱을 오픈(또는, 실행)하고, 장면의 SSM 비디오를 캡처 하거나 카메라 앱을 이용하여 고속 모션(예를 들어, 축구공이 킥(kick)된 모션)이 포함된 이벤트의 순차적인 이 미지의 세트의 SSM 비디오를 캡처할 수 있다. 전자 장치는, 입력(또는, 명령)이 수신되면, 와이드 이미지 센서(140A) 및 UW 이미지 센서(140B)의 FOV에 대한 이미지 프레임 각각을 캡처하는 ISP(130A) 및 ISP(130B)를 포함할 수 있다. 단계 401에서, 와이드 이미지 센서(140A) 및 UW 이미지 센서(140B)는 이미지 프레임을 캡처하고, 이미지 프레임 의 로우 입력(raw input)(또는, 미 가공 입력)을 ISP(130A) 및 ISP(130B) 각각에 공급할 수 있다. 또한, ISP(130A) 및 ISP(130B)는, 이미지 품질을 향상시키기 위해, 와이드 이미지 센서(140A) 및 UW 이미지 센서 (140B)에서 자동 노출, 자동 초점, 자동 화이트 밸런스 기능을 포함하는 3A stats을 조정할 수 있다. ISP(130A) 및 ISP(130B)는 미 가공 입력을 이용하여 와이드 이미지 프레임(즉, 와이드 이미지 센서(140A)의 FOV로부터의 이미지 프레임) 및 UW 이미지 프레임(즉, UW 이미지 센서(140B)의 FOV로부터의 이미지 프레임)을 생성할 수 있 다. 단계 402에서, ISP(130A) 및 ISP(130B)는 와이드 이미지 프레임 및 UW 이미지 프레임을 카메라 HAL로 전 송할 수 있다. 카메라 HAL은 카메라 앱의 사용자 인터페이스(User Interface, UI)를 표시하고, 카메라 앱 의 UI 상에서 와이드 이미지 프레임의 프리뷰(preview) 영상을 표시할 수 있다. 또한, 사용자는 카메라 앱을 이 용하여 PCR 요청을 전송하고, ROI를 마킹하고, 상태 정보 등을 알 수 있다. 카메라 HAL은 메타 데이터를 판단하고 메타데이터를 와이드 이미지 프레임과 연관시킬 수 있다. 단계 403에서, 카메라 HAL은 와이드 및 UW 이미지 프레임 및 연관된 메타 데이터를 SSM 비디오 컨트롤러로 전송할 수 있다. 단계 404에서, SSM 비디오 컨트롤러는 장면에서 이동 가능한 객체 및 정적 객체를 식별하기 위해 UW 이미 지 프레임에 대한 AI 장면 분석을 수행할 수 있다. SSM 비디오 컨트롤러는, 햇빛, 밤, 불, 물, 하늘 등과 같은 상이한 장면에 대해 더 나은 SSM 사용 사례 맞춤화(customization)를 위해, 장면을 이해하기 위해 AI 모델 을 이용하여 UW 이미지 프레임에서 캡처된 장면을 분석할 수 있다. 또한, SSM 비디오 컨트롤러는 AI 모델을 이용하여 장면 상의 객체를 인식할 수 있다. SSM 비디오 컨트롤러 는 인식된 객체를 AI 모델을 이용하여 이동 가능한 객체와 정적 객체로 분류할 수 있다. AI 모델은 풍선,다트, 공 등과 같이 다양한 객체를 검출하도록 학습되었기 때문에, SSM 비디오 컨트롤러는 장면에 존재하 는 객체의 조합을 찾음으로써 장면 분석을 수행할 수 있다. 예를 들어, 풍선과 다트가 포함된 프레임의 스트림 (stream)은 다트가 풍선에 충돌하여 풍선이 터질 때 인식되므로, 트리거는 동일한 것에 대해 최적화될 수 있다. 장면 분석은 SSM 비디오 컨트롤러가 트리거링 객체가 와이드 FOV를 벗어나므로 UW 녹화로 시프팅(또는, 스 위칭)하는 것이 유용한지 식별할 수 있게 한다. SSM 비디오 컨트롤러는 장면에 존재하는 객체의 깊이를 추정할 수 있다. 깊이 정보는 SSM 비디오 컨트롤 러에 의해 추가로 사용되어 장면에 존재하는 중요한 객체를 판단함으로써 멀리 떨어져 있거나 중요하지 않 은 객체의 모션으로 인한 잘못된 검출을 회피할 수 있다. 단계 405에서, SSM 비디오 컨트롤러는 통계 모델을 이용하여 장면에서 이동 가능한 객체 및 정적 객체를 식별하기 위해 UW 이미지 프레임에 대한 통계 분석을 수행할 수 있다. SSM 비디오 컨트롤러는 UW 이미지 프레임에서 후보 객체의 중심 위치를 산출(또는, 컴퓨팅)할 수 있다. SSM 비디오 컨트롤러는 2개의 UW 이 미지 프레임에서 객체의 중심 사이의 거리가 임계 거리(예를 들어, 200 픽셀)보다 큰 지 여부를 식별할 수 있다. 또한, SSM 비디오 컨트롤러는, 2개의 UW 영상 프레임에서 객체의 중심 사이의 거리가 임계 거리보다 큰 경우, 객체를 이동 가능한 객체로 분류할 수 있다. SSM 비디오 컨트롤러는, 2개의 UW 이미지 프레임에 서 객체의 중심 사이의 거리가 임계 거리보다 크지 않은 경우, 객체를 정적 객체로 분류할 수 있다. 단계 406에서, SSM 비디오 컨트롤러는 AI 장면 분석 및 통계 분석으로부터 이동 가능한 객체로 분류된 객 체를 식별하여 후보 객체로 할당한다. 단계 407에서, SSM 비디오 컨트롤러는 후보 객체의 속도를 컴퓨팅 하고, 객체를 추적하고, 객체의 궤적을 예측하고, UW 이미지 프레임에서 후보 객체의 중심 위치에 기초하여 SSM 비디오를 캡처하는 트리거를 예측할 수 있다. 단계 408에서, SSM 비디오 컨트롤러는 와이드 이미지 프레임의 신뢰도 맵을 생성하기 위해 정적 변수를 이 용하여 와이드 이미지 프레임에 대한 입력 모델링을 수행할 수 있다. SSM 비디오 컨트롤러는 와이드 이미 지 프레임을 작은 서브 블록으로 분할하고, 고정된 지속 시간 동안 작은 서브 블록에 정적 변수를 적용하여 입 력 모델링을 수행할 수 있다. 단계 409에서, SSM 비디오 컨트롤러는 메타 데이터에 기초하여 글로벌 모션이 와이드 이미지 프레임에 영 향을 미치는지 여부를 식별할 수 있다. 단계 410에서, 글로벌 모션이 와이드 이미지 프레임에 영향을 미치는 것으로 검출(또는, 식별)되면, SSM 비디오 컨트롤러는 현재 와이드 이미지 프레임을 폐기하고 다음 와이드 이미지 프레임을 선택한다. 단계 411에서, 글로벌 모션이 와이드 이미지 프레임에 영향을 미치지 않는 것으로 검출(또는, 식별)되면, SSM 비디오 컨트롤러는 신뢰도 맵이 페어 신뢰도 임계값보다 큰 지 여부를 식별할 수 있다. 신뢰도 맵이 페어 신뢰도 임계값보다 크지 않는 것으로 식별되면, SSM 비디오 컨트롤러는 현재 와이드 이미지 프레임을 폐기하고 다음 와이드 이미지 프레임을 선택한다. 단계 412에서, 신뢰도 맵이 페어 신뢰도 임계값보다 큰 것으로 식별되면, SSM 비디오 컨트롤러는 UW 이미 지 프레임의 모션 맵을 생성할 수 있다. 이 때, 모션 맵은 화이트 픽셀 블록 및 블랙 배경이 포함될 수 있다. 모션 맵의 위치에 존재하는 화이트 픽셀 블록은 UW 이미지 프레임의 대응 위치에 존재하는 모션을 나타낼 수 있 다. SSM 비디오 컨트롤러는 UW 이미지 프레임에서 작은 움직임을 무시하고, 현저하게 이동하는 움직임만이 모션 맵 상에서 화이트 픽셀 블록으로 마킹될 수 있다. SSM 비디오 컨트롤러는 화이트 픽셀 블록의 클러스터(cluster)를 생성하기 위해 화이트 픽셀 블록에 대한 블록 클러스터링을 수행한다. 5의 경계를 사용하여, 블록 클러스터링을 수행하기 위해 SSM 비디오 컨트롤러 에 의해 5-평균(mean) 클러스터링 방법이 사용될 수 있다. 서로 매우 가까운 (단순 거리 파라미터, 즉, 에 의해 결정되는) 클러스터는, 단지 멀리 떨어져 있고 연결되지 않은 클러스 터로 남아 있을 때까지, 단일 클러스터로서 병합될 수 있다. 단순 클러스터링에 따라 충돌(clash)이 발생되는 경우(예를 들어, 클러스터 중심이 가까우나 잘 연결되지 않은 경우), AI 장면 분석기는 객체 및 그 특성에 대한 명확성을 위해 호출될 수 있다. 경계 블록과 함께 클러 스터 크기에 대한 제약이 또한 클러스터 병합에 사용될 수 있다. C1 및 C2는 다음 조건(수학식 1)이 충족되면 병 합될 수 있는 클러스터이다.수학식 1"}
{"patent_id": "10-2020-0152072", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "여기서, h 및 w는 각각 UW 이미지 프레임 I의 높이 및 폭이다. α는 최소 클러스터 크기를 제어하기 위해 경험 적으로 결정된 상수이다. Kc는 K-평균(Mean)에서 취해진 클러스터의 총 개수를 의미한다. β는 경험적으로 결정 된 상수이다. dn은 양쪽 클러스터를 경계로 하는 블록의 개수이다. D는 C2를 경계로 하는 블록의 총 개수이다. 임의의 클러스터 쌍에 대해 이러한 조건이 유효하지 않을 때까지 클러스터는 재귀적(recursively)으로 병합될 수 있다. 또한, SSM 비디오 컨트롤러는 희소하고 밀집한 객체 및 모션을 이해하기 위하여 밀도 함수를 이 용할 수 있다. SSM 비디오 컨트롤러는 클러스터의 중심을 판단한다. 단계 413에서, SSM 비디오 컨트롤러는, 이미지 프레임 클러스터의 중심 위치 변화가 검출되면, 이미지 프 레임의 ROI 상에서 모션을 검출할 수 있다. SSM 비디오 컨트롤러는, 이미지 프레임의 클러스터 중심의 위 치 변화가 검출되지 않으면, 이미지 프레임의 ROI 상에서 모션을 검출하지 않을 수 있다. 또한, SSM 비디오 컨 트롤러는 이미지 프레임을 폐기하고 다음 이미지 프레임을 선택할 수 있다. 단계 414에서, SSM 비디오 컨트롤러는 전자 장치의 자동 센서 스위치를 사용할 수 있는지 확인할 수 있다. 단계 415에서, SSM 비디오 컨트롤러는, 자동 센서 스위치를 사용할 수 없는 경우, 와이드 이미지 프 레임을 녹화하기로 결정할 수 있다. 단계 416에서, SSM 비디오 컨트롤러는, 자동 센서 스위치를 사용할 수 있는 경우, 이미지 프레임에서의 객체의 위치에 기초하여 녹화를 위한 와이드 이미지 프레임 또는 UW 이미지 프 레임 중 어느 하나를 선택할 수 있다. 후보 객체가 와이드 FOV를 벗어나 이동하는 것으로 식별되면, SSM 비디오 컨트롤러는 더 나은 객체 모션의 FOV를 제공하기 위해 UW 센서(140B)를 사용하여 SSM 비디오를 녹화하기로 결정할 수 있다. 단계 417에서, SSM 비디오 컨트롤러는 결정에 따라 와이드 이미지 프레임 또는 UW 이미지 프레임 중 어느 하나를 녹화하도록 카메라 HAL을 지시(instruct)할 수 있다. 단계 418에서, 카메라 HAL은 와이드/UW 이미지 프레임 녹화를 개시하도록 FRC(190A)에 지시할 수 있다. FRC(190A)는 이미지 프레임의 와이드/UW 프레임 레이트를 업스케일링한 후 와이드/UW 이미지 프레임을 인코더(190B)로 전송할 수 있다. 인코더(190B)는 SSM 비 디오를 형성하기 위해 와이드/UW 이미지 프레임을 인코딩하고 SSM 비디오를 저장하기 위해 메모리로 전송 할 수 있다. 흐름도에서 다양한 액션, 동작, 블록, 단계 등은 제시된 순서로, 상이한 순서로 또는 동시에 수행될 수 있 다. 또한, 일부 실시예에서, 액션, 동작, 블록, 단계 등의 일부는 본 발명의 범위를 벗어나지 않고 생략, 추가, 수정, 건너 뛰기 등이 될 수 있다. 도 5는 본 개시의 일 실시예에 따른, 전자 장치가 사무실 캐빈(office cabin)의 장면에서 객체를 식별하는 과정을 설명하기 위한 도면이다. 도 5에 도시된 바와 같이, 랩 탑, 고글, 컵, 스마트폰 및 책이 사무실 캐빈에 배치된 경우를 가정한다. 501에 도시된 바와 같이, 전자 장치의 카메라 앱 이 사무실 캐빈과 사무실 캐빈에 배치된 객체에 대한 미리 보기의 이미지 프레임을 표시할 수 있다. 전자 장치 는, 장면에 존재하는 객체를 식별하기 위하여, 이미지 센서에 의해 캡처된 미리 보기 이미지 프레임 에서 장면을 분석하기 위해 학습된 AI 모델을 사용할 수 있다. 도 5의 508에 도시된 바와 같이, 전자 장치는, 학습된 AI 모델을 이용하여, 바운딩 박스(bounding box)(509, 510, 511, 512, 513)를 식별하여 랩탑, 고글, 컵, 스마트폰 및 책 주위에 표시할 수 있다. 또한, 전자 장치는 학습된 AI 모델을 이용하여 객체의 위치 및 객체의 이름을 식별한다. 바운딩 박스의 형상은 정사각형, 원형 등으로 다양하게 구현될 수 있다. 바운딩 박스의 크기는 객체의 크기에 기초하여 변경될 수 있다. 또한, 전자 장치는 학습된 AI 모델을 이용하여 장면에 존재하는 객체를 이동 가능한 객체 또는 정적 객체로 분류할 수 있다. 도 6은 본 개시의 일 실시예로, 축구 경기장의 장면을 나타내는 예시적인 시나리오이며, 전자 장치는 통계 모델을 이용하여 장면의 객체를 이동 가능한 객체 또는 정적 객체로 분류할 수 있다. 예시 시나리오에서, 전자 장치는 골대를 향해 움직이는 공을 포함하는 축구 경기장의 장면에 대한 미리 보기 장면의 이미 지 프레임을 표시할 수 있으며, 여기서 나무는 장면의 배경에 존재할 수 있다. 607 및 608은, 공이 움직이는 동안, 전자 장치가 표시하는 미리 보기 장면의 제1 이미지 프레임 및 제2 이미지 프레임을 나타 낸다. 전자 장치는 장면에 존재하는 객체 \"공, 골대 및 나무\"를 검출하기 위해 통계 모델 을 사용할 수 있다. 또한, 전자 장치는 검출된 객체 주위에 다양한 두께를 가지는 바운딩 박스(604, 605, 606)를 표시할 수 있다. 이 때, 바운딩 박스의 두께는 전자 장치를 기준으로 객체의 근접성(closeness)을 나타낼 수 있다. 나무는 전자 장치로부터 가장 멀리 떨어져 있으므로, 나무 주위의 바운딩 박스 의 두께는 가장 얇은 두께를 가질 수 있다. 공이 나무보다 전자 장치에 더 가까우므로, 공 주위의 바운딩 박스의 두께는 나무 주위의 바운딩 박스의 두께보다 두껍다. 골대가 전자 장치에 가장 가까우므로, 골대 주위의 바운딩 박스의 두께는 공 주위의 바운딩 박스의 두 께보다 두껍다. 일 실시예로, 전자 장치에 대한 객체의 근접성을 나타내기 위해 바운딩 박스에 다른 컬러가 부여될 수 있 다. 전자 장치는 이미지 프레임에서 객체의 바운딩 박스의 중심을 판단할 수 있다. 그리고, 전자 장치 는, 2개의 이미지 프레임 각각 상에서 객체 주위의 바운딩 박스의 중심간의 거리 차이가 임계값보다 큰 경 우, 상기 객체를 이동 가능한 객체로 분류할 수 있다. 전자 장치는, 2개의 이미지 프레임 각각 상에서 객 체 주위의 바운딩 박스의 중심간의 거리 차이가 임계값 이하인 경우, 상기 객체를 이동 가능한 객체로 분류할 수 있다 다른 객체는 정적 객체로 분류할 수 있다. 여기서, 임계값은 예로, 200 픽셀로 설정될 수 있다. 예로, 제1 이미지 프레임에서 바운딩 박스의 중심 위치는 위치 A에 있는 반면, 제2 이미지 프레임 에서 경계 박스의 중심 위치는 위치 B에 있을 수 있다. 2개의 이미지 프레임에서 공의 중심 간 의 차이를 고려할 때, 위치 A와 B 사이의 거리는 250 픽셀일 수 있다. 2개의 프레임에서 공의 중심 간 차 이가 200 픽셀보다 크므로, 전자 장치는 공을 동적 객체로 분류할 수 있다. 2개의 프레임에서 골대 의 중심 간 차이는 200 픽셀 미만인 제로 픽셀이므로, 전자 장치는 골대를 정적 객체로 분류할 수 있다. 2개의 프레임에서 나무의 중심 간 차이는 200 픽셀 미만인 제로 픽셀이므로, 전자 장치는 나무를 정적 객체로 분류할 수 있다. 도 7A 및 도 7B는 본 개시의 일 실시예에 따른, 거리의 장면을 나타내는 예시적인 시나리오이며, 전자 장치 는 장면에 대응하는 이미지 프레임의 모션 맵을 생성할 수 있다. 도 7a은 전자 장치가 미리 보기 장 면의 이미지 프레임을 표시하는 과정을 도시하고 있다. 이 때, 미리 보기 장면에는 이동 가능한 객체인 '자전거 , 제1 숙녀 및 제2 숙녀'가 포함될 수 있다. 자전거는 매우 느리게 이동하고 있고, 제1 숙녀 및 제2 숙녀 는 자전거보다 빨리 걷고 있을 수 있다. 도 7B는, 전자 장치에 의해, 장면의 이미지 프레임에 대해 생성된 모션 맵을 나타내는 도면이다. 객체의 모션 데이터는 모션 맵에서 화이트 픽셀로 마킹될 수 있다. 자전거에 대해 마킹된 화이트 픽셀을 이용하여 형성된 클러스터는 도 7B의 클러스터로서 제공될 수 있다. 제1 숙녀에 대해 마킹된 화이트 픽셀을 이 용하여 형성된 클러스터는 도 7B의 클러스터로 제공될 수 있다. 제2 숙녀에 대해 마킹된 화이트 픽셀 을 이용하여 형성된 클러스터는 도 7B의 클러스터 및 클러스터로 제공될 수 있다. 전자 장치는 클러스터(704, 705, 706, 707) 주위에 타원형 바운딩 박스(708, 709, 710, 711)를 각각 생성 하고, 바운딩 박스의 중심을 판단할 수 있다. 또한, 전자 장치는 바운딩 박스에서 화이트 픽셀의 더 낮은 밀도로 인해 클러스터를 폐기할 수 있다. 또한, 전자 장치는 더 큰 클러스터 크기 및 바운딩 박 스 내의 화이트 픽셀의 밀도의 수용으로 인해 제1 숙녀를 이동 가능한 객체로 분류할 수 있다. 또한, 전자 장치는, 바운딩 박스(710 및 711)의 중심의 근접성 및 바운딩 박스(710 및 711)의 크기로 인해, 단일 클러스터를 형성하기 위해 클러스터와 클러스터를 병합할 수 있다. 그리고, 전자 장치 는 큰 클러스터 크기 및 병합된 단일 클러스터 내의 화이트 픽셀의 밀도의 수용으로 인해 제2 숙녀를 이동 가능한 객체로 분류할 수 있다.도 8은 본 개시의 일 실시예에 따른, 축구 경기장의 장면을 나타내는 예시적인 시나리오이며, 전자 장치는 장면에서 이동 가능한 객체의 속도를 산출(또는, 컴퓨팅)할 수 있다. 예시적인 시나리오에서, 전자 장치가 축구 경기장의 미리 보기 장면을 표시할 수 있다. 이 때, 미리 보기 장면에는 골대를 향해 이동하고 있는 공이 포함되며, 나무는 배경에 존재할 수 있다. 801은 공의 위치가 위치 A에 있을 때, 전자 장 치가 표시하는 미리 보기 장면의 제1 이미지 프레임을 나타낸다. 802는 공의 위치가 위치 B에 있을 때, 전자 장치가 표시하는 미리 보기 장면의 제2 이미지 프레임을 나타낸다. 위치 A로부터 위치 B로의 위 치 변화에 기초하여 공이 장면에서 이동하는 객체라고 식별되면, 전자 장치는 중심의 (X, Y) 좌표를 하기 수학식 2와 같이 계산함으로써 객체의 중심 위치를 판단할 수 있다. 수학식 2"}
{"patent_id": "10-2020-0152072", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "여기서, N은 모션 블록에서의 픽셀의 총 개수이다. 중심은 본질적으로 프레임에 플롯된(plotted)된 객체의 중심이며, 궤적이 예측될 수 있다. Xi 및 Yi는 해당 객체 를 구성하는 모션 블록의 중심 픽셀의 좌표이다. 64 x 72 그리드 섹션이 803으로 나타낸 이미지 프레임에 대응 하는 것으로 가정한다. 화이트 픽셀 블록으로 이루어진 화이트 원은 공에 대응하는 모션 블록을 나타 낼 수 있다. 화이트 원의 위치는 803에 플롯된 제1 및 제2 이미지 프레임(801, 802) 상에서 공의 위 치에 대응될 수 있다. 공의 중심은 화이트 원의 중심에서의 도트(dot)로 나타내질 수 있다. 전자 장치는 예를 들어, 적어도 6개의 연속 프레임으로부터 중심의 위치 좌표를 이용하여 이동하는 객체, 즉, 공의 경로의 궤적 및 형상을 식별할 수 있다. 전자 장치는 포물선, 원형 또는 선형 식 중 어느 하나에 맞는 곡선을 풀기 위해 중심의 위치 좌표를 사용할 수 있다. 전자 장치는 X 및 Y 방향으로 프레임 사이의 중심에 의해 커버되는 거리를 평균화하여 객체의 속도를 컴퓨팅할 수 있다. 또한, 전자 장치는 프 레임 당 픽셀 속도를 이용하여 와이드 FOV에서 객체가 ROI에 충돌될 프레임을 추정할 수 있다. 또한, 전자 장치 는 수직 방향으로 중심이 횡단한 거리 ΔY 및 수평 방향으로 중심이 횡단한 거리 ΔX를 산출할 수 있다. 전자 장치는 평균 속도 Vx 및 Vy를 계산하기 위해 4개 이상의 프레임에 걸쳐 ΔX 및 ΔY를 평균화할 수 있 다. 또한, 전자 장치는 수학식 3을 사용하여 객체와 ROI 사이의 거리 및 속도를 사용하여 객체가 ROI에 진 입하는 X 방향에 대한 프레임 번호(Fn)를 예측할 수 있다. 수학식 3"}
{"patent_id": "10-2020-0152072", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "여기서, XROI는 ROI의 X 좌표이고, XC는 중심의 X 좌표를 의미한다. 마찬가지로, 수학식 4를 이용하여 Y 방향에 대한 프레임 번호(Fn)를 찾고, 이들 중 최소값이 선택될 수 있다. 수학식 4 여기서, YROI는 ROI의 Y 좌표이고, YC는 중심의 Y 좌표를 의미할 수 있다. 도 9A 내지 도 9I는 본원에 개시된 실시예에 따른, 축구 경기장의 장면을 나타내는 예시적인 시나리오이며, 전 자 장치는 SSM 비디오 녹화에 대한 트리거를 예측하기 위해 장면의 각각의 이미지 프레임을 분석할 수 있 다. 전자 장치가 축구 경기장에 대한 미리 보기 장면을 표시할 수 있다. 전자 장치의 UW 이미지 센서 (140B)의 FOV는 도 9A에 나타낸 바와 같이, 골대, 경기장, 나무, 아파트 및 조명대 를 포함할 수 있다. 전자 장치의 와이드 이미지 센서(140A)의 FOV는 골대, 경기장, 나무, 아파트 및 조명대를 포함할 수 있다. 예시적인 시나리오에서 ROI는 와이드 이미지 센서 (140A)의 FOV일 수 있다. 공이 UW 이미지 센서(140B)의 FOV로 진입하고, 전자 장치가 UW 이미지 센서(140B)로부터 연속 적인 이미지 프레임(906, 908, 910, 912, 914, 916, 918, 920)의 미리 보기 장면를 표시할 수 있다. 907, 909, 911, 913, 915, 917, 919, 921은 각각 연속 이미지 프레임(906, 908, 910, 912, 914, 916, 918, 920)의 이미지 프레임에 대해 전자 장치에 의해 생성된 모션 맵이다. 도 9b에 도시된 바와 같이, UW 이미지 센서(140B)의 제1 이미지 프레임으로부터 시작하여, 전자 장치(10 0)는 각각의 모션 맵을 생성하기 위해 이미지 프레임을 작은 블록으로 분할하고, 이동하는 객체, 즉, 공을 모션 맵에 화이트 픽셀 블록으로 표현할 수 있다. 화이트 픽셀 블록은 각각의 이미지 프레임에서 공에 대 응하는 모션 블록을 나타낸다. 도 9c에 도시된 바와 같이, UW 이미지 센서(140B)의 제2 이미지 프레임에서, 전자 장치는 화이트 픽 셀 블록의 클러스터를 생성하고 클러스터를 단일 객체로 분류할 수 있다. 객체의 중심이 시간의 경과 에 따라 이동하고 있으므로, 전자 장치는 공을 SSM 비디오 캡처를 트리거링하는 후보 객체로 고려할 수 있다. 도 9d에 도시된 바와 같이 UW 이미지 센서(140B)의 제3 이미지 프레임에서, 전자 장치는 표현(또는, 모션 맵)상에 클러스터의 중심에 기초하여 객체의 중심의 위치를 기록할 수 있다. 도 9e에 도시된 바와 같이, UW 이미지 센서(140B)의 제4 이미지 프레임에서, 전자 장치는 표현(또는, 모션 맵)상에서 클러스터의 중심의 모션에 기초하여 객체가 이동하고 있음을 검출할 수 있다. 또한, 전자 장치는, 객체가 평균적으로 프레임 사이에서 이동하는 이미지의 부분에 대해 알기 위해, 프레임 당 픽셀 속도를 계산하기 위해 수 프레임(~4 프레임)에 걸쳐 중심 위치 간의 차이를 평균화할 수 있다. 도 9f에 도시된 바와 같이, UW 이미지 센서(140B)의 제5 이미지 프레임에서, 전자 장치는 클러스터 의 중심 위치에 기초하여 제2, 제3, 제4, 제5 프레임으로부터 객체의 위치에 대한 정보를 획득하고, 위치 정보에 기초하여 객체의 속도를 계산할 수 있다. 전자 장치는 제8 프레임에서 객체가 와이드 이미지 센서 (140A)의 FOV로 진입할 것을 나타낼 수 있다. 도 9g에 도시된 바와 같이, UW 이미지 센서(140B)의 제6 이미지 프레임에서, 전자 장치는 현재 프레 임과 함께 마지막 3개 프레임(914, 912, 910)을 사용하여 객체의 속도를 추정하고, 속도에 기초하여 ROI (즉, 와이드 이미지 센서(140A)의 FOV)의 추후 진입을 예측할 수 있다. 또한, 전자 장치는 제8 프레 임에서 객체가 와이드 이미지 센서(140A)에 진입할 것임을 나타낼 수 있다. 도 9h에 나타낸 바와 같이 UW 이미지 센서(140B)의 제7 이미지 프레임에서, 전자 장치는 마지막 3개 프레임(916, 914, 912)으로부터의 객체의 위치에 대한 지식에 기초하여 공이 다음 프레임에서 ROI에 진입할 것이라고 결정할 수 있다. 도 9i에 나타낸 바와 같이 UW 이미지 센서(140B)의 제8 이미지 프레임에 서, 객체는 ROI에 진입하고, 전자 장치는 와이드 이미지 센서(140A)의 FOV로부터 이미지 프레임을 캡 처하기 위해 와이드 이미지 센서(140A)를 트리거링할 수 있다. 도 10은 본 개시의 일 실시예에 따른, 이동 가능한 객체의 컴퓨팅된 궤적을 나타내는 예시적인 시나리오이다. 도 9a 내지 도 9i에 도시된 예시적인 시나리오와 관련하여, 전자 장치는 이미지 프레임(즉, 제2 이미 지 프레임), 912(즉, 제4 이미지 프레임), 916(즉, 제6 이미지 프레임), 920(즉, 제8 이미지 프레임)에서 모션 블록의 위치를 각각 위치 B, D, F, H 각각에 중첩(superimpose)시킬 수 있다. 또한, 전자 장치는 위치 B,D, F, H에 기초하여 객체 중심의 위치 결정 및 속도 추정을 사용하여 예측된 궤적을 나타내는 점선을 생 성할 수 있다. 또한, 전자 장치는 객체의 궤적 및 속도에 기초하여 객체가 UW 이미지 센서(140B)의 FOV를 가로지르거나 ROI(즉, FOV)에 진입하는 프레임을 예측한다. 또한, 전자 장치는, 예측 프 레임을 캡처하기 위한 순간이 도달되면, 더 나은 품질 및 사용자의 시청 경험(viewing experience)을 위해, SSM 비디오를 녹화하기 위하여 UW 이미지 센서(140B)를 와이드 이미지 센서(140B)로 스위칭할 수 있다. 도 11A 내지 도 11E는 본 개시의 일 실시예에 따른, 스케이트장의 장면을 나타내는 예시적인 시나리오이 며, 전자 장치는 스케이트장에서 스케이트를 타는 소년의 스티칭된(stitched) 이미지를 생성 할 수 있다. 즉, 전자 장치가 소년이 스케이트장에서 스케이트를 타는 장면을 표시하고 있는 상황을 가정한다. 사용자는 전자 장치를 이용하여 장면의 스티칭된 이미지를 생성하기를 원할 수 있다. 사 용자는 도 11A에 도시된 바와 같이 전자 장치에 의해 표시되는 장면의 미리 보기 이미지 프레임 상에서 ROI를 마킹할 수 있다. 전자 장치는 소년이 스케이팅을 시작할 때 장면을 분석하고 모션을 검 출할 수 있다. 소년이 ROI 위치에 도달한 경우를 가정한다. 그리고, 전자 장치는 ROI에 서 모션을 검출하고, 장면의 이미지 캡처를 트리거링할 수 있다. 또한, 전자 장치는 특정 연속 이미지 프 레임에서 소년의 위치 변화에 기초하여 소년의 속도를 판단할 수 있다. 또한, 전자 장치는 소년 의 속도, 소년의 모션의 궤적 및 FOV의 영역에 기초하여 스티칭된 이미지를 생성하기 위해 캡처할 연속 이미지 프레임의 수 및 각각의 연속 프레임을 캡처하는 기간을 판단할 수 있다. 또한, 전자 장치는 동일한 기간 후에 장면의 14개 이상의 샷을 캡처하도록 트리거링할 수 있다. 전자 장치에 의해 캡처된 제5 이미지가 도 11B에 도시되어 있다. 전자 장치에 의해 캡처된 제14 이미지는 도 11C에 도시되어 있다. 전자 장치에 의해 캡처된 제15 이미지는 도 11D에 도시될 수 있다. 그리고, 전자 장치는 캡처된 15개의 이 미지를 모두 오버레잉(overlaying)함으로써 도 11E에 나타낸 바와 같이 장면의 스티칭된 이미지를 생성할 수 있 다. 도 12A 내지 도 12D는 본 개시의 일 실시예에 따른, 스케이팅 벤치의 장면을 나타내는 예시적인 시나리오 이며, 전자 장치는 장면의 이미지 프레임의 ROI에서의 모션을 검출하는 것에 응답하여 SSM 비디오의 녹화를 수행 시작할 수 있다. 소년이 스케이팅 벤치 상에서 스케이트를 타고 있는 경우를 가정한다. 사용자는 전자 장치를 사용하여 장면의 SSM 비디오를 녹화하기를 원할 수 있다. 사용자는 도 12A에 나타낸 바와 같이 전자 장치에 의해 표시되는 장면의 미리 보기 이미지 프레임 상에 ROI를 마 킹할 수 있다. 전자 장치는 도 12B에 나타낸 바와 같이 소년이 스케이팅을 시작할 때 장면을 분석하 고 모션을 검출할 수 있다. 소년이 ROI에 도달하는 경우를 가정한다. 또한, 전자 장치는 ROI 에서 모션을 검출하고 장면의 SSM 비디오 캡처를 트리거링할 수 있다. 또한, 전자 장치는, 도 12D에 도시 된 바와 같이 모션이 ROI에 존재할 때까지, 도 12C에 도시된 바와 같이 SSM 비디오를 계속 녹화할 수 있 다. 도 13A 및 도 13B는, 본 개시의 일 실시예에 따른, 두 소년(1304, 1305)의 장면을 나타내는 예시적인 시나리오 이며, 전자 장치는, 장면의 이미지 프레임의 적어도 하나의 ROI(1301, 1302)에서 모션이 검출되면, 소년 (1304, 1305)에 대한 SSM 비디오를 캡처할 수 있다. 사용자가 전자 장치를 사용하여 위로 점프하는 두 소 년(1304, 1305)의 장면의 SSM 비디오를 녹화하기를 원할 수 있다. 사용자는, 도 13A에 도시된 바와 같이, 상이 한 위치에서 전자 장치에 의해 표시되는 장면의 미리 보기 이미지 프레임 상에 2개의 ROI(1301, 1302)를 마킹할 수 있다. 두 소년(1304, 1305)이 위로 점프하고 한 소년의 손이 ROI에 도달하는 경우를 가 정한다. 전자 장치는 장면을 분석하고 도 13B에 도시된 바와 같이 소년의 손이 ROI에 도달할 때 ROI에서의 모션을 검출할 수 있다. 또한, 전자 장치는 장면의 SSM 비디오의 캡처를 트리거링할 수 있다. 또한, 전자 장치는 모션이 적어도 하나의 ROI(1301, 1302)에 존재할 때까지 SSM 비디오를 계속 녹화할 수 있다. 본 개시의 또 다른 실시예로, 도 14에 도시된 바와 같이, 전자 장치는 메모리, 제1 카메라, 제2 카메라, 프로세서, 디스플레이, 입력부 및 스피커를 포함할 수 있다.다만, 도 15에 도시된 구성은 본 개시의 실시 예들을 구현하기 위한 예시도이며, 통상의 기술자에게 자명한 수 준의 적절한 하드웨어 및 소프트웨어 구성들이 전자 장치에 추가로 포함될 수 있다. 메모리는 도 1에 도시된 메모리와 마찬가지로 전자 장치의 적어도 하나의 다른 구성 요소와 관 련된 명령 또는 데이터를 저장할 수 있다. 메모리는 프로세서에 의해 액세스되며, 프로세서에 의한 데이터의 독취/기록/수정/삭제/갱신 등이 수행될 수 있다. 본 개시에서 메모리라는 용어는 메모리, 프로세서 내 롬(미도시), 램(미도시) 또는 전자 장치(10 0)에 장착되는 메모리 카드(미도시)(예를 들어, micro SD 카드, 메모리 스틱)를 포함할 수 있다. 또한, 메모리 에는 디스플레이의 디스플레이 영역에 표시될 각종 화면을 구성하기 위한 프로그램 및 데이터 등이 저장 될 수 있다. 메모리의 구체적인 설명은 도 1의 메모리를 참조하여 구체적으로 설명하였으므로 중복 되는 설명은 생략하도록 한다. 제1 카메라는 제1 이미지 센서(140A)를 포함하며, 전자 장치의 주변을 촬영하여 하나 이상의 이미지 프레임을 획득하는 구성이다. 제1 카메라는 전자 장치의 주변을 촬영하여 복수의 이미지 프레임을 획득하는 영상을 획득할 수 있으며, 여기서 영상은 라이브 뷰(live-view)를 포함할 수 있다. 제2 카메라는 제2 이미지 센서(140B)를 포함하며, 전자 장치의 주변을 촬영하여 하나 이상의 이미지 프레임을 획득하는 구성이다. 제2 카메라는 전자 장치의 주변을 촬영하여 복수의 이미지 프레임을 획득하는 영상을 획득할 수 있으며, 여기서 영상은 라이브 뷰(live-view)를 포함할 수 있다. 프로세서는 도 1에 도시된 SSM 컨트롤러 및 프로세서가 하나의 구성 요소로 병합된 구성 요소 이다. 즉, SSM 컨트롤러와 프로세서는 도 14에 도시된 바와 같이, 하나의 프로세서로 병합된 형태로 구현될 수 있으나, 이에 국한되는 것은 아니며 도 1에 도시된 것과 같이 별개의 구성 요소로 구현될 수 있다. 프로세서는 메모리와 전기적으로 연결되어 전자 장치의 전반적인 기능 및 동작을 제어할 수 있다. 프로세서는 제1 카메라를 통해 전자 장치의 주변을 촬영하여 복수의 이미지 프레임을 획득할 수 있다. 이 때, 제1 카메라를 통해 촬영할 수 있는 영역은 제1 카메라에 포함된 제1 이미 지 센서(140A)의 시야 내에 포함된 영역을 의미할 수 있다. 프로세서는 획득된 복수의 이미지 프레임을 메모리 중 버퍼(buffer)에 저장할 수 있다. 다만, 버퍼는 메모리와는 별개의 구성 요소로 구현될 수 있다. 프로세서는 복수의 이미지 프레임 각각에 관심 영역을 설정할 수 있다. 예를 들어, 프로세서는 제1 카메라를 통해 획득된 복수의 이미지 프레임으로 구성된 영상을 표시하도록 디스플레이를 제어할 수 있다. 터치 스크린을 포함하는 디스플레이 중 일부 영역에 관심 영역으로 설정하기 위한 사용자 터치 가 입력되면, 프로세서는 터치가 입력된 영역을 관심 영역으로 설정할 수 있다. 또 다른 예로, 프로세서 는 자동 초점 방식을 이용하여 복수의 이미지 프레임 상에 관심 영역을 설정할 수 있다. 프로세서는 복수의 이미지 프레임 각각에 대응되는 모션 식별 맵(또는, 신뢰도 맵)을 획득할 수 있다. 여 기서, 모션 식별 맵은 복수의 이미지 프레임 각각에서 검출된 모션 데이터에 기초하여 생성될 수 있다. 구체적으로, 프로세서는 복수의 이미지 프레임 각각을 복수의 세그먼트(segment)로 분할하고, 복수의 이 미지 프레임 각각의 복수의 세그먼트 각각에서 모션 데이터를 검출할 수 있다. 프로세서는 복수의 이미지 프레임 각각의 복수의 세그먼트 각각에서 검출된 모션 데이터의 평균을 산출하여 복수의 이미지 프레임 각각에 대한 모션 식별 맵을 획득할 수 있다. 한편, 프로세서는 복수의 이미지 프레임과 관련된 메타 데이터에 기초하여 복수의 이미지 프레임을 제1 카메라를 통해 획득하는 동안 전자 장치가 기설정된 범위를 초과하여 움직이는지 여부를 식별할 수 있다. 예를 들면, 프로세서는 악수와 같은 글로벌 모션에 의해 전자 장치가 기설정된 범위를 초과하 여 움직였는지 여부를 식별할 수 있다. 즉, 프로세서는 글로벌 모션이 복수의 이미지 프레임에 영향을 미 쳤는지 여부를 식별할 수 있다. 전자 장치가 기설정된 범위를 초과하여 움직인다고 식별되면, 프로세서는 버퍼에 저장된 복수의 이 미지 프레임을 삭제할 수 있다. 그리고, 프로세서는 삭제된 복수의 이미지 프레임 이후에 획득된 이미지 프레임을 획득하는 동안 전자 장치가 기설정된 범위를 초과하여 움직이는지 여부를 식별할 수 있다. 한편, 전자 장치가 기설정된 범위를 초과하여 움직이지 않는다고 식별되면, 프로세서는 복수의 이미지 프레임 각각을 복수의 세그먼트로 분할하여 모션 식별 맵을 획득할 수 있다. 프로세서는 복수의 이미지 프레임 각각에 대응되는 모션 식별 맵과 모션 임계값(또는, 페어 신뢰도 임계 값)을 비교할 수 있다. 프로세서는 복수의 이미지 프레임 중 모션 임계값을 충족하는 모션 식별 맵에 대 응되는 이미지 프레임을 식별하고, 식별된 이미지 프레임 중 적어도 하나의 이미지 프레임을 선택할 수 있다. 한편, 모션 임계값(또는, 페어 신뢰도 임계값)을 결정하는 과정은 전술하였으므로 중복되는 설명은 생략하도록 한다. 프로세서는 모션 식별 맵에 기초하여 선택된 적어도 하나의 프레임을 객체를 인식하도록 학습된 인공 지 능 모델에 입력하여 선택된 적어도 하나의 프레임 상에 포함된 객체에 대한 정보를 획득할 수 있다. 여기서, 객 체에 대한 정보는 객체의 유형, 객체의 크기 또는 형태 등 중 적어도 하나를 포함할 수 있다. 프로세서는 획득된 객체에 대한 정보에 기초하여 객체를 움직이는(또는, 움직일 수 있는(movable)) 객체 또는 정적(static) 객체 중 하나로 분류할 수 있다. 프로세서가 객체를 움직이는 객체 또는 정적 객체로 분류하는 과정은 전술하였으므로 중복되는 설명은 생략하도록 한다. 프로세서는, 객체가 움직이는 객체라고 식별되면, 식별된 움직이는 객체를 후보 객체로 할당할 수 있다. 프로세서는 선택된 적어도 하나의 프레임의 관심 영역 상에서 후보 객체의 움직임이 존재하는지 여부를 식별할 수 있다. 프로세서는 관심 영역 상에 후보 객체의 움직임이 존재하는 여부에 따라 제1 카메라 를 통해 SSM 기능을 수행할 수 있다. SSM 기능을 수행한다는 것은 SSM 비디오를 녹화하기 위한 기능이 트 리거되어 고속 촬영을 시작한다는 것을 의미할 수 있다. 구체적으로, 프로세서는 후보 객체를 통계 모델에 입력하여 후보 객체의 속도 또는 움직임 궤적 중 적어 도 하나에 대한 정보를 획득할 수 있다. 프로세서는 획득된 후보 객체의 속도 또는 움직임 궤적 중 적어 도 하나에 대한 정보를 이용하여 관심 영역 상에 후보 객체의 움직임이 존재하는지 여부를 식별(또는, 모니터링)할 수 있다. 프로세서가 후보 객체의 속도 또는 움직임 궤적 중 적어도 하나에 대한 정보를 획 득하는 과정은 전술하였으므로 중복되는 설명은 생략하도록 한다. 적어도 하나의 관심 영역 내에 객체의 움직임이 존재한다고 식별되면, 프로세서는 제1 카메라를 이 용하여 SSM 기능을 수행할 수 있다. 적어도 하나의 관심 영역 내에 객체의 움직임이 기설정된 시간 내에 존재하 지 않는다고 식별되면, 프로세서는 버퍼에 저장된 복수의 이미지 프레임 이후에 획득된 이미지 프레임에 기초하여 SSM 기능을 수행할지 여부를 식별할 수 있다. 또 다른 예로, 적어도 하나의 관심 영역 내에 객체의 움직임이 존재한다고 식별되면, 프로세서는 제1 카 메라에서 제2 카메라로 스위칭하고, 제2 카메라를 통해 SSM 기능을 수행할 수 있다. 이 때, 제2 카 메라에 포함된 제2 이미지 센서의 시야(Field of View, FOV)는 제1 카메라에 포함된 제1 이미지 센서의 시야보다 넓을 수 있다. 디스플레이는 도 4A의 디스플레이와 마찬가지로 프로세서의 제어에 따라 다양한 정보를 표시 할 수 있다. 디스플레이는 예를 들어, 액정 디스플레이 (LCD), 발광 다이오드 (LED) 디스플레이, 유기 발 광 다이오드 (OLED) 디스플레이, 양자 발광 다이오드 (QLED) 디스플레이, MEMS (microelectromechanical systems) 디스플레이 등으로 구현될 수 있다. 디스플레이는 다중 초점 디스플레이와 같은 깊이 인식(depth-aware) 디스플레이로 구현될 수 있다. 디스 플레이는 다양한 컨텐츠(예를 들어, 텍스트, 이미지, 비디오, 아이콘 또는 기호)를 표시할 수 있다. 특히, 디스플레이는 제1 카메라 또는 제2 카메라를 통해 획득된 복수의 이미지 프레임을 포 함하는 영상(또는, 라이브 뷰)를 표시할 수 있다. 디스플레이는 터치 스크린을 포함할 수 있고, 전자 펜 또는 사용자의 신체 부분을 사용하여 터치, 제스처, 근접 또는 호버링(hovering) 입력을 수신할 수 있다. 또한, 디스플레이는 플렉서블 디스플레이로 구현될 수 있다. 입력부는 회로를 포함하며, 전자 장치를 제어하기 위한 사용자 입력을 수신할 수 있다. 특히, 입력 부는 사용자 손 또는 스타일러스 펜 등을 이용한 사용자 터치를 입력받기 위한 터치 패널, 사용자 조작을 입력받기 위한 버튼 등이 포함될 수 있다. 또 다른 예로, 입력부는 다른 입력 장치(예로, 키보드, 마우스, 모션 입력부 등)로 구현될 수 있다. 한편, 입력부는 사용자로부터 입력된 제1 입력 데이터를 수 신하거나 각종 사용자 명령을 입력받을 수 있다. 특히, 입력부는 이미지 프레임 상에 관심 영역을 설졍하려는 사용자 명령을 입력받을 수 있다. 스피커는 오디오 처리부(미도시)에 의해 디코딩이나 증폭, 노이즈 필터링과 같은 다양한 처리 작업이 수 행된 각종 오디오 데이터를 출력하는 구성이다. 또한, 스피커는 각종 알림 음이나 음성 메시지를 출력할 수 있다. 예를 들어, 스피커는 SSM 기능을 수행한다는 알림 음 또는 제1 카메라에서 제2 카메라 로 스위칭된다는 알림 음을 출력할 수 있다. 도 15는 본 개시의 일 실시예에 따른, 전자 장치의 제어 방법을 설명하기 위한 순서도이다. 전자 장치는 제1 카메라를 통해 전자 장치의 주변을 촬영하여 복수의 이미지 프레임을 획득할 수 있 다(S1510). 이 때, 제1 카메라를 통해 촬영할 수 있는 영역은 제1 카메라에 포함된 제1 이미지 센서의 시야 내 에 포함된 영역을 의미할 수 있다. 전자 장치는 복수의 이미지 프레임 상에 관심 영역을 설정할 수 있다(S1520). 예를 들면, 전자 장치 는 복수의 이미지 프레임으로 구성된 영상(또는, 장면)을 표시할 수 있다. 전자 장치는 표시된 영상 중 일 부를 관심 영역으로 설정하려는 사용자 입력(예를 들어, 사용자 터치 등)을 수신할 수 있다. 또 다른 예로, 전 자 장치는 자동 초점 기능을 이용하여 특정 객체가 있는 영역을 관심 영역으로 설정할 수 있다. 전자 장치는 복수의 이미지 프레임 각각에 대응되는 모션 식별 맵을 획득하고, 획득된 모션 식별 맵에 기 초하여 복수의 이미지 프레임 중 적어도 하나의 이미지 프레임을 선택할 수 있다(S1530). 구체적으로, 전자 장치는 복수의 이미지 프레임 각각을 복수의 세그먼트로 분할하고, 복수의 이미지 프레 임 각각의 복수의 세그먼트 각각에서 모션 데이터를 검출할 수 있다. 전자 장치는 복수의 이미지 프레임 각각의 복수의 세그먼트 각각에서 검출된 모션 데이터의 평균(average)을 산출하여 복수의 이미지 프레임 각각 에 대한 모션 식별 맵을 획득할 수 있다. 그리고, 전자 장치는 복수의 이미지 프레임 각각에 대응되는 모션 식별 맵과 모션 임계값을 비교할 수 있 다. 전자 장치는 복수의 이미지 프레임 중 모션 임계값을 충족하는 모션 식별 맵에 대응되는 이미지 프레 임을 식별하고, 식별된 이미지 프레임 중 적어도 하나의 이미지 프레임을 선택할 수 있다. 전자 장치는 선택된 적어도 하나의 이미지 프레임 상에 설정된 관심 영역 상에서 객체의 움직임이 존재하 는지 여부 식별할 수 있다(S1540). 구체적으로, 전자 장치는 선택된 적어도 하나의 프레임을 객체를 인식 하도록 학습된 인공 지능 모델에 입력하여 선택된 적어도 하나의 프레임 상에 포함된 객체에 대한 정보를 획득 할 수 있다. 전자 장치는 획득된 객체에 대한 정보에 기초하여 객체를 움직이는 객체 및 정적 객체로 분류 하고, 분류된 움직이는 객체를 식별된 객체를 후보 객체로 할당할 수 있다. 그리고, 전자 장치는 관심 영 역 상에서 후보 객체의 움직임이 존재하는지 여부를 식별할 수 있다. 전자 장치는 식별 결과에 기초하여 제1 카메라를 통해 SSM 기능을 수행할 수 있다. 예를 들어, 적어도 하 나의 관심 영역 내에 상기 객체의 움직임이 존재한다고 식별되면, 전자 장치는 제1 카메라를 이용하여 SSM 기능을 수행할 수 있다. 또 다른 예로, 적어도 하나의 관심 영역 내에 객체의 움직임이 기설정된 시간 내에 존 재하지 않는다고 식별되면, 전자 장치는 복수의 이미지 프레임 이후에 제1 카메라를 통해 획득된 이미지 프레임에 기초하여 SSM 기능을 수행할지 여부를 식별할 수 있다. 즉, 전자 장치는 복수의 이미지 프레임 이후에 제1 카메라를 통해 획득된 이미지 프레임과 관련하여 상술된 처리 동작을 반복할 수 있다. 한편, 기기로 읽을 수 있는 저장매체는, 비일시적(non-transitory) 저장매체의 형태로 제공될 수 있다. 여기서, '비일시적 저장매체'는 실재(tangible)하는 장치이고, 신호(signal)(예: 전자기파)를 포함하지 않는다는 것을 의미할 뿐이며, 이 용어는 데이터가 저장매체에 반영구적으로 저장되는 경우와 임시적으로 저장되는 경우를 구 분하지 않는다. 예로, '비일시적 저장매체'는 데이터가 임시적으로 저장되는 버퍼를 포함할 수 있다. 일 실시 예에 따르면, 본 문서에 개시된 다양한 실시 예들에 따른 방법은 컴퓨터 프로그램 제품(computer program product)에 포함되어 제공될 수 있다. 컴퓨터 프로그램 제품은 상품으로서 판매자 및 구매자 간에 거래 될 수 있다. 컴퓨터 프로그램 제품은 기기로 읽을 수 있는 저장 매체(예: compact disc read only memory (CD- ROM))의 형태로 배포되거나, 또는 어플리케이션 스토어(예: 플레이 스토어TM)를 통해 또는 두개의 사용자 장치 들(예: 스마트폰들) 간에 직접, 온라인으로 배포(예: 다운로드 또는 업로드)될 수 있다. 온라인 배포의 경우에,컴퓨터 프로그램 제품(예: 다운로더블 앱(downloadable app))의 적어도 일부는 제조사의 서버, 어플리케이션 스 토어의 서버, 또는 중계 서버의 메모리와 같은 기기로 읽을 수 있는 저장 매체에 적어도 일시 저장되거나, 임시 적으로 생성될 수 있다. 이상에서 상술한 바와 같은 본 개시의 다양한 실시 예들에 따른 구성 요소(예: 모듈 또는 프로그램) 각각은 단 수 또는 복수의 개체로 구성될 수 있으며, 전술한 해당 서브 구성 요소들 중 일부 서브 구성 요소가 생략되거나, 또는 다른 서브 구성 요소가 다양한 실시 예에 더 포함될 수 있다. 대체적으로 또는 추가적으로, 일부 구성 요소들(예: 모듈 또는 프로그램)은 하나의 개체로 통합되어, 통합되기 이전의 각각의 해당 구성 요소 에 의해 수행되는 기능을 동일 또는 유사하게 수행할 수 있다. 다양한 실시 예들에 따른, 모듈, 프로그램 또는 다른 구성 요소에 의해 수행되는 동작들은 순차적, 병렬적, 반 복적 또는 휴리스틱하게 실행되거나, 적어도 일부 동작이 다른 순서로 실행되거나, 생략되거나, 또는 다른 동작 이 추가될 수 있다. 한편, 본 개시에서 사용된 용어 \"부\" 또는 \"모듈\"은 하드웨어, 소프트웨어 또는 펌웨어로 구성된 유닛을 포함하 며, 예를 들면, 로직, 논리 블록, 부품, 또는 회로 등의 용어와 상호 호환적으로 사용될 수 있다. \"부\" 또는 \" 모듈\"은, 일체로 구성된 부품 또는 하나 또는 그 이상의 기능을 수행하는 최소 단위 또는 그 일부가 될 수 있다. 예를 들면, 모듈은 ASIC(application-specific integrated circuit)으로 구성될 수 있다. 본 개시의 다양한 실시 예들은 기기(machine)(예: 컴퓨터)로 읽을 수 있는 저장 매체(machine-readable storage media에 저장된 명령어를 포함하는 소프트웨어로 구현될 수 있다. 기기는 저장 매체로부터 저장된 명령 어를 호출하고, 호출된 명령어에 따라 동작이 가능한 장치로서, 개시된 실시 예들에 따른 전자 장치(예: 전자 장치)를 포함할 수 있다. 상기 명령이 프로세서에 의해 실행될 경우, 프로세서가 직접 또는 상기 프로세서의 제어 하에 다른 구성요소들 을 이용하여 상기 명령에 해당하는 기능을 수행할 수 있다. 명령은 컴파일러 또는 인터프리터에 의해 생성 또는 실행되는 코드를 포함할 수 있다. 이상에서는 본 개시의 바람직한 실시 예에 대하여 도시하고 설명하였지만, 본 개시는 상술한 특정의 실시 예에"}
{"patent_id": "10-2020-0152072", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "한정되지 아니하며, 청구범위에서 청구하는 본 개시의 요지를 벗어남이 없이 당해 개시가 속하는 기술분야에서 통상의 지식을 가진 자에 의해 다양한 변형실시가 가능한 것은 물론이고, 이러한 변형실시들은 본 개시의 기술 적 사상이나 전망으로부터 개별적으로 이해되어서는 안 될 것이다."}
{"patent_id": "10-2020-0152072", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 개시의 일 실시에예 따른, 전자 장치의 구성을 설명하기 위한 블록도이고, 도 2은 본 개시의 일 실시에예 따른, 전자 장치에 포함된 SSM 비디오 컨트롤러의 구성을 설명하기 위한 도 3은 본 개시의 일 실시에예 따른, 전자 장치의 제어 방법을 설명하기 위한 순서도, 도 4a 및 도 4b는 본 개시의 일 실시에예 따른, 전자 장치의 제어 방법을 설명하기 위한 도면, 도 5은 본 개시의 일 실시에예 따른, 전자 장치가 인공 지능 모델을 이용하여 객체를 인식하는 과정을 설명하기 위한 도면, 도 6은 본 개시의 일 실시에예 따른, 전자 장치가 SSM 기능을 수행하는 과정을 설명하기 위한 도면, 도 7a 및 도 7b는 본 개시의 일 실시에예 따른, 전자 장치가 모션 맵을 생성 및 활용하는 과정을 설명하기 위한 도면, 도 8은 본 개시의 일 실시에예 따른, 전자 장치가 객체에 대한 정보를 식별하는 과정을 설명하기 위한 도면, 도 9a 내지 도 9i는 본 개시의 일 실시에예 따른, 전자 장치가 SSM 기능을 수행하는 과정을 설명하기 위한 도면, 도 10은 본 개시의 일 실시에예 따른, 전자 장치가 이미지 센서를 스위칭하는 과정을 설명하기 위한 도면, 도 11a 내지 도 11e는 본 개시의 일 실시에예 따른, 전자 장치가 장면의 스티칭(stitching)된 이미지를 생성하 는 과정을 설명하기 위한 도면, 도 12a 내지 도 12d는 본 개시의 일 실시에예 따른, 전자 장치가 SSM 기능을 수행하는 과정을 설명하기 위한 도 면, 도 13a 내지 도 13b는 본 개시의 일 실시예에 따른, 전자 장치가 SSM 기능을 수행하는 과정을 설명하기 위한 도 면, 도 14는 본 개시의 일 실시예에 따른, 전자 장치의 구성을 도시한 블록도, 도 15는 본 개시의 일 실시예에 따른, 전자 장치의 제어 방법을 설명하기 위한 도면이다."}
