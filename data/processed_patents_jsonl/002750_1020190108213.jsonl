{"patent_id": "10-2019-0108213", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2021-0026854", "출원번호": "10-2019-0108213", "발명의 명칭": "멀티모달 추적기술을 적용한 다중지능 모니터링 시스템 및 그 동작 방법", "출원인": "주식회사 나눔기술", "발명자": "박진영"}}
{"patent_id": "10-2019-0108213", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "사용자 얼굴을 인식하고, 상기 사용자의 감정, 동선, 머리 움직임 및 시선위치를 감지하며, 상기 사용자의 시점에 대한 영상을 감지하고, 상기 영상에 대한 상황을 음성 및 문자 중 적어도 어느 하나로 설명하는 인식부;상기 사용자의 감정, 동선, 머리 움직임 및 시선위치를 통해 컴패니언 플래닝 그래프를 산출하고, 상기 컴패니언 플래닝 그래프를 통해 사용자의 감정 및 신체의 상태를 파악하며, 상기 파악된 사용자의 감정 및 신체의 상태를 통해 상기 사용자의 의도를 추론하는 추론부; 및상기 추론된 사용자의 의도를 맞춰서 3D 가상 아바타가 응답하며, 상기 응답한 3D 가상 아바타에 대응되는 상기사용자의 음성이 입력되고, 상기 입력된 사용자의 음성을 인식하여 컴패니언이 문자 및 음성을 통해 발화하며,상기 발화된 컴패니언의 문자를 파악하여 상기 3D 가상 아바타의 감정상태를 표현하는 표현부를 포함하는 멀티모달 추적기술을 적용한 다중지능 모니터링시스템."}
{"patent_id": "10-2019-0108213", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 저장 매체에 추가 할 수 있는 물리적 보안으로서 외부로부터 완벽히 격리된 저장 공간을 만든다. 정보 를 담은 저장매체의 도입부에 산화물 반도체를 이용한 컨트롤러를 추가해 정보를 보호한다. 정보를 훼손하지 않 고 물리적으로 보호 할 수 있으며 안에 있는 정보를 읽기 위해서 컨트롤러 변형이 일어나면 추후 사용자가 공개 된 정보인지 알 수 있어 비공개 정보를 보관하는데 뛰어나다."}
{"patent_id": "10-2019-0108213", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 멀티모달 추적기술을 적용한 다중지능 모니터링시스템 및 그 동작 방법에 관한 것으로서, 사용자를 이해하고 적절한 도움을 주는 동반자 관점에서 다양한 입력을 수집하여 학습하는 적응형 기계학습 기반 자율지 능 디지털 동반자를 구현하는 기술적 사상을 개시한다."}
{"patent_id": "10-2019-0108213", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "아이폰의 시리와 같이 사용자가 말을 하면 그것을 녹음해 애플의 서버로 전송하고, 전송된 사용자의 음성을 분 석하여 텍스트로 변환하는 기술이 개발되고 있다. 처음 시리가 발표되었을 때는 단순한 음성인식 기능을 탑재하고 있었지만, 점점 많은 사람들이 음성인식 개인비 서라고 인식하기 시작했다. 그래서, 인공지능의 한 종류인 딥러닝 기술의 발달과 함께 개인비서 및 디지털 컴패 니언의 개념이 일반화 되어가고 있다. 따라서, 디지털 동반자 디바이스별 모니터링 및 디버깅 정보를 제공하여 동반자의 응답 및 자율반응에 대한 근 거를 제시하고, 이를 통해 동반자 이해 및 지능모듈 개선에 활용하는 연구 및 개발이 활발해지고 있다. 선행기술문헌 특허문헌 (특허문헌 0001) 한국공개특허 제10-2019-0043201호, \"디지털 동반자를 위한 EMMA 기반의 모니터링 인터페이스 시스템\""}
{"patent_id": "10-2019-0108213", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 사용자를 이해하고 적절한 도움을 주는 동반자 관점에서 다양한 입력을 수집하여 학습하는 적응형 기 계학습 기반 자율지능 디지털 동반자 프로젝트를 포함하는 멀티모달 추적기술을 적용한 다중지능 모니터링시스 템 및 그 동작 방법을 제공하고자 한다본 발명은 디지털 동반자가 주어진 상황을 이해하고, 대응 전략을 수립하며 개입 시점과 행위를 결정하는 과정 을 실시간으로 모니터링 할 수 있도록 시각화 기법을 적용하여 직관적으로 통찰, 디버깅할 수 있도록 구현하는 멀티모달 추적기술을 적용한 다중지능 모니터링시스템 및 그 동작 방법을 제공하고자 한다."}
{"patent_id": "10-2019-0108213", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "일실시예에 따른 멀티모달 추적기술을 적용한 다중지능 모니터링시스템 및 그 동작 방법은 사용자 얼굴을 인식 하고, 상기 사용자의 감정, 동선, 머리 움직임 및 시선위치를 감지하며, 상기 사용자의 시점에 대한 영상을 감 지하고, 상기 영상에 대한 상황을 음성 및 문자 중 적어도 어느 하나로 설명하는 인식부, 상기 사용자의 감정, 동선, 머리 움직임 및 시선위치를 통해 컴패니언 플래닝 그래프를 산출하고, 상기 컴패니언 플래닝 그래프를 통 해 사용자의 감정 및 신체의 상태를 파악하며, 상기 파악된 사용자의 감정 및 신체의 상태를 통해 상기 사용자 의 의도를 추론하는 추론부 및 상기 추론된 사용자의 의도를 맞춰서 3D 가상 아바타가 응답하며, 상기 응답한 3D 가상 아바타에 대응되는 상기 사용자의 음성이 입력되고, 상기 입력된 사용자의 음성을 인식하여 컴패니언 이 문자 및 음성을 통해 발화하며, 상기 발화된 컴패니언의 문자를 파악하여 상기 3D 가상 아바타의 감정상태를 표현하는 표현부를 포함한다."}
{"patent_id": "10-2019-0108213", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명에 따르면 사용자를 이해하고 적절한 도움을 주는 동반자 관점에서 다양한 입력을 수집하여 학습하는 적 응형 기계학습 기반 자율지능 디지털 동반자 프로젝트를 포함하는 멀티모달 추적기술을 적용한 다중지능 모니터 링시스템 및 그 동작 방법을 제공할 수 있다. 본 발명에 따르면 디지털 동반자가 주어진 상황을 이해하고, 대응 전략을 수립하며 개입 시점과 행위를 결정하 는 과정을 실시간으로 모니터링 할 수 있도록 시각화 기법을 적용하여 직관적으로 통찰, 디버깅할 수 있도록 구 현하는 멀티모달 추적기술을 적용한 다중지능 모니터링시스템 및 그 동작 방법을 제공할 수 있다."}
{"patent_id": "10-2019-0108213", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 명세서에 개시되어 있는 본 발명의 개념에 따른 실시예들에 대해서 특정한 구조적 또는 기능적 설명들은 단 지 본 발명의 개념에 따른 실시예들을 설명하기 위한 목적으로 예시된 것으로서, 본 발명의 개념에 따른 실시예 들은 다양한 형태로 실시될 수 있으며 본 명세서에 설명된 실시예들에 한정되지 않는다. 본 발명의 개념에 따른 실시예들은 다양한 변경들을 가할 수 있고 여러 가지 형태들을 가질 수 있으므로 실시예 들을 도면에 예시하고 본 명세서에 상세하게 설명하고자 한다. 그러나, 이는 본 발명의 개념에 따른 실시예들 을 특정한 개시형태들에 대해 한정하려는 것이 아니며, 본 발명의 사상 및 기술 범위에 포함되는 변경, 균등물, 또는 대체물을 포함한다. 제1 또는 제2 등의 용어를 다양한 구성요소들을 설명하는데 사용될 수 있지만, 상기 구성요소들은 상기 용어들 에 의해 한정되어서는 안 된다. 상기 용어들은 하나의 구성요소를 다른 구성요소로부터 구별하는 목적으로만, 예를 들어 본 발명의 개념에 따른 권리 범위로부터 이탈되지 않은 채, 제1 구성요소는 제2 구성요소로 명명될 수 있고, 유사하게 제2 구성요소는 제1 구성요소로도 명명될 수 있다. 어떤 구성요소가 다른 구성요소에 \"연결되어\" 있다거나 \"접속되어\" 있다고 언급된 때에는, 그 다른 구성요소에 직접적으로 연결되어 있거나 또는 접속되어 있을 수도 있지만, 중간에 다른 구성요소가 존재할 수도 있다고 이 해되어야 할 것이다. 반면에, 어떤 구성요소가 다른 구성요소에 \"직접 연결되어\" 있다거나 \"직접 접속되어\" 있 다고 언급된 때에는, 중간에 다른 구성요소가 존재하지 않는 것으로 이해되어야 할 것이다. 구성요소들 간의 관계를 설명하는 표현들, 예를 들어 \"~사이에\"와 \"바로~사이에\" 또는 \"~에 직접 이웃하는\" 등도 마찬가지로 해 석되어야 한다. 본 명세서에서 사용한 용어는 단지 특정한 실시예들을 설명하기 위해 사용된 것으로, 본 발명을 한정하려는 의 도가 아니다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 명세서에 서, \"포함하다\" 또는 \"가지다\" 등의 용어는 설시된 특징, 숫자, 단계, 동작, 구성요소, 부분품 또는 이들을 조 합한 것이 존재함으로 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성요소, 부분품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되어야 한다. 다르게 정의되지 않는 한, 기술적이거나 과학적인 용어를 포함해서 여기서 사용되는 모든 용어들은 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자에 의해 일반적으로 이해되는 것과 동일한 의미를 가진다. 일반적 으로 사용되는 사전에 정의되어 있는 것과 같은 용어들은 관련 기술의 문맥상 가지는 의미와 일치하는 의미를갖는 것으로 해석되어야 하며, 본 명세서에서 명백하게 정의하지 않는 한, 이상적이거나 과도하게 형식적인 의 미로 해석되지 않는다. 이하, 실시예들을 첨부된 도면을 참조하여 상세하게 설명한다. 그러나, 특허출원의 범위가 이러한 실시예들에 의해 제한되거나 한정되는 것은 아니다. 각 도면에 제시된 동일한 참조 부호는 동일한 부재를 나타낸다. 도 1은 본 발명의 실시예에 따른 멀티모달 추적기술을 적용한 다중지능 모니터링시스템 및 그 동작 방법의 구성 을 나타내는 모식도를 도시하는 도면이다. 일실시예에 따른 멀티모달 추적기술을 적용한 다중지능 모니터링시스템 및 그 동작 방법의 목적은 1) 디지털동 반자 : 사용자를 이해하고 적절한 도움을 주는 동반자 관점에서 다양한 입력을 수집하여 학습하는 적응형 기계 학습 기반 자율지능 디지털 동반자 프로젝트이며, 2) 동반자 모니터링 및 디버깅 : 디지털 동반자가 주어진 상 황을 이해하고, 대응 전략을 수립하며 개입 시점과 행위를 결정하는 과정을 실시간으로 모니터링 할 수 있도록 시각화 기법을 적용하여 직관적으로 통찰, 디버깅할 수 있도록 구현하는데 목적이 있다. 이를 위해, 다중지능 모니터링시스템은 인식부, 추론부, 및 표현부를 포함할 수 있다. 먼저, 인식부는 사용자 얼굴을 인식하고, 상기 사용자의 감정, 동선, 머리 움직임 및 시선위치를 감지하며, 상 기 사용자의 시점에 대한 영상을 감지하고, 상기 영상에 대한 상황을 음성 및 문자 중 적어도 어느 하나로 설명 할 수 있다. 다음으로, 추론부는 사용자의 감정, 동선, 머리 움직임 및 시선위치를 통해 컴패니언 플래닝 그래프를 산출하고, 상기 컴패니언 플래닝 그래프를 통해 사용자의 감정 및 신체의 상태를 파악하며, 상기 파악된 사용자 의 감정 및 신체의 상태를 통해 상기 사용자의 의도를 추론할 수 있다. 다음으로, 표현부는 추론된 사용자의 의도를 맞춰서 3D 가상 아바타가 응답하며, 상기 응답한 3D 가상 아바타에 대응되는 상기 사용자의 음성이 입력되고, 상기 입력된 사용자의 음성을 인식하여 컴패니언이 문자 및 음성을 통해 발화하며, 상기 발화된 컴패니언의 문자를 파악하여 상기 3D 가상 아바타의 감정상태를 표현할 수 있다. 일실시예에 따른 멀티모달 추적기술을 적용한 다중지능 모니터링시스템 및 그 동작 방법은 디지털 동반자 디바 이스별 모니터링 및 디버깅 정보를 제공하여 동반자의 응답 및 자율반응에 대한 근거를 제시하고, 이를 통해 동 반자 이해 및 지능모듈 개선에 활용할 수 있다. [표 1]"}
{"patent_id": "10-2019-0108213", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "표 1은 시스템 요구사항의 정의를 나타낸 것이다. 일실시예에 따른 멀티모달 추적기술을 적용한 다중지능 모니터링시스템 및 그 동작 방법은 컨테이너 기반으로 개발된 지능엔진들과 함께 모니터링 시스템도 컨테이너 기반으로 개발되어 AI 컨테이너 프레임워크에 의해 관리 됨. Application에서 gRPC로 engine들을 호출하여 나온 결과들을 파라미터로 하여 모니터링 시스템 컨테이너를 호출하여 결과들을 데이터베이스에 저장하고, 이를 get하여 웹 서비스를 통해 모니터링하고 디버깅할 수 있도록 할 수 있다. 도 2은 본 발명의 실시예에 따른 디지털 동반자 전체 시스템 구성도에서의 모니터링 시스템을 나타내는 모식도 를 도시하는 도면이다. 1) Application의 gRPC Client에서 AI 엔진 컨테이너들에 gRPC 호출하여 AI 엔진들의 결과를 STRING 형태로 Return받고 이를 AI 엔진 결과 INFO JSON의 output 값으로 한다 2) 이 AI 엔진 결과 INFO 를 모니터링 시스템 컨테이너에 gRPC 호출하고 파라미터로 넘겨 DB에 저장하며 모니터 링 시스템의 웹 화면에 나타낸다. 3) 해석이 필요 없는 신체정보에 대한 시그널이나 얼굴인식 등의 실시간 정보는 엔진에서의 gRPC Client가 직접 모니터링 시스템 컨테이너로 realtime data를 파라미터로하여 gRPC 호출한다. 도 3는 일실시예에 따른 디지털 동반자 모니터링 시스템 구성도을 도시한 것이다. 모니터링 시스템 구성도는 Application의 gRPC호출로 지능엔진의 결과를 받아오면 이를 AI 엔진 결과 INFO JSON 의 output 값으로 하고 다시 모니터링 시스템에 gRPC 호출로 넘겨줄 수 있다. 그리고, 그 결과를 모니터링 시스템 컨테이너로 gRPC 호출하여 보내줌. 넘겨진 지능엔진의 결과는 JSON으로 변 환하여 DB에 저장함. 마지막 엔진까지 정상적으로 처리 된 결과는 파싱하여 모니터링 화면에 출력하고, 모든 결 과들은 이벤트리스트 페이지를 통해 디버깅 환경을 제공할 수 있다. 1) AI 엔진에서 나온 결과를 파라미터로 모니터링 시스템 gRPC 호출하여 넘겨준다. 2) 모니터링 시스템으로 넘겨진 AI 엔진의 결과를 모니터링과 디버깅 서비스를 위한 함수로 전달한다. 3) String 형태의 AI 엔진의 결과를 Database에 Insert한다. 4) String 형태의 AI 엔진의 결과를 JSON으로 변환하고 파싱한다. 5) 파싱한 결과를 브로드캐스터에 전달한다. 6) 브로드캐스터는 모니터링 웹 페이지의 웹소켓을 통해 파싱한 결과를 전달하여 실시간 모니터링 플로우로 나 타낸다. 7) 사용자가 모니터링 서비스에서 디버깅을 위한 이벤트리스트 웹 페이지에 접속하면 데이터베이스에서 이벤트 리스트들을 Get하여 목록으로 보여주고, 사용자가 이벤트를 선택하면 디버깅 환경을 제공한다. 도 4는 일실시예에 따른 모니터링 서비스 시퀀스 다이어그램을 도시한 것이다. 1) 실시간 데이터를 모니터링 시스템 컨테이너에 gRPC 호출한다. 2) 실시간 데이터를 모니터링 웹페이지에 지속적으로 보내 모니터링 할 수 있게 한다. 3) Application에서 AI 엔진에 gRPC 호출한다. 4) AI 엔진의 결과가 Application에 Return 된다. 5) 해당 디바이스의 ID인 DCId(참조 2), 전체 시스템의 프로세스 맵에 대한 정보를 넘겨줄 processMap, 그리고 AI 엔진들의 결과 out을 AI 엔진 결과 INFO 에 넣어 파라미터로 모니터링 컨테이너에 gRPC 호출한다. 6) AI 엔진의 결과와 해당하는 프로세스 맵을 Database에 Insert 요청한다. 7) Database에 Insert가 수행된다. 8) 모두 수행된 이벤트를 AI 엔진들의 결과와 프로세스 맵으로 모니터링 웹페이지에 웹소켓을 통해 넘겨주어 플 로우와 함께 모니터링 서비스 한다. 9) Application에 성공여부를 리턴한다. 도 5는 일실시예에 따른 디버깅 서비스 시퀀스 다이어그램을 도시한 것이다. 오픈 1) 사용자가 모니터링 웹페이지에서 이벤트 리스트 페이지를 연다. 2) getDevicesList 함수를 실행시킨다. 3) Database에서 디바이스 리스트를 get 요청한다. 4) 이벤트 리스트에 대한 get 요청이 완료된다. 5) 웹소켓을 통해 웹페이지로 디바이스 리스트를 보낸다. 6) 디바이스 리스트를 웹페이지를 통해 사용자에게 보여준다 닫기 7) 사용자가 디바이스 리스트에서 하나를 선택한다. 8) 해당 디바이스의 ID로 getEventsList(DCId) 함수를 실행시킨다. 9) Database에서 이벤트 리스트를 get 요청한다. 10) 이벤트 리스트에 대한 get 요청이 완료된다. 11) 웹소켓을 통해 웹페이지로 이벤트 리스트를 보낸다. 12) 이벤트 리스트를 웹페이지를 통해 사용자에게 보여준다. 13) 사용자가 이벤트 리스트에서 하나의 이벤트를 선택한다. 14) getEventDetail 함수에 파라미터로 해당 이벤트의 아이디를 파라미터로 하여 호출한다. 15) 해당 이벤트의 디테일(JSON)과 프로세스 맵을 Database에서 get요청한다. 16) 해당 이벤트에 대한 get 요청이 완료된다. 17) 해당 이벤트 디테일을 웹소켓을 통해 보낸다. 18) 해당 이벤트 디테일과 프로세스 맵을 이용하여 이벤트 플로우와 디버깅 환경을 사용자에게 제공한다. 도 6는 일실시예에 따른 탠서플로우의 예를 도시한 것이다. Maker/프레임웍은 도커 컨테이너는 일종의 소프트웨어를 소프트웨어의 실행에 필요한 모든 것을 포함하는 완전 한 파일 시스템 안에 감싼다. 여기에는 코드, 런타임, 시스템 도구, 시스템 라이브러리 등 서버에 설치되는 무 엇이든 포함할 수 있다. gRPC는 네트워크 상태나 콜 방식을 신경쓰지 않고 프로그래머가 원격의 함수를 실행하게 하며 C++, Java, Python, Go 등의 여러 언어를 지원할 수 있다. 디지털동반자의 지능 엔진들은 도커 컨테이너로 개발하고 배포되어 gRPC로 지능엔진의 함수들을 실행할 수 있다. config.yaml을 작성하고 AIContaitnerMaker (KETI 제공유틸리티) 를 이용하면 컨테이너와 gRPC 세팅을 자동으 로 할 수 있다. 2) 모니터링 시스템 Maker/프레임웍 활용방안 도 7는 일실시예에 따른 모니터링 시스템 메이커 및 프레임웍을 도시한 것이다. 모니터링 시스템도 지능엔진의 결과들을 받기 쉽고 빠르게 처리하기 위하여 같은 프레임웍에 올려질 수 있다. 1) 모니터링 시스템에 대한 설정파일config.yaml을 작성한다. 2) AIContainerMaker(KETI 제공 유틸리티)를 이용하여 컨테이너를 만든다. 3) 컨테이너에서 모니터링 시스템을 개발한다. 4) 이미지로 변한하고KETI 제공 클라우드 리포지토리에 업로드 한다. 5) 그 이미지를 다운로드 받고 컨테이너로 변환하여 프레임웍에 올리면 프레임웍에 올려진 다른 지능엔진들과 어울리게 한다. 6) 모니터링 시스템 컨테이너에 gRPC 호출해 지능엔진들의 결과를 보내어 모니터링이 이루어진다. 도 8는 일실시예에 따른 모니터링 및 디버깅 상세설계를 도시한 것이다. 1) ubuntu os기반의 컨테이너를 생성한다. 2) nodeJS 에서 gRPC로 통신하여 데이터를 받아 웹 서비스 한다. 3) gRPC를 통해 받은 데이터를 nodeJS에서 mongoDB로 저장한다. 도 9는 일실시예에 따른 모니터링 및 디버깅 정의 및 스펙을 도시한 것이다. 먼저, 모니터링 및 디버깅 정의는 디지털 동반자 디바이스별 모니터링 및 디버깅 정보를 제공하여 동반자의 응 답 및 자율반응에 대한 근거를 제시하고, 이를 통해 동반자 이해 및 지능모듈 개선에 활용할 수 있다. 모니터링 및 디버깅 방법은 동반자 이해를 포함할 수 있다. 동반자 이해는 동반자가 사용자의 상태를 어떻게 이해하고 있는지를 모니터링 할 수 있다. 얼굴인식은 디지털 동반자의 카메라가 사용자의 얼굴을 촬영하여 어떤 표정을 하고 있는지, 동반자는 그 표정을 어떻게 이해하고 있는지(웃음, 찡그림, 끄덕거림, 코 주름)를 모니터링 할 수 있다. 사용자 상태는 사용자의 체온, 호흡, 맥락, 심전도를 실시간으로 보여주고, 디지털 동반자가 사용자의 상태와 행동 등에 따라 어떤 감정, 정서, 정신상태를 갖고 있는지 모니터링 할 수 있다. 친밀도 및 대화전략는 디지털 동반자와 사용자가 얼마만큼의 친밀감을 갖고 있는지, 디지털 동반자가 어떠한 대 화 전략을 취하고 있는지에 대해 모니터링 할 수 있다. 도 10는 일실시예에 따른 동반자 대화를 도시한 것이다. 동반자대화는 동반자가 사용자에게 어떤 대화를 취하고 있는지를 모니터링 할 수 있다. 1. 디지털 동반자가 사용자에게 어떤 표정과 입모양으로 이야기하는지를 모니터링 한다. 2. 디지털 동반자가 사용자에게 어떤 문장을 어떻게 어절을 나누고 어절에 따라 어떤 제스쳐와 감정으로 말하는 지를 모니터링 한다. 3. 디지털 동반자가 사용자에게 어떤 문장의 말을 하는지를 모니터링 한다. 도 11은 일실시예에 따른 동반자 대화의 실시간 화면을 도시한 것이다. 실시간화면은 디지털 동반자에 대한 입력에 대해 각 지능엔진들이 어떻게, 무슨 판단을 내려 어떤 결과를 내리 는지에 대하여 실시간 플로우로 나타내고 지능엔진을 선택하여 세부사항을 모니터링 할 수 있다. 실시간 플로우는 디지털 동반자에 실시간으로 들어는 입력과 이를 멀티모달 해석하여 출력하는 과정을 플로우로 보여준다. Confidence와 Duration을 한눈에 볼 수 있으며, Confidence가 너무 낮거나 Duration이 너무 높은 경 우에 이상현상을 각화하여 모니터링 한다. 실시간 플로우의 세부사항은 실시간 플로우에서 지능엔진을 선택하면, 해당 지능엔진의 입출력에 대한 JSON 내 용을 확인하여 모니터링할 수 있다. 도 12은 일실시예에 따른 동반자 대화의 이벤트 리스트를 도시한 것이다. 동반자대화는 동반자가 사용자에게 어떤 대화를 취하고 있는지를 모니터링 할 수 있다. 1. 디지털 동반자가 사용자에게 어떤 표정과 입모양으로 이야기하는지를 모니터링 한다. 2. 디지털 동반자가 사용자에게 어떤 문장을 어떻게 어절을 나누고 어절에 따라 어떤 제스쳐와 감정으로 말하는 지를 모니터링 한다. 3. 디지털 동반자가 사용자에게 어떤 문장의 말을 하는지를 모니터링 한다. 도 13은 일실시예에 따른 디지털 컴패니온 컨테이너 기반 프레임워크를 도시한 것이다. 디지털 동반자 응용서비스와의 인터페이스 정의는 모니터링을 위한 정보(디바이스, 모듈, 입출력값 등)를 받기 위한 과정으로 응용서비스와 주고받을 프로토콜을 정의할 수 있다. AI 엔진 결과 INFO 전송은 Application의 gRPC Client에서 AI 엔진 컨테이너들에 gRPC 호출하여 AI 엔진들의 결과를 STRING 형태의 JSON으로 Return받은 후, 이를 모니터링 컨테이너에 파라미터로 하여 넘겨줄 때 AI 엔진 결과에 대한 INFO도 파라미터로 포함하여 gRPC 호출. 다음의 AI 엔진결과 INFO 요소들을 proto 메시지 선언할 수 있다. [표 2]"}
{"patent_id": "10-2019-0108213", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "표 2는 AI 엔진 결과 정보를 나타낸 것이다. gRPC는 구글에서 처음 개발하여 공개한 원격 프로시저 호출(RPC) 시스템으로 HTTP/2 를 사용하고 인터페이스 설 명 언어로 프로토콜 버퍼를 사용하고, 인터페이스 설명 언어가 하나이기 때문에 다양한 언어에서 데이터를 주고 받을 수 있는 장점이 있다. HTTP/2는 HTTP/1.1의 알려진 성능 제한이 개선된 프로토콜로 헤더 필드 압축과 동일한 연결에서 다중 동시 교환 허용 등을 통한 리소스 비용 절감 및 성능 개선이 진행된다. 프로토콜 버퍼는 구글에서 공개한 직렬화 데이터 구조로 다양한 언어를 지원한다는 장점이 있다. 최대 64M 까지 데이터를 전달할 수 있으며, JSON 과 유연한 데이터 전환이 가능하다. 도 14은 일실시예에 따른 gRPC 테스트의 python to nodejs를 도시한 것이다. I 필요 소프트웨어 (테스트 기준) nodejs (v6.14.4) ? nodejs grpc module (v1.11.0) ? mongoDB(v2.6.10) ? Python (v2.7.12) ? grpcio, grpcio-tool (v1.16.0) II. protobuf 인터페이스 선언 gRPC를 사용하려면 받는 쪽과 주는 쪽 모두 인터페이스 모델을 정의해주어야 한다. message 는 각 언어에서 Object 에 해당하는 값이며 Service 는 Function 에 해당하는 값이다 도 15은 일실시예에 따른 nodejs 설치를 도시한 것이다. 도 16은 일실시예에 따른 npm 모듈 설치의 package.json 파일 작성 후 npm install 실행를 도시한 것이다. 도 17은 일실시예에 따른 mongoDB 설치를 도시한 것이다. 도 18은 일실시예에 따른 python 관련 grpc 라이브러리 설치를 도시한 것이다. 도 19은 일실시예에 따른 grpc_sender.py의 공통 코드를 도시한 것이다. 도 20은 일실시예에 따른 grpc_inference.py의 main를 도시한 것이다. 도 21은 일실시예에 따른 current_tracking_1.json의 샘플 json 데이터를 도시한 것이다. 도 22은 일실시예에 따른 cam .jpg의 샘플 이미지 데이터를 도시한 것이다. 도 23은 일실시예에 따른 app_grpc.js의 주요 핵심 코드를 도시한 것이다. 도 24은 일실시예에 따른 Receive서버 실행를 도시한 것이다. 도 25은 일실시예에 따른 Send클라이언트 실행를 도시한 것이다. 도 26은 일실시예에 따른 클라이언트 전송 로그를 도시한 것이다. 도 27은 일실시예에 따른 서버 전송 로그를 도시한 것이다. 도 28은 일실시예에 따른 작성한 예제 프로그램 결과 화면를 도시한 것이다. 도 29은 일실시예에 따른 gRPC로 이미지 전송를 도시한 것이다. gRPC로 이미지 전송에 대한 플로우(Flow)는 다음과 같다. 1. Base64 인코딩으로 string 형태로 변환하여 데이터 전달한다. 2. 서버에서는 string 을 js 의 FileReader 객체로 변환하여 이미지 출력한다. 3. 연속된 이미지를 지속적으로 교환하여 동영상처럼 보이게한다. 일실시예에 따른 멀티모달 추적기술을 적용한 다중지능 모니터링시스템 및 그 동작 방법은 4.2와 같이 모니터링 시스템 컨테이너의 함수를 gRPC call 할 때, deviceId를 파라미터로 보내 데이터베이스에 저장하고 관리하므로 5.3에 장치 선택 기능을 이용하여 개별 디바이스에 대한 모니터링이 가능할 수 있다. 일실시예에 따른 멀티모달 추적기술을 적용한 다중지능 모니터링시스템 및 그 동작 방법은 5.4 json양식이 지능 엔진에서 4.1처럼 전달되어 5.3의 네 가지 웹페이지를 통해 디지털 동반자의 응답 및 행위를 이해할 수 있는 근 거를 제시할 수 있다. 일실시예에 따른 멀티모달 추적기술을 적용한 다중지능 모니터링시스템 및 그 동작 방법은 5.4 json양식이 지능 엔진에서 4.1처럼 전달되어 5.3의 실시간 화면을 통해, 각 지능모듈별 상세사항 기능을 이용하여 전체시스템에 서 정의된 프로세스의 지능모듈별 입출력정보를 확인할 수 있다 일실시예에 따른 멀티모달 추적기술을 적용한 다중지능 모니터링시스템 및 그 동작 방법은 5.4 json양식이 지능 엔진에서 4.1처럼 전달되어 5.3의 실시간 화면을 통해 duration이나 confidence 등이 기대치에 많이 미치지 못 할 때 해당 모듈을 하이라이팅하여, 실시간 지능모듈의 이상유무를 판단할 수 있다 일실시예에 따른 멀티모달 추적기술을 적용한 다중지능 모니터링시스템 및 그 동작 방법은 5.4 json양식이 지능 엔진에서 4.1처럼 전달되어 5.3의 실시간 화면과 세부사항 기능을 통해, 지능모듈별 처리현황(정확도, 처리시간 등)을 파악할 수 있다. 일실시예에 따른 멀티모달 추적기술을 적용한 다중지능 모니터링시스템 및 그 동작 방법은 4.1과 같이 지능엔진 에서 전달된 디바이스의 ID, 지능엔진들의 결과가 DB에 저장되어, 5.3의 이벤트리스트로 특정시점의 이벤트 입출력정보를 디바이스별, 지능모듈별 조회할 수 있다. 일실시예에 따른 멀티모달 추적기술을 적용한 다중지능 모니터링시스템 및 그 동작 방법은 4.1과 같이 gRPC client app에서 전달된 전체 시스템의 프로세스 맵에 대한 정보로 전체시스템 지능모듈 프로세스와 동일한 프로 세스 기반의 모니터링이 가능하다. 일실시예에 따른 멀티모달 추적기술을 적용한 다중지능 모니터링시스템 및 그 동작 방법은 5.1과 같이 모니터링 시스템 컨테이너가 같은 프레임웍에 올려지기 때문에 지능엔진의 결과들을 받기 쉽고 빠르게 처리하므로, 각 지 능모듈 및 전체시스템에 성능저하를 최소화할 수 있다. 이로써 디지털 동반자 디바이스별 모니터링 및 디버깅 정보를 제공하여 동반자의 응답 및 자율반응에 대한 근거 를 제시하고, 이를 통해 동반자 이해 및 지능모듈 개선에 활용할 수 있다. [참조1] 프로세스 맵 전체 시스템 지능모듈 프로세스와 동일한 프로세스 기반의 모니터링이 가능하므로, 전체 프로세스 흐름을 관장 하는 gRPC Client application에서 프로세스 맵을 모니터링 시스템으로 전달해주어야 한다. 예시1 엔진이 a,b,c가 있을 때 engineId가 각 a,b,c 일 때, 프로세스가 a -> b -> c순인 경우 String processMap = \"a:b, b,c\"; 예시2 엔진이 a,b,c가 있을 때 engineId가 각 a,b,c 일 때, 프로세스가 a -> b,c(동시)순인 경우 String processMap = \"a:bc\"; 엔진이 a,b,c가 있을 때 engineId가 각 a,b,c 일 때, 프로세스가 a,b(동시) ->c순인 경우 String processMap = \"ab:c\"; [참조 2] DCId 디지털 동반자의 장치별 조회가 가능하게 하는 역할을 담당한다. 어떤 엑소브레인 장치에서 나온 지능 엔진 결 과인지를 알 수 있도록, 엔진결과들이 모이는 gRPC Client application에서 모니터링 시스템의 함수를 호출할 때 AI 엔진 결과 INFO의 DCId포함하여 전달해주어야 한다. String DCId [참조3] 실시간 데이터 전송 모니터링 시스템 컨테이너의 gRPC server로 연결하여 실시간 데이터를 파라미터로gRPC 호출하는 소스 제공 예정. 실시간 데이터 값이 생길 때마다 호출로 gRPC 호출할 수 있다.(너무 많은 호출로 성능 저하 발생시, 스트 리밍 등으로 우회 가능성 있음) [참조4] 실시간 데이터 전송 제한량 실시간 데이터 전송은 gRPC 프로토콜을 이용하기 때문에 gRPC의 최대 전송량인 64MB 를 넘을 수 없음. 이미지가 포함된 데이터의 경우 64MB를 넘지 않도록 조절이 필요할 수 있다. 이상에서 설명된 장치는 하드웨어 구성요소, 소프트웨어 구성요소, 및/또는 하드웨어 구성요소 및 소프트웨어 구성요소의 조합으로 구현될 수 있다. 예를 들어, 실시예들에서 설명된 장치 및 구성요소는, 예를 들어, 프로 세서, 콘트롤러, ALU(arithmetic logic unit), 디지털 신호 프로세서(digital signal processor), 마이크로컴 퓨터, FPA(field programmable array), PLU(programmable logic unit), 마이크로프로세서, 또는 명령 (instruction)을 실행하고 응답할 수 있는 다른 어떠한 장치와 같이, 하나 이상의 범용 컴퓨터 또는 특수 목적 컴퓨터를 이용하여 구현될 수 있다. 처리 장치는 운영 체제(OS) 및 상기 운영 체제 상에서 수행되는 하나 이상 의 소프트웨어 애플리케이션을 수행할 수 있다. 또한, 처리 장치는 소프트웨어의 실행에 응답하여, 데이터를접근, 저장, 조작, 처리 및 생성할 수도 있다. 이해의 편의를 위하여, 처리 장치는 하나가 사용되는 것으로 설"}
{"patent_id": "10-2019-0108213", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "명된 경우도 있지만, 해당 기술분야에서 통상의 지식을 가진 자는, 처리 장치가 복수 개의 처리 요소 (processing element) 및/또는 복수 유형의 처리 요소를 포함할 수 있음을 알 수 있다. 예를 들어, 처리 장치 는 복수 개의 프로세서 또는 하나의 프로세서 및 하나의 콘트롤러를 포함할 수 있다. 또한, 병렬 프로세서 (parallel processor)와 같은, 다른 처리 구성(processing configuration)도 가능하다. 소프트웨어는 컴퓨터 프로그램(computer program), 코드(code), 명령(instruction), 또는 이들 중 하나 이상의 조합을 포함할 수 있으며, 원하는 대로 동작하도록 처리 장치를 구성하거나 독립적으로 또는 결합적으로 (collectively) 처리 장치를 명령할 수 있다. 소프트웨어 및/또는 데이터는, 처리 장치에 의하여 해석되거나 처리 장치에 명령 또는 데이터를 제공하기 위하여, 어떤 유형의 기계, 구성요소(component), 물리적 장치, 가상 장치(virtual equipment), 컴퓨터 저장 매체 또는 장치, 또는 전송되는 신호 파(signal wave)에 영구적으로, 또는 일시적으로 구체화(embody)될 수 있다. 소프트웨어는 네트워크로 연결된 컴퓨터 시스템 상에 분산되어서, 분산된 방법으로 저장되거나 실행될 수도 있다. 소프트웨어 및 데이터는 하나 이상의 컴퓨터 판독 가능 기록 매 체에 저장될 수 있다. 실시예에 따른 방법은 다양한 컴퓨터 수단을 통하여 수행될 수 있는 프로그램 명령 형태로 구현되어 컴퓨터 판 독 가능 매체에 기록될 수 있다. 상기 컴퓨터 판독 가능 매체는 프로그램 명령, 데이터 파일, 데이터 구조 등 을 단독으로 또는 조합하여 포함할 수 있다. 상기 매체에 기록되는 프로그램 명령은 실시예를 위하여 특별히 설계되고 구성된 것들이거나 컴퓨터 소프트웨어 당업자에게 공지되어 사용 가능한 것일 수도 있다. 컴퓨터 판 독 가능 기록 매체의 예에는 하드 디스크, 플로피 디스크 및 자기 테이프와 같은 자기 매체(magnetic media), CD-ROM, DVD와 같은 광기록 매체(optical media), 플롭티컬 디스크(floptical disk)와 같은 자기-광 매체 (magneto-optical media), 및 롬(ROM), 램(RAM), 플래시 메모리 등과 같은 프로그램 명령을 저장하고 수행하도 록 특별히 구성된 하드웨어 장치가 포함된다. 프로그램 명령의 예에는 컴파일러에 의해 만들어지는 것과 같은 기계어 코드뿐만 아니라 인터프리터 등을 사용해서 컴퓨터에 의해서 실행될 수 있는 고급 언어 코드를 포함한다. 상기된 하드웨어 장치는 실시예의 동작을 수행하기 위해 하나 이상의 소프트웨어 모듈로서 작동하도 록 구성될 수 있으며, 그 역도 마찬가지이다."}
{"patent_id": "10-2019-0108213", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "이상과 같이 실시예들이 비록 한정된 도면에 의해 설명되었으나, 해당 기술분야에서 통상의 지식을 가진 자라면 상기의 기재로부터 다양한 수정 및 변형이 가능하다. 예를 들어, 설명된 기술들이 설명된 방법과 다른 순서로 수행되거나, 및/또는 설명된 시스템, 구조, 장치, 회로 등의 구성요소들이 설명된 방법과 다른 형태로 결합 또 는 조합되거나, 다른 구성요소 또는 균등물에 의하여 대치되거나 치환되더라도 적절한 결과가 달성될 수 있다. 그러므로, 다른 구현들, 다른 실시예들 및 특허청구범위와 균등한 것들도 후술하는 특허청구범위의 범위에 속한 다."}
{"patent_id": "10-2019-0108213", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 실시예에 따른 멀티모달 추적기술을 적용한 다중지능 모니터링시스템 및 그 동작 방법의 구성 을 나타내는 모식도를 도시하는 도면이다. 도 2은 본 발명의 실시예에 따른 디지털 동반자 전체 시스템 구성도에서의 모니터링 시스템을 나타내는 모식도 를 도시하는 도면이다. 도 3는 일실시예에 따른 디지털 동반자 모니터링 시스템 구성도을 도시한 것이다. 도 4는 일실시예에 따른 모니터링 서비스 시퀀스 다이어그램을 도시한 것이다. 도 5는 일실시예에 따른 디버깅 서비스 시퀀스 다이어그램을 도시한 것이다. 도 6는 일실시예에 따른 탠서플로우의 예를 도시한 것이다. 도 7는 일실시예에 따른 모니터링 시스템 메이커 및 프레임웍을 도시한 것이다. 도 8는 일실시예에 따른 모니터링 및 디버깅 상세설계를 도시한 것이다. 도 9는 일실시예에 따른 모니터링 및 디버깅 정의 및 스펙을 도시한 것이다. 도 10는 일실시예에 따른 동반자 대화를 도시한 것이다. 도 11은 일실시예에 따른 동반자 대화의 실시간 화면을 도시한 것이다. 도 12은 일실시예에 따른 동반자 대화의 이벤트 리스트를 도시한 것이다. 도 13은 일실시예에 따른 디지털 컴패니온 컨테이너 기반 프레임워크를 도시한 것이다. 도 14은 일실시예에 따른 gRPC 테스트의 python to nodejs를 도시한 것이다.도 15은 일실시예에 따른 nodejs 설치를 도시한 것이다. 도 16은 일실시예에 따른 npm 모듈 설치의 package.json 파일 작성 후 npm install 실행를 도시한 것이다. 도 17은 일실시예에 따른 mongoDB 설치를 도시한 것이다. 도 18은 일실시예에 따른 python관련 grpc 라이브러리 설치를 도시한 것이다. 도 19은 일실시예에 따른 grpc_sender.py의 공통 코드를 도시한 것이다. 도 20은 일실시예에 따른 grpc_inference.py의 main를 도시한 것이다. 도 21은 일실시예에 따른 current_tracking_1.json의 샘플 json 데이터를 도시한 것이다. 도 22은 일실시예에 따른 cam .jpg의 샘플 이미지 데이터를 도시한 것이다. 도 23은 일실시예에 따른 app_grpc.js의 주요 핵심 코드를 도시한 것이다. 도 24은 일실시예에 따른 Receive서버 실행를 도시한 것이다. 도 25은 일실시예에 따른 Send클라이언트 실행를 도시한 것이다. 도 26은 일실시예에 따른 클라이언트 전송 로그를 도시한 것이다. 도 27은 일실시예에 따른 서버 전송 로그를 도시한 것이다. 도 28은 일실시예에 따른 작성한 예제 프로그램 결과 화면를 도시한 것이다. 도 29은 일실시예에 따른 gRPC로 이미지 전송를 도시한 것이다."}
