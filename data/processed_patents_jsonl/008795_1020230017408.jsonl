{"patent_id": "10-2023-0017408", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0074617", "출원번호": "10-2023-0017408", "발명의 명칭": "리소스가 제한된 개인형 이동장치의 비전 기반 군중 계수 장치 및 방법", "출원인": "주식회사 매스아시아", "발명자": "손성욱"}}
{"patent_id": "10-2023-0017408", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "임베디드 플랫폼에서 실행되어 군중 수를 카운트할 수 있도록 학습된 인공지능 모듈;카메라; 및상기 인공지능 모듈을 실행하기 위한 임베디드 플랫폼과 상기 카메라가 탑재되어 있고, 상기 카메라로부터 입력된 군중 이미지를 상기 인공지능 모듈이 처리하여 군중 수를 산출하는 개인형 이동장치를 포함하는 리소스가 제한된 개인형 이동장치의 비전 기반 군중 계수 장치."}
{"patent_id": "10-2023-0017408", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 비전 기반 군중 계수 장치는상기 개인형 이동장치가 산출된 군중 수를 외부로 출력하기 위한 통신부를 더 포함하는 것을 특징으로 하는 리소스가 제한된 개인형 이동장치의 비전 기반 군중 계수 장치."}
{"patent_id": "10-2023-0017408", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항 또는 제2항에 있어서, 상기 인공지능 모듈은입력된 이미지를 슬라이싱하여 소정 수의 패치로 변환하는 슬라이싱부와,상기 패치를 입력받아 크기가 다른 소정 수의 커널을 통해 컨볼루션 연산하여 복수개의 피처 맵을 생성하는 제1계층 컨볼루션 블록과,상기 제1 계층 컨볼루션 블록의 피처 맵을 풀링 연산하는 제1 계층 풀링 블록과,상기 제1 계층 풀링 블록의 출력을 입력받아 크기가 다른 소정 수의 커널을 통해 컨볼루션 연산하여 복수개의피처 맵을 생성하는 제2 계층 컨볼루션 블록과,상기 제2 계층 컨볼루션 블록의 피처 맵을 풀링 연산하는 제2 계층 풀링 블록과,상기 제2 계층 풀링 블록의 출력을 입력받아 크기가 다른 소정 수의 커널을 통해 컨볼루션 연산하여 복수개의슬라이스된 밀도 맵을 생성하는 제3 계층 컨볼루션 블록과,상기 제3 계층 컨볼루션 블록의 슬라이스된 밀도 맵을 1x1 커널로 컨볼루션 연산한 후 하나의 이미지 밀도 맵을생성하는 합성부와,합성된 이미지 밀도 맵의 헤드 수를 카운트하여 군중 수를 산출하는 계수부를 포함하는 것을 특징으로 하는 리소스가 제한된 개인형 이동장치의 비전 기반 군중 계수 장치."}
{"patent_id": "10-2023-0017408", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서, 상기 인공지능 모듈은상기 계수부의 출력에 위치정보를 결합하여 송신 패킷을 생성하는 패킷 생성부를 더 포함하는 것을 특징으로 하는 리소스가 제한된 개인형 이동장치의 비전 기반 군중 계수 장치."}
{"patent_id": "10-2023-0017408", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제3항에 있어서, 상기 커널의 크기는5×5, 7×7, 9×9, 11×11, 13×13, 16×16 중 어느 하나인 것을 특징으로 하는 리소스가 제한된 개인형 이동장치의 비전 기반 군중 계수 장치."}
{"patent_id": "10-2023-0017408", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "공개특허 10-2024-0074617-3-개인형 이동장치의 카메라 뷰 시점에서 학습을 위한 군중 이미지를 수집하는 단계;수집된 군중 이미지에서 사람을 식별하기 위해 라벨 바운딩 박스를 부여하는 레이블링 단계;개인형 이동장치의 임베디드 플랫폼에서 실행할 수 있는 인공지능 모델을 구축하는 단계;레이블링된 학습 데이터로 상기 인공지능 모델을 학습시키는 모델 학습 단계;학습된 인공지능 모델의 파라메터를 양자화시켜 모델 크기를 최소화하는 단계;학습된 인공지능 모델을 개인형 이동장치에 배포하는 단계;학습된 인공지능 모듈이 탑재된 개인형 이동장치가 현장에서 군중 이미지를 촬영하는 현장 이미지 수집 단계;수집된 현장 군중 이미지를 전처리하는 데이터 전처리 단계;전처리된 현장 군중 이미지를 학습된 인공지능 모델에 적용하여 밀도 맵을 생성하는 단계; 및생성된 밀도 맵에서 사람 수를 카운트하는 군중 카운트 단계를 포함하는 리소스가 제한된 개인형 이동장치의 비전 기반 군중 계수 방법."}
{"patent_id": "10-2023-0017408", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6항에 있어서, 상기 비전 기반 군중 계수 방법은카운트된 군중 수 정보와 위치정보를 외부로 전송하는 단계를 더 포함하는 것을 특징으로 하는 리소스가 제한된개인형 이동장치의 비전 기반 군중 계수 방법."}
{"patent_id": "10-2023-0017408", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제6항 또는 제7항에 있어서, 상기 레이블링 단계는수집된 군중 이미지에서 사람 전신에 1차 바운딩 박스를 부여한 후 소정의 방식에 따라 1차 바운딩 박스에서 헤드 위치에 2차 라벨 바운딩 박스를 부여하는 것을 특징으로 하는 리소스가 제한된 개인형 이동장치의 비전 기반군중 계수 방법."}
{"patent_id": "10-2023-0017408", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서, 상기 레이블링 단계는적응형 가우시안 커널 크기(Adaptive Gaussian Kernel Size)를 사용하여 머리의 크기에 따른 변화를 반영하는것을 특징으로 하는 리소스가 제한된 개인형 이동장치의 비전 기반 군중 계수 방법."}
{"patent_id": "10-2023-0017408", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제6항 또는 제7항에 있어서, 상기 인공지능 모델은입력된 군중 이미지가 슬라이싱된 패치들을 입력받아 크기가 다른 소정 수의 커널을 통해 컨볼루션 연산하여 복수개의 피처 맵을 생성하는 제1 계층 컨볼루션 블록과,상기 제1 계층 컨볼루션 블록의 피처 맵을 풀링 연산하는 제1 계층 풀링 블록과,상기 제1 계층 풀링 블록의 출력을 입력받아 크기가 다른 소정 수의 커널을 통해 컨볼루션 연산하여 복수개의피처 맵을 생성하는 제2 계층 컨볼루션 블록과,상기 제2 계층 컨볼루션 블록의 피처 맵을 풀링 연산하는 제2 계층 풀링 블록과,상기 제2 계층 풀링 블록의 출력을 입력받아 크기가 다른 소정 수의 커널을 통해 컨볼루션 연산하여 복수개의슬라이스된 밀도 맵을 생성하는 제3 계층 컨볼루션 블록과,상기 제3 계층 컨볼루션 블록의 슬라이스된 밀도 맵을 1x1 커널로 컨볼루션 연산한 후 하나의 이미지 밀도 맵을생성하는 합성부와,합성된 이미지 밀도 맵의 헤드 수를 카운트하여 군중 수를 산출하는 계수부를 구비하는공개특허 10-2024-0074617-4-딥 뉴럴 네트워크(DNN)인 것을 특징으로 하는 리소스가 제한된 개인형 이동장치의 비전 기반 군중 계수 방법."}
{"patent_id": "10-2023-0017408", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명의 실시예는 리소스가 제한된 개인형 이동장치에서 비전 기반으로 유동인구를 계수하기 위한 장치 및 방 법을 개시한다. 개시된 비전 기반 군중 계수 장치는, 임베디드 플랫폼에서 실행되어 군중 수를 카운트할 수 있도록 학습된 인공 (뒷면에 계속)"}
{"patent_id": "10-2023-0017408", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 도시의 유동인구를 계수하기 위한 장치 및 방법에 관한 것으로, 더욱 상세하게는 리소스가 제한된 개 인형 이동장치에서 비전 기반으로 유동인구를 계수하기 위한 장치 및 방법에 관한 것이다."}
{"patent_id": "10-2023-0017408", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "일반적으로, 도시 유동인구(보행자, 군중 등)는 시민행동을 이해하는 데에 중요한 대표적인 자료이다. 이것은 효율적인 도시 계획 및 관리(예: 대중 교통 계획, 상점 위치 및 거리 보행 가능성)를 용이하게 하는 견고한 기 반을 제공한다. 그러나 대도시의 노상 유동인구 데이터를 확보하기 위해서는 모니터링을 위한 대규모 인프라가 필요하기 때문에 쉽지 않다. 대한민국 특허청 공개특허공보(A)에 공개번호 제10-2019-0099155호로 공개된 \"사람수 카운팅 장치 및 사람수 카 운팅 방법\"(이하 '특허문헌 1'이라 함)에는 탑재된 인공지능(AI) 알고리즘 및 기계학습(machine learning) 알고 리즘을 실행하여 사람수 카운팅을 수행하고 5G 통신 환경에서 사용자 단말기 및 서버와 통신할 수 있는 사람수 카운팅 장치 및 사람수 카운팅 방법이 개시되어 있다. 그런데 특허문헌 1은 스마트 폰과 같은 사용자 단말기를 이용하기 때문에 모바일 네트워크 사업자(MNO)에게 비 용을 지불해야 하고, 보행자와 운전자를 구분하지 않으며, 특정 모바일 네트워크 사업자(MNO)에 가입한 사람만 포함한다는 문제점이 있다. 이러한 문제점을 해결하기 위해 대한민국 특허청 공개특허공보(A)에 공개번호 제10-2022-0056399호로 공개된 \" 확장 합성곱 신경망을 이용한 군중 장면 이미지 실시간 분석 장치 및 방법\"(이하 '특허문헌 2'라 함)은 CCTV나 카메라 등으로부터 수집된 군중 장면 이미지에 엔드 투 엔드(End to End) 확장 합성곱 신경망(Convolutional Neural Network: CNN)을 적용하여 고품질의 실시간 군중 밀도 분포맵을 생성한 후 생성된 실시간 군중 밀도 분 포맵을 기반으로 군중 장면 이미지의 사람 수를 계수하는 것이다. 특허문헌 2는 비전을 기반으로 군중 수를 카운트하기 때문에 특허문헌 1의 문제점을 해결할 수 있으나 확장 합 성곱 신경망 알고리즘을 수행하기 위해서는 학습과정과 추론 과정에서 대량의 자원(Resource)을 필요로 하기 때 문에 리소스가 제한된 개인형 이동장치 등에는 적용할 수 없다는 한계점이 있다. 한편, 최근 들어 시내의 교통량 증가에 따른 교통 체증 등으로 인하여 가까운 거리를 간편하게 이동하기 위한 전기 자전거나 전동 킥보드와 같은 퍼스널 모빌리티 (Personal Mobility) 혹은 라스트 마일 모빌리티(Last Mile Mobility)의 이용이 증가하고 있다. 이러한 퍼스널 모빌리티(PM)는 전기모터 및 배터리를 사용하기 때문에 연료 비가 적게 들고, 친환경적이란 장점과 더불어 1인 가구 증가에 따른 간편한 이동수단에 대한 니즈가 증가하면서 새롭게 주목받고 있다. 특히 이동수단에 대한 관점이 점차 소유에서 이용으로 변화되면서 전동 킥보드와 같이 1 인형 이동수단을 공유하는 퍼스널 모빌리티 공유 서비스(Shared Personal Mobility Service)가 널리 이용되고 있다. 이와 같이 개인형 이동장치 공유 시장이 급속도로 성장하면서, 2025년까지 전 세계 시장 규모는 대략 400억~500 억 달러에 달할 것으로 예상된다. 따라서 널리 보급된 개인형 이동장치를 도시의 유동 인구를 모니터링하는 데 사용할 경우 많은 장점이 있을 것이다. 예컨대, 개인형 이동장치 공유 서비스 시스템은 충전 및 관리에 막대한 비용이 들기 때문에 도시의 유동인구를 정확하게 파악할 수 있다면 공유 서비스 사업자가 개인형 이동장치를 효 율적으로 재배치하여 수익의 극대화를 도모할 수 있고, 부가적으로 유동인구 데이터를 이용한 비지니스도 가능 할 것이다. 선행기술문헌 특허문헌(특허문헌 0001) KR 10-2019-0099155 A (특허문헌 0002) KR 10-2022-0056399 A 비특허문헌 (비특허문헌 0001) M. Sandler and et al. 2018. Inverted Residuals and Linear Bottlenecks: Mobile Networks for Classification, Detection and Segmentation. (비특허문헌 0002) L. Zheng and et al. 2017. Person Re-identification in the Wild. In 2017 IEEE CVPR. 3346-.3355.."}
{"patent_id": "10-2023-0017408", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명이 해결하고자 하는 과제는 리소스가 제한된 전동 스쿠터 등과 같은 개인형 이동장치에서 비전을 기반으 로 인공지능을 적용하여 군중을 정확하게 계수하면서도 통신 및 연산 비용을 최소로 하고, 길거리 촬영에 의한 개인정보 보호 등의 문제를 해결할 수 있는 리소스가 제한된 개인형 이동장치의 비전 기반 군중 계수 장치 및 방법을 제공하는 것이다."}
{"patent_id": "10-2023-0017408", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 일 실시예는 리소스가 제한된 개인형 이동장치의 비전 기반 군중 계수 장치를 개시한다. 개시된 비전 기반 군중 계수 장치는, 임베디드 플랫폼에서 실행되어 군중 수를 카운트할 수 있도록 학습된 인공 지능 모듈과, 카메라와, 상기 인공지능 모듈을 실행하기 위한 임베디드 플랫폼과 상기 카메라가 탑재되어 있고, 상기 카메라로부터 입력된 군중 이미지를 상기 인공지능 모듈이 처리하여 군중 수를 산출하는 개인형 이동장치 를 포함한다. 상기 비전 기반 군중 계수 장치는 상기 개인형 이동장치가 산출된 군중 수를 외부로 출력하기 위한 통신부를 더 포함할 수 있다. 상기 인공지능 모듈은 입력된 이미지를 슬라이싱하여 소정 수의 패치로 변환하는 슬라이싱부와, 상기 패치를 입 력받아 크기가 다른 소정 수의 커널을 통해 컨볼루션 연산하여 복수개의 피처 맵을 생성하는 제1 계층 컨볼루션 블록과, 상기 제1 계층 컨볼루션 블록의 피처 맵을 풀링 연산하는 제1 계층 풀링 블록과, 상기 제1 계층 풀링 블록의 출력을 입력받아 크기가 다른 소정 수의 커널을 통해 컨볼루션 연산하여 복수개의 피처 맵을 생성하는 제2 계층 컨볼루션 블록과, 상기 제2 계층 컨볼루션 블록의 피처 맵을 풀링 연산하는 제2 계층 풀링 블록과, 상 기 제2 계층 풀링 블록의 출력을 입력받아 크기가 다른 소정 수의 커널을 통해 컨볼루션 연산하여 복수개의 슬 라이스된 피처 밀도 맵을 생성하는 제3 계층 컨볼루션 블록과, 상기 제3 계층 컨볼루션 블록의 슬라이스된 밀도 맵을 1x1 커널로 컨볼루션 연산한 후 하나의 이미지 밀도 맵을 생성하는 합성부와, 합성된 이미지 밀도 맵의 헤 드 수를 카운트하여 군중 수를 산출하는 계수부를 포함하는 것이다. 본 발명의 다른 일 실시예는 리소스가 제한된 개인형 이동장치의 비전 기반 군중 계수 방법을 개시한다. 개시된 비전 기반 군중 계수 방법은, 개인형 이동장치의 카메라 뷰 시점에서 학습을 위한 군중 이미지를 수집하 는 단계와, 수집된 군중 이미지에서 사람을 식별하기 위해 라벨 바운딩 박스를 부여하는 레이블링 단계와, 개인 형 이동장치의 임베디드 플랫폼에서 실행할 수 있는 인공지능 모델을 구축하는 단계와, 레이블링된 학습 데이터 로 상기 인공지능 모델을 학습시키는 모델 학습 단계와, 학습된 인공지능 모델의 파라메터를 양자화시켜 모델 크기를 최소화하는 단계와, 학습된 인공지능 모델을 개인형 이동장치에 배포하는 단계와, 학습된 인공지능 모듈 이 탑재된 개인형 이동장치가 현장에서 군중 이미지를 촬영하는 현장 이미지 수집 단계와, 수집된 현장 군중 이 미지를 전처리하는 데이터 전처리 단계와, 전처리된 현장 군중 이미지를 학습된 인공지능 모델에 적용하여 밀도 맵을 생성하는 단계와, 생성된 밀도 맵에서 사람 수를 카운트하는 군중 카운트 단계를 포함한다."}
{"patent_id": "10-2023-0017408", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명의 실시예에 따르면, 널리 배포된 개인형 이동장치를 이용하여 길거리 이미지에서 유동인구 수 정보만 산출한 후 개인형 이동장치의 위치 데이터와 함께 중앙서버로 전송하여 통신비용을 절감함과 아울러 사생활 침 해(길거리 촬영에 의한 개인정보 보호) 문제를 예방할 수 있고, 중앙서버를 활용한 서비스 사업자는 도시 곳곳 에 있는 많은 전동 스쿠터의 정보를 통해 도시 전체의 유동 인구 지도를 도출하여 다양한 서비스를 제공할 수 있다. 예컨대, 본 실시예에 따라 산출된 유동인구 데이터는 다른 비즈니스 또는 연구용으로 사용할 수 있는 유 동 인구 데이터 소스 역할을 할 수 있고, 특히 공유 서비스 사업자는 이 정보를 이용해 개인형 이동장치를 효율 적으로 재배치함으로써 수익의 극대화를 도모할 수 있으며, 부가적으로 유동인구 데이터를 이용한 비지니스도 가능하다. 또한 본 발명의 실시예에 따르면, 가벼운 군중 계수 심층신경망(DNN)을 제안하고 패치 기반 학습 및 추론을 적 용하여 낮은 메모리 사용량으로도 심층신경망(DNN) 기반으로 군중 수를 카운트할 수 있어 개인형 이동장치 외에 다른 다양한 임베디드 시스템에도 적용할 수 있다."}
{"patent_id": "10-2023-0017408", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명과 본 발명의 실시에 의해 달성되는 기술적 과제는 다음에서 설명하는 본 발명의 바람직한 실시예들에 의하여 보다 명확해질 것이다. 다음의 실시예들은 단지 본 발명을 설명하기 위하여 예시된 것에 불과하며, 본 발명의 범위를 제한하기 위한 것은 아니다. 도 1은 본 발명의 실시예에 따라 리소스가 제한된 개인형 이동장치에서 비전 기반으로 유동인구를 계수하기 위 한 방법을 도시한 순서도이고, 도 2는 본 발명의 실시예에 따른 레이블링을 설명하기 위한 사진의 예이며, 도 3 은 본 발명의 실시예에 따른 적응형 가우시안 커널을 설명하기 위한 사진의 예이다. 본 발명의 실시예에서는 설 명의 편의를 위해서 개인형 이동장치로서 전동 스쿠터를 예로들어 설명하기로 한다. 본 발명의 실시예에 따른 리소스가 제한된 개인형 이동장치의 비전 기반 군중 계수 방법은 도 1에 도시된 바와 같이, 크게 인공지능 모델을 학습시키고 테스트하기 위한 군중 이미지 데이터를 수집하는 학습 데이터 수집 과 정(S1)과, 수집된 이미지 데이터를 전처리하고 라벨 바운딩 박스를 부여하는 레이블링 과정(S2), 레이블링된 학 습 데이터를 이용하여 본 발명의 실시예에 따른 인공지능 모델(MicrowdNet)을 학습시키는 학습과정(S3~S5), 학 습된 인공지능 모델(MicrowdNet)을 개인형 이동장치에 배포하여 현장의 군중을 실제 카운트하는 모델 운영과정 (S6~S12)으로 구분된다. 도 1을 참조하면, 학습 데이터 수집 과정(S1)에서는 실제 전동 스쿠터가 근처 거리를 찍은 사진을 수집하거나 전동 스쿠터 뷰 시점에서 거리를 촬영한 사진을 수집한다. 본 발명의 실시예에 사용되는 군중 이미지는 공중에서 촬영된 이미지(조감도 이미지)와 달리 전동 스쿠터의 시점에서 촬영된 이미지이므로 인간 눈의 시점과 유사 하고, 밀집된 군중보다는 대략 20명 이내의 보행자 등을 대상으로 군중 이미지를 수집하는 것이 바람직하다. 레이블링 과정(S2)에서는 수집된 군중 이미지에 대한 실측 밀도 맵을 생성할 수 있도록 각 사람의 머리 위치를 감지하고 중심점에 적응형 가우시안 커널을 적용한다. 이를 위해 본 발명의 실시예에서는 도 2에 도시된 사진과 같이 이미지 속 사람의 전신에 1차로 바운딩 박스를 설정한 후 사람이 포함된 각 바운딩 박스에 대해 위에서부 터 높이가 1/10인 수평 중심점을 머리의 중심 지점으로 레이블링한다. 통계에서 따르면, 인간의 머리는 전체 높 이의 약 1/10, 전체 너비의 중간에 위치하는 것으로 알려져 있다. 또한 군중 계산 작업에서 중요한 문제 중 하나는 머리 크기의 변화인데, 서로 다른 머리 크기에 대해 고정된 가 우시안 커널을 사용하면 성능에 해로울 수 있다. 이는 DNN이 훈련을 통해 머리의 크기 변화를 캡처하는 반면 고 정 가우시안 커널은 각 머리의 크기에 대한 정보를 가지고 있지 않기 때문이다. 이 문제를 해결하려면 각 머리 의 커널 너비가 머리 크기에 비례해야 한다. 비지도 군집화를 사용하여 머리 크기를 추정하는 이전 방식과 달리 본 발명의 실시예에서는 도 3에 도시된 바와 같이 적응형 가우시안 커널 크기를 적용하여 이를 해결한다. 즉, 통계에 따르면, 사람의 머리 너비가 몸 너비의 약 1/2∼1/3이라는 것이 알려져 있으므로, 본 발명의 실시예에서 는 전체 신체에 대한 바운딩 박스 레이블을 사용하여 머리 크기를 추정한다. 도 3의 (a)는 밀도 맵(Density Maps)을 생성하기 위한 입력 이미지의 예이고, (b)는 고정 가우시안 커널(fixed Gaussian kernel)을 적용하여 생성된 밀도 맵의 예이며, (c)는 적응형 가우시안 커널(adaptive Gaussian kernel)을 적용하여 생성된 밀도 맵의 예이다. 도 3을 참조하면, 도 3의 (a)와 같은 동일한 입력 이미지에 대해 고정 커널 크기를 적용할 경우에는 도 3의 (b)와 같이 머리의 크기를 구분할 수 없으나 적응형 커널 크기를 적 용한 경우에는 도 3의 (c)와 같이 머리 크기가 반영되는 것을 알 수 있다. 즉, 본 발명의 실시예에 따르면, 밀 도 맵의 원이 입력 이미지의 실제 머리 크기를 올바르게 나타내는 것을 알 수 있다. 이와 같이 각 이미지에 대해 레이블을 다시 지정한 후 입력 이미지는 많은 IoT 카메라가 지원하는 640×480 해 상도로 크기가 조정되고, 밀도 맵도 본 발명의 실시예에서는 160×120 해상도로 크기가 조정된다. 다시 도 1을 참조하면, 임베디드용 인공지능 모델 구축 단계(S3)에서는 전동 스쿠터에 탑재된 임베디드 플랫폼 과 같이 리소스가 제한된 임베디드 플랫폼에 심층 신경망(DNN)을 적용할 수 있도록 간단한 아키텍처의 인공지능 모델을 선택한다. 본 발명의 실시예에서는 나중에 자세히 살펴보는 바와 같이 전동 스쿠터의 MCU에서 실행할 수 있는 아주 가벼운 심층 신경망(DNN) 구조(MiCrowdNet)를 제안한다. 모델 학습 단계(S4)에서는 레이블링된 학습 데이터로 구축된 인공지능 모델을 학습시킨다. 본 발명의 실시예에 서는 텐서플로우 라이트(TensorFlow Lite)를 이용하여 인공지능 모델을 구축하고 컴파일링한 후 학습 데이터를 피팅시켜 인공지능 모델을 학습시킨다. 모델 학습과정에는 검증 절차와 테스트 데이터에 의한 테스트 절차가 포 함된다. 이어 양자화 단계(S5)에서는 학습된 인공지능 모델의 파라메터를 8비트 정수로 양자화시켜 모델 크기를 최소화 함으로써 전동 스쿠터의 MCU에서 실행될 수 있게 한다. 이와 같이 인공지능 모델에 대한 학습이 완료되면, 모델 배포단계(S6)에서 학습된 인공지능 모델을 전동 스쿠터 와 같은 개인형 이동장치에 배포하여 개인형 이동장치의 MCU로 추론할 수 있게 한다. 배포 방식으로는 전동 스 쿠터 제조 과정이나 유지보수 단계에서 오프라인 업그레이드 방식으로 전동 스쿠터의 임베디드 플랫폼에 탑재할 수도 있고, 서버에서 통신망을 통해 연결된 전동 스쿠터에 온라인 방식으로 배포할 수도 있다. 이후 학습된 인공지능 모델이 탑재된 개인형 이동장치는 군중 계수 기능이 온되어 있으면 정해진 주기나 수신된 명령에 따라 카메라로 주변의 길거리를 촬영하여 현장 이미지를 수집하고, 수집된 이미지 데이터를 전처리한 후 학습된 인공지능 모델에 적용하여 밀도 맵을 생성한다(S7~S10). 그리고 군중 카운트 단계(S11)에서는 생성된 밀도 맵에서 사람 수(헤드 수)를 카운트하고, 전송 단계(S12)에서 는 사람 수 정보와 개인형 이동장치의 위치정보 등을 결합하여 송신 패킷을 형성한 후 통신망을 통해 서버측으 로 전송한다. 도 4는 본 발명의 실시예에 따른 리소스가 제한된 개인형 이동장치의 비전 기반 군중 계수 장치를 도시한 개략 도이고, 도 5는 도 4에 도시된 MiCrowdNet의 아키텍처를 도시한 개략도이며, 도 6은 도 5에 사용된 MV2 블록의 구조를 도시한 개략도이다. 본 발명의 실시예에 따라 전동 스쿠터를 이용하여 유동 인구를 측정하기 위한 비전 기반 온디바이스 군중 계수 시스템(이하 'MiCrowd'라 한다; 100)은 도 4에 도시된 바와 같이, 카메라, GPS 모듈, 데이터 전처리부 , 학습된 심층 신경망 모델인 MicrowdNet, 계수부, 패킷 생성부, 무선통신부를 포함 하고, 전동 스쿠터(도 7의 10)에 탑재되어 있다. 데이터 전처리부와, MicrowdNet, 계수부, 및 패킷 생성부는 개인형 이동장치의 임베디드 플랫폼 상에 구현될 수 있다. 도 4를 참조하면, 카메라는 전동 스쿠터에 탑재되어 운행중이나 주차중에 길거리 주변을 촬영하여 군중 이 미지를 수집하기 위한 것으로, 640×480 해상도 등 다양한 해상도로 촬영할 수 있다. GPS 모듈은 GPS 위성으로부터 GPS 신호를 수신하여 위치 정보를 제공한다. 데이터 전처리부는 카메라로부터 입력된 이미지를 심층 신경망 모델의 추론에 사용할 수 있도록 전처 리하고, MicrowdNet은 리소스가 제한된 임베디드 플랫폼에 심층 신경망(DNN)을 적용하여 MCU에서 추론할 수 있을 만큼 가벼운 MiCrowd용 심층 신경망이다. 본 발명의 실시예에 따른 MicrowdNet은 도 5에 도시된 바와 같이, 입력 이미지를 슬라이싱(slicing)하여 다수의 패치(patch)로 분할하는 슬라이싱부와, 4개의 모바일넷(MV2) 블록(122-1~122-4)으로 이루어진 제1 계층 컨볼루션 블록, 4개의 풀링 블록으로 이루어진 제1 계층 풀링 블록, 4개의 모바일넷(MV2) 블록 (124-1~124-4)으로 이루어진 제2 계층 컨볼루션 블록, 4개의 풀링 블록으로 이루어진 제2 계층 풀링 블록 , 4개의 모바일넷(MV2) 블록(126-1~126-4)으로 이루어진 제3 계층 컨볼루션 블록, 포인트와이즈 컨볼 루션 블록, 슬라이스된 패치 밀도 맵을 하나의 이미지 밀도 맵으로 합성하는 합성부로 구성된다. 도 5를 참조하면, 슬라이싱부는 카메라로부터 입력된 640×480 해상도의 이미지를 서로 겹치지 않는 64×64 해상도의 부분 이미지로 슬라이싱하여 80개의 패치로 분할한다. 이와 같이 입력 이미지를 패치로 분할함 으로써 입력 크기를 최소화 하여 전동 스쿠터의 MCU에서 실행할 수 있게 된다. 제1 계층 컨볼루션 블록은 패치를 입력받아 크기가 다른 소정 수의 커널을 통해 컨볼루션 연산하여 복수개 의 피처 맵을 생성하는 것으로서, 본 발명의 실시예에서는 서로 병렬로 연결된 16×16 커널, 12채널의 MV2 블록 (122-1), 13×13 커널, 12채널의 MV2 블록(122-2), 9×9 커널, 16채널의 MV2 블록(122-3), 7×7 커널, 20채널 의 MV2 블록(122-4)으로 구성된다. 여기서, MV2 블록은 모델을 경량화하기 위해 Depthwise separable convolution를 활용한 MobileNet을 개량한 모바일넷버전2( MobileNetV2) 블록으로서, n(커널 크기),k(채널), MV2 블록은 도 6에 도시된 바와 같이 1×1, 3k 컨볼루션 블록과 n×n Depthwise 컨볼루션 블록, 1x1, k 컨볼루 션 블록의 출력에 입력을 다시 더해 출력하는 구조로 되어 있다(비특허문헌 1 참조). 제1 계층 풀링 블록은 본 발명의 실시예에서는 최대값 연산을 하는 4개의 Max 풀링 블록으로 구성되어 제1 계층 컨볼루션 블록의 피처 맵을 풀링 연산한다. 제2 계층 컨볼루션 블록은 제1 계층 풀링 블록의 출력을 각각 입력받아 크기가 다른 소정 수의 커널 을 통해 컨볼루션 연산하여 복수개의 피처 맵을 생성하는 것으로서, 본 발명의 실시예에서는 서로 병렬로 연결 된 13×13 커널, 24채널의 MV2 블록(124-1), 11×11 커널, 24채널의 MV2 블록(124-2), 7×7 커널, 32채널의 MV2 블록(124-3), 5×5 커널, 40채널의 MV2 블록(124-4)으로 구성된다. 여기서, MV2 블록은 모델을 경량화하기 위해 Depthwise separable convolution를 활용한 MobileNet을 개량한 모바일넷버전2( MobileNetV2) 블록으로서, 앞서 설명한 바와 동일한 것이다. 제2 계층 풀링 블록은 본 발명의 실시예에서는 최대값 연산을 하는 4개의 Max 풀링 블록으로 구성되어 제2 계층 컨볼루션 블록의 피처 맵을 풀링 연산한다. 제3 계층 컨볼루션 블록은 제2 계층 풀링 블록의 출력을 각각 입력받아 크기가 다른 소정 수의 커널 을 통해 컨볼루션 연산하여 슬라이스된 피처 밀도 맵을 생성하는 것으로서, 본 발명의 실시예에서는 서로 병렬 로 연결된 13×13 커널, 6채널의 MV2 블록(126-1), 11×11 커널, 6채널의 MV2 블록(126-2), 7×7 커널, 8채널 의 MV2 블록(126-3), 5×5 커널, 10채널의 MV2 블록(126-4)으로 구성된다. 포인트와이즈 컨볼루션 블록은 제3 계층 컨볼루션 블록의 슬라이스된 밀도 맵을 1x1 커널로 컨볼루션 연산하여 하나의 이미지 밀도 맵을 생성하는 합성부 역할을 한다. 다시 도 4를 참조하면, 계수부는 합성된 이미지 밀도 맵의 헤드 수를 카운트하여 군중 수를 산출하고, 패 킷 생성부는 계수부의 군중 수에 GPS모듈로부터 입력받은 위치정보를 결합하여 송신 패킷을 생성 하며, 무선 통신부는 개인형 이동장치가 산출한 군중 수와 위치정보 등을 서버측으로 출력하거나 서버 로부터 명령을 수신하여 인공지능 모델 등을 업데이트하기 위한 것이다. 무선통신부는 WiFi, 블루투스,LoRa, Zigbee, NB-IoT, LTE-M 등과 같은 알려진 다양한 통신 프로토콜로 구현될 수 있다. 도 7은 본 발명의 실시예를 이용한 서비스 시스템의 예를 도시한 개략도이다. 도 7을 참조하면, 도시지역 등에 분산 배치된 각 전동 스쿠터들(10-1~10-N)은 카메라와 GPS모듈, 각종 센서들 및 본 발명의 실시예에 따른 학습된 심층신경망(DNN) 모델이 탑재된 임배디드 플랫폼을 구비하고 있고, 주차중에 카메라로 길거리 주변을 촬영한 후 군중 이미지에서 군중 수를 산출하여 통신망을 통해 서비 스 서버로 전송한다. 서비스 서버는 개인형 이동장치 공유 서비스 사업자나 지방 자치단체 등에서 운영 할 수 있는 시스템으로, 분산된 전동 스쿠터(10-1~10-N)로부터 위치와 군중 수 정보를 시간대별로 입력받아 도 시지역 전체의 유동인구 수를 파악할 수 있도록 현황판에 그래픽 등으로 표시하거나 유동인구 수에 기반한 다양 한 서비스를 제공할 수 있다. 한편, 전동 스쿠터(10-1~10-N)는 보행자에게 방해가 되지 않도록 지정된 장소에 주차하는 것이 보편화되었다. 같은 장소에 있는 전동 스쿠터(10-1~10-N)에서 사람 수를 세는 것이 비슷하다면 이러한 모든 전동 스쿠터에서 MiCrowdNet을 실행하는 것은 중복될 수 있다. 본 발명의 실시예에서는 이러한 문제를 해결하기 위해 GPS 정보를 사용하여 전동 스쿠터(10-1~10-N)를 클러스터링할 수 있으며, 클러스터의 대표 전동 스쿠터만 MiCrowdNet을 실 행하여 통신 비용을 줄이고 배터리 수명을 절약할 수 있다. 클러스터 리더(대표)는 MiCrowdNet을 병렬로 실행하 기 위해 일부 패치를 클러스터 구성원에게 오프로드할 수도 있다. 그렇지 않으면 인접한 전동 스쿠터가 다른 사 람 수를 보고하는 경우 카메라 각도가 다른 여러 클러스터 구성원을 선택하여 정확도를 높일 수도 있다. 그리고 전동 스쿠터(10-1~10-N)가 임의의 카메라 각도로 주차되거나 예기치 않은 충돌 후 땅에 떨어지면 카메라 가 이상적인 이미지를 수집할 수 없다. 본 발명의 실시예에 따른 전동 스쿠터(10-1~10-N)는 자이로스코프를 사용하여 카메라 각도를 분석하고, 부적절한 이미지 처리를 건너뛰어 중복 계산을 완화함으로써 이러한 이상 현 상을 감지할 수 있다. [시험 예] 도 8은 본 발명의 실시예를 테스트하기 위한 테스트베드(Testbed)를 도시한 개략도이고, 도 9는 본 시험 예에 의한 밀도 맵의 예를 도시한 사진이다. 먼저, 본 시험 예에서는 학습 및 테스트 데이터로서 PRW(Person Re-identification in the Wild) 데이터 세트 (비특허문헌 2 참조)를 사용하고, 임베디드 플랫폼의 경우 240MHz 클록, 512kB SRAM 및 4MB 플래시가 있는 ESP32-S3를 사용한다. 본 시험 예에 사용되는 심층신경망인 MicrowNet은 TensorFlow Lite에서 구현된 것이다. On-MCU 추론을 위한 본 시험 예의 테스트베드(Testbed)는 도 8에 도시된 바와 같이, 서버와 MCU가 무선으로 연 결되어 있다. 즉, MCU는 전체 테스트 데이터 세트를 로컬에 저장할 수 없기 때문에 서버가 테스트 데이터 세트 를 저장하고 추론을 위해 이미지를 하나씩 MCU로 보내는 구조로 구현한다. 도 8을 참조하면, 테스트베드는 각 테스트 이미지에 대해 다음과 같은 동작을 수행한다. 서버는 테스트 이미지를 무선(Wi-Fi)으로 MCU에 전송하고(①), MCU는 이미지를 더 작은 패치로 나눈다(②). 이 어 MCU는 각 패치를 메모리에 로드하고 MiCrowdNet을 이용하여 추론을 수행한 후(③), 모든 패치에 대한 추론 결과를 누적하여 전체 이미지에 대한 결과를 생성한다(④). 이후 MCU는 이미지에 대한 최종 결과를 서버에 무선 으로 전송하고(⑤), 서버는 이미지에 대한 예측 결과를 평가한다. PRW 데이터 세트에서 훈련용으로 5,704개의 이미지를 사용하고, 테스트용으로 6,112개의 이미지를 사용한다. MAE(평균 절대 오차)를 정확도 메트릭으로 사용하여 예측 값이 실측값에 얼마나 가까운지 직관적으로 알려준다. 예를 들어, 모델의 MAE가 1인 경우 모델의 예측 값은 평균적으로 1만큼 벗어난다. 본 시험 예에서는 MiCrowdNet을 기존 군중 계수 모델과 비교하기 위해 CSRNet, P2PNet 및 MCNN을 비교 예로 선 택한다. 비교 예들도 모두 64×64 패치 기반 추론을 위해 PRW에서 훈련되었다. 다음 표 1은 시험 예에 따른 매개변수 수, 모델 크기 및 MAE 측면에서 결과를 보여준다. 표 1"}
{"patent_id": "10-2023-0017408", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "상기 표 1은 PRW 데이터 세트에서 다양한 군중 계수 DNN의 성능을 나타낸 것으로서, 표 1의 각 모델은 640×480 이미지의 64×64 패치를 사용하여 훈련 및 테스트된 것이다. 표 1에서 보는 바와 같이 MiCrowdNet은 다른 비교 예들에 비해 크기가 훨씬 더 작으며 가장 무거운 P2PNet보다 600배 더 작고, 가장 가벼운 MCNN보다 4배 더 작은 것을 알 수 있다. 이 소형 아키텍처를 통해 MiCrowdNet은 MCNN보다 29% 더 정확하고 훨씬 더 무거운 다른 모델(P2PNet 및 CSRNet)과 비교할 수 있는 1.12 MAE를 제공한다. 이는 MCNN, MobileNetV2 블록 및 양자화보다 커널이 하나 더 많고 계층이 하나 더 적은 MiCrowdNet에 대한 설계 선택의 효율성을 확인할 수 있다. 도 9의 MiCrowdNet에 대한 정성적 분석에서도 MiCrowdNet이 사람을 감지하고 밀도 맵을 정확하게 생성할 수 있음을 보여준다. 도 9를 참조하면, MiCrowdNet의 정성 분석에 따르면, MiCrowdNet은 첫 번째 행의 군중 이미지에서 두 번째 행의 밀도 맵을 정확하게 생성하는 것을 알 수 있다. 또한 본 시험 예에서는 패치 크기에 따른 영향을 분석하기 위해 다음 표 2와 같이 패치 사이즈를 달리한 경우의 모델 간 성능을 비교하였다. 표 2"}
{"patent_id": "10-2023-0017408", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "상기 표 2는 패치 크기가 MiCrowdNet 성능에 미치는 영향을 나타낸 것으로,다양한 패치 크기에 따른 MiCrowdNet 의 메모리 요구 사항 및 추론 시간을 보여준다. 표 2에서 OOM은 메모리 부족을 나타내며, MAE는 여전히 서버에 서 계산하여 보고된 것을 알 수 있다. 본 발명의 실시예에서 전체 640×480 이미지를 사용하려면 ESP32-S3의 메모리 제약을 훨씬 초과하는 약 10MB의 메모리가 필요하다. 따라서 MCU에서 MiCrowdNet을 실행하려면 패치 기반 추론이 필수적임을 확인할 수 있다. 또 한 표 2는 입력 크기가 클수록 각 패치에 대한 추론이 느려지고 피크 메모리가 커짐을 보여준다. 반면 입력 크 기가 너무 작으면 성능이 심각하게 저하될 수 있다. 본 발명의 실시예에서는 이러한 장단점을 고려하여 앞서 설 명한 바와 같이 MiCrowdNet에 대해 64 × 64의 패치 크기를 선택한다. 한편, 본 시험 예에서는 카메라 시점의 영향을 분석하기 위하여 전동 스쿠터(E-scooter) 뷰(view)를 반영한 데 이터 셋의 중요도를 평가한다. 본 시험 예에서 상공에서의 뷰(high-place view; 조감도 뷰)로는 군중 계수을 위 한 대중적인 데이터 세트인 ShanghaiTech와 군중 계수를 위한 무거운 DNN인 CSRNet을 사용한다. ShanghaiTech 의 경우는 학습용으로 400개 이미지를 사용하고 테스트용으로 316개 이미지를 사용한다. 이 시험 예에서는 정확도에만 초점을 맞추기 때문에 모델은 전체 해상도 이미지에서 학습 및 테스트된다. 다음 표 3은 본 시험 예에서 영역 이동의 영향을 보여주는 다양한 테스트 및 학습 데이터 세트를 사용한 평가 결과(MAE)를 나타낸 것이다. 표 3"}
{"patent_id": "10-2023-0017408", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "상기 표 2를 참조하면, MiCrowdNet과 CSRNet이 데이터 세트에서 학습하고 다른 데이터 세트에서 테스트할 때 상 당한 성능 저하가 있는 것을 보여준다. CSRNet은 480배 더 무겁고 훨씬 더 많은 지식(knowledge)을 포함할 수 있지만 테스트 시간에 데이터 도메인이 이동하면 해당 조감도에서 학습으로 얻은 지식은 쓸모가 없게 된다. 반 면에 레이블이 재지정된 PRW에서 학습을 받으면 MAE는 100배 이상 감소한다. 이것은 카메라 시점이 중요하다는 것을 보여준다. 다른 시점은 모델 아키텍처에 관계없이 테스트 정확도에 영향을 미치는 상당한 데이터 도메인 이동을 유발한다."}
{"patent_id": "10-2023-0017408", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "이상에서 본 발명은 도면에 도시된 일 실시예를 참고로 설명되었으나, 본 기술분야의 통상의 지식을 가진 자라 면 이로부터 다양한 변형 및 균등한 타 실시예가 가능하다는 점을 이해할 것이다."}
{"patent_id": "10-2023-0017408", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 실시예에 따른 리소스가 제한된 개인형 이동장치의 비전 기반 군중 계수 방법을 도시한 순서 도, 도 2는 본 발명의 실시예에 따른 레이블링을 설명하기 위한 사진의 예, 도 3은 본 발명의 실시예에 따른 적응형 가우시안 커널을 설명하기 위한 사진의 예, 도 4는 본 발명의 실시예에 따른 리소스가 제한된 개인형 이동장치의 비전 기반 군중 계수 장치를 도시한 개략 도, 도 5는 도 4에 도시된 MiCrowdNet의 아키텍처를 도시한 개략도, 도 6은 도 5에 사용된 MV2 블록의 구조를 도시한 개략도, 도 7은 본 발명의 실시예를 이용한 서비스 시스템의 예를 도시한 개략도, 도 8은 본 발명의 실시예를 테스트하기 위한 시험 구성을 도시한 개략도, 도 9는 본 발명의 시험 구성에 의한 밀도 맵의 예를 도시한 사진이다."}
