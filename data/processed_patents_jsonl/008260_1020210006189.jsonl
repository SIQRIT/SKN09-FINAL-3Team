{"patent_id": "10-2021-0006189", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2022-0103506", "출원번호": "10-2021-0006189", "발명의 명칭": "딥러닝 기반 자동 대흉근 측정 장치 및 그 방법을 실행하기 위한 프로그램이 기록된 기록매체", "출원인": "고려대학교 산학협력단", "발명자": "양제파"}}
{"patent_id": "10-2021-0006189", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "분류화 인공지능 모델에 의해, 대상체에 대해 획득된 제1 흉부 전산화 단층촬영(CT) 영상의 제1 관상면 영상으로부터 대흉근이 존재하는 제1 수평면 영상들을 판별하도록 구성되는 대흉근 존재 영역 판별부; 및분할 인공지능 모델에 의해, 대흉근이 존재하는 것으로 판별된 제1 수평면 영상들에서 특징들을 추출하는 영역분할을 통해 대흉근의 영역을 분할하도록 구성되는 대흉근 영역 분할부;를 포함하는, 딥러닝 기반 자동 대흉근측정 장치."}
{"patent_id": "10-2021-0006189", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,제2 흉부 CT 영상의 제2 관상면 영상에 대흉근 존재 영역이 라벨링된 제1 학습 영상을 이용하여 상기 분류화 인공지능 모델을 학습시키도록 구성되는 분류화 인공지능 모델 학습부; 및상기 제2 흉부 CT 영상의 제2 수평면 영상에 대흉근 영역이 라벨링된 제2 학습 영상을 이용하여 상기 분할 인공지능 모델을 학습시키도록 구성되는 분할 인공지능 모델 학습부;를 더 포함하는, 딥러닝 기반 자동 대흉근 측정장치."}
{"patent_id": "10-2021-0006189", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,상기 대흉근 존재 영역 판별부는:상기 제1 흉부 CT 영상으로부터 컬러 합성 처리된 상기 제1 관상면 영상을 획득하고, 상기 분류화 인공지능 모델 학습부에 의해 학습된 상기 분류화 인공지능 모델을 이용하여 상기 제1 관상면 영상 내 대흉근 존재 영역을예측하여 상기 제1 흉부 CT 영상의 복수의 수평면 영상들 중 상기 제1 수평면 영상들을 추출하도록 구성되는,딥러닝 기반 자동 대흉근 측정 장치."}
{"patent_id": "10-2021-0006189", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서,상기 대흉근 존재 영역 판별부는:상기 제1 흉부 CT 영상의 적층된 관상면 영상들 중에서 적층 순번을 기준으로 중간 부분에 해당하는 관상면 위치들을 확인하고;상기 관상면 영상들 중에서 상기 관상면 위치들에 해당하는 복수의 회색조 관상면 영상들을 추출하고;상기 복수의 회색조 관상면 영상들을 하나로 합성하여 컬러 관상면 영상을 획득하고;상기 컬러 관상면 영상을 설정된 길이로 맞추어 상기 제1 관상면 영상을 획득하고; 그리고상기 제1 관상면 영상으로부터 상기 분류화 인공지능 모델에 의해 상기 제1 수평면 영상들을 판별하도록 구성되는, 딥러닝 기반 자동 대흉근 측정 장치."}
{"patent_id": "10-2021-0006189", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서,상기 복수의 회색조 관상면 영상들은 상기 제2 관상면 영상들의 적층 순번을 기준으로, 3/8, 4/8 및 5/8의 관상면 위치들에 해당하는 제2 관상면 영상들을 포함하는, 딥러닝 기반 자동 대흉근 측정 장치.공개특허 10-2022-0103506-3-청구항 6 제2항에 있어서,상기 대흉근 영역 분할부는:상기 분할 인공지능 모델 학습부에 의해 학습된 상기 분할 인공지능 모델을 이용하여 대흉근 예측 영상을 생성하고; 그리고상기 대흉근 예측 영역에서 노이즈에 해당하는 미소 영역들을 제외하여 상기 대흉근의 영역을 분할하도록 구성되는, 딥러닝 기반 자동 대흉근 측정 장치."}
{"patent_id": "10-2021-0006189", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6항에 있어서,상기 대흉근 영역 분할부는:상기 대흉근 예측 영상을 이진화 처리하여 설정된 픽셀값을 가지는 이진화 영상을 생성하고;상기 이진화 영상에서 인접한 픽셀들을 연결하여 그룹핑하여 상기 이진화 영상을 다수의 영역들로 분할하고; 그리고상기 다수의 영역들의 넓이를 각각 산출하고, 넓이가 기준값 이하인 영역을 제외하여 대흉근을 측정하도록 구성되는, 딥러닝 기반 자동 대흉근 측정 장치."}
{"patent_id": "10-2021-0006189", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1항에 있어서,상기 분류화 인공지능 모델은 에피션트넷(EfficientNet) 모델을 기반으로 완전연결층이 추가되어 구현되고,상기 분할 인공지능 모델은:제1 컨볼루션 처리 및 풀링 처리를 복수의 컨트랙팅 레이어를 통해 순차적으로 반복하여 수행하도록 구성되는컨트랙팅 패스;제2 컨볼루션 처리 및 업 샘플링 처리를 복수의 익스펜딩 레이어를 통해 순차적으로 반복하여 수행하도록 구성되는 익스펜시브 패스; 및상기 컨트랙팅 패스에서 추출된 제1 특징 맵을 상기 익스펜시브 패스로 전달하도록 구성되는 스킵 커넥션부;를포함하고,상기 익스펜시브 패스는 상기 복수의 익스펜딩 레이어에 각각 적용되는 어텐션 모듈을 포함하고,상기 어텐션 모듈은:상기 스킵 커넥션부에 의해 상기 컨트랙팅 패스의 컨트랙팅 레이어로부터 상기 제1 특징 맵을 전달받고;상기 익스펜시브 패스의 제1 익스펜딩 레이어로부터 제2 특징 맵을 전달받고;상기 제1 특징 맵과 상기 제2 특징 맵을 기반으로 제3 컨볼루션 처리, 렐루 활성화 처리, 및 시그모이드 처리를수행하여 어텐션 맵을 생성하고; 그리고상기 어텐션 맵을 상기 익스펜시브 패스의 제2 익스펜딩 레이어로 전달하도록 구성되는, 딥러닝 기반 자동 대흉근 측정 장치."}
{"patent_id": "10-2021-0006189", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "딥러닝 기반 자동 대흉근 측정 방법을 실행하기 위한 프로그램이 기록된 컴퓨터로 판독 가능한 기록 매체로서,상기 딥러닝 기반 자동 대흉근 측정 방법은:분류화 인공지능 모델에 의해, 대상체에 대해 획득된 제1 흉부 전산화 단층촬영(CT) 영상의 제1 관상면 영상으로부터 대흉근이 존재하는 제1 수평면 영상들을 판별하는 단계; 및공개특허 10-2022-0103506-4-분할 인공지능 모델에 의해, 대흉근이 존재하는 것으로 판별된 제1 수평면 영상들에서 특징들을 추출하는 영역분할을 통해 대흉근의 영역을 분할하는 단계;를 포함하는, 컴퓨터로 판독 가능한 기록 매체."}
{"patent_id": "10-2021-0006189", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9항에 있어서,상기 딥러닝 기반 자동 대흉근 측정 방법은:분류화 인공지능 모델 학습부에 의해, 제2 흉부 CT 영상의 제2 관상면 영상에 대흉근 존재 영역이 라벨링된 제1학습 영상을 이용하여 상기 분류화 인공지능 모델을 학습시키는 단계; 및분할 인공지능 모델 학습부에 의해, 상기 제2 흉부 CT 영상의 제2 수평면 영상에 대흉근 영역이 라벨링된 제2학습 영상을 이용하여 상기 분할 인공지능 모델을 학습시키는 단계;를 더 포함하는, 컴퓨터로 판독 가능한 기록매체."}
{"patent_id": "10-2021-0006189", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제10항에 있어서,상기 제1 수평면 영상들을 판별하는 단계는:상기 제1 흉부 CT 영상으로부터 컬러 합성 처리된 상기 제1 관상면 영상을 획득하고, 상기 분류화 인공지능 모델 학습부에 의해 학습된 상기 분류화 인공지능 모델을 이용하여 상기 제1 관상면 영상 내 대흉근 존재 영역을예측하여 상기 제1 흉부 CT 영상의 복수의 수평면 영상들 중 상기 제1 수평면 영상들을 추출하는 단계를 포함하는, 컴퓨터로 판독 가능한 기록 매체."}
{"patent_id": "10-2021-0006189", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항에 있어서,상기 제1 수평면 영상들을 판별하는 단계는:상기 제1 흉부 CT 영상의 적층된 관상면 영상들 중에서 적층 순번을 기준으로 중간 부분에 해당하는 관상면 위치들을 확인하는 단계;상기 관상면 영상들 중에서 상기 관상면 위치들에 해당하는 복수의 회색조 관상면 영상들을 추출하는 단계;상기 복수의 회색조 관상면 영상들을 하나로 합성하여 컬러 관상면 영상을 획득하는 단계;상기 컬러 관상면 영상을 설정된 길이로 맞추어 상기 제1 관상면 영상을 획득하는 단계; 및상기 제1 관상면 영상으로부터 상기 분류화 인공지능 모델에 의해 상기 제1 수평면 영상들을 판별하는 단계를포함하는, 컴퓨터로 판독 가능한 기록 매체."}
{"patent_id": "10-2021-0006189", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제10항에 있어서,상기 대흉근의 영역을 분할하는 단계는:상기 분할 인공지능 모델 학습부에 의해 학습된 상기 분할 인공지능 모델을 이용하여 대흉근 예측 영상을 생성하는 단계; 및상기 대흉근 예측 영역에서 노이즈에 해당하는 미소 영역들을 제외하여 상기 대흉근의 영역을 분할하는 단계를포함하는, 컴퓨터로 판독 가능한 기록 매체."}
{"patent_id": "10-2021-0006189", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제13항에 있어서,상기 대흉근의 영역을 분할하는 단계는:상기 대흉근 예측 영상을 이진화 처리하여 설정된 픽셀값을 가지는 이진화 영상을 생성하는 단계;공개특허 10-2022-0103506-5-상기 이진화 영상에서 인접한 픽셀들을 연결하여 그룹핑하여 상기 이진화 영상을 다수의 영역들로 분할하는 단계; 및상기 다수의 영역들의 넓이를 각각 산출하고, 넓이가 기준값 이하인 영역을 제외하여 대흉근을 측정하는 단계를포함하는, 컴퓨터로 판독 가능한 기록 매체."}
{"patent_id": "10-2021-0006189", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "흉부 CT 영상을 이용하여 딥러닝 기법을 활용하여 대흉근 영역에 대한 자동 측정을 수행하는 딥러닝 기반 자동 대흉근 측정 장치 및 그 방법을 실행하기 위한 프로그램이 기록된 기록매체가 개시된다. 본 발명의 실시예에 따 른 딥러닝 기반 자동 대흉근 측정 장치는: 분류화 인공지능 모델에 의해, 대상체에 대해 획득된 제1 흉부 전산화 단층촬영(CT) 영상의 제1 관상면 영상으로부터 대흉근이 존재하는 제1 수평면 영상들을 판별하도록 구성되는 대 흉근 존재 영역 판별부; 및 분할 인공지능 모델에 의해, 대흉근이 존재하는 것으로 판별된 제1 수평면 영상들에 서 특징들을 추출하는 영역 분할을 통해 대흉근의 영역을 분할하도록 구성되는 대흉근 영역 분할부;를 포함한다."}
{"patent_id": "10-2021-0006189", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 흉부 CT 영상을 이용하여 딥러닝 기법을 활용하여 대흉근 영역에 대한 자동 측정을 수행하는 기술에 관한 것이다."}
{"patent_id": "10-2021-0006189", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "대흉근(pectoralis muscle)은 어깨 관절의 움직임을 담당하는 중요한 역할을 하는 근육이다. 대흉근은 팔을 구 부릴 수 있도록 도우며, 팔의 확장을 용이하게 한다. 또한, 대흉근은 강제 호흡이 필요한 경우 가슴과 갈비뼈를 들어올리는 것을 도와 공기를 들이마셔 폐가 팽창하도록 하는 등의 호흡근 역할도 한다. 따라서 대흉근의 크기 와 근질은 호흡과 관련된 수치 및 질환 진행도와 필연적으로 큰 관계를 가지고 있으며, 다양한 폐질환의 진행도 및 진척도, 특히 근육 감소량과도 관계가 큰 질환인 만성 폐쇄성 폐질환(COPD; Chronic Obstructive Pulmonary Disease)과 관계가 큰 것으로 알려져 있다. 한편, 흉부 전산화 단층촬영(CT; Computed Tomography)은 흉부의 단면상의 영상을 획득하는 기술로, 흉부 진단 에 이용하는 검사법으로 널리 활용되고 있다. 현재 의료계에서는 주로 CT 영상의 특정 슬라이스(slice) 위치에 해당하는 2D 단면에서의 측정 결과를 이용하여 대흉근의 크기를 측정하고 있다. 그러나, 2D 단면에서의 측정 방 법은 환자의 자세나 의료진의 숙련도에 따라 환자의 대흉근의 크기가 다르게 측정되는 점에서 한계가 있다."}
{"patent_id": "10-2021-0006189", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 흉부 CT 영상을 이용하여 딥러닝 기법을 활용하여 대흉근 영역에 대한 자동 측정을 수행하는 딥러닝 기반 자동 대흉근 측정 장치 및 그 방법을 실행하기 위한 프로그램이 기록된 기록매체를 제공하기 위한 것이다. 또한, 본 발명은 환자의 자세나 의료 전문가의 임상적 판단에 따라 대흉근 측정 결과가 변화되지 않으며, 대흉 근 영역에 대한 측정 정확도를 높일 수 있는 딥러닝 기반 자동 대흉근 측정 기술을 제공하기 위한 것이다. 본 발명의 목적은 이상에서 언급한 목적으로 제한되지 않으며, 언급되지 않은 또 다른 목적들은 아래의 기재로 부터 본 발명이 속하는 통상의 지식을 가진 자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2021-0006189", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 실시예에 따른 딥러닝 기반 자동 대흉근 측정 장치는: 분류화 인공지능 모델에 의해, 대상체에 대해 획득된 제1 흉부 전산화 단층촬영(CT) 영상의 제1 관상면 영상으로부터 대흉근이 존재하는 제1 수평면 영상들을 판별하도록 구성되는 대흉근 존재 영역 판별부; 및 분할 인공지능 모델에 의해, 대흉근이 존재하는 것으로 판별 된 제1 수평면 영상들에서 특징들을 추출하는 영역 분할을 통해 대흉근의 영역을 분할하도록 구성되는 대흉근 영역 분할부;를 포함한다. 본 발명의 실시예에 따른 딥러닝 기반 자동 대흉근 측정 장치는: 제2 흉부 CT 영상의 제2 관상면 영상에 대흉근 존재 영역이 라벨링된 제1 학습 영상을 이용하여 상기 분류화 인공지능 모델을 학습시키도록 구성되는 분류화 인공지능 모델 학습부; 및 상기 제2 흉부 CT 영상의 제2 수평면 영상에 대흉근 영역이 라벨링된 제2 학습 영상 을 이용하여 상기 분할 인공지능 모델을 학습시키도록 구성되는 분할 인공지능 모델 학습부;를 더 포함할 수 있 다. 상기 대흉근 존재 영역 판별부는: 상기 제1 흉부 CT 영상으로부터 컬러 합성 처리된 상기 제1 관상면 영상을 획 득하고, 상기 분류화 인공지능 모델 학습부에 의해 학습된 상기 분류화 인공지능 모델을 이용하여 상기 제1 관 상면 영상 내 대흉근 존재 영역을 예측하여 상기 제1 흉부 CT 영상의 복수의 수평면 영상들 중 상기 제1 수평면영상들을 추출하도록 구성될 수 있다. 상기 대흉근 존재 영역 판별부는: 상기 제1 흉부 CT 영상의 적층된 관상면 영상들 중에서 적층 순번을 기준으로 중간 부분에 해당하는 관상면 위치들을 확인하고; 상기 관상면 영상들 중에서 상기 관상면 위치들에 해당하는 복수의 회색조 관상면 영상들을 추출하고; 상기 복수의 회색조 관상면 영상들을 하나로 합성하여 컬러 관상면 영상을 획득하고; 상기 컬러 관상면 영상을 설정된 길이로 맞추어 상기 제1 관상면 영상을 획득하고; 그리고 상 기 제1 관상면 영상으로부터 상기 분류화 인공지능 모델에 의해 상기 제1 수평면 영상들을 판별하도록 구성될 수 있다. 상기 복수의 회색조 관상면 영상들은 상기 제2 관상면 영상들의 적층 순번을 기준으로, 3/8, 4/8 및 5/8의 관상 면 위치들에 해당하는 제2 관상면 영상들을 포함할 수 있다. 상기 대흉근 영역 분할부는: 상기 분할 인공지능 모델 학습부에 의해 학습된 상기 분할 인공지능 모델을 이용하 여 대흉근 예측 영상을 생성하고; 그리고 상기 대흉근 예측 영역에서 노이즈에 해당하는 미소 영역들을 제외하 여 상기 대흉근의 영역을 분할하도록 구성될 수 있다. 상기 대흉근 영역 분할부는: 상기 대흉근 예측 영상을 이진화 처리하여 설정된 픽셀값을 가지는 이진화 영상을 생성하고; 상기 이진화 영상에서 인접한 픽셀들을 연결하여 그룹핑하여 상기 이진화 영상을 다수의 영역들로 분 할하고; 그리고 상기 다수의 영역들의 넓이를 각각 산출하고, 넓이가 기준값 이하인 영역을 제외하여 대흉근을 측정하도록 구성될 수 있다. 상기 분류화 인공지능 모델은 에피션트넷(EfficientNet) 모델을 기반으로 완전연결층이 추가되어 구현될 수 있 다. 상기 분할 인공지능 모델은: 제1 컨볼루션 처리 및 풀링 처리를 복수의 컨트랙팅 레이어를 통해 순차적으로 반복하여 수행하도록 구성되는 컨트랙팅 패스; 제2 컨볼루션 처리 및 업 샘플링 처리를 복수의 익스펜딩 레이어 를 통해 순차적으로 반복하여 수행하도록 구성되는 익스펜시브 패스; 및 상기 컨트랙팅 패스에서 추출된 제1 특 징 맵을 상기 익스펜시브 패스로 전달하도록 구성되는 스킵 커넥션부;를 포함할 수 있다. 상기 익스펜시브 패스는 상기 복수의 익스펜딩 레이어에 각각 적용되는 어텐션 모듈을 포함할 수 있다. 상기 어 텐션 모듈은: 상기 스킵 커넥션부에 의해 상기 컨트랙팅 패스의 컨트랙팅 레이어로부터 상기 제1 특징 맵을 전 달받고; 상기 익스펜시브 패스의 제1 익스펜딩 레이어로부터 제2 특징 맵을 전달받고; 상기 제1 특징 맵과 상기 제2 특징 맵을 기반으로 제3 컨볼루션 처리, 렐루 활성화 처리, 및 시그모이드 처리를 수행하여 어텐션 맵을 생 성하고; 그리고 상기 어텐션 맵을 상기 익스펜시브 패스의 제2 익스펜딩 레이어로 전달하도록 구성될 수 있다. 본 발명의 실시예에 따르면, 딥러닝 기반 자동 대흉근 측정 방법을 실행하기 위한 프로그램이 기록된 컴퓨터로 판독 가능한 기록 매체가 제공된다. 상기 딥러닝 기반 자동 대흉근 측정 방법은: 분류화 인공지능 모델에 의해, 대상체에 대해 획득된 제1 흉부 전산화 단층촬영(CT) 영상의 제1 관상면 영상으로부터 대흉근이 존재하는 제1 수평면 영상들을 판별하는 단계; 및 분할 인공지능 모델에 의해, 대흉근이 존재하는 것으로 판별된 제1 수평면 영상들에서 특징들을 추출하는 영역 분할을 통해 대흉근의 영역을 분할하는 단계;를 포함한다. 상기 딥러닝 기반 자동 대흉근 측정 방법은: 분류화 인공지능 모델 학습부에 의해, 제2 흉부 CT 영상의 제2 관 상면 영상에 대흉근 존재 영역이 라벨링된 제1 학습 영상을 이용하여 상기 분류화 인공지능 모델을 학습시키는 단계; 및 분할 인공지능 모델 학습부에 의해, 상기 제2 흉부 CT 영상의 제2 수평면 영상에 대흉근 영역이 라벨 링된 제2 학습 영상을 이용하여 상기 분할 인공지능 모델을 학습시키는 단계;를 더 포함할 수 있다. 상기 제1 수평면 영상들을 판별하는 단계는: 상기 제1 흉부 CT 영상으로부터 컬러 합성 처리된 상기 제1 관상면 영상을 획득하고, 상기 분류화 인공지능 모델 학습부에 의해 학습된 상기 분류화 인공지능 모델을 이용하여 상 기 제1 관상면 영상 내 대흉근 존재 영역을 예측하여 상기 제1 흉부 CT 영상의 복수의 수평면 영상들 중 상기 제1 수평면 영상들을 추출하는 단계를 포함할 수 있다. 상기 제1 수평면 영상들을 판별하는 단계는: 상기 제1 흉부 CT 영상의 적층된 관상면 영상들 중에서 적층 순번 을 기준으로 중간 부분에 해당하는 관상면 위치들을 확인하는 단계; 상기 관상면 영상들 중에서 상기 관상면 위 치들에 해당하는 복수의 회색조 관상면 영상들을 추출하는 단계; 상기 복수의 회색조 관상면 영상들을 하나로 합성하여 컬러 관상면 영상을 획득하는 단계; 상기 컬러 관상면 영상을 설정된 길이로 맞추어 상기 제1 관상면 영상을 획득하는 단계; 및 상기 제1 관상면 영상으로부터 상기 분류화 인공지능 모델에 의해 상기 제1 수평면 영상들을 판별하는 단계를 포함할 수 있다. 상기 대흉근의 영역을 분할하는 단계는: 상기 분할 인공지능 모델 학습부에 의해 학습된 상기 분할 인공지능 모 델을 이용하여 대흉근 예측 영상을 생성하는 단계; 및 상기 대흉근 예측 영역에서 노이즈에 해당하는 미소 영역 들을 제외하여 상기 대흉근의 영역을 분할하는 단계를 포함할 수 있다. 상기 대흉근의 영역을 분할하는 단계는: 상기 대흉근 예측 영상을 이진화 처리하여 설정된 픽셀값을 가지는 이 진화 영상을 생성하는 단계; 상기 이진화 영상에서 인접한 픽셀들을 연결하여 그룹핑하여 상기 이진화 영상을 다수의 영역들로 분할하는 단계; 및 상기 다수의 영역들의 넓이를 각각 산출하고, 넓이가 기준값 이하인 영역을 제외하여 대흉근을 측정하는 단계를 포함할 수 있다."}
{"patent_id": "10-2021-0006189", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명의 실시예에 의하면, 흉부 CT 영상을 이용하여 딥러닝 기법을 활용하여 대흉근 영역에 대한 자동 측정을 수행하는 딥러닝 기반 자동 대흉근 측정 장치 및 그 방법을 실행하기 위한 프로그램이 기록된 기록매체가 제공 된다. 또한, 본 발명의 실시예에 의하면, 환자의 자세나 의료 전문가의 임상적 판단에 따라 대흉근 측정 결과가 변화 되는 것을 방지할 수 있으며, 대흉근 영역에 대한 측정 정확도를 높일 수 있다."}
{"patent_id": "10-2021-0006189", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명의 목적 및 효과, 그리고 그것들을 달성하기 위한 기술적 구성들은 첨부되는 도면과 함께 상세하게 후술 되어 있는 실시예들을 참조하면 명확해질 것이다. 본 발명을 설명함에 있어서 공지 기능 또는 구성에 대한 구체 적인 설명이 본 발명의 요지를 불필요하게 흐릴 수 있다고 판단되는 경우에는 그 상세한 설명을 생략할 것이다. 그리고 후술되는 용어들은 본 발명에서의 기능을 고려하여 정의된 용어들로서 이는 사용자, 운용자의 의도 또는 관례 등에 따라 달라질 수 있다. 그러나 본 발명은 이하에서 개시되는 실시예들에 한정되는 것이 아니라 서로 다른 다양한 형태로 구현될 수 있"}
{"patent_id": "10-2021-0006189", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "다. 단지 본 실시예들은 본 발명의 개시가 완전하도록 하고, 본 발명이 속하는 기술분야에서 통상의 지식을 가 진 자에게 발명의 범주를 완전하게 알려주기 위해 제공되는 것이며, 본 발명은 청구항의 범주에 의해 정의될 뿐 이다. 그러므로 그 정의는 본 명세서 전반에 걸친 내용을 토대로 내려져야 할 것이다. 본 명세서에서 사용되는 '~부, ~모듈'은 적어도 하나의 기능이나 동작을 처리하는 단위로서, 예를 들어 소프트 웨어, FPGA 또는 하드웨어 구성요소를 의미할 수 있다. '~부, ~모듈'에서 제공하는 기능은 복수의 구성요소에 의해 분리되어 수행되거나, 다른 추가적인 구성요소와 통합될 수도 있다. 본 명세서의 '~부, ~모듈'은 반드시 소프트웨어 또는 하드웨어에 한정되지 않으며, 어드레싱할 수 있는 저장 매체에 있도록 구성될 수도 있고, 하나 또는 그 이상의 프로세서들을 재생시키도록 구성될 수도 있다. 이하에서는 도면을 참조하여 본 발명의 실시예에 대해서 구체적으로 설명하기로 한다. 본 발명의 실시예에 따른 딥러닝 기반 자동 대흉근 측정 장치는 대상체(환자)에 대해 획득된 제1 흉부 전산화 단층촬영 영상(3D 흉부 CT 영상)의 제1 관상면 영상으로부터 대흉근(pectoralis muscle)이 존재하는 제1 수평면 영상들을 판별하는 딥러닝 기반의 분류화 인공지능 모델과, 대흉근이 존재하는 것으로 판별된 제1 수평면 영상 들에서 특징들을 추출하는 영역 분할을 통해 대흉근의 영역을 분할하는 딥러닝 기반의 분할 인공지능 모델을 포 함한다. 본 발명의 실시예에 따른 딥러닝 기반 자동 대흉근 측정 장치는 3D 초음파 영상의 관상면(Coronal) 영상을 통해 대흉근이 존재하는 수평면(Axial) 영상들을 판별(detection)하고, 대흉근이 존재한다고 판단된 수평면 CT 영상 에서 실제 대흉근의 영역을 분할(segmentation) 할 수 있다. 본 발명의 실시예에 따른 딥러닝 기반 자동 대흉근 측정 장치는 3D 흉부 CT 영상 중 수평면 영상만을 사용하는 것이 아니라, 3D 흉부 CT 영상의 수평면 영상과 함께 관상면 영상을 사용하여 대흉근 측정에 활용함으로써, 2D 대흉근이 아닌 3D 대흉근 영역을 측정할 수 있다. 또한, 본 발명의 실시예에 따른 딥러닝 기반 자동 대흉근 측정 장치는 3D CT 영상을 이용하면서도, 3D 볼륨을 직접적으로 활용하지 않고, 인공지능 모델에 의해 해당 영역에서의 특징을 추출하는 방식으로, 2.5D 환자정보를 활용하여 대흉근에 해당하는 3D 영역을 추출할 수 있다. 상술한 바와 같은 본 발명의 실시예에 따른 딥러닝 기반 자동 대흉근 측정 장치에 의하면, 딥러닝 기반으로 학 습된 다수의 인공지능 모델(분류화 인공지능 모델, 분할 인공지능 모델)을 기반으로 대흉근 영역에 대한 자동 측정을 수행할 수 있다. 본 발명의 실시예에 따른 딥러닝 기반 자동 대흉근 측정 장치에 의하면, 환자의 자세에 따라 대흉근 측정 결과 가 변화되는 것을 방지하고, 의료 전문가의 임상적 판단에 따라 대흉근 측정 결과가 좌우되는 것을 방지할 수 있으며, 대흉근 영역에 대한 측정 정확도를 높일 수 있다. 도 1은 본 발명의 실시예에 따른 딥러닝 기반 자동 대흉근 측정 장치의 구성도이다. 도 1을 참조하면, 본 발명 의 실시예에 따른 딥러닝 기반 자동 대흉근 측정 장치는 사용자 인터페이스부, 입력부, 딥러닝 기 반 자동 대흉근 측정부, 저장부, 표시부, 및 제어부를 포함할 수 있다. 사용자 인터페이스부는 의사 등의 의료전문가가 딥러닝 기반의 자동 대흉근 측정을 위한 프로그램을 실행하 기 위한 각종 명령을 입력하도록 제공될 수 있다. 사용자 인터페이스부는 예를 들어, 키보드, 마우스, 터치 패드, 전자펜, 음성 인식부 등의 입력 인터페이스를 포함할 수 있다. 입력부는 딥러닝 기반의 자동 대흉근 측정을 위해 필요한 각종 데이터, 예를 들어, 의료전문가가 사용자 인 터페이스부를 이용하여 지정한 환자의 흉부 전산화 단층촬영(CT) 영상을 입력받도록 제공될 수 있다. 입력 부는 흉부 CT 장치로부터 데이터를 전송받거나, 저장부로부터 데이터를 입력받을 수 있다. 딥러닝 기반 자동 대흉근 측정부는 딥러닝 기반으로 학습된 다수의 인공지능 모델(분류화 인공지능 모델, 분할 인공지능 모델)을 이용하여 환자의 흉부 CT 영상으로부터 대흉근 영역이나 대흉근 크기(면적) 등을 자동으 로 측정하는 프로세스를 수행할 수 있다. 저장부는 환자의 흉부 CT 영상, 딥러닝 기반으로 다수의 인공지능 모델(분류화 인공지능 모델, 분할 인공지 능 모델)을 학습하기 위한 프로그램, 학습된 다수의 인공지능 모델을 기반으로 환자의 대흉근 영역과 대흉근 크 기 등을 자동 측정하는 프로세스를 수행하는 프로그램 등을 저장할 수 있다. 표시부는 환자의 흉부 CT 영상, 흉부 CT 영상의 관상면 영상들, 시상면 영상들, 수평면 영상들, 딥러닝 기 반 자동 대흉근 측정부에 의해 흉부 CT 영상으로부터 예측된 대흉근 영역, 대흉근 면적 등의 정보를 의료 단말기의 디스플레이 화면을 통해 표시하도록 제공될 수 있다. 제어부는 사용자 인터페이스부, 입력부, 딥러닝 기반 자동 대흉근 측정부, 저장부, 및 표 시부 등의 각종 구성요소를 제어하여 인공지능 모델을 이용하여 환자의 흉부 CT 영상으로부터 대흉근 영역이나 대흉근 크기 등을 측정하는 프로세스를 수행하는 적어도 하나의 프로세서를 포함할 수 있다. 도 2는 본 발명의 실시예에 따른 딥러닝 기반 자동 대흉근 측정 장치를 구성하는 딥러닝 기반 자동 대흉근 측정 부의 구성도이다. 도 2를 참조하면, 딥러닝 기반 자동 대흉근 측정부는 대흉근 존재 영역 판별부, 대 흉근 영역 분할부, 분류화 인공지능 모델 학습부 및 분할 인공지능 모델 학습부를 포함할 수 있 다. 대흉근 존재 영역 판별부는 대상체(환자)에 대해 획득된 제1 흉부 CT 영상의 제1 관상면 영상(coronal image)으로부터, 제1 흉부 CT 영상의 수평면 영상들(axial images) 중 대흉근이 존재하는 제1 수평면 영상들을 판별하는 분류화 인공지능 모델을 포함할 수 있다. 대흉근 영역 분할부는 제1 흉부 CT 영상의 수평면 영상들 중 대흉근이 존재하는 것으로 판별된 제1 수평면 영상들에서 특징들을 추출하는 영역 분할(segmentation)을 통해 제1 수평면 영상들에서 대흉근의 영역을 분할하 는 분할 인공지능 모델을 포함할 수 있다. 분류화 인공지능 모델 학습부와, 분할 인공지능 모델 학습부는 다수의 학습 영상(예를 들어, 인공지 능 모델의 학습을 위한 3D 흉부 CT 영상의 다수의 관상면 영상 및 다수의 수평면 영상)을 이용하여 분류화 인공 지능 모델과 분할 인공지능 모델을 학습시킬 수 있다. 분류화 인공지능 모델 학습부는 제2 흉부 CT 영상의 제2 관상면 영상 내에 대흉근 존재 영역(대흉근이 존 재하는 관상면 위치들)이 라벨링된 다수의 제1 학습 영상을 이용하여 대흉근이 존재하는 수평면 영상들의 분류 (classification)를 위한 분류화 인공지능 모델을 학습시킬 수 있다. 분할 인공지능 모델 학습부는 제2 흉부 CT 영상의 제2 수평면 영상 내에 대흉근 영역이 라벨링된 다수의 제2 학습 영상(대흉근에 해당하는 영역과 대흉근이 아닌 영역이 구별된 수평면 영상)을 이용하여 제1 수평면 내 대흉근 영역의 분할을 위한 분할 인공지능 모델을 학습시킬 수 있다. 도 3은 본 발명의 실시예에 따른 본 발명의 실시예에 따른 딥러닝 기반 자동 대흉근 측정 장치를 구성하는 분류 화 인공지능 모델의 개념도이다. 분류화 인공지능 모델은 에피션트넷(EfficientNet) 모델을 기반으로 완전연결층(Fully Connected Layer)이 추가되어 구현될 수 있다. 실시예에서, 에피션트넷 모델은 \"EfficientNet-b6\" 모델을 기반으로 구현될 수 있다. 에피션트넷 모델은 알려진 바와 같이, 어댑티브에버리지풀(AdaptiveAvgPool2d), 드롭아웃(Dropout), 리니어(Linear) 프로세스를 추가적으 로 동작시킬 수 있다. 에피션트넷 모델에서, 어댑티브에버리지풀은 입력 값의 형태를 리니어하게 바꾸어 주는 역할을 한다. 드롭아웃 은 오버피팅(overfitting)을 막기 위한 것으로, 계수를 0.5로 설정할 경우 절반의 네트워크를 생략하는 역할을 할 수 있다. 리니어 프로세스는 출력 피쳐(feature)의 수를 결정하는 역할을 한다. 도 4는 본 발명의 실시예에 따른 본 발명의 실시예에 따른 딥러닝 기반 자동 대흉근 측정 장치를 구성하는 분할 인공지능 모델의 개념도이다. 분할 인공지능 모델은 영상 크기를 줄여나가는 컨트랙팅 패스, 영상 크 기를 키워나가는 익스펜시브 패스, 및 스킵 커넥션부를 포함할 수 있다. 컨트랙팅 패스(contracting path)는 제1 컨볼루션(convolution) 처리 및 풀링(pooling) 처리(예를 들어, 맥스 풀링 처리, 평균 풀링 처리 등)를 복수의 컨트랙팅 레이어(contracting layer)를 통해 순차적으로 반복하 여 수행할 수 있다. 익스펜시브 패스(expansive path)는 제2 컨볼루션 처리 및 업 샘플링(up sampling) 처리를 복수의 익스펜 딩 레이어(expanding layer)를 통해 순차적으로 반복하여 수행할 수 있다. 스킵 커넥션부(skip connection unit)는 컨트랙팅 패스의 컨트랙팅 레이어에서 추출된 제1 특징 맵 (컨볼루션 영상)을 컨트랙팅 레이어와 대응하는 익스펜시브 패스의 익스펜딩 레이어로 전달할 수 있다. 익스펜시브 패스는 복수의 어텐션 모듈(attention module)을 포함할 수 있다. 어텐션 모듈은 익 스펜시브 패스의 복수의 익스펜딩 레이어에 각각 적용될 수 있다. 실시예에서, 분할 인공지능 모델은 어텐션 모듈이 익스펜시브 패스에 추가된 유넷(U-Net) 모델로 구현될 수 있다. 어텐션 모듈은 스킵 커넥션부에 의해 컨트랙팅 패스의 컨트랙팅 레이어로부터 제1 특징 맵을 전 달받고, 익스펜시브 패스의 제1 익스펜딩 레이어로부터 제2 특징 맵을 전달받을 수 있다.어텐션 모듈은 전달받은 제1 특징 맵과 제2 특징 맵을 기반으로 제3 컨볼루션 처리, 렐루(ReLU) 활성화 처 리, 및 시그모이드(Sigmoid) 처리를 수행하여 어텐션 맵을 생성할 수 있다. 어텐션 모듈은 컨볼루션(Convolution) -> 배치 노멀라이제이션(Batch Normalization)/컨볼루션 -> 배치 노멀라이제이션 -> 렐루 활성화 함수(ReLu) -> 컨볼루션 -> 배치 노멀라이제이션 -> 시그모이드(Sigmoid) 순의 처리를 수행할 수 있다. 또한, 유넷 모델에는 학습률을 조절하기 위한 스케듈러(scheduler)로서, 리듀스엘알온플래튜 (ReduceLROnPlateau)가 적용될 수 있다. 매트릭(metric) 개선이 중지된 경우 학습 정체, 학습률 감소에 의해 이 익을 얻을 수 있도록, 에폭(epoch) 수에 대한 개선이 보이지 않는 경우 학습률을 50%씩 감소시키도록 구동될 수 있다. 익스펜시브 패스의 제1 익스펜딩 레이어의 어텐션 모듈에 의해 생성된 어텐션 맵은 익스펜시브 패스 의 제1 익스펜딩 레이어에 연결된 제2 익스펜딩 레이어로 전달될 수 있다. 분할 인공지능 모델은 커스텀 손실함수(custom loss function)을 이용하여 흉부 영역에 해당하는 영상 중 앙 위쪽 부분의 가중치(weight)를 증가시켜 대흉근에 해당하는 영역분할 처리를 하도록 구성될 수 있다. 실시예에서, 대흉근 존재 영역 판별부는 대흉근 측정의 대상체인 환자의 제1 흉부 CT 영상으로부터 컬러 합성 처리된 제1 관상면 영상을 획득할 수 있다. 환자의 제1 흉부 CT 영상으로부터 획득된 제1 관상면 영상은 분류화 인공지능 모델에 입력될 수 있다. 대흉근 존재 영역 판별부는 분류화 인공지능 모델 학습부에 의해 학습된 분류화 인공지능 모델 을 이용하여 제1 관상면 영상 내 대흉근 존재 영역을 예측하여 제1 흉부 CT 영상의 복수의 수평면 영상들 중 제 1 수평면 영상들을 추출할 수 있다. 제1 흉부 CT 영상으로부터 제1 관상면 영상을 획득하기 위하여, 대흉근 존재 영역 판별부는 먼저 환자에 대해 획득된 제1 흉부 CT 영상의 적층된 관상면 영상들 중에서 적층 순번을 기준으로 중간 부분에 해당하는 관 상면 위치들을 확인할 수 있다. 다음으로, 대흉근 존재 영역 판별부는 제1 흉부 CT 영상의 관상면 영상들 중에서 관상면 위치들에 해당하 는 복수의 회색조(grayscale) 관상면 영상들을 추출할 수 있다. 실시예에서, 제1 흉부 CT 영상의 관상면 영상들 중에서 추출되는 복수의 회색조 관상면 영상들은 적층 순번을 기준으로, 3/8, 4/8 및 5/8의 관상면 위치들에 해당하는 3개의 관상면 영상들을 포함할 수 있다. 단, 관상면 위 치들은 CT 영상 크기에 따라 다르게 설정될 수도 있다. 다음으로, 대흉근 존재 영역 판별부는 설정된 관상면 위치들에 해당하는 복수의 회색조 관상면 영상들(예 를 들어, 3/8, 4/8 및 5/8의 관상면 위치들에 해당하는 3개의 관상면 영상들)을 이어 붙여 각각 RGB 컬러를 담 당할 수 있도록 하나로 합성하여 컬러 관상면 영상을 획득할 수 있다. 다음으로, 대흉근 존재 영역 판별부는 컬러 관상면 영상을 설정된 길이로 맞추어 제1 관상면 영상을 획득 할 수 있다. 예를 들어, 관상면 영상의 높이를 설정 길이(예를 들어, 416)으로 맞추기 위해, 관상면 영상이 설 정 길이인 416 보다 길면 아래 부분을 자르고, 설정 길이인 416 보다 짧으면 가장 아래 행과 같은 배열을 아래 부분에 추가하여 설정 길이인 416으로 맞출 수 있다. 대흉근 존재 영역 판별부는 제1 관상면 영상으로부터 분류화 인공지능 모델에 의해 제1 흉부 CT 영상 의 수평면 영상들 중 대흉근이 존재하는 제1 수평면 영상들을 판별할 수 있다. 대흉근 영역 분할부는 분할 인공지능 모델 학습부에 의해 학습된 분할 인공지능 모델을 이용하 여 대흉근 예측 영상을 생성하고, 대흉근 예측 영역에서 노이즈에 해당하는 미소 영역들(작은 크기의 영역들)을 제외하여 대흉근의 영역을 분할할 수 있다. 노이즈 제거 과정을 보다 구체적으로 설명하면, 대흉근 영역 분할부는 분할 인공지능 모델 학습부에 서 출력되는 대흉근 예측 영상을 이진화 처리하여 설정된 픽셀값을 가지는 이진화 영상을 생성할 수 있다. 대흉근 영역 분할부는 예를 들어, 임계값(threshold)에 기반한 이진화 처리한 후, 픽셀 값이 '1'인 픽셀들 만을 남김으로써, 이진화 영상을 생성할 수 있다. 다음으로, 대흉근 영역 분할부는 이진화 영상에서 인접한 픽셀들을 연결하여 그룹핑하여 이진화 영상을 다 수의 영역들(예를 들어, 픽셀값 '1'을 가지는 영역들)로 분할할 수 있다. 이때, 대흉근 영역 분할부는 예를 들어, 커넥티드 컴포넌트 위드 스탯(Connected Component With Stats) 을 통해 인접한 픽셀들을 연결 및 그룹핑한 후 라벨링을 수행할 수 있다. 다음으로, 대흉근 영역 분할부는 이진화 영상에서 분할된 다수의 영역들의 넓이를 각각 산출하고, 넓이가 기준값(예를 들어, 픽셀 10개에 해당하는 기준 넓이) 이하인 영역을 제외하여 대흉근을 측정할 수 있다. 도 5는 본 발명의 실시예에 따라 컴퓨터로 판독 가능한 기록매체에 기록된 프로그램에 의해 실행되는 딥러닝 기 반 자동 대흉근 측정 방법의 순서도이다. 도 1, 도 2 및 도 5를 참조하면, 다수의 학습 영상을 획득되면, 분류 화 인공지능 모델 학습부와, 분할 인공지능 모델 학습부는 다수의 학습 영상을 이용하여 분류화 인공 지능 모델과 분할 인공지능 모델을 학습시킬 수 있다(S110, S120). 분류화 인공지능 모델 학습부는 제2 흉부 CT 영상의 제2 관상면 영상 내에 대흉근 존재 영역이 라벨링된 다수의 제1 학습 영상을 이용하여 분류화 인공지능 모델을 학습시킬 수 있다. 분할 인공지능 모델 학습부는 제2 흉부 CT 영상의 제2 수평면 영상 내에 대흉근 영역이 라벨링된 다수의 제2 학습 영상을 이용하여 분할 인공지능 모델을 학습시킬 수 있다. 대흉근 존재 영역 판별부는 대상체(환자)에 대해 획득된 제1 흉부 CT 영상으로부터 제1 관상면 영상 (coronal image)을 획득하고, 분류화 인공지능 모델에 의해 제1 관상면 영상으로부터 제1 흉부 CT 영상의 수평면 영상들(axial images)에 대흉근이 존재하는지 여부를 판별할 수 있다(S130, S140). 대흉근 영역 분할부는 분할 인공지능 모델에 의해 제1 흉부 CT 영상의 수평면 영상들 중 대흉근이 존 재하는 것으로 판별된 제1 수평면 영상들에서 특징들을 추출하는 영역 분할(segmentation)을 통해 3D 흉부 CT 영상의 수평면 영상에서 대흉근 예측 영상을 생성하고, 예측된 대흉근 예측 영상에서 노이즈 영역을 제외하여 대흉근 영역을 분할할 수 있다(S150, S160). 도 6은 도 5의 단계 S130을 나타낸 순서도이다. 도 7은 도 6의 실시예에 따라 제1 관상면 영상을 획득하는 과정 을 설명하기 위한 예시도이다. 도 1, 도 2, 도 5 내지 도 7을 참조하면, 제1 흉부 CT 영상으로부터 제1 관상면 영상을 획득하기 위하여, 대흉근 존재 영역 판별부는 먼저 환자에 대해 획득된 제1 흉부 CT 영상의 적층된 관상면 영상들 중에서 적층 순번을 기준으로 중간 부분에 해당하는 관상면 위치들을 확인할 수 있다(S132). 다음으로, 대흉근 존재 영역 판별부는 제1 흉부 CT 영상의 관상면 영상들 중에서 관상면 위치들에 해당하 는 복수의 회색조(grayscale) 관상면 영상들(11, 12, 13)을 추출할 수 있다(S134). 실시예에서, 제1 흉부 CT 영상의 관상면 영상들 중에서 추출되는 복수의 회색조 관상면 영상들은 적층 순번을 기준으로, 3/8, 4/8 및 5/8의 관상면 위치들에 해당하는 3개의 관상면 영상들(11, 12, 13)을 포함할 수 있다. 관상면 위치들은 CT 영상 크기에 따라 다르게 설정될 수도 있다. 다음으로, 대흉근 존재 영역 판별부는 설정된 관상면 위치들에 해당하는 복수의 회색조 관상면 영상들(예 를 들어, 3/8, 4/8 및 5/8의 관상면 위치들에 해당하는 3개의 관상면 영상들)을 이어 붙여 각각 RGB 컬러를 담 당할 수 있도록 하나로 합성하여 컬러 관상면 영상을 획득할 수 있다(S136). 다음으로, 대흉근 존재 영역 판별부는 컬러 관상면 영상을 설정된 길이로 맞추어 제1 관상면 영상(1 5)을 획득할 수 있다(S138). 예를 들어, 관상면 영상의 높이를 설정 길이로 맞추기 위해, 관상면 영상이 설정 길이 보다 길면 아래 부분을 자르고, 설정 길이 보다 짧으면 가장 아래 행과 같은 배열을 아래에 추가해 길이를 맞출 수 있다. 이후, 대흉근 존재 영역 판별부는 제1 관상면 영상으로부터 분류화 인공지능 모델에 의해 제1 흉부 CT 영상의 수평면 영상들 중 대흉근이 존재하는 제1 수평면 영상들을 판별할 수 있다. 대흉근 영역 분할부는 분할 인공지능 모델 학습부에 의해 학습된 분할 인공지능 모델을 이용하 여 대흉근 예측 영상을 생성하고, 대흉근 예측 영역에서 노이즈에 해당하는 미소 영역들(작은 크기의 영역들)을 제외하여 대흉근의 영역을 분할할 수 있다. 도 8은 도 6의 단계 S160을 나타낸 순서도이다. 도 9는 본 발명의 실시예에 따라 예측된 대흉근 영역의 분할 결 과를 나타낸 도면이다. 도 1, 도 2, 도 6, 도 8 및 도 9를 참조하면, 대흉근 영역 분할부는 분할 인공지능 모델 학습부에서 출력되는 대흉근 예측 영상을 이진화 처리하여 설정된 픽셀값을 가지는 이진화 영상을 생성할 수 있다(S162). 대흉근 영역 분할부는 예를 들어, 임계값(threshold)에 기반한 이진화 처리한 후, 픽셀 값이 '1'인 픽셀들 만을 남김으로써, 이진화 영상을 생성할 수 있다. 다음으로, 대흉근 영역 분할부는 이진화 영상에서 인접한 픽셀들을 연결하여 그룹핑하여 이진화 영상을 다 수의 영역들(예를 들어, 픽셀값 '1'을 가지는 영역들)로 분할할 수 있다(S164). 이때, 대흉근 영역 분할부는 예를 들어, 커넥티드컴포넌트위드스탯(Connected Component With Stats)을 통해 인접한 픽셀들을 연결 및 그룹핑한 후 라벨링을 수행할 수 있다. 다음으로, 대흉근 영역 분할부는 이진화 영상에서 분할된 다수의 영역들의 넓이를 각각 산출하고, 넓이가 기준값(예를 들어, 픽셀 10개에 해당하는 기준 넓이) 이하인 영역을 제외하여 대흉근을 측정할 수 있다(S166). 도 10은 본 발명의 실시예에 따라 딥러닝 기반으로 대흉근이 존재하는 수평면 영상을 추출한 결과를 나타낸 도 면이다. 도 10의 (a)는 3D 흉부 CT 영상에서 추출된 제1 관상면 영상, (b)는 마스크 영역, (c)는 예측 마스크 영역, (d)는 대흉근 영역(PM)과 비-대흉근 영역(Non-PM)으로 예측된 수평면 영상 슬라이스 범위를 나타낸다. 도 10의 (b)에 도시된 마스크 영역은 대흉근이 존재하는 수평면들에 해당하는 영역을 나타내며, 도 10의 (c)에 도시된 예측 마스크 영역은 분류화 인공지능 모델에 의해 분류한 수평면들에 해당하는 영역을 나타낸다. 본 발 명의 실시예에 따라 딥러닝 기반의 인공지능 모델에 의해 자동 대흉근 측정을 수행하여 대흉근이 존재하는 수평 면 영상 슬라이스를 판별한 결과, 약 95%의 높은 정확도를 나타내는 것으로 측정되었다. 도 11은 본 발명의 실시예에 따라 딥러닝 기반으로 수평면 영상에서 대흉근 영역을 분할한 결과를 나타낸 도면 이다. 도 11의 (a)는 수평면 영상에서 대흉근 영역에 해당하는 마스크이고, 도 11의 (b)는 딥러닝 기반의 분할 인공지능 모델에 의해 예측된 대흉근 영역이고, (c)는 (a)의 결과와 (b)의 결과 간의 차이이다. 본 발명의 실시 예에 따라 딥러닝 기반의 인공지능 모델에 의해 수평면 영상에서 대흉근 영역을 분할한 결과, 약 90%의 높은 정 확도로 대흉근 영역을 예측하였다. 상술한 바와 같은 본 발명의 실시예에 따른 딥러닝 기반 자동 대흉근 측정 방법을 실행하기 위한 프로그램이 기 록된 기록매체에 의하면, 딥러닝 기반으로 학습된 다수의 인공지능 모델(분류화 인공지능 모델, 분할 인공지능 모델)을 기반으로 대흉근 영역에 대한 자동 측정을 수행할 수 있다. 본 발명의 실시예에 의하면, 3D 초음파 영상의 관상면(Coronal) 영상을 통해 대흉근이 존재하는 수평면(Axial) 영상들을 판별하고, 대흉근이 존재한다고 판단된 수평면 CT 영상에서 실제 대흉근의 영역을 분할할 수 있다. 또한, 본 발명의 실시예에 의하면, 3D CT 영상 중 수평면 영상만을 사용하는 것이 아니라, 수평면 영상과 함께 관상면 영상을 사용하여 대흉근 측정에 활용함으로써, 2D 대흉근이 아닌 3D 대흉근을 측정할 수 있다. 또한, 본 발명의 실시예에 의하면, 3D CT 영상을 이용하면서도, 3D 볼륨을 직접적으로 활용하지 않고, 인공지능 모델에 의해 해당 영역에서의 특징을 추출하여, 2.5D 환자정보를 활용하여 대흉근에 해당하는 3D 영역을 추출할 수 있다. 또한, 본 발명의 실시예에 의하면, 환자의 자세 변화나 의료 전문가의 임상적 판단에 따라 대흉근 측정 결과가 변화되는 것을 방지할 수 있으며, 대흉근 영역에 대한 측정 정확도를 높일 수 있다."}
{"patent_id": "10-2021-0006189", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "이상의 설명은 본 발명의 기술 사상을 예시적으로 설명한 것에 불과한 것으로서, 본 발명이 속하는 기술분야에 서 통상의 지식을 가진 자라면 본 발명의 본질적인 특성에서 벗어나지 않는 범위에서 다양한 수정 및 변형이 가 능할 것이다. 따라서, 본 발명에 개시된 실시예들은 본 발명의 기술 사상을 한정하기 위한 것이 아니라 설명하 기 위한 것이고, 이러한 실시예에 의하여 본 발명의 기술 사상의 범위가 한정되는 것은 아니다. 본 발명의 보호 범위는 아래의 청구범위에 의하여 해석되어야 하며, 그와 동등한 범위 내에 있는 모든 기술 사상은 본 발명의 권리범위에 포함되는 것으로 해석되어야 할 것이다."}
{"patent_id": "10-2021-0006189", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 실시예에 따른 딥러닝 기반 자동 대흉근 측정 장치의 구성도이다. 도 2는 본 발명의 실시예에 따른 딥러닝 기반 자동 대흉근 측정 장치를 구성하는 딥러닝 기반 자동 대흉근 측정 부의 구성도이다. 도 3은 본 발명의 실시예에 따른 본 발명의 실시예에 따른 딥러닝 기반 자동 대흉근 측정 장치를 구성하는 분류 화 인공지능 모델의 개념도이다. 도 4는 본 발명의 실시예에 따른 본 발명의 실시예에 따른 딥러닝 기반 자동 대흉근 측정 장치를 구성하는 분할 인공지능 모델의 개념도이다. 도 5는 본 발명의 실시예에 따라 컴퓨터로 판독 가능한 기록매체에 기록된 프로그램에 의해 실행되는 딥러닝 기 반 자동 대흉근 측정 방법의 순서도이다. 도 6은 도 5의 단계 S130을 나타낸 순서도이다. 도 7은 도 6의 실시예에 따라 제1 관상면 영상을 획득하는 과정을 설명하기 위한 예시도이다. 도 8은 도 6의 단계 S160을 나타낸 순서도이다. 도 9는 본 발명의 실시예에 따라 예측된 대흉근 영역의 분할 결과를 나타낸 도면이다. 도 10은 본 발명의 실시예에 따라 딥러닝 기반으로 대흉근이 존재하는 수평면 영상을 추출한 결과를 나타낸 도 면이다. 도 11은 본 발명의 실시예에 따라 딥러닝 기반으로 수평면 영상에서 대흉근 영역을 분할한 결과를 나타낸 도면 이다."}
