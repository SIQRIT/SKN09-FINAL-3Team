{"patent_id": "10-2015-7029066", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2016-0011620", "출원번호": "10-2015-7029066", "발명의 명칭": "상호 작용하는 합성 캐릭터 대화 시스템 및 방법", "출원인": "토이토크, 인코포레이티드", "발명자": "제이콥, 오렌 엠."}}
{"patent_id": "10-2015-7029066", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "사용자로부터 음성을 포함하는 오디오 입력을 수신하는 단계;상기 음성에 대한 문자 설명을 획득하는 단계;상기 문자 설명에 기초하여 응답 오디오 출력을 판단하는 단계; 및합성 캐릭터가 판단된 상기 응답 오디오 출력을 이용하여 이야기하게 하는 단계를 포함하는,사용자를 합성 캐릭터와의 대화에 관여시키는 방법."}
{"patent_id": "10-2015-7029066", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,사용자로부터의 음성을 포함하는 복수의 오디오 입력을 수신하는 단계를 더 포함하고,상기 복수의 오디오 입력은 하나 이상의 합성 캐릭터로부터의 복수의 이야기된 출력과 관련되는,사용자를 합성 캐릭터와의 대화에 관여시키는 방법."}
{"patent_id": "10-2015-7029066", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,상기 복수의 오디오 입력은 하나 이상의 합성 캐릭터에 의해 제기된 질문에 대한 답변을 포함하는,사용자를 합성 캐릭터와의 대화에 관여시키는 방법."}
{"patent_id": "10-2015-7029066", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제2항에 있어서,상기 복수의 오디오 입력은 문자의 내레이션(narration)을 포함하고, 상기 하나 이상의 합성 캐릭터로부터의 복수의 이야기된 출력은 상기 내래이션에 대한 애드리빙(ad-libbing) 또는 코멘터리(commentary)를 포함하는,사용자를 합성 캐릭터와의 대화에 관여시키는 방법."}
{"patent_id": "10-2015-7029066", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제2항에 있어서,상기 복수의 오디오 입력은 주제에 관한 대화에서의 진술을 포함하는,사용자를 합성 캐릭터와의 대화에 관여시키는 방법."}
{"patent_id": "10-2015-7029066", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "공개특허 10-2016-0011620-3-제1항에 있어서,상기 음성에 대한 문자 설명을 획득하는 단계는, 전용 음성 처리 서비스로 상기 오디오 입력을 전송하는 단계를포함하는,사용자를 합성 캐릭터와의 대화에 관여시키는 방법."}
{"patent_id": "10-2015-7029066", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에 있어서,상기 오디오 입력을 수신하는 단계는, \"자동 음성 활동 검출(Automatic-Voice-Activity-Detection)\", \"말하려면 홀드(Hold-to-Talk)\", \"말하려면 탭(Tap-to-Talk)\" 또는 \"말하려면 탭(침묵 검출)(Tap-to-Talk-With-Silence-Detection)\" 동작 중 하나를 수행할지 판단하는 단계를 포함하는,사용자를 합성 캐릭터와의 대화에 관여시키는 방법."}
{"patent_id": "10-2015-7029066", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서,판단된 오디오 입력 동작을 반영하도록 아이콘을 수정하는 단계를 더 포함하는,사용자를 합성 캐릭터와의 대화에 관여시키는 방법."}
{"patent_id": "10-2015-7029066", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1항에 있어서,상기 응답 오디오 출력을 판단하는 단계는 사용자 개인화 메타데이터를 판단하는 단계를 포함하는,사용자를 합성 캐릭터와의 대화에 관여시키는 방법."}
{"patent_id": "10-2015-7029066", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제1항에 있어서,상기 캐릭터의 안면 특징의 일부를 애니메이션화하는 목적으로 상기 응답 오디오 출력과 관련된 음소 메타데이터를 획득하는 단계를 더 포함하는,사용자를 합성 캐릭터와의 대화에 관여시키는 방법."}
{"patent_id": "10-2015-7029066", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제1항에 있어서,상기 사용자로부터의 복수의 응답을 리뷰하고, 상기 리뷰에 기초하여 사용자-캐릭터 대화보다 더 많은 캐릭터간대화를 수행하는 단계를 더 포함하는,사용자를 합성 캐릭터와의 대화에 관여시키는 방법."}
{"patent_id": "10-2015-7029066", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제1항에 있어서,공개특허 10-2016-0011620-4-우선 순위 메타데이터를 상기 합성 캐릭터에 대한 각각의 잠재적인 응답에 관련시키고, 하나의 가능한 응답이다른 응답 전에 출력되게 하도록 상기 우선 순위 메타데이터를 이용하는 단계를 더 포함하는,사용자를 합성 캐릭터와의 대화에 관여시키는 방법."}
{"patent_id": "10-2015-7029066", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제1항에 있어서,상기 합성 캐릭터가 판단된 상기 응답 오디오 출력을 이용하여 이야기하게 하는 단계는, 상기 합성 캐릭터가 사용자 장치를 이용하여 사진을 찍는 것을 제안하게 하는 단계를 포함하는,사용자를 합성 캐릭터와의 대화에 관여시키는 방법."}
{"patent_id": "10-2015-7029066", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제1항에 있어서,사용자 장치를 이용하여, 사용자에 대하여 사진이 찍히게 하는 단계; 및상기 사진을 소셜 네트워크의 하나 이상의 사용자에게 전송하는 단계를 더 포함하는,사용자를 합성 캐릭터와의 대화에 관여시키는 방법."}
{"patent_id": "10-2015-7029066", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "사용자에 의해 선택된 상호 작용 장면과 관련된 복수의 컴포넌트를 검색하는 단계;상기 장면에서 합성 캐릭터를 나타내도록 상기 복수의 컴포넌트 중 적어도 하나를 구성하는 단계; 및상기 복수의 컴포넌트의 적어도 일부를 사용자 장치에 전송하는 단계를 포함하는,사용자를 합성 캐릭터와의 대화에 시각적으로 관여시키는 방법."}
{"patent_id": "10-2015-7029066", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제15항에 있어서,사용자와 관련된 개인화 메타데이터를 검색하고, 상기 개인화 메타데이터에 기초하여 상기 복수의 컴포넌트 중적어도 하나를 수정하는 단계를 더 포함하는,사용자를 합성 캐릭터와의 대화에 시각적으로 관여시키는 방법."}
{"patent_id": "10-2015-7029066", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제15항에 있어서,상기 복수의 컴포넌트를 검색하는 단계는, 데이터베이스로부터 복수의 음성 파형을 검색하는 단계를 포함하는,사용자를 합성 캐릭터와의 대화에 시각적으로 관여시키는 방법.공개특허 10-2016-0011620-5-청구항 18 디스플레이;프로세서;통신 포트; 및 명령어를 포함하는 메모리를 포함하고,상기 명령어는, 상기 프로세서가,사용자로부터 음성을 포함하는 오디오 입력을 수신하고;상기 음성에 대한 문자 설명을 획득하고;상기 문자 설명에 기초하여 응답 오디오 출력을 판단하고; 그리고,합성 캐릭터가 판단된 상기 응답 오디오 출력을 이용하여 이야기하게 하도록,구성되는,사용자를 합성 캐릭터와의 대화에 관여시키는 컴퓨터 시스템."}
{"patent_id": "10-2015-7029066", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제18항에 있어서,상기 오디오 입력을 수신하는 것은, \"자동 음성 활동 검출(Automatic-Voice-Activity-Detection)\", \"말하려면홀드(Hold-to-Talk)\", \"말하려면 탭(Tap-to-Talk)\" 또는 \"말하려면 탭(침묵 검출)(Tap-to-Talk-With-Silence-Detection)\" 동작 중 하나를 수행할지 판단하는 것을 포함하는,사용자를 합성 캐릭터와의 대화에 관여시키는 컴퓨터 시스템."}
{"patent_id": "10-2015-7029066", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제19항에 있어서,상기 명령어는, 상기 프로세서가, 판단된 상기 동작을 반영하도록 아이콘을 수정하게 하도록 구성되는,사용자를 합성 캐릭터와의 대화에 관여시키는 컴퓨터 시스템."}
{"patent_id": "10-2015-7029066", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_21", "content": "제18항에 있어서,상기 응답 오디오 출력을 판단하는 것은, 사용자 개인화 메타데이터를 판단하는 것을 포함하는,사용자를 합성 캐릭터와의 대화에 관여시키는 컴퓨터 시스템."}
{"patent_id": "10-2015-7029066", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_22", "content": "제18항에 있어서,상기 명령어는, 상기 프로세서가, 상기 캐릭터의 안면 특징의 일부를 애니메이션화하는 목적으로 상기 응답 오디오 출력과 관련된 음소 메타데이터를 획득하게 하도록 구성되는,공개특허 10-2016-0011620-6-사용자를 합성 캐릭터와의 대화에 관여시키는 컴퓨터 시스템."}
{"patent_id": "10-2015-7029066", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_23", "content": "제18항에 있어서,상기 명령어는, 상기 프로세서가, 상기 사용자로부터의 복수의 응답을 리뷰하고, 상기 리뷰에 기초하여 사용자-캐릭터 대화보다 더 많은 캐릭터간 대화를 수행하게 하도록 구성되는,사용자를 합성 캐릭터와의 대화에 관여시키는 컴퓨터 시스템."}
{"patent_id": "10-2015-7029066", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_24", "content": "제18항에 있어서,상기 명령어는, 상기 프로세서가, 우선 순위 메타데이터를 상기 합성 캐릭터에 대한 각각의 잠재적인 응답에 관련시키고, 하나의 가능한 응답이 다른 응답 전에 출력되게 하기 위하여 상기 우선 순위 메타데이터를 이용하게하도록 구성되는,사용자를 합성 캐릭터와의 대화에 관여시키는 컴퓨터 시스템."}
{"patent_id": "10-2015-7029066", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_25", "content": "제18항에 있어서,상기 합성 캐릭터가 판단된 상기 응답 오디오 출력을 이용하여 이야기하게 하는 것은, 상기 합성 캐릭터가 사용자 장치를 이용하여 사진을 찍는 것을 제안하게 하는 것을 포함하는,사용자를 합성 캐릭터와의 대화에 관여시키는 컴퓨터 시스템."}
{"patent_id": "10-2015-7029066", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_26", "content": "사용자로부터 음성을 포함하는 오디오 입력을 수신하는 오디오 입력 수신 수단;상기 음성에 대한 설명을 판단하는 음성 설명 판단 수단;상기 설명에 기초하여 응답 오디오 출력을 판단하는 응답 오디오 출력 판단 수단; 및합성 캐릭터가 판단된 상기 응답 오디오 출력을 이용하여 이야기하게 하는 합성 캐릭터 이야기 수단을 포함하는,사용자를 합성 캐릭터와의 대화에 관여시키는 컴퓨터 시스템."}
{"patent_id": "10-2015-7029066", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_27", "content": "제26항에 있어서,상기 오디오 입력 수신 수단은, 마이크, 패킷 수신 모듈, WiFi 수신기, 휴대 전화 네트워크 수신기, 이더넷 연결, 무선 수신기, LAN 연결 또는 수송 가능한 메모리 저장 장치에 대한 인터페이스 중 하나를 포함하는,사용자를 합성 캐릭터와의 대화에 관여시키는 컴퓨터 시스템."}
{"patent_id": "10-2015-7029066", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_28", "content": "공개특허 10-2016-0011620-7-제26항에 있어서,상기 음성 설명 판단 수단은, 전용 음성 처리 서버에 대한 연결, 자연어 처리 프로그램, 음성 인식 시스템, 은닉 마르코프 모델(Hidden Markov Model) 또는 베이지안 분류기(Bayesian Classifier) 중 하나를 포함하는,사용자를 합성 캐릭터와의 대화에 관여시키는 컴퓨터 시스템."}
{"patent_id": "10-2015-7029066", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_29", "content": "제26항에 있어서,상기 응답 오디오 출력 판단 수단은, 인공 지능 엔진, 기계 학습 분류기, 판단 트리, 상태 전이 다이어그램, 마르코프 모델 또는 베이지안 분류기 중 하나를 포함하는,사용자를 합성 캐릭터와의 대화에 관여시키는 컴퓨터 시스템."}
{"patent_id": "10-2015-7029066", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_30", "content": "제26항에 있어서,상기 합성 캐릭터 이야기 수단은, 스피커, 이동 장치에서의 스피커에 대한 연결, 사용자 장치와 통신하는 WiFi송신기, 패킷 송신 모듈, 사용자 장치와 통신하는 휴대 전화 네트워크 송신기, 사용자 장치와 통신하는 이더넷연결, 사용자 장치와 통신하는 무선 송신기 또는 사용자 장치와 통신하는 LAN 연결 중 하나를 포함하는,사용자를 합성 캐릭터와의 대화에 관여시키는 컴퓨터 시스템."}
{"patent_id": "10-2015-7029066", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "다양한 개시된 실시예는 대화 기반의 인간-컴퓨터 상호 작용을 위한 시스템 및 방법에 관련된다. 일부 실시예에 서, 시스템은 복수의 상호 작용 장면을 포함한다. 사용자는 각각의 장면을 액세스할 수 있고 그 능동적인 장면과 관련된 활동에 관하여 합성 캐릭터와의 대화에 관여할 수 있다. 소정의 실시예에서, 중앙 서버는 합성 캐릭터의 음성과 관련된 복수의 파형을 보관하고, 인공 지능의 동작과 함께 사용자 장치에 파형을 동적으로 전달할 수 있 다. 일부 실시예에서, 캐릭터의 음성은 텍스트를 음성으로 변환하는(text-to-speech) 유틸리티로 생성된다."}
{"patent_id": "10-2015-7029066", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "[관련 출원에 대한 교차 참조] 본 출원은 본 명세서에 전문이 참조로서 편입되는 2013년 3월 14일 출원된 미국 특허 출원 제13/829,925호에 대 한 우선권을 주장한다. ["}
{"patent_id": "10-2015-7029066", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "] 다양한 개시된 실시예들은 대화 기반의 인간-컴퓨터 상호 작용을 위한 시스템 및 방법에 관한 것이다. 배 경 기 술 인간 컴퓨터 상호 작용(Human computer interaction; HCI)는, 컴퓨터 공학, 인지 과학, 인터페이스 설계 및 많 은 다른 분야에 집중하는, 인간과 컴퓨터 사이의 상호 작용을 수반한다. 인공 지능(AI)은 컴퓨터 시스템이 사용 자의 입력에 유기적으로 응답하도록 허용하는 적응적 행동을 포함하는 다른 발전하는 지식 분야이다. 가능하게 는 사용자와의 상호 작용을 위하여 합성 캐릭터(synthetic character)를 제공함으로써, AI가 HCI를 증강시키는 데 사용될 수 있지만, AI가 의문이 있다면, 상호 작용은 사용자에게 진부하거나 인공적인 것으로 보일 수 있다. 이것은 AI가 상호 작용과 관련된 상황 요인을 해명하지 못하거나 AI가 사용자와 상호 작용할 때 \"실물과 같은 (life-like)\" 모습을 유지하지 못하는 경우에 특히 그렇다. 대화는, 인간-인간 상호 작용을 위한 우수한 방법이 지만, 대화의 상황적이고 본질적인 모호한 특성 때문에 AI 시스템에 대하여 특히 문제가 될 수 있다. 심지어 무 생물 캐릭터를 살아 있는 엔티티로서 더욱 손쉽게 수용할 수 있는 어린이도 언제 대화적 AI가 HCI 상황과의 관 계를 끊었는지를 인식할 수 있다. HCI를 통해 어린이를 가르치고 관심을 끄는 것은 매우 바람직할 수 있지만, 생명이 없고 상황적으로 무지한 AI 행동이라는 장애물을 극복하여야 한다.따라서, 대화 다이얼로그의 과제를 수용하는 사용자, 특히 더 어린 사용자에게 효율적인 HCI 상호 작용을 제공 하기 위한 시스템 및 방법에 대한 요구가 존재한다. 소정의 실시예는 사용자를 합성 캐릭터와의 대화에 관여시키는 방법을 고려하며, 방법은, 사용자로부터 음성을 포함하는 오디오 입력을 수신하는 단계; 음성에 대한 문자 설명을 획득하는 단계; 문자 설명에 기초하여 응답 오디오 출력을 판단하는 단계; 및 합성 캐릭터가 판단된 응답 오디오 출력을 이용하여 이야기하게 하는 단계를 포함한다. 일부 실시예에서, 방법은, 사용자로부터의 음성을 포함하는 복수의 오디오 입력을 수신하는 단계를 더 포함하고, 복수의 오디오 입력은 하나 이상의 합성 캐릭터로부터의 복수의 이야기된 출력과 관련된다. 일부 실 시예에서, 복수의 오디오 입력은 하나 이상의 합성 캐릭터에 의해 제기된 질문에 대한 답변을 포함한다. 일부 실시예에서, 복수의 오디오 입력은 문자의 내레이션(narration)을 포함하고, 하나 이상의 합성 캐릭터로부터의 복수의 이야기된 출력은 내래이션에 대한 애드리빙(ad-libbing) 또는 코멘터리(commentary)를 포함한다. 일부 실시예에서, 복수의 오디오 입력은 주제에 관한 대화에서의 진술을 포함한다. 일부 실시예에서, 음성에 대한 문 자 설명을 획득하는 단계는, 전용 음성 처리 서비스로 오디오 입력을 전송하는 단계를 포함한다. 일부 실시예에 서, 오디오 입력을 수신하는 단계는, \"자동 음성 활동 검출(Automatic-Voice-Activity-Detection)\", \"말하려면 홀드(Hold-to-Talk)\", \"말하려면 탭(Tap-to-Talk)\" 또는 \"말하려면 탭(침묵 검출)(Tap-to-Talk-With-Silence- Detection)\" 동작 중 하나를 수행할지 판단하는 단계를 포함한다. 일부 실시예에서, 방법은, 판단된 오디오 입 력 동작을 반영하도록 아이콘을 수정하는 단계를 더 포함한다. 일부 실시예에서, 방법은, 판단된 오디오 입력 동작을 반영하도록 아이콘을 수정하는 단계를 더 포함한다. 일부 실시예에서, 응답 오디오 출력을 판단하는 단 계는 사용자 개인화 메타데이터를 판단하는 단계를 포함한다. 일부 실시예에서, 방법은 캐릭터의 안면 특징의 일부를 애니메이션화하는 목적으로 응답 오디오 출력과 관련된 음소 애니메이션 메타데이터를 획득하는 단계를 더 포함한다. 일부 실시예에서, 방법은, 판단된 오디오 입력 동작을 반영하도록 아이콘을 수정하는 단계와, 사 용자로부터의 복수의 응답을 리뷰하고, 리뷰에 기초하여 사용자-캐릭터 대화보다 더 많은 캐릭터간 대화를 수행 하는 단계를 더 포함한다. 일부 실시예에서, 방법은, 우선 순위 메타데이터를 합성 캐릭터에 대한 각각의 잠재 적인 응답에 관련시키고, 하나의 가능한 응답이 다른 응답 전에 출력되게 하도록 우선 순위 메타데이터를 이용 하는 단계를 더 포함한다. 일부 실시예에서, 합성 캐릭터가 판단된 응답 오디오 출력을 이용하여 이야기하게 하 는 단계는, 합성 캐릭터가 사용자 장치를 이용하여 사진을 찍는 것을 제안하게 하는 단계를 포함한다. 일부 실 시예에서, 방법은, 사용자 장치를 이용하여, 사용자에 대하여 사진이 찍히게 하는 단계; 및 사진을 소셜 네트워 크의 하나 이상의 사용자에게 전송하는 단계를 더 포함한다. 소정의 실시예는, 사용자에 의해 선택된 상호 작용 장면과 관련된 복수의 컴포넌트를 검색하는 단계; 장면에서 합성 캐릭터를 나타내도록 복수의 컴포넌트 중 적어도 하나를 구성하는 단계; 및 복수의 컴포넌트의 적어도 일 부를 사용자 장치에 전송하는 단계를 포함하는, 사용자를 합성 캐릭터와의 대화에 시각적으로 관여시키는 방법 을 고려한다. 일부 실시예에서, 방법은 사용자와 관련된 개인화 메타데이터를 검색하고, 개인화 메타데이터에 기초하여 복수 의 컴포넌트 중 적어도 하나를 수정하는 단계를 더 포함한다. 일부 실시예에서, 복수의 컴포넌트를 검색하는 단 계는, 데이터베이스로부터 복수의 음성 파형을 검색하는 단계를 포함한다. 소정의 실시예는, 사용자를 합성 캐릭터와의 대화에 관여시키는 컴퓨터 시스템를 고려하고, 시스템은, 디스플레 이; 프로세서; 통신 포트; 및 명령어를 포함하는 메모리를 포함하고, 명령어는, 프로세서가, 사용자로부터 음성 을 포함하는 오디오 입력을 수신하고; 음성에 대한 문자 설명을 획득하고; 문자 설명에 기초하여 응답 오디오 출력을 판단하고; 그리고, 합성 캐릭터가 판단된 상기 응답 오디오 출력을 이용하여 이야기하게 하도록 구성된다. 일부 실시예에서, 오디오 입력을 수신하는 것은, \"자동 음성 활동 검출(Automatic-Voice-Activity- Detection)\", \"말하려면 홀드(Hold-to-Talk)\", \"말하려면 탭(Tap-to-Talk)\" 또는 \"말하려면 탭(침묵 검 출)(Tap-to-Talk-With-Silence-Detection)\" 동작 중 하나를 수행할지 판단하는 것을 포함한다. 일부 실시예에 서, 명령어는, 프로세서가, 판단된 동작을 반영하도록 아이콘을 수정하게 하도록 구성된다. 일부 실시예에서, 응답 오디오 출력을 판단하는 것은, 사용자 개인화 메타데이터를 판단하는 것을 포함한다. 일부 실시예에서, 명 령어는, 프로세서가, 캐릭터의 안면 특징의 일부를 애니메이션화하는 목적으로 응답 오디오 출력과 관련된 음소 메타데이터를 획득하게 하도록 구성된다. 일부 실시예에서, 명령어는, 프로세서가, 사용자로부터의 복수의 응답 을 리뷰하고, 리뷰에 기초하여 사용자-캐릭터 대화보다 더 많은 캐릭터간 대화를 수행하게 하도록 구성된다. 일 부 실시예에서, 명령어는, 프로세서가, 우선 순위 메타데이터를 합성 캐릭터에 대한 각각의 잠재적인 응답에 관 련시키고, 하나의 가능한 응답이 다른 응답 전에 출력되게 하기 위하여 우선 순위 메타데이터를 이용하게 하도 록 구성된다. 일부 실시예에서, 합성 캐릭터가 판단된 응답 오디오 출력을 이용하여 이야기하게 하는 것은, 합 성 캐릭터가 사용자 장치를 이용하여 사진을 찍는 것을 제안하게 하는 것을 포함한다. 소정의 실시예는, 사용자를 합성 캐릭터와의 대화에 관여시키는 컴퓨터 시스템을 고려하며, 컴퓨터 시스템은, 사용자로부터 음성을 포함하는 오디오 입력을 수신하는 오디오 입력 수신 수단; 음성에 대한 설명을 판단하는 음성 설명 판단 수단; 설명에 기초하여 응답 오디오 출력을 판단하는 응답 오디오 출력 판단 수단; 및 합성 캐 릭터가 판단된 응답 오디오 출력을 이용하여 이야기하게 하는 합성 캐릭터 이야기 수단을 포함한다. 일부 실시예에서, 상기 오디오 입력 수신 수단은, 마이크, 패킷 수신 모듈, WiFi 수신기, 휴대 전화 네트워크 수신기, 이더넷 연결, 무선 수신기, LAN 연결 또는 수송 가능한 메모리 저장 장치에 대한 인터페이스 중 하나를 포함한다. 일부 실시예에서, 음성 설명 판단 수단은, 전용 음성 처리 서버에 대한 연결, 자연어 처리 프로그램, 음성 인식 시스템, 은닉 마르코프 모델(Hidden Markov Model) 또는 베이지안 분류기(Bayesian Classifier) 중 하나를 포함한다. 일부 실시예에서, 응답 오디오 출력 판단 수단은, 인공 지능 엔진, 기계 학습 분류기, 판단 트리, 상태 전이 다이어그램, 마르코프 모델 또는 베이지안 분류기 중 하나를 포함한다. 일부 실시예에서, 합성 캐릭터 이야기 수단은, 스피커, 이동 장치에서의 스피커에 대한 연결, 사용자 장치와 통신하는 WiFi 송신기, 패 킷 송신 모듈, 사용자 장치와 통신하는 휴대 전화 네트워크 송신기, 사용자 장치와 통신하는 이더넷 연결, 사용 자 장치와 통신하는 무선 송신기 또는 사용자 장치와 통신하는 LAN 연결 중 하나를 포함한다."}
{"patent_id": "10-2015-7029066", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "다음의 설명 및 도면은 예시적인 것이며, 한정하는 것으로 고려되지 않는다. 다양한 특정 상세가 개시 내용의 완전한 이해를 제공하기 위하여 설명된다. 그러나, 소정의 경우에, 잘 알려진 상세는 설명을 흐리게 하는 것을 방지하기 위하여 설명되지 않는다. 본 개시 내용에서 하나 또는 일 실시예에 대한 언급은 동일한 실시예에 대한 참조일 수 있으나 반드시 그러한 것은 아니며, 이러한 참조는 실시예들 중 적어도 하나를 의미한다. 본 명세서에서 \"하나의 실시예\" 또는 \"일 실시예\"에 대한 언급은 그 실시예와 관련되어 설명되는 특정 특징, 구 조 또는 특성이 본 개시 내용의 적어도 하나의 실시예에 포함된다는 것을 의미한다. 본 명세서에서의 다양한 곳 에서의 \"일 실시예에서\"라는 어구의 출현은 반드시 모두 동일한 실시예를 가리키는 것이 아니며, 다른 실시예를 상호 배제하는 별도의 또는 대체적인 실시예도 아니다. 더하여, 일부 실시예에 의해 발현될 수 있지만 다른 실 시예에 의해서는 발현되지 않을 수 있는 다양한 특징이 설명된다. 유사하게, 일부 실시예를 위한 요건일 수는 있지만 다른 실시예를 위한 요건이 아닐 수 있는 다양한 요건이 설명된다. 본 명세서에서 사용되는 용어는 일반적으로, 본 개시 내용에서의 상황에서 그리고 각 용어가 사용되는 특정 상 황에서, 본 발명이 속하는 기술 분야에서의 보통의 의미를 갖는다. 본 개시 내용의 설명에 관한 실시자에게 추 가의 안내를 제공하기 위하여, 본 개시 내용을 설명하는데 사용되는 소정의 용어가 아래에서 또는 본 명세서의 다른 부분에서 논의된다. 편의를 위하여, 소정의 용어는, 예를 들어, 대문자, 이탤릭체 및/또는 따옴표를 이용 하여 강조될 수 있다. 강조의 사용은 용어의 의미 및 범위에 영향을 미치지 않는다; 용어의 의미 및 범위는, 강 조 여부에 관계없이, 동일한 상황에서 동일하다. 동일한 요소가 2 이상의 방식으로 설명될 수 있다는 것이 이해 될 것이다. 결과적으로, 다른 표현 또는 동의어가 여기에서 논의되는 임의의 하나 이상의 용어에 대하여 사용될 수 있고, 용어가 여기에서 상술되거나 논의되는지 여부에 대하여 어떠한 특정의 중요성을 두지 않는다. 소정의 용어에 대한 동의어가 제공된다. 하나 이상의 동의어의 설명은 다른 동의어의 사용을 배제하지 않는다. 여기에서 논의되 는 임의의 용어에 대한 예를 포함하는 본 명세서에서의 어디에서든 예의 사용은 단지 예시적이며, 본 개시 내용 또는 임의의 예시적인 용어에 대한 의미 및 범위를 더 제한하려고 의도되지 않는다. 유사하게, 본 개시 내용은 본 명세서에 제공된 다양한 실시예에 한정되지 않는다. 본 개시 내용의 범위를 더 제한하려는 의도 없이, 본 개시 내용의 실시예들에 따른 설비, 장치, 방법 및 이들의 관련된 결과의 예가 아래에 주어진다. 제목 또는 부제가 독자의 편의를 위하여 예에서 사용될 수 있고, 이는 어 떠한 방식으로도 본 개시 내용의 범위를 제한하여서는 안 된다는 것에 주목하라. 달리 정의되지 않는다면, 여기 에서 사용된 모든 기술적 과학적 용어는 본 개시 내용이 관련되는 기술 분야에서 통상의 지식을 가진 자에 의해 일반적으로 이해되는 것과 동일한 의미를 가진다. 상충하는 경우, 정의를 포함하는 본 문헌이 지배할 것이다. 시스템 개요 소정의 개시된 실시예는 대화 기반의 인간-컴퓨터 상호 작용을 위한 시스템 및 방법에 관련된다. 일부 실시예에 서, 시스템은 가상 환경에서 복수의 상호 작용 장면을 포함한다. 사용자는 각각의 장면을 액세스할 수 있고 그 능동적인 장면과 관련된 활동에 관하여 합성 캐릭터와의 대화에 관여할 수 있다. 소정의 실시예에서, 중앙 서버 는 합성 캐릭터의 음성과 관련된 복수의 파형을 보관하고, 인공 지능의 동작과 함께 사용자 장치에 파형을 동적 으로 전달할 수 있다. 일부 실시예에서, 음성은 서버로부터의 파형이 사용 가능하지 않거나 검색하기에 비효율 적일 때, 텍스트를 음성으로 변환하는(text-to-speech) 유틸리티로 생성된다. 도 1은 소정의 실시예에서 구현될 수 있는 바와 같은 시스템 내의 다양한 컴포넌트의 블록도를 도시한다. 일부 실시예에서, 호스트 서버 시스템은 다양한 개시된 특징을 수행할 수 있으며, 네트워크(108a-b)를 통해 사 용자 장치(110a-b)와 통신할 수 있다. 일부 실시예에서, 네트워크(108a-b)는 동일한 네트워크이며, 인터넷, LAN(Local Area Network), 로컬 WiFi 애드혹 네트워크 등과 같은 일반적인 네트워크일 수 있다. 일부 실시예에 서, 네트워크는 셀룰러 타워(107a-b) 및 사용자 장치(110a-b)로부터의 송신을 포함한다. 사용자(112a-b)는 사용 자 인터페이스(109a-b)를 이용하여 자신의 해당하는 장치에서의 로컬 애플리케이션과 상호 작용할 수 있다. 일 부 실시예에서, 사용자는 로컬 애플리케이션을 통해 서버와 통신할 수 있다. 로컬 애플리케이션은 단독형 (stand-alone) 소프트웨어 프로그램일 수 있으며, 또는, 예를 들어 인터넷 브라우저로서, 최소의 전문적인 로컬 프로세싱으로 서버로부터 정보를 제공할 수 있다. 서버는 개시된 다양한 과정을 구현하기 위하여 복수의 소프트웨어, 펌웨어 및/또는 하드웨어 모듈을 포함 할 수 있다. 예를 들어, 서버는 다양한 기능을 수행하기 위하여 동적 라이브러리와 같은 복수의 시스템 도구 를 포함할 수 있다. 음성 데이터 및 애니메이션(animation) 데이터를 저장하기 위한 데이터베이 스뿐만 아니라, 메타데이터(metadata)를 저장하기 위한 데이터베이스도 포함될 수 있다. 또한, 일부 실시 예에서, 서버는 사용자 장치(110a-b)로부터의 자산(asset) 요청에 대한 더욱 효율적인 응답 시간을 가능하 게 하기 위하여 캐시를 포함할 수 있다. 소정의 실시예에서, 서버는 장치가 가상 환경에서 사용자와의 상호 작용을 위하여 합성 캐릭터를 생성하도 록 사용자 장치(110a-b)에 자산을 제공하는 서비스를 호스팅할 수 있다. 일부 실시예에서, 가상 환경의 동작은 사용자 장치(110a-b) 및 서버 사이에 분포될 수 있다. 예를 들어, 일부 실시예에서, 가상 환경 및/또는 AI 로직은 서버에서 실행될 수 있고, 사용자 장치는 결과를 디스플레이하기에 충분한 정보만을 요청할 수 있 다. 다른 실시예에서, 가상 환경 및/또는 AI는 사용자 장치(110a-b)에 지배적으로 실행될 수 있고, 새로운 자산 을 획득하기 위하여 단지 불규칙하게 서버와 통신할 수 있다.가상 환경 토폴러지 도 2는 소정의 실시예에서 사용될 수 있는 바와 같은 가상 환경에서의 복수의 상호 작용 장면 사이의 토폴러지 관계를 도시한다. 이 예에서, 3개의 상호 작용 장면 A, B, C(201a-c)과, 사용자가 상호 작용 세션을 시작할 수 있는 주요 장면(201d)이 있다. 일부 실시예에서, 장면은 가정에서의 \"방(room)\" 또는 게임 쇼(game show)에서의 상이한 \"게임\"을 포함할 수 있다. 각각의 상호 작용 장면은 고유의 상황을 제공할 수 있으며, 다른 장면에 공통 인 일부 요소와 고유한 일부 요소를 포함할 수 있다. 사용자는, 전이(202c-e)의 경우에서와 같이, 제한 없이 일 부 장면으로부터 전이할 수 있다. 그러나, 일부 전이는 장면 A(201a)에서 장면 B(202b)로의 전이 및 장면 C(201c)에서 장면 A(202a)로의 전이와 같이 단방향일 수 있다. 일부 실시예에서, 사용자는 음성으로 표시되는 합성 캐릭터 제안과의 동의 또는 구두 명령(oral command)에 의해 장면 사이에서 전이한다. 일부 실시예에서, 사용자는, 대화 AI 로직이 새로운 장면에 대하여 다시 초기화되고 구성될 수 있도록, 상호 작 용의 뒤를 이어 주요 장면(201d)으로 복귀할 필요가 있을 수 있다. 예시적인 가상 환경 장면 도 3은 소정의 실시예에서 구현될 수 있는 바와 같은 가상 환경에서의 주요 장면의 그래픽 사용자 인터페이스 (GUI)의 예시적인 스크린샷을 도시한다. 일부 실시예에서, GUI는 이동 전화기의 디스플레이 스크린 또는 이동 전화기나 태블릿 장치의 터치 스크린 상에서와 같은 인터페이스(109a-b)에 나타날 수 있다. 이 예에서 예 시된 바와 같이, GUI는 합성 캐릭터에 대한 제1 표시(301a) 및 제2 표시(301b), 사용자 그래픽(304a)이나 개별 정적 또는 실시간 사용자 비디오(304b)를 갖는 메뉴 바 및 음성 인터페이스를 포함할 수 있다. 메뉴는 사용자에게 시각적이고 기능적인 연속성을 제공하기 위하여 가상 환경의 모든 장면에 걸쳐 공통 요 소를 묘사한다. 음성 인터페이스는 합성 캐릭터(301a-b)로부터의 질문에 응답하는데 사용될 수 있다. 예를 들어, 일부 실시예에서, 사용자는 응답을 수신하기 위하여 마이크를 활성화하도록 인터페이스를 터치할 수 있다. 다른 실시예에서, 인터페이스는 사용자가 일부 다른 입력 장치를 선택할 때 밝아지거나 아니면 활성 인 상태를 나타낼 수 있다. 일부 실시예에서, 인터페이스는 녹음이 시스템에 의해 개시될 때 자동으로 밝 아질 수 있다. 일부 실시예에서, 실시간 사용자 비디오(304b)는 사용자 장치를 사용할 때, 가능하게는 사용자 장치와 통신하는 카메라로 획득된, 실시간 또는 거의 실시간인 사용자의 이미지를 묘사한다. 도 3에 표시된 바와 같이, 사용자의 묘사는, 예를 들어, 얼굴의 털, 가발, 모자, 귀걸이 등을 실시간 비디오 이미지에 오버레이함으로써, 시스템에 의해 수정될 수 있다. 오버레이는 가상 환경에서 발생하는 활동에 응답하여, 그리고/또는 합성 캐릭터와의 대화 에 의해 생성될 수 있다. 예를 들어, 상호 작용이 해적 모험 중인 사용자를 포함하는 것과 같은 롤플레잉(role- playing)과 관련될 때, 사용자의 이미지는 해적 모자, 해골과 뼈, 또는 상호 작용에 밀접한 관련이 있는 유사한 자산으로 오버레이될 수 있다. 일부 실시예에서, 사용자 그래픽(304a)은 사용자의 정적 이미지이다. 애플리케이 션 설정 동안, 시스템은 사용자의 이미지를 얻고 사용자 그래픽(304a)으로서 제공될 \"표준\" 또는 \"디폴트\" 이미 지로서 이미지를 보관할 수 있다. 그러나, 본 명세서에서 더욱 상세히 설명되는 바와 같이, 일부 실시예에서, 사용자는 오버레이된 그래픽을 갖는 이미지가 사용자 그래픽(304a)을 대체하도록 선택할 수 있다. 일부 실시예 에서, 사용자는 자기 주도적으로 사용자 그래픽(304a)을 대체할 수 있다. 일부 실시예에서, 상호 작용은 사용자가 사용자 장치에 의해 사진을 찍는 것을 활성화하도록 또는 시스템이 사 용자의 사진을 자동으로 찍도록, 하나 이상의 합성 캐릭터에 의한 제안이나 초대를 포함할 수 있다. 예를 들어, 해적 상호 작용을 개시하는 것에 따라 그리고 먼저 사용자에게 해적 모자를 제공한 후에, 합성 캐릭터는 사용자 의 모습에 코멘트하고 사용자 장치에 위치된 카메라를 이용하여 사용자의 이미지를 캡처하도록 제안할 수 있다.사용자가 동의하는 응답을 하면, 시스템은 이미지를 캡처하고, 영구적으로 또는 해적 상호 작용의 일부 부분 동 안, 이미지를 보관하거나 사용자 그래픽(304a)을 대체하도록 이미지를 사용할 수 있다. 일부 실시예에서, 동일 하거나 대응하는 그래픽이 합성 캐릭터의 이미지에 오버레이될 수 있다. 본 명세서에서 더욱 상세히 설명되는 바와 같이, 장면의 다른 요소와 상호 작용하기 위해서뿐만 아니라 대화하 고 있는 것을 나타내기 위하여, 합성 캐릭터(301a-b)는 다양한 애니메이션을 수행할 수 있다. 도 4는 소정의 실시예에서 구현될 수 있는 바와 같은 가상 환경에서의 \"노변 환담(fireside chat) 장면\" GUI의 예시적인 스크린샷을 도시한다. 배경에서의 요소는 사용자가 어느 장면에 현재 있는지 사용자 에게 나타낼 수 있다. 이 예에서, 사용자의 이미지, 가능하게는 사용자의 장치에서의 카메라를 이용하여 획득된 실시간 이미지가 사용될 수 있다. 합성 캐릭터(301b)와 같은 합성 캐릭터는 상호 작용 전체에 걸쳐 사용 자에게 질문을 제기할 수 있고, 사용자는 음성 인터페이스를 이용하여 응답할 수 있다. 문자 박스는 대화의 주제 및 성질(예를 들어, \"학교\")을 나타내는데 사용될 수 있다. 도 5는 소정의 실시예에서 구현될 수 있는 바와 같은 가상 환경에서의 \"대비(versus) 장면\" GUI의 예시적 인 스크린샷을 도시한다. 이 예에서, 합성 캐릭터가 GUI에 보이지 않지만, 시스템은 여전히 질문을 제시하 고(가능하게는 합성 캐릭터의 음성으로), 사용자로부터 응답 및 진술을 수신할 수 있다. 이 장면에서, 스크롤링 헤더(504a)가 대화에 관련된 상황적 정보를 나타내기 위하여 사용될 수 있다. 이 예에서, 요소에 표시된 사용자는 상대 이미지에 표시된 해적과 재치 대결을 한다. 문자 박스(502a-b)는 시스템에 의해 제기되는 질문과, 사용자에 의해 제공될 수 있거나 제공되는 것으로 기대되는 가능한 대답을 나타내는데 사용될 수 있다. 도 6은 소정의 실시예에서 구현될 수 있는 바와 같은 가상 환경에서의 \"게임 쇼(game show) 장면\" GUI의 예시적 인 스크린샷을 도시한다. 이 장면에서, 합성 캐릭터(301b)는 게임 쇼를 진행할 수 있고, 사용자는 참가자이다. 합성 캐릭터(301b)는 사용자에게 질문을 제기할 수 있다. 기대되는 답은 문자 박스(602a-c)에 제공될 수 있다. 합성 캐릭터(301c)는 합성 캐릭터(301b)와 상이한 합성 캐릭터일 수 있거나, 동일한 캐릭터의 별도의 애니메이 션으로 동작하는 예시일 수 있다. 합성 캐릭터(301c)는 사용자에게 질문을 제기할 수 있다. 타이틀 스크린(60 3)이 콘테스트의 성질을 나타내는데 사용될 수 있다. 사용자의 이미지는 실시간 또는 거의 실시간으로 영역 에 디스플레이될 수 있다. 도 7은 소정의 실시예에서 구현될 수 있는 바와 같은 가상 환경에서의 \"이야기 하기(story telling) 장면\" GUI의 예시적인 스크린샷을 도시한다. 이 장면에서, GUI는 문자 영역과 그래픽 영역으로 분할될 수 있다. 합성 캐릭터(301a-b)는 각각의 영역(701, 702)이 업데이트됨에 따라 이야기의 일부를 내래이션 하거나(narrate) 롤플레잉할 수 있다. 캐릭터(301a-b)는, 가능하게는 롤플레잉 과정의 일부로서, 서로 대화할 수 있고, 주기적으로 사용자와 대화할 수 있다. 일부 실시예에서, 사용자는 영역에서 본문을 읽고, 캐릭터 (301a-b)는 이야기의 부분에 따라 또는 사용자의 읽기에 따라 애드립을 하거나 코멘트한다. 사용자 상호 작용 도 8은 소정의 실시예에서 구현될 수 있는 바와 같은 가상 환경에서의 사용자 상호 작용 과정에서의 소정의 단 계들을 도시하는 플로우 차트이다. 단계 801에서, 시스템은 도 3에 도시된 바와 같은 주요 장면을 사용자에게 제공할 수 있다. 단계 802에서, 시스템은 상호 작용 장면에 대한 사용자 선택(예를 들어, 구두(oral) 선택)을 수신할 수 있다. 일부 경우에, 입력은 그래픽 아이콘에 관련된 터치 또는 스와이프(swipe)를 포함할 수 있지만, 다른 경우에, 입력은 합성 캐릭터로부터의 질의에 대한 응답과 같은 사용자에 의한 구두 응답일 수 있다. 단계 803에서, 시스템은 선택된 상호 작용 장면을 사용자에게 제공할 수 있다.단계 804에서, 시스템은 기준에 기초하여 사용자를 대화 시컨스에 관여시킬 수 있다. 기준은 사용자와의 이전 대화 및 사회적 정보 또는 사용자와의 이전 상호 작용에 기초하여 생성된 통계 데이터베이스를 포함할 수 있다. 단계 805에서, 시스템은 사용자가 선택된 장면과 관련된 활동을 반복하기 원하는지 판단할 수 있다. 예를 들어, 합성 캐릭터는 사용자의 선호에 관하여 질의할 수 있다. 사용자가, 아마도 구두로 또는 촉각 입력을 통해, 동일 한 활동을 계속하도록 선택하면, 시스템은 이전과 동일한 기준을 이용하여 활동을 반복할 수 있거나, 또는 단계 806은 이전 대화 히스토리를 반영하도록 기준을 수정할 수 있다. 이 대신에, 사용자가 활동을 반복하기 원하지 않으면, 단계 807에서 시스템은 사용자가 그만두기를 원하는지 판 단할 수 있다. 사용자가 그만두기 원하지 않으면, 역시 가능하게는 합성 캐릭터와의 상호 작용을 통하여, 단계 802에서 시스템은 사용자가 어느 상호 작용 장면에 들어가기 원하는지 다시 판단한다. 단계 802에서 주요 장면 에 들어가기 전 또는 후에, 시스템은 또한 이전 대화 및 사용자의 개인 특성에 기초하여 기준을 수정할 수 있다. 일부 실시예에서, 사용자는 맵(map) 인터페이스를 이용하여 장면 사이에 전이한다. 일부 실시예에서, 소정의 기준이 충족될 때에만 사용될 수 있도록, 컨텐츠는 태그가 붙여질 수 있다. 이것은 시 스템이 사용자에게 맞추어진 컨텐츠를 제공할 수 있게 한다. 기준에 대한 예시적인 필드는 다음을 포함할 수 있 다: 반복(Repeat) - 캐릭터가 어떤 것을 반복하고 있을 때 사용하기 위한 대체적인 응답; 한 번만(Once Only) - 이 응답을 한 번만 사용하고, 예를 들어, 절대 이를 반복하지 않음; 연령(Age) - 사용자의 연령이 특정 범위 내 에 있는 경우에만 응답을 사용; 성별(Gender) - 사용자의 성별이 남성 또는 여성인 경우에만 응답을 사용; 날짜 (Day) - 현재 날짜가 특정일과 일치하는 경우에만 응답을 이용; 시간(Time) - 현재 시간이 시간 범위 내에 있는 경우에만 응답을 이용; 마지막 활동(Last-Activity) - 이전 활동이 특정 활동과 일치하는 경우에 응답을 사용; 플레이된 분(Minute Played) - 사용자가 플레이에 대하여 제공된 분의 수량을 초과한 경우에 응답을 사용; 지역 (Region) - 사용자가 주어진 지리적 지역에 있는 경우에 응답을 사용; 마지막 플레이(Last Played) - 사용자가 주어진 일수 동안 서비스를 사용하지 않은 경우에 응답을 사용; 등. 합성 캐릭터에 의해 사용되는 응답은 AI 엔 진이 장래에 반복 응답을 제공하는 것을 방지하도록 시스템에 의해 타임 스탬핑되어(timestamped) 기록될 수 있 다. 사용자는 개인 정보의 저장을 용이하게 하기 위하여 사용자 계정과 관련될 수 있다. 또한, 기준은, 분석으로부터 유도될 수 있다. 일부 실시예에서, 시스템은 대화 세션 동안 발생하는 모든 주요 이벤트에 대한 통계를 로그한다. 이러한 통계는 서버에 로그될 수 있으며, 사용자가 서비스와 어떻게 상호 작용 하는지에 대하여 분석을 제공하도록 적합한 규모로 수집될 수 있다. 이는 컨텐츠에 대하여 업데이트를 하게 하 거나 또는 컨텐츠의 우선 순위를 변경시키게 하는데 사용될 수 있다. 예를 들어, 분석은 사용자가 다른 활동에 비해 어느 한 활동을 선호한다고 알려 줄 수 있어, 더욱 매력적인 컨텐츠가 장래의 사용자에 대하여 더욱 신속 하게 드러나게 할 수 있다. 일부 실시예에서, 컨텐츠에 대하여 이렇게 우선 순위를 다시 부여하는 것은, 사용자 로부터 로그된 데이터에 기초하여 적합한 규모로 자동으로 발생할 수 있다. 또한, 이전 대화의 분석을 통해서, 이들이 빈번하게 발생하기 때문에 집필(writing) 팀은 더 많은 집필을 요구 하는 주제에 대한 통찰력을 얻을 수 있다. 물론, 일부 컨텐츠는 다른 컨텐츠보다 더 웃기게 연출될 수 있다. 시 스템은 사용자의 관심과 주의를 붙잡기 위하여 \"최상의\" 컨텐츠를 초기에 사용하기 원할 수 있다. AI 또는 설계 자는 이에 따라 높은 우선 순위, 중간 우선 순위 또는 낮은 우선 순위로 컨텐츠에 태그를 붙일 수 있다. AI 엔 진은 일부 실시예에서 다른 컨텐츠보다 더 높은 우선 순위로 표시된 컨텐츠를 전달하는 것을 선호할 수 있다. 컴포넌트 관리 도 9는 소정의 실시예에서 구현될 수 있는 바와 같은 컴포넌트 기반 컨텐츠 관리 및 전달 과정에서의 소정 의 단계들을 도시하는 플로우 차트이다. 도 3 내지 7의 예시적인 장면의 각각에서, 문자 박스(305, 402, 502a-b, 602a-c), 타이틀 스크린, 사용자 이미지(401, 501, 501) 및 합성 캐릭터(301a-c)와 같은 다양한 요소 가 \"컴포넌트\"로서 시스템에 의해 다루어질 수 있다. 컴포넌트는 장면에서 나타나거나 사용될 수 있는 자산 (asset) 또는 자산의 모음(collection)을 지칭할 수 있다. 예를 들어, 컴포넌트는 다음을 포함할 수 있다: 이미 지 - 가능한 알파 투명도(alpha transparency)를 갖는 이미지 레이어; 사용자 비디오 피드 - 일부 실시예에서 카메라가 사용자에 대하여 계속 훈련되게 하기 위한 얼굴 추적을 이용하여, 장치의 카메라의 출력을 디스플레이 한다; 캐릭터 애니메이션 - 3D 기하 구조 또는 2D 이미지를 이용하여 애니메이션 처리되는 가상 캐릭터를 디스 플레이한다; 텍스트 뷰어 - 가상 캐릭터로부터의 마지막 질문에 대한 개요 또는 상태 텍스트를 디스플레이한다; 연속 텍스트 표시(Progressive Text Reveal) - 가상 캐릭터가 단어를 말할 때 단어를 나타내는데 사용된다; 이 미지 기반 애니메이션 - 번쩍이는 빛, 이동하는 그림 또는 컴포넌트 사이의 전이 등과 같은 이미지 기반의 아핀 (affine) 애니메이션을 디스플레이한다; 등. 장면에 들어감에 따라, 또는 그 전에, 시스템은 어느 컴포넌트가 상호 작용 경험에 관련되는지 판단할 수 있다. 그 다음, 서버는, 상호 작용 동안 사용을 위하여 로컬로 캐싱되도록, 사용자 장치(110a-b)에 컴포넌트 또 는 예상되는 컴포넌트의 일부를 제공할 수 있다. AI 엔진이 서버에서 동작하는 경우에, 서버는 어느 컴포넌트가 사용자 장치(110a-b)에 전송될지를 판단할 수 있다. AI 엔진이 사용자 장치(110a-b)에 동작하는 실 시예에서, 사용자 장치는 어느 컴포넌트를 서버로부터 요청할지 판단할 수 있다. 각각의 경우에, 일부 실시예에 서, AI 엔진은 사용자 장치(110a-b)에 이전에 로컬로 캐싱되지 않은 컴포넌트만을 전송되게 할 것이다. 과정을 참조하면, 단계 901에서, 시스템은, 가능하게는 서버 또는 사용자 장치와 통신하는 데이터베 이스로부터, 사용자 특성을 검색할 수 있다. 단계 902에서, 시스템은 상호 작용 장면과 관련된 컴포넌트를 검색 할 수 있다. 단계 903에서, 시스템은 컴포넌트 개인화 메타데이터를 판단할 수 있다. 예를 들어, 시스템은 합성 캐릭터의 행동 또는 대화 파라미터를 판단할 수 있거나, 또는, 가능하게는 전술한 바와 같이 기준을 이용하여, 소정의 컴포넌트와 관련될 이미지를 판단할 수 있다. 단계 905에서, 시스템은 상호 작용 세션을 개시한다, 상호 작용 세션 동안, 단계 906에서, 시스템은 상호 작용 통계를 로그할 수 있다. 상호 작용 세션 동안 단계 907에서, 또는 상호 작용 세션의 종결에 이어서 단계 909에서, 시스템은 상호 작용 통계를 보고할 수 있다. 도 10은 소정의 실시예에서 구현될 수 있는 바와 같은 컴포넌트 형성 및 관리 시스템을 위한 GUI의 예시 적인 스크린샷을 도시한다. 이러한 예시적인 인터페이스에서, 설계자는, \"노변 환담\"과 같은 다른 것은 특정 장 면에 고유하지만, 일부가 복수의 장면에 공통될 수 있는 카테고리 리스트를 형성할 수 있다. 각각의 카테 고리 내에서, 설계자는, 컴포넌트와 대화 요소 및 이 둘 사이의 상호 작용을 특정할 수 있다. 일부 실시예에서, 설계자는 대화 요소와 컴포넌트 사이의 관계를 나타낼 수 있고, 컴포넌트가 어느 선호 순서로 선택 되어야 하고, 전송되어야 하고, 우선 순위화되어야 하고, 상호 작용되어야 하는지 나타낼 수 있다. 다양한 도구 가 대화 및 컴포넌트 상호 작용을 편집하고 설계하는데 사용될 수 있고, 이는 텍스트 편집 또는 워드 프 로세싱 소프트웨어에 공통되는 요소(예를 들어, 맞춤법 검사, 텍스트 포맷팅 등)을 포함할 수 있다. GUI 를 이용하여, 설계자는 컴포넌트 선택을 통해서 대화 상호 작용을 연출할 수 있다. 예를 들어, 대답(602a-c)에 대한 컴포넌트를 특정함으로써, 시스템은 사용자가 이러한 단어 중 하나에 응답할 가능성을 증가시킬 수 있다. 자산 기대(Asset Anticipation) 도 11은 소정의 실시예에서 구현될 수 있는 바와 같은 동적 AI 대화 관리 과정에서의 소정의 단계들을 도시하는 플로우 차트이다. 단계 1101에서, 시스템은, 사용자와 하나 이상의 합성 캐릭터 사이에, 또는 대화가 비결정적 인 경우에 합성 캐릭터 사이에 발생할 수 있는 가능한 대화 경로를 예측할 수 있다. 단계 1102에서, 시스템은 데이터베이스로부터 N 음성 파형을 검색하여 사용자 장치(110a-b)에서 또는 서버 시스템에서 로컬로 이를 캐싱할 수 있다. 단계 1103에서, 시스템은 데이터베이스로부터 N 음성 파형에 대응하는 메타데이터를 검색하여사용자 장치(110a-b)에서 또는 서버 시스템에서 로컬로 이를 캐싱할 수 있다. 단계 1104에서, 시스템은 AI 엔진에 음성 파형과 로컬로 캐싱된 애니메이션 메타데이터를 통지할 수 있고, 애니메이션 메타데이터를 이용하 여 합성 캐릭터를 애니메이션화할 수 있다. 이러한 방식으로, AI 엔진은 사용자에게 제공될 컨텐츠의 선택에 있 어서 네트워크 지연(latency) 및/또는 자원 사용 가능성을 예측할 수 있다. 일부 실시예에서, 애니메이션은 파형과 관련된 음소(phoneme) 메타데이터에 의해 구동될 수 있다. 예를 들어, 타임스탬프가 턱과 입술의 운동과 같은 소정의 애니메이션을 파형의 대응하는 포인트와 상관시키는데 사용될 수 있다. 이러한 방식으로, 합성 캐릭터의 애니메이션은 시스템에 의해 선택된 파형에 동적으로 조정될 수 있다. 일부 실시예에서, 이 \"음소 메타데이터\"는 기존의 합성 캐릭터 애니메이션과 혼합되는 오프셋을 포함할 수 있다. 음소 메타데이터는 자산 형성 과정 동안 자동으로 생성될 수 있거나, 또는 애니메이터 또는 오디오 엔지 니어에 의해 명시적으로 생성될 수 있다. 파형이 텍스트를 음성으로 변환하는(text-to-speech) 프로그램에 의해 생성되는 경우에, 시스템은 생성된 파형과 관련된 음소 애니메이션 메타데이터를 생성하기 위한 음소 애니메이 션 메터데이터 모음으로부터의 요소를 결부시킬 수 있다. 불만(frustration) 관리 도 12는 소정의 실시예에서 구현될 수 있는 바와 같은 불만(frustration) 관리 과정에서의 소정의 단계들을 도 시하는 플로우 차트이다. 단계 1201에서, 시스템은 대화 로그를 모니터한다. 일부 실시예에서, 시스템은 이전에 존재하는 대화 기록을 모니터할 수 있다. 일부 실시예에서, 시스템은 현재 대화의 진행 중인 로그를 모니터할 수 있다. 모니터링의 일부로서, 시스템은 불만을 나타내는 것으로 사용자로부터 응답을 식별할 수 있고, 이에 따라 응답에 태그를 붙일 수 있다. 단계 1202에서, 시스템은 불만이 태그된 응답이 임계값을 초과하는지 아니면 응답이 사용자의 불만 레벨을 평가 하기 위한 기준을 충족하는지 판단할 수 있다. 사용자의 응답이 불만을 나타내면, 시스템은 단계 1203으로 진행 하여, 사용자의 불만에 관하여 AI 엔진에 통지할 수 있다. 응답하여, 단계 1204에서, AI 엔진은 불만을 누그러 뜨리는 것을 돕기 위하여 합성 캐릭터 사이에 상호 작용 파라미터를 조정할 수 있다. 예를 들어, 사용자를 응답 에 자주 관여시키는 대신에, 캐릭터가 좀 더 서로 상호 작용하려고 하거나, 또는 상호 작용의 흐름을 사용자를 관여시키는 것에 더 좋은 것으로 결정된 상황으로 자동으로 향하게 할 수 있다. 음성 인식 도 13은 소정의 실시예에서 구현될 수 있는 바와 같은 음성 수신(speech reception) 과정에서의 소정의 단계들을 도시하는 플로우 차트이다. 단계 1301에서, 시스템은 사용자에 의해 기대되는 응답의 캐릭터를 판단할 수 있다. 일부 실시예에서, 응답의 캐릭터는 바로 이전의 합성 캐릭터의 진술 및 질의에 기초하여 판단될 수 있 다. 단계 1302에서, 시스템은, \"말하려면 홀드(Hold-to-Talk)\" 기능이 적합한지 판단할 수 있다. 적합하다면, 시스 템은 단계 1305에서 \"말하려면 홀드\" 아이콘을 제공하고, 단계 1306에서 \"말하려면 홀드\" 동작을 수행할 수 있 다. \"말하려면 홀드\" 아이콘은 음성 인터페이스의 수정이거나 그에 가까운 아이콘으로서 나타날 수 있다. 일부 실시예에서, 아이콘이 제공되지 않고(예를 들어, 단계 1305는 건너뛴다), 시스템은 기존의 아이콘(들)을 이용하여 단계 1306에서 \"말하려면 홀드\"을 수행한다. \"말하려면 홀드\" 동작은 합성 캐릭터가 초기에 응답을 대 기하고 있을 때 사용자 장치의 마이크에서의 녹음이 디스에이블되는 과정을 포함할 수 있다. 음성 인터페이스 와 같은 아이콘을 선택한 것에 따라, 사용자 장치의 마이크에서 녹음하는 것이 이네이블될 수 있고, 사용 자는 합성 캐릭터와 연관된 대화에 응답할 수 있다. 사용자는 응답을 제공하는 것을 완료할 때까지 아이콘을 계 속하여 홀딩(예를 들어, 물리적으로 터치하거나 아니면 촉각 입력을 제공)할 수 있고, 그 다음 녹음을 완료하기위하여 아이콘을 해제할 수 있다. 단계 1303에서, 시스템은 \"말하려면 탭(Tap-to-Talk)\" 기능이 적합한지 판단할 수 있다. 적합하다면, 시스템은 단계 1307에서 \"말하려면 탭\" 아이콘을 제공하고, 단계 1308에서 \"말하려면 탭\" 동작을 수행할 수 있다. \"말하 려면 탭\" 아이콘은 음성 인터페이스의 수정이거나 그에 가까운 아이콘으로서 나타날 수 있다. 일부 실시예 에서, 아이콘이 제공되지 않고(예를 들어, 단계 1307는 건너뛴다), 시스템은 기존의 아이콘(들)을 이용하여 단 계 1308에서 \"말하려면 탭\"을 수행한다. \"말하려면 탭\" 동작은 합성 캐릭터가 초기에 응답을 대기하고 있을 때 사용자 장치의 마이크에서의 녹음이 디스에이블되는 과정을 포함할 수 있다. 음성 인터페이스와 같은 아이 콘을 선택한 것에 따라, 사용자 장치의 마이크에서 녹음하는 것이 이네이블될 수 있고, 사용자는 합성 캐릭터와 연관된 대화에 응답할 수 있다. 이 응답의 완료에 이어, 사용자는 녹음을 완료하고, 일부 실시예에서는 마이크 를 디스에이블하기 위하여, 아이콘, 아마도 초기에 선택된 것과 동일한 아이콘을 다시 선택할 수 있다. 단계 1304에서, 시스템은 \"말하려면 탭(침묵 검출)(Tap-to-Talk-With-Silence-Detection)\" 기능이 적합한지 판 단할 수 있다. 적합하다면, 시스템은 단계 1309에서 \"말하려면 탭(침묵 검출)\" 아이콘을 제공하고, 단계 1310에 서 \"말하려면 탭(침묵 검출)\" 동작을 수행할 수 있다. \"말하려면 탭(침묵 검출)\" 아이콘은 음성 인터페이스 의 수정이거나 그에 가까운 아이콘으로서 나타날 수 있다. 일부 실시예에서, 아이콘이 제공되지 않고(예를 들어, 단계 1309는 건너뛴다), 시스템은 기존의 아이콘(들)을 이용하여 단계 1310에서 \"말하려면 탭(침묵 검 출)\"을 수행한다. \"말하려면 탭(침묵 검출)\" 동작은 합성 캐릭터가 초기에 응답을 대기하고 있을 때 사용자 장 치의 마이크에서의 녹음이 디스에이블되는 과정을 포함할 수 있다. 음성 인터페이스와 같은 아이콘을 선택 한 것에 따라, 사용자 장치의 마이크에서 녹음하는 것이 이네이블될 수 있고, 사용자는 합성 캐릭터와 연관된 대화에 응답할 수 있다. 이 응답의 완료에 이어, 사용자는 마이크를 능동적으로 디스에이블하지 않고 침묵할 수 있다. 시스템은 연속된 침묵을 검출하여 소정의 임계 기간이 경과한 후에 녹음을 정지할 수 있다. 일부 실시예 에서, 녹음의 주파수 스펙트럼의 에너지를 측정함으로써 침묵이 검출될 수 있다. 시스템이 \"말하려면 홀드\", \"말하려면 탭\" 또는 \"말하려면 탭(침묵 검출)\"의 어느 것도 적합하다고 판단하지 않 으면, 시스템은 \"자동 음성 활동 검출(Automatic-Voice-Activity-Detection)\" 동작을 수행한다. \"자동 음성 활 동 검출\" 동안, 시스템은 사용자 장치에서, 마이크가 아직 활성되지 않았다면, 마이크를 활성화할 수 있다 . 그 다음, 단계 1312에서, 시스템은 음성이 존재하는지 판단하기 위하여 녹음된 오디오의 파워 및 주파 수를 분석할 수 있다. 음성이 소정의 임계 기간 동안 존재하지 않는다면, 시스템은 녹음을 종결할 수 있다. 사회적 자산 메시징 도 14는 소정의 실시예에서 구현될 수 있는 바와 같은 사회적 자산 공유 GUI의 예시적인 스크린샷을 도시한다. 이 실시예에서, 사용자 또는 사용자의 관련자와 같은 리뷰어가 합성 캐릭터와의 다양한 상호 작용 동안 캡처된 일련의 이미지를 제공받을 수 있다. 예를 들어, 이미지의 일부는 사용자에 의해 자발적으로 요청되었던 것일 수 있고, 모자 및/또는 얼굴의 털과 같은 사용자의 이미지에 대한 다양한 자산 오버레이를 묘사할 수 있다. 또한, 일부 실시예에서, 복수의 이미지는 다양한 상호 작용에서 다양한 순간에 사용자를 자동으로 찍은 이미지를 포함할 수 있다. 갤러리 컨트롤(1402, 1403)이 이미지, 가능하게는 사용자가 참가하는 상이한 시 나리오에 의해 조직화된 이미지의 상이한 모음으로부터 선택하는데 사용될 수 있다. 도 15는 소정의 실시예에서 구현될 수 있는 바와 같은 도 14의 사회적 자산 공유 GUI에서의 메시지 기안 (drafting) 도구의 예시적인 스크린샷을 도시한다. 공유하기 위한 이미지의 선택에 이어, 시스템은 팝업 디스플레이를 제공할 수 있다. 디스플레이는 선택된 이미지의 확대된 버전과 텍스트 입력을 받아들이기 위한 영역을 포함할 수 있다. 또한, 페이스북(Faceboook), 마이스페이스(MySpace), 트위터 (Twitter) 등과 같은 하나 이상의 메시지 매체를 선택하기 위한 입력이 제공될 수 있다. 사용자는 영역 내에 코멘터리(commentary) 문자를 입력할 수 있다. 공유 아이콘을 선택함으로써, 사용자는 이미지와 코멘터리 텍스트를 입력에 의해 특정된 커뮤니티와 공유할 수 있다. 일부 실시예에서, 메시지 기안 도구는 어린이 사용자의 부모에 의해 사용된다. 도 16은 소정의 실시예에서 구현될 수 있는 바와 같은 사회적 이미지 캡처 과정에서의 소정의 단계들을 도시하 는 플로우 차트이다. 단계 1601에서, 시스템은 이미지 캡처가 대화에 관련된다고 판단할 수 있다. 예를 들어, 사용자의 이미지(304b)에서(또는, 이미지(401, 501) 등에서) 소정의 자산을 오버레이하는 것을 포함하는 롤플레 잉 시컨스의 개시에 이어, 시스템은 자산이 오버레이된 이미지가 캡처되게 하도록 사용자를 고무시키기 위하여 키가 입력될 수 있다. 단계 1602에서의 사용자 이미지에서의 자산의 오버레이에 이어, 단계 1603에서 시스템은 사용자가 이미지 캡처에 관여하는 것을 제안할 수 있다. 제안은 가상 환경에서 합성 캐릭터 중 하나에 의해 이 루어질 수 있다. 단계 1604에서, 가능하게는 구두 응답을 통해, 사용자가 동의하면, 단계 1605에서, 시스템은 사용자의 이미지를 캡처할 수 있다. 그 다음, 시스템은 단계 1606에서 이미지를 저장할 수 있고, 단계 1607에서 리뷰를 위하여 캡처된 이미지를 제공할 수 있다. 이미지는 사용자에 의한, 또는 사용자의 어머니 또는 다른 가 족 구성원과 같은 다른 개인에 의한 리뷰를 위하여 제공될 수 있다. 단계 1608에서 리뷰 동안 이미지가 공유에 대하여 수락되면, 시스템은 단계 1609에서 공유를 위하여 캡처된 이미지를 선택된 소셜 네트워크에 전송할 수 있다. 컴퓨터 시스템 개요 다양한 실시예는 전술한 다양한 단계 및 동작을 포함한다. 다양한 이러한 단계 및 동작은 하드웨어 컴포넌트에 의해 수행될 수 있거나, 또는 명령어로 프로그래밍된 범용 또는 전용 프로세서가 단계를 수행하게 하도록 사용 될 수 있는 기계 실행 가능한 명령어로 구체화될 수 있다. 이 대신에, 단계들은 하드웨어, 소프트웨어 및/또는 펌웨어의 조합에 의해 수행될 수 있다. 이와 같이, 도 17은 소정의 개시된 실시예를 구현하는데 사용될 수 있는 컴퓨터 시스템의 일례이다. 다양한 개시된 특징은 컴퓨터 시스템 상에 위치될 수 있다. 본 예에 따 르면, 컴퓨터 시스템은 버스, 적어도 하나의 프로세서, 적어도 하나의 통신 포트, 메인 메모 리, 리무버블(removable) 저장 매체, 리드 온리 메모리 및 대량 저장소를 포함한다. 프로세서(들)는 Intel® Itanium® 또는 Itanium 2® 프로세서(들), 또는 AMD® Opteron® 또는 Athlon MP® 프로세서(들), 또는 Motorola®의 프로세스 라인을 포함하지만, 이에 한정되지 않는 임의의 공지된 프로세 서일 수 있다. 통신 포트(들)는 모뎀 기반의 다이얼업 연결과의 사용을 위한 RS-232 포트, 10/100 이더넷 포트, 또는 구리나 섬유를 이용하는 기가비트 포트 중 임의의 것일 수 있다. 통신 포트(들)는 LAN(Local Area Network), WAN(Wide Area Network) 또는 컴퓨터 시스템이 연결되는 임의의 네트워크와 같은 네트워 크에 따라 선택될 수 있다."}
{"patent_id": "10-2015-7029066", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "메인 메모리는 RAM(Random Access Memory) 또는 본 발명이 속하는 기술분야에서 일반적으로 알려진 임의 의 다른 동적 저장 장치(들)일 수 있다. 리드 온리 메모리는 프로세서를 위한 명령어와 같은 정적 정보를 저장하기 위한 PROM(Programmable Read Only Memory) 칩과 같은 임의의 정적 저장 장치(들)일 수 있다. 대량 저장소는 정보 및 명령어를 저장하는데 사용될 수 있다. 예를 들어, Adaptec® 계열의 SCSI 드라이 브와 같은 하드 디스크, 광 디스크, Adaptec 계열의 RAID 드라이브와 같은 예를 들어 RAID인 디스크 어레이, 또 는 임의의 다른 대량 저장소 장치가 사용될 수 있다. 버스는 프로세서(들)를 다른 메모리, 저장소 및 통신 블록에 통신 가능하게 연결한다. 버스 는 사용되는 저장 장치에 따라 PCI/PCI-X 또는 SCSI 기반의 시스템 버스일 수 있다.리무버블 저장 매체는 임의의 종류의 외부 하드 드라이브, 플로피 드라이브, IOMEGA® Zip 드라이브, CD- ROM(Compact Disc - Read Only Memory), CD-RW(Compact Disc - Re-Writable), DVD-ROM(Digital Video Disk - Read Only Memory)일 수 있다. 전술한 컴포넌트는 가능성 있는 일부 종류를 예시하는 것으로 의도된다. 단지 예시적인 실시예이기 때문에, 전 술한 예는 어떠한 방식으로도 본 발명의 범위를 한정하지 않는다. 본 발명의 하나 이상의 실시예에 대한 상세한 설명이 위에서 제공되었지만, 다양한 대체물, 수정물 및 균등물이 본 발명의 기술적 사상과 달라지지 않으면서 본 발명이 속하는 기술 분야에서 통상의 지식을 가진자에게 명백할 것이다. 예를 들어, 위에서 설명된 실시예가 특정 특징을 언급하지만, 본 발명의 범위는 특정의 상이한 조합을 갖는 실시예 및 설명된 특징을 모두 포함하지 않는 실시예도 포함한다. 따라서, 본 발명의 범위는 이러한 대체 물, 수정물 및 균등물을 모두 포함하는 것으로 의도된다. 그러므로, 전술한 설명은 본 발명의 범위를 제한하는 것으로 고려되어서는 안 된다. 비고 컴퓨터 판독 가능한 매체가 일 실시예에서 단일 매체인 것으로 나타내지만, \"컴퓨터 판독 가능한 매체\"라는 용 어는 하나 이상의 명령어 세트를 저장하는 단일 매체 또는 복수의 매체(예를 들어, 중앙 집중형 또는 분산형 데 이터베이스 및/또는 관련된 캐시 및 서버)를 포함하도록 취급되어야 한다. 또한, \"컴퓨터 판독 가능한 매체\"라 는 용어는 컴퓨터에 의한 실행을 위한 명령어 세트를 저장하거나, 인코딩하거나, 운반할 수 있고, 컴퓨터가 현 재 개시된 기술 및 혁신에 대한 방법 또는 모듈의 임의의 하나 이상을 수행하게 하는 임의의 매체를 포함하도록 취급되어야 한다. 컴퓨터는 서버 컴퓨터, 클라이언트 컴퓨터, 개인용 컴퓨터(PC), 태블릿 PC, 랩탑 컴퓨터, STB(set-top box), PDA(personal digital assistant), 휴대 전화기, 아이폰®, 아이패드®, 프로세서, 전화기, 웹 기기 (appliance), 네트워크 라우터, 스위치 또는 브리지, 또는 기계에 의해 취해질 동작을 특정하는 명령어 세트(순 차형이거나 또는 다른 것)를 실행할 수 있는 임의의 기계일 수 있다. 일반적으로, 본 개시 내용의 실시예를 구현하기 위하여 실행되는 루틴은 운영 체계 또는 특정 애플리케이션, 컴 포넌트, 프로그램, 객체, 모듈 또는 \"컴퓨터 프로그램\"이라 하는 명령어 시컨스의 일부로서 구현될 수 있다. 컴 퓨터 프로그램은 일반적으로 컴퓨터 내의 다양한 메모리 및 저장 장치에서 다양한 시간에 하나 이상의 명령어 세트를 포함하고, 컴퓨터에서 하나 이상의 처리 유닛 또는 프로세서에 의해 판독되고 실행될 때, 컴퓨터가 동작 을 수행하여 본 개시 내용의 다양한 양태를 포함하는 요소를 실행하게 한다. 더하여, 실시예가 완전하게 기능하는 컴퓨터 및 컴퓨터 시스템과 연계하여 설명되었지만, 다양한 실시예가 다양 한 형태의 프로그램 제품으로서 배포될 수 있고, 개시 내용이 배포를 실제로 달성하는데 사용되는 특정 종류의 컴퓨터 판독 가능한 매체에 관계없이 동일하게 적용된다. 본문이 다른 것을 명확하게 요구하지 않는다면, 설명 및 특허청구범위 전체를 통해서, \"포함한다\", \"포함하는\" 등과 같은 문구는, 배타적 또는 소진적 의미에 반대되는, 포함적 의미로서 고려되어야 한다; 즉, \"포함하지만 한정되지 않는다\"는 의미. 본 명세서에 사용된 바와 같이, \"연결되는\", \"결합되는\"이라는 용어 또는 이의 임의 의 변형은, 2개 이상의 요소 사이의 직접적이거나 간접적인 임의의 연결 또는 결합을 의미한다; 요소들 사이의 연결 또는 결합은 물리적, 논리적 또는 그 조합일 수 있다. 또한, \"여기에서\", \"위에서\", \"아래에서\"라는 단어 및 유사한 의미의 단어는, 본 출원서에서 사용될 때, 전체로서의 본 출원서을 지칭하며, 본 출원서의 임의의 특정 부분을 지칭하지 않는다. 또한, 상황이 허락한다면, 단수 또는 복수를 이용하는 전술한 발명을 실시하기 위 한 구체적인 내용에서의 단어는 각각 복수 또는 단수를 포함할 수 있다. 2 이상의 항목에 대한 리스트를 참조하 는 \"또는\"이라는 단어는 단어에 대한 다음의 해석을 모두 포함한다: 리스트 내의 임의의 항목, 리스트 내의 모 든 항목 및 리스트 내의 항목의 임의의 조합. 본 개시 내용의 실시예에 대한 전술한 상세한 설명은 소진적인 것 또는 위에서 개시된 정확한 형태로 교시 내용 을 한정하는 것으로 의도되지 않는다. 본 개시내용의 특정 실시예 및 그에 대한 예가 예시적인 목적으로 전술되 지만, 본 발명에 속하는 기술 분야에서 통상의 지식을 가진 자가 인식하는 바와 같이, 다양한 균등한 수정이 본 개시 내용의 범위 내에서 가능하다. 예를 들어, 프로세스 또는 블록이 주어진 순서로 제공되지만, 다른 실시예 는, 상이한 순서로, 단계를 갖는 루틴을 수행하거나 블록을 갖는 시스템을 채용할 수 있고, 일부 프로세스 또는 블록이 삭제되거나, 이동되거나, 추가되거나, 분할되거나, 조합되거나, 그리고/또는 수정되어 대체물 또는 서브 콤비네이션을 제공할 수 있다. 이러한 프로세스 또는 블록의 각각은 다양한 상이한 방식으로 구현될 수 있다. 또한, 때때로 프로세스 또는 블록이 연속적으로 수행되는 것으로 도시되지만, 이 대신에 프로세서 또는 블록은 병행하여 수행될 수 있거나, 상이한 시간에 수행될 수 있다. 또한, 여기에서 언급된 임의의 특정 숫자는 단지 예이다: 다른 구현예는 상이한 값 또는 범위를 채용할 수 있다. 여기에서 제공되는 본 개시 내용의 교시는 반드시 전술한 시스템이 아니고 다른 시스템에 적용될 수 있다. 전술 한 다양한 실시예의 요소 및 동작은 조합되어 다른 실시예를 제공할 수 있다. 첨부된 출원서에서 리스트될 수 있는 임의의 것을 포함하는 전술한 임의의 특허 및 출원과 다른 참고 문헌은, 본 명세서에 참조로서 편입된다. 개시 내용의 양태는, 필요하다면, 전술한 참고 문헌의 시스템, 기능 및 개념을 채용하여 개시 내용에 대한 또 다른 실시예를 제공하도록 수정될 수 있다."}
{"patent_id": "10-2015-7029066", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "이러한 변경 및 다른 변경이 전술한 발명을 실시하기 위한 구체적인 내용에 비추어 이루어질 수 있다. 전술한 설명이 본 개시 내용의 소정의 실시예를 설명하고 고려되는 최선의 형태를 설명하지만, 전술한 것이 본문에서 얼마나 상세하게 나타나는지에 관계없이, 교시 내용은 많은 방식으로 실시될 수 있다. 시스템의 상세는, 여기에 개시된 내용에 의해 여전히 포함되면서, 그 상세에서 상당하게 변동될 수 있다. 전술한 바와 같이, 본 개시 내 용의 특징 또는 양태를 설명할 때 사용된 특정 용어는 그 용어가 관련된 본 개시 내용의 임의의 특수한 특성, 특징 또는 양태에 제한되기 위하여 여기에서 재정의되는 것을 의미하도록 취급되어서는 안 된다. 일반적으로 다"}
{"patent_id": "10-2015-7029066", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "음의 특허청구범위에서 사용되는 용어는, 전술한 발명을 실시하기 위한 구체적인 내용 부분이 이러한 용어를 명 시적으로 정의하고 있지 않는다면, 본 개시 내용을 본 명세서에 개시된 특정 실시예로 한정하도록 고려되어서는 안 된다. 따라서, 본 개시 내용의 실제 범위는 개시된 실시예뿐만 아니라, 특허청구범위 하에서 개시 내용을 실 시하거나 구현하는 모든 균등한 방식을 포함한다.도면 도면1 도면2 도면3 도면4 도면5 도면6 도면7 도면8 도면9 도면10 도면11 도면12 도면13 도면14 도면15 도면16 도면17"}
{"patent_id": "10-2015-7029066", "section": "도면", "subsection": "도면설명", "item": 1, "content": "본 개시 내용의 하나 이상의 실시예가 유사한 도면 부호가 유사한 요소를 나타내는 첨부된 도면에서 한정이 아 니라 예로서 예시된다. 도 1은 소정의 실시예에서 구현될 수 있는 바와 같은 시스템 내의 다양한 컴포넌트의 블록도를 도시한다. 도 2는 소정의 실시예에서 사용될 수 있는 바와 같은 가상 환경에서의 복수의 상호 작용 장면 사이의 토폴러지 관계를 도시한다. 도 3은 소정의 실시예에서 구현될 수 있는 바와 같은 가상 환경에서의 주요 장면의 그래픽 사용자 인터페이스 (GUI)의 예시적인 스크린샷을 도시한다. 도 4는 소정의 실시예에서 구현될 수 있는 바와 같은 가상 환경에서의 \"노변 환담(fireside chat) 장면\" GUI의 예시적인 스크린샷을 도시한다. 도 5는 소정의 실시예에서 구현될 수 있는 바와 같은 가상 환경에서의 \"대비(versus) 장면\" GUI의 예시적인 스 크린샷을 도시한다. 도 6은 소정의 실시예에서 구현될 수 있는 바와 같은 가상 환경에서의 \"게임 쇼(game show) 장면\" GUI의 예시적 인 스크린샷을 도시한다.도 7은 소정의 실시예에서 구현될 수 있는 바와 같은 가상 환경에서의 \"이야기 하기(story telling) 장면\" GUI 의 예시적인 스크린샷을 도시한다. 도 8은 소정의 실시예에서 구현될 수 있는 바와 같은 가상 환경에서의 사용자 상호 작용 과정에서의 소정의 단 계들을 도시하는 플로우 차트이다. 도 9는 소정의 실시예에서 구현될 수 있는 바와 같은 컴포넌트 기반 컨텐츠 관리 및 전달 과정에서의 소정의 단 계들을 도시하는 플로우 차트이다. 도 10은 소정의 실시예에서 구현될 수 있는 바와 같은 컴포넌트 형성 및 관리 시스템을 위한 GUI의 예시적인 스 크린샷을 도시한다. 도 11은 소정의 실시예에서 구현될 수 있는 바와 같은 동적 AI 대화 관리 과정에서의 소정의 단계들을 도시하는 플로우 차트이다. 도 12는 소정의 실시예에서 구현될 수 있는 바와 같은 불만(frustration) 관리 과정에서의 소정의 단계들을 도 시하는 플로우 차트이다. 도 13은 소정의 실시예에서 구현될 수 있는 바와 같은 음성 수신(speech reception) 과정에서의 소정의 단계들 을 도시하는 플로우 차트이다. 도 14는 소정의 실시예에서 구현될 수 있는 바와 같은 사회적 자산 공유 GUI의 예시적인 스크린샷을 도시한다. 도 15는 소정의 실시예에서 구현될 수 있는 바와 같은 도 14의 사회적 자산 공유 GUI에서의 메시지 기안 (drafting) 도구의 예시적인 스크린샷을 도시한다. 도 16은 소정의 실시예에서 구현될 수 있는 바와 같은 사회적 이미지 캡처 과정에서의 소정의 단계들을 도시하 는 플로우 차트이다. 도 17은 소정의 개시된 실시예를 구현하는데 사용될 수 있는 컴퓨터 시스템에서의 컴포넌트의 블록도이다."}
