{"patent_id": "10-2020-0085406", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2022-0007319", "출원번호": "10-2020-0085406", "발명의 명칭": "전자장치 및 그의 제어방법", "출원인": "삼성전자주식회사", "발명자": "신현종"}}
{"patent_id": "10-2020-0085406", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "전자장치에 있어서,복수의 영상신호를 수신하고,상기 복수의 영상신호의 영상데이터를 각각 추출하고, 상기 추출된 복수의 영상데이터에 기초한 복수의 영상을 화면의 복수의 영역에 각각 할당한 통합영상데이터를가진 하나의 통합영상신호를 생성하는 입력신호처리부; 및상기 통합영상신호의 통합영상데이터에 기초하여 상기 화면에 표시하기 위한 영상프레임을 생성하는영상처리부;를 포함하는 전자장치."}
{"patent_id": "10-2020-0085406", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 복수의 영상신호는 HDMI(High-Definition Multimedia Interface)를 통해 수신되는 전자장치."}
{"patent_id": "10-2020-0085406", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,입력신호처리부는 상기 수신된 복수의 영상신호를 디코딩하는 디코더; 및 상기 디코딩 한 복수의 영상신호로부터 각각 복수의 영상데이터를 추출하여 상기 통합영상데이터를 생성하는 영상통합부를 포함하는 전자장치."}
{"patent_id": "10-2020-0085406", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서,상기 영상통합부는 상기 복수 영상신호의 위치 또는 크기 중 적어도 하나에 관한 정보를 기초로 상기 통합영상신호를 생성하는 전자장치."}
{"patent_id": "10-2020-0085406", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제3항에 있어서,상기 영상통합부는 상기 복수의 영상신호의 동기신호에 기초하여 상기 통합영상데이터에 대응하는 상기 통합영상신호의 동기신호를 생성하는 전자장치."}
{"patent_id": "10-2020-0085406", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제3항에 있어서,상기 통합영상신호는 상기 복수 영상신호의 통합 전과 통합 후의 위치 또는 크기 차이에 관한 정보를 포함하는전자장치."}
{"patent_id": "10-2020-0085406", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에 있어서,상기 통합영상신호에 기초하여 상기 영상프레임을 표시하는 디스플레이부를 더 포함하는 전자장치."}
{"patent_id": "10-2020-0085406", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "공개특허 10-2022-0007319-3-제7항에 있어서,상기 디스플레이부는 상기 영상처리부에서 생성한 영상프레임의 시간을 조절하는 타이밍 컨트롤러를 포함하는전자장치."}
{"patent_id": "10-2020-0085406", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제7항에 있어서,제2영상신호를 수신하는 제2인터페이스부; 및상기 제2영상신호를 기초로 화면에 표시하기 위한 제2영상프레임을 생성하는 제2영상처리부를 더 포함하는 전자장치."}
{"patent_id": "10-2020-0085406", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9항에 있어서,상기 디스플레이부는 상기 통합영상신호와 상기 제2영상신호를 합성하여 표시하는 전자장치."}
{"patent_id": "10-2020-0085406", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제1항에 있어서,상기 영상처리부는,영상데이터의 영상 포맷에 대응하는 디코딩(decoding);인터레이스(interlace) 방식의 영상데이터를 프로그레시브(progressive) 방식으로 변환하는 디인터레이싱(de-interlacing);영상데이터를 기 설정된 해상도로 조정하는 스케일링(scaling);영상 화질 개선을 위한 노이즈 감소(noise reduction);디테일 강화(detail enhancement); 또는프레임 리프레시 레이트(frame refresh rate) 변환 중 적어도 하나를 수행하는 전자장치."}
{"patent_id": "10-2020-0085406", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "전자장치의 제어방법에 있어서,복수의 영상신호를 수신하는 단계와;상기 복수의 영상신호의 영상데이터를 각각 추출하고, 상기 추출된 복수의 영상데이터에 기초한 복수의 영상을 화면의 복수의 영역에 각각 할당한 통합영상데이터를가진 하나의 통합영상신호를 생성하는 단계; 및상기 통합영상신호의 통합영상데이터에 기초하여 상기 화면에 표시하기 위한 영상프레임을 생성하는 단계를 포함하는 전자장치의 제어방법."}
{"patent_id": "10-2020-0085406", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제12항에 있어서,상기 복수의 영상신호는 HDMI를 통해 수신되는 전자장치의 제어방법."}
{"patent_id": "10-2020-0085406", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제12항에 있어서,상기 통합영상신호의 생성단계는 상기 복수의 영상신호를 디코딩하는 단계를 포함하는 전자장치의 제어방법."}
{"patent_id": "10-2020-0085406", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "공개특허 10-2022-0007319-4-제14항에 있어서,상기 통합영상신호는 상기 복수 영상신호의 위치 또는 크기 중 적어도 하나의 정보에 기초하여 생성되는 전자장치의 제어방법."}
{"patent_id": "10-2020-0085406", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제14항에 있어서,상기 통합영상신호의 생성단계는 상기 복수의 영상신호의 동기신호에 기초하여 통합영상데이터에 대응하는 상기통합영상신호의 동기신호를 생성하는 단계를 포함하는 전자장치의 제어방법."}
{"patent_id": "10-2020-0085406", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제14항에 있어서,상기 통합영상신호는 상기 복수 영상신호의 통합 전과 통합 후의 위치 또는 크기 차이에 관한 정보를 포함하는전자장치의 제어방법."}
{"patent_id": "10-2020-0085406", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제14항에 있어서,제2인터페이스부로부터 제2영상신호를 수신하는 단계를 더 포함하는 전자장치의 제어방법."}
{"patent_id": "10-2020-0085406", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제18항에 있어서,상기 통합영상신호를 상기 제2영상신호와 합성하여 표시하는 단계를 더 포함하는 전자장치의 제어방법."}
{"patent_id": "10-2020-0085406", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제12항에 있어서,상기 영상프레임의 생성단계는,영상데이터의 영상 포맷에 대응하는 디코딩(decoding);인터레이스(interlace) 방식의 영상데이터를 프로그레시브(progressive) 방식으로 변환하는 디인터레이싱(de-interlacing);영상데이터를 기 설정된 해상도로 조정하는 스케일링(scaling);영상 화질 개선을 위한 노이즈 감소(noise reduction);디테일 강화(detail enhancement); 또는프레임 리프레시 레이트(frame refresh rate) 변환 중 적어도 하나를 수행하는 전자장치의 제어방법."}
{"patent_id": "10-2020-0085406", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "다수의 영상을 분할하여 표시하는 전자장치가 개시된다. 전자장치는 복수의 영상신호를 수신하고, 상기 복수의 영상신호의 영상데이터를 각각 추출하고, 상기 추출된 복수의 영상데이터에 기초한 복수의 영상을 화면의 복수의 영역에 각각 할당한 통합영상데이터를 가진 하나의 통합영상신호를 생성하는 입력신호처리부 및 상기 통합영상신 호의 통합영상데이터에 기초하여 상기 화면에 표시하기 위한 영상프레임을 생성하는 영상처리부를 포함한다."}
{"patent_id": "10-2020-0085406", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 멀티뷰(Multi-view) 영상을 처리하여 표시하는 전자장치 및 그의 제어방법에 관한 것이다."}
{"patent_id": "10-2020-0085406", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "대형 스크린을 가진 디스플레이장치가 보편화되면서 여러 영상을 하나의 스크린에서 나누어 보고 싶어하는 요구 가 있다. 종래의 디스플레이장치는 멀티뷰 표시를 위해 다수의 HDMI 수신부를 통해 수신되는 다수의 영상신호 각각을 처리하는 다수의 비디오 프로세서가 필요하다. 이와 같이, 종래의 디스플레이장치는 멀티뷰용 영상표시를 위해서 다수의 HDMI 수신부를 통해 수신된 다수의 영 상신호에 대해 각각의 영상처리를 수행함으로써 처리해야 하는 데이터 양 증대에 따른 전송 선로 상의 데이터스루풋(data Throughput)이 매우 커지고, 시스템 구성 비용이 증가하는 문제가 있다."}
{"patent_id": "10-2020-0085406", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "따라서, 본 발명의 목적은, 단일 스크린에 다수의 영상을 표시함에 있어 데이터 스루풋을 줄이고 시스템 구성비 용을 절감할 수 있는 전자장치 및 그의 제어방법을 제공하는 것이다."}
{"patent_id": "10-2020-0085406", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상술한 목적을 달성하기 위한 전자장치가 제공된다. 전자장치는 복수의 영상신호를 수신하고, 상기 복수의 영상 신호의 영상데이터를 각각 추출하고, 상기 추출된 복수의 영상데이터에 기초한 복수의 영상을 화면의 복수의 영 역에 각각 할당한 통합영상데이터를 가진 하나의 통합영상신호를 생성하는 입력신호처리부 및 상기 통합영상신 호의 통합영상데이터에 기초하여 상기 화면에 표시하기 위한 영상프레임을 생성하는 영상처리부를 포함한다. 상기 복수의 영상신호는 HDMI(High-Definition Multimedia Interface)를 통해 수신될 수 있다. 입력신호처리부는 상기 수신된 복수의 영상신호를 디코딩하는 디코더; 및 상기 디코딩 한 복수의 영상신호로부 터 각각 복수의 영상데이터를 추출하여 상기 통합영상데이터를 생성하는 영상통합부를 포함할 수 있다. 상기 영상통합부는 상기 복수 영상신호의 위치 또는 크기 중 적어도 하나에 관한 정보를 기초로 상기 통합영상 신호를 생성할 수 있다. 상기 영상통합부는 상기 복수의 영상신호의 동기신호에 기초하여 상기 통합영상데이터에 대응하는 상기 통합영 상신호의 동기신호를 생성할 수 있다. 상기 통합영상신호는 상기 복수 영상신호의 통합 전과 통합 후의 위치 또는 크기 차이에 관한 정보를 포함할 수 있다. 상기 통합영상신호에 기초하여 상기 영상프레임을 표시하는 디스플레이부를 더 포함할 수 있다. 상기 디스플레이부는 상기 영상처리부에서 생성한 영상프레임의 시간을 조절하는 타이밍 컨트롤러를 포함할 수 있다. 전자장치는 제2영상신호를 수신하는 제2인터페이스부 및 상기 제2영상신호를 기초로 화면에 표시하기 위한 제2 영상프레임을 생성하는 제2영상처리부를 더 포함할 수 있다. 상기 디스플레이부는 상기 통합영상신호와 상기 제2영상신호를 합성하여 표시할 수 있다. 상기 영상처리부는 영상데이터의 영상 포맷에 대응하는 디코딩(decoding), 인터레이스(interlace) 방식의 영상 데이터를 프로그레시브(progressive) 방식으로 변환하는 디인터레이싱(de-interlacing), 영상데이터를 기 설정 된 해상도로 조정하는 스케일링(scaling), 영상 화질 개선을 위한 노이즈 감소(noise reduction), 디테일 강화 (detail enhancement) 또는 프레임 리프레시 레이트(frame refresh rate) 변환 중 적어도 하나를 수행할 수 있 다. 본 발명의 실시예에 따른 전자장치의 제어방법이 제공된다. 전자장치의 제어방법은 복수의 영상신호를 수신하는 단계와, 상기 복수의 영상신호의 영상데이터를 각각 추출하고, 상기 추출된 복수의 영상데이터에 기초한 복수의 영상을 화면의 복수의 영역에 각각 할당한 통합영상데이터를 가진 하나의 통합영상신호를 생성하는 단계 및 상 기 통합영상신호의 통합영상데이터에 기초하여 상기 화면에 표시하기 위한 영상프레임을 생성하는 단계를 포함 한다. 상기 통합영상신호의 생성단계는 상기 복수의 영상신호를 디코딩하는 단계를 포함할 수 있다. 상기 복수 영상신호의 위치 또는 크기 중 적어도 하나의 정보에 기초하여 생성될 수 있다. 상기 통합영상신호의 생성단계는 상기 복수의 영상신호의 동기신호에 기초하여 통합영상데이터에 대응하는 상기 통합영상신호의 동기신호를 생성하는 단계를 포함할 수 있다. 상기 전자장치의 제어방법은 제2인터페이스부로부터 제2영상신호를 수신하는 단계를 더 포함할 수 있다. 상기 전자장치의 제어방법은 상기 통합영상신호를 상기 제2영상신호와 합성하여 표시하는 단계를 더 포함할 수 있다. 상기 영상프레임의 생성단계는 영상데이터의 영상 포맷에 대응하는 디코딩(decoding), 인터레이스(interlace) 방식의 영상데이터를 프로그레시브(progressive) 방식으로 변환하는 디인터레이싱(de-interlacing), 영상데이터 를 기 설정된 해상도로 조정하는 스케일링(scaling), 영상 화질 개선을 위한 노이즈 감소(noise reduction), 디 테일 강화(detail enhancement) 또는 프레임 리프레시 레이트(frame refresh rate) 변환 중 적어도 하나를 수 행할 수 있다."}
{"patent_id": "10-2020-0085406", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명에 의한 전자장치는 화면의 복수 영역에 표시되는 다수 영상을 입력단계에서 하나의 통합영상신호로 통 합한 후에, 하나의 영상처리부에서 화면에 표시하기 위한 영상프레임으로 처리함으로써, 영상 처리를 위한 전송 선로 상의 데이터 스루풋을 줄일 수 있고 시스템 구성비용을 절감할 수 있다."}
{"patent_id": "10-2020-0085406", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하에서는 첨부 도면을 참조하여 본 발명의 실시예들을 상세히 설명한다. 도면에서 동일한 참조번호 또는 부호 는 실질적으로 동일한 기능을 수행하는 구성요소를 지칭하며, 도면에서 각 구성요소의 크기는 설명의 명료성과 편의를 위해 과장되어 있을 수 있다. 다만, 본 발명의 기술적 사상과 그 핵심 구성 및 작용이 이하의 실시예에 설명된 구성 또는 작용으로만 한정되지는 않는다. 본 발명을 설명함에 있어서 본 발명과 관련된 공지 기술 또는 구성에 대한 구체적인 설명이 본 발명의 요지를 불필요하게 흐릴 수 있다고 판단되는 경우에는 그 상세한 설명 을 생략하기로 한다. 본 문서에서, \"가진다,\" \"가질 수 있다,\" \"포함한다,\" 또는 \"포함할 수 있다\" 등의 표현은 해당 특징(예: 수치, 기능, 동작, 또는 부품 등의 구성요소)의 존재를 가리키며, 추가적인 특징의 존재를 배제하지 않는다. 본 문서에서, \"A 또는 B,\" \"A 또는/및 B 중 적어도 하나,\" 또는 \"A 또는/및 B 중 하나 또는 그 이상\"등의 표현 은 함께 나열된 항목들의 모든 가능한 조합을 포함할 수 있다. 예를 들면, \"A 또는 B,\" \"A 및 B 중 적어도 하나,\" 또는 \"A 또는 B 중 적어도 하나\"는, 적어도 하나의 A를 포함, 적어도 하나의 B를 포함, 또는 적어도 하나의 A 및 적어도 하나의 B 모두를 포함하는 경우를 모두 지칭할 수 있다. 본 발명의 실시예에서, 제1, 제2 등과 같이 서수를 포함하는 용어는 하나의 구성요소를 다른 구성요소로부터 구 별하는 목적으로만 사용되며, 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 또한, 본 발명의 실시예에서 '상부', '하부', '좌측', '우측', '내측', '외측', '내면', '외면', '전방', '후방' 등의 용어는 도면을 기준으로 정의한 것이며, 이에 의해 각 구성요소의 형상이나 위치가 제한되는 것은 아니다. 본 문서에서 사용된 표현 \"~하도록 구성된(또는 설정된)(configured to)\"은 상황에 따라, 예를 들면, \"~에 적 합한(suitable for),\" \"~하는 능력을 가지는(having the capacity to),\" \"~하도록 설계된(designed to),\" \"~하 도록 변경된(adapted to),\" \"~하도록 만들어진(made to),\" 또는 \"~를 할 수 있는(capable of)\"과 바꾸어 사용 될 수 있다. 용어 \"~하도록 구성된(또는 설정된)\"은 하드웨어적으로 \"특별히 설계된(specifically designed to)\" 것만을 반드시 의미하지 않을 수 있다. 대신, 어떤 상황에서는, \"~하도록 구성된 장치\"라는 표현은, 그 장 치가 다른 장치 또는 부품들과 함께 \"~할 수 있는\" 것을 의미할 수 있다. 예를 들면, 문구 \"A, B, 및 C를 수행 하도록 구성된(또는 설정된) 서브 프로세서\"는 해당 동작을 수행하기 위한 전용 프로세서(예: 임베디드 프로세 서), 또는 메모리 장치에 저장된 하나 이상의 소프트웨어 프로그램들을 실행함으로써, 해당 동작들을 수행할 수 있는 범용 프로세서(generic-purpose processor)(예: CPU 또는 application processor)를 의미할 수 있다. 본 문서의 다양한 실시예들에 따른 전자장치는, 영상을 처리하는 예를 들면, 텔레비전, 스마트폰, 태블릿 PC, 이동 전화기, 영상 전화기, 전자책 리더기, 데스크탑 PC, 랩탑 PC, 넷북 컴퓨터, 워크스테이션, 서버, PDA, PMP(portable multimedia player), MP3 플레이어, 의료기기, 카메라, 또는 웨어러블 장치 중 적어도 하나를 포 함할 수 있다. 어떤 실시예들에서, 전자장치는, 예를 들면, 블루 레이 플레이어, DVD(digital video disk) 플레이어, 셋탑박스, 홈 오토매이션 컨트롤 패널, 보안 컨트롤 패널, 미디어 박스, 게임 콘솔, 전자 사전, 캠코 더, 또는 전자 액자 중 적어도 하나를 포함할 수 있다. 다른 실시예에서, 전자장치는, 네비게이션 장치, 위성 항법 시스템(GNSS(global navigation satellite system)), EDR(event data recorder), FDR(flight data recorder), 자동차 인포테인먼트 장치, 선박용 전자 장 비(예: 선박용 항법 장치, 자이로 콤파스 등), 항공 전자기기(avionics), 보안 기기, 차량용 헤드 유닛(head unit) 중 적어도 하나를 포함할 수 있다. 본 문서에서, 사용자라는 용어는 전자장치를 사용하는 사람 또는 전자장치를 사용하는 장치(예: 인공지능 전자 장치)를 지칭할 수 있다. 도 1은 본 발명의 제1실시예에 따른 전자장치의 화면을 나타내는 도면이다. 도 1에 나타낸 바와 같이, 전자장치는 화면을 4개의 영역으로 분할하여 4개의 영상(Video1~4)을 표시하고 있 다. 전자장치는 하나의 화면에 4개의 영상을 분할하여 표시하는 것으로 한정되지 않고, 1~3개의 영상 또는 5 개 이상의 영상을 분할하여 표시할 수도 있다. 도 2는 본 발명의 제1실시예에 따른 전자장치의 구성을 나타내는 블록도이다. 도 2에 나타낸 바와 같이, 전자장치는 소스장치로부터 예를 들면 4개의 영상신호를 수신할 수 있는 인터 페이스부, 입력신호 처리부, 영상처리부, 디스플레이부, 오디오처리부, 음성출력부 및 프로세서를 포함할 수 있다. 소스장치는 영상 컨텐츠를 전자장치로 전송할 수 있는 장치, 예를 들면 셋탑박스, 서버, 중계장치, 컴퓨 터, 모바일장치 등을 포함할 수 있다. 인터페이스부는 예를 들면 TMDS(Transition Minimized Differential Signal) 포맷의 4개의 영상신호를 수 신하는 4개의 HDMI(High-Definition Multimedia Interface)Rx1~Rx4를 포함할 수 있다. 도 2에 나타낸 인터페이 스는 설명의 편의상 4개의 HDMI Rx1~Rx4를 예로 들어 나타낸 것으로, 이에 한정되지 않는다. 인터페이스부는 유선인터페이스부와 무선인터페이스부를 포함할 수 있다. 유선인터페이스부는 방송신호를 수신하기 위한 지상파/위성방송 안테나 연결 튜너, 케이블 방송 케이블 연결 인 터페이스 등을 포함할 수 있다. 유선인터페이스부는 영상기기 연결을 위한 HDMI, DP, DVI, Component, S-Video, 컴포지트(RCA 단자) 등을 포함 할 수 있다. 유선인터페이스부는 범용 전자기기 연결을 위한 USB 인터페이스 등을 포함할 수 있다. 유선인터페이스부는 광케이블 기기의 연결 인터페이스를 포함할 수 있다. 유선인터페이스부는 헤드셋, 이어폰, 외부 스피커 등의 오디오기기 연결 인터페이스를 포함할 수 있다. 유선인터페이스부는 이더넷 등 유선 네트워크 기기의 연결 인터페이스를 포함할 수 있다. 무선인터페이스부는 와이파이, 블루투스, ZigBee, Z-wave, RFID, WiGig, WirelessHD, UWB(Ultra-Wide Band), Wireless USB, NFC(Near Field Communication) 등 무선 네트워크 기기의 연결 인터페이스를 포함할 수 있다. 무선인터페이스부는 리모컨신호 송신 및/또는 수신을 위한 IR 송수신 모듈을 포함할 수 있다. 무선인터페이스부는 2G ~ 5G 등 이동통신기기 연결 인터페이스를 포함할 수 있다. 인터페이스부는 다양한 소스장치 각각에 대해 전용으로 통신을 수행하는 전용통신모듈을 포함할 수 있다. 인터페이스부는 다양한 소스장치들과 공통으로 통신을 수행하는 공용통신모듈, 예를 들면 와이파이모듈 등을 포함할 수 있다. 인터페이스부는 입력인터페이스부와 출력인터페이스부를 포함할 수도 있다. 이때, 입력인터페이스부와 출력 인터페이스부는 하나의 모듈로 통합되거나 별도의 모듈로 구현될 수도 있다. 입력신호처리부는 HDMI Rx1~Rx4를 통해 수신된 4개의 4k 영상신호1~4를 통합하여 하나의 통합영상신호(MV S)를 생성할 수 있다. 입력신호처리부는 영상신호를 디코딩하는 디코더, 복수의 영상신호를 통합하는 영상통합부 및 오 디오 스위칭부를 포함할 수 있다. 디코더는 TMDS 포맷의 영상신호1~4를 각각 디코딩 할 수 있다. 디코더는 예를 들면 FEC(Forward Error Correction) 디코더 또는 DSC(Display Stream Compression) 디코더를 포함할 수 있다. 영상통합부는 예를 들면 TMDS 포맷의 영상신호1~4로부터 각각 액티브 영상데이터1~4를 추출할 수 있다. 영 상통합부는 추출된 4개의 액티브 영상데이터1~4를 설정된 위치 및 크기로 화면의 4개 영역에 각각 할당한 통합영상데이터(MVD; merged video data)를 생성할 수 있다. 영상통합부는 인터페이스부로부터 수신된 복수의 영상신호 중 화면에 표시될 영상신호를 선택할 수 있 다. 영상통합부는 선택된 영상신호의 위치 및/또는 선택된 영상신의 크기 중 적어도 하나에 관한 정보를 기초로 통합영상데이터(MVD)를 생성할 수 있다. 영상통합부는 4개의 영상신호1~4의 동기신호에 기초하여 통합영상데이터(MVD)에 대응하는 동기신호를 생성 할 수 있다. 영상통합부는 통합된 4개의 영상신호1~4의 정보, 통합 전과 통합 후의 차이에 관한 정보, 예를 들면 통합 시에 변화된 영상의 크기 차이 정보와 같은 통합정보(MVI; merged video information)를 생성할 수 있다. 영상통합부는 통합 시에 생성된 통합영상데이터(MVD), 동기신호 및 통합정보(MVI)에 기초하여 통합영상신 호(MVS; merged video signal)를 생성하여 영상처리부로 전달할 수 있다. 오디오 스위칭부는 4개의 영상신호1~4 각각에 포함된 4개의 오디오신호(Audio1~4)를 추출하여 오디오처리 부1~4로 전달할 수 있다. 오디오 스위칭부는 4개의 영상(Video1~4)에 대응하는 4개의 오디오신호 (Audio1~4)를 출력할 출력장치, 예를 들면 스피커1~4에 관한 정보를 기초로 오디오신호(Audio1~4)를 오디오처리 부 1~4에 할당되도록 스위칭할 수 있다. 오디오신호(Audio1~4)를 출력할 스피커1~4에 관한 정보는 사용자입력을 통해 프로세서로부터 수신할 수 있다. 입력신호처리부는 전자장치에 내장되는 PCB 상에 실장되는 메인 SoC(Main SoC)에 포함되는 형태로서 구 현 가능하다. 입력신호처리부는 제어프로그램이 설치된 비휘발성의 메모리로부터 명령어들(instructions)을 포함하는 제 어프로그램의 적어도 일부를 휘발성의 메모리로 로드하고, 로드된 제어프로그램의 명령어를 실행하는 프로세서 , 예를 들면 CPU(Central Processing Unit), AP(application processor), 또는 마이크로프로세서 (microprocessor)로 구현될 수도 있다. 영상처리부는 입력신호처리부에서 수신한 통합영상신호(MVS)에 대해 디스플레이부에 표시하기 위한 영상프레임을 생성하는 다양한 영상처리 프로세스를 수행한다. 영상처리부가 수행하는 영상처리 프로세스의 종류는 다양하다. 영상처리 프로세스는 예를 들면 통합영상데이터(MVS)의 영상 포맷에 대응하는 디코딩 (decoding), 인터레이스(interlace) 방식의 통합영상데이터(MVS)를 프로그레시브(progressive) 방식으로 변환 하는 디인터레이싱(de-interlacing), 통합영상데이터(MVS)를 기 설정된 해상도로 조정하는 스케일링(scaling), 영상 화질 개선을 위한 노이즈 감소(noise reduction), 디테일 강화(detail enhancement), 프레임 리프레시 레이트(frame refresh rate) 변환 등을 포함할 수 있다. 영상처리부는 이러한 프로세스를 수행한 결과의 영상프레임을 전자장치에 내장된 디스플레이부에 전 송할 수 있다. 디스플레이부는 영상처리부에서 처리된 영상프레임을 표시할 수 있다. 디스플레이부의 구현 방식은 한정되지 않는 바, 액정(liquid crystal), 플라즈마(plasma), 발광 다이오드 (light-emitting diode), 유기발광 다이오드(organic light-emitting diode), 면전도 전자총(surface- conduction electron-emitter), 탄소 나노 튜브(carbon nano-tube), 나노 크리스탈(nano-crystal) 등의 다양한 디스플레이 패널로 구현될 수 있다. 디스플레이부는 구현 방식에 따라서 부가적인 구성을 추가적으로 포함할 수 있다. 예를 들면, 디스플레이부 는 영상처리부에서 생성한 영상프레임의 시간을 조절하는 타이밍 컨트롤러와 영상을 표시하는 화 면을 구성하는 패널을 포함할 수 있다. 디스플레이부는 추가적으로 패널을 구동시키는 패널구동 부를 더 포함할 수 있다. 오디오처리부1~4는 수신된 4개의 오디오신호(Audio1~4)를 처리할 수 있다. 오디오처리부1~4는 오디오 스위칭부에서 수신한 디지털 오디오신호(Audio1~4)에서 아날로그 오디오 신호(Audio1~4)로의 변환, 증폭, 믹싱 등을 수행할 수 있다. 오디오처리부1~4는 믹싱 된 아날로그 오디오 신호(Audio1~4)를 음성출력부 로 출력할 수 있다. 음성출력부는 4개의 영상신호1~4에 포함된 각각의 오디오신호(Audio1~4)를 재생하는 4개의 스피커 1~4를 포 함할 수 있다. 예를 들면, 스피커1~3은 전자장치에 내장되고, 스피커4는 외부에 마련되어 제2인터페이스부, 예를 들면 블루투스 통신모듈을 통해 연결될 수 있다. 물론, 스피커 1~4는 모두 내장될 수도 있고, 모두 외 부에 마련될 수도 있다. 프로세서는 전자장치의 각 구성 부품, 예를 들면 인터페이스, 입력신호처리부, 영상처리부, 디스플레이부, 오디오처리부, 및 음성출력부를 제어할 수 있다. 프로세서는 화면의 복수 영역에 표시할 영상의 선택, 선택된 영상이 표시되는 위치, 표시되는 영상의 크기 에 관한 정보를 기초로 입력신호처리부에 전달할 수 있다. 이러한 정보는 예를 들면 OSD를 통해 사용자로부 터 입력된 화면설정 정보를 기초로 얻을 수 있다. 프로세서는 사용자로부터 화면설정 변경입력이 수신되면 이를 입력신호처리부로 전송하여 통합영상신호 (MVS) 생성에 반영할 수 있다. 화면설정 변경입력은 특정영역에 표시되던 영상을 새로운 영상으로 변경하거나, 영역과 영역 간의 표시 영상을 교환하거나, 표시되는 영상의 크기를 변경하는 경우 등을 포함할 수 있다. 프로세서는 전자장치의 전원이 켜지는 경우 최종적으로 설정된 화면 설정정보를 통항영상신호(MVS) 생성 에 반영하도록 입력신호처리부에 전달할 수 있다. 물론, 입력신호처리부는 메모리에 저장된 가장 마지 막에 설정된 화면 설정정보를 직접 참조할 수도 있다. 프로세서는 사용자ID별로 설정된 화면설정 정보를 입력신호처리부에 전달할 수도 있다. 프로세서는 사용자에 의해 선택 또는 설정된 4개의 영상(Video1~4)에 대응하는 오디오신호(Audio1~4)를 재 생할 스피커1~4에 관한 정보를 저장하거나 입력신호처리부에 전달할 수 있다. 프로세서는 데이터를 수집하고, 수집된 데이터를 분석, 처리, 및 결과 정보 생성 중 적어도 일부를 규칙 기 반 또는 인공지능(Artificial Intelligence) 알고리즘으로서 기계학습, 신경망 네트워크(neural network), 또 는 딥러닝 알고리즘 중 적어도 하나를 이용하여 수행할 수 있다. 일 예로, 프로세서는 학습부 및 인식부의 기능을 수행할 수 있다. 학습부는, 예를 들면, 학습된 신경망 네 트워크를 생성하는 기능을 수행하고, 인식부는 학습된 신경망 네트워크를 이용하여 데이터를 인식(또는, 추론, 예측, 추정, 판단)하는 기능을 수행할 수 있다. 학습부는 신경망 네트워크를 생성하거나 갱신할 수 있다. 학습 부는 신경망 네트워크를 생성하기 위해서 학습 데이터를 획득할 수 있다. 예를 들면, 학습부는 학습 데이터를 메모리 또는 외부로부터 획득할 수 있다. 학습 데이터는, 신경망 네트워크의 학습을 위해 이용되는 데이터일 수 있다. 학습부는 학습 데이터를 이용하여 신경망 네트워크를 학습시키기 전에, 획득된 학습 데이터에 대하여 전처리 작 업을 수행하거나, 또는 복수 개의 학습 데이터들 중에서 학습에 이용될 데이터를 선별할 수 있다. 예를 들면, 학습부는 학습 데이터를 기 설정된 포맷으로 가공하거나, 필터링하거나, 또는 노이즈를 추가/제거하여 학습에 적절한 데이터의 형태로 가공할 수 있다. 학습된 신경망 네트워크는, 복수의 신경망 네트워크(또는, 레이어)들 로 구성될 수 있다. 복수의 신경망 네트워크의 노드들은 가중치를 가지며, 복수의 신경망 네트워크들은 일 신경 망 네트워크의 출력 값이 다른 신경망 네트워크의 입력 값으로 이용되도록 서로 연결될 수 있다. 신경망 네트워 크의 예로는, CNN (Convolutional Neural Network), DNN (Deep Neural Network), RNN (Recurrent Neural Network), RBM (Restricted Boltzmann Machine), DBN (Deep Belief Network), BRDNN(Bidirectional Recurrent Deep Neural Network) 및 심층 Q-네트워크 (Deep Q-Networks)과 같은 모델을 포함할 수 있다. 한편 인식부는 타겟 데이터를 획득할 수 있다. 타겟 데이터는 메모리 또는 외부로부터 획득된 것일 수 있다. 타 겟 데이터는, 신경망 네트워크의 인식 대상이 되는 데이터일 수 있다. 인식부는 타겟 데이터를 학습된 신경망 네트워크에 적용하기 전에, 획득된 타겟 데이터에 대하여 전처리 작업을 수행하거나, 또는 복수 개의 타겟 데이 터들 중에서 인식에 이용될 데이터를 선별할 수 있다. 예를 들면, 인식부는 타겟 데이터를 기 설정된 포맷으로 가공하거나, 필터링 하거나, 또는 노이즈를 추가/제거하여 인식에 적절한 데이터의 형태로 가공할 수 있다. 인 식부는 전처리된 타겟 데이터를 신경망 네트워크에 적용함으로써, 신경망 네트워크로부터 출력되는 출력값을 획 득할 수 있다. 다양한 실시예에 따르면, 인식부는 출력값과 함께 학률값(또는, 신뢰도값)을 함께 획득할 수 있 다. 프로세서는 제어프로그램이 설치된 비휘발성의 메모리로부터 명령어들(instructions)을 포함하는 제어프로 그램의 적어도 일부를 휘발성의 메모리로 로드하고, 로드된 제어프로그램의 명령어를 실행하는 적어도 하나의 범용 프로세서를 포함하며, 예를 들면 CPU(Central Processing Unit), AP(application processor), 또는 마이 크로프로세서(microprocessor)로 구현될 수 있다. 프로세서는 싱글 코어, 듀얼 코어, 트리플 코어, 쿼드 코어 및 그 배수의 코어를 포함할 수 있다. 프로세서 는 복수 개 마련될 수 있다. 프로세서는 예를 들어, 메인 프로세서(main processor) 및 슬립 모드 (sleep mode, 예를 들어, 대기 전원만 공급되는 모드)에서 동작하는 서브 프로세서(sub processor)를 포함할 수 있다. 또한, 프로세서, 롬 및 램은 내부 버스(bus)를 통해 상호 연결된다. 프로세서는 전자장치에 내장되는 PCB 상에 실장되는 메인 SoC(Main SoC)에 포함되는 형태로서 구현 가능 하다. 다른 실시예에서 메인 SoC는 영상처리부를 더 포함할 수 있다. 제어프로그램은, BIOS, 디바이스드라이버, 운영체계, 펌웨어, 플랫폼 및 응용프로그램(어플리케이션) 중 적어도 하나의 형태로 구현되는 프로그램(들)을 포함할 수 있다. 응용프로그램은, 전자장치의 제조 시에 미리 설치 또는 저장되거나, 혹은 추후 사용 시에 외부로부터 응용프로그램의 데이터를 수신하여 수신된 데이터에 기초하 여 설치될 수 있다. 응용 프로그램의 데이터는, 예컨대, 어플리케이션 마켓과 같은 외부 서버로부터 전자장치 로 다운로드될 수도 있다. 이와 같은 제어프로그램, 외부 서버 등은, 컴퓨터프로그램제품의 일례이나, 이에 한정되는 것은 아니다. 전자장치는 메모리를 더 포함할 수 있다. 메모리는 컴퓨터에 의해 판독 가능한 기록매체로서, 한정 되지 않은 데이터가 저장된다. 메모리는 프로세서에 의해 액세스 되며, 이들에 의한 데이터의 독취, 기 록, 수정, 삭제, 갱신 등이 수행된다. 메모리는 화면 설정 정보, 예를 들면 화면의 복수의 영역에 표시하기 위해 할당된 영상 정보, 영상의 위치 정보, 영상의 크기 정보 등을 저장할 수 있다. 메모리에 저장되는 데이터는, 인터페이스부를 통해 수신된 각종 영상/음성 컨텐츠 및 수신된 영상을 처 리하여 순차적으로 표시한 복수 프레임 데이터를 포함할 수 있다. 메모리는 음성인식을 위한 음성인식모듈 (음성인식엔진)을 포함할 수 있다. 메모리는 운영체제, 운영체제 상에서 실행 가능한 다양한 애플리케이션, 영상데이터, 부가데이터 등을 포함 할 수 있다. 메모리는 제어프로그램이 설치되는 비휘발성의 메모리, 설치된 제어프로그램의 적어도 일부가 로드되는 휘 발성의 메모리를 포함한다. 메모리는 플래시 메모리 타입(flash memory type), 하드디스크 타입(hard disk type), 멀티미디어 카드 마 이크로 타입(multimedia card micro type), 카드 타입의 메모리(예를 들어 SD 또는 XD 메모리 등), 램(RAM,Random Access Memory) SRAM(Static Random Access Memory), 롬(ROM, Read-Only Memory), EEPROM(Electrically Erasable Programmable Read-Only Memory), PROM(Programmable Read-Only Memory) 자기 메모리, 자기 디스크, 광디스크 중 적어도 하나의 타입의 저장매체를 포함할 수 있다. 전자장치는 음성인식부를 포함할 수 있다. 음성인식부는 메모리에 저장된 음성인식모듈을 실행하여 전자장치에 내장된 마이크, 또는 외부장치, 예를 들면 모바일장치나 리모컨에 내장된 마이크 등으로부터 입력 또는 전달된 음성을 인식할 수 있다. 모바일장치나 리모컨의 마이크로 음성을 수신하는 경우, 모바일장치 또는 리모컨은 아날로그 음성 신호를 디지 털화 하여 예를 들면 블루투스 등으로 전자장치 측으로 전송할 수 있다. 전자장치 자체의 마이크로 음성 신호를 수신하는 경우, 수신된 아날로그 음성 신호는 디지털화 하여 전자장 치의 프로세서로 전송될 수 있다. 전자장치는 수신한 음성 신호를 서버로 전송할 수 있다. 이때, 서버는 음성신호 관련 데이터를 적절한 텍스 트로 변환하는 STT서버 또는 STT서버 기능도 함께 수행하는 메인 서버일 수도 있다. STT서버에서 처리된 데이터는 전자장치가 다시 수신하거나 다른 서버로 바로 전송할 수도 있다. 물론, 전자장치는 수신한 음성신호를 STT서버로 전송하지 않고, 전자장치 내에서 자체적으로 처리할 수도 있다. 즉, 전자장치는 자체적으로 STT서버 역할을 수행할 수도 있다. 전자장치는 서버에서 전송한 텍스트나 자체적으로 변환한 텍스트를 이용하여 특정 기능 수행할 수 있다. 이 때, 기능을 수행하는 것은 전자장치 내 프로세서일 수도 있고, 변환된 텍스트가 전송된 별도 서버(STT서 버와 다른 서버 또는 STT서버 역할도 하는 서버)일 수 있다. 도 3은 본 발명의 실시예에 따라 분할영상 표시를 위한 전자장치의 제어방법을 나타내는 순서도이다. 사용자는 화면의 1/4분면, 2/4분면, 3/4분면, 4/4분면에 각각 Video1, Video2, Video3, Video4를 표시하도록 설정할 수 있다. 이때, 사용자는 각 영역에 표시되는 Video1, Video2, Video3, Video4의 크기도 조절할 수 있다. 프로세서는 이러한 화면 설정입력 정보, 즉 영상의 위치 및/또는 크기를 입력신호처리부로 전송 할 수 있다. 단계 S11에서, 인터페이스부는 4개의 영상신호1~4를 수신할 수 있다. 이때, 인터페이스부는 도 2에 나 타낸 바와 같이 HDMI일 수 있다. 단계 S12에서, 입력신호처리부는 다수의 영상신호 중 화면에 표시할 4개의 4k 영상신호1~4를 선택하고, 디 코딩을 수행할 수 있다. 영상신호1~4는 도 4에 나타낸 바와 같은 4개 TMDS포맷으로 이루어질 수 있다. TMDS(Transition Minimized Differential Signal)는 '영상데이터 기간', '데이터 아일랜드 기간', '제어 기간' 세가지 모드 중 하나를 사용하여 영상, 음성, 그리고 기타 데이터들을 전송한다. '영상데이터 기간'에서는 영 상데이터가 전송될 수 있다. '데이터 아일랜드 기간'은 '수평/수직 귀선기간'에 발생하여 음성과 기타 데이터들 이 여러 개의 패킷으로 나누어져 보내질 수 있다. '제어 기간'은 '영상데이터 기간'과 '데이터 아일랜드 기간' 사이에 발생될 수 있다. HDMI는 TMDS를 사용하여 '영상데이터 기간'에 8b/10b 인코딩 방식으로,'제어 기간'에 2b/10b인코딩 방식으로 10 비트의 영상데이터를 전송할 수 있다. 또한, HDMI는 '데이터 아일랜드 기간'에 4b/10b 인코딩 방식으로 음성과 기타자료를 전송할 수 있다. 이때, 한번의 '데이터 아일랜드 기간'에 32픽셀 만큼의 데이터를 전송할 수 있고, 패킷의 내용을 설명하는 32비트 패킷 헤더가 포함될 수 있다. 패킷 헤더에는 오류 수정 기능을 위한 8비트의 BCH ECC(Error Correction Code) 패리티 데이터가 포함될 수 있다. 각각의 패킷은 4개의 하부패킷을 가질 수 있다. 각각의 하부패킷은 64비트로 이루어질 수 있다. 이 패킷에도 8 비트의 BCH ECC 패리티 데이터가 포함될 수 있다. 또한 각각의 '데이터 아일랜드 기간'에서는 최대 18개의 패킷 을 전송할 수 있다. HDMI 1.3a 사양에 있는 15개의 패킷 종류 중 7개는 음성에 관하여, 나머지 8개는 기타 데이 터를 위해 할당될 수 있다. 이들 중에는 표준 제어 패킷과 Gamut 메타데이터 패킷이 있다. 표준 제어 패킷은 음 향에 노이즈가 발생할 때 음 소거를 해주는 기능(AVMUTE)과 색심도에 대한 정보를 가질 수 있다. Gamut 메타데 이터 패킷은 xvYCC 사용을 위해 필요한, 재생중인 비디오 스트림을 위한 색 공간에 대한 정보를 담을 수 있다.도 4는 TMDS포맷의 영상신호1~4(Video1~4)를 나타내는 도면이다. 영상신호 1은 화면 전체에 표시되는 액티브 영상데이터1(Active Video1), 오디오데이터1(Audio1), 및 기타 데이 터1을 포함할 수 있다. 영상신호 1은 액티브 영상데이터1을 화면 전체에 표시하기 위한 수직 및 수평 동기신호 1(VSync1, HSync1)을 포함할 수 있다. 영상신호 2는 화면 전체에 표시되는 액티브 영상데이터2(Active Video2), 오디오데이터2(Audio2), 및 기타 데이 터 2를 포함할 수 있다. 영상신호 2는 액티브 영상데이터2를 화면 전체에 표시하기 위한 수직 및 수평 동기신호 2(VSync2, HSync2)를 포함할 수 있다. 영상신호 3은 화면 전체에 표시되는 액티브 영상데이터3(Active Video3), 오디오데이터3(Audio3), 및 기타 데이 터 3을 포함할 수 있다. 영상신호 3은 액티브 영상데이터3을 화면 전체에 표시하기 위한 수직 및 수평 동기신호 3(VSync3, HSync3)을 포함할 수 있다. 영상신호 4는 화면 전체에 표시되는 액티브 영상데이터4(Active Video4), 오디오데이터4(Audio4), 및 기타 데이 터 4를 포함할 수 있다. 영상신호 4는 액티브 영상데이터4를 화면 전체에 표시하기 위한 수직 및 수평 동기신호 4(VSync4, HSync4)를 포함할 수 있다. 단계 S13에서, 입력신호처리부는 영상신호1~4로부터 액티브 영상데이터1~4(Active Video1~4)를 추출할 수 있다. 단계 S14에서, 입력신호처리부는 도 5에 나타낸 바와 같이, 화면의 복수 영역 중에 표시될 위치 및 크기 정 보를 기초로 액티브 영상데이터1~4(Active Video1~4)를 화면의 복수 영역에 할당한 통합영상데이터(MVD)를 생성 할 수 있다. 예를 들면, 통합영상데이터(MVD)는 화면의 1/4분면에 소정 크기의 액티브 영상데이터1(Active Video1)가 배치되 고, 화면의 2/4분면에 소정 크기의 액티브 영상데이터2(Active Video2)가 배치되고, 화면의 3/4분면에 소정 크 기의 액티브 영상데이터3(Active Video3)이 배치되고, 화면의 4/4분면에 소정 크기의 액티브 영상데이터 4(Active Video4)가 배치될 수 있다. 도 5는 통합영상신호(MVS)를 나타내는 도면이다. 입력신호처리부는 액티브 영상데이터1~4(Active Video1~4)의 위치 및/또는 크기 및 액티브 영상데이터 1~4(Active Video1~4)의 수직 및 수평 동기신호1~4(VSync1~4, HSync1~4)를 참조하여 통합영상데이터(MVD)의 수 직 및 수평 동기신호M(MVSync, MHSync)를 생성할 수 있다. 입력신호처리부는 통합영상데이터(MVD)에 관한 정보 및 액티브 영상데이터1~4(Active Video1~4)의 변화된 위치 및/또는 크기 차이에 관한 정보와 같은 통합정보(MVI)를 생성할 수 있다. 입력신호처리부는 생성된 통합영상데이터(MVD), 수직 및 수평 동기신호M(MVSync, MHSync), 통합정보(MVI)를 포함하는 통합영상신호(MVS)를 생성할 수 있다. 단계 S15에서, 영상처리부는 통합영상신호(MVS)를 기초로 액티브 통합영상데이터를 추출하고, 추출된 통합 영상데이터에 대해 화면에 표시하기 위한 다양한 처리를 통해 수행하여 영상프레임을 생성할 수 있다. 영상프레 임의 생성을 위한 처리는 예를 들면 통합영상데이터(MVS)의 영상 포맷에 대응하는 디코딩(decoding), 인터레이 스(interlace) 방식의 통합영상데이터(MVS)를 프로그레시브(progressive) 방식으로 변환하는 디인터레이싱(de- interlacing), 통합영상데이터(MVS)를 기 설정된 해상도로 조정하는 스케일링(scaling), 영상 화질 개선을 위한 노이즈 감소(noise reduction), 디테일 강화(detail enhancement), 프레임 리프레시 레이트(frame refresh rate) 변환 등을 포함할 수 있다. 단계 S16에서, 디스플레이부는 생성된 영상프레임을 기초로 화면 전체에 통합영상데이터(MVD)에 대응하는 통합영상을 표시할 수 있다. 상술한 바와 같이, 본 발명의 전자장치는 영상처리부가 수신된 복수의 영상신호를 처리하기 전에, 복수 의 영상신호 각각의 액티브 영상데이터를 화면의 복수 영역 중에 표시될 위치 및/또는 크기에 맞게 조정하여 통 합함으로써 하나의 영상처리부만으로 화면의 복수 영역에 표시할 복수의 영상신호를 처리할 수 있다. 또한, 본 발명의 전자장치는 화면을 4개로 분할한 후 4개의 4k 영상신호1~4를 각 분할 영역에 할당하여 표시 함으로써, 전체적으로 8k 영상을 표시하는 것이 가능하다. 도 6은 본 발명의 제2실시예에 따른 전자장치의 구성을 나타내는 블록도이다. 제2실시예에 따른 전자장치는 자체적으로 영상을 표시하는 디스플레이부가 배제되고, 인터페이스부, 예 를 들면 HDMI를 통해 수신된 4개의 영상신호1~4를 통합하여 통합영상신호(MVS)를 생성하고, 통합영상신호(MVS) 를 기초로 영상프레임을 생성하여 외부에 마련된 디스플레이장치, 예를 들면 텔레비전이나 모니터로 출력할 수 있다. 또한, 4개의 영상신호1~4에 포함된 오디오신호1~4를 처리하여 케이블(C) 또는 블루투수 통신모듈 를 통해 외부에 마련된 음성출력장치로 출력할 수 있다. 물론, 제2실시예에 따른 전자장치는 간단한 알림, 제어 메뉴 등을 표시하기 위한 디스플레이부를 포함할 수도 있다. 도 7은 본 발명의 제3실시예에 따른 전자장치의 구성을 나타내는 블록도이다. 제3실시예에 따른 전자장치는 통합해야 할 영상, 통합 시에 영상의 화면 내 배치, 표시하는 영상의 크기, 표 시하는 영상의 오디오신호를 재생하는 스피커 정보 등을 디스플레이장치로부터 수신하여 복수의 영상신호1~4 를 통합하여 하나의 통합영상신호(MVS)를 생성할 수 있다. 통합영상신호(MVS)를 생성에 대한 설명은 도 2에 나 타낸 제1실시예에 따른 입력신호처리부와 유사하므로 생략한다. 제3실시예에 따른 전자장치는 화면의 복수 영역에 할당하여 표시할 예를 들면 4개의 영상신호1~4를 통합하여 통합영상신호(MVS)를 생성한 후, 디스플레이장치로 전달할 수 있다. 이때, 영상신호1~4는 인터페이스부를 통 해 외부의 소스장치로부터 수신될 수 있다. 디스플레이장치는 전자장치로부터 화면의 복수 영역에 표시할 영상신호1~4가 합쳐진 통합영상신호(MVS)를 수신하고, 화면표시를 위한 영상프레임을 생성하고, 영상프레임을 디스플레이부의 화면에 표시할 수 있다. 도 8은 본 발명의 제4실시예에 따른 전자장치의 복수의 영상신호를 처리하여 표시하는 시나리오를 나타내는 도면이다. 사용자는 기존 화면의 1/4분면, 2/4분면, 3/4분면, 4/4분면에 각각 표시되던 Video1, Video2, Video3, Video4 에서 4/4분면의 Video4를 USB에 있는 USB Movie로 변경할 수 있다. 이때, 프로세서는 이러한 화면 설정입력 정보를 입력신호처리부로 전송할 수 있다. 인터페이스부는 4개의 제1영상신호1~4를 각각 수신하는 HDMI1~4 및 제2영상신호(USB Movie)가 저장된 USB에 연결된 USB인터페이스를 포함할 수 있다. 입력신호처리부는 4개의 제1영상신호1~4 중 제1영상신호1~3을 선택하여 액티브 영상데이터1~3(Active Video1~3)을 추출하고, 이 액티브 영상데이터1~3(Active Video1~3)를 각각 화면의 1/4분면, 2/4분면, 3/4분면 의 영역에 할당하여 통합한 통합영상데이터(MVD)를 생성한 후에, 이를 기초로 통합영상신호(MVS)를 생성할 수 있다. 이와 같이, 통합영상데이터(MVD)는 화면의 4/4분면의 영역을 비워진 상태로 생성될 수 있다. 통합영상신 호(MVS)는 영상처리부1로 전달될 수 있다. USB인터페이스를 통해 수신된 제2영상신호(USB Movie)는 영상처리부2로 전달될 수 있다. 입력신호처리부는 영상신호1~2에 대응하는 오디오신호1~2를 추출한 후에 이를 오디오처리부1~2(141,142)로 전달할 수 있다. 영상처리부1은 통합영상신호(MVS)를 화면의 1/4분면, 2/4분면, 3/4분면에 표시하기 위한 제1영상프레임을 생성할 수 있다. 영상처리부2는 제2영상신호(USB Movie)를 화면의 4/4분면에 표시하기 위한 제2영상프레임을 생성할 수 있 다. 디스플레이부는 제1영상프레임과 제2영상프레임을 합성하여 제1영상1~3(Video1~3) 및 제2영상(USB Movie)을 화면에 표시할 수 있다. 사용자는 HDMI1의 영상1(Video1)의 오디오신호1은 TV스피커로 재생하고, HDMI2의 영상2(Video2)의 오디오 신호2는 블루투스 스피커로 재생하도록 지정할 수 있다. 오디오처리부1~2(141,142)는 오디오신호1~2를 각각 처리하여 음성출력부의 TV스피커와 블루투스 스피 커로 전송하여 재생할 수 있다. 도 9는 본 발명의 제5실시예에 따른 전자장치의 복수의 영상신호를 처리하여 표시하는 시나리오를 나타내는 도면이다. 사용자는 기존 화면의 1/4분면, 2/4분면, 3/4분면, 4/4분면에 각각 표시되던 Video1, Video2, Video3, Video4 를 Video3, Video2, Video1, Video4로 변경할 수 있다. 이때, 프로세서는 이러한 화면 설정입력 정보를 입 력신호처리부로 전송할 수 있다. 입력신호처리부는 4개의 제1영상신호1~4 중 제1영상신호1~4를 모두 선택하여 액티브 영상데이터1~4(Active Video1~4)를 추출하고, 이 액티브 영상데이터1~4(Active Video1~4)를 각각 화면의 3/4분면, 2/4분면, 1/4분면, 4/4분면의 영역에 할당하여 통합한 통합영상데이터(MVD)를 생성한 후에, 이를 기초로 통합영상신호(MVS)를 생성 할 수 있다. 이와 같이, 통합영상데이터(MVD)는 화면설정에 따라 표시된 영상의 순서를 변경되면 입력신호처리 부가 이를 반영하여 영상의 표시 순서가 바뀌도록 생성되어 영상처리부로 전달될 수 있다. 입력신호처리부는 영상신호1~2에 대응하는 오디오신호1~2를 추출한 후에 이를 오디오처리부1~2(141,142)로 전달할 수 있다. 영상처리부는 통합영상신호(MVS)를 기초로 화면의 1/4분면, 2/4분면, 3/4분면, 4/4분면에 각각 영상 3(Video3), 영상2(Video2), 영상1(Video1) 및 영상4(Video4)를 표시하기 위한 영상프레임을 생성할 수 있다. 디스플레이부는 영상처리부에서 전달한 영상프레임을 화면에 표시할 수 있다. 사용자는 HDMI1의 영상1(Video1)의 오디오신호1은 TV스피커로 재생하고, HDMI2의 영상2(Video2)의 오디오 신호2는 블루투스 스피커로 재생하도록 지정할 수 있다. 오디오처리부1~2(141,142)는 오디오신호1~2를 각각 처리하여 음성출력부의 TV스피커와 블루투스 스피 커로 전송하여 재생할 수 있다. 변형실시예로서, 전자장치는 화면에서 메인 영상 내에 별도로 작은 부가영상을 동시에 표시할 수 있는 PIP(Picture in Picture)에 적용할 수 있다. 이때, 영상통합부는 PIP 설정정보를 받고, 화면전체의 메인 영상에 부가영상이 위치와 크기를 반영하여 통합영상신호(MVS)를 생성할 수 있다. 결과적으로, 전자장치는 메인 영상과 부가영상을 하나의 영상처리부로 처리하여 PIP 영상을 표시할 수 있다. 본 발명의 실시예에 따른, 복수의 영상을 화면의 복수 영역에 할당하여 표시하는 입력신호처리모듈은 컴퓨터 판 독 가능 기록매체로서 메모리에 저장된 컴퓨터프로그램제품 또는 네트워크통신으로 송수신되는 컴퓨터프로 그램 제품으로 구현될 수 있다. 또한, 상술한 입력신호처리모듈은 단독 또는 통합되어 컴퓨터프로그램으로 구 현될 수 있다. 이상에서는 본 발명의 바람직한 실시예에 대하여 도시하고 설명하였지만, 본 발명은 상술한 특정의 실시예에 한"}
{"patent_id": "10-2020-0085406", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "정되지 아니하며, 청구범위에서 청구하는 본 발명의 요지를 벗어남이 없이 당해 발명이 속하는 기술분야에서 통 상의 지식을 가진 자에 의해 다양한 변형실시가 가능한 것은 물론이고, 이러한 변형 실시 예들은 본 발명의 기 술적 사상이나 전망으로부터 개별적으로 이해되어서는 안 될 것이다."}
{"patent_id": "10-2020-0085406", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 제1실시예에 따른 전자장치의 화면을 나타내는 도면이다. 도 2는 본 발명의 제1실시예에 따른 전자장치의 구성을 나타내는 블록도이다. 도 3은 본 발명의 제1실시예에 따라 분할영상 표시를 위한 전자장치의 제어방법을 나타내는 순서도이다. 도 4는 TMDS포맷의 영상신호1~4를 나타내는 도면이다. 도 5는 통합영상신호(MVS)를 나타내는 도면이다. 도 6은 본 발명의 제2실시예에 따른 전자장치의 구성을 나타내는 블록도이다. 도 7은 본 발명의 제3실시예에 따른 전자장치의 구성을 나타내는 블록도이다. 도 8은 본 발명의 제4실시예에 따른 전자장치의 복수의 영상신호를 처리하여 표시하는 시나리오를 나타내는 도 면이다. 도 9는 본 발명의 제5실시예에 따른 전자장치의 복수의 영상신호를 처리하여 표시하는 시나리오를 나타내는 도 면이다."}
