{"patent_id": "10-2023-0152820", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2025-0024449", "출원번호": "10-2023-0152820", "발명의 명칭": "인공지능 모델을 활용한 의료영상 내 각 영역 분할 방법 및 장치", "출원인": "경북대학교 산학협력단", "발명자": "정순기"}}
{"patent_id": "10-2023-0152820", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "영상 처리 장치가 환자의 CT이미지를 입력 받는 단계; 상기 영상 처리 장치가 상기 CT(Computed Tomograpy)이미지를 분할 모델(Segmentation Model)에 입력하는단계; 상기 영상 처리 장치가 상기 분할 모델의 출력값을 기반으로 상기 CT이미지의 각 영역을 분할하는 단계;를 포함하되, 상기 영상 분할 모델은 제1 학습 데이터 및 제2 학습 데이터를 기반으로 학습된 모델이고, 상기 제1 학습 데이터는 CT이미지 및 제1 학습 데이터에 포함된 CT이미지의 레퍼런스 이미지를 포함하고, 상기 제2 학습 데이터는 CT이미지를 포함하는, 인공지능 모델을 활용한 의료영상 내 각 영역 분할 방법."}
{"patent_id": "10-2023-0152820", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 분할 모델은 학습 과정에서 구조는 동일하나 서로 다른 가중치로 초기화 된 제1 오토인코더 및 제2 오토인코더를 이용하고, 상기 분할 모델은 제1 손실값 및 제2 손실값을 포함하는 손실함수 값이 최소가 되도록 학습된 모델이고, 상기 제1 손실값은 상기 제1 오토인코더가 상기 제1 학습 데이터에 포함된 CT이미지의 각 영역을 분할한 결과와상기 제1 학습 데이터에 포함된 레퍼런스 이미지와의 차이값을 기반으로 계산된 값이고, 상기 제2 손실값은 상기 제1 오토인코더가 상기 제2 학습 데이터에 포함된 CT이미지의 각 영역을 분할 한 결과와 상기 제2 오토인코더가 상기 제2 학습 데이터에 포함된 CT 이미지와의 차이값을 기반으로 계산된 값인, 인공지능 모델을 활용한 의료영상 내 각 영역 분할 방법."}
{"patent_id": "10-2023-0152820", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서, 상기 제1 손실값은 다중 클래스 크로스 엔트로피 손실(Multi-class cross entropy loss), L2 손실, 다이스 유사 점수 손실(Dice Similarity Score) 및 IoU(Intersection over Union) 손실을 포함하는, 인공지능 모델을 활용한 의료영상 내 각 영역 분할 방법."}
{"patent_id": "10-2023-0152820", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제2항에 있어서, 상기 제2 손실값은 다중 클래스 크로스 엔트로피 손실(Multi-class cross entropy loss) 및 L2 손실을 포함하는, 인공지능 모델을 활용한 의료영상 내 각 영역 분할 방법."}
{"patent_id": "10-2023-0152820", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서, 상기 CT이미지의 각 영역을 분할하는 것은 CT이미지의 각 픽셀을 배경(Background), 골격근(Skeletal muscle,MUS), 근육간 지방 조직(intermuscular adipose tissue, IMAT), 포화 지방 조직(Saturated adipose tissue,SAT) 및 내장 지방 조직(Visceral adipose tissue, VAT) 중 하나로 분할하는 것인, 인공지능 모델을 활용한 의료영상 내 각 영역 분할 방법.공개특허 10-2025-0024449-3-청구항 6 환자의 CT이미지를 입력 받는 입력장치; 상기 CT(Computed Tomograpy)이미지를 분할 모델(Segmentation Model)에 입력하고, 상기 분할 모델의 출력값을기반으로 상기 CT이미지의 각 영역을 분할하는 연산장치; 및상기 CT이미지 및 분할 모델을 저장하는 저장장치; 를 포함하되, 상기 영상 분할 모델은 제1 학습 데이터 및 제2 학습 데이터를 기반으로 학습된 모델이고, 상기 제1 학습 데이터는 CT이미지 및 제1 학습 데이터에 포함된 CT이미지의 레퍼런스 이미지를 포함하고, 상기 제2 학습 데이터는 CT이미지를 포함하는, 인공지능 모델을 활용한 의료영상 내 각 영역 분할 장치."}
{"patent_id": "10-2023-0152820", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6항에 있어서, 상기 분할 모델은 학습 과정에서 구조는 동일하나 서로 다른 가중치로 초기화 된 제1 오토인코더 및 제2 오토인코더를 이용하고, 상기 분할 모델은 제1 손실값 및 제2 손실값을 포함하는 손실함수 값이 최소가 되도록 학습된 모델이고, 상기 제1 손실값은 상기 제1 오토인코더가 상기 제1 학습 데이터에 포함된 CT이미지의 각 영역을 분할한 결과와상기 제1 학습 데이터에 포함된 레퍼런스 이미지와의 차이값을 기반으로 계산된 값이고, 상기 제2 손실값은 상기 제1 오토인코더가 상기 제2 학습 데이터에 포함된 CT이미지의 각 영역을 분할 한 결과와 상기 제2 오토인코더가 상기 제2 학습 데이터에 포함된 CT 이미지와의 차이값을 기반으로 계산된 값인, 인공지능 모델을 활용한 의료영상 내 각 영역 분할 장치."}
{"patent_id": "10-2023-0152820", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서, 상기 제1 손실값은 다중 클래스 크로스 엔트로피 손실(Multi-class cross entropy loss), L2 손실, 다이스 유사 점수 손실(Dice Similarity Score) 및 IoU(Intersection over Union) 손실을 포함하는, 인공지능 모델을 활용한 의료영상 내 각 영역 분할 장치."}
{"patent_id": "10-2023-0152820", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제7항에 있어서, 상기 제2 손실값은 다중 클래스 크로스 엔트로피 손실(Multi-class cross entropy loss) 및 L2 손실을 포함하는, 인공지능 모델을 활용한 의료영상 내 각 영역 분할 장치."}
{"patent_id": "10-2023-0152820", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제6항에 있어서, 상기 CT이미지의 각 영역을 분할하는 것은 CT이미지의 각 픽셀을 배경(Background), 골격근(Skeletal muscle,MUS), 근육간 지방 조직(intermuscular adipose tissue, IMAT), 포화 지방 조직(Saturated adipose tissue,SAT) 및 내장 지방 조직(Visceral adipose tissue, VAT) 중 하나로 분할하는 것인, 인공지능 모델을 활용한 의료영상 내 각 영역 분할 장치."}
{"patent_id": "10-2023-0152820", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "인공지능 모델을 활용한 의료영상 내 각 영역 분할 방법은 영상 처리 장치가 환자의 CT이미지를 입력 받는 단계; 상기 영상 처리 장치가 상기 CT(Computed Tomograpy)이미지를 분할 모델(Segmentation Model)에 입력하는 단계; 및 상기 영상 처리 장치가 상기 분할 모델의 출력값을 기반으로 상기 CT이미지의 각 영역을 분할하는 단계;를 포 함한다. 상기 영상 분할 모델은 제1 학습 데이터 및 제2 학습 데이터를 기반으로 학습된 모델이다. 상기 제1 학습 데이터 는 CT이미지 및 제1 학습 데이터에 포함된 CT이미지의 레퍼런스 이미지를 포함이다. 상기 제2 학습 데이터는 CT 이미지를 포함한다."}
{"patent_id": "10-2023-0152820", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "이하 설명하는 기술은 인공지능 모델을 활용해 의료영상을 분할하는 방법을 개시한다. 특히 라벨링 데이터가 부 족한 경우에도 분할모델을 학습하는 방법을 제공한다."}
{"patent_id": "10-2023-0152820", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "의료영상은 의학 및 진단에 사용되는 영상을 말한다. 의료영상은 환자의 건강 상태를 시각적으로 확인하고 진단 을 지원하는데 사용된다. 의료영상의 종류로는 X-Ray 영상, 초음파 영상, 자기 공명 영상(MRI) 및 CT영상이 있 다. 최근 인공신경망 기반의 인공지능 모델을 이용해서 의료영상을 분석하는 기술들이 개발되고 있다. 예를 들어 의 료영상을 기반으로 환자에게 병이 있는지 없는지를 분류하는 기술이 개발되고 있다. 또한 의료영상을 기반으로 의료영상 내 병변이 있는 지점을 검출하는 기술도 개발되고 있다. 또한 의료영상을 기반으로 의료영상의 각 영 역을 분할하는 기술도 개발되고 있다. 선행기술문헌 특허문헌 (특허문헌 0001) 한구 등록특허공보 10-2321427"}
{"patent_id": "10-2023-0152820", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "인공신경망 기반의 인공지능 모델을 구축하기 위해서는 많은 양의 학습 데이터가 필요하다. 특히 분할 모델이나 검출 모델을 구축하기 위해서는 정답값이 있는 레퍼런스(Reference) 데이터, 즉 라벨링(Labeled) 된 데이터가 필요하다. 하지만 위와 같은 레퍼런스 데이터를 구축하는 것은 많은 양의 시간과 노력이 필요하다. 레퍼런스 데 이터를 구축하기 위해서 사람이 일일이 정답을 입력해 주어야 하기 때문이다. 특히 의료영상의 경우 일반사람이 아닌 의사등의 전문가등이 의료영상을 보고 정답을 입력해야 하기 때문에 더욱 많은 시간과 노력이 필요하다. 이하 설명하는 기술은 위와 같은 문제점을 해결하기 위하여 많은 양의 라벨링 데이터가 확보되지 않더라도 분할 모델을 학습하는 방법을 제공하고자 한다."}
{"patent_id": "10-2023-0152820", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "인공지능 모델을 활용한 의료영상 내 각 영역 분할 방법은 영상 처리 장치가 환자의 CT이미지를 입력 받는 단계; 상기 영상 처리 장치가 상기 CT(Computed Tomograpy)이미지를 분할 모델(Segmentation Model)에 입력하 는 단계; 및 상기 영상 처리 장치가 상기 분할 모델의 출력값을 기반으로 상기 CT이미지의 각 영역을 분할하는 단계;를 포함한다. 상기 영상 분할 모델은 제1 학습 데이터 및 제2 학습 데이터를 기반으로 학습된 모델이다. 상기 제1 학습 데이 터는 CT이미지 및 제1 학습 데이터에 포함된 CT이미지의 레퍼런스 이미지를 포함이다. 상기 제2 학습 데이터는 CT이미지를 포함한다."}
{"patent_id": "10-2023-0152820", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "이하 설명하는 기술을 이용하면 의료영상에서 각 영역을 분할할 수 있다. 이를 통해 의료인이 의료영상을 보고 분석하는 시간을 대폭 감소 시키거나, 의료인의 판단을 보조할 수 있다. 이하 설명하는 기술을 이용하면 많은 양의 라벨링 데이터가 확보되지 않더라도 분할 모델을 구축할 수 있다. 이 를 통해 라벨링된 학습 데이터를 구축하는데 들어가는 시간과 노력을 감소시킬 수 있다."}
{"patent_id": "10-2023-0152820", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하 설명하는 기술은 다양한 변경을 가할 수 있고 여러 가지 실시예를 가질 수 있다. 명세서의 도면에 이하 설 명하는 기술의 특정 실시 형태가 기재될 수 있다. 그러나, 이는 이하 설명하는 기술의 설명을 위한 것이며 이하 설명하는 기술을 특정한 실시 형태에 대해 한정하려는 것이 아니다. 따라서 이하 설명하는 기술의 사상 및 기술 범위에 포함되는 모든 변경 물, 균등 물 내지 대체 물이 이하 설명하는 기술에 포함하는 것으로 이해되어야 한 다. 다양한 구성요소들을 설명하기 위해서 제1, 제2, A, B 등의 용어가 사용될 수 있다. 하지만 상기 용어는 단지 하나의 구성요소를 다른 구성요소들과 구별하기 위해서 사용될 뿐, 상기 용어로 해당 구성요소들을 한정하려고 하는 것이 아니다. 예를 들어, 이하 설명하는 기술의 권리 범위를 벗어나지 않으면서 제1 구성요소는 제2 구성 요소로 명명될 수 있고, 유사하게 제2 구성요소도 제1 구성요소로 명명될 수 있다. “및/또는” 이라는 용어는 복수의 관련된 기재된 항목들의 조합 또는 복수의 관련된 기재된 항목들 중의 어느 항목을 포함한다. 이하 사용되는 용어에서 단수의 표현은 문맥상 명백하게 다르게 해석되지 않는 한 복수의 표현을 포함하는 것으 로 이해되어야 하고, \"포함한다\" 등의 용어는 기재된 특징, 개수, 단계, 동작, 구성요소, 부분품 또는 이들을 조합한 것이 존재함을 의미하는 것이지, 하나 또는 그 이상의 다른 특징들이나 개수, 단계 동작 구성요소, 부분 품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 배제하지 않는 것으로 이해되어야 한다. 도면에 대한 상세한 설명을 하기에 앞서, 본 명세서에서의 구성부들에 대한 구분은 각 구성부가 담당하는 주기 능 별로 구분한 것에 불과함을 명확히 하고자 한다. 즉, 이하에서 설명할 2개 이상의 구성부가 하나의 구성부로 합쳐지거나 또는 하나의 구성부가 보다 세분화된 기능별로 2개 이상으로 분화되어 구비될 수도 있다. 그리고 이 하에서 설명할 구성 부 각각은 자신이 담당하는 주기능 이외에도 다른 구성부가 담당하는 기능 중 일부 또는 전 부의 기능을 추가적으로 수행할 수도 있으며, 구성부 각각이 담당하는 주기능 중 일부 기능이 다른 구성부에 의 해 전담되어 수행될 수도 있음은 물론이다. 또, 방법 또는 동작 방법을 수행함에 있어서, 상기 방법을 이루는 각 과정들은 문맥상 명백하게 특정 순서를 기 재하지 않은 이상 명기된 순서와 다르게 일어날 수 있다. 즉, 각 과정들은 명기된 순서와 동일하게 일어날 수도 있고 실질적으로 동시에 수행될 수도 있으며 반대의 순서대로 수행될 수도 있다. 본 개시에서, 인공지능(artificial intelligence, AI)은 인공적인 지능 또는 이를 만들 수 있는 방법론을 연구 하는 분야를 의미할 수 있고, 기계 학습(machine learning)은 인공지능 기술의 한 분야로서 컴퓨팅 장치가 데이 터를 통해 학습하여 특정 대상 혹은 조건을 이해할 수 있게 하거나 데이터의 패턴을 찾아내 분류하는 기술적 방 식으로써 컴퓨터가 데이터를 분석할 수 있게 하는 알고리즘일 수 있다. 본 발명에서 개시하는 기계 학습은 인공 지능 모델을 학습하기 위한 동작 방법을 포함하는 의미로서 이해될 수 있다. 이하 영상 처리 장치가 인공지능 모델을 활용한 의료영상 내 각 영역 분할 방법(이하 영역 분할 방법)을 수행하 는 전체적인 과정을 설명한다. 도1은 영상 처리 장치가 영역 분할 방법을 수행하는 전체적인 과정을 보여준다. 영상 처리 장치는 환자의 CT(computed tomography) 이미지를 입력 받을 수 있다. 영상 처리 장치는 CT이미 지를 분할 모델(Segmentation Model)에 입력할 수 있다. 영상 처리 장치는 분할 모델의 출력값을 기반으로 CT이 미지의 각 영역을 분할할 수 있다. 영상 분할 모델은 제1 학습 데이터 및 제2 학습 데이터를 기반으로 학습된 모델일 수 있다. 제1 학습 데이터는 CT이미지 및 제1 학습 데이터에 포함된 CT이미지의 레퍼런스 이미지를 포함할 수 있다. 제2 학습 데이터는 CT이 미지를 포함할 수 있다.이하 영역 분할 방법에 대해 구체적으로 설명한다. 도2는 영역 분할 방법의 실시예 중 하나의 순서도이다. 영상 처리 장치는 CT이미지를 입력 받을 수 있다. CT(Computed tomography)는 컴퓨터와 X선을 사용하여 신체 내부의 단면 이미지를 생성하는 방법 중 하나이다. CT이미지는 환자의 내부 구조를 시각적으로 파악하는데 도움을 준다. 이에 CT이미지는 다양한 의료상황에서 사 용된다. CT이미지는 뇌, 가슴, 복부, 골격계등 다양한 부위 및 장기 진단에 사용된다. CT이미지는 복부 CT이미지일 수 있다. 즉 CT이미지는 환자의 복부를 촬영한 CT이미지일 수 있다. 영상 처리 장치는 상기 CT이미지를 분할 모델에 입력할 수 있다. 분할 모델은 인공신경망(artificial neural network) 기반의 모델일 수 있다. 분할 모델(Segmentation)은 오토 인코더 기반의 모델일 수 있다. 분할 모델은 Consistency Learning기반으로 학습된 모델일 수 있다. 즉 분할 모델은 라벨링 데이터가 있는 학습 데이터 및 라벨링 데이터가 없는 학습 데이터를 기반으로 학습된 모델일 수 있다. 분할 모델의 구조 및 학습 과정에 대해서는 이하에서 구체적으로 설명한다. 영상 처리 장치는 분할 모델의 출력값을 기반으로 복부 CT이미지의 각 영역을 분할할 수 있다. CT이미지의 각 영역을 분할하는 것은 CT이미지의 각 픽셀별로 어떠한 클래스에 속할지 계산하는 것을 의미할 수 있다. 일 실시예로 CT이미지가 복부 CT이미지인 경우 복부 CT이미지의 각 픽셀을 배경(Background), 골격근 (Skeletal muscle, MUS), 근육간 지방 조직(intermuscular adipose tissue, IMAT), 포화 지방 조직(Saturated adipose tissue, SAT) 및 내장 지방 조직(Visceral adipose tissue, VAT) 중 하나로 분할하는 것을 포함할 수 있다. 이하 분할모델을 학습하는 과정에 대해 구체적으로 설명한다. 도3은 분할모델의 학습 과정의 실시예 중 하나를 보여준다. 분할 모델은 오토인코더 기반의 모델일 수 있다. 분할 모델은 NCL(Network Consistency Learning)기반의 학습 방법으로 학습된 모델일 수 있다. 제1 학습 데이터 및 제2 학습 데이터는 분할 모델의 학습을 위해 이용 될 수 있다. 제1 학습 데이터(DL)는 CT이미지(Xl) 및 레퍼런스 이미지(Yl)를 포함한다. 즉 제1 학습 데이터는 CT이미지 및 제 1 학습 데이터에 포함된 CT이미지의 각 영역에 분할된 레퍼런스(Reference) 이미지(또는 라벨링 이미지, Labeld)를 포함할 수 있다. 레퍼런스 이미지는 CT이미지의 각 영역이 분할된 정답 데이터를 의미할 수 있다. 제2 학습 데이터(DU)는 CT이미지(Xu)만을 포함할 수 있다. 즉 제2 학습 데이터에 포함된 CT이미지에 대한 레퍼런 스 이미지는 없을 수 있다. (Unlabled) 제2 학습 데이터의 양은 제1 학습 데이터의 양 보다 많을 수 있다|DL| < |DU|. 이는 일반적으로 레퍼런스 이미지, 즉 라벨링된 데이터를 확보하기 어렵기 때문이다. 필요한 경우 제1 학습 데이터 및 제2 학습 데이터는 데이터 증강 처리 기법을 통해 증강(Augmentation)될 수도 있다. 분할 모델은 학습 과정에서 서로 다른 가중치로 초기화 된 제1 오토인코더(f(θ1)) 및 제2 오토인코더(f(θ2))를 이용할 수 있다. 제1 오토인코더와 제2 오토인코더는 서로 구조는 동일하나 서로 다른 가중치(θ1, θ2) 로 초기화 되어 있다. 제1 오토인코더는 제1 학습 데이터에 포함된 CT이미지를 입력 받을 수 있다. 제1 오토인코더는 제1 학습 데이터 에 포함된 CT이미지의 각 영역을 분할할 수 있다( . 제1 오토인코더의 출력값과 제1 학습 데이터에 포함된 레 퍼런스 데이터(y)의 차이값을 기반으로 제1 손실값이 계산될 수 있다. 즉 제1 손실값은 제1 오토인코더가 제1학습 데이터에 포함된 CT이미지의 각 영역을 분할한 결과와 제1 학습 데이터에 포함된 레퍼런스 이미지와의 차 이값을 기반으로 계산된 값일 수 있다. 일 실시예로 제1 손실값은 상기 제1 손실값은 다중 클래스 크로스 엔트로피 손실(Multi-class cross entropy loss), L2 손실, 다이스 유사 점수 손실(Dice Similarity Score) 및 IoU(Intersection over Union) 손실을 포 함할 수 있다. 수학식1은 다중 크로스 엔트로피 손실을 구할 때 이용되는 식이다. 수학식 1"}
{"patent_id": "10-2023-0152820", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "수학식2는 L2 손실을 구할 때 이용되는 식이다. 수학식 2"}
{"patent_id": "10-2023-0152820", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "수학식3은 다이스 유사 점수 손실을 구할 때 이용되는 식이다. 수학식 3"}
{"patent_id": "10-2023-0152820", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "수학식4는 IoU 손실을 구할 때 이용되는 식이다. 수학식 4"}
{"patent_id": "10-2023-0152820", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "수학식1내지 수학식4에서 N은 학습 데이터의 총 개수를 의미한다. 제1 오토인코더 및 제2 오토인코더는 제2 학습 데이터에 포함된 CT이미지를 입력 받을 수 있다. 제1 오토인코더 및 제2 오토인코더는 제2 학습 데이터에 포함된 CT이미지의 각 영역을 분할할 수 있다. 제1 오토인코더의 출력 값( 과 제2 오토인코더의 출력값( 의 차이 값을 기반으로 제2 손실값이 계산될 수 있다. 즉 제2 손실값은 제1 오토인코더가 제2 학습 데이터에 포함된 CT이미지의 각 영역을 분할 한 결과와 제2 오토인코더가 제2 학습 데이터에 포함된 CT 이미지와의 차이값을 기반으로 계산된 값일 수 있다. 일 실시예로 제2 손실값은 다중 클래스 크로스 엔트로피 손실(Multi-class cross entropy loss), L2 손실을 포 함할 수 있다. 분할 모델은 손실함수의 값이 최소가 되도록 학습될 수 있다. 손실함수의 값은 제1 손실값 및 제2 손실값을 포 함한다. 즉 제1 학습 데이터가 제1 오토인코더의 분할 성능을 향상시키기게 함과 동시에 제2 학습 데이터가 제1 오토인코더 및 제2 오토인코더를 유사하게 할 수 있다. 이는 제1 학습 데이터의 양이 제2 학습 데이터의 양보다 많은 경우에 더욱 유용하다. 이를 통해 레퍼런스 데이터를 확보하지 못한 상황에서도 분할모델을 학습시킬 수 있다. 이하 분할모델의 일실시예에 대해 살펴본다. 분할 모델은 원본 이미지 해상도를 감소시키지 않으면서도 제한된 메모리를 활용해 제1 오토인코더 및 제2 오토 인코더를 학습시키기 위하여 경량화된(LightWeight) 모델일 수 있다. 분할 모델은 오토인코더 기반의 모델일 수 있다. 이에 분할 모델은 인코더-디코더를 포함할 수 있다. 인코더는 11개의 novel Res-ConV 블록과 5개의 Max Pool 레이어를 포함할 수 있다. 디코더는 4개의 Res-Conv 블록과 5개의 ConvTranspose 레이어를 포함할 수 있다. 도4는 Res-ConV 블록의 내부 구조를 보여준다. Res-Conv블록은 가중치가 부여된 공간 어텐션(Fs) 및 채널 어텐션(Fc)를 기반으로 입력(Fin)와 입력으로부터 추 출된 특징(FConv)을 응집(Aggregate)한다. 어텐션 가중치는 훈련과정에서 학습될 수 있다. 마지막 예측은 1x1 컨볼루션 레이어를 통하여 획득할 수 있다. 이하 분할 모델을 실제로 구축하고 구축된 분할 모델의 성능을 평가한 실험결과에 대해 살펴본다. 분할모델을 구추가기 위하여 경북대 병원에서 획득한 CT이미지를 이용하였다. CT이미지 중 157개의 CT이미지는5개로 영역으로 분할되었다. 분할된 5개의 영역은 배경(Background), 골격근 (Skeletal muscle, MUS), 근육간 지방 조직(intermuscular adipose tissue, IMAT), 포화 지방 조직(Saturated adipose tissue, SAT) 및 내장 지방 조직(Visceral adipose tissue, VAT) 이다. 분할된 157개의 CT이미지 중 103개는 학습(Training) 데이터로 54개는 검증(Validation) 데이터로 이용되었다. 이와 함께 라벨링 데이터가 없는 218개의 데이터도 함께 이용되었다. 모델 학습에 이용되는 CT이미지는 뒤집기(Flips), 크로핑(Cropping), 사이즈 조절(rezie)등의 기법을 통해 데이 터 증강을 거치게 되었다. 도5는 분할 모델의 성능을 대조군과 비교한 결과이다. 구체적으로 분할 모델(NCL)과 대조군을 비교한 결과이다. 성능 지표로는 DSC 및 IoU가 이용되었다. 전체적으로 전술한 학습 방법을 적용한 모델의 성능이 그 대조군보다 높은 것을 확인할 수 있다. 약 10% 또는 12% 정도의 성능이 향상된 것을 확인할 수 있다. 도6은 분할 모델이 CT이미지에서 각 영역을 분할할 결과를 보여준다. 분할 모델이 CT이미지에서 각 영역을 분할할 결과(Predicted Mask)는 그 레퍼런스 데이터(Target Mask)와 상당 히 유사한 것을 확인할 수 있다. 이하 도7을 통해 영상 처리 장치에 대해 설명한다. 도7은 영상 처리 장치의 실시예 중 하나의 구성이다. 영상 처리 장치는 도1에서 설명한 영상 처리 장치에 해당할 수 있다. 즉 영상 처리 장치는 전술 한 영역 분할 방법을 수행하는 장치일 수 있다. 영상 처리 장치는 물리적으로 다양한 형태로 구현될 수 있다. 예를 들어 영상 처리 장치는 PC, 노트 북, 스마트기기, 서버 또는 데이터처리 전용 칩셋 등의 형태를 가질 수 있다. 영상 처리 장치는 입력장치, 저장장치, 연산장치, 출력장치, 인터페이스 장치 및 통신장치를 포함할 수 있다. 입력장치는 일정한 명령 또는 데이터를 입력 받는 인터페이스 장치(키보드, 마우스, 터치스크린 등)를 포 함할 수도 있다. 입력장치는 별도의 저장장치(USB, CD, 하드디스크 등)를 통하여 정보를 입력 받는 구성을 포함할 수도 있다. 입력장치는 입력 받는 데이터를 별도의 측정장치를 통하여 입력 받거나, 별도의 DB를 통하여 입력 받을 수도 있다. 입력장치는 통신장치을 통해 데이터를 유선 또는 무선 통신으로 입력 받을 수도 있다. 입력장치는 전술한 영역 분할 방법을 수행하는데 필요한 정보를 입력 받을 수 있다. 입력장치는 전술 한 영역 분할 방법을 수행하는데 필요한 모델을 입력 받을 수 있다. 입력장치는 CT이미지를 입력 받을 수 있다. 입력장치는 분할 모델을 입력 받을 수 있다. 저장장치는 일정한 정보를 저장하는 장치가 될 수도있다. 저장장치는 입력장치를 통해 입력 받 은 정보를 저장할 수 있다. 저장장치는 연산장치가 연산하는 과정에서 생성되는 정보를 저장할 수 있 다. 즉 저장장치는 메모리를 포함할 수 있다. 저장장치는 전술한 영역 분할 방법을 수행하는데 필요한 정보를 저장할 수 있다. 저장장치는 전술한 영역 분할 방법을 수행하는데 필요한 모델을 저장할 수 있다. 저장장치는 CT이미지를 저장할 수 있다. 저 장장치는 분할 모델을 저장할 수 있다. 연산장치는 데이터를 처리하고, 일정한 연산을 처리하는 프로세서, AP, 프로그램이 임베디드된 칩과 같은 장치일 수 있다. 연산장치는 영상 처리 장치를 제어하는 제어신호를 생성할 수 있다. 연산장치(33 0)는 영상 처리 장치에 포함된 입력장치, 저장장치, 출력장치, 인터페이스 장치 및 통신장치을 제어하는 제어신호를 생성할 수 있다. 연산장치는 전술한 영역 분할 방법을 수행하는데 필요한 연산을 할 수 있다. 연산장치는 CT(Computed Tomograpy)이미지를 분할 모델(Segmentation Model)에 입력할 수 있다. 연산장치는 분할 모델의 출력값을 기반으로 상기 CT이미지의 각 영역을 분할할 수 있다. 출력장치는 일정한 정보를 출력하는 장치가 될 수도 있다. 출력장치는 데이터 과정에 필요한 인터페 이스, 입력된 데이터, 분석결과 등을 출력할 수도 있다. 출력장치는 디스플레이, 문서를 출력하는 장치, 스피커등과 같이 물리적으로 다양한 형태로 구현될 수도 있다. 출력장치는 저장장치에 저장된 정보를 출력할 수 있다. 출력장치는 연산장치가 연산하는 과정에서 생성된 정보를 출력할 수 있다. 출력장치 는 연산장치가 연산한 결과를 출력할 수 있다. 인터페이스 장치는 외부로부터 일정한 명령 및 데이터를 입력 받는 장치일 수 있다. 인터페이스 장치(35 0)는 영상 처리 장치를 제어하기 위한 제어신호를 입력 받을 수 있다. 인터페이스 장치는 영상 처리 장치가 분석한 결과를 출력할 수 있다. 인터페이스 장치는 물리적으로 연결된 입력 장치 또는 외부 저장장치로부터 영역 분할 방법을 수행하는데 필요한 정보를 입력 받을 수 있다. 통신장치는 유선 또는 무선 네트워크를 통해 일정한 정보를 수신하고 전송하는 구성을 의미할 수 있다. 통 신장치는 Wi-Fi(Wireless Fidelity), Wi-Fi Direct, 블루투스(Bluetooth), UWB(Ultra Wide Band) 또는 NFC(Near Field Communication), USB(Universal Serial Bus), 혹은 HDMI(High Definition Multimedia Interface), LAN(Local Area Network) 등과 같은 네트워크 통신을 수행할 수 있다. 통신장치는 영상 처리 장치를 제어하는데 필요한 제어 신호를 수신할 수 있다. 통신장치는 영상 처리 장치가 분석한 결과를 전송할 수 있다. 통신장치는 영역 분할 방법을 수행하는데 필요한 정보를 수신받을 수 있다. 통신장치는 영역 분할 방 법을 수행하는데 필요한 모델을 수신 받을 수 있다. 전술한 영상 분할 방법은 컴퓨터에서 실행될 수 있는 실행가능한 알고리즘을 포함하는 프로그램(또는 어플리케 이션)으로 구현될 수 있다. 상기 프로그램은 일시적 또는 비일시적 판독 가능 매체(non-transitory computer readable medium)에 저장되어 제공될 수 있다. 상기 일시적 판독 가능 매체는 스태틱 램(Static RAM，SRAM), 다이내믹 램(Dynamic RAM，DRAM), 싱크로너스 디 램 (Synchronous DRAM，SDRAM), 2배속 SDRAM(Double Data Rate SDRAM，DDR SDRAM), 증강형 SDRAM(Enhanced SDRAM，ESDRAM), 동기화 DRAM(Synclink DRAM，SLDRAM) 및 직접 램버스 램(Direct Rambus RAM，DRRAM) 과 같은 다양한 RAM을 의미한다. 상기 비일시적 판독 가능 매체는 레지스터, 캐쉬, 메모리 등과 같이 짧은 순간 동안 데이터를 저장하는 매체가 아니라 반영구적으로 데이터를 저장하며, 기기에 의해 판독(reading)이 가능한 매체를 의미한다. 구체적으로는, 상술한 다양한 어플리케이션 또는 프로그램들은 CD, DVD, 하드 디스크, 블루레이 디스크, USB, 메모리카드, ROM (read-only memory), PROM (programmable read only memory), EPROM(Erasable PROM, EPROM) 또는 EEPROM(Electrically EPROM) 또는 플래시 메모리 등과 같은 비일시적 판독 가능 매체에 저장되어 제공될 수 있 다. 본 실시예 및 본 명세서에 첨부된 도면은 전술한 기술에 포함되는 기술적 사상의 일부를 명확하게 나타내고 있 는 것에 불과하며, 전술한 기술의 명세서 및 도면에 포함된 기술적 사상의 범위 내에서 당업자가 용이하게 유추 할 수 있는 변형 예와 구체적인 실시예는 모두 전술한 기술의 권리범위에 포함되는 것이 자명하다고 할 것이다."}
{"patent_id": "10-2023-0152820", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도1은 영상 처리 장치가 영역 분할 방법을 수행하는 전체적인 과정을 보여준다. 도2는 영역 분할 방법의 실시예 중 하나의 순서도이다. 도3은 분할모델의 학습 과정의 실시예 중 하나를 보여준다. 도4는 Res-ConV 블록의 내부 구조를 보여준다. 도5는 분할 모델의 성능을 대조군과 비교한 결과이다. 도6은 분할 모델이 CT이미지에서 각 영역을 분할할 결과를 보여준다. 도7은 영상 처리 장치의 실시예 중 하나의 구성이다."}
