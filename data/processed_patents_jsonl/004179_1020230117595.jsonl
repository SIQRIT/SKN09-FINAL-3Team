{"patent_id": "10-2023-0117595", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2025-0035222", "출원번호": "10-2023-0117595", "발명의 명칭": "얼굴 표정 생성 장치", "출원인": "주식회사 엘리펀트에이아이", "발명자": "김동래"}}
{"patent_id": "10-2023-0117595", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "표정 변화가 없는 제1 얼굴 데이터 및 표정 변화가 있는 제2 얼굴 데이터를 각각 입력 받는 얼굴 데이터입력부; 및상기 제2 얼굴 데이터의 얼굴 움직임 정보를 상기 제1 얼굴 데이터에 적용하여 상기 제1 얼굴 데이터에 포함된얼굴에 표정 변화가 적용된 제3 얼굴 데이터를 생성하여 출력하는 얼굴 데이터 처리부를 포함하는 것을 특징으로 하는 얼굴 표정 생성 장치."}
{"patent_id": "10-2023-0117595", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1 항에 있어서,상기 얼굴 데이터 입력부는,얼굴 표정 변화가 적용될 객체의 얼굴 사진 또는 이미지 파일을 포함하는 상기 제1 얼굴 데이터를 입력 받는 제1 얼굴 데이터 입력부; 및시간의 흐름에 따라 얼굴 표정 변화가 있는 객체의 얼굴 동영상 파일을 포함하는 상기 제2 얼굴 데이터를 입력받는 제2 얼굴 데이터 입력부를 포함하는 것을 특징으로 하는 얼굴 표정 생성 장치."}
{"patent_id": "10-2023-0117595", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1 항에 있어서,상기 얼굴 데이터 처리부는,상기 제1 얼굴 데이터로부터 미리 정의된 위치의 얼굴 특징점을 인식하고, 인식된 다수의 제1 얼굴 특징점을 추출하는 제1 얼굴 특징점 인식부;상기 제2 얼굴 데이터로부터 미리 정의된 위치의 얼굴 특징점을 인식하고, 인식된 다수의 제2 얼굴 특징점을 추출하는 제2 얼굴 특징점 인식부;상기 제1 얼굴 특징점 및 상기 제2 얼굴 특징점 간을 서로 1:1 매칭하는 얼굴 특징점 매칭부;상기 제2 얼굴 특징점에 대한 움직임을 분석하여 제2 얼굴 특징점 움직임 정보를 생성하는 제2 얼굴 특징점 움직임 정보 생성부; 및상기 제2 얼굴 특징점 움직임 정보를 상기 제1 얼굴 데이터의 얼굴 특징점에 반영하여 상기 제1 얼굴 데이터에포함된 얼굴에 시간의 흐름에 따른 표정 변화가 적용된 상기 제3 얼굴 데이터를 생성하는 제3 얼굴 데이터 생성부를 포함하는 것을 특징으로 하는 얼굴 표정 생성 장치."}
{"patent_id": "10-2023-0117595", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3 항에 있어서,상기 제2 얼굴 특징점 움직임 정보 생성부는,2차원 공간 상에서 인식된 상기 제2 얼굴 특징점 각각에 대하여 시간 변화량에 따른 벡터값을 추출하여 상기 제2 얼굴 특징점 움직임 정보를 생성하는 것을 특징으로 하는 얼굴 표정 생성 장치.공개특허 10-2025-0035222-3-청구항 5 제4 항에 있어서,상기 제2 얼굴 특징점 움직임 정보 생성부는,3차원 공간 상에서의 얼굴 특징점 움직임 정보에 대하여 기계 학습된 인공지능 알고리즘이 미리 구축되고, 상기인공지능 알고리즘에 상기 제2 얼굴 특징점 움직임 정보를 입력하여 Z축에 대한 추가 얼굴 특징점 움직임 정보를 출력하고, 상기 추가 얼굴 특징점 움직임 정보를 상기 제2 얼굴 특징점 움직임 정보와 결합하여 3차원 공간상에서의 얼굴 특징 움직임 정보를 생성하는 것을 특징으로 하는 얼굴 표정 생성 장치."}
{"patent_id": "10-2023-0117595", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 얼굴 표정 생성 장치에 관한 것으로, 해결하고자 하는 과제는 표정 변화를 적용하기를 원하는 대상의 얼굴에 실제 다양한 표정을 구사하는 대상의 얼굴의 움직임을 반영함으로써 보다 다양하고 자연스러운 표정 변화 를 구현하는데 있다. 일례로, 표정 변화가 없는 제1 얼굴 데이터 및 표정 변화가 있는 제2 얼굴 데이터를 각각 입력 받는 얼굴 데이터 입력부; 및 상기 제2 얼굴 데이터의 얼굴 움직임 정보를 상기 제1 얼굴 데이터에 적용하여 상기 제1 얼굴 데이터 에 포함된 얼굴에 표정 변화가 적용된 제3 얼굴 데이터를 생성하여 출력하는 얼굴 데이터 처리부를 포함하는 얼 굴 표정 생성 장치를 개시한다."}
{"patent_id": "10-2023-0117595", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명의 실시예는 얼굴 표정 생성 장치에 관한 것이다."}
{"patent_id": "10-2023-0117595", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "멀티 미디어 기술이 발달함에 따라, 사람들은 스마트폰과 같은 디지털 기기를 이용하여 용이하게 영상을 촬영하 고 재생하면서, 영상 내의 인물의 인상을 원하는 대로 임의 조작하여 변형시킬 수 있게 되었다. 촬영 영상 내의 인물의 얼굴형이나 얼굴 구조 등을 고려하지 않고, 동일한 패턴으로 인물의 인상을 변형하면, 본 얼굴과 괴리감이 있을 뿐만 아니라, 실제 얼굴이 특정 표정을 지었을 때와 대비하여 다소 어색한 표정을 짓 게 될 수 밖에 없으며, 프로그램 상에서 미리 정해 놓은 표정 이외에 다양한 표정 변화에 대한 구현에 한계가 있을 수 밖에 없다. 선행기술문헌 특허문헌 (특허문헌 0001) 공개특허공보 제10-2013-0032620호(공개일자: 2013년04월02일) (특허문헌 0002) 공개특허공보 제10-2017-0047167호(공개일자: 2027년05월04일)"}
{"patent_id": "10-2023-0117595", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명의 실시예는, 표정 변화를 적용하기를 원하는 대상의 얼굴에 실제 다양한 표정을 구사하는 대상의 얼굴 의 움직임을 반영함으로써 보다 다양하고 자연스러운 표정 변화를 구현할 수 있는 얼굴 표정 생성 장치를 제공 한다."}
{"patent_id": "10-2023-0117595", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 실시예에 따른 얼굴 표정 생성 장치는, 표정 변화가 없는 제1 얼굴 데이터 및 표정 변화가 있는 제2 얼굴 데이터를 각각 입력 받는 얼굴 데이터 입력부; 및 상기 제2 얼굴 데이터의 얼굴 움직임 정보를 상기 제1 얼굴 데이터에 적용하여 상기 제1 얼굴 데이터에 포함된 얼굴에 표정 변화가 적용된 제3 얼굴 데이터를 생성하 여 출력하는 얼굴 데이터 처리부를 포함한다. 또한, 상기 얼굴 데이터 입력부는, 얼굴 표정 변화가 적용될 객체의 얼굴 사진 또는 이미지 파일을 포함하는 상 기 제1 얼굴 데이터를 입력 받는 제1 얼굴 데이터 입력부; 및 시간의 흐름에 따라 얼굴 표정 변화가 있는 객체 의 얼굴 동영상 파일을 포함하는 상기 제2 얼굴 데이터를 입력 받는 제2 얼굴 데이터 입력부를 포함할 수 있다. 또한, 상기 얼굴 데이터 처리부는, 상기 제1 얼굴 데이터로부터 미리 정의된 위치의 얼굴 특징점을 인식하고, 인식된 다수의 제1 얼굴 특징점을 추출하는 제1 얼굴 특징점 인식부; 상기 제2 얼굴 데이터로부터 미리 정의된위치의 얼굴 특징점을 인식하고, 인식된 다수의 제2 얼굴 특징점을 추출하는 제2 얼굴 특징점 인식부; 상기 제1 얼굴 특징점 및 상기 제2 얼굴 특징점 간을 서로 1:1 매칭하는 얼굴 특징점 매칭부; 상기 제2 얼굴 특징점에 대 한 움직임을 분석하여 제2 얼굴 특징점 움직임 정보를 생성하는 제2 얼굴 특징점 움직임 정보 생성부; 및 상기 제2 얼굴 특징점 움직임 정보를 상기 제1 얼굴 데이터의 얼굴 특징점에 반영하여 상기 제1 얼굴 데이터에 포함 된 얼굴에 시간의 흐름에 따른 표정 변화가 적용된 상기 제3 얼굴 데이터를 생성하는 제3 얼굴 데이터 생성부를 포함할 수 있다. 또한, 상기 제2 얼굴 특징점 움직임 정보 생성부는, 2차원 공간 상에서 인식된 상기 제2 얼굴 특징점 각각에 대 하여 시간 변화량에 따른 벡터값을 추출하여 상기 제2 얼굴 특징점 움직임 정보를 생성할 수 있다. 또한, 상기 제2 얼굴 특징점 움직임 정보 생성부는, 3차원 공간 상에서의 얼굴 특징점 움직임 정보에 대하여 기 계 학습된 인공지능 알고리즘이 미리 구축되고, 상기 인공지능 알고리즘에 상기 제2 얼굴 특징점 움직임 정보를 입력하여 Z축에 대한 추가 얼굴 특징점 움직임 정보를 출력하고, 상기 추가 얼굴 특징점 움직임 정보를 상기 제 2 얼굴 특징점 움직임 정보와 결합하여 3차원 공간 상에서의 얼굴 특징 움직임 정보를 생성할 수 있다. 또한, 상기 얼굴 데이터 입력부는, 상기 제2 얼굴 데이터를 입력 받되, 서로 다른 객체 또는 서로 다른 표정 변 화가 있는 적어도 두 개의 제2 얼굴 데이터를 입력 받고, 상기 얼굴 데이터 처리부는, 상기 적어도 두 개의 제2 얼굴 데이터를 대상으로 서로 다른 얼굴 영역에 대한 얼굴 특징점을 각각 나누어 인식하도록 상기 제2 얼굴 특 징점 인식부의 기능 동작을 설정하는 제2 얼굴 특징점 인식 설정부를 더 포함하고, 상기 제2 얼굴 특징점 인식 부는, 상기 제2 얼굴 특징점 인식 설정부의 기능 동작 설정에 따라 상기 적어도 두 개의 제2 얼굴 데이터 중 어 느 한 얼굴 데이터에 대하여 특정 얼굴 영역에 대한 얼굴 부분 특징점을 인식 및 추출하고, 나머지 다른 얼굴 데이터에 대하여 나머지 특정 얼굴 영역에 대한 얼굴 부분 특징점을 인식 및 추출하는 방식으로 동작하고, 얼굴 부분 특징점들을 취합하여 상기 제2 얼굴 특징점으로서 상기 얼굴 특징점 매칭부와 공유할 수 있다. 또한, 상기 제2 얼굴 특징점 인식 설정부는, 상기 적어도 두 개의 제2 얼굴 데이터에 대하여 얼굴 특징점에 각 각 할당된 고유번호의 범위를 서로 다르게 설정하여 상기 적어도 두 개의 제2 얼굴 데이터에 대하여 서로 다른 얼굴 영역을 각각 지정할 수 있다."}
{"patent_id": "10-2023-0117595", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명에 따르면, 표정 변화를 적용하기를 원하는 대상의 얼굴에 실제 다양한 표정을 구사하는 대상의 얼굴의 움직임을 반영함으로써 보다 다양하고 자연스러운 표정 변화를 구현할 수 있는 얼굴 표정 생성 장치를 제공할 수 있다."}
{"patent_id": "10-2023-0117595", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 명세서에서 사용되는 용어에 대해 간략히 설명하고, 본 발명에 대해 구체적으로 설명하기로 한다. 본 발명에서 사용되는 용어는 본 발명에서의 기능을 고려하면서 가능한 현재 널리 사용되는 일반적인 용어들을 선택하였으나, 이는 당 분야에 종사하는 기술자의 의도 또는 판례, 새로운 기술의 출현 등에 따라 달라질 수 있 다. 또한, 특정한 경우는 출원인이 임의로 선정한 용어도 있으며, 이 경우 해당되는 발명의 설명 부분에서 상세 히 그 의미를 기재할 것이다. 따라서 본 발명에서 사용되는 용어는 단순한 용어의 명칭이 아닌, 그 용어가 가지 는 의미와 본 발명의 전반에 걸친 내용을 토대로 정의되어야 한다. 명세서 전체에서 어떤 부분이 어떤 구성요소를 \"포함\"한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다른 구성요소를 제외하는 것이 아니라 다른 구성요소를 더 포함할 수 있음을 의미한다. 또한, 명세서에 기재된 \"...부\", \"모듈\" 등의 용어는 적어도 하나 이상의 기능이나 동작을 처리하는 단위를 의미하며, 이는 하드웨어 또는 소프트웨어로 구현되거나 하드웨어와 소프트웨어의 결합으로 구현될 수 있다. 아래에서는 첨부한 도면을 참고하여 본 발명의 실시예에 대하여 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자가 용이하게 실시할 수 있도록 상세히 설명한다. 그러나 본 발명은 여러 가지 상이한 형태로 구현될 수 있으며 여기에서 설명하는 실시예에 한정되지 않는다. 그리고 도면에서 본 발명을 명확하게 설명하기 위해서 설 명과 관계없는 부분은 생략하였으며, 명세서 전체를 통하여 유사한 부분에 대해서는 유사한 도면 부호를 붙였다. 도 1은 본 발명의 실시예에 따른 얼굴 표정 생성 장치의 개요도이다. 도 1을 참조하면, 본 발명의 실시예에 따른 얼굴 표정 생성 장치는 사용자 통신단말를 포함할 수 있으 며, 추가적으로 인공지능 서버를 더 포함할 수 있다. 상기 사용자 통신단말은 제1 인물의 얼굴이 촬영된 사진 또는 이미지 형태의 제1 얼굴 데이터와, 제2 인물 의 얼굴이 촬영된 동영상 형태의 제2 얼굴 데이터를 각각 입력 받고, 입력된 제2 얼굴 데이터의 얼굴 움직임 정 보를 제1 얼굴 데이터에 적용하여 제1 얼굴 데이터에 포함된 제1 인물의 얼굴에 제2 인물의 표정 변화가 적용된 제3 얼굴 데이터를 생성하여 출력할 수 있다. 여기서, 제1 인물과 제2 인물은 서로 다른 인물인 것이 바람직하 나, 서로 동일한 인물이더라도 무방하다. 다만, 서로 다른 인물의 경우 제2 인물이 표정 또는 표정의 변화가 다 양한 인물을 적용되는 것이 제1 인물에 대한 보다 더 다양하고 풍부한 표정 또는 표정 변화를 적용할 수 있음에 따라 더욱 유리하다고 볼 수 있다. 본 실시예에 따른 제2 얼굴 데이터는 반드시 하나의 동영상만을 포함할 필요 는 없으며, 두 개 이상의 동영상 파일이 적용될 수 있으며, 각 동영상 파일에 촬영된 인물이 동일 인물이거나 서로 다른 인물일 수도 있다. 이러한 사용자 통신단말은 스마트폰(smartphone), 스마트 패드(smartpad), 타블렛 PC(Tablet PC), PCS(Personal Communication System), GSM(Global System for Mobile communications), PDC(Personal Digital Cellular), PHS(Personal Handyphone System), PDA(Personal Digital Assistant), IMT(International Mobile Telecommunication)-2000, CDMA(Code Division Multiple Access)-2000, W-CDMA(W-Code Division Multiple Access), Wibro(Wireless Broadband Internet) 단말 등 서비스 요청자가 휴대 가능한 무선 통신 장치 및 거치 형 PC, 노트북과 같은 휴대용 컴퓨팅 장치를 포괄할 수 있다. 상기 인공지능 서버는 사용자 통신단말의 일부 기능을 처리하거나 분업하는 형태로 얼굴 표정 생성 프 로세스의 처리가 가능하도록 구성될 수 있다. 예를 들어, 사용자 통신단말에서 제1 및 제2 얼굴 데이터가 입력되면, 입력된 데이터를 인공지능 서버가 수신하여 얼굴 표정 생성 프로세스를 처리한 후 그 결과물인 제3 얼굴 데이터를 사용자 통신단말로 전송하는 형태의 동작이 이루어지도록 구성되거나, 후술하겠지만 인 공지능 알고리즘을 활용하여 얼굴의 표정 변화에 따른 움직임 정보와 관련하여 Z축 벡터값을 예측하기 위한 프 로세스만 처리하도록 구성될 수도 있다. 이러한 인공지능 서버는, 하드웨어적으로 통상적인 웹 서버와 동일한 구성을 가지며, 소프트웨어적으로는 C, C++, Java, Visual Basic, Visual C 등과 같은 다양한 형태의 언어를 통해 구현되어 여러 가지 기능을 하는 프로그램 모듈을 포함할 수 있으며, 인공지능 기술(머신러닝 알고리즘)이 탑재되어 얼굴의 표정 변화에 대한 벡 터값 추정과 관련된 다양한 기능을 수행할 수 있다. 또한, 일반적인 서버용 하드웨어에 도스(dos), 윈도우 (window), 리눅스(linux), 유닉스(unix), 매킨토시(macintosh), 안드로이드(Android), 아이오에스(iOS) 등의 운영 체제에 따라 다양하게 제공되고 있는 웹 서버 프로그램을 이용하여 구현될 수 있다. 본 실시예에 따른 사용자 통신단말 및 인공지능 서버 간을 연결하는 네트워크 통신의 일 예로는, 이동 통신을 위한 기술표준들 또는 통신방식(예를 들어, GSM(Global System for Mobile communication), CDMA(Code Division Multi Access), CDMA2000(Code Division Multi Access 2000), EV-DO(Enhanced Voice-Data Optimized or Enhanced Voice-Data Only), WCDMA(Wideband CDMA), HSDPA(High Speed Downlink Packet Access), HSUPA(High Speed Uplink Packet Access), LTE(Long Term Evolution), LTE-A(Long Term Evolution-Advanced), 5G 등)에 따라 구축된 이동 통신망을 포함할 수 있으나, 특별히 한정하는 것은 아니다. 또한, 유선 통신망의 일 예로는, LAN(Local Area Network), WAN(Wide Area Network)등의 폐쇄형 네트워크일 수 있으며, 인터넷과 같은 개방형 네트워크인 것이 바람직하다. 인터넷은 TCP/IP 프로토콜 및 그 상위계층에 존재하는 여러 서비스, 즉 HTTP(HyperText Transfer Protocol), Telnet, FTP(File Transfer Protocol), DNS(Domain Name System), SMTP(Simple Mail Transfer Protocol), SNMP(Simple Network Management Protocol), NFS(Network File Service), NIS(Network Information Service)를 제공하는 전세계적인 개방형 컴퓨터 네트워크 구조를 의미한다. 도 2는 본 발명의 실시예에 따른 얼굴 표정 생성 장치의 구성을 나타낸 블록도이고, 도 3은 본 발명의 실시예에 따른 얼굴 데이터 입력부의 구성을 나타낸 블록도이고, 도 4는 본 발명의 실시예에 따른 얼굴 데이터 처리부의 구성을 나타낸 블록도이고, 도 5는 본 발명의 실시예에 따른 제1 및 제2 얼굴 특징점 인식부를 통한 얼굴 특징 점들을 인식한 결과에 대한 일례를 나타낸 도면이고, 도 6은 본 발명의 실시예에 따른 얼굴 특징점 매칭부의 기 능 구성을 설명하기 위해 나타낸 도면이고, 도 7은 본 발명의 실시예에 따른 제2 얼굴 특징점 움직임 정보 생성 부 의 기능 구성을 설명하기 위해 나타낸 도면이고, 도 8은 본 발명의 실시예에 따른 제2 얼굴 특징점 움직임 정보 생성부의 3차원 상에서 제2 얼굴 특징점 움직임 정보(벡터값_XYZ)를 생성하는 구성을 설명하기 위해 나타 낸 도면이고, 도 9는 본 발명의 실시예에 따른 얼굴 데이터 생성부 의 기능 구성을 설명하기 위해 나타낸 도면 이고, 도 10은 본 발명의 실시예에 따른 얼굴 데이터에 대한 출력 데이터의 구성 및 예시를 정리하여 나타낸 도 면이고, 도 11은 본 발명의 실시예에 따른 제2 얼굴 특징점 인식 설정부의 기능 구성을 설명하기 위해 나타낸 도면이며, 도 12 및 도 13은 본 발명의 실시예에 따른 제2 얼굴 특징점 인식 설정부를 통한 ROI 설정에 따른 얼 굴 특징점 매칭부, 제2 얼굴 특징점 움직임 정보 생성부 및 얼굴 데이터 생성부의 기능 구성을 설명하기 위해 나타낸 도면이다. 도 2를 참조하면, 본 발명의 실시예에 따른 얼굴 표정 생성 장치는 얼굴 데이터 입력부와 얼굴 데이 터 처리부 중 적어도 하나를 포함할 수 있다. 상기 얼굴 데이터 입력부는 표정 변화가 없는 제1 얼굴 데이터 및 표정 변화가 있는 제2 얼굴 데이터를 각 각 입력 받을 수 있다. 이를 위해, 얼굴 데이터 입력부는 도 3에 도시된 바와 같이 제1 얼굴 데이터 입력부와 제2 얼굴 데이 터 입력부 중 적어도 하나를 포함할 수 있다. 상기 제1 얼굴 데이터 입력부는 얼굴 표정 변화가 적용될 객체(이하 제1 인물이라고 함)의 얼굴 사진 또는 이미지 파일을 포함하는 제1 얼굴 데이터를 입력 받을 수 있다. 상기 제2 얼굴 데이터 입력부는 시간의 흐름에 따라 얼굴 표정 변화가 있는 객체(이하 제2 인물이라고 함)의 얼굴 동영상 파일을 포함하는 제2 얼굴 데이터를 입력 받을 수 있다. 본 실시예에서, 제1 인물과 제2 인물은 서로 다른 인물인 것이 바람직하나, 서로 동일한 인물이더라도 무방하다. 다만, 서로 다른 인물의 경우 제2 인물이 표정 또는 표정의 변화가 다양한 인물을 적용되는 것이 제1 인물에 대한 보다 더 다양하고 풍부한 표정 또는 표정 변화를 적용할 수 있음에 따라 더욱 유리하다고 볼 수 있 다. 본 실시예에 따른 제2 얼굴 데이터는 반드시 하나의 동영상만을 포함할 필요는 없으며, 두 개 이상의 동영 상 파일이 적용될 수 있으며, 각 동영상 파일에 촬영된 인물이 동일 인물이거나 서로 다른 인물일 수도 있다. 상기 얼굴 데이터 처리부는, 제2 얼굴 데이터의 얼굴 움직임 정보를 제1 얼굴 데이터에 적용하여 제1 얼굴 데이터에 포함된 얼굴에 표정 변화가 적용된 제3 얼굴 데이터를 생성하여 출력할 수 있다.이를 위해 얼굴 데이터 처리부는 도 4에 도시된 바와 같이 제1 얼굴 특징점 인식부, 제2 얼굴 특징점 인식부, 얼굴 특징점 매칭부, 제2 얼굴 특징점 움직임 정보 생성부, 얼굴 데이터 생성부 및 제2 얼굴 특징점 인식 설정부 중 적어도 하나를 포함할 수 있다. 상기 제1 얼굴 특징점 인식부는 제1 얼굴 데이터(제1 인물의 얼굴 사진 또는 이미지)로부터 미리 정의된 위치의 얼굴 특징점들(이하 제1 얼굴 특징점이라고 함)을 각각 인식하고, 도 5에 도시된 바와 같이 인식된 다수 의 제1 얼굴 특징점(예를 들어 68개)을 추출할 수 있다. 제1 얼굴 특징점은 영상 내의 얼굴 영역에서 눈썹, 눈, 코, 입술, 턱 라인 등 그 위치가 미리 정의되어 있으며, 제1 인물의 얼굴 영역으로부터 인식되는 다수 개(예를 들어 68개)의 점 분포도로서 표출될 수 있다. 이와 같이 제1 얼굴 데이터에서 제1 얼굴 특징점을 인식하기 위해서는, 우선 제1 인물이 촬영된 사진 또는 이미 지에서 얼굴 영역을 찾아 동일한 형태의 정면 얼굴을 추출하는 전처리 과정이 선행돼야 한다. 이러한 전처리 과 정은 입력된 사진 또는 이미지에서 얼굴 영역을 찾는 얼굴 검출 과정(face detection), 눈과 코 등 얼굴의 특징 을 나타내는 점을 찾는 얼굴 정렬 과정(face alignment), 얼굴 정렬 과정의 특징점을 이용해 얼굴 영역을 동일 한 형태와 크기로 변경하는 정규화 과정(normalization)을 포함할 수 있다. 상기 제2 얼굴 특징점 인식부는 제2 얼굴 데이터(제2 인물의 얼굴 동영상)로부터 미리 정의된 위치의 얼굴 특징점들(이하 제2 얼굴 특징점이라고 함)을 각각 인식하고, 도 5에 도시된 바와 같이 인식된 다수의 제2 얼굴 특징점(예를 들어 68개)을 추출할 수 있다. 상술한 바와 같이 얼굴 특징점들은 영상 내의 얼굴 영역에서 눈썹, 눈, 코, 입술, 턱 라인 등 그 위치가 미리 정의되어 있으며, 제2 인물의 얼굴 영역으로부터 인식되는 다수 개 (예를 들어 68개)의 점 분포도로서 표출될 수 있다. 이와 같이 제2 얼굴 데이터에서 제2 얼굴 특징점을 인식하기 위해서는 상술한 바와 같이 전처리 과정을 수행해 야 하지만, 이에 앞서 동영상을 일정 시간 단위의 영상 프레임으로 나눈 후 각 영상 프레임 별로 전처리 과정을 수행해야 한다. 상기 얼굴 특징점 매칭부는 도 6에 도시된 바와 같이 제1 얼굴 특징점 및 제2 얼굴 특징점 간을 서로 1:1 매칭할 수 있다. 얼굴 영역에서 인식되는 제1 얼굴 특징점 및 제2 얼굴 특징점 각각은 68개의 점 분포도로서 각 각의 점들은 고유번호가 미리 할당되어 있다. 이에 따라 68개의 제1 얼굴 특징점과 68개의 제2 얼굴 특징점을 각 고유번호 별로 1:1 매칭할 수 있다. 상기 제2 얼굴 특징점 움직임 정보 생성부는 제2 얼굴 특징점에 대한 움직임을 분석하여 제2 얼굴 특징점 움직임 정보를 생성할 수 있다. 좀 더 구체적으로는, 도 7에 도시된 바와 같이 2차원 공간 상에서 인식된 제2 얼굴 특징점 각각에 대하여 시간 변화량에 따른 벡터값(XY)을 추출하여 제2 얼굴 특징점 움직임 정보를 생성할 수 있다. 이러한 제2 얼굴 특징점 의 움직임 분석 결과는 제2 얼굴 특징점 각각에 대한 XY 값을 갖는 벡터로 도출될 수 있으며, 이를 위해 전후 또는 인접한 영상 프레임 내 제2 얼굴 특징점들을 추적하고, 그에 따라 각 제2 얼굴 특징점에 대한 위치 변화와 속도 변화 등에 대한 벡터값을 계산할 수 있다. 또한, 제2 얼굴 특징점 움직임 정보 생성부는, 도 8에 도시된 바와 같이 3차원 공간 상에서의 얼굴 특징점 움직임 정보에 대하여 기계 학습된 인공지능 알고리즘이 미리 구축되고, 미리 구축된 인공지능 알고리즘에 제2 얼굴 특징점 움직임 정보를 입력하여 Z축에 대한 추가 얼굴 특징점 움직임 정보를 출력하고, 출력된 추가 얼굴 특징점 움직임 정보(Z축 벡터값)를 제2 얼굴 특징점 움직임 정보(XY축 벡터값)에 결합 또는 추가하여 3차원 공 간 상에서의 얼굴 특징 움직임 정보를 생성할 수 있다. 본 실시예에서는 2차원 공간 상에서 나타나는 제2 얼굴 특징점 움직임 정보(XY축 벡터값)을 이용하는 것을 기본 설정으로 이루어지나, 사용자 옵션에 따라 Z축 방향(화면 상에서 전후방 방향)에 대한 얼굴 움직임 정보까지 예 측하여 추가할 수 있다. 일반적으로 촬영은 3차원 상의 객체(인물)을 촬영하지만 촬영된 결과물인 동영상은 2차 원 상에서 표출되므로, 하나의 영상물을 기반으로 3차원의 움직임까지 인식하기는 상당히 어렵다. 예를 들어, 입술 부위를 특정하는 특징점이 있다고 가정했을 때, 제2 인물이 어떠한 표정을 지었지만 XY축 방향 으로 나타나는 움직임이 거의 없고 X축 방향으로 나타나는 움직임만 있는 경우가 있다(예를 들어 입술 모양을 유지한 채 입술을 앞으로만 내미는 표정). 이러한 경우, 제2 얼굴 특징점 움직임 분석 결과로는 해당 입술의 움직임이 없는 것으로 인식되기 때문에, 실제 로 제2 인물이 Z축 방향으로 얼굴 특정 부위를 움직였음에도 불구하고 제1 인물의 표정에는 반영될 정보가 없게된다. 이러한 문제를 해결하기 위하여, XY축 방향에 대한 벡터값으로 Z축 방향에 대한 벡터값을 기계 학습한 인 공지능 알고리즘을 활용하여 미세한 XY축 벡터값만으로 Z축 벡터값을 추정하고, 추정된 값을 적용함으로써 보다 정교한 표정 변화에 대한 검출이 가능해진다. 예를 들어, XY축 벡터값이 원을 그리며 미세하게 회전하는 방향을 갖거나 미리 정의된 특정 패턴을 갖는 방향을 갖는지를 인공지능 알고리즘을 통해 검출하여 특정 위치에 대한 Z 축 방향에 대한 벡터값을 추정할 수 있다. 상기 얼굴 데이터 생성부는 제2 얼굴 특징점 움직임 정보를 제1 얼굴 특징점에 반영하여 제1 얼굴 데이터 에 포함된 얼굴에 시간의 흐름에 따른 표정 변화가 적용된 제3 얼굴 데이터를 생성할 수 있다. 도 9에 도시된 바와 같이, 제2 얼굴 특징점 움직임 정보는 XY축 벡터값 또는 XYZ축 벡터값을 포함할 수 있으며, 시간정보 또한 포함할 수 있다. 이에 따라 시간의 흐름에 따라 다수의 얼굴 특징점들이 특정 방향, 크기, 속도 로 얼마나 이동했는지에 대한 정보를 제1 얼굴 특징점에 적용함으로써, 정적으로 표현되어 있던 제1 인물의 얼 굴 표정에 시간의 흐름에 따라 제2 인물이 지었던 표정 변화가 그대로 반영된 제3 얼굴 데이터(동영상)가 생성 될 수 있다. 정리하면, 본 실시예의 얼굴 표정 생성 장치는 도 10에 도시된 바와 같이 표정 변화가 없는 제1 인물의 사 진이나 이미지를 포함하는 제1 얼굴 데이터와, 표정 변화가 있는 제2 인물의 동영상을 포함하는 제2 얼굴 데이 터를 각각 입력 받고, 제2 인물의 표정 변화가 제1 인물에 반영되어 시간의 흐름에 따라 표정 변화를 갖는 제2 인물에 대한 제3 얼굴 데이터(동영상)를 생성하여 출력할 수 있다. 상기 제2 얼굴 특징점 인식 설정부는 적어도 두 개의 제2 얼굴 데이터를 대상으로 서로 다른 얼굴 영역에 대한 얼굴 특징점을 각각 나누어 인식하도록 제2 얼굴 특징점 인식부의 기능 동작을 설정할 수 있다. 도 11에 도시된 바와 같이, 제2 얼굴 데이터 입력부를 통하여 표정 변화를 갖는 제2-1 인물을 촬영한 동영 상인 제2-1 얼굴 데이터와, 표정 변화를 갖는 제2-2 인물을 촬영한 동영상인 제2-1 얼굴 데이터를 입력 받을 수 있다. 여기서, 제2-1 인물과 제2-2 인물은 서로 다른 인물이고, 서로 다른 표정 변화를 갖는 것이 바람직하나, 서로 동일 인물이면서 서로 다른 표정 변화를 갖거나, 서로 동일 인물에 유사한 표정 변화를 갖는 것이어도 무 방하다. 또한, 재생 시간이 허용 범위 내에서 유사한 동영상을 적용하는 것이 바람직하며, 여기서 허용 범위나 1초 이내로 특정할 수 있으나, 지나치게 시간 차이가 나는 동영상인 경우 얼굴 표정 변화를 나타내는 시간에 대 한 차이가 현저히 나타나게 되어 두 얼굴에 대한 각각의 부분적인 표정을 적용하는데 무리가 있게 되므로, 가급 적 시간 차이가 1초 내외로 유사한 동영상을 적용하는 것이 적절하다. 이러한 제2 얼굴 특징점 인식 설정부는 별도의 UI(User Interface)를 통한 사용자 옵션 조작에 따라 실행 될 수 있으나, 제2 얼굴 데이터에 2개 이상의 동영상 파일이 입력되는 경우 해당 옵션이 자동 설정되어 해당 기 능이 수행될 수도 있다. 이와 같이 제2 얼굴 특징점 인식 설정부에 의한 사용자 옵션이 설정된 경우, 제2 얼굴 특징점 인식부(12 2)는, 적어도 두 개의 제2 얼굴 데이터 중 어느 한 얼굴 데이터(이하 제2-1 얼굴 데이터라고 함)에 대하여 특정 얼굴 영역(이하 제1 얼굴 영역(ROI_1)이라고 함, ROI: Region Of Interest)에 대한 얼굴 부분 특징점(이하 제 2-1 얼굴 특징점이라고 함)을 인식 및 추출하고, 나머지 다른 얼굴 데이터(이하 제2-2 얼굴 데이터라고 함)에 대하여 나머지 특정 얼굴 영역(이하 제2 얼굴 영역(ROI_2)라고 함)에 대한 얼굴 부분 특징점(이하 제2-2 얼굴 특징점이라고 함)을 인식 및 추출하는 방식으로 동작하고, 얼굴 부분 특징점들을 취합하여 제2 얼굴 특징점으로 서 얼굴 특징점 매칭부와 공유할 수 있다. 예를 들어, 도 11에 도시된 바와 같이 제2-1 얼굴 데이터에 대해서는 코부터 눈썹까지의 영역을 제1 얼굴 영역 (ROI_1)으로 설정하고, 제2-2 얼굴 데이터에 대해서는 코 아래부터 턱까지의 영역을 제2 얼굴 영역(ROI_2)으로 설정할 수 있다. 이때, 또한, 제1 얼굴 영역(ROI_1)과 제2 얼굴 영역(ROI_2)의 합은 하나의 얼굴 영역이 된다. 이와 같은 ROI는 얼굴 특징점의 분포도에 대하여 미리 정의되어 있어, 별도의 UI(User Interface)를 통해 어떠 한 얼굴 데이터에 대하여 어떠한 ROI를 적용할 것인지를 지정함으로써 서로 다른 제2 얼굴 데이터 별로 서로 다 른 얼굴 영역을 지정할 수 있다. 상기 제2 얼굴 특징점 인식 설정부를 통해 제1 얼굴 영역(ROI_1)과 제2 얼굴 영역(ROI_2)이 설정된 정보를 얼굴 특징점 매칭부와 공유함으로써, 도 12에 도시된 바와 같이 제1 얼굴 영역(ROI_1)과 제2 얼굴 영역 (ROI_2)에 해당하는 각각의 얼굴 특징점들이 제1 얼굴 특징점과 1:1 매칭될 수 있으며, 이후 도 13에 도시된 바 와 같이 제1 얼굴 영역(ROI_1)과 제2 얼굴 영역(ROI_2)의 움직임 정보(XZ축 벡터값 또는 XYZ축 벡터값)를 제1얼굴 특징점에 반영하여 제3 얼굴 데이터를 생성하는 과정을 수행할 수 있다. 한편, 제2 얼굴 특징점 인식 설정부는, 적어도 두 개의 제2 얼굴 데이터에 대하여 얼굴 특징점에 각각 할 당된 고유번호의 범위를 서로 다르게 설정하여 상기 적어도 두 개의 제2 얼굴 데이터에 대하여 서로 다른 얼굴 영역을 각각 지정할 수도 있다. 예를 들어, 얼굴 특징점은 1번부터 68번까지 각 얼굴 특정 부위 별로 고유번호를 가지고 있어, 1번부터 45번까 지를 제1 얼굴 영역(ROI_1)으로 지정하고, 46번부터 68번까지를 제2 얼굴 영역(ROI_2)으로 지정할 수 있으며, 고유번호 지정 범위 또한 구성된 얼굴 영역의 수만큼 구분되어 미리 정의되어 있다. 이상에서 설명한 것은 본 발명에 의한 얼굴 표정 생성 장치를 실시하기 위한 하나의 실시예에 불과한 것으로서, 본 발명은 상기 실시예에 한정되지 않고, 이하의 특허청구범위에서 청구하는 바와 같이 본 발명의 요지를 벗어 남이 없이 당해 발명이 속하는 분야에서 통상의 지식을 가진 자라면 누구든지 다양한 변경 실시가 가능한 범위 까지 본 발명의 기술적 정신이 있다고 할 것이다."}
{"patent_id": "10-2023-0117595", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 실시예에 따른 얼굴 표정 생성 장치의 개요도이다. 도 2는 본 발명의 실시예에 따른 얼굴 표정 생성 장치의 구성을 나타낸 블록도이다. 도 3은 본 발명의 실시예에 따른 얼굴 데이터 입력부의 구성을 나타낸 블록도이다. 도 4는 본 발명의 실시예에 따른 얼굴 데이터 처리부의 구성을 나타낸 블록도이다. 도 5는 본 발명의 실시예에 따른 제1 및 제2 얼굴 특징점 인식부를 통한 얼굴 특징점들을 인식한 결과에 대한 일례를 나타낸 도면이다. 도 6은 본 발명의 실시예에 따른 얼굴 특징점 매칭부의 기능 구성을 설명하기 위해 나타낸 도면이다. 도 7은 본 발명의 실시예에 따른 제2 얼굴 특징점 움직임 정보 생성부 의 기능 구성을 설명하기 위해 나타낸 도 면이다. 도 8은 본 발명의 실시예에 따른 제2 얼굴 특징점 움직임 정보 생성부의 3차원 상에서 제2 얼굴 특징점 움직임 정보(벡터값_XYZ)를 생성하는 구성을 설명하기 위해 나타낸 도면이다. 도 9는 본 발명의 실시예에 따른 얼굴 데이터 생성부의 기능 구성을 설명하기 위해 나타낸 도면이다. 도 10은 본 발명의 실시예에 따른 얼굴 데이터에 대한 출력 데이터의 구성 및 예시를 정리하여 나타낸 도면이다.도 11은 본 발명의 실시예에 따른 제2 얼굴 특징점 인식 설정부의 기능 구성을 설명하기 위해 나타낸 도면이다. 도 12 및 도 13은 본 발명의 실시예에 따른 제2 얼굴 특징점 인식 설정부의 ROI 설정에 따른 얼굴 특징점 매칭 부, 제2 얼굴 특징점 움직임 정보 생성부 및 얼굴 데이터 생성부의 기능 구성을 설명하기 위해 나타낸 도면이다."}
