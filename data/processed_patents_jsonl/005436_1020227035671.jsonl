{"patent_id": "10-2022-7035671", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2022-0154763", "출원번호": "10-2022-7035671", "발명의 명칭": "이미지 처리 방법 및 전자 장비", "출원인": "비보 모바일 커뮤니케이션 컴퍼니 리미티드", "발명자": "루이, 유안레"}}
{"patent_id": "10-2022-7035671", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "전자 장비에 적용하는 이미지 처리 방법에 있어서,사용자의 제1 입력을 수신하고,전술한 제1 입력에 응답하여, 대상 이미지에서의 제1 텍스트 구역을 식별하고,전술한 제1 텍스트 구역에 위치하는 제1 텍스트가 대상 이미지에서 표시된 텍스트 이미지를 훈련해 제1 텍스트의 제1 폰트 모델을 얻고,사용자의 제2 입력을 수신하고,전술한 제2 입력에 응답하여 제1 입력 텍스트를 얻은 다음에 제1 폰트 모델에 따라 제1 입력 텍스트를 훈련하여제1 텍스트의 폰트와 어울리는 제2 텍스트를 얻고,대상 이미지에서 제2 텍스트로 제1 텍스트를 치환하는, 이미지 처리 방법."}
{"patent_id": "10-2022-7035671", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 제1 텍스트 구역에 위치하는 제1 텍스트가 대상 이미지에서 표시된 텍스트 이미지를 훈련해 제1 텍스트의 제1 폰트 모델을 얻는 과정에서,제1 텍스트가 속한 언어 유형을 식별하고,그 언어 유형과 대응하는 코퍼스에서 제1 텍스트가 대상 이미지에서의 텍스트 이미지를 훈련해 제1 폰트 모델을얻는, 이미지 처리 방법."}
{"patent_id": "10-2022-7035671", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서, 대상 이미지에서 제2 텍스트로 제1 텍스트를 치환한 후,대상 이미지에서 제1 텍스트의 텍스트 이미지가 위치하는 레이어와 배경 레이어 사이의 매핑 관계에 따라 대상이미지에서의 제2 텍스트에 대해 투영 변환을 하는, 이미지 처리 방법."}
{"patent_id": "10-2022-7035671", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서, 대상 이미지에서 제2 텍스트로 제1 텍스트를 치환한 후,대상 이미지에서 제1 텍스트의 텍스트 이미지가 대응하는 배경 스타일에 따라 제2 텍스트가 위치하는 구역에서배경 이미지를 형성하는, 이미지 처리 방법."}
{"patent_id": "10-2022-7035671", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서, 제1 텍스트의 텍스트 이미지가 대응하는 배경 스타일에 따라 제2 텍스트가 위치하는 구역에서배경 이미지를 형성하는 과정에서,제1 텍스트의 텍스트 이미지가 대응하는 구역의 화소 정보에 따라, 대상 이미지에서 제2 텍스트가 위치하는 구역에서 화소를 충전하여 배경 이미지를 형성하고,생성적 대립쌍 네트워크를 이용하여 제1 텍스트의 텍스트 이미지가 대응하는 구역의 화소 정보에 따라, 제2 텍스트가 위치하는 구역에서 배경 이미지를 형성하는, 이미지 처리 방법."}
{"patent_id": "10-2022-7035671", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서, 제1 입력에 응답하여 대상 이미지에서의 제1 텍스트 구역을 식별한 후,예정하고 저장한 후보 폰트 스타일을 표시하고, 사용자가 후보 폰트 스타일 중 대상 폰트 스타일에 대한 제3 입공개특허 10-2022-0154763-2-력을 수신하고,제3 입력에 응답하여, 대상 텍스트가 대응하는 제2 폰트 모델에 따라, 제1 텍스틀 훈련하여 대상 텍스트의 폰트스타일과 어울리는 제3 텍스트를 얻고,대상 이미지에서 제3 텍스트로 제1 텍스트를 치환하는, 이미지 처리 방법."}
{"patent_id": "10-2022-7035671", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "전자 장비에 있어서,사용자의 제1 입력을 수신하는 제1 수신 모듈;제1 입력에 응답하여 대상 이미지에서의 제1 텍스트 구역을 식별하는 식별 모듈;제1 텍스트 구역에 위치하는 제1 텍스트가 대상 이미지에서 표시된 텍스트 이미지를 훈련해 제1 텍스트의 제1폰트 모델을 얻는, 제1 프로세스 모듈;사용자의 제2 입력을 수신하는 제2 수신 모듈;제2 입력에 응답하여 제1 입력 텍스트를 얻은 다음에 제1 폰트 모델에 따라 제1 입력 텍스트를 훈련하여 제1 텍스트의 폰트와 어울리는 제2 텍스트를 얻는 제2 프로세스 모듈; 및대상 이미지에 적용하여 제2 텍스트로 제1 텍스트를 치환하는 제1 치환 모듈을 포함하는, 전자 장비."}
{"patent_id": "10-2022-7035671", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서, 제1 프로세스 모듈은:제1 텍스트가 속한 언어 유형을 식별하는 식별 장치; 및언어 유형과 대응하는 코퍼스에서 제1 텍스트가 대상 이미지에서의 텍스트 이미지를 훈련해 제1 폰트 모델을 얻기 위한 제1 처리 장치를 포함하는, 전자 장비."}
{"patent_id": "10-2022-7035671", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제7항에 있어서,대상 이미지에서 제1 텍스트의 텍스트 이미지가 위치하는 레이어와 배경 레이어 사이의 매핑 관계에 따라 대상이미지에서의 제2 텍스트에 대해 투영 변환을 하는 제3 프로세스 모듈을 포함하는, 전자 장비."}
{"patent_id": "10-2022-7035671", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제7항에 있어서,대상 이미지에서 제1 텍스트의 텍스트 이미지가 대응하는 배경 스타일에 따라 제2 텍스트가 위치하는 구역에서배경 이미지를 형성하는 제4 프로세스 모듈을 포함하는, 전자 장비."}
{"patent_id": "10-2022-7035671", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제10항에 있어서, 제4 프로세스 모듈은:제1 텍스트의 텍스트 이미지가 대응하는 구역의 화소 정보에 따라, 대상 이미지에서 제2 텍스트가 위치하는 구역에서 화소를 충전하여 배경 이미지를 형성하는 제2 처리 장치; 또는생성적 대립쌍 네트워크를 이용하여 제1 텍스트의 텍스트 이미지가 대응하는 구역의 화소 정보에 대해 상호 게임 학습을 시켜 제2 텍스트가 대응하는 구역의 배경 이미지를 형성하는 제3 처리 장치 중 하나를 포함하는, 전자 장비."}
{"patent_id": "10-2022-7035671", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제7항에 있어서,예정하고 저장한 후보 폰트 스타일을 표시하는 디스플레이 모듈;공개특허 10-2022-0154763-3-사용자로부터 후보 폰트 스타일 중 대상 폰트 스타일에 대한 제3 입력을 수신하는 제3 수신 모듈;제3 입력에 응답하여, 대상 텍스트가 대응하는 제2 폰트 모델에 따라, 제1 텍스트를 훈련하여 대상 텍스트의 폰트 스타일과 어울리는 제3 텍스트를 얻는 제4 프로세스 모듈; 및대상 이미지에서 제3 텍스트로 제1 텍스트를 치환하는 제2 치환 모듈을 포함하는, 전자 장비."}
{"patent_id": "10-2022-7035671", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 이미지 처리 방법 및 전자 장비 한 가지를 제공하며 다음과 같은 내용을 포함한다. 사용자의 제1 입력 을 수신하여 응답한 다음에 대상 이미지에서의 제1 텍스트 구역을 식별하고, 제1 텍스트 구역이 대상 이미지에서 표시된 텍스트 이미지를 훈련해 제1 텍스트 구역의 제1 폰트 모델을 얻는다. 그리고 제2 입력을 수신하여 응답한 다음에 제1 입력 텍스트를 얻는다. 그리고 제1 폰트 모델에 따라 제1 입력 텍스트를 훈련하여 제1 텍스트 구역의 폰트와 어울리는 제2 텍스트를 얻고 대상 이미지에서 제2 텍스트로 제1 텍스트 구역의 텍스트를 치환한다."}
{"patent_id": "10-2022-7035671", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 통신 기술 영역에 관한 것으로, 특히 이미지 처리 및 전자 장비에 관한 것이다."}
{"patent_id": "10-2022-7035671", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "현재, 전자 장비를 통해 이미지에 나타난 텍스트를 교체하려면 우선 도포 구두를 이용하여 원래의 텍스트를 지 워야 한다. 그리고 이미지에다가 텍스트 박스를 추가하여 텍스트의 글자 색깔과 폰트를 설치한 다음에 입력한 텍스트를 원래 이미지에 붙어야 한다. 이러한 텍스트 편집 방식은 텍스트를 바꿀 수 있지만 사용자가 이미지의 원 텍스트 구역을 수동으로 도포하고 조정해야 한다. 이러한 과정에서 사용자가 도포 범위를 정밀하게 파악하기가 어렵고 작업이 워낙 복잡하기 때문 에 정확한 도포가 어려운 것이다. 뿐만 아니라, 치환 텍스트는 기본 설정의 폰트와 색깔만 선택할 수 있기 때문 에 치환 텍스트와 원 텍스트의 표시 효과가 일치하지 않는 경우가 많다. 이로 인해 텍스트 편집이 비교적 생경 하고 텍스트 편집 효과가 떨어질 수밖에 없다. 본 발명은 이미지 처리 방법 및 전자 장비 한 가지를 제공한다. 이럼으로써 기존 기술로 이미지 텍스트를 치환 하려면 과정이 복잡하고 편집 효과가 부족하다는 문제를 해결할 수 있다. 전술한 기술적 문제를 해결하기 위해, 본 발명은 다음과 같이 실현된다. 제1 양상에서, 본 발명의 실시예는 전자 장비에 적용되는 이미지 처리 방법을 제공하며 다음과 같은 내용을 포 함한다. 사용자의 제1 입력을 수신한다. 제1 입력에 응답하여 대상 이미지의 제1 텍스트 구역을 식별한다. 제1 텍스트 구역에 위치하는 제1 텍스트가 대상 이미지에서 표시된 텍스트 이미지를 훈련해 제1 텍스트의 제1 폰트 모델을 얻게 된다. 사용자의 제2 입력을 수신한다. 제2 입력에 응답하여 제1 입력 텍스트를 얻은 다음에 제1 폰트 모델에 따라 제1 입력 텍스트를 훈련하여 제1 텍 스트의 폰트와 어울리는 제2 텍스트를 얻게 된다. 대상 이미지에서 제2 텍스트로 제1 텍스트를 치환한다. 제2 양상에서, 본 발명의 실시예는 전자 장비 한 가지를 제공하며 다음과 같은 내용을 포함한다. 제1 수신 모듈, 사용자의 제1 입력을 수신한다. 식별 모듈, 제1 입력에 응답하여 대상 이미지에서의 제1 텍스트 구역을 식별한다. 제1 프로세스 모듈, 제1 텍스트 구역에 위치하는 제1 텍스트가 대상 이미지에서 표시된 텍스트 이미지를 훈련해 제1 텍스트의 제1 폰트 모델을 얻는다. 제2 수신 모듈, 사용자의 제2 입력을 수신한다. 제2 프로세스 모듈, 제2 입력에 응답하여 제1 입력 텍스트를 얻은 다음에 제1 폰트 모델에 따라 제1 입력 텍스 트를 훈련하여 제1 텍스트의 폰트와 어울리는 제2 텍스트를 얻는다.제1 치환 모듈, 대상 이미지에 적용하여 제2 텍스트로 제1 텍스트를 치환한다. 제3 양상에서, 본 발명의 실시예는 전자 장비 한 가지를 제공하며 프로세서, 메모리, 메모리에 저장하고 프로세 서에 의해 실행할 수 있는 컴퓨터 프로그램을 포함한다. 이 컴퓨터 프로그램은 프로세서에서 실행될 때 전술한 이미지 처리 방법의 절차에 따라 실행된다. 제4 양상에서, 본 발명의 실시예는 컴퓨터 판독 가능 기억 매체를 제공한다. 컴퓨터 판독 가능 기억 매체에는 컴퓨터 프로그램이 저장돼 있으며 이 컴퓨터 프로그램은 프로세서에서 실행될 때 전술한 이미지 처리 방법의 절 차에 따라 실행된다. 본 발명의 실시예는 사용자의 제1 입력을 수신하여 응답한 다음에 대상 이미지에서의 제1 텍스트 구역을 식별하 고, 제1 텍스트 구역에 위치하는 제1 텍스트가 대상 이미지에서 표시된 텍스트 이미지를 훈련해 제1 폰트 모델 을 얻는다. 그리고 제2 입력을 수신하여 응답한 다음에 제1 폰트 모델에 따라 제1 입력 텍스트를 훈련하여 제1 텍스트의 폰트와 어울리는 제2 텍스트를 얻고 대상 이미지에서 제2 텍스트로 제1 텍스트를 치환한다. 이럼으로 써 사용자가 대상 이미지의 텍스트를 간편하게 치환할 수 있으며, 입력한 텍스트의 폰트가 대상 이미지의 원 텍 스트 폰트와 같이 만들어 입력한 텍스트는 대상 이미지와 잘 어울리게 할 수 있다. 이러한 방식을 통해 이미지 의 텍스트 치환이 복잡하고 자연스럽지 못한다는 문제를 해결한다."}
{"patent_id": "10-2022-7035671", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "[관련 출원에 대한 상호 참조] 본 출원은 2020년 3월 27일 자로 중국에서 출원한 중국 특허출원 번호가 No. 202010229382.0인 특허의 우선권을 주장하며, 그 전체가 참조로서 본원에 포함된다. 본 발명이 해결하고자 하는 기술 문제, 기술 방안 및 장점을 더욱 명확하게 보여주기 위해, 다음은 도면 및 구 체적인 실시예를 참조하려 상세히 설명할 것이다. 도 1은 본 발명의 실시예가 제공하는 이미지 처리 방법의 흐름도를 보여준다. 본 발명의 실시예는 모니터 조정 기능을 갖는 전자 장비에 적용되는 이미지 처리 방법을 제공하며, 본 발명의 실시예의 이미지 처리 방법은 다음 과 같은 단계를 포함할 수 있다. 단계 101에서 전자 장비는 사용자의 제1 입력을 수신한다. 본 발명의 실시예는 전자 장비가 대상 이미지를 표시하는 경우에 사용자가 제1 입력을 수행함으로써 전자 장비 가 제1 입력을 수신하게 할 수 있다. 나아가 전자 장비가 대상 이미지의 제1 텍스트에 대한 식별 절차를 수행하 도록 트리거할 수 있다. 여기서 말하는 제1 입력은 오디오 입력, 제스처 입력, 전자 장비에 작용하는 터치 입력 및 모션 입력 중 적어도 하나를 포함할 수 있다. 제스처 입력은 손의 움직임 입력, 머리의 움직임 입력 및 얼굴의 움직임 입력 중 적어 도 하나를 포함할 수 있으나 이에 한정되는 것은 아니다. 전자 장비에 작용하는 터치 입력은 스크린 또는 하우 징에 작용하는 터치 입력을 포함할 수 있으나 이에 한정되지 않으며, 전자 장비에 작용하는 모션 입력은 전자 장비에 작용하는 흔들림 동작 입력, 반전 동작 입력 및 플렉시블 스크린에 작용하는 굽힘 입력/구부러짐 입력을 포함할 수 있으나 이에 한정되지 않는다. 단계 102에서 전자 장비는 제1 입력에 응답하여 대상 이미지에서의 제1 텍스트 구역을 식별한다. 본 발명의 실시예에서는 전자 장비가 단계 101에서 수신된 제1 입력에 응답하여 대상 이미지를 측정하고, 대상 이미지에서 나타난 제1 텍스트 구역을 식별한다. 선택적으로, 전자 장비는 광학식 문자 인식(Optical Character Recognition, OCR) 기술과 인공지능(Artificial Intelligence, AI) 기술을 통해 대상 이미지를 측정하여 대상 이미지의 제1 텍스트 구역을 식별하여 제1 텍스트 및 제1 텍스트가 대상 이미지에서의 좌표 위치를 얻을 수 있 다. 바람직하게는 사용자가 식별 결과를 직관적으로 파악할 수 있도록, 전자 장비는 대상 이미지에서의 제1 텍스트 구역의 제1 텍스트 내용 및 제1 텍스트가 대상 이미지에서의 좌표 위치를 측정할 수 있다. 그 다음에 대상 이미 지의 제1 텍스트 구역을 예장 마킹으로 표시할 수 있다. 예컨대, 대상 이미지의 제1 텍스트 구역을 이미지 마스 크에 의해 표시할 수 있다. 예를 들어, 제1 텍스트 구역을 이미지 마스크에 의해 예정 색깔(빨간색 등)으로 표 시하여 사용자가 확인할 수 있도록 할 수 있다. 전자 장비는 사용자가 예정 마킹에 대한 이동 입력을 수신한 다 음에, 전자 장비는 이동 입력에 응답하여 이동 입력의 종료 위치에 대해 텍스트 식별하여 제1 텍스트를 식별한 다. 이럼으로써, 사용자가 잘못 식별된 위치를 제때 수정할 수 있도록 하는데, 이동 입력은 드래그 입력 및 프 레스 드래그 입력 중 적어도 하나를 포함할 수 있다. 단계 103에서는, 전자 장비는 제1 텍스트 구역에 위치하는 제1 텍스트가 대상 이미지에서 표시된 텍스트 이미지 를 훈련해 제1 텍스트의 제1 폰트 모델을 얻는다. 본 발명의 실시예의 경우, 전자 장비는 단계 102를 통해 식별한 제1 텍스트의 텍스트 이미지를 훈련 모델에 입 력하여 AI훈련을 한 다음에, 제1 텍스트의 폰트와 어울리는 제1 폰트 모델을 얻는다. 이렇게 함으로써 이후의 단계에서 제1 폰트 모델에 의해 대상 이미지에 대한 텍스트 편집 과정에서 같은 폰트를 유지할 수 있어 편집한 텍스트는 대상 이미지와 잘 어울리게 할 수 있다. 단계 104에서는, 전자 장비는 사용자의 제2 입력을 수신한다. 본 발명의 실시예의 경우, 사용자가 제2 입력의 진행을 통해 제1 텍스트의 편집 및 수정을 촉발할 수 있다. 여 기서 말하는 제2 입력은 오디오 입력, 제스처 입력, 전자 장비에 작용하는 터치 입력 및 모션 입력 중 적어도 하나를 포함할 수 있다. 선택적으로, 사용자가 직관적이고 간편하게 조작하게 하도록, 제2 입력은 대상 이미지의 제1 텍스트에 대한 예 정 터치 입력일 수 있다. 예컨대, 예정 터치 입력은 클릭 입력과 프레스 입력 중 적어도 하나를 포함할 수 있다. 단계 105에서는, 전자 장비가 제2 입력에 응답하여 제1 입력 텍스트를 얻는다. 그 다음에 제1 폰트 모델에 의해 제1 입력 텍스트를 훈련하여 제1 텍스트의 폰트와 어울리는 제2 텍스트를 얻게 된다. 본 발명의 실시예의 경우, 전자 장비가 단계 104에서 수신한 제2 입력에 응답하여 사용자가 입력한 제1 입력 텍 스트를 얻는다. 그 다음에 제1 입력 텍스트를 제1 텍스트의 제1 폰트 모델에 입력하여 훈련한다. 이럼으로써 제 1 텍스트의 폰트와 어울리는 텍스트, 즉, 제2 텍스트를 얻게 된다. 이렇게 하면 사용자가 입력한 텍스트의 폰트 스타일은 대상 이미지의 원 텍스트(즉, 제1 텍스트)와 같이 만들어 편집 후의 텍스트(즉, 제2 텍스트)는 대상 이미지와 자연스럽게 융합하게 할 수 있다. 단계 106에서는, 전자 장비는 대상 이미지에서 제2 텍스트로 제1 텍스트를 치환한다. 본 발명의 실시예의 경우, 전자 장비가 단계 105에서 훈련을 통해 얻은 제2 텍스트로 대상 이미지에서의 제1 텍 스트를 치환한다. 이는 대상 이미지에서의 텍스트 치환을 간편하게 실현하고 사용자가 입력한 텍스트의 폰트 스 타일은 대상 이미지의 원 텍스트와 같이 만들어 사용자가 입력한 텍스트를 대상 이미지와 자연스럽게 융합하게 할 수 있다. 더 나아가, 전자 장비가 제2 텍스트로 제1 텍스트를 치환한 후, 제2 텍스트를 대상 이미지와 융합하여 저장함으 로써 사용자가 필요한 이미지를 얻을 수 있다. 본 발명의 실시예는 전자 장비를 통해 사용자의 제1 입력을 수신하여 응답한 다음에 대상 이미지에서의 제1 텍 스트 구역을 식별하고, 제1 텍스트 구역에 위치하는 제1 텍스트가 대상 이미지에서 표시된 텍스트 이미지를 훈 련해 제1 폰트 모델을 얻는다. 그리고 제2 입력을 수신하여 응답한 다음에 제1 폰트 모델에 따라 제1 입력 텍스 트를 훈련하여 제1 텍스트의 폰트와 어울리는 제2 텍스트를 얻고 대상 이미지에서 제2 텍스트로 제1 텍스트를 치환한다. 이럼으로써 사용자가 대상 이미지의 텍스트를 간편하게 치환할 수 있으며, 입력한 텍스트의 폰트가 대상 이미지의 원 텍스트 폰트와 같이 만들어 입력한 텍스트는 대상 이미지와 잘 어울리게 할 수 있다. 이러한방식을 통해 이미지의 텍스트 치환이 복잡하고 자연스럽지 못한다는 문제를 해결한다. 선택적으로, 본 발명의 일부 실시예의 경우, 단계 103에서 전자 장비가 제1 텍스트 구역에 위치하는 제1 텍스트 가 대상 이미지에서 표시된 텍스트 이미지를 훈련해 제1 텍스트의 제1 폰트 모델을 얻다. 이 과정에서 다음과 같은 절차를 포함할 수 있다. 전자 장비가 제1 텍스트가 속한 언어 유형을 식별한다. 전자 장비가 그 언어 유형 과 대응하는 코퍼스에서 제1 텍스트가 대상 이미지에서의 텍스트 이미지를 훈련해 제1 폰트 모델을 얻는다. 이 럼으로써 전자 장비가 제1 텍스트의 텍스트 이미지를 제1 텍스트가 속한 언어 유형이 대응하는 코퍼스에서 훈련 함으로써 대응하는 코퍼스의 데이터에 의해, 제1 텍스트와 대응하는 폰트 스타일을 편리하고 정확하게 얻을 수 있다. 선택적으로, 본 발명의 일부 실시예의 경우, 단계 106에서 전자 장비가 대상 이미지에서 제2 텍스트로 제1 텍스 트를 치환한 후, 다음과 같은 절차를 포함할 수 있다. 전자 장비는 대상 이미지에서 제1 텍스트의 텍스트 이미 지가 위치하는 레이어와 배경 레이어 사이의 매핑 관계에 따라, 대상 이미지에서의 제2 텍스트에 대해 투영 변 환을 한다. 이럼으로써, 치환된 제2 텍스트가 대상 이미지에 처한 위치는 원래 제1 텍스트와 일치하게 하여, 편 집 후의 텍스트는 편집 전과 같은 표시 효과를 확보한다. 선택적으로, 본 발명의 일부 실시예의 경우, 전자 장비가 대상 이미지에서 제2 텍스트로 제1 텍스트를 치환한 후, 나아가 넥스트의 배경 구역을 회복함으로써 원 배경의 효과를 회복할 수도 있다. 예컨대, 단계 106에서 전 자 장비가 대상 이미지에서 제2 텍스트로 제1 텍스트를 치환한 후, 다음과 같은 절차를 포함할 수 있다. 전자 장비는 대상 이미지에서 제1 텍스트의 텍스트 이미지가 대응하는 배경 스타일에 따라 제2 텍스트가 위치하는 구 역에서 배경 이미지를 형성한다. 이럼으로써 새로운 텍스트(즉, 제2 텍스트)가 대상 이미지의 배경과 이질감 없 이 잘 융합하게 할 수 있다. 바람직하게는, 본 발명의 일부 실시예의 경우, 전자 장비는 대상 이미지에서 제1 텍스트의 텍스트 이미지가 대 응하는 배경 스타일에 따라 제2 텍스트가 위치하는 구역에서 배경 이미지를 형성하면, 다음의 방법 중 하나를 포함할 수 있다. 방법 1: 전자 장비는 대상 이미지에서 제1 텍스트의 텍스트 이미지가 대응하는 구역의 화소 정보에 따라, 대상 이미지에서 제2 텍스트가 위치하는 구역에서 화소를 충전하여 배경 이미지를 형성한다. 방법1에서는, 제1 텍스 트의 텍스트 이미지가 대응하는 구역의 화소 정보를 배경 충전의 기반으로 하여, 이를 통해 제2 텍스트가 대응 하는 구역의 배경 이미지를 형성한다. 이럼으로써 제2 텍스트가 대응하는 구역의 배경이 스타일은 제1 텍스트의 원 배경 스타일과 일치하게 할 수 있다. 방법 2: 전자 장비는 생성적 대립쌍 네트워크를 이용하여 제1 텍스트의 텍스트 이미지가 대응하는 구역의 화소 정보에 따라, 제2 텍스트가 위치하는 구역에서 배경 이미지를 형성한다. 방법2는 생성적 대립쌍 네트워크（ Generative Adversarial Networks, GAN）모델의 생성모델（Generative Model）과 판별 모델（Discriminative Model）을 이용하여 제1 텍스트의 텍스트 이미지가 대응하는 구역의 화소 정보에 대해 상호 게임 학습을 시켜 제2 텍스트가 대응하는 구역의 배경 이미지를 형성한다. 이럼으로써 제2 텍스트가 대응하는 구역의 배경 스타일 은 제1 텍스트 구역의 원 배경 스타일과 더욱 이질감 없이 융합하게 할 수 있다. 물론, 이해할 수 있는 것은 본 발명의 실시예의 경우, 단계 106에서, 전자 장비가 대상 이미지에서 제2 텍스트 로 제1 텍스트를 치환한 후, 전자 장비는 제2 텍스트가 위치한 구역 주변의 화소 정보를 이용해 배경 이미지를 형성할 수도 있는 것이다. 선택적으로, 본 발명의 일부 실시예의 경우, 텍스트를 수정하거나 편집하는 과정에서 더 나아가 번역 기능도 갖 출 수 있다. 전자 장비는 사용자가 입력한 텍스트가 예정한 언어로 번역한 후, 제1 폰트 모델에 입력하여 훈련 을 할 수 있다. 즉, 본 발명 실시예의 경우, 제1 입력 텍스트는 제2 입력의 입력 텍스트일 수도 있고, 또한 제2 입력의 입력 텍스트가 예정 언어로 번역된 텍스트일 수도 있다. 이렇게 함으로써 사용자의 다원적인 편집 수요 에 만족할 수 있다. 선택적으로, 본 발명의 일부 실시예의 경우, 대상 이미지에 대한 다원적인 편집을 이루기 위해, 단계 102에서 전자 장비는 제1 입력에 응답하여 대상 이미지에서의 제1 텍스트 구역을 식별한 후, 다음과 같은 절차를 포함할 수 있다. 전자 장비는 예정하고 저장한 후보 폰트를 표시한다. 그리고 전자 장비는 사용자가 후보 폰트 중 대상 폰트에 대한 제3 입력을 수신한다. 전자 장비는 제3 입력에 응답하여, 대상 텍스트가 대응하는 제2 폰트 모델에 따라, 제1 텍스트를 훈련하여 대상 텍스트의 폰트와 어울리는 제3 텍스트를 얻게 된다. 전자 장비는 대상 이미 지에서 제3 텍스트로 제1 텍스트를 치환한다. 이렇게 함으로써 사용자가 더욱 편리하게 선호하는 폰트 스타일로대상 이미지의 텍스트를 수정하거나 편집할 수 있게 한다. 여기서 말하는 후보 폰트는 전자 장비가 미리 저장하 거나 수장한 폰트일 수도 있고 아니면 전자 장비에서 예정 기간 안에 쓰던 폰트일 수도 있다. 뿐만 아니라, 전 자 장비는 후보 폰트가 대응하는 폰트 모델을 저장한다. 예컨대, 예정 기간은 현재 시스템 시간의 1주 전까지로 설정하고, 후보 폰트는 1주 안에 쓰던(즉, 최근에 쓰던) 폰트 스타일일 수 있다. 그리고, 전자 장비의 캐시 자 원을 지나치게 점용하지 않도록, 후보 폰트가 전자 장비에서 예정 기간 안에 쓰던 폰트인 경우, 후보 폰트의 수 양은 예정 수치로 설정할 수 있다. 이 예정 수치는 전자 장비의 기본 설정일 수도 있고 사용자가 설정한 것일 수도 있다. 예컨대, 이 예정 수치는 3개로 설정할 수 있다. 선택적으로, 본 발명의 일부 실시예의 경우, 사용자가 제1 텍스트에 대한 다원적인 편집을 이루기 위해, 단계 103에서는, 전자 장비는 제1 텍스트가 대상 이미지에서 표시된 텍스트 이미지를 훈련해 제1 텍스트의 제1 폰트 모델을 얻은 후, 다음과 같은 부분을 포함할 수 있다. 대상 이미지에서 텍스트 박스로 제1 텍스트를 표시한다. 이럼으로써 사용자가 텍스트 박스로 표시된 제1 텍스트에 의해 텍스트를 편리하게 편집할 수 있다. 더 나아가, 전자 장비는 대상 이미지에서 제1 텍스트 구역에 대해 사각형 표기를 하여, 이 표기를 투영 변환을 한 다음에 텍스트 박스로 제1 텍스트를 표시한다. 예컨대, 단계 104에서, 전자 장비는 사용자의 제2 입력을 수신한다. 이는 다음과 같은 내용을 포함할 수 있다. 텍스트 박스에 대한 제2 입력을 수신한다. 이 제2 입력은 예정 터치 입력일 수 있다. 예컨대, 텍스트 박스에 대 한 클릭 입력, 텍스트 박스에 대한 프레스 입력 중 적어도 하나를 포함할 수 있다. 더 나아가, 사용자가 더욱 편리하게 편집하게 하도록, 단계 105에서 제1 입력 텍스트를 얻은 다음에 제1 폰트 모델에 의해 제1 입력 텍스 트를 훈련하여 제1 텍스트의 폰트와 어울리는 제2 텍스트를 얻기 전에, 전자 장비가 제2 입력에 응답하여 텍스 트 입력 인터페이스를 표시한다. 전자 장비가 제1 텍스트의 텍스트 내용을 추출하여 텍스트 입력 인터페이스에 서 제1 텍스트의 텍스트 내용을 표시한다. 이렇게 함으로써 사용자가 텍스트 입력 인터페이스를 통해 제1 텍스 트의 내용에 대해 2차 편집과 수정을 편리하게 진행할 수 있다. 여기서 말하는 텍스트 입력 인터페이스는 입력 키보드일 수 있다. 예컨대, 전자 장비가 대상 이미지에서 텍스트 박스로 제1 텍스트를 표시한 후, 전자 장비는 사용자가 텍스트 박 스에 대한 예정 입력을 수신하여 이에 응답하고, 제1 텍스트가 대상 이미지에서의 표시 크기와 표시 위치 중 적 어도 하나를 조정한다. 예를 들어, 사용자가 텍스트 박스에 대한 예정 입력을 통해 제1 텍스트에 대한 확대, 회 전, 및 움직임을 실현할 수 있다. 예컨대, 사용자의 맨 머신 체험을 향상시키고, 사용자의 간단한 조작을 실현하기 위하여, 본 발명의 실시예에서 는 예정 컨트롤을 설정할 수 있다. 제1 입력, 제2 입력 및 제3 입력 등과 같은 대응 조정 입력에 응답하기 전에, 전자 장비는 사용자가 예정 컨트롤에 대한 터치 입력을 수신함으로써, 전술한 수정 입력이 제1 텍스트에 대한 편집 과정에서의 텍스트 교체 기능, 번역 기능, 표시 크기 및 표시 위치의 조정 기능을 촉발할 수 있다. 이는 사용자의 조작 실수를 피할 수 있다. 본 발명의 실시예에서 제기한 이미지 처리 방법은 사용자의 제1 입력을 수신하여 응답한 다음에, 대상 이미지에 서의 제1 텍스트 구역을 식별하고, 제1 텍스트 구역에 위치하는 제1 텍스트가 대상 이미지에서 표시된 텍스트 이미지를 훈련해 제1 폰트 모델을 얻는다. 그리고 제2 입력을 수신하여 응답한 다음에 제1 폰트 모델에 따라 제 1 입력 텍스트를 훈련하여 제1 텍스트의 폰트와 어울리는 제2 텍스트를 얻고 대상 이미지에서 제2 텍스트로 제1 텍스트를 치환한다. 이럼으로써 사용자가 대상 이미지의 텍스트를 간편하게 치환할 수 있으며, 입력한 텍스트의 폰트가 대상 이미지의 원 텍스트 폰트와 같이 만들어 입력한 텍스트는 대상 이미지와 잘 어울리게 할 수 있다. 이러한 방식을 통해 이미지의 텍스트 치환이 복잡하고 자연스럽지 못한다는 문제를 해결한다. 전술한 방법에 의하여, 본 발명의 실시예는 전술한 방법을 실현하기 위한 전자 장비를 제공한다. 도 2는 본 발명의 실시예에서 제공한 전자 장비의 구조 설명도이다. 본 발명의 실시예는 전자 장비를 제공 하며 제1 수신 모듈, 식별 모듈, 제1 프로세스 모듈, 제2 수신 모듈, 제2 프로세스 모듈 , 제1 치환 모듈을 포함할 수 있다. 제1 수신 모듈, 사용자의 제1 입력을 수신한다. 식별 모듈, 제1 입력에 응답하여 대상 이미지에서의 제1 텍스트 구역을 식별한다. 제1 프로세스 모듈, 제1 텍스트 구역에 위치하는 제1 텍스트가 대상 이미지에서 표시된 텍스트 이미지를 훈련해 제1 텍스트의 제1 폰트 모델을 얻는다.제2 수신 모듈, 사용자의 제2 입력을 수신한다. 제2 프로세스 모듈, 제2 입력에 응답하여 제1 입력 텍스트를 얻은 다음에 제1폰트 모델에 따라 제1 입력 텍스트를 훈련하여 제1 텍스트의 폰트와 어울리는 제2 텍스트를 얻는다. 제1 치환 모듈, 대상 이미지에 적용하여 제2 텍스트로 제1 텍스트를 치환한다. 선택적으로, 본 발명의 일부 실시예의 경우, 제1 프로세스 모듈은 식별 장치와 제1 처리 장치를 포함할 수 있다. 식별 장치는 제1 텍스트가 속한 언어 유형을 식별한다. 제1 처리 장치는 언어 유형과 대응하는 코퍼스에서 제1 텍스트가 대상 이미지에서의 텍스트 이미지를 훈련해 제 1 폰트 모델을 얻는다. 선택적으로, 본 발명의 일부 실시예의 경우, 전자 장비는 제3 프로세스 모듈을 포함할 수 있다. 제3 프로세스 모듈은 대상 이미지에서 제1 텍스트의 텍스트 이미지가 위치하는 레이어와 배경 레이어 사이의 매 핑 관계에 따라 대상 이미지에서의 제2 텍스트에 대해 투영 변환을 한다. 선택적으로, 본 발명의 일부 실시예의 경우, 전자 장비는 제4 프로세스 모듈을 포함할 수 있다. 제4 프로세스 모듈은 대상 이미지에서 제1 텍스트의 텍스트 이미지가 대응하는 배경 스타일에 따라 제2 텍스트 가 위치하는 구역에서 배경 이미지를 형성한다. 바람직하게는 본 발명의 일부 실시예의 경우, 제4 프로세스 모듈은 제2 처리 장치와 제3 처리 장치를 포함할 수 있다. 제2 처리 장치는 제1 텍스트의 텍스트 이미지가 대응하는 구역의 화소 정보에 따라, 대상 이미지에서 제2 텍스 트가 위치하는 구역에서 화소를 충전하여 배경 이미지를 형성한다. 제3 처리 장치는 생성적 대립쌍 네트워크를 이용하여 제1 텍스트의 텍스트 이미지가 대응하는 구역의 화소 정보 에 대해 상호 게임 학습을 시켜 제2 텍스트가 대응하는 구역의 배경 이미지를 형성한다. 선택적으로, 본 발명의 일부 실시예의 경우, 제1 입력 텍스트는 제2 입력의 입력 텍스트, 아니면 제2 입력의 입 력 텍스트가 예정 언어로 번역된 텍스트이다. 선택적으로, 본 발명의 일부 실시예의 경우, 전자 장비는 디스플레이 모듈, 제3 수신 모듈, 제4 프로세스 모듈, 제2 치환 모듈을 포함할 수 있다. 디스플레이 모듈은 예정하고 저장한 후보 폰트를 표시한다. 제3 수신 모듈은 사용자가 후보 폰트 중 대상 폰트 스타일에 대한 제3 입력을 수신한다. 제4 프로세스 모듈은 제3 입력에 응답하여, 대상 텍스트가 대응하는 제2 폰트 모델에 따라, 제1 텍스트를 훈련 하여 대상 텍스트의 폰트 스타일과 어울리는 제3 텍스트를 얻게 된다. 제2 치환 모듈은 대상 이미지에서 제3 텍스트로 제1 텍스트를 치환한다. 본 발명의 실시예에서 제공한 전자 장비는 도 1의 방법 실시예에서 전자 장비가 실현의 전 과정을 실현할 수 있으며 여기서 반복하지 않도록 더 이상 군말을 하지 않는다. 본 발명의 실시예에서 제공한 전자 장비는 제1 수신 모듈, 식별 모듈, 제1 프로세스 모듈의 상호 협조를 통해 사용자의 제1 입력에 수신하여 응답한 다음에 대상 이미지에서의 제1 텍스트 구역을 식별한다. 그리고 제1 텍스 트 구역에 위치하는 제1 텍스트가 대상 이미지에서 표시된 텍스트 이미지를 훈련해 제1 폰트 모델을 얻는다. 그 다음에 제2 수신 모듈, 제2 프로세스 모듈, 제1 치환 모듈의 상호 협조를 통해 제2 입력을 수신하여 응답한 다 음에 제1 폰트 모델에 따라 제1 입력 텍스트를 훈련하여 제1 텍스트의 폰트와 어울리는 제2 텍스트를 얻고 대상 이미지에서 제2 텍스트로 제1 텍스트를 치환한다. 이럼으로써 사용자가 대상 이미지의 텍스트를 간편하게 치환 할 수 있으며, 입력한 텍스트의 폰트가 대상 이미지의 원 텍스트 폰트와 같이 만들어 입력한 텍스트는 대상 이 미지와 잘 어울리게 할 수 있다. 이러한 방식을 통해 이미지의 텍스트 치환이 복잡하고 자연스럽지 못한다는 문 제를 해결한다. 도 3은 본 발명의 실시예에서 제공하는 전자 장비의 하드웨어 구조 설명도이다. 전자 장비는 무선 주파수 장치, 네트워크 모듈, 오디오 출력 장치, 입력 장치, 센서 , 표시 장치, 사용자 입력 장치, 인터페이스 장치, 메모리, 프로세서, 전원 등 부분을 포함하되 이에 한정하지 않는다. 본 발명의 기술 분야의 통상 지식을 가진 자라면, 도 3에서 제시된 전자 장비의 구조는 전자 장비에 대한 제한을 구성하지 않으며, 전자 장비가 제시된 것보다 더 많거나 더 적은 구성 요소를 포함하거나, 일부 구성 요소를 조합하거나, 서로 다른 구성 요소를 배열할 수 있다. 본 발 명의 실시예에서, 전자 장비는 휴대폰, 태블릿, 노트북, 피디에이, 차량용 단말기, 웨어러블 기기, 만보계 등을 포함하되 이에 한정되지 않는다. 그 중에 사용자 입력 장치는 사용자의 제1 입력을 수신한다. 프로세서는 제1 입력에 응답하여 대상 이미지에서의 제1 텍스트 구역을 식별한다. 그리고 제1 텍스트 구역에 위치하는 제1 텍스트가 대상 이미지에서 표시된 텍스트 이미지를 훈련해 제1 텍스트의 제1 폰트 모델을 얻는다. 사용자 입력 장치는 사용자의 제2 입력을 수신한다. 프로세서는 제2 입력에 응답하여 제1 입력 텍스트를 얻은 다음에, 제1 폰트 모델에 따라 제1 입력 텍스트를 훈련하여 제1 텍스트의 폰트와 어울리는 제2 텍스트를 얻는다. 표시 장치는 대상 이미 지에서 제2 텍스트로 제1 텍스트를 치환한다. 이럼으로써 사용자가 대상 이미지의 텍스트를 간편하게 치환할 수 있으며, 입력한 텍스트의 폰트가 대상 이미지의 원 텍스트 폰트와 같이 만들어 입력한 텍스트는 대상 이미지와 잘 어울리게 할 수 있다. 이러한 방식을 통해 이미지의 텍스트 치환이 복잡하고 자연스럽지 못한다는 문제를 해 결한다. 본 발명의 실시예에서는 무선 주파수 장치는 메시지 송수신 또는 통화 과정에서 신호를 수신하거나 송신할 수 있다. 구체적으로는 무선 주파수 장치는 기지국으로부터의 하향 데이터를 수신한 후 프로세서로 전송하여 처리한다. 또한 상향 데이터를 기지국으로 전송한다. 일반적으로 무선 주파수 장치는 안테나, 적 어도 하나의 증폭기, 송수신기, 연결기, 저잡음 증폭기, 다이플렉서 등을 포함하지만 이에 한정되지 않는다. 또 한 무선 주파수 장치는 무선 통신 시스템을 통해 네트워크 및 기타 장치와 통신할 수 있다. 전자 장비는 네트워크 모듈을 통해 사용자에게 이메일의 송수신, 웹 브라우징, 스트림 미디어 이용 등 무 선 광대역 인터넷 접속을 제공한다. 오디오 출력 장치는 무선 주파수 장치 또는 네트워크 모듈이 수신하거나 메모리에 저장된 오디오 데이터를 오디오 신호로 변환하여 오디오로 출력할 수 있다. 또한, 오디오 출력 장치는 전자 장비 가 수행하는 특정 기능과 관련된 오디오 출력(예를 들어 호출 신호 수신음, 메시지 수신음 등)을 집행할 수 있다. 오디오 출력 장치는 스피커, 버저 및 수화기 등을 포함한다. 입력 장치는 오디오 또는 영상 신호를 수신한다. 입력 장치는 그래픽 처리 장치（Graphics Processing Unit， GPU）와 마이크로폰을 포함할 수 있다. 그래픽 처리 장치는 동영상 캡처 장치 촬영 모드 또는 이미지 캡처 모드에서 카메라와 같은 이미지 촬영 장치로 얻은 정지 이미지 또는 동영상의 이미지 데이터를 처리한다. 처리된 영상 프레임은 표시 장치에 표시될 수 있다. 그래픽 처리 장치가 처리된 화상 프레임은 메모리(또는 다른 메모리 매체)에 저장되거나 무선 주파수 장치, 또는 네트워 크 모듈로 전송한다. 마이크로폰은 소리를 수신할 수 있고, 이러한 소리를 오디오 데이터로 처리할 수 있다. 처리된 오디오 데이터는 전화 통화 모드에서 무선 주파수 장치를 통해 이동 통신 기지국으로 전 송 가능한 포맷으로 변환되어 출력될 수 있다. 전자 장비는 적어도 센서 한 가지를 포함한다. 예컨대, 광 센서, 이동 센서 및 다른 유형의 센서를 포함할 수 있다. 구체적으로 광센서는 주변 광센서와 근접각 센서를 포함한다. 그 중에 주변 광센서는 주변 환 경의 밝기에 따라 표시 패널의 밝기를 조절할 수 있다. 근접각 센서는 전자 장비가 귀가에 접근할 때, 표시 패널을 및/또는 배면광 모드로 전환한다. 이동 센서로서 가속도 센서는 각 방향(일반적으로 3축) 가속도의 크기, 그리고 정지 시 중력의 크기 및 방향을 검출할 수 있습니다. 이는 전자 장비의 자태(스크 린의 가로/세로 모드 전환, 관련 게임과 자력계 자세 교정 등)를 식별할 수 있고 진동 식별 관련 기능(예를 들 어, 만보계, 두드림 등)을 갖출 수 있다. 센서는 지문 센서, 압력 센서, 홍채 센서, 분자 센서, 회전의, 기압계, 습도계, 온도계, 적외선 센서 등을 포함할 수 있으며 여기서 더 이상 군말을 하지 않는다. 표시 장치는 사용자가 입력된 정보 또는 사용자에게 제공되는 정보를 표시한다. 표시 장치는 표시 패 널을 포함할 수 있으며 액정 모니터（Liquid Crystal Display， LCD）, 유기 발광 다이오드(Organic Light-Emitting Diode, OLED) 등의 방식으로 표시 패널을 배치할 수 있다. 사용자 입력 장치는 입력되는 숫자 또는 문자 정보를 수신하고, 전자 장비의 사용자 설정 및 기능 제어에 관한 키 신호 입력을 생성한다. 구체적으로 사용자 입력 장치는 터치 패널 및 기타 입력 장치(307 2)를 포함한다. 터치 스크린으로도 불리는 터치 패널은 사용자가 패널 자체 또는 근처에서의 터치 조작 (예컨대, 사용자가 손가락, 스타일러스 펜 등 적합한 물건이나 부속품을 사용하여 터치 패널 또는 터치 패널 근처에서의 조작)을 수집할 수 있다. 터치 패널은 터치 검출 장치와 터치 컨트롤러 두 부분으 로 구성될 수 있다. 터치 검출 장치는 사용자의 터치 위치를 검출하고 터치 조작에 따른 신호를 검출하여 터치 컨트롤러로 전송한다. 터치 컨트롤러는 터치 검출 장치로부터 터치 정보를 수신하여 이를 접촉점 좌표로 변환한 후, 프로세서로 전송하여 프로세서로부터 명령을 수신하여 실행한다. 또 터치 패널은 저항기, 콘덴서, 적외선, 표면 탄성파 등 다양한 형태로 구현할 수 있다. 터치 패널을 제외하고 사용자 입력 장치 는 기타 입력 장치도 포함할 수 있다. 구체적으로 기타 입력 장치는 실제 키보드, 기능 키(예 를 들어 음량 조절키, 스위치키 등), 트랙 볼, 마우스, 조작 레버를 포함하되 이에 한정되지 않는다. 더욱이 터치 패널은 표시 패널에 씌워질 수 있다. 터치 패널은 그 자체 또는 근처의 터치 조 작을 검출한 후 터치 이벤트의 유형을 판정하기 위해 프로세서로 전송하고, 그 다음에 프로세서는 터 치 이벤트의 유형에 따라 표시 패널에 대응하는 시각적 출력을 제공한다. 도 3에서는 터치 패널과 표시 패널이 서로 독립된 부품으로 전자 장비의 입출력 기능을 실현하고 있으나, 일부 실시예의 경우, 터 치 패널과 표시 패널을 일체화 하여 전자 장비의 입출력 기능을 구현할 수 있으며, 이에 한정되는 것은 아니다. 인터페이스 장치는 외부 장치와 전자 장비가 접속되는 인터페이스이다. 예를 들어, 외부 장치는 유선 또는 무선 헤드셋 포트, 외부 전원(또는 배터리 충전기) 포트, 유선 또는 무선 데이터 포트, 메모리 카드 포트, 식별 모듈을 갖는 장치와 연결하는 포트, 오디오 입출력(I/O) 포트, 동영상 I/O 포트, 이어폰 포트 등을 포함할 수 있다. 인터페이스 장치는 외부 장치로부터의 입력(데이터 정보, 전력 등)을 수신하여 수신된 입력을 전 자 장비 내의 하나 이상의 소자로 송신하거나 전자 장비와 외부 장치 사이에서 데이터를 송신할 수 있다. 메모리는 소프트웨어 프로그램 및 각종 데이터를 저장할 수 있다. 메모리는 프로그램 저장 구역과 데 이터 저장 구역을 포함할 수 있다. 그 중에 프로그램 저장 구역은 운영체제, 적어도 하나의 기능에 필요한 애플 리케이션(예를 들어 오디오 재생 기능, 이미지 재생 기능 등) 등을 저장할 수 있다. 데이터 저장 구역은 휴대 전화 사용에 따라 생성된 데이터(예를 들어 오디오 데이터, 전화 번호부 등) 등을 저장할 수 있다. 또한 메모리 는 고속 랜덤 액세스 메모리를 포함할 수 있으며, 적어도 하나의 디스크 메모리 디바이스, 플래시 메모리 디바이스 또는 기타 휘발성 고체 메모리 디바이스와 같은 비휘발성 메모리를 포함할 수 있다. 프로세서는 전자 장비의 제어 센터로서 각종 인터페이스와 회선을 이용하여 전자 장비의 각부를 연결하고, 메모리에 저장된 소프트웨어 프로그램 및/또는 모듈을 실행하며, 메모리에 저장된 데이터를 호출하여 전자 장비의 각종 기능을 실행하고 데이터를 처리함으로써 전자 장비의 전체를 감시한다. 프로세서는 하나 이상의 처리 장치를 포함할 수 있다. 바람직하게는 프로세서는 애플리케이션 프로세서 및 모뎀 프로세서를 통합할 수 있다. 애플리케이션 프로세서는 주로 운영체제, 사용자 인터페이스 및 애플리케이션 등을 처리하며, 모뎀 프로세서는 주로 무선 통신을 처리한다. 전술한 모뎀 프로세서는 프로세서에 통합되지 않아도 된다. 전자 장비는 각 부품에 전력을 공급하는 전원(예를 들어 배터리)도 포함할 수 있으며, 바람직하게는 전원은 전원 관리 시스템을 통해 프로세서와 논리적으로 연결함으로써 전원 관리 시스템을 통해 충전, 방전 및 전력 소모 관리 등의 기능을 실현할 수 있다. 또한, 전자 장비는 제시하지 않는 기능 모듈을 포함하고 있으며, 여기서 더 이상 설명은 생략한다. 바람직하게, 본 발명의 일부 실시예는 전자 장비 한 가지를 제공한다. 이 전자 장비는 프로세서와 메모리 , 그리고 메모리에 기억되고 프로세서에서 운영 가능한 컴퓨터 프로그램을 포함한다. 이 컴퓨터 프로그램은 프로세서에 의해 실행될 때 전술한 이미지 처리 방법 실시예의 각 단계를 구현하고, 또 동일한 기술적 효과를 달성할 수 있으므로, 반복을 피하고자 여기서 상세한 설명을 생략한다. 본 발명의 실시예는 컴퓨터 판독 가능 기억 매체를 제공함에 있어서, 상기 컴퓨터 판독 가능 기억 매체에는 컴 퓨터 프로그램이 저장되어 있으며, 상기 컴퓨터 프로그램이 프로세서에 의해 실행될 때 전술한 이미지 처리 방 법 실시예의 각 단계를 구현하고, 또 동일한 기술적 효과를 달성할 수 있으므로, 반복을 피하고자 여기서 상세 한 설명을 생략한다. 여기서, 상기 컴퓨터 판독 가능 기억 매체는 롬(Read-Only Memory, ROM), 램(Random Access Memory, RAM), 자기 디스크 또는 시디롬 등일 수 있다.여기서 기재된 실시예들은 하드웨어, 소프트웨어, 펌웨어, 미들웨어, 마이크로 코드 또는 이들의 조합으로 구현 될 수 있다. 하드웨어 구현의 경우, 모듈, 장치, 서브 모듈, 서브장치 등은 하나 이상의 주문형 집적회로 (Application Specific Integrated Circuits, ASIC), 디지털 신호 프로세서(Digital Signal Processing, DSP), 디지털 신호 처리 장치(DSP Device, DSPD), 프로그램 가능 논리 소자(Programmable Logic Device, PLD), 필드 프로그램 가능 게이트 어레이(Field-Programmable Gate Array, FPGA), 범용 프로세서, 컨트롤러, 마이크 로 컨트롤러, 마이크로프로세서, 본 출원의 기능을 수행하기 위한 다른 전자기기 또는 그 조합으로 실현할 수 있다. 본 명세서에서, “포함한다”, “갖는다” 또는 다른 임의의 변형은 비 배타적 포함을 의도하며, 일련의 요소를 포함하는 프로세스, 방법, 물품 또는 장치는 그 요소뿐만 아니라 명확하게 나열되지 않은 다른 요소도 포함하며, 또는 이러한 프로세스, 방법, 물품 또는 장치의 고유한 요소도 포함한다는 점에 유의해야 한다. 별도 로 제한이 없는 한, “~을 포함한다”로 정의된 요소는 해당 요소를 포함하는 프로세스, 방법, 물품 또는 장치 에서 다른 동일한 요소의 존재를 배제하지 않는다. 상기 실시예의 설명을 통해, 당업자라면 상기 실시예의 방법이 소프트웨어와 필요한 일반 하드웨어 플랫폼을 결 합하는 방식에 의해 구현되거나 또는 하드웨어에 의해 구현될 수 있지만, 많은 경우에 소프트웨어와 필요한 일 반 하드웨어 플랫폼을 결합하는 방식이 더 바람직하다는 것을 명백하게 이해할 수 있을 것이다. 이러한 이해를 기반으로, 본 발명의 기술적 솔루션의 본질적 부분 또는 관련 기술에 기여한 부분 또는 해당 기술 솔루션의 전 부 또는 일부분을 소프트웨어 제품의 형태로 구현할 수 있고, 단말(휴대폰, 컴퓨터, 서버, 에어컨 또는 네트워 크 장비 등)에 의해 본 발명의 각 실시예에 따른 방법을 수행할 수 있는 복수의 명령을 포함시켜 해당 컴퓨터 소프트웨어 제품을 저장 매체(예: ROM/RAM, 자기 디스크, 시디롬)에 저장할 수 있다. 전술한 바와 같이 첨부된 도면을 결부하여 본 발명의 실시예들을 설명하였지만, 본 발명은 전술한 구체적인 실 시예들에 제한되지 않으며, 전술한 구체적인 실시예들은 제한적이 아닌 예시에 불과하다. 당업자라면 본 발명의 사상 및 청구범위에 따른 보호 범위를 벗어나지 않고 본 발명에 기초하여 다양한 양상을 도출할 수 있으며, 이 는 모두 본 발명의 보호범위에 속한다.도면 도면1 도면2 도면3"}
{"patent_id": "10-2022-7035671", "section": "도면", "subsection": "도면설명", "item": 1, "content": "본 발명의 실시예의 기술적 솔루션을 더욱 명확하게 설명하기 위해, 이하 본 발명의 실시예를 설명함에 있어서 필요한 도면에 대해 간단하게 소개하도록 하며, 여기서 설명된 도면은 본 발명의 일부 실시예에 불과하며, 본 발명의 기술 분야의 통상 지식을 가진 자라면 본 발명의 실시예를 기반으로 창의적인 노력 없이 이러한 도면에 근거하여 다른 도면도 얻을 수 있음이 분명하다. 도 1은 본 발명의 실시예에서 제공하는 이미지 처리 방법의 개략적인 흐름도이다. 도 2는 본 발명의 실시예에서 제공하는 전자 장비의 구조 설명도이다. 도 3은 본 발명의 실시예에서 제공하는 전자 장비의 하드웨어 구조 설명도이다."}
