{"patent_id": "10-2019-0179963", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2021-0086191", "출원번호": "10-2019-0179963", "발명의 명칭": "줄거리를 통한 머신러닝 기반의 미디어 흥행 예측", "출원인": "성균관대학교산학협력단", "발명자": "정윤경"}}
{"patent_id": "10-2019-0179963", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "줄거리로 구성된 텍스트 데이터에 대하여 전처리를 수행하는 단계;제1 모델을 이용하여, 상기 전처리된 데이터로부터 감정점수를 산출하는 단계;상기 산출된 감정점수를 이용하여 제1 입력데이터를 생성하는 단계;제2 모델을 이용하여, 상기 전처리된 데이터로부터 제2 입력데이터를 생성하는 단계; 및상기 제1 입력데이터와 상기 제2 입력데이터를 미리 학습된 제3 모델에 적용하여, 상기 줄거리에 상응하는 컨텐츠의 후보클래스를 결정하는 단계;를 포함하되,상기 후보클래스는, 흥행을 나타내는 제1 클래스와 비흥행을 나타내는 제2 클래스를 포함하는 것을 특징으로 하는, 방법."}
{"patent_id": "10-2019-0179963", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1 항에 있어서,,상기 줄거리는,영화, 뮤지컬, 콘서트, 연극, 스포츠, 전시, 서적 또는 음악 중 적어도 하나를 포함하는 것을 특징으로 하는,방법."}
{"patent_id": "10-2019-0179963", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1 항에 있어서,상기 전처리를 수행하는 단계는,상기 줄거리로 구성된 텍스트 데이터를 문장 단위로 분할하는 단계를 포함하는 것을 특징으로 하는, 방법."}
{"patent_id": "10-2019-0179963", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3 항에 있어서,상기 전처리를 수행하는 단계는,상기 문장 단위로 분할된 텍스트 데이터에 관한 리스트를 생성하는 단계를 더 포함하는 것을 특징으로 하는, 방법."}
{"patent_id": "10-2019-0179963", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1 항에 있어서,상기 감정점수는,긍정점수(positive score), 부정점수(negative score), 중립점수(neutral score), 또는 혼합점수(compoundscore)를 포함하는 것을 특징으로 하는, 방법.공개특허 10-2021-0086191-3-청구항 6 제1 항에 있어서,상기 제1 모델은 감정점수에 관한 정보와 상기 전처리된 데이터를 학습 데이터로 제공하여 학습된 신경망 모델인 것을 특징으로 하는, 방법."}
{"patent_id": "10-2019-0179963", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1 항에 있어서,상기 제1 모델은 VADER sentiment Analyzer인 것을 특징으로 하는, 방법."}
{"patent_id": "10-2019-0179963", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1 항에 있어서,상기 감정점수는 N 차원의 벡터이고,상기 감정점수를 산출하는 단계는,상기 줄거리를 구성하는 복수의 문장 중 가장 마지막에 위치한 문장부터 역순으로 상기 복수의 문장 각각에 대한 감정점수를 산출하되, 상기 복수의 문장의 수(=M)가 N 미만인 경우, (N-M)만큼의 나머지 차원에는 제로패딩(zero-padding)을 적용하는 것을 특징으로 하는, 방법."}
{"patent_id": "10-2019-0179963", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1 항에 있어서,상기 제2 모델은 ELMO 모델인 것을 특징으로 하는, 방법"}
{"patent_id": "10-2019-0179963", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제1 항에 있어서,제1 입력데이터를 생성하는 단계는,상기 감정점수를 Merged 1D CNN에 적용하여, 제1 특징벡터를 생성하는 것을 특징으로 하는, 방법"}
{"patent_id": "10-2019-0179963", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제1 항에 있어서,제1 입력데이터를 생성하는 단계는,상기 감정점수를 제1 Bidirectional LSTM에 적용하여 제1 벡터를 생성하는 단계,상기 제1 벡터를 제2 Bidirectional LSTM에 적용하여 제2 벡터를 생성하는 단계; 및상기 제1 벡터와 상기 제2 벡터를 합(add)하여 제2 특징벡터를 생성하는 단계;를 포함하는 것을 특징으로 하는, 방법.공개특허 10-2021-0086191-4-청구항 12 제1 항에 잇어서,상기 후보클래스를 결정하는 단계는,상기 제1 입력데이터와 상기 제2 입력데이터를 결합(concatenate)하여 결합벡터(concatenated vector)를 생성하는 단계;상기 결합벡터를 상기 미리 학습된 제3 모델에 적용하여, 상기 줄거리에 상응하는 컨텐츠의 후보 클래스를 결정하는 단계;를 포함하는 것을 특징으로 하는, 방법."}
{"patent_id": "10-2019-0179963", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제1 항에 있어서,상기 제3 모델은,컨텐츠에 관한 흥행점수가 레이블링된 학습용 줄거리에 기반하여 미리 학습된 분류모델이고,상기 학습용 줄거리는 전처리가 수행된 텍스트 데이터인 것을 특징으로 하는, 방법."}
{"patent_id": "10-2019-0179963", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제13 항에 있어서,상기 컨텐츠에 관한 흥행점수는,상기 학습용 줄거리에 관한 수요자의 평가점수이며,상기 평가점수가 X점 이상이면 흥행을 나타내는 상기 제1 클래스, Y점 미만이면 비흥행을 나타내는 상기 제2 클래스인 것을 특징으로 하는, 방법."}
{"patent_id": "10-2019-0179963", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제14 항에 있어서,상기 X와 상기 Y는 서로 다른 값인 것을 특징으로 하는, 방법."}
{"patent_id": "10-2019-0179963", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제1 항 내지 제14 항 중 어느 한 항의 방법을 컴퓨터 시스템에서 실행하기 위한 프로그램이 기록된 컴퓨터 시스템이 판독 가능한 기록매체."}
{"patent_id": "10-2019-0179963", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "줄거리를 통한 머신러닝 기반의 미디어 흥행 예측이 개시된다. 본 명세서의 일 실시예에 따른 방법은 줄거리로 구성된 텍스트 데이터에 대하여 전처리를 수행하고, 제1 모델을 이용하여, 상기 전처리된 데이터로부터 감정점수 를 산출하고, 상기 산출된 감정점수를 이용하여 제1 입력데이터를 생성하고, 제2 모델을 이용하여, 상기 전처리 된 데이터로부터 제2 입력데이터를 생성하고, 상기 제1 입력데이터와 상기 제2 입력데이터를 미리 학습된 제3 모 델에 적용하여, 상기 줄거리에 상응하는 컨텐츠의 후보클래스를 결정한다."}
{"patent_id": "10-2019-0179963", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 명세서는 줄거리를 통한 머신러닝 기반의 미디어 흥행 예측에 관한 것이다."}
{"patent_id": "10-2019-0179963", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "인공지능 기술은 기계학습(딥러닝) 및 기계학습을 활용한 요소 기술들로 구성된다. 기계학습은 입력 데이터들의 특징을 스스로 분류/학습하는 알고리즘 기술이며, 요소기술은 딥러닝 등의 기계학 습 알고리즘을 활용하여 인간 두뇌의 인지, 판단 등의 기능을 모사하는 기술로서, 언어적 이해, 시각적 이해, 추론/예측, 지식 표현, 동작 제어 등의 기술 분야로 구성된다. 한편, 기계학습은 언어적 이해의 분야에서 영화, 드라마 등을 포함하는 미디어의 줄거리만을 이용하여 미디어가 일반수요자에게 공개되기 이전에 미디어의 흥행 또는 비흥행을 예측하는 일부 시도가 있었다. 그러나, 영화의 스포일러를 이용하여 흥행 여부를 예측하는 방법에서는 성능이 낮고, 훈련 데이터와 테스트 데이터의 수가 적어 신뢰하기 어려웠다. 또한, 다른 시도는 영화의 줄거리뿐만 아니라 영화가 개봉한 이후에 수집할 수 있는 인자들 을 활용하므로 미디어의 제작 및/또는 투자 결정을 위한 흥행 여부를 판별할 수 없었다."}
{"patent_id": "10-2019-0179963", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 명세서는 전술한 필요성 및/또는 문제점을 해결하는 것을 목적으로 한다. 또한, 본 명세서는, 미디어의 줄거리만을 이용하여 미디어의 흥행도를 예측할 수 하는 줄거리를 통한 머신러닝 기반의 미디어 흥행 예측을 구현하는 것을 목적으로 한다."}
{"patent_id": "10-2019-0179963", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 명세서의 일 실시예에 따른 방법은 줄거리로 구성된 텍스트 데이터에 대하여 전처리를 수행하는 단계;제1 모 델을 이용하여, 상기 전처리된 데이터로부터 감정점수를 산출하는 단계;상기 산출된 감정점수를 이용하여 제1 입력데이터를 생성하는 단계;제2 모델을 이용하여, 상기 전처리된 데이터로부터 제2 입력데이터를 생성하는 단 계; 및 상기 제1 입력데이터와 상기 제2 입력데이터를 미리 학습된 제3 모델에 적용하여, 상기 줄거리에 상응하 는 컨텐츠의 후보클래스를 결정하는 단계;를 포함한다. 또한, 상기 후보클래스는, 흥행을 나타내는 제1 클래스와 비흥행을 나타내는 제2 클래스를 포함할 수 있다. 또한, 상기 줄거리는, 영화, 뮤지컬, 콘서트, 연극, 스포츠, 전시, 서적 또는 음악 중 적어도 하나를 포함할 수 있다. 또한, 상기 전처리를 수행하는 단계는, 상기 줄거리로 구성된 텍스트 데이터를 문장 단위로 분할하는 단계를 포 함할 수 있다. 또한, 상기 전처리를 수행하는 단계는, 상기 문장 단위로 분할된 텍스트 데이터에 관한 리스트를 생성하는 단계 를 더 포함할 수 있다. 또한, 상기 감정점수는, 긍정점수(positive score), 부정점수(negative score), 중립점수(neutral score), 또 는 혼합점수(compound score)를 포함할 수 있다. 또한, 상기 제1 모델은 감정점수에 관한 정보와 상기 전처리된 데이터를 학습 데이터로 제공하여 학습된 신경망 모델일 수 있다. 또한, 상기 제1 모델은 VADER sentiment analyzer일 수 있다. 또한, 상기 감정점수는 N 차원의 벡터이고, 상기 감정점수를 산출하는 단계는, 상기 줄거리를 구성하는 복수의 문장 중 가장 마지막에 위치한 문장부터 역순으로 상기 복수의 문장 각각에 대한 감정점수를 산출하되, 상기 복 수의 문장의 수(=M)가 N 미만인 경우, (N-M)만큼의 나머지 차원에는 제로패딩(zero-padding)을 적용할 수 있다. 또한, 상기 제2 모델은 ELMO 모델일 수 있다. 또한, 제1 입력데이터를 생성하는 단계는, 상기 감정점수를 Merged 1D CNN에 적용하여, 제1 특징벡터를 생성할 수 있다. 또한, 제1 입력데이터를 생성하는 단계는, 상기 감정점수를 제1 Bidirectional LSTM에 적용하여 제1 벡터를 생 성하는 단계, 상기 제1 벡터를 제2 Bidirectional LSTM에 적용하여 제2 벡터를 생성하는 단계; 및 상기 제1 벡 터와 상기 제2 벡터를 합(add)하여 제2 특징벡터를 생성하는 단계;를 포함할 수 있다. 또한, 상기 후보클래스를 결정하는 단계는, 상기 제1 입력데이터와 상기 제2 입력데이터를 결합(concatenate)하 여 결합벡터(concatenated vector)를 생성하는 단계; 상기 결합벡터를 상기 미리 학습된 제3 모델에 적용하여,상기 줄거리에 상응하는 컨텐츠의 후보 클래스를 결정하는 단계; 를 포함할 수 있다. 또한, 상기 제3 모델은, 컨텐츠에 관한 흥행점수가 레이블링된 학습용 줄거리에 기반하여 미리 학습된 분류모델 이고, 상기 학습용 줄거리는 전처리가 수행된 텍스트 데이터일 수 있다. 또한, 상기 컨텐츠에 관한 흥행점수는, 상기 학습용 줄거리에 관한 수요자의 평가점수이며, 상기 평가점수가 X 점 이상이면 흥행을 나타내는 상기 제1 클래스, Y점 미만이면 비흥행을 나타내는 상기 제2 클래스일 수 있다. 또한, 상기 X와 상기 Y는 서로 다른 값을 가질 수 있다."}
{"patent_id": "10-2019-0179963", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 명세서의 일 실시예에 따른 줄거리를 통한 머신러닝 기반의 미디어 흥행 예측의 효과에 대해 설명하면 다음 과 같다. 본 명세서는 미디어의 줄거리만을 이용하여 미디어의 흥행도를 예측할 수 있다. 본 명세서에서 얻을 수 있는 효과는 이상에서 언급한 효과로 제한되지 않으며, 언급하지 않은 또 다른 효과들은"}
{"patent_id": "10-2019-0179963", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 2, "content": "아래의 기재로부터 본 명세서가 속하는 기술분야에서 통상의 지식을 가진 자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2019-0179963", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 첨부된 도면을 참조하여 본 명세서에 개시된 실시예를 상세히 설명하되, 도면 부호에 관계없이 동일하거 나 유사한 구성요소는 동일한 참조 번호를 부여하고 이에 대한 중복되는 설명은 생략하기로 한다. 이하의 설명 에서 사용되는 구성요소에 대한 접미사 \"모듈\" 및 \"부\"는 명세서 작성의 용이함만이 고려되어 부여되거나 혼용 되는 것으로서, 그 자체로 서로 구별되는 의미 또는 역할을 갖는 것은 아니다. 또한, 본 명세서에 개시된 실시 예를 설명함에 있어서 관련된 공지 기술에 대한 구체적인 설명이 본 명세서에 개시된 실시예의 요지를 흐릴 수 있다고 판단되는 경우 그 상세한 설명을 생략한다. 또한, 첨부된 도면은 본 명세서에 개시된 실시예를 쉽게 이 해할 수 있도록 하기 위한 것일 뿐, 첨부된 도면에 의해 본 명세서에 개시된 기술적 사상이 제한되지 않으며, 본 명세서의 사상 및 기술 범위에 포함되는 모든 변경, 균등물 내지 대체물을 포함하는 것으로 이해되어야 한다. 제1, 제2 등과 같이 서수를 포함하는 용어는 다양한 구성요소들을 설명하는데 사용될 수 있지만, 상기 구성요소 들은 상기 용어들에 의해 한정되지는 않는다. 상기 용어들은 하나의 구성요소를 다른 구성요소로부터 구별하는 목적으로만 사용된다. 어떤 구성요소가 다른 구성요소에 \"연결되어\" 있다거나 \"접속되어\" 있다고 언급된 때에는, 그 다른 구성요소에 직접적으로 연결되어 있거나 또는 접속되어 있을 수도 있지만, 중간에 다른 구성요소가 존재할 수도 있다고 이 해되어야 할 것이다. 반면에, 어떤 구성요소가 다른 구성요소에 \"직접 연결되어\" 있다거나 \"직접 접속되어\" 있 다고 언급된 때에는, 중간에 다른 구성요소가 존재하지 않는 것으로 이해되어야 할 것이다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 출원에서, \"포함한다\" 또는 \"가지다\" 등의 용어는 명세서상에 기재된 특징, 숫자, 단계, 동작, 구성요소, 부 품 또는 이들을 조합한 것이 존재함을 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성요소, 부품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되 어야 한다. < 흥행예측장치 > 도 1은 본 명세서의 일 실시예에 따른 흥행예측장치의 블록도이다. 도 1을 참조하면, 흥행예측장치는 적어도 하나의 프로세서, 메모리, 통신 모듈을 포함할 수 있다. 프로세서는 하나 이상의 어플리케이션 프로세서(application processor, AP), 하나 이상의 커뮤니케이션 프로세서(communication processor, CP) 또는 적어도 하나 이상의 AI 프로세서(artificial intelligence processor)를 포함할 수 있다. 어플리케이션 프로세서, 커뮤니케이션 프로세서 또는 AI 프로세서는 서로 다른 IC(integrated circuit) 패키지들 내에 각각 포함되거나 하나의 IC 패키지 내에 포함될 수 있다. 어플리케이션 프로세서는 운영체제 또는 응용 프로그램을 구동하여 어플리케이션 프로세서에 연결된 다수의 하 드웨어 또는 소프트웨어 구성요소들을 제어하고, 멀티미디어 데이터를 포함한 각종 데이터 처리/연산을 수행할 수 있다. 일 례로, 상기 어플리케이션 프로세서는 SoC(system on chip)로 구현될 수 있다. 프로세서는 GPU(graphic prcessing unit, 미도시)를 더 포함할 수 있다. 커뮤니케이션 프로세서는 흥행예측장치와 네트워크로 연결된 다른 전자 기기들 간의 통신에서 데이터 링크 를 관리하고 통신 프로토콜을 변환하는 기능을 수행할 수 있다. 일 례로, 커뮤니케이션 프로세서는 SoC로 구현 될 수 있다. 커뮤니케이션 프로세서는 멀티미디어 제어 기능의 적어도 일부를 수행할 수 있다. 또한, 커뮤니케이션 프로세서는 통신 모듈의 데이터 송수신을 제어할 수 있다. 커뮤니케이션 프로세서는 어플리케이션 프로세서의 적어도 일부로 포함되도록 구현될 수도 있다. 어플리케이션 프로세서 또는 커뮤니케이션 프로세서는 각각에 연결된 비휘발성 메모리 또는 다른 구성요소 중 적어도 하나로부터 수신한 명령 또는 데이터를 휘발성 메모리에 로드(load)하여 처리할 수 있다. 또한, 어플리케이션 프로세서 또는 커뮤니케이션 프로세서는 다른 구성요소 중 적어도 하나로부터 수신하거나 다른 구 성요소 중 적어도 하나에 의해 생성된 데이터를 비휘발성 메모리에 저장할 수 있다. 한편, 프로세서(특히, AI 프로세서)는 메모리에 저장된 프로그램을 이용하여 신경망을 학습할 수 있 다. 프로세서는 흥행예측장치의 동작과 관련된 데이터를 인식하기 위한 신경망을 학습할 수 있다. 여 기서, 신경망은 인간의 뇌 구조(예를 들어, 인간의 신경망의 뉴런 구조)를 컴퓨터 상에서 모의하도록 설계될 수 있다. 신경망은 입력층(input layer), 출력층(output layer) 및 적어도 하나의 은닉층(hidden layer)를 포함할 수 있다. 각 층은 가중치를 갖는 적어도 하나의 뉴런을 포함하고, 신경망은 뉴런과 뉴런을 연결하는 시냅스 (synapse)를 포함할 수 있다. 신경망에서 각 뉴런은 시냅스를 통해 입력되는 입력 신호를 가중치(weight) 및/또 는 편향(bias)에 대한 활성함수(activation function)의 함수값으로 출력할 수 있다. 복수의 네트워크 모드들은 뉴런이 시냅스를 통해 신호를 주고받는 뉴런의 시냅틱 활동을 모의하도록 각각 연결 관계에 따라 데이터를 주고받을 수 있다. 딥러닝 모델에서 복수의 네트워크 노드들은 서로 다른 레이어에 위치 하면서 콘볼루션(convolution) 연결 관계에 따라 데이터를 주고받을 수 있다. 신경망 모델의 예는 심층 신경망 (deep neural network, DNN), 합성곱 신경망(convolutional neural network, CNN), 순환 신경망(recurrent neural network), 제한 볼츠만 머신(restricted Boltzmann machine), 심층 신뢰 신경망(deep belief network), 심층 Q-네트워크(deep Q-Network)와 같은 다양한 딥러닝 기법들을 포함하며, 비전인식, 음성인식, 자연어처리, 음성/신호처리 등의 분야에서 적용될 수 있다. 한편, 전술한 바와 같은 기능을 수행하는 프로세서는 범용 프로세서(예를 들어, CPU)일 수 있으나, 인공지 능 학습을 위한 AI 전용 프로세서(예를 들어, GPU)일 수 있다. 한편, 본 명세서의 다양한 실시예에서 프로세서은 다양한 컨텐츠의 줄거리로 구성된 텍스트 데이터에 기반 하여 감정점수를 추출하고, 추출된 감정점수와 다양한 신경망 모델을 이용하여 줄거리만을 이용하여 컨텐츠의 흥행여부를 결정할 수 있다. 구체적인 내용은 도 2 이후로 후술한다.메모리는 내장 메모리 또는 외장 메모리를 포함할 수 있다. 내장 메모리는 휘발성 메모리(예를 들면, DRAM(dynamic RAM), SRAM(static RAM), SDRAM(synchronous dynamic RAM) 등) 또는 비휘발성 메모리 비휘발성 메모리(예를 들면, OTPROM(one time programmable ROM), PROM(programmable ROM), EPROM(erasable and programmable ROM), EEPROM(electrically erasable and programmable ROM), mask ROM, flash ROM, NAND flash memory, NOR flash memory 등) 중 적어도 하나를 포함할 수 있다. 일 실시예에 따르면, 상기 내장 메모리는 SSD(solid state drive)의 형태를 취할 수도 있다. 상기 외장 메모리는 플래시 드라이브(flash drive), 예를 들면, CF(compact flash), SD(secure digital), Micro-SD(micro secure digital), Mini-SD(mini secure digital), xD(extreme digital) 또는 메모리 스틱(memory stick) 등을 더 포함할 수 있다. 본 명세서의 일 실시예에 따른 흥행예측장치의 메모리는 복수의 문장으로 구성된 학습용 코퍼스를 저 장하고 있을 수 있다. 상기 학습용 코퍼스는 다양한 언어 및/또는 억양으로 구성된 텍스트 데이터를 포함할 수 있다. 학습용 코퍼스는 흥행예측장치의 센서(미도시) 또는 카메라(미도시)를 통해 수집되거나 통신 모듈 을 이용하여 통신 가능한 외부 단말로부터 수신된 텍스트 데이터일 수 있다. 또한, 메모리는 본 명세 서의 일 시릿예에 따른 데이터의 분류/인식을 위한 학습 알고리즘을 통해 생성된 러닝모델(learning model)을 저장할 수 있다. 나아가, 메모리는 러닝모델의 입력 데이터, 학습 데이터, 또는 학습 히스토리 등을 저장 할 수도 있다. 통신 모듈은 무선 통신 모듈 또는 RF 모듈를 포함할 수 있다. 무선 통신 모듈은, 예를 들면, Wi-Fi, BT, GPS 또는 NFC를 포함할 수 있다. 예를 들면, 무선 통신 모듈은 무선 주파수를 이용하여 무선 통신 기능을 제공 할 수 있다. 추가적으로 또는 대체적으로, 무선 통신 모듈은 흥행예측장치를 네트워크(예: Internet, LAN, WAN, telecommunication network, cellular network, satellite network, POTS 또는 5G network 등)와 연결시 키기 위한 네트워크 인터페이스 또는 모뎀 등을 포함할 수 있다. RF 모듈은 데이터의 송수신, 예를 들면, RF 신호 또는 호출된 전자 신호의 송수신을 담당할 수 있다. 일 례로, RF 모듈는 트랜시버(transceiver), PAM(power amp module), 주파수 필터(frequency filter) 또는 LNA(low noise amplifier) 등을 포함할 수 있다. 또한, RF 모듈은 무선통신에서 자유공간상의 전자파를 송수신하기 위한 부품, 예를 들면, 도체 또는 도선 등을 더 포함할 수 있다. 본 명세서의 다양한 실시예에 따른 흥행예측장치는 서버, TV, 냉장고, 오븐, 의류 스타일러, 로봇 청소기, 드론, 에어컨, 공기 청정기, PC, 스피커, 홈 CCTV, 조명, 세탁기 및 스마트 플러그 중 적어도 하나로 구현될 수 있다. 도 1에서 설명한 흥행예측장치의 구성요소는 일반적으로 전자 기기에 구비되는 구성요소를 예시한 것이므로, 본 명세서의 실시예에 따른 흥행예측장치는 전술한 구성요소에 한정되지 않으며 필요에 따라 생 략 및/또는 추가될 수 있다. 도 2는 본 명세서의 일 실시예에 따른 흥행예측 프로세스를 설명하기 위한 블록도이다. 도 2를 참조하면, 흥행예측장치의 프로세서는 흥행예측을 위한 딥러닝 또는 머신러닝 기반의 신경망 모델을 생성하기 위하여, 학습데이터를 수집할 수 있다. 이때, 상기 신경망 모델의 학습에 이용되는 학습데이터 는 학습의 효율 및/또는 신경망 모델의 고성능의 구현을 위하여 일정한 형태로 전처리될 수 있다. 일 실시예에 서, 프로세서는 전처리 모듈을 통해 컨텐츠의 줄거리로 구성된 텍스트 데이터를 문장 단위로 추출할 수 있다. 상기 컨텐츠는 줄거리를 가질 수 있는 하나 이상의 공연물 또는 저작물로서 영화, 뮤지컬, 콘서트, 연 극, 스포츠, 전시, 서적 또는 음악 중 적어도 하나를 포함하나, 이에 한정되는 것은 아니다. 도 2는 상기 컨텐 츠의 일 예로 영화를 가정하여 설명하고, 본 명세서의 다양한 실시예 또는 권리범위가 영화의 경우로 한정되는 것으로 해석될 것은 아니다. 본 명세서의 일 실시예에서 프로세서는 전처리 모듈을 통해 문장 단위로 추출된 데이터를 리스트화할 수 있다. 이처럼 생성된 문장 리스트는 적어도 하나의 문장을 리스트 형태로 포함할 수 있다. 문장 리스트는 이 후에 문맥 벡터(context vector) 또는 감정점수(sentiment score)를 생성하거나 산출하는 경우에 입력 데이터로 이용될 수 있다. 흥행예측장치의 프로세서는 전처리된 데이터를 제1 모델 또는 제2 모델에 적용할 수 있다. 여기서 제1 모델은 감정점수 추출모듈(Sentiment Score Extrcation Module)로 정의할 수 있고, 제2 모델 은 ELMO벡터화모듈(ELMO Vectorization Module)로 정의할 수 있다. 제1 모델은 감정점수에 관한 정보와 전처리된 데이터를 학습 데이터로 제공하여 학습된 신경망 모델일 수 있다. 감정점수는 긍정점수(positive score), 부정점수(negative score), 중립점수(neutral score), 또는 혼합 점수(compound score)를 포함할 수 있다. 혼합점수는 -1점(부정점수의 최대값)과 +1(긍정점수의 최대값) 사이의 정규화된 모든 어휘에 대한 감정점수의 합계를 나타낼 수 있다. 일 례로, 제1 모델은 VADER sentiment analyzer로 구현될 수 있다. 제1 모델을 이용하여 생성되는 감정점수는 N 차원의 벡터로 표현될 수 있다. 일례로, N 차원은 198 차원일 수 있다. 이는, 영화의 경우에 가장 긴 줄거리가 198 개의 문장을 가지고 있기 때 문이며, 컨텐츠의 종류에 기반하여 상기 N은 각각의 컨텐츠의 가장 긴 줄거리의 문장 수에 상응하도록 가변될 수 있다. 한편, 일 실시예에서 상기 줄거리를 구성하는 복수의 문장 중 가장 마지막에 위치한 문장으로부터 역 순으로 상기 복수의 문장 각각에 대한 감정점수를 산출하고, 상기 복수의 문장의 수가(=M)가 N 미만인 경우에 (N-M)만큼의 나머지 차원(또는 문장)에는 제로패딩(zero-padding)이 적용될 수 있다. 도 3을 참조하면, 프로세 서는 제1 모델을 이용하여 \"Loki escapes after killing Coulson and ejecting Thor from the airship, while the Hulk falls to the ground after attacking a S.H.I.E.L.D.\"라는 문장에 대하여, 긍 정점수는 0.056, 부정점수는 0.275, 중립점수는 0.669를 산출할 수 있고, 이를 각각의 가중치로 연산하여 산출한 혼합점수로는 -0.7845를 산출할 수 있다. 상기 문장은 가장 마지막 문장(last sentence) 로부터 O 번째(O는 자연수)에 위치한 문장일 수 있다. 한편, 제1 모델에 입력되는 줄거리의 문장이 P 개인 (P는 N 미만의 자연수) 경우에, P+1, 쪋, N 차원의 벡터 공간은 제로패딩이 적용되어 0 을 갖는다. 이는 흥행예 측 프로세스의 성능에 영향을 미치지는 않으며, 감정인자를 도 3과 같이 처리한 이유는 복수의 줄거리 각각에 포함된 문장의 수가 다르며, 일반적인 줄거리의 구성에 비추어 하이라이트는 마지막에 분포될 가능성이 크므로 위와 같이 감정인자를 처리한다. 프로세서는 제2 모델을 이용하여 전처리된 데이터(에를 들어, 줄거리를 구성하는 복수의 문장 또는 상기 복수의 문장으로부터 추출된 문장 리스트)로부터 임베딩 벡터를 생성할 수 있다. 일 실시예에서 제2 모델 은, 전술한 바와 같이, ELMO로 구현될 수 있다. Word2vec, Glove에 의한 임베딩 방법은 다양한 NLP(Natural Language Processing)에서 이용되나, 상기 Word2vec, Glove에 의한 임베딩 방법은 동음이의어 (homophones)와 같이 컨텍스트에 따라 다른 의미를 갖는 단어들을 다룰 수 없으므로, 본 명세서의 일 실시예에 따른 제2 모델은 컨텍스트에 따라 다른 임베딩 벡터를 생성하는 ELMO 임베딩 방법을 이용한다. 프로세서는 제1 모델을 이용하여 생성된 감정점수를 Merged 1D-CNN 또는 Residual Bidirectional LSTM에 적용할 수 있다. 프로세서는 제2 모델을 이용하여 생성된 임베딩 벡터를 FC 레이어에 적용할 수 있다. 그리고, 프로세서는 Merged 1D-CNN 또는 Residual Bidirectional LSTM으로부터 생성된 특징벡터 와 ELMO 모델 및 FC 레이어로부터 생성된 특징벡터를 결합(concatenate)하여 결합벡터(concatenated vector)를 생성할 수 있다. 이처럼 생성된 결합벡터는 미리 학습된 제3 모델의 입력으로 적용될 수 있다. 제3 모델 은 신경망 기반의 분류모델로서, 전처리가 수행된 학습용 줄거리와 상기 학습용 줄거리의 컨텐츠에 관한 흥행점수에 기반하여 지도학습된 분류모델이다. 도 4a는 Merged 1D-CNN을 이용하여 특징벡터를 생성하는 과정을 나타내는 도면이고, 도 4b는 Residual Bidirectional LSTM를 이용하여 특징벡터를 생성하는 과정을 나타내는 도면이다. 도 4a를 참조하면, 프로세서는 전처리된 텍스트를 ELMO에 입력하고, Merged 1D-CNN에 감정점수를 나타내는 벡터를 입력할 수 있다. ELMO 임베딩은 각각의 영화 줄거리의 문장 벡터에 민-풀링(mean-pooling)이 적용되어 1024차원의 벡터로 들어가며, FC 레이어(fully-connected layer)를 통하여 256 차원의 벡터가 될 수 있다. 감 정점수를 나타내는 감정벡터(sentiment vector)는 도 5와 같이, 1D CNN 레이어를 통하여 연산되며, 64차원의 Feature Detector와 3사이즈의 커널을 통하여 (198-3+1)의 컨볼루션 연산이 수행된다. 콘볼루션 연산의 수행 결 과 (Z X 196 X 64) 차원의 벡터가 형성된다(Z는 샘플의 수). 다음 1D CNN도 동일한 과정 하에서 연산되어 (Z X 196 X 64) 차원의 벡터를 형성한다. 이렇게 형성된 벡터는 Max pooling 레이어에서 반으로 축소된 주요 특징을 가지는 벡터를 형성하게 되며, ELMO 임베딩 결과와 결합되기 위하여 Flatten 레이어를 통해 차원을 펼치게 된다. 일 례로, 차원을 펼친 결과 감정벡터는 100 차원을 가지는 특징벡터로 표현될 수 있다. 프로세서는 전술한 전처리된 텍스트로부터 추출한 256 차원의 특징벡터와 감정점수로부터 추출한 100 차원의 특징벡터를 결 합하여 분류모델의 입력값을 생성하고, 생성된 입력값에 따라 생성되는 분류모델의 출력으로 컨텐츠의 흥행 및/또는 비흥행 여부를 결정하게 된다. 도 4b의 Residual Bidirectional LSTM를 이용하여 특징벡터를 생성하는 과정에서 ELMO 임베딩은 1D CNN을 이용 하는 도 4a와 동일하다. 한편, 도 4b의 경우에는 2 개의 Bidirectional LSTM을 이용하여 긴 문장의 의존도를 개 선할 수 있다. 구체적으로, 프로세서는 제1 Bidrection LSTM의 출력값과 제2 Bidirection LSTM이 출력값 을 합하고, 합의 결과를 Flattening할 수 있다. 이때 제2 Bidirection LSTM의 입력은 제1 Bidirection LSTM의 출력일 수 있다. 그리고, 프로세서는 전처리된 텍스트로부터 추출된 특징벡터와 감정점수에 기반한 특징벡 터를 결합하고, 이로부터 컨텐츠의 흥행 및/또는 비흥행 여부를 결정할 수 있다. 본 명세서의 다양한 실시예에 따른 흥행예측장치는 결과값을 1 또는 0으로 이진분류하기 위하여 손실함수로 Binary Cross-entropy Error를 이용할 수 있다. 도 6은 본 명세서의 일 실시예에 따른 흥행예측방법의 순서도이다. 도 6을 참조하면, 흥행예측장치의 프로세서는 줄거리를 포함하는 텍스트에 대한 전처리를 수행할 수 있다(S110). 줄거리는 영화, 뮤지컬, 콘서트, 연극, 스퐃, 전시, 서적 또는 음악 중 적어도 하나에 관한 줄거리 를 포함한다. 전처리 과정은 줄거리로 구성된 텍스트 데이터를 문장 단위로 분할하는 방법 또는 줄거리로 구성 된 텍스트 데이터를 문장 단위로 분할하고, 분할된 문장 단위의 텍스트로부터 복수의 문장들을 포함하는 리스트 틀 생성하는 방법 중 어느 하나를 포함할 수 있다. 프로세서는, 전처리된 데이터를 제1 모델(예를 들어, VADER sentiment analyzer) 또는 제2 모델(예를 들 어, ELMO)에 입력할 수 있다(S120). 구체적으로, 프로세서는 제1 모델을 이용하여, 상기 전처리된 데이터 로부터 감정점수(예를 들어, 긍정점수, 부정점수, 중립점수, 또는 혼합점수)를 산출할 수 있다. 제1 모델은 감 정점수에 관한 정보와 상기 전처리된 데이터를 학습 데이터로 제공하여 미리 학습된 신경망 모델일 수 있다. 본 명세서의 다양한 실시예에서 감정점수는 N 차원의 감정벡터로 표현될 수 있다. 상기 감정벡터는 줄거리를 구성 하는 복수의 문장 중 가장 마지막에 위치한 문장으로부터 연숙으로 복수의 문장 각각에 대한 감정점수를 산출하 여 생성된다. 또한, 프로세서는 상기 복수의 문장의 수(=M)가 N 미만인 경우에 감정벡터의 차원 중 (N- M)만큼의 나머지 차원에 대하여 제로패딩을 적용할 수 있다. 프로세서는 산출된 감정점수를 이용하여 제1 입력데이터를 생성할 수 있다. 구체적으로, 본 명세서의 다양 한 실시예에서 제1 입력데이터는 1D-CNN 또는 Residual Bidirectional LSTM의 출력으로 생성될 수 있다. 또한, 프로세서는 제2 모델을 이용하여, 상기 전처리된 데이터로부터 제2 입력데이터를 생성할 수 있다. 제1 입 력데이터와 제2 입력데이터는 벡터의 형태로 생성될 수 있으며, 이후에 분류모델의 입력데이터로 인가될 수 있 다. 프로세서는 ELMO 임베딩 레이어의 출력과 1D-CNN 또는 Residual Bidirectional LSTM의 출력을 결합하여 분류모델에 적용하고, 그 결과에 기반하여 컨텐츠의 흥행 또는 비흥행 중 어느 하나를 결정할 수 있다(S140). 구체적으로, 프로세서는 상기 제1 입력데이터와 상기 제2 입력데이터를 미리 학습된 제3 모델에 적용하여, 상기 줄거리에 상응하는 컨텐츠의 후보클래스를 결정할 수 있다. 상기 후보클래스는, 흥행을 나타내는 제1 클래 스와 비흥행을 나타내는 제2 클래스를 포함할 수 있다. 보다 구체적으로, 프로세서는 제1 입력데이터와 제 2 입력데이터를 결합하여 결합벡터를 생성하고, 생성된 결합벡터를 미리 학습된 분류모델에 적용하여 줄거리에 상응하는 컨텐츠의 후보클래스를 결정할 수 있다. 이때, 분류모델은 컨텐츠에 관한 흥행점수가 레이블링된 학습 용 줄거리에 기반하여 미리 학습된 분류모델이고, 학습용 줄거리는 전처리가 수행된 텍스트 데이터로 구성될 수 있다. 상기 컨텐츠에 관한 흥행점수는 학습용 줄거리에 관한 수요자의 평가점수이며, 상기 평가점수가 X 점 이 상이면 흥행을 나타내는 상기 제1 클래스이고, Y 점 미만이면 비흥행을 나타내는 상기 제2 클래스로 분류될 수 있다. 이때, X와 Y는 서로 다른 값을 가질 수 있다. 전술한 본 명세서는, 프로그램이 기록된 매체에 컴퓨터가 읽을 수 있는 코드로서 구현하는 것이 가능하다. 컴퓨 터가 읽을 수 있는 매체는, 컴퓨터 시스템에 의하여 읽혀질 수 있는 데이터가 저장되는 모든 종류의 기록장치를 포함한다. 컴퓨터가 읽을 수 있는 매체의 예로는, HDD(Hard Disk Drive), SSD(Solid State Disk), SDD(Silicon Disk Drive), ROM, RAM, CD-ROM, 자기 테이프, 플로피 디스크, 광 데이터 저장 장치 등이 있으며, 또한 캐리어 웨이브(예를 들어, 인터넷을 통한 전송)의 형태로 구현되는 것도 포함한다. 따라서, 상기의 상세한 설명은 모든 면에서 제한적으로 해석되어서는 아니되고 예시적인 것으로 고려되어야 한다. 본 명세서의 범위는 첨부된 청구 항의 합리적 해석에 의해 결정되어야 하고, 본 명세서의 등가적 범위 내에서의 모든 변경은 본 명세서의 범위에 포함된다.부호의 설명 210 : 줄거리 220 : 전처리 모듈 231 : 제2 모델 241 : 제1 모델 252 : 제3 모델"}
{"patent_id": "10-2019-0179963", "section": "도면", "subsection": "도면설명", "item": 1, "content": "본 명세서에 관한 이해를 돕기 위해 상세한 설명의 일부로 포함되는, 첨부 도면은 본 명세서에 대한 실시예를 제공하고, 상세한 설명과 함께 본 명세서의 기술적 특징을 설명한다. 도 1은 본 명세서의 일 실시예에 따른 흥행예측장치의 블록도이다. 도 2는 본 명세서의 일 실시예에 따른 흥행예측 프로세스를 설명하기 위한 블록도이다. 도 3 은 본 명세서의 감정점수 추출과정을 예시적으로 설명하기 위한 도면이다. 도 4a는 Merged 1D-CNN을 이용하여 특징벡터를 생성하는 과정을 나타내는 도면이다. 도 4b는 Residual Bidirectional LSTM를 이용하여 특징벡터를 생성하는 과정을 나타내는 도면이다. 도 5는 1D CNN을 설명하기 위한 도면이다. 도 6은 본 명세서의 일 실시예에 따른 흥행예측방법의 순서도이다."}
