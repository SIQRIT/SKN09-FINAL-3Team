{"patent_id": "10-2021-0160191", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0073619", "출원번호": "10-2021-0160191", "발명의 명칭": "얼굴 인식을 이용하여 차량 정보를 관리하는 전자 장치 및 그 동작 방법", "출원인": "주식회사 마인드포지", "발명자": "채규열"}}
{"patent_id": "10-2021-0160191", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "서버의 동작 방법으로서,주차장 내에 설치된 복수의 카메라 장치들 중 제 1 카메라 장치에 의해 촬영된 차량의 번호판을 포함하는 제 1이미지 및 상기 제 1 카메라 장치의 식별 정보를 획득하는 단계;상기 제 1 이미지에 기반하여 차량의 번호를 식별하는 단계;상기 제 1 카메라 장치의 식별 정보 및/또는 상기 제 1 이미지에 기반하여식별된 상기 차량의 번호에 기반하여,상기 차량의 위치에 대한 정보를 획득하는 단계;제 1 얼굴을 포함하는 제 2 이미지를 획득하는 단계;상기 제 2 이미지에 기반하여 상기 제1 얼굴에 대한 제 1 정보를 획득하는 단계;상기 제 1 얼굴에 대한 상기 제 1 정보, 상기 차량의 위치에 대한 정보, 및 상기 차량의 번호를 서로 연관된 형태로 상기 서버에 저장하는 단계;관리 장치로부터, 상기 관리 장치에 의해 촬영된 제2 얼굴을 포함하는 제 3 이미지와 함께 차량 위치를 요청하는 메시지를 수신하는 단계;상기 제 3 이미지에 기반하여 상기 제2 얼굴에 대한 제 2 정보를 획득하는 단계; 및상기 서버에 저장된 상기제 1 얼굴에 대한 상기 제 1 정보와 상기 제 2 얼굴에 대한 상기 제 2 정보를 비교한것에 기반하여 식별된, 상기 제 2 정보에 대응하는 차량의 위치에 대한 정보를 상기 관리 장치로 송신하는단계;를 포함하는,서버의 동작 방법."}
{"patent_id": "10-2021-0160191", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1 항에 있어서, 상기 서버는 상기 복수의 카메라 장치들의 식별 정보에 대응하는 상기 주차장의 복수의 주차구역들에 대한 정보를 미리 저장하고,상기 복수의 주차 구역들 중 상기 제 1 카메라 장치의 식별 정보에 대응하는 제 1 주차 구역을 식별하는 단계;및상기 식별된 차량의 번호에 기반하여 식별되는 상기 제 1 주차 구역 중 특정 서브 주차 구역을, 상기 차량의 위치에 대한 정보로서 획득하는 단계;를 포함하는,서버의 동작 방법."}
{"patent_id": "10-2021-0160191", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 2 항에 있어서,상기 특정 서브 주차 구역에 주차가 완료된 상기 차량으로부터 상기 사용자가 하차하는 경우 상기 사용자의 근점을 감지한 특정 조명 장치에 의해 턴-온된 상기 제 1 카메라 장치에 의해 촬영된 상기 사용자의 얼굴을 포함하는 상기 제 2 이미지를 수신하는 단계;를 포함하는,서버의 동작 방법."}
{"patent_id": "10-2021-0160191", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "공개특허 10-2023-0073619-3-제 1 항에 있어서,상기 제 2 이미지로서, 상기 관리 장치에 의해 특정 촬영 방법으로 촬영된 복수의 제 2 이미지들 및 상기 특정촬영 방법에 대한 정보를 수신하는 단계; 상기 복수의 제 2 이미지들은 모두 사용자의 얼굴을 포함하되 서로 다른 밝기 특성, 및/또는 서로 다른 픽셀 값을 가지고,상기 복수의 제 2 이미지들, 상기 특정 촬영 방법, 상기 차량의 위치에 대한 정보, 및 상기 차량의 번호를 서로연관된 형태로 상기 서버에 저장하는 단계;상기 관리 장치로부터 상기 차량 위치를 요청하는 메시지를 수신하는 경우, 상기 메시지에 기반하여 상기 차량의 번호 및/또는 사용자의 얼굴을 식별하는 단계;상기 차량의 번호 및/또는 상기 사용자의 얼굴에 대응하는 제 1 촬영 방법에 대한 정보를 상기 관리 장치로 송신하는 단계;상기 제 3 이미지로서, 상기 관리 장치에 의해 상기 제 1 촬영 방법으로 촬영된 복수의 제 3 이미지들을 수신하는 단계;상기 데이터베이스와 상기 복수의 제 3 이미지들을 비교한 것에 기반하여 식별된 상기 복수의 제 3 이미지들에대응하는, 차량의 위치에 대한 정보를 상기 관리 장치로 송신하는 단계;를 포함하고,상기 특정 촬영 방법은 상기 관리 장치에 포함된 복수의 조명 장치들을 특정 순서로 턴-온하여 사용자의 얼굴을촬영하는 방법을 포함하는,서버의 동작 방법."}
{"patent_id": "10-2021-0160191", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제 1 항에 있어서,상기 제 2 이미지에 기반하여 상기 사용자의 얼굴에 대한 제 1 정보로서 상기 사용자의 얼굴의 복수의 특징점들별 제 1 값을 식별하는 단계; 및상기 제 3 이미지에 기반하여 상기 사용자의 얼굴에 대한 제 2 정보로서 상기 사용자의 얼굴의 상기 복수의 특징점들 별 제 2 값을 식별하는 단계;를 포함하고,상기 복수의 특징점들은 상기 사용자의 얼굴의 일부의 형태, 얼굴 부분들 간의 각도와 거리, 또는 뼈 돌출 정도중 적어도 하나를 포함하는,서버의 동작 방법."}
{"patent_id": "10-2021-0160191", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제 5 항에 있어서,사용자 얼굴을 포함하는 복수의 이미지들 및 상기 복수의 이미지들에 대응하는 상기 복수의 특징점들 별 값에대한 정보를 트레이닝 데이터로 하여 인공 지능 모델을 생성하는 단계; 상기 인공 지능 모델은 특정 이미지의픽셀 정보를 입력 받은 것에 대한 응답으로 상기 복수의 특징 점들 별 특정 값을 출력하도록 구현되고,상기 인공 지능 모델에 상기 제 2 이미지의 픽셀 값 또는 상기 제 3 이미지의 픽셀 값을 입력 한 것에 대한 응답으로 상기 복수의 특징점들 별 제 1 값 또는 상기 복수의 특징점들 별 제 2 값을 획득하는 단계;를 포함하는서버의 동작 방법."}
{"patent_id": "10-2021-0160191", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "프로세서에 의해 실행 가능한 프로그램 코드를 저장하는 비일시적 컴퓨터 판독가능 매체에 있어서, 상기 프로그공개특허 10-2023-0073619-4-램 코드가 실행되는 경우 상기 프로그램 코드는 상기 프로세서가:주차장 내에 설치된 복수의 카메라 장치들 중 제 1 카메라 장치에 의해 촬영된 차량의 번호판을 포함하는 제 1이미지 및 상기 제 1 카메라 장치의 식별 정보를 획득하고,상기 제 1 이미지에 기반하여 차량의 번호를 식별하고,상기 제 1 카메라 장치의 식별 정보 및/또는 상기 제 1 이미지에 기반하여 식별된 상기 차량의 번호에기반하여, 상기 차량의 위치에 대한 정보를 획득하고,제 1 얼굴을 포함하는 제 2 이미지를 획득하고,상기 제 2 이미지에 기반하여 상기 제 1 얼굴에 대한 제 1 정보를 획득하고,상기 차량의 위치에 대한 정보 및 상기 제 1 얼굴에 대한 상기 제 1 정보를 외부 전자 장치로 전송하고,제 2 얼굴을 포함하는 제 3 이미지를 획득하고,상기 제 3 이미지에 기반하여 상기 제 2 얼굴에 대한 제 2 정보를 획득하고,상기 제 2 얼굴에 대한 상기 제 2 정보를 상기 외부 전자 장치로 전송하도록 하고, 상기 제 2 정보의 전송에 기반하여 상기 제 2 얼굴에 대응하는 상기 차량의 위치에 대한 정보가 식별되는,비일시적 컴퓨터 판독가능 매체."}
{"patent_id": "10-2021-0160191", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "서버로서,통신 회로; 및적어도 하나의 프로세서;를 포함하고, 상기 적어도 하나의 프로세서는:주차장 내에 설치된 복수의 카메라 장치들 중 제 1 카메라 장치에 의해 촬영된 차량의 번호판을 포함하는 제 1이미지 및 상기 제 1 카메라 장치의 식별 정보를 획득하고,상기 제 1 이미지에 기반하여 차량의 번호를 식별하고,상기 1 카메라 장치의 식별 정보 및/또는 상기 제 1 이미지에 기반하여 상기 식별된 차량의 번호에 기반하여,상기 차량의 위치에 대한 정보를 획득하고,제 1 얼굴을 포함하는 제 2 이미지를 획득하고,상기 제 2 이미지에 기반하여 상기 제 1 얼굴에 대한 제 1 정보를 획득하고,상기 사용자의 얼굴에 대한 상기 제 1 정보, 상기 차량의 위치에 대한 정보, 및 상기 차량의 번호를 서로 연관된 형태로 상기 서버에 저장하고,상기 관리 장치에 의해 촬영된 제 2 얼굴을 포함하는 제 3 이미지와 함께 차량 위치를 요청하는 메시지를 수신하고,상기 제 3 이미지에 기반하여 제 2 얼굴에 대한 제 2 정보를 획득하고,상기 서버에 저장된 상기 제 1 얼굴에 대한 상기 제 1 정보와 상기 제 2 정보를 비교한 것에 기반하여 식별된상기 제 2 정보에 대응하는 차량의 위치에 대한 정보를 상기 관리 장치로 송신하도록 설정된,서버."}
{"patent_id": "10-2021-0160191", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제 8 항에 있어서,상기 적어도 하나의 프로세서는:상기 제 2 이미지로서, 상기 관리 장치에 의해 특정 촬영 방법으로 촬영된 복수의 제 2 이미지들 및 상기 특정촬영 방법에 대한 정보를 수신하고, 상기 복수의 제 2 이미지들은 모두 사용자의 얼굴을 포함하되 서로 다른 밝공개특허 10-2023-0073619-5-기 특성, 및/또는 서로 다른 픽셀 값을 가지고,상기 복수의 제 2 이미지들, 상기 특정 촬영 방법, 상기 차량의 위치에 대한 정보, 및 상기 차량의 번호를 서로연관된 형태로 저장되는 상기 데이터베이스를 상기 서버에 저장하고,상기 관리 장치로부터 상기 차량 위치를 요청하는 메시지를 수신하는 경우, 상기 메시지에 기반하여 상기 차량의 번호 및/또는 상기 사용자의 얼굴을 식별하고,상기 차량의 번호 및/또는 상기 사용자의 얼굴에 대응하는 제 1 촬영 방법에 대한 정보를 상기 관리 장치로 송신하고,상기 제 3 이미지로서, 상기 관리 장치에 의해 상기 제 1 촬영 방법으로 촬영된 복수의 제 3 이미지들을 수신하고,상기 데이터베이스와 상기 복수의 제 3 이미지들을 비교한 것에 기반하여 식별된 상기 복수의 제 3 이미지들에대응하는, 차량의 위치에 대한 정보를 상기 관리 장치로 송신하도록 설정된,서버."}
{"patent_id": "10-2021-0160191", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제 9 항에 있어서,상기 특정 촬영 방법은 상기 관리 장치에 포함된 복수의 조명 장치들 중 조명 장치를 특정 순서로 턴-온하여 사용자의 얼굴을 촬영하는 방법을 포함하는,서버."}
{"patent_id": "10-2021-0160191", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 출원의 일 실시예에 따르면, 일 실시예에 따르면, 서버의 동작 방법으로서, 주차장 내에 설치된 복수의 카메 라 장치들 중 제 1 카메라 장치에 의해 촬영된 차량의 번호판을 포함하는 제 1 이미지 및 상기 제 1 카메라 장치 의 식별 정보를 획득하는 단계; 상기 제 1 이미지에 기반하여 차량의 번호를 식별하는 단계; 상기 1 카메라 장치 (뒷면에 계속)"}
{"patent_id": "10-2021-0160191", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 얼굴 인식에 기반하여, 차량의 정보를 관리하기 위한 전자 장치 및 그 동작 방법에 관한 것이다."}
{"patent_id": "10-2021-0160191", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "얼굴 인식(또는 안면 인식)(Face Recognition) 기술이란 열적외선 촬영, 3차원 측정, 골격 분석 등을 통해 얼굴 형태나 열상(Thermal Image)을 스캔·저장·인식하는 기술로, 카메라에 잡힌 얼굴 이미지와 저장된 사진 DB를 비교하여 신원을 확인하는 데에 이용되어 왔다. 특히 최근에는, 공항이나 터미널, 은행거래 등에서 인증 절차를 간소화하는 방안으로 얼굴 인식 기술을 활용하 고 있다."}
{"patent_id": "10-2021-0160191", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "일 실시예에 따르면, 일 과제는 얼굴 인식에 기반하여 식별된 사용자의 얼굴을 소정의 키(key)로서 차량의 위치 에 대한 정보를 관리하도록 함으로써, 주차 차량 정보의 관리의 효율성을 높이는 전자 장치 및 그 동작 방법을 제공하는 것에 있다. 일 실시예에 따르면, 다른 과제는 안티 스푸핑 기법에 기반하여 획득된 사용자의 얼굴을 포함하는 이미지들을 등록함으로써, 악의를 가진 사용자에 의해 주차 차량의 위치에 대한 정보가 취득되는 문제점을 방지하는 전자 장치 및 동작 방법을 제공하는 것에 있다.일 실시예에 따르면, 또 다른 과제는 인공 지능 모델을 기반으로 식별된 사용자의 얼굴의 특징점 별 값을 획득 함으로써, 사용자의 얼굴에 기반한 주차 위치 정보의 관리의 효율성을 높이는 전자 장치 및 동작 방법을 제공하 는 것에 있다. 본 발명이 해결하고자 하는 과제가 상술한 과제로 제한되는 것은 아니며, 언급되지 아니한 과제들은 본 명세서"}
{"patent_id": "10-2021-0160191", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 2, "content": "및 첨부된 도면으로부터 본 출원이 속하는 기술분야에서 통상의 지식을 가진 자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2021-0160191", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "일 실시예에 따르면, 서버의 동작 방법으로서, 주차장 내에 설치된 복수의 카메라 장치들 중 제 1 카메라 장치 에 의해 촬영된 차량의 번호판을 포함하는 제 1 이미지 및 상기 제 1 카메라 장치의 식별 정보를 획득하는 단계; 상기 제 1 이미지에 기반하여 차량의 번호를 식별하는 단계; 상기 1 카메라 장치의 식별 정보 및/또는 상 기 제 1 이미지에 기반하여 식별된 상기 차량의 번호에 기반하여, 상기 차량의 위치에 대한 정보를 획득하는 단 계; 제 1 얼굴을 포함하는 제 2 이미지를 획득하는 단계; 상기 제 2 이미지에 기반하여 상기 사용자의 제 1 얼 굴에 대한 제 1 정보를 획득하는 단계; 상기 제 1 얼굴에 대한 상기 제 1 정보, 상기 차량의 위치에 대한 정보, 및 상기 차량의 번호를 서로 연관된 형태로 상기 서버에 저장하는 단계; 관리 장치로부터, 상기 관리 장치에 의 해 촬영된 제 2 얼굴을 포함하는 제 3 이미지와 함께 차량 위치를 요청하는 메시지를 수신하는 단계; 상기 제 3 이미지에 기반하여 상기 제 2 얼굴에 대한 제 2 정보를 획득하는 단계; 및 상기 서버에 저장된 상기 제 1 얼굴 에 대한 상기 제 1 정보와 상기 제 2 정보를 비교한 것에 기반하여 식별된, 상기 제 2 정보에 대응하는 차량의 위치에 대한 정보를 상기 관리 장치로 송신하는 단계;를 포함하는, 서버의 동작 방법이 제공될 수 있다. 일 실시예에 따르면, 프로세서에 의해 실행 가능한 프로그램 코드를 저장하는 비일시적 컴퓨터 판독가능 매체에 있어서, 상기 프로그램 코드가 실행되는 경우 상기 프로그램 코드는 상기 프로세서가: 주차장 내에 설치된 복수 의 카메라 장치들 중 제 1 카메라 장치에 의해 촬영된 차량의 번호판을 포함하는 제 1 이미지 및 상기 제 1 카 메라 장치의 식별 정보를 획득하고, 상기 제 1 이미지에 기반하여 차량의 번호를 식별하고, 상기 제 1 카메라 장치의 식별 정보 및/또는 상기 제 1 이미지에 기반하여 식별된 상기 차량의 번호에 기반하여, 상기 차량의 위 치에 대한 정보를 획득하고, 제 1 얼굴을 포함하는 제 2 이미지를 획득하고, 상기 제 2 이미지에 기반하여 상기 제 1 얼굴에 대한 제 1 정보를 획득하고, 상기 차량의 위치에 대한 정보 및 상기 제 1 얼굴에 대한 상기 제 1 정보를 외부 전자 장치로 전송하고, 제 2 얼굴을 포함하는 제 3 이미지를 획득하고, 상기 제 3 이미지에 기반하 여 상기 제 2 얼굴에 대한 제 2 정보를 획득하고, 상기 제 2 얼굴에 대한 상기 제 2 정보를 상기 외부 전자 장 치로 전송하도록 하고, 상기 제 2 정보의 전송에 기반하여 상기 제 2 얼굴에 대응하는 상기 차량의 위치에 대한 정보가 식별되는, 비일시적 컴퓨터 판독가능 매체가 제공될 수 있다. 일 실시예에 따르면, 서버로서, 통신 회로; 및 적어도 하나의 프로세서;를 포함하고, 상기 적어도 하나의 프로 세서는: 주차장 내에 설치된 복수의 카메라 장치들 중 제 1 카메라 장치에 의해 촬영된 차량의 번호판을 포함하 는 제 1 이미지 및 상기 제 1 카메라 장치의 식별 정보를 획득하고, 상기 제 1 이미지에 기반하여 차량의 번호 를 식별하고, 상기 1 카메라 장치의 식별 정보 및/또는 상기 제 1 이미지에 기반하여 상기 식별된 차량의 번호 에 기반하여, 상기 차량의 위치에 대한 정보를 획득하고, 제 1 얼굴을 포함하는 제 2 이미지를 획득하고, 상기 제 2 이미지에 기반하여 상기 제 1 얼굴에 대한 제 1 정보를 획득하고, 상기 사용자의 얼굴에 대한 상기 제 1 정보, 상기 차량의 위치에 대한 정보, 및 상기 차량의 번호를 서로 연관된 형태로 상기 서버에 저장하고, 상기 관리 장치에 의해 촬영된 제 2 얼굴을 포함하는 제 3 이미지와 함께 차량 위치를 요청하는 메시지를 수신하고, 상기 제 3 이미지에 기반하여 제 2 얼굴에 대한 제 2 정보를 획득하고, 상기 서버에 저장된 상기 제 1 얼굴에 대한 상기 제 1 정보와 상기 제 2 정보를 비교한 것에 기반하여 식별된 상기 제 2 정보에 대응하는 차량의 위치 에 대한 정보를 상기 관리 장치로 송신하도록 설정된, 서버가 제공될 수 있다."}
{"patent_id": "10-2021-0160191", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 2, "content": "과제의 해결 수단이 상술한 해결 수단들로 제한되는 것은 아니며, 언급되지 아니한 해결 수단들은 본 명세서 및"}
{"patent_id": "10-2021-0160191", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 3, "content": "첨부된 도면으로부터 본 출원이 속하는 기술분야에서 통상의 지식을 가진 자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2021-0160191", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "일 실시예에 따르면, 전자 장치 및 동작 방법은 얼굴 인식에 기반하여 식별된 사용자의 얼굴을 소정의 키(key) 로서 차량의 위치에 대한 정보를 관리하도록 함으로써, 주차 차량 정보의 관리의 효율성을 향상시킬 수 있다. 일 실시예에 따르면, 전자 장치 및 동작 방법은 안티 스푸핑 기법에 기반하여 획득된 사용자의 얼굴을 포함하는 이미지들을 등록함으로써, 악의를 가진 사용자에 의해 주차 차량의 위치에 대한 정보가 취득되는 문제점을 방지 할 수 있다. 일 실시예에 따르면, 전자 장치 및 동작 방법은 인공 지능 모델을 기반으로 식별된 사용자의 얼굴의 특징점 별 값을 획득함으로써, 사용자의 얼굴에 기반한 주차 위치 정보의 관리의 효율성을 향상시킬 수 있다. 효과가 상술한 효과로 제한되는 것은 아니며, 언급되지 아니한 효과들은 본 명세서 및 첨부된 도면으로부터 본"}
{"patent_id": "10-2021-0160191", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 2, "content": "출원이 속하는 기술분야에서 통상의 지식을 가진 자에게 명확히 이해될 수 있을 것이다."}
{"patent_id": "10-2021-0160191", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 명세서에 기재된 실시예는 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자에게 다양한 실시예들에 따르면, 사상을 명확히 설명하기 위한 것이므로, 본 발명이 본 명세서에 기재된 실시예에 의해 한정되는 것은 아니며, 다양한 실시예들에 따르면, 범위는 다양한 실시예들에 따르면, 사상을 벗어나지 아니하는 수정예 또는 변형예를 포함하는 것으로 해석되어야 한다. 본 명세서에서 사용되는 용어는 본 발명에서의 기능을 고려하여 가능한 현재 널리 사용되고 있는 일반적인 용어 를 선택하였으나 이는 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자의 의도, 관례 또는 새로운 기술 의 출현 등에 따라 달라질 수 있다. 다만, 이와 달리 특정한 용어를 임의의 의미로 정의하여 사용하는 경우에는 그 용어의 의미에 관하여 별도로 기재할 것이다. 따라서 본 명세서에서 사용되는 용어는 단순한 용어의 명칭이 아닌 그 용어가 가진 실질적인 의미와 본 명세서의 전반에 걸친 내용을 토대로 해석되어야 한다. 본 명세서에 첨부된 도면은 본 출원을 용이하게 설명하기 위한 것으로 도면에 도시된 형상은 다양한 실시예들에 따르면, 이해를 돕기 위하여 필요에 따라 과장되어 표시된 것일 수 있으므로 본 출원이 도면에 의해 한정되는 것은 아니다. 본 명세서에서 본 발명에 관련된 공지의 구성 또는 기능에 대한 구체적인 설명이 다양한 실시예들에 따르면, 요 지를 흐릴 수 있다고 판단되는 경우에 이에 관한 자세한 설명은 필요에 따라 생략하기로 한다. 본 문서의 다양한 실시예들 및 이에 사용된 용어들은 본 문서에 기재된 기술적 특징들을 특정한 실시예들로 한 정하려는 것이 아니며, 해당 실시예의 다양한 변경, 균등물, 또는 대체물을 포함하는 것으로 이해되어야 한다. 도면의 설명과 관련하여, 유사한 또는 관련된 구성요소에 대해서는 유사한 참조 부호가 사용될 수 있다. 아이템 에 대응하는 명사의 단수 형은 관련된 문맥상 명백하게 다르게 지시하지 않는 한, 상기 아이템 한 개 또는 복수 개를 포함할 수 있다. 본 문서에서, \"A 또는 B\", \"A 및 B 중 적어도 하나\",\"A 또는 B 중 적어도 하나,\"\"A, B 또 는 C,\" \"A, B 및 C 중 적어도 하나,\"및 \"A, B, 또는 C 중 적어도 하나\"와 같은 문구들 각각은 그 문구들 중 해 당하는 문구에 함께 나열된 항목들 중 어느 하나, 또는 그들의 모든 가능한 조합을 포함할 수 있다. \"제 1\", \" 제 2\", 또는 \"첫째\" 또는 \"둘째\"와 같은 용어들은 단순히 해당 구성요소를 다른 해당 구성요소와 구분하기 위해 사용될 수 있으며, 해당 구성요소들을 다른 측면(예: 중요성 또는 순서)에서 한정하지 않는다. 어떤(예: 제 1) 구성요소가 다른(예: 제 2) 구성요소에, \"기능적으로\" 또는 \"통신적으로\"라는 용어와 함께 또는 이런 용어 없이, \"커플드\" 또는 \"커넥티드\"라고 언급된 경우, 그것은 상기 어떤 구성요소가 상기 다른 구성요소에 직접적 으로(예: 유선으로), 무선으로, 또는 제 3 구성요소를 통하여 연결될 수 있다는 것을 의미한다. 본 문서에서 사용된 용어 \"모듈\"은 하드웨어, 소프트웨어 또는 펌웨어로 구현된 유닛을 포함할 수 있으며, 예를 들면, 로직, 논리 블록, 부품, 또는 회로 등의 용어와 상호 호환적으로 사용될 수 있다. 모듈은, 일체로 구성된 부품 또는 하나 또는 그 이상의 기능을 수행하는, 상기 부품의 최소 단위 또는 그 일부가 될 수 있다. 예를 들 면, 일실시예에 따르면, 모듈은 ASIC(application-specific integrated circuit)의 형태로 구현될 수 있다. 본 문서의 실시예들(예: 제 1 실시예, 제 2 실시예, 제 3 실시예, 및 제 4 실시예)에 기재된 기기(machine)(예: 관리 서버, 관리 장치, 카메라 장치, 엣지 장치)의 동작들은, 기기에 의해 읽을 수 있는 기록 매체(또는 저장 매체(storage medium))(예: 메모리)에 저장된 하나 이상의 명령어들을 포함하는 소프 트웨어(예: 프로그램)로서 구현될 수 있다. 예를 들면, 기기(예: 관리 서버, 관리 장치, 카메라 장치 , 엣지 장치)의 제어 회로(예: 프로세서)는, 기록 매체로부터 저장된 하나 이상의 명령어들 중 적어 도 하나의 명령을 호출하고, 그것을 실행할 수 있다. 이것은 기기가 상기 호출된 적어도 하나의 명령어에 따라 적어도 하나의 기능을 수행하도록 운영되는 것을 가능하게 한다. 상기 하나 이상의 명령어들은 컴파일러에 의해 생성된 코드 또는 인터프리터에 의해 실행될 수 있는 코드를 포함할 수 있다. 기기로 읽을 수 있는 저장매체는, 비일시적(non-transitory) 저장매체의 형태로 제공될 수 있다. 여기서, '비일시적'은 저장매체가 실재 (tangible)하는 장치이고, 신호(signal)(예: 전자기파)를 포함하지 않는다는 것을 의미할 뿐이며, 이 용어는 데 이터가 저장매체에 반영구적으로 저장되는 경우와 임시적으로 저장되는 경우를 구분하지 않는다.일실시예에 따르면, 본 문서에 개시된 다양한 실시예들에 따른 방법은 컴퓨터 프로그램 제품(computer program product)에 포함되어 제공될 수 있다. 컴퓨터 프로그램 제품은 상품으로서 판매자 및 구매자 간에 거래될 수 있 다. 컴퓨터 프로그램 제품은 기기로 읽을 수 있는 저장 매체(예: compact disc read only memory (CD-ROM))의 형태로 배포되거나, 또는 어플리케이션 스토어(예: 플레이 스토어TM)를 통해 또는 두개의 사용자 장치들(예: 스 마트폰들) 간에 직접, 온라인으로 배포(예: 다운로드 또는 업로드)될 수 있다. 온라인 배포의 경우에, 컴퓨터 프로그램 제품의 적어도 일부는 제조사의 서버, 어플리케이션 스토어의 서버, 또는 중계 서버의 메모리와 같은 기기로 읽을 수 있는 저장 매체에 적어도 일시 저장되거나, 임시적으로 생성될 수 있다. 다양한 실시예들에 따르면, 상기 기술한 구성요소들의 각각의 구성요소(예: 모듈 또는 프로그램)는 단수 또는 복수의 개체를 포함할 수 있다. 다양한 실시예들에 따르면, 전술한 해당 구성요소들 중 하나 이상의 구성요소들 또는 동작들이 생략되거나, 또는 하나 이상의 다른 구성요소들 또는 동작들이 추가될 수 있다. 대체적으로 또는 추가적으로, 복수의 구성요소들(예: 모듈 또는 프로그램)은 하나의 구성요소로 통합될 수 있다. 이런 경우, 통 합된 구성요소는 상기 복수의 구성요소들 각각의 구성요소의 하나 이상의 기능들을 상기 통합 이전에 상기 복수 의 구성요소들 중 해당 구성요소에 의해 수행되는 것과 동일 또는 유사하게 수행할 수 있다. 다양한 실시예들에 따르면, 모듈, 프로그램 또는 다른 구성요소에 의해 수행되는 동작들은 순차적으로, 병렬적으로, 반복적으로, 또는 휴리스틱하게 실행되거나, 상기 동작들 중 하나 이상이 다른 순서로 실행되거나, 생략되거나, 또는 하나 이상의 다른 동작들이 추가될 수 있다. 1. 스마트 얼굴 인식 시스템 이하에서는 일 실시예에 따른 스마트 얼굴 인식 시스템에 대해서 설명한다. 본 명세서에서 스마트 얼굴 인식 시스템은 얼굴 인식에 기반하여 서비스를 제공하는 시스템일 수 있다. 예를 들 어, 스마트 얼굴 인식 시스템은 얼굴 인식에 기반하여, 주차장(parking lot)에 주차된 차량들에 대한 정보를 관 리하는 시스템을 포함할 수 있다. 예를 들어, 스마트 얼굴 인식 시스템은 차량을 주차한 사용자의 얼굴을 포함 하는 이미지를 촬영하고 이미지로부터 사용자의 얼굴을 식별할 수 있다. 스마트 얼굴 인식 시스템은 상기 사용 자가 주차한 차량의 위치에 대한 정보와 사용자의 얼굴을 연관된 형태로 등록할 수 있다. 즉, 스마트 얼굴 인식 시스템은 사용자의 얼굴을 차량의 위치에 대한 정보를 요청하기 위한 일종의 키(key) 정보로서 저장할 수 있다. 이후에 스마트 얼굴 인식 시스템은 다시 사용자의 얼굴에 대한 정보가 수신되는 경우, 상기 사용자의 얼굴에 연 관되도록 저장된 차량의 위치에 대한 정보를 제공할 수 있다. 이하에서는 스마트 얼굴 인식 시스템에 대해서 더 구체적으로 설명한다. 2. 스마트 얼굴 인식 시스템의 구성 도 1a는 일 실시예에 따른 스마트 얼굴 인식 시스템에 포함된 장치들의 일 예를 설명하기 위한 도면이다. 도 1b 는 일 실시예에 따른 스마트 얼굴 인식 시스템에 포함된 장치들의 다른 예를 설명하기 위한 도면이다. 이하에서 는 도 2a 내지 도 2b를 참조하여, 도 1a 내지 도 1b에 대해서 설명한다. 도 2a는 일 실시예에 따른 주차장(parking lot)에 배치된 카메라 장치들의 예를 설명하기 위한 도면이다. 도 2b는 일 실시예에 따른 관리 장치, 엣지 장치, 및 관리 서버의 예를 설명하기 위한 도면이다. 도 1a를 참조하면, 스마트 얼굴 인식 시스템은 관리 서버, 관리 장치, 및 적어도 하나의 카메라 장치 를 포함할 수 있다. 이러한 시스템은 \"2.3\" 목차에서 후술되는 서버 타입으로 정의될 수 있다. 또한 도 1b 를 참조하면, 스마트 얼굴 인식 시스템은 관리 서버, 관리 장치, 적어도 하나의 카메라 장치, 및 엣지 장치를 포함할 수 있다. 이러한 시스템은 \"2.3\" 목차에서 후술되는 하이브리드 타입으로 정의될 수 있다. 다만, 도 1a 및 도 1b에 도시된 바에 제한되지 않고 스마트 얼굴 인식 시스템은 도시된 장치들 보다 더 적은 구성들을 포함하거나, 더 많은 구성들을 포함하도록 구현될 수도 있다. 일 실시예에 따르면, 관리 서버(management server)는 다양한 종류의 정보를 분석/인식할 수 있다. 예를 들어, 관리 서버는 주차장(parking lot)에 배치된 카메라 장치들에 의해 촬영된 이미지로부터 차량의 번호를 인식하고, 인식된 차량의 번호를 갖는 차량의 위치에 기반하여 주차 위치에 대한 정보를 분석할 수 있다. 또 예를 들어, 관리 서버는 주차장(parking lot)에 배치된 카메라 장치들 및/또는 관리 장치 에 배치된 카메라 장치(미도시)에 의해 촬영된 사용자의 얼굴을 포함하는 이미지에 대한 얼굴 인식 동작을수행한 것에 기반하여, 사용자의 얼굴에 대한 정보를 분석(예: 얼굴 인식 기능)할 수 있다. 한편 기재된 바에 제한되지 않고, 관리 서버의 사용자의 얼굴에 대한 정보를 분석하는 동작은, 후술되는 엣지 장치에 의해 수행될 수도 있다. 일 실시예에 따르면, 관리 서버는 전술한 바와 같이 다양한 종류의 정보를 분석/인식한 결과에 기반하여, 차량 위치 등록 동작 및 차량 위치 제공 동작을 수행할 수 있다. 예를 들어, 관리 서버는 차량의 위치와 차량의 사용자의 얼굴을 서로 연관된 형태로 등록하는 차량 위치 등록 동작을 수행할 수 있다. 또 예를 들어, 관리 서버는 관리 장치로부터 특정 사용자의 얼굴에 대한 정보를 포함하는 차량 위치를 요청하는 메 시지를 수신하는 경우, 미리 등록된 정보들 중에서 특정 사용자의 얼굴과 연관되도록 저장된 차량의 위치에 대 한 정보를 관리 장치로 제공하는 차량 위치 제공 동작을 수행할 수 있다. 각각의 관리 서버의 구체적 인 동작에 대해서는 후술한다. 일 실시예에 따르면, 관리 장치는 도 2b에 도시된 바와 같이 사용자와 상호 커뮤니케이션 하도록 설치되는 일종의 키오스크(kiosk) 장치일 수 있다. 기재된 바에 제한되지 않고 상기 관리 장치는 키오스크(kiosk) 장치 이외에도 태블릿, 스마트 단말, 웨어러블 장치, 스마트 TV 등 사용자로부터 입력을 수신하고, 정보를 제공 가능한 다양한 종류의 장치들로 구현될 수도 있다. 예를 들어, 상기 관리 장치는 사용자에 대한 정보를 획 득하고, 관리 서버로 전송할 수 있다. 일 예로, 관리 장치는 사용자의 얼굴을 촬영한 것에 기반하여 사용자의 얼굴을 포함하는 이미지를 획득할 수 있다. 또 일 예로, 관리 장치는 사용자로부터 차량 번호에 대한 정보를 입력 받을 수 있다. 또 일 예로, 관리 장치는 카메라 장치들에 의해 촬영된 차량 번호를 포함하는 이미지를 주차장(parking lot)에 설치된 중계기(A), 카메라 장치들, 및/또는 관리 서버를 통해서 수신할 수 있다. 또 예를 들어, 관리 장치는 주차 위치에 대한 정보를 제공할 수 있다. 관리 장치 는 사용자의 얼굴에 대한 이미지를 포함하는 차량 위치를 요청하는 메시지를 관리 서버로 전송하고, 상기 요청 메시지에 대한 응답으로서, 관리 서버로부터 차량 위치에 대한 정보를 획득한 후, 상기 차량 위 치에 대한 정보를 제공(예: 디스플레이)에 표시할 수 있다. 일 실시예에 따르면, 관리 장치는 주차장(parking lot)의 출/입구의 근처에 배치될 수 있으나, 기재 및/또 는 도시된 바에 제한되지 않고 다양한 위치에 배치될 수도 있다. 일 실시예에 따르면, 엣지 장치(edge device, 400)는 다른 장치들(예: 관리 장치 또는 카메라 장치) 의 내부 또는 외부에 구비되어, 특정 기능을 제공하도록 구현될 수 있다. 예를 들어, 엣지 장치는 특정 기 능을 제공하기 위한 엣지 컴퓨팅(edge computing)을 수행하는 장치로서, 다른 장치들(예: 관리 장치 또는 카메라 장치)에 구비되어 촬영된 이미지를 분석하는 동작을 수행하도록 구현될 수 있다. 상기 특정 기능은 사용자의 얼굴을 포함하는 이미지로부터 사용자의 얼굴에 대한 정보(예: 픽셀 값, 또는 특징 점 별 값(또는 랜 드마크 값))를 획득하는 얼굴 인식 기능, 차량 번호판을 포함하는 이미지로부터 차량 번호를 획득하는 차량 번 호 인식 기능, 및 인식된 차량 번호의 차량의 위치를 식별하는 차량 위치 식별 기능 중 적어도 하나를 포함할 수 있다. 예를 들어 도 2a를 참조하면, 카메라 장치는 차량 번호판을 포함하는 이미지를 촬영한 후, 차량 번호 인식 기능을 제공하도록 구현된 엣지 장치(400a)를 이용하여 차량 번호를 획득할 수 있다. 예를 들어 도 2b를 참조하면, 관리 장치는 사용자의 얼굴에 대한 이미지를 촬영한 후, 얼굴 인식 기능을 제공하도록 구 현된 엣지 장치(400b)를 이용하여 사용자의 얼굴에 대한 정보를 획득할 수 있다. 엣지 장치들(400a, 400b)은 도 2a 내지 도 2b에 도시된 바와 같이 USB 장치로 구현될 수 있으나, 기재 및/또는 도시된 바에 제한되지 않고 SD 카드, 또는 케이블로 연결 가능한 전자 장치들 등 다른 장치에 연결 가능한 형태로 다양하게 구현될 수 있다. 도 2a 및 도 2b를 참조하면 상기 엣지 장치(400a)가 카메라 장치에 구비되고, 다른 엣지 장치(400b)는 관 리 장치에 구비되는 것으로 도시되어 있으나, 기재 및/또는 도시된 바에 제한되지 않고 상기 엣지 장치들 (400a, 400b)이 특정 장치(예: 관리 장치)에만 구비되거나 또는 기재 및/또는 도시된 예 이외의 장치(예: 관리 서버) 등에도 구비될 수 있다. 일 실시예에 따르면, 카메라 장치들은 주차되는 차량에 대한 이미지 및/또는 차량에서 탑승하거나 하차하 는 사용자의 이미지를 획득하도록 주차장(parking lot)에 배치될 수 있다. 예를 들어, 도 2a를 참조하면 카메라 장치들은 주차장(parking lot) 내의 주차 영역들(P)에 배치되는 차량의 번호판 및/또는 차량에서 탑승하거 나 하차하는 사용자의 이미지를 촬영하기 위한 위치에 배치될 수 있다. 일 예로 도 2a에 도시된 바와 같이, 복 수의 카메라 장치들(301, 302)는 주차장(parking lot)의 천장의 시설물(L)(예: 배관, 랙 등)을 따라서 일렬로 배치될 수 있다. 다시 말해, 복수의 카메라 장치들(301, 302)는 주차 영역들(P) 사이를 가로지르는 열 형태로 배치될 수 있으며, 기재 및/또는 도시된 바에 제한되지 않고, 카스토퍼(car stopper) 등과 같이 차량의 번호판및/또는 사용자를 촬영하기 위한 위치에 카메라 장치들이 배치될 수 있다. 일 실시예에 따르면, 카메라 장치들은 촬영된 이미지를 관리 서버 및/또는 관리 장치로 전송할 수 있다. 이때, 카메라 장치들은 주차장(parking lot)에 구비되는 중계기(A)를 통해서 관리 서버 및/ 또는 관리 장치와 통신 연결을 설정하여 설정된 통신 연결에 기반하여 촬영된 이미지를 전송하거나, 기재 된 바에 제한되지 않고 직접 통신 연결을 설정하여 촬영된 이미지를 전송할 수도 있다. 한편 일 실시예에 따르면 관리 장치와 카메라 장치들이 특정 건물 내에 배치되는 것으로 기재 및/또 는 도시하였으나, 기재 및/또는 도시된 바에 제한되지 않고 주차장(parking lot)이 구비되는 시설이라면 특정 건물에 제한되지 않고 다양한 종류의 시설 및/또는 야외에도 배치 될 수 있다. 한편 본 출원의 일 실시예에 따르면 스마트 얼굴 인식 시스템으로서, 얼굴 정보를 키(key)로서 차량의 주차 위 치에 대한 정보를 관리하는 동작을 예로 들어서 설명하나, 기재된 바에 제한되지 않고 얼굴 정보를 키(key)로서 다양한 종류의 정보를 관리하는 시스템으로 구현될 수도 있다. 예를 들어, 카메라 장치가 차량 번호판이 아닌 상품의 진열대를 촬영하도록 구비되는 경우, 사용자의 얼굴을 키로서 상품의 진열대에서 사용자가 집어 든 상품에 대한 정보를 관리하는 시스템으로 구현될 수도 있다. 일 예로, 특정 진열대에서 특정 상품이 사용자에 의해 획득되는 경우, 카메라 장치는 사용자의 얼굴 및 특정 상품을 포함하는 이미지를 촬영할 수 있다. 카 메라 장치는 촬영된 이미지로부터 사용자의 얼굴 및 특정 상품을 인식하고, 인식된 정보들(예: 사용자의 얼굴 및 특정 상품)을 관리 장치로 전달할 수 있다. 관리 장치는 인식된 정보들을 획득하고 저장할 수 있다. 관리 장치는 관리 장치로 접근한 사용자의 이미지를 촬영한 것에 기반하여 촬영된 이미지로 부터 사용자의 얼굴을 인식하는 경우, 기-저장된 정보와 사용자의 얼굴을 비교한 것에 기반하여 사용자의 얼굴 에 대응하는 상품에 대한 정보를 제공할 수 있다. 2.1. 스마트 얼굴 인식 시스템의 구성들의 일 예 이하에서는 스마트 얼굴 인식 시스템에 포함된 장치들의 동작을 수행하기 위한 구성들의 일 예에 대해서 설명한 다. 한편, 스마트 얼굴 인식 시스템은 구현 목적에 따라서 시스템 타입(system type) 또는 온 디바이스 타입 (on-device type)으로 구현될 수 있으므로, 이에 대해서는 \"2.2 목차\"에서 후술한다. 도 3a는 일 실시예에 따른 스마트 얼굴 인식 시스템에 포함된 장치들(예: 관리 서버, 관리 장치, 카 메라 장치)의 구성의 일 예를 나타내는 블록도이다. 도 3b는 일 실시예에 따른 스마트 얼굴 인식 시스템에 포함된 장치들(예: 관리 서버, 관리 장치, 카메라 장치)의 구성의 다른 예를 나타내는 블록도이 다. 한편 도 3a 및 도 3b에 도시된 바에 제한되지 않고, 스마트 얼굴 인식 시스템에 포함된 장치들은 도시된 구 성들 보다 더 적은 구성들 또는 더 많은 구성들을 포함할 수 있다. 이하에서는 도 3a 및 도 3b를 참조하여 관리 서버, 관리 장치, 카메라 장치의 구성의 예에 대해 서 설명한다. 2.1 시스템 타입으로 구현되는 시스템의 구성의 예 2.1.1 관리 서버의 구성의 일 예 먼저, 관리 서버의 구성의 일 예에 대해서 설명한다. 도 3a을 참조하면, 일 실시예에 따르면 관리 서버는 제 1 통신 회로, 차량 번호 인식 모듈, 얼 굴 인식 모듈, 및 주차 위치 관리 모듈을 포함하는 제 1 제어 회로, 및 메모리를 포함할 수 있다. 상기 제 1 통신 회로는 외부 장치(예: 관리 장치, 또는 카메라 장치)와 통신할 수 있다. 예를 들면, 제 1 통신 회로는 무선 통신 또는 유선 통신을 통해서 네트워크에 연결되어 외부 장치(예: 전자 장 치)와 통신을 설정하여, 설정된 통신을 통해 정보 및/또는 데이터를 교환할 수 있다. 상기 제 1 제어 회로는 관리 서버의 전반적인 동작을 제어할 수 있다. 이를 위해 제 1 제어 회로 는 각종 정보의 연산 및 처리를 수행하고 관리 서버의 구성 요소들(예: 제 1 통신 회로)의 동작 을 제어할 수 있다. 제 1 제어 회로는 하드웨어, 소프트웨어, 또는 이들의 조합에 따라 컴퓨터나 이와 유사한 장치로 구현될 수 있다. 하드웨어적으로 상기 제 1 제어 회로는 전기적인 신호를 처리하여 제어 기능 을 수행하는 전자 회로 형태(예: CPU 등)로 제공될 수 있으며, 소프트웨어적으로는 하드웨어적인 상기 제 1 제 어 회로를 구동시키는 프로그램 형태로 제공될 수 있다. 이하에서 설명되는 관리 서버의 제 1 제어 회로에 포함되는 모듈들(예: 차량 번호 인식 모듈, 얼굴 인식 모듈, 및 주차 위치 관리 모듈 )은 상기 제 1 제어 회로가 모듈과 연관된 동작을 수행하도록 제어할 수 있다. 다시 말해, 상기 모듈 들은 상기 모듈과 연관된 동작을 수행하도록 제어하기 위한 프로그램, 컴퓨터 판독 가능한 코드, 프로세스 또는 인스트럭션(instructions)들로 구현되며, 상기 모듈들이 상기 제 1 제어 회로에 의해 실행되는 경우, 상기 제 1 제어 회로가 상기 모듈과 연관된 동작을 수행하도록 제어할 수 있다. 한편, 이하의 설명에서 특별한 언급이 없는 경우에는 전자 장치의 동작은 상기 제 1 제어 회로의 제어에 의해 수행되는 것으로 해석 될 수 있다. 상기 제 1 제어 회로는 차량 번호 인식 모듈을 포함하며, 상기 차량 번호 인식 모듈은 차량 번 호 인식 기능을 제공할 수 있다. 예를 들어, 상기 차량 번호 인식 모듈은 카메라 장치에 의해 획득된 적어도 하나의 차량 번호판을 포함하는 이미지로부터 차량 번호를 인식할 수 있다. 예를 들어, 차량 번호 인식 모듈은 이미지에 포함된 객체들을 인식하고, 인식된 객체들과 미리 저장된 차량 번호판에 대한 이미지를 비교한 것에 기반하여 차량 번호판을 인식할 수 있다. 상기 차량 번호 인식 모듈 객체들을 인식하는 동작 은, ROI(region of interest)를 인식하는 주지의 알고리즘에 기반하여 수행될 수 있다. 차량 번호 인식 모듈 은 인식된 차량 번호판으로부터 차량 번호를 식별할 수 있다. 또 상기 차량 번호 인식 모듈은 차량 위치 식별 기능을 제공할 수 있다. 예를 들어, 상기 차량 번호 인식 모듈은 상기 식별된 차량 번호를 가지는 차량의 위치를 식별할 수 있다. 상기 차량 번호 인식 모듈은 이미지를 촬영한 카메라 장치의 식별 정보에 대응하는 주차 구역 중에서, 상기 이미지 상에서 식별된 차량 번호의 위치에 대응하는 서브 주차 구역을 상기 차량의 위치로서 식별할 수 있다. 여기서, 주차 구역이란 하나 의 카메라 장치가 촬영할 수 있도록 상기 하나의 카메라 장치에 할당된 구역이다. 상기 주차 구역은 하나 또는 복수의 서브 주차 구역들을 포함할 수 있으며, 각각의 서브 주차 구역에는 한 대의 차량이 주차할 수 있도록 주 차선이 그려져 있을 수 있다. 또한 주차선이 그려진 서브 주차 구역 이외에, 통로 및 출입문 앞과 같이 주차선 이 그려지지 않은 구역에도 차량이 불법 주차할 수도 있다. 상기 카메라 장치는 이러한 불법 주차 차량을 촬영 할 수 있도록 상기 통로 및 출입문 앞과 같은 구역에 할당 및 설치될 수도 있다. 따라서 주차된 차량을 촬영하 기 위해 카메라 장치에 할당된 구역이 있을 경우, 그 구역은 주차선이 그려졌는지 여부에 관계 없이 그 구역은 상기 주차 구역의 범주 내에 포함될 수 있다. 상기 제 1 제어 회로는 얼굴 인식 모듈을 포함하며, 상기 얼굴 인식 모듈은 얼굴 인식 기능을 제공할 수 있다. 상기 얼굴 인식 모듈은 관리 장치 및/또는 카메라 장치에 의해 획득된 사용자 의 얼굴을 포함하는 이미지로부터 사용자의 얼굴을 인식할 수 있다. 예를 들어, 차량 번호 인식 모듈은 소 정의 얼굴 인식(face recognition) 알고리즘 및/또는 인공 지능 모델에 기반하여 이미지로부터 사용자의 얼굴을 식별할 수 있다. 차량 번호 인식 모듈은 사용자의 얼굴을 식별하는 동작의 적어도 일부로, 사용자의 얼굴 의 특징 점(또는 랜드마크)에 대한 정보를 식별할 수 있으며, 이에 대해서는 후술한다. 한편 시스템이 하이브리드 타입으로 구현되는 경우, 전술한 차량 번호 인식 모듈의 차량 번호 인식 기능, 차량 위치 식별 기능, 또는 얼굴 인식 모듈의 얼굴 인식 기능 중 적어도 일부는, 엣지 장치(400a, 400b)에 구현될 수 있다. 이에 따라, 이를 구비하는 장치(예: 관리 장치, 카메라 장치) 대신에 엣지 장치 (400a, 400b)에서 동작이 수행될 수도 있다. 상기 제 1 제어 회로는 주차 위치 관리 모듈을 포함하며, 상기 주차 위치 관리 모듈은 관리 서 버에 축적되는 사용자의 얼굴, 사용자의 차량 번호, 및 사용자의 차량의 위치에 대한 정보를 서로 연관된 형태로 등록하여 관리할 수 있다. 예를 들어, 관리 서버는 관리 장치 및/또는 카메라 장치로부 터 수신되는 정보에 기반하여, 특정 사용자의 얼굴, 특정 사용자의 차량의 차량 번호, 및 특정 사용자의 차량의 위치(예: 주차 위치)에 대한 정보를 획득할 수 있다. 관리 서버는 상기 특정 사용자의 얼굴을 소정의 키 (key)로서, 사용자의 얼굴과 상기 차량 번호 및 차량의 위치를 연관된 형태로 메모리에 등록(예: 차량 위 치 등록 동작을 수행)할 수 있다. 이에 따라, 관리 서버는 차량 위치 제공 동작을 수행할 수 있다.상기 메 모리는 각종 정보(예: 사용자의 얼굴, 사용자의 차량의 차량 번호, 사용자의 차량의 위치, 및/또는 카메라 의 식별 정보에 대응하는 주차장(parking lot)의 주차 위치(예: 주차 구역)에 대한 정보)를 저장할 수 있다. 메 모리는 데이터를 임시적으로 또는 반영구적으로 저장할 수 있다. 예를 들어, 관리 서버의 메모리 에는 관리 서버를 구동하기 위한 운용 프로그램(OS: Operating System), 웹 사이트를 호스팅하기 위한 데이터나 프로그램 내지는 어플리케이션(예를 들어, 웹 어플리케이션)에 관한 데이터 등이 저장될 수 있다. 상기 메모리의 예로는 하드 디스크(HDD: Hard Disk Drive), SSD(Solid State Drive), 플래쉬 메모리 (flash memory), 롬(ROM: Read-Only Memory), 램(RAM: Random Access Memory) 등이 있을 수 있다. 이러한 메모 리는 내장 타입 또는 탈부착 가능한 타입으로 제공될 수 있다. 2.1.2 관리 장치의 구성의 일 예 이하에서는 관리 장치의 구성의 일 예에 대해서 설명한다. 도 3a를 참조하면, 일 실시예에 따르면 관리 장치는 제 2 통신 회로, 제 2 제어 회로, 제 2 카 메라 모듈, 및 디스플레이를 포함할 수 있다. 상기 제 2 통신 회로는 외부 장치(예: 관리 서버, 및/또는 카메라 장치)와 통신할 수 있다. 예 를 들면, 제 2 통신 회로는 무선 통신 또는 유선 통신을 통해서 네트워크에 연결되어 외부 장치(예: 관리 서버, 및/또는 카메라 장치)와 통신을 설정하여, 설정된 통신을 통해 정보 및/또는 데이터를 교환할 수 있다. 상기 제 2 제어 회로는 전자 장치의 전반적인 동작을 제어할 수 있다. 이를 위해 제 2 제어 회로 는 각종 정보의 연산 및 처리를 수행하고 전자 장치의 구성 요소들(예: 제 2 통신 회로)의 동작 을 제어할 수 있다. 상기 제 2 카메라 모듈은 촬영을 위한 이미지 센서 회로, 촬영된 이미지 데이터를 처리하기 위한 각종 회 로(예: 이미지 프로세서)를 포함할 수 있다. 상기 이미지 센서 회로는 CCD(charge coupled device), CMOS(complementary metal-oxide semiconductor)의 센서 형태로 구현될 수 있다. 상기 디스플레이는 액정 디스플레이(LCD), 발광 다이오드(LED) 디스플레이, 유기 발광 다이오드(OLED) 디 스플레이, 또는 마이크로 전자기계 시스템 (MEMS) 디스플레이, 또는 전자종이(electronic paper) 디스플레이를 포함할 수 있다. 상기 디스플레이는, 관리 서버로부테 제공되는 인터페이스를 표시할 수 있다. 상기 디스플레이는 입력 장치를 포함할 수 있다. 상기 입력 장치는 사용자(예: 제작자 또는 소비자)로부터 정보 를 입력 받을 수 있다(예: 인터페이스 상에서 사용자 입력(예: 핸드 라이팅, 드로잉, 다양한 종류의 터치, 텍스 트 타이핑 등)을 수신). 상기 입력 장치는 사용자 입력을 받거나 또는 사용자에게 정보를 출력하는 각종 인터페 이스나 연결 포트 등일 수 있다. 사용자 입력은 키 입력, 터치 입력, 음성 입력을 비롯한 다양한 형태로 이루어 질 수 있다. 이러한 사용자 입력을 받을 수 있는 입력 모듈의 예로는 전통적인 형태의 키패드나 키보드, 마우스 는 물론, 사용자의 터치를 감지하는 터치 센서, 음성 신호를 입력받는 마이크, 영상 인식을 통해 제스처 등을 인식하는 카메라, 사용자 접근을 감지하는 조도 센서나 적외선 센서 등으로 구성되는 근접 센서, 가속도 센서나 자이로 센서 등을 통해 사용자 동작을 인식하는 모션 센서 및 그 외의 다양한 형태의 사용자 입력을 감지하거나 입력받는 다양한 형태의 입력 수단을 포함할 수 있다. 여기서, 터치 센서는 디스플레이 패널에 부착되는 터치 패널이나 터치 필름을 통해 터치를 감지하는 압전식 또는 정전식 터치 센서, 광학적인 방식에 의해 터치를 감지 하는 광학식 터치 센서 등으로 구현될 수 있다. 다시 말해, 디스플레이는, 상기 입력 장치로서 터치 스크린을 포함할 수 있으며, 예를 들면, 전자 펜 또는 사용자의 신체의 일부를 이용한 터치, 제스쳐, 근접, 또는 호버링 입력을 수신할 수 있다. 이외에도 상기 입력 장치는 자체적으로 사용자 입력을 감지하는 장치 대신 사용자 입력을 입력받는 외부의 입력 장치를 연결시키는 입력 인터페이스(USB 포트, PS/2 포트 등)의 형태로 구현될 수도 있다. 2.1.3 카메라 장치의 구성의 일 예 이하에서는 관리 장치의 구성의 일 예에 대해서 설명한다. 도 3a을 참조하면, 일 실시예에 따르면 카메라 장치는 제 3 통신 회로, 제 3 제어 회로, 및 제 3 카메라 모듈을 포함할 수 있다. 상기 제1 통신 회로, 제2 통신 회로, 및 제3 통신 회로는 무선 통신 또는 유선 통신을 통해서 네트워크에 연결되어 외부 장치와 통신을 설정하여, 설정된 통신을 통해 정보 및/또는 데이터를 교환할 수 있다. 상기 무선 통신은, 예를 들면, LTE, LTE-A(LTE Advance), CDMA(code division multiple access),WCDMA(wideband CDMA), UMTS(universal mobile telecommunications system), WiBro(Wireless Broadband), 또 는 GSM(Global System for Mobile Communications) 등 중 적어도 하나를 사용하는 셀룰러 통신을 포함할 수 있 다. 한 실시예에 따르면, 무선 통신은, 예를 들면, WiFi(wireless fidelity), 블루투스, 블루투스 저전력 (BLE), 지그비(Zigbee), NFC(near field communication), 자력 시큐어 트랜스미션(Magnetic Secure Transmission), 라디오 프리퀀시(RF), 또는 보디 에어리어 네트워크(BAN) 중 적어도 하나를 포함할 수 있다. 한 실시예에 따르면, 무선 통신은 GNSS를 포함할 수 있다. GNSS는, 예를 들면, GPS(Global Positioning System), Glonass(Global Navigation Satellite System), Beidou Navigation Satellite System(이하 \"Beidou\") 또는 Galileo, the European global satellite-based navigation system일 수 있다. 이하, 본 문서에서는, \"GPS\"는 \"GNSS\"와 상호 호환적으로 사용될 수 있다. 유선 통신은, 예를 들면, USB(universal serial bus), HDMI(high definition multimedia interface), RS-232(recommended standard232), 전력선 통신, 또는 POTS(plain old telephone service) 등 중 적어도 하나를 포함할 수 있다. 네트워크는 텔레커뮤니케이션 네트워크, 예를 들면, 컴퓨터 네트워크(예: LAN 또는 WAN), 인터넷, 또는 텔레폰 네트워크 중 적어도 하나를 포함할 수 있다. 상기 제 1 제어 회로, 제2 제어 회로, 제3 제어 회로는 하드웨어, 소프트웨어, 또는 이들의 조 합에 따라 컴퓨터나 이와 유사한 장치로 구현될 수 있다. 하드웨어적으로 상기 제 1 제어 회로, 제2 제어 회로, 제3 제어 회로는 전기적인 신호를 처리하여 제어 기능을 수행하는 전자 회로 형태(예: AP(application processor), CPU(central processing unit), GPU(graphic processing unit), DPU(display processing unit), 또는 NPU(neural processing unit) 중 적어도 하나)로 제공될 수 있으며, 소프트웨어적으로 는 하드웨어적인 상기 제 1 제어 회로, 제2 제어 회로, 제3 제어 회로를 구동시키는 프로그램 형태로 제공될 수 있다. 또한 상기 제 1 제어 회로, 제2 제어 회로, 제3 제어 회로 내에 포함되 는 각 모듈은 프로그램, 컴퓨터 판독 가능한 코드, 프로세스 또는 인스트럭션(instructions)들로 구현될 수 있 다. 상기 모듈이 상기 제 1 제어 회로, 제2 제어 회로, 제3 제어 회로에 의해 실행되는 경우, 상기 제 1 제어 회로, 제2 제어 회로, 제3 제어 회로가 상기 모듈과 연관된 동작을 수행하도록 제어할 수 있다. 상기 제 2 카메라 모듈, 및 상기 제 3 카메라 모듈은 촬영을 위한 이미지 센서 회로, 촬영된 이미지 데이터를 처리하기 위한 각종 회로(예: 이미지 프로세서)를 포함할 수 있다. 상기 이미지 센서 회로는 CCD(charge coupled device), CMOS(complementary metal-oxide semiconductor)의 센서 형태로 구현될 수 있다. 2.2 하이브리드 타입으로 구현되는 시스템의 구성의 예 이하에서는 도 3b를 참조하여, 하이브리드 타입으로 구현되는 시스템의 구성의 예에 대해서 설명한다. \"2.1 목 차\"에서 전술한 바와 중복되는 설명은 생략한다. 도 3b를 참조하면 도 3a의 시스템과 비교하여, 일 실시예에 따르면 시스템의 관리 서버의 제 1 제어 회로 는 주차 위치 관리 모듈을 포함하되, 얼굴 인식 모듈은 포함하지 않을 수 있다. 카메라 장치 에 구비되는 제 1 엣지 장치(400a)는 제 4 제어 회로 및 인터페이스를 포함할 수 있다. 제4 제 어 회로는 차량 번호 인식 모듈을 포함할수 있다. 관리 장치에 구비되는 제 2 엣지 장치(400b) 는 제 5 제어 회로, 및 인터페이스를 포함할 수 있다. 제5 제어 회로은 얼굴 인식 모듈을 포함할 수 있다. 한편 기재 및/또는 도시된 바에 제한되지 않고, 특정 엣지 장치(예: 제 2 엣지 장치(400b))에 상기 차량 번호 인식 모듈 및 얼굴 인식 모듈이 구현되어, 특정 엣지 장치(예: 제 2 엣지 장치 (400b))를 구비하는 장치(예: 관리 장치)에서 차량 번호 인식 기능과 얼굴 인식 기능 모두가 제공될 수도 있다. 또 한편 도시되지 않았으나, 상기 차량 번호 인식 모듈을 포함하는 엣지 장치(예: 제 1 엣지 장치 (400a))에는 카메라에 대응하는 주차 구역에 대한 정보와 이미지 상의 차량 번호의 위치 별 서브 주차 구역에 대한 정보가 미리 저장된 데이터 베이스가 구현되어 있을 수 있다.상기 인터페이스는 다른 장치(예: 관리 장치, 카메라 장치)와 통신 연결하도록 구현될 수 있다. 예를 들어, 상기 인터페이스는 USB 포 트와 같은 유선 인터페이스를 포함할 수 있으나, 기재된 바에 제한되지 않고 블루투스 모듈, 지그비(ZigBee) 모 듈, Wi-Fi 모듈과 같은 무선 인터페이스를 포함할 수 있다. 상기 제 4 제어 회로 및 제 5 제어 회로는 각각 엣지 장치(400a, 400b)의 전반적인 동작을 제어할 수 있다. 상기 제 4 제어 회로는 상기 인터페이스를 통해서 카메라 장치에 의해 촬영된 이미지를 획득하고, 상기 차량 번호 인식 모듈을 이용하여 획득된 이미지로부터 차량 번호 및 주차 위치에 대한 정 보를 획득할 수 있다. 상기 제 5 제어 회로는 상기 인터페이스를 통해서 관리 장치에 의해 촬영된 이미지를 획득하고, 상기 얼굴 인식 모듈을 이용하여 획득된 이미지로부터 사용자의 얼굴에 대한 정보 (예: 픽셀 값, 및/또는 특징점 별 값)을 획득할 수 있다. 2.2 스마트 얼굴 인식 시스템 의 구현 예 스마트 얼굴 인식 시스템은 상술한 바와 같이 서버 타입 또는 온 디바이스 타입으로 구현될 수 있다. 일 실시예에 따르면 상술한 바와 같이 차량 번호 인식 기능, 사용자의 얼굴 인식 기능, 차량 위치 등록 기능 및 차량 위치 제공 기능이 관리 서버에서 수행되며 상기 동작들에 따른 시각화된 정보가 관리 장치로 제 공되도록 구현되는 경우, 스마트 얼굴 인식 시스템은 서버 타입으로 정의될 수 있다. 또 일 실시예에 따르면, 상술한 구성들이 하나의 로컬 장치에 구현되는 경우, 스마트 얼굴 인식 시스템은 온 디 바이스(On-device) 타입으로 정의될 수 있다. 예를 들어, 관리 서버의 구성들이 관리 장치에 구현 되 는 경우, 스마트 얼굴 인식 시스템은 온 디바이스(On-device)타입으로 정의될 수 있다. 이 경우, 관리 장치 가 차량 번호 인식 기능, 사용자의 얼굴 인식 기능, 차량 위치 등록 기능 및 차량 위치 제공 기능을 모두 수행할 수 있다. 또 기재된 바에 국한되지 않고, 스마트 얼굴 인식 시스템은 바와 같이 서버 타입과 온 디바이스 타입이 조합되 는 하이브리드 타입으로 구현될 수 있다. 예를 들어, 관리 서버의 적어도 하나의 구성(예: 사용자 얼굴 인 식을 위한 얼굴 인식 모듈)이 엣지 장치에 구현되되 다른 구성(예: 다른 모듈들과 데이터 베이스 )은 관리 서버에 구현되는 형태는, 하이브리드 타입으로 정의될 수 있다. 이하에서는 스마트 얼굴 인식 시스템이 서버 타입으로 구현된 것을 예로 들어 기술하나, 기재된 바에 제한되지 않고 당업자에 의해 온-디바이스 타입 및/또는 하이브리드 타입으로 이해될 수 있다. 즉, 이하에서 설명의 편의 를 위하여 시스템이 서버 타입으로 구현된 경우를 예로 들어 다양한 실시예들이 기술될 수 있으나, 이하에서 기 술되는 동작들은 하이브리드 타입의 시스템의 엣지 장치에 의해 수행될 수도 있다. 3. 스마트 얼굴 인식 시스템의 동작 이하에서는 스마트 얼굴 인식 시스템을 구성하는 장치들(예: 관리 서버, 관리 장치, 및 카메라 장치 )의 동작의 다양한 예들에 대해서 설명한다. 3.1. 제 1 실시예 <얼굴 인식에 기반한 사용자의 얼굴을 키(key)로서 차량의 위치를 등록하고, 차량의 위치를 제공 하는 동작> 일 실시예에 따르면, 관리 서버는 얼굴 인식 알고리즘에 기반하여 주차장에 주차된 차량의 사용자의 얼굴 을 식별하고, 식별된 사용자의 얼굴을, 소정의 키(key)로서, 사용자의 차량의 번호 및/또는 사용자의 차량의 위 치(예: 주차 위치)와 연관된 형태로 등록(예: 차량 위치 등록 동작)할 수 있다. 이후 관리 서버는 특정 사 용자의 얼굴이 식별되는 경우, 등록된 정보 중에서 식별된 사용자의 얼굴에 대응하는 차량의 번호 및/또는 사용 자의 차량의 위치에 대한 정보를 제공(예: 차량 위치 제공 동작)할 수 있다. 도 4a는 본 출원의 일 실시예에 따른 스마트 얼굴 인식 시스템의 동작의 일 예를 설명하기 위한 흐름도이다. 도 4b 및 도 4c는 본 출원의 일 실시예에 따른 스마트 얼굴 인식 시스템의 동작의 다른 예를 설명하기 위한 흐름도 이다. 다양한 실시예들에 따르면 스마트 얼굴 인식 시스템의 동작은 도 4a, 도 4b, 및 도 4c에 도시되는 동작의 순서에 국한되지 않고, 도시되는 순서와 다른 순서로 수행될 수 있다. 또한, 다양한 실시예들에 따르면, 도 4a, 도 4b, 및 도 4c에 도시되는 스마트 얼굴 인식 시스템의 동작들뿐만 아니라 추가적인 동작들이 수행되거나, 또 는 상기 동작들 중 일부를 제외한 적어도 하나의 동작이 수행될 수도 있다. 이하에서는 도 5 내지 6을 참조하여 도 4a 및 도 4b에 대해서 설명한다. 도 5a는 본 출원의 일 실시예에 따른 카메라 장치가 주차장(parking lot)에 주차된 차량의 차량 번호판을 포함하는 이미지를 촬영하는 동작의 예를 설명하기 위한 도면이다. 도 5b는 본 출원의 일 실시예에 따른 관리 서버의 차량 위치 등록 동작 및 차량 위치 제공 동작의 예를 설명하기 위한 도면이다. 도 6은 본 출원의일 실시예에 따른 관리 장치의 다른 구현 예를 설명하기 위한 도면이다. 일 실시예에 따르면, 카메라 장치(300a)는 401 동작에서 차량 번호판을 포함하는 제 1 이미지를 촬영하고, 402 동작에서 관리 장치로 제 1 이미지 및 카메라 장치의 식별 정보를 송신할 수 있다. 또는 기재된 바에 제한되지 않고, 카메라 장치는 관리 장치를 경유하지 않고, 관리 서버로 제 1 이미지 및 카메라 장치의 식별 정보를 직접 송신할 수 있다. 예를 들어 도 5a를 참조하면 복수의 카메라 장치들(300a, 300b, 300c)은 주차 구역(P1, P2, P3)에 주차되는 차량에 대한 이미지를 촬영하도록 주차장의 천장의 시설물(L)(예: 배관, 랙)에 배치될 수 있다. 즉 카메라 장치(300a, 300b, 300c) 별로 서로 다른 주차 구역(P1, P2, P3)에 할 당될 수 있다. 예를 들어, 복수의 카메라 장치들(300a, 300b, 300c)은 주차장의 천장의 시설물(L)(예: 배관, 랙)에 지정된 간격으로 일렬로 배치될 수 있으나, 기재 및/또는 도시된 바에 제한되지 않고 전술한 바와 같이 카스토퍼(car stopper)와 같은 주차장(parking lot) 내의 다양한 위치 및/또는 시설에 구비될 수 있다. 특정 카 메라 장치(300a)는 주차 구역(P1) 내에 차량이 진입되고, 특정 조건이 만족되는 경우 차량에 대한 이미지(예: 제 1 이미지)를 촬영할 수 있다. 예를 들어, 상기 특정 조건은 상기 차량이 특정 구역(P1) 내에 진입된 이후 소 정의 시간이 경과되는 것을 포함할 수 있다. 다른 예로서, 상기 특정 조건은 상기 차량이 특정 구역(P1) 내에 진입된 것으로 확인되는 것을 포함할 수 있으며, 이 경우 상기 차량이 특정 구역(P1) 내로 진입하였음이 확인되 면 즉시 그 차량에 대한 이미지(예: 제1 이미지)를 촬영할 수도 있다. 특정 카메라 장치(300a)는 촬영된 이미지 (예: 제 1 이미지)와 함께 카메라 장치(300a)의 식별 정보를 관리 장치로 전송할 수 있다. 후술하겠으나, 관리 서버는 카메라 장치(300a)의 식별 정보에 기반하여 차량이 주차된 주차 구역(P1)을 식별할 수 있다. 일 실시예에 따르면, 카메라 장치(300a)는 촬영된 이미지 내의 오브젝트를 분석한 것에 기반하여, 주차 구역(예: P1) 내로 차량의 진입 여부를 확인할 수 있다. 예를 들어, 특정 카메라 장치(300a)는 이미지 내의 특 정 주차 구역(P1)을 나타내는 외곽선을 인식하고, 인식된 외곽선에 의해 둘러 쌓인(또는 정의되는) 영역 내에 위치되는 오브젝트의 형상을 인식할 수 있다. 특정 카메라 장치(300a)는 상기 인식된 오브젝트의 형상과 카메 라 장치(300a)에 기-저장된 차량의 종류 별 오브젝트의 형상과 비교한 것에 기반하여 서로 대응하는 경우, 상기 특정 주차 구역(P1) 내로 차량이 진입된 것으로 확인할 수 있다. 카메라 장치는 특정 주차 구역(P1) 내로 차량이 진입된 것으로 확인된 경우 전술한 바와 같이, 그 차량에 대한 이미지(예: 제 1 이미지)를 획득할 수 있 다. 일 실시예에 따르면 도 5a에 도시된 바와 같이, 관리 장치는 403 동작에서 카메라 장치로부터 수신 (또는, 주차장의 중계기(A)를 통해 수신)된 제 1 이미지 및 카메라 장치의 식별 정보를 관리 서버로 송신할 수 있다. 또는 기재된 바에 제한되지 않고 전술한 바와 같이, 카메라 장치로부터 관리 장치를 경유하지 않고, 관리 서버로 제 1 이미지 및 카메라 장치의 식별 정보가 직접 송신될 수 있다. 일 실시예에 따르면, 관리 서버는 404 동작에서 제 1 이미지에 기반하여 차량 번호를 식별하고, 제 1 이미 지 및/또는 카메라 장치 식별 정보에 기반하여 차량의 주차 위치를 식별할 수 있다. 예를 들어, 관리 서버 는 카메라의 식별 정보 별 차량의 주차 구역에 대한 정보에 기반하여, 차량의 주차 구역들 중 상기 카메라 장치의 식별 정보에 대응하는 차량의 주차 구역(예: P1)을 식별할 수 있다. 이후, 관리 서버 는 제 1 이미지를 분석한 것에 기반하여 식별된 차량 번호의 위치에 기반하여 차량의 식별된 주차 구역(예: P1) 내에서의 정확한 위치(예: 서브 주차 구역(예: SP1, SP2))를 식별할 수 있다. 상기 차량 번호 식별 동작은, 차 량 번호 인식 모듈에 의해 수행될 수 있으므로, 중복되는 설명은 생략한다. 관리 서버는 카메라 장치 들(300a, 300b, 300c)의 식별 정보 별로 카메라 장치들(300a, 300b, 300c)이 할당된 주차 구역(P1, P2, P3)에 대한 구역 정보를 미리 저장할 수 있다. 관리 서버는 상기 구역 정보에 기반하여 수신된 카메라 장치(30 0)의 식별 정보에 대응하는 주차 구역(예: P1)을 식별할 수 있다. 이때 도 5a의 주차장(parking lot)의 탑 뷰 (Top view)를 참조하면, 상기 주차 구역(P1)은 복수의 서브 주차 구역들(예: SP1, SP2)을 포함할 수 있다. 상기 서브 주차 구역들(예: SP1, SP2)은 카메라 장치에 의해 촬영된 이미지 내의 특정 영역들에 대응할 수 있다. 관리 서버는 이미지 내에서 식별된 차량 번호가 위치되는 특정 영역을 식별하고, 식별된 특정 영역 에 대응하는 서브 주차 구역(SP1)을 식별할 수 있다. 결과적으로, 관리 서버는 특정 차량 번호를 가지는 차량이 특정 서브 주차 구역(SP1)에 위치됨을 나타내는 차량의 위치 정보를 획득할 수 있다. 한편, 상기 차량 번호를 식별하고 주차 위치를 식별하는 동작은 카메라 장치에 연결되는 제 1 엣지 장치 (400a)에서 수행될 수도 있다. 예를 들어 도 4b를 참조하면, 카메라 장치는 416a 동작에서 차량 번호판을 포함하는 제 1 이미지를 제 1 엣지 장치(400a)로 전달할 수 있다. 제 1 엣지 장치(400a)는 416b 동작에서 제 1 이미지를 획득하고, 제 1 이미지에 기반하여 차량 번호를 식별하고, 제 1 이미지 및/또는 카메라 장치의 식별 정보에 기반하여 차량의 주차 위치를 식별하고, 416c 동작에서 차량 번호 및 주차 위치를 카메라 장치로 전송할 수 있다. 카메라 장치는 416d 동작에서 차량 번호 및 주차 위치 정보를 관리 서버로 전송할 수 있다.일 실시예에 따르면, 관리 장치는 405 동작에서 차량 위치 등록 요청을 획득하고, 406 동 작에서 차량 번호를 획득하고, 사용자 얼굴을 포함하는 제 2 이미지를 촬영하고, 407 동작에서 제 2 이미지 및 차량 번호를 관리 서버로 송신할 수 있다. 예를 들어 사용자(U)는 차량을 주차한 이후에, 관리 장치 로 다가가 차량 위치를 등록하기 위한 입력을 가할 수 있다. 일 예로 도 5b에 도시된 바와 같이, 관리 장치 는 차량 위치 등록을 유발하기 위한 아이콘을 포함하는 화면을 표시하고, 사용자(U)로부터 상기 아이콘이 선택되는 경우 차량 번호(예: xx가 xxxx)를 입력 받을 수 있다. 이때 관리 장치는 상기 사용자(U)에 의해 상기 아이콘이 선택되기 전 또는 화면을 표시하기 전에 카메라 모듈을 이용하여 사용자(U)를 촬영하고, 촬 영된 사용자(U)의 얼굴을 포함하는 이미지를 관리 서버로 전송하고, 관리 서버에 등록되었는지 여부 를 판단할 수 있다. 관리 서버는 상기 사용자(U)의 얼굴이 등록되지 않은 경우, 이를 관리 장치로 알 릴 수 있다. 관리 장치는 상기 사용자(U)의 얼굴이 등록되지 않은 것으로 식별된 경우, 차량 번호(예: xx 가 xxxx)를 입력 받기 위한 화면을 표시할 수 있다. 한편 후술하겠으나, 관리 장치는 상기 사용자(U)의 얼 굴이 등록된 것으로 식별된 경우, 차량 위치 정보를 제공할 수 있다. 일 실시예에 따르면, 관리 장치 주변에 조명 장치(미도시)가 구비되고, 사용자가 접근하는 경우 상기 조명 장치(미도시)가 상기 조명 장치 내에 구비된 센서(예, 적외선 센서)를 이용하여 사용자의 접근을 식별하고 관리 장치의 카메라 모듈을 턴-온할 수 있다. 예를 들어, 조명 장치(미도시)는 근접 센서를 포함할 수 있다. 사 용자가 상기 관리 장치에 접근하는 경우, 조명 장치(미도시)는 근접 센서를 이용하여 사용자의 근접을 식 별한 것에 기반하여 상기 관리 장치로 사용자의 근접을 알리기 위한 신호를 전달할 수 있다. 관리 장치 는 상기 획득된 신호에 기반하여 카메라 모듈을 턴-온할 수 있따. 이에 따라, 관리 장치는 턴-온된 카메라 모듈을 이용하여 사용자의 얼굴을 촬영할 수 있다. 일 실시예에 따르면, 관리 장치는 차량 번호(예: xx가 xxxx)가 성공적으로 입력되는 경우, 카메라 모듈 을 이용하여 사용자(U)의 얼굴을 촬영하고 사용자(U)의 얼굴을 포함하는 이미지(500a)(예: 제 2 이미지)를 획득할 수 있다. 이때, 관리 장치는 상기 카메라 장치에 의해 촬영된 이미지(예: 제 1 이미지)로부터 식별된 차량 번호들 중, 사용자(U)에 의해 입력된 차량 번호(예: xx가 xxxx)가 존재하는 경우 상기 차량 번호 (예: xx가 xxxx)가 성공적으로 입력된 것으로 판단하고 사용자(U)의 얼굴을 촬영할 수 있다. 관리 장치는 상기 카메라 장치에 의해 촬영된 이미지(예: 제 1 이미지)로부터 식별된 차량 번호들 중, 사용자(U)에 의 해 입력된 차량 번호(예: xx가 xxxx)가 존재하지 않는 경우 다시 차량 번호를 재입력할 것을 요구하기 위한 화 면을 표시할 수 있다. 한편 기재된 순서에 제한되지 않고, 관리 장치가 차량 번호를 획득하는 동작이 사용 자(U)의 얼굴을 포함하는 이미지(예: 제 2 이미지)를 획득하는 동작보다 나중에 수행될 수도 있다. 일 실시예에 따르면, 관리 장치는 사용자(U)의 얼굴을 정확하게 촬영하기 위한 가이드 화면을 표시할 수 있다. 일 실시예에 따르면, 관리 장치는 사용자(U)의 제스쳐(gesture)(예: 손 동작) 또는 특정 음성(예: 소리지 르는 동작, 또는 특정 키워드(예: 경비실)를 포함하는 음성)을 획득한 것에 기반하여, 관리실 및/또는 경비실에 설치된 전자장치와 연결하여 관리자 및/또는 경비원과 통신하도록 할 수 있다. 일 실시예에 따르면, 관리 장치는 키오스크가 뿐만 아니라 현관문에 설치되는 형태로도 구현될 수 있다. 예를 들어 도 6에 도시된 바와 같이 상기 관리 장치는 현관문의 초인종 장치 형태로 구비되며, 사용자(U) 에 의해 초인종 장치의 초인종이 눌리는 경우 구비된 카메라 모듈을 이용하여 사용자(U)의 얼굴(500a)을 촬영할 수 있다. 일 실시예에서, 관리 서버는 현관문에 설치된 관리 장치로부터 수신되는 이미지에 기반하여, 관리 서버에 등록된 사용자의 얼굴 이외의 다른 사람의 얼굴을 등록할 수 있다. 예를 들어, 관 리 장치는 현관문 앞에 서있는 복수의 사용자들의 얼굴을 포함하는 이미지를 촬영하고, 촬영된 이미지를 관리 서버로 전송할 수 있다. 관리 서버는 기-등록된 정보에 기반하여 복수의 사용자의 얼굴들 중에 서 저장된 차량 번호가 등록된 사용자 얼굴이 존재하는 경우, 복수의 사용자의 얼굴들 중 나머지 사용자의 얼굴 을 방문객의 얼굴로서 등록할 수 있다. 이에 따라 키오스크인 관리 장치에서 등록된 사용자의 얼굴 뿐만 아니라, 관리 서버에 의해 사용자와 함께 방문한 다른 방문자들에 대한 정보(예: 얼굴)가 함께 관리될 수 있다. 또 일 실시예에서, 관리 서버는 현관문에 설치된 관리 장치로부터 수신되는 이미지에 기반하여, 관리 서버에 등록된 사용자의 방문 정보를 함께 등록할 수 있다. 예를 들어, 관리 서버는 기-저장된 관리 장치의 식별 정보 별 방문 위치(예: 아파트인 경우 동 및 호수) 정보에 기반하여, 관리 장 치의 식별 정보에 대응하는 방문 위치를 식별할 수 있다. 전술한 바와 같이, 관리 서버는 기-등록된 정보에 기반하여 복수의 사용자의 얼굴들 중에서 저장된 차량 번호가 등록된 사용자 얼굴이 존재하는 경우, 상기 식별된 방문 위치 또한 기-등록된 정보와 함께 등록할 수 있다. 일 실시예에 따르면, 관리 서버는 408 동작에서 제 2 이미지에 기반하여 사용자 얼굴을 식별하고, 409 동 작에서 차량 번호, 주차 위치, 및 사용자 얼굴을 서로 연관되도록 저장할 수 있다. 예를 들어 도 5b를 참조하면, 관리 서버는 제 2 이미지로부터 얼굴을 인식하기 위한 동작을 수행하고, 사용자(U)의 얼굴에 대 한 정보(예: 이미지의 사용자의 얼굴을 나타내는 영역의 픽셀 값)와 함께 수신된 차량 번호와 상기 차량 번호에 대응하는 차량의 위치에 대한 정보(예: 서브 주차 구역)를 서로 연관된 형태로 저장할 수 있다. 상기 관리 서버 의 얼굴을 인식하기 위한 동작은, 얼굴 인식 모듈에 의해 수행될 수 있으므로 구체적인 설명은 생략 한다. 한편 도 4b를 참조하면, 얼굴 인식 기능을 제공하도록 구현된 엣지 장치가 관리 장치에 구비되는 경 우, 도 4a의 407 동작 내지 408 동작 대신에 관리 장치와 엣지 장치에서 얼굴 인식 기능이 제공될 수 있다. 예를 들어, 관리 장치는 417a 동작에서 제 2 이미지를 엣지 장치로 전달할 수 있다. 엣지 장치 는 417a 동작에서 제 2 이미지를 획득하고, 417b 동작에서 제 2 이미지로부터 사용자 얼굴에 대한 제 1 정 보(예: 픽셀 값, 또는 후술되는 특징점 별 값)를 획득하고, 417c 동작에서 사용자 얼굴에 대한 제 1 정보를 관 리 장치로 전달할 수 있다. 이에 따라, 관리 장치는 417d 동작에서 관리 서버로 사용자 얼굴에 대한 제 1 정보와 차량 번호를 관리 서버로 전송하고, 관리 서버는 409 동작에서 차량 번호, 주차 위 치, 및 사용자 얼굴에 대한 제 1 정보를 연관되도록 저장할 수 있다. 이 경우, 관리 장치는 엣지 장치 로부터 사용자 얼굴에 대한 제 1 정보를 획득하는 경우, 사용자 얼굴을 포함하는 제 2 이미지를 삭제함으 로써 사용자의 개인 정보에 대한 보호를 보장할 수 있다. 일 실시예에 따르면, 관리 장치는 410 동작에서 차량 위치 제공 요청을 획득하고, 411 동작에서 사용자 얼 굴을 포함하는 제 3 이미지를 촬영하고, 412 동작에서 제 3 이미지를 관리 서버로 송신할 수 있다. 예를 들어 도 5a에 도시된 바와 같이, 관리 장치는 사용자(U)가 접근하는 경우, 자동으로 카메라 모듈을 이용하 여 사용자(U)의 얼굴을 포함하는 이미지(500b)(예: 제 3 이미지)를 촬영하고, 이미지(500b)(예: 제 3 이미지)를 관리 서버로 송신할 수 있다. 일 실시예에 따르면, 관리 서버는 413 동작에서 제 3 이미지에 기반하여 사용자 얼굴을 식별하고, 미리 저 장된 정보로부터, 식별된 사용자 얼굴에 대응하는 차량 번호 및/또는 주차 위치를 식별하고, 414 동작에서 차량 번호 및/또는 주차 위치에 대한 정보를 관리 장치로 송신할 수 있다. 예를 들어 도 5b에 도시된 바와 같이, 관리 서버는 미리 저장된 정보 중에서 상기 이미지(500b)(예: 제 3 이미지)에 포함된 얼굴에 대응하는, 차량 번호(예: xx가 xxxx) 및/또는 주차 위치(예: 서브 주차 구역인 A spot-A1)를 식별하고 식별된 차량 번호(예: xx가 xxxx) 및/또는 주차 위치(예: 서브 주차 구역인 A spot-A1)를 관리 장치로 전송할 수 있다. 한편 도 4c를 참조하면, 얼굴 인식 기능을 제공하도록 구현된 엣지 장치가 관리 장치에 구비되는 경 우, 도 4a의 412 동작 내지 413 동작의 일부 대신에 관리 장치와 엣지 장치에서 얼굴 인식 기능이 제 공될 수 있다. 예를 들어, 관리 장치는 418a 동작에서 제 3 이미지를 엣지 장치로 전달할 수 있다. 엣지 장치는 418a 동작에서 제 3 이미지를 획득하고, 418b 동작에서 제 3 이미지로부터 사용자 얼굴에 대 한 제 1 정보(예: 픽셀 값, 또는 후술되는 특징점 별 값)를 획득하고, 418c 동작에서 사용자 얼굴에 대한 제 2 정보를 관리 장치로 전달할 수 있다. 이에 따라, 관리 장치는 418d 동작에서 관리 서버로 사용 자 얼굴에 대한 제 2 정보를 관리 서버로 전송하고, 관리 서버는 413 동작에서 미리 저장된 정보로부 터 관리 장치로부터 수신된 제 2 정보에 대응하는 차량 번호 및/또는 주차 위치를 식별할 수 있다. 이 경 우 마찬가지로, 관리 장치는 엣지 장치로부터 사용자 얼굴에 대한 제 2 정보를 획득하는 경우, 사용 자 얼굴을 포함하는 제 2 이미지를 삭제함으로써 사용자의 개인정보에 대한 보호를 보장할 수 있다. 일 실시예에 따르면, 관리 장치는 415 동작에서 차량 번호 및/또는 주차 위치에 대한 정보를 표시할 수 있 다. 예를 들어, 관리 장치는 관리 서버로부터 수신된 차량 번호(예: xx가 xxxx) 및/또는 주차 위치 (예: 서브 주차 구역인 A spot-A1)를 디스플레이 상에 표시할 수 있다. 이때, 관리 장치는 주차장 맵 상의 상기 주차 위치(예: 서브 주차 구역인 A spot-A1)에 대응하는 위치에 차량의 위치를 나타내기 위한 오브젝트를 표시하고, 상기 오브젝트와 함께 차량 번호(예: xx가 xxxx)를 표시할 수 있다. 3.2 제 2 실시예 <주차장에서 주차된 차량에서 사용자가 하차하는 경우, 자동으로 사용자를 촬영하여 얼굴을 인 식하는 동작> 전술한 스마트 얼굴 인식 시스템의 동작들은 제 2 실시예에 준용될 수 있으므로, 중복되는 설명은 생략한다. 일 실시예에 따르면, 스마트 얼굴 인식 시스템은 주차장(parking lot)에 차량의 주차가 완료된 이후에, 사용자 가 하차하는 경우 특정 차량 번호를 갖는 차량의 사용자의 얼굴을 촬영할 수 있다. 도 7은 본 출원의 일 실시예에 따른 스마트 얼굴 인식 시스템의 동작의 다른 예를 설명하기 위한 흐름도이다. 다양한 실시예들에 따르면 스마트 얼굴 인식 시스템의 동작은 도 7에 도시되는 동작의 순서에 국한되지 않고, 도시되는 순서와 다른 순서로 수행될 수 있다. 또한, 다양한 실시예들에 따르면, 도 7에 도시되는 스마트 얼굴 인식 시스템의 동작들 이외에 추가적인 동작들이 수행되거나, 또는 상기 동작들 중 일부를 제외한 적어도 하나 의 동작이 수행될 수도 있다. 이하에서는 도 8을 참조하여 도 7에 대해서 설명한다. 도 8은 본 출원의 일 실시예에 따른 차량에서 하차한 사용자의 얼굴을 촬영하는 동작의 예를 설명하기 위한 도 면이다. 일 실시예에 따르면, 카메라 장치는 701 동작에서 차량 번호판을 포함하는 제 1 이미지를 촬영하고, 702 동작에서 관리 서버로 제 1 이미지 및 카메라 장치의 식별 정보를 송신할 수 있다. 카메라 장치의 401 동작 내지 402 동작에서 전술한 바와 같이, 카메라 장치는 관리 장치를 경유하거나, 또는 관리 장치를 경유하지 않고 직접 관리 서버로 제 1 이미지 및 카메라 장치의 식별 정보를 송신할 수 있다. 상기 카메라 장치의 701 동작 내지 702 동작은 전술한 카메라 장치의 401 동작 내지 402 동작과 같이 구현될 수 있으므로 중복되는 설명은 생략한다. 일 실시예에 따르면, 관리 서버는 703 동작에서 제 1 이미지에 기반하여 차량 번호를 식별하고, 제 1 이미 지 및/또는 식별 정보에 기반하여 차량의 주차 위치를 식별할 수 있다. 예를 들어 관리 서버는 카메라 장 치의 식별 정보에 대응하는 주차 구역 중에서, 상기 제 1 이미지에 기반하여 식별된 차량 번호를 갖는 차 량의 위치에 기반하여 차량이 주차된 특정 서브 주차 구역을 식별할 수 있다. 상기 관리 서버의 703 동작 은 전술한 카메라 장치의 404 동작과 같이 구현될 수 있으므로 중복되는 설명은 생략한다. 일 실시예에 따르면, 카메라 장치는 704 동작에서 차량으로부터 나온 사용자가 식별되는 경우 사용자의 얼 굴을 포함하는 제 2 이미지를 촬영하고, 706 동작에서 제 2 이미지를 관리 서버로 송신할 수 있다. 예를 들어 도 8에 도시된 바와 같이, 카메라 장치는 조명 장치로부터 인터럽트(또는 신호)를 수신하는 경 우, 상기 인터럽트(또는 신호)에 기반하여 구동을 수행하여 사용자의 얼굴을 포함하는 이미지(예: 제 2 이미 지)를 촬영할 수 있다. 차량으로부터 사용자(U)가 하차하는 경우, 조명 장치는 근접 센서를 이용하여 차량 으로부터 하차된 사용자(U)의 근접을 검출하고 상기 검출에 기반하여 턴-온될 수 있다. 턴-온된 조명 장치(80 0)는 광을 출력하면서 카메라 장치로 상기 인터럽트(또는 신호)를 전송할 수 있다. 상기 조명 장치가 턴-온되기 전에 카메라 장치는 비활성화 상태일 수 있다. 상기 카메라 장치는 상기 인터럽트(또는 신 호)를 수신한 것에 기반하여 활성화되고, 사용자(U)를 촬영하고 제 2 이미지를 획득할 수 있다. 또는 상기 카메 라 장치는 조도 센서를 이용하여 조도가 기-설정된 값 이상인 것을 검출하고, 이에 기반하여 활성화되어 사용자(U)를 촬영하고 제 2 이미지를 획득할 수 있다. 일 실시예에 따르면, 상기 제 2 이미지에 복수의 사용자들의 얼굴들이 포함된 경우(예: 운전석과 동승석에서 하 차한 복수의 사용자들), 관리 장치는 복수의 사용자들의 얼굴들 중 운전석의 위치에 대응하는 위치를 갖는 사용자의 얼굴을 차량의 사용자의 얼굴로서 식별할 수 있다. 예를 들어, 관리 장치는 운전석의 위치에 대 한 정보(예: 좌측)를 미리 저장할 수 있다. 이에 따라, 관리 장치는 획득된 이미지로부터 식별된 사용자들 의 얼굴들의 좌표들을 식별하고, 식별된 좌표들 중에서 좌측에 가까운 값을 가지는 좌표에 대응하는 사용자의 얼굴을 차량의 사용자의 얼굴로서 식별할 수 있다. 한편, 관리 장치는 차량의 종류 별로 운전석의 위치에 대한 정보를 미리 저장하고, 미리-저장된 정보와 이미지로부터 식별된 차량의 종류에 기반하여 차량의 종류에 대응하는 운전석의 위치에 대한 정보를 획득할 수도 있다.일 실시예에 따르면, 관리 서버는 706 동작에서 제 2 이미지에 기반하여 사용자의 얼굴을 식별하고, 707 동작에서 차량 번호, 주차 위치, 및 사용자 얼굴을 서 로 연관되도록 저장할 수 있다. 관리 서버의 706 동작 내지 707 동작은 전술한 관리 서버의 408 동작 내지 409 동작과 같이 수행될 수 있으므로 중복되는 설명은 생략한다. 일 실시예에 따르면, 관리 장치는 708 동작에서 차량 위치 제공 요청을 획득하고, 709 동작에서 사용자 얼 굴을 포함하는 제 3 이미지를 촬영하고, 710 동작에서 제 3 이미지를 관리 서버로 송신할 수 있다. 관리 장치의 708 동작 내지 710 동작은 전술한 관리 장치의 410 동작 내지 412 동작과 같이 수행될 수 있으므로 중복되는 설명은 생략한다. 일 실시예에 따르면, 관리 서버는 711 동작에서 제 3 이미지에 기반하여 사용자 얼굴을 식별하고, 미리 저 장된 정보로부터, 식별된 사용자 얼굴에 대응하는 차량 번호 및/또는 주차 위치를 식별하고, 712 동작에서 차량 번호 및/또는 주차 위치에 대한 정보를 관리 장치로 송신할 수 있다. 관리 서버의 711 동작 내지 712 동작은 전술한 관리 서버의 413 동작 내지 414 동작과 같이 수행될 수 있으므로 중복되는 설명은 생략한다. 일 실시예에 따르면, 관리 장치는 713 동작에서 차량 번호 및/또는 주차 위치에 대한 정보를 표시할 수 있 다. 관리 서버의 713 동작은 전술한 관리 서버의 415 동작과 같이 수행될 수 있으므로 중복되는 설명 은 생략한다. 3.3 제 3 실시예 < 안티 스푸핑(anti spoofing) 동작> 전술한 스마트 얼굴 인식 시스템의 동작들은 제 3 실시예에 준용될 수 있으므로, 중복되는 설명은 생략한다. 일 실시예에 따르면, 전술한 바와 같이 스마트 얼굴 인식 시스템은 사용자의 얼굴에 대한 정보를 차량의 위치에 대한 정보를 획득하기 위한 소정의 키(key)로서 관리할 수 있다. 이때, 스마트 얼굴 인식 시스템은 사용자의 얼 굴에 대한 정보의 위조를 방지하기 위해서, 안티 스푸핑(anti spoofing) 동작을 수행할 수 있다. 예를 들어, 스 마트 얼굴 인식 시스템은 위조를 방지하기 위해서 특정 촬영 방법에 기반하여 사용자의 얼굴을 포함하는 이미지 들을 촬영하고, 상기 특정 촬영 방법 또한 소정의 키(key)로서 등록할 수 있다. 이후에 스마트 얼굴 인식 시스 템은 특정 촬영 방법으로 사용자의 얼굴을 촬영하도록 함으로써, 위조된 사용자의 얼굴 이미지를 이용하여 차량 위치에 대한 정보를 탈취하는 범죄를 예방할 수 있다. 상기 특정 촬영 방법은 서로 다른 조명 조건에서 사용자 의 얼굴을 복수회 촬영하는 방법, 및 사용자의 표정 및/또는 시선을 변경하도록 가이드하여 사용자의 얼굴을 복 수회 촬영하는 방법을 포함할 수 있다. 도 9는 본 출원의 일 실시예에 따른 스마트 얼굴 인식 시스템의 동작의 다른 예를 설명하기 위한 흐름도이다. 다양한 실시예들에 따르면 스마트 얼굴 인식 시스템의 동작은 도 9에 도시되는 동작의 순서에 국한되지 않고, 도시되는 순서와 다른 순서로 수행될 수 있다. 또한, 다양한 실시예들에 따르면, 도 9에 도시되는 스마트 얼굴 인식 시스템의 동작들뿐만 아니라 추가적인 동작들이 수행되거나, 또는 상기 동작들 중 일부를 제외한 적어도 하나의 동작이 수행될 수도 있다. 이하에서는 도 10 내지 도 11을 참조하여 도 9에 대해서 설명한다. 도 10은 본 출원의 일 실시예에 따른 스마트 얼굴 인식 시스템의 안티 스푸핑 동작의 일 예를 설명하기 위한 도 면이다. 도 11은 본 출원의 일 실시예에 따른 스마트 얼굴 인식 시스템의 안티 스푸핑 동작의 일 예를 설명하기 위한 도면이다. 일 실시예에 따르면, 카메라 장치는 901 동작에서 차량 번호판을 포함하는 제 1 이미지를 촬영하고, 902 동작에서 관리 장치로 제 1 이미지 및 카메라 장치의 식별 정보를 송신할 수 있다. 또는 기재된 바에 제한 되지 않고, 카메라 장치는 관리 장치를 경유하지 않고, 관리 서버로 제 1 이미지 및 카메라 장 치의 식별 정보를 직접 송신할 수 있다. 일 실시예에 따르면, 관리 장치는 903 동작에서 카메라 장치(30 0)로부터 수신(또는, 주차장의 중계기(A)를 통해 수신)된 제 1 이미지 및 카메라 장치의 식별 정보를 관리 서버 로 송신할 수 있다. 또는 기재된 바에 제한되지 않고 전술한 바와 같이, 카메라 장치로부터 관리 장 치를 경유하지 않고, 관리 서버로 제 1 이미지 및 카메라 장치의 식별 정보가 직접 송신될 수 있다. 일 실시예에 따르면, 관리 서버는 904 동작에서 제 1 이미지에 기반하여 차량 번호를 식별하고, 제 1 이미 지 및/또는 식별 정보에 기반하여 차량의 주차 위치를 식별할 수 있다. 일 실시예에 따르면, 관리 장치는 905 동작에서 차량 위치 등록 요청을 획득하고, 906 동작에서 차량 번호 를 획득하고, 특정 촬영 방법에 기반하여 사용자 얼굴을 포함하는 복수의 제 2 이미지들을 촬영하고, 907 동작 에서 복수의 제 2 이미지들, 특정 촬영 방법에 대한 정보, 및 차량 번호 송신 할 수 있다. 예를 들어 관리 장치 는 안티 스푸핑(anti spoofing)을 위하여 특정 촬영 방법에 기반하여 사용자의 얼굴을 포함하는 복수의 이 미지들(예: 복수의 제 2 이미지들)을 촬영하고, 이미지들(예: 복수의 제 2 이미지들), 특정 촬영 방법, 및 사용 자에 의해 입력된 차량 번호에 대한 정보를 관리 서버로 송신할 수 있다. 일 실시예에 따르면 상기 특정 촬영 방법은 서로 다른 조명 조건에서 사용자의 얼굴을 복수회 촬영하는 방법, 및 사용자의 표정 및/또는 시선을 변경하도록 가이드하여 사용자의 얼굴을 복수회 촬영하는 방법을 포함할 수있다. 일 실시예에서 도 10을 참조하면, 관리 장치는 복수의 조명 장치들(1001, 1002, 1003, 1004)에 기반 하여 복수의 조명 조건들 하에서 사용자의 얼굴을 포함하는 복수의 이미지들(예: 복수의 제 2 이미지들)을 촬영 할 수 있다. 예를 들어, 관리 장치는 특정 순서로 복수의 조명 장치들(1001, 1002, 1003, 1004)을 순차적 으로 턴-온한 상태에서 사용자를 촬영함으로써, 복수의 이미지들(1000a, 1000b, 1000c, 1000d)을 획득할 수 있 다. 이에 따라, 상기 복수의 이미지들(1000a, 1000b, 1000c, 1000d)은 영역 별로 서로 다른 밝기 값을 가질 수 있다. 일 실시예에서 도 11을 참조하면, 관리 장치는 사용자의 표정을 가이드하기 위한 화면(또는 음성)에 기반하여, 순차적으로 사용자의 서로 다른 표정을 포함하는 얼굴을 포함하는 복수의 이미지들(1100a, 1100b, 1100c, 1100d)을 촬영할 수 있다. 또 일 실시예에서 도시되지 않았으나, 관리 장치는 사용자의 시선의 위 치를 가이드하기 위한 오브젝트(예: 빨간 점)의 위치를 변경하면서, 순차적으로 사용자의 얼굴을 포함하는 복수 의 이미지들을 촬영할 수 있다. 이때, 복수의 이미지들의 사용자의 얼굴의 시선의 위치는 관리 장치에 표 시되는 오브젝트의 위칭에 대응하며, 서로 다를 수 있다. 결과적으로 복수 회 촬영된 이미지들은 모두 사용자의 얼굴을 포함하나, 픽셀 값이 서로 다를 수 있다. 예를 들어, 복수 회 촬영된 이미지들은 서로 다른 밝기 값, 및 /또는 서로 다른 픽셀 값을 가질 수 있다. 일 실시예에 따르면 관리 장치는 특정 촬영 방법에 대한 정보로서, 조명 장치의 턴-온 된 순서에 대한 정 보, 사용자의 표정들의 순서에 대한 정보, 및 사용자의 시선의 위치를 가이드하기 위한 오브젝트(예: 빨간 점) 의 위치들에 대한 정보를 획득하고, 이를 관리 서버로 전송할 수 있다. 일 실시예에 따르면 관리 서버는 908 동작에서 특정 촬영 방법, 차량 번호, 주차 위치, 및 복수의 제 2 이 미지들을 서로 연관되도록 저장할 수 있다. 관리 서버는 전술한 정보에서 추가적으로, 특정 촬영 방 법에 대한 정보를 상기 차량 번호, 주차 위치, 및 복수의 제 2 이미지들과 연관되도록 더 저장할 수 있다. 일 실시예에 따르면, 관리 장치는 909 동작에서 차량 위치 제공 요청을 획득하고, 910 동작에서 특정 촬영 방법에 대한 정보를 요청하는 메시지를 송신하고, 관리 서버는 911 동작에서 특정 촬영 방법에 대한 정보 를 송신할 수 있다. 예를 들어, 관리 장치는 사용자의 얼굴을 촬영하고 촬영된 이미지를 관리 서버로 송신하거나, 및/또는 사용자로부터 입력된 차량 번호에 대한 정보를 관리 서버로 송신할 수 있다. 관리 서 버는 상기 수신된 이미지에서 식별된 사용자의 얼굴 및/또는 차량 번호에 대응하는 특정 촬영 방법에 대한 정보를 관리 장치로 전송할 수 있다. 일 실시예에 따르면, 관리 서버는 912 동작에서 특정 촬영 방법에 기반하여 사용자 얼굴을 포함하는 복수 의 제 3 이미지들을 촬영하고, 913 동작에서 복수의 제 3 이미지들을 관리 장치로 전송할 수 있다. 일 실시예에 따르면, 관리 서버는 914 동작에서 복수의 제 3 이미지들과 미리 저장된 정보에 기반하여, 대 응하는 차량 번호 및/또는 주차 위치를 식별하고, 915 동작에서 차량 번호 및/또는 주차 위치에 대한 정보를 관 리 장치로 송신할 수 있다. 예를 들어, 관리 서버는 미리 저장된 정보를 특정 촬영 방법에 의해 촬영 된 사용자의 얼굴을 포함하는 복수의 제 3 이미지들을 비교하고, 비교 결과에 기반하여 복수의 제 3 이미지들에 대응하는 차량 번호 및/또는 차량 위치에 대한 정보가 존재하는 경우 이를 관리 장치로 전송할 수 있다. 일 실시예에 따르면, 관리 장치는 916 동작에서 차량 번호 및/또는 주차 위치에 대한 정보를 표시할 수 있 다. 3.4 제 4 실시예 <얼굴 인식 시, 얼굴의 특징 점의 값을 식별하고 비교하는 동작> 전술한 스마트 얼굴 인식 시스템의 동작들은 제 4 실시예에 준용될 수 있으므로, 중복되는 설명은 생략한다. 일 실시예에 따르면, 관리 서버는 사용자의 얼굴을 포함하는 이미지로부터 사용자의 얼굴을 인식할 수 있 다. 관리 서버는 사용자의 얼굴을 인식하는 동작의 적어도 일부로, 사용자의 얼굴의 특징 점의 값을 식별 하는 동작을 수행할 수 있다. 상기 특징 점은 사용자들 간의 얼굴을 비교하기 용이한 얼굴 부분을 의미하는 것으로, 예를 들면 콧날 부분의 영역, 얼굴 형상 영역 등을 포함할 수 있다. 이에 따라, 관리 서버는 사용자 의 얼굴 대신 특징 점에 대한 값을 저장하고, 추후에 특징 점에 대한 값을 비교함으로써 사용자의 얼굴 인식률 을 향상시킬 뿐만 아니라 데이터가 저장되는 양을 현저하게 감소시켜 서버의 운용 부담을 저감할 수 있다. 도 12a는 본 출원의 일 실시예에 따른 스마트 얼굴 인식 시스템의 동작의 다른 예를 설명하기 위한 흐름도이다. 도 12b는 본 출원의 일 실시예에 따른 스마트 얼굴 인식 시스템의 동작의 다른 예를 설명하기 위한 흐름도이다. 다양한 실시예들에 따르면 스마트 얼굴 인식 시스템의 동작은 도 12a 및 도 12b에 도시되는 동작의 순서에 국한되지 않고, 도시되는 순서와 다른 순서로 수행될 수 있다. 또한, 다양한 실시예들에 따르면, 도 12a 및 도 12b 에 도시되는 스마트 얼굴 인식 시스템의 동작들뿐만 아니라 추가적인 동작들이 수행되거나, 또는 상기 동작들 중 일부를 제외한 적어도 하나의 동작이 수행될 수도 있다. 이하에서는 도 13 내지 도 14를 참조하여 도 12a 및 도 12b에 대해서 설명한다. 도 13은 본 출원의 일 실시예에 따른 관리 장치의 사용자의 얼굴의 특징 점을 정확하게 분석하기 위해, 사 용자의 위치를 가이드하는 동작의 예를 설명하기 위한 도면이다. 도 14는 본 출원의 일 실시예에 따른 특징 점 의 예를 설명하기 위한 도면이다. 일 실시예에 따르면, 관리 서버는 1201 동작에서 관리 장치로부터 사용자의 얼굴을 포함하는 제 1 이 미지를 수신할 수 있다. 관리 장치는 도 13에 도시된 바와 같이, 사용자의 얼굴의 특징 점의 분석이 가능 한 이미지가 촬영되도록, 특정 거리에서 사용자(U)를 촬영하고 촬영된 이미지(예: 제 1 이미지)를 관리 서버 로 전송할 수 있다. 관리 장치는 상기 사용자를 촬영한 이미지로부터 식별되는 사용자(U)의 눈 사이 의 거리(d)에 기반하여 관리 장치와 사용자(U) 사이의 거리를 식별할 수 있다. 관리 장치는 식별된 거리가 이미지를 촬영하기 위한 지정된 거리와 다른 경우, 사용자(U)와의 거리를 조정하기 위해서 가이드(예: 화면 또는 음성)를 제공할 수 있다. 일 실시예에 따르면, 관리 서버는 1202 동작에서 제 1 이미지로부터 사용자의 얼굴에 대한 복수의 특징점 들 별 제 1 값을 추출하고, 1203 동작에서 복수의 특징점들 별 값을 차량 번호 및 주차 위치와 연관되도록 저장 할 수 있다. 예를 들어 도 14에 도시된 바와 같이, 관리 서버는 사용자의 얼굴 중에서 사용자들 간의 얼굴 의 비교가 용이한(즉 사용자의 얼굴을 특정 지를 수 있는) 특징 점(또는 랜드 마크)에 대한 값을 추출할 수 있 다. 상기 특징 점(또는 랜드 마크)은 도 14에 도시된 바와 같이, 신체 일부의 형태(예: 눈의 형태, 눈썹 형태, 콧대의 형태, 입술의 형태, 얼굴의 형태), 신체 일부 간의 거리(예: 눈ㆍ입ㆍ콧 구멍ㆍ턱ㆍ 간의 각도와 거리), 신체 일부의 뼈 돌출 정도 등을 포함할 수 있으며, 기재 및/또는 도시된 바에 제한되지 않고 다양한 부위가 특징 점(또는 랜드 마크)이 될 수 있다. 관리 서버는 상기 제 1 이미지로부 터 사용자의 얼굴을 인식하고, 사용자의 얼굴로부터 특징 점(또는 랜드 마크)(1401, 1402, 1403, 1404, 1405)을 추출하고, 3차원(3D) 공간 분석 방법에 기반하여 추출된 특징점(또는 랜드마크)(1401, 1402, 1403, 1404, 1405) 별 각도 및/또는 방향을 나타내는 벡터 값을 획득할 수 있다. 관리 서버는 전술한 정보에서 사 용자의 얼굴에 대한 정보로서, 상기 추출된 특징점 별 각도 및/또는 방향을 나타내는 벡터 값을 저장할 수 있다. 후술하겠으나, 상기 3차원(3D) 공간 분석 방법은 인공 지능 모델을 이용한 분석 방법을 포함할 수 있다. 한편 1201 동작 내지 1202 동작 대신에, 도 12b를 참조하면 관리 장치가 1208 동작에서 사용자의 얼굴을 포함하는 이미지를 획득하고, 1209 동작에서 관리 장치에 구비된 엣지 장치를 이용하여 엣지 장치를 이용하여 이미지로부터 사용자의 얼굴에 대한 복수의 특징점들 별 값을 추출할 수 있다. 관리 장치는 1210 동작에서 값의 추출 이후 이미지를 삭제하고, 1211 동작에서 상기 값을 관리 서버로 전달할 수 있다. 이에 따라, 관리 서버가 상기 얼굴에 대한 특징점들 별 값을 획득할 수 있다. 일 실시예에 따르면, 관리 서버는 1204 동작에서 관리 장치로부터 사용자의 얼굴을 포함하는 제 2 이미지 를 수신하고, 1205 동작에서 제 1 이미지로부터 사용자의 얼굴에 대한 복수의 특징점들 별 제 2 값을 추출할 수 있다. 예를 들어 전술한 바와 같이, 관리 서버는 관리 장치로부터 차량 위치를 요청하는 메시지와 함 께 사용자의 얼굴을 포함하는 이미지(예: 제 2 이미지)를 획득하고, 이미지(예: 제 2 이미지)로부터 사용자의 얼굴의 특징점(1401, 1402, 1403, 1404, 1405) 별 각도 및/또는 방향을 나타내는 벡터 값을 획득할 수 있다. 한편 1204 동작 내지 1205 동작 대신에, 도 12b를 참조하면 관리 장치가 1208 동작에서 사용자의 얼굴을 포함하는 이미지를 획득하고, 1209 동작에서 관리 장치에 구비된 엣지 장치를 이용하여 엣지 장치를 이용하여 이미지로부터 사용자의 얼굴에 대한 복수의 특징점들 별 값을 추출할 수 있다. 관리 장치는 1210 동작에서 값의 추출 이후 이미지를 삭제하고, 1211 동작에서 상기 값을 관리 서버로 전달할 수 있다. 이에 따라, 관리 서버가 상기 얼굴에 대한 특징점들 별 값을 획득할 수 있다. 일 실시예에 따르면, 관리 서버는 1206 동작에서 제 1 값과 제 2 값의 대응 여부를 판단하고, 상기 제 1 값과 상기 제 2 값이 대응하는 경우 1207 동작에서 저장된 차량 번호 및/또는 주차 위치를 관리 장치로 송신할 수 있다. 관리 서버는 미리 저장된 정보와 상기 추출된 사용자의 얼굴의 특징점(1401, 1402, 1403, 1404, 1405) 별 각도 및/또는 방향을 나타내는 벡터 값을 비교한 결과에 기반하여, 대응하는 차량 번호 및/또는 차량 위치에 대한 정보가 존재하는 경우, 이를 관리 장치로 전송할 수 있다.3.4 제 5 실시예 <얼굴 인식 시 인공 지능 모델에 기반하여, 얼굴의 특징 점의 값을 식별하고 비교하는 동작> 전술한 스마트 얼굴 인식 시스템의 동작들은 제 4 실시예에 준용될 수 있으므로, 중복되는 설명은 생략한다. 일 실시예에 따르면, 관리 서버는 사용자의 얼굴을 포함하는 이미지에 대한 픽셀 값을 입력 받은 것에 대 한 응답으로 사용자의 얼굴의 특징점들 별 값(예: 벡터 값)을 추출하도록 구현된 인공 지능 모델을 미리 저장할 수 있다. 관리 서버는 인공 지능 모델을 이용하여, 사용자의 얼굴에 대한 특징점들 별 값(예: 벡터 값)을 획득할 수 있다. 도 15a는 본 출원의 일 실시예에 따른 스마트 얼굴 인식 시스템의 동작의 다른 예를 설명하기 위한 흐름도이다. 도 15b는 본 출원의 일 실시예에 따른 스마트 얼굴 인식 시스템의 동작의 다른 예를 설명하기 위한 흐름도이다. 다양한 실시예들에 따르면 스마트 얼굴 인식 시스템의 동작은 도 15a 및 도 15b에 도시되는 동작의 순서에 국한 되지 않고, 도시되는 순서와 다른 순서로 수행될 수 있다. 또한, 다양한 실시예들에 따르면, 도 15a에 도시되는 스마트 얼굴 인식 시스템의 동작들뿐만 아니라 추가적인 동작들이 수행되거나, 또는 상기 동작들 중 일부를 제 외한 적어도 하나의 동작이 수행될 수도 있다. 이하에서는 도 16 내지 도 17을 참조하여 도 15a 및 도 15b에 대 해서 설명한다. 도 16은 본 출원의 일 실시예에 따른 관리 서버의 사용자의 얼굴에 대한 특징점들 별 값(예: 벡터 값)을 획득하기 위한 인공 지능 모델을 생성하는 동작의 예를 설명하기 위한 도면이다. 도 17은 본 출원의 일 실시예에 따른 관리 서버의 인공 지능 모델을 이용하여 얼굴에 대한 특징점들 별 값(예: 벡터 값)을 획득하는 동작의 예를 설명하기 위한 도면이다. 일 실시예에 따르면, 관리 서버는 1501 동작에서 관리 서버에서 기-저장된 사용자의 얼굴을 포함하는 이미 지와 이에 대응하는 사용자의 얼굴의 특징점의 값에 대한 정보들을 획득하고, 1502 동작에서 획득된 정보들을 기반으로, 사용자의 얼굴의 특징점의 값을 획득하기 위한 인공 지능 모델을 학습할 수 있다. 예를 들어 관리 서 버에는 사용자의 얼굴을 포함하는 복수의 이미지들과 복수의 이미지들에 대응하는 사용자의 얼굴의 특징점 들(또는 랜드마크들)에 대한 값(예: 벡터 값)이 미리 분석되어, 복수의 이미지들과 복수의 이미지들에 대응하는 사용자의 얼굴의 특징점들(또는 랜드마크들)에 대한 값(예: 벡터 값)이 메모리에 미리 저장될 수 있다. 이 하에서는 관리 서버의 메모리에 축적된 빅 데이터에 기반한, 인공 지능 모델을 생성 하는 동작 의 예에 대해서 설명한다. 일 실시예에서 먼저 관리 서버는 도 16의 1601 내지 1602에 도시된 바와 같이 인공 지능 모델을 생 성하기 위해, 메모리에 축적된 사용자의 얼굴을 포함하는 복수의 이미지들과 복수의 이미지들에 대응하는 사용자의 얼굴의 특징점들(또는 랜드마크들)에 대한 값(예: 벡터 값)을 획득할 수 있다. 이때, 관리 서버 는 상기 메모리에 축적된 정보를 획득하는 동작의 적어도 일부로, 상기 관리 서버에 저장된 정보들 중 특징점들에 대한 값의 신뢰도가 임계값 보다 높은 정보들을 획득할 수 있다. 일 실시예에서, 관리 서버는 도 16의 1602에 도시된 바와 같이 복수의 이미지들과 복수의 이미지들에 대응 하는 사용자의 얼굴의 특징점들(또는 랜드마크들)에 대한 값(예: 벡터 값)을 학습이 가능한 형태로 가공할 수 있다. 예를 들어 관리 서버는 각 정보들을 전처리(예: 이미지를 픽셀 값으로 변환하는 등)하고 행렬 연산 이 가능한 행렬 값으로 환산하고, 환산된 행렬 값들이 연산 가능해지도록 정렬하는 등의 동작(예: Allocation, Wrangling)을 수행할 수 있다. 상기 데이터를 전처리하는 동작은 주지의 기술이므로 구체적인 설명은 생략한다. 일 실시예에서, 관리 서버는 가공된 정보들(예: 이미지의 픽셀 값, 및 이미지에 대응하는 특징점의 벡터 값들)을 트레이닝 데이터(training data)로 하여 학습을 진행함으로써, 인공 지능 모델을 생성할 수 있다. 예를 들어, 관리 서버는 사용자의 얼굴을 포함하는 이미지의 픽셀 값을 입력 데이터(input data)로 하고, 이미지에 대응하는 사용자의 얼굴의 특징점들(예: A feature, B feature, C feature) 별 벡터 값을 출력 데이터(output data)로 설정하여, 다양한 종류의 인공 지능 학습 알고리즘에 기반하여 학습(예: 파라미터(예: 가중치(weight)) 학습을 수행할 수 있다. 상기 인공 지능 학습 알고리즘은 다양한 종류의 주지의 머신 러 닝(machine learning) 및 딥 러닝(deep learning) 알고리즘을 포함할 수 있으므로, 구체적인 설명은 생략한다. 이때, 상기 학습에 따라서, 생성된 인공 지능 모델은 이미지의 픽셀 값을 입력 받은 것에 대한 응 답으로, 특징점들 별 값을 최종 출력하도록 구현될 수 있다. 예를 들어, 생성된 인공 지능 모델은 이미지의 픽셀 값을 처리하기 위한 가중치 값들을 포함하는 적어도 하나의 레이어를 포함하고, 적어도 하나의 레이어에서 상기 이미지의 픽셀 값이 연산됨에 따라서 결과 값으로서 특징점들 별 값을 출력할 수 있다.일 실시예에 따르면, 관리 서버는 1503 동작에서 관리 장치로부터 사용자의 얼굴을 포함하는 이미지(170 0)를 수신하고, 1504동작에서 인공 지능 모델에 기반하여 사용자의 얼굴에 대한 복수의 특징점들 별 값을 획득 할 수 있다. 예를 들어 도 17에 도시된 바와 같이, 관리 서버는 차량 위치 등록 동작 및/또는 차량 위치 제공 동작을 수행하는 중에, 관리 장치로부터 사용자의 얼굴을 포함하는 이미지를 수신할 수 있다. 관리 서버는 수신된 이미지를 픽셀 값을 획득하고, 기 구현된 인공 지능 모델에 획득된 픽셀 값을 입력한 것에 대한 응답으로, 인공 지능 모델로부터 출력되는 사용자의 얼굴의 특징 점들 별 값(예: 벡터 값)을 획득할 수 있다. 한편 1503 동작 내지 1504 동작 대신에, 도 15b를 참조하면 관리 장치가 1505 동작에서 사용자의 얼굴을 포함하는 이미지를 획득하고, 1209 동작에서 관리 장치에 구비된 엣지 장치에 저장된 전술한 저장된 인공 지능 모델에 기반하여, 복수의 특징점들 별 값을 획득할 수 있다. 관리 장치는 1507 동작에서 값의 추출 이후 이미지를 삭제하고, 1508동작에서 상기 값을 관리 서버로 전달할 수 있다. 이에 따라, 관 리 서버가 상기 얼굴에 대한 특징점들 별 값을 획득할 수 있다."}
{"patent_id": "10-2021-0160191", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1a는 일 실시예에 따른 스마트 얼굴 인식 시스템에 포함된 장치들의 일 예를 설명하기 위한 도면이다. 도 1b는 일 실시예에 따른 스마트 얼굴 인식 시스템에 포함된 장치들의 다른 예를 설명하기 위한 도면이다. 도 2a는 일 실시예에 따른 주차장(parking lot)에 배치된 카메라 장치들의 예를 설명하기 위한 도면이다. 도 2b는 일 실시예에 따른 관리 장치 및 관리 서버의 예를 설명하기 위한 도면이다. 도 3a는 일 실시예에 따른 스마트 얼굴 인식 시스템에 포함된 장치들(예: 관리 서버, 관리 장치, 카메라 장치) 의 구성의 일 예를 나타내는 블록도이다. 도 3b는 일 실시예에 따른 스마트 얼굴 인식 시스템에 포함된 장치들(예: 관리 서버, 관리 장치, 카메라 장치) 의 구성의 다른 예를 나타내는 블록도이다. 도 4a는 일 실시예에 따른 스마트 얼굴 인식 시스템의 동작의 일 예를 설명하기 위한 흐름도이다. 도 4b 및 도 4c는 일 실시예에 따른 스마트 얼굴 인식 시스템의 동작의 다른 예를 설명하기 위한 흐름도이다. 도 5a는 일 실시예에 따른 카메라 장치가 주차장(parking lot)에 주차된 차량의 차량 번호판을 포함하는 이미지 를 촬영하는 동작의 예를 설명하기 위한 도면이다. 도 5b는 일 실시예에 따른 관리 서버의 차량 위치 등록 동작 및 차량 위치 제공 동작의 예를 설명하기 위한 도 면이다. 도 6은 일 실시예에 따른 관리 장치의 다른 구현 예를 설명하기 위한 도면이다. 도 7은 일 실시예에 따른 스마트 얼굴 인식 시스템의 동작의 다른 예를 설명하기 위한 흐름도이다. 도 8은 일 실시예에 따른 차량에서 하차한 사용자의 얼굴을 촬영하는 동작의 예를 설명하기 위한 도면이다. 도 9는 일 실시예에 따른 스마트 얼굴 인식 시스템의 동작의 다른 예를 설명하기 위한 흐름도이다. 도 10은 일 실시예에 따른 스마트 얼굴 인식 시스템의 안티 스푸핑 동작의 일 예를 설명하기 위한 도면이다. 도 11은 일 실시예에 따른 스마트 얼굴 인식 시스템의 안티 스푸핑 동작의 일 예를 설명하기 위한 도면이다. 도 12a는 일 실시예에 따른 스마트 얼굴 인식 시스템의 동작의 다른 예를 설명하기 위한 흐름도이다. 도 12b는 일 실시예에 따른 스마트 얼굴 인식 시스템의 동작의 다른 예를 설명하기 위한 흐름도이다. 도 13은 일 실시예에 따른 관리 장치의 사용자의 얼굴의 특징 점을 정확하게 분석하기 위해, 사용자의 위치를 가이드하는 동작의 예를 설명하기 위한 도면이다. 도 14는 일 실시예에 따른 특징 점의 예를 설명하기 위한 도면이다. 도 15a는 일 실시예에 따른 스마트 얼굴 인식 시스템의 동작의 다른 예를 설명하기 위한 흐름도이다. 도 15b는 일 실시예에 따른 스마트 얼굴 인식 시스템의 동작의 다른 예를 설명하기 위한 흐름도이다.도 16은 일 실시예에 따른 관리 서버의 사용자의 얼굴에 대한 특징점들 별 값(예: 벡터 값)을 획득하기 위한 인 공 지능 모델을 생성하는 동작의 예를 설명하기 위하 도면이다. 도 17은 일 실시예에 따른 관리 서버의 인공 지능 모델을 이용하여 얼굴에 대한 특징점들 별 값(예: 벡터 값)을 획득하는 동작의 예를 설명하기 위하 도면이다."}
