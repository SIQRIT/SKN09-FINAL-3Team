{"patent_id": "10-2021-7007212", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2021-0043626", "출원번호": "10-2021-7007212", "발명의 명칭": "심층 신경망용 압축 방법, 칩, 전자 장치 및 매체", "출원인": "넥스트브이피유", "발명자": "조우, 지"}}
{"patent_id": "10-2021-7007212", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "복수의 계층을 포함하는 심층 신경망용 압축 방법으로서, 상기 방법은, 입력 계층을 제외한 상기 복수의 계층중 적어도 하나의 계층에 대하여:파라미터 저장 공간으로부터 상기 계층의 파라미터를 판독하는 단계;직전 계층에 의해 저장된 제1 특징 맵을 특징 맵 저장 공간으로부터 판독하는 단계;상기 판독된 파라미터 및 상기 제1 특징 맵에 기초하여 제2 특징 맵을 생성하는 단계;제3 특징 맵을 얻기 위해 상기 제2 특징 맵을 압축하는 단계; 및상기 특징 맵 저장 공간 내에 상기 제3 특징 맵을 저장하는 단계를 포함하는 것을 특징으로 하는 방법."}
{"patent_id": "10-2021-7007212", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 제2 특징 맵에 대하여 수행된 상기 압축은 손실 압축인 것을 특징으로 하는 방법."}
{"patent_id": "10-2021-7007212", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서, 상기 방법은 상기 심층 신경망의 훈련 과정 및 상기 심층 신경망의 추론 과정에서 순전파 위상(forward propagation phase)에 사용되는 것을 특징으로 하는 방법."}
{"patent_id": "10-2021-7007212", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서, 상기 심층 신경망은 컨볼루션 신경망(convolutional neural network)을 포함하고, 상기 컨볼루션 신경망은 복수의 컨볼루션 계층을 포함하며, 상기 방법은 상기 복수의 컨볼루션 계층 중 적어도 하나에 대해수행되는 것을 특징으로 하는 방법."}
{"patent_id": "10-2021-7007212", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서,상기 제1 특징 맵은 압축된 특징 맵이고,상기 판독된 파라미터 및 상기 제1 특징 맵에 기초하여 상기 제2 특징 맵을 생성하는 단계는:상기 제1 특징 맵을 압축 해제하는 단계; 및상기 판독된 파라미터 및 상기 압축 해제된 제1 특징 맵에 기초하여, 상기 제2 특징 맵을 생성하는 단계를 포함하는 것을 특징으로 하는 방법."}
{"patent_id": "10-2021-7007212", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서,상기 파라미터 저장 공간으로부터 판독된 상기 파라미터는 압축된 파라미터이고,상기 판독된 파라미터 및 상기 제1 특징 맵에 기초하여 상기 제2 특징 맵을 생성하는 단계는:상기 판독된 파라미터를 압축 해제하는 단계; 및상기 압축 해제된 파라미터 및 상기 제1 특징 맵에 기초하여 상기 제2 특징 맵을 생성하는 단계를 포함하는 것을 특징으로 하는 방법.공개특허 10-2021-0043626-3-청구항 7 제2항에 있어서, 상기 제2 특징 맵을 압축하는 단계는:상기 제2 특징 맵을 공간 도메인으로부터 주파수 도메인으로 변환하는 단계; 및변환 계수를 양자화하는 단계를 포함하는 것을 특징으로 하는 방법."}
{"patent_id": "10-2021-7007212", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제2항에 있어서, 상기 제2 특징 맵을 압축하는 단계는 상기 제2 특징 맵에 대한 예측 코딩을 수행하는 단계를더 포함하고,상기 예측 코딩은 인트라 예측(intra prediction) 및 인터 예측(inter prediction) 중 어느 하나 또는 양자를포함하는 것을 특징으로 하는 방법."}
{"patent_id": "10-2021-7007212", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제2항에 있어서, 상기 제2 특징 맵을 압축하는 단계는 다른 압축 비율로 상기 제2 특징 맵의 다른 영역을 압축하는 단계를 포함하고, 상기 다른 영역 각각의 압축 비율은 상기 해당 영역에 대한 관심도에 의존하며, 제1 관심도의 영역의 압축 비율은 제2 관심도의 영역의 압축 비율보다 작고, 상기 제1 관심도는 상기 제2 관심도보다높은 것을 특징으로 하는 방법."}
{"patent_id": "10-2021-7007212", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제2항에 있어서, 상기 제2 특징 맵을 압축하는 단계는 상기 제2 특징 맵에 대한 비균일 양자화(non-uniformquantization)를 수행하는 단계를 포함하고, 상기 제2 특징 맵의 다른 영역은 다른 양자화 구간 간격(quantization steps)을 갖는 것을 특징으로 하는 방법."}
{"patent_id": "10-2021-7007212", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제10항에 있어서, 상기 제2 특징 맵의 상기 영역 각각의 상기 양자화 구간 간격이: 상기 영역의 이미지 복잡성; 상기 제2 특징 맵 내에서 상기 영역의 위치;상기 영역의 중요도; 상기 영역 내의 특정한 특징의 존재 또는 부재; 및 상기 영역 내의 상기 특정한 특징의 수중 적어도 하나에 기초하여 결정되는 것을 특징으로 하는 방법."}
{"patent_id": "10-2021-7007212", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항에 있어서, 상기 특정한 특징은 상기 심층 신경망의 애플리케이션 시나리오에 대한 관심의 특징을 포함하는 것을 특징으로 하는 방법."}
{"patent_id": "10-2021-7007212", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제11항에 있어서, 상기 영역 내의 상기 특정한 특징의 존재 또는 부재에 따라 상기 영역 각각의 상기 양자화 구간 간격의 결정은: 상기 영역 내의 상기 특정한 특징의 존재에 응답하여, 상기 영역에 제1 양자화 구간 간격을 할당하는 단계; 및상기 영역 내의 상기 특정한 특징의 부재에 응답하여, 상기 영역에 제2 양자화 구간 간격을 할당하는 단계를 포함하고,상기 제1 양자화 구간 간격은 상기 제2 양자화 구간 간격보다 작은 것을 특징으로 하는 방법.공개특허 10-2021-0043626-4-청구항 14 제11항에 있어서, 상기 영역 내의 상기 특정한 특징의 수에 따라 상기 영역 각각의 상기 양자화 구간 간격의 결정은:미리 설정된 임계값을 초과하는 상기 영역 내의 상기 특정한 특징의 수에 응답하여, 상기 영역에 제3 양자화 구간 간격을 할당하는 단계; 및미리 설정된 임계값 이하인 상기 영역 내의 상기 특정한 특징의 수에 응답하여, 상기 영역에 제4 양자화 구간간격을 할당하는 단계를 포함하고, 상기 제3 양자화 구간 간격은 상기 제4 양자화 구간 간격보다 작은 것을 특징으로 하는 방법."}
{"patent_id": "10-2021-7007212", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제1항에 있어서, 상기 심층 신경망은 객체 인식을 위해 비디오 데이터를 처리하도록 구성되는 것을 특징으로 하는 방법."}
{"patent_id": "10-2021-7007212", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "칩으로서, 상기 칩은:파라미터 저장 공간-여기서 상기 파라미터 저장 공간은 심층 신경망의 파라미터를 저장하도록 구성됨- 및 특징맵 저장 공간-여기서 상기 특징 맵 저장 공간은 상기 심층 신경망의 특징 맵을 저장하도록 구성됨-을 포함하는메모리; 및제1항 내지 제15항 중 어느 한 항에 따른 방법을 수행하기 위해, 상기 메모리와 협력하도록 구성되는 심층 신경망 엔진을 포함하는 것을 특징으로 하는 칩."}
{"patent_id": "10-2021-7007212", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제16항에 있어서, 상기 메모리는 랜덤 액세스 메모리를 포함하는 것을 특징으로 하는 칩."}
{"patent_id": "10-2021-7007212", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제16항에 있어서, 상기 칩은 인공 지능 비전 칩을 포함하는 것을 특징으로 하는 칩."}
{"patent_id": "10-2021-7007212", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제18항에 있어서, 상기 칩은:이미지 신호를 처리하도록 구성된 이미지 신호 처리(ISP) 유닛; 및오디오 및 비디오 신호를 인코딩 및 디코딩하도록 구성된 멀티미디어 신호 코덱을 더 포함하는 것을 특징으로 하는 칩."}
{"patent_id": "10-2021-7007212", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "전자 장치로서, 상기 전자 장치는:이미지 및 비디오 데이터 중 어느 하나 또는 양자를 캡처하도록 구성된 이미지 센서; 및제16항 내지 제19항 중 어느 한 항에 따른 칩을 포함하고,상기 칩은 객체 인식을 위한 상기 캡처된 이미지 및 상기 비디오 데이터 중 어느 하나 또는 양자를 처리하기 위하여 심층 신경망을 사용하도록 구성되는 것을 특징으로 하는 전자 장치."}
{"patent_id": "10-2021-7007212", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_21", "content": "공개특허 10-2021-0043626-5-전자 장치로서, 상기 전자 장치는:프로세서; 및프로그램을 저장하는 메모리를 포함하고,상기 프로그램은. 상기 프로세서에 의해 실행될 경우, 상기 전자 장치가 제1항 내지 제15항 중 어느 한 항에 따른 방법을 수행하도록 하는 명령을 포함하는 것을 특징으로 하는 전자 장치."}
{"patent_id": "10-2021-7007212", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_22", "content": "프로그램을 저장하는 컴퓨터 판독 가능한 저장 매체로서, 상기 프로그램은, 프로세서에 의해 실행될 경우, 상기프로세서가 제1항 내지 제15항 중 어느 한 항에 따른 방법을 수행하도록 하는 명령을 포함하는 것을 특징으로하는 컴퓨터 판독 가능한 저장 매체."}
{"patent_id": "10-2021-7007212", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "심층 신경망용 압축 방법이 개시된다. 심층 신경망은 복수의 계층으로 구성된다. 방법은 입력 계층이 아닌 복수 의 계층 중 적어도 하나의 계층에 대해: 파라미터 저장 공간으로부터 해당되는 계층의 파라미터를 판독하 는 단계단계; 특징 맵 저장 공간으로부터 상위 계층에 의해 저장된 제1 특징 맵을 판독하는 단계; 판 독된 파라미터 및 제1 특징 맵에 기초하여 제2 특징 맵을 생성하는 단계; 제3 특징 맵을 획득하기 위해 제2 특징 맵을 압축하는 단계; 및 제3 특징 맵을 특징 맵 저장 공간에 저장하는 단계를 포함한다. 본 발명 은 또한 압축 방법에 기초한 칩, 전자 장치, 및 매체에 관한 것이다."}
{"patent_id": "10-2021-7007212", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 신경망에 관한 것으로, 보다 구체적으로 심층 신경망용 압축에 관한 것이다."}
{"patent_id": "10-2021-7007212", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "심층 신경망(DNN)은 인공 지능 기술의 핵심이다. 현재, 심층 신경망은 광범위한 연구와 주목을 받아 컴퓨터 비 전, 음성 인식, 로봇, 자율 주행 등을 포함하는 인공 지능 애플리케이션의 많은 분야에 적용된다. 심층 신경망은 입력 계층, 다수의 은닉 계층(중간 계층이라고도 함), 및 출력 계층을 포함하는 복수의 신경망 계층으로 구성된다. 현재 심층 신경망에는 일반적으로 매우 많은 수의 계층, 심지어 최대 수천 개의 계층이 있 으며 각각의 계층에는 많은 수의 노드가 포함된다. 따라서, 전체 심층 신경망에는 매우 큰 저장 공간과 메모리 대역폭이 필요한 수백만 또는 수천만 개의 파라미터가 포함될 수 있다. 이는 저장 비용을 증가시킬 뿐만 아니라 심층 신경망의 성능에도 영향을 미친다. 특히, 비디오 감시 및 자율 주행과 같은 실시간 애플리케이션의 경우 심층 신경망의 저장 문제는 성능 및 하드웨어 설계에서 병목 현상이 되고 있다."}
{"patent_id": "10-2021-7007212", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 일 측면에 따르면, 심층 신경망을 위한 압축 방법이 제공된다. 심층 신경망은 복수의 계층을 포함한 다. 방법은, 입력 계층을 제외한 복수의 계층 중 하나 이상의 계층에 대해, 파라미터 저장 공간으로부터 계층의 파라미터를 판독하는 단계; 특징 맵 저장 공간으로부터의 직전 계층에 의해 저장된 제1 특징 맵을 판독하는 단 계; 판독된 파라미터 및 제1 특징 맵에 기초하여 제2 특징 맵을 생성하는 단계; 제3 특징 맵을 획득하기 위해 제2 특징 맵을 압축하는 단계; 및 제3 특징 맵을 특징 맵 저장 공간에 저장하는 단계를 포함한다. 본 발명의 또 다른 측면에 따르면, 메모리와 심층 신경망 엔진을 포함하는 칩이 제공된다. 메모리에는 파라미터 저장 공간과 특징 맵 저장 공간이 포함되며, 파라미터 저장 공간은 심층 신경망의 파라미터를 저장하도록 구성 되고, 특징 맵 저장 공간은 심층 신경망의 특징 맵을 저장하도록 구성된다. 심층 신경망 엔진은 본 발명에 따른 방법을 수행하기 위해 메모리와 협력하도록 구성된다. 본 발명의 또 다른 측면에 따르면, 이미지 센서 및 전술한 칩을 포함하는 전자 장치가 제공된다. 이미지 센서는 이미지 및/또는 비디오 데이터를 캡처하도록 구성된다. 칩은 심층 신경망을 사용하여 캡처된 이미지 및/또는 객 체 인식을 위한 비디오 데이터를 처리하도록 구성된다. 본 발명의 또 다른 측면에 따르면, 프로세서, 및 프로그램을 저장하는 메모리를 포함하는 전자 장치가 제공된다. 프로그램은 프로세서에 의해 실행될 때 전자 장치가 본 발명에 따른 방법을 수행하게 하는 명령을 포함한다. 본 발명의 또 다른 측면에 따르면, 프로그램을 저장하는 컴퓨터 판독 가능 저장 매체가 제공된다. 프로그램은 프로세서에 의해 실행될 때 프로세서가 본 발명에 따른 방법을 수행하게 하는 명령을 포함한다."}
{"patent_id": "10-2021-7007212", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명에서, 달리 명시되지 않는 한, 다양한 요소를 설명하는 데 사용되는 용어 \"제1,\" \"제2\" 등은 이러한 요 소의 위치, 시간 또는 중요도 관계를 제한하려는 것이 아니라 하나의 구성요소를 다른 구성요소와 구별하기 위 한 것이다. 일부 실시예에서, 제1 요소 및 제2 요소는 요소의 동일한 인스턴스를 지칭할 수 있고, 일부 경우에 문맥 설명에 기초하여, 제1 요소 및 제2 요소는 또한 상이한 인스턴스를 지칭할 수 있다. 본원에서 다양한 예의 설명에 사용된 용어는 단지 특정 예를 설명하기 위한 것이며 제한하려는 의도가 아니다. 요소의 수가 구체적으로 정의되지 않은 경우, 문맥에서 달리 명시하지 않는 한 하나 이상의 요소가 있을 수 있 다. 또한, 본원에서 사용된 용어 \"및/또는\"은 나열된 항목의 임의의 및 모든 가능한 조합을 포함한다. 도 1은 예시적인 심층 신경망을 나타내는 개략도이다. 심층 신경망은 입력 계층과 출력 계층 외에 적어도 하나 의 은닉 계층을 포함하는 신경망이다. 예로서, 도 1에 도시된 심층 신경망은 입력 계층, 두 개의 은 닉 계층(120, 130), 및 출력 계층을 포함한다. 각각의 계층은 여러 노드(뉴런이라고도 함)를 포함한 다. 예로서, 도 1의 입력 계층은 3개의 노드를 가지고, 은닉 계층은 4개의 노드를 가지며, 은닉 계층 은 3개의 노드를 가지고, 출력 계층은 2개의 노드를 갖는다. 도 1은 심층 신경망의 간단한 예일뿐이 며 실제 심층 신경망의 은닉 계층 수와 각각의 계층의 노드 수는 이러한 숫자보다 훨씬 클 수 있다는 것에 주의 해야 한다. 입력 계층은 화상의 픽셀, 오디오의 진폭 샘플, 시스템 상태의 디지털 표현 등과 같은 입력 데이터를 수신 한다. 데이터는 은닉 계층으로 전파된다. 으닉 계층의 각각의 노드는 수신된 데이터를 계산하고 계산 결과를 다음 은닉 계층으로 전파한다. 유사하게, 은닉 계층의 각각의 노드는 수신된 데이터를 계산하 고 계산 결과를 출력 계층으로 전파한다. 출력 계층은 수신 된 데이터를 처리하여, 예를 들어, 특정 객체에 대한 인식 결과와 같은, 결과를 출력한다. 계층들 사이의 노드는 완전히 연결되거나 부분적으로 연결될 수 있다. 완전히 연결된 경우, 현재 계층(예: 출력 계층)의 임의의 노드는 직전 계층(예: 은닉 계층)의 모든 노드에 연결된다. 부분적으로 연결된 경우, 현재 계층 내의 하나 이상의 노드(예: 출력 계층)는 직전 계층(예: 은닉 계층)의 모든 노드가 아닌 일부에만 연결될 수 있다. 도 1에 나타난 네트워크에서, 모든 계층이 완전히 연결되어 있다. 그러나, 심층 신경 망의 적어도 일부 계층은 대안적으로 부분적으로 연결될 수 있음을 이해할 수 있다.일반적으로 은닉 계층(120, 130) 및 출력 계층의 각각의 노드는 입력 데이터에 대해 선형 또는 비선형 연 산을 수행한다. 은닉 계층에 노드가 있고, 노드에는 4개의 입력(x1, x2, x3, x4)이 있으며 출력 (y)이 있다고 가정하면,"}
{"patent_id": "10-2021-7007212", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "공식 여기서, wi는 노드(i=1,2,3,4; 그리고 일부 신경망에서, 가중치는 연결이라고도 한다. 즉, 은닉 계층 내의 각각의 노드로부터 은닉 계층의 노드로의 연결이 대응하는 가중치를 나타내는 데 사용된다)의 입력(xi)의 가중치이고, b는 노드의 편향(bias)이며, 함수는, 시그모이드(sigmoid) 함수, 쌍곡 탄젠트 (tanh) 함수, 정류된 선형 단위(ReLU, rectified linear unit) 함수, 또는 리키(leaky) ReLU 함수와 같은, 일 반적으로 비선형 함수인, 노드의 활성화 함수이다. 편향(b)도 활성화 함수도 필요하지 않으며 일부 노 드는 가중치(w)만 가질 수 있음을 이해할 수 있다. 신경망에서, 각각의 노드의 계산에 사용되는 가중치(w)와 편향(b)은 일반적으로 훈련 과정에서 연속 학습을 통 해 획득되며, 일반적으로 신경망의 파라미터라고 한다. 심층 신경망의 계층과 노드 수가 일반적으로 매우 크기 때문에, 훈련과 추론에 필요한 파라미터의 수가 많다. 예를 들어, 입력 데이터가 100 × 100 픽셀 크기의 컬러 이미지라고 가정하면, 각각의 픽셀에는 R, G, B의 세 가지 값이 있으므로, 입력 계층에는 3 × 104 노드가 있으며, 각각의 노드는 하나의 픽셀의 컬러 값을 나타낸다. 신경망의 제1 은닉 계층에 1000개의 노드가 있고 입력 계층에 완전히 연결되어 있다고 가정하면, 제1 은닉 계층의 계산에 필요한 파라미터(가중치(w) 및 편향(b))의 수는 3 × 107 + 1000이다. 계층의 수가 증가함에 따라, 그에 따라 파라미터 수가 증가한다. 추론 과정이나 신경망의 훈련 과정에서, 각각의 계층은 대응하는 파 라미터를 (다양한 랜덤 액세스 메모리 또는 DRAM, SRAM, DDR RAM, 또는 기타 랜덤 액세스 솔리드 스테이트 메모 리와 같은 휘발성 메모리일 수있는 그래픽 프로세서의 메모리와 같은) 메모리에서 판독하고/판독하거나 대응하 는 파라미터를 메모리에 저장해야 하기 때문에, 이는 메모리의 저장 용량과 메모리 대역폭에 큰 부담을 준다. 일반적인 심층 신경망은 컨볼루션(convolutional) 신경망이며, 심층 신경만의 은닉 계층에는 적어도 하나의 컨 볼루션 계층이 포함된다. 기존의 심층 신경망과 비교하면, 컨볼루션 신경망은 이미지 및 음성 인식 및 기타 측 면에서 더 나은 결과를 출력할 수 있으며 네트워크에 필요한 파라미터의 수를 줄일 수 있다. 컨볼루션 신경망의 가장 일반적인 애플리케이션은 이미지 인식이다. 다음 설명에서, 예를 들어, 입력 데이터는 이미지이다. 그러나, 당업자는 컨볼루션 신경망의 적용이 이미지 인식에 제되지 않음을 이해해야 한다. 일반적인 컨볼루션 신경망에서, 입력 이미지가 일련의 컨볼루션 계층을 통과 한 후, 선택적 풀링 계층, 및 완전 한 연결 계층, 대응하는 인식 결과가 출력될 수 있다. 도 2는 예시적인 컨볼루션 신경망을 나타내는 개략도이다. 컨볼루션 신경망은 다양한 형태를 가지고 있다는 것에 주의해야 하며, 도 2는 단순한 예시적인 표 현일 뿐이며, 본 발명의 해결책은 이에 제한되지 않는다. 도 2에 도시된 바와 같이, 컨볼루션 신경망은 입력 계층을 포함 할 수 있다. 입력 계층이 이미 지와 같은 입력 데이터를 수신하기 위해 사용될 수 있다. 선택적으로, 입력 계층은 후속 처리를 용이하게 하기 위해 데이터에 대해 전처리(예: 비 의미, 정규화, 역 상관, 미백 등)를 수행할 수 있다. 예로서, 도 2의 입력 이미지는 28 × 28 픽셀의 회색조 이미지이며, 즉, 입력 이미지의 크기는 28 × 28 × 1 이다. 각각의 픽 셀은 도 1의 입력 계층의 하나의 노드와 동일할 수 있다. 컬러 이미지가 입력되면, 컬러 이미지에는 R, G, B의 3개의 컬러 채널이 있으므로 컬러 이미지의 크기는 28 × 28 × 3이 될 것이다. 도 2에 도시된 컨볼루션 신경망은 2개의 컨볼루션 계층(220, 230)을 더 포함한다. 컨볼루션 계층(220, 230) 각각은 입력 이미지에 대한 특징 추출을 수행하기 위해 하나 이상의 컨볼루션 커널(필터라고도 함)을 사용 할 수 있다. 특히, 각각의 컨볼루션 커널(kernel)은 가중치 행렬이며, 이미지의 특징을 추출하기 위해 컨볼루션 계층에 입력된 이미지 데이터와 컨볼루션된다(convolved). 서로 다른 컨볼루션 커널은, 일반적으로 컨볼루션 계 층에서 컨볼루션 커널의 위치에 따라 다른, 수직 가장자리, 수평 가장자리, 곡선, 색상 또는 기타 낮은 수준의 특징 또는 눈, 코, 모자 또는 기타 높은 레벨의 특징과 같은 서로 다른 이미지 특징을 추출할 수 있다. 이러한 컨볼루션 연산의 출력을 특징 맵이라고 할 수 있다. 입력 계층에 대하여, 입력 계층의 특징 맵은 입 력 이미지이다. 본원에서 언급되는 \"특징 맵\"은 이미지에 기초하여 추출된 데이터에 제한되지 않으며, 컨볼루션 신경망 내의 컨볼루션 계층의 입력 및 출력 데이터에 제한되지 않는다. 다양한 심층 신경망 내 계층의 모든 입력 및 출력 데이터는 특징 맵으로 간주될 수 있다. 컨볼루션 계층은 32개의 컨볼루션 커널을 가지며, 각각의 컨볼루션 커널의 크기는 5 × 5 × 1 이다. 이는 입력 이미지가 (깊이 1을 갖는) 그레이 스케일 이미지인 경우이다. 입력 계층의 이미지가 컬러 이미지인 경우, 컨볼루션 계층의 각각의 컨볼루션 커널의 깊이는 3이며, 즉, 컨볼 루션 커널의 크기는 5 × 5 × 3 이다. 전술한 바와 같이, 컨볼루션 커널은 가중치 행렬이며, 가중치 행렬은 컨볼루션 커널에 대응하는 출력 특 징 맵을 얻기 위해 입력 이미지와 컨볼루션될 수 있다. 더 구체적으로, 컨볼루션 계층의 경우, 입력 영상 에서 5 × 5 컨볼루션 커널과 5 × 5 픽셀 블록의 내적을 수행하여 특징 값이 획득될 수 있다. 이러한 내적은 컨볼루션 커널의 각각의 가중치에 대응하는 위치의 픽셀을 곱한 다음 합산을 수행하는 것을 의미한다. 또한, 편 향(있는 경우)이 추가될 수 있다. 입력 이미지 내의 5 × 5 픽셀 블록의 위치가, 예를 들어, 좌측에서 우측으로 그리고 상부에서 하부로, 순차적으로 변경되고(단계가 1이라고 가정), 24 × 24 특징 값으로 구성된 특징 맵, 즉, 컨볼루션 커널의 출력 특징 맵을 얻을 수 있도록, 각각의 위치에서 5 × 5 픽셀 블록의 내적과 하나 및 동 일한 컨볼루션 커널이 수행된다. 컬러 이미지의 경우, 입력 이미지의 깊이와 컨볼루션 커널의 깊이는 모두 3이 다. 컨볼루션 커널의 각각의 계층이 입력 이미지의 대응하는 계층과 컨볼루션된 이후, 컨볼루션 커널의 출력 특 징 맵이 3개의 컨볼루션 결과에 대해 산술적 합산을 수행하여 획득될 수 있다. 각각의 컨볼루션 커널에 대하여, 24 × 24 크기의 특징 맵이 생성될 수 있다. 컨볼루션 계층에는 32개의 컨볼루션 커널이 있으므로, 24 × 24 크기의 총 32개의 특징 맵이 생성되거나, 또는 하나의 24 × 24 × 32 크기의 특징 맵이 생성된다. 유사하게, 컨볼루션 계층은 64개의 컨볼루션 커널을 가지며, 각각의 컨볼루션 커널의 크기는 3 × 3 × 32 이다. 각각의 컨볼루션 커널은 컨볼루션 계층에 의해 출력된 특징 맵과 컨볼루션되어 22 × 22 특징 맵이 생성된다. 따라서, 컨볼루션 계층은 22 × 22 크기의 총 64개의 특징 맵을 생성하거나, 또는 22 × 22 × 64 크기의 하나의 특징 맵을 생성한다. 컨볼루션 신경망은 또한, 도 1의 출력 계층과 유사할 수 있는, 출력 계층으로서 완전히 연결된 계층 을 포함할 수 있으며, 본원에서는 반복되지 않을 것이다. 도 2에는 완전히 연결된 계층이 하나만 표시되어 있으나, 당업자는 복수의 완전히 연결된 계층이 있을 수 있고, 각각의 완전히 연결된 계층은 서로 다른 수의 노 드를 가질 수 있음을 이해해야 한다. 도 2는 컨볼루션 신경망의 단순한 예일 뿐이라는 것을 이해해야 한다. 실제 컨볼루션 신경망에서, 컨볼루션 계 층의 수는 일반적으로 더 크다. 컨볼루션 커널을 사용하여 수행되는 연산은 내적에 제한되지 않고 디지털 신호 처리에서 일반적으로 사용되는 다양한 필터링 연산(예: 가우시안 필터, 라플라시안 필터 등을 사용하여 수행 됨)과 같이 더 복잡할 수 있다. 각각의 컨볼루션 계층에는, 도 1을 참조하여 전술한 활성화 기능과 유사할 수 있는, 활성화 함수도 포함될 수 있다. 각각의 특징 맵에 대하여, 제로 패딩 연산(zero padding operation)이 특 징 맵의 주변에서 수행되어 출력 특징 맵의 2차원 크기가 입력 특징 맵과 일치하도록 할 수 있다. 또한, 컨볼루 션 계층들 사이에 선택적인 풀링 계층(표시되지 않음)이 있을 수도 있고, 풀링 계층은 이미지 국부 상관의 원리 를 이용하여 컨볼루션 계층에서 출력된 특징 맵을 다운 샘플링하여 후속 계층의 계산량이 감소한다. 컨볼루션 신경망의 파라미터는 주로 컨볼루션 계층과 완전히 연결된 계층의 가중치와 가능한 편향이다. 일반적 인 심층 신경망의 파라미터와 유사하게, 이러한 파라미터는 훈련된 컨볼루션 신경망이 획득될 때까지 훈련을 통 해 지속적으로 최적화된다. 컨볼루션 신경망의 컨볼루션 계층 내에 있는 서로 다른 픽셀 블록이 동일한 컨볼루 션 커널을 공유할 수 있기 때문에, 그리고 컨볼루션 커널의 크기는 특징 맵(일반적으로 파라미터 공유 및 로컬 인식이라고 함)의 크기보다 훨씬 작기 때문에, 기존의 심층 신경망과 비교하면, 컨볼루션 신경망은 신경망의 파 라미터의 수를 효과적으로 감소시킬 수 있다. 그러나, 컨볼루션 신경망의 많은 계층과 각각의 계층의 컨볼루션 커널 수로 인해, 컨볼루션 신경망의 파라미터는 여전히 큰 저장 용량과 메모리 대역폭을 차지한다. 현재, 심층 신경망의 저장 문제를 해결하거나 완화하기 위한 몇 가지 연구가 있다. 한 가지 아이디어는 고 대역 폭 메모리(HBM)와 같이 대역폭이 더 큰 메모리를 사용하는 것이다. 그러나, 이러한 방식은 비용이 많이 들고 하 드웨어 설계도 매우 어렵다. 또 다른 아이디어는 심층 신경망을 압축하는 것이다. 하나의 압축 방법은 신경망의 규모를 변경하는 것이다. 예 를 들어, 신경망의 계층 수 또는 컨볼루션 커널의 수를 감소시키거나 또는 신경망에서 중요하지 않은 연결을 제 거하여 신경망이 트리밍될(trimmed) 수 있거나, 또는 행렬 또는 텐서 분해(tensor decomposition)의 아이디어가, 네트워크 스토리지 오버헤드를 감소시키기 위해, 적은 수의 파라미터로 원래 네트워크 파라미터 행 렬 또는 파라미터 텐서를 재구성하는 데 사용된다. 또 다른 압축 방법은 신경망 파라미터 자체를 압축하는 것이다. 예를 들어, 저 비트 양자화가 저장 및 계산 오버헤드를 감소시키기 위해, 64비트 부동 소수점 숫자 대신, 8비트 또는 16비트 정수를 사용하는 것과 같이 네트워크 파라미터에서 수행 될 수 있다. 대안적으로, 무손실 압 축이, 예를 들어, 압축을 위한 Huffman 코딩을 사용하여, 파라미터에 대해 수행될 수 있다. 그러나, 무손실 압 축의 압축률은 낮고 일반적으로 2:1을 초과하지 않으며 그 효과는 그다지 안정적이지 않다. 현재 심층 신경망에 대한 대부분의 압축 방법은 신경망 파라미터의 압축에 초점을 맞추고 있음을 알 수 있다. 그러나, 본 발명자들은 신경망의 파라미터에 더해 특징 맵에 대한 액세스 또한 큰 저장 용량과 메모리 대역폭을 차지한다는 것을 인지하였다. 특히, 심층 신경망의 추론 및 훈련 과정에서, 각각의 계층에서 생성 된 특징 맵은 다음 계층에서 판독하고 사용할 수 있도록 메모리(예: 다양한 랜덤 액세스 메모리 또는 DRAM, SRAM, DDR RAM 또 는 기타 랜덤 액세스 솔리드 스테이트 메모리와 같은 휘발성 메모리)에 저장되어야 한다. 입력 데이터가 많은 경우(예: 입력 이미지의 해상도가 높음), 특징 맵에 대한 액세스는 또한 많은 양의 저장 공간과 메모리 대역폭 을 소비하며, 파라미터의 액세스보다 더 많은 메모리 리소스를 사용한다. 이는 신경망의 응용, 특히 신경망의 실시간 응용에있어 큰 도전이다. 이를 위해, 본 발명은, 기존의 신경망 압축 기술보다 신경망의 대용량 데이터를 실시간으로 적용하는 데 더 적 합한, 심층 신경망을 위한 새로운 압축 방법을 제안한다. 도 3은 본 발명의 예시적인 실시예에 따른 심층 신경망을 위한 예시적인 압축 방법을 도시하는 흐름도이다. 방법은 입력 계층을 제외한 심층 신경망의 임의의 계층에 대해 수행될 수 있다. 설명의 편의 를 위해 제i 계층을 예로 들어 설명한다. 블록에서, 제i 계층은 파라미터 저장 공간으로부터 계산을 위해 계층에 필요한 파라미터를 판독한다. 파라 미터는, 도 1과 관련하여 설명된 각각의 노드에 의해 사용된 가중치(w)와 편항(b) 또는 도 2와 관련하여 설명된 각각의 컨볼루션 커널의 가중치와 편향과 같은, 심층 신경망의 파라미터일 수 있다. 일 실시예에 따르면, 블록 내의 파라미터 저장 공간으로부터 판독된 파라미터는 압축된 파라미터일 수 있 다. 파라미터 압축 방식은, 예를 들어, 무손실 압축(예를 들어, Huffman 코딩) 또는 손실 압축일 수 있다. 블록에서, 제i 계층은 특징 맵 저장 공간으로부터 제(i-1) 계층에 의해 저장된 제1 특징 맵을 판독한다. 제1 특징 맵은 신경망의 모든 계층에서 출력되는 데이터일 수 있다. 예를 들어, 제1 특징 맵은, 도 1의 입력 계 층, 은닉 계층, 은닉 계층에 의해 출력된 데이터, 또는 도 2의 입력 계층, 컨볼루션 계층 및 컨볼루션 계층에 의해 출력된 데이터, 또는 풀링 계층, 완전히 연결된 계층 등에 의해 출력된 데 이터일 수 있다. 일 실시예에 따르면, 제1 특징 맵은 압축된 특징 맵일 수 있다. 특히, 제(i-1) 계층에 의해 생성된 특징 맵이 압축되여 특징 맵 저장 공간에 저장될 수 있고, 따라서, 제i 계층이 판독하는 제1 특징 맵은 압축된 특징 맵이 다. 또 다른 실시예에 따르면, 제1 특징 맵은 대안적으로 압축되지 않은 특징 맵일 수 있다. 예를 들어, 제(i- 1) 계층에 의해 생성된 특징 맵은 압축되지 않고 특징 맵 저장 공간에 직접 저장된다. 블록에서, 제i 계층은 판독 파라미터와 제1 특징 맵에 기초하여 제2 특징 맵을 생성한다. 일 실시예에 따 르면, 판독 파라미터가 압축된 파라미터인 경우, 파라미터가 압축 해제된 다음 제i 계층의 계산에 사용될 수 있 다. 또 다른 실시예에 따르면, 제1 판독 특징 맵이 압축된 특징 맵인 경우, 제1 특징 맵은 압축 해제된 다음 제 i 계층의 계산에 사용될 수 있다. 생성의 예를 들어, 제i 계층에 의해, 제(i-1) 계층의 특징 맵과 대응하는 파 라미터에 기초하여 한 제2 특징 맵, 참조가, 각각의 노드가 공식을 사용하여 노드의 출력을 생성할 수"}
{"patent_id": "10-2021-7007212", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "있으며 각각의 계층의 모든 노드의 출력을 요약한 후 계층에서 생성된 특징 맵이 획득될 수 있는, 도 1과 연계 하여 설명될 수 있다. 생성의 예에 대해, 제i 계층에 의해, 제(i-1) 계층의 특징 맵과 대응하는 파라미터에 기 초하여 한 제2 특징 맵, 참조가, 각각의 게층의 컨볼루션 커널이 직전 계층의 특징 맵과 컨볼루션되어 컨볼루션 커널에 대응하는 특징 맵을 생성할 수 있는, 도 2와 연계하여 설명될 수 있다. 계층에 복수의 컨볼루션 커널이 있는 경우, 복수의 특징 맵이 생성될 수 있거나, 복수의 특징 맵이 고차원 특징 맵으로 결합될 수 있다. 이는 특징 맵을 생성하는 예일 뿐이며, 블록에서 제2 특징 맵을 생성하는 구현은 이에 제한되지 않음을 이해할 수 있다. 블록에서, 제i 계층은 제3 특징 맵을 획득하기 위해 블록에서 생성된 제2 특징 맵을 압축한다. 제2 특징 맵의 압축은 무손실 압축일 수 있으며, 보다 바람직하게는 손실 압축일 수 있으며, 이에 대해서는 아래에 서 더 자세히 설명한다. 일 실시예에 따르면, 상기 제2 특징 맵을 압축하는 단계는 다른 압축 비율로 제2 특징 맵의 다른 영역들을 압축 하는 것을 포함할 수 있으며, 각각의 영역의 압축비는 영역의 관심도에 의존한다. 일 실시예에서, 관심도가 높은 영역(예: 제1 관심도)의 압축비는 관심도가 낮은 영역(예: 제1 관심도보다 낮은 제2 관심도)의 압축비보다 작다. 예를 들어, 신경망에 의해 처리되는 객체가 이미지 또는 비디오일 경우, 이미지의 관심 영역(즉, 인물 사 진과 같이 관심도가 높은 영역)에 대하여, 일반적으로 영역의 압축 및 압축 해제 후 얻은 이미지는 원본 이미지 와 높은 유사성을 갖는 것이 바람직하며, 이런 이유로, 정보 손실을 감소시키기 위해 작은 압축 비율이 사용될 수 있으며, 이미지에서 관심이 없는 영역(즉, 하늘과 같이 관심도가 낮은 영역)의 경우, 영역의 압축 및 압축 해제 후 얻은 이미지와 원본 이미지 사이의 유사성에 대한 요구 사항이 감소할 수 있고, 이런 이유로, 큰 압축 비율이 사용될 수 있다. 유사성 측정 파라미터는, 예를 들어, 유클리드 거리, 피크 신호 대 잡음비(PSNR), 구조 적 유사성 평가(SSIM) 등일 수 있다. 블록에서, 제i 계층은 블록에서 획득된 제3 특징 맵을 특징 맵 저장 공간에 저장한다. 파라미터 저장 공간과 특징 맵 저장 공간은 별도의 메모리에 위치하거나 동일한 메모리를 공유할 수 있다. 예로서, 파라미터 저장 공간 및 특징 맵 저장 공간에 사용되는 메모리는 DRAM, SRAM, DDR RAM, 또는 기타 랜덤 액세스 솔리드 스 테이트 메모리와 같은 고속 랜덤 액세스 메모리일 수 있다. 방법은 심층 신경망의 추론 과정과 심층 신경망의 훈련 과정 모두에 적용될 수 있다. 이는 도 5 및 6과 함 께 나중에 더 자세히 설명될 것이다. 방법을 사용하여, 심층 신경망의 적어도 하나의 계층에 의해 생성된 특징 맵이 압축하여 저장되므로, 특징 맵에 필요한 저장 공간과 동일한 메모리 대역폭이 크게 감소될 수 있다. 이는 신경망의 실시간 적용에 특히 유 용하다. 예를 들어, 비디오 감시의 응용 시나리오에서, 신경망을 사용하여 비디오 이미지의 물체를 실시간으로 인식하면, 많은 수의 비디오 프레임이 실시간으로 처리되어야 한다. 비디오 데이터의 해상도가 높은 경우(예: 300 × 300 픽셀 이상), 이는 메모리 대역폭에 큰 도전을 가져올 것이다. 동일하게 저장하기 전에 특징 맵을 압 축함으로써, 특징 맵을 메모리에 저장하고 판독할 때 차지하는 메모리 대역폭을 크게 감소시킬 수 있어 신경망 의 실시간 적용을 실현하는 데 도움이 된다. 또한, 판독 압축된 특징 맵은 계산을 위해 압축 해제되기 때문에 (예: 컨볼루션), 방법은 신경망의 추론 정확도에 거의 영향을 미치지 않는다. 방법은, 또한 신경망의 동작을 더욱 가속화하고 메모리의 전력 소비를 감소시키기 위해, 신경망 파라미터의 압축 및 대응하는 하드웨어 설계와 결합될 수 있다. 방법은 임의의 심층 신경망에 적용 가능하다. 컨볼루션 신경망에 대해, 방법은 적어도 하나의 컨볼루 션 계층에 대해 수행될 수 있다. 선택적으로, 방법은 풀링 계층 및 완전히 연결된 계층에 대해 대안적으로 수행될 수 있다. 컨볼루션 신경망에 대해, 방법은 모든 컨볼루션 계층에 대해 수행될 수 있거나, 또는 방 법이 일부 컨볼루션 계층에 대해 선택적으로 수행될 수 있다. 일반적으로, 입력 측에 가까운 컨볼루션 계 층에서 생성된 특징 맵은 출력 측에 가까운 컨볼루션 계층에서 생성된 특징 맵보다 크고 더 많은 저장 공간과 메모리 대역폭을 차지한다. 따라서, 방법은 입력 측에 가까운 하나 이상의 컨볼루션 층에 우선적으로 적용 될 수 있다. 논리적으로 필요하지 않는 한, 방법의 단계들의 순서는 도시되거나 설명된 순서에 제한되지 않고 필요에 따라 조정되거나 병렬로 수행될 수 있다는 것에 유의해야 하며, 다른 단계의 동작은 병렬로 또는 인터리브 방식 으로 수행될 수 있다. 본 발명은 이에 대해 어떠한 제한도 부과하지 않는다. 예를 들어, 블록 및 블록"}
{"patent_id": "10-2021-7007212", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "은 본 발명의 내용의 구현에 영향을 주지 않고 역순으로 또는 병렬로 수행될 수 있다. 다음은 특징 맵의 압축을 더 자세히 설명하기 위해 비디오 데이터를 신경망에 대한 입력으로 사용한다. 특징 맵 의 압축은, 도 3과 함께 설명된, 제(i-1) 계층, 제i 계층, 또는 모든 계층과 같은, 신경망의 임의의 계층에 적 용될 수 있다. 도 4는 본 발명의 예시적인 실시예에 따라 특징 맵을 압축하는 것을 나타내는 개략적인 블록도이다. 도 4에 도 시된 바와 같이, 예측(블록 410), 변환(블록 420), 양자화(블록 430) 및 엔트로피 코딩(블록 440)과 같은 동작 이 신경망의 계층에 의해 생성된 특징 맵에서 수행되어 특징 맵에서 공간 중복성, 시간 중복성, 및 코딩 중복성 이 제거될 수 있다. 도 4의 이러한 동작은 아래에서 차례로 설명될 것이다. 그러나, 도 4의 모든 동작이 본원에 필요한 것은 아니며, 하나 이상의 블록 (410 내지 440)이 필요에 따라 특징 맵을 압축하는 데 사용될 수 있음을 이해할 수있다. 예를 들어, 특징 맵에서 무손실 압축이 수행되는 경우, 양자화는 특징 맵에서 수행되지 않 거나, 또는 엔트로피 코딩만이 특징 맵에서 수행될 수 있다. 또 다른 예에 대해, 특징 맵의 압축은 변환 , 양자화, 및 엔트로피 코딩만을 포함할 수 있으며, 예측이 수행되지 않을 수 있다. 블록에서, 입력 특징 맵에서 예측 코딩이 수행된다. 예측 코딩은 인트라 예측(intra prediction) 및 인터 예측(inter prediction) 중 하나 또는 양쪽 모두를 포함할 수 있다. 인트라 프레임 코딩을 사용하여 공간 중복 이 제거될 수 있고 인터 프레임 코딩을 사용하여 시간 중복이 제거될 수 있다. 특징 맵은 복수의 블록으로 분할 될 수 있으며, 블록별로 코딩이 수행된다. 예로서, MPEG, H.264, 및 H.265와 같은 비디오 표준에서 채택된 다양 한 예측 코딩 기술은 블록에서 특징 맵의 예측 코딩에 사용될 수 있다. 블록에서, 특징 맵은 공간 영역에서 주파수 영역으로 변환되어 신호들 간의 상관 관계를 효과적으로 제거 하고 대부분의 에너지를 저주파 영역에 집중시킨다. 변환 결과에 따라, 고주파 영역의 신호는 후속 양자화 구간 간격(quantization step)에서 폐기될 수 있거나, 또는 저주파 영역에 대한 더 작은 양자화 구간 간격과 고주파 영역에 대한 더 큰 양자화 구간 간격은 큰 압축 비율을 달성하면서 높은 이미지 품질을 유지하는 데 사용될 수 있다. 예로서, 이산 푸리에 변환(DCT), 이산 사인 변환(DST), K-L 변환, 웨이블릿 변환 등과 같은 다양한 변환 기술을 사용하여 특징 맵이 변환될 수 있다. 블록에서, 블록에서 획득된 변환 계수가 양자화된다. 양자화에서, 적은 수의 양자화 값을 사용하여 많은 수의 변환 계수가 대략적으로 나타날 수 있다. 원래의 변환 계수와 재구성된 변환 계수 사이에 차이가 있 으므로, 즉, 왜곡이 있으므로, 양자화를 사용하는 특징 맵 압축은 손실 압축이다. 무손실 압축에 비해, 손실 압 축은 더 많은 알고리즘과 더 조정 가능한 압축 파라미터를 가지고 있으며 압축 비율을 제어하여 다양한 요구 사 항에 적용될 수 있다. 본 발명의 실시예에 따르면, 손실 압축을 사용하면 신경망 추론의 정확도에 거의 영향을 미치지 않으면 서 더 큰 압축 비율이 얻어질 수 있다. 예를 들어, 일 실시예에 따르면, 손실 압축의 압축 비율 이 10:1 보다 큰 경우, 신경망의 추론 정확도가 5% 미만으로 감소한다. 또한, 훈련 과정에서, 계층의 특징 맵에 손실 압축을 수행하는 것은 파라미터 및 계층의 특징 맵에 장애를 추가하는 것과 동일할 수 있으며, 이는 훈련 이 로컬 최소값으로 떨어지는 것을 방지할 수 있으므로, 신경망의 추론 능력이 향상될 수 있다. 블록에서, 블록의 양자화 결과에 대해 엔트로피 코딩을 수행하여 예측 및 변환 후에도 여전히 존재하 는 통계적 중복 정보가 제거된다. 예로서, 엔트로피 코딩은 가변 길이 코딩(VLC)(예를 들어, Huffman 코딩, 지 수 Golomb 코드 (EGC) 등) 또는 산술 코딩을 사용할 수 있다. 특징 맵의 압축 과정은 도 4와 함께 위에서 간략하게 설명되었다. 당업자는 이러한 설명이 본 발명에 대한 제한 이 아닌 단지 예시적인 설명이라는 것을 이해할 수 있다. 특정 구현에서, 특징 맵은, MPEG, H.264, H.265 및 기 타 비디오 표준에 기초하여 하는 압축 방법 또는 현재 개발 중이거나 향후 개발될 다양한 영상 압축 방식과 같 은, 알려진 다양한 비디오 압축 방법을 사용하여 압축될 수 있다. 이는 본 발명에 제한되지 않는다. 본 발명의 일 실시예에 따르면, 특징 맵 압축(예를 들어, 도 3의 블록에 도시된 제2 특징 맵 압축)은 특징 맵의 비균일 양자화(non-uniform quantization)를 포함할 수 있다. 일 실시예에 따르면, 특징 맵의 다른 영역에 대해 다른 양자화 구간 간격이 사용될 수 있다. 각각의 영역의 양자화 구간 간격을 결정하기 위해 많은 요인이 고려될 수 있다. 일 실시예에 따르면, 영역의 양자화 구간 간격은 영역의 이미지 복잡도에 따라 결정될 수 있다. 예를 들어, 작 은 양자화 구간 간격은 더 많은 세부 사항을 유지하기 위해 이미지 복잡도가 높은 영역에 할당되고, 큰 양자화 구간 간격은 이미지 복잡도가 낮은 영역에 할당된다. 일 예에서, 이미지 복잡도는 미리 설정된 임계값으로 측정 될 수 있다. 높은 이미지 복잡도는 이미지 복잡도가 미리 설정된 임계값보다 크다는 것을 의미하고, 낮은 이미 지 복잡도는 이미지 복잡도가 미리 설정된 임계값보다 작거나 같음을 의미할 수 있다. 또 다른 실시예에 따르면, 영역의 양자화 구간 간격은 특징 맵에서 영역의 위치에 따라 결정될 수 있다. 예를 들어, 비디오 감시 애플리케이션의 경우, 각각의 비디오 카메라에 의해 특별히 모니터링되는 영역은 이미지 내 에서 상대적으로 고정된 위치를 가질 수 있으며, 위치에 대응하는 특징 맵 영역에는 작은 양자화 구간 간격이 할당될 수 있다. 또 다른 실시예에 따르면, 영역의 양자화 구간 간격은 영역의 중요도에 따라 결정될 수 있다. 예를 들어, 비디 오 이미지에 대하여, 영상에서 영역의 중요도를 미리 결정할 수 있으며, 양자화 중 중요도의 순서에 따라 다른 양자화 구간 간격이 할당될 수있다. 또 다른 실시예에 따르면, 영역의 양자화 구간 간격은 영역의 특정한 특징의 존재 또는 부재에 따라 결정될 수 있다. 특정한 특징은 신경망의 애플리케이션 시나리오에 의존할 수 있다. 일 실시예에 따르면, 특정한 특징은 애플리케이션 시나리오에서 관심있는 기능일 수 있다. 예를 들어, 보안 모니터링의 경우, 특정한 특징은 사람 또는 신원과 관련된 기능일 수 있고, 교통 모니터링의 경우, 구체적인 특징은 차량 모델, 번호판, 신호등 등과 관련된 특징일 수 있으며, 축구 경기 생중계의 경우, 특정한 특징은 선수, 공, 심판, 골 등과 관련된 특징일 수있다. 일 예에서, 특정한 특징이 영역 내에 존재하는 경우, 작은 양자화 구간 간격(예: 제1 양자화 구간 간격) 이 더 자세한 내용을 유지하기 위해 영역에 할당될 수 있으며, 영역 내에 특정한 특징이없는 경우, 큰 양자화 구간 간격(예를 들어, 제1 양자화 구간 간격보다 큰 제2 양자화 구간 간격)이 영역에 할당될 수 있다. 또 다른 실시예에 따르면, 영역의 양자화 구간 간격은 영역 내의 특정한 특징의 수에 따라 결정될 수 있다. 일 예에서, 영역 내의 특정한 특징의 수가 많은 경우(예: 미리 결정된 임계값보다 큰 경우), 작은 양자화 구간 간 격(예를 들어, 제3 양자화 구간 간격)이 더 많은 세부 사항을 유지하기 위해 영역에 할당될 수 있으며, 영역의 특정한 특징의 수가 적은 경우(예: 미리 결정된 임계값 이하), 큰 양자화 구간 간격(예를 들어, 제3 양자화 구 간 간격보다 큰 제4 양자화 구간 간격)이 영역에 할당될 수 있다. 이전 실시 예와 유사하게, 특정한 특징은 본 원에서 반복되지 않을 애플리케이션 시나리오에 의존할 수 있다. 위에서 언급한 이러한 요소들은 개별적으로 또는 조합으로 고려될 수 있음을 이해할 수 있다. 이는 본원에 제한 되지 않는다. 영역의 특징에 따른 특징 맵의 영역에 다른 양자화 구간 간격이 할당되고, 이는 높은 압축률을 달 성할 수 있을 뿐만 아니라 애플리케이션에 중요한 특징 맵의 세부 사항을 가능한 한 많이 유지할 수 있게 하여, 신경망의 추론 정확도가 유지된다. 다음은 도 5 및 도 6과 관련하여 본 발명의 일 실시예에 따른 신경망의 추론 과정 및 훈련 과정을 설명한다. 도 5는 본 발명의 예시적인 실시예에 따른 심층 신경망의 추론 프로세스의 개략도이다. 신경망의 추론 과정은 처리 할 데이터를 훈련 된 신경망에 입력하여 추론 결과를 얻는 과정이다. 도 5에 도시된 바와 같이, 심층 신경망은 입력 계층, 출력 계층, 및 복수의 은닉 계층을 포함한다. 단순함을 위해, 도 5는 2개의 인접한 계층 인, 제i 계층과 제(i+1) 계층만을 도시하며, 이들은 각각 참조 번호 534 및 536으로 도시된다. 도 5는 또한 파 라미터 저장 공간 및 특징 맵 저장 공간을 도시한다. 추론 과정에서, 신경망의 각각의 계층은 출력 계층이 최종 추론 결과를 출력할 때까지 들어오는 데이터를 순차적으로 처리한다. 계층(534, 536)에서의 처리는 예로서 아래에서 설명될 것이다. 도 5에 도시된 바와 같이, 제i 계층은 파라미터 저장 공간으로부터의 계산을 위해 계층에 의해 요구되는 파라미터를 판독한다. 선택적으로, 파라미터가 압축되면, 파라미터는 블록 내에 서 압축 해제된다. 계층은 또한 특징 맵 저장 공간으로부터 제(i-1) 계층에 의해 저장된 특징 맵 을 판독한다. 선택적으로, 특징 맵이 압축되면, 블록내에서 특징 맵이 압축 해제된다. 파 라미터 및 특징 맵의 압축 해제된 버전에 기초하여, 계층의 특징 맵이 생성된다. (블록에 서) 특징 맵이 압축된 후, 특징 맵은 계층에 의해 저장된 특징 맵으로서 특징 맵 저장 공간에 저장된다. 다음으로, 제(i+1) 계층은 제i 계층과 유사한 동작을 수행한다. 파라미터 및 특징 맵은 각 각 파라미터 저장 공간으로부터 판독되고 특징 맵 저장 공간이 (블록(544, 556)에 도시된대로) 압축 해제된다. 이어서, 파라미터 및 특징 맵의 압축 해제된 버전에 기초하여, 계층의 특징 맵이 생 성된다. (블록에서) 특징 맵이 압축된 후, 특징 맵은 다음 계층에서의 사용을 위해 계층에 의해 저장 된 특징 맵으로서 특징 맵 저장 공간 내에 저장된다. 비유하면, 신경망의 후속 계층은 출력 계층이 최종 추론 결과를 출력 할 때까지 위의 작업을 순서대로 수 행한다. 비록 도 5는 앞에서 언급했듯이 파라미터의 압축 및 압축 해제와 각각의 계층의 특징 맵을 설명하지만, 이러한 압축 및 압축 해제 작업은 신경망의 일부 계층에서만 수행될 수 있으며, 대안적으로, 압축 및 압축 해제 작업은 파라미터 대신 특징 맵에서만 수행될 수 있음을 이해해야 한다. 도 6은 본 발명의 예시적인 실시예에 따른 심층 신경망의 훈련 과정의 개략도이다. 신경망의 훈련 과정은 알려 진 샘플 세트에 기초하여 신경망의 파라미터를 훈련시키는 과정이다. 신경망의 훈련 과정은 최종 출력 결과와 목표 값 사이의 오차가 미리 결정된 임계값 미만이 될 때까지 계속 반복된다. 각각의 반복은 일반적으로 순전파 위상(forward propagation phase)과 역전파 위상(back propagation phase)의 2개의 위상으로 분할된다. 순전파 위상은 추론 프로세스와 유사하다. 각각의 샘플에 대하여, 각각의 계층은 최종 출력 값을 얻기 위해 순차적으로 계산을 수행한다. 다음으로, 역전파 위상에서, 출력 값과 목표 값 사이의 오차가 먼저 계산된다. 오차가 미리 결정된 임계값보다 큰 경우, 오차는 역방향 전파를 위해 출력 계층으로부터 신경망으로 전송되며, 계층의 오차 가 순서대로 계산되고 계산된 오차에 따라 계층의 파라미터가 업데이트된다. 업데이트된 파라미터에 따라 다음 반복의 순전파 위상이 시작된다. 도 6에서, 명확성을 위해, 점선은 순전파 위상과 역전파 위상을 분리하는데 사용된다. 도 6의 상단에서 볼 수 있듯이, 훈련 과정의 순전파 위상은 도 5와 같으며 본원에서 자세한 내용은 반복하지 않는다. 도 6의 하단은 훈련 과정의 역전파 위상을 도시한다. 역전파 위상에서, 순전파 위상에서 최종 출력 값과 목표 값 사이의 오차 는 출력 계층에서 입력 계층으로 순차적으로 전송된다. 제(i+1) 계층은 제(i+2) 계층으로부터 수신된 계층의 오차에 기초하여 업데이트된 파라미터를 계산하여 파라미터 저장 공간에 저장한 다. 선택적으로, 업데이트된 파라미터는 (블록에서) 압축되어 파라미터 저장 공간에 저장될 수 있다. 계층은 또한 제i 계층의 오차를 계산하고 동일한 것을 계층으로 다시 전파한다. 유사하게, 계층 은 수신된 오차에 기초하여 업데이트된 파라미터를 계산하고,이를 파라미터 저장 공간에 저장한 다. 선택적으로, 업데이트된 파라미터는 (블록에서) 압축된 후 파라미터 저장 공간 내에 저장될 수 있다. 도 6의 좌측의 큰 화살표에서 볼 수 있듯이, 역전파 위상이 입력 계층에서 종료될 경우, 훈련 프로 세스는 모든 계층의 업데이트된 파라미터에 기초하여 다음 반복의 순전파 위상을 시작한다. 도 5 및 6은 신경망의 예시적인 추론 과정 및 훈련 과정만을 도시한다는 것에 유의해야 한다. 당업자는, 신경망 의 다른 구조에 기초하여, 다른 대응하는 추론 프로세스 및 훈련 프로세스가 사용될 수 있음을 이해할 수 있다. 도 7은 본 발명의 예시적인 실시예에 따른 칩을 도시하는 개략도이다. 칩은 메모리 및 심층 신 경망 엔진을 포함할 수 있다. 메모리는 파라미터 저장 공간 및 특징 맵 저장 공간을 포함할 수 있다. 파라미터 저장 공간은 심층 신경망 의 파라미터를 저장하는 데 사용되며, 특징 맵 저장 공간은 심층 신경망의 특징 맵을 저장하는 데 사용된다. 일 실시예에 따르면, 메모리는 다양한 랜덤 액세스 메모리 또는 DRAM, SRAM, DDR RAM, 또는 기타 랜덤 액세스 솔리드 스테이트 메모리와 같은 휘발성 메모리일 수 있다. 심층 신경망 엔진은 심층 신경망을 이미지 데이터와 같은 입력 데이터에 적용하여 이미지 감지, 인식, 분 할과 같은 동작을 구현할 수 있다. 심층 신경망 엔진은 메모리와 협력하여 전술한 바와 같은 본 발명 의 다양한 실시예에서의 방법을 수행할 수 있다. 일 실시예에 따르면, 심층 신경망 엔진은, 예를 들어, 애 플리케이션 특정 집적 회로(ASIC, application-specific integrated circuit)에 의해 구현되는 하드웨어로 구 현될 수 있다. 특정 요구 사항에 따라 심층 신경망 엔진의 구현에 다양한 변형이 이루어질 수 있음을 이해해야 한다. 예 를 들어, 다양한 변형은 하드웨어, 소프트웨어, 펌웨어, 미들웨어, 마이크로 코드, 하드웨어 기술 언어, 또는 이들의 임의의 조합으로 구현될 수 있다. 예를 들어, 심층 신경망 엔진은, ASIC 대신 본 발명에 따른 로직 및 알고리즘을 사용하여, (VERILOG, VHDL, 및 C++와 같은) 어셈블리 언어 또는 하드웨어 프로그래밍 언어로 하 드웨어를 프로그래밍함(예를 들어, 필드 프로그래밍 가능 게이트 어레이(FPGA, field programmable gate array) 및/또는 프로그래밍 가능한 논리 어레이(PLA, programmable logic array)를 포함하는 프로그래밍 가능 논리 회로)으로써 구현될 수 있다. 일 실시예에 따르면, 칩은 인공 지능(AI) 비전 칩일 수 있다. 또한, 도 7에는 도시되지 않으나, 칩은, (이미지 센서에 의해 출력되는 신호와 같은) 이미지 신호를 처리하도록 구성된 이미지 신호 처리 (ISP) 장치, 오디오 및 비디오 신호 등을 인코딩 및 디코딩하도록 구성된 멀티미디어 신호와 같은, 다른 구성요 소를 더 포함할 수 있다. 도 8은 본 발명의 예시적인 실시예에 따른 전자 장치를 도시하는 개략도이다. 전자 장치는 도 7에 도 시된 칩 및 이미지 센서를 포함할 수 있다. 이미지 센서는 이미지 및/또는 비디오 데이터를 캡 처하도록 구성될 수 있다. 일 실시예에 따르면, 전자 장치는 비디오 카메라 또는 AI 비전 칩이 통합된 카 메라일 수 있다. 이러한 전자 장치는 다양한 시나리오(예: 보안 모니터링에서 사람 얼굴 또는 기타 특정 물체의 자동 감지 및 인식, 보행자, 자동차, 교통 표지판 등의 실시간 감지 및 인식, 자율 주행에서 로봇의 물 체 인식 및 장애물 회피 지원 등)에서 사용될 수 있다. 도 9는 본 발명의 예시적인 실시예에 따른 다른 전자 장치를 도시하는 개략도이다. 전자 장치는, 워 크 스테이션, 서버, 데스크톱 컴퓨터, 랩톱 컴퓨터, 태블릿 컴퓨터, 개인용 정보 단말기, 스마트폰, 온보드 컴 퓨터, 또는 이들의 조합일 수 있는, 처리 및/또는 계산을 수행하도록 구성된 임의의 머신일 수 있으나, 이들에 제한되지는 않는다. 본 발명의 실시예들에 따른 전술한 방법은 전자 장치 또는 유사한 장치 또는 시스템에 의해 전체적으로 또는 적어도 부분적으로 구현될 수 있다. 전자 장치는 버스, 하나 이상의 프로세서, 하나 이상의 메모리, 하나 이상의 입력 장치 , 및 하나 이상의 출력 장치를 포함할 수 있다. 하나 이상의 프로세서는 임의의 유형의 프로세서일 수 있으며, 하나 이상의 범용 프로세서(예: 중앙 처리 장치(CPU)) 및/또는 하나 이상의 전용 프로세서(예: 그래픽 처리 장치(GPU))를 포함할 수 있지만 이에 제한되지 않는다. 하나 이상의 메모리는 비 휘발성 메모 리(예: 디스크 드라이브, 광학 저장 장치, 솔리드 스테이트 메모리, 플로피 디스크, 하드 디스크, 자기 테이프, 및 판독 전용 메모리(ROM)) 및/또는 휘발성 메모리(예: 랜덤 액세스 메모리(RAM) 및 캐시 메모리)를 포함할 수 있다. 메모리는 본 발명의 실시예들에 따른 방법을 구현하기위한 데이터 및/또는 프로그램을 저장할 수 있 다. 메모리 내에 저장된 데이터는, 예를 들어, 도 5 및 도 6에 도시된 파라미터 저장 공간 및 특징 맵 저 장 공간의 데이터이다. 메모리 내에 저장된 프로그램은 프로세서에 의해 실행될 때, 전자 장치 가 본 발명의 실시예에 따른 방법을 수행하게 할 수 있다. 입력 장치는 전자 장치에 정보를 입력할 수 있는 임의의 유형의 장치일 수 있으며, 센서(예: 전술한 이미지 센서), 마우스, 키보드, 터치 스크린, 마이크, 및/또는 원격 제어기를 포함할 수 있지만 이에 제한되지 는 않는다. 출력 장치는 정보를 출력할 수있는 임의의 유형의 장치일 수 있으며, 디스플레이, 스피커, 비 디오/오디오 출력 단자, 진동기, 및/또는 다양한 출력 인터페이스를 포함할 수 있지만 이에 제한되지는 않는다. 전자 장치의 하나 이상의 구성요소가 네트워크 상에 분산될 수 있다는 것을 이해해야 한다. 예를 들어, 일 부 처리는 하나의 프로세서에 의해 실행될 수 있는 반면, 다른 처리는 하나의 프로세서에서 떨어진 다른 프로세 서에 의해 실행될 수 있다. 따라서, 전자 장치는 복수의 위치에서 처리를 수행하는 분산 컴퓨팅 시스템으 로 해석될 수 있다. 또한, 본 발명의 측면은 프로그램을 저장하는 컴퓨터 판독 가능 저장 매체를 포함할 수 있으며, 프로그램은 프 로세서에 의해 실행될 때 프로세서가 전술한 방법 중 임의의 것을 수행하게 하는 명령을 포함한다. 본 발명의 일부 측면에 따른 예시적인 방법 및 제품의 실시 양태는 다음 항목에 나열된다. 1. 복수의 계층을 포함하는, 심층 신경망을 위한 압축 방법으로서, 상기 방법은, 입력 계층을 제외한 복수의 계 층 중 하나 이상의 계층에 대하여: 파라미터 저장 공간으로부터 계층의 파라미터를 판독하는 단계; 직전 계층에 의해 저장된 제1 특징 맵을 특징 맵 저장 공간으로부터 판독하는 단계; 판독된 파라미터 및 제1 특징 맵에 기초 하여 제2 특징 맵을 생성하는 단계; 제3 특징 맵을 얻기 위해 제2 특징 맵을 압축하는 단계; 및 특징 맵 저장 공간 내에 제3 특징 맵을 저장하는 단계를 포함한다. 2. 항목 1에 따른 방법에 있어서, 제2 특징 맵에 대하여 수행된 압축에는 손실 압축이 포함된다. 3. 항목 1에 따른 방법에 있어서, 방법은 심층 신경망의 훈련 과정 및 심층 신경망의 추론 과정에서 순전파 위 상에 사용된다. 4. 항목 1에 따른 방법에 있어서, 심층 신경망은 컨볼루션 신경망을 포함하고, 컨볼루션 신경망은 복수의 컨볼 루션 계층을 포함하며, 방법은 컨볼루션 계층들 중 적어도 하나에 대해 수행된다. 5. 항목 1에 따른 방법에 있어서, 제1 특징 맵은 압축된 특징 맵이고, 상기 판독된 파라미터 및 제1 특징 맵에 기초하여 제2 특징 맵을 생성하는 단계는: 제1 특징 맵을 압축 해제하는 단계; 및 판독된 파라미터 및 압축 해 제된 제1 특징 맵에 기초하여, 제2 특징 맵을 생성하는 단계를 포함한다. 6. 항목 1에 따른 방법에 있어서, 파라미터 저장 공간으로부터 판독된 파라미터는 압축된 파라미터이고, 상기 판독된 파라미터 및 제1 특징 맵에 기초하여 제2 특징 맵을 생성하는 단계는: 판독된 파라미터의 압축을 해제하 는 단계; 및 압축 해제된 파라미터 및 제1 특징 맵에 기초하여 제2 특징 맵을 생성하는 단계를 포함한다. 7. 항목 2에 따른 방법에 있어서, 상기 제2 특징 맵을 압축하는 단계는: 제2 특징 맵을 공간 도메인으로부터 주 파수 도메인으로 변환하는 단계; 및 변환 계수를 양자화하는 단계를 포함한다. 8. 항목 2에 따른 방법에 있어서, 상기 제2 특징 맵을 압축하는 단계는: 제2 특징 맵에서 예측 코딩을 수행하는 단계를 포함하고, 예측 코딩은 인트라 예측 및/또는 인터 예측을 포함한다. 9. 항목 2에 따른 방법에 있어서, 상기 제2 특징 맵을 압축하는 단계는 다른 압축 비율로 제2 특징 맵의 다른 영역을 압축하는 단계를 포함하고, 다른 영역 각각의 압축비율은 해당 영역에 대한 관심도에 의존하며, 제1 관 심도의 영역의 압축 비율이 제2 관심도의 영역의 압축 비율보다 작고, 제1 관심도는 제2 관심도보다 높다. 10. 항목 2에 따른 방법에 있어서, 상기 제2 특징 맵을 압축하는 단계는 제2 특징 맵에 대한 비균일 양자화를 수행하는 단계를 포함하고, 제2 특징 맵의 다른 영역은 다른 양자화 구간 간격을 갖는다.11. 항목 10에 따른 방법에 있어서, 제2 특징 맵의 영역 각각의 양자화 구간 간격이: 영역의 이미지 복잡성; 제 2 특징 맵 내에서 영역의 위치; 영역의 중요도; 영역 내의 특정한 특징의 존재 또는 부재; 및 영역 내의 특정한 특징의 수 중 적어도 하나에 기초한다. 12. 항목 11에 따른 방법에 있어서, 특정한 특징에는 심층 신경망의 애플리케이션 시나리오에 대한 관심의 특징 이 포함된다. 13. 항목 11에 따른 방법에 있어서, 영역 내의 특정한 특징의 존재 또는 부재에 따라 영역 각각의 양자화 구간 간격의 결정은: 영역 내의 특정한 특징의 존재에 응답하여, 영역에 제1 양자화 구간 간격을 할당하는 단계; 영 역 내의 특정한 특징의 부재에 응답하여, 영역에 제2 양자화 구간 간격을 할당하는 단계를 포함하고, 제1 양자 화 구간 간격은 제2 양자화 구간 간격보다 작다. 14. 항목 11에 따른 방법에 있어서, 영역 내의 특정한 특징의 수에 따라 영역 각각의 양자화 구간 간격의 결정 은: 영역 내의 특정한 특징의 수가 미리 설정된 임계값보다 큰 경우, 영역에 제3 양자화 구간 간격을 할당하는 단계; 및 영역 내의 특정한 특징의 수가 미리 결정된 임계값보다 작거나 같은 경우, 영역에 제4 양자화 구간 간 격을 할당하는 단계를 포함하고, 제3 양자화 구간 간격은 제4 양자화 구간 간격보다 작다. 15. 항목 1에 따른 방법에 있어서, 심층 신경망은 객체 인식을 위한 비디오 데이터 처리에 사용된다. 16. 칩으로서, 칩은: 파라미터 저장 공간 및 특징 맵 저장 공간; 및 항목 1 내지 15 중 어느 하나에 따른 방법 을 수행하기 위해, 메모리와 협력하도록 구성되는 심층 신경망 엔진을 포함하고, 파라미터 저장 공간은 심층 신 경망의 파라미터를 저장하도록 구성되며, 특징 맵 저장 공간은 심층 신경망의 특징 맵을 저장하도록 구성된다. 17. 항목 16에 따른 칩에 있어서, 메모리는 랜덤 액세스 메모리를 포함한다. 18. 항목 16에 따른 칩에 있어서, 칩에는 인공 지능 비전 칩이 포함되어 있다. 19. 항목 18에 따른 칩에 있어서, 칩은: 이미지 신호를 처리하기 위한 이미지 신호 처리(ISP) 유닛; 및 오디오 및 비디오 신호를 인코딩 및 디코딩하도록 구성된 멀티미디어 신호 코덱을 더 포함한다. 20. 전자 장치로서, 전자 장치는: 이미지 및/또는 비디오 데이터를 캡처하도록 구성된 이미지 센서; 및 항목 16 내지 19 중 어느 하나에 따른 칩을 포함하고, 칩은 객체 인식을 위한 캡처된 이미지 및/또는 비디오 데이터를 처리하기 위해 심층 신경망을 사용하도록 구성된다. 21. 전자 장치로서, 전자 장치는: 프로세서; 및 프로그램을 저장하는 메모리를 포함하고, 프로그램은, 프로세서 에 의해 실행될 경우, 전자 장치가 항목 1 내지 15 중 어느 하나에 따른 방법을 수행하게 하는 명령을 포함한다. 22. 프로그램을 저장하는 컴퓨터 판독 가능한 저장 매체로서, 프로그램은, 프로세서에 의해 실행될 경우, 프로 세서가 항목 1 내지 15 중 어느 하나에 따른 방법을 수행하도록 하는 명령을 포함한다. 본 발명의 실시예 또는 예는 도면을 참조하여 설명되었지만, 전술한 방법, 칩 및 장치는 단지 예시적인 실시예 또는 예라는 것을 이해해야 하며, 본 발명의 범위는 실시예 또는 예에 의해 제한되지 않고, 청구된 청구 범위 및 그와 관련되는 것의 범위에 의해서만 정의된다. 실시예 또는 실시예의 다양한 요소는 생략되거나 그와 동등 한 요소로 대체될 수 있다. 또한, 단계는 본 발명에서 설명된 것과 다른 순서로 수행될 수 있다. 또한, 실시예 또는 예의 다양한 요소는 다양한 방식으로 결합될 수 있다. 기술이 발전함에 따라 본원에 설명된 많은 요소들이 본 발명 이후 나타나는 관련된 요소들로 대체될 수 있다는 것이 중요하다.도면 도면1 도면2 도면3 도면4 도면5 도면6 도면7 도면8 도면9"}
{"patent_id": "10-2021-7007212", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도면은, 본원의 실시예를 예시적으로 도시하고 일부를 구성하며, 본원의 서면 설명과 함께 실시예의 예시적인 구현을 설명하기 위해 사용된다. 도시된 실시 예는 단지 예시적인 목적을 위한 것이며 청구 범위를 제한하지 않 는다. 도면 전체에 걸쳐 동일한 참조 부호는 동일한 구성 요소를 지칭한다. 도 1은, 본 발명의 예시적인 실시예에 따른, 심층 신경망을 나타내는 개략도이다. 도 2는, 본 발명의 예시적인 실시예에 따른, 컨볼루션 신경망(CNN, convolutional neural network)을 나타내는 개략도이다. 도 3은, 본 발명의 예시적인 실시예에 따른, 심층 신경망을 위한 예시적인 압축 방법을 도시하는 흐름도이다. 도 4는, 본 발명의 예시적인 실시예에 따른, 특징 맵을 압축하는 것을 나타내는 개략적인 블록도이다. 도 5는, 본 발명의 예시적인 실시예에 따른, 심층 신경망의 추론 과정을 나타내는 개략도이다. 도 6은, 본 발명의 예시적인 실시예에 따른, 심층 신경망의 훈련 과정을 나타내는 개략도이다. 도 7은, 본 발명의 예시적인 실시예에 따른, 칩을 도시하는 개략도이다. 도 8은, 본 발명의 예시적인 실시예에 따른, 전자 장치를 도시하는 개략도이다. 도 9는, 본 발명의 예시적인 실시예에 따른, 다른 전자 장치를 도시하는 개략도이다."}
