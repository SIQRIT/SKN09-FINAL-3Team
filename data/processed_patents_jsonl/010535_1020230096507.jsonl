{"patent_id": "10-2023-0096507", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2025-0015275", "출원번호": "10-2023-0096507", "발명의 명칭": "순차적 강화학습 모델링을 위한 그래프 인코딩 표현법", "출원인": "고려대학교 산학협력단", "발명자": "이병준"}}
{"patent_id": "10-2023-0096507", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "순차적 강화학습 모델링을 위한 그래프 인코딩 방법에 관한 것으로,그래프 데이터를 입력으로 받는 단계;상기 그래프 데이터를 전처리하는 단계;전처리한 상기 그래프 데이터를 임베딩하는 단계;임베딩한 데이터에 트랜스포머 기반 인코딩을 수행하는 단계;상기 트랜스포머 기반 인코딩을 수행한 후, 복수의 추가적인 인코딩을 수행하여 그래프 인코더 은닉 상태를 생성하는 단계;상기 그래프 인코딩 은닉 상태를 학습 가능한 잠재 코드북을 사용해 잠재변수로 변환하는 단계; 및궤적 데이터를 생성하도록 디코딩하는 단계; 를 포함하는그래프 인코딩 방법."}
{"patent_id": "10-2023-0096507", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,트랜스포머 기반 인코딩을 수행하는 단계는,상기 트랜스포머 구조의 자기 집중 연산을 적용하여 상기 그래프 데이터의 노드와 엣지의 특성을 모델링하는 것을 특징으로 하는그래프 인코딩 방법."}
{"patent_id": "10-2023-0096507", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 그래프 인코더 은닉 상태를 생성하는 단계는,상기 그래프 데이터의 노드의 중요도를 나타내는 중심성 인코딩 수행 단계;상기 그래프 데이터의 엣지의 속성을 나타내는 엣지 인코딩 수행 단계; 및상기 그래프 데이터에 공간적인 정보를 추가하는 공간 인코딩 수행 단계; 를 포함하는그래프 인코딩 방법."}
{"patent_id": "10-2023-0096507", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명의 그래프 인코딩 방법은 순차적 강화학습 모델링을 위한 그래프 인코딩 방법에 관한 것으로, 그래프 데 이터를 입력으로 받는 단계, 그래프 데이터를 전처리하는 단계, 전처리한 그래프 데이터를 임베딩하는 단계, 임 베딩한 데이터에 트랜스포머 기반 인코딩을 수행하는 단계, 트랜스포머 기반 인코딩을 수행한 후, 복수의 추가적 인 인코딩을 수행하여 그래프 인코더 은닉 상태를 생성하는 단계, 그래프 인코딩 은닉 상태를 학습 가능한 잠재 코드북을 사용해 잠재변수로 변환하는 단계 및 궤적 데이터를 생성하도록 디코딩하는 단계를 포함할 수 있다."}
{"patent_id": "10-2023-0096507", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 순차적 강화학습 모델링을 위한 그래프 인코딩 표현법에 관한 것이다."}
{"patent_id": "10-2023-0096507", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "강화학습은 에이전트라고 불리는 학습 주체가 환경과 상호작용하여 특정 목표를 달성하기 위해 행동을 학습하는 방법으로, 보상과 벌점을 통해 행동 효과를 평가하고 에이전트의 행동을 최적화한다. 강화학습은 기존의 지도 학습과 비지도 학습에 비해 데이터에 대한 의존도가 상대적으로 낮기 때문에 레이블링 데이터가 다량으로 필요 없어 실제 환경에서 효율적으로 사용할 수 있기 때문에 현재와 미래의 인공지능 연구와 응용 프로그램(예: 자율 주행, 로봇, 게임, 금융 등)에서 매우 유망한 분야로 인정받고 있다. 하지만 강화학습은 다량의 데이터가 필요하지 않은 대신, 실제 환경에서 에이전트가 상호작용하며 경험을 얻어 야 하며, 실세계 문제는 매우 복잡한 특성 공간을 가지기 때문에 대규모의 상태 공간과 연속적인 행동 공간을 다루는 문제는 도전적이다. 또한, 실세계에서 보상 함수를 정의하는 것은 어려운 문제이며 실시간 응용을 위해 서는 안정적인 학습이 필요하다. 강화학습은 현실 세계에서 복잡한 문제를 해결하기 위해 강력한 도구로 사용될 수 있지만 학습 과정이 불안정하 고 환경과 상호작용하는 것에 큰 비용과 자원이 소모되므로 최근에는 미리 보상이 레이블링된 데이터로 효율적 으로 학습할 수 있는 오프라인 강화학습(Offline Reinforcement Learning)이 주목을 받고 있다. 오프라인 강화학습 중에서도 지도 학습과 유사한 방식으로 동작하는 순차적 강화학습(Sequential Reinforcement Learning)은 의사 결정을 간소화할 수 있어 많은 연구가 이루어지고 있다. 선행기술문헌 특허문헌 (특허문헌 0001) 한국공개특허 제10-2023-0065343호"}
{"patent_id": "10-2023-0096507", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "기존의 일반적인 강화학습은 에이전트의 현재 상태는 이전 상태에만 영향을 미친다는 마르코프 속성(Markov Property)을 가정하여, 장지평선 의사 결정 문제(Long-horizon Decision-Making Problem)를 국소 하위 문제 (Local Subproblems)로 분해하여 해결한다. 하지만 이 가정은 강화학습 프로세스에서 학습 불안정성을 야기할 수 있으며 이를 해결하기 위해 앙상블 기법(Ensemble Learning) 혹은 보수주의 기법(Conservatism) 등 복잡한 프로세스나 메커니즘을 추가하여 에이전트를 학습해야 한다. 반면, 최근 각광받고 있는 순차적 강화학습은 일반 순차적 생성 모델링(Sequential Generative Modeling) 문제 를 강화학습 문제로 해결하는 것으로, 보상을 최대화 하는 일련의 행동을 생성하도록 하는 방법이다. 순차적 강 화학습은 궤적(Trajectory) 데이터의 상태, 행동, 보상 값을 순차적인(시계열) 데이터(Sequential Data) 스트림 으로 취급하여 상태와 행동을 공동으로 모델링할 수 있다는 이점을 제공하며, 이는 본질적으로 분포 내 행동을 생성할 수 있도록 장려한다. 하지만 순차적 강화학습은 현실 세계에 사용되기에는 추론 시간이 과도하게 소요되거나 잠재 변수의 사용으로 인해 정보 손실이 발생한다는 단점이 있다. 이를 해결하기 위해 모델의 인코더 혹은 디코더의 구조를 정교하게 바꾸어 순차적 강화학습 에이전트를 학습하 면, 기존에 강화학습의 불안정성을 해결하기 위한 복잡한 프로세스를 추가하지 않아도 된다. 따라서 본 발명에서는 정교한 그래프 인코더 구조가 강화학습 에이전트에 귀납적 편향을 제공하여 순차적 강화 학습 에이전트의 성능을 향상할 수 있는 방법을 제시한다. 그래프 신경망(GNN, Graph Neural Network)는 그래프 데이터에서 노드와 엣지의 특성을 모델링하기 위한 신경망 구조를 의미한다. 기존의 그래프 신경망은 주변 이웃 노드의 정보를 집계하고, 집계한 정보를 노드의 표현으로 업데이트하는 반복 적인 단계를 통해 그래프를 표현하므로 지역적인 정보는 잘 표현하지만 그래프의 전역적인 정보에 대한 표현력 은 약하다. 트랜스포머 구조는 인공지능 모델링 전반에 걸쳐 사용되는 모델 구조로 전역적인 정보를 잘 모델링하는 구조로 알려져 있다. 이 트랜스포머 구조의 자기 집중(Self-Attention) 연산을 그래프 표현 방법에 이용하면 기존 그래 프 신경망에서 전역적인 정보를 잘 표현하지 못하는 한계점을 해결할 수 있다. 기존의 트랜스포머 구조를 그대로 그래프 표현에 적용하게 되면 그래프의 전체적인 구조 정보(Graph structural information)을 모델이 인식하지 못해 그래프로 포현된 데이터에 대해 순차적 생성 모델링에 적용하기 적합하지 않다. 따라서 중심성 인코딩(Centrality Encoding), 엣지 인코딩(Edge Encoding), 공간 인코딩(Spatial Encoding)등의 추가적인 인코딩 방법을 통해 인코딩 표현력을 높여줄 수 있다."}
{"patent_id": "10-2023-0096507", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 그래프 인코딩 방법은 순차적 강화학습 모델링을 위한 그래프 인코딩 표현법에 관한 것으로, 그래프 데이터를 입력으로 받는 단계, 그래프 데이터를 전처리하는 단계, 전처리한 그래프 데이터를 임베딩하는 단계, 임베딩한 데이터에 트랜스포머 기반 인코딩을 수행하는 단계, 트랜스포머 기반 인코딩을 수행한 후, 복수의 추 가적인 인코딩을 수행하여 그래프 인코더 은닉 상태를 생성하는 단계, 그래프 인코딩 은닉 상태를 학습 가능한 잠재 코드북을 사용해 잠재변수로 변환하는 단계 및 궤적 데이터를 생성하도록 디코딩하는 단계를 포함할 수 있 다. 또한, 일 실시예에 의하면, 트랜스포머 기반 인코딩을 수행하는 단계는, 트랜스포머 구조의 자기 집중 연산을 적용하여 그래프 데이터의 노드와 엣지의 특성을 모델링하는 것을 특징으로 할 수 있다. 또한, 일 실시예에 의하면, 그래프 인코더 은닉 상태를 생성하는 단계는, 그래프 데이터의 노드의 중요도를 나 타내는 중심성 인코딩 수행 단계, 그래프 데이터의 엣지의 속성을 나타내는 엣지 인코딩 수행 단계 및 그래프 데이터에 공간적인 정보를 추가하는 공간 인코딩 수행 단계를 포함할 수 있다."}
{"patent_id": "10-2023-0096507", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "순차적 강화학습에서 정보 손실을 줄이고, 데이터 표현력을 높이기 위해 트랜스포머 구조의 자기 집중 연산을 사용하며, 이 연산을 통해 강화학습 에이전트에 일종의 귀납적 편향(Inductive Bias)을 제공할 수 있다. 순차적 강화학습은 기존의 강화학습처럼 복잡한 최적화 과정을 배제하는 대신 순차적 모델링의 데이터 표현력에 의존하게 되므로, 데이터 표현력을 높일 수 있는 인코더 구조를 활용함으로써 에이전트가 지역적인 정보는 물론 전역적인 정보까지 활용하여 행동을 생성할 수 있도록 유도할 수 있다. 기존의 그래프 신경망(Graph Neural Network)와 달리 그래프 정보를 인코딩하기 위해 트랜스포머 구조의 자기 주의(Self-Attention)연산을 활용함으로써 그래프 구조와 각 노드, 엣지의 특성을 동시에 모델링할 수 있으며 기존 그래프 신경망과 달리 서로 거리가 먼 노드의 관계까지 잘 학습할 수 있다. 또한, 트랜스포머 구조를 활용함으로써 기존의 그래프 신경망 구조와 다르게 간단하고 유연한 모델 구조 구현이 가능하며 모델링 확장에 용이하다. 본 발명에서 제안하는 그래프 인코딩 기법은 그래프로 표현될 수 있는 모든 환경과 데이터에 적용할 수 있어 보 편성과 이식성이 뛰어날 뿐 아니라 기존 그래프 인코딩 기법들보다 우수한 모델 성능을 보여줄 수 있다. 강화학습은 현재와 미래의 인공지능 연구와 응용 프로그램에서 매우 유망한 분야로 인정받고 있지만, 구현과 실 세계 적용이 어렵다는 단점이 있다. 본 발명에서 제안하는 순차적 강화학습 모델링을 위한 그래프 인코딩 표현 법을 통해 모델링 과정을 간소화하고 실세계에 적용할 수 있도록 하여 복잡한 문제를 해결하기 위한 도구로 활 용될 것으로 기대된다."}
{"patent_id": "10-2023-0096507", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명의 이점 및 특징, 그리고 그것들을 달성하는 방법은 첨부되는 도면과 함께 후술되어 있는 실시예들을 참 조하면 명확해질 것이다. 그러나 본 발명은 이하에서 개시되는 실시예들에 한정되는 것이 아니라 서로 다른 다 양한 형태로 구현될 수 있으며, 단지 본 실시예들은 본 발명의 개시가 완전하도록 하고, 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자에게 발명의 범주를 완전하게 알려주기 위해 제공되는 것이며, 본 발명은 청구 항의 범주에 의해 정의될 뿐이다. 본 명세서에서 사용되는 용어에 대해 간략히 설명하고, 본 발명에 대해 구체적으로 설명하기로 한다. 본 발명에서 사용되는 용어는 본 발명에서의 기능을 고려하면서 가능한 현재 널리 사용되는 일반적인 용어들을 선택하였으나, 이는 당 분야에 종사하는 기술자의 의도 또는 판례, 새로운 기술의 출현 등에 따라 달라질 수 있 다. 또한, 특정한 경우는 출원인이 임의로 선정한 용어도 있으며, 이 경우 해당되는 발명의 설명 부분에서 상 세히 그 의미를 기재할 것이다. 따라서 본 발명에서 사용되는 용어는 단순한 용어의 명칭이 아닌, 그 용어가 가 지는 의미와 본 발명의 전반에 걸친 내용을 토대로 정의되어야 한다. 명세서 전체에서 어떤 부분이 어떤 구성요소를 \"포함\"한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다른 구성요소를 제외하는 것이 아니라 다른 구성요소를 더 포함할 수 있음을 의미한다. 또한, 명세서에서 사용되는 \"부\", \"모듈\", \"유닛\" 등의 용어는 적어도 하나의 기능 또는 동작을 처리하는 단위를 의미하며, 소프트웨어, FPGA 또는 ASIC과 같은 하드웨어 구성요소, 또는 소프트웨어와 하드웨어의 결합으로 구현될 수 있다. 그렇지만 \"부\", \"모듈\", \"유닛\" 등의 용어가 소프트웨어 또는 하드웨어에 한정되는 의미는 아니다. \"부\", \"모듈\", \"유닛\" 등은 어드레싱할 수 있는 저장 매체에 있도록 구성될 수도 있고 하나 또는 그 이상의 프로세서들을 재생 시키도록 구성될 수도 있다. 따라서, 일 예로서 \"\"부\", \"모듈\", \"유닛\" 등의 용어는 소프트웨어 구성요소들, 객 체지향 소프트웨어 구성요소들, 클래스 구성요소들 및 태스크 구성요소들과 같은 구성요소들과, 프로세스들, 함 수들, 속성들, 프로시저들, 서브루틴들, 프로그램 코드의 세그먼트들, 드라이버들, 펌웨어, 마이크로 코드, 회 로, 데이터, 데이터베이스, 데이터 구조들, 테이블들, 어레이들 및 변수들을 포함한다. 아래에서는 첨부한 도면을 참고하여 본 발명의 실시예에 대하여 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자가 용이하게 실시할 수 있도록 상세히 설명한다. 그리고 도면에서 본 발명을 명확하게 설명하기 위해서 설명과 관계없는 부분은 생략한다. “제1\", \"제2\" 등과 같이 서수를 포함하는 용어는 다양한 구성 요소들을 설 명하는데 사용될 수 있지만, 구성 요소들은 용어들에 의해 한정되지는 않는다. 용어들은 하나의 구성요소를 다 른 구성요소로부터 구별하는 목적으로만 사용된다. 예를 들어, 본 발명의 권리 범위를 벗어나지 않으면서 제1 구성요소는 제2 구성요소로 명명될 수 있고, 유사하게 제2 구성요소도 제1 구성요소로 명명될 수 있다. \"및/ 또는\" 이라는 용어는 복수의 관련된 항목들의 조합 또는 복수의 관련된 항목들 중의 어느 하나의 항목을 포함한 다. 본 명세서에 설명된 다양한 시스템, 장치, 저장 매체, 모듈 및 기구는 전용 연산 디바이스, 또는 하나 이상의 전용 연산 디바이스의 하나 이상의 연산 칩에서 구현될 수도 있다. 이하, 도면을 참조하여 본 발명의 순차적 강화학습 모델링을 위한 그래프 인코딩 표현법에 관하여 설명하도록 한다. 본 명세서에서는 에이전트의 현재 상태 , 현재 상태에서 취하는 행동 , 행동으로 받는 보상 과 누적 보상 합 , 다음 상태 를 포함하는 일련의 전이 데이터(Transition Data)세트 가 있고, 특정 시간 동안의 전이 데이터세트의 집합을 궤적 데이터 (Trajectory Data) 로 정의한다. 데이터는 시간순으로 정렬이 되어 있다고 가정하며 이는 일종이 순차적(시계열) 데이터(Sequential Data)를 의미한다. (도 1에서 “원본 순차 데 이터”를 의미) 순차적(시계열) 데이터는 상관관계를 통해 노드 와 엣지 로 표현되는 그래프 데이터로 변형하 는 전처리 단계를 수행할 수 있는 도메인이다. 즉, 본 명세서에서 다루는 도메인 데이터는 순차적(시계열) 데이 터는 전처리 과정을 통해 그래프 데이터로 표현이 가능하거나 원본 그래프 데이터가 존재하는 데이터이다. (도 1에서 “변형된 그래프 데이터”를 의미) 전처리를 거친 그래프 데이터는 인공지능 모델링의 입력이 될 수 있도록 선형 연산과 같은 일련의 연산을 거쳐 벡터 혹은 행렬 데이터로 표현되며, 이 벡터 혹은 행렬 데이터를 생성하는 과정은 ‘임베딩’이라고 한다. (도 1에서 “그래프 선형 은닉 상태”를 의미) 임베딩을 거친 그래프 은닉 상태는 트랜스포머 기반 그래프 표현 인코더의 직접적인 입력이 되어 T개의 특징 벡 터 가 생성된다.트랜스포머 기반 그래프 인코더에서는 그래프의 특징, 엣지의 인덱스, 인접 행렬이 입력이 된다. 인코더는 중심 성 인코딩과 공간 인코딩 두 가지 유형의 인코딩을 기본적으로 적용하고, 엣지의 특성을 활용할 수 있는 도메인 의 데이터의 경우 엣지 인코딩까지 총 세 가지 유형의 인코딩을 적용할 수 있다. 중심성 인코딩의 경우, 각 노드의 중요성을 포착하기 위해 각 노드의 차수(degree) 속성을 이용하여 학습 가능 한 중심성 임베딩 벡터 를 계산한다. 해당 인코딩은 방향이 없는 그래프에 적합하며 각 노 드 별 중심성 점수를 내포한다. 해당 중심성 점수는 노드의 특징 벡터 에 더해지며(수식 : ) 각각 내차(Indegree) , 외차(Outdegree) 와 연관이 되 어 있다. (도 1에서 “중심성 인코딩 행렬”를 의미) 순차적(시계열) 데이터의 경우 위치 인코딩은 일반적으로 각 노드 혹은 요소의 순서 또는 상대적인 위치를 포착 하는데 사용된다. 그러나 그래프 구조 데이터의 경우 노드에는 고유한 순차 정렬이 없다. 대신 노드는 다차원 공간에 존재하며 엣지 로 연결된다. 주어진 그래프의 문맥 벡터를 계산하여 각 노드의 공간적 관 계를 연결성에 따라 측정할 수 있다. 본 발명에서는 각 노드 사이의 최단 경로 거리(SPD, Shortest Path Distance)를 연결성 함수 로 채택하며, 스칼라 로 학습되고 학습된 최단 경로 거리는 자기 주의(Self-Attention) 모듈 의 편향(Bias) 항에 더해줌으로써 (수식: )공간적인 표현을 그래프 표현에 더해줄 수 있다. (도 1에서 “공간 인코딩 행렬”를 의미) 중심성 임베딩 벡터 와 공간 임베딩 벡터 는 모두 학습 가능한 파라미터로써, 이 임베딩 벡터를 통합하여 트랜스포머 기반 그래프 인코더는 그래프의 구조적 정보를 포착하여 서로 다른 노드 의 상태간의 상관관계를 효과적으로 나타낼 수 있게 된다. 엣지 인덱스는 노드간 방향 연결을 나타내며, 엣지 인덱스 는 인접 행렬에서 노드 간의 인접 관계 를 지정하는 인접 행렬 을 구성하는데 사용된다. 엣지 정보는 인덱스를 통해 인접 행렬을 구성하는 것 외에, 엣지의 특징 벡터로 나타낼 수 있는 특성이 있는 경우 엣지 특성을 임베딩하여 엣지 인코딩을 적용할 수 있다. (도 1에서 “엣지 인코딩 행렬”를 의미) 중심성 인코딩 행렬과 공간 인코딩 행렬, 그리고 추가적으로 엣지 인코딩 행렬을 종합하여 최종적으로 그래프 인코더 은닉 상태가 생성되며, 이렇게 생성된 그래프 인코더 은닉 상태는 그래프 데이터에서 중요한 노드를 표 현하는 중심성과 각 노드간의 연결성을 표현한 공간성, 그리고 엣지의 특성까지 고려되는 고레벨 특징 벡터가 된다. (도 1에서 “그래프 인코더 은닉 상태”를 의미) 인코딩이 끝난 그래프 인코더 은닉 상태는 변형 자동 인코더(VAE, Variational AutoEncoder), 벡터 양자화 변형 자동 인코더(VQ-VAE, Vector-Quantized VAE) 등의 잠재 변수를 모델링할 수 있는 추가적인 모듈로 전달된다. 그래프 인코더 은닉 상태는 학습 가능한 코드북 을 사용해 잠재 변수 로 변환된다. (수식 : where ) 변형 자동 인코더 모듈은 최종 결과를 디코딩하는 디코더로써 사용된다. (수식 : ) 임의의 궤적 데이터(Trajectory Data)를 디코더가 생성하게 하는 대신, 원하는 목표에 도달하는 궤적 데이터를 생성할 수 있도록 하기 위해 잠재 변수에 대한 사전 분포(Prior Distribution)는 맨 처음 상태(Initial State) 에 따라 조건부화 된다. 이를 통해 주어진 처음 상태에서 시작하는 궤적 데이터를 생성할 수 있다. 잠재변수와 처음 상태가 연결되고(Concatenation) 이 두 가지를 적절하게 혼합한 상태를 만들기 위해 혼합 레이 어(Mixing Layer)에 잠재변수와 처음 상태가 연결된 벡터가 공급된다. 혼합 레이어의 출력 차원은 그래프 인코 더 은닉 상태의 차원과 동일하며 그 후 시간적 정보를 포함할 수 있도록 위치 임베딩(Positional Embedding)을 더해준다. 최종적으로 디코더는 이전 모든 상태의 전이 데이터가 그래프 표현력을 갖춘 그래프 인코더 은닉 상태를 입력으 로 받아 다음 상태를 예측하게 된다. 예를 들어 마지막 데이터가 ‘상태(state) ’에 관한 데이터였다면 ‘상 태(state) ’에서 취해야할 ‘행동(action) ’을 예측하고, 마지막 데이터가 ‘행동(action) ’ 데이터 였다면 해당 ‘행동(action) ’을 통해 받게 되는 ‘보상(reward) ’을 예측하며, 마지막 데이터가 ‘보 상(reward) ’이었을 경우 ‘다음 상태(next state) ’를 디코더는 생성하게 되는 것이다. 이 과정을 통해 모델을 학습하기 위해 재구성된 궤적(trajectory) 를 실제 궤적 (trajectory)와 비교하여 손실 함수를 계산하고 각 모듈의 파라미터들을 업데이트 하게 되며 이 손실은 생성된 궤적이 원하는 속성을 포착하고 입력 데이터의 기본 구조를 준수하도록 보장할 수 있다. 트랜스포머 구조는 이전 상태들을 모두 입력으로 받아야 하는 자동 회귀 구조이다. 이 구조는 병렬 샘플링을 불 가능하게 하는 구조로 필연적으로 추론 시간을 길게 만들 수밖에 없으며, 현실 세계에서 사용하기에 불가능한 경우가 많다. 자동 회귀 샘플링에서 추론 시간을 줄이기 위해 또 하나의 트랜스포머 구조를 사용해 상태 조건부 선행 모델을 학습할 수 있다. 추론 시간 동안 현재 상태를 조건으로 학습한 이전 모델에서 잠재 코드를 샘플링해서 잠재 코 드의 수보다 더 많은 연속적 상태를 샘플링할 수 있도록 하여 추론 시간 성능을 개선할 수 있다. 단일 전환에 해당하는 단일 잠재 코드를 샘플링하기 위해 샘플링을 기준으로 삼을 점수 함수를 사용한 빔 검색 (Beam Search)를 사용한다. 이 점수 함수에는 누적 보상, 즉 최종 값 추정치를 활용할 수 있도록 설계되어 있다. 잠재 코드의 다양성을 제어하는 항을 포함하고 다양한 구성 요소가 포함되어 있어 추론시 검색에 용이하 도록 한다. 빔 검색에서 조건부 확률을 직접적으로 사용하는 대신 이 점수 함수 를 사용한다. 추론 시간은 기존에 각 디코딩 단계마다 D^3의 시간 복잡도를 갖는데, 디코더에 공급되는 입력의 수를 최소화 함으로써 시간 복잡도를 D, 즉 상수 시간으로 줄일 수 있다. <실시예> 실시예: 로봇 시뮬레이터에서의 활용 더 자세하게는, 딥러닝 기반 강화학습을 위한 데이터셋을 제공하는 프로젝트 D4RL(Datasets for Deep Data- Driven Reinforcement Learning)에서의 로봇 시뮬레이터 Mujoco 환경을 활용할 수 있다. Mujoco는 다양한 로봇 및 물체 상호작용을 모델링하기 위한 물리 시뮬레이터 엔진이다. Mujoco 환경 중 하나로 Halfcheeta 환경을 이 용을 예시로 들어 설명한다. Halfcheeta는 네 개의 다리와 몸통으로 구성된 로봇 치타이며 이 환경의 상태(State)는 로봇의 관절 각도, 각 관절의 속도, 관절의 위치 및 관절 각속도와 같은 다양한 정보로 구성되 있다. 이러한 상태 정보는 로봇의 현재 상태를 설명하고 관찰 가능한 정보를 제공한다. 그리고 행동(Action)은 로봇의 각 관절에 대한 토크(Torque) 값 을 나타내며 각 관절은 다양한 방향으로 회전할 수 있고 각 관절에 대한 토크 값을 결정하여 움직임을 생성할 수 있다. 보상(Reward)는 환경에서 주어진 행동에 대한 환경의 피드백을 의미한다. 일반적으로 로봇이 정지한 상태에서 움직이는 것에 대해 음의 보상이 제공되고, 목표로 설정된 속도에 도달할 때 양의 보상이 제공될 수 있다. 궤적 데이터는 환경에서 로봇의 상태, 행동, 보상, 다음 상태로 이루어진 전이 데이터가 특정 시간만큼 순차적 으로 주어진 데이터를 의미한다. 예를 들어서, 총 10의 시간만큼의 궤적 데이터가 존재한다고 하면 (상태1, 행 동1, 보상1, 상태2, 행동2, 보상2, ... 상태10, 행동10, 보상10)으로 이루어진 일련의 데이터가 주어지는 것이다. 다차원의 상태와 행동 보상 값으로 구성된 데이터를 그래프 구조로 표현하기 위해 로봇 시뮬레이터에서 연 결된 각 몸체를 노드로 연결하고 몸체의 상태를 노드의 특징으로 구성할 수 있어 최종적으로 로봇 시뮬레이터의 각 상태를 그래프에서 해당 노드에 할당할 수 있는 것이다. 이는 xml 데이터를 파싱하는 것으로 구현될 수 있다. 또한, 노드의 특징 벡터는 각 노드(몸체)의 위치, 행동, 보상 값의 고유한 조합으로 나타내어진다. 노드 특징 벡터는 노드간에 일관된 차원을 보장하기 위해 최대 특징 차원으로 패딩된다. 그래프의 엣지는 로봇 시뮬레이터 가 연결된 관절의 방향을 통해 구성할 수 있으며 이를 통해 노드간 인접 관계를 표현하는 인접 행렬을 구성할 수 있다. 로봇의 연결된 몸체를 그래프 데이터 셋으로 표현한 뒤 선형 프로세스를 통해 벡터 혹은 행렬로 변환하고 본 발 명에서 제안되는 중심점 인코딩, 공간 인코딩, 엣지 인코딩을 적용해서 그래프 인코더 은닉 상태를 도출한다. 그래프 인코더 은닉 상태는 로봇 시뮬레이터에서 연결된 관절과 몸체들의 상관성과 구조를 표현할 수 있는 인코 더 벡터를 의미한다. 또한, 상관관계가 반영된 인코더 벡터는 강화학습 에이전트가 활용할 수 있는 정보가 더 많아지는 것을 의미한다. 그래프 은닉 인코더 은닉 상태를 디코더가 받고 디코더가 다음 상태를 예측하는 과정이 반복되어 일련의 순차적 인 잠재 변수를 생성해내고 해당 잠재 변수들은 추론을 위한 모델에 입력되어 순차적인 궤적 데이터로 디코딩된 다. 디코딩된 순차적인 궤적 데이터의 여러 후보에서 점수 함수를 계산해 가장 높은 점수를 지닌 궤적 데이터가 선정되고 해당 궤적 데이터에서 다음 행동을 계산하고 다음 행동을 통해 로봇의 움직임이 조정된다. <실험 결과와 사용된 하이퍼파라미터> 도 2를 참조하여 실험 결과와 사용된 하이퍼파라미터에 관하여 설명하도록 한다. TAP은 그래프 인코딩 기법을 적용하지 않은 모델을 의미하며 GraphormerTAP은 본 발명에서 제안하는 그래프 표 현법을 적용한 모델이다. 강화학습에 순차적 모델링 프레임워크를 적용하면 의사 결정 과정을 간소화할 수 있고 여기에 로봇 시뮬레이터에서 각 몸체와 관절의 상관관계를 의미하는 귀납적 편향을 적용해 고레벨 그래프 표현 법을 적용한다면 모델링 성능이 향상되어 결과가 향상되는 것을 확인할 수 있다. 그래프 표현법을 적용시 모든 환경에서 더 나은 성능을 보여주는 것은 아니나, 이는 그래프 표현법을 통해 반영할 수 있는 상관관계가 적은 환경이라는 것을 의미하며, 환경에서 여러 노드로 표현될 수 있는 객체들간 상관관계가 큰 도메인일 경우 성능 이 향상된다는 것을 확인할 수 있었다. 본원 발명의 실시예 들과 관련된 기술 분야에서 통상의 지식을 가진 자는 상기 기재의 본질적인 특성에서 벗어 나지 않는 범위에서 변형된 형태로 구현될 수 있음을 이해할 수 있을 것이다. 그러므로, 개시된 방법들은 한정 적인 관점이 아닌 설명적 관점에서 고려되어야 한다. 본 발명의 범위는 발명의 상세한 설명이 아닌 특허청구 범 위에 나타나며, 그와 동등한 범위 내에 있는 모든 차이점은 본 발명의 범위에 포함되는 것으로 해석되어야 한다.도면 도면1 도면2"}
{"patent_id": "10-2023-0096507", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 일 실시예에 따른 그래프 인코딩 방법의 순서도이다. 도 2는 일 실시예에 따른 하이퍼파라미터 및 실험결과이다."}
