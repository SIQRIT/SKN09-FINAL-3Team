{"patent_id": "10-2022-0078514", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0001617", "출원번호": "10-2022-0078514", "발명의 명칭": "작업현장의 위험요소를 탐지하는 방법 및 장치", "출원인": "연세대학교 산학협력단", "발명자": "김하영"}}
{"patent_id": "10-2022-0078514", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "분석장치가 '영상획득 시작신호'를 수신하는 단계; 상기 분석장치가 상기 '영상획득 시작신호'를 수신한 경우, 작업현장의 영상을 획득하는 단계; 상기 분석장치가 상기 획득한 영상을 탐지모델에 입력하는 단계; 및상기 분석장치가 상기 탐지모델이 출력하는 값에 따라 상기 작업현장의 적어도 하나의 위험요소를 분석하는 단계;를 포함하되상기 탐지모델은 학습데이터로 작업현장의 영상을 이용하여, 상기 작업현장에서 발생할 수 있는 적어도 하나의위험요소에 대한 정보를 출력하도록 학습된 학습모델인작업현장의 위험요소를 탐지하는 방법."}
{"patent_id": "10-2022-0078514", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서상기 '영상획득 시작신호'는통신데이터로 전송된 신호인 것인작업현장의 위험요소를 탐지하는 방법."}
{"patent_id": "10-2022-0078514", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서상기 통신데이터는 이동통신, 위성통신, 레이더, 안테나, RFID(Radio Frequency Identification), 광케이블, NFC(Near Fieldcommunication), 블루투스 및 와이파이 중 적어도 하나를 이용한 통신에 의한 데이터인작업현장의 위험요소를 탐지하는 방법."}
{"patent_id": "10-2022-0078514", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서상기 '영상획득 시작신호'는 상기 작업현장에서 작업자의 행동으로부터 얻은 신호인작업현장의 위험요소를 탐지하는 방법."}
{"patent_id": "10-2022-0078514", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서상기 작업자의 행동으로부터 얻은 신호는 공개특허 10-2024-0001617-3-‘작업자가 윙크하는 행위', '작업자가 손을 흔드는 행위', '작업자가 박수를 치는 행위', '안전모를 착용하는행위' 및 '작업자가 사다리를 설치하는 행위' 중 적어도 하나를 포함하는작업현장의 위험요소를 탐지하는 방법."}
{"patent_id": "10-2022-0078514", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서상기 탐지모델은작업현장의 영상 및 상기 작업현장의 영상에 포함된 다수의 위험요소에 대한 정보가 멀티-라벨링(multilabeling)된 학습데이터를 이용하여 학습된 것인작업현장의 위험요소를 탐지하는 방법."}
{"patent_id": "10-2022-0078514", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6항에 있어서상기 멀티-라벨링된 학습데이터를 이용하여 학습하는 것은상기 분석장치와는 별도의 학습장치를 이용해서 학습하는 것인작업현장의 위험요소를 탐지하는 방법."}
{"patent_id": "10-2022-0078514", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1항에 있어서 상기 작업현장의 영상을 획득하는 단계는CCTV(Closed-circuit television), 무인비행장치에 부착된 카메라, 액션캠 및 360도 카메라 중 적어도 하나를이용하여 상기 작업현장의 영상을 획득하는 것을 포함하는작업현장의 위험요소를 탐지하는 방법"}
{"patent_id": "10-2022-0078514", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1항에 있어서상기 위험요소에 대한 정보는 '인적 위험요소' 및 '물적 위험요소'에 대한 정보 중 적어도 하나를 포함하는작업현장의 위험요소를 탐지하는 방법."}
{"patent_id": "10-2022-0078514", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제1항에 있어서상기 적어도 하나의 위험요소에 대한 정보를 출력하는 단계는상기 위험요소(들)에 대한 대처법에 대한 정보도 함께 출력하는 것을 포함하는공개특허 10-2024-0001617-4-작업현장의 위험요소를 탐지하는 방법."}
{"patent_id": "10-2022-0078514", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제10항에 있어서상기 위험요소(들)에 대한 대처법에 대한 정보는‘작업자가 안전장비를 미착용하는 경우 안전장비를 착용하라는 것', '작업자가 뛰어다니는 경우 뛰어다니지 말라는 것', '단체작업에서 단독으로 작업하는 경우 단체로 작업하라는 것', '작업물 끝단에서 작업하는 경우 거기서 벗어라나는 것', '사다리의 안전장치를 미설치 하는 경우 안전장치를 설치하라는 것' 및 '미끄러운 물체를방치하는 경우 해당 물체를 치우라는 것' 중 적어도 하나를 포함하는작업현장의 위험요소를 탐지하는 방법."}
{"patent_id": "10-2022-0078514", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제1항에 있어서상기 하나의 위험요소에 대한 정보를 출력하는 단계는'소리를 통하여 작업자에게 경고음을 출력하는 것', '통신장치를 이용해 상기 작업자의 단말기에 문자를 통보하는 것' 및 '안전관리자에게 위험요소에 대해 통지하는 것 중 적어도 하나를 포함하는작업현장의 위험요소를 탐지하는 방법."}
{"patent_id": "10-2022-0078514", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제1항에 있어서상기 작업현장의 적어도 하나의 위험요소를 분석하는 단계는상기 작업현장에 포함된 적어도 하나의 위험요소를 분석하여 멀티라벨링하는 것을 포함하는작업현장의 위험요소를 탐지하는 방법."}
{"patent_id": "10-2022-0078514", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "‘영상획득 시작신호'를 수신하는 수신장치; 상기 수신장치가 '영상획득 시작신호'를 수신하면 작업현장의 영상을 획득하는 입력장치;상기 입력장치가 획득한 영상을 탐지모델에 입력하고, 상기 탐지모델이 출력하는 값에 따라 상기 작업현장의적어도 하나의 위험요소를 분석하는 연산장치; 및상기 연산장치가 분석한 적어도 하나의 위험요소를 출력하는 출력장치;를 포함하되상기 탐지모델은 학습데이터로 작업현장의 영상을 이용하여, 상기 작업현장에서 발생할 수 있는 적어도 하나의위험요소에 대한 정보를 출력하도록 학습된 학습모델인 작업현장의 위험요소를 탐지하는 장치"}
{"patent_id": "10-2022-0078514", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "인공지능을 이용한 공사현장의 다중 위험요소를 탐지하는 방법은 분석장치가 작업현장의 영상을 획득하는 단계; 분석장치가 상기 획득한 영상을 탐지모델에 입력하는 단계; 및 분석장치가 상기 탐지모델이 출력하는 값에 따라 상기 작업현장의 적어도 하나의 위험요소를 탐지하는 단계;를 포함하되 상기 영상을 획득하는 단계는 상기 작업 현장의 작업자의 행동을 인식해야 영상을 획득하는 단계이고, 상기 탐지모델은 학습데이터로 작업현장의 영상을 이용하여, 상기 작업현장에서 발생할 수 있는 적어도 하나의 위험요소에 대한 정보를 출력하도록 학습된 학습모 델인 것을 포함한다."}
{"patent_id": "10-2022-0078514", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "이하 설명하는 기술은 인공지능을 이용하여 공사현장에서 발생할 수 있는 여러 위험요소를 탐지하고 이를 작업 자들에게 알려주는 방법 및 장치에 대한 것이다."}
{"patent_id": "10-2022-0078514", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "작업현장에서는 여러가지 위험요소들이 있다. 이러한 위험요소로 인하여 작업현장에서 사고가 발생하는 경우 많 은 인명피해와 물적피해가 발생할 수 있다. 이를 방지하기 위하여 기존에는 안전지도요원이나 전문가들이 현장 에 배치되어 일어날 수 있는 사고에 대해 방지하고 있었으나, 최근에는 딥러닝 기술을 이용해서 작업현장에서 일어날 수 있는 위험에 대해 파악하려 하고 있다. 선행기술문헌 특허문헌 (특허문헌 0001) 한국 특허출원 : 10-2018-0081144"}
{"patent_id": "10-2022-0078514", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "기존 작업현장에서 위험을 알려주는 방법들은 담당자나 기술지도 요원에 의해 수동 및 육안으로 체크되는 경우 가 많았다. 이에 담당자나 기술지도 요원이 현장이 없는 경우 작업현장에 작업자가 위험을 탐지하기는 상당히 어려웠다. 특히 작업현장에는 단순히 하나의 위험만이 아니라 여러 위험이 도사리고 있다. 이에 단순히 작업현장에서 하나 의 위험요소만 판단할 수 있는 것 뿐만 아니라, 여러가지 위험요소를 판단할 필요성이 있다. 또한 작업현장에는 여러가지의 이벤트가 발생하나, 모든 이벤트에 대해서 위험요소가 있는지 판단할 필요성은 적고, 특정한 경우만 위험요소가 있는지 판단할 필요성이 있다. 이하 설명하는 발명은 위와 같은 과제를 해결하기 위해서 필요한 경우에만 인공지능을 이용해 작업현장에서 위 험요소를 판단할 수 있게 하는 방법을 제공한다."}
{"patent_id": "10-2022-0078514", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "작업현장의 위험요소를 탐지하는 방법 및 장치는 분석장치가 '영상획득 시작신호'를 수신하는 단계; 상기 분석 장치가 상기 '영상획득 시작신호'를 수신한 경우, 작업현장의 영상을 획득하는 단계; 상기 분석장치가 상기 획 득한 영상을 탐지모델에 입력하는 단계; 및 상기 분석장치가 상기 탐지모델이 출력하는 값에 따라 상기 작업현 장의 적어도 하나의 위험요소를 분석하는 단계;를 포함하되 상기 탐지모델은 학습데이터로 작업현장의 영상을 이용하여, 상기 작업현장에서 발생할 수 있는 적어도 하나의 위험요소에 대한 정보를 출력하도록 학습된 학습모 델인 것을 특징으로 한다. 상기 '영상획득 시작신호'는 통신데이터로 전송된 신호인 것일 수도 있다. 상기 통신데이터는 이동통신, 위성통신, 레이더, 안테나, RFID(Radio Frequency Identification), 광케이블, NFC(Near Field communication), 블루투스 및 와이파이 중 적어도 하나를 이용한 통신에 의한 데이터일 수도 있 다. 상기 '영상획득 시작신호'는 상기 작업현장에서 작업자의 행동으로부터 얻은 신호인것일 수도 있다. 상기 작업자의 행동으로부터 얻은 신호는 ‘작업자가 윙크하는 행위', '작업자가 손을 흔드는 행위', '작업자가 박수를 치는 행위', '안전모를 착용하는 행위' 및 '작업자가 사다리를 설치하는 행위' 중 적어도 하나를 포함하 는 것일 수도 있다. 상기 탐지모델은 작업현장의 영상 및 상기 작업현장의 영상에 포함된 다수의 위험요소에 대한 정보가 멀티-라벨 링(multi labeling)된 학습데이터를 이용하여 학습된것일 수도 있다. 상기 멀티-라벨링된 학습데이터를 이용하여 학습하는 것은 상기 분석장치와는 별도의 학습장치를 이용해서 학습 하는 것일 수도 있다. 상기 작업현장의 영상을 획득하는 단계는 CCTV(Closed-circuit television), 무인비행장치에 부착된 카메라, 액 션캠 및 360도 카메라 중 적어도 하나를 이용하여 상기 작업현장의 영상을 획득하는 것을 포함하는 것일 수도 있다. 상기 위험요소에 대한 정보는 ‘인적 위험요소' 및 '물적 위험요소'에 대한 정보 중 적어도 하나를 포함하는 것 일 수도 있다. 상기 적어도 하나의 위험요소에 대한 정보를 출력하는 단계는 상기 위험요소(들)에 대한 대처법에 대한 정보도 함께 출력하는 것을 포함하는 것일수도 있다. 상기 위험요소(들)에 대한 대처법에 대한 정보는 ‘작업자가 안전모를 미착용하는 경우 안전모를 착용하라는 것', '작업자가 뛰어다니는 경우 뛰어다니지 말라는 것', '단체작업에서 단독으로 작업하는 경우 단체로 작업하 라는 것', '사다리의 안전장치를 미설치 하는 경우 안전장치를 설치하라는 것' 및 '미끄러운 물체를 방치하는 경우 해당 물체를 치우라는 것' 중 적어도 하나를 포함하는 것일 수도 있다. 상기 하나의 위험요소에 대한 정보를 출력하는 단계는 '소리를 통하여 작업자에게 경고음을 출력하는 것', '통 신장치를 이용해 상기 작업자의 단말기에 문자를 통보하는 것' 및 '안전관리자에게 위험요소에 대해 통지하는 것 중 적어도 하나를 포함하는 것 일 수도 있다."}
{"patent_id": "10-2022-0078514", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "이하 설명하는 발명을 통하여 작업자는 개인 디바이스를 활용하여 언제든지 위험요소에 대해 체크받을 수 있다. 이를 통해 담당자나 기술지도 요원이 현장에 있지 않아도, 원격으로 언제든지 탐지 가능하며 안전관리자 책임자 의 역할수행에 부담감을 줄일 수 있으며, 소규모 작업장등에서도 유용하게 활용할 수 있다. 이하 설명하는 발명을 통하여 하나의 영상에 대해서도 복합적인 위험요소 모두를 탐지할 수 있다. 또 이를 위하 여 다중 레이블링(multi labeling)을 할 수 있는 인터페이스를 제공하여 누구든지 손쉽게 영상에 대하여 위험요 소가 무엇이 있는지 레이블링 할 수 있다. 이하 설명하는 발명을 통해 기술지도나 위험여부를 체크하고 싶은 순간에만 장치가 영상을 촬영할 수 있게 하여, 장치나 서버 등의 부하가 적게 걸릴 수 있다."}
{"patent_id": "10-2022-0078514", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하 설명하는 기술은 다양한 변경을 가할 수 있고 여러 가지 실시예를 가질 수 있는 바, 특정 실시예들을 도면 에 예시하고 상세하게 설명하고자 한다. 그러나, 이는 이하 설명하는 기술을 특정한 실시 형태에 대해 한정하려 는 것이 아니며, 이하 설명하는 기술의 사상 및 기술 범위에 포함되는 모든 변경, 균등물 내지 대체물을 포함하 는 것으로 이해되어야 한다. 제1, 제2, A, B 등의 용어는 다양한 구성요소들을 설명하는데 사용될 수 있지만, 해당 구성요소들은 상기 용어 들에 의해 한정되지는 않으며, 단지 하나의 구성요소를 다른 구성요소로부터 구별하는 목적으로만 사용된다. 예 를 들어, 이하 설명하는 기술의 권리 범위를 벗어나지 않으면서 제1 구성요소는 제2 구성요소로 명명될 수 있고, 유사하게 제2 구성요소도 제1 구성요소로 명명될 수 있다. 및/또는 이라는 용어는 복수의 관련된 기재된 항목들의 조합 또는 복수의 관련된 기재된 항목들 중의 어느 항목을 포함한다. 본 명세서에서 사용되는 용어에서 단수의 표현은 문맥상 명백하게 다르게 해석되지 않는 한 복수의 표현을 포함 하는 것으로 이해되어야 하고, \"포함한다\" 등의 용어는 설시된 특징, 개수, 단계, 동작, 구성요소, 부분품 또는 이들을 조합한 것이 존재함을 의미하는 것이지, 하나 또는 그 이상의 다른 특징들이나 개수, 단계 동작 구성요 소, 부분품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 배제하지 않는 것으로 이해되어야 한다. 도면에 대한 상세한 설명을 하기에 앞서, 본 명세서에서의 구성부들에 대한 구분은 각 구성부가 담당하는 주기 능 별로 구분한 것에 불과함을 명확히 하고자 한다. 즉, 이하에서 설명할 2개 이상의 구성부가 하나의 구성부로 합쳐지거나 또는 하나의 구성부가 보다 세분화된 기능별로 2개 이상으로 분화되어 구비될 수도 있다. 그리고 이 하에서 설명할 구성부 각각은 자신이 담당하는 주기능 이외에도 다른 구성부가 담당하는 기능 중 일부 또는 전 부의 기능을 추가적으로 수행할 수도 있으며, 구성부 각각이 담당하는 주기능 중 일부 기능이 다른 구성부에 의 해 전담되어 수행될 수도 있음은 물론이다. 또, 방법 또는 동작 방법을 수행함에 있어서, 상기 방법을 이루는 각 과정들은 문맥상 명백하게 특정 순서를 기 재하지 않은 이상 명기된 순서와 다르게 일어날 수 있다. 즉, 각 과정들은 명기된 순서와 동일하게 일어날 수도 있고 실질적으로 동시에 수행될 수도 있으며 반대의 순서대로 수행될 수도 있다. 이하 설명하는 기술을 설명하는데 필요한 용어에 대해 설명한다. 이하 설명하는 기술에서 작업현장이란 공사현장, 공장내의 현장, 기타 작업등이 일어나는 현장 등이 포함될 수 있다. 이하 설명하는 기술에서 위험요소란 사고가 발생될 수 있는 원인을 제공하는 요소를 포함한다. 이하 설명하는 기술에서 멀티라벨링(multi labeling)은 하나의 데이터에 여러 개의 객체가 있어 각 객체가 어떠 한 클래스에 속하는지 분류하는 것을 말한다. 이는 하나의 데이터를 여러 개 클래스 중에 하나로 분류하는 멀티 클래스(multi class)와 비교 된다. 이하 설명하는 기술에서 학습모델이란 기계학습(merchine learning) 모델을 말하며, 기계 학습모델은 다양한 유 형의 모델을 포함할 수 있다. 예컨데 기계 학습모델은 결정 트리, RF(random forest), KNN(K-nearest neighbor), 나이브 베이즈(Naive Bayes), SVM(support vector machine), ANN(artificial neural network) 등 이 포함될 수도 있다. 상기 ANN은 DNN(Deep Neural Network)가 될 수 있으며, 이는 CNN(Convolutional Neural Network), RNN(Recurrent Neural Network), RBM(Restricted Boltzmann Machine), DBN(Deep Belief Network) 및 GAN(Generative Adversarial Network), RL(Relation Networks) 을 포함할 수 있다. 상기 CNN모델은 컨볼루션 층(Convolution layer), 풀링 층(Pooling layer), 드랍 층(Drop layer), 정규화 층 (Nomalization layer), 평탄화 층(Flatten layer)와 완전한 연결 층(fully connected layer, 또는 dense layer) 및 전역 평균 풀링층(Global Average pooling) 중 적어도 하나를 포함할 수 있다. 상기 컨볼루션 층(Convolution layer)은 입력된 정보에서 특징을 추출하고 이로 부터 특성 맵(feature map)을 만든다. 상기 풀링 층(Pooling layer)은 컨볼루션층에서 만든 특성맵의 크기를 줄이거나 특정 데이터를 강조하 기 위하여 특징 맵의 값중 가장 큰 값을 추출하거나(맥스 풀링 층, Max Pooling layer) 평균 값을 추출한다(평 균 풀링 층, Average Pooling Layer). 상기 드랍 층(Drop layer)은 딥 러닝 모델에서 과적합(Overfitting)을 방지하기 위하여 훈련과정 중에 신경망모델의 일부분만 이용한다. 상기 정규화층(Nomalization layer)는 데이터 를 샘플 혹은 특성 단위로 정규화 한다. 상기 플래튼 층(Flatten layer)은 추출한 데이터의 특징을 하나의 차원 으로 만든다. 상기 완전한 연결 층은(fully connected layer)는 각 layer의 노드(node) 모두 연결해주며, 최종 적으로 입력데이터가 어떤 분류에 속하는 것인지 판단 할 수 있다. 상기 전역 평균 풀링층(Global Average Pooling)은 같은 채널의 특징을 모두 평균내어 채널의 개수만큼의 차원을 가지는 벡터로 만들어 줄 수 있다. 상기 CNN모델은 활성함수로 Sigmoid, Tanh, Softmax, ReLU, Leaky RELU, Parametric RELU, ELU등의 활성함수가 이용될 수도 있다. 먼저 인공지능을 이용한 작업현장의 위험요소를 탐지하는 방법에 대한 전체적인 과정에 대해 설명한다. 도1은 위험요소를 탐지하는 방법에 대한 전체적인 과정을 도시한 것이다. 분석장치는 '영상획득 시작신호'를 수신할 수 있다. 분석장치는 촬영장치을 이용하여 작업현장 의 영상을 획득할 수 있다. 상기 분석장치는 상기 획득한 이미지를 작업현장에서 위험요소를 탐지할 수 있 는 탐지모델에 입력할 수 있다. 상기 분석장치는 상기 탐지모델이 출력한 값을 기초로 상기 작업현장에서 의 적어도 하나의 위험요소에 대해 분석할 수 있다. 상기 분석장치는 상기 분석한 위험요소를 출력장치 를 통하여 출력할 수 있다. 도1에서 분석장치가 촬영장치을 이용해 작업현장의 영상을 획득하는 것은, '영상획득 시작신호'를 수 신함으로써 수행될 수 있다. 상기 '영상획득 시작신호'는 통신데이터로 전송된 신호일 수도 있다. 예를 들어 상기 통신데이터는 광케이블, NFC, WIFI, 블루투스, 인공위성을 이용한 통신등에 의한 데이터 일 수 있다. 또는 상기 '영상획득 시작신호'는 상기 작업현장 작업자의 행동으로부터 얻은 신호일 수도 있다. 상기 작업자의 행동으로부터 얻은 신호란 영상장치가 촬영을 시작하기 위해 하는 행동을 포함한다. 예를 들어 \"윙크하는 행 위\", \"손을 흔드는 행위\", \"박수치는 행위\" , \"사다리를 설치하는 행위\", \"카드를 영상장치에 가져다 대는 행위\" 및 \"안전모를 착용하는 행위\" 중 적어도 하나가 포함되어 있을 수도 있다. 이를 통해 작업현장의 모든 영 상을 획득하는 것이 아닌, 특정행동을 기준 이전 또는 이후의 영상만을 획득할 수도 있다. 그러한 경우 모든 영 상을 저장할 필요가 없어 저장용량 부담을 줄일 수 있다. 상기 분석장치는 상기 작업자의 행동 중 어떠한 행동이 '영상획득 시작신호'가 될 것인지 미리 정해 놓을 수도 있다. 상기 분석장치는 작업자의 행동을 인식하기 위해서 사람의 행동을 인식하는 인식모델을 이용할 수도 있다. 상기 인식모델은 기존 사람의 행동을 촬영한 영상을 학습데이터로 하여, 상기 사람의 행동이 무엇인지 인식하는 학습모델일 수도 있다. 상기 분석장치는 작업현장의 영상을 프레임 단위로 분리해서 획득할 수 있다. 예를 들어 작업현장의 영상 을 촬영하더라도 작업현장의 위험요소가 포함되어 있는 영상의 프레임만을 선택해서 획득할 수도 있다. 또는 상 기 작업자의 특정행동을 기준으로 그 이전 또는 그 이전의 영상의 프레임만을 분리해서 획득할 수도 있다. 도1에서 영장장치는 작업현장의 영상을 촬영할 수 있는 장치를 포함한다. 예를 들어 타워크레인에 부착된 CCTV, 드론에 부착된 카메라, 작업자에게 부착된 액션캠, 360도 카메라, 위성카메라 및 현장에 존재하는 영상송 신이 가능한 surveillance system 중 적어도 하나가 포함될 수도 있다. 상기 영상장치가 촬영하는 작엽현장의 영상에는 적어도 하나의 위험요소가 포함되어 있을 수가 있다. 상기 위험요소는 작업현장에서 사고가 발생될 수 있는 원인을 포함한다. 상기 위험요소에는 '인적 위험요소' 및 '물적 위험요소' 중 적어도 하나가 포함되어 있을 수 있다. 상기 '인적 위험요소'는 작업자의 행동으로 인하여 사고가 발생될 수 있는 것을 포함한다. 예를 들어 안전장비 (안전모, 안전화, 안전벨트, 안전장갑, 안전복, 안전안경 등) 미 착용', '작업물 끝 단에서 작업하는 행위' '뛰 어다니는 행위' 및 '단체작업에서 단독으로 작업하는 행위' 중 적어도 하나가 포함되어 있을 수 있다. 상기 '물적 위험요소'는 작업자의 행동이 아닌 물건등에 의하여 사고가 발생할 수 있는 것을 포함한한다. 예를 들어 '기준에 맞지 아니한 안전모착용', '통로에 얼음과 같은 미끄러운 물체를 방치하는 것', '안전통로를 미 설치', '날카로운 물체 방치' 및 '아웃트리거 미 설치' 중 적어도 하나가 포함되어 있을 수 있다. 도1에서 분석장치는 탐지모델을 이용해서 작업현장의 영상으로부터 위험요소가 무엇이 있는지 탐지 할 수 있다. 이때 작업현장에 다수의 위험요소를 탐지하여 멀티라벨링하여 분석할 수도 있다. 상기 탐지모델은 기존에 존재하는 작업현장의 영상을 학습데이터로 하여 위험요소가 무엇이 있는지 탐지해주도 록 학습된 학습모델일 수도 있다. 상기 학습을 위한 학습데이터로 멀티 라벨링(multi-labeling)된 데이터를 이용할 수도 있다. 상기 학습을 위하여 학습장치가 이용될 수도 있다. 구체적인 내용은 이하에서 설명한다. 상기 탐지모델은 CNN과 같은 딥러닝 모델로 구현될 수도 있으며, 멀티레이블링을 위하여 활성함수으로 sigmoid 함수가 이용될 수도 있다. 도1에서 출력장치는 분석장치가 분석한 작업현장의 위험요소에 대해 출력할 수 있다. 상기 출력장치는 상기 작업현장의 위험요소와 함께 그 대책에 대해서도 함께 출력할 수 있다. 예를 들어 '안전모를 미착용' 위험요인을 탐지하는 경우 그에 대한 대책으로 '안전모를 착용하라'는 대책에 대해서도 함 께 출력할 수 있다. 상기 출력장치는 작업현장의 작업자에게 소리등을 이용해서 탐지한 위험요소에 대해 알려줄 수도 있다. 예 를 들어 '안전모 미착용' 위험요소가 발견된 경우 작업자에게 강한 경고음을 발생시켜 안전모를 미착용했다고 알려 줄 수도 있다. 상기 출력장치는 작업현장의 작업자에게 문자메세지와 같은 통신장치를 이용해서 탐지한 위험요소에 대해 알려 줄 수도 있다. 예를 들어 '안전모 미착용' 위험요소를 탐지한 경우, 상기 작업현장의 작업자에게 문자메세 지로 '안전모를 미착용하였다'는 것을 알려 줄 수 있다. 이하 도2을 통하여 상기 탐지모델을 학습시키는 과정에 대하여 구체적으로 설명한다. 도2는 학습장치(도1의 400)가 탐지모델을 학습시키는 과정에 대해 도시한 것이다. 학습장치는 '영상획득 시작신호'를 수신한다.(S410). 상기 작업자의 행동을 감지하면 작업현장의 영상을 촬영하 기 시작한다(S420). 학습장치는 상기 작업현장의 위험요소에 정보를 획득한다(S430). 학습장치는 상기 촬영한 작업현장 영상과 위험요소에 대한 정보를 이용해서 학습데이터를 만든다(S440). 학습장치는 상기 학습데이터를 이용해서 탐지모델을 학습시킨다(S450). 도2에서 학습장치가 '영상획득 시작신호'를 수신하는 단계(S410)는 통신데이터로 전송된 '영상획득 시작신호'를 수신하는 단계를 포함할 수도 있다. 상기 통신데이터는 이동통신, 위성통신, 레이더, 안테나, RFID(Radio Frequency Identification), 광케이블, NFC(Near Field communication), 블루투스 및 와이파이 중 적어도 하나를 이용한 통신에 의한 데이터일 수도 있 다. 도2에서 학습장치가 '영상획득 시작신호'를 수신하는 단계는(S410), 학습데이터에 이용될 영상을 획득하기 위해 서 작업자의 특정행동을 인식하는 것을 포함한다. 상기 학습장치는 상기 작업자의 행동 중 어떠한 행동을 인식해야 상기 작업현장의 영상을 획득할 것인지 미리 정해 놓을 수도 있다. 예를 들어 학습장치는 '작업자의 박수치는 행위'를 인식하면 작업현장의 영상을 획득하도 록 미리 정해 놓을 수도 있다. 상기 학습장치는 작업자의 특정행동을 인식하기 위해서 사람의 행동을 인식하는 인식모델을 이용할 수도 있다. 상기 인식모델은 기존 사람의 행동을 촬영한 영상을 학습데이터로 하여, 상기 사람의 행동이 무엇인지 인식하는 학습모델일 수도 있다. 도2에서 학습장치가 작업영상을 촬영하는 단계(S420)는 촬영장치를 이용해서 할 수 있다. 예를 들어 상기 촬영 장치에는 타워크레인에 부착된 CCTV, 드론에 부착된 카메라, 작업자에게 부착된 액션캠, 360도 카메라 및 위성 카메라 중 적어도 하나가 포함될 수도 있다. 상기 학습장치가 촬영(S420)하는 작업영상에는 적어도 하나의 위험요소가 포함되어 있을 수가 있다. 상기 위험요소는 작업현장에서 사고가 발생될 수 있는 원인을 포함한다. 상기 위험요소에는 '인적 위험요소' 및 '물적 위험요소' 중 적어도 하나가 포함되어 있을 수 있다. 상기 '인적 위험요소'는 작업자의 행동으로 인하여 사고가 발생될 수 있는 것을 포함한다. 예를 들어 '안전장비 (안전모, 안전화, 안전벨트, 안전장갑, 안전복, 안전안경 등) 미 착용' '작업물 끝단에서 작업하는 행위', '뛰 어다니는 행위' 및 '단체작업에서 단독으로 작업하는 행위' 중 적어도 하나가 포함되어 있을 수 있다. 상기 '물적 위험요소'는 작업자의 행동이 아닌 물건등에 의하여 사고가 발생할 수 있는 것을 포함한한다. 예를 들어 '기준에 맞지 아니한 안전모착용', '통로에 얼음과 같은 미끄러운 물체를 방치하는 것', '안전통로를 미 설치', '날카로운 물체 방치' 및 '아웃트리거 미 설치' 중 적어도 하나가 포함되어 있을 수 있다. 도2에서 작업현장에서 발생할 수 있는 위험요소 정보를 획득하는 과정(S430)은 작업자가 입력하는 정보를 기초 로 할 수 있다. 예를 들어 작업자는 작업현장에 대한 영상에 대해서 '안전모를 미 착용하였다', '날카로운 물체 를 그냥 방치하였다'는 정보를 상기 학습장치에 입력하면, 상기 학습장치는 위험요소에 대한 정보를 획득할 수 있다. 도2에서 학습데이터를 생성하는 과정(S440)는 상기 획득한 영상과 상기 입력받은 위험요소에 대한 정보를 합하 여 학습데이터를 만드는 과정을 포함한다. 예를 들어 상기 획득한 영상에서 '안전모를 미 착용하였다'는 위험요 소 정보를 획득한 경우, 학습모델은 상기 영상에서의 행동과 같은 경우 '안전모를 미착용 한 것이다'라는 학습 데이터를 만들 수 있다. 상기 학습데이터를 생성하는 과정(S440)은 멀티 라벨링(multi labeling)과정이 포함되어 있을 수도 있다. 예를 들어 하나의 영상에 '안전모를 미 착용하였다' , '안전장치 없이 사다리를 설치하였다' 등과 같은 위험요소가 여러 개 있는 경우, 이와 같은 정보를 합쳐서 학습데이터를 만들 수 있다. 도2에서 상기 학습데이터를 이용하여 탐지모델을 학습시키는 과정(S450)은 손실함수로 크로스 엔트로피 함수 (cross-entropy loss function)가 이용될 수도 있다. 또한 상기 탐지모델은 그 활성함수로 Sigmoid, Tanh, Softmax, ReLU, Leaky RELU, Parametric RELU, ELU등을 이용할 수 있다. 이하 도3을 통하여 학습장치(도1의 400)가 학습데이터를 생성하는 실시예에 대해 설명한다(S440). 도3는 학습장치가 학습데이터를 생성하는 실시예를 도시한 것이다. 도3에서 왼쪽의 영상은 학습장치가 촬영한 영상이며, 오른쪽의 항목들(442, 카테고리 위험요소)은 상기 영 상에 대한 위험요소에 대한 정보이다. 상기 왼쪽의 영상은 도2에서 학습장치가 작업영상을 촬영하는 단계(S420)을 통하여 획득한 영상을 포함한 다. 상기 오른쪽의 항목들은 도2에서 위험요소정보를 획득하는 단계(S430)을 통하여 획득하는 위험요소 정보를 포함한다. 상기 위험요소를 획득하는 정보는 카테고리별로 구분하여 획득할 수도 있다. 예를 들어 도3에서 보이 는 것과 같이 위험요소에 대해 크게 인적요인, 물적요인의 카테고리로 나눈 뒤 물적요인 분류에서는 어떠한 물 체(A형 사다리)때문에 위험요소가 있을 수 있다고 선택한뒤 그 사유로 \"아웃트리거 미 설치\" 가 있다고 기재하 고, 인적요인 분류에서는 \"2인1조 작업 미실시', \"안전모 미착용\", \"안전대 미착용\"등의 사유가 있다고 기재하 여 위험요소에 대한 정보를 획득할 수도 있다. 학습장치는 촬영장치를 통해 획득한 영상과 사용자로부터 받은 위험요소 정보를 통합하여 학습데이터 를 만들 수 있다. 학습장치는 하나의 영상에 다수의 위험요소에 대한 정보를 입력 받은 뒤 학습데이터를 만드는 멀티라벨링(multi labeling)을 할 수도 있다. 예를 들어 도3에서 보는 것과 같이 작업자가 사다리를 타고 있는 영상에 대하여 '2인 1조 작업 미실시', '아웃트리거 미설치', '안전모 미착용', '안전대 미착용'이라는 위험요소가 있다고 라벨링할 수 있다. 이하 도4을 통해서 상기 분석장치가 작업현장의 영상을 분석해 작업현장의 위험요소에 대해 분석한 결과에 대해 설명한다. 도4는 분석장치가 분석한 실시예를 도시한 것이다. 도4에서 전체 영상의 사진은 상기 분석장치가 획득한 작업현장의 영상을 말하며, 아래쪽에 '안전모 미착용' 등의 표시는 분석장치가 상기 작업현장에서 탐지한 위험요소에 대한 결과값을 보여준다. 상기 분석장치는 획득한 작업현장의 영상에서 위험요소가 무엇인지 판단할 수 있다. 예를 들어 도4에서 본 것과 같이 작업현장 영상으로부터 상기 작업현장에 '2인1조 작업 미 실시', '아웃 트리거 미설치', '안전대 미착용', '안전대 미착용'과 같은 위험요소가 있다고 파악할 수 있다. 상기 분석장치는 획득한 작업현장 영상으로부터 여러 개의 위험요소가 있는 경우, 이를 멀티라벨링(multi- labeling)하여 분석할 수도 있다. 예를 들어 전술한바와 같이 하나의 영상에 4개의 위험요소가 있다고 파악할 수도 있다. 이하 도5을 통하여 작업현장의 영상으로부터 위험요소를 알려주는 분석장치의 구성에 대해 설명한다. 도5는 분석장치의 구성에 대해서 도시한 예이다. 상기 분석장치는 전술한 분석장치(도1의 200)에 해당한다. 상기 분석장치는 PC, 노트북, 스마트기기, 서버, 또는 데이터처리 전용 칩셋등과 물리적으로 다양한 형태 로 구현될 수도 있다. 상기 분석장치는 입력장치 저장장치, 연산장치을 포함할 수도 있다. 상기 분석장치는 출력 장치을 더 포함할 수도 있다. 도5의 입력장치는 작업현장의 영상을 입력받는 장치를 포함할 수도 있다. 이는 전술한 도1의 영상장치(도 1의 100)가 될 수도 있다. 상기 입력장치는 작업현장의 영상을 유선 또는 무선 네트워크를 통해 수신받는 통신장치를 포함할 수도 있 다. 상기 입력장치는 별도의 저장장치(USB,CD,하드디스크 등)을 통하여 정보를 입력받는 구성을 포함할 수도 있다. 상기 입력장치는 입력받는 데이터를 별도의 측정장치를 통하여 입력받거나, 별도의 DB을 통하여 입력받을 수도 있다. 상기 입력장치는 적어도 하나의 위험요소를 포함하는 작업현장의 영상을 입력받을 수도 있다. 상기 입력장치는 '영상획득 시작신호'를 수신하는 수신장치를 포함할 수도 있다. 도5의 저장장치는 상기 입력장치로부터 온 정보를 저장할 수도 있다. 상기 저장장치는 작업현장의 영상으로부터 위험요소를 탐지해주는 탐지모델을 저장할 수도 있다. 상기 저장장치는 상기 탐지모델이 출력하는 결과값에 대해 저장할 수도 있다. 상기 저장장치는 탐지모델을 학습할 때 이용하는 학습데이터를 저장할 수도 있다. 도5의 연산장치는 상기 입력장치로부터 획득한 영상을 탐지모델에 입력한 뒤 그 출력값을 기준으로 상기 영상으로부터 위험요소를 분석할 수 있다. 도5의 출력장치는 일정한 정보를 출력하는 장치가 될 수도 있다. 상기 출력장치은 데이터 과정에 필요한 인터페이스, 입력된 데이터, 분석결과 등을 출력할 수도 있다. 상기 출력장치은 디스플레이어, 문서를 출력하는 장치, 통신장치 등과 같이 물리적으로 다양한 형태로 구 현될 수도 있다."}
{"patent_id": "10-2022-0078514", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도1은 위험요소를 탐지하는 방법에 대한 전체적인 과정을 도시한 것이다. 도2는 학습장치가 탐지모델을 학습시키는 과정에 대해 도시한 것이다. 도3는 학습장치가 학습데이터를 생성하는 실시예를 도시한 것이다. 도4는 분석장치가 분석한 실시예를 도시한 것이다. 도5는 분석장치의 구성에 대해서 도시한 예이다."}
