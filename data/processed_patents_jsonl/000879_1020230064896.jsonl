{"patent_id": "10-2023-0064896", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0123213", "출원번호": "10-2023-0064896", "발명의 명칭": "학습 몰입도 진단 시스템 및 방법", "출원인": "(주)에듀에이아이", "발명자": "연성주"}}
{"patent_id": "10-2023-0064896", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "학습자의 학습 몰입도를 진단하는 시스템에 있어서,상기 학습자가 학습하는 콘텐츠를 출력하고, 복수의 센서를 구비하여 상기 학습자의 생체 정보 및 학습 환경 정보를 포함하는 센서 정보를 수집하는 출력 장치;상기 학습자의 얼굴을 촬영하는 촬영 장치를 구비하여 상기 학습자의 얼굴 영상을 수집하고, 상기 센서 정보 및상기 학습자의 얼굴 영상을 몰입도 진단 모델에 입력하여 상기 학습자의 학습 몰입도 진단 결과를 도출하는 클라이언트; 및상기 센서 정보 및 상기 학습 몰입도 진단 결과를 저장하고, 상기 센서 정보 및 상기 학습자의 얼굴 영상을 기반으로 상기 몰입도 진단 모델을 생성하는 서버;를 포함하는 학습 몰입도 진단 시스템."}
{"patent_id": "10-2023-0064896", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 출력 장치는,상기 학습자가 학습하는 콘텐츠의 음성 신호를 출력하는 음성 신호 출력부; 및상기 학습자의 뇌파 정보 및 심박 정보를 포함하는 생체 정보를 측정하고, 상기 학습자가 학습하는 대상 공간의공기청정도를 측정하는 센서부;를 포함하는 것인, 학습 몰입도 진단 시스템."}
{"patent_id": "10-2023-0064896", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 클라이언트는,상기 학습자가 복수의 입력 장치를 통해 입력하는 입력 정보, 상기 출력 장치로부터 수집된 센서 정보 및 상기서버로부터 상기 몰입도 진단 모델을 수신하는 수신부;상기 입력 정보 및 센서 정보를 상기 몰입도 진단 모델에 입력하여 상기 학습자의 학습 몰입도 진단 결과를 도출하는 진단부; 및상기 학습 몰입도 진단 결과를 상기 서버로 송신하고, 상기 학습 몰입도 진단 결과를 기반으로 상기 학습자에게주의 정보를 전송하는 송신부;를 포함하는 것인, 학습 몰입도 진단 시스템."}
{"patent_id": "10-2023-0064896", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서,상기 수신부는,상기 학습자의 개인 정보, 콘텐츠 이용 내역, 선호 콘텐츠, 성적을 포함하는 메타데이터를 더 수신하고,상시 송신부는,상기 메타데이터를 상기 서버로 전송하는 것인, 학습 몰입도 진단 시스템.공개특허 10-2024-0123213-3-청구항 5 제3항에 있어서,상기 송신부는,상기 학습 몰입도 진단 결과를 미리 설정된 복수의 단계에 따라 분류하고 상기 분류된 단계에 대응하는 상기 주의 정보를 송신하는 것인, 학습 몰입도 진단 시스템."}
{"patent_id": "10-2023-0064896", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제3항에 있어서,상기 진단부는,미리 설정된 시간 간격으로 상기 학습자가 학습하는 콘텐츠에 대한 상기 학습 몰입도 진단 결과를 복수회 도출하고, 상기 복수회 도출된 학습 몰입도 진단 결과를 종합하여 상기 콘텐츠에 대한 콘텐츠 몰입도를 결정하는 것인, 학습 몰입도 진단 시스템."}
{"patent_id": "10-2023-0064896", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제4항에 있어서,상기 서버는,상기 센서 정보 및 상기 학습 몰입도 진단 결과를 저장하는 데이터 저장부;상기 센서 정보 및 상기 학습자의 얼굴 영상을 복수의 조합으로 라벨링하여 학습 데이터를 생성하는 학습 데이터 생성부;상기 학습 데이터를 학습하여 상기 학습자의 학습 몰입도를 진단하는 몰입도 진단 모델을 생성하는 모델생성부;상기 학습 몰입도 진단 결과를 기반으로 추천 콘텐츠를 결정하고, 상기 추천 콘텐츠를 상기 클라이언트로 전송하는 콘텐츠 추천부; 및상기 학습 몰입도 진단 결과를 출력하고, 상기 학습자 관리를 위한 인터페이스를 제공하는 인터페이스부;를 포함하는 것인, 학습 몰입도 진단 시스템."}
{"patent_id": "10-2023-0064896", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서,상기 학습 데이터 생성부는,미리 설정된 뇌파 집중 지표 범위에 기초하여 상기 센서 정보를 라벨링하여 학습 데이터를 생성하는 것인, 학습몰입도 진단 시스템."}
{"patent_id": "10-2023-0064896", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제7항에 있어서,상기 학습 데이터 생성부는,상기 메타데이터 및 상기 센서 정보를 복수의 조합으로 라벨링하여 학습 데이터를 생성하는 것인, 학습 몰입도진단 시스템."}
{"patent_id": "10-2023-0064896", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제7항에 있어서,상기 모델 생성부는,지식 증류 기법을 기반으로 상기 몰입도 진단 모델을 경량화하는 것인, 학습 몰입도 진단 시스템.공개특허 10-2024-0123213-4-청구항 11 학습자의 학습 몰입도를 진단하는 방법에 있어서,상기 학습자가 학습하는 콘텐츠를 출력하고, 복수의 센서를 구비하여 상기 학습자의 생체 정보 및 학습 환경 정보를 포함하는 센서 정보를 수집하는 단계;상기 학습자의 얼굴을 촬영하는 촬영 장치를 구비하여 상기 학습자의 얼굴 영상을 수집하고, 상기 센서 정보 및상기 학습자의 얼굴 영상을 몰입도 진단 모델에 입력하여 상기 학습자의 학습 몰입도 진단 결과를 도출하는 단계; 및상기 센서 정보 및 상기 학습 몰입도 진단 결과를 저장하고, 상기 센서 정보 및 상기 학습자의 얼굴 영상을 기반으로 상기 몰입도 진단 모델을 생성하는 단계;를 포함하는 학습 몰입도 진단 방법."}
{"patent_id": "10-2023-0064896", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항의 방법을 컴퓨터에서 실행시키기 위한 프로그램을 기록한 컴퓨터로 읽을 수 있는 기록매체."}
{"patent_id": "10-2023-0064896", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "학습 몰입도 진단 시스템에 관한 것이며, 학습자가 학습하는 콘텐츠를 출력하고, 복수의 센서를 구비하여 상기 학습자의 생체 정보 및 학습 환경 정보를 포함하는 센서 정보를 수집하는 출력 장치, 상기 학습자의 얼굴을 촬영 하는 촬영 장치를 구비하여 상기 학습자의 얼굴 영상을 수집하고, 상기 센서 정보 및 상기 학습자의 얼굴 영상을 몰입도 진단 모델에 입력하여 상기 학습자의 학습 몰입도 진단 결과를 도출하는 클라이언트 및 상기 센서 정보 및 상기 학습 몰입도 진단 결과를 저장하고, 상기 센서 정보 및 상기 학습자의 얼굴 영상을 기반으로 상기 몰입 도 진단 모델을 생성하는 서버를 포함할 수 있다."}
{"patent_id": "10-2023-0064896", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본원은 학습 몰입도 진단 시스템 및 방법에 관한 것이다."}
{"patent_id": "10-2023-0064896", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "코로나19의 확산은 우리 사회에 많은 변화를 초래하였다. 정부에서는 전염병 확산을 방지하기 위하여, 고강도 사회적 거리 두기 정책을 실시하였으며, 다중 이용 시설과 업종의 운영을 제한하였다. 코로나19가 장기화됨에 따라, 우리 사회는 비대면 접촉이 일반화되는 ‘언택트 사회(untact society)’ 또는 면대면 접촉이 줄어들고 온라인 접촉이 늘어나는 ‘온택트 사회(ontact society)’로 변화되고 있다. 코로나19의 예기치 못한 확산으로 인하여, 단위학교에서는 원격수업은 인적, 물적 기반을 충분히 갖추지 못한 상태에서 시작되었다. 학교 현장에 서는 컴퓨터나 스마트폰 같은 기기 확보, 인터넷 환경의 구축, 학습관리시스템(LMS)의 기능 부족, 서버 불안정, 교사의 정보화 능력의 한계 등과 같은 어려움을 경험하였다. 또한, 온라인 수업에 익숙하지 않은 교원들은 수업 을 준비하고 수업 자료를 개발하기 위해 많은 시간을 투자하였으며, 학생들이 정상적으로 수업에 참여할 수 있 도록 많은 노력을 기울이게 되었다. 하지만 기존 대면 수업과 달리 비대면 수업 시 학습자의 집중도는 현저히 떨어지고, 교육자가 이를 파악하는 데 어려움을 겪고 있다. 종래의 집중도 분석 기술은 카메라모듈을 통해 촬영된 영상매체를 이용하여, 학습자의 얼굴을 검출하고, 검출된 얼굴을 기반하여 얼굴 방향을 분석하고, 얼굴이 화면을 향하고 있는지 분석함으로써, 학습자가 실제로 화면을 응시하고 있는지 분석하여, 원격지에 존재하는 학습자의 학습 집중도를 제공한다. 하지만, 이러한 진단 결과만 으로 집중도를 정확히 설명하는데 어려움이 있다. 이에, 인공지능 모델을 기반으로 학습자의 생체 정보를 복합 데이터로 활용하여 학습 몰입도를 판단하고 교수자가 관리 가능한 클라이언트를 제공하는 학습 몰입도 진단 시 스템을 개시하고자 한다. 본원의 배경이 되는 기술은 한국등록특허공보 제10-2245319호에 개시되어 있다."}
{"patent_id": "10-2023-0064896", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본원은 전술한 종래 기술의 문제점을 해결하기 위한 것으로서, 학습자의 생체 정보 및 복합 신호를 기반으로 인 공지능 모델을 이용하여 학습자의 학습 몰입도를 진단할 수 있는 학습 몰입도 진단 장치를 제공하려는 것을 목 적으로 한다. 본원은 전술한 종래 기술의 문제점을 해결하기 위한 것으로서, 학습자의 디바이스에 연결되어 있는 기기를 통해 학습자의 모습, 환경에서 발생하는 다양한 생체 신호를 검출하고 복합 데이터로 활용하여 학습 몰입도를 진단할수 있는 학습 몰입도 진단 시스템을 제공하려는 것을 목적으로 한다. 다만, 본원의 실시예가 이루고자 하는 기술적 과제는 상기된 바와 같은 기술적 과제들로 한정되지 않으며, 또 다른 기술적 과제들이 존재할 수 있다."}
{"patent_id": "10-2023-0064896", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기한 기술적 과제를 달성하기 위한 기술적 수단으로서, 본원의 일 실시예에 따른 학습 몰입도 진단 시스템은 학습자가 학습하는 콘텐츠를 출력하고, 복수의 센서를 구비하여 상기 학습자의 생체 정보 및 학습 환경 정보를 포함하는 센서 정보를 수집하는 출력 장치, 상기 학습자의 얼굴을 촬영하는 촬영 장치를 구비하여 상기 학습자 의 얼굴 영상을 수집하고, 상기 센서 정보 및 상기 학습자의 얼굴 영상을 몰입도 진단 모델에 입력하여 상기 학 습자의 학습 몰입도 진단 결과를 도출하는 클라이언트 및 상기 센서 정보, 상기 학습 몰입도 진단 결과를 저장 하고, 상기 센서 정보 및 상기 학습자의 얼굴 영상을 기반으로 상기 몰입도 진단 모델을 생성하는 서버를 포함 할 수 있다. 또한, 상기 출력 장치는 상기 학습자가 학습하는 콘텐츠의 음성 신호를 출력하는 음성 신호 출력부 및 상기 학 습자의 뇌파 정보 및 심박 정보를 포함하는 생체 정보를 측정하고, 상기 학습자가 학습하는 대상 공간의 학습 환경 정보를 수집하는 센서부를 포함할 수 있다. 또한, 상기 클라이언트는 상기 학습자가 복수의 입력 장치를 통해 입력하는 입력 정보, 상기 출력 장치로부터 수집된 센서 정보 및 상기 서버로부터 상기 몰입도 진단 모델을 수신하는 수신부, 상기 입력 정보 및 센서 정보 를 상기 몰입도 진단 모델에 입력하여 상기 학습자의 학습 몰입도 진단 결과를 도출하는 진단부 및 상기 학습 몰입도 진단 결과를 상기 서버로 송신하고, 상기 학습 몰입도 진단 결과를 기반으로 상기 학습자에게 주의 정보 를 전송하는 송신부를 포함할 수 있다. 또한, 상기 수신부는 상기 학습자의 개인 정보, 콘텐츠 이용 내역, 선호 콘텐츠, 성적을 포함하는 메타데이터를 더 수신하고, 상기 송신부는 상기 메타데이터를 상기 서버로 전송할 수 있다. 또한, 상기 송신부는 학습 몰입도 진단 결과를 미리 설정된 복수의 단계에 따라 분류하고 상기 분류된 단계에 대응하는 상기 주의 정보를 송신할 수 있다. 또한, 상기 진단부는 미리 설정된 시간 간격으로 상기 학습자가 학습하는 콘텐츠에 대한 상기 학습 몰입도 진단 결과를 복수회 도출하고, 상기 복수회 도출된 학습 몰입도 진단 결과를 종합하여 상기 콘텐츠에 대한 콘텐츠 몰 입도를 결정할 수 있다. 또한, 상기 서버는 상기 센서 정보 및 상기 학습 몰입도 진단 결과를 저장하는 데이터 저장부, 상기 센서 정보 및 상기 학습자의 얼굴 영상을 복수의 조합으로 라벨링하여 학습 데이터를 생성하는 학습 데이터 생성부, 상기 학습 데이터를 학습하여 상기 학습자의 학습 몰입도를 진단하는 몰입도 진단 모델을 생성하는 모델 생성부, 상 기 학습 몰입도 진단 결과를 기반으로 추천 콘텐츠를 결정하고, 상기 추천 콘텐츠를 상기 클라이언트로 전송하 는 콘텐츠 추천부 및 상기 학습 몰입도 진단 결과를 출력하고, 상기 학습자 관리를 위한 인터페이스를 제공하는 인터페이스부를 포함할 수 있다. 또한, 상기 학습 데이터 생성부는 미리 설정된 뇌파 집중 지표 범위에 기초하여 상기 센서 정보를 라벨링하여 학습 데이터를 생성할 수 있다. 또한, 상기 학습 데이터 생성부는 상기 메타데이터 및 상기 센서 정보를 복수의 조합으로 라벨링하여 학습 데이 터를 생성할 수 있다. 또한, 상기 모델 생성부는 지식 증류 기법을 기반으로 상기 몰입도 진단 모델을 경량화할 수 있다. 한편, 본원의 일 실시예에 따른 학습 몰입도 진단 방법은 상기 학습자가 학습하는 콘텐츠를 출력하고, 복수의 센서를 구비하여 상기 학습자의 생체 정보 및 학습 환경 정보를 포함하는 센서 정보를 수집하는 단계, 상기 학 습자의 얼굴을 촬영하는 촬영 장치를 구비하여 상기 학습자의 얼굴 영상을 수집하고, 상기 센서 정보 및 상기 학습자의 얼굴 영상을 몰입도 진단 모델에 입력하여 상기 학습자의 학습 몰입도 진단 결과를 도출하는 단계 및 상기 센서 정보 및 상기 학습 몰입도 진단 결과를 저장하고, 상기 센서 정보 및 상기 학습자의 얼굴 영상을 기 반으로 상기 몰입도 진단 모델을 생성하는 단계를 포함할 수 있다. 상술한 과제 해결 수단은 단지 예시적인 것으로서, 본원을 제한하려는 의도로 해석되지 않아야 한다. 상술한 예 시적인 실시예 외에도, 도면 및 발명의 상세한 설명에 추가적인 실시예가 존재할 수 있다."}
{"patent_id": "10-2023-0064896", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "전술한 본원의 과제 해결 수단에 의하면, 학습자 기기의 카메라, 마이크, 키보드 및 마우스에서 데이터를 수집 하고 주요 변수들을 추출 및 가공하여 인공지능을 기반으로 학습 몰입도를 단계별로 분류할 수 있고, 분석된 학 습 몰입도 단계를 클라우드 서버로 전송하여, 학습자를 실시간으로 모니터링하고 다수의 학습자를 관리할 수 있 는 시스템을 제공할 수 있는 효과가 있다. 다만, 본원에서 얻을 수 있는 효과는 상기된 바와 같은 효과들로 한정되지 않으며, 또 다른 효과들이 존재할 수 있다."}
{"patent_id": "10-2023-0064896", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "아래에서는 첨부한 도면을 참조하여 본원이 속하는 기술 분야에서 통상의 지식을 가진 자가 용이하게 실시할 수 있도록 본원의 실시예를 상세히 설명한다. 그러나 본원은 여러 가지 상이한 형태로 구현될 수 있으며 여기에서 설명하는 실시예에 한정되지 않는다. 그리고 도면에서 본원을 명확하게 설명하기 위해서 설명과 관계없는 부분 은 생략하였으며, 명세서 전체를 통하여 유사한 부분에 대해서는 유사한 도면 부호를 붙였다. 본원 명세서 전체에서, 어떤 부분이 다른 부분과 \"연결\"되어 있다고 할 때, 이는 \"직접적으로 연결\"되어 있는 경우뿐 아니라, 그 중간에 다른 소자를 사이에 두고 \"전기적으로 연결\" 또는 \"간접적으로 연결\"되어 있는 경우 도 포함한다. 본원 명세서 전체에서, 어떤 부재가 다른 부재 \"상에\", \"상부에\", \"상단에\", \"하에\", \"하부에\", \"하단에\" 위치 하고 있다고 할 때, 이는 어떤 부재가 다른 부재에 접해 있는 경우뿐 아니라 두 부재 사이에 또 다른 부재가 존 재하는 경우도 포함한다. 본원 명세서 전체에서, 어떤 부분이 어떤 구성 요소를 \"포함\"한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다른 구성 요소를 제외하는 것이 아니라 다른 구성 요소를 더 포함할 수 있는 것을 의미한다. 본원은 학습 몰입도 진단 시스템 및 방법에 관한 것이다. 도 1은 본원의 일 실시예에 따른 학습 몰입도 진단 시스템의 개략적인 구성을 나타낸 도면이다. 본원에서 개시하는 학습 몰입도 진단 시스템은 출력 장치, 클라이언트 및 서버를 포함할 수 있 다. 한편, 도 1에는 출력 장치 및 클라이언트가 하나씩 구비되는 것으로 도시되어 있으나, 이에 한정되 는 것은 아니며, 본원의 구현예에 따라서 콘텐츠를 학습하는 복수의 학습자가 착용한 출력 장치 또는 복수 의 학습자가 사용하는 클라이언트가 포함될 수 있고, 복수의 서버가 본원에서 개시하는 학습 몰입도 진 단 시스템을 통합적으로 관리할 수 있음은 물론이다. 출력 장치, 클라이언트 및 서버 상호간은 네트워크를 통해 통신할 수 있다. 네트워크는 단 말들 및 서버들과 같은 각각의 노드 상호간에 정보 교환이 가능한 연결 구조를 의미하는 것으로, 이러한 네트워 크의 일 예에는, 3GPP(3rd Generation Partnership Project) 네트워크, LTE(Long Term Evolution) 네트워 크, 5G 네트워크, WIMAX(World Interoperability for Microwave Access) 네트워크, 인터넷(Internet), LAN(Local Area Network), Wireless LAN(Wireless Local Area Network), WAN(Wide Area Network), PAN(Personal Area Network), wifi 네트워크, 블루투스(Bluetooth) 네트워크, 위성 방송 네트워크, 아날로그 방송 네트워크, DMB(Digital Multimedia Broadcasting) 네트워크 등이 포함되나 이에 한정되지는 않는다. 서버는 및 관리자 단말(미도시) 상호간은 네트워크를 통해 통신할 수 있다. 관리자 단말(미도시)은 예 를 들면, 스마트폰(Smartphone), 스마트패드(SmartPad), 태블릿 PC등과 PCS(Personal Communication System), GSM(Global System for Mobile communication), PDC(Personal Digital Cellular), PHS(Personal Handyphone System), PDA(Personal Digital Assistant), IMT(International Mobile Telecommunication)-2000, CDMA(Code Division Multiple Access)-2000, W-CDMA(Wideband-Code Division Multiple Access), Wibro(Wireless Broadband Internet) 단말기 같은 모든 종류의 무선 통신 장치일 수 있다. 본원의 일 실시예에 따르면, 출력 장치는 학습자가 학습하는 콘텐츠를 출력하고, 복수의 센서를 구비하여 학습자의 생체 정보 및 학습 환경 정보를 포함하는 센서 정보를 수집할 수 있다. 이와 관련하여, 도 2는 본원의 일 실시예에 따른 출력 장치의 개략적인 구성을 나타낸 블록도이다. 도 2를 참조하면, 출력 장치는 학습자가 학습하는 콘텐츠의 음성 신호를 출력하는 음성 신호 출력부 및 학습자의 뇌파 정보 및 심박 정보를 포함하는 생체 정보를 측정하고, 학습자가 학습하는 대상 공간의 학습 환경 정보를 수집하는 센서부를 포함할 수 있다. 구체적으로, 출력 장치는 콘텐츠를 학습하는 학습자의 머리에 착용되어 콘텐츠의 음성 신호를 출력하고, 뇌 파 측정 센서, 심박 센서를 통해 콘텐츠를 학습하는 학습자의 생체 신호를 측정하고, 미세먼지 측정 센서 또는 이산화탄소 농도 측정 센서를 통해 학습자가 학습하는 대상 공간의 공기청정도를 측정할 수 있다. 본원의 일 실시예에 따르면, 출력 장치는 학습자의 두피와 접촉하는 영역에 뇌파 측정 센서를 구비하고, 뇌 파 측정 센서는 수개의 전극으로 구성되어 학습자로부터 측정된 전기신호를 증폭한 파형의 뇌파 정보를 획득할 수 있다. 뇌파는 뇌의 활동에 따라 일어나는 전류 또는 그것을 도출 및/또는 증폭하여 기록한 것을 의미한다. 즉, 뇌의 전기적 활동에 의해서 일어나는 두피 상의 두 점 사이의 전위 변동을 연속적으로 기록한 것을 뇌파(두피 뇌파) 라고 한다. 이것에 대해서 뇌의 피질(皮質)에서 유도하는 것을 각각 피질 뇌파라고 부른다. 임상적으로는 두피 뇌파를 보통 간단하게 뇌파라고 한다. 이 전위 변동은 심근 및 골격근과 마찬가지로 물리적 또는 화학적 변동에 의해서 전위차를 일으키는 신경 세포의 기본적 특성에 기인하고 있다. 또한, 출력 장치의 뇌파 측정 센서에 의해 측정된 뇌파의 유형에는 델타(DELTA, δ)파, 세타(THETA, θ)파, 알파(ALPHA, α)파, 베타(BETA, β)파, 및 감마(GAMMA, γ)파 유형이 포함될 수 있다. 이에만 한정되는 것은 아 니고, 뇌파의 유형에는 SMR파, 하이베타(HIGH BETA)파 등이 포함될 수 있다. 또한, 출력 장치는 학습자의 측두동맥과 접촉하도록 하는 영역에 심박 센서를 구비하고, 학습자로부터 측정 된 심박 정보를 획득할 수 있다. 예를 들어, 학습자로부터 측정된 심박 정보는 40bpm ~ 55bpm(느림), 55bpm ~ 75bpm(정상), 75bpm ~ 120bpm(빠름) 또는 120bpm ~ 170bpm(매우 빠름)으로 분류된 정보를 획득할 수 있다. 본원에서 개시하는 센서부를 구성하는 센서는 상술한 센서들로만 한정되는 것이 아니라 학습자의 생체 정 보를 획득하고, 학습 환경 정보를 수집할 수 있는 다양한 센서가 이용될 수 있음은 물론이다. 본원의 일 실시예에 따르면, 클라이언트는 학습자의 얼굴을 촬영하는 촬영 장치를 구비하여 학습자의 얼굴 영상을 수집하고, 센서 정보 및 학습자의 얼굴 영상을 몰입도 진단 모델에 입력하여 학습자의 몰입도 진단 결과 를 도출할 수 있다. 이와 관련하여, 도 3은 본원의 일 실시예에 따른 클라이언트의 개략적인 구성을 나타낸 블록도이다. 도 3을 참조하면, 클라이언트는 학습자가 복수의 입력 장치를 통해 입력하는 입력 정보, 출력 장치로부 터 수집된 센서 정보 및 서버로부터 몰입도 진단 모델을 수신하는 수신부, 입력 정보 및 센서 정보를 몰입도 진단 모델에 입력하여 학습자의 학습 몰입도 진단 결과를 도출하는 진단부 및 학습 몰입도 진단 결 과를 서버로 송신하고, 학습 몰입도 진단 결과를 기반으로 학습자에게 주의 정보를 전송하는 송신부를 포함할 수 있다. 구체적으로, 클라이언트의 수신부는 학습자로부터 키보드, 마우스, 터치스크린 등의 전자기기 또는 출 력 장치에 구비된 마이크를 포함하는 복수의 입력 장치를 통해 입력되는 입력 정보, 출력 장치에 구비 된 각종 센서로부터 수집된 학습자의 생체 정보 또는 학습 환경 정보를 포함하는 센서 정보를 수신하고, 진단부 는 수신부에서 수신한 몰입도 진단 모델을 기반으로 입력 정보 및 센서 정보를 몰입도 진단 모델에 입력하여 해당 콘텐츠에 대한 학습자의 학습 몰입도 진단 결과를 산출하고, 학습 몰입도 진단 결과에 따라 주의 정보를 생성하며, 송신부는 생성된 주의 정보를 클라이언트 또는 서버로 전송할 수 있다.또한, 본원의 일 실시예에 따르면, 수신부는 학습자의 개인 정보, 콘텐츠 이용 내역, 선호 콘텐츠, 성적을 포함하는 메타데이터를 수신할 수 있다. 구체적으로, 수신부는 서버로부터 학습자의 연령, 성별, 거주지, 학력, 전공을 포함하는 개인 정보, 학습자의 과목별 콘텐츠 이용 내역, 기간별 콘텐츠 이용 내역을 포함하는 콘텐츠 이용 내역, 학습자가 선호하는 콘텐츠의 종류 및 강사를 포함하는 선호 콘텐츠, 학습자가 학기별, 과목별로 사전에 입력한 성적을 포함하는 메 타데이터를 수신할 수 있다. 또한, 본원의 일 실시예에 따르면, 진단부는 미리 설정된 시간 간격으로 학습자가 학습하는 콘텐츠에 대한 학습 몰입도 진단 결과를 복수회 도출하고, 복수회 도출된 학습 몰입도 진단 결과를 종합하여 콘텐츠에 대한 콘 텐츠 몰입도를 결정할 수 있다. 구체적으로, 진단부는 학습자가 콘텐츠를 학습하는 동안 센서부로부터 미리 설정된 시간 간격으로 센 서 정보를 획득하여 몰입도 진단 모델에 입력하여 각각의 시간에 대한 학습 몰입도 진단 결과를 도출하고, 복수 회 도출된 학습 몰입도 진단 결과를 종합하여 해당 콘텐츠에 대한 콘텐츠 몰입도를 산출할 수 있다. 또한, 진단부는 복수회 도출된 각각의 학습 몰입도 진단 결과를 기반으로 학습자의 콘텐츠 몰입도 저하 구 간 정보를 생성할 수 있다. 예를 들어, 진단부는 콘텐츠를 학습하는 학습자의 몰입도 진단 결과가 0-10분은 60, 11-20분은 80, 21- 30분은 40, 31-40분은 30인 경우 해당 콘텐츠의 21-30분 구간을 콘텐츠 몰입도 저하 구간 정보로 생성하는 것일 수 있다. 또한, 진단부는 학습자가 학습한 복수의 콘텐츠에 대한 각각의 콘텐츠 몰입도 저하 구간 정보를 기반으로 학습자 몰입도 저하 정보를 생성할 수 있다. 예를 들어, 진단부는 학습자의 제1콘텐츠 몰입도 저하 구간 정보가 21-30분 구간이고, 제2콘텐츠의 몰입도 저하 구간 정보가 31-40분 구간, 제3콘텐츠의 몰입도 저하 구간 정보가 31-40분 구간, 제4콘텐츠의 몰입도 저하 구간 정보가 41-50분 구간인 경우 31-40분 구간을 학습자 몰입도 저하 정보로 생성하는 것일 수 있다. 또한, 본원의 일 실시예에 따르면 송신부는 메타데이터를 서버로 전송하고, 학습 몰입도 진단 결과를 복수의 단계로 구분하여 센서 정보에 기초하여 미리 설정된 주의 정보를 클라이언트 또는 서버로 전송 할 수 있다. 구체적으로, 송신부는 몰입도 진단 결과를 미리 설정된 구간에 따라 복수의 단계로 구분하고 구분된 단계 에 대응하는 주의 정보를 클라이언트 또는 서버로 전송할 수 있다. 예를 들어, 몰입도 진단 결과를 0-10은 1단계, 11-20은 2단계, 21-40은 3단계, 41-60은 4단계, 61-80은 5단계, 80-100은 6단계로 구분한 경우, 송신부는 진단부에서 측정된 학습자의 몰입도 진단 결과가 1단계이면 \"집중하세요\", 2단계이면 \"더 집중해주세요\" 등의 주의 정보를 클라이언트 또는 서버로 전송할 수 있다. 본원의 일 실시예에 따르면 서버는 센서 정보 및 학습 몰입도 진단 결과를 저장하고, 센서 정보 및 학습자 의 얼굴 영상을 기반으로 몰입도 진단 모델을 생성할 수 있다. 이와 관련하여, 도 4는 본원의 일 실시예에 따른 서버의 개략적인 구성을 나타낸 블록도이다. 도 4를 참조하면, 서버는 데이터 저장부, 학습 데이터 생성부, 모델 생성부, 콘텐츠 추천부 및 인터페이스부를 포함할 수 있다. 본원의 일 실시예에 따르면, 데이터 저장부는 센서 정보 및 학습 몰입도 진단 결과를 저장할 수 있다. 구체적으로, 데이터 저장부는 출력 장치에서 측정된 각종 센서 정보, 미리 설정된 시간 간격으로 측정 된 학습자의 학습 몰입도 진단 결과, 콘텐츠 몰입도, 콘텐츠 몰입도 저하 구간 정보, 학습자 몰입도 저하 정보, 학습자의 개인 정보, 콘텐츠 이용 내역, 선호 콘텐츠, 성적을 포함하는 메타데이터를 저장할 수 있다. 본원의 일 실시예에 따르면, 학습 데이터 생성부는 센서 정보 및 학습자의 얼굴 영상을 복수의 조합으로 라벨링하여 학습 데이터를 생성할 수 있다. 구체적으로, 학습 데이터 생성부는 몰입도 진단 모델의 학습을 위하여 센서 정보에 포함된 뇌파 정보 및 심박 정보, 학습자가 학습하는 대상 공간의 학습 환경 정보와 동일한 시간 구간에 촬영된 학습자의 얼굴 영상을 매칭하여 라벨링한 학습 데이터를 생성할 수 있다. 예를 들어, 출력 장치에서 측정된 뇌파의 주파수가 1 Hz 이상 4 Hz 미만인 경우 뇌파의 유형을 델타파인 것으로 식별하고, 식별된 뇌파의 유형에 대응하는 학습자의 몰입도 상태로는 숙면 상태인 것으로 판단할 수 있다. 마찬가지로, 측정된 뇌파의 주파수가 4 Hz 이상 8 Hz 미만인 경우에는 뇌파의 유형이 세타파로 식별되고, 학습 자의 몰입도 상태로는 졸린 상태, 망상, 산만함, 백일몽의 상태로 판단될 수 있다. 측정된 뇌파의 주파수가 8 Hz 이상 12 Hz 미만인 경우에는 뇌파의 유형이 알파파로 식별되고, 학습자의 몰입도 상태로는 집중이 느슨하고 정신이 멍한 상태로 판단될 수 있다. 측정된 뇌파의 주파수가 12 Hz 이상 15 Hz 미만인 경우에는 뇌파의 유형이 SMR파로 식별되고, 학습자의 몰입도 상태로는 움직이지 않는 상태에서 집중력을 유지하는 상태로 판단될 수 있 다. 측정된 뇌파의 주파수가 15 Hz 이상 18 Hz 미만인 경우에는 뇌파의 유형이 베타파로 식별되고, 학습자의 몰입도 상태로는 활동적인 상태에서 집중력을 유지하는 상태로 판단될 수 있다. 측정된 뇌파의 주파수가 18 Hz 이상 30 Hz 미만인 경우에는 뇌파의 유형이 하이베타파로 식별되고, 뇌 상태로는 경직된 상태, 불안한 상태, 긴장한 상 태로 판단될 수 있다. 측정된 뇌파의 주파수가 30 Hz 이상인 경우에는 뇌파의 유형이 감마파로 식별되고, 뇌 상 태로는 흥분한 상태, 불안한 상태, 순간 인지하는 상태로 판단할 수 있다. 학습 데이터 생성부는 센서부에서 측정된 델타(DELTA, δ)파, 세타(THETA, θ)파, 알파(ALPHA, α) 파, 베타(BETA, β)파, 및 감마(GAMMA, γ)파를 포함하는 복수의 뇌파 유형 중 어느 하나와 해당 뇌파 유형이 측정된 시간 구간에 대응하는 학습자의 얼굴 영상을 매칭하여 라벨링한 학습 데이터를 생성하는 것일 수 있다. 달리 말해, 학습자의 몰입도 상태에 따른 학습자의 얼굴 영상을 매칭하여 라벨링한 학습 데이터를 생성하는 것 일 수 있다. 또한, 학습 데이터 생성부는 미리 학습된 알고리즘을 통해 학습자의 얼굴 영상에서 학습자 얼굴의 특징점 좌표를 계산하고 각각의 특징점 좌표와 뇌파 정보 및 심박 정보, 학습자가 학습하는 대상 공간의 학습 환경 정 보를 매칭하여 라벨링한 학습 데이터를 생성할 수 있다. 구체적으로, 학습 데이터 생성부는 미리 학습된 알고리즘을 통해 동공의 위치, 입술의 위치, 눈썹의 위치, 코의 위치, 코의 높이, 턱의 높이, 얼굴의 윤곽 등의 얼굴의 특징점 정보를 파악하고 각각의 특징점 좌표를 x축 의 좌표와 y축의 좌표, 높낮이 정보인 z축의 좌표를 계산할 수 있다. 예를 들어, 얼굴의 특징점 좌표를 계산하는 알고리즘은 XceptionNet 알고리즘일 수 있다. XceptionNet 알고리즘 은 이미지의 특징을 추출하기 위한 합성곱 신경망 모델 중 하나로 중요한 특징에 가중치를 주어 학습할 수 있다. 또한, XceptionNet 알고리즘을 훈련하기 위한 데이터는 68개의 얼굴 특징점을 제공하는 오픈 데이터셋인 300W- LP일 수 있다. 300W-LP 데이터셋은 얼굴 특징점 검출에 있어서 머리 자세가 크게 틀어진 문제(large-pose)를 해 결하기 위하여 측면 얼굴 렌더링 방법으로 300W 데이터셋을 렌더링하여 제작된 데이터셋으로 61,225장의 얼굴 이미지를 포함한다. 또한 다양한 표정의 이미지, 다양한 환경에서의 이미지, 다양한 각도에서 촬영한 이미지를 포함한다. 300W-LP 데이터셋은 렌더링을 통해 만들어진 얼굴의 측면 이미지를 포함하여 large-pose에 더 강인하 도록 학습할 수 있다. 300W-LP 데이터셋은 총 9,000장의 이미지를 포함하고 6,679장의 이미지는 눈썹, 눈, 얼굴, 윤곽 등의 위치를 표현한 68개의 얼굴 특징점 좌표 및 3D 좌표를 제공할 수 있다. 또한, 상술한 300W-LP 데이터셋을 기초하여 학습한 XceptionNet 알고리즘을 통해 얼굴 특징점을 계산할 수 있으 나, 이에 한정되는 것은 아니다. 또한, 본원의 일 실시예에 따르면, 학습 데이터 생성부는 메타데이터 및 센서 정보를 복수의 조합으로 라 벨링하여 학습 데이터를 생성할 수 있다. 구체적으로, 학습 데이터 생성부는 출력 장치에서 측정된 센서 정보와 학습자의 개인 정보, 콘텐츠 이 용 내역, 선호 콘텐츠, 성적을 포함하는 메타데이터를 복수의 조합으로 라벨링하여 학습 데이터를 생성할 수 있 다. 본원의 일 실시예에 따르면, 모델 생성부는 학습 데이터를 학습하여 학습자의 학습 몰입도를 진단하는 몰 입도 진단 모델을 생성할 수 있다.구체적으로, 모델 생성부는 센서 정보, 학습자의 얼굴 영상 및 메타데이터를 복수의 조합으로 라벨링하여 생성된 학습 데이터를 학습하여 학습자의 몰입도를 진단하는 몰입도 진단 모델을 생성할 수 있다. 본원의 일 실시예에 따른 몰입도 진단 모델은 예를 들어, 복수의 기계 학습 신경망(Neural Network)을 기반으로 하는 모델일 수 있다. 객체 인식 모델은 인간의 뇌 구조를 컴퓨터 상에서 모의하도록 설계될 수 있으며 인간의 신경망의 뉴런(neuron)을 모의하는, 가중치를 가지는 복수의 네트워크 노드들을 포함할 수 있다. 복수의 네트워 크 노드들은 뉴런이 시냅스(synapse)를 통하여 신호를 주고 받는 뉴런의 시냅틱(synaptic) 활동을 모의하도록 각각 연결 관계를 형성할 수 있다. 또한 객체 인식 모델은, 일 예로, 신경망 모델, 또는 신경망 모델에서 발전 한 딥 러닝 모델을 포함할 수 있다. 딥 러닝 모델에서 복수의 네트워크 노드들은 서로 다른 깊이(또는, 레이 어)에 위치하면서 컨볼루션(convolution) 연결 관계에 따라 데이터를 주고 받을 수 있다. 인공지능 모델의 예에 는 DNN(Deep Neural Network), RNN(Recurrent Neural Network), BRDNN(Bidirectional Recurrent Deep Neural Network) 등이 있을 수 있으나 이에 한정되지 않는다. 또한, 본원의 일 실시예에 따르면, 클라이언트의 진단부는 서버에서 생성된 몰입도 진단 모델에 센서 정보, 학습자의 얼굴 영상, 입력 장치를 통해 입력되는 입력 정보 중 어느 하나를 입력하여 학습자의 학습 몰입도 진단 결과를 도출할 수 있다. 구체적으로, 진단부는 센서 정보, 학습자의 얼굴 영상, 입력 장치를 통해 입력되는 입력 정보를 다양한 구 성으로 조합하여 라벨링된 학습 데이터를 학습하여 생성된 몰입도 진단 모델에 센서 정보, 학습자의 얼굴 영상, 입력 장치를 통해 입력되는 입력 정보 중 적어도 어느 하나를 입력하여 학습자의 학습 몰입도 진단 결과를 도출 할 수 있다. 본원의 일 실시예에 따르면, 서버는 생성된 몰입도 진단 모델을 저장하고 클라이언트의 요청에 따라 몰 입도 진단 모델을 클라이언트로 송신할 수 있다. 구체적으로, 복수의 학습자 별로 생성된 몰입도 진단 모델은 서버에 보관되고, 복수의 학습자 각각의 클라 이언트의 요청에 따라 해당 학습자의 클라이언트에 해당 학습자에 대하여 생성된 몰입도 진단 모델을 송신할 수 있다. 본원의 일 실시예에 따르면, 모델 생성부는 지식 증류 기법을 기반으로 몰입도 진단 모델을 경량화할 수 있다. 지식 증류 기법은 네트워크 구조가 큰 교사 네트워크에서 구조가 작은 학생 네트워크로 지식을 이전하는 방법으 로 학생 네트워크의 정확도를 향상시키는 일종의 경량화 기법 중 하나이다. 일반적으로 교사 네트워크에서 학생 네트워크로 지식을 전달한다고 하여 '전이학습(Transfer Learning)'으로 칭하기도 하며 수치적으로 천천히 교사 네트워크의 출력값을 학생 네트워크가 마치 물이 증류되 듯 따라가도록 설계되어 지식증류라고 칭한다. 구체적으로, 모델 생성부에서 생성되는 몰입도 진단 모델은 센서 정보, 학습자의 얼굴 영상 및 메타데이터 를 입력하여 제1몰입도 진단 모델(교사 네트워크)을 미리 학습시키고, 미리 학습된 제1몰입도 진단 모델에서 출 력된 제1레이블과 센서 정보, 학습자의 얼굴 영상 및 메타데이터를 기초하여 제2몰입도 진단 모델(학생 네트워 크)를 학습시켜 제2레이블을 출력하고, 제1몰입도 진단 모델 및 제2몰입도 진단 모델 각각에서 출력된 제1레이 블 및 제2레이블에 기초하여 손실값을 산출하고 산출된 손실값을 비교하여 제2몰입도 진단 모델의 가중치를 갱 신하여 경량화된 몰입도 진단 모델을 생성할 수 있다. 본원의 일 실시예에 따르면, 콘텐츠 추천부는 학습 몰입도 진단 결과를 기반으로 추천 콘텐츠를 결정하고, 추천 콘텐츠를 클라이언트로 전송할 수 있다. 구체적으로, 콘텐츠 추천부는 복수의 콘텐츠에 대한 학습자의 학습 몰입도 진단 결과를 몰입도 진단 모델 에 입력하여 학습자에게 적합한 추천 콘텐츠를 결정하고, 추천 콘텐츠 목록을 생성하여 해당 학습자의 클라이언 트로 전송할 수 있다. 또한, 본원의 일 실시예에 따르면, 콘텐츠 추천부는 학습 몰입도 진단 결과 및 메타데이터를 기반으로 추 천 콘텐츠를 결정하고, 결정된 추천 콘텐츠를 클라이언트로 전송할 수 있다. 구체적으로, 콘텐츠 추천부는 학습 몰입도 진단 결과 및 학습자의 개인 정보, 콘텐츠 이용 내역, 선호 콘 텐츠, 성적을 포함하는 메타데이터를 기반으로 추천 콘텐츠를 결정하고, 추천 콘텐츠 목록을 생성하여 해당 학 습자의 클라이언트로 전송할 수 있다.예를 들어, 콘텐츠 추천부는 학습자의 학습 몰입도 진단 결과에 따라 결정된 복수의 추천 콘텐츠 중 학습 자의 개인 정보, 콘텐츠 이용 내역, 선호 콘텐츠, 성적 등을 포함하는 메타데이터와 매칭하여 필터링한 추천 콘 텐츠 목록을 생성하여 해당 학습자의 클라이언트로 전송하는 것일 수 있다. 본원의 일 실시예에 따르면, 인터페이스부는 학습 몰입도 진단 결과를 출력하고, 학습자 관리를 위한 인터 페이스를 제공할 수 있다. 구체적으로, 인터페이스부는 미리 설정된 시간 간격으로 측정된 복수의 학습자에 대한 학습 몰입도 진단 결과, 콘텐츠 몰입도, 콘텐츠 몰입도 저하 구간 정보, 학습자 몰입도 저하 정보를 실시간으로 모니터링하고, 학 습자의 생체 정보 및 학습 환경 정보를 포함하는 센서 정보를 실시간으로 출력하는 메뉴, 학습자 각각의 개인 정보, 콘텐츠 이용 내역, 선호 콘텐츠, 성적을 입력 및 출력하는 메뉴, 학습자의 주의 정보를 표시하는 메뉴를 출력하는 것일 수 있으나, 이에 한정되는 것이 아니라 학습자 관리를 위한 다양한 메뉴가 구성될 수 있음은 물 론이다. 이하에서는 상기에 자세히 설명된 내용을 기반으로, 본원의 동작 흐름을 간단히 살펴보기로 한다. 도 5는 본원의 일 실시예에 따른 학습 몰입도 진단 방법에 대한 동작 흐름도이다. 도 5에 도시된 학습 몰입도 진단 방법은 앞서 설명된 학습 몰입도 진단 시스템에 의하여 수행될 수 있다. 따라서, 이하 생략된 내용이라고 하더라도 학습 몰입도 진단 시스템에 대하여 설명된 내용은 학습 몰입도 진단 방법에 대한 설명에서도 동일하게 적용될 수 있다. 단계 S11에서 출력 장치는 학습자가 학습하는 콘텐츠를 출력하고, 복수의 센서를 구비하여 학습자의 생체 정보 및 학습 환경 정보를 포함하는 센서 정보를 수집할 수 있다. 다음으로, 단계 S12에서 클라이언트는 학습자의 얼굴 영상을 수집하고, 센서 정보 및 학습자의 얼굴 영상을 몰입도 진단 모델에 입력하여 학습자의 학습 몰입도 진단 결과를 도출할 수 있다. 다음으로, 단계 S13에서 서버는 센서 정보 및 학습 몰입도 진단 결과를 저장하고, 센서 정보 및 학습자의 얼굴 영상을 기반으로 몰입도 진단 모델을 생성할 수 있다. 상술한 설명에서, 단계 S11 내지 S13은 본원의 구현예에 따라서, 추가적인 단계들로 더 분할되거나, 더 적은 단 계들로 조합될 수 있다. 또한, 일부 단계는 필요에 따라 생략될 수도 있고, 단계 간의 순서가 변경될 수도 있다. 본원의 일 실시 예에 따른 학습 몰입도 진단 방법은 다양한 컴퓨터 수단을 통하여 수행될 수 있는 프로그램 명 령 형태로 구현되어 컴퓨터 판독 가능 매체에 기록될 수 있다. 상기 컴퓨터 판독 가능 매체는 프로그램 명령, 데이터 파일, 데이터 구조 등을 단독으로 또는 조합하여 포함할 수 있다. 상기 매체에 기록되는 프로그램 명령 은 본 발명을 위하여 특별히 설계되고 구성된 것들이거나 컴퓨터 소프트웨어 당업자에게 공지되어 사용 가능한 것일 수도 있다. 컴퓨터 판독 가능 기록 매체의 예에는 하드 디스크, 플로피 디스크 및 자기 테이프와 같은 자 기 매체(magnetic media), CD-ROM, DVD와 같은 광기록 매체(optical media), 플롭티컬 디스크(floptical dis k)와 같은 자기-광 매체(magneto-optical media), 및 롬(ROM), 램(RAM), 플래시 메모리 등과 같은 프로그램 명 령을 저장하고 수행하도록 특별히 구성된 하드웨어 장치가 포함된다. 프로그램 명령의 예에는 컴파일러에 의해 만들어지는 것과 같은 기계어 코드뿐만 아니라 인터프리터 등을 사용해서 컴퓨터에 의해서 실행될 수 있는 고급 언어 코드를 포함한다. 상기된 하드웨어 장치는 본 발명의 동작을 수행하기 위해 하나 이상의 소프트웨어 모듈 로서 작동하도록 구성될 수 있으며, 그 역도 마찬가지이다. 또한, 전술한 학습 몰입도 진단 방법은 기록 매체에 저장되는 컴퓨터에 의해 실행되는 컴퓨터 프로그램 또는 애 플리케이션의 형태로도 구현될 수 있다."}
{"patent_id": "10-2023-0064896", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "전술한 본원의 설명은 예시를 위한 것이며, 본원이 속하는 기술분야의 통상의 지식을 가진 자는 본원의 기술적 사상이나 필수적인 특징을 변경하지 않고서 다른 구체적인 형태로 쉽게 변형이 가능하다는 것을 이해할 수 있을 것이다. 그러므로 이상에서 기술한 실시예들은 모든 면에서 예시적인 것이며 한정적이 아닌 것으로 이해해야만 한다. 예를 들어, 단일형으로 설명되어 있는 각 구성 요소는 분산되어 실시될 수도 있으며, 마찬가지로 분산된 것으로 설명되어 있는 구성 요소들도 결합된 형태로 실시될 수 있다. 본원의 범위는 상기 상세한 설명보다는 후술하는 특허청구범위에 의하여 나타내어지며, 특허청구범위의 의미 및 범위 그리고 그 균등 개념으로부터 도출되는 모든 변경 또는 변형된 형태가 본원의 범위에 포함되는 것으로 해석되어야 한다."}
{"patent_id": "10-2023-0064896", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본원의 일 실시예에 따른 학습 몰입도 진단 시스템의 개략적인 구성을 나타낸 도면이다. 도 2는 본원의 일 실시예에 따른 출력 장치의 개략적인 구성을 나타낸 블록도이다. 도 3은 본원의 일 실시예에 따른 클라이언트의 개략적인 구성을 나타낸 블록도이다. 도 4는 본원의 일 실시예에 따른 서버의 개략적인 구성을 나타낸 블록도이다. 도 5는 본원의 일 실시예에 따른 학습 몰입도 진단 방법에 대한 동작 흐름도이다."}
