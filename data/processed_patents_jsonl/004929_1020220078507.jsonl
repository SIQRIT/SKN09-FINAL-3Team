{"patent_id": "10-2022-0078507", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2022-0099932", "출원번호": "10-2022-0078507", "발명의 명칭": "네비게이션 방법, 네비게이션 장치, 전자장비, 컴퓨터 판독가능 저장매체 및 컴퓨터 프로그램", "출원인": "아폴로 인텔리전트 커넥티비티", "발명자": "덩 수난"}}
{"patent_id": "10-2022-0078507", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "네비게이션 방법으로서,실경 영상 및 네비게이션 정보를 취득하는 것,상기 실경 영상을 전환하여, 적어도 하나의 차량 탑재 안경의 윈도와 매칭되는 투사 영상을 얻는 것,상기 투사 영상과 상기 네비게이션 정보를 융합하여 네비게이션 영상을 얻는 것, 및상기 네비게이션 영상을 상기 차량 탑재 안경으로 송신하여, 상기 차량 탑재 안경이 상기 네비게이션 영상을 표시하도록 하는 것을 포함하는, 네비게이션 방법."}
{"patent_id": "10-2022-0078507", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 실경 영상이 차량 탑재 단말의 제1 영상 수집 장비에 의해 수집된 제1 실경 영상일 경우, 상기 실경 영상을 전환하여 투사 영상을 얻는 것은,상기 차량 탑재 안경의 제2 영상 수집 장비에 의해 수집된 제2 실경 영상과 상기 차량 탑재 안경의 윈도의 제1위치 관계를 취득하는 것,상기 제1 실경 영상과 상기 제2 실경 영상의 제2 위치 관계를 확정하는 것, 및상기 제1 위치 관계 및 상기 제2 위치 관계에 기초하여, 상기 제1 실경 영상을 전환하여 투사 영상을 얻는 것을 포함하는, 네비게이션 방법."}
{"patent_id": "10-2022-0078507", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,상기 차량 탑재 안경의 제2 영상 수집 장비에 의해 수집된 제2 실경 영상과 상기 차량 탑재 안경의 윈도의 제1위치 관계를 취득하는 것은,상기 차량 탑재 안경의 상기 제2 영상 수집 장비의 위치 및 상기 윈도의 위치에 기초하여 제1 위치 관계를 확정하는 것을 포함하는, 네비게이션 방법."}
{"patent_id": "10-2022-0078507", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제2항 또는 제3항에 있어서,상기 제1 실경 영상과 상기 제2 실경 영상의 제2 위치 관계를 확정하는 것은,상기 제1 실경 영상과 상기 제2 실경 영상에 대해 특징 포인트를 추적하고, 특징 포인트 추적의 제1결과에 기초하여, 상기 제1 실경 영상과 상기 제2 실경 영상의 제2 위치 관계를 확정하는 것, 및상기 차량 탑재 안경이 지정 위치에 있을 때 수집한 제3 실경 영상과 상기 제1 실경 영상에 대해 특징 포인트를추적하고, 특징 포인트 추적의 제2 결과에 기초하여, 상기 제1 실경 영상과 상기 제3 실경 영상의 제3 위치 관계를 확정하고, 상기 차량 탑재 안경의 현재 위치와 상기 지정 위치에 기초하여, 또한, 상기 제3 위치 관계에기초하여, 상기 제1 실경 영상과 상기 제2 실경 영상의 제2 위치 관계를 확정하는 것중 어느 하나를 포함하는, 네비게이션 방법."}
{"patent_id": "10-2022-0078507", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "공개특허 10-2022-0099932-3-제4항에 있어서,상기 차량 탑재 안경의 현재 위치는 상기 차량 탑재 안경의 위치확정 시스템에 기초하여 얻은 것인, 네비게이션방법."}
{"patent_id": "10-2022-0078507", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항 내지 제3항 중 어느 한 항에 있어서,상기 실경 영상이 상기 차량 탑재 안경의 제2 영상 수집 장비에 의해 수집된 제2 실경 영상일 경우, 상기 실경영상을 전환하여 투사 영상을 얻는 것은,상기 차량 탑재 안경의 제2 영상 수집 장비에 의해 수집된 제2 실경 영상과 상기 차량 탑재 안경의 윈도의 제1위치 관계를 취득하는 것, 및상기 제1 위치 관계에 기초하여, 상기 제1 실경 영상을 전환하여 투사 영상을 얻는 것을 포함하는, 네비게이션 방법."}
{"patent_id": "10-2022-0078507", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제4항에 있어서,상기 네비게이션 영상을 상기 차량 탑재 안경으로 송신하는 것은,무선 통신 방식을 통해 상기 네비게이션 영상을 상기 차량 탑재 안경으로 송신하는 것을 포함하는, 네비게이션방법."}
{"patent_id": "10-2022-0078507", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "네비게이션 방법으로서,차량 탑재 단말로부터 송신한 네비게이션 영상을 수신하는 것, 및상기 네비게이션 영상을 표시하는 것을 포함하되,상기 네비게이션 영상은 투사 영상 및 네비게이션 정보를 융합하여 얻은 것이고,상기 투사 영상은 실경 영상을 전환하여 얻은 것이고, 적어도 하나의 차량 탑재 안경의 윈도와 매칭되는, 네비게이션 방법."}
{"patent_id": "10-2022-0078507", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "네비게이션 장치로서,실경 영상 및 네비게이션 정보를 취득하기 위한 데이터 취득모듈,상기 실경 영상을 전환하여, 적어도 하나의 차량 탑재 안경의 윈도와 매칭되는 투사 영상을 얻기 위한 영상 전환모듈,상기 투사 영상과 상기 네비게이션 정보를 융합하여 네비게이션 영상을 얻기 위한 영상 융합모듈, 및상기 네비게이션 영상을 상기 차량 탑재 안경으로 송신하여, 상기 차량 탑재 안경이 상기 네비게이션 영상을 표시하도록 하기 위한 네비게이션 영상 송신모듈을 포함하는, 네비게이션 장치."}
{"patent_id": "10-2022-0078507", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "네비게이션 장치로서,차량 탑재 단말로부터 송신한 네비게이션 영상을 수신하기 위한 네비게이션 영상 수신모듈, 및상기 네비게이션 영상을 표시하기 위한 네비게이션 모듈공개특허 10-2022-0099932-4-을 포함하되,상기 네비게이션 영상은 투사 영상 및 네비게이션 정보를 융합하여 얻은 것이고,상기 투사 영상은 실경 영상을 전환하여 얻은 것이고, 적어도 하나의 차량 탑재 안경의 윈도와 매칭되는, 네비게이션 장치."}
{"patent_id": "10-2022-0078507", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "전자장비로서,적어도 하나의 프로세서, 및상기 적어도 하나의 프로세서와 통신 연결되는 메모리를 포함하되, 상기 메모리에는 상기 적어도 하나의 프로세서에 의해 실행 가능한 명령이 저장되어 있고, 상기명령이 상기 적어도 하나의 프로세서에 의해 실행될 경우, 상기 적어도 하나의 프로세서로 하여금 제1항 내지제3항 및 제8항 중 어느 한 항의 방법을 실행하도록 하는, 전자장비."}
{"patent_id": "10-2022-0078507", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "컴퓨터 프로그램이 저장되어 있는 비일시적 컴퓨터 판독가능 저장매체로서,상기 컴퓨터 프로그램이, 프로세서에 의해 실행될 경우, 제1항 내지 제3항 및 제8항 중 어느 한 항의 방법을 구현하는, 비일시적 컴퓨터 판독가능 저장매체."}
{"patent_id": "10-2022-0078507", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "컴퓨터 판독가능 저장 매체에 저장된 컴퓨터 프로그램으로서,상기 컴퓨터 프로그램의 명령이, 프로세서에 의해 실행될 경우, 제1항 내지 제3항 및 제8항 중 어느 한 항의 방법을 구현하는, 컴퓨터 프로그램."}
{"patent_id": "10-2022-0078507", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 개시는 차량 인터넷"}
{"patent_id": "10-2022-0078507", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": ", 특히, 네비게이션 기술 분야에 관한 것으로서, 네비게이션 방법, 네비게이션 장치, 전자장비, 컴퓨터 판독가능 저장매체 및 컴퓨터 프로그램을 제공한다. 구체적인 구현 방안은, 실경 영상 및 네비게이션 정보를 취득하는 것, 실경 영상을 전환하여, 적어도 하나의 차량 탑재 안경의 윈도와 매칭되는 투 사 영상을 얻는 것, 투사 영상과 네비게이션 정보를 융합하여 네비게이션 영상을 얻는 것, 및 네비게이션 영상을 차량 탑재 안경으로 송신하여, 차량 탑재 안경이 네비게이션 영상을 표시하도록 하는 것을 포함한다. 본 기술방 안에 의하면, 차량 탑재 안경에 기반하여 AR 네비게이션을 구현하고, 사용자의 머리의 위치 변화로 인해 AR 네비 게이션의 효과에 미치는 악영향을 방지할 수 있으므로, AR 네비게이션의 효과를 보장하고, 사용자의 사용 체험을 보장할 수 있다. 대 표 도 - 도1"}
{"patent_id": "10-2022-0078507", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 2, "content": "공개특허10-2022-0099932 CPC특허분류 G01C 21/3602 (2019.08) G02B 27/017 (2013.01)명 세 서 청구범위 청구항 1 네비게이션 방법으로서, 실경 영상 및 네비게이션 정보를 취득하는 것, 상기 실경 영상을 전환하여, 적어도 하나의 차량 탑재 안경의 윈도와 매칭되는 투사 영상을 얻는 것, 상기 투사 영상과 상기 네비게이션 정보를 융합하여 네비게이션 영상을 얻는 것, 및 상기 네비게이션 영상을 상기 차량 탑재 안경으로 송신하여, 상기 차량 탑재 안경이 상기 네비게이션 영상을 표 시하도록 하는 것 을 포함하는, 네비게이션 방법. 청구항 2 제1항에 있어서, 상기 실경 영상이 차량 탑재 단말의 제1 영상 수집 장비에 의해 수집된 제1 실경 영상일 경우, 상기 실경 영상 을 전환하여 투사 영상을 얻는 것은, 상기 차량 탑재 안경의 제2 영상 수집 장비에 의해 수집된 제2 실경 영상과 상기 차량 탑재 안경의 윈도의 제1 위치 관계를 취득하는 것, 상기 제1 실경 영상과 상기 제2 실경 영상의 제2 위치 관계를 확정하는 것, 및 상기 제1 위치 관계 및 상기 제2 위치 관계에 기초하여, 상기 제1 실경 영상을 전환하여 투사 영상을 얻는 것 을 포함하는, 네비게이션 방법. 청구항 3 제2항에 있어서, 상기 차량 탑재 안경의 제2 영상 수집 장비에 의해 수집된 제2 실경 영상과 상기 차량 탑재 안경의 윈도의 제1 위치 관계를 취득하는 것은, 상기 차량 탑재 안경의 상기 제2 영상 수집 장비의 위치 및 상기 윈도의 위치에 기초하여 제1 위치 관계를 확정 하는 것을 포함하는, 네비게이션 방법. 청구항 4 제2항 또는 제3항에 있어서, 상기 제1 실경 영상과 상기 제2 실경 영상의 제2 위치 관계를 확정하는 것은, 상기 제1 실경 영상과 상기 제2 실경 영상에 대해 특징 포인트를 추적하고, 특징 포인트 추적의 제1결과에 기초 하여, 상기 제1 실경 영상과 상기 제2 실경 영상의 제2 위치 관계를 확정하는 것, 및 상기 차량 탑재 안경이 지정 위치에 있을 때 수집한 제3 실경 영상과 상기 제1 실경 영상에 대해 특징 포인트를 추적하고, 특징 포인트 추적의 제2 결과에 기초하여, 상기 제1 실경 영상과 상기 제3 실경 영상의 제3 위치 관 계를 확정하고, 상기 차량 탑재 안경의 현재 위치와 상기 지정 위치에 기초하여, 또한, 상기 제3 위치 관계에 기초하여, 상기 제1 실경 영상과 상기 제2 실경 영상의 제2 위치 관계를 확정하는 것 중 어느 하나를 포함하는, 네비게이션 방법. 청구항 5 제4항에 있어서, 상기 차량 탑재 안경의 현재 위치는 상기 차량 탑재 안경의 위치확정 시스템에 기초하여 얻은 것인, 네비게이션 방법. 청구항 6 제1항 내지 제3항 중 어느 한 항에 있어서, 상기 실경 영상이 상기 차량 탑재 안경의 제2 영상 수집 장비에 의해 수집된 제2 실경 영상일 경우, 상기 실경 영상을 전환하여 투사 영상을 얻는 것은, 상기 차량 탑재 안경의 제2 영상 수집 장비에 의해 수집된 제2 실경 영상과 상기 차량 탑재 안경의 윈도의 제1 위치 관계를 취득하는 것, 및 상기 제1 위치 관계에 기초하여, 상기 제1 실경 영상을 전환하여 투사 영상을 얻는 것 을 포함하는, 네비게이션 방법. 청구항 7 제4항에 있어서, 상기 네비게이션 영상을 상기 차량 탑재 안경으로 송신하는 것은, 무선 통신 방식을 통해 상기 네비게이션 영상을 상기 차량 탑재 안경으로 송신하는 것을 포함하는, 네비게이션 방법. 청구항 8 네비게이션 방법으로서, 차량 탑재 단말로부터 송신한 네비게이션 영상을 수신하는 것, 및 상기 네비게이션 영상을 표시하는 것 을 포함하되, 상기 네비게이션 영상은 투사 영상 및 네비게이션 정보를 융합하여 얻은 것이고, 상기 투사 영상은 실경 영상을 전환하여 얻은 것이고, 적어도 하나의 차량 탑재 안경의 윈도와 매칭되는, 네비 게이션 방법. 청구항 9 네비게이션 장치로서, 실경 영상 및 네비게이션 정보를 취득하기 위한 데이터 취득모듈, 상기 실경 영상을 전환하여, 적어도 하나의 차량 탑재 안경의 윈도와 매칭되는 투사 영상을 얻기 위한 영상 전 환모듈, 상기 투사 영상과 상기 네비게이션 정보를 융합하여 네비게이션 영상을 얻기 위한 영상 융합모듈, 및 상기 네비게이션 영상을 상기 차량 탑재 안경으로 송신하여, 상기 차량 탑재 안경이 상기 네비게이션 영상을 표 시하도록 하기 위한 네비게이션 영상 송신모듈 을 포함하는, 네비게이션 장치. 청구항 10 네비게이션 장치로서, 차량 탑재 단말로부터 송신한 네비게이션 영상을 수신하기 위한 네비게이션 영상 수신모듈, 및 상기 네비게이션 영상을 표시하기 위한 네비게이션 모듈을 포함하되, 상기 네비게이션 영상은 투사 영상 및 네비게이션 정보를 융합하여 얻은 것이고, 상기 투사 영상은 실경 영상을 전환하여 얻은 것이고, 적어도 하나의 차량 탑재 안경의 윈도와 매칭되는, 네비 게이션 장치. 청구항 11 전자장비로서, 적어도 하나의 프로세서, 및 상기 적어도 하나의 프로세서와 통신 연결되는 메모리 를 포함하되, 상기 메모리에는 상기 적어도 하나의 프로세서에 의해 실행 가능한 명령이 저장되어 있고, 상기 명령이 상기 적어도 하나의 프로세서에 의해 실행될 경우, 상기 적어도 하나의 프로세서로 하여금 제1항 내지 제3항 및 제8항 중 어느 한 항의 방법을 실행하도록 하는, 전자장비. 청구항 12 컴퓨터 프로그램이 저장되어 있는 비일시적 컴퓨터 판독가능 저장매체로서, 상기 컴퓨터 프로그램이, 프로세서에 의해 실행될 경우, 제1항 내지 제3항 및 제8항 중 어느 한 항의 방법을 구 현하는, 비일시적 컴퓨터 판독가능 저장매체. 청구항 13 컴퓨터 판독가능 저장 매체에 저장된 컴퓨터 프로그램으로서, 상기 컴퓨터 프로그램의 명령이, 프로세서에 의해 실행될 경우, 제1항 내지 제3항 및 제8항 중 어느 한 항의 방 법을 구현하는, 컴퓨터 프로그램. 발명의 설명 기 술 분 야 본 개시는 차량 인터넷 기술 분야, 특히, 네비게이션 기술 분야에 관한 것으로서, 구체적으로는, 네비게이션 방 법, 네비게이션 장치, 전자장비, 컴퓨터 판독가능 저장매체 및 컴퓨터 프로그램에 관한 것이다."}
{"patent_id": "10-2022-0078507", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "AR(Augmented Reality, 증강 현실)기술이 갈수록 광범위하게 활용됨에 따라, AR 활용에 대한 사용자들의 접수도 도 점점 높아지고 있다. AR 네비게이션 구현이 바로 AR 기술의 중요한 응용 장면 중 하나이다. AR 네비게이션의 내용을 차량 탑재 안경에 투사할 경우, 사용자의 머리의 흔들림으로 인해, 투사된 AR 네비게이 션 정보와 사용자가 본 영상 사이에 일정한 위치 편차가 발생하게 되는데, 이는 AR 네비게이션의 효과에 영향을 주고, 사용자의 사용 체험에도 영향을 미치게 된다."}
{"patent_id": "10-2022-0078507", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 개시는, 상기 결함 중 적어도 하나를 해결하기 위한 것으로서, 네비게이션 방법, 네비게이션 장치, 전자장비, 컴퓨터 판독가능 저장매체 및 컴퓨터 프로그램을 제공한다."}
{"patent_id": "10-2022-0078507", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 개시의 제1 측면에 의하면, 실경 영상 및 네비게이션 정보를 취득하는 것, 실경 영상을 전환하여, 적어도 하나의 차량 탑재 안경의 윈도와 매칭되는 투사 영상을 얻는 것, 투사 영상과 네비게이션 정보를 융합하여 네비게이션 영상을 얻는 것, 및 네비게이션 영상을 차량 탑재 안경으로 송신하여, 차량 탑재 안경이 네비게이션 영상을 표시하도록 하는 것을 포함하는 네비게이션 방법을 제공한다. 본 개시의 제2 측면에 의하면, 차량 탑재 단말로부터 송신한 네비게이션 영상을 수신하는 것, 및 네비게이션 영상을 표시하는 것을 포함하고, 네비게이션 영상은 투사 영상 및 네비게이션 정보를 융합하여 얻은 것이고, 투사 영상은 실경 영상을 전환하여 얻은 것이고, 적어도 하나의 차량 탑재 안경의 윈도와 매칭되는 다른 네비게 이션 방법을 제공한다. 본 개시의 제3 측면에 의하면, 실경 영상 및 네비게이션 정보를 취득하기 위한 데이터 취득모듈, 실경 영상을 전환하여, 적어도 하나의 차량 탑재 안경의 윈도와 매칭되는 투사 영상을 얻기 위한 영상 전환모듈, 투사 영상과 네비게이션 정보를 융합하여 네비게이션 영상을 얻기 위한 영상 융합모듈, 및 네비게이션 영상을 차량 탑재 안경으로 송신하여, 차량 탑재 안경이 네비게이션 영상을 표시하도록 하기 위한 네비게이션 영상 송신모듈을 포함하는 네비게이션 장치를 제공한다. 본 개시의 제4 측면에 의하면, 차량 탑재 단말로부터 송신한 네비게이션 영상을 수신하기 위한 네비게이션 영상 수신모듈, 및 네비게이션 영상을 표시하기 위한 네비게이션 모듈을 포함하고, 네비게이션 영상은 투사 영상 및 네비게이션 정보를 융합하여 얻은 것이고, 투사 영상은 실경 영상을 전환하여 얻은 것이고, 적어도 하나의 차량 탑재 안경의 윈도와 매칭되는 다른 네비게 이션 장치를 제공한다. 본 개시의 제5 측면에 의하면, 적어도 하나의 프로세서, 및 상기 적어도 하나의 프로세서와 통신 연결되는 메모리를 포함하는 전자장비에 있어서, 메모리에는 상기 적어도 하나의 프로세서에 의해 실행 가능한 명령이 저장되어 있고, 명령이 상기 적어도 하나 의 프로세서에 의해 실행될 경우, 상기 적어도 하나의 프로세서로 하여금 상기의 방법을 실행하도록 하는 전자장비를 제공한다. 본 개시의 제6 측면에 의하면, 컴퓨터 프로그램이 저장되어 있는 비일시적 컴퓨터 판독가능 저장매체에 있어서, 상기 컴퓨터 프로그램이 프로세서에 의해 실행될 경우, 상기 네비게이션 방법을 구현하는 비일시적 컴퓨터 판독 가능 저장매체를 제공한다. 본 개시의 제7 측면에 의하면, 컴퓨터 판독가능 저장 매체에 저장된 컴퓨터 프로그램에 있어서, 상기 컴퓨터 프로그램의 명령이 프로세서에 의해 실행될 경우, 상기 네비게이션 방법을 구현하는 컴퓨터 프로그 램을 제공한다. 본 명세서에 기술된 내용은 그 목적이 본 개시의 실시예의 핵심 또는 중요한 특징을 지정하기 위한 것이 아니고, 또한, 본 개시의 범위는 이에 한정되지 아니함을 이해하여야 한다. 본 개시의 다른 특징들은 하기 설명 으로부터 용이하게 이해할 수 있을 것이다."}
{"patent_id": "10-2022-0078507", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 개시에 따른 기술방안에 의하면, 하기와 같은 유익한 기술적 효과를 가져올 수 있다. 본 개시의 실시예에 따른 기술방안에 의하면, 실경 영상 및 네비게이션 정보를 취득하고, 실경 영상을 전환하여, 적어도 하나의 차량 탑재 안경의 윈도와 매칭되는 투사 영상을 얻고, 투사 영상과 네비게이션 정보를 융합하여 네비게이션 영상을 얻고, 네비게이션 영상을 차량 탑재 안경으로 송신하여, 차량 탑재 안경이 네비게 이션 영상을 표시하도록 한다. 본 기술방안에 의하면, 차량 탑재 안경에 기반하여 AR 네비게이션을 구현하고, 사용자의 머리의 위치 변화로 인해 AR 네비게이션의 효과에 미치는 악영향을 방지할 수 있으므로, AR 네비게이 션의 효과를 보장하고, 사용자의 사용 체험을 보장할 수 있다."}
{"patent_id": "10-2022-0078507", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 도면을 참조하여 본 개시의 예시적인 실시예들을 설명한다. 쉽게 이해할 수 있도록, 본 개시의 실시예들 의 세부사항을 포함하게 되는데, 이들은 단지 예시적인 것에 불과하다. 따라서, 당업자라면 본 개시의 범위 및 취지를 벗어나지 않으면서 본 개시의 실시예에 대해 여러가지 변경 및 수정이 이루어질 수 있음을 이해할 것이다. 또한, 명확성과 간결성을 위해 하기의 설명에 있어서, 공지된 기능 및 구성에 대한 설명은 생략한다. 기존의 AR 네비게이션은 일반적으로 차량 탑재 단말의 스크린 또는 AR HUD(Augmented Reality Head Up Display)에 투사되는데, 이와 같은 종래방식에는 일정한 결함이 있으므로, 사용자의 사용 체험이 떨어진다. 차량 탑재 단말의 스크린에 투사되는 방식의 AR 네비게이션일 경우, 네비게이션 정보는 실경과 융합되는 것이 아니라 동영상과 융합되므로, 실질적으로는 실경과의 진정한 결합이 아니며, 운전자가 네비게이션 정보를 취득 하기 위해서는 고개를 숙여 스크린을 봐야 한다. AR HUD에 표시되는 방식의 AR 네비게이션일 경우, AR HUD가 구현가능한 시야각도(FOV)가 비교적 작고, 강한 빛 이 조사될 경우 화면의 명암비저하가 심각하며, HUD에 의해 투사되는 윈도(eyebox)는 상대적으로 고정되어 있고, 윈도로부터 일정한 범위를 벗어나면, 전반적인 화면을 볼 수 없게 된다. AR 네비게이션 정보를 MR 안경에 투사할 수 있다면, 상기 AR 네비게이션을 차량 탑재 단말의 스크린 또는 AR HUD에 투사하는 경우의 결함을 해소할 수 있다. 일반적인 MR(Mediated Reality) 안경은, 위치확정 칩 및 영상 생성수단이 모두 안경에 독립적으로 결합되어 있 다. 하지만, 차량용 분야에서는, 관련 네비게이션 정보를 표시하기 위해, GPS(Global Positioning System), IMU(Inertial Measurement Unit) 등 위치확정 칩을 안경에 결합할 경우, 안경의 무게가 증가될 뿐만 아니라, 장 비가 간결하지 않고 부피가 커진다. 기존의 AR 네비게이션은, 일반적으로 차량 탑재 단말의 카메라를 통해 실경 영상을 수집한 후, 실경 영상에 따 라 네비게이션 정보를 생성하는데, AR 네비게이션의 내용을 차량 탑재 안경에 투사할 경우, 사용자의 머리의 흔 들림으로 인해, 투사된 AR 네비게이션 정보와 사용자가 본 영상 사이에 일정한 위치 편차가 발생하게 되는데, 이는 AR 네비게이션의 효과에 영향을 주고, 사용자의 사용 체험에도 영향을 미치게 된다.본 출원의 실시예에 따른 네비게이션 방법, 네비게이션 장치, 전자장비, 컴퓨터 판독가능 저장매체 및 컴퓨터 프로그램은, 상기와 같은 종래기술의 기술적 문제 중 적어도 하나를 해결하기 위한 것이다. 도 1은 본 개시의 실시예에 따른 네비게이션 방법의 개략적인 흐름도를 나타낸다. 도 1에 도시된 바와 같이, 상 기 방법은 주로 하기의 단계들을 포함할 수 있다. 단계 S110: 실경 영상 및 네비게이션 정보를 취득한다. 단계 S120: 실경 영상을 전환하여, 적어도 하나의 차량 탑재 안경의 윈도와 매칭되는 투사 영상을 얻는다. 단계 S130: 투사 영상과 네비게이션 정보를 융합하여 네비게이션 영상을 얻는다. 단계 S140: 네비게이션 영상을 차량 탑재 안경으로 송신하여 차량 탑재 안경이 네비게이션 영상을 표시하도록 한다. 여기서, 실경 영상은 차량 주변 환경의 영상이다. 네비게이션 정보는 실경 영상과 융합함으로써, 네비게이션 영 상을 얻을 수 있다. 네비게이션 정보는 네비게이션 영상에 표시되어 사용자를 위해 네비게이션을 실행하는 정보 또는 제시 정보일 수 있고, ADAS(Advanced Driving Assistance System) 정보 및 고정밀도 지도 정보 등을 포함 할 수 있다. 예를 들어, 네비게이션 정보는 차량 주행 방향 변경을 표시하는 화살표일 수도 있고, POI(Point of Information) 중 건물의 정보(건물명칭 등)일 수도 있다. 차량 탑재 안경은 MR 안경 등과 같은 스마트 안경을 포함할 수 있는데, 이에 한정되지는 않으며, 사용자는 차량 을 운전할 때 차량 탑재 안경을 착용하여, 차량 탑재 안경을 통해 네비게이션을 실현할 수 있다. 본 개시의 실시예에 따른 네비게이션 시스템에 의하면, 사용자가 많은 경우의 사용 수요에 대비하여, 차량내에 복수의 차량 탑재 안경을 배치할 수 있다. 사용자가 차량 탑재 안경을 착용할 경우, 사용자의 눈의 가시 영역은 차량 탑재 안경의 윈도(eyebox)와 대응되 므로, 실경 영상을 전환하여, 차량 탑재 안경의 윈도와 매칭되는 투사 영상을 얻을 수 있고, 해당 투사 영상은 사용자의 눈의 가시 영역과 매칭되며, 해당 투사 영상과 네비게이션 정보를 융합하여 AR 네비게이션을 실행함으 로써, AR 네비게이션 효과를 보장하고, 사용자에게 증강현실과 같은 느낌을 줄 수 있으며, 사용자의 머리의 움 직임으로 인해 AR 네비게이션의 효과가 떨어지는 것을 방지할 수 있다. 실제 사용중, 사용자의 머리 위치는 실시간으로 변할 수 있으므로, AR 네비게이션 효과를 보장하기 위해, 조정 주기를 설정하여 주기적으로 실경 영상을 전환할 수 있는데, 예를 들어, 조정 주기는 2초일 수 있다. 본 개시의 실시예에 의하면, 네비게이션 영상을 생성한 후, 네비게이션 영상을 차량 탑재 안경으로 송신하여, 차량 탑재 안경을 통해 네비게이션 영상을 표시함으로써, AR 네비게이션을 구현할 수 있다. AR 네비게이션을 차 량 탑재 안경에 투사함으로써, 종래기술에서 AR 네비게이션을 차량 탑재 단말의 스크린 또는 AR HUD에 투사하는 방식의 결함을 해소하여, 사용자의 사용 체험을 향상시킬 수 있다. 본 개시의 실시예에 따른 방법에 의하면, 실경 영상 및 네비게이션 정보를 취득하고, 실경 영상을 전환하여, 적 어도 하나의 차량 탑재 안경의 윈도와 매칭되는 투사 영상을 얻고, 투사 영상과 네비게이션 정보를 융합하여 네 비게이션 영상을 얻고, 네비게이션 영상을 차량 탑재 안경으로 송신하여, 차량 탑재 안경이 네비게이션 영상을 표시하도록 한다. 본 기술방안은, 차량 탑재 안경에 기반하여 AR 네비게이션을 구현함으로써, 사용자의 머리의 위치 변화로 인해 AR 네비게이션의 효과가 떨어지는 것을 방지하여, AR 네비게이션의 효과를 보장하고, 사용자 의 사용 체험을 보장할 수 있다. 본 개시의 선택가능한 형태에 의하면, 실경 영상이 차량 탑재 단말의 제1 영상 수집 장비에 의해 수집된 제1 실 경 영상일 경우, 실경 영상을 전환하여 투사 영상을 얻는 것은, 차량 탑재 안경의 제2 영상 수집 장비에 의해 수집된 제2 실경 영상과 차량 탑재 안경의 윈도의 제1 위치 관계 를 취득하는 것, 제1 실경 영상과 제2 실경 영상의 제2 위치 관계를 확정하는 것, 및 제1 위치 관계 및 제2 위치 관계에 기초하여, 제1 실경 영상을 전환하여 투사 영상을 얻는 것을 포함한다. 본 개시의 실시예에 의하면, 실경 영상은 차량 탑재 단말의 제1 영상 수집 장비에 의해 수집될 수 있고, 차량 탑재 안경의 제2 영상 수집 장비에 의해 수집될 수도 있다. 영상 수집 장비는 카메라를 포함할 수 있는데, 이에 한정되지는 않는다. 실경 영상이 차량 탑재 단말의 제1 영상 수집 장비에 의해 수집된 제1 실경 영상일 경우, 차량 탑재 안경의 제2 영상 수집 장비와 차량 탑재 안경에서의 윈도의 위치는 고정되어 있으므로, 제2 영상 수집 장비와 차량 탑재 안 경의 윈도의 실제 위치 관계로부터, 제2 실경 영상과 차량 탑재 안경의 윈도의 제1 위치 관계를 확정할 수 있다. 사용자의 머리 위치는 실시간으로 변할 수 있으므로, 제1 실경 영상과 제2 실경 영상의 제2 위치 관계도 실시간 으로 변하게 된다. 따라서, 조정 주기에 따라 제2 위치 관계를 주기적으로 취득할 수 있다. 제1 위치 관계 및 제2 위치 관계를 확정한 후, 제1 위치 관계 및 제2 위치 관계에 따라 제1 실경 영상을 전환하 여 투사 영상을 얻을 수 있다. 예를 들어, 제1 위치 관계는 [R1 T1]로 표시할 수 있고, 여기서, R는 회전 행렬(rotation matrix)이고, T는 이 동 행렬(translation matrix)이며, 이때, P(eyebox)=[R1 T1] P(camera2)이다. 여기서, [R1 T1]는 확정된 값이 고, P(eyebox)는 투사 영상을 나타내고, P(camera2)는 제2 실경 영상을 나타낸다. 제2 위치 관계는 [R2 T2]로 표시할 수 있고, 이때, P(camera2)=[R2 T2] P(camera1)이다. 여기서, P(camera1)는 제1 실경 영상을 나타내고, P(camera2)는 제2 실경 영상을 나타낸다. 이로부터, P(eyebox)=[R1 T1] P(camera2)= [R1 T1] [R2 T2] P(camera1)를 도출해낼 수 있다. 본 개시의 선택가능한 형태에 의하면, 제1 실경 영상과 제2 실경 영상의 제2 위치 관계를 확정하는 것은, 제1 실경 영상과 제2 실경 영상에 대해 특징 포인트를 추적하고, 특징 포인트 추적의 제1결과에 기초하여, 제1 실경 영상과 제2 실경 영상의 제2 위치 관계를 확정하는 것, 및 차량 탑재 안경이 지정 위치에 있을 때 수집한 제3 실경 영상과 제1 실경 영상에 대해 특징 포인트를 추적하고, 특징 포인트 추적의 제2 결과에 기초하여, 제1 실경 영상과 제3 실경 영상의 제3 위치 관계를 확정하고, 차량 탑재 안경의 현재 위치와 지정 위치에 기초하여, 또한, 제3 위치 관계에 기초하여, 제1 실경 영상과 제2 실경 영상의 제2 위치 관계를 확정하는 것, 중의 임의의 하나를 포함한다. 본 개시의 실시예에 의하면, 제2 위치 관계는 PNP 해석 등 특징 포인트 추적 등 방식을 통해 얻을 수 있다. 구 체적으로는, 제1 실경 영상의 특징 포인트를 끊임없이 제2 실경 영상의 특징 포인트와 비교 추적하여 해석하는 것이고, 해석 결과는 P(camera2)=[R2 T2] P(camera1)로 표시할 수 있다. 실시간 처리를 위해서는, 해당 해석 과정에 대한 시간 지연을 억제하여야하는데, 제1 실경 영상과 제2 실경 영 상을 차량 탑재 단말의 MCU(Microcontroller Unit，)로 송신하여 처리할 수 있다. 본 개시의 실시예에 의하면, 네비게이션 영상의 생성은 차량 탑재 단말에서 완성할 수 있고, 네비게이션 영상을 차량 탑재 안경에 송신함으로써, 차량 탑재 안경에 센서를 과다하게 배치할 필요가 없고, 차량 탑재 안경의 부 피가 커지는 것을 방지할 수 있다. 본 개시의 실시예에 의하면, 차량 내의 사용자의 지정 위치를 설정하고, 해당 지정 위치를 기준으로, 차량 탑재 안경이 지정 위치에 있을 때 수집한 제3 실경 영상과 제1 실경 영상의 제3 위치 관계를 산출한 다음, 실시간으 로 차량 탑재 안경의 위치를 확정하고, 지정 위치에 대한 차량 탑재 안경의 위치 변화를 산출하며, 해당 위치 변화 및 제3 위치 관계로부터 제2 위치 관계를 확정할 수 있다. 실제 사용중, 제3 위치 관계는 영상 특징 포인트 추적 방식을 통해 취득할 수 있다. 예를 들어, 운전자가 차량 탑재 안경을 착용하고 단정하게 앉아있을 때의 차량 탑재 안경의 위치를 지정 위치로 설정할 수 있다. 영상 특징 포인트 추적을 이용하여 관계의 초기값 P(camera2)=[R20 T20] P(camera1)를 취득한 다. 동적 과정에서, 위치확정 시스템을 통해 상대 위치 변화[Rx Tx]를 취득하고, 이때, P(camera2)=[Rx Tx][R20 T20] P(camera1)이다. 본 개시의 실시예의 선택가능한 실시형태에 의하면, 차량 탑재 안경의 현재 위치는 차량 탑재 안경의 위치확정 시스템에 기초하여 얻은 것이다.본 개시의 실시예에 의하면, 차량 탑재 안경의 위치확정 시스템은 GPS/IMU 등 위치확정 칩을 포함할 수 있다. 본 개시의 실시예의 선택가능한 실시형태에 의하면, 실경 영상이 차량 탑재 안경의 제2 영상 수집 장비에 의해 수집된 제2 실경 영상일 경우, 실경 영상을 전환하여 투사 영상을 얻는 것은, 차량 탑재 안경의 제2 영상 수집 장비에 의해 수집된 제2 실경 영상과 차량 탑재 안경의 윈도의 제1 위치 관계 를 취득하는 것, 및 제1 위치 관계에 기초하여, 제1 실경 영상을 전환하여 투사 영상을 얻는 것을 포함한다. 본 개시의 실시예에서, 실경 영상이 차량 탑재 안경의 제2 영상 수집 장비에 의해 수집된 제2 실경 영상일 경우, 차량 탑재 안경의 제2 영상 수집 장비 및 차량 탑재 안경의 윈도의 위치는 고정되어 있으므로, 제2 영상 수집 장비와 차량 탑재 안경의 윈도의 실제 위치 관계에 따라, 제2 실경 영상과 차량 탑재 안경의 윈도의 제1 위치 관계를 확정할 수 있다. 제1 위치 관계에 기초하여, 제2 실경 영상을 투사 영상으로 전환할 수 있다. 예를 들어, P(eyebox)= [R1 T1] P(camera2)일 수 있고, 여기서, P(eyebox)는 투사 영상을 나타내고, P(camera2)는 제2 실경 영상을 나타낸다. 제1 위치 관계는 [R1 T1]로 표시할 수 있다. 본 개시의 실시예의 선택가능한 실시형태에 의하면, 네비게이션 영상을 차량 탑재 안경으로 송신하는 것은, 무선 통신 방식을 통해 네비게이션 영상을 차량 탑재 안경으로 송신하는 것을 포함한다. 여기서, 무선 통신 방식은 wifi(Wireless Fidelity)일 수 있고, 또는, USB(Universal Serial Bus) 인터페이스 또는 Ivdss(Low-Voltage Differential Signaling) 인터페이스 등과 같은 유선 방식을 통해 네비게이션 영상을 송신할 수도 있다. 도 2는 본 개시의 실시예에 따른 다른 네비게이션 방법의 개략적인 흐름도를 나타낸다. 도 2에 도시된 바와 같 이, 상기 방법은 주로 하기의 단계를 포함할 수 있다. 단계 S210: 차량 탑재 단말로부터 송신한 네비게이션 영상을 수신한다. 여기서, 네비게이션 영상은 투사 영상과 네비게이션 정보를 융합하여 얻은 것이고, 투사 영상은 실경 영상을 전환하여 얻은 것이고, 적어도 하나의 차량 탑재 안경의 윈도와 매칭된다. 단계 S220: 네비게이션 영상을 표시한다. 여기서, 실경 영상은 차량 주변 환경의 영상이다. 네비게이션 정보는 실경 영상과 융합함으로써, 네비게이션 영 상을 얻을 수 있다. 네비게이션 정보는 네비게이션 영상에 표시되어 사용자를 위해 네비게이션을 실행하는 정보 또는 제시 정보일 수 있고, 네비게이션 정보는 ADAS (Advanced Driving Assistance System) 정보 및 고정밀도 지도 정보 등을 포함할 수 있다. 예를 들어, 네비게이션 정보는 차량 주행 방향 변경을 표시하는 화살표일 수도 있고, POI(Point of Information) 중 건물의 정보(건물명칭 등)일 수도 있다. 차량 탑재 안경은 MR 안경 등과 같은 스마트 안경을 포함할 수 있는데, 이에 한정되지는 않으며, 사용자는 차량 을 운전할 때 차량 탑재 안경을 착용하여, 차량 탑재 안경을 통해 네비게이션을 실현할 수 있다. 본 개시의 실시예에 따른 네비게이션 시스템에 의하면, 사용자가 많은 경우의 사용 수요에 대비하여, 차량내에 복수의 차량 탑재 안경을 배치할 수 있다. 사용자가 차량 탑재 안경을 착용할 경우, 사용자의 눈의 가시 영역은 차량 탑재 안경의 윈도(eyebox)와 대응되 므로, 실경 영상을 전환하여, 차량 탑재 안경의 윈도와 매칭되는 투사 영상을 얻을 수 있고, 해당 투사 영상은 사용자의 눈의 가시 영역과 매칭되며, 해당 투사 영상과 네비게이션 정보를 융합하여 AR 네비게이션을 실행함으 로써, AR 네비게이션 효과를 보장하고, 사용자에게 증강현실과 같은 느낌을 줄 수 있으며, 사용자의 머리의 움 직임으로 인해 AR 네비게이션의 효과가 떨어지는 것을 방지할 수 있다. 실제 사용중, 사용자의 머리 위치는 실시간으로 변할 수 있으므로, AR 네비게이션 효과를 보장하기 위해, 조정 주기를 설정하여 주기적으로 실경 영상을 전환할 수 있는데, 예를 들어, 조정 주기는 2초일 수 있다. 본 개시의 실시예에 의하면, 네비게이션 영상을 생성한 후, 네비게이션 영상을 차량 탑재 안경으로 송신하여, 차량 탑재 안경을 통해 네비게이션 영상을 표시함으로써, AR 네비게이션을 구현할 수 있다. AR 네비게이션을 차 량 탑재 안경에 투사함으로써, 종래기술에서 AR 네비게이션을 차량 탑재 단말의 스크린 또는 AR HUD에 투사하는방식의 결함을 해소하여, 사용자의 사용 체험을 향상시킬 수 있다. 본 개시의 실시예에 따른 방법에 의하면, 차량 탑재 단말은 실경 영상 및 네비게이션 정보를 취득하고, 실경 영 상을 전환하여, 적어도 하나의 차량 탑재 안경의 윈도와 매칭되는 투사 영상을 얻고, 투사 영상과 네비게이션 정보를 융합하여 네비게이션 영상을 얻고, 네비게이션 영상을 차량 탑재 안경으로 송신하여, 차량 탑재 안경이 네비게이션 영상을 표시하도록 한다. 본 기술방안은, 차량 탑재 안경에 기반하여 AR 네비게이션을 구현함으로써, 사용자의 머리의 위치 변화로 인해 AR 네비게이션의 효과가 떨어지는 것을 방지하여, AR 네비게 이션의 효과를 보장하고, 사용자의 사용 체험을 보장할 수 있다. 도 3은 본 개시의 실시예에 따른 네비게이션 시스템의 개략적인 구성도를 나타낸다. 도 3에 도시된 바와 같이, Camera1은 차량 탑재 단말의 제1 영상 수집 장비이다. Camera2는 차량 탑재 안경의 제2 영상 수집 장비이다. Eyebox는 윈도이다. MCU는 차량 탑재 단말의 MCU이고, AR creator은 증강현실 소프트 웨어 세트로서, ADAS(Advanced Driving Assistance System), SD/HD MAP(즉, 도로 목록 지도 또는 고정밀 지 도), ANP(Apollo Navigation Pilot)지도를 포함한다. Camera1에 의해 수집된 제1 실경 영상 및 Camera2에 의해 수집된 제2 실경 영상은 MCU로 송신되고, MCU에서 네 비게이션 영상을 생성한 후, 무선 전송 방식(예를 들어, wifi) 등을 통해 네비게이션 영상을 차량 탑재 안경의 PGU(즉, 영상 생성수단)로 송신하여, PGU가 네비게이션 영상을 표시하도록 할 수 있다. 도 1에 도시된 방법과 동일한 원리에 기초하여, 도 4는 본 개시의 실시예에 따른 네비게이션 장치의 개략적인 구성도를 나타낸다. 도 4에 도시된 바와 같이, 상기 네비게이션 장치는, 실경 영상 및 네비게이션 정보를 취득하기 위한 데이터 취득모듈은, 실경 영상을 전환하여, 적어도 하나의 차량 탑재 안경의 윈도와 매칭되는 투사 영상을 얻기 위한 영상 전환모듈 , 투사 영상과 네비게이션 정보를 융합하여 네비게이션 영상을 얻기 위한 영상 융합모듈, 및 네비게이션 영상을 차량 탑재 안경으로 송신하여, 차량 탑재 안경이 네비게이션 영상을 표시하도록 하기 위한 네비게이션 영상 송신모듈을 포함할 수 있다. 본 개시의 실시예에 따른 네비게이션 장치에 의하면, 실경 영상 및 네비게이션 정보를 취득하고, 실경 영상을 전환하여, 적어도 하나의 차량 탑재 안경의 윈도와 매칭되는 투사 영상을 얻고, 투사 영상과 네비게이션 정보를 융합하여 네비게이션 영상을 얻고, 네비게이션 영상을 차량 탑재 안경으로 송신하여, 차량 탑재 안경이 네비게 이션 영상을 표시하도록 한다. 본 기술방안은, 차량 탑재 안경에 기반하여 AR 네비게이션을 구현함으로써, 사용 자의 머리의 위치 변화로 인해 AR 네비게이션의 효과가 떨어지는 것을 방지하여, AR 네비게이션의 효과를 보장 하고, 사용자의 사용 체험을 보장할 수 있다. 선택적으로, 실경 영상이 차량 탑재 단말의 제1 영상 수집 장비에 의해 수집된 제1 실경 영상일 경우, 영상 전 환모듈은 실경 영상을 투사 영상으로 전환할 때, 구체적으로, 차량 탑재 안경의 제2 영상 수집 장비에 의해 수집된 제2 실경 영상과 차량 탑재 안경의 윈도의 제1 위치 관계 를 취득하고, 제1 실경 영상과 제2 실경 영상의 제2 위치 관계를 확정하고, 제1 위치 관계 및 제2 위치 관계에 기초하여, 제1 실경 영상을 전환하여 투사 영상을 얻는다. 선택적으로, 영상 전환모듈은 차량 탑재 안경의 제2 영상 수집 장비에 의해 수집된 제2 실경 영상과 차량 탑재 안경의 윈도의 제1 위치 관계를 취득할 때, 구체적으로, 차량 탑재 안경의 제2 영상 수집 장비의 위치 및 윈도 의 위치에 기초하여 제1 위치 관계를 확정한다. 선택적으로, 영상 전환 모듈은 제1 실경 영상과 제2 실경 영상의 제2 위치 관계를 확정할 때, 구체적으로, 제1 실경 영상과 제2 실경 영상에 대해 특징 포인트를 추적하고, 특징 포인트 추적의 제1결과에 기초하여, 제1 실경 영상과 제2 실경 영상의 제2 위치 관계를 확정하거나, 차량 탑재 안경이 지정 위치에 있을 때 수집한 제3 실경 영상과 제1 실경 영상에 대해 특징 포인트를 추적하고, 특징 포인트 추적의 제2 결과에 기초하여, 제1 실경 영상과 제3 실경 영상의 제3 위치 관계를 확정하고, 차량탑재 안경의 현재 위치와 지정 위치에 기초하여, 또한, 제3 위치 관계에 기초하여, 제1 실경 영상과 제2 실경 영상의 제2 위치 관계를 확정한다. 선택적으로, 차량 탑재 안경의 현재 위치는 차량 탑재 안경의 위치확정 시스템에 기초하여 얻은 것이다. 선택적으로, 실경 영상이 차량 탑재 안경의 제2 영상 수집 장비에 의해 수집된 제2 실경 영상일 경우, 영상 전 환모듈은 실경 영상을 투사 영상으로 전환할 때, 구체적으로, 차량 탑재 안경의 제2 영상 수집 장비에 의해 수집된 제2 실경 영상과 차량 탑재 안경의 윈도의 제1 위치 관계 를 취득하고, 제1 위치 관계에 기초하여, 제1 실경 영상을 전환하여 투사 영상을 얻는다. 선택적으로, 네비게이션 영상 송신모듈은 네비게이션 영상을 차량 탑재 안경으로 송신할 때, 구체적으로, 무선 통신 방식을 통해 네비게이션 영상을 차량 탑재 안경으로 송신한다. 본 개시의 실시예에 따른 네비게이션 장치의 상기 각 모듈은, 도 1에 도시된 실시예에 따른 네비게이션 방법의 대응되는 단계를 구현하는 기능을 갖고 있음을 이해할 수 있을 것이다. 상기 기능은 하드웨어에 의해 구현될 수 도 있고, 하드웨어가 대응하는 소프트웨어를 실행함으로써 구현될 수도 있다. 상기 하드웨어 또는 소프트웨어는 상기 기능에 대응하는 하나 또는 복수의 모듈을 포함한다. 상기 모듈은 소프트웨어 및/또는 하드웨어일 수 있고, 상기 각 모듈은 단독으로 구현될 수도 있고, 복수의 모듈을 집적하여 구현될 수도 있다. 상기 네비게이션 장치의 각 모듈의 기능에 대한 설명은 도 1에 도시된 실시예에 따른 네비게이션 방법의 대응하는 설명을 참조할 수 있고, 여기서는 설명을 생략한다. 도 2에 도시된 방법과 동일한 원리에 기초하여, 도 5는 본 개시의 실시예에 따른 네비게이션 장치의 개략적인 구성도를 나타낸다. 도 5에 도시된 바와 같이, 상기 네비게이션 장치는, 차량 탑재 단말로부터 송신한 네비게이션 영상을 수신하기 위한 네비게이션 영상 수신모듈, 및 네비게이션 영상을 표시하기 위한 네비게이션 모듈을 포함하고, 네비게이션 영상은 투사 영상 및 네비게이션 정보를 융합하여 얻은 것이고, 투사 영상은 실경 영상을 전환하여 얻은 것이고, 적어도 하나의 차량 탑재 안경의 윈도와 매칭된다. 본 개시의 실시예에 따른 방법에 의하면, 차량 탑재 단말은 실경 영상 및 네비게이션 정보를 취득하고, 실경 영 상을 전환하여, 적어도 하나의 차량 탑재 안경의 윈도와 매칭되는 투사 영상을 얻고, 투사 영상과 네비게이션 정보를 융합하여 네비게이션 영상을 얻고, 네비게이션 영상을 차량 탑재 안경으로 송신하여, 차량 탑재 안경이 네비게이션 영상을 표시하도록 한다. 본 기술방안은, 차량 탑재 안경에 기반하여 AR 네비게이션을 구현함으로써, 사용자의 머리의 위치 변화로 인해 AR 네비게이션의 효과가 떨어지는 것을 방지하여, AR 네비게 이션의 효과를 보장하고, 사용자의 사용 체험을 보장할 수 있다. 본 개시의 실시예에 따른 네비게이션 장치의 상기 각 모듈은, 도 2에 도시된 실시예에 따른 네비게이션 방법의 대응되는 단계를 구현하는 기능을 갖고 있음을 이해할 수 있을 것이다. 상기 기능은 하드웨어에 의해 구현될 수 도 있고, 하드웨어가 대응하는 소프트웨어를 실행함으로써 구현될 수도 있다. 상기 하드웨어 또는 소프트웨어는 상기 기능에 대응하는 하나 또는 복수의 모듈을 포함한다. 상기 모듈은 소프트웨어 및/또는 하드웨어일 수 있고, 상기 각 모듈은 단독으로 구현될 수도 있고, 복수의 모듈을 집적하여 구현될 수도 있다. 상기 네비게이션 장치의 각 모듈의 기능에 대한 설명은 도 2에 도시된 실시예에 따른 네비게이션 방법의 대응하는 설명을 참조할 수 있고, 여기서는 설명을 생략한다. 본 개시의 기술방안에 있어서, 관련된 사용자 개인 정보의 취득, 저장 및 응용 등은 모두 관련 법률과 법규의 규정에 부합되고, 공중도덕에 어긋나지 않는다. 본 개시의 실시예에 의하면, 본 개시는 전자장비, 컴퓨터 판독가능 저장매체 및 컴퓨터 프로그램을 더 제공한다. 상기 전자장비는, 적어도 하나의 프로세서 및 적어도 하나의 프로세서와 통신 연결되는 메모리를 포함하고, 메 모리에는 적어도 하나의 프로세서에 의해 실행 가능한 명령이 저장되어 있고, 명령이 적어도 하나의 프로세서에 의해 실행될 경우, 적어도 하나의 프로세서로 하여금 본 개시의 실시예에 따른 네비게이션 방법을 실행하도록한다. 종래기술에 비해, 상기 전자장비는, 실경 영상 및 네비게이션 정보를 취득하고, 실경 영상을 전환하여, 적어도 하나의 차량 탑재 안경의 윈도와 매칭되는 투사 영상을 얻고, 투사 영상과 네비게이션 정보를 융합하여 네비게 이션 영상을 얻고, 네비게이션 영상을 차량 탑재 안경으로 송신하여, 차량 탑재 안경이 네비게이션 영상을 표시 하도록 한다. 본 기술방안은, 차량 탑재 안경에 기반하여 AR 네비게이션을 구현함으로써, 사용자의 머리의 위치 변화로 인해 AR 네비게이션의 효과가 떨어지는 것을 방지하여, AR 네비게이션의 효과를 보장하고, 사용자의 사 용 체험을 보장할 수 있다. 상기 컴퓨터 판독가능 저장매체는 컴퓨터 프로그램이 저장되어 있는 비일시적 컴퓨터 판독가능 저장매체이고, 컴퓨터 프로그램이 프로세서에 의해 실행될 경우, 본 개시의 실시예에 따른 네비게이션 방법을 구현한다. 종래기술에 비해, 상기 컴퓨터 판독가능 저장매체는, 실경 영상 및 네비게이션 정보를 취득하고, 실경 영상을 전환하여, 적어도 하나의 차량 탑재 안경의 윈도와 매칭되는 투사 영상을 얻고, 투사 영상과 네비게이션 정보를 융합하여 네비게이션 영상을 얻고, 네비게이션 영상을 차량 탑재 안경으로 송신하여, 차량 탑재 안경이 네비게 이션 영상을 표시하도록 한다. 본 기술방안은, 차량 탑재 안경에 기반하여 AR 네비게이션을 구현함으로써, 사용 자의 머리의 위치 변화로 인해 AR 네비게이션의 효과가 떨어지는 것을 방지하여, AR 네비게이션의 효과를 보장 하고, 사용자의 사용 체험을 보장할 수 있다. 상기 컴퓨터 프로그램은 컴퓨터 판독가능 저장 매체에 저장되어 있고, 컴퓨터 프로그램의 명령이 프로세서에 의 해 실행될 경우, 본 개시의 실시예에 따른 네비게이션 방법을 구현한다. 종래기술에 비해, 상기 컴퓨터 프로그램은, 실경 영상 및 네비게이션 정보를 취득하고, 실경 영상을 전환하여, 적어도 하나의 차량 탑재 안경의 윈도와 매칭되는 투사 영상을 얻고, 투사 영상과 네비게이션 정보를 융합하여 네비게이션 영상을 얻고, 네비게이션 영상을 차량 탑재 안경으로 송신하여, 차량 탑재 안경이 네비게이션 영상 을 표시하도록 한다. 본 기술방안은, 차량 탑재 안경에 기반하여 AR 네비게이션을 구현함으로써, 사용자의 머리 의 위치 변화로 인해 AR 네비게이션의 효과가 떨어지는 것을 방지하여, AR 네비게이션의 효과를 보장하고, 사용 자의 사용 체험을 보장할 수 있다. 도 6은 본 개시의 실시예들을 구현하기 위한 예시적인 전자장비의 개략적인 블록도이다. 전자장비는 예를 들어, 랩탑 컴퓨터, 데스크 탑 컴퓨터, 워크스테이션, PDA(Personal Digital Assistants), 서버, 블레이드 서 버, 메인프레임 컴퓨터, 및 기타 적절한 컴퓨터와 같은 다양한 형태의 디지털 컴퓨터를 포함할 수 있다. 전자장 비는 예를 들어, PDA(Personal Digital Assistants), 셀룰러 전화기, 스마트 폰, 웨어러블 장비, 및 기타 유사 한 계산 장비와 같은 다양한 형태의 모바일 장비를 포함할 수 있다. 본 명세서에 기재된 부품, 이들의 연결 및 관계, 그리고 이들의 기능은 단지 예시적인 것에 불과하며, 본 명세서에서 설명 및/또는 요구하는 본 개시의 범 위를 한정하기 위한 것이 아니다. 도 6에 도시된 바와 같이, 장비는ROM(Read Only Memory)에 저장된 컴퓨터 프로그램 또는 저장수단 으로부터 RAM(Random Access Memory)에 로딩된 컴퓨터 프로그램에 따라 각종 적당한 동작 및 처리 를 실행할 수 있는 계산수단을 포함한다. 또한, RAM에는 장비의 동작에 필요한 다양한 프로 그램 및 데이터가 더 저장될 수 있다. 계산수단, ROM 및 RAM은 버스라인를 통해 서로 연결된다. 입력/출력(I/O) 인터페이스도 버스라인에 연결된다. 장비내의 복수의 부품은 I/O 인터페이스에 연결되고, 상기 부품에는, 예를 들어 키보드, 마우스 등 과 같은 입력수단, 예를 들어 각종 유형의 디스플레이, 스피커 등과 같은 출력수단, 예를 들어 자 기 디스크, 광 디스크 등과 같은 저장수단, 및 예를 들어 네트워크 카드, 모뎀, 무선 통신 송수신기 등과 같은 통신수단이 포함된다. 통신수단에 의해, 장비는 인터넷과 같은 컴퓨터 네트워크 및/또 는 각종 전자통신망을 통해 다른 장비와 정보/데이터를 교환할 수 있다. 계산수단은 처리 기능 및 계산 기능을 가진 각종 범용 및/또는 주문형 처리 어셈블리일 수 있다. 계산수 단의 일부 실예로서는, 중앙 처리 장치(CPU), 그래픽 처리 장치(GPU), 각종 주문형 인공지능(AI) 컴퓨팅 칩, 각종 머신 러닝 모델 알고리즘을 운행하는 계산수단, 디지털 신호 프로세서(DSP), 및 임의의 적합한 프로세 서, 컨트롤러, 마이크로 컨트롤러 등이 포함될 수 있는데, 이에 한정되지는 않는다. 계산수단은 본 개시 의 실시예에 따른 네비게이션 방법을 실행한다. 예를 들어, 일부 실시예에 있어서, 본 개시의 실시예에 따른 네 비게이션 방법은 예를 들어 저장수단과 같은 기계 판독가능 매체에 포함되는 컴퓨터 소프트웨어 프로그램 의 형태로 실현될 수 있다. 일부 실시예에 있어서, 컴퓨터 프로그램의 일부 또는 전부는 ROM 및/또는 통신수단을 거쳐 장비에 로딩 및/또는 설치될 수 있다. 컴퓨터 프로그램이 RAM에 로딩되고 계 산수단에 의해 실행될 경우, 본 개시의 실시예에 따른 네비게이션 방법의 하나 또는 복수의 단계를 실행 할 수 있다. 선택적으로, 다른 실시예에 있어서, 계산수단은 다른 임의의 적합한 방식(예를 들어, 펌웨어)을 통해 본 개시의 실시예에 따른 네비게이션 방법을 실행하도록 구성될 수 있다. 상기에서 설명한 시스템 및 기술의 다양한 실시 형태는 디지털 전자 회로 시스템, 집적 회로 시스템, FPGA(Field Programmable Gate Array), ASIC(Application Specific Integrated circuit), ASSP(Application Specific Standard Product), SOC(System on Chip), CPLD(Complex Programmable Logic Device), 컴퓨터 하드 웨어, 펌웨어, 소프트웨어, 및/또는 이들의 조합으로 구현될 수 있다. 이러한 다양한 실시형태는 하나 또는 복 수의 컴퓨터 프로그램을 통해 구현될 수 있고, 상기 하나 또는 복수의 컴퓨터 프로그램은 적어도 하나의 프로그 램 가능 프로세서를 포함하는 프로그램 가능 시스템에서 실행 및/또는 해석될 수 있으며, 상기 프로그램 가능 프로세서는 주문형 또는 범용 프로그램 가능 프로세서일 수 있고, 저장 시스템, 적어도 하나의 입력장치, 및 적 어도 하나의 출력장치로부터 데이터 및 명령을 수신하고, 데이터 및 명령을 저장 시스템, 적어도 하나의 입력장 치, 및 적어도 하나의 출력장치로 전송할 수 있다. 본 개시의 방법을 실시하기 위한 프로그램 코드는 하나 또는 복수의 프로그래밍 언어의 임의의 조합을 통해 프 로그래밍을 실행할 수 있다. 이러한 프로그램 코드는 범용 컴퓨터, 주문형 컴퓨터 또는 다른 프로그래밍 가능한 데이터 처리 장치의 프로세서 또는 컨트롤러에 제공되어, 프로그램 코드가 프로세서 또는 컨트롤러에 의해 실행 됨으로써, 흐름도 및/또는 블록도에서 규정한 기능/동작을 실시하도록 할 수 있다. 프로그램 코드는 전부 머신 에 의해 실행되거나 또는 부분적으로 머신에 의해 실행될 수 있고, 또는 독립적인 소프트웨어 패키지로서 부분 적으로 머신에 의해 실행됨과 동시에 부분적으로 원격 머신에 의해 실행되거나, 또는 전부 원격 머신 또는 서버 에 의해 실행될 수 있다. 본 명세서에 있어서, 기계 판독가능 매체는 실체적인 매체일 수 있고, 상기 매체에는 명령 실행 시스템, 장치 또는 장비에 의해 사용되거나 또는 명령 실행 시스템, 장치 또는 장비와 결합하여 사용되는 프로그램이 포함되 거나 저장될 수 있다. 기계 판독가능 매체는 기계 판독가능 신호 매체 또는 기계 판독가능 저장매체일 수 있다. 기계 판독가능 신호 매체는, 전자적, 자기적, 광학적, 전자기적, 적외선적 반도체 시스템, 장치 또는 장비, 또 는 이들의 임의의 적합한 조합을 포함할 수 있는데, 이에 한정되지는 않는다. 기계 판독가능 저장매체의 보다 구체적인 실예로는, 하나 또는 복수의 라인에 의해 전기적으로 연결되는 휴대용 컴퓨터 디스크, 하드 디스크, RAM, ROM, EPROM(Erasable Programming ROM), 플래시 메모리, 광 파이버, CD-ROM, 광학적 저장 장비, 자기적 저장 장비, 또는 이들의 임의의 적합한 조합일 수 있다. 사용자와의 인터액션을 제공하기 위해서는, 컴퓨터를 통해 본 명세서에서 설명한 시스템 및 기술을 구현할 수 있는데, 상기 컴퓨터는, 사용자에게 정보를 표시하기 위한 표시 장치(예를 들어, CRT(음극선관) 또는 LCD(액정 디스플레이) 모니터), 및 사용자가 상기 컴퓨터에 입력을 제공할 수 있는 키보드 및 포인팅 디바이스(예를 들어, 마우스 또는 트랙 볼)를 포함한다. 기타 유형의 디바이스도 사용자와의 인터액션을 제공하는데 사용될 수 있다. 예를 들어, 사용자에게 제공되는 피드백은 임의의 형태의 센싱 피드백(예를 들어, 시각 피드백, 청각 피 드백, 또는 촉각 피드백)일 수 있고, 임의의 형태(소리 입력, 음성 입력, 또는 촉각 입력을 포함)로 사용자로부 터의 입력을 수신할 수 있다. 본 명세서에서 설명한 시스템 및 기술은, 백 그라운드 부품을 포함하는 컴퓨팅 시스템(예를 들어, 데이터 서 버), 또는 미들웨어 부품을 포함하는 컴퓨팅 시스템(예를 들어, 애플리케이션 서버), 또는 프론트 앤드 부품을 포함하는 컴퓨팅 시스템(예를 들어, GUI 또는 웹 브라우저를 갖는 사용자 컴퓨터로서, 사용자는 상기 GUI 또는 상기 웹 브라우저를 통하여 본 명세서에서 설명한 상기 시스템 및 기술의 실시 형태와 인터액션을 할 수 있음), 또는 이러한 백 그라운드 부품, 미들웨어 부품, 또는 프론트 앤드 부품의 임의의 조합을 포함하는 컴퓨팅 시스 템에서 구현될 수 있다. 시스템의 부품은 임의의 형태 또는 매체의 디지털 데이터 통신(예를 들어, 통신 네트워 크)을 통해 서로 연결될 수 있다. 통신 네트워크는 예를 들어 근거리 통신망(LAN), 광역 통신망(WAN) 및 인터넷 을 포함할 수 있다. 컴퓨터 시스템은 클라이언트 및 서버를 포함할 수 있다. 클라이언트 및 서버는 일반적으로 서로 멀리 떨어져 있 고, 통상적으로 통신 네트워크를 통해 인터액션을 진행한다. 클라이언트와 서버의 관계는 대응하는 컴퓨터에서 실행되고 서로 클라이언트-서버의 관계를 갖는 컴퓨터 프로그램에 의해 생성된다. 서버는 클라우드 서버일 수도 있고, 분포식 시스템의 서버 또는 블록체인과 결합된 서버일 수도 있다. 상기에서 설명한 다양한 프로세스를 사용하여 각 단계의 순서를 조정하거나, 일부 단계를 추가 또는 삭제할 수 있다는 점을 이해하여야 한다. 예를 들어, 본 개시에 개시된 기술방안이 원하는 결과를 구현할 수 있는 한, 본 개시에 기재된 다양한 단계는 병렬적으로 또는 순차적으로, 또는 서로 다른 순서로 실행될 수 있고, 본 개시는 이에 대해 특별히 한정하지 않는다. 본 개시의 보호범위는 상기 다양한 실시 형태에 의해 제한되지 않는다. 당업자라면, 설계 요구 및 기타 요소에 의해, 다양한 수정, 조합, 서브 조합 및 교체가 이루어질 수 있음을 이해할 것이다. 본 개시의 취지 및 원칙내 에서 이루어진 임의의 수정, 등가 교체 및 개선 등은 모두 본 개시의 보호범위에 속한다."}
{"patent_id": "10-2022-0078507", "section": "도면", "subsection": "도면설명", "item": 1, "content": "첨부된 도면은 본 기술방안을 보다 쉽게 이해하도록 하기 위한 것이고, 본 개시는 이에 한정되지 않는다. 도 1은 본 개시의 실시예에 따른 네비게이션 방법의 개략적인 흐름도이다. 도 2는 본 개시의 다른 실시예에 따른 네비게이션 방법의 개략적인 흐름도이다. 도 3은 본 개시의 실시예에 따른 네비게이션 시스템의 개략적인 구성도이다. 도 4는 본 개시에 따른 네비게이션 장치의 개략적인 구성도이다. 도 5는 본 개시에 따른 다른 네비게이션 장치의 개략적인 구성도이다. 도 6은 본 개시의 실시예에 따른 네비게이션 방법을 구현하기 위한 전자장비의 블록도이다."}
