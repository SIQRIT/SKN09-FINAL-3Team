{"patent_id": "10-2021-0176476", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0087865", "출원번호": "10-2021-0176476", "발명의 명칭": "인공지능 손위치 인식을 이용한 아바타 제어시스템", "출원인": "주식회사 리안", "발명자": "이희용"}}
{"patent_id": "10-2021-0176476", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "사용자의 손 모션을 감지하여 사용자의 손 모션 데이터를 생성하는 영상 처리 모듈;외부로부터 수신되는 제어신호에 따라 미리 생성된 아바타를 동작시키는 아바타 동작 모듈; 및상기 사용자의 손 모션 데이터에 대응되는 아바타의 동작 정보를 생성하고, 상기 생성된 아바타의 동작 정보를기초로 상기 아바타를 동작시키는 프로세서를 포함하는 것을 특징으로 하는 인공지능 손위치 인식을 이용한 아바타 제어시스템."}
{"patent_id": "10-2021-0176476", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 영상 처리 모듈은,사용자를 촬영하여 X축(화면의 좌우), Y축(화면의 상하) 및 Z축(화면의 깊이)으로 분할된 영상 프레임을 생성하는 영상 생성부;상기 영상 프레임 중 사용자의 손의 위치에 대응하는 좌표값을 생성하는 손위치 생성부; 및상기 좌표값의 이동 방향을 산출하고, 상기 산출된 좌표값의 이동 방향을 기초로 미리 설정된 사용자의 손 모션데이터를 생성하는 모션 데이터 생성부를 포함하는 것을 특징으로 하는 인공지능 손위치 인식을 이용한 아바타제어시스템."}
{"patent_id": "10-2021-0176476", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,상기 모션 데이터 생성부는사용자의 왼손, 오른손, 또는 왼손 및 오른손의 좌표값을 이용하여 이동 방향을 산출하되,사용자의 왼손만 좌우로 이동되는 경우, 좌우 이동 정보에 대응되는 X축에 대한 사용자의 모션 데이터를 생성하고,사용자의 오른손만 상하로 이동되는 경우, 상하 이동 정보에 대응되는 Z축에 대한 사용자의 모션 데이터를 생성하며,사용자의 왼손 및 오른 손이 모은 상태로 상하로 이동되는 경우, 상하 이동 정보에 대응되는 Y축에 대한 사용자의 모션 데이터를 생성하는 것을 특징으로 하는 인공지능 손위치 인식을 이용한 아바타 제어시스템."}
{"patent_id": "10-2021-0176476", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서,상기 모션 데이터 생성부는사용자의 왼손 및 오른 손의 거리가 사용자의 손을 표현하는 객체의 크기보다 작으면 사용자의 왼손 및 오른 손이 모은 상태인 것으로 판단하는 것을 특징으로 하는 인공지능 손위치 인식을 이용한 아바타 제어시스템.공개특허 10-2023-0087865-3-청구항 5 제3항에 있어서,상기 모션 데이터 생성부는사용자의 왼손 및 오른 손이 모은 상태로 미리 설정된 영역으로 이동되는 경우, 정지 동작을 의미하는 사용자의모션 데이터를 생성하는 것을 특징으로 하는 인공지능 손위치 인식을 이용한 아바타 제어시스템."}
{"patent_id": "10-2021-0176476", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 사용자의 손 모션을 감지하여 사용자의 손 모션 데이터를 생성하는 영상 처리 모듈; 외부로부터 수신 되는 제어신호에 따라 미리 생성된 아바타를 동작시키는 아바타 동작 모듈; 및 상기 사용자의 손 모션 데이터에 대응되는 아바타의 동작 정보를 생성하고, 상기 생성된 아바타의 동작 정보를 기초로 상기 아바타를 동작시키는 프로세서를 포함하는 인공지능 손위치 인식을 이용한 아바타 제어시스템에 관한 것으로, 기존의 LSTM(Long Short Term Memory) 딥러닝 방식과 같은 무거운 인공지능 계산을 수행하지 않고도 정지영상에서 간단한 계산으로 아바 타 제어명령을 생성할 수 있기 때문에, 손 위치 인식을 이용한 아바타 제어기를 제공할 수 있는 효과가 있다."}
{"patent_id": "10-2021-0176476", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 인공지능 손위치 인식을 이용한 아바타 제어시스템에 관한 것이다."}
{"patent_id": "10-2021-0176476", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "최근, 증강 현실(augmented reality) 기술이 발전하면서 현실 세계와 가상 세계를 서로 융합하는 기술들이 개발 되고 있다. 예를 들면, 가상 교육 시스템, 스크린 골프 시스템 및 가상 체험 시뮬레이션 시스템 등이 그 대표적 인 예일 것이다. 이들 가상 시스템은, 터치보드 등의 디스플레이장치를 이용하여 콘텐츠 영상을 출력한 상태에서, 사용자가 모션 을 취하면 모션에 대응하여 해당 콘텐츠를 제어하도록 구성되어 있다. 이러한 가상 시스템은 미디어파이프(mediapipe)라는 도구를 이용하면 손이나 얼굴을 인식하도록 할 수 있다. 또 한, 이러한 도구는 손가락 마디의 관절을 인식할 수 있고, 손전체를 인식할 수 있다. 다만, 한 장의 정지영상에서 손의 위치를 파악하는 것은 용이하지만, 손의 위치만으로 동작을 인식하기에는 한 계가 있어서 LSTM 등의 인공지능 기법을 이용하여 자세 추정을 하기도 한다. 그러나, 초당 60프레임 이상을 화면에 보여주는 상황에서 실시간으로 자세 추정 계산을 수행하는 것은 시스템에 부하가 크다는 문제점이 있었다. 선행기술문헌 특허문헌 (특허문헌 0001) 등록특허공보 제10-1189633호(공고일자: 2012. 10. 10)"}
{"patent_id": "10-2021-0176476", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "전술한 문제점을 개선하기 위한 본 발명 실시예들의 목적은 기존의 LSTM(Long Short Term Memory)방식과 같은 무거운 인공지능 계산을 수행하지 않고도 정지영상에서 간단한 계산으로 아바타 제어명령을 생성할 수 있는 인 공지능 손위치 인식을 이용한 아바타 제어시스템을 제공하는 것이다."}
{"patent_id": "10-2021-0176476", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기와 같은 목적을 달성하기 위하여, 본 발명의 일 실시예에 의한 인공지능 손위치 인식을 이용한 아바타 제어 시스템은 사용자의 손 모션을 감지하여 사용자의 손 모션 데이터를 생성하는 영상 처리 모듈; 외부로부터 수신 되는 제어신호에 따라 미리 생성된 아바타를 동작시키는 아바타 동작 모듈; 및 상기 사용자의 손 모션 데이터에대응되는 아바타의 동작 정보를 생성하고, 상기 생성된 아바타의 동작 정보를 기초로 상기 아바타를 동작시키는 프로세서를 포함하는 것을 특징으로 한다. 상기 영상 처리 모듈은, 사용자를 촬영하여 X축(화면의 좌우), Y축(화면의 상하) 및 Z축(화면의 깊이)으로 분할 된 영상 프레임을 생성하는 영상 생성부; 상기 영상 프레임 중 사용자의 손의 위치에 대응하는 좌표값을 생성하 는 손위치 생성부; 및 상기 좌표값의 이동 방향을 산출하고, 상기 산출된 좌표값의 이동 방향을 기초로 미리 설 정된 사용자의 손 모션 데이터를 생성하는 모션 데이터 생성부를 포함하는 것을 특징으로 한다. 상기 모션 데이터 생성부는 사용자의 왼손, 오른손, 또는 왼손 및 오른손의 좌표값을 이용하여 이동 방향을 산 출하되, 사용자의 왼손만 좌우로 이동되는 경우, 좌우 이동 정보에 대응되는 X축에 대한 사용자의 모션 데이터 를 생성하고, 사용자의 오른손만 상하로 이동되는 경우, 상하 이동 정보에 대응되는 Z축에 대한 사용자의 모션 데이터를 생성하며, 사용자의 왼손 및 오른 손이 모은 상태로 상하로 이동되는 경우, 상하 이동 정보에 대응되 는 Y축에 대한 사용자의 모션 데이터를 생성하는 것을 특징으로 한다. 상기 모션 데이터 생성부는 사용자의 왼손 및 오른 손의 거리가 사용자의 손을 표현하는 객체의 크기보다 작으 면 사용자의 왼손 및 오른 손이 모은 상태인 것으로 판단하는 것을 특징으로 한다. 상기 모션 데이터 생성부는 사용자의 왼손 및 오른 손이 모은 상태로 미리 설정된 영역으로 이동되는 경우, 정 지 동작을 의미하는 사용자의 모션 데이터를 생성하는 것을 특징으로 한다."}
{"patent_id": "10-2021-0176476", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명의 일 실시예에 따른 인공지능 손위치 인식을 이용한 아바타 제어시스템은 기존의 LSTM(Long Short Term Memory) 딥러닝 방식과 같은 무거운 인공지능 계산을 수행하지 않고도 정지영상에서 간단한 계산으로 아바타 제 어명령을 생성할 수 있기 때문에, 손 위치 인식을 이용한 아바타 제어기를 제공할 수 있다."}
{"patent_id": "10-2021-0176476", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "상기한 바와 같은 본 발명을 첨부된 도면들과 실시예들을 통해 상세히 설명하도록 한다. 본 발명에서 사용되는 기술적 용어는 단지 특정한 실시 예를 설명하기 위해 사용된 것으로, 본 발명을 한정하려 는 의도가 아님을 유의해야 한다. 또한, 본 발명에서 사용되는 기술적 용어는 본 발명에서 특별히 다른 의미로 정의되지 않는 한, 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자에 의해 일반적으로 이해되는 의미로 해석되어야 하며, 과도하게 포괄적인 의미로 해석되거나, 과도하게 축소된 의미로 해석되지 않아야 한다. 또한, 본 발명에서 사용되는 기술적인 용어가 본 발명의 사상을 정확하게 표현하지 못하는 잘못된 기술적 용어일 때에 는, 당업자가 올바르게 이해할 수 있는 기술적 용어로 대체되어 이해되어야 할 것이다. 또한, 본 발명에서 사용 되는 일반적인 용어는 사전에 정의되어 있는 바에 따라, 또는 전후 문맥상에 따라 해석되어야 하며, 과도하게 축소된 의미로 해석되지 않아야 한다.또한, 본 발명에서 사용되는 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한 복수의 표현을 포함한다. 본 발명에서, \"구성된다\" 또는 \"포함한다\" 등의 용어는 발명에 기재된 여러 구성 요소들, 또는 여러 단계를 반 드시 모두 포함하는 것으로 해석되지 않아야 하며, 그 중 일부 구성 요소들 또는 일부 단계들은 포함되지 않을 수도 있고, 또는 추가적인 구성 요소 또는 단계들을 더 포함할 수 있는 것으로 해석되어야 한다. 또한, 본 발명에서 사용되는 제 1, 제 2 등과 같이 서수를 포함하는 용어는 구성 요소들을 설명하는데 사용될 수 있지만, 구성 요소들은 용어들에 의해 한정되어서는 안 된다. 용어들은 하나의 구성 요소를 다른 구성 요소 로부터 구별하는 목적으로만 사용된다. 예를 들어, 본 발명의 권리 범위를 벗어나지 않으면서 제 1 구성 요소는 제 2 구성 요소로 명명될 수 있고, 유사하게 제 2 구성 요소도 제 1 구성 요소로 명명될 수 있다. 이하, 첨부된 도면을 참조하여 본 발명에 따른 바람직한 실시 예를 상세히 설명하되, 도면 부호에 관계없이 동 일하거나 유사한 구성 요소는 동일한 참조 번호를 부여하고 이에 대한 중복되는 설명은 생략하기로 한다. 또한, 본 발명을 설명함에 있어서 관련된 공지 기술에 대한 구체적인 설명이 본 발명의 요지를 흐릴 수 있다고 판단되는 경우 그 상세한 설명을 생략한다. 또한, 첨부된 도면은 본 발명의 사상을 쉽게 이해할 수 있도록 하기 위한 것일 뿐, 첨부된 도면에 의해 본 발명의 사상이 제한되는 것으로 해석되어서는 아니 됨을 유의해야 한다. 도 1은 본 발명의 일 실시예에 따른 인공지능 손위치 인식을 이용한 아바타 제어시스템을 개략적으로 나타내는 블록도이고, 도 2는 도 1의 영상 처리 모듈의 영상 생성부에서의 동작인식을 위한 영역의 구성을 나타내는 도면 이며, 도 3은 도 1의 영상 처리 모듈의 모션 데이터 생성부에서 사용자의 두 손에 대한 모음 여부를 판단하는 알고리즘을 설명하기 위한 도면이고, 도 4는 도 1의 영상 처리 모듈의 모션 데이터 생성부에서 사용자의 손 모 션 데이터를 정의하는 도면이며, 도 5a 내지 5d는 도 1의 영상 처리 모듈의 모션 데이터 생성부에서 사용자의 손 모션 데이터를 생성하는 예를 나타내는 도면이고, 도 6은 본 발명의 일 실시예에 따른 인공지능 손위치 인식 을 이용한 아바타 제어시스템의 동작을 나타내는 순서도이다. 도 1에 도시된 바와 같이, 본 발명의 일 실시예에 따른 인공지능 손위치 인식을 이용한 아바타 제어시스템은, 정지영상에서 간단한 계산으로 아바타 제어명령을 생성할 수 있는 시스템이고, 이를 위하여 영상 처리 모듈 , 아바타 동작 모듈 및 프로세서를 포함한다. 도시되어 있지는 않지만, 본 발명의 일 실시예에 따른 인공지능 손위치 인식을 이용한 아바타 제어시스템은, 아 바타 생성모듈과 출력 모듈을 더 포함할 수 있다. 상기 아바타 생성모듈은 가상현실(Virtual Reality) 환경에서 사용자의 아바타를 생성한다. 본 명세서에서 아바 타(avatar)는 실제 현실이 아닌 컴퓨터 프로그래밍에 의해 가상의 공간으로 구현된 가상현실에서 사용자의 명령 에 따라 제어될 수 있는 가상의 캐릭터를 의미한다. 아바타의 생김새는 사용자의 몰입감을 향상시키고 원할한 바이오피드백을 제공하기 위해 사용자와 유사한 생김새를 갖는 인간의 형상일 수 있으나 특정 형태로 한정되지 는 아니한다. 일 실시예에서, 사용자의 손 모션 데이터에 기초하여 아바타가 자동으로 생성될 수 있다. 예를 들어, 정지 영상 에서 사용자의 손 모션 변화를 감지하여 이에 따라 아바타의 자세 또는 동작을 변화시킬 수 있다. 이와 같이 사 용자의 손 모션 데이터에 따라 가상환경의 아바타의 형상이나 태도를 적절히 변화시키는 것은 가상현실에서의 실재감과 몰입감을 향상시킬 수 있다. 가상현실 환경에서 생성된 아바타는 후술하는 바와 같이 사용자의 손 모션 데이터에 기초하여 결정된 명령에 대 응하는 동작을 수행한다. 이를 이용하여, 사용자는 실제로 동작을 수행하지 않더라도 손 모션 데이터에 대응되 는 제어신호를 내보내 가상현실의 아바타가 특정한 동작을 행하도록 제어할 수 있고, 프로그램에서 제공되는 평 가 프로토콜 또는 훈련 프로토콜을 수행할 수 있다. 상기 출력 모듈은 아바타가 동작을 수행하는 영상을 실시간으로 출력하기 위한 TV, 모니터, HMD 등의 출력장치 이다. 일 실시예에서, 상기 출력 모듈은 발광다이오드(LED), 유기발광소자(OLED), 발광중합체(LEP), 전자발광소 자(EL), 전계방출소자(FED), 또는 중합체발광소자(PLED) 등이 적용된 디스플레이로 구성될 수 있다. 또한, 상기 출력 모듈은 머리에 착용 가능한 형태인 HMD(Head Mounted Display) 장치로 구성될 수 있다. HMD 장 치는 사용자의 머리에 착용하여 양안에 대응되는 디스플레이를 통해 화면을 감상할 수 있는 차세대 디스플레이 장치이다. 일반적으로 IMU 센서를 포함하여 회전 값을 통해 사용자의 머리 움직임을 동기화 시킬 수 있다. 이를 통해, 사용자는 증강현실(Augmented Reality) 또는 가상현실(Virtual Reality) 환경에서 종래의 모니터 장치로시청하는 것보다 더 뛰어난 몰입감을 느낄 수 있다. 상기 영상 처리 모듈은 사용자의 손 모션을 감지하여 사용자의 손 모션 데이터를 생성하는 장치로서, 영상 생성부, 손위치 생성부 및 모션 데이터 생성부를 포함한다. 상기 영상 생성부는 통상의 카메라를 이용할 수 있으며, 도 2에 도시된 바와 같이, 사용자를 촬영하여 정지 영상을 기초로 영상 프레임을 생성하는 장치로, X축(화면의 좌우), Y축(화면의 상하) 및 Z축(화면의 깊이)으로 분할된 영상 프레임을 생성하는 장치이다. 상기 손위치 생성부는 영상 생성부에 의하여 생성된 영상 프레임 중 사용자의 손의 위치에 대응하는 좌 표값을 생성하는 장치이다. 구체적으로, 상기 손위치 생성부는 정지 영상으로 구성된 영상 프레임 중 사용 자의 손 부분의 영상을 캡쳐하여 손의 모션에 대응한 좌표값(즉, 손의 좌표)을 생성한다. 이때, 손의 좌표는 손 가락 관절, 손목 관절을 포함하고, 이에 손의 전체적인 크기 및 손가락 길이 등을 확인할 수 있도록 한다. 또한, 상기 손위치 생성부에서는 손가락 끝 및 각 관절의 포인트의 이동을 추적하여 손의 움직임을 추적하 여 좌표값을 생성한다. 상기 손위치 생성부는, 영상 생성부로부터 전달된 영상 프레임간의 연결관계를 정의하는 전처리부(미도 시)와, 전처리가 이루어진 영상 프레임에서 미리 학습된 학습 정보를 기반으로 하여 손을 인식하는 손 인식부 (미도시)와, 인식된 손에 대한 좌표 조정을 수행하고, 미리 학습된 학습 정보를 기반으로 하여 영상 프레임간 변위로부터 손의 이동좌표를 계산하는 이동좌표 산출부(미도시)를 포함한다. 여기서, 손에 대한 인식에 있어, 먼저 손에 대한 학습을 수행하여 학습된 결과를 저장하고, 이 저장된 학습 정 보로부터 손에 대한 인식이 이루어지는 것이 바람직하다. 한편, 손에 대한 인식과 함께 머리, 몸통, 팔, 다리 등의 학습 및 이의 인식도 함께 이루어지며, 이들의 인식을 통해 손의 위치를 정확하게 판단하는데 이용할 수 있다. 이와 같이 구성된 손위치 생성부에서, 손을 인식하고 좌표를 산출함에 있어, 움직임을 추정하는 추정기법을 이용하여 미리 예측된 위치에서 손의 존재여부를 확인하게 된다. 각 영상 프레임들에서 손의 움직임 추정기법을 통해 손을 추정하여 검색하고, 검색된 손의 이동좌표를 산출한다. 즉, 이전 영상 프레임에서 손의 움직임 벡터 성분을 추출하고, 현재 영상 프레임에서 손의 움직임 벡터성분을 추출하여 움직임 추정을 실행하게 되며, 이에 다음 영상 프레임에서의 손의 위치를 추정할 수 있는 것이다. 또한 이러한 추정은 미리 학습된 학습 정보에 의 해 이루어지게 된다. 만약, 추정된 위치에 손이 존재하지 않을 경우에는 추정된 위치를 중심으로 반경을 설정하 여 해당 반경 내에서 손에 대한 검색이 이루어진다. 이때 팔이 검색되었다면, 인체의 구조에 기반하여 손의 위 치를 더욱 손쉽게 추정하게 된다. 상기 모션 데이터 생성부는 손위치 생성부에서 생성된 좌표값의 이동 방향을 산출하고, 상기 산출된 좌 표값의 이동 방향을 기초로 미리 설정된 사용자의 손 모션 데이터를 생성하는 장치이다. 상기 모션 데이터 생성부는 손위치 생성부에서 생성된 좌표값을 전달받아 이동 위치 등의 변화를 처리 하며, 또한 이동 위치 변화로부터 이벤트(제어)를 생성하고, 전달된 손의 좌표로부터 손 형상을 인식함과 아울 러 사용자의 손 모션 데이터를 생성한다. 즉, 상기 모션 데이터 생성부는 손위치 생성부에서 생성된 좌표값을 수신하고, 프로세서를 통해 이 를 처리하여 대응되는 사용자의 명령(즉, 아바타 제어신호)인 사용자의 손 모션 데이터를 결정한다. 명령의 결 정에 필요한 분석 알고리즘 또는 룩업 테이블 등의 관련 정보는 손위치 기반 제어 프로그램과 함께 메모리에 저 장될 수 있다. 또한, 상기 모션 데이터 생성부는 프로세서를 통해 아바타 제어신호에 대해 주파수 필터링을 수행한다. 고주파 노이즈를 제거하고자 하는 경우 저역 통과 필터(low-pass filter)를 이용할 수 있고, 특정 주파수 영역 을 선택하고자 하는 경우 대역 통과 필터(band-pass filter)를 이용하거나, 특정 주파수 영역을 제거하고자 하 는 경우 대역 저지 필터(bandstop filter)를 이용할 수 있다. 상기 모션 데이터 생성부는 필터링된 신호의 해당 주파수에 대한 로그 값 및 분산 값을 포함하여 산출한 데 이터 파워에 기초하여 특징 벡터를 추출한다. 예를 들어, 프로세서는 고속 푸리에 변환(FFT)에 기초하여 신 호 데이터 상의 특정 주파수의 신호 성분이 차지하는 비중을 정량적으로 분석할 수 있다. 이외에도 아바타 제어신호에 신호처리 함수를 적용해 평균, 편차, RMS(Root mean square), 왜도, 첨도, DF(Dominant frequency) 등을 계산하여 특징벡터를 추출할 수 있고, 추출된 특징벡터 데이터는 대응되는 사용자의 명령을 결정하는데 이용된다. 한편, 상기 모션 데이터 생성부는 아바타 제어신호에 대한 전처리가 완료되면, 분류기 생성 모듈을 통해 복 수의 분류기(classifier)를 생성할 수 있다. 프로세서는 복수의 분류 알고리즘에 기초하여 분류기를 생성할 수 있다. 복수의 분류기는 사용자의 손 모션 데이터를 분류하여 상기 데이터가 특정 클래스에 해당하는지 여부 를 판단한다. 상기 모션 데이터 생성부는 이에 기초하여 복수의 동작 중 실시간 사용자의 손 모션 데이터에 대응하는 동 작을 선택하고 최종적으로 사용자의 명령(command)을 결정한다. 구체적으로, 프로세서는 분류기에 기초하여 입력된 실시간 사용자의 손 모션 데이터에 대한 각 움직임을 확률이나 점수 등의 출력 값으로 산출할 수 있고, 프로세서는 확률 또는 점수가 가장 큰 값을 갖는 동작을 선택하여 명령을 결정할 수 있다. 실시예에 따라 다양한 형태의 명령이 사용자의 손 모션 데이터와 대응되도록 미리 저장될 수 있다. 예를 들어, 단순히 아바타를 전후좌우로 움직이는 명령에서 나아가 앉기/서기와 같은 명령이나, 발을 위아래로 들기, 무릎 을 굽히거나 펴기와 같은 관절 관련 움직임도 명령으로 지정될 수 있다. 본 발명은 다양한 종류의 사용자의 손 위치 신호를 동시에 획득할 수 있고, 이를 세부적인 동작 명령들과 매칭함으로써 다양하고 자연스러운 형태의 동작을 가상현실에서 구현할 수 있다. 각 명령에 대한 사용자의 의도를 파악하고 오작동률을 줄이기 위한 신호 처리 알고리즘은 전술한 바와 같다. 다시 설명하자면, 상기 모션 데이터 생성부는 도 4에 도시된 바와 같이, 사용자의 손 위치에 따른 사용자의 동작 명령을 정의하고, 사용자의 왼손(L), 오른손(R), 또는 왼손(L) 및 오른손(R)의 좌표값을 이용하여 이동 방 향을 산출한다. 상세하게는, 상기 모션 데이터 생성부는 아래와 같이 좌표축 이동 방향을 정의한다. X 축: 화면에서 좌우로 움직이는 방향, 오른쪽으로 가면 + Y 축: 화면에서 상하로 움직이는 방향, 위로 가면 + Z 축: 화면 깊이로 움직이는 방향, 스크린을 보는 사람 방향으로 나오면 + X축 방향 제어 왼손을 좌우로 움직여 조정한다(왼손이 -X 위치하면 왼쪽으로 이동, +X 에 위치하면 오른쪽으로 이동) Y축 방향 제어 두 손을 모은 채로 두 손을 상하로 움직여 조정한다(두 손이 +Y에 위치하면 위쪽으로 이동, -Y에 위치하면 아래 로 이동). Z축 방향 제어 오른손을 상하로 움직여 조정한다(오른손이 +Z위치하면 화면 앞쪽으로 이동, -Z에 위치하면 화면 뒤쪽으로 이동). 정지 동작 두 손을 모은 채로 stop 구역으로 이동하면 정지한다. 상기 모션 데이터 생성부는 도 5a에 도시된 바와 같이, 사용자의 왼손만 좌우로 이동되는 경우, 좌우 이동 정보에 대응되는 X축에 대한 사용자의 모션 데이터를 생성한다. 또한, 상기 모션 데이터 생성부는 도 5b에 도시된 바와 같이, 사용자의 오른손만 상하로 이동되는 경우, 상 하 이동 정보에 대응되는 Z축에 대한 사용자의 모션 데이터를 생성한다. 또한, 상기 모션 데이터 생성부는 도 5c에 도시된 바와 같이, 사용자의 왼손 및 오른 손이 모은 상태로 상 하로 이동되는 경우, 상하 이동 정보에 대응되는 Y축에 대한 사용자의 모션 데이터를 생성한다. 한편, 상기 모션 데이터 생성부는 사용자의 왼손 및 오른 손의 거리가 사용자의 손을 표현하는 객체의 크기 보다 작으면 사용자의 왼손 및 오른 손이 모은 상태인 것으로 판단한다. 즉, 상기 모션 데이터 생성부는 도 3 및 수학식 1에서와 같이, 두 손 간의 거리(d)가 손을 표현하는 객체의 크기(2 * r)보다 작으면 두 손을 모으 는 것으로 판단한다.[수학식 1] d < 2* r 상기 모션 데이터 생성부는 도 5d에 도시된 바와 같이, 사용자의 왼손 및 오른 손이 모은 상태로 미리 설정 된 영역(stop)으로 이동되는 경우, 정지 동작을 의미하는 사용자의 모션 데이터를 생성한다. 상기 아바타 동작 모듈은 외부로부터 수신되는 제어신호에 따라 미리 생성된 아바타를 동작시키는 장치이다. 즉, 상기 아바타 동작 모듈은 아바타 생성모듈에 의하여 생성된 아바타를 프로세서로부터 수 신되는 제어 신호를 기초로 동작시켜 출력 모듈을 통하여 출력시키게 된다. 상기 아바타 동작 모듈은 프로세서로부터 결정된 명령(command)을 수신하고, 프로세서를 통해 아바 타가 상기 명령에 대응되는 동작을 수행하도록 제어한다. 사용자의 동작 의도는 스테이트(state)로 변환되어 명 령으로 결정된다. (예를 들어, 좌우 이동, 앞뒤 이동, 상하 이동 등) 한편, 동일한 동작이라도 회전의 크기와 동작의 속도가 상이할 수 있는데, 명령의 스테이트 외에도 제어신호의 진폭(amplitude)에 따라 조절될 수 있다. 예를 들어, 특정한 주파수를 갖는 제어신호가 감지되었는데, 해당 주 파수 및 부위의 신호가 아바타를 \"앞으로 전진\"시키는 명령과 매칭되어 있다면, 아바타 동작 모듈은 아바타 가 앞으로 전진하도록 제어한다. 이때, 제어신호의 진폭이 클수록 아바타는 빠른 속도로 전진하고 진폭이 작을 수록 아바타는 천천히 전진할 수 있다. 상기 프로세서는 영상 처리 모듈에 의하여 생성된 사용자의 손 모션 데이터에 대응되는 아바타의 동작 정보를 생성하고, 상기 생성된 아바타의 동작 정보를 기초로 아바타 동작모듈을 통하여 아바타를 동작시킨다. 상기와 같이 구성된 본 발명의 일 실시예에 따른 인공지능 손위치 인식을 이용한 아바타 제어시스템은, 도 6에 도시된 바와 같이, 영상 생성부에 의하여 촬영된 사용자의 영상 프레임을 손위치 생성부를 통하여 캡쳐 하여 손의 위치에 대응하는 좌표값을 인식한다(S10). 그런 다음, 모션데이터 생성부를 통하여 양손 간의 거리 계산을 수행(S20)한 후, 한 손으로 판단되는 경우 에는 앞뒤좌우 손 위치를 계산(S30)하여 좌우 이동으로 판단되면, 프로세서를 통하여 아바타를 좌우로 이동 (S31)시키고, 앞뒤 이동으로 판단되면, 프로세서를 통하여 아바타를 앞뒤로 이동(S32)시킨다. 또한, 모션데이터 생성부를 통하여 양손 간의 거리 계산을 수행(S20)한 후, 두손으로 판단되는 경우에는 상 하 손위치 계산(S40)하여 상하 이동으로 판단되면, 프로세서를 통하여 아바타를 상하로 이동(S41)시킨다. 상기와 같이 구성된 본 발명의 일 실시예에 따른 인공지능 손위치 인식을 이용한 아바타 제어시스템에 따르면, 기존의 LSTM(Long Short Term Memory) 딥러닝 방식과 같은 무거운 인공지능 계산을 수행하지 않고도 정지영상에 서 간단한 계산으로 아바타 제어명령을 생성할 수 있기 때문에, 손 위치 인식을 이용한 아바타 제어기를 제공할 수 있다. 한편, 상기 영상 처리 모듈의 표면에는 오염물질의 부착방지 및 제거를 효과적으로 달성할 수 있도록 오염 방지 도포용 조성물로 이루어진 오염방지도포층이 도포될 수 있다. 상기 오염 방지 도포용 조성물은 소듐세스퀴카보네이트 및 부틸카비톨이 1:0.01 ~ 1:2 몰비로 포함되어 있고, 소듐세스퀴카보네이트 및 부틸카비톨 총함량은 전체 수용액에 대해 1 ~10 중량%이다. 상기 소듐세스퀴카보네이트 및 부틸카비톨은 몰비로서 1:0.01 ~ 1:2가 바람직한 바, 몰비가 상기 범위를 벗어 나는 경우에는 오염방지도포층의 도포성이 저하되거나 도포 후에 표면의 수분흡착이 증가하여 도포막이 제거되 는 문제점이 있다. 상기 소듐세스퀴카보네이트 및 부틸카비톨은 전체 조성물 수용액 중 1 ~ 10 중량%가 바람직한 바, 1 중량% 미 만이면 오염방지도포층의 도포성이 저하되는 문제점이 있고, 10 중량%를 초과하면 도포막 두께의 증가로 인한 결정석출이 발생하기 쉽다. 한편, 본 오염방지도포용 조성물을 영상 처리 모듈의 표면 상에 도포하는 방법으로는 스프레이법에 의해 도 포하는 것이 바람직하다. 또한, 상기 영상 처리 모듈의 표면 상의 최종 도포막 두께는 700 ~ 2500Å이 바람 직하며, 보다 바람직하게는 900 ~ 2000Å이다. 상기 도포막의 두께가 700 Å미만이면 고온 열처리의 경우에 열 화되는 문제점이 있고, 2500 Å을 초과하면 도포 표면의 결정석출이 발생하기 쉬운 단점이 있다.또한, 본 오염 방지 도포용 조성물은 소듐세스퀴카보네이트 0.1 몰 및 부틸카비톨 0.05몰을 증류수 1000 ㎖에 첨가한 다음 교반하여 제조될 수 있다. 상기 구성 성분의 비율 및 도포막 두께를 상기와 같이 수치 한정한 이유는, 본 발명자가 수차례 실패를 거듭하 면서 시험결과를 통해 분석한 결과, 상기 비율에서 최적의 오염방지 도포 효과를 나타내었다. 상기 프로세서의 표면에는 표면에 방열용 코팅제가 도포되어 프로세서에서 방출되는 열이 충분히 발산 되지 못하여 프로세서의 표면이 과도하게 가열되는 방지하고 열을 효과적으로 방출할 수가 있다. 이 방열용 코팅제 조성물은 규산칼륨 58중량%, 산화크롬 11중량%, 그라파이트 13중량%, 질화규소 8중량%, 수산 화나트륨(NaOH) 3중량%, 산화티탄 3중량%, 폴리아마이드왁스 2중량%, 3-아미노프로필 트리메톡시실란 2중량%로 구성된다. 규산칼륨은 바인더 수지 역할을 하고, 산화크롬은 내마모 역할을 하며, 그라파이트는 열전도성과 전기적 특성이 우수하며, 질화규소는 강도 향상 및 균열을 방지하고, 수산화나트륨은 분산제 역할을 하며, 산화티탄은 내후성 을 위해서, 폴라아마이드왁스는 침강방지 역할을 하고, 3-아미노프로필 트리메톡시실란은 부착력 증강 역할을 한다. 상기와 같이 구성 물질 및 구성 성분을 한정하고 혼합 비율의 수치를 한정한 이유는, 본 발명자가 수차례 실패 를 거듭하면서 시험 결과를 통해 분석한 결과, 상기 구성 성분 및 수치 한정 비율에서 최적의 효과를 나타내었 다. 상기 아바타 동작모듈의 표면에는 살균기능 및 사용자 스트레스 완화 등에 도움이 되는 기능성 오일이 혼합 된 환경용 방향제 물질이 코팅될 수 있다. 방향제 물질과 기능성 오일의 혼합 비율은 상기 방향제 물질 95~97중량%에 상기 기능성 오일 3~5중량%가 혼합되 며, 기능성 오일은 안젤리카오일(Angelica oil) 50중량%, 시트로넬라오일(Citronella oil) 50중량%로 구성된다. 여기서 기능성 오일은 방향제 물질에 대해 3~5중량%가 혼합되는 것이 바람직하다. 기능성 오일의 혼합비율이 3 중량% 미만이면, 그 효과가 미미하며, 기능성 오일의 혼합비율이 3~5중량%를 초과하면 그 효과가 크게 향상되지 않는 반면에 경제성이 떨어진다. 안젤리카오일(Angelica oil)은 스트레스 완화, 긴장완화, 살균 등에 좋은 효과 가 있고, 시트로넬라오일(Citronella oil)은 심리적으로 마음을 정화하고 고양시키며 두통, 우울증, 신경통 등 에 작용효과가 우수하다. 따라서, 이러한 기능성 오일이 혼합된 방향제 물질이 아바타 동작모듈의 표면에 코팅됨에 따라, 아바타 동작모듈의 표면을 살균 처리하고 사용자의 스트레스 등을 경감시키는 등의 효과를 얻을 수 있다. 환경용 방향제 물질 및 기능성 오일에 대해 구성 성분을 한정하고 혼합 비율의 수치를 한정한 이유는, 본 발명 자가 수차례 실패를 거듭하면서 시험 결과를 통해 분석한 결과, 상기 구성 성분 및 수치 한정 비율에서 최적의 효과를 나타내었다. 한편, 영상 처리 모듈의 하단부에는 고무재질의 진동흡수부가 더 설치 될 수 있다. 이 진동흡수부는 고무 재질로 이루어질 수 있으며, 이러한 진동흡수부의 원료 함량비는 고무 60중량%, 디부틸치 오우레아 8중량%, 칼슘스테아레이트 6중량%, 카아본블랙 19중량%, 3C(N-PHENYL-N'-ISOPROPYL- P- PHENYLENEDIAMINE) 3중량%, 유기퍼옥사이드 4중량% 를 혼합한다. 디부틸치오우레아는 가황촉진 향상 등을 위해 첨가되며, 칼슘스테아레이트는 연화제 역할을 위해 첨가되고, 카 아본블랙은 내마모성, 열전도성 등을 증대하거나 향상시키기 위해 첨가된다. 3C (N-PHENYL-N'-ISOPROPYL- P-PHENYLENEDIAMINE)는 산화방지제로 첨가되며, 유기퍼옥사이드는 촉진제 등의 역 할을 위해 첨가된다. 따라서 본 발명은 진동흡수부의 탄성, 인성 및 강성이 증대되므로 내구성이 향상되며, 이에 따라 진동흡수부의 수명이 증대된다. 고무재질의 인장강도는 155Kg/㎠ 로 형성된다. 고무재질 구성 물질 및 구성 성분을 한정하고 혼합 비율의 수치 등을 한정한 이유는, 본 발명자가 수차례 실패 를 거듭하면서 시험 결과를 통해 분석한 결과, 상기 구성 성분 및 수치 한정 비율에서 최적의 효과를 나타내었다. 이상에서는 본 발명에 따른 바람직한 실시예들에 대하여 도시하고 또한 설명하였다. 그러나 본 발명은 상술한 실시예에 한정되지 아니하며, 특허 청구의 범위에서 첨부하는 본 발명의 요지를 벗어남이 없이 당해 발명이 속 하는 기술 분야에서 통상의 지식을 가진 자라면 누구든지 다양한 변형 실시가 가능할 것이다."}
{"patent_id": "10-2021-0176476", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일 실시예에 따른 인공지능 손위치 인식을 이용한 아바타 제어시스템을 개략적으로 나타내는 블럭도이다. 도 2는 도 1의 영상 처리 모듈의 영상 생성부에서의 동작인식을 위한 영역의 구성을 나타내는 도면이다. 도 3은 도 1의 영상 처리 모듈의 모션 데이터 생성부에서 사용자의 두 손에 대한 모음 여부를 판단하는 알고리 즘을 설명하기 위한 도면이다. 도 4는 도 1의 영상 처리 모듈의 모션 데이터 생성부에서 사용자의 손 모션 데이터를 정의하는 도면이다. 도 5a 내지 5d는 도 1의 영상 처리 모듈의 모션 데이터 생성부에서 사용자의 손 모션 데이터를 생성하는 예를 나타내는 도면이다. 도 6은 본 발명의 일 실시예에 따른 인공지능 손위치 인식을 이용한 아바타 제어시스템의 동작을 나타내는 순서 도이다."}
