{"patent_id": "10-2021-0046631", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2022-0140301", "출원번호": "10-2021-0046631", "발명의 명칭": "인공지능을 통해 학습자 식별이 가능한 화상 학습 시스템 및 그 방법", "출원인": "주식회사 퀄슨", "발명자": "장현석"}}
{"patent_id": "10-2021-0046631", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "인공지능을 통해 학습자 식별이 가능한 화상 학습 시스템에 있어서, 학습자에 의해 발화된 음성 신호를 수신하고, 수신된 음성 신호를 전처리하는 음성 인식부, 상기 전처리된 음성 신호로부터 학습자 고유의 음성 특징 벡터를 추출하는 특징 추출부, 상기 학습자 음성으로부터 추출된 음성 특징 벡터를 기 구축된 학습모델에 입력하여 학습자를 식별하는 식별부,그리고 상기 식별된 학습자의 학습 정보를 이용하여 매칭 가능한 원어민 강사를 추출하고, 추출된 원어민 강사에 대한정보를 학습자 단말기에 제공하며, 상기 학습자 단말기로부터 특정 원어민 강사에 대한 연결 요청 신호를 수신하면, 해당되는 원어민 강사 단말기에 수업 요청 신호를 전송하여 강사와 학습자를 연결시키는 제어부를 포함하는 화상 학습 시스템."}
{"patent_id": "10-2021-0046631", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 복수의 학습자로부터 발화된 음성을 수집하는 음성 데이터 수집부, 그리고 상기 수집된 학습자 음성으로부터MFCC(Mel-Frequency Cepstrum Coefficient) 또는 LPC(Linear Predictive Coding) 알고리즘을 이용하여 학습자마다 고유의 음성 특징 벡터를 추출하고, 추출한 음성 특징 벡터를 데이터셋으로 하여 GMM-UBM(GaussianMixture Model - Universal Background Model)의 학습모델의 학습시키는 학습부를 더 포함하는 화상 학습 시스템."}
{"patent_id": "10-2021-0046631", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 학습 정보는, 학습자의 학습 내역 및 선호 강사 유형에 대한 정보를 포함하고, 상기 제어부는, 상기 학습 정보와 매칭되는 원어민 강사 정보를 추출하는 화상 학습 시스템."}
{"patent_id": "10-2021-0046631", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,원어민 강사명, 수업 가능 시간, 강사 평가 정보를 포함하는 강사 정보를 수집하는 강사 정보 수집부를 더 포함하는 화상 학습 시스템."}
{"patent_id": "10-2021-0046631", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서,상기 제어부는, 상기 원어민 강사 정보를 이용하여 매칭 가능한 원어민 강사를 추출하고, 추출된 원어민 강사와 매칭될 경우,WebRTC 기반의 저지연 화상 학습으로 어학 학습을 수행하게 하는 화상 학습 시스템."}
{"patent_id": "10-2021-0046631", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5항에 있어서,공개특허 10-2022-0140301-3-상기 제어부는, 학습이 완료되면 학습 영상, 학습한 문장 및 학습 피드백 정보를 학습 정보에 업로드하고, 상기 학습 정보를 학습자 단말기에 전달하는 화상 학습 시스템."}
{"patent_id": "10-2021-0046631", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "화상 학습 시스템을 이용한 화상 학습 방법에 있어서, 학습자에 의해 발화된 음성 신호를 수신하고, 수신된 음성 신호를 전처리하는 단계, 상기 전처리된 음성 신호로부터 학습자 고유의 음성 특징 벡터를 추출하는 단계, 상기 학습자 음성으로부터 추출된 음성 특징 벡터를 기 구축된 학습모델에 입력하여 학습자를 식별하는 단계,그리고 상기 식별된 학습자의 학습 정보를 이용하여 매칭 가능한 원어민 강사를 추출하고, 추출된 원어민 강사에 대한정보를 학습자 단말기에 제공하며, 상기 학습자 단말기로부터 특정 원어민 강사에 대한 연결 요청 신호를 수신하면, 해당되는 원어민 강사 단말기에 수업 요청 신호를 전송하여 강사와 학습자를 연결시키는 단계를 포함하는화상 학습 방법."}
{"patent_id": "10-2021-0046631", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서, 복수의 학습자로부터 발화된 음성을 수집하는 단계, 그리고상기 수집된 학습자 음성으로부터 MFCC(Mel-Frequency Cepstrum Coefficient) 또는 LPC(Linear PredictiveCoding) 알고리즘을 이용하여 학습자마다 고유의 음성 특징 벡터를 추출하고, 추출한 음성 특징 벡터를 데이터셋으로 하여 GMM-UBM(Gaussian Mixture Model - Universal Background Model)의 학습모델의 학습시키는 단계를더 포함하는 화상 학습 방법."}
{"patent_id": "10-2021-0046631", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제7항에 있어서,상기 학습 정보는, 학습자의 학습 내역 및 선호 강사 유형에 대한 정보를 포함하고, 상기 강사와 학습자를 연결시키는 단계는, 상기 학습 정보와 매칭되는 원어민 강사 정보를 추출하는 화상 학습 방법."}
{"patent_id": "10-2021-0046631", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제7항에 있어서,원어민 강사명, 수업 가능 시간, 강사 평가 정보를 포함하는 원어민 강사 정보를 수집하는 단계를 더 포함하는화상 학습 방법."}
{"patent_id": "10-2021-0046631", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제10항에 있어서,상기 강사와 학습자를 연결시키는 단계는, 상기 원어민 강사 정보를 이용하여 매칭 가능한 원어민 강사를 추출하고, 추출된 원어민 강사와 매칭될 경우,WebRTC 기반의 저지연 화상 학습으로 어학 학습을 수행하게 하는 화상 학습 방법."}
{"patent_id": "10-2021-0046631", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항에 있어서,공개특허 10-2022-0140301-4-상기 강사와 학습자를 연결시키는 단계는, 학습이 완료되면 학습 영상, 학습한 문장 및 학습 피드백 정보를 학습 정보에 업로드하고, 상기 학습 정보를 학습자 단말기에 전달하는 화상 학습 방법."}
{"patent_id": "10-2021-0046631", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 인공지능을 통해 학습자 식별이 가능한 화상 학습 시스템 및 그 방법 에 대한 것이다. 본 발명에 따른 화상 학습 시스템은 학습자에 의해 발화된 음성 신호를 수신하고, 수신된 음성 신호를 전처리하 는 음성 인식부, 상기 전처리된 음성 신호로부터 학습자 고유의 음성 특징 벡터를 추출하는 특징 추출부, 상기 (뒷면에 계속)"}
{"patent_id": "10-2021-0046631", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 인공지능을 통해 학습자 식별이 가능한 화상 학습 시스템 및 그 방법에 관한 것으로, 보다 상세하게 는 AI 스피커 환경에서 학습 모델을 이용하여학습자의 음성을 분석해 학습자를 식별하고, 식별된 학습자의 특성 에 맞는 맞춤형 서비스를 제공하여 학습자의 학습 효율을 극대화하는 화상 학습 시스템 및 그 방법에 관한 것이다."}
{"patent_id": "10-2021-0046631", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "딥러닝 및 AI 기술이 발전함에 따라, 영상 및 소리와 관련된 다양한 기술(TTS, STT)에도 딥러닝 기반의 AI 기술 이 적용되며 빠르게 발전해가고 있다. AI 스피커 또한, 딥러닝 기술과 함께 빠르게 발전하고 있는 분야 중 하나 이며, 여러 유저가 하나의 기기를 공유하면서 발생하는 문제들 또한 AI 기술을 통해 빠르게 개선되고 있는 상황 이다. 한편, 종래의 외국어 학습방법으로는 학습자가 듣기, 읽기, 회화, 쓰기 등의 외국어 습득을 위해 뉴스청취, 학 원, 학습교재, 전화를 이용한 말하기 훈련을 각각 따로 따로 훈련하고 있었다. 그러나, 종래의 방법은 듣기, 읽기, 회화, 쓰기 등의 외국어 학습을 각각 따로 따로 훈련함으로써 외국어 습득 을 위해 가장 중요한 반복 효과가 저해되어 학습효율이 떨어지게 되는 문제점이 있었고, 또한 통문장 암기에 의 한 외국에 훈련 시 지속적인 단어 및 문장의 활용이 수반되지 않으면 학습자는 곧 문장을 망각하게 되어 다시 기억 속에서 꺼내기 위한 작업을 해야 하기 때문에 이 또한 학습효율이 낮아지게 되는 문제점이 발생하고 있었 다. 또한, 종래에는 대부분이 테이프 등을 활용하여 외국어를 청취하기 때문에 단어에 대한 억양 및 문장에 대한 리 듬 학습이 사실상 어려워지는 문제점이 있었고, DVD와 같은 영상매체를 이용한 외국어 듣기학습은 상황에 따른 표현 방법 등을 익힐 수 있는 장점은 있으나 현란한 동영상으로 인하여 소리에 집중할 수 없는 문제점이 있었다. 따라서, 최근에는 온라인을 통해 학습자와 원어민 강사를 매칭하여 학습을 수행하고 있다. 어학 학습의 특성상, 학습자 파악 및 학습자의 학습 진도 및 레벨에 따른 맞춤 학습이 중요하고, 여러 유저가 하나의 기기를 공유하 는 AI 스피커 학습 환경에서 현재 발화하는 학습자가 누구인지 파악하는 기술(Speaker Recognition)은 필수적이 다. 그러나, 현재 학습자 인식 모듈이 적용된 AI 스피커 기반의 어학 학습 서비스는 개발되지 않은 상황이다. 본 발명의 배경이 되는 기술은 대한민국 공개특허공보 제10-2130006호(2020.07.03. 공고)에 개시되어 있다."}
{"patent_id": "10-2021-0046631", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명이 이루고자 하는 기술적 과제는 AI 스피커 환경에서 학습 모델을 이용하여학습자의 음성을 분석해 학습 자를 식별하고, 식별된 학습자의 특성에 맞는 맞춤형 서비스를 제공하여 학습자의 학습 효율을 극대화하는 화상 학습 시스템 및 그 방법을 제공하기 위한 것이다."}
{"patent_id": "10-2021-0046631", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "이러한 기술적 과제를 이루기 위한 본 발명의 실시 예에 따른 인공지능을 통해 학습자 식별이 가능한 화상 학습 시스템에 있어서, 인공지능을 통해 학습자 식별이 가능한 화상 학습 시스템에 있어서, 학습자에 의해 발화된 음 성 신호를 수신하고, 수신된 음성 신호를 전처리하는 음성 인식부, 상기 전처리된 음성 신호로부터 학습자 고유 의 음성 특징 벡터를 추출하는 특징 추출부, 상기 학습자 음성으로부터 추출된 음성 특징 벡터를 기 구축된 학습모델에 입력하여 학습자를 식별하는 식별부, 그리고 상기 식별된 학습자의 학습 정보를 이용하여 매칭 가능한 원어민 강사를 추출하고, 추출된 원어민 강사에 대한 정보를 학습자 단말기에 제공하며, 상기 학습자 단말기로 부터 특정 원어민 강사에 대한 연결 요청 신호를 수신하면, 해당되는 원어민 강사 단말기에 수업 요청 신호를 전송하여 강사와 학습자를 연결시키는 제어부를 포함한다. 복수의 학습자로부터 발화된 음성을 수집하는 음성 데이터 수집부, 그리고 상기 수집된 학습자 음성으로부터 MFCC(Mel-Frequency Cepstrum Coefficient) 또는 LPC(Linear Predictive Coding) 알고리즘을 이용하여 학습자 마다 고유의 음성 특징 벡터를 추출하고, 추출한 음성 특징 벡터를 데이터셋으로 하여 GMM-UBM(Gaussian Mixture Model - Universal Background Model)의 학습모델의 학습시키는 학습부를 더 포함할 수 있다. 상기 학습 정보는, 학습자의 학습 내역 및 선호 강사 유형에 대한 정보를 포함하고, 상기 제어부는, 상기 학습 정보와 매칭되는 원어민 강사 정보를 추출할 수 있다. 원어민 강사명, 수업 가능 시간, 강사 평가 정보를 포함하는 원어민 강사 정보를 수집하는 강사 정보 수집부를 더 포함할 수 있다. 상기 제어부는, 상기 원어민 강사 정보를 이용하여 매칭 가능한 원어민 강사를 추출하고, 추출된 원어민 강사와 매칭될 경우, WebRTC 기반의 저지연 화상 학습으로 어학 학습을 수행하게 할 수 있다. 상기 제어부는, 학습이 완료되면 학습 영상, 학습한 문장 및 학습 피드백 정보를 학습 정보에 업로드하고, 상기 학습 정보를 학습자 단말기에 전달할 수 있다. 또한, 본 발명의 실시 예에 따른 화상 학습 시스템을 이용한 화상 학습 방법에 있어서, 학습자에 의해 발화된 음성 신호를 수신하고, 수신된 음성 신호를 전처리하는 단계, 상기 전처리된 음성 신호로부터 학습자 고유의 음 성 특징 벡터를 추출하는 단계, 상기 학습자 음성으로부터 추출된 음성 특징 벡터를 기 구축된 학습모델에 입력 하여 학습자를 식별하는 단계, 그리고 상기 식별된 학습자의 학습 정보를 이용하여 매칭 가능한 원어민 강사를 추출하고, 추출된 원어민 강사에 대한 정보를 학습자 단말기에 제공하며, 상기 학습자 단말기로부터 특정 원어 민 강사에 대한 연결 요청 신호를 수신하면, 해당되는 원어민 강사 단말기에 수업 요청 신호를 전송하여 강사와 학습자를 연결시키는 단계를 포함한다."}
{"patent_id": "10-2021-0046631", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "이와 같이 본 발명에 따르면, 멀티 유저 환경에서 학습자의 음성 명령을 통한 학습자 식별을 가능하게 하며, 식 별된 학습자 개개인에 맞는 맞춤형 어학 학습을 제공할 수 있으므로 학습자의 학습 효율을 향상시킬 수 있다."}
{"patent_id": "10-2021-0046631", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하 첨부된 도면을 참조하여 본 발명에 따른 바람직한 실시 예를 상세히 설명하기로 한다. 이 과정에서 도면에 도시된 선들의 두께나 구성요소의 크기 등은 설명의 명료성과 편의상 과장되게 도시되어 있을 수 있다. 또한 후술되는 용어들은 본 발명에서의 기능을 고려하여 정의된 용어들로서, 이는 사용자, 운용자의 의도 또는 관례에 따라 달라질 수 있다. 그러므로 이러한 용어들에 대한 정의는 본 명세서 전반에 걸친 내용을 토대로 내 려져야 할 것이다. 이하에서는 본 발명의 실시예에 따른 화상 학습 시스템에 대해 더욱 구체적으로 설명한다. 도 1은 본 발명의 실시예에 따른 화상 학습 시스템을 설명하기 위한 구성도이다. 도 1에 도시된 바와 같이, 본 발명의 실시예에 따른 화상 학습 시스템은 매칭 서버, 학습자 단말기 및 원어민 강사 단말기를 포함한다. 먼저, 매칭 서버는 학습자 단말기로부터 수신된 학습자의 음성 신호에 따라 학습자를 식별한다. 그리 고 매치 서버는 식별된 학습자의 의도에 따라 원어민 강사를 매칭할 경우, 매칭 가능한 원어민 강사 정보 를 추출하고, 추출된 원어민 강사 정보를 학습자 단말기에 전달한다. 그 다음, 학습자 단말기로부터 연결 요청 신호를 수신하면, 매칭 서버는 수신된 연결 요청 신호에 따라 학습자와 원어민 강사를 매칭시켜 학습 자로 하여금 화상 학습을 수행하게 한다. 본 발명의 실시예에 따르면, 학습자는 단말기를 매칭 서버에서 제공하는 어학 학습이 가능한 앱 또는 웹페이지 접속한 상태에서 발화하고, 학습자로부터 발화된 음성을 인식한 학습자 단말기는 학습자의 음성 신호를 매칭 서버에 전달한다. 그러면, 매칭 서버는 학습이 완료된 학습 모델에 전달받은 음성 신호를 입력하여 학습자를 식별한다. 그리 고, 매칭 서버는 식별된 학습자의 학습 정보를 이용하여 매칭 가능한 복수의 원어민 강사 정보를 추출한다. 그 다음, 매칭 서버는 추출된 복수의 원어민 강사 정보를 학습자 단말기에 전달하고, 학습 자가 복수의 원어민 강사 중에서 어느 특정한 강사를 선택하면, 해당 되는 학습자 단말기와 원어민 강사 단말기를 연결하여 학습을 수행하게 하도록 한다 본 발명의 실시예에서 학습자 단말기 및 원어민 강사 단말기는 통신망을 통해 네트워크에 접속 가능 한 공지된 다양한 수단일 수 있다. 예를 들어 스마트 폰, 스마트 패드, 각종 모바일 기기, 노트북 등이 이에 해 당될 수 있다. 여기서, 학습자 단말기 및 원어민 강사 단말기에 대한 모바일 앱의 제공 정보 및 관리 권한은 사용자 속성에 따라 달리 주어지므로 모바일 앱의 구동 화면 역시 차별화된 형태로 제공되는 것은 자명 하다. 학습자 단말기 및 원어민 강사 단말기는 실질적으로 동일한 기능을 수행하는 단말기로서, 본 발명의 실시예에서는 설명의 편의상 단말기를 사용하는 주체에 따라 각각 다른 명칭으로 구별하기로 한다. 도 2는 도 1에 도시된 매칭 서버를 설명하기 위한 블록구성도이다. 도 2에 도시된 바와 같이, 본 발명의 실시예에 따른 매칭 서버는 음성 인식부, 특징 추출부, 식 별부, 학습부, 강사 정보 수집부 및 제어부를 포함한다. 먼저, 음성 인식부는 학습자 단말기로부터 발화된 음성 신호를 수신한다. 그 다음, 특징 추출부는 MFCC(Mel-Frequency Cepstrum Coefficient) 또는 LPC(Linear Predictive Coding) 알고리즘을 이용하여 음성 신호로부터 학습자마다 가지는 고유의 음성 특징 벡터를 추출한다. 그리고, 식별부는 수신된 음성 신호로부터 추출된 학습자 고유의 음성 특징 벡터를 학습이 완료된 학습모 델에 입력하여 학습자를 식별한다. 학습부는 GMM-UBM(Gaussian Mixture Model - Universal Background Model)의 학습모델을 구축하고, 구축 된 학습모델에 음성 특징 벡터를 입력하여 학습자를 식별하도록 학습시킨다. 부연하자면, 학습부는 추출한 음성 특징 벡터를 데이터셋으로 하여 GMM-UBM(Gaussian Mixture Model - Universal Background Model)의 학습 모델의 학습시킨다. 그리고, 강사 정보 수집부는 원어민 강사 단말기로부터 전달받은 원어민 강사명, 수업 가능 시간, 강 사 평가 정보를 포함하는 강사 정보를 수집한다. 마지막으로 제어부는 식별된 학습자 정보를 이용하여 학습자에 대응되며 현재 시점에서 학습 가능한 원어 민 강사를 추출한다. 그리고 제어부는 추출된 원어민 강사에 대한 정보를 학습자 단말기에 제공하고, 학습자 단말기로부터 특정 원어민 강사에 대한 연결 요청 신호를 수신하면, 해당되는 원어민 강사 단말기 에 수업 요청 신호를 전송하여 강사와 학습자를 연결시킨다. 이하에서는 도 3을 이용하여 본 발명의 실시예에 따른 화상 학습 시스템을 이용한 학습자와 원어민 강사를 매칭 하는 방법에 대해 더욱 상세하게 설명한다. 도 3은 본 발명의 실시예에 따른 화상 학습 시스템을 이용한 학습자와 원어민 강사의 매칭 방법을 설명하기 위 한 순서도이다. 도 3에 도시된 바와 같이, 본 발명의 실시예에 따르면, 매칭 서버는 복수의 학습자의 음성 신호를 수집하 고, 수집된 음성 신호를 이용하여 기 구축된 학습 모델을 학습시킨다(S310). 먼저, 특징 추출부는 MFCC(Mel-Frequency Cepstrum Coefficient) 또는 LPC(Linear Predictive Coding) 알 고리즘을 이용하여 복수의 학습자 단말기로부터 수신된 음성 신호로부터 각각의 음성 특징 벡터를 추출한 다. 그 다음, 학습부는 추출된 음성 특징 벡터를 이용하여 데이터셋을 생성하고, 생성된 데이터셋을 이용하여 GMM-UBM(Gaussian Mixture Model - Universal Background Model)의 학습모델을 학습시킨다. 자세히는, 학습부는 복수의 학습자로부터 획득한 음성 특징 벡터를 이용 배경 화자 모델을 구축하고, 일부 학습자로부터 획득한 음성 특징 벡터를 이용하여 적응 학습시킨다. 그러면, 학습모델은 복수의 배경 화자들 중 에서 특정한 화자를 식별할 수 있게 된다. S310단계가 완료되면, 음성 인식부는 학습자 단말기로부터 수신된 음성 신호를 인식한다(S320). 부연하자면, 학습자는 단말기를 이용하여 학습을 수행할 수 있는 앱 또는 웹페이지에 접속하고, 앱 또는 웹페이지를 실행시킨 상태에서 발화한다. 그러면, 학습자 단말기는 획득한 음성 신호를 매칭 서버에 전달한다. 학습자의 음성 신호를 수신한 음성 인식부는 음성 신호를 전처리한다. 그 다음, 특징 추출부는 전처리된 음성 신호로부터 학습자마다 고유한 음성 특징 벡터를 추출한다(S330). 부연하자면, 식별부는 MFCC(Mel-Frequency Cepstrum Coefficient) 또는 LPC(Linear Predictive Coding) 알고리즘을 이용하여 학습자의 음성 신호로부터 음성 특징 벡터를 추출한다. 그 다음, 매칭 서버는 학습자의 성향에 따라 온멘디드 형식으로 학습자와 원어민 강사를 연결하기 위하여 학습자의 음성 특징 벡터를 학습이 완료된 학습모델에 입력하여 학습자를 식별한다(S340). 부연하자면, 식별부는 추출된 음성 특징 벡터를 학습이 완료된 학습모델에 입력한다. 그러면, 학습모델은 입력된 음성 특징 벡터를 이용하여 복수의 학습자 중에서 해당되는 학습자를 식별한다. 그리고, 제어부는 식별된 학습자에 대응하여 학습 내역 및 선호 강사 유형에 대한 학습자 정보를 추출하고, 추출된 학습자 정보와 매칭되는 원어민 강사를 추출한다(S350). 자세히는, 제어부는 강사 정보 수집부로부터 연결 가능한 유휴 원어민 강사 정보를 획득한다. 그리고 제어부는 유휴 원어민 강사 중에서 학습자 정보와 매칭되는 복수의 원어민 강사를 추출하고, 추출된 복수 의 원어민 강사에 대한 정보는 학습자 단말기에 전달된다. S350단계를 완료하면, 학습자는 단말기를 통해 전달받은 복수의 원어민 강사에 대한 정보를 확인하고, 그 중에서 특정한 원어민 강사를 선택한다. 학습자 단말기는 선택된 원어민 강사에 대해 연결 요청 신호를 매 칭 서버에 전달한다. 그러면, 제어부는 해당 원어민 강사 단말기에 수업 요청 신호를 송신한다. 그리고, 해당되는 원어민 강사 단말기로부터 학습 가능 신호를 수신하면, 제어부는 식별된 학습자와 원어민 강사가 매칭된 것으로 판단하고, 매칭 완료 신호와 함께 온라인 어학 학습을 제공한다(S360). 학습이 완료되면 제어부는 학습 영상, 학습한 문장 및 학습 피드백 정보를 학습자의 학습 정보에 업로드하 고, 학습 정보를 학습자 단말기에 전달한다. 이와 같이 본 발명에 따른 화상 학습 시스템은 멀티 유저 환경에서 학습자의 음성을 통한 학습자 식별을 가능하 게 하며, 식별된 학습자 개개인에 맞는 맞춤형 어학 학습을 제공할 수 있으므로 학습자의 학습 효율을 향상시킬 수 있다. 본 발명은 도면에 도시된 실시 예를 참고로 하여 설명되었으나 이는 예시적인 것에 불과하며, 당해 기술이 속하 는 분야에서 통상의 지식을 가진 자라면 이로부터 다양한 변형 및 균등한 타 실시 예가 가능하다는 점을 이해할 것이다. 따라서 본 발명의 진정한 기술적 보호범위는 아래의 특허청구범위의 기술적 사상에 의하여 정해져야 할 것이다.부호의 설명 100 : 매칭 서버 110 : 음성 인식부 120 : 특징 추출부 130 : 식별부 140 : 학습부 150 : 강사 정보 수집부 160 : 제어부 200 : 학습자 단말기 300 : 원어민 강사 단말기"}
{"patent_id": "10-2021-0046631", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 실시예에 따른 화상 학습 시스템을 설명하기 위한 구성도이다. 도 2는 도 1에 도시된 매칭 서버를 설명하기 위한 블록구성도이다. 도 3은 본 발명의 실시예에 따른 화상 학습 시스템을 이용한 학습자와 강사의 매칭 방법을 설명하기 위한 순서 도이다."}
