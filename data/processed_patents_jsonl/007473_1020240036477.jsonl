{"patent_id": "10-2024-0036477", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0037225", "출원번호": "10-2024-0036477", "발명의 명칭": "이미지 안정화를 위한 프로세서 및 이를 포함하는 장치", "출원인": "주식회사 딥엑스", "발명자": "김녹원"}}
{"patent_id": "10-2024-0036477", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "인공지능 기반의 이미지 안정화를 위한 프로세서에 있어서,적어도 하나의 프로세싱 엘리먼트, 및 적어도 하나의 프로세싱 엘리먼트에 전기적으로 연결된 적어도 하나의 메모리를 포함하고,상기 프로세서는 떨림 감지 데이터를 획득하고, 상기 이미지의 흔들림을 보상하기 위한 안정화 데이터를 출력하도록 구성되고,상기 떨림 감지 데이터는 2개 이상의 센서로부터 획득되고,상기 안정화 데이터는 상기 떨림 감지 데이터에 기초하여 상기 안정화 데이터를 출력하도록 훈련된 인공 신경망모델을 이용하여 출력되는, 프로세서."}
{"patent_id": "10-2024-0036477", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 인공 신경망 모델은, 강화학습(Reinforcement Learning)을 기반으로 훈련되는, 프로세서."}
{"patent_id": "10-2024-0036477", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서, 상기 인공 신경망 모델에 대한 강화 학습을 위해 가상 떨림 감지 데이터가 제공되는, 프로세서."}
{"patent_id": "10-2024-0036477", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서, 상기 가상 떨림 감지 데이터는 앉는 패턴, 걷는 패턴, 달리는 패턴, 선박의 움직임 패턴, 자동차의 움직임패턴, 오토바이의 움직임 패턴 중 적어도 하나를 포함하는, 프로세서."}
{"patent_id": "10-2024-0036477", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서,상기 떨림 감지 데이터는 상기 2개 이상의 센서의 위치 변화를 감지하기 위한 신호를 포함하는, 프로세서."}
{"patent_id": "10-2024-0036477", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서, 상기 2개 이상의 센서는 자이로 센서 및 홀 센서를 포함하는, 프로세서.공개특허 10-2024-0037225-3-청구항 7 제1항에 있어서, 상기 떨림 감지 데이터는 상기 2개 이상의 센서의 x축 및 y축 회전 움직임에 의해 감지된 신호를 포함하는, 프로세서."}
{"patent_id": "10-2024-0036477", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1항에 있어서, 상기 인공 신경망 모델에 입력된 이미지의 디 포커스량 데이터를 더 획득하는, 프로세서."}
{"patent_id": "10-2024-0036477", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1항에 있어서, 상기 인공 신경망 모델은 학습용 학습 데이터를 기반으로 상기 이미지의 흔들림에 따른 오차 값이 기 설정된 값을 수렴하도록 사전 학습된 모델인, 프로세서."}
{"patent_id": "10-2024-0036477", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제1항에 있어서, 상기 인공 신경망 모델은,상기 떨림 감지 데이터가 입력되는 입력 노드, 상기 입력 노드의 인공지능 연산을 수행하는 히든 레이어 및 상기 안정화 데이터를 출력하는 출력 노드를 포함하는, 프로세서."}
{"patent_id": "10-2024-0036477", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제1항에 있어서, 중앙처리장치(CPU)와 신경망처리장치(NPU)가 집적된 시스템 온 칩(SoC)으로 구현된, 프로세서."}
{"patent_id": "10-2024-0036477", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제1항에 있어서, 중앙 처리 장치(CPU), 애플리케이션 프로세서(AP), 마이크로 처리 장치(MPU), 마이크로 컨트롤러 유닛(MCU), 이미지 신호 프로세서(ISP) 중 적어도 하나로 구현되는, 프로세서."}
{"patent_id": "10-2024-0036477", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "렌즈;상기 렌즈에 결합된 이미지 센서; 상기 렌즈 또는 상기 이미지 센서에 결합되는 적어도 2개 이상의 센서; 및상기 적어도 2개 이상의 센서로부터 상기 렌즈 또는 상기 이미지 센서에 대한 떨림 감지 데이터를 수신하여 학습된 인공 신경망 모델을 처리하여 안정화 데이터를 출력하는 프로세서를 포함하는, 장치.공개특허 10-2024-0037225-4-청구항 14 제13항에 있어서,상기 프로세서로부터 상기 안정화 데이터를 수신하여 제어 신호를 출력하는 VCM 드라이버(Voice Coil MotorDriver) 및상기 제어 신호를 이용하여 상기 렌즈 또는 상기 이미지 센서의 위치를 보상하는 VCM 액츄에이터(Voice CoilMotor Actuator)를 더 포함하는, 장치."}
{"patent_id": "10-2024-0036477", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제14항에 있어서,상기 VCM 드라이버는 변환식 또는 룩업 테이블을 이용하여 상기 안정화 데이터를 상기 제어 신호로 변환하도록구성되는, 장치."}
{"patent_id": "10-2024-0036477", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제14항에 있어서,상기 VCM 액츄에이터는 x축 및/또는 y축으로 상기 렌즈 또는 상기 이미지 센서의 위치를 제어하도록 구성되는,장치."}
{"patent_id": "10-2024-0036477", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "인공 지능 연산을 수행하기 위한 곱셈 및 누산 연산자 및/또는 산술 논리 연산자를 포함하는 복수의 프로세싱엘리먼트를 포함하고,이미지 및 떨림 감지 데이터를 수신하고, 상기 이미지의 흔들림을 보상하기 위한 안정화 데이터를 생성하도록구성되고,상기 안정화 데이터는 프로세서에 의해 훈련된 인공 신경망 모델에 의해 추론되는, 프로세서."}
{"patent_id": "10-2024-0036477", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제17항에 있어서,상기 인공 신경망 모델은 상기 떨림 감지 데이터 또는 가상 떨림 감지 데이터를 통해 학습되는, 프로세서."}
{"patent_id": "10-2024-0036477", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제17항에 있어서,상기 안정화 데이터를 추론하기 위해 온도 데이터 및 디포커스 양 데이터 중 적어도 하나를 더 수신하도록 구성되는, 프로세서."}
{"patent_id": "10-2024-0036477", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제17항에 있어서,공개특허 10-2024-0037225-5-VCM 액츄에이터(Voice Coil Motor Actuator)에 제어 신호를 출력하기 위해 상기 안정화 데이터는 VCM 드라이버(Voice Coil Motor Driver)에 입력되고상기 제어 신호는 상기 이미지의 흔들림을 보상하는 VCM 액츄에이터에 입력되는, 프로세서."}
{"patent_id": "10-2024-0036477", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "인공지능 기반의 이미지 안정화를 위한 프로세서는 적어도 하나의 프로세싱 엘리먼트, 및 적어도 하나의 프로세 싱 엘리먼트에 전기적으로 연결된 적어도 하나의 메모리를 포함하고, 프로세서는 떨림 감지 데이터를 획득하고, 상기 이미지의 흔들림을 보상하기 위한 안정화 데이터를 출력하도록 구성되고, 떨림 감지 데이터는 2개 이상의 센서로부터 획득되고, 안정화 데이터는 상기 떨림 감지 데이터에 기초하여 상기 안정화 데이터를 출력하도록 훈 련된 인공 신경망 모델을 이용하여 출력될 수 있다."}
{"patent_id": "10-2024-0036477", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 인공지능 기반 이미지 안정화를 위한 프로세서 및 장치에 관한 것이다."}
{"patent_id": "10-2024-0036477", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "카메라는 사람의 손떨림 현상에 의하여 촬영된 영상이 흔들리는 문제점을 해결하기 위해 손떨림을 보상하는 영 상 안정화 기술IS(Image Stabilizer, IS)이 적용된다. 이러한 영상 안정화 기술은 광학적 영상 안정화 기술(Optical Image Stabilizer, OIS)과 이미지 센서를 이용한 안정화 기술을 포함한다. OIS 기술이 적용된 카메라 모듈은 자이로 센서(Gyro sensor) 등과 같은 항법 센서를 통해서 떨림을 감지하고, 코일(coil)과 마그넷(magnet) 사이의 이격 변화를 감지하는 홀 센서(Hall sensor)를 이용하여 보상 신호를 생성 한다. 보상 신호를 기반으로 영상의 떨림을 안정화 한다. 특히, 카메라 모듈은 이미지 센서가 고정되고, 렌즈가 쉬프트(shift)되어 떨림을 보상하는 렌즈 쉬프트 방식과 이미지 센서와 렌즈가 동시에 회전(tilt)되어 떨림을 보상하는 카메라 회전 방식을 이용하여 떨림을 보상할 수 있다."}
{"patent_id": "10-2024-0036477", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "일반적으로 OIS 시스템은 렌즈와 이미지 센서가 함께 고정되는 OIS 시스템과 이미지 센서가 고정되는 OIS 시스 템을 포함할 수 있다. 구체적으로, 렌즈와 이미지 센서가 함께 고정되는 카메라-틸트 아키텍처(Camera-Tilt Architecture)방식의 OIS 시스템은 포토 센서 및 액츄에이터로 구성되고, 렌즈와 이미지 센서가 고정된 구조물을 동시에 틸트시켜 영상 떨림을 안정화 할 수 있다. 구체적으로, 센서가 고정되는 배럴-쉬프트 아키텍처(Barrel-Shift Architecture) 방식의 OIS 시스템은 액츄에이 터, 홀 센서(hall sensor) 및 마그넷으로 구성되고, 마그넷으로 렌즈를 쉬프트(shift)하여 영상 떨림을 안정화 할 수 있다. 이러한 OIS 시스템은 영상 떨림을 감지하는 센서들의 감지 신호를 기반으로 안정화 신호를 생성하는 간단한 피 드백 알고리즘을 이용하여 안정화를 수행한다. 이처럼 간단한 피드백 알고리즘을 이용하여 안정화를 수행하면 알고리즘의 성능에 제한이 있다는 사실을 본 개 시의 발명자는 인식하였다. 이에, 본 개시가 해결하고자 하는 과제는 영상 떨림을 보상하는 동작의 처리 속도를 극대화하고, 소비 전력을 저감할 수 있는 인공지능 기반 센서 보정 방법 및 이에 따른 카메라 모듈을 제공하는 것이다. 이에, 본 개시가 해결하고자 하는 과제는 영상 떨림을 보상하는 동작의 처리 속도를 극대화하고, 소비 전력을 저감할 수 있는 인공지능 기반 센서 보정 방법 및 이를 처리하는 프로세서를 제공하는 것이다. 이에, 본 개시가 해결하고자 하는 과제는, 인공지능 강화 학습을 통해서 다양한 사용 환경의 떨림 패턴을 보상 할 수 있는 인공지능 기반 센서 보정 방법 및 이를 처리하는 프로세서를 제공하는 것이다. 이에, 본 개시가 해결하고자 하는 과제는, 인공지능 학습을 통하여, 영상 떨림을 보상하는 동작의 처리 속도를 극대화하고, 소비 전력을 저감할 수 있는 인공지능 기반 센서 보정 방법 및 장치를 제공하는 것이다.이에, 본 개시가 해결하고자 하는 과제는, 특정한 패턴을 인공지능 학습을 통하여 학습하여, 영상 떨림을 보상 하는 동작의 처리 속도를 극대화하고, 소비 전력을 저감할 수 있는 인공지능 기반 센서 보정 방법 및 장치를 제 공하는 것이다. 단 본 개시는 이에 제한되지 않으며, 또 다른 과제들은 아래의 기재로부터 당업자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2024-0036477", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "전술한 바와 같은 과제를 해결하기 위하여 본 발명의 일 예시에 따른 프로세서 및 장치가 제공된다. 인공지능 기반의 이미지 안정화를 위한 프로세서는 적어도 하나의 프로세싱 엘리먼트, 및 적어도 하나의 프로세 싱 엘리먼트에 전기적으로 연결된 적어도 하나의 메모리를 포함하고, 프로세서는 떨림 감지 데이터를 획득하고, 상기 이미지의 흔들림을 보상하기 위한 안정화 데이터를 출력하도록 구성되고, 떨림 감지 데이터는 2개 이상의 센서로부터 획득되고, 안정화 데이터는 상기 떨림 감지 데이터에 기초하여 상기 안정화 데이터를 출력하도록 훈 련된 인공 신경망 모델을 이용하여 출력될 수 있다. 인공 신경망 모델은 강화학습(Reinforcement Learning)을 기반으로 훈련될 수 있다. 인공 신경망 모델에 대한 강화 학습을 위해 가상 떨림 감지 데이터가 제공될 수 있다. 가상 떨림 감지 데이터는 앉는 패턴, 걷는 패턴, 달리는 패턴, 선박의 움직임 패턴, 자동차의 움직임 패턴, 오 토바이의 움직임 패턴 중 적어도 하나를 포함할 수 있다. 떨림 감지 데이터는 2개 이상의 센서의 위치 변화를 감지하기 위한 신호를 포함할 수 있다. 2개 이상의 센서는 자이로 센서 및 홀 센서를 포함할 수 있다. 떨림 감지 데이터는 상기 2개 이상의 센서의 x축 및 y축 회전 움직임에 의해 감지된 신호를 포함할 수 있다. 프로세서는 인공 신경망 모델에 입력된 이미지의 디 포커스량 데이터를 더 획득할 수 있다. 인공 신경망 모델은 학습용 학습 데이터를 기반으로 상기 이미지의 흔들림에 따른 오차 값이 기 설정된 값을 수 렴하도록 사전 학습된 모델일 수 있다. 인공 신경망 모델은 떨림 감지 데이터가 입력되는 입력 노드, 상기 입력 노드의 인공지능 연산을 수행하는 히든 레이어 및 상기 안정화 데이터를 출력하는 출력 노드를 포함할 수 있다. 프로세서는 중앙처리장치(CPU)와 신경망처리장치(NPU)가 집적된 시스템 온 칩(SoC)으로 구현될 수 있다. 프로세서는 중앙 처리 장치(CPU), 애플리케이션 프로세서(AP), 마이크로 처리 장치(MPU), 마이크로 컨트롤러 유 닛(MCU), 이미지 신호 프로세서(ISP) 중 적어도 하나로 구현될 수 있다. 장치는 렌즈, 렌즈에 결합된 이미지 센서, 렌즈 또는 상기 이미지 센서에 결합되는 적어도 2개 이상의 센서 및 적어도 2개 이상의 센서로부터 상기 렌즈 또는 상기 이미지 센서에 대한 떨림 감지 데이터를 수신하여 학습된 인공 신경망 모델을 처리하여 안정화 데이터를 출력하는 프로세서를 포함할 수 있다. 장치는 상기 프로세서로부터 상기 안정화 데이터를 수신하여 제어 신호를 출력하는 VCM 드라이버(Voice Coil Motor Driver) 및 제어 신호를 이용하여 상기 렌즈 또는 상기 이미지 센서의 위치를 보상하는 VCM 액츄에이터 (Voice Coil Motor Actuator)를 더 포함할 수 있다. VCM 액츄에이터는 x축 및/또는 y축으로 상기 렌즈 또는 상기 이미지 센서의 위치를 제어하도록 구성될 수 있다. 프로세서는 인공 지능 연산을 수행하기 위한 곱셈 및 누산 연산자 및/또는 산술 논리 연산자를 포함하는 복수의 프로세싱 엘리먼트를 포함하고, 이미지 및 떨림 감지 데이터를 수신하고, 상기 이미지의 흔들림을 보상하기 위 한 안정화 데이터를 생성하도록 구성되고, 안정화 데이터는 프로세서에 의해 훈련된 인공 신경망 모델에 의해 추론될 수 있다. 인공 신경망 모델은 상기 떨림 감지 데이터 또는 가상 떨림 감지 데이터를 통해 학습될 수 있다. 안정화 데이터를 추론하기 위해 온도 데이터 및 디포커스 양 데이터 중 적어도 하나를 더 수신하도록 구성될 수 있다.VCM 액츄에이터(Voice Coil Motor Actuator)에 제어 신호를 출력하기 위해 상기 안정화 데이터는 VCM 드라이버 (Voice Coil Motor Driver)에 입력되, 상기 제어 신호는 상기 이미지의 흔들림을 보상하는 VCM 액츄에이터에 입 력될 수 있다."}
{"patent_id": "10-2024-0036477", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 명세서 또는 출원에 개시되어 있는 본 개시의 개념에 따른 실시 예들에 대해서 특정한 구조적 내지 단계적 설명들은 단지 본 개시의 개념에 따른 실시 예를 설명하기 위한 목적으로 예시된 것이다. 본 개시의 개념에 따른 실시 예들은 다양한 형태로 실시될 수 있으며 본 개시의 개념에 따른 실시 예들은 다양 한 형태로 실시될 수 있으며 본 명세서 또는 출원에 설명된 실시 예들에 한정되는 것으로 해석되어서는 아니 된 다. 본 개시의 개념에 따른 실시 예는 다양한 변경을 가할 수 있고 여러 가지 형태를 가질 수 있으므로 특정 실시 예들을 도면에 예시하고 본 명세서 또는 출원에 상세하게 설명하고자 한다. 그러나, 이는 본 개시의 개념에 따 른 실시 예를 특정한 개시 형태에 대해 한정하려는 것이 아니며, 본 개시의 사상 및 기술 범위에 포함되는 모든 변경, 균등물 내지 대체물을 포함하는 것으로 이해되어야 한다. 제 1 및/또는 제 2 등의 용어는 다양한 구성 요소들을 설명하는데 사용될 수 있지만, 상기 구성 요소들은 상기 용어들에 의해 한정되어서는 안 된다. 상기 용어들은 하나의 구성 요소를 다른 구성 요소로부터 구별하는 목적으로만, 예컨대 본 개시의 개념에 따른 권리 범위로부터 이탈되지 않은 채, 제 1 구성요소는 제 2 구성요소로 명명될 수 있고, 유사하게 제 2 구성요소 는 제 1 구성요소로도 명명될 수 있다. 어떤 구성요소가 다른 구성요소에 \"연결되어\" 있다거나 \"접속되어\" 있다고 언급된 때에는, 그 다른 구성요소에 직접적으로 연결되어 있거나 또는 접속되어 있을 수도 있지만, 중간에 다른 구성요소가 존재할 수도 있다고 이 해되어야 할 것이다. 반면에, 어떤 구성요소가 다른 구성요소에 \"직접 연결되어\" 있다거나 \"직접 접속되어\" 있 다고 언급된 때에는, 중간에 다른 구성요소가 존재하지 않는 것으로 이해되어야 할 것이다. 구성요소들 간의 관계를 설명하는 다른 표현들, 즉 \"~사이에\"와 \"바로 ~사이에\" 또는 \"~에 이웃하는\"과 \"~에 직 접 이웃하는\" 등도 마찬가지로 해석되어야 한다. 본 문서에서, \"A 또는 B,\" \"A 또는/및 B 중 적어도 하나,\" 또는 \"A 또는/및 B 중 하나 또는 그 이상\" 등의 표현 은 함께 나열된 항목들의 모든 가능한 조합을 포함할 수 있다. 예를 들면, \"A 또는 B,\" \"A 및 B 중 적어도 하나,\" 또는 \"A 또는 B 중 적어도 하나\"는, 적어도 하나의 A를 포함, 적어도 하나의 B를 포함, 또는 적어도 하나의 A 및 적어도 하나의 B 모두를 포함하는 경우를 모두 지칭할 수 있다. 본 문서에서 사용된 \"제 1,\" \"제 2,\" \"첫째,\" 또는 \"둘째,\" 등의 표현들은 다양한 구성요소들을, 순서 및/또는 중요도에 상관없이 수식할 수 있고, 한 구성요소를 다른 구성요소와 구분하기 위해 사용될 뿐 해당 구성요소들 을 한정하지 않는다. 예를 들면, 제 1 사용자 기기와 제 2 사용자 기기는, 순서 또는 중요도와 무관하게, 서로 다른 사용자 기기를 나타낼 수 있다. 예를 들면, 본 문서에 기재된 권리범위를 벗어나지 않으면서 제 1 구성요소는 제 2 구성요소로 명명될 수 있고, 유사하게 제 2 구성요소도 제 1 구성요소로 바꾸어 명명될 수 있다. 본 문서에서 사용된 용어들은 단지 특정한 실시 예를 설명하기 위해 사용된 것으로, 다른 예시의 범위를 한정하 려는 의도가 아닐 수 있다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함할 수 있다. 기술적이거나 과학적인"}
{"patent_id": "10-2024-0036477", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "용어를 포함해서 여기서 사용되는 용어들은 본 문서에 기재된 기술분야에서 통상의 지식을 가진 자에 의해 일반 적으로 이해되는 것과 동일한 의미를 가질 수 있다. 본 문서에 사용된 용어들 중 일반적인 사전에 정의된 용어들은, 관련 기술의 문맥상 가지는 의미와 동일 또는 유사한 의미로 해석될 수 있으며, 본 문서에서 명백하게 정의되지 않는 한, 이상적이거나 과도하게 형식적인 의 미로 해석되지 않는다. 경우에 따라서, 본 문서에서 정의된 용어일지라도 본 문서의 실시 예들을 배제하도록 해 석될 수 없다. 본 명세서에서 사용한 용어는 단지 특정한 실시 예를 설명하기 위해 사용된 것으로, 본 개시를 한정하려는 의도 가 아니다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 명세서에서, \"포함하다\" 또는 \"가지다\" 등의 용어는 서술된 특징, 숫자, 단계, 동작, 구성요소, 부분품 또는 이들을 조합한 것이 존재함 을 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성요소, 부분품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되어야 한다. 다르게 정의되지 않는 한, 기술적이거나 과학적인 용어를 포함해서 여기서 사용되는 모든 용어들은 본 개시가 속하는 기술 분야에서 통상의 지식을 가진 자에 의해 일반적으로 이해되는 것과 동일한 의미를 가지고 있다. 일반적으로 사용되는 사전에 정의되어 있는 것과 같은 용어들은 관련 기술의 문맥상 가지는 의미와 일치하는 의 미를 가지는 것으로 해석되어야 하며, 본 명세서에서 명백하게 정의하지 않는 한, 이상적이거나 과도하게 형식 적인 의미로 해석되지 않는다. 본 발명의 여러 예시들의 각각 특징들이 부분적으로 또는 전체적으로 서로 결합 또는 조합 가능하며, 당업자가 충분히 이해할 수 있듯이 기술적으로 다양한 연동 및 구동이 가능하며, 각 예시들이 서로에 대하여 독립적으로 실시 가능할 수도 있고 연관 관계로 함께 실시 가능할 수도 있다. 실시 예를 설명함에 있어서 본 개시가 속하는 기술 분야에 익히 알려져 있고 본 개시와 직접적으로 관련이 없는 기술 내용에 대해서는 설명을 생략한다. 이는 불필요한 설명을 생략함으로써 본 개시의 요지를 흐리지 않고 더 욱 명확히 전달하기 위함이다. 이하, 첨부한 도면을 참조하여 본 개시의 바람직한 실시 예를 설명함으로써, 본 개시를 상세히 설명한다. 이하, 본 개시의 실시 예를 첨부된 도면을 참조하여 상세하게 설명한다. 도 1은 본 개시의 일 예시에 따른 카메라 모듈이 포함된 장치를 설명하는 개략적인 개념도이다. 도 1을 참조하면 장치(A)는 카메라 모듈을 포함할 수 있다. 장치(A)는 카메라 모듈, 프로세서 및 제1 메모리를 포함할 수 있다, 다양한 예시에 따르면, 장치(A)는 제1 메모리와 구분된 제2 메모리를 더 포함하도록 구성될 수 있다. 즉, 장치(A)는 제2 메모리를 선택적으로 포함하거나 또는 배제하도록 구성될 수 있다. 카메라 모듈은 영상을 촬영하는 유닛으로, 떨림을 감지하고, 이를 보상하기 위한 OIS 시스템을 포함할 수 있다. 예를 들어, OIS 시스템은 떨림을 감지하기 위한 적어도 둘 이상의 센서 및 떨림을 보상하기 위한 보상 유 닛들을 포함할 수 있다. 특히, OIS 시스템은 연산 장치인 프로세서를 포함할 수 있다. 프로세서는 다양하게 변형실시 될 수 있다. 예를 들어, 프로세서는 CPU(Central Processing Unit)나 AP(Application Processor)와 같은 연산 장치일 수 있다. 예를 들어, 프로세서는 MPU(Micro Processing Unit)와 같은 연산 장치 일 수 있다. 예를 들어, 프로세서는 MCU(Micro Controller Unit)와 같은 연산 장치 일 수 있다. 예를 들어, 프로세서는 NPU(Neural Processing Unit)와 같은 연산 장치 일 수 있다. 예를 들어, 프로세서는 ISP(Image Signal Processor)와 같은 연산 장치 일 수 있다. 예를 들어, 프로세서는 CPU와 NPU와 같은 다양한 연산 장치가 통합된 SoC(System on Chip)일 수 있다. 예를 들어, 프로세서는 상술한 연산 장치들이 통합 칩(Integrated Chip (IC))의 형태로 구현될 수 있다. 단, 본 개시의 예시들은 프로세서에 한정되지 않는다. 프로세서는 카메라 모듈, 제1 메모리와 동작 가능하게 통신할 수 있다. 추가적으로 프로세서 는 제2 메모리와 동작 가능하게 통신할 수 있다. 프로세서는 CPU나 AP와 같은 연산 장치에 해당할 수 있다. 또한, 프로세서는 CPU, GPU, NPU와 같은 다양한 연산 장치가 통합된 SoC와 같은 통합 칩의 형태로 구현될 수 있다. 다양한 예시에서 프로세서는 OIS 시스템의 연산 장치로서 동작할 수도 있다. * 프로세서는 카메라 모듈의 출력 영상인 베이어 패턴(bayer patten)을 입력 받아 RGB 입력 영상 또는 YUV 입력으로 변환된 데이터를 출력하는 ISP와 CPU 같은 다양한 연산 장치가 통합된 통합 칩의 형태로 구현될 수 있 다. 즉, 본 개시의 예시들에 따른 프로세서는 전용 프로세서 및/또는 통합 된 이종의 프로세서들을 지칭할 수 있다. 카메라 모듈은 프로세서와 통합된 통합 칩의 형태로 구현되는 것도 가능하다. 제1 메모리는 반도체 다이에 실장된 메모리로 온칩 영역(A)에서 처리되는 데이터를 캐싱하거나 또는 저장 하기 위한 메모리일 수 있다. 제1 메모리는 ROM, SRAM, DRAM, Resistive RAM, Magneto-resistive RAM, Phase-change RAM, Ferroelectric RAM, Flash Memory, HBM 등과 같은 메모리 중 하나의 메모리를 포함할 수 있 다. 제1 메모리는 적어도 하나의 메모리 유닛으로 구성될 수 있다. 제1 메모리는 단일 (homogeneous) 메모리 유닛 또는 이종(heterogeneous) 메모리 유닛으로 구성될 수 있다. 제1 메모리는 내부 메모리 또는 온-칩 메모리로 구성될 수 있다. 제2 메모리는 ROM, SRAM, DRAM, Resistive RAM, Magneto-resistive RAM, Phase-change RAM, Ferroelectric RAM, Flash Memory, HBM 등과 같은 메모리 중 하나의 메모리를 포함할 수 있다. 제2 메모리 는 적어도 하나의 메모리 유닛으로 구성될 수 있다. 제2 메모리는 단일 메모리 유닛 또는 이종 메 모리 유닛으로 구성될 수 있다. 제2 메모리는 메인 메모리 또는 오프-칩 메모리로 구성될 수 있다. 이하에서는 도 2를 참조하여 카메라 모듈에 대해서 구체적으로 설명한다. 도 2는 본 개시의 일 예시에 따른 카메라 모듈을 설명하는 개략적인 개념도이다. 도 2를 참조하면, 카메라 모듈은 렌즈, 이미지 센서, 제1 센서, VCM 드라이버(Voice Coil Motor Driver), 프로세서 및 VCM 액츄에이터(Actuator)를 포함할 수 있다. 단, 도 1에 도시되었듯이, 프로세서는 카메라 모듈에 포함되거나 또는 카메라 모듈외부에 배 치되도록 구성되는 것도 가능하다. 즉, 도 2의 프로세서는 카메라 모듈에서 배제되고, 프로세서 는 외부에서 카메라 모듈과 통신하도록 구성될 수 있다. 렌즈는 사물에서 들어오는 광을 모으거나 발산시키면서 광학적인 상을 맺도록 구성된다. 이미지 센서(11 0)는 렌즈를 통해서 들어온 광을 디지털 신호로 변환하는 소자로서, CCD(Charge Coupled Device) 센서 또는 CMOS(Complementary Metal Oxide Semi-conductor) 등을 포함할 수 있다. 제1 센서는 카메라 모듈 또는 장치(A)의 떨림을 감지하기 위한 센서이다. 제1 센서는 자이로 센서 등과 같이 물체의 회전 속도를 측정하는 각속도 센서일 수 있다. 다시 말해서, 제1 센서를 통해서 획 득된 이동 신호는 제1 센서의 x축 이동 및 y축 이동에 대한 정보를 포함할 수 있다. VCM 드라이버는 렌즈의 위치를 올바르게 조정하기 위해 VCM 액츄에이터로 제어 신호를 전달하도 록 구성될 수 있다. VCM 액츄에이터는 렌즈 홀더, 마그넷, 제2 센서, 코일 홀더 및 코일을 포함할 수 있다. 구체적으로, 렌즈 홀더는 렌즈가 실장되도록 구성되고, 마그넷은 자기력을 이용하여 렌즈 의 위치를 조정하도록 구성될 수 있다. 제2 센서는 VCM 액츄에이터의 떨림을 감지하기 위한 센서로서, OIS 코일과 마그넷 사이의 이격 변화를 감지하기 위한 홀 센서일 수 있다. 코일 홀더는 OIS 코일이 실장되도록 구성되고, OIS 코일은 마그넷과 대향 배치되어 마그넷 의 자력을 제어하도록 구성될 수 있다. 프로세서는 렌즈, 이미지 센서, 제1 센서, VCM 드라이버(Voice Coil Motor Driver) 및 VCM 액츄에이터(Actuator)와 동작 가능하도록 연결되어 카메라 모듈의 전반적인 동작을 수행할 수 있다. 특히, 프로세서는 인공신경망을 기반으로 떨림을 보상하기 위한 동작을 수행하도록 구성될 수 있다. 구체적으로, 프로세서는 카메라 모듈에 포함된 적어도 둘 이상의 센서(즉, 제1 센서 및 제2 센 서)로부터 이동 신호(즉, 떨림 감지 신호)를 각각 획득한다. 프로세서는 획득된 각각의 이동 신호에 기반하여 영상 떨림을 보상하기 위한 보상 신호를 추론하도록 학습된 인공신경망 모델을 이용하여 추론된 보상 신호를 생성할 수 있다. 프로세서가 추론한 보상 신호에 기반하여 영상 떨림을 보정할 수 있다. 여기서, 이동 신호는 자이로 센서의 x축 값 및 y축 값과 함께 홀 센서의 x축 값 및 y축 값을 포함할 수 있다. 나아가, 프로세서는 내부 메모리(미도시)를 더 포함하고, 영상 떨림을 보상하기 위해 이용되는 다양한 데 이터를 저장할 수 있다. 본 개시의 다양한 예시에 따라 카메라 모듈은 NPU 및 NPU 메모리를 포함하는 엣지 디바이스로 구현될 수 있다. 이하에서는 프로세서에서 인공신경망 모델을 이용하여 영상 떨림을 보상하기 위한 방법을 도 3 내지 도 6 을 참조하여 상세하게 설명하기로 한다. 도 3은 본 개시의 일 예시에 따른 인공신경망 모델을 설명하는 개략적인 개념도이다. 도 3을 참조하면, 인공신경망 모델은 제1 센서를 통해서 획득된 카메라 모듈의 이동 신호 및 제2 센서를 통해서 획득된 렌즈의 이동 신호를 포함하는 떨림 감지 데이터가 입력 데이터로서 입력된다. 부연 설명하면, 이미지 센서는 카메라 모듈에 고정되기 때문에, 제1 센서를 통해서 카메라 모 듈의 떨림을 감지하면, 실질적으로 이미지 센서의 떨림을 감지할 수 있게 된다. 따라서 카메라 모듈의 떨림을 감지하여 이미지 센서의 떨림을 실질적으로 감지할 수 있다. * 부연 설명하면, 렌즈는 렌즈 홀더에 고정되기 때문에, 제2 센서를 통해서 렌즈 홀더의 떨 림을 감지하면, 실질적으로 렌즈의 떨림을 감지할 수 있게 된다. 따라서, 렌즈 홀더의 떨림을 감지하 여 렌즈의 떨림을 실질적으로 감지할 수 있다. 여기서, 떨림 감지 데이터는, 예를 들어 카메라 모듈에 관한 x축의 회전각 및 y축의 회전각과, VCM 액츄 에이터에 관한 x축의 회전각 및 y축 회전각을 포함할 수 있다. 상술하였듯이, VCM 액츄에이터의 떨림 감지 데이터는 실질적으로 렌즈의 떨림 감지 데이터를 의미하 게 된다. 또한 도 2에서 카메라 모듈에 렌즈가 포함된 것으로 도시 되었지만, 이는 카메라 모듈에서의 렌즈의 기능을 고려한 것일 뿐이며, 렌즈는 렌즈 홀더에 고정된 것으로 이해되어야 한다. 본 개시의 예시에서, 인공신경망 모델은 떨림 감지 데이터를 입력 받아 영상 떨림을 보상하기 위한 안정화 데이터를 추론하고, 추론된 안정화 데이터를 출력할 수 있다. VCM 드라이버는 추론된 안정화 데이터를 입력 받아 렌즈의 떨림을 안정화 하기 위한 제어 신호 를 출력할 수 있다. 예를 들어, 인공신경망 모델은 안정화 데이터를 제어 신호로 변환하기 위한 변환 유닛을 더 포함하고, 변환 유닛을 통해 안정화 데이터가 제어 신호로 변환되어 출력될 수 있다. 본 개시의 다양한 예시에 따라 안정화 데이터는 VCM 드라이버가 추론된 안정화 데이터를 기반으 로 이미지 센서의 위치를 보상하도록 제어하기 위한 제어 신호로서 출력될 수 있다. 본 개시의 예시에서 안정화 데이터는 렌즈 및 이미지 센서의 위치를 보상하기 위한 제어 신호로서 출력될 수도 있다. 본 개시의 예시에서, 인공신경망 모델은 강화학습으로 학습될 모델일 수 있다. 예를 들면, 인공신경망 모델은 RNN, CNN, DNN, MDP, DP, MC, TD(SARSA), QL, DQN, PG, AC, A2C, A3C 등의 모델일 수 있다. 단, 본 개시는 이에 제한되지 않으며, 떨림 감지 데이터를 입력으로 하여 위치 보상 데이터를 추론하기 위해 학 습된 다양한 인공신경망 모델일 수 있다. 본 개시의 다양한 예시에 따른 인공신경망 모델은 복수개의 인공신경망 모델 중 선택된 모델일 수 있다. 복수개의 인공신경망 모델은 후술하는 Actor model을 의미한다. 이하에서는 인공신경망 모델의 학습 방법에 대해서 도 4를 참조하여 상세하게 설명하기로 한다. 도 4는 본 개시의 일 예시에 따른 인공신경망 모델의 학습 방법을 설명하는 개략적인 개념도이다. 제시된 예시 에서는 인공신경망 모델을 Actor-Critic 등과 같은 강화학습을 기반으로 하는 모델로 가정하여 설명한다. 특히, 후술하는 동작들은 프로세서를 통해서 수행될 수 있다. 도 4를 참조하면, 인공신경망 모델은 주어진 환경(Environment) 또는 상태(State)에서 최적의 행동 (Action)을 선택하도록 학습될 수 있다. 여기서, 인공신경망 모델은 Actor-Critic 알고리즘을 기반으로 할 수 있다. 이러한 인공신경망 모델 은 주어진 환경에서 상태(S)가 주어졌을 때 행동(Action)을 결정하는 제1 모델(Actor model)과 상태(S)의 가치 를 평가하는 제2 모델(Critic)을 포함한다. 주어진 환경은 현재 상태(St), 다음으로 선택 가능한 상태(St+1), 어떤 상태에서 취할 수 있는 행동(a) 및 어떤 상태에서 한 행동에 대한 보상(r) 및 어떤 상태에서 특정 행동을 취할 확률인 정책(policy)을 포함할 수 있다. 구체적으로, 센서를 통해서 카메라 모듈에 대한 제1 이동 신호(θYaw, θPitch) 및 렌즈에 대 한 제2 이동 신호(θHSx, θHSy)가 획득된다. 여기서, 제1 이동 신호(θYaw, θPitch)는 제1 센서로부터획득되고, 제2 이동 신호(θHSx, θHSy)는 제2 센서로부터 획득될 수 있다. 예를 들어, 제1 이동 신호(θYaw, θPitch)는 카메라 모듈에 대한 x축 회전각(θPitch) 및 y축 회전각(θ Yaw)을 포함한다. 예를 들어, 제2 이동 신호(θHSx, θHSy)는 렌즈에 대한 x축 회전각(θHSx) 및 y축 회전각(θHSy)을 포함 할 수 있다. 여기서 제1 이동 신호(θYaw, θPitch)는 실질적으로 이미지 센서의 떨림을 감지하는 신호이다. 제2 이동 신호(θHSx, θHSy)는 실질적으로 렌즈의 떨림을 감지하는 신호이다. 프로세서는 획득된 떨림 감지 데이터(θYaw, θPitch, θHSx, θHSy)를 이용하여 현재 상태(St), 다음 상 태(St+1), 행동(at) 보상(rt+1) 및 정책(policy)을 포함하는 환경 데이터를 결정하여 배치 메모리에 저장할 수 있다. 여기서, 배치 메모리는 인공신경망 모델을 배치 데이터(batch)로 학습시키기 위해 환경 데이터를 저 장하는 메모리일 수 있다. 현재 상태(St)에 대한 데이터는 현재 획득된 떨림 감지 데이터(θYaw, θPitch, θHSx, θHSy)를 의미하고, 다 음 상태(St+1)에 대한 데이터는 현재 상태에 대하여 행동을 취한 후에 획득되는 떨림 감지 데이터를 의미할 수 있다. 행동(at)에 대한 데이터는 떨림 감지 데이터(θYaw, θPitch, θHSx, θHSy)에 기반하여 추론할 수 있는 렌즈의 안정화 데이터(+Xaxis, -Xaxis, +Yaxis, -Yaxis)를 의미하고, 보상(rt+1)에 대한 데이터는 카메라 모듈에 대한 x축 회전각(θPitch)과 렌즈에 대한 x축 회전각(θHSx) 사이의 차이값과, 카메라 모듈 에 대한 y축 회전각(θYaw)과 렌즈에 대한 y축 회전각(θHSy) 사이의 차이값을 기반으로 하는 에러 값을 의미한다. 이어서, 배치 메모리부터 현재 상태(St) 및 다음 상태(St+1)에 관한 데이터가 인공신경망 모델의 제1 모델 (Actor model) 및 제2 모델(Critic model) 각각에 학습 데이터로서 입력된다. 프로세서는 이를 바탕으로 보상(rt+1)을 최대로 하는 정책(즉, 행동)을 결정하도록 인공신경망 모델을 학습시킨다. 여기서, 보상(rt+1)을 최대로 하는 정책(즉, 행동)은 에러값이 기 설정된 값을 수렴하는 안정화 데 이터를 의미할 수 있다. 예를 들어, 기 설정된 값은 '0'일 수 있다. 본 개시에서 에러값이 '0'을 수렴하는 경우 떨림이 없다고 판단될 수 있다. 구체적으로, 제1 모델(Actor model)은 입력된 떨림 감지 데이터(θYaw, θPitch, θHSx, θHSy)에 기반하여 안 정화 데이터를 추론한다. 제1 모델(Actor model)은 추론된 안정화 데이터를 기반으로 렌즈의 위치를 보상 했을 때 에러값이 기 설정된 값을 수렴할 확률을 결정한다. 제2 모델(Critic model)은 제1 모델(Actor model)이 입력된 떨림 감지 데이터(θYaw, θPitch, θHSx, θHSy) 에 기반하여 추론된 안정화 데이터에 대한 가치를 평가한다. 가치에 대한 평가 결과는 제1 모델(Actor model)에 전달되어 제1 모델(Actor model)이 추후 행동을 결정하는데 이용될 수 있다. 학습 단계에서 떨림 감지 데이터는 다양한 형태로 제공되는 것이 가능하다. 예를 들면, 강화 학습을 위한 카메라 모듈을 특정 지그(jig)에 고정시키고 지그가 특정 패턴으로 움직이 도록 프로그래밍 할 수 있다. 예를 들면, 강화 학습을 위한 카메라 모듈을 적어도 한 명의 사용자가 들고 특정 시간동안 움직일 수 있 다. 예를 들면, 강화 학습을 위해서, 가상의 떨림 감지 데이터를 제공할 수 있다. 여기서 특정 패턴은 앉기, 걷기, 뛰기, 선박의 동작, 자동차의 동작, 오토바이의 동작 등 일 수 있다. 강화 학습 기간 동안, 적어도 하나의 특정 패턴이 적용될 수 있다. 강화 학습 기간 동안, 적어도 하나의 특정 패턴이 순차적으로 또는 무작위로 적용 될 수 있다. 제1 모델(Actor model)를 통해 추론된 안정화 데이터는 VCM 드라이버로 전달되고, VCM 드라이버는 VCM 액츄에이터의 떨림을 보상하기 위한 제어 신호를 VCM 액츄에이터로 전달한다. 본 개시에서 안정화 데이터는 VCM 드라이버가 VCM 액츄에이터를 제어하도록 VCM 드라이버에 입 력 가능한 전압(Vx, Vy)으로 변환되어 전달될 수 있다. 이러한 전압(Vx, Vy)을 수신한 VCM 드라이버는 VCM 액츄에이터를 x축과 y축으로 제어하기 위한 제어 신호를 VCM 액츄에이터로 전달한다. 여기서, 제어 신호는 VCM 액츄에이터를 x축으로 제어하기 위한 전류(cx) 및 VCM 액츄에이터를 y축으로 제어하기 위한 전류(cy)를 포함할 수 있다. 이러한 전류(cx, cy)를 수신한 VCM 액츄에이터에 의해 렌즈의 위치가 보상됨으로써, 영상 떨림을 보상할 수 있다. 다음 단계에서 센서를 통해 떨림 감지 데이터가 획득되고, 상술한 학습 동작들이 반복적으로 수행될 수 있 다. 이러한 학습 동작들은 성공 기준 또는 최대 에피소드 수에 도달할 때까지 수행될 수 있으나, 이에 한정되지 않는다. 예를 들어, 성공 기준은 추론된 안정화 데이터에 기반하여 결정된 에러값이 '0'을 수렴하는 기준을 포 함할 수 있다. 본 개시의 다양한 예시에 따라 프로세서는 학습 동작 동안 획득된 에러 값을 수집하고, 수집된 에러 값을 이용하여 인공신경망 모델을 추가 학습함으로써, 인공신경망 모델을 업데이트할 수 있다. 본 개시의 다양한 예시에 따라 프로세서는 영상의 MTF 데이터를 획득하고, 획득된 MTF 데이터를 기반으로 제2 모델(Critic model)을 학습시킬 수 있다. 본 개시의 다양한 예시에 따른 제1 모델(Actor model)은 강화학습을 통해 커스터마이징(customizing)될 수 있다. 이하에서는 상술한 인공신경망 모델의 구체적인 학습 동작에 대해서 도 5를 참조하여 상세하게 설명하기로 한다. 도 5는 본 개시의 일 예시에 따른 인공신경망 모델의 구체적인 학습 동작을 설명하는 개략적인 개념도이다. 도 5를 참조하면, 제1 모델 및 제2 모델 각각은 현재 획득된 떨림 감지 데이터(θYaw, θPitch, θ HSx, θHSy)(st) 및 현재 상태에 대하여 행동을 취한 후에 획득되는 떨림 감지 데이터(st+1)를 학습 데이터로서 입력받는다. 제1 모델은 떨림 감지 데이터(st, st+1)를 입력으로 하여 행동(Action) 및 정책(Policy)을 출력한다. 여기 서, 행동(Action)은 추론된 안정화 데이터를 의미하고, 정책(Policy)은 현재 상태 St에서 행동 at를 취할 확률 πθ(at|St) 및 Batch로 업데이트되기 전 제1 모델의 현재 상태 St에서 행동 at를 취할 확률 πθold(at|St)을 포함한다. 제2 모델은 떨림 감지 데이터(st, st+1)를 입력으로 하여 떨림 감지 데이터(st, st+1)에 대한 가치 Vυ(St), V υ(St+1) 및 출력된 가치 Vυ(St), Vυ(St+1)에 대한 예상 이익(advantage) 을 출력한다. 여기서, 가치 Vυ (St)는 현재 상태인 떨림 감지 데이터(st)에 대한 가치를 의미하고, 가치 Vυ(St+1)는 다음 상태인 떨림 감지 데이 터(st+1)에 대한 가치를 의미한다. 제1 모델은 πθ(at|St), πθold(at|St) 및 제2 모델의 출력인 를 기반으로 손실 를 결 정할 수 있다. 여기서, θ는 제1 모델의 모든 가중치 및 바이어스 등을 나타내는 파라미터 벡터를 의미할 수 있다. 손실 는 하기의 [수학식 1]로 나타낼 수 있다. 수학식 1 여기서, 는 를 의미하고, 는 를 의미할 수 있다. 이어서, r은 보상을 의미하고, γ는 할인 요인을 의미한다. 제1 모델은 상술한 손실 를 이용하여 제1 모델의 파리미터 벡터 θ를 업데이트할 수 있다. 제2 모델은 가치 Vυ(St), Vυ(St+1)를 이용하여 손실 을 결정할 수 있다. 여기서, υ는 제2 모델(51 0)의 파라미터 벡터를 의미할 수 있다. 손실 는 하기의 [수학식 2]로 나타낼 수 있다. 수학식 2"}
{"patent_id": "10-2024-0036477", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "제2 모델은 상술한 손실 을 이용하여 제2 모델의 파라미터 벡터 υ를 업데이트할 수 있다. 제1 모델로부터 전달된 행동(Action)인 추론된 안정화 데이터는 변환 유닛을 통해 VCM 드라이버(13 0)에서 입력 가능한 전압(vx, vy)으로 변경된다. 예를 들어, 안정화 데이터는 VCM 드라이버를 제어하기 위 한 아날로그 전압 또는 디지털 신호로 변환될 수 있다. 이러한 변환 유닛에서 출력되는 전압이 스위칭 될 때, 오버 슈팅(overshooting) 또는 링잉(ringing) 현상이 발생될 수 있다. 이러한 문제점을 해결하기 위해 변환 유닛은 전압이 슬로프되어 출력되도록 학습된 인공신경망 모델을 이용할 수 있다. VCM 드라이버는 VCM 액츄에이터가 렌즈의 위치를 보상하도록 제어 신호(cx, cy)를 전달하고, 이후 동 작은 도 4에서 서술한 바와 같이 학습 동작이 수행될 수 있다. 이하에서는 도 4 및 도 5에서 설명한 바와 같이 학습된 인공신경망 모델을 이용하여 영상 떨림을 보상하는 방법 에 대해서 도 6을 참조하여 상세하게 설명하기로 한다. 학습된 인공신경망 모델은 가중치 데이터가 학습 완료된 상태로 가중치 데이터 보정이 더 이상 이루어지지 않는 다. 부연 설명하면, 학습을 수행하는 프로세서와 추론을 수행하는 프로세서는 서로 상이한 프로세서를 이 용하여 각각 수행될 수 있다. 예를 들면, 본 개시의 예시들에 따른 학습을 수행하는 프로세서는 GPU일 수 있으며, 추론을 수행하는 프로 세서는 NPU일 수 있다. 즉, 기계 학습 과정에서 사용되는 프로세서와 기계 학습 완료 후 추론 과정에서 사 용되는 프로세서는 서로 상이할 수 있다. 예를 들면, 추론 과정에서 사용되는 프로세서는 기계 학습이 불가능하지만 상대적으로 빠른 처리속도와 소 비 전력이 저감된 NPU가 적용될 수 있다. NPU로 구현된 프로세서는 학습이 안되는 대신, 고속의 저전력 프로세서로 구현되어 다양한 엣지 디바 이스로 구현될 수 있는 장점이 있다. 또한 학습이 가능한 프로세서로 추가적인 기계 학습을 진행하여 갱신 된 가중치 데이터를 NPU로 구현된 프로세서에 제공함으로 써, 학습이 불가능한 문제를 해결할 수 있다. 부연 설명하면, 본 개시의 예시들에 따른 제1 모델(Actor model)은 카메라 모듈에 내장된 NPU로 구현된 프로세서에서 처리되도록 구성될 수 있다. 부연 설명하면, 본 개시의 예시들에 따른 제2 모델(Critic model)은 학습 전용 프로세서에서 처리되도록 구성될 수 있다. 여기서 학습 전용 프로세서는 카메라 모듈 외부에 배치된 별도의 프로세서일 수 있 다. 단 본 개시의 예시들은 이에 제한되지 않는다. 도 6은 본 개시의 일 예시에 따른 학습된 인공신경망 모델을 이용하여 영상 떨림을 보상하는 방법을 설명하는 개략적인 개념도이다. 후술하는 동작들은 NPU로 구현된 프로세서를 통해서 수행될 수 있다. 단, 본 개시의예시들에 따른 프로세서는 NPU로 제한되지 않는다. 도 6의 예시에서는 제2 모델(Critic model)이 배제될 수 있다. 따라서, 제1 모델(Actor model)만 이용하여 추론 을 수행 할 수 있다. 이러한 경우, 제1 모델(Actor model)의 가중치는 학습이 완료된 경우 일 수 있다. 또한, 제1 모델(Actor model)만 사용할 경우, 학습 단계가 배제될 수 있고, 제2 모델(Critic model)이 배제될 수 있기 때문에, 소비 전력 저감, 연산량 저감 및 처리 속도가 증가될 수 있다. 또한, NPU로 구현된 저전력 프로세서 를 적용하여 고속, 저전력의 카메라 모듈을 구현할 수 있다. 도 6을 참조하면, 센서를 통해서 환경에 해당하는 떨림 데이터(St)가 획득되고, 획득된 떨림 데이터(St)가 배치 메모리에 저장된다. 배치 메모리에 저장된 떨림 데이터(St)는 안정화 신호 생성부의 입력 데이터로서 입력된다. 안정화 신호 생성부는 예를 들면, 4개의 입력 노드들, 복수개의 히든 레이어들(hidden layers)과 4개의 출력 노드 들로 이루어진 제1 모델(Actor model)을 포함할 수 있다. 단, 제1 모델(Actor model)의 구조는 이에 한정되지 않는다. 4개의 입력 노드들 각각으로부터 θYaw, θPitch, θHSx, θHSy이 입력되면 제1 모델(Actor model)은 에러값 (r)을 기 설정된 값으로 수렴하기 위한 안정화 데이터(+Xaxis, -Xaxis, +Yaxis, -Yaxis)를 추론한다. 따라서 제1 모델(Actor model)은 추론된 안정화 데이터(+Xaxis, -Xaxis, +Yaxis, -Yaxis)를 출력할 수 있다. 여기서, 에러값(r)은 카메라 모듈에 대한 x축 회전각(θPitch)과 렌즈에 대한 x축 회전각(θHSx) 사 이의 차이값(errx)과, 카메라 모듈에 대한 y축 회전각(θYaw)과 렌즈에 대한 y축 회전각(θHSy) 사 이의 차이값(erry)을 서로 더한 값일 수 있다. 예를 들어, 에러값은 와 같은 수식으로 표현 될 수 있다. 변환 유닛(Transpose)는 제1 모델(Actor model)에서 추론된 안정화 데이터(+Xaxis, -Xaxis, +Yaxis, -Yaxis)를 VCM 드라이버의 입력을 위해 이용 가능한 전압으로 변경할 수 있다. 변환 유닛(Transpose)은 변환식 또는 룩업 테이블 등을 이용하여 안정화 데이터를 전압(vx, vy)으로 변환하고, 변환된 전압(vx, vy)을 제어 신호로서 출력한다. 예를 들어, 이러한 전압(vx, vy)은 0V~5V이고, 해당 범위는 VCM 드라이버의 입력 규격에 대응될 수 있다. 예를 들면 +Xaxis 가 입력되면, 안정화 전압(vx)의 전압을 1 단계, 예를 들면, 0.001V 증가시킬 수 있다. 예를 들면 -Xaxis 가 입력되면, 안정화 전압(vx)의 전압을 1 단계, 예를 들면, 0.001V 감소시킬 수 있다. 예를 들면 +Yaxis 가 입력되면, 안정화 전압(vy)의 전압을 1 단계, 예를 들면, 0.001V씩 증가시킬 수 있다. 예 를 들면 -Yaxis 가 입력되면, 안정화 전압(vy)의 전압을 1 단계, 예를 들면, 0.001V씩 감소시킬 수 있다. 즉, 안정화 전압은 기 설정된 전압 스텝 단위로 가변 될 수 있다. 안정화 속도는 전압 스텝의 단위 및 전압 스텝이 갱신되는 간격에 따라서 결정될 수 있다. 단, 본 개시의 예시들은 전압 단계 및 갱신 간격에 제한되지 않는다. 전압(vx, vy)이 입력되면 VCM 드라이버는 안정화 데이터에 따라 VCM 액츄에이터의 떨림을 보상하기 위 한 제어 신호를 출력할 수 있다. 이러한 제어 신호는 VCM 액츄에이터를 제어하기 위한 전류(cx,cy)일 수 있 다. 예를 들어, 이러한 전류(cx,cy)는 -100mA~100mA일 수 있고, 해당 범위는 VCM 액츄에이터의 입력 규격 에 대응될 수 있다. 전류(cx,cy)가 입력되면 VCM 액츄에이터는 입력된 전류에 따라 렌즈의 위치가 보상되도록 동작함으로 써, 영상 안정화를 수행할 수 있다. 이하에서는 장치(A)가 온도를 측정하기 위한 센서를 더 구비하고, 온도 데이터를 더 고려하여 영상 떨림을 보상 하는 방법에 대해서 도 7 내지 도 9를 참조하여 상세하게 설명하기로 한다.* 도 7은 본 개시의 다른 예시에 따른 인공신경망 모델을 설명하는 개략적인 개념도이다. 도 7을 참조하면, 인공신경망 모델은 제1 센서를 통해서 획득된 카메라 모듈의 이동 신호와 제 2 센서를 통해서 획득된 렌즈의 이동 신호를 포함하는 떨림 감지 데이터 및 온도 센서를 통해서 획득된 온도 데이터가 입력 데이터로서 입력된다. 부연 설명하면, 이미지 센서는 카메라 모듈에 고정되기 때문에, 제1 센서를 통해서 카메라 모 듈의 떨림을 감지하면, 실질적으로 이미지 센서의 떨림을 감지할 수 있게 된다. 따라서 카메라 모듈 의 떨림을 감지하여 이미지 센서의 떨림을 실질적으로 감지할 수 있다. 부연 설명하면, 렌즈는 렌즈 홀더에 고정되기 때문에, 제2 센서를 통해서 렌즈 홀더의 떨 림을 감지하면, 실질적으로 렌즈의 떨림을 감지할 수 있게 된다. 따라서, 렌즈 홀더의 떨림을 감지하 여 렌즈의 떨림을 실질적으로 감지할 수 있다. 여기서, 떨림 감지 데이터는, 도 3에서 상술한 떨림 감지 데이터를 의미할 수 있다. 온도 데이터를 측정하는 온 도 센서는 카메라 모듈에 더 포함되거나, 프로세서에 포함되는 센서이거나, 전용 센서일 수 있으나, 이에 한정되지 않는다. 본 개시의 예시에서, 인공신경망 모델은 떨림 감지 데이터 및 온도 데이터를 입력으로 하여 영 상 떨림을 보상하기 위한 안정화 데이터를 추론하고, 추론된 안정화 데이터를 출력할 수 있다. 이하에서는 도 7의 인공신경망 모델의 학습 방법에 대해서 도 8을 참조하여 상세하게 설명하기로 한다. 도 8은 본 개시의 다른 예시에 따른 인공신경망 모델의 학습 방법을 설명하는 개략적인 개념도이다. 제시된 예 시에서는 인공신경망 모델을 Actor-Critic 등과 같은 강화학습을 기반으로 하는 모델로 가정하여 설명한다. 특히, 후술하는 동작들은 프로세서를 통해서 수행될 수 있다. 도 8을 참조하면, 센서를 통해서 카메라 모듈에 대한 제1 이동 신호(θYaw, θPitch) 및 렌즈 에 대한 제2 이동 신호(θHSx, θHSy)가 획득되고, 온도 데이터(Temp)가 획득된다. 여기서, 제1 이동 신호(θ Yaw, θPitch)는 제1 센서로부터 획득되고, 제2 이동 신호(θHSx, θHSy)는 제2 센서로부터 획득되며, 온도 센서로부터 온도 신호(Temp)가 획득될 수 있다. 여기서 제1 이동 신호(θYaw, θPitch)는 실질적으로 이미지 센서의 떨림을 감지하는 신호이다. 제2 이동 신호(θHSx, θHSy)는 실질적으로 렌즈의 떨림을 감지하는 신호이다. 프로세서는 획득된 떨림 감지 데이터(θYaw, θPitch, θHSx, θHSy) 및 온도 데이터(Temp)를 이용하여 현 재 상태(St), 다음 상태(St+1), 행동(at) 보상(rt+1) 및 정책(policy)을 포함하는 환경 데이터를 결정하여 배치 메 모리에 저장할 수 있다. 여기서, 현재 상태(St)에 대한 데이터는 현재 획득된 떨림 감지 데이터(θYaw, θPitch, θHSx, θHSy) 및 온도 데이터(Temp)를 의미할 수 있다. 다음 상태(St+1)에 대한 데이터는 현재 상태에 대하여 행동을 취한 후에 획득되 는 떨림 감지 데이터 및 온도 데이터를 의미할 수 있다. 행동(at)에 대한 데이터는 떨림 감지 데이터(θYaw, θ Pitch, θHSx, θHSy) 및 온도 데이터(Temp)에 기반하여 추론할 수 있는 렌즈의 안정화 데이터(+Xaxis, -Xaxis, +Yaxis, -Yaxis)를 의미한다. 보상(rt+1)에 대한 데이터는 카메라 모듈에 대한 x축 회전각(θPitch)과 렌즈에 대한 x축 회전각(θ HSx) 사이의 차이값과, 카메라 모듈에 대한 y축 회전각(θYaw)과 렌즈에 대한 y축 회전각(θHSy) 사 이의 차이값과, 온도 데이터(Temp)를 기반으로 하는 에러값을 의미한다. 이어서, 배치 메모리부터 현재 상태(St) 및 다음 상태(St+1)에 관한 데이터가 인공신경망 모델의 제1 모델(Actor model) 및 제2 모델(Critic model) 각각에 학습 데이터로서 입력된다. 프로세서는 이를 바탕으로 보상(rt+1)을 최대로 하는 정책(즉, 행동)을 결정하도록 인공신경망 모델을 학습시킨다. 구체적으로, 제1 모델(Actor model)은 입력된 떨림 감지 데이터(θYaw, θPitch, θHSx, θHSy)및 온도 데이터(Temp)에 기반하여 안정화 데이터를 추론한다. 제1 모델(Actor model)은 추론된 안정화 데이터를 기반으로 렌즈의 위치를 보상했을 때 에러값이 기 설정된 값을 수렴할 확률을 결정한다. 제2 모델(Critic model)은 제1 모델(Actor model)이 입력된 떨림 감지 데이터(θYaw, θPitch, θHSx, θHSy) 및 온도 데이터(Temp)에 기반하여 추론된 안정화 데이터에 대한 가치를 평가한다. 가치에 대한 평가 결과는 제1 모델(Actor model)에 전달되어 제1 모델(Actor model)이 추후 행동을 결정하는데 이용될 수 있다. 학습 단계에서 떨림 감지 데이터는 다양한 형태로 제공되는 것이 가능하다. 예를 들면, 강화 학습을 위한 카메라 모듈을 특정 지그(jig)에 고정시키고 지그가 특정 패턴으로 움직이 도록 프로그래밍 할 수 있다. 예를 들면, 강화 학습을 위한 카메라 모듈을 적어도 한 명의 사용자가 들고 특정 시간동안 움직일 수 있 다. 예를 들면, 강화 학습을 위해서, 가상의 떨림 감지 데이터를 제공할 수 있다. 여기서 특정 패턴은 앉기, 걷기, 뛰기, 선박의 동작, 자동차의 동작, 오토바이의 동작 등 일 수 있다. 강화 학습 기간 동안, 적어도 하나의 특정 패턴이 적용될 수 있다. 강화 학습 기간 동안, 적어도 하나의 특정 패턴이 순차적으로 또는 무작위로 적용 될 수 있다. 제1 모델(Actor model)를 통해 추론된 안정화 데이터는 VCM 드라이버로 전달되고, VCM 드라이버는 VCM 액츄에이터의 떨림을 보상하기 위한 제어 신호를 VCM 액츄에이터로 전달한다. 이러한 전압(Vx, Vy)을 수신한 VCM 드라이버는 VCM 액츄에이터를 x축과 y축으로 제어하기 위한 제어 신호를 VCM 액츄 에이터로 전달한다. 제어 신호를 수신한 VCM 액츄에이터에 의해 렌즈의 위치가 보상됨으로써, 영상 떨림을 보상할 수 있다. 다음 단계에서 센서를 통해 떨림 감지 데이터 및 온도 데이터가 획득되고, 상술한 학습 동작들이 반복적으 로 수행될 수 있다. 이러한 학습 동작들은 성공 기준 또는 최대 에피소드 수에 도달할 때까지 수행될 수 있으나, 이에 한정되지 않는다. 예를 들어, 성공 기준은 추론된 안정화 데이터에 기반하여 결정된 에러값이 ' 0'을 수렴하는 기준을 포함할 수 있다. 이하에서는 상술한 인공신경망 모델의 구체적인 학습 동작에 대해서 도 5를 참조하여 상세하게 설명하기로 한다. 인공신경망 모델은 도 5에서 설명한 바와 동일한 방법으로 학습을 수행할 수 있다. 도 5를 참조하면, 제1 모델 및 제2 모델 각각은 현재 획득된 떨림 감지 데이터(θYaw, θPitch, θ HSx, θHSy) 및 온도 데이터(Temp)를 포함하는 현재 상태(st)와, 현재 상태에 대하여 행동을 취한 후에 획득되 는 떨림 감지 데이터 및 온도 데이터를 포함하는 다음 상태(st+1)를 학습 데이터로서 입력받는다. 제1 모델은 떨림 감지 데이터 및 온도 데이터(st, st+1)를 입력으로 하여 추론된 안정화 데이터와 함께 현 재 상태 St에서 행동 at를 취할 확률 πθ(at|St) 및 Batch로 업데이트되기 전 제1 모델의 현재 상태 St에서 행동 at를 취할 확률 πθold(at|St)을 출력한다. 제2 모델은 떨림 감지 데이터 및 온도 데이터(st, st+1)를 입력으로 하여 떨림 감지 데이터(st, st+1)에 대한 가치 Vυ(St), Vυ(St+1) 및 출력된 가치 Vυ(St), Vυ(St+1)에 대한 예상 이익(advantage) 을 출력한다. 제1 모델은 πθ(at|St), πθold(at|St) 및 제2 모델의 출력인 를 기반으로 손실 를 결 정하고, 결정된 손실 를 이용하여 제1 모델의 파리미터 벡터 θ를 업데이트할 수 있다. 손실 은 상술한 <수학식 1>을 이용하여 산출될 수 있다. 제2 모델은 가치 Vυ(St), Vυ(St+1)를 이용하여 손실 을 결정하고, 결정된 손실 을 이용하여 제2 모델의 파라미터 벡터 υ를 업데이트할 수 있다. 손실 은 상술한 <수학식 2>를 이용하여 산출될 수 있다. 제1 모델로부터 전달된 안정화 데이터는 변환 유닛을 통해 VCM 드라이버에서 입력 가능한 전압 (vx, vy)으로 변환되어 출력되고, VCM 드라이버는 VCM 액츄에이터가 렌즈의 위치를 보상하도록 제어 신호(cx, cy)를 전달하고, 이후 동작은 도 8에서 서술한 바와 같이 학습 동작이 수행될 수 있다. 이하에서는 도 5 및 도 8에서 설명한 바와 같이 학습된 인공신경망 모델을 이용하여 영상 떨림을 보상하는 방법 에 대해서 도 9를 참조하여 상세하게 설명하기로 한다. 도 9는 본 개시의 다른 예시에 따른 학습된 인공신경망 모델을 이용하여 영상 떨림을 보상하는 방법을 설명하는 개략적인 개념도이다. 후술하는 동작들은 프로세서를 통해서 수행될 수 있다. 도 9의 예시에서는 제2 모델(Critic model)이 배제될 수 있다. 따라서, 제1 모델(Actor model)만 이용하여 추론 을 수행 할 수 있다. 이러한 경우, 제1 모델(Actor model)의 가중치는 학습이 완료된 경우 일 수 있다. 또한, 제1 모델(Actor model)만 사용할 경우, 학습 단계가 배제될 수 있고, 제2 모델(Critic model)이 배제될 수 있기 때문에, 소비 전력 저감, 연산량 저감 및 처리 속도가 증가될 수 있다. 또한, NPU로 구현된 저전력 프 로세서를 적용하여 고속, 저전력의 카메라 모듈을 구현할 수 있다. 도 9를 참조하면, 센서를 통해서 환경에 해당하는 떨림 감지 데이터 및 온도 데이터(St)가 획득되고, 획득 된 떨림 데이터 및 온도 데이터(St)가 배치 메모리에 저장된다. 배치 메모리에 저장된 떨림 감지 데이터 및 온도 데이터(St)는 안정화 신호 생성부의 입력 데이터로 서 입력된다. 안정화 신호 생성부는 5개의 입력 노드들, 복수개의 히든 레이어들과 4개의 출력 노드들로 이루어진 제1 모델(Actor model)을 포함할 수 있다. 단, 제1 모델(Actor model)의 구조는 이에 한정되지 않는다. 5개의 입력 노드들 각각으로부터 θYaw, θPitch, θHSx, θHSy, Temp가 입력되면 제1 모델(Actor model)은 에 러값(r)을 기 설정된 값으로 수렴하기 위한 안정화 데이터(+Xaxis, -Xaxis, +Yaxis, -Yaxis)를 추론하고, 추론 된 안정화 데이터(+Xaxis, -Xaxis, +Yaxis, -Yaxis)를 출력한다. 여기서, 에러값(r)은 카메라 모듈에 대 한 x축 회전각(θPitch)과 렌즈에 대한 x축 회전각(θHSx) 사이의 차이값(errx)과, 카메라 모듈에 대한 y축 회전각(θYaw)과 렌즈에 대한 y축 회전각(θHSy) 사이의 차이값(erry)을 서로 더한 값일 수 있다. 예를 들어, 에러값은 와 같은 수식으로 표현될 수 있다. 안정화 신호 생성부는 추론된 안정화 데이터(+Xaxis, -Xaxis, +Yaxis, -Yaxis)를 VCM 드라이버의 입 력을 위해 이용 가능한 전압으로 변경하도록 구성된 변환 유닛(Transpose)을 더 포함할 수 있다. 변환 유닛 (Transpose)은 변환식 또는 룩업 테이블 등을 이용하여 안정화 데이터를 전압(vx, vy)으로 변환하고, 변환된 전 압(vx, vy)을 제어 신호로서 출력한다. 전압(vx, vy)이 입력되면 VCM 드라이버는 안정화 데이터에 따라 VCM 액츄에이터의 떨림을 보상하기 위 한 제어 신호를 출력할 수 있다. 이러한 제어 신호는 VCM 액츄에이터를 제어하기 위한 전류(cx, cy)일 수 있다. 전류(cx, cy)가 입력되면 VCM 액츄에이터는 입력된 전류에 따라 렌즈의 위치가 보상되도록 동작함으로 써, 영상 안정화를 수행할 수 있다. 이하에서는 장치(A)가 자동 초점(Auto Focus, AF)용 코일을 더 구비하고, 인공지능신경망에 기반하여 AF 및 OIS 를 제어하는 방법에 대해서 도 10 내지 도 14를 참조하여 상세하게 설명하기로 한다. 도 10은 본 개시의 또다른 예시에 따른 카메라 모듈을 설명하는 개략적인 개념도이다. 제시된 예시에서는 설명 의 편의를 위해 앞서 설명한 구성 요소와 동일한 구성 요소에 대한 설명을 생략한다.도 10을 참조하면, 카메라 모듈은 렌즈, 이미지 센서, 제1 센서, VCM 드라이버, 프 로세서 및 VCM 액츄에이터를 포함하고, VCM 액츄에이터는 AF 코일을 더 포함할 수 있다. AF 코일은 AF 마그넷(미도시)에 대응하여 배치되고, AF 마그넷의 위치를 제어하기 위한 전압이 인가되도록 구성될 수 있다. 프로세서는 카메라 모듈에 포함된 적어도 둘 이상의 센서(즉, 제1 센서 및 제2 센서)로부 터 이동 신호를 획득하고, 영상의 주파수 성분으로부터 디포커스량을 결정하고, 획득된 이동 신호 및 결정된 디 포커스량에 기반하여 영상 떨림 및 초점을 보상하기 위한 떨림 보상 신호를 추론하도록 학습된 인공신경망 모델 을 이용하여 떨림 보상 신호를 추론할 수 있다. 이어서, 프로세서는 추론된 떨림 보상 신호에 기반하여 영 상 떨림 및 초점을 보상할 수 있다. 여기서, 이동 신호는 초점 조절을 위한 홀 센서의 z축 값을 더 포함할 수 있다. 이하에서는 프로세서에서 인공신경망 모델을 이용하여 영상 떨림을 보상하고, 초점을 조절하기 위한 방법 을 도 11 내지 도 14를 참조하여 상세하게 설명하기로 한다. 도 11은 본 개시의 또다른 예시에 따른 인공신경망 모델을 설명하는 개략적인 개념도이다. 도 11을 참조하면, 인공신경망 모델은 제1 센서를 통해서 획득된 카메라 모듈의 이동 신호와 제2 센서를 통해서 획득된 렌즈의 이동 신호를 포함하는 떨림 감지 데이터 및 영상의 주파수 성분으로부터 결정된 디포커스량 데이터(defocus_amount)가 입력 데이터로서 입력된다. 여기서, 떨림 감 지 데이터는, 홀 센서를 통해서 획득된 z축 회전각을 더 포함할 수 있다. 본 개시의 예시에서, 인공신경망 모델은 떨림 감지 데이터 및 디포커스량 데이터를 입력으로 하여 영상 떨림을 보상하고, 초점을 조정하기 위한 안정화 데이터를 추론하고, 추론된 안정화 데이터를 출력할 수 있다. 이하에서는 도 11의 인공신경망 모델의 학습 방법에 대해서 도 12를 참조하여 상세하게 설명하기로 한다. 도 12은 본 개시의 또다른 예시에 따른 인공신경망 모델의 학습 방법을 설명하는 개략적인 개념도이다. 제시된 예시에서는 인공신경망 모델을 Actor-Critic 등과 같은 강화학습을 기반으로 하는 모델로 가정하여 설명 한다. 특히, 후술하는 동작들은 프로세서를 통해서 수행될 수 있다. 도 12를 참조하면, 센서를 통해서 카메라 모듈에 대한 제1 이동 신호(θYaw, θPitch) 및 렌즈(10 0)에 대한 제2 이동 신호(θHSx, θHSy, θHSz)가 획득되고, 영상의 주파수 성분으로부터 결정된 디포커스량 데 이터(defocus_amount)가 획득된다. 디포커스량 데이터는 프로세서, 이미지 센서 또는 ISP(image signal processor) 등에 의해서 획득될 수 있다. 프로세서는 획득된 떨림 감지 데이터(θYaw, θPitch, θHSx, θHSy), 렌즈 초점 데이터(θHSz) 및 디포커 스량 데이터(defocus_amount)를 이용하여 현재 상태(St), 다음 상태(St+1), 행동(at) 보상(rt+1) 및 정책(polic y)을 포함하는 환경 데이터를 결정하고, 결정된 환경 데이터를 배치 메모리에 저장할 수 있다. 여기서, 현 재 상태(St)에 대한 데이터는 현재 획득된 떨림 감지 데이터(θYaw, θPitch, θHSx, θHSy), 렌즈 초점 데이터 (θHSz) 및 디포커스량 데이터(defocus_amount)를 의미할 수 있다. 다음 상태(St+1)에 대한 데이터는 현재 상태 에 대하여 행동을 취한 후에 획득되는 떨림 감지 데이터 및 디포커스량 데이터를 의미할 수 있다. 행동(at)에 대 한 데이터는 떨림 감지 데이터(θYaw, θPitch, θHSx, θHSy), 렌즈 초점 데이터(θHSz) 및 디포커스량 데이터 (defocus_amount)에 기반하여 추론할 수 있는 렌즈의 안정화 데이터(+Xaxis, -Xaxis, +Yaxis, -Yaxis, +Zaxis, -Zaxis,)를 의미하고, 보상(rt+1)에 대한 데이터는 카메라 모듈에 대한 x축 회전각(θPitch)과 렌 즈에 대한 x축 회전각(θHSx) 사이의 차이값과, 카메라 모듈에 대한 y축 회전각(θYaw)과 렌즈(10 0)에 대한 y축 회전각(θHSy) 사이의 차이값과, 디포커스량 데이터를 기반으로 하는 에러값을 의미한다. 이어서, 배치 메모리부터 현재 상태(St) 및 다음 상태(St+1)에 관한 데이터가 인공신경망 모델의 제1 모델(Actor model) 및 제2 모델(Critic model) 각각에 학습 데이터로서 입력된다. 프로세서는 이를 바탕으로 에러값이 기 설정된 값을 수렴하는 안정화 데이터를 추론하도록 인공신경망 모 델을 학습시킨다. 구체적으로, 제1 모델(Actor model)은 입력된 떨림 감지 데이터(θYaw, θPitch, θHSx, θHSy), 렌즈 초점 데 이터(θHSz) 및 디포커스량 데이터(defocus_amount)에 기반하여 안정화 데이터를 추론한다. 제1 모델(Actor model)은 추론된 안정화 데이터를 기반으로 렌즈의 위치를 보상했을 때 에러값이 기 설정된 값을 수렴할 확률을 결정한다. 제2 모델(Critic model)은 제1 모델(Actor model)이 입력된 떨림 감지 데이터(θYaw, θPitch, θHSx, θHSy), 렌즈 초점 데이터(θHSz) 및 디포커스량 데이터(defocus_amount)에 기반하여 추론된 안정화 데이터에 대한 가치 를 평가한다. 가치에 대한 평가 결과는 제1 모델(Actor model)에 전달되어 제1 모델(Actor model)이 추후 행동 을 결정하는데 이용될 수 있다. 학습 단계에서 떨림 감지 데이터는 다양한 형태로 제공되는 것이 가능하다. 예를 들면, 강화 학습을 위한 카메라 모듈을 특정 지그(jig)에 고정시키고 지그가 특정 패턴으로 움직이 도록 프로그래밍 할 수 있다. 예를 들면, 강화 학습을 위한 카메라 모듈을 적어도 한 명의 사용자가 들고 특정 시간동안 움직일 수 있 다. 예를 들면, 강화 학습을 위해서, 가상의 떨림 감지 데이터를 제공할 수 있다. 여기서 특정 패턴은 앉기, 걷기, 뛰기, 선박의 동작, 자동차의 동작, 오토바이의 동작 등 일 수 있다. 강화 학습 기간 동안, 적어도 하나의 특정 패턴이 적용될 수 있다. 강화 학습 기간 동안, 적어도 하나의 특정 패턴이 순차적으로 또는 무작위로 적용 될 수 있다. 제1 모델(Actor model)를 통해 추론된 안정화 데이터는 VCM 드라이버로 전달되고, VCM 드라이버는 VCM 액츄에이터의 떨림을 보상하기 위한 제어 신호를 VCM 액츄에이터로 전달한다. 본 개시에서 안정 화 데이터는 VCM 드라이버가 VCM 액츄에이터를 제어하도록 VCM 드라이버에 입력 가능한 전압 (Vx, Vy, Vz)으로 변환되어 전달될 수 있다. 이러한 전압(Vx, Vy, Vz)을 수신한 VCM 드라이버는 VCM 액츄 에이터를 x축, y축 및 z축으로 제어하기 위한 제어 신호를 VCM 액츄에이터로 전달한다. 여기서, 제어 신호는 VCM 액츄에이터를 x축으로 제어하기 위한 전류(cx), VCM 액츄에이터를 y축으로 제어하기 위한 전류(cy) 및 VCM 액츄에이터를 z축으로 제어하기 위한 전류(cz)를 포함할 수 있다. 이러한 전류(cx, cy, cz)를 수신한 VCM 액츄에이터는 렌즈의 위치가 보상되도록 동작함으로써, 영상 떨 림을 보상할 수 있다. 다음 단계에서 센서를 통해 떨림 감지 데이터(θYaw, θPitch, θHSx, θHSy), 렌즈 초점 데이터(θHSz) 가 획득되고, 영상의 주파수 성분으로부터 디포커스량 데이터(defocus_amount)가 획득된 후 상술한 학습 동작들 이 반복적으로 수행될 수 있다. 이러한 학습 동작들은 성공 기준 또는 최대 에피소드 수에 도달할 때까지 수행 될 수 있으나, 이에 한정되지 않는다. 예를 들어, 성공 기준은 추론된 안정화 데이터에 기반하여 결정된 에러값 이 '0'을 수렴하는 기준을 포함할 수 있다. 이하에서는 상술한 인공신경망 모델의 구체적인 학습 동작에 대해서 도 13을 참조하여 상세하게 설명하기 로 한다. 도 13은 본 개시의 또다른 예시에 따른 인공신경망 모델의 구체적인 학습 동작을 설명하는 개략적인 개념도이다. 도 13을 참조하면, 제1 모델 및 제2 모델 각각은 현재 획득된 떨림 감지 데이터(θYaw, θPitch, θHSx, θHSy), 렌즈 초점 데이터(θHSz)와 디포커스량 데이터(defocus_amount)를 포함하는 현재 상태(st)와 및 현재 상태에 대하여 행동을 취한 후에 획득되는 떨림 감지 데이터 및 디포커스량 데이터를 포함하는 다음 상태 (st+1)를 학습 데이터로서 입력받는다. 제1 모델은 떨림 감지 데이터 및 디포커스량 데이터(st, st+1)를 입력으로 하여 추론된 안정화 데이터와 함께 현재 상태 St에서 행동 at를 취할 확률 πθ(at|St) 및 Batch로 업데이트되기 전 제1 모델의 현재 상 태 St에서 행동 at를 취할 확률 πθold(at|St)을 출력한다. 제2 모델은 떨림 감지 데이터 및 디포커스량 데이터(st, st+1)를 입력으로 하여 떨림 감지 데이터(st, st+ 1)에 대한 가치 Vυ(St), Vυ(St+1) 및 출력된 가치 Vυ(St), Vυ(St+1)에 대한 예상 이익(advantage) 을 출력 한다. 제1 모델은 πθ(at|St), πθold(at|St) 및 제2 모델의 출력인 를 기반으로 손실 를 결정하고, 결정된 손실 를 이용하여 제1 모델의 파리미터 벡터 θ를 업데이트할 수 있다. 손실 은 상술한 <수학식 1>을 이용하여 산출될 수 있다. 제2 모델은 가치 Vυ(St), Vυ(St+1)를 이용하여 손실 을 결정하고, 결정된 손실 을 이용하여 제 2 모델의 파라미터 벡터 υ를 업데이트할 수 있다. 손실 은 상술한 [수학식 2]를 이용하여 산출될 수 있다. 제1 모델로부터 전달된 안정화 데이터는 변환 유닛을 통해 VCM 드라이버에서 입력 가능한 전 압(vx, vy, vz)으로 변환되어 출력되고, VCM 드라이버는 VCM 액츄에이터가 렌즈의 위치를 보상하도록 제어 신호(cx, cy, cz)를 전달하고, 이후 동작은 도 12에서 서술한 바와 같이 학습 동작이 수행될 수 있다. 이를 통해 영상 떨림을 보상할 뿐만 아니라 초점 보상 또한 수행될 수 있다. 이하에서는 도 12 및 도 13에서 설명한 바와 같이 학습된 인공신경망 모델을 이용하여 영상 떨림을 보상하는 방 법에 대해서 도 14를 참조하여 상세하게 설명하기로 한다. 도 14는 본 개시의 다른 예시에 따른 학습된 인공신경망 모델을 이용하여 영상 떨림을 보상하는 방법을 설명하 는 개략적인 개념도이다. 후술하는 동작들은 프로세서를 통해서 수행될 수 있다. 도 14를 참조하면, 센서를 통해서 떨림 감지 데이터가 획득되고, 영상의 주파수 성분으로부터 디포커스량 데이터(St)가 획득된 후 획득된 떨림 데이터 및 디포커스량 데이터(St)가 배치 메모리에 저장된다. 도 14의 예시에서는 제2 모델(Critic model)이 배제될 수 있다. 따라서, 제1 모델(Actor model)만 이용하여 추 론을 수행 할 수 있다. 이러한 경우, 제1 모델(Actor model)의 가중치는 학습이 완료된 경우 일 수 있다. 또한, 제1 모델(Actor model)만 사용할 경우, 학습 단계가 배제될 수 있고, 제2 모델(Critic model)이 배제될 수 있기 때문에, 소비 전력 저감, 연산량 저감 및 처리 속도가 증가될 수 있다. 또한, NPU로 구현된 저전력 프로세서 를 적용하여 고속, 저전력의 카메라 모듈을 구현할 수 있다. 배치 메모리에 저장된 떨림 감지 데이터 및 디포커스량 데이터(St)는 인정화 신호 생성부의 입력 데이터로서 입력된다. 안정화 신호 생성부는 6개의 입력 노드들, 복수개의 히든 레이어들과 6개의 출력 노드들로 이루어진 제1 모델(Actor model)을 포함할 수 있다. 단, 제1 모델(Actor model)의 구조는 이에 한정되 지 않는다. 6개의 입력 노드들 각각으로부터 θYaw, θPitch, θHSx, θHSy, θHSz, defocus_amount가 입력되면 제1 모델 (Actor model)은 에러값(r)을 기 설정된 값으로 수렴하기 위한 안정화 데이터(+Xaxis, -Xaxis, +Yaxis, -Yaxis, +Zaxis, -Zaxis)를 추론하고, 추론된 안정화 데이터(+Xaxis, -Xaxis, +Yaxis, -Yaxis, +Zaxis, -Zaxis)를 출력한다. 여기서, 에러값(r)은 카메라 모듈에 대한 x축 회전각(θPitch)과 렌즈에 대한 x축 회전각(θHSx) 사이의 차이값(errx)과, 카메라 모듈에 대한 y축 회전각(θYaw)과 렌즈에 대한 y 축 회전각(θHSy) 사이의 차이값(erry)을 서로 더한 값에서 디포커스량(defocus_amount)을 더한 값일 수 있다. 예를 들어, 에러값(r)은 와 같은 수식으로 표현될 수 있다. Defocus_amount는 전압(vz)값에 따라 조절될 수 있다. AF 코일은 전압(vz)에 대응되는 (cz)값에 따라 AF 코 일을 z축을 조절할 수 있다. 따라서 AF 코일이 구비된 렌즈 홀더에 고정된 렌즈의 z축을 이동시킬 수 있다. 따라서 Defocus_amount가 조절될 수 있다. 안정화 신호 생성부는 추론된 안정화 데이터(+Xaxis, -Xaxis, +Yaxis, -Yaxis, +Zaxis, -Zaxis)를 VCM 드라이버의 입력을 위해 이용 가능한 전압으로 변경하도록 구성된 변환 유닛(Transpose)을 더 포함할 수있다. 변환 유닛(Transpose)은 변환식 또는 룩업 테이블 등을 이용하여 안정화 데이터를 전압(vx, vy, vz)으로 변환하고, 변환된 전압(vx, vy, vz)을 제어 신호로서 출력한다. 전압(vx, vy, vz)이 입력되면 VCM 드라이버는 안정화 데이터에 따라 VCM 액츄에이터의 떨림을 보상하 기 위한 제어 신호를 출력할 수 있다. 이러한 제어 신호는 VCM 액츄에이터를 제어하기 위한 전류(cx, cy, cz)일 수 있다. 전류(cx, cy, cz)가 입력되면 VCM 액츄에이터는 VCM 액츄에이터는 입력된 전류에 따라 렌즈의 위 치가 보상되도록 동작함으로써, 영상 안정화 및 초점 조정을 수행할 수 있다. 본 개시의 다양한 예시에 따른 카메라 모듈은 센서를 통해서 떨림 감지 데이터(θYaw, θPitch, θHSx, θHSy) 및 온도 데이터(Temp)를 획득하고, 렌즈 초점 데이터(θHSz)와 영상의 주파수 성분으로부터 디포커스량 데이터(defocus_amount)를 획득할 수 있다. 카메라 모듈은 획득된 떨림 감지 데이터, 온도 데이터, 렌즈 초점 데이터 및 디포커스량 데이터를 기초로 영상 안정화 및 초점 조정을 위한 안정화 데이터를 추론하도록 학습된 인공신경망 모델을 이용하여 안정화 데이 터를 출력할 수 있다. 이하에서는 카메라 모듈에서 영상 안정화를 위한 방법에 대해서 도 15를 참조하여 설명하도록 한다. 도 15는 본 개시의 예시에 카메라 모듈에서 영상 안정화를 위한 방법을 설명하는 흐름도이다. 제시된 예시에서 후술하는 동작들은 카메라 모듈의 프로세서에 의해서 수행될 수 있다. 도 15를 참조하면, 프로세서는 둘 이상의 센서로부터 영상에 관한 떨림 감지 데이터가 획득된다(S1500). 본 개시의 예시에 따른 둘 이상의 센서는, 자이로 센서(Gyro sensor), 홀 센서(Hall sensor) 및 포토 센서 중 적어도 둘 이상을 포함할 수 있다. 여기서, 떨림 감지 데이터는, 자이로 센서의 x, y축 회전 움직임 및 홀 센서 의 x, y축 회전 움직임을 감지한 신호를 포함할 수 있다. 프로세서는 획득된 떨림 감지 데이터를 기초로 영상 떨림을 보상하기 위한 안정화 데이터를 출력하도록 학 습된 인공신경망 모델을 이용하여 안정화 데이터를 출력한다(S1510). 이어서, 프로세서는 출력된 안정화 데이터를 이용하여 영상 떨림을 보상한다(S1520). 도 16은 본 개시에 따른 신경 프로세싱 유닛을 설명하는 개략적인 개념도이다. 도 16에 도시된 신경 프로세싱 유닛(neural processing unit, NPU)은 인공신경망 모델을 위한 동작을 수 행하도록 특화된 프로세서이다. 인공신경망 모델은 여러 입력 또는 자극이 들어오면 각각 가중치를 곱해 더해주고, 추가적으로 편차를 더한 값 을 활성화 함수를 통해 변형하여 전달하는 인공 뉴런들이 모인 네트워크를 의미한다. 이렇게 학습된 인공신경망 은 입력 데이터로부터 추론(inference) 결과를 출력하는데 사용될 수 있다. 상기 신경 프로세싱 유닛(NPU)은 전기/전자 회로로 구현된 반도체일 수 있다. 상기 전기/전자 회로라 함은 수많 은 전자 소자, (예컨대 트렌지스터, 커패시터)를 포함하는 것을 의미할 수 있다. 상기 신경 프로세싱 유닛(NPU)은 복수의 프로세싱 엘리먼트(processing element: PE) , NPU 내부 메모리 , NPU 스케줄러, 및 NPU 인터페이스를 포함할 수 있다. 복수의 프로세싱 엘리먼트 , NPU 내부 메모리, NPU 스케줄러, 및 NPU 인터페이스 각각은 수많은 트렌지스터 들이 연결된 반도체 회로일 수 있다. 따라서, 이들 중 일부는 육안으로는 식별되어 구분되기 어려울 수 있고, 동작에 의해서만 식별될 수 있다. 신경 프로세싱 유닛(NPU은 제1 모델(Actor model)을 추론하도록 구성될 수 있다. 예컨대, 임의 회로는 복수의 프로세싱 엘리먼트으로 동작하기도 하고, 혹은 NPU 스케줄러로 동작 될 수도 있다. NPU 스케줄러는 신경 프로세싱 유닛(NPU)의 인공신경망 추론 동작을 제어하도록 구성된 제어부의 기능을 수행하도록 구성될 수 있다. 상기 신경 프로세싱 유닛(NPU)은 복수의 프로세싱 엘리먼트, 복수의 프로세싱 엘리먼트에서 추론 될 수 있는 인공신경망모델을 저장하도록 구성된 NPU 내부 메모리, 및 인공신경망모델의 데이터 지역성정보 또는 구조에 대한 정보에 기초하여 복수의 프로세싱 엘리먼트 및 NPU 내부 메모리를 제어하 도록 구성된 NPU 스케줄러를 포함할 수 있다. 여기서, 인공신경망모델은 인공신경망모델의 데이터 지역 성 정보 또는 구조에 대한 정보를 포함할 수 있다. 인공신경망모델은 특정 추론 기능을 수행하도록 학습된 AI 인식모델을 의미할 수 있다. 복수의 프로세싱 엘리먼트는 인공신경망을 위한 동작을 수행할 수 있다. NPU 인터페이스는 시스템 버스를 통해서 신경 프로세싱 유닛(NPU)와 연결된 다양한 구성요소들, 예컨대 메모리와 통신할 수 있다. NPU 스케줄러는 신경 프로세싱 유닛(NPU)의 추론 연산을 위한 복수의 프로세싱 엘리먼트의 연산 및 NPU 내부 메모리의 읽기 및 쓰기 순서를 제어하도록 구성될 수 있다. NPU 스케줄러는 인공신경망모델의 데이터 지역성 정보 또는 구조에 대한 정보에 기초하여 복수의 프로세 싱 엘리먼트 및 NPU 내부 메모리을 제어하도록 구성될 수 있다. NPU 스케줄러는 복수의 프로세싱 엘리먼트에서 작동할 인공신경망모델의 구조를 분석하거나 또는 이미 분석된 정보를 제공받을 수 있다. 예를 들면, 인공신경망모델이 포함할 수 있는 인공신경망의 데이터는 각 각의 레이어의 노드 데이터(즉, 특징맵), 레이어들의 배치 데이터, 지역성 정보 또는 구조에 대한 정보, 각각의 레이어의 노드를 연결하는 연결망 각각의 가중치 데이터 (즉, 가중치 커널) 중 적어도 일부를 포함할 수 있다. 인공신경망의 데이터는 NPU 스케줄러 내부에 제공되는 메모리 또는 NPU 내부 메모리에 저장될 수 있다. NPU 스케줄러는 인공신경망모델의 데이터 지역성 정보 또는 구조에 대한 정보에 기초하여 신경 프로세싱 유닛(NPU)가 수행할 인공신경망모델의 연산 순서를 스케줄링 할 수 있다. NPU 스케줄러는 인공신경망모델의 데이터 지역성 정보 또는 구조에 대한 정보에 기초하여 인공신경망모 델의 레이어의 특징맵 및 가중치 데이터가 저장된 메모리 어드레스 값을 획득할 수 있다. 예를 들면, NPU 스케 줄러는 메모리에 저장된 인공신경망모델의 레이어의 특징맵 및 가중치 데이터가 저장된 메모리 어드레스 값을 획득할 수 있다. 따라서 NPU 스케줄러는 구동할 인공신경망모델의 레이어의 특징맵 및 가중치 데이 터를 메인 메모리에서 가져와서 NPU 내부 메모리에 저장할 수 있다. 각각의 레이어의 특징맵은 대응되는 각각의 메모리 어드레스 값을 가질 수 있다. 각각의 가중치 데이터는 대응되는 각각의 메모리 어드레스 값을 가질 수 있다. NPU 스케줄러는 인공신경망모델의 데이터 지역성 정보 또는 구조에 대한 정보, 예를 들면, 인공신경망모 델의 인공신경망의 레이어들의 배치 데이터, 지역성 정보 또는 구조에 대한 정보에 기초해서 복수의 프로세싱 엘리먼트의 연산 순서를 스케줄링 할 수 있다. NPU 스케줄러는 인공신경망모델의 데이터 지역성 정보 또는 구조에 대한 정보에 기초하여 스케줄링 하기 때문에, 일반적인 CPU의 스케줄링 개념과 다르게 동작할 수 있다. 일반적인 CPU의 스케줄링은 공평성, 효율성, 안정성, 반응 시간 등을 고려하여, 최상의 효율을 낼 수 있도록 동작한다. 즉, 우선 순위, 연산 시간 등을 고려 해서 동일 시간내에 가장 많은 프로세싱을 수행하도록 스케줄링 한다. 종래의 CPU는 각 프로세싱의 우선 순서, 연산 처리 시간 등의 데이터를 고려하여 작업을 스케줄링 하는 알고리 즘을 사용하였다. 이와 다르게 NPU 스케줄러는 인공신경망모델의 데이터 지역성 정보 또는 구조에 대한 정보에 기초하여 결정된 신경 프로세싱 유닛(NPU)의 프로세싱 순서대로 신경 프로세싱 유닛(NPU)를 제어할 수 있다. 더 나아가면, NPU 스케줄러는 인공신경망모델의 데이터 지역성 정보 또는 구조에 대한 정보 및/또는 사 용하려는 신경 프로세싱 유닛(NPU)의 데이터 지역성 정보 또는 구조에 대한 정보에 기초하여 결정된 프로세싱 순서대로 신경 프로세싱 유닛(NPU)를 구동할 수 있다. 단, 본 개시는 신경 프로세싱 유닛(NPU)의 데이터 지역성 정보 또는 구조에 대한 정보에 제한되지 않는다. NPU 스케줄러는 인공신경망의 데이터 지역성 정보 또는 구조에 대한 정보를 저장하도록 구성될 수 있다. 즉, NPU 스케줄러는 적어도 인공신경망모델의 인공신경망의 데이터 지역성 정보 또는 구조에 대한 정보 만 활용하더라도 프로세싱 순서를 결정할 수 있다. 더 나아가서, NPU 스케줄러는 인공신경망모델의 데이터 지역성 정보 또는 구조에 대한 정보 및 신경 프 로세싱 유닛(NPU)의 데이터 지역성 정보 또는 구조에 대한 정보를 고려하여 신경 프로세싱 유닛(NPU)의 프로세 싱 순서를 결정할 수 있다. 또한, 결정된 프로세싱 순서대로 신경 프로세싱 유닛(NPU)의 프로세싱 최적화도 가 능하다. 복수의 프로세싱 엘리먼트는 인공신경망의 특징맵과 가중치 데이터를 연산하도록 구성된 복수의 프로세 싱 엘리먼트들(PE1 to PE12)이 배치된 구성을 의미한다. 각각의 프로세싱 엘리먼트는 MAC (multiply and accumulate) 연산기 및/또는 ALU (Arithmetic Logic Unit) 연산기를 포함할 수 있다. 단, 본 개시에 따른 예시 들은 이에 제한되지 않는다. 각각의 프로세싱 엘리먼트는 추가적인 특수 기능을 처리하기 위해 추가적인 특수 기능 유닛을 선택적으로 더 포 함하도록 구성될 수 있다. 예를 들면, 프로세싱 엘리먼트(PE)는 배치-정규화 유닛, 활성화 함수 유닛, 인터폴레이션 유닛 등을 더 포함하 도록 변형 실시되는 것도 가능하다. 도 16에서는 예시적으로 복수의 프로세싱 엘리먼트들이 도시되었지만, 하나의 프로세싱 엘리먼트 내부에 MAC을 대체하여, 복수의 곱셈기(multiplier) 및 가산기 트리(adder tree)로 구현된 연산기들이 병렬로 배치되어 구성 되는 것도 가능하다. 이러한 경우, 복수의 프로세싱 엘리먼트는 복수의 연산기를 포함하는 적어도 하나 의 프로세싱 엘리먼트로 지칭되는 것도 가능하다. 복수의 프로세싱 엘리먼트는 복수의 프로세싱 엘리먼트들(PE1 to PE12)을 포함하도록 구성된다. 도 16에 도시된 복수의 프로세싱 엘리먼트들(PE1 to PE12)은 단지 설명의 편의를 위한 예시이며, 복수의 프로세싱 엘리 먼트들(PE1 to PE12)의 개수는 제한되지 않는다. 복수의 프로세싱 엘리먼트들(PE1 to PE12)의 개수에 의해서 복 수의 프로세싱 엘리먼트의 크기 또는 개수가 결정될 수 있다. 복수의 프로세싱 엘리먼트의 크기 는 N x M 행렬 형태로 구현될 수 있다. 여기서 N 과 M은 0보다 큰 정수이다. 복수의 프로세싱 엘리먼트 는 N x M 개의 프로세싱 엘리먼트를 포함할 수 있다. 즉, 프로세싱 엘리먼트는 1개 이상일 수 있다. 복수의 프로세싱 엘리먼트의 크기는 신경 프로세싱 유닛(NPU)이 작동하는 인공신경망모델의 특성을 고려 하여 설계할 수 있다. 복수의 프로세싱 엘리먼트는 인공신경망 연산에 필요한 덧셈, 곱셈, 누산 등의 기능을 수행하도록 구성 된다. 다르게 설명하면, 복수의 프로세싱 엘리먼트는 MAC(multiplication and accumulation) 연산을 수 행하도록 구성될 수 있다.본 개시의 예시에 따른 인공신경망 모델은, 강화학습(Reinforcement Learning)을 기반 으로 할 수 있다. 본 개시의 예시에 따른 떨림 감지 데이터는, 카메라 모듈 및 렌즈의 위치 변화를 감지하는 신호를 포함할 수 있 다. 본 개시의 예시에 따른 인공신경망 모델은, 학습을 위한 학습 데이터를 기초로 영상 움직임에 의한 에러 값이 기 설정된 값을 수렴하도록 사전 학습된 모델을 기반으로 할 수 있다. 여기서, 에러 값은 자이로 센서의 x축 이 동과 홀 센서의 x축 이동 사이의 차이값 및 자이로 센서의 y축 이동과 홀 센서의 y축 이동 사이의 차이값을 기 반으로 계산될 수 있다. 본 개시의 예시에 따른 인공신경망 모델은, 떨림 감지 데이터를 입력으로 하여 영상 떨림을 보상하기 위해 카메 라 모듈에 포함된 렌즈의 이동을 제어하기 위한 제어 신호를 출력할 수 있다. 본 개시의 예시에 따른 인공신경망 모델은, 떨림 감지 데이터를 입력으로 하여 영상 떨림을 보상하기 위해 카메 라 모듈에 포함된 이미지 센서의 이동을 제어하기 위한 제어 신호를 출력할 수 있다. 본 개시의 예시에 따른 사전 학습된 모델은, 떨림 감지 데이터를 기초로 에러 값이 상기 기 설정된 값을 수렴하 는 안정화 데이터를 추론하도록 학습된 제1 모델 및 추론된 안정화 데이터에 대한 가치를 평가하도록 학습된 제 2 모델을 포함할 수 있다. 본 개시의 다양한 예시에 따른 인공신경망 모델은, 떨림 감지 데이터를 입력으로 하여 안정화 데이터를 추론하 기 위한 학습과, 안정화 데이터에 대한 추론을 동시에 수행할 수 있다.본 개시의 다양한 예시에 따른 인공신경망 모델은, 떨림 감지 데이터가 입력되는 입력 노드, 합성곱 연산을 수 행하는 히든 레이어 및 안정화 데이터를 출력하는 출력 노드를 포함할 수 있다. 본 개시의 다양한 예시에 따른 프로세서는 학습을 통해 에러 값을 수집하고, 수집된 에러 값을 이용하여 인공신경망 모델을 업데이트할 수 있다. 본 개시의 다양한 예시에 따라 카메라 모듈은 온도를 측정하는 온도 센서를 더 포함하고, 프로세서는 떨림 감지 데이터 및 온도 센서를 통해 획득된 온도 데이터를 기초로 인공신경망 모델을 이용하여 안정화 데이터를 출력할 수 있다. 본 개시의 다양한 예시에 따라 떨림 감지 데이터는, 자이로 센서의 x축, y축 회전 움직임 및 홀 센서의 x축, y 축, z축 회전 움직임을 감지한 신호를 포함하고, 프로세서는 영상의 주파수 성분으로부터 디포커스량 데이 터를 획득하고, 떨림 감지 데이터 및 디포커스량 데이터를 기초로 상기 인공신경망 모델을 이용하여 상기 안정 화 데이터를 출력할 수 있다. 본 개시의 다양한 예시에 따라 인공신경망 모델은, 영상의 MTF(Modulation Transfer Function) 데이터를 학습을 위한 학습 데이터로서 사용할 수 있다. MTF 데이터는 디포커스량을 정량화 한 데이터 일 수 있다. 인공지능 기반의 이미지 안정화를 위한 프로세서는 적어도 하나의 프로세싱 엘리먼트, 및 적어도 하나의 프로세 싱 엘리먼트에 전기적으로 연결된 적어도 하나의 메모리를 포함하고, 프로세서는 떨림 감지 데이터를 획득하고, 상기 이미지의 흔들림을 보상하기 위한 안정화 데이터를 출력하도록 구성되고, 떨림 감지 데이터는 2개 이상의 센서로부터 획득되고, 안정화 데이터는 상기 떨림 감지 데이터에 기초하여 상기 안정화 데이터를 출력하도록 훈 련된 인공 신경망 모델을 이용하여 출력될 수 있다. 인공 신경망 모델은 강화학습(Reinforcement Learning)을 기반으로 훈련될 수 있다. 인공 신경망 모델에 대한 강화 학습을 위해 가상 떨림 감지 데이터가 제공될 수 있다. 가상 떨림 감지 데이터는 앉는 패턴, 걷는 패턴, 달리는 패턴, 선박의 움직임 패턴, 자동차의 움직임 패턴, 오 토바이의 움직임 패턴 중 적어도 하나를 포함할 수 있다. 떨림 감지 데이터는 2개 이상의 센서의 위치 변화를 감지하기 위한 신호를 포함할 수 있다. 2개 이상의 센서는 자이로 센서 및 홀 센서를 포함할 수 있다. 떨림 감지 데이터는 상기 2개 이상의 센서의 x축 및 y축 회전 움직임에 의해 감지된 신호를 포함할 수 있다. 프로세서는 인공 신경망 모델에 입력된 이미지의 디 포커스량 데이터를 더 획득할 수 있다. 인공 신경망 모델은 학습용 학습 데이터를 기반으로 상기 이미지의 흔들림에 따른 오차 값이 기 설정된 값을 수 렴하도록 사전 학습된 모델일 수 있다. 인공 신경망 모델은 떨림 감지 데이터가 입력되는 입력 노드, 상기 입력 노드의 인공지능 연산을 수행하는 히든 레이어 및 상기 안정화 데이터를 출력하는 출력 노드를 포함할 수 있다. 프로세서는 중앙처리장치(CPU)와 신경망처리장치(NPU)가 집적된 시스템 온 칩(SoC)으로 구현될 수 있다. 프로세서는 중앙 처리 장치(CPU), 애플리케이션 프로세서(AP), 마이크로 처리 장치(MPU), 마이크로 컨트롤러 유 닛(MCU), 이미지 신호 프로세서(ISP) 중 적어도 하나로 구현될 수 있다. 장치는 렌즈, 렌즈에 결합된 이미지 센서, 렌즈 또는 상기 이미지 센서에 결합되는 적어도 2개 이상의 센서 및 적어도 2개 이상의 센서로부터 상기 렌즈 또는 상기 이미지 센서에 대한 떨림 감지 데이터를 수신하여 학습된 인공 신경망 모델을 처리하여 안정화 데이터를 출력하는 프로세서를 포함할 수 있다. 장치는 상기 프로세서로부터 상기 안정화 데이터를 수신하여 제어 신호를 출력하는 VCM 드라이버(Voice Coil Motor Driver) 및 제어 신호를 이용하여 상기 렌즈 또는 상기 이미지 센서의 위치를 보상하는 VCM 액츄에이터 (Voice Coil Motor Actuator)를 더 포함할 수 있다. VCM 액츄에이터는 x축 및/또는 y축으로 상기 렌즈 또는 상기 이미지 센서의 위치를 제어하도록 구성될 수 있다. 프로세서는 인공 지능 연산을 수행하기 위한 곱셈 및 누산 연산자 및/또는 산술 논리 연산자를 포함하는 복수의 프로세싱 엘리먼트를 포함하고, 이미지 및 떨림 감지 데이터를 수신하고, 상기 이미지의 흔들림을 보상하기 위 한 안정화 데이터를 생성하도록 구성되고, 안정화 데이터는 프로세서에 의해 훈련된 인공 신경망 모델에 의해 추론될 수 있다. 인공 신경망 모델은 상기 떨림 감지 데이터 또는 가상 떨림 감지 데이터를 통해 학습될 수 있다. 안정화 데이터를 추론하기 위해 온도 데이터 및 디포커스 양 데이터 중 적어도 하나를 더 수신하도록 구성될 수 있다. VCM 액츄에이터(Voice Coil Motor Actuator)에 제어 신호를 출력하기 위해 상기 안정화 데이터는 VCM 드라이버 (Voice Coil Motor Driver)에 입력되, 상기 제어 신호는 상기 이미지의 흔들림을 보상하는 VCM 액츄에이터에 입 력될 수 있다. 본 명세서와 도면에 게시된 본 개시의 예시들은 본 개시의 기술내용을 쉽게 설명하고 본 개시의 이해를 돕기 위 해 특정 예를 제시한 것뿐이며, 본 명의 범위를 한정하고자 하는 것은 아니다. 여기에 게시된 예시들 이외에도 발명의 기술적 사상에 바탕을 둔 다른 변형 예들이 실시 가능하다는 것은 본 개시가 속하는 기술 분야에서 통상 의 지식을 가진 자에게 자명한 것이다."}
{"patent_id": "10-2024-0036477", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 개시의 일 예시에 따른 카메라 모듈이 포함된 장치를 설명하는 개략적인 개념도이다. 도 2는 본 개시의 일 예시에 따른 카메라 모듈을 설명하는 개략적인 개념도이다. 도 3은 본 개시의 일 예시에 따른 인공신경망 모델을 설명하는 개략적인 개념도이다. 도 4는 본 개시의 일 예시에 따른 인공신경망 모델의 학습 방법을 설명하는 개략적인 개념도이다. 도 5는 본 개시의 일 예시에 따른 인공신경망 모델의 구체적인 학습 동작을 설명하는 개략적인 개념도이다. 도 6은 본 개시의 일 예시에 따른 학습된 인공신경망 모델을 이용하여 영상 떨림을 보상하는 방법을 설명하는 개략적인 개념도이다. 도 7은 본 개시의 다른 예시에 따른 인공신경망 모델을 설명하는 개략적인 개념도이다. 도 8은 본 개시의 다른 예시에 따른 인공신경망 모델의 학습 방법을 설명하는 개략적인 개념도이다. 도 9는 본 개시의 다른 예시에 따른 학습된 인공신경망 모델을 이용하여 영상 떨림을 보상하는 방법을 설명하는 개략적인 개념도이다. 도 10은 본 개시의 또다른 예시에 따른 카메라 모듈을 설명하는 개략적인 개념도이다. 도 11은 본 개시의 또다른 예시에 따른 인공신경망 모델을 설명하는 개략적인 개념도이다. 도 12은 본 개시의 또다른 예시에 따른 인공신경망 모델의 학습 방법을 설명하는 개략적인 개념도이다. 도 13는 본 개시의 또다른 예시에 따른 인공신경망 모델의 구체적인 학습 동작을 설명하는 개략적인 개념도이다. 도 14는 본 개시의 다른 예시에 따른 학습된 인공신경망 모델을 이용하여 영상 떨림을 보상하는 방법을 설명하 는 개략적인 개념도이다. 도 15는 본 개시의 예시에 카메라 모듈에서 영상 안정화를 위한 방법을 설명하는 흐름도이다. 도 16은 본 개시에 따른 신경 프로세싱 유닛을 설명하는 개략적인 개념도이다."}
