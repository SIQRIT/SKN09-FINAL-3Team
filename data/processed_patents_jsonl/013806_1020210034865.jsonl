{"patent_id": "10-2021-0034865", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2022-0129927", "출원번호": "10-2021-0034865", "발명의 명칭": "음성 인식 서비스를 제공하는 전자 장치 및 방법", "출원인": "삼성전자주식회사", "발명자": "이호정"}}
{"patent_id": "10-2021-0034865", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "전자 장치가 음성 인식 서비스를 제공하는 방법에 있어서,상기 전자 장치의 화면 상에 복수의 객체들이 디스플레이되는 도중에 사용자의 음성 명령을 수신하는 단계;상기 음성 명령이 수신됨에 따라, 상기 화면 상에 디스플레이 되는 상기 복수의 객체들을 식별하는 단계;상기 복수의 객체들의 타입들에 기초하여, 상기 음성 명령으로부터 변환된 텍스트를 해석하는 단계; 및상기 텍스트의 해석 결과에 기초하여, 상기 복수의 객체들 중에서 선택된 객체와 관련된 동작을 수행하는 단계를 포함하며,상기 복수의 객체들의 타입들은, 상기 전자 장치에 대한 사용자 입력에 의해 선택 가능 한지 여부에 따라 구별되는, 방법."}
{"patent_id": "10-2021-0034865", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 음성 명령을 해석하는데 이용되는, 상기 복수의 객체들에 관련된 데이터 구조를 생성하는 단계를 더 포함하고,상기 복수의 객체들에 관련된 데이터 구조를 생성하는 단계는,상기 복수의 객체들에 대한 영상 처리를 통한 문자 판독 또는 상기 복수의 객체들을 제공하는 애플리케이션의메타 데이터 판독에 의해, 상기 복수의 객체들의 타입들을 식별하는 단계;상기 복수의 객체들의 타입들에 기초하여, 상기 복수의 객체들의 우선 순위를 결정하는 단계; 및상기 복수의 객체들과, 상기 복수의 객체들과 관련된 용어(term)들 간의 관계를 나타내는 트리 형태의 데이터구조를 생성하는 단계를 포함하는, 방법."}
{"patent_id": "10-2021-0034865", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,상기 복수의 객체들과 관련된 용어들은,상기 복수의 객체들에 포함되는 텍스트 정보, 또는 상기 복수의 객체들을 제공하는 애플리케이션의 메타 데이터에 포함되는 상기 복수의 객체들의 속성(attribute) 정보 중 적어도 하나로부터 획득되는 것을 특징으로 하는,방법."}
{"patent_id": "10-2021-0034865", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제2항에 있어서,상기 복수의 객체들은 이미지 정보 및 텍스트 정보 중 적어도 하나를 포함하고,상기 이미지 정보는 상기 화면의 오브젝트 레이어 상에 표시되고, 상기 텍스트 정보는 상기 화면의 텍스트 레이어 상에 표시되며,상기 오브젝트 레이어 및 상기 텍스트 레이어에 기초하여, 상기 복수의 객체들의 타입들이 식별되는 것을 특징으로 하는, 방법."}
{"patent_id": "10-2021-0034865", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제2항에 있어서, 공개특허 10-2022-0129927-3-상기 복수의 객체들의 타입들을 식별하는 단계는,상기 복수의 객체들이 상기 전자 장치에 대한 사용자 입력에 의해 선택 가능 한지 또는 선택 불가능 한지, 텍스트 정보를 포함하는 지 또는 텍스트 정보를 포함하지 않는 지를 구분하는 단계를 포함하는, 방법."}
{"patent_id": "10-2021-0034865", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서,상기 음성 명령을 해석하는데 이용되는, 상기 복수의 객체들에 관련된 데이터 구조를 생성하는 단계를 더 포함하고,상기 음성 명령이 수신됨에 따라, 상기 화면 상에 디스플레이 되는 상기 복수의 객체들을 식별하는 단계는,상기 음성 명령으로부터 변환된 텍스트로부터 상기 사용자의 발화 의도의 타입을 결정하는 단계; 및상기 발화 의도의 타입 및 상기 복수의 객체들의 타입들에 기초하여, 상기 데이터 구조의 상기 복수의 객체들의우선 순위를 다시 결정하는 단계를 포함하는, 방법."}
{"patent_id": "10-2021-0034865", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에 있어서,상기 음성 명령으로부터 텍스트를 획득하는 단계;상기 텍스트로부터 상기 사용자의 발화 의도의 타입을 결정하는 단계; 및상기 발화 의도의 타입에 기초하여 제1모드로 동작할 지 또는 제2모드로 동작할 지 여부를 판단하는 단계를 더포함하고,상기 제1모드에서 상기 전자 장치는 상기 화면 상에 디스플레이 되는 복수의 객체들의 타입들에 기초하여 생성된 데이터 구조를 고려하여 상기 텍스트에 대한 자연어 이해를 수행하고, 상기 제2모드에서 상기 전자 장치는상기 복수의 객체들의 타입들에 기초하여 생성된 데이터 구조를 고려하지 않고 상기 텍스트에 대한 자연어 이해를 수행하는 것을 특징으로 하는, 방법."}
{"patent_id": "10-2021-0034865", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1항에 있어서,상기 음성 명령으로부터 텍스트를 획득하는 단계;상기 텍스트에 활성화 단어가 포함되는 지 여부에 기초하여 제1모드로 동작할 지 또는 제2모드로 동작할 지 여부를 판단하는 단계를 더 포함하고,상기 제1모드에서 상기 전자 장치는 상기 화면 상에 디스플레이 되는 복수의 객체들의 타입들에 기초하여 생성된 데이터 구조를 고려하여 상기 텍스트에 대한 자연어 이해를 수행하고, 상기 제2모드에서 상기 전자 장치는상기 복수의 객체들의 타입들에 기초하여 생성된 데이터 구조를 고려하지 않고 상기 텍스트에 대한 자연어 이해를 수행하는 것을 특징으로 하는, 방법."}
{"patent_id": "10-2021-0034865", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1항에 있어서,상기 텍스트 해석 결과는, 상기 텍스트에 기초하여 결정되는 상기 사용자의 발화 의도, 상기 복수의 객체들 중에서 선택된 객체, 및 상기사용자의 발화 의도에 따라 상기 전자 장치가 상기 선택된 객체와 관련하여 실행해야 할 기능 중 적어도 하나에대한 정보를 포함하는 것을 특징으로 하는 방법."}
{"patent_id": "10-2021-0034865", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제1항에 있어서,공개특허 10-2022-0129927-4-상기 복수의 객체들 중에서 선택된 객체와 관련된 동작은,상기 선택된 객체와 관련된 비디오의 재생, 상기 선택된 객체와 관련된 이미지 또는 텍스트를 확대하여 디스플레이, 또는 상기 선택된 객체에 포함되는 텍스트로부터 음성 출력 중 적어도 하나의 동작을 포함하는, 방법."}
{"patent_id": "10-2021-0034865", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제1항에 있어서,상기 복수의 객체들 중에서 선택된 객체와 관련된 동작을 수행하는 단계는,상기 사용자의 음성 명령에 응답하여, 상기 선택된 객체와 관련된 응답 메시지를 생성하고 출력하는 단계를 포함하는, 방법."}
{"patent_id": "10-2021-0034865", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "음성 인식 서비스를 제공하는 전자 장치에 있어서,디스플레이;수신부; 하나 이상의 명령어를 저장하는 메모리; 및 상기 저장된 하나 이상의 명령어를 실행하여 음성 인식 서비스를 제공하는 적어도 하나의 프로세서를 포함하고,상기 적어도 하나의 프로세서는, 상기 디스플레이의 화면 상에 복수의 객체들이 디스플레이되는 도중에 상기 수신부를 통해 사용자의 음성 명령을 수신하고, 상기 음성 명령이 수신됨에 따라, 상기 화면 상에 디스플레이 되는 상기 복수의 객체들을 식별하고, 상기 복수의 객체들의 타입들에 기초하여, 상기 음성 명령으로부터 변환된 텍스트를 해석하고, 상기 텍스트의 해석 결과에 기초하여, 상기 복수의 객체들 중에서 선택된 객체와 관련된 동작을 수행하고,상기 복수의 객체들의 타입들은, 상기 전자 장치에 대한 사용자 입력에 의해 선택 가능 한지 여부에 따라 구별되는 것을 특징으로 하는, 전자 장치."}
{"patent_id": "10-2021-0034865", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제12항에 있어서,상기 적어도 하나의 프로세서는, 상기 음성 명령을 해석하는데 이용되는 상기 복수의 객체들에 관련된 데이터 구조를 생성하도록 구성되고,상기 복수의 객체들에 대한 영상 처리를 통한 문자 판독 또는 상기 복수의 객체들을 제공하는 애플리케이션의메타 데이터 판독에 의해, 상기 복수의 객체들의 타입들을 식별하고, 상기 복수의 객체들의 타입들에 기초하여,상기 복수의 객체들의 우선 순위를 결정함으로써, 상기 복수의 객체들과, 상기 복수의 객체들과 관련된 용어들간의 관계를 나타내는 트리 형태의 데이터 구조를 생성하는 것을 특징으로 하는, 전자 장치."}
{"patent_id": "10-2021-0034865", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제12항에 있어서,상기 복수의 객체들과 관련된 용어들은,상기 복수의 객체들에 포함되는 텍스트 정보, 또는 상기 복수의 객체들을 제공하는 애플리케이션의 메타 데이터에 포함되는 상기 복수의 객체들의 속성(attribute) 정보 중 적어도 하나로부터 획득되는 것을 특징으로 하는,전자 장치."}
{"patent_id": "10-2021-0034865", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제13항에 있어서, 상기 적어도 하나의 프로세서는,공개특허 10-2022-0129927-5-상기 복수의 객체들이 상기 전자 장치에 대한 사용자 입력에 의해 선택 가능 한지 또는 선택 불가능 한지, 텍스트 정보를 포함하는 지 또는 텍스트 정보를 포함하지 않는 지를 구분함으로써, 상기 복수의 객체들의 타입들을식별하는 것을 특징으로 하는, 전자 장치."}
{"patent_id": "10-2021-0034865", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제12항에 있어서,상기 적어도 하나의 프로세서는, 상기 음성 명령을 해석하는데 이용되는 상기 복수의 객체들에 관련된 데이터 구조를 생성하고,상기 음성 명령이 수신됨에 따라, 상기 화면 상에 디스플레이 되는 상기 복수의 객체들을 식별하기 위하여, 상기 음성 명령으로부터 변환된 텍스트로부터 상기 사용자의 발화 의도의 타입을 결정하고, 상기 발화 의도의 타입 및 상기 복수의 객체들의 타입들에 기초하여, 상기 데이터 구조의 상기 복수의 객체들의 우선 순위를 다시결정하는 것을 특징으로 하는, 전자 장치."}
{"patent_id": "10-2021-0034865", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제12항에 있어서,상기 적어도 하나의 프로세서는,상기 음성 명령으로부터 텍스트를 획득하고,상기 텍스트로부터 상기 사용자의 발화 의도의 타입을 결정하고,상기 발화 의도의 타입에 기초하여 제1모드로 동작할 지 또는 제2모드로 동작할 지 여부를 판단하도록구성되고,상기 제1모드에서 상기 전자 장치는, 상기 화면 상에 디스플레이 되는 복수의 객체들의 타입들에 기초하여 생성된 데이터 구조를 고려하여, 상기 텍스트에 대한 자연어 이해를 수행하고, 상기 제2모드에서 상기 전자 장치는상기 복수의 객체들의 타입들에 기초하여 생성된 데이터 구조를 고려하지 않고 상기 텍스트에 대한 자연어 이해를 수행하는 것을 특징으로 하는, 전자 장치."}
{"patent_id": "10-2021-0034865", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제12항에 있어서,상기 적어도 하나의 프로세서는,상기 음성 명령으로부터 텍스트를 획득하고,상기 텍스트에 활성화 단어가 포함되는 지 여부에 기초하여 제1모드로 동작할 지 또는 제2모드로 동작할 지 여부를 판단하도록 구성되고,상기 제1모드에서 상기 전자 장치는 상기 화면 상에 디스플레이 되는 복수의 객체들의 타입들에 기초하여 생성된 데이터 구조를 고려하여 상기 텍스트에 대한 자연어 이해를 수행하고, 상기 제2모드에서 상기 전자 장치는상기 복수의 객체들의 타입들에 기초하여 생성된 데이터 구조를 고려하지 않고 상기 텍스트에 대한 자연어 이해를 수행하는 것을 특징으로 하는, 전자 장치."}
{"patent_id": "10-2021-0034865", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제12항에 있어서,상기 복수의 객체들 중에서 선택된 객체와 관련된 동작은,상기 선택된 객체와 관련된 비디오의 재생, 상기 선택된 객체와 관련된 이미지 또는 텍스트를 확대하여 디스플레이, 또는 상기 선택된 객체에 포함되는 텍스트로부터 음성 출력 중 적어도 하나의 동작을 포함하는, 전자 장치."}
{"patent_id": "10-2021-0034865", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "공개특허 10-2022-0129927-6-디스플레이를 포함하는 전자 장치를 통해 음성 인식 서비스를 제공하는 서버에 있어서,상기 전자 장치와 통신하기 위한 통신 인터페이스;하나 이상의 명령어를 저장하는 메모리; 및 상기 메모리에 저장된 하나 이상의 명령어를 실행하는 적어도 하나의 프로세서를 포함하고, 상기 적어도 하나의 프로세서는,상기 전자 장치의 화면 상에 복수의 객체들이 디스플레이되는 도중에 상기 전자 장치를 통해 수신된 사용자의음성 명령에 관한 정보를 수신하고, 상기 음성 명령이 수신됨에 따라, 상기 화면 상에 디스플레이 되는 상기 복수의 객체들을 식별하고, 상기 복수의 객체들의 타입들에 기초하여, 상기 음성 명령으로부터 변환된 텍스트를해석하고, 상기 텍스트 해석 결과에 기초하여, 상기 적어도 하나의 객체 중에서 선택된 객체와 관련된 동작을수행하도록 상기 전자 장치를 제어하고,상기 복수의 객체들의 타입들은, 상기 전자 장치에 대한 사용자 입력에 의해 선택 가능 한지 여부에 따라 구별되는 것을 특징으로 하는, 서버."}
{"patent_id": "10-2021-0034865", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "일 실시 예에 따르면 전자 장치가 음성 인식 서비스를 제공하는 방법은, 상기 전자 장치의 화면 상에 복수의 객 체들이 디스플레이되는 도중에 사용자의 음성 명령을 수신하는 단계; 상기 음성 명령이 수신됨에 따라, 상기 화 면 상에 디스플레이 되는 상기 복수의 객체들을 식별하는 단계; 상기 복수의 객체들의 타입들에 기초하여, 상기 음성 명령으로부터 변환된 텍스트를 해석하는 단계; 및 상기 텍스트의 해석 결과에 기초하여, 상기 복수의 객체 들 중에서 선택된 객체와 관련된 동작을 수행하는 단계를 포함하며, 상기 복수의 객체들의 타입들은, 상기 전자 장치에 대한 사용자 입력에 의해 선택 가능 한지 여부에 따라 구별될 수 있다."}
{"patent_id": "10-2021-0034865", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 음성 인식 서비스를 제공하는 전자 장치 및 방법에 관한 것으로서, 보다 상세하게는 화면 상에 디스 플레이 되는 컨텐츠에 기초하여 음성 인식 서비스를 제공하는 전자 장치 및 방법에 관한 것이다."}
{"patent_id": "10-2021-0034865", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "최근에 스마트 폰과 같이 다양한 기능을 복합적으로 수행하는 전자 장치들이 개발됨에 따라, 조작성을 향상시키 기 위하여 음성 인식이 가능한 전자 장치들이 출시되고 있다. 음성 인식 기술은, 사용자가 발화하는 음성 명령의 의미 내용을 컴퓨터 등의 전자 장치가 자동적으로 인식하는 기술을 의미한다. 일 예로서, 음성 인식 기술은, 스마트 스피커, 스마트 폰, 컴퓨터, PDA(personal digital assistants), PMP(portable multimedia player), 스마트 가전, 네비게이션, 웨어러블 디바이스 등과 같은 전자 장치의 다양한 기능을 사용자의 버튼 조작 또는 터치 스크린 접촉 없이도 손쉽게 실행할 수 있도록 하는 장점을 갖는다. 또한, 인공 지능(Artificial Intelligence, AI) 기술이 발전함에 따라 음성 인식 기능에도 인공 지능 기술이 접 목됨으로써, 다양한 발화들에 대해서 빠르고 정확한 음성 인식이 가능해졌다. 인공 지능 시스템은 인간 수준의 지능을 구현하는 컴퓨터 시스템이며, 기존 룰(rule) 기반 스마트 시스템과 달리 기계가 스스로 학습하고 판단하 며 똑똑해지는 시스템이다. 인공지능 시스템은 사용할 수록 인식률이 향상되고 사용자의 취향을 보다 정확하게 이해할 수 있게 되어, 기존의 룰 기반 스마트 시스템은 점차 딥러닝 기반 인공지능 시스템으로 대체되고 있다."}
{"patent_id": "10-2021-0034865", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "일반적으로 음성 인식 기술은, 신규한 컨텐츠의 명칭, 또는 새롭게 설치된 애플리케이션의 기능과 같이 충분히 학습되지 않은 데이터와 관련된 사용자의 발화를 인식하는 성능이 떨어질 수 있다. 따라서, 사용자가 이용하고 있는 애플리케이션의 기능 또는 사용자가 보고 있는 화면 내의 기능과 연관된 사용자의 발화 의도를 정확히 파 악하고, 사용자의 발화 의도에 따른 동작을 수행하도록 하는 기술이 요구되고 있다."}
{"patent_id": "10-2021-0034865", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상술한 기술적 과제를 달성하기 위한 기술적 수단으로서, 본 개시의 일 측면은 전자 장치가 음성 인식 서비스를 제공하는 방법에 있어서, 상기 전자 장치의 화면 상에 복수의 객체들이 디스플레이되는 도중에 사용자의 음성 명령을 수신하는 단계; 상기 음성 명령이 수신됨에 따라, 상기 화면 상에 디스플레이 되는 상기 복수의 객체들을 식별하는 단계; 상기 복수의 객체들의 타입들에 기초하여, 상기 음성 명령으로부터 변환된 텍스트를 해석하 는 단계; 및 상기 텍스트의 해석 결과에 기초하여, 상기 복수의 객체들 중에서 선택된 객체와 관련된 동작을 수 행하는 단계를 포함하며, 상기 복수의 객체들의 타입들은, 상기 전자 장치에 대한 사용자 입력에 의해 선택 가 능 한지 여부에 따라 구별되는, 방법을 제공할 수 있다. 또한 본 개시의 일 실시 예에서 상기 음성 명령을 해석하는데 이용되는, 상기 복수의 객체들에 관련된 데이터 구조를 생성하는 단계를 더 포함하고, 상기 복수의 객체들에 관련된 데이터 구조를 생성하는 단계는, 상기 복수 의 객체들에 대한 영상 처리를 통한 문자 판독 또는 상기 복수의 객체들을 제공하는 애플리케이션의 메타 데이 터 판독에 의해, 상기 복수의 객체들의 타입들을 식별하는 단계; 상기 복수의 객체들의 타입들에 기초하여, 상 기 복수의 객체들의 우선 순위를 결정하는 단계; 및 상기 복수의 객체들과, 상기 복수의 객체들과 관련된 용어 (term)들 간의 관계를 나타내는 트리 형태의 데이터 구조를 생성하는 단계를 포함하는, 방법을 제공할 수 있다. 또한 본 개시의 일 실시 예에서 상기 복수의 객체들과 관련된 용어들은, 상기 복수의 객체들에 포함되는 텍스 트 정보, 또는 상기 복수의 객체들을 제공하는 애플리케이션의 메타 데이터에 포함되는 상기 복수의 객체들의 속성(attribute) 정보 중 적어도 하나로부터 획득되는 것을 특징으로 하는, 방법을 제공할 수 있다. 또한 본 개시의 일 실시 예에서 상기 복수의 객체들은 이미지 정보 및 텍스트 정보 중 적어도 하나를 포함하고, 상기 이미지 정보는 상기 화면의 오브젝트 레이어 상에 표시되고, 상기 텍스트 정보는 상기 화면의 텍스트 레이어 상에 표시되며, 상기 오브젝트 레이어 및 상기 텍스트 레이어에 기초하여, 상기 복수의 객체들의 타입들이 식별되는 것을 특징으로 하는, 방법을 제공할 수 있다. 또한 본 개시의 일 실시 예에서 상기 복수의 객체들이 상기 전자 장치에 대한 사용자 입력에 의해 선택 가능 한지 또는 선택 불가능 한지, 텍스트 정보를 포함하는 지 또는 텍스트 정보를 포함하지 않는 지를 구분하는 단 계를 포함하는, 방법을 제공할 수 있다. 또한 본 개시의 일 실시 예에서 상기 음성 명령을 해석하는데 이용되는, 상기 복수의 객체들에 관련된 데이터 구조를 생성하는 단계를 더 포함하고, 상기 음성 명령이 수신됨에 따라, 상기 화면 상에 디스플레이 되는 상기 복수의 객체들을 식별하는 단계는, 상기 음성 명령으로부터 변환된 텍스트로부터 상기 사용자의 발화 의도의 타 입을 결정하는 단계; 및 상기 발화 의도의 타입 및 상기 복수의 객체들의 타입들에 기초하여, 상기 데이터 구조 의 상기 복수의 객체들의 우선 순위를 다시 결정하는 단계를 포함하는, 방법을 제공할 수 있다. 또한 본 개시의 일 실시 예에서 상기 음성 명령으로부터 텍스트를 획득하는 단계; 상기 텍스트로부터 상기 사 용자의 발화 의도의 타입을 결정하는 단계; 및 상기 발화 의도의 타입에 기초하여 제1모드로 동작할 지 또는 제 2모드로 동작할 지 여부를 판단하는 단계를 더 포함하고, 상기 제1모드에서 상기 전자 장치는 상기 화면 상에 디스플레이 되는 복수의 객체들의 타입들에 기초하여 생성된 데이터 구조를 고려하여 상기 텍스트에 대한 자연 어 이해를 수행하고, 상기 제2모드에서 상기 전자 장치는 상기 복수의 객체들의 타입들에 기초하여 생성된 데이 터 구조를 고려하지 않고 상기 텍스트에 대한 자연어 이해를 수행하는 것을 특징으로 하는, 방법을 제공할 수 있다. 또한 본 개시의 일 실시 예에서 상기 음성 명령으로부터 텍스트를 획득하는 단계; 상기 텍스트에 활성화 단어 가 포함되는 지 여부에 기초하여 제1모드로 동작할 지 또는 제2모드로 동작할 지 여부를 판단하는 단계를 더 포 함하고, 상기 제1모드에서 상기 전자 장치는 상기 화면 상에 디스플레이 되는 복수의 객체들의 타입들에 기초하 여 생성된 데이터 구조를 고려하여 상기 텍스트에 대한 자연어 이해를 수행하고, 상기 제2모드에서 상기 전자 장치는 상기 복수의 객체들의 타입들에 기초하여 생성된 데이터 구조를 고려하지 않고 상기 텍스트에 대한 자연 어 이해를 수행하는 것을 특징으로 하는, 방법을 제공할 수 있다. 또한 본 개시의 일 실시 예에서 상기 텍스트 해석 결과는, 상기 텍스트에 기초하여 결정되는 상기 사용자의 발 화 의도, 상기 복수의 객체들 중에서 선택된 객체, 및 상기 사용자의 발화 의도에 따라 상기 전자 장치가 상기 선택된 객체와 관련하여 실행해야 할 기능 중 적어도 하나에 대한 정보를 포함하는 것을 특징으로 하는 방법을 제공할 수 있다. 또한 본 개시의 일 실시 예에서 상기 복수의 객체들 중에서 선택된 객체와 관련된 동작은, 상기 선택된 객체와 관련된 비디오의 재생, 상기 선택된 객체와 관련된 이미지 또는 텍스트를 확대하여 디스플레이, 또는 상기 선택 된 객체에 포함되는 텍스트로부터 음성 출력 중 적어도 하나의 동작을 포함하는, 방법을 제공할 수 있다. 또한 본 개시의 일 실시 예에서 상기 복수의 객체들 중에서 선택된 객체와 관련된 동작을 수행하는 단계는, 상 기 사용자의 음성 명령에 응답하여, 상기 선택된 객체와 관련된 응답 메시지를 생성하고 출력하는 단계를 포함하는, 방법을 제공할 수 있다. 본 개시의 다른 측면은 음성 인식 서비스를 제공하는 전자 장치에 있어서, 디스플레이; 수신부; 하나 이상의 명령어를 저장하는 메모리; 및 상기 저장된 하나 이상의 명령어를 실행하여 음성 인식 서비스를 제공하는 적어 도 하나의 프로세서를 포함하고, 상기 적어도 하나의 프로세서는, 상기 디스플레이의 화면 상에 복수의 객체들 이 디스플레이되는 도중에 상기 수신부를 통해 사용자의 음성 명령을 수신하고, 상기 음성 명령이 수신됨에 따 라, 상기 화면 상에 디스플레이 되는 상기 복수의 객체들을 식별하고, 상기 복수의 객체들의 타입들에 기초하여, 상기 음성 명령으로부터 변환된 텍스트를 해석하고, 상기 텍스트의 해석 결과에 기초하여, 상기 복수 의 객체들 중에서 선택된 객체와 관련된 동작을 수행하고, 상기 복수의 객체들의 타입들은, 상기 전자 장치에 대한 사용자 입력에 의해 선택 가능 한지 여부에 따라 구별되는 것을 특징으로 하는, 전자 장치를 제공할 수 있 다. 또한 본 개시의 일 실시 예에서 상기 적어도 하나의 프로세서는, 상기 음성 명령을 해석하는데 이용되는 상기 복수의 객체들에 관련된 데이터 구조를 생성하도록 구성되고, 상기 복수의 객체들에 대한 영상 처리를 통한 문 자 판독 또는 상기 복수의 객체들을 제공하는 애플리케이션의 메타 데이터 판독에 의해, 상기 복수의 객체들의 타입들을 식별하고, 상기 복수의 객체들의 타입들에 기초하여, 상기 복수의 객체들의 우선 순위를 결정함으로써, 상기 복수의 객체들과, 상기 복수의 객체들과 관련된 용어들 간의 관계를 나타내는 트리 형태의 데이터 구조를 생성하는 것을 특징으로 하는, 전자 장치를 제공할 수 있다. 또한 본 개시의 일 실시 예에서 상기 적어도 하나의 프로세서는, 상기 복수의 객체들이 상기 전자 장치에 대한 사용자 입력에 의해 선택 가능 한지 또는 선택 불가능 한지, 텍스트 정보를 포함하는 지 또는 텍스트 정보를 포 함하지 않는 지를 구분함으로써, 상기 복수의 객체들의 타입들을 식별하는 것을 특징으로 하는, 전자 장치를 제 공할 수 있다. 또한 본 개시의 일 실시 예에서 상기 적어도 하나의 프로세서는, 상기 음성 명령을 해석하는데 이용되는 상기 복수의 객체들에 관련된 데이터 구조를 생성하고, 상기 음성 명령이 수신됨에 따라, 상기 화면 상에 디스플레이 되는 상기 복수의 객체들을 식별하기 위하여, 상기 음성 명령으로부터 변환된 텍스트로부터 상기 사용자의 발화 의도의 타입을 결정하고, 상기 발화 의도의 타입 및 상기 복수의 객체들의 타입들에 기초하여, 상기 데이터 구 조의 상기 복수의 객체들의 우선 순위를 다시 결정하는 것을 특징으로 하는, 전자 장치를 제공할 수 있다. 또한 본 개시의 일 실시 예에서 상기 적어도 하나의 프로세서는, 상기 음성 명령으로부터 텍스트를 획득하고, 상기 텍스트로부터 상기 사용자의 발화 의도의 타입을 결정하고, 상기 발화 의도의 타입에 기초하여 제1모드로 동작할 지 또는 제2모드로 동작할 지 여부를 판단하도록 구성되고, 상기 제1모드에서 상기 전자 장치는, 상기 화면 상에 디스플레이 되는 복수의 객체들의 타입들에 기초하여 생성된 데이터 구조를 고려하여, 상기 텍스트에 대한 자연어 이해를 수행하고, 상기 제2모드에서 상기 전자 장치는 상기 복수의 객체들의 타입들에 기초하여 생 성된 데이터 구조를 고려하지 않고 상기 텍스트에 대한 자연어 이해를 수행하는 것을 특징으로 하는, 전자 장치 를 제공할 수 있다. 또한 본 개시의 일 실시 예에서 상기 적어도 하나의 프로세서는, 상기 음성 명령으로부터 텍스트를 획득하고, 상기 텍스트에 활성화 단어가 포함되는 지 여부에 기초하여 제1모드로 동작할 지 또는 제2모드로 동작할 지 여 부를 판단하도록 구성되고, 상기 제1모드에서 상기 전자 장치는 상기 화면 상에 디스플레이 되는 복수의 객체들 의 타입들에 기초하여 생성된 데이터 구조를 고려하여 상기 텍스트에 대한 자연어 이해를 수행하고, 상기 제2모 드에서 상기 전자 장치는 상기 복수의 객체들의 타입들에 기초하여 생성된 데이터 구조를 고려하지 않고 상기 텍스트에 대한 자연어 이해를 수행하는 것을 특징으로 하는, 전자 장치를 제공할 수 있다. 또한 본 개시의 일 실시 예에서 상기 복수의 객체들 중에서 선택된 객체와 관련된 동작은, 상기 선택된 객체와 관련된 비디오의 재생, 상기 선택된 객체와 관련된 이미지 또는 텍스트를 확대하여 디스플레이, 또는 상기 선택 된 객체에 포함되는 텍스트로부터 음성 출력 중 적어도 하나의 동작을 포함하는, 전자 장치를 제공할 수 있다. 본 개시의 다른 측면은 디스플레이를 포함하는 전자 장치를 통해 음성 인식 서비스를 제공하는 서버에 있어서, 상기 전자 장치와 통신하기 위한 통신 인터페이스; 하나 이상의 명령어를 저장하는 메모리; 및 상기 메모리에 저장된 하나 이상의 명령어를 실행하는 적어도 하나의 프로세서를 포함하고, 상기 적어도 하나의 프로세서는, 상기 전자 장치의 화면 상에 복수의 객체들이 디스플레이되는 도중에 상기 전자 장치를 통해 수신된 사용자의 음성 명령에 관한 정보를 수신하고, 상기 음성 명령이 수신됨에 따라, 상기 화면 상에 디스플레이 되는 상기 복 수의 객체들을 식별하고, 상기 복수의 객체들의 타입들에 기초하여, 상기 음성 명령으로부터 변환된 텍스트를해석하고, 상기 텍스트 해석 결과에 기초하여, 상기 적어도 하나의 객체 중에서 선택된 객체와 관련된 동작을 수행하도록 상기 전자 장치를 제어하고, 상기 복수의 객체들의 타입들은, 상기 전자 장치에 대한 사용자 입력에 의해 선택 가능 한지 여부에 따라 구별되는 것을 특징으로 하는, 서버를 제공할 수 있다."}
{"patent_id": "10-2021-0034865", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "아래에서는 첨부한 도면을 참조하여 본 개시가 속하는 기술 분야에서 통상의 지식을 가진 자가 용이하게 실시할 수 있도록 본 개시의 실시 예를 상세히 설명한다. 그러나 본 개시는 여러 가지 상이한 형태로 구현될 수 있으며 여기에서 설명하는 실시 예에 한정되지 않는다. 그리고 도면에서 본 개시를 명확하게 설명하기 위해서 설명과 관계없는 부분은 생략하였으며, 명세서 전체를 통하여 유사한 부분에 대해서는 유사한 도면 부호를 붙였다. 명세서 전체에서, 어떤 부분이 다른 부분과 \"연결\"되어 있다고 할 때, 이는 \"직접적으로 연결\"되어 있는 경우뿐 아니라, 그 중간에 다른 소자를 사이에 두고 \"전기적으로 연결\"되어 있는 경우도 포함한다. 또한 어떤 부분이 어떤 구성요소를 \"포함\"한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다른 구성요소를 제외하는 것이 아 니라 다른 구성요소를 더 포함할 수 있는 것을 의미한다. 본 개시에서 음성 인식 서비스는, 사용자가 발화하는 음성 명령의 의미를 전자 장치, 또는 서버 등이 자동적으 로 인식하고, 인식 결과에 따라 다양한 기능을 제공하는 서비스일 수 있다. 예를 들어, 음성 인식 서비스에 의 하면, 사용자가 음성 명령에 의해 전자 장치의 동작을 제어하거나, 사용자가 직접 전자 장치와 대화하는 것처럼응답 메시지를 전자 장치로부터 제공 받을 수 있다. 이하 첨부된 도면을 참고하여 본 개시를 상세히 설명하기로 한다. 도 1은 일반적인 전자 장치가 사용자의 음성 명령을 이해하지 못하는 경우를 설명한다. 일반적인 음성 인식 서비스를 제공하는 전자 장치는, 사용자의 음성 명령에 기초하여 애플리케이션을 실행할 수는 있으나, 애플리케이션의 실행 화면이 로딩(load)된 후에는 로딩된 화면과 연관된 음성 인식 기능을 지원하지 않는다. 예를 들어, 전자 장치가 애플리케이션을 실행하면, 텍스트 또는 이미지 등의 형태로 컨텐 츠와 관련된 기능을 표시하는 실행 화면이 로딩될 수 있다. 이 때, 전자 장치는, 실행 화면 내에 표시 된 기능과 관련된 음성 명령의 인식을 지원하지 못한다. 따라서, 본 개시는, 일반적인 음성 인식 서비스를 제공하 는 전자 장치가 화면과 연관된 음성 인식 기능을 지원하지 못하는 문제를 해결하기 위한 것이다. 또한, 일반적인 음성 인식 서비스를 제공하는 전자 장치는, 신규한 컨텐츠의 명칭, 또는 새롭게 설치된 애 플리케이션의 기능과 같이 충분히 학습되지 않은 데이터와 관련된 사용자의 음성 명령을 인식하는 성능이 떨어 질 수 있다. 그러나, 음성 인식 성능을 높이기 위해서, 신규한 컨텐츠의 명칭, 또는 새롭게 설치된 애플리케이 션의 기능과 같이 모든 신규한 데이터를 학습하는 것은 자원의 제약으로 인한 어려움이 있다. 따라서, 음성 인식 서비스를 제공하는 전자 장치가, 사용자에게 제공되는 화면에 연속적인 사용자의 음성 명령 을 정확하게 인식하기 위해서, 사용자의 음성 명령 또는 음성 명령의 음성 인식 결과를 애플리케이션의 기능과 매핑하는 기술의 개발이 요구된다. 예를 들어, 음성 명령과 매핑되는 애플리케이션의 기능은, API(application programming interface) 형태로 표현될 수 있다. 음성 명령(또는, 음성 명령의 음성 인식 결과)과 애플리케이션 의 기능 간의 매핑은, 음성 명령(또는, 음성 명령의 음성 인식 결과)에 따라 API를 호출할 수 있도록 구현된 논 리적 코드 또는 조회 테이블(look-up table)의 형태로 표현될 수 있다. 도 2는 본 개시의 일 실시 예에 따른 전자 장치가 화면 상에 디스플레이 되는 객체를 고려하여 사용자의 음성 명령에 대한 음성 인식 서비스를 제공하는 방법을 설명한다. 본 개시의 일 실시 예에 따른 전자 장치는, TV, 스마트폰 등 디스플레이를 구비한 전자 장치를 포함할 수 있다. 일 실시 예에 따른 전자 장치는, 사용자가 발화한 음성 명령을 수신하면, 화면 상에 디스플레이 되고 있는 텍스트, 및 화면을 구성하는 출력 레이어에 기초하여 사용자의 음성 명령을 해석할 수 있다. 예를 들 어, 전자 장치는, 화면 상에 디스플레이 되는 텍스트의 내용 및 위치 중 적어도 하나에 기초하여 사용자의 음성 명령을 해석할 수 있다. 일 실시 예에 따른 전자 장치는, 애플리케이션의 실행 화면 내에서 제공되는 기능과 연관된 사용자의 음성 명령을 정확하게 이해하기 위하여, 실행 화면 상에 디스플레이 되는 객체를 고려할 수 있다. 객체란, 애플리케이션의 실행 화면 상에서 사용자에게 텍스트 또는 이미지 등의 형태로 제공되는 정보, 애플리 케이션의 기능을 사용자가 선택할 수 있도록 제공되는 화면의 구성 요소, 또는 그 구성 요소와 관련된 정보(예 를 들어, 텍스트 정보, 이미지 정보, 메타 데이터 등)를 모두 포함한 개념이다. 예를 들어, 객체는, 화면 내의 소정 영역 내에 표시되는 텍스트, 화면 내의 소정 영역 내에 표시되는 이미지, 아이콘, 또는 메뉴 중 적어도 하 나를 포함할 수 있다. 일 실시 예에 따르면, 전자 장치는, 애플리케이션의 메타 데이터 및 화면에 대한 영상 처리를 통한 문자 인식 결과를 이용하여, 객체들에 대한 정보를 포함하는 데이터 구조를 생성할 수 있다. 전자 장치의 운영 체제(operating system, OS)는, 사용자의 음성 명령을 해석하기 위해, 생성된 데이터 구조를 이용할 수 있다. 일 실시 예에 따르면, 전자 장치는, 객체들에 대한 정보를 포함하는 데이터 구조를 검색 및 정렬이 가능한 형태로 정의하여 저장할 수 있다. 예를 들어, 데이터 구조의 형태는 그래프, 조회 테이블, 연결 리스트, 또는 트리의 형태를 가질 수 있다. 도 2에 도시된 바와 같이, 본 개시의 일 실시 예에 따른 전자 장치의 화면은 두 개의 레이어(202, 203)로 구분될 수 있다. 오브젝트 레이어는 화면 상에 표시되는 선택 가능 객체와 선택 불가능 객체에 대 한 정보를 포함할 수 있다. 텍스트 레이어는, 화면 상에 표시되는 텍스트 컨텐츠, 화면 상에 표시되는 이 미지로부터 문자 인식을 통해 인식되는 텍스트 컨텐츠, 또는 객체의 메타데이터로부터 인식되는 텍스트 컨텐츠 에 대한 정보를 포함할 수 있다. 오브젝트 레이어 및 텍스트 레이어에 기초하여, 객체의 타입이 식별 될 수 있다.일 실시 예에 따른 전자 장치는, 객체가 선택 가능한 타입인지 선택 불가능한 타입인지 판단하거나, 객체 가 텍스트 타입인지 또는 해석가능(interpretable) 타입인지 판단할 수 있다. 선택 가능 타입이란, 디스플레이 되는 유저 인터페이스 상에서 선택될 수 있는 객체의 타입을 의미하고, 선택 불가능 타입이란, 선택할 수 없는 고정된 객체의 타입을 의미할 수 있다. 또한, 텍스트 타입이란, 텍스트 정보를 포함하는 객체의 타입을 의미하 고, 해석가능 객체란, 텍스트가 추출되거나 텍스트 정보를 포함하지는 않지만, 영상 처리를 통한 화면 인식 또 는 메타 데이터 등을 통해 해석 가능한 이미지를 포함하는 객체의 타입을 의미할 수 있다. 해석가능 객체는, 논 -텍스트 객체, 이미지 객체 등으로 지칭될 수 있다 일 실시 예에 따른 전자 장치는, 음성 명령을 해석하는데 이용하기 위하여, 화면에 디스플레이 되는 하나 이상의 객체들에 관련된 데이터 구조를 생성할 수 있다. 사용자가 발화한 음성 명령이 수신되면, 전자 장치 는, 소정 조건 만족 시, 미리 생성된 데이터 구조에 포함되는 객체들의 우선 순위에 따라 음성 명령을 해 석하고 대응하는 동작을 수행할 수 있다. 예를 들어, 사용자의 발화 의도가 소정 타입(예를 들어, 전자 장치가 제공하는 기능을 선택하거나 실행하고자 하는 실행 가능(actionable) 타입, 또는 전자 장치가 제공하는 정보에 접근하고자 하는 접근 가능(accessible) 타입)이면서, 음성 명령을 해석하기 위해 미리 생성해 둔 하나 이상의 객체들에 관련된 데이터 구조가 존재하는 경우가 있을 수 있다. 이 경우, 전자 장치는, 사용자의 발화 의도가 애플리케이션의 실행 화면 내에서 제 공하는 기능을 실행하는 것이라고 판단할 수 있다. 반면에, 발화 의도가 소정 타입이 아니거나, 하나 이상의 객체들에 관련된 데이터 구조가 존재하지 않는 경우, 전자 장치는, 화면에 디스플레이 되는 객체를 고려하지 않고 일반적인 자연어 이해를 수행할 수 있다. 도 2에 예시된 바와 같이 사용자가 발화한 음성 명령 \"Stranger Things 틀어줘\"를 수신하였다고 가정하면, 전자 장치는 음성 명령의 \"틀어줘\" 부분에 기초하여 사용자의 발화 의도의 타입이 실행 가능 타입이라 고 판단할 수 있다. 또한, 전자 장치는, \"Stranger Things\"가 화면에 디스플레이 되고 있는 선택 가능 객 체와 관련된(또는, 선택 가능 객체에 근접한) 컨텐츠의 명칭인 경우, 사용자의 음성 명령이 해당 컨텐츠를 재생할 것을 지시하는 것이라고 판단할 수 있다. 전자 장치는, 판단 결과에 기초하여, 선택 가능 객체에 대한 소정 기능을 수행하는 실행 함수(예를 들어, 소정 기능을 실행하는 API의 호출, 소정 기능과 매핑된 EventID의 발생 등)를 발생시킬 수 있다. 도 3a는 본 개시의 일 실시 예에 따른 음성 인식 시스템의 예시를 나타낸다. 도 3a에 도시된 바와 같이, 본 개시의 일 실시 예에 따른 전자 장치는 단독으로 사용자에게 음성 인식 서비스를 제공할 수 있다. 예를 들어, 전자 장치는, TV, 냉장고, 세탁기 등의 가전 제품, 스마트 폰, PC, 웨어러블 디바이스, PDA(personal digital assistant), 미디어 플레이어, 마이크로 서버, GPS(global positioning system) 장치, 전자책 단말기, 디지털 방송용 단말기, 네비게이션, 키오스크, MP3 플레이어, 디지 털 카메라 및 기타 모바일 또는 비모바일 컴퓨팅 장치일 수 있으나, 이에 제한되지 않는다. 일 실시 예에 따른 전자 장치는, 사용자의 음성 명령을 수신하고, 화면 상에 디스플레이 되는 적어도 하나의 객체를 고려하여 수신된 음성 명령을 해석할 수 있다. 전자 장치는, 해석 결과에 기초하여, 소정 동작을 수행하거나 응답 메시지를 생성하고 출력할 수 있다. 또한, 도 3b에 도시된 바와 같이, 일 실시 예에 따른 전자 장치는, 서버와 같은 다른 전자 장치와 연 동하여 음성 인식 서비스를 제공할 수 있다. 전자 장치와 서버는 유선 또는 무선으로 연결 될 수 있 다. 서버는, 전자 장치와 데이터, 자원 및 서비스를 공유하거나, 전자 장치의 제어, 파일 관리, 또 는 네트워크 전체의 감시 등을 수행할 수 있다. 전자 장치는, 서버와의 통신을 통해 사용자의 음성 명령에 대한 소정 동작을 수행하거나 응답 메시지를 출력할 수 있다. 일 실시 예에 따른 전자 장치는, 사용자의 음성 명령을 수신하고, 음성 명령과 관련된 정보를 서버 에게 전송할 수 있다. \"음성 명령과 관련된 정보”는, 음성 명령을 포함하는 오디오 신호를 포함하거나, 음성 명령으로부터 추출된 특징 벡터, 또는 음성 명령이 변환된 텍스트를 포함할 수 있다. 일 실시 예에 따른 서버는, 전자 장치의 화면 상에 디스플레이 되는 적어도 하나의 객체 및 전자 장치로부터 수신 된 음성 명령과 관련된 정보에 기초하여, 사용자의 음성 명령을 해석할 수 있다. 서버는, 음성 명령 해석 결과를 전자 장치에게 전송함으로써, 전자 장치가 소정 동작을 수행하거나 응답 메시지를 출력하도록 제어할 수 있다. 도 3a 및 3b에 도시된 바와 같이, 일 실시 예에 따른 음성 인식 서비스 제공 시스템은, 적어도 하나의 전자 장 치 및/또는 서버를 포함할 수 있다. 이하에서는, 설명의 편의를 위해 “전자 장치”가 서버를 거치지 않고 자체 적으로 음성 인식 서비스를 온-디바이스로 제공하는 경우를 예를 들어 서술하겠다. 다만, 본 개시는 온-디바이 스로 제공되는 음성 인식 서비스에 제한되지 않으며, 이하에서 기술되는 전자 장치의 동작의 일부 또는 전부는 전자 장치와 연결되는 다른 전자 장치 및/또는 서버에서 수행될 수 있다. 도 4는 본 개시의 일 실시 예에 따른 전자 장치가 음성 인식 서비스를 제공하는 방법의 흐름도를 도시한다. 일 실시 예에 따른 전자 장치는, 화면 상에 하나 이상의 객체를 나타내는 디스플레이를 포함하는 전자 장 치일 수 있다. 전자 장치는, 음성 명령을 해석하는데 이용하기 위하여, 화면 상에 디스플레이 되는 하나 이상의 객체에 관련된 데이터 구조를 미리 생성할 수 있다. 화면 상에 디스플레이 되는 하나 이상의 객체들은 이미지 정보 및 텍스트 정보 중 적어도 하나를 포함할 수 있 다. 객체의 이미지 정보는, 화면의 오브젝트 레이어 상에 표시되고, 객체의 텍스트 정보는 화면의 텍스트 레이 어 상에 표시될 수 있다. 일 실시 예에 따른 전자 장치는, 화면을 구성하는, 오브젝트 레이어 및 텍스트 레이어에 기초하여, 객체들의 타입들을 식별할 수 있다. 예를 들어, 전자 장치는, 객체가 전자 장치에 대한 사용자 입력에 의해 선택 가능 한지 또는 선택 불 가능 한지, 텍스트 정보를 포함하는 지 또는 텍스트 정보를 포함하지 않는 지에 기초하여 객체의 타입을 구분할 수 있다. 일 실시 예에 따른 전자 장치는, 화면 상에 디스플레이 되는 객체에 대한 영상 처리를 통한 문자 판독, 또 는 화면 상에 객체를 제공하는 애플리케이션의 메타 데이터 판독에 의해, 객체의 타입을 식별할 수 있다. 전자 장치는, 화면 상에 디스플레이 되는 하나 이상의 객체의 타입에 기초하여, 하나 이상의 객체의 우선 순위 를 결정할 수 있다. 전자 장치는, 화면 상에 디스플레이 되는 하나 이상의 객체들이 우선 순위에 따라 상 하 관계를 갖는 데이터 구조를 생성할 수 있다. 또한, 일 실시 예에 따른 전자 장치는, 객체들에 포함되는 텍스트 정보, 또는 객체들을 제공하는 애플리케 이션의 메타 데이터에 포함되는 객체들의 속성(attribute) 정보 중 적어도 하나로부터, 객체들과 관련된 용어 (term)들을 획득할 수 있다. 일 실시 예에 따르면, 전자 장치는, 객체들에 대한 정보를 포함하는 데이터 구조를 검색 및 정렬이 가능한 형태로 정의하여 저장할 수 있다. 예를 들어, 데이터 구조의 형태는 그래프, 조 회 테이블, 연결 리스트, 또는 트리의 형태를 가질 수 있다. 예를 들어, 전자 장치는, 하나 이상의 객체들 이 상하 관계를 구성하는 데이터 구조 내에서, 각 객체와 관련 용어들이 수평적 관계를 갖도록 트리 형태의 데 이터 구조를 생성할 수 있다. 단계 S410에서 일 실시 예에 따른 전자 장치는, 하나 이상의 객체가 디스플레이되는 도중에 사용자의 음성 명령을 수신할 수 있다. 일 실시 예에 따른 전자 장치는, 수신된 음성 명령으로부터 텍스트를 획득하고, 텍스트에 대한 자연어 이 해 처리를 통해 사용자의 발화 의도를 판단할 수 있다. 일 예로서, 전자 장치는, 종단간 자동 음성 인식(end-to-end ASR) 모델을 이용하여 음성 명령으로부터 텍 스트를 획득할 수 있다. 종단간 자동 음성 인식 방식이란, 음성 데이터가 인식되면 딥러닝 엔진을 거쳐 바로 하 나의 문장이 도출되도록 훈련된 심층 신경망을 이용하는 음성 인식 방식이다. 종단간 자동 음성 인식 모델의 예 로는, RNN-T 모델, 및 CTC 모델 등이 존재한다. 다른 예로서, 전자 장치는, 음향 모델, 사전, 및 언어 모델을 이용하는 음성 인식 방식을 이용할 수 있다. 이러한 음성 인식 방식은, 음성을 텍스트로 변환하는 과정에서 음성의 음소를 찾아내고 음소를 바탕으로 단어를 뽑아내고 문장을 찾아내는 각각의 과정이 다양한 모듈로 구성될 수 있다. 예를 들어, 전자 장치는, 음향 모델을 이용하여 음성 신호로부터 음소열을 획득하고, 사전 및 언어 모델에 기초하여 음소열로부터 단어들을 추 정하고 추정된 단어들을 포함하는 텍스트를 획득할 수 있다. 수신된 음성 명령으로부터 텍스트가 획득되면, 일 실시 예에 따른 전자 장치는, 자연어 이해 모델을 통해, 텍스트를 분석함으로써 사용자가 음성 명령을 발화한 의도를 판단할 수 있다. 전자 장치는, 발화 의도가 실행 가능 타입 또는 접근 가능 타입인지 여부를 판단할 수 있다. 예를 들어, 전자 장치는 \"Stranger Things 틀어줘\"라는 텍스트가 획득되면, 자연어 이해 모델을 통해 사용자의 발화 의도가 \"Stranger Things\"와관련된 기능을 실행하기 위한 것임을 판단할 수 있다. 다른 예를 들면, 전자 장치는 \"Stranger Things 확 대해줘\"라는 텍스트가 획득되면, 자연어 이해 모델을 통해 사용자의 발화 의도가 \"Stranger Things\"와 관련된 정보에 접근하기 위한 것임을 판단할 수 있다. 단계 S420에서 일 실시 예에 따른 전자 장치는, 음성 명령이 수신됨에 따라, 화면 상에 디스플레이 되는 하나 이상의 객체를 식별할 수 있다. 일 실시 예에 따른 전자 장치는, 음성 명령으로부터 변환된 텍스트로부터 사용자의 발화 의도의 타입을 결 정할 수 있다. 전자 장치는, 발화 의도의 타입 및 하나 이상의 객체들의 타입들에 기초하여, 데이터 구조 의 하나 이상의 객체들의 우선 순위를 다시 결정할 수 있다. 일 실시 예에 따른 전자 장치는, 발화 의도의 타입이 소정 타입(예를 들어, 실행 가능 타입 또는 접근 가 능 타입)이고, 화면에 디스플레이 되고 있는 객체에 대한 데이터 구조가 존재하는 경우, 데이터 구조의 객체들 의 우선 순위를 다시 결정할 수 있다. 전자 장치는, 발화 의도의 타입에 따라, 객체들의 타입들에 서로 다 른 우선 순위를 부여할 수 있다. 일 예로서, 전자 장치는, 사용자의 음성 명령의 발화 의도가 실행 가능 타입인 경우, 화면에 디스플레이 되고 있는 선택 가능 객체가 음성 인식 시 우선적으로 참조되도록 우선 순위를 부여할 수 있다. 다른 예로서, 전자 장치는, 사용자의 음성 명령의 발화 의도가 접근 가능 타입인 경우, 화면에 디스플레이 되고 있는 선택 불가능 객체가 음성 인식 시 우선적으로 참조되도록 우선 순위를 부여할 수 있다. 발화 의도의 타입에 따라 객체들에게 서로 다른 우선 순위를 부여하는 방법은, 추후에 도 7을 참조하여 구체적으로 설명한다. 단계 S430에서 일 실시 예에 따른 전자 장치는, 하나 이상의 객체의 타입에 기초하여, 음성 명령으로부터 변환된 텍스트를 해석할 수 있다. 하나 이상의 객체의 타입은, 전자 장치에 대한 사용자 입력에 의해 선택 가능 한지 여부에 따라 구별될 수 있다. 일 실시 예에 따른 전자 장치는, 타입에 따라 객체에 우선 순위가 부여된 데이터 구조를 이용하여, 텍스트 를 해석할 수 있다. 일 예로서, 전자 장치는, 사용자의 음성 명령의 발화 의도가 실행 가능 타입인 경우, 데이터 구조 내에서 상대적으로 높은 우선 순위가 부여된 선택 가능 객체를 우선적으로 참조하여 텍스트를 해석할 수 있다. 다른 예 로서, 전자 장치는, 사용자의 음성 명령의 발화 의도가 접근 가능 타입인 경우, 데이터 구조 내에서 상대 적으로 높은 우선 순위가 부여된 선택불가능 객체를 우선적으로 참조하여 텍스트를 해석할 수 있다. 일 실시예에 따른 전자 장치는, 음성 명령으로부터 변환된 텍스트로부터 의도(intent)에 해당하는 부분과 엔티티(entity)에 해당하는 부분을 식별하고, 화면 상에 디스플레이 되는 객체들과 관련된 데이터 구조를 참조 하여, 식별된 의도 및 엔티티가 의미하는 바를 해석할 수 있다. 의도란, “실행해줘”, “보여줘”와 같이 음성 명령에 응답하여 전자 장치가 수행해야 할 동작과 관련된 텍스트 부분을 의미하고, 엔티티란, 수행해야 할 동작의 대상과 관련된 텍스트 부분을 의미할 수 있다. 엔티티는, 텍스트에 포함되는 특정한 의미를 가지고 있는 단어, 또는 어구 중 적어도 하나를 포함할 수 있다. 일 실시예에 따른 전자 장치는, 사용자의 음성 명령으로부터 변환된 텍스트의 의도가 모호한 경우, 화면 상에 디스플레이 되는 객체들(또는, 화면 상에 제공되는 애플리케이션의 기능들)과 관련된 데이터 구조에 기초 하여 의도를 해석할 수 있다. 예를 들어, 동영상 재생과 관련된 객체들을 포함하는 화면이 디스플레이되고 있는 도중에 \"Stranger Things 해 줘\"라는 음성 명령이 수신될 수 있다. 이 때, 전자 장치는 '해줘'가 동영상 재생을 명령하는 것이라고 판 단하고, 관련된 API, 즉, 'Stranger Things'와 관련된 동영상을 재생하는 API를 호출할 수 있다. 또한, 일 실시예에 따른 전자 장치는, 영화 제목, 노래 제목, 또는 영화 설명 등 학습되지 않은 새로운 컨 텐츠와 관련되어 해석이 어려운 엔티티에 대해서, 화면 상에 디스플레이 되는 객체들(또는, 객체들의 메타 데이 터)과 관련된 데이터 구조에 기초하여 엔티티를 해석할 수 있다. 전자 장치는, 획득된 텍스트로부터 식별 된 적어도 하나의 엔티티를 해석하기 위해서, 화면에서 구성된 데이터 구조 내의 정보들을 음성 인식 모델 및 언어 인식 모델이 사전처럼 참조하도록 할 수 있다. 일 실시예에 따른 전자 장치는, 음성 명령으로부터 획득된 텍스트 내에 식별된 엔티티와 화면 상에 디스플 레이 되는 객체들을 비교할 수 있다. 전자 장치는, 화면 상에 디스플레이 되는 객체들 중에서, 식별된 엔 티티와 가장 관련도가 높은 객체를 선택할 수 있다. 전자 장치는, 텍스트 내에서 식별된 엔티티가, 선택된객체를 지시하는 것으로 판단할 수 있다. 예를 들어, 동영상 재생과 관련된 객체들을 포함하는 화면이 디스플레이되고 있는 도중에 \"Wife 틀어줘\"라는 음 성 명령이 수신될 수 있다. 이 때, 전자 장치는, “Wi-Fi”라는 단어만 학습되어 있는 경우에도, 화면 상 에 디스플레이 되는 객체에 포함되는 영화 제목 \"Wife\"에 기초하여 \"Wife\"를 \"Wi-Fi\"로 오인식하지 않고 정확하 게 해석할 수 있다. 단계 S440에서 일 실시 예에 따른 전자 장치는, 텍스트의 해석 결과에 기초하여, 하나 이상의 객체 중에서 선택된 객체와 관련된 동작을 수행할 수 있다. 일 실시 예에 따른 전자 장치는, 텍스트 해석 결과로서, 텍스트에 기초하여 결정되는 사용자의 발화 의도, 화면 상에 디스플레이 되는 하나 이상의 객체들 중에서 선택된 객체, 및 사용자의 발화 의도에 따라 선택된 객 체와 관련하여 실행해야 할 기능 중 적어도 하나에 대한 정보를 도출할 수 있다. 일 실시 예에 따른 전자 장치는, 텍스트의 해석 결과에 기초하여, 화면 상에 디스플레이 되는 하나 이상의 객체들 중에서 선택된 객체와 관련된 컨텐츠(예를 들어, 오디오, 비디오 등)를 재생하는 동작, 선택된 객체와 관련된 이미지 또는 텍스트를 확대하여 디스플레이하는 동작, 또는 선택된 객체에 포함되는 텍스트를 음성으로 변환하여 출력하는 동작 중 적어도 하나를 수행할 수 있다. 또한, 일 실시 예에 따른 전자 장치는, 텍스트의 해석 결과에 기초하여, 화면 상에 디스플레이 되는 하나 이상의 객체들 중에서 선택된 객체와 관련된 응답 메시지를 생성하고 출력할 수 있다. 일 실시 예에 따른 전자 장치는, 화면 상에 하나 이상의 객체들이 디스플레이되는 도중에 수신되는 음성 명령을 해석하는데 이용하기 위해서, 하나 이상의 객체들에 관련된 데이터 구조를 미리 생성할 수 있다. 도 5는 본 개시의 일 실시 예에 따른 전자 장치가 화면 상에 디스플레이 되는 객체들에 관한 데이터 구조를 생 성하는 방법의 흐름도를 도시한다. 단계 S510에서 일 실시 예에 따른 전자 장치는, 화면 상에 디스플레이 되는 하나 이상의 객체를 식별할 수 있다. 전자 장치는, 예를 들어, OCR(optical character recognition) 등을 이용하여 화면 상에 디스플레이 되는 객체에 대한 영상 처리를 통하여 문자를 판독하거나, 객체에 포함된 텍스트 정보를 식별함으로써, 화면에 디스 플레이 되는 객체와 관련된 컨텐츠를 인식할 수 있다. 또는, 전자 장치는, 화면 상에 하나 이상의 객체를 제공하는 애플리케이션의 메타 데이터를 판독함으로써, 화면에 디스플레이 되는 컨텐츠를 인식할 수 있다. 단계 S520에서 일 실시 예에 따른 전자 장치는, 식별된 하나 이상의 객체의 타입을 결정할 수 있다. 일 실시 예에 따른 전자 장치는, 화면을 복수의 레이어들로 구분할 수 있다. 전자 장치는, 복수의 레 이어들을 겹쳐서 하나 이상의 객체를 화면 상에 표시할 수 있다. 예를 들어, 도 2에 도시된 바와 같이, 전자 장 치는, 화면을 오브젝트 레이어 및 텍스트 레이어로 구분할 수 있다. 일 실시 예에 따른 전자 장치는, 복수의 레이어들에 의해서 객체에 포함되는 이미지 정보와 텍스트를 분류 함으로써, 객체의 타입을 결정할 수 있다. 전자 장치는, 오브젝트 레이어 상에 표시되는 하나 이상의 객체가 선택 가능한 객체인지 선택 불가능한 객체인지 판단할 수 있다. 선택 가능 객체란, 디스플레이 되는 유저 인터페이스 상에서 선택할 수 있는 객체를 의미할 수 있다. 전자 장치 는, 선택 가능 객체에 대한 사용자 입력에 의해, 해당 객체에 대응하는 영역을 지정하거나, 해당 객체와 관련된 항목을 실행하거나, 현재 페이지에서 해당 객체와 관련된 다른 부분으로 이동하거나, 해당 객체와 관련 된 다른 페이지로 이동하거나, 해당 객체와 관련된 기능을 실행할 수 있다. 예를 들어, 선택 가능 객체란, 동영 상 스트리밍 서비스를 제공하는 애플리케이션에서 어떠한 동영상이 재생되도록 하는 동영상의 썸네일, 또는 동 영상 제목, 애플리케이션의 실행 메뉴 등을 포함할 수 있다. 반면에, 선택 불가능 객체란, 디스플레이 되는 유저 인터페이스 상에서 선택할 수 없는 고정된 객체를 의미할 수 있다. 예를 들어, 선택 불가능 객체란, 동영상 스트리밍 서비스를 제공하는 애플리케이션에서 동영상과 관련 된 설명, 참조 이미지 등을 포함할 수 있다. 예를 들어, 객체가, 사용자의 클릭 제스쳐를 통해 선택되는 경우, 선택 가능 객체는 클릭 가능 객체(Clickable object)라고 지칭되고, 선택 불가능 객체는 논-클릭 가능 객체(Non-Clickable object)라고 지칭될 수 있다. 그러나, 본 개시의 다양한 실시 예는, 사용자가 객체를 클릭하여 선택하는 방식에 제한되지 않으며, 다양한 방식 에 따라 객체를 선택할 수 있고, 사용자가 객체를 선택하는 방식에 따라, 선택 가능 객체 및 선택 불가능 객체 의 명칭도 다양하게 지칭될 수 있음으 자명하다. 또한, 전자 장치는, 화면 상의 객체가 텍스트 레이어 상에 표시되는 텍스트 정보를 포함하는 지 여부에 기 초하여, 하나 이상의 객체가 텍스트 객체인지 또는 해석가능(interpretable) 객체인지 판단할 수 있다. 텍스트 객체란, 텍스트 정보를 포함하는 객체를 의미할 수 있다. 해석가능 객체란, 텍스트가 추출되지는 않지만, 영상 처리를 통한 화면 인식 또는 메타 데이터 등을 통해 해석 가능한 이미지를 포함하는 객체를 의미 할 수 있다. 해석가능 객체는, 논-텍스트 객체, 이미지 객체 등으로 지칭될 수 있다. 단계 S530에서 일 실시 예에 따른 전자 장치는, 하나 이상의 객체의 타입에 기초하여, 음성 명령을 해석하 기 위해 이용되는데이터 구조를 생성할 수 있다. 일 실시 예에 따르면, 전자 장치는, 객체들에 대한 정보를 포함하는 데이터 구조를 검색 및 정렬이 가능한 형태로 정의하여 저장할 수 있다. 예를 들어, 데이터 구조의 형태는 그래프, 조회 테이블, 연결 리스트, 또는 트리의 형태를 가질 수 있다. 예를 들어, 전자 장치는, 하나 이상의 객체들이 상하 관계를 구성하는 데이 터 구조 내에서, 각 객체와 관련 용어들이 수평적 관계를 갖도록 트리 형태의 데이터 구조를 생성할 수 있다. 음성 명령 수신 전에 생성되는 초기 데이터 구조는, 시스템이 정한 규칙에 따라 생성 될 수 있다. 일 실시 예에 따른 전자 장치는, 하나 이상의 객체의 타입에 기초하여, 객체의 우선 순위를 결정할 수 있다. 예를 들어, 전자 장치는, 객체의 타입에 따라 미리 결정된 초기 값을 이용하여, 화면 상에 식별되는 하나 이상의 객체 에 대한 우선 순위를 결정할 수 있다. 또는, 예를 들어, 전자 장치는, 하나 이상의 객체를 타입 별로 분류 하고, 화면 상에 배치되는 객체의 위치, 또는 단계 S510에서 객체가 식별되는 순서에 따라서, 가장 상단에 위치 하거나 가장 먼저 식별된 객체의 타입에 가장 높은 순위를 부여할 수 있다. 전자 장치는, 객체의 타입에 따른 우선 순위에 기초하여 화면 상에 식별되는 하나 이상의 객체에 대한 우선 순위를 결정할 수 있다. 일 실시 예에 따른 전자 장치는, 화면 상에 디스플레이 되는 하나 이상의 객체와, 각 객체와 관련된 적어 도 하나의 용어(term) 간의 관계를 나타내는 데이터 구조를 생성할 수 있다. 생성된 데이터 구조 내에서, 화면 상에 디스플레이 되는 객체들은 우선 순위에 따라 상하 관계를 가지며, 소정 객체와 소정 객체와 관련된 적어도 하나의 용어가 수평적인 관계를 가질 수 있다. 한편, 일 실시 예에 따른 전자 장치는, 사용자가 음성 명령을 발화한 의도에 기초하여, 일반적인 음성 인 식 동작 또는 본 개시에서 새롭게 제안되는 음성 인식 동작을 선택적으로 수행할 수 있다. 일반적인 음성 인식 동작이란, 전자 장치의 일반적인 기능과 관련된 자연어 이해 모델 및 대화 관리 모델을 이용하여 사용자의 음성 명령을 해석하는 것을 의미할 수 있다. 일반적인 음성 인식 동작을 수행하는 경우, 전자 장치는 한번 학습되어 정해진 모델을 이용하므로, 어떠한 화면이 디스플레이 되고 있는 지 여부에 관계 없이 음성 명령에 대 해 정해진 해석을 하고, 음성 명령에 응답하는 기능을 수행한다. 본 개시에서 새롭게 제안되는 음성 인식 동작 은, 화면 상에 디스플레이 되는 객체 또는 실행 중인 애플리케이션이 제공하는 기능을 우선적으로 고려하여 자 연어 이해 처리 및 대화 관리를 수행함으로써 사용자의 음성 명령을 해석하는 것을 의미할 수 있다. 일 실시 예에 따른 전자 장치는, 발화 의도에 기초하여, 본 개시에서 새롭게 제안되는 음성 인식을 수행하 는 제1모드로 동작할 지 또는 일반적인 음성 인식을 수행하는 제2모드로 동작할 지 여부를 판단할 수 있다. 일 예로서, 전자 장치는, 발화 의도의 타입에 기초하여, 제1모드로 동작할 지 또는 제2모드로 동작할 지 여부 를 판단할 수 있다. 다른 예로서, 전자 장치는, 사용자의 음성 명령이 변환된 텍스트에 활성화 단어가 포 함되는 지 여부에 기초하여 제1모드로 동작할 지 또는 제2모드로 동작할 지 여부를 판단할 수 있다. 일 실시 예에 따른 전자 장치는, 제1모드에서, 화면 상에 디스플레이 되는 적어도 하나의 객체의 타입에 기초하여 생성된 데이터 구조를 고려하여, 텍스트에 대한 자연어 이해를 수행할 수 있다. 반면에, 일 실시 예에 따른 전자 장치는, 제2모드에서, 적어도 하나의 객체의 타입에 기초하여 생성된 데이터 구조를 고려하지 않고, 텍스트에 대한 자연어 이해를 수행할 수 있다. 이하에서는, 도 6을 참조하여 일 실시 예에 따른 전자 장치가 본 개시에서 새롭게 제안되는 음성 인식 동 작을 선택적으로 수행하는 방법을 설명한다. 도 6은 본 개시의 일 실시 예에 따른 전자 장치가 음성 인식 서비스를 제공하는 방법의 흐름도를 도시한다. 일 실시 예에 따른 전자 장치는, 화면 상에 하나 이상의 객체를 나타내는 디스플레이할 수 있다. 예를 들 어, 전자 장치는, 애플리케이션을 실행함으로써, 애플리케이션에서 제공되는 하나 이상의 객체를 화면 상 에 디스플레이 할 수 있다. 단계 S610에서 일 실시 예에 따른 전자 장치는, 하나 이상의 객체가 디스플레이 되는 도중에 음성 명령을 수신할 수 있다. 단계 S620에서 일 실시 예에 따른 전자 장치는, 수신된 음성 명령을 텍스트로 변환하는 음성 인식을 수행 할 수 있다. 단계 S630에서 일 실시 예에 따른 전자 장치는, 변환된 텍스트에 대해 제1자연어 이해를 수행함으로써, 사 용자가 음성 명령을 발화한 의도를 결정할 수 있다. 전자 장치는, 제1자연어 이해 모델을 통해, 텍스트를 분석함으로써 사용자가 음성 명령을 발화한 의도를 판단할 수 있다. 일 실시 예에 따른 전자 장치는, 제1자연어 이해 모델을 통해, 텍스트로부터 사용자의 의도(intent)를 식 별하고, 사용자의 의도 대로 소정 동작을 수행하기 위해 필요한 적어도 하나의 엔티티(entity)를 식별할 수 있 다. 단계 S640에서 일 실시 예에 따른 전자 장치는, 사용자의 발화 의도의 타입이 소정 타입인지 여부를 결정 할 수 있다. 예를 들어, 전자 장치는, 발화 의도 타입이 실행 가능 타입 또는 접근 가능 타입인지 여부를 판단할 수 있 다. 실행 가능 타입의 발화는, 사용자가 전자 장치가 제공하는 기능을 선택하거나 실행하고자 하는 발화로서, \"보여 줘\", \"틀어줘\", \"실행해 줘\" 등의 음성 명령을 포함할 수 있다. 접근 가능 타입의 발화는, 사용자가 전자 장치 가 제공하는 정보에 접근하고자 하는 발화로서, \"읽어줘\", \"확대해 줘\" 등의 음성 명령을 포함할 수 있다. 단계 S650에서 일 실시 예에 따른 전자 장치는, 사용자의 발화 의도의 타입이 소정 타입인 경우, 화면에 디스플레이 되고 있는 객체에 대한 데이터 구조가 존재하는 지 여부를 판단할 수 있다. 예를 들어, 전자 장치 는, 사용자의 발화 의도의 타입이 실행 가능 타입 또는 접근 가능 타입인 경우, 음성 명령을 해석하는데 이용하기 위한 디스플레이 객체 관련 데이터 구조가 존재하는 지 여부를 판단할 수 있다. 단계 S660에서 일 실시 예에 따른 전자 장치는, 화면에 디스플레이 되고 있는 객체에 대한 데이터 구조가 존재하는 경우, 제1모드로 동작할 수 있다. 전자 장치는, 화면에 디스플레이 되고 있는 객체를 고려하여 사용자의 음성 명령을 해석하는 제2자연어 이해를 수행할 수 있다. 일 실시 예에 따른 전자 장치는, 제1자연어 이해를 통해 1차적으로 사용자의 발화 의도를 결정하고, 발화 의도의 타입에 기초하여 제2자연어 이해를 수행함으로써 추가적으로 사용자의 음성 명령을 해석할 수 있다. 전 자 장치는, 제2자연어 이해 모델을 통해, 화면 상에 디스플레이 되고 있는 객체들을 고려하여 사용자의 음 성 명령을 해석할 수 있다. 전자 장치는, 화면에 디스플레이 되는 하나 이상의 객체와 관련하여 생성된 데 이터 구조를 이용하여, 화면에서 제공 가능한 기능이 우선적으로 인식되거나 실행될 수 있도록 제2자연어 이해 를 수행할 수 있다. 일 실시예에 따른 전자 장치는, 화면 상에 디스플레이 되는 객체들과 관련된 데이터 구조에 기초하여, 사 용자의 음성 명령이 변환된 텍스트로부터 식별된 의도 및 엔티티를 해석할 수 있다. 전자 장치는, 제2 자연어 이해를 통해 사용자의 의도를 해석하기 위해서, 화면 상에 디스플레이 되고 있는 객체들을 참조하는 순서를 결정할 수 있다. 전자 장치는, 발화 의도의 타입 및 객체들의 타입들에 기초하 여, 데이터 구조의 객체들의 우선 순위를 다시 결정할 수 있다. 전자 장치는, 발화 의도의 타입에 따라, 객체들의 타입들에 서로 다른 우선 순위를 부여할 수 있다. 예를 들어, 전자 장치는, 랭킹 테이블을 이용 하여, 데이터 구조의 하나 이상의 객체에 대해 우선 순위를 다시 매기는 리랭킹(re-ranking)을 수행할 수 있다. 도 7은 본 개시의 일 실시 예에 따른 전자 장치가 객체에 대해서 결정하는 우선 순위의 예를 도시한다. 도 7에 도시된 바와 같이, 발화 의도의 타입이 소정 기능을 선택하거나 실행하고자 하는 실행 가능 타입인 경우, 일 실시 예에 따른 전자 장치는, 선택 가능 객체를 우선적으로 참조할 수 있다. 발화 의도의 타입이 실행 가능 타입인 경우, 일 실시 예에 따른 전자 장치는, 선택 가능 텍스트 객체, 선택 가능 해석가능 객 체, 선택 불가능 텍스트 객체, 및 선택 불가능 해석가능 객체 순서로 우선 순위를 부여할 수 있다. 도 7의 표에 도시된 숫자는, 객체의 타입에 부여되는 우선 순위를 나타낸다.데이터 구조 내에서 객체에 높은 우선 순위를 부여한다는 것은, 전자 장치가 사용자의 음성 명령을 해석하 기 위하여 해당 객체를 우선적으로 참조한다는 것을 의미할 수 있다. 또는, 데이터 구조 내에서 객체의 우선 순 위가 높다는 것은, 전자 장치가 사용자의 음성 명령을 해석하는 데 있어서, 사용자의 발화가 해당 객체와 관련될 확률이 높다는 것을 의미할 수 있다. 또한, 발화 의도의 타입이 소정 정보에 접근하고자 하는 접근 가능 타입인 경우, 일 실시 예에 따른 전자 장치 는, 텍스트 객체를 우선적으로 참조할 수 있다. 일 실시 예에 따른 전자 장치는, 발화 의도의 타입이 접근 가능 타입인 경우, 선택 불가능 텍스트 객체, 선택 가능 텍스트 객체, 선택 불가능 해석가능 객체, 및 선 택 가능 해석가능 객체 순서로 우선 순위를 부여할 수 있다. 일 실시 예에 따른 전자 장치는, 발화 의도의 타입 및 하나 이상의 객체들의 타입들에 기초하여, 하나 이 상의 객체에 대한 우선 순위가 다시 부여된 데이터 구조를 이용한 제2자연어 이해를 수행할 수 있다. 전자 장치 는, 화면 상에 디스플레이 되는 객체와 관련된 데이터 구조를 고려한 제2자연어 이해를 거쳐, 사용자의 음 성 명령이 변환된 텍스트를 해석할 수 있다. 일 실시예에 따른 전자 장치는, 화면 상에 디스플레이 되는 객체들과 관련된 데이터 구조에 기초하여, 사 용자의 음성 명령이 변환된 텍스트로부터 식별된 의도 및 엔티티를 해석할 수 있다. 전자 장치는, 데이터 구조에 기초하여, 텍스트로부터 식별된 의도가 객체와 관련된 애플리케이션 기능을 실행하기 위한 것으로 해석 할 수 있다. 또한, 전자 장치는, 데이터 구조에 기초하여, 텍스트로부터 식별된 엔티티가 화면 상에 디스 플레이 되는 하나 이상의 객체들 중에서 선택된 객체를 가리키는 것으로 해석할 수 있다. 일 실시 예에 따른 전자 장치는, 텍스트 해석 결과로서, 텍스트에 기초하여 결정되는 사용자의 발화 의도, 화면 상에 디스플레이 되는 하나 이상의 객체들 중에서 선택된 객체, 및 사용자의 발화 의도에 따라 선택된 객 체와 관련하여 실행해야 할 기능 중 적어도 하나에 대한 정보를 획득할 수 있다. 다시 도 6으로 되돌아와서, 단계 S680에서 일 실시 예에 따른 전자 장치는, 텍스트의 해석 결과에 기초하 여, 하나 이상의 객체 중에서 선택된 객체와 관련된 동작을 수행할 수 있다. 일 실시 예에 따른 전자 장치는, 텍스트의 해석 결과에 기초하여, 화면 상에 디스플레이 되는 하나 이상의 객체들 중에서 선택된 객체와 관련된 컨텐츠를 재생하는 동작, 선택된 객체와 관련된 이미지 또는 텍스트를 확 대하여 디스플레이하는 동작, 또는 선택된 객체에 포함되는 텍스트를 음성으로 변환하여 출력하는 동작 중 적어 도 하나를 수행할 수 있다. 도 6에 도시된 바와 같이, 일 실시 예에 따른 전자 장치는, 발화 의도가 소정 타입인 경우, 화면 컨텐츠 구성(예를 들어, 화면에 디스플레이 되는 하나 이상의 객체)과 관련하여 생성된 데이터 구조를 이용하여, 화면 에서 제공 가능한 기능이 우선적으로 인식되거나 실행될 수 있도록 제2자연어 이해를 수행할 수 있다. 반면에, 사용자의 발화 의도의 타입이 소정 타입이 아니거나, 화면에 디스플레이 되고 있는 객체에 관한 데이터 가 존재하지 않는 경우, 단계 S670에서 일 실시 예에 따른 전자 장치는, 제2모드로 동작할 수 있다. 전자 장치는, 제2모드에서 제3자연어 이해를 수행할 수 있다. 전자 장치는, 화면 상에 디스플레이 되는 객체를 고려하지 않고, 사용자의 음성 명령이 변환된 텍스트에 대한 제3자연어 이해를 수행할 수 있다. 제3자연어 이해란, 화면에 디스플레이 되는 객체를 우선적으로 고려하 지 않는 일반적인 자연어 이해 모델을 통한 자연어 이해를 의미할 수 있다. 전자 장치는, 제3자연어 이해 모델을 통한 텍스트의 해석 결과에 기초하여, 해석 결과와 관련된 동작을 수 행할 수 있다. 예를 들어, 전자 장치는, 텍스트 해석 결과에 대해 응답 메시지를 생성하고 출력할 수 있다. 전자 디바이스는, 음성, 텍스트 및 영상 중 적어도 하나의 형태로 응답 메시지를 출력할 수 있다. 도 8은 본 개시의 일 실시 예에 따른 전자 장치가 음성 명령을 해석하기 위해 이용하는 객체 정보의 예를 도시 한다. 일 실시 예에 따른 전자 장치가 생성하는 데이터 구조에 포함되는 객체와 관련된 용어는, 객체의 속성을 나타내는 값 또는 정보를 의미할 수 있다. 예를 들어, 동영상 스트리밍 애플리케이션이 \"Stranger Things\"라는 제목의 호러 TV 시리즈를 재생하기 위한 선 택 가능 텍스트 객체인 제1객체를 화면 상에 제공하는 경우를 가정한다. 이 경우, 전자 장치는, 제1객체로 부터 판독할 수 있는 텍스트 정보인 \"Stranger Things\", \"Stranger\", \"Things\" 및 제1객체의 메타 데이터에서가져온 속성 값인 \"horror\", \"season 1\" 및 \"television series\"등을 객체와 관련된 용어로서 획득할 수 있다. 전자 장치는, 제1 객체의 용어들을 리스트로 구성하고, 제1객체와 리스트를 연관시켜 데이터 구조 내에 저 장할 수 있다. 데이터 구조 내에서 복수의 객체들(810, 820, 830)의 리스트는 우선 순위에 따라 상하 관계를 가질 수 있다. 객 체의 표현은, 객체의 타입, 객체와 관련된 실행 기능, 및 객체와 관련된 적어도 하나의 용어 중 적어도 하나를 포함할 수 있다. 예를 들어, 제1 객체의 표현은, 제1객체의 타입이 클릭가능 타입임을 나타내는 정보 (Type: Clickable), 제1객체가 선택되었을 때 수행되는 기능이 컨텐츠 재생임을 나타내는 정보(Function: Play.Content()), 제1객체와 관련된 용어들(예를 들어, Stranger Things, horror, Season 1 등)의 리스트(81 1)를 포함할 수 있다. 도 9a는 본 개시의 일 실시 예에 따른 전자 장치가, 사용자가 음성 명령을 발화한 의도에 기초하여 데이터 구조 내의 복수의 객체들의 우선 순위를 다시 결정하는 예를 도시한다. 일 실시 예에 따른 전자 장치는, 음성 명령을 해석하는데 이용하기 위해서, 화면(901, 902)에 디스플레이 되는 객체들에 관련된 데이터 구조를 생성할 수 있다. 전자 장치는, 화면(901, 902)에 디스플레이 되는 객 체들을 이용하여 계층(hierarchy)을 구성할 수 있다. 전자 장치는, 객체들과 관련된 용어들을 객체들과 연 관시킬 수 있다. 도 9a에 도시된 바와 같이, 전자 장치는, \"Stranger Things 틀어줘\"라는 음성 명령이 수신됨에 따라, 사용 자의 발화 의도의 타입이 실행 가능 타입임을 결정할 수 있다. 전자 장치는, 미리 결정된 리랭킹 테이블에 서 실행 가능 타입 발화에 대한 객체 타입 별 우선 순위를 식별하고, 식별된 우선 순위에 기초하여, 화면 상에 디스플레이되는 객체들의 우선 순위가 다시 결정된 데이터 구조를 획득할 수 있다. 일 실시예에 따른 전자 장치는, 데이터 구조에 기초하여 사용자의 음성 명령을 해석할 수 있다. 일 실시예에 따른 전자 장치는, 사용자의 음성 명령이 변환된 텍스트로부터 의도(intent)를 식별하고, 사 용자의 발화 의도를 파악하기 위해 이용되는 적어도 하나의 엔티티를 식별할 수 있다. 전자 장치는, 식별 된 적어도 하나의 엔티티를 데이터 구조 내의 객체 정보(예를 들어, 객체와 관련된 기능, 객체와 관련된 용어, 객체와 관련된 메타 데이터 등)와 비교할 수 있다. 전자 장치는, 적어도 하나의 엔티티가 데이터 구 조 내의 객체 정보와 관련성이 있다고 생각되는 경우, 텍스트로부터 식별되는 의도와 적어도 하나의 엔티 티의 의미를 해석하는 데 있어서 데이터 구조를 이용할 수 있다. 예를 들어, \"Stranger Things 틀어줘\"라는 음성 명령이 수신될 때, '틀어줘'를 의도로 식별하고 'Stranger Things'를 엔티티로 식별할 수 있다. 이 때, 전자 장치는, 식별된 엔티티인 \"Stranger Things\"가 동영상 재생 애플리케이션에 의해 로딩되는 실행 화면 상의 객체와 연관성이 있다고 판단할 수 있다. 전자 장치는, 이러한 판단에 기초하여, '틀어줘'를 해석함에 있어서, 화면 상에 디스플레이 되는 객체들과 관련 하여 미리 생성된 데이터 구조를 이용할 수 있다. 따라서, 전자 장치는, '틀어줘'가 동영상 재생을 명령하 는 것이라고 판단하고, 관련된 API, 즉, 'Stranger Things'와 관련된 동영상을 재생하는 API를 호출할 수 있다. 전자 장치는, 데이터 구조에 기초하여 사용자의 음성 명령이 변환된 텍스트를 해석함으로써 화면 상 에 디스플레이 되고 있는 하나 이상의 객체들 중에서 하나를 선택하고, 선택된 객체와 관련된 것으로 사용자의 음성 명령을 해석할 수 있다. 일 실시 예에 따른 전자 장치는, 우선 순위가 다시 결정된 데이터 구조에 기초하여, 클릭가능 객체인 \"Stranger Things\"를 재생하기 위한 객체를 선택하고, 선택된 객체에 대응하는 동영상인 \"Stranger Things\"를 재생할 수 있다. 일 실시 예에 따른 전자 장치는, 사용자의 발화 의도의 타입이 달라짐에 따라, 화면 상에 디스플레이 되는 객체들의 우선 순위를 변경할 수 있다. 도 9b는 본 개시의 일 실시 예에 따른 전자 장치가, 사용자가 음성 명령을 발화한 의도에 기초하여 데이터 구조 내의 복수의 객체들의 우선 순위를 다시 결정하는 예를 도시한다. 도 9b에 도시된 바와 같이, 일 실시 예에 따른 전자 장치는, \"Stranger Things 읽어줘\"라는 음성 명령이 수신되면, 사용자의 발화 의도의 타입이 접근 가능 타입임을 결정할 수 있다. 전자 장치는, 미리 결정된 랭킹 테이블에서 접근 가능 타입 발화에 대한 객체 타입 별 우선 순위를 식별하고, 식별된 우선 순위에 따라,화면 상에 디스플레이 되는 객체들의 우선 순위가 다시 결정된 데이터 구조를 획득할 수 있다. 일 실시 예에 따른 전자 장치는, 우선 순위가 다시 결정된 데이터 구조에 기초하여, 클릭불가능 객체 들 중에서 \"Stranger Things\"와 관련된 텍스트 객체를 선택하고, 선택된 객체에 포함된 텍스트(예를 들어, 동영 상 \"Stranger Things\"와 관련된 주요 정보, 또는 줄거리 등)를 음성 신호로 변환하여 출력할 수 있다. 도 10a는 일반적인 전자 장치가 사용자의 음성 명령에 응답하여 제공하는 음성 인식 결과와 본 개시의 일 실시 예에 따른 전자 장치가 사용자의 음성 명령에 응답하여 제공하는 음성 인식 결과의 예를 도시한다. 도 10a는 일 실시 예에 따른 전자 장치가 영화 컨텐츠를 제공하는 애플리케이션을 실행하는 도중에 \"바람 과 함께 사라지다 보여줘\"라는 사용자의 음성 명령을 수신하는 경우를 도시한다. 화면에 디스플레이 되는 객체의 타입은 클릭가능 해석가능 타입이고, 객체의 타입은 클릭 불가능 텍스트 타입이다. 화면은, 일반적인 자연어 이해에 따라 사용자에게 제공되는 음성 인식 결과를 도시한다. 사용자 가 음악 재생 애플리케이션을 통해 \"바람과 함께 사라지다\"라는 제목의 음악을 자주 재생하는 경우, 전자 장치 는 \"바람과 함께 사라지다\"라는 발화를 해석하는 데 있어서, 음악 제목으로 해석하도록 학습(learn)되어 있을 수 있다. 반면에, 화면는, 본 개시에서 제안하는 자연어 이해에 따라 사용자에게 제공되는 음성 인식 결과를 도시한다. 일 실시 예에 따른 전자 장치는, 화면에 디스플레이 되는 객체들(1011, 1012)을 고려하여, 화면 에서 제공 가능한 기능이 우선적으로 인식되거나 실행될 수 있도록 자연어 이해를 수행할 수 있다. 일 실시 예 에 따른 전자 장치는, 음성 명령이 변환된 텍스트로부터 엔티티 \"바람과 함께 사라지다\"를 식별하고, 식별 된 엔티티를 화면에 디스플레이 되는 객체들(1011, 1012)과 비교할 수 있다. 전자 장치는, 식별된 엔티티 가 화면에 디스플레이 되는 객체들(1011, 1012)과 관련성이 있다고 생각되는 경우, 식별된 엔티티의 의미를 해 석하는 데 있어서 객체들과 관련된 데이터 구조를 이용할 수 있다. 일 실시 예에 따른 전자 장치는, 사용자의 음성 명령의 \"바람과 함께 사라지다\"를 클릭가능 객체와 관련된 영화 제목으로 해석할 수 있다. 따라서, 도 10a에 도시된 바와 같이, 사용자의 음성 명령에 응답하여, 화면에 디스플레이 되고 있는 객체와 관련된 영화 \"바람과 사라지다\"가 재생될 수 있다. 도 10b는 일반적인 전자 장치가 사용자의 음성 명령에 응답하여 제공하는 음성 인식 결과와 본 개시의 일 실시 예에 따른 전자 장치가 사용자의 음성 명령에 응답하여 제공하는 음성 인식 결과의 예를 도시한다. 도 10b는 일 실시 예에 따른 전자 장치가 영화 컨텐츠를 제공하는 애플리케이션을 실행하는 도중에 \"아이 언맨2 보여줘\"라는 사용자의 음성 명령을 수신하는 경우를 도시한다. 화면에 디스플레이되는 객체 의 타입은 클릭가능 텍스트 타입이고, 객체의 타입은 클릭가능 텍스트 타입이다. 화면은, 일반적인 자연어 이해에 따라 사용자에게 제공되는 음성 인식 결과를 도시한다. 일반적인 자 연어 이해에 따라 \"A를 보여줘\"가 A를 검색해달라는 의도로 해석될 수 있다. 이 경우, 전자 장치는 \"아이 언맨2 보여줘\"라는 사용자의 발화 의도를 아이언맨 시리즈를 검색하라는 것으로 해석할 수 있다. 따라서, 화면 에 도시된 바와 같이, 아이언맨 시리즈가 검색된 결과가 화면에 표시될 수 있다. 반면에, 화면는, 본 개시에서 제안하는 자연어 이해에 따라 사용자에게 제공되는 음성 인식 결과를 도시한다. 일 실시 예에 따른 전자 장치는, 화면에 디스플레이 되는 객체들(1031, 1032)을 고려하여, 화면에서 제공 가능한 기능이 우선적으로 인식되거나 실행될 수 있도록 자연어 이해를 수행할 수 있 다. 일 실시 예에 따른 전자 장치는, 사용자의 음성 명령 \"아이언맨2 보여줘\"를 클릭가능 객체와 관 련된 영화를 재생해 달라는 요청으로 해석할 수 있다. 따라서, 도 10b에 도시된 바와 같이, 사용자의 음성 명령 에 응답하여, 객체와 관련된 영화 \"아이언맨2\"가 재생될 수 있다. 도 11은 일반적인 전자 장치가 사용자의 음성 명령에 응답하여 제공하는 음성 인식 결과와 본 개시의 일 실시 예에 따른 전자 장치가 사용자의 음성 명령에 응답하여 제공하는 음성 인식 결과의 예를 도시한다. 본 개시의 일 실시 예에 따른 전자 장치는, 화면 상의 위치 정보를 포함하는 사용자의 음성 명령에 의해서 도 제어가 가능할 수 있다. 일 실시 예에 따른 전자 장치는, 사용자의 음성 명령과 관련된 화면 상에 디스 플레이 되는 하나 이상의 객체를 식별함에 있어서, 사용자의 음성 명령에 기초하여 위치 정보를 획득하고, 디스 플레이 되는 객체의 위치 정보에 기초한 음성 인식 서비스를 제공할 수 있다. 도 11에 도시된 바와 같이, 일 실시 예에 따른 전자 장치는 영화 컨텐츠를 제공하는 애플리케이션을 실행 하는 도중에 \"맨 오른쪽 영화 보여줘\" 또는 \"현재 커서의 왼쪽에 보이는 영화 틀어줘\"라는 사용자의 음성 명령을 수신하는 경우를 도시한다. 화면에 디스플레이되는 객체의 타입은 클릭가능 해석가능 타입 일 수 있다. 화면은, 일반적인 자연어 이해에 따라 사용자에게 제공되는 음성 인식 결과를 도시한다. 일반적인 전 자 장치는, 사용자의 음성 명령으로부터 획득된 텍스트에서 화면 상의 위치 정보를 나타내는 \"맨 오른쪽\" 또는 \"현재 커서의 왼쪽\"이라는 엔티티의 의미를 해석하지 못할 수 있다. 일반적인 전자 장치는, 화면 에 도시된 바와 같이, 음성 명령에 대한 해석이 제대로 수행되지 않았다는 응답 메시지를 출력할 수 있다. 반면에, 화면는, 본 개시에서 제안하는 자연어 이해에 따라 사용자에게 제공되는 음성 인식 결과를 도시한다. 일 실시 예에 따른 전자 장치는, 화면에 디스플레이 되는 객체들의 위치 정보를 고려하여, 화면에서 제공 가능한 기능이 우선적으로 인식되거나 실행될 수 있도록 자연어 이해를 수행할 수 있 다. 일 실시 예에 따른 전자 장치는, 화면에 디스플레이 되는 객체들의 위치 정보를 고려하여, 사용자의 음성 명령으로부터 획득된 텍스트에서 화면 상의 위치 정보를 나타내는 \"맨 오른쪽\" 또는 \"현재 커서의 왼쪽\"이 라는 엔티티의 의미를 해석할 수 있다. 일 실시 예에 따른 전자 장치는, 객체들의 위치 정보를 고려하여, \"맨 오른쪽\" 또는 \"현재 커서의 왼쪽\"이라는 엔티티가 클릭가능 객체를 가리키는 것으로 해석할 수 있다. 전자 장치는, 클릭가능 객체와 관련된 영화를 재생해 달라는 요청하는 것으로 사용자의 음성 명령을 해석할 수 있다. 따라서, 도 11에 도시된 바와 같이, 사용자의 음성 명령에 응답하여, 객체와 관련된 영 화가 재생될 수 있다. 상술한 바와 같이, 일 실시예에 따른 전자 장치는, 화면 상에 디스플레이 되는 객체들과 관련된 데이터 구 조에 기초하여 사용자의 음성 명령으로부터 변환된 텍스트를 해석함으로써, 디스플레이 되는 화면과 관련된 사 용자의 음성 명령에 대한 음성 인식 정확도를 높일 수 있다. 이하에서는, 일 실시 예에 따른 음성 인식 서비스를 제공하는 전자 장치의 구성을 설명한다. 이하에서 서 술하는 전자 장치의 각 구성은, 상술한 전자 장치가 동작하는 방법의 각 단계를 수행할 수 있다. 따 라서, 상술한 설명과 중복되는 설명은 생략한다. 도 12a는 본 개시의 일 실시 예에 따른 전자 장치의 구성을 나타내는 블록도이다. 본 개시의 일 실시 예에 따른 전자 장치는 컴퓨터 장치로 구현되는 고정형 단말이거나 이동형 단말일 수 있다. 전자 장치는, 예를 들어, 텔레비전, 스마트 폰(smart phone), 내비게이션, 컴퓨터, 노트북, 디지털 방송용 단말, 인공 지능 스피커, PDA(Personal Digital Assistants), PMP(Portable Multimedia Player), 및 태 블릿 PC 중 적어도 하나일 수 있으나, 이에 한정되지 않는다. 전자 장치는, 무선 또는 유선 통신 방식을 이용하여 네트워크를 통해 다른 디바이스 및/또는 서버와 통신할 수 있다. 도 12a를 참조하면, 전자 장치는, 수신부, 디스플레이, 프로세서, 및 메모리를 포함 할 수 있다. 도 12a에 도시된 구성 요소 모두가 전자 장치의 필수 구성 요소인 것은 아니다. 도 12a에 도 시된 구성 요소보다 많은 구성 요소에 의해 전자 장치가 구현될 수도 있고, 도 12a에 도시된 구성 요소보 다 적은 구성 요소에 의해 전자 장치가 구현될 수도 있다. 예를 들어, 도 12b에 도시된 바와 같이, 일부 실시 예에 따른 전자 장치는, 입력부, 출력부 및 통신 인터페이스를 더 포함할 수도 있다. 도 12a 및 도 12b에 도시된 적어도 하나의 구성 요소는 도 4 내지 도 6의 동작을 수행할 수 있다. 그러므로, 도 4 내지 도 6을 참조하여 상술한 설명과 중복되는 설명은 생략될 수 있다. 본 개시의 일 실시 예에 따른 수신부는 사용자로부터 음성 명령을 수신할 수 있다. 예를 들어, 수신부 는, 마이크로폰(Microphone)에 의해 외부의 소리를 전기적인 음향 데이터로 변환함으로써 음성 명령을 수 신할 수 있다. 도 12a에는, 수신부가, 전자 장치의 내부에 포함되는 것으로 도시되었으나, 다른 일 실시 예에 따르면 수신부는 별도의 디바이스 내에 포함되고 전자 장치와는 유, 무선으로 연결되는 형 태로 구현될 수 있다. 본 개시의 일 실시 예에 따른 디스플레이는, 전자 장치에서 처리되는 정보를 표시 출력한다. 예를 들 어, 디스플레이는, 전자 장치에 설치된 애플리케이션을 실행시키기 위한 아이콘을 표시하거나, 실행 되고 있는 애플리케이션으로부터 제공되는 화면 컨텐츠를 표시하거나, 전자 장치의 제어와 관련된 UI(User Interface) 또는 GUI(Graphic User Interface)를 표시할 수 있다. 예를 들어, 디스플레이는, 하나 이상의객체를 포함하는 화면을 표시할 수 있다. 디스플레이와 터치패드가 레이어 구조를 이루어 터치 스크린으로 구성되는 경우, 디스플레이는 출력 장치 이외에 입력 장치로도 사용될 수 있다. 디스플레이는 액정 디스플레이(liquid crystal display), 박 막 트랜지스터 액정 디스플레이(thin film transistor-liquid crystal display), 유기 발광 다이오드(organic light-emitting diode), 플렉시블 디스플레이(flexible display), 3차원 디스플레이(3D display), 전기영동 디 스플레이(electrophoretic display) 중에서 적어도 하나를 포함할 수 있다. 그리고 전자 장치의 구현 형태 에 따라 전자 장치는 디스플레이를 2개 이상 포함할 수 있다. 또한 다른 일 실시 예에 따르면 디스플 레이는 별도의 디바이스 내에 포함되고 전자 장치와는 유, 무선으로 연결되는 형태로 구현될 수 있다. 본 개시의 일 실시 예에 따른 메모리는, 음성 인식 서비스를 제공하기 위한 인스트럭션들, 음성 인식에 이 용되는 각종 모델, 데이터 구조, 신경망, 또는 사전 정보 등을 저장할 수 있다. 본 개시의 일 실시 예에 따른 프로세서는, 메모리에 저장된 하나 이상의 인스터럭션들을 실행함으로 써, 전자 장치를 제어하여 본 개시의 다양한 실시 예들에 따른 음성 인식 서비스를 제공할 수 있다. 도 12a에는 전자 장치가 하나의 프로세서를 포함하는 것으로 도시되었지만 본 개시는 도시된 실시 예에 제한되지 않는다. 전자 장치는 복수의 프로세서들을 포함할 수 있다. 전자 장치가 복수의 프로세서들 을 포함하는 경우, 후술하는 프로세서의 동작 및 기능은 복수의 프로세스들에서 부분적으로 수행될 수 있 다. 본 개시의 일 실시 예에 따른 프로세서는, 디스플레이의 화면 상에 하나 이상의 객체를 디스플레이하 는 도중에 수신부를 통해 사용자의 음성 명령을 수신할 수 있다. 프로세서는, 음성 명령이 수신됨에 따라, 화면 상에 디스플레이 되는 하나 이상의 객체를 식별하고, 하나 이상의 객체의 타입들에 기초하여 음성 명령으로부터 변환된 텍스트를 해석할 수 있다. 프로세서는, 텍스트의 해석 결과에 기초하여, 하나 이상의 객체 중에서 선택된 객체와 관련된 동작을 수행할 수 있다. 하나 이상의 객체의 타입들은, 전자 장치에 대한 사 용자 입력에 의해 선택 가능 한지 여부에 따라 구별될 수 있다. 이하, 프로세서의 동작을 보다 구체적으로 기술한다. 프로세서는, 디스플레이의 화면 상에 하나 이상의 객체를 디스플레이하고, 음성 명령을 해석하는데 이용하기 위하여 하나 이상의 객체에 관련된 데이터 구조를 생성할 수 있다. 일 실시 예에 따른 프로세서 는, 하나 이상의 객체에 대한 영상 처리를 통한 문자 판독 또는 하나 이상의 객체를 제공하는 애플리케이션의 메타 데이터 판독에 의해, 하나 이상의 객체의 타입들을 식별할 수 있다. 예를 들어, 프로세서는, 하나 이상의 객체가 전자 장치에 대한 사용자 입력에 의해 선택 가능 한지 또는 선택 불가능 한지, 텍스트 정보를 포함하는 지 또는 텍스트 정보를 포함하지 않는 지를 구분함으로써, 하 나 이상의 객체의 타입들을 식별할 수 있다. 일 실시 예에 따른 프로세서는, 하나 이상의 객체의 타입들에 기초하여 하나 이상의 객체의 우선 순위를 결정하고, 하나 이상의 객체와, 하나 이상의 객체와 관련된 용어들 간의 관계를 나타내는 트리 형태의 데이터 구조를 생성할 수 있다. 음성 명령을 해석하는데 이용하기 위해 생성되는 객체와 관련된 데이터 구조는, 도 7, 도 8, 도 9a, 및 도 9b에 대한 설명이 적용될 수 있다. 구체적인 설명은 생략한다. 일 실시 예에 따른 프로세서는, 소정 조건을 만족하면, 화면 컨텐츠 구성(예를 들어, 화면에 디스플레이 되는 하나 이상의 객체)과 관련하여 생성된 데이터 구조를 이용하여, 화면에서 제공 가능한 기능이 우선적으로 인식되거나 실행되도록 동작할 수 있다. 일 예로서, 프로세서는, 음성 명령을 텍스트로 변환하고, 텍스트로부터 사용자의 발화 의도의 타입을 결정 할 수 있다. 프로세서는, 제1 자연어 이해를 통해 텍스트를 1차적으로 해석함으로써 사용자의 발화 의도의 타입을 결정할 수 있다. 프로세서는, 발화 의도의 타입에 기초하여 제1모드로 동작할 지 또는 제2모드로 동작할 지 여부를 판단할 수 있다. 예를 들어, 전자 장치는, 발화 의도 타입이 소정 타입(예를 들어, 실행 가능 타입 또는 접근 가능 타입)이라고 판단되면 제1모드로 동작하고, 소정 타입이 아닌 경우 제2모드로 동작할 수 있다. 다른 예로서, 프로세서는, 음성 명령으로부터 텍스트를 획득하고, 텍스트에 활성화 단어가 포함되는 지 여 부를 판단할 수 있다. 프로세서는, 음성 명령이 변환된 텍스트에 활성화 단어가 포함되는 지 여부에 기초 하여 제1모드로 동작할 지 또는 제2모드로 동작할 지 여부를 판단할 수 있다. 예를 들어, 전자 장치는, 텍스트에 활성화 단어가 포함되면 제2모드로 동작하고, 텍스트에 활성화 단어가 포함되지 않으면 제1모드로 동작 할 수 있다. 예를 들어, \"Hi, Bixby\"가 활성화 단어로서 이용되는 경우, 전자 장치는, 사용자의 음성 명령 \"Hi, Bixby. 동영상 스트리밍 애플리케이션 실행해줘”에 응답하여 '동영상 스트리밍 애플리케이션'을 실행할 수 있다. '동 영상 스트리밍 애플리케이션'을 실행하는 중에, 전자 장치는, 사용자의 문맥 상의 대화(contextual dialogue)를 대기하는 상태에 있을 수 있다. 대기 상태에서 전자 장치는, 사용자가 \"Hi, Bixby\"를 호출하 는 경우 제2 모드로 동작하고, 사용자가 활성화 단어 없이 \"Stranger Things 틀어줘\"라고 발화하는 경우 제1 모 드로 동작할 수 있다. 또 다른 예로서, 프로세서는, 발화 의도 타입이 소정 타입(예를 들어, 실행 가능 타입 또는 접근 가능 타 입)이고, 화면에 디스플레이 되고 있는 객체에 대한 데이터 구조가 존재하는 경우, 제1모드로 동작할 것을 결정 할 수 있다. 프로세서는, 발화 의도 타입이 소정 타입이더라도, 화면에 디스플레이 되고 있는 객체에 대한 데이터 구조가 존재하지 않는 경우, 제2모드로 동작할 것을 결정할 수 있다. 전자 장치는, 제1모드에서, 화면 상에 디스플레이 되는 하나 이상의 객체의 타입들에 기초하여 생성된 데 이터 구조를 고려하여, 텍스트에 대한 자연어 이해를 수행할 수 있다. 반면에, 전자 장치는, 제2모드에서, 하나 이상의 객체의 타입들에 기초하여 생성된 데이터 구조를 고려하지 않고 텍스트에 대한 자연어 이해를 수행 할 수 있다. 제1모드에서 동작할 것으로 결정하는 경우, 프로세서는, 음성 명령이 수신됨에 따라, 화면 상에 디스플레 이 되는 하나 이상의 객체를 식별할 수 있다. 구체적으로, 일 실시 예에 따른 프로세서는, 발화 의도의 타 입 및 하나 이상의 객체의 타입들에 기초하여, 데이터 구조의 하나 이상의 객체의 우선 순위를 다시 결정할 수 있다. 일 실시 예에 따른 프로세서는, 사용자의 발화 의도의 타입에 따라, 하나 이상의 객체들의 타입들에 서로 다른 우선 순위를 부여할 수 있다. 예를 들어, 전자 장치는, 랭킹 테이블을 이용하여, 데이터 구조의 하나 이상의 객체에 대해 우선 순위를 다시 매기는 리랭킹(re-ranking)을 수행할 수 있다. 일 실시 예에 따른 프로세서는, 발화 의도의 타입 및 하나 이상의 객체들의 타입들에 기초하여, 하나 이상 의 객체에 대한 우선 순위가 다시 부여된 데이터 구조를 이용한 자연어 이해를 수행할 수 있다. 프로세서 는, 화면 상에 디스플레이 되는 객체와 관련된 데이터 구조에 기초하여, 텍스트를 해석할 수 있다. 일 실시 예에 따른 프로세서는, 텍스트의 해석 결과에 기초하여, 하나 이상의 객체 중에서 선택된 객체와 관련된 동작을 수행할 수 있다. 일 실시 예에 따른 프로세서는, 텍스트 해석 결과로서, 텍스트에 기초하여 결정되는 사용자의 발화 의도, 화면 상에 디스플레이 되는 하나 이상의 객체들 중에서 선택된 객체, 및 사용자의 발화 의도에 따라 선택된 객 체와 관련하여 실행해야 할 기능 중 적어도 하나에 대한 정보를 도출할 수 있다. 일 실시 예에 따른 프로세서는, 텍스트의 해석 결과에 기초하여, 화면 상에 디스플레이 되는 하나 이상의 객체들 중에서 선택된 객체와 관련된 컨텐츠(예를 들어, 오디오, 비디오 등)를 재생하는 동작, 선택된 객체와 관련된 이미지 또는 텍스트를 확대하여 디스플레이하는 동작, 또는 선택된 객체에 포함되는 텍스트를 음성으로 변환하여 출력하는 동작 중 적어도 하나를 수행할 수 있다. 한편, 도 12a에 도시된 구성 요소보다 많은 구성 요소에 의해 전자 장치가 구현될 수도 있다. 예를 들어, 도 12b에 도시된 바와 같이, 일부 실시 예에 따른 전자 장치는, 입력부, 출력부 및 통신 인터페 이스를 더 포함할 수도 있다. 도 12b는 본 개시의 일 실시 예에 따른 전자 장치의 구성을 나타내는 블록도이다. 입력부는, 전자 장치에 대한 사용자 입력을 수신할 수 있다. 예를 들어, 입력부는, 사용자의 터 치를 수신하는 터치 패널, 음성 명령을 수신하는 수신부, 또는 입력 인터페이스를 포함할 수 있 다. 입력부는, 사용자로부터 음성 인식 서비스와 관련된 설정을 입력 받거나, 제어 명령을 수신할 수 있다. 수신부는, 사용자의 음성 명령을 수신할 수 있다. 예를 들어, 수신부는, 마이크로폰(Microphone)에 의해 외부의 소리를 전기적인 음향 데이터로 변환함으로써 음성 명령을 직접 수신할 수 있다. 또는, 수신부는, 외부 장치에서 송신한 음성 명령을 수신할 수 있다. 또한, 입력 인터페이스는, 사용자의 푸시 조작을 수신하는 버튼, 사용자의 회전 조작을 수신하는 휠, 키보 드(key board), 및 돔 스위치 (dome switch) 등을 포함할 수 있다. 출력부는, 전자 장치에서 처리되거나 저장되는 정보를 출력할 수 있다. 예를 들어, 출력부는, 영상 신호를 출력 할 수 있는 디스플레이를 포함할 수 있다. 또는, 출력부는, 오디오 신호를 출력할 수 있는 스피커를 포함할 수 있다. 통신 인터페이스는, 전자 장치가 다른 장치 또는 서버와 통신을 하게 하는 하나 이상의 구성요소를 포함할 수 있다. 예를 들어, 통신부는, 근거리 통신 모듈, 유선 통신 모듈, 이동 통신 모듈 등을 포함할 수 있다. 일 실시 예에 따른 프로세서는, 화면 상에 디스플레이 되는 하나 이상의 객체들을 고려하여 사용자의 음성 명령을 해석한 결과에 기초하여, 스피커를 통해 응답 메시지를 출력하거나, 통신 인터페이스를 통해 해석 결과와 관련된 정보를 전송할 수 있다. 한편, 일 실시 예에 따른 음성 인식 서비스 제공 시스템은, 적어도 하나의 전자 장치 및 서버를 포함할 수 있으 며, 상술한 전자 장치의 동작의 일부 또는 전부는 전자 장치와 연결되는 서버에서 수행될 수 있다. 도 13은 본 개시의 일 실시 예에 따른 서버의 구성을 나타내는 블록도이다. 도 13을 참조하면, 일 실시 예에 따른 서버는, 통신 인터페이스, 메모리 및 프로세서를 포 함할 수 있다. 도 13에 도시된 구성 요소보다 많은 구성 요소에 의해 서버가 구현될 수 있다. 본 개시의 일 실시 예에 따른 통신 인터페이스는 외부의 전자 장치로부터 사용자의 음성 명령에 관한 정보 를 수신할 수 있다. \"음성 명령과 관련된 정보”는, 음성 명령을 포함하는 오디오 신호를 포함하거나, 음성 명 령으로부터 추출된 특징 벡터, 또는 음성 명령이 변환된 텍스트를 포함할 수 있다. 일 실시 예에 따른 서버는, 전자 장치의 화면 상에 디스플레이 되는 적어도 하나의 객체 및 전자 장치로부 터 수신된 음성 명령과 관련된 정보에 기초하여, 사용자의 음성 명령을 해석할 수 있다. 본 개시의 일 실시 예에 따른 메모리는, 음성 인식 서비스를 제공하기 위한 인스트럭션들, 음성 인식에 이 용되는 각종 모델, 데이터 구조, 신경망, 또는 사전 정보 등을 저장할 수 있다. 본 개시의 일 실시 예에 따른 프로세서는, 메모리에 저장된 하나 이상의 인스터럭션들을 실행함으로 써, 서버를 제어하여 본 개시의 다양한 실시 예들에 따른 음성 인식 서비스를 제공할 수 있다. 도 13에는 서버가 하나의 프로세서를 포함하는 것으로 도시되었지만 본 개시는 도시된 실시 예에 제한되지 않는 다. 서버는 복수의 프로세서들을 포함할 수 있다. 서버가 복수의 프로세서들을 포함하는 경우, 후술 하는 프로세서의 동작 및 기능은 복수의 프로세스들에서 부분적으로 수행될 수 있다. 프로세서는, 음성 명령을 해석하는데 이용하기 위하여, 전자 장치의 화면 상에 디스플레이 되는 하나 이상 의 객체에 관련된 데이터 구조를 생성할 수 있다. 일 실시 예에 따른 프로세서는, 하나 이상의 객체에 대 한 영상 처리를 통한 문자 판독 또는 하나 이상의 객체를 제공하는 애플리케이션의 메타 데이터 판독에 의해, 하나 이상의 객체의 타입들을 식별할 수 있다. 예를 들어, 프로세서는, 하나 이상의 객체가 전자 장치에 대한 사용자 입력에 의해 선택 가능 한지 또는 선택 불가능 한지, 텍스트 정보를 포함하는 지 또는 텍스트 정보를 포함하지 않는 지를 구분함으로써, 하나 이 상의 객체의 타입들을 식별할 수 있다. 일 실시 예에 따른 프로세서는, 하나 이상의 객체의 타입들에 기초하여 하나 이상의 객체의 우선 순위를 결정하고, 하나 이상의 객체와, 하나 이상의 객체와 관련된 용어들 간의 관계를 나타내는 데이터 구조를 생성할 수 있다. 본 개시의 일 실시 예에 따른 프로세서는, 전자 장치의 화면 상에 하나 이상의 객체가 디스플레이되는 도 중에 수신된 사용자의 음성 명령과 관련된 정보를 전자 장치로부터 수신할 수 있다. 프로세서는, 화면 상에 디스플레이 되는 하나 이상의 객체를 식별하고, 하나 이상의 객체의 타입들에 기초 하여 음성 명령으로부터 변환된 텍스트를 해석할 수 있다. 일 실시 예에 따른 프로세서는, 사용자의 발화 의도의 타입에 따라, 하나 이상의 객체들의 타입들에 서로 다른 우선 순위를 부여할 수 있다. 예를 들어, 서버는, 랭킹 테이블을 이용하여, 데이터 구조의 하나 이상 의 객체에 대해 우선 순위를 다시 매기는 리랭킹(re-ranking)을 수행할 수 있다. 일 실시 예에 따른 프로세서는, 발화 의도의 타입 및 하나 이상의 객체들의 타입들에 기초하여, 하나 이상 의 객체에 대한 우선 순위가 다시 부여된 데이터 구조를 이용한 자연어 이해를 수행할 수 있다. 프로세서 는, 화면 상에 디스플레이 되는 객체와 관련된 데이터 구조에 기초하여, 텍스트를 해석할 수 있다. 일 실시 예에 따른 프로세서는, 텍스트 해석 결과로서, 텍스트에 기초하여 결정되는 사용자의 발화 의도, 화면 상에 디스플레이 되는 하나 이상의 객체들 중에서 선택된 객체, 및 사용자의 발화 의도에 따라 선택된 객 체와 관련하여 실행해야 할 기능 중 적어도 하나에 대한 정보를 고려할 수 있다. 서버는, 텍스트 해석 결과를 전자 장치에게 전송함으로써, 전자 장치가 소정 동작을 수행하거나 응답 메시 지를 출력하도록 제어할 수 있다. 일 실시 예에 따른 프로세서는, 텍스트의 해석 결과에 기초하여, 전자 장치의 화면 상에 선택된 객체와 관 련된 컨텐츠(예를 들어, 오디오, 비디오 등)를 재생하는 동작, 선택된 객체와 관련된 이미지 또는 텍스트를 확 대하여 디스플레이하는 동작, 또는 선택된 객체에 포함되는 텍스트를 음성으로 변환하여 출력하는 동작 중 적어 도 하나를 수행하도록 전자 장치를 제어할 수 있다. 한편, 본 개시에 따른 음성 인식 방법은 인공지능 기술에 기초하여 프로세서와 메모리를 통해 동작된다. 프로세 서는 하나 또는 복수의 프로세서로 구성될 수 있다. 이때, 하나 또는 복수의 프로세서는 CPU, AP, DSP(Digital Signal Processor) 등과 같은 범용 프로세서, GPU, VPU(Vision Processing Unit)와 같은 그래픽 전용 프로세서 또는 NPU와 같은 인공지능 전용 프로세서일 수 있다. 하나 또는 복수의 프로세서는, 메모리에 저장된 기 정의된 동작 규칙 또는 인공지능 모델에 따라, 입력 데이터를 처리하도록 제어한다. 또는, 하나 또는 복수의 프로세서 가 인공지능 전용 프로세서인 경우, 인공지능 전용 프로세서는, 특정 인공지능 모델의 처리에 특화된 하드웨어 구조로 설계될 수 있다. 기 정의된 동작 규칙 또는 인공지능 모델은 학습을 통해 만들어진 것을 특징으로 한다. 여기서, 학습을 통해 만 들어진다는 것은, 기본 인공지능 모델이 학습 알고리즘에 의하여 다수의 학습 데이터들을 이용하여 학습됨으로 써, 원하는 특성(또는, 목적)을 수행하도록 설정된 기 정의된 동작 규칙 또는 인공지능 모델이 만들어짐을 의미 한다. 이러한 학습은 본 개시에 따른 인공지능이 수행되는 기기 자체에서 이루어질 수도 있고, 별도의 서버 및/ 또는 시스템을 통해 이루어 질 수도 있다. 학습 알고리즘의 예로는, 지도형 학습(supervised learning), 비지도 형 학습(unsupervised learning), 준지도형 학습(semi-supervised learning) 또는 강화 학습(reinforcement learning)이 있으나, 전술한 예에 한정되지 않는다. 인공지능 모델은, 복수의 신경망 레이어들로 구성될 수 있다. 복수의 신경망 레이어들 각각은 복수의 가중치들 (weight values)을 갖고 있으며, 이전(previous) 레이어의 연산 결과와 복수의 가중치들 간의 연산을 통해 신경 망 연산을 수행한다. 복수의 신경망 레이어들이 갖고 있는 복수의 가중치들은 인공지능 모델의 학습 결과에 의 해 최적화될 수 있다. 예를 들어, 학습 과정 동안 인공지능 모델에서 획득한 로스(loss) 값 또는 코스트(cost) 값이 감소 또는 최소화되도록 복수의 가중치들이 갱신될 수 있다. 인공 신경망은 심층 신경망(DNN:Deep Neural Network)를 포함할 수 있으며, 예를 들어, CNN (Convolutional Neural Network), DNN (Deep Neural Network), RNN (Recurrent Neural Network), RBM (Restricted Boltzmann Machine), DBN (Deep Belief Network), BRDNN(Bidirectional Recurrent Deep Neural Network) 또는 심층 Q-네트워크 (Deep Q-Networks) 등이 있으나, 전술한 예에 한정되지 않는다. 또한, 개시된 실시 예들은 컴퓨터로 읽을 수 있는 저장 매체(computer-readable storage media)에 저장된 명령 어를 포함하는 S/W 프로그램으로 구현될 수 있다. 컴퓨터는, 저장 매체로부터 저장된 명령어를 호출하고, 호출된 명령어에 따라 개시된 실시 예에 따른 동작이 가 능한 장치로서, 개시된 실시 예들에 따른 전자 장치 및 서버를 포함할 수 있다. 컴퓨터로 읽을 수 있는 저장매체는, 비일시적(non-transitory) 저장매체의 형태로 제공될 수 있다. 여기서, ‘ 비일시적’은 저장매체가 신호(signal)를 포함하지 않으며 실재(tangible)한다는 것을 의미할 뿐 데이터가 저장 매체에 반영구적 또는 임시적으로 저장됨을 구분하지 않는다. 또한, 개시된 실시 예들에 따른 전자 장치 또는 방법은 컴퓨터 프로그램 제품(computer program product)에 포 함되어 제공될 수 있다. 컴퓨터 프로그램 제품은 상품으로서 판매자 및 구매자 간에 거래될 수 있다.컴퓨터 프로그램 제품은 S/W 프로그램, S/W 프로그램이 저장된 컴퓨터로 읽을 수 있는 저장 매체를 포함할 수 있다. 예를 들어, 컴퓨터 프로그램 제품은 전자 장치의 제조사 또는 전자 마켓(예, 구글 플레이 스토어, 앱 스 토어)을 통해 전자적으로 배포되는 S/W 프로그램 형태의 상품(예, 다운로더블 앱)을 포함할 수 있다. 전자적 배 포를 위하여, S/W 프로그램의 적어도 일부는 저장 매체에 저장되거나, 임시적으로 생성될 수 있다. 이 경우, 저 장 매체는 제조사의 서버, 전자 마켓의 서버, 또는 SW 프로그램을 임시적으로 저장하는 중계 서버의 저장매체가 될 수 있다. 컴퓨터 프로그램 제품은, 서버 및 단말(예로, 음성 인식 서비스 제공 장치 또는 디바이스)로 구성되는 시스템에 서, 서버의 저장매체 또는 단말의 저장매체를 포함할 수 있다. 또는, 서버 또는 단말과 통신 연결되는 제3 장치 (예, 스마트 폰)가 존재하는 경우, 컴퓨터 프로그램 제품은 제3 장치의 저장매체를 포함할 수 있다. 또는, 컴퓨 터 프로그램 제품은 서버로부터 단말 또는 제3 장치로 전송되거나, 제3 장치로부터 단말로 전송되는 S/W 프로그 램 자체를 포함할 수 있다. 이 경우, 서버, 단말 및 제3 장치 중 하나가 컴퓨터 프로그램 제품을 실행하여 개시된 실시 예들에 따른 방법을 수행할 수 있다. 또는, 서버, 단말 및 제3 장치 중 둘 이상이 컴퓨터 프로그램 제품을 실행하여 개시된 실시 예들에 따른 방법을 분산하여 실시할 수 있다. 예를 들면, 서버(예로, 클라우드 서버 또는 인공 지능 서버 등)가 서버에 저장된 컴퓨터 프로그램 제품을 실행 하여, 서버와 통신 연결된 단말이 개시된 실시 예들에 따른 방법을 수행하도록 제어할 수 있다. 또 다른 예로, 제3 장치가 컴퓨터 프로그램 제품을 실행하여, 제3 장치와 통신 연결된 단말이 개시된 실시 예에 따른 방법을 수행하도록 제어할 수 있다. 제3 장치가 컴퓨터 프로그램 제품을 실행하는 경우, 제3 장치는 서버로부터 컴퓨터 프로그램 제품을 다운로드하 고, 다운로드된 컴퓨터 프로그램 제품을 실행할 수 있다. 또는, 제3 장치는 프리로드된 상태로 제공된 컴퓨터 프로그램 제품을 실행하여 개시된 실시 예들에 따른 방법을 수행할 수도 있다.도면 도면1 도면2 도면3a 도면3b 도면4 도면5 도면6 도면7 도면8 도면9a 도면9b 도면10a 도면10b 도면11 도면12a 도면12b 도면13"}
{"patent_id": "10-2021-0034865", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 일반적인 전자 장치가 사용자의 음성 명령을 이해하지 못하는 경우를 설명한다. 도 2는 본 개시의 일 실시 예에 따른 전자 장치가 화면 상에 디스플레이 되는 객체를 고려하여 사용자의 음성 명령에 대한 음성 인식 서비스를 제공하는 방법을 설명한다. 도 3a는 본 개시의 일 실시 예에 따른 음성 인식 시스템의 예시를 나타낸다. 도 3b는 본 개시의 일 실시 예에 따른 음성 인식 시스템의 예시를 나타낸다. 도 4는 본 개시의 일 실시 예에 따른 전자 장치가 음성 인식 서비스를 제공하는 방법의 흐름도를 도시한다. 도 5는 본 개시의 일 실시 예에 따른 전자 장치가 화면 상에 디스플레이 되는 객체들에 관한 데이터 구조를 생 성하는 방법의 흐름도를 도시한다. 도 6은 본 개시의 일 실시 예에 따른 전자 장치가 음성 인식 서비스를 제공하는 방법의 흐름도를 도시한다. 도 7은 본 개시의 일 실시 예에 따른 전자 장치가 객체에 대해서 결정하는 우선 순위의 예를 도시한다. 도 8은 본 개시의 일 실시 예에 따른 전자 장치가 음성 명령을 해석하기 위해 이용하는 객체 정보의 예를 도시 한다. 도 9a는 본 개시의 일 실시 예에 따른 전자 장치가, 사용자가 음성 명령을 발화한 의도에 기초하여 데이터 구조 내의 복수의 객체들의 우선 순위를 다시 결정하는 예를 도시한다. 도 9b는 본 개시의 일 실시 예에 따른 전자 장치가, 사용자가 음성 명령을 발화한 의도에 기초하여 데이터 구조 내의 복수의 객체들의 우선 순위를 다시 결정하는 예를 도시한다. 도 10a는 일반적인 전자 장치가 사용자의 음성 명령에 응답하여 제공하는 음성 인식 결과와 본 개시의 일 실시 예에 따른 전자 장치가 사용자의 음성 명령에 응답하여 제공하는 음성 인식 결과의 예를 도시한다. 도 10b는 일반적인 전자 장치가 사용자의 음성 명령에 응답하여 제공하는 음성 인식 결과와 본 개시의 일 실시 예에 따른 전자 장치가 사용자의 음성 명령에 응답하여 제공하는 음성 인식 결과의 예를 도시한다. 도 11은 일반적인 전자 장치가 사용자의 음성 명령에 응답하여 제공하는 음성 인식 결과와 본 개시의 일 실시 예에 따른 전자 장치가 사용자의 음성 명령에 응답하여 제공하는 음성 인식 결과의 예를 도시한다. 도 12a는 본 개시의 일 실시 예에 따른 전자 장치의 구성을 나타내는 블록도이다. 도 12b는 본 개시의 일 실시 예에 따른 전자 장치의 구성을 나타내는 블록도이다. 도 13은 본 개시의 일 실시 예에 따른 서버의 구성을 나타내는 블록도이다."}
