{"patent_id": "10-2021-0193690", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0104399", "출원번호": "10-2021-0193690", "발명의 명칭": "질의문장 분류 시스템 및 분류 방법", "출원인": "동국대학교 산학협력단", "발명자": "양기주"}}
{"patent_id": "10-2021-0193690", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "질의 형태를 갖는 적어도 하나의 입력문장을 입력데이터로 입력받는 입력부;상기 입력문장의 구조적 특성을 반영하여 모방데이터를 생성하고, 상기 모방데이터와 사전에 학습된 언어모델로부터 생성된 비교데이터를 비교하여 상기 입력문장에 대한 유형을 결정하여 출력데이터를 생성하는 분류수단;및상기 출력데이터가 출력되는 출력부를 포함하는 문장 분류 시스템."}
{"patent_id": "10-2021-0193690", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1 항에 있어서,상기 분류수단은,상기 입력문장의 상기 구조적 특성을 분석하여 분석데이터를 생성하는 문장분석수단;상기 분석데이터 및 외부 노이즈를 입력받아 상기 입력문장에 대한 유형을 예측하여 상기 모방데이터를 생성하는 생성수단;복수의 질의문장들 각각의 유형에 대한 분류를 사전에 학습하고, 상기 입력문장에 대응하는 유형을 특정하여 상기 비교데이터를 생성하는 언어학습모델; 및상기 모방데이터와 상기 비교데이터를 비교하여 상기 출력데이터를 생성하는 구별수단을 포함하는 질의문장 분류 시스템."}
{"patent_id": "10-2021-0193690", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 2 항에 있어서,상기 문장분석수단은,상기 입력문장을 복수의 단위단어(sub-word)들로 토큰화하여 제1 중간데이터를 생성하는 토크나이저;상기 토크나이저로부터 상기 제1 중간데이터를 수신하고, 상기 단위단어들 사이의 위계 관계를 분석하여 상기입력 문장의 구조를 결정하고, 상기 구조를 파스 트리 형태로 만들어 제2 중간데이터를 생성하는 파싱부; 및상기 제2 중간데이터를 기초로 상기 분석데이터를 생성하는 추출부를 포함하는 질의문장 분류 시스템."}
{"patent_id": "10-2021-0193690", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 3 항에 있어서,상기 생성수단은 상기 구별수단으로부터 기출력된 기출력데이터를 참조하여 상기 입력문장에 대한 유형을 예측하는 질의문장 분류 시스템."}
{"patent_id": "10-2021-0193690", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제 3 항에 있어서,공개특허 10-2023-0104399-3-상기 문장분석수단은 상기 분석데이터를 복수 차례 생성하고, 상기 구별수단은 상기 출력데이터를 복수 차례 생성하고, 상기 생성수단은 상기 모방데이터를 복수 차례 생성하고, 상기 언어학습모델은 상기 비교데이터를 복수차례 생성하고,상기 구별수단으로부터 생성된 제n 차 출력데이터는 상기 생성수단에 전송되고,상기 생성수단은 상기 제n 차 출력데이터를 제n+1 차 분석데이터 및 상기 외부 노이즈와 함께 입력받아 상기 입력 문장에 대한 유형을 예측하여 제n+1 차 모방데이터를 생성하고,상기 구별수단은 상기 제n+1 차 모방데이터 및 제n+1 차 비교데이터와의 차이를 비교하여 제n+1 차 출력데이터를 생성하고,상기 n는 1 이상의 자연수인 질의문장 분류 시스템."}
{"patent_id": "10-2021-0193690", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제 4 항에 있어서,상기 생성수단은,상기 분석데이터, 상기 외부 노이즈, 및 상기 기출력데이터를 입력받아, 상기 분석데이터, 상기 외부 노이즈,및 상기 기출력데이터를 동일 차원의 벡터 형태로 변환 및 합성하여 가공데이터를 생성하는 전처리부; 및상기 가공데이터를 입력받아 상기 입력 문장에 대한 유형을 예측하여 상기 모방데이터를 생성하는 제너레이터를포함하는 질의문장 분류 시스템."}
{"patent_id": "10-2021-0193690", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제 3 항에 있어서,상기 추출부는 상기 파스 트리 형태의 상기 제2 중간데이터를 입력받아 벡터 형태의 상기 분석데이터를 생성하는 그래프 신경망(GNN, Graph Neural Network)을 포함하는 질의문장 분류 시스템."}
{"patent_id": "10-2021-0193690", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제 7 항에 있어서,상기 그래프 신경망은 GraphSAGE인 질의문장 분류 시스템."}
{"patent_id": "10-2021-0193690", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제 2 항에 있어서,상기 언어학습모델은 BERT 모델(Bidirectional Encoder Representations from Transformers Model)인 질의문장분류 시스템."}
{"patent_id": "10-2021-0193690", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제 3 항에 있어서,상기 파싱부는 상기 단위단어들 사이의 의존 관계를 분석하는 의존성 파서(Dependency parser)를 포함하는 질의문장 분류 시스템.공개특허 10-2023-0104399-4-청구항 11 제 1 항에 있어서,상기 출력데이터는 상기 입력문장의 유형 후보들 각각에 대한 확률값의 집합인 질의문장 분류 시스템."}
{"patent_id": "10-2021-0193690", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제 7 항에 있어서,상기 입력부에 입력되는 입력문장에 대한 유형 분류 정확도는 51% 이상인 질의문장 분류 시스템."}
{"patent_id": "10-2021-0193690", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제 7 항에 있어서,상기 입력부에 동일한 입력문장이 제m 차례 반복 입력되고, 상기 출력부로부터 제1 내지 제m 출력데이터들이 출력되고,상기 m이 10 이하인 자연수일 때, 상기 제m 출력데이터에 대한 상기 유형 분류 정확도의 최대값은 62.2% 이상인질의문장 분류 시스템."}
{"patent_id": "10-2021-0193690", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제 7 항에 있어서,상기 입력부에 입력 가능한 상기 입력문장의 최대 개수는 5452개 이상인 질의문장 분류 시스템."}
{"patent_id": "10-2021-0193690", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "입력부가 문장분석수단 및 언어학습모델 각각에 질의 형태를 갖는 적어도 하나의 입력문장을 입력하는 단계;상기 문장분석수단이 상기 입력문장의 구조적 특징을 분석하여 분석데이터를 생성하는 단계;생성수단이 상기 분석데이터 및 외부 노이즈를 입력받아 상기 입력문장에 대한 유형을 예측하여 모방데이터를생성하는 단계;복수의 질의문장들 각각의 유형에 대한 분류가 사전에 학습된 언어학습모델이 상기 입력문장에 대응하는 유형을특정하여 비교데이터를 생성하는 단계;구별수단이 상기 모방데이터와 상기 비교데이터를 비교하여 출력데이터를 생성하는 단계를 포함하는 질의문장분류 방법."}
{"patent_id": "10-2021-0193690", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제 15 항에 있어서,상기 단계들 각각은 복수 차례 반복 수행되고,제n 차 출력데이터 생성 단계에서, 상기 제n 차 출력데이터는 상기 생성수단에 재입력되고,제n+1 차 모방데이터를 생성하는 단계에서, 상기 생성수단은 상기 재입력된 제n 차 출력데이터, 제n+1차 분석데이터, 상기 외부 노이즈를 기초로하여 제n+1 차 입력문장에 대한 유형을 예측하는 질의문장 분류 방법.공개특허 10-2023-0104399-5-청구항 17 제 15 항에 있어서,상기 분석데이터를 생성하는 단계는,토크나이저가 상기 입력문장을 복수의 단위단어(sub-word)들로 토큰화하여 제1 중간데이터를 생성하는 단계;파싱부가 상기 제1 중간데이터를 수신하여 상기 단위단어들 사이의 위계 관계를 분석하여 상기 입력 문장의 구조를 결정하는 단계;파싱부가 상기 입력 문장의 구조를 파스 트리 형태로 만들어 제2 중간데이터를 생성하는 단계; 및그래프 신경망(GNN, Graph Neural Network)이 상기 제2 중간데이터를 입력받아 벡터 형태의 상기 분석데이터를생성하는 단계를 포함하는 질의문장 분류 방법."}
{"patent_id": "10-2021-0193690", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제 15 항에 있어서,상기 모방데이터를 생성하는 단계는,상기 생성수단의 전처리부가 상기 분석데이터, 상기 외부 노이즈 및 기출력데이터를 동일 차원의 벡터 형태로변환 및 합성하여 가공데이터를 생성하는 단계; 및상기 생성수단의 제너레이터가 상기 가공데이터를 입력받고, 상기 입력 문장에 대한 유형을 예측하여 상기 모방데이터를 생성하는 단계를 포함하는 질의문장 분류 방법."}
{"patent_id": "10-2021-0193690", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명의 실시 예에 따른 질의문장 형태를 갖는 적어도 하나의 입력 문장을 입력데이터로 입력받는 입력부, 상 기 입력 문장의 구조적 특성을 반영하여 모방데이터를 생성하고, 생성된 상기 모방데이터와 사전에 학습된 언어 모델 간의 유사도를 비교하여 상기 입력 문장에 대한 유형을 결정하여 출력데이터를 생성하는 분류수단, 및 상기 출력데이터가 출력되는 출력부를 포함한다."}
{"patent_id": "10-2021-0193690", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 질의문장 분류 시스템 및 분류 방법에 관한 것으로, 상세하게는 질의문장에 대한 질의 유형 분류 정 확도가 향상된 질의문장 분류 시스템에 관한 것이다."}
{"patent_id": "10-2021-0193690", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "최근, 인공지능 기술과 컴퓨터 장비의 발전에 힘입어, 질의응답 또는 대화 시스템에 대한 개발이 활발하다. 질 의응답 시스템은 채팅, 모바일 기기 및 지능형 로봇 등의 여러 응용시스템에 적용되고 있으며, 이에 의하여 질 의응답의 정확성 및 신속성 향상을 위한 기술에 관심이 집중되고 있다. 질의문장 분류(Question Classification)는 질의 응답 시스템(Question and Answering System)의 기본적인 작업 중 하나로, 질문 유형 을 구분하는 작업이다. 질문에 대한 보다 정확하고 빠른 답을 찾기 위해서는 질문 유형에 대한 정확한 분류가 요구된다."}
{"patent_id": "10-2021-0193690", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명의 목적은 질의 유형의 분류 정확도가 향상된 질의문장 분류 시스템을 제공하는 데 있다."}
{"patent_id": "10-2021-0193690", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 실시 예에 따른 질의문장 분류 시스템은 질의 형태를 갖는 적어도 하나의 입력문장을 입력데이터로 입력받는 입력부, 상기 입력문장의 구조적 특성을 반영하여 모방데이터를 생성하고, 상기 모방데이터와 사전에학습된 언어모델로부터 생성된 비교데이터를 비교하여 상기 입력문장에 대한 유형을 결정하여 출력데이터를 생 성하는 분류수단, 및 상기 출력데이터가 출력되는 출력부를 포함한다. 상기 분류수단은, 상기 입력문장의 상기 구조적 특성을 분석하여 분석데이터를 생성하는 문장분석수단, 상기 분 석데이터 및 외부 노이즈를 입력받아 상기 입력문장에 대한 유형을 예측하여 상기 모방데이터를 생성하는 생성 수단, 복수의 질의문장들 각각의 유형에 대한 분류를 사전에 학습하고, 상기 입력문장에 대응하는 유형을 특정 하여 상기 비교데이터를 생성하는 언어학습모델, 및 상기 모방데이터와 상기 비교데이터를 비교하여 상기 출력 데이터를 생성하는 구별수단을 포함한다. 상기 문장분석수단은, 상기 입력문장을 복수의 단위단어(sub-word)들로 토큰화하여 제1 중간데이터를 생성하는 토크나이저, 상기 토크나이저로부터 상기 제1 중간데이터를 수신하고, 상기 단위단어들 사이의 위계 관계를 분 석하여 상기 입력 문장의 구조를 결정하고, 상기 구조를 파스 트리 형태로 만들어 제2 중간데이터를 생성하는 파싱부, 및 상기 제2 중간데이터를 기초로 상기 분석데이터를 생성하는 추출부를 포함한다. 상기 생성수단은 상기 구별수단으로부터 기생성된 기출력데이터를 참조하여 상기 입력문장에 대한 유형을 예측 한다. 상기 문장분석수단은 상기 분석데이터를 복수 차례 생성하고, 상기 구별수단은 상기 출력데이터를 복수 차례 생 성하고, 상기 생성수단은 상기 모방데이터를 복수 차례 생성하고, 상기 언어학습모델은 상기 비교데이터를 복수 차례 생성하고, 상기 구별수단으로부터 생성된 제n 차 출력데이터는 상기 생성수단에 전송되고, 상기 생성수단 은 상기 제n 차 출력데이터를 상기 제n+1 차 분석데이터 및 상기 외부 노이즈와 함께 입력받아 상기 입력 문장 에 대한 유형을 예측하여 제n+1 차 모방데이터를 생성하고, 상기 구별수단은 상기 제n+1 차 모방데이터 및 제 n+1 차 비교데이터와의 차이를 비교하여 제n+1 차 출력데이터를 생성하고, 상기 n는 1 이상의 자연수이다. 상기 생성수단은, 상기 분석데이터, 상기 외부 노이즈, 및 상기 기출력데이터를 입력받아, 상기 분석데이터, 상 기 외부 노이즈, 및 상기 기출력데이터를 동일 차원의 벡터 형태로 변환 및 합성하여 가공데이터를 생성하는 전 처리부 및 상기 가공데이터를 입력받아 상기 입력 문장에 대한 유형을 예측하여 상기 모방데이터를 생성하는 제 너레이터를 포함한다. 상기 추출부는 상기 파스 트리 형태의 상기 제2 중간데이터를 입력받아 그래프 형태의 상기 분석데이터를 생성 하는 그래프 신경망(GNN, Graph Neural Network)을 포함한다. 상기 그래프 신경망은 GraphSAGE이다. 상기 언어학습모델은 BERT 모델(Bidirectional Encoder Representations from Transformers Model)이다. 상기 파싱부는 상기 단위단어들 사이의 의존 관계를 분석하는 의존성 파서(Dependency parser)를 포함한다. 상기 출력데이터는 상기 입력문장의 유형 후보들 각각에 대한 확률값의 집합이다. 상기 입력부에 입력되는 입력문장에 대한 유형 분류 정확도는 51% 이상이다. 상기 입력부에 동일한 입력문장이 제m 차례 반복 입력되고, 상기 출력부로부터 제1 내지 제m 출력데이터들이 출 력되고, 상기 m이 10 이하인 자연수일 때, 상기 제m 출력데이터에 대한 상기 유형 분류 정확도의 최대값은 62.2% 이상이다. 상기 입력부에 입력 가능한 상기 입력문장의 최대 개수는 5452개 이상이다. 본 발명의 실시 예에 따른 질의문장 분류 방법은, 입력부가 문장분석수단 및 언어학습모델 각각에 질의 형태를 갖는 적어도 하나의 입력문장을 입력하는 단계, 상기 문장분석수단이 상기 입력문장의 구조적 특징을 분석하여 분석데이터를 생성하는 단계, 생성수단이 상기 분석데이터 및 외부 노이즈를 입력받아 상기 입력문장에 대한 유 형을 예측하여 모방데이터를 생성하는 단계, 복수의 질의문장들 각각의 유형에 대한 분류가 사전에 학습된 언어 학습모델이 상기 입력문장에 대응하는 유형을 특정하여 비교데이터를 생성하는 단계, 구별수단이 상기 모방데이 터와 상기 비교데이터를 비교하여 출력데이터를 생성하는 단계를 포함한다. 상기 단계들 각각은 복수 차례 반복 수행되고, 제n 차 출력데이터 생성 단계에서, 상기 제n 차 출력데이터는 상 기 생성수단에 재입력되고, 제n+1 차 모방데이터를 생성하는 단계에서, 상기 생성수단은 상기 재입력된 제n 차 출력데이터, 제n+1차 분석데이터, 상기 외부 노이즈를 기초로하여 제n+1 차 입력문장에 대한 유형을 예측한다. 상기 분석데이터를 생성하는 단계는, 토크나이저가 상기 입력문장을 복수의 단위단어(sub-word)들로 토큰화하여 제1 중간데이터를 생성하는 단계, 파싱부가 상기 제1 중간데이터를 수신하여 상기 단위단어들 사이의 위계 관계 를 분석하여 상기 입력 문장의 구조를 결정하는 단계, 파싱부가 상기 입력 문장의 구조를 파스 트리 형태로 만 들어 제2 중간데이터를 생성하는 단계, 및 그래프 신경망(GNN, Graph Neural Network)이 상기 제2 중간데이터를 입력받아 그래프 형태의 상기 분석데이터를 생성하는 단계를 포함한다. 상기 모방데이터를 생성하는 단계는, 상기 분석데이터, 상기 외부 노이즈 및 기출력데이터를 동일 차원의 벡터 형태로 변환 및 합성하여 가공데이터를 생성하는 단계, 및 제너레이터가 상기 가공데이터를 입력받고, 상기 입 력 문장에 대한 유형을 예측하여 상기 모방데이터를 생성하는 단계를 포함한다."}
{"patent_id": "10-2021-0193690", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명에 의하면, 질의 유형에 대한 분류 정확도가 향상될 수 있다."}
{"patent_id": "10-2021-0193690", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하에서 설명되는 모든 실시 예들은 본 발명의 이해를 돕기 위해 예시적으로 나타낸 것이며, 여기에 설명된 실 시 예들과 다르게 변형되어 다양한 실시 형태로 실시될 수 있다. 또한, 본 발명을 설명함에 있어서, 관련된 공 지 기능 혹은 공지 구성요소에 대한 구체적인 설명이 본 발명의 요지를 불필요하게 흐릴 수 있다고 판단되는 경 우, 그 구체적인 설명은 생략하도록 한다. 첨부된 도면은 발명의 이해를 돕기 위해서 실제 축척대로 도시된 것이 아니라 일부 구성요소의 치수가 과장되게 도시될 수 있으며, 각 구성요소들에 참조번호를 기재할 때, 동일한 구성요소들에 대해서는 다른 도면에 표시되 더라도 가능한 한 동일한 부호로 표시하였다. 또한, 본 발명의 실시 예의 구성 요소를 설명하는 데 있어서, 제1, 제2, A, B, (a), (b) 등의 용어를 사용할 수 있다. 이러한 용어는 그 구성 요소를 다른 구성 요소와 구별하기 위한 것일 뿐, 그 용어에 의해 해당 구성 요소 의 본질이나 차례 또는 순서 등이 한정되지 않는다. 어떤 구성 요소가 다른 구성요소에 '연결', '결합' 또는 ' 접속'된다고 기재된 경우, 그 구성 요소는 그 다른 구성요소에 직접적으로 연결, 결합 또는 접속될 수 있지만, 그 구성 요소와 그 다른 구성요소 사이에 또 다른 구성 요소가 '연결', '결합' 또는 '접속'될 수도 있다고 이해 되어야 할 것이다. 따라서, 본 명세서에 기재된 실시 예와 도면에 도시된 구성은 본 발명의 가장 바람직한 실시 예에 불과할 뿐이 고 본 발명의 기술적 사상을 모두 대변하는 것은 아니므로, 본 발명에 대한 다양한 변형 실시 예들이 있을 수 있다. 그리고, 본 명세서 및 청구범위에서 사용된 용어나 단어는 통상적이거나 사전적인 의미로 한정되어서는 안되며, 발명자는 그 자신의 발명을 가장 최선의 방법으로 설명하기 위해 용어의 개념을 적절하게 정의할 수 있다는 원 칙에 입각하여 본 발명의 기술적 사상에 부합하는 의미와 개념으로 해석되어야만 한다.또한, 본 발명은 이하에서 개시되는 실시 예들에 한정되는 것이 아니라 서로 다른 다양한 형태로 구현될"}
{"patent_id": "10-2021-0193690", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "것이며, 단지 본 실시 예들은 본 발명의 개시가 완전하도록 하며, 본 발명이 속하는 기술분야에서 통상의 지식 을 가진 자에게 발명의 범주를 완전하게 알려주기 위해 제공되는 것이며, 본 발명은 청구항의 범주에 의해 정의 될 뿐이다. 또한, 본 출원에서 사용된 단수의 표현은 문맥상 명백히 다른 것을 뜻하지 않는 한, 복수의 표현을 포함한다. 도 1은 본 발명의 실시 예에 따른 질의문장 분류 시스템의 구성이 간략하게 도시된 블록도이다. 도 1을 참조하면, 본 발명의 실시 예에 따른 질의문장 분류 시스템은 입력되는 질의 형태의 입력문장(I D)에 대한 카테고리, 즉 질의 유형을 분류하는 시스템이다. 질의문장 분류 시스템은 입력부 분류수단, 출력부를 포함한다. 입력부는 입력데이터(ID)를 입력받는다. 입력데이터(ID)는 질의 형태를 갖는 적어도 하나의 입력문장일 수 있다. 상기 질의 형태는 질의 문장의 카테고리를 의미한다. 본 실시 예에서, 입력부에 복수의 입력문장 (ID)이 입력될 수 있다. 예시적으로, 입력부에 입력가능한 입력문장(ID)의 최대 개수는 5452개 이상일 수 있다. 입력부에 입력된 입력문장(ID)은 후술될 분류수단의 문장분석수단 및 언어학습모델 에 각각 전송된다. 분류수단은 입력문장(ID)의 구조적 특성을 고려하여 복수의 질의 유형 후보들 중 입력문장(ID)에 대한 질 의 유형을 결정하여 출력데이터를 생성한다. 본 실시 예에서, 질의 유형 후보들은 50개 이상일 수 있다. 분류수단은 문장분석수단, 생성수단, 언어학습모델, 및 구별수단을 포함한다. 문장분석수단은 입력부로부터 수신된 입력문장(ID)의 구조적 특성을 분석하여 분석데이터(VD)를 생성 한다. 문장분석수단는 생성된 분석데이터(VD)를 생성수단에 전송한다. 문장분석수단에 관하여 이하, 도 2 내지 도 4에서 보다 상세히 후술된다. 생성수단은 문장분석수단으로부터 분석데이터(VD)를 수신한다. 또한, 생성수단 분석데이터(VD) 외에 외부로부터 노이즈(ND)를 입력받는다. 생성수단은 분석데이터(VD) 및 외부 노이즈(ND)를 입력받아 기 계 학습을 수행하고, 입력문장(ID)에 대한 유형을 예측하여 모방데이터(FD)를 생성한다. 즉, 모방데이터(FD)는 생성수단이 예측한 입력문장(ID)의 질의 유형에 해당한다. 모방데이터(FD)는 구별수단에 전송된다. 본 발명의 실시 예에 따르면, 생성수단은 구별수단으로부터 사전에 생성된 기출력데이터를 참조하여 입력문장(ID)에 대한 유형을 예측할 수 있다. 즉, 구별수단에서 생성된 출력데이터(OD)는 출력부를 통하여 출력되는 동시에, 생성수단의 참조데이터(CD)로 활용될 수 있다. 생성수단는 참조데이터(CD), 분석데이터(VS) 및 외부 노이즈(ND)를 바탕으로 입력문장(ID)에 대한 유형을 예측할 수 있다. 언어학습모델은 말뭉치(Corpus)가 사전 학습된 모델이다. 본 실시 예에서, 언어학습모델은 복수의 질 의문장들 및 복수의 질의문장들 각각의 유형에 대한 분류가 사전 학습된 모델일 수 있다. 예시적으로, 언어학습 모델은 BERT 모델(Bidirectional Encoder Representations from Transformers Model)일 수 있다. 언어학습모델은 입력부로부터 입력문장(ID)을 수신하고, 입력문장(ID)에 대응하는 유형을 특정하여 비교데이터(LD)를 생성한다. 즉, 비교데이터(LD)는 언어학습모델이 특정한 입력문장(ID)의 질의 유형에 해 당한다. 비교데이터(LD)는 구별수단에 전송된다. 구별수단은 생성수단으로부터 수신된 모방데이터(FD) 및 언어학습모델로부터 수신된 비교데이터 (LD)를 비교한다. 구별수단은 비교 결과값을 바탕으로 출력데이터(OD)를 생성한다. 도 6은 출력데이터의 형태가 예시적으로 도시된 도면이다. 도 6을 도 1과 함께 참조하면, 출력데이터(OD)는 출력부에 전송되어 출력부에 의하여 출력된다. 본 실시 예에 따르면, 출력데이터(OD)는 입력문장(ID)의 유형 후보들 각각에 대한 확률값(P1~Pk)의 집합일 수 있다. 본 실시 예에서, 상기 확률값(P1~Pk)의 개수는 50개 이상일 수 있다. 복수의 확률값들(P1~Pk) 중 최고값에 해당하는 일 유형 후보가 입력문장(ID)에 대한 최종 질의 유형으로 분류될 수 있다. 본 실시 예에서, 상기 최고값은 질의문장 분류 시스템의 설계자에 의하여 임의로 설정된 소정의 값 이상일 수 있다.본 실시 예에 따르면, 출력부는 최종 질의 유형의 분류 여부를 별도의 확률값 형태(Pk+1)로 표시할 수 있 다. 즉, 출력데이터(OD)는 입력문장(ID)의 유형 후보들에 대한 확률값(P1~Pk) 외에 최종 질의 유형의 분류 여부 를 나타내는 종단 확률값(Pk+1)을 더 포함할 수 있다. 만약, 복수의 확률값들(P1~Pk) 중 상기 소정의 값 이상인 값이 존재하지 않는 경우, 출력부는 최종 질의 유형이 분류되지 않음을 종단 확률값(Pk+1)으로 표시할 수 있다. 다시 도 1을 참조하면, 전술한 바와 같이, 본 실시 예에 따른 출력데이터(OD)는 출력부를 통해 출력됨과 동시에 생성수단으로 전송된다. 생성수단으로 전송되는 출력데이터(OD)는 참조데이터(CD)로 정의되며, 참조데이터(CD)는 추후 생성수단에 수신될 또 다른 입력문장(ID)에 대한 질의 유형 예측 시, 참 조될 수 있다. 이하, 참조데이터(CD)에 관하여 보다 상세히 후술된다. 본 실시 예에 따르면, 입력부에 입력되는 입력문장(ID)의 수는 n개 이상일 수 있다. 따라서, 문장분석수단 은 분석데이터(VD)를 제n 차례 이상 생성하고, 생성수단은 모방데이터(FD)를 제n 차례 이상 생성하고, 언어학습모델은 비교데이터(LD)를 제n 차례 이상 생성하고, 구별수단은 출력데이터(OD)를 제n 차례 이상 생성할 수 있다. n은 1 이상의 자연수이다. 구별수단으로부터 생성된 제n 차 출력데이터(OD_n, CD)는 출력부 및 생성수단에 전송된다. 출력 부에 전송된 제n 차 출력데이터(OD_n)은 출력부를 통해 출력되고, 생성수단에 전송된 제n 차 출 력데이터(CD)는 생성수단에 의하여 제n+1 차 분석데이터(VD_n+1) 및 외부 노이즈(ND_n+1)와 함께 변환 및 합성된 후, 제n+1 차 입력 문장(ID_n+1)에 대한 유형을 예측하여 제n+1 차 모방데이터(FD_n+1)를 생성할 수 있 다. 구별수단은 제n+1 차 모방데이터(FD_n+1) 및 제n+1 차 비교데이터(LD_n+1)와의 차이를 비교하여 제n+1 차 출력데이터를 생성할 수 있다. 도 2는 도 1에 도시된 분류 수단의 구성 일부가 도시된 블록도이고, 도 3은 도 2에 도시된 문장분석수단의 기능 이 간략하게 도시된 도면이다. 도 4는 파싱부에 의하여 생성된 파스트리의 일 예이다. 도 2는 분류수단의 구성 중 문장분석수단 및 생성수단의 구성만이 도시되었다. 도 2 내지 도 4를 참조하면, 문장분석수단은 토크나이저, 파싱부, 및 추출부를 포함한다. 토크나이저는 문장분석수단으로 수신된 입력문장(ID)을 토큰화한다. 본 실시 예에서, 토크나이저 는 입력문장(ID)을 복수의 단위단어(Sub-word)들로 구획할 수 있다. 예시적으로, 일 입력문장(ID)이 \"What is a micron?\"의 텍스트를 포함하는 경우, 토크나이저는 입력문장(ID)을'what', 'is', 'a', 'micron'과 같이 복수의 토큰들로 구획할 수 있다. 또한, 토크나이저는 각 토큰들의 품사를 식별하여 태그를 붙이는 작업인 '품사 태깅(Pos tagging)'을 수행할 수 있다. 토크나이저로부터 토큰화 및 품사 태깅이 완료된 데 이터는 제1 중간데이터(TD)라 정의된다. 도면에 도시되지 않았으나, 토크나이저는 입력문장(ID)을 토큰화하기 전에, 입력문장(ID) 각각이 포함하는 특수문자 또는 Stop word를 제거하는 역할을 수행할 수도 있다. 파싱부는 토크나이저로부터 제1 중간데이터(TD)를 수신하고, 수신된 제1 중간데이터(TD)를 분석하여 입력문장(ID)의 구조를 결정한다. 파싱부는 파서(Parser)를 포함할 수 있다. 파서(미도시)는 입력문장(I D)의 구조를 파스트리 형태로 생성하여 제2 중간데이터(PD)를 생성한다. 구체적으로, 파싱부는 단위단어들 간의 위계 관계를 분석하여, 각 단위단어들이 노드이고, 각 단위단어의 태그를 상기 위계 관계에 대응하도록 연 결하여 에지로 표현되는 파스트리 형태의 원시 그래프를 생성할 수 있다. 본 실시 예에서, 상기 그래프는 각 단 위단어 사이의 의존성을 나타낼 수 있다. 즉, 본 실시 예에서, 파서(Parser)는 단위단어들 사이의 의존 관계를 분석하는 의존성 파서(Dependency parser)일 수 있다. 본 발명이 파서의 종류에 특별히 한정되는 것은 아니다. 예시적으로, 본 발명의 다른 실시 예에서, 파싱부는 요소성 파서(Constituency parser)일 수도 있다. 도 5는 추출부가 모방데이터를 생성하는 과정이 도시된 도면이다. 도 5를 참조하면, 추출부는 파싱부로부터 생성된 제2 중간데이터(PD)를 수신하고, 제2 중간데이터 (PD)를 기초로 분석데이터(VD)를 생성한다. 본 실시 예에서, 추출부는 입력문장(ID)에 대한 문장 구조가 포함된 그래프를 생성하는 그래프 신경망 (GNN, Graph Neural Network)를 포함할 수 있다. 그래프 신경망은 파스트리 형태의 제2 중간데이터(PD)를 입력 받아, 파스트리를 이루는 노드들 각각의 주변 정보를 학습하고, 노드들 각각에 상기 주변 정보를 포함하는 특징 을 부여하여 벡터 형태의 분석데이터(VD)를 생성할 수 있다. 본 실시 예에서, 그래프 신경망(GNN)은 GraphSAGE일 수 있다. 본 발명은 그래프 신경망(GNN)의 종류에 특별히 한정되지는 않는다. 생성된 분석데이터(VD)는 생성 수단에 전송된다. 다시 도 1 및 도 2를 참조하면, 생성수단은 전처리부 및 제너레이터를 포함한다. 전처리부(22 1)는 분석데이터(VD), 구별수단으로부터 사전에 생성된 기출력데이터(CD) 및 외부 노이즈(ND)를 수신한다. 전처리부는 분석데이터(VD), 상기 기출력데이터(CD), 및 외부 노이즈(ND)를 동일 차원의 벡터 형태로 변환 한다. 또한, 전처리부는 변환된 벡터들을 합성하여 가공데이터(MD)를 생성할 수 있다. 생성된 가공데이터 (MD)는 제너레이터에 전송된다. 제너레이터는 가공데이터(MD)를 수신하고, 입력문장(ID)에 대한 유형을 예측하여 모방데이터(FD)를 생성한 다. 본 발명의 실시 예에 따르면, 상기 분류 수단은 GAN-BERT(Generative Adversarial Networks with Bidirectional Encoder Representations from Transformers) 모델을 포함할 수 있다. GAN 모델은 입력문장(I D)에 대한 질의 유형에 대한 가짜 정답 라벨을 포함하는 모방데이터(FD)를 생성하는 생성 수단과, 입력문 장(ID)에 대한 진짜 정답 라벨을 포함하는 비교데이터(LD)와 모방데이터(FD)의 차이를 구별하는 구별수단 이 상호 적대적으로 작용하는 모델을 의미한다. GAN-BERT 모델은 언어학습모델 중 하나인 BERT 모델로부터 출력 된 출력물을 GAN 딥러닝 모델의 정답 라벨로 사용하는 분류 모델을 의미한다. 분류수단이 GAN-BERT 모델을 포함하는 경우, BERT 모델만을 이용하여 입력문장(ID)에 대한 질의 유형을 분류하는 경우보다, 입력부에 입력 가능한 입력문장(ID)의 종류가 다양해질 수 있다. 또한, 본 발명의 실시 예에 따르면, 분류수단이 문장분석수단을 포함하므로, 생성수단이 입력문 장(ID)의 구조적 특성을 반영하여 모방데이터(FD)를 생성할 수 있다. 따라서, 분류수단이 포함하는 생성수 단 및 구별수단의 학습도가 향상될 수 있다. 즉, 분류수단의 분류 정확도가 향상될 수 있다. 도 7은 본 발명의 실시 예에 따른 질의문장 시스템의 분류정확도와 그 비교 예가 도시된 그래프이고, 도 8은 도 7에 도시된 그래프에 대응하는 epochs당 분류정확도 수치들이 기재된 표이다. 도 7의 그래프 A는 비교 예에 따 른 분류정확도 그래프이며, 그래프 B는 본 발명의 실시 예에 따른 분류정확도 그래프이다. 도 7 및 도 8을 참조하면, 본 발명의 실시 예에 따른 질의문장 분류 시스템은 복수 차례 반복 구동되며 학습될 수 있다. 예시적으로, 질의문장 분류 시스템이 제m 차례 반복 구동 되는 경우(m은 자연수, 단위: epoch), 입력부에는 동일한 입력문장(ID)이 제m 차례 반복 입력되고, 상기 출력부는 출력데이터(OD) 를 제m 차례 출력할 수 있다. 본 발명의 실시 예에 따르면, 질의문장 분류 시스템은 구동 횟수에 따라 상 이한 출력데이터들(OD)을 출력할 수 있다. 출력부로부터 출력되는 출력데이터(OD)는 제1 내지 제m 출력데 이터들을 포함한다. 그래프 A를 참조하면, m이 1 내지 3인 구간에서, 39.8% 이상 41.6% 이하의 분류 정확도를 갖는다. 즉, 비교 예 에 따른 질의문장 분류 시스템(미도시)은 제3 차례 이하로 반복 구동 될 경우, 최대 41.6&의 분류 정확도를 갖 는다. 또한, 그래프 A는 m이 8 내지 10인 구간에서, 53.6% 이상 54.4% 이하의 분류 정확도를 가지며, m이 8 이 상일 때, 안정적 포화곡선을 갖는다. 비교 예에 따른 질의문장 분류 시스템(미도시)은 제8 차례 이상 반복 구동 될 경우, 안정된 분류 정확도를 가지며, 그 최대값은 54.4%일 수 있다. 그래프 B를 참조하면, m이 1 일 경우, 62.2%의 분류 정확도를 갖는다. 본 실시 예에 따른 질의문장 분류 시스템은 반복 학습을 수행하지 않아도 높은 분류 정확도를 가질 수 있다. 그래프 B를 참조하면, 질의문장 분류 시스템의 분류 정확도는 반복 학 습 수행 여부에 무관하게 51% 이상일 수 있다. 또한, 그래프 B는 m이 4 내지 10인 구간에서, 58% 이상 60.4% 이 하의 분류 정확도를 가지며 m이 4 이상일 때, 안정적 포화곡선을 갖는다. 즉, 본 발명의 질의문장 분류 시스템 은 제4 차례 이상 반복 구동될 경우, 안정된 분류 정확도를 가지며, 그 최대값은 60.4%일 수 있다. 본 발 명의 실시 예에 따르면, 분류 정확도가 향상될 수 있으며, 상대적으로 적은 횟수의 반복 학습을 수행하더라도 안정적인 분류 정확도를 가질 수 있다. 도 9는 본 발명의 실시 예에 따른 질의문장 분류 방법의 과정이 도시된 순서도이다. 도 9를 참조하면, 본 발명의 실시 예에 따른 질의문장 분류 방법은 먼저, 입력부가 분장분석수단 및 언어학습모델 각각에 질의 형태를 갖는 적어도 하나의 입력문장(ID)을 입력한다(S1). 문장분석수단은 수신된 입력문장(ID)의 구조적 특징을 분석하여 분석데이터(VD)를 생성한다(S2). 분석데이 터(VD)는 생성수단에 전송된다.생성수단은 수신된 분석데이터(VD) 및 외부 노이즈(ND)를 입력받아 입력문장(ID)에 대한 유형을 예측하여 모방데이터(FD)를 생성한다(S3). 모방데이터(FD)는 구별수단으로 전송된다. 언어학습모델은 수신된 입력문장(ID)에 대응하는 유형을 특정하여 비교데이터(LD)를 생성한다(S4). 언어학 습모델은 복수의 질의문장들 각각의 유형에 대한 분류가 사전에 학습된 모델일 수 있다. 비교데이터(LD)는 구별수단에 전송된다. 상기 비교데이터(LD)를 생성하는 단계(S4)는 입력부가 언어학습모델에 입력문장(ID)을 입력하는 단계 (S1) 직후에 수행될 수 있다. 즉, 본 발명은 비교데이터(LD)를 생성하는 단계(S4)와 분석데이터(VD)를 생성하는 단계(S2) 및 모방데이터(FD)를 생성하는 단계(S3) 간 선후 관계를 특정하지 않는다. 구별수단은 수신된 모방데이터(FD)와 비교데이터(LD)를 비교하여 출력데이터(OD)를 생성한다(S5). 출력데 이터(OD)는 출력부를 통해 출력됨과 동시에 생성수단에 전송된다(S6). 본 발명의 실시 예에 따르면, 상기 단계들(S1~S6) 각각은 복수 차례 반복 수행될 수 있다. 상기 분석데이터(VD)를 생성하는 단계(S2)는, 토크나이저가 입력문장(ID)을 복수의 단위단어들로 토큰화하 여 제1 중간데이터(TD)를 생성하는 단계, 파싱부가 제1 중간데이터(TD)를 수신하여 단위단어들 사이의 위 계 관계를 분석하여 입력문장(ID)의 구조를 결정하는 단계, 파싱부가 입력문장(ID)의 구조를 파스 트리 형 태로 만들어 제2 중간데이터(PD)를 생성하는 단계, 및 추출부의 그래프 신경망이 상기 제2 중간데이터(P D)를 입력받아 벡터 형태의 분석데이터(VD)를 생성하는 단계를 포함한다. 상기 모방데이터(FD)를 생성하는 단계(S3)는, 생성수단의 전처리부가 분석데이터(VD), 구별수단(24 0)으로부터 사전에 생성된 기출력데이터(CD)를 입력받아 동일 차원의 벡터 형태로 변환 및 합성하여 가공데이터 (MD)를 생성하는 단계, 및 생성수단의 제너레이터가 가공데이터(MD)를 입력받고, 입력문장(ID)에 대 한 유형을 예측하여 모방데이터(FD)를 생성하는 단계를 포함한다. 이상 첨부된 도면을 참조하여 본 발명의 실시 예들을 더욱 상세하게 설명하였으나, 본 발명은 반드시 이러한 실 시 예로 국한되는 것은 아니고, 본 발명의 기술사상을 벗어나지 않는 범위 내에서 다양하게 변형 실시될 수 있 다. 따라서, 본 발명에 개시된 실시 예들은 본 발명의 기술 사상을 한정하기 위한 것이 아니라 설명하기 위한 것이 고, 이러한 실시 예에 의하여 본 발명의 기술 사상의 범위가 한정되는 것은 아니다. 그러므로, 이상에서 기술한 실시 예들은 모든 면에서 예시적인 것이며 한정적이 아닌 것으로 이해해야만 한다. 본 발명의 보호 범위는 아래 의 청구범위에 의하여 해석되어야 하며, 그와 동등한 범위 내에 있는 모든 기술 사상은 본 발명의 권리범위에 포함되는 것으로 해석되어야 할 것이다."}
{"patent_id": "10-2021-0193690", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 실시 예에 따른 질의문장 분류 시스템의 구성이 간략하게 도시된 블록도이다. 도 2는 도 1에 도시된 분류 수단의 구성 일부가 도시된 블록도이다. 도 3은 도 2에 도시된 문장분석수단의 기능이 간략하게 도시된 도면이다. 도 4는 파싱부에 의하여 생성된 파스트리의 일 예이다. 도 5는 추출부가 모방데이터를 생성하는 과정이 도시된 도면이다. 도 6은 출력데이터의 형태가 예시적으로 도시된 도면이다. 도 7은 본 발명의 실시 예에 따른 질의문장 시스템의 분류정확도와 그 비교 예가 도시된 그래프이다. 도 8은 도 7에 도시된 그래프에 대응하는 epochs당 분류정확도 수치들이 기재된 표이다. 도 9는 본 발명의 실시 예에 따른 질의문장 분류 방법의 과정이 도시된 순서도이다."}
