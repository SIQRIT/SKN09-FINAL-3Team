{"patent_id": "10-2024-7026840", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0134018", "출원번호": "10-2024-7026840", "발명의 명칭": "모델 구성 방법 및 장치", "출원인": "후아웨이 테크놀러지 컴퍼니 리미티드", "발명자": "주, 융허"}}
{"patent_id": "10-2024-7026840", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "모델 구성 방법으로서,제1 액세스 네트워크 디바이스로부터 제1 모델 요청 메시지를 수신하는 단계;상기 제1 모델 요청 메시지 및 제1 맵핑 관계에 기초하여 제1 모델을 결정하는 단계- 상기 제1 맵핑 관계는 모델, 모델 애플리케이션 시나리오, 및 모델 기능 사이의 맵핑 관계를 포함하거나, 또는 상기 제1 맵핑 관계는 모델, 모델 성능 레벨, 및 모델 기능 사이의 맵핑 관계를 포함함 -; 및상기 제1 모델에 관한 정보를 상기 제1 액세스 네트워크 디바이스에 전송하는 단계를 포함하는 방법."}
{"patent_id": "10-2024-7026840", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 제1 모델 요청 메시지는 상기 제1 모델의 모델 애플리케이션 시나리오 및 모델 기능을 표시하는 방법."}
{"patent_id": "10-2024-7026840", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서, 상기 제1 모델 요청 메시지는 상기 제1 모델의 모델 기능 및 모델 성능 레벨을 표시하거나, 또는 상기 제1 모델의 모델 기능 및 모델 성능 지표를 표시하는 방법."}
{"patent_id": "10-2024-7026840", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항 내지 제3항 중 어느 한 항에 있어서, 상기 제1 모델에 관한 정보는 상기 제1 모델의 다음:모델 인덱스, 모델 구조 정보, 모델 파라미터, 모델 입력 포맷, 모델 출력 포맷, 모델 성능 지표, 모델 애플리케이션 시나리오, 모델 기능, 또는 트레이닝 파라미터 중 적어도 하나를 표시하는 방법."}
{"patent_id": "10-2024-7026840", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항 내지 제4항 중 어느 한 항에 있어서, 추가로,상기 제1 액세스 네트워크 디바이스로부터 제1 피드백 정보를 수신하는 단계; 및상기 제1 피드백 정보에 기초하여 상기 제1 모델을 업데이트하는 단계를 포함하는 방법."}
{"patent_id": "10-2024-7026840", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5항에 있어서, 상기 제1 피드백 정보는 상기 제1 모델에 의해 출력되는 예측 정보의 실제 정확도를 표시하고,상기 피드백 정보에 기초하여 상기 제1 모델을 업데이트하는 단계는,상기 제1 모델에 의해 출력되는 상기 예측 정보의 실제 정확도가 임계값 미만일 때, 상기 제1 모델을 다시 트레이닝시키는 단계, 및 상기 제1 모델을 업데이트하는 단계를 포함하는 방법."}
{"patent_id": "10-2024-7026840", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제5항에 있어서, 상기 제1 피드백 정보는 시나리오 변경 표시, 모델 성능 레벨 변경 표시, 또는 모델 성능 지표변경 표시를 표시하고, 상기 제1 피드백 정보에 기초하여 제1 모델을 업데이트하는 단계는,상기 시나리오 변경 표시, 상기 모델 성능 레벨 변경 표시, 또는 상기 모델 성능 지표 변경 표시에 기초하여 단말 디바이스에 대한 제2 모델을 선택하는 단계; 및상기 제2 모델에 관한 정보를 상기 제1 액세스 네트워크 디바이스에 전송하는 단계- 상기 제2 모델은 상기 제1모델을 업데이트하기 위한 것임 -를 포함하는 방법.공개특허 10-2024-0134018-3-청구항 8 제1항 내지 제7항 중 어느 한 항에 있어서, 추가로,제2 액세스 네트워크 디바이스로부터 제2 모델 요청 메시지를 수신하는 단계- 상기 제2 모델 요청 메시지는 상기 제1 모델의 인덱스를 표시함 -;상기 제1 모델의 인덱스에 기초하여 상기 제1 모델을 결정하는 단계; 및상기 제1 모델에 관한 정보를 상기 제2 액세스 네트워크 디바이스에 전송하는 단계를 포함하는 방법."}
{"patent_id": "10-2024-7026840", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "모델 구성 방법으로서,제1 모델 요청 메시지를 OAM(operations, administration and maintenance)에 전송하는 단계- 상기 제1 모델요청 메시지는 제1 모델의 모델 애플리케이션 시나리오 및 모델 기능을 표시하거나, 또는 상기 제1 모델 요청메시지는 제1 모델의 모델 기능 및 모델 성능 레벨을 표시하거나, 또는 제1 모델의 모델 기능 및 모델 성능 지표를 표시함 -; 및상기 OAM으로부터 상기 제1 모델에 관한 정보를 수신하는 단계를 포함하는 방법."}
{"patent_id": "10-2024-7026840", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9항에 있어서, 제1 모델 요청 메시지를 OAM에 전송하기 전에, 상기 방법은 추가로,인공 지능 AI-기반 강화된 서비스가 제공될 필요가 있는지를 결정하는 단계를 포함하는 방법."}
{"patent_id": "10-2024-7026840", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제9항 또는 제10항에 있어서, 상기 제1 모델에 관한 정보는 상기 제1 모델의 다음:모델 인덱스, 모델 구조 정보, 모델 파라미터, 모델 입력 포맷, 모델 출력 포맷, 모델 성능 지표, 모델 애플리케이션 시나리오, 모델 기능, 또는 트레이닝 파라미터 중 적어도 하나를 표시하는 방법."}
{"patent_id": "10-2024-7026840", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제9항 내지 제11항 중 어느 한 항에 있어서, 추가로,예측 정보를 획득하기 위해 상기 제1 모델에 기초하여 모델 추론을 수행하는 단계를 포함하는 방법."}
{"patent_id": "10-2024-7026840", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제12항에 있어서, 추가로,상기 예측 정보를 단말 디바이스에 전송하는 단계- 상기 예측 정보는 예측 결과를 포함함 -를 포함하는 방법."}
{"patent_id": "10-2024-7026840", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제12항 또는 제13항에 있어서, 상기 예측 정보는 상기 예측 결과를 예측하는 정확도를 추가로 포함하는 방법."}
{"patent_id": "10-2024-7026840", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제13항 또는 제14항에 있어서, 추가로,상기 단말 디바이스로부터 제2 피드백 정보를 수신하는 단계- 상기 제2 피드백 정보는 상기 예측 정보의 실제정확도를 표시함 -를 포함하는 방법."}
{"patent_id": "10-2024-7026840", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제9항 내지 제15항 중 어느 한 항에 있어서, 추가로,상기 제1 피드백 정보를 상기 OAM에 전송하는 단계- 상기 제1 피드백 정보는 예측 정보의 실제 정확도, 애플리케이션 시나리오 변경 표시, 모델 성능 레벨 변경 표시, 또는 모델 성능 지표 변경 표시를 표시함 -를 포함하는공개특허 10-2024-0134018-4-방법."}
{"patent_id": "10-2024-7026840", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제9항 내지 제16항 중 어느 한 항에 있어서, 추가로,단말 디바이스의 타겟 셀을 결정하는 단계; 및상기 제1 모델의 인덱스를 상기 타겟 셀에 대응하는 제2 액세스 네트워크 디바이스에 전송하는 단계를 포함하는방법."}
{"patent_id": "10-2024-7026840", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제17항에 있어서, 추가로,상기 타겟 셀에 대응하는 상기 제2 액세스 네트워크 디바이스에 제1 표시 정보를 전송하는 단계- 상기 제1 표시정보는 상기 제1 모델의 입력 데이터의 타입 정보를 표시함 -를 포함하는 방법."}
{"patent_id": "10-2024-7026840", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제17항 또는 제18항에 있어서, 추가로,상기 모델 추론에 필요한 과거 데이터 정보를, 상기 제2 액세스 네트워크 디바이스에, 전송하는 단계를 포함하는 방법."}
{"patent_id": "10-2024-7026840", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제17항 내지 제19항 중 어느 한 항에 있어서, 추가로,상기 제2 액세스 네트워크 디바이스로부터 제2 표시 정보를 수신하는 단계- 상기 제2 표시 정보는 다음: 상기단말이 상기 타겟 셀로 핸드오버된다는 점을 표시함, 또는 상기 제1 모델을 삭제하라고 제1 액세스 네트워크 디바이스에게 표시함, 또는 대응하는 컴퓨팅 리소스를 해제하라고 제1 액세스 네트워크 디바이스에게 표시함 중적어도 하나를 표시함 -; 및상기 대응하는 컴퓨팅 리소스를 해제하기 위해 상기 제1 모델을 삭제하는 단계를 포함하는 방법."}
{"patent_id": "10-2024-7026840", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_21", "content": "모델 구성 방법으로서,제1 액세스 네트워크 디바이스로부터 제1 모델의 인덱스를 수신하는 단계;제2 모델 요청 메시지를 OAM(operations, administration and maintenance)에 전송하는 단계- 상기 제2 모델요청 메시지는 상기 제1 모델의 인덱스를 표시함 -; 및상기 OAM으로부터 상기 제1 모델에 관한 정보를 수신하는 단계를 포함하는 방법."}
{"patent_id": "10-2024-7026840", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_22", "content": "제21항에 있어서, 상기 제1 모델에 관한 정보는 상기 제1 모델의 다음:모델 인덱스, 모델 구조 정보, 모델 파라미터, 모델 입력 포맷, 모델 출력 포맷, 모델 성능 지표, 모델 애플리케이션 시나리오, 모델 기능, 또는 트레이닝 파라미터 중 적어도 하나를 표시하는 방법."}
{"patent_id": "10-2024-7026840", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_23", "content": "제21항 또는 제22항에 있어서, 추가로,상기 제1 액세스 네트워크 디바이스로부터 제1 표시 정보를 수신하는 단계- 상기 제1 표시 정보는 상기 제1 모델의 입력 데이터의 타입 정보를 표시함 -를 포함하는 방법."}
{"patent_id": "10-2024-7026840", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_24", "content": "제21항 내지 제23항 중 어느 한 항에 있어서, 추가로,공개특허 10-2024-0134018-5-상기 제1 액세스 네트워크 디바이스로부터 모델 추론에 필요한 과거 데이터 정보를 수신하는 단계를 포함하고;상기 모델 추론에서, 상기 과거 데이터 정보는 상기 제1 모델의 입력 데이터를 결정하기 위한 것인 방법."}
{"patent_id": "10-2024-7026840", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_25", "content": "제21항 내지 제24항 중 어느 한 항에 있어서, 추가로,상기 제1 액세스 네트워크 디바이스에 제2 표시 정보를 전송하는 단계- 상기 제2 표시 정보는 다음: 단말이 타겟 셀로 핸드오버된다는 점을 표시함, 또는 상기 제1 모델을 삭제하라고 상기 제1 액세스 네트워크 디바이스에게 표시함, 또는 대응하는 컴퓨팅 리소스를 해제하라고 상기 제1 액세스 네트워크 디바이스에게 표시함 중 적어도 하나를 표시함 -를 포함하는 방법."}
{"patent_id": "10-2024-7026840", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_26", "content": "통신 장치로서, 제1항 내지 제8항 중 어느 한 항에 따른 방법을 구현하도록 구성되는 유닛을 포함하는 통신 장치."}
{"patent_id": "10-2024-7026840", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_27", "content": "통신 장치로서, 프로세서 및 메모리를 포함하고, 상기 프로세서는 상기 메모리에 연결되고, 상기 프로세서는 제1항 내지 제8항 중 어느 한 항에 따른 방법을 구현하도록 구성되는 통신 장치."}
{"patent_id": "10-2024-7026840", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_28", "content": "통신 장치로서, 제9항 내지 제20항 중 어느 한 항에 따른 방법을 구현하도록 구성되는 유닛을 포함하는 통신 장치."}
{"patent_id": "10-2024-7026840", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_29", "content": "통신 장치로서, 프로세서 및 메모리를 포함하고, 상기 프로세서는 상기 메모리에 연결되고, 상기 프로세서는 제9항 내지 제20항 중 어느 한 항에 따른 방법을 구현하도록 구성되는 통신 장치."}
{"patent_id": "10-2024-7026840", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_30", "content": "통신 장치로서, 제21항 내지 제25항 중 어느 한 항에 따른 방법을 구현하도록 구성되는 유닛을 포함하는 통신장치."}
{"patent_id": "10-2024-7026840", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_31", "content": "통신 장치로서, 프로세서 및 메모리를 포함하고, 상기 프로세서는 상기 메모리에 연결되고, 상기 프로세서는 제21항 내지 제25항 중 어느 한 항에 따른 방법을 구현하도록 구성되는 통신 장치."}
{"patent_id": "10-2024-7026840", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_32", "content": "통신 시스템으로서, 제26항 또는 제27항에 따른 통신 장치, 제28항 또는 제29항에 따른 통신 장치, 및 제30항또는 제31항에 따른 통신 장치를 포함하는 통신 시스템."}
{"patent_id": "10-2024-7026840", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_33", "content": "컴퓨터-판독가능 저장 매체로서, 상기 컴퓨터-판독가능 저장 매체는 명령어들을 저장하고; 상기 명령어들이 컴퓨터 상에서 실행될 때, 상기 컴퓨터는 제1항 내지 제8항 중 어느 한 항에 따른 방법, 또는 제9항 내지 제20항중 어느 한 항에 따른 방법, 또는 제21항 내지 제25항 중 어느 한 항에 따른 방법을 수행하는 것이 가능하게 되는 컴퓨터-판독가능 저장 매체."}
{"patent_id": "10-2024-7026840", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_34", "content": "컴퓨터 프로그램 제품으로서, 명령어들을 포함하고, 상기 명령어들이 컴퓨터 상에서 실행될 때, 상기 컴퓨터는제1항 내지 제8항 중 어느 한 항에 따른 방법, 또는 제9항 내지 제20항 중 어느 한 항에 따른 방법, 또는 제21항 내지 제25항 중 어느 한 항에 따른 방법을 수행하는 것이 가능하게 되는 컴퓨터 프로그램 제품.공개특허 10-2024-0134018-6-"}
{"patent_id": "10-2024-7026840", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "모델 구성 방법 및 장치가 제공된다. 이러한 방법은, OAM(operations, administration and maintenance)이 제1 액세스 네트워크 디바이스로부터 제1 모델 요청 메시지를 수신하는 것을 포함한다. OAM은 제1 모델 요청 메시지 및 제1 맵핑 관계에 기초하여 제1 모델을 결정하며, 제1 맵핑 관계는 모델, 모델 애플리케이션 시나리오, 및 모 델 기능 사이의 맵핑 관계를 포함하거나, 또는 제1 맵핑 관계는 모델, 모델 성능 레벨, 및 모델 기능 사이의 맵 핑 관계를 포함한다. OAM은 제1 모델에 관한 정보를 제1 액세스 네트워크 디바이스에 전송한다. 본 출원에서의 방법 및 장치에 따르면, 모델 추론의 성능 및 속도를 개선하기 위해, 애플리케이션 시나리오 또는 성능 지표에 매칭되는 제1 모델이 제1 액세스 네트워크 디바이스에 대해 구성될 수 있다."}
{"patent_id": "10-2024-7026840", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "<관련 출원에 대한 상호-참조> 본 출원은 2022년 1월 26일자로 중국 특허청에 출원되고 발명의 명칭이 \"MODEL CONFIGURATION METHOD AND APPARATUS\"인 중국 특허 출원 제202210096175.1호에 대한 우선권을 주장하며, 이는 그 전체가 본 명세서에 참조 로 원용된다. <기술 분야> 본 출원은 통신 기술들의 분야에, 특히, 모델 구성 방법 및 장치에 관련된다."}
{"patent_id": "10-2024-7026840", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "무선 통신 네트워크에서, 예를 들어, 이동 통신 네트워크에서, 네트워크에 의해 지원되는 서비스들은 점점 더 다양화되고, 따라서 충족될 필요가 있는 요건들은 점점 더 다양화된다. 예를 들어, 네트워크는 초고속, 초저 레이턴시, 및/또는 초대형 접속을 지원하는 것이 가능할 필요가 있다. 이러한 특징은 네트워크 계획, 네트워크 구성, 및/또는 리소스 스케줄링을 점점 더 복잡하게 만든다. 이러한 새로운 요건들, 시나리오들, 및 특징들은 네트워크 계획, 동작들 및 유지보수, 및 효율적인 동작에 전례없는 도전과제들을 가져온다. 이러한 도전과제들 을 충족시키기 위해, 인공 지능 기술이 무선 통신 네트워크에 도입되어, 네트워크 지능을 구현할 수 있다. 이 러한 것에 기초하여, 네트워크에서 액세스 네트워크 디바이스에 대한 인공 지능 모델을 어떻게 구성할지는 연구 할 가치가 있는 문제이다. 본 출원은, 제1 액세스 네트워크 디바이스에 대해, 애플리케이션 시나리오 또는 성능 레벨에 매칭되는 제1 모델 을 구성하고, 모델 예측의 성능 및 속도를 개선하기 위한, 모델 구성 방법 및 장치를 제공한다. 제1 양태에 따르면, 모델 구성 방법이 제공된다. 이러한 방법은 OAM(operations, administration and maintenance)에 의해 수행되거나, 또는 OAM에서 구성되는 컴포넌트(프로세서, 칩 등)일 수 있거나, 또는 소프트 웨어 모듈 등일 수 있다. 이러한 방법은, 제1 액세스 네트워크 디바이스로부터 제1 모델 요청 메시지를 수신하는 단계; 제1 모델 요청 메시지 및 제1 맵 핑 관계에 기초하여 제1 모델을 결정하는 단계- 제1 맵핑 관계는 모델, 모델 애플리케이션 시나리오, 및 모델 기능 사이의 맵핑 관계를 포함하거나, 또는 제1 맵핑 관계는 모델, 모델 성능 레벨, 및 모델 기능 사이의 맵핑 관계를 포함함 -; 및 제1 모델에 관한 정보를 제1 액세스 네트워크 디바이스에 전송하는 단계를 포함한다. 선 택적으로, 모델, 모델 성능 레벨, 및 모델 기능 사이의 맵핑 관계는 모델, 모델 성능 지표, 및 모델 기능 사이 의 맵핑 관계로 대체될 수 있다. 전술한 방법에 따르면, 동일한 기능을 구현하는 모델들의 성능 지표들에 대한 요건들은 상이한 애플리케이션 시 나리오들에서 상이하다. 본 출원에서, OAM은 제1 맵핑 관계를 저장하며, 제1 맵핑 관계는 모델, 모델 애플리케 이션 시나리오, 및 모델 기능 사이의 맵핑 관계이다. 맵핑 관계에 기초하여, 동일한 모델 기능에 대해, 상이한 애플리케이션 시나리오들에서, 시나리오에 대응하는 모델이 할당될 수 있어서, 모델은 모델에 대응하는 시나리 오에서 성능 지표에 대한 요건을 충족시킨다. 동일한 모델이 임의의 시나리오에서 모델 추론을 위한 것인 경우 와 비교하여, 본 출원의 해결책들은 예측 성능, 예측 속도 등을 개선할 수 있다. 대안적으로, 본 출원에서, OAM은 제1 맵핑 관계를 수립하며, 제1 맵핑 관계는 모델, 모델 성능 레벨(또는 모델 성능 지표), 및 모델 기능 사이의 맵핑 관계이다. 모델들의 모델 성능 지표들에 대한 요건들이 상이한 애플리케이션 시나리오들에서 상이 하고, 모델 성능 지표와 성능 레벨 사이의 대응관계가 있기 때문에, OAM은 제1 맵핑 관계에 기초하여 상이한 애 플리케이션 시나리오들에서 상이한 모델 성능 지표들에 대해 상이한 모델들을 구성할 수 있다. 동일한 모델이 임의의 시나리오에서 모델 성능 지표 하에서의 모델 추론을 위한 것인 경우와 비교하여, 본 출원의 해결책들은 예측 성능, 예측 속도 등을 개선할 수 있다. 가능한 설계에서, 제1 모델 요청 메시지는 제1 모델의 모델 애플리케이션 시나리오 및 모델 기능을 표시한다. 가능한 설계에서, 제1 모델 요청 메시지는 제1 모델의 모델 기능 및 모델 성능 레벨을 표시하거나, 또는 제1 모 델의 모델 기능 및 모델 성능 지표를 표시한다. 가능한 설계에서, 제1 모델에 관한 정보는 제1 모델의 다음: 모델 인덱스, 모델 구조 정보, 모델 파라미터, 모델 입력 포맷, 모델 출력 포맷, 모델 성능 지표, 모델 애플리 케이션 시나리오, 모델 기능, 또는 트레이닝 파라미터 중 적어도 하나를 표시한다. 전술한 방법에 따르면, OAM은 제1 모델에 관한 정보를 제1 액세스 네트워크 디바이스에 전송한다. 제1 액세스 네트워크 디바이스는 제1 모델에 관한 정보에 기초하여 제1 모델을 결정하거나 또는 복원할 수 있다. 선택적으 로, 제1 모델에 관한 정보는 트레이닝 파라미터를 포함할 수 있고, 제1 액세스 네트워크 디바이스는, 모델에 대 한 다양한 요건을 충족시키기 위해, 트레이닝 파라미터에 기초하여 제1 모델을 후속하여 계속 트레이닝시킬 수 있다. 가능한 설계에서, 이러한 방법은 추가로, 제1 액세스 네트워크 디바이스로부터 제1 피드백 정보를 수신하는 단 계; 및 제1 피드백 정보에 기초하여 제1 모델을 업데이트하는 단계를 포함한다. 가능한 설계에서, 제1 피드백 정보는 제1 모델에 의해 출력되는 예측 정보의 실제 정확도를 표시하고, 피드백 정보에 기초하여 제1 모델을 업데이트하는 단계는, 제1 모델에 의해 출력되는 예측 정보의 실제 정확도가 임계 값 미만일 때, 제1 모델을 다시 트레이닝시키는 단계, 및 제1 모델을 업데이트하는 단계를 포함한다. 전술한 방법에 따르면, 제1 모델을 결정할 때, 제1 액세스 네트워크 디바이스는 제1 모델에 기초하여 모델 추론 을 수행할 수 있고, 추론 결과는 예측 정보라고 지칭될 수 있다. 제1 피드백 정보는 예측 정보에 기초하여 결 정되며, 제1 피드백 정보는 제1 모델에 의해 출력되는 예측 정보의 실제 정확도를 포함하고, 제1 피드백 정보는 OAM에 피드백된다. OAM은, 제1 모델의 추론 결과의 정확도를 개선하기 위해, 제1 피드백 정보에 기초하여 제1 모델을 업데이트한다. 가능한 설계에서, 제1 피드백 정보는 시나리오 변경 표시, 모델 성능 레벨 변경 표시, 또는 모델 성능 지표 변 경 표시를 표시한다. 제1 모델이 제1 피드백 정보에 기초하여 업데이트되는 것은, 시나리오 변경 표시, 모델 성능 레벨 변경 표시, 또는 모델 성능 지표 변경 표시에 기초하여 단말 디바이스에 대한 제2 모델을 선택하는 것; 및 제2 모델에 관한 정보를 제1 액세스 네트워크 디바이스에 전송하는 것- 제2 모델은 제1 모델을 업데이트 하기 위한 것임 -을 포함한다. 전술한 방법과 유사하게, 이러한 설계에서, 애플리케이션 시나리오, 모델 성능 레벨, 또는 모델 성능 지표가 변 경될 때, 제1 액세스 네트워크 디바이스는 애플리케이션 시나리오 변경, 모델 성능 레벨 변경, 또는 모델 성능 지표 변경을 표시하는 표시 정보를, OAM에 전송하고, OAM은 모델 추론을 위한 변경된 애플리케이션 시나리오, 모델 성능 레벨, 또는 모델 성능 지표에 기초하여 모델을 제1 액세스 네트워크 디바이스에 다시 할당하고, 제1 액세스 네트워크 디바이스에 할당되는 모델이 애플리케이션 시나리오, 모델 성능 레벨, 모델 성능 지표에 대한 요건을 충족시키는 것이 가능한 한 많이 보장될 수 있다는 점이 차이이다. 가능한 설계에서, 이러한 방법은 추가로, 제2 액세스 네트워크 디바이스로부터 제2 모델 요청 메시지를 수신하 는 단계- 제2 모델 요청 메시지는 제1 모델의 인덱스를 표시함 -; 제1 모델의 인덱스에 기초하여 제1 모델을 결 정하는 단계; 및 제1 모델에 관한 정보를 제2 액세스 네트워크 디바이스에 전송하는 단계를 포함한다. 제2 양태에 따르면, 모델 구성 방법이 제공된다. 제1 양태에 대응하는 제1 액세스 네트워크 디바이스 측에 대 한 이러한 방법의 유익한 효과들에 대해서는, 제1 양태를 참조한다. 이러한 방법은 제1 액세스 네트워크 디바 이스에 의해 수행되거나, 또는 제1 액세스 네트워크 디바이스에서 구성되는 컴포넌트(프로세서, 칩 등)일 수 있 거나, 또는 소프트웨어 모듈 등일 수 있다. 이러한 방법은, 제1 모델 요청 메시지를 OAM(operations, administration and maintenance)에 전송하는 단계- 제1 모델 요청 메시지는 제1 모델의 모델 애플리케이션 시나리오 및 모델 기능을 표시하거나, 또는 제1 모델 요청 메시지는 제 1 모델의 모델 기능 및 모델 성능 레벨을 표시하거나, 또는 제1 모델의 모델 기능 및 모델 성능 지표를 표시함 -; 및 OAM으로부터 제1 모델에 관한 정보를 수신하는 단계를 포함한다. 가능한 설계에서, 제1 모델 요청 메시지를 OAM에 전송하기 전에, 이러한 방법은 추가로, 인공 지능 AI-기반 강 화된 서비스가 제공될 필요가 있는지를 결정하는 단계를 포함한다. 가능한 설계에서, 제1 모델에 관한 정보는 제1 모델의 다음: 모델 인덱스, 모델 구조 정보, 모델 파라미터, 모델 입력 포맷, 모델 출력 포맷, 모델 성능 지표, 모델 애플리 케이션 시나리오, 모델 기능, 또는 트레이닝 파라미터 중 적어도 하나를 표시한다. 가능한 설계에서, 이러한 방법은 추가로, 예측 정보를 획득하기 위해 제1 모델에 기초하여 모델 추론을 수행하 는 단계를 포함한다. 가능한 설계에서, 이러한 방법은 추가로, 예측 정보를 단말 디바이스에 전송하는 단계- 예측 정보는 예측 결과 를 포함함 -를 포함한다. 가능한 설계에서, 예측 정보는 예측 결과를 예측하는 정확도를 추가로 포함한다. 가능한 설계에서, 이러한 방법은 추가로, 단말 디바이스로부터 제2 피드백 정보를 수신하는 단계- 제2 피드백 정보는 예측 정보의 실제 정확도를 표시함 -를 포함한다. 가능한 설계에서, 이러한 방법은 추가로, 제1 피드백 정보를 OAM에 전송하는 단계- 제1 피드백 정보는 예측 정 보의 실제 정확도, 애플리케이션 시나리오 변경 표시, 모델 성능 레벨 변경 표시, 또는 모델 성능 지표 변경 표 시를 표시함 -를 포함한다. 본 출원에서, 제1 모델은 단말 디바이스에 대해 인공 지능 AI 또는 머신 학습 ML 추론 서비스를 제공하거나, 또 는 제1 액세스 네트워크 디바이스에 대해 AI 또는 ML 추론 서비스를 제공할 수 있다는 점이 주목되어야 한다. 제1 모델이 단말 디바이스에 대해 AI 또는 ML 추론 서비스를 제공하도록 구성될 때, 이러한 방법은 다음을 추가 로 포함한다: 제1 RAN 노드가 제1 모델의 추론 정보(또는 예측 정보라고 지칭됨)를 단말 디바이스에 전송한다. 단말 디바이스는 추론 정보에 기초하여 제2 피드백 정보를 제1 액세스 네트워크 디바이스에 전송하며, 제2 피드 백 정보는 추론 정보의 실제 정확도를 표시할 수 있고, 제1 액세스 네트워크 디바이스는 제2 피드백 정보를 OAM 에 직접 전달할 수 있다. 대안적으로, 제1 액세스 네트워크 디바이스는 제2 피드백 정보에 기초하여 추론 정보 의 실제 정확도를 획득하고,추론 정보의 실제 정확도를 표시하는 제1 피드백 정보 등을, OAM에, 전송한다. OAM 은, 제1 모델의 추론 성능, 추론 속도 등을 개선하기 위해, 추론 정보의 실제 정확도에 기초하여 제1 모델을 업 데이트할 수 있다. 가능한 설계에서, 이러한 방법은 추가로, 단말 디바이스의 타겟 셀을 결정하는 단계; 및 제1 모델의 인덱스를 타겟 셀에 대응하는 제2 액세스 네트워크 디바이스에 전송하는 단계를 포함한다. 가능한 설계에서, 이러한 방법은 추가로, 타겟 셀에 대응하는 제2 액세스 네트워크 디바이스에 제1 표시 정보를 전송하는 단계- 제1 표시 정보는 제1 모델의 입력 데이터의 타입 정보를 표시함 -를 포함한다. 가능한 설계에서, 이러한 방법은 추가로, 모델 추론에 필요한 과거 데이터 정보를, 제2 액세스 네트워크 디바이 스에, 전송하는 단계를 포함한다. 가능한 설계에서, 이러한 방법은 추가로, 제2 액세스 네트워크 디바이스로부터 제2 표시 정보를 수신하는 단계- 제2 표시 정보는 다음: 단말이 타겟 셀로 핸드오버된다는 점을 표시함, 또는 제1 모델을 삭제하라고 제1 액세스 네트워크 디바이스에게 표시함, 또는 대응하는 컴퓨팅 리소스를 해제하라고 제1 액세스 네트워크 디바이스에게 표시함 중 적어도 하나를 표시함 -; 및 대응하는 컴퓨팅 리소스를 해제하기 위해 제1 모델을 삭제하는 단계를 포함한다. 제3 양태에 따르면, 모델 구성 방법이 제공된다. 제1 양태에 대응하는 제1 액세스 네트워크 디바이스 측에 대 한 이러한 방법의 유익한 효과들에 대해서는, 제1 양태를 참조한다. 이러한 방법은 제2 액세스 네트워크 디바 이스에 의해 수행되거나, 또는 제2 액세스 네트워크 디바이스에서 구성되는 컴포넌트(프로세서, 칩 등)일 수 있 거나, 또는 소프트웨어 모듈 등일 수 있다. 이러한 방법은, 제1 액세스 네트워크 디바이스로부터 제1 모델의 인덱스를 수신하는 단계; 제2 모델 요청 메시지를 OAM(operations, maintenance, and administration)에 전송하는 단계- 제2 모델 요청 메시지는 제1 모델의 인 덱스를 표시함 -; 및 OAM으로부터 제1 모델에 관한 정보를 수신하는 단계를 포함한다. 가능한 설계에서, 제1 모델에 관한 정보는 제1 모델의 다음: 모델 인덱스, 모델 구조 정보, 모델 파라미터, 모 델 입력 포맷, 모델 출력 포맷, 모델 성능 지표, 모델 애플리케이션 시나리오, 모델 기능, 또는 트레이닝 파라 미터 중 적어도 하나를 표시한다. 가능한 설계에서, 이러한 방법은 추가로, 제1 액세스 네트워크 디바이스로부터 제1 표시 정보를 수신하는 단계- 제1 표시 정보는 제1 모델의 입력 데이터의 타입 정보를 표시함 -를 포함한다.가능한 설계에서, 이러한 방법은 추가로, 제1 액세스 네트워크 디바이스로부터 모델 추론에 필요한 과거 데이터 정보를 수신하는 단계를 포함하고, 모델 추론에서, 과거 데이터 정보는 제1 모델의 입력 데이터를 결정하기 위 한 것이다. 가능한 설계에서, 이러한 방법은 추가로, 제1 액세스 네트워크 디바이스에 제2 표시 정보를 전송하는 단계- 제2 표시 정보는 다음: 단말이 타겟 셀로 핸드오버된다는 점을 표시함, 또는 제1 모델을 삭제하라고 제1 액세스 네 트워크 디바이스에게 표시함, 또는 대응하는 컴퓨팅 리소스를 해제하라고 제1 액세스 네트워크 디바이스에게 표 시함 중 적어도 하나를 표시함 -를 포함한다. 제4 양태에 따르면, 장치가 제공된다. 유익한 효과들에 대해서는, 제1 양태의 설명들을 참조한다. 이러한 장 치는 OAM(operations, administration and maintenance), 또는 OAM에서 구성되는 장치, 또는 OAM과 매칭함에 있어서 사용될 수 있는 장치일 수 있다. 설계에서, 이러한 장치는 제1 양태에서 설명되는 방법들/동작들/단계들/액션들과 일-대-일 대응관계에 있는 유 닛들을 포함할 수 있다. 이러한 유닛들은 하드웨어 회로, 소프트웨어, 또는 하드웨어 회로와 소프트웨어의 조 합을 사용하여 구현될 수 있다. 예를 들어, 이러한 장치는 처리 유닛 및 통신 유닛을 포함할 수 있고, 이러한 처리 유닛 및 통신 유닛은 제1 양 태의 임의의 설계 예에서의 대응하는 기능들을 수행할 수 있다. 통신 유닛은 제1 액세스 네트워크 디바이스로부터 제1 모델 요청 메시지를 수신하도록 구성된다. 처리 유닛은 제1 모델 요청 메시지 및 제1 맵핑 관계에 기초하여 제1 모델을 결정하도록 구성되며, 제1 맵핑 관계는 모델, 모델 애플리케이션 시나리오, 및 모델 기능 사이의 맵핑 관계를 포함하거나, 또는 제1 맵핑 관계는 모델, 모델 성능 레벨, 및 모델 기능 사이의 맵핑 관계를 포함한다. 통신 유닛은 제1 모델에 관한 정보를 제1 액세스 네트 워크 디바이스에 전송하도록 추가로 구성된다. 처리 유닛 및 통신 유닛의 구체적인 실행 프로세스들에 대해서 는, 제1 양태를 참조한다. 상세사항들이 본 명세서에서 다시 설명되지는 않는다. 예를 들어, 이러한 장치는 제1 양태에서 설명되는 방법을 구현하도록 구성되는 메모리를 포함한다. 이러한 장 치는 명령어들 및/또는 데이터를 저장하도록 구성되는 메모리를 추가로 포함할 수 있다. 이러한 메모리는 프로 세서에 연결된다. 메모리에 저장된 프로그램 명령어들을 실행할 때, 프로세서는 제1 양태에서 설명되는 방법을 구현할 수 있다. 이러한 장치는 통신 인터페이스를 추가로 포함할 수 있고, 이러한 통신 인터페이스는 다른 디 바이스와 통신하기 위해 장치에 의해 사용된다. 예를 들어, 이러한 통신 인터페이스는 송수신기, 회로, 버스, 모듈, 핀, 또는 다른 타입의 통신 인터페이스일 수 있고, 다른 디바이스는 네트워크 디바이스 등일 수 있다. 가능한 설계에서, 이러한 장치는, 프로그램 명령어들을 저장하도록 구성되는 메모리; 제1 액세스 네트워크 디바이스로부터 제1 모델 요청 메시지를 수신하도록 구성되는 통신 인터페이스; 및 제1 모델 요청 메시지 및 제1 맵핑 관계에 기초하여 제1 모델을 결정하도록 구성되는 프로세서- 제1 맵핑 관계 는 모델, 모델 애플리케이션 시나리오, 및 모델 기능 사이의 맵핑 관계를 포함하거나, 또는 제1 맵핑 관계는 모 델, 모델 성능 레벨, 및 모델 기능 사이의 맵핑 관계를 포함함 -를 포함하고; 통신 인터페이스는 제1 모델에 관한 정보를 제1 액세스 네트워크 디바이스에 전송하도록 추가로 구성된다. 통신 인터페이스 및 프로세서의 구체적인 실행 프로세스들에 대해서는, 제1 양태의 설명들을 참조한다. 상세사 항들이 다시 설명되지는 않는다. 제5 양태에 따르면, 장치가 제공된다. 유익한 효과들에 대해서는, 제2 양태의 설명들을 참조한다. 이러한 장 치는 제1 액세스 네트워크 디바이스, 제1 액세스 네트워크 디바이스에서 구성되는 장치, 또는 제1 액세스 네트 워크 디바이스와 매칭함에 있어서 사용될 수 있는 장치일 수 있다. 설계에서, 이러한 장치는 제2 양태에서 설 명되는 방법들/동작들/단계들/액션들과 일-대-일 대응관계에 있는 유닛들을 포함할 수 있다. 이러한 유닛들은 하드웨어 회로, 소프트웨어, 또는 하드웨어 회로와 소프트웨어의 조합을 사용하여 구현될 수 있다. 예를 들어, 이러한 장치는 처리 유닛 및 통신 유닛을 포함할 수 있고, 이러한 처리 유닛 및 통신 유닛은 제2 양 태의 임의의 설계 예에서의 대응하는 기능들을 수행할 수 있다. 통신 유닛은 제1 모델 요청 메시지를 OAM(operations, administration and maintenance)에 전송하도록- 제1 모 델 요청 메시지는 제1 모델의 모델 애플리케이션 시나리오 및 모델 기능을 표시하거나, 또는 제1 모델 요청 메시지는 제1 모델의 모델 기능 및 모델 성능 레벨을 표시함 -; 그리고 OAM으로부터 제1 모델에 관한 정보를 수신 하도록 구성된다. 처리 유닛은 제1 모델에 관한 정보에 기초하여 제1 모델을 결정하도록 구성된다. 처리 유닛 및 통신 유닛의 구체적인 실행 프로세스들에 대해서는, 제2 양태를 참조한다. 상세사항들이 본 명세서에서 다 시 설명되지는 않는다. 예를 들어, 이러한 장치는 제2 양태에서 설명되는 방법을 구현하도록 구성되는 메모리를 포함한다. 이러한 장 치는 명령어들 및/또는 데이터를 저장하도록 구성되는 메모리를 추가로 포함할 수 있다. 이러한 메모리는 프로 세서에 연결된다. 메모리에 저장된 프로그램 명령어들을 실행할 때, 프로세서는 제2 양태에서 설명되는 방법을 구현할 수 있다. 이러한 장치는 통신 인터페이스를 추가로 포함할 수 있고, 이러한 통신 인터페이스는 다른 디 바이스와 통신하기 위해 장치에 의해 사용된다. 예를 들어, 이러한 통신 인터페이스는 송수신기, 회로, 버스, 모듈, 핀, 또는 다른 타입의 통신 인터페이스일 수 있고, 다른 디바이스는 단말 등일 수 있다. 가능한 설계에 서, 이러한 장치는, 프로그램 명령어들을 저장하도록 구성되는 메모리; 제1 모델 요청 메시지를 OAM(operations, administration and maintenance)에 전송하도록- 제1 모델 요청 메시 지는 제1 모델의 모델 애플리케이션 시나리오 및 모델 기능을 표시하거나, 또는 제1 모델 요청 메시지는 제1 모 델의 모델 기능 및 모델 성능 레벨을 표시함 -; 그리고 OAM으로부터 제1 모델에 관한 정보를 수신하도록 구성되 는 통신 인터페이스; 및 제1 모델에 관한 정보에 기초하여 제1 모델을 결정하도록 구성되는 프로세서를 포함한다. 통신 인터페이스 및 프로세서의 구체적인 실행 프로세스들에 대해서는, 제2 양태의 설명들을 참조한다. 상세사 항들이 다시 설명되지는 않는다. 제6 양태에 따르면, 장치가 제공된다. 유익한 효과들에 대해서는, 제3 양태의 설명들을 참조한다. 이러한 장 치는 제2 액세스 네트워크 디바이스, 제2 액세스 네트워크 디바이스에서 구성되는 장치, 또는 제2 액세스 네트 워크 디바이스와 매칭함에 있어서 사용될 수 있는 장치일 수 있다. 설계에서, 이러한 장치는 제3 양태에서 설 명되는 방법들/동작들/단계들/액션들과 일-대-일 대응관계에 있는 유닛들을 포함할 수 있다. 이러한 유닛들은 하드웨어 회로, 소프트웨어, 또는 하드웨어 회로와 소프트웨어의 조합을 사용하여 구현될 수 있다. 예를 들어, 이러한 장치는 처리 유닛 및 통신 유닛을 포함할 수 있고, 이러한 처리 유닛 및 통신 유닛은 제3 양 태의 임의의 설계 예에서의 대응하는 기능들을 수행할 수 있다. 통신 유닛은 제1 액세스 네트워크 디바이스로부터 제1 모델의 인덱스를 수신하도록; 제2 모델 요청 메시지를 OAM(operations, maintenance, and administration)에 전송하도록- 제2 모델 요청 메시지는 제1 모델의 인덱스 를 표시함 -; 그리고 OAM으로부터 제1 모델에 관한 정보를 수신하도록 구성된다. 처리 유닛은 제1 모델에 관한 정보에 기초하여 제1 모델을 결정하도록 구성된다. 처리 유닛 및 통신 유닛의 구체적인 실행 프로세스들에 대 해서는, 제3 양태를 참조한다. 상세사항들이 본 명세서에서 다시 설명되지는 않는다. 예를 들어, 이러한 장치는 제3 양태에서 설명되는 방법을 구현하도록 구성되는 메모리를 포함한다. 이러한 장 치는 명령어들 및/또는 데이터를 저장하도록 구성되는 메모리를 추가로 포함할 수 있다. 이러한 메모리는 프로 세서에 연결된다. 메모리에 저장된 프로그램 명령어들을 실행할 때, 프로세서는 제3 양태에서 설명되는 방법을 구현할 수 있다. 이러한 장치는 통신 인터페이스를 추가로 포함할 수 있고, 이러한 통신 인터페이스는 다른 디 바이스와 통신하기 위해 장치에 의해 사용된다. 예를 들어, 이러한 통신 인터페이스는 송수신기, 회로, 버스, 모듈, 핀, 또는 다른 타입의 통신 인터페이스일 수 있고, 다른 디바이스는 단말 등일 수 있다. 가능한 설계에 서, 이러한 장치는, 프로그램 명령어들을 저장하도록 구성되는 메모리; 제1 액세스 네트워크 디바이스로부터 제1 모델의 인덱스를 수신하도록; 제2 모델 요청 메시지를 OAM(operations, maintenance, and administration)에 전송하도록- 제2 모델 요청 메시지는 제1 모델의 인덱스 를 표시함 -; 그리고 OAM으로부터 제1 모델에 관한 정보를 수신하도록 구성되는 통신 인터페이스를 포함한다. 프로세서는 제1 모델에 관한 정보에 기초하여 제1 모델을 결정하도록 구성된다. 통신 인터페이스 및 프로세서의 구체적인 실행 프로세스들에 대해서는, 제3 양태의 설명들을 참조한다. 상세사 항들이 다시 설명되지는 않는다.제7 양태에 따르면, 본 출원의 실시예는 컴퓨터-판독가능한 저장 매체를 추가로 제공하며, 이는 명령어들을 포 함한다. 이러한 명령어들이 컴퓨터 상에서 실행될 때, 이러한 컴퓨터는 제1 양태, 제2 양태, 또는 제3 양태 중 어느 하나에서의 방법을 수행하는 것이 가능하게 된다. 제8 양태에 따르면, 본 출원은 칩 시스템을 추가로 제공한다. 이러한 칩 시스템은 프로세서를 포함하고, 제1 양태, 제2 양태, 또는 제3 양태 중 어느 하나에서의 방법을 구현하도록 구성되는 메모리를 추가로 포함할 수 있 다. 이러한 칩 시스템은 칩을 포함할 수 있거나, 또는 칩 및 다른 개별 컴포넌트를 포함할 수 있다. 제9 양태에 따르면, 본 출원은 컴퓨터 프로그램 제품을 추가로 제공하며, 이는 명령어들을 포함한다. 이러한 명령어들이 컴퓨터 상에서 실행될 때, 이러한 컴퓨터는 제1 양태, 제2 양태, 또는 제3 양태 중 어느 하나에서의 방법을 수행하는 것이 가능하게 된다. 제10 양태에 따르면, 본 출원은 시스템을 추가로 제공한다. 이러한 시스템은 제4 양태에서의 장치 및 제5 양태 에서의 장치; 또는 제4 양태에서의 장치, 제5 양태에서의 장치, 및 제6 양태에서의 장치를 포함한다."}
{"patent_id": "10-2024-7026840", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "item": 1, "content": "도 1은 본 출원이 적용되는 통신 시스템의 아키텍처의 도면이다. 도 1에 도시되는 바와 같이, 통신 시스 템은 무선 액세스 네트워크 및 코어 네트워크를 포함한다. 선택적으로, 통신 시스템은 인터넷 을 추가로 포함할 수 있다. 무선 액세스 네트워크는 적어도 하나의 액세스 네트워크 디바이스(예를 들어, 도 1에서의 110a 및 110b)를 포함할 수 있고, 적어도 하나의 단말 디바이스(예를 들어, 도 1에서의 120a 내지 120j)를 추가로 포함할 수 있다. 단말 디바이스는 무선 방식으로 액세스 네트워크 디바이스에 접속되고, 액세스 네트워크 디바이스는 무선 또는 유선 방식으로 코어 네트워크에 접속된다. 코어 네트워크 디바이스 및 액세스 네트워크 디바이스는 서로 독립적인 상이한 물리적 디바이스들일 수 있거나, 또는 코어 네트워크 디바이 스의 기능들 및 액세스 네트워크 디바이스의 논리적 기능들은 동일한 물리적 디바이스에 통합될 수 있거나, 또 는 코어 네트워크 디바이스의 기능들의 일부 및 액세스 네트워크 디바이스의 기능들의 일부는 하나의 물리적 디 바이스에 통합될 수 있다. 단말 디바이스들은 유선 또는 무선 방식으로 서로 접속될 수 있고, 액세스 네트워크 디바이스들은 유선 또는 무선 방식으로 서로 접속될 수 있다. 도 1은 단지 도면이다. 통신 시스템은 다른 네 트워크 디바이스를 추가로 포함할 수 있고, 예를 들어, 도 1에 도시되지 않은, 무선 릴레이 디바이스 및 무선 백홀 디바이스를 추가로 포함할 수 있다. 액세스 네트워크 디바이스는 기지국(base station), 진화된 NodeB(evolved NodeB, eNodeB), 송신 수신 포인트 (transmission reception point, TRP), 5세대(5th generation, 5G) 이동 통신 시스템에서의 차세대 NodeB(next generation NodeB, gNB), 개방 무선 액세스 네트워크(open radio access network, O-RAN)에서의 액세스 네트워 크 디바이스, 6세대(6th generation, 6G) 이동 통신 시스템에서의 차세대 기지국, 미래의 이동 통신 시스템에서 의 기지국, 무선 충실도(wireless fidelity, Wi-Fi) 시스템에서의 액세스 노드 등일 수 있거나; 또는 모듈 또는 유닛일 수 있고, 예를 들어, 기지국의 기능들의 일부를 완료하는, 중앙 유닛(central unit, CU), 분산 유닛 (distributed unit, DU), 중앙 유닛 제어 평면(CU control plane, CU-CP) 모듈, 또는 중앙 유닛 사용자 평면 (CU user plane, CU-UP) 모듈일 수 있다. 무선 액세스 네트워크 디바이스는 매크로 기지국(예를 들어, 도 1에 서의 110a)일 수 있거나, 또는 마이크로 기지국 또는 실내 기지국(예를 들어, 도 1에서의 110b)일 수 있거나, 또는 릴레이 노드, 도너 노드 등일 수 있다. 액세스 네트워크 디바이스에 의해 사용되는 구체적인 기술 및 구체적인 디바이스 형태는 본 출원에서 제한되지 않는다. 본 출원의 실시예들에서, 액세스 네트워크 디바이스의 기능을 구현하도록 구성되는 장치는 액세스 네트워크 디 바이스일 수 있거나, 또는 기능을 구현함에 있어서 액세스 네트워크 디바이스를 지원할 수 있는 장치, 예를 들 어, 칩 시스템, 하드웨어 회로, 소프트웨어 모듈, 또는 하드웨어 회로와 소프트웨어 모듈의 조합일 수 있다. 이러한 장치는 액세스 네트워크 디바이스에 설치될 수 있거나 또는 액세스 네트워크 디바이스와 매칭함에 있어 서 사용될 수 있다. 본 출원에서, 칩 시스템은 칩을 포함할 수 있거나, 또는 칩 및 다른 개별 컴포넌트를 포함 할 수 있다. 설명의 용이함을 위해, 다음은 액세스 네트워크 디바이스의 기능들을 구현하도록 구성되는 장치가 액세스 네트워크 디바이스이고 액세스 네트워크 디바이스가 RAN 노드인 예를 사용하여 본 출원에서 제공되는 기 술적 해결책들을 설명한다. 프로토콜 레이어 구조 액세스 네트워크 디바이스와 단말 디바이스 사이의 통신은 명시된 프로토콜 레이어 구조를 준수한다. 프로토콜 레이어 구조는 제어 평면 프로토콜 레이어 구조 및 사용자 평면 프로토콜 레이어 구조를 포함할 수 있다. 예를 들어, 제어 평면 프로토콜 레이어 구조는 무선 리소스 제어(radio resource control, RRC) 레이어, 패킷 데이터 수렴 프로토콜(packet data convergence protocol, PDCP) 레이어, 무선 링크 제어(radio link control, RLC) 레이어, 매체 액세스 제어(media access control, MAC) 레이어, 및 물리적 레이어와 같은 프로토콜 레이어들의 기능들을 포함할 수 있다. 예를 들어, 사용자 평면 프로토콜 레이어 구조는 PDCP 레이어, RLC 레이어, MAC 레 이어, 및 물리적 레이어와 같은 프로토콜 레이어들의 기능들을 포함할 수 있다. 가능한 구현에서, 서비스 데이 터 적응 프로토콜(service data adaptation protocol, SDAP) 레이어가 PDCP 레이어 위에 추가로 포함될 수 있 다. 선택적으로, 액세스 네트워크 디바이스와 단말 디바이스 사이의 프로토콜 레이어 구조는 AI 기능에 관련된 데이 터를 송신하기 위한 인공 지능(artificial intelligence, AI) 레이어를 추가로 포함할 수 있다. 중앙 유닛(central unit, CU) 및 분산 유닛(distributed unit, DU) 액세스 디바이스는 CU 및 DU를 포함할 수 있다. 중앙집중형 방식으로 하나의 CU에 의해 복수의 DU들이 제어될 수 있다. 예를 들어, CU와 DU 사이의 인터페이스는 F1 인터페이스라고 지칭될 수 있다. 제어 평면(control plane, CP) 인터페이스는 F1-C일 수 있고, 사용자 평면(user panel, UP) 인터페이스는 F1-U일 수 있다. 각각 의 인터페이스의 구체적인 명칭은 본 출원에서 제한되지 않는다. CU 및 DU는 무선 네트워크의 프로토콜 레이어 에 기초하여 분할될 수 있다. 예를 들어, PDCP 레이어 및 이러한 PDCP 레이어 위의 프로토콜 레이어의 기능들 은 CU 상에서 설정되고, 이러한 PDCP 레이어 아래의 프로토콜 레이어들(예를 들어, RLC 레이어 및 MAC 레이어) 의 기능들은 DU 상에서 설정된다. 다른 예를 들어, PDCP 레이어 위의 프로토콜 레이어의 기능들은 CU 상에서 설정되고, PDCP 레이어 및 PDCP 레이어 아래의 프로토콜 레이어들의 기능들은 DU 상에서 설정된다. 이러한 것 은 제한되지 않는다. 프로토콜 레이어들에 기초하는 CU 및 DU의 처리 기능들로의 전술한 분할은 단지 예이고, 대안적으로 다른 분할 일 수 있다. 예를 들어, CU 또는 DU는 더 많은 프로토콜 레이어들의 기능들을 갖도록 정의될 수 있고, 다른 예 를 들어, CU 또는 DU는 대안적으로 프로토콜 레이어들의 처리 기능들의 일부를 갖도록 정의될 수 있다. 설계에 서, RLC 레이어의 기능들 및 RLC 레이어 위의 프로토콜 레이어들의 기능들의 일부가 CU 상에서 설정되고, RLC 레이어의 나머지 기능들 및 RLC 레이어 아래의 프로토콜 레이어들의 기능들이 DU 상에서 설정된다. 다른 설계 에서, CU 또는 DU의 기능들의 분할은 서비스 타입들 또는 다른 시스템 요건들에 기초하여 대안적으로 수행될 수 있다. 예를 들어, 분할은 레이턴시들에 기초하여 수행될 수 있다. 처리 시간이 레이턴시 요건을 충족시킬 필 요가 있는 기능들은 DU 상에서 설정되고, 처리 시간이 레이턴시 요건을 충족시킬 필요가 없는 기능들은 CU 상에 서 설정된다. 다른 설계에서는, CU는 대안적으로 코어 네트워크의 하나 이상의 기능을 가질 수 있다. 예를 들 어, CU는 중앙집중형 관리를 용이하게 하기 위해 네트워크 측 상에 배치될 수 있다. 다른 설계에서는, DU의 무 선 유닛(radio unit, RU)이 원격으로 배치된다. 선택적으로, RU는 무선 주파수 기능을 가질 수 있다. 선택적으로, DU 및 RU는 물리 레이어(physical layer, PHY)에서 구별될 수 있다. 예를 들어, DU는 PHY 레이어 의 상위-레이어 기능들을 구현할 수 있고, RU는 PHY 레이어의 하위-레이어 기능들을 구현할 수 있다. PHY 레이 어가 전송을 위해 사용될 때, PHY 레이어의 기능들은 다음의 기능들: 순환 중복 체크(cyclic redundancy check, CRC) 코드의 추가, 채널 인코딩, 레이트 매칭, 스크램블링, 변조, 레이어 맵핑, 프리코딩, 리소스 맵핑, 물리 안테나 맵핑, 또는 무선 주파수 전송 중 적어도 하나를 포함할 수 있다. PHY 레이어가 수신을 위해 사용될 때,PHY 레이어의 기능들은 다음의 기능들: CRC 체크, 채널 디코딩, 디-레이트 매칭, 디스크램블링, 복조, 레이어 디맵핑, 채널 검출, 리소스 디맵핑, 물리 안테나 디맵핑, 또는 무선 주파수 수신 중 적어도 하나를 포함할 수 있다. PHY 레이어의 상위-레이어 기능들은 PHY 레이어의 일부 기능들을 포함할 수 있다. 예를 들어, 일부 기 능들은 MAC 레이어에 더 가깝다. PHY 레이어의 하위-레이어 기능들은 PHY 레이어의 일부 다른 기능들을 포함할 수 있다. 예를 들어, 기능들의 일부는 무선 주파수 기능에 더 가깝다. 예를 들어, PHY 레이어의 상위-레이어 기능들은 CRC 코드 추가, 채널 코딩, 레이트 매칭, 스크램블링, 변조, 및 레이어 맵핑을 포함할 수 있고, PHY 레이어의 하위-레이어 기능들은 프리코딩, 리소스 맵핑, 물리 안테나 맵핑, 및 무선 주파수 전송 기능들을 포함 할 수 있다. 대안적으로, PHY 레이어의 상위-레이어 기능은 CRC 코드 추가, 채널 코딩, 레이트 매칭, 스크램블 링, 변조, 레이어 맵핑, 및 프리코딩을 포함할 수 있다. PHY 레이어의 하위-레이어 기능은 리소스 맵핑, 물리 안테나 맵핑, 및 무선 주파수 전송 기능들을 포함할 수 있다. 예를 들어, PHY 레이어의 상위-레이어 기능들은 CRC 체크, 채널 디코딩, 디-레이트 매칭, 디코딩, 복조, 및 레이어 디맵핑을 포함할 수 있고, PHY 레이어의 하 위-레이어 기능들은 채널 검출, 리소스 디맵핑, 물리 안테나 디맵핑, 및 무선 주파수 수신의 기능들을 포함할 수 있다. 대안적으로, PHY 레이어의 상위-레이어 기능들은 CRC 체크, 채널 디코딩, 디-레이트 매칭, 디코딩, 복조, 레이어 디맵핑 및 채널 검출을 포함할 수 있고, PHY 레이어의 하위-레이어 기능들은 리소스 디맵핑, 물리 안테나 디맵핑 및 무선 주파수 수신의 기능들을 포함할 수 있다. 예를 들어, CU의 기능들은 하나의 엔티티에 의해 구현될 수 있거나, 또는 상이한 엔티티들에 의해 구현될 수 있 다. 예를 들어, CU의 기능들은 추가로 분할될 수 있다. 구체적으로, CU의 것인 제어 평면 및 사용자 평면은, 제어 평면 CU 엔티티(즉, CU-CP 엔티티) 및 사용자 평면 CU 엔티티(즉, CU-UP 엔티티)인, 상이한 엔티티들에 의 해 분리되고 구현된다. CU-CP 엔티티 및 CU-UP 엔티티는, 액세스 네트워크 디바이스의 기능들을 공동으로 완료 하기 위해, DU에 연결될 수 있다. 선택적으로, DU, CU, CU-CP, CU-UP, 및 RU 중 어느 하나는 소프트웨어 모듈, 하드웨어 구조, 또는 소프트웨어 모듈과 하드웨어 구조의 조합일 수 있다. 이러한 것은 제한되지 않는다. 상이한 엔티티들이 상이한 형태들로 존재할 수 있으며, 이는 제한되지 않는다. 예를 들어, DU, CU, CU-CP, 및 CU-UP는 소프트웨어 모듈들이고, RU 는 하드웨어 구조이다. 이러한 모듈들 및 이러한 모듈들에 의해 수행되는 방법들은 본 출원의 보호 범위 내에 또한 속한다. 가능한 구현에서, 액세스 네트워크 디바이스는 CU-CP, CU-UP, DU, 및 RU를 포함한다. 예를 들어, 본 출원은 DU, 또는 DU 및 RU, 또는 CU-CP, DU, 및 RU, 또는 CU-UP, DU, 및 RU에 의해 실행된다. 이러한 것은 제한되지 않는다. 이러한 모듈들에 의해 수행되는 방법들은 본 출원의 보호 범위 내에 또한 속한다. 단말 디바이스는 단말, 사용자 장비(user equipment, UE), 이동국, 이동 단말 디바이스 등이라고 또한 지칭될 수 있다. 단말 디바이스는, 예를 들어, 다음의 시나리오들: 디바이스-대-디바이스(device-to-device, D2D), 차 량-대-사물(vehicle-to-everything, V2X), 머신-타입 통신(machine-type communication, MTC), 사물 인터넷 (internet of things, IOT), 가상 현실, 증강 현실, 산업 제어, 자율-주행, 원격의료, 스마트 그리드, 스마트 가구, 스마트 오피스, 스마트 웨어러블, 스마트 교통, 스마트 시티 등 중 적어도 하나를 포함하지만 이에 제한 되지는 않는 다양한 시나리오들에서의 통신에서 널리 사용된다. 단말 디바이스는 이동 전화, 태블릿 컴퓨터, 무선 송수신기 기능을 갖는 컴퓨터, 웨어러블 디바이스, 차량, 무인 비행체, 헬리콥터, 비행기, 선박, 로봇, 로 봇 팔, 스마트 홈 디바이스 등일 수 있다. 단말 디바이스에 의해 사용되는 구체적인 기술 및 구체적인 디바이 스 형태는 본 출원에서 제한되지 않는다. 본 출원의 실시예들에서, 단말 디바이스의 기능을 구현하도록 구성되는 장치는 단말 디바이스일 수 있거나, 또 는 기능을 구현함에 있어서 단말 디바이스를 지원할 수 있는 장치, 예를 들어, 칩 시스템, 하드웨어 회로, 소프 트웨어 모듈, 또는 하드웨어 회로와 소프트웨어 모듈의 조합일 수 있다. 이러한 장치는 단말 디바이스에 설치 될 수 있거나 또는 단말 디바이스와 매칭함에 있어서 사용될 수 있다. 설명의 용이함을 위해, 다음은 단말 디 바이스의 기능들을 구현하도록 구성되는 장치가 단말 디바이스이고 단말 디바이스가 UE인 예를 사용하여 본 출 원에서 제공되는 기술적 해결책들을 설명한다. 기지국 및 단말 디바이스는 고정되거나 또는 이동가능할 수 있다. 기지국 및/또는 단말 디바이스는, 실내 또는 실외 시나리오, 및 핸드헬드 또는 차량-장착형 시나리오를 포함하여, 육상에 배치될 수 있거나; 또는 수상에 배 치될 수 있거나; 또는 공중에서 비행기, 풍선, 및 인공 위성 상에 배치될 수 있다. 기지국 및 단말 디바이스의 애플리케이션 시나리오들은 본 출원에서 제한되지 않는다. 기지국 및 단말 디바이스는 동일한 시나리오 또는 상이한 시나리오들에서 배치될 수 있다. 예를 들어, 기지국 및 단말 디바이스는 양자 모두 육상에 배치된다.대안적으로, 기지국은 육상에 배치되고, 단말 디바이스는 수상에 배치된다. 예들이 하나씩 설명되지는 않는다. 기지국과 단말 디바이스의 역할들은 상대적일 수 있다. 예를 들어, 도 1에서의 헬리콥터 또는 무인 비행체 (120i)가 이동 기지국으로서 구성될 수 있다. 무선 액세스 네트워크(100 내지 120i)에 액세스하는 단말 디바이 스(120j)에 대해, 단말 디바이스(120i)는 기지국이고; 한편 기지국(110a, 120i)은 단말 디바이스이고, 다시 말 해서, 110a 및 120i는 무선 에어 인터페이스 프로토콜에 기초하여 서로 통신한다. 110a 및 120i는 대안적으로 기지국들 사이의 인터페이스 프로토콜에 기초하여 서로 통신할 수 있다. 이러한 경우, 110a에 상대적으로, 120i가 또한 기지국이다. 따라서, 기지국 및 단말 디바이스는 통신 장치들이라고 집합적으로 지칭될 수 있고, 도 1에서의 110a 및 110b는 기지국의 기능들을 갖는 통신 장치라고 지칭될 수 있고, 도 1에서의 120a 내지 120j 는 단말 디바이스의 기능들을 갖는 통신 장치라고 지칭될 수 있다. 본 출원에서, AI-관련 동작을 구현하기 위해 도 1에 도시되는 통신 시스템에 독립 네트워크 엘리먼트(예를 들어, AI 네트워크 엘리먼트 또는 AI 노드라고 지칭됨)가 도입될 수 있다. AI 네트워크 엘리먼트는 통신 시스 템에서의 액세스 네트워크 디바이스에 직접 접속될 수 있거나, 또는 제3자 네트워크 엘리먼트를 통해 액세스 네 트워크 디바이스에 간접적으로 접속될 수 있다. 제3자 네트워크 엘리먼트는 인증 관리 기능(authentication management function, AMF) 또는 사용자 평면 기능(user plane function, UPF)과 같은 코어 네트워크 엘리먼트 일 수 있다. 대안적으로, AI-관련 동작을 구현하도록 통신 시스템에서의 다른 네트워크 엘리먼트에서 AI 기능, AI 모듈, 또는 AI 엔티티가 구성될 수 있다. 예를 들어, 다른 네트워크 엘리먼트는 (gNB와 같은) 액세스 네트 워크 디바이스, 코어 네트워크 디바이스, 또는 동작들, 관리 및 유지보수(operations, administration and maintenance, OAM)일 수 있다. 이러한 경우, AI-관련 동작을 수행하는 네트워크 엘리먼트는 내장된 AI 기능이 있는 네트워크 엘리먼트이다. OAM은 액세스 네트워크 디바이스 및/또는 코어 네트워크 디바이스에 대해 동작, 관리, 유지보수 등을 수행하도록 구성된다. 본 출원에서, 도 2 또는 도 3에 도시되는 바와 같이, AI 모델은 코어 네트워크 디바이스, 액세스 네트워크 디바 이스, 단말 디바이스, OAM 등 중 적어도 하나 상에 배치될 수 있고, 대응하는 기능은 AI 모델을 사용하여 구현 된다. 본 출원에서, 상이한 노드들 상에 배치되는 AI 모델들은 동일하거나 또는 상이할 수 있다. 이러한 모델 들은 다음: 모델의 상이한 구조 파라미터들, 예를 들어, 모델의 레이어들 및/또는 가중치들의 상이한 수량들, 모델의 상이한 입력 파라미터들, 또는 모델의 상이한 출력 파라미터들 중 적어도 하나의 면에서 상이하다. 모 델의 상이한 입력 파라미터들 및/또는 모델의 상이한 출력 파라미터들은 모델의 상이한 기능들로서 설명될 수 있다. 도 2와 상이하게, 도 3에서, 액세스 네트워크 디바이스의 기능은 CU 및 DU로 분리된다. 선택적으로, CU 및 DU는 O-RAN 아키텍처에서의 CU 및 DU일 수 있다. 하나 이상의 AI 모델이 CU에 배치될 수 있고, 및/또는 하 나 이상의 AI 모델이 DU에 배치될 수 있다. 선택적으로, 도 3에서의 CU는 CU-CP 및 CU-UP로 추가로 분리될 수 있다. 선택적으로, 하나 이상의 AI 모델이 CU-CP에 배치될 수 있고, 및/또는 하나 이상의 AI 모델이 CU-UP에 배치될 수 있다. 선택적으로, 도 2 또는 도 3에서, 액세스 네트워크 디바이스의 OAM과 코어 네트워크 디바이스 의 OAM은 별도로 배치될 수 있다. 선택적으로, 도 4a는 본 출원에 따른 통신 시스템의 아키텍처이다. 도 4a에 도시되는 바와 같이, 제1 설계에서, 액세스 네트워크 디바이스는, 모델 트레이닝 및 추론을 수행하도록 구성되는, 거의 실시간 액세스 네 트워크 지능형 제어(RAN intelligent controller, RIC) 모듈을 포함한다. 예를 들어, 거의 실시간 RIC는 AI 모델을 트레이닝하고 AI 모델을 사용하여 추론을 수행하도록 구성될 수 있다. 예를 들어, 거의 실시간 RIC는 CU, DU, 또는 RU 중 적어도 하나로부터 네트워크 측 및/또는 단말 측의 정보를 획득할 수 있고, 이러한 정보는 트레이닝 데이터 또는 추론 데이터로서 사용될 수 있다. 선택적으로, 거의 실시간 RIC는 추론 결과를 CU, DU, RU, 또는 단말 디바이스 중 적어도 하나에 제출할 수 있다. 선택적으로, CU 및 DU는 추론 결과를 교환할 수 있 다. 선택적으로, DU 및 RU는 추론 결과를 교환할 수 있다. 예를 들어, 거의 실시간 RIC는 추론 결과를 DU에 제출하고, DU는 추론 결과를 RU에 전달한다. 대안적으로, 제2 설계에서, 도 4a에 도시되는 바와 같이, 액세스 네트워크 디바이스는 모델 학습 및 추론을 수 행하도록 구성되는 비-실시간 RIC(여기서, 선택적으로, 비-실시간 RIC는 OAM 또는 코어 네트워크 디바이스에 위 치될 수 있음)를 포함할 수 있다. 예를 들어, 비-실시간 RIC는 AI 모델을 트레이닝하고 모델을 사용하여 추론 을 수행하도록 구성된다. 예를 들어, 비-실시간 RIC는 CU, DU, 또는 RU 중 적어도 하나로부터 네트워크 측 및/ 또는 단말 측의 정보를 획득할 수 있고, 이러한 정보는 트레이닝 데이터 또는 추론 데이터로서 사용될 수 있다. 추론 결과는 CU, DU, RU, 또는 단말 디바이스 중 적어도 하나에 제출될 수 있다. 선택적으로, CU 및 DU는 추론 결과를 교환할 수 있다. 선택적으로, DU 및 RU는 추론 결과를 교환할 수 있다. 예를 들어, 비-실시간 RIC는추론 결과를 DU에 제출하고, DU는 추론 결과를 RU에 전달한다. 대안적으로, 제3 설계에서, 도 4a에 도시되는 바와 같이, 액세스 네트워크 디바이스는 거의 실시간 RIC를 포함 하고, 비-실시간 RIC(여기서, 선택적으로, 비-실시간 RIC는 OAM 또는 코어 네트워크 디바이스에 위치될 수 있음)는 액세스 네트워크 디바이스 외부에 위치한다. 전술한 제2 설계와 동일하게, 비-실시간 RIC는 모델 트레 이닝 및 추론을 위한 것일 수 있고; 및/또는 제1 설계와 동일하게, 거의 실시간 RIC는 모델 트레이닝 및 추론을 위한 것일 수 있고; 및/또는 비-실시간 RIC는 모델 트레이닝을 수행하고, 거의 실시간 RIC는 비-실시간 RIC로부 터 AI 모델 정보를 획득하고, CU, DU, 또는 RU 중 적어도 하나로부터 네트워크 측 및/또는 단말 측의 정보를 획 득하고, 정보 및 AI 모델 정보를 사용하여 추론 결과를 획득할 수 있다. 선택적으로, 거의 실시간 RIC는 추론 결과를 CU, DU, RU, 또는 단말 디바이스 중 적어도 하나에 제출할 수 있다. 선택적으로, CU 및 DU는 추론 결과 를 교환할 수 있다. 선택적으로, DU 및 RU는 추론 결과를 교환할 수 있다. 예를 들어, 거의 실시간 RIC는 추 론 결과를 DU에 제출하고, DU는 추론 결과를 RU에 전달한다. 예를 들어, 거의 실시간 RIC는 모델 A를 트레이닝 하고 모델 A를 사용하여 추론을 수행하도록 구성된다. 예를 들어, 비-실시간 RIC는 모델 B를 트레이닝하고 모 델 B를 사용하여 추론을 수행하도록 구성된다. 예를 들어, 비-실시간 RIC는 모델 C를 트레이닝하고 모델 C에 관한 정보를 거의 실시간 RIC에 전송하도록 구성되고, 거의 실시간 RIC는 추론을 위해 모델 C를 사용한다. 도 4b는 본 출원에 따른 다른 통신 시스템의 아키텍처의 도면이다. 도 4a와 비교하여, 도 4b에서, CU는 CU-CP 및 CU-UP로 분리된다. AI 모델은 AI 기능의 구체적인 구현이다. AI 모델은 모델의 입력과 출력 사이의 맵핑 관계를 표현한다. AI 모 델은 신경망, 선형 회귀 모델, 결정 트리 모델, 지원 벡터 머신(support vector machine, SVM), Bayesian 네트 워크, Q-학습 모델, 다른 머신 학습 모델 등일 수 있다. 본 출원에서, AI 기능은 다음: 데이터 수집(트레이닝 데이터 및/또는 추론 데이터를 수집함), 데이터 전처리, 모델 트레이닝(또는 모델 학습이라고 지칭됨), 모델 정 보 해제(모델 정보 구성), 모델 검증, 모델 추론, 또는 추론 결과 해제 중 적어도 하나를 포함할 수 있다. 추 론은 예측이라고 또한 지칭될 수 있다. 본 출원에서, AI 모델은 줄여서 모델이라고 지칭될 수 있다. 도 4c는 AI 모델의 애플리케이션 아키텍처의 도면이다. 데이터 소스(data source)는 트레이닝 데이터 및 추론 데이터를 저장하도록 구성된다. 모델 트레이닝 호스트(model training host)는 데이터 소스에 의해 제공되는 트레이닝 데이터(training data)를 분석하거나 또는 트레이닝시켜 AI 모델을 획득하고, AI 모델을 모델 추론 노 드(model inference host)에 배치한다. 선택적으로, 모델 트레이닝 노드는 모델 추론 노드 상에 배치된 AI 모 델을 추가로 업데이트할 수 있다. 모델 추론 노드는 배치된 모델의 관련 정보를 모델 트레이닝 노드에게 추가 로 피드백할 수 있어서, 모델 트레이닝 노드는 배치된 AI 모델을 최적화 또는 업데이트 등을 한다. 모델 트레이닝 노드에 의한 학습을 통해 AI 모델을 획득하는 것은 트레이닝 데이터를 사용하여 모델 트레이닝 노드에 의한 학습을 통해 모델의 입력과 출력 사이의 맵핑 관계를 획득하는 것과 동등하다. 모델 추론 노드는 AI 모델을 사용하여 데이터 소스에 의해 제공되는 추론 데이터에 기초하여 추론을 수행하고 추론 결과를 획득한 다. 이러한 방법은 다음과 같이 또한 설명될 수 있다: 모델 추론 노드는 추론 데이터를 AI 모델에 입력하고, AI 모델을 사용하여 출력을 획득한다. 출력은 추론 결과이다. 추론 결과는 액션의 객체에 의해 사용(작용)되 는 구성 파라미터, 및/또는 액션의 객체에 의해 작용되는 동작을 표시할 수 있다. 추론 결과는 액터(actor) 엔 티티에 의해 중앙집중형으로 계획될 수 있고, 액션을 위해 액션의 하나 이상의 객체(예를 들어, 네트워크 엔티 티들)에 전송될 수 있다. 선택적으로, 액터 엔티티 또는 액터 객체는 액터 엔티티 또는 액터 객체에 의해 수집 되는 파라미터 또는 측정량을 데이터 소스에 피드백할 수 있다. 이러한 프로세스는 성능 피드백이라고 지칭될 수 있고, 피드백된 네트워크 파라미터는 트레이닝 데이터 또는 추론 데이터로서 사용될 수 있다. 선택적으로, 액터 엔티티 또는 액터 객체는 모델 추론 노드에 의해 출력되는 추론 결과에 기초하여 모델 성능에 관련된 피드 백 정보를 추가로 결정하고, 피드백 정보를 모델 추론 노드에 피드백할 수 있다. 모델 추론 노드는 피드백 정 보에 기초하여 모델의 성능 정보를 모델 트레이닝 노드에 피드백할 수 있어서, 모델 트레이닝 노드는 배치된 AI 모델을 최적화하거나 또는 업데이트한다. 이러한 프로세스는 모델 피드백이라고 지칭될 수 있다. AI 모델은 신경망 또는 다른 머신 학습 모델일 수 있다. 신경망이 예로서 사용된다. 신경망은 머신 학습 기술 의 구체적인 구현 형태이다. 보편적 근사화 정리에 따르면, 신경망은 이론적으로 임의의 연속 함수에 근사화할 수 있어서, 신경망은 임의의 맵핑을 학습하는 능력을 갖는다. 따라서, 신경망은 복잡한 고차원 문제에 대한 추 상화 모델링을 정확하게 수행할 수 있다. 신경망의 아이디어는 두뇌 조직의 뉴런 구조로부터의 것이다. 각각의 뉴런은 뉴런의 입력 값들에 대해 가중 합 산 연산을 수행하고, 활성화 함수를 통해 가중 합산의 결과를 출력한다. 도 5는 뉴런의 구조의 도면이다. 뉴런의 입력 값들은 이고, 입력 값들에 대응하는 가중치는 각각 이고, 가중 합산의 바이어스는 b라고 가정된다. 활성화 함수의 형태들은 다양화될 수 있다. 하나의 뉴런의 활성화 함수는 인 것으로 가정된다. 이러한 경우, 뉴런의 출력은 이다. 다른 예를 들어, 뉴런의 활성화 함수가 이면, 뉴런의 출력은 이다. , , 및 b는 십진수, 정수(예를 들어, 0, 양의 정수 또는 음의 정수), 또는 복소수와 같은 임의의 가능한 값일 수 있다. 신경망에서의 상이한 뉴런들의 활성화 함수들은 동일하거나 또는 상이할 수 있다. 신경망은 멀티-레이어 구조를 일반적으로 포함하고, 각각의 레이어는 하나 이상의 뉴런을 포함할 수 있다. 신 경망의 깊이 및/또는 폭을 증가시키는 것은 신경망의 표현 능력을 개선할 수 있고, 복잡한 시스템들에 대한 더 강력한 정보 추출 및 추상화 모델링 능력들을 제공할 수 있다. 신경망의 깊이는 신경망에 포함되는 레이어들의 수량을 지칭할 수 있고, 각각의 레이어에 포함되는 뉴런들의 수량은 레이어의 폭이라고 지칭될 수 있다. 도 6 은 신경망의 레이어 관계의 도면이다. 구현에서, 신경망은 입력 레이어 및 출력 레이어를 포함한다. 수신된 입력에 관해 뉴런 처리를 수행한 후에, 신경망의 입력 레이어는 결과를 출력 레이어에 전달하고, 출력 레이어는 신경망의 출력 결과를 획득한다. 다른 구현에서, 신경망은 입력 레이어, 은닉 레이어, 및 출력 레이어를 포함 한다. 수신된 입력에 대해 뉴런 처리를 수행한 후에, 신경망의 입력 레이어는 결과를 중간 은닉 레이어에 전달 하고, 다음으로 은닉 레이어는 계산 결과를 출력 레이어 또는 인접한 은닉 레이어에 전달하고, 최종적으로, 출 력 레이어는 신경망의 출력 결과를 획득한다. 하나의 신경망은 하나의 은닉 레이어 또는 순차적으로 접속되는 복수의 은닉 레이어들을 포함할 수 있다. 이러한 것은 제한되지 않는다. 신경망의 트레이닝 프로세스에서, 손 실 함수가 정의될 수 있다. 손실 함수는 신경망의 출력 값과 신경망의 이상적인 타겟 값 사이의 갭 또는 차이 를 설명한다. 손실 함수의 구체적인 형태는 본 출원에서 제한되지 않는다. 신경망의 트레이닝 프로세스는, 신 경망의 그래디언트, 레이어들의 수량, 및 폭, 뉴런의 가중치, 뉴런의 활성화 함수에서의 파라미터 등과 같은, 신경망 파라미터를 조정하는 프로세스이어서, 손실 함수의 값은 임계값 미만이거나 또는 타겟 요건을 충족시킨 다. 하나의 해결책에서, RAN 노드는 복수의 AI-지원형 경우들을 지원한다. 예를 들어, 이동성 강화, 로드 밸런싱, 및 네트워크 에너지 절약. OAM은 AI 모델을 트레이닝 또는 저장하도록 구성된다. RAN 노드는 OAM으로부터 AI 모델을 요청하고 AI 모델을 사용하여 추론을 수행한다. OAM이 RAN 노드에 대한 대응하는 모델을 어떻게 구성하 는지는 본 출원에서 해결되어야 할 문제이다. 본 출원의 설명들에서, OAM은 AI 모델을 트레이닝 또는 저장할 수 있는 다른 노드, 예를 들어, 클라우드 서버, 코어 네트워크 디바이스, 또는 다른 가능한 디바이스로 대체될 수 있다. 도 7에 도시되는 바와 같이, 모델 구성 방법의 프로시저가 제공되며, 적어도 다음의 단계들을 포함한다. 단계 701: 제1 RAN 노드가 제1 모델 요청 메시지를 OAM에 전송하고, 이에 대응하여, OAM이 제1 RAN 노드로부터 제1 모델 요청 메시지를 수신함. 구별의 용이함을 위해, 제1 RAN 노드에 의해 OAM에 전송되는 모델 요청 메시지는 제1 모델 요청 메시지라고 지 칭된다. 제2 RAN 노드에 의해 OAM에 전송되는 모델 요청 메시지는 제2 모델 요청 메시지라고 지칭된다. 모델 요청 메시지는 OAM으로부터 모델을 요청하기 위해 RAN 노드에 의해 사용되고, 모델 요청 메시지의 명칭은 제한 되지 않는다. 예를 들어, 제1 모델 요청 메시지는 제1 메시지라고 또한 지칭될 수 있고, 제2 모델 요청 메시지 는 제2 메시지라고 또한 지칭될 수 있다. 상이한 RAN 노드들을 구별하기 위해, RAN 노드들은 제1 RAN 노드, 제 2 RAN 노드 등이라고 지칭된다. 제1 RAN 노드와 제2 RAN 노드는 상이한 RAN 노드들이다. 제1 RAN 노드와 제2 RAN 노드 사이의 관계는 제한되지 않는다. 설계에서, 제1 RAN 노드는 서비스 시나리오 및 기능 요건을 결정하고, 서비스 시나리오 및 기능 요건에 기초하 여 제1 모델 요청 메시지를 결정할 수 있다. 서비스 시나리오 및 기능 요건은 RAN 노드의 서비스 시나리오 및 기능 요건이다. 예를 들어, 제1 모델 요청 메시지를 사용하여 요청되는 제1 모델은 RAN 노드에 관련된 모델 추 론을 위한 것, 예를 들어, 셀 에너지 절약을 위한 것이다. 제1 RAN 노드는 RAN 노드의 서비스 시나리오 및 기 능 요건에 기초하여 제1 모델 요청 메시지 등을 결정할 수 있다. 대안적으로, 서비스 시나리오 및 기능 요건은 UE의 서비스 시나리오 및 기능 요건이다. 예를 들어, 제1 모델 요청 메시지를 사용하여 요청되는 제1 모델은UE와 관련된 모델 추론을 위한 것, 예를 들어, UE의 이동 궤적의 예측을 위한 것이다. 제1 RAN 노드는 서비스 시나리오 및 UE의 기능 요건에 기초하여 제1 모델 요청 메시지 등을 결정할 수 있다. 대안적으로, 제1 RAN 노 드는 RAN 노드 및 UE 이외의 노드의 기능 요건 및 서비스 시나리오에 기초하여 제1 모델 요청 메시지 등을 결정 할 수 있다. 이러한 것은 제한되지 않는다. 제1 RAN 노드는 UE에 의해 보고되는 정보에 기초하여 UE의 서비스 시나리오 및 기능 요건을 획득할 수 있다. 예를 들어, UE는 자율-주행 시나리오에 있고, 서비스의 품질 (quality of service, QoS) 예측 서비스 요청을 RAN 노드에 전송한다. RAN 노드는 자율-주행 및 QoS 예측으로 서 UE의 서비스 시나리오 및 기능 요건을 획득할 수 있다. 대안적으로, 제1 RAN 노드는 분석을 통해 UE의 서비 스 시나리오 및 기능 요건을 획득할 수 있다. 예를 들어, RAN 노드는 UE가 셀 에지로 이동하고 이동성 강화 서 비스를 필요로 한다는 점을 발견하고, 이동성 강화 서비스는 UE의 궤적 정보의 예측을 필요로 하여서, UE의 서 비스 시나리오 및 기능 요건은 UE의 궤적 정보의 이동성 강화 및 예측이다. 대안적으로, 제1 RAN 노드는 다른 디바이스로부터 UE의 서비스 시나리오 및 기능 요건을 획득할 수 있으며, 다른 디바이스는 드라이브 테스트들의 최소화(minimization of drive tests, MDT) 디바이스 등을 포함하지만 이에 제한되지 않는다. 대안적으로, 제 1 RAN 노드는 서비스 시나리오 및 UE의 기능 요건을 저장한다. 예를 들어, 제1 RAN 노드에 액세스할 때, UE는 UE의 서비스 시나리오 및 기능 요건을 제1 RAN 노드에 적극적으로 보고한다. 본 출원에서, 서비스 시나리오는 다음: 이동성 강화, 로드 밸런싱, 가상 현실(virtual reality, VR), 증강 현실 (augmented reality, AR), 차량-대-사물(vehicle-to-everything)(자율-주행), 무선 로봇 클라우드 제어, 힘 피 드백을 사용한 원격 진단, 고-해상도 비디오(예를 들어, 8K 비디오) 등 중 적어도 하나를 포함하지만, 이에 제 한되지 않는다. 예를 들어, 이동성 강화는 이동 UE에 대한 서빙 셀 핸드오버를 위한 강화된 서비스를 제공하는 것을 지칭한다. 예를 들어, RAN 노드는 UE의 이동 궤적, 측정 보고, 셀 부하 상태 등 중 적어도 하나에 기초하 여 UE의 타겟 셀, 핸드오버 시간 등을 예측한다. UE의 타겟 셀은 UE가 핸드오버될 서빙 셀을 지칭할 수 있다. UE의 이동 방식은 고정된 경로 상에서 이동하는 것, 비-고정된 경로 상에서 이동하는 것 등을 포함한다. 이동 성 강화는 고정된 경로 상의 차량 이동에 대한 이동성 강화, 비-고정된 경로 상의 차량 이동에 대한 이동성 강 화, 보행자 시나리오에 대한 이동성 강화 등을 포함할 수 있다. 원격 진찰이라고 또한 지칭되는, 원격 진단에 서, 의사는, 네트워크를 통해, 다른 장소에 있는 환자에 대해 진단 또는 수술을 수행한다. 전술한 힘 피드백은 힘의 햅틱 피드백이고, 레이턴시에 대한 매우 높은 요건을 갖는 서비스이고, 레이턴시 예측 서비스가 제공될 필 요가 있다. 예를 들어, 예측된 레이턴시가 임계값을 초과할 때, 응급상황에 미리 응답하기 위해, 정보 송신 해 결책이 조정될 필요가 있거나 또는 경보가 제공될 필요가 있다. 본 출원에서, 기능 요건은 다음: UE 궤적 예측, 부하 예측, 신호 대 간섭 플러스 노이즈 비율(signal to interference plus noise ratio, SINR) 예측, 참조 신호 수신 전력(reference signal received power, RSRP) 예측, 참조 신호 수신 품질(reference signal received quality, RSRQ) 예측, 레이턴시 예측, QoS 예측, 처리 량 예측, 셀 에너지 절약 등 중 적어도 하나를 포함하지만 이에 제한되지는 않는다. 설계에서, 제1 RAN 노드가 서비스 시나리오 및 기능 요건에 기초하여 제1 모델 요청 메시지를 결정한 후에, 제1 모델 요청 메시지는 서비스 시나리오 및 기능 요건을 표시하고, 다시 말해서, 제1 모델 요청 메시지는 요청된 제1 모델의 모델 애플리케이션 시나리오, 모델 기능 등을 표시한다. 모델 애플리케이션 시나리오는 전술한 서 비스 시나리오에 대응하고, 모델 기능은 전술한 기능 요건에 대응한다. 본 출원에서의 표시는 암시적 표시, 명 시적 표시 등을 포함할 수 있다. 이러한 것은 제한되지 않는다. 예를 들어, 제1 모델 요청 메시지는 서비스 시나리오, 기능 요건 등을 포함할 수 있다. 대안적으로, 제1 RAN 노드는 서비스 시나리오 및 기능 요건을 OAM 등에 직접 전송할 수 있다. 예를 들어, 제1 RAN 노드에 의해 OAM에 전송되는 서비스 시나리오와 기능 요건의 조합은, 이동성 강화 시나리오 및 궤적 예측, 로드 밸런싱 및 궤적 예측, 자율-주행 및 QoS 예측, VR/AR 및 QoS 예측, 무선 로봇 클라우드 제어 및 레이턴시 예측, 힘 피드백 및 레이턴시 예측을 사용한 원격 진단 등을 포함 할 수 있다. 다른 설계에서, 서비스 시나리오 및 기능 요건에 기초하여 제1 RAN 노드에 의해 제1 모델 요청 메시지를 결정하 는 프로세스는 다음을 포함한다: 제1 RAN 노드는 서비스 시나리오 및 기능 요건에 기초하여 요청된 제1 모델의 모델 기능 및 모델 성능 지표를 결정한다. 모델 기능은 전술한 기능 요건에 대응한다. 모델 성능 지표는 다음: 정확도, 계산량, 메모리 점유, 추론 지속기간 등 중 적어도 하나를 포함한다. 정확도는 샘플들의 총 수 량에 대해 정확하게 예측되는 샘플들의 수량의 백분율이다. 계산량은 모델에 필요한 계산 시간들의 수량이다. 모델의 전체 계산량은, 모델에서의 연산자들의 계산량의 합과 동일하고, 계산량은 하드웨어 계산 유닛에 모델의 요건을 피드백한다. 대안적으로, 계산량은 모델이 실행될 때 점유되는 컴퓨팅 리소스의 크기일 수 있다. 메모 리 점유는 모델이 실행 중일 때 점유되는 메모리 및 비디오 RAM의 크기들을 지칭하거나, 또는 메모리 점유는 모델의 크기 등이라고 지칭될 수 있다. 추론 지속기간은 예측 결과를 추론하기 위해 모델에 의해 필요로 되는 지 속기간을 지칭한다. 제1 RAN 노드에 의해 OAM에 전송되는 제1 모델 요청 메시지는 제1 모델의 모델 기능 및 모 델 성능 지표를 표시한다. 예를 들어, 제1 모델 요청 메시지는 모델 기능 및 모델 성능 지표를 포함한다. 대 안적으로, 제1 RAN 노드는 모델 기능 및 모델 성능 지표를 OAM에 직접 전송할 수 있다. 모델 기능은 모델 카테 고리라고 또한 지칭될 수 있다. 예를 들어, 제1 RAN 노드는 분석을 통해, 자율-주행 시나리오에서의 QoS 예측 서비스가 UE에 대해 제공될 필요가 있다는 점을 학습하고, 제1 RAN 노드는 자율-주행 시나리오에서 QoS 예측 서 비스에 필요한 성능 지표를 계속 분석할 수 있고, 제1 RAN 노드는 QoS 예측 서비스 및 대응하는 성능 지표를 OAM에 전송한다. 대안적으로, 제1 RAN 노드는 모델 성능 지표에 기초하여 모델 성능 레벨을 결정한다. 모델 성능 레벨과 모델 성능 지표 사이에 대응관계가 존재한다. 상세사항들에 대해서는 다음 설명들을 참조한다. 제1 RAN 노드에 의해 OAM에 전송되는 제1 모델 요청 메시지는 요청된 제1 모델의 모델 기능 및 모델 성능 레벨 을 표시한다. 선택적으로, 단계 701 전에, 이러한 방법은 다음을 추가로 포함할 수 있다: 제1 RAN 노드가 AI-기반 강화된 서 비스가 제공될 필요가 있는지를 결정한다. AI-기반 강화된 서비스가 제공될 필요가 있으면, 단계 701이 수행되 어 제1 모델 요청 메시지를 OAM에 전송한다. AI-기반 강화된 서비스가 제공될 필요가 없으면, 도 7에 도시되는 프로시저는 수행되지 않는다. 예를 들어, AI-기반 이동성 강화 해결책에서, 소스 RAN 노드는 UE의 타겟 셀을 AI 방식으로 예측할 수 있다. 그러나, UE가 셀 에지에 위치되지 않을 때, 소스 RAN 노드는 UE의 타겟 셀을 예 측할 필요가 없다. 다시 말해서, UE가 셀 에지에 있을 때에만, 소스 RAN 노드는 타겟 셀을 예측하기 위한 모델 을 요청하기 위해 제1 모델 요청 메시지를 OAM에 전송할 필요가 있다. 대안적으로, 소스 RAN 노드가 UE의 타겟 셀을 AI 방식으로 예측할 때, 모델의 입력은 UE의 궤적 정보를 포함한다. 그러나, UE의 궤적이 매우 랜덤할 때, AI 방식으로 예측되는 타겟 셀의 정확도가 크게 감소될 수 있다. 이러한 경우, 소스 RAN 노드는 UE의 타겟 셀을 예측하기 위해 AI 방식을 사용하지 않는 것을 고려할 수 있다. 이러한 경우, 소스 RAN 노드는 더 이상 제 1 모델 요청 메시지를 OAM에 전송하지 않지만, 종래의 방식으로 UE의 타겟 셀을 예측한다. 단계 702: OAM이 제1 모델 요청 메시지 및 제1 맵핑 관계에 기초하여 제1 모델을 결정함. 본 출원에서, 상이한 모델들을 구별하기 위해, 상이한 모델들은 각각 제1 모델, 제2 모델 등이라고 지칭된다. 모델은 모델의 입력과 출력 사이의 맵핑 관계를 표현하고, 구체적인 기능을 구현하기 위한 것이다. 모델의 명 칭은 제한되지 않는다. 예를 들어, 모델은 AI 모델이라고 또한 지칭될 수 있다. AI 모델은 신경망, 선형 회귀 모델, 결정 트리 모델, SVM, Bayesian 네트워크, Q-학습 모델, 또는 다른 머신 학습 모델일 수 있다. 제1 맵핑 관계는 맵핑, 대응관계 등을 표현한다. 제1 맵핑 관계는 대응관계 등이라고 또한 지칭될 수 있다. 유사한 경 우들이 후속하여 하나씩 설명되지는 않는다. 본 출원에서, OAM은 제1 맵핑 관계를 획득할 수 있다. 제1 맵핑 관계는 OAM 또는 다른 노드에 의해 수립될 수 있다. OAM은 다른 노드를 통해 제1 맵핑 관계를 획득한다. 예에서, 제1 맵핑 관계는 모델, 모델 성능 레벨, 및 모델 기능 사이의 맵핑 관계를 포함하고, 모델 성능 레벨은 줄여서 성능 레벨이라고 지칭될 수 있다. 예를 들어, 모델 성능 레벨과 모델 성능 지표 사이에 일-대-다 대응관계가 있다. 예를 들어, 모델 레벨 분류에 대한 모델 성능 지표는 정확도를 포함하고, 레벨들은 정확도에 기초하여 분류될 수 있다. 더 높은 정확도는 더 높은 모델 성능 레벨을 표시한다. 대안적으로, 모델 레벨 분류에 대한 모델 성능 지표는 추론 지속기간을 포함 하고, 레벨들은 추론 지속기간에 기초하여 분류될 수 있다. 더 짧은 추론 지속기간은 더 높은 모델 성능 레벨 을 표시한다. 대안적으로, 모델 레벨 분할에 대한 모델 성능 지표는 정확도, 계산량, 추론 지속기간, 및 메모 리 점유 중 적어도 2개의 지표들을 포함한다. 예를 들어, 복수의 지표들을 가중된 값을 결정하기 위해 구체적 인 가중 방식으로 가중되고, 레벨들은 가중된 값에 기초하여 분류된다. 상이한 기능들을 갖는 모델들에 대해, 모델 성능 레벨 분류를 위한 방식들은 동일하거나 또는 상이하다. 예를 들어, 모델 성능 레벨들은 궤적 예측을 위한 모델 및 SINR 예측을 위한 모델에 대한 모델 정확도에 기초하여 분류된다. 궤적 예측을 위한 모델 및 SINR 예측을 위한 모델 양자 모두가 3개의 모델 성능 레벨들을 포함한다고 가정된다. 표 1에서 보여지는 바와 같이, 궤적 예측을 위한 모델에 대해, 모델 성능 레벨 1에 대응하는 정확도는 [n1, n2]이고, 모델 성능 레벨 2 에 대응하는 정확도는 (n2, n3]이고, 모델 성능 레벨 3에 대응하는 정확도는 (n3, n4]이며, 여기서 n4는 n3 이 상이고, n3은 n2 이상이고, n2는 n1 이상이다. 표 2에 도시되는 바와 같이, SINR 예측을 위한 모델에 대해, 모 델 성능 레벨 1에 대응하는 정확도는 [m1, m2]이고, 모델 성능 레벨 2에 대응하는 정확도는 (m2, m3]이며, 여기 서 m3은 m2 이상이고, m2는 m1 이상이다. 다른 예를 들어, 표 3에서 보여지는 바와 같이, SINR 예측을 위한 모델에 대해, 모델 성능 레벨 1에 대응하는 추론 지속기간은 [t1, t2]이고, 모델 성능 레벨 2에 대응하는 추론 지 속기간은 (t2, t3]이고, 모델 성능 레벨 3에 대응하는 추론 지속기간은 (t3, t4]이며, 여기서 t4는 t3 이상이고, t3은 t2 이상이고, t2는 t1 이상이다. 표 1"}
{"patent_id": "10-2024-7026840", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "표 2"}
{"patent_id": "10-2024-7026840", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "표 3"}
{"patent_id": "10-2024-7026840", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "이러한 설계에서, 제1 RAN 노드는 모델 애플리케이션 시나리오를 획득하고, 모델 애플리케이션 시나리오에 기초 하여 대응하는 모델 성능 지표를 결정하고, 모델 성능 지표에 기초하여 모델 성능 레벨을 결정할 수 있다. OAM 에 전송되는 제1 모델 요청 메시지는 모델 성능 레벨 및 모델 기능을 표시한다. OAM은 제1 모델 요청 메시지에 의해 표시되는 모델 성능 레벨 및 모델 기능에 기초하여 제1 맵핑 관계로부터 제1 모델이라고 지칭되는 모델을결정한다. 제1 맵핑 관계는 모델, 모델 성능 레벨, 및 모델 기능 사이의 맵핑 관계를 포함한다. 표 6에서의 다음의 설명들이 참조될 수 있다. 예에서, 제1 맵핑 관계는 모델, 모델 애플리케이션 시나리오, 및 모델 기능 사이의 맵핑 관계를 포함한다. 예 를 들어, 제1 맵핑 관계는 AI 모델, 자율-주행 시나리오, 및 QoS 예측을 포함한다. 예를 들어, 제1 RAN 노드는 모델 애플리케이션 시나리오 및 제1 모델의 모델 기능을 획득할 수 있다. 단계 701 에서의 설명들이 참조될 수 있다. 제1 RAN 노드에 의해 OAM에 전송되는 제1 모델 요청 메시지는 모델 애플리케 이션 시나리오 및 제1 모델의 모델 기능을 표시한다. OAM은 제1 모델 요청 메시지에 의해 표시되는 애플리케이 션 시나리오 및 모델 기능에 기초하여 제1 맵핑 관계로부터 AI 모델을 결정할 수 있다. AI 모델은 제1 모델이 라고 지칭된다. 예를 들어, 표 4에서 보여지는 바와 같이, 제1 맵핑 관계는 4개의 애플리케이션 시나리오들(인 덱스들 1 내지 4를 가짐) 및 3개의 모델 기능들(인덱스들 1 내지 3을 가짐)을 포함한다. 4개의 애플리케이션 시나리오들 및 3개의 모델 기능들은 12개의 맵핑 관계들을 형성할 수 있고, 12개의 맵핑 관계들의 인덱스들은 1 내지 12이다. 예를 들어, 맵핑 관계 1은 애플리케이션 시나리오 1, 모델 기능 1, 및 모델 1을 포함하고, 맵핑 관계 2는 애플리케이션 시나리오 1, 모델 기능 2, 및 모델 2를 포함한다. 표 4"}
{"patent_id": "10-2024-7026840", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "표 4에서 보여지는 제1 맵핑 관계에서, 동일한 모델 기능에 대해, 대응하는 모델들은 상이한 시나리오들에서 상 이하다. 예를 들어, 모델 기능 1은 애플리케이션 시나리오들 1 내지 4에서 각각 모델 1, 모델 4, 모델 7, 및 모델 10에 대응한다. OAM이 표 4에서 보여지는 제1 맵핑 관계를 수립하는 것이 예로서 사용된다. 동일한 모델 기능에 대해, OAM은 상이한 시나리오들에서 대응하는 트레이닝 데이터를 별도로 수집하고 대응하는 AI 모델들을 트레이닝시킬 수 있다. 예를 들어, OAM은, 애플리케이션 시나리오 1에서, 모델 기능 1에 대응하는 트레이닝 데 이터를 수집하고, 트레이닝 데이터를 사용하여 모델 1을 트레이닝시킬 수 있어서, 모델 1은 애플리케이션 시나 리오 1의 성능 지표를 충족시킬 수 있다. 트레이닝 프로세스는 머신 학습, 비-머신 학습, 강화 학습 등일 수 있다. 이러한 것은 제한되지 않는다. 대안적으로, 이러한 예에서, 모델 성능 레벨과 모델 성능 지표 사이에 일-대-일 대응관계가 있고, 각각의 모델 성능 레벨은 고유 모델 성능 지표에 대응하고, 각각의 모델 성능 지표는 고유 모델 성능 레벨에 대응한다. 예 를 들어, 표 5에서 보여지는 바와 같이, 모델 성능 레벨들 1 내지 3은 모델 성능 지표들 1 내지 3에 각각 대응 한다. 모델 성능 지표가 정확도, 계산량, 추론 지속기간, 및 메모리 점유를 포함하는 것이 예로서 사용된다. 모델 성능 레벨 1은 모델 성능 지표 1에 대응하며, 이에 대응하여, 정확도는 적어도 99%이고, 계산량은 최대 3% 이고, 추론 지속기간은 최대 1초이고, 메모리 점유는 최대 500 KB이다.표 5"}
{"patent_id": "10-2024-7026840", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "이러한 예에서, 제1 RAN 노드는 요청된 모델의 모델 성능 지표를 획득할 수 있고, OAM에 전송되는 제1 모델 요 청 메시지는 모델 기능 및 요청된 모델의 모델 성능 지표를 표시한다. 제1 모델 요청 메시지를 수신할 때, OAM 은 제1 모델 요청 메시지에 의해 표시되는 모델 성능 지표에 기초하여 모델 성능 레벨을 결정할 수 있다. 대안 적으로, 제1 RAN 노드는 모델 성능 지표에 기초하여 모델 성능 레벨을 결정할 수 있고, OAM에 전송되는 제1 모 델 요청 메시지는 모델 기능 및 모델 성능 레벨을 표시한다. OAM은 모델 기능 및 모델 성능 레벨에 기초하여 제1 맵핑 관계로부터 모델을 결정하고, 이러한 모델은 제1 모델 등이라고 지칭된다. 예를 들어, 표 6에서 보여 지는 바와 같이, 제1 맵핑 관계는 인덱스들 1 내지 12를 갖는 12개의 맵핑 관계들을 포함한다. 예를 들어, 맵 핑 관계 1은 모델 1, 모델 성능 레벨 1, 및 모델 기능 1을 포함하고, 맵핑 관계 2는 모델 2, 모델 성능 레벨 1, 및 모델 기능 2를 포함한다. 표 6"}
{"patent_id": "10-2024-7026840", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 7, "content": "모델 성능 레벨과 모델 성능 지표 사이에 일-대-일 대응관계가 있는 전술한 예에서, 전술한 제1 맵핑 관계에서 의 모델 성능 레벨이 모델 성능 지표로 대체될 수 있다는 점이 주목되어야 한다. 대안적으로, 본 출원에서, 제 1 맵핑 관계는 모델 성능 지표에 기초하여 수립될 수 있다. 예를 들어, 제1 맵핑 관계는 모델, 모델 성능 지표, 및 모델 기능 사이의 맵핑 관계를 포함한다. 이러한 설계에서, 제1 모델 요청 메시지는 모델 기능 및 제 1 모델의 모델 성능 지표를 표시한다. OAM은 제1 모델 요청 메시지에 의해 표시되는 모델 기능 및 모델 성능 지표에 기초하여 제1 맵핑 관계로부터 모델을 결정한다. 모델은 제1 모델이라고 지칭될 수 있다. 예를 들어, 표 7에서 보여지는 바와 같이, 제1 맵핑 관계는 인덱스들 1 내지 12를 갖는 12개의 맵핑 관계들을 포함한다. 예를 들어, 맵핑 관계 1은 모델 1, 모델 성능 지표 1, 및 모델 기능 1을 포함하고, 맵핑 관계 2는 모델 2, 모델 성능 지표 1, 및 모델 기능 2를 포함한다.표 7"}
{"patent_id": "10-2024-7026840", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 8, "content": "표 6 또는 표 7에서 보여지는 제1 맵핑 관계에서, 동일한 모델 기능에 대응하는 모델들은 상이한 모델 성능 레 벨들 또는 모델 성능 지표들 하에서 상이하다. 예를 들어, 표 6 또는 표 7을 참조한다. 모델 기능 1에 대해, 모델 성능 레벨들 1 내지 4 또는 모델 성능 지표들 1 내지 4에 대응하는 모델들은, 각각, 모델 1, 모델 4, 모델 7, 및 모델 10이다. OAM이 표 6 또는 표 7에서 보여지는 제1 맵핑 관계를 수립하는 것이 예로서 사용된다. OAM은 상이한 모델 성능 레벨들 또는 모델 성능 지표들 하에서 대응하는 트레이닝 데이터를 별도로 수집하고, 대응하는 모델들을 트레이닝시킬 수 있다. 예를 들어, OAM은 모델 성능 레벨 1 또는 모델 성능 지표 1 하에서 모델 기능 1에 대응하는 트레이닝 데이터를 수집하고, 모델 1을 트레이닝시킬 수 있다. 위에 설명되는 바와 같이, 모델 성능 지표는 다음: 정확도, 계산량, 메모리 점유, 추론 지속기간 등 중 적어도 하나를 포함한다. 상이한 시나리오들에서, 동일한 모델 기능은 모델 성능 지표들에 대해 상이한 요건들을 가질 수 있다. 선택적으로, 모델 성능 지표에서의 계산량은 컴퓨팅 리소스 점유라고 또한 지칭되고, 메모리 점유는 모델 크기라고 또한 지칭된다. 가능한 경우에, 표 8에 도시되는 바와 같이, VR/AR 시나리오 및 V2X 시나리오에 서, QoS 예측에서의 모델의 성능 지표들에 대한 요건들은 상이하다. 다른 가능한 경우에, 표 9에서 보여지는 바와 같이, 고정된 경로 상의 차량, 비-고정된 경로 상의 차량, 및 보행자 시나리오와 같은 시나리오들에서, 궤 적 예측에서의 모델의 성능 지표들에 대한 요건들은 상이하다. 표 8 표 9"}
{"patent_id": "10-2024-7026840", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 9, "content": "상이한 시나리오들에서, 동일한 기능의 모델의 성능 지표들에 대한 요건들이 상이할 수 있다. 동일한 모델이 임의의 시나리오에서 기능에 대한 추론을 위한 것이면, 대응하는 시나리오의 성능 지표에 대한 요건을 충족시키 는 것은 어렵다. 예를 들어, 표 8에서, AR/VR 시나리오 및 V2X 시나리오에 대해, QoS 예측에서의 동일한 모델 이 모델 추론을 위한 것이면, 각각의 시나리오의 성능 지표에 대한 요건을 충족시키는 것은 어렵다. 본 출원의 해결책에서는, 위의 표 4에서 보여지는 제1 맵핑 관계가 참조될 수 있다. 동일한 모델 기능에 대해, 상이한 모 델들이 상이한 시나리오들에서 구성될 수 있다. 예를 들어, VR/AR 시나리오에서, 모델은 QoS 예측을 위해 구성 된다. V2X 시나리오에서, 다른 모델이 QoS 예측을 위해 구성된다. 대안적으로, 위의 표 6에서 보여지는 맵핑 관계가 참조될 수 있다. 대응하는 성능 레벨들을 갖는 모델들은 상이한 시나리오들에서 성능 지표들에 대한 요 건들에 대해 구성될 수 있다. 대안적으로, 위의 표 7에서 보여지는 맵핑 관계가 참조될 수 있고, 상이한 모델 들이 상이한 성능 지표들에 대해 구성될 수 있어서, 각각의 모델은 대응하는 애플리케이션 시나리오의 성능 지 표에 대한 요건을 충족시킨다. 단계 703: OAM이 제1 모델에 관한 정보를 제1 RAN 노드에 전송함. 본 출원에서, 제1 모델에 관한 정보는 제1 모델의 다음: 모델 인덱스(index), 모델 구조 정보, 모델 파라미터, 모델 입력 포맷, 모델 출력 포맷, 입력 데이터 처리 방식, 출력 데이터 처리 방식, 모델 성능 지표, 모델 애플 리케이션 시나리오, 모델 기능, 트레이닝 파라미터 등 중 적어도 하나를 표시한다. 모델 인덱스는 상이한 모델들을 구별하기 위한 것이다. 모델 구조 정보, 모델 파라미터, 모델 입력 포맷, 모델 출력 포맷 등은 제1 모델을 결정하기 위해 제1 RAN 노드에 의해 사용된다. 다시 말해서, 제1 RAN 노드는 모델 구조 정보, 모델 파라미터, 모델 입력 포맷, 모델 출력 포맷 등에 기초하여 제1 모델을 결정한다. 모델 구조 정보는 다음: 모델에 포함되는 레이어들의 수량(모델의 깊이라고 또한 지칭됨), 각각의 레이어의 네트워크 타입 (예를 들어, 완전 접속 레이어 네트워크, 컨볼루션 레이어 네트워크, 또는 긴 단기 메모리(long short-term memory, LSTM) 레이어), 각각의 레이어에 포함되는 뉴런들의 수량(모델의 폭이라고 또한 지칭됨), 레이어들 사 이의 접속 관계 등 중 적어도 하나를 포함한다. 모델 파라미터는 다음: 뉴런의 가중치, 뉴런의 활성화 함수, 활성화 함수의 오프셋 등 중 적어도 하나를 포함할 수 있다. 모델 입력 포맷 및 출력 포맷은 모델에 대해 모델 트레이닝 또는 추론이 수행될 때 입력 데이터 및 출력 데이터에 의해 충족될 필요가 있는 포맷들일 수 있다. 전술한 입력 데이터 처리 방식은 수집된 원시 데이터가 모델에 입력되기 전에 원시 데이터를 전처리하는 방식을 포함한다. 예를 들어, 허수 부분이 원시 데이터의 실수 부분으로부터 분리되거나, 또는 원시 데이터에 대한 정 규화 처리가 수행되거나, 또는 원시 데이터의 위상 및 진폭이 분리된다. 전술한 출력 데이터 처리 방식은 모델 이 데이터를 출력할 때 출력 데이터를 처리하는, 예를 들어, 출력 데이터를 인터셉트하는 방식을 포함한다. 모 델 성능 지표, 모델 애플리케이션 시나리오, 및 모델 기능에 대해서는, 전술한 설명들을 참조한다. 본 출원에 서, 모델 구조, 모델 파라미터, 모델 입력 포맷, 및 모델 출력 포맷과 같은 정보에 기초하여 제1 모델을 결정할 때, 제1 RAN 노드는 전술한 트레이닝 파라미터에 기초하여 제1 모델을 추가로 계속 트레이닝시킬 수 있다. 트 레이닝 파라미터는 손실 함수의 표시 정보 등을 포함할 수 있다. 예를 들어, 제1 RAN 노드는 트레이닝 데이터 를 획득할 수 있다. 트레이닝 데이터는 제1 RAN 노드로부터, 또는 UE로부터, 또는 제1 RAN 노드와 UE 양자 모 두로부터, 또는 다른 노드로부터 온 것일 수 있다. 제1 RAN 노드는 트레이닝 데이터에 기초하여 제1 모델을 트 레이닝시킨다. 예를 들어, 트레이닝 데이터는 제1 모델에 입력된다. 손실 함수의 값은 제1 모델의 출력에 기초하여 결정된다. 손실 함수의 값이 임계값 미만이거나 또는 타겟 요건을 충족시키면, 제1 모델에 대한 트레이 닝이 종료된다. 손실 함수의 값이 임계값 이상이거나 또는 타겟 요건을 충족시키지 않으면, 제1 모델의 파라미 터가 업데이트되고, 제1 모델에 대한 트레이닝이 계속된다. 제1 모델의 파라미터가 업데이트되는 것은 제1 모 델의 다음의 정보: 신경망의 레이어들의 수량, 신경망의 폭, 레이어들 사이의 접속 관계, 뉴런의 가중치, 뉴런 의 활성화 함수, 활성화 함수에서의 오프셋 등 중 적어도 하나를 업데이트하는 것을 포함할 수 있다. 트레이닝 프로세스는 레이블 학습, 비-레이블 학습, 강화 학습 등일 수 있다. 이러한 것은 제한되지 않는다. 제1 모델 이 트레이닝될 때, 제1 모델의 초기 모델은 제1 모델에 관한 정보에 의해 표시될 수 있거나, 또는 랜덤하게 생 성될 수 있거나, 또는 프로토콜에서 합의될 수 있다. 이러한 것은 제한되지 않는다. 대안적으로, 제1 모델에 관한 정보는 제1 모델의 다음: 모델, 모델 사용 설명, 또는 모델 인덱스 중 적어도 하 나를 표시한다. 모델은 네트워크 아키텍처, 파라미터 가중치, 트레이닝 하이퍼파라미터, 최적화기(optimizer), 배치 크기(batch size), 학습 레이트(learning rate), 모멘텀(momentum) 등을 포함한다. 선택적으로, 제1 RAN 노드는 트레이닝 하이퍼파라미터에 기초하여 온라인 트레이닝 등을 수행할 수 있다. 모델 사용 설명은 모델 입 력/출력 포맷, 모델 성능 지표, 모델 애플리케이션 시나리오, 및 모델 기능 중 적어도 하나를 포함한다. 모델 인덱스는 상이한 모델들을 구별하기 위해 사용되는 모델의 수 등이다. 실제 애플리케이션 동안, 동일한 기능을 구현하는 모델들의 성능 지표들에 대한 요건들은 상이한 애플리케이션 시나리오들에서 상이하다. 예를 들어, 위의 표 8 또는 표 9에서 보여지는 바와 같이, QoS 예측 및 궤적 예측에 대해, 모델들의 성능 지표들에 대한 요건들은 상이한 시나리오들에서 상이하다. 본 출원에서, OAM은 제1 맵핑 관계를 수립하며, 제1 맵핑 관계는 모델, 모델 애플리케이션 시나리오, 및 모델 기능 사이의 맵핑 관계이다. 맵핑 관계에 기초하여, 동일한 모델 기능에 대해, 상이한 애플리케이션 시나리오들에서, 시나리오에 대응하는 모델이 구성될 수 있어서, 모델은 모델에 대응하는 시나리오에서 성능 지표에 대한 요건을 충족시킨다. 동일한 모델이 임의의 시나리오에서 모델 추론을 위한 것인 경우와 비교하여, 본 출원의 해결책들은 예측 성능, 예측 속도 등을 개선할 수 있다. 대안적으로, 본 출원에서, OAM은 제1 맵핑 관계를 수립하며, 제1 맵핑 관계는 모델, 모델 성능 레벨, 및 모델 기능 사이의 맵핑 관계이거나, 또는 제1 맵핑 관계는 모델, 모델 성능 지표, 및 모델 기능 사이의 맵핑 관계이다. 모델들의 성능 지표들에 대한 요건들이 상이한 애플리케이션 시나리오들에서 상이하고, 모델 성능 지표와 모델 성능 레벨 사이의 대응관계가 있기 때문에, OAM은 제1 맵핑 관계에 기초하여 상이한 애플리케이션 시나리오들에서 모델 성능 지표들에 대한 상이한 요건들에 대해 상이한 모델들을 구성할 수 있다. 동일한 모델이 임의의 시나리오에서 모델 성능 지표 하에서의 모델 추론을 위한 것인 경우와 비교하 여, 본 출원의 해결책들은 예측 성능, 예측 속도 등을 개선할 수 있다. 선택적으로, 단계 701 내지 단계 703 외에도, 도 7에 도시되는 프로시저는 다음의 단계들을 추가로 포함할 수 있다. 단계 704: 제1 RAN 노드가 예측 정보를 획득하기 위해 제1 모델에 기초하여 모델 추론을 수행함. 예를 들어, 제1 RAN 노드는 입력 데이터를 수집하고, 모델 추론을 위해 컴퓨팅 리소스, 메모리 리소스 등을 할 당할 수 있다. 입력 데이터는 제1 RAN 노드 및/또는 UE로부터, 또는 다른 노드 등으로부터 올 수 있다. 이러 한 것은 제한되지 않는다. 선택적으로, 제1 RAN 노드는 모델 사용 설명에 기초하여 입력 데이터를 수집할 수 있다. 입력 데이터는 제1 모델에 입력되고, 예측 정보로서 출력된다. 대안적으로, 입력 데이터가 처리되고, 처리된 입력 데이터가 제1 모델에 입력되고; 및/또는 제1 모델의 출력 데이터가 처리되고, 처리된 출력 데이터 는 예측 정보이다. 입력 데이터 및 출력 데이터는 제1 모델의 입력 포맷 및 출력 포맷에 대한 요건들을 충족시 킨다는 점이 이해될 수 있다. 예측 정보는 예측 결과를 포함한다. 예를 들어, OAM과 같은 모델 트레이닝 노드 가 모델을 트레이닝시킬 때, 모델 트레이닝 노드는 수집된 데이터 세트를 트레이닝 세트, 검증 세트, 및 테스트 세트로 분류한다. 모델 트레이닝 노드는 모델을 획득하기 위해 트레이닝 세트를 사용하여 모델 트레이닝을 수 행하고, 이러한 프로세스는 모델 트레이닝이라고 지칭될 수 있다. 모델은 검증 세트를 사용하여 검증되고, 이 러한 프로세스는 모델 검증이라고 지칭될 수 있다. 모델 검증은 모델 트레이닝 동안 일반적으로 수행된다. 예 를 들어, 모델이 하나 이상의 에포크(epochs)에 대해 트레이닝될 때마다, 검증 세트는, 현재 모델을 검증하고, 모델 트레이닝 상태를 모니터하고, 예를 들어, 현재 모델이 부적합한지, 과적합한지, 또는 수렴되었는지를 검증 하고, 트레이닝을 종료할지를 결정하기 위해 사용될 수 있다. 선택적으로, 모델 검증 프로세스에서, 모델의 하 이퍼파라미터가 추가로 조정될 수 있다. 하이퍼파라미터는 모델의 다음 파라미터들: 신경망의 레이어들의 수량, 뉴런들의 수량, 활성화 함수, 손실 함수 등 중 적어도 하나를 지칭할 수 있다. 모델은 테스트 세트를 사 용하여 테스트되고, 이러한 프로세스는 모델 테스트라고 지칭될 수 있다. 예를 들어, 모델 트레이닝이 완료된 후에, 테스트 세트는 트레이닝된 모델을 테스트하기 위한 것이다. 예를 들어, 모델의 일반화 능력이 평가되거나, 또는 모델이 요건을 충족시키는지가 결정되거나, 또는 모델이 이용가능한지가 결정되거나, 또는 모델의 예 측 정확도가 획득된다. 본 출원에서, 제1 모델에 관한 것인 그리고 OAM에 의해 제1 RAN 노드에 전송되는 정보 는 예측 정확도 등을 추가로 포함할 수 있다. 대안적으로, 제1 모델을 결정할 때, 제1 RAN 노드는, 예측 정확 도 등을 획득하기 위해, 로컬로 수집된 테스트 데이터를 사용하여 제1 모델을 테스트할 수 있다. 제1 모델에 의해 추론되는 예측 결과 외에도, 선택적으로, 제1 RAN 노드에 의해 UE에 전송되는 예측 정보는 예측 정확도를 추가로 포함할 수 있다. 예를 들어, 궤적 예측에서, 제1 RAN 노드에 의해 UE에 전송되는 예측 정보는 UE의 예 측된 궤적 정보 및 예측된 궤적 정보의 정확도(예를 들어, 98%)를 포함한다. 본 출원에서, 예측 정보가 제1 RAN 노드에 관련된 예측 정보이면, 제1 RAN 노드는 예측 정보에 기초하여 제1 피 드백 정보를 결정한다. 예를 들어, 제1 RAN은 예측 정보에 기초하여 대응하는 액션을 수행한다. 예를 들어, 네트워크 에너지 절약 시나리오에서, 예측 정보는 에너지 절약 정책, 예를 들어, 캐리어 셧다운, 심볼 셧다운, 셀 셧다운, 또는 딥 슬립이다. 제1 RAN 노드가 제1 모델을 사용하여 에너지 절약 정책을 추론한 후에, 제1 RAN 노드는 에너지 절약 정책을 실행할 수 있다. 제1 RAN 노드는 예측 정보가 실행되기 전과 후에 성능 사이의 변 경(예를 들어, UE의 셀 처리량들 또는 QoS 사이의 변경)에 기초하여 제1 피드백 정보를 결정한다. 대안적으로, 예측 정보는 UE에 관련된 예측 정보이고, 제1 RAN 노드는 예측 정보를 UE에 전송할 필요가 있다. UE는 예측 정 보에 기초하여 제2 피드백 정보를 결정한다. 예를 들어, UE는 예측 정보가 실행된 후인 성능 변경에 기초하여 제2 피드백 정보를 결정할 수 있다. 예를 들어, 이동성 강화 시나리오에서, 예측 정보는 UE가 핸드오버될 타겟 셀, 핸드오버 시간 등이다. UE는 예측 정보에 기초하여 대응하는 액션을 수행하고, 예측 정보가 실행된 후인 성능 변경에 기초하여 제2 피드백 정보를 결정할 수 있다. 대안적으로, UE는, 제2 피드백 정보를 결정하기 위 해, 예측 정보를 실제 정보와 비교한다. 예를 들어, 궤적 예측 시나리오에서, UE는, 제2 피드백 정보를 결정하 기 위해, UE의 예측된 이동 궤적을 UE의 실제 이동 궤적과 비교할 수 있다. UE는 제2 피드백 정보를 제1 RAN 노드에 전송한다. 제1 RAN 노드는 수신된 제2 피드백 정보에 기초하여 제1 피드백 정보를 OAM에 전송하고, OAM 은 제1 피드백 정보에 기초하여 제1 모델을 업데이트하는 등이다. 상세사항들에 대해서는, 다음의 단계 705 및 단계 706에서의 제1 설계의 설명들을 참조한다. 대안적으로, 애플리케이션 시나리오가 변경되거나 또는 요구된 모델의 성능 레벨(또는 성능 지표)이 변경된다고 결정할 때, 제1 RAN 노드는 대안적으로, OAM에, 시나리오가 변 경되거나 또는 성능 레벨이 변경된다는 점을 표시하는 제1 피드백 정보를 전송할 수 있다. OAM은 시나리오 변 경 표시 또는 성능 레벨 변경 표시에 기초하여 제1 RAN 노드에 대한 모델을 재구성할 수 있다. 이러한 모델은 제2 모델 등이라고 지칭될 수 있다. 예를 들어, UE가 보행 시나리오로부터 차량이 고정된 경로 상에서 주행하 는 시나리오로 변경할 때, 제1 RAN 노드는 보행 시나리오에서 요청된 궤적 예측에서의 모델을 사용하여, 차량이 고정된 경로 상에서 주행하는 시나리오에서의 이동 궤적을 예측하고, 결과적으로, 예측 정확도에서의 감소가 야 기될 수 있다. 본 출원에서, UE의 시나리오가 변경된다는 점을 발견할 때, 제1 RAN 노드는 시나리오 변경을 OAM 등에게 표시할 수 있고, OAM은 제1 RAN 노드에 대해, 현재 시나리오에 매칭되는 모델 등을 구성할 수 있다. 전술한 시나리오 변경 표시 또는 성능 레벨 변경 표시는 UE를 분석하는 것에 의해 제1 RAN 노드에 의해 발견될 수 있거나, 또는 UE에 의해 제1 RAN 노드에 보고될 수 있다. 상세사항들에 대해서는, 단계 706에서의 제2 설계 의 설명들을 참조한다. 대안적으로, 제1 모델은 제1 RAN 노드에 관련된 모델이고, 제1 RAN은, 제1 RAN을 분석 하는 것에 의해, 애플리케이션 시나리오가 변경되거나, 또는 성능 레벨이 변경되는 것 등을 결정할 수 있다. 단계 705: 제1 RAN 노드가 예측 정보를 UE에 전송함. 이에 대응하여, UE는 제1 RAN 노드로부터 예측 정보를 수 신한다. 단계 706: UE가 제2 피드백 정보를 제1 RAN 노드에 전송함. 이에 대응하여, 제1 RAN 노드는 UE로부터 제2 피드 백 정보를 수신한다. 제1 설계에서, 예측 정보를 수신할 때, UE는, 예측 정보의 정확도를 결정하기 위해, 제1 RAN 노드에 의해 전송 되는 예측 정보를 실제 정보와 비교할 수 있다. 이러한 정확도는 예측 정보의 실제 정확도라고 지칭된다. 예 를 들어, 예측 정보는 궤적 정보이다. UE는 예측된 궤적 정보를 UE의 실제 궤적 정보와 비교하여, 예측 정보의 실제 정확도를 결정하고, 제2 피드백 정보를 제1 RAN 노드에 전송할 수 있으며, 제2 피드백 정보는 예측 정보의 실제 정확도를 표시한다. 이러한 표시는 암시적 표시, 명시적 표시 등일 수 있다. 다시 말해서, UE는 예측 정 보의 실제 정확도를 제1 RAN 노드에 전송한다. 예를 들어, UE는 시간의 기간에서의 예측 정보의 실제 정확도를 제1 RAN 노드에 피드백할 수 있으며, 이러한 피드백은 주기적 피드백, 이벤트 트리거링에 기초한 피드백 등일 수 있다. 예를 들어, UE는 주기성으로서 10초를 사용하고, 매 10초마다 예측 정보의 실제 정확도를 계산하고, 실제 정확도를 제1 RAN 노드에 피드백할 수 있다. 대안적으로, UE는 또한 매 10초마다 예측 정보의 정확도를 계산한다. 정확도가 임계값 미만(예를 들어, 80%)일 때, UE는 예측 정보의 실제 정확도를 제1 RAN 노드에 전송한다. 제2 설계에서, UE의 애플리케이션 시나리오가 변경되거나 또는 UE의 성능 레벨이 변경된다는 점을 발견할 때, UE는 대안적으로 제2 피드백 정보를 제1 RAN 노드에 전송할 수 있다. 제2 피드백 정보는 애플리케이션 시나리 오가 변경되거나 또는 성능 레벨이 변경된다는 점을 표시한다. 다시 말해서, UE는 애플리케이션 시나리오 변경 표시, 성능 레벨 변경 표시 등을 제1 RAN 노드에 전송한다. 단계 707: 제1 RAN 노드가 제1 피드백 정보를 OAM에 전송함. 이에 대응하여, OAM은 제1 RAN 노드로부터 제1 피 드백 정보를 수신한다. 설계에서, 제1 RAN 노드는 주기적으로, 또는 이벤트 트리거링 등에 기초하여 제1 피드백 정보를 OAM에 전송할 수 있다. 제1 피드백 정보는 예측 정보의 실제 정확도를 암시적으로 또는 명시적으로 표시할 수 있다. 다시 말해서, 제1 RAN 노드는 예측 정보의 실제 정확도를 OAM에 전송한다. 전술한 단계 706과 유사하게, 제1 RAN 노 드는 시간의 기간에서의 예측 정보의 실제 정확도를 OAM에 피드백할 수 있다. 예를 들어, 제1 RAN 노드는, 이 벤트 트리거링 등에 기초하여, 시간의 기간에서의 예측 정보의 실제 정확도를 OAM에 주기적으로 피드백할 수 있 다. 다른 설계에서, 제1 모델에 관련된 애플리케이션 시나리오 또는 성능 레벨이 변경될 때, 제1 RAN 노드는 제1 피 드백 정보를 OAM에 전송한다. 제1 피드백 정보는 애플리케이션 시나리오가 변경되거나 또는 성능 레벨이 변경 된다는 점을 표시한다. 다시 말해서, 제1 RAN 노드는 애플리케이션 시나리오 변경 표시, 성능 레벨 변경 표시 등을 OAM에 전송한다. 단계 708: OAM이 제1 피드백 정보에 기초하여 제1 모델을 업데이트함. 설계에서, 제1 피드백 정보가 제1 모델에 의해 출력되는 예측 정보의 실제 정확도를 표시할 때, OAM이 제1 피드 백 정보에 기초하여 제1 모델을 업데이트하는 것은 다음을 포함한다: 제1 모델에 의해 출력되는 예측 정보의 실 제 정확도가 임계값 미만일 때, 제1 모델이 다시 트레이닝되고, 제1 모델이 업데이트된다. 예를 들어, OAM은 트레이닝 데이터를 수집할 수 있으며, 트레이닝 데이터는 제1 RAN 노드 및/또는 UE, 다른 노드 등으로부터의 것 이다. OAM은 수집된 트레이닝 데이터를 사용하여 제1 모델을 다시 트레이닝시킬 수 있다. 모델 트레이닝 프로 세스에 대해서는, 전술한 설명들을 참조한다. 다른 설계에서, 제1 피드백 정보는 시나리오 변경 표시, 모델 성능 레벨 변경 표시 또는 모델 성능 지표 변경 표시를 표시한다. OAM이 제1 피드백 정보에 기초하여 제1 모델을 업데이트하는 것은 다음을 포함한다: 제2 모 델이 시나리오 변경 표시, 모델 성능 레벨 변경 표시, 또는 모델 성능 지표 변경 표시에 기초하여 결정된다. 예를 들어, 제1 맵핑 관계는 모델, 모델 애플리케이션 시나리오, 및 모델 기능 사이의 맵핑 관계를 포함하고, OAM은 표시된 시나리오 변경 표시에 기초하여 변경된 시나리오를 결정할 수 있다. 변경된 시나리오에 대응하는 모델은 전술한 제1 맵핑 관계에 기초하여 결정되고, 제2 모델이라고 지칭된다. 대안적으로, 제1 맵핑 관계는 모델, 모델 성능 레벨, 및 모델 기능 사이의 맵핑 관계를 포함하고, OAM은 표시된 모델 성능 레벨 변경 표시에 기초하여 변경된 모델 성능 레벨을 결정할 수 있다. 대안적으로, OAM은 표시된 모델 성능 지표 변경 표시에 기 초하여 변경된 모델 성능 레벨을 결정할 수 있다. 변경된 모델 성능 레벨에 대응하는 모델은 전술한 맵핑 관계 에 기초하여 결정되고, 제2 모델이라고 지칭된다. 대안적으로, 제1 맵핑 관계는 모델, 모델 성능 지표, 및 모 델 기능 사이의 맵핑 관계를 포함한다. OAM은 제1 맵핑 관계에 기초하여 표시된 변경된 모델 성능 지표에 대응 하는 모델을 결정하고, 이러한 모델은 제2 모델이라고 지칭된다. 단계 709: OAM이 업데이트된 모델에 관한 정보를 제1 RAN 노드에 전송함. 이에 대응하여, 제1 RAN 노드는 OAM으 로부터 업데이트된 모델에 관한 정보를 수신한다. 업데이트된 모델에 관한 정보에 포함되는 내용에 대해서는, 전술한 단계 703에서의 제1 모델에 관한 정보에 포 함되는 내용을 참조한다. 상세사항들이 본 명세서에서 다시 설명되지는 않는다. 본 출원에서, 제1 RAN 노드는 이벤트 트리거링 등에 기초하여 주기적으로 제1 피드백 정보를 OAM에 전송할 수 있다. OAM은, 제1 피드백 정보에 기초하여, 제1 모델이 업데이트될 필요가 있는지를 평가하여, 제1 모델을 시 기적절한 방식으로 업데이트하고, 제1 모델의 예측 성능 및 예측 속도를 개선한다. 도 7의 프로시저에서의 방법을 사용하여 제1 RAN 노드에 대해 제1 모델이 구성된 후에, 도 8에 도시되는 바와 같이, 본 출원은 셀 핸드오버 흐름도를 제공한다. 이러한 프로시저에서, 제1 RAN 노드는 소스 RAN 노드라고 지 칭되고, 제2 RAN 노드는 타겟 RAN 노드라고 지칭되며, 이러한 프로시저는 적어도 다음의 단계들을 포함한다.단계 801: 소스 RAN 노드가 타겟 셀을 결정함. 설계에서, 소스 RAN 노드는 UE에 의해 보고되는 측정 보고를 수신할 수 있으며, 이러한 측정 보고는 셀의 식별 정보, 셀의 품질 정보 등을 포함한다. 셀은 현재 서빙 셀, 이웃 셀 등일 수 있다. 이러한 것은 제한되지 않는 다. 설계에서, UE는 측정 보고를 소스 RAN 노드에 주기적으로 보고할 수 있다. 예를 들어, UE는 서빙 셀의 신 호 품질 및/또는 이웃 셀의 신호 품질을 주기적으로 측정하고, 다음으로 측정된 정보를 소스 RAN 노드에 주기적 으로 보고할 수 있다. 대안적으로, UE는 서빙 셀의 신호 품질 및/또는 이웃 셀의 신호 품질을 주기적으로 측정 하고, 구체적인 조건이 충족될 때 측정된 정보 등을 소스 RAN 노드에 보고할 수 있다. 본 출원에서, 측정 보고는 셀의 식별 정보를 포함한다. 셀의 식별 정보는 셀의 셀 글로벌 식별자(cell global identifier, CGI), 물리 셀 식별자(physical cell identifier, PCI) 및 주파수, 셀 아이덴티티(cell identity, cell ID), 비-공개 네트워크 식별자(non-public network identifier, NPN ID), 비-지상 네트워크 식별자(non- terrestrial network identifier, NTN ID), 다른 셀 아이덴티티 등 중 적어도 하나를 포함할 수 있다. CGI는 공중 육상 모바일 네트워크(public land mobile network, PLMN ID), 셀 ID 등을 포함할 수 있다. 선택적으로, 셀의 식별 정보는 추적 영역 코드(tracking area code, TAC) 및/또는 셀이 속하는 네트워크 디바이스의 식별 정 보, 예를 들어, 글로벌 네트워크 디바이스 식별자를 추가로 포함할 수 있다. 본 출원에서, 측정 보고는 셀의 신호 품질 정보를 포함한다. 예를 들어, UE는 다운링크 동기화 채널, 채널 상 태 정보 참조 신호, 복조 참조 신호(demodulation reference signal, DMRS), 셀-특정 참조 신호(cell-specific reference signal, CRS), 동기화 신호 블록(synchronization signal block, SSB), 동기화 신호/물리적 브로드 캐스트 채널 블록, 또는 다른 다운링크 신호 중 적어도 하나를 측정하는 것에 의해 셀의 품질 정보를 획득할 수 있다. 예를 들어, 셀의 품질 정보는 수신 신호 코드 전력(received signal code power, RSCP), 참조 신호 수 신 전력(reference signal received power, RSRP), 참조 신호 수신 품질(reference signal received quality, RSRQ), 신호 노이즈 비율(signal noise ratio, SNR), 신호 대 간섭 플러스 노이즈 비율(signal to interference plus noise ratio, SINR), 참조 신호 강도 표시(reference signal strength indication, RSSI), 또는 다른 신호 품질 중 적어도 하나를 포함할 수 있다. 선택적으로, 셀의 품질 정보는 셀 레벨, 빔 레벨, 동기화 신호/물리 브로드캐스트 채널 블록(synchronization signal/physical broadcast channel block, SS/PBCH Block) 레벨, 채널 상태 정보 참조 신호(channel state information reference signal, CSI-RS) 레벨, 수비학(numerology) 레벨, 슬라이싱(slicing) 레벨, 또는 대역 폭 부분(bandwidth part, BWP) 레벨 중 적어도 하나일 수 있다. 셀의 품질 정보의 레벨은 셀의 품질 정보가 측 정되는 입도이다. 예를 들어, 셀 레벨에 있는 셀의 품질 정보는 UE가 복수의 측정-예정 셀 내의 각각의 셀을 측정하여, 각각의 셀의 품질을 획득하는 것을 의미한다. 대안적으로, 셀의 품질이 빔 레벨에 있다는 것은 셀이 적어도 하나의 빔을 포함한다는 것을 의미하고, UE는 셀 내의 빔을 측정하는 것에 의해 셀의 품질 정보를 획득 한다. 예를 들어, 셀은 3개의 빔들을 포함하고, UE는 3개의 빔들에서 빔 1, 빔 2 및 빔 3을 별도로 측정하여, 빔 품질 조건을 충족시키는 빔 1의 품질 정보 및 빔 2의 품질 정보를 획득할 수 있다. 선택적으로, UE는 다음 으로, 예를 들어, 빔 1의 품질 정보 및 빔 2의 품질 정보에 기초하여 더 큰 값, 평균, 또는 가중화된 합산을 획 득하여, 셀의 품질 정보를 획득할 수 있다. 대안적으로, UE는 빔 1의 품질 정보 및 빔 2의 품질 정보 양자 모 두를 보고할 수 있다. 다른 입도로 UE에 의해 측정되는 셀의 품질 정보는 전술한 것과 유사하고, 다시 설명되 지는 않는다. 셀 품질 정보가 빔 레벨, SS/PBCH 블록 레벨, CSI-RS 레벨, 에어 인터페이스 기술 레벨, 슬라이싱 레벨, BWP 레 벨 등이면, 셀의 식별 정보는 대응하는 빔의 식별 정보, SS/PBCH 블록의 식별 정보, CSI-RS의 식별 정보, 에어 인터페이스 기술의 식별 정보, 슬라이스의 식별 정보, BWP의 식별 정보 등 중 적어도 하나를 추가로 포함한다는 점이 주목되어야 한다. 설계에서, 측정 보고를 수신할 때, 소스 RAN 노드는, 측정 보고에 기초하여, 서빙 셀이 UE에 대해 핸드오버될 필요가 있는지를 결정할 수 있다. 예를 들어, 소스 셀의 서비스의 품질이 구체적인 임계값보다 낮으면, 서빙 셀이 UE에 대해 핸드오버될 필요가 있다고 결정될 수 있다. 소스 RAN 노드는 수신된 측정 보고에 기초하여 UE 에 대한 타겟 셀을 선택할 수 있다. 예를 들어, 신호 품질이 임계값 초과이고 신호 품질이 최상인 셀이 UE의 이웃 셀들로부터 타겟 셀로서 선택될 수 있다. 다른 설계에서, 소스 RAN 노드는 AI 방식으로 타겟 셀을 결정할 수 있다. 소스 RAN 노드는 AI 모델 또는 머신 학습(machine learning, ML) 모델을 사용하여 타겟 셀을 예측할 수 있다. AI 모델 또는 ML 모델의 입력 데이터 는 다음: UE의 측정 보고, 이웃 셀의 과거 및/또는 실시간 부하, UE의 과거 궤적 정보, 현재 순간에서의 UE의지리적 좌표, 현재 순간에서의 UE의 이동 방향, UE의 이동 속도 등 중 적어도 하나를 포함한다. AI 모델 또는 ML 모델의 출력 데이터는 다음: UE의 타겟 셀, 핸드오버 타임스탬프 등 중 적어도 하나를 포함한다. 단계 802: 소스 RAN 노드가 모델 정보를 타겟 셀에 대응하는 타겟 RAN 노드에 전송함. 설계에서, 소스 RAN 노드는 모델 정보를 타겟 RAN 노드에 전송할 수 있으며, 모델 정보는 제1 모델의 인덱스를 포함한다. 선택적으로, 모델 정보는 다음: 제1 모델의 애플리케이션 시나리오, 제1 모델의 기능, 모델 추론을 위해 제1 모델에 의해 수집될 필요가 있는 데이터 등 중 적어도 하나를 추가로 포함할 수 있다. 예를 들어, AI-기반 이동성 강화 해결책에서, 모델 추론을 수행하는 RAN 노드는 UE가 이전에 액세스한 RAN 노드로부터 UE의 과거 핸드오버 성공 또는 실패 경우를 요청할 필요가 있다. 본 출원에서, 소스 RAN 노드가 모델 추론을 위해 수집될 필요가 있는 데이터를 타겟 RAN 노드에 통지할 필요가 있는 프로세스는 다음과 같이 추가로 설명될 수 있다: RAN 노드는 제1 표시 정보를 타겟 RAN 노드에 전송하며, 제1 표시 정보는 제1 모델의 입력 데이터의 타입 정보를 표시한다. 이러한 프로세스에서, 소스 RAN 노드는 모델 추론 프로세스에서 모델 추론을 위해 수집될 필 요가 있는 데이터를 미리 타겟 RAN 노드에 통지할 수 있어서, 타겟 소스 RAN은 모델 추론을 준비하여, 모델 추 론 효율을 개선한다. 단계 803: 소스 RAN 노드가 UE의 과거 정보를 타겟 RAN 노드에 전송함- 과거 정보는 UE로부터 소스 RAN 노드에 의해 수집되는 적어도 과거 데이터, 과거 정보 등을 포함함 -. 설계에서, UE의 과거 정보는 제1 모델 등을 사용하여 모델 추론을 수행하기 위해 필요한 정보일 수 있다. 다시 말해서, 타겟 RAN 노드가 제1 모델을 사용하여 모델 추론을 수행할 때, 과거 정보는 제1 모델의 입력 데이터의 일부로서 사용될 수 있다. 전술한 프로세스는 다음과 같이 추가로 설명될 수 있다: 소스 RAN 노드는 모델 추론 에 필요한 과거 데이터 정보를 타겟 RAN 노드에 전송하며, 과거 데이터 정보는 제1 모델의 입력 데이터를 결정 하기 위한 것이다. 예를 들어, 타겟 RAN 노드는 모델 추론을 수행하기 위해 과거 데이터를 제1 모델의 입력으 로서 직접 사용할 수 있거나; 또는 타겟 RAN 노드는 과거 데이터를 처리하고, 처리된 과거 데이터를 제1 모델의 입력으로서 사용할 수 있다. 이러한 것은 제한되지 않는다. 단계 803은 단계 802 후에 수행될 수 있거나, 또는 단계 804 후에 수행될 수 있다는 점이 주목되어야 한다. 이 러한 것은 제한되지 않는다. 도 8에서의 프로시저에서, 단계 802 후에 프로시저가 수행되는 예가 설명을 위해 사용된다. 예를 들어, 타겟 셀이 AI 방식으로 결정되면, 단계 803은 단계 802 이후에 수행될 수 있다. 대안적 으로, 타겟 셀이 비-AI 방식으로 결정되는 경우, 단계 803은 단계 804 이후에 수행될 수 있다. 본 출원에서, 모든 프로시저들에서의 단계들의 순서는 제한되지 않는다. 단계 804: UE가 소스 RAN 노드에 대응하는 소스 셀로부터 타겟 RAN 노드에 대응하는 타겟 셀로 핸드오버됨. 핸 드오버 후에, 타겟 셀은 UE의 서빙 셀로서 역할을 한다. 단계 805: 타겟 RAN 노드가 제2 표시 정보를 소스 RAN 노드에 전송함- 제2 표시 정보는 다음: UE가 타겟 셀로 핸드오버된다는 점을 표시하는 것, 제1 모델을 삭제하도록 소스 RAN 노드에게 표시하는 것, 또는 대응하는 컴퓨 팅 리소스를 해제하도록 소스 RAN 노드에게 표시하는 것 중 적어도 하나를 표시한다. 예를 들어, 소스 RAN 노드는 모델 추론을 위해 리소스의 1%를 UE에 할당한다. UE가 타겟 셀로 핸드오버된 후에, 소스 RAN 노드는 UE에 할당되는 컴퓨팅 리소스의 1%를 해제하고, 제1 모델을 삭제하는 등을 할 수 있다. 단계 806: 소스 RAN 노드가 대응하는 컴퓨팅 리소스를 해제하기 위해 제1 모델을 삭제함. 단계 807: 타겟 RAN 노드가 제2 모델 요청 메시지를 OAM에 전송함- 제2 모델 요청 메시지는 제1 모델의 인덱스 를 표시함 -. 단계 808: OAM이 제1 모델의 인덱스에 기초하여 제1 모델을 결정할 수 있음. 본 출원에서, 제1 모델의 인덱스와 제1 모델 사이에는 맵핑 관계가 있다. OAM은 제1 모델의 인덱스에 기초하여 제1 모델을 결정할 수 있다. 단계 809: OAM이 제1 모델에 관한 정보를 타겟 RAN 노드에 전송함. 단계 8010: 타겟 RAN 노드가 예측 정보를 획득하기 위해 제1 모델에 기초하여 모델 추론을 수행함. 단계 8011: 타겟 RAN 노드가 예측 정보를 UE에 전송함. 단계 8012: UE가 제2 피드백 정보를 타겟 RAN 노드에 전송함. 단계 8013: 타겟 RAN 노드가 제1 피드백 정보를 OAM에 전송함. 단계 8014: OAM이 제1 모델을 업데이트함. 단계 8015: OAM이 업데이트된 제1 모델에 관한 정보를 타겟 RAN 노드에 전송함. 단계들 809 내지 8015의 구체적인 수행 프로세스에 대해서는, 도 7의 설명들을 참조한다. 본 출원에서, UE가 셀 핸드오버를 수행할 때, 소스 RAN 노드는 제1 모델의 인덱스를 타겟 RAN 노드에 전송하여, AI 서비스의 연속성을 보장한다. 또한, UE가 성공적으로 핸드오버된 후에, 타겟 RAN 노드는 컴퓨팅 리소스를 해제하기 위해 모델 관련 정보를 삭제하라고 소스 RAN 노드에 통지하여, RAN 노드의 메모리 리소스 점유 및 컴 퓨팅 리소스 점유가 감소될 수 있다. 전술한 방법들에서의 기능들을 구현하기 위해, OAM 및 RAN 노드가 기능들을 수행하기 위한 대응하는 하드웨어 구조들 및/또는 소프트웨어 모듈들을 포함한다는 점이 이해될 수 있다. 해당 기술에서의 숙련자는, 본 출원에 서 설명되는 예들에서의 유닛들 및 방법 단계들을 참조하면, 본 출원이 하드웨어 또는 하드웨어와 컴퓨터 소프 트웨어의 조합에 의해 구현될 수 있다는 것을 용이하게 인식할 것이다. 기능이 하드웨어의 형태로 수행되는지 또는 컴퓨터 소프트웨어에 의해 구동되는 하드웨어의 형태로 수행되는지는 기술적 해결책들의 특정 애플리케이 션 시나리오들 및 설계 제약들에 의존한다. 도 9 및 도 10은 본 출원에 따른 가능한 통신 장치들의 구조들의 도면들이다. 이러한 통신 장치들은 전술한 방 법들에서 OAM 또는 RAN 노드의 기능들을 구현하도록 구성될 수 있고, 따라서 전술한 방법들의 유익한 효과를 또 한 구현할 수 있다. 도 9에 도시되는 바와 같이, 통신 장치는 처리 유닛 및 송수신기 유닛을 포함한다. 통신 장치 는 도 7 또는 도 8에 도시되는 방법에서의 OAM, 소스 RAN 노드, 또는 타겟 RAN 노드의 기능들을 구현하도 록 구성된다. 통신 장치가 도 7 또는 도 8에 도시되는 방법에서의 OAM의 기능을 구현하도록 구성될 때, 송수신기 유닛 은 제1 액세스 네트워크 디바이스로부터 제1 모델 요청 메시지를 수신하도록 구성된다. 처리 유닛은 제1 모델 요청 메시지 및 제1 맵핑 관계에 기초하여 제1 모델을 결정하도록 구성되며, 제1 맵핑 관계는 모델, 모델 애플리케이션 시나리오, 및 모델 기능 사이의 맵핑 관계를 포함하거나; 또는 제1 맵핑 관계는 모델, 모델 성능 레벨, 및 모델 기능 사이의 맵핑 관계를 포함한다. 송수신기 유닛은 제1 모델에 관한 정보를 제1 액 세스 네트워크 디바이스에 전송하도록 추가로 구성된다. 통신 장치가 도 7 또는 도 8에 도시되는 방법에서의 제1 RAN 노드 또는 소스 RAN 노드의 기능을 구현하도 록 구성될 때, 송수신기 유닛은 제1 모델 요청 메시지를 OAM(operations, administration and maintenance)에 전송하도록 구성되며, 제1 모델 요청 메시지는 제1 모델의 모델 애플리케이션 시나리오 및 모델 기능을 표시하거나, 또는 제1 모델 요청 메시지는 제1 모델의 모델 성능 레벨 및 모델 기능을 표시한다. 송수 신기 유닛은 OAM으로부터 제1 모델에 관한 정보를 수신하도록 추가로 구성된다. 통신 장치가 도 8에 도시되는 방법에서의 타겟 RAN 노드의 기능을 구현하도록 구성될 때, 송수신기 유닛 은 제1 액세스 네트워크 디바이스로부터 제1 모델의 인덱스를 수신하고 제2 모델 요청 메시지를 OAM(operations, maintenance, and administration)으로 전송하도록 구성된다. 제2 모델 요청 메시지는 제1 모델의 인덱스를 표시하고 OAM으로부터 제1 모델에 관한 정보를 수신한다. 처리 유닛 및 송수신기 유닛의 더 상세한 설명들에 대해서는, 도 5, 도 7 또는 도 8에 도시되는 방법 의 관련 설명들을 직접 참조한다. 상세사항들이 본 명세서에서 다시 설명되지는 않는다. 도 10에 도시되는 바와 같이, 통신 장치는 프로세서 및 인터페이스 회로를 포함한다. 프로 세서 및 인터페이스 회로는 서로 연결된다. 인터페이스 회로는 송수신기, 입력/출력 인터페 이스, 핀 등일 수 있다는 점이 이해될 수 있다. 선택적으로, 통신 장치는, 프로세서에 의해 실행 되는 명령어들을 저장하도록, 또는 명령어들을 실행하기 위해 프로세서에 의해 필요로 되는 입력 데이터 를 저장하도록, 또는 프로세서가 명령어들을 실행한 후에 생성되는 데이터를 저장하도록 구성되는 메모리 를 추가로 포함할 수 있다. 통신 장치가 전술한 방법을 구현하도록 구성될 때, 프로세서는 처리 유닛의 기능들을 구현하 도록 구성되고, 인터페이스 회로는 송수신기 유닛의 기능들을 구현하도록 구성된다.통신 장치가 OAM에서 사용되는 모듈일 때, OAM에서의 모듈은 전술한 방법에서의 OAM의 기능들을 구현한다. OAM 에서의 모듈은 OAM에서의 다른 모듈(예를 들어, 무선 주파수 모듈 또는 안테나)로부터 정보를 수신하거나- 이러 한 정보는 RAN 노드에 의해 OAM에 전송됨 -; 또는 OAM에서의 모듈은 OAM에서의 다른 모듈(예를 들어, 무선 주파 수 모듈 또는 안테나)에 정보를 전송한다- 이러한 정보는 OAM에 의해 RAN 노드에 전송됨 -. 본 명세서에서 OAM 에서의 모듈은 OAM 기저대역 칩일 수 있거나, 또는 다른 모듈 등일 수 있다. 통신 장치가 RAN 노드에서 사용되는 모듈일 때, RAN 노드에서의 모듈은 전술한 방법에서 RAN 노드의 기능들을 구현한다. RAN 노드에서의 모듈은 RAN 노드에서의 다른 모듈(예를 들어, 무선 주파수 모듈 또는 안테나)로부터 정보를 수신하거나- 이러한 정보는 단말에 의해 RAN 노드에 전송됨 -; 또는 RAN 노드에서의 모듈은 RAN 노드에 서의 다른 모듈(예를 들어, 무선 주파수 모듈 또는 안테나)에 정보를 전송한다- 이러한 정보는 RAN 노드에 의해 단말에 전송됨 -. 본 명세서에서 RAN 노드에서의 모듈은 RAN 노드 기저대역 칩일 수 있거나, 또는 DU 또는 다른 모듈일 수 있다. 본 명세서에서 DU는 개방형 무선 액세스 네트워크(open radio access network, O-RAN) 아키 텍처에서의 DU일 수 있다. 본 출원의 실시예들에서의 프로세서는 중앙 처리 유닛(central processing unit, CPU)일 수 있거나, 또는 다른 범용 프로세서, 디지털 신호 프로세서(digital signal processor, DSP), 또는 주문형 집적 회로(application- specific Integrated circuit, ASIC), 필드 프로그램가능 게이트 어레이(field programmable gate array, FPGA) 또는 다른 프로그램가능 논리 디바이스, 트랜지스터 논리 디바이스, 하드웨어 컴포넌트, 또는 이들의 임 의의 조합일 수 있다는 점이 이해될 수 있다. 범용 프로세서는 마이크로프로세서 또는 임의의 정규 프로세서일 수 있다. 본 출원에서의 메모리는 랜덤 액세스 메모리, 플래시 메모리, 판독-전용 메모리, 프로그램가능 판독-전용 메모 리, 소거가능 프로그램가능 판독-전용 메모리, 전기적으로 소거가능 프로그램가능 판독-전용 메모리, 레지스터, 하드 디스크 드라이브, 이동식 하드 디스크 드라이브, CD-ROM, 또는 해당 기술에서 잘 알려진 임의의 다른 형태 의 저장 매체일 수 있다. 예를 들어, 저장 매체는 프로세서에 연결되어, 프로세서가 저장 매체로부터 정보를 판독하거나 또는 정보를 저 장 매체에 기입할 수 있다. 저장 매체는 대안적으로 프로세서의 컴포넌트일 수 있다. 프로세서 및 저장 매체 는 ASIC에 배치될 수 있다. 또한, ASIC는 기지국 또는 단말에 위치될 수 있다. 물론, 프로세서 및 저장 매체 는 개별 컴포넌트들로서 기지국 또는 단말에 존재할 수 있다. 본 출원에서의 방법들의 전부 또는 일부는 소프트웨어, 하드웨어, 펌웨어, 또는 이들의 임의의 조합에 의해 구 현될 수 있다. 소프트웨어가 실시예들을 구현하기 위한 것일 때, 실시예들의 전부 또는 일부는 컴퓨터 프로그 램 제품의 형태로 구현될 수 있다. 컴퓨터 프로그램 제품은 하나 이상의 컴퓨터 프로그램 또는 명령어를 포함 한다. 이러한 컴퓨터 프로그램들 또는 명령어들이 컴퓨터 상에서 로딩되고 실행될 때, 본 출원의 실시예들에 따른 프로시저 또는 기능들이 완전히 또는 부분적으로 실행된다. 이러한 컴퓨터는 범용 컴퓨터, 전용 컴퓨터, 컴퓨터 네트워크, 네트워크 디바이스, 사용자 장비, 코어 네트워크 디바이스, OAM, 또는 다른 프로그램가능 장 치일 수 있다. 이러한 컴퓨터 프로그램 또는 명령어들은 컴퓨터-판독가능 저장 매체에 저장될 수 있거나, 또는 컴퓨터-판독가능 저장 매체로부터 다른 컴퓨터-판독가능 저장 매체에 송신될 수 있다. 예를 들어, 이러한 컴퓨 터 프로그램 또는 명령어들은 웹사이트, 컴퓨터, 서버, 또는 데이터 센터로부터 유선 또는 무선 방식으로 다른 웹사이트, 컴퓨터, 서버, 또는 데이터 센터에 송신될 수 있다. 이러한 컴퓨터-판독가능 저장 매체는 컴퓨터, 또는 데이터 저장 디바이스, 예를 들어, 하나 이상의 사용가능 매체를 통합하는 서버 또는 데이터 센터에 의해 액세스될 수 있는 임의의 사용가능 매체일 수 있다. 이러한 사용가능 매체는 자기 매체, 예를 들어, 플로피 디 스크, 하드 디스크 드라이브, 또는 자기 테이프일 수 있거나; 또는 광학 매체, 예를 들어, 디지털 비디오 디스 크일 수 있거나; 또는 반도체 매체, 예를 들어, 고체-상태 드라이브일 수 있다. 이러한 컴퓨터-판독가능 저장 매체는 휘발성 또는 비-휘발성 저장 매체일 수 있거나, 또는 2개의 타입들의 저장 매체: 휘발성 저장 매체 및 비-휘발성 저장 매체를 포함할 수 있다. 본 출원의 실시예들에서, 달리 표명되거나 또는 논리적 충돌이 없는 한, 상이한 실시예들에서의 용어들 및/또는 설명들은 일관되고 상호 참조될 수 있으며, 상이한 실시예들에서의 기술적 특징들은 그의 내부 논리적 관계에 기초하여 조합되어, 새로운 실시예를 형성할 수 있다. 본 출원에서, \"적어도 하나(at least one)\"는 하나 이상을 의미하고, \"복수의(a plurality of)\"는 2개 이상을 의미한다. \"및/또는(and/or)\"은 연관 객체들 사이의 연관 관계를 설명하고 3개의 관계가 존재할 수 있다는 점 을 표현한다. 예를 들어, A 및/또는 B는 다음의 경우들: A가 단독으로 존재함, A와 B 양자 모두가 존재함, 및B가 단독으로 존재함을 표현할 수 있으며, A 및 B는 단수 또는 복수일 수 있다. 본 출원의 텍스트 설명들에서, 문자 \"/\"는 연관된 객체들 사이의 \"또는(or)\" 관계를 표시한다. 본 출원에서의 공식에서, 문자 \"/\"는 연관된 객체들 사이의 \"분할(division)\" 관계를 표시한다. \"A, B, 또는 C 중 적어도 하나를 포함함(including at least one of A, B, or C)\"은, A를 포함함; B를 포함함; C를 포함함; A 및 B를 포함함; A 및 C를 포함함; B 및 C를 포함함; 및 A, B, 및 C를 포함함을 표시할 수 있다. 본 출원에서 사용되는 다양한 숫자들은 단지 설명의 용이함을 위해 구별된 것일 뿐이고, 본 출원의 범위를 제한 하기 위해 사용되지 않는다는 점이 이해될 수 있다. 전술한 프로세스들의 일련 번호들은 실행 순서를 의미하지 않고, 프로세스들의 실행 순서는 프로세스들의 기능들 및 내부 로직에 기초하여 결정될 필요가 있다."}
{"patent_id": "10-2024-7026840", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 출원에 따른 통신 시스템의 도면이다. 도 2 및 도 3은 본 출원에 따른 모델 배치의 도면들이다. 도 4a 및 도 4b는 본 출원에 따른 통신 시스템들의 아키텍처들의 도면들이다. 도 4c는 본 출원에 따른 AI 모델을 적용하는 도면이다. 도 5는 본 출원에 따른 뉴런의 도면이다. 도 6은 본 출원에 따른 신경망의 도면이다. 도 7 및 도 8은 본 출원에 따른 개략적인 흐름도들이다. 도 9 및 도 10은 본 출원에 따른 장치들의 구조들의 도면들이다."}
