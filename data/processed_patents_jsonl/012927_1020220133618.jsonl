{"patent_id": "10-2022-0133618", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0149705", "출원번호": "10-2022-0133618", "발명의 명칭": "이미지를 처리하는 전자 장치 및 그 동작 방법", "출원인": "삼성전자주식회사", "발명자": "최이삭"}}
{"patent_id": "10-2022-0133618", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "전자 장치가 이미지를 처리하는 방법에 있어서,제1 카메라를 이용하여 적어도 하나의 라벨을 포함하는 객체의 제1 이미지를 획득하는 단계(S210);상기 제1 이미지를 제1 AI 모델에 적용함으로써, 상기 제1 이미지 내에서 상기 적어도 하나의 라벨에 대응하는영역을 관심 영역으로 식별하는 단계(S220);상기 제1 이미지를 제2 AI 모델에 적용함으로써, 상기 객체의 3차원 형상 타입에 관한 데이터를 획득하는 단계(S230);상기 관심 영역으로 식별된 상기 적어도 하나의 라벨에 대응하는 영역 및 상기 객체의 3차원 형상 타입에 관한데이터에 기초하여, 상기 객체, 상기 적어도 하나의 라벨 및 상기 제1 카메라 중 적어도 하나와 관련된 3차원파라미터 값들을 획득하는 단계(S240);상기 3차원 파라미터 값들에 기초하여, 상기 적어도 하나의 라벨의 굴곡 형상을 추정하는 단계(S250); 및상기 적어도 하나의 라벨에 대한 원근 변환(perspective transformation)을 수행함으로써, 상기 적어도 하나의라벨의 굴곡 형상이 평평하게 된 플랫(flat) 라벨 이미지를 획득하는 단계(S260)를 포함하는, 방법."}
{"patent_id": "10-2022-0133618", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 3차원 파라미터 값들은,상기 객체의 3차원 형상과 관련된 높이 값 및 반지름 값, 상기 객체의 표면의 관심 영역의 각도 값, 3차원 기하학적 변환을 위한 이동(translation) 값 및 회전(rotation) 값, 및 상기 카메라의 초점 거리 값 중 적어도 하나를 포함하는 것인, 방법."}
{"patent_id": "10-2022-0133618", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항 내지 제2항 중 어느 한 항에 있어서,상기 제1 AI 모델은, 이미지 내에서 라벨에 대응하는 영역을 관심 영역으로 추론하도록 훈련된 인공지능 모델이고,상기 제2 AI 모델은, 이미지 내 객체의 3차원 형상 타입을 추론하도록 훈련된 인공지능 모델인 것인, 방법."}
{"patent_id": "10-2022-0133618", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항 내지 제3항 중 어느 한 항에 있어서,상기 객체의 3차원 형상 타입에 관한 데이터를 획득하는 단계는,사용자로부터 상기 객체의 3차원 형상 타입에 관련된 사용자 입력을 수신하는 단계; 및복수의 3차원 형상 타입 중에서 상기 사용자 입력에 대응하는 3차원 형상 타입에 가중치를 적용하여 상기 객체의 3차원 형상 타입을 식별하는 단계를 포함하는, 방법."}
{"patent_id": "10-2022-0133618", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "공개특허 10-2023-0149705-3-제1항 내지 제4항 중 어느 한 항에 있어서,상기 적어도 하나의 라벨에 대응하는 영역을 상기 관심 영역으로 식별하는 단계는,상기 적어도 하나의 라벨에 대응하는 영역을 나타내는 제1 키포인트들을 식별하는 단계를 포함하고,상기 3차원 파라미터 값들을 획득하는 단계는,상기 객체의 3차원 형상 타입에 대응하는 가상 객체 및 상기 가상 객체의 3차원 파라미터 초기값들을 획득하는단계;상기 제1 키포인트들에 기초하여, 상기 가상 객체의 3차원 파라미터 초기값들을 조정하는 단계; 및상기 조정된 3차원 파라미터 초기 값들을 상기 3차원 파라미터 값들로 획득하는 단계를 포함하는, 방법."}
{"patent_id": "10-2022-0133618", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5항에 있어서,상기 제1 키포인트들에 기초하여, 상기 가상 객체의 3차원 파라미터의 초기값들을 조정하는 단계는,상기 가상 객체의 가상 라벨에 대응하는 영역을 나타내는 제2 키포인트들을 설정하는 단계; 및상기 제2 키포인트들이 상기 제1 키포인트들에 정합하도록 상기 가상 객체의 3차원 파라미터 초기값들을 조정하는 단계를 포함하는, 방법."}
{"patent_id": "10-2022-0133618", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항 내지 제6항 중 어느 한 항에 있어서,상기 플랫 라벨 이미지로부터 상기 객체와 관련된 정보를 획득하는 단계는,상기 플랫 라벨 이미지에 광학 문자 인식(Optical character recognition; OCR)을 적용하는 단계를 포함하는,방법."}
{"patent_id": "10-2022-0133618", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1항 내지 제7항 중 어느 한 항에 있어서,상기 전자 장치는,상기 제1 카메라보다 화각이 넓은 제2 카메라를 더 포함하는, 방법."}
{"patent_id": "10-2022-0133618", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서, 상기 객체의 3차원 형상 타입에 관한 데이터를 획득하는 단계는,상기 제2 카메라를 통해 상기 객체의 제2 이미지를 획득하는 단계; 및상기 제2 이미지를 상기 제2 AI 모델에 더 적용함으로써, 상기 객체의 3차원 형상 타입에 관련된 정보를 획득하는 단계를 포함하는, 방법."}
{"patent_id": "10-2022-0133618", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제8항에 있어서,공개특허 10-2023-0149705-4-상기 방법은,상기 제1 카메라를 이용하여 실시간으로 촬영되는 상기 제1 이미지를 상기 제1 AI 모델에 적용하여 상기 관심영역의 신뢰도를 획득하는 단계;상기 제2 카메라를 이용하여 실시간으로 촬영되는 제2 이미지를 상기 제2 AI 모델에 적용하여 상기 객체의 3차원 형상 타입의 신뢰도를 획득하는 단계; 및상기 객체의 3차원 형상 타입의 신뢰도 및 상기 관심 영역의 신뢰도 각각의 임계 값에 기초하여, 상기 제1 이미지 및 상기 제2 이미지를 각각 캡쳐하는 단계를 더 포함하는, 방법."}
{"patent_id": "10-2022-0133618", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제10항에 있어서,상기 방법은,상기 플랫 라벨 이미지 또는 상기 플랫 라벨 이미지로부터 획득된 정보에 기초하여, 데이터베이스 내에서 일치하는 데이터를 검색하는 단계; 및상기 검색 결과를 표시하는 단계를 더 포함하되,상기 데이터베이스는, 상기 전자 장치가 이전에 획득한 또다른 플랫 라벨 이미지들 및 또다른 객체들과 관련된정보가 저장된 것인, 방법."}
{"patent_id": "10-2022-0133618", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "이미지를 처리하는 전자 장치에 있어서,제1 카메라(2200);하나 이상의 인스트럭션을 저장하는 메모리(2300); 및상기 메모리에 저장된 상기 하나 이상의 인스트럭션을 실행하는 적어도 하나의 프로세서(2400)를 포함하고,상기 적어도 하나의 프로세서(2400)는, 상기 하나 이상의 인스트럭션을 실행함으로써,제1 카메라(2200)를 이용하여 적어도 하나의 라벨을 포함하는 3차원의 객체의 제1 이미지를 획득하고,상기 제1 이미지를 제1 AI 모델에 적용함으로써, 상기 제1 이미지 내에서 상기 적어도 하나의 라벨에 대응하는영역을 관심 영역으로 식별하고,상기 제1 이미지를 제2 AI 모델에 적용함으로써, 상기 객체의 3차원 형상 타입에 관한 데이터를 획득하고,상기 관심 영역으로 식별된 상기 적어도 하나의 라벨에 대응하는 영역 및 상기 객체의 3차원 형상 타입에 관한데이터에 기초하여, 상기 객체, 상기 적어도 하나의 라벨 및 상기 제1 카메라와 중 적어도 하나와 관련된 3차원파라미터를 획득하고,상기 3차원 파라미터에 기초하여, 상기 적어도 하나의 라벨의 굴곡 형상을 추정하고,상기 적어도 하나의 라벨에 대한 원근 변환(perspective transformation)을 수행함으로써, 상기 적어도 하나의라벨의 굴곡 형상이 평평하게 된 플랫(flat) 라벨 이미지를 획득하는, 전자 장치."}
{"patent_id": "10-2022-0133618", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제12항에 있어서, 상기 3차원 파라미터 값들은,상기 객체의 3차원 형상과 관련된 높이 값 및 반지름 값, 상기 객체의 표면의 관심 영역의 각도 값, 3차원 기하학적 변환을 위한 이동(translation) 값 및 회전(rotation) 값, 및 상기 카메라의 초점 거리 값 중 적어도 하나공개특허 10-2023-0149705-5-를 포함하는 것인, 전자 장치."}
{"patent_id": "10-2022-0133618", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제12항에 있어서,상기 제1 AI 모델은, 이미지 내에서 라벨에 대응하는 영역을 관심 영역으로 추론하도록 훈련된 인공지능 모델이고,상기 제2 AI 모델은, 이미지 내 객체의 3차원 형상 타입을 추론하도록 훈련된 인공지능 모델인 것인, 전자장치."}
{"patent_id": "10-2022-0133618", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제12항에 있어서,상기 적어도 하나의 프로세서는, 상기 하나 이상의 인스트럭션을 실행함으로써,사용자로부터 상기 객체의 3차원 형상 타입에 관련된 사용자 입력을 수신하고,복수의 3차원 형상 타입 중에서 상기 사용자 입력에 대응하는 3차원 형상 타입에 가중치를 적용하여 상기 객체의 3차원 형상 타입을 식별하는, 전자 장치."}
{"patent_id": "10-2022-0133618", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제12항에 있어서,상기 적어도 하나의 프로세서는, 상기 하나 이상의 인스트럭션을 실행함으로써,상기 적어도 하나의 라벨에 대응하는 영역을 나타내는 제1 키포인트들을 식별하고,상기 객체의 3차원 형상 타입에 대응하는 가상 객체 및 상기 가상 객체의 3차원 파라미터의 초기값들을 획득하고,상기 제1 키포인트들에 기초하여, 상기 가상 객체의 3차원 파라미터의 초기값들을 조정하고,상기 조정된 3차원 파라미터의 값들을 상기 3차원 파라미터의 값들로 획득하는, 전자 장치."}
{"patent_id": "10-2022-0133618", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제16항에 있어서,상기 적어도 하나의 프로세서는, 상기 하나 이상의 인스트럭션을 실행함으로써,상기 가상 객체의 가상 라벨에 대응하는 영역을 나타내는 제2 키포인트들을 설정하고,상기 제2 키포인트들이 상기 제1 키포인트들에 정합하도록 조정함으로써, 상기 가상 객체의 3차원 파라미터의초기값들이 상기 객체의 3차원 파라미터의 정답 값에 근사하도록 조정하는, 전자 장치."}
{"patent_id": "10-2022-0133618", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제12항에 있어서,상기 적어도 하나의 프로세서는, 상기 하나 이상의 인스트럭션을 실행함으로써,공개특허 10-2023-0149705-6-상기 플랫 라벨 이미지에 광학 문자 인식(Optical character recognition; OCR)을 적용하는, 전자 장치."}
{"patent_id": "10-2022-0133618", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제12항에 있어서,상기 전자 장치는,상기 제1 카메라보다 화각이 넓은 제2 카메라를 더 포함하고,상기 적어도 하나의 프로세서는, 상기 하나 이상의 인스트럭션을 실행함으로써,상기 제2 카메라를 통해 상기 객체의 제2 이미지를 획득하고,상기 제2 이미지를 상기 제2 AI 모델에 더 적용함으로써, 상기 객체의 3차원 형상 타입에 관련된 정보를 획득하는, 전자 장치."}
{"patent_id": "10-2022-0133618", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제1항 내지 제11항 중 어느 한 항의 방법을 컴퓨터에서 실행시키기 위한 프로그램을 기록한 컴퓨터로 읽을 수있는 기록매체."}
{"patent_id": "10-2022-0133618", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "전자 장치가 이미지를 처리하는 방법이 제공된다. 상기 방법은, 제1 카메라를 이용하여 적어도 하나의 라벨을 포 함하는 객체의 제1 이미지를 획득하는 단계; 상기 제1 이미지를 제1 AI 모델에 적용함으로써, 상기 제1 이미지 내에서 상기 적어도 하나의 라벨에 대응하는 영역을 관심 영역으로 식별하는 단계; 상기 제1 이미지를 제2 AI 모 (뒷면에 계속)"}
{"patent_id": "10-2022-0133618", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "이미지 내 관심 영역의 왜곡을 제거하는 알고리즘을 적용하는, 전자 장치 및 그 동작 방법이 제공된다."}
{"patent_id": "10-2022-0133618", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "3차원 공간을 촬영한 디지털 이미지에서는, 3차원 객체의 곡면 등으로 인한 물리적인 왜곡, 촬영 관점 (perspective)으로 인한 왜곡 등이 존재한다. 이러한 3차원 특성으로 인한 왜곡을 제거하기 위해 3차원 정보를 활용하는 다양한 기술/기법이 개발되고 있다. 3차원 정보를 활용한 이미지 왜곡 제거 방법에 있어서, 3차원 정 보 획득을 위한 센서 등의 하드웨어 없이, 알고리즘을 이용하여 객체의 3차원 정보를 추론하고, 이미지 내 왜곡 을 제거하기 위한 알고리즘들이 최근 사용되고 있다."}
{"patent_id": "10-2022-0133618", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 개시의 일 측면에 따르면, 전자 장치가 이미지를 처리하는 방법이 제공될 수 있다. 상기 방법은, 제1 카메라 를 이용하여 적어도 하나의 라벨을 포함하는 객체의 제1 이미지를 획득하는 단계를 포함할 수 있다. 상기 방법 은, 상기 제1 이미지를 제1 AI 모델에 적용함으로써, 상기 제1 이미지 내에서 상기 적어도 하나의 라벨에 대응 하는 영역을 관심 영역으로 식별하는 단계를 포함할 수 있다. 상기 방법은, 상기 제1 이미지를 제2 AI 모델에 적용함으로써, 상기 객체의 3차원 형상 타입에 관한 데이터를 획득하는 단계를 포함할 수 있다. 상기 방법은, 상기 관심 영역으로 식별된 상기 적어도 하나의 라벨에 대응하는 영역 및 상기 객체의 3차원 형상 타입에 관한 데이터에 기초하여, 상기 객체, 상기 적어도 하나의 라벨 및 상기 제1 카메라 중 적어도 하나와 관련된 3차원 파라미터 값들을 획득하는 단계를 포함할 수 있다. 상기 방법은, 상기 3차원 파라미터 값들에 기초하여, 상기 적어도 하나의 라벨의 굴곡 형상을 추정하는 단계를 포함할 수 있다. 상기 방법은, 상기 적어도 하나의 라벨에 대한 원근 변환(perspective transformation)을 수행함으로써, 상기 적어도 하나의 라벨의 굴곡 형상이 평평하 게 된 플랫(flat) 라벨 이미지를 획득하는 단계를 포함할 수 있다. 본 개시의 일 측면에 따르면, 이미지를 처리하는 전자 장치가 제공될 수 있다. 상기 전자 장치는, 제1 카메라, 하나 이상의 인스트럭션을 저장하는 메모리, 및 상기 메모리에 저장된 상기 하나 이상의 인스트럭션을 실행하는 적어도 하나의 프로세서를 포함할 수 있다. 상기 적어도 하나의 프로세서는, 상기 하나 이상의 인스트럭션을 실 행함으로써, 제1 카메라를 이용하여 적어도 하나의 라벨을 포함하는 3차원의 객체의 제1 이미지를 획득할 수 있 다. 상기 적어도 하나의 프로세서는, 상기 하나 이상의 인스트럭션을 실행함으로써, 상기 제1 이미지를 제1 AI 모델에 적용함으로써, 상기 제1 이미지 내에서 상기 적어도 하나의 라벨에 대응하는 영역을 관심 영역으로 식별 할 수 있다. 상기 적어도 하나의 프로세서는, 상기 하나 이상의 인스트럭션을 실행함으로써, 상기 제1 이미지를 제2 AI 모델에 적용함으로써, 상기 객체의 3차원 형상 타입에 관한 데이터를 획득할 수 있다. 상기 적어도 하나 의 프로세서는, 상기 하나 이상의 인스트럭션을 실행함으로써, 상기 관심 영역으로 식별된 상기 적어도 하나의 라벨에 대응하는 영역 및 상기 객체의 3차원 형상 타입에 관한 데이터에 기초하여, 상기 객체, 상기 적어도 하 나의 라벨 및 상기 제1 카메라와 중 적어도 하나와 관련된 3차원 파라미터를 획득할 수 있다. 상기 적어도 하나 의 프로세서는, 상기 하나 이상의 인스트럭션을 실행함으로써, 상기 3차원 파라미터에 기초하여, 상기 적어도 하나의 라벨의 굴곡 형상을 추정할 수 있다. 상기 적어도 하나의 프로세서는, 상기 하나 이상의 인스트럭션을 실행함으로써, 상기 적어도 하나의 라벨에 대한 원근 변환(perspective transformation)을 수행함으로써, 상기 적어도 하나의 라벨의 굴곡 형상이 평평하게 된 플랫(flat) 라벨 이미지를 획득할 수 있다. 본 개시의 일 측면에 따르면, 전자 장치가 이미지를 처리하는 방법이 제공될 수 있다. 상기 방법은, 제1 카메라 를 이용하여 객체의 라벨을 포함하는 상기 객체의 일부 이미지를 획득하는 단계를 포함할 수 있다. 상기 방법은, 상기 객체의 일부 이미지를 제1 AI 모델에 적용함으로써 상기 객체의 상기 라벨에 대응하는 영역을 관 심 영역으로 식별하는 단계를 포함할 수 있다. 상기 방법은, 상기 제1 카메라보다 화각이 넓은 제2 카메라를 이 용하여 상기 객체의 전체 이미지를 획득하는 단계를 포함할 수 있다. 상기 방법은, 상기 객체의 전체 이미지를 제2 AI 모델에 적용함으로써 상기 객체의 3차원 형상 타입을 식별하는 단계를 포함할 수 있다. 상기 방법은, 상 기 객체의 3차원 형상 타입에 대응하는 3차원 파라미터를 획득하는 단계를 포함할 수 있다. 상기 방법은, 상기 관심 영역에 관한 정보 및 상기 3차원 파라미터에 기초하여 상기 라벨의 원근 변환(perspective transformation)을 수행함으로써, 상기 라벨의 굴곡 형상이 평평하게 된 플랫 라벨 이미지를 획득하는 단계를 포함할 수 있다. 상기 방법은, 상기 플랫 라벨 이미지로부터 상기 객체와 관련된 정보를 획득하는 단계를 포함 할 수 있다. 본 개시의 일 측면에 따르면, 이미지를 처리하는 전자 장치가 제공될 수 있다. 상기 전자 장치는, 제1 카메라, 제2 카메라, 하나 이상의 인스트럭션을 저장하는 메모리, 및 상기 메모리에 저장된 상기 하나 이상의 인스트럭 션을 실행하는 적어도 하나의 프로세서를 포함할 수 있다. 상기 적어도 하나의 프로세서는, 상기 하나 이상의 인스트럭션을 실행함으로써, 상기 제1 카메라를 이용하여 객체의 라벨을 포함하는 상기 객체의 일부 이미지를 획득할 수 있다. 상기 적어도 하나의 프로세서는, 상기 하나 이상의 인스트럭션을 실행함으로써, 상기 객체의 일부 이미지를 제1 AI 모델에 적용함으로써 상기 객체의 상기 라벨에 대응하는 영역을 관심 영역으로 식별할 수 있다. 상기 적어도 하나의 프로세서는, 상기 하나 이상의 인스트럭션을 실행함으로써, 상기 제1 카메라보다 화 각이 넓은 상기 제2 카메라를 이용하여 상기 객체의 전체 이미지를 획득할 수 있다. 상기 적어도 하나의 프로세 서는, 상기 하나 이상의 인스트럭션을 실행함으로써, 상기 객체의 전체 이미지를 제2 AI 모델에 적용함으로써 상기 객체의 3차원 형상 타입을 식별할 수 있다. 상기 적어도 하나의 프로세서는, 상기 하나 이상의 인스트럭션 을 실행함으로써, 상기 객체의 3차원 형상 타입에 대응하는 3차원 파라미터를 획득할 수 있다. 상기 적어도 하 나의 프로세서는, 상기 하나 이상의 인스트럭션을 실행함으로써, 상기 관심 영역에 관한 정보 및 상기 3차원 파 라미터에 기초하여 상기 라벨의 원근 변환(perspective transformation)을 수행함으로써, 상기 라벨의 굴곡 형 상이 평평하게 된 플랫 라벨 이미지를 획득할 수 있다. 상기 적어도 하나의 프로세서는, 상기 하나 이상의 인스 트럭션을 실행함으로써, 상기 플랫 라벨 이미지로부터 상기 객체와 관련된 정보를 획득할 수 있다. 본 개시의 일 측면에 따르면, 전자 장치가 이미지를 처리하여 왜곡을 제거하는, 전술 및 후술하는 방법들 중 어 느 하나를 실행시키기 위한 프로그램이 기록된 컴퓨터 판독 가능 기록매체를 제공할 수 있다."}
{"patent_id": "10-2022-0133618", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 개시에서, \"a, b 또는 c 중 적어도 하나\" 표현은 \" a\", \" b\", \" c\", \"a 및 b\", \"a 및 c\", \"b 및 c\", \"a, b 및 c 모두\", 혹은 그 변형들을 지칭할 수 있다. 본 개시에서 사용되는 용어는 본 개시에서의 기능을 고려하면서 가능한 현재 널리 사용되는 일반적인 용어들을 선택하였으나, 이는 당 분야에 종사하는 기술자의 의도 또는 판례, 새로운 기술의 출현 등에 따라 달라질 수 있 다. 또한, 특정한 경우는 출원인이 임의로 선정한 용어도 있으며, 이 경우 해당되는 설명 부분에서 상세히 그 의미를 기재할 것이다. 따라서 본 개시에서 사용되는 용어는 단순한 용어의 명칭이 아닌, 그 용어가 가지는 의 미와 본 개시의 전반에 걸친 내용을 토대로 정의되어야 한다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함할 수 있다. 기술적이거나 과학적인 용어를 포함해서 여기서 사용되는 용어들은 본 명세서에 기재된 기술 분야에서 통상의 지식을 가진 자에 의해 일반적으로 이해되는 것과 동일한 의미를 가질 수 있다. 또한, 본 명세서에서 사용되는 '제1' 또는 '제2' 등과 같이 서수를 포함하는 용어는 다양한 구성 요소들을 설명하는데 사용할 수 있지만, 상기 구성 요소들은 상기 용 어들에 의해 한정되어서는 안 된다. 상기 용어들은 하나의 구성 요소를 다른 구성 요소로부터 구별하는 목적으 로만 사용된다. 명세서 전체에서 어떤 부분이 어떤 구성요소를 \"포함\"한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다른 구성요소를 제외하는 것이 아니라 다른 구성요소를 더 포함할 수 있음을 의미한다. 또한, 명세서에 기재된 \"부\", \"모듈\" 등의 용어는 적어도 하나의 기능이나 동작을 처리하는 단위를 의미하며, 이는 하드웨어 또는 소 프트웨어로 구현되거나 하드웨어와 소프트웨어의 결합으로 구현될 수 있다. 아래에서는 첨부한 도면을 참고하여 본 개시의 실시예에 대하여 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자가 용이하게 실시할 수 있도록 상세히 설명한다. 그러나 본 개시는 여러 가지 상이한 형태로 구현될 수 있으며 여기에서 설명하는 실시예에 한정되지 않는다. 그리고 도면에서 본 개시를 명확하게 설명하기 위해서 설 명과 관계없는 부분은 생략하였으며, 명세서 전체를 통하여 유사한 부분에 대해서는 유사한 도면 부호를 붙였다. 또한, 각각의 도면에서 사용된 도면 부호는 각각의 도면을 설명하기 위한 것일 뿐, 상이한 도면들 각각 에서 사용된 상이한 도면 부호가 상이한 요소를 나타내기 위한 것은 아니다. 이하 첨부된 도면을 참고하여 본 개시를 상세히 설명하기로 한다. 도 1은 본 개시의 일 실시예에 따른 전자 장치가 이미지의 왜곡을 제거하는 일 예시를 나타내는 도면이다. 도 1을 참조하면, 일 실시예에 따른 전자 장치는 카메라 및 디스플레이를 포함하는 장치일 수 있다. 전자 장치는 카메라를 통해 이미지(정지 이미지 및/또는 비디오)를 촬영하고, 디스플레이를 통해 이미지를 출 력하는 장치일 수 있다. 예를 들어, 전자 장치는 스마트 TV, 스마트 폰, 태블릿 PC, 랩탑 PC, 등을 포함 할 수 있으나, 이에 한정되는 것은 아니다. 전자 장치는 카메라 및 디스플레이를 포함하는 다양한 종류 및 형태의 전자 장치로 구현될 수 있다. 또한, 전자 장치는 오디오를 출력하기 위한 스피커를 포함할 수 도 있다. 일 실시예에서, 전자 장치의 사용자는 전자 장치의 카메라를 이용하여 객체를 촬영할 수 있다. 전자 장치는 객체의 적어도 일부를 포함하는 이미지를 획득할 수 있다. 본 개시에서, 이미지 내의 객체의 표면에 인식되어야 할 정보가 있는 경우, 이를 '관심 영역'이라 지 칭한다. 예를 들어, 객체의 표면에 부착된 라벨 영역이 관심 영역이 될 수 있다. 일 실시예에서, 전자 장 치는 객체의 관심 영역으로부터, 객체와 관련된 정보를 추출할 수 있다.본 개시에서는, 관심 영역의 일 예시로, 상품의 '라벨'에 대한 왜곡을 제거하는 것을 설명한다. 여기서 라 벨이란, 종이, 스티커, 천 등으로 제작되어 상품에 부착되는 것으로, 라벨에는 상품의 상표나 상품명 등이 인쇄 되어 있을 수 있다. 또한, 상품의 라벨은 상품과 관련된 다양한 정보, 예를 들어, 상품의 성분, 사용법, 사용량, 취급상의 주의 사항, 상품의 가격, 부피, 용량 등이 포함될 수 있다. 본 개시에서 전자 장치는 객체에 포함된 적어도 하나의 라벨에 대응하는 영역을 관심 영역으로 식별하고, 적어도 하나의 라벨에 대응하는 영역으로부터 객체와 관련된 정보를 획득할 수 있다. 객체(10 0)가 3차원 형상인 경우, 2차원적인 이미지 내에서 객체의 라벨의 형상이 왜곡될 수 있다. 이에 따라, 전자 장치가 객체의 라벨로부터 획득한 정보(예를 들어, 로고, 아이콘, 텍스트 등)의 정확도가 저하될 수 있다. 일 실시예에 따른 전자 장치는, 관심 영역(예를 들어, 적어도 하나의 라벨)으로부 터 정확한 정보를 추출하기 위해, 객체의 이미지를 이용하여 왜곡 없는 라벨 이미지를 획득할 수 있다. 여기서, 왜곡 없는 라벨 이미지는 객체의 관심 영역의 왜곡을 감소시키거나 및/또는 제거한 이미지를 말한다. 예를 들어, 왜곡 없는 라벨 이미지는 라벨 영역의 굴곡 왜곡이 감소되거나 제거 되어 평평하게 된 이미지일 수 있다. 본 개시에서, 왜곡 없는 라벨 이미지는 플랫 라벨 이미지로도 지칭될 수 있다. 일 실시예에 따른 전자 장치는 왜곡 없는 이미지를 생성하기 위해, 객체의 3차원 정보를 추정 할 수 있다. 전자 장치는 객체의 3차원 정보에 기초하여 관심 영역을 평면으로 변환함으로써, 왜곡 없는 이미지를 획득한다. 객체의 3차원 정보는, 객체의 3차원 형상과 관련된 3차원 파라미 터 또는 객체를 촬영하는 카메라와 관련된 3차원 파라미터를 포함할 수 있다. 또한, 3차원 형상은 구, 정육면체, 실린더 등을 포함할 수 있으나 이에 한정되는 것은 아니다. 본 개시에서, '3차원 파라미터'란, 객체의 3차원 형상과 관련된 기하학적 특징을 나타내는 요소들을 말한 다. 3차원 파라미터는 예를 들어, 객체의 높이 및 반지름 정보(또는, 가로, 세로 정보), 객체의 3차 원 공간 상에서의 3차원 기하학적 변환을 위한 이동(translation) 및 회전(rotation) 정보, 객체를 촬영한 전자 장치의 카메라의 초점 거리 정보 등을 포함할 수 있으나, 이에 한정되는 것은 아니다. 3차원 파라미 터는 변수이며, 3차원 파라미터 중 어느 하나의 값이 변경됨에 따라 3차원 형상 또한 변경될 수 있다. 3차원 파 라미터 요소들이 모여 3차원 파라미터 셋을 구성할 수 있다. 이러한 3차원 파라미터 셋에 따라 결정되는, 객체 의 3차원 형상을 나타낼 수 있는 정보를 본 개시에서는 '3차원 정보'로 지칭한다. 본 개시에서, '객체의 3차원 정보'란 이미지에 포함되는 객체의 3차원 형상을 나타낼 수 있도록 파라미터 값(예를 들어, 가로 값, 세로 값, 높이 값, 반지름 값 등)이 튜닝된 3차원 파라미터를 말한다. 객체 의 3차원 정보는 반드시 객체의 절대적인 가로, 세로, 높이, 반지름 등의 값을 나타내는 3차원 파라 미터들로 구성될 필요는 없으며, 객체의 3차원 비율을 나타내는 상대적인 값을 나타내는 3차원 파라미터들 로 구성될 수 있다. 즉, 전자 장치는 객체의 3차원 정보가 있으면, 객체와 동일한 비율을 갖는 3차원 형상의 객체를 렌더링할 수 있다. 일 실시예에 따른 전자 장치는, 관심 영역의 왜곡을 제거하는 이미지 처리 동작을 수행하기 위해, 객체의 적어도 일부를 포함하는 이미지로부터 관심 영역을 식별하고, 객체의 3차원 형상 타입을 식별하며, 객체의 관심 영역 및 객체의 3차원 형상 타입에 기초하여, 객체의 3차원 정보를 추정할 수 있다. 그리고 전자 장치는 객체의 3차원 정보에 기초하여 왜곡 없는 이미지 를 생성할 수 있다. 일 실시예에 의하면, 전자 장치는 왜곡 없는 이미지로부터 객체 정보를 추출하고, 왜곡 없는 이미지 및/또는 왜곡 없는 이미지로부터 추출된 객체 정보를 사용자에게 제공할 수도 있다. 전자 장치가 이미지 처리 동작들을 통해 관심 영역의 왜곡을 제거하거나 왜곡 없는 이미지로부 터 정보를 추출하는 구체적인 동작들에 대해서는, 후술하는 도면들과 그에 대한 설명에서 더 상세하게 서술하기 로 한다. 도 2는 본 개시의 일 실시예에 따른 전자 장치가 이미지를 처리하는 방법을 설명하기 위한 흐름도이다. 단계 S210에서, 일 실시예에 전자 장치는 제1 카메라를 이용하여 적어도 하나의 라벨을 포함하는 객체의 제1 이미지를 획득한다. 전자 장치는 사용자의 조작을 통해 제1 카메라를 활성화할 수 있다. 예를 들어, 사용자는 객체에 관한 정보를 얻기 위해 전자 장치의 카메라를 활성화하여 객체를 촬영할 수 있다. 사용 자는 카메라를 실행하기 위한 하드웨어 버튼 또는 아이콘을 터치하여 카메라를 활성화할 수도 있고, 음성 명령(예: 하이 빅스비 카메라 켜줘, 하이 빅스비 사진 찍어서 라벨 정보 보여줘)을 통해 카메라를 활성화할 수도 있 다. 일 실시예에서, 제1 카메라는 망원 카메라, 광각 카메라, 초광각 카메라 중 하나일 수 있으며, 제1 이미지는, 망원 카메라로 촬영된 이미지, 광각 카메라로 촬영된 이미지, 초광각 카메라로 촬영된 이미지 중 하나일 수 있 다. 일 실시예에서, 전자 장치는 하나 이상의 카메라를 포함할 수 있다. 예를 들어, 전자 장치는 제1 카메라, 제2 카메라 등으로 구성되는 멀티카메라를 포함할 수 있다. 전자 장치에 카메라가 복수 개 포함 되는 경우, 각각의 카메라의 사양은 상이할 수 있다. 예를 들어 복수의 카메라는, 서로 다른 초점 거리 및 화각 을 갖는, 망원 카메라, 광각 카메라, 초광각 카메라 등을 포함할 수 있다. 다만, 전자 장치에 포함되는 카메라의 종류는 전술한 예시에 한정되는 것은 아니다. 전자 장치에 카메라가 복수 개 포함된 경우, 제1 이미지는, 복수의 카메라를 통해 획득된 이미지들을 합성한 이미지일 수도 있다. 제1 이미지는 전자 장치(200 0)의 화면에서 표시되는 프리뷰 이미지를 캡쳐하여 저장한 것일 수 있고, 이미 촬영되어 전자 장치에 저장된 것 일 수 있으며, 전자 장치의 외부로부터 획득된 이미지일 수 있다. 제1 이미지는 적어도 하나의 라벨을 포 함하는 객체의 일부를 촬영한 이미지일 수 있으며, 또는, 객체의 전체를 촬영한 이미지일 수 있다. 한편, 일 실 시예에 의하면, 제1 이미지는, 제1 카메라에 의해 연속적으로 촬영된 파노라마 이미지일 수도 있다. 단계 S220에서, 일 실시예에 따른 전자 장치는 제1 이미지를 제1 AI 모델에 적용함으로써, 제1 이미지 내 에서 적어도 하나의 라벨에 대응하는 영역을 관심 영역으로 식별한다. 예를 들어, 전자 장치는 제1 카메 라를 통해 제1 이미지가 획득된 경우, 제1 이미지를 제1 AI 모델에 적용할 수 있다. 이때, 제1 AI 모델은 제1 이미지 내에서 관심 영역을 추론하고, 관심 영역에 관련된 데이터를 출력할 수 있다. 한편, 본 개시에서 제1 이 미지를 제1 AI 모델에 적용한다는 것은, 제1 이미지 자체를 제1 AI 모델에 적용하는 것뿐만 아니라, 제1 이미지 를 전처리하여 제1 AI 모델에 적용하는 것도 포함할 수도 있다. 예를 들어, 전자 장치는 제1 이미지에서 일부 영역을 잘라낸 이미지(cropped image), 제1 이미지를 리사이즈한 이미지, 또는 제1 이미지에서 일부를 잘 라내고 리사이즈한 이미지를 제1 AI 모델에 적용할 수도 있다. 본 개시에서, 제1 AI 모델은 관심 영역 식별 모델로 지칭될 수 있다. 관심 영역 식별 모델은, 이미지를 입력 받 아 이미지 내 객체의 관심 영역에 관련된 데이터를 출력하도록 훈련된 인공지능 모델일 수 있다. 예를 들어, 관 심 영역 식별 모델은 이미지 내에서 라벨에 대응하는 영역을 관심 영역으로 추론하도록 훈련된 인공지능 모델일 수 있다. 일부 실시예에서, 전자 장치는 관심 영역 식별 모델을 이용하여, 객체의 표면의 관심 영역(예를 들어, 상품에 부착된 라벨 등)을 식별할 수 있다. 일부 실시예에서, 전자 장치는 관심 영역 식별 모델을 이용하여 객체의 관심 영역을 나타내는 키포인트들(본 개시에서, 제1 키포인트들로도 지칭됨)을 식별할 수 있다. 예를 들어, 제1 AI 모델은 제1 이미지 내에서 적어도 하나의 라벨의 가장자리(edge)를 나타내는 키포인트 들 (또는 좌표 값)에 관한 정보를 출력할 수 있다. 제1 AI 모델이 제1 이미지 내에서 관심 영역을 추정하는 동 작에 대해서는 도 5를 참조하여 더 자세히 살펴보기로 한다. 한편, 본 개시에서는 설명의 편의를 위해 객체의 관심 영역으로 라벨 영역을 예시로 설명하나, 관심 영역은 이 에 한정되지 않는다. 전자 장치에 의해, 객체로부터 추출하고자 하는 정보가 있는 또다른 영역들도 관심 영역으로 설정될 수 있으며, 본 개시의 실시예들이 동일/유사하게 적용될 수 있다. 단계 S230에서, 일 실시예에 따른 전자 장치는 제1 이미지를 제2 AI 모델에 적용함으로써 객체의 3차원 형상 타입에 관한 데이터를 획득한다. 예를 들어, 전자 장치는 제1 카메라를 통해 제1 이미지가 획득된 경우, 제1 이미지를 제2 AI 모델에 적용할 수 있다. 이때, 제2 AI 모델은 제1 이미지에 포함된 객체의 3차원 형 상 타입을 추론하고, 객체의 3차원 형상 타입에 관련된 데이터를 출력할 수 있다. 본 개시에서, 제2 AI 모델은 객체 3차원 형상 식별 모델로 지칭될 수 있다. 객체 3차원 형상 식별 모델은, 이미지를 입력 받아 이미지 내 객 체의 3차원 형상 타입에 관련된 데이터를 출력하도록 훈련된 인공지능 모델일 수 있다. 예를 들어, 객체 3차원 형상 식별 모델은, 이미지 내 객체의 3차원 형상 타입을 추론하도록 훈련된 인공지능 모델일 수 있다. 일부 실 시예에서, 전자 장치는 3차원 객체 형상 식별 모델을 이용하여, 제1 이미지 내에 포함된 객체의 3차원 형 상 타입(예를 들어, 구, 정육면체, 실린더 등)을 식별할 수 있다. 전자 장치가 3차원 객체 형상 식별 모 델을 이용하여 객체의 3차원 형상 타입을 식별하는 동작에 대해서는 도 4를 참조하여 후에 더 살펴보기로 한다. 이미지 내의 객체가 3차원 형상인 경우, 2차원적인 이미지 내에서 3차원 객체의 표면에 부착되어있는 관심 영역 이 왜곡됨으로 인해 관심 영역 내의 정보(예를 들어, 로고, 아이콘, 텍스트 등)의 식별의 정확도가 저하될 수 있다. 예를 들어, 객체가 실린더 타입의 상품인 경우, 실린더 표면에 달라붙는 상품의 라벨은 객체의 곡면 표면에 부착되어 있으므로, 실린더 타입의 상품을 촬영한 이미지 내에서 관심 영역인 상품의 라벨은 왜곡되어 있다. 일 실시예에 따른 전자 장치는 객체의 3차원 형상을 식별하고, 관심 영역의 왜곡을 제거하기 위하여, 식 별된 객체의 3차원 형상 타입에 관한 데이터를 이용할 수 있다. 일 실시예에 의하면, 제1 이미지를 제1 AI 모델에 적용하여 제1 이미지 내에서 적어도 하나의 라벨에 대응하는 영역을 관심 영역으로 식별하는 단계 S220과 제1 이미지를 제2 모델에 적용하여 제1 이미지에 포함된 객체의 3 차원 형상 타입에 관한 데이터를 획득하는 단계 S230은 병렬적으로 수행될 수 있다. 예를 들어, 전자 장치 는, 제1 카메라를 통해 제1 이미지를 획득하는 경우, 제1 이미지를 제1 AI 모델과 제2 AI 모델에 각각 입 력할 수 있다. 이때, 제1 AI 모델이 제1 이미지 내에서 적어도 하나의 라벨에 대응하는 영역을 관심 영역으로 추론하는 동작과 제2 AI 모델이 제1 이미지에 포함된 객체의 3차원 형상 타입을 추론하는 동작은 병렬적으로 이 루어질 수 있다. 일 실시예에 의하면, 단계 S220과 단계 S230 중 어느 하나의 단계가 먼저 수행될 수도 있다. 예를 들어, 전자 장치는, 제1 이미지를 제1 AI 모델에 먼저 입력하여 제1 AI 모델이 관심 영역을 추론한 결과를 확인한 후 에 제1 이미지를 제2 AI 모델에 입력할 수도 있다. 반대로, 전자 장치는, 제1 이미지를 제2 AI 모델에 먼 저 입력하여 제2 AI 모델이 제1 이미지 내에 포함된 객체의 3차원 형상 타입을 추론한 결과를 확인한 후에 제1 이미지를 제1 AI 모델에 입력할 수도 있다. 단계 S240에서, 일 실시예에 따른 전자 장치는 관심 영역으로 식별된 적어도 하나의 라벨에 대응하는 영 역 및 객체의 3차원 형상 타입에 관한 데이터에 기초하여, 객체, 적어도 하나의 라벨 및 제1 카메라 중 적어도 하나와 관련된 3차원 파라미터 값들을 획득한다. 일부 실시예에서, 3차원 파라미터의 요소들은 객체의 3차원 형 상과 관련된 가로, 세로, 높이, 반지름 정보 등을 포함할 수 있다. 일부 실시예에서, 3차원 파라미터의 요소들 은 객체의 3차원 공간 상에서의 3차원 기하학적 변환을 위한 이동(translation) 및 회전(rotation) 정보를 포함 할 수 있다. 이동 및 회전 정보는 전자 장치의 카메라가 객체를 어떤 위치에서 어떤 각도로 바라보고 촬 영한 것인지를 나타내는 정보일 수 있다. 일부 실시예에서, 3차원 파라미터의 요소들은 객체를 촬영한 전자 장 치의 카메라의 초점 거리 정보를 포함할 수 있다. 다만, 3차원 파라미터는 전술한 예시에 한정되는 것은 아니며, 전자 장치가 객체의 3차원 기하학적 특징을 식별하고 관심 영역의 왜곡을 제거하기 위한 다른 정 보들을 더 포함할 수 있다. 일 실시예에서, 3차원 파라미터는 객체의 3차원 형상에 대응하도록 결정된다. 즉, 각각의 3차원 형상의 타입(이 하, 3차원 형상 타입)마다 이에 대응하는 3차원 파라미터의 요소는 상이할 수 있다. 예를 들어, 3차원 형상이 실린더 타입인 경우, 실린더 타입에 대응하는 3차원 파라미터는 반지름을 포함할 수 있으나, 3차원 형상이 정육 면체 타입인 경우, 정육면체 타입에 3차원 파라미터는 반지름을 포함하지 않을 수 있다. 단계 S230에서 획득되 는 객체의 3차원 형상 타입에 대응하는 3차원 파라미터란, 객체의 정확한 3차원 정보를 획득하기 위해 사용되는 초기값들로 설정되어 있을 수 있다. 전자 장치는 초기값을 갖는 3차원 파라미터를 객체의 3차원 정보를 나타내도록 파라미터 값들을 미세 조정하여, 객체의 3차원 정보를 나타내는 3차원 파라미터를 획득할 수 있다. 일 실시예에서, 객체의 3차원 형상 타입이 실린더(또는, 병(bottle))인 경우, 3차원 파라미터의 요소는 객체의 가로, 세로, 높이, 반지름 정보, 객체의 3차원 공간 상에서의 이동 및 회전 정보, 객체를 촬영한 전자 장치 의 카메라의 초점 거리 정보를 포함할 수 있으나, 이에 한정되는 것은 아니다. 전술한 것과 같이, 객체의 3차원 형상 타입이 직육면체인 경우, 직육면체 타입에 대응하는 3차원 파라미터의 요소는 실린더 타입에 대응하 는 3차원 파라미터의 요소와 상이할 수 있다. 일 실시예에서, 전자 장치는 적어도 하나의 라벨의 굴곡 형상을 나타내는 3차원 정보를 획득할 수 있다. 전자 장치는 3차원 파라미터의 초기값이 객체의 3차원 파라미터의 정답 값에 근사 또는 정합하도록 미세 조정함으로써, 조정된 3차원 파라미터의 최종 값이 객체의 3차원 정보를 나타내도록 만들 수 있다. 전술한 예시 인, 3차원 형상 타입이 실린더(또는, 병)인 경우를 계속하여 설명하면, 전자 장치는 3차원 파라미터의 값 들 중 가로, 세로, 높이, 반지름이 객체의 가로, 세로, 높이의 상대적인 비율 또는 절대적인 값을 나타내도록 조정할 수 있다. 또한, 전자 장치는 3차원 파라미터의 값들 중 이동 및 회전 값이, 객체의 3차원 공간 상 에서의 이동 정도 및 회전 정도를 나타내는 값이 되도록 조정할 수 있다. 또한, 전자 장치는 3차원 파라 미터의 값들 중 초점 거리 값이, 객체를 촬영한 전자 장치의 카메라의 초점 거리를 나타내는 값이 되도록 조정할 수 있다. 일 실시예에서, 전자 장치는 객체의 3차원 정보를 추정하기 위해 임의의 가상 객체를 설정할 수 있다. 가 상 객체는, 단계 S230에서 식별된 객체의 3차원 형상 타입과 동일한 형상 타입을 가지며, 초기 파라미터 값들을갖는 3차원 파라미터를 이용하여 렌더링 가능한 객체일 수 있다. 전자 장치는 3차원 가상 객체를 2차원으 로 투영하고, 가상 객체의 키포인트들(본 개시에서, 제2 키포인트들로도 지칭됨)을 설정할 수 있다. 전자 장치는 가상 객체의 키포인트들이 단계 S220에서 획득된 객체의 키포인트들(제1 키포인트들)에 정합 하도록 3차원 파라미터 값들을 미세 조정할 수 있다. 3차원 파라미터의 미세 조정 작업이 반복 수행됨에 따라, 3차원 파라미터의 최종 값들이 결정되고, 3차원 파라미터의 최종 값들이 객체의 3차원 정보를 나타내게 되면, 가상 객체로부터 획득된 제2 키포인트들이 객체의 제1 키포인트들에 정합된다. 전자 장치가 미세 조정 작 업을 통해 객체의 3차원 정보를 나타내도록 3차원 파라미터의 값들을 변경하는 동작은, 도 6a에 대한 설명에서 더 기술한다. 단계 S240에서 서술한, 전자 장치가 3차원 파라미터 값들을 획득한다고 하는 것은, 전술한 조정 작업을 통해 획득된 3차원 파라미터의 최종 값을 획득하는 것을 말한다. 단계 S250에서, 일 실시예에 따른 전자 장치는 3차원 파라미터 값들에 기초하여, 적어도 하나의 라벨의 굴곡 형상을 추정한다. 전술한 단계들을 통해 값이 조정된 3차원 파라미터는, 이미지 내 객체의 3차원 정보(예를 들어, 객체의 가로, 세로, 높이, 반지름, 객체의 표면에 부착된 라벨의 굴곡 정도(각도) 등)를 나타낸다. 전자 장치는 3차원 파라미터를 이용하여 객체의 표면의 관심 영역인, 라벨을 나타내는 2차원 메시(mesh)를 생성할 수 있다. 여기서 2차원 메시(mesh) 데이터는 3차원 파라미터 값들을 이용하여, 3차원 공간 상의 라벨 표면 좌표를 2차원으로 투 영한 결과로서, 제1 이미지 내의 라벨 표면 왜곡 정보를 의미할 수 있다. 다만, 이에 한정되는 것은 아니며, 전 자 장치는 라벨의 굴곡 형상 뿐 아니라 라벨이 부착되어 있는 객체 표면의 굴곡 형상을 추정할 수도 있다. 단계 S260에서, 일 실시예에 따른 전자 장치는 적어도 하나의 라벨에 대한 원근 변환을 수행함으로써, 라 벨의 굴곡 형상이 평평하게 된, 플랫 라벨 이미지를 획득한다. 전자 장치는 원근 변환(perspective transform)을 이용하여, 라벨의 굴곡 형상을 평평하게 변환할 수 있 다. 평평하게 변환된 라벨의 이미지는, 객체의 3차원 형상으로 인한 촬영 시 왜곡 등이 제거 및/또는 감소된 이 미지이므로, 본 개시에서는 왜곡 없는 이미지, 또는 플랫 라벨 이미지로 지칭될 수 있다. 한편, 단계 S240 내지 단계 S260의 동작에는 왜곡 제거 모델이 이용될 수 있다. 왜곡 제거 모델은, 객체 내의 관심 영역 정보 및 객체와 관련된 3차원 파라미터 값들을 입력 받아 왜곡 없는 이미지를 출력하도록 훈련된 인 공지능 모델일 수 있다. 관심 영역 정보는 관심 영역의 이미지 및 관심 영역의 키포인트들의 좌표를 포함할 수 있다. 예를 들어, 왜곡 제거 모델은, 곡면을 포함하는 3차원 객체의 표면에 부착되어 굴곡이 있는 채로 촬영된 라벨을 포함하는 이미지를 입력 받아, 라벨이 평평하게 된 플랫 라벨 이미지를 획득할 수 있다. 일 실시예에서, 전자 장치는 플랫 라벨 이미지로부터 객체와 관련된 정보를 획득할 수 있다. 전자 장치 는 관심 영역 내 정보를 추출하기 위한 검출 모델을 이용하여 관심 영역 내의 로고, 아이콘, 텍스트 등을 식별할 수 있다. 정보 검출 모델은 전자 장치의 메모리에 저장될 수도 있고, 외부 서버에 저장될 수도 있 다. 전자 장치는 전술한 단계들을 통해, 이미지 내 객체의 3차원 정보를 추론하고, 추론된 객체의 3차원 정보를 이용하여 정밀한 원근 변환을 수행함으로써 관심 영역의 왜곡을 제거하므로, 향상된 정확도로 관심 영역 내의 정보를 추출할 수 있다. 전자 장치가 정보 검출 모델을 이용하여 플랫 라벨 이미지로부터 객체와 관 련된 정보를 획득하는 동작에 대해서는 도 7을 참조하여 후에 조금 더 살펴보기로 한다. 이하에서는, 도 3을 참조하여, 전자 장치가 제1 AI 모델(관심 영역 식별 모델) 및 제2 AI 모델(객체 3차 원 형상 식별 모델)을 이용하여, 기하학적 왜곡이 포함된 제1 이미지로부터 왜곡이 제거된 플랫 라벨 이미지를 획득하는 동작에 대해서 더 살펴보기로 한다. 도 3은 본 개시의 일 실시예에 따른 전자 장치가 이미지를 처리하는 동작을 전반적으로 설명하기 위한 도면이다. 도 3을 참조하면, 일 실시예에 따른 전자 장치는 객체의 이미지 이하, 객체 이미지를 획득할 수 있다. 객체는 적어도 하나의 라벨을 포함할 수 있다. 일 실시예에서, 전자 장치는 사용자의 카메라 제어에 의해 객체를 캡쳐함으로써 객체의 이미지 를 획득할 수 있다. 또는, 전자 장치는 이미 캡쳐된 객체의 이미지를 다른 전자 장치(예를 들어, 서버, 다른 사용자의 전자 장치 등)로부터 수신할 수 있다. 일 실시예에서, 전자 장치는 관심 영역 식별 모델을 이용하여 관심 영역을 식별할 수 있다. 관 심 영역 식별 모델은 이미지를 입력 받아 이미지 내 객체의 관심 영역에 관련된 데이터를 출력 하도록 훈련된 인공지능 모델일 수 있다. 관심 영역에 관련된 데이터는 예를 들어, 관심 영역의 키포 인트들 및/또는 이들의 좌표 등일 수 있으나, 이에 한정되는 것은 아니다. 이하에서, 관심 영역에 관련된 데이터는 설명의 편의를 위해 관심 영역으로 지칭된다. 도 3의 예시에서, 관심 영역은 객체의 표면에 부착된 라벨이지만, 관심 영역의 종류는 이에 한정되는 것은 아니다. 일 실시예에서, 전자 장치는 객체 이미지를 관심 영역 식별 모델의 입력 데이터로 사용할 수 있다. 또한, 전자 장치는 객체 이미지에 소정의 전처리 알고리즘을 적용하여 관심 영역을 식별 하기에 보다 적합하도록 처리할 수 있다. 예를 들어, 전자 장치는 객체 이미지의 일부를 잘라내고 리사이즈하여 획득된, 잘라낸 객체 이미지를 관심 영역 식별 모델의 입력 데이터로 사용할 수 있다. 이 경우, 객체 이미지에서 잘라내어진 영역은, 관심 영역 이외의 영역일 수 있다. 또한, 잘라낸 객체 이미 지에는 객체의 적어도 일부가 포함될 수 있으며, 객체의 관심 영역이 포함될 수 있다. 일 실시예에서, 전자 장치는 객체 3차원 형상 식별 모델을 이용하여 객체의 3차원 형상 타입을 식별할 수 있다. 객체 3차원 형상 식별 모델은 이미지를 입력 받아 이미지 내 객체의 3차원 형상 타 입에 관한 데이터를 출력하도록 훈련된 인공지능 모델일 수 있다. 도 3의 예시에서, 3차원 형상 타입(32 2)은 예시적으로 실린더로 도시되었지만, 이에 한정되는 것은 아니다. 예를 들어, 3차원 형상 타입은 구, 정육면체 등일 수 있다. 이하에서, 3차원 형상 타입에 관련된 데이터는 설명의 편의를 위해 3차원 형상 타 입으로 지칭된다. 전자 장치는 3차원 형상 타입에 기초하여 3차원 파라미터의 초기 값들을 획득할 수 있다. 3차 원 파라미터는 3차원 형상 타입에 기초하여 결정할 수 있다. 예를 들어, 3차원 형상 타입이 실 린더 타입인 경우, 실린더 타입에 대응하는 3차원 파라미터의 요소들은 높이, 반지름, 객체 표면의 관심 영역의 각도, 3차원 공간 상의 이동 좌표 및 화전 좌표, 카메라의 초점 거리 중 적어도 하나를 포함할 수 있다. 일 실시예에서, 전자 장치는 왜곡 제거 모델을 이용하여 왜곡 없는 이미지를 획득할 수 있다. 왜곡 제거 모델은, 관심 영역, 3차원 파라미터, 객체 이미지(또는, 잘라낸 객체 이미지 )를 입력 받아, 왜곡 없는 이미지를 출력하도록 훈련된 인공지능 모델일 수 있다. 도 3의 예시에서는, 관심 영역이 라벨이고, 객체는 병이므로, 왜곡 없는 이미지는 병 표면에 부착된 라 벨의 왜곡을 제거한, 플랫 라벨 이미지일 수 있다. 다만, 왜곡 없는 이미지는 플랫 라벨 이미지에 한정되 는 것은 아니다. 왜곡 없는 이미지는, 관심 영역의 타입, 3차원 형상 타입에 따라 획득 가능한 모든 유형의 이미지를 포함할 수 있다. 일 실시예에서, 왜곡 제거 모델은 3차원 파라미터의 초기 값들을 튜닝하여, 3차원 파라미터의 최종 값들이 객체의 3차원 정보를 나타내도록 할 수 있다. 예를 들어, 왜곡 제거 모델에 의해, 객체 의 가로, 세로, 높이, 반지름, 객체의 표면에 부착된 라벨의 굴곡 정도(각도) 등의 상대적 또는 절대적인 값들이 획득될 수 있다. 왜곡 제거 모델은, 객체의 3차원 정보를 나타내는 3차원 파라미터의 최 종 값들에 기초하여, 왜곡 없는 이미지를 생성할 수 있다. 예를 들어, 왜곡 제거 모델은 3차원 파라 미터의 최종 값들에 기초하여, 굴곡진 객체의 표면에 부착된 라벨의 굴곡이 평평하게 되도록 변환함 으로써, 라벨의 왜곡이 제거된 플랫 라벨 이미지를 왜곡 없는 이미지로 획득할 수 있다. 일 실시예에서, 전자 장치는 왜곡 제거 모델의 동작은 일련의 데이터 처리/연산으로 대체될 수 있다. 전자 장치는 왜곡 제거 모델을 이용하지 않고, 일련의 데이터 처리/연산을 수행하여 왜곡 없 는 이미지를 획득할 수 있다. 예를 들어, 전자 장치는 객체의 3차원 정보를 추정하기 위해 임의의 가상 객체를 설정할 수 있다. 임의의 가상 객체는 3차원 파라미터의 초기 값들에 기초하여 생성될 수 있다. 전자 장치는 임의의 가상 객체로부터 임의의 관심 영역을 설정하고, 임의의 가상 객체의 임의의 관 심 영역과 객체의 관심 영역이 매칭되도록 3차원 파라미터의 값들을 조정함으로써, 3차원 파라미터 의 최종 값들을 획득할 수 있다. 전자 장치는 3차원 파라미터의 최종 값들에 기초하여, 왜곡 없는 이미지를 생성할 수 있다. 전자 장치가 객체의 3차원 정보를 추정하기 위해 임의의 가상 객체를 설정하는 동작에 대해서는 도 6a를 참조하여 후에 더 살펴보기로 한다.도 4는 본 개시의 일 실시예에 따른 전자 장치가 객체의 3차원 형상을 식별하는 동작을 설명하기 위한 도면이다. 일 실시예에서, 전자 장치는 객체 3차원 형상 식별 모델을 이용하여 객체의 3차원 형상 타입을 식별할 수 있다. 전자 장치는 객체의 이미지를 입력 받아 피쳐들을 추출하는 객체 3차원 형상 식별 모델의 신경망 연산을 통해 객체의 3차원 형상 타입을 식별할 수 있다. 객체 3차원 형상 식별 모델은, 3차원 객체를 포함하는 다양한 이미지들로 구성되는 트레이닝 데이터셋에 기초하여 훈련된 것일 수 있다. 객체 3차원 형상 식별 모델의 트레이닝 데이터셋의 객체 이미지들에는, 객 체의 3차원 형상 타입이 레이블링 되어 있을 수 있다. 객체의 3차원 형상 타입은 예를 들어, 구, 정 육면체, 각뿔, 원뿔, 잘린 원뿔, 반구, 직육면체 등이 포함될 수 있으나, 이에 한정되는 것은 아니다. 일 실시예에서, 전자 장치는 식별된 3차원 형상 타입에 기초하여 객체의 3차원 형상 타입에 대 응하는 3차원 파라미터를 획득할 수 있다. '3차원 파라미터'란, 객체의 3차원 형상과 관련된 기하학 적 특징을 나타내는 요소들을 말한다. 예를 들어, 3차원 형상 타입이 '구'인 경우, '구'의 3차원 파라미터 가 획득되고, 3차원 형상 타입이 '정육면체'인 경우, '정육면체'의 3차원 파라미터가 획득될 수 있다. 3차원 파라미터를 구성하는 요소들은 3차원 형상 타입 마다 상이할 수 있다. 예를 들어, '구' 의 3차원 파라미터에는 반지름 및/또는 직경 등의 요소가 포함될 수 있으며, '정육면체'의 3차원 파라미터 에는 가로, 세로, 높이 등의 요소가 포함될 수 있다. 한편, 도 4에 도시된 3차원 파라미터는 설명의 편의를 위해 기하학적 특징인 가로, 세로, 반지름, 깊이 등 의 요소들만 도시되었으나, 3차원 파라미터는 이에 한정되는 것은 아니다. 3차원 파라미터는 공간 상 에서 객체의 회전 좌표 정보, 공간 상에서 객체의 이동 좌표 정보, 객체를 촬영한 카메라의 초점 거리 정보 및 객체의 관심 영역에 관한 3차원 정보(예를 들어, 관심 영역의 가로, 세로, 곡률 등) 등을 더 포함할 수 있다. 즉, 도시된 3차원 파라미터는 시각적 이해를 돕기 위한 예시일 뿐이며, 3차원 파라미터,는 전술한 예 시들 외에 이미지 내 객체의 3차원 정보를 추정하기 위해 활용 가능한 어떠한 유형의 요소든지 더 포함될 수 있 고, 전술한 예시들 중에서 일부 요소들이 제외될 수도 있다. 다시 구체적인 예를 들면, 일 실시예에 따른 전자 장치는 이미지를 객체 3차원 형상 식별 모델(41 0)에 적용하여, 이미지 내의 객체의 3차원 형상 타입인 실린더 타입을 식별할 수 있다. 전자 장 치는 실린더 타입에 대응하는, 실린더의 3차원 파라미터를 획득할 수 있다. 실린더의 3차원 파 라미터는 예를 들어, 실린더의 직경 D, 실린더의 반지름 r, 3차원 공간상에서의 실린더의 회전 정보 R, 3 차원 공간상에서의 실린더의 이동 정보 T, 실린더의 높이 h, 실린더 표면의 관심 영역의 높이 h', 실린더 표면 에서 관심 영역(예를 들어, 상품의 라벨 등)이 차지하는 각도 θ, 카메라의 초점거리 정보 F 등을 포함할 수 있 으나, 이에 한정되는 것은 아니다. 일 실시예에서, 3차원 파라미터에 포함되는 각각의 요소들은, 임의의 객체의 3차원 정보를 나타내는 초기 값이 설정되어 있을 수 있다. 일 실시예에 따른 전자 장치는, 3차원 파라미터가 객체의 3차원 정보 를 나타내도록 매칭할 수 있다. 예를 들어, 전자 장치는 실린더의 3차원 파라미터 값들을 조정하여, 실린더의 3차원 파라미터 값들이 이미지 내의 객체의 3차원 정보를 나타내도록 할 수 있다. 즉, 전자 장치는 이미지 내 객체의 3차원 정보를 나타내는 3차원 파라미터 값들을 획득할 수 있다. 이에 대하여는 도 6a에 대한 설명에서 더 기술한다. 한편, 본 개시의 도면들에서는 이미지 내 객체가 '와인' 이고 관심 영역이 '와인 라벨'인 것을 예시로 설 명하지만, 본 개시는 이에 한정되는 것은 아니다. 예를 들어, 본 개시에서 와인 병의 3차원 형상 타입은 실린더 타입로 식별되는 것을 설명하지만, 객 체 3차원 형상 식별 모델의 훈련 및 튜닝에 따라서는 와인 병이 병(bottle) 타입으로 식별될 수도 있고, 이에 따라 획득되는 3차원 파라미터도 병 타입에 대응하는 3차원 파라미터일 수 있다. 또다른 예를 들면, 이미지 내 객체가 다른 타입의 3차원 형상인 '구, 원뿔, 직육면체' 등의 객체일 수도 있다. 이 경우, 전자 장치는 각각의 객체 별로 3차원 형상 타입을 식별하고, 3차원 파라미터를 획득 할 수 있다. 또다른 예를 들면, 이미지 내 관심 영역은 상품의 라벨이 아닌, 상품의 성분, 사용법, 사용량 등 상품(객체)에 관련된 정보를 나타내는 영역일 수도 있다. 이 경우, 전자 장치는 객체의 관심 영역에 포함되는 정보를정확하게 식별하기 위해, 본 개시의 실시예들에 따른 왜곡 제거 동작들을 수행하고, 왜곡 없는 이미지로부터 객 체와 관련된 정보를 획득할 수 있다. 도 5는 본 개시의 일 실시예에 따른 전자 장치가 객체의 표면의 관심 영역을 식별하는 동작을 설명하기 위한 도 면이다. 일 실시예에서, 전자 장치는 관심 영역 식별 모델을 이용하여 관심 영역을 식별할 수 있다. 전 자 장치는 객체 이미지(이하, 이미지)를 입력 받아 피쳐들을 추출하는 관심 영역 식별 모델 의 신경망 연산을 통해 관심 영역을 식별할 수 있다. 일 실시예에서, 전자 장치는 관심 영역 식별 모델에 입력될 이미지를 전처리할 수 있다. 전자 장치는 이미지의 일부를 잘라내고 리사이즈하여 획득된, 입력 이미지를 관심 영역 식별 모델 의 입력 데이터로 사용할 수 있다. 일 실시예에서, 전자 장치는 관심 영역 식별 모델에 입력될 이미지를 다른 카메라를 이용하여 획득할 수 있다. 예를 들어, 전자 장치는 사용자가 객체를 촬영할 때, 다른 고해상도 카메라를 이용하여 관심 영역의 고해상도 이미지를 획득할 수 있다. 이 경우, 사용자가 촬영하는 이미지는 객체 이미지와 같은 포맷일 수 있고, 전자 장치가 관심 영역 식별을 위해 별도로 저장하는 이미지는 입력 이미지와 같은 포맷일 수 있다. 관심 영역 식별 모델은, 관심 영역을 포함하는 다양한 이미지들로 구성되는 트레이닝 데이터셋에 기초하여 훈련된 것일 수 있다. 관심 영역 식별 모델의 트레이닝 데이터셋의 관심 영역 이미지들에는, 관심 영역을 나타내는 키포인트들이 레이블링 되어 있을 수 있다. 전자 장치가 관심 영역 식별 모델을 이용하여 식별하는 관심 영역은, 검출된 관심 영역이 표시된 이미지, 관심 영역을 나타내는 키포인트들 및/또 는 이미지 내에서 키포인트들의 좌표 등을 포함할 수 있으나, 이에 한정되는 것은 아니다. 관심 영역 식별 모델은, 백본(backbone) 네트워크 및 회귀 모듈을 포함할 수 있다. 백본 네트워크는 입력 이미지로부터 다양한 피쳐들을 추출하기 위한 알려진 신경망(예를 들어, CNN 등) 알고리즘들이 사용될 수 있다. 예를 들어, 백본 네트워크는 미리-훈련된(pre-trained) 네트워크 모델일 수 있으며, 관심 영역 식별 모델 의 성능 개선을 위해 다른 타입의 신경망으로 변경될 수 있다. 회귀 모듈은 관심 영역을 검출하는 태 스크를 수행한다. 예를 들어, 회귀 모듈은 관심 영역을 나타내는 경계 박스, 키포인트들 등이 정답 값에 수렴하 도록 학습하기 위한 회귀 알고리즘을 포함할 수 있다. 회귀 모듈은 관심 영역을 검출하기 위한 신경망 레 이어 및 가중치들을 포함할 수 있다. 예를 들어, 회귀 모듈은 관심 영역을 검출하기 위한 R-CNN(Regions with Convolutional Neuron Networks features) 등으로 구성될 수 있으나, 이에 한정되는 것은 아니다. 전자 장치 는 관심 영역 식별 모델의 트레이닝 데이터셋을 이용하여 회귀 모듈의 레이어들을 훈련시킬 수 있다. 도 6a는 본 개시의 일 실시예에 따른 전자 장치가 객체의 3차원 정보를 획득하는 동작을 설명하기 위한 도면이 다. 도 6a를 설명함에 있어서, 설명의 편의를 위해 객체의 3차원 형상 타입은 실린더로 식별된 경우를 예시로 들어 설명한다. 다만, 객체의 3차원 형상 타입은 실린더에 한정되는 것은 아니며, 전술한 예시를 포함하여 기하학적 특징을 3차원 파라미터로 나타낼 수 있는 어떠한 3차원 형상 타입에 대해서도 적용될 수 있다. 일 실시예에 따른 전자 장치는, 객체의 3차원 정보를 획득하기 위해 후술되는 동작들을 수행할 수 있다. 전자 장치는 객체의 3차원 정보에 기초하여 원근 변환을 수행하므로, 객체의 3차원 정보 없이 일반적으로 원근 변환을 수행하는 것보다 정밀하게 이미지 내 왜곡을 제거할 수 있다. 이미지 내의 왜곡은 3차원 객체 표면 의 곡선면으로 인한 관심 영역의 왜곡 등을 포함할 수 있다. 예를 들어, 객체의 3차원 형상의 곡선면으로 인해, 객체 표면에 부착된 라벨이 2차원의 이미지 내에서 왜곡된 것을 예로 들 수 있으나, 이에 한정되는 것은 아니다. 일 실시예에서, 전자 장치는 기 저장된 다양한 3차원 형상 타입(예를 들어, 실린더, 구, 정육면체 등)에 대응하는 3차원 파라미터 중에서, 식별된 3차원 형상 타입인 '실린더'에 대응하는 3차원 파라미터를 획득 할 수 있다. 실린더 타입에 대응하는 3차원 파라미터는 예를 들어, 실린더의 반지름 r, 3차원 공간상에서 의 실린더의 회전 정보 R, 3차원 공간상에서의 실린더의 이동 정보 T, 관심 영역의 높이 h, 실린더 표면에서 관 심 영역(예를 들어, 상품의 라벨 등)이 차지하는 각도 θ, 카메라의 초점거리 정보 F 등을 포함할 수 있으나, 이에 한정되는 것은 아니다. 3차원 파라미터에 포함되는 각각의 요소들은, 초기값이 설정되어 있을 수 있 다.일 실시예에서, 전자 장치는 이미지 내 객체의 3차원 정보를 추정하기 위해, 가상 객체를 설정할 수 있다. 가상 객체는, 이미지 내 객체의 3차원 형상 타입과 동일한 형상 타입으로 설정되며, 3차원 파라미터 의 초기 값으로 렌더링되는 객체일 수 있다. 즉, 도 6a의 예시에서는, 가상 객체는 실린더 타입이고, 3차원 파라미터의 초기값(r, R, T, h, θ, F)을 3차원 정보로 하는 객체이다. 또한, 가상 객체는 가 상 객체에 대하여 임의로 설정된 초기 관심 영역을 포함할 수 있다. 전자 장치는 가상 객체의 3차원 정보를 나타내는 3차원 파라미터 값들이 이미지 내 객체의 3차원 정 보를 나타내도록, 3차원 파라미터 값들을 미세 조정할 수 있다. 전자 장치는 가상 객체를 2차원으로 투영하고, 가상 객체의 관심 영역(예를 들어, 라벨)을 나 타내는 키포인트들(또한, 제2 키포인트들로도 지칭됨)을 설정할 수 있다. 전자 장치는 제2 키포인트 들이 이미지 내 객체의 관심 영역을 나타내는 키포인트들(또한, 제1 키포인트들로도 지칭됨)에 정합 하도록 3차원 파라미터 값들을 미세 조정할 수 있다. 전자 장치가 이미지 내 객체의 관심 영역을 나 타내는 제1 키포인트들을 획득하는 동작은 전술하였으므로, 동일한 설명은 생략한다. 전자 장치는 손실 함수에 기초하여 제2 키포인트들이 제1 키포인트들에 정합하도록 조정할 수 있다. 함수 f는 실린더의 3차원 파라미터인 r, R, T, h, θ, F 를 변수로 포함하는 함수일 수 있다. 전자 장치는 함수 f를 이용하여 가상 객체의 제2 키포인트들을 추정할 수 있으며, 손실 함수를 이용 하여 제2 키포인트들과 제1 키포인트들의 오차가 최소화 되도록 제2 키포인트들을 조정할 수 있 다. 전자 장치는 제2 키포인트들이 제1 키포인트들에 정합하도록 3차원 파라미터의 값들을 변 경할 수 있다. 전자 장치는 변경된 3차원 파라미터의 값들에 기초하여 가상 객체를 재생성(업 데이트)하고, 전술한 동작을 반복할 수 있다. 즉, 전자 장치는, 3차원 파라미터의 값을 조정하고, 3 차원 파라미터의 조정된 값들의 3차원 정보를 갖는 가상 객체의 생성을 반복하면서, 가상 객체를 2차 원으로 투영하여 획득된 제2 키포인트들과 이미지 내 객체의 관심 영역을 나타내는 제1 키포인트들의 차이가 최소가 되는 3차원 파라미터의 값들을 획득할 수 있다. 위 조정 작업이 반복됨에 따라, 가상 객체 에 대하여 설정된 3차원 파라미터의 초기값들은, 객체의 3차원 파라미터의 정답 값에 근사하도록 조 정될 수 있다. 제2 키포인트들이 제1 키포인트들에 정합되면, 이 때의 가상 객체에 대응되는 3 차원 파라미터의 값들은 이미지 내 객체의 3차원 정보를 나타낸다. 전자 장치는 최종적으로 이미지 내 객체의 3차원 정보를 나타내는 3차원 파라미터를 획득할 수 있다. 도 6b는 본 개시의 일 실시예에 따른 전자 장치가 객체의 3차원 정보에 기초하여 관심 영역의 왜곡을 제거하는 동작을 설명하기 위한 도면이다. 도 6b를 설명함에 있어서, 도 6a에서 예시로 설명한 내용을 계속하여 설명한다. 도 6b를 참조하면, 일 실시예에 따른 전자 장치는 3차원 파라미터의 값들의 미세 조정 과정을 통해, 이미지 내 객체의 3차원 정보를 나타내는 3차원 파라미터 값들을 획득할 수 있다. 전자 장치는 3차원 파라미터 값들을 이용하여 이미지 내 객체의 표면의 관심 영역을 나타내는 2차원 메시(mesh) 데이터를 생성할 수 있다. 2차원 메시 데이터는, 획득된 3차원 파라미터 값들에 기 초하여, 3차원 공간 상에서 객체의 관심 영역 좌표를 2차원으로 투영하여 생성된 데이터를 말하며, 객체의 관심 영역의 왜곡 정보를 포함한다. 예를 들어, 굴곡 형상을 갖는 3차원 객체인 '와인 병'의 표면에 부착된 관심 영 역은 '와인 라벨'일 수 있다. 이 경우, 2차원 메시 데이터는 와인 병의 표면에 부착된 와인 라벨의 3차원 공간상 좌표를 2차원으로 투영한 것으로, 와인 병을 포함하는 이미지 내에서 관심 영역인 와인 라벨의 왜곡 정 보를 나타낼 수 있다. 전자 장치는 굴곡 왜곡이 반영된 2차원 메시 데이터를 평면(flat) 데이터로 변환할 수 있다. 이 경우, 데이터 변환을 위한 다양한 알고리즘이 적용될 수 있다. 예를 들어, 전자 장치는 원근 변환 알 고리즘을 이용할 수 있으나, 이에 한정되는 것은 아니다. 일 실시예에 따른 전자 장치는 평면 데이터를 생성함으로써, 평면 데이터에 대응하는, 왜곡 없 는 이미지를 획득할 수 있다. 예를 들어, 왜곡 없는 이미지는, 와인 병의 곡선 면에 부착되어 있는, 굴곡 형상을 갖는 와인의 라벨을 평평하게 편 이미지일 수 있으나, 이에 한정되는 것은 아니다. 일부 실시예에 서, 전자 장치는 왜곡 없는 이미지를 획득할 때, 픽셀 간 보간을 수행하여 이미지 품질을 개선할 수 있다. 전자 장치는 관심 영역의 왜곡 없는 이미지를 이용하여, 관심 영역 내 정보를 추출할 수 있다. 왜곡 없는 이미지는 객체의 정확한 3차원 정보를 추론한 결과에 기초하여 생성된 것이므로, 이미지 내 정보를 추출하기 위한 일반적인 정보 검출 모델(예: OCR 모델)을 이용하더라도 관심 영역 내의 로고, 아이콘, 텍스트 등이 보다 더 정확하게 검출될 수 있다. 즉, 왜곡된 이미지 내에서 정보를 추출하기 위해 이미지 내의 왜곡을 반영하여 별도로 정보 검출 모델을 훈련시키지 않더라도, 일반적인 정보 검출 모델을 통해서도 정확한 정보 추 출이 가능할 수 있다. 다만, 전술한 일반적인 정보 검출 모델은 예시일 뿐이며, 전자 장치는 로고, 아이 콘, 텍스트 등에 왜곡이 있는 훈련 데이터를 포함하여 훈련된 검출 모델 또한 이용할 수 있다. 도 7은 본 개시의 일 실시예에 따른 전자 장치가 관심 영역 내의 정보를 추출하는 동작을 설명하기 위한 도면이 다. 도 7을 설명함에 있어서, 전자 장치가 전술한 실시예들에 따라, 이미지 내에 객체가 있고, 객체의 전체 영역 중 적어도 일부의 영역이 관심 영역이며, 관심 영역의 왜곡 없는 이미지를 획득한 것을 전제로 설명 한다. 구체적으로, 왜곡 없는 이미지는 상품의 라벨의 왜곡(예를 들어, 굴곡으로 인한 왜곡 등)을 제거한 플랫 라벨 이미지일 수 있다. 일 실시예에서, 전자 장치는 정보 검출 모델을 이용하여 관심 영역의 왜곡 없는 이미지로부터 관심 영역 내 정보를 추출할 수 있다. 관심 영역 내 정보는 객체와 관련된 정보일 수 있다. 예를 들 어, 전자 장치는 정보 검출 모델을 이용하여, 객체에 포함된 상품 라벨의 왜곡 없는 이미지를 획득하고, 상품 라벨에 포함되는 객체와 관련된, 관심 영역 내 정보를 획득할 수 있다. 일 실시예에서, 정보 검출 모델은 왜곡 없는 이미지를 이용하여 정보를 추출하므로, 정보 추출을 위 해 사용되는 알려진 검출 모델들이 이용될 수 있다. 예를 들어, 정보 검출 모델은 OCR 모델일 수 있다. 전 자 장치는 OCR 모델을 이용하여 관심 영역 내의 텍스트들을 검출할 수 있다. OCR 모델은, 일반 문자, 특 수 문자(special character) 및 기호(symbol) 등을 인식할 수 있다. 다만, 관심 영역 내 정보는 이에 한 정되는 것은 아니며, 관심 영역 내의 로고, 아이콘, 이미지 등을 검출하기 위한 다양한 검출 모델들이 이용될 수 있다. 구체적으로, 로고 검출 모델, 아이콘 검출 모델, 이미지 검출 모델, 객체 검출 모델 등이 포함될 수 있다. 일 실시예에서, 정보 검출 모델은 왜곡 없는 이미지에 기초하여 훈련된 인공지능 모델일 수 있다. 전 술한 실시예들에 따라 획득되는 왜곡 없는 이미지로부터 정보 추출의 정밀성을 확보하기 위해, 전자 장치 왜곡 없는 이미지 및 관심 영역 내 정보를 트레이닝 데이터셋에 포함시켜 정보 검출 모델 을 더 훈련시킬 수 있다. 이 경우, 전자 장치는 알려진 검출 모델들을 미리-훈련된 모델로 하여, 관 심 영역 내 정보가 보다 정밀하게 추출되도록 정보 검출 모델을 훈련시킬 수 있다. 일부 실시예에서, 전자 장치는 하나 이상의 정보 검출 모델을 용할 수 있다. 예를 들어, 전자 장치는 둘 이상의 정보 검출 모델 각각으로부터 획득된 정보를 독립적으로 표시/제공하거나, 둘 이상의 정보 검출 모델 각각으로부터 획득된 정보를 조합 및/또는 가공하여, 새로운 2차 정보를 생성하고, 생성된 2차 정보를 표시/제 공할 수 있다. 도 8a는 본 개시의 일 실시예에 따른 전자 장치가 3차원 정보를 획득하여 왜곡 없는 이미지를 획득한 제1 예시 를 설명하기 위한 도면이다. 도 8a 내지 도 8c에서, 시점이란, 전자 장치의 카메라가 객체를 바라본 방향 및/또는 각도를 나타내 기 위해 임의로 선정된 용어이다. 도 8a를 참조하면, 일 실시예에 따른 전자 장치는 제1 시점에서 객체를 촬영한 객체 이미지로 부터 관심 영역을 식별하고, 왜곡 없는 이미지(예를 들어, 플랫 라벨 이미지)를 획득할 수 있다. 일 실시예에서, 제1 시점은 전자 장치의 카메라가 객체를 정면에서 바라본 것일 수 있다. 이 경우, 전자 장치가 객체를 정면에서 촬영하더라도, 3차원 형상의 객체를 촬영한 이미지는 2차원이기 때문 에, 객체에 부착된 라벨에는 객체 자체에 존재하는 곡면으로 인한 왜곡이 있을 수 있다. 일 실시예에 따른 전자 장치는, 객체 이미지로부터 관심 영역을 잘라내고, 관심 영역을 포함하는 왜곡 없는 이미지를 획득할 수 있다. 전자 장치는 왜곡 없는 이미지를 획득하기 위해, 객체의 3차원 정보를 이용할 수 있다. 3차원 정보는 객체에 대하여 튜닝된 3차원 파라미터 값 들로 구성될 수 있다. 예를 들어, 3차원 정보는 실린더 형상의 객체의 반지름, 3차원 공간 상에서의 객체 의 회전 좌표, 3차원 공간상에서의 객체의 이동 좌표, 객체의 표면에서 관심 영역이 차지 하는 각도(즉, 객체의 3차원 형상인 실린더의 중심 축으로부터 관심 영역 양 끝단 사이의 각도), 전자 장치가 객체 이미지를 촬영하였을 때 카메라의 초점 거리 등을 포함할 수 있다. 전자 장치는 3차원 정보에 기초하여, 관심 영역이 2차원 평면에서 왜곡 없이 표현될 수 있도록 원근 변환을 수행할 수 있다. 이에 대한 구체적인 동작들은 전술하였으므로, 동일한 설명은 생략한다. 한편, 전자 장치가 객체를 바라보는 시점이 변경됨에 따라 관심 영역에 발생하는 왜곡의 정도 가 상이해질 수 있다. 일 실시예에 따른 전자 장치는 3차원 정보를 활용함으로써 왜곡의 정도에 관계 없 이 강건한 왜곡 제거를 수행할 수 있다. 이를 도 8b 및 도 8c를 참조하여 더 설명하기로 한다. 도 8b는 본 개시의 일 실시예에 따른 전자 장치가 3차원 정보를 획득하여 왜곡 없는 이미지를 획득한 제2 예시 를 설명하기 위한 도면이다. 도 8b를 참조하면, 일 실시예에 따른 전자 장치는 제2 시점에서 객체를 촬영한 객체 이미지로 부터 관심 영역을 식별하고, 왜곡 없는 이미지(예를 들어, 플랫 라벨 이미지)를 획득할 수 있다. 일 실시예에서, 제2 시점은 전자 장치의 카메라가 객체를 수직 위 방향으로 기울여서 바라본 것일 수 있다. 이 경우, 객체 이미지에 포함되는 관심 영역에는, 객체의 3차원 형상으로 인한 왜곡 외에도, 전자 장치의 카메라의 시점으로 인한 왜곡 또한 존재할 수 있다. 전자 장치는 객체의 3차원 정보를 이용함으로써, 객체의 3차원 형상으로 인한 왜곡 및 전자 장치의 카메라의 시점으로 인한 왜곡을 제거한, 왜곡 없는 이미지를 획득할 수 있다. 예를 들어, 변환 이미지는 관심 영역을 평평하게 원근 변환하여 생성된 이미지이다. 원근 변환은 알 려진 원근 변환 알고리즘이 이용될 수 있으므로, 구체적인 설명은 생략한다. 변환 이미지를 참조하면, 관 심 영역을 평평하게 변환하더라도 객체의 3차원 형상으로 인한 왜곡 및/또는 카메라의 시점으로 인한 왜곡(824-1, 824-2) 등이 잔존할 수 있다. (도 8b의 왜곡(824-1, 824-2)은, 기준 직선 대비 글자가 곡선으로 휘어진 왜곡을 예시적으로 나타낸다.) 일 실시예에서, 3차원 정보는 객체의 3차원 정보를 나타내도록 튜닝된 3차원 파라미터 값들로 구성될 수 있다. 예를 들어, 3차원 정보는 객체의 반지름, 3차원 공간 상에서의 객체의 회전 좌표, 3차원 공간 상에서의 객체의 이동 좌표, 객체의 표면에서 관심 영역이 차지하는 각도(즉, 객체의 3차 원 형상인 실린더의 중심 축으로부터 관심 영역 양 끝단 사이의 각도), 전자 장치가 객체 이미지를 촬영하였을 때 카메라의 초점 거리 등을 포함할 수 있다. 일 실시예에 따른 전자 장치는 3차원 정보를 이 용하여 정밀하게 원근 변환을 수행함으로써, 객체의 3차원 형상 및 카메라의 촬영 시점으로 인해 발생하는 왜곡 을 제거한, 왜곡 없는 이미지를 획득할 수 있다. 도 8c는 본 개시의 일 실시예에 따른 전자 장치가 3차원 정보를 획득하여 왜곡 없는 이미지를 획득한 제3 예시 를 설명하기 위한 도면이다. 도 8c를 참조하면, 일 실시예에 따른 전자 장치는 제3 시점에서 객체를 촬영한 객체 이미지로 부터 관심 영역을 식별하고, 왜곡 없는 이미지(예를 들어, 플랫 라벨 이미지)를 획득할 수 있다. 일 실시예에서, 제3 시점은 전자 장치의 카메라가 객체를 수직 아래 방향으로 기울여서 바라본 것일 수 있다. 이 경우, 객체의 이미지에 포함되는 관심 영역에는, 객체의 3차원 형상으로 인한 왜곡 외에도, 전자 장치의 카메라의 시점으로 인한 왜곡 또한 존재할 수 있다. 예를 들어, 변환 이미지는 관심 영역을 평평하게 원근 변환하여 생성된 이미지이다. 변환 이미지 를 참조하면, 관심 영역을 평평하게 변환하더라도 객체의 3차원 형상으로 인한 왜곡 및/또는 카 메라의 시점으로 인한 왜곡(834-1, 834-2) 등이 잔존할 수 있다. (도 8c의 왜곡(834-1, 834-2)은, 기준 직선 대비 글자가 곡선으로 휘어진 왜곡을 예시적으로 나타낸다.) 전자 장치는 객체의 3차원 정보를 이용함으로써, 정밀한 왜곡 없는 이미지를 획득할 수 있다. 이에 대하여는 도 8b에서 이미 기술하였으므로, 동일한 설명은 생략한다. 일 실시예에서, 3차원 정보에 포함되는 3차원 파라미터는, 3차원 공간 상에서의 객체의 회전 좌표, 3차원 공간상에서의 객체의 이동 좌표 등이 포함될 수 있다. 이에 따라, 전자 장치는 왜곡 없는 이미지 를 생성할 때, 관심 영역을 이동 및 회전시키고, 원근 변환을 수행할 수 있다. 일 실시예에서, 3차원 정보에 포함되는 3차원 파라미터는, 전자 장치가 객체 이미지를 촬영하였을 때 카메라의 초점 거리를 포함할 수 있다. 이에 따라, 전자 장치는 왜곡 없는 이미지를 생성할 때,초점 거리에 기초하여 관심 영역을 포함하는 이미지를 전처리하고, 원근 변환을 수행할 수 있다. 즉, 전자 장치는 왜곡 없는 이미지를 생성할 때, 3차원 정보를 이용함으로써, 객체의 3차원 형 상으로 인한 왜곡 및/또는 카메라의 시점으로 인한 왜곡 등을 제거한다. 이에 따라, 전자 장치는 이미지 내 관심 영역의 왜곡의 정도에 관계 없이 강건한 왜곡 제거를 수행할 수 있다. 도 9a는 본 개시의 일 실시예에 따른 전자 장치가 왜곡 없는 이미지로부터 정보를 추출한 제1 예시를 설명하기 위한 도면이다. 도 9a를 참조하면, 원본 이미지, 잘라낸 이미지, 및 왜곡 없는 이미지가 도시되어 있다. 일 실시예에서, 전자 장치는 정보 검출 모델을 이용하여 이미지 내 존재하는 정보를 추출할 수 있다. 전 자 장치는 왜곡 없는 이미지를 획득하면, 일반적인 정보 검출 모델을 이용하여 관심 영역 내 정보를 검출할 수 있다. 즉, 전자 장치는 왜곡된 이미지 내에서 정보를 추출하기 위해 이미지 내의 왜곡을 반영 하여 별도로 검출 모델을 훈련시키지 않더라도, 왜곡 없는 이미지를 생성하고, 왜곡 없는 이미지에 일반적인 검출 모델을 적용할 수 있다. 이에 따라, 전자 장치는 별도로 정보 검출 모델을 훈련/업데이트 하기 위한 컴퓨팅 자원을 절약할 수 있다. 예를 들어, 전자 장치는 OCR 모델을 이용하여, 이미지 내 존재하는 텍스트들을 검출할 수 있다. 이하에서, 전자 장치가 OCR 모델을 이용하여 이미지로부터 텍스트를 추출하는 것을 예시로 설명한다. 일 실시예에서, 원본 이미지는 전자 장치가 카메라를 이용하여 획득한 원시 이미지(raw image)이다. 원본 이미지는 객체의 3차원 형상으로 인한 관심 영역의 왜곡이 포함될 수 있으며, 이미지 내에 관심 영역 외에 다른 여백 공간들이 더 포함될 수 있다. 즉, 관심 영역 외 노이즈 픽셀들이 포함될 수 있다. 전자 장치 가 원본 이미지에 대하여 OCR을 적용한다면, 전술한 원본 이미지의 특징들로 인하여, 관심 영 역 내 텍스트들 중 적어도 일부가 미인식되거나, 오인식 될 수 있다. 예를 들어, 원본 이미지 내에서, 텍 스트의 검출 영역은 사각 박스로 표시되어 있으며, 텍스트가 검출된 영역들 중에서 검출 영역 내 검출 텍스트가 오인식된 것은 빗금친 화살표로 표시(오인식된 경우)되어 있다. 또한, 텍스트가 있으나 검출 영역으로 식별되지 않은 것은 검은 화살표로 표시(미인식된 경우)되어 있다. 보다 구체적인 예시로, 관심 영역 내에서 검출해야하 는 텍스트 블록의 수가 14개일 때, 원본 이미지에 대하여 OCR을 적용한 결과(즉, 원본 이미지로부터 검출된 텍스트를 참조하면), 검출된 텍스트 블록은 8개이며, 이 중 적어도 일부는 텍스트 검출 결과가 정 확하지 않을 수 있다. 보다 명확한 이해를 돕기 위해, 원본 이미지로부터 검출된 텍스트를 참조하여, 본 개시에서 예시적으 로 설명하는 미인식된 경우 및 오인식된 경우를 더 설명하고, 잘라낸 이미지 및 왜곡 없는 이미지로 부터 정보를 추출한 예시적인 결과를 설명한다. 일 실시예에서, OCR 모델은 이미지 내에서 텍스트를 검출하고, 검출된 텍스트를 인식하며, 인식한 결과를 신뢰 도가 소정 임계값(예를 들어, 0.5) 이상인 것에 기초하여 인식 결과를 출력할 수 있다. 본 개시의 예시들에서 '미인식된 경우'란 이미지에 대하여 텍스트 검출 및 인식을 수행하였음에도 불구하고, 이 미지로부터 텍스트 검출 및 인식 결과가 출력되지 않은 것을 의미할 수 있다. 예를 들어, '미인식된 경우'란, 1)텍스트가 검출되지 않은 경우, 2) 텍스트가 검출되고 텍스트 인식이 수행되었으나, 인식 결과의 신뢰도가 소 정 임계값(예를 들어, 0.5) 미만이어서 인식 결과가 출력되지 않은 경우를 포함할 수 있다. 본 개시의 예시들에서, '인식된 경우'란 텍스트가 검출되고 텍스트 인식이 수행되었으며, 인식 결과의 신뢰도가 소정 임계값(예를 들어, 0.5) 이상이어서 인식 결과가 출력된 것을 포함할 수 있다. 여기서, '인식된 경우'는 '잘 인식된 경우'와 '오인식된 경우'로 구별될 수 있다. 본 개시의 예시들에서 '잘 인식된 경우'와 '오인식된 경우'는 상대적인 개념으로써 사용될 수 있다. 예를 들어, '오인식된 경우'란, 인식된 결과의 신뢰도가 낮은 경 우(예를 들어, 신뢰도 0.5 이상 0.8 미만)를 의미할 수 있으며, '잘 인식된 경우'란, 인식된 결과의 신뢰도가 '오인식된 경우'보다 상대적으로 높은 경우(예를 들어, 신뢰도 0.8 이상)를 의미할 수 있다. 이에 따라, '오인 식된 경우'에 해당하는 텍스트 인식 결과들은, 인식 결과가 출력되었으나 실제 텍스트의 정확한 인식 결과가 아 닐 수 있다. 예를 들어, 원본 이미지로부터 검출된 텍스트의 인식 결과들 중에서 두번째 인식 텍스트 를 나타내는, '2: \"A *^\"mfr~ y*D' 는 인식 결과의 신뢰도가 0.598 이므로 상대적으로 낮은 값이고, 인식 결과 또한 부정확한 텍스트이므로, '오인식된 경우'로 지칭될 수 있다. 마찬가지의 예시로, 원본 이미지로부터 검출된 텍스트의 인식 결과들 중에서 첫번째 인식 텍스트를 나타내는 '1: ELEVE'는 인식 결과의 신뢰도가 0.888이므로 상대적으로 높은 값이고, 인식 결과 또한 정확한 텍스트이므로 '잘 인식된 경우'로 지칭될 수있다. 한편, OCR 모델에 의해 텍스트를 검출/인식한 결과의 신뢰도가 높더라도, 이미지 자체의 왜곡으로 인해 텍스트 검출/인식의 결과가 정확하지 않을 수 있다. 예를 들어, 원본 이미지로부터 검출된 텍스트의 인식 결 과들 중에서 세번째 인식 텍스트를 나타내는 '3: pour cette cuv6e'는 인식 결과의 신뢰도가 0.960이지만, 실제 정확한 텍스트는 'pour cette cuvee'이다. 이는, 원본 이미지 자체에 존재하는 곡면 왜곡으로 인해 발생하 는 것으로, 별도로 왜곡에 관련된 특징들을 학습한 것이 아닌 일반적인 OCR 모델을 이용함으로 인한 것일 수 있 다. 일 실시예에 따른 전자 장치는 왜곡 없는 이미지을 생성하고, 왜곡 없는 이미지에 대하여 OCR을 수행하므로, 일반적인 OCR 모델을 이용하더라도 정확한 텍스트가 검출되도록 할 수 있다. 이하에서, 서로 다른 특징을 갖는 이미지들인 잘라낸 이미지 및 왜곡 없는 이미지에 대하여, 일반적 인 OCR 모델을 이용하여 텍스트를 검출하는 예시를 더 설명할 것이다. 전술한 미인식/오인식에 관련된 설명은, 후술되는 잘라낸 이미지로부터 검출된 텍스트 왜곡 없는 이미지로부터 검출된 텍스트에도 동일하게 적용될 수 있다. 또한, 도 9b에서 설명되는 원본 이미지로부터 검출된 텍스트, 잘라낸 이미 지로부터 검출된 텍스트 및 왜곡 없는 이미지로부터 검출된 텍스트에도 동일하게 적용될 수 있다. 일 실시예에서, 잘라낸 이미지는 원본 이미지로부터 관심 영역을 검출하고, 관심 영역만을 잘라낸 이 미지이다. 잘라낸 이미지는 객체의 3차원 형상으로 인한 관심 영역의 왜곡이 포함될 수 있다. 전자 장치 가 잘라낸 이미지에 대하여 OCR을 적용한다면, 전술한 잘라낸 이미지의 특징으로 인하여, 관심 영역 내 텍스트들 중 적어도 일부가 미인식되거나, 오인식될 수 있다. 구체적인 예시로, 관심 영역 내에서 검출 해야하는 텍스트 블록의 수가 14개일 때, 잘라낸 이미지에 대하여 OCR을 적용한 결과(즉, 잘라낸 이미지 로부터 검출된 텍스트를 참조하면), 검출된 텍스트 블록은 9개이며, 이 중 적어도 일부는 텍스트 검 출 결과가 정확하지 않을 수 있다. 일 실시예에서, 왜곡 없는 이미지는 전자 장치가 전술한 실시예들에 따라, 객체의 3차원 형상을 식 별하고, 관심 영역을 식별하며, 객체의 3차원 정보를 나타내는 3차원 파라미터 값들을 획득하고, 3차원 파라미 터 값들에 기초하여 원근 변환을 수행한 이미지이다. 왜곡 없는 이미지는 3차원 정보에 기초하여 정밀하게 2차원으로 원근 변환된 이미지이므로, 전자 장치는 보다 정확한 텍스트 검출 결과를 획득할 수 있다. 전 자 장치가 왜곡 없는 이미지에 대하여 OCR을 적용한다면, 관심 영역 내 텍스트들이 정확하게 검출될 수 있다. 구체적인 예시로, 관심 영역 내에서 검출해야 하는 텍스트 블록의 수가 14개일 때, 왜곡 없는 이미지 에 대하여 OCR을 적용한 결과(즉, 왜곡 없는 이미지로부터 검출된 텍스트를 참조하면), 검출된 텍스트 블록은 14개이며, 정확한 텍스트 검출 결과가 획득될 수 있다. 한편, 전술한 검출해야 하는 텍스트 블록의 수, 미인식된 텍스트 블록들, 오인식된 텍스트 블록들은 설명의 편 의를 위한 예시일 뿐, 텍스트 인식 결과를 단정하기 위한 것은 아니다. 즉, 원본 이미지 및 잘라낸 이미지 에 대하여 텍스트를 검출한 결과보다, 왜곡 없는 이미지에 대하여 텍스트를 검출한 결과가 상대적으 로 정확도가 높다는 것을 설명하고자 하는 것임이 이해되어야 할 것이다. 도 9b는 본 개시의 일 실시예에 따른 전자 장치가 왜곡 없는 이미지로부터 정보를 추출한 제2 예시를 설명하기 위한 도면이다. 도 9b를 참조하면, 원본 이미지, 잘라낸 이미지, 및 왜곡 없는 이미지가 도시되어 있다. 일 실시예에서, 원본 이미지 및 잘라낸 이미지는, 객체의 3차원 형상으로 인한 왜곡 외에도, 전자 장 치가 객체를 촬영한 시점(거리, 각도 등)으로 인한 왜곡이 존재할 수 있다. 전자 장치는 객체의 3차원 형상을 식별하고, 관심 영역을 식별하며, 객체의 3차원 정보를 나타내는 3차원 파라미터 값들을 획득하고, 3차원 파라미터 값들에 기초하여 원근 변환을 수행함으로써 왜곡 없는 이미지 를 획득할 수 있다. 여기서, 3차원 파라미터에는 3차원 공간 상에서의 객체의 회전 좌표, 3차원 공간상에서의 객체의 이동 좌표, 카메라의 초점거리 등이 포함될 수 있으므로, 전자 장치는 관심 영역을 이동 및/또는 회전시키고, 원근 변환을 수행할 수 있다. 구체적으로, 전자 장치는 원본 이미지에서, 3차원 공간을 촬영한 이미지의 중심부에 객체가 있지 않은 경우, 3차원 파라미터에 포함되는 공간상에서의 객체의 이동 정보 에 기초하여 객체를 중심으로 이동시킬 수 있다. 또한, 전자 장치는 원본 이미지에서 객체가 3차원 공간을 촬영한 이미지 내에서 회전되어 있는 경우, 3차원 파라미터에 포함되는 공간상에서의 객체의 회전 정보 에 기초하여, 객체가 수평/수직 정렬되도록 회전시킬 수 있다. 또한, 전자 장치는 원본 이미지를 촬영한 카메라의 초점 거리를 이용하여, 객체의 이동/회전 정도를 보완할 수 있다. 일 실시예에서, 객체의 이동/ 회전 등은, 전술한 실시예들에서 객체의 3차원 정보를 나타내는 3차원 파라미터 값들을 획득하는 동작에 포함될 수 있다. 즉, 전자 장치가 객체의 3차원 정보를 나타내는 3차원 파라미터 값들을 획득하기 위한 미세 조 정 작업을 수행함에 따라, 이동 정보, 회전 정보 및 초점거리 정보 등이 활용될 수 있다. 이에 따라, 도 9b에 도시된 것과 같이, 원본 이미지 내에 객체가 비스듬하게 촬영되어 있을 지라도, 왜곡 없는 이미지는 관심 영역의 수평/수직 정렬이 된 상태로 획득될 수 있다. 일 실시예에서, 원본 이미지 및 잘라낸 이미지에 대하여 텍스트를 검출한 결과보다, 왜곡 없는 이미 지에 대하여 텍스트를 검출한 결과가 상대적으로 정확도가 높을 수 있다. 즉, 원본 이미지로부터 검 출된 텍스트, 잘라낸 이미지로부터 검출된 텍스트 및 왜곡 없는 이미지로부터 검출된 텍스 트를 참조하면, 왜곡 없는 이미지로부터 검출된 텍스트가 가장 정확하게 식별됨을 알 수 있다. 한편, 미인식된 텍스트 블록들, 오인식된 텍스트 블록들은 설명의 편의를 위한 예시일 뿐, 텍스트 인식 결과를 단정하기 위한 것은 아니다. 즉, 원본 이미지 및 잘라낸 이미지에 대하여 텍스트를 검출한 결과보다, 왜곡 없는 이미지에 대하여 텍스트를 검출한 결과가 상대적으로 정확도가 높다는 것을 설명하고자 하는 것 임이 이해되어야 할 것이다. 도 10a는 본 개시의 일 실시예에 따른 전자 장치가 객체 3차원 형상 식별 모델을 훈련시키는 동작을 설명하기 위한 도면이다. 일 실시예에서, 전자 장치는 객체 3차원 형상 식별 모델을 훈련시킬 수 있다. 전자 장치는 3 차원 객체를 포함하는 다양한 이미지들로 구성되는 트레이닝 데이터셋을 이용하여, 객체 3차원 형상 식별 모델 을 훈련시킬 수 있다. 트레이닝 데이터셋에는 객체의 3차원 형상 전체를 포함하는 트레이닝 이미지 (들)가 포함될 수 있다. 일 실시예에서, 전자 장치는 객체 3차원 형상 식별 모델의 추론 성능을 향상시키기 위하여 객체의 3차원 형상 일부를 포함하는 트레이닝 이미지들을 이용할 수 있다. 객체의 3차원 형상 일부를 포함하는 트레이닝 이미지들은, 다양한 각도, 거리에서 객체의 전체 또는 일부를 촬영함으로써 획득된 것일 수 있 다. 예를 들어, 제1 방향(1012-1)에서 객체의 전체 또는 일부를 촬영한 이미지가 획득될 수 있으며, 제2 방향 (1012-2)에서 객체의 전체 또는 일부를 촬영한 이미지가 획득될 수 있다. 전술한 예시와 같이, 객체를 촬영 가 능한 모든 방향에 대하여, 객체의 전체 도는 일부를 촬영한 이미지가 트레이닝 이미지들에 포함되어, 트 레이닝 데이터로 사용될 수 있다. 일부 실시예에서, 객체의 3차원 형상 일부를 포함하는 트레이닝 이미지들은 트레이닝 데이터셋에 이미 포 함되어 있을 수 있다. 일부 실시예에서, 전자 장치는 객체의 3차원 형상 일부를 포함하는 트레이닝 이미 지들을 외부 장치(예를 들어, 서버 등)로부터 수신할 수 있다. 일부 실시예에서, 전자 장치는 카메 라를 이용하여 객체의 3차원 형상 일부를 포함하는 트레이닝 이미지들을 획득할 수 있다. 예를 들어, 전 자 장치는 사용자에게 객체의 일부를 촬영하도록 가이드하는 인터페이스를 제공할 수 있다. 일 실시예에 따른 전자 장치는, 객체의 3차원 형상 전체를 포함하는 트레이닝 이미지(들) 및 객체 의 3차원 형상 일부를 포함하는 트레이닝 이미지들을 이용하여 훈련된 객체 3차원 형상 식별 모델을 이용 하여, 객체의 3차원 형상을 추론할 수 있다. 예를 들어, 객체의 일부만이 촬영된 입력 이미지만이 입력되 더라도, 전자 장치는 입력 이미지 내 객체의 3차원 형상 타입이 실린더임을 추론할 수 있다. 도 10b는 본 개시의 일 실시예에 따른 전자 장치가 객체 3차원 형상 식별 모델을 훈련시키는 다른 동작을 설명 하기 위한 도면이다. 도 10b를 참조하면, 전자 장치는 객체 3차원 형상 모델을 훈련시키기 위한 트레이닝 데이터들을 생 성할 수 있다. 일 실시예에서, 트레이닝 데이터셋에는 객체의 3차원 형상 전체를 포함하는 트레이닝 이미지(들)가 포함 될 수 있다. 전자 장치는 트레이닝 데이터셋에 포함되는 이미지들에 대하여 소정의 데이터 증강 작업을 수행함으로써, 트레이닝 데이터들을 생성할 수 있다. 예를 들어, 전자 장치는 객체의 3차원 형상 전체를 포함하는 트레이닝 이미지(들)를 크롭하여, 객체의 3차원 형상 일부를 포함하는 트레이닝 이미지들(101 4)을 생성할 수 있다. 구체적인 예를 들면, 전자 장치는 트레이닝 이미지을 6분할함으로써, 1개의 트레이닝 데이터가 6개의 트레이닝 데이터가 되도록 데이터를 증강할 수 있다. 예를 들어, 트레이닝 이미지의 제1 영역(1014-1)이 분할 영역으로 결정되면, 잘라낸 제1 이미지(1014-2)가 훈련 데이터로 사용될 수 있다. 한편, 도 10b에는 크롭만이 예시로 도시되어 있으나, 로테이션, 플립 등 다양한 다른 데이터 증강 방식이 적용될 수도 있다. 일 실시예에 따른 전자 장치는, 객체의 3차원 형상 전체를 포함하는 트레이닝 이미지(들) 및 객체 의 3차원 형상 일부를 포함하는 트레이닝 이미지들을 이용하여 훈련된 객체 3차원 형상 식별 모델을 이용 하여, 객체의 3차원 형상을 추론할 수 있다. 예를 들어, 객체의 일부만이 촬영된 입력 이미지만이 입력되 더라도, 전자 장치는 입력 이미지 내 객체의 3차원 형상 타입이 실린더임을 추론할 수 있다. 한편, 전자 장치는 전술한 트레이닝 데이터들에 대하여도, 소정의 데이터 증강 작업을 수행하고, 증강된 데이터를 더 이용하여 객체 3차원 형상 식별 모델을 훈련시킴으로써, 객체 3차원 형상 식별 모델의 추론 성능을 향상시킬 수 있다. 예를 들어, 전자 장치는 객체의 3차원 형상 전체를 포함하는 트레이닝 이 미지(들), 3차원 형상 일부를 포함하는 트레이닝 이미지들(1012, 1014)에 대하여, 크롭, 로테이션, 플립 등의 다양한 데이터 증강 방식을 적용하고, 증강된 데이터를 훈련 데이터셋에 포함시킬 수 있다. 도 10c는 본 개시의 일 실시예에 따른 전자 장치가 객체의 3차원 형상을 식별하는 실시예를 설명하기 위한 도면 이다. 일 실시예에서, 전자 장치는 객체의 일부만이 촬영된 입력 이미지(이하에서, 입력 이미지)를 객체 3차원 형상 식별 모델에 입력하고, 객체 3차원 형상 추론 결과를 획득할 수 있다. 이 경우, 입력 이미지가 객체의 전체 형상을 포함하지 않기 때문에, 객체 3차원 형상 추론 결과의 보완이 필요할 수 있다. 예를 들어, 객체 3차원 형상 추론 결과는 실린더 타입일 확률 50%, 잘린 원뿔 타입일 확률 50% 일 수 있으며, 객체 3차원 형상 식별 모델이 객체 3차원 형상을 확정하기 위한 임계 값은 확률 값: 80% 이상일 수 있다. 이 경우, 실린더 타입일 확률(50%)과 원뿔 타입일 확률(50%) 모두 객체 3차원 형상을 확정하기 위한 임계 값(80%)을 초과하지 않으므로, 전자 장치는 객체 3차원 형상 추론 결과를 보완하기 위한 동작을 수행할 수 있다. 일 실시예에서, 전자 장치는 객체 3차원 형상 추론 결과 값이 기 설정된 임계 값 미만인 것에 기초 하여, 객체 3차원 형상 추론 결과를 보완하기 위한 정보 검출 동작을 수행할 수 있다. 정보 검출 동작은 예를 들어, 로고, 아이콘, 텍스트 등을 검출하는 것일 수 있으나, 이에 한정되는 것은 아니다. 보다 구체적 예 를 들면, 전자 장치는 입력 이미지에 대하여 OCR을 수행하여, 입력 이미지 내에서 텍스트를 검출할 수 있다. 이 경우, 검출된 텍스트는 상품명인 'ABCDE'일 수 있다. 전자 장치는 검출된 텍스트에 기초하여, 데이터베이스 내에서 또는 외부 서버를 통해서 상품을 검색할 수 있다. 예를 들어, 전자 장치 는 'ABCDE'의 상품을 데이터베이스에서 검색할 수 있다. 전자 장치는 상품 검색 결과에 기초하여, 3차원 형상 타입의 가중치를 결정할 수 있다. 예를 들어, 'ABCDE' 상품의 검색 결과, 시중에서 유통되는 'ABCDE' 상품 의 95% 이상이 실린더 타입임을 식별할 수 있다. 이 경우, 전자 장치는 실린더 타입에 가중치를 적용할 것으로 결정할 수 있다. 전자 장치는 객체 3차원 형상 추론 결과에 결정된 가중치를 적용할 수 있 다. 가중치 적용 결과, 최종적으로 결정된 객체의 3차원 형상 타입이 실린더인 것으로 결정될 수 있다. 일 실시예에서, 전자 장치는 객체 3차원 형상 식별 모델에 입력 이미지를 입력하는 것과 병 렬적으로, 정보 검출 동작을 수행할 수 있다 예를 들어, 전자 장치는 입력 이미지에 대하여 OCR을 수행할 수 있다. 전자 장치는 병렬적으로 수행한 OCR 결과에 기초하여, 객체 3차원 형상 추론 결과(102 6)에 적용될 가중치를 결정할 수 있다. 도 10d는 본 개시의 일 실시예에 따른 전자 장치가 객체의 3차원 형상을 식별하는 실시예를 설명하기 위한 도면 이다. 일 실시예에서, 전자 장치는 입력 이미지를 객체 3차원 형상 식별 모델에 입력하고, 객체 3 차원 형상 추론 결과를 획득할 수 있다. 전자 장치는 입력 이미지를 객체 3차원 형상 식별 모델에 적용하기 이전에, 객체 검색 도메 인 선택을 위한 사용자 인터페이스를 표시할 수 있다. 예를 들어, 전자 장치는 유제품, 와인, 통조림 등 의 선택 가능한 도메인을 표시하고, 도메인을 선택하는 사용자 입력을 수신할 수 있다. 전자 장치는 검색 도메인을 선택하는 사용자 입력에 기초하여, 3차원 형상 타입의 가중치를 결정할 수 있 다. 예를 들어, 사용자가 와인 라벨 검색을 선택한 경우, 시중에서 유통되는 와인 상품의 95% 이상이 실린더 타 입임을 식별할 수 있다. 이 경우, 전자 장치는 실린더 타입에 가중치를 적용할 것으로 결정할 수 있다.전자 장치는 객체 3차원 형상 추론 결과에 결정된 가중치를 적용할 수 있다. 가중치 적용 결과, 최 종적으로 결정된 객체의 3차원 형상 타입이 실린더인 것으로 결정될 수 있다. 도 11은 본 개시의 일 실시예에 따른 전자 장치가 관심 영역 식별 모델을 훈련시키는 동작을 설명하기 위한 도 면이다. 일 실시예에서, 전자 장치는 관심 영역 식별 모델을 훈련시킬 수 있다. 전자 장치는 관심 영 역을 포함하는 다양한 이미지들로 구성되는 트레이닝 데이터셋에 기초하여 관심 영역 식별 모델을 훈련시킬 수 있다. 트레이닝 데이터셋의 관심 영역 이미지들에는, 관심 영역을 나타내는 키포인트들이 레 이블링 되어 있을 수 있다. 전자 장치가 관심 영역 식별 모델을 이용하여 식별하는 관심 영역은, 검출된 관심 영역이 표시된 이미지, 관심 영역을 나타내는 키포인트들 및/또는 이미지 내에서 키포인트들의 좌 표 등을 포함할 수 있으나, 이에 한정되는 것은 아니다. 일 실시예에서, 전자 장치는 훈련된 관심 영역 식별 모델을 전자 장치에 저장할 수 있다. 전 자 장치는 전술한 실시예들에 따라 전자 장치가 이미지 내 왜곡을 제거하는 동작들을 수행할 때, 훈련된 관심 영역 식별 모델을 실행시킬 수 있다. 일 실시예에 의하면, 전자 장치는 훈련된 관심 영역 식별 모델을 외부 서버에 업로드할 수도 있다. 도 12는 본 개시의 일 실시예에 따른 전자 장치가 왜곡 제거 모델을 훈련시키는 동작을 설명하기 위한 도면이다. 일 실시예에서, 전자 장치는 왜곡 제거 모델을 훈련시킬 수 있다. 왜곡 제거 모델을 훈련시 키기 위한 훈련 데이터셋은, 관심 영역 데이터 및 3차원 파라미터 데이터가 포함될 수 있다. 관심 영역 데이터는 예를 들어, 관심 영역을 포함하는 이미지, 관심 영역을 나타내는 키포인트들이 포함될 수 있으나, 이 에 한정되는 것은 아니다. 3차원 파라미터 데이터는 예를 들어, 객체의 가로, 세로, 높이 및 반지름 정보, 객체 의 3차원 공간 상에서의 3차원 기하학적 변환을 위한 이동(translation) 및 회전(rotation) 정보, 객체를 촬영 한 전자 장치의 카메라의 초점 거리 정보 등을 포함할 수 있으나, 이에 한정되는 것은 아니다. 일 실시예에서, 왜곡 제거 모델은 관심 영역 데이터 및 3차원 파라미터 데이터를 입력 받아, 왜곡 없는 이미지를 출력할 수 있다. 따라서, 왜곡 제거 모델은, 특정 3차원 형상을 갖는 객체에 대하여, 해당 객체 의 관심 영역이 어느 부분이고, 이에 대응하는 객체의 3차원 정보는 어떤 값들인지를 학습하기 위한 신경망이 이용될 수 있다. 일 실시예에서, 전자 장치는 훈련된 왜곡 제거 모델을 전자 장치에 저장할 수 있다. 전자 장 치는 전술한 실시예들에 따라 전자 장치가 이미지 내 왜곡을 제거하는 동작들을 수행할 때, 훈련된 왜곡 제거 모델을 실행시킬 수 있다. 일 실시예에 의하면, 전자 장치는 훈련된 왜곡 제거 모델 을 외부 서버에 업로드할 수도 있다. 도 13은 본 개시의 일 실시예에 따른 전자 장치에 멀티 카메라를 설명하기 위한 도면이다. 일 실시예에서, 전자 장치는 멀티 카메라를 포함할 수 있다. 예를 들어, 전자 장치는 제1 카메라 , 제2 카메라 및 제3 카메라를 포함할 수 있다. 다만, 도 13에서 설명의 편의를 위해 카메라 를 3개 도시하였으나, 이에 한정되는 것은 아니며 멀티 카메라는 2개 이상의 카메라를 의미한다. 멀티 카메라에 포함되는 각각의 카메라의 사양은 상이할 수 있다. 예를 들어, 제1 카메라는 망원 카메라, 제2 카메라는 광각 카메라, 제3 카메라는 초광각 카메라로 구성될 수 있다. 다만, 카메라의 종류는 이에 한정되는 것은 아니며, 표준 카메라 등이 포함될 수 있다. 각각의 카메라는 서로 다른 특징의 이미지를 획득할 수 있다. 예를 들어, 제1 카메라에 의해 획득된 제1 이미지는, 객체를 확대하여 촬영하여 객체의 일부가 포함되는 이미지일 수 있다. 제2 카메라에 의 해 획득된 제2 이미지는, 제1 카메라보다 넓은 화각으로 객체를 촬영하여 객체의 전체가 포함되는 이미지일 수 있다. 제3 카메라에 의해 획득된 제3 이미지는, 제1 카메라, 제2 카메라 보다 더 넓은 화각으로 객체를 촬영하여 객체의 전체 및 장면의 넓은 영역이 포함되는 이미지일 수 있다. 일 실시예에서, 전자 장치에 포함되는 멀티 카메라의 각각으로부터 획득되는 이미지의 특징이 상이하므로, 어떠한 카메라를 이용하여 획득된 이미지가 이용되는지에 따라, 전술한 동작들에 따른 전자 장치 가 이미지 내 객체로부터 정보를 추출하는 결과 또한 상이할 수 있다. 이미지에 포함되는 객체를 인식하 고 객체의 관심 영역으로부터 정보를 추출하기 위해, 전자 장치는 멀티 카메라 중 어느 카메라를 활성화할지 여부를 결정할 수 있다. 일 실시예에서, 전자 장치는 제1 카메라를 활성화하고 객체를 촬영하여 제1 이미지를 획득할 수 있다. 전자 장치는 제1 이미지를 이용하여 이미지 내의 객체의 3차원 형상 타입 및 객체의 관심 영역을 식별할 수 있다. 일부 실시예에서, 전술한 예시에 따르면 제1 이미지는 망원 카메라인 제1 카메라 를 이용하여 획득된 이미지일 수 있다. 이 경우, 제1 이미지에는 객체의 일부만이 포함되어, 제1 이미지 내의 객체의 관심 영역은 충분한 신뢰도(예를 들어, 소정의 값 이상)로 식별되나, 제1 이미지 내의 객체의 3차원 형상 타입은 불충분한 신뢰도로 식별될 수 있다. 전자 장치는 객체의 3차원 형 상 타입을 식별하기 위해, 제2 카메라 및/또는 제3 카메라를 활성화함으로써, 객체의 전체를 포함 하는 제2 이미지 및/또는 제3 이미지를 획득하고, 제2 이미지 및/또는 제3 이미지를 이용하여 객체의 3차원 형상 타입을 식별할 수 있다. 즉, 전자 장치는 객체의 관심 영역과 3차원 형상 타 입을 식별하기에 적합한 이미지를 선택적으로 이용할 수 있다. 일 실시예에서, 전자 장치는 제1 카메라 및 제2 카메라를 활성화하고 객체를 촬영하여 제1 이미지 및 제2 이미지를 획득할 수 있다. 전자 장치는 객체의 일부를 포함하는 제1 이미지 를 이용하여 객체의 관심 영역을 식별하고, 객체의 전체를 포함하는 제2 이미지 및/또는 제3 이미 지를 이용하여 객체의 3차원 형상 타입을 식별할 수 있다. 일 실시예에 따른 전자 장치가 카메라를 활성화하는 동작은, 전술한 예시에 한정되지 않는다. 전자 장치 는 멀티 카메라에 포함되는 카메라의 가능한 모든 조합을 이용할 수 있다. 예를 들어, 전자 장치는 제2 카메라 및 제3 카메라만을 활성화하거나, 제1 카메라, 제2 카메라 및 제3 카메라 모두를 활성화할 수 있다. 한편, 일 실시예에 따른 전자 장치가 객체의 관심 영역을 식별하는 동작, 객체의 3차원 형상 타입을 식별 하는 동작, 및 관심 영역의 왜곡을 제거하는 동작에는, 전술한 인공지능 모델들(예를 들어, 객체 3차원 형상 식 별 모델, 관심 영역 식별 모델, 왜곡 제거 모델 등)이 이용될 수 있다. 이에 대한 동일한 설명은 생략한다. 전자 장치가 멀티 카메라를 이용하여 이미지를 처리하고 왜곡을 제거하는 구체적인 동작들은, 후술하는 도면들 및 그에 대한 설명에서 더 기술하기로 한다. 도 14a는 본 개시의 일 실시예에 따른 전자 장치가 멀티 카메라를 이용하는 동작을 설명하기 위한 흐름도이다. 도 2의 단계 S210에서와 같이, 일 실시예에 따른 전자 장치는 제1 카메라를 이용하여 적어도 하나의 라벨 을 포함하는 객체의 제1 이미지를 획득할 수 있다. 전자 장치가 객체의 제1 이미지를 획득하는 동작에 대 해서는 자세하게 전술하였으므로, 중복되는 설명은 생략하기로 한다. 단계 S210 이후에 단계 S230이 수행될 수 있으며, 그 이후에 단계 S1410이 수행될 수 있다. 단계 S1410에서, 일 실시예에 따른 전자 장치는 제1 카메라를 이용하여 획득된 객체의 제1 이미지로부터 객체의 3차원 형상 타입이 식별되었는지 여부를 체크한다. 예를 들어, 제1 카메라를 이용하여 획득한 제1 이미 지가 객체의 일부만을 포함하고 있는 경우, 전자 장치가 제1 이미지를 제2 AI 모델에 입력하더라도 제2 AI 모델은 객체의 3차원 형상 타입을 정확히 추론할 수 없다. 이때, 제2 AI 모델은 객체의 3차원 형상 타입을 추론할 수 없다는 결과를 출력하거나, 3차원 형상 타입 추론에 대한 낮은 신뢰도 값을 출력할 수 있다. 전자 장 치는 제2 AI 모델로부터 임계값 이하의 신뢰도 값을 갖는 결과가 출력되는 경우, 제1 이미지로부터 객체 의 3차원 형상 타입이 식별되지 않았다고 판단할 수 있다. 일 실시예에서, 전자 장치는 제1 이미지로부터 객체의 3차원 형상 타입이 식별되지 않는 경우, 단계 S1420을 수행할 수 있다. 한편, 단계 S1420는 전자 장치는 도 10c 및 도 10d에서 전술한, 3차원 형상 타 입에 가중치를 결정하고, 가중치를 적용하여 3차원 형상을 식별하는 동작과 선택적 또는 중복적으로 적용될 수 있다. 전자 장치는 객체의 3차원 형상 타입이 식별되는 경우, 왜곡 제거 동작을 계속하기 위해 단계 S1450의 동작을 수행할 수 있다. 단계 S1420에서, 일 실시예에 따른 전자 장치는 제2 카메라를 활성화한다. 제2 카메라는 제1 카메라보다 넓은 화각을 갖는 카메라일 수 있다. 제2 카메라는 예를 들어, 광각 카메라, 초광각 카메라 등일 수 있으나, 이 에 한정되는 것은 아니다. 단계 S1430에서, 일 실시예에 따른 전자 장치는 제2 카메라를 이용하여 제2 이미지를 획득한다. 제2 카메 라는 제1 카메라보다 화각이 넓으므로, 제1 카메라를 이용하여 획득한 제1 이미지에는 객체의 일부 3차원 형상만이 포함되더라도, 제2 카메라를 이용하여 획득한 제2 이미지는 객체의 전체 3차원 형상이 포함될 수 있다. 단계 S1440에서, 일 실시예에 따른 전자 장치는 제2 이미지를 제2 AI 모델에 적용함으로써 객체의 3차원 형상 타입에 관한 데이터를 획득한다. 제2 이미지에는 객체의 전체 3차원 형상이 포함될 수 있다. 단계 S1440의 동작은 도 2의 단계 S230의 동작과 동일하므로, 구체적인 설명은 생략한다. 단계 S1450에서, 일 실시예에 따른 전자 장치는 제1 이미지 및 제2 이미지 중 적어도 하나를 제1 AI 모델 에 적용함으로써 객체의 3차원 형상을 식별한다. 일 실시예에서, 제1 이미지에는 객체의 일부 3차원 형상만이 포함되더라도, 관심 영역은 온전히 포함될 수 있다. 전자 장치는 제1 이미지를 제1 AI 모델(관심 영역 식별 모델)에 적용함으로써, 제1 이미지 내에서 적어도 하나의 라벨에 대응하는 영역을 관심 영역으로 식별할 수 있다. 일 실시예에서, 제2 이미지에는 객체의 전체 3차원 형상이 포함되므로, 관심 영역 또한 전부 포함될 수 있다. 전자 장치는 제2 이미지를 제1 AI 모델(관심 영역 식별 모델)에 적용함으로써, 제2 이미지 내에서 적어도 하나의 라벨에 대응하는 영역을 관심 영역으로 식별할 수 있다. 일 실시예에서, 전자 장치는 제1 이미지 및 제2 이미지를 각각 제1 AI 모델(관심 영역 식별 모델)에 적용 하고, 각각의 이미지로부터 획득된 관심 영역 식별 결과를 선택하거나, 조합함으로써 관심 영역을 식별할 수 있 다. 전자 장치는 단계 S1450을 수행한 후, 도 2의 단계 S240을 수행할 수 있다. 이 경우, 도 2의 단계 S240 내지 단계 S270에서 제1 카메라와 관련된 동작/데이터 등은, 제2 카메라에도 동일하게 적용될 수 있다. 도 14b는 도 14a를 보충적으로 더 설명하기 위한 도면이다. 일 실시예에서, 전자 장치가 제1 카메라를 이용하여 획득한 제1 이미지는, 객체의 일부만이 포함될 수 있다. 이때, 객체 3차원 형상 식별 모델은 제1 이미지로부터 객체의 3차원 형상 타입을 식별하 지 못할 수 있다. 이 경우, 전자 장치는 단계 S1420을 수행하여, 제1 카메라보다 화각이 넓은 제2 카메라 를 활성화하고, 활성화된 제2 카메라를 이용하여 제2 이미지를 획득할 수 있다. 전자 장치는 제2 이미지를 객체 3차원 형상 식별 모델에 입력함으로써, 객체의 3차원 형상 타입을 식별할 수 있다. 한편, 전자 장치가 제2 이미지를 이용하여 객체의 3차원 형상 타입을 식별하는 동작은, 도 10c 및 도 10d 에서 전술한, 전자 장치가 3차원 형상 타입에 가중치를 결정하고, 가중치를 적용하여 3차원 형상을 식별 하는 동작과 선택적 또는 중복적으로 적용될 수 있다. 도 15a는 본 개시의 일 실시예에 따른 전자 장치가 멀티 카메라를 이용하는 동작을 설명하기 위한 흐름도이다. 단계 S1510에서, 일 실시예에 따른 전자 장치는 제1 카메라를 이용하여 객체의 일부(예를 들어, 라벨)를 포함하는 제1 이미지를 획득하고, 제2 카메라를 이용하여 객체의 전체를 포함하는 제2 이미지를 획득한다. 제2 카메라는, 제1 카메라보다 화각이 넓은 카메라일 수 있다. 예를 들어, 제1 카메라는 망원 카메라이고, 제2 카메 라는 광각 카메라, 초광각 카메라 등일 수 있으나, 이에 한정되는 것은 아니다. 일 실시예에서, 전자 장치 의 카메라를 활성화하여 객체를 촬영할 수 있다. 사용자는 카메라를 실행하기 위한 하드웨어 버튼 또는 아이콘을 터치하여 카메라를 활성화할 수도 있고, 음성 명령을 통해 카메라를 활성화할 수도 있다 사용자가 객체의 라벨로부터 정보를 추출하기 위해, 제1 카메라에 대응하는 프리뷰 영역에 라벨이 전반적으로 나타나도록 전자 장치의 위치를 조정하는 경우, 전자 장치가 제1 카메라를 이용하여 획득한 제1 이 미지에는 객체의 라벨은 명확히 나타날 수 있으나, 객체의 전체 형상은 나타나지 않을 수 있다. 하지만, 제1 카 메라보다 화각이 넓은 제2 카메라를 이용하여 획득된 제2 이미지에는 객체의 전체 형상이 나타날 수 있다. 단계 S1520에서, 일 실시예에 따른 전자 장치는 제1 이미지를 제1 AI 모델(관심 영역 식별 모델)에 적용 함으로써 객체의 표면의 관심 영역(예를 들어, 적어도 하나의 라벨에 대응하는 영역)을 식별한다. 제1 이미지는 관심 영역이 포커싱된 이미지이므로, 제1 이미지를 제1 AI 모델에 적용함으로써, 관심 영역을 정확히 식별할 수 있다. 단계 S1520은, 도 2의 단계 S220에 대응하므로, 동일한 설명은 생략한다. 단계 S1530에서, 일 실시예에 따른 전자 장치는 제2 이미지를 제2 AI 모델에 적용함으로써 객체의 3차원 형상 타입을 식별한다. 단계 S1530은, 제2 이미지를 이용한다는 것만 차이가 있을 뿐 도 2의 단계 S230에 대응 하므로, 동일한 설명은 생략한다. 단계 S1540에서, 일 실시예에 따른 전자 장치는 객체의 3차원 형상 타입에 대응하는 3차원 파라미터 값들 을 획득한다. 단계 S1540은, 도 2의 단계 S240에 대응하므로, 동일한 설명은 생략한다.도 15b는 도 15a를 보충적으로 더 설명하기 위한 도면이다. 일 실시예에서, 전자 장치가 제1 카메라를 이용하여 획득한 제1 이미지는, 망원 카메라를 이용하여 획득된 이미지일 수 있다. 제1 이미지는 객체의 전체 3차원 형상을 포함하지 않고 관심 영역을 확대하여 포함하고 있으므로, 관심 영역을 식별하기에 적합한 이미지일 수 있다. 이 경우, 전자 장치는 제1 이미지 를 관심 영역 식별 모델에 입력함으로써, 제1 이미지 내에서 적어도 하나의 라벨에 대응하는 영역 을 관심 영역으로 식별할 수 있다. 일 실시예에서, 전자 장치가 제2 카메라를 이용하여 획득한 제2 이미지는, 광각 카메라 및/또는 초 광각 카메라를 이용하여 획득된 이미지일 수 있다. 제2 이미지는 객체의 전체 3차원 형상을 포함하고 있 으므로, 객체의 3차원 형상을 식별하기에 적합한 이미지일 수 있다. 이 경우, 전자 장치는 제2 이미지 를 객체 3차원 형상 식별 모델에 입력함으로써, 제2 이미지 내의 객체의 3차원 형상 타입을 식별할 수 있다. 도 16a는 본 개시의 일 실시예에 따른 전자 장치가 멀티 카메라를 이용하는 동작을 설명하기 위한 흐름도이다. 단계 S1610에서, 일 실시예에 따른 전자 장치는 제1 카메라를 이용하여 실시간으로 촬영되는 제1 이미지 를 제1 AI 모델(관심 영역 식별 모델)에 적용하여 관심 영역의 신뢰도를 획득한다. 제1 카메라는 망원 카메라일 수 있다. 일 실시예에서, 전자 장치의 사용자가 객체를 인식하고자 하는 경우(예를 들어, 상품의 라벨을 검색하고 자 하는 경우 등), 사용자는 카메라 애플리케이션을 활성화할 수 있다. 사용자는 전자 장치의 화면에 표 시되는 프리뷰 이미지 등을 보면서 카메라가 객체를 응시하도록 카메라의 시야를 계속하여 조정할 수 있다. 전 자 장치는 제1 카메라를 통해 실시간으로 획득되는 제1 이미지 프레임들에 대하여, 각각의 제1 이미지 프 레임들을 관심 영역 식별 모델에 입력할 수 있다. 전자 장치는 각각의 제1 이미지 프레임들에 대한 관심 영역 식별의 정확도를 나타내는, 관심 영역의 신뢰도를 획득할 수 있다. 단계 S1620에서, 일 실시예에 따른 전자 장치는 제2 카메라를 이용하여 실시간으로 촬영되는 제2 이미지 를 제2 AI 모델에 적용하여 객체의 3차원 형상 타입의 신뢰도를 획득한다. 제2 카메라는, 광각 카메라 또는 초 광각 카메라일 수 있다. 일 실시예에서, 전자 장치는 제2 카메라를 통해 실시간으로 획득되는 제2 이미지 프레임들에 대하여, 각 각의 제2 이미지 프레임들을 객체 3차원 형상 추정 모델에 입력할 수 있다. 전자 장치는 각각의 제2 이미 지 프레임들에 대한 객체 3차원 형상 추정의 정확도를 나타내는, 객체의 3차원 형상 타입의 신뢰도를 획득할 수 있다. 단계 S1630에서, 일 실시예에 따른 전자 장치는 관심 영역의 신뢰도가 제1 임계 값을 초과하는지 여부를 판단한다. 제1 임계 값은 관심 영역에 대하여 기 설정된 임계 값일 수 있다. 전자 장치는 관심 영역의 신 뢰도가 제1 임계 값 이하인 경우, 제1 임계 값을 초과하는 신뢰도가 획득될 때까지 단계 S1610을 계속하여 수행 할 수 있다. 단계 S1640에서, 일 실시예에 따른 전자 장치는 객체의 3차원 형상 타입의 신뢰도가 제2 임계 값을 초과 하는지 여부를 판단한다. 제2 임계 값은 객체의 3차원 형상에 대하여 기 설정된 임계 값일 수 있다. 전자 장치 는 객체의 3차원 형상 타입의 신뢰도가 제2 임계 값 이하인 경우, 제2 임계 값을 초과하는 신뢰도가 획득 될 때까지 단계 S1620을 계속하여 수행할 수 있다. 단계 S1650에서, 일 실시예에 따른 전자 장치는 제1 이미지 및 제2 이미지를 각각 캡쳐한다. 일 실시예에서, 단계 S1650이 수행되는 조건은 관심 영역의 신뢰도가 제1 임계 값을 초과하고, 3차원 형상 타입 의 신뢰도가 제2 임계 값을 초과하는 AND 조건이다. 전자 장치는 제1 이미지 및 제2 이미지를 각각 캡쳐 하여 저장하고, 단계 S1520 및 그 이후의 단계들을 수행할 수 있다. 이 경우, 전자 장치는 제1 이미지를 관심 영역 식별 모델에 적용함으로써 객체의 표면의 관심 영역을 식별하고, 제2 이미지를 객체 3차원 형상 식별 모델에 적용함으로써 객체의 3차원 형상을 식별할 수 있다. 이에 대한 구체적인 동작들은 전술하였으므로, 동일 한 설명은 생략한다. 도 16b는 도 16a를 보충적으로 더 설명하기 위한 도면이다. 도 16b 및 도 16c를 설명함에 있어서, 사용자가 와인의 라벨을 인식하고자 하는 경우를 예시로 설명한다. 도 16b를 참조하면, 일 실시예에 따른 전자 장치는 객체 인식을 위한 제1 화면을 표시할 수 있다. 제1 화면은 전자 장치의 사용자가 객체 인식을 수행할 수 있도록 가이드하는 인터페이스를 포함할 수 있다. 예를 들어, 전자 장치는 제1 화면에 객체의 관심 영역이 포함되도록 가이드하는 사각 박 스(다만, 사각형에 한정되지 않으며 원형 등 유사한 기능을 할 수 있는 다른 형태를 포함함)를 표시하고, '와인 라벨을 검색합니다' 등의 가이드를 표시할 수 있다. 일부 실시예에서, 전자 장치는 제1 화면 에 표시되는 이미지로부터 객체가 인식되지 않는 경우, '카메라를 통해 상품을 비춰 주세요' 등의 가이드 를 표시할 수 있다. 일 실시예에서, 전자 장치는 카메라로부터 획득되는 프리뷰 이미지를 나타내는 제2 화면을 표시할 수 있다. 사용자는 제2 화면을 보면서, 객체가 이미지 내에 완전히 포함되도록 카메라의 시야를 조정할 수 있다. 전자 장치는 카메라의 프리뷰 이미지인 제2 화면이 표시되는 동안, 관심 영역의 신뢰도 및 객체의 3차원 형상 타입의 신뢰도를 계산할 수 있다. 이는, 전술하였으므로 동일한 설명은 생략한다. 관심 영역의 신뢰도가 제1 임계값을 초과하고, 객체의 3차원 형상 타입의 신뢰도가 제2 임계값을 초과하는 경우, 전자 장치는 관심 영역으로 식별된 적어도 하나의 라벨에 대응하는 영역 및 객체의 3차원 형상 타 입에 관한 데이터에 기초하여, 객체와 관련된 3차원 파라미터 값들을 획득할 수 있다. 그리고 전자 장치 는 객체와 관련된 3차원 파라미터 값들을 이용하여 적어도 하나의 라벨의 굴곡 형상을 추정하고, 원근 변환을 수행함으로써, 적어도 하나의 라벨의 굴곡 형상이 평평하게 된 플랫 라벨 이미지를 획득할 수 있다. 전자 장치 는 플랫 라벨 이미지가 획득되고 플랫 라벨 이미지로부터 객체에 관련된 정보가 추출되는 경우(즉, 상품 이 인식되는 경우), '와인 정보가 검색되었습니다'와 같은 알림을 프리뷰 이미지 상에 출력할 수 있다. 그리고 전자 장치는 플랫 라벨 이미지로부터 추출된 객체에 관련된 정보를 출력할 수 있다. 예를 들어, 전자 장치는 와인 라벨 이미지 및 와인에 관한 상세 정보를 출력할 수 있다. 도 16c는 도 16a를 보충적으로 더 설명하기 위한 도면이다. 도 16c를 참조하면, 일 실시예에 따른 전자 장치는 객체 인식을 위한 제1 화면을 표시할 수 있다. 제1 화면은 전자 장치의 사용자가 객체 인식을 수행할 수 있도록 가이드하는 인터페이스를 포함할 수 있다. 예를 들어, 전자 장치는 제1 화면에 객체의 관심 영역이 포함되도록 가이드하는 사각 박 스(다만, 사각형에 한정되지 않으며 원형 등 유사한 기능을 할 수 있는 다른 형태를 포함함)를 표시하고, '와인 라벨을 검색합니다' 등의 가이드를 표시할 수 있다. 일부 실시예에서, 전자 장치는 제1 화면 에 표시되는 이미지로부터 객체가 인식되지 않는 경우, '카메라를 통해 상품을 비춰 주세요' 등의 가이드 를 표시할 수 있다. 일 실시예에서, 전자 장치는 카메라의 프리뷰 이미지인 제2 화면이 표시되는 동안, 관심 영역의 신 뢰도 및 객체의 3차원 형상 타입의 신뢰도를 계산할 수 있다. 전자 장치는 관심 영역의 신뢰도가 제1 임 계 값을 초과하고, 객체의 3차원 형상 타입의 신뢰도가 제2 임계 값을 초과하여야 이미지로부터 왜곡을 제거하 기 위한 이후의 동작들을 수행한다. 따라서, 관심 영역의 신뢰도가 제1 임계 값 이하 및/또는 객체의 3차원 형 상 타입의 신뢰도가 제2 임계 값 이하인 경우, 전자 장치는 제1 이미지 및 제2 이미지를 획득하기 위해 사용자에게 카메라 시야를 조정할 수 있도록 가이드하는 알림을 출력할 수 있다. 예를 들어, 전자 장치는 '와인 라벨을 인식할 수 없습니다. 카메라 각도를 조정해 주세요'와 같은 알림을 화면에 표시하거나, 오 디오로 출력할 수 있다. 도 17은 본 개시의 일 실시예에 따른 전자 장치가 이미지를 처리하여 추출된 정보를 제공하는 동작을 설명하기 위한 도면이다. 일 실시예에서, 전자 장치는 왜곡 없는 이미지인 플랫 라벨 이미지를 생성하고, 플랫 라벨 이미지로부터 객체와 관련된 정보를 추출하여 사용자에게 제공할 수 있다. 일 실시예에서, 전자 장치는 객체 인식을 시작하기 위한 제1 화면을 표시할 수 있다. 제1 화면 에는 '와인 라벨 스캔'과 같은 사용자 인터페이스가 포함될 수 있다. 전자 장치의 사용자는 사용자 인터페이스를 통해 객체 인식 동작을 시작할 수 있다. 일 실시예에서, 전자 장치는 객체 인식을 수행하기 위한 제2 화면을 표시할 수 있다. 제2 화면 은 전자 장치의 사용자가 객체 인식을 수행할 수 있도록 가이드하는 인터페이스를 포함할 수 있다. 예를 들어, 전자 장치는 제2 화면에 객체의 관심 영역이 포함되도록 가이드하는 가이드 영역(1702- 1)를 표시하고, '와인 전면 라벨을 촬영하세요' 등의 가이드 문구(1702-2)를 표시할 수 있다. 전자 장치는 멀티 카메라를 통해 복수의 이미지들(예를 들어, 망원 이미지, 광각 이미지, 초광각 이미지 등)을 획득하고, 전술한 실시예들에 따른 3차원 정보에 기초한 왜곡 제거 동작들을 수행할 수 있다. 즉, 전자 장치는 이미 지 내에서 와인 라벨 영역을 추출하고, 왜곡을 제거하는 보정을 수행하여 왜곡 없는 와인 라벨 이미지를 생성한 다. 또한, 전자 장치는 왜곡 없는 와인 라벨 이미지에 OCR을 적용하여, 와인과 관련된 정보들을 추출할 수 있다. 전자 장치는 와인 라벨에서 식별된 텍스트 정보를 이용하여, 와인 정보를 검색할 수 있다. 일 실시예에서, 전자 장치가 1)와인 라벨 영역을 추출/보정하고, 2)와인 라벨에서 식별된 텍스트 정보를 이용하여 와인 정보를 검색 하면, 전자 장치는 객체 인식 및 검색 결과를 나타내는 제3 화면을 표 시할 수 있다. 제3 화면에는 전자 장치가 전술한 실시예들에 따라 생성한 왜곡 없는 이미지가 표시 될 수 있다. 도 17의 예시에서 왜곡 없는 이미지는, 와인 라벨 이미지일 수 있다. 와인 라벨 이미지는 와인 병 에 곡선형으로 부착된 와인 라벨이 평평하게 변환된, 플랫 라벨 이미지일 수 있다. 제3 화면에는, 전자 장치가 전술한 실시예들에 따라 획득한 객체와 관련된 정보가 표시될 수 있다. 도 17의 예시에서 객체와 관련된 정보는, 와인 상세 정보일 수 있다. 이 경우, 와인 라벨 이미지로부터 OCR을 수행한 결과인, 와인 이름, 원산지, 생산 년도 등이 표시될 수 있다. 일 실시예에서, 제3 화면에는, 와인 라벨 이미지로부터 획득된 객체와 관련된 정보 외에도, 서버로부터 획득되거나 전자 장치의 데이터베이스로부터 획득된, 객체에 관련된 추가 정보가 더 표시될 수 있다. 예 를 들어, 와인 라벨 이미지로부터 획득될 수 없는 와인의 산도, 바디감, 알코올 도수 등이 표시될 수 있다. 일 실시예에서, 제3 화면에는 다른 전자 장치로부터 획득되는 정보 및/또는 사용자 입력에 기초하여 획득 되는 정보가 더 표시될 수 있다. 예를 들어, 와인의 별명, 입고일, 보관 위치, 등이 표시될 수 있다. 다만, 와인 라벨 이미지로부터 획득 가능한 정보 및 와인 라벨 이미지 외 다른 경로로부터 획득 되어 표시되는 정보는 예시적으로 설명한 것이며, 전술한 것으로 한정되는 것은 아니다. 일 실시예에서, 전자 장치는 객체 인식 및 검색 결과를 데이터베이스화한 제4 화면을 표시할 수 있 다. 이 경우, 전자 장치는 왜곡 없는 이미지인 플랫 라벨 이미지들을 미리보기 형태로 표시할 수 있다. 각각의 플랫 라벨 이미지들을 선택하면, 제 3화면과 같이, 선택된 플랫 라벨 이미지에 대응하는 와 인 정보들이 다시 표시될 수 있다. 도 18은 본 개시의 일 실시예에 따른 전자 장치가 이미지를 처리하는 동작에 관련된 시스템의 일 예시를 설명하 기 위한 도면이다. 일 실시예에서, 전자 장치가 사용하는 모델들은, 신경망 연산을 수행하기에 적합한 다른 전자 장치(예를 들어, 로컬 PC 등)에서 훈련된 것일 수 있다. 예를 들어, 객체 3차원 형상 추정 모델, 관심 영역 식별 모델, 왜 곡 제거 모델, 정보 추출 모델 등이 다른 전자 장치에서 훈련되어 학습 완료된 상태로 저장되어 있을 수 있다. 일 실시예에서, 전자 장치는 다른 전자 장치에 저장된, 훈련된 모델들을 수신할 수 있다. 전자 장치 는 수신된 모델들에 기초하여, 전술한 이미지 처리 동작들을 수행할 수 있다. 이 경우, 전자 장치 는 훈련된 모델들을 실행하여 추론 동작을 수행하고, 플랫 라벨 이미지와 라벨 정보를 생성할 수 있다. 생성된 플랫 라벨 이미지 및 라벨 정보는, 애플리케이션 등을 통해 사용자에게 제공될 수 있다. 도 18에서는, 전자 장 치의 예시로 모바일 폰에 모델이 저장되어 사용되는 것을 예시로 설명하였으나, 이에 한정되는 것은 아니 다. 전자 장치는 TV, 태블릿 PC, 스마트 냉장고 등등, 애플리케이션을 실행 가능하고 디스플레이 및 카메 라가 탑재된 모든 전자 장치를 포함할 수 있다. 한편, 이전 도면들의 설명에서 기술한 것처럼, 전자 장치가 사용하는 모델들은, 전자 장치의 컴퓨 팅 자원을 이용하여 훈련될 수 있다. 이에 대한 구체적인 설명은 전술하였으므로, 생략한다. 도 19는 본 개시의 일 실시예에 따른 전자 장치가 서버를 이용하여 이미지를 처리하는 동작에 관련된 시스템의 일 예시를 설명하기 위한 도면이다. 일 실시예에서, 전자 장치가 사용하는 모델들은, 신경망 연산을 수행하기에 적합한 다른 전자 장치(예를 들어, 로컬 PC 등)에서 훈련된 것일 수 있다. 예를 들어, 객체 3차원 형상 추정 모델, 관심 영역 식별 모델, 왜 곡 제거 모델, 정보 추출 모델 등이 다른 전자 장치에서 훈련되어 학습 완료된 상태로 저장되어 있을 수 있다. 또한, 다른 전자 장치(예를 들어, 로컬 PC 등)에서 훈련된 모델들은, 또다른 전자 장치(예를 들어, 서버 등)로 전송되어 저장될 수 있다.일 실시예에서, 전자 장치는 서버를 이용하여 이미지 처리 동작들을 수행할 수 있다. 전자 장치는 카메라를 이용하여 객체 이미지들(예를 들어, 망원 이미지, 광각 이미지, 초광각 이미지 등)을 촬영하고, 이미 지들을 서버로 전송할 수 있다. 이 경우, 서버는 훈련된 모델들을 실행하여 추론 동작을 수행하고, 플랫 라벨 이미지와 라벨 정보를 생성할 수 있다. 전자 장치는 서버로부터 플랫 라벨 이미지와 라벨 정보를 수신할 수 있다. 수신된 플랫 라벨 이미지 및 라벨 정보는, 애플리케이션 등을 통해 사용자에게 제공될 수 있다. 도 19 에서는, 전자 장치의 예시로 모바일 폰에 모델이 저장되어 사용되는 것을 예시로 설명하였으나, 이에 한 정되는 것은 아니다. 전자 장치는 TV, 태블릿 PC, 스마트 냉장고 등등, 애플리케이션을 실행 가능하고 디 스플레이 및 카메라가 탑재된 모든 전자 장치를 포함할 수 있다. 한편, 이전 도면들의 설명에서 기술한 것처럼, 전자 장치가 사용하는 모델들은, 전자 장치의 컴퓨 팅 자원을 이용하여 훈련될 수 있다. 이에 대한 구체적인 설명은 전술하였으므로, 생략한다. 도 20은 본 개시의 일 실시예에 따른 전자 장치의 구성을 도시한 블록도이다. 일 실시예에 따른 전자 장치는 통신 인터페이스, 카메라(들), 메모리 및 프로세서 를 포함할 수 있다. 통신 인터페이스는 프로세서의 제어에 의해 다른 전자 장치들과 데이터 통신을 수행할 수 있다. 통신 인터페이스는 통신 회로를 포함할 수 있다. 통신 인터페이스는 예를 들어, 유선 랜, 무선 랜 (Wireless LAN), 와이파이(Wi-Fi), 블루투스(Bluetooth), 지그비(ZigBee), WFD(Wi-Fi Direct), 적외선 통신 (IrDA, infrared Data Association), BLE (Bluetooth Low Energy), NFC(Near Field Communication), 와이브로 (Wireless Broadband Internet, Wibro), 와이맥스(World Interoperability for Microwave Access, WiMAX), SWAP(Shared Wireless Access Protocol), 와이기그(Wireless Gigabit Alliances, WiGig) 및 RF 통신을 포함하 는 데이터 통신 방식 중 적어도 하나를 이용하여, 전자 장치와 다른 디바이스들 간의 데이터 통신을 수행 할 수 있는, 통신 회로를 포함할 수 있다. 통신 인터페이스는 전자 장치의 이미지 처리 동작을 수행하기 위한 데이터를 외부 전자 장치와 송 수신할 수 있다. 예를 들어, 통신 인터페이스는 전자 장치가 이용하는 인공지능 모델들을 송수신하 거나, 인공지능 모델들의 훈련 데이터셋을 서버 등과 송수신할 수 있다. 또한, 전자 장치는 왜곡이 제거 되어야 할 이미지를 서버 등으로부터 획득할 수 있다. 또한, 전자 장치는 객체와 관련된 정보를 검색하기 위해 서버 등과 데이터를 송수신할 수 있다. 카메라(들)는 객체를 촬영하여 비디오 및/또는 이미지를 획득할 수 있다. 카메라(들)는 하나 이상 일 수 있다. 카메라(들)는 예를 들어, RGB 카메라, 망원 카메라, 광각 카메라, 초광각 카메라 등을 포함 할 수 있으나, 이에 한정되는 것은 아니다. 카메라(들)는 복수의 프레임들을 포함하는 비디오를 획득할 수 있다. 카메라(들)의 구체적인 종류 및 세부 기능은 통상의 기술자가 명확하게 추론할 수 있으므로, 설 명을 생략한다. 메모리는 프로세서가 판독할 수 있는 명령어들, 데이터 구조, 및 프로그램 코드(program code)가 저장될 수 있다. 메모리는 하나 이상일 수 있다. 개시된 실시예들에서, 프로세서가 수행하는 동작 들은 메모리에 저장된 프로그램의 명령어들 또는 코드들을 실행함으로써 구현될 수 있다. 메모리는 플래시 메모리 타입(flash memory type), 하드디스크 타입(hard disk type), 멀티미디어 카드 마이크로 타입(multimedia card micro type), 카드 타입의 메모리(예를 들어 SD 또는 XD 메모리 등)를 포함할 수 있으며, 롬(ROM, Read-Only Memory), EEPROM(Electrically Erasable Programmable Read-Only Memory), PROM(Programmable Read-Only Memory), 자기 메모리, 자기 디스크, 광디스크 중 적어도 하나를 포함하는 비 휘 발성 메모리 및 램(RAM, Random Access Memory) 또는 SRAM(Static Random Access Memory)과 같은 휘발성 메모 리를 포함할 수 있다. 일 실시예에 따른 메모리는 전자 장치가 이미지 내 왜곡을 제거하기 위해 동작하도록 하는 하나 이 상의 인스트럭션 및/또는 프로그램을 저장할 수 있다. 예를 들어, 메모리에는 관심 영역 식별 모듈 , 객체 3차원 형상 식별 모듈, 3차원 정보 획득 모듈, 왜곡 제거 모듈 및 정보 추출 모듈이 저장될 수 있다. 프로세서는 전자 장치의 전반적인 동작들을 제어할 수 있다. 예를 들어, 프로세서는 메모리 에 저장된 프로그램의 하나 이상의 명령어들(instructions)을 실행함으로써, 전자 장치가 이미지에서 왜곡을 제거하기 위한 전반적인 동작들을 제어할 수 있다. 프로세서는 하나 이상일 수 있다. 본 개시에 따른 하나 이상의 프로세서는 CPU (Central Processing Unit), GPU (Graphics Processing Unit), APU (Accelerated Processing Unit), MIC (Many Integrated Core), DSP (Digital Signal Processor), 및 NPU (Neural Processing Unit) 중 적어도 하나를 포함할 수 있다. 하나 이상의 프로세서는, 하나 이 상의 전자부품을 포함하는 집적된 시스템 온 칩(SoC) 형태로 구현될 수 있다. 하나 이상의 프로세서 각각은 별 개의 하드웨어(H/W)로 구현될 수도 있다. 프로세서는 관심 영역 식별 모듈을 실행하여, 이미지 내에서 적어도 하나의 라벨에 대응하는 영역 을 관심 영역으로 식별할 수 있다. 관심 영역 식별 모듈은 관심 영역 식별 모델을 포함할 수 있다. 관심 영역 식별 모듈에 관련된 구체적인 동작들은, 이전의 도면들에서 상세하게 설명하였으므로, 동일한 설명 은 생략한다. 프로세서는 객체 3차원 형상 식별 모듈을 실행하여, 이미지 내의 객체의 3차원 형상 타입에 관한 데이터를 획득한다. 객체 3차원 형상 식별 모듈은 객체 3차원 형상 식별 모델을 포함할 수 있다. 객체 3 차원 형상 식별 모듈에 관련된 구체적인 동작들은, 이전의 도면들에서 상세하게 설명하였으므로, 동일한 설명은 생략한다. 프로세서는 3차원 정보 획득 모듈을 실행하여, 이미지 내의 객체의 3차원 정보를 추론할 수 있다. 프로세서는 관심 영역 및 객체의 3차원 형상 타입에 관한 데이터에 기초하여, 객체, 적어도 하나의 라벨 및 제1 카메라 중 적어도 하나와 관련된 3차원 파라미터 값들을 획득한다. 여기서, 3차원 파라미터 값들을 획득 한다고 하는 것은, 객체의 3차원 형상에 대응하는 3차원 파라미터의 초기값들을 미세 조정하여, 객체의 3차원 정보를 나타내도록 한 것일 수 있다. 3차원 정보 획득 모듈에 관련된 구체적인 동작들은, 이전의 도면들 에서 상세하게 설명하였으므로, 동일한 설명은 생략한다. 프로세서는 왜곡 제거 모듈을 실행하여, 이미지의 왜곡을 제거할 수 있다. 왜곡 제거 모듈은 왜곡 제거 모델을 포함할 수 있다. 프로세서는 3차원 파라미터에 기초하여, 적어도 하나의 라벨의 굴곡 형상을 추정할 수 있다. 프로세서는 적어도 하나의 라벨에 대한 원근 변환을 수행함으로써, 라벨의 굴곡 형상이 평평하게 된, 플랫 라벨 이미지를 획득할 수 있다. 왜곡 제거 모듈에 관련된 구체적인 동작들은, 이전의 도면들에서 상세하게 설명하였으므로, 동일한 설명은 생략한다. 프로세서는 정보 추출 모듈을 실행하여, 왜곡 없는 이미지로부터 정보를 추출할 수 있다. 정보 추 출 모듈은 정보 추출 모델을 포함할 수 있다. 프로세서는 정보 추출 모듈을 이용하여 관심 영역 내 정보를 추출하며, 예를 들어, 관심 영역 내의 로고, 아이콘, 텍스트 등을 식별할 수 있다. 정보 추출 모듈 에 관련된 구체적인 동작들은, 이전의 도면들에서 상세하게 설명하였으므로, 동일한 설명은 생략한다. 한편, 전술한 메모리에 저장된 모듈들은, 설명의 편의를 위한 것이며 반드시 이에 한정되는 것은 아니다. 전술한 실시예들을 구현하기 위해 다른 모듈이 추가될 수 있으며, 전술한 모듈들 중 일부의 모듈들은 하나의 모 듈로 구현될 수도 있다. 본 개시의 일 실시예에 따른 방법이 복수의 동작을 포함하는 경우, 복수의 동작은 하나의 프로세서에 의해 수행 될 수도 있고, 복수의 프로세서에 의해 수행될 수도 있다. 예를 들어, 일 실시예에 따른 방법에 의해 제1 동작, 제2 동작, 제3 동작이 수행될 때, 제1 동작, 제2 동작, 및 제3 동작 모두 제1 프로세서에 의해 수행될 수도 있 고, 제1 동작 및 제2 동작은 제1 프로세서(예를 들어, 범용 프로세서)에 의해 수행되고 제3 동작은 제2 프로세 서(예를 들어, 인공지능 전용 프로세서)에 의해 수행될 수도 있다. 여기서, 제2 프로세서의 예시인 인공지능 전 용 프로세서는, 인공지능 모델의 훈련/추론을 위한 연산들이 수행될 수도 있다. 그러나, 본 개시의 실시예들이 이에 한정되는 것은 아니다. 본 개시에 따른 하나 이상의 프로세서는 싱글 코어 프로세서(single-core processor)로 구현될 수도 있고, 멀티 코어 프로세서(multi-core processor)로 구현될 수도 있다. 본 개시의 일 실시예에 따른 방법이 복수의 동작을 포함하는 경우, 복수의 동작은 하나의 코어에 의해 수행될 수도 있고, 하나 이상의 프로세서에 포함된 복수의 코어에 의해 수행될 수도 있다. 도 20에 도시 되지는 않았지만, 전자 장치는 사용자 인터페이스를 더 포함할 수 있다. 사용자 인터페이스 는 사용자의 입력을 수신하는 입력 인터페이스와 정보를 출력하는 출력 인터페이스를 포함할 수 있다. 출력 인터페이스는 비디오 신호 또는 오디오 신호의 출력을 위한 것이다. 출력 인터페이스는 디스플레이부, 음 향 출력부, 진동 모터 등을 포함할 수 있다. 디스플레이부와 터치패드가 레이어 구조를 이루어 터치스크린으로 구성되는 경우, 디스플레이부는 출력 인터페이스 이외에 입력 인터페이스로도 사용될 수 있다. 디스플레이부는 액정 디스플레이(liquid crystal display), 박막 트랜지스터 액정 디스플레이(thin film transistor-liquid crystal display), 발광 다이오드(LED, light-emitting diode), 유기 발광 다이오드(organic light-emitting diode), 플렉시블 디스플레이(flexible display), 3차원 디스플레이(3D display), 전기영동 디스플레이 (electrophoretic display) 중에서 적어도 하나를 포함할 수 있다. 그리고 전자 장치의 구현 형태에 따라 전자 장치는 디스플레이부를 2개 이상 포함할 수도 있다. 음향 출력부는 통신 인터페이스로부터 수신되거나 메모리에 저장된 오디오 신호를 출력할 수 있다. 또한, 음향 출력부는 전자 장치에서 수행되는 기능과 관련된 음향 신호를 출력할 수 있다. 음향 출력부는 스피커(speaker), 부저(Buzzer) 등을 포함할 수 있다. 입력 인터페이스는, 사용자로부터의 입력을 수신하기 위한 것이다. 입력 인터페이스는, 키 패드(key pad), 돔 스위치 (dome switch), 터치 패드(접촉식 정전 용량 방식, 압력식 저항막 방식, 적외선 감지 방식, 표면 초음파 전도 방식, 적분식 장력 측정 방식, 피에조 효과 방식 등), 조그 휠, 조그 스위치 중 적어도 하나일 수 있으나, 이에 한정되는 것은 아니다. 입력 인터페이스는, 음성 인식 모듈을 포함할 수 있다. 예를 들어, 전자 장치는 마이크로폰을 통해 아날 로그 신호인 음성 신호를 수신하고, ASR(Automatic Speech Recognition) 모델을 이용하여 음성 부분을 컴퓨터로 판독 가능한 텍스트로 변환할 수 있다. 전자 장치는 자연어 이해(Natural Language Understanding, NLU) 모델을 이용하여 변환된 텍스트를 해석하여, 사용자의 발화 의도를 획득할 수 있다. 여기서 ASR 모델 또는 NLU 모델은 인공지능 모델일 수 있다. 언어적 이해는 인간의 언어/문자를 인식하고 응용/처리하는 기술로서, 자연어 처리(Natural Language Processing), 기계 번역(Machine Translation), 대화 시스템(Dialog System), 질의 응 답(Question Answering), 음성 인식/합성(Speech Recognition/Synthesis) 등을 포함한다. 도 21은 본 개시의 일 실시예에 따른 서버의 구성을 도시한 블록도이다. 일 실시예에서, 전술한 전자 장치의 동작들은, 서버에서 수행될 수 있다. 일 실시예에 따른 서버는 통신 인터페이스, 메모리 및 프로세서를 포함할 수 있다. 서 버의 통신 인터페이스, 메모리 및 프로세서는 도 20의 전자 장치의 통신 인터페 이스, 메모리 및 프로세서에 각각 대응되므로, 동일한 설명은 생략한다. 일 실시예에 따른 서버는, 전자 장치 보다 연산량이 많은 연산을 수행 가능하도록, 컴퓨팅 성능이 전자 장치보다 높은 장치일 수 있다. 서버는 추론에 비해 상대적으로 많은 연산량이 요구되는, 인 공지능 모델의 훈련을 수행할 수 있다. 서버는 인공지능 모델을 이용하여 추론을 수행하고, 추론 결과를 전자 장치로 전송할 수 있다. 본 개시는, 3차원 정보를 활용한 이미지 왜곡 제거 방법에 있어서, 3차원 정보 획득을 위한 센서 등의 하드웨어 없이, 알고리즘을 이용하여 객체의 3차원 정보를 추론하고, 이미지 내 왜곡을 제거하는 이미지 처리 방법을 제 시하고자 한다. 본 개시에서 이루고자 하는 기술적 과제는, 이상에서 언급한 것으로 제한되지 않으며, 언급되지 않은 또 다른"}
{"patent_id": "10-2022-0133618", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "기술적 과제들은 아래의 기재로부터 본 발명이 속하는 기술분야에서 통상의 지식을 가진 자에게 명확하게 이해 될 수 있을 것이다. 본 개시의 일 측면에 따르면, 전자 장치가 이미지를 처리하는 방법이 제공될 수 있다. 상기 방법은, 제1 카메라를 이용하여 적어도 하나의 라벨을 포함하는 객체의 제1 이미지를 획득하는 단계를 포함할 수 있다. 상기 방법은, 상기 제1 이미지를 제1 AI 모델에 적용함으로써, 상기 제1 이미지 내에서 상기 적어도 하나의 라벨에 대응하는 영역을 관심 영역으로 식별하는 단계를 포함할 수 있다. 상기 방법은, 상기 제1 이미지를 제2 AI 모델 에 적용함으로써, 상기 객체의 3차원 형상 타입에 관한 데이터를 획득하는 단계를 포함할 수 있다. 상기 방법은, 상기 관심 영역으로 식별된 상기 적어도 하나의 라벨에 대응하는 영역 및 상기 객체의 3차원 형상 타입 에 관한 데이터에 기초하여, 상기 객체, 상기 적어도 하나의 라벨 및 상기 제1 카메라 중 적어도 하나와 관련된 3차원 파라미터 값들을 획득하는 단계를 포함할 수 있다. 상기 방법은, 상기 3차원 파라미터 값들에 기초하여, 상기 적어도 하나의 라벨의 굴곡 형상을 추정하는 단계를 포함할 수 있다. 상기 방법은, 상기 적어도 하나의 라 벨에 대한 원근 변환(perspective transformation)을 수행함으로써, 상기 적어도 하나의 라벨의 굴곡 형상이 평평하게 된 플랫(flat) 라벨 이미지를 획득하는 단계를 포함할 수 있다. 상기 3차원 파라미터 값들은, 상기 객체의 3차원 형상과 관련된 가로, 값 세로 값 , 높이 값 및 반지름 값, 상 기 객체의 표면의 관심 영역의 각도 값, 3차원 기하학적 변환을 위한 이동(translation) 값 및 회전(rotation) 값, 및 상기 카메라의 초점 거리 값 중 적어도 하나를 포함할 수 있다. 상기 제1 AI 모델은, 이미지 내에서 라벨에 대응하는 영역을 관심 영역으로 추론하도록 훈련된 인공지능 모델일 수 있다. 상기 제2 AI 모델은, 이미지 내 객체의 3차원 형상 타입을 추론하도록 훈련된 인공지능 모델일 수 있 다. 상기 객체의 3차원 형상 타입에 관한 데이터를 획득하는 단계는, 사용자로부터 상기 객체의 3차원 형상 타입에 관련된 사용자 입력을 수신하는 단계를 포함할 수 있다. 상기 객체의 3차원 형상 타입에 관한 데이터를 획득하 는 단계는, 복수의 3차원 형상 타입 중에서 상기 사용자 입력에 대응하는 3차원 형상 타입에 가중치를 적용하여 상기 객체의 3차원 형상 타입을 식별하는 단계를 더 포함할 수 있다. 상기 적어도 하나의 라벨에 대응하는 영역을 상기 관심 영역으로 식별하는 단계는, 상기 적어도 하나의 라벨에 대응하는 영역을 나타내는 제1 키포인트들을 식별하는 단계를 포함할 수 있다. 상기 3차원 파라미터 값들을 획 득하는 단계는, 상기 객체의 3차원 형상 타입에 대응하는 가상 객체 및 상기 가상 객체의 3차원 파라미터 초기 값들을 획득하는 단계를 포함할 수 있다. 상기 3차원 파라미터 값들을 획득하는 단계는, 상기 제1 키포인트들에 기초하여, 상기 가상 객체의 3차원 파라미터 초기값들을 조정하는 단계를 더 포함할 수 있다. 상기 3차원 파라 미터 값들을 획득하는 단계는, 상기 조정된 3차원 파라미터 초기 값들을 상기 3차원 파라미터 값들로 획득하는 단계를 더 포함할 수 있다. 상기 제1 키포인트들에 기초하여, 상기 가상 객체의 3차원 파라미터의 초기값들을 조정하는 단계는, 상기 가상 객체의 가상 라벨에 대응하는 영역을 나타내는 제2 키포인트들을 설정하는 단계를 포함할 수 있다. 상기 제1 키 포인트들에 기초하여, 상기 가상 객체의 3차원 파라미터의 초기값들을 조정하는 단계는, 상기 제2 키포인트들이 상기 제1 키포인트들에 정합하도록 상기 가상 객체의 3차원 파라미터 초기값들을 조정하는 단계를 더 포함할 수 있다. 상기 플랫 라벨 이미지로부터 상기 객체와 관련된 정보를 획득하는 단계는, 상기 플랫 이미지에 광학 문자 인식 (Optical character recognition; OCR)을 적용하는 단계를 포함할 수 있다. 상기 전자 장치는, 상기 제1 카메라보다 화각이 넓은 제2 카메라를 더 포함할 수 있다. 상기 객체의 3차원 형상 타입에 관한 데이터를 획득하는 단계는, 상기 제2 카메라를 통해 상기 객체의 제2 이미 지를 획득하는 단계를 포함할 수 있다. 상기 객체의 3차원 형상 타입에 관한 데이터를 획득하는 단계는, 상기 제2 이미지를 상기 제2 AI 모델에 더 적용함으로써, 상기 객체의 3차원 형상 타입에 관련된 정보를 획득하는 단 계를 더 포함할 수 있다. 상기 방법은, 상기 제1 카메라를 이용하여 실시간으로 촬영되는 상기 제1 이미지를 상기 제1 AI 모델에 적용하 여 상기 관심 영역의 신뢰도를 획득하는 단계를 더 포함할 수 있다. 상기 방법은, 상기 제2 카메라를 이용하여 실시간으로 촬영되는 제2 이미지를 상기 제2 AI 모델에 적용하여 상기 객체의 3차원 형상 타입의 신뢰도를 획득 하는 단계를 더 포함할 수 있다. 상기 방법은, 상기 객체의 3차원 형상 타입의 신뢰도 및 상기 관심 영역의 신 뢰도 각각의 임계 값에 기초하여, 상기 제1 이미지 및 상기 제2 이미지를 각각 캡쳐하는 단계를 더 포함할 수 있다. 상기 방법은, 상기 플랫 라벨 이미지 또는 상기 플랫 라벨 이미지로부터 획득된 정보에 기초하여, 데이터베이스 내에서 일치하는 데이터를 검색하는 단계를 더 포함할 수 있다. 상기 방법은, 상기 검색 결과를 표시하는 단계 를 더 포함하되, 상기 데이터베이스는, 상기 전자 장치가 이전에 획득한 또다른 플랫 라벨 이미지들 및 또다른 객체들과 관련된 정보가 저장된 것일 수 있다. 본 개시의 일 측면에 따르면, 이미지를 처리하는 전자 장치가 제공될 수 있다. 상기 전자 장치는, 제1 카메라, 하나 이상의 인스트럭션을 저장하는 메모리, 및 상기 메모리에 저장된 상기 하나 이상의 인스트럭션을 실행하는 적어도 하나의 프로세서를 포함할 수 있다. 상기 적어도 하나의 프로세서는, 상기 하나 이상의 인스트럭션을 실 행함으로써, 제1 카메라를 이용하여 적어도 하나의 라벨을 포함하는 3차원의 객체의 제1 이미지를 획득할 수 있 다. 상기 적어도 하나의 프로세서는, 상기 하나 이상의 인스트럭션을 실행함으로써, 상기 제1 이미지를 제1 AI 모델에 적용함으로써, 상기 제1 이미지 내에서 상기 적어도 하나의 라벨에 대응하는 영역을 관심 영역으로 식별할 수 있다. 상기 적어도 하나의 프로세서는, 상기 하나 이상의 인스트럭션을 실행함으로써, 상기 제1 이미지를 제2 AI 모델에 적용함으로써, 상기 객체의 3차원 형상 타입에 관한 데이터를 획득할 수 있다. 상기 적어도 하나 의 프로세서는, 상기 하나 이상의 인스트럭션을 실행함으로써, 상기 관심 영역으로 식별된 상기 적어도 하나의 라벨에 대응하는 영역 및 상기 객체의 3차원 형상 타입에 관한 데이터에 기초하여, 상기 객체, 상기 적어도 하 나의 라벨 및 상기 제1 카메라와 중 적어도 하나와 관련된 3차원 파라미터를 획득할 수 있다. 상기 적어도 하나 의 프로세서는, 상기 하나 이상의 인스트럭션을 실행함으로써, 상기 3차원 파라미터에 기초하여, 상기 적어도 하나의 라벨의 굴곡 형상을 추정할 수 있다. 상기 적어도 하나의 프로세서는, 상기 하나 이상의 인스트럭션을 실행함으로써, 상기 적어도 하나의 라벨에 대한 원근 변환(perspective transformation)을 수행함으로써, 상기 적어도 하나의 라벨의 굴곡 형상이 평평하게 된 플랫(flat) 라벨 이미지를 획득할 수 있다. 상기 적어도 하나의 프로세서는, 상기 하나 이상의 인스트럭션을 실행함으로써, 사용자로부터 상기 객체의 3차 원 형상 타입에 관련된 사용자 입력을 수신할 수 있다. 상기 적어도 하나의 프로세서는, 상기 하나 이상의 인스 트럭션을 실행함으로써, 복수의 3차원 형상 타입 중에서 상기 사용자 입력에 대응하는 3차원 형상 타입에 가중 치를 적용하여 상기 객체의 3차원 형상 타입을 식별할 수 있다. 상기 적어도 하나의 프로세서는, 상기 하나 이상의 인스트럭션을 실행함으로써, 상기 적어도 하나의 라벨에 대 응하는 영역을 나타내는 제1 키포인트들을 식별할 수 있다. 상기 적어도 하나의 프로세서는, 상기 하나 이상의 인스트럭션을 실행함으로써, 상기 객체의 3차원 형상 타입에 대응하는 가상 객체 및 상기 가상 객체의 3차원 파 라미터의 초기값들을 획득할 수 있다. 상기 적어도 하나의 프로세서는, 상기 하나 이상의 인스트럭션을 실행함 으로써, 상기 제1 키포인트들에 기초하여, 상기 가상 객체의 3차원 파라미터의 초기값들을 조정할 수 있다. 상 기 적어도 하나의 프로세서는, 상기 하나 이상의 인스트럭션을 실행함으로써, 상기 조정된 3차원 파라미터의 값 들을 상기 3차원 파라미터의 값들로 획득할 수 있다. 상기 적어도 하나의 프로세서는, 상기 하나 이상의 인스트럭션을 실행함으로써, 상기 가상 객체의 가상 라벨에 대응하는 영역을 나타내는 제2 키포인트들을 설정할 수 있다. 상기 적어도 하나의 프로세서는, 상기 하나 이상 의 인스트럭션을 실행함으로써, 상기 제2 키포인트들이 상기 제1 키포인트들에 정합하도록 조정함으로써, 상기 가상 객체의 3차원 파라미터의 초기값들이 상기 객체의 3차원 파라미터의 정답 값에 근사하도록 조정할 수 있다. 상기 적어도 하나의 프로세서는, 상기 하나 이상의 인스트럭션을 실행함으로써, 상기 플랫 라벨 이미지에 광학 문자 인식(Optical character recognition; OCR)을 적용할 수 있다. 상기 전자 장치는, 상기 제1 카메라보다 화각이 넓은 제2 카메라를 더 포함하고, 상기 적어도 하나의 프로세서 는, 상기 하나 이상의 인스트럭션을 실행함으로써, 상기 제2 카메라를 통해 상기 객체의 제2 이미지를 획득할 수 있다. 상기 적어도 하나의 프로세서는, 상기 하나 이상의 인스트럭션을 실행함으로써, 상기 제2 이미지를 상기 제2 AI 모델에 더 적용함으로써, 상기 객체의 3차원 형상 타입에 관련된 정보를 획득할 수 있다. 일 실시예에 따른 전자 장치가 이미지를 처리하는 방법은, 제1 카메라를 이용하여 객체의 라벨을 포함하는 객체 의 일부 이미지를 획득하는 단계를 포함할 수 있다. 상기 방법은, 객체의 일부 이미지를 제1 AI 모델에 적용함 으로써 객체의 상기 라벨에 대응하는 영역을 관심 영역으로 식별하는 단계를 포함할 수 있다. 상기 방법은, 제1 카메라보다 화각이 넓은 제2 카메라를 이용하여 객체의 전체 이미지를 획득하는 단계를 포함할 수 있다. 상기 방법은, 객체의 전체 이미지를 제2 AI 모델에 적용함으로써 객체의 3차원 형상 타입을 식별하는 단계를 포함할 수 있다. 상기 방법은, 객체의 3차원 형상 타입에 대응하는 3차원 파라미터를 획득하는 단계를 포함할 수 있다. 상기 방법은, 관심 영역에 관한 정보 및 3차원 파라미터에 기초하여 상기 라벨의 원근 변환(perspective transformation)을 수행함으로써, 라벨의 굴곡 형상이 평평하게 된 플랫 라벨 이미지를 획득하는 단계를 포함할 수 있다. 상기 방법은, 상기 플랫 라벨 이미지로부터 객체와 관련된 정보를 획득하는 단계를 포함할 수 있다. 한편, 본 개시의 실시예들은 컴퓨터에 의해 실행되는 프로그램 모듈과 같은 컴퓨터에 의해 실행 가능한 명령어 를 포함하는 기록 매체의 형태로도 구현될 수 있다. 컴퓨터 판독 가능 매체는 컴퓨터에 의해 액세스 될 수 있는 임의의 가용 매체일 수 있고, 휘발성 및 비휘발성 매체, 분리형 및 비분리형 매체를 모두 포함한다. 또한, 컴퓨 터 판독 가능 매체는 컴퓨터 저장 매체 및 통신 매체를 포함할 수 있다. 컴퓨터 저장 매체는 컴퓨터 판독 가능 명령어, 데이터 구조, 프로그램 모듈 또는 기타 데이터와 같은 정보의 저장을 위한 임의의 방법 또는 기술로 구 현된 휘발성 및 비휘발성, 분리형 및 비분리형 매체를 모두 포함한다. 통신 매체는 전형적으로 컴퓨터 판독 가능 명령어, 데이터 구조, 또는 프로그램 모듈과 같은 변조된 데이터 신호의 기타 데이터를 포함할 수 있다. 또한, 컴퓨터에 의해 읽을 수 있는 저장매체는, 비일시적(non-transitory) 저장매체의 형태로 제공될 수 있다. 여기서, '비일시적 저장매체'는 실재(tangible)하는 장치이고, 신호(signal)(예: 전자기파)를 포함하지 않는다 는 것을 의미할 뿐이며, 이 용어는 데이터가 저장매체에 반영구적으로 저장되는 경우와 임시적으로 저장되는 경 우를 구분하지 않는다. 예로, '비일시적 저장매체'는 데이터가 임시적으로 저장되는 버퍼를 포함할 수 있다. 일 실시예에 따르면, 본 문서에 개시된 다양한 실시예들에 따른 방법은 컴퓨터 프로그램 제품(computer program product)에 포함되어 제공될 수 있다. 컴퓨터 프로그램 제품은 상품으로서 판매자 및 구매자 간에 거래될 수 있 다. 컴퓨터 프로그램 제품은 기기로 읽을 수 있는 저장 매체(예: compact disc read only memory (CD-ROM))의 형태로 배포되거나, 또는 어플리케이션 스토어를 통해 또는 두개의 사용자 장치들(예: 스마트폰들) 간에 직접, 온라인으로 배포(예: 다운로드 또는 업로드)될 수 있다. 온라인 배포의 경우에, 컴퓨터 프로그램 제품(예: 다운 로더블 앱(downloadable app))의 적어도 일부는 제조사의 서버, 어플리케이션 스토어의 서버, 또는 중계 서버의 메모리와 같은 기기로 읽을 수 있는 저장 매체에 적어도 일시 저장되거나, 임시적으로 생성될 수 있다."}
{"patent_id": "10-2022-0133618", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "전술한 본 개시의 설명은 예시를 위한 것이며, 본 개시가 속하는 기술분야의 통상의 지식을 가진 자는 본 개시 의 기술적 사상이나 필수적인 특징을 변경하지 않고서 다른 구체적인 형태로 쉽게 변형이 가능하다는 것을 이해 할 수 있을 것이다. 그러므로 이상에서 기술한 실시예들은 모든 면에서 예시적인 것이며 한정적이 아닌 것으로 이해해야만 한다. 예를 들어, 단일형으로 설명되어 있는 각 구성 요소는 분산되어 실시될 수도 있으며, 마찬가 지로 분산된 것으로 설명되어 있는 구성 요소들도 결합된 형태로 실시될 수 있다. 본 개시의 범위는 상기 상세한 설명보다는 후술하는 특허청구범위에 의하여 나타내어지며, 특허청구범위의 의미 및 범위 그리고 그 균등 개념으로부터 도출되는 모든 변경 또는 변형된 형태가 본 개시의 범위에 포함되는 것으 로 해석되어야 한다.도면 도면1 도면2 도면3 도면4 도면5 도면6a 도면6b 도면7 도면8a 도면8b 도면8c 도면9a 도면9b 도면10a 도면10b 도면10c 도면10d 도면11 도면12 도면13 도면14a 도면14b 도면15a 도면15b 도면16a 도면16b 도면16c 도면17 도면18 도면19 도면20 도면21"}
{"patent_id": "10-2022-0133618", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 개시의 일 실시예에 따른 전자 장치가 이미지의 왜곡을 제거하는 일 예시를 나타내는 도면이다. 도 2는 본 개시의 일 실시예에 따른 전자 장치가 이미지를 처리하는 방법을 설명하기 위한 흐름도이다. 도 3은 본 개시의 일 실시예에 따른 전자 장치가 이미지를 처리하는 동작을 전반적으로 설명하기 위한 도면이다.도 4는 본 개시의 일 실시예에 따른 전자 장치가 객체의 3차원 형상을 식별하는 동작을 설명하기 위한 도면이다. 도 5는 본 개시의 일 실시예에 따른 전자 장치가 객체의 표면의 관심 영역을 식별하는 동작을 설명하기 위한 도 면이다. 도 6a는 본 개시의 일 실시예에 따른 전자 장치가 객체의 3차원 정보를 획득하는 동작을 설명하기 위한 도면이 다. 도 6b는 본 개시의 일 실시예에 따른 전자 장치가 객체의 3차원 정보에 기초하여 관심 영역의 왜곡을 제거하는 동작을 설명하기 위한 도면이다. 도 7은 본 개시의 일 실시예에 따른 전자 장치가 관심 영역 내의 정보를 추출하는 동작을 설명하기 위한 도면이 다. 도 8a는 본 개시의 일 실시예에 따른 전자 장치가 3차원 정보를 획득하여 왜곡 없는 이미지를 획득한 제1 예시 를 설명하기 위한 도면이다. 도 8b는 본 개시의 일 실시예에 따른 전자 장치가 3차원 정보를 획득하여 왜곡 없는 이미지를 획득한 제2 예시 를 설명하기 위한 도면이다. 도 8c는 본 개시의 일 실시예에 따른 전자 장치가 3차원 정보를 획득하여 왜곡 없는 이미지를 획득한 제3 예시 를 설명하기 위한 도면이다. 도 9a는 본 개시의 일 실시예에 따른 전자 장치가 왜곡 없는 이미지로부터 정보를 추출한 제1 예시를 설명하기 위한 도면이다. 도 9b는 본 개시의 일 실시예에 따른 전자 장치가 왜곡 없는 이미지로부터 정보를 추출한 제2 예시를 설명하기 위한 도면이다. 도 10a는 본 개시의 일 실시예에 따른 전자 장치가 객체 3차원 형상 식별 모델을 훈련시키는 동작을 설명하기 위한 도면이다. 도 10b는 본 개시의 일 실시예에 따른 전자 장치가 객체 3차원 형상 식별 모델을 훈련시키는 다른 동작을 설명 하기 위한 도면이다. 도 10c는 본 개시의 일 실시예에 따른 전자 장치가 객체의 3차원 형상을 식별하는 실시예를 설명하기 위한 도면 이다. 도 10d는 본 개시의 일 실시예에 따른 전자 장치가 객체의 3차원 형상을 식별하는 실시예를 설명하기 위한 도면 이다. 도 11은 본 개시의 일 실시예에 따른 전자 장치가 관심 영역 식별 모델을 훈련시키는 동작을 설명하기 위한 도 면이다. 도 12는 본 개시의 일 실시예에 따른 전자 장치가 왜곡 제거 모델을 훈련시키는 동작을 설명하기 위한 도면이다. 도 13은 본 개시의 일 실시예에 따른 전자 장치에 포함되는 멀티 카메라를 설명하기 위한 도면이다. 도 14a는 본 개시의 일 실시예에 따른 전자 장치가 멀티 카메라를 이용하는 동작을 설명하기 위한 흐름도이다. 도 14b는 도 14a를 보충적으로 더 설명하기 위한 도면이다. 도 15a는 본 개시의 일 실시예에 따른 전자 장치가 멀티 카메라를 이용하는 동작을 설명하기 위한 흐름도이다. 도 15b는 도 15a를 보충적으로 더 설명하기 위한 도면이다. 도 16a는 본 개시의 일 실시예에 따른 전자 장치가 멀티 카메라를 이용하는 동작을 설명하기 위한 흐름도이다. 도 16b는 도 16a를 보충적으로 더 설명하기 위한 도면이다. 도 16c는 도 16a를 보충적으로 더 설명하기 위한 도면이다. 도 17은 본 개시의 일 실시예에 따른 전자 장치가 이미지를 처리하여 추출된 정보를 제공하는 동작을 설명하기위한 도면이다. 도 18은 본 개시의 일 실시예에 따른 전자 장치가 이미지를 처리하는 동작에 관련된 시스템의 일 예시를 설명하 기 위한 도면이다. 도 19는 본 개시의 일 실시예에 따른 전자 장치가 서버를 이용하여 이미지를 처리하는 동작에 관련된 시스템의 일 예시를 설명하기 위한 도면이다. 도 20은 본 개시의 일 실시예에 따른 전자 장치의 구성을 도시한 블록도이다. 도 21은 본 개시의 일 실시예에 따른 서버의 구성을 도시한 블록도이다."}
