{"patent_id": "10-2022-0035723", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0138099", "출원번호": "10-2022-0035723", "발명의 명칭": "하둡 기반 빅데이터 소재 관리 방법", "출원인": "주식회사에이테크", "발명자": "김정완"}}
{"patent_id": "10-2022-0035723", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "데이터 수집부, 데이터 처리부, 데이터 저장부, 데이터 분석부 및 모니터링부를 포함하고, 다양한 형태의 빅 데이터를 수집, 저장, 분석을 실시간으로 처리할 수 있는 하둡 기반 빅데이터 소재 관리 방법에 있어서,상기 데이터 수집부에서 다양한 경로를 통해 소재 관리 데이터를 수집하는 데이터 수집 단계;상기 데이터 처리부에서 상기 데이터 수집부로부터 전달되는 데이터에 대해 전처리를 수행하는 데이터 처리 단계;상기 데이터 저장부에서 상기 데이터 수집부에서 수집된 데이터와 상기 데이터 처리부에서 전처리된 데이터를분산 저장하는 데이터 저장 단계;상기 데이터 분석부에서 상기 데이터 처리부로부터 전달되는 데이터 또는 상기 데이터 저장부에 저장된 데이터를 분석하고, 분석 결과를 생성하는 데이터 분석 단계; 및상기 모니터링부에서 상기 데이터 분석부로부터 분석된 데이터를 표시하는 모니터링 단계;를 포함하는 것을 특징으로 하는 하둡 기반 빅데이터 소재 관리 방법."}
{"patent_id": "10-2022-0035723", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1 항에 있어서,상기 데이터 수집부는,정형화된 데이터를 sqoop, NFS-Gateway, Hadoop Client, SCP 및 FTP 중 적어도 하나에서 수집하며,비정형화된 데이터를 kafka 또는 Flume에서 수집하는 것을 특징으로 하는 하둡 기반 빅데이터 소재 관리 방법."}
{"patent_id": "10-2022-0035723", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 1 항에 있어서,상기 데이터 저장부는,하둡 분산형 파일 시스템(HDFS; Hadoop Distributed File System)인 것을 특징으로 하는 하둡 기반 빅데이터소재 관리 방법."}
{"patent_id": "10-2022-0035723", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 3 항에 있어서,상기 데이터 저장부는,입력되는 데이터를 3-copy 방식으로 저장되되, 하나의 Rack에 2개의 데이터 노드를 저장하고, 다른 하나는 다른Rack에 저장하는 것을 특징으로 하는 하둡 기반 빅데이터 소재 관리 방법."}
{"patent_id": "10-2022-0035723", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제 1 항에 있어서,공개특허 10-2023-0138099-3-상기 데이터 저장부는,아파치 에어플로우(Apache Airflow)를 활용하여 일별, 주별 및 월별 중 적어도 하나의 기준으로 상기 데이터를저장하는 것을 특징으로 하는 하둡 기반 빅데이터 소재 관리 방법."}
{"patent_id": "10-2022-0035723", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제 1 항에 있어서,상기 데이터 분석부는,상기 데이터 처리부로부터 전달되는 데이터 또는 상기 데이터 저장부에 저장된 데이터를 인공지능 알고리즘에의해 분석하여, 분석결과를 생성하는 것을 특징으로 하는 하둡 기반 빅데이터 소재 관리 방법."}
{"patent_id": "10-2022-0035723", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제 6 항에 있어서,상기 데이터 분석 단계는,요구분석 모듈에서 사용자로부터 입력되는 분석 요구 사항을 입력받는 요구분석 단계;인공지능 분석 모듈에서 상기 요구 분석 모듈에 입력되는 분석 요구 사항에 따라 상기 데이터 처리부로부터 전달되는 데이터 또는 상기 데이터 저장부에 저장된 데이터를 인공지능 알고리즘에 의해 분석하는 인공지능 분석단계; 및학습 모듈에서 상기 인공지능 분석 모듈에서 분석하는 기법을 학습하는 학습 단계;를 포함하는 것을 특징으로하는 하둡 기반 빅데이터 소재 관리 방법."}
{"patent_id": "10-2022-0035723", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 정형, 반정형, 비정형 등 다양한 형태의 빅 데이터를 수집, 저장, 분석을 실시간으로 처리할 수 있는 하둡 기반 빅데이터 소재 관리 방법에 관한 것으로, 데이터 수집부, 데이터 처리부, 데이터 저장부, 데이터 분석 부 및 모니터링부를 포함하고, 다양한 형태의 빅 데이터를 수집, 저장, 분석을 실시간으로 처리할 수 있는 하둡 (뒷면에 계속)"}
{"patent_id": "10-2022-0035723", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 하둡 기반 빅데이터 소재 관리 방법에 관한 것으로, 더욱 상세하게는, 정형, 반정형, 비정형 등 다양 한 형태의 빅 데이터를 수집, 저장, 분석을 실시간으로 처리할 수 있는 하둡 기반 빅데이터 소재 관리 방법에 관한 것이다."}
{"patent_id": "10-2022-0035723", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "최근 정형 또는 비정형 등의 대규모 데이터에 의미있는 가치를 부여하는 빅 데이터(big data) 기술에 대한 관심 이 높아지고 있다. 많은 응용 서비스들은 빅 데이터를 통해 정확하고 빠른 결과가 도출되도록 요청된다. 빅 데이터라는 용어는, 어느 정도 경과한 시간 내에 속한 데이터를 수집, 관리, 저장, 검색, 공유, 분석, 및 시 각화하기 위한 보통의 소프트웨어 툴 및 컴퓨터 시스템으로는 다루기 어려운 수준의 데이터 양을 갖는 데이터셋 (data set)에 대하여 주로 적용된다. 빅 데이터의 사이즈는 테라바이트, 엑사바이트 또는 제타바이트의 범위를 가질 수도 있다. 빅 데이터는 다양한 분야에 존재한다. 예를 들어, 웹로그(web logs), RFID(radio frequency identification), 소셜 네트워크(social network), 소셜 데이터, 인터넷 텍스트와 문서, 인터넷 검색 인덱싱(internet search indexing), 천문학, 기상학, 유전체학, 생물지구화학(biogeochemistry), 생물학, 군사 감시, 의료 기록, 사진 기록, 비디오 기록, 및 전자상거래 등이다. 빅 데이터는 일반적으로 하둡(Hadoop)이라는 생태계를 기반으로 수행되고 있다. 하둡은 정형 또는 비정형 등의 대량의 데이터를 수집하여 데이터의 중복 분산 저장 및 분산된 네트워크 클러스터에서 병렬로 처리한다. 이러한 하둡에 의하여 단시간의 정보의 처리 및 가치 있는 정보의 추출이라는 기술적 의의를 빅 데이터에 부여 하고 있다. 하둡의 HDFS(Hadoop Distributed File System)은 대규모 데이터를 분산 저장시키는 오픈 소스로써 수집된 데이터를 신뢰성 있게 저장하는 기술이다. 하지만, 하둡은 일괄 처리 시스템으로서 수집 데이터를 실시간으로 처리하지 못한다는 문제점이 있다. 즉, 하둡 은 수집되는 데이터를 일정 기간 저장한 후, 데이터 분석을 위한 외부 요청에 따라 대규모의 데이터에 대해서 분석을 수행한다. 최근 대안으로, 인 메모리 데이터 처리 기술인 스톰(Storm)과 스파크(Spark) 같은 하둡 에코 시스템(echo system)이 언급되고 있다. 스톰(Storm)은 발생하는 이벤트를 저장 과정 없이 병렬처리를 할 수 있고, 맵리듀스(MapReduce) 모델과 유사한 방법으로 데이터를 처리할 수 있다. 또한, 스톰(Storm)의 메커니즘에 따라, 스파우트(spout)에서는 데이터를 튜 플 단위로 생성하고, 볼트(bolt)에서 튜플 단위로 데이터를 처리하고, 처리 결과를 저장한다. 스파크(Spark)는 RDD(Resilient Distribute Dataset)라는 데이터 집합의 추상화 객체를 도입하여 데이터 처리 를 수행한다. 하지만, 이러한 종래 기술은 하둡을 기반으로 하여 메커니즘을 수행해야 하며, 이를 습득하기 위한 추가적인 노 력이 필요하다. 또한, 종래의 기술은 대량의 데이터에 대하여 반복적인 작업을 많이 수행하는 응용, 예를 들어 반복적인 데이터 연산과 같은 과학적인 응용에 유용하다. 선행기술문헌 특허문헌 (특허문헌 0001) 대한민국 공개특허공보 제10-2017-0089067(2017.08.03.)"}
{"patent_id": "10-2022-0035723", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 상기한 문제점을 해결하기 위하여 안출된 것으로, 본 발명의 목적은 정형, 반정형, 비정형 등 다양한 형태의 빅 데이터를 수집, 저장, 분석을 실시간으로 처리할 수 있는 하둡 기반 빅데이터 소재 관리 방법을 제공 하는 것이다. 본 발명의 목적들은 이상에서 언급한 목적으로 제한되지 않으며, 언급되지 않은 또 다른 목적들은 아래의 기재"}
{"patent_id": "10-2022-0035723", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 2, "content": "로부터 본 발명의 기술분야에서 통상의 지식을 지닌 자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2022-0035723", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명은 상기의 목적을 달성하기 위해서, 데이터 수집부, 데이터 처리부, 데이터 저장부, 데이터 분석부 및 모니터링부를 포함하고, 다양한 형태의 빅 데이터를 수집, 저장, 분석을 실시간으로 처리할 수 있는 하둡 기반 빅데이터 소재 관리 방법에 있어서, 상기 데이터 수집부에서 다양한 경로를 통해 소재 관리 데이터를 수집하는 데이터 수집 단계와, 상기 데이터 처리부에서 상기 데이터 수집부로부터 전달되는 데이터에 대해 전처리를 수행 하는 데이터 처리 단계와, 상기 데이터 저장부에서 상기 데이터 수집부에서 수집된 데이터와 상기 데이터 처리 부에서 전처리된 데이터를 분산 저장하는 데이터 저장 단계와, 상기 데이터 분석부에서 상기 데이터 처리부로부 터 전달되는 데이터 또는 상기 데이터 저장부에 저장된 데이터를 분석하고, 분석 결과를 생성하는 데이터 분석 단계 및 상기 모니터링부에서 상기 데이터 분석부로부터 분석된 데이터를 표시하는 모니터링 단계를 포함하는 것을 특징으로 한다. 또한, 상기 데이터 수집부는 정형화된 데이터를 sqoop, NFS-Gateway, Hadoop Client, SCP 및 FTP 중 적어도 하 나에서 수집하며, 비정형화된 데이터를 kafka 또는 Flume에서 수집하는 것을 특징으로 한다.또한, 상기 데이터 저장부는 하둡 분산형 파일 시스템(HDFS; Hadoop Distributed File System)인 것을 특징으 로 한다. 또한, 상기 데이터 저장부는 입력되는 데이터를 3-copy 방식으로 저장되되, 하나의 Rack에 2개의 데이터 노드를 저장하고, 다른 하나는 다른 Rack에 저장하는 것을 특징으로 한다. 또한, 상기 데이터 저장부는 아파치 에어플로우(Apache Airflow)를 활용하여 일별, 주별 및 월별 중 적어도 하 나의 기준으로 상기 데이터를 저장하는 것을 특징으로 한다. 또한, 상기 데이터 분석부는 상기 데이터 처리부로부터 전달되는 데이터 또는 상기 데이터 저장부에 저장된 데 이터를 인공지능 알고리즘에 의해 분석하여, 분석결과를 생성하는 것을 특징으로 한다. 또한, 상기 데이터 분석 단계는 요구분석 모듈에서 사용자로부터 입력되는 분석 요구 사항을 입력받는 요구분석 단계와, 인공지능 분석 모듈에서 상기 요구 분석 모듈에 입력되는 분석 요구 사항에 따라 상기 데이터 처리부로 부터 전달되는 데이터 또는 상기 데이터 저장부에 저장된 데이터를 인공지능 알고리즘에 의해 분석하는 인공지 능 분석 단계 및 학습 모듈에서 상기 인공지능 분석 모듈에서 분석하는 기법을 학습하는 학습 단계를 포함하는 것을 특징으로 한다."}
{"patent_id": "10-2022-0035723", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명의 하둡 기반 빅데이터 소재 관리 방법은 데이터 수집부, 데이터 처리부, 데이터 저장부 및 데이터 분석 부를 포함함에 따라, 다양한 매체 등의 데이터 소스를 통해 수집된 데이터를 수집하여 정형화 및 정규화하여 데 이터의 품질을 높이고, 보다 정확한 분석을 수행할 수 있는 효과를 제공한다. 또한, 데이터 처리부는 데이터 변환, 교정, 통합 및 축소 프로세스를 통해 데이터를 정형화 및 정규화할 수 있 는 효과를 제공한다. 그리고, 본원발명의 데이터의 통합 기준값 존재 여부확인, 중복 데이터 제거, 다양한 데이터를 하나의 데이터 셋으로 통합 및 통합 과정에서 필요없는 데이터를 제거하여 필요 데이터만 조회 및 저장하여 물리 모듈을 최적 화할 수 있는 효과를 제공한다. 더불어, 본원발명의 데이터 분석부는 요구분석 모듈과, 인공지능 분석 모듈 및 학습 모듈을 포함하여 구성되며, 사용자로부터 입력되는 분석 요구 사항을 인공지능 알고리즘에 의해 분석하고, 인공지능 알고리즘을 실시간으로 학습하여 새로운 기법을 지속적으로 학습하여 사용자 요구 사항에 최적화된 분석을 수행할 수 있는 효과를 제공 한다."}
{"patent_id": "10-2022-0035723", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명의 이점 및 특징, 그리고 그것들을 달성하는 방법은 첨부되는 도면과 함께 상세하게 후술되어 있는 실시 예들을 참조하면 명확해질 것이다. 그러나 본 발명은 이하에서 개시되는 실시예들에 한정되는 것이 아니라 서로"}
{"patent_id": "10-2022-0035723", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "다른 다양한 형태로 구현될 것이며, 단지 본 실시예들은 본 발명의 개시가 완전하도록 하며, 본 발명이 속하는기술분야에서 통상의 지식을 가진 자에게 발명의 범주를 완전하게 알려주기 위해 제공되는 것이며, 본 발명은 청구항의 범주에 의해 정의될 뿐이다. 아래 첨부된 도면을 참조하여 본 발명의 실시를 위한 구체적인 내용을 상세히 설명한다. 도면에 관계없이 동일 한 부재번호는 동일한 구성요소를 지칭하며, \"및/또는\"은 언급된 아이템들의 각각 및 하나 이상의 모든 조합을 포함한다. 비록 제1, 제2 등이 다양한 구성요소들을 서술하기 위해서 사용되나, 이들 구성요소들은 이들 용어에 의해 제한 되지 않음은 물론이다. 이들 용어들은 단지 하나의 구성요소를 다른 구성요소와 구별하기 위하여 사용하는 것이다. 따라서, 이하에서 언급되는 제1 구성요소는 본 발명의 기술적 사상 내에서 제2 구성요소일 수도있음은 물론 이다. 본 명세서에서 사용된 용어는 실시예들을 설명하기 위한 것이며, 본 발명을 제한하고자 하는 것은 아니다. 본 명세서에서, 단수형은 문구에서 특별히 언급하지 않는 한 복수형도 포함한다. 명세서에서 사용되는 \"포함한다 (comprises)\" 및/또는 \"포함하는(comprising)\"은 언급된 구성요소 외에 하나 이상의 다른 구성요소의 존재 또는 추가를 배제하지 않는다. 다른 정의가 없다면, 본 명세서에서 사용되는 모든 용어(기술 및 과학적 용어를 포함)는 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자에게 공통적으로 이해될 수 있는 의미로 사용될 수 있을 것이다. 또 일반적으로 사용되는 사전에 정의되어 있는 용어들은 명백하게 특별히 정의되어 있지 않는 한 이상적으로 또는 과도하게 해 석되지 않는다. 이하, 첨부된 도면을 참조하여 본 발명의 바람직한 실시예를 상세히 설명하기로 한다. 도 1은 본 발명의 바람직한 하둡 기반 빅데이터 소재 관리 방법을 나타낸 순서도이며, 도 2는 본 발명의 바람직 한 일실시예에 따른 하둡을 이용한 빅데이터 소재 수집 및 분석 시스템을 나타낸 개념도이고, 도 3은 본 발명의 바람직한 일실시예에 따른 데이터 처리부를 나타낸 개념도이며, 도 4 및 도 5는 본 발명의 바람직한 일실시예에 따른 데이터 저장부를 나타낸 개념도이고, 도 6은 본 발명의 바람직한 일실시예에 따른 데이터 분석부를 나타낸 구성도이며, 도 7 내지 도 12은 본 발명의 바람직한 일실시예에 따른 하둡 기반 빅데이터 소재 관리 방법 플랫 폼을 나타낸 예시도이다. 도 1에 도시된 바와 같이, 본 발명의 바람직한 하둡 기반 빅데이터 소재 관리 방법은 데이터 수집 단계(S100), 데이터 처리 단계(S200), 데이터 저장 단계(S300), 데이터 분석 단계(S400) 및 모니터링 단계(S500)를 포함하여 구성된다. 먼저, 본 발명의 바람직한 하둡 기반 빅데이터 소재 관리 방법는 데이터 수집부, 데이터 처리부, 데 이터 저장부, 데이터 분석부 및 모니터링부를 포함하고, 다양한 형태의 빅 데이터를 수집, 저장, 분석을 실시간으로 처리할 수 있는 하둡 기반 빅데이터 소재 관리 방법에 관한 것이다. 그리고 도 2에 도시된 바와 같이, 본 발명의 하둡을 이용한 빅데이터 소재 수집 및 분석 시스템은 데이터 수집부, 데이터 처리부, 데이터 저장부, 데이터 분석부 및 모니터링부를 포함하여 구 성된다. 여기서, 상기 데이터 수집부에서 다양한 경로를 통해 소재 관리 데이터를 수집한다.(S100) 먼저, 상기 데이터 수집부는 다양한 경로를 통해 소재 관리 데이터를 수집하며, 예를 들면 데이터는 소재 의 소재코드, 소재명, 소재 SPEC, 소재 용도 및 소재 제조사 정보를 포함한다. 여기서, 상기 데이터 수집부는 도 3에 도시된 바와 같이, 다양한 종류의 수집 툴을 이용하여 데이터를 수 집하는데, 예를 들어 상기 데이터 수집 툴로는 정형화된 데이터를 sqoop, NFS-Gateway, Hadoop Client, SCP 및 FTP 중 적어도 하나에서 수집하며, 비정형화된 데이터를 kafka 또는 Flume에서 수집할 수 있다. 이때, sqoop은 맵리듀스(MapReduce)를 기반으로 기반으로 구현된 데이터 적재 프로그램으로, 맵리듀스는 정렬되 지 않은 데이터들을 속성이 같은 데이터와 묶어 분류해주는 역할을 한다.특히, 관계형 데이터베이스 및 HDFS 사이에 데이터 적재가 가능하므로 많은 프로젝트에서 널리 사용하고 있다. 스쿱은 모든 적재 과정을 자동화하고 병렬처리 방식으로 작업하며 고장방지능력(fault tolerance)을 지원한다. 또한, 비정형화된 데이터를 수집하는 kafka는 실시간으로 기록 스트림을 게시, 구동, 저장 및 처리할 수 있는 분산 데이터 스트리밍 플랫폼으로, 여러 소스에서 데이터 스트림을 처리하고 여러 사용자에게 전달하도록 설계 된다. 그리고 kafka는 여러 대의 분산 서버에서 대량의 데이터를 처리하는 분산 메시징 시스템으로, 데이터를 받고, 높은 처리량과 실시간으로 대량의 데이터를 취급할 수 있다. 또한, 상기 데이터 수집부는 다양한 종류의 인터페이스 프로토콜을 통해 데이터를 수집하게 되는데, 예를 들어 인터페이스 프로토콜로는 FTP(File Transfer Protocol), HTTP(Hyper Text Transfer Protocol), TCP/IP(Transmission Control Protocol/Internet Protocol) 등이 있다. 그리고 상기 데이터 수집부에서 수집된 데이터는 필요에 따라 상기 데이터 저장부에 저장되거나, 데 이터 처리를 위해 상기 데이터 처리부로 전달된다. 다음으로, 상기 데이터 처리부(S200)에서 상기 데이터 수집부로부터 전달되는 데이터에 대해 전처리를 수행한다. 이때, 상기 데이터 처리부는 상기 데이터 수집부로부터 전달되는 데이터에 대해 전처리를 수행하는 구성으로, 상기 데이터 수집부에 의해 수집된 데이터를 전처리하여 전처리된 데이터를 생성한다. 이때, 상기 데이터 처리부는 응용 서비스에 따라 달라지는데 데이터를 전처리하기 위한 여러 개의 전처리 모듈로 구성될 수 있다. 한편, 상기 데이터 처리부에 의해 생성되는 가공 데이터는 필요에 따라 상기 데이터 저장부에 저장되 거나, 분석을 위해 상기 데이터 분석부로 전달된다. 특히, 상기 데이터 전처리부는 상기 데이터 전처리부의 상태 및 상기 데이터 분석부의 상태를 지속적으로 판단하고, 상기 데이터 처리부 및 상기 데이터 분석부의 상태가 정상인 경우에 데이터를 전달하도록 구성될 수 있다. 여기서, 상기 데이터 전처리부는 상기 데이터 수집부에서 수집된 정형 또는 비정형 데이터 중 노이즈 가 많고 불안정하거나 누릭 데이터가 존재할 수 있기 때문에, 데이터 변환, 교정, 통합 및 축소를 통하여 데이 터를 정형화 및 정규화하여 데이터의 품질을 높이고, 향후 데이터 분석부에서 정확한 분석을 수행할 수 있 도록 데이터를 전처리하는 구성이다. 특히, 상기 데이터 전처리부는 상기 데이터 수집부로부터 수집된 데이터에서 중복 데이터 제거, 다양 한 데이터를 하나의 데이터 셋으로 통합, 통합 과정에 필요 없는 데이터 또는 변수 제거, 같은 데이터이거나 변 수 명이 다른 경우 변수명 변경 및 통합하게 된다. 다음으로, 상기 데이터 저장부에서 상기 데이터 수집부에서 수집된 데이터와 상기 데이터 처리부 에서 전처리된 데이터를 분산 저장한다.(S300) 이때, 상기 데이터 저장부는 상기 데이터 수집부에서 수집된 데이터와 상기 데이터 처리부에서 전처리된 데이터를 분산 저장하는 구성으로, 일예로, 하둡 분산형 파일 시스템(HDFS; Hadoop Distributed File System)일 수 있다. 이때, 상기 데이터 저장부는 데이터 수집부로부터 전달되는 데이터, 상기 데이터 처리부로부터 전달되는 데이터 및 상기 데이터 분석부로부터 전달되는 분석 결과를 저장할 수 있다."}
{"patent_id": "10-2022-0035723", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "한편, 상기 하둡 분산형 파일 시스템은 본 발명이 속하는 기술분야에서 기 공지되어 사용되는 것으로, 상기 데 이터 저장부의 구조에 대해서는 데이터 저장부의 일례를 도시한 도 4을 참조하여 간략하게 설명하도 록 한다. 도 4를 참조하면, 상기 데이터 저장부는 클라이언트 노드, 네임 노드 및 데이터 노드로 구 성될 수 있다. 상기 클라이언트 노드는 HDFS API를 통해 데이터의 입출력을 담당하며, 상기 네임 노드는 저장될 데 이터와 관련된 메타 데이터를 저장하고 있으며, 데이터 노드로의 데이터 저장을 담당한다. 상기 데이터 노드는 네임 노드로부터 요청되는 데이터를 제공하거나 네임 노드로부터 제공되는 데이터를 저장하는 역할을 담당한다. 이때, 다수의 데이터 노드는 서로 연동되며, 상기 데이터 노드는 블록 단위로 데이터를 관리한다. 또한, 상기 데이터 저장부는 도 5에 도시된 바와 같이, 입력되는 데이터를 3-copy 방식으로 저장되되, 하 나의 Rack에 2개의 데이터 노드를 저장하고, 다른 하나는 다른 Rack에 저장할 수 있다. 여기서, 상기 데이터 저장부는 데이터를 빠르게 저장할 수 있도록 설계된 블록 구조의 하둡기반 분산파일 시스템을 이용하여 자체적인 분산저장 방식으로 데이터의 안전성을 보장하며, 수십 테라바이트 이상의 대용량 파일을 분산된 서버에 저장하여 관리할 수 있도록 한다. 특히, 상기 데이터 저장부는 HDFS 클라이언트를 통해 HDFS에 파일 저장 명령이 입력되면, 네임 노드 에 통신하여 파일을 저장할 데이터 노드의 주소 정보를 요청하게 된다. 그리고, 네임 노드는 자신이 관리하는 HDFS의 메타데이터에서 요청한 정보를 제공하는데, 3-copy 방식으로 파일을 분산 저장하면서 한 Rack에는 2개를, 나머지 1개는 다른 Rack에 저장하게 된다. 또한, HDFS 클라이언트는 제공받은 데이터 노드 주소에서 처음 데이터 노드와 통신하여 데이터를 저장하고, 처음 데이터 노드로 파일이 저장되는 순간부터 두번째 데이터 노드에 데이터를 저장하고, 이후 세번째 데이터 노드까지 데이터를 저장하게 된다. 이후, 데이터 노드들에 의해 파일 저장이 완료되면 네임 노드는 그 정보를 클라이언트로 전송하게 된 다. 그리고 상기 데이터 저장부는 아파치 에어플로우(Apache Airflow)를 활용하여 일별, 주별 및 월별 중 적어 도 하나의 기준으로 상기 데이터를 저장할 수 있다. 다음으로, 상기 데이터 분석부에서 상기 데이터 처리부로부터 전달되는 데이터 또는 상기 데이터 저 장부에 저장된 데이터를 분석하고, 분석 결과를 생성한다.(S400) 이때, 상기 데이터 분석부는 상기 데이터 처리부로부터 전달되는 데이터 또는 상기 데이터 저장부 에 저장된 데이터를 분석하고, 분석 결과를 생성하는 구성으로, 응용 서비스에 따라 적합한 분석 모델링을 이용하여 데이터를 분석할 수 있으며, 상기 데이터 분석부에 의해 분석되는 분석 결과는 상기 데이터 저장 부에 저장되거나, 상기 모니터링부에 제공될 수 있다. 한편, 상기 데이터 분석부는 상기 데이터 저장부에 저장된 데이터에 대해 사용자의 명령에 따라 일괄 분석하거나, 상기 데이터 전처리부로부터 전달되는 데이터에 대해 실시간으로 분석할 수 있다. 여기서, 상기 데이터 분석부는 상기 데이터 처리부로부터 전달되는 데이터 또는 상기 데이터 저장부 에 저장된 데이터를 인공지능 알고리즘에 의해 분석하여, 분석결과를 생성하게 된다. 보다, 상세하게는, 도 6에 도시된 바와 같이, 상기 데이터 분석부는 사용자로부터 입력되는 분석 요구 사 항을 입력받는 요구분석 모듈과, 상기 요구 분석 모듈에 입력되는 분석 요구 사항에 따라 상기 데이 터 처리부로부터 전달되는 데이터 또는 상기 데이터 저장부에 저장된 데이터를 인공지능 알고리즘에 의해 분석하는 인공지능 분석 모듈과, 상기 인공지능 분석 모듈에서 분석하는 기법을 학습하는 학습 모듈으로 이루어질 수 있다. 먼저, 상기 요구분석 모듈은 사용자의 분석 및 활용도, 사용자의 요구사항 및 사용자의 목표를 포함하는 사용자의 소재 분석 요구 사항을 입력받을 수 있다. 그리고 상기 인공지능 분석 모듈은 상기 요구분석 모듈에서 입력받은 분석 요구 사항을 분석하여, 인 공지능 알고리즘에 의해 소재를 분석하게 된다. 이때, 인공지능 알고리즘은 로컬라이제이션(Localization) 알고리즘을 이용하여 적어도 하나의 소재 이미지 내 에 포함된 패턴을 객체로 검출하여 패턴 데이터셋으로 데이터베이스화하고, 적어도 하나의 소재제품 정보, 및 적어도 하나의 이미지 데이터를 패턴 데이터셋에 포함시켜 MATPL(Multi-Attribute Textile Product Landmark) 데이터 셋을 구축하는 과정을 포함할 수 있다.또한, 인공지능 알고리즘은 유사도 학습을 위한 MATPL 데이터 셋에 포함된 속성 값에 대한 매개변수를 정의하고 컨볼루션레이어(Convolution Layer)를 이용하여 분류 및 클러스터링(Clustering)을 위한 CNN 기본 모델을 구성 할 수 있다. 여기서, 로컬라이제이션은, 이미지 안의 객체(Object)가 이미지 안의 어느 위치에 있는지 위치 정보를 출력해주 는 것으로, 주로 바운딩 박스(Bounding box)를 이용하며, 바운딩 박스의 네 꼭지점 픽셀의 좌표가 출력되는 것 이 아닌, 좌상단(left top), 우하단(right bottom) 좌표를 출력하는 것이다. 그리고, 객체 검출(Object Detection)은, 분류(Classification)와 로컬라이제이션이 동시에 수행되는 것을 의미한다. 모델의 학습 목적에 따라 특정 객체만 검출하는 경우도 있고 복수의 객체를 검출하는 모델을 만들기도 한다. 또한, 객체 인식(Object Recognition)이란, 대부분 객체 검출과 같은 의미로 쓰이지만, 검출은 객체의 존재 유 무만을 의미하고, 인식은 객체의 종류를 아는 것으로 해석할 수도 있다. 그 이외의 용어는 빅데이터 검출에서 공지된 것으로 상세한 설명은 생략하기로 한다. 그리고 상기 학습 모듈은 상기 인공지능 분석 모듈에서 분석하는 기법을 학습하는 구성으로, 복수 개의 분 속 요구 사항에 따라 분석하는 학습 기법을 유사한 정도에 따라 사용하는 기법을 분석 및 학습하게 된다. 이후, 상기 모니터링부에서 상기 데이터 분석부로부터 분석된 데이터를 표시한다.(S500) 이때, 상기 모니터링부는 상기 데이터 분석부로부터 분석된 데이터를 표시하는 구성으로, 사용자에게 정보 제공 등의 목적을 위하여, 상기 데이터 분석부로부터 제공되는 분석 결과를 외부에서 확인할 수 있도록 표 시하게 된다. 상술한 바와 같이, 본 발명의 하둡을 이용한 빅데이터 소재 수집 및 분석 시스템은 정형, 반정형, 비정형 등 다양한 형태의 소재 관련 빅데이터를 수집, 저장, 분석을 실시간으로 처리할 수 있고, 사용자의 요구사항에 따라 분석처리하여 사용자로 제공할 수 있는 시스템에 관한 것이다. 다음으로, 본 발명의 하둡을 이용한 빅데이터 소재 수집 및 분석 시스템을 나타낸 도 7 내지 도 12을 참 고하여, 사용자가 소재 관리를 할 수 있는 시스템을 설명하기로 한다. 먼저, 도 7에 도시된 바와 같이, 사용자는 기설정한 아이디 및 비밀번호를 통해 로그인을 수행할 수 있고, 시스 템관리, 생산관리 및 품질관리를 수행할 수 있다. 그리고, 데이터저장부에 기저장된 데이터들에 대한 일별/주별/월별로 작업 발행 및 등록 현황을 수치 또는 그래프로 확인할 수 있다. 다음으로, 도 8에 도시된 바와 같이, 상기 시스템관리 탭의 하위 탭인 원료코드관리 탭에서 본 발명의 하둡을 이용한 빅데이터 소재 수집 및 분석 시스템에 저장된 소재 관련 데이터를 관리할 수 있는 페이지로, 소재 코드, 소재의 원료명, SPEC, 용도, 제조사 및 사용여부 관련 정보를 검색, 수정, 등록 및 확인할 수 있다. 이때, 소재 검색은 상기 데이터 저장부에 저장된 데이터 중, 검색하고자 하는 데이터만을 검색할 수 있도 록, 검색 탭이 형성되어 있으며, 검색 탭을 이용하여 사용자가 요청하는 소재 관련 데이터만 조회할 수 있고, 도 9에 도시된 바와 같이, 수정 탭을 이용하여 소재 관련 정보를 수정할 수 있다. 또한, 도 10에 도시된 바와 같이, 소재 관련 설비 데이터 정보를 데이터 저장부에 저장할 수 있으며, 데이 터 저장부에 저장된 설비 관련 데이터를 설비관리 탭에서 확인할 수 있다. 이때, 설비 관련 정보는 설비의 호기번호, 호기명, 종류, 모델명, 규격, 용도, 제조사, 도입일자, 담당자 및 사 용여부 정보가 포함될 수 있으며, 검색, 수정 및 등록할 수 있다. 등록을 통하여 설비 관련 정보를 등록 시, 데이터 저장부에 분산 저장되며, 검색 및 수정 탭을 통해 데이 터 저장부에 저장된 데이터를 검색 및 수정할 수 있다. 또한, 도 11에 도시된 바와 같이, 사용자 관련 데이터 정보를 데이터 저장부에 저장할 수 있으며, 데이터 저장부에 저장된 사용자 관련 데이터를 사용자관리 탭에서 확인할 수 있다. 이때, 사용자 관련 정보는 사용자명, 아이디, 부서, 직급, 전화번호, 이메일, 권한명, 관리자여부 및 사용여부 정보가 포함될 수 있으며, 검색, 수정 및 등록할 수 있다. 다음으로, 도 12에 도시된 바와 같이, 작업지시 관련 데이터 정보를 데이터 저장부에 저장할 수 있으며, 데이터 저장부에 저장된 작업지시 관련 데이터를 작업현황 탭에서 확인할 수 있다. 여기서, 작업지시 관련 정보는, 문서번호, 접수번호, 접수일자, B/T담당자, 거래처, 거래처 담당자, 품명, 색상, 등록자, 등록일자 및 수정일자를 포함할 수 있으며, 검색, 수정 및 등록할 수 있다. 이외에도, 다양한 소재 관리 데이터를 입력받아 저장할 수 있으며, 저장된 데이터는 하둡을 이용하여 분산 저장 되어 실시간으로 검색, 수정 및 등록을 수행할 수 있다."}
{"patent_id": "10-2022-0035723", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "이상과 첨부된 도면을 참조하여 본 발명의 실시예를 설명하였지만, 본 발명이 속하는 기술분야에서 통상의 지식 을 가진 자는 본 발명이 그 기술적 사상이나 필수적인 특징을 변경하지 않고서 다른 구체적인 형태로 실시될 수 있다는 것을 이해할 수 있을 것이다. 그러므로 이상에서 기술한 실시예들은 모든 면에서 예시적인 것이며 한정 적이 아닌 것으로 이해되어야 한다."}
{"patent_id": "10-2022-0035723", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 바람직한 하둡 기반 빅데이터 소재 관리 방법을 나타낸 순서도이다. 도 2는 본 발명의 바람직한 일실시예에 따른 하둡을 이용한 빅데이터 소재 수집 및 분석 시스템을 나타낸 개념 도이다. 도 3은 본 발명의 바람직한 일실시예에 따른 데이터 처리부를 나타낸 개념도이다. 도 4 및 도 5는 본 발명의 바람직한 일실시예에 따른 데이터 저장부를 나타낸 개념도이다. 도 6은 본 발명의 바람직한 일실시예에 따른 데이터 분석부를 나타낸 구성도이다. 도 7 내지 도 12은 본 발명의 바람직한 일실시예에 따른 하둡 기반 빅데이터 소재 관리 방법 플랫폼을 나타낸 예시도이다."}
