{"patent_id": "10-2023-0050559", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0154231", "출원번호": "10-2023-0050559", "발명의 명칭": "기계 학습 훈련을 위한 데이터 생성방법 및 장치", "출원인": "주식회사 세명소프트", "발명자": "황바울"}}
{"patent_id": "10-2023-0050559", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "물체의 자세 인식의 학습을 위한 데이터를 생성하는 장치에 의해 수행되는 방법으로서,물체의 자세 인식 대상이 되는 물체에 관한 3차원 형상 정보를 생성하는 단계;상기 3차원 형상 정보를 이용하여 상기 물체가 위치하는 3차원 가상환경을 생성하는 단계; 및상기 3차원 가상환경에서 상기 물체를 촬영하는 단계를 포함하고,상기 3차원 가상환경을 생성하는 단계는,상기 물체가 속하는 3차원 공간을 정의하기 위해 기준 축에 관한 정보를 수신하는 단계;상기 기준 축에 대해 상기 물체의 기준 자세에 관한 정보를 수신하는 단계; 및상기 물체의 배경에 관한 정보를 수신하는 단계를 포함하도록 구성되는,기계 학습 훈련을 위한 데이터 생성방법."}
{"patent_id": "10-2023-0050559", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은, 물체의 자세 인식의 학습을 위한 데이터를 생성하는 장치에 의해 수행되는 방법으로서, 물체의 자세 인식 대상이 되는 물체에 관한 형상 정보를 생성하는 단계; 형상 정보를 이용하여 상기 물체가 위치하는 가상환 경을 생성하는 단계; 및 가상환경에서 상기 물체를 촬영하는 단계를 포함하는 데이터 생성방법을 개시한다. 본 발명에 따르면, 인공지능 학습 모델의 목적 함수에 적합한 데이터를 생성할 수 있다."}
{"patent_id": "10-2023-0050559", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 기계 학습 훈련을 위한 데이터 생성방법 및 장치에 관한 것으로, 더욱 상세하게는 물체의 자세 인식 을 위한 인공 신경망의 학습용 데이터 생성방법 및 장치에 관한 것이다."}
{"patent_id": "10-2023-0050559", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "제조 공정 자동화는 수작업 공정보다 효율성이 높고, 인력 감소로 인한 자동화 장비 교체의 필요성 증가 및 비 전과 로봇 기술의 발전으로 산업혁명 이후 꾸준히 발전해왔다. 제조 공정 자동화는 단순 반복 작업을 대체할 수 있는 로봇개발에 집중되어 로봇 반복 정밀도 향상 등과 같은 하드웨어 관련 분야에서 주로 연구되어 왔다. 그러나 전자분야의 부품 포장 및 조립공정 작업에 대한 자동화는 기술개발의 한계로 인하여 여전히 수작업에 의 존하고 있다. 최근 4차 산업혁명으로 인하여 스마트공장 분야가 대두되면서 실시간 모니터링, 부품조립, 물류 및 작업 내역 추적관리, 작업 상태파악, 불량관리 등의 분야에 자동화를 위한 인공지능기술이 적용되고 있다. 전자부품 포장 및 조립 공정 자동화에 대한 수요의 증가로 부품조립 분야에서는 인공지능기술을 기반으로 움직 이는 물체를 인식하고 추적하여 로봇이 물체를 파지할 수 있도록 하는 비주얼 서보잉 기술 개발이 활발히 진행 되고 있다. 비주얼 서보잉을 이용한 물체 추적 기술은 위치기반 시각적 제어(Position Based Visual Servoing, PBVS)와 이미지기반 시각적 제어(Image Based Visual Servoing, IBVS)로 분류될 수 있다. PBVS는 3차원 공간 속의 물체와 2차원 공간의 영상과의 관계를 이용하여 제어하는 기법으로써, 카메라 내외부 매개 변수 추출 및 영상 왜곡으로 인한 오차 보상이 필요하다는 단점이 있다. IBVS는 카메라 내외부 매개변수 추출은 필요하지 않지만, 카메라 영상에서 획득한 특징점들이 영상 위의 목표 위치로 이동하는 제어 방식을 카메라 영상에 의존하고 있기 때문에 조명 등 외부 환경 변화에 영향을 받아 제어 가 어려운 단점이 있다. 따라서 이러한 단점을 보완하기 위해 두 가지 방법을 결합하여 사용하는 기술 등의 연 구개발이 진행되고 있다. 제조 현장의 작업자들이 작업하고 있는 조립분야를 로봇으로 대체하기 위해서는 물체 검출 정확도가 높고 실시 간 처리 기술이 요구되기 때문에 실제 현장에 적용할 수 있는 상용화 단계의 기술 개발은 미흡한 편이다. 현재 연구단계에서, 저속 동적 물체에 대한 비주얼 서보잉 기술은 로봇이 안정적으로 물체를 추적하는 단계까지 기술 이 개발되어 있는 실정이다.고속 동적 물체 조립의 경우, 물체 검출의 정확도 및 자세 추정 정밀도를 높이는 연구가 진행되어 왔지만, 동적 물체의 경우 속도가 높을수록 영상 블러링이 많이 발생하기 때문에 물체 검출 정확도와 자세 추정 정밀도가 떨 어지는 문제점이 발생한다. 로봇은 비주얼 서보잉을 위해 먼저 타겟 물체를 정하고 그 물체의 위치와 방향을 인지해야 한다. 다음 로봇은 이미 알고 있는 DB를 통해 물체를 인식하고 스테레오 카메라를 통해 그 물체에 대한 3차원 좌표를 구한다. 또한 비주얼 서보잉을 위해서 그 물체의 자세가 추정되어야 한다. 물체의 자세 추정을 통해 비주얼 서보잉이 수행될 수 있다. 물체 인식을 위해 물체의 크기, 회전, 이동에 불변인 디스크립터(descriptor)를 사용하는 SIFT(Scale Invariant Feature Transform)를 사용한다. SIFT를 통해 물체가 인식된다. 3차원 정보 획득을 위해 스테레오 비전을 사용될 수 있다. 두 영상 간의 매칭은 SIFT를 이용하여 매칭을 수행한 후, 3차원 정보가 획득된다. 획득된 3차원 정보들을 가지고 원하는 물체의 자세 추정이 수행된다. 정확한 자세 추정을 위해 3차원 정보를 이용하여 위치 오차를 통한 매칭 검증이 수행된다. 산업 현장 제조 공정과정에 실제 적용하기 위해서는 먼저, 실시간으로 안정적인 물체 검출이 이루어져야 한다. 그러나 기존 전통방식을 동적 물체 조립에 적용할 경우 정확한 물체 검출 및 자세 추정 정밀도가 저하되는 문제 점이 발생될 수 있다. 최근에는 인공지능 알고리즘, 예를 들어 인공 신경망에 기반하는 물체 인식 기술이 로봇의 비주얼 서보잉에 사 용되고 있다. 그런데, 인공 신경망을 비주얼 서보잉에 이용하기 위해서는, 인공 신경망에 대한 학습이 선행되어 야 한다. 인공 신경망의 학습에는 학습용 데이터와 테스트용 데이터가 필요하고, 인공 신경망의 학습 효율은 데이터의 양 과 질에 달려있기 때문에 양질의 다량의 데이터가 필요하다. 그런데 학습에 필요한 데이터를 직접 만들어서 사 용되는 경우 보다는 이미 만들어진 공공 데이터를 이용하기 때문에, 목적 함수에 적합한 학습용 데이터 및 테스 트용 데이터를 얻는 것은 어려운 일이다. 관련 발명으로서 공개번호 제10-2021-0002410호의 발명은, 외형인식모델 학습용 데이터셋 구축 방법, 장치 및 프로그램에 관한 것으로, 학습용 영상데이터 획득단계, 학습용 영상데이터 제공단계, 세부 개별외형특성 획득단 계 및 학습용 데이터셋 구축 단계를 포함하는 방법을 개시하고 있으나, 어떻게 학습용 영상데이터를 획득하는 지에 대해서는 구체적인 언급이 없다. 관련 발명으로서 등록번호 제10-2207489호의 발명은, 데이터 생성방법에 관한 것으로, 냉동기기의 운전에 관한 데이터 수집에 있어서, 실제 데이터를 기반으로 어떻게 인공데이터를 생성하는 지에 대한 언급이 없다. 관련 발명으로서 공개번호 제10-2021-0004162호의 발명은, 인공지능 머신러닝 학습을 위한 데이터셋 자동 생성 장치 및 SW와 그의 제어 방법에 관한 것으로, 공간에 위치한 물품에 대한 이미지를 획득하는 카메라를 포함하는 데이터셋 자동 생성 인공지능 장치를 개시하고 있으나, 카메라는 사람에 의해 수동으로 조작될 수 밖에 없기 때 문에 자동화의 문제점이 있다. 위에 소개된 관련 발명들은 인공지능 모델의 학습에 필요한 데이터를 생성한다는 발명의 목적 면에서 본 발명과 공통점이 있을 수는 있으나, 가상환경을 통해 영상을 직접 생성하는 본 발명의 구성과 구별되고, 따라서 효과 면에서도 큰 차이를 보이고 있다. 선행기술문헌 특허문헌 (특허문헌 0001) 한국 공개 특허 제10-2021-0002410호 (2021.01.08 공개) (특허문헌 0002) 한국 등록 특허 제10-2207489호 (2021,01.26 공고) (특허문헌 0003) 한국 공개 특허 제10-2021-0004162호 (2021.01.13 공개)"}
{"patent_id": "10-2023-0050559", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 2, "content": "발명의 내용"}
{"patent_id": "10-2023-0050559", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명이 해결하고자 하는 일 과제는, 공공 데이터에 의존하여 학습을 수행했던 종래 기술에 따른 인공지능 학 습 모델의 학습 훈련의 문제점을 해결하는 것이다. 본 발명이 해결하고자 하는 일 과제는, 인공지능 학습 모델의 목적 함수에 적합한 학습용 및 테스트용 데이터를 직접 생성할 수 있는 방법 및 장치를 제안하는 것이다."}
{"patent_id": "10-2023-0050559", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 일 실시 예에 따른 데이터 생성방법은, 물체의 자세 인식의 학습을 위한 데이터를 생성하는 장치에 의해 수행되는 방법으로서, 물체의 자세 인식 대상이 되는 물체에 관한 형상 정보를 생성하는 단계; 형상 정보 를 이용하여 상기 물체가 위치하는 가상환경을 생성하는 단계; 및 가상환경에서 물체를 촬영하는 단계를 포함하 도록 구성될 수 있다. 본 발명의 일 실시 예에 따른 데이터 생성방법은, 물체의 자세 인식의 학습을 위한 데이터를 생성하는 장치에 의해 수행되는 방법으로서, 물체의 자세 인식 대상이 되는 물체에 관한 형상 정보를 생성하는 단계; 형상 정보 를 이용하여 상기 물체가 위치하는 가상환경을 생성하는 단계; 및 가상환경에서 물체를 촬영하는 단계를 포함하 고, 물체에 관한 형상 정보를 생성하는 단계는, 물체에 관한 CAD 모델을 생성하는 단계를 포함하도록 구성될 수 있다. 본 발명의 일 실시 예에 따른 데이터 생성방법은, 물체의 자세 인식의 학습을 위한 데이터를 생성하는 장치에 의해 수행되는 방법으로서, 물체의 자세 인식 대상이 되는 물체에 관한 형상 정보를 생성하는 단계; 형상 정보 를 이용하여 상기 물체가 위치하는 가상환경을 생성하는 단계; 및 가상환경에서 물체를 촬영하는 단계를 포함하 고, 가상환경을 생성하는 단계는, 물체가 속하는 3차원 공간을 정의하기 위해 기준 축에 관한 정보를 수신하는 단계; 기준 축에 대해 상기 물체의 기준 자세에 관한 정보를 수신하는 단계; 및 물체의 배경에 관한 정보를 수 신하는 단계를 포함하도록 구성될 수 있다. 본 발명의 일 실시 예에 따른 데이터 생성방법은, 물체의 자세 인식의 학습을 위한 데이터를 생성하는 장치에 의해 수행되는 방법으로서, 물체의 자세 인식 대상이 되는 물체에 관한 형상 정보를 생성하는 단계; 형상 정보 를 이용하여 상기 물체가 위치하는 가상환경을 생성하는 단계; 및 가상환경에서 물체를 촬영하는 단계를 포함하 고, 물체를 촬영하는 단계는, 상기 물체에 대한 RGB 정보 및 깊이 정보를 수집하는 단계를 포함하도록 구성될 수 있다. 본 발명의 일 실시 예에 따른 데이터 생성 시스템은, 물체의 자세 인식의 대상이 되는 물체에 관한 형상 정보를 이용하여 물체 및 물체가 속하는 3차원 공간을 생성하는 가상환경 설정부; 가상환경에서 상기 물체를 촬영하는 가상 촬영부; 및 촬영된 영상, 물체에 관한 정보 및 촬영에 사용된 카메라 정보가 포함된 데이터를 생성하는 학 습용 데이터 생성부를 포함하도록 구성될 수 있다."}
{"patent_id": "10-2023-0050559", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명에 의하면, 인공지능 학습 모델의 목적 함수에 적합한 데이터를 생성할 수 있다. 또한, 물체의 위치 및 회전 정보가 포함된 데이터를 물체 자세 인식의 인공지능 모델의 학습에 이용할 수 있다."}
{"patent_id": "10-2023-0050559", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명을 상세하게 설명하기 전에, 본 명세서에서 사용된 용어나 단어는 통상적이거나 사전적인 의미로 무조건 한정하여 해석되어서는 아니 되며, 본 발명의 발명자가 자신의 발명을 가장 최선의 방법으로 설명하기 위해서 각종 용어의 개념을 적절하게 정의하여 사용할 수 있고, 더 나아가 이들 용어나 단어는 본 발명의 기술적 사상 에 부합하는 의미와 개념으로 해석되어야 함을 알아야 한다. 이하, 본 발명의 실시 예에 대해 관련 도면들을 참조하여 상세히 설명하기로 한다. 도 1은 본 발명의 일 실시 예에 따른 데이터 생성 시스템의 블록도이다. 도 1을 참조하면, 데이터 생성 시스템은 제어부, 입력 장치, 출력 장치, 저장 장치, 통신 장치, 및 메모리를 포함하도록 구성될 수 있다. 그리고 메모리는 런타임 핸들러, 임 포트/엑스포트, 가상환경 설정부, 장면 컨트롤러 및 카메라 컨트롤러를 포함하도록 구성될 수 있다. 제어부는, 프로세서(processor)에 해당하는 중앙처리장치 형태로 구현될 수 있고, 데이터 생성방법을 구성 하는 명령어 셋을 실행하는 기능을 수행한다. 제어부는 사용자 입력장치, 카메라, 출력 장치, 저장 장치, 통신 장치로의 데이터 송신 및 이들로부터의 데이터 수신을 통해 이들의 동작을 기본적으로 제어할 수 있다. 사용자 입력 장치는, 데이터 생성방법(S100)의 실행에 있어서 필요한 각종 사용자 입력, 예를 들어 문자, 숫자 입력 등을 수신하는 기능을 수행한다. 카메라는 실제 촬영된 이미지를 제공하는 기능을 한다. 예를 들어 카메라는 가상환경에서 사용될 배 경 이미지로서, 실제 공장 내의 조립라인이 촬영된 이미지, 예를 들어 RGB 정보 및 깊이 정보를 포함하는 이미 지를 배경 이미지로 데이터 생성 장치에 제공할 수 있다. 출력 장치는, 데이터 생성방법(S100)의 실행에 있어서 사용자에게 각종 데이터와 정보, 예를 들어 런타임 핸들러, 사용자 인터페이스 등을 디스플레이 하거나, 소리를 출력하는 기능을 수행한다. 저장 장치는, 데이터 생성방법의 실행에 있어서 각종 데이터와 정보, 예를 들어 물체의 3차원 형상 정보, 카메라 정보 등을 저장하는 기능을 수행한다. 통신 장치는, 데이터 생성방법의 실행에 있어서 카메라를 비롯하여 각종 외부 기기 및 외부 기기, 예를 들 어 서버와 다양한 프로토콜을 통해 데이터를 송신 및 수신하는 기능을 수행한다. 따라서 통신 장치는 내부적으 로 다양한 프로토콜에 대응하는 통신 모듈, 예를 들어 병렬통신 모듈, 직렬통신 모듈, 근거리 통신 모듈, 셀룰 러 통신 모듈, 무선랜 통신 모듈, 및 인터넷 통신 모듈 등을 포함하도록 구성될 수 있다. 메모리는 전원의 ON/OFF에 따라 저장된 데이터가 유지되거나 사라지는 비휘발성 또는 휘발성 반도체 소자 를 통해서 구현될 수 있다. 메모리는 소프트웨어 형태로 구현된 명령 수행 모듈들을 로드하고, 이를 저장 하는 기능을 수행한다. 런타임 핸들러는, 3차원 가상공간에 기준 축을 설정하고, 기준 축에 따라 물체를 배치하는 기능을 수행한 다. 임포트/엑스포트는 물체의 입체 형상 정보, 예를 들어 3D CAD 파일을 읽어 들이고, 변환된 다른 형태의 파 일을 출력하는 기능을 한다. 가상환경 설정부는 물체에 관한 정보 및 배경에 관한 정보를 수신하고 이를 이용하여 가상환경을 설정하고, 가상환경에서 배치된 카메라의 설정에 따라 물체를 촬영하는 기능을 한다. 가상환경 설정부는, 실제 물체가 놓여 있거나, 물체가 움직이는 생산 라인의 작업 환경에 근접하도록, 가 상환경에서 조명의 위치, 방향, 및 조도를 제어할 수 있다. 장면 컨트롤러는 가상환경에서 물체 및 배경을 포함하는 장면을 컨트롤하는 기능을 한다. 카메라 컨트롤러는 가상환경에서 카메라 정보에 기반하여 배치된 카메라를 컨트롤하는 기능을 한다. 가상 환경에 배치된 카메라는 가상의 카메라에 해당한다. 사용자는, 가상환경 설정부를 이용하여 가상환경에 다 양한 종류의 카메라 중에서 촬영에 사용될 카메라를 선택할 수 있다. 도 2는 본 발명의 일 실시 예에 따른 데이터 생성 시스템의 네트워크 관계도이다. 도 2를 참조하면, 데이터 생성 시스템은 네트워크를 통해 통신할 수 있도록 서버와 연결될 수 있다. 서버는 물체에 대한 3차원 형상 정보, 3차원 CAD 파일 등을 데이터 생성 시스템에 제공할 수 있다. 그 밖에 서버는 가상환경에 필요한 카메라에 관한 정보 등을 데이터 생성 시스템에 제공할 수 있다. 네트워크는 유선 및 무선 네트워크, 예를 들어, LAN(local area network), WAN(wide area network), TCP/IP의 인터넷(internet), 인트라넷(intranet) 및 엑스트라넷(extranet), 그리고 모바일 네트워크, 예를 들 어 셀룰러, 3G, LTE, WiFi 네트워크, 애드혹 네트워크 및 이들의 조합을 비롯한 임의의 적절한 통신 네트워크 일 수 있다. 네트워크는 허브, 브리지, 라우터, 스위치 및 게이트웨이와 같은 네트워크 요소들의 연결을 포함할 수 있 다. 네트워크는 인터넷과 같은 공용 네트워크 및 안전한 기업 사설 네트워크와 같은 사설 네트워크를 비롯 한 하나 이상의 연결된 네트워크들, 예컨대 다중 네트워크 환경을 포함할 수 있다. 네트워크에의 액세스는 하나 이상의 유선 또는 무선 액세스 네트워크들을 통해 제공될 수 있다. 도 3은 본 발명의 일 실시 예에 따른 데이터 생성 방법의 흐름도이다. 도 4는 본 발명의 일 실시 예에 따른 데이터 생성 방법의 예시도이다. 도 4를 참조하면, 도 3을 참조하면, 데이터 생성 방법(S100)은 물체에 관한 형상 정보 생성(S110), 물체에 관한 형상 정보를 이용하여 가상환경 생성(S120), 가상환경에서 물체를 촬영(S130) 및 촬영 정보를 이용하여 학습에 필요한 데이터 생성(S140)을 포함하도록 구성될 수 있다. 도 1의 데이터 생성 시스템은 도 3의 데이터 생성방법(S100)을 수행하는 주체에 해당한다. S110 단계에서 데이터 생성 시스템은, 데이터 생성 시스템은 물체에 관한 형상 정보를 생성할 수 있 다. 도 4를 참조하면, 물체에 관한 형상 정보는 컴퓨터 지원 설계(Computer Aided Design, CAD)에 의해 생성된 3D 설계 파일일 수 있다. 데이터 생성 시스템은 임포트/익스포트를 이용하여 컴퓨터 지원 설계를 통 해 제작된 3D 설계 파일을 읽어 들이고, 다른 프로그램 모듈이 공유할 수 있도록 이를 다른 형태의 파일로 변환 하여 출력할 수 있다. S120 단계에서 데이터 생성 시스템은, 물체에 관한 형상 정보를 이용하여 가상환경을 생성할 수 있다. 도 4를 참조하면, 가상환경은, 기준 축 설정, 물체의 기준 자세 설정 및 장면 설정을 포함하도록 구성될 수 있다. 장면 설정에는 주변 환경 및 물체의 재질 등이 표현될 수 있다. S130 단계에서 데이터 생성 시스템은, 데이터 생성 시스템은 가상환경에서 물체를 촬영할 수 있다. 도 4를 참조하면, 데이터 생성 시스템 가상환경에 가상의 카메라를 배치하고 물체의 랜덤한 면을 촬영할 수 있다. 임의의 자세 및 위치를 구현하기 위해 카메라가 회전하거나, 물체가 자유낙하할 수 있다. S140 단계에서 데이터 생성 시스템은, 데이터 생성 시스템은 촬영 정보를 이용하여 학습에 필요한 데 이터를 생성할 수 있다. 도 4를 참조하면 학습용 데이터 및 테스트용 데이터가 생성될 수 있으며, 이들 데이터 는, RGB 이미지, 깊이 이미지와 물체 및 배경에 관한 정보를 포함할 수 있다. 본 발명의 일 실시 예에 따른 데이터 생성방법 및 시스템은 대용량의 이미지 데이터를 이용하여 인공 신경망의 일종인 CNN(Convolutional Neural Network)를 학습하여 다양한 정보를 주는 알고리즘을 위하여 대용량의 데이터 를 자율적으로 생성할 수 있다. 데이터 생성 시스템은 고해상도의 이미지를 생성할 수 있는 렌더링 기술을 이용하여 실제 사진 이미지와 유사한 데이터를 생성하고, 가상환경에서의 깊이 값을 이용하여 깊이 이미지를 생성할 수 있다. 데이터 생성방법에 의해 생성된 이미지에 대해서 물체의 위치를 특정할 수 있는 좌표 값과, 이미지 사진 상에서 물체의 회전 정도를 알 수 있도록 각 축에 대한 회전 정도인 오일러 각도를 출력한다. 이 회전 정보는 카메라의 위치 및 각도를 모두 고려하여 생성된 각도로 이미지상에서 물체가 취하는 자세 정보를 가진다.본 발명의 일 실시 예에 따른, 데이터 생성방법(S100)은 이를 실행하는 명령어 셋을 포함하는 프로그램 형태로 구현될 수 있다. 데이터 생성방법을 실행하는 프로그램은, 프로그램은 기준 축 설정 프로그램에 해당하는 런타 임 핸들러, 공유 폴더, 장면 촬영 프로그램에 해당하는 가상환경 설정부를 포함하도록 구성될 수 있다. 본 발명의 일 실시 예에 따른 프로그램은, 사용자에게 필요한 정보를 입력 받는 프로그램과 실제 동작 프로그램 을 분리한 구조로서, 기준 축 설정 프로그램에서, 데이터를 생성할 때 카메라의 속성 및 물체의 재질, 장면의 배경 등을 선택할 수 있도록 하였다. 이 정보는 기준 축 설정 프로그램과 장면 촬영 프로그램 둘 모두 접근할 수 있는 공유 폴더에 출력되어 생성된다. 장면 촬영 프로그램에서는 이 정보들을 가지고 가상 환경의 구성, 카 메라의 속성을 변경하여 사용자가 원하는 데이터를 생성할 수 있도록 한다. 기준 축 설정 프로그램에 해당하는 런타임 핸들러는 사용자가 원하는 데이터를 출력할 수 있도록 세부사항 들을 조정할 수 있다. 임포트/엑스포트는 정보를 입력 받을 수 있는 환경을 제공하는 그래픽 유저 인터페이스와 데이터를 생성하 고 싶은 3D 모델 파일(.obj, .3ds)을 임포트하고 공유 폴더에 저장할 파일들을 출력하는 임포트/엑스포트 기능 을 제공한다. 런타임 핸들러는 오일러 각도로서 출력되는 물체의 자세 정보의 기준 축을 사용자가 설정할 수 있도록 물 체를 직접 돌려가며 기준 축을 맞출 수 있는 기능을 제공한다. 이에 대한 정보들은 공유 폴더에 저장된다. 공유폴더에 저장되는 파일은 3D 모델 파일을 유니티 프로그램에서 재구현할 수 있도록 변환된 메쉬 파일과, 카 메라 설정 및 물체에 대한 정보가 담긴 파일이다. 공유 폴더는 기준 축 설정 프로그램에 해당하는 런타임 핸들 러와 장면 촬영 프로그램에 해당하는 가상환경 설정부가 모두 접근할 수 있도록 설정된 폴더이다. 가상환경 설정부는 공유 폴더에 저장되어 있는 파일 정보들을 통해서 이미지를 생성할 때 쓰이는 카메라의 세부사항들을 설정하여 주고 대상이 되는 물체의 재질 등의 속성을 설정하고, 공유 폴더 안의 파일들에 대한 정 보들이 모두 반영된 가상환경에서 물체에 대한 영상을 생성할 수 있다. 가상환경 설정부는 인식 대상이 되는 물체를 랜덤한 자세를 취하게 하고 가상의 카메라를 이용하여 물체에 대한 영상을 생성할 수 있다. 또는 카메라 자체가 일정한 각도로 회전하면서 물체에 대한 영상이 촬영될 수 있 다. 카메라는, 물체에 대한 RGB 이미지를 먼저 촬영하게 하고, 그 후 물체에 대한 깊이 이미지를 RGB 이미지를 생성할 때와 동일한 물체와 카메라의 위치, 자세를 맞춘 후에 생성하도록 구성될 수 있다. 인식 대상 물체의 다양한 면이 자연스럽게 생성되기 위해, 물체를 가상환경에서 자유낙하 시키고, 떨어지면서 자세가 변하는 물체가 촬영될 수 있다. 여기서, 물체는, 그 형상에 따라 자유낙하 시에 물리적 법칙, 예를 들어 모멘트에 의한 회전을 통해 랜덤한 면이 촬영될 수 있다. 임포트/엑스포트는 가상환경 설정부에 의해 생성된 이미지들에 대하여 각 이미지와 같은 이름을 가진 바이너리 파일을 생성하는데 여기에는 이미지의 크기, 물체의 위치, 물체의 자세 및 이미지에서 물체가 점유하 는 범위에 대한 정보를 포함된다. 도 5는 본 발명의 일 실시 예에 따른 데이터 생성 시스템 사용자 인터페이스의 예시도이다. 도 5를 참조하면, 기준 축이 설정된 후, 물체가 배치된 가상환경이 묘사되어 있다. 도 6은 본 발명의 일 실시 예에 따른 데이터 생성 시스템 사용자 인터페이스의 예시도이다. 도 6을 참조하면, 기준 축이 설정된 후, 물체가 배치된 가상환경의 배경 화면이 묘사되어 있다. 도 7은 본 발명의 일 실시 예에 따른 데이터 생성방법에 의해 생성된 데이터의 예시도이다. 도 7을 참조하면, 본 발명의 일 실시 예에 따른 데이터 생성 시스템의 의해 생성된 데이터의 구조가 묘사 되어 있다. 생성된 데이터는, RGB 이미지, 깊이 정보(Depth image) 및 자세정보를 포함할 수 있다. 여기서 자세 정보는, 물체의 중심 좌표(x, y, z)에 관한 정보, 카메라 시점에서 기준 자세 대비 회전 정보를 포함할 수 있다. 이와 같이 본 발명의 일 실시 예에 따르면, 인공지능 학습 모델의 목적 함수에 적합한 데이터를 생성할 수 있다. 또한, 물체의 위치 및 회전 정보가 포함된 데이터를 물체 자세 인식의 인공지능 모델의 학습에 이용할 수 있다. 이상, 일부 예를 들어서 본 발명의 바람직한 여러 가지 실시 예에 대해서 설명하였지만, 본 \"발명을 실시하기 위한 구체적인 내용\" 항목에 기재된 여러 가지 다양한 실시 예에 관한 설명은 예시적인 것에 불과한 것이며, 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자라면 이상의 설명으로부터 본 발명을 다양하게 변형하여 실 시하거나 본 발명과 균등한 실시를 행할 수 있다는 점을 잘 이해하고 있을 것이다. 또한, 본 발명은 다른 다양한 형태로 구현될 수 있기 때문에 본 발명은 상술한 설명에 의해서 한정되는 것이 아 니며, 이상의 설명은 본 발명의 개시 내용이 완전해지도록 하기 위한 것으로 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자에게 본 발명의 범주를 완전하게 알려주기 위해 제공되는 것일 뿐이며, 본 발명은 청구범 위의 각 청구항에 의해서 정의될 뿐임을 알아야 한다."}
{"patent_id": "10-2023-0050559", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일 실시 예에 따른 데이터 생성 시스템의 블록도이다. 도 2는 본 발명의 일 실시 예에 따른 데이터 생성 시스템의 네트워크 관계도이다. 도 3은 본 발명의 일 실시 예에 따른 데이터 생성 방법의 흐름도이다. 도 4는 본 발명의 일 실시 예에 따른 데이터 생성 방법의 예시도이다. 도 5는 본 발명의 일 실시 예에 따른 데이터 생성 시스템 사용자 인터페이스의 예시도이다.도 6은 본 발명의 일 실시 예에 따른 데이터 생성 시스템 사용자 인터페이스의 예시도이다. 도 7은 본 발명의 일 실시 예에 따른 데이터 생성방법에 의해 생성된 데이터의 예시도이다."}
