{"patent_id": "10-2020-0146532", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2022-0060678", "출원번호": "10-2020-0146532", "발명의 명칭": "VR 컨텐츠의 저작 및 체험을 위한 시스템 및 서비스 제공 방법", "출원인": "주식회사 채움숲", "발명자": "최경호"}}
{"patent_id": "10-2020-0146532", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "VR(Virtual Reality) 컨텐츠의 저작 및 체험을 위한 시스템에 있어서,VR 컨텐츠의 저작을 위한 제1 웹 페이지 및 VR 컨텐츠의 체험을 위한 제2 웹 페이지를 제공하는, 서버;상기 서버와 연결되어 상기 제1 웹 페이지를 디스플레이 하고, 상기 제1 웹 페이지와 관련된 사용자 입력에 대한 정보를 상기 서버로 전송하는, 사용자 단말; 및상기 서버와 연결되어 상기 제2 웹 페이지에 포함된 VR 컨텐츠를 디스플레이 하는, VR 장치;를 포함하고,상기 서버는, 상기 제1 웹 페이지 상에서,적어도 하나의 프로젝트를 생성하기 위한 사용자 입력이 상기 사용자 단말을 통해 수신되면, 상기 프로젝트의식별 정보 및 위치 정보를 입력 받기 위한 제1 UI(User Interface)를 제공하고,상기 프로젝트 내에 적어도 하나의 레이어를 추가하기 위한 사용자 입력이 상기 사용자 단말을 통해 수신되면,상기 레이어 상에 적어도 하나의 시점(timepoint)의 VR 영상을 업로드 받기 위한 제2 UI를 제공하고,상기 서버는, 상기 제2 웹 페이지 상에서,상기 생성된 프로젝트를 선택하는 사용자 입력이 상기 VR 장치를 통해 수신되면, 상기 프로젝트 내의 적어도 하나의 레이어에 포함된 VR 영상을 제공하는, 시스템."}
{"patent_id": "10-2020-0146532", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 서버는,상기 제1 웹 페이지 상에서, 상기 레이어 내에 적어도 하나의 부가 정보를 추가하기 위한 제3 UI를 제공하고,상기 제3 UI와 관련하여 상기 사용자 단말을 통해 수신된 사용자 입력을 기반으로, 상기 제2 웹 페이지 상에서상기 레이어의 상기 VR 영상과 상기 부가 정보를 함께 제공하는, 시스템."}
{"patent_id": "10-2020-0146532", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,상기 서버는,상기 제1 웹 페이지의 상기 제3 UI를 통해, 상기 레이어의 VR 영상 중 특정한 시점(timepoint) 및 특정한 시야각(Field of View)에 대하여 상기 부가 정보를 추가하기 위한 사용자 입력을 수신하고,상기 제2 웹 페이지 상에서, 상기 VR 영상이 상기 시점 및 상기 시야각으로 제공되는 경우, 상기 부가 정보를추가로 제공하는, 시스템."}
{"patent_id": "10-2020-0146532", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,상기 서버는, 상기 제1 웹 페이지 상에서,상기 프로젝트 내에 포함된 적어도 하나의 레이어의 순서를 변경하거나 또는 삭제하기 위한 제4 UI를 제공하는,시스템."}
{"patent_id": "10-2020-0146532", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "공개특허 10-2022-0060678-3-제1항에 있어서,상기 서버는,상기 VR 장치의 위치 정보를 식별하고,상기 제2 웹 페이지 상에서, 상기 식별된 위치 정보와 매칭되는 적어도 하나의 프로젝트를 추천하는, 시스템."}
{"patent_id": "10-2020-0146532", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서,상기 서버는,입력된 VR 영상의 속성과 관련된 복수의 파라미터의 값을 출력하도록 훈련된 인공지능 모델을 포함하고,상기 서버에 등록된 복수의 프로젝트 각각에 포함된 VR 영상을 상기 인공지능 모델에 입력하여, 상기 복수의 프로젝트 각각에 대한 상기 복수의 파라미터의 값을 획득하고,상기 획득된 복수의 파라미터의 값을 기반으로, 상기 복수의 프로젝트 중 상기 선택된 프로젝트와 매칭되는 프로젝트를 추천하는, 시스템."}
{"patent_id": "10-2020-0146532", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에 있어서,상기 서버는,상기 서버에 등록된 복수의 프로젝트 중 특정 장소에 태깅된 적어도 하나의 프로젝트 각각의 조회수를기반으로, 상기 장소에 태깅된 적어도 하나의 프로젝트 각각을 위한 리워드를 산출하는, 시스템."}
{"patent_id": "10-2020-0146532", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서,상기 시스템은,상기 서버에 등록된 복수의 프로젝트 중 적어도 하나의 프로젝트의 상기 장소에 대한 태깅(Tagging) 여부를 결정하는 적어도 하나의 관리자 장치;를 더 포함하고,상기 서버는,상기 프로젝트를 상기 장소에 태깅하기 위한 사용자 입력이 상기 사용자 단말을 통해 수신되면, 상기 프로젝트에 포함된 VR 영상을 상기 관리자 장치로 전송하고,상기 관리자 장치로부터 상기 태깅에 대한 승낙이 수신되면, 상기 프로젝트를 상기 장소에 태깅하는, 시스템."}
{"patent_id": "10-2020-0146532", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "VR컨텐츠의 저작 및 체험을 위한 시스템이 개시된다. 본 시스템은, VR 컨텐츠의 저작을 위한 제1 웹 페이지 및 VR 컨텐츠의 체험을 위한 제2 웹 페이지를 제공하는 서버, 서버와 연결되어 제1 웹 페이지를 디스플레이 하고, 제1 웹 페이지와 관련된 사용자 입력에 대한 정보를 서버로 전송하는 사용자 단말, 서버와 연결되어 제2 웹 페이 지에 포함된 VR 컨텐츠를 디스플레이 하는 VR 장치를 포함한다."}
{"patent_id": "10-2020-0146532", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 VR 컨텐츠를 제공하는 시스템에 관한 것으로, 보다 상세하게는, VR 컨텐츠의 저작 및 체험을 수행할 수 있는 웹 환경을 제공하는 시스템 및 서비스 제공 방법에 관한 것이다."}
{"patent_id": "10-2020-0146532", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "VR(Virtual Reality) 및 AR(Augmented Reality) 컨텐츠는 가상의 요소를 현실감 있게 제공할 수 있다. 다만, 현실에 존재하지 않는 가상의 환경을 포함하는 VR 컨텐츠 외에, 실제로 존재하는 공간을 VR 카메라를 통 해 촬영하여 획득된 VR 컨텐츠 역시 각광받고 있다. 그리고, 다양한 VR 카메라들이 출시되면서 기술자가 아닌 일반인 역시 실제 존재하는 공간 또는 대상에 대하여 3D의 VR 영상을 촬영하는 것이 가능하다. 특히, 실제로 존재하는 관광 명소, 휴양림, 자연 경관 등이 촬영된 VR 컨텐츠는, 이동에 제약이 있는 장애인이 공간적 제약 없이 관광 명소, 휴양림 등을 현실감 있게 체험할 수 있게 한다. 또한, 해당 VR 컨텐츠는, 관광 명소, 휴양림, 자연 경관 등을 홍보하여 실제 방문을 유도하는 수단으로도 사용 될 수 있다는 점에서 의미가 있다. 다만, 상술하였듯 일반인들도 3D의 VR 영상을 촬영하는 것이 가능해진 반면, 일반인들이 촬영한 VR 영상을 저작 하고 공유하기 위한 웹 기반 플랫폼 기술은 발전이 더 필요하다. 선행기술문헌 특허문헌 (특허문헌 0001) 등록 특허 공보 제10-21527610000(ＨＴＭＬ５ 웹 환경 기반 ＶＲ 및 ＡＲ 인터랙션 콘텐츠 서 비스 제공 시스템)"}
{"patent_id": "10-2020-0146532", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 개시는 VR 컨텐츠를 쉽게 저작하고 공유할 수 있도록 하는 웹 기반 플랫폼을 구성하는 시스템을 제공한다. 본 개시는, VR 컨텐츠를 저작하기 위한 웹 페이지 환경 내에서, 사용자로 하여금 단계 별로 VR 컨텐츠를 저작할 수 있도록 하는 최적의 User Interface를 출력하는 시스템 및 서비스 제공 방법을 제공한다. 본 발명의 목적들은 이상에서 언급한 목적으로 제한되지 않으며, 언급되지 않은 본 발명의 다른 목적 및 장점들 은 하기의 설명에 의해서 이해될 수 있고, 본 발명의 실시 예에 의해 보다 분명하게 이해될 것이다. 또한, 본 발명의 목적 및 장점들은 특허 청구 범위에 나타낸 수단 및 그 조합에 의해 실현될 수 있음을 쉽게 알 수 있을 것이다."}
{"patent_id": "10-2020-0146532", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 개시의 일 실시 예에 따른 VR(Virtual Reality) 컨텐츠의 저작 및 체험을 위한 시스템은, VR 컨텐츠의 저작 을 위한 제1 웹 페이지 및 VR 컨텐츠의 체험을 위한 제2 웹 페이지를 제공하는, 서버, 상기 서버와 연결되어 상 기 제1 웹 페이지를 디스플레이 하고, 상기 제1 웹 페이지와 관련된 사용자 입력에 대한 정보를 상기 서버로 전 송하는, 사용자 단말, 상기 서버와 연결되어 상기 제2 웹 페이지에 포함된 VR 컨텐츠를 디스플레이 하는, VR 장 치를 포함한다. 상기 서버는, 상기 제1 웹 페이지 상에서, 적어도 하나의 프로젝트를 생성하기 위한 사용자 입 력이 상기 사용자 단말을 통해 수신되면, 상기 프로젝트의 식별 정보 및 위치 정보를 입력 받기 위한 제1 UI(User Interface)를 제공하고, 상기 프로젝트 내에 적어도 하나의 레이어를 추가하기 위한 사용자 입력이 상 기 사용자 단말을 통해 수신되면, 상기 레이어 상에 적어도 하나의 시점(timepoint)의 VR 영상을 업로드 받기 위한 제2 UI를 제공한다. 그리고, 상기 서버는, 상기 제2 웹 페이지 상에서, 상기 생성된 프로젝트를 선택하는 사용자 입력이 상기 VR 장치를 통해 수신되면, 상기 프로젝트 내의 적어도 하나의 레이어에 포함된 VR 영상을 제공한다. 상기 서버는, 상기 제1 웹 페이지 상에서, 상기 레이어 내에 적어도 하나의 부가 정보를 추가하기 위한 제3 UI 를 제공하고, 상기 제3 UI와 관련하여 상기 사용자 단말을 통해 수신된 사용자 입력을 기반으로, 상기 제2 웹 페이지 상에서 상기 레이어의 상기 VR 영상과 상기 부가 정보를 함께 제공할 수도 있다. 이때, 상기 서버는, 상기 제1 웹 페이지의 상기 제3 UI를 통해, 상기 레이어의 VR 영상 중 특정한 시점 (timepoint) 및 특정한 시야각(Field of View)에 대하여 상기 부가 정보를 추가하기 위한 사용자 입력을 수신하 고, 상기 제2 웹 페이지 상에서, 상기 VR 영상이 상기 시점 및 상기 시야각으로 제공되는 경우, 상기 부가 정보 를 추가로 제공할 수 있다. 또한, 상기 서버는, 상기 제1 웹 페이지 상에서, 상기 프로젝트 내에 포함된 적어도 하나의 레이어의 순서를 변 경하거나 또는 삭제하기 위한 제4 UI를 제공할 수 있다. 한편, 상기 서버는, 상기 VR 장치의 위치 정보를 식별하고, 상기 제2 웹 페이지 상에서, 상기 식별된 위치 정보 와 매칭되는 적어도 하나의 프로젝트를 추천할 수 있다.상기 서버는, 입력된 VR 영상의 속성과 관련된 복수의 파라미터의 값을 출력하도록 훈련된 인공지능 모델을 포 함할 수도 있다. 이 경우, 상기 서버는, 상기 서버에 등록된 복수의 프로젝트 각각에 포함된 VR 영상을 상기 인 공지능 모델에 입력하여, 상기 복수의 프로젝트 각각에 대한 상기 복수의 파라미터의 값을 획득하고, 상기 획득 된 복수의 파라미터의 값을 기반으로, 상기 복수의 프로젝트 중 상기 선택된 프로젝트와 매칭되는 프로젝트를 추천할 수 있다. 한편, 상기 서버는, 상기 서버에 등록된 복수의 프로젝트 중 특정 장소에 태깅된 적어도 하나의 프로젝트 각각 의 조회수를 기반으로, 상기 장소에 태깅된 적어도 하나의 프로젝트 각각을 위한 리워드를 산출할 수 있다. 이 경우, 상기 시스템은, 상기 서버에 등록된 복수의 프로젝트 중 적어도 하나의 프로젝트의 상기 장소에 대한 태깅(Tagging) 여부를 결정하는 적어도 하나의 관리자 장치를 더 포함할 수 있다. 여기서, 상기 서버는, 상기 프로젝트를 상기 장소에 태깅하기 위한 사용자 입력이 상기 사용자 단말을 통해 수신되면, 상기 프로젝트에 포 함된 VR 영상을 상기 관리자 장치로 전송하고, 상기 관리자 장치로부터 상기 태깅에 대한 승낙이 수신되면, 상 기 프로젝트를 상기 장소에 태깅할 수 있다. 본 개시의 일 실시 예에 따라 서버를 포함하는 시스템의 VR(Virtual Reality) 컨텐츠 저작 및 체험을 위한 서비 스 제공 방법은, VR 컨텐츠의 저작을 위한 제1 웹 페이지를 제공하는 단계, 상기 저작된 VR 컨텐츠의 체험을 위 한 제2 웹 페이지를 제공하는 단계를 포함한다. 상기 제1 웹 페이지를 제공하는 단계는, 적어도 하나의 프로젝 트를 생성하기 위한 사용자 입력이 사용자 단말을 통해 수신되면, 상기 프로젝트의 식별 정보 및 위치 정보를 입력 받기 위한 제1 UI(User Interface)를 제공하고, 상기 프로젝트 내에 적어도 하나의 레이어를 추가하기 위 한 사용자 입력이 상기 사용자 단말을 통해 수신되면, 상기 레이어 상에 적어도 하나의 시점(timepoint)의 VR 영상을 업로드 받기 위한 제2 UI를 제공한다. 상기 제2 웹 페이지를 제공하는 단계는, 상기 생성된 프로젝트를 선택하는 사용자 입력이 상기 VR 장치를 통해 수신되면, 상기 프로젝트 내의 적어도 하나의 레이어에 포함된 VR 영상을 제공한다."}
{"patent_id": "10-2020-0146532", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 개시에 따른 시스템은, 일반인도 쉽게 VR 컨텐츠를 저작하고 저작된 VR 컨텐츠를 공유할 수 있는 서비스를 제공한다는 효과가 있다. 본 개시의 일부 실시 예에 따른 시스템은, VR 컨텐츠의 저작 및 공유 환경 내에서 리워드 및/또는 서비스 적합 성을 관리하는 솔루션을 제공한다는 효과가 있다."}
{"patent_id": "10-2020-0146532", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 개시에 대하여 구체적으로 설명하기에 앞서, 본 명세서 및 도면의 기재 방법에 대하여 설명한다. 먼저, 본 명세서 및 청구범위에서 사용되는 용어는 본 개시의 다양한 실시 예들에서의 기능을 고려하여 일반적 인 용어들을 선택하였다. 하지만, 이러한 용어들은 당해 기술 분야에 종사하는 기술자의 의도나 법률적 또는 기 술적 해석 및 새로운 기술의 출현 등에 따라 달라질 수 있다. 또한, 일부 용어는 출원인이 임의로 선정한 용어 도 있다. 이러한 용어에 대해서는 본 명세서에서 정의된 의미로 해석될 수 있으며, 구체적인 용어 정의가 없으 면 본 명세서의 전반적인 내용 및 당해 기술 분야의 통상적인 기술 상식을 토대로 해석될 수도 있다. 또한, 본 명세서에 첨부된 각 도면에 기재된 동일한 참조번호 또는 부호는 실질적으로 동일한 기능을 수행하는 부품 또는 구성요소를 나타낸다. 설명 및 이해의 편의를 위해서 서로 다른 실시 예들에서도 동일한 참조번호 또 는 부호를 사용하여 설명한다. 즉, 복수의 도면에서 동일한 참조 번호를 가지는 구성요소를 모두 도시되어 있다 고 하더라도, 복수의 도면들이 하나의 실시 예를 의미하는 것은 아니다. 또한, 본 명세서 및 청구범위에서는 구성요소들 간의 구별을 위하여 \"제1\", \"제2\" 등과 같이 서수를 포함하는 용어가 사용될 수 있다. 이러한 서수는 동일 또는 유사한 구성요소들을 서로 구별하기 위하여 사용하는 것이며 이러한 서수 사용으로 인하여 용어의 의미가 한정 해석되어서는 안 된다. 일 예로, 이러한 서수와 결합된 구성 요소는 그 숫자에 의해 사용 순서나 배치 순서 등이 제한되어서는 안 된다. 필요에 따라서는, 각 서수들은 서로 교체되어 사용될 수도 있다. 본 명세서에서 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 출원에서, \"포함하다\" 또는 \"구성되다\" 등의 용어는 명세서상에 기재된 특징, 숫자, 단계, 동작, 구성요소, 부품 또는 이 들을 조합한 것이 존재함을 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성 요소, 부품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되어야 한다. 본 개시의 실시 예에서 \"모듈\", \"유닛\", \"부(part)\" 등과 같은 용어는 적어도 하나의 기능이나 동작을 수행하는 구성요소를 지칭하기 위한 용어이며, 이러한 구성요소는 하드웨어 또는 소프트웨어로 구현되거나 하드웨어 및 소프트웨어의 결합으로 구현될 수 있다. 또한, 복수의 \"모듈\", \"유닛\", \"부(part)\" 등은 각각이 개별적인 특정 한 하드웨어로 구현될 필요가 있는 경우를 제외하고는, 적어도 하나의 모듈이나 칩으로 일체화되어 적어도 하나 의 프로세서로 구현될 수 있다. 또한, 본 개시의 실시 예에서, 어떤 부분이 다른 부분과 연결되어 있다고 할 때, 이는 직접적인 연결뿐 아니라, 다른 매체를 통한 간접적인 연결의 경우도 포함한다. 또한, 어떤 부분이 어떤 구성요소를 포함한다는 의미는, 특별히 반대되는 기재가 없는 한 다른 구성요소를 제외하는 것이 아니라 다른 구성요소를 더 포함할 수 있는 것 을 의미한다. 도 1은 본 개시의 일 실시 예에 따른 시스템의 구성을 설명하기 위한 블록도이다. 도 1을 참조하면, VR 컨텐츠의 저작 및 체험을 위한 본 시스템은 사용자 단말, 서버, VR 장치 를 포함할 수 있다. 사용자 단말은 스마트폰, 데스크탑 PC, 태블릿 PC, 노트북 PC 등으로 구현될 수 있으며, 이밖에 다양한 단 말 장치로 구현될 수 있다. 사용자 단말은 하나 이상의 시점(timepoint)에 대한 3D의 VR 영상을 저장할 수 있다. VR 영상은, 각 시점 에 대하여 3D의 가상 공간을 구성하는 하나 이상의 이미지를 포함한다. 사용자 단말은 360도로 촬영을 수행하는 VR 카메라를 포함하는 촬영 장치와 통신을 수행하는 한편, 촬영 장치로부터 촬영된 VR 영상을 수신할 수 있다. 이 밖에, 사용자 단말은 적어도 하나의 외부 장치로부터 VR 영상을 수신할 수 있다. 서버는 적어도 하나의 네트워크를 통해 다양한 전자 장치와 연결될 수 있다. 네트워크는 영역 또는 규모에 따라 개인 통신망(PAN; Personal Area Network), 근거리 통신망(LAN; Local Area Network), 광역 통신망(WAN;Wide Area Network) 등일 수 있으며, 네트워크의 개방성에 따라 인트라넷(Intranet), 엑스트라넷(Extranet), 또는 인터넷(Internet) 등일 수 있다. 서버는 사용자 단말 및 VR 장치와 연결될 수 있으며, 연결된 각 장치에 적어도 하나의 웹 페이 지를 제공할 수 있다. 일 예로, 서버는 HTML 5 형식의 웹 페이지를 제공할 수 있으나 이에 한정되지 않는 다. 사용자 단말 및 VR 장치는 각각 무선 통신 또는 유선 통신을 통해 서버와 통신을 수행할 수 있 다. 이때, 사용자 단말 및 VR 장치는 각각 적어도 하나의 중계 장치를 통해 서버와 연결될 수도 있다. 무선 통신은 LTE(long-term evolution), LTE-A(LTE Advance), 5G(5th Generation) 이동통신, CDMA(code division multiple access), WCDMA(wideband CDMA), UMTS(universal mobile telecommunications system), WiBro(Wireless Broadband), GSM(Global System for Mobile Communications), DMA(Time Division Multiple Access), WiFi(Wi-Fi), WiFi Direct, Bluetooth, NFC(near field communication), Zigbee 등의 통신 방식 중 적어도 하나를 포함할 수 있다. 유선 통신은 이더넷(Ethernet), 광 네트워크(optical network), USB(Universal Serial Bus), 선더볼트 (ThunderBolt) 등의 통신 방식 중 적어도 하나를 포함할 수 있다. 여기서, 통신부는 상술한 유무선 통신 방식에 따른 네트워크 인터페이스(Network Interface) 또는 네트워크 칩을 포함할 수 있다. VR 장치는 사용자에게 VR 영상을 제공하기 위한 기기이다. VR 장치는 VR 영상을 제공할 수 있는 HMD(Head Mounted Device), 스마트 안경, 기타 VR/AR 기기로 구현될 수 있다. 또한, VR 장치는 스마트폰, 태블릿 PC 등으로 구현될 수 있다. 일 예로, 스마트폰인 VR 장치는 자체 구비된 디스플레이의 방향에 맞는 시야각에 따라 3D의 VR 영상을 부분적으로 제공할 수 있다. VR 장치는 개인이 소유한 단말 장치일 수도 있고, 특정 전시장이나 체험관에 비치되어 DID(Digital Information Display) 형태로 이용되는 단말 장치일 수도 있다. VR 장치는 적어도 하나의 다른 디스플레이 장치(TV, 스크린 등)와 동기화될 수 있으며, VR 장치에서 디스플레이 되는 VR 영상의 적어도 일부가 다른 디스플레이 장치에서 디스플레이 될 수 있다. VR 장치는 VR 영상 내에서의 움직임, 시선 방향, 그 밖에 다양한 UI와 관련된 사용자 입력을 수신하는 적 어도 하나의 버튼, 터치 패드, 모션 센서, 카메라, 가속도 센서 등을 포함할 수 있다. 또는, 사용자 입력을 수 신하기 위한 별도의 단말 장치가 VR 장치와 연결되는 것도 가능하다. 도 2는 본 개시의 일 실시 예에 따른 시스템의 서비스 제공 방법을 설명하기 위한 흐름도이다. 도 2를 참조하면, 서버는 VR 컨텐츠의 저작을 위한 웹 페이지를 제공할 수 있다(S210). 이때, 사용자 단말은 서버와 연결되어 웹 페이지를 디스플레이 하고, 웹 페이지와 관련된 사용자 입 력에 대한 정보를 서버로 전송할 수 있다. 구체적인 예로, 사용자 단말 장치는 서버가 제공하는 로그인용 웹 페이지를 디스플레이 할 수 있다. 여기서, 사용자 단말 장치는 사용자 입력에 따라 입력된 ID 및 비밀번호를 서버로 전송할 수 있다. 입력된 ID 및 비밀번호가 회원가입 등을 통해 기등록된 사용자의 정보(ID, 비밀번호)와 일치하는 경우, 서버 는 사용자 단말을 통해 사용자 개인의 VR 컨텐츠를 저작하기 위한 웹 페이지를 제공할 수 있다. 사용자 단말에 수신된 사용자 입력을 통해 VR 컨텐츠가 저작되면, 서버는 저작된 VR 컨텐츠를 사용자 의 VR 컨텐츠로 등록할 수 있다. 한편, 서버는 VR 컨텐츠의 체험을 위한 웹 페이지를 제공할 수 있다(S220). 본 웹 페이지를 통해, 서버는 등록된 적어도 한 명의 사용자의 VR 컨텐츠를 VR 장치에 제공할 수 있 다. 그 결과, VR 장치의 사용자는 VR 컨텐츠를 체험할 수 있다. 구체적으로, VR 장치 역시 로그인 과정을 거쳐 서버의 웹 페이지에 접속할 수 있다. 여기서, VR 장치는, 사용자 입력에 따라, 서버에 등록된 복수의 VR 컨텐츠 중 적어도 하나를 선택할 수 있다.만약, 선택된 VR 컨텐츠가 사용자 단말을 통해 저작된 VR 컨텐츠라면, VR 장치는 서버로부터 해 당 VR 컨텐츠를 수신하고, 수신된 VR 컨텐츠를 사용자에게 제공할 수 있다. 여기서, VR 장치는 사용자 입력에 따라 서버로 결제에 필요한 사용자 정보를 전송함으로써 일정 금액 결제를 수행할 수 있으며, 결제가 수행됨을 전제로 VR 컨텐츠를 서버로부터 제공받을 수도 있다. 이하 도 3 내지 도 9를 통해서는, 서버가 VR 컨텐츠 저작을 위한 웹 페이지를 사용자 단말에 제공하 는 실시 예를 보다 구체적으로 설명한다. 도 3은 본 개시의 일 실시 예에 따른 시스템이 VR 컨텐츠 저작을 위한 웹 페이지를 제공하는 동작을 설명하기 위한 흐름도이다. 도 3은 도 2에서 설명한 S210 과정을 보다 구체화한 것이다. VR 컨텐츠 저작을 위한 웹 페이지를 통해, 서버는 저작을 위한 다양한 UI를 제공할 수 있다. 도 3을 참조하면, 적어도 하나의 프로젝트(project)를 생성하기 위한 사용자 입력이 사용자 단말을 통해 서버로 수신되면, 서버는 프로젝트의 식별 정보 및 위치 정보를 입력 받기 위한 UI(User Interface) 를 제공할 수 있다(S310). 프로젝트는, 하나의 VR 컨텐츠를 저작 및 등록하기 위한 단위로서, 특정 사용자가 하나의 VR 컨텐츠를 저작 및 등록하고자 하는 경우, 하나의 프로젝트 내에서 저작 작업을 수행할 수 있다. 식별 정보는 프로젝트의 제목, 카테고리 등을 포함할 수 있고, 위치 정보는 프로젝트의 VR 컨텐츠가 나타내는 특정 공간 또는 장소의 위치 또는 주소에 대한 정보를 포함할 수 있다. 생성된 프로젝트(VR 컨텐츠)는, 해당 프로젝트를 생성한 사용자의 정보(로그인 정보), 프로젝트의 식별 정보, 프로젝트의 위치 정보 등과 함께 서버 상에 등록될 수 있다. 프로젝트가 생성된 이후, 프로젝트 내에 적어도 하나의 레이어(layer)를 추가하기 위한 사용자 입력이 사용자 단말을 통해 수신되면, 서버는 레이어 상에 적어도 하나의 시점(timepoint)의 VR 영상을 업로드 받기 위한 제2 UI를 제공할 수 있다. 레이어는, 하나의 장면(scene)을 구성하는 VR 영상을 포함하는 단위이다. 프로젝트는, 각각 하나의 장면에 해당 하는 레이어를 하나 이상 포함할 수 있다. 또는, 프로젝트는, 일 주제에 해당하는 플로어(floor)를 하나 이상 포함할 수도 있다. 각 플로어는, 하나의 주 제에 매칭되며, 하나의 주제는 하나 이상의 장면을 포함할 수 있다. 즉, 각 플로어는 하나 이상의 레이어를 포 함할 수 있다. 이 경우, 프로젝트가 생성되면, 서버는 사용자 입력에 따라 플로어를 추가하는 한편 플로어의 제목(주제) 를 입력 받을 수 있다. 그리고, 서버는 추가된 플로어 내에 적어도 하나의 레이어를 추가하기 위한 사용자 입력에 따라 VR 영상을 업로드 받기 위한 UI를 제공할 수 있다. 이렇듯, VR 컨텐츠는 프로젝트, 레이어의 두 단계로 구성되어 저작되거나 또는 프로젝트, 플로어, 레이어의 세 단계로 구성되어 저작될 수 있는 바, 이는 서버가 제공하는 (VR 컨텐츠 저작용) 웹 페이지의 설계 방식에 따라 선택적으로 구현될 수 있다. 레이어 상에 업로드 되는 VR 영상은, VR 카메라를 통해 촬영된 것일 수 있다. 구체적으로, 하나 이상의 시점 (timepoint)에 대하여 기설정된 시야범위(ex. 360도, 3D)에 해당하는 적어도 하나의 이미지를 포함할 수 있다. 일 예로, VR 카메라를 통해 특정 공간을 촬영하는 경우, 해당 공간을 촬영하면서 VR 카메라가 이동함에 따라 각 시점(timepoint) 별로 VR 카메라의 위치가 달라지고, 따라서 각 시점 별로 기설정된 시야범위 내의 이미지가 획 득될 수 있다. 그리고, 획득된 이미지를 포함하는 VR 영상이 생성될 수 있다. 여기서, 생성된 VR 영상은 사용자 단말에 저장될 수 있다. 그리고, VR 컨텐츠 저작용 웹 페이지 상에서 사용자 단말을 통해 수신된 사용자 입력에 따라, 서버는 사용자 단말로부터 해당 VR 영상을 수신하여 적어도 하나의 레이어에 업로드 할 수 있다. 도 4는 본 개시의 일 실시 예에 따른 서버가 프로젝트의 식별 정보 및 위치 정보를 입력 받기 위해 UI를 제공하 는 동작을 설명하기 위한 도면이다. 도 4는 프로젝트를 생성하기 위한 사용자 입력이 수신된 상황에서, 사용자 단말에 디스플레이 되는 서버 의 웹 페이지를 도시한 것이다. 도 4를 참조하면, 서버는 생성될 프로젝트의 식별 정보 및 위치 정보를 입력 받기 위한 UI를 제공할 수 있다. 구체적으로, UI는 프로젝트의 제목, 카테고리, 주소 등에 대한 사용자 입력을 수신하도록 구성될 수 있다. 주소가 입력되면, 서버는 기저장된 맵(ex. 대한민국 지도) 내에서 해당 주소의 위치를 식별할 수 있다. 그 리고, 웹 페이지 상에서, 서버는 해당 위치를 포함하는 맵의 적어도 일부 영역을 나타내는 이미지를 제공 할 수 있다. 또한, UI는 설명, 태그, 공개 유무 등에 대한 사용자 입력을 수신하도록 구성될 수 있다. 공개 유무는, 생성된 프로젝트의 VR 컨텐츠를 다른 사용자(VR 장치)에게 제공할 지 여부를 선택받기 위한 항목 이다. 태그는, 적어도 하나의 키워드와 해당 프로젝트를 연동시키기 위한 항목이다. 태그 항목에 적어도 하나의 키워 드가 입력되면, 서버는 해당 키워드를 프로젝트와 연동시킬 수 있다. 구체적인 예로, 태그 항목에 특정 키워드(ex. ABC 휴양림)가 입력된 상태로 프로젝트가 생성된 경우를 가정한다. 이후, 서버의 (VR 컨텐츠 체험용) 웹 페이지 상에서 VR 장치를 통해 해당 키워드가 검색되면, 서버 는 해당 프로젝트의 식별 정보(ex. 제목) 및 썸네일 등을 VR 장치에 제공함으로써 해당 프로젝트를 추천할 수 있다. 한편, 본 실시 예에서는 프로젝트의 생성이 요청된 직후 상술한 UI가 제공되는 경우만을 설명하였으나, 추 후 UI에 입력된 정보가 수정되거나 또는 적어도 일부 항목(ex. 공개 유무, 태그, 주소 등)에 대한 사용자 입력은 프로젝트가 완성(도 5 내지 도 8 또는 도 5 내지 도 9의 과정이 모두 완료)된 이후 수행될 수도 있다. 한편, 도 5는 본 개시의 일 실시 예에 따른 서버가 레이어에 VR 영상을 업로드 받기 위한 UI를 제공하는 동작을 설명하기 위한 도면이다. 도 5는, 생성된 프로젝트(제목: ABC 휴양림에서의 하루) 내에 적어도 하나의 레이어를 추가하기 위한 사용자 입 력이 수신된 상황에서 서버가 사용자 단말을 통해 제공하는 웹 페이지의 예를 도시한 것이다. 도 5를 참조하면, 서버는 추가된 레이어 내에 VR 영상을 업로드 받기 위한 UI를 제공할 수 있다. 이때, 사용자 단말은 VR 영상을 업로드 하기 위한 사용자 입력이 수신됨에 따라, VR 영상을 서버로 전송할 수 있다. 그리고, 서버는 해당 VR 영상을 추가된 레이어 내에 저장/등록할 수 있다. 도 6은 본 개시의 일 실시 예에 따른 서버가 프로젝트, 플로어, 레이어 기반의 VR 컨텐츠 저작 환경을 제공하는 동작을 설명하기 위한 도면이다. 도 6은 “ABC 휴양림에서의 하루”이라는 제목을 갖는 프로젝트가 생성되고, 프로젝트 내에서 “건물 01” 및 “건물 02”에 해당하는 각 플로어가 추가되었으며, 복수의 장면(scene 1, 2, 3, …)에 해당하는 복수의 레이어 가 추가된 상황을 가정한다. 프로젝트 “ABC 휴양림에서의 하루”의 VR 컨텐츠를 저작하기 위한 도 6의 웹 페이지 상에서, 서버는 플로 어 리스트 UI, 레이어 리스트 UI, 선택된 레이어의 VR 영상을 디스플레이 하는 디스플레이 UI, 디스플레이 되는 VR 영상의 시점 및 시야각을 선택하기 위한 화면 전환 UI, VR 영상의 적어도 일부를 편집 하기 위한 편집 메뉴 UI 등을 제공할 수 있다. 플로어 리스트 UI는 플로어를 추가하기 위한 항목, 그리고 현재 생성된 플로어들을 나타내는 플로어 항목들(610-1, 2)을 포함할 수 있다. 플로어 항목들(610-1, 2)의 위치는 플로어 항목들(610-1, 2)이 제공되는 순서를 나타낸다. 즉, 추후 본 프로젝 트가 VR 장치를 통해 제공되는 경우, 각 플로어에 포함되는 VR 영상들이 플로어의 순서에 따라 제공될 수 있다.서버는 플로어 리스트 UI를 통해 수신된 사용자 입력을 통해 적어도 하나의 플로어의 순서를 변경하 거나 또는 삭제할 수 있다. 구체적으로, 사용자 단말을 통해 수신된 사용자 입력이 플로어 항목(610-1)을 터치 및 드래그하여 플로어 항목(610-2) 아래로 이동시키는 조작인 경우, 서버는 플로어 리스트 UI 내에서 플로어 항목들(610-1, 2)의 위치(순서)를 바꿀 수 있다. 레이어 리스트 UI는 현재 선택된 플로어(610-1)에 포함된 레이어들을 나타내는 레이어 항목들(620-1, 2, 3, 4, 5, …), 그리고 레이어를 추가하기 위한 항목을 포함할 수 있다. 레이어 항목들(620-1, 2, 3, 4, 5, …)의 위치는 레이어 항목들(610-1, 2, 3, 4, 5, …)이 제공되는 순서를 나 타낸다. 즉, 추후 본 프로젝트가 VR 장치를 통해 제공되는 경우, 각 레이어에 포함되는 VR 영상이 레이어 의 순서에 따라 제공될 수 있다. 서버는 레이어 리스트 UI를 통해 수신된 사용자 입력을 통해 적어도 하나의 레이어의 순서를 변경하 거나 또는 삭제할 수 있다. 구체적으로, 사용자 단말을 통해 수신된 사용자 입력이 레이어 항목(620-1)을 터치 및 드래그하여 레이어 항목(620-2) 우측으로 이동시키는 조작인 경우, 서버는 레이어 리스트 UI 내에서 레이어 항목들(620- 1, 2)의 위치(순서)를 바꿀 수 있다. 디스플레이 UI는 현재 선택된 레이어(620-1)에 포함되는 VR 영상을 디스플레이 할 수 있다. 여기서, 화면 전환 UI는 디스플레이 UI 내에 디스플레이 되는 VR 영상의 시점(timepoint) 및 시야각 을 설정하기 위한 복수의 메뉴 항목을 제공할 수 있다. 구체적으로, 화면 전환 UI 내에서 “이전” 항목이 선택되는 경우, 현재 디스플레이 UI에 나타난 VR 이미지의 직전 시점에 촬영된 VR 이미지가 디스플레이 될 수 있다. 반대로, 화면 전환 UI 내에서 “다음” 항목이 선택되는 경우, 현재 디스플레이 UI에 나타난 VR 이미지의 다음 시점에 촬영된 VR 이미지가 디스플 레이 될 수 있다. 또한, 화면 전환 UI 내에서 각각 상하좌우를 가리키는 화살표들 중 적어도 하나가 선택됨에 따라, 현재 디 스플레이 UI에 나타난 VR 이미지와 동일한 시점에 촬영되었지만 시야각이 다른 VR 이미지가 디스플레이 될 수 있다. 구체적으로, 디스플레이 UI 내에 특정한 VR 이미지가 디스플레이 된 상태에서, 좌측을 가리키는 화살표가 선택되는 경우, 동일한 시점에 촬영되었지만 시야각이 조금 더 좌측에 해당하는 VR 이미지가 제공될 수 있다. 이때, 좌측을 가리키는 화살표가 한 번 더 선택된다면, 역시 동일한 시점에 촬영되었지만 시야각이 추가로 더 좌측에 해당하는 VR 이미지가 제공될 수 있다. 또한, 화면 전환 UI는 디스플레이 UI 내에 표시되는 VR 이미지의 시야범위를 확대 또는 축소하기 위 한 적어도 하나의 항목(ex. (+), (-))을 제공할 수도 있다. 편집 메뉴 UI는 현재 선택된 레이어(620-1)의 VR 영상을 편집하기 위한 다양한 툴에 해당하는 메뉴 항목들 을 제공한다. 편집 메뉴 UI를 통한 VR 영상의 편집은, 레이어에 포함되는 VR 영상 전체를 대상으로 수행될 수도 있고 및 /또는 레이어에 포함되는 VR 영상 중 디스플레이 UI에 표시되고 있는 VR 이미지를 대상으로만 수행될 수도 있다. 구체적으로, 편집 메뉴 UI의 컬러 항목이 선택되는 경우, VR 영상의 컬러를 조정하기 위한 툴(UI)이 제공 될 수 있다. 편집 메뉴 UI의 사운드 항목이 선택되는 경우, VR 영상에 포함되는 사운드의 유무 또는 볼륨 등을 조정하 기 위한 툴(UI)이 제공될 수 있다. 편집 메뉴 UI의 효과 항목이 선택되는 경우, VR 영상에 대한 다양한 효과(애니메이션 효과, 강조 표시 등)를 추가/조정하기 위한 툴(UI)이 제공될 수 있다. 편집 메뉴 UI의 부가 정보 항목이 선택되는 경우, VR 영상에 다양한 부가 정보를 추가하기 위한 툴(UI) 제 공될 수 있다. 관련하여, 도 7은 본 개시의 일 실시 예에 따른 서버가 VR 영상에 부가 정보를 추가하는 동작을 설명하기 위한 도면이다. 도 7은 도 6에서 부가 정보 항목이 선택된 상황을 가정한다. 도 7을 참조하면, 부가 정보 항목이 선택됨에 따라, 다양한 부가 정보를 입력하기 위한 부가 정보 UI가 제 공될 수 있다. 부가 정보 UI는 텍스트 입력, 이미지 추가, 사운드 추가, 동영상 추가 등의 항목을 포함할 수 있다. 부가 정보 UI와 관련하여 사용자 단말을 통해 수신된 사용자 입력을 기반으로, 서버는 웹 페이 지 상에서 현재 선택된 레이어의 VR 영상과 부가 정보(텍스트, 이미지, 사운드, 동영상 등)를 함께 제공할 수 있다. 구체적으로, VR 영상 중 특정한 시점 및 특정한 시야각에 해당하는 VR 이미지가 디스플레이 UI에 디스플레 이 된 상태에서, 적어도 하나의 부가 정보를 추가하기 위한 사용자 입력이 수신되는 경우, 서버는 해당 VR 이미지와 함께 부가 정보를 제공하도록 설정할 수 있다. 일 예로, 텍스트 입력이 선택된 경우, 서버는 도 8과 같이 텍스트를 입력 받기 위한 UI를 제공할 수 있다. 이때, UI를 통해 텍스트가 입력되면, 서버는 입력된 텍스트가 현재 디스플레이 UI에 디스플레이 되고 있는 VR 이미지(: 특정 시점 및 시야각에 대응됨)와 함께 제공되도록 설정할 수 있다. 그 결과, 추후 상술한 프로젝트의 VR 컨텐츠를 서버로부터 제공받는 VR 장치가, 부가 정보(ex. 텍스 트)가 추가된 특정한 시점 및 특정한 시야각에 해당하는 VR 이미지를 제공받게 되는 경우, 부가 정보(ex. 텍스 트)가 VR 이미지와 함께 제공될 수 있다. 즉, VR 장치의 사용자가 해당 시점 및 해당 시야각에 해당하는 VR 이미지를 바라보게 되는 순간, VR 장치 는 텍스트를 추가로 제공하게 된다. 일 예로, 사용자 단말의 사용자는 업로드 된 VR 영상 내에서 특정한 대상(ex. 진귀한 고목)을 포함하는 VR 이미지(특정한 시점 및 시야각에 대응됨) 상에 텍스트(ex. 고목에 대한 설명)를 추가할 수 있다. 그 결과, 추후 해당 VR 영상을 제공받는 VR 장치의 사용자는 VR 영상을 체험하던 중 해당 대상(ex. 진귀한 고목)을 바라 보는 동시에 텍스트(ex. 고목에 대한 설명)를 제공받을 수 있게 된다. 일 예로, 사용자 단말의 사용자는 업로드 된 VR 영상 내에서 특정한 대상(ex. 인물 사진 액자)을 포함하는 VR 이미지(특정한 시점 및 시야각에 대응됨) 상에 동영상(ex. 인물의 인터뷰 영상)을 추가할 수 있다. 그 결과, 추후 해당 VR 영상을 제공받는 VR 장치의 사용자는 VR 영상을 체험하던 중 해당 대상(ex. 인물 사진 액 자)을 바라보는 동시에 동영상(ex. 인물의 인터뷰 영상)을 제공받을 수 있게 된다. 일 예로, 사용자 단말의 사용자는 업로드 된 VR 영상 내에서 특정한 대상(ex. 휴양림 입구)을 포함하는 VR 이미지(특정한 시점 및 시야각에 대응됨) 상에 사운드(ex. 휴양림을 소개하는 음성)를 추가할 수 있다. 그 결과, 추후 해당 VR 영상을 제공받는 VR 장치의 사용자는 VR 영상을 체험하던 중 해당 대상(ex. 휴양림 입 구)을 바라보는 동시에 동영상(ex. 휴양림을 소개하는 음성)을 제공받을 수 있다. 한편, 서버는 사용자 단말을 통해 수신된 사용자 입력을 기반으로, 상술한 디스플레이 UI 내에 레이어들을 연결하는 노드를 시각화 할 수도 있다. 관련하여, 도 9는 본 개시의 일 실시 예에 따른 서버가 레이어들을 연결하는 노드를 시각화 하는 동작을 설명하 기 위한 도면이다. 도 9는, 프로젝트의 제목(ex. ABC 휴양림에서의 하루)이 특정 공간(ex. ABC 휴양림)과 관련되고, 현재 선택된 플로어가 해당 공간(ex. ABC 휴양림) 내의 특정한 건물(ex. 건물 01)을 나타내고, 플로어 내 레이어들은 각각 해당 건물(ex. 건물 01) 내의 부분 공간들(ex. 방, 거실, 화장실 등)에 대한 VR 영상을 포함하는 상황을 가정한 다. 이 경우, 사용자 단말을 통해 수신된 사용자 입력을 기반으로, 서버는 현재 선택된 레이어의 VR 영상 을 디스플레이 하는 디스플레이 UI 상에, 각 부분 공간들(레이어) 간의 위치 관계에 따른 노드를 추가할수 있다. 도 9에서, 추가된 노드들의 번호는 레이어들의 번호(순서)에 매칭된다. 일 예로, 노드를 추가한 뒤 각 노드를 터치 및 드래그하는 사용자 입력이 수신됨에 따라, VR 영상 내에서 각 노 드의 위치(특정한 시점, 시야각)가 변경될 수 있다. 추후, 서버가 도 9의 프로젝트를 VR 장치에 제공하는 경우, VR 장치의 사용자가 노드가 위치한 지점을 포함하는 VR 이미지(특정 시점 및 특정 시야각)를 바라보게 된다면, 서버는 VR 장치를 통해 (기존에 보이지 않던) 노드를 시각화할 수 있고, VR 장치의 사용자가 해당 노드를 선택하면, 레이어가 전 환되면서 선택된 노드에 매칭되는 레이어(부분 공간)의 VR 영상이 제공될 수 있다. 이를 통해, VR 장치의 사용자는 부분 공간들 간의 위치 관계에 따라 직관적으로 부분 공간들 사이를 빠르 게 이동하면서 체험할 수 있다는 효과가 있다. 한편, 이하에서는, 서버가 저작된 VR 컨텐츠를 VR 장치를 통해 제공하는 실시 예들을 설명한다. 일 실시 예에 따라, 앞서 사용자 단말에 수신된 사용자 입력을 통해 생성된 프로젝트(VR 컨텐츠)를 선택하 는 사용자 입력이 VR 장치를 통해 수신되면, 서버는 해당 프로젝트 내의 적어도 하나의 레이어에 포 함된 VR 장치로 제공할 수 있다. 그 결과, VR 장치의 사용자는 다른 사용자가 저작한 VR 컨텐츠를 선택적으로 체험할 수 있다. 한편, 도 10은 본 개시의 일 실시 예에 따른 서버가 VR 컨텐츠의 체험을 위한 웹 페이지를 제공하는 예를 설명 하기 위한 도면이다. 도 10은, VR 장치가 3D 영상을 제공하기 위한 VR 기기가 아니라, 스마트폰 또는 데스크탑 PC 등으로 구현 된 경우를 가정한 것이다. 도 10을 참조하면, 서버가 VR 장치에 제공하는 웹 페이지는, 선택된 VR 컨텐츠가 디스플레이 되는 디 스플레이 UI, 디스플레이 UI에 디스플레이 되는 VR 영상의 시점 및 시야각을 선택하기 위한 화면 전환 UI, 선택된 VR 컨텐츠에 대한 다른 사용자들의 코멘트 및 호감도를 나타내는 평가 정보 UI, 적어도 하나의 다른 VR 컨텐츠를 추천하는 추천 리스트 UI 등을 포함할 수 있다. 서버는 VR 장치를 통해 수신되는 화면 전환 UI에 대한 사용자 입력에 따라 선택된 시점, 시야 각, 시야범위를 기반으로, 디스플레이 UI 내의 VR 영상을 디스플레이 할 수 있다. 한편, 서버는 추천 리스트 UI 내에 포함될 VR 컨텐츠를 다양한 방식에 따라 선택하여 추천할 수 있 다. 일 실시 예로, 서버는 VR 장치의 위치 정보를 식별하고, 식별된 위치 정보와 매칭되는 적어도 하나의 프로젝트를 추천 리스트 UI를 통해 추천할 수 있다. 이때, 서버는 VR 장치의 GPS(Global Positioning System) 정보에 따라 VR 장치의 위치를 식별 할 수 있다. 또는, 서버는 VR 장치와 연결된 적어도 하나의 중계 장치의 위치 정보에 따라 VR 장치 의 위치를 식별할 수 있다. 또는, 서버는 VR 장치의 사용자의 정보(ex. 서비스의 회원가입 시 수집 가능)에 따라 사용자의 주소를 식별하고, 해당 주소를 VR 장치의 위치로 식별할 수 있다. 여기서, 서버는 서버에 등록된 복수의 프로젝트 중 상술한 주소 정보가 VR 장치의 위치와 가장 가까운 프로젝트를 적어도 하나 식별하고, 식별된 프로젝트(VR 컨텐츠)를 추천할 수 있다. 다른 실시 예로, 서버는 입력된 VR 영상의 속성과 관련된 복수의 파라미터의 값을 출력하도록 훈련된 인공 지능 모델을 포함할 수 있다. 복수의 파라미터는, VR 컨텐츠의 저작 및 체험을 위하여 서버가 제공하는 서비스가 무엇을 대상으로 하는 VR 컨텐츠에 관한 것인지에 따라 다르게 설정될 수 있다. 일 예로, 서버가 여행지 또는 휴양림 등의 가상 체험을 위한 VR 컨텐츠의 저작 및 체험에 대한 서비스를 제공하는 경우를 가정할 수 있다. 이 경우, 복수의 파라미터는, RGB 컬러 각각의 비율 및 밝기, VR 영상 내 기설정된 객체(ex. 나무, 숲, 하늘)의 출현 빈도, 기설정된 객체(ex. 풀장, 계곡, 바비큐장 등)의 포함 여부 등을 포함할 수 있다. 서버는 서버에 등록된 복수의 프로젝트 각각에 포함된 VR 영상을 해당 인공지능 모델에 입력하여, 복 수의 프로젝트 각각에 대한 복수의 파라미터의 값을 획득할 수 있다. 그리고, 서버는 획득된 복수의 파라미터의 값을 기반으로, 등록된 복수의 프로젝트 중 선택된 프로젝트와 매칭되는 프로젝트를 추천할 수 있다. 구체적으로, 서버는 복수의 파라미터의 값을 비교한 결과 현재 선택된 프로젝트와 가장 유사한 적어도 하 나의 프로젝트를 추천할 수 있다. 한편, 서버는 각 프로젝트의 조회수에 따라 각 프로젝트를 저작한 사용자에 대한 리워드를 산출할 수 있다. 구체적으로, 서버는 서버에 등록된 복수의 프로젝트 중 특정한 하나의 장소에 태깅된 적어도 하나의 프로젝트 각각의 조회수를 기반으로, 해당 장소에 태깅된 적어도 하나의 프로젝트 각각을 위한 리워드를 산출할 수 있다. 일 예로, 국립 휴양림에 대한 VR 컨텐츠의 저작 및 체험 서비스가 제공되는 경우, 각 휴양림 별로 기설정된 수 치의 리워드가 이미 배정되어 있을 수 있다. 이 경우, 서버는 특정한 하나의 휴양림에 태깅된 프로젝트들이 해당 휴양림에 배정된 리워드를 조회수에 따라 나누는 형태로(조회수가 많을수록 리워드가 커짐), 각 프로젝트를 저작한 사용자에 대한 리워드를 산출할 수 있다. 그 결과, 예측 가능한 비용 범위 내에서 국립 휴양림에 대한 VR 기반의 홍보 내지는 체험이 활성화되는 상황이 기대될 수 있다. 한편, 상술한 시스템은, 사용자 단말, 서버, VR 장치 외에 관리자 장치를 더 포함할 수 있다. 관리자 장치는 다양한 사용자 단말(사용자)에 의해 저작된 VR 컨텐츠의 태깅을 관리하기 위한 장치이다. 관리자 장치는 적어도 하나의 단말 또는 서버로 구현될 수 있다. 일 예로, 시스템이 제공하는 서비스가 국립 휴양림에 대한 VR 컨텐츠 저작 및 체험인 경우, 관리자 장치 는 국립 휴양림의 관리 단체의 서버 또는 관리자의 단말에 해당할 수 있다. 관련하여, 도 11은 본 개시의 일 실시 예에 따른 시스템이 관리자 장치의 승낙을 기반으로 각 장소에 VR 영상을 태깅하는 동작을 설명하기 위한 블록도이다. 앞서 도 4를 통해 설명하였듯, 서버는 저작 과정에서 수신된 사용자 입력에 따라 각 프로젝트에 태그 되는 키워드를 입력 받을 수 있다. 다만, 시스템이 제공하는 서비스가 국립 휴양림에 대한 VR 컨텐츠 저작 및 체험인 경우 등에 있어서는, 각 프로젝트에 대한 검증이 선행됨을 전제로 각 휴양림(키워드)에 대한 태깅이 수행될 필요가 있다. 특정 휴양림과 전혀 무관하거나 유해한 VR 컨텐츠가 해당 휴양림에 태깅되는 경우, 서비스의 본 목적을 흐릴 수 있기 때문이다. 관련하여, 도 11을 참조하면, 사용자 단말은 서버에 프로젝트의 특정 키워드(ex. ABC 휴양림)에 대한 태깅을 요청할 수 있다(S1110). 일 예로, 사용자 단말을 통해, 저작된 프로젝트에 특정 키워드(ex. ABC 휴양림)를 태그하기 위한 사용자 입력이 수신될 수 있다. 이 경우, 서버는 해당 프로젝트의 VR 영상을 관리자 장치로 전송할 수 있다(S1120). 여기서, 관리자 장치는 ABC 휴양림의 관리 단체의 서버 또는 관계자의 단말일 수 있다. 구체적으로, 서버는 해당 프로젝트 내에 적어도 하나의 VR 영상이 업로드 되면, 업로드 된 VR 영상을 관리 자 장치로 전송할 수 있다. 여기서, 관리자 장치는 VR 영상을 기반으로 태깅의 승낙 여부를 결정할 수 있다. 일 예로, 관리자 장치를 통해 VR 영상을 직접 접한 관리자의 입력에 따라 승낙 여부가 결정될 수 있다. 다른 예로, 관리자 장치는 VR 영상과 키워드(ex. ABC 휴양림) 간의 관련성 및 유해성을 분석하도록 훈련된 적어도 하나의 인공지능 모델을 이용하여 승낙 여부를 결정할 수도 있다. 이때, 인공지능 모델은, 키워드(ex. ABC 휴양림)와 관련된 복수의 이미지(ex. ABC 휴양림의 이미지들)를 통해 훈련됨으로써, 입력된 이미지가 해당 키워드와 매칭되는지 여부를 판단하도록 훈련된 적어도 하나의 인공지능 모델을 포함할 수 있다. 또한, 인공지능 모델은, 유해한 내용을 담은 복수의 이미지 및/또는 건전한 내용만을 담은 복수의 이미지를 기 반으로 훈련됨으로써, 입력된 이미지가 유해한지(ex. 선정성, 폭력성 등) 여부를 판단하도록 훈련된 적어도 하 나의 인공지능 포함할 수 있다. 만약, 관리자 장치가 태깅을 승낙하는 것으로 결정한 경우, 관리자 장치는 태깅의 승낙을 알리는 정 보를 서버로 전송할 수 있다(S1130). 그 결과, 사용자 입력에 따라 해당 키워드(ex. ABC 휴양림)를 검색한 VR 장치는 서버로부터 상술한 프로젝트(VR 컨텐츠)를 제공받을 수 있게 된다(S1140). 반면, 관리자 장치가 태깅을 승낙하지 않는 것으로 결정한 경우, 관리자 장치는 서버로 태깅의 거절을 알리는 정보를 서버로 전송할 수 있다. 이 경우, 서버는 태그된 키워드의 변경/삭제 또는 VR 영상의 변경을 요청하는 정보(ex. 푸쉬 알림)를 사용 자 단말을 통해 사용자에게 제공할 수 있다. 또는, VR 영상이 유해한 것으로 식별된 경우, 서버는 프로젝트의 삭제를 요청하는 정보 및/또는 사용자에 대한 경고를 담은 정보를 사용자 단말을 통해 사용자에게 제공할 수 있다. 한편, 이상에서 설명된 다양한 실시 예들은 소프트웨어(software), 하드웨어(hardware) 또는 이들의 조합된 것 을 이용하여 컴퓨터(computer) 또는 이와 유사한 장치로 읽을 수 있는 기록 매체 내에서 구현될 수 있다. 하드웨어적인 구현에 의하면, 본 개시에서 설명되는 실시 예들은 ASICs(Application Specific Integrated Circuits), DSPs(digital signal processors), DSPDs(digital signal processing devices), PLDs(programmable logic devices), FPGAs(field programmable gate arrays), 프로세서(processors), 제어기 (controllers), 마이크로 컨트롤러(micro-controllers), 마이크로 프로세서(microprocessors), 기타 기능 수행 을 위한 전기적인 유닛(unit) 중 적어도 하나를 이용하여 구현될 수 있다. 일부의 경우에 본 명세서에서 설명되는 실시 예들이 프로세서 자체로 구현될 수 있다. 소프트웨어적인 구현에 의하면, 본 명세서에서 설명되는 절차 및 기능과 같은 실시 예들은 별도의 소프트웨어 모듈들로 구현될 수 있다. 상술한 소프트웨어 모듈들 각각은 본 명세서에서 설명되는 하나 이상의 기능 및 작동을 수행할 수 있다. 한편, 상술한 본 개시의 다양한 실시 예들에 따른 사용자 단말, 서버, VR 장치 등에서의 처리동 작을 수행하기 위한 컴퓨터 명령어(computer instructions)는 비일시적 컴퓨터 판독 가능 매체(non-transitory computer-readable medium)에 저장될 수 있다. 이러한 비일시적 컴퓨터 판독 가능 매체에 저장된 컴퓨터 명령어 는 특정 기기의 프로세서에 의해 실행되었을 때 상술한 다양한 실시 예에 따른 처리 동작을 상술한 특정 기기들 이 수행하도록 한다. 비일시적 컴퓨터 판독 가능 매체란 레지스터, 캐쉬, 메모리 등과 같이 짧은 순간 동안 데이터를 저장하는 매체 가 아니라 반영구적으로 데이터를 저장하며, 기기에 의해 판독(reading)이 가능한 매체를 의미한다. 비일시적 컴퓨터 판독 가능 매체의 구체적인 예로는, CD, DVD, 하드 디스크, 블루레이 디스크, USB, 메모리카드, ROM 등 이 있을 수 있다. 이상에서는 본 개시의 바람직한 실시 예에 대하여 도시하고 설명하였지만, 본 개시는 상술한 특정의 실시 예에"}
{"patent_id": "10-2020-0146532", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "한정되지 아니하며, 청구범위에서 청구하는 본 개시의 요지를 벗어남이 없이 당해 개시에 속하는 기술분야에서 통상의 지식을 가진자에 의해 다양한 변형실시가 가능한 것은 물론이고, 이러한 변형실시들은 본 개시의 기술적 사상이나 전망으로부터 개별적으로 이해되어서는 안될 것이다."}
{"patent_id": "10-2020-0146532", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 개시의 일 실시 예에 따른 시스템의 구성을 설명하기 위한 블록도, 도 2는 본 개시의 일 실시 예에 따른 시스템의 서비스 제공 방법을 설명하기 위한 흐름도, 도 3은 본 개시의 일 실시 예에 따른 시스템이 VR 컨텐츠 저작을 위한 웹 페이지를 제공하는 동작을 설명하기 위한 흐름도, 도 4는 본 개시의 일 실시 예에 따른 서버가 프로젝트의 식별 정보 및 위치 정보를 입력 받기 위해 UI를 제공하 는 동작을 설명하기 위한 도면, 도 5는 본 개시의 일 실시 예에 따른 서버가 레이어에 VR 영상을 업로드 받기 위한 UI를 제공하는 동작을 설명 하기 위한 도면, 도 6은 본 개시의 일 실시 예에 따른 서버가 프로젝트, 플로어, 레이어 기반의 VR 컨텐츠 저작 환경을 제공하는 동작을 설명하기 위한 도면, 도 7은 본 개시의 일 실시 예에 따른 서버가 VR 영상에 부가 정보를 추가하는 동작을 설명하기 위한 도면, 도 8은 본 개시의 일 실시 예에 따른 서버가 VR 영상에 텍스트를 추가하기 위한 UI를 제공하는 동작을 설명하기 위한 도면, 도 9는 본 개시의 일 실시 예에 따른 서버가 레이어들을 연결하는 노드를 시각화 하는 동작을 설명하기 위한 도 면, 도 10은 본 개시의 일 실시 예에 따른 서버가 VR 컨텐츠의 체험을 위한 웹 페이지를 제공하는 예를 설명하기 위한 도면, 그리고 도 11은 본 개시의 일 실시 예에 따른 시스템이 관리자 장치의 승낙을 기반으로 각 장소에 VR 영상을 태깅하는 동작을 설명하기 위한 블록도이다."}
