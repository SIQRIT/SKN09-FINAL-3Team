{"patent_id": "10-2019-0139692", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2021-0053722", "출원번호": "10-2019-0139692", "발명의 명칭": "전자장치 및 그 제어방법", "출원인": "삼성전자주식회사", "발명자": "권재성"}}
{"patent_id": "10-2019-0139692", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "전자장치에 있어서,마이크로폰으로 입력되는 복수의 제1사용자 음성에 대응하는 동작을 수행하고,상기 복수의 제1사용자 음성을 발화 특성에 따라 분류한 복수의 음성 그룹 중 사용자에 대응하는 음성 그룹을식별하고,상기 식별된 음성 그룹의 발화 특성에 기초하여, 상기 마이크로폰으로 입력되는 제2사용자 음성에 대한 상기 사용자의 화자 인식을 수행하는 프로세서를 포함하는 전자장치."}
{"patent_id": "10-2019-0139692", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 프로세서는, 상기 식별된 음성 그룹의 발화 특성에 기초하여 화자 모델을 생성하고,상기 생성된 화자 모델에 기초하여 상기 복수의 제1사용자 음성에 대한 인식을 수행하여 상기 생성된 화자 모델을 보정하고,상기 보정된 화자 모델에 기초하여 상기 사용자의 화자 인식을 수행하는 전자장치."}
{"patent_id": "10-2019-0139692", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 프로세서는, 상기 복수의 음성 그룹 중에서 상기 제1사용자 음성의 데이터가 가장 많은 음성 그룹을 상기사용자에 대응하는 음성 그룹으로 식별하는 전자장치."}
{"patent_id": "10-2019-0139692", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,상기 발화 특성은, 상기 입력되는 복수의 제1사용자 음성의 톤, 세기, 및 빠르기 중 적어도 하나를 포함하는 전자장치."}
{"patent_id": "10-2019-0139692", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제2항에 있어서,상기 프로세서는, 상기 복수의 제1사용자 음성 중 상기 생성된 화자 모델과의 유사도가 임계값 이상인 제1사용자 음성에 기초하여 상기 생성된 화자 모델을 보정하는 전자장치."}
{"patent_id": "10-2019-0139692", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제2항에 있어서,상기 프로세서는,상기 사용자에 대응하는 화자 모델이 생성되어 있는지 여부를 식별하고,상기 화자 모델이 생성되어 있지 않은 경우, 상기 화자 모델을 생성하는 전자장치."}
{"patent_id": "10-2019-0139692", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "공개특허 10-2021-0053722-3-제2항에 있어서,상기 프로세서는, 상기 사용자에 대하여 복수의 상기 화자 모델을 생성하고,상기 복수의 화자 모델 간의 발화 특성의 유사도를 식별하고,상기 복수의 화자 모델 중 상기 유사도가 임계값 이상인 2이상의 화자 모델을 병합하는 전자장치."}
{"patent_id": "10-2019-0139692", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "전자장치의 제어방법에 있어서,마이크로폰으로 입력되는 복수의 제1사용자 음성에 대응하는 동작을 수행하는 단계;상기 복수의 제1사용자 음성을 발화 특성에 따라 분류한 복수의 음성 그룹 중 사용자에 대응하는 음성 그룹을식별하는 단계; 및상기 식별된 음성 그룹의 발화 특성에 기초하여, 상기 마이크로폰으로 입력되는 제2사용자 음성에 대한 상기 사용자의 화자 인식을 수행하는 단계를 포함하는 전자장치의 제어방법."}
{"patent_id": "10-2019-0139692", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서,상기 사용자의 화자 인식을 수행하는 단계는, 상기 식별된 음성 그룹의 발화 특성에 기초하여 화자 모델을 생성하는 단계;상기 생성된 화자 모델에 기초하여 상기 복수의 제1사용자 음성에 대한 인식을 수행하여 상기 생성된 화자 모델을 보정하는 단계; 및상기 보정된 화자 모델에 기초하여 상기 사용자의 화자 인식을 수행하는 단계를 포함하는 전자장치의 제어방법."}
{"patent_id": "10-2019-0139692", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제8항에 있어서,상기 음성그룹을 식별하는 단계는, 상기 복수의 음성 그룹 중에서 상기 제1사용자 음성의 데이터가 가장 많은음성 그룹을 상기 사용자에 대응하는 음성 그룹으로 식별하는 단계를 포함하는 전자장치의 제어방법."}
{"patent_id": "10-2019-0139692", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제8항에 있어서,상기 발화 특성은, 상기 입력되는 복수의 제1사용자 음성의 톤, 세기, 및 빠르기 중 적어도 하나를 포함하는 전자장치의 제어방법."}
{"patent_id": "10-2019-0139692", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제9항에 있어서,상기 생성된 화자 모델을 보정하는 단계는,상기 복수의 제1사용자 음성 중 상기 생성된 화자 모델과의 유사도가 임계값 이상인 제1사용자 음성에 기초하여상기 생성된 화자 모델을 보정하는 단계를 포함하는 전자장치의 제어방법."}
{"patent_id": "10-2019-0139692", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제9항에 있어서,상기 화자 모델을 생성하는 단계는,상기 사용자에 대응하는 화자 모델이 생성되어 있는지 여부를 식별하는 단계;공개특허 10-2021-0053722-4-상기 화자 모델이 생성되어 있지 않은 경우, 상기 화자 모델을 생성하는 단계를 포함하는 전자장치의 제어방법."}
{"patent_id": "10-2019-0139692", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제9항에 있어서, 상기 화자 모델을 보정하는 단계는,상기 사용자에 대하여 복수의 상기 화자 모델을 생성하는 단계;상기 복수의 화자 모델 간의 발화 특성의 유사도를 식별하는 단계; 및상기 복수의 화자 모델 중 상기 유사도가 임계값 이상인 2이상의 화자 모델을 병합하는 단계를 포함하는 전자장치의 제어방법."}
{"patent_id": "10-2019-0139692", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "컴퓨터가 읽을 수 있는 코드로서, 전자장치의 제어방법을 수행하는 코드를 포함하는 컴퓨터 프로그램이 저장된기록매체에 있어서, 상기 전자장치의 제어방법은, 마이크로폰으로 입력되는 복수의 제1사용자 음성에 대응하는 동작을 수행하는 단계;상기 복수의 제1사용자 음성을 발화 특성에 따라 분류한 복수의 음성 그룹 중 사용자에 대응하는 음성 그룹을식별하는 단계; 및상기 식별된 음성 그룹의 발화 특성에 기초하여, 상기 마이크로폰으로 입력되는 제2사용자 음성에 대한 상기 사용자의 화자 인식을 수행하는 단계를 포함하는 것을 특징으로 하는 컴퓨터가 읽을 수 있는 프로그램이 기록된기록매체."}
{"patent_id": "10-2019-0139692", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명의 일 실시예에 따른 전자장치에 있어서, 마이크로폰으로 입력되는 복수의 제1사용자 음성에 대한 인식을 수행하여 상기 각 사용자 음성에 대응하는 동작을 수행하고, 상기 복수의 제1사용자 음성을 발화 특성 별로 분류 한 복수의 음성 그룹을 획득하고, 상기 획득된 복수의 음성 그룹 중 사용자에 대응하는 음성 그룹을 선택하고, 상기 선택된 음성 그룹의 발화 특성에 기초하여, 마이크로폰으로 입력되는 제2사용자 음성에 대한 상기 사용자의 화자 인식을 수행하는 프로세서를 포함할 수 있다."}
{"patent_id": "10-2019-0139692", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 사용자의 발화를 통해 화자인식 기능을 제공하는 전자장치 및 그 제어방법에 관한 것이다."}
{"patent_id": "10-2019-0139692", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "화자(사용자)인식은 전자장치에 입력된 사용자의 발화를 통해 사용자가 전자장치의 정당한 사용자가 맞는지를 인식하는 것으로, 화자인식은 사용자의 발화를 등록하여 화자 모델을 생성하는 화자등록과정과, 화자등록과정에 서 생성한 화자 모델과 발화를 비교하여 등록한 화자의 여부를 확인하는 화자인식과정으로 진행된다. 화자등록 과정에서는 화자인식대상 발화어와 유사하거나 비슷한 문장을 사용자에게 보여주어 사용자가 그 문장을 발화하 도록 하고, 전자장치는 발화한 음성데이터로 개별 화자 모델을 생성한다. 화자인식과정에서는 사용자의 화자인 식 발화를 검출하여, 그 발화를 등록한 화자 모델과 비교하여 화자인식을 수행한다."}
{"patent_id": "10-2019-0139692", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명의 목적은, 보다 효과적으로 화자인식을 수행할 수 있는 전자장치 및 그 제어방법을 제공하는 것이다."}
{"patent_id": "10-2019-0139692", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 일 실시예에 따른 전자장치에 있어서, 마이크로폰으로 입력되는 복수의 제1사용자 음성에 대한 인식 을 수행하여 상기 각 사용자 음성에 대응하는 동작을 수행하고, 상기 복수의 제1사용자 음성을 발화 특성 별로 분류한 복수의 음성 그룹을 획득하고, 상기 획득된 복수의 음성 그룹 중 사용자에 대응하는 음성 그룹을 선택하 고, 상기 선택된 음성 그룹의 발화 특성에 기초하여, 마이크로폰으로 입력되는 제2사용자 음성에 대한 상기 사 용자의 화자 인식을 수행하는 프로세서를 포함할 수 있다. 상기 프로세서는, 상기 선택된 음성 그룹의 발화 특성에 기초하여 화자 모델을 생성하고, 상기 생성된 화자 모 델에 기초하여 상기 복수의 제1사용자 음성에 대한 인식을 수행하여 상기 생성된 화자 모델을 보정하고, 상기보정된 화자 모델에 기초하여 상기 사용자의 화자 인식을 수행할 수 있다. 상기 프로세서는, 상기 복수의 음성 그룹 중에서 상기 제1사용자 음성의 데이터가 가장 많은 음성 그룹을 상기 사용자에 대응하는 음성 그룹으로 선택할 수 있다. 상기 발화 특성은, 상기 입력되는 복수의 제1사용자 음성의 톤, 세기, 및 빠르기 중 적어도 하나를 포함할 수 있다. 상기 프로세서는, 상기 복수의 제1사용자 음성 중 상기 생성된 화자 모델과의 유사도가 임계값 이상인 제1사용 자 음성에 기초하여 상기 생성된 화자 모델을 보정할 수 있다. 상기 프로세서는, 상기 사용자에 대응하는 화자 모델이 생성되어 있는지 여부를 식별하고, 상기 화자 모델이 생 성되어 있지 않은 경우, 상기 화자 모델을 생성할 수 있다. 상기 프로세서는, 상기 사용자에 대하여 복수의 상기 화자 모델을 생성하고, 상기 복수의 화자 모델 간의 발화 특성의 유사도를 식별하고, 상기 복수의 화자 모델 중 상기 유사도가 임계값 이상인 2이상의 화자 모델을 병합 할 수 있다. 본 발명의 일 실시예에 따른 전자장치의 제어방법에 있어서, 마이크로폰으로 입력되는 복수의 제1사용자 음성에 대한 인식을 수행하여 상기 각 사용자 음성에 대응하는 동작을 수행하는 단계; 상기 복수의 제1사용자 음성을 발화 특성 별로 분류한 복수의 음성 그룹을 획득하는 단계; 상기 획득된 복수의 음성 그룹 중 사용자에 대응하 는 음성 그룹을 선택하는 단계; 및 상기 선택된 음성 그룹의 발화 특성에 기초하여, 마이크로폰으로 입력되는 제2사용자 음성에 대한 상기 사용자의 화자 인식을 수행하는 단계를 포함할 수 있다. 상기 사용자의 화자 인식을 수행하는 단계는, 상기 선택된 음성 그룹의 발화 특성에 기초하여 화자 모델을 생성 하는 단계; 상기 생성된 화자 모델에 기초하여 상기 복수의 제1사용자 음성에 대한 인식을 수행하여 상기 생성 된 화자 모델을 보정하는 단계; 및 상기 보정된 화자 모델에 기초하여 상기 사용자의 화자 인식을 수행하는 단 계를 포함할 수 있다. 상기 음성그룹을 선택하는 단계는, 상기 복수의 음성 그룹 중에서 상기 제1사용자 음성의 데이터가 가장 많은 음성 그룹을 상기 사용자에 대응하는 음성 그룹으로 선택하는 단계를 포함할 수 있다. 상기 생성된 화자 모델을 보정하는 단계는, 상기 복수의 제1사용자 음성 중 상기 생성된 화자 모델과의 유사도 가 임계값 이상인 제1사용자 음성에 기초하여 상기 생성된 화자 모델을 보정하는 단계를 포함할 수 있다. 상기 화자 모델을 생성하는 단계는, 상기 사용자에 대응하는 화자 모델이 생성되어 있는지 여부를 식별하는 단 계; 상기 화자 모델이 생성되어 있지 않은 경우, 상기 화자 모델을 생성하는 단계를 포함할 수 있다. 상기 화자 모델을 보정하는 단계는, 상기 사용자에 대하여 복수의 상기 화자 모델을 생성하는 단계; 상기 복수 의 화자 모델 간의 발화 특성의 유사도를 식별하는 단계; 및 상기 복수의 화자 모델 중 상기 유사도가 임계값 이상인 2이상의 화자 모델을 병합하는 단계를 포함할 수 있다. 컴퓨터가 읽을 수 있는 코드로서, 전자장치의 제어방법을 수행하는 코드를 포함하는 컴퓨터 프로그램이 저장된 기록매체에 있어서, 상기 전자장치의 제어방법은, 마이크로폰으로 입력되는 복수의 제1사용자 음성에 대한 인식 을 수행하여 상기 각 사용자 음성에 대응하는 동작을 수행하는 단계; 상기 복수의 제1사용자 음성을 발화 특성 별로 분류한 복수의 음성 그룹을 획득하는 단계; 상기 획득된 복수의 음성 그룹 중 사용자에 대응하는 음성 그 룹을 선택하는 단계; 및 상기 선택된 음성 그룹의 발화 특성에 기초하여, 마이크로폰으로 입력되는 제2사용자 음성에 대한 상기 사용자의 화자 인식을 수행하는 단계를 포함할 수 있다."}
{"patent_id": "10-2019-0139692", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명은 화자 인식을 수행할 경우, 화자등록과정에서 발생하는 번거로움을 줄여 사용자의 편의성을 높일 수 있다."}
{"patent_id": "10-2019-0139692", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하에서는 첨부 도면을 참조하여 본 발명의 실시예들을 상세히 설명한다. 도면에서 동일한 참조번호 또는 부호 는 실질적으로 동일한 기능을 수행하는 구성요소를 지칭하며, 도면에서 각 구성요소의 크기는 설명의 명료성과 편의를 위해 과장되어 있을 수 있다. 다만, 본 발명의 기술적 사상과 그 핵심 구성 및 작용이 이하의 실시예에 설명된 구성 또는 작용으로만 한정되지는 않는다. 본 발명을 설명함에 있어서 본 발명과 관련된 공지 기술 또는 구성에 대한 구체적인 설명이 본 발명의 요지를 불필요하게 흐릴 수 있다고 판단되는 경우에는 그 상세한 설명 을 생략하기로 한다. 본 발명의 실시예에서, 제1, 제2 등과 같이 서수를 포함하는 용어는 하나의 구성요소를 다른 구성요소로부터 구 별하는 목적으로만 사용되며, 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 또한, 본 발명의 실시예에서, '구성되다', '포함하다', '가지다' 등의 용어는 하나 또는 그 이상의 다른 특징들 이나 숫자, 단계, 동작, 구성요소, 부품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않 는 것으로 이해되어야 한다. 또한, 본 발명의 실시예에서, '모듈' 혹은 '부'는 적어도 하나의 기능이나 동작을 수행하며, 하드웨어 또는 소프트웨어로 구현되거나 하드웨어와 소프트웨어의 결합으로 구현될 수 있으며, 적어 도 하나의 모듈로 일체화되어 구현될 수 있다. 또한, 본 발명의 실시예에서, 복수의 요소 중 적어도 하나(at least one)는, 복수의 요소 전부뿐만 아니라, 복수의 요소 중 나머지를 배제한 각 하나 혹은 이들의 조합 모두 를 지칭한다. 도 1은 본 발명의 일 실시예에 의한 전자장치의 구성을 도시한 블록도이다.도 1에 도시된 바와 같이, 전자장치 는 통신부, 신호입출력부, 디스플레이부, 사용자입력부, 저장부, 마이크로폰 , 프로세서를 포함할 수 있다. 이하, 전자장치의 구성에 관해 설명한다. 전자장치는 영상을 표시할 수 있는 디스플레이장치로 구현 될 수 있다. 일 예로, 전자장치는 TV, 컴퓨터, 스마트 폰, 태블릿, 휴대용 미디어 플레이어, 웨어러블 디 바이스, 비디오 월, 전자액자 등을 포함할 수 있다. 또한, 전자장치는 디스플레이를 구비하지 않는 셋탑박 스 등의 영상처리장치, 냉장고, 세탁기 등의 생활가전, 컴퓨터본체와 같은 정보처리장치 등 다양한 종류의 장치 로 구현될 수 있다. 전자장치는 음성인식기능을 이용하여 화자인식을 수행할 수 있다. 전자장치는 사용자 음성을 수신하 면, 사용자 음성에 대한 음성신호를 획득한다. 사용자 음성에 대한 음성신호를 획득하기 위하여, 전자장치(10 0)는 사용자 음성을 수집하는 마이크로폰을 구비하거나, 또는 마이크로폰을 가진 리모트 컨트롤러, 스마트 폰 등의 외부장치로부터 음성신호를 수신할 수 있다. 외부장치에 리모트 컨트롤러 어플리케이션을 설치하여 전 자장치를 제어하거나 음성인식 등의 기능을 수행할 수도 있다. 이와 같은 어플리케이션이 설치된 외부장치 의 경우, 사용자 음성을 수신할 수 있으며, 외부장치는 TV와 Wi-Fi/BT 또는 적외선 등을 이용하여 데이터 송수 신 및 제어가 가능한 바, 상기 통신 방식을 구현할 수 있는 복수의 통신부가 전자장치 내에 존재할 수 있 다. 통신부는 다양한 종류의 유선 및 무선 통신 프로토콜에 대응하는 통신모듈, 통신칩 등의 구성요소들 중 적 어도 하나 이상을 포함하는 양방향 통신회로이다. 예를 들면, 통신부는 이더넷으로 라우터 또는 게이트웨 이에 유선 접속된 랜카드나, 와이파이(Wi-Fi) 방식에 따라서 AP와 무선통신을 수행하는 무선통신모듈이나, 블루투스 등과 같은 1대 1 다이렉트 무선통신을 수행하는 무선통신모듈 등으로 구현될 수 있다. 통신부는 네트 워크 상의 서버와 통신함으로써, 서버와의 사이에 데이터 패킷을 송수신할 수 있다. 다른 실시예로서, 통신부 는 서버 외의 다른 외부기기와 연결될 수 있으며, 다른 외부기기로부터 오디오 데이터를 비롯한 각종 데이 터를 수신하거나, 혹은 다른 외부기기로 오디오 데이터를 비롯한 각종 데이터를 전송할 수 있다. 전자장치(10 0)에 구비된 마이크로폰으로 음성이나 소리를 수신하는 경우, 통신부는 아날로그 형태의 음성신호(혹 은 소리신호)를 디지털화하여 프로세서로 전송하고, 외부기기로부터 음성신호를 수신하는 경우, 아날로그 형태의 음성신호를 디지털화 하여 블루투스나 Wi-Fi 등 데이터 전송 통신을 이용하여 통신부로 전송한다. 신호입출력부는 셋탑박스, 광학미디어 재생장치와 같은 외부기기, 또는 외부 디스플레이장치나, 스피커 등 과 1:1 또는 1:N(N은 자연수) 방식으로 유선 접속됨으로써, 해당 외부기기로부터 비디오/오디오 신호를 수신하 거나 또는 해당 외부기기에 비디오/오디오 신호를 출력한다. 신호입출력부는 예를 들면 HDMI 포트, DisplayPort, DVI 포트, 썬더볼트, USB 포트 등과 같이, 기 설정된 전송규격에 따른 커넥터 또는 포트 등을 포 함한다. 이 때, 예컨대, HDMI, DP, 썬더볼트 등은 비디오/오디오 신호를 동시에 전송할 수 있는 커넥터 또는 포 트이고, 다른 실시예로서, 신호입출력부는, 비디오/오디오 신호를 각각 별개로 전송하는 커넥터 또는 포트 를 포함할 수도 있다. 디스플레이부는 화면 상에 영상을 표시할 수 있는 디스플레이 패널을 포함한다. 디스플레이 패널은 액정 방식과 같은 수광 구조 또는 OLED 방식과 같은 자발광 구조로 마련된다. 디스플레이부는 디스플레이 패널 의 구조에 따라서 부가적인 구성을 추가로 포함할 수 있는데, 예를 들면 디스플레이 패널이 액정 방식이라면, 디스플레이부는 액정 디스플레이 패널과, 광을 공급하는 백라이트유닛과, 액정 디스플레이 패널의 액정을 구동시키는 패널구동기판을 포함한다. 사용자입력부는 사용자의 입력을 수행하기 위해 마련된 다양한 종류의 입력 인터페이스 관련 회로를 포함 한다. 사용자입력부는 전자장치의 종류에 따라서 여러 가지 형태의 구성이 가능하며, 예를 들면 전자 장치의 기계적 또는 전자적 버튼부, 전자장치와 분리된 리모트 컨트롤러, 터치패드, 디스플레이부 에 설치된 터치스크린 등이 있다. 저장부는 디지털화된 데이터를 저장한다. 저장부는 전원의 제공 유무와 무관하게 데이터를 보존할 수 있는 비휘발성 속성의 스토리지(storage)와, 프로세서에 의해 처리되기 위한 데이터가 로딩되며 전원이 제 공되지 않으면 데이터를 보존할 수 없는 휘발성 속성의 메모리(memory)를 포함한다. 스토리지에는 플래시메모리 (flash-memory), HDD(hard-disc drive), SSD(solid-state drive) ROM(Read Only Memory) 등이 있으며, 메모리 에는 버퍼(buffer), 램(RAM; Random Access Memory) 등이 있다. 마이크로폰은 사용자 음성을 비롯한 외부 환경의 소리를 수집한다. 마이크로폰은 수집된 소리의 신호 를 프로세서에 전달한다. 마이크로폰은 전자장치의 본체에 설치될 수도 있고, 전자장치의 본체와 분리된 리모트 컨트롤러에 설치될 수도 있다. 후자의 경우에, 마이크로폰에 의한 음성신호는 리모트 컨 트롤러로부터 통신부에 수신된다. 프로세서는 인쇄회로기판 상에 장착되는 CPU, 칩셋, 버퍼, 회로 등으로 구현되는 하나 이상의 하드웨어 프 로세서를 포함하며, 설계 방식에 따라서는 SOC(system on chip)로 구현될 수도 있다. 프로세서는 전자장치 가 디스플레이장치로 구현되는 경우에 디멀티플렉서, 디코더, 스케일러, 오디오 DSP(Digital Signal Processor), 앰프 등의 다양한 프로세스에 대응하는 모듈들을 포함한다. 여기서, 이러한 모듈들 중 일부 또는 전체가 SOC로 구현될 수 있다. 예를 들면, 디멀티플렉서, 디코더, 스케일러 등 영상처리와 관련된 모듈이 영상 처리 SOC로 구현되고, 오디오 DSP는 SOC와 별도의 칩셋으로 구현되는 것이 가능하다. 프로세서는 마이크로폰 등에 의해 사용자 음성에 대한 음성신호를 획득하면, 음성신호를 음성데이터 로 변환할 수 있다. 이 때, 음성데이터는 음성신호를 텍스트 데이터로 변환하는 STT(Speech-to-Text) 처리 과정 을 통해 얻어진 텍스트 데이터일 수 있다. 프로세서는 음성데이터가 나타내는 커맨드를 식별하고, 식별된 커맨드에 따라서 동작을 수행한다. 음성데이터 처리 과정과, 커맨드 식별 및 수행 과정은, 전자장치에서 모두 실행될 수도 있다. 그러나, 이 경우에 전자장치에 필요한 시스템 부하 및 소요 저장용량이 상대적으 로 커지게 되므로, 적어도 일부의 과정은 네트워크를 통해 전자장치와 통신 가능하게 접속되는 적어도 하 나의 서버에 의해 수행될 수 있다. 그리고, 프로세서는 사용자 음성이 수신된 경우, 수신된 사용자 음성의 발화 특성을 식별하고, 식별된 발 화 특성에 대응하는 화자 모델에 기초하여 사용자 음성에 대한 화자인식을 수행할 수 있다.전자장치는 화자 인식을 위해 적어도 하나의 화자 모델을 구비할 수 있다. 화자 모델은 사용자 음성에 따 른 음성신호를 프로세서 등이 해석 가능한 텍스트 데이터로 변환하기 위해 사용되는 하드웨어/소프트웨어 컴포 넌트이다. 화자 모델은, 예컨대, 마르코프 모델(Hidden Markov Model; HMM), 동적 시간 왜곡(Dynamic Time Warping; DTW) 등의 알고리즘에 따라서 발화 음성에 대한 통계적 모델링을 통해 구현되는 음향 모델(Acoustic Model), 말뭉치(언어 연구를 위하여 컴퓨터가 텍스트를 가공, 처리, 분석할 수 있는 형태로 모아 놓은 자료의 집합) 수집을 통해 구현되는 언어 모델(Language Model) 등을 포함할 수 있다. 화자 모델은 모델 개발에 사용된 사용자 데이터 및 말뭉치 데이터 등에 의해 고유한 특성, 예컨대, 발화 특성에 대응하도록 마련될 수 있다. 발 화 특성에는, 예컨대, 사용자 음성의 톤, 세기, 빠르기, 주파수, 주기 등이 있을 수 있다. 다만, 발화 특성은 이에 한정되는 것은 아니다. 본 발명에 따른 프로세서는 전자장치와 같은 기기(Machine)가 읽을 수 있는 저장 매체(Storage Medium)에 저장된 소프트웨어의 명령어들 중 적어도 하나의 명령을 호출하고, 그것을 실행할 수 있다. 이것은 전자장치와 같은 기기가 상기 호출된 적어도 하나의 명령어에 따라 적어도 하나의 기능을 수행하도록 운영 되는 것을 가능하게 한다. 상기 하나 이상의 명령어들은 컴파일러에 의해 생성된 코드 또는 인터프리터에 의해 실행될 수 있는 코드를 포함할 수 있다. 기기로 읽을 수 있는 저장매체는, 비일시적(Non-transitory) 저장매체 의 형태로 제공될 수 있다. 여기서, ‘비일시적’은 저장매체가 실재(tangible)하는 장치이고, 신호(예컨대, 전 자기파)를 포함하지 않는다는 것을 의미할 뿐이며, 이 용어는 데이터가 저장매체에 반영구적으로 저장되는 경우 와 임시적으로 저장되는 경우를 구분하지 않는다. 한편, 프로세서는 마이크로폰 등에 의해 수신된 사용자 음성의 발화 특성을 식별하고, 식별된 발화 특성에 대응하는 화자 모델에 기초하여 사용자 음성에 대한 화자인식 동작을 수행하기 위한 데이터 분석, 처리, 및 결과 정보 생성 중 적어도 일부를 규칙 기반 또는 인공지능(Artificial Intelligence) 알고리즘으로서 기계 학습, 신경망 네트워크(neural network), 또는 딥러닝 알고리즘 중 적어도 하나를 이용하여 수행할 수 있다. 일 예로, 프로세서는 학습부 및 인식부의 기능을 함께 수행할 수 있다. 학습부는 학습된 신경망 네트워크 를 생성하는 기능을 수행하고, 인식부는 학습된 신경망 네트워크를 이용하여 데이터를 인식(또는, 추론, 예측, 추정, 판단)하는 기능을 수행할 수 있다. 학습부는 신경망 네트워크를 생성하거나 갱신할 수 있다. 학습부는 신 경망 네트워크를 생성하기 위해서 학습 데이터를 획득할 수 있다. 일 예로, 학습부는 학습 데이터를 저장부 또는 외부로부터 획득할 수 있다. 학습 데이터는, 신경망 네트워크의 학습을 위해 이용되는 데이터일 수 있으며, 상기한 동작을 수행한 데이터를 학습데이터로 이용하여 신경망 네트워크를 학습시킬 수 있다. 학습부는 학습 데이터를 이용하여 신경망 네트워크를 학습시키기 전에, 획득된 학습 데이터에 대하여 전처리 작 업을 수행하거나, 또는 복수 개의 학습 데이터들 중에서 학습에 이용될 데이터를 선별할 수 있다. 일 예로, 학 습부는 학습 데이터를 기 설정된 포맷으로 가공하거나, 필터링하거나, 또는 노이즈를 추가/제거하여 학습에 적 절한 데이터의 형태로 가공할 수 있다. 학습부는 전처리된 학습 데이터를 이용하여 상기한 동작을 수행하도록 설정된 신경망 네트워크를 생성할 수 있다. 학습된 신경망 네트워크는, 복수의 신경망 네트워크(또는, 레이어)들로 구성될 수 있다. 복수의 신경망 네트워 크의 노드들은 가중치를 가지며, 복수의 신경망 네트워크들은 일 신경망 네트워크의 출력 값이 다른 신경망 네 트워크의 입력 값으로 이용되도록 서로 연결될 수 있다. 신경망 네트워크의 예로는, CNN (Convolutional Neural Network), DNN (Deep Neural Network), RNN (Recurrent Neural Network), RBM (Restricted Boltzmann Machine), DBN (Deep Belief Network), BRDNN (Bidirectional Recurrent Deep Neural Network) 및 심층 Q-네 트워크 (Deep Q-Networks)과 같은 모델을 포함할 수 있다. 한편 인식부는 상기한 동작을 수행하기 위해, 타겟 데이터를 획득할 수 있다. 타겟 데이터는 저장부 또는 외부로부터 획득된 것일 수 있다. 타겟 데이터는 신경망 네트워크의 인식 대상이 되는 데이터일 수 있다. 인식 부는 타겟 데이터를 학습된 신경망 네트워크에 적용하기 전에, 획득된 타겟 데이터에 대하여 전처리 작업을 수 행하거나, 또는 복수 개의 타겟 데이터들 중에서 인식에 이용될 데이터를 선별할 수 있다. 일 예로, 인식부는 타겟 데이터를 기 설정된 포맷으로 가공하거나, 필터링 하거나, 또는 노이즈를 추가/제거하여 인식에 적절한 데 이터의 형태로 가공할 수 있다. 인식부는 전처리된 타겟 데이터를 신경망 네트워크에 적용함으로써, 신경망 네 트워크로부터 출력되는 츨력값을 획득할 수 있다. 인식부는 출력값과 함께, 확률값 또는 신뢰도값을 획득할 수 있다. 일 예로, 본 발명에 따른 전자장치의 제어방법은 컴퓨터 프로그램 제품 (Computer Program Product)에 포 함되어 제공될 수 있다. 컴퓨터 프로그램 제품은, 앞서 설명한, 프로세서에 의해 실행되는 소프트웨어의명령어들을 포함할 수 있다. 컴퓨터 프로그램 제품은 상품으로서 판매자 및 구매자 간에 거래될 수 있다. 컴퓨 터 프로그램 제품은 기기로 읽을 수 있는 저장 매체(예컨대, CD-ROM)의 형태로 배포되거나, 또는 어플리케이션 스토어(예컨대, 플레이 스토어TM)를 통해 또는 두 개의 사용자 장치들(예컨대, 스마트폰들) 간에 직접, 온라인 으로 배포(예컨대, 다운로드 또는 업로드)될 수 있다. 온라인 배포의 경우에, 컴퓨터 프로그램 제품의 적어도 일부는 제조사의 서버, 어플리케이션 스토어의 서버, 또는 중계 서버의 메모리와 같은 기기로 읽을 수 있는 저 장 매체에 적어도 일시 저장되거나, 임시적으로 생성될 수 있다. 도 2는 본 발명의 일 실시예에 의한 전자장치의 동작 흐름도를 도시한 도면이다. 본 발명의 일 실시예에 따르면, 프로세서는 마이크로폰으로 입력되는 복수의 사용자 음성에 대한 인식을 수행하여 각 사용자 음성에 대응하는 동작을 수행한다(S210). 이 때, 프로세서는 복수의 사용자 음성을 발화 특성 별로 분류한 복수의 음성 그룹을 획득한다(S220). 이 때, 본 발명의 일 실시예에 따른 발화 특성에는, 예컨대, 사용자 음성 의 톤, 세기, 빠르기, 주파수, 주기 등이 있을 수 있다. 다만, 발화 특성은 이에 한정되는 것은 아니다. 따라서, 본 실시예에 따른 프로세서는 복수의 사용자 음성이 입력된 경우, 입력된 사용자 음성의 발화 특 성을 식별하여, 유사한 발화 특성을 가지는 사용자 음성 별로 분류할 수 있다. 그 후, 프로세서는 획득된 복수의 음성 그룹 중 사용자에 대응하는 음성 그룹을 선택(혹은 식별)하고(S230), 선택된 음성 그룹의 발화 특 성에 기초하여, 마이크로폰으로 입력되는 사용자 음성에 대한 화자 인식을 수행한다(S240). 따라서, 본 발명의 일 실시예에 따르면, 화자 인식을 위해 별도의 화자등록과정을 거치지 않더라도, 전자장치의 동작에 따라 축적되는 사용자 음성만으로 화자 인식이 가능하므로, 사용자의 편의성이 향상된다. 도 3은 본 발명의 일 실시예에 따른 전자장치의 동작 흐름도를 도시한 도면이다. 도 3은 도 2에 도시된 내용을 보다 자세히 설명한다. 본 발명의 일 실시예에 따르면, 마이크로폰 등을 통해 복수의 사용자 음성, 예컨대, 사용자 음성 1, 사용자 음성 2, 사용자 음성 3, … , 사용자 음성 n 등이 입력될 수 있다. 본 발명의 프로세서는 복수의 사용자 음성을 발화 특성에 기초하여 유사한 발화 특성을 가지는 사용자 음성들을 음성 그룹 1, 음성 그룹 2, 음성 그룹 3, … ,음성 그룹 k 등으로 분류할 수 있다(S310). 프로세서는. 사용자 수와 음성 그룹 수를 동일하게 하여, 사용자 별로 음성 그룹을 생성하거나, 사용자 수와 음성 그룹 수가 동일하 지 않게 음성 그룹을 생성할 수 있다. 이 때, 전자장치에 음성 그룹을 형성하기 쉬우며, 형성된 음성 그룹 의 정확도를 높이기 위하여, 음성 그룹 분류에 있어 오류가 발생할 확률이 소정치 이하가 되도록 사용자 음성의 수를 확보한다. 본 발명의 일 실시예에 따라 복수의 사용자 음성이 복수의 음성 그룹으로 분류되고 나면, 프로세서는 복수 의 음성 그룹 중 하나의 그룹을 선택한다(S320). 이 때, 전자장치의 사용자를 특정하기 위하여, 프로세서 는 분류된 음성 그룹 중에서 사용자 음성이 가장 많이 포함된 음성 그룹을 선택하고, 선택된 음성 그룹에 대응하는 발화를 한 사용자를 실제 전자장치를 사용하는 사용자라고 인식한다. 전자장치를 가장 많이 이용하는 자가 전자장치에서 화자 인식을 수행할 사용자일 확률이 높기 때문이다. 다만, 사용자를 특정하 기 위한 방법으로는, 사용자 음성의 수에만 한정되지 않고, 다른 다양한 방법이 이용될 수 있다. 예컨대, 프로 세서는 다른 경로를 통하여 사용자의 정보를 획득하고, 획득된 정보에 기초하여 사용자 음성과 사용자 간 의 연관성을 식별할 수도 있다. 이 때, 다음 수식 1에 따라 사용자 음성의 개수가 가장 많은 음성 그룹을 선택할 수 있다. [수식 1]"}
{"patent_id": "10-2019-0139692", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "사용자가 인식되고 난 뒤에는, 전자장치에 사용자 음성이 입력되면(S330), 프로세서는 입력된 사용자 음성과 선택된 음성 그룹의 발화 특성을 비교하여 동일한 사용자에 기한 음성 입력인지 식별하여 화자 인식을 한다(S340). 입력된 사용자 음성과 음성 그룹의 발화 특성이 유사하면, 전자장치의 사용자라고 인식될 수 있다. 이와 같이, 전자장치는 하나의 음성 그룹을 선택할 수도 있으나 이에 한정되는 것은 아니며, 사용자 음성 의 개수가 가장 많은 그룹을 선택한 후, 그 다음으로 많은 개수를 가지는 음성 그룹을 선택하여 복수의 사용자 를 인식할 수 있다. 따라서, 본 발명의 일 실시예에 따르면, 음성 그룹을 선택함에 있어 음성 그룹별 사용자 음성의 수 등을 고려하 여 화자 인식의 신뢰성이 높아질 수 있다.도 4는 본 발명의 일 실시예에 따른 음성 그룹 별 음성데이터 양을 도시한 도면이다. 본 발명의 일 실시예에 따 르면, 프로세서는 복수의 사용자 음성을 유사한 발화 특성을 가지는 사용자 음성끼리 분류한다. 따라서, 복수의 사용자 음성은 음성 그룹 1, 음성 그룹 2, 음성 그룹 3, … , 음성 그룹 k로 나뉘어지고, 각 음성 그룹 이 가지는 음성 데이터 양은 각각 A1, A2, A3, … , Ak이라고 가정한다. 이 때, 프로세서는 k개의 음성 그 룹 중에서 사용자 음성의 데이터가 가장 많은 음성 그룹을 사용자에 대응하는 음성 그룹으로 선택할 수 있다. 특정 발화 특성을 가지는 사용자 음성의 데이터가 가장 많다는 것은 전자장치를 사용한 복수의 사용자 중 가장 빈번하게 전자장치를 사용하였다고 볼 수 있기 때문이다. 예컨대, 음성 그룹 3의 음성 데이터의 양이 A3로 k개의 음성 그룹 중 가장 많은 경우, 음성 그룹 3에 해당하는 사용자 음성을 발화한 사용자가 전자장치를 가장 자주 사용하였다고 볼 수 있고, 전자장치는 이를 사용자로 인식할 수 있다. 따라서, 본 발명의 일 실 시예에 따르면, 음성 그룹 별 음성 데이터의 양에 기초하여 전자장치의 주 사용자가 존재하는지, 몇 명이 주로 사용하는지 등 파악이 가능하다. 도 5는 본 발명의 일 실시예에 따른 전자장치의 동작 흐름도를 도시한 도면이다. 프로세서는 복수의 음성 그룹 중에서 사용자 음성이 가장 많이 포함된 음성 그룹을 선택하고, 선택한 음성 그룹을 통하여 화자 모델을 생성할 수 있다(S510). 이는 특정 사용자의 음성데이터는 선택된 특정 음성 그룹뿐만 아니라 다른 음성 그룹에 도 포함되어 있을 수 있기 때문에, 선택된 특정 음성 그룹으로 특정 화자 모델을 생성하여 모든 사용자 음성을 대상으로 다시 사용자 음성을 분류하기 위함이다. 따라서, 프로세서는 생성된 화자 모델에 기초하여 복수 의 사용자 음성에 대한 인식을 수행하고(S520), 생성된 화자 모델을 보정할 수 있다(S530). 화자 모델이 보정되 고 난 후, 전자장치에 사용자 음성이 입력되면(S540), 프로세서는 보정된 화자 모델에 기초하여 사용 자의 화자 인식을 수행할 수 있다(S550). 본 발명의 일 실시예는 하나의 화자 모델 생성 및 보정에 한정되는 것 은 아니며, 복수의 음성 그룹 중 하나를 선택하여 남은 사용자 음성 및 신규로 입력된 사용자 음성을 대상으로 복수의 화자 모델을 생성 및 보정할 수 있다. 따라서, 본 발명의 일 실시예에 따르면, 선택한 음성 그룹 자체만으로 화자 인식을 수행하는 것보다, 생성한 화 자 모델을 보정함으로써 화자 인식의 정확도가 더 높아질 수 있고, 동일 사용자 음성이 다른 음성 그룹에 분류 된 것을 식별할 수 있으므로 신뢰도가 높아질 수 있다. 도 6은 본 발명의 일 실시예에 따른 전자장치의 동작 흐름도를 도시한 도면이고, 도 7은 본 발명의 일 실시예에 따른 사용자 음성별 화자 모델에 대한 스코어 테이블을 도시한 도면이다. 본 발명의 일 실시예에 따르면, 화자 모델이 생성되면, 프로세서는 생성된 화자 모델의 발화 특성에 기초 하여 복수의 사용자 음성별로 스코어를 계산할 수 있다(S610). 이 때, 전자장치에 생성된 화자 모델은 적 어도 하나 이상일 수 있다. 도 7에 도시된 테이블에 따르면, 예컨대, 복수의 사용자 음성에 기초하여 화자 모델 1, 화자 모델 2, 화자 모델 3, 화자 모델 4가 생성되었다고 가정해 본다. 이 때, 화자 인식을 위한 스코어 의 임계값을 1이라고 가정하고, 사용자 음성 1 내지 사용자 음성 6을 생성된 4개의 화자 모델의 발화 특성과 각 각 비교하여 스코어를 계산한다. 그리고 프로세서는 각 사용자 음성의 계산된 스코어가 화자 모델을 이용 하여 화자 인식을 위한 임계값보다 큰 지 여부를 판단할 수 있다(S620). 이 때, 각 사용자 음성의 계산된 스코 어가 화자 모델을 이용하여 화자 인식을 위한 임계값보다 크다는 것은, 특정 사용자 음성이 특정 화자 모델의 발화 특성과 유사하다고 인식되는 것을 의미한다. 예컨대, 도 7에서 사용자 음성 1은 스코어가 임계값 1을 초과 하는 화자 모델 1과 화자 모델 4로 인식될 수 있지만, 화자 모델 1에 대한 스코어가 1.5로 화자 모델 4에 대한 스코어인 1.1보다 높기 때문에 사용자 음성 1은 화자 모델 1에 해당한다고 인식될 수 있다. 나머지 발화에 대해 서도 판단하면, 사용자 음성 2는 화자 모델 2로, 사용자 음성 3은 화자 모델 4로, 사용자 음성 4는 화자 모델 3 으로, 사용자 음성 6은 화자 모델 1로 인식할 수 있다. 사용자 음성 5의 경우, 생성된 모든 화자 모델과의 스코 어 값이 화자 인식 임계값 1을 넘지 못하므로 화자 인식이 되지 못함을 알 수 있다. 사용자 음성과 생성된 화자 모델 중 하나의 발화 특성과의 스코어가 임계값보다 큰 경우(S620의 Yes), 프로세서 는 해당하는 사용자 음성은 해당 화자 모델의 발화 특성과 유사한 것으로 간주하여 화자 모델의 데이터에 사용자 음성 데이터를 병합하여 화자 모델을 보정한다. 예컨대, 도 7에서 화자 모델 1에 대해 사용자 음성 1의 데이터만 포함되고 사용자 음성 6의 데이터가 포함되지 않은 경우를 가정한다. 도 7의 테이블을 참조하면, 사용자 음성 1과 사용자 음성 6은 각각 화자 모델 1에 대해 스코어가 1.5, 2.5로 임계값보다 큰 값을 가지므로, 사용자 음성 1과 사용자 음성 6은 화자 모델 1의 발화 특성과 유사하다고 판단할 수있다. 따라서, 화자 모델 1 이 생성된 후, 프로세서는 사용자 음성 6을 화자 모델 1에 분류하여 보정할 수 있다. 본 발명의 일 실시예 에 따르면, 화자 모델이 생성된 후에는 신규 수신된 사용자 음성을 비롯하여 저장부에 저장된 사용자 음성을 이용하여 화자 모델을 지속적으로 보정함으로써 화자 모델을 정교하게 구축할 수 있다. 반면, 스코어가 임계값보다 낮은 사용자 음성은 생성된 화자 모델과 다른 사용자의 음성으로 판단하여, 프로세 서는 사용자 음성을 저장부에 다시 저장할 수 있다. 해당 사용자 음성은 추후 발화 특성이 유사한 사 용자 음성들과 함께 새로운 모델을 생성할 수 있을 것이다. 예컨대, 도 7에서 사용자 음성 5는 생성된 화자 모 델과의 스코어 값이 모두 임계값을 넘지 못하므로, 사용자 음성 5의 발화 특성에 해당하는 화자 모델은 생성되 지 않음을 의미한다. 따라서 프로세서는 사용자 음성 5의 데이터를 저장부에 다시 저장하고 추후 새 로운 모델을 생성하는데 이용될 수 있다. 도 8은 본 발명의 일 실시예에 따른 사용자 음성에 따른 발화 특성에 대한 테이블을 도시한 도면이다. 본 발명의 일 실시예에 따른 발화 특성은, 전자장치에 입력되는 복수의 사용자 음성의 톤, 세기, 및 빠르 기 중 적어도 하나를 포함할 수 있다. 예컨대, 전자장치의 저장부에 사용자 음성 1, 사용자 음성 2, 사용자 음성 3, 사용자 음성 4가 저장되어 있다고 가정해 본다. 사용자 음성 1의 경우 톤은 t1, 세기는 l1, 빠 르기는 s1을 가지고, 사용자 음성 2의 경우 톤은 t2, 세기는 l2, 빠르기는 s2을 가지고, 사용자 음성 3의 경우 톤은 t3, 세기는 l3, 빠르기는 s3을 가지고, 사용자 음성 1의 경우 톤은 t4, 세기는 l4, 빠르기는 s4을 가진다. 프로세서는 각 사용자 음성의 발화 특성에 기초하여 도 6 및 도 7에서 설명한 복수의 사용자 음성별 생성 된 화자 모델에 대한 스코어를 계산할 수 있을 것이다. 본 발명의 일 실시예에 따른 발화 특성을 데이터화함으 로써, 사용자 음성과 화자 모델의 발화 특성의 비교를 구체적으로 수행할 수 있다. 도 9는 본 발명의 일 실시예에 따른 전자장치의 동작 흐름도를 도시한 도면이고, 도 10은 본 발명의 일 실시예 에 따른 화자 모델 간 유사도 테이블을 도시한 도면이다. 본 발명의 일 실시예에 따르면, 화자 모델을 생성하는 과정에서 기존에 생성된 화자 모델과 동일한 화자의 모델이 생성될 수 있고, 하나의 사용자에 대응하는 화자 모 델이 복수 개 생성되어 있을 수 있다. 이는, 사용자 음성은 사용자의 발화 특성 변이와 주변 환경 등에 의해 그 발화 특성이 다르게 인식되어, 다른 모델에 사용자의 음성이 포함될 수 있기 때문이다. 따라서, 프로세서 는 화자 모델 간 유사도를 계산하여 사용자에 대응하는 화자 모델이 생성되어 있는지 여부를 식별할 수 있다 (S910). 화자 모델 간 유사도는 다음 수식을 통해 계산할 수 있다. [수식 2]"}
{"patent_id": "10-2019-0139692", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "[수식 3]"}
{"patent_id": "10-2019-0139692", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "수식 2의 유사도 는 i 화자 모델의 각 사용자 음성별 스코어 와 j 화자 모델의 각 사용자 음성별 스코 어 의 비를 나타낸 것이다. 이 때, 유사도를 간결하게 나타내기 위해 소수점 셋째 자리에서 반올림한다. 예 컨대, 도 7의 테이블을 참조하면, 사용자 음성 2에 대한 화자 모델 1의 스코어와 화자 모델 2의 스코어는 각각 0.3과 1.1이다. 수식 2를 이용하여 화자 모델 2에 대한 화자 모델 1의 유사도를 나타내면, 0.3/1.1으로 0.27이 된다. 마찬가지로 도 7의 테이블을 참조하여, 사용자 음성 2에 대한 화자 모델 2의 스코어와 화자 모델 3의 스코어로 유사도를 나타내면 0.1/1.1로 0.09가 된다. 나머지 사용자 음성과 화자 모델의 스코어를 이 용해 도 10의 유사도 테이블을 채울 수 있다. 다만, 도 7에서 살펴봤듯이, 화자 모델 1의 경우, 사용자 음성 1과 사용자 음성 6이 해당할 수 있는데, 이처럼 복수의 사용자 음성이 하나의 화자 모델에 대응하는 경우, 화자 모델 간 유사도는 수식 3을 이용하여 계산할 수 있다. 화자 모델은 복수의 사용자 음성으로 이루어지므로, 사실상 화자 모델 간 유사도는 수식 3의 전체 유사도 라고 볼 수 있다. 수식 3의 전체 유사도 는 i 화자 모델과 j 화자 모델 간의 유사도 의 전체 합 을 i 화자 모델에 해당하는 사용자 음성의 개수로 나눈 값이다. 예컨대, 화자 모델 1에 대한 화자 모델 2의 유 사도를 계산해 본다. 도 7의 테이블을 참조하면, 사용자 음성 1에 대한 화자 모델 1의 스코어와 화자 모델 2의 스코어는 각각 1.5와 0.2이고, 사용자 음성 6에 대한 화자 모델 1의 스코어와 화자 모델 2의 스코어는 각각2.5와 0.2이다. 수식 2를 이용하여 사용자 음성별 화자 모델간의 유사도를 구해보면, 0.2/1.5, 0.2/2.5이다. 따 라서, 도 10의 테이블에 도시된 화자 모델 1에 대한 화자 모델 2의 전체 유사도는 사용자 음성별 화자 모 델간의 유사도를 사용자 음성 개수로 나눈 값이 된다. 즉, (0.2/1.5 + 0.2/2.5)/2가 되어 약 0.11이 된다. 이와 같은 방법으로 프로세서는 화자 모델 간의 유사도를 구할 수 있고, 소정의 기준에 따라 유사도가 일 정 값을 넘는 화자 모델들은 유사하다고 판단할 수 있다. 프로세서는 사용자에 대응하는 화자 모델이 생성 되어 있다고 식별되지 않으면(S910의 No), 새로운 화자 모델을 생성한다(S920). 따라서, 전자장치는 동일한 화자 모델이 복수 개 생성되는 것을 방지할 수 있다. 도 11은 본 발명의 일 실시예에 따른 전자장치의 동작 흐름도를 도시한 도면이다. 본 발명의 일 실시예에 따르 면, 전자장치에 음성이 입력된 경우(S1110), 사용자 음성을 생성된 화자 모델의 발화 특성에 기초하여 스 코어를 계산하고(S1120), 계산된 스코어가 임계값이 넘는 경우 전자장치의 사용자로 인증한다(S1130)."}
{"patent_id": "10-2019-0139692", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일 실시예에 의한 전자장치의 구성을 도시한 블록도이다. 도 2는 본 발명의 일 실시예에 의한 전자장치의 동작 흐름도를 도시한 도면이다.도 3은 본 발명의 일 실시예에 따른 전자장치의 동작 흐름도를 도시한 도면이다. 도 4는 본 발명의 일 실시예에 따른 음성 그룹 별 음성데이터 양을 도시한 도면이다. 도 5는 본 발명의 일 실시예에 따른 전자장치의 동작 흐름도를 도시한 도면이다. 도 6은 본 발명의 일 실시예에 따른 전자장치의 동작 흐름도를 도시한 도면이다. 도 7은 본 발명의 일 실시예에 따른 사용자 음성별 화자 모델에 대한 스코어 테이블을 도시한 도면이다. 도 8은 본 발명의 일 실시예에 따른 사용자 음성에 따른 발화 특성에 대한 테이블을 도시한 도면이다. 도 9는 본 발명의 일 실시예에 따른 전자장치의 동작 흐름도를 도시한 도면이다. 도 10은 본 발명의 일 실시예에 따른 화자 모델 간 유사도 테이블을 도시한 도면이다. 도 11은 본 발명의 일 실시예에 따른 전자장치의 동작 흐름도를 도시한 도면이다."}
