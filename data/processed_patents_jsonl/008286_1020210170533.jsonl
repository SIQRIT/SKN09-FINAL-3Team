{"patent_id": "10-2021-0170533", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0083348", "출원번호": "10-2021-0170533", "발명의 명칭": "컨텐츠 제작 방법 및 플랫폼", "출원인": "(주)셀빅", "발명자": "정영균"}}
{"patent_id": "10-2021-0170533", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "공지의 인공신경망 소프트웨어가 적용된 서버와, 단말로 구성되고, 상기 서버와 상기 단말 간 정보를 상호 송수신하는 컨텐츠 제작 플랫폼에 있어서,N개의 영상정보로 구성되는 영상정보군 중 제 1영상정보와, 상기 제 1영상정보와 대응되는 프레임 번호를 저장하는 제 1프레임을 생성하여 상기 제 1프레임을 저장하고, 상기 영상정보군의 모든 N개의 영상정보에 대해 순차적으로 상기 N개의 영상정보와, 상기 N개의 영상정보와 대응되는 일련의 프레임 번호들을 저장하는 N개의 프레임들을 생성하여, 상기 N개의 프레임들을 저장하고, 상기 N개의 프레임들을 상기 서버로 송신하는 단말;상기 수신된 N개의 프레임들 중 상기 제 1프레임의 제 1영상정보를 추출하고, 상기 제 1영상정보로부터 M개의관절 좌표로 구성된 휴먼포즈 데이터를 생성하고, 상기 제 1영상정보로부터 상기 M개의 관절 좌표와 대응되는레이블을 생성하고, 상기 제 1영상정보로부터 메쉬 데이터을 생성하고, 상기 수신된 모든 N개의 프레임들에 대해 순차적으로 영상정보들을 추출하고, 상기 영상정보들로부터 M개의 관절 좌표로 구성된 휴먼포즈 데이터들을 생성하고, 상기 영상정보들로부터 상기 M개의 관절 좌표와 대응되는 레이블들로 구성된 레이블 맵을 생성하고, 상기 N개의 영상정보들로부터 메쉬 데이터들을 생성하여,상기 휴먼포즈 데이터들과 상기 휴먼포즈 데이터들과 대응되는 주소 값들과, 상기 레이블 맵들과 상기 레이블맵들과 대응되는 주소 값들과, 상기 메쉬 데이터들과 상기 메쉬 데이터들과 대응되는 주소 값들을 상기 N개의프레임들에 저장하고, 상기 N개의 프레임들을 상기 단말로 송신하는 서버;상기 단말은,상기 수신된 N개의 프레임들로부터 추출된 상기 휴먼포즈 데이터들과, 상기 레이블 맵 및 상기 메쉬 데이터들을이용하여 N개의 영상정보로 구성되는 영상정보군과 대응되는 컨텐츠를 생성하고, 상기 프레임들은 일련의 프레임 번호들이 저장되어 있는 것을 특징으로 하는, 컨텐츠 제작 플랫폼."}
{"patent_id": "10-2021-0170533", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 단말은,상기 추출된 휴먼포즈 데이터들을 칼만 필터 및 저주파 통과 필터를 적용하여 보정된 휴먼포즈 데이터들을 생성하고, 상기 추출된 휴먼포즈 데이터들을 상기 보정된 휴먼포즈 데이터들로 대체하는 것을 특징으로 하는, 컨텐츠 제작 플랫폼."}
{"patent_id": "10-2021-0170533", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 2항에 있어서, 상기 서버는, 상기 N개의 프레임들 중 A개의 제 2프레임들에 대해서, 상기 A개의 제 2프레임들에 대응되는 휴먼포즈데이터들, 레이블들 및 메쉬 데이터들의 미생성 요청정보를 수신한 경우, 상기 미생성 요청정보에 따라, 상기 A개의 제 2프레임들에 대한 휴먼포즈 데이터들, 레이블들 및 메쉬 데이터들을 미생성하여, 상기 휴먼포즈 데이터들, 레이블들 및 메쉬 데이터들이 저장되지 않은 A개의 제 2프레임들과,휴먼포즈 데이터들, 레이블들 및 메쉬 데이터들이 저장된 N-A개의 프레임들을 상기 단말로 송신하고, 상기 단말은,상기 수신된 A개의 제 2프레임들의 일련번호가 상기 N-A개의 프레임들의 일련번호와 가장 가까운 프레임들을 설정하여, 상기 수신된 A개의 제 2프레임들의 휴먼포즈 데이터들, 레이블들 및 메쉬 데이터들을 상기 설정된 가장공개특허 10-2023-0083348-3-가까운 프레임들의 휴먼포즈 데이터들, 레이블들 및 메쉬 데이터들로 반영하여 저장하는 것을 특징으로 하는 컨텐츠 제작 플랫폼."}
{"patent_id": "10-2021-0170533", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 1항에 있어서, 상기 N개의 영상정보로 구성되는 영상정보군이 정면의 인체정보를 포함하고, 상기 정면의 인체정보와 대응되는후면정보가 포함되어 있지 않은 경우, 상기 서버는 상기 M개의 관절 좌표 중 제 1 관절 좌표와 상기 레이블 맵과의 이격 거리가 기 설정된 이격 거리이하인 경우, 상기 레이블 맵을 상기 제 1 관절 좌표에 대응되는 제 1인체 레이블로 생성하고, 상기 M개의 모든관절 좌표에 대해서 순차적으로 M개의 인체 레이블을 생성하고, 상기 M개의 인체 레이블로 구성된 인체 레이블맵을 생성하고,상기 M개의 관절 좌표와 상기 레이블 맵의 이격 거리가 기 설정된 이격 거리를 초과한 경우, 비인체 레이블 맵을 생성하고, 상기 인체 레이블 맵과 상기 비인체 레이블 맵으로 구성되는 제 2영상 정보를 생성하고,상기 제 1영상정보를 N개의 패치로 분리하여 N개의 제 1영상정보패치를 생성하고, 상기 N개의 제 1영상정보패치로 구성되는 제 1패치 맵을 생성하고, 상기 제 2영상정보를 N개의 패치로 분리하여 N개의 제 2영상정보패치를 생성하고, 상기 N개의 제 2영상정보패치로 구성되는 제 2패치 맵을 생성하고, 상기 N개의 제 1영상정보패치 중 제 1영상정보패치를 B개의 서브패치로 분리하고, 상기 제 1영상정보패치와 대응되는 상기 B개의 서브패치로 구성된 제 1서브패치군을 생성하고, 상기 N개의 모든 제 1영상정보패치에 대해순차적으로 상기 N개의 모든 제 1영상정보패치 각각에 대응되는 N개의 서브패치군을 생성하고, 상기 N개의 서브패치군으로 구성된 서브 패치 맵을 생성하여 서브 패치 맵을 생성하고,상기 제 1서브패치군을 구성하는 B개의 서브패치 색상정보 값을 합산하여 평균 값을 계산하고, 상기 평균 값을상기 B개의 서브패치의 색상정보 값으로 변경하고, 상기 변경된 색상정보 값이 반영된 B개의 서브패치로 구성된제 1평균서브패치군을 생성하고, 상기 N개의 모든 서브패치군에 대해 순차적으로 N개의 평균서브패치군을 생성하고, 상기 N개의 평균서브패치군으로 구성된 평균서브 패치 맵을 생성하고,상기 평균서브 패치 맵을 구성하는 N개의 평균서브패치군 중 제 1평균서브패치군의 위치좌표가, 상기 인체 레이블 맵을 구성하는 패치들의 위치좌표 중 하나의 위치좌표와 동일한 위치 좌표인 경우에 한해, 상기 N개의 평균서브패치군이 포함된 평균서브 패치 맵 중 제 1평균서브패치군을 둘러싸고 있는 복수개의 제 1 인접평균서브패치군을 설정하고, 상기 제 1평균서브패치군의 제 1가중치와, 상기 제 1평균서브패치군과 상기 복수개의 인접평균서브패치군 간의 이격 거리에 비례하여 상기 복수개의 평균서브패치군의 제 2가중치를 설정하고, 상기 제 1평균서브패치군에 상기 제 1가중치가 반영된 제 1색상정보 값과, 상기 복수개의 인접평균서브패치군의 색상정보에제 2가중치가 반영된 제 2색상정보 값의 평균 값을 반영하여 후면 색상정보 값을 생성하고, 상기 후면 색상정보값이 반영된 제 1후면서브패치군을 생성하고, 상기 평균서브패치 맵을 구성하는 N개의 모든 평균서브패치군에순차적으로 S개의 제 1후면서브패치군을 생성하고, 상기 평균서브 패치 맵을 구성하는 N개의 평균서브패치군 중 제 1평균서브패치군의 위치좌표가, 상기 인체 레이블 맵을 구성하는 패치들의 위치좌표 중 하나의 위치좌표와 동일한 위치 좌표가 아닌 경우, 상기 제 1평균서브패치군의 색상정보 값이 반영된 제 2후면서브패치군을 생성하고, 상기 평균서브패치 맵을 구성하는 N개의 모든평균서브패치군에 순차적으로 T개의 제 2후면서브패치군을 생성하고,상기 S개의 제 1후면서브패치군과, 상기 T개의 제 2후면서브패치군으로 구성되는 후면서브패치 맵을 생성하고, 상기 복수개의 제 1인접 평균서브패치군은,상기 복수개의 제 1인접 평균서브패치군의 위치좌표가 상기 인체 레이블 맵을 구성하는 패치들의 위치좌표 중하나의 위치좌표와 동일한 위치 좌표이고, 상기 제 1가중치는 상기 제 2가중치 보다 큰 값으로 설정되고,상기 제 1가중치와 상기 복수개의 제 1 인접평균서브패치군에 설정된 제 2가중치들의 합이 1이고, 공개특허 10-2023-0083348-4-상기 제 1 가중치인 C는 이고, 상기 제 2 가중치인 w는이고,상기 제 1가중치와 상기 제 2가중치들의 상관 관계식인 W은 이고, 상기 Z는 상기 제 1평균서브패치군과, 상기 복수개의 제 1 인접평균서브패치군의 패치군수의 합이고, 상기 패치, 서브패치는 복수개의 픽셀로 구성되고, 상기 픽셀은 상기 픽셀의 주소 값, 상기 픽셀의 위치정보 및상기 픽셀의 색상정보가 저장되어 있는 것을 특징으로 하는 컨텐츠 제작 플랫폼."}
{"patent_id": "10-2021-0170533", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "공지의 인공신경망 소프트웨어가 적용된 서버와, 단말로 구성되고, 상기 서버와 상기 단말 간 정보를 상호 송수신하는 컨텐츠 제작 방법에 있어서,상기 단말은 N개의 영상정보로 구성되는 영상정보군 중 제 1영상정보와, 상기 제 1영상정보와 대응되는 주소값을 저장하는 제 1프레임을 생성하여 상기 제 1프레임을 저장하는 단계;와 상기 단말은 상기 영상정보군의 모든 N개의 영상정보에 대해 순차적으로 상기 N개의 영상정보와, 상기 N개의 영상정보와 대응되는 주소 값들을 저장하는 N개의 프레임들을 생성하여, 상기 N개의 프레임들을 저장하고, 상기 N개의 프레임들을 상기 서버로 송신하는 단계;상기 서버는 상기 수신된 N개의 프레임들 중 상기 제 1프레임의 제 1영상정보를 추출하고, 상기 제 1영상정보로부터 M개의 관절 좌표로 구성된 휴먼포즈 데이터를 생성하고, 상기 제 1영상정보로부터 상기 M개의 관절 좌표와대응되는 레이블을 생성하고, 상기 제 1영상정보로부터 메쉬 데이터을 생성하는 단계;상기 서버는 상기 수신된 모든 N개의 프레임들에 대해 순차적으로 영상정보들을 추출하고, 상기 영상정보들로부터 M개의 관절 좌표로 구성된 휴먼포즈 데이터들을 생성하고, 상기 영상정보들로부터 상기 M개의 관절 좌표와대응되는 레이블들로 구성된 레이블 맵들을 생성하고, 상기 N개의 영상정보들로부터 메쉬 데이터들을 생성하여,상기 휴먼포즈 데이터들과 상기 휴먼포즈 데이터들과 대응되는 주소 값들과, 상기 레이블 맵들과 상기 레이블맵들과 대응되는 주소 값들과, 상기 메쉬 데이터들과 상기 메쉬 데이터들과 대응되는 주소 값들을 상기 N개의프레임들에 저장하고, 상기 N개의 프레임들을 상기 단말로 송신하는 단계;상기 단말은, 상기 수신된 N개의 프레임들로부터 추출된 상기 휴먼포즈 데이터들과, 상기 레이블 맵 및 상기 메쉬 데이터들을 이용하여 N개의 영상정보로 구성되는 영상정보군과 대응되는 컨텐츠를 생성하는 단계를포함하고, 상기 단말로 송신하는 단계는,상기 단말은 상기 추출된 휴먼포즈 데이터들을 칼만 필터 및 저주파 통과 필터를 적용하여 보정된 휴먼포즈 데이터들을 생성하고, 상기 추출된 휴먼포즈 데이터들을 상기 보정된 휴먼포즈 데이터들로 대체하는 단계를 더 포함하고, 상기 단말로 송신하는 단계는, 상기 서버는 상기 N개의 프레임들 중 A개의 제 2프레임들에 대해서, 상기 A개의 제 2프레임들에 대응되는 휴먼포즈 데이터들, 레이블들 및 메쉬 데이터들의 미생성 요청정보를 수신한 경우에 한해, 상기 미생성 요청정보에 따라, 상기 A개의 제 2프레임들에 대한 휴먼포즈 데이터들, 레이블들 및 메쉬 데이터들을 미생성하여, 상기 휴먼포즈 데이터들, 레이블들 및 메쉬 데이터들이 저장되지 않은 A개의 제 2프레임들과,공개특허 10-2023-0083348-5-휴먼포즈 데이터들, 레이블들 및 메쉬 데이터들이 저장된 N-A개의 프레임들을 상기 단말로 송신하는 단계;와, 상기 단말은, 상기 수신된 A개의 제 2프레임들의 일련번호가 상기 N-A개의 프레임들의 일련번호와 가장 가까운프레임들을 설정하고, 상기 수신된 A개의 제 2프레임들의 휴먼포즈 데이터들, 레이블들 및 메쉬 데이터들을 상기 가장 가까운 프레임들의 휴먼포즈 데이터들, 레이블들 및 메쉬 데이터들로 반영하는 저장하는 단계;를 포함하고,상기 프레임들은 일련의 프레임 번호들이 저장되어 있는 것을 특징으로 하는, 컨텐츠 제작 방법."}
{"patent_id": "10-2021-0170533", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제 5항에 있어서,상기 N개의 영상정보로 구성되는 영상정보군이 정면의 인체정보를 포함하고, 상기 정면의 인체정보와 대응되는후면정보가 포함되어 있지 않은 경우,상기 서버는 상기 M개의 관절 좌표 중 제 1 관절 좌표와 상기 레이블 맵의 이격 거리가 기 설정된 이격 거리 이하인 경우, 상기 레이블 맵을 상기 제 1 관절 좌표에 대응되는 제 1인체 레이블로 생성하는 단계;상기 단말은 상기 제 1인체 레이블을 생성하는 단계를 상기 M개의 모든 관절 좌표에 대해 순차적으로 수행하여,M개의 인체 레이블을 생성하고, 상기 M개의 인체 레이블로 구성된 인체 레이블 맵을 생성하는 단계;상기 단말은 상기 M개의 관절 좌표와 상기 레이블 맵의 이격 거리가 기 설정된 이격 거리를 초과한 경우, 비인체 레이블 맵을 생성하고, 상기 인체 레이블 맵과 상기 비인체 레이블 맵으로 구성되는 제 2영상 정보를 생성하는 단계;상기 단말은 상기 제 1영상정보를 N개의 패치로 분리하여 N개의 제 1영상정보패치를 생성하고, 상기 N개의 제 1영상정보패치로 구성되는 제 1패치 맵을 생성하는 단계;상기 단말은 상기 제 2영상정보를 N개의 패치로 분리하여 N개의 제 2영상정보패치를 생성하고, 상기 N개의 제 2영상정보패치로 구성되는 제 2패치 맵을 생성하는 단계;상기 단말은 상기 N개의 제 1영상정보패치 중 제 1영상정보패치를 B개의 서브패치로 분리하고, 상기 제 1영상정보패치와 대응되는 상기 B개의 서브패치로 구성된 제 1서브패치군을 생성하는 단계;상기 단말은 상기 제 1서브패치군을 생성하는 단계를 상기 N개의 모든 제 1영상정보패치에 대해 순차적으로 수행하여, 상기 N개의 모든 제 1영상정보패치 각각에 대응되는 N개의 서브패치군을 생성하고, 상기 N개의 서브패치군으로 구성된 서브 패치 맵을 생성하는 단계;상기 단말은 상기 제 1서브패치군을 구성하는 B개의 서브패치 색상정보 값을 합산하여 평균 값을 계산하고, 상기 평균 값을 상기 B개의 서브패치의 색상정보 값으로 변경하고, 상기 변경된 색상정보 값이 반영된 B개의 서브패치로 구성된 제 1평균서브패치군을 생성하는 단계;상기 단말은 상기 제 1평균서브패치군을 생성하는 단계를 상기 N개의 모든 서브패치군에 대해 순차적으로 수행하여, N개의 평균서브패치군을 생성하고, 상기 N개의 평균서브패치군으로 구성된 평균서브 패치 맵을 생성하는단계;상기 단말은 상기 N개의 평균서브패치군이 포함된 평균서브 패치 맵 중 제 1평균서브패치군을 둘러싸고 있는 복수개의 제 1 인접평균서브패치군을 설정하고, 상기 제 1평균서브패치군의 제 1가중치와, 상기 제 1평균서브패치군과 상기 복수개의 인접평균서브패치군 간의 이격 거리에 비례하여 상기 복수개의 평균서브패치군의 제 2가중치를 설정하고, 상기 제 1평균서브패치군에 상기 제 1가중치가 반영된 제 1색상정보 값과, 상기 복수개의 인접평균서브패치군의 색상정보에 제 2가중치가 반영된 제 2색상정보 값의 평균 값을 반영하여 후면 색상정보 값을생성하고, 상기 후면 색상정보 값이 반영된 후면서브패치군을 생성하는 단계; 및상기 단말은 상기 후면서브패치군을 생성하는 단계를 상기 평균서브패치 맵을 구성하는 N개의 모든 평균서브패치군에 순차적으로 수행하여, N개의 후면서브패치군을 생성하고, 상기 N개의 후면서브패치군으로 구성되는 후면서브패치 맵을 생성하는 단계;를 더 포함하고, 상기 패치, 서브패치는 복수개의 픽셀로 구성되고, 상기 픽셀은 상기 픽셀의 주소 값, 상기 픽셀의 위치정보 및상기 픽셀의 색상정보가 저장되어 있고,공개특허 10-2023-0083348-6-상기 후면 색상정보 값이 반영된 후면서브패치군을 생성하는 단계는, 상기 평균서브 패치 맵을 구성하는 N개의평균서브패치군 중 제 1평균서브패치군의 위치좌표가, 상기 인체 레이블 맵을 구성하는 패치들의 위치좌표 중하나의 위치좌표와 동일한 위치 좌표인 경우에 한해, 상기 후면 색상정보 값이 반영된 제 1후면서브패치군을 생성하고, 상기 평균서브 패치 맵을 구성하는 N개의 평균서브패치군 중 제 1평균서브패치군의 위치좌표가, 상기인체 레이블 맵을 구성하는 패치들의 위치좌표 중 하나의 위치좌표와 동일한 위치 좌표가 아닌 경우, 상기 제 1평균서브패치군의 색상정보 값이 반영된 제 2후면서브패치군을 생성하고, 상기 N개의 후면서브패치군으로 구성되는 후면서브패치 맵을 생성하는 단계는, 상기 평균서브 패치 맵을 구성하는 N개의 평균서브패치군 중 제 1평균서브패치군의 위치좌표가, 상기 인체 레이블 맵을 구성하는 패치들의 위치좌표 중 하나의 위치좌표와 동일한 위치 좌표인 경우에 한해, 상기 후면 색상정보 값이 반영된 후면서브패치군을 생성하는 단계를 상기 평균서브패치 맵을 구성하는 N개의 모든 평균서브패치군에 순차적으로 수행하여, S개의 제 1후면서브패치군을 생성하고, 상기 평균서브 패치 맵을 구성하는 N개의 평균서브패치군 중 제 1평균서브패치군의 위치좌표가, 상기 인체 레이블 맵을 구성하는 패치들의 위치좌표 중 하나의 위치좌표와 동일한 위치 좌표가 아닌 경우, 상기 제 1평균서브패치군의 색상정보 값이 반영된 제 2후면서브패치군을 생성하는 단계를 상기 평균서브패치 맵을 구성하는 N개의모든 평균서브패치군에 순차적으로 수행하여, T개의 제 2후면서브패치군을 생성하여, 상기 S개의 제 1후면서브패치군과, 상기 T개의 제 2후면서브패치군으로 구성되는 후면서브패치 맵을 생성하고,상기 복수개의 제 1인접 평균서브패치군은,상기 복수개의 제 1인접 평균서브패치군의 위치좌표가 상기 인체 레이블 맵을 구성하는 패치들의 위치좌표 중하나의 위치좌표와 동일한 위치 좌표인 것이고,상기 제 1가중치는 상기 제 2가중치 보다 큰 값으로 설정되고,상기 제 1가중치와 상기 복수개의 제 1 인접평균서브패치군에 설정된 제 2가중치들의 합이 1이고, 상기 제 1 가중치인 C는 이고, 상기 제 2 가중치인 w는이고,상기 제 1가중치와 상기 제 2가중치들의 상관 관계식인 W은 이고, 상기 Z는 상기 제 1평균서브패치군과, 상기 복수개의 제 1 인접평균서브패치군의 패치군수의 합이고, 상기 패치, 서브패치는 복수개의 픽셀로 구성되고, 상기 픽셀은 상기 픽셀의 주소 값, 상기 픽셀의 위치정보 및상기 픽셀의 색상정보가 저장되어 있는 것을 특징으로 하는 컨텐츠 제작 방법."}
{"patent_id": "10-2021-0170533", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 공지의 인공신경망 소프트웨어가 적용된 서버와, 단말로 구성되고, 상기 서버와 상기 단말 간 정보를 상호 송수신하는 컨텐츠 제작 플랫폼에 있어서, N개의 영상정보로 구성되는 영상정보군 중 제 1영상정보와, 상기 제 1영상정보와 대응되는 주소값을 저장하는 제 1프레임을 생성하여 상기 제 1프레임을 저장하고, 상기 영상정보 (뒷면에 계속)"}
{"patent_id": "10-2021-0170533", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 컨텐츠 제작 방법 및 시스템에 관한 것으로서, 심층인공신경망을 이용하여 입력된 영상으로부터 휴먼 포즈 데이터, 레이블 맵 및 3D 메쉬데이터를 추출하여 사용자가 필요한 컨텐츠를 제작하는 방법 및 플랫폼을 제 공하는 것에 관한 것이다."}
{"patent_id": "10-2021-0170533", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "최근 심층신경망 기반의 인공지능을 적용한 다양한 연구와 상용화가 활발해 지고 있다. 또한, 인공신경망과 연 계하여 실시간으로 사용자와 상호작용을 구현하는 컨텐츠에 대해 수요가 증가하고 있다. 체험형 컨텐츠 장치는 기존 박물관이나 전시장과 같은 여러 사람이 모인 장소에 주로 설치되어 운영되고 있고, 체험형 컨텐츠 장치는 대부분 연결된 기기의 버튼을 접촉하여 누르는 방식이 보편적이고, 사용자들이 해당 장치 를 접촉하여 매번 충격이 누적되기 때문에 기기 자체의 내구성이 빠르게 소모되는 문제점이 있다. 또한, 해당 장치의 제어기기가 고정되어 배치되기 때문에, 여러 사용자가 동시에 사용하기 어려운 것이 현실이다. 이에 따라, 최근, 체험형 컨텐츠 장치는 증강현실(AR, Augmented Reality) 기술을 적용한 체험형 컨텐츠가 각광 받고 있는 추세이다. 증강현실 기술을 적용한 실감형 컨텐츠는 카메라 영상 데이터를 입력받아 기존 영상처리 기술과 컴퓨터비전 기술을 활용하여 간단한 동작이나 거리를 추정하여 체험형 콘텐츠를 주로 제공한다. 또한, 하드웨어의 발전으로 인해 그래픽 처리 장치(GPU)의 성능이 상승됨으로 인해 기존에 존재하던 신경망 구조의 인 공지능 기술의 실제 구현이 가능해지고, 더 발전한 심층신경망(DNN, Deep Neural Networks)의 형태가 주류로 각 광 받으며 관련 연구와 동시에 상용화가 빠르게 이루어지고 있다. 이에 따라 소비자가 원하는 체험형 콘텐츠의 인식 기술의 수준도 올라갔으며, 인공지능을 이용한 사용자 상호작용을 적용하려고 많은 시도가 일어나고 있는 상황이다. 증강현실 체험형 컨텐츠의 상호작용을 제공하기 위해서, 고사양의 그래픽 처리 장치의 사용이 필요한 상황이다. 그러나 사용자들은 고사양의 개인용 컴퓨터를 보유하지 않고 현재 널리 보급된 스마트폰을 이용하는 추세이다. 따라서, 현재의 체험형 컨텐츠는 박물관이나 전시관 뿐만 아니라 사용자의 자택이나 회사 등 어느 곳에서도 스 마트폰 기반으로 작동 가능하도록 개발되고 있다. 따라서, 스마트폰이나 개인용 컴퓨터 등의 저사양 기기에서도 풍부한 상호작용 기술을 제공하는 증강현실 체험 형 컨텐츠의 발전과, 다양한 사용자의 취향에 맞춤 콘텐츠 제작과 활성화를 위해서, 효율적인 신경망 연산 처리 및 콘텐츠 제작, 콘텐츠 플랫폼 구조에 대해 연구가 필요하다. 선행기술문헌 특허문헌 (특허문헌 0001) 대한민국 등록번호공보 10-2245220(2021.04.27. 공고) (특허문헌 0002) 대한민국 공개특허공보 10-1906431(2018.10.11. 공고) (특허문헌 0003) 대한민국 공개특허공보 10-1829733(2018.02.09. 공고)"}
{"patent_id": "10-2021-0170533", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 인공신경망 소프트웨어가 적용된 서버와, 단말로 구성되고, 상기 서버와 상기 단말 간 정보를 상호 송수신하여, 상기 정보를 기초로 영상을 생성하고 제공하는 컨텐츠 제작 플랫폼 및 방법을 제공하는 것을 과제 로 한다."}
{"patent_id": "10-2021-0170533", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기 과제를 해결하기 위한 컨텐츠 제작 플랫폼은, 공지의 인공신경망 소프트웨어가 적용된 서버와, 단말로 구성되고, 상기 서버와 상기 단말 간 정보를 상호 송수 신하는 컨텐츠 제작 플랫폼에 있어서, N개의 영상정보로 구성되는 영상정보군 중 제 1영상정보와, 상기 제 1영 상정보와 대응되는 주소값을 저장하는 제 1프레임을 생성하여 상기 제 1프레임을 저장하고, 상기 영상정보군의 모든 N개의 영상정보에 대해 순차적으로 상기 N개의 영상정보와, 상기 N개의 영상정보와 대응되는 주소 값들을 저장하는 N개의 프레임들을 생성하여, 상기 N개의 프레임들을 저장하고, 상기 N개의 프레임들을 상기 서버로 송 신하는 단말과, 상기 수신된 N개의 프레임들 중 상기 제 1프레임의 제 1영상정보를 추출하고, 상기 제 1영상정보로부터 M개의 관절 좌표로 구성된 휴먼포즈 데이터를 생성하고, 상기 제 1영상정보로부터 상기 M개의 관절 좌 표와 대응되는 레이블을 생성하고, 상기 제 1영상정보로부터 메쉬 데이터을 생성하고, 상기 수신된 모든 N개의 프레임들에 대해 순차적으로 영상정보들을 추출하고, 상기 영상정보들로부터 M개의 관절 좌표로 구성된 휴먼포 즈 데이터들을 생성하고, 상기 영상정보들로부터 상기 M개의 관절 좌표와 대응되는 레이블들로 구성된 레이블 맵들을 생성하고, 상기 N개의 영상정보들로부터 메쉬 데이터들을 생성하여, 상기 휴먼포즈 데이터들과 상기 휴 먼포즈 데이터들과 대응되는 주소 값들과, 상기 레이블 맵들과 상기 레이블 맵들과 대응되는 주소 값들과, 상기 메쉬 데이터들과 상기 메쉬 데이터들과 대응되는 주소 값들을 상기 N개의 프레임들에 저장하고, 상기 N개의 프 레임들을 상기 단말로 송신하는 서버와, 상기 단말은, 상기 수신된 N개의 프레임들로부터 추출된 상기 휴먼포즈 데이터들과, 상기 레이블 맵 및 상기 메쉬 데이터들을 이용하여 N개의 영상정보로 구성되는 영상정보군과 대응 되는 컨텐츠를 생성하고, 상기 프레임들은 일련의 프레임 번호들이 저장되어 있는 것을 특징으로 한다. 또한, 상기 단말은, 상기 추출된 휴먼포즈 데이터들을 칼만 필터 및 저주파 통과 필터를 적용하여 보정된 휴먼 포즈 데이터들을 생성하고, 상기 추출된 휴먼포즈 데이터들을 상기 보정된 휴먼포즈 데이터들로 대체하는 것을 특징으로 한다. 또한, 상기 서버는, 상기 N개의 프레임들 중 A개의 제 2프레임들에 대해서, 상기 A개의 제 2프레임들에 대응되 는 휴먼포즈 데이터들, 레이블들 및 메쉬 데이터들의 미생성 요청정보를 수신한 경우, 상기 미생성 요청정보에 따라, 상기 A개의 제 2프레임들에 대한 휴먼포즈 데이터들, 레이블들 및 메쉬 데이터들을 미생성하여, 상기 휴 먼포즈 데이터들, 레이블들 및 메쉬 데이터들이 저장되지 않은 A개의 제 2프레임들과, 휴먼포즈 데이터들, 레이 블들 및 메쉬 데이터들이 저장된 N-A개의 프레임들을 상기 단말로 송신하고, 상기 단말은, 상기 수신된 A개의 제 2프레임들의 일련번호가 상기 N-A개의 프레임들의 일련번호와 가장 가까운 프레임들을 설정하여, 상기 수신 된 A개의 제 2프레임들의 휴먼포즈 데이터들, 레이블들 및 메쉬 데이터들을 상기 설정된 가장 가까운 프레임들 의 휴먼포즈 데이터들, 레이블들 및 메쉬 데이터들로 반영하여 저장하는 것을 특징으로 한다. 또한, 상기 N개의 영상정보로 구성되는 영상정보군이 정면의 인체정보를 포함하고, 상기 정면의 인체정보와 대 응되는 후면정보가 포함되어 있지 않은 경우, 상기 서버는 상기 M개의 관절 좌표 중 제 1 관절 좌표와 상기 레 이블 맵과의 이격 거리가 기 설정된 이격 거리 이하인 경우, 상기 레이블 맵을 상기 제 1 관절 좌표에 대응되는 제 1인체 레이블로 생성하고, 상기 M개의 모든 관절 좌표에 대해서 순차적으로 M개의 인체 레이블을 생성하고, 상기 M개의 인체 레이블로 구성된 인체 레이블 맵을 생성하고, 상기 M개의 관절 좌표와 상기 레이블 맵의 이격 거리가 기 설정된 이격 거리를 초과한 경우, 비인체 레이블 맵을 생성하고, 상기 인체 레이블 맵과 상기 비인체 레이블 맵으로 구성되는 제 2영상 정보를 생성하고, 상기 제 1영상정보를 N개의 패치로 분리하여 N개의 제 1영 상정보패치를 생성하고, 상기 N개의 제 1영상정보패치로 구성되는 제 1패치 맵을 생성하고, 상기 제 2영상정보 를 N개의 패치로 분리하여 N개의 제 2영상정보패치를 생성하고, 상기 N개의 제 2영상정보패치로 구성되는 제 2 패치 맵을 생성하고, 상기 N개의 제 1영상정보패치 중 제 1영상정보패치를 B개의 서브패치로 분리하고, 상기 제 1영상정보패치와 대응되는 상기 B개의 서브패치로 구성된 제 1서브패치군을 생성하고, 상기 N개의 모든 제 1영 상정보패치에 대해 순차적으로 상기 N개의 모든 제 1영상정보패치 각각에 대응되는 N개의 서브패치군을 생성하 고, 상기 N개의 서브패치군으로 구성된 서브 패치 맵을 생성하여 서브 패치 맵을 생성하고, 상기 제 1서브패치 군을 구성하는 B개의 서브패치 색상정보 값을 합산하여 평균 값을 계산하고, 상기 평균 값을 상기 B개의 서브패 치의 색상정보 값으로 변경하고, 상기 변경된 색상정보 값이 반영된 B개의 서브패치로 구성된 제 1평균서브패치 군을 생성하고, 상기 N개의 모든 서브패치군에 대해 순차적으로 N개의 평균서브패치군을 생성하고, 상기 N개의 평균서브패치군으로 구성된 평균서브 패치 맵을 생성하고, 상기 평균서브 패치 맵을 구성하는 N개의 평균서브패 치군 중 제 1평균서브패치군의 위치좌표가, 상기 인체 레이블 맵을 구성하는 패치들의 위치좌표 중 하나의 위치 좌표와 동일한 위치 좌표인 경우에 한해, 상기 N개의 평균서브패치군이 포함된 평균서브 패치 맵 중 제 1평균서 브패치군을 둘러싸고 있는 복수개의 제 1 인접평균서브패치군을 설정하고, 상기 제 1평균서브패치군의 제 1가중 치와, 상기 제 1평균서브패치군과 상기 복수개의 인접평균서브패치군 간의 이격 거리에 비례하여 상기 복수개의 평균서브패치군의 제 2가중치를 설정하고, 상기 제 1평균서브패치군에 상기 제 1가중치가 반영된 제 1색상정보 값과, 상기 복수개의 인접평균서브패치군의 색상정보에 제 2가중치가 반영된 제 2색상정보 값의 평균 값을 반영 하여 후면 색상정보 값을 생성하고, 상기 후면 색상정보 값이 반영된 제 1후면서브패치군을 생성하고, 상기 평 균서브패치 맵을 구성하는 N개의 모든 평균서브패치군에 순차적으로 S개의 제 1후면서브패치군을 생성하고, 상 기 평균서브 패치 맵을 구성하는 N개의 평균서브패치군 중 제 1평균서브패치군의 위치좌표가, 상기 인체 레이블 맵을 구성하는 패치들의 위치좌표 중 하나의 위치좌표와 동일한 위치 좌표가 아닌 경우, 상기 제 1평균서브패치 군의 색상정보 값이 반영된 제 2후면서브패치군을 생성하고, 상기 평균서브패치 맵을 구성하는 N개의 모든 평균 서브패치군에 순차적으로 T개의 제 2후면서브패치군을 생성하고, 상기 S개의 제 1후면서브패치군과, 상기 T개의제 2후면서브패치군으로 구성되는 후면서브패치 맵을 생성하고, 상기 복수개의 제 1인접 평균서브패치군은, 상 기 복수개의 제 1인접 평균서브패치군의 위치좌표가 상기 인체 레이블 맵을 구성하는 패치들의 위치좌표 중 하 나의 위치좌표와 동일한 위치 좌표이고, 상기 제 1가중치는 상기 제 2가중치 보다 큰 값으로 설정되고, 상기 제 1가중치와 상기 복수개의 제 1 인접평균서브패치군에 설정된 제 2가중치들의 합이 1이고, 상기 제 1 가중치인 C 는 이고, 상기 제 2 가중치인 w는 이고, 상기 제 1가중치와 상기 제 2가중치들의 상 관 관계식인 W은 이고, 상기 Z는 상기 제 1평균서브패치군과, 상기 복수개의 제 1 인 접평균서브패치군의 패치군수의 합이고, 상기 패치, 서브패치는 복수개의 픽셀로 구성되고, 상기 픽셀은 상기 픽셀의 주소 값, 상기 픽셀의 위치정보 및 상기 픽셀의 색상정보가 저장되어 있는 것을 특징으로 한다. 상기 과제를 해결하기 위한 컨텐츠 제작 방법은 공지의 인공신경망 소프트웨어가 적용된 서버와, 단말로 구성되 고, 상기 서버와 상기 단말 간 정보를 상호 송수신하는 컨텐츠 제작 방법에 있어서, 상기 단말은 N개의 영상정 보로 구성되는 영상정보군 중 제 1영상정보와, 상기 제 1영상정보와 대응되는 주소값을 저장하는 제 1프레임을 생성하여 상기 제 1프레임을 저장하는 단계와, 상기 단말은 상기 영상정보군의 모든 N개의 영상정보에 대해 순 차적으로 상기 N개의 영상정보와, 상기 N개의 영상정보와 대응되는 주소 값들을 저장하는 N개의 프레임들을 생 성하여, 상기 N개의 프레임들을 저장하고, 상기 N개의 프레임들을 상기 서버로 송신하는 단계와, 상기 서버는 상기 수신된 N개의 프레임들 중 상기 제 1프레임의 제 1영상정보를 추출하고, 상기 제 1영상정보로부터 M개의 관절 좌표로 구성된 휴먼포즈 데이터를 생성하고, 상기 제 1영상정보로부터 상기 M개의 관절 좌표와 대응되는 레이블을 생성하고, 상기 제 1영상정보로부터 메쉬 데이터을 생성하는 단계와, 상기 서버는 상기 수신된 모든 N 개의 프레임들에 대해 순차적으로 영상정보들을 추출하고, 상기 영상정보들로부터 M개의 관절 좌표로 구성된 휴 먼포즈 데이터들을 생성하고, 상기 영상정보들로부터 상기 M개의 관절 좌표와 대응되는 레이블들로 구성된 레이 블 맵들을 생성하고, 상기 N개의 영상정보들로부터 메쉬 데이터들을 생성하여, 상기 휴먼포즈 데이터들과 상기 휴먼포즈 데이터들과 대응되는 주소 값들과, 상기 레이블 맵들과 상기 레이블 맵들과 대응되는 주소 값들과, 상 기 메쉬 데이터들과 상기 메쉬 데이터들과 대응되는 주소 값들을 상기 N개의 프레임들에 저장하고, 상기 N개의 프레임들을 상기 단말로 송신하는 단계와, 상기 단말은, 상기 수신된 N개의 프레임들로부터 추출된 상기 휴먼포 즈 데이터들과, 상기 레이블 맵 및 상기 메쉬 데이터들을 이용하여 N개의 영상정보로 구성되는 영상정보군과 대 응되는 컨텐츠를 생성하는 단계를 포함하고, 상기 단말로 송신하는 단계는, 상기 단말은 상기 추출된 휴먼포즈 데이터들을 칼만 필터 및 저주파 통과 필터를 적용하여 보정된 휴먼포즈 데이터들을 생성하고, 상기 추출된 휴 먼포즈 데이터들을 상기 보정된 휴먼포즈 데이터들로 대체하는 단계를 더 포함하고, 상기 단말로 송신하는 단계 는, 상기 서버는 상기 N개의 프레임들 중 A개의 제 2프레임들에 대해서, 상기 A개의 제 2프레임들에 대응되는 휴먼포즈 데이터들, 레이블들 및 메쉬 데이터들의 미생성 요청정보를 수신한 경우에 한해, 상기 미생성 요청정 보에 따라, 상기 A개의 제 2프레임들에 대한 휴먼포즈 데이터들, 레이블들 및 메쉬 데이터들을 미생성하여, 상 기 휴먼포즈 데이터들, 레이블들 및 메쉬 데이터들이 저장되지 않은 A개의 제 2프레임들과, 휴먼포즈 데이터들, 레이블들 및 메쉬 데이터들이 저장된 N-A개의 프레임들을 상기 단말로 송신하는 단계;와, 상기 단말은, 상기 수 신된 A개의 제 2프레임들의 일련번호가 상기 N-A개의 프레임들의 일련번호와 가장 가까운 프레임들을 설정하고, 상기 수신된 A개의 제 2프레임들의 휴먼포즈 데이터들, 레이블들 및 메쉬 데이터들을 상기 가장 가까운 프레임 들의 휴먼포즈 데이터들, 레이블들 및 메쉬 데이터들로 반영하는 저장하는 단계;를 포함하고, 상기 프레임들은 일련의 프레임 번호들이 저장되어 있는 것을 특징으로 한다. 또한, 상기 N개의 영상정보로 구성되는 영상정보군이 정면의 인체정보를 포함하고, 상기 정면의 인체정보와 대 응되는 후면정보가 포함되어 있지 않은 경우,, 상기 서버는 상기 M개의 관절 좌표 중 제 1 관절 좌표와 상기 레 이블 맵의 이격 거리가 기 설정된 이격 거리 이하인 경우, 상기 레이블 맵을 상기 제 1 관절 좌표에 대응되는 제 1인체 레이블로 생성하는 단계와, 상기 단말은 상기 제 1인체 레이블을 생성하는 단계를 상기 M개의 모든 관 절 좌표에 대해 순차적으로 수행하여, M개의 인체 레이블을 생성하고, 상기 M개의 인체 레이블로 구성된 인체 레이블 맵을 생성하는 단계와, 상기 단말은 상기 M개의 관절 좌표와 상기 레이블 맵의 이격 거리가 기 설정된 이격 거리를 초과한 경우, 비인체 레이블 맵을 생성하고, 상기 인체 레이블 맵과 상기 비인체 레이블 맵으로 구 성되는 제 2영상 정보를 생성하는 단계와, 상기 단말은 상기 제 1영상정보를 N개의 패치로 분리하여 N개의 제 1 영상정보패치를 생성하고, 상기 N개의 제 1영상정보패치로 구성되는 제 1패치 맵을 생성하는 단계와, 상기 단말 은 상기 제 2영상정보를 N개의 패치로 분리하여 N개의 제 2영상정보패치를 생성하고, 상기 N개의 제 2영상정보패치로 구성되는 제 2패치 맵을 생성하는 단계와, 상기 단말은 상기 N개의 제 1영상정보패치 중 제 1영상정보패 치를 B개의 서브패치로 분리하고, 상기 제 1영상정보패치와 대응되는 상기 B개의 서브패치로 구성된 제 1서브패 치군을 생성하는 단계와, 상기 단말은 상기 제 1서브패치군을 생성하는 단계를 상기 N개의 모든 제 1영상정보패 치에 대해 순차적으로 수행하여, 상기 N개의 모든 제 1영상정보패치 각각에 대응되는 N개의 서브패치군을 생성 하고, 상기 N개의 서브패치군으로 구성된 서브 패치 맵을 생성하는 단계와, 상기 단말은 상기 제 1서브패치군을 구성하는 B개의 서브패치 색상정보 값을 합산하여 평균 값을 계산하고, 상기 평균 값을 상기 B개의 서브패치의 색상정보 값으로 변경하고, 상기 변경된 색상정보 값이 반영된 B개의 서브패치로 구성된 제 1평균서브패치군을 생성하는 단계와, 상기 단말은 상기 제 1평균서브패치군을 생성하는 단계를 상기 N개의 모든 서브패치군에 대해 순차적으로 수행하여, N개의 평균서브패치군을 생성하고, 상기 N개의 평균서브패치군으로 구성된 평균서브 패치 맵을 생성하는 단계와, 상기 단말은 상기 N개의 평균서브패치군이 포함된 평균서브 패치 맵 중 제 1평균서브패 치군을 둘러싸고 있는 복수개의 제 1 인접평균서브패치군을 설정하고, 상기 제 1평균서브패치군의 제 1가중치와, 상기 제 1평균서브패치군과 상기 복수개의 인접평균서브패치군 간의 이격 거리에 비례하여 상기 복 수개의 평균서브패치군의 제 2가중치를 설정하고, 상기 제 1평균서브패치군에 상기 제 1가중치가 반영된 제 1색 상정보 값과, 상기 복수개의 인접평균서브패치군의 색상정보에 제 2가중치가 반영된 제 2색상정보 값의 평균 값 을 반영하여 후면 색상정보 값을 생성하고, 상기 후면 색상정보 값이 반영된 후면서브패치군을 생성하는 단계 및 상기 단말은 상기 후면서브패치군을 생성하는 단계를 상기 평균서브패치 맵을 구성하는 N개의 모든 평균서브 패치군에 순차적으로 수행하여, N개의 후면서브패치군을 생성하고, 상기 N개의 후면서브패치군으로 구성되는 후 면서브패치 맵을 생성하는 단계를 더 포함하고, 상기 패치, 서브패치는 복수개의 픽셀로 구성되고, 상기 픽셀은 상기 픽셀의 주소 값, 상기 픽셀의 위치정보 및 상기 픽셀의 색상정보가 저장되어 있고, 상기 후면 색상정보 값 이 반영된 후면서브패치군을 생성하는 단계는, 상기 평균서브 패치 맵을 구성하는 N개의 평균서브패치군 중 제 1평균서브패치군의 위치좌표가, 상기 인체 레이블 맵을 구성하는 패치들의 위치좌표 중 하나의 위치좌표와 동일 한 위치 좌표인 경우에 한해, 상기 후면 색상정보 값이 반영된 제 1후면서브패치군을 생성하고, 상기 평균서브 패치 맵을 구성하는 N개의 평균서브패치군 중 제 1평균서브패치군의 위치좌표가, 상기 인체 레이블 맵을 구성하 는 패치들의 위치좌표 중 하나의 위치좌표와 동일한 위치 좌표가 아닌 경우, 상기 제 1평균서브패치군의 색상정 보 값이 반영된 제 2후면서브패치군을 생성하고, 상기 N개의 후면서브패치군으로 구성되는 후면서브패치 맵을 생성하는 단계는, 상기 평균서브 패치 맵을 구성하는 N개의 평균서브패치군 중 제 1평균서브패치군의 위치좌표 가, 상기 인체 레이블 맵을 구성하는 패치들의 위치좌표 중 하나의 위치좌표와 동일한 위치 좌표인 경우에 한해, 상기 후면 색상정보 값이 반영된 후면서브패치군을 생성하는 단계를 상기 평균서브패치 맵을 구성하는 N 개의 모든 평균서브패치군에 순차적으로 수행하여, S개의 제 1후면서브패치군을 생성하고, 상기 평균서브 패치 맵을 구성하는 N개의 평균서브패치군 중 제 1평균서브패치군의 위치좌표가, 상기 인체 레이블 맵을 구성하는 패 치들의 위치좌표 중 하나의 위치좌표와 동일한 위치 좌표가 아닌 경우, 상기 제 1평균서브패치군의 색상정보 값 이 반영된 제 2후면서브패치군을 생성하는 단계를 상기 평균서브패치 맵을 구성하는 N개의 모든 평균서브패치군 에 순차적으로 수행하여, T개의 제 2후면서브패치군을 생성하여, 상기 S개의 제 1후면서브패치군과, 상기 T개의 제 2후면서브패치군으로 구성되는 후면서브패치 맵을 생성하고, 상기 복수개의 제 1인접 평균서브패치군은, 상 기 복수개의 제 1인접 평균서브패치군의 위치좌표가 상기 인체 레이블 맵을 구성하는 패치들의 위치좌표 중 하 나의 위치좌표와 동일한 위치 좌표인 것이고, 상기 제 1가중치는 상기 제 2가중치 보다 큰 값으로 설정되고, 상 기 제 1가중치와 상기 복수개의 제 1 인접평균서브패치군에 설정된 제 2가중치들의 합이 1이고, 상기 제 1 가중 치인 C는 이고, 상기 제 2 가중치인 w는 이고, 상기 제 1가중치와 상기 제 2가중치 들의 상관 관계식인 W은 이고, 상기 Z는 상기 제 1평균서브패치군과, 상기 복수개의 제 1 인접평균서브패치군의 패치군수의 합이고, 상기 패치, 서브패치는 복수개의 픽셀로 구성되고, 상기 픽셀은 상기 픽셀의 주소 값, 상기 픽셀의 위치정보 및 상기 픽셀의 색상정보가 저장되어 있는 것을 특징으로 한다."}
{"patent_id": "10-2021-0170533", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명은 로드밸런싱 기능을 적용하여 서버와 단말 환경에서 적용되고, 컨텐츠 제작 시, 제작방법이 간단하여 일반사용자도 컨텐츠를 제작할 수 있는 장점이 있다. 또한, 본 발명은 입력된 전면 영상정보을 이용하여 후면 영상정보를 생성하고, 로드밸런싱 기능을 적용하여 연 산량을 빠르게 처리할 수 있는 컨텐츠 제작방법 및 플랫폼을 제공하는 장점이 있다."}
{"patent_id": "10-2021-0170533", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명의 이점 및 특징, 그리고 그것들을 달성하는 방법은 첨부되는 도면과 함께 상세하게 후술되어 있는 실시 예를 참조하면 명확해질 것이다. 그러나 본 발명은 여기서 설명되는 실시예들에 한정되지 않고 다른 형태로 구 체화될 수도 있다. 오히려, 여기서 소개되는 실시예들은 개시된 내용이 철저하고 완전해질 수 있도록 그리고 당 업자에게 본 발명의 사상이 충분히 전달될 수 있도록 하기 위해 제공되는 것이다. 본 출원에서 사용한 용어는 단지 특정한 실시예를 설명하기 위해 사용된 것으로, 본 발명을 한정하려는 의도가 아니다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 출원에서, \"포함 하다\" 또는 \"가지다\" 등의 용어는 명세서상에 기재된 특징, 숫자, 단계, 동작, 구성요소, 부분품 또는 이들을 조합한 것이 존재함을 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성요소, 부분품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되어야 한다. 다르게 정의되지 않는 한, 기술적이거나 과학적인 용어를 포함해서 여기서 사용되는 모든 용어들은 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자에 의해 일반적으로 이해되는 것과 동일한 의미가 있다. 일반적으 로 사용되는 사전에 정의되어 있는 것과 같은 용어들은 관련 기술의 문맥상 가지는 의미와 일치하는 의미가 있 는 것으로 해석되어야 하며, 본 출원에서 명백하게 정의하지 않는 한, 이상적이거나 과도하게 형식적인 의미로 해석되지 않는다. 이하에서는 본 발명의 구체적인 실시예를 도면을 참조하여 상세히 설명하도록 한다. 도 1은 본 발명에 따른 컨텐츠 영상 제작을 위한 전체 시스템도이다. 도 1을 참조하면, 본 발명에 따른 컨텐츠 영상 제작 플랫폼은, 서버와, 단말을 포함하여 구성된다. 상기 서버 및 단말은 개인용 PC, 스마트폰, 서버일 수 있으며, 상기 서버와 단말 간 무선 또는 유선 통신을 통한 장거리 통신을 할 수 있고, 블루투스, 무선랜 등 근거리 통신을 수행할 수 있다. 또한, 상기 서버 및 단말은 입력 및 출력 수단과, 카메라를 포함하여 영상촬영을 수행할 수 있고, 저장수단이 포 함되어 앱 소프트웨어 설치 및 처리가 가능하다. 일반적인 PC와 서버 등이 포함하는 공지 기술이 적용될 수 있 고, 이에 대한 설명은 생략하기로 한다. 상기 서버는 영상부, 휴먼포즈 생성부, 레이블 맵 생성부, 3D 매쉬 생성부, 통신부 를 포함하여 구성되고, 물리적 또는 논리적으로 구성될 수 있다. 또한, 다른 실시예로, 상기 서버는 인체 레이블 맵 생성부, 패치 맵 생성부를 더 포함하여 구성될 수 있다. 또한, 다른 실시예로, 상기 서버는 로드밸런서부를 포함하여 구성될 수 있다. 여기서, 상기 서버를 구성하는 영상부, 휴먼포즈 생성부, 레이블 맵 생성부, 3D 매쉬 생성부 , 통신부와, 인체 레이블 맵 생성부, 패치 맵 생성부와, 로드밸런서부는 특정 기능 및 연산을 수행하는 프로세서로 구성되고, 하나 또는 복수개의 프로세서로 구성될 수 있고, 특정 알고리즘이 적 용될 수 있다. 상기 영상부는 서버를 구성하는 내장된 카메라 등 영상장치를 이용하여 영상정보를 획득하거나, 기 저장된 영상정보를 획득한다. 또한, 상기 영상부는 단말을 구성하는 영상부가 획득된 영상정보를 수신하여, 해당 영상정보를 이용하여 처리할 수 도 있다. 여기서, 상기 단말의 통신부는 N개의 영상정보로 구성되는 영상정보군 중 제 1영상정보와, 상기 제 1 영상정보와 대응되는 프레임 번호를 저장하는 제 1프레임을 생성하여 상기 제 1프레임을 저장하고, 상기 영상정 보군의 모든 N개의 영상정보에 대해 순차적으로 상기 N개의 영상정보와, 상기 N개의 영상정보와 대응되는 일련 의 프레임 번호들을 저장하는 N개의 프레임들을 생성하여, 상기 N개의 프레임들을 저장하고, 상기 N개의 프레임 들을 상기 서버를 구성하는 통신부를 경유하여, 상기 서버로 송신된다. 여기서, 상기 프레임 구 조는 후술하여 상세히 기술하기로 한다. 상기 N개의 프레임들이 수신되면, 상기 휴먼포즈 생성부는 상기 수신된 N개의 프레임들 중 상기 제 1프레 임의 제 1영상정보를 추출하고, 상기 제 1영상정보로부터 M개의 관절 좌표로 구성된 휴먼포즈 데이터를 생성하 고, 상기 레이블 맵 생성부는 상기 제 1영상정보로부터 상기 M개의 관절 좌표와 대응되는 레이블을 생성하 고, 상기 3D 매쉬 생성부는 상기 제 1영상정보로부터 메쉬 데이터을 생성한다. 이러한 과정을 반복하여, 상기 휴먼포즈 생성부, 상기 레이블 맵 생성부 및 상기 3D 매쉬 생성부 는 상기 수신된 모든 N개의 프레임들에 대해 순차적으로 영상정보들을 추출하고, 상기 영상정보들로부터 M 개의 관절 좌표로 구성된 휴먼포즈 데이터들을 생성하고, 상기 영상정보들로부터 상기 M개의 관절 좌표와 대응 되는 레이블들로 구성된 레이블 맵을 생성하고, 상기 N개의 영상정보들로부터 메쉬 데이터들을 생성한다. 상기 휴먼포즈 데이터들을 생성, 레이블 맵을 생성 및 메쉬 데이터들을 생성 단계는 후술하여 상세히 기술한다. 또한, 상기 서버를 구성하는 통신부는 상기 휴먼포즈 데이터들과 상기 휴먼포즈 데이터들과 대응되는 주소 값들과, 상기 레이블 맵들과 상기 레이블 맵들과 대응되는 주소 값들과, 상기 메쉬 데이터들과 상기 메쉬 데이터들과 대응되는 주소 값들을 상기 N개의 프레임들에 저장하고, 상기 N개의 프레임들을 상기 단말의 통신부를 경유하여, 상기 단말로 송신한다. 상기 단말이 상기 N개의 프레임들을 수신하면, 상기 단말을 구성하는 컨텐츠 제작부는 상기 수 신된 N개의 프레임들로부터 추출된 상기 휴먼포즈 데이터들과, 상기 레이블 맵 및 상기 메쉬 데이터들을 이용하여 N개의 영상정보로 구성되는 영상정보군과 대응되는 컨텐츠를 생성한다. 여기서, 상기 단말을 구성하는 컨텐츠 제작부가 컨텐츠를 생성하기 이전에, 상기 후처리부가 상 기 추출된 휴먼포즈 데이터들을 칼만 필터 및 저주파 통과 필터를 적용하여 보정된 휴먼포즈 데이터들을 생성하 고, 상기 추출된 휴먼포즈 데이터들을 상기 보정된 휴먼포즈 데이터들로 대체하는 후처리를 수행한다. 상기 후처리 공정은, 프레임 스킵 및 보간 기술과, 칼만 필터와 저주파 통과 필터 기술 등이 적용되어 수행된다. 상기 프레임 스킵 및 보간 기술은, 상기 단말을 구성하는 영상부가 서버로 연산을 요청 시, 입 력된 매 프레임을 전부 연산 요청하지 않고, 중간 프레임에 대한 연산을 요청하지 않는 방식을 의미한다. 다시 상세 기술하면, 상기 서버는, 상기 N개의 프레임들 중 A개의 제 2프레임들에 대해서, 상기 A개의 제 2프레임들에 대응되는 휴먼포즈 데이터들, 레이블들 및 메쉬 데이터들의 미생성 요청정보를 수신한 경우, 상기 미생성 요청정보에 따라, 상기 A개의 제 2프레임들에 대한 휴먼포즈 데이터들, 레이블들 및 메쉬 데이터들을 미 생성하여, 상기 휴먼포즈 데이터들, 레이블들 및 메쉬 데이터들이 저장되지 않은 A개의 제 2프레임들과, 휴먼포 즈 데이터들, 레이블들 및 메쉬 데이터들이 저장된 N-A개의 프레임들을 상기 단말로 송신하고, 상기 단말 은 상기 수신된 A개의 제 2프레임들의 일련번호가 상기 N-A개의 프레임들의 일련번호와 가장 가까운 프레임들을 설정하여, 상기 수신된 A개의 제 2프레임들의 휴먼포즈 데이터들, 레이블들 및 메쉬 데이터들을 상기 설정된 가 장 가까운 일련번호를 포함하는 프레임들의 휴먼포즈 데이터들, 레이블들 및 메쉬 데이터들로 반영하여 저장하 는 방법을 의미한다. 이러한 방법을 적용할 경우, 모든 프레임의 연산을 하지 않고, 연속된 프레임의 앞, 뒤의 데이터의 중간 값을 보간할 수 있어 연산 부담을 줄일 수 있는 장점이 있다. 상기 휴먼포즈 데이터의 칼만 필터(kalman filter)와 저주파 통과 필터(low pass filter) 적용 기법은 연속된 프레임의 휴먼포즈 데이터인 관절 좌표 벡터의 움직임에서 잡음을 제거하기 위한 기법으로, 칼만 필터는 연속된 과거의 연속된 관절 벡터 값들을 기반으로 현재의 관절 좌표를 예측하고, 예측된 값을 참조하여 실제 연산 결과 관절 좌표를 보정하는 기법이다. 저주파 통과 필터는 상기 칼만 필터의 과거의 연속된 관절 벡터 값 들을 기반 으로 갑작스러운 관절 좌표 이동 등의 잡음을 억제하는 기능을 수행한다. 이에 대해서는 후술하기로 한다. 상기 후처리가 완료되고, 컨텐츠 제작이 완료되면, 상기 컨텐츠 재생부는 컨텐츠를 재생한다. 제 2실시예로 상기 N개의 영상정보로 구성되는 영상정보군이 정면의 인체정보를 포함하고, 상기 정면의 인체정 보와 대응되는 후면정보가 포함되어 있지 않은 경우, 후면영상정보를 추정하는 방법에 대해 기술한다. 후면영상정보를 추정하기 위해서, 상기 서버는 인체 레이블 맵 생성부, 패치 맵 생성부를 추가 하여 구성된다. 상기 서버를 구성하는 인체 레이블 맵 생성부는 상기 서버는 상기 M개의 관절 좌표 중 제 1 관절 좌표와 상기 레이블 맵과의 이격 거리가 기 설정된 이격 거리 이하인 경우, 상기 레이블 맵을 상기 제 1 관절 좌표에 대응되는 제 1인체 레이블로 생성하고, 상기 M개의 모든 관절 좌표에 대해서 순차적으로 M개의 인체 레이블을 생성하고, 상기 M개의 인체 레이블로 구성된 인체 레이블 맵을 생성하고, 상기 M개의 관절 좌표와 상기 레이블 맵의 이격 거리가 기 설정된 이격 거리를 초과한 경우, 비인체 레이블 맵을 생성하고, 상기 인체 레이블 맵과 상기 비인체 레이블 맵으로 구성되는 제 2영상 정보를 생성한다. 상기 서버를 구성하는 패치 맵 생성부는 상기 제 1영상정보를 N개의 패치로 분리하여 N개의 제 1영상정보 패치를 생성하고, 상기 N개의 제 1영상정보패치로 구성되는 제 1패치 맵을 생성하고, 상기 제 2영상정보를 N개 의 패치로 분리하여 N개의 제 2영상정보패치를 생성하고, 상기 N개의 제 2영상정보패치로 구성되는 제 2패치 맵 을 생성하고, 상기 N개의 제 1영상정보패치 중 제 1영상정보패치를 B개의 서브패치로 분리하고, 상기 제 1영상 정보패치와 대응되는 상기 B개의 서브패치로 구성된 제 1서브패치군을 생성하고, 상기 N개의 모든 제 1영상정보 패치에 대해 순차적으로 상기 N개의 모든 제 1영상정보패치 각각에 대응되는 N개의 서브패치군을 생성하고, 상 기 N개의 서브패치군으로 구성된 서브 패치 맵을 생성하여 서브 패치 맵을 생성하고, 상기 제 1서브패치군을 구 성하는 B개의 서브패치 색상정보 값을 합산하여 평균 값을 계산하고, 상기 평균 값을 상기 B개의 서브패치의 색 상정보 값으로 변경하고, 상기 변경된 색상정보 값이 반영된 B개의 서브패치로 구성된 제 1평균서브패치군을 생 성하고, 상기 N개의 모든 서브패치군에 대해 순차적으로 N개의 평균서브패치군을 생성하고, 상기 N개의 평균서 브패치군으로 구성된 평균서브 패치 맵을 생성하고, 상기 평균서브 패치 맵을 구성하는 N개의 평균서브패치군중 제 1평균서브패치군의 위치좌표가, 상기 인체 레이블 맵을 구성하는 패치들의 위치좌표 중 하나의 위치좌표 와 동일한 위치 좌표인 경우에 한해, 상기 N개의 평균서브패치군이 포함된 평균서브 패치 맵 중 제 1평균서브패 치군을 둘러싸고 있는 복수개의 제 1 인접평균서브패치군을 설정하고, 상기 제 1평균서브패치군의 제 1가중치와, 상기 제 1평균서브패치군과 상기 복수개의 인접평균서브패치군 간의 이격 거리에 비례하여 상기 복 수개의 평균서브패치군의 제 2가중치를 설정하고, 상기 제 1평균서브패치군에 상기 제 1가중치가 반영된 제 1색 상정보 값과, 상기 복수개의 인접평균서브패치군의 색상정보에 제 2가중치가 반영된 제 2색상정보 값의 평균 값 을 반영하여 후면 색상정보 값을 생성하고, 상기 후면 색상정보 값이 반영된 제 1후면서브패치군을 생성하고, 상기 평균서브패치 맵을 구성하는 N개의 모든 평균서브패치군에 순차적으로 S개의 제 1후면서브패치군을 생성하 고, 상기 평균서브 패치 맵을 구성하는 N개의 평균서브패치군 중 제 1평균서브패치군의 위치좌표가, 상기 인체 레이블 맵을 구성하는 패치들의 위치좌표 중 하나의 위치좌표와 동일한 위치 좌표가 아닌 경우, 상기 제 1평균 서브패치군의 색상정보 값이 반영된 제 2후면서브패치군을 생성하고, 상기 평균서브패치 맵을 구성하는 N개의 모든 평균서브패치군에 순차적으로 T개의 제 2후면서브패치군을 생성하고, 상기 S개의 제 1후면서브패치군과, 상기 T개의 제 2후면서브패치군으로 구성되는 후면서브패치 맵을 생성하고, 상기 복수개의 제 1인접 평균서브패 치군은, 상기 복수개의 제 1인접 평균서브패치군의 위치좌표가 상기 인체 레이블 맵을 구성하는 패치들의 위치 좌표 중 하나의 위치좌표와 동일한 위치 좌표이고, 상기 제 1가중치는 상기 제 2가중치 보다 큰 값으로 설정되 고, 상기 제 1가중치와 상기 복수개의 제 1 인접평균서브패치군에 설정된 제 2가중치들의 합이 1이고, 상기 제 1 가중치인 C는 이고, 상기 제 2 가중치인 w는 이고, 상기 제 1가중치와 상기 제 2가중치들의 상관 관계식인 W은 이고, 상기 Z는 상기 제 1평균서브패치군과, 상 기 복수개의 제 1 인접평균서브패치군의 패치군수의 합이고, 상기 패치, 서브패치는 복수개의 픽셀로 구성되고, 상기 픽셀은 상기 픽셀의 주소 값, 상기 픽셀의 위치정보 및 상기 픽셀의 색상정보가 저장되어 있다. 이에 대한 상세한 설명은 후술하기로 한다. 또한, 다른 실시예로, 상기 서버는 로드밸런서부를 추가로 포함하여 구성될 수 있다. 상기 로드밸런 서부는 상기 서버를 구성하고 있는 특정부의 연산처리 능력 및 현재 처리하고 있는 연산처리량을 기 준으로 상기 수신된 영상정보, 즉 프레임들을 분배한다. 또한, 상기 서버가 복수개의 서버로 구성될 경우, 상기 복수개의 서버를 구성하고 있는 특정부의 연산처리 능력 및 현재 처리하고 있는 연산처리량을 기준으로 상 기 수신된 영상정보, 즉 프레임들을 분배한다. 또한, 상기 로드밸런서부는, 일 예로 인공신경망 알고리즘 을 이용하여, 각각의 특정부가 특정 기능을 수행하기 위해서 연산처리용량, 연산량 등의 로드에 관한 실시간 정 보를 획득하여, 상기 로드가 적은 특정부로 상기 수신영상정보를 전달한다. 이러한 로드밸런싱 기능을 적용하여, 상기 각각의 특정부의 연산처리 효율을 증대 시킬 수 있다. 또한, 상기 서버의 로드밸런스부는 단말이 요청 또는 송신한 영상정보를 하나의 단위로 분배한 다. 이러한 로드밸런싱 기능을 적용하여, 서버에 적은 수의 단말가 접속한 경우에도 활성화된 합성곱 신경 망(CNN, Convolutional Neural Network)을 최대로 활용할 수 있다. 도 2는 본 발명에 따른 컨텐츠 영상 제작 방법을 나타내는 흐름도이다. 도 2를 참조하면, 서버는 영상정보를 단 말로부터 수신단계(S210), 서버는 수신영상정보를 특정부로 전달하는 단계(S220), 서버를 구성하는 특정부는 전 달된 영상정보를 가공하는 단계(S230), 서버는 가공영상 정보를 단말로 송신하는 단계(S240), 단말은 상기 가공 영상을 후처리하는 단계(S250), 단말은 상기 가공영상을 이용하여 편집영상 생성하는 단계(S260) 및 단말은 상 기 편집영상을 재생하는 단계(S270)를 포함하여 구성될 수 있다. 상기 서버는 영상정보를 단말로부터 수신단계(S210)는, 단말을 구성하는 영상부가 카메라로부터 획득 된 영상을 영상정보로 저장한 이후, 상기 영상정보를 서버로 통신부를 이용하여 서버로 송신한 다. 상기 서버는 상기 단말로부터 송신된 상기 영상정보를 상기 서버를 구성하고 있는 통신부를 이용하여 수신한다. 도 3은 본 발명에 따른 입력영상, 생성된 휴먼포즈 정보, 레이블 맵, 인체 레이블 맵 및 3D 메쉬 정보를 송수신 하기 위한 데이터 프레임 개념도이다. 도 3을 참조하여, 상기 영상정보 및 프레임 구조에 대해서 기술한다. 여기서, 상기 영상정보는, 일반적으로 데이터를 저장하는 파일형식인 JPG 파일 등 다양한 형태로 영상 또는 이 미지를 저장하는 데이터 또는 데이터 파일을 의미한다. 또한, 일련의 연속된 이미지인 동영상 파일을 포함할 수있다. 상기 영상정보는 N개의 영상정보를 저장하고 있고, 상기 N개의 영상정보를 구성하는 영상정보군을 생성하여 저 장한다. 상기 N개의 각각의 영상정보는 각각의 프레임에 저장되고 송수신된다. 상기 프레임은, 공지된 데이터 전송 방법인, OSI 7 Layer 구조를 채용하고 있어, 일반적이 통신 전송 데이터와 호환성을 유지하고 있으며, 상위단인 Applicaition 단계에서 일부 구조가 변경된 형태이다. 즉, Applicaition 단계의 프레임 구조의 헤더 부분에 프레임 번호의 일련번호를 부가하고, 일예로, 1, 2, 3 등 순서로 일련번호를 부가한다. 이후, 상기 헤더 이후 데이터 저장공간에 일정량의 저장용량을 설정하여, 영상정보, 휴먼포즈 데이터, 레이블 맵 정보, 인체 레이블 맵 정보, 매쉬정보를 순차적으로 저장한다. 이러한 프레임 구조를 적용하 여 상기 서버와 상기 단말간 데이터 교환 시, 기존 보다 빠른 데이터 전송 및 처리가 가능하다. 또 한, 상기 프레임은 픽셀의 주소 값, 위치좌표 관련 위치정보 등이 저장될 수 있다. 여기서, 상기 단말은 상기 프레임을 N개의 프레임들로 설정하고, 상기 단말은은 상기 제 1 영상정보 와, 일련번호를 부가 및 저장하여 제 1 프레임을 생성한다. 또한, 상기 단말은 상기 N개의 영상정보와 일 련번호들을 순차적으로 부가 및 저장하여 N개의 프레임을 생성한다. 상기 단말을 구성하는 상기 통신부는 상기 N개의 프레임들을 서버로 송신한다. 여기서, 상기 통 신부는 상기 제 1프레임을 생성 시, 바로 서버 송신하고, 순차적으로 생성되는 N개의 프레임들을 서 버로 송신할 수 있고, 또는 모든 N개의 프레임들이 생성된 후, 상기 모든 N개의 프레임들을 서버로 송신 할 수 도 있다. 즉, 상기 단말은 N개의 영상정보로 구성되는 영상정보군 중 제 1영상정보와, 상기 제 1영상정보와 대응되 는 프레임 번호를 저장하는 제 1프레임을 생성하여 상기 제 1프레임을 저장한다. 또한, 상기 단말은 상기 영상 정보군의 모든 N개의 영상정보에 대해 순차적으로 상기 N개의 영상정보와, 상기 N개의 영상정보와 대응되는 프 레임의 일련번호들을 저장하는 N개의 프레임들을 생성하여, 상기 N개의 프레임들을 저장하고, 상기 N개의 프레 임들을 상기 서버로 송신한다. 또한, 상기 단말은 상기 N개의 프레임들을 동시에 서버로 송신할 수도 있고, 지정된 프레임들만 선택 적으로 송신할 수 도 있다. 상기 서버는 영상정보를 단말로부터 수신한 이후, 상기 수신 영상정보를 특정부로 전달하는 단계(S220)를 수행한다. 상기 서버를 구성하고 있는 로드밸런서부는 상기 서버를 구성하고 있는 특정부의 연산처리 능력 및 현재 처리하고 있는 연산처리량을 기준으로 상기 수신된 영상정보, 즉 프레임들을 분배한다. 또한, 상기 서 버가 복수개의 서버로 구성될 경우, 상기 복수개의 서버를 구성하고 있는 특정부의 연산처리 능력 및 현재 처리하고 있는 연산처리량을 기준으로 상기 수신된 영상정보, 즉 프레임들을 분배할 수 있다. 또한, 상기 로드 밸런서부는, 일 예로 인공신경망 알고리즘을 이용하여, 각각의 특정부가 특정 기능을 수행하기 위해서 연 산처리용량, 연산량 등의 로드에 관한 실시간 정보를 획득하여, 상기 로드가 적은 특정부로 상기 수신영상정보 를 전달한다. 이러한 로드밸런싱 기능을 적용하여, 상기 각각의 특정부의 연산처리 효율을 증대 시킬 수 있다. 또한, 상기 서버를 구성하는 로드밸런스부는 단말이 요청 또는 송신한 영상정보를 하나의 단위 로 분배한다. 이러한 로드밸런싱 기능을 적용하여, 서버에 적은 수의 단말이 접속한 경우에도 활성화된 합 성곱 신경망(CNN, Convolutional Neural Network)을 최대로 활용할 수 있다. 여기서, 특정부는, 도 1을 참조하여 기재하면, 휴먼포즈 생성부, 레이블 맵 생성부, 3D 매쉬 생성부 포함하여 구성된다. 또한, 후술할 제 2실시예의 경우, 인체 레이블 맵 생성부, 패치 맵 생성부(15 0)를 추가로 포함하여 구성될 수 있다. 또한, 일 예로, 휴먼포즈 생성부, 레이블 맵 생성부, 3D 매쉬 생성부, 인체 레이블 맵 생성부 , 패치 맵 생성부는 특정 기능 및 연산을 수행하는 프로세서로 구성되고, 하나 또는 복수개의 프로세 서로 구성될 수 있다. 상기 수신 영상정보를 특정부로 전달하는 단계(S220)가 수행된 이후, 상기 서버를 구성하는 특정부는 전달된 영상정보를 가공하는 단계(S230)를 수행한다. 상기 서버를 구성하는 특정부는 전달된 영상정보를 가공하는 단계 (S230)는 상기 전달된 영상정보, 즉, 프레임들을 이용하여, 휴먼포즈 데이터 생성, 레이블 맵 생성, 3D 매쉬 생성 단계를 수행한다. 여기서, 상기 휴먼포즈 데이터 생성, 상기 레이블 맵 생성, 상기 3D 매쉬 생성 단계는 수신된 프레인 단위로 수 행되고, 순서와 무관하게 선택적으로 수행할 수 있다. 도 4는 본 발명에 일실시예에 따른 입력된 제 1영상정보를 이용하여 휴먼포즈 데이터를 생성하는 개념도이다. 도 4를 참조하면, 휴먼포즈 생성부는 상기 제 1영상정보를 이용하여 휴먼포즈 데이터를 생성한다. 상기 휴먼포즈 생성부는 상기 수신된 제 1프레임으로부터 제 1영상정보를 추출하고 , 상기 제 1영상정보로 부터 M개의 관절 좌표로 구성된 휴먼포즈 데이터를 생성한다. 또한, 상기 휴먼포즈 생성부는 상기 수신된 모든 N개의 프레임들에 대해 순차적으로 영상정보들을 추출하고, 상기 영상정보들로부터 M개의 관절 좌표로 구 성된 휴먼포즈 데이터들을 생성한다. 여기서, 공지의 휴먼포즈 생성 알고리즘을 이용하고, 상기 공지의 휴먼포즈 생성 알고리즘이 적용되어, 심층신 경망의 한 종류인 합성곱 신경망(CNN, Convolutional Neural Network)을 이용하여 반복 학습하여 최종적으로 휴 먼포즈 백터 맵을 생성한다. 여기서, 상기 합성곱 신경망(CNN, Convolutional Neural Network)은 상기 제 1영 상정보에 저장되어 있는 인체 관련 정보를 추출하고, 상기 추출된 인체정보를 이용하여 각 인체 관절의 좌표를 출력하고, 상기 출력된 인체의 관절 좌표 중 예측 정확도가 높은 좌표를 선택해서 2차원 관절 좌표를 설정한다. 이후, 상기 2차원 관절 좌표를 이용하여 3차원 관절 좌표를 생성하는데, 3차원 표준 인체 메쉬 데이터 모델 (SMPL, Skinned Multi-Person Linear Model)을 이용하여, 상기 2차원 관절 좌표를 상기 3차원 표준 인체 메쉬 데이터 모델에 적용하여 매칭된 3차원 관절좌표, 즉, 휴먼포즈 백터 맵을 생성한다. 여기서, 일반적으로 휴먼포즈의 의미는, 입력된 원본 이미지 상에서 검출된 사람에 대해 코, 팔꿈치, 발목 등의 지정된 개수의 관절과 각각의 이미지 좌표 체계 상에서의 3차원 좌표 벡터를 의미하고, 상기 좌표는 0~1 사이의 값으로 정규화 되어 있는 공지된 기술이다. 여기서, 상기 생성된 휴먼포즈 백터 맵은 도 4를 참조한다. 도 5는 본 발명에 일실시예에 따른 입력된 제 1영상정보를 이용하여 휴먼포즈 데이터인 관절좌표에 대한 도면이 다. 도 5를 참조하면, 일 실시예로, 상기 휴먼포즈 데이터는 23개의 관절좌표로 구성되고, 각각의 관절좌표에는 명칭 및 고유번호가 부여되어, 이후 인체 레이블 맵을 생성시, 상기 관절좌표가 이용될 수 있다. 상기 관절좌 표는 필요에 따라 임의로 설정될 수 있다. 또한, 필요에 따라, 3차원 좌표인 휴먼포즈 백터 맵을 이용할 수 있 다. 도 6은 본 발명에 일실시예에 따른 입력된 제 1영상정보를 이용하여 세그멘테이션하여 레이블 맵을 생성하는 개 념도이다. 도 6을 참조하면, 휴먼포즈 생성부가 상기 제 1 영상정보를 이용하여 휴먼포즈 데이터를 생성하 면, 레이블 맵 생성부는 상기 제 1영상정보를 이용하여 레이블 맵 데이터를 생성하는 단계(S220)를 수행한 다. 상기 레이블 맵 생성부는 상기 수신된 N개의 프레임들 중 상기 제 1프레임의 제 1영상정보를 추출하고, 상 기 제 1영상정보로부터 상기 M개의 관절 좌표와 대응되는 레이블을 생성한다. 상기 레이블 맵 생성부는 상 기 수신된 모든 N개의 프레임들에 대해 순차적으로 영상정보들을 추출하고, 상기 영상정보들로부터 상기 M개의 관절 좌표와 대응되는 레이블들로 구성된 레이블 맵들을 생성한다. 여기서, 일반적으로 세그멘테이션(Semantic Image Segmentation)의 의미는 영상정보 상에서 인체정보를 검출하 고, 검출된 인체정보가 존재하는 픽셀을 참(True)으로, 검출된 인체정보가 존재하지 않는 픽셀을 거짓(False)으 로 픽셀 값을 지정하여 원본과 같은 크기로 레이블 맵(Label Map)을 구성하는 기술을 의미한다. 공지의 레이블 맵 생성 알고리즘을 이용하고, 상기 공지의 레이블 맵생성 알고리즘이 적용되어, 심층신경망의 한 종류인 합성곱 신경망(CNN, Convolutional Neural Network)을 이용하여 반복 학습하여 최종적으로 레이블 맵 을 생성한다. 여기서, 레이블 맵 추출방법은 상기 레이블 맵이 상기 영상 정보의 이미지 크기와 동일한 이미지 크기로 설정하 고, 일반적인 RGB 채널이 아닌 흑백 채널을 사용하여 0~255의 값을 사용하도록 설정한다. 상기 영상정보 중 인체정보에 해당되는 픽셀은 255로 설정하고, 상기 영상정보 중 인체정보에 해당되지 않는 픽 셀은 0으로 설정하여 레이블 맵을 생성하고, 저장한다. 상기 레이블 맵 추출방법은 합성곱 신경망(CNN, Convolutional Neural Network)에 적용하여, 인체 영역에 해당 되는 픽셀의 정보만 분리하여 레이블 맵을 추출하도록 반복하여 학습한다. 상기 추출된 레이블 맵은 상기 전달된 영상정보와 비교해 데이터 크기가 작아진다. 이러한 데이터 손실을 보상하기 위해, 공지의 합성곱 신경망(인코더-디코더 구조로 합성곱 신경망)을 적용하여 최종적으로 레이블 맵을 생성한다. 여기서, 세그멘테이션 결과 레이블 맵은 도 6을 참조한다. 도 7은 본 발명에 따른 입력영상을 이용하여 3D 메쉬 데이터를 생성하는 개념도이다. 도 7을 참조하여, 3D 메쉬 데이터를 생성을 생성하는 단계에 대해서 기술한다. 상기 3D 메쉬 생성부는 상기 수신된 N개의 프레임들 중 상기 제 1프레임의 제 1영상정보를 추출하고, 상기 제 1영상정보로부터 메쉬 데이터을 생성한다. 또한, 상기 3D 메쉬 생성부는 상기 수신된 모든 N개의 프레 임들에 대해 순차적으로 영상정보들을 추출하고, 상기 N개의 영상정보들로부터 메쉬 데이터들을 생성한다. 여기서, 일반적으로, 3D 메쉬 데이터는 3차원 가상 월드 좌표 상에서의 점을 의미하는 3차원 벡터인 버텍스 (Vertex)와, 상기 버텍스 3개를 하나의 쌍으로 하여 삼각형의 폴리곤(Polygon)을 구성하는 페이스(Face)정보를 가진 데이터를 의미하고, 일반적으로 obj 파일 구조를 사용하고 있다. 상기 전달된 영상 정보 또는 상기 생성된 휴먼포즈 백터 맵과, 상기 생성된 레이블 맵을 정보를 이용하여 3차원 메쉬정보를 생성한다. 일반적으로 3차원 메쉬정보를 생성하는 알고리즘이 적용되는 상기 합성곱 신경망(CNN, Convolutional Neural Network)을 이용하여, 상기 인체 정보의 전면 및 후면의 3차원 벡터인 버텍스와, 이에 상응하는 페이스정보를 생성하여 3차원 메쉬정보를 생성한다. 여기서, 상기 인체 정보의 전면 및 후면의 3차원 벡터인 버텍스와, 이에 상응하는 페이스정보를 결합하여 최종 메쉬 정보를 생성하고, 저장한다. 상기 서버를 구성하는 특정부는 전달된 영상정보를 가공하는 단계(S230)를 수행하여, 휴먼포즈 데이터, 레이블 맵 및 3차원 메쉬정보가 생성되면, 상기 서버는 가공영상 정보를 단말로 송신하는 단계(S240)를 수행한다. 도 3을 다시 참조하여 기술하면, 상기 휴먼포즈 데이터, 레이블 맵 및 3차원 메쉬정보를 상기 프레임에 저장한 다. 상기 프레임은 기 저장된 프레임번호, 영상정보, 휴먼포즈 데이터, 레이블 맵 정보를 저장 후, 상기 프레임 을 서버로 송신한다. 상기 서버는 상기 휴먼포즈 데이터들과 상기 휴먼포즈 데이터들과 대응되는 주소 값들과, 상기 레이블 맵 들과 상기 레이블 맵들과 대응되는 주소 값들과, 상기 메쉬 데이터들과 상기 메쉬 데이터들과 대응되는 주소 값 들을 상기 N개의 프레임들에 저장하고, 상기 N개의 프레임들을 상기 단말로 송신한다. 여기서, 단말의 요청에 따라, 상기 요청에 상응하는 정보를 상기 프레임에 저장하여 송신한다. 도 3은 본 발명에 따른 입력영상, 생성된 휴먼포즈 정보, 레이블 맵, 인체 레이블 맵 및 3D 메쉬 정보를 송수신 하기 위한 데이터 프레임 개념도이다. 도 3을 참조하여, 상기 서버 및 단말 간 데이터 파일을 송신하 는 프레임 구조 및 데이터 저장을 위한 프레임 구조에 대해서 기술한다. 도 3을 참조하면, 프레임 구조는 서버와 단말 간의 통신하는 데이터 구조임과 동시에, 데이터를 저장 할 때 사용되는 프레임 구조이다. 상기 단말은, 특정연산을 상기 프레임의 특정 필드에 적용하여 상기 서 버로 요청하면, 상기 서버는 요청된 특정 연산을 수행하여, 해당 프레임 번호와 결과 데이터만을 구성해 상기 단말로 응답하는 프레임 구조로 통신이 진행된다. 해당 프레임 구조는 필요한 데이터만을 요청하거나 응답 할 수 있도록 분리 및 조립이 자유롭게 구성되어 있다. 또한, 해당 프레임 구조는 상기 단말이 실시간으로 컨텐츠를 재생하기 위해 데이터를 저장하는 콘텐츠 버 퍼로 이용되고, 상기 재생이 끝난 프레임에는 새로운 정보가 입력되도록 해서, 저장 공간을 효율적으로 사용할 수 있도록 설계되었다. 따라서, 상기 프레임 구조를 기반으로 컨텐츠 재생 버퍼를 원형 큐 형태로 구성하고 프 레임 번호를 기준으로 동기화를 수행하여, 실시간 콘텐츠 재생을 수행할 수 있는 장점이 있다. 상기 단말은 상기 가공영상 정보, 즉, 상기 프레임들을 수신하면, 단말은 상기 가공영상을 후처리하 는 단계(S250)를 수행한다. 상기 단말을 구성하는 상기 후처리부는 상기 가공 영상정보를 후처리한다. 상기 단말은, 상기 수신된 N개의 프레임들로부터 추출된 상기 휴먼포즈 데이터들과, 상기 레이블 맵 및 상 기 메쉬 데이터들을 이용하여 N개의 영상정보로 구성되는 영상정보군과 대응되는 컨텐츠를 생성한다. 상기 단말을 구성하는 후처리부는 상기 추출된 휴먼포즈 데이터들을 칼만 필터 및 저주파 통과 필터 를 적용하여 보정된 휴먼포즈 데이터들을 생성하고, 상기 추출된 휴먼포즈 데이터들을 상기 보정된 휴먼포즈 데 이터들로 대체하는 후처리단계를 수행한다. 상기 후처리부는 공지의 알고리즘인, 휴먼포즈 데이터의 칼만 필터(kalman filter)와 저주파 통과 필터 (low pass filter) 적용한다. 상기 연속된 프레임의 휴먼포즈 데이터인 관절 좌표 벡터의 움직임의 노이즈를 제 거한다. 상기 칼만 필터는 연속된 이전의 관절 벡터 값들을 기반으로 현재의 관절 좌표를 예측하고, 상기 예측 된 관절 좌표를 적용하여 실제 연산 결과 관절 좌표를 보정한다. 상기 저주파 통과 필터는 상기 칼만 필터의 연 속된 이전 관절 벡터 값 들을 기반으로 갑작스러운 관절 좌표 이동 시, 노이즈를 제거하는 기능을 수행한다. 상기 후처리부는 휴먼포즈 데이터의 프레임 스킵 및 보간 기법을 적용할 수 있다. 상기 서버는, 상기 N개의 프레임들 중 A개의 제 2프레임들에 대해서, 상기 A개의 제 2프레임들에 대응되는 휴먼포즈 데이터들, 레이블들 및 메쉬 데이터들의 미생성 요청정보를 수신한 경우, 상기 미생성 요청정보에 따 라, 상기 A개의 제 2프레임들에 대한 휴먼포즈 데이터들, 레이블들 및 메쉬 데이터들을 미생성하여, 상기 휴먼 포즈 데이터들, 레이블들 및 메쉬 데이터들이 저장되지 않은 A개의 제 2프레임들과, 휴먼포즈 데이터들, 레이블 들 및 메쉬 데이터들이 저장된 N-A개의 프레임들을 상기 단말로 송신한다. 상기 단말은, 상기 수신된 A개의 제 2프레임들의 일련번호가 상기 N-A개의 프레임들의 일련번호와 가장 가 까운 프레임들을 설정하여, 상기 수신된 A개의 제 2프레임들의 휴먼포즈 데이터들, 레이블들 및 메쉬 데이터들 을 상기 설정된 가장 가까운 프레임들의 휴먼포즈 데이터들, 레이블들 및 메쉬 데이터들로 반영하여 저장한다. 여기서, 상기 단말은 상기 서버로 연산을 요청 시, 상기 단말을 구성하는 영상부에서 입력된 매 프레임을 전부 연산 요청하는 것이 아니라 중간 프레임은 연산을 요청하지 않는 경우, 일예로, 연속으로 입력된 3개의 프레임 중에서 중간 프레임은 연산을 요청하지 않는다. 상기 단말이 상기 서버로부터 연산 결과를 수신하 고, 상기 비어있는 중간 휴먼포즈 데이터 공간을 채우기 위해 연속된 프레임 구조를 이용해 앞, 뒤의 휴먼포즈 결과 데이터의 중간 값을 보간하여 채우는 과정을 수행할 수 있다. 이러한 과정을 통해 서버의 연산 부담을 감 소시킬 수 있다. 또한, 상기 후처리부는, 상기 보정된 휴먼포즈 백터 맵과, 마스킹 된 레이블 맵을 이용하여 뼈대 좌표를 생성하고, 상기 뼈대 좌표의 움직임에 대응되는 최종 메쉬 정보를 맵핑하여 자연스로운 스키닝(Skinning)을 수 행한다. 상기 뼈대 좌표와 상기 최종 메쉬 정보를 이용하여, 후술한 애니메이션 적용 시, 애니메이션을 상기 뼈대 좌표 의 움직임과 동일하게 구현 할수 있다. 상기 단말은 상기 가공영상의 후처리가 완료되면, 상기 단말은 상기 가공영상을 이용하여 편집영상 생성하는 단계(S260)를 수행하고, 상기 편집 영상이 생성되면, 상기 편집영상을 재생할 수 있다. 도 8은 본 발 명에 일시예에 따른 단말의 컨텐츠 제작부의 개요도이다. 도 9는 본 발명에 일시예에 따른 세그멘테이션 적용된 일 예시도이다. 도 10은 본 발명에 일시예에 따른 3D 메쉬 데이터가 적용된 일 예시도이다. 도 11은 본 발명에 일시예에 따른 3D 메쉬 데이터가 적용된 다른 예시도이다. 도 9 내지 도 11을 참조하면, 상기 단말을 구성 하는 컨텐츠 제작부는, 상기 단말이 영상부를 통해 획득된 영상정보와, 상기 단말이 영상부의 후처리부가 후처리를 수행하여 획득된 휴먼포즈 벡터 맵 정보와, 상기 레이블 맵 정보, 매쉬 정보를 이용 하여 상기 획득된 영상정보를 기초로 컨텐츠를 제작할 수 있다. 일 예로, 컨텐츠 제작부가 특정 애니메이션 또는 3D 아바타를 설정하면, 상기 애니메이션 또는 3D 아바타 에 상기 후처리를 수행하여 획득된 휴먼포즈 벡터 맵 정보를 반영하여 상기 애니메이션 또는 3D 아바타의 움직 임을 제어할 수 있다. 또한 일 예로, 상기 영상정보의 특정 값에, 즉, 만세 자세나 차렷 자세 동작에 대해서 특 정 이벤트를 수행하게 제공할 수 있다. 또한, 일예로, 컨텐츠 제작부가 기 설정된 2D나 3D 배경 영상, 동영상이나 3차원 게임 공간을 설정하면, 후처리를 수행하여 획득된 레이블 맵 정보를 상기 획득된 영상 정보에 적용하여 합성 영상을 제공할 수 있다. 또한, 일예로, 컨텐츠 제작부가 특정 애니메이션 또는 3D 아바타를 설정하면, 상기 후처리를 수행하여 획 득된 매쉬 정보를 반영할 경우, 상기 특정 애니메이션 또는 3D 아바타는 상기 매쉬 정보가 반영되어, 상기 획득 된 영상 정보의 인체 또는 객체의 움직임과 동일한 움직임을 구현할 수 있다. 또한, 상기 컨텐츠 제작부는 본인이 제작 또는 다른 사용자가 공유한 콘텐츠나 리소스를 적용할 수 있는 확장성을 적용할 수 있다. 상기 단말은 상기 가공영상을 이용하여 편집영상 생성하는 단계(S260)의 수행 완료 후, 단말은 상기 편집영상을 재생하는 단계(S270)를 수행한다. 또한, 상기 단말은 프레임 구조의 헤더 부분에 프레임 번호 의 일련번호를 부가하고, 일예로, 1, 2, 3 등 순서로 일련번호를 부가한다. 이후, 상기 헤더 이후 데이터 저장 공간에 일정량의 저장용량을 설정하고, 상기 저장공간에 상기 단말의 영상부가 획득한 영상정보를 반영 및 저장한 후, 상기 서버로 전송한다. 상기 서버는 상기 프레임 번호 및 상기 저장된 영상정보에 해당하 는 정보, 즉, 휴먼포즈 데이터 정보, 레이블 맵 정보, 최종 매쉬 정보를 순차적으로 저장한 후, 상기 단말(20 0)로 전송한다. 이러한 방법으로 상기 프레임 간 싱크를 맞추게 되어, 상기 단말을 구성하는 상기 컨텐츠 재생부는 실시간으로 컨텐츠를 재생할 수 있다. 본 발명의 제 2실시예인, 상기 N개의 영상정보로 구성되는 영상정보군이 정면의 인체정보를 포함하고, 상기 정 면의 인체정보와 대응되는 후면정보가 포함되어 있지 않은 영상이 입력된 경우, 후면 영상을 추출하는 방법에 대해 기술한다. 도 2는 본 발명에 따른 컨텐츠 영상 제작 방법을 나타내는 흐름도이다. 도 12는 본 발명에 일시예에 따른 후면 영상정보를 생성하는 흐름도이다. 도 13은 본 발명에 따른 후면 영상정보를 생성하는 방법을 나타내는 개념도이 다. 도 2, 12 및 도13을 참조하면, 서버는 영상정보를 단말로부터 수신단계(S210), 서버는 수신영상정보를 특정 부로 전달하는 단계(S220), 서버내 특정부는 전달된 영상정보를 가공하는 단계(S230), 서버는 가공영상 정보를 단말로 송신하는 단계(S240), 단말은 상기 가공영상을 후처리하는 단계(S250), 단말은 상기 가공영상을 이용하 여 편집영상 생성하는 단계(S260) 및 단말은 상기 편집영상을 재생하는 단계(S270)를 포함하여 구성된다. 여기서, 제 2실시예인 상기 정면의 인체정보와 대응되는 후면정보가 포함되어 있지 않은 영상이 입력된 경우, 상기 서버를 구성하는 특정부는 전달된 영상정보를 가공하는 단계(S230)는 상기 휴먼포즈 데이터를 이용하여 상 기 인체 레이블 맵을 생성하는 단계(S1210), 상기 인체 레이블 맵 및 비인체 레이블 맵을 이용하여 제 2영상정 보를 생성하는 단계(S1220), 상기 제 1영상정보와 상기 제 2영상정보를 이용하여 패치 정보를 생성하는 단계 (S1230) 및 상기 패치 정보를 이용하여 후면 영상정보 생성하는 단계(S1240)를 더 포함하여 구성될 수 있다. 도 12 내지 도 13을 참조하면, 상기 서버는 영상정보를 단말로부터 수신(S210)하고, 상기 서버는 수신영상정보 를 특정부로 전달(S220)한 이후, 상기 서버를 구성하는 특정부는 전달된 영상정보를 가공하는 단계(S230)를 수 행한다. 여기서, 제 1실시예의 구성 및 실시 단계는 그대로 적용되고, 제 2실시예에 적용되는 추가적인 구성 및 단계에 대해서만 기술한다. 여기서, 제 1영상정보는, 일반적으로 데이터를 저장하는 파일형식인 JPG 파일 등 다양한 형태로 영상 또는 이미 지를 저장하는 데이터 또는 데이터 파일을 의미한다. 또한, 상기 제 1영상정보는, 상기 제 1영상정보 내에 인체 관련 정보를 포함하는 이미지 영상을 포함할 수 있고, 특히, 상기 인체 관련 정보는 전면 영상을 포함하고, 후 면 영상을 포함하지 않을 수 도 있고, 반대로 후면 영상을 포함하고, 전면 영상을 포함하지 않을 수도 있다. 도 5는 본 발명에 일실시예에 따른 입력된 제 1영상정보를 이용하여 휴먼포즈 데이터인 관절좌표에 대한 도면이 다. 도 5를 참조하면, 일 실시예로, 상기 휴먼포즈 데이터는 23개의 관절좌표로 구성되고, 각각의 관절좌표에는 명칭 및 고유번호가 부여되어, 이후 인체 레이블 맵을 생성시, 상기 관절좌표가 이용될 수 있다. 상기 관절좌 표는 필요에 따라 임의로 설정될 수 있다. 또한, 필요에 따라, 3차원 좌표인 휴먼포즈 백터 맵을 이용할 수 있 다. 도 15 본 발명에 일시예에 따른 인체 레이블 맵과 비인체 레이블 맵을 나타내는 일 예시도이다. 도 5 및 도 15 을 참조하여 기술하면, 인체 레이블 맵 생성부는 상기 휴먼데이터의 관절 좌표와, 상기 레이블 맵과의 거 리를 측정하고, 상기 측정된 거리가 기 설정된 거리보다 작은 경우, 해당 관절좌표와 대응되는 레이블을 인체 레이블로 설정한다. 여기서, 인체 레이블 맵 생성부는 기 설정된 거리는 임의로 설정할 수 있으며, 상기 설정 값에 따라 인체 레이블 수 변경 될 수 있다. 여기서는, 기 설정된 거리는 관절좌표에 대응되는 인체 레이블 수가 결정될 수 있 도록 설정하는 것이 바람직하다. 또한, 관절좌표가 H개로 구성된 경우, H개의 관절좌표에 대해서, 상기 각각의 관절좌표와, 상기 레이블 맵과의 거리를 측정하고, 상기 측정된 거리가 기 설정된 거리보다 작은 경우, 해당 관절좌표와 대응되는 레이블을 인체 레이블로 설정하고, 이를 순차적으로 반복 수행하여 H개의 인체 레이블을 생성하고, 상기 생성된 H개의 인체 레이블로 구성된 인체 레이블 맵을 생성한다. 여기서, 상기 거리는 일반적인 거리특정 용어인, 유클리디안 거리(Euclidean distance)를 의미한다. 또한, 앞에서 기술된 상기 휴먼데이터인 관절 좌표가 23개인 경우에 이에 대응되는 23개의 인체 레이블이 생성 된다. 즉, H개의 관절좌표가 이용될 경우, H개의 인체 레이블이 생성되고, 생성된 H개의 인체 레이블로 구성되 는 인체 레이블 맵이 생성된다. 인체 레이블 맵 생성부가 인체 레이블 맵이 생성된 이후, 상기 인체 레이블 맵 및 비인체 레이블 맵을 이 용하여 제 2영상정보를 생성하는 단계(S1220)를 수행한다. 여기서, 비인체 레이블 맵은 상기 관절 좌표와 기설정된 거리보다 큰 경우에 해당하는 영역을 의미한다. 즉, 제 2 영상정보는 제 1영상정보의 인체영역에 해당되는 인체 레이블 맵과, 상기 제 1영상정보의 인체 영역에 해당되지 않는 비인체 레이블 맵으로 구성된다. 상기 제 2영상정보가 생성된 이후, 패치 맵 생성부는 상기 제 1영상정보와 상기 제 2영상정보를 이용하여 패치 정보를 생성하는 단계(S1230)를 수행한다. 도 14는 본 발명에 일실시예에 따른 제 1영상정보와 제 2영상정보를 이용하여 패치 정보를 생성하는 세부 흐름 도이다. 도 14를 참조하면, 상기 제 1영상정보를 특정단위로 분리하여 제 1패치 맵을 생성하는 단계(S1410)와, 상기 제 2영상정보를 특정단위로 분리하여 제 2패치 맵을 생성하는 단계(S1420) 및 상기 제 1패치 맵, 상기 제 2패치 맵을 이용하여 후면 패치 맵 생성하는 단계(S1430)를 포함한다. 먼저, 상기 패치 맵 생성부는 상기 제 1영상정보를 특정단위로 분리하여 제 1패치 맵을 생성하는 단계 (S1410)를 수행한다. 도 16은 본 발명에 일시예에 따른 제 1입력영상과, 제 2입력영상이 복수개의 패치들로 분리되고, 생성되는 후면 서브패치맵을 나타내는 개념도이다. 도 17은 본발명에 일시예에 따른 제 1입력영상의 분리된 제 1영상패치를 서 브패치로 분리된 서브패치군을 나타내는 개념도이다. 도 16 및 도 17을 참조하여, 상기 분리된 특정단위인 패치 및 서브 패치에 관해 기술한다. 도 16을 참조하면, 패치 맵 생성부는 상기 제 1영상정보를 N개의 패치로 분리하여 N개의 제 1영상정보패치 를 생성하고, 상기 N개의 제 1영상정보패치로 구성되는 제 1패치 맵을 생성한다. 여기서, 패치 맵 생성부는 P와 Q를 임의로 설정할 수 있고, P와 Q를 동일하게 또는 다르게 설정할 수 있다. 일반적으로 영상이미지는 각각의 픽셀 단위로 표현되고, 저장되는 구조이어서, P*Q=N개로 분리된 패치도 픽셀 단위로 저장되는 바, 이에 대해서는 공지의 기술이 적용되어 구체적인 기재는 생략한다. 상기 패치 맵 생성부는 상기 제 1영상정보를 분리하여, (1,1)으로 표현되는 제 1패치부터, (P,Q)으로 표현 되는 P*Q의 패치를 생성하고, 상기 생성된 P*Q개, 즉, N개의 제 1영상정보패치를 제 1패치 맵으로 규정하여 용 어를 정의한다. 또한, 상기 패치 맵 생성부는 상기 제 2영상정보를 N개의 패치로 분리하여 N개의 제 2영상정보패치를 생성 하고, 상기 N개의 제 2영상정보패치로 구성되는 제 2패치 맵을 생성한다. 상기 패치 맵 생성부는 상기 제 2영상정보를 분리하여, (1,1)으로 표현되는 제 1패치부터, (P,Q)으로 표현 되는 P*Q의 패치를 생성하고, 상기 생성된 P*Q개, 즉, N개의 제 2영상정보패치를 제 2패치 맵으로 규정하여 용 어를 정의한다. 여기서, 패치 맵 생성부는 P와 Q를 임의로 설정할 수 있고, P와 Q를 동일하게 또는 다르게 설정할 수 있다. 일반적으로 영상이미지는 각각의 픽셀 단위로 표현되고, 저장되고 구조이어서, N개로 분리된 패치도 픽셀 단위로 저장되는 바, 이에 대해서는 공지의 기술이 적용되어 구체적인 기재는 생략한다. 여기서, 상기 픽셀은 공지로 기술된 기술 용어이고, 본 발명에 필요한 범위 내에서 해당 픽셀의 정보에 저장된 정보에 대해 기술한다. 상기 픽셀은 일정정보를 저장하고 있고, 해당 정보를 색상 및 밝기 등으로 표현한다. 상 기 일정 정보는 상기 픽셀의 주소 값, 상기 픽셀의 주소 값에 대응되는 위치정보와 색상정보를 포함할 수 있다. 상기 위치정보는 상기 픽셀의 위치한 위치좌표정보를 포함하고, 상기 색상정보는 공지기술인 색상정보 표시 형 식 인 RGB 값으로 구성되고, RGB 각각의 값은 0~255 범위로 설정하여 사용될 수 있다. 여기서, 상기 제 1패치 맵의 (1,1) 제 1영상정보패치와, 상기 제 2패치 맵의 (1,1) 제 2영상정보패치를 1:1로 매핑하는 것을 동기화로 표현하고, 상기 제 1패치 맵의 (1,2) 제 1영상정보패치와, 상기 제 2패치 맵의 (1,2) 제 1영상정보패치를 1:1로 매핑하고, 순차적으로 상기 제 1패치 맵의 (P,Q)인 제 1영상정보패치와, 상기 제 2패 치 맵의 (P,Q)인 제 2영상정보패치를 1:1로 매핑하여, 상기 제 1패치 맵과 상기 제 2패치 맵의 각각의 구성 패 치를 매핑하여 동기화를 수행한다. 여기서, 상기 제 1패치 맵을 구성하는 N개의 제 1영상정보패치와 제 2패치 맵을 구성하는 N개의 제 2영상정보패 치의 동기화를 위해, 각각의 패치를 구성하는 위치좌표를 이용할 수 있고, 상기 동기화된 제 1영상정보패치와, 상기 제 2영상정보패치는 동일한 위치좌표를 가지고 매핑되어 동기화 된다. 이로 인해, 상기 제 1패치 맵을 구 성하는 N개의 제 1영상정보패치와 제 2패치 맵을 구성하는 N개의 제 2영상정보패치 각각은 동일한 위치정보를 저장하고 있다. 여기서, 상기 제 1패치 맵을 구성하는 N개의 제 1영상정보패치는 N개의 서브패치군으로 구성된다. 상기 서브 패치는 한 개 또는 복수 개의 픽셀로 구성된다. 여기서, 상기 픽셀은 공지로 기술된 기술 용어이고, 본 발명에 필요한 범위 내에서 해당 픽셀의 정보에 저장된 정보에 대해 기술한다. 상기 픽셀은 일정정보를 저장하고 있고, 해당 정보를 색상 및 밝기 등으로 표현한다. 상 기 일정 정보는 상기 픽셀의 주소 값, 상기 픽셀의 주소 값에 대응되는 위치정보와 색상정보를 포함할 수 있다. 상기 위치정보는 상기 픽셀의 위치한 위치좌표정보를 포함하고, 상기 색상정보는 공지기술인 색상정보 표시 형 식 인 RGB 값으로 구성되고, RGB 각각의 값은 0~255 범위로 설정하여 사용될 수 있다. 상기 서브 패치는 상기 픽셀을 J개로 구성되고, 상기 J개는 임의로 설정될 수 있다. 바람직하게는 J=4로 설정할 수 있으나, 이에 한정되지 않는다. 또한, 상기 패치는 상기 서브패치 K개로 구성될 수 있고, 상기 K개는 임의로 설정될 수 있다. 바람직하게는 K=4로 설정할 수 있으나, 이에 한정되지 않는다. 여기서, 상기 서브 패치를 구성 하는 특정단위는, J개로 구성된 픽셀을 의미하고, 상기 패치를 구성하는 특정단위는, K개로 구성된 서브패치를 의미한다. 다시, 상기 제 1영상정보를 특정단위로 분리하여 제 1패치 맵을 생성하는 단계(S1410)를 기재하면, 상기 패치 맵 생성부는 상기 제 1영상정보를 N개의 패치로 분리하여 N개의 제 1영상정보패치를 생성하고, 상기 N개의 제 1영상정보패치로 구성되는 제 1패치 맵을 생성한다. 또한, 상기 제 1영상정보패치는 A개의 서브패치로 분리하고, 상기 제 1영상정보패치와 대응되는 상기 A개의 서 브패치로 구성된 서브패치군을 생성한다. 또한, 상기 N개의 모든 제 1영상정보패치에 대해 순차적으로 A개의 서브패치로 분리하고, 상기 N개의 모든 제 1 영상정보패치 각각에 대응되는 N개의 서브패치군을 생성하고, 상기 N개의 서브패치군으로 구성된 서브 패치 맵 을 생성한다. 여기서, 상기 서브 패치맵을 구성하는 N개의 서브패치군과, 상기 제 1패치 맵을 구성하는 N개의 제 1영상정보패 치는, 앞에서 기재된 복수개의 픽셀들로 구성되고, 상기 픽셀의 저장정보인 주소 값, 상기 픽셀의 주소 값에 대 응되는 위치정보와 색상정보도 함께 저장된다. 상기 서브 패치 맵이 생성된 이후, 상기 제 1서브패치군을 구성하는 A개 서브패치의 색상정보 값을 합산하여 평 균 값을 계산하고, 상기 평균 값을 상기 A개의 서브패치의 색상정보 값으로 변경하고, 상기 변경된 색상정보 값 이 반영된 A개의 서브패치로 구성되어 제 1평균서브패치군을 생성한다. 또한, 상기 A개의 서브패치 색상정보 값을 합산하여 평균 값을 계산하고, 상기 평균 값을 상기 A개의 서브패치 의 색상정보 값으로 변경하고, 상기 변경된 색상정보 값이 반영된 A개의 서브패치로 구성되어 제 1평균서브패치 군을 생성하는 과정을, 상기 N개의 모든 서브패치군에 대해 순차적으로 수행하여, N개의 평균서브패치군을 생성 하고, 상기 N개의 평균서브패치군으로 구성된 평균서브 패치 맵을 생성한다. 도 18은 본발명에 일시예에 따른 서브패치군을 구성하는 서브패치의 픽셀 정보 및 평균 연산을 수행하여 제 1평 균서브패치군을 생성하는 개념도이다. 도 18을 참조하면, 1개의 패치가 4개의 서브패치로 구성되고, 상기 서브 패치가 4개의 픽셀로 구성된 일 실시예이다. 여기서, 앞서 기재된 바와 같이, 하나의 픽셀은 RGB 형태의 3가지 색상정보를 포함하고 있으며, 각각의 표현 값 은 0 ~ 255까지 자연수로 표현된다. 상기 서브패치1을 구성하는 4개 픽셀은 색상정보가 기재되어 있고, 상기 서 브패치 2 내지 4를 각각 구성하는 4개의 픽셀은 색상정보 기재되어 있다. 이들 각각의 색상정보를 합산 및 평균연산을 수행하여, 제 1평균 서브패치군을 생성하고, 상기 생성된 제 1 평균 서브 패치군에는 합산 및 평균 연산 이 수행된 색상정보가 반영된다. 앞에서 기술된 바와 같이, 서브 패치는 임의개의 픽셀로 설정할 수 있고, 제 1 패치도 임의개의 서브패치로 설 정할 수 있다. 상기 패치 맵 생성부는 상기 제 1영상정보를 특정단위로 분리하여 제 1패치 맵을 생성하면, 상기 패치 맵 생성부는 상기 제 2영상정보를 특정단위로 분리하여 제 2패치 맵을 생성하는 단계(S1420)를 수행한다. 보다 구체적으로 기술하면, 상기 제 2영상정보를 N개의 패치로 분리하여 N개의 제 2영상정보패치를 생성하고, 상기 N개의 제 2영상정보패치로 구성되는 제 2패치 맵을 생성한다. 일반적으로, 상기 N개의 제 2영상정보패치로 구성되는 제 2패치 맵의 N개의 제 2영상정보패치는 상기 제 1패치 맵을 구성하는 N개의 제 1영상정보패치와 동일한 패치 개수로 구성하는 것이 바람직하다. 결과적으로, 상기 제 1패치 맵을 구성하는 N개의 제 1영상정보패치와, 상기 평균서브 패치 맵을 구성하는 N개의 평균서브패치군과, 상기 제 2패치 맵을 구성하는 N개의 제 2영상정보패치는 동일한 N개의 패치 개수로 구성되는 것이 바람직하다. 상기 제 2영상정보를 특정단위로 분리하여 제 2패치 맵이 생성된 이후, 상기 패치 맵 생성부는 상기 제 1 패치 맵, 상기 제 2패치 맵을 이용하여 후면 패치 맵 생성하는 단계(S1430)를 수행한다. 실시예 중 제 3실시예를 기재한다. 제 3실시예에 대해 기술하면, 상기 N개의 평균서브패치군이 포함된 평균서브 패치 맵 중 제 1평균서브패치군을 둘러싸고 있는 복수개의 제 1 인접평균서브패치군을 설정하고, 상기 제 1평균서브패치군의 제 1가중치와, 상기 제 1평균서브패치군과 상기 복수개의 인접평균서브패치군 간의 이격 거리에 비례하여 상기 복수개의 평균서브패 치군의 제 2가중치를 설정하고, 상기 제 1평균서브패치군에 상기 제 1가중치가 반영된 제 1색상정보 값과, 상기 복수개의 인접평균서브패치군의 색상정보에 제 2가중치가 반영된 제 2색상정보 값의 평균 값을 반영하여 후면 색상정보 값을 생성하고, 상기 후면 색상정보 값이 반영된 후면서브패치군을 생성하고, 상기 후면서브패치군을 생성하는 단계를 상기 평균서브패치 맵을 구성하는 N개의 모든 평균서브패치군에 순차적으로 수행하여, N개의 후면서브패치군을 생성하고, 상기 N개의 후면서브패치군으로 구성되는 후면서브패치 맵을 생성한다. 도 16 내지 20을 참조하여 구체적으로 기재하면, 도 16은 제 1패치 맵과, 제 2패치 맵을 이용하여 생성된 후면 서브패치 맵을 나타내고 있다. 상기 패치 맵 생성부는 상기 제 1패치 맵의 N개의 제 1영상정보패치로부터 생성된 N개의 평균서브패치군으 로 구성된 평균서브 패치 맵을 이용하여, 즉, 일정 연산을 수행하여 N개의 후면서브패치군을 구성된 후면서브패 치 맵을 생성한다. 여기서, 상기 패치 맵 생성부는 상기 평균서브 패치 맵을 구성하는 N개의 평균서브패치군 중 하나인 제 1 평균서브패치군을 임의로 선정하여, 상기 제 1평균서브패치군을 둘러싸고 있는 복수개의 제 1 인접평균서브패치 군을 설정한다. 도 19를 참조하면, 상기 패치 맵 생성부가 중앙에 제 1평균서브패치군을 설정하면, 인접한 평균서브 패치군은 8개가 설정되고, 상기 설정된 8개의 평균서브패치군을 제 1인접평균서브 패치군으로 한다. 여기서, 상기 패치 맵 생성부가 제 1평균 서브패치군에 제 1가중치를 임의로 설정할 수 있고, 일 예 로, 0.4를 설정한 후, 상기 제 1인접평균서브 패치군에 제 2가중치를 임의로 설정할 수 있고, 일 예로, 0.075를 설정할 수 있다. 제 1평균 서브패치군의 제1 가중치와 제 1인접평균서브 패치군을 구성하는 8개의 평균서브패치군의 제 2가중치 합을 1로 하는 것이 바람직하고, 제 1평균 서브패치군의 제1 가중치를 제 1인접평균서브 패치군 의 제 2 가중치보다 크게 설정하는 것이 바람직하다. 또한, 제 1인접평균서브 패치군을 구성하는 8개의 평균서브패치군의 제 2 가중치는 균등하게 설정하는 것이 바람직하다. 일 예로, 상기 제 1 가중치와 상기 제 1인접평균서브 패치군의 제 2가중치는 아래의 수식조건을 만족한다.상기 제 1 가중치인 C는 이고, 상기 제 2 가중치인 w는 이고, 상기 제 1가중치와 상기 제 2가중치들의 상관 관계식인 W은 이고, 상기 Z는 상기 제 1평균서브패치군과, 상기 복수개의 제 1 인접평균서브패치군의 패치군수의 합으로 설정한다. 도 19를 다시 참조하여, 후면서브 패치군을 생성하는 단계를 기술한다. 상기 제 1평균서브패치군은 RGB 색상정보를 저장하고 있고, 상기 제 1가중치를 적용하여, 각각의 RGB 색상정보 값에 상기 제 1가중치가 적용된 합산 값을 구한다. 또한, 제 1인접평균서브 패치군을 구성하는 8개의 평균서브패치군도 각각의 RGB 색상정보 값을 저장하고 있고, 각각의 RGB 색상정보 값에 상기 제 2가중치가 적용된 합산 값을 구한다. 제 1평균서브패치군에 저장된 상기 제 1가중치가 적용된 합산 값과, 제 1인접평균서브 패치군을 구 성하는 8개의 평균서브패치군에 각각의 RGB 색상정보 값에 상기 제 2가중치가 적용된 합산 값의 평균 값을 계산 한다. 상기 평균 값을, 상기 제 1평균서브패치군의 각각의 RGB 색상정보 값으로 대체하여 저장하고, 상기 각각 의 RGB 색상정보 값으로 대체된 상기 제 1평균서브패치군을 제 1 후면서브패치군으로 생성한다. 위에서 기술된 방법을 상기 후면서브패치군을 생성하는 단계를, 상기 평균서브패치 맵을 구성하는 N개의 모든 평균서브패치군에 순차적으로 수행하여, N개의 후면서브패치군을 생성하고, 상기 N개의 후면서브패치군으로 구 성되는 후면서브패치 맵을 생성한다. 상기 후면서브패치 맵이 생성된 이후, 상기 패치 정보를 이용 후면 영상정보 생성(S1240)한다. 상기 N개의 후면서브패치군 사이의 노이즈 제거를 위해서, 상기 노이즈는 공지된 엣지 블렌딩 알고리즘을 적용 하여, 각각 후면 패치의 가장자리 픽셀을 가우시안 블러(Gaussian Blur) 연산을 수행하여 노이즈를 제거하는 엣 지 블렌딩을 수행하고, 최종적인 후면 텍스처 맵을 생성한다. 실시예 중 제 4실시예를 기재한다. 상기 제 4실시예는 데이터 연산량을 감소시키기 위해서, 제 2영상정보 중 인 체 레이블 맵에 해당되는 인체 레이블 패치에 대해서만, 제 1실시예의 가중치 기반 연산을 수행하여 제 1후면서 브패치군을 생성하고, 비인체레이블 맵의 경우, 별도의 가중치 연산을 수행하지 않고, 평균서브패치군을 적용하 여 제 2후면서브패치군을 생성하고, 상기 제 1후면서브패치군과, 상기 제 2후면서브패치군을 적용하여 후면서브 패치 맵을 생성한다. 이에 대해 구체적으로 기술하면, 상기 제 1패치 맵의 (1,1)의 제 1영상정보패치와, 상기 제 2패치 맵의 (1,1)의 제 2영상정보패치를 1:1로 매핑하는 것을 동기화로 표현하고, 상기 제 1패치 맵의 (1,2) 제 1영상정보패치와, 상기 제 2패치 맵의 (1,2) 제 1영상정보패치를 1:1로 매핑하고, 순차적으로 상기 제 1패치 맵의 (P,Q) 제 1영상 정보패치와, 상기 제 2패치 맵의(P,Q) 제 2영상정보패치를 1:1로 매핑하여, 상기 제 1패치 맵과 상기 제 2패치 맵의 각각의 구성 패치를 매핑하여 동기화를 수행한다. 여기서, 상기 제 1패치 맵을 구성하는 N개의 제 1영상정보패치와 제 2패치 맵을 구성하는 N개의 제 2영상정보 패치의 동기화를 위해, 각각의 패치를 구성하는 위치좌표를 이용할 수 있고, 상기 동기화된 제 1영상정보패치와, 상기 제 2영상정보패치는 동일한 위치좌표를 가지고 매핑되어 동기화 된다. 이로 인해, 상기 제 1패치 맵을 구성하는 N개의 제 1영상정보패치와 제 2패치 맵을 구성하는 N개의 제 2영상정보패치 각각은 동 일한 위치정보를 저장하고 있다. 또한, 앞서 기술된 바와 같이, 상기 N개의 서브패치군과, 상기 N개의 제 1평균서브패치군은 색상정보 값만 변경 되어 저장되어 있고, 상기 N개의 서브패치군과, 상기 N개의 제 1평균서브패치군은 상기 N개의 제 1영상정보패치 의 각각의 위치정보를 그대로 저장되어 있다. 따라서, 상기 N개의 제 1평균서브패치군은 상기 제 2패치 맵을 구 성하는 N개의 제 2영상정보패치와 동기화 되어 있어, 동일한 위치좌표를 저장하고 있다. 또한, 앞서 기술된 바와 같이, 상기 제 2패치 맵을 구성하는 N개의 제 2영상정보패치도 각각의 위치정보가 저장 되어 있고, 상기 각각의 위치정보는 인체 레이블 맵과, 비인체레이블 맵의 각각의 패치에 저장되어 있다. 따라서, 상기 N개의 제 1평균서브패치군은, 상기 인체 레이블 맵과, 비인체레이블 맵의 위치정보를 기초로 동기 화 될 수 있다. 상기 N개의 제 1평균서브패치군 중 제 1평균서브패치군의 위치좌표가, 상기 인체 레이블 맵을 구성하는 패치들 의 위치좌표 중 하나의 위치좌표와 동일한 위치 좌표인 경우, 가중치 연산을 수행하여 제 1후면서브패치군을 생 성하고, 상기 N개의 제 1평균서브패치군 중 제 1평균서브패치군의 위치좌표가, 상기 비인체 레이블 맵을 구성하 는 패치들의 위치좌표 중 하나의 위치좌표와 동일한 위치 좌표인 경우, 가중치 연산을 수행하지 않고, 상기 제 1평균서브패치군을 제 2후면서브패치군으로 대체한다. 결과적으로 가중치 연산을 수행하여 생성된 제 1후면서브패치군이 S개, 가중치 연산을 수행하지 않고 생성된 제 2후면서브패치군이 T개라면, S+T=N을 만족하여, 후면서브패치 맵이 생성된다. 이를 상세히 기술하면, 인체 레이블 맵을 구성하는 패치들의 경우, 아래의 과정을 통해 S개의 제 1후면서브패치 군이 생성된다. 상기 N개의 평균서브패치군이 포함된 평균서브 패치 맵 중 제 1평균서브패치군을 둘러싸고 있는 복수개의 제 1 인접평균서브패치군을 설정하고, 상기 제 1평균서브패치군의 제 1가중치와, 상기 제 1평균서브패치군과 상기 복 수개의 인접평균서브패치군 간의 이격 거리에 비례하여 상기 복수개의 평균서브패치군의 제 2가중치를 설정하고, 상기 제 1평균서브패치군에 상기 제 1가중치가 반영된 제 1색상정보 값과, 상기 복수개의 인접평균서 브패치군의 색상정보에 제 2가중치가 반영된 제 2색상정보 값의 평균 값을 반영하여 후면 색상정보 값을 생성하 고, 상기 후면 색상정보 값이 반영된 후면서브패치군을 생성하고, 상기 후면서브패치군을 생성하는 단계를 상기 평균서브패치 맵을 구성하는 N개의 모든 평균서브패치군에 순차적으로 수행하여, S개의 제 1후면서브패치군을 생성한다. 도 16 내지 20을 참조하여 구체적으로 기재하면, 도 16은 제 1패치 맵과, 제 2패치 맵을 이용하여 생성된 후면 서브패치 맵을 나타내고 있다. 상기 패치 맵 생성부는 상기 제 1패치 맵의 N개의 제 1영상정보패치로부터 생성된 N개의 평균서브패치군을 구성된 평균서브 패치 맵을 이용하여, 즉, 일정 연산을 수행하여 S개의 제 1후면서브패치군을 생성한다. 여기서, 상기 패치 맵 생성부는 상기 평균서브 패치 맵을 구성하는 N개의 평균서브패치군 중 하나인 제 1 평균서브패치군을 임의로 선정하여, 상기 제 1평균서브패치군을 둘러싸고 있는 복수개의 제 1 인접평균서브패치 군을 설정한다. 도 19를 참조하면, 상기 패치 맵 생성부가 중앙에 제 1평균서브패치군을 설정하면, 인접한 평균서브 패치군은 8개가 설정되고, 상기 설정된 8개의 평균서브패치군을 제 1인접평균서브 패치군으로 한다. 여기서, 상기 패치 맵 생성부가 제 1평균 서브패치군에 제 1가중치를 임의로 설정할 수 있고, 일 예 로, 0.4를 설정한 후, 상기 제 1인접평균서브 패치군에 제 2가중치를 임의로 설정할 수 있고, 일 예로, 0.075를 설정할 수 있다. 제 1평균 서브패치군의 제1 가중치와 제 1인접평균서브 패치군을 구성하는 8개의 평균서브패치군의 제 2 가중치 합을 1로 하는 것이 바람직하고, 제 1평균 서브패치군의 제1 가중치를 제 1인접평균서브 패치군의 제 2 가중치보다 크게 설정하는 것이 바람직하다. 또한, 제 1인접평균서브 패치군을 구성하는 8개의 평 균서브패치군의 제 2 가중치는 균등하게 설정하는 것이 바람직하다. 여기서, 상기 제 1평균 서브패치군과 인접한 제 1인접평균서브 패치군 중 8개의 평균서브패치군이 상기 인체 레 이블 맵을 구성하는 패치의 위치정보 값에 포함되지 않은 영역, 즉, 비인체 레이블 맵을 구성하는 패치인 경우, 해당 가중치인 제 2가중치를 0으로 설정하고, 상기 제 1평균 서브패치군과 인접한 제 1인접평균서브 패치군 중 8개의 평균서브패치군이 상기 인체 레이블 맵을 구성하는 패치의 위치정보 값에 해당되는 영역인 경우, 제 2가 중치를 부여한다. 일 예로, 상기 제 1 가중치와 상기 제 1인접평균서브 패치군의 제 2가중치는 아래의 수식조건을 만족한다. 상기 제 1 가중치인 C는 이고, 상기 제 2 가중치인 w는 이고, 상기 제 1가중치와 상기 제 2가중치들의 상관 관계식인 W은 이고, 상기 Z는 상기 제 1평균서브패치군과, 상기 복수개의 제 1 인접평균서브패치군의 패치군수의 합으로 설정한다. 도 19을 다시 참조하여, 후면서브 패치군을 생성하는 단계를 기술한다. 상기 제 1평균서브패치군은 RGB 색상정보를 저장하고 있고, 상기 제 1가중치를 적용하여, 각각의 RGB 색상정보 값에 상기 제 1가중치가 적용된 합산 값을 구한다. 또한, 제 1인접평균서브 패치군을 구성하는 8개의 평균서브패치군도 각각의 RGB 색상정보 값을 저장하고 있고, 각각의 RGB 색상정보 값에 상기 제 2가중치가 적용된 합산 값을 구한다. 제 1평균서브패치군에 저장된 상기 제 1가중치가 적용된 합산 값과, 제 1인접평균서브 패치군을 구 성하는 8개의 평균서브패치군에 각각의 RGB 색상정보 값에 상기 제 2가중치가 적용된 합산 값의 평균 값을 계산 한다. 상기 평균 값을, 상기 제 1평균서브패치군의 각각의 RGB 색상정보 값으로 대체하여 저장하고, 상기 각각 의 RGB 색상정보 값으로 대체된 상기 제 1평균서브패치군을 제 1 후면서브패치군으로 생성한다. 위에서 기술된 방법을 상기 후면서브패치군을 생성하는 단계를 상기 평균서브패치 맵을 구성하는 N개의 모든 평 균서브패치군에 순차적으로 수행하여, S개의 후면서브패치군을 생성한다. 비인체 레이블 맵을 구성하는 패치들의 경우, 아래의 과정을 통해 T개의 제 2후면서브패치군이 생성된다. 다시 기술하면, 상기 N개의 제 1평균서브패치군 중 제 1평균서브패치군의 위치좌표가, 상기 비인체 레이블 맵을 구성하는 패치들의 위치좌표 중 하나의 위치좌표와 동일한 위치 좌표인 경우, 가중치 연산을 수행하지 않고, 상 기 제 1평균서브패치군을 제 2후면서브패치군으로 대체하여, T개의 제 2후면서브패치군을 생성한다. 상기 S개의 제 1후면서브패치군과, 상기 T개의 제 2후면서브패치군을 적용하여 최종적은 S+T=N 개의 후면서브 패치군으로 구성되는 후면서브패치 맵을 생성한다. 상기 후면서브패치 맵이 생성된 이후, 상기 패치 정보를 이용 후면 영상정보 생성(S1240)한다. 상기 N개의 후면서브패치군 사이의 노이즈 제거를 위해서, 상기 노이즈는 공지된 엣지 블렌딩 알고리즘을 적용 하여, 각각 후면 패치의 가장자리 픽셀을 가우시안 블러(Gaussian Blur) 연산을 수행하여 노이즈를 제거하는 엣 지 블렌딩을 수행하고, 최종적인 후면 텍스처 맵을 생성한다."}
{"patent_id": "10-2021-0170533", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명에 따른 컨텐츠 영상 제작을 위한 전체 시스템도이다. 도 2는 본 발명에 따른 컨텐츠 영상 제작 방법을 나타내는 흐름도이다. 도 3은 본 발명에 따른 입력영상, 생성된 휴먼포즈 정보, 레이블 맵, 인체 레이블 맵 및 3D 메쉬 정보를 송수신 하기 위한 데이터 프레임 개념도이다. 도 4는 본 발명에 일실시예에 따른 입력된 제 1영상정보를 이용하여 휴먼포즈 데이터를 생성하는 개념도이다. 도 5는 본 발명에 일실시예에 따른 입력된 제 1영상정보를 이용하여 휴먼포즈 데이터인 관절좌표에 대한 도면이 다. 도 6은 본 발명에 따른 입력영상을 이용하여 세그멘테이션하여 레이블 맵을 생성하는 개념도이다. 도 7은 본 발명에 따른 입력영상을 이용하여 3D 메쉬 데이터를 생성하는 개념도이다. 도 8은 본 발명에 일시예에 따른 단말의 컨텐츠 제작부의 개요도이다. 도 9는 본 발명에 일시예에 따른 세그멘테이션 적용된 일 예시도이다. 도 10은 본 발명에 일시예에 따른 3D 메쉬 데이터가 적용된 일 예시도이다. 도 11은 본 발명에 일시예에 따른 3D 메쉬 데이터가 적용된 다른 예시도이다. 도 12는 본 발명에 일시예에 따른 후면 영상정보를 생성하는 흐름도이다. 도 13은 본 발명에 따른 후면 영상정보를 생성하는 방법을 나타내는 개념도이다. 도 14는 본 발명에 일실시예에 따른 제 1영상정보와 제 2영상정보를 이용하여 패치 정보를 생성하는 세부 흐름 도이다. 도 15는 본 발명에 일시예에 따른 인체 레이블 맵과 비인체 레이블 맵을 나타내는 일 예시도이다. 도 16은 본 발명에 일시예에 따른 제 1입력영상과, 제 2입력영상이 복수개의 패치들로 분리되고, 생성되는 후면 서브패치맵을 나타내는 개념도이다. 도 17은 본발명에 일시예에 따른 제 1입력영상의 분리된 제 1영상패치를 서브패치로 분리된 서브패치군을 나타 내는 개념도이다. 도 18은 본발명에 일시예에 따른 서브패치군을 구성하는 서브패치의 픽셀 정보 및 평균 연산을 수행하여 제 1평 균서브패치군을 생성하는 개념도이다. 도 19는 본발명에 일시예에 따른 제 1평균서브패치군과, 제 1인정평균서브패치군에 제 1 및 제 2 가중치를 부여 하는 개념도이다. 도 20은 본발명에 일시예에 따른 제 1 및 제 2 가중치를 부여하여 후면서브패치 맵을 생성하는 개념도이다."}
