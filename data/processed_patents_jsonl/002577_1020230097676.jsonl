{"patent_id": "10-2023-0097676", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0029718", "출원번호": "10-2023-0097676", "발명의 명칭": "인공지능 모델 기반의 유방암 조직병리학 이미지 판별방법", "출원인": "주식회사 휴민텍", "발명자": "박범"}}
{"patent_id": "10-2023-0097676", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "2048x1536의 픽셀 크기를 가진 TIFF 형식인 유방암 조직병리학 이미지 데이터 세트를 입력하는 단계;상기 유방암 조직병리학 이미지 데이터 세트를 얼룩 정규화(Stain Normalization)하는 단계; 상기 얼룩 정규화된 이미지 데이터 세트를 512x512의 픽셀 크기를 가진 패치로 변환하는 단계;상기 변환된 이미지 데이터 세트를 데이터 불균형 처리를 위하여 SMOTE(Synthetic Minority OversamplingTechnique) 기법을 사용하여 오버 샘플링하는 단계;전이학습(transfer learning)을 사용하여 사전 학습된 ResNet-34 모델에서 특징을 추출하는 단계;상기 특징을 모두 추출한 ResNet-34 모델의 최종 레이어를 판별기로 미세조정하는 단계;상기 미세조정된 ResNet-34 모델을 상기 오버샘플링된 이미지 데이터 세트에 적용하는 단계; 및유방암 조직병리학 이미지를 판별하여 정상 또는 침습성 유방암으로 출력하는 단계를 포함하는 인공지능 기반의유방암 조직병리학 이미지 판별방법."}
{"patent_id": "10-2023-0097676", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 전이학습에서 사전 학습된 특징이 추출되면 합성곱 레이어는 고정하고 최종 레이어만 시그모이드 함수가활성화되어 출력을 결정하는 유방암 조직병리학 이미지 판별방법."}
{"patent_id": "10-2023-0097676", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 유방암 조직병리학 이미지를 판별 및 출력하는 단계 다음 검증 및 평가 단계가 추가로 포함되는 유방암 조직병리학 이미지 판별방법."}
{"patent_id": "10-2023-0097676", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서, 상기 검증 및 평가 단계에는 판별값을 평가하여 참양성, 참음성, 위양성, 위음성으로 이루어진 혼동행렬(Confusion Matrix)을 구하고, 상기 혼동행렬을 이용하여 정확도(Accuracy), 정밀도(Precision), 재현율(Recall), F-점수(F-score)를 측정하는 유방암 조직병리학 이미지 판별방법"}
{"patent_id": "10-2023-0097676", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 인공지능 기반의 유방암 조직병리학 이미지 판별방법에 관한 것으로, 구체적으로 2048x1536의 픽셀 크 기를 가진 TIFF 형식인 유방암 조직병리학 이미지 데이터 세트를 입력하는 단계; 상기 유방암 조직병리학 이미지 데이터 세트를 얼룩 정규화(Stain Normalization)하는 단계; 상기 얼룩 정규화된 이미지 데이터 세트를 512x512 (뒷면에 계속)"}
{"patent_id": "10-2023-0097676", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 유방암 조직병리학 이미지 판별방법에 관한 것으로, 구체적으로 인공지능 모델에 기반하여 유방암 조 직병리학 이미지를 분석하고, 정상 또는 침습성 유방암 여부를 판단하여 임상의가 침습성 유방암 슬라이드를 찾 는 시간 및 노력을 줄여주는 유방암 조직병리학 이미지 판별방법에 관한 것이다."}
{"patent_id": "10-2023-0097676", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "유방암은 전세계 여성에게서 발병되는 가장 흔한 암 유형으로, 남성과 여성 모두에서 발생할 수 있지만 여성에 게서 훨씬 더 흔하게 발생하며, 암으로 인한 주요 사망 원인 중 하나로 손꼽히고 있다. 상기 유방암의 다양한 타입을 올바르게 진단하기 위해서는 의학적 검사(일반적으로 외과 의사가 수행)를 실시한 다음, 유방 조직을 현미경으로 분석해야 한다. 이를 위해서는 우선, 생검 재료를 절단한 다음 헤마톡실린 (hematoxylin) 및 에오신(eosin)을 사용하여 염색하여야 한다. 상기 헤마톡실린 용액은 데옥시리보핵산(DNA)에 결합하고 핵을 강조하는 반면, 상기 에오신은 단백질에 결합하고 다른 구조를 강조한다. 그 다음, 전문 병리학 자가 현미경을 사용하여 디지털화된 이미지에서 강조 표시된 영역을 시각화하여 조직 생검을 평가한다. 조직 생 검의 평가는 조직 생검의 초기 단서를 식별할 수 있게 한다. 그러나 전문 병리학자가 이 작업을 수행함에 있어 서는 상당한 시간 및 노력이 투입되어야 한다. 일반인이 유방암을 진단받기 위해서는 시간과 비용이 많이 소요될 뿐만 아니라 병리학자의 사전 지식과 병리학 적 보고의 일관성에 크게 의존할 수밖에 없다. 전문 병리학자의 평균 진단 정확도는 약 75%로 알려져 있다. 한편으로는, 컴퓨터 보조 진단(Computer-Aided Diagnosis) 시스템이 개발되어 의사가 많은 병원에서 환자를 보 다 신속하고 정확하게 진단할 수 있도록 돕고 있다. 상기 CAD 시스템은 유방암 검출의 진단 과정에 통합되어 관 찰자간 편차를 줄이고, 생검 권장 사항을 효과적으로 제공하며, 정상 조직(normal tissues) 및 침습성 암종 (invasive carcinomas)을 구별하는데 사용되고 있다. 하지만, 상기 CAD 시스템은 헤마톡실린 및 에오신으로 염색된 이미지를 사용하여 생검 조직의 진단 효율을 증가 시키는데 기여하였으나, 대부분의 CAD 시스템은 전통적으로 비효율적이고 시간이 많이 소요되는 수작업 특징 추 출 방법을 사용하였다. 또한 최근에는 가장 차별화된 특징을 추출하고 의료 이미지 분석의 효과를 향상시키기 위해 딥러닝 네트워크가 개발되었다. 특징 추출을 위한 딥러닝 네트워크 사용과 관련하여 다음과 같이 두 가지 장점이 있다. 첫 번째, 다른 기계학습 도구를 사용하는 것보다 딥러닝 학습 모델을 사용하여 더 복잡한 특징 세트를 자동으로 추출할 수 있다. 두 번째, 공동 학습 및 계층 학습 특징은 딥러닝 네트워크의 여러 계층에서 추출할 수 있으므로 결과 적으로 딥러닝 네트워크는 특징 선택 단계에서 효율적으로 사용된다. 하지만, 헤마톡실린 및 에오신으로 염색된 유방 조직 생검 이미지는 이미지의 크기가 크기 때문에 딥 러닝 모델 을 사용하여 학습하는데 어려움이 있다. 또한 유방암 조직병리학 이미지 분석의 다른 어려운 문제는 불균형 데이터 문제와 관련이 있다. 예를 들어 DCNN(Deep Convolutional Neural Network)은 사용 가능한 트레이닝 샘플 수가 트레이닝 단계에서 충분히 큰 경 우에만 효과적이다. 반대로, 트레이닝 샘플이 제한되면 이러한 네트워크는 종종 과적합(overfitting)을 겪는다. 자연적인 이미지 판별 작업의 경우와 달리 유방암 검출과 같은 의료 응용 분야를 위한 딥러닝 네트워크의 효과 적인 트레이닝에 사용할 수 있는 의료 이미지는 훨씬 적다. 이는 데이터 프라이버시 문제와 데이터 수집 비용 증가 때문이다. 또한 많은 다른 의료 이미지 응용에서와 같이, 유방암 검출 방법은 환자로부터 데이터를 수집하는 것이 쉬운 일 이 아니기 때문에 불균형한 트레이닝 데이터의 문제가 발생해 왔다."}
{"patent_id": "10-2023-0097676", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 상기와 같은 불균형한 학습 데이터의 문제를 해결하고, 매우 큰 병리학 이미지 데이터 세트를 가능한 최소한의 부하를 투입하여 시스템 성능 및 판별 정확도를 향상시키는 인공지능 기반의 유방암 조직병리학 이미 지 판별방법을 제공하는 것에 그 목적이 있다."}
{"patent_id": "10-2023-0097676", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기 목적을 달성하기 위하여, 본 발명의 인공지능 기반의 유방암 조직병리학 이미지 판별방법에는 2048x1536의 픽셀 크기를 가진 TIFF 형식인 유방암 조직병리학 이미지 데이터 세트를 입력하는 단계, 상기 유방암 조직병리 학 이미지 데이터 세트를 얼룩 정규화(Stain Normalization)하는 단계, 상기 얼룩 정규화된 이미지 데이터 세트 를 512x512의 픽셀 크기를 가진 패치로 변환하는 단계, 상기 변환된 이미지 데이터 세트를 데이터 불균형 처리 를 위하여 SMOTE(Synthetic Minority Oversampling Technique) 기법을 사용하여 오버 샘플링하는 단계, 전이학 습(transfer learning)을 사용하여 사전 학습된 ResNet-34 모델에서 특징을 추출하는 단계, 상기 특징을 모두 추출한 ResNet-34 모델의 최종 레이어를 판별기로 미세조정하는 단계, 상기 미세조정된 ResNet-34 모델을 상기 오버샘플링된 이미지 데이터 세트에 적용하는 단계 및 유방암 조직병리학 이미지를 판별하여 정상 또는 침습성 유방암으로 출력하는 단계를 포함하는 인공지능 기반의 유방암 조직병리학 이미지 판별방법일 수 있다. 본 발명의 다른 일 실시 형태로서, 상기 전이학습에서 사전 학습된 특징이 추출되면 합성곱 레이어는 고정하고 최종 레이어만 시그모이드 함수가 활성화되어 출력을 결정하는 유방암 조직병리학 이미지 판별방법일 수 있다. 본 발명의 다른 일 실시 형태로서, 상기 유방암 조직병리학 이미지를 판별 및 출력하는 단계 다음 검증 및 평가 단계가 추가로 포함되는 유방암 조직병리학 이미지 판별방법일 수 있다. 본 발명의 다른 일 실시 형태로서, 상기 검증 및 평가 단계에는 판별값을 평가하여 참양성, 참음성, 위양성, 위 음성으로 이루어진 혼동행렬(Confusion Matrix)을 구하고, 상기 혼동행렬을 이용하여 정확도(Accuracy), 정밀도 (Precision), 재현율(Recall), F-점수(F-score)를 측정하는 유방암 조직병리학 이미지 판별방법일 수 있다."}
{"patent_id": "10-2023-0097676", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명은 유방암 조직병리학 이미지 판별방법에 있어서, 불균형한 트레이닝 데이터의 문제를 해결하고, 용량이 매우 큰 병리학 데이터 세트의 부하를 최소화하여 시스템 성능 및 판별 정확도를 향상시킬 수 있다."}
{"patent_id": "10-2023-0097676", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 첨부한 도면을 참조하여 본 발명의 인공지능 모델 기반의 유방암 조직병리학 이미지 판별 방법에 대한 바 람직한 실시 예를 상세히 설명한다. 각 도면에 제시된 동일한 참조부호는 동일한 부재를 나타낸다. 또한 본 발 명의 실시 예들에 대해서 특정한 구조적 내지 기능적 설명들은 단지 본 발명에 따른 실시 예를 설명하기 위한 목적으로 예시된 것으로, 다르게 정의되지 않는 한, 기술적이거나 과학적인 용어를 포함해서 여기서 사용되는"}
{"patent_id": "10-2023-0097676", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "모든 용어들은 본 발명이 속하는 기술분야에서 통상의 지식을 가진 자에 의해 일반적으로 이해되는 것과 동일한의미를 가지고 있다. 일반적으로 사용되는 사전에 정의되어 있는 것과 같은 용어들은 관련 기술의 문맥상 가지 는 의미와 일치하는 의미를 가지는 것으로 해석되어야 하며, 본 명세서에서 명백하게 정의하지 않는 한, 이상적 이거나 과도하게 형식적인 의미로 해석되지 않는 것이 바람직하다. 도 1은 본 발명의 유방암 조직병리학 이미지 판별방법의 전체 흐름을 나타낸 도면으로, 상기 유방암 조직병리학 이미지를 판별방법의 각 단계를 나타낸 것이다. 구체적으로, 본 발명의 인공지능 기반의 유방암 조직병리학 이미지 판별방법에는 유방암 조직병리학 이미지 데 이터 세트를 입력하는 단계(S10), 이미지 얼룩 정규화(Stain Normalization) 단계(S11), 얼룩 정규화된 이미지 데이터 세트를 512x512의 픽셀 크기를 가진 패치로 변환하는 단계(S12), 상기 변환된 이미지 데이터 세트를 SMOTE(Synthetic Minority Oversampling Technique) 기법을 사용하여 오버 샘플링하는 단계(S13), 전이학습 (transfer learning)을 사용하여 특징을 추출하는 단계(S14), 학습모델의 최종 레이어를 미세조정하는 단계 (S15), 전이학습된 모델을 오버샘플링된 이미지 데이터 세트에 적용하는 단계(S16), 유방암 조직병리학 이미지 를 판별 및 출력하는 단계(S17)를 포함한다. 유방암 조직병리학 이미지 데이터 세트를 입력하는 단계(S10)는 헤마톡실린 및 에오신으로 염색된 유방 생검 이 미지 데이터를 입력하는 단계로, 정상 및 침습성 유방암 2가지의 클래스를 가진 데이터 세트는 2048x1536 픽셀 의 TIFF(Tag Image File Format) 형식의 현미경 이미지이며, 픽셀 스케일은 0.41㎛ x 0.42 ㎛이다. 일반적으로 병리학자는 TIFF 형식의 현미경 이미지를 주로 사용한다. 본 발명은 병리학자를 위한 판별방법이며, TIFF 형식은 고품질 이미지를 저장하고 데이터의 손실을 피하면서 신경망 모델에서 학습을 수행하는데 있어서 편리하므로 TIFF 형식을 사용하는 것이 바람직하다. 이미지 얼룩 정규화 단계(S11)는 유방암 조직병리학 이미지 데이터 세트의 전처리 과정이다. 유방암 조직병리학 이미지는 관심 영역을 강조하기 위하여 헤마톡실린 및 에오신으로 염색된다. 그러나 헤마톡 실린 및 에오신 염색 과정 또는 조직 슬라이드 이미지 획득 과정에서 헤마톡실린 및 에오신 염색 농도의 차, 스 캔 과정에서 빛의 영향 등의 다양한 환경적 요인으로 인해 유방암 조직병리학 이미지 별로 얼룩 색상값의 차이 가 나타날 수 있다. 유방암 조직병리학 이미지 데이터의 얼룩 색상 값의 차이는 해당 이미지 데이터 세트로 학 습한 모델의 판별 결과에 영향을 미칠 수 있으므로 이미지 얼룩 정규화 과정이 필요하다. 얼룩의 색상을 정규화하는 동안 이미지 품질이 왜곡되어 색상 픽셀이 흩어지는 단점을 보완하기 위해, 구조 보 존의 특성을 가지는 Vahadane 얼룩 정규화 알고리즘을 이용한다. Vahadane 얼룩 정규화 알고리즘을 통해 데이터 세트에 있는 이미지의 얼룩 밀도 맵이 생성될 수 있으며, 대상 이미지의 얼룩 색상과 결합되어 이미지 색상만 변경하고 구조는 보존되어 다른 정규화 기법에 비하여 최소 손실 로 정규화를 수행할 수 있다. 본 발명에서 적용하는 얼룩 정규화 전처리 방식은 유방암 조직병리학 이미지 데이터 세트의 얼룩 밀도 맵을 생 성하는 단계, 상기 얼룩 밀도 맵의 얼룩 세부정보에 따라 목표 이미지의 얼룩을 설정하는 단계, 및 상기 얼룩 밀도 맵의 얼룩과 상기 설정된 목표 이미지의 얼룩을 결합하여 정규 얼룩을 생성하는 단계를 포함한다. 도 2 Vahadane 얼룩 정규화 알고리즘을 이용한 본 발명의 얼룩 정규화 과정을 나타낸 도면이다. Vahadane 얼룩 정규화(Stain Normalization) 알고리즘에서 제공하는 1388x1040 픽셀 크기를 가진 PNG 형식의 얼룩 정규화 이미 지와 2048x1536 픽셀 크기를 가진 TIFF 형식의 소스 이미지를 정규화 하면 두 이미지의 특성이 병합되어 1296x1296 픽셀의 이미지가 생성되는데, 얼룩 정규화 이미지의 얼룩 색상과 결합되어 이미지 색상만 변경되고 구조는 보존되는 것을 확인할 수 있다. 얼룩 정규화된 이미지 데이터 세트를 512x512의 픽셀 크기를 가진 패치로 변환하는 단계(S12)는 CNN(Convolutional Neural Network)이 특징을 정확하게 감지할 수 있도록 이미지를 작은 패치로 변환하여 세부 정보를 강조하는 단계이다. 변환하는 패치의 크기를 512x512 픽셀로 하는 것은 이 패치 크기는 큰 시야(FOV: Field of View)를 포함하고, 더 큰 공간 해상도를 가질 수 있기 때문이다. 일반적으로 사용되는 64x64 및 256x256 크기의 패치는 더 적은 픽 셀과 흐릿한 이미지로 출력 결과를 제공하여 정확도가 떨어질 수 있다. 패치 크기가 클수록 네트워크에 의해 만 들어진 각 예측에 더 많은 샘플이 통합되어 더 나은 결과를 제공하기 때문이다. 모델 정확도를 높이고 명확한 출력 결과를 제공하기 위하여 512x512 크기를 선택하는 것이 바람직하다. 변환된 이미지 데이터 세트를 데이터 불균형 처리를 위하여 SMOTE(Synthetic Minority Oversampling Technique) 기법을 사용하여 오버 샘플링하는 단계(S13)는 모델이 불균형한 크기의 두 클래스를 구분하기 어렵 기 때문에 소수 클래스의 합성 또는 더미 샘플을 생성하여 두 클래스의 분포를 동일하게 만드는 단계이다. 예를 들어, 데이터 세트에서 유방암은 44개의 샘플이 있는 소수 클래스이고 정상은 48개의 이미지가 있는 다수 클래스라고 할 때, SMOTE 알고리즘은 유방암 클래스에 4개의 합성 샘플을 생성하여 샘플 수준을 48개로 높임으 로써 클래스당 48개의 샘플을 갖도록 두 클래스가 균형을 이루게 할 수 있다. 도 4는 본 발명에서 데이터 불균형 처리를 위한 오버 샘플링을 수행하는 모델링 방법의 일 실시예를 나타낸 것으로, 오버샘플링 방식은 침습성 유방암 이미지 데이터의 수량이 이미지 인식을 위한 기계학습의 학습용 데이터 세트로 사용하기에 적합하지 않은 불균형한 상태인 경우에 이를 균형 상태를 만들기 위해 수량이 적은 침습성 유방암 이미지 데이터를 가상 데이터로서 생성하는 방식이다. 도 4에서 살펴보면, 유방암 조직병리학 이미지 데이터 세트 중 샘플의 개수에 기초한 불균형비(IR: Imbalanced Ratio)를 산출할 수 있다(S130). 여기서, 불균형비는 유방암 조직병리학 이미지 데이터 세트에서 다수 클래스의 데이터 수를 소수 클래스의 데이터 수로 나눈 값이다. 불균형비 산출에 앞서 불균형의 판단 기준이 될 수 있는 임계비율이 설정될 수 있는데, 이미지 샘플을 통해 양 성과 음성의 구분이 비교적 명확하다는 측면에서 임계비율은 1.0~1.5로 설정하는 것이 바람직하며, 가장 바람직 하게는 1.0으로 설정하는 것이다. 데이터 불균형 처리를 위한 오버 샘플링을 수행하는 모델링 방법에서는 산출된 불균형비가 불균형의 판단 기준 이 되는 임계 비율, 예를 들어 1.0인지 여부를 판단할 수 있다(S131). 여기서, 임계 비율인 1.0은 하나의 예시 에 불과할 뿐이며 이는 유방암 조직병리학 이미지 샘플의 상태 등에 따라 다르게 설정된다. 만약 산출된 불균형비가 임계 비율인 1.0을 초과하고, 유방암 이미지가 소수 클래스이고, 정상 이미지가 다수 클래스일 경우에는 유방암 조직병리학 이미지의 데이터 세트가 불균형 상태로 판단하여, 소수 클래스인 유방암 이미지의 샘플을 가상 데이터 증강 방식으로 생성한다(S132). 가상 데이터 증강 방식은 소수 클래스의 데이터를 합성하여 증강시키는 오버 샘플링 알고리즘으로 잘 알려져 있는 SMOTE가 사용된다. 만약 산출된 불균형비가 임계 비율인 1.0일 경우에는, 유방암 조직병리학 이미지의 데이터 세트가 균형 상태로 판단되어 가상 데이터 증강 방식의 수행이 중단된다(S133). 전이학습을 사용한 특징 추출 단계(S14)는 사전 학습된 모델로부터 학습된 특징을 추출하여 새모델로 전송하는 단계이다. 전이학습을 위한 신경망 모델은 입력 레이어, 복수의 합성곱 레이어, 풀링 레이어 및 최종 레이어를 포함한다. 입력 레이어는 7x7 크기의 64개의 필터를 가지는 합성곱 신경망 레이어로 구성될 수 있으며, 입력 레이어에는 오버 샘플링 된 데이터 세트의 이미지가 입력된다. 합성곱 레이어 및 풀링 레이어는 복수개가 사용될 수 있으며, 합성곱 레이어는 입력 데이터에 필터를 적용 후 활성화 함수를 반영하여 이미지를 변환할 수 있다. 여기에서 풀링 레이어는 이미지의 차원을 줄이는 서브 샘플 링 레이어 일 수 있고 생략될 수 있다. 하나 이상의 합성곱 레이어는 3x3 크기의 64개의 필터를 가지는 합성곱 신경망 레이어, 3x3 크기의 128개의 필 터를 가지는 합성곱 신경망 레이어, 3x3 크기의 256개 필터를 가지는 합성곱 신경망 레이어 및 3x3 크기의 512 개 필터를 가지는 합성곱 신경망 레이어가 포함될 수 있다. 학습모델의 최종 레이어 미세조정 단계(S15)는 최종 레이어를 시그모이드 활성화 기능으로 대체하여 미세 조정 하는 단계이다. 최종 레이어는 입력 데이터 세트를 기반으로 판별 모델의 출력을 결정할 수 있다. 최종 레이어는 시그모이드 활 성화 기능(SIGMOID; Sigmoid activation function)을 통해 미세 조정될 수 있으며, 상기 미세 조정 이후에는 전체 신경망 모델을 다시 고정 해제하여 학습의 출력을 얻음으로써, 신경망 모델 학습의 처리 속도 및 진단 정 확도를 향상시킨다. 시그모이드 함수를 사용하는 주된 이유는 이진 판별을 수행하기 때문이다. 따라서 확률(0 또는 1)을 출력하는 모형에 특히 사용된다. 본 발명의 인공지능 모델 기반의 유방암 조직병리학 이미지 판별방법은 정상과 침습성유방암의 2가지 클래스만 존재하기 때문에 시그모이드 함수가 적합하다. 본 발명에서 사용되는 신경망 모델은 Resnet-34으로, VGG16, patch-based classifier(PBC) 등과 같은 종래 모 델과 다르게 잔차연결로 각 레이어들이 연결되어 있는 구조로 이루어져 있다. Resnet-34는 Adam Optimizer를 사용하여 최대 학습률 0.01로 10 에포크 동안 학습되었다. 그래디언트 클리핑 (Gradient Clipping)은 0.1로 설정되었고 가중치 감쇠(Weigt Decay)는 0.0001로 설정되었다. Adam Optimizer는 딥 러닝 모델을 훈련하기 위한 확률적 경사 하강을 위한 대체 최적화 알고리즘이다. Adam Optimizer는 AdaGrad 및 RMSProp 알고리즘의 최고 속성을 결합하여 노이즈가 문제에서 희소 기울기를 처리할 수 있는 최적화 알고리즘을 제공한다. 그래디언트 클리핑은 폭발하는 기울기를 처리하는 기술이다. 그래디언트 클리핑의 개념은 매우 간단하다. 기울 기가 너무 커지면 작게 유지하도록 크기를 조정한다. 가중치 감쇠 또는 정규화는 신경망의 가중치에 적용되는 정규화 기술이다. 1차 손실 함수와 가중치의 Norm에 대 한 페널티를 모두 손상시키는 손실 함수를 최소화한다. 도 3는 본 발명의 인공지능 모델 기반 신경망 및 종래의 VGG19 인공지능 모델 기반 신경망의 대략적인 구조를 나타낸 것으로, 34-layer residual이 본 발명에서 사용되는 신경망 모델이다. 상기와 같은 잔차 연결을 통해 본 발명의 신경망 모델 내에는 복수의 잔차 블록이 형성될 수 있으며, 적어도 하 나의 잔차 블록은 다른 잔차 블록의 출력 값을 입력 값으로 수신할 수 있다. 예를 들어, 신경망 모델이 2개의 잔차 블록을 포함하고, 입력 레이어로부터 순차적으로 존재하는 각각의 블록을 제1 잔차 블록, 제2 잔차 블록이라 하면 제2 잔차 블록은 제1 잔차 블록의 출력 값을 입력 값으로 수신할 수 있 다. 잔차 블록은 심층 구조를 갖는 합성곱 신경망 기반 모델에 있어 기존의 스택 구조에 일종의 스킵 연결(또는 숏 컷 연결로 지칭됨)을 추가한 구조를 가질 수 있다. 도 5는 가중치 레이어의 입력과 출력이 ID 연결을 통해 연결되는 방식의 잔차 블록의 형태를 보여주고 있다. 잔차 블록에서는 입력이 x이면, 최종적으로 학습해야 할 데이터는 H(x)이고, 상기 H(x)는 F(x) + x로서, F(x) = H(x) - x로 표현될 수 있다. 따라서, 잔차 블록은 가중치 레이어를 통해 쌓여진 출력 H(x)와 입력 간의 잔차를 학습함으로써 결과적으로 원 래 학습을 의도한 결과 F(x)를 얻을 수 있으며, 이와 같이 잔차만 학습하면 되는 잔차 학습 블록 구조를 갖는 합성곱 신경망 기반 모델의 학습은 잔차 학습으로 지칭될 수 있다. 본 발명에서 신경망 학습 모델 내 복수의 잔차 블록 각각은 복수의 레이어 배열을 각각 포함할 수 있으며, 상기 레이어 배열에는 최종 레이어가 포함될 수 있다. 상기와 같은 잔차 학습을 적용함으로써, 합성곱 신경망 기반 모델이 합성곱 레이어에 입력되는 유방암 조직병리 학 이미지를 학습할 때, 합성곱 레이어의 기존 파라미터와 입력된 유방암 조직병리학 이미지로 새롭게 생성된 파라미터 사이의 차이 값으로만 학습할 수 있다. 상기와 같은 잔차 학습의 적용을 통해 본 발명의 신경망 학습 모델에서는 합성곱 레이어 간에 연결을 통해 기울 기 값을 일정하게 유지할 수 있으면서도, 모델 학습 중 가중치를 학습하기 위해 기울기가 역전될 때, 레이어 간 의 손실로 인한 기울기가 소실되지 않으므로 유방암 조직병리학 이미지 판별 시스템의 성능 및 판별 정확도가 향상될 수 있다. 본 발명에서는 신경망 모델을 학습시키는 방법은 함수의 기울기를 구하여 기울기가 낮은 쪽으로 계속 이동시켜 극값(최적값)에 이를 때까지 반복하는 경사하강법이다. 경사하강법은 오차의 변화에 대한 합성곱 레이어의 가중치 변화를 측정하고, 복수의 합성곱 레이어에서의 최종 레이어에서 최종 레이어에 도달할 때까지의 기울기를 역전파하는 가중치 학습 방법이다. 신경망 모델은 복수개의 레이어를 가지고 있지만 가중치를 측정하는 동안 기울기 값은 계속 감소할 수 있으며, 입력 레이어에 도달하면 0이 될 수 있는데, 이를 기울기 소실이라 한다. ResNet-34 모델은 가중치 레이어 간에 ID 연결이 있으므로, 기울기 역전파(back-propagation)시 각 복수의 레이 어에서 잔차를 가져와 후속 레이어에서 사용하므로 기울기 값이 각 레이어에서 일정하게 유지될 수 있고, 신경 망 모델 전체 성능이 향상될 수 있다. 반면, VGG16, Patch-Based Classifier(PBC) 등 다른 신경망 모델은 가중치 계층 간에 ID 연결이 없으므로 모델 학습 중에 기울기 값이 감소하며, 신경망 모델 전체 성능이 저하될 수 있다. 학습된 모델을 데이터 세트에 적용하는 단계(S16)에서 신경망 모델을 학습시키기 위한 소스코드는 구글 코랩의 파이썬 언어로 작성된 코드이다. 도 6은 판별이기(ImageClassifiactionBase)로 최종 레이어를 미세 조정한 다음 사전 학습된 모델 (BreastCancerResnet34)로 가져오는 알고리즘의 일부이다. 학습된 모델을 데이터 세트에 적용하는 단계(S16)를 수행하는 세부 과정을 설명하면 다음과 같은데, 파이썬 라 이브러리를 가져오는 단계, 구글 코랩을 클라이드 저장소와 연동하는 단계, 상기 클라우드 저장소로부터 데이터 세트를 가져오는 단계; 상기 데이터 세트를 학습 세트, 테스트 세트 및 검증 세트로 분할하고 저장하는 단계, 배치 사이즈를 조절하는 단계, F-점수 알고리즘을 정의하는 단계, SMOTE 오버샘플링을 포함하는 영상판별 알고 리즘을 가져오는 단계, 유방암 진단을 위한 Resnet-34 신경망 모델을 가져오는 단계, 최종 레이어를 교체하고 합성곱 레이어를 포함하는 나머지 레이어는 고정하는 단계, 상기 신경망 모델을 평가하는 단계, 에포크의 수 및 학습 시간을 세팅하는 단계, 상기 합성곱 레이어를 포함하는 나머지 레이어에 저장된 매개변수를 고정한 상태에 서 최종 레이어를 학습하는 단계 및 상기 고정된 매개변수를 고정 해제하고 상기 모델을 다시 학습하는 단계를 포함한다. 처음부터 전체 신경망 모델을 학습하는 대신에 초기 계층을 고정하고, 데이터 세트로 마지막 몇 계층만 학습함 으로써, 시간을 절약하고 모델 성능을 향상시킬 수 있다. 구체적으로, 상기 전이 학습은 상기 학습한 신경망 모 델에서 합성곱 레이어는 고정하고, 이것은 최종 레이어만 학습되는 방식으로 수행된다. 구체적으로 전이 학습은 사전 학습된 신경망 모델에서 합성곱 레이어는 고정하고 최종 레이어만 학습되는 방식으로 수행된다. 도 7은 학습모델의 전이학습 과정을 나타낸 흐름도이다. ResNet-34의 최종 레이어는 이미지 데이터 세트를 기반 으로 판별 모델의 출력을 결정한다. 도 7과 같이, 최종 레이어만 시그모이드 활성화 기능으로 대체하여 미세 조 정되었으며 나머지 4개의 합성곱 레이어는 고정되었다. 전이학습을 사용하여 ResNet-34의 모든 합성곱 레이어에 서 사전 훈련된 기능을 추출하고 추출이 완료된 레이어를 고정한 다음 최종 레이어에 미세 조정을 적용한 후 전 체 모델을 다시 고정 해제하여 출력을 결정한다. 전이 학습은 이미 학습된 다른 인공 신경망의 변수(예: 가중치 값)를 해당 인공 신경망에 적용하는 학습 방법이 다. 즉, 시스템의 초기 설치과정 중, 사용자의 명령 또는 주어진 조건의 만족에 따라, 본 발명의 일 실시 예에 따른 다른 시스템의 인공 신경망을 이용한 전이 학습이 수행될 수 있다. 파이썬 라이브러리는 텐서플로우, 파이토치, 케라스 또는 테아노 등의 소프트웨어 일 수 있다. 텐서플로우는 구글에서 공개된 딥 러닝과 머신 러닝 기술인 오픈소스 소프트웨어를 의미한다. 파이토치는 파이 썬을 위한 오픈소스 머신 러닝 라이브러리로 토치를 기반으로 하며, 자연어 처리와 같은 애플리케이션을 위해 사용된다. GPU사용이 가능하기 때문에 속도가 상당히 빠르다. 케라스는 파이썬으로 작성된 오픈 소스 신경망 라이브러리이다. MXNet, Deeplearning4j, 텐서플로, Microsoft Cognitive Toolkit 또는 Theano 위에서 수행할 수 있다. 딥 신경망과의 빠른 실험을 가능케 하도록 설계되었으 며 최소한의 모듈 방식의 확장 가능성에 초점을 둔다. TensorFlow, Theano, CNTK 등 딥 러닝 라이브러리를 포함 하고 있어 쉽게 다층 퍼셉트론 신경망 모델, 컨볼루션 신경망 모델, 순환 신경망 모델, 조합 모델 등을 구성할 수 있다. 테아노는 파이썬 라이브러리의 하나로 다차원 배열과 관계가 있는 수학적 표현을 정의하고, 최적화하며, 평가하 도록 해준다. 데이터 세트는 학습 세트, 테스트 세트 및 검증 세트로 분할되고 저장되는데, 학습 데이터 세트는 신경망을 학 습시키는 데 사용되고, 검증 데이터 세트는 은닉 레이어 개수와 같은 초매개변수를 튜닝하는 데 사용되며, 테스 트 데이터 세트는 신경망의 성능을 최종 평가하는 데 사용된다. 유방암 조직병리학 이미지 판별 및 출력 단계(S17)은 이미지 판별 모듈에서 수행되며, 전이 학습을 통해 신경망 모델을 적용한 유방암 조직병리학 이미지 데이터 세트를 정상 또는 침습성 유방암의 2가지 클래스로 판별하고소프트웨어 응용프로그램에 적용하여 판별 결과물을 출력하는 단계이다. 도 9는 본 발명의 유방암 조직병리학 이미지 알고리즘을 구현하여 실제 사용되고 있는 소프트웨어 응용 프로그 램을 나타낸 도면이다. 구체적으로 상기 소프트웨어 응용 프로그램은 얼룩 정규화, 오버샘플링 및 암을 판별하기 위한 개별 모듈로 설 계될 수 있으며, 사용자는 “가져오기” 탭을 사용하여 애플리케이션에서 유방암 조직병리학 이미지를 가져와서 이미지 판별을 수행할 수 있는데, 이미지 ID가 있는 판별된 이미지 형식으로 “결과(result)”탭에서 결과의 출 력을 얻을 수 있다. 도 10는 본 발명의 인공지능 모델 기반의 유방암 조직병리학 이미지 판별방법을 통해 얻은 출력 이미지이다. 좌 측의 이미지는 정상 조직의 이미지이고, 우측의 이미지는 침습성 유방암 조직의 이미지이다. 유방암 조직병리학 이미지를 판별 및 출력하는 단계 이후 검증 및 평가하는 단계가 추가로 포함될 수 있다. 도 8은 SMOTE를 적용하고 Resnet-34 모델을 사용한 본 발명의 실시예와 SMOTE 적용 없이 Resnet-34 모델을 사용 한 비교예의 판별결과를 평가하여 각각 혼동행렬로 나타낸 도면이다. 혼동행렬은 판별 모델의 예측 결과를 평가하는 데 사용되는 행렬이며 참양성(TP: True Positive), 위양성(FP: False Positive), 위음성(FN: False Negative), 참음성(TN: True Negative)을 구성요소로 한다. 참양성은 유방암 이미지를 양성으로 판별한 경우이고, 위양성은 정상 이미지를 양성으로 판별한 경우이며, 위음 성은 유방암 이미지를 음성으로 판별한 경우고, 참음성은 정상 이미지를 음성으로 판별한 경우이다. 혼동행렬을 이용하여 정확도(Accuracy), 정밀도(Precision), 재현율(Recall), F-점수(F-score) 등의 판별 모델 성능 지표를 계산할 수 있다. 혼동행렬은 판별 모델의 성능을 시각화하고 평가하는데 매우 유용한 도구이다. 정확도는 가장 직관적인 성능 측정값으로, 전체 판별값에 대한 참양성 및 참음성의 합의 비율이다. 데이터 집합 의 균형이 맞지 않으면 정확도가 좋지 않을 수 있다."}
{"patent_id": "10-2023-0097676", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "정밀도는 전체 양성으로 판별된 판별값에 대한 참양성의 비율이다. 정밀도가 1에 가까울수록 좋은 판별기이다. 정밀도는 분자와 분모가 동일한 경우에만 1이 되며, 이는 위양성이 0임을 의미한다."}
{"patent_id": "10-2023-0097676", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "재현율은 민감도 또는 참양성의 비율이라고도 하며 참양성의 수를 참양성과 위음성의 합으로 나눈 값으로 정의 할 수 있다. 재현율이 1에 가까울수록 좋은 판별기이다. 재현율은 분자와 분모가 동일한 경우에만 1이 되며, 이 는 위음성이 0임을 의미한다."}
{"patent_id": "10-2023-0097676", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "F-점수는 상기와 같은 정밀도와 재현율을 모두 고려한 측정 기준으로 정밀도와 재현율의 조화평균으로 정의된다. 위양성과 위음성이 모두 0일 때 F-점수는 1이 된다."}
{"patent_id": "10-2023-0097676", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "본 발명의 유방암 조직병리학 이미지 알고리즘을 구현한 모델의 정확도, 손실 및 학습률은 에포크를 기준으로 학습 전반에 걸친 모델 수행 성능의 추세를 볼 수 있다. 여기에서 에포크는 학습 알고리즘이 전체 학습 데이터세트를 통해 실행되는 횟수를 정의하는 하이퍼 파라미터로, 본 발명의 신경망 모델은 최대 10번의 에포크를 가 질 수 있다. 본 발명에서는 8~10번의 에포크에서 F-점수가 0.5~0.6의 범위에서 일정하게 나타날 수 있는데, 에포크가 8번 미 만일 때 F-점수가 일정하게 나타날 경우에는 신경망 모델의 데이터 처리의 재현율이 저하될 수 있고, 에포크가 10번을 초과할 때 F-점수가 일정하게 나타날 경우에는 신경망 모델의 데이터 처리 속도가 낮아져 모델 성능이 저하되었음을 의미한다. 또한, 본 발명에서는 상기 8~10번의 에포크 범위에서 F-점수가 0.5~0.6의 범위에서 일정하게 나타날 수 있는데, F-점수가 0.5 미만에서 일정할 경우에는 신경망 모델의 데이터 처리 정확도에 문제가 있을 수 있고, 0.6을 초과 할 경우에는 신경망 모델의 데이터 처리의 재현율이 저하될 수 있다. 본 발명에서는 7~10 에포크에서 로스가 0에 수렴할 수 있는데, 7 에포크 미만에서 로스가 0에 수렴할 경우에는 신경망 모델의 데이터 처리의 재현율이 저하될 수 있고, 10 에포크 초과하여 로스가 0에 수렴할 경우에는 신경 망 모델의 데이터 처리 속도가 낮아져 모델 성능이 저하되는 현상이 발생할 수 있다. 8 에포크 이전에는 검증 데이터셋이 신경망 모델에 적합하게 적응하려 했기 때문에 로스가 높게 나타났지만, 8 에포크 이후에는 과적합(over-fitting) 요인이 제거되어 로스가 0으로 감소되었다. 본 발명에서는 배치 크기가 14~20에서 학습률의 최대값이 나타날 수 있는데, 배치 크기가 상기의 범위 내에 있 을 때, 신경망 모델의 데이터 처리 속도가 최적화되어 최대값에 도달하는 데 소요되는 시간을 최대한 단축시킬 수 있다. 이하, 본 발명의 이해를 돕기 위하여 구체적인 실시예를 제시한다. 그러나, 하기의 실시예는 본 발명을 보다 쉽"}
{"patent_id": "10-2023-0097676", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 7, "content": "게 이해하기 위해서 제공되는 것일 뿐, 실시예에 의하여 본 발명의 내용이 한정되는 것은 아니다. <신경망 모델의 정확도, 정밀도, 재현율, F-점수, 위양성 및 위음성 측정> 하기의 [표 1]은 SMOTE 오버샘플링을 함께 수행한 Resnet-34 학습모델과 오버샘플링을 수행하지 않은 기존의 신 경망 모델에 사용된 사용된 데이터 세트 및 신경망 모델을 나타낸 것이다. 기존의 신경망 모델은 VGG16, Image Wise Classification이다. 여기에서 SMOTE 오버샘플링을 함께 수행한 Resnet-34을 실시예 1로, SMOTE 오버샘플링을 수행하지 않은 Resnet- 34, VGG16 및 Image Wise Classification을 각각 비교예 1~3으로 하였고, 상기 학습모델들에 입력되는 모든 이 미지는 2048X1536인 고해상도를 나타내는 TIFF 형식으로, 상기 이미지 200개를 3.61GB 램을 사용하여 각각의 딥 러닝 프레임 워크의 판별 성능을 평가하였다. 표 1 구분 데이터 세트 신경망 모델 실시예1 ICIAR Breast Cancer Dataset Resnet-34 - with SMOTE Sampling Technique 비교예1 ICIAR Breast Cancer Dataset Resnet-34 비교예2 Breakhis Dataset VGG16 비교예3 ICIAR Breast Cancer Dataset Image Wise Classification 상기 실시예 1, 비교예 1~3의 신경망 모델 및 데이터 세트를 기반으로 정확도, 정밀도, 재현율, F-점수를 측정 하였고, 결과는 하기의 [표 2]와 같다. 표 2 구분 정확도 정밀도 재현율 F-점수 실시예 1 96.5% 92% 100% 96% 비교예 1 94% 94% 94% 94% 비교예 2 92.4% 61.56% 62.40% 61.55% 비교예 3 92.5% 92.59 92.39% 92.49 본 발명에 유방암 조직병리학 이미지 판별방법으로 판별한 실시예에서는 100%의 재현율이 나왔고 이는 위음성이 0임을 의미한다. <신경망 모델의 처리시간 측정> 상기 실시예 1, 비교예 1~3의 조건으로 이미지 데이터를 판별하는데 걸리는 처리시간을 측정하였고, 결과는 하 기의 [표 3]과 같다. 표 3 실시예 1 비교예 1 비교예 2 비교예 3 처리시간 5분 10분 8분 11분 상기의 [표 3]에서 살펴본 바와 같이, 2048X1536인 고해상도를 나타내는 TIFF 형식 이미지 200개를 3.61GB 램을 사용하여 판별할 때, 실시예 1의 신경망 모델 기반으로 처리할 때 소요되는 시간은 5분으로, 비교예 1~3의 신경 망 모델을 기반으로 처리한 경우와 대비하여 볼 때 고해상도를 나타내는 TIFF 형식 이미지를 빠르게 처리하는 것으로 확인되었다."}
{"patent_id": "10-2023-0097676", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 유방암 조직병리학 이미지 판별방법의 흐름도이다. 도 2는 Vahadane 얼룩 정규화 알고리즘을 이용한 본 발명의 얼룩 정규화 과정을 나타낸 도면이다. 도 3은 본 발명의 인공지능 모델 기반 신경망 및 종래의 VGG19 인공지능 모델 기반 신경망의 구조를 비교한 것 이다. 도 4는 본 발명에서 데이터 불균형 처리를 위한 오버 샘플링을 수행하는 방법의 흐름도이다. 도 5는 가중치 레이어의 입력과 출력이 ID 연결을 통해 연결되는 방식의 잔차 블록의 형태를 나타낸 것이다. 도 6은 본 발명에서 최종 레이어를 미세 조정하는 알고리즘이다. 도 7은 모델의 전이학습 관정을 나타낸 흐름도이다. 도 8은 본 발명의 실시예와 비교예 1의 판별결과를 검증하여 혼동 행렬로 나타낸 도면이다. 도 9은 본 발명의 유방암 조직병리학 이미지 알고리즘을 구현한 응용 프로그램의 화면이다. 도 10는 본 발명의 인공지능 모델 기반의 유방암 조직병리학 이미지 판별방법을 통해 얻은 출력 이미지이다."}
