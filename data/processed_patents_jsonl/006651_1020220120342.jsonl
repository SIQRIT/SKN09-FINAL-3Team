{"patent_id": "10-2022-0120342", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0041159", "출원번호": "10-2022-0120342", "발명의 명칭": "CPU-GPU 협업 시스템 및 방법", "출원인": "주식회사 글로벌탑넷", "발명자": "이현호"}}
{"patent_id": "10-2022-0120342", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "CPU 모듈;상기 CPU 모듈과 제1 시리얼 버스 및 제2 시리얼 버스 중 적어도 하나의 시리얼 버스를 통해 연결되는 하나 이상의 확장 모듈;상기 CPU 모듈과 상기 하나 이상의 확장 모듈 중 적어도 일부의 모듈로부터 작업 요청을 생성한 하나의 모듈 그룹을 식별하는 제1 제어 모듈;상기 요청에 응답하여 작업을 수행하는 GPU 모듈;상기 CPU 모듈 및 상기 GPU 모듈과 연관된 메인 메모리; 및상기 요청을 상기 GPU 모듈로 전달하는 제2 제어 모듈을 포함하고, 상기 GPU 모듈은 상기 요청과 연관된 상기 메인 메모리 상의 주소 정보를 기초로 상기 메인 메모리의 데이터 영역에 접근하도록 구성될 수 있다."}
{"patent_id": "10-2022-0120342", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 CPU 모듈 및 상기 하나 이상의 확장 모듈은 외부 장치와 연결되도록 구성된 인터페이스를 각각 포함할 수있다."}
{"patent_id": "10-2022-0120342", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 모듈 그룹은 상기 제1 시리얼 버스 또는 상기 제2 시리얼 버스 중 어느 하나의 시리얼 버스를 통해 통신할수 있다."}
{"patent_id": "10-2022-0120342", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,상기 모듈 그룹은 상기 CPU 모듈을 포함하지 않는, CPU-GPU 서버 협업 시스템."}
{"patent_id": "10-2022-0120342", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서,상기 모듈 그룹은 제1 작업 요청을 생성한 제1 모듈 그룹 및 제2 작업 요청을 생성한 제2 모듈 그룹을포함하고,상기 제2 제어 모듈은 상기 제1 작업 요청과 상기 제2 작업 요청을 비교한 결과를 기초로 상기 제1 작업 요청을작업 대상 요청으로 결정하고, 상기 작업 대상 요청과 연관된 상기 메인 메모리 상의 제3 주소 정보를 기초로공개특허 10-2024-0041159-3-상기 GPU의 제4 주소 공간과 상기 제3 주소 공간의 맵핑을 수행할 수 있다."}
{"patent_id": "10-2022-0120342", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5항에 있어서,상기 비교한 결과는 상기 제1 작업 요청에 따른 제1 작업과 상기 제2 작업 요청과 연관된 제2 작업의 연산 시간을 비교한 결과를 포함할 수 있다."}
{"patent_id": "10-2022-0120342", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에 있어서,상기 하나 이상의 확장 모듈은 상기 하나 이상의 확장 모듈로부터 상기 하나의 모듈 그룹에 포함되는 적어도 일부의 모듈을 구분하도록 구성된 통신 회로를 각각 포함할 수 있다."}
{"patent_id": "10-2022-0120342", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1항에 있어서,상기 하나 이상의 확장 모듈은 제1 확장 모듈, 제2 확장 모듈 및 제3 확장 모듈을 포함하고,상기 작업 요청을 생성한 상기 하나의 모듈 그룹이 상기 제1 확장 모듈 및 상기 제2 확장 모듈을 포함하는경우, 상기 제1 확장 모듈과 상기 제2 확장 모듈은 상기 제2 확장 모듈의 통신 회로에 의해 서로 연결되고, 상기 제2 확장 모듈과 상기 제3 확장 모듈은 상기 제3 확장 모듈의 통신 회로에 의해 서로 분리될 수 있다."}
{"patent_id": "10-2022-0120342", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 개시의 일 실시예에 따르면, CPU-GPU 서버 협업 시스템은 CPU 모듈, CPU 모듈과 제1 시리얼 버스 및 제2 시리 얼 버스 중 적어도 하나의 시리얼 버스를 통해 연결되는 하나 이상의 확장 모듈, CPU 모듈과 하나 이상의 확장 모듈 중 적어도 일부의 모듈로부터 작업 요청을 생성한 하나의 모듈 그룹을 식별하는 제1 제어 모듈, 요청에 응 답하여 작업을 수행하는 GPU 모듈, CPU 모듈 및 GPU 모듈과 연관된 메인 메모리 및 요청을 GPU 모듈로 전달하는 제2 제어 모듈을 포함하고, GPU 모듈은 요청과 연관된 메인 메모리 상의 주소 정보를 기초로 메인 메모리의 데이 터 영역에 접근하도록 구성될 수 있다."}
{"patent_id": "10-2022-0120342", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 CPU-GPU 서버 협업 시스템 및 방법에 관한 것이다."}
{"patent_id": "10-2022-0120342", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "GPU(Graphic Processing Unit)는 본래 그래픽 연산, 특히 3D 관련 연산에 초점을 맞춘 특수 목적 프로세서였으 나 최근에는 인공지능 연산 및 병렬 컴퓨팅 목적으로 수요가 크게 늘어나면서 전통적인 CPU 제조사까지 GPU개발 에 뛰어들고 있다. 그러나, 그렇다고 해서 GPU가 CPU가 하던 일을 모두 대신할 수 있는 것은 아니다. GPU는 연산 장치(ALU)의 구 조가 단순하고, 작은 제어/캐시 영역을 가지며 멀티-코어 구조로 설계되기 때문에 특정 연산에 대하여 매우 빠 른 속도를 보인다. 특히, 직렬 연산이 아닌 병렬 연산에 최적화된 구조적 특징으로 인해 HPC(High Performance Computing) 분야, 보안과 네트워크 장비 분야 등에서 그 활용에 대한 관심이 커지고 있다. 그러나, 컴퓨터가 제대로 작동하기 위해서는 여전히 CPU의 역할이 중요하다. 이와 같은 이유로 최근 CPU와 GPU의 연계가 중요해 지고 있으나, 두 프로세서에 의한 연산 작업이 효과적으로 스케줄링 되고 분산될 수 있도록 CPU, GPU, I/0 메모 리 관리를 하나의 아키텍처로 결합하는 것은 시스템과 애플리케이션 소프트웨어가 단일화된 CPU/GPU 시스템 아 키텍처의 특징, 특성, 상호 연결 및 속성을 모두 고려해야한다는 어려움이 따른다."}
{"patent_id": "10-2022-0120342", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 개시에서는 상술한 문제를 해결하기 위한 멀티 모듈 방식의 CPU-GPU 서버 협업 시스템 및 방법이 제공된다."}
{"patent_id": "10-2022-0120342", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 개시의 일 실시예에 따르면, CPU-GPU 서버 협업 시스템은 CPU 모듈, CPU 모듈과 제1 시리얼 버스 및 제2 시 리얼 버스 중 적어도 하나의 시리얼 버스를 통해 연결되는 하나 이상의 확장 모듈, CPU 모듈과 하나 이상의 확 장 모듈 중 적어도 일부의 모듈로부터 작업 요청을 생성한 하나의 모듈 그룹을 식별하는 제1 제어 모듈, 요청에 응답하여 작업을 수행하는 GPU 모듈, CPU 모듈 및 GPU 모듈과 연관된 메인 메모리 및 요청을 GPU 모듈로 전달하 는 제2 제어 모듈을 포함하고, GPU 모듈은 요청과 연관된 메인 메모리 상의 주소 정보를 기초로 메인 메모리의 데이터 영역에 접근하도록 구성될 수 있다. 일 실시예에 따르면, CPU 모듈 및 하나 이상의 확장 모듈은 외부 장치와 연결되도록 구성된 인터페이스를 각각 포함할 수 있다. 일 실시예에 따르면, 모듈 그룹은 제1 시리얼 버스 또는 제2 시리얼 버스 중 어느 하나의 시리얼 버스를 통해 통신할 수 있다. 일 실시예에 따르면, 모듈 그룹은 CPU 모듈을 포함하지 않도록 구성될 수 있다. 일 실시예에 따르면, 모듈 그룹은 제1 작업 요청을 생성한 제1 모듈 그룹 및 제2 작업 요청을 생성한 제2 모듈 그룹을 포함하고, 제2 제어 모듈은 제1 작업 요청과 제2 작업 요청을 비교한 결과를 기초로 제1 작업 요청을 작 업 대상 요청으로 결정하고, 작업 대상 요청과 연관된 메인 메모리 상의 제3 주소 정보를 기초로 GPU의 제4 주 소 공간과 제3 주소 공간의 맵핑을 수행할 수 있다. 일 실시예에 따르면, 비교한 결과는 제1 작업 요청에 따른 제1 작업과 제2 작업 요청과 연관된 제2 작업의 연산 시간을 비교한 결과를 포함할 수 있다. 일 실시예에 따르면, 하나 이상의 확장 모듈은 하나 이상의 확장 모듈로부터 하나의 모듈 그룹에 포함되는 적어 도 일부의 모듈을 구분하도록 구성된 통신 회로를 각각 포함할 수 있다. 일 실시예에 따르면, 하나 이상의 확장 모듈은 제1 확장 모듈, 제2 확장 모듈 및 제3 확장 모듈을 포함하고, 작 업 요청을 생성한 하나의 모듈 그룹이 제1 확장 모듈 및 제2 확장 모듈을 포함하는 경우, 제1 확장 모듈과 제2 확장 모듈은 제2 확장 모듈의 통신 회로에 의해 서로 연결되고, 제2 확장 모듈과 제3 확장 모듈은 제3 확장 모 듈의 통신 회로에 의해 서로 분리될 수 있다."}
{"patent_id": "10-2022-0120342", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 개시의 일부 실시예에 따르면, 확장 모듈을 통해 I/O 인터페이스의 범용성을 향상시킴과 동시에 메모리의 접 근 횟수를 감소시켜 전력 소비 효율을 극대화할 수 있는 CPU-GPU 서버 협업 시스템이 제공될 수 있다. 도 2는 본 개시의 일 실시예에 따른 CPU 모듈 및 복수의 확장 모듈(120_1 내지 120_N) 각각의 구성을 나타 내는 블록도이다. 도 3은 본 개시의 하나 이상의 확장 모듈을 포함하는 모듈 그룹을 설명하기 위한 블록도이다. 도 4는 본 개시의 일 시시예에 따른 제2 제어 모듈의 구성을 나타내는 블록도이다."}
{"patent_id": "10-2022-0120342", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 본 개시의 실시를 위한 구체적인 내용을 첨부된 도면을 참조하여 상세히 설명한다. 다만, 이하의 설명에 서는 본 개시의 요지를 불필요하게 흐릴 우려가 있는 경우, 널리 알려진 기능이나 구성에 관한 구체적 설명은 생략하기로 한다. 첨부된 도면에서, 동일하거나 대응하는 구성요소에는 동일한 참조부호가 부여되어 있다. 또한, 이하의 실시예들 의 설명에 있어서, 동일하거나 대응되는 구성요소를 중복하여 기술하는 것이 생략될 수 있다. 그러나 구성요소 에 관한 기술이 생략되어도, 그러한 구성요소가 어떤 실시예에 포함되지 않는 것으로 의도되지는 않는다. 개시된 실시예의 이점 및 특징, 그리고 그것들을 달성하는 방법은 첨부되는 도면과 함께 후술되어 있는 실시예 들을 참조하면 명확해질 것이다. 그러나 본 개시는 이하에서 개시되는 실시예들에 한정되는 것이 아니라 서로 다른 다양한 형태로 구현될 수 있으며, 단지 본 실시예들은 본 개시가 완전하도록 하고, 본 개시가 통상의 기술 자에게 발명의 범주를 완전하게 알려주기 위해 제공되는 것일 뿐이다. 본 명세서에서 사용되는 용어에 대해 간략히 설명하고, 개시된 실시예에 대해 구체적으로 설명하기로 한다. 본 명세서에서 사용되는 용어는 본 개시에서의 기능을 고려하면서 가능한 현재 널리 사용되는 일반적인 용어들을 선택하였으나, 이는 관련 분야에 종사하는 기술자의 의도 또는 판례, 새로운 기술의 출현 등에 따라 달라질 수 있다. 또한, 특정한 경우는 출원인이 임의로 선정한 용어도 있으며, 이 경우 해당되는 발명의 설명 부분에서 상 세히 그 의미를 기재할 것이다. 따라서 본 개시에서 사용되는 용어는 단순한 용어의 명칭이 아닌, 그 용어가 가 지는 의미와 본 개시의 전반에 걸친 내용을 토대로 정의되어야 한다. 본 명세서에서의 단수의 표현은 문맥상 명백하게 단수인 것으로 특정하지 않는 한, 복수의 표현을 포함한다. 또 한, 복수의 표현은 문맥상 명백하게 복수인 것으로 특정하지 않는 한, 단수의 표현을 포함한다. 명세서 전체에 서 어떤 부분이 어떤 구성요소를 '포함'한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다른 구성요소를 제외하는 것이 아니라 다른 구성요소를 더 포함할 수 있음을 의미한다. 도 1은 본 개시의 일 실시예에 따른 씨쥐 서버 협업 시스템(이하, '시스템'이라 한다)의 구성을 나타내는 블록도이다. 도시된 바와 같이, 시스템은 CPU 모듈, 복수의 확장 모듈(120_1 내지 120_N)(본 개시에 서, N은 2 이상의 자연수이다), 제1 제어 모듈, 제2 제어 모듈, GPU 모듈 및 메인 메모리(16 0)를 포함할 수 있다. 여기서, 씨쥐 서버 협업 시스템은 하나의 하드웨어적 구성에 포함될 수 있다. 예를 들어, 씨쥐 서버 협업 시스템은 하나의 칩(chip)에서 구현될 수 있다. CPU 모듈은 연산 작업을 수행할 수 있다. 또한, CPU 모듈은 GPU 모듈에 대하여 연산 작업을 요 청할 수 있다. 이를 위해, CPU 모듈은 작업 요청을 생성하고, 생성된 작업 요청을 GPU 모듈에 직접 적으로 전송할 수 있다. 추가적으로, CPU 모듈은 특정 연산 작업과 연관된 주소 정보를 포함하는 작업 요 청을 생성함으로써, 작업 요청을 기초로 해당 연산 작업이 수행되는 것을 가능하게 할 수 있다. 이에 관한 상 세한 설명은, 하단에 후술된다. 복수의 확장 모듈(120_1 내지 120_N)은 연산 작업을 수행할 수 있다. 구체적으로, 복수의 확장 모듈(120_1 내 지 120_N)은 CPU 모듈과 함께 또는 따로 연산 작업을 수행할 수 있다. 예를 들어, 복수의 확장 모듈 (120_1 내지 120_N) 중 적어도 일부의 모듈은 하나의 모듈 그룹으로 그룹핑되어 연산 작업을 수행할 수 있다. 다른 예를 들어, 복수의 확장 모듈(120_1 내지 120_N) 중 적어도 일부 및 CPU 모듈은 하나의 모듈 그룹으 로 그룹핑되어 연산 작업을 수행할 수 있다. 이 때, 상술한 하나의 모듈 그룹에 포함되는 적어도 일부의 모듈 은 CPU 및/또는 복수의 확장 모듈(120_1 내지 120_N) 중 적어도 일부에 의해 생성된 작업 요청을 기초로 결정될 수 있다. 또한, 상술한 하나의 모듈 그룹에 포함되는 적어도 일부의 모듈 각각은 서로 인접한 영역에 배치될 수 있다. 제1 제어 모듈은 CPU 모듈 및 복수의 확장 모듈(120_1 내지 120_N) 중 적어도 일부의 모듈로부터 작 업 요청을 생성한 하나의 모듈 그룹을 식별할 수 있다. 예를 들어, 제1 제어 모듈은 CPU 모듈, 제1 확장 모듈(120_1) 및 제2 확장 모듈(미도시)를 포함하는 제1 모듈 그룹을 식별할 수 있다. 이 때, 제1 모듈 그 룹에 의해 생성된 작업 요청은 CPU 모듈, 제1 확장 모듈(120_1) 및 제2 확장 모듈(미도시) 중 적어도 하나 의 모듈에 의해 생성될 수 있다. 다른 예를 들어, 제1 제어 모듈은 제1 확장 모듈(120_1), 제2 확장 모듈 (미도시) 및 제3 확장 모듈(미도시)를 포함하는 제2 모듈 그룹을 식별할 수 있다. 이 때, 제2 모듈 그룹에 의 해 생성된 작업 요청은 CPU 모듈, 제1 확장 모듈(120_1) 및 제2 확장 모듈(미도시) 중 적어도 하나의 모듈 에 의해 생성될 수 있다. 제2 제어 모듈은 CPU 모듈 및/또는 복수의 확장 모듈(120_1 내지 120_N) 중 적어도 일부의 모델로부 터 생성된 작업 요청을 GPU 모듈로 전송할 수 있다. 그리고 나서, GPU 모듈은 작업 요청을 기초로 연산 작업을 수행할 수 있다. 이 때, GPU 모듈은 해당 연산 작업을 수행하는데 필요한 데이터를 획득하기 위하여 메인 메모리에 접근할 수 있다. 그러나, 접근 대상인 데이터의 용량이 큰 만큼 GPU 모듈이 CPU 모듈과 메인 메모리 페이지 테이블에 접근하는 횟수는 증가할 수밖에 없다. 이러한 횟수를 감소 시켜 시스템에 의한 전력 소모를 감소시키기 위하여 본 개시의 GPU 모듈은 생성된 작업 요청과 연관 된 메인 메모리 상의 주소 정보를 기초로 연산에 필요한 데이터가 저장된 메인 메모리의 데이터 영역 에 접근할 수 있다. 도 2는 본 개시의 일 실시예에 따른 CPU 모듈 및 복수의 확장 모듈(120_1 내지 120_N) 각각의 구성을 나타 내는 블록도이다. 도시된 바와 같이, CPU 모듈은 CPU 연산 회로 및 CPU 통신 회로를 포함할 수 있다. 또한, 제1 확장 모듈(120_1)은 제1 인터페이스(122_1), 제1 연산 회로(124_1) 및 제1 통신 회로(126_ 1)를 포함할 수 있다. 이와 유사하게, 제N 확장 모듈(120_N)은 제N 인터페이스(122_N), 제N 연산 회로(124_N) 및 제N 통신 회로(126_N)를 포함할 수 있다. 여기서, 제1 인터페이스(122_1)와 제N 인터페이스(122_N)의 외부 장치에 대한 호환성은 서로 상이할 수 있다. 이에 따라, CPU 모듈은 연산 작업 수행이 가능한 복수의 확 장 모듈(120_1 내지 120_N)을 통해 보다 다양한 연산 작업을 수행할 수 있다. 복수의 확장 모듈(120_1 내지 120_N) 각각은 서로 복수의 시리얼 버스 중 적어도 일부의 버스를 통해 통신할 수 있다. 예를 들어, 복수의 확장 모듈(120_1 내지 120_N)은 두 개의 시리얼 버스 중 하나의 시리얼 버스를 통해 통신할 수 있다. 이를 위해, 복수의 확장 모듈(120_1 내지 120_N) 각각은 제 2 시리얼 버스를 분리하는 복수의 통신 회로(126_1 내지 126_N)를 포함할 수 있다. 시리얼 버스가 분리되면, 분리된 일방의 버스를 흐르는 데이터 가 타방의 버스에 들어 올 수 없어 복수의 통신이 경합했을 때 발생하는 대기 시간을 줄일 수 있고, 입출력 응 답을 고속화할 수 있다. 예를 들어, 제1 통신 회로(126_1)의 제1 시리얼 버스와 관련된 영역이 OFF되는 경우, CPU 모듈 측에 인접한 제1 확장 모듈(120_1 내지 120_N)의 사이에서 제1 시리얼 버스를 통한 통신이 실시 되지 않는다. 다른 예를 들어, 제2 통신 회로(미도시)의 제1 시리얼 버스와 관련된 영역이 OFF되는 경우, 제2 확장 모듈(미도시)의 좌측에 인접한 제1 확장 모듈(120_1)과의 사이에서 제1 시리얼 버스를 통한 통신이 실시되 지 않는다. 도 3은 본 개시의 하나 이상의 확장 모듈을 포함하는 모듈 그룹을 설명하기 위한 블록도이다. 여기서, 모듈 그룹은 도 2의 CPU 모듈 및 복수의 확장 모듈 중 적어도 일부의 모듈을 포함할 수 있다. 예를 드렁, 연산을 수행하기 위하여 작업 요청을 생성한 모듈 그룹이 상기 제1 확장 모듈(120_1) 및 제2 확장 모듈 (120_2)을 포함하는 경우, 제1 확장 모듈(120_1)과 제2 확장 모듈(120_2)은 제2 확장 모듈(120_2)의 통신 회로 (126_1)에 의해 서로 연결되고, 제2 확장 모듈(120_2)과 제3 확장 모듈(120_3)은 제3 확장 모듈(120_3)의 통신 회로(126_3)에 의해 서로 분리될 수 있다. 다만, 여기서 분리되는 것은 복수의 확장 모듈을 연결하는 복수의 시리얼 버스 중 하나의 시리얼 버스를 통한 통신이 분리되는 것을 지칭할 수 있다. 즉, 위 예시의 상황에서 다 른 연산을 수행하기 위하여 다른 작업 요청을 생성한 다른 모듈 그룹이 제2 확장 모듈(120_2) 및 제3 확장 모듈 (120_3)을 포함하는 경우, 제2 확장 모듈(120_2) 및 제3 확장 모듈(120_3)은 제1 시리얼 버스를 통해서는 분리 되어 있더라도 제2 시리얼 버스를 통해서는 통신하도록 구성될 수 있다. 도 4는 본 개시의 일 시시예에 따른 제2 제어 모듈의 구성을 나타내는 블록도이다. 도시된 바와 같이, 제 2 제어 모듈은 작업 관리 모듈 및 주소 맵핑 모듈을 포함할 수 있다. 작업 관리 모듈은 작업 요청이 생성된 모듈 그룹을 식별하고, 해당 모듈 그룹으로부터 생성된 작업 요청을 GPU 모듈로 전송할 수 있다. 주소 맵핑 모듈은 상술한 작업 요청과 연관된 메인 메모리 상의 주소 정보를 기초로 메인 메모리의 데이터 영역에 접근할 수 있다. 예를 들어, 제2 제어 모듈은 제1 작업 요청과 제2 작업 요청을 비교한 결과를 기초로 제1 작업 요청을 작업 대상 요청으로 결정하고, 작업 대상 요청과 연관된 메인 메모리 상의 제3 주소 정보를 기 초로 GPU의 제4 주소 공간과 제3 주소 공간의 맵핑을 수행하는 방식으로 CPU 모듈과 주소 정보를 공유하는 메인 메모리의 데이터 영역에 접근할 수 있다. 본 개시의 앞선 설명은 통상의 기술자들이 본 개시를 행하거나 이용하는 것을 가능하게 하기 위해 제공된다. 본 개시의 다양한 수정예들이 통상의 기술자들에게 쉽게 자명할 것이고, 본원에 정의된 일반적인 원리들은 본 개시의 취지 또는 범위를 벗어나지 않으면서 다양한 변형예들에 적용될 수도 있다. 따라서, 본 개시는 본원에 설명된 예들에 제한되도록 의도된 것이 아니고, 본원에 개시된 원리들 및 신규한 특징들과 일관되는 최광의의"}
{"patent_id": "10-2022-0120342", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "범위가 부여되도록 의도된다.본 명세서에서는 본 개시가 일부 실시예들과 관련하여 설명되었지만, 본 발명이 속하는 기술분야의 통상의 기술 자가 이해할 수 있는 본 개시의 범위를 벗어나지 않는 범위에서 다양한 변형 및 변경이 이루어질 수 있다는 점 을 알아야 할 것이다. 또한, 그러한 변형 및 변경은 본 명세서에서 첨부된 특허청구의 범위 내에 속하는 것으 로 생각되어야 한다."}
{"patent_id": "10-2022-0120342", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 개시의 일 실시예에 따른 씨쥐 서버 협업 시스템(이하, '시스템'이라 한다)의 구성을 나타내는 블록도이다."}
