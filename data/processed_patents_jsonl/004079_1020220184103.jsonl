{"patent_id": "10-2022-0184103", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0102246", "출원번호": "10-2022-0184103", "발명의 명칭": "자연어 대화 인터페이스 시스템을 위한 회피형 발화 처리 방법, 장치 및 컴퓨터-판독 가능 기", "출원인": "주식회사 솔트룩스", "발명자": "이경일"}}
{"patent_id": "10-2022-0184103", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "하나 이상의 프로세서 및 상기 프로세서에서 수행 가능한 명령들을 저장하는 하나 이상의 메모리를 포함하는 컴퓨팅 장치에서 구현되는 자연어 대화 인터페이스 시스템을 위한 회피형 발화 처리 방법에 있어서,사용자로부터 자연어가 입력되는 경우, 상기 입력된 자연어에 대응되는 문장에 포함된 형태소를 확인하여, 상기확인된 형태소를 통해 상기 문장에 대한 구문 타입을 판단하는 구문 타입 판단 단계;상기 구문 타입 판단 단계의 기능 수행에 의해 상기 문장의 구문 타입이 판단되면, 기 저장된 형태소 의미 사전을 기반으로, 상기 형태소에 대한 의미 정보를 확인하는 의미 정보 확인 단계;상기 의미 정보의 확인이 완료되면, 상기 문장의 구문 타입 및 상기 문장을 구성하는 형태소의 의미 정보를 통해 상기 문장에 대한 관점 분석 프로세스를 수행하여, 상기 관점 분석 프로세스의 결과를 통해 상기 문장을 객관형 문장 또는 주관형 문장으로 결정하는 관점 분석 프로세스 시작 단계; 및상기 관점 분석 프로세스 시작 단계의 기능 수행에 의해 상기 문장이 객관형 문장으로 결정되는 경우, 상기 객관형 문장에 대한 응답을 회피하는 회피 문장에 기반한 회피 문장 정보를 생성하여, 출력 수단을 통해 상기 생성된 회피 문장 정보에 기반한 회피형 발화 신호를 출력하는 회피형 발화 출력 단계;를 포함하는 것을 특징으로하는 자연어 대화 인터페이스 시스템을 위한 회피형 발화 처리 방법."}
{"patent_id": "10-2022-0184103", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 구문 타입 판단 단계는,상기 자연어가 입력되는 경우, 상기 입력된 자연어에 대응되는 문장에 포함된 복수 개의 형태소를 식별하여, 상기 식별된 형태소를 기반으로, 상기 문장을 구성하는 복수 개의 어절을 확인하는 어절 확인 단계;상기 어절 확인 단계의 기능 수행에 의해 상기 복수 개의 어절의 확인이 완료되면, 기 저장된 품사 분류 정보를기반으로, 상기 복수 개의 어절에 포함된 형태소들 각각에 대한 품사를 확인하여, 상기 확인된 품사를 통해 상기 복수 개의 어절 각각의 문장 성분을 분류하는 성분 분류 단계; 및상기 성분 분류 단계의 기능 수행에 의해 상기 복수 개의 어절 각각에 대한 문장 성분의 분류가 완료된 경우,상기 분류된 문장 성분 간의 조합 관계를 확인하여, 상기 문장에 대한 구문 타입을 결정하는 구문 결정 단계;를포함하는 것을 특징으로 하는 자연어 대화 인터페이스 시스템을 위한 회피형 발화 처리 방법."}
{"patent_id": "10-2022-0184103", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,상기 구문 타입은,상기 복수 개의 어절 각각에 대한 문장 성분 간의 조합 관계를 기반으로 결정되는 상기 문장에 대한 문장 형태로써,주어 및 서술어로 조합되어 구성되는 제1 타입상기 주어, 부사어 및 상기 서술어로 조합되어 구성되는 제2 타입;상기 주어, 목적어 및 상기 서술어로 조합되어 구성되는 제3 타입;상기 주어, 보어 및 상기 서술어로 조합되어 구성되는 제4 타입; 및공개특허 10-2024-0102246-3-상기 주어, 상기 목적어, 상기 보어 및 상기 서술어로 조합되어 구성되는 제5 타입;을 포함하는 것을 특징으로하는 자연어 대화 인터페이스 시스템을 위한 회피형 발화 처리 방법."}
{"patent_id": "10-2022-0184103", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서,상기 의미 정보 확인 단계는,상기 문장의 구문 타입이 판단되면, 상기 문장에 포함된 형태소를 식별하여, 상기 기 저장된 형태소 의미 사전에 기반해 상기 식별된 형태소에 대한 개체명 분석 프로세스(named entity recognition process)를 시작하는 분석 프로세스 시작 단계; 및상기 개체명 분석 프로세스가 시작됨에 따라, 상기 기 저장된 형태소 의미 사전에 기반해 상기 식별된 형태소각각의 의미에 대응되는 의미 정보가 확인되는 경우, 상기 확인된 의미에 대응되는 의미 정보를 상기 식별된 형태소 각각에 태깅하는 의미 정보 태깅 단계;를 포함하는 것을 특징으로 하는 자연어 대화 인터페이스 시스템을위한 회피형 발화 처리 방법."}
{"patent_id": "10-2022-0184103", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서,상기 관점 분석 프로세스 시작 단계는,상기 의미 정보 태깅 단계가 완료됨에 따라, 상기 관점 분석 프로세스를 시작하는 경우, 상기 문장의 구문 타입및 상기 형태소마다 태깅된 의미 정보를 기 저장된 감성분석 알고리즘을 통해 분석하는 감성분석 프로세스를 시작하는 감성분석 진행 단계;상기 감성분석 프로세스가 시작됨에 따라, 상기 기 저장된 감성분석 알고리즘을 기반으로, 상기 문장의 구문 타입 및 상기 형태소마다 태깅된 의미 정보를 분석하는 경우, 상기 분석 결과를 통해 상기 문장에서 주관 카테고리에 포함되는 형태소가 존재하는지를 식별하는 주관 형태소 식별 단계; 및상기 주관 형태소 식별 단계의 기능 수행에 의해 상기 문장에 주관 카테고리에 포함되는 형태소가 존재하지 않는 것을 확인하는 경우, 상기 문장을 객관형 문장으로 결정하는 객관형 문장 결정 단계;를 포함하는 것을 특징으로 하는 자연어 대화 인터페이스 시스템을 위한 회피형 발화 처리 방법."}
{"patent_id": "10-2022-0184103", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5항에 있어서,상기 주관 카테고리는,개인의 감성 및 감정 표현에 기반한 키워드를 포함하는 감성 감정 카테고리;개인의 의견 및 판단에 기반한 키워드를 포함하는 의견 판단 카테고리; 및개인의 평가에 기반한 키워드를 포함하는 평가 카테고리;를 포함하는 것을 특징으로 하는 자연어 대화 인터페이스 시스템을 위한 회피형 발화 처리 방법."}
{"patent_id": "10-2022-0184103", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6항에 있어서,상기 회피형 발화 출력 단계는,상기 회피 문장 정보를 생성하기 이전에 상기 출력 수단을 제어하는 챗봇 프로그램의 유형을 확인하는 챗봇 유공개특허 10-2024-0102246-4-형 확인 단계;상기 챗봇 유형 확인 단계의 기능 수행에 의해 상기 챗봇 프로그램의 유형이 열린 주제 대화형 인공지능 유형으로 확인되는 경우, 상기 객관형 문장에 대한 응답을 회피하는 회피형 문장에 기반한 회피 문장 정보인 제1 회피문장 정보를 생성하는 제1 회피 문장 정보 생성 단계; 및상기 챗봇 유형 확인 단계의 기능 수행에 의해 상기 챗봇 프로그램의 유형이 지식 베이스 기반 질의 응답형 인공지능 유형으로 확인되되, 상기 객관형 문장에 대한 응답이 지식 베이스에 적어도 두 개 이상 존재하는 것을확인하는 경우, 상기 객관형 문장에 대한 응답을 회피하는 회피형 문장에 기반한 회피 문장 정보인 제2 회피 문장 정보를 생성하는 제2 회피 문장 정보 생성 단계;를 포함하는 것을 특징으로 하는 자연어 대화 인터페이스 시스템을 위한 회피형 발화 처리 방법."}
{"patent_id": "10-2022-0184103", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서,상기 회피형 발화 출력 단계는,상기 제1 회피 문장 정보 및 상기 제2 회피 문장 정보 중 하나의 생성이 완료되면, 생성된 회피 문장 정보에 기반한 회피형 발화 신호를 상기 출력 수단을 통해 출력하여, 사용자로 하여금 객관형 문장이 아닌 주관형 문장에대응되는 발화를 하도록 유도하는 것을 특징으로 하는 자연어 대화 인터페이스 시스템을 위한 회피형 발화 처리방법."}
{"patent_id": "10-2022-0184103", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "하나 이상의 프로세서 및 상기 프로세서에서 수행 가능한 명령들을 저장하는 하나 이상의 메모리를 포함하는 컴퓨팅 장치에서 구현되는 자연어 대화 인터페이스 시스템을 위한 회피형 발화 처리 장치에 있어서,사용자로부터 자연어가 입력되는 경우, 상기 입력된 자연어에 대응되는 문장에 포함된 형태소를 확인하여, 상기확인된 형태소를 통해 상기 문장에 대한 구문 타입을 판단하는 구문 타입 판단부;상기 구문 타입 판단부의 기능 수행에 의해 상기 문장의 구문 타입이 판단되면, 기 저장된 형태소 의미 사전을기반으로, 상기 형태소에 대한 의미 정보를 확인하는 의미 정보 확인부;상기 의미 정보의 확인이 완료되면, 상기 문장의 구문 타입 및 상기 문장을 구성하는 형태소의 의미 정보를 통해 상기 문장에 대한 관점 분석 프로세스를 수행하여, 상기 관점 분석 프로세스의 결과를 통해 상기 문장을 객관형 문장 또는 주관형 문장으로 결정하는 관점 분석 프로세스 시작부; 및상기 관점 분석 프로세스 시작부의 기능 수행에 의해 상기 문장이 객관형 문장으로 결정되는 경우, 상기 객관형문장에 대한 응답을 회피하는 회피 문장에 기반한 회피 문장 정보를 생성하여, 출력 수단을 통해 상기 생성된회피 문장 정보에 기반한 회피형 발화 신호를 출력하는 회피형 발화 출력부;를 포함하는 것을 특징으로 하는 자연어 대화 인터페이스 시스템을 위한 회피형 발화 처리 장치."}
{"patent_id": "10-2022-0184103", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "컴퓨터-판독가능 기록매체로서,상기 컴퓨터-판독가능 기록매체는, 컴퓨팅 장치로 하여금 이하의 단계들을 수행하도록 하는 명령들을 저장하며,상기 단계들은;사용자로부터 자연어가 입력되는 경우, 상기 입력된 자연어에 대응되는 문장에 포함된 형태소를 확인하여, 상기확인된 형태소를 통해 상기 문장에 대한 구문 타입을 판단하는 구문 타입 판단 단계;상기 구문 타입 판단 단계의 기능 수행에 의해 상기 문장의 구문 타입이 판단되면, 기 저장된 형태소 의미 사전을 기반으로, 상기 형태소에 대한 의미 정보를 확인하는 의미 정보 확인 단계;공개특허 10-2024-0102246-5-상기 의미 정보의 확인이 완료되면, 상기 문장의 구문 타입 및 상기 문장을 구성하는 형태소의 의미 정보를 통해 상기 문장에 대한 관점 분석 프로세스를 수행하여, 상기 관점 분석 프로세스의 결과를 통해 상기 문장을 객관형 문장 또는 주관형 문장으로 결정하는 관점 분석 프로세스 시작 단계; 및상기 관점 분석 프로세스 시작 단계의 기능 수행에 의해 상기 문장이 객관형 문장으로 결정되는 경우, 상기 객관형 문장에 대한 응답을 회피하는 회피 문장에 기반한 회피 문장 정보를 생성하여, 출력 수단을 통해 상기 생성된 회피 문장 정보에 기반한 회피형 발화 신호를 출력하는 회피형 발화 출력 단계;를 포함하는 것을 특징으로하는 컴퓨터-판독가능 기록매체."}
{"patent_id": "10-2022-0184103", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 하나 이상의 프로세서 및 상기 프로세서에서 수행 가능한 명령들을 저장하는 하나 이상의 메모리를 포 함하는 컴퓨팅 장치에서 구현되는 자연어 대화 인터페이스 시스템을 위한 회피형 발화 처리 방법에 있어서, 사용 자로부터 자연어가 입력되는 경우, 상기 입력된 자연어에 대응되는 문장에 포함된 형태소를 확인하여, 상기 확인 (뒷면에 계속)"}
{"patent_id": "10-2022-0184103", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 자연어 대화 인터페이스 시스템을 위한 회피형 발화 처리 방법에 관한 것으로서, 구체적으로는 사용 자로부터 자연어가 입력되는 경우, 자연어에 대응되는 문장에 포함된 형태소를 확인하여, 문장에 대한 구문 타 입을 판단하며, 기 저장된 형태소 의미 사전을 기반으로, 형태소에 대한 의미 정보를 확인하고, 문장의 구문 타 입 및 문장을 구성하는 형태소의 의미 정보를 통해 문장에 대한 관점 분석 프로세스를 수행하여, 문장을 객관형 문장 또는 주관형 문장으로 결정하고, 문장이 객관형 문장으로 결정되는 경우, 객관형 문장에 대한 응답을 회피 하는 회피 문장에 기반한 회피 문장 정보를 생성하여, 출력 수단을 통해 회피 문장 정보에 기반한 회피형 발화 신호를 출력하도록 하는 기술에 관한 것이다."}
{"patent_id": "10-2022-0184103", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "종래의 대화형 인공지능 시스템의 발화 생성 모델은 입력 발화를 자연어 처리해 문맥과 의도를 파악하고, 파악 된 문맥과 의도에 관련된 응답 발화를 출력하는 구조이다. 만약 입력 발화가 객관적인 사실을 질의하는 문장이 라면, 발화 생성 모델은 이에 맞는 객관적인 정보를 바탕으로 응답 발화를 출력해야 되지만, 시스템 특성 상 패 턴화 또는 학습된 형태를 바탕으로 발화를 생성하게 됨에 따라 문맥과 의도에 맞지 않는 응답 발화를 출력하는 문제점을 가지고 있다. 이에 따라, 업계에서는 시스템이 객관적인 사실을 식별하지 못하는 경우, 입력 발화에 대한 회피형 발화를 출력 하기 위한 다양한 기술들을 개발하고 있다. 일 예로서, 한국등록특허 10-2256007(자연어 질의를 통한 문서 검색 및 응답 제공 시스템 및 방법)에는 자연어 질의를 토큰화하여 데이터베이스 내의 모든 문서와 유사도 검색을 수행해 하나 이상의 문서를 선별하고, 선별된 문서에 대한 응답의 위치를 추론하는 기술이 개시되어 있다. 그러나, 상술한 선행기술에서는 단순히 질의에 대한 응답이 저장된 위치를 추론하는 기술만이 개시되어 있을 뿐, 사용자로부터 자연어가 입력되는 경우, 자연어에 대응되는 문장에 포함된 형태소를 확인하여, 문장에 대한 구문 타입을 판단하며, 기 저장된 형태소 의미 사전을 기반으로, 형태소에 대한 의미 정보를 확인하고, 문장의 구문 타입 및 문장을 구성하는 형태소의 의미 정보를 통해 문장에 대한 관점 분석 프로세스를 수행하여, 문장을 객관형 문장 또는 주관형 문장으로 결정하고, 문장이 객관형 문장으로 결정되는 경우, 객관형 문장에 대한 응답 을 회피하는 회피 문장에 기반한 회피 문장 정보를 생성하여, 출력 수단을 통해 회피 문장 정보에 기반한 회피 형 발화 신호를 출력하도록 하는 기술은 개시되어 있지 않아, 이를 해결할 수 있는 기술의 필요성이 대두되고 있다."}
{"patent_id": "10-2022-0184103", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "이에 본 발명은 자연어 대화 인터페이스 시스템을 위한 회피형 발화 처리 방법을 통해 사용자로부터 자연어가 입력되는 경우, 자연어에 대응되는 문장에 포함된 형태소를 확인하여, 문장에 대한 구문 타입을 판단하며, 기 저장된 형태소 의미 사전을 기반으로, 형태소에 대한 의미 정보를 확인하고, 문장의 구문 타입 및 문장을 구성 하는 형태소의 의미 정보를 통해 문장에 대한 관점 분석 프로세스를 수행하여, 문장을 객관형 문장 또는 주관형 문장으로 결정하고, 문장이 객관형 문장으로 결정되는 경우, 객관형 문장에 대한 응답을 회피하는 회피 문장에기반한 회피 문장 정보를 생성하여, 출력 수단을 통해 회피 문장 정보에 기반한 회피형 발화 신호를 출력하도록 함으로써, 자연어 대화 인터페이스 시스템을 이용하는 사용자에게 자연스러운 커뮤니케이션 서비스를 제공하는 것에 그 목적이 있다."}
{"patent_id": "10-2022-0184103", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 일 실시예에 따른 하나 이상의 프로세서 및 상기 프로세서에서 수행 가능한 명령들을 저장하는 하나 이상의 메모리를 포함하는 컴퓨팅 장치에서 구현되는 자연어 대화 인터페이스 시스템을 위한 회피형 발화 처리 방법에 있어서, 사용자로부터 자연어가 입력되는 경우, 상기 입력된 자연어에 대응되는 문장에 포함된 형태소를 확인하여, 상기 확인된 형태소를 통해 상기 문장에 대한 구문 타입을 판단하는 구문 타입 판단 단계; 상기 구문 타입 판단 단계의 기능 수행에 의해 상기 문장의 구문 타입이 판단되면, 기 저장된 형태소 의미 사전을 기반으 로, 상기 형태소에 대한 의미 정보를 확인하는 의미 정보 확인 단계; 상기 의미 정보의 확인이 완료되면, 상기 문장의 구문 타입 및 상기 문장을 구성하는 형태소의 의미 정보를 통해 상기 문장에 대한 관점 분석 프로세스를 수행하여, 상기 관점 분석 프로세스의 결과를 통해 상기 문장을 객관형 문장 또는 주관형 문장으로 결정하는 관 점 분석 프로세스 시작 단계; 및 상기 관점 분석 프로세스 시작 단계의 기능 수행에 의해 상기 문장이 객관형 문장으로 결정되는 경우, 상기 객관형 문장에 대한 응답을 회피하는 회피 문장에 기반한 회피 문장 정보를 생성 하여, 출력 수단을 통해 상기 생성된 회피 문장 정보에 기반한 회피형 발화 신호를 출력하는 회피형 발화 출력 단계;를 포함하는 것을 특징으로 한다. 상기 구문 타입 판단 단계는, 상기 자연어가 입력되는 경우, 상기 입력된 자연어에 대응되는 문장에 포함된 복 수 개의 형태소를 식별하여, 상기 식별된 형태소를 기반으로, 상기 문장을 구성하는 복수 개의 어절을 확인하는 어절 확인 단계; 상기 어절 확인 단계의 기능 수행에 의해 상기 복수 개의 어절의 확인이 완료되면, 기 저장된 품사 분류 정보를 기반으로, 상기 복수 개의 어절에 포함된 형태소들 각각에 대한 품사를 확인하여, 상기 확인 된 품사를 통해 상기 복수 개의 어절 각각의 문장 성분을 분류하는 성분 분류 단계; 및 상기 성분 분류 단계의 기능 수행에 의해 상기 복수 개의 어절 각각에 대한 문장 성분의 분류가 완료된 경우, 상기 분류된 문장 성분 간의 조합 관계를 확인하여, 상기 문장에 대한 구문 타입을 결정하는 구문 결정 단계;를 포함하는 것이 바람직 하다. 상기 구문 타입은, 상기 복수 개의 어절 각각에 대한 문장 성분 간의 조합 관계를 기반으로 결정되는 상기 문장 에 대한 문장 형태로써, 주어 및 서술어로 조합되어 구성되는 제1 타입 상기 주어, 부사어 및 상기 서술어로 조 합되어 구성되는 제2 타입; 상기 주어, 목적어 및 상기 서술어로 조합되어 구성되는 제3 타입; 상기 주어, 보어 및 상기 서술어로 조합되어 구성되는 제4 타입; 및 상기 주어, 상기 목적어, 상기 보어 및 상기 서술어로 조합 되어 구성되는 제5 타입;을 포함하는 것이 가능하다. 상기 의미 정보 확인 단계는, 상기 문장의 구문 타입이 판단되면, 상기 문장에 포함된 형태소를 식별하여, 상기 기 저장된 형태소 의미 사전에 기반해 상기 식별된 형태소에 대한 개체명 분석 프로세스(named entity recognition process)를 시작하는 분석 프로세스 시작 단계; 및 상기 개체명 분석 프로세스가 시작됨에 따라, 상기 기 저장된 형태소 의미 사전에 기반해 상기 식별된 형태소 각각의 의미에 대응되는 의미 정보가 확인되는 경우, 상기 확인된 의미에 대응되는 의미 정보를 상기 식별된 형태소 각각에 태깅하는 의미 정보 태깅 단계;를 포함하는 것이 가능하다. 상기 관점 분석 프로세스 시작 단계는, 상기 의미 정보 태깅 단계가 완료됨에 따라, 상기 관점 분석 프로세스를 시작하는 경우, 상기 문장의 구문 타입 및 상기 형태소마다 태깅된 의미 정보를 기 저장된 감성분석 알고리즘을 통해 분석하는 감성분석 프로세스를 시작하는 감성분석 진행 단계; 상기 감성분석 프로세스가 시작됨에 따라, 상기 기 저장된 감성분석 알고리즘을 기반으로, 상기 문장의 구문 타입 및 상기 형태소마다 태깅된 의미 정보를 분석하는 경우, 상기 분석 결과를 통해 상기 문장에서 주관 카테고리에 포함되는 형태소가 존재하는지를 식별하 는 주관 형태소 식별 단계; 및 상기 주관 형태소 식별 단계의 기능 수행에 의해 상기 문장에 주관 카테고리에 포함되는 형태소가 존재하지 않는 것을 확인하는 경우, 상기 문장을 객관형 문장으로 결정하는 객관형 문장 결 정 단계;를 포함하는 것이 가능하다. 상기 주관 카테고리는, 개인의 감성 및 감정 표현에 기반한 키워드를 포함하는 감성 감정 카테고리; 개인의 의 견 및 판단에 기반한 키워드를 포함하는 의견 판단 카테고리; 및 개인의 평가에 기반한 키워드를 포함하는 평가 카테고리;를 포함하는 것이 가능하다. 상기 회피형 발화 출력 단계는, 상기 회피 문장 정보를 생성하기 이전에 상기 출력 수단을 제어하는 챗봇 프로 그램의 유형을 확인하는 챗봇 유형 확인 단계; 상기 챗봇 유형 확인 단계의 기능 수행에 의해 상기 챗봇 프로그 램의 유형이 열린 주제 대화형 인공지능 유형으로 확인되는 경우, 상기 객관형 문장에 대한 응답을 회피하는 회 피형 문장에 기반한 회피 문장 정보인 제1 회피 문장 정보를 생성하는 제1 회피 문장 정보 생성 단계; 및 상기 챗봇 유형 확인 단계의 기능 수행에 의해 상기 챗봇 프로그램의 유형이 지식 베이스 기반 질의 응답형 인공지능 유형으로 확인되되, 상기 객관형 문장에 대한 응답이 지식 베이스에 적어도 두 개 이상 존재하는 것을 확인하는 경우, 상기 객관형 문장에 대한 응답을 회피하는 회피형 문장에 기반한 회피 문장 정보인 제2 회피 문장 정보를 생성하는 제2 회피 문장 정보 생성 단계;를 포함하는 것이 가능하다. 상기 회피형 발화 출력 단계는, 상기 제1 회피 문장 정보 및 상기 제2 회피 문장 정보 중 하나의 생성이 완료되 면, 생성된 회피 문장 정보에 기반한 회피형 발화 신호를 상기 출력 수단을 통해 출력하여, 사용자로 하여금 객 관형 문장이 아닌 주관형 문장에 대응되는 발화를 하도록 유도하는 것이 가능하다. 본 발명의 일 실시예에 따른 하나 이상의 프로세서 및 상기 프로세서에서 수행 가능한 명령들을 저장하는 하나 이상의 메모리를 포함하는 컴퓨팅 장치에서 구현되는 자연어 대화 인터페이스 시스템을 위한 회피형 발화 처리 장치에 있어서, 사용자로부터 자연어가 입력되는 경우, 상기 입력된 자연어에 대응되는 문장에 포함된 형태소를 확인하여, 상기 확인된 형태소를 통해 상기 문장에 대한 구문 타입을 판단하는 구문 타입 판단부; 상기 구문 타 입 판단부의 기능 수행에 의해 상기 문장의 구문 타입이 판단되면, 기 저장된 형태소 의미 사전을 기반으로, 상 기 형태소에 대한 의미 정보를 확인하는 의미 정보 확인부; 상기 의미 정보의 확인이 완료되면, 상기 문장의 구 문 타입 및 상기 문장을 구성하는 형태소의 의미 정보를 통해 상기 문장에 대한 관점 분석 프로세스를 수행하여, 상기 관점 분석 프로세스의 결과를 통해 상기 문장을 객관형 문장 또는 주관형 문장으로 결정하는 관 점 분석 프로세스 시작부; 및 상기 관점 분석 프로세스 시작부의 기능 수행에 의해 상기 문장이 객관형 문장으 로 결정되는 경우, 상기 객관형 문장에 대한 응답을 회피하는 회피 문장에 기반한 회피 문장 정보를 생성하여, 출력 수단을 통해 상기 생성된 회피 문장 정보에 기반한 회피형 발화 신호를 출력하는 회피형 발화 출력부;를 포함하는 것을 특징으로 한다. 본 발명의 일 실시예에 따른 컴퓨터-판독가능 기록매체로서, 상기 컴퓨터-판독가능 기록매체는, 컴퓨팅 장치로 하여금 이하의 단계들을 수행하도록 하는 명령들을 저장하며, 상기 단계들은; 사용자로부터 자연어가 입력되는 경우, 상기 입력된 자연어에 대응되는 문장에 포함된 형태소를 확인하여, 상기 확인된 형태소를 통해 상기 문장 에 대한 구문 타입을 판단하는 구문 타입 판단 단계; 상기 구문 타입 판단 단계의 기능 수행에 의해 상기 문장 의 구문 타입이 판단되면, 기 저장된 형태소 의미 사전을 기반으로, 상기 형태소에 대한 의미 정보를 확인하는 의미 정보 확인 단계; 상기 의미 정보의 확인이 완료되면, 상기 문장의 구문 타입 및 상기 문장을 구성하는 형 태소의 의미 정보를 통해 상기 문장에 대한 관점 분석 프로세스를 수행하여, 상기 관점 분석 프로세스의 결과를 통해 상기 문장을 객관형 문장 또는 주관형 문장으로 결정하는 관점 분석 프로세스 시작 단계; 및 상기 관점 분 석 프로세스 시작 단계의 기능 수행에 의해 상기 문장이 객관형 문장으로 결정되는 경우, 상기 객관형 문장에 대한 응답을 회피하는 회피 문장에 기반한 회피 문장 정보를 생성하여, 출력 수단을 통해 상기 생성된 회피 문 장 정보에 기반한 회피형 발화 신호를 출력하는 회피형 발화 출력 단계;를 포함하는 것을 특징으로 한다."}
{"patent_id": "10-2022-0184103", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명인 자연어 대화 인터페이스 시스템을 위한 회피형 발화 처리 방법은 잘못 처리된 응답 발화가 사용자에 게 제공되더라도 즉각적인 반응을 통해 대화의 주도권을 다시 가져올 수 있으며, 사용자가 원하는 질의를 다시 시도해 대화 성공률 및 사용자의 만족도를 향상시킬 수 있다. 또한, 잘못 처리된 응답 발화에 대한 질의 재시도 및 오류 사례가 수집됨에 따라 시스템의 성능 향상을 위한 분 석 데이터를 확보할 수 있으며, 수집된 데이터를 학습용 데이터로 정제해 학습에 반영함으로써, 시스템의 품질 을 지속적으로 향상시킬 수 있다."}
{"patent_id": "10-2022-0184103", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하에서는, 다양한 실시 예들 및/또는 양상들이 이제 도면들을 참조하여 개시된다. 하기 설명에서는 설명을 목 적으로, 하나이상의 양상들의 전반적 이해를 돕기 위해 다수의 구체적인 세부사항들이 개시된다. 그러나, 이러 한 양상(들)은 이러한 구체적인 세부사항들 없이도 실행될 수 있다는 점 또한 본 발명의 기술 분야에서 통상의 지식을 가진 자에게 인식될 수 있을 것이다. 이후의 기재 및 첨부된 도면들은 하나 이상의 양상들의 특정한 예 시적인 양상들을 상세하게 기술한다. 하지만, 이러한 양상들은 예시적인 것이고 다양한 양상들의 원리들에서의 다양한 방법들 중 일부가 이용될 수 있으며, 기술되는 설명들은 그러한 양상들 및 그들의 균등물들을 모두 포함 하고자 하는 의도이다. 본 명세서에서 사용되는 \"실시 예\", \"예\", \"양상\", \"예시\" 등은 기술되는 임의의 양상 또는 설계가 다른 양상 또는 설계들보다 양호하다거나, 이점이 있는 것으로 해석되지 않을 수도 있다. 또한, \"포함한다\" 및/또는 \"포함하는\"이라는 용어는, 해당 특징 및/또는 구성요소가 존재함을 의미하지만, 하나 이상의 다른 특징, 구성요소 및/또는 이들의 그룹의 존재 또는 추가를 배제하지 않는 것으로 이해되어야 한다. 또한, 제 1, 제 2 등과 같이 서수를 포함하는 용어는 다양한 구성요소들을 설명하는데 사용될 수 있지만, 상기 구성요소들은 상기 용어들에 의해 한정되지는 않는다. 상기 용어들은 하나의 구성요소를 다른 구성요소로부터 구별하는 목적으로만 사용된다. 예를 들어, 본 발명의 권리 범위를 벗어나지 않으면서 제 1 구성요소는 제 2 구 성요소로 명명될 수 있고, 유사하게 제 2 구성요소도 제 1 구성요소로 명명될 수 있다. 및/또는 이라는 용어는 복수의 관련된 기재된 항목들의 조합 또는 복수의 관련된 기재된 항목들 중의 어느 항목을 포함한다. 또한, 본 발명의 실시 예들에서, 별도로 다르게 정의되지 않는 한, 기술적이거나 과학적인 용어를 포함해서 여 기서 사용되는 모든 용어들은 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자에 의해 일반적으로 이해 되는 것과 동일한 의미를 가지고 있다. 일반적으로 사용되는 사전에 정의되어 있는 것과 같은 용어들은 관련 기 술의 문맥 상 가지는 의미와 일치하는 의미를 가지는 것으로 해석되어야 하며, 본 발명의 실시 예에서 명백하게 정의하지 않는 한, 이상적이거나 과도하게 형식적인 의미로 해석되지 않는다. 도 1은 본 발명의 일 실시 예에 따른 자연어 대화 인터페이스 시스템을 위한 회피형 발화 처리 방법을 설명하기 위한 순서도이다. 도 1을 참조하면, 하나 이상의 프로세서 및 상기 프로세서에서 수행 가능한 명령들을 저장하는 하나 이상의 메 모리를 포함하는 컴퓨팅 장치로 구현되는 자연어 대화 인터페이스 시스템을 위한 회피형 발화 처리 방법은 구문 타입 판단 단계(S101 단계), 의미 정보 확인 단계(S103 단계), 관점 분석 프로세스 시작 단계(S105 단계) 및 회 피형 발화 출력 단계(S107 단계)를 포함할 수 있다. S101 단계에서, 상기 하나 이상의 프로세서(이하, 프로세서로 칭함)는 사용자로부터 자연어가 입력되는 경우, 상기 입력된 자연어에 대응되는 문장에 포함된 형태소를 확인하여, 상기 확인된 형태소를 통해 문장에 대한 구 문 타입을 판단할 수 있다. 일 실시예에 따르면, 상기 프로세서는 사용자로부터 언어 신호(예: 음성 신호 또는 텍스트 입력)를 수신하는 경 우, 상기 수신된 언어 신호에 대응되는 자연어를 통해 문장을 식별할 수 있다. 이 때, 상기 프로세서는 상기 자 연어를 통해 단일 문장 또는 상기 단일 문장이 복수 개로 구성된 복합 문장을 식별할 수 있다. 일 실시예에 따르면, 상기 프로세서는 상기 문장의 식별이 완료되면, 상기 문장에 포함된 형태소를 확인하여, 상기 문장에 대한 구문 타입을 판단할 수 있다. 상기 형태소는 문장을 구성하는 단어를 분석한 단위로, 뜻을 가진 가장 작은 말의 단위를 의미할 수 있다. 일 실시예에 따르면, 상기 프로세서는 상기 확인된 형태소를 통해 문장의 구문 타입을 판단할 수 있다. 구문 타 입은 또 다른 말로 문장의 문형일 수 있는데, 문형은, 문장 성분이 문장을 구성할 때의 배열 유형으로써, 문장 의 형태를 의미할 수 있다. 상기와 관련하여, 상기 프로세서가 상기 문장의 형태소를 확인해 문장의 구문 타입 (예: 문형)을 판단하는 자세한 설명은 도 2에서 설명하도록 한다. 일 실시예에 따르면, 상기 프로세서는 상기 문장의 구문 타입의 판단이 완료되면, 의미 정보 확인 단계(S103 단 계)를 수행할 수 있다. S103 단계에서, 상기 프로세서는 구문 타입 판단 단계(S101 단계)의 기능 수행에 의해 문장의 구문 타입이 판단 되면, 기 저장된 형태소 의미 사전을 기반으로, 상기 형태소에 대한 의미 정보를 확인할 수 있다. 일 실시예에 따르면, 상기 기 저장된 형태소 의미 사전은 형태소 각각에 대한 의미가 매칭되어 있는 구성으로써, 구문 타입에 따라 복수 개의 의미로 해석되는 동음이의어의 의미를 식별하기 위한 복수 개의 의미 정보를 포함할 수 잇다. 예를 들어, 상기 기 저장된 형태소 의미 사전은 형태소 \"말\"에 대한 의미 정보로써, \" 회화\"를 의미하는 의미 정보(예: 제1 의미 정보)와 \"동물\"을 의미하는 의미 정보(예: 제2 의미 정보)를 포함할 수 있다. 이 때, 상기 프로세서는 상기 판단된 문장의 구문 타입에 따라 상기 \"말\"에 대한 의미 정보를 제1 의 미 정보 또는 제2 의미 정보로 식별할 수 있다. 일 실시예에 따르면, 상기 프로세서는 상기 의미 정보의 확인이 완료되면, 관점 분석 프로세스 시작 단계(S105 단계)를 수행할 수 있다. S105 단계에서, 상기 프로세서는 상기 의미 정보의 확인이 완료되면, 문장의 구문 타입 및 문장을 구성하는 형 태소의 의미 정보를 통해 문장에 대한 관점 분석 프로세스를 수행하여, 관점 분석 프로세스의 결과를 통해 문장 을 객관형 문장 또는 주관형 문장으로 결정할 수 있다. 일 실시예에 따르면, 상기 프로세서는 상기 구문 타입 판단 단계(S101 단계) 및 상기 의미 정보 확인 단계(S103 단계)의 기능 수행이 완료됨에 따라 상기 문장에 대한 의미의 해석이 완료되면, 상기 의미의 해석이 완료된 문 장을 감성분석하여, 상기 문장이 객관형 문장인지 주관형 문장인지 결정할 수 있다. 상기와 관련하여, 상기 객관형 문장은 사람의 감정이나 의견이 포함되어 있지 않은 문장으로, 일반적으로 자연 어 처리 영역에서 전문 질의 응답 서비스에 기반한 지식 베이스에서 추출되는 문장이 응답으로 출력되도록 하는 문장일 수 있다. 예를 들어, \"오늘 날씨 어때?\" 및 \"오늘 월드컵 가나전에 대한 한국의 스코어는 몇으로 끝났어?\"에 대응하는 객관적인 응답을 이끌어내도록 하는 문장을 객관형 문장이라고 할 수 있다. 또한, 상기 주관형 문장은 사람의 감정이나 의견이 포함되어 있는 문장으로, 일반적으로 자연어 처리 영역에서 열린 주제 대화 서비스에 기반한 지식 베이스에서 추출되는 문장이 응답으로 출력되도록 하는 문장일 수 있다. 예를 들어, \"오늘 날씨가 너무 어두운데 기분이 어때?\" 및 \"오늘 월드컵 가나전에서 한국이 이길거 같아?\"에 대 응하는 주관적인 응답을 이끌어내도록 하는 문장을 주관형 문장이라고 할 수 있다. 즉, 상기 관점 분석 프로세스는 상기 문장을 분석하여, 분석 결과를 통해 문장이 객관형 문장 또는 주관형 문장 인지를 판단하기 위한 감성분석 프로세스일 수 있다. 일 실시예에 따르면, 상기 프로세서는 문장이 객관형 문장으로 결정되는 경우, 회피형 발화 출력 단계(S107 단 계)를 수행할 수 있다. S107 단계에서, 상기 프로세서는 상기 관점 분석 프로세스 시작 단계(S105 단계)의 기능 수행에 의해 문장이 객 관형 문장으로 결정되는 경우, 상기 객관형 문장에 대한 응답을 회피하는 회피 문장에 기반한 회피 문장 정보를 생성하여, 출력 수단을 통해 생성된 회피 문장 정보에 기반한 회피형 발화 신호를 출력할 수 있다. 일 실시예에 따르면, 상기 회피 문장 정보는 상기 출력 수단으로 하여금 회피형 발화 신호를 출력하도록 하는 구성으로써, 상기 사용자로부터 수신한 자연어에 대응되는 문장이 객관적인 사실이 필요로 하는 문장인 경우, 상기 문장에 대한 회피 형태의 회피형 발화 신호를 출력하도록 해 안정적이고 자연스러운 커뮤니케이션 서비스 를 제공하도록 하는 정보일 수 있다. 예를 들어, \"오늘 날씨 어때?\"와 같은 객관형 문장에 대한 회피 문장 정보 는 \"어제 날씨는 추웠는데 오늘 날씨는 어떨지 모르겠어\"라는 회피형 발화 신호를 포함할 수 있다. 일 실시예에 따르면, 상기 프로세서는 상기 문장이 객관형 문장으로 결정되는 경우, 열린 주제 대화 서비스에 기반한 지식 베이스에서 상기 입력된 객관형 문장에 대한 객관형 응답을 제공할 수 없으므로, 입력된 객관형 문장을 회피하는 회피 문장 정보를 상기 열린 주제 대화 서비스에 기반한 지식 베이스에서 추출해 상기 회피 문장 정보에 기반한 회피형 발화 신호를 출력할 수 있다. 도 2는 본 발명의 일 실시 예에 따른 자연어 대화 인터페이스 시스템을 위한 회피형 발화 처리 장치의 구문 타 입 판단부를 설명하기 위한 블록도이다. 도 2를 참조하면, 하나 이상의 프로세서 및 상기 프로세서에서 수행 가능한 명령들을 저장하는 하나 이상의 메 모리를 포함하는 컴퓨팅 장치로 구현되는 자연어 대화 인터페이스 시스템을 위한 회피형 발화 처리 장치는 구문 타입 판단 부(예: 도 1의 구문 타입 판단 단계(S101 단계)와 동일한 기능 수행)를 포함할 수 있다. 일 실시예에 따르면, 상기 구문 타입 판단부는 사용자로부터 자연어가 입력되는 경우, 상기 입력된 자연어 에 대응되는 문장에 포함된 형태소를 확인하여, 상기 확인된 형태소를 통해 상기 문장에 대한 구문 타입을 판단 할 수 있다. 일 실시예에 따르면, 상기 구문 타입 판단부는 상술한 기능을 수행하기 위한 세부 구성으로, 어절 확인부 , 성분 분류부 및 구문 결정부를 포함할 수 있다. 일 실시예에 따르면, 상기 어절 확인부는 상기 자연어가 입력되는 경우, 입력된 자연어에 대응되는 문장 (200a)에 포함된 복수 개의 형태소를 식별하여, 상기 식별된 형태소를 기반으로, 상기 문장을 구성하는 복수 개 의 어절을 확인할 수 있다. 예를 들어, 상기 어절 확인부는 상기 자연어를 수신하는 경우, 상기 수신된 자 연어에 기반한 문장(200a)인 \"오늘 날씨는 어때?\"를 식별할 수 있다. 이에 따라, 상기 어절 확인부는 식별된 문장인 \"오늘 날씨는 어때?\"를 \"오늘\" v \"~의\" v \"날씨\" v \"~는\" v \"어떻\" v \"~다\"로 분해하여, 총 6개의 형태소(201a)로 분해할 수 있다. 상기와 관련하여, 상기 어절 확인부는 상기 문장(200a)을 복수 개의 형태소(201a)로 식별한 경우, 상기 식 별된 복수 개의 형태(201a) 각각이 어떤 형태소인지를 구분할 수 있다. 상기 형태소의 종류는 자립 형태소(혼자 쓰일 수 있는 형태소(예: 날씨)), 의존 형태소(다른 말에 의존하여 쓰 이는 형태소(예: ~을, ~는, ~다)), 실질 형태소(실질적인 의미를 갖는 형태소(예: 오늘)) 및 형식 형태소(문법 적 관계나 형식적 의미를 더해주는 형태소(예: 조사, 어미, 접사))로 구분되는데, 상기 어절 확인부는 상 기 분해된 형태소 각각의 종류를 분석할 수 있다. 이 때, 상기 어절 확인부는 기 저장된 형태소 정보를 기 반으로, 상기 분해된 형태소 각각의 종류를 구분하여 확인할 수 있다. 이 후, 상기 어절 확인부는 상기 문장(200a)을 구성하는 어절을 확인할 수 있다. 어절은 문장을 구성하고 있는 각각의 마디로써, 문장 성분의 최소 단위로서, 띄어쓰기의 단위가 되는 구성일 수 있다. 일 실시예에 따르면, 상기 어절 확인부는 문장 내의 적어도 하나의 어절을 확인하기 위하여, 토큰화 (tokenization) 프로세스를 수행할 수 있다. 이 때, 상기 어절 확인부는 상기 토큰화 프로세스를 진행 시, 일반적으로 한국어는 영어와 달리 형태소가 독립적인 단어로만 구성되어 있지 않은, 교착어이기 때문에 단어 토 큰화가 아닌 형태소 토큰화 방식을 수행할 수 있다. 상기 어절 확인부는 상기 문장에 포함된 복수 개의 형 태소 및 형태소의 종류를 인식하고, 상기 형태소의 종류를 구분하여, 자립 형태소 및 의존 형태소의 결합으로 구성되는 것을 하나의 토큰으로 인식하여, 하나의 어절로 지정할 수 있다. 일 실시예에 따르면, 상기 어절 확인부는 상기 형태소 토큰화 방식의 토큰화 프로세스를 진행하여, 상기 문장 내에 포함된 복수 개의 어절을 확인할 수 있다. 예를 들어, 상기 어절 확인부는 \"오늘 날씨는 어 때?\"에서 어절을 확인할 수 있다. 상기 어절 확인부는 \"오늘 날씨는 어때\"에 대한 형태소 토큰화를 진행하 여, \"오늘의\" v \"날씨는\" v \"어떠한가요\"라는 3개의 어절을 확인할 수 있다. 일 실시예에 따르면, 상기 성분 분류부는 상기 어절 확인부의 기능 수행에 의해 복수 개의 어절의 확 인이 완료되면, 기 저장된 품사 분류 정보를 기반으로, 복수 개의 어절에 포함된 형태소들 각각에 대한 품사를 확인하여, 상기 확인된 품사를 통해 상기 복수 개의 어절 각각의 문장 성분을 분류할 수 있다. 이 때, 상기 기 저장된 품사 분류 정보는 품사 태그 정보를 의미할 수 있다. 일 실시예에 따르면, 상기 성분 분류부는 상기 기 저장된 품사 분류 정보를 통해 형태소 각각에 대한 품사 를 정의할 수 있다. 한국어는 기본적으로 5언 9품사 태깅(Part-of-speech tagging) 기술을 통해 형태소 각각의 품사를 정의할 수 있다. 상기 기 저장된 품사 분류 정보는 형태소 각각의 품사를 정의하기 위한 기준 형태소 정 보(품사 정보 포함)를 포함할 수 있다.보다 자세하게 상기 성분 분류부는 상기 기 저장된 품사 분류 정보를 통해 형태소 각각에 대한 품사를 정 의하고, 상기 품사가 정의된 형태소들 중 하나의 토큰으로 인식되는 구성의 문장 성분을 결정할 수 있다. 예를 들어 상기 성분 분류부는 상기 기 저장된 품사 분류 정보를 기반으로,\"날씨\"과 \"는\"에 대한 품사를 분류할 수 있다. 상기 성분 분류부는 상기 \"날씨\"을 명사로 분류하고, 상기 \"는\"을 조사로 분류할 수 있다. 상기 성분 분류부는 상기 분류된 품사를 기반으로, 하나의 토큰으로 인식되는 \"날씨는\"의 문장 성분을 목적어로 결정할 수 있다. 일 실시예에 따르면, 상기 구문 결정부는 상기 성분 분류부에 의해 상기 복수 개의 어절 각각에 대한 문장 성분의 분류가 완료된 경우, 상기 분류된 문장 성분 간의 조합 관계를 확인할 수 있다. 상기 구문 결정부 는 상기 확인 결과를 기반으로, 상기 문장에 대한 구문 타입을 결정할 수 있다. 즉, 상기 문장에 대한 구 문 타입(205a)은 근본적으로 형태소에 기반하여 판단되는 구성일 수 있다. 일 실시예에 따르면, 상기 구문 결정부는 문장의 구문 타입을 구문 타입표(205a)를 통해 결정할 수 있다. 상기와 관련하여, 제1 구문 타입은 주어 및 서술어의 조합에 의한 구문 타입이고, 제2 구문 타입은 주어와 부사 어 및 서술어의 조합에 의한 구문 타입이고, 제3 구문 타입은 주어와 목적어 및 서술어의 조합에 의한 구문 타 입이고, 제4 구문 타입은 주어와 보어 및 서술어의 조합에 의한 구문 타입이고, 제5 구문 타입은 주어, 목적, 보어 및 서술어에 의한 구문 타입일 수 있다. 즉, 상기 구문 타입은 복수 개의 어절 각각에 대한 문장 성분 간 의 조합 관계를 기반으로 결정되는 상기 문장(200a)에 대한 문장 형태일 수 있다. 일 실시예에 따르면, 상기 구문 결정부는 상기 표(205a)에 개시된 내용을 기반으로, 상기 복수 개의 어절 각각에 대한 문장 성분의 조합 관계를 확인함으로써, 상기 문장(200a)에 대한 구문 타입을 결정할 수 있다. 도 3은 본 발명의 일 실시 예에 따른 자연어 대화 인터페이스 시스템을 위한 회피형 발화 처리 방법의 의미 정 보 확인 단계를 설명하기 위한 순서도이다. 도 3을 참조하면, 하나 이상의 프로세서 및 상기 프로세서에서 수행 가능한 명령들을 저장하는 하나 이상의 메 모리를 포함하는 컴퓨팅 장치로 구현되는 자연어 대화 인터페이스 시스템을 위한 회피형 발화 처리 방법은 의미 정보 확인 단계(예: 도 1의 의미 정보 확인 단계(S103 단계))를 포함할 수 있다. 일 실시예에 따르면, 상기 의미 정보 확인 단계는 구문 타입 판단 단계(예: 도 1의 구문 타입 판단 단계(S101 단계))의 기능 수행에 의해 문장의 구문 타입이 판단되면, 기 저장된 형태소 의미 사전을 기반으로, 상기 형태 소에 대한 의미 정보를 확인하는 단계일 수 있다. 일 실시예에 따르면, 상기 구문 타입 판단 단계는 상술한 기능을 수행하기 위한 세부 단계로, 분석 프로세스 시 작 단계(S301 단계) 및 의미 정보 태깅 단계(S303 단계)를 포함할 수 있다. S301 단계에서, 상기 하나 이상의 프로세서(이하, 프로세서로 칭함)는 문장의 구문 타입이 판단되면, 문장에 포 함된 형태소를 식별하여, 기 저장된 형태소 의미 사전에 기반해 식별된 형태소에 대한 개체명 분석 프로세스 (named entity recognition process)를 시작할 수 있다. 일 실시예에 따르면, 상기 기 저장된 형태소 의미 사전에 저장된 복수 개의 의미 정보는 문장의 구문 타입마다 동음이의어가 다수 존재하는 형태소들의 의미를 식별하기 위한 구성일 수 있다. 상기와 관련하여, 상기 개체명 분석 프로세스는 인명(person), 지명(location), 기관명(organization) 등 의미 정보(예: 개체명 태그)를 형태소 또는 문장 성분에 부여하기 위한 프로세스일 수 있다. 일반적으로 개체명 분석 프로세스는 딥 러닝을 적용한 LSTM(long short term memory)-CRF의 방식이나 LSTM-RNN(recurrent neural network) 방식에 기반한 프로세스일 수 있으며, BERT 방식에 기반한 프로세스일 수 있다. 일 실시예에 따르면, 상기 프로세서는 상기 개체명 분석 프로세스가 시작되는 경우, 의미 정보 태깅 단계(S303 단계)를 수행할 수 있다. S303 단계에서, 상기 프로세서는 상기 개체명 분석 프로세스가 시작됨ㅁ에 따라, 상기 기 저장된 형태소 의미 사전에 기반해 상기 식별된 형태소 각각의 의미에 대응되는 의미 정보가 확인되는 경우, 상기 확인된 의미에 대 응되는 의미 정보를 상기 식별된 형태소 각각에 태깅할 수 있다 일 실시예에 따르면, 상기 프로세서는 상기 문장을 구성하는 형태소에 대한 의미 정보의 확인이 완료되면, 상기 확인된 의미 정보를 각각의 형태소에 태깅함으로써, 상기 개체명 분석 프로세스를 완료할 수 있다. 상기와같이, 의미 정보가 부여된 형태소로 구성된 문장은 이후에 문장의 의도를 분석하기 위해 활용될 수 있다. 도 4는 본 발명의 일 실시 예에 따른 자연어 대화 인터페이스 시스템을 위한 회피형 발화 처리 방법의 의미 정 보 확인 단계를 설명하기 위한 순서도이다. 도 4를 참조하면, 하나 이상의 프로세서 및 상기 프로세서에서 수행 가능한 명령들을 저장하는 하나 이상의 메 모리를 포함하는 컴퓨팅 장치로 구현되는 자연어 대화 인터페이스 시스템을 위한 회피형 발화 처리 방법은 관점 분석 프로세스 시작 단계(예: 도 1의 관점 분석 프로세스 시작 단계(S105 단계))를 포함할 수 있다. 일 실시예에 따르면, 상기 관점 분석 프로세스 시작 단계는 의미 정보의 확인이 완료되면, 상기 문장의 구문 타 입 및 상기 문장을 구성하는 형태소의 의미 정보를 통해 상기 문장에 대한 관점 분석 프로세스를 수행하여, 관 점 분석 프로세스의 결과를 통해 상기 문장을 객관형 문장 또는 주관형 문장으로 결정하는 단계일 수 있다. 일 실시예에 따르면, 상기 관점 분석 프로세스 시작 단계는 상술한 기능을 수행하기 위한 세부 단계로, 감성분 석 진행 단계(S401 단계), 주관 형태소 식별 단계(S403 단계) 및 객관형 문장 결정 단계(S405 단계)를 포함할 수 있다. S401 단계에서, 상기 하나 이상의 프로세서(이하, 프로세서로 칭함)는 의미 정보 태깅 단계(예: 도 3의 의미 정 보 태깅 단계(S303 단계))가 완료됨에 따라, 관점 분석 프로세스를 시작하는 경우, 문장의 구문 타입 및 상기 형태소마다 태깅된 의미 정보를 기 저장된 감성분석 알고리즘을 통해 분석할 수 있다. 보다 자세하게, 상기 프로세서는 상기 관점 분석 프로세스가 시작되는 경우, 상기 문장의 구문 타입 및 형태소 마다 태깅된 의미 정보를 통해 문장의 전체적인 의도를 확인한 상태에서, 상기 기 저장된 감성분석 알고리즘을 통해 상기 문장을 분석할 수 있다. 일 실시예에 따르면, 상기 프로세서는 상기 기 저장된 감성분석 알고리즘을 통해 상기 문장의 분석을 시작한 경 우, 주관 형태소 식별 단계(S403 단계)를 수행할 수 있다. S403 단계에서, 상기 프로세서는 상기 감성분석 프로세스가 시작됨에 따라, 기 저장된 감성분석 알고리즘을 기 반으로 상기 문장의 구문 타입 및 형태소마다 태깅된 의미 정보를 분석하는 경우, 븐석 결과를 통해 문장에서 주관 카테고리에 포함되는 형태소가 존재하는지를 식별할 수 있다. 보다 자세하게, 상기 프로세서는 상기 감성분석 프로세스가 시작되는 경우, 상기 문장의 구문 타입 및 형태소마 다 태깅된 의미 정보를 통해 문장의 전체적인 의미를 확인한 상태에서, 상기 기 저장된 감성분석 알고리즘을 통 해 상기 문장을 분석할 수 있다. 예를 들어, 상기 프로세서는 상기 문장의 구문 타입 및 형태소마다 태깅된 의미 정보를 통해 문장의 전체적인 의도를 확인한 상태에서, 상기 문장에 대하여, 멀티모달 신경망(multimodal NN) 및 한국어 기반의 버트(BERT, Bidirectional Encoder Representations from Transformers) 모델의 기 저장된 감성분석 알고리즘을 통해, 상 기 문장에 대한 감성분석 프로세스를 실시할 수 있다. 예를 들어, 상기 멀티모달 신경망은 텍스트 처리 알고리즘이 포함된 신경망 처리를 위한 구성이다. 해당 신경망 은 특히 다종의 생체 신호를 이용한 딥러닝 기반 감정 분류 등에 사용되어, 다종의 데이터를 기반으로 일 결과 를 도출하기 위해서 사용되는 모델로 이해된다. 또한, 상기 프로세서는 문장에 대한 딥 러닝 적용을 통한 감성분석에 사용될 수 있는 단어(예: 키워드) 추출 방 식이 사용될 수 있다. 또는 문장 자체에 대한 감성 트리 등을 이용한 감성분석 알고리즘을 적용할 수 있다. 예를 들어, 상기 프로세서는 문장을 기반으로 한 감성분석 알고리즘으로써, 예를 들어 상술한 버트 모델을 통해 상기 문장에 대한 감성분석 프로세스를 수행할 수 있다. 이 때의 감성분석 알고리즘은 머신 러닝 및 단어 (keyword) 기반 분석 알고리즘일 수 있다. 상기와 관련하여, 머신러닝 기반의 감성분석은 예를 들어, 회귀 분석을 통한 사전 구축 방식이 있다. 일반적으 로 사용자로부터 획득되는 자연어를 구성하는 복수 개의 형태소에 평점을 부여하는데, 이렇게 평점을 레이블링 된 데이터에 회귀 분석 모델을 적용하여 각 형태소에 대한 감성 사전을 구축하며, 구축한 이후에는 교차 검증을 통해 감성 사전으로서의 타당한 성능을 지니는지를 평가된 감성분석의 한 종류일 수 있다. 상기 프로세서는 상 기 머신러닝 기반의 감성분석을 통해 상기 문장을 분석 시, 검증을 통해 구축된 사전의 성능이 확보된 상태에서 컨텐츠에 대한 감성 분석을 수행할 수 있게 된다.한편 Semi-supervised 방식이 있다. 지도 학습과 비지도 학습의 중간인 준지도 학습(Semi-supervised Learning)을 통해 상기 감성 사전을 구축하기도 한다. 준지도 학습 기반의 방법은 2가지 세부 방법으로 나뉘게 된다. 첫 번째는 감 성 그래프(Sentiment graph)를 이용하는 방식이다. 고차원 단어를 저차원으로 임베딩한 후 에 거리를 기반으로 각 단어 사이의 네트워크를 구축한다. 감성 점수가 확실한 수 개의 단어를 미리 레이블링 (Pre-labeled sentiment words)한 뒤에 공간 상의 위치에 따라 나머지 단어의 감성 점수를 측정한다. 보다 자세하게, \"좋다\", \"짱\", \"재밌다\", \"훌륭하다\" 등을 긍정으로 \"거슬리다\", \"억지\", \"지루\", \"아쉬움\" 등 을 부정으로, 그리고 \"보다\", \"감독\", \"주인공\", \"친구\", \"카메라\" 와 같이 중립으로 미리 레이블링 하고 그리 고 이들과의 관계로부터 나머지 단어의 감정 점수를 매기게 되어 감성분석을 수행하게 된다. 준지도 학습을 통한 두 번째 접근 방식은 자가 학습(self-training)이다. 이 방법 역시 상기 감성 그래프 방법 과 같이, 복수 개의 특정 단어는 미리 레이블링 된 상태이다. 이 어휘로만 분류기를 학습한 뒤에 정답이 없는 어휘에 분류기를 적용하여 결과의 신뢰도가 높으면 정답으로 지정한 후, 학습기를 재학습하는 방식이다. 반복 학습 횟수가 늘어날수록 레이블링 되는 단어가 더 많아질 수 있다. RNTN(Recursive Neural Tensor Network) 방법 역시 사용될 수 있다. 여기서의 R은 Recursive(재귀적인)를 나타 내는 단어로 RNN에서 사용되는 Recurrent(순환하는)와는 다른 의미를 가지고 있다. RNTN은 두 가지 벤치마크 모 델이 있다. 첫 번째는 RecursiveNN으로서, 각 단어를 아래와 같이 구조적으로 나타낸 이후 각 단어를 구 (Phrase)로 하나씩 결합하면서 감성이 어떻게 나타내는 지를 계속해서 학습한다. 일 논문에서는 긍정과 부정을 25단계로 구분하였으며, 동일한 구에 대해서는 3명이 평가한 결과물의 평균을 사용하여 레이블링 한다. 여기서 재귀적(Recursive)이라는 수식어를 사용하는 이유는 각 단어 혹은 구마다 동일한 가중치를 적용하기 때문이다. 두 번째는 MV-RNN(Matrix-Vector Recursive Neural Network) 이다. 이 방법은 더 긴 문장의 문맥을 행렬에 저 장하여 기존 RecursiveNN의 한계점을 해결하고자 한다. 그리고 두 벤치마크 모델을 결합하여 텐서로 쌓아 나타 낸 것이 바로 아래의 RNTN이다. RNTN은 일반적으로 각각의 벤치마크 모델보다 성능이 더 좋다. 특히 \"but\"등의 단어로 두 문장이 이어져 있거나 복잡한 부정 표현(High-level Negation)이 문장에 존재하는 경우에 기존 모델 보다 훨씬 더 좋은 성능을 나타낸다. 한편 버트 모델은, 구글에서 개발한 NLP(자연어처리) 사전 훈련 기술이며, 특정 분야에 국한된 기술이 아니라 모든 자연어 처리 분야에서 좋은 성능을 내는 범용 랭귀지 모델(Language Model)이다. 11개 이상의 자연어처리 과제에서 BERT가 최첨단 성능을 발휘하고 있어, 최근 언어처리에 매우 적합한 모델로 각광받고 있는 모델일 수 있다. 특정 과제를 수행하기 위한 모델의 성능은, 데이터가 충분히 많다면 Embedding이 큰 영향을 미치게 되며, 단어 의 의미를 잘 표현하는 벡터로 표현하는 Embedding된 단어들이 훈련과정에서 당연히 좋은 성능을 낼 것이다. 이 임베딩 과정에서 BERT를 사용하는 것이고, BERT는 특정 과제를 하기 전 사전 훈련 Embedding을 통해 특정 과제 의 성능을 더 좋게 할 수 있는 언어모델로 이해될 수 있다. BERT등장 이전에는 데이터의 전처리 임베딩을 Word2Vec, GloVe, Fasttext 방식을 많이 사용했지만, 요즘의 고성 능을 내는 대부분의 모델에서 BERT를 많이 사용하고 있다. 버트 모델에서는 인풋 텍스트 데이터를 Token Embedding, Segment Embedding 및 Position Embedding을 통해 처 리한다. Token Embedding은 Word Piece 임베딩 방식으로서 각 Char(문자) 단위로 임베딩을 하고, 자주 등장하면 서 가장 긴 길이의 sub-word를 하나의 단위로 만든다. 자주 등장하지 않는 단어는 다시 sub-word로 만든다. 이 는 이전에 자주 등장하지 않았던 단어를 모조리 'OOV'처리하여 모델링의 성능을 저하했던 'OOV'문제도 해결할 수 있다. Segment Embedding에서는 토큰 시킨 단어들을 다시 하나의 문장으로 만드는 작업을 수행한다. BERT에서는 두개 의 문장을 구분자([SEP])를 넣어 구분하고 그 두 문장을 하나의 Segment로 지정하여 입력한다. BERT에서는 이 한 세그먼트를 512 sub-word 길이로 제한하는데, 한국어는 보통 20 sub-word가 한 문장을 이룬다고 하며 대부분 의 문장은 60 sub-word가 넘지 않는다고 하니 BERT를 사용할 때, 하나의 세그먼트에 128로 제한하여도 충분히 학습이 가능하다. Position Embedding에 있어서 버트는 Transformer 모델의 일부만을 사용한다. Transformer란 CNN, RNN 과 같은 모델 대신 Self-Attention 이라는 모델을 사용하는 모델이다. BERT는 Transformer의 인코더, 디코더 중 인코더 만 사용합니다. Self Attention은 입력의 위치를 고려하지 않고 입력 토큰의 위치 정보를 고려한다. 그래서 Transformer모델에 서는 Sinusoid 함수를 이용하여 Positional encoding을 사용하고 BERT는 이를 따서 Position Encoding을 사용 한다. 즉 Token의 순서대로 임베딩을 수행하는 것이다. BERT는 위 세가지 임베딩을 합치고 이에 Layer정규화와 Dropout을 적용하여 입력으로 사용한다. 데이터들을 임베딩하여 훈련시킬 데이터를 모두 인코딩 하였으면, 사전훈련(Pre-Training)을 시킨다. 즉 본 발 명에서상기 프로세서는, 버트 모델을 적용하여, 버트 모델은 기존의 특정 스페시픽(Specific)한 분야의 분석 모 델을 사용하지 않고, 제너럴(General)한 모델을 먼저 제시한 뒤 이를 Fine Tuning하여 해당 태스크를 수행하는 알고리즘을 도출한다. 즉, 버트 모델에 대한 프리 트레이닝(Pre-training)을 진행하고, 상기 문장을 제외한 다 른 문장을 이용하여 상기 버트 모델에 대한 파인 튜닝(Fine tuning)을 통해 상기 버트 모델을 지속적으로 학습 시키는 것이다. 기존의 방법들은 보통 문장을 왼쪽에서 오른쪽으로 학습하여 다음 단어를 예측하는 방식이거나, 예측할 단어의 좌우 문맥을 고려하여 예측하는 방식을 사용한다. 하지만 BERT는 언어의 특성을 잘 학습하도록, MLM(Masked Language Model) 및 NSP(Next Sentence Prediction) 두가지 방식을 사용한다. MLM은 입력 문장에서 임의로 토근을 버리고(Mask처리) 해당 토큰을 맞추는 방식으로 학습을 진행하게 되고, NSP 는 두 문장이 주어졌을 때, 두 문장의 순서를 예측하는 방식으로서, 두 문장 간 관련이 고려되야 하는 NLI와 QA 의 파인 튜닝을 위해 두 문장의 연관을 맞추는 학습을 진행한다. 프리 트레이닝 이후에는 상기와 같이 학습된 언어모델을 전이학습시키는 Fine tuning 과정이 수행된다. 즉 프리 트레인을 마친 단어 임베딩(문장임베딩)은 말뭉치의 의미적 문법적 정보를 충분히 담고 있고, 다운스트림 태스 크를 수행하기 위한 파인튜닝 추가학습을 통해 임베딩을 다운스트림 태스크에 맞게 업데이트 하게 된다. 전이학 습은 BERT의 언어 모델의 출력에 추가적인 모델을 쌓아 만든다. 일반적으로 복잡한 CNN, LSTM, Attention을 쌓 지 않고 간단한 DNN만 쌓아도 성능이 잘 나오며 별 차이가 없다고 알려져 있다. ERT를 각 Task에 쓰기위해서는 먼저 문장 쌍 분류 문제로 두 문장을 하나의 입력으로 넣고 두 문장간 관계를 구 하거나, 한 문장을 입력으로 넣고 문장의 종류를 분류하거나, 문장이나 문단 내에서 원하는 정답 위치의 시작과 끝을 구하거나, 입력 문장 Token들의 개체명(Named entity recognigion)을 구하거나 품사(Part-of-speech tagging) 를 구한다. 이때, 상기 프로세서는 해당 파인튜닝을 이용하여 입력 문장에 대한 긍부정 분류를 수행하게 되는데, 파인튜닝 으로 입력 문장의 종류(긍/부정)를 분류하는 task의 경우 classification layer가 추가되어 문장에 대한 수치나 단어 등의 키워드에 따라서 긍부정을 분류하고, 이때 파라미터로서, Batch Size, Epoch, Max Sequence Length, Dropout Rate, Learning Rate 등이 설정되어 사용될 수 있다. 즉, 상기 프로세서는 기 저장된 감성분석 알고리즘을 통해 문장 내의 형태소를 분석하여, 분석 결과로 추출되는 형태소가 상기 기 저장된 감성분석 알고리즘에 기반한 감성 사전 중 긍정 카테고리, 부정 카테고리 및 중립 카 테고리 중 어느 감성 카테고리에 포함되는지를 식별하는 감성분석 프로세스를 수행하여, 상기 문장에 대한 감성 분석의 결과 값을 획득할 수 있다. 예를 들어, 상기 프로세서는 기 저장된 감성분석 알고리즘을 통해 문장 내의 형태소를 분석하여, 분석 결과로 추출되는 복수 개의 형태소 중 제1 형태소가 상기 기 저장된 감성분석 알고리즘에 기반한 감성 사전 중 긍정 카 테고리에 포함되는 것을 식별할 수 있다. 또한, 상기 프로세서는 기 저장된 감성분석 알고리즘을 통해 문장 내 의 형태소를 분석하여, 분석 결과로 추출되는 복수 개의 형태소 중 제2 형태소가 상기 기 저장된 감성분석 알고 리즘에 기반한 감성 사전 중 부정 카테고리에 포함되는 것을 식별할 수 있다. 마지막, 상기 프로세서는 기 저장 된 감성분석 알고리즘을 통해 문장 내의 형태소를 분석하여, 분석 결과로 추출되는 복수 개의 형태소 중 제3 형 태소가 상기 기 저장된 감성분석 알고리즘에 기반한 감성 사전 중 중립 카테고리(의견을 묻거나 감정을 묻는 형 태소가 포함된 카테고리)에 포함되는 것을 식별할 수 있다. 이에 따라, 상기 프로세서는 상기 문장이 긍정 카테고리, 부정 카테고리 및 중립 카테고리 중 적어도 하나에 기 반한 형태소가 포함되어 있는 것을 확인한 경우, 상기 확인한 결과 값에 기반해 상기 문장을 구성하는 복수 개 의 형태소 중 적어도 하나가 주관 카테고리에 포함되는 형태소가 존재하는 것으로 식별할 수 있다. 상기와 관련하여, 상기 주관 카테고리는 개인의 감성 및 감정 표현에 기반한 키워드(형태소)를 포함하는 감성 감정 카테고리, 개인의 의견 및 판단에 기반한 키워드(형태소)를 포함하는 의견 판단 카테고리, 개인의 평가에기반한 키워드(형태소)를 포함하는 평가 카테고리를 포함할 수 있다. 즉, 상기 주관 카테고리는 개인의 감정이 나 의견이 포함되어 있는 문장을 구성하는 형태소를 포함하고 있는 카테고리일 수 있다. 일 실시예에 따르면, 상기 프로세서는 상기 주관 형태소 식별 단계(S403 단계)의 기능 수행이 완료됨에 따라, 상기 문장에 주관 카테고리에 포함되는 형태소가 존재하지 않는 것을 확인하면, 상기 객관형 문장 결정 단계 (S405 단계)를 수행할 수 있다. S405 단계에서, 상기 프로세서는 상기 주관 형태소 식별 단계(S403 단계)의 기능 수행에 의해 문장에 주관 카테 고리에 포함되는 형태소가 존재하지 않는 것을 확인한 경우, 문장을 객관형 문장으로 결정할 수 있다. 상기와 관련하여, 상기 객관형 문장은 사람의 감정이나 의견이 포함되어 있지 않은 문장으로, 전문 질의 응답 커뮤니케이션 서비스에서 주로 사용되는 문장일 수 있다. 도 5는 본 발명의 일 실시 예에 따른 자연어 대화 인터페이스 시스템을 위한 회피형 발화 처리 방법의 회피형 발화 출력 단계를 설명하기 위한 순서도이다. 도 5를 참조하면, 하나 이상의 프로세서 및 상기 프로세서에서 수행 가능한 명령들을 저장하는 하나 이상의 메 모리를 포함하는 컴퓨팅 장치로 구현되는 자연어 대화 인터페이스 시스템을 위한 회피형 발화 처리 방법은 회피 형 발화 출력 단계(예: 도 1의 회피형 발화 출력 단계(S107 단계))를 포함할 수 있다. 일 실시예에 따르면, 상기 회피형 발화 출력 단계는 관점 분석 프로세스 시작 단계(예: 도 1의 관점 분석 프로 세스 시작 단계(S105 단계))의 기능 수행에 의해 문장이 객관형 문장으로 결정되는 경우, 상기 객관형 문장에 대한 응답을 회피하는 회피 문장에 기반한 회피 문장 정보를 생성하여, 출력 수단을 통해 상기 생성된 회피 문 장 정보에 기반한 회피형 발화 신호를 출력하는 단계일 수 있다. 일 실시예에 따르면, 상기 회피형 발화 출력 단계는 상술한 기능을 수행하기 위한 세부 단계로, 챗봇 유형 확인 단계(S501 단계), 제1 회피 문장 정보 생성 단계(S503 단계) 및 제2 회피 문장 정보 생성 단계(S505 단계)를 포 함할 수 있다. S501 단계에서, 상기 하나 이상의 프로세서(이하, 프로세서로 칭함)는 상기 회피 문장 정보를 생성하기 이전에 출력 수단을 제어하는 챗봇 프로그램의 유형을 확인할 수 있다. 일 실시예에 따르면, 상기 프로세서는 상기 출력 수단을 제어하는 챗봇 프로그램의 유형이 지식 베이스 기반 질 의 응답형 인공지능 유형인지 열린 주제 대화형 인공지능 유형인지를 확인할 수 있다. 상기와 관련하여, 상기 지식 베이스 기반 질의 응답형 인공지능 유형은 특정 주제에 대한 전문적인 질의 응답을 수행하는 인공지능 유형으로써, 객관형 문장에 대한 응답을 출력하는 유형일 수 있다 또한, 상기 열린 주제 대 화형 인공지능 유형은 일상 생활에 대한 일반적인 질의 응답을 수행하는 인공지능 유형으로써, 주관형 문장에 대한 응답을 출력하는 유형일 수 있다. 일 실시예에 따르면, 상기 프로세서는 상기 챗봇 프로그램의 유형이 열린 주제 대화형 인공지능 유형으로 확인 되면, 제1 회피 문장 정보 생성 단계(S503 단계)를 수행할 수 있다. S503 단계에서, 상기 프로세서는 상기 챗봇 유형 확인 단계(S501 단계)의 기능 수행에 의해 챗봇 프로그램의 유 형이 열린 주제 대화형 인공지능 유형으로 확인되는 경우, 객관형 문장에 대한 응답을 회피하는 회피형 문장에 기반한 회피 문장 정보인 제1 회피 문장 정보를 생성할 수 있다. 일 실시예에 따르면, 상기 프로세서는 상기 챗봇 프로그램의 유형이 열린 주제 대화형 인공지능 유형으로 확인 되는 경우, 상기 객관형 문장에 대한 응답을 회피하는 회피형 문장을 생성하여, 제1 회피 문장 정보를 생성할 수 있다. 상기와 관련하여, 열린 주제 대화형 인공지능 유형의 챗봇 프로그램은 사용자로부터 수신된 자연어에 기반한 객관형 질문에 대한 명확한 응답을 할 수 없기 때문에, 상기 객관형 질문을 회피하기 위한 제1 회피 문 장 정보를 생성할 수 있다. 상기와 관련하여, 상기 제1 회피 문장 정보는 챗봇 프로그램의 유형이 열린 주제 대화형 인공지능 유형일 때, 사용자로부터 객관형 문장이 수신되는 경우, 상기 수신된 객관형 문장에 대한 회피 응답을 제공하기 위한 문장 으로 구성된 정보일 수 있다. 상기 제1 회피 문장 정보는 열린 주제 대화형 인공지능 기반의 지식 베이스에서 추출되는 키워드를 통해 생성되는 정보일 수 있다. 일 실시예에 따르면, 상기 프로세서는 상기 챗봇 프로그램의 유형이 지식 베이스 기반 질의 응답형 인공지능 유 형으로 확인되면, 제2 회피 문장 정보 생성 단계(S505 단계)를 수행할 수 있다. S505 단계에서, 상기 프로세서는 챗봇 유형 확인 단계(S501 단계)의 기능 수행에 의해 챗봇 프로그램의 유형이 지식 베이스 기반 질의 응답형 인공지능 유형으로 확인되되, 상기 객관형 문장에 대한 응답이 지식 베이스에 적 어도 두 개 이상 존재하는 것을 확인하는 경우, 상기 객관형 문장에 대한 응답을 회피하는 회피형 문장에 기반 한 회피 문장 정보인 제2 회피 문장 정보를 생성할 수 있다. 일 실시예에 따르면, 상기 프로세서는 상기 챗봇 프로그램의 유형이 지식 베이스 기반 질의 응답형 인공지능 유 형으로 확인된 상태에서, 상기 객관형 문장에 대한 객관형 응답을 상기 지식 베이스에서 추출할 수 있다. 다만, 상기 프로세서는 상기 객관형 문장에 대한 객관형 응답이 상기 지식 베이스에 적어도 두 개 이상 존재하는 경우, 객관형 문장에 대한 객관형 응답을 출력하지 않고, 상기 객관형 문장을 회피하는 회피형 문장에 기반한 제2 회피 문장 정보를 상기 지식 베이스를 통해 생성할 수 있다. 상기와 관련하여, 상기 제2 회피 문장 정보는 챗봇 프로그램의 유형이 지식 베이스 기반 질의 응답형 인공지능 유형일 때, 사용자로부터 객관형 문장이 수신되는 경우, 상기 객관형 문장에 대응 객관형 응답이 적어도 두 개 이상이면 상기 수신된 객관형 문장에 대한 회피 응답을 제공하기 위한 문장으로 구성된 정보일 수 있다. 상기 제2 회피 문장 정보는 지식 베이스 기반 질의 응답형 인공지능 기반의 지식 베이스에서 추출되는 키워드를 통해 생성되는 정보일 수 있다. 도 6은 본 발명의 일 실시 예에 따른 자연어 대화 인터페이스 시스템을 위한 회피형 발화 처리 장치의 회피형 발화 출력부를 설명하기 위한 블록도이다. 도 6을 참조하면, 하나 이상의 프로세서 및 상기 프로세서에서 수행 가능한 명령들을 저장하는 하나 이상의 메 모리를 포함하는 컴퓨팅 장치로 구현되는 자연어 대화 인터페이스 시스템을 위한 회피형 발화 처리 장치는 회피 형 발화 출력부(예: 도 1의 회피형 발화 출력 단계(S107 단계)와 동일한 기능 수행)를 포함할 수 있다. 일 실시예에 따르면, 상기 회피형 발화 출력부는 관점 분석 프로세스 시작 단계의 기능 수행에 의해 문장 이 객관형 문장으로 결정되는 경우, 상기 객관형 문장에 대한 응답을 회피하는 회피 문장에 기반한 회피 문장 정보를 생성하여, 출력 수단을 통해 상기 생성된 회피 문장 정보에 기반한 회피형 발화 신호를 출력할 수 있다. 일 실시예에 따르면, 상기 회피형 발화 출력부는 상술한 기능 외에도 다른 기능을 수행할 수 있다. 상기와 관련하여, 상기 회피형 발화 출력부는 제1 회피 문장 정보 및 제2 회피 문장 정보 중 하 나의 생성이 완료되면, 생성된 회피 문장 정보(제1 회피 문장 정보 또는 제2 회피 문장 정보)에 기반한 회피형 발화 신호를 출력 수단을 통해 출력하여, 사용자로 하여금 객관형 문장이 아닌 주관형 문장에 대응되는 발화를 하도록 유도할 수 있다. 일 실시예에 따르면, 상기 제1 회피 문장 정보는 챗봇 프로그램의 유형이 열린 주제 대화형 인공지능 유형 인 상태에서, 객관형 문장을 수신한 경우, 수신된 객관형 문장에 대한 회피형 문장에 기반해 생성된 정보일 수 있다. 일 실시예에 따르면, 상기 제2 회피 문장 정보는 챗봇 프로그램의 유형이 지식 베이스 기반 질의 응답형 인공지능 유형이되, 수신한 객관형 문장에 대한 객관형 응답이 적어도 두 개 이상인 경우, 수신된 객관형 문장 에 대한 회피형 문장에 기반해 생성된 정보일 수 있다. 이에 따라, 상기 회피형 발화 출력부는 출력 수단을 통해 상기 제1 회피 문장 정보 또는 제2 회피 문장 정 보 중 하나에 기반한 회피형 발화 신호를 출력하여, 사용자로 하여금 객관형 문장이 아닌 주관형 문장에 대응되 는 발화를 하도록 유도할 수 있다. 도 7은 본 발명의 일 실시 예에 따른 컴퓨팅 장치의 내부 구성의 일 예를 설명하기 위한 도면이다. 도 7은 본 발명의 일 실시 예에 따른 컴퓨팅 장치의 내부 구성의 일 예를 도시하였으며, 이하의 설명에 있어서, 상술한 도 1 내지 6에 대한 설명과 중복되는 불필요한 실시 예에 대한 설명은 생략하기로 한다. 도 7에 도시한 바와 같이, 컴퓨팅 장치은 적어도 하나의 프로세서(processor), 메모리 (memory), 주변장치 인터페이스(peripEHRal interface), 입/출력 서브시스템(I/O subsystem), 전력 회로 및 통신 회로를 적어도 포함할 수 있다. 이때, 컴퓨팅 장치 은 촉각 인터페이스 장치에 연결된 유저 단말이기(A) 혹은 전술한 컴퓨팅 장치(B)에 해당될 수 있다.메모리는, 일례로 고속 랜덤 액세스 메모리(high-speed random access memory), 자기 디스크, 에스램 (SRAM), 디램(DRAM), 롬(ROM), 플래시 메모리 또는 비휘발성 메모리를 포함할 수 있다. 메모리는 컴퓨팅 장치의 동작에 필요한 소프트웨어 모듈, 명령어 집합 또는 그밖에 다양한 데이터를 포함할 수 있다. 이때, 프로세서나 주변장치 인터페이스 등의 다른 컴포넌트에서 메모리에 액세스하는 것 은 프로세서에 의해 제어될 수 있다. 주변장치 인터페이스는 컴퓨팅 장치의 입력 및/또는 출력 주변장치를 프로세서 및 메모리 에 결합시킬 수 있다. 프로세서는 메모리에 저장된 소프트웨어 모듈 또는 명령어 집합을 실행하여 컴퓨팅 장치을 위한 다양한 기능을 수행하고 데이터를 처리할 수 있다. 입/출력 서브시스템은 다양한 입/출력 주변장치들을 주변장치 인터페이스에 결합시킬 수 있다. 예를 들어, 입/출력 서브시스템은 모니터나 키보드, 마우스, 프린터 또는 필요에 따라 터치스크린이나 센서 등의 주변장치를 주변장치 인터페이스에 결합시키기 위한 컨트롤러를 포함할 수 있다. 다른 측면에 따르면, 입/출력 주변장치들은 입/출력 서브시스템을 거치지 않고 주변장치 인터페이스에 결합될 수도 있다. 전력 회로는 단말기의 컴포넌트의 전부 또는 일부로 전력을 공급할 수 있다. 예를 들어 전력 회로 는 전력 관리 시스템, 배터리나 교류(AC) 등과 같은 하나 이상의 전원, 충전 시스템, 전력 실패 감지 회 로(power failure detection circuit), 전력 변환기나 인버터, 전력 상태 표시자 또는 전력 생성, 관리, 분배 를 위한 임의의 다른 컴포넌트들을 포함할 수 있다. 통신 회로는 적어도 하나의 외부 포트를 이용하여 다른 컴퓨팅 장치와 통신을 가능하게 할 수 있다. 또는 상술한 바와 같이 필요에 따라 통신 회로는 RF 회로를 포함하여 전자기 신호(electromagnetic signal)라고도 알려진 RF 신호를 송수신함으로써, 다른 컴퓨팅 장치와 통신을 가능하게 할 수도 있다. 이러한 도 7의 실시 예는, 컴퓨팅 장치의 일례일 뿐이고, 컴퓨팅 장치은 도 7에 도시된 일부 컴 포넌트가 생략되거나, 도 7에 도시되지 않은 추가의 컴포넌트를 더 구비하거나, 2개 이상의 컴포넌트를 결합시 키는 구성 또는 배치를 가질 수 있다. 예를 들어, 모바일 환경의 통신 단말을 위한 컴퓨팅 장치는 도 7에 도시 된 컴포넌트들 외에도, 터치스크린이나 센서 등을 더 포함할 수도 있으며, 통신 회로에 다양한 통신방식 (WiFi, 3G, LTE, Bluetooth, NFC, Zigbee 등)의 RF 통신을 위한 회로가 포함될 수도 있다. 컴퓨팅 장치(1000 0)에 포함 가능한 컴포넌트들은 하나 이상의 신호 처리 또는 어플리케이션에 특화된 집적 회로를 포함하는 하드 웨어, 소프트웨어, 또는 하드웨어 및 소프트웨어 양자의 조합으로 구현될 수 있다. 본 발명의 실시 예에 따른 방법들은 다양한 컴퓨팅 장치를 통하여 수행될 수 있는 프로그램 명령(instruction) 형태로 구현되어 컴퓨터 판독 가능 매체에 기록될 수 있다. 특히, 본 실시 예에 따른 프로그램은 PC 기반의 프 로그램 또는 모바일 단말 전용의 어플리케이션으로 구성될 수 있다. 본 발명이 적용되는 애플리케이션은 파일 배포 시스템이 제공하는 파일을 통해 이용자 단말에 설치될 수 있다. 일 예로, 파일 배포 시스템은 이용자 단말 이기의 요청에 따라 상기 파일을 전송하는 파일 전송부(미도시)를 포함할 수 있다. 이상에서 설명된 장치는 하드웨어 구성요소, 소프트웨어 구성요소, 및/또는 하드웨어 구성요소 및 소프트웨어구 성요소의 조합으로 구현될 수 있다. 예를 들어, 실시 예들에서 설명된 장치 및 구성요소는, 예를 들어, 프로세 서, 콘트롤러, ALU(arithmetic logic unit), 디지털 신호 프로세서(digital signal processor), 마이크로컴퓨 터, FPGA(field programmable gate array), PLU(programmable logic unit), 마이크로프로세서, 또는 명령 (instruction)을 실행하고 응답할 수 있는 다른 어떠한 장치와 같이, 하나 이상의 범용 컴퓨터 또는 특수 목적 컴퓨터를 이용하여 구현될 수 있다. 처리 장치는 운영 체제(OS) 및 상기 운영 체제상에서 수행되는 하나 이상의 소프트웨어 애플리케이션을 수행할 수 있다. 또한, 처리 장치는 소프트웨어의 실행에 응답하여, 데이터를 접근, 저장, 조작, 처리 및 생성할 수도 있다. 이해의 편의를 위하여, 처리 장치는 하나가 사용되는 것으로 설명된 경 우도 있지만, 해당 기술 분야에서 통상의 지식을 가진 자는, 처리 장치가 복수 개의 처리 요소(processing element) 및/또는 복수 유형의 처리 요소를 포함할 수 있음을 알 수 있다. 예를 들어, 처리 장치는 복수 개의 프로세서 또는 하나의 프로세서 및 하나의 콘트롤러를 포함할 수 있다. 또한, 병렬 프로세서(parallel processor)와 같은, 다른 처리 구성(processing configuration)도 가능하다. 소프트웨어는 컴퓨터 프로그램(computer program), 코드(code), 명령(instruction), 또는 이들 중 하나 이상의 조합을 포함할 수 있으며, 원하는 대로 동작하도록 처리 장치를 구성하거나 독립적으로 또는 결합적으로(collectively) 처리 장치를 명령할 수 있다. 소프트웨어 및/또는 데이터는, 처리 장치에 의하여 해석되거나 처 리 장치에 명령 또는 데이터를 제공하기 위하여, 어떤 유형의 기계, 구성요소(component), 물리적 장치, 가상장 치(virtual equipment), 컴퓨터 저장 매체 또는 장치에 영구적으로, 또는 일시적으로 구체화(embody)될 수 있다. 소프트웨어는 네트워크로 연결된 컴퓨팅 장치상에 분산되어서, 분산된 방법으로 저장되거나 실행될 수도 있다. 소프트웨어 및 데이터는 하나 이상의 컴퓨터 판독 가능 기록 매체에 저장될 수 있다. 실시 예에 따른 방법은 다양한 컴퓨터 수단을 통하여 수행될 수 있는 프로그램 명령 형태로 구현되어 컴퓨터 판 독 가능 매체에 기록될 수 있다. 상기 컴퓨터 판독 가능 매체는 프로그램 명령, 데이터 파일, 데이터 구조 등을 단독으로 또는 조합하여 포함할 수 있다. 상기 매체에 기록되는 프로그램 명령은 실시 예를 위하여 특별히 설계 되고 구성된 것들이거나 컴퓨터 소프트웨어 당업자에게 공지되어 사용 가능한 것일 수도 있다. 컴퓨터 판독 가 능 기록 매체의 예에는 하드 디스크, 플로피 디스크 및 자기 테이프와 같은 자기 매체(magnetic media), CD- ROM, DVD와 같은 광 기록 매체(optical media), 플롭티컬 디스크(floptical disk)와 같은 자기-광 매체 (magneto-optical media), 및 롬(ROM), 램(RAM), 플래시 메모리 등과 같은 프로그램 명령을 저장하고 수행하도 록 특별히 구성된 하드웨어 장치가 포함된다. 프로그램 명령의 예에는 컴파일러에 의해 만들어지는 것과 같은 기계어 코드뿐만 아니라 인터프리터 등을 사용해서 컴퓨터에 의해서 실행될 수 있는 고급 언어 코드를 포함한다. 상기된 하드웨어 장치는 실시예의 동작을 수행하기 위해 하나 이상의 소프트웨어 모듈로서 작동하도 록 구성될 수 있으며, 그 역도 마찬가지이다. 이상과 같이 실시 예들이 비록 한정된 실시 예와 도면에 의해 설명되었으나, 해당 기술 분야에서 통상의 지식을 가진 자라면 상기의 기재로부터 다양한 수정 및 변형이 가능하다. 예를 들어, 설명된 기술들이 설명된 방법과 다른 순서로 수행되거나, 및/또는 설명된 시스템, 구조, 장치, 회로 등의 구성요소들이 설명된 방법과 다른 형 태로 결합 또는 조합되거나, 다른 구성요소 또는 균등물에 의하여 대치되거나 치환되더라도 적절한 결과가 달성 될 수 있다. 그러므로, 다른 구현들, 다른 실시 예들 및 특허청구범위와 균등한 것들도 후술하는 특허청구범위 의 범위에 속한다.도면 도면1 도면2 도면3 도면4 도면5 도면6 도면7"}
{"patent_id": "10-2022-0184103", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일 실시 예에 따른 자연어 대화 인터페이스 시스템을 위한 회피형 발화 처리 방법을 설명하기 위한 순서도이다. 도 2는 본 발명의 일 실시 예에 따른 자연어 대화 인터페이스 시스템을 위한 회피형 발화 처리 장치의 구문 타 입 판단부를 설명하기 위한 블록도이다. 도 3은 본 발명의 일 실시 예에 따른 자연어 대화 인터페이스 시스템을 위한 회피형 발화 처리 방법의 의미 정보 확인 단계를 설명하기 위한 순서도이다. 도 4는 본 발명의 일 실시 예에 따른 자연어 대화 인터페이스 시스템을 위한 회피형 발화 처리 방법의 의미 정 보 확인 단계를 설명하기 위한 순서도이다. 도 5는 본 발명의 일 실시 예에 따른 자연어 대화 인터페이스 시스템을 위한 회피형 발화 처리 방법의 회피형 발화 출력 단계를 설명하기 위한 순서도이다. 도 6은 본 발명의 일 실시 예에 따른 자연어 대화 인터페이스 시스템을 위한 회피형 발화 처리 장치의 회피형 발화 출력부를 설명하기 위한 블록도이다. 도 7는 본 발명의 일 실시 예에 따른 컴퓨팅 장치의 내부 구성의 일 예를 설명하기 위한 도면이다."}
