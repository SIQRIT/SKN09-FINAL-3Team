{"patent_id": "10-2022-0007367", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0111468", "출원번호": "10-2022-0007367", "발명의 명칭": "기계학습을 이용한 흉터 조직 영역 검출을 위한 장치 및 방법", "출원인": "부경대학교 산학협력단", "발명자": "이명기"}}
{"patent_id": "10-2022-0007367", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "데이터 학습을 위한 검출 영역을 지정하는 검출 영역 지정부;검출 영역 지정부의 지정에 따른 검출 영역 정보를 이용하여 Mask R-CNN 모델을 이용하여 데이터 학습을 하는데이터 학습부;테스트를 진행하여 정확도를 산출하고, 표준 편차를 계산하여 모델을 평가하고 정확도가 높은 모델을 선정하는모델 평가 및 선정부;모델 평가 및 선정부를 통하여 선정된 모델을 이용하여 새로운 데이터가 모델에 적용되었을 때 흉터 조직을 일반 조직과 구분하여 자동으로 인식하는 조직 구분부;픽셀 단위로 판단하는 Mask R-CNN의 특성을 이용하여 검출된 픽셀의 수로 흉터 영역의 넓이를 예측하는 영역 면적 예측부;를 포함하는 것을 특징으로 하는 기계학습을 이용한 흉터 조직 영역 검출을 위한 장치."}
{"patent_id": "10-2022-0007367", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1 항에 있어서, 데이터 학습은 'MMDetection' 플랫폼을 사용하고,디지털 병리학 이미지 추론을 위한 모델(Mask R-CNN)과 Backborn(ResNet)을 선정하여 학습을 시키고, 학습을 진행하며 하이퍼파라미터를 조정하는 것을 특징으로 하는 기계학습을 이용한 흉터 조직 영역 검출을 위한 장치."}
{"patent_id": "10-2022-0007367", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 2 항에 있어서, 하이퍼파라미터는 Optimizer, Learning rate, Epoch, Batch size 항목을 포함하는 것을 특징으로 하는 기계학습을 이용한 흉터 조직 영역 검출을 위한 장치."}
{"patent_id": "10-2022-0007367", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 1 항에 있어서, 영역 면적 예측부에서 검출된 픽셀의 수로 흉터 영역의 넓이를 예측하고,분석할 이미지를 선택하여 Threshold 및 이미지 저장 여부 선택을 하고 결과는 CSV 파일로 저장하는 것을 특징으로 하는 기계학습을 이용한 흉터 조직 영역 검출을 위한 장치."}
{"patent_id": "10-2022-0007367", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제 4 항에 있어서, 흉터 조직 영역 검출 결과를 이미지로 저장하여 시각적으로 확인하거나,정답 Mask와 인공지능에 의해 검출된 Mask를 비교 분석하고, 픽셀 수를 추출하여 수치적으로 확인할 수 있도록하는 것을 특징으로 하는 기계학습을 이용한 흉터 조직 영역 검출을 위한 장치."}
{"patent_id": "10-2022-0007367", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제 1 항에 있어서, 모델 평가 및 선정부는 정확도가 높은 모델을 선정하기 위한 평가 지표로 정밀도, 리콜, 손실, 정확도 및 신뢰도 점수 항목을 포함하는 것을 특징으로 하는 기계학습을 이용한 흉터 조직 영역 검출을 위한 장치."}
{"patent_id": "10-2022-0007367", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제 1 항에 있어서, 조직 구분부에서 정상 조직과 흉터 조직의 형태를 구별하기 위하여 K-평균 클러스터링을 사용하여 조직 분할을 하고,각 조직 이미지에서 각 색상 포인트를 클러스터링한 다음 각 이미지에서 콜라겐, 모낭(HF), 분비샘(G), 핵(N)특징을 분할하기 위해 배치되는 것을 특징으로 하는 기계학습을 이용한 흉터 조직 영역 검출을 위한 장치.공개특허 10-2023-0111468-3-청구항 8 제 7 항에 있어서, 흉터 조직의 형태를 구별하기 위하여 조직 색 공간 변환을 하고,색 공간 변환 후, K-평균 클러스터링 알고리즘으로 조직 이미지에서 각 데이터 포인트를 콜라겐 영역(collagenarea), 전경(foreground) 및 배경(background)의 세 그룹으로 분리하고 라벨을 지정하는 것을 특징으로 하는 기계학습을 이용한 흉터 조직 영역 검출을 위한 장치."}
{"patent_id": "10-2022-0007367", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제 8 항에 있어서, 콜라겐 영역 분할이 콜라겐 농도 맵을 생성하기 위한 특징으로 선택되고,콜라겐 마스크는 콜라겐 포지티브 픽셀을 마스킹하고 통기성의 디스크 커널로 컨볼루션을 통해 섬유 밀도(fiberdensity)(m) 맵을 생성하고, 벡터 합계는 섬유 방향을 계산하기 위해 적용되는 것을 특징으로 하는 기계학습을이용한 흉터 조직 영역 검출을 위한 장치."}
{"patent_id": "10-2022-0007367", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제 9 항에 있어서, 이미지 내의 각 픽셀을 둘러싼 다른 방향에 따라 이미지 강도의 가변성을 식별함으로써 섬유방향을 정의하고, 중심 픽셀을 통과하는 모든 포지티브의 픽셀과 이러한 방향 벡터와 관련된 엔젤(angels)이 계산되고, 방향의 X와 Y 성분을 획득한 후, 공기성 디스크 커널을 이용한 공간 컨볼루션은 벡터 합계를 얻기 위해 사용되고 결과방향의 크기(R)를 만드는 것을 특징으로 하는 기계학습을 이용한 흉터 조직 영역 검출을 위한 장치."}
{"patent_id": "10-2022-0007367", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제 10 항에 있어서, 콜라겐의 방향분산을 얻기 위한 정규화는,으로 정의되고,여기서, V,R 및 m은 방향 분산, 결과 방향의 크기 및 콜라겐 밀도 맵인 것을 특징으로 하는 기계학습을 이용한흉터 조직 영역 검출을 위한 장치."}
{"patent_id": "10-2022-0007367", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "데이터 학습을 위한 검출 영역을 지정하는 검출 영역 지정 단계;검출 영역 지정 단계의 지정에 따른 검출 영역 정보를 이용하여 Mask R-CNN 모델을 이용하여 데이터 학습을 하는 데이터 학습 단계;테스트를 진행하여 정확도를 산출하고, 표준 편차를 계산하여 모델을 평가하고 정확도가 높은 모델을 선정하는모델 평가 및 선정 단계;모델 평가 및 선정 단계를 통하여 선정된 모델을 이용하여 새로운 데이터가 모델에 적용되었을 때 흉터 조직을일반 조직과 구분하여 자동으로 인식하는 조직 구분 단계;픽셀 단위로 판단하는 Mask R-CNN의 특성을 이용하여 검출된 픽셀의 수로 흉터 영역의 넓이를 예측하는 영역 면적 예측 단계;를 포함하는 것을 특징으로 하는 기계학습을 이용한 흉터 조직 영역 검출을 위한 방법."}
{"patent_id": "10-2022-0007367", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 조직의 화상 흉터 영역을 검출 및 분석 과정에서 이미지 전처리 과정이 필요없어 분석 시간 및 분석 결과 편차를 줄일 수 있도록 한 기계학습을 이용한 흉터 조직 영역 검출을 위한 장치 및 방법에 관한 것으로, 데 이터 학습을 위한 검출 영역을 지정하는 검출 영역 지정부;검출 영역 지정부의 지정에 따른 검출 영역 정보를 이 용하여 Mask R-CNN 모델을 이용하여 데이터 학습을 하는 데이터 학습부;테스트를 진행하여 정확도를 산출하고, 표준 편차를 계산하여 모델을 평가하고 정확도가 높은 모델을 선정하는 모델 평가 및 선정부;모델 평가 및 선정 부를 통하여 선정된 모델을 이용하여 새로운 데이터가 모델에 적용되었을 때 흉터 조직을 일반 조직과 구분하여 자동으로 인식하는 조직 구분부;픽셀 단위로 판단하는 Mask R-CNN의 특성을 이용하여 검출된 픽셀의 수로 흉터 영역의 넓이를 예측하는 영역 면적 예측부;를 포함하는 것이다."}
{"patent_id": "10-2022-0007367", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 조직의 화상 흉터 영역을 검출 및 분석 기술에 관한 것으로, 구체적으로 이미지 전처리 과정이 필요 없어 분석 시간 및 분석 결과 편차를 줄일 수 있도록 한 기계학습을 이용한 흉터 조직 영역 검출을 위한 장치 및 방법에 관한 것이다."}
{"patent_id": "10-2022-0007367", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "일반적으로 피부손상은 상처, 피부염 또는 건조를 포함할 수 있다. 상처는 외부요인 혹은 내부요인으로 피부의 연속성이 깨졌거나 구조적인 결손 등이 발생한 것을 의미한다. 또한 상처는 열에 의해 피부가 손상되는 화상을 포함할 수 있다. 또한 상처는 욕창에 의한 상처를 포함할 수 있다. 피부손상의 빠른 치유를 위해서는 피부손상에 따른 치료방법 이 적용되어야 하는데, 환자가 피부손상 치료에 관한 지식이 부족하여 피부손상의 치유가 더디게 되거나, 흉터 가 남는 경우가 생기고 있다. 또한 피부손상의 경우, 피부손상에 의한 손상의 깊이의 평가 방법이 그 중요도에 비하여 많이 연구되지 않은 실 정이다. 또한 그 판단이 전문가에 의한 주관적 판단에 의존도가 높다. 게다가, 세계적으로도 피부손상 전문가가 부족한 실정이다. 피부손상 전문가에 의하지 않고 일반인이 피부손상에 의한 초기손상 깊이를 과소평가한 경우 피부손상이 악화되 는 경우가 있으며, 초기 손상의 깊이를 과대평가하였을 경우 비용 상승의 원인이 되는 경우가 있다. 최근 이미지 분석 분야에서 딥러닝이 좋은 성능을 보이고 있다. 피부손상과 관련된 영상 및 피부손상과 관련된 정보를 이용하여 기계학습을 통해 피부손상의 심각성을 결정할 수 있는 모델이 만들어질 수 있다. 이러한 기계학습 모델은 피부의 손상의 심각성을 초기에 비교적 정확하게 판단할 수 있다. 또한, 환자가 불필요 한 비용을 지출하거나, 환자의 피부손상이 악화되는 상황을 방지할 수 있다. 종래 기술의 조직의 흉터를 분석하기 위한 방법은 대부분 'Image J' 등의 소프트웨어를 이용한 방법이다. 이 방법은 연구자가 직접 WSI(whole Slide Image)의 흉터 영역을 Crop하여 8-bit 이미지로 변환, pixel 수(또 는 비율)로 영역의 넓이를 검출하는 형식이다. 다만 이 방법은 연구자마다 기준이 달라 실제 영역과의 편차가 심하고 crop, 영역지정 등 복잡한 검출 프로그램 사용법 숙지를 요구하며 시간이 많이 걸린다. 따라서, 분석 시간 및 분석 결과 편차를 줄일 수 있도록 하여 신속하고 정확한 조직의 화상 흉터 영역을 검출 및 분석에 관한 새로운 기술의 개발이 요구되고 있다. 선행기술문헌 특허문헌 (특허문헌 0001) 대한민국 등록특허 제10-2192953호 (특허문헌 0002) 대한민국 공개특허 제10-2021-0002184호 (특허문헌 0003) 대한민국 공개특허 제10-2021-0101285호"}
{"patent_id": "10-2022-0007367", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 종래 기술의 조직의 화상 흉터 영역을 검출 및 분석 기술의 문제점을 해결하기 위한 것으로, 이미지 전처리 과정이 필요 없어 분석 시간 및 분석 결과 편차를 줄일 수 있도록 한 기계학습을 이용한 흉터 조직 영역 검출을 위한 장치 및 방법을 제공하는데 그 목적이 있다. 본 발명은 데이터 학습을 위해 검출할 영역에 대한 정보를 얻기 위하여, 'Labelme' 등의 annotation 프로그램을 사용하여 검출할 영역을 지정하여 획득된 학습 데이터에 필요한 정보를 토대로 모델이 학습되어 새로운 데이터 를 분석하여 정확도를 높인 기계학습을 이용한 흉터 조직 영역 검출을 위한 장치 및 방법을 제공하는데 그 목적 이 있다. 본 발명은 학습 후 테스트용 데이터로 테스트를 진행하여 직접 annotation한 정답과 결과를 비교하여 정확도를 산출하고, 표준 편차 등을 계산하여 모델을 평가하여 정확도가 높은 모델을 선정하여 사용하는 것에 의해, 흉터조직을 일반 조직과 구분하여 자동으로 인식하고 영역의 넓이를 산출할 수 있도록 한 기계학습을 이용한 흉터 조직 영역 검출을 위한 장치 및 방법을 제공하는데 그 목적이 있다. 본 발명은 Pixel 단위로 판단하는 Mask R-CNN의 특성을 활용하여 검출된 Pixel의 수로 흉터 영역의 넓이를 예측 할 수 있도록 하고, 학습된 모델을 선택하여 사용 가능하고, 분석할 이미지를 선택하고, Threshold 및 이미지 저장 여부 선택이 가능하도록 한 기계학습을 이용한 흉터 조직 영역 검출을 위한 장치 및 방법을 제공하는데 그 목적이 있다. 본 발명은 흉터 조직 영역 검출 결과를 CSV파일로 저장하고, 모든 분석과정을 자동으로 진행되도록 하여 빠른 시간 내에 디지털 병리학 및 이미지 분석에 적용될 수 있도록 한 기계학습을 이용한 흉터 조직 영역 검출을 위 한 장치 및 방법을 제공하는데 그 목적이 있다. 본 발명은 학습된 모델을 이용하여 새로운 데이터셋을 다른 과정 없이 분석하는 것이 가능하도록 하여 정확성, 속도 및 단순성 측면에서 유리하고, Crop과 같은 이미지 전처리 과정이 필요 없어 분석 시간이 현저히 줄어들고, 분석 결과에 영향을 주는 요소를 줄여 분석 결과 편차를 효과적으로 줄일 수 있도록 한 기계학습을 이용한 흉터 조직 영역 검출을 위한 장치 및 방법을 제공하는데 그 목적이 있다. 본 발명은 분석 결과를 이미지로 저장하여 시각적으로 확인하거나 사람이 Annotation 한 정답 Mask와 인공지능 에 의해 검출된 Mask를 비교 분석할 수 있고, Pixel 수를 추출하여 수치적으로 확인할 수 있도록 하여 디지털 병리학 이미지 분석 결과의 품질을 높일 수 있도록 한 기계학습을 이용한 흉터 조직 영역 검출을 위한 장치 및 방법을 제공하는데 그 목적이 있다. 본 발명의 다른 목적들은 이상에서 언급한 목적으로 제한되지 않으며, 언급되지 않은 또 다른 목적들은 아래의 기재로부터 당업자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2022-0007367", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기와 같은 목적을 달성하기 위한 본 발명에 따른 기계학습을 이용한 흉터 조직 영역 검출을 위한 장치는 데이 터 학습을 위한 검출 영역을 지정하는 검출 영역 지정부;검출 영역 지정부의 지정에 따른 검출 영역 정보를 이 용하여 Mask R-CNN 모델을 이용하여 데이터 학습을 하는 데이터 학습부;테스트를 진행하여 정확도를 산출하고, 표준 편차를 계산하여 모델을 평가하고 정확도가 높은 모델을 선정하는 모델 평가 및 선정부;모델 평가 및 선정 부를 통하여 선정된 모델을 이용하여 새로운 데이터가 모델에 적용되었을 때 흉터 조직을 일반 조직과 구분하여 자동으로 인식하는 조직 구분부;픽셀 단위로 판단하는 Mask R-CNN의 특성을 이용하여 검출된 픽셀의 수로 흉터 영역의 넓이를 예측하는 영역 면적 예측부;를 포함하는 것을 특징으로 한다. 다른 목적을 달성하기 위한 본 발명에 따른 기계학습을 이용한 흉터 조직 영역 검출을 위한 방법은 데이터 학습 을 위한 검출 영역을 지정하는 검출 영역 지정 단계;검출 영역 지정 단계의 지정에 따른 검출 영역 정보를 이용 하여 Mask R-CNN 모델을 이용하여 데이터 학습을 하는 데이터 학습 단계;테스트를 진행하여 정확도를 산출하고, 표준 편차를 계산하여 모델을 평가하고 정확도가 높은 모델을 선정하는 모델 평가 및 선정 단계;모델 평가 및 선정 단계를 통하여 선정된 모델을 이용하여 새로운 데이터가 모델에 적용되었을 때 흉터 조직을 일반 조직과 구분하여 자동으로 인식하는 조직 구분 단계;픽셀 단위로 판단하는 Mask R-CNN의 특성을 이용하여 검출된 픽셀 의 수로 흉터 영역의 넓이를 예측하는 영역 면적 예측 단계;를 포함하는 것을 특징으로 한다."}
{"patent_id": "10-2022-0007367", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "이상에서 설명한 바와 같은 본 발명에 따른 기계학습을 이용한 흉터 조직 영역 검출을 위한 장치 및 방법은 다 음과 같은 효과가 있다. 첫째, 흉터 조직 영역 검출 및 분석 과정에서 이미지 전처리 과정이 필요 없어 분석 시간 및 분석 결과 편차를 줄일 수 있도록 한다. 둘째, 데이터 학습을 위해 검출할 영역에 대한 정보를 얻기 위하여, 'Labelme' 등의 annotation 프로그램을 사 용하여 검출할 영역을 지정하여 획득된 학습 데이터에 필요한 정보를 토대로 모델이 학습되어 새로운 데이터를 분석하여 정확도를 높인다. 셋째, 학습 후 테스트용 데이터로 테스트를 진행하여 직접 annotation한 정답과 결과를 비교하여 정확도를 산출 하고, 표준 편차 등을 계산하여 모델을 평가하여 정확도가 높은 모델을 선정하여 사용하는 것에 의해, 흉터 조직을 일반 조직과 구분하여 자동으로 인식하고 영역의 넓이를 산출할 수 있도록 한다. 넷째, Pixel 단위로 판단하는 Mask R-CNN의 특성을 활용하여 검출된 Pixel의 수로 흉터 영역의 넓이를 예측할 수 있도록 하고, 학습된 모델을 선택하여 사용 가능하고, 분석할 이미지를 선택하고, Threshold 및 이미지 저장 여부 선택이 가능하도록 한다. 다섯째, 흉터 조직 영역 검출 결과를 CSV파일로 저장하고, 모든 분석과정을 자동으로 진행되도록 하여 빠른 시 간 내에 디지털 병리학 및 이미지 분석에 적용될 수 있도록 한다. 여섯째, 학습된 모델을 이용하여 새로운 데이터셋을 다른 과정 없이 분석하는 것이 가능하도록 하여 정확성, 속 도 및 단순성 측면에서 유리하고, Crop과 같은 이미지 전처리 과정이 필요 없어 분석 시간이 현저히 줄어들고, 분석 결과에 영향을 주는 요소를 줄여 분석 결과 편차를 효과적으로 줄일 수 있도록 한다. 일곱째, 분석 결과를 이미지로 저장하여 시각적으로 확인하거나 사람이 Annotation 한 정답 Mask와 인공지능에 의해 검출된 Mask를 비교 분석할 수 있고, Pixel 수를 추출하여 수치적으로 확인할 수 있도록 하여 디지털 병리 학 이미지 분석 결과의 품질을 높일 수 있도록 한다."}
{"patent_id": "10-2022-0007367", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 본 발명에 따른 기계학습을 이용한 흉터 조직 영역 검출을 위한 장치 및 방법의 바람직한 실시 예에 관하 여 상세히 설명하면 다음과 같다. 본 발명에 따른 기계학습을 이용한 흉터 조직 영역 검출을 위한 장치 및 방법의 특징 및 이점들은 이하에서의 각 실시 예에 대한 상세한 설명을 통해 명백해질 것이다. 도 1은 흉터 조직의 조직 분석을 위한 수동 검출과 기계 학습 사이의 계통 비교 구성도이고, 도 2는 정상 조직 (왼쪽)과 흉터 조직(오른쪽)의 H&E로 염색된 피부 조직의 형태학적 구성도이다. 도 1에서와 같이, 기계학습을 이용한 흉터 조직 영역 검출은 학습된 모델을 이용하여 새로운 데이터셋을 다른 과정 없이 분석하는 것이 가능하도록 하여 정확성, 속도 및 단순성 측면에서 유리하고, Crop과 같은 이미지 전 처리 과정이 필요없어 분석 시간이 현저히 줄어들고, 분석 결과에 영향을 주는 요소를 줄여 분석 결과 편차를 효과적으로 줄일 수 있도록 한다. 도 2에서 정상 조직(왼쪽)은 모낭(HF), 분비선(G), 핵(N)을 보여주는 반면, 흉터 조직(오른쪽)은 HF와 G의 부재 를 나타낸다(스케일 바 = 100㎛; 10X). 이와 같은 본 발명에 따른 기계학습을 이용한 흉터 조직 영역 검출을 위한 장치 및 방법은 흉터 조직 영역 검출 및 분석 과정에서 이미지 전처리 과정이 필요 없어 분석 시간 및 분석 결과 편차를 줄일 수 있도록 한 것이다. 이를 위하여 본 발명은 데이터 학습을 위해 검출할 영역에 대한 정보를 얻기 위하여, 'Labelme' 등의 annotation 프로그램을 사용하여 검출할 영역을 지정하여 획득된 학습 데이터에 필요한 정보를 토대로 모델이 학습되어 새로운 데이터를 분석하는 구성을 포함할 수 있다. 본 발명은 학습 후 테스트용 데이터로 테스트를 진행하여 직접 annotation한 정답과 결과를 비교하여 정확도를 산출하고, 표준 편차 등을 계산하여 모델을 평가하여 정확도가 높은 모델을 선정하여 사용하는 것에 의해, 흉터 조직을 일반 조직과 구분하여 자동으로 인식하고 영역의 넓이를 산출할 수 있도록 하는 구성을 포함할 수 있다. 도 3은 조직학 슬라이드에서 흉터 식별을 위한 Mask RCNN 알고리즘의 블록 다이어그램(FM = 피쳐 맵, RPN = 지 역 제안 네트워크, FCN = 완전 연결 네트워크, FC 계층 = 완전 연결 계층)이다. 기계학습(machine learning)과 합성곱 신경망(convolution neural network)을 이용한 이미지 분석, 조직학 및 디지털 병리학 이미지 분석의 기본 개념은 도 3에서와 같다. 데이터 학습은 'MMDetection' 플랫폼을 사용하는데, 이 플랫폼은 Hyperparameter를 조정하기에 쉽고 모델 추론 을 위한 여러 툴을 제공한다. 디지털 병리학 이미지 추론에 알맞은 모델(Mask R-CNN)과 Backborn(ResNet)을 선정하여 학습을 시키고, 학습을 진행하며 Hyperparameter를 조정하여 fine-tuning을 진행한다. 도 4는 본 발명에 따른 기계학습을 이용한 흉터 조직 영역 검출을 위한 장치의 구성도이다. 본 발명에 따른 기계학습을 이용한 흉터 조직 영역 검출을 위한 장치는 데이터 학습을 위해 검출할 영역에 대한 정보를 얻기 위하여 annotation 프로그램을 사용하여 검출할 영역을 지정하는 검출 영역 지정부와, 검출 영 역 지정부의 지정에 따른 검출 영역 정보를 이용하여 사물검출(Object detection) 기술에 픽셀 단위로 물체 를 판단하는 Instantce Segmentation 기법을 함께하는 Mask R-CNN 모델을 이용하여 데이터 학습을 하는 데이터 학습부와, 테스트용 데이터로 테스트를 진행하여 직접 annotation한 정답과 결과를 비교하여 정확도를 산출 하고, 표준 편차 등을 계산하여 모델을 평가하고 정확도가 높은 모델을 선정하는 모델 평가 및 선정부와, 모델 평가 및 선정부를 통하여 선정된 모델을 이용하여 새로운 데이터가 모델에 적용되었을 때 흉터 조직을 일반 조직과 구분하여 자동으로 인식하는 조직 구분부와, Pixel 단위로 판단하는 Mask R-CNN의 특성을 활용 하여 검출된 Pixel의 수로 흉터 영역의 넓이를 예측하는 영역 면적 예측부를 포함한다. 이와 같은 구성을 갖는 본 발명에 따른 기계학습을 이용한 흉터 조직 영역 검출을 위한 장치는 학습 후 테스트 용 데이터로 테스트를 진행하여 직접 annotation한 정답과 결과를 비교하여 정확도를 산출하고, 표준 편차 등을 계산하여 모델을 평가하고 정확도가 높은 모델을 선정하여 선정된 모델을 이용하여 새로운 데이터가 모델에 적 용되었을 때 흉터 조직을 일반 조직과 구분하여 자동으로 인식하고 영역의 넓이를 산출할 수 있도록 하는 것이다. 여기서, Pixel 단위로 판단하는 Mask R-CNN의 특성을 활용하여 검출된 Pixel의 수로 흉터 영역의 넓이를 예측하 고, 분석할 이미지를 선택하고, Threshold 및 이미지 저장 여부 선택을 하고 결과는 CSV 파일로 저장하는 것이다. 특히, 흉터 조직 영역 검출 결과를 CSV파일로 저장하고, 모든 분석과정을 자동으로 진행되도록 하여 빠른 시간 내에 디지털 병리학 및 이미지 분석에 적용될 수 있도록 하고, 분석 결과를 이미지로 저장하여 시각적으로 확인 하거나 사람이 Annotation 한 정답 Mask와 인공지능에 의해 검출된 Mask를 비교 분석할 수 있고, Pixel 수를 추 출하여 수치적으로 확인할 수 있도록 하여 디지털 병리학 이미지 분석 결과의 품질을 높일 수 있도록 한다. 본 발명에 따른 기계학습을 이용한 흉터 조직 영역 검출을 위한 방법을 구체적으로 설명하면 다음과 같다. 도 5는 본 발명에 따른 기계학습을 이용한 흉터 조직 영역 검출을 위한 방법을 나타낸 플로우 차트이다. 본 발명에 따른 기계학습을 이용한 흉터 조직 영역 검출을 위한 방법은 도 5에서와 같이, 데이터 학습을 위해 검출할 영역에 대한 정보를 얻기 위하여 annotation 프로그램을 사용하여 검출할 영역을 지정하는 검출 영역 지 정 단계(S501)와, 검출 영역 지정 단계의 지정에 따른 검출 영역 정보를 이용하여 사물검출(Object detection) 기술에 픽셀 단위로 물체를 판단하는 Instantce Segmentation 기법을 함께하는 Mask R-CNN 모델을 이용하여 데 이터 학습을 하는 데이터 학습 단계(S502)와, 테스트용 데이터로 테스트를 진행하여 직접 annotation한 정답과 결과를 비교하여 정확도를 산출하고, 표준 편차 등을 계산하여 모델을 평가하고 정확도가 높은 모델을 선정하는 모델 평가 및 선정 단계(S503)와, 모델 평가 및 선정 단계를 통하여 선정된 모델을 이용하여 새로운 데이터가 모델에 적용되었을 때 흉터 조직을 일반 조직과 구분하여 자동으로 인식하는 조직 구분 단계(S504)와, Pixel 단위로 판단하는 Mask R-CNN의 특성을 활용하여 검출된 Pixel의 수로 흉터 영역의 넓이를 예측하는 영역 면적 예 측 단계(S505)를 포함한다. 본 발명의 실시 예로서, 본 발명이 기술한 방법을 H&E 염색된 WSI tissue의 화상으로 인한 흉터(scar) 영역을 검출해내고 Pixel 수를 계산하는데 적용하였다. 총 239장의 학습 데이터를 Mask R-CNN모델로 표 1에서와 같은 하이퍼 파라미터와 함께 학습시켰을 경우 최적의 결과를 보여준다. 표 1"}
{"patent_id": "10-2022-0007367", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "평가 지표는 정밀도, 리콜, 손실, 정확도 및 신뢰도 점수를 얻기 위해 MMDtection 도구를 기반으로 수행된다. Mask RCNN의 다중 작업 손실 함수(L)는 수학식 1에서와 같이 분류 손실(Lcls), 국소화(Lbox) 및 분할 마스크 (Lmask)의 결합으로 정의된다. 수학식 1"}
{"patent_id": "10-2022-0007367", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "분류 및 국소화를 위한 손실 함수(Lcls+box)는 수학식 2에서 정의된다. 수학식 2"}
{"patent_id": "10-2022-0007367", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "여기서, i는 미니 배치(mini-batch)에서 앵커(anchor)의 지수이고, 는 예측 확률(predicted probability) 및 그라운드 진리 라벨(ground-truth label), 는 양의 앵커와 관련된 4개의 좌표와 그라운 드 진리 박스를 나타내는 벡터이며, 는 정규화를 위한 균형 매개 변수이다. 모델의 손실 함수는 각 클래스에 대한 마스크 학습을 시도했지만, 마스크 생성을 위한 클래스 간에 경쟁이 발생 하지 않았다. 마스크 손실은 다음과 같은 식에 의해 평균 이진 교차 엔트로피 손실(average binary cross-entropy loss)로 정의된다.수학식 3"}
{"patent_id": "10-2022-0007367", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "여기서, 는 크기가 m*m 인 실제 마스크에 있는 셀(i,j)의 라벨이며, 는 실제 진리 클래스 k에 대해 학 습된 마스크에 있는 동일한 셀의 예측값이다. 신뢰도 점수를 얻는 것 외에도, 소프트맥스 분류기 는 소프트맥스 계산의 점수 형식을 확률로 변환했다. 모든 평가 지표는 MMDetection 도구에 의해 수행되었고 흉터 검출 AI 모델에 적용되었다. 흉터 검출 성능에 관하여 설명하면 다음과 같다. 흉터 마스크 예측의 성능을 평가하기 위해 흉터 면적 측정을 종래 기술의 방법과 기계 학습 간에 비교했다. 종래 기술의 방법에서는 WSI를 자르고 흉터가 없는 영역을 선택적으로 제거했다. 그런 다음 이미지 J(National Institute of Health, Bethsda, MD)를 사용하여 흉터 픽셀 값을 구함으로써 흉터 부위를 추정했다. 본 발명에서는 마스크 예측을 위한 흉터 측정은 각 백본에 대해 제안된 모델을 통해 자동으로 계산된다. 종래 기술의 방법과 본 발명에 따른 방법 사이의 통계적 유의성을 결정하기 위해 ANOVA를 이용한 통계적 분석을 수행하였다. 도 6은 콜라겐 밀도 추출기의 블록 다이어그램으로, (a) K-평균 군집화, (b) 콜라겐 밀도 추출기 및 (c) 콜라겐 의 방향 분산을 나타낸 것이다. 조직 분할을 위한 K-평균 군집 분석에 관하여 설명하면 다음과 같다. HE로 염색된 조직 이미지는 정상 조직과 흉터 조직의 형태를 구별하고 명확히 하기 위해 분할되었다. K-평균 클 러스터링을 사용한 조직 분할은 각 조직 이미지에서 각 색상 포인트를 클러스터링한 다음 각 이미지에서 콜라겐, 모낭(HF), 분비샘(G), 핵(N)과 같은 주요 특징을 분할하기 위해 배치되었다. 일 실시 예에서 ROI 입력은 다양한 886*1614, 750*500, 500*500, 250*250 픽셀 크기로 테스트된다. 도 6은 흉터 특성화의 전체 과정을 설명하기 위한 것이다. 첫 번째 단계는 조직 색 공간의 변형이다. ROI 입력이 색차 및 휘도 면에서 불안정한 RGB 색 공간을 가지고 있기 때문에 CIE L*a*b 색 공간은 RGB 색 공간 에서 CIE L*a*B로 변환하여 안정적인 색 공간으로 가져온다. 모든 색상 정보는 'a*' 및 'b*' 레이어에 있으며 L을 수행하여 이미지의 밝기와 어두움을 조절한다. 색 공간 변환 후, (a)K-평균 클러스터링 알고리즘은 조직 이미지에서 각 데이터 포인트를 콜라겐 영역(collagen area), 전경(foreground) 및 배경(background)의 세 그룹으로 분리한다. 이러한 그룹은 알고리즘에 의해 숫자(0, 1, 2)로 라벨이 지정된다. 이 알고리즘은 각 성단과 세 중심부 사이의 거리를 하나씩 측정한다. 그런 다음 알고리즘은 데이터 점을 가장 가까운 중심점으로 그룹화한다. 그룹화 후, K-평균 클러스터링 알고리즘은 콜라겐 영역 분할, 전경 분할 및 배경 분할을 제공한다. 콜라겐 밀도 및 콜라겐 방향 변화에 관하여 설명하면 다음과 같다. (b)K-평균 군집화의 특징인 콜라겐 영역 분할이 콜라겐 농도 맵을 생성하기 위한 특징으로 선택된다. 콜라겐 마스크는 콜라겐 포지티브 픽셀을 마스킹하고 통기성이 좋은 디스크 커널로 컨볼루션을 통해 섬유 밀도 (fiber density)(m) 맵을 생성한다. 또한, 벡터 합계는 섬유 방향을 계산하기 위해 적용된다. 본 발명에 따른 방법에서 이미지 내의 각 픽셀을 둘러싼 다른 방향에 따라 이미지 강도의 가변성을 식별함으로 써 섬유 방향을 정의한다. 중심 픽셀을 통과하는 모든 포지티브의 픽셀과 이러한 방향 벡터와 관련된 엔젤(angels)이 계산된다. 방향의 X와 Y 성분을 획득한 후, 공기성 디스크 커널을 이용한 공간 컨볼루션은 벡터 합계를 얻기 위해 사용되 었고 결과 방향의 크기(R)를 만든다. 마지막으로 콜라겐의 방향분산을 얻기 위한 정규화는 다음과 같다. 수학식 4"}
{"patent_id": "10-2022-0007367", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "여기서, V,R 및 m은 방향 분산, 결과 방향의 크기 및 콜라겐 밀도 맵이다. 도 7은 다양한 백본을 사용한 Mask RCNN으로 흉터 식별하는 것을 나타낸 구성도이다. (a) 노란색 흉터 마스크가 있는 전체 슬라이드 이미지이고, (b) 흉터 영역의 확대 이미지, (c) 기존 방법과 기 계 학습 방법 사이의 측정된 흉터 영역(픽셀 수)의 통계적 비교를 나타낸 것이다. (a)(b)의 파란색과 노란색 박스는 각각 주석이 달린 답변(파란색)과 예측된 흉터 영역(노란색)을 나타낸다. 총 4가지 종류의 Backborn으로 학습시켜 흉터 조직 영상 데이터에 최적인 모델을 찾았다. 학습에 사용되지 않은 79장의 새로운 조직 영상 데이터에 대해 테스트를 수행하였으며 모델의 성능을 평가하는 기준인 mAP(mean average precision), mAR(mean average recall) 값과 이미지 한 장 분석에 걸린 평균 시간은 표 2에서와 같다. 표 2"}
{"patent_id": "10-2022-0007367", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "item": 7, "content": "도 8은 전체 조직학 슬라이드 영상의 조직 특성을 나타낸 구성도이다. (a) HE 염색 조직(더미 영역), (b) 해당 콜라겐 밀도 맵 및 (c) 방향 분산 맵이고, 노란색 점선은 해당하는 흉 터 영역을 나타낸다. 도 9는 K-평균 군집화를 통한 색상 분할을 통한 조직 분석 특성을 나타낸 구성도이다. (a) 원본 데이터 세트(HE 염색 조직), (b) 전경 분할(FS; 모낭, 분비선 및 핵), (c) 콜라겐 영역 분할(CAS), (d) 콜라겐 밀도 지도(CDM), (e) FS, CAS, CDM의 통계 비교이다. 도 10은 서로 다른 영상 크기의 일반(왼쪽) 및 흉터 조직(오른쪽) 간의 ROI 영상 비교 구성도이다. (a) HE 염색 조직(정상인 경우 a1-a3 및 흉터의 경우 a4-a6), (b) 전경 분할(b1-b6), (c) 콜라겐 영역 분할 (c1-c6), (d) 콜라겐 밀도 맵(d1-d6) 및 (e) 방향 분산 맵(e1-e6)이다. 도 11은 정상 조직과 흉터 조직의 통계적 비교 그래프이다. (a) 전경 분할, (b) 콜라겐 영역 분할, (c) 콜라겐 농도 맵 및 (d) 콜라겐의 방향 분산을 나타낸 것이다. 학습된 모델은 평가 데이터에 대해 높은 정확성을 보였고, 분석 속도도 사람이 하는 것과 비교해 아주 빨랐다. 결과를 이미지로 저장하여 시각적으로 확인하거나 사람이 Annotation 한 정답 Mask 와 인공지능에 의해 검출된 Mask를 비교 분석할 수 있고, 표 3에서와 같이 Pixel 수를 추출하여 수치적으로 확인할 수 있다. 표 3은 정답 Mask Pixel 수와 인공지능으로 검출된 Mask Pixel 수의 비교 결과를 나타낸 것으로, 실제로 이전에 사용하던 방법과 비교 하였을 때, 더 높은 정확도와 빠른 속도를 보였다. 표 3"}
{"patent_id": "10-2022-0007367", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 8, "content": "이상에서 설명한 본 발명에 따른 기계학습을 이용한 흉터 조직 영역 검출을 위한 장치 및 방법은 학습 후 테스 트용 데이터로 테스트를 진행하여 직접 annotation한 정답과 결과를 비교하여 정확도를 산출하고, 표준 편차 등 을 계산하여 모델을 평가하고 정확도가 높은 모델을 선정하여 선정된 모델을 이용하여 새로운 데이터가 모델에 적용되었을 때 흉터 조직을 일반 조직과 구분하여 자동으로 인식하고 영역의 넓이를 산출할 수 있도록 한 것이다. 이상에서의 설명에서와 같이 본 발명의 본질적인 특성에서 벗어나지 않는 범위에서 변형된 형태로 본 발명이 구 현되어 있음을 이해할 수 있을 것이다. 그러므로 명시된 실시 예들은 한정적인 관점이 아니라 설명적인 관점에서 고려되어야 하고, 본 발명의 범위는 전술한 설명이 아니라 특허청구 범위에 나타나 있으며, 그와 동등한 범위 내에 있는 모든 차이점은 본 발명에 포함된 것으로 해석되어야 할 것이다."}
{"patent_id": "10-2022-0007367", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 흉터 조직의 조직 분석을 위한 수동 검출과 기계 학습 사이의 계통 비교 구성도 도 2는 정상 조직(왼쪽)과 흉터 조직(오른쪽)의 H&E로 염색된 피부 조직의 형태학적 구성도 도 3은 조직학 슬라이드에서 흉터 식별을 위한 Mask RCNN 알고리즘의 블록 다이어그램 도 4는 본 발명에 따른 기계학습을 이용한 흉터 조직 영역 검출을 위한 장치의 구성도 도 5는 본 발명에 따른 기계학습을 이용한 흉터 조직 영역 검출을 위한 방법을 나타낸 플로우 차트 도 6은 콜라겐 밀도 추출기의 블록 다이어그램 도 7은 다양한 백본을 사용한 Mask RCNN으로 흉터 식별하는 것을 나타낸 구성도 도 8은 전체 조직학 슬라이드 영상의 조직 특성을 나타낸 구성도 도 9는 K-평균 군집화를 통한 색상 분할을 통한 조직 분석 특성을 나타낸 구성도 도 10은 서로 다른 영상 크기의 일반(왼쪽) 및 흉터 조직(오른쪽) 간의 ROI 영상 비교 구성도 도 11은 정상 조직과 흉터 조직의 통계적 비교 그래프"}
