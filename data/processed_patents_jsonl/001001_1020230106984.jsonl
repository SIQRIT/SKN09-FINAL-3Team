{"patent_id": "10-2023-0106984", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2025-0025946", "출원번호": "10-2023-0106984", "발명의 명칭": "화자 분할을 수행하는 인공지능 모델을 학습하는 방법 및 그 장치", "출원인": "한양대학교 산학협력단", "발명자": "장준혁"}}
{"patent_id": "10-2023-0106984", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "복수의 화자들의 음성이 포함된 음성 데이터로부터 각 화자의 음성 정보를 추출하는 화자 분할(speakerdiarization)을 수행하는 인공지능 모델을 학습하는 장치에 있어서,복수의 화자들의 음성이 포함된 음성 데이터 및 화자 레이블 시퀀스 정보를 포함하는 학습 데이터를 수신하는수신부;상기 음성 데이터를 임베딩하는 임베딩부;상기 임베딩된 음성 데이터를 인코딩하는 인코딩부; 및상기 인코딩된 음성 데이터 및 화자 레이블 시퀀스 정보에 기반하여 손실을 계산하는 손실함수 계산부; 를 포함하고,상기 인코딩부는 복수 개의 인코더 블록을 포함하고, 상기 임베딩된 음성 데이터는 상기 복수의 인코더 블록들을 순차적으로 통과하면서 인코딩되는,인공지능 모델 학습 장치."}
{"patent_id": "10-2023-0106984", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 인코더 블록은 헤드(head) 정보를 포함하고, 각 인코더 블록은 서로 다른 헤드 정보를 포함하는,인공지능 모델 학습 장치."}
{"patent_id": "10-2023-0106984", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서, 상기 인공지능 모델 학습 장치는,상기 복수의 인코더 블록들 중 적어도 하나의 블록의 헤드 정보를 증류(distill)하는 증류부; 를 더 포함하는,인공지능 모델 학습 장치."}
{"patent_id": "10-2023-0106984", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서, 상기 증류부는화자 판별을 위한 특징 벡터(feature vector)를 추출하는 단계;상기 특징 벡터를 이용하여, 상기 복수의 인코더 블록들 중 적어도 하나의 인코더 블록을 추출하는 단계; 및 상기 추출한 인코더 블록의 헤드 정보를 증류하는 단계; 를 수행하는,인공지능 모델 학습 장치."}
{"patent_id": "10-2023-0106984", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서,상기 추출하는 단계는 상기 특징 벡터로부터 계산된 타겟 행렬과의 유사도를 측정함으로써 인코더 블록을 추출하고, 상기 헤드 정보를 증류하는 단계는 상기 추출된 인코더 블록과 상기 타겟 행렬로부터 도출된 증류 손실을 이용하여 증류하는,인공지능 모델 학습 장치.공개특허 10-2025-0025946-3-청구항 6 제5항에 있어서,상기 유사도는 평균 제곱 오차(mean squared error)에 기반하여 계산되는,인공지능 모델 학습 장치."}
{"patent_id": "10-2023-0106984", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제3항에 있어서, 상기 증류부는 제1 인코더 블록의 헤드 정보를 이용하여 제2 인코더 블록의 헤드 정보로 증류하는,인공지능 모델 학습 장치."}
{"patent_id": "10-2023-0106984", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서, 상기 제1 인코더 블록은 상기 제2 인코더 블록보다 상위에 위치하는,인공지능 모델 학습 장치."}
{"patent_id": "10-2023-0106984", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제7항에 있어서, 상기 증류부는 상기 제1 인코더 블록의 헤드 정보와, 상기 제1 인코더 블록이 아닌 인코더 블록들의 헤드 정보의 평균 제곱 오차를 도출함으로써, 증류 손실을 계산하는,인공지능 모델 학습 장치."}
{"patent_id": "10-2023-0106984", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "복수의 화자들의 음성이 포함된 음성 데이터로부터 각 화자의 음성 정보를 추출하는 화자 분할(speakerdiarization)을 수행하는 인공지능 모델을 학습하는 방법에 있어서,복수의 화자들의 음성이 포함된 음성 데이터 및 화자 레이블 시퀀스 정보를 포함하는 학습 데이터를 수신하는단계;상기 음성 데이터를 임베딩하는 단계;상기 임베딩된 음성 데이터를 인코딩하는 단계; 및상기 인코딩된 음성 데이터 및 화자 레이블 시퀀스 정보에 기반하여 손실을 계산하는 단계; 를 포함하고,상기 인코딩하는 단계는 복수 개의 인코더 블록을 포함하고, 상기 임베딩된 음성 데이터는 상기 복수의 인코더블록들을 순차적으로 통과하면서 인코딩되는,인공지능 모델 학습 방법."}
{"patent_id": "10-2023-0106984", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "복수의 화자들의 음성이 포함된 음성 데이터로부터 각 화자의 음성 정보를 추출하는 화자 분할(speaker diarization)을 수행하는 인공지능 모델을 학습하는 장치에 있어서, 복수의 화자들의 음성이 포함된 음성 데이터 및 화자 레이블 시퀀스 정보를 포함하는 학습 데이터를 수신하는 수신부; 상기 음성 데이터를 임베딩하는 임베딩 부; 상기 임베딩된 음성 데이터를 인코딩하는 인코딩부; 및 상기 인코딩된 음성 데이터 및 화자 레이블 시퀀스 정보에 기반하여 손실을 계산하는 손실함수 계산부; 를 포함할 수 있다."}
{"patent_id": "10-2023-0106984", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 화자 분할을 수행하는 인공지능 모델을 학습하는 시스템에 관한 것이다. 구체적으로, 복수의 화자들 의 음성이 포함된 음성 데이터로부터 각 화자의 음성 정보를 추출하는 화자 분할(speaker diarization)을 수행 하는 인공지능 모델을 학습하는 방법, 장치 및 그 시스템에 관한 것이다. 화자 분할을 수행하는 인공지능 모델 은 구체적으로, 트랜스포머의 기반의 종단간 화자 분할 시스템 개선을 위한 어텐션 헤드 자가 증류 기법을 수행 할 수 있다."}
{"patent_id": "10-2023-0106984", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "화자 분할 시스템(speaker diarization system)은 2명 이상의 복수의 화자들의 음성이 담긴 혼합 음성 데이터를 분석한다. 구체적으로, 화자 분할 시스템은 음성 테이터를 각 화자별로 분할하여 '누가 언제 말했는가'를 구분 하기 위해 사용된다. 화자 분할 기술은 비즈니스 회의나 인터뷰 등 여러 명의 화자가 대화식으로 진행하는 음성 데이터를 인식하기 위한 음성 관련 어플리케이션에 필수적이다. 이러한 화자 분할 시스템은 화자 분리를 수행하 는 과정에서 음성의 다른 구간에서 추출된 임베딩이 같은 화자인지 아닌지 비교하여 구분하는 화자 검증 (speaker verification) 시스템과도 관련이 있다. 더 나아가, 화자 분할 시스템은 화자 분리를 수행 후 분할된 음성을 기반으로 문자로 기록하기 위한 음성인식에 도 도움을 줄 수 있다. 화자 분할 시스템은 여러 발화자들의 목소리를 구별하여 화자 분리를 수행함으로써 섞인 음성 구간에 대한 음성 인식 기술의 성능 향상에도 기여할 수 있는 기술이다. 이와 관련된 배경 기술로는, “End-to-end neural speaker diarization with self-attention,\" IEEE Automatic Speech Recognition and Understanding Workshop 2019에서 제안된 SA-EEND 시스템이 있다."}
{"patent_id": "10-2023-0106984", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "상기와 같은 문제점을 해결하기 위한 본 발명의 목적은, 화자 분할을 수행하는 인공지능 모델을 학습하는 방법 및 그 장치를 제공하는 것이다."}
{"patent_id": "10-2023-0106984", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상술한 과제를 해결하기 위하여 실시예들에 따른 인공지능 모델 학습 장치는, 복수의 화자들의 음성이 포함된 음성 데이터로부터 각 화자의 음성 정보를 추출하는 화자 분할(speaker diarization)을 수행한다. 실시예들에 따른 인공지능 모델 학습 장치는 복수의 화자들의 음성이 포함된 음성 데이터 및 화자 레이블 시퀀 스 정보를 포함하는 학습 데이터를 수신하는 수신부; 상기 음성 데이터를 임베딩하는 임베딩부; 상기 임베딩된 음성 데이터를 인코딩하는 인코딩부; 및/또는 상기 인코딩된 음성 데이터 및 화자 레이블 시퀀스 정보에 기반하 여 손실을 계산하는 손실함수 계산부; 를 포함할 수 있고, 상기 인코딩부는 복수 개의 인코더 블록을 포함할 수 있고, 상기 임베딩된 음성 데이터는 상기 복수의 인코더 블록들을 순차적으로 통과하면서 인코딩될 수 있다. 한편, 실시예들에 따른 인코더 블록은 헤드(head) 정보를 포함하고, 각 인코더 블록은 서로 다른 헤드 정보를 포함할 수 있다. 나아가, 실시예들에 따른 인공지능 모델 학습 장치는, 상기 복수의 인코더 블록들 중 적어도 하나의 블록의 헤 드 정보를 증류(distill)하는 증류부; 를 더 포함할 수 있다. 더 나아가 실시예들에 따른 증류부는 화자 판별을 위한 특징 벡터(feature vector)를 추출하는 단계; 상기 특징 벡터를 이용하여, 상기 복수의 인코더 블록들 중 적어도 하나의 인코더 블록을 추출하는 단계; 및/또는 상기 추 출한 인코더 블록의 헤드 정보를 증류하는 단계; 를 수행할 수 있다. 또한, 상술한 추출하는 단계는 상기 특징 벡터로부터 계산된 타겟 행렬과의 유사도를 측정함으로써 인코더 블록 을 추출할 수 있고, 헤드 정보를 증류하는 단계는 상기 추출된 인코더 블록과 상기 타겟 행렬로부터 도출된 손 실을 이용하여 증류할 수 있다. 한편, 실시예에 따른 유사도는 평균 제곱 오차(mean squared error)에 기반하여 계산될 수 있다. 또, 실시예들에 따른 증류부는 제1 인코더 블록의 헤드 정보를 이용하여 제2 인코더 블록의 헤드 정보로 증류할 수 있다. 한편, 제1 인코더 블록은 상기 제2 인코더 블록보다 상위에 위치할 수 있다. 또한, 실시예들에 따른 증류부는 증류부는 상기 제1 인코더 블록의 헤드 정보와, 상기 제1 인코더 블록이 아닌 인코더 블록들의 헤드 정보의 평균 제곱 오차를 도출함으로써, 증류 손실을 계산할 수 있다."}
{"patent_id": "10-2023-0106984", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "실시예들에 따른 인공지능 모델 학습 방법(또는 장치)은 이러한 구성을 이용함으로써, 인공지능 모델의 학습 성 능 개선을 도모하면서도 연산량이 증가하거나 새로운 손실 계산을 위해서 새로운 타겟을 생성해야 하는 문제점 을 개선하는 효과가 있다.실시예들에 따른 인공지능 모델 학습 방법(또는 장치)은 이러한 구성을 이용함으로써, 인코더 블록 수의 증가 및 하위 계층에 대한 기여도를 높일 수 있다는 효과가 있다."}
{"patent_id": "10-2023-0106984", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명은 다양한 변경을 가할 수 있고 여러 가지 실시예를 가질 수 있는 바, 특정 실시예들을 도면에 예시하고 상세한 설명에 상세하게 설명하고자 한다. 그러나, 이는 본 발명을 특정한 실시 형태에 대해 한정하려는 것이 아니며, 본 발명의 사상 및 기술 범위에 포함되는 모든 변경, 균등물 내지 대체물을 포함하는 것으로 이해되어 야 한다. 각 도면을 설명하면서 유사한 참조부호를 유사한 구성요소에 대해 사용하였다. 제1, 제2, A, B 등의 용어는 다양한 구성요소들을 설명하는데 사용될 수 있지만, 구성요소들은 용어들에 의해 한정되어서는 안 된다. 용어들은 하나의 구성요소를 다른 구성요소로부터 구별하는 목적으로만 사용된다. 예를 들어, 본 발명의 권리 범위를 벗어나지 않으면서 제1 구성요소는 제2 구성요소로 명명될 수 있고, 유사하게 제2 구성요소도 제1 구성요소로 명명될 수 있다. '및/또는' 이라는 용어는 복수의 관련된 기재된 항목들의 조합 또 는 복수의 관련된 기재된 항목들 중의 어느 항목을 포함한다. 어떤 구성요소가 다른 구성요소에 \"연결되어\" 있다거나 \"접속되어\" 있다고 언급된 때에는, 그 다른 구성요소에 직접적으로 연결되어 있거나 또는 접속되어 있을 수도 있지만, 중간에 다른 구성요소가 존재할 수도 있다고 이 해되어야 할 것이다. 반면에, 어떤 구성요소가 다른 구성요소에 \"직접 연결되어\" 있다거나 \"직접 접속되어\" 있 다고 언급된 때에는, 중간에 다른 구성요소가 존재하지 않는 것으로 이해되어야 할 것이다. 본 출원에서 사용한 용어는 단지 특정한 실시예를 설명하기 위해 사용된 것으로, 본 발명을 한정하려는 의도가 아니다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 출원에서, \"포함 하다\" 또는 \"가지다\" 등의 용어는 명세서상에 기재된 특징, 숫자, 단계, 동작, 구성요소, 부품 또는 이들을 조 합한 것이 존재함을 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성요소, 부 품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되어야 한다. 다르게 정의되지 않는 한, 기술적이거나 과학적인 용어를 포함해서 여기서 사용되는 모든 용어들은 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자에 의해 일반적으로 이해되는 것과 동일한 의미를 가지고 있다. 일 반적으로 사용되는 사전에 정의되어 있는 것과 같은 용어들은 관련 기술의 문맥 상 가지는 의미와 일치하는 의 미를 가지는 것으로 해석되어야 하며, 본 출원에서 명백하게 정의하지 않는 한, 이상적이거나 과도하게 형식적 인 의미로 해석되지 않는다. 화자 분할 시스템(speaker diarization system)은 2명 이상의 복수의 화자들의 음성이 담긴 혼합 음성 데이터를 분석하여, 화자 별로 '누가 언제 말했는가'를 구분하기 위해 사용된다. '화자'는 음성 데이터에 포함된 특정 주체를 의미할 수 있다. 예를 들어, 화자 분할 시스템은 복수의 주체들의 음성이 포함된 음성 데이터를 수신할 수 있고, 이를 분석하여 음성 데이터에 포함된 여러 화자들에 대한 음성 정보, 각 화자가 말한 구간 및/또는 말한 내용을 확인 또는 추출할 수 있다. 화자 분할 시스템은, 음성 데이터에 포함된 각 화자에 대한 정보를 추출 및 구별할 수 있는 인공지능 모델 (artificial intelligence model)을 하나 이상 포함할 수 있다. 인공지능 모델은 예를 들어 트랜스포머(transformer) 모델을 포함할 수 있다. 화자 분할 시스템의 인공 지능 모델을 학습하는 방법(이하 '인공지능 모델 학습 방법')은 다양할 수 있다. 예를 들어, 화자 분할 시스템은 IEEE Automatic Speech Recognition and Understanding Workshop 2019에서 제안된 “End-to-end neural speaker diarization with self-attention\" 문헌에서 제안한 SA-EEND 시스템일 수 있다. 이러한 SS-EEND 시스템의 문제점으로 지적된 인코더 블록 수 증가 및 하위 계층에 대한 기여도 문제를 해결하기 위하여 IEEE International Conference on Acoustics, Speech and Signal Processing 2022 “Auxiliary loss of transformer with residual connection for end-to-end speaker diarization”에서 제안한 시스템 등을 이 용할 수 있다. ICASSP 2023 “transformer-based end-to-end speaker diarization by assigning auxiliary losses to attention heads.”에서 제안한 트랜스포머 인코더 기반의 화자 분할 시스템에서 인코더 블록의 헤드 에 각 화자의 음성 유무와 관련된 타겟 라벨을 이용하여 추가 손실을 부여하는 방법도 이용될 수 있다. 인공지 능 모델 학습 방법과 관련하여, 음성 인식 시스템의 계층별 성능을 개선시키기 위한 자가 증류 기법이 “based on high-level information supervision for compressing end-to-end asr model”에서 제안되기도 하였다. 이처럼 실시예들에 따른 화자 분리 시스템의 개발을 위해 인공 지능 모델을 학습하는 방법이 상술한 바와 같이 제시되었다. 상술한 예시들은 트랜스포머 인코더 기반의 종단간 시스템이 주로 사용되며, 이러한 시스템의 성능 개선을 위해 인코더 블록 자체의 학습뿐 아니라 이를 구성하는 어텐션 헤드의 학습을 도모하는 방법들을 제시한 다. 하지만 상술한 예시 방법들은 인코더 블록 수의 증가 및 하위 계층에 대한 기여도가 크지 않다는 한계점이 있다. 또, 이러한 문제점을 조금이나마 개선하기 위해 모든 블록에 대해 추가 손실을 부여하는 등의 방법 등이 상술한 문헌 등에 의해 제안되었지만, 이는 성능 개선을 위해 모든 블록에서 순열 불변 방식으로 학습해야 하기 때문에 연산량이 증가하거나 새로운 손실 계산을 위해서는 새로운 타겟을 생성해야한다는 한제점이 있다. 이러한 문제점을 해결하기 위하여 본 명세서에서는 실시예들에 따른 인공지능 모델의 개선된 학습 방법을 제안 한다. 본 명세서에서 설명하는 제안된 인공지능 모델의 학습 방법(이하 '실시예들에 따른 인공지능 모델 학습 방법')을 설명한다. 한편, 실시예들에 따른 인공지능 모델 학습 방법은 실시예들에 따른 인공지능 모델 학습 장 치에 의해 수행될 수 있다. 실시예들에 따른 인공지능 모델 학습 방법은 복수의 화자들의 음성이 포함된 음성 데이터로부터 각 화자의 음성 정보를 추출하는 화자 분할(speaker diarization)을 수행할 수 있다. 실시예들에 따른 인공지능 모델 학습 방법 은 복수의 화자들의 음성이 포함된 음성 데이터 및 화자 레이블 시퀀스 정보를 포함하는 학습 데이터를 수신하 는 단계; 상기 음성 데이터를 임베딩하는 단계; 상기 임베딩된 음성 데이터를 인코딩하는 단계; 및/또는 상기 인코딩된 음성 데이터 및 화자 레이블 시퀀스 정보에 기반하여 손실을 계산하는 단계; 를 포함할 수 있다. 여기 서 인코딩하는 단계는 복수 개의 인코더 블록을 포함할 수 있고, 상기 임베딩된 음성 데이터는 상기 복수의 인 코더 블록들을 순차적으로 통과하면서 인코딩될 수 있다. 각 단계별 구체적인 내용은 도면과 함께 이하에서 자 세히 설명하기로 한다. 즉, 실시예들에 따른 인공지능 모델 학습 방법은 트랜스포머 인코더 기반의 종단간 화자 분할 시스템에서, 시스 템의 깊이에 따라 상위 계층과 하 위 계층으로 나눈 후 상위 계층의 어텐션 헤드에서 학습한 상위 지식을 하위 계층의 어텐션 헤드로 증류(distill)할 수 있다. 도 1은 화자 분할을 수행하는 실시예들에 따른 인공지능 모델 학습 장치의 구성의 예시도이다. 인공지능 모델 학습 장치는 복수의 화자들의 음성이 포함된 음성 데이터로부터 각 화자의 음성 정보를 추출 하는 화자 분할(speaker diarization)을 수행하는 인공지능 모델을 학습한다. 실시예들에 따른 인공지능 모델 학습 장치는 실시예들에 따른 인공지능 모델 학습 방법을 수행한다. 실시예 들에 따른 인공지능 모델 학습 장치는 수신부, 임베딩부, 인코딩부, 손실함수 계산부, 증 류부를 포함한다. 수신부는 복수의 화자들의 음성이 포함된 음성 데이터 및 화자 레이블 시퀀스 정보를 포함하는 학습 데이터 를 수신할 수 있다. 임베딩부는 상기 음성 데이터를 임베딩(embedding)할 수 있다. 임베딩부는 수신부가 수신한 음성 데이 터를 하나 또는 여러 개의 벡터(vector) 데이터로 변환하는 등의 임베딩을 수행할 수 있다. 인코딩부는 상기 임베딩된 음성 데이터를 인코딩(encoding)할 수 있다. 인코딩부는 하나의 인코더 블록 (encoder block)을 포함할 수도 있지만, 복수 개의 인코더 블록들을 포함할 수도 있다. 한편, 인코더 블록들은 직렬로(serially) 연결될 수 있다. 즉, 이러한 복수 개의 인코더 블록들은, 상술한 음성 데이터 또는 임베딩된 음성 데이터가 순차적으로 통과되면서 최종적으로 인코딩된 정보를 출력할 수 있다. 손실함수 계산부는 인코딩부에 의해 인코딩된 음성 데이터와 화자 레이블 시퀀스 정보를 이용하여, 손 실 함수(loss function)에 따라 손실(loss)을 계산할 수 있다. 손실함수 계산부에서 계산한 손실은, 실시예 들에 따른 인공지능 모델, 인코딩부의 일부 또는 전부를 학습하는데 이용될 수 있다. 즉, 인공지능 모델, 인코딩부의 일부 또는 전부는 손실함수 계산부에서 계산한 손실을 이용하여, 역전파(back-propagation) 기법 등에 따라 학습될 수 있다. 한편, 실시예들에 따른 인코딩부는 트랜스포머 인코더 기반의 종단간 화자 분할 모델(예를 들어, SA-EEND 모델) 구조에 사용된 인코딩 모델을 이용할 수 있다. 즉, 실시예들에 따른 인코딩부에 포함된 복수의 인코 더 블록들은 각각 멀티-헤드 셀프 어텐션(Multi-head self-attention, MHSA) 모델과 풀리 커넥티드 피드 포워드 신경망(Fully Connected Feed-Forward Networks)를 포함한다. 멀티-헤드 셀프 어텐션(MHSA)은 헤드(head)를 포 함할 수 있고, 헤드는 헤드 정보를 포함한다. 다시 말해, 실시예들에 따른 인코딩부는 MHSA 모델 및 풀리 커넥티드 피드 포워드 신경망을 포함하는 인코더 블록을 복수 개 포함하며, 이들은 선형으로 직렬로 연결될 수 있다. 한편, 인코더 블록 내에서 담고 있는 헤드(또는 헤드 정보)는 음성 및 화자 정보와 관련된 패턴을 학습한다는 점에 초점을 맞춘다는 점에서, 학습을 진행하는 과정에서 효율적으로 개선되거나 증류(또는 갱신)될 필요가 있 다. 이 때, 출력 계층(예를 들어, 인코더 블록들 중 출력단에 가까운 블록들 또는 레이어들)에 더 가까울수록 최종 예측과 관련된 정보가 더 많이 포함되어 있을 수 있다. 따라서, 이러한 출력 계층에 더 가까운 블록들 즉, 상위 블록들의 정보 또는 최적화된 정보를 이용하여 출력 계층에서 먼 블록득 즉, 하위 블록들의 헤드 정보를 갱신하거나 새롭게 재구성될 필요가 있다. 이에 따라, 실시예들에 따른 증류부는 상술한 트랜스포머 인코더 기반의 종단간 화자 분할 모델을 내포하는 인공지능 모델 학습 장치의 효율적인 학습을 도모하기 위해, 상위 인코더 블록의 헤드 정보를 하위 인코더 블록의 헤드로 자가 증류하는 방법들 (이하 제안할 출력-헤드 증류(Output-to-head distillation) 기법 또는, 헤드간 증류(Heads-to-Head distillation))을 이용하여, 각 인코더 블록에 포함된 헤드 정보를 갱신 또는 증류 할 수 있다. 실시예들에 따른 인공지능 모델 학습 방법(또는 장치)은 이러한 구성을 이용함으로써, 인공지능 모델의 학습 성 능 개선을 도모하면서도 연산량이 증가하거나 새로운 손실 계산을 위해서 새로운 타겟을 생성해야 하는 문제점 을 개선하는 효과가 있다. 실시예들에 따른 인공지능 모델 학습 방법(또는 장치)은 이러한 구성을 이용함으로써, 인코더 블록 수의 증가 및 하위 계층에 대한 기여도를 높일 수 있다는 효과가 있다. 이하 도 2에서는, 실시예들에 따른 인공지능 모델을 학습하기 위한 시스템을 구체적으로 서술한다. 도 2는 화자 분할을 수행하는 실시예들에 따른 인공지능 모델을 학습하는 시스템을 나타내는 도면이다. 구체적으로 도 2는 실시예들에 따른 인공지능 모델과 이들을 학습하기 위하여 수행되는 증류 동작을 수행하는 과정을 나타낸다. 실시예들에 따른 인공지능 모델은 예를 들어, 4개 또는 그 이상의 인코더 블록(encoder block)들을 포함하는 SA-EEND 모델일 수 있다. 실시예들에 따른 인공지능 모델은 복수의 화자들이 포함되는 음성 데이터로부터 각 화자에 대한 정보인 화자의 활동 레이블을 예측한다. 실시예들에 따른 인공지능 모델은 화자 활동 레이블의 시퀀스를 예측하기 위해 T 길이 입력 특징(input feature) 정보인 X = [x1, · · · · xT]를 선형 레이어([도 2]의 Linear)를 통과시켜 아래 와 같은 임베딩 벡터인 e_0^t 로 변환한다. 여기서, t는 시간 프레임 인덱스(time frame index)를 의미할 수 있 다. [도 2]에서 실시예들에 따른 인공지능 모델을 학습하기 위한 시스템이 입력 특징을 임베딩하는 과정은 [도 1]의 임베딩부에서 수행될 수 있다. 한편, 실시예들에 따른 인공지능 모델의 입력 데이터는 음성 데이터가 임베딩된 데이터일 수 있으며, 임베딩은 예를 들어 25ms 프레임 길이와 10ms 프레임 이동을 갖는 23차원 로그 스케일 멜 필터뱅크 에너지(log-scaledmel-filterbank energies)일 수 있다. 이후, 실시예들에 따른 인공지능 모델은 적어도 4개의 인코더 블록([도 2]의 Encoder block)들을 더 포함할 수 있다. 각 인코더 블록에서는 T 길이의 인코딩된 특징 벡터를 출력한다. 실시예들에 따른 인코더 블록은 MHSA 및 피드-포워드 네트워크(Feed-forward Network)를 포함한다. 이후, 실시 예들에 따른 인공지능 모델은 인코딩된 입력 데이터를 레이어 정규화하기 위한 레이어 정규화부([도 2]의 LN)를 통과할 수 있다. 피드-포워드 네트워크는 예를 들어, 두 개의 선형 레이어들과 ReLU 활성화 함수를 거칠 수 있 다. 한편, 각 인코더 블록 내 MHSA는 적어도 4개의 헤드(head)들을 포함할 수 있다. 각 헤드는 SA 헤드로 호칭될 수 있다. SA 헤드는 스케일드 닷-프로덕트 어텐션(scaled dot-product attention) 기법을 이용하여, 아래와 같이 어텐션 정보를 계산할 수 있다. 아래에서, H는 전역 특징 관계(global feature relations)를 고려하는 T X T 크기의 어텐션 가중치 행렬로써, 쿼리 Q와 키 K 값을 제곱근 d으로 나눈 값에 의하여 정의될 수 있다. V는 T X d 크기의 값이고, d는 히든 스페이스(hidden space)의 차원수를 나타낸다."}
{"patent_id": "10-2023-0106984", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "실시예들에 따른 인공지능 모델을 학습하기 위한 시스템은, 입력 데이터를 복수 개의 인코더 블록들을 통과시킨 후 각 화자에 대한 정보의 예측 결과 y_t를 시간 프레임 단위로 출력한다. 실시예들에 따른 인공지능 모델을 학 습하기 위한 시스템은, y_t를 출력하기 위하여 레이어 정규화 모델인 LayerNorm 및 선형 레이어인 Linear를 이 용할 수 있고, 최종적으로 Sigmoid 함수를 이용할 수 있다. 실시예들에 따른 인공지능 모델을 학습하기 위한 시 스템이 y_t를 출력하는 구체적인 과정은 다음과 같다."}
{"patent_id": "10-2023-0106984", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "[도 2]에서 실시예들에 따른 인공지능 모델을 학습하기 위한 시스템이 입력 특징을 인코딩하는 과정, LayerNorm 및 Linear을 통해 출력을 도출하는 과정의 일부 또는 전부는 [도 1]의 인코딩부에서 수행될 수 있다. 실시예들에 따른 인공지능 모델은, 학습 데이터의 학습을 위하여 손실 함수를 이용한 손실을 계산할 수 있다. 계산한 손실 는 다음과 같이 계산될 수 있다. 는 화자들의 정보에 대한 가능한 모든 조합을 의미할 수 있고, 는 각 조합에 대한 화자 레이블 시퀀스를 의미할 수 있다."}
{"patent_id": "10-2023-0106984", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "[도 2]에서 실시예들에 따른 인공지능 모델을 학습하기 위한 시스템이 손실함수를 계산하는 과정 일부 또는 전 부는 [도 1]의 손실함수 계산부에서 수행될 수 있다. 한편, 실시예들에 따른 인공지능 모델을 학습하기 위한 시스템은 인코더 블록들 중 출력 계층에 더 가까운 블록 들 즉, 상위 인코더 블록들의 정보 또는 최적화된 정보를 이용하여 출력 계층에서 먼 블록득 즉, 하위 인코더 블록들의 헤드 정보를 갱신하거나 새롭게 재구성될 필요가 있다. 따라서, 실시예들에 따른 인공지능 모델을 학 습하기 위한 시스템은 인코더 블록들 내의 헤드 정보를 증류(distill)할 수 있다. 지식 증류(Knowledge Distillation) 기법은 지식을 Student 네트워크로 추출하기 위해 Teacher 네트워크를 사 용하여 모델을 압축하는 데 일반적으로 사용되는 방법이다. 이에 따라, 실시예들에 따른 인공지능 모델을 학습 하기 위한 시스템은 최적화된 정보(상술한 O_t 정보)와 하위 인코더 블록의 헤드 정보의 유사도 비교를 기반으 로, 하위 인코더 블록의 헤드 정보를 자가 증류(self-distill)하는 출력-헤드 증류(Output to Head Distillation) 동작을 수행할 수 있다. 이하 출력-헤드 증류 방법에 대하여 설명한다. 실시예들에 따른 인공지능 모델을 학습하기 위한 시스템은 출력 특징 벡터인 를 추출한다. O_s는 실시예들에 따른 인공지능 모델의 인코더 블록들 (또는, LayerNorm 및 Liner 모듈들)을 통과하여 출력된 출력 특징 벡터를 의미할 수 있다. O_s는 [도 1]의 인코딩부에서 출력된 데이터를 의미할 수 있 다. O_s는 화자를 구분하는데 사용되는 최고차원의 정보를 포함한다. 그 후, 실시예들에 따른 인공지능 모델을 학습하기 위한 시스템은 O_s를 이용하여 다음 수학식에 기반하여 M_s 값을 도출한다. M_s는 학습 손실과의 유사도를 계산하고, 어느 인코더 블록의 어느 헤드에 증류할지 결정하기 위하여 이용된다."}
{"patent_id": "10-2023-0106984", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "실시예들에 따른 인공지능 모델을 학습하기 위한 시스템은, 증류를 할 SA 헤드를 결정하기 위하여, 아래 수학식 과 같이 p번째 인코더 블록의 헤드의 어텐션 가중치 행렬인 과 상술한 M_s의 평균 제곱 오차 (MSE, Mean Square Error)를 계산하여 헤드 증류에 이용되는 증류 손실 정보 를 계산한다. 여기서, M은 p번째 인코더 블록의 어텐션 헤드(head)들의 개수를 의미한다."}
{"patent_id": "10-2023-0106984", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "또 다른 자가-증류의 방법으로, 실시예들에 따른 인공지능 모델을 학습하기 위한 시스템은, 각 인코더 블록 내 의 헤드 정보를 서로 교체하거나 변경함으로써 증류하는 헤드간 증류(Head to Head Distillation) 동작을 수행 할 수도 있다. 실시예들에 따른 인공지능 모델을 학습하기 위한 시스템은, 제1 인코더 블록 내의 헤드 정보를 제2 인코더 블록 내의 헤드 정보로 증류할 수 있다. 여기서, 제1 인코더 블록은 인공지능 모델의 출력 단에 가까이 위치하는 인 코더 블록인 상위 인코더 블록을 의미할 수 있고, 제2 인코더 블록은 제1 인코더 블록보다 입력 단에 더 가까이 위치하는 인코더 블록을 의미할 수 있다. 즉, 제2 인코더 블록은 인공지능 모델의 입력 단에 가까이 위치하는 인코더 블록인 하위 인코더 블록을 의미할 수 있다. 먼저, 실시예들에 따른 인공지능 모델을 학습하기 위한 시스템은, 제1 인코더 블록의 헤드 정보를 증류받을 제2 인코더 블록을 선택하는 동작을 수행할 수 있다. 즉, 실시예들에 따른 인공지능 모델을 학습하기 위한 시스템은, 하위 인코더 블록의 헤드 정보인 에 증류시키기 위하여, 목표하는 인코더 블록의 헤드의 어텐션 가중치 행렬인 (즉, p번째 인코더 블록의 m번째 어텐션 가중치 행렬)을 탐색한다. (여기서, p는 k보다 작 다) 여기서, 실시예들에 따른 인공지능 모델을 학습하기 위한 시스템은 가장 큰 평균 제곱 오차(MSE, Mean Square Error)를 포함하는 를 추출한다. k번째 인코더 블록의 SA 헤드로 증류될 p번째 인코더 블록의 헤드 정보 는 다음과 같이 나타낼 수 있다."}
{"patent_id": "10-2023-0106984", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 7, "content": "한편, 실시예들에 따른 인공지능 모델을 학습하기 위한 시스템은, 또한 상위 SA 헤드가 공유하도록 나타내는 정 보의 양을 기반으로 디자인 가중치에 어텐션 메커니즘을 적용할 수 있다. 즉, k번째 인코더 블록의 SA 헤드에서 p번째 인코더 블록의 SA 헤드를 추출할 때 어텐션 값 ε는 다음과 같이 정의될 수 있다."}
{"patent_id": "10-2023-0106984", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 8, "content": "[도 2]에서는, 상위 인코더 블록으로부터 증류받을 인코더 블록은 첫 번째 인코더 블록임을 확인할 수 있다 (p=1). 이후, 실시예들에 따른 인공지능 모델을 학습하기 위한 시스템은 헤드 증류에 이용되는 증류 손실 정보 를 계산한다."}
{"patent_id": "10-2023-0106984", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 9, "content": "그 후, 도출된 A_k를 기반으로, ε를 도출하고, 도출된 εk를 기반으로 증류 손실 정보를 계산할 수 있다. 예를 들어, 가 p번째 인코더 블록인 상위 인코더 블록(이하, 제1 인코더 블록이라 한다)이다. 여기서, 실시 예들에 따른 인공지능 모델을 학습하기 위한 시스템은 각 인코더 블록의 헤드 정보와 제1 인코더 블록의 헤드 정보의 평균 제곱 오차를 계산하고, 이를 기반으로 가장 큰 평균 제곱 오차를(즉, 유사도가 가장 낮은 값을) 증 류 손실로 사용하기 위하여 A_k를 계산한다. 각 인코더 블록이 복수 개의 헤드들(예를 들어, m개의 헤드들)을 포함하면, 각 m개의 헤드에 대하여 도출된 결과를 모두 더하여 A_k를 도출한다. 정리하면, 실시예들에 따른 인공지능 모델을 학습하기 위한 시스템은, 인코더 블록 내 헤드 정보를 학습하는 과 정에서 갱신하거나 자가-증류하기 위하여 출력-헤드 증류(Output to Head Distillation) 동작을 수행할 수 있다. 그 과정에서, 시스템은 증류 손실 정보 을 계산하여 인코더 블록의 헤드 정보를 갱신하거나 최적화 한다. 또한, 시슽템은 헤드간 증류(Head to Head Distillation) 동작을 수행할 수도 있다. 그 과정에서 시스템 은 증류 손실 정보 를 계산하여 계산하여 인코더 블록의 헤드 정보를 갱신하거나 최적화한다. 실시예들에 따른 인공지능 모델 학습 방법(또는 장치)은 이러한 구성을 이용함으로써, 인공지능 모델의 학습 성 능 개선을 도모하면서도 연산량이 증가하거나 새로운 손실 계산을 위해서 새로운 타겟을 생성해야 하는 문제점 을 개선하는 효과가 있다. 실시예들에 따른 인공지능 모델 학습 방법(또는 장치)은 이러한 구성을 이용함으로써, 인코더 블록 수의 증가 및 하위 계층에 대한 기여도를 높일 수 있다는 효과가 있다. 도 3는 실시예들에 따른 인공지능 모델의 학습 시 사용되는 학습 데이터의 예시이다. 실시예들에 따른 인공지능 모델의 학습 시스템의 시뮬레이션 및 성능 검증을 위하여 실제 데이터 세트를 준비하 였다. 학습 데이터를 생성하는 음성 혼합 시뮬레이션 알고리즘은 Sim2spk로 표시되는 시뮬레이션된 데이터 세트 를 생성하는 데 사용되었다. Switchboard-2(Phases I, II, III), Switchboard Cellular(Parts 1 and 2), NIST Speaker Recognition Assessment(2004, 2005, 2006, 2008) 말뭉치도 사용하여 Sim2spk를 사용하였다. 이 말뭉 치는 모두 8kHz로 샘플링되었다. Sim2spk는 다른 발화에서 10~20개의 발화를 무작위로 선택하여 생성된 모든 발 화에 대해 두 개의 서로 다른 스피커를 사용했다. 각 발화는 MUSAN의 배경 잡음 샘플과 함께 추가되었으며 0.5 의 확률로 무작위로 선택된 시뮬레이션된 실내 임펄스 응답으로 컨볼루션되었다. 실제 평가 데이터 세트에는 CALLHOME(CH) 데이터 세트의 두 화자 전화 대화 발화 세트가 사용되었다. CH 데이터 세트의 두 화자 녹음이 적 응 및 테스트 세트로 분할되었다. 데이터 세트의 세부 사항은 혼합물 및 중첩 비율의 수를 포함하여 [도 3]에 도시되었다. 각각 4개의 헤드를 사용하는 4개의 트랜스포머 인코더 블록이 있는 SA-EEND가 기본 모델로 사용되었다. 모델 매 개변수의 수는 5.35M이다. 입력 기능은 25ms 프레임 길이와 10ms 프레임 이동을 갖는 23차원 로그 스케일 멜 필 터뱅크 에너지였다. 학습 손실은 Ld와 보조 손실 함수에 스케일링 계수를 곱한 값의 합으로 계산되었다. SA- EEND는 4개의 인코더 블록을 포함하기 때문에 L_NFSD는 두 그룹에 적용되었다. 하나는 처음 두 개의 인코더 블 록으로 구성되고 다른 하나는 마지막 두 개의 인코더 블록으로 구성된다. 또한 L_O2H와 L_H2H는 각각 스케일링 계수 1과 0.2를 사용하여 적용하였다. 데이터 세트는 2개의 화자로 구성되었으므로 선택한 2개의 SA 헤드에 L_O2H를 적용하였다. Adam 옵티마이저는 모든 훈련 단계에서 100,000개의 워밍업 단계를 적용했으며, 적응 동안 에만 학습률을 0.00001로 설정했다. 모델은 Sim2spk 데이터 세트를 사용하여 각각 100 epoch에 대해 사전 훈련 및 미세 조정되었으며 CH 2-speaker 데이터 세트는 추가 100 epoch에 대한 적응 단계에 사용되었다. 사전 학습 이 완료된 후 마지막 10 epoch에서 얻은 모델의 매개변수를 평균화한 후 미세 조정 또는 적응에 사용했다. 평가 는 앞서 언급한 매개변수 평균화 방식을 적용한 모델을 사용하여 수행했다. 분할 오류율(DER)은 각 세그먼트의 시작과 끝 모두에 대해 칼라 허용 오차가 0.25초인 평가 메트릭으로 사용되었다. 최종 화자 활동 예측을 위해 11프레임 중간 필터와 임계값 0.5를 적용하였다. 이에 따른 결과는 [도 4]에서 설명한다.도 4는 학습된 인공지능 모델을 이용하여 화자 분할을 수행한 결과와 그 성능을 나타낸 도면이다. 도 4의 401은 사전 훈련 및 미세 조정 단계 동안 다양한 보조 손실을 사용하여 훈련된 EEND 모델의 성능을 보여 준다. L_aux는 마지막 인코더 블록을 제외한 모든 인코더 블록에서 L_d와 같은 방식으로 계산된 보조 손실이다. 또한 L_S와 L_O는 각각 특정 SA 헤드와 2인 화자 활동 대상에서 생성된 행렬 간, 특정 SA 헤드와 전체 음성 활 동 패턴 간 BCE와 MSE를 사용하여 계산된 보조 손실이다. 401의 제안된 두 가지 손실에 대한 실험 결과는 첫 번째 인코더 블록에 자가 증류를 적용했을 때 얻은 것이다. 시뮬레이션된 데이터와 실제 데이터 세트 모두에서 제안된 자가 증류 방법은 자가 증류에 대해 각 인코더 블록 의 출력을 사용한 NFSD 및 AFSD보다 낮은 DER을 달성하였다. 401에서 볼 수 있듯이 미세 조정 단계에서 기존의 자가 증류 기술을 적용하면 두 데이터 세트의 기준 시스템이 크게 개선되어 제안된 보조 손실을 사용하여 훈련된 다른 모델과 경쟁적인 성능을 생성했다. 그러나 사전 학습 단계에서만 자가 증류 방법을 적용한 경우에는 성능 향상이 있었다. 이것은 자가 증류 방법이 모델이 맞춰진 후 에 가장 잘 적용된다는 것이 일반적으로 인정되기 때문일 수 있다. 따라서 제안된 자가 증류 방법 역시 모델이 사전에 충분히 훈련된 후 적용되었을 때 더 효과적이었다고 설명할 수 있다. 도 4의 402는, 제안된 자가 증류 손실이 자가 증류가 적용되는 인코더 블록의 다른 위치에 미치는 영향을 조사 한다. 자가 증류는 모델의 하위 계층에 걸쳐 높은 수준의 정보를 공유하는 것을 목표로 하기 때문에 제안된 자 가 증류 방법이 적용되는 인코더 블록의 수를 최하위 계층에서 최상위 계층으로 점진적으로 확장하여 실험을 수 행하였다. 흥미롭게도 제안된 손실 함수를 첫 번째 인코더 블록에만 적용하면 모든 하위 블록에 적용하는 것보 다 우수한 성능을 보였다. 도 5는 화자 분할을 수행하는 실시예들에 따른 인공지능 모델 학습 시스템이 자가 증류를 수행한 후의 효과를 나타내는 도면이다. 구체적으로, 도 5는 SA 헤드에 대한 자가 증류의 손실의 영향을 조사하기 위해 본 명세서에서 언급한 학습된 인 공지능 모델의 인코더 블록들의 4가지 어텐션 가중치 매트릭스를 시각화한 도면이다. 도 5에서 처음 세 행은 첫 번째 인코더 블록에서 계산된 주의 어텐션 행렬을 나타내며 네 번째 및 다섯 번째 행은 두 번째 인코더 블록에 해당한다. 도 4의 (a) 및 (b)를 비교하면 L_O2H를 적용하여 4개의 어텐션 헤드가 더 큰 가중치로 더 명확한 패 턴을 보이는 것을 확인하였다. 도 4의 (c)에 나타난 L_H2H의 경우, 가중치가 작은 항등항의 패턴은 head1과 head4에서 학습되었고, head3의 패턴이 도 4의 (b)보다 더 뚜렷하였다. 따라서 도 3 및 도 4의 DER을 고려하면 자가 증류 손실이 하위 블록의 SA 헤드가 음성 패턴을 효과적으로 학습하는 데 도움이 되었다고 추론할 수 있다. SA-EEND, RX-EEND의 모든 두 번째 인코더 블록과 제안한 모델은 두 개의 SA 헤드에서 항등식 어텐션 가중치 매 트릭스만 보여준다. 흥미롭게도, 제안된 L_H2H 손실이 적용된 SA-EEND의 두 번째 블록의 두 개의 주의 가중치 매트릭스(head2 및 head3)는 도 4 (e)의 동일성 유사 패턴 외에도 비동일성 유사 패턴을 나타내었다. L_H2H를 첫 번째 블록에만 적용할 경우 첫 번째 블록의 SA 헤드와 상위 블록의 SA 헤드 간의 MSE를 최소화하기 때문에 중간 블록의 SA 헤드 교육에 영향을 줄 수 있다. 따라서 항등 행렬을 완화하고 중복 훈련된 SA 헤드를 효과적으 로 활용하여 성능 향상을 달성할 수 있었다. 도 6은 화자 분할을 수행하는 실시예들에 따른 인공지능 모델 학습 방법을 나타낸다. 실시예들에 따른 인공지능 모델 학습 방법은 600 단계 내지 603 단계를 수행할 수 있다. 각 단계는 도 1 내지 도 5에 나타난 인공지능 모델 학습 장치 또는 시스템에 의해 수행될 수 있다. 도 6을 참조하면, 실시예들에 따른 인공지능 모델 학습 방법은, 복수의 화자들의 음성이 포함된 음성 데이터 및 화자 레이블 시퀀스 정보를 포함하는 학습 데이터를 수신한다. 600 단계는 예를 들어, 도 1의 수신부 에 의해 수행될 수 있다. 도 6을 참조하면, 실시예들에 따른 인공지능 모델 학습 방법은, 상기 음성 데이터를 임베딩한다. 601 단계 는 도 1의 임베딩부에 의해 수행될 수 있다. 도 6을 참조하면, 실시예들에 따른 인공지능 모델 학습 방법은, 상기 인코딩된 음성 데이터 및 화자 레이블 시 퀀스 정보에 기반하여 손실을 계산한다. 여기서, 인코딩부는 복수 개의 인코더 블록을 포함할 수 있다. 여 기서, 임베딩된 음성 데이터는 상기 복수의 인코더 블록들을 순차적으로 통과하면서 인코딩된다. 602 단계는 도1의 인코딩부에 의해 수행될 수 있다. 한편, 실시예들에 따른 인코더 블록은 MHSA 및 피드-포워드 네트워크 모델을 포함할 수 있다. 각 MHSA는 하나 이상의 헤드(head)를 포함할 수 있고, 각 헤드는 헤드 정보를 포함한다. 도 6을 참조하면, 실시예들에 따른 인공지능 모델 학습 방법은, 상기 추출한 인코더 블록의 헤드 정보를 증류 한다. 603 단계에서, 실시예들에 따른 인공지능 모델 학습 방법은, 인공지능 학습 과정에서 인코더 블록들 각각의 헤드들의 정보(예를 들어, 어텐션 가중치 행렬 등)를 갱신하거나 변경하는 등의 증류 작업을 수행할 수 있다. 603 단계에서는 출력-헤드 증류(Output to Head Distillation) 방식 또는 헤드간 증류(Head to Head Distillation) 중 적어도 하나의 방식에 기초하여 자가 증류 작업을 수행할 수 있다. 우선, 출력-헤드 증류 방식에서, 603 단계는 화자 판별을 위한 특징 벡터(feature vector)를 추출하는 단계; 상 기 특징 벡터를 이용하여, 상기 복수의 인코더 블록들 중 적어도 하나의 인코더 블록을 추출하는 단계; 및 상기 추출한 인코더 블록의 헤드 정보를 증류하는 단계; 를 수행할 수 있다. 여기서, 추출하는 단계는 상기 특징 벡 터로부터 계산된 타겟 행렬과의 유사도(예를 들어, 평균 제곱 오차(mean squared error)에 기반하여 계산될 수 있음)를 측정함으로써 인코더 블록을 추출할 수 있다. 또, 헤드 정보를 증류하는 단계는 상기 추출된 인코더 블 록과 상기 타겟 행렬로부터 도출된 증류 손실을 이용하여 증류한다. 또한, 헤드간 증류(Head to Head Distillation) 방식에서, 603 단계는 제1 인코더 블록의 헤드 정보를 이용하여 제2 인코더 블록의 헤드 정보로 증류할 수 있다. 여기서, 제1 인코더 블록은 상기 제2 인코더 블록보다 상위에 위치한다. 또, 603 단계에서는 제1 인코더 블록의 헤드 정보와, 제1 인코더 블록이 아닌 인코더 블록들의 헤드 정보의 평균 제곱 오차를 도출함으로써, 증류 손실을 계산한다. 도 7은 실시예들에 따른 화자 분할을 수행하는 인공지능 모델을 학습하는 장치의 구성도의 예시이다. 도 7를 참조하면, 서버는 입력부, 출력부, 제어부, 저장부 및 통신부를 포함한다. 입력부는 관리자로부터 명령이나 정보를 입력 받는다. 입력부는 오디오 신호를 입력 받기 위한 마이 크로폰 및 키 입력부 중에서 하나 이상을 포함할 수 있다. 출력부는 명령 처리 결과나 각종 정보를 관리자에게 출력한다. 예를 들어, 출력부는 상술한 화자 분 할을 수행하는 인공지능 모델을 학습하는 시스템에서 생성된 정보를 출력한다. 이를 위하여, 출력부는 도 면에 도시되지는 않았으나, 디스플레이, 스피커, 햅틱 출력부 및 광 출력부를 포함할 수 있다. 디스 플레이는 평판 디스플레이(Flat panel display), 연성 디스플레이(Flexible display), 불투명 디스플레이, 투"}
{"patent_id": "10-2023-0106984", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 10, "content": "명 디스플레이, 전자종이(Electronic paper, E-paper), 또는 본 발명이 속하는 기술분야에서 잘 알려진 임의의 형태로 제공될 수 있다. 디스플레이에는 터치 패드가 적층되어 터치 스크린(touch screen)을 구성할 수 있으며, 이러한 터치 스크린을 통해 터치 키가 구현될 수 있다. 출력부는 디스플레이 및 스피커 외에도 본 발명이"}
{"patent_id": "10-2023-0106984", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 11, "content": "속하는 기술분야에서 잘 알려진 임의의 형태의 출력 수단을 더 포함하여 구성될 수도 있다. 제어부는 서버 내의 구성요소들을 연결하고 제어한다. 일 예로, 상술한 화자 분할을 수행하는 인공지 능 모델을 학습하는 시스템으로부터 생성된 정보가 출력부를 통해 출력될 수 있도록 각 구성요소들을 제어 한다. 다른 예로, 제어부는 관리자에 의해 판단 정보가 입력되면, 판단 정보가 포함된 응답 신호를 생성한 다. 제어부는 CPU(Central Processing Unit), MPU(Micro Processor Unit), MCU(Micro Controller Unit), GPU(Graphic Processing Unit) 또는 본 발명의 기술 분야에 잘 알려진 임의의 형태의 프로세서를 포함하여 구성 될 수 있다. 저장부는 서버가 동작하는데 필요한 데이터, 프로그램 및 어플리케이션 등을 저장한다. 이러한 저장부 는 비휘발성 메모리, 휘발성 메모리, 하드 디스크, 광 디스크, 광자기 디스크, 또는 본 발명이 속하는 기 술분야에서 잘 알려진 임의의 형태의 컴퓨터로 읽을 수 있는 기록 매체를 포함할 수 있다. 통신부는 유무선 네트워크를 통해 화자 분할을 수행하는 인공지능 모델을 학습하는 시스템 또는 다른 시스 템과 통신한다. 본 명세서와 도면에 게시된 본 발명의 실시 예들은 본 발명의 기술 내용을 쉽게 설명하고 본 발명의 이해를 돕 기 위해 특정 예를 제시한 것뿐이며, 본 발명의 범위를 한정하고자 하는 것은 아니다. 여기에 게시된 실시 예들이외에도 본 발명의 기술적 사상에 바탕을 둔 다른 변형 예들이 실시 가능하다는 것은 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자에게 자명한 것이다. 상기에서는 본 발명의 바람직한 실시예를 참조하여 설명하였지만, 해당 기술 분야의 숙련된 당업자는 하기의 특 허 청구의 범위에 기재된 본 발명의 사상 및 영역으로부터 벗어나지 않는 범위 내에서 본 발명을 다양하게 수정 및 변경시킬 수 있음을 이해할 수 있을 것이다."}
{"patent_id": "10-2023-0106984", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 화자 분할을 수행하는 실시예들에 따른 인공지능 모델 학습 장치의 구성의 예시도이다. 도 2는 화자 분할을 수행하는 실시예들에 따른 인공지능 모델 학습 시스템을 나타내는 도면이다. 도 3는 실시예들에 따른 인공지능 모델의 학습 시 사용되는 학습 데이터의 예시이다. 도 4는 학습된 인공지능 모델을 이용하여 화자 분할을 수행한 결과와 그 성능을 나타낸 도면이다. 도 5는 화자 분할을 수행하는 실시예들에 따른 인공지능 모델 학습 시스템이 자가 증류를 수행한 후의 효과를 나타내는 도면이다. 도 6은 화자 분할을 수행하는 실시예들에 따른 인공지능 모델 학습 방법을 나타낸다. 도 7은 실시예들에 따른 화자 분할을 수행하는 인공지능 모델을 학습하는 장치의 구성도의 예시이다."}
