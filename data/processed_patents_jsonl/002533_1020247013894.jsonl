{"patent_id": "10-2024-7013894", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0115228", "출원번호": "10-2024-7013894", "발명의 명칭": "정보 처리 장치, 정보 처리 방법, 프로그램", "출원인": "소니 세미컨덕터 솔루션즈 가부시키가이샤", "발명자": "에키 료지"}}
{"patent_id": "10-2024-7013894", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "피사체를 촬상함으로써 얻어진 촬상 화상에 대해서 인공 지능 모델을 사용한 화상 처리를 행하는 촬상 장치로부터, 상기 화상 처리의 결과를 나타내는 결과 정보를 취득하고, 취득한 결과 정보에 기초하여, 상기 촬상 장치의촬상 설정 정보, 및 상기 인공 지능 모델의 탐색을 인공 지능을 사용하여 행하는 탐색 처리부와,상기 탐색 처리부가 상기 탐색에 의해 구한 상기 촬상 설정 정보와 상기 인공 지능 모델을 상기 촬상 장치에 적용하는 적용 처리부를 구비한,정보 처리 장치."}
{"patent_id": "10-2024-7013894", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 촬상 장치로부터 취득한 상기 촬상 화상에 대해서 인공 지능 모델을 사용한 화상 처리를행하는 화상 처리부를 구비하고,상기 탐색 처리부는, 상기 촬상 장치에서의 화상 처리와 상기 화상 처리부에 의한 화상 처리의 인식 결과가 다른 경우에, 상기 탐색을 행하는, 정보 처리 장치."}
{"patent_id": "10-2024-7013894", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서, 상기 화상 처리부가 사용하는 인공 지능 모델은, 상기 촬상 장치의 화상 처리에 사용되는 인공지능 모델보다 고성능의 것으로 된, 정보 처리 장치."}
{"patent_id": "10-2024-7013894", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서, 상기 탐색 처리부에서의 탐색에서는, 상기 촬상 장치에서의 화상 처리의 결과가 상기 화상 처리부에 의한 화상 처리의 결과에 가까워지는 인공 지능 모델을 탐색하는, 정보 처리 장치."}
{"patent_id": "10-2024-7013894", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서, 상기 탐색 처리부는, 상기 촬상 화상을 얻을 때의 환경 정보에 기초하여 상기 촬상 설정 정보의 탐색을 행하는, 정보 처리 장치."}
{"patent_id": "10-2024-7013894", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5항에 있어서, 상기 환경 정보는, 상기 촬상 장치의 설치 장소에 관한 정보를 포함하는, 정보 처리 장치."}
{"patent_id": "10-2024-7013894", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제5항에 있어서, 상기 환경 정보는, 상기 촬상 장치의 수광부에 입사하는 광에 관한 정보를 포함하는, 정보 처리 장치."}
{"patent_id": "10-2024-7013894", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1항에 있어서, 인공 지능 모델의 상기 탐색은, 상기 촬상 장치의 성능에 기초한 것으로 된, 정보 처리 장치."}
{"patent_id": "10-2024-7013894", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서, 상기 촬상 장치의 성능은, 화상 처리에 관한 성능으로 된, 정보 처리 장치."}
{"patent_id": "10-2024-7013894", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제1항에 있어서, 상기 탐색에 의해 얻어지는 상기 촬상 설정 정보와 상기 인공 지능 모델은, 애플리케이션에 따라 다른 것으로 된, 정보 처리 장치.공개특허 10-2024-0115228-2-청구항 11 제1항에 있어서, 상기 탐색 처리부는, 상기 촬상 장치와 당해 정보 처리 장치를 포함하는 각 장치에서 실행하는처리의 분담에 관한 탐색 처리를 행하는, 정보 처리 장치."}
{"patent_id": "10-2024-7013894", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항에 있어서, 상기 각 장치에서 실행하는 처리는, 상기 결과 정보를 사용하여 행하는 분석 처리를포함하는, 정보 처리 장치."}
{"patent_id": "10-2024-7013894", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제2항에 있어서, 상기 화상 처리부에 의한 화상 처리에서는, 상기 촬상 장치에서 얻어진 촬상 화상 대신에 생성된 대체 화상이 사용되는, 정보 처리 장치."}
{"patent_id": "10-2024-7013894", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제13항에 있어서, 상기 대체 화상은, 상기 촬상 장치에서 얻어진 촬상 화상에 기초하여 생성된 가상 화상으로된, 정보 처리 장치."}
{"patent_id": "10-2024-7013894", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제1항에 있어서, 애플리케이션의 선택 정보를 취득하고, 상기 선택 정보에 따라서 상기 촬상 설정 정보와 상기인공 지능 모델을 선택하는 선택 처리부를 구비한, 정보 처리 장치."}
{"patent_id": "10-2024-7013894", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제1항에 있어서, 상기 인공 지능 모델을 사용한 화상 처리는, 인공 지능 모델을 사용한 화상 인식 처리로 된,정보 처리 장치."}
{"patent_id": "10-2024-7013894", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "피사체를 촬상함으로써 얻어진 촬상 화상에 대해서 인공 지능 모델을 사용한 화상 처리를 행하는 촬상 장치로부터, 상기 화상 처리의 결과를 나타내는 결과 정보를 취득하고, 취득한 결과 정보에 기초하여, 상기 촬상 장치의촬상 설정 정보, 및 상기 인공 지능 모델의 탐색을 인공 지능을 사용하여 행하는 탐색 처리와,상기 탐색에 의해 구한 상기 촬상 설정 정보와 상기 인공 지능 모델을 상기 촬상 장치에 적용하는 처리를 컴퓨터 장치가 실행하는,정보 처리 방법."}
{"patent_id": "10-2024-7013894", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "피사체를 촬상함으로써 얻어진 촬상 화상에 대해서 인공 지능 모델을 사용한 화상 처리를 행하는 촬상 장치로부터, 상기 화상 처리의 결과를 나타내는 결과 정보를 취득하고, 취득한 결과 정보에 기초하여, 상기 촬상 장치의촬상 설정 정보, 및 상기 인공 지능 모델의 탐색을 인공 지능을 사용하여 행하는 탐색 기능과,상기 탐색에 의해 구한 상기 촬상 설정 정보와 상기 인공 지능 모델을 상기 촬상 장치에 적용하는 기능을 연산처리 장치에 실행시키는,프로그램."}
{"patent_id": "10-2024-7013894", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 기술에 관한 정보 처리 장치는, 피사체를 촬상함으로써 얻어진 촬상 화상에 대해서 인공 지능 모델을 사용한 화상 처리를 행하는 촬상 장치로부터, 상기 화상 처리의 결과를 나타내는 결과 정보를 취득하고, 취득한 결과 정 보에 기초하여, 상기 촬상 장치의 촬상 설정 정보, 및 상기 인공 지능 모델의 탐색을 인공 지능을 사용하여 행하 는 탐색 처리부와, 상기 탐색 처리부가 상기 탐색에 의해 구한 상기 촬상 설정 정보와 상기 인공 지능 모델을 상 기 촬상 장치에 적용하는 적용 처리부를 구비한 것이다."}
{"patent_id": "10-2024-7013894", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 기술은, 인공 지능 모델의 탐색을 행하는 정보 처리 장치, 정보 처리 방법 및 프로그램의 기술 분야에 관한 것이다."}
{"patent_id": "10-2024-7013894", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "기계 학습 분야의 발전에 수반하여, 다양한 문제에 대한 최적의 해를 얻기 위해서 기계 학습이 사용되고 있다. 예를 들어, 특허문헌 1에서는, 인식 처리부가 DNN(Deep Neural Network)을 사용한 인식 처리를 행하는 기계 학 습부로서 마련되어 있는 기술이 개시되어 있다. 선행기술문헌 특허문헌 (특허문헌 0001) 일본 특허 제6638852호 공보"}
{"patent_id": "10-2024-7013894", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "기계 학습에 의한 화상 인식의 정밀도를 높이는 데 있어서는, 촬상 설정을 적정화하는 것이 중요하게 된다. 즉, 기계 학습에 사용되는 인공 지능이 고성능이어도, 촬상 설정이 적정하지 않으면 화상 인식 결과의 정밀도는 기대한 수준에 미치지 못할 우려가 있다. 본 기술은 이러한 문제를 감안해서 이루어진 것이며, 피사체를 촬상한 촬상 화상에 대해서 인공 지능을 사용한 화상 인식 처리를 행하는 촬상 장치에 대해서, 화상 인식 처리에 사용하는 인공 지능 모델, 및 촬상 설정의 적 정화를 도모함으로써, 화상 인식 정밀도의 향상을 도모하는 것을 목적으로 한다."}
{"patent_id": "10-2024-7013894", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 기술에 관한 정보 처리 장치는, 피사체를 촬상함으로써 얻어진 촬상 화상에 대해서 인공 지능 모델을 사용한 화상 처리를 행하는 촬상 장치로부터, 상기 화상 처리의 결과를 나타내는 결과 정보를 취득하고, 취득한 결과 정보에 기초하여, 상기 촬상 장치의 촬상 설정 정보 및 상기 인공 지능 모델의 탐색을 인공 지능을 사용하여 행 하는 탐색 처리부와, 상기 탐색 처리부가 상기 탐색에 의해 구한 상기 촬상 설정 정보와 상기 인공 지능 모델을 상기 촬상 장치에 적용하는 적용 처리부를 구비한 것이다. 촬상 설정 정보란, 촬상 화상을 얻기 위한 촬상 동작에 관한 설정 정보를 넓게 의미하는 것이다. 구체적으로는, 포커스나 조리개 등과 같은 광학적인 설정이나, 프레임 레이트, 노광 시간, 게인 등과 같은 촬상 화상 신호의 판독 동작에 관한 설정, 나아가 감마 보정 처리, 노이즈 리덕션 처리, 초해상 처리 등, 읽어내진 촬상 화상 신호에 대한 화상 신호 처리에 관한 설정 등을 넓게 포함하는 것이다. 또한, 인공 지능 모델이란, 화상 인식 처리나 화상 검출 처리 등의 화상 처리에 사용되는 인공 지능의 모델이다. 인공 지능 모델의 탐색이란, 예를 들어 화상 처리가 컨볼루션 연산을 포함하는 경우에 있어서의 가 중 계수 등의 각종 처리 파라미터나, 화상 처리가 뉴럴 네트워크를 사용하여 행해지는 경우에 있어서의 네트워 크 구조에 관한 설정 정보(예를 들어, 커널 사이즈의 정보 등을 포함함) 등을 최적화하는 처리이다."}
{"patent_id": "10-2024-7013894", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 첨부 도면을 참조하여, 본 기술에 관한 정보 처리 장치의 실시 형태를 다음의 순서로 설명한다. <1. 정보 처리 시스템> <1-1. 시스템 전체 구성> <1-2. AI 모델 및 AI 애플리케이션의 등록> <1-3. 시스템의 기능 개요> <1-4. 촬상 장치의 구성> <1-5. 정보 처리 장치의 하드웨어 구성> <2. 제1 실시 형태로서의 탐색 처리> <3. 제2 실시 형태로서의 탐색 처리> <4. 제3 실시 형태로서의 탐색 처리> <5. 변형예> <6. 마켓 플레이스의 화면예> <7. 정리> <8. 본 기술> <1. 정보 처리 시스템> <1-1. 시스템 전체 구성> 도 1은 본 기술에 관한 실시 형태로서의 정보 처리 시스템의 개략 구성예를 도시한 블록도이다. 도시된 바와 같이 정보 처리 시스템은, 클라우드 서버와, 유저 단말기와, 복수의 카메라와, 포그 서버와, 관리 서버를 적어도 구비하고 있다. 본 예에서는, 적어도 클라우드 서버, 유저 단말기, 포그 서버 및 관리 서버는, 예를 들어 인터넷 등으로 된 네트워크를 통한 상호 통신을 행하는 것이 가 능하게 구성되어 있다. 클라우드 서버, 유저 단말기, 포그 서버 및 관리 서버는, CPU(Central Processing Unit), ROM(Read Only Memory) 및 RAM(Random Access Memory)을 갖는 마이크로컴퓨터를 구비한 정보 처리 장치로서 구 성되어 있다. 여기서, 유저 단말기는, 정보 처리 시스템을 사용한 서비스의 수혜자인 유저에 의해 사용되는 것이 상 정되는 정보 처리 장치이다. 또한, 관리 서버는, 서비스의 제공자에 의해 사용되는 것이 상정되는 정보 처 리 장치이다. 각 카메라는, 예를 들어 CCD(Charge Coupled Device)형 이미지 센서나 CMOS(Complementary Metal Oxide Semiconductor)형 이미지 센서 등의 이미지 센서를 구비하고, 피사체를 촬상해서 디지털 데이터로서의 화상 데 이터(촬상 화상 데이터)를 얻는다. 또한, 후술하는 바와 같이 각 카메라는, 촬상 화상에 대해서 AI(Artificial Intelligence: 인공 지능)를 사용한 처리(예를 들어, 화상 인식 처리나 화상 검출 처리 등)를 행 하는 기능도 갖고 있다. 이후의 설명에서는, 화상 인식 처리나 화상 검출 처리 등, 화상에 대한 각종 처리를 단순히 「화상 처리」라고 기재한다. 예를 들어, AI(혹은 AI 모델)를 사용한 화상에 대한 각종 처리는 「AI 화 상 처리」라고 기재한다. 각 카메라는, 포그 서버와 데이터 통신 가능하게 구성되며, 예를 들어 AI를 사용한 처리(화상 처리 등)의 결과를 나타내는 처리 결과 정보 등의 각종 데이터를 포그 서버에 송신하거나, 포그 서버로부터 각종 데 이터를 수신하거나 하는 것이 가능하게 된다. 여기서, 도 1에 나타내는 정보 처리 시스템에 대해서는, 예를 들어 각 카메라의 화상 처리에서 얻어지 는 처리 결과 정보에 기초하여, 포그 서버 또는 클라우드 서버가 피사체의 분석 정보를 생성하고, 생성한 분석 정보를 유저 단말기를 통해서 유저에게 열람시킨다는 용도가 상정된다. 이 경우, 각 카메라의 용도로서는, 각종 감시 카메라의 용도를 생각할 수 있다. 예를 들어, 점포나 오피스, 주택 등의 옥내에 대한 감시 카메라, 주차장이나 거리 등의 옥외를 감시하기 위한 감시 카메라(교통 감시 카메 라 등을 포함함), FA(Factory Automation)나 IA(Industrial Automation)에서의 제조 라인의 감시 카메라, 차내 나 차밖을 감시하는 감시 카메라 등의 용도를 들 수 있다. 예를 들어, 점포에서의 감시 카메라의 용도라면, 복수의 카메라를 점포 내의 소정 위치에 각각 배치하여, 유 저가 방문객의 고객층(성별이나 연령층 등)이나 점포 내에서의 행동(동선) 등을 확인할 수 있도록 하는 것을 생 각할 수 있다. 그 경우, 상기한 분석 정보로서는, 이러한 방문객의 고객층의 정보나 점포 내에서의 동선의 정 보 및 정산 계산대에서의 혼잡 상태의 정보(예를 들어, 정산 계산대의 대기 시간) 등을 생성하는 것을 생각할 수 있다. 혹은, 교통 감시 카메라의 용도라면, 각 카메라를 도로 근방의 각 위치에 배치하여, 유저가 통과 차량에 관 한 넘버(차량 번호)나 차의 색, 차종 등의 정보를 인식할 수 있도록 하는 것을 생각할 수 있으며, 그 경우, 상 기한 분석 정보로서는, 이러한 넘버나 차의 색, 차종 등의 정보를 생성하는 것을 생각할 수 있다. 또한, 주차장에 교통 감시 카메라를 사용한 경우는, 주차되어 있는 각 차량을 감시할 수 있도록 카메라를 배치 하여, 의심스러운 행동을 하고 있는 수상한 사람이 각 차량의 주변에 없는지 등을 감시하고, 수상한 사람이 있 을 경우에는, 수상한 사람이 있는 것이나 그 수상한 사람의 속성(성별이나 연령층) 등을 통지하는 것을 생각할 수 있다. 또한, 거리나 주차장의 빈 공간을 감시하여, 유저에게 차를 주차할 수 있는 공간의 장소를 통지하는 것도 생각 할 수 있다. 포그 서버는, 예를 들어 상기한 점포의 감시 용도에서는 각 카메라와 함께 감시 대상의 점포 내에 배치되 는 등, 감시 대상마다 배치되는 것이 상정된다. 이와 같이 점포 등의 감시 대상마다 포그 서버를 마련함으 로써, 감시 대상에 있어서의 복수의 카메라로부터의 송신 데이터를 클라우드 서버가 직접 수신할 필요가없어져, 클라우드 서버의 처리 부담 경감이 도모된다. 또한, 포그 서버는, 감시 대상으로 하는 점포가 복수 있고, 그러한 점포가 모두 동일 계열에 속하는 점포일 경우에는, 점포마다 마련하는 것이 아니라, 그러한 복수의 점포에 대해 하나 마련하는 것도 생각할 수 있다. 즉, 포그 서버는, 감시 대상마다 하나 마련하는 것에 한정되지 않고, 복수의 감시 대상에 대해서 하나의 포 그 서버를 마련하는 것도 가능한 것이다. 또한, 클라우드 서버, 혹은 각 카메라측에 처리 능력이 있는 등의 이유로, 포그 서버의 기능을 클라우 드 서버 혹은 각 카메라측에 부여할 수 있는 경우는, 정보 처리 시스템에 있어서 포그 서버를 생 략하고, 각 카메라를 직접 네트워크에 접속시켜, 복수의 카메라로부터의 송신 데이터를 클라우드 서버 가 직접 수신하도록 해도 된다. <1-2. AI 모델 및 AI 애플리케이션의 등록> 상술한 바와 같이, 정보 처리 시스템에서는, 에지측의 정보 처리 장치인 카메라에서 AI 화상 처리를 행 하고, 클라우드측의 정보 처리 장치인 클라우드 서버에서, 에지측에서의 AI 화상 처리의 결과 정보(예를 들 어 AI를 사용한 화상 인식 처리의 결과 정보)를 사용하여 고도의 애플리케이션 기능을 실현하는 것이다. 여기서, 클라우드측의 정보 처리 장치인 클라우드 서버(혹은 포그 서버를 포함함)에 애플리케이션 기능을 등록하는 방법은 다양하게 생각할 수 있다. 그 일례에 대해서, 도 2를 참조하여 설명한다. 또한, 포그 서버에 대해서는 도 2에서의 도시를 생략하고 있지만, 포그 서버를 구비한 구성으로 되어도 된다. 그 때의 포그 서버는, 클라우드측의 기능의 일부를 부담해도 되고, 에지측의 기능의 일부를 부담해도 된다. 상술한 클라우드 서버와 관리 서버는, 클라우드측의 환경을 구성하는 정보 처리 장치이다. 또한, 카메라는 에지측의 환경을 구성하는 정보 처리 장치이다. 또한, 클라우드측의 정보 처리 장치가 제공하는 각종 서비스를 이용하는 유저가 사용하는 유저 단말기로서는, AI 화상 처리에 사용되는 애플리케이션을 개발하는 유저가 사용하는 애플리케이션 개발자 단 말기(2A)와, 애플리케이션을 이용하는 유저가 사용하는 애플리케이션 이용자 단말기(2B)와, AI 화상 처리에 사 용되는 AI 모델을 개발하는 유저가 사용하는 AI 모델 개발자 단말기(2C) 등이 있다. 또한, 물론, 애플리케이션 개발자 단말기(2A)는 AI 화상 처리를 사용하지 않는 애플리케이션을 개발하는 유저에 의해 사용되어도 된다. 클라우드측의 정보 처리 장치에는, AI에 의한 학습을 행하기 위한 학습용 데이터 세트가 준비되어 있다. AI 모 델을 개발하는 유저는, AI 모델 개발자 단말기(2C)를 이용하여 클라우드측의 정보 처리 장치와 통신을 행하고, 이들의 학습용 데이터 세트를 다운로드한다. 이때, 학습용 데이터 세트가 유료로 제공되어도 된다. 예를 들어, AI 모델 개발자는, 클라우드측의 기능으로서 준비되어 있는 마켓 플레이스(전자 시장)에 개인 정보를 등 록함으로써 마켓 플레이스에 등록된 각종 기능이나 소재의 구입을 가능하게 한 상태에서, 학습용 데이터 세트의 구입을 행해도 된다. AI 모델 개발자는, 학습용 데이터 세트를 사용하여 AI 모델의 개발을 행한 후, AI 모델 개발자 단말기(2C)를 사 용하여 당해 개발 완료된 AI 모델을 마켓 플레이스에 등록한다. 이에 의해, 당해 AI 모델이 다운로드되었을 때 AI 모델 개발자에게 인센티브가 지불되도록 해도 된다. 또한, 애플리케이션을 개발하는 유저는, 애플리케이션 개발자 단말기(2A)를 이용하여 마켓 플레이스로부터 AI 모델을 다운로드하고, 당해 AI 모델을 이용한 애플리케이션(이후, 「AI 애플리케이션」이라고 기재)의 개발을 행한다. 이때, 상술한 바와 같이, AI 모델 개발자에게 인센티브가 지불되어도 된다. 애플리케이션 개발 유저는, 애플리케이션 개발자 단말기(2A)를 사용하여 당해 개발 완료된 AI 애플리케이션을 마켓 플레이스에 등록한다. 이에 의해, 당해 AI 애플리케이션이 다운로드되었을 때 AI 애플리케이션을 개발한 유저에게 인센티브가 지불되도록 해도 된다. AI 애플리케이션을 이용하는 유저는, 애플리케이션 이용자 단말기(2B)를 이용하여 마켓 플레이스로부터 AI 애플 리케이션 및 AI 모델을 자신이 관리하는 에지측의 정보 처리 장치로서의 카메라에 전개(디플로이)하기 위한조작을 행한다. 이때, AI 모델 개발자에게 인센티브가 지불되도록 해도 된다. 이에 의해, 카메라에 있어서 AI 애플리케이션 및 AI 모델을 사용한 AI 화상 처리를 행하는 것이 가능하게 되 고, 화상을 촬상할 뿐만 아니라 AI 화상 처리에 의해 방문객의 검출이나 차량의 검출을 행하는 것이 가능해진다. 또한, 카메라에서는, AI 화상 처리에 의해, 카메라로 촬상된 촬상 화상으로부터 방문객의 속성 정보가 추 출 가능하게 되어 있어도 된다. 이러한 속성 정보는, 카메라로부터 네트워크를 통해서 클라우드측의 정보 처리 장치에 송신된다. 클라우드측의 정보 처리 장치에는, 클라우드 애플리케이션이 전개되어 있고, 각 유저는, 네트워크를 통해서 클라우드 애플리케이션을 이용 가능하게 되어 있다. 그리고 클라우드 애플리케이션 중에는, 방문객의 속성 정 보나 촬상 화상을 사용하여 방문객의 동선을 분석하는 애플리케이션 등이 준비되어 있다. 이러한 클라우드 애 플리케이션은, 애플리케이션 개발 유저 등에 의해 업로드된다. 애플리케이션 이용 유저는, 애플리케이션 이용자 단말기(2B)를 사용하여 동선 분석을 위한 클라우드 애플리케이 션을 이용함으로써, 자신의 점포에 대한 방문객의 동선 분석을 행하고, 해석 결과를 열람하는 것이 가능하게 되 어 있다. 해석 결과의 열람은, 예를 들어 점포의 맵 상에 방문객의 동선이 그래피컬하게 제시됨으로써 행해진 다. 또한, 동선 분석의 결과가 히트 맵의 형태로 표시되어, 방문객의 밀도 등이 제시됨으로써 해석 결과의 열람이 행해져도 된다. 또한, 그러한 정보는, 방문객의 속성 정보마다 표시의 분류가 이루어져 있어도 된다. 클라우드측의 마켓 플레이스에서는, 유저마다 최적화된 AI 모델이 각각 등록되어 있어도 된다. 예를 들어, 어 떤 유저가 관리하고 있는 점포에 배치된 카메라에서 촬상된 촬상 화상이 적절하게 클라우드측의 정보 처리 장치에 업로드되어 축적된다. 서버측의 정보 처리 장치에서는, 업로드된 촬상 화상이 일정 매수 쌓일 때마다 AI 모델의 재학습 처리를 행하여, AI 모델을 갱신해서 마켓 플레이스에 다시 등록하는 처리가 실행된다. 또한, AI 모델의 재학습 처리는, 예를 들어 마켓 플레이스 상에서 유저가 옵션으로서 선택할 수 있도록 해도 된 다. 예를 들어, 점포 내에 배치된 카메라로부터의 어두운 화상을 사용하여 재학습된 AI 모델이 당해 카메라에 전개됨으로써, 어두운 장소에서 촬상된 촬상 화상에 관한 화상 처리의 인식율 등을 향상시킬 수 있다. 또한, 점포 밖에 배치된 카메라로부터의 밝은 화상을 사용하여 재학습된 AI 모델이 당해 카메라에 전개됨으로써, 밝은 장소에서 촬상된 화상에 관한 화상 처리의 인식율 등을 향상시킬 수 있다. 즉, 애플리케이션 이용 유저는, 갱신된 AI 모델을 다시 카메라에 재전개함으로써, 항상 최적화된 처리 결과 정보를 얻는 것이 가능해진다. 또한, AI 모델의 재학습 처리에 대해서는 다시 후술한다. 또한, 카메라로부터 서버측의 정보 처리 장치에 업로드되는 정보(촬상 화상 등)에 개인 정보가 포함되어 있 는 경우에는, 프라이버시의 보호 관점에서 프라이버시에 관한 정보를 삭제한 데이터가 업로드되도록 해도 되고, 프라이버시에 관한 정보가 삭제된 데이터를 AI 모델 개발 유저나 애플리케이션 개발 유저가 이용 가능하게 해도 된다. 상기한 처리의 흐름을 도 3 및 도 4에 나타낸다. 또한, 클라우드측 정보 처리 장치는, 도 1에서의 클라우드 서버나 관리 서버 등이 해당한다. AI 모델 개발자가 LCD(Liquid Crystal Display) 혹은 유기 EL(Electro Luminescence) 패널 등을 포함하는 표시 부를 갖는 AI 모델 개발자 단말기(2C)를 사용하여 마켓 플레이스에 등록되어 있는 데이터 세트의 일람을 열람하 여 원하는 데이터 세트를 선택한 것에 따라, AI 모델 개발자 단말기(2C)는 스텝 S21에서, 당해 선택된 데이터 세트의 다운로드 요구를 클라우드측 정보 처리 장치에 송신한다. 이것을 받아, 클라우드측 정보 처리 장치에서는, 스텝 S1에서, 해당 요구를 접수하고, 스텝 S2에서, 요구된 데 이터 세트를 AI 모델 개발자 단말기(2C)에 송신하는 처리를 행한다. AI 모델 개발자 단말기(2C)에서는, 스텝 S22에서, 데이터 세트를 수신하는 처리를 행한다. 이에 의해, AI 모델 개발자는, 데이터 세트를 사용한 AI 모델의 개발이 가능해진다. AI 모델 개발자가 AI 모델의 개발을 종료한 후, AI 모델 개발자가 개발 완료된 AI 모델을 마켓 플레이스에 등록 하기 위한 조작을 행하면(예를 들어, AI 모델의 명칭이나, 그 AI 모델이 놓여 있는 어드레스 등을 지정하면), AI 모델 개발자 단말기(2C)는, 스텝 S23에서, AI 모델의 마켓 플레이스에의 등록 요구를 클라우드측 정보 처리 장치에 송신한다. 이것을 받아, 클라우드측 정보 처리 장치는, 스텝 S3에서, 해당 등록 요구를 접수하고, 스텝 S4에서, AI 모델의 등록 처리를 행함으로써, 예를 들어 마켓 플레이스 상에서 AI 모델을 표시시킬 수 있다. 이에 의해, AI 모델 개발자 이외의 유저가 AI 모델의 다운로드를 마켓 플레이스로부터 행하는 것이 가능해진다. 예를 들어, AI 애플리케이션의 개발을 행하고자 하는 애플리케이션 개발자는, 애플리케이션 개발자 단말기(2A) 를 사용하여 마켓 플레이스에 등록되어 있는 AI 모델의 일람을 열람한다. 애플리케이션 개발자 단말기(2A)는, 애플리케이션 개발자의 조작(예를 들어, 마켓 플레이스 상의 AI 모델의 하나를 선택하는 조작)에 따라, 스텝 S31에서, 당해 선택된 AI 모델의 다운로드 요구를 클라우드측 정보 처리 장치에 송신한다. 클라우드측 정보 처리 장치는 스텝 S5에서 당해 요구를 접수하고, 스텝 S6에서 AI 모델의 송신을 애플리케이션 개발자 단말기(2A)에 대해서 행한다. 애플리케이션 개발자 단말기(2A)는, 스텝 S32에서, AI 모델의 수신을 행한다. 이에 의해, 애플리케이션 개발자 는, 다른 사람이 개발한 AI 모델을 사용하는 AI 애플리케이션의 개발이 가능해진다. 애플리케이션 개발자가 AI 애플리케이션의 개발을 종료한 후, AI 애플리케이션을 마켓 플레이스에 등록하기 위 한 조작(예를 들어, AI 애플리케이션의 명칭이나 그 AI 모델이 놓여 있는 어드레스 등을 지정하는 조작)을 행하 면, 애플리케이션 개발자 단말기(2A)는 스텝 S33에서, AI 애플리케이션의 등록 요구를 클라우드측 정보 처리 장 치에 송신한다. 클라우드측 정보 처리 장치는, 스텝 S7에서, 당해 등록 요구를 접수하고, 스텝 S8에서, AI 애플리케이션의 등록 을 행함으로써, 예를 들어 마켓 플레이스 상에서 AI 애플리케이션을 표시시킬 수 있다. 이에 의해, 애플리케이 션 개발자 이외의 유저가 AI 애플리케이션을 마켓 플레이스 상에서 선택해서 다운로드하는 것이 가능해진다. 예를 들어, 도 4에 도시하는 바와 같이, AI 애플리케이션을 이용하고자 하는 유저에 의해, 애플리케이션 이용자 단말기(2B)는 스텝 S41에서, 목적 선택을 행한다. 목적 선택에서는, 선택된 목적이 클라우드측 정보 처리 장치 에 송신된다. 이것을 받아, 클라우드측 정보 처리 장치는 스텝 S9에서, 목적에 따른 AI 애플리케이션을 선택하고, 스텝 S10에 서, AI 모델을 선택한다. 예를 들어, 목적에 따른 AI 애플리케이션과 AI 모델이 대응지어진 테이블 데이터가 클라우드측 정보 처리 장치에 기억되어 있어, 목적에 따른 AI 애플리케이션과 AI 모델을 선택하는 것이 가능하 게 되어 있다. 클라우드측 정보 처리 장치는 스텝 S11에서, 선택된 AI 애플리케이션 및 AI 모델을 전개하는 처리를 행한다. 이 전개 처리에서는, AI 애플리케이션 및 AI 모델이 카메라에 송신된다. 이에 따라, 카메라에서는, 스텝 S51에 의해 AI 애플리케이션 및 AI 모델의 전개 처리가 행해진다. 이에 의 해, 카메라에서 촬상된 촬상 화상에 대해서 AI 화상 처리가 가능해진다. 카메라는, 스텝 S52에서, 촬상 동작을 행함으로써 화상의 취득을 행한다. 그리고 카메라는 스텝 S53에서, 취득한 화상에 대한 AI 화상 처리를 행하여, 예를 들어 화상 인식 결과를 얻는다. 카메라는, 스텝 S54에서, 촬상 화상이나 AI 화상 처리의 결과 정보의 송신 처리가 행해진다. 스텝 S54의 정 보 송신에서는, 촬상 화상과 AI 화상 처리의 결과 정보 양쪽을 송신해도 되고, 어느 한쪽만을 송신해도 된다. 이들 정보를 수신한 클라우드측 정보 처리 장치는, 스텝 S12에서, 분석 처리를 행한다. 이 분석 처리에 의해, 예를 들어 방문객의 동선 분석이나, 교통 감시를 위한 차량 분석 처리 등이 행해진다. 클라우드측 정보 처리 장치는 스텝 S13에서, 분석 결과의 제시 처리를 행한다. 이 처리는, 예를 들어 상술한 클라우드 애플리케이션을 유저가 이용함으로써 실현된다.애플리케이션 이용자 단말기(2B)는, 분석 결과의 제시 처리를 받아, 스텝 S42에서 분석 결과를 모니터 등에 표 시시키는 처리를 행한다. 여기까지의 처리로, AI 애플리케이션의 이용자인 유저는, 스텝 S41에서 선택한 목적에 따른 분석 결과를 얻을 수 있다. 또한, 애플리케이션 이용자가 관리하고 있는 카메라가 촬상한 화상에 최적화하도록 AI 모델의 갱신이 행해져 도 된다. 예를 들어, 카메라가 스텝 S52, S53, S54의 각 처리를 반복하여 실행함으로써, 클라우드측 정보 처리 장치에 는, 카메라로부터 수신한 촬상 화상이나 AI 화상 처리의 결과 정보가 축적되어 간다. 그리고 클라우드측 정보 처리 장치는, 일정량의 정보가 축적되었을 경우에, 스텝 S14에서, AI 모델의 갱신 처리 를 행한다. 이 처리는, AI 모델에 새로운 데이터를 부여함으로써 AI 모델의 재학습을 행하는 처리이다. 클라우드측 정보 처리 장치는 스텝 S15에서, 갱신된 새로운 AI 모델을 전개하는 처리를 행한다. 이 전개 처리를 받아, 카메라에서는 스텝 S55에서 새로운 AI 모델을 전개하는 처리가 실행된다. 또한, AI 애플리케이션에 대해서도 갱신되어 있는 경우에는, 스텝 S55의 처리에서, 갱신된 AI 애플리케이션을 또한 전개해도 된다. <1-3. 시스템의 기능 개요> 본 실시 형태에서는, 정보 처리 시스템을 사용한 서비스로서, 고객으로서의 유저가 각 카메라의 AI 화 상 처리에 관한 기능의 종별을 선택할 수 있는 서비스를 상정하고 있다. 기능의 종별 선택이란, 예를 들어 화 상 인식 기능과 화상 검출 기능 등을 선택해도 되고, 특정 피사체에 관한 화상 인식 기능이나 화상 검출 기능을 발휘하도록 더욱 세밀한 종별을 선택해도 된다. 예를 들어, 비지니스 모델로서, 서비스 제공자는, AI에 의한 화상 인식 기능을 가진 카메라나 포그 서버 를 유저에게 판매하여, 그러한 카메라나 포그 서버를 감시 대상이 되는 장소에 설치시킨다. 그리고 상술 한 바와 같은 분석 정보를 유저에게 제공하는 서비스를 전개한다. 이때, 고객에 따라서는, 예를 들어 점포 감시의 용도나 교통 감시의 용도 등, 시스템에 요구하는 용도가 다르기 때문에, 고객이 요구하는 용도에 대응한 분석 정보가 얻어지도록, 카메라가 갖는 AI 화상 처리 기능을 선택 적으로 설정하는 것을 가능하게 한다. 본 예에서는, 이러한 카메라의 AI 화상 처리 기능을 선택적으로 설정하는 기능을 관리 서버가 갖는다. 또한, 관리 서버의 기능을 클라우드 서버나 포그 서버가 구비하고 있어도 된다. 여기서, 클라우드측의 정보 처리 장치인 클라우드 서버나 관리 서버와, 에지측의 정보 처리 장치인 카메 라의 접속에 대해서, 도 5를 참조하여 설명한다. 클라우드측의 정보 처리 장치에는, Hub를 통해서 이용 가능한 기능인 재학습 기능과 디바이스 관리 기능과 마켓 플레이스 기능이 실장되어 있다. Hub는, 에지측 정보 처리 장치에 대해서 시큐리티로 보호된 신뢰성이 높은 통신을 행한다. 이에 의해, 에지측 정보 처리 장치에 대해서 각종 기능을 제공할 수 있다. 재학습 기능은, 재학습을 행하여 새롭게 최적화된 AI 모델의 제공을 행하는 기능이며, 이에 의해, 새로운 학습 소재에 기초하는 적절한 AI 모델의 제공이 행해진다. 디바이스 관리 기능은, 에지측 정보 처리 장치로서의 카메라 등을 관리하는 기능이며, 예를 들어 카메라 에 전개된 AI 모델의 관리나 감시, 그리고 문제의 검출이나 트러블 슈팅 등의 기능을 제공할 수 있다. 또한, 디바이스 관리 기능은, 인증된 유저에 의한 안전한 액세스를 보호한다. 마켓 플레이스 기능은, 상술한 AI 모델 개발자에 의해 개발된 AI 모델이나 애플리케이션 개발자에 의해 개발된 AI 애플리케이션을 등록하는 기능이나, 그러한 개발물을 허가된 에지측 정보 처리 장치에 전개하는 기능 등을 제공한다. 또한, 마켓 플레이스 기능은, 개발물의 전개에 따른 인센티브의 지불에 관한 기능도 제공된다. 에지측 정보 처리 장치로서의 카메라에는, 에지 런타임이나 AI 애플리케이션 및 AI 모델이나 이미지 센서 (IS)를 구비하고 있다. 에지 런타임은, 카메라에 전개된 애플리케이션의 관리나 클라우드측 정보 처리 장치와의 통신을 행하기 위한 임베디드 소프트웨어 등으로서 기능한다. AI 모델은, 상술한 바와 같이, 클라우드측 정보 처리 장치에서의 마켓 플레이스에 등록된 AI 모델을 전개한 것 이며, 이에 의해 카메라는 촬상 화상을 사용하여 목적에 따른 AI 화상 처리의 결과 정보를 얻을 수 있다. 도 6을 참조하여, 관리 서버가 갖는 기능의 개요를 설명한다. 도시된 바와 같이 관리 서버는, 애플리케이션 설정 기능(F1) 및 처리 분담 탐색 기능을 갖는다. 애플리케이션 설정 기능(F1)은, 정보 처리 시스템의 애플리케이션을 설정하는 기능이다. 여기서 말하는 애플리케이션이란, 상술한 AI 애플리케이션이며, 점포 감시나 교통 감시 등의 용도에 따라서 선택되는 것이다. 애플리케이션 설정 기능(F1)은, 고객이 요망하는 용도에 대응한 분석 정보가 얻어지도록, 정보 처리 시스템 의 기능 설정을 행하는 기능이 된다. 구체적으로, 애플리케이션 설정 기능(F1)의 처리로서, 관리 서버는, 유저 단말기(도 2에서의 애플리케이 션 이용자 단말기(2B)에 상당)로부터의 AI 애플리케이션의 선택의 접수 처리나, 선택된 AI 애플리케이션에 대응 하는 AI 화상 처리 기능이 얻어지도록 하기 위한 각 카메라에 대한 AI의 설정 처리, 및 카메라의 AI 화상 처리의 결과에 기초하여 생성하는 분석 정보로서, 선택된 AI 애플리케이션에 대응하는 분석 정보가 얻어지도록 하기 위한 분석 처리의 처리 내용을 선택해서 설정하는 선택 설정 처리를 행한다. 분석 처리의 선택 설정 처리 에 대해서는, 당해 분석 처리를 클라우드 서버가 행하는 경우에는 클라우드 서버를 대상으로 해서 행하고, 포그 서버가 행하는 경우는 포그 서버를 대상으로 해서 행한다. 또한, 분석 처리란, 예를 들어 동선을 분석하는 처리나, 교통량을 분석하는 처리 등이다. 예를 들어, 동선을 분석하는 처리라면, 카메라가 촬상한 촬상 화상마다, 인물을 검출하는 화상 인식 처리를 실시한 인식 결과 정보를 얻는다. 그리고 해당 인식 결과 정보에 기초하여 각 촬상 화상의 촬상 시각 및 검출 대상의 인물이 검 출된 화소 영역을 특정하고, 최종적으로 당해 인물의 점포 내에서의 움직임을 파악함으로써, 대상 인물의 동선 을 분석한다. 특정 인물의 움직임뿐만 아니라, 점포를 방문한 방문객의 움직임을 전체적으로 파악하는 경우에는, 방문객마다 이러한 처리를 행하여, 마지막으로 통계 처리를 실시함으로써, 방문객의 일반적인 동선 등을 분석할 수 있다. 처리 분담 탐색 기능(F2)은, 유저에 대한 분석 정보의 제시에 이르기까지의 일련의 처리에 대해서, 어느 부분의 처리를 어느 장치에서 행할지와 같은 처리 분담을 최적화하기 위해서, AI를 사용한 탐색을 행하는 기능을 의미 한다. 또한, 이 처리 분담 탐색 기능(F2)의 상세에 대해서는 후에 다시 설명한다. 도 7은 클라우드 서버가 갖는 기능의 개요를 설명하기 위한 도면이다. 도시된 바와 같이 클라우드 서버는, 클라우드측 AI 화상 처리 기능(F3)과 촬상 설정 탐색 기능(F4)과 AI 모 델 탐색 기능(F5)을 갖는다. 클라우드측 AI 화상 처리 기능(F3)은, 각 카메라로부터 보내져 온 촬상 화상에 대해서 AI 화상 처리를 행하 는 기능이다. 클라우드 서버에서 실행되는 AI 화상 처리를 「클라우드측 AI 화상 처리」라고 기재한다. 그 리고 클라우드측 AI 화상 처리에 사용되는 AI 모델을 「클라우드측 AI 모델」이라고 기재한다. 클라우드측 AI 화상 처리로서는, 예를 들어 타깃으로 하는 피사체를 인식하는 화상 인식 처리를 행한다. 여기 서의 타깃으로서는, 화상으로부터의 검출 대상이 될 수 있는 물체를 가리킨다. 정보 처리 시스템의 용도 등에 따라, 어떠한 물체가 타깃으로 될지는 다르지만, 모든 물체가, 여기서 말하는 타깃으로 될 가능성이 있다. 어디까지나 일부이지만 예시하면, 사람을 포함하는 동물, 이동체(자동차, 자전거, 항공기 등), 식물(야채, 과실, 수목 등), 공업 제품이나 부품, 건조물, 시설, 산, 바다, 강, 별, 태양, 구름 등, 모든 물체가 해당될 가 능성이 있다. 클라우드측 AI 화상 처리에 사용되는 AI는, 카메라에서의 AI 화상 처리에 사용되는 AI와는 다른 AI로 되어 있다. 또한, 이하의 설명에서는, AI 화상 처리로서 AI를 사용한 화상 인식 처리를 일례로서 설명하지만, 본 실시 형태 는 이것에 한정되는 것이 아니라, 후술하는 바와 같이 화상 검출 처리 등 다른 기능 종별의 AI 화상 처리이어도된다. 촬상 설정 탐색 기능(F4)은, 카메라로부터 AI 화상 처리의 결과를 나타내는 화상 인식의 결과 정보(이후, 「 인식 결과 정보」라고 기재)를 취득하고, 취득한 인식 결과 정보에 기초하여, 카메라의 촬상 설정 정보를 AI 를 사용하여 탐색하는 기능이다. 여기서, 촬상 설정 정보(이하, 단순히 「촬상 설정」이라고도 함)란, 촬상 화 상을 얻기 위한 촬상 동작에 관한 설정 정보를 넓게 의미하는 것이다. 구체적으로는, 포커스나 조리개 등과 같 은 광학적인 설정이나, 프레임 레이트, 노광 시간, 게인 등과 같은 촬상 화상 신호의 판독 동작에 관한 설정, 나아가 감마 보정 처리, 노이즈 리덕션 처리, 초해상 처리 등, 읽어내진 촬상 화상 신호에 대한 화상 신호 처리 에 관한 설정 등을 넓게 포함하는 것이다. AI 모델 탐색 기능(F5)은, 카메라로부터 AI 화상 처리의 결과를 나타내는 인식 결과 정보를 취득하고, 취득 한 인식 결과 정보에 기초하여, 카메라에서의 화상 인식 처리에 사용되는 최적의 AI 모델의 탐색을 다른 AI 를 사용하여 행하는 기능이다. 여기서, 카메라에서의 화상 인식 처리에 사용되는 AI 모델을 「에지측 AI 모 델」이라고 기재한다. 즉, AI 모델의 탐색이란, 에지측 AI 모델의 탐색이며, 예를 들어 화상 인식 처리가 컨볼루션 연산을 포함하는 CNN(Convolutional Neural Network) 등에서의 가중 계수 등의 각종 처리 파라미터나 네트워크 구조에 관한 설정 정보(예를 들어, 커널 사이즈의 정보 등을 포함함) 등을 최적화하는 처리이다. 클라우드 서버가 이러한 촬상 설정 탐색 기능(F4), AI 모델 탐색 기능(F5), 즉, AI를 사용하여 카메라의 촬상 설정 정보나 에지측 AI 모델을 탐색하는 기능을 가짐으로써, 상술한 애플리케이션 설정 기능(F1)으로 기능 설정이 행해진 AI 화상 처리에 대해서, 화상 인식 결과를 양호하게 하는 촬상 설정이 행해지도록 도모됨과 함께, 실제의 사용 환경에 따른 적절한 에지측 AI 모델을 사용하여 AI 화상 처리가 행해지게 된다. 또한, 이러한 촬상 설정 탐색 기능(F4), AI 모델 탐색 기능(F5)의 상세에 대해서는 후에 다시 설명한다. <1-4. 촬상 장치의 구성> 도 8은 카메라의 내부 구성예를 나타낸 블록도이다. 도시된 바와 같이 카메라는, 촬상 광학계, 광학계 구동부, 이미지 센서(IS), 제어부, 메모리부 , 통신부를 구비하고 있다. 이미지 센서(IS)와 제어부와 메모리부와 통신부는 버스를 통해서 접속되어, 서로 데이터 통신을 행하는 것이 가능하게 되어 있다. 촬상 광학계는, 커버 렌즈, 줌 렌즈, 포커스 렌즈 등의 렌즈나 조리개(아이리스) 기구를 구비한다. 이 촬 상 광학계에 의해, 피사체로부터의 광(입사광)이 유도되어, 이미지 센서(IS)의 수광면에 집광된다. 광학계 구동부는, 촬상 광학계가 갖는 줌 렌즈, 포커스 렌즈 및 조리개 기구의 구동부를 포괄적으로 나 타낸 것이다. 구체적으로, 광학계 구동부는, 이들 줌 렌즈, 포커스 렌즈, 조리개 기구 각각을 구동하기 위 한 액추에이터 및 해당 액추에이터의 구동 회로를 갖고 있다. 제어부는, 예를 들어 CPU, ROM 및 RAM을 갖는 마이크로컴퓨터를 구비해서 구성되며, CPU가 ROM에 기억되어 있는 프로그램, 또는 RAM에 로드된 프로그램에 따라서 각종 처리를 실행함으로써, 카메라의 전체 제어를 행 한다. 또한, 제어부는, 광학계 구동부에 대해서 줌 렌즈, 포커스 렌즈, 조리개 기구 등의 구동 지시를 행한다. 광학계 구동부는 이들 구동 지시에 따라서 포커스 렌즈나 줌 렌즈의 이동, 조리개 기구의 조리개 블레이드의 개폐 등을 실행시키게 된다. 또한, 제어부는, 메모리부에 대한 각종 데이터의 기입이나 판독에 관한 제어를 행한다. 메모리부는, 예를 들어 HDD(Hard Disk Drive)나 플래시 메모리 장치 등의 불휘발성 기억 디바이스로 되고, 이미지 센서(IS)로부터 출력된 화상 데이터의 보존 장소(기록처)로서 사용된다. 또한, 제어부는, 통신부를 통해서 외부 장치와의 사이에서 각종 데이터 통신을 행한다. 본 예에서의 통신부는, 적어도 도 1에 나타낸 포그 서버(혹은 클라우드 서버)와의 사이에서의 데이터 통신을 행하 는 것이 가능하게 구성되어 있다. 이미지 센서(IS)는, 예를 들어 CCD형, CMOS형 등의 이미지 센서로서 구성되어 있다. 이미지 센서(IS)는, 촬상부, 화상 신호 처리부, 센서내 제어부, AI 화상 처리부, 메모리부 , 통신 I/F를 구비하고, 각각이 버스를 통해서 서로 데이터 통신 가능하게 되어 있다. 촬상부는, 포토다이오드 등의 광전 변환 소자를 갖는 화소가 2차원으로 배열된 화소 어레이부와, 화소 어레 이부가 구비하는 각각의 화소로부터 광전 변환에 의해 얻어진 전기 신호를 읽어내는 판독 회로를 구비하고 있어, 해당 전기 신호를 촬상 화상 신호로서 출력하는 것이 가능하게 되어 있다. 판독 회로에서는, 광전 변환에 의해 얻어진 전기 신호에 대해서, 예를 들어 CDS(Correlated Double Sampling) 처리, AGC(Automatic Gain Control) 처리 등을 실행하고, 또한 A/D(Analog/Digital) 변환 처리를 행한다. 화상 신호 처리부는, A/D 변환 처리 후의 디지털 데이터로서의 촬상 화상 신호에 대해서, 전처리, 동시화 처리, YC 생성 처리, 해상도 변환 처리, 코덱 처리 등을 행한다. 전처리에서는, 촬상 화상 신호에 대해서 R, G, B의 흑색 레벨을 소정의 레벨로 클램프하는 클램프 처리나, R, G, B의 색 채널간의 보정 처리 등을 행한다. 동시화 처리에서는, 각 화소에 관한 화상 데이터가, R, G, B 모든 색 성분을 갖도록 하는 색 분리 처리를 실시한다. 예를 들어, 베이어 배열의 컬러 필터를 사용한 촬상 소자의 경우는, 색 분리 처리로서 디모자이크 처리가 행해진다. YC 생성 처리에서는, R, G, B의 화상 데이터로부터, 휘도(Y) 신호 및 색(C) 신호를 생성(분리)한다. 해상도 변환 처리에서는, 각종 신호 처리가 실시된 화상 데이 터에 대해서, 해상도 변환 처리를 실행한다. 코덱 처리에서는, 상기 각종 처리가 실시된 화상 데이터에 대해서, 예를 들어 기록용이나 통신용의 부호화 처리, 파일 생성을 행한다. 코덱 처리에서는, 동화상의 파일 형식으로서, 예를 들어 MPEG-2(MPEG: Moving Picture Experts Group)나 H.264 등의 형식에 의한 파일 생성을 행하는 것이 가능해진다. 또한 정지 화상 파일 로서 JPEG(Joint Photographic Experts Group), TIFF(Tagged Image File Format), GIF(Graphics Interchange Format) 등의 형식의 파일 생성을 행하는 것도 생각할 수 있다. 센서내 제어부는, 촬상부에 대한 지시를 행하여 촬상 동작의 실행 제어를 행한다. 마찬가지로, 화상 신호 처리부에 대해서도 처리의 실행 제어를 행한다. AI 화상 처리부는, 촬상 화상에 대해서 AI 화상 처리로서의 화상 인식 처리를 행한다. 카메라에서 실행 되는 AI 화상 처리를 「에지측 AI 화상 처리」라고 기재한다. 에지측 AI 화상 처리로서는, 타깃으로 하는 피사체를 인식하는 처리를 행한다. 에지측 AI 화상 처리에서의 타 깃은, 클라우드측 AI 화상 처리에서의 타깃과 마찬가지로 다양하게 생각할 수 있다. AI에 의한 에지측 화상 인식 기능은, 예를 들어 CPU나 FPGA(Field Programmable Gate Array), DSP(Digital Signal Processor) 등, 프로그래머블한 연산 처리 장치를 사용하여 실현할 수 있다. AI 화상 처리부에서 실현 가능한 에지측 화상 인식의 기능은, 에지측 AI 화상 처리의 알고리즘을 변경함으 로써 전환하는 것이 가능해진다. 바꾸어 말하면, 에지측 AI 화상 처리에 사용되는 에지측 AI 모델을 전환함으 로써, AI 화상 처리의 기능 종별을 전환할 수 있다. 에지 AI 화상 처리의 기능 종별에 대해서는 다양하게 생각 할 수 있지만, 예를 들어 이하에 예시하는 바와 같은 종별을 들 수 있다. ·클래스 식별 ·시맨틱 세그멘테이션 ·인물 검출 ·차량 검출 ·타깃의 트래킹 ·OCR(Optical Character Recognition: 광학 문자 인식) 상기 기능 종별 중, 클래스 식별은, 타깃의 클래스를 식별하는 기능이다. 여기서 말하는 「클래스」란, 물체의 카테고리를 나타내는 정보이며, 예를 들어 「사람」 「자동차」 「비행기」 「배」 「트럭」 「새」 「고양이」 「개」 「사슴」 「개구리」 「말」 등을 구별하는 것이다. 타깃의 트래킹이란, 타깃으로 된 피사체의 추종을 행하는 기능이며, 해당 피사체의 위치의 이력 정보를 얻는 기 능이라고 환언할 수 있는 것이다. 메모리부에는, 화상 신호 처리부에 의해 얻어진 촬상 화상 데이터 등의 각종 데이터의 보존 장소로서 사용된다. 또한, 본 예에서 메모리부는, AI 화상 처리부가 에지측 AI 화상 처리의 과정에서 사용하는 데이터의 일시적인 기억에도 사용하는 것이 가능해진다. 또한, 메모리부에는, AI 화상 처리부에서 사용되는 AI 애플리케이션이나 AI 모델의 정보가 기억된다. 또한, AI 애플리케이션이나 AI 모델의 정보는, 후술하는 컨테이너 기술을 사용하여, 컨테이너 등으로서 메모리 부에 전개되어도 된다. 에지측 AI 화상 처리에 사용되는 에지측 AI 모델을 메모리부에 전개함으로써, AI 화상 처리의 기능 종별을 변경하거나, 재학습에 의해 성능의 향상이 도모된 AI 모델로 변경하거나 할 수 있 다. 또한, 상술한 바와 같이 본 실시 형태에서는 화상 인식에 사용되는 AI 모델이나 AI 애플리케이션에 관한 예에 기초한 설명을 행하고 있지만, 이것에 한정되지 않고, AI 기술을 사용하여 실행되는 프로그램 등이 대상으로 되 어 있어도 된다. 또한, 메모리부의 용량이 작은 경우에는, AI 애플리케이션이나 AI 모델의 정보는, 컨테이너 기술을 사용하 여, 컨테이너 등으로서 메모리부 등 이미지 센서(IS) 밖의 메모리에 전개한 후, AI 모델만을 하기에서 설명 하는 통신 I/F를 통해서 이미지 센서(IS) 내의 메모리부에 저장시키도록 해도 된다. 통신 I/F는, 이미지 센서(IS)의 외부에 있는 제어부나 메모리부 등과의 통신을 행하는 인터페이스 이다. 통신 I/F는, 화상 신호 처리부가 실행하는 프로그램이나 AI 화상 처리부가 이용하는 AI 애 플리케이션이나 AI 모델 등을 외부로부터 취득하기 위한 통신을 행하고, 이미지 센서(IS)가 구비하는 메모리부 에 기억시킨다. 이에 의해, AI 모델이 이미지 센서(IS)가 구비하는 메모리부의 일부에 기억되어, AI 화상 처리부에 의 한 이용이 가능해진다. AI 화상 처리부는, 이와 같이 하여 얻어진 AI 애플리케이션이나 AI 모델을 사용하여 소정의 화상 인식 처리 를 행함으로써 목적에 준한 피사체의 인식을 행한다. AI 화상 처리의 인식 결과 정보는, 통신 I/F를 통해서 이미지 센서(IS)의 외부에 출력된다. 즉, 이미지 센서(IS)의 통신 I/F로부터는, 화상 신호 처리부로부터 출력되는 화상 데이터뿐만 아니라, AI 화상 처리의 인식 결과 정보가 출력된다. 또한, 이미지 센서(IS)의 통신 I/F로부터는, 화상 데이터와 인식 결과 정보 중 어느 한쪽만을 출력시킬 수 도 있다. 예를 들어, 상술한 AI 모델의 재학습 기능을 이용하는 경우에는, 재학습 기능에 사용되는 촬상 화상 데이터가 통신 I/F 및 통신부를 통해서 이미지 센서(IS)로부터 클라우드측 정보 처리 장치에 업로드된다. 또한, AI 모델을 사용한 추론을 행하는 경우에는, AI 화상 처리의 인식 결과 정보가 통신 I/F 및 통신부 를 통해서 이미지 센서(IS)로부터 카메라 밖의 다른 정보 처리 장치에 출력된다. 이미지 센서(IS)의 구성은 다양하게 생각할 수 있다. 여기서는, 이미지 센서(IS)가 2층으로 적층된 구조를 구 비하고 있는 예를 설명한다. 이미지 센서(IS)는, 도 9에 도시하는 바와 같이, 2개의 다이가 적층된 1칩의 반도체 장치로서 구성되어 있다. 이미지 센서(IS)는, 도 8에 나타내는 촬상부로서의 기능을 구비하는 다이 D1과, 화상 신호 처리부와 센 서내 제어부와 AI 화상 처리부와 메모리부와 통신 I/F를 구비한 다이 D2가 적층되어 구성되어 있다. 다이 D1과 다이 D2는, 예를 들어 Cu-Cu 접합에 의해 전기적으로 접속되어 있다. 카메라에 AI 모델이나 AI 애플리케이션 등을 전개하는 방법은 다양하게 생각할 수 있다. 일례로서 컨테이너 기술을 사용한 예를 설명한다. 카메라에서는, 도 8에 나타내는 제어부로서의 CPU나 GPU(Graphics Processing Unit)나 ROM이나 RAM 등 의 각종 하드웨어 상에 오퍼레이션 시스템이 인스톨되어 있다(도 10 참조). 오퍼레이션 시스템은, 카메라에서의 각종 기능을 실현하기 위해서 카메라의 전체 제어를 행하는 기본 소프트 웨어이다.오퍼레이션 시스템 상에는, 범용 미들웨어가 인스톨되어 있다. 범용 미들웨어는, 예를 들어 하드웨어로서의 통신부를 사용한 통신 기능이나, 하드웨어로서의 표시부(모니터 등)를 사용한 표시 기능 등의 기본적 동작을 실현하기 위한 소프트웨어이다. 오퍼레이션 시스템 상에는, 범용 미들웨어뿐만 아니라 오케스트레이션 툴 및 컨테이너 엔진이 인스톨되어 있다. 오케스트레이션 툴 및 컨테이너 엔진은, 컨테이너의 동작 환경으로서의 클러스터를 구축함으로 써, 컨테이너의 전개나 실행을 행한다. 또한, 도 5에 나타내는 에지 런타임은 도 10에 나타내는 오케스트레이션 툴 및 컨테이너 엔진에 상당한 다. 오케스트레이션 툴은, 컨테이너 엔진에 대해서 상술한 하드웨어 및 오퍼레이션 시스템의 리소 스의 할당을 적절하게 행하게 하기 위한 기능을 갖는다. 오케스트레이션 툴에 의해 각 컨테이너가 소 정의 단위(후술하는 포드)로 모아지고, 각 포드가 논리적으로 다른 에어리어로 된 워커 노드(후술)에 전개된다. 컨테이너 엔진은, 오퍼레이션 시스템에 인스톨되는 미들웨어의 하나이며, 컨테이너를 동작시키는 엔진이다. 구체적으로는, 컨테이너 엔진은, 컨테이너 내의 미들웨어가 구비하는 설정 파일 등에 기초 하여 하드웨어 및 오퍼레이션 시스템의 리소스(메모리나 연산 능력 등)를 컨테이너에 할당하는 기 능을 갖는다. 또한, 본 실시 형태에서 할당되는 리소스는, 카메라가 구비하는 제어부 등의 리소스뿐만 아니라, 이미지 센서(IS)가 구비하는 센서내 제어부나 메모리부나 통신 I/F 등의 리소스도 포함된다. 컨테이너는, 소정의 기능을 실현하기 위한 애플리케이션과 라이브러리 등의 미들웨어를 포함하여 구성된다. 컨테이너는, 컨테이너 엔진에 의해 할당된 하드웨어 및 오퍼레이션 시스템의 리소스를 사용하 여 소정의 기능을 실현하기 위해서 동작한다. 본 실시 형태에서는, 도 5에 나타내는 AI 애플리케이션 및 AI 모델은 컨테이너 중 1개에 상당한다. 즉, 카 메라에 전개된 각종 컨테이너 중 1개는, AI 애플리케이션 및 AI 모델을 사용한 소정의 AI 화상 처리 기 능을 실현한다. 컨테이너 엔진 및 오케스트레이션 툴에 의해 구축되는 클러스터의 구체적인 구성예에 대해서 도 11 을 참조하여 설명한다. 또한 클러스터는, 하나의 카메라가 구비하는 하드웨어뿐만 아니라 다른 장 치가 구비하는 다른 하드웨어의 리소스를 이용하여 기능이 실현되도록 복수의 기기에 걸쳐서 구축되어도 된다. 오케스트레이션 툴은, 컨테이너의 실행 환경의 관리를 워커 노드 단위로 행한다. 또한, 오케스트 레이션 툴은, 워커 노드 전체를 관리하는 마스터 노드를 구축한다. 워커 노드에서는, 복수의 포드가 전개된다. 포드는, 1개 또는 복수의 컨테이너를 포함하여 구 성되며, 소정의 기능을 실현한다. 포드는, 오케스트레이션 툴에 의해 컨테이너를 관리하기 위한 관리 단위가 된다. 워커 노드에서의 포드의 동작은, 포드 관리 라이브러리에 의해 제어된다. 포드 관리 라이브러리는, 논리적으로 할당된 하드웨어의 리소스를 포드에 이용시키기 위한 컨테이 너 런타임이나 마스터 노드로부터 제어를 접수하는 에이전트나 포드간의 통신이나 마스터 노드와의 통신을 행하는 네트워크 프록시 등을 갖고 구성되어 있다. 즉, 각 포드는, 포드 관리 라이브러리에 의해 각 리소스를 사용한 소정의 기능을 실현 가능하게 된다. 마스터 노드는, 포드의 전개를 행하는 애플리케이션 서버와, 애플리케이션 서버에 의한 컨테이 너의 전개 상황을 관리하는 매니저와, 컨테이너를 배치하는 워커 노드를 결정하는 스케줄러 와, 데이터 공유를 행하는 데이터 공유부를 포함하여 구성되어 있다. 도 10 및 도 11에 나타내는 구성을 이용함으로써, 컨테이너 기술을 사용하여 상술한 AI 애플리케이션 및 AI 모 델을 카메라의 이미지 센서(IS)에 전개하는 것이 가능해진다. 또한, 상술한 바와 같이, AI 모델에 대해서, 도 8의 통신 I/F를 통해서 이미지 센서(IS) 내의 메모리부(4 5)에 저장시켜, 이미지 센서(IS) 내에서 AI 화상 처리를 실행시키도록 해도 되고, 도 10 및 도 11에 나타내는 구성을 이미지 센서(IS) 내의 메모리부 및 센서내 제어부에 전개하여, 이미지 센서(IS) 내에서 컨테이 너 기술을 사용하여 상술한 AI 애플리케이션 및 AI 모델을 실행시켜도 된다. <1-5. 정보 처리 장치의 하드웨어 구성> 정보 처리 시스템이 구비하는 클라우드 서버, 유저 단말기, 포그 서버, 관리 서버 등의 정보 처리 장치의 하드웨어 구성에 대해서 도 12를 참조하여 설명한다. 정보 처리 장치는 CPU를 구비하고 있다. CPU는, 상술한 각종 처리를 행하는 연산 처리부로서 기능하며, ROM이나 예를 들어 EEP-ROM(Electrically Erasable Programmable Read-Only Memory) 등의 불휘 발성 메모리부에 기억되어 있는 프로그램 또는 기억부로부터 RAM에 로드된 프로그램에 따라서 각종 처리를 실행한다. RAM에는 또한, CPU가 각종 처리를 실행하는데 있어서 필요한 데이터 등도 적절하게 기억된다. 또한, 클라우드 서버로서의 정보 처리 장치가 구비하는 CPU는, 상술한 각 기능을 실현하기 위한 탐색 처 리부 및 송신 처리부를 구비하고 있다. 그리고 탐색 처리부는, 촬상 설정 탐색 기능(F4)과 AI 모델 탐색 기능 (F5)을 실현한다. CPU, ROM, RAM, 불휘발성 메모리부는, 버스를 통해서 서로 접속되어 있다. 이 버스 에는 또한, 입출력 인터페이스(I/F)도 접속되어 있다. 입출력 인터페이스에는, 조작자나 조작 디바이스를 포함하는 입력부가 접속된다. 예를 들어 입력부로서는, 키보드, 마우스, 키, 다이얼, 터치 패널, 터치 패드, 리모트 컨트롤러 등의 각종 조작자나 조작 디바이스가 상정된다. 입력부에 의해 유저의 조작이 검지되고, 입력된 조작에 따른 신호는 CPU에 의해 해석된다. 또한 입출력 인터페이스에는, LCD 혹은 유기 EL 패널 등을 포함하는 표시부나, 스피커 등을 포함하는 음성 출력부가 일체 또는 별체로서 접속된다. 표시부는 각종 표시를 행하는 표시부이며, 예를 들어 컴퓨터 장치의 하우징에 마련되는 디스플레이 디바이 스나, 컴퓨터 장치에 접속되는 별체의 디스플레이 디바이스 등에 의해 구성된다. 표시부는, CPU의 지시에 기초하여 표시 화면 상에 각종 화상 처리를 위한 화상이나 처리 대상의 동화상 등의 표시를 실행한다. 또한 표시부는 CPU의 지시에 기초하여, 각종 조작 메뉴, 아이콘, 메시지 등, 즉 GUI(Graphical User Interface)로서의 표시를 행한다. 입출력 인터페이스에는, 하드 디스크나 고체 메모리 등으로 구성되는 기억부나, 모뎀 등으로 구성되는 통신부가 접속되는 경우도 있다. 통신부는, 인터넷 등의 전송로를 통한 통신 처리나, 각종 기기와의 유선/무선 통신, 버스 통신 등에 의한 통신을 행한다. 입출력 인터페이스에는 또한, 필요에 따라 드라이브가 접속되고, 자기 디스크, 광 디스크, 광자기 디스 크, 혹은 반도체 메모리 등의 리무버블 기억 매체가 적절하게 장착된다. 드라이브에 의해, 리무버블 기억 매체로부터 각 처리에 사용되는 프로그램 등의 데이터 파일 등을 읽어 낼 수 있다. 읽어내진 데이터 파일은 기억부에 기억되거나, 데이터 파일에 포함되는 화상이나 음성이 표시 부나 음성 출력부에서 출력되거나 한다. 또한 리무버블 기억 매체로부터 읽어내진 컴퓨터 프로그 램 등은 필요에 따라서 기억부에 인스톨된다. 이 컴퓨터 장치에서는, 예를 들어 본 실시 형태의 처리를 위한 소프트웨어를, 통신부에 의한 네트워크 통신 이나 리무버블 기억 매체를 통해서 인스톨할 수 있다. 혹은 당해 소프트웨어는 미리 ROM이나 기억부 등에 기억되어 있어도 된다. 또한, 카메라에서 촬상된 촬상 화상이나 AI 화상 처리에 의한 처리 결과를 수취하여, 기억부나 드라이브 를 통해서 리무버블 기억 매체에 기억시켜도 된다. CPU가 각종 프로그램에 기초하여 처리 동작을 행함으로써, 상술한 연산 처리부를 구비한 정보 처리 장치인 클라우드 서버로서의 필요한 정보 처리나 통신 처리가 실행된다. 또한, 클라우드 서버는, 도 6과 같은 컴퓨터 장치가 단일하게 구성되는 것에 한정되지 않고, 복수의 컴퓨터 장치가 시스템화되어 구성되어도 된다. 복수의 컴퓨터 장치는, LAN(Local Area Network) 등에 의해 시스템화되 어 있어도 되고, 인터넷 등을 이용한 VPN(Virtual Private Network) 등에 의해 원격지에 배치된 것이어도 된다. 복수의 컴퓨터 장치에는, 클라우드 컴퓨팅 서비스에 의해 이용 가능한 서버군(클라우드)으로서의 컴퓨터 장치가 포함되어도 된다. <2. 제1 실시 형태로서의 탐색 처리> 제1 실시 형태로서의 탐색 처리는, 촬상 설정의 탐색과 에지측 AI 모델의 탐색을 행하는 것이다. 구체적인 처리의 흐름에 대해서 도 13 및 도 14를 참조하여 설명한다. 우선, 유저는, 카메라에 의해 촬상된 촬상 화상 데이터로부터 원하는 분석 정보를 얻기 위한 AI 애플리케이 션을 선택하는 조작을 유저 단말기에 대해서 행한다. 또한, 이후의 설명에서는, AI 애플리케이션을 단순히 「애플리케이션」이라고 기재하는 경우도 있다. 애플리케이션은, 일례로서 상술한 바와 같이 점포 감시나 교통 감시, 혹은 방문객의 동선 파악 등의 용도이며, AI 화상 처리를 행하는 목적이라고 환언할 수도 있다. 또한, 목적(애플리케이션)에 대응해서 하나의 AI 애플리케이션이 존재하는 경우뿐만 아니라, 목적에 대응해서 복수의 AI 애플리케이션이 존재하는 경우도 있다. 구체적으로는, 예를 들어 「점포 감시」라는 목적을 달성하 기 위한 AI 애플리케이션이 복수 준비되어 있는 경우가 있다. 그 경우에는, 유저는, 「점포 감시」라는 목적을 선택해도 되고, 「점포 감시」라는 목적을 달성하기 위해서 준비된 복수의 AI 애플리케이션 중에서 하나의 AI 애플리케이션을 선택해도 된다. 전자의 경우, 즉, 유저가 「목적」을 선택한 경우는, 후술하는 설명에서의 「 애플리케이션」을 「목적」이라고 바꿔 읽음으로써 실현 가능하다. 또한, 일례로서는, 마켓 플레이스로서 「점포 감시」나 「교통 감시」 등의 상기 목적과, 복수의 상기 AI 애플 리케이션(예를 들어, 속성 인식의 AI 애플리케이션)의 일람을 유저 단말기에 표시시켜, 그들 중에서 원하는 목적이나 원하는 AI 애플리케이션을 유저가 선택함으로써 상기 선택은 실현 가능해진다. 유저 단말기는, 스텝 S101에서 애플리케이션의 선택 조작을 접수하고, 선택된 애플리케이션의 정보를 관리 서버에 대해서 송신하는 처리를 행한다. 관리 서버는, 스텝 S201에서, 유저 단말기로부터 애플리케이션 선택 정보를 수신한다. 또한, 관리 서버는, 애플리케이션의 선택 정보와 함께, 유저 단말기로부터 환경 정보를 수신한다. 환경 정보는, 카메라가 설치되어 있는 환경에 관한 정보 등이며, 예를 들어 점포 내나 옥외나 차내 등 설치되어 있는 장소에 관한 정보이어도 되고, 역광이나 순광이나 사광 등 카메라와 태양 등의 광원의 위치 관계를 나 타내는 정보이어도 된다. 또한, 검출 대상의 피사체를 나타내는 정보가 환경 정보에 포함되어 있어도 되고, 구 체적으로는, 피사체의 이동 속도 등이 포함된다. 또한, 설치 장소에 관한 정보는, 옥내나 옥외뿐만 아니라, 공공도로, 공원내 등의 정보이어도 되고, 더욱 자세 한 간선 도로, 골목길, 고속 도로 등의 정보이어도 된다. 환경 정보는, 유저에 의해 입력된 정보이어도 되고, 촬상 화상에 대한 해석 처리를 행한 결과 얻어지는 정보이 어도 된다. 또한, 유저에 의해 입력된 정보인 경우는, 마켓 플레이스 상에서 환경 정보를 선택할 수 있도록, 상술한 환경 정보를 일람으로서 표시시켜 두고, 예를 들어 상기 목적이나 복수의 상기 AI 애플리케이션을 선택할 때, 유저에 게 환경 정보를 선택시키도록 해도 된다. 관리 서버는, 스텝 S202에서, 애플리케이션에 따른 최적의 촬상 설정을 선택한다. 또한, 여기서 말하는 최 적이란, 실제로 최적의 촬상 설정을 가리키는 것이 아니라, 최적의 촬상 설정이라고 관리 서버에 의해 추정 된 촬상 설정을 가리킨다. 계속해서, 관리 서버는 스텝 S203에서, 애플리케이션에 따른 최적의 에지측 AI 모델을 선택한다. 여기서 말 하는 최적의 에지측 AI 모델에 대해서도, 관리 서버에 의해 최적이라고 추정된 에지측 AI 모델을 가리킨다. 또한, 이 처리에서는, 에지측 AI 모델을 사용한 AI 애플리케이션도 동시에 선택된다.관리 서버에는, 지금까지의 데이터가 빅 데이터로서 축적되어 있고, 애플리케이션과 환경 정보와 촬상 장치 에 적용된 에지측 AI 모델과 그 인식 결과 정보가 복수 관련지어져서 관리되고 있다. 인식 결과 정보는, 인식 된 피사체나, 인식 정확도나 우도 등의 수치 정보 등의 정보로 되어 있다. 이들 빅 데이터는, 해석 처리에 의해 인과 관계가 해석되어 있어, 예를 들어 환경 정보를 어떻게 변화시키면 인 식 결과 정보가 어떻게 변화하는지 등의 지견이 얻어지고 있다. 그리고 AI 화상 처리의 성능을 향상시키기 위 해서 선택되어야 하는 에지측 AI 모델 등도 해석에 의해 특정 가능하게 되어 있다. 관리 서버는, 금회 유저에 의해 선택된 애플리케이션과 환경 정보에 가장 가까운 조합에 있어서 가장 양호한 인식 결과 정보가 얻어진 촬상 설정이 최적의 촬상 설정으로서 선택된다. 예를 들어, 세단 타입의 차량을 검출할 때 가장 양호한 인식 결과가 얻어진 촬상 설정과 에지측 AI 모델이 있었 다고 하자. 그리고 동일한 카메라를 사용하여 이번에는 버스를 검출하는 경우에 있어서, 버스와 세단 타입 의 차량은 피사체로서의 특징이 유사하다고 판정되면, 세단 타입의 차량을 검출했을 때 사용된 촬상 설정과 에 지측 AI 모델이 최적의 것이라고 추정되어 선택된다. 관리 서버는 스텝 S204에서, 스텝 S202에서 선택된 촬상 설정과 스텝 S203에서 선택된 에지측 AI 모델을 카 메라에 대해서 송신한다. 이 처리에서는, 에지측 AI 모델뿐만 아니라 AI 애플리케이션에 대해서도 카메라 에 송신된다. 카메라는, 관리 서버로부터 촬상 설정과 에지측 AI 모델을 수신한 후, 스텝 S301에서, 촬상 설정을 갱신 하는 처리를 행한다. 이 처리는, 관리 서버로부터 수신한 촬상 설정을 카메라에 적용하는 처리이다. 이어서, 카메라는 스텝 S302에서, 관리 서버로부터 수신한 에지측 AI 모델을 갱신(전개)하는 처리를 행한 다. 카메라에 있어서 스텝 S301 및 스텝 S302의 처리가 실행됨으로써, 관리 서버에서 최적이라고 판정된 촬상 설정 및 에지측 AI 모델이 카메라에 적용되어, 초깃값으로서는 적절한 촬상 화상 데이터 및 인식 결과 정보 를 얻을 수 있다. 인식 결과 정보는, 예를 들어 검출한 피사체의 클래스 식별 정보와 그 우도(90％ 등)와 검출 위치(촬상 화상에 서의 화소 위치) 등이 된다. 카메라는 스텝 S303에서, 촬상된 촬상 화상에 대한 에지측 AI 화상 처리를 행한다. 카메라는 스텝 S304에서, 촬상 화상 데이터와 인식 결과 정보를 클라우드 서버에 대해서 송신한다. 클라 우드 서버에 대한 정보의 송신은 포그 서버를 통해서 행해지지만, 클라우드 서버에 대해서 직접 송신 되어도 된다. 카메라가 클라우드 서버에 대해서 촬상 화상 데이터와 인식 결과 정보를 송신한 후의 처리에 대해서, 도 14에 나타낸다. 클라우드 서버는 스텝 S401에서, 촬상 화상 데이터와 인식 결과 정보를 수신하고, 계속되는 스텝 S402에서, 클라우드측 AI 화상 처리를 실행한다. 클라우드측 AI 화상 처리는, 수신한 촬상 화상에 대해서 행해지는 처리이다. 또한, 클라우드측 AI 화상 처리는, 에지측 AI 화상 처리에 사용된 에지측 AI 모델과는 다른 클라우드측 AI 모델을 사용하여 실행된다. 클라우드측 AI 모델은, 에지측 AI 모델과 비교해서 고성능의 AI 모델이며, CNN이라면, 층수나 채널수나 필터 사 이즈나 스트라이드값 등의 적어도 일부가 다른 것으로 되어 있다. 구체적으로는, 클라우드측 AI 모델은 에지측 AI 모델에 대해서, 층수나 채널수나 필터 사이즈가 크게 되고, 스트라이드값이 작게 되어 있다. 이에 의해, 클라우드측 AI 모델은 고성능인 반면, 연산 비용이나 사용하는 메모리 사이즈 등이 에지측 AI 모델 에 대해서 크게 되어 있다. 클라우드 서버는 스텝 S403에서, 인식 결과 정보를 비교하는 처리를 행한다. 구체적으로는, 카메라로부 터 수신한 인식 결과 정보와 클라우드측 AI 모델을 사용한 클라우드측 AI 화상 처리의 인식 결과 정보를 비교하 여, 카메라에 있어서 클라우드 서버에서 얻어진 인식 결과 정보와 동등한 결과가 얻어졌는지 여부를 판정 한다. 또한, 양쪽의 인식 결과 정보의 차이가 허용 범위 내이면, 스텝 S403의 처리에서, 동등한 결과가 얻어졌 다고 판정된다.동등한 인식 결과 정보가 얻어졌을 경우에는, 클라우드 서버는 도 14에 나타내는 이후의 처리를 실행하지 않 아도 된다. 동등한 인식 결과 정보가 얻어지지 않았을 경우에는, 카메라의 촬상 설정이나 에지측 AI 모델이 최적이 아니 라고 판정한다. 그 경우에는, 클라우드 서버는 우선 스텝 S404에서, 카메라에 설정되어야 하는 적절한 촬상 설정을 탐색 하는 촬상 설정 탐색 처리를 행한다. 촬상 설정 탐색 처리는, 탐색용 AI를 사용하여 행해진다. 탐색용 AI에 사용되는 AI 모델인 탐색용 AI 모델은, 카메라의 카메라 설정과, 카메라에 의해 촬상된 촬상 화상으로부터 검출하는 검출 대상(이동체나 인물 등)과, 카메라의 설치 장소나 광원 등의 조건이나 검출 대 상의 이동 속도 등의 정보인 환경 정보와, 인식 결과 정보를 교사 데이터로 해서 그것들의 인과 관계를 학습함 으로써 구축된 AI 모델이다. 즉, 탐색용 AI 모델은, 상술한 빅 데이터를 교사 데이터로 해서 학습함으로써 얻 어진 AI 모델이다. 스텝 S404의 촬상 설정 탐색 처리에서는, 이러한 탐색용 AI 모델에 변수로서의 환경 정보를 입력함으로써, 클라 우드 서버에서 얻어진 인식 결과 정보와 동등한, 혹은 가까운 인식 결과 정보가 얻어지는 촬상 설정이 탐색 된다. 예를 들어, 검출 대상이 이동체이며, 또한, 이동체의 이동 속도가 고속일 경우에는, 촬상 설정의 탐색에 의해, 수광 시간을 8msec 등의 단시간으로 하고, ISO 감도를 높은 편으로 하고, 블러 보정을 강화로 하고, HDR을 ON으 로 하는 설정 등이 얻어진다. 혹은, 반도체 제조에 있어서 레지스트액이 정상적으로 도포되어 있는지 여부를 감시하는 카메라이라면, 흑백 화상을 대상으로 해서 AI 화상 처리를 행하는 것이나, 윤곽 강조 처리를 강화로 하는 것 등이 촬상 설정으로서 탐색된다. 이러한 촬상 설정 정보의 탐색에서는, 사전에 탐색된 결과가 리스트 형상으로 클라우드 서버에 기억되어 있 어도 된다. 즉, 스텝 S404의 처리에서는, 환경 정보에 기초하여 리스트로부터 하나의 촬상 설정 정보가 선택되 어도 된다. 또한, 정기적으로, 혹은 그때마다 탐색 처리가 행해져도 된다. 환경 정보에 대응하는 적절한 촬상 설정 정보는, 어디까지나 적합하다고 추정된 촬상 설정을 나타내는 것이며, 반드시 촬상 설정 중에서 최적이라고는 한정되지 않는다. 또한, 환경 정보와 촬상 설정과 그 인식 결과 정보에 관한 데이터는 매일매일 축적되어 가는 것으로, 새로운 탐색 처리를 행함으로써, 보다 적절한 촬상 설정 정보가 발견될 가능성은 부정할 수 없다. 스텝 S404의 처리를 행할 때마다 새롭게 촬상 설정 정보의 탐색 처리를 행함으로써, 보다 적절한 촬상 설정 정 보가 탐색될 가능성을 높일 수 있다. 이어서, 클라우드 서버는 스텝 S405에서, 양호한 AI 화상 처리의 결과를 얻기 위한 에지측 AI 모델을 탐색하 는 AI 모델 탐색 처리를 행한다. AI 모델 탐색 처리에서는, 예를 들어 에지측 AI 모델의 각 노드간에 설정되는 가중 계수에 대해서, 최적의 수치 를 탐색하는 처리이다. 이 탐색 처리는, 에지측 AI 화상 처리의 인식 결과 정보와 클라우드측 AI 화상 처리의 인식 결과 정보가 다른 촬상 화상을 입력으로 하여, 클라우드측 AI 화상 처리의 인식 결과 정보가 얻어지도록 에지측 AI 모델을 재학습 하는 처리라고 환언할 수 있다. 예를 들어, 어떤 촬상 화상에 대해서, 에지측 AI 모델을 사용한 에지측 AI 화상 처리의 인식 결과 정보에서는 세단 타입의 차량이 촬상되어 있을 가능성이 10％로 된 것에 반해, 클라우드측 AI 모델을 사용한 클라우드측 AI 화상 처리의 인식 결과 정보에서는 세단 타입의 차량이 촬상되어 있을 가능성이 90％로 되었다고 하자. 에지측 AI 모델보다 클라우드측 AI 모델쪽이 고성능이기 때문에, 이 경우에는, 클라우드측 AI 모델을 사용한 인 식 결과 정보쪽이 올바른 인식 결과 정보인 것으로서 다룬다. 그리고 클라우드 서버는, 스텝 S405의 AI 모델 탐색 처리에서, 인식 결과 정보의 괴리를 작게 하도록, 구체 적으로는, 세단 타입의 차량이 촬상되어 있을 가능성이 높다는 인식 결과 정보가 얻어지도록 에지측 AI 모델의 탐색, 예를 들어 상술한 가중 계수 등을 수정하는 처리를 행한다.이와 같이 하여 얻어진 에지측 AI 모델은, 스텝 S403에 의해 얻어진 촬상 설정과 함께, 클라우드 서버의 스 텝 S406의 처리에 의해 관리 서버에 송신된다. 관리 서버는, 스텝 S205에서, 촬상 설정과 에지측 AI 모델을 클라우드 서버로부터 수신한다. 이어서, 관리 서버는, 탐색 처리에 의해 얻어진 촬상 설정과 에지측 AI 모델을 기억함과 함께, 스텝 S206에 서, 당해 촬상 설정과 에지측 AI 모델을 카메라에 대해서 송신한다. 카메라는, 관리 서버로부터 촬상 설정과 에지측 AI 모델을 수신하여, 스텝 S305에서 촬상 설정을 갱신한 다. 또한, 카메라는 스텝 S306에서, 에지측 AI 모델을 갱신하는 처리를 행한다. 도 13 및 도 14에 나타내는 각 처리를 각 장치가 실행함으로써, 카메라에서의 에지측 AI 화상 처리의 인식 결과가 클라우드측 AI 모델을 사용하여 얻어진 인식 결과와 동등한 것이 된다. 바꾸어 말하면, 에지측 AI 화상 처리의 인식 결과가 적절한 것으로 된다. 이에 의해, 포그 서버나 클라우드 서버는, 인식 결과 정보에 기초하여, 피사체의 동선에 관한 분석 정보 나 차량에 관한 분석 정보를 얻을 수 있다. 또한, 상술한 에지측 AI 모델의 탐색에서는, 기본적으로는 인식 결과 정보의 질이 향상되는 에지측 AI 모델을 탐색한다. 단, 이것에 구애되지 않고, 종합적인 퍼포먼스가 향상되도록 에지측 AI 모델을 탐색해도 된다. 예를 들어, 카메라에 있어서 에지측 AI 모델을 사용한 화상 인식 처리를 실행할 때 메모리의 사용량이 핍박 해져 처리 속도가 대폭 저하되는 경우에는, 인식 결과 정보의 질이 다소 저하되더라도 처리 시간이 단축되는 에 지측 AI 모델을 탐색해도 된다. 즉, 본 예에서의 에지측 AI 모델의 탐색 처리에서는, 카메라의 성능을 고려해서 행해져도 된다. 여기서 말 하는 카메라의 성능이란, 카메라가 구비하는 연산 처리부의 처리 성능이나 카메라가 구비하는 메모리 의 용량이나 기억부의 용량 등이다. 또한, 에지측 AI 화상 처리에 대해서 허용되는 처리 시간 등을 고려해도 된다. 예를 들어, 카메라가 구비하는 메모리의 용량이 작은 경우에는, 에지측 AI 화상 처리에서 사용하는 메모리 용량이 억제되는 에지측 AI 모델이 탐색된다. 혹은, 카메라가 구비하는 기억부의 용량이 작은 경우에는, 소사이즈의 에지측 AI 모델이 탐색된다. 또한, 에지측 AI 화상 처리의 처리 시간을 짧게 할 필요가 있는 경우에는, 촬상 화상의 입력부터 인식 결과 정 보의 출력까지의 시간이 짧아지는 에지측 AI 모델, 즉, 연산량이 작은 에지측 AI 모델이 탐색된다. 또한, 이러한 처리 시간의 길고 짧음의 희망 등도 상술한 환경 정보로서, 마켓 플레이스로부터 유저에 의해 입 력시키도록 해도 되고, 마켓 플레이스 상에 유저의 희망 항목(예를 들어, 속도 중시, 인식율 중시 등)을 마련하 여, 거기에서 유저가 선택할 수 있도록 해도 된다. 또한, 카메라의 성능을 고려해서 에지측 AI 모델의 탐색을 행하는 경우에는, 에지측 AI 화상 처리에 관한 카 메라의 성능을 고려해도 된다. 여기서, 카메라의 성능 등의 정보는, 카메라가 클라우드 서버 등에 접속되었을 때, 카메라로부터의 성능 정보를 클라우드 서버 등에 자동적으로 송신하도록 설계해 두어도 되고, 마켓 플레이스 등을 통해서 유 저가 수동으로 클라우드 서버에 등록하도록 해도 된다. 예를 들어, 촬상 동작에 의해 얻어진 촬상 화상에 대해서 에지측 AI 화상 처리를 행할 때의 카메라의 처리 성능이나 메모리 용량이나 메모리에의 액세스 속도 등을 고려한 에지측 AI 모델이 탐색되어도 된다. 이러한 에지측 AI 모델의 탐색은, 일반적으로 지식의 증류(Knowledge Distillation)라는 방법으로서 알려져 있 다. 또한, 본 실시 형태에서는, 유저에 의해 입력된 환경 정보가 올바르다고 보고 촬상 설정의 탐색 및 에지측 AI 모델의 탐색을 행하는 예를 설명하였다. 그러나, 유저에 의해 입력된 환경 정보가 옳지 않은 경우도 있다. 예를 들어, 유저에 의해 입력된 정보에 기초하면, 순광 환경에서 촬상된 촬상 화상이 얻어질 것으로 추정되는 경우가 있다. 그러나, 실제로 카메라로부터 수신한 촬상 화상을 해석한 결과, 역광 환경에 의해 촬상되었다고 추정할 수 있는 경우가 있다. 또한, 유저에 의해 입력된 정보로부터의 추정에 반하여, 달빛 아래에서 촬상 되었다고 추정되는 경우나 야간에 촬상되었다고 추정되는 경우 등도 있다. 혹은, 유저에 의해 입력된 환경 정보에 기초하는 피사체의 이동 속도와, 촬상 화상으로부터 추정되는 피사체의 이동 속도가 다른 경우 등도 있다. 이러한 상황은, 예를 들어 유저가 카메라를 설치했을 때의 카메라의 방향과 현재의 카메라의 방향이 다른 경우나, 피사체의 이동 속도를 유저가 착각하고 있었을 경우나, 촬상되는 시간대를 착각하고 있었던 경우 등에 일어날 수 있다. 이러한 경우에는, 유저에 의해 입력된 환경 정보를 올바르다고 보는 것이 아니라, 화상 해석에 의해 얻어진 환 경 정보가 올바르다고 보고, 스텝 S404의 촬상 설정의 탐색 처리나 스텝 S405의 에지측 AI 모델의 탐색 처리를 실행하는 것이 바람직하다. 즉, 유저에 의해 입력된 환경 정보를 보정하면서 각 탐색 처리를 실행해도 된다. 또한, 환경 정보의 보정 처리는, 스텝 S402에서의 클라우드측 AI 화상 처리의 실행 시에 맞추어서 행해도 된다. 즉, 스텝 S402의 클라우드측 AI 화상 처리에서, 검출 대상의 피사체를 검출함과 함께, 촬상 화상이 얻어진 환경 이나 피사체에 관한 정보(이동 속도 등)를 추정하는 처리를 행해도 된다. <3. 제2 실시 형태로서의 탐색 처리> 제2 실시 형태에서의 탐색 처리는, 카메라와 포그 서버와 관리 서버와 클라우드 서버(1A)를 포함하는 각 장치에 대해서, 유저가 지정한 애플리케이션의 목적을 달성하기 위해 실행되는 각 처리를 적절하게 분배하기 위한 것이다. 분배 대상의 처리로서는, 예를 들어 도 14의 스텝 S403의 비교 처리나, 애플리케이션의 목적을 달성하기 위해서 행해지는 분석 처리나, 분석 정보를 유저에게 제시하기 위한 표시 처리 및 제시 처리나, 클라우드측 AI 화상 처 리 등이다. 또한, 이들 처리 이외에도, 유저가 애플리케이션에 관한 분석 정보를 얻을 때까지 실행되는 각종 처리가 분배 대상의 처리에 포함되어 있어도 된다. 본 실시 형태에서는, 처리의 분배를 행하기 위한 탐색 처리를 클라우드 서버(1A)가 실행하는 것으로 하여, 클라 우드 서버(1A)의 기능 구성을 도 15에 나타낸다. 또한, 도 6 및 도 7에 도시하는 바와 같이, 본 탐색 처리를 관리 서버가 실행해도 된다. 클라우드 서버(1A)는, 클라우드측 AI 화상 처리 기능(F3)과 촬상 설정 탐색 기능(F4)과 AI 모델 탐색 기능(F5) 에 더하여 애플리케이션 설정 기능(F1)과 처리 분담 탐색 기능(F2)을 갖는다. 즉, 본 실시 형태에서의 클라우 드 서버(1A)는, 제1 실시 형태에서의 클라우드 서버와 관리 서버의 양쪽 기능을 통합한 서버 장치로 되어 있다. 각 기능에 대해서는, 상술했기 때문에 설명을 생략한다. 처리의 분배를 결정하기 위해서는, 클라우드 서버(1A)는, 사전에 기계 학습을 행한다. 이에 의해, 클라우드 서 버(1A)는, 처리 분배를 결정하기 위해서 사용되는 처리 분배용 AI 모델을 획득한다. 사전 학습에서는, 빅 데이터가 사용된다. 빅 데이터는, 애플리케이션의 종류와, 카메라에 관한 정보와, 해 석 대상의 촬상 화상과, 처리에 사용되는 OS(Operating System)의 정보나 처리 시간과, 각 장치의 연산 기능의 이용률이나 메모리 용량의 이용률 등의 각 장치의 성능을 어느 정도 소비했는지를 나타내는 정보와, 처리 시간 등의 각 정보가 관련지어져서 기억되어 있다. 또한, 복수대의 카메라를 갖는 점포 감시라면, 점포의 넓이 등의 정보도 빅 데이터에 포함된다. 즉, 감시 대상의 정보나 검출 대상의 정보 등이 포함되어 있어도 된다. 또한, 각 장치의 가격 등 다른 비용 정보가 포함되어 있어도 된다. 사전 학습에서 클라우드 서버(1A)가 실행하는 구체적인 처리에 대해서 흐름도를 도 16에 나타낸다. 클라우드 서버(1A)는, 스텝 S501에서, 빅 데이터를 취득한다. 계속해서, 클라우드 서버(1A)는 스텝 S502에서, 기계 학습을 행한다. 이 기계 학습에 의해, 클라우드 서버(1 A)는, 스텝 S503에서, 처리 분담 탐색을 위한 AI 모델로서 처리 분담용 AI 모델을 획득한다.빅 데이터가 시간의 경과와 함께 축적되어 갈 경우에는, 클라우드 서버(1A)는 도 16에 나타내는 처리를 데이터 의 축적마다, 혹은 일정 시간마다 실행해도 된다. 이에 의해, 최신의 빅 데이터에 따라서 처리 분담용 AI 모델을 갱신할 수 있다. 실제로 처리 분담용 AI 모델이 이용되는 경우에 각 장치가 실행하는 처리의 일례를 도 17에 나타낸다. 유저 단말기는, 카메라에 의해 촬상된 촬상 화상으로부터 원하는 분석 정보를 얻기 위한 애플리케이션을 선택하는 유저 조작을 접수하고, 스텝 S101에서 애플리케이션 선택 정보를 클라우드 서버(1A)에 송신한다. 클라우드 서버(1A)는, 스텝 S201에서, 애플리케이션 선택 정보를 수신한 후, 스텝 S411에서, 리소스의 선택 처 리를 행한다. 리소스의 선택 처리는, 애플리케이션의 실현에 사용되는 카메라나 포그 서버 등의 각 장치 의 정보나, 상술한 환경 정보 등을 선택하는 처리이다. 리소스의 선택 처리는, 유저에 의해 입력된 정보에 기초해서 행해지고 있어도 되고, 예를 들어 점포가 구비하는 감시 카메라나 정보 처리 장치가 미리 등록되어 있는 경우에는, 해당 등록 정보에 기초해서 행해지고 있어도 된 다. 카메라 등의 각 장치의 정보는, 스펙 정보가 유저에 의해 입력되어도 되고, 카메라의 메이커 정보나 모델 명이나 형식 번호 정보 등이 입력됨으로써 간접적으로 특정 가능하게 되어 있어도 된다. 포그 서버 등의 정 보 처리 장치의 정보에 대해서도 마찬가지이다. 클라우드 서버(1A)는 스텝 S412에서, 상술한 처리 분담용 AI 모델을 사용하여 처리 분담의 탐색을 행한다. 그 결과, 각 장치에서 무슨 처리를 실행할지에 관한 탐색 결과가 얻어진다. 클라우드 서버(1A)는, 스텝 S413에서, 탐색 결과로서의 처리 분배에 따른 실행 프로그램을 장치마다 생성하여, 각 장치에 송신한다. 이에 따라, 포그 서버에서는, 스텝 S601에서 실행 프로그램을 수신하고, 스텝 S602에서 실행 프로그램을 전 개한다. 마찬가지로, 카메라에서는, 스텝 S311에서 실행 프로그램을 수신하고, 스텝 S312에서 실행 프로그램을 전개 한다. 또한, 클라우드 서버(1A)에서도, 스텝 S414에서 실행 프로그램의 전개가 행해진다. 이에 의해, 포그 서버나 카메라나 클라우드 서버(1A)에서, 처리 분담에 따른 각 처리가 실행된다. <4. 제3 실시 형태로서의 탐색 처리> 제3 실시 형태는, 카메라(3B)와 포그 서버 등 에지측(예를 들어 점포측)에 배치되는 정보 처리 장치와, 클라 우드 서버(1B)나 관리 서버 등 클라우드측에 배치되는 정보 처리 장치의 사이에서 프라이버시에 관한 정보의 송수신을 가능한 한 행하지 않도록 하는 것이다. 여기서, 제1 실시 형태에서는, 카메라(3B)에서 촬상된 촬상 화상이 클라우드 서버에 송신됨으로써, 클라우드 서버에서 촬상 화상을 사용한 촬상 설정의 탐색이나 에지측 AI 모델의 탐색이나 AI 모델의 리트레인을 행할 수 있었다. 이에 반해, 제3 실시 형태에서는, 촬상 화상을 가공한 대체 화상을 카메라(3B)로부터 클라우드 서버(1B)에 송신 함으로써, 프라이버시에 관한 정보의 송수신을 억제함과 함께 촬상 설정의 탐색이나 에지측 AI 모델의 탐색을 적절하게 행하도록 한다. 클라우드 서버(1B)의 기능 구성에 대해서 도 18에 나타낸다. 클라우드 서버(1B)는, 클라우드측 AI 화상 처리 기능(F3)과 촬상 설정 탐색 기능(F4)과 AI 모델 탐색 기능(F5) 에 더하여, 화상 생성 기능(F6)을 갖고 있다. 화상 생성 기능(F6)은, 카메라(3B)로 촬상된 촬상 화상에 기초한 가상 화상을 생성하는 기능이다. 가상 화상의 생성 방법은 몇가지 생각할 수 있다. 예를 들어, 클라우드 서버(1B)는, 촬상 화상이 촬상된 촬영 환경에 관한 정보를 카메라(3B)로부터 수신하여, 당 해 정보에 따라서 가상 화상을 생성해도 된다.혹은, 클라우드 서버(1B)는, 인물 등이 촬상되어 있지 않은 배경 화상을 카메라(3B)로부터 수신하고, 수신한 배 경 화상에 인물 화상을 중첩시킴으로써 가상 화상을 생성해도 된다. 이 때 사용되는 인물 화상은, 카메라(3B) 로부터 수신하는 것이 아니라, 클라우드 서버(1B)에서 생성 혹은 기록된 가공의 인물 화상이어도 되고, 프라이 버시의 문제가 일어나지 않을 인물 화상이어도 된다. 또한, 인물 화상의 중첩 위치는, 카메라(3B)에 의해 촬상된 촬상 화상에서의 피사체로서의 인물의 촬상 위치로 되어도 된다. 이 경우에는, 카메라(3B)로부터 중첩 위치를 나타내는 정보가 클라우드 서버(1B)에 대해서 송신 된다. 이하에 나타내는 예에서는, 카메라(3B)는 클라우드 서버(1B)에 대해서 배경 화상을 송신하는 경우를 든다. 본 실시 형태에서의 각 장치에서의 구체적인 처리의 흐름에 대해서 도 19 및 도 20을 참조하여 설명한다. 또한, 제1 실시 형태에서 참조한 도 13 및 도 14와 동등한 처리에 대해서는, 동일한 스텝 번호를 부여하고 적절 하게 설명을 생략한다. 유저 단말기는, 스텝 S101에서, 유저에 의해 선택된 애플리케이션의 정보를 관리 서버에 대해서 송신한다. 관리 서버는, 스텝 S201에서, 유저 단말기로부터 애플리케이션 선택 정보와 환경 정보를 수신한다. 관리 서버는, 스텝 S202에서, 애플리케이션에 따른 최적의 촬상 설정을 선택한다. 계속해서, 관리 서버는 스텝 S203에서, 애플리케이션에 따른 최적의 에지측 AI 모델을 선택한다. 관리 서버는 스텝 S204에서, 스텝 S202에서 선택된 촬상 설정과 스텝 S203에서 선택된 에지측 AI 모델을 카 메라(3B)에 대해서 송신한다. 카메라(3B)는, 관리 서버로부터 촬상 설정과 에지측 AI 모델을 수신한 후, 스텝 S301에서, 촬상 설정을 갱신 하는 처리를 행한다. 이어서, 카메라(3B)는 스텝 S302에서, 관리 서버로부터 수신한 에지측 AI 모델을 갱신하는 처리를 행한다. 카메라(3B)는 스텝 S303에서, 촬상된 촬상 화상에 대한 에지측 AI 화상 처리를 행한다. 이러한 에지측 AI 화상 처리는, 예를 들어 상술한 도 8의 이미지 센서(IS) 내의 AI 모델을 사용한 처리를 행하는 AI 화상 처리부에 행하게 해도 된다. 이와 같이 이미지 센서(IS) 내에서 에지측 AI 화상 처리를 행함으로써, 프라이버시를 보다 강하게 보호할 수 있 다. 카메라(3B)는 스텝 S321에서, 배경 화상을 생성한다. 배경 화상은, 인물을 포함해서 촬상된 촬상 화상으로부터 인물을 제거함으로써 얻어도 된다. 예를 들어, 복수매의 촬상 화상으로부터 인물 등이 촬상되어 있지 않은 영 역을 조합함으로써 배경 화상으로서 생성해도 되고, 화각 내에 인물 등이 없는 순간을 촬상한 촬상 화상을 배경 화상으로 해도 된다. 이러한 배경 화상을 생성하는 처리에서, 예를 들어 상술한 도 8의 AI 모델을 사용한 처리를 행하는 AI 화상 처 리부에서, 촬상 화상으로부터 인물 등을 인식시켜, 인식된 인물을 촬상 화상으로부터 제거하는 처리를 행함 과 함께, 화상에서의 그 제거한 인물 화상의 위치 정보를 추출해도 된다. 카메라(3B)는, 스텝 S322에서, 배경 화상과 인식 결과 정보를 클라우드 서버(1B)에 대해서 송신한다. 클라우드 서버(1B)에 대한 정보의 송신은 포그 서버를 통해서 행해지지만, 클라우드 서버(1B)에 대해서 직접 송신되어 도 된다. 카메라(3B)가 클라우드 서버(1B)에 대해 배경 화상 데이터와 인식 결과 정보를 송신한 후의 처리에 대해서, 도 20에 나타낸다. 클라우드 서버(1B)는 스텝 S421에서, 배경 화상 데이터와 인식 결과 정보를 수신하고, 계속되는 스텝 S422에서, 가상 화상의 생성을 행한다. 가상 화상의 생성은, 예를 들어, 배경 화상의 소정 위치에 가상의 인물 화상을 중 첩시키거나 해서 행해진다. 또한, 가상의 인물 화상의 중첩 위치는, 상술한 바와 같이, 카메라(3B)에서 촬상된 인물의 촬상 위치 정보를 수 신하여, 그 인물의 촬상 위치와 동일한 위치로 되어도 된다. 클라우드 서버(1B)는 스텝 S402에서, 클라우드측 AI 화상 처리를 실행한다. 본 예에서의 클라우드측 AI 화상 처리는, 생성한 가상 화상에 대해서 행해지는 처리이다. 단, 예를 들어 촬상 되는 인물에게 허가를 받은 경우 등 프라이버시의 문제가 존재하지 않는 경우에는, 물론, 카메라(3B)에서 촬상 된 인물의 촬상 화상을 사용해도 실현 가능한 것은 물론이다. 또한, 클라우드측 AI 화상 처리는, 에지측 AI 화 상 처리에 사용된 에지측 AI 모델과는 다른 클라우드측 AI 모델을 사용하여 실행된다. 클라우드 서버(1B)는 스텝 S403에서, 인식 결과 정보를 비교하는 처리를 행한다. 구체적으로는, 카메라(3B)로 부터 수신한 인식 결과 정보와 클라우드측 AI 모델을 사용한 클라우드측 AI 화상 처리의 인식 결과 정보를 비교 하여, 카메라(3B)에 있어서 클라우드 서버(1B)에서 얻어진 인식 결과 정보와 동등한 결과가 얻어졌는지 여부를 판정한다. 동등한 결과가 얻어지지 않았을 경우에는, 클라우드 서버(1B)는 스텝 S404 이후의 각 처리를 행한다. 구체적으로, 클라우드 서버(1B)는 스텝 S404에서, 카메라(3B)에 설정되어야 하는 적절한 촬상 설정을 탐색하는 촬상 설정 탐색 처리를 행한다. 이어서, 클라우드 서버(1B)는 스텝 S405에서, 양호한 인식 결과를 얻기 위한 에지측 AI 모델을 탐색하는 AI 모 델 탐색 처리를 행한다. 클라우드 서버(1B)는, 스텝 S406에서, 스텝 S403에 의해 얻어진 촬상 설정과 스텝 S404에 의해 얻어진 에지측 AI 모델을 관리 서버에 송신한다. 관리 서버는, 스텝 S205에서, 촬상 설정과 에지측 AI 모델을 클라우드 서버(1B)로부터 수신한다. 이어서, 관리 서버는, 탐색 처리에 의해 얻어진 촬상 설정과 에지측 AI 모델을 기억함과 함께, 스텝 S206에 서, 당해 촬상 설정과 에지측 AI 모델을 카메라(3B)에 대해서 송신한다. 카메라(3B)는, 관리 서버로부터 촬상 설정과 에지측 AI 모델을 수신하여, 스텝 S305에서 촬상 설정을 갱신한 다. 또한, 카메라(3B)는 스텝 S306에서, 에지측 AI 모델을 갱신하는 처리를 행한다. 또한, 제3 실시 형태에서는, 클라우드 서버(1B)가 화상 생성 기능(F6)을 갖는 예를 나타냈지만, 카메라(3B)가 화상 생성 기능(F6)을 갖고 있어도 된다. 예를 들어, 카메라(3B)에서, 인물의 얼굴 등의 개인 정보가 포함되는 영역을 모두 칠한 화상이나 결락시킨 화상 을 가상 화상으로서 생성하여, 클라우드 서버(1B)에 송신해도 된다. 클라우드 서버(1B)에서는, 칠해진 영역이 나 정보가 결락된 영역에 대체 화상을 끼워 넣어도 되고, 그대로 가상 화상으로서 사용함으로써 클라우드측 AI 화상 처리나 촬상 설정 탐색 처리나 AI 모델 탐색 처리를 실행해도 된다. 혹은, 클라우드 서버(1B)는, 카메라(3B)로부터 수신한 배경 화상을 수신하여, 배경 화상을 그대로 촬상 화상으 로서 사용하여 각종 기능을 실현해도 된다. 이와 같이, 에지측의 정보 처리 장치로부터 클라우드측의 정보 처리 장치에 대해서, 개인 정보 등이 송신되지 않도록 구성됨으로써, 피사체에 관한 프라이버시의 보호를 도모할 수 있다. 또한, 도 13 및 도 14에 나타낸 스텝 S201부터 스텝 S206의 각 처리는, 관리 서버에 의해 실행되는 예를 나 타냈지만, 관리 서버가 구비하는 기능을 클라우드 서버가 구비함으로써, 클라우드 서버가 스텝 S201부 터 스텝 S206의 각 처리를 실행해도 된다. 바꾸어 말하면, 클라우드 서버와 관리 서버가 동일한 정보 처 리 장치로 되어 있어도 된다. <5. 변형예> 상기에서는, 카메라(3, 3B)로서, 통상의 RGB 화상 등의 센싱 화상, 즉, 화소마다의 수광량을 나타내는 화상을 얻는 센서를 사용하는 예를 들었지만, 본 기술은 그 이외의 촬상 장치에 적용하는 것이 가능하다. 구체적으로 는, 예를 들어 ToF(Time of Flight) 센서 등과 같이 센싱 화상으로서 뎁스 화상을 얻는 센서, 즉, 화소마다의 거리를 나타내는 거리 화상을 얻는 뎁스 센서를 사용하는 경우에도 적합하게 적용할 수 있다. 혹은, 본 기술은, 서멀 센서, 즉, 센싱 화상으로서 화소마다의 온도를 나타내는 서멀 화상을 얻는 센서 장치나, 편광 센 서, 즉, 화소마다의 편광 정보를 나타내는 화상을 얻는 센서 장치를 사용하는 경우에도 적합하게 적용할 수 있다. 또한, 상술한 각 센서에 더하여, 다파장(멀티스펙트럼) 센서, EVS(Event based Vision Sensor), IR(Infrared) 센서, SWIR(Short Wavelength infrared) 센서, 습도 센서, 수분 센서 등에도 적용할 수 있다. 그리고 본 기술에서 「촬상」이란, 센싱 화상으로서 화소마다의 수광량을 나타내는 화상을 얻는 것에 한정되지 않고, 상기와 같은 뎁스 화상이나 서멀 화상, 편광 화상, 다파장 화상, EVS에 의한 휘도의 변화 부분이 표현되 는 화상, 소정의 파장대에서의 화상, 습도 화상, 수분 분포 화상 등을 얻는 것을 넓게 포함하는 개념이다. 상술한 설명에서는, 에지측 AI 모델에 의한 AI 화상 처리의 결과와 클라우드측 AI 모델에 의한 AI 화상 처리의 결과가 다른 경우에 최적의 에지측 AI 모델의 탐색을 행하는 예를 나타냈다. 이 외에도, 서비스의 제공자나 이용자(유저)의 조작을 트리거로 해서 AI 모델의 재학습과 각 카메라에 전개 된 에지측 AI 모델이나 AI 애플리케이션의 갱신이 행해져도 된다. 이때의 처리의 흐름에 대해서, 구체적으로 도 21을 참조하여 설명한다. 또한, 도 21은 복수의 카메라 중 1 대의 카메라에 주목해서 기재한 것이다. 또한, 이하의 설명에서 갱신 대상이 된 에지측 AI 모델은, 카메라 가 구비하는 이미지 센서(IS)에 전개되어 있는 것이다. 단, 에지측 AI 모델은 카메라에서의 이미지 센서 (IS) 외에 전개되어도 된다. 우선, 처리 스텝 PS1에서, 서비스의 제공자나 이용자에 의한 AI 모델의 재학습 지시가 행해진다. 이 지시는, 클라우드측 정보 처리 장치가 구비하는 API(Application Programming Interface) 모듈이 구비하는 API 기능을 이용하여 행해진다. 또한, 당해 지시에서는, 학습에 사용하는 화상량(예를 들어 매수)이 지정된다. 이후, 학 습에 사용하는 화상량을 「소정 매수」라고도 기재한다. API 모듈은, 당해 지시를 받아, 처리 스텝 PS2에서 Hub(도 5에 나타낸 것과 마찬가지의 것)에 대해서 재학습의 리퀘스트와 화상량의 정보를 송신한다. Hub는, 처리 스텝 PS3에서, 에지측 정보 처리 장치로서의 카메라에 대해서 업데이트 통지와 화상량의 정보를 송신한다. 카메라는, 촬영을 행함으로써 얻어진 촬상 화상 데이터를 처리 스텝 PS4에서 스토리지 군의 화상 DB(Database)에 송신한다. 이 촬영 처리와 송신 처리는, 재학습에 필요한 소정 매수에 달성할 때까지 행해진다. 또한, 카메라는, 촬상 화상 데이터에 대한 추론 처리를 행함으로써 추론 결과를 얻었을 경우에는, 처리 스텝 PS4에서 촬상 화상 데이터의 메타데이터로서 추론 결과를 화상 DB에 기억해도 된다. 카메라에서의 추론 결과가 메타데이터로서 화상 DB에 기억됨으로써, 클라우드측에서 실행되는 AI 모델의 재 학습에 필요한 데이터를 엄선할 수 있다. 구체적으로는, 카메라에서의 추론 결과와 클라우드측 정보 처리 장치에서 윤택한 컴퓨터 자원을 사용하여 실행되는 추론의 결과가 상이한 화상 데이터만을 사용하여 재학습을 행할 수 있다. 따라서, 재학습에 요하는 시간을 단축하는 것이 가능해진다. 소정 매수의 촬영과 송신을 종료한 후, 카메라는 처리 스텝 PS5에서, 소정 매수의 촬상 화상 데이터의 송신 이 완료된 것을 Hub에 통지한다. Hub는, 해당 통지를 받아, 처리 스텝 PS6에서, 재학습용 데이터의 준비가 완료된 것을 오케스트레이션 툴에 통 지한다. 오케스트레이션 툴은, 처리 스텝 PS7에서, 라벨링 처리의 실행 지시를 라벨링 모듈에 대해서 송신한다. 라벨링 모듈은, 라벨링 처리의 대상이 된 화상 데이터를 화상 DB로부터 취득해서(처리 스텝 PS8), 라벨링 처리 를 행한다. 여기서 말하는 라벨링 처리란, 상술한 클래스 식별을 행하는 처리이어도 되고, 화상의 피사체에 관한 성별이나 연령을 추정해서 라벨을 부여하는 처리이어도 되고, 피사체에 관한 포즈를 추정해서 라벨을 부여하는 처리이어 도 되고, 피사체의 행동을 추정해서 라벨을 부여하는 처리이어도 된다. 라벨링 처리는, 수동으로 행해져도 되고, 자동으로 행해져도 된다. 또한, 라벨링 처리는 클라우드측의 정보 처 리 장치에서 완결해도 되고, 다른 서버 장치가 제공하는 서비스를 이용함으로써 실현되어도 된다.라벨링 처리를 종료한 라벨링 모듈은, 처리 스텝 PS9에서, 라벨이 달린 결과 정보를 데이터 세트 DB에 기억한다. 여기서 데이터 세트 DB에 기억되는 정보는, 라벨 정보와 화상 데이터의 조가 되어도 되고, 화상 데 이터 그 자체 대신에 화상 데이터를 특정하기 위한 화상 ID(Identification) 정보가 되어도 된다. 라벨이 달린 결과 정보가 기억된 것을 검출한 스토리지 관리부는, 처리 스텝 PS10에서 오케스트레이션 툴에 대 한 통지를 행한다. 해당 통지를 수신한 오케스트레이션 툴은, 소정 매수의 화상 데이터에 대한 라벨링 처리가 종료된 것을 확인하 고, 처리 스텝 PS11에서, 재학습 모듈에 대한 재학습 지시를 송신한다. 재학습 지시를 수신한 재학습 모듈은, 처리 스텝 PS12에서 데이터 세트 DB로부터 학습에 사용하는 데이터 세트 를 취득함과 함께, 처리 스텝 PS13에서 학습 완료된 AI 모델 DB로부터 업데이트 대상의 AI 모델을 취득한다. 재학습 모듈은, 취득한 데이터 세트와 AI 모델을 사용하여 AI 모델의 재학습을 행한다. 이와 같이 하여 얻어진 업데이트 완료된 AI 모델은, 처리 스텝 PS14에서 다시 학습 완료된 AI 모델 DB에 기억된다. 업데이트 완료된 AI 모델이 기억된 것을 검출한 스토리지 관리부는, 처리 스텝 PS15에서 오케스트레이션 툴에 대한 통지를 행한다. 해당 통지를 수신한 오케스트레이션 툴은, 처리 스텝 S16에서, AI 모델의 변환 지시를 변환 모듈에 대해서 송신 한다. 변환 지시를 수신한 변환 모듈은, 처리 스텝 PS17에서 학습 완료된 AI 모델 DB로부터 업데이트 완료된 AI 모델 을 취득하여, AI 모델의 변환 처리를 행한다. 해당 변환 처리에서는, 전개처의 기기인 카메라의 스펙 정보 등에 맞추어서 변환하는 처리를 행한다. 이 처 리에서는, AI 모델의 성능을 가능한 한 떨어뜨리지 않도록 다운사이징을 행함과 함께, 카메라 상에서 동작 가능하도록 파일 형식의 변환 등이 행해진다. 변환 모듈에 의해 변환 완료된 AI 모델은 상술한 에지측 AI 모델로 된다. 이 변환 완료된 AI 모델은, 처리 스 텝 PS18에서 변환 완료된 AI 모델 DB에 기억된다. 변환 완료된 AI 모델이 기억된 것을 검출한 스토리지 관리부는, 처리 스텝 PS19에서 오케스트레이션 툴에 대한 통지를 행한다. 해당 통지를 수신한 오케스트레이션 툴은, 처리 스텝 PS20에서, AI 모델의 업데이트를 실행시키기 위한 통지를 Hub에 대해서 송신한다. 이 통지에는, 업데이트에 사용하는 AI 모델이 기억되어 있는 장소를 특정하기 위한 정 보를 포함하고 있다. 해당 통지를 수신한 Hub는, 카메라에 대해서 AI 모델의 업데이트 지시를 송신한다. 업데이트 지시에 대해서 도, AI 모델이 기억되어 있는 장소를 특정하기 위한 정보가 포함되어 있다. 카메라는, 처리 스텝 PS22에서, 변환 완료된 AI 모델 DB로부터 대상의 변환 완료된 AI 모델을 취득해서 전개 하는 처리를 행한다. 이에 의해, 카메라의 이미지 센서(IS)에서 이용되는 AI 모델의 갱신이 행해진다. AI 모델을 전개함으로써 AI 모델의 갱신을 종료한 카메라는, 처리 스텝 PS23에서 Hub에 대해서 갱신 완료 통 지를 송신한다. 해당 통지를 수신한 Hub는, 처리 스텝 PS24에서 오케스트레이션 툴에 대해서 카메라의 AI 모델 갱신 처리가 완료된 것을 통지한다. 또한, AI 모델의 갱신만을 행하는 경우는, 여기까지의 처리로 완결한다. AI 모델에 더하여 AI 모델을 이용하는 AI 애플리케이션의 갱신을 행하는 경우에는, 후술하는 처리가 더 실행된 다. 구체적으로, 오케스트레이션 툴은 처리 스텝 PS25에서, 전개 제어 모듈에 대해서 업데이트된 펌웨어 등의 AI 애 플리케이션의 다운로드 지시를 송신한다. 전개 제어 모듈은, 처리 스텝 PS26에서, Hub에 대해서 AI 애플리케이션의 전개 지시를 송신한다. 이 지시에는, 업데이트된 AI 애플리케이션이 기억되어 있는 장소를 특정하기 위한 정보가 포함되어 있다.Hub는, 처리 스텝 PS27에서, 당해 전개 지시를 카메라에 대해서 송신한다. 카메라는, 처리 스텝 PS28에서, 전개 제어 모듈의 컨테이너 DB로부터 업데이트된 AI 애플리케이션을 다운로 드해서 전개한다. 또한, 상기 설명에서는, 카메라의 이미지 센서(IS) 상에서 동작하는 AI 모델의 갱신과 카메라에서의 이미 지 센서(IS) 밖에서 동작하는 AI 애플리케이션의 갱신을 시퀀셜하게 행하는 예를 설명하였다. AI 모델과 AI 애플리케이션 양쪽이 카메라의 이미지 센서(IS) 밖에서 동작하는 경우에는, AI 모델과 AI 애플 리케이션 양쪽을 하나의 컨테이너로서 통합해서 갱신해도 된다. 그 경우에는, AI 모델의 갱신과 AI 애플리케이 션의 갱신이 시퀀셜이 아니라 동시에 행해져도 된다. 그리고 처리 스텝 PS25, PS26, PS27, PS28의 각 처리를 실행함으로써, 실현 가능하다. 또한, 카메라의 이미지 센서(IS)에 컨테이너를 전개하는 것이 가능한 경우에 대해서도, 처리 스텝 PS25, PS26, PS27, PS28의 각 처리를 실행함으로써, AI 모델이나 AI 애플리케이션의 갱신을 행할 수 있다. 상술한 처리를 행함으로써, 유저의 사용 환경에서 촬상된 촬상 화상 데이터를 사용하여 AI 모델의 재학습이 행 해진다. 따라서, 유저의 사용 환경에서 고정밀도의 인식 결과를 출력할 수 있는 에지측 AI 모델을 생성할 수 있다. 또한, 점내의 레이아웃을 변경한 경우나 카메라의 설치 장소를 변경한 경우 등, 유저의 사용 환경이 변화하 였다고 해도, 그 때마다 적절하게 AI 모델의 재학습을 행할 수 있기 때문에, AI 모델에 의한 인식 정밀도를 저 하시키지 않고 유지하는 것이 가능해진다. 또한, 상술한 각 처리는, AI 모델의 재학습 시뿐만 아니라, 유저의 사용 환경 하에서 시스템을 처음으로 가동시 킬 때 실행해도 된다. <6. 마켓 플레이스의 화면예> 마켓 플레이스에 관해서 유저에게 제시되는 화면의 일례에 대해서, 각 도면을 참조하여 설명한다. 도 22는 로그인 화면 G1의 일례를 나타낸 것이다. 로그인 화면 G1에는, 유저 ID를 입력하기 위한 ID 입력란과, 패스워드를 입력하기 위한 패스워드 입력란 이 마련되어 있다. 패스워드 입력란의 하방에는, 로그인을 행하기 위한 로그인 버튼과, 로그인을 중지하기 위한 캔슬 버튼 이 배치되어 있다. 또한, 그 하방에는, 패스워드를 잊은 유저용 페이지로 천이하기 위한 조작자나, 신규로 유저 등록을 행하기 위 한 페이지로 천이하기 위한 조작자 등이 적절하게 배치되어 있다. 적절한 유저 ID와 패스워드를 입력한 후에 로그인 버튼을 누르면, 유저 고유의 페이지로 천이하는 처리가 클라우드 서버 및 유저 단말기 각각에서 실행된다. 도 23은, 예를 들어 애플리케이션 개발자 단말기(2A)를 이용하는 AI 애플리케이션 개발자나, AI 모델 개발자 단 말기(2C)를 이용하는 AI 모델 개발자에게 제시되는 화면의 일례이다. 각 개발자는, 개발을 위해서 학습용 데이터 세트나 AI 모델이나 AI 애플리케이션을 마켓 플레이스를 통해서 구 입하는 것이 가능하게 되어 있다. 또한, 자신이 개발한 AI 애플리케이션이나 AI 모델을 마켓 플레이스에 등록 하는 것이 가능하게 되어 있다. 도 23에 나타내는 개발자용 화면 G2에는, 구입 가능한 학습용 데이터 세트나 AI 모델이나 AI 애플리케이션 등 (이후, 통합해서 「데이터」라고 기재)이 좌측에 표시되어 있다. 또한, 도시하고 있지 않지만, 학습용 데이터 세트의 구입 시에, 학습용 데이터 세트의 화상을 디스플레이 상에 표시시키고, 마우스 등의 입력 장치를 사용하여 화상의 원하는 부분만을 프레임으로 둘러싸서, 이름을 입력하는 것만으로, 학습의 준비를 할 수 있다. 예를 들어, 고양이의 화상으로 AI 학습을 행하고자 하는 경우, 화상 상의 고양이의 부분만을 프레임으로 둘러쌈 과 함께, 텍스트 입력으로서 「고양이」라고 입력함으로써, 고양이의 애노테이션이 부가된 화상을 AI 학습용으로 준비할 수 있다. 또한, 원하는 데이터를 발견하기 쉽도록, 목적을 선택 가능하게 되어 있어도 된다. 즉, 선택된 목적에 적합한 데이터만이 표시되는 표시 처리가 클라우드 서버 및 유저 단말기 각각에서 실행된다. 또한, 개발자용 화면 G2에서는, 각 데이터의 구입 가격이 표시되어 있어도 된다. 또한, 개발자용 화면 G2의 우측에는, 개발자가 수집 또는 작성한 학습용 데이터 세트나, 개발자가 개발한 AI 모 델이나 AI 애플리케이션을 등록하기 위한 입력란이 마련되어 있다. 각 데이터마다, 명칭이나 데이터의 보존 장소를 입력하기 위한 입력란이 마련되어 있다. 또한, AI 모델에 대해서는, 리트레인의 필요/불필요를 설정하기 위한 체크 박스가 마련되어 있다. 또한, 등록 대상의 데이터를 구입할 때 필요한 가격을 설정 가능한 가격 설정란(도면 중에서는 입력란으로 서 기재) 등이 마련되어 있어도 된다. 또한, 개발자용 화면 G2의 상부에는, 유저 정보의 일부로서 유저명이나 최종 로그인 날짜 등이 표시되어 있다. 또한, 이외에도, 유저가 데이터 구입 시에 사용 가능한 통화량이나 포인트수 등이 표시되어 있어도 된다. 도 24는, 예를 들어 자신이 관리하는 에지측의 정보 처리 장치로서의 카메라에 AI 애플리케이션이나 AI 모델 을 전개함으로써, 각종 분석 등을 행하는 유저(상술한 애플리케이션 이용 유저)에게 제시되는 이용자용 화면 G3 의 일례이다. 유저는, 마켓 플레이스를 통해서 감시 대상의 공간에 배치하는 카메라를 구입 가능하게 되어 있다. 따라서, 이용자용 화면 G3의 좌측에는, 카메라에 탑재되는 이미지 센서(IS)의 종류나 성능, 그리고 카메라의 성능 등을 선택 가능한 라디오 버튼이 배치되어 있다. 또한, 유저는, 마켓 플레이스를 통해서 포그 서버로서의 정보 처리 장치를 구입 가능하게 되어 있다. 따라 서, 이용자용 화면 G3의 좌측에는, 포그 서버의 각 성능을 선택하기 위한 라디오 버튼이 배치되어 있다. 또한, 이미 포그 서버를 갖고 있는 유저는 포그 서버의 성능 정보를 여기에 입력함으로써, 포그 서버 의 성능을 등록할 수 있다. 유저는, 자신이 경영하는 점포 등의 임의의 장소에 구입한 카메라(혹은, 마켓 플레이스를 통하지 않고 구입 한 카메라이어도 됨)를 설치함으로써 원하는 기능을 실현하는데, 마켓 플레이스에서는, 각 카메라의 기능 을 최대한 발휘시키기 위해서, 카메라의 설치 장소에 관한 정보를 등록하는 것이 가능하게 되어 있다. 이용자용 화면 G3의 우측에는, 카메라가 설치되는 환경에 관한 환경 정보를 선택 가능한 라디오 버튼이 배치되어 있다. 유저는, 카메라가 설치되는 환경에 관한 환경 정보를 적절하게 선택함으로써, 상술한 최적 의 촬상 설정이 대상의 카메라에 설정된다. 또한, 카메라를 구입함과 함께 해당 구입 예정인 카메라의 설치 장소가 정해져 있는 경우에는, 이용자용 화면 G3의 좌측의 각 항목과 우측의 각 항목을 선택함으로써, 설치 예정 장소에 따라 최적의 촬상 설정이 미리 설정된 카메라를 구입할 수 있다. 이용자용 화면 G3에는 실행 버튼이 마련되어 있다. 실행 버튼을 누름으로써, 구입에 관한 확인을 행하 는 확인 화면이나, 환경 정보의 설정을 확인하기 위한 확인 화면으로 천이한다. 이에 의해, 유저는, 원하는 카 메라나 포그 서버를 구입하는 것이나, 카메라에 관한 환경 정보의 설정을 행하는 것이 가능해진다. 마켓 플레이스에서는, 카메라의 설치 장소를 변경했을 때를 위해서, 각 카메라의 환경 정보를 변경하는 것이 가능하게 되어 있다. 도시하지 않은 변경 화면에서 카메라의 설치 장소에 관한 환경 정보를 다시 입력 함으로써, 카메라에 최적의 촬상 설정을 재설정하는 것이 가능해진다. <7. 정리> 상술한 각 예에서 설명한 바와 같이, 정보 처리 장치(클라우드 서버(1, 1A, 1B))는, 피사체를 촬상함으로써 얻 어진 촬상 화상(카메라(3, 3B)에 의한 촬상 화상)에 대해서 인공 지능 모델(에지측 AI 모델)을 사용한 화상 처 리(에지측 AI 화상 처리)를 행하는 촬상 장치(카메라(3, 3B))로부터, 화상 처리의 결과를 나타내는 결과 정보 (예를 들어 상술한 인식 결과 정보)를 취득하고, 취득한 결과 정보에 기초하여, 촬상 장치의 촬상 설정 정보 및 인공 지능 모델의 탐색을 인공 지능(탐색용 AI)을 사용하여 행하는 탐색 처리부(촬상 설정 탐색 기능(F4)과 AI 모델 탐색 기능(F5))와, 탐색 처리부가 탐색에 의해 구한 촬상 설정 정보와 인공 지능 모델을 촬상 장치에 적용하는 적용 처리부(예를 들어 통신부)를 구비한 것이다. 촬상 설정 정보란, 촬상 화상을 얻기 위한 촬상 동작에 관한 설정 정보를 넓게 의미하는 것이다. 구체적으로는, 포커스나 조리개 등과 같은 광학적인 설정이나, 프레임 레이트, 노광 시간, 게인 등과 같은 촬상 화상 신호의 판독 동작에 관한 설정, 나아가 감마 보정 처리, 노이즈 리덕션 처리, 초해상 처리 등, 읽어내진 촬상 화상 신호에 대한 화상 신호 처리에 관한 설정 등을 넓게 포함하는 것이다. 또한, 인공 지능 모델이란, 예를 들어 AI 화상 처리에 사용되는 인공 지능의 모델이다. 인공 지능 모델의 탐색 이란, 예를 들어 AI 화상 처리가 컨볼루션 연산을 포함하는 경우의 가중 계수 등의 각종 처리 파라미터나, AI 화상 처리가 뉴럴 네트워크를 사용하여 행해지는 경우의 네트워크 구조에 관한 설정 정보(예를 들어, 커널 사이 즈의 정보 등을 포함함) 등을 최적화하는 처리이다. 본 구성에 의하면, 화상 인식의 확실도나 정밀도가 낮은 경우에는, 촬상 장치의 촬상 설정 정보나 AI 화상 처리 에 사용되는 인공 지능 모델의 탐색이 행해진다. 그리고 화상 인식의 확실도나 정밀도가 향상되는 촬상 설정이 나 인공 지능 모델을 탐색에 의해 얻어, 촬상 장치에 설정(전개)된다. 따라서, 보다 적절한 촬상 설정으로 촬상된 촬상 화상에 대해서 새롭게 구축된 확실도가 높은 인공 지능 모델로 써 AI 화상 처리가 행해지기 때문에, 검출 대상의 피사체에 관한 인식을 보다 고정밀도로 행하는 것이 가능해진 다. 또한, 촬상 장치와는 다른 정보 처리 장치(클라우드 서버(1, 1A, 1B))를 사용함으로써, 촬상 장치보다 처리 성 능이 높은 컴퓨터 장치를 사용하여 탐색 처리를 행할 수 있기 때문에, 촬상 설정 및 인공 지능 모델의 탐색에 관한 처리 시간을 단축시킬 수 있다. 본 구성에 의하면, NAS(Neural Architecture Search)라고 불리는 방법으로 뉴럴 네트워크의 구조의 최적화가 행 해진다. 그리고 탐색 처리부에 의한 NAS에서는, 뉴럴 네트워크, 즉, AI 모델이 탐색 공간으로서 정의되는 것이 아니라, 촬상 장치의 노광 제어나 촬상 화상 신호에 대해서 행해지는 각종 처리에 사용되는 변수 등을 포함해서 탐색 공간이라고 정의된다. 따라서, 클라우드 서버(1, 1A, 1B)나 카메라(3, 3B)를 포함한 정보 처리 시스템 전체를 최적화하는 것이 가능해진다. 바꾸어 말하면, 유저가 원하는 애플리케이션을 실현하기 위해서, 에지측 AI 모델뿐만 아니라 촬상 화상을 얻기 위한 각종 설정이나 처리를 포함해서 전체적으로 최적화하는 것이 가능해진다. 이에 의해, 유저에게 있어서 최적의 분석 결과 정보를 얻을 수 있다. 상술한 바와 같이, 촬상 장치(카메라(3, 3B))로부터 취득한 촬상 화상에 대해서 인공 지능 모델(클라우드측 AI 모델)을 사용한 화상 처리(클라우드측 AI 화상 처리)를 행하는 화상 처리부(클라우드측 AI 화상 처리 기능(F 3))를 구비하고, 탐색 처리부(촬상 설정 탐색 기능(F4)과 AI 모델 탐색 기능(F5))는, 촬상 장치(카메라(3, 3 B))에서의 화상 처리(에지측 AI 화상 처리)와 화상 처리부에 의한 화상 처리(클라우드측 AI 화상 처리)의 인식 결과가 다른 경우에, 탐색을 행해도 된다. 예를 들어, 촬상 장치에서 사용되는 인공 지능 모델과는 다른 인공 지능 모델을 사용하여 AI 화상 처리를 행하 고, 그 결과를 비교함으로써, 촬상 장치에서의 AI 화상 처리의 정밀도를 평가하는 것이 가능해진다. 이에 의해, 촬상 장치에서의 AI 화상 처리에 사용되는 인공 지능 모델을 개량할 필요가 있는지 여부를 적절하게 판단하는 것이 가능해진다. 도 14 등을 참조하여 화상 인식을 일례로서 설명한 바와 같이, 화상 처리부(클라우드측 AI 화상 처리 기능(F 3))가 사용하는 인공 지능 모델(클라우드측 AI 모델)은, 촬상 장치(카메라(3, 3B))의 화상 처리(에지측 AI 화상 처리)에 사용되는 인공 지능 모델(에지측 AI 모델)보다 고성능인 것으로 되어도 된다. 이에 의해, 클라우드 서버(1, 1A, 1B)에서 고성능의 인공 지능 모델을 사용함으로써 얻어지는 결과 정보에 기초 하여 촬상 장치에서의 AI 화상 처리의 결과 정보의 정밀도를 판정할 수 있다. 따라서, 촬상 장치의 AI 화상 처리의 결과 정보의 정밀도를 올바르게 판정할 수 있어, 촬상 장치에 전개된 인공 지능 모델의 고성능화에 기여할 수 있다. 또한, 촬상 장치에 전개되는 에지측 AI 모델이 적절하게 소형화됨으로써, 에지측 AI 화상 처리에서 소비되는 전 력을 삭감할 수 있다. 도 14 등을 참조하여 화상 인식을 일례로서 설명한 바와 같이, 탐색 처리부(AI 모델 탐색 기능(F5))에서의 탐색 에서는, 촬상 장치(카메라(3, 3B))에서의 화상 처리(에지측 AI 화상 처리)의 결과가 화상 처리부(클라우드측 AI화상 처리 기능(F3))에 의한 화상 처리(클라우드측 AI 화상 처리)의 결과에 가까워지는 인공 지능 모델(에지측 AI 모델)을 탐색해도 된다. 이에 의해, 클라우드 서버(1, 1A, 1B)에서 사용되는 고성능의 인공 지능 모델의 결과 정보에 기초하여 촬상 장 치에서의 AI 화상 처리의 결과 정보가 올바른 것인지 여부를 판정할 수 있다. 그리고 결과 정보의 괴리에 기초해서 새롭게 인공 지능 모델의 탐색이 행해짐으로써, 고성능의 인공 지능 모델 에 성능적으로 가까운 인공 지능 모델이 탐색되어 촬상 장치에 전개된다. 따라서, 소형이면서 또한 고성능의 인공 지능 모델을 사용하여 촬상 장치에서의 AI 화상 처리를 행할 수 있다. 도 14 등을 참조하여 화상 인식을 일례로서 설명한 바와 같이, 탐색 처리부(촬상 설정 탐색 기능(F4))는, 촬상 화상을 얻을 때의 환경 정보에 기초하여 촬상 설정 정보의 탐색을 행해도 된다. 환경 정보란, 점포 내나 옥외나 차내 등, 촬상 장치(카메라(3, 3B))가 설치되어 있는 장소에 관한 정보이어도 되고, 역광이나 순광이나 사광 등 촬상 장치와 태양의 위치 관계를 나타내는 정보, 즉, 광원에 관한 정보이어도 된다. 또한, 검출 대상의 피사체를 나타내는 정보가 환경 정보에 포함되어 있어도 되고, 구체적으로는, 피사체 의 이동 속도 등이 포함되어 있어도 된다. 환경 정보를 올바르게 파악함으로써, 유저가 하고 싶은 것에 따른, 즉, 목적이나 검출 대상의 특징이나 거동 혹 은 촬영 조건 등을 가미한 적절한 촬상 설정 정보를 탐색할 수 있다. 환경 정보는, 촬상 장치(카메라(3, 3B))의 설치 장소에 관한 정보를 포함하고 있어도 된다. 촬상 장치의 설치 장소에 따라, 촬상되는 촬상 화상의 특징이 다른 경우가 있다. 본 구성에 의하면, 촬상 장치 의 설치 장소에 관한 정보로서, 예를 들어 촬상 장치에의 입사광의 광량 등의 정보를 얻을 수 있다. 또한, 촬 상 장치의 방향의 정보가 환경 정보에 포함되어 있는 경우에는, 시각 정보로부터 태양 등의 광원과의 위치 관계 를 적절하게 추정할 수 있기 때문에, 촬상 장치에의 입사광의 광량 등을 또한 적절하게 추정할 수 있다. 이에 의해, 적절한 촬상 설정 정보를 탐색할 수 있다. 또한, 환경 정보는, 촬상 장치(카메라(3, 3B))의 수광부(촬상부)에 입사하는 광에 관한 정보를 포함하고 있 어도 된다. 촬상 장치의 수광부에 입사하는 광의 광량에 따른 적절한 촬상 설정이 되어 있지 않은 경우에는, 검출 대상이 인식하기 어려운 촬상 화상이 얻어지는 경우가 있다. 본 구성에 의하면, 촬상 장치의 수광부에 입사하는 광에 관한 정보를 포함하는 환경 정보에 기초하여 촬상 설정 정보의 탐색이 행해지기 때문에, 수광부에 대한 입사광의 광량에 따른 적절한 촬상 설정 정보 등이 탐색된다. 이에 의해, 적절한 촬상 설정 정보를 촬상 장치에 설정하는 것이 가능해진다. 제1 실시 형태에서 설명한 바와 같이, 인공 지능 모델(에지측 AI 모델)의 탐색은, 촬상 장치(카메라(3, 3B))의 성능에 기초한 것으로 되어도 된다. 촬상 장치에 따라서는, 사이즈가 큰 인공 지능 모델을 전개할 수 없는 경우나, 인공 지능 모델을 사용한 AI 화 상 처리의 연산량에 대해서 연산 성능이 낮은 경우 등이 있다. 이러한 촬상 장치의 성능을 고려하지 않고 인공 지능 모델의 탐색을 행해 버리면, 촬상 장치에서의 에지측 AI 화상 처리의 성능이 저하되어 버릴 우려나, 에지측 AI 화상 처리를 애당초 실행할 수 없을 우려가 있다. 그러 나 본 구성에 의하면, 촬상 장치의 성능을 고려해서 인공 지능 모델의 탐색이 행해지기 때문에, 촬상 장치의 연 산부의 성능을 최대한 이용한 에지측 AI 화상 처리를 실행 가능한 인공 지능 모델을 탐색할 수 있다. 인공 지능 모델(에지측 AI 모델)의 탐색은, 촬상 장치(카메라(3, 3B))에서의 화상 처리(에지측 AI 화상 처리)에 관한 성능에 기초해서 행해져도 된다. 에지측 AI 화상 처리에 관한 성능을 고려해서 에지측 AI 모델의 탐색을 행함으로써, 촬상 장치에 대해서 적절한 에지측 AI 모델이 탐색되어 전개된다. 따라서, 어떠한 촬상 장치를 카메라(3, 3B)로서 사용하였다고 해도, 촬 상 장치에 따른 적절한 AI 화상 처리의 처리 결과를 얻을 수 있다. 도 13 등을 참조하여 화상 인식을 일례로서 설명한 바와 같이, 탐색에 의해 얻어지는 촬상 설정 정보와 인공 지 능 모델(에지측 AI 모델)은, 애플리케이션에 의해 다른 것으로 되어도 된다.애플리케이션이란, 촬상 장치(카메라(3, 3B))에 대해서 유저가 어떤 일을 시키고 싶은지를 나타내는 것이며, 예 를 들어 점포에 내점한 방문객의 카운트나, 방문객의 동선 분석이나, 교통량 조사나, 제조 라인에서의 불량품 검출 등을 들 수 있다. 그리고 애플리케이션이 다르면, 최적의 인공 지능 모델(에지측 AI 모델)이 다른 것을 생각할 수 있다. 본 구성에 의하면, 애플리케이션에 따라 다른 인공 지능 모델이 탐색되기 때문에, 애플리케이션에 최적인 인공 지능 모델을 촬상 장치에 전개해서 양호한 결과 정보를 얻을 수 있다. 또한, 제1 실시 형태에서, AI를 사용한 처리(AI 화상 처리)로서 화상 인식 처리를 일례로 들었지만, 화상 검출 처리 등 AI를 사용한 다른 처리(AI 화상 처리)이어도 된다. 제2 실시 형태에서 설명한 바와 같이, 탐색 처리부(처리 분담 탐색 기능(F2))는, 촬상 장치(카메라(3, 3B))와 당해 정보 처리 장치(클라우드 서버(1, 1A, 1B))를 포함하는 각 장치에서 실행하는 처리의 분담에 관한 탐색 처 리를 행해도 된다. 촬상 장치와 정보 처리 장치를 포함하는 각 장치간에서는 성능 차가 있는 것을 생각할 수 있다. 또한, 애플리 케이션의 목적을 달성할 때까지 행해지는 화상 처리(클라우드측 AI 화상 처리)나 비교 처리나 분석 처리는, 처 리에 필요한 연산량이나 메모리의 용량 등이 다르다. 본 구성에 의하면, 각 장치에 각 처리를 배분할 경우에, 각 장치의 성능이 고려된다. 따라서, 각 처리를 적재 적소에 배분할 수 있기 때문에, 처리의 효율화를 도모할 수 있다. 또한, 각 장치에서 실행하는 처리는, 결과 정보를 사용하여 행하는 분석 처리를 포함하고 있어도 된다. 배분의 대상이 되는 각 처리에 포함되는 분석 처리는, 애플리케이션에 따라 연산량이나 사용 메모리양 등이 다 른 처리이다. 이러한 처리가 적절하게 배분됨으로서, 유저가 원하는 분석 결과를 효율적으로 얻을 수 있다. 또한, 제2 실시 형태에서, AI를 사용한 처리(AI 화상 처리)로서 화상 인식 처리를 일례로 들었지만, 화상 검출 처리 등 AI를 사용한 다른 처리(AI 화상 처리)이어도 된다. 제3 실시 형태에서 설명한 바와 같이, 화상 처리부(클라우드측 AI 화상 처리 기능(F3))에 의한 화상 처리(클라 우드측 AI 화상 처리)에서는, 촬상 장치(카메라(3, 3B))에서 얻어진 촬상 화상 대신에 생성된 대체 화상이 사용 되어도 된다. 예를 들어, 촬상 장치에 대해서 마련된 본 구성의 정보 처리 장치(클라우드 서버(1, 1A, 1B))가 서버 장치인 경 우에, 서버 장치에서 화상 처리(클라우드측 AI 화상 처리)를 행하기 위해서 촬상 장치에서 촬상된 촬상 화상을 서버 장치에 송신하는 것은, 프라이버시의 관점에서 적절하지 않을 우려가 있다. 본 구성에 의하면, 대체 화상이 서버 장치로서의 정보 처리 장치에 송신되기 때문에, 프라이버시의 보호가 도모 된다. 또한, 대체 화상은, 상술한 바와 같이, 촬상 장치에서 촬상된 촬상 화상의 일부분을 사용하여 생성하는 것이 가 능하다. 이에 의해, 결과 정보의 비교를 적절하게 행할 수 있고, 나아가, 인공 지능 모델을 적절하게 탐색하는 것이 가능해진다. 제3 실시 형태에서 설명한 바와 같이, 대체 화상은, 촬상 장치(카메라(3, 3B))에서 얻어진 촬상 화상에 기초하 여 생성된 가상 화상으로 되어도 된다. 정보 처리 장치(클라우드 서버(1, 1A, 1B))가 서버 장치이었을 경우에, 본 구성에 의하면, 촬상 장치에서 촬상 된 촬상 화상을 대신해서 가상 화상을 사용하여 클라우드측 AI 화상 처리가 실행된다. 따라서, 보다 한층 프라이버시 보호를 도모할 수 있다. 또한, 제3 실시 형태에서, AI를 사용한 처리(AI 화상 처리)로서 화상 인식 처리를 일례로 들었지만, 화상 검출 처리 등 AI를 사용한 다른 처리(AI 화상 처리)이어도 된다. 상술한 바와 같이, 정보 처리 장치(클라우드 서버(1, 1A, 1B))는, 애플리케이션의 선택 정보, 즉, 유저 단말기 를 사용하여 유저에 의해 선택된 애플리케이션의 선택 정보를 취득하고, 당해 선택 정보에 따라서 촬상 설정 정보와 인공 지능 모델(에지측 AI 모델)을 선택하는 선택 처리부(애플리케이션 설정 기능)를 구비하고 있어도된다. 이에 의해, 유저는, 애플리케이션의 선택을 행하는 것만으로 최적이라고 추정된 촬상 설정 정보와 인공 지능 모 델을 촬상 장치(카메라(3, 3B))에 전개할 수 있다. 따라서, 유저가 관리하는 촬상 장치로부터 학습용 데이터 세트로서의 촬상 화상을 송신하는 처리나, 그러한 촬 상 화상을 사용한 인공 지능 모델의 재학습을 행하는 처리를 실행하지 않고, AI 화상 처리에 따른 원하는 분석 결과 정보를 얻을 수 있다. 상술한 각 예에서 설명한 바와 같이, 인공 지능 모델(AI 모델)을 사용한 화상 처리(에지측 AI 화상 처리)는, 인 공 지능 모델을 사용한 화상 인식 처리로 되어도 된다. 이에 의해, 적절한 촬상 설정으로 촬상된 화상을 사용함과 함께, 적절한 AI 애플리케이션이나 AI 모델이 전개된 상태에서 카메라에서 AI를 사용한 화상 인식 처리를 행할 수 있다. 따라서, 유저에게 있어서 화상 인식 처 리에 관한 최적의 분석 결과 정보를 얻을 수 있다. 본 기술에서의 정보 처리 방법은, 피사체를 촬상함으로써 얻어진 촬상 화상(카메라(3, 3B)에 의한 촬상 화상)에 대해서 인공 지능(에지측 AI 모델)을 사용한 화상 처리(에지측 AI 화상 처리)를 행하는 촬상 장치(카메라(3, 3B))로부터, 화상 처리의 결과를 나타내는 결과 정보를 취득하고, 취득한 결과 정보에 기초하여, 촬상 장치의 촬상 설정 정보, 및 인공 지능 모델의 탐색을 인공 지능(탐색용 AI)을 사용하여 행하는 탐색 처리와, 탐색에 의 해 구한 촬상 설정 정보와 인공 지능 모델을 촬상 장치에 적용하는 처리를 컴퓨터 장치가 실행하는 것이다. 상술한 정보 처리 장치(클라우드 서버(1, 1A, 1B))에 실행시키는 프로그램은, 컴퓨터 장치 등의 기기에 내장되 어 있는 기록 매체로서의 HDD(Hard Disk Drive)나, CPU를 갖는 마이크로컴퓨터 내의 ROM 등에 미리 기록해 둘 수 있다. 혹은 또한 프로그램은, 플렉시블 디스크, CD-ROM(Compact Disk Read Only Memory), MO(Magneto Optical) 디스크, DVD(Digital Versatile Disc), 블루레이 디스크(Blu-ray Disc(등록 상표)), 자기 디스크, 반 도체 메모리, 메모리 카드 등의 리무버블 기록 매체에, 일시적 혹은 영속적으로 저장(기록)해 둘 수 있다. 이 러한 리무버블 기록 매체는, 소위 패키지 소프트웨어로서 제공할 수 있다. 또한, 이러한 프로그램은, 리무버블 기록 매체로부터 퍼스널 컴퓨터 등에 인스톨하는 것 외에, 다운로드 사이트 로부터, LAN(Local Area Network), 인터넷 등의 네트워크를 통해서 다운로드할 수도 있다. 또한, 본 명세서에 기재된 효과는 어디까지나 예시이며 한정되는 것이 아니고, 또한 다른 효과가 있어도 된다. 또한, 상술한 각 예는 어떻게 조합해도 되며, 각종 조합을 사용한 경우라도 상술한 다양한 작용 효과를 얻는 것 이 가능하다. <8. 본 기술> 본 기술은 이하와 같은 구성을 취할 수도 있다. 피사체를 촬상함으로써 얻어진 촬상 화상에 대해서 인공 지능 모델을 사용한 화상 처리를 행하는 촬상 장치 로부터, 상기 화상 처리의 결과를 나타내는 결과 정보를 취득하고, 취득한 결과 정보에 기초하여, 상기 촬상 장 치의 촬상 설정 정보, 및 상기 인공 지능 모델의 탐색을 인공 지능을 사용하여 행하는 탐색 처리부와, 상기 탐색 처리부가 상기 탐색에 의해 구한 상기 촬상 설정 정보와 상기 인공 지능 모델을 상기 촬상 장치에 적 용하는 적용 처리부를 구비한 정보 처리 장치. 상기 촬상 장치로부터 취득한 상기 촬상 화상에 대해서 인공 지능 모델을 사용한 화상 처리를 행하는 화상 처리부를 구비하고, 상기 탐색 처리부는, 상기 촬상 장치에서의 화상 처리와 상기 화상 처리부에 의한 화상 처리의 인식 결과가 다 른 경우에, 상기 탐색을 행하는, 상기 에 기재된 정보 처리 장치. 상기 화상 처리부가 사용하는 인공 지능 모델은, 상기 촬상 장치의 화상 처리에 사용되는 인공 지능 모델보 다 고성능의 것으로 된, 상기 에 기재된 정보 처리 장치. 상기 탐색 처리부에서의 탐색에서는, 상기 촬상 장치에서의 화상 처리의 결과가 상기 화상 처리부에 의한 화상 처리의 결과에 가까워지는 인공 지능 모델을 탐색하는, 상기 에 기재된 정보 처리 장치. 상기 탐색 처리부는, 상기 촬상 화상을 얻을 때의 환경 정보에 기초하여 상기 촬상 설정 정보의 탐색을 행 하는, 상기 내지 상기 의 어느 것에 기재된 정보 처리 장치. 상기 환경 정보는, 상기 촬상 장치의 설치 장소에 관한 정보를 포함하는, 상기 에 기재된 정보 처리 장 치. 상기 환경 정보는, 상기 촬상 장치의 수광부에 입사하는 광에 관한 정보를 포함하는, 상기 내지 상기 의 어느 것에 기재된 정보 처리 장치. 인공 지능 모델의 상기 탐색은, 상기 촬상 장치의 성능에 기초한 것으로 된, 상기 내지 상기 의 어 느 것에 기재된 정보 처리 장치. 상기 촬상 장치의 성능은, 화상 처리에 관한 성능으로 된, 상기 에 기재된 정보 처리 장치. 상기 탐색에 의해 얻어지는 상기 촬상 설정 정보와 상기 인공 지능 모델은, 애플리케이션에 따라 다른 것으로 된, 상기 내지 상기 의 어느 것에 기재된 정보 처리 장치. 상기 탐색 처리부는, 상기 촬상 장치와 당해 정보 처리 장치를 포함하는 각 장치에서 실행하는 처리의 분 담에 관한 탐색 처리를 행하는, 상기 내지 상기 의 어느 것에 기재된 정보 처리 장치. 상기 각 장치에서 실행하는 처리는, 상기 결과 정보를 사용하여 행하는 분석 처리를 포함하는, 상기 에 기재된 정보 처리 장치. 상기 화상 처리부에 의한 화상 처리에서는, 상기 촬상 장치에서 얻어진 촬상 화상 대신에 생성된 대체 화 상이 사용되는, 상기 에 기재된 정보 처리 장치. 상기 대체 화상은, 상기 촬상 장치에서 얻어진 촬상 화상에 기초하여 생성된 가상 화상으로 된, 상기 (1 3)에 기재된 정보 처리 장치. 애플리케이션의 선택 정보를 취득하고, 상기 선택 정보에 따라서 상기 촬상 설정 정보와 상기 인공 지능 모델을 선택하는 선택 처리부를 구비한, 상기 내지 상기 의 어느 것에 기재된 정보 처리 장치. 상기 인공 지능 모델을 사용한 화상 처리는, 인공 지능 모델을 사용한 화상 인식 처리로 된, 상기 내 지 상기 의 어느 것에 기재된 정보 처리 장치. 피사체를 촬상함으로써 얻어진 촬상 화상에 대해서 인공 지능을 사용한 화상 처리를 행하는 촬상 장치로부 터, 상기 화상 처리의 결과를 나타내는 결과 정보를 취득하고, 취득한 결과 정보에 기초하여, 상기 촬상 장치의 촬상 설정 정보, 및 상기 인공 지능 모델의 탐색을 인공 지능을 사용하여 행하는 탐색 처리와, 상기 탐색에 의해 구한 상기 촬상 설정 정보와 상기 인공 지능 모델을 상기 촬상 장치에 적용하는 처리를 컴퓨 터 장치가 실행하는, 정보 처리 방법. 피사체를 촬상함으로써 얻어진 촬상 화상에 대해서 인공 지능을 사용한 화상 처리를 행하는 촬상 장치로부 터, 상기 화상 처리의 결과를 나타내는 결과 정보를 취득하고, 취득한 결과 정보에 기초하여, 상기 촬상 장치의 촬상 설정 정보, 및 상기 인공 지능 모델의 탐색을 인공 지능을 사용하여 행하는 탐색 기능과, 상기 탐색에 의해 구한 상기 촬상 설정 정보와 상기 인공 지능 모델을 상기 촬상 장치에 적용하는 기능을 연산 처리 장치에 실행시키는, 프로그램."}
{"patent_id": "10-2024-7013894", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 정보 처리 시스템의 구성예를 도시하는 도면이다. 도 2는 클라우드측 정보 처리 장치가 구비하는 마켓 플레이스 기능을 통해서 AI 모델이나 AI 애플리케이션의 등 록이나 다운로드를 행하는 각 기기에 대해서 설명하기 위한 도면이다. 도 3은 도 4와 함께 마켓 플레이스 기능을 통해서 AI 모델이나 AI 애플리케이션의 등록이나 다운로드를 행할 때 각 장치가 실행하는 처리의 흐름의 일례를 도시한 도면이다. 도 4는 도 3과 함께 마켓 플레이스 기능을 통해서 AI 모델이나 AI 애플리케이션의 등록이나 다운로드를 행할 때 각 장치가 실행하는 처리의 흐름의 일례를 도시한 도면이다. 도 5는 클라우드측의 정보 처리 장치와 에지측의 정보 처리 장치의 접속 양태에 대해서 설명하기 위한 도면이다. 도 6은 관리 서버의 기능 블록도이다.도 7은 클라우드 서버의 기능 블록도이다. 도 8은 카메라의 내부 구성예를 도시한 블록도이다. 도 9는 이미지 센서의 구성예를 도시하는 도면이다. 도 10은 카메라의 소프트웨어 구성을 도시하는 블록도이다. 도 11은 컨테이너 기술을 사용한 경우의 컨테이너의 동작 환경을 도시하는 블록도이다. 도 12는 정보 처리 장치의 하드웨어 구성의 일례를 도시하는 블록도이다. 도 13은 제1 실시 형태에서의 각 장치의 처리 흐름의 일례를 도시하는 도면이다. 도 14는 제1 실시 형태에서의 각 장치의 처리 흐름의 일례를 도시하는 도면이다. 도 15는 제2 실시 형태에서의 클라우드 서버의 기능 블록도이다. 도 16은 제2 실시 형태에서의 사전 학습으로서 클라우드 서버가 실행하는 처리의 흐름도이다. 도 17은 제2 실시 형태에서의 각 장치의 처리 흐름의 일례를 도시하는 도면이다. 도 18은 제3 실시 형태에서의 클라우드 서버의 기능 블록도이다. 도 19는 제3 실시 형태에서의 각 장치의 처리 흐름의 일례를 도시하는 도면이다. 도 20은 제3 실시 형태에서의 각 장치의 처리 흐름의 일례를 도시하는 도면이다. 도 21은 변형예에서의 처리의 흐름을 설명하는 도면이다. 도 22는 마켓 플레이스에 로그인하기 위한 로그인 화면의 일례를 도시하는 도면이다. 도 23은 마켓 플레이스를 이용하는 각 개발자에게 제시되는 개발자용 화면의 일례를 도시하는 도면이다. 도 24는 마켓 플레이스를 이용하는 애플리케이션 이용 유저에게 제시되는 이용자용 화면의 일례를 도시하는 도 면이다."}
