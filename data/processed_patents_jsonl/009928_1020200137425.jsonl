{"patent_id": "10-2020-0137425", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2022-0053225", "출원번호": "10-2020-0137425", "발명의 명칭": "이미지 처리 방법 및 이를 이용한 이미지 처리 장치", "출원인": "주식회사 메디트", "발명자": "백종웅"}}
{"patent_id": "10-2020-0137425", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "치아를 포함하는 대상체를 스캔하여 이미지 데이터를 획득하는 스캔 단계;상기 이미지 데이터에서 상기 치아의 우식을 판단하는 데이터 분석 단계; 및상기 우식이 판단된 이미지 데이터를 3차원으로 표시하는 디스플레이 단계;를 포함하는 것을 특징으로 하는 이미지 처리 방법."}
{"patent_id": "10-2020-0137425", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "청구항 1에 있어서,상기 이미지 데이터는 2차원 이미지 데이터인 것을 특징으로 하는 이미지 처리 방법."}
{"patent_id": "10-2020-0137425", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "청구항 1에 있어서,상기 데이터 분석 단계는,상기 이미지 데이터를 적어도 하나의 대영역으로 구분하는 단계;인공지능을 이용하여 상기 대영역별 우식을 판단하는 우식 판단 단계; 및상기 우식이 판단된 상기 이미지 데이터로부터 3차원 모델을 생성하는 단계;를 포함하는 것을 특징으로 하는 이미지 처리 방법."}
{"patent_id": "10-2020-0137425", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "청구항 3에 있어서,상기 대영역은 적어도 하나의 소영역을 포함하는 수퍼픽셀(superpixel)인 것을 특징으로 하는 이미지 처리방법."}
{"patent_id": "10-2020-0137425", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "청구항 3에 있어서,상기 대영역으로 구분하는 단계는,상기 이미지 데이터를 구분하기 위한 복수개의 대영역을 생성하는 단계;상기 복수개의 대영역 간의 특성값을 비교하는 단계; 및상기 특성값의 비교에 따라 상기 대영역의 바운더리를 조정하는 단계;를 포함하는 이미지 처리 방법."}
{"patent_id": "10-2020-0137425", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "청구항 5에 있어서,상기 복수개의 대영역의 수는 상기 이미지 데이터의 해상도에 따라 가변되는 것을 특징으로 하는 이미지 처리방법."}
{"patent_id": "10-2020-0137425", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "청구항 5에 있어서,상기 특성값을 비교하는 단계에서,공개특허 10-2022-0053225-3-상기 특성값은 상기 이미지 데이터로부터 획득한 색상 정보인 것을 특징으로 하는 이미지 처리 방법."}
{"patent_id": "10-2020-0137425", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "청구항 3에 있어서,상기 우식 판단 단계는,상기 이미지 데이터의 상기 대영역 별로 우식 여부를 판단하는 단계;판단된 상기 우식 여부를 기초로 적어도 하나의 마스크 영역을 포함하는 마스크를 생성하는 단계; 및상기 마스크 영역에 우식 표현값을 맵핑하는 단계;를 포함하는 것을 특징으로 하는 이미지 처리 방법."}
{"patent_id": "10-2020-0137425", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "청구항 3에 있어서,상기 우식 판단 단계는,상기 이미지 데이터의 상기 대영역 별로 기 설정된 기준에 따라 우식 클래스를 판단하는 단계;판단된 상기 우식 클래스를 기초로 적어도 하나의 마스크 영역을 포함하는 마스크를 생성하는 단계; 및상기 마스크 영역에 상기 우식 클래스에 대응되는 우식 표현값을 맵핑하는 단계;를 포함하는 것을 특징으로 하는 이미지 처리 방법."}
{"patent_id": "10-2020-0137425", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "청구항 9에 있어서,상기 기 설정된 기준은 ICDAS(International Caries Detection and Assessment System)인 것을 특징으로 하는이미지 처리 방법."}
{"patent_id": "10-2020-0137425", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "청구항 8 또는 청구항 9 중 어느 한 항에 있어서,상기 우식 표현값은 소정 색상 및 소정 패턴 중 적어도 하나인 것을 특징으로 하는 이미지 처리 방법."}
{"patent_id": "10-2020-0137425", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "청구항 8 또는 청구항 9 중 어느 한 항에 있어서,상기 우식 표현값이 맵핑된 상기 마스크는 상기 이미지 데이터 상에 오버랩(overlap) 되는 것을 특징으로 하는이미지 처리 방법."}
{"patent_id": "10-2020-0137425", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "청구항 9에 있어서,상기 우식 표현값은 상기 우식 클래스별 상이한 색상을 가지는 것을 특징으로 하는 이미지 처리 방법."}
{"patent_id": "10-2020-0137425", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "청구항 12에 있어서,상기 마스크가 오버랩된 상기 이미지 데이터는 3차원 모델로 생성되는 것을 특징으로 하는 이미지 처리 방법."}
{"patent_id": "10-2020-0137425", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "청구항 14에 있어서,상기 우식 표현값은 상기 3차원 모델 상에 디스플레이되는 것을 특징으로 하는 이미지 처리 방법."}
{"patent_id": "10-2020-0137425", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "공개특허 10-2022-0053225-4-치아를 포함하는 대상체를 스캔하여 이미지 데이터를 획득하는 스캔부;상기 이미지 데이터에서 상기 치아의 우식을 판단하여 데이터를 분석하는 제어부; 및상기 우식이 판단된 상기 이미지 데이터를 3차원으로 표시하는 디스플레이부;를 포함하는 것을 특징으로 하는이미지 처리 장치."}
{"patent_id": "10-2020-0137425", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "청구항 16에 있어서,상기 이미지 데이터는 2차원 이미지 데이터인 것을 특징으로 하는 이미지 처리 장치."}
{"patent_id": "10-2020-0137425", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "청구항 16에 있어서,상기 제어부는,상기 이미지 데이터를 적어도 하나의 대영역으로 구분하는 대영역 생성조정부;인공지능을 이용하여 상기 대영역별 우식을 판단하는 우식 판단부;를 포함하는 것을 특징으로 하는 이미지 처리장치."}
{"patent_id": "10-2020-0137425", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "청구항 18에 있어서,상기 대영역은 적어도 하나의 소영역을 포함하는 수퍼픽셀(superpixel)인 것을 특징으로 하는 이미지 처리장치."}
{"patent_id": "10-2020-0137425", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "청구항 18에 있어서,상기 대영역 생성조정부는,(1) 상기 이미지 데이터를 구분하기 위한 복수개의 대영역을 생성하고,(2) 상기 복수개의 대영역 간의 특성값을 비교하며,(3) 상기 특성값의 비교에 따라 상기 대영역의 바운더리를 조정하는 것을 특징으로 하는 이미지 처리 장치."}
{"patent_id": "10-2020-0137425", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_21", "content": "청구항 20에 있어서,상기 특성값은 상기 이미지 데이터로부터 획득한 색상 정보인 것을 특징으로 하는 이미지 처리 장치."}
{"patent_id": "10-2020-0137425", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_22", "content": "청구항 18에 있어서,상기 우식 판단부는 상기 이미지 데이터의 상기 대영역 별로 우식 여부를 판단하는 것을 특징으로 하는 이미지처리 장치."}
{"patent_id": "10-2020-0137425", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_23", "content": "청구항 18에 있어서,상기 우식 판단부는 상기 이미지 데이터의 상기 대영역 별로 우식 클래스를 판단하는 것을 특징으로 하는 이미지 처리 장치."}
{"patent_id": "10-2020-0137425", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_24", "content": "공개특허 10-2022-0053225-5-청구항 23에 있어서,상기 우식 클래스는 ICDAS(International Caries Detection and Assessment System) 기준에 따라 분류되는 것을 특징으로 하는 이미지 처리 장치."}
{"patent_id": "10-2020-0137425", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_25", "content": "청구항 18에 있어서,상기 제어부는,상기 우식 판단부에 의해 상기 대영역별로 우식 여부 또는 우식 클래스가 판단된 결과로 적어도 하나의 마스크영역을 포함하는 마스크를 생성하는 마스크 생성부;를 더 포함하며,상기 마스크 생성부는,상기 마스크 영역별 상기 우식 판단부에 의해 판단된 우식 여부 또는 우식 클래스에 대응되는 우식 표현값을 맵핑하여, 상기 마스크를 상기 이미지 데이터에 오버랩(overlap)하는 것을 특징으로 하는 이미지 처리 장치."}
{"patent_id": "10-2020-0137425", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_26", "content": "청구항 25에 있어서,상기 제어부는,상기 마스크가 오버랩된 상기 이미지 데이터를 3차원 모델로 생성하는 3차원 모델 생성부;를 더 포함하는 것을특징으로 하는 이미지 처리 장치."}
{"patent_id": "10-2020-0137425", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_27", "content": "청구항 25에 있어서,상기 디스플레이부는,상기 3차원 모델 및 상기 3차원 모델 상에 오버랩된 상기 우식 표현값을 함께 디스플레이하는 것을 특징으로 하는 이미지 처리 장치."}
{"patent_id": "10-2020-0137425", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명에 따른 이미지 처리 방법은, 치아를 포함하는 대상체를 스캔하여 이미지 데이터를 획득하는 스캔 단계, 상기 이미지 데이터에서 상기 치아의 우식을 판단하는 단계, 및 상기 우식이 판단된 상기 이미지 데이터를 디스 플레이하는 단계를 포함할 수 있다. 본 발명에 따라, 사용자(치료자)는 환자의 치아에 대해 우식 여부 및/또는 우식 클래스를 신속하고 객관적으로 판단하고 적합한 치료를 제공할 수 있다."}
{"patent_id": "10-2020-0137425", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 이미지 처리 방법 및 이를 이용한 이미지 처리 장치에 관한 것이다."}
{"patent_id": "10-2020-0137425", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "치아 우식(dental caries)은 치과 진료 중 높은 비율을 차지한다, 우식 치아의 치료를 위하여, 우식이 발생한 부분을 삭제하고, 삭제된 부분을 아말감(amalgam), 레진(resin), 또는 금(gold)으로 충진하는 방법으로 치료가 수행되고 있다. 치료자는 환자의 치아 상태를 확인하고, 환자에게 치아 상태에 따른 적합한 치료 방법을 제안한다. 그러나, 일 반적으로 치료자는 육안으로 환자의 치아 상태를 확인하므로 주관적인 판단에 주로 의존하게 된다. 이러한 판단 은 치료 상황마다 달라질 수 있으며, 부정확한 판단을 야기할 수 있다. 한편, 3차원 스캐닝 기술은 측정, 검사, 역설계, 컨텐츠 생성, CAD/CAM, 의료기기 등 다양한 산업 분야에서 사 용되고 있으며 컴퓨팅 기술의 발전으로 인한 스캐닝 성능의 향상으로 인해 그 실용성이 더욱 확대되고 있다. 특 히, 정밀한 측정이 필요한 덴탈 분야에서 3차원 스캐닝 기술은 사용 빈도가 증가하는 추세이다. 덴탈 산업 분야 에서, 3차원 스캐닝 기술을 사용하여 우식 여부를 포함하는 치아의 상태를 진단하는 방법에 대한 산업계의 요구 가 존재한다. 한국 등록특허 제1574376호에서는 치아의 우식을 탐지하기 위해 발광 수단을 이용한다. 발광 수단은 일반적으로 형광광을 사용할 수 있으며, 치아에 형광을 조사하기 위해서는 스캐너 등에 발광 수단을 포함하여야 한다. 발광 수단을 포함하는 스캐너는 상대적으로 무겁고 고비용에 해당한다. 따라서, 별도의 발광 수단을 구비하지 않고치아의 우식 여부 및 우식 상태를 표현해줄 수 있는 방법 및 시스템에 대한 요구가 존재한다. 선행기술문헌 특허문헌 (특허문헌 0001) KR 10-2020-0050346 A"}
{"patent_id": "10-2020-0137425", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 치료자의 치아 상태 확인을 위한 불필요한 과정 수행을 방지하고, 스캔을 통해 치아의 우식된 부분을 시각적으로 표현할 수 있는 이미지 처리 방법을 제공한다. 또한, 상기와 같은 이미지 처리 방법을 사용하기 위한 과정들이 수행되어 치아의 우식된 부분을 시각적으로 표 현할 수 있는 이미지 처리 장치를 제공한다. 본 발명의 기술적 과제들은 이상에서 언급한 기술적 과제들로 제한되지 않으며, 언급되지 않은 또 다른 기술적 과제들은 아래의 기재들로부터 당업자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2020-0137425", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "전술한 바와 같은 목적을 달성하기 위해, 본 발명에 따른 이미지 처리 방법은 치아를 포함하는 대상체를 스캔하 여 이미지 데이터를 획득하는 스캔 단계와, 스캔 단계로부터 획득한 이미지 데이터에서 우식을 판단하는 데이터 분석 단계, 그리고 우식 분석 결과를 3차원으로 표시하는 디스플레이 단계를 포함한다. 한편, 본 발명에 따른 이미지 처리 장치는 치아를 포함하는 대상체를 스캔하여 이미지 데이터를 획득하는 스캔 부와, 이미지 데이터에서 치아의 우식을 판단하여 데이터를 분석하는 제어부, 그리고 우식이 판단된 이미지 데 이터를 3차원으로 표시하는 디스플레이부를 포함하여 다양한 구성요소를 가질 수 있다."}
{"patent_id": "10-2020-0137425", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명에 따른 이미지 처리 방법 및 이미지 처리 장치를 사용함으로써, 각각의 치아의 우식 상태를 판단하기 위한 과정이 신속하게 수행되는 이점이 있다. 또한, 본 발명에 따른 이미지 처리 방법 및 이미지 처리 장치를 사용함으로써, 별도의 발광 수단을 사용하지 않 고 우식 치아를 판단할 수 있다. 이는 장치의 경량화 및 비용 감소로 이어지는 이점이 있다. 또한, 이미지 데이터를 3차원 모델로 생성하여, 우식 영역에 해당하는 복셀을 시각적으로 표시함으로써, 사용자 (치료자)는 환자의 구강 내부에서 명확한 위치에 어느 정도의 치아 우식이 발생하였는지 용이하게 확인할 수 있 다. 따라서, 사용자는 다시 실제 치아를 확인하지 않고 소정 치아의 상태에 따라 적합한 치료방법을 제시할 수 있다."}
{"patent_id": "10-2020-0137425", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 본 발명의 일부 실시예들을 예시적인 도면을 통해 상세하게 설명한다. 각 도면의 구성요소들에 참조부호 를 부가함에 있어서, 동일한 구성요소들에 대해서는 비록 다른 도면상에 표시되더라도 가능한 한 동일한 부호를 가지도록 하고 있음에 유의해야 한다. 또한, 본 발명의 실시예를 설명함에 있어, 관련된 공지 구성 또는 기능에 대한 구체적인 설명이 본 발명의 실시예에 대한 이해를 방해한다고 판단되는 경우에는 그 상세한 설명은 생략한 다. 본 발명의 실시예의 구성 요소를 설명하는 데 있어서, 제 1, 제 2, A, B, (a), (b) 등의 용어를 사용할 수 있다. 이러한 용어는 그 구성 요소를 다른 구성 요소와 구별하기 위한 것일 뿐, 그 용어에 의해 해당 구성 요소 의 본질이나 차례 또는 순서 등이 한정되지 않는다. 또한, 다르게 정의되지 않는 한, 기술적이거나 과학적인 용 어를 포함해서 여기서 사용되는 모든 용어들은 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자에 의해 일반적으로 이해되는 것과 동일한 의미를 가진다. 일반적으로 사용되는 사전에 정의되어 있는 것과 같은 용어들 은 관련 기술의 문맥상 가지는 의미와 일치하는 의미를 가진 것으로 해석되어야 하며, 본 출원에서 명백하게 정 의하지 않는 한, 이상적이거나 과도하게 형식적인 의미로 해석되지 않는다. 본 발명을 설명함에 있어서, 이미지 데이터를 구성하는 최소 단위인 픽셀(pixel)은 소영역으로, 소정 픽셀의 집 합인 수퍼픽셀(superpixel)은 대영역으로 명명한다. 도 1은 본 발명에 따른 이미지 처리 방법의 순서도, 도 2 내지 도 4는 본 발명에 따른 이미지 처리 방법의 세부 순서도이다. 도 1을 참조하면, 본 발명에 따른 이미지 처리 방법은, 치아를 포함하는 대상체를 스캔하여 이미지 데이터를 획 득하는 스캔 단계(S110)와, 이미지 데이터에서 치아의 우식을 판단하는 데이터 분석 단계(S130), 그리고 우식이 판단된 이미지 데이터를 3차원으로 표시하는 디스플레이 단계(S150)를 포함할 수 있다. 이하에서는, 각 단계에 대하여 상세히 설명하기로 한다. 스캔 단계(S110) 본 발명에 따른 이미지 처리 방법은 스캔 단계(S110)를 포함한다. 스캔 단계(S110)는 대상체를 스캔하여 이미지 데이터를 획득하는 단계일 수 있다. 대상체는 다양한 물체일 수 있으나, 본 발명의 목적을 고려하였을 때, 치아, 치은(잇몸), 악궁 등을 포함하는 환자의 구강 내부일 수 있다. 스캔 단계(S110)는 후술할 이미지 처리 장 치의 스캔부에 의해 수행되며, 스캔부는 대상체와의 스캔거리와 스캔각도를 자유롭게 조절할 수 있는 핸드헬드 형 스캐너(handheld scanner)일 수 있다. 이미지 데이터는 2차원 이미지 데이터 또는 3차원 이미지 데이터의 샷(shot)일 수 있다. 스캔 단계(S110)에서 획득된 이미지 데이터는 후술할 분석하는 단계(S130)에서 사용될 수 있다. 일 실시예로, 스캔 단계(S110)는 대상체에 대한 사진을 찍는 것을 의미할 수 있으며, 이 경우 이미지 데이터는 2차원 이미지 데이터일 수 있다. 보다 구체적으로, 본 발명은 우식 판단시에, 상기 2차원 이미지를 유사한 특성 값을 갖는 대영역으로 구분하고, 상기 대영역으로부터 우식을 판단한다. 이는 3차원 데이터로부터 특성값을 획 득하고 분석하는 것에 비해 저장 공간을 절약하고 리소스 낭비를 방지할 수 있는 장점이 있다. 한편, 스캔부는, 획득한 이미지 데이터로부터 입체적인 3차원 모델을 생성하기 위해, 대상체에 광을 조사할 수 있다. 이 때, 대상체를 향하여 조사되는 광은 다양한 형태를 가질 수 있다. 예시적으로, 상기 광은 가시광선 영 역의 파장을 가지는 광일 수 있다. 또한, 상기 광은 소정 패턴을 가지는 구조광일 수 있다. 구조광은 이미지 데 이터가 깊이 정보를 가지도록 할 수 있으며, 예시적으로 서로 다른 색상의 직선 무늬가 연속적으로 나타나는 스 트라이프 패턴이 구조광으로 사용될 수 있다. 구조광의 패턴은 패턴 마스크 또는 DMD(Digital MicromirrorDevice)와 같은 패턴 생성 수단을 통해 생성될 수 있다. 다만, 3차원 모델을 획득하기 위해 반드시 구조광 방식 을 사용할 필요는 없으며, 3차원 모델을 생성하기 위해 깊이 정보를 획득할 수 있는 어떠한 방식이라도 가능하 다. 데이터 분석 단계(S130) 이어서, 전술한 스캔 단계(S110)에서 획득한 이미지 데이터를 통해, 치아의 우식을 판단하는 데이터 분석 단계 (S130)가 수행될 수 있다. 도 2를 참조하면, 데이터 분석 단계(S130)는 이미지 데이터를 소정의 대영역으로 구 분(S131)하고, 이미지 데이터로부터 치아의 우식을 판단(S132)하며, 우식이 판단된 이미지 데이터로부터 3차원 모델을 생성하는 단계(S133)들을 포함할 수 있다. 즉, 데이터 분석 단계(S130)는 스캔 단계(S110)에서 획득한 이미지 데이터를 해석, 가공하는 과정들을 포함한다. 이하에서는 데이터 분석 단계(S130)의 세부적인 구성에 대해 설명하기로 한다. 도 2를 참조하면, 데이터를 분석하는 단계(S130)는 이미지 데이터를 적어도 하나의 대영역으로 구분하는 단계 (S131)를 포함할 수 있다. 실질적으로 대영역은 복수개일 수 있고, 대영역들 간에는 바운더리(boundary)를 가진 다. 이 때, 대영역은 적어도 하나의 소영역을 포함하는 수퍼픽셀(superpixel)일 수 있다. 한편, 이미지 데이터를 적어도 하나의 대영역으로 구분하는 것은 상기 대영역 별로 우식을 판단하기 위한 것으 로, 이를 통해 본 발명에 따른 이미지 처리 방법을 수행하는 장치의 연산 부하를 경감시킬 수 있다. 도 3 및 도 5 내지 도 8은 본 발명에 따른 이미지 처리 방법 중 대영역이 생성되고 조정되는 과정을 설명하기 위한 도이다. 도 3 및 도 5를 참조하면, 대영역으로 구분하는 단계(S131)는, 이미지 데이터를 구분하기 위한 복수개의 대영역 을 생성하는 단계(S1311)를 포함한다. 예시적으로, 이미지 데이터는 직사각형의 형태로 획득되며, 이미지 데이 터는 이미지를 표현하기 위한 최소 단위인 소영역의 집합으로 이루어져 있다. 이미지 데이터는 M×N(M, N은 자연수) 개의 소영역이 일정한 배열로 집합 형성된 것일 수 있다. 이 때, 복수개 의 대영역을 생성하는 단계(S1311)는 이미지 데이터를 동일한 크기를 가지고 동일한 수의 소영역을 포함하도록 대영역을 생성할 수 있다. 예를 들면, 이미지 데이터가 1600×1200개의 소영역 해상도를 가지고 있는 경우, 400 ×300개의 소영역을 가지는 16개의 대영역이 생성되어 이미지 데이터를 구분할 수 있다. 이미지 데이터를 복수 개의 대영역으로 구분하면, 후술할 특성값을 비교하는 단계(S1312) 및 바운더리를 조정하는 단계(S1313)가 신속 하게 수행될 수 있다. 상기 복수개의 대영역을 생성하는 단계(S1311)는 이미지 데이터의 해상도에 따라 대영역의 수를 적절히 설정한 것일 수 있다. 예시적으로, 이미지 데이터가 1600×1200개의 소영역 해상도를 가지고, 기 설정된 10개의 대영역 을 생성하도록 이미지 데이터를 구분할 수 있다. 이 때, 대영역의 수에 따라, 이미지 데이터는 320×600개의 소 영역 해상도를 가지는 대영역들로 구분될 수 있다. 본 발명을 설명하기 위한 예시로, 6×6개의 소영역을 가지는 이미지 데이터가 제시된다. 이미지 데이터는 복수 개의 대영역(710, 720, 730, 740, 750, 760)으로 구분되기 위해, 2×3개의 소영역을 가지는 동일한 크기의 6개 의 대영역으로 구분될 수 있다. 이러한 대영역들(710, 720, 730, 740, 750, 760) 간의 바운더리(BD)가 임시적으 로 설정될 수 있으며, 바운더리(BD)는 바운더리를 조정하는 단계(S1313)에 의해 변경될 수 있다. 전술한 대영역의 수, 및 대영역의 크기는 예시적인 것이며, 사용자의 필요 또는 이미지 데이터의 조건에 따라 가변적으로 설정될 수 있다. 상기 바운더리를 조정하기 위해, 대영역으로 구분하는 단계(S131)는 복수개의 대영역 간의 특성값을 비교하는 단계(S1312)를 포함한다. 특성값을 비교하는 단계(S1312)는, 동일 또는 유사한 특성을 가지는 소영역들끼리 대 영역으로 그룹화시키기 위한 일 과정이다. 특성값은 이미지 데이터로부터 획득한 정보들 중 적어도 하나일 수 있다. 예시적으로, 특성값은 이미지 데이터를 구성하는 각각의 소영역에서, 해당 소영역에 입력된 데이터의 색상(color) 정보, 크기(size) 정보, 질감(texture) 정보, 및 바운더리 박스(boundary box)의 차이를 나타내는 필(fill) 정보를 포함할 수 있다. 이 때, 우식을 판단하기 위한 본 발명의 목적상, 특성값으로 사용되는 정보로 색상 정보가 적합할 수 있다. 한편, 특성값을 비교하는 단계(S1312)는 대영역의 바운더리(BD)에 인접하는 소영 역들의 특성값을 비교하는 것일 수 있다. 바운더리(BD)에 인접하는 소영역들의 특성값을 비교함으로써, 특성값 이 유사한 소영역들끼리 대영역을 형성하도록 바운더리(BD)가 변경(S1313)될 수 있다. 도 6 내지 도 8을 참조하면, 대영역으로 구분된 이미지 데이터는 각각의 소영역에 해당하는 픽셀(711 내지 716, 721 내지 726)의 색상 정보를 획득한다. 이 때, 색상 정보는 Gray 모델, RGB 모델, HSV 모델, CMYK 모델, YCbCr 모델 등 다양한 색상 모델을 통해 획득할 수 있다. 다만, Gray 모델은 0 내지 255의 무채색을 표현하는 것으로, 명확한 특성값 비교 및 실질적인 우식 판단이 용이하지 않다. 따라서, 사용되는 색상 모델은 유채색의 색상 모델일 수 있다. 한편, 소영역 간의 유사성을 판단하기 위해 해당 색상 모델의 컬러 히스토그램(color histogram)을 특성값으로 사용할 수 있다. 보다 상세하게는, 컬러 히스토그램을 통한 유사성 판단은, 각각의 소영역에 대한 컬러 히스토그램이 생성되고, 바운더리(BD)를 사이에 두고 인접하는 소영역들의 컬러 히스토그램을 중첩시켜 유사성 여부를 판단하는 것일 수 있다. 예시적으로, 바운더리를 사이에 두고 인접하는 임의의 제1 소영역과 임의의 제2 소영역(미도시)에 대하여 각각의 컬러 히스토그램이 생성되고, 생성된 컬러 히스토그램들을 중첩시키면, 중첩되는 면적이 계산될 수 있다. 이 때, 중첩되는 면적이 임계값 이상의 값을 가지는 경우, 제1 소영역과 제2 소영역은 유사한 특성값을 가지는 것으로 판단될 수 있다. 이하에서는, 설명상 편의를 위하여 하나의 소영역이 하나의 대표적인 색상을 가지는 것으로 설명한다. 다만, 이 는 하나의 소영역이 대표적인 색상을 포함하는 컬러 히스토그램을 가지는 것으로 해석되어야 한다. 도 6을 참조하면, 각각의 소영역에는 특성값이 할당되어 있다. 이 때, 대영역의 바운더리에 인접한 소영역들 간 의 특성값 비교가 수행될 수 있다. 예시적으로, 제1 대영역의 제2 소영역과, 제2 대영역의 제1 소영역의 특성값 비교가 수행될 수 있다. 도시된 바와 같이, 제1 대영역 중 제2 소영역의 특성 값과 제2 대영역 중 제1 소영역의 특성값은 모두 W(백색)일 수 있다. 또한, 제1 대영역 중 제4 소영역의 특성값과 제2 대영역 중 제3 소영역의 특성값이 서로 비교될 수 있다. 도시된 바와 같이, 제1 대영역 중 제4 소영역의 특성값과 제2 대영역 중 제3 소영역의 특성값은 모두 B(검정색)일 수 있다. 마찬가지로, 제1 대영역 중 제6 소영역의 특성값과 제2 대영역 중 제5 소영역의 특성값이 서로 비교될 수 있다. 도시된 바와 같이, 제1 대영역 중 제6 소영역의 특성값은 W(백색)일 수 있고, 제2 대영역 중 제5 소영역의 특성값은 Y(황색)일 수 있다. 바운더리(BD)에 인접한 소영역들의 특성값 비교에 따라, 바운더리(BD)는 새로운 바운더리(BD')로 조정(S1313)될 수 있다. 도 7을 참조하면, 제2 대영역의 제1 소영역이었던 부분은 제1 대영역으로 편입되어 제 1 대영역의 제7 소영역(721')에 해당될 수 있다. 또한, 제1 대영역의 제4 소영역이었던 부분은 제2 대영역으로 편입되어 제2 대영역의 제7 소영역(714')에 해당될 수 있다. 따라서, 소영역들이 속 한 대영역의 변경에 따라 바운더리(BD')가 조정될 수 있다. 소영역의 조정은 기존의 바운더리(BD)에 인접한 소 영역들에 각각 인접하는 다른 소영역들의 특성값을 참조하여 수행될 수 있다. 이미지 데이터에서 바운더리(BD) 의 지속적인 갱신에 따라, 유사한 특성값을 가지는 소영역들끼리 대영역을 형성할 수 있다. 도 8을 참조하면, 이미지 데이터에 따라, 대영역의 수는 변경될 수 있고, 이에 따라 초기 대영역에 포함되어 있 던 소영역의 개수 또한 변경될 수 있다. 보다 상세하게는, 소영역의 특성값 분포에 따라, 대영역의 수는 최초 생성된 대영역의 수보다 많거나 적을 수 있다. 예시적으로, 제1 대영역에 포함되었던 제4 소영역과, 제2 대영역에 포함되었던 제3 소영역이 하나의 새로운 대영역을 형성할 수 있다. 새로운 대영역 (770\")은 B(검정색)의 특성값을 가지는 소영역들(714\", 723\")을 포함할 수 있다. 이와 같이, 유사한 특성값을 가지는 소영역들끼리 대영역을 형성함으로써, 수퍼픽셀(superpixel)의 형태로 이미지 데이터가 구분될 수 있다. 따라서, 치아의 우식 여부는 대영역 별로 판단될 수 있으며, 사용자는 신속하게 우식이 발생한 치아를 확인할 수 있다. 또한, 대영역 단위로 우식 치아를 판단함으로써, 본 발명에 따른 이미지 처리 방법을 수행하는 장치의연산 부하를 경감시킬 수 있다. 도 9는 본 발명에 따른 이미지 처리 방법에 의해 대영역이 조정되는 이미지 데이터를 예시적으로 나타낸 도이다. 도 9(a) 내지 도 9(c)에 도시된 바에 따르면, 이미지 데이터가 특성값(예시적으로, 색상 정보)에 따라 영역이 조정된다. 먼저 도 9(a)에서, 동일한 크기를 가지는 대영역이 생성되어 이미지 데이터를 구분한다. 도 9(b)에서 는 이웃하는 대영역들의 바운더리 인근에서 특성값 비교가 수행되고, 유사한 특성값을 가지는 소영역들끼리 대 영역을 형성하도록 바운더리의 조정이 수행된다. 바운더리의 조정이 수행됨으로써, 일부 대영역이 새로 생성되 거나 또는 병합될 수 있다. 도 9(c)에서는 바운더리의 조정이 완료되어 이정표, 제1 구름, 제2 구름, 및 배경이 인식될 수 있을 정도로 정밀하게 구분된다. 이하에서는, 도 4를 참조하여 우식 판단 단계(S132)에 대해 상세히 설명하기로 한다. 우식 판단 단계(S132)는 대영역 별로 우식 여부를 판단하거나, 우식으로 판단된 영역에 대해 우식 클래스를 판 단하는 우식 분류 단계(S1321)를 포함한다. 구체적으로, 우식 분류 단계(S1321)는 인공 지능(Artificial Intelligence, AI)를 이용하여 대영역화된 이미지 데이터 내 우식 특징 및/또는 우식의 심각성 정도를 추출할 수 있다. 상기 인공지능은 딥 러닝(deep learning)일 수 있고, 구체적으로는 ANN(Artificial Neural Network), CNN(Convolution Neural Network), DNN(Deep Neural Network), 및 RNN(Recurrent Neural Network) 중 선택된 1종 이상일 수 있다. 본 발명에서는 예시적으로, CNN(Convolution Neural Network)을 이용할 수 있으며, CNN은 컨벌루전 레이어 (convolution layer), 풀링 레이어(pooling layer) 순으로 수행되거나, 컨벌루전 레이어와 풀링 레이어에 더하 여 풀리 커넥티드 레이어(fully connected layer)가 추가적으로 수행될 수 있다. 보다 구체적으로는, CNN은 n×n 크기의 커널 필터(kernel filter)를 이용하여 컨벌루전 연산을 수행하는 컨벌루 전 레이어를 통해 특징 맵(feature map)을 획득한다. 이후, 풀링 레이어는 n×n 크기의 커널 필터(kernel filter)를 이용하여 특징 맵의 값을 샘플링하여 특징 맵의 우식 특징을 부각시킨다. 상기와 같은 과정을 반복적 으로 수행함으로써 우식 특징이 추출될 수 있고, 선택적으로 풀리 커넥티드 레이어에서 기설정된 기준에 따라 우식 클래스(class, 우식의 심각성)을 분류할 수 있다. 한편, 기설정된 기준은 예시적으로 ICDAS(International Caries Detection and Assessment System)일 수 있다. ICDAS는 우식의 심각성 정도를 단계적으로 분류한 기준으로, 0부터 6까지의 정수로 구성된 7개의 레벨로 나눠진 다. 상기 레벨은 대영역의 특성값에 의해 결정될 수 있다. 우식 클래스가 분류된 이후에, 우식 판단 단계(S132)는 판단된 우식 여부 및/또는 우식 클래스를 기초로 적어도 하나의 마스크 영역을 포함하는 마스크(mask)를 생성(S1322)할 수 있다. 마스크는 우식 여부 및/또는 우식 클래 스에 의해 우식이 발생한 것으로 판단된 부분들의 집합일 수 있으며, 상기 부분들은 대영역들일 수 있다. 즉, 우식이 발생한 것으로 판단된 대영역이 마스크에 포함된 마스크 영역을 구성할 수 있다. 이후, 상기 마스크 영역에 우식 여부 및/또는 우식 클래스에 대응되는 우식 표현값이 맵핑(mapping)될 수 있다 (S1323). 우식 표현값이 맵핑되는 것은 마스크 영역에 특정한 표현값이 할당되는 것을 의미할 수 있다. 우식 표 현값은 디스플레이 단계에서 사용자에게 치아 우식 여부를 시각적으로 나타낼 수 있는 수단일 수 있다. 예시적 으로, 우식 표현값은 소정 색상 및 소정 패턴 중 적어도 하나일 수 있다. 우식 표현값이 맵핑된 마스크는 이미 지 데이터 상에 오버랩(overlap) 되며, 이미지 데이터 또는 후술할 3차원 모델을 표시할 때 함께 표시될 수 있 다. 우식 표현값은 우식 여부 및/또는 우식 클래스를 기준으로 맵핑될 수 있다. 예시적으로, 우식 분류 단계(S132 1)에서 우식이 발생하지 않은 부분은 마스크로 형성되지 않고, 우식이 발생한 부분은 마스크로 형성된다. 따라 서, 마스크 전체에 대하여 소정 색상 및 소정 패턴 중 적어도 하나를 맵핑함으로써, 우식의 존재 여부만을 시각 적으로 표시할 수 있다. 즉, 우식 표현값은 우식 클래스와 관계없이 동일한 값을 가질 수 있다. 예를 들면, 우식 표현값은 우식 클래스가 분류되지 않고 우식 여부만이 판단된 결과에 따라, 우식이 발생한 부분에 하나의 우 식 표현값이 적용되거나, 우식 클래스가 3 내지 6인 마스크 영역에 대해서 하나의 우식 표현값이 적용될 수 있 다. 우식 표현값은 형광색, 적색, 또는 흑색 색상일 수 있다. 사용자는 우식 표현값이 표시됨에 따라, 우식이 발생한 치아를 용이하게 확인할 수 있다. 또는, 우식 표현값은 우식 클래스 별로 상이한 값을 가지도록 맵핑될 수 있다. 보다 상세하게는, 마스크는 우식 클래스 별로 형성된 마스크 영역을 포함하고, 상기 마스크 영역의 우식 클래스 별로 서로 다른 색상이 맵핑될 수 있다. 우식 클래스 분류와 우식 표현값 맵핑에 대해 보다 상세하게 설명한다. 예시적으로, 대영역은 백색(white), 황 색(yellow), 갈색(brown), 검정색(black)과 같이 다양한 특성값을 가질 수 있다. 한편, 하나의 대영역은 동일 또는 유사한 특성값을 가지는 소영역들로 구성될 수 있다. 인공지능을 이용하여 상기 대영역의 특성값들로부터 우식 특징 및/또는 우식 클래스를 추출하고, 추출한 값을 기초로 마스크를 생성할 수 있다. 생성된 마스크는 적 어도 하나의 마스크 영역을 포함하며, 마스크 영역에 우식 표현값이 맵핑될 수 있다. 예를 들면, 기 설정된 기준에 따라 임의의 대영역에서 특성값이 백색인 경우 해당 영역은 우식이 발생하지 않은 부분으로 판단되고(레벨 0), 마스크로 형성되지 않는다. 또한, 특성값이 황색인 부분이 마른 법랑질(dry enamel)에 위치하는 경우 경미한 우식이 발생한 부분으로 판단되고(레벨 1), 해당 우식 영역에 대응되는 마스크 영역에 우식 표현값이 맵핑될 수 있다. 또한, 특성값이 황색인 부분이 젖은 법랑질(wet enamel)에 위치하는 경 우 보통의 우식이 발생한 부분으로 판단되고(레벨 2), 해당 우식 영역에 대응되는 마스크 영역에 우식 표현값이 맵핑될 수 있다. 또한, 치아에 캐비티(cavity)가 발생한 경우, 해당 영역은 캐비티의 면적 및/또는 비율에 따라 3 내지 6의 레벨 의 우식이 발생한 부분으로 판단되고, 해당 우식 영역에 대응되는 마스크 영역에 우식 표현값이 맵핑될 수 있다. 보다 구체적으로는, 상기 캐비티에 따른 3 내지 6의 레벨은, 특성값이 검정색인 대영역이 점유하는 비율, 또는 특성값이 검정색인 대영역의 면적에 따라 판단될 수 있다. 또는, 이러한 비율과 면적의 관계를 혼용하여 우식 클래스가 분류될 수 있다. 예시적으로 법랑질에 해당하는 부분에서, 특성값이 검정색이고 0.5mm 미만의 크기를 가지는 대영역은, 해당 우 식 영역에 대응되는 마스크 영역에 우식 표현값이 매핑될 수 있다. 유사하게, 특성값이 검정색인 대영역이 소정 이미지 데이터의 절반 이상을 차지하는 경우 매우 심각한 우식이 발생한 것으로 판단되고, 해당 우식 영역에 대 응되는 마스크 영역에 우식 표현값이 맵핑될 수 있다. 상기와 같은 과정에 따라, 우식이 발생한 부분을 나타낼 수 있다. 다만, 우식 클래스를 분류하기 위한 기준 수치는 본 발명을 설명하기 위해 예시적으로 사용된 것이다. 따라서, 필요에 따라, 상기 수치는 변경될 수 있다. 우식 표현값이 우식 클래스에 따라 상이한 색상을 가지는 내용에 대하여 상세히 설명하기로 한다. 예시적으로, 우식 클래스가 레벨 0인 경우 마스크로 형성되지 않으므로 우식 표현값이 맵핑되지 않는다. 우식 클래스가 레벨 1인 경우 대응되는 마스크 영역에 녹색(green)이, 우식 클래스가 레벨 2인 경우 대응되는 마스크 영역에 청록색 (cyan)이, 우식 클래스가 레벨 3인 경우 대응되는 마스크 영역에 심홍색(magenta)이, 우식 클래스가 레벨 4인 경우 대응되는 마스크 영역에 청색(blue)이, 우식 클래스가 레벨 5인 경우 대응되는 마스크 영역에 적색(red)이, 그리고 우식 클래스가 레벨 6인 경우 대응되는 마스크 영역에 검정색(black)이 각각 맵핑될 수 있 다. 전술한 바와 같이 우식 표현값이 맵핑된 마스크는 이미지 데이터 상에 오버랩되어 이미지 데이터의 실제 색상과 함께 표시될 수 있다. 한편, 마스크는 소정의 투명도를 가질 수 있다. 마스크가 소정의 투명도를 가짐으로써, 사용자는 치아의 실제 형태와 우식 여부를 동시에 확인할 수 있는 이점이 있다. 한편, 대안적인 실시예에 따르면, 우식 표현값은 0부터 5까지의 정수로 구성된 6 레벨 우식 클래스 분류 기준일 수 있다. 상기 기준은 ICDAS 기준을 일부 간소화한 약식 기준일 수 있다. 예시적으로, 상기 기준은 임의의 대영 역에서 특성값이 백색인 경우 해당 영역은 우식이 발생하지 않은 부분으로 판단되고(레벨 0), 마스크로 형성되 지 않는다. 또한, 특성값이 황색인 부분이 존재하는 경우 보통의 우식이 발생한 부분으로 판단되고(레벨 1), 해 당 우식 영역에 대응되는 마스크 영역에 우식 표현값이 맵핑될 수 있다.또한, 치아에 캐비티(cavity)가 발생한 경우, 해당 영역은 캐비티의 면적 및/또는 비율에 따라 2 내지 5의 레벨 의 우식이 발생한 부분으로 판단되고, 해당 우식 영역에 대응되는 마스크 영역에 우식 표현값이 맵핑될 수 있다. 보다 구체적으로는, 상기 캐비티에 따른 2 내지 5의 레벨은, 특성값이 검정색인 대영역이 점유하는 비율, 또는 특성값이 검정색인 대영역의 면적에 따라 판단될 수 있다. 또는, 이러한 비율과 면적의 관계를 혼용하여 우식 클래스가 분류될 수 있다. 우식 클래스에 따라 동일하거나 상이한 우식 표현값이 맵핑될 수 있는 것은 전 술한 바와 같다. 우식 판단 단계(S132)가 완료되어 마스크가 생성되고, 우식 여부 및/또는 우식 클래스 별로 우식 표현값이 맵핑 (S1323)되면, 이미지 데이터로부터 적어도 하나의 복셀을 포함하는 3차원 모델을 생성하는 단계(S133)가 수행될 수 있다. 이 때, 3차원 모델은 복수의 이미지 데이터가 얼라인(align)되어 생성될 수 있고, 이미지 데이터의 깊 이 정보를 통해 2차원 데이터가 3차원 모델로 생성될 수 있다. 한편, 마스크는 이미지 데이터 상에 오버랩된다. 이미지 데이터로부터 3차원 모델이 생성될 때, 3차원 모델을 구성하는 복셀들은 우식 표현값이 오버랩된 부분에 한하여 우식 표현값을 표시할 수 있다. 이에 따라, 3차원 모델은 우식 표현값을 통해 우식 영역을 함께 표시할 수 있다. 도 10는 본 발명에 따른 이미지 처리 방법에서 스캔 단계를 거쳐 획득한 이미지 데이터를 개략적으로 나타낸 도 이고, 도 11은 본 발명에 따른 이미지 처리 방법에서 우식 치아 판단이 수행된 이미지 데이터를 개략적으로 나 타낸 도이다. 도 10을 참조하면, 스캔 단계(S110)를 통하여 획득한 이미지 데이터가 나타난다. 이미지 데이터는 치 아와 치은을 포함할 수 있으며, 치아에서 우식이 진행되는 부분들이 식별될 수 있다. 예시적으 로, 제1 우식 부분(L1), 제2 우식 부분(L2), 제3 우식 부분(L3), 제4 우식 부분(L4), 및 제5 우식 부분(L6)이 나타날 수 있다. 상기 우식 부분들(L1, L2, L3, L4, L6)은 대영역으로 구분하는 단계(S131)에서 특성값에 따라 구분되는 적어도 하나의 대영역들로 분리될 수 있다. 도 11을 참조하면, 우식 판단이 완료된 후, 이미지 데이터 상에 우식 표현값이 표시될 수 있다. 우식 표현값을 통해, 이미지 데이터 상에 우식이 발생한 위치(L1', L2', L3', L4', L6')를 사용자가 명확하게 인지할 수 있다. 상기 우식 표현값이 표시됨으로써, 사용자는 치아에 대한 우식 발생 여부 및 우식의 심각성을 정밀하게 인식할 수 있고, 우식의 경중에 따라 치료를 수행할 수 있는 이점이 있다. 디스플레이 단계(S150) 데이터 분석 단계(S130)가 완료되면, 우식이 판단된 이미지 데이터를 3차원으로 표시하는 디스플레이 단계 (S150)가 수행될 수 있다. 디스플레이 단계(S150)는 출력 장치를 통해 데이터 분석 결과를 표시하며, 출력 장치 는 모니터와 같은 시각적 표시장치일 수 있다. 디스플레이 단계(S150)에서 표시되는 정보는, 치아를 포함하는 대상체의 2차원 이미지 데이터 또는 3차원 모델 생성 단계(S133)를 통해 생성된 3차원 모델이다. 이 때, 2차원 이미지 데이터 상에 우식 표현값이 표시되는 것 은 직관적일 수 있으나, 치아에서 정확히 어떤 위치에 우식이 발생하였는지 확인하기에는 용이하지 않다. 이에 반해, 3차원 모델은 대상체의 색상 및 대상체의 형상을 입체적으로 표현한다. 3차원 모델은 실제 대상체와 같은 색상, 형상, 치수 등을 가질 수 있으며, 3차원 모델 상에 우식 표현값이 표시되면 사용자는 우식이 발생한 위치, 크기, 각도를 용이하게 확인할 수 있으므로 환자에게 최적의 치료를 제공할 수 있다. 따라서, 데이터 분 석 단계(S130)에서 분석된 데이터(특히, 우식 판단)는 3차원 모델 상에 표시되는 것이 효과적이다. 한편, 전술한 이미지 처리 방법은 치아 영역에 해당하는 부분에 대해서만 수행될 수 있으며, 치은과 악궁에 해 당하는 부분들에 대해서는 본 발명에 따른 이미지 처리 방법이 적용되지 않을 수 있다. 예시적으로, 이미지 데 이터를 구성하는 각각의 소영역으로부터 획득한 색상이 컬러 히스토그램에서 적색 계열에 해당하는 경우, 이미 지 데이터가 포함하는 대상체는 치은 또는 악궁에 해당할 가능성이 높다. 따라서, 소영역으로부터 획득한 색상에 의해 대상체가 치은 또는 악궁인 것으로 판단된 경우, 대응되는 위치에 마스크가 생성되지 않을 수 있다. 상 기와 같은 과정에 의하여, 치아와 구강 내부의 다른 부분들(치은 및 악궁)을 구분하여, 선택적으로 치아 영역에 한해서 마스크가 생성되고 우식 표현값이 맵핑될 수 있다. 이에 따라, 치아 영역에 대해서만 우식 여부 및/또는 우식 클래스가 판단될 수 있으며, 사용자의 혼란을 방지할 수 있다. 또한, 전술한 이미지 처리 방법에 있어서, 3차원 모델 전체에 걸쳐 우식 표현값이 표시되는 것뿐만 아니라, 각 각의 치아에 대하여 구분화(segmentation) 과정이 수행되고, 각각의 치아에 대한 우식 클래스가 분류될 수도 있 다. 각각의 치아에 대해 판단된 우식 클래스에 따라, 소정 치아에 대한 우식 발생 위치와 면적 등을 기초로 적 합한 치료방법이 제시되는 과정이 추가로 수행될 수 있다. 예시적으로, 치아의 교두 부분에 우식이 발생한 경우 온레이(onlay) 방식의 치료방법을, 치아의 교두 부분 이외의 부분에 우식이 발생한 경우 인레이(inlay) 방식의 치료방법이 우식 표현값과 함께 표시될 수 있다. 전술한 내용은 이미지 데이터의 특성값을 통하여 외부적으로 나타난 우식을 판단할 수 있다. 그러나, 외부적으 로 노출되지 않은 내부 우식이 판단될 필요가 있으며, 내부 우식의 진행 여부에 따라 발치가 필요할 수 있다. 따라서, 생성된 3차원 모델에서 구분화 과정이 수행된 각각의 치아는, 선택되었을 때 내부 우식에 따른 치아 발 치 방식의 치료방법이 우식 표현값과 함께 표시될 수 있다. 예시적으로, 소정 치아를 선택하면, 기 수행된 치아 표면의 우식 판단 과정에 부가적으로 내부 우식을 판단하는 단계가 추가적으로 수행될 수 있다. 내부 우식을 판 단하는 단계는 이미지 데이터로부터 획득한 특성값을 기초로 수행될 수 있으며, 특성값은 예시적으로, 색상 정 보일 수 있다. 소정 치아가 전체적으로 저채도(law saturation)의 색상을 가지는 경우, 우식 클래스가 낮은 경 우에도 내부 우식으로 판단될 수 있다. 예를 들면, 소정 치아에 대한 이미지 데이터에서 저채도 부분이 기 설정 된 비율 이상인 경우 내부 우식으로 판단될 수 있으며, '발치' 치료방법이 표시될 수 있다. 내부 우식은, 색상 의 채도를 이용하여 판단될 수 있지만, 음파 스캔 정보, 적외선 스캔 정보 등을 사용하여 판단될 수도 있다. 내 부 우식 판단 단계를 더 포함함에 따라, 표면 우식뿐만 아니라 잠재적인 우식 치아에 대해서도 치료가 가능한 이점이 있다. 이하에서는, 본 발명의 다른 실시예에 따른 이미지 처리 방법을 설명하기로 한다. 본 발명의 다른 실시예를 설 명함에 있어, 본 발명의 일 실시예에 따른 이미지 처리 방법과 동일한 내용은 생략한다. 도 12는 본 발명의 다른 실시예에 따른 이미지 데이터 처리 방법의 순서도, 도 13은 본 발명의 다른 실시예에 따른 이미지 데이터 처리 방법의 세부 순서도이다. 도 12 및 도 13을 참조하면, 본 발명의 다른 실시예에 따른 이미지 처리 방법은, 치아를 포함하는 대상체를 스 캔하여 이미지 데이터를 획득하는 스캔 단계(S210)와, 이미지 데이터에서 치아의 우식을 판단하는 데이터 분석 단계(S230), 그리고 우식이 판단된 이미지 데이터를 3차원 디스플레이하는 단계(S250)를 포함할 수 있다. 본 발 명의 다른 실시예에 따른 스캔 단계(S210)와 디스플레이 단계(S250)는 전술한 바와 동일하다. 한편, 데이터 분석 단계(S230)는 전술한 바와 달리, 스캔 단계(S210)에서 획득한 이미지 데이터로부터 우식 판 단을 수행하지 않고 3차원 모델을 생성(S231)할 수 있다. 이어서, 본 발명의 다른 실시예에 따른 이미지 처리 방법은 3차원 모델을 치아별로 구분화하는 단계(S232)를 포 함할 수 있다. 3차원 모델이 치아별로 구분됨으로써, 사용자는 우식 판단을 원하는 치아만 선택할 수 있다. 보 다 상세하게는, 사용자가 우식 판단을 원하는 치아를 선택하면, 해당 치아를 포함하는 2차원 이미지 데이터만을 추출하고, 추출된 이미지 데이터들로부터 우식 판단이 수행(S233)될 수 있다. 이와 같이, 분석 대상 치아를 포 함하는 이미지 데이터들만 분석함으로써, 분석에 필요한 시스템 리소스를 절약할 수 있고 신속한 분석이 가능해 지는 이점이 있다. 이미지 데이터를 이용하여 우식 판단을 수행하는 것은 전술한 바와 같은 방식을 이용할 수 있으므로, 관련된 기 재는 생략하도록 한다. 또는, 상기 이미지 데이터가 3차원 데이터일 경우, 3차원 데이터는 3차원 대영역으로 구분될 수 있다. 각각의 3 차원 대영역 간의 바운더리에서, 인접하는 3차원 소영역의 특성값이 비교될 수 있고, 특성값의 비교에 따라 3차 원 대영역 간의 바운더리가 조정될 수 있다. 따라서, 유사한 특성값을 가지는 3차원 소영역들끼리 3차원 대영역 을 형성할 수 있다. 이후, 3차원 대영역별로 우식 여부 및/또는 우식 클래스의 판단이 수행될 수 있고, 적어도 하나의 마스크 영역 을 가지는 3차원 마스크가 생성될 수 있다. 이어서, 우식 여부 및/또는 우식 클래스에 따라 마스크 영역에 우식 표현값이 맵핑될 수 있다. 이는 2차원의 평면 마스크가 3차원의 입체 마스크로 변경된 것이며, 전체적인 우식 여부 판단 단계는 전술한 바와 같다. 또한, 3차원 모델에서 치은 또는 악궁에 해당하는 것으로 판단된 부분은 마스크가 형성되지 않을 수 있거나 우 식 표현값이 맵핑되지 않을 수 있다. 이는 3차원 소영역(복셀)의 특성값이 컬러 히스토그램 상 적색 계열의 색 상인 경우, 해당 부분은 치은 또는 악궁으로 판단될 수 있다. 치은 또는 악궁으로 판단된 부분에 우식 표현값이 맵핑되지 않도록 함으로써, 사용자의 혼란을 방지할 수 있다. 이하에서는, 본 발명에 따른 이미지 처리 장치에 대해 상세히 설명하기로 한다. 다만, 전술한 본 발명에 따른 이미지 처리 방법과 중복되는 내용은 생략한다. 도 14는 본 발명에 따른 이미지 처리 장치의 구성도이다. 도 14를 참조하면, 본 발명에 따른 이미지 처리 장치는, 치아를 포함하는 대상체를 스캔하여 이미지 데이터 를 획득하는 스캔부와, 이미지 데이터에서 치아의 우식을 판단하는, 데이터를 분석하는 제어부, 그리 고 우식이 판단된 이미지 데이터를 3차원으로 표시하는 디스플레이부를 포함할 수 있다. 스캔부는 치아를 포함하는 대상체를 스캔한다. 본 발명의 목적 상, 대상체는 치아에 우식이 발생하였는지 판단하기 위한 환자의 구강 내부일 수 있다. 스캔부는 환자의 구강 내부에 인입 또는 인출되면서 환자의 구강 내부를 다양한 스캔 거리 및 스캔 각도로 스캔할 수 있는 3차원 스캐너(3-dimensional scanner)일 수 있다. 스캔부는 적어도 하나의 카메라와, 그와 연결된 이미징 센서를 포함하여 대상체에 대한 이미지 데이 터를 획득할 수 있다. 한편, 이미징 센서는 CCD 센서, CMOS 센서와 같은 컬러 이미지 센서 또는 모노 이미지 센 서일 수 있다. 한편, 스캔부는 획득한 이미지 데이터로부터 제어부가 3차원 모델을 생성하기 위해, 일정한 패턴을 가지는 구조광을 조사할 수 있다. 구조광의 패턴은 패턴 마스크 또는 DMD(Digital Micromirror Device)와 같은 패턴 생성 수단을 통해 생성될 수 있다. 다만, 이미지 데이터를 3차원 모델로 생성하기 위하여 반드시 구조광 방식을 사용하여야 하는 것은 아니며, 마크, 레이저, TOF 방식과 같은 알려진 방식들 중 적어도 하나를 사용할 수 있다. 이하에서는, 제어부의 구성에 대하여 상세히 설명하기로 한다. 제어부는 스캔부에서 획득한 이미지 데이터를 분석할 수 있다. 보다 상세하게는, 제어부는 이미 지 데이터를 적어도 하나의 대영역으로 구분하는 대영역 생성조정부를 포함할 수 있다. 이 때, 대영역은 적어도 하나의 소영역을 포함하는 수퍼픽셀(superpixel)일 수 있으며, 소영역은 이미지 데이터를 구성하는 픽셀 (pixel)일 수 있다. 대영역 생성조정부는 이미지 데이터를 적어도 하나의 동일한 크기 및 동일한 소영역을 가지는 대영역들로 구분되도록 대영역을 생성할 수 있다. 대영역들 간에는 바운더리가 형성될 수 있다. 한편, 대영역 생성조정부는 바운더리에 인접하는 소영역들의 특성값을 비교할 수 있다. 이 때, 비교하는 특성값은 소영역이 가지는 이미지 데이터의 부분별 특징이며, 예시적으로는 색상 정보, 질감 정보, 크기 정보, 필(fill) 정보 등을 포함할 수 있으며, 본 발명의 목적 상 특성값은 이미지 데이터로부터 획득한 색상 정보일 수 있다. 특성값 비교가 수행되면, 대영역 생성조정부는 유사한 특성값을 가지는 소영역들끼리 동일한 대영역으로 형성되도록 바운더리를 조정할 수 있다. 대영역 생성조정부에서 대영역을 생성하고, 특성값을 비교하며, 바운더리를 조정하는 과정은 본 발명에 따른 이미지 처리 방법에서 전술한 바와 같다.한편, 제어부는 조정된 바운더리를 가지는 대영역을 기초로 우식을 판단하는 우식 판단부를 포함할 수 있다. 우식 판단부는 딥 러닝을 포함하는 인공지능(AI) 기술을 통해 우식 여부를 판단할 수 있으며, 우 식 판단에 사용될 수 있는 딥 러닝 기술은 전술한 ANN, CNN, DNN, RNN 중 선택된 1종일 수 있다. 우식 판단부 는 대영역별로 우식 여부 및/또는 우식 클래스를 판단하여 우식을 판단할 수 있으며, 상기 기준은 ICDAS 기준일 수 있다. 다만, ICDAS 기준에 한정되는 것은 아니며, 경우에 따라 적합한 분류 기준이 적용될 수 있다. 제어부는 우식 판단부에 의해 우식 여부 및/또는 우식 클래스가 판단된 후, 이를 기초로 적어도 하나 의 마스크 영역을 마스크를 생성하는 마스크 생성부를 더 포함할 수 있다. 이후, 마스크 생성부는 마스크에 마스크 영역별로 우식 여부 및/또는 우식 클래스에 대응되는 우식 표현값 을 맵핑(mapping)할 수 있다. 우식 표현값이 맵핑되는 것은 마스크 영역에 특정한 표현값이 할당되는 것을 의미 할 수 있다. 우식 표현값은 디스플레이 단계에서 사용자에게 치아 우식 여부를 시각적으로 나타낼 수 있는 수단 일 수 있다. 예시적으로, 우식 표현값은 소정 색상 및 소정 패턴 중 적어도 하나일 수 있다. 우식 표현값이 맵 핑된 마스크는 이미지 데이터 상에 오버랩(overlap) 되며, 이미지 데이터 또는 후술할 3차원 모델을 표시할 때 함께 표시될 수 있다. 우식을 판단하는 과정, 마스크를 생성하는 과정, 우식 표현값을 마스크에 맵핑하는 과정은 본 발명에 따른 이미 지 처리 방법에 전술한 바와 같으므로, 중복된 기재는 생략한다. 제어부는 스캔부에서 획득한 이미지 데이터를 3차원 모델로 생성하는 3차원 모델 생성부를 더 포함할 수 있다. 3차원 모델을 생성하기 위해, 이미지 데이터는 대상체의 깊이 정보를 포함하기 위해 구조광 방 식 등을 통해 획득될 수 있다. 3차원 모델은 적어도 하나의 복셀을 포함할 수 있다. 이미지 데이터로부터 3차원 모델을 생성할 때, 3차원 모델을 구성하는 복셀들은 우식 표현값이 오버랩된 부분에 한하여 우식 표현값이 표시 되도록 할 수 있다. 따라서, 사용자는 3차원 모델에서 우식이 발생한 위치, 각도, 크기 등을 용이하게 확인할 수 있고, 환자에게 적합한 치료를 제공할 수 있는 이점이 있다. 본 발명에 따른 이미지 처리 장치는, 전술한 제어부의 분석 결과를 3차원으로 표시하는 디스플레이부(30 0)를 포함할 수 있다. 디스플레이부는 이미지 데이터 또는 마스크가 오버랩된 이미지 데이터를 표시할 수 있다. 또는, 디스플레이부는 3차원 모델과 3차원 모델의 복셀이 가지는 우식 표현값을 표시할 수 있거나, 3차원 모델과 3차원 모델 상에 맵핑되는 3차원 마스크의 우식 표현값을 함께 표시할 수 있다. 따라서, 사용자는 육안으로 환자의 구강 내부 또는 생성된 3차원 모델에 대한 주관적인 분석을 할 필요가 없다. 전술한 바와 같이 환자의 구강 내부에 대해 인공지능을 사용하여 우식 여부 및/또는 우식 클래스를 객관적으로 판단하고, 이를 시 각적으로 표시함으로써, 사용자는 환자에게 신속하고 객관적인 치료를 제공할 수 있는 이점이 있다. 이상의 설명은 본 발명의 기술 사상을 예시적으로 설명한 것에 불과한 것으로서, 본 발명이 속하는 기술 분야에 서 통상의 지식을 가진 자라면 본 발명의 본질적인 특성에서 벗어나지 않는 범위에서 다양한 수정 및 변형이 가 능할 것이다. 따라서, 본 발명에 개시된 실시예들은 본 발명의 기술 사상을 한정하기 위한 것이 아니라 설명하기 위한 것이고, 이러한 실시예에 의하여 본 발명의 기술 사상의 범위가 한정되는 것은 아니다. 본 발명의 보호 범위는 아래의 청구범위에 의하여 해석되어야 하며, 그와 동등한 범위 내에 있는 모든 기술 사상은 본 발명의 권리범위 에 포함되는 것으로 해석되어야 할 것이다."}
{"patent_id": "10-2020-0137425", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명에 따른 이미지 처리 방법의 순서도이다. 도 2 내지 도 4는 본 발명에 따른 이미지 처리 방법의 세부 순서도이다. 도 5 내지 도 8은 본 발명에 따른 이미지 처리 방법 중 대영역이 생성되고 조정되는 과정을 설명하기 위한 도이 다. 도 9는 본 발명에 따른 이미지 처리 방법에 의해 대영역이 조정되는 이미지 데이터를 예시적으로 나타낸 도이다. 도 10는 본 발명에 따른 이미지 처리 방법에서 스캔 단계를 거쳐 획득한 이미지 데이터를 개략적으로 나타낸 도 이다. 도 11은 본 발명에 따른 이미지 처리 방법에서 우식 치아 판단이 수행된 이미지 데이터를 개략적으로 나타낸 도이다. 도 12는 본 발명의 다른 실시예에 따른 이미지 데이터 처리 방법의 순서도이다. 도 13은 본 발명의 다른 실시예에 따른 이미지 데이터 처리 방법의 세부 순서도이다. 도 14는 본 발명에 따른 이미지 처리 장치의 구성도이다."}
