{"patent_id": "10-2021-0156476", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0070660", "출원번호": "10-2021-0156476", "발명의 명칭": "인공지능 영상 조작 검출 방법 및 장치", "출원인": "성균관대학교산학협력단", "발명자": "김광수"}}
{"patent_id": "10-2021-0156476", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "전자 장치의 인공지능 영상 조작 검출 방법으로서, 대상 영상에서 연속된 프레임을 추출하는 단계; 각 프레임에 대하여 얼굴 영역을 검출하는 단계; 상기 각 프레임에 대하여 복수개의 얼굴 경계 윈도우를 생성하는 단계; 상기 각 프레임에 대하여 얼굴 영역을 제거한 배경 영역에 존재하는 하나 이상의 물체들을 검출하고, 하나 이상의 물체들의 배경 경계 윈도우를 생성하는 단계;상기 각 프레임에 대하여 얼굴 경계 윈도우의 픽셀값과 배경 경계 윈도우의 픽셀값에 기초하여 얼굴 경계 특성과 배경 경계 특성을 추출하고 통합한 통합 데이터를 생성하는 단계; 및상기 통합 데이터를 분석하여 인공지능 영상 조작여부를 판정하는 단계를 포함하는 영상 조작 검출 방법."}
{"patent_id": "10-2021-0156476", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 얼굴 경계 윈도우를 생성하는 단계는 검출된 얼굴 영역에서 얼굴 경계선을 기준으로 얼굴 경계의 수직 선분을 생성하고, 생성된 수직 선분당 평행한 선분을 일정 간격으로 생성하고, 상기 수직 선분과 생성된 평행한 선분의 집합을 포함하는 얼굴 경계 윈도우를 생성하는 것을 특징으로 하는 영상 조작 검출 방법."}
{"patent_id": "10-2021-0156476", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 하나 이상의 물체들의 배경 경계 윈도우를 생성하는 단계에서, 하나의 프레임에서 상기 검출된 얼굴 영역을 제거하고, 얼굴 영역이 제거된 배경 영역에 존재하는 서 각 물체들의 경계선을 기준으로 물체 경계의 수직 선분을 생성하고, 생성된 수직 선분당 평행한 선분을 일정 간격으로 생성하고, 상기 수직 선분과 생성된 평행한 선분의 집합을 포함하는 배경 경계 윈도우를 생성하는 것을 특징으로 하는 영상 조작 검출 방법."}
{"patent_id": "10-2021-0156476", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서,상기 검출된 얼굴 영역을 제거할 때, 검출된 얼굴 영역에서 미리 설정된 픽셀만큼 얼굴 외측으로 확장된 얼굴영역을 생성하고, 확장된 얼굴 영역을 상기 프레임으로부터 제거하는 것을 특징으로 하는 영상 조작 검출 방법."}
{"patent_id": "10-2021-0156476", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "공개특허 10-2023-0070660-3-제1항에 있어서,상기 통합 데이터를 생성하는 단계는, 상기 얼굴 경계 윈도우 각각에 대하여, 얼굴 경계 윈도우 내에 있는 픽셀값을 산출하고, 각 픽셀값들에 대하여경계선에 수직한 수직방향으로 이웃하는 픽셀값과의 차이를 계산하여 제1 차분값을 생성하고, 상기 제1 차분값을 얼굴 경계 특성으로 하는 단계; 상기 배경 경계 윈도우 각각에 대하여, 배경 경계 윈도우 내에 있는 픽셀값을 산출하고, 각 픽셀값들에 대하여경계선에 수직한 수직방향으로 이웃하는 픽셀값과의 차이를 계산하여 제2 차분값을 생성하고, 하나의 프레임에포함된 모든 배경 경계 윈도우에 대한 제2 차분값들의 평균값을 계산하는 단계; 각 얼굴 경계 윈도우에 대한 제1 차분값과 상기 제2 차분값들의 평균값의 차이값을 계산하여 배경 경계 특성을생성하는 단계; 및 상기 얼굴 경계 특성과 상기 배경 경계 특성을 합하여 통합 특성을 생성하는 단계를 포함하는 것을 특징으로 하는 영상 조작 검출 방법."}
{"patent_id": "10-2021-0156476", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서,상기 통합 데이터를 분석하여 인공지능 영상 조작여부를 판정하는 단계는, 상기 통합 데이터를 딥러닝 모델에 적용함으로써 인공지능 영상 조작여부를 판정하는 것을 특징으로 하는 영상조작 검출 방법."}
{"patent_id": "10-2021-0156476", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "대상 영상을 획득하는 영상 획득부; 상기 대상 영상에서 연속된 프레임을 추출하고, 각 프레임에 대하여 얼굴 영역을 검출하여, 상기 각 프레임에대하여 복수개의 얼굴 경계 윈도우를 생성하고, 상기 각 프레임에 대하여 얼굴 영역을 제거한 배경 영역에 존재하는 하나 이상의 물체들을 검출하고, 하나 이상의 물체들의 배경 경계 윈도우를 생성하며, 상기 각 프레임에대하여 얼굴 경계 윈도우의 픽셀값과 배경 경계 윈도우의 픽셀값에 기초하여 얼굴 경계 특성과 배경 경계 특성을 추출하고 통합한 통합 데이터를 생성하는 특성 추출부; 및상기 통합 데이터를 분석하여 인공지능 영상 조작여부를 판정하는 조작 검출부를 포함하는 영상 조작 검출 장치."}
{"patent_id": "10-2021-0156476", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서,상기 특성 추출부는, 검출된 얼굴 영역에서 얼굴 경계선을 기준으로 얼굴 경계의 수직 선분을 생성하고, 생성된 수직 선분당 평행한선분을 일정 간격으로 생성하고, 상기 수직 선분과 생성된 평행한 선분의 집합을 포함하는 얼굴 경계 윈도우를생성하는 것을 특징으로 하는 영상 조작 검출 장치."}
{"patent_id": "10-2021-0156476", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제7항에 있어서,공개특허 10-2023-0070660-4-상기 특성 추출부는, 하나의 프레임에서 상기 검출된 얼굴 영역을 제거하고, 얼굴 영역이 제거된 배경 영역에 존재하는 서 각 물체들의 경계선을 기준으로 물체 경계의 수직 선분을 생성하고, 생성된 수직 선분당 평행한 선분을 일정 간격으로 생성하고, 상기 수직 선분과 생성된 평행한 선분의 집합을 포함하는 배경 경계 윈도우를 생성하는 것을 특징으로 하는 영상 조작 검출 장치."}
{"patent_id": "10-2021-0156476", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9항에 있어서,상기 검출된 얼굴 영역을 제거할 때, 검출된 얼굴 영역에서 미리 설정된 픽셀만큼 얼굴 외측으로 확장된 얼굴영역을 생성하고, 확장된 얼굴 영역을 상기 프레임으로부터 제거하는 것을 특징으로 하는 영상 조작 검출 장치."}
{"patent_id": "10-2021-0156476", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제7항에 있어서,상기 특성 추출부는, 상기 얼굴 경계 윈도우 각각에 대하여, 얼굴 경계 윈도우 내에 있는 픽셀값을 산출하고, 각 픽셀값들에 대하여경계선에 수직한 수직방향으로 이웃하는 픽셀값과의 차이를 계산하여 제1 차분값을 생성하고, 상기 제1 차분값을 얼굴 경계 특성으로 하고, 상기 배경 경계 윈도우 각각에 대하여, 배경 경계 윈도우 내에 있는 픽셀값을 산출하고, 각 픽셀값들에 대하여경계선에 수직한 수직방향으로 이웃하는 픽셀값과의 차이를 계산하여 제2 차분값을 생성하고, 하나의 프레임에포함된 모든 배경 경계 윈도우에 대한 제2 차분값들의 평균값을 계산하며, 각 얼굴 경계 윈도우에 대한 제1 차분값과 상기 제2 차분값들의 평균값의 차이값을 계산하여 배경 경계 특성을생성하고, 상기 얼굴 경계 특성과 상기 배경 경계 특성을 합하여 통합 특성을 생성하는것을 특징으로 하는 영상 조작 검출 장치."}
{"patent_id": "10-2021-0156476", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제7항에 있어서,상기 조작 검출부는, 상기 통합 데이터를 딥러닝 모델에 적용함으로써 인공지능 영상 조작여부를 판정하는 것을 특징으로 하는 영상조작 검출 장치."}
{"patent_id": "10-2021-0156476", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 전자 장치의 인공지능 영상 조작 검출 방법에 관한 것으로서, 영상 조작 검출 방법은 대상 영상에서 연속된 프레임을 추출하는 단계; 각 프레임에 대하여 얼굴 영역을 검출하는 단계; 상기 각 프레임에 대하여 복수 개의 얼굴 경계 윈도우를 생성하는 단계; 상기 각 프레임에 대하여 얼굴 영역을 제거한 배경 영역에 존재하는 하 나 이상의 물체들을 검출하고, 하나 이상의 물체들의 배경 경계 윈도우를 생성하는 단계; 상기 각 프레임에 대하 여 얼굴 경계 윈도우의 픽셀값과 배경 경계 윈도우의 픽셀값에 기초하여 얼굴 경계 특성과 배경 경계 특성을 추 출하고 통합한 통합 데이터를 생성하는 단계; 및 상기 통합 데이터를 분석하여 인공지능 영상 조작여부를 판정하 는 단계를 포함하는 것을 특징으로 한다."}
{"patent_id": "10-2021-0156476", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 인공지능 영상 조작 검출 방법 및 장치에 관한 것으로, 인공지능도허영상에 의해 조작되는 과정에서 발생하는 경계 영역 색 분포의 변화를 주목하여 인공지능 영상 조작을 검출하는 방법 및 장치에 관한 것이다."}
{"patent_id": "10-2021-0156476", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "인공지능 기술이 발달함에 따라, 사람의 얼굴을 다른 사람의 몸에 합성하는 딥페이크 영상도 정교해지고 있다. 그리고 딥페이크 영상이 정교해짐에 따라 최근 들어 딥페이크를 통한 가짜 뉴스, 유명인 포르노그래피 등 여러 사회적 문제가 발생하고 있다. 따라서, 딥페이크 영상을 판별하고 탐지하는 기술의 개발은 매우 중요하다. 기존의 기술들은 대부분 합성 결과물인 얼굴 부분만 주목하여 해당 부분에서 특성을 추출하는 방법을 제시해 왔 다. 그러나 얼굴 영역의 특성만 고려하면 특정한 생성 알고리즘이 남긴 특징만을 추출하게 된다는 문제점이 있 다. 이러한 문제점 때문에, 기존의 방법들은 인공지능 영상 조작 검출 교차검증(훈련에 사용한 영상과 전혀 다 른 생성 알고리즘을 통해 만든 딥페이크 영상의 진위를 판단) 결과가 좋지 못하다."}
{"patent_id": "10-2021-0156476", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명의 일 실시예에 따른 검출 성능이 우수한 인공지능 영상 조작 검출 방법 및 장치를 제공하는데 그 목적 이 있다. 본 발명의 기술적 과제들은 이상에서 언급한 기술적 과제들로 제한되지 않으며, 언급되지 않은 또 다른 기술적 과제들은 아래의 기재로부터 통상의 기술자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2021-0156476", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기 목적을 달성하기 위해, 본 발명의 일 실시예에서 제공하는 전자 장치의 인공지능 영상 조작 검출 방법으로 서, 대상 영상에서 연속된 프레임을 추출하는 단계; 각 프레임에 대하여 얼굴 영역을 검출하는 단계; 상기 각 프레임에 대하여 복수개의 얼굴 경계 윈도우를 생성하는 단계; 상기 각 프레임에 대하여 얼굴 영역을 제거한 배 경 영역에 존재하는 하나 이상의 물체들을 검출하고, 하나 이상의 물체들의 배경 경계 윈도우를 생성하는 단계; 상기 각 프레임에 대하여 얼굴 경계 윈도우의 픽셀값과 배경 경계 윈도우의 픽셀값에 기초하여 얼굴 경계 특성 과 배경 경계 특성을 추출하고 통합한 통합 데이터를 생성하는 단계; 및 상기 통합 데이터를 분석하여 인공지능 영상 조작여부를 판정하는 단계를 포함하는 것을 특징으로 한다. 일 실시예에서, 상기 얼굴 경계 윈도우를 생성하는 단계는, 검출된 얼굴 영역에서 얼굴 경계선을 기준으로 얼굴 경계의 수직 선분을 생성하고, 생성된 수직 선분당 평행한 선분을 일정 간격으로 생성하고, 상기 수직 선분과 생성된 평행한 선분의 집합을 포함하는 얼굴 경계 윈도우를 생성하는 것을 특징으로 한다. 일 실시예에서, 상기 하나 이상의 물체들의 배경 경계 윈도우를 생성하는 단계에서, 하나의 프레임에서 상기 검 출된 얼굴 영역을 제거하고, 얼굴 영역이 제거된 배경 영역에 존재하는 서 각 물체들의 경계선을 기준으로 물체 경계의 수직 선분을 생성하고, 생성된 수직 선분당 평행한 선분을 일정 간격으로 생성하고, 상기 수직 선분과 생성된 평행한 선분의 집합을 포함하는 배경 경계 윈도우를 생성하는 것을 특징으로 한다. 일 실시예에서, 상기 검출된 얼굴 영역을 제거할 때, 검출된 얼굴 영역에서 미리 설정된 픽셀만큼 얼굴 외측으 로 확장된 얼굴 영역을 생성하고, 확장된 얼굴 영역을 상기 프레임으로부터 제거하는 것을 특징으로 한다. 일 실시예에서, 상기 통합 데이터를 생성하는 단계는, 상기 얼굴 경계 윈도우 각각에 대하여, 얼굴 경계 윈도우 내에 있는 픽셀값을 산출하고, 각 픽셀값들에 대하여 경계선에 수직한 수직방향으로 이웃하는 픽셀값과의 차이 를 계산하여 제1 차분값을 생성하고, 상기 제1 차분값을 얼굴 경계 특성으로 하는 단계; 상기 배경 경계 윈도우 각각에 대하여, 배경 경계 윈도우 내에 있는 픽셀값을 산출하고, 각 픽셀값들에 대하여 경계선에 수직한 수직방 향으로 이웃하는 픽셀값과의 차이를 계산하여 제2 차분값을 생성하고, 하나의 프레임에 포함된 모든 배경 경계 윈도우에 대한 제2 차분값들의 평균값을 계산하는 단계; 각 얼굴 경계 윈도우에 대한 제1 차분값과 상기 제2 차 분값들의 평균값의 차이값을 계산하여 배경 경계 특성을 생성하는 단계; 및 상기 얼굴 경계 특성과 상기 배경 경계 특성을 합하여 통합 특성을 생성하는 단계를 포함하는 것을 특징으로 한다. 일 실시예에서, 상기 통합 데이터를 분석하여 인공지능 영상 조작여부를 판정하는 단계는, 상기 통합 데이터를 딥러닝 모델에 적용함으로써 인공지능 영상 조작여부를 판정하는 것을 특징으로 한다. 본 발명의 일 실시예에 따른 영상 조작 검출 장치는 대상 영상을 획득하는 영상 획득부; 상기 대상 영상에서 연 속된 프레임을 추출하고, 각 프레임에 대하여 얼굴 영역을 검출하여, 상기 각 프레임에 대하여 복수개의 얼굴 경계 윈도우를 생성하고, 상기 각 프레임에 대하여 얼굴 영역을 제거한 배경 영역에 존재하는 하나 이상의 물체 들을 검출하고, 하나 이상의 물체들의 배경 경계 윈도우를 생성하며, 상기 각 프레임에 대하여 얼굴 경계 윈도 우의 픽셀값과 배경 경계 윈도우의 픽셀값에 기초하여 얼굴 경계 특성과 배경 경계 특성을 추출하고 통합한 통 합 데이터를 생성하는 특성 추출부; 및 상기 통합 데이터를 분석하여 인공지능 영상 조작여부를 판정하는 조작 검출부를 포함하는 것을 특징으로 한다."}
{"patent_id": "10-2021-0156476", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명의 일 실시예에 따른 장치 및 방법에 따르면 인공지능 영상 조작 검출 성능이 우수하다. 본 발명의 일 실시예에 따른 장치 및 방법에 따르면 교차검증 성능이 우수하므로, 새로운 유형의 딥페이크 영상 의 진위 판단시 우수한 탐지 성능을 제공할 수 있다."}
{"patent_id": "10-2021-0156476", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 2, "content": "본 발명의 효과들은 이상에서 언급한 효과들로 제한되지 않으며, 언급되지 않은 또 다른 효과들은 아래의 기재 로부터 통상의 기술자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2021-0156476", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "아래에서는 첨부한 도면을 참고로 하여 본 발명의 실시 예에 대하여 설명하되, 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자가 본 발명을 용이하게 실시할 수 있도록 상세히 설명한다. 그러나 본 발명은 여러 가지 상이한 형태로 구현될 수 있으며 여기에서 설명하는 실시 예에 한정되지 않는다. 한편 도면에서 본 발명을 명확 하게 설명하기 위해서 설명과 관계없는 부분은 생략하였으며, 명세서 전체를 통하여 유사한 부분에 대해서는 유 사한 도면 부호를 붙였다. 또한 상세한 설명을 생략하여도 본 기술 분야의 당업자가 쉽게 이해할 수 있는 부분 의 설명은 생략하였다. 명세서 및 청구범위 전체에서, 어떤 부분이 어떤 구성 요소를 포함한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다른 구성 요소를 제외하는 것이 아니라 다른 구성 요소를 더 포함할 수 있는 것을 의미한다. 본 발명에서 설명한 인공지능 영상 조작은 인공지능 기술을 이용해 기존 사진이나 영상을 원본에 겹쳐서 실제로 존재하는 영상인 것처럼 만들어내는 기법으로서, 딥페이크(Deepfake)라고도 불린다. 딥페이크는 딥러닝(deep learning)과 페이크(fake)의 합성어이다. 본 발명은 촬영된 이미지에 나타나는 모든 물체의 경계부분의 색 분포를 추출하고, 이를 활용하여 인공지능 영 상 조작을 효과적으로 검출한다. 도 1은 본 발명의 일 실시예에 따른 인공지능 영상 조작 검출 장치의 구성을 설명하기 위한 블럭도이다. 도 1을 참조하면 본 명세서의 일 실시 예에 따르는 인공지능 영상 조작 검출 장치는 영상 획득부, 특 성 추출부 및 조작 검출부를 포함할 수 있다. 영상 획득부는 연결된 외부 장치 및/또는 단말로부터 영상을 획득하거나, 영상을 직접 입력받을 수 있다. 획득된 영상은 인공지능 영상 조작 검출 대상이 된다. 특성 추출부는 영상 획득부에서 연속된 프레임을 추출하고 추출된 프레임에서 얼굴 영역(face region)을 검출하여, 얼굴과 얼굴이 아닌 배경 부분의 경계 영역에 주목한다. 이 영역에서 나타나는 색 분포를 추출하여 해당 영상이 어떤 환경에서 촬영됐는지에 대한 내재적인 특징을 구한다. 특성 추출 방법에 대해서는 이하 도 2 내지 도 5를 참조하여 더욱 상세히 설명한다. 조작 검출부는 특성 추출부에 의해 추출된 특성에 기초하여 영상의 조작 여부를 판단한다. 일 실시예에서, 조작 검출부는 특성 추출부에 의해 추출된 특성들을 시공간적으로 해석할 수 있는 3D 딥러닝 모델을 통해 주어진 영상의 조작 여부를 판단한다. 도 2는 본 발명의 일 실시예에 따른 인공지능 영상 조작 검출 방법을 설명하기 위한 개념도이다. 도 2의 인공지능 영상 조작 검출 방법은 도 1의 인공지능 영상 조작 검출 장치에 의해 행해질 수 있다. S110에서, 인공지능 영상 조작 검출 장치는 획득한 영상에서 연속된 프레임을 추출한다. 단계 S120에서 인공지능 영상 조작 검출 장치는 추출된 프레임에서 모든 물체의 경계부분의 색 분포에 따른 특 성을 추출한다. 이를 위해 먼저, 프레임에서 얼굴 영역을 탐지하여, 얼굴 영역과 얼굴이 아닌 배경 영역을 분리하여 배경 영역 프레임을 생성한다. 얼굴 영역을 포함하는 프레임(이하 얼굴 영역 프레임이라 함)에서 얼굴의 윤곽선을 정의하고, 정의한 윤곽선의 주변의 픽셀(Pixel)값을 추출하여 얼굴 경계 특성을 구한다. 마찬가지 방법으로, 배경 영역만을 포함하는 프레임(배경 영역 프레임)에 존재하는 물체들의 윤곽선을 정의하고, 윤곽선을 따라 주변의 픽셀값을 추출하여 배경 경계 특성을 구한다. 단계 S130에서, 프레임별로 구한 얼굴 경계 특성과 배경 경계 특성들에 기초하여 영상의 조작 여부를 판단한다. 일 실시예에서, 얼굴 경계 특성과 배경 경계 특성들을 분석하기 위하여 인공신경망 분류 모델에 입력에 적용할 수 있다. 예를 들어, 인공신경망 분류 모델은 추출한 특성을 시공간적으로 해석할 수 있는 3D CNN 기반의 모델 로 구성할 수 있다. 을 통합하여 인공신경망 분류 모델에 입력한다. 분류 모델은 최종적으로 해당 영상이 일반 영상인지, 딥페이크 영상인지 분류한다. 도 3은 본 발명의 일 실시예에 따른 인공지능 영상 조작 검출 방법을 설명하기 위한 블럭도이다. 도 3은 도 1 및 도 2에서 설명한 인공지능 영상 조작 검출 장치에 의해 수행될 수 있다. 단계 S211, S212에서 대상 영상에서 연속된 프레임을 추출하고 추출된 프레임에서 얼굴 영역(face region)을 탐 지한다. 일 실시예에서, 얼굴 영역을 탐지하기 위하여 dlib의 get_frontal_face_detector를 활용할 수 있으나, 이에 한 정하는 것은 아니고 알려진 얼굴 인식 모듈을 적용할 수 있다. 얼굴 영역 탐지 기술은 이미 널리 알려진 기술이 므로 상세한 설명은 생략한다. 여기서, 얼굴 영역은 단일 영상 또는 단일 프레임에서 얼굴을 포함하는 영역일 수 있다. 얼굴 영역은 눈, 코, 입, 눈썹 등 얼굴의 주요 구성요소들 및 얼굴의 윤곽선 등을 포함하는 영역일 수 있다. 예를 들어, 단일 영상 또는 단일 프레임에는 사람의 전신(full body)이 포함될 수 있다. 특성 추출부는 사람의 전신 중 얼굴에 대응하는 얼굴 영역을 검출할 수 있다 일 실시예에서 특성 추출부는 이전 프레임(previous frame)의 얼굴 영역을 검출 결과에 기초하여 현재 프 레임(current frame)의 얼굴 영역을 검출할 수 있다. 얼굴의 운동 속도는 일정 속도 이하로 제한되므로, 이전 프레임에서 얼굴이 포함된 영역을 주변으로 확대하여 현재 프레임의 얼굴 영역을 결정할 수 있다. 다음 단계 S221 내지 S224를 포함하는 얼굴 영역 특성을 추출하는 단계와 단계 S231 내지 S235를 포함하는 배경 영역 특성을 추출하는 단계를 각각 설명한다. 단계 S221에서, 특성 추출부는 프레임의 얼굴 영역으로부터 특징점들을 추출할 수 있다. 특성 추출부(12 0)는 현재 프레임에서 눈, 코, 입, 눈썹, 얼굴의 윤곽선 등을 나타내는 특징점들을 추출할 수 있다. 예를 들어, 특성 추출부는 SIFT(scale-invariant feature transform) 알고리즘, SURF(speed up robust feature) 알고 리즘, 및 FAST(features from accelerated segment test) 알고리즘 중 적어도 하나를 사용하여 특징점들을 검 출할 수 있다. 단계 S222에서, 특성 추출부는 추출된 프레임의 얼굴 영역에서의 경계선을 정의하고, 단계 S223에서, 특성 추출부는 얼굴 영역에서 얼굴 경계선을 기준으로 얼굴 경계 수직선분을 생성한다. 상기 얼굴 경계 수직선 분의 길이 및 후술되는 배경 경계 수직선분의 길이는 미리 설정될 수 있다. 단계 S224에서, 특성 추출부는 얼굴 경계 수직선분에 기초하여 얼굴 경계 윈도우를 생성한다. 수직 선분 생성 및 얼굴 경계 윈도우 생성은 도 5 및 도 6을 참조하여 상세히 설명한다. 단계 S231, S232에서, 특성 추출부는 각 프레임을 가우시안 처리하여 엣지(edge) 이미지를 도출한다. 단계 S233에서, 에지 이미지에서 단계 S212에서 탐지한 얼굴 영역에 기초하여 얼굴 영역을 제거한다. 이때, 단 계 S212에서 탐지한 얼굴 영역을 미리 설정된 픽셀만큼 확장시킨 확장된 얼굴 영역을 제거한다. 이와 같이 확장 된 얼굴 영역을 삭제함으로써 얼굴 탐지에서 얼굴임에도 얼굴 영역에 포함되지 못한 에러에 의한 영향을 줄여 순수 배경을 추출할 수 있다. 단계 S234에서, 특성 추출부는 배경 영역 프레임에 존재하는 물체의 경계선을 추출하고, 각 경계선을 기준 으로 배경 경계 수직선분을 생성한다. 단계 S235에서, 특성 추출부는 배경 경계 수직선분에 기초하여 배경 경계 윈도우를 생성한다. 수직 선분 생성 및 배경 경계 윈도우 생성은 도 8 및 도 9를 참조하여 상세히 설명한다. 단계 S241 내지 단계 S243은 특성 추출부에 의한 특성 통합한다. 단계 S241에서 경계 윈도우 픽셀값을 계산하고, 단계 S242에서 계산된 픽셀값에 기초하여 얼굴 영역 특성과 배 경 영역 특성을 통합하고, 단계 S243에서 각 프레임별 특성을 통합한다. 다음 단계 S251, S252에서 통합된 영역 특성들을 미리 저장된 분류 모델에 적용하여 해당 영상이 일반 영상인지 조작된 영상인지를 판단하고 결과를 제공한다. 도 4는 본 발명의 일 실시예에 따른 개별 프레임에서 얼굴 영역을 탐지하고 얼굴 특징점을 추출하는 방법을 설 명하기 위한 도면이다. 도 4의 (a)는 캡처된 하나의 프레임의 일 예이다. 일 실시예에서, 대상 영상에서 하나의 프레임을 캡처하기 위하여, 주어진 영상을 Python OpenCV 라이브러리를 활용하여 시간 축으로 연속하게 프레임(Frame)을 추출한다. 도 4의 (b)는 도 4의 (a)의 프레임에서 dlib의 get_frontal_face_detector를 활용하여 얼굴을 탐색한 결과를 나타낸다. 도 4의 (c)는 dlib의 shape_predictor를 활용하여 얼굴의 68개의 특징점을 추출한 결과를 나타낸다. 이와 같이 추출된 얼굴의 특징점은 도 5에서와 같이 얼굴 경계선을 정의하기 위해 사용된다. 도 5는 본 발명의 일 실시예에 따른 얼굴 경계 수직성분을 생성하고 얼굴 윈도우를 생성하는 방법을 설명하기 위한 도면이다. 도 5의 (a)는 캡처된 하나의 프레임의 일 예이다. 도 5의 (b)는 도 4의 (c)에서 추출한 68개의 특징점을 활용하여 얼굴의 윤곽선을 나타낸 결과를 보여주는 도면 이다. 도 5의 (c)는 얼굴의 윤곽선을 활용하여 얼굴 경계의 수직선분을 나타낸 결과이다. 일 실시예에서, 주어진 얼굴 영역의 68개의 특징점 중 첫 17개 점 (얼굴 윤곽을 나타내는 특징점)을 활용하여 얼굴 윤곽선을 정의할 수 있다. 17개의 특징점에서 각 이웃하는 특징점을 잇는 선분에 수직한 선분을 구함으로 써, 16개의 수직선분을 생성할 수 있다. 수직 선분은 균일한 간격의 미리 설정된 개수(예컨대 20개)의 점으로 이루어져 있다. 정의된 수직 선분과 평행한 선분들을 생성하여 경계 윈도우를 구성한다. 도 5의 (d)는 얼굴 경계의 수직선분을 활용하여 얼굴 경계 윈도우를 나타낸 결과이다. 각 수직 선분 1개당 평행한 선분을 일정한 간격으로 19개 생성한다. 그리고 앞서 구한 수직 선분 1개와 평행한 19개의 선분 총 20개의 선분 집합을 얼굴 경계 윈도우라고 정의한다. 윈도우의 개수는 획득한 수직 선분의 개수 와 같다. 예를 들어, 구한 수직 선분이 총 16개인 경우, 얼굴 1개당 최종적으로 만들어지는 얼굴 경계 윈도우는 16개가 된다. 도 6은 본 발명의 일 실시예에 따라 생성된 경계 윈도우를 설명하기 위한 예시도이다. 도 6을 참조하면, 윈도우의 t방향은 경계의 수직방향을 나타낸다. 윈도우 중심의 t방향의 중심선분을 포함한다. 얼굴 경계 영역 및 배경 경계 영역은 복수개의 윈도우로 표시할 수 있다. 각 윈도우에 검은색 점으로 표시된 좌표에 대응하는 픽셀값(RGB)을 구하여특성값으로 한다. 도 7은 도 3의 단계 S232의 엣지(edge) 이미지를 도출하는 방법을 설명하기 위한 도면이다. 본 발명의 일 실시예는 배경 영역 특성을 추출하기 위하여, 얼굴을 제외한 배경에서의 물체의 경계 특성을 이용 한다. 도 7의 (a)는 캡처된 하나의 프레임의 일 예이다. 도 7의 (b)는 프레임에 5x5 가우시안 필터를 활용하여 프레임을 Blur 처리한 결과 이미지의 일 예로서, 이와 같 이 각 프레임에 대하여 가우시안 필터를 이용하여 필터링한다. 가우시안 필터는 중앙값만 도드라지게 보이고 주변은 잘 안 보이게 하는 마스킹의 형태로 엣지를 감지하기 위해 널리 사용되는 선형 필터이다. 본 발명에서 가우시안 필터를 사용하였으나, 이에 한정하는 것은 아니고, 엣지를 검출할 수 있는 다양한 기법을 적용할 수 있음은 물론이다. 다음 프레임에 존재하는 물체의 엣지를 검출하기 위하여 엣지 디텍터 예컨대 Canny Edge Detector를 활용하여 도 7의 (b)와 같이 필터링된 이미지에서 엣지 포인트(Edge Point)들을 구한다. 이렇게 획득한 엣지 포인트들을 포함하는 이미지를 엣지 이미지라 정의한다. 도 8은 도 3의 단계 S233의 엣지(edge) 이미지에서 얼굴 영역을 제거하는 방법을 설명하기 위한 도면이다. 도 8의 (a)는 7의 (c)의 엣지 이미지이다. 도 8의 (b)는 도 4의 (b)를 참조하여 설명한 dlib의 get_frontal_face_detector를 활용하여 구한 얼굴 영역 마 스크이다. 도 8의 (c)는 도 8의 (b)에서 구한 얼굴 영역 마스크를 얼굴 외측 방향으로 미리 설정된 픽셀만큼 확장시킨 확 장된 얼굴 영역 마스크를 나타낸다. 도 8의 (a)의 이미지에서, 도 8의 (c)의 확장된 얼굴 영역을 제거하여 배경 엣지 이미지를 생성한다. 즉, 배경 엣지 이미지는 얼굴 영역이 제거된 엣지 이미지로 정의할 수 있다. 도 9는 본 발명의 일 실시예에 따라 배경 경계 윈도우를 생성하는 방법을 설명하기 위한 도면이다. 도 9의 (a)는 배경 엣지 이미지의 일 예이다. 도 9의 (b)는 배경 엣지 이미지에서 미리 설정된 개수의 엣지 포인트를 나타낸 이미지의 일 예이다. 상기 미리 설정된 개수는 배경 이미지에 나타낸 엣지 포인트 중 약 10%일 수 있다. 이와 같이 선택된 엣지 포인트에서, 이웃하는 엣지 포인트 사이의 선분과 수직하는 수직선분을 구하고, 수직선 분을 기초로 경계 윈도우를 생성한다. 얼굴 경계 윈도우를 생성한 방법과 마찬가지로, 각 수직 선분 1개당 평행 한 선분을 일정한 간격으로 생성한다. 그리고 앞서 구한 수직 선분 1개와 평행한 선분들을 모두 포함하는 선분 집합을 배경 경계 윈도우라고 정의한다. 윈도우의 개수는 획득한 수직 선분의 개수와 같다. 도 10은 본 발명의 일 실시예에 따른 특성 통합 방법을 설명하기 위한 도면이다. 도 10을 참조하여 설명하는 특성 통합 방법은 하나의 프레임에 대한 특성 통합 방법이다. 먼저, S811, S812에서 하나의 프레임에 포함된 복수개의 얼굴 경계 윈도우 각각에 대하여 얼굴 경계 윈도우 내 에 있는 픽셀값을 산출하고, 각 픽셀값들에 대하여 경계선에 수직한 수직방향으로 이웃하는 픽셀값과의 차이를 계산한다. 예를 들어, 얼굴 경계 윈도우의 사이즈가 20*20 이었다면, 각 얼굴 경계 윈도우 픽셀 차분값을 포함 하는 영역의 사이즈는 20*19가 된다. 이에 따라 생성된 얼굴 경계 윈도우 픽셀 차분값이 얼굴 경계 특성이 되고, 얼굴 경계 특성의 사이즈는 각 얼굴 경계 윈도우 픽셀 차분값을 포함하는 영역의 사이즈와 동일한 20*19 가 된다. 다음, S821, S822에서 각 배경 경계 윈도우로부터 각 픽섹값을 산출하고, 각 픽셀값들의 수직방향으로 이웃하는 픽셀값과의 차이를 계산한다. 배경 경계 윈도우의 사이즈는 얼굴 경계 윈도우의 사이즈와 동일하게 20*20이고, 각 배경 경계 읜도우 픽셀 차분값을 포함하는 영역의 사이즈는 각 얼굴 경계 윈도우 픽셀 차분값을 포함하는 영 역의 사이즈와 동일하게 20*19이다. 다음, S823에서 모든 배경 경계 윈도우에 대하여 픽셀 차분값들의 평균값을 계산한다. 다음 단계 S824에서, 이와 같이 평균을 낸 배경 경계 픽셀 차분값과 얼굴 경계 픽셀 차분 값과의 차이를 계산하 여 배경 경계 특성값을 생성한다. 이와 같이 생성된 배경 경계 특성의 사이즈는 얼굴 경계 특성의 사이즈와 동 일하게 20*19이다. 이와 같이 생성된 얼굴 경계 특성 및 배경 경계 특성을 합하여 하나의 프레임에 대한 얼굴 영역 및 배경 영역의 특성을 통합한다. 도 10을 참조하여 설명한 특성 통합 방법은 단일 프레임에서의 특성을 구하는 과정이므로, 여러 연속된 프레임 을 포함하는 영상에서의 조작을 판별하기 위해서는 하나의 영상에서 추출한 여러 프레임들에 대해 모두 같은 방 법을 반복하여 특성을 추출한다. 도 11은 본 발명의 일 실시예에 따른 인공지능 영상 조작을 검출하기 위한 딥러닝 분류 모델의 일 예이다. 도 11을 참조하면, 본 발명의 일 실시예에 따른 분류 모델은 합성곱 신경망(Convolutional Neural Network) 모 델인 DenseNet일 수 있다. 모델의 전체적인 구조는 종래 기술인 DenseNet을 참고한다. 딥 러닝 모델은 최종적으로 입력한 특성이 딥페이크 영상에서 추출한 것인지, 일반 영상에서 추출한 것인지 분류한다. 분류 모델은 하나의 프레임에 대하여 모든 윈도우의 얼굴 경계 특성과 배경 경계 특성을 합한 결과를 하나의 인 풋 데이터로 한다. 분류 모델은 인풋 데이터를 입력받아 최종적으로 영상의 조작여부를 결과로 출력한다. 분류 모델은 종래의 3차 원의 합성곱 신경망으로서 시공간적으로 해석하여 특징을 추출할 수 있다. 도 12는 본 발명의 일 실시예에 따른 인공지능 영상 조작 검출 실험 결과를 나타낸 테이블이다. 도 12를 참조하면, 여러 종래 기법들과 본 발명의 일 실시예에 따른 검출 결과를 비교하여 나타내었다. 해당 실험은 특정한 딥페이크 데이터셋 (FaceForensics++)으로만 훈련한 딥페이크 탐지 프레임워크를 전혀 다른 유형의 딥페이크 데이터셋 (Celeb-DF)로 검증을 진행한다. 정확도 측정은 이진 분류 성능평가 지표인 AUC(Area Under Curve)로 나타낸다. 도 12를 참조하면 알 수 있는 바와 같이, 종래 기술들의 탐지 능력 대비 약 7~20% 정도 우수한 성능을 보이는 것을 알 수 있다. 이상, 본 발명은 도면에 도시된 실시예를 참고로 설명되었으나 이는 예시적인 것에 불과하며, 본 기술 분야의 통상의 지식을 가진 자라면 이로부터 다양한 변형 및 균등한 타 실시예가 가능하다는 점을 이해할 것이다. 따라서, 본 발명의 진정한 기술적 보호 범위는 첨부된 특허청구범위의 기술적 사상에 의해 정해져야 할 것이다."}
{"patent_id": "10-2021-0156476", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일 실시예에 따른 인공지능 영상 조작 검출 장치의 구성을 설명하기 위한 블럭도이다. 도 2는 본 발명의 일 실시예에 따른 인공지능 영상 조작 검출 방법을 설명하기 위한 개념도이다. 도 3은 본 발명의 일 실시예에 따른 인공지능 영상 조작 검출 방법을 설명하기 위한 블럭도이다. 도 4는 본 발명의 일 실시예에 따른 개별 프레임에서 얼굴 영역을 탐지하고 얼굴 특징점을 추출하는 방법을 설 명하기 위한 도면이다. 도 5는 본 발명의 일 실시예에 따른 얼굴 경계 수직성분을 생성하고 얼굴 윈도우를 생성하는 방법을 설명하기 위한 도면이다. 도 6은 본 발명의 일 실시예에 따라 생성된 경계 윈도우를 설명하기 위한 예시도이다. 도 7은 도 3의 단계 S232의 엣지(edge) 이미지를 도출하는 방법을 설명하기 위한 도면이다. 도 8은 도 3의 단계 S233의 엣지(edge) 이미지에서 얼굴 영역을 제거하는 방법을 설명하기 위한 도면이다. 도 9는 본 발명의 일 실시예에 따라 배경 경계 윈도우를 생성하는 방법을 설명하기 위한 도면이다. 도 10은 본 발명의 일 실시예에 따른 특성 통합 방법을 설명하기 위한 도면이다. 도 11은 본 발명의 일 실시예에 따른 인공지능 영상 조작을 검출하기 위한 딥러닝 분류 모델의 일 예이다. 도 12는 본 발명의 일 실시예에 따른 인공지능 영상 조작 검출 실험 결과를 나타낸 테이블이다."}
