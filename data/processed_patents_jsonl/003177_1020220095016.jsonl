{"patent_id": "10-2022-0095016", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0016804", "출원번호": "10-2022-0095016", "발명의 명칭": "볼류메트릭 피처를 이용하여 깊이 맵을 생성하는 장치 및 방법", "출원인": "포티투닷 주식회사", "발명자": "김중희"}}
{"patent_id": "10-2022-0095016", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "볼류메트릭 피처를 이용하여 단안 카메라의 포즈 정보를 획득하는 방법에 있어서,하나 이상의 단안 카메라를 통해 서라운드 뷰 이미지를 획득하는 단계;상기 서라운드 뷰 이미지에 포함된 기본 이미지를 인코딩하여 다중 스케일(multi-scale) 이미지 피처들을 생성하는 단계;상기 다중-스케일 이미지 피처들 각각을 소정의 해상도를 기준으로 리사이즈(resize) 및연접(concatenate)하여, 상기 기본 이미지에 대한 단일 피처맵을 생성하는 단계;상기 단일 피처맵을 인코딩한 후, 인코딩 결과를 3차원 공간으로 투영함으로써 볼류메트릭 피처(volumetricfeature)를 생성하는 단계; 및포즈 디코더를 이용하여 상기 볼류메트릭 피처를 디코딩함으로써, 다음 시점에서의 단안 카메라의 포즈 정보를일괄 획득하는 단계;를 포함하는, 방법."}
{"patent_id": "10-2022-0095016", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1 항에 있어서, 상기 단안 카메라의 포즈 정보를 일괄 획득하는 단계는,포즈 디코더를 이용하여 상기 볼류메트릭 피처를 디코딩함으로써, 기준 단안 카메라의 현재 시점과 다음 시점카메라 포즈 간의 변화량을 나타내는 표준 카메라 모션(canonical camera motion)을 획득하는 단계; 및상기 기준 단안 카메라와 다른 단안 카메라 간 외부 파라미터 관계 및 상기 표준 카메라 모션에 기초하여, 상기다음 시점에서의 상기 다른 단안 카메라의 포즈 정보를 일괄 획득하는 단계;를 포함하는, 방법."}
{"patent_id": "10-2022-0095016", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 2 항에 있어서, 상기 표준 카메라 모션을 획득하는 단계는,상기 볼류메트릭 피처를 조감도(BEV) 피처로 평면화(flatten)하는 단계; 및상기 포즈 디코더를 이용하여 상기 조감도 피처를 디코딩하는 단계;를 포함하는, 방법."}
{"patent_id": "10-2022-0095016", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 2 항에 있어서, 상기 방법은,깊이 디코더를 이용하여 상기 볼류메트릭 피처를 디코딩함으로써, 상기 서라운드 뷰 이미지의 깊이 맵을 생성하는 단계;를 더 포함하는, 방법."}
{"patent_id": "10-2022-0095016", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "공개특허 10-2024-0016804-3-제 4 항에 있어서,상기 방법은, 상기 서라운드 뷰 이미지를 뉴럴 네트워크의 입력 데이터로 이용하고, 상기 깊이 맵 및 상기 표준 카메라 모션을 출력 데이터 이용함으로써 상기 뉴럴 네트워크를 학습시키는 단계;를 더 포함하는, 방법."}
{"patent_id": "10-2022-0095016", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제 5 항에 있어서,상기 뉴럴 네트워크는 이미지 재구성 손실(image reconstruction loss) 및 깊이 합성 손실(depth synthesisloss)을 최소화하는 방향으로 학습되는 것인, 방법."}
{"patent_id": "10-2022-0095016", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제 6 항에 있어서, 상기 이미지 재구성 손실은, 시간적(temporal) 손실, 공간적(spatio) 손실 및 시공간적(spatio-temporal) 손실을 포함하는 것인, 방법."}
{"patent_id": "10-2022-0095016", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제 6 항에 있어서, 상기 깊이 합성 손실은, 깊이 일관성(consistency) 손실을 포함하는 것인, 방법."}
{"patent_id": "10-2022-0095016", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "단안 카메라를 이용하여 깊이 맵을 생성하는 장치에 있어서,적어도 하나의 프로그램이 저장된 메모리; 및상기 적어도 하나의 프로그램을 실행하는 프로세서를 포함하고,상기 프로세서는,하나 이상의 단안 카메라를 통해 서라운드 뷰 이미지를 획득하고,상기 서라운드 뷰 이미지에 포함된 기본 이미지를 인코딩하여 다중 스케일(multi-scale) 이미지 피처들을 생성하고,상기 다중-스케일 이미지 피처들 각각을 소정의 해상도를 기준으로 리사이즈(resize) 및연접(concatenate)하여, 상기 기본 이미지에 대한 단일 피처맵을 생성하고,상기 단일 피처맵을 깊이 정보(depth information)와 함께 인코딩한 후, 인코딩 결과를 3차원 공간으로 투영함으로써 볼류메트릭 피처(volumetric feature)를 생성하며,상기 볼류메트릭 피처에 기초하여 다음 시점에서의 단안 카메라의 포즈 정보를 일괄 획득하는 것인, 장치."}
{"patent_id": "10-2022-0095016", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제 1 항의 방법을 컴퓨터에서 실행하기 위한 프로그램을 기록한 컴퓨터로 읽을 수 있는 기록매체."}
{"patent_id": "10-2022-0095016", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 개시는 볼류메트릭 피처를 이용하여 깊이 맵을 생성하는 장치 및 방법에 관한 것이다. 본 개시의 일 실시 예 에 따른 방법은, 서라운드 뷰 이미지에 포함된 기본 이미지를 인코딩 및 후처리하여 기본 이미지에 대한 단일 피 처맵을 생성하고, 단일 피처맵을 깊이 정보와 함께 인코딩한 후, 인코딩 결과를 3차원 공간으로 투영함으로써 볼 류메트릭 피처를 생성할 수 있다. 본 방법에서는 깊이 디코더를 이용하여 볼류메트릭 피처를 디코딩함으로써, 서 라운드 뷰 이미지의 깊이 맵을 생성할 수 있다."}
{"patent_id": "10-2022-0095016", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 볼류메트릭 피처를 이용하여 깊이 맵을 생성하는 장치 및 방법에 관한 것이다."}
{"patent_id": "10-2022-0095016", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "로봇 비전(robot vision), 휴먼 컴퓨터 인터페이스(human computer interface), 지능형 시각 감시(intelligent visual surveillance), 3D 이미지 획득(3D image acquisition) 등과 같이 다양한 분야에서 이용되는 3D 깊이 정보의 추정 방법에 대해 활발한 연구가 이루어지고 있다. 특히 자율주행(autonomous driving) 시스템에서, 수 집된 영상 데이터 상에서 검출된 객체와 차량과의 거리를 비롯하여 다양한 주행 환경을 인지하고 판단함으로써 차량을 제어하기 위해 정확성이 높은 깊이 추정에 대한 연구가 요구되고 있다. 깊이 정보를 추정하는 방법은 적외선, 초음파, 레이저, 빛의 산란 특성 등의 신호를 이용하는 방법과 영상을 분 석하는 방식이 있다. 적외선, 초음파를 이용하여 거리를 추정하는 방식은 객체의 상태에 따라 반사되어 돌아오 는 신호가 영향을 받을 수 있다는 단점이 있다. 레이저 등의 신호를 이용하는 것은 정확도가 높지만 고가의 추 가적인 장치를 이용하여야 한다는 단점이 있다. 반면, 카메라를 이용하여 깊이 정보를 추정하는 것은 별도의 추가적인 장치를 필요로 하지 않는다. 또한, 깊이 정보는 스테레오 카메라를 이용한 시차 계산을 바탕으로 생성될 수 있으나, 정확한 깊이 추정을 위해 두대의 카 메라에 대한 정교한 보정(calibration) 작업이 필요하며, 시차(disparity) 계산에 많은 시간이 소요된다는 문제 점이 있다. 따라서 단안 카메라로부터 깊이 정보를 정확하게 추정하는 방법에 대한 연구의 필요성이 대두되고 있다."}
{"patent_id": "10-2022-0095016", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 2, "content": "전술한 배경기술은 발명자가 본 발명의 도출을 위해 보유하고 있었거나, 본 발명의 도출 과정에서 습득한 기술 정보로서, 반드시 본 발명의 출원 전에 일반 공중에게 공개된 공지기술이라 할 수는 없다."}
{"patent_id": "10-2022-0095016", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 볼류메트릭 피처를 이용하여 깊이 맵을 생성하는 장치 및 방법을 제공하는데 있다. 본 발명이 해결하 고자 하는 과제는 이상에서 언급한 과제에 한정되지 않으며, 언급되지 않은 본 발명의 다른 과제 및 장점들은 하기의 설명에 의해서 이해될 수 있고, 본 발명의 실시 예에 의해보다 분명하게 이해될 것이다. 또한, 본 발명 이 해결하고자 하는 과제 및 장점들은 특허 청구 범위에 나타낸 수단 및 그 조합에 의해 실현될 수 있음을 알 수 있을 것이다."}
{"patent_id": "10-2022-0095016", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상술한 기술적 과제를 달성하기 위한 기술적 수단으로서, 본 개시의 제1 측면은, 볼류메트릭 피처를 이용하여 단안 카메라의 포즈 정보를 획득하는 방법에 있어서, 하나 이상의 단안 카메라를 통해 서라운드 뷰 이미지를 획 득하는 단계; 상기 서라운드 뷰 이미지에 포함된 기본 이미지를 인코딩하여 다중 스케일(multi-scale) 이미지 피처들을 생성하는 단계; 상기 다중-스케일 이미지 피처들 각각을 소정의 해상도를 기준으로 리사이즈(resize) 및 연접(concatenate)하여, 상기 기본 이미지에 대한 단일 피처맵을 생성하는 단계; 상기 단일 피처맵을 인코딩 한 후, 인코딩 결과를 3차원 공간으로 투영함으로써 볼류메트릭 피처(volumetric feature)를 생성하는 단계; 및 포즈 디코더를 이용하여 상기 볼류메트릭 피처를 디코딩함으로써, 다음 시점에서의 단안 카메라의 포즈 정보를 일괄 획득하는 단계;를 포함하는, 방법을 제공할 수 있다. 본 개시의 제 2 측면은, 단안 카메라를 이용하여 깊이 맵을 생성하는 장치에 있어서, 적어도 하나의 프로그램이 저장된 메모리; 및 상기 적어도 하나의 프로그램을 실행하는 프로세서를 포함하고, 상기 프로세서는, 하나 이상 의 단안 카메라를 통해 서라운드 뷰 이미지를 획득하고, 상기 서라운드 뷰 이미지에 포함된 기본 이미지를 인코 딩하여 다중 스케일(multi-scale) 이미지 피처들을 생성하고, 상기 다중-스케일 이미지 피처들 각각을 소정의 해상도를 기준으로 리사이즈(resize) 및 연접(concatenate)하여, 상기 기본 이미지에 대한 단일 피처맵을 생성 하고, 상기 단일 피처맵을 깊이 정보(depth information)와 함께 인코딩한 후, 인코딩 결과를 3차원 공간으로 투영함으로써 볼류메트릭 피처(volumetric feature)를 생성하며, 상기 볼류메트릭 피처에 기초하여 다음 시점에 서의 단안 카메라의 포즈 정보를 일괄 획득하는 것인, 장치를 제공할 수 있다. 본 개시의 제 3 측면은, 제 1 측면에 따른 방법을 컴퓨터에서 실행하기 위한 프로그램을 기록한 컴퓨터로 읽을 수 있는 기록매체를 제공할 수 있다. 이 외에도, 본 발명을 구현하기 위한 다른 방법, 다른 시스템 및 상기 방법을 실행하기 위한 컴퓨터 프로그램이 저장된 컴퓨터로 판독 가능한 기록매체가 더 제공될 수 있다. 전술한 것 외의 다른 측면, 특징, 이점이 이하의 도면, 특허청구범위 및 발명의 상세한 설명으로부터 명확해질 것이다."}
{"patent_id": "10-2022-0095016", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "전술한 본 개시의 과제 해결 수단에 의하면, 본 개시에서는 실제 촬영된 이미지가 아닌, 카메라 포즈를 임의로 변조하는 경우에도 매끄러운 깊이 맵을 생성할 수 있다."}
{"patent_id": "10-2022-0095016", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명의 이점 및 특징, 그리고 그것들을 달성하는 방법은 첨부되는 도면과 함께 상세하게 설명되는 실시 예들 을 참조하면 명확해질 것이다. 그러나 본 발명은 아래에서 제시되는 실시 예들로 한정되는 것이 아니라, 서로 다른 다양한 형태로 구현될 수 있고, 본 발명의 사상 및 기술 범위에 포함되는 모든 변환, 균등물 내지 대체물 을 포함하는 것으로 이해되어야 한다. 아래에 제시되는 실시 예들은 본 발명의 개시가 완전하도록 하며, 본 발"}
{"patent_id": "10-2022-0095016", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "명이 속하는 기술분야에서 통상의 지식을 가진 자에게 발명의 범주를 완전하게 알려주기 위해 제공되는 것이다. 본 발명을 설명함에 있어서 관련된 공지 기술에 대한 구체적인 설명이 본 발명의 요지를 흐릴 수 있다고 판단되 는 경우 그 상세한 설명을 생략한다. 본 출원에서 사용한 용어는 단지 특정한 실시 예를 설명하기 위해 사용된 것으로, 본 발명을 한정하려는 의도가 아니다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 출원에서, \"포함 하다\" 또는 \"가지다\" 등의 용어는 명세서상에 기재된 특징, 숫자, 단계, 동작, 구성요소, 부품 또는 이들을 조 합한 것이 존재함을 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성요소, 부 품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되어야 한다. 본 개시의 일부 실시예는 기능적인 블록 구성들 및 다양한 처리 단계들로 나타내어질 수 있다. 이러한 기능 블 록들의 일부 또는 전부는, 특정 기능들을 실행하는 다양한 개수의 하드웨어 및/또는 소프트웨어 구성들로 구현 될 수 있다. 예를 들어, 본 개시의 기능 블록들은 하나 이상의 마이크로프로세서들에 의해 구현되거나, 소정의 기능을 위한 회로 구성들에 의해 구현될 수 있다. 또한, 예를 들어, 본 개시의 기능 블록들은 다양한 프로그래 밍 또는 스크립팅 언어로 구현될 수 있다. 기능 블록들은 하나 이상의 프로세서들에서 실행되는 알고리즘으로 구현될 수 있다. 또한, 본 개시는 전자적인 환경 설정, 신호 처리, 및/또는 데이터 처리 등을 위하여 종래 기 술을 채용할 수 있다. \"매커니즘\", \"요소\", \"수단\" 및 \"구성\" 등과 같은 용어는 넓게 사용될 수 있으며, 기계적 이고 물리적인 구성들로서 한정되는 것은 아니다. 또한, 도면에 도시된 구성 요소들 간의 연결 선 또는 연결 부재들은 기능적인 연결 및/또는 물리적 또는 회로적 연결들을 예시적으로 나타낸 것일 뿐이다. 실제 장치에서는 대체 가능하거나 추가된 다양한 기능적인 연결, 물 리적인 연결, 또는 회로 연결들에 의해 구성 요소들 간의 연결이 나타내어질 수 있다.이하에서, '차량'은 자동차, 버스, 오토바이, 킥보드 또는 트럭과 같이 기관을 가지고 사람이나 물건을 이동시 키기 위해 이용되는 모든 종류의 운송 수단을 의미할 수 있다. 이하 첨부된 도면을 참고하여 본 개시를 상세히 설명하기로 한다. 도 1 내지 도 3은 일 실시예에 따른 자율 주행 방식을 설명하기 위한 도면들이다. 도 1을 참조하면, 본 발명의 일 실시예에 따른 자율 주행 장치는, 차량에 장착되어 자율 주행 차량을 구현 할 수 있다. 자율 주행 차량에 장착되는 자율 주행 장치는, 주변의 상황 정보를 수집하기 위한 다양한 센서 들을 포함할 수 있다. 일례로, 자율 주행 장치는 자율 주행 차량의 전면에 장착된 이미지 센서 및/또는 이 벤트 센서를 통해, 전방에서 운행 중인 선행 차량의 움직임을 감지할 수 있다. 자율 주행 장치는 자율 주행 차량의 전면은 물론, 옆 차로에서 운행중인 다른 주행 차량과, 자율 주행 차량 주변의 보행자 등을 감지하기 위한 센서들을 더 포함할 수 있다. 자율 주행 차량 주변의 상황 정보를 수집하기 위한 센서들 중 적어도 하나는, 도 1에 도시한 바와 같이 소정의 화각(FoV)을 가질 수 있다. 일례로, 자율 주행 차량의 전면에 장착된 센서가 도 1에 도시한 바와 같은 화각 (FoV)을 갖는 경우에, 센서의 중앙에서 검출되는 정보가 상대적으로 높은 중요도를 가질 수 있다. 이는, 센서의 중앙에서 검출되는 정보에, 선행 차량의 움직임에 대응하는 정보가 대부분 포함되어 있기 때문일 수 있다. 자율 주행 장치는, 자율 주행 차량의 센서들이 수집한 정보를 실시간으로 처리하여 자율 주행 차량의 움직임을 제어하는 한편, 센서들이 수집한 정보 중에 적어도 일부는 메모리 장치에 저장할 수 있다. 도 2를 참조하면, 자율 주행 장치는 센서부, 프로세서, 메모리 시스템, 및 차체 제어 모듈 등을 포함할 수 있다. 센서부는 복수의 센서들(42-45)을 포함하며, 복수의 센서들(42-45)은 이미지 센서, 이벤트 센서, 조도 센서, GPS 장치, 가속도 센서 등을 포함할 수 있다. 센서들(42-45)이 수집한 데이터는 프로세서로 전달될 수 있다. 프로세서는 센서들(42-45)이 수집한 데 이터를 메모리 시스템에 저장하고, 센서들(42-45)이 수집한 데이터에 기초하여 차체 제어 모듈을 제어 하여 차량의 움직임을 결정할 수 있다. 메모리 시스템은 둘 이상의 메모리 장치들과, 메모리 장치들을 제어 하기 위한 시스템 컨트롤러를 포함할 수 있다. 메모리 장치들 각각은 하나의 반도체 칩으로 제공될 수 있다. 메모리 시스템의 시스템 컨트롤러 외에, 메모리 시스템에 포함되는 메모리 장치들 각각은 메모리 컨트 롤러를 포함할 수 있으며, 메모리 컨트롤러는 신경망과 같은 인공지능(AI) 연산 회로를 포함할 수 있다. 메모리 컨트롤러는 센서들(42-45) 또는 프로세서로부터 수신한 데이터에 소정의 가중치를 부여하여 연산 데이터를 생성하고, 연산 데이터를 메모리 칩에 저장할 수 있다. 도 3은 자율 주행 장치가 탑재된 자율 주행 차량의 센서가 획득한 영상 데이터의 예시를 나타낸 도면이다. 도 3 을 참조하면, 영상 데이터는 자율 주행 차량의 전면에 장착된 센서가 획득한 데이터일 수 있다. 따라서 영 상 데이터에는 자율 주행 차량의 전면부, 자율 주행 차량과 같은 차로의 선행 차량, 자율 주행 차 량 주변의 주행 차량, 배경 및 차선(55, 56) 등이 포함될 수 있다. 도 3에 도시한 실시예에 따른 영상 데이터에서, 자율 주행 차량의 전면부와 배경이 나타나는 영역 의 데이터는 자율 주행 차량의 운행에 영향을 미칠 가능성이 거의 없는 데이터일 수 있다. 다시 말해, 자율 주 행 차량의 전면부와 배경은 상대적으로 낮은 중요도를 갖는 데이터로 간주될 수 있다. 반면, 선행 차량과의 거리, 및 주행 차량의 차로 변경 움직임 등은 자율 주행 차량의 안전한 운행에 있 어서 매우 중요한 요소일 수 있다. 따라서, 영상 데이터에서 선행 차량 및 주행 차량 등이 포함되 는 영역의 데이터는 자율 주행 차량의 운행에 있어서 상대적으로 높은 중요도를 가질 수 있다. 자율 주행 장치의 메모리 장치는, 센서로부터 수신한 영상 데이터의 영역별로 가중치를 다르게 부여하여 저 장할 수 있다. 일례로, 선행 차량과 주행 차량 등이 포함되는 영역의 데이터에는 높은 가중치를 부여하 고, 자율 주행 차량의 전면부와 배경이 나타나는 영역의 데이터에는 낮은 가중치를 부여할 수 있다. 도 4a 내지 4b는 일 실시예에 따른 서라운드 뷰 이미지를 획득하는 방법을 설명하기 위한 예시적인 도면이다. 깊이 맵을 생성하는 장치(이하, '깊이 맵 생성 장치')는 하나 이상의 단안 카메라를 통해 차량이 주행 중인 도 로에 대한 이미지를 획득할 수 있다. 하나 이상의 카메라는 차량에 설치될 때, 차량의 전방위에 대한 이미지를 촬영하도록 각각 다른 방향으로 배향 되어 설치될 수 있다. 하나 이상의 카메라 각각은 내부 파라미터(intrinsic parameters) 및 외부 파라미터 (extrinsic parameters)를 가진다. 내부 파라미터에는 초점거리(focal length), 주점(principal point) 및 비대칭계수(skew coefficient) 등이 포 함될 수 있다. 외부 파라미터는 카메라 좌표계와 월드 좌표계 사이의 변환 관계를 설명하는 파라미터로서, 외부 파라미터에는 두 좌표계 사이의 회전(rotation) 및 평행이동(translation) 변환 정보가 포함될 수 있다. 도 4a를 참조하면, 차량에는 6대의 카메라가 설치되고, 각각 차량의 전방(front), 후방(rear), 우측 전방(front-right), 우측 후방(rear-right), 좌측 전방(front-left) 및 좌측 후방(rear-left)을 촬영하도록 설 치될 수 있다. 차량에 설치된 각 카메라에서 획득된 이미지는 Ii로 표현될 수 있고, 예를 들어, 도 4a에 설치된 각 카메 라는 I1, I2, 쪋, I6으로 나타낼 수 있다. 도 4a 및 도 4b를 비교하면, 도 4a에는 시점 t에서 각 카메라로부터 촬영된 6개의 이미지가 도시되고, 각 이미 지는 으로 나타낼 수 있다. 또한, 도 4b에는 시점 t 이후인 시점 t+1에서 각 카메라로부터 촬영된 6 개의 이미가 도시되고, 각 이미지는 으로 나타낼 수 있다. 이하에서, 상술한 바와 같이 차량에 설치된 하나 이상의 단안 카메라로부터 소정의 시점에서 촬영된 복수 의 기본 이미지들로 구성된 이미지 세트를 '서라운드 뷰 이미지'라고 지칭하기로 한다. 도 5는 일 실시예에 따른 이미지 인코더를 이용하여 서라운드 뷰 이미지에 대한 단일 피처맵을 생성하는 방법을 설명하기 위한 도면이다. 깊이 맵 생성 장치는 이미지 인코더(image encoder)를 포함할 수 있다. 이미지 인코더는 서라운드 뷰 이미지에 포함되는 복수의 기본 이미지를 입력 데이터로 이용할 수 있다. 이미지 인코더는 기본 이미지에 대한 다중 스케일(multi-scale) 이미지 피처들을 생성할 수 있다. 또 한, 이미지 인코더는 다중 스케일 이미지 피처들을 소정의 해상도를 기준으로 리사이즈(resize) 후 서로 연접(concatenate)하여, 기본 이미지에 대한 단일 피처맵을 생성할 수 있다. 구체적으로, 도 5를 참조하면, 이미지 인코더는 CNN(convolution neural network)을 이용하여 기본 이미 지의 해상도를 1/2씩 낮추어 다중 스케일 이미지 피처들을 생성할 수 있다. 예를 들어, 이미지 인코더 는 다중 스케일 이미지 피처들을 생성하기 위해 resnet 18을 이용하여, 기본 이미지(H X W 해상도) 대비 1/2, 1/4, 1/8, 1/16 해상도의 다중 스케일 이미지 피처들을 생성할 수 있다. 또한, 이미지 인코더 는 'H/8 X W/8'를 기준 해상도로 설정하고, 다중 스케일 이미지 피처들을 업-샘플링(up-sampling)하 여 'H/8 X W/8' 기준으로 리사이즈 후 서로 연접하여 단일 피처맵을 생성할 수 있다. 즉, 깊이 맵 생성 장치는 상술한 방법을 통해 이미지 인코더를 이용하여, 서라운드 뷰 이미지에 포함된 복 수의 기본 이미지들 각각(Ii)에 대한 단일 피처맵(Fi)을 생성할 수 있다. 예를 들어, 깊이 맵 생성 장치는 서라 운드 뷰 이미지에 포함된 복수의 기본 이미지들 I1, I2, 쪋, I6 각각에 대한 단일 피처맵 F1, F2, 쪋, F6을 생성 할 수 있다. 도 6a 내지 6b는 일 실시예에 따른 단일 피처맵을 이용하여 볼류매트릭 피처를 생성하는 방법을 설명하기 위한 예시적인 도면이다. 깊이 맵 생성 장치는 단일 피처맵을 깊이 정보(depth information)와 함께 인코딩한 후, 인코딩 결과를 3차원 공간으로 투영함으로써 볼류메트릭 피처(volumetric feature)를 생성할 수 있다. 도 6a를 참조하면, 소정의 카메라로부터 촬영된 기본 이미지 Ii로부터 생성된 단일 피처맵 Fi에 대해, 깊이 맵 생성 장치는 픽셀 p에서 소정의 카메라의 중심까지의 광선(ray)을 따라 복셀 세트(set of voxels)를 선택하고, 단일 피처맵에 픽셀을 할당한 Fi(p)를 설정할 수 있다. 깊이 맵 생성 장치는 소정의 카메라의 내부 파라미터 및 외부 파라미터를 이용한 backward-warping과 같은 매핑 함수로 이를 구현할 수 있다. 각 픽셀 p의 단일 피처맵 Fi(p)에는, Fi(p) 픽셀의 광선을 따른(along) 높은 고수준 정보(high-level information)가 포함되므로, 도 6b를 참조하면, 깊이 맵 생성 장치는 Fi(p)를 복셀 좌표의 깊이 정보와 연결(concatenate)하여 인코딩할 수 있다. 또한, 깊이 맵 생성 장치는 인코딩 결과를 3차원 공간으로 투영 함으로써 각 복셀 좌표 (x, y, z)에 대한 로컬 3차원 피처를 추출할 수 있다. 한편, 서라운드 뷰 이미지를 촬영하는 복수의 카메라들의 뷰에서의 공간적 겹침(overlap)이 발생함에 따라 3차 원 볼류메트릭 공간 상의 일부 복셀들이 복수의 단일 피처맵과 연관될 수 있다. 도 6b를 참조하면, 3차원 볼류메트릭 공간 상의 일부 복셀은 겹침이 발생한 반면, 나머지 복셀은 겹침이 발생하 지 않음을 확인할 수 있다. 깊이 맵 생성 장치는 로컬 3차원 피처를 볼류메트릭 인코더에 입력하여 볼류메트릭 피처를 생성할 수 있다. 일 실시예에서, 깊이 맵 생성 장치는 복셀 별로 겹침이 발생했는지 여부에 따라 서로 다른 다층 퍼셉트론(Multi- Layer Perceptron; MLP)에 할당할 수 있다. 도 6c를 참조하면, 로컬 3차원 피처가 볼류메트릭 인코더에 입력된 후 겹침이 발생한 복셀과, 겹침이 발생하지 않은 복셀은 서로 다른 MLP에 할당됨을 확인할 수 있다. 깊이 맵 생성 장치는 서로 다른 MLP에 할당되어 인코딩된 결과를 전체적으로 융합(fuse)하여 볼류메트릭 피처 를 생성할 수 있다. 본 개시에서는 복셀 별로 겹침이 발생했는지 여부에 따라 서로 다른 MLP에 할당하여 인코딩 후 그 결과를 융합하여 볼류메트릭 피처를 생성함으로써, 볼류메트릭 피처의 각 복셀은 3D 지 오메트리와 관련된 고차원 피처를 인코딩할 수 있다. 도 7은 일 실시예에 따른 서라운드 뷰 이미지의 깊이 맵을 생성하는 방법을 설명하기 위한 예시적인 도면이다. 깊이 맵 생성 장치는 차량에 설치된 하나 이상의 카메라의 내부 파라미터 및 외부 파라미터에 기초하여 도 6에 서 생성된 볼류메트릭 피처를 소정의 해상도를 갖는 투영된 이미지 피처로 변환할 수 있다. 여기서, 내부 파라 미터에는 초점거리(focal length), 주점(principal point) 및 비대칭계수(skew coefficient) 등이 포함될 수 있다. 외부 파라미터는 카메라 좌표계와 월드 좌표계 사이의 변환 관계를 설명하는 파라미터로서, 외부 파라미 터에는 두 좌표계 사이의 회전(rotation) 및 평행이동(translation) 변환 정보가 포함될 수 있다. 또한, 깊이 맵 생성 장치는 깊이 디코더(depth decoder)를 이용하여 투영된 이미지 피처를 디코딩함으로써, 서 라운드 뷰 이미지의 깊이 맵을 생성할 수 있다. 구체적으로, 도 7을 참조하면, 깊이 맵 생성 장치는 볼류메트릭 피처에 대해 카메라 별 내부 파라미터 Ki 및 외부 파라미터 Ei를 적용하여 소정의 해상도 'H/8 X W/8'를 갖는 투영된 이미지 피처 를 생성할 수 있 다. 예를 들어, 깊이 맵 생성 장치는 볼류메트릭 피처 V에 대해 카메라 별 외부 파라미터 E1, E2, 쪋, E6를 적용하여 투영된 이미지 피처 를 생성할 수 있다. 깊이 맵 생성 장치는 깊이 디코더를 이용하여 해상도 'H/8 X W/8'를 갖는 투영된 이미지 피처 를 디코딩함으로써, 해상도 'H X W'의 깊이 맵을 생성할 수 있다. 예를 들어, 깊이 맵 생성 장치는 해상도 'H/8 X W/8'를 갖는 투영된 이미지 피처 를 업샘플링하여, 깊이 맵 D1, D2, 쪋, D6를 생성할 수 있다. 깊이 디코더는 업샘플링을 위한 3개의 컨벌루션 레이어 및 깊이 출력을 위한 1개의 컨벌루션으로 구성될 수 있으나, 이에 제한되지 않는다. 본 개시에서는 도 5 내지 도 7에서 상술한 방법을 통해, 도 4a의 서라운드 뷰 이미지로써 획득된 각 6개의 카메 라 별 이미지 I1, I2, 쪋, I6를 도 7의 깊이 맵 D1, D2, 쪋, D6로 변환할 수 있다. 도 8a 내지 8e는 일 실시예에 따른 임의의 회전 뷰에 따른 깊이 맵을 획득하는 방법을 설명하기 위한 예시적인 도면이다. 도 7에서 상술한 바와 같이, 깊이 맵 생성 장치는 차량에 설치된 하나 이상의 카메라의 외부 파라미터에 기초하 여 볼류메트릭 피처를 소정의 해상도를 갖는 투영된 이미지 피처로 변환할 수 있다. 본 개시는 이 과정에서 일반성을 잃지 않고, 카메라 포즈를 그대로 유지하는 대신 원하는 뷰에 대한 표준 좌표 계(canonical coordinate)로부터의 투영 행렬(projective matrix)을 사용하여 볼류메트릭 피처를 투영된 이미 지 피처로 변환할 수 있다. 특히, 본 개시는 표준 모션(canonical motion)과 원하는 카메라 포즈의 곱으로 새로운 카메라 포즈를 변조(modulate)할 수 있다. 즉, 깊이 맵 생성 장치는 볼류메트릭 피처를 소정의 해상도를 갖 는 투영된 이미지 피처로 변환하기 위한 투영 행렬을 결정하고, 요구되는 뷰(desired view)에 맞는 투영 행렬을 이용하여 깊이 맵을 변조할 수 있다. 또한, 카메라 뷰에서 공간적 겹침이 공통 볼류메트릭 피처를 공유하기 때문에, 본 개시에서는 일관된 메트릭 스 케일 깊이 맵(metric scaled depth maps)을 예측할 수 있다. 본 개시에 따른 방법은, 임의의 초점 거리뿐만 아니라 요(yaw)/롤(roll)/피치(pitch) 각도를 변화시켜가며 매끄 러운 깊이 맵을 생성할 수 있다. 즉, 본 개시에서는 실제 촬영된 이미지가 아닌, 카메라 포즈를 임의로 변조하 는 경우에도 매끄러운 깊이 맵을 생성할 수 있다. 도 8a는 차량에 설치된 3대의 카메라로부터 획득된 이미지로써, 각각 차량의 좌측 전방(front-left), 전방 (front) 및 우측 전방(front-right)을 촬영한 이미지에 해당된다. 도 8b는 본 개시에 따른 방법으로 카메라의 초점을 x1, x1/2, x1/3 배율로 변조하여 획득한 깊이 맵에 해당하고, 도 8c는 본 개시에 따른 방법으로 좌측 전방 및 우측 전방의 이미지를 기준으로 요 각도(yaw angle) 을 변조한 뷰-보간(view-interpolation) 깊이 맵에 해당하고, 도 8d는 본 개시에 따른 방법으로 전방 이미지를 롤 각도(roll angle)을 ±10°변조한 깊이 맵에 해당하고, 도 8e는 본 개시에 따른 방법으로 전방 이미지를 피 치 각도(pitch angle)을 ±3°변조한 깊이 맵에 해당한다. 도 9는 일 실시예에 따른 표준 모션 예측을 수행하는 방법을 설명하기 위한 예시적인 도면이다. 깊이 맵 생성 장치는 도 6에서 생성된 볼류메트릭 피처를 조감도(BEV) 피처로 평면화(flatten)할 수 있다. 또한, 깊이 맵 생성 장치는 포즈 디코더를 이용하여 조감도 피처를 디코딩함으로써, 기준 단안 카메라의 현재 시점과 다음 시점 카메라 포즈 간의 변화량을 나타내는 표준 카메라 모션(canonical camera motion)을 획득할 수 있다. 여기서 '모션'은 기준 단안 카메라의 현재 시점과 다음 시점 간 포즈의 변화량을 의미한다. 깊이 맵 생성 장치는 기준 단안 카메라와 다른 단안 카메라 간 외부 파라미터 관계 및 표준 카메라 모션에 기초하여, 다 음 시점에서의 다른 단안 카메라의 포즈 정보를 일괄 획득할 수 있다. 구체적으로, 도 9를 참조하면, 깊이 맵 생성 장치는 볼류메트릭 피처( )의 Z축을 채널 차원 C로 붕괴시키고(collapse)(즉, 3D tensor 로 reshaping), 2D 컨벌루션을 적용함으로써 평면 화된 조감도 피처 FBEV)(즉, )를 생성할 수 있다. 또한, 깊이 맵 생성 장치는 포즈 디코더를 이용하여 표준 카메라 모션 을 획득할 수 있다. 표준 카 메라 모션 은, 기준 단안 카메라(예를 들어, 전방 단안 카메라)의 현재 시점(t)과 다음 시점(t+1) 카메 라 포즈 간의 변화량을 나타낸다. 깊이 맵 생성 장치는 기준 단안 카메라와 다른 단안 카메라 간 외부 파라미터 관계 및 표준 카메라 모션에 기초 하여, 다음 시점에서의 다른 단안 카메라의 포즈 정보를 일괄 획득할 수 있다. 이는 아래 수학식 1과 같이 표현 될 수 있다. 아래 수학식 1에서 E1은 기준 단안 카메라의 외부 파라미터를 의미한다. 수학식 1"}
{"patent_id": "10-2022-0095016", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "item": 3, "content": "도 9를 참조하면, 차량에 설치된 단안 카메라가 총 N개인 경우, 깊이 맵 생성 장치는 상기 수학식 1을 이용하여 기준 단안 카메라 외 다른 단안 카메라의 다음 시점 t+1에서의 포즈 정보 를 일괄 획 득할 수 있다. 한편, 전방 카메라 외 다른 방향으로 배향된 단안 카메라도 기준 단안 카메라로 설정될 수 있다. 도 10은 일 실시예에 따른 자기지도 학습을 이용한 뉴럴 네트워크를 설명하기 위한 예시적인 도면이다. 깊이 맵 생성 장치는 자기지도 학습(self-supervised learning)을 이용하여 뉴럴 네트워크를 학습시킬 수 있다. 깊이 맵 생성 장치는 서라운드 뷰 이미지를 뉴럴 네트워크의 입력 데이터로 이용하고, 깊이 맵 및 표준 카메라 모션을 출력 데이터 이용함으로써 뉴럴 네트워크를 학습시킬 수 있다. 일 실시예에서, 뉴럴 네트워크는 아래 수학식 2에 따른 이미지 재구성 손실(image reconstruction loss)"}
{"patent_id": "10-2022-0095016", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "및 깊이 합성 손실(depth synthesis loss) 을 최소화하는 방향으로 학습될 수 있다. 수학식 2"}
{"patent_id": "10-2022-0095016", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "또한, 이미지 재구성 손실은 아래 수학식 3에 따른 시간적(temporal) 손실 , 공간적(spatio) 손실 및 시 공간적(spatio-temporal) 손실 을 포함할 수 있다. 한편, 아래 수학식 3에서 는 smoothness loss를 의미한다. 수학식 3"}
{"patent_id": "10-2022-0095016", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "또한, 깊이 합성 손실은, 아래 수학식 4에 따른 깊이 일관성(consistency) 손실 를 포함할 수 있다. 깊이 일관성 손실 은 새로운 뷰에서 합성된 깊이와 알려진 각 카메라 뷰 i에서의 깊이 사이의 깊이 차이에 대한 페널티를 나타냅니다. 수학식 4"}
{"patent_id": "10-2022-0095016", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "item": 7, "content": "도 11은 일 실시예에 따른 단안 카메라를 이용하여 깊이 맵을 생성하는 방법을 설명하기 위한 흐름도이다. 도 11을 참조하면, 단계 1110에서, 프로세서는 하나 이상의 단안 카메라를 통해 서라운드 뷰 이미지를 획득할 수 있다. 단계 1020에서, 프로세서는 서라운드 뷰 이미지에 포함된 기본 이미지를 인코딩하여 다중 스케일(multi-scale) 이미지 피처들을 생성할 수 있다. 단계 1030에서, 프로세서는 다중-스케일 이미지 피처들 각각을 소정의 해상도를 기준으로 리사이즈(resize) 및 연접(concatenate)하여, 기본 이미지에 대한 단일 피처맵을 생성할 수 있다. 단계 1040에서, 프로세서는 단일 피처맵을 깊이 정보(depth information)와 함께 인코딩한 후, 인코딩 결과를 3 차원 공간으로 투영함으로써 볼류메트릭 피처(volumetric feature)를 생성할 수 있다. 일 실시예에서, 프로세서는 단일 피처맵을 상기 깊이 정보와 연결(concatenate)하여 인코딩한 후, 인코딩 결과 를 3차원 공간으로 투영함으로써 3차원 볼류메트릭 공간 상의 로컬 3차원 피처를 추출할 수 있다. 또한, 프로세서는 로컬 3차원 피처를 이용하여 상기 볼류메트릭 피처를 생성할 수 있다. 일 실시예에서, 프로세서는 볼류메트릭 인코더에 로컬 3차원 피처를 입력하여 볼류메트릭 피처를 생성할 수 있 다. 일 실시예에서, 볼류메트릭 인코더는 복수개의 다층 퍼셉트론(Multi-Layer Perceptron)으로 구성될 수 있다. 프 로세서는 3차원 볼류메트릭 공간 상의 복셀 별로 겹침이 발생했는지 여부에 따라 서로 다른 다층 퍼셉트론에 할 당할 수 있다. 프로세서는 서로 다른 다층 퍼셉트론으로부터의 인코딩 결과를 융합(fuse)하여 볼류메트릭 피처 를 생성할 수 있다. 단계 1050에서, 프로세서는 깊이 디코더를 이용하여 볼류메트릭 피처를 디코딩함으로써, 서라운드 뷰 이미지의 깊이 맵을 생성할 수 있다. 일 실시예에서, 프로세서는 카메라의 내부 파라미터(intrinsic parameter) 및 외부 파라미터(extrinsic parameter)에 기초하여, 볼류메트릭 피처를 상기 소정의 해상도를 갖는 투영된 이미지 피처로 변환할 수 있다. 프로세서는 깊이 디코더를 이용하여 투영된 이미지 피처를 디코딩함으로써, 서라운드 뷰 이미지의 깊이 맵을 생 성할 수 있다. 일 실시예에서, 프로세서는 볼류메트릭 피처를 소정의 해상도를 갖는 투영된 이미지 피처로 변환하기 위한 투영 행렬(projective matrix)을 결정할 수 있다. 프로세서는 요구되는 뷰(desired view)에 맞는 투영 행렬을 이용하 여, 깊이 맵을 변조할 수 있다. 일 실시예에서, 프로세서는 볼류메트릭 피처를 조감도(BEV) 피처로 평면화(flatten)할 수 있다. 프로세서는 포 즈 디코더를 이용하여 조감도 피처를 디코딩함으로써, 기준 단안 카메라의 현재 시점과 다음 시점 카메라 포즈 간의 변화량을 나타내는 표준 카메라 모션(canonical camera motion)을 획득할 수 있다. 프로세서는 기준 단안 카메라와 다른 단안 카메라 간 외부 파라미터 관계 및 표준 카메라 모션에 기초하여, 다음 시점에서의 상기 다 른 단안 카메라의 포즈 정보를 일괄 획득할 수 있다. 일 실시예에서, 프로세서는 서라운드 뷰 이미지를 뉴럴 네트워크의 입력 데이터로 이용하고, 깊이 맵 및 표준 카메라 모션을 출력 데이터 이용함으로써 상기 뉴럴 네트워크를 학습시킬 수 있다. 뉴럴 네트워크는 이미지 재구성 손실(image reconstruction loss) 및 깊이 합성 손실(depth synthesis loss)을 최소화하는 방향으로 학습될 수 있다. 이미지 재구성 손실은, 시간적(temporal) 손실, 공간적(spatio) 손실 및 시공간적(spatio-temporal) 손실을 포함할 수 있다. 깊이 합성 손실은, 깊이 일관성(consistency) 손실을 포함 할 수 있다. 도 12는 일 실시예에 따른 깊이 맵 생성 장치의 블록도이다. 도 12를 참조하면, 깊이 맵 생성 장치는 통신부, 프로세서 및 DB를 포함할 수 있다. 도 12의 깊이 맵 생성 장치에는 실시예와 관련된 구성요소들만이 도시되어 있다. 따라서, 도 12에 도시된"}
{"patent_id": "10-2022-0095016", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 8, "content": "구성요소들 외에 다른 범용적인 구성요소들이 더 포함될 수 있음을 당해 기술분야의 통상의 기술자라면 이해할 수 있다. 통신부는 외부 서버 또는 외부 장치와 유선/무선 통신을 하게 하는 하나 이상의 구성 요소를 포함할 수 있다. 예를 들어, 통신부는, 근거리 통신부(미도시), 이동 통신부(미도시) 및 방송 수신부(미도시) 중 적 어도 하나를 포함할 수 있다. DB는 깊이 맵 생성 장치 내에서 처리되는 각종 데이터들을 저장하는 하드웨어로서, 프로세서(122 0)의 처리 및 제어를 위한 프로그램을 저장할 수 있다. DB는 DRAM(dynamic random access memory), SRAM(static random access memory) 등과 같은 RAM(random access memory), ROM(read-only memory), EEPROM(electrically erasable programmable read-only memory), CD-ROM, 블루레이 또는 다른 광학 디스크 스토리지, HDD(hard disk drive), SSD(solid state drive), 또는 플 래시 메모리를 포함할 수 있다. 프로세서는 깊이 맵 생성 장치의 전반적인 동작을 제어한다. 예를 들어, 프로세서는 DB에 저장된 프로그램들을 실행함으로써, 입력부(미도시), 디스플레이(미도시), 통신부, DB 등을 전반적으로 제어할 수 있다. 프로세서는, DB에 저장된 프로그램들을 실행함으로써, 깊이 맵 생성 장치의 동작을 제어할 수 있다.프로세서는 도 1 내지 도 11에서 상술한 깊이 맵 생성 장치의 동작 중 적어도 일부를 제어할 수 있 다. 깊이 맵 생성 장치 및 자율 주행 장치는 동일한 장치이거나, 각 장치에서 수행되는 적어도 일부 의 동작이 동일할 수 있다. 프로세서는 ASICs (application specific integrated circuits), DSPs(digital signal processors), DSPDs(digital signal processing devices), PLDs(programmable logic devices), FPGAs(field programmable gate arrays), 제어기(controllers), 마이크로 컨트롤러(micro-controllers), 마이크로 프로세서 (microprocessors), 기타 기능 수행을 위한 전기적 유닛 중 적어도 하나를 이용하여 구현될 수 있다. 일 실시예로, 깊이 맵 생성 장치는 이동성을 가지는 전자 장치일 수 있다. 예를 들어, 깊이 맵 생성 장치 는 스마트폰, 태블릿 PC, PC, 스마트 TV, PDA(personal digital assistant), 랩톱, 미디어 플레이어, 내 비게이션, 카메라가 탑재된 디바이스 및 기타 모바일 전자 장치로 구현될 수 있다. 또한, 깊이 맵 생성 장치 는 통신 기능 및 데이터 프로세싱 기능을 구비한 시계, 안경, 헤어 밴드 및 반지 등의 웨어러블 장치로 구현될 수 있다. 다른 실시예로, 깊이 맵 생성 장치는 차량 내에 임베디드 되는 전자 장치일 수 있다. 예를 들어, 깊이 맵 생성 장치는 생산 과정 이후 튜닝(tuning)을 통해 차량 내에 삽입되는 전자 장치일 수 있다. 또 다른 실시예로, 깊이 맵 생성 장치는 차량 외부에 위치하는 서버일 수 있다. 서버는 네트워크를 통해 통신하여 명령, 코드, 파일, 컨텐츠, 서비스 등을 제공하는 컴퓨터 장치 또는 복수의 컴퓨터 장치들로 구현될 수 있다. 서버는 차량에 탑재된 장치들로부터 차량의 이동 경로를 결정하기 위해 필요한 데이터를 수신하고, 수 신한 데이터에 기초하여 차량의 이동 경로를 결정할 수 있다. 또 다른 실시예로, 깊이 맵 생성 장치에서 수행되는 프로세스는 이동성을 가지는 전자 장치, 차량 내에 임베디되는 전자 장치 및 차량 외부에 위치하는 서버 중 적어도 일부에 의해 수행될 수 있다. 본 발명에 따른 실시 예는 컴퓨터 상에서 다양한 구성요소를 통하여 실행될 수 있는 컴퓨터 프로그램의 형태로 구현될 수 있으며, 이와 같은 컴퓨터 프로그램은 컴퓨터로 판독 가능한 매체에 기록될 수 있다. 이때, 매체는 하드 디스크, 플로피 디스크 및 자기 테이프와 같은 자기 매체, CD-ROM 및 DVD와 같은 광기록 매체, 플롭티컬 디스크(floptical disk)와 같은 자기-광 매체(magneto-optical medium), 및 ROM, RAM, 플래시 메모리 등과 같 은, 프로그램 명령어를 저장하고 실행하도록 특별히 구성된 하드웨어 장치를 포함할 수 있다. 한편, 상기 컴퓨터 프로그램은 본 발명을 위하여 특별히 설계되고 구성된 것이거나 컴퓨터 소프트웨어 분야의 당업자에게 공지되어 사용 가능한 것일 수 있다. 컴퓨터 프로그램의 예에는, 컴파일러에 의하여 만들어지는 것 과 같은 기계어 코드뿐만 아니라 인터프리터 등을 사용하여 컴퓨터에 의해서 실행될 수 있는 고급 언어 코드도 포함될 수 있다. 일 실시예에 따르면, 본 개시의 다양한 실시예들에 따른 방법은 컴퓨터 프로그램 제품(computer program product)에 포함되어 제공될 수 있다. 컴퓨터 프로그램 제품은 상품으로서 판매자 및 구매자 간에 거래될 수 있 다. 컴퓨터 프로그램 제품은 기기로 읽을 수 있는 저장 매체(예: compact disc read only memory (CD-ROM))의 형태로 배포되거나, 또는 어플리케이션 스토어(예: 플레이 스토어TM)를 통해 또는 두 개의 사용자 장치들 간에 직접, 온라인으로 배포(예: 다운로드 또는 업로드)될 수 있다. 온라인 배포의 경우에, 컴퓨터 프로그램 제품의 적어도 일부는 제조사의 서버, 어플리케이션 스토어의 서버, 또는 중계 서버의 메모리와 같은 기기로 읽을 수 있는 저장 매체에 적어도 일시 저장되거나, 임시적으로 생성될 수 있다. 본 발명에 따른 방법을 구성하는 단계들에 대하여 명백하게 순서를 기재하거나 반하는 기재가 없다면, 상기 단 계들은 적당한 순서로 행해질 수 있다. 반드시 상기 단계들의 기재 순서에 따라 본 발명이 한정되는 것은 아니 다. 본 발명에서 모든 예들 또는 예시적인 용어(예들 들어, 등등)의 사용은 단순히 본 발명을 상세히 설명하기 위한 것으로서 특허청구범위에 의해 한정되지 않는 이상 상기 예들 또는 예시적인 용어로 인해 본 발명의 범위 가 한정되는 것은 아니다. 또한, 당업자는 다양한 수정, 조합 및 변경이 부가된 특허청구범위 또는 그 균등물의 범주 내에서 설계 조건 및 팩터에 따라 구성될 수 있음을 알 수 있다. 따라서, 본 발명의 사상은 상기 설명된 실시 예에 국한되어 정해져서는 아니 되며, 후술하는 특허청구범위뿐만 아니라 이 특허청구범위와 균등한 또는 이로부터 등가적으로 변경된 모든 범위는 본 발명의 사상의 범주에 속한 다고 할 것이다.도면 도면1 도면2 도면3 도면4a 도면4b 도면5 도면6a 도면6b 도면6c 도면7 도면8a 도면8b 도면8c 도면8d 도면8e 도면9 도면10 도면11 도면12"}
{"patent_id": "10-2022-0095016", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1 내지 도 3은 일 실시예에 따른 자율 주행 방식을 설명하기 위한 도면들이다. 도 4a 내지 4b는 일 실시예에 따른 서라운드 뷰 이미지를 획득하는 방법을 설명하기 위한 예시적인 도면이다. 도 5는 일 실시예에 따른 이미지 인코더를 이용하여 서라운드 뷰 이미지에 대한 단일 피처맵을 생성하는 방법을 설명하기 위한 도면이다. 도 6a 내지 6b는 일 실시예에 따른 단일 피처맵을 이용하여 볼류매트릭 피처를 생성하는 방법을 설명하기 위한 예시적인 도면이다. 도 7은 일 실시예에 따른 서라운드 뷰 이미지의 깊이 맵을 생성하는 방법을 설명하기 위한 예시적인 도면이다. 도 8a 내지 8e는 일 실시예에 따른 임의의 회전 뷰에 따른 깊이 맵을 획득하는 방법을 설명하기 위한 예시적인 도면이다. 도 9는 일 실시예에 따른 표준 모션 예측을 수행하는 방법을 설명하기 위한 예시적인 도면이다. 도 10은 일 실시예에 따른 자기지도 학습을 이용한 뉴럴 네트워크를 설명하기 위한 예시적인 도면이다. 도 11은 일 실시예에 따른 단안 카메라를 이용하여 깊이 맵을 생성하는 방법을 설명하기 위한 흐름도이다. 도 12는 일 실시예에 따른 깊이 맵 생성 장치의 블록도이다."}
