{"patent_id": "10-2023-0105562", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2025-0024277", "출원번호": "10-2023-0105562", "발명의 명칭": "향상된 신뢰도를 가진 음향 인식 결과 제공 방법, 장치 및 컴퓨터 프로그램", "출원인": "코클 아이엔씨", "발명자": "박정수"}}
{"patent_id": "10-2023-0105562", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "컴퓨팅 장치의 하나 이상의 프로세서에서 수행되는 방법에 있어서,음향 데이터를 획득하는 단계;음향 데이터를 분할하여 복수 개의 음향 서브 데이터를 생성하는 단계; 및상기 복수 개의 음향 서브 데이터를 음향 인식 모델의 입력으로 처리하여 각 음향 서브 데이터에 대응하는 음향인식 결과 정보를 생성하는 단계;를 포함하는,향상된 신뢰도를 가진 음향 인식 결과 제공 방법."}
{"patent_id": "10-2023-0105562", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 복수 개의 음향 서브 데이터를 생성하는 단계는,상기 음향 데이터를 기 설정된 크기 단위로 분할하여 복수 개의 음향 서브 데이터를 생성하는 단계; 를 포함하며,상기 음향 인식 모델은,상기 복수 개의 음향 서브 데이터 각각을 입력으로 하여 각 음향 서브 데이터에 대응하는 복수 개의 출력을 제공하는 제1인식 모델 및 상기 복수 개의 음향 서브 데이터 간의 조합을 통해 생성된 조합 재검증 음향 서브 데이터를 입력으로 하여, 상기 조합 재검증 음향 서브 데이터에 대응하는 출력을 제공하는 제2인식 모델을 포함하는,향상된 신뢰도를 가진 음향 인식 결과 제공 방법."}
{"patent_id": "10-2023-0105562", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,상기 음향 인식 결과 정보를 생성하는 단계는,상기 제1인식 모델이 상기 각 음향 서브 데이터에 대응하여 출력한 음향 인식 결과 정보들을 기반으로 음향 서브 데이터의 재검증이 필요한 재검증 음향 서브 데이터를 선별하는 단계;상기 선별된 재검증 음향 서브 데이터를 기준으로 조합 재검증 음향 서브 데이터를 생성하는 단계; 및상기 조합 재검증 음향 서브 데이터를 상기 제2인식 모델에 입력으로 처리하여 음향 인식 결과 정보를 생성하는단계; 를 포함하며,상기 제2인식 모델은,클라우드 API를 통해 구현되는 것을 특징으로 하는,향상된 신뢰도를 가진 음향 인식 결과 제공 방법.공개특허 10-2025-0024277-3-청구항 4 제3항에 있어서,상기 재검증 음향 서브 데이터를 선별하는 단계는,상기 제1인식 모델의 출력에 관련한 인식 항목들 간의 유사도 점수를 도출하는 단계; 및산출된 상기 유사도 점수를 기반으로 재검증 음향 서브 데이터를 선별하는 단계; 를 포함하는,향상된 신뢰도를 가진 음향 인식 결과 제공 방법."}
{"patent_id": "10-2023-0105562", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제3항에 있어서,상기 재검증 음향 서브 데이터를 선별하는 단계는,상기 제1인식 모델의 출력에 관련한 음향 인식 결과 정보가 기 설정된 재검증 항목 내에 포함되는지 여부를 식별하는 단계; 및상기 음향 인식 결과 정보가 상기 재검증 항목 내에 포함되는 경우, 상기 음향 인식 결과 정보 산출에 기반이되는 음향 서브 데이터를 재검증이 필요한 재검증 음향 서브 데이터로 선별하는 단계; 를 포함하는,향상된 신뢰도를 가진 음향 인식 결과 제공 방법."}
{"patent_id": "10-2023-0105562", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제3항에 있어서,상기 제1인식 모델은,각 인식 항목 별 확률값을 출력하고, 산출된 확률값들 중 최대값에 해당하는 확률값에 대응하는 인식 항목을 기반으로 음향 인식 결과 정보를 생성하는 것을 특징으로 하며,상기 재검증 음향 서브 데이터를 선별하는 단계는,상기 제1인식 모델을 통해 산출된 각 인식 항목 별 확률값 중 기 설정된 임계 기준치를 초과하는 인식 항목이복수 개인 경우, 상기 음향 인식 결과 정보 산출에 기반이 되는 음향 서브 데이터를 재검증이 필요한 재검증 음향 서브 데이터로 선별하는 단계; 를 포함하는,향상된 신뢰도를 가진 음향 인식 결과 제공 방법."}
{"patent_id": "10-2023-0105562", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에 있어서,상기 음향 인식 결과 정보를 생성하는 단계는,상기 음향 인식 결과 정보 간의 연관관계 정보를 생성하는 단계; 및상기 연관관계 정보를 기반으로 각 음향 서브 데이터에 대응하는 상기 음향 인식 결과 정보들 중 적어도 하나의음향 인식 결과 정보에 대한 보정을 수행하는 단계; 를 포함하는,향상된 신뢰도를 가진 음향 인식 결과 제공 방법."}
{"patent_id": "10-2023-0105562", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "공개특허 10-2025-0024277-4-제7항에 있어서,상기 적어도 하나의 음향 인식 결과 정보에 대한 보정을 수행하는 단계는,제1음향 인식 결과 정보와 제2음향 인식 결과 정보가 기 설정된 시간 이내에 생성된 경우, 상기 제1음향 인식결과와 상기 제2음향 인식 결과 정보에 대응하는 연관관계 정보를 기반으로 제1음향 인식 결과 및 제2음향 인식결과 중 적어도 하나에 대한 보정을 수행하는 것을 특징으로 하는,향상된 신뢰도를 가진 음향 인식 결과 제공 방법."}
{"patent_id": "10-2023-0105562", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1항에 있어서,상기 방법은,무드 감지 모델을 활용하여 상기 음향 인식 결과 정보에 대응하는 무드 정보를 생성하는 단계; 를 더 포함하며,상기 무드 정보는,음향 데이터가 획득되는 공간에 관련한 분위기에 대한 예측 정보로, 장소 예측 정보 및 감정 예측 정보를 포함하며,상기 음향 인식 결과 정보를 생성하는 단계는,제1음향 서브 데이터에 대응하는 제1음향 인식 결과 정보와 상기 제1음향 서브 데이터에 대응하는 상기 무드 정보 간의 연관성 정보를 생성하는 단계;상기 연관성 정보가 기 설정된 기준치 이상인 경우, 상기 제1음향 인식 결과 정보에 대한 보정을 수행하지 않는단계; 및상기 연관성 정보가 기 설정된 기준치 미만인 경우, 상기 제1음향 인식 결과 정보에 대한 보정을 수행하는단계; 를 포함하며,상기 무드 감지 모델은,상기 음향 인식 결과 정보를 인식하여 시점 별 주변 상황에 대응하는 상기 무드 정보를 출력하도록 학습된 신경망 모델인 것을 특징으로 하는,향상된 신뢰도를 가진 음향 인식 결과 제공 방법."}
{"patent_id": "10-2023-0105562", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9항에 있어서,상기 제1음향 인식 결과 정보에 대한 보정을 수행하는 단계는,상기 제1음향 인식 결과와 유사성을 가진 복수의 키워드를 식별하는 단계;상기 복수의 키워드 각각과 상기 무드 정보 간 복수의 연관성 서브 정보를 생성하는 단계; 및상기 복수의 연관성 서브 정보 중 최대값에 해당하는 최대 연관성 서브 정보를 식별하고, 최대 연관성 서브 정보에 대응하는 키워드에 기초하여 상기 제1음향 인식 결과 정보에 대한 보정을 수행하는 단계; 를 포함하는,향상된 신뢰도를 가진 음향 인식 결과 제공 방법."}
{"patent_id": "10-2023-0105562", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "하나 이상의 인스트럭션을 저장하는 메모리; 및공개특허 10-2025-0024277-5-상기 메모리에 저장된 상기 하나 이상의 인스트럭션을 실행하는 프로세서를 포함하고,상기 프로세서는 상기 하나 이상의 인스트럭션을 실행함으로써,제1항의 방법을 수행하는, 장치."}
{"patent_id": "10-2023-0105562", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "하드웨어인 컴퓨터와 결합되어, 제1항의 방법을 수행할 수 있도록 컴퓨터에서 독출가능한 기록매체에 저장된 컴퓨터프로그램."}
{"patent_id": "10-2023-0105562", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "전술한 과제를 해결하기 위한 본 발명의 일 실시예에서, 향상된 신뢰도를 가진 음향 인식 결과 제공 방법이 개시 된다. 상기 방법은, 음향 데이터를 획득하는 단계, 음향 데이터를 분할하여 복수 개의 음향 서브 데이터를 생성 하는 단계 및 상기 복수 개의 음향 서브 데이터를 음향 인식 모델의 입력으로 처리하여 각 음향 서브 데이터에 대응하는 음향 인식 결과 정보를 생성하는 단계를 포함할 수 있다."}
{"patent_id": "10-2023-0105562", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 음향 데이터의 인식률 향상시키기 위한 방법에 관한 것으로, 보다 구체적으로, 음향 데이터를 시간단 위 구간으로 분할하여 각 구간에 대한 인식을 수행하는 과정에서 계산량을 줄이면서도 인식률을 향상을 도모하 며, 다양한 주변 상황에 대응하여 향상된 정확도를 가진 음향 인식 결과를 제공하기 위한 방법에 관한 것이다."}
{"patent_id": "10-2023-0105562", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "완전히 소리를 못듣거나 또는 소리를 잘 구별하지 못하는 청각 장애우들은 소리를 듣고 상황을 판단하는 것이 어렵기 때문에 일상생활에 많은 어려움이 있을 뿐만 아니라, 소리 정보를 이용하여 실내, 실외 환경에서의 위험 한 상황을 인지할 수 없어 즉각적인 대처가 불가능하다. 청각 장애우뿐 아니라, 이어폰 착용 보행자, 고령자 등 청감각이 없거나 제한된 상황에서는 사용자 주변에서 발생하는 음향이 차단될 수 있다. 추가적으로, 사용자가 수면을 취하는 등 음향을 감지하기 어려운 상황에서는 주변 상황을 인지하지 못하여 위험한 상황에 처하거나, 사고를 당할 우려가 있다. 한편, 이러한 환경속에서 음향 이벤트를 검출하고 인식하는 기술 개발에 대한 필요성이 대두되고 있다. 음향 이 벤트를 검출하고 인식하는 기술은, 실생활 환경 컨텍스트 인식, 위험상황 인식, 미디어 콘텐츠 인식, 유선 통신 상의 상황분석 등 다양한 분야에 응용 가능한 기술로 지속적으로 연구되고 있다. 음향 이벤트 인식 기술로는, 오디오 신호로부터 MFCC, energy, spectral flux, zero crossing rate 등 다양한 특징 값을 추출하여 우수한 특징을 검증하는 연구와 Gaussian mixture model 또는 rule 기반의 분류 방법 등에 대한 연구가 주를 이루고 있으며, 최근에는 상기 방법들을 개선하기 위해 딥러닝 기반의 기계학습 방법이 연구 되고 있다. 그러나, 이러한 방법들은 낮은 신호대비 잡음비에서 음향 검출의 정확도가 보장되며, 주변 잡음과 사건 음향을 구별하는데 어렵다는 한계점을 가진다. 즉, 다양한 주변 노이즈를 포함하는 실생활 환경에서는 신뢰도 높은 음향 이벤트 검출이 어려울 수 있다. 구체 적으로, 유효한 음향 이벤트를 검출하기 위해서는 시계열적(즉, 연속적)으로 획득되는 음향 데이터에 대해 음향 이벤트가 발생했는지 여부를 판단해야 하며, 이와 함께 어떠한 이벤트 클래스가 발생했는지도 인식해야 하기 때 문에 높은 신뢰도를 담보하기 어려울 수 있다. 또한, 둘 이상의 이벤트가 동시에 발생하는 경우, 단일 이벤트 (monophonic)가 아닌 다중 이벤트(polyphonic) 인식 문제까지 해결해야 하므로, 음향 이벤트의 인식률이 더 낮 아질 수 있다. 따라서, 실생활 환경에서 시계열적으로 획득되는 음향 데이터에 대응하여 인식률을 높여 향상된 신뢰도를 가진 음향 인식을 제공하고자 하는 수요가 존재할 수 있다. 선행기술문헌 특허문헌(특허문헌 0001) 대한민국 등록특허 10-2014-0143069"}
{"patent_id": "10-2023-0105562", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명이 해결하고자 하는 과제는 전술한 문제점을 해결하기 위한 것으로서, 음향 데이터를 시간단위 구간으로 분할하여 각 구간에 대한 인식을 수행하는 과정에서 계산량을 줄이면서도 인식률을 향상을 도모하며, 다양한 주 변 상황에 대응하여 향상된 정확도를 가진 음향 인식 결과를 제공하기 위함이다. 본 발명이 해결하고자 하는 과제들은 이상에서 언급된 과제로 제한되지 않으며, 언급되지 않은 또 다른 과제들 은 아래의 기재로부터 통상의 기술자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2023-0105562", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상술한 과제를 해결하기 위한 본 발명의 다양한 실시예에 따른 향상된 신뢰도를 가진 음향 인식 결과 제공 방법 이 개시된다. 상기 방법은, 음향 데이터를 획득하는 단계, 음향 데이터를 분할하여 복수 개의 음향 서브 데이터 를 생성하는 단계 및 상기 복수 개의 음향 서브 데이터를 음향 인식 모델의 입력으로 처리하여 각 음향 서브 데 이터에 대응하는 음향 인식 결과 정보를 생성하는 단계를 포함할 수 있다. 대안적인 실시예에서, 상기 복수 개의 음향 서브 데이터를 생성하는 단계는, 상기 음향 데이터를 기 설정된 크 기 단위로 분할하여 복수 개의 음향 서브 데이터를 생성하는 단계를 포함하며, 상기 음향 인식 모델은, 상기 복 수 개의 음향 서브 데이터 각각을 입력으로 하여 각 음향 서브 데이터에 대응하는복수 개의 출력을 제공하는 제 1인식 모델 및 상기 복수 개의 음향 서브 데이터 간의 조합을 통해 생성된 조합 재검증 음향 서브 데이터를 입 력으로 하여, 조합 재검증 음향 서브 데이터에 대응하는 출력을 제공하는 제2인식 모델을 포함할 수 있다. 대안적인 실시예에서, 상기 음향 인식 결과 정보를 생성하는 단계는, 상기 제1인식 모델이 상기 각 음향 서브 데이터에 대응하여 출력한 음향 인식 결과 정보들을 기반으로 음향 서브 데이터의 재검증이 필요한 재검증 음향 서브 데이터를 선별하는 단계, 상기 선별된 재검증 음향 서브 데이터를 기준으로 조합 재검증 음향 서브 데이터 를 생성하는 단계 및 상기 조합 재검증 음향 서브 데이터를 상기 제2인식 모델에 입력으로 처리하여 음향 인식 결과 정보를 생성하는 단계를 포함하며, 상기 제2인식 모델은, 클라우드 API를 통해 구현되는 것을 특징으로 할 수 있다. 대안적인 실시예에서, 상기 재검증 음향 서브 데이터를 선별하는 단계는, 상기 제1인식 모델의 출력에 관련한 인식 항목들 간의 유사도 점수를 도출하는 단계 및 산출된 상기 유사도 점수를 기반으로 재검증 음향 서브 데이 터를 선별하는 단계를 포함할 수 있다. 대안적인 실시예에서, 상기 재검증 음향 서브 데이터를 선별하는 단계는, 상기 제1인식 모델의 출력에 관련한 음향 인식 결과 정보가 기 설정된 재검증 항목 내에 포함되는지 여부를 식별하는 단계 및 상기 음향 인식 결과 정보가 상기 재검증 항목 내에 포함되는 경우, 상기 음향 인식 결과 정보 산출에 기반이 되는 음향 서브 데이터 를 재검증이 필요한 재검증 음향 서브 데이터로 선별하는 단계를 포함할 수 있다. 대안적인 실시예에서, 상기 제1인식 모델은, 각 인식 항목 별 확률값을 출력하고, 산출된 확률값들 중 최대값에 해당하는 확률값에 대응하는 인식 항목을 기반으로 음향 인식 결과 정보를 생성하는 것을 특징으로 하며, 상기 재검증 음향 서브 데이터를 선별하는 단계는, 상기 제1인식 모델을 통해 산출된 각 인식 항목 별 확률값 중 기 설정된 임계 기준치를 초과하는 인식 항목이 복수 개인 경우, 상기 음향 인식 결과 정보 산출에 기반이 되는 음 향 서브 데이터를 재검증이 필요한 재검증 음향 서브 데이터로 선별하는 단계를 포함할 수 있다. 대안적인 실시예에서, 상기 음향 인식 결과 정보를 생성하는 단계는, 음향 인식 결과 정보 간의 연관관계 정보 를 생성하는 단계 및 상기 연관관계 정보를 기반으로 각 음향 서브 데이터에 대응하는 상기 음향 인식 결과 정 보들 중 적어도 하나의 음향 인식 결과 정보에 대한 보정을 수행하는 단계; 를 포함할 수 있다. 대안적인 실시예에서, 상기 적어도 하나의 음향 인식 결과 정보에 대한 보정을 수행하는 단계는, 제1음향 인식 결과 정보와 제2음향 인식 결과 정보가 기 설정된 시간 이내에 생성된 경우, 상기 제1음향 인식 결과와 상기 제2음향 인식 결과 정보에 대응하는 연관관계 정보를 기반으로 제1음향 인식 결과 및 제2음향 인식 결과 중 적어 도 하나에 대한 보정을 수행하는 것을 특징으로 할 수 있다. 대안적인 실시예에서, 상기 방법은, 무드 감지 모델을 활용하여 상기 음향 인식 결과 정보에 대응하는 무드 정 보를 생성하는 단계를 더 포함하며, 상기 무드 정보는, 음향 데이터가 획득되는 공간에 관련한 분위기에 대한 예측 정보로, 장소 예측 정보 및 감정 예측 정보를 포함하며, 상기 음향 인식 결과 정보를 생성하는 단계는, 제 1음향 서브 데이터에 대응하는 제1음향 인식 결과 정보와 상기 제1음향 서브 데이터에 대응하는 상기 무드 정보 간의 연관성 정보를 생성하는 단계, 상기 연관성 정보가 기 설정된 기준치 이상인 경우, 상기 제1음향 인식 결 과 정보에 대한 보정을 수행하지 않는 단계 및 상기 연관성 정보가 기 설정된 기준치 미만인 경우, 상기 제1음 향 인식 결과 정보에 대한 보정을 수행하는 단계를 포함하며, 상기 무드 감지 모델은, 상기 음향 인식 결과 정 보를 인식하여 시점 별 주변 상황에 대응하는 상기 무드 정보를 출력하도록 학습된 신경망 모델인 것을 특징으 로 할 수 있다. 본 발명의 다른 실시예에 따르면, 향상된 신뢰도를 가진 음향 인식 결과 제공 장치가 개시된다. 상기 장치는, 하나 이상의 인스트럭션을 저장하는 메모리 및 상기 메모리에 저장된 상기 하나 이상의 인스트럭션을 실행하는 프로세서를 포함하고, 상기 프로세서는 상기 하나 이상의 인스트럭션을 실행함으로써, 전술한 향상된 신뢰도를 가진 음향 인식 결과 제공 방법을 수행할 수 있다. 본 발명의 또 다른 실시예에 따르면, 컴퓨터에서 독출가능한 기록매체에 저장된 컴퓨터 프로그램이 개시된다. 상기 컴퓨터 프로그램은 하드웨어인 컴퓨터와 결합되어, 전술한 향상된 신뢰도를 가진 음향 인식 결과 제공 방 법을 수행할 수 있다. 본 발명의 기타 구체적인 사항들은 상세한 설명 및 도면들에 포함되어 있다."}
{"patent_id": "10-2023-0105562", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명의 다양한 실시예에 따라, 음향 데이터를 시간단위 구간으로 분할하여 각 구간에 대한 인식을 수행하는 과정에서 계산량을 줄이면서도 인식률을 향상을 도모하며, 다양한 주변 상황에 대응하여 향상된 정확도를 가진 음향 인식 결과를 제공할 수 있다."}
{"patent_id": "10-2023-0105562", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 2, "content": "본 발명의 효과들은 이상에서 언급된 효과로 제한되지 않으며, 언급되지 않은 또 다른 효과들은 아래의 기재로 부터 통상의 기술자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2023-0105562", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "다양한 실시예들이 이제 도면을 참조하여 설명된다. 본 명세서에서, 다양한 설명들이 본 발명의 이해를 제공하 기 위해서 제시된다. 그러나, 이러한 실시예들은 이러한 구체적인 설명 없이도 실행될 수 있음이 명백하다. 본 명세서에서 사용되는 용어 \"컴포넌트\", \"모듈\", \"시스템\" 등은 컴퓨터-관련 엔티티, 하드웨어, 펌웨어, 소프 트웨어, 소프트웨어 및 하드웨어의 조합, 또는 소프트웨어의 실행을 지칭한다. 예를 들어, 컴포넌트는 프로세서 상에서 실행되는 처리과정(procedure), 프로세서, 객체, 실행 스레드, 프로그램, 및/또는 컴퓨터일 수 있지만, 이들로 제한되는 것은 아니다. 예를 들어, 컴퓨팅 장치에서 실행되는 애플리케이션 및 컴퓨팅 장치 모두 컴포넌 트일 수 있다. 하나 이상의 컴포넌트는 프로세서 및/또는 실행 스레드 내에 상주할 수 있다. 일 컴포넌트는 하 나의 컴퓨터 내에 로컬화 될 수 있다. 일 컴포넌트는 2개 이상의 컴퓨터들 사이에 분배될 수 있다. 또한, 이러 한 컴포넌트들은 그 내부에 저장된 다양한 데이터 구조들을 갖는 다양한 컴퓨터 판독가능한 매체로부터 실행할 수 있다. 컴포넌트들은 예를 들어 하나 이상의 데이터 패킷들을 갖는 신호(예를 들면, 로컬 시스템, 분산 시스 템에서 다른 컴포넌트와 상호작용하는 하나의 컴포넌트로부터의 데이터 및/또는 신호를 통해 다른 시스템과 인 터넷과 같은 네트워크를 통해 전송되는 데이터)에 따라 로컬 및/또는 원격 처리들을 통해 통신할 수 있다. 더불어, 용어 \"또는\"은 배타적 \"또는\"이 아니라 내포적 \"또는\"을 의미하는 것으로 의도된다. 즉, 달리 특정되지 않거나 문맥상 명확하지 않은 경우에, \"X는 A 또는 B를 이용한다\"는 자연적인 내포적 치환 중 하나를 의미하는 것으로 의도된다. 즉, X가 A를 이용하거나; X가 B를 이용하거나; 또는 X가 A 및 B 모두를 이용하는 경우, \"X는 A 또는 B를 이용한다\"가 이들 경우들 어느 것으로도 적용될 수 있다. 또한, 본 명세서에 사용된 \"및/또는\"이라 는 용어는 열거된 관련 아이템들 중 하나 이상의 아이템의 가능한 모든 조합을 지칭하고 포함하는 것으로 이해 되어야 한다. 또한, \"포함한다\" 및/또는 \"포함하는\"이라는 용어는, 해당 특징 및/또는 구성요소가 존재함을 의미하는 것으로 이해되어야 한다. 다만, \"포함한다\" 및/또는 \"포함하는\"이라는 용어는, 하나 이상의 다른 특징, 구성요소 및/또 는 이들의 그룹의 존재 또는 추가를 배제하지 않는 것으로 이해되어야 한다. 또한, 달리 특정되지 않거나 단수 형태를 지시하는 것으로 문맥상 명확하지 않은 경우에, 본 명세서와 청구범위에서 단수는 일반적으로 \"하나 또 는 그 이상\"을 의미하는 것으로 해석되어야 한다. 당업자들은 추가적으로 여기서 개시된 실시예들과 관련되어 설명된 다양한 예시적 논리적 블록들, 구성들, 모듈 들, 회로들, 수단들, 로직들, 및 알고리즘 단계들이 전자 하드웨어, 컴퓨터 소프트웨어, 또는 양쪽 모두의 조합 들로 구현될 수 있음을 인식해야 한다. 하드웨어 및 소프트웨어의 상호교환성을 명백하게 예시하기 위해, 다양 한 예시적 컴포넌트들, 블록들, 구성들, 수단들, 로직들, 모듈들, 회로들, 및 단계들은 그들의 기능성 측면에서 일반적으로 위에서 설명되었다. 그러한 기능성이 하드웨어로 또는 소프트웨어로서 구현되는지 여부는 전반적인 시스템에 부과된 특정 어플리케이션(application) 및 설계 제한들에 달려 있다. 숙련된 기술자들은 각각의 특정 어플리케이션들을 위해 다양한 방법들로 설명된 기능성을 구현할 수 있다. 다만, 그러한 구현의 결정들이 본 발 명의 영역을 벗어나게 하는 것으로 해석되어서는 안된다. 제시된 실시예들에 대한 설명은 본 발명의 기술 분야에서 통상의 지식을 가진 자가 본 발명을 이용하거나 또는 실시할 수 있도록 제공된다. 이러한 실시예들에 대한 다양한 변형들은 본 발명의 기술 분야에서 통상의 지식을 가진 자에게 명백할 것이다. 여기에 정의된 일반적인 원리들은 본 발명의 범위를 벗어남이 없이 다른 실시예들 에 적용될 수 있다. 그리하여, 본 발명은 여기에 제시된 실시예들로 한정되는 것이 아니다. 본 발명은 여기에 제시된 원리들 및 신규한 특징들과 일관되는 최광의의 범위에서 해석되어야 할 것이다.본 명세서에서, 컴퓨터는 적어도 하나의 프로세서를 포함하는 모든 종류의 하드웨어 장치를 의미하는 것이고, 실시 예에 따라 해당 하드웨어 장치에서 동작하는 소프트웨어적 구성도 포괄하는 의미로서 이해될 수 있다. 예 를 들어, 컴퓨터는 스마트폰, 태블릿 PC, 데스크톱, 노트북 및 각 장치에서 구동되는 사용자 클라이언트 및 애 플리케이션을 모두 포함하는 의미로서 이해될 수 있으며, 또한 이에 제한되는 것은 아니다. 이하, 첨부된 도면을 참조하여 본 발명의 실시예를 상세하게 설명한다. 본 명세서에서 설명되는 각 단계들은 컴퓨터에 의하여 수행되는 것으로 설명되나, 각 단계의 주체는 이에 제한 되는 것은 아니며, 실시 예에 따라 각 단계들의 적어도 일부가 서로 다른 장치에서 수행될 수도 있다. 본 발명의 다양한 실시예에 따른 향상된 신뢰도를 가진 음향 인식 결과 제공 방법은, 음향 데이터의 인식률이 향상되도록 인식된 음향 데이터에 대한 추가적인 검증을 수행하는 방법, 일정 시간 내 출력되는 음향 인식 결과 들을 기반으로 음향 인식 결과들 중 적어도 일부를 보정하는 방법, 또는 주변 환경과 분위기를 실시간 파악하고, 이를 음향 데이터와 함께 고려하여 음향 인식 결과를 도출하는 방법을 포함할 수 있다. 실시예에서, 음향 데이터의 인식 정확도 향상은, 음향 데이터에서 특정 이벤트를 감지하는 인식 정확도가 향상됨을 의미할 수 있다. 음향 데이터에 대한 추가적인 검증을 수행하는 방법은, 예를 들어, 복수 개의 신경망 모델(예컨대, 음향 인식 모델)을 활용하여 복수 회 추가적인 음향 인식 결과를 도출하여 검증을 수행함으로써, 최종 도출되는 음향 인식 결과의 신뢰도 향상을 도모하는 방법을 의미할 수 있다. 이 경우, 복수 개의 신경망 모델 각각은, 서로 상이한 출력 과정을 가진 신경망 모델일 수 있다. 예컨대, 각 신경망 모델은, 입력에 활용되는 음향 데이터의 길이 구 간이 서로 상이한 모델로, 하나의 모델은 1초 구간의 음향 데이터를 기반으로 음향 인식 결과를 도출하는 모델 일 수 있으며, 다른 하나의 모델은 5초의 구간의 음향 데이터를 기반으로 음향 인식 결과를 도출하는 모델일 수 있다. 다만, 이에 제한되지 않으며, 복수 개의 신경망 모델은 서로 상이한 성능을 가진 음향 인식 모델일 수 있 다. 구체적인 예를 들어, 일반적으로 비교적 저성능의 가벼운 제1인식 모델을 활용하여 1차적으로 음향 인식을 수행하여 음향 인식 결과를 출력할 수 있다. 여기서, 1차적으로 출력한 음향 인식 결과에 대한 신뢰도가 다소 떨어진다고 판단되는 경우, 제1인식 모델 보다 고성능을 가진 제2인식 모델을 통해 재차 음향 인식을 수행하여, 1차 음향 인식 결과에 대한 재검증을 수행하게 된다. 이는, 평상 시 제1인식 모델을 활용하다가, 필요 시 제2인 식 모델을 활용하여 재검증만을 수행하도록 하는 구성으로, 계산량을 효과적으로 줄이면서도 인식 결과의 신뢰 도를 향상시킬 수 있다는 장점이 있다. 또한, 일정 시간 내 출력되는 음향 인식 결과들을 기반으로 음향 인식 결과들 중 적어도 일부를 보정하는 방법 은, 예컨대, 음향 데이터에 대응하는 음향 인식 결과에 대한 후처리 보정을 의미할 수 있다. 음향 데이터를 일 정 시간 간격으로 분할되어 입력될 수 있으며, 본 발명은 각 분할된 데이터에 대응하는 음향 인식 결과를 출력 하게 된다. 이 경우, 일정 시간 내에 출력된 음향 인식 결과 간의 연관관계를 파악하여 특정 음향 인식 결과를 다른 음향 인식 결과로 보정할 수 있다. 구체적인 예를 들어, 소리 A(예컨대, gunshot)라는 음향 인식 결과가 출력된 이후, n초 이내에 소리 B(예컨대, applause)라는 음향 인식 결과가 출력되는 경우, 소리 A의 인식 결과 를 소리 C(예컨대, 폭죽소리)로 보정할 수 있다. 즉, 일정 시간 내에 출력(또는 인식)되는 음향 인식 결과 간의 연관관계를 고려하여 음향 인식 결과들 중 적어도 하나에 대한 보정을 수행함으로써, 인식 정확도를 향상시킬 수 있다. 또한, 본 발명은 주변 환경과 분위기를 실시간 파악하고, 이를 획득되는 음향 데이터와 함께 고려하여 음향 인 식 결과를 도출하여 음향 데이터의 인식 정확도를 향상시킬 수 있다. 음향 데이터가 획득되는 시점에 해당 주변 환경 및 분위기를 감지하는 별도의 신경망 모델(예컨대, 무드 감지 모델)을 활용하여 음향 데이터의 입력 전과 후의 상황을 인지할 수 있으며, 이를 음향 분석 과정에서 음향 데이터와 함께 고려함으로써, 출력되는 음향 인 식 결과의 신뢰도를 향상시킬 수 있다. 구체적인 예를 들어, A 소리(예컨대, 폭죽 소리)의 경우, 일반적인 음향 인식 모델에서 gunshot(총소리)으로 인식될 수 있다. 짧은 폭발음의 경우, 높은 정확도의 음향 인식 결과를 출 력하기 어렵다. 본 발명은 해당 소리가 감지되기 전과 후에 감지되는 음향 인식 결과들을 기반으로 음향 데이터 가 획득되는 상황에 대응하는 분위기를 파악하고, 이를 음향 데이터와 함께 고려하여 음향 인식 결과를 도출할 수 있다. 예를 들어, 해당 A 소리의 인식 이전과 이후에, 노래 소리, 박수 소리, 환호 소리가 감지된 것을 식별 하여, 해당 A 소리에 관련한 분위기가 축하 분위기(또는 파티, 밝거나, 행복한 분위기)인 것으로 파악하여, 해 당 폭발음을 '총소리'가 아닌 '폭죽소리'로 인식하게 된다. 즉, 인식하고자 하는 음향 데이터의 전후 시점에 출 력되는 음향 인식 결과들을 기반으로 전반적인 분위기를 파악하고, 파악된 분위기를 고려하여 음향 데이터에 대한 인식을 수행함으로써, 음향 인식 결과의 출력 정확도를 향상시킬 수 있다. 음향 데이터의 인식 정확도를 향 상시키는 방법에 관련한 보다 구체적인 설명은, 이하에서 자세하게 후술하도록 한다. 도 1은 본 발명의 일 실시예에 따른 향상된 신뢰도를 가진 음향 인식 결과 제공 방법을 수행하기 위한 시스템을 개략적으로 나타낸 도면이다. 도 1에 도시된 바와 같이, 본 발명의 일 실시예에 따른 향상된 신뢰도를 가진 음 향 인식 결과 제공 방법을 수행하기 위한 시스템은, 음향 데이터의 인식 정확도를 향상시키기 위한 서버, 사용자 단말 및 외부 서버를 포함할 수 있다. 여기서, 도 1에 도시된 향상된 신뢰도를 가진 음향 인 식 결과 제공 방법을 수행하기 위한 시스템은 일 실시예에 따른 것이고, 그 구성 요소가 도 1에 도시된 실시예 에 한정되는 것은 아니며, 필요에 따라 부가, 변경 또는 삭제될 수 있다. 일 실시예에서, 음향 데이터의 인식 정확도를 향상시키기 위한 서버는 음향 데이터에 기반하여 특정 이벤 트가 발생하였는지 여부를 판별할 수 있다. 구체적으로, 음향 데이터의 인식 정확도를 향상시키기 위한 서버 는 실생활에 관련한 음향 데이터를 획득하고, 획득한 음향 데이터에 대한 분석을 통해 특정 이벤트가 발생 하였는지 여부를 판별할 수 있다. 일 실시예에서, 특정 이벤트는, 보안, 안전 또는 위험 발생에 관련한 것으로, 예컨대, 경보 소리, 아이의 울음 소리, 유리 깨지는 소리, 타이어 펑크 나는 소리 등의 발생에 관련한 것일 수 있다. 전술한 특정 이벤트에 관련한 음향에 대한 구체적인 기재는 일 예시일 뿐, 본 발명은 이에 제한되지 않는 다. 실시예에 따르면, 음향 데이터의 인식 정확도를 향상시키기 위한 서버는 API(Application Programming Interface)에 의해 구현되는 임의의 서버를 포함할 수 있다. 예컨대, 사용자 단말은 음향 데이터를 획득하 여 Cloud API를 통해 서버로 전달할 수 있다. 예컨대, 서버는 사용자 단말로부터 음향 데이터를 획득할 수 있으며, 음향 데이터에 대한 분석을 통해 비상 경보 소리(예컨대, 사이렌 소리)가 발생하였다고 판단 할 수 있다. 실시예에서, 음향 데이터의 인식 정확도를 향상시키기 위한 서버는 음향 인식 모델(예: 인공 지능 모델)을 통해 음향 데이터에 대한 분석을 수행할 수 있다. 일 실시예에서, 음향 인식 모델(예: 인공지능 모델)은 하나 이상의 네트워크 함수로 구성되며, 하나 이상의 네 트워크 함수는 일반적으로 ‘노드’라 지칭될 수 있는 상호 연결된 계산 단위들의 집합으로 구성될 수 있다. 이 러한 ‘노드’들은 ‘뉴런(neuron)’들로 지칭될 수도 있다. 하나 이상의 네트워크 함수는 적어도 하나 이상의 노드들을 포함하여 구성된다. 하나 이상의 네트워크 함수를 구성하는 노드(또는 뉴런)들은 하나 이상의 ‘링크 ’에 의해 상호 연결될 수 있다. 인공지능 모델 내에서, 링크를 통해 연결된 하나 이상의 노드들은 상대적으로 입력 노드 및 출력 노드의 관계를 형성할 수 있다. 입력 노드 및 출력 노드의 개념은 상대적인 것으로서, 하나의 노드에 대하여 출력 노드 관계에 있는 임의의 노드는 다른 노드와의 관계에서 입력 노드 관계에 있을 수 있으며, 그 역도 성립할 수 있다. 전술 한 바와 같이, 입력 노드 대 출력 노드 관계는 링크를 중심으로 생성될 수 있다. 하나의 입력 노드에 하나 이상 의 출력 노드가 링크를 통해 연결될 수 있으며, 그 역도 성립할 수 있다. 하나의 링크를 통해 연결된 입력 노드 및 출력 노드 관계에서, 출력 노드는 입력 노드에 입력된 데이터에 기초 하여 그 값이 결정될 수 있다. 여기서 입력 노드와 출력 노드를 상호 연결하는 노드는 가중치(weight)를 가질 수 있다. 가중치는 가변적일 수 있으며, 인공지능 모델이 원하는 기능을 수행하기 위해, 사용자 또는 알고리즘 에 의해 가변될 수 있다. 예를 들어, 하나의 출력 노드에 하나 이상의 입력 노드가 각각의 링크에 의해 상호 연 결된 경우, 출력 노드는 상기 출력 노드와 연결된 입력 노드들에 입력된 값들 및 각각의 입력 노드들에 대응하 는 링크에 설정된 가중치에 기초하여 출력 노드 값을 결정할 수 있다. 전술한 바와 같이, 인공지능 모델은 하나 이상의 노드들이 하나 이상의 링크를 통해 상호연결 되어 인공지능 모 델 내에서 입력 노드 및 출력 노드 관계를 형성한다. 인공지능 모델 내에서 노드들과 링크들의 개수 및 노드들 과 링크들 사이의 연관관계, 링크들 각각에 부여된 가중치의 값에 따라, 인공지능 모델의 특성이 결정될 수 있 다. 예를 들어, 동일한 개수의 노드 및 링크들이 존재하고, 링크들 사이의 가중치 값이 상이한 두 인공지능 모 델이 존재하는 경우, 두 개의 인공지능 모델들은 서로 상이한 것으로 인식될 수 있다. 인공지능 모델을 구성하는 노드들 중 일부는, 최초 입력 노드로부터의 거리들에 기초하여, 하나의 레이어 (layer)를 구성할 수 있다. 예를 들어, 최초 입력 노드로부터 거리가 n인 노드들의 집합은, n 레이어를 구성할 수 있다. 최초 입력 노드로부터 거리는, 최초 입력 노드로부터 해당 노드까지 도달하기 위해 거쳐야 하는 링크 들의 최소 개수에 의해 정의될 수 있다. 그러나, 이러한 레이어의 정의는 설명을 위한 임의적인 것으로서, 인공지능 모델 내에서 레이어의 차수는 전술한 것과 상이한 방법으로 정의될 수 있다. 예를 들어, 노드들의 레이어 는 최종 출력 노드로부터 거리에 의해 정의될 수도 있다. 최초 입력 노드는 인공지능 모델 내의 노드들 중 다른 노드들과의 관계에서 링크를 거치지 않고 데이터가 직접 입력되는 하나 이상의 노드들을 의미할 수 있다. 또는, 인공지능 모델 네트워크 내에서, 링크를 기준으로 한 노 드 간의 관계에 있어서, 링크로 연결된 다른 입력 노드들 가지지 않는 노드들을 의미할 수 있다. 이와 유사하게, 최종 출력 노드는 인공지능 모델 내의 노드들 중 다른 노드들과의 관계에서, 출력 노드를 가지지 않 는 하나 이상의 노드들을 의미할 수 있다. 또한, 히든 노드는 최초 입력 노드 및 최후 출력 노드가 아닌 인공지 능 모델을 구성하는 노드들을 의미할 수 있다. 본 발명의 일 실시예에 따른 인공지능 모델은 입력 레이어의 노 드가 출력 레이어에 가까운 히든 레이어의 노드보다 많을 수 있으며, 입력 레이어에서 히든 레이어로 진행됨에 따라 노드의 수가 감소하는 형태의 인공지능 모델일 수 있다. 인공지능 모델은 하나 이상의 히든 레이어를 포함할 수 있다. 히든 레이어의 히든 노드는 이전의 레이어의 출력 과 주변 히든 노드의 출력을 입력으로 할 수 있다. 각 히든 레이어 별 히든 노드의 수는 동일할 수도 있고 상이 할 수도 있다. 입력 레이어의 노드의 수는 입력 데이터의 데이터 필드의 수에 기초하여 결정될 수 있으며 히든 노드의 수와 동일할 수도 있고 상이할 수도 있다. 입력 레이어에 입력된 입력 데이터는 히든 레이어의 히든 노 드에 의하여 연산될 수 있고 출력 레이어인 완전 연결 레이어(FCL: fully connected layer)에 의해 출력될 수 있다. 다양한 실시예에서, 인공지능 모델은, 복수의 음향 데이터와 각 음향 데이터에 대응하는 특징정보를 학습 데이 터로 하여 지도학습(supervised learning)될 수 있다. 그러나, 이에 한정되지 않고, 다양한 학습 방법이 적용될 수 있다. 여기서, 지도학습은 통상적으로 특정 데이터와 특정 데이터에 연관된 정보를 라벨링하여 학습 데이터를 생성하 고, 이를 이용하여 학습시키는 방법으로써, 인과 관계를 가진 두 데이터를 라벨링하여 학습 데이터를 생성하고, 생성된 학습 데이터를 통해 학습하는 방법을 의미한다. 일 실시예에서, 음향 데이터의 인식 정확도를 향상시키기 위한 서버는 하나 이상의 네트워크 함수의 학습 이 사전 결정된 에폭 이상 수행된 경우, 검증 데이터를 이용하여 학습의 중단 여부를 결정할 수 있다. 사전 결 정된 에폭은 전체 학습 목표 에폭의 일부일 수 있다. 검증 데이터는 라벨링된 학습 데이터 중 적어도 일부로 구성될 수 있다. 즉 음향 데이터의 인식 정확도를 향상 시키기 위한 서버는 학습 데이터를 통해 인공지능 모델의 학습을 수행하며, 인공지능 모델의 학습이 사전 결정된 에폭 이상 반복된 후, 검증 데이터를 이용하여 인공지능 모델의 학습 효과가 사전 결정된 수준 이상인지 여부를 판단할 수 있다. 예를 들어, 음향 데이터의 인식 정확도를 향상시키기 위한 서버는 100개의 학습 데이터를 이용하여 목표 반복 학습 횟수가 10회인 학습을 수행하는 경우, 사전결정된 에폭인 10회의 반복 학습 을 수행한 후, 10개의 검증 데이터를 이용하여 3회의 반복 학습을 수행하여, 3회의 반복 학습 동안 인공지능 모 델 출력의 변화가 사전결정된 수준 이하인 경우 더 이상의 학습이 무의미한 것으로 판단하고 학습을 종료할 수 있다. 즉, 검증 데이터는 인공지능 모델의 반복 학습에서 에폭별 학습의 효과가 일정 이상인지 이하인지 여부에 기초 하여 학습의 완료를 결정하는 데 이용될 수 있다. 전술한 학습 데이터, 검증 데이터의 수 및 반복 횟수는 예시 일 뿐이며 본 발명은 이에 제한되지 않는다. 음향 데이터의 인식 정확도를 향상시키기 위한 서버는 테스트 데이터를 이용하여 하나 이상의 네트워크 함 수의 성능을 테스트하여 하나 이상의 네트워크 함수의 활성화 여부를 결정함으로써, 인공지능 모델을 생성할 수 있다. 테스트 데이터는 인공지능 모델의 성능을 검증하기 위하여 사용될 수 있으며, 학습 데이터 중 적어도 일 부로 구성될 수 있다. 예를 들어, 학습 데이터 중 70%는 인공지능 모델의 학습(즉, 레이블과 비슷한 결과값을 출력하도록 가중치를 조정하기 위한 학습)을 위해 활용될 수 있으며, 30%는 인공지능 모델의 성능을 검증하기 위한 테스트 데이터로써 활용될 수 있다. 음향 데이터의 인식 정확도를 향상시키기 위한 서버는 학습이 완 료된 인공지능 모델에 테스트 데이터를 입력하고 오차를 측정하여 사전 결정된 성능 이상인지 여부에 따라 인공 지능 모델의 활성화 여부를 결정할 수 있다. 음향 데이터의 인식 정확도를 향상시키기 위한 서버는 학습이 완료된 인공지능 모델에 테스트 데이터를 이 용하여 학습 완료된 인공지능 모델의 성능을 검증하고 학습 완료된 인공지능 모델의 성능이 사전에 결정된 기준 이상인 경우 해당 인공지능 모델을 다른 어플리케이션에서 사용하도록 활성화할 수 있다. 또한, 음향 데이터의 인식 정확도를 향상시키기 위한 서버는 학습 완료된 인공지능 모델의 성능이 사전에 결정된 기준 이하인 경우 해당 인공지능 모델을 비활성화하여 폐기할 수 있다. 예를 들어, 음향 데이터의 인식 정확도를 향상시키기 위한 서버는 정확도(accuracy), 정밀도(precision), 재현율(recall) 등의 요소를 기 준으로 하여 생성된 인공지능 모델 모델의 성능을 판단할 수 있다. 전술한 성능 평가 기준은 예시일 뿐이며 본 발명은 이에 제한되지 않는다. 음향 데이터의 인식 정확도를 향상시키기 위한 서버는 각각의 인공지능 모 델을 독립적으로 학습시켜 복수의 인공지능 모델 모델을 생성할 수 있으며, 성능을 평가하여 일정 성능 이상의 인공지능 모델만을 사용할 수 있다. 그러나, 이에 한정되지 않는다. 본 명세서에 걸쳐, 연산 모델, 신경망, 네트워크 함수, 뉴럴 네트워크(neural network)는 동일한 의미로 사용될 수 있다. (이하에서는 신경망으로 통일하여 기술한다.) 데이터 구조는 신경망을 포함할 수 있다. 그리고 신경망 을 포함한 데이터 구조는 컴퓨터 판독가능 매체에 저장될 수 있다. 신경망을 포함한 데이터 구조는 또한 신경망 에 입력되는 데이터, 신경망의 가중치, 신경망의 하이퍼 파라미터, 신경망으로부터 획득한 데이터, 신경망의 각 노드 또는 레이어와 연관된 활성 함수, 신경망의 학습을 위한 손실 함수를 포함할 수 있다. 신경망을 포함한 데 이터 구조는 상기 개시된 구성들 중 임의의 구성 요소들을 포함할 수 있다. 즉, 신경망을 포함한 데이터 구조는 신경망에 입력되는 데이터, 신경망의 가중치, 신경망의 하이퍼 파라미터, 신경망으로부터 획득한 데이터, 신경 망의 각 노드 또는 레이어와 연관된 활성 함수, 신경망의 트레이닝을 위한 손실 함수 등 전부 또는 이들의 임의 의 조합을 포함하여 구성될 수 있다. 전술한 구성들 이외에도, 신경망을 포함한 데이터 구조는 신경망의 특성을 결정하는 임의의 다른 정보를 포함할 수 있다. 또한, 데이터 구조는 신경망의 연산 과정에 사용되거나 발생되는 모든 형태의 데이터를 포함할 수 있으며 전술한 사항에 제한되는 것은 아니다. 컴퓨터 판독가능 매체는 컴퓨터 판독가능 기록 매체 및/또는 컴퓨터 판독가능 전송 매체를 포함할 수 있다. 신경망은 일반적으로 노드라 지칭될 수 있는 상호 연결된 계산 단위들의 집합으로 구성될 수 있다. 이러한 노드들은 뉴런(neuron)들로 지칭될 수도 있다. 신경망은 적어도 하나 이상의 노드들을 포함하여 구성된다. 본 발명의 일 실시예에 따르면, 음향 데이터의 인식 정확도를 향상시키기 위한 서버는 클라우드 컴퓨팅 서 비스를 제공하는 서버일 수 있다. 보다 구체적으로, 음향 데이터의 인식 정확도를 향상시키기 위한 서버는 인터넷 기반 컴퓨팅의 일종으로 정보를 사용자의 컴퓨터가 아닌 인터넷에 연결된 다른 컴퓨터로 처리하는 클라 우드 컴퓨팅 서비스를 제공하는 서버일 수 있다. 상기 클라우드 컴퓨팅 서비스는 인터넷 상에 자료를 저장해 두 고, 사용자가 필요한 자료나 프로그램을 자신의 컴퓨터에 설치하지 않고도 인터넷 접속을 통해 언제 어디서나 이용할 수 있는 서비스일 수 있으며, 인터넷 상에 저장된 자료들을 간단한 조작 및 클릭으로 쉽게 공유하고 전 달할 수 있다. 또한, 클라우드 컴퓨팅 서비스는 인터넷 상의 서버에 단순히 자료를 저장하는 것뿐만 아니라, 별 도로 프로그램을 설치하지 않아도 웹에서 제공하는 응용프로그램의 기능을 이용하여 원하는 작업을 수행할 수 있으며, 여러 사람이 동시에 문서를 공유하면서 작업을 진행할 수 있는 서비스일 수 있다. 또한, 클라우드 컴퓨 팅 서비스는 IaaS(Infrastructure as a Service), PaaS(Platform as a Service), SaaS(Software as a Service), 가상 머신 기반 클라우드 서버 및 컨테이너 기반 클라우드 서버 중 적어도 하나의 형태로 구현될 수 있다. 즉, 본 발명의 음향 데이터의 인식 정확도를 향상시키기 위한 서버는 상술한 클라우드 컴퓨팅 서비 스 중 적어도 하나의 형태로 구현될 수 있다. 전술한 클라우드 컴퓨팅 서비스의 구체적인 기재는 예시일 뿐, 본 발명은 클라우드 컴퓨팅 환경을 구축하는 임의의 플랫폼을 포함할 수도 있다. 다양한 실시예에서, 음향 데이터의 인식 정확도를 향상시키기 위한 서버는 네트워크를 통해 사용자 단말 과 연결될 수 있고, 음향 데이터를 분석하는 음향 인식 모델을 생성하여 제공할 수 있으며, 뿐만 아니라, 음향 인식 모델을 통해 음향 데이터를 분석한 정보(예컨대, 음향 인식 결과 정보)를 사용자 단말로 제공수 있다. 여기서, 네트워크는 복수의 단말 및 서버들과 같은 각각의 노드 상호 간에 정보 교환이 가능한 연결 구조를 의 미할 수 있다. 예를 들어, 네트워크는 근거리 통신망(LAN: Local Area Network), 광역 통신망(WAN: Wide Area Network), 인터넷(WWW: World Wide Web), 유무선 데이터 통신망, 전화망, 유무선 텔레비전 통신망 등을 포함한 다. 또한, 여기서, 무선 데이터 통신망은 3G, 4G, 5G, 3GPP(3rd Generation Partnership Project), 5GPP(5th Generation Partnership Project), LTE(Long Term Evolution), WIMAX(World Interoperability for Microwave Access), 와이파이(Wi-Fi), 인터넷(Internet), LAN(Local Area Network), Wireless LAN(Wireless Local Area Network), WAN(Wide Area Network), PAN(Personal Area Network), RF(Radio Frequency), 블루투스(Bluetooth) 네트워크, NFC(Near-Field Communication) 네트워크, 위성 방송 네트워크, 아날로그 방송 네트워크,DMB(Digital Multimedia Broadcasting) 네트워크 등이 포함되나 이에 한정되지는 않는다. 일 실시예에서, 사용자 단말은 네트워크를 통해 음향 데이터의 인식 정확도를 향상시키기 위한 서버 와 연결될 수 있으며, 음향 데이터의 인식 정확도를 향상시키기 위한 서버로 음향 데이터를 제공할 수 있 고, 제공된 음향 데이터에 대한 응답으로 각종 이벤트 발생에 관한 음향 인식 결과 정보(예를 들어, 총 소리, 경보 소리, 아이의 울음 소리, 유리 깨지는 소리, 타이어 펑크 나는 소리 등의 발생)를 제공받을 수 있다. 여기서, 사용자 단말은 휴대성과 이동성이 보장되는 무선 통신 장치로서, 네비게이션, PCS(Personal Communication System), GSM(Global System for Mobile communications), PDC(Personal Digital Cellular), PHS(Personal Handyphone System), PDA(Personal Digital Assistant), IMT(International Mobile Telecommunication)-2000, CDMA(Code Division Multiple Access)-2000, W-CDMA(W-Code Division Multiple Access), Wibro(Wireless Broadband Internet) 단말, 스마트폰(Smartphone), 스마트 패드(Smartpad), 타블렛 PC(Tablet PC) 등과 같은 모든 종류의 핸드헬드(Handheld) 기반의 무선 통신 장치를 포함할 수 있으나, 이에 한 정되지 않는다. 예컨대, 사용자 단말은, 특정 영역에 관련한 감지를 수행하기 위하여 특정 영역에 구비될 수 있다. 예를 들어, 사용자 단말은 차량에 구비되어 차량이 주차 중 또는 주행 중 발생하는 음향 데이터 를 획득할 수 있다. 다른 예를 들어, 사용자 단말은 어린이들이 위치한 영역(예컨대, 놀이터, 또는 시설 내 공간)에 대응하여 위급 상황 감지를 위하여 구비될 수도 있다. 전술한 사용자 단말이 구비되는 구체적인 위 치 또는 장소에 관한 설명은 예시일 뿐, 본 발명은 이에 제한되지 않는다. 일 실시예에서, 외부 서버는 네트워크를 통해 음향 데이터의 인식 정확도를 향상시키기 위한 서버와 연결될 수 있으며, 음향 데이터의 인식 정확도를 향상시키기 위한 서버가 인공지능 모델을 활용하여 음향 데이터를 분석하기 위해 필요한 각종 정보/데이터를 제공하거나, 인공지능 모델을 활용한 음향 데이터 분석을 수행함에 따라 도출되는 결과 데이터를 제공받아 저장 및 관리할 수 있다. 예를 들어, 외부 서버는 음향 데이터의 인식 정확도를 향상시키기 위한 서버의 외부에 별도로 구비되는 저장 서버일 수 있으나, 이에 한 정되지 않는다. 이하 도 2를 참조하여 음향 데이터의 인식 정확도를 향상시키기 위한 서버의 하드웨어 구 성에 대해 설명하도록 한다. 도 2는 본 발명의 일 실시예와 관련된 음향 데이터의 인식 정확도를 향상시키기 위한 서버의 하드웨어 구성도이 다. 도 2를 참조하면, 본 발명의 일 실시예에 따른 음향 데이터의 인식 정확도를 향상시키기 위한 서버(이하, “서버”)는 하나 이상의 프로세서, 프로세서에 의하여 수행되는 컴퓨터 프로그램을 로드 (Load)하는 메모리, 버스, 통신 인터페이스 및 컴퓨터 프로그램을 저장하는 스토리지(15 0)를 포함할 수 있다. 여기서, 도 2에는 본 발명의 실시예와 관련 있는 구성요소들만 도시되어 있다. 따라서,"}
{"patent_id": "10-2023-0105562", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "본 발명이 속한 기술분야의 통상의 기술자라면 도 2에 도시된 구성요소들 외에 다른 범용적인 구성 요소들이 더 포함될 수 있음을 알 수 있다. 프로세서는 서버의 각 구성의 전반적인 동작을 제어한다. 프로세서는 CPU(Central Processing Unit), MPU(Micro Processor Unit), MCU(Micro Controller Unit), GPU(Graphic Processing Unit) 또는 본 발 명의 기술 분야에 잘 알려진 임의의 형태의 프로세서를 포함하여 구성될 수 있다. 프로세서는 메모리에 저장된 컴퓨터 프로그램을 판독하여 본 발명의 일 실시예에 따른 인공지능 모델 을 위한 데이터 처리를 수행할 수 있다. 본 발명의 일 실시예에 따라 프로세서는 신경망의 학습을 위한 연 산을 수행할 수 있다. 프로세서는 딥러닝(DL: deep learning)에서 학습을 위한 입력 데이터의 처리, 입력 데이터에서의 피처 추출, 오차 계산, 역전파(backpropagation)를 이용한 신경망의 가중치 업데이트 등의 신경망 의 학습을 위한 계산을 수행할 수 있다. 또한, 프로세서는 CPU, GPGPU, 및 TPU 중 적어도 하나가 네트워크 함수의 학습을 처리할 수 있다. 예를 들 어, CPU 와 GPGPU가 함께 네트워크 함수의 학습, 네트워크 함수를 이용한 데이터 분류를 처리할 수 있다. 또한, 본 발명의 일 실시예에서 복수의 컴퓨팅 장치의 프로세서를 함께 사용하여 네트워크 함수의 학습, 네트워크 함 수를 이용한 데이터 분류를 처리할 수 있다. 또한, 본 발명의 일 실시예에 따른 컴퓨팅 장치에서 수행되는 컴퓨 터 프로그램은 CPU, GPGPU 또는 TPU 실행가능 프로그램일 수 있다. 본 명세서에서 네트워크 함수는 인공 신경망, 뉴럴 네트워크와 상호 교환 가능하게 사용될 수 있다. 본 명세서 에서 네트워크 함수는 하나 이상의 뉴럴 네트워크를 포함할 수도 있으며, 이 경우 네트워크 함수의 출력은 하나이상의 뉴럴 네트워크의 출력의 앙상블(ensemble)일 수 있다. 프로세서는 메모리에 저장된 컴퓨터 프로그램을 판독하여 본 발명의 일 실시예에 따른 음향 인식 모 델을 제공할 수 있다. 본 발명의 일 실시예에 따라, 프로세서는 음향 인식 모델을 학습시키기 위한 계산을 수행할 수 있다. 본 발명의 일 실시예에 따르면, 프로세서는 통상적으로 서버의 전반적인 동작을 처리할 수 있다. 프 로세서는 위에서 살펴본 구성요소들을 통해 입력 또는 출력되는 신호, 데이터, 정보 등을 처리하거나 메모 리에 저장된 응용 프로그램을 구동함으로써, 사용자 또는 사용자 단말에게 적정한 정보 또는, 기능을 제공 하거나 처리할 수 있다. 또한, 프로세서는 본 발명의 실시예들에 따른 방법을 실행하기 위한 적어도 하나의 애플리케이션 또는 프 로그램에 대한 연산을 수행할 수 있으며, 서버는 하나 이상의 프로세서를 구비할 수 있다. 다양한 실시예에서, 프로세서는 프로세서 내부에서 처리되는 신호(또는, 데이터)를 일시적 및/또는 영구적으로 저장하는 램(RAM: Random Access Memory, 미도시) 및 롬(ROM: Read-Only Memory, 미도시)을 더 포 함할 수 있다. 또한, 프로세서는 그래픽 처리부, 램 및 롬 중 적어도 하나를 포함하는 시스템온칩(SoC: system on chip) 형태로 구현될 수 있다. 메모리는 각종 데이터, 명령 및/또는 정보를 저장한다. 메모리는 본 발명의 다양한 실시예에 따른 방 법/동작을 실행하기 위하여 스토리지로부터 컴퓨터 프로그램을 로드할 수 있다. 메모리에 컴퓨 터 프로그램이 로드되면, 프로세서는 컴퓨터 프로그램을 구성하는 하나 이상의 인스트럭션들을 실행함으로써 상기 방법/동작을 수행할 수 있다. 메모리는 RAM과 같은 휘발성 메모리로 구현될 수 있을 것 이나, 본 발명의 기술적 범위가 이에 한정되는 것은 아니다. 버스는 서버의 구성 요소 간 통신 기능을 제공한다. 버스는 주소 버스(address Bus), 데이터 버 스(Data Bus) 및 제어 버스(Control Bus) 등 다양한 형태의 버스로 구현될 수 있다. 통신 인터페이스는 서버의 유무선 인터넷 통신을 지원한다. 또한, 통신 인터페이스는 인터넷 통 신 외의 다양한 통신 방식을 지원할 수도 있다. 이를 위해, 통신 인터페이스는 본 발명의 기술 분야에 잘 알려진 통신 모듈을 포함하여 구성될 수 있다. 몇몇 실시예에서, 통신 인터페이스는 생략될 수도 있다. 스토리지는 컴퓨터 프로그램을 비 임시적으로 저장할 수 있다. 서버를 통해 음향 데이터의 인식 정확도를 향상시키기 위한 프로세스를 수행하는 경우, 스토리지는 음향 데이터의 인식 정확도를 향상시키 기 위한 프로세스를 제공하기 위하여 필요한 각종 정보를 저장할 수 있다. 스토리지는 ROM(Read Only Memory), EPROM(Erasable Programmable ROM), EEPROM(Electrically Erasable Programmable ROM), 플래시 메모리 등과 같은 비휘발성 메모리, 하드 디스크, 착탈형 디스크, 또는 본 발명이 속하는 기술 분야에서 잘 알려진 임의의 형태의 컴퓨터로 읽을 수 있는 기록 매체를 포함하여 구성될 수 있다. 컴퓨터 프로그램은 메모리에 로드될 때 프로세서로 하여금 본 발명의 다양한 실시예에 따른 방 법/동작을 수행하도록 하는 하나 이상의 인스트럭션들을 포함할 수 있다. 즉, 프로세서는 상기 하나 이상 의 인스트럭션들을 실행함으로써, 본 발명의 다양한 실시예에 따른 상기 방법/동작을 수행할 수 있다. 일 실시예에서, 컴퓨터 프로그램은 음향 데이터를 획득하는 단계, 음향 데이터를 분할하여 복수 개의 음향 서브 데이터를 생성하는 단계 및 복수 개의 음향 서브 데이터를 음향 인식 모델의 입력으로 처리하여 각 음향 서브 데이터에 대응하는 음향 인식 결과 정보를 생성하는 단계를 포함하는 향상된 신뢰도를 가진 음향 인식 결 과 제공 방법을 수행하도록 하는 하나 이상의 인스트럭션을 포함할 수 있다. 본 발명의 실시예와 관련하여 설명된 방법 또는 알고리즘의 단계들은 하드웨어로 직접 구현되거나, 하드웨어에 의해 실행되는 소프트웨어 모듈로 구현되거나, 또는 이들의 결합에 의해 구현될 수 있다. 소프트웨어 모듈은 RAM(Random Access Memory), ROM(Read Only Memory), EPROM(Erasable Programmable ROM), EEPROM(Electrically Erasable Programmable ROM), 플래시 메모리(Flash Memory), 하드 디스크, 착탈형 디스크, CD-ROM, 또는 본 발명이 속하는 기술 분야에서 잘 알려진 임의의 형태의 컴퓨터 판독가능 기록매체에 상주할 수도 있다. 본 발명의 구성 요소들은 하드웨어인 컴퓨터와 결합되어 실행되기 위해 프로그램(또는 애플리케이션)으로 구현 되어 매체에 저장될 수 있다. 본 발명의 구성 요소들은 소프트웨어 프로그래밍 또는 소프트웨어 요소들로 실행될 수 있으며, 이와 유사하게, 실시 예는 데이터 구조, 프로세스들, 루틴들 또는 다른 프로그래밍 구성들의 조 합으로 구현되는 다양한 알고리즘을 포함하여, C, C++, 자바(Java), 어셈블러(assembler) 등과 같은 프로그래밍 또는 스크립팅 언어로 구현될 수 있다. 기능적인 측면들은 하나 이상의 프로세서들에서 실행되는 알고리즘으로 구현될 수 있다. 이하, 도 3 내지 도 12를 참조하여, 서버에 의해 수행되는 향상된 신뢰도를 가진 음향 인 식 결과 제공 방법에 대해 설명하도록 한다. 도 3은 본 발명의 일 실시예와 관련된 향상된 신뢰도를 가진 음향 인식 결과 제공 방법을 예시적으로 나타낸 순 서도이다. 도 3에 도시된 단계들은 필요에 의해 순서가 변경될 수 있으며, 적어도 하나 이상의 단계가 생략 또 는 추가될 수 있다. 즉, 이하의 단계들은 본 발명의 일 실시예에 불과할 뿐, 본 발명의 권리 범위는 이에 제한 되지 않는다. 본 발명의 일 실시예에 따르면, 향상된 신뢰도를 가진 음향 인식 결과 제공 방법은 음향 데이터를 획득하는 단 계(S100)를 포함할 수 있다. 서버는 음향 데이터를 획득할 수 있다. 음향 데이터는 실생활에서 획 득되는 음향에 관련한 정보를 포함할 수 있다. 본 발명의 일 실시예에 따른 음향 데이터의 획득은, 메모리(12 0)에 저장된 음향 데이터를 수신하거나 또는 로딩(loading)하는 것일 수 있다. 또한, 음향 데이터의 획득은, 유/무선 통신 수단에 기초하여 다른 저장 매체, 다른 컴퓨팅 장치, 동일한 컴퓨팅 장치 내의 별도 처리 모듈로부터 데이터를 수신하거나 또는 로딩하는 것일 수 있다. 일 실시예에 따르면, 음향 데이터는 사용자에 관련한 사용자 단말을 통해 획득될 수 있다. 예를 들어, 사용자에 관련한 사용자 단말은, 스마트폰(Smartphone), 스마트 패드(Smartpad), 타블렛PC(Tablet PC) 등 과 같은 모든 종류의 핸드헬드(Handheld) 기반의 무선 통신 장치 또는 특정 공간(예컨대, 사용자의 주거 공간) 상에 구비된 전자 장치(예컨대, 마이크를 통해 음향 데이터를 수신할 수 있는 장치) 등을 포함할 수 있다. 본 발명의 일 실시예에 따르면, 향상된 신뢰도를 가진 음향 인식 결과 제공 방법은, 음향 데이터를 분할하여 복 수 개의 음향 서브 데이터를 생성하는 단계(S200)를 포함할 수 있다. 실시예에서, 복수 개의 음향 서브 데이터를 생성하는 단계는, 음향 데이터를 기 설정된 크기 단위로 분할하여 복수 개의 음향 서브 데이터를 생성하는 단계를 포함할 수 있다. 서버는 음향 데이터를 일정 시간 단위로 분할하여 복수 개의 음향 서브 데이터를 생성할 수 있다. 복 수의 음향 서브 데이터는, 시계열 정보인 음향 데이터를 특정 시간 단위에 기초하여 복수의 프레임으로 분할한 것일 수 있다. 구체적으로, 서버는 음향 데이터를 미리 정해진 제1시간 단위의 크기를 갖도록 분할하여 복 수 개의 음향 서브 데이터를 구성할 수 있다. 음향(또는 소리)의 경우, 지속적으로 발생하는 시계열 데이터이기 때문에 일정 시간 구간으로 분할하여 각 구간 별로 인식이 수행되어야 한다. 예를 들어, 제1음향 데이터가 1분이라는 시간에 대응하여 획득된 음향 데이터인 경우, 서버는, 제1시간 단 위를 1초로 설정하여 제1음향 데이터를 분할하여 60개의 음향 서브 데이터(또는, 음향 서브 프레임)를 구성할 수 있다. 전술한 제1시간 단위 및 하나 이상의 음향 서브 데이터에 관련한 구체적인 수치적 기재는 예시일 뿐, 본 발명은 이에 제한되지 않는다. 실시예에서, 음향 데이터를 복수 개의 음향 서브 데이터로 분할하는 과정에서, 작은 시간 단위로 분할할수록 신경망(즉, 음향 인식 모델)의 계산량이 줄어들어 성능이 향상된다는 장점이 있다. 입력에 해당하는 음향 서브 데이터의 길이가 짧아짐에 따라 계산량이 현저하게 줄어드는 경우, 음 향 인식 모델은 짧은 구간 인식 모델로써 활용이 가능해짐에 따라, Edge SDK로 활용될 수 있다. 즉, 음향 데이 터를 복수 개의 짧은 구간으로 분할함에 따라, 음향 인식 모델이 서버 자체에서 실행가능한 하나의 응용 프로그 램을 통해 구동될 수 있다. 실시예에서, 특정 음향의 경우, 짧은 구간 인식을 수행하는 음향 인식 모델을 통해 향상된 신뢰도를 가진 음향 인식 결과 정보를 도출하기 어려울 수 있다. 예컨대, 지속성(duration)이 짧은 소리의 경우, 특정 구간만을 참 고하여서는 해당 음향을 정확하게 인식해내기 어렵다는 우려가 있다. 보다 구체적인 예를 들어, 도 4의 (a)를 참조하면, 짧은 지속성을 갖는 총소리에 관련한 제1음향 데이터(10a)의 경우, 1초 단위로 분할되어 제1음향 서브 데이터(11a) 내지 제8음향 서브 데이터(18a)로 구분될 수 있다. 이 경 우, 제3음향 서브 데이터(13a)에서 발생하는 총소리는, 해당 제3음향 서브 데이터(13a)에 대응하는 구간 내에 온전히 포함됨에 따라, 하나의 구간(즉, 제3음향 서브 데이터(13a))를 고려하더라도 정확한 인식이 가능할 수 있다.한편, 도 4의 (b)를 참조하면, 짧은 지속성을 갖는 총소리에 관련한 제2음향 데이터(10b) 또한, 동일하게 1초 단위로 분할되어 제1음향 서브 데이터(11b) 내지 제8음향 서브 데이터(18b)로 구분될 수 있다. 이 경우, 총소리 는, 도 4의 (b)에 도시된 바와 같이, 제2음향 서브 데이터(12b)와 제3음향 서브 데이터(13b)를 걸쳐져 있을 수 있다. 음향 데이터는 시계열적으로 획득되는 데이터이며, 일정 크기를 통해 분할되는 것임에 따라, 전술한 바와 같이, 총소리의 폭발음과 에코가 서로 다른 구간에 존재할 수 있다. 이 경우, 음향 인식 모델을 통해 제2음향 서브 데이터(12b) 및 제3음향 서브 데이터(13b) 각각을 인식하는 경우, 온전한 총소리를 모두 포함하는 것이 아 니기 때문에, 정확한 인식이 불가능할 수 있으며, 이에 따라, 출력의 정확도(즉, 인식 정확도)가 저하될 수 있 다. 즉, 지속성의 짧은 음향이 서로 다른 구간으로 분할됨에 따라 음향 인식의 정확도가 저하될 수 있다. 이를 극복 하기 위하여 음향을 분할하는 시간 단위를 크게(예컨대, 2초) 가져갈 수 있으나, 이러한 경우에는 음향 인식 모 델의 계산량이 늘어나게되어 저가 디바이스에 활용이 불가능하며, 효율적이지 못하다는 문제점이 있다. 이에 따라, 본 발명의 서버는 별도의 신경망 모델을 추가적으로 구성하여 인식 정확도가 결여되는 상황에 서 재차 음향 인식을 수행할 수 있다. 즉, 복수 개의 신경망 모델을 활용하여 복수 회 추가적인 음향 인식 결과 를 도출하여 재검증을 수행함으로써, 최종 도출되는 음향 인식 결과의 신뢰성 향상을 도모할 수 있다. 특히, 단 순히 복수의 신경망 모델을 복수 회 활용하는 것이 아닌, 인식 정확도가 다소 결여될 것으로 예측된 특정 상황 에 대응하여 추가적인 검증을 수행함으로써, 계산량을 효과적으로 줄이면서도 인식 결과의 신뢰도를 향상시킬 수 있다. 복수의 신경망 모델을 활용하여 재검증을 수행함으로써, 인식 정확도를 향상시키는 구성에 대한 설명 은 도 5를 참조하여 이하에서 자세히 후술하도록 한다. 도 5는 본 발명의 일 실시예와 관련된 복수의 인공지능 모델을 활용한 재검증을 통해 음향 인식 결과 정보를 생 성하는 과정을 예시적으로 나타낸 순서도이다. 도 5에 도시된 단계들은 필요에 의해 순서가 변경될 수 있으며, 적어도 하나 이상의 단계가 생략 또는 추가될 수 있다. 즉, 이하의 단계들은 본 발명의 일 실시예에 불과할 뿐, 본 발명의 권리 범위는 이에 제한되지 않는다. 일 실시예에 따르면, 음향 인식 결과 정보를 생성하는 단계는, 제1인식 모델이 각 음향 서브 데이터에 대 응하여 출력한 음향 인식 결과 정보들을 기반으로 음향 서브 데이터의 재검증이 필요한 재검증 음향 서브 데이 터를 선별하는 단계(S311)를 포함할 수 있다. 실시예에 따르면, 본 발명의 음향 인식 모델은 복수 개의 음향 서브 데이터 각각을 입력으로 하여 각 음향 서브 데이터에 대응하는 복수 개의 출력을 제공하는 제1인식 모델을 포함할 수 있다. 일 실시예에 따르면, 서버는 오토인코더를 비지도학습(Unsupervised Learning) 방식을 통해 학습시킬 수 있다. 구체적으로, 서버는 입력 데이터와 유사한 출력 데이터를 출력하도록 오토인코더를 구성하는 차원 감소 네트워크 함수(예컨대, 인코더) 및 차원 복원 네트워크 함수(예컨대, 디코더)를 학습시킬 수 있다. 자세히 설명하면, 차원 감소 네트워크 함수를 통해 인코딩 과정에서 입력된 음향 데이터의 핵심 특징 데이터(또는, 피 처(feature))만을 히든 레이어를 통해 학습하고 나머지 정보를 손실시킬 수 있다. 이 경우, 차원 복원 네트워크 함수를 통한 디코딩 과정에서 히든 레이어의 출력 데이터는 완벽한 복사 값이 아닌 입력 데이터(즉, 음향 데이 터)의 근사치일 수 있다. 즉, 서버는 출력 데이터와 입력 데이터가 최대한 같아지도록 가중치를 조정함으 로써, 오토인코더를 학습시킬 수 있다. 오토인코더는 입력 데이터와 유사한 출력 데이터를 출력하기 위한 신경망의 일종일 수 있다. 오토 인코더는 적 어도 하나의 히든 레이어를 포함할 수 있으며, 홀수 개의 히든 레이어가 입출력 레이어 사이에 배치될 수 있다. 각각의 레이어의 노드의 수는 입력 레이어의 노드의 수에서 병목 레이어(인코딩)라는 중간 레이어로 축소되었다 가, 병목 레이어에서 출력 레이어(입력 레이어와 대칭)로 축소와 대칭되어 확장될 수도 있다. 입력 레이어 및 출력 레이어의 수는 입력 데이터의 전처리 이후에 남은 입력 데이터의 항목들의의 수와 대응될 수 있다. 오토 인코더 구조에서 인코더에 포함된 히든 레이어의 노드의 수는 입력 레이어에서 멀어질수록 감소하는 구조를 가 질 수 있다. 병목 레이어(인코더와 디코더 사이에 위치하는 가장 적은 노드를 가진 레이어)의 노드의 수는 너무 작은 경우 충분한 양의 정보가 전달되지 않을 수 있으므로, 특정 수 이상(예를 들어, 입력 레이어의 절반 이상 등)으로 유지될 수도 있다. 서버는 객체 정보가 각각 태깅된 복수의 학습 데이터를 포함하는 학습 데이터 세트를 학습된 차원 감소 네 트워크의 입력으로 하여 출력된 객체 별 특징 데이터를 태깅된 객체 정보와 매칭하여 저장할 수 있다. 구체적으 로, 서버는 차원 감소 네트워크 함수를 이용하여 제1음향 식별 정보(예컨대, 유리 깨지는 소리)가 태깅된제1학습 데이터 서브 세트를 차원 감소 네트워크 함수의 입력으로 하여, 제1학습 데이터 서브 세트에 포함된 학 습 데이터들에 대한 제1객체의 특징(feature) 데이터를 획득할 수 있다. 획득된 특징 데이터는 벡터로 표현될 수 있다. 이 경우, 제1학습 데이터 서브 세트에 포함된 복수의 학습 데이터 각각에 대응하여 출력된 특징 데이 터들은 제1음향에 관련한 학습 데이터를 통한 출력이므로 벡터 공간 상에서 비교적 가까운 거리에 위치할 수 있 다. 서버는 벡터로 표현된 제1음향에 관련한 특징 데이터들에 제1음향 식별 정보(즉, 유리 깨지는 소리)를 매칭하여 저장할 수 있다. 학습된 오토인코더의 차원 감소 네트워크 함수의 경우, 차원 복원 네트워크 함수가 입력 데이터를 잘 복원할 수 있도록 하는 특징을 잘 추출하도록 학습될 수 있다. 또한 예를 들어, 제2음향 식별 정보(예컨대, 사이렌 소리)가 태깅된 제1학습 데이터 서브 세트 각각에 포함된 복수의 학습 데이터들은 차원 감소 네트워크 함수를 통해 특징 데이터(즉, 피처)들로 변환되어 벡터 공간 상에 표시될 수 있다. 이 경우, 해당 특징 데이터들은 제2음향 식별 정보(즉, 사이렌 소리)에 관련한 학습 데이터를 통한 출력이므로, 벡터 공간 상에서 비교적 가까운 거리에 위치할 수 있다. 이 경우, 제2음향 식별 정보에 대응 하는 특징 데이터들은 제1음향 식별 정보(예컨대, 유리 깨지는 소리)에 대응하는 특징 데이터들과 상이한 벡터 공간 상에 표시될 수 있다. 실시예에서, 서버는 학습된 오토인코더에서 차원 감소 네트워크 함수를 포함하여 음향 인식 모델을 구성할 수 있다. 즉, 상기와 같은 학습 과정을 통해 생성된 차원 감소 네트워크 함수를 포함하여 구성된 음향 인식 모 델은 음향 서브 데이터를 입력으로 하는 경우, 해당 음향 서브 데이터를 차원 감소 네트워크 함수를 활용한 연 산을 통해 음향 서브 데이터에 대응하는 특징정보(즉, 피처)를 추출할 수 있다. 이 경우, 음향 인식 모델은 음향 서브 데이터에 대응하는 피처가 표시된 영역과 객체 별 특징 데이터의 벡터 공 간 상의 거리 비교를 통해 음향 스타일의 유사성을 평가할 수 있으며, 해당 유사성 평가에 기반하여 음향 서브 데이터에 대응하는 음향 인식 결과 정보를 출력할 수 있다. 일 실시예에서, 음향 인식 결과 정보는, 복수의 인 식 항목 및 복수의 인식 항목 각각에 대응하는 확률값을 포함할 수 있다. 구체적으로, 음향 인식 모델(또는 제1인식 모델)은 음향 서브 데이터를 차원 감소 네트워크 함수를 이용하여 연 산함으로써, 특징정보(즉, 피처)를 출력할 수 있다. 이 경우, 음향 인식 모델은, 음향 서브 데이터에 대응하여 출력된 특징정보와 학습을 통해 벡터 공간 상에 사전 기록된 음향 식별 정보 별 특징 데이터들 간의 위치에 기 반하여 음향 서브 데이터에 대응하는 복수의 인식 항목 및 각 인식 항목에 대응하는 확률값을 출력할 수 있다. 복수의 인식 항목은, 음향이 어떠한 항목에 관련한 것인지를 식별하기 위한 것으로, 예컨대, 총 소리, 폭죽 소 리, 비명 소리, 타이어 터지는 소리, 사이렌 소리, 강아지가 짖는 소리, 비가 내리는 소리 등을 포함할 수 있으 나, 이에 제한되지 않는다. 이러한 복수의 인식 항목은, 음향 서브 데이터에 대응하여 출력된 특징정보와 벡터 공간 상의 위치가 가까운 음향 식별 정보들에 기초하여 생성될 수 있다. 예컨대, 음향 인식 모델은 제1음향 서 브 데이터에 대응하여 출력된 제1특징 정보와 근접한 위치에 있는 특징정보들에 매칭된 음향 식별 정보를 통해 복수의 인식 항목을 구성할 수 있다. 전술한 복수의 인식 항목에 관련한 구체적인 기재는 예시일 뿐, 본 발명은 이에 제한되지 않는다. 각 인식 항목에 대응하는 확률값은, 인식 항목 각각에 대응하여 예측한 정확도에 관한 정보일 수 있다. 예컨대, 음향 인식 모델은 제1음향 서브 데이터에 대응하여 출력된 제1특징 정보와 근접한 위치에 있는 특징정보들에 매 칭된 음향 식별 정보를 통해 복수의 인식 항목 정보를 구성할 수 있다. 이 경우, 제1특징 정보가 각 음향 식별 정보에 대응하는 특징정보들과 위치가 가까울수록 높은 확률값이 산출될 수 있으며, 제1특징 정보와 각 음향 식 별 정보에 대응하는 특징정보들의 위치가 멀수록 낮은 확률값이 산출될 수 있다. 구체적인 예를 드어, 도 6에 도시된 바와 같이, 음향 인식 모델(또는, 제1인식 모델)은 제1음향 서브 데이터에 대응하여 '사이렌 소리', '비명 소리', '유리 깨지는 소리' 및 '그외 소리'에 관련한다는 복수의 인식 항목 을 출력할 수 있다. 또한, 음향 인식 모델은 각 인식 항목에 대응하여 '1', '95', '3' 및 '2'라는 확 률값을 출력할 수 있다. 즉, 음향 인식 모델은 제1음향 서브 데이터에 대응하여 사이렌 소리에 관련될 확 률이 '1'이며, 비명 소리에 관련될 확률이 '95'이며, 유리 깨지는 소리에 관련될 확률이 '3'이고, 그리고 그외 소리에 관련될 확률이 '2'라는 확률값을 출력할 수 있다. 전술한 인식 항목 및 확률값 각각에 대한 구체적 인 수치에 대한 기재는 예시일 뿐, 본 발명은 이에 제한되지 않는다. 즉, 서버는 음향 인식 모델을 통해 음향 데이터에 기초하여 생성된 복수의 음향 서브 데이터 각각에 대응 하는 인식 항목들 및 각 인식 항목들에 대응하는 확률값을 출력할 수 있다. 예를 들어, 음향 인식 모델은 제1음향 서브 데이터에 대응하여 제1인식 항목들 및 제1인식 항목들 각각에 대응하는 확률값을 출력할 수 있으며, 제 2음향 서브 데이터에 대응하여 제2인식 항목들 및 제2인식 항목들 각각에 대응하는 확률값을 출력할 수 있다. 일 실시예에 따르면, 제1인식 모델은 각 인식 항목 별 확률값을 산출하고, 산출된 확률값 중 최대값에 해 당하는 확률값에 대응하는 인식 항목을 기반으로 음향 인식 결과 정보를 생성하는 것을 특징으로 할 수 있다. 예를 들어, 도 6을 참조하면, 최대 확률값 95%에 대응하는 인식 항목을 통해, 음향 서브 데이터의 인식 결과가 scream이라는 음향 인식 결과 정보가 생성되게 된다. 또한 실시예에서, 제1인식 모델은 각 인식 항목 별 확률값을 산출하고, 산출된 확률값이 각 인식 항목에 사전 설정된 임계 확률값을 초과하는지 여부에 따라 음향 인식 결과 정보를 생성하는 것을 특징으로 할 수도 있 다. 다양한 실시예에 따르면, 본 발명의 음향 인식 모델은 복수 개로 구비될 수 있다. 음향 인식 모델은 제1인식 모 델 및 제2인식 모델을 포함할 수 있다. 이 경우, 제2인식 모델은, 입력에 활용되는 음향 서브 데이터의 구간의 길이가 제1인식 모델과 상이한 모델일 수 있다. 제2인식 모델은 제1인식 모델 보다 높은 성능을 가진 신경망 모델일 수 있다. 예를 들어, 제1인식 모델은 1초의 구간의 음향 서브 데이 터를 기반으로 음향 인식 결과를 도출하도록 학습된 신경망 모델이며, 제2인식 모델은 2초의 구간의 음향 서브 데이터를 기반으로 음향 인식 결과를 도출하는 신경망 모델일 수 있다. 즉, 제1인식 모델 및 제2인식 모델은 서로 상이한 성능을 가진 신경망 모델들이며, 재검증에는 보다 성능이 좋은 제2인식 모델이 활용되게 된다. 실시예에서, 제1인식 모델은 비교적 짧은 구간의 음향 서브 데이터를 인식하여 결과를 출 력하는 신경망 모델일 수 있으며, 제2인식 모델은 비교적 긴 구간의 음향 서브 데이터를 인식하여 결과를 출력하는 신경망 모델일 수 있다. 제1인식 모델의 경우, 짧은 구간의 음향을 분석하기 때문에, 계산량이 적으며, 이에 따른 컴퓨팅 파워의 소모가 적다는 장점이 있다. 반면, 제2인식 모델의 경우, 비교적 긴 구간의 음향을 분석하기 때문에, 계산 량이 보다 증가하여 저가 디바이스에서 응용 프로그램으로 설치되어 활용되기 어렵다는 단점이 있으나, 인식하 는 구간이 길기 때문에, 출력의 정확도가 높다는 장점이 있다. 다양한 실시예에서, 서버는 제1인식 모델에 대응하는 출력 결과 즉 음향 인식 결과 정보에 기초하여 다른 신경망 모델(예컨대, 제2인식 모델)을 활용하여 재검증을 수행할지 여부를 결정할 수 있다. 이는, 평상 시 에는, 가벼운 제1인식 모델을 활용하나, 출력 정확도가 결여되는 경우에만 추가적인 신경망 모델이 활용되 도록 함으로써, 계산량 및 활용되는 컴퓨팅 파워를 저감시키기 위함이다. 서버는 제1인식 모델이 각 음향 서브 데이터에 대응하여 출력한 음향 인식 결과 정보들을 기반으로 음향 서브 데이터의 재검증이 필요한 재검증 음향 서브 데이터를 선별할 수 있다. 서버는 음향 인식 결과 정보가 사전에 분류된 항목(예컨대, 재검증이 필요한 항목)에 관련한지 또는, 음향 인식 결과 정보의 정확도가 모호하다고 판단한 경우에 대응하여 재검증을 수행할 수 있으며, 재검증을 수행 대상이 되는 음향 서브 데이터 를 선별할 수 있다. 구체적인 실시예에서, 서버는 제1인식 모델을 통해 산출된 각 인식 항목 간의 유사도 점수를 산출하 고, 산출된 유사도 점수를 기반으로 재검증 음향 서브 데이터를 선별할 수 있다. 예를 들어, 제1인식 모델은, 특정 음향 서브 데이터에 대응하여 '총소리', '풍선 터지는소리' 및 '불꽃놀이 소 리'라는 인식 항목들을 출력할 수 있으며, 각 인식 항목들의 확률값을 85%, 90% 및 94%로 산출할 수 있다. 이 경우, 가장 높은 확률값을 가지는 불꽃놀이를 기반으로 음향 인식 결과 정보가 생성될 수 있다. 한편, 서버 는 제1인식 모델이 출력한 인식 항목들 간의 유사도 점수를 산출할 수 있다. 실시예에서, 인식 항목 들 간의 유사도 점수는, 각 항목에 대응하는 음향들 간의 유사도 평가를 기반으로 수행될 수 있다. 일 예로, 인 식 항목들 각각에 대응하는 대표 음향 서브 데이터를 차원 감소 네트워크 함수에 입력함으로써, 각 인식 항목에 대응하는 임베딩을 획득할 수 있으며, 임베딩 유사도를 통해 인식 항목 간의 유사도가 평가될 수 있다. 또한 예 를 들어, 임베딩된 단어 벡터 간의 코사인 각도를 계산하여 유사도를 측정하는 코사인 유사도를 활용하여 각 인 식 항목 간의 유사도를 평가할 수도 있다. 다른 예를 들어, 시맨틱 텍스트 유사도를 판단하기 위하여 Siamese network와 transformer 기반의 모델이 활용될 수 있다. 전술한 키워드 간의 유사도 평가 방법에 대한 구체적인 기재는 예시일 뿐, 본 발명은 이에 제한되지 않는다. 추가적인 실시예에서, 자카드 유사도, 유클리드 거리 및 워드넷을 활용하여 키워드 또는 단어 간의 유사도를 측정할 수도 있다. 제1인식 모델이 출력한 인식 항목들 간의 유사도 평가에 기초하여 유사도 점수가 도출되게 된다. 인식 항 목들 간의 유사도가 높을수록 높은 유사도 점수가 산출되며, 인식 항목들 간의 유사도가 낮을수록 낮은 유사도 점수가 산출된다. 실시예에 따르면, 인식 항목들 간의 유사도가 높을수록 제1인식 모델의 출력 정확도가 낮아질 수 있다. 예를 들어, 제1인식 모델이 A 음향 서브 데이터에 대응하여 출력한 인식 항목들이 '비명 소리', '충돌 소 리' 및 '비오는 소리'인 경우, 해당 항목들 간의 음향 유사도가 적으므로, 유사성 점수가 낮게 산출된다. 즉, 결과 예측에 후보가 되는 인식 항목들이 상이할수록, 각 항목에 대한 특징이 명확히 상이하므로 제1인식 모델의 출력의 신뢰도가 담보된다. 반면, 제1인식 모델이 B 음향 서브 데이터에 대응하여 출력한 인식 항목들이 '총소리', '풍선 터지는 소리' 및 '불꽃놀이 소리'인 경우, 해당 항목 간의 음향 유사도가 높으므로, 유사성 점수가 높게 산출될 수 있다. 즉, 결과 예측에 후보가 되는 인식 항목들이 매우 유사하므로, 각 항목의 특징을 구분하기 위한 난이도가 높기 때문에, 제1인식 모델의 출력에 대한 신뢰도가 다소 낮아질 수 있다. 다시 말해, 음향적인 특징 요소가 전혀 유사하지 않은 인식 항목들(예컨대, 비명 소리, 깨지는 소리 및 비오는 소리)이 출력되는 경우에는 최종 출력되는 인식 결과가 정확할 가능성이 높을 수 있으나(각 인식 항목의 음향적 특징이 전혀 상이함에 따라 신경망이 올바른 출력을 제공할 확률이 높음), 높은 유사도를 가진 인식 항목들(예 컨대, 총소리, 폭죽소리 및 불꽃놀이 소리)이 출력되는 경우에는 최종 출력되는 인식 결과가 다소 부정확할 가 능성이 높다. 즉, 서버는 제1인식 모델이 출력한 인식항목 들의 유사도 점수를 산출함으로써, 음향 인식 결과 정보 가 신뢰할만한 것인지 여부를 판별할 수 있다. 인식항목 간의 유사도 점수가 낮은 경우(즉, 일정 기준치 이하인 경우)에는 음향 인식 결과 정보가 신뢰할만한 것으로 판별하여, 음향 서브 데이터에 대한 별도의 재검증을 수행 하지 않으며, 인식항목 간의 유사도 점수가 높은 경우(즉, 일정 기준치를 초과하는 경우)에는 음향 인식 결과 정보의 신뢰도가 낮은 것으로 판별하여, 음향 서브 데이터를 재검증이 필요한 재검증 음향 서브 데이터로 선별 할 수 있다. 실시예에서, 음향 서브 데이터에 대한 재검증은, 제2인식 모델을 활용하여 음향 인식 결과 정보를 재차 도 출하는 것을 의미할 수 있다. 또한, 서버는 제1인식 모델을 통해 산출된 각 인식 항목 별 확률값 중 기 설정된 임계 기준치를 초과 하는 인식 항목이 복수 개인 경우, 음향 인식 결과 정보 산출에 기반이 되는 음향 서브 데이터를 재검증이 필요 한 재검증 음향 서브 데이터로 선별할 수 있다. 예를 들어, 제1인식 모델은, 특정 음향 서브 데이터에 대응하여 '총소리', '풍선 터지는소리' 및 '불꽃놀이 소 리'라는 인식 항목들을 출력할 수 있으며, 각 인식 항목들의 확률값을 85%, 90% 및 94%로 산출할 수 있다. 이 경우, 가장 높은 확률값을 가지는 불꽃놀이를 기반으로 음향 인식 결과 정보가 생성되게 된다. 다만, 다른 인식 항목들 모두, 각 인식 항목에 대응하여 사전 설정된 임계 기준치(예컨대, 82%, 85% 및 88%)를 초과할 수 있다. 이는, 제1인식 모델이 다른 인식 항목들 또한 확률이 높다고 판단한 것이므로, 음향 인식 결과 정보의 신 뢰도가 다소 저하됨을 의미할 수 있다. 예를 들어, 인식항목 a, b, c 각각의 확률값이 97%, 6% 및 3%인 경우에 는, 인식항목 a 만이 확률값이 사전 설정된 임계 기준치(예컨대, 80%)를 초과하므로, 음향 인식 결과 정보에 대 한 신뢰도가 높을 수 있다. 다시 말해, 확률값이 각 인식 항목에 대응하는 임계 기준치를 초과하는 인식 항목의 수가 적을수록 최종 출력되 는 인식 결과가 정확할 가능성이 높을 수 있으나(예컨대, 확률값이 임계 기준치를 초과하는 인식 항목이 하나인 경우, 인식 결과의 신뢰도가 가장 높을 수 있음), 확률 값이 각 인식 항목에 대응하는 임계 기준치를 초과하는 인식 항목의 수가 많을수록 최종 출력되는 인식 결과가 다소 부정확할 가능성이 높다. 즉, 서버는 제1인식 모델을 통해 산출된 각 인식 항목 별 확률값 중 기 설정된 임계 기준치를 초과하 는 인식 항목이 복수 개인지를 식벽하여 음향 인식 결과 정보가 신뢰할만한 것인지 여부를 판별할 수 있다. 확 률값이 임계 기준치를 초과하는 인식 항목이 하나인 경우에는 음향 인식 결과 정보가 신뢰할만한 것으로 판별하 여 음향 서브 데이터에 대한 별도의 재검증을 수행하지 않으며, 확률값이 임계 기준치를 초과하는 인식 항목이 복수(즉, 두 개 이상) 개인 경우에는 음향 인식 결과 정보가 낮은 것으로 판별하여 음향 서브 데이터를 재검증 이 필요한 재검증 음향 서브 데이터로 선별할 수 있다. 또한, 실시예에서, 재검증 음향 서브 데이터를 선별하는 단계는, 제1인식 모델의 출력에 관현한 음향 인식 결과 정보가 기 설정된 재검증 항목 내에 포함되는지 여부를 식별하는 단계 및 음향 인식 결과 정보가 재검증 항목 내에 포함되는 경우, 음향 인식 결과 정보 산출에 기반이 되는 음향 서브 데이터를 재검증이 필요한 재검증 음향 서브 데이터로 선별하는 단계를 포함할 수 있다. 기 설정된 재검증 항목은, 출력의 정확도가 다소 저하될 것으로 예상되어 사전에 미리 정의한 항목들의 조합일 수 있다. 예를 들어, 폭발음의 경우, 총소리인지, 풍선이 터지는 소리인지, 폭죽이 터지는 소리인지, 불꽃놀이 소리인지 증 음향적 특징이 유사하여 구분이 어렵기 때문에, 해당 소리 중 하나로 음향 인식 결과 정보가 생성 된 경우, 충분한 신뢰성을 담보하기 어렵다. 따라서, 본 발명은 음향적 특징 구분이 어려운 항목들을 미리 사전에 저장하여 기 설정된 재검증 항목을 구축할 수 있으며, 제1인식 모델이 기 설정된 재검증 항목에 포함된 음향 인식 결과 정보를 출력하는 경우, 서버 는 해당 음향 인식 결과 정보의 생성에 기반이 된 음향 서브 데이터를 재검증이 필요한 재검증 음향 서브 데이터로 선별할 수 있다. 즉, 구분이 어려운 유사한 음향들을 기반으로 기 설정된 재검증 항목을 사전에 구성할 수 있으며, 제1인식 모델 의 출력(즉, 음향 인식 결과 정보)이 기 설정된 재검증 항목에 대응하는 경우, 해당 음향 서브 데이터를 재검증 음향 서브 데이터로 결정할 수 있다. 실시예에 따르면, 음향 인식 결과 정보를 생성하는 단계는, 선별된 재검증 음향 서브 데이터를 기준으로 조합 재검증 음향 서브 데이터를 생성하는 단계(S312)를 포함할 수 있다. 구체적으로, 서버는 재검증 음향 서브 데이터가 선별되는 경우, 재검증 음향 서브 데이터를 기준으로 전, 후에 관련한 추가 음향 서브 데이터를 식별할 수 있다. 또한, 서버는 재검증 음향 서브 데이터와 추가 음 향 서브 데이터를 조합하여 조합 재검증 음향 서브 데이터를 생성할 수 있다. 또한 실시예에서, 음향 인식 결과 정보를 생성하는 단계는, 조합 재검증 음향 서브 데이터를 제2인식 모델(22 0)에 입력으로 처리하여 음향 인식 결과 정보를 생성하는 단계(S313)를 포함할 수 있다. 실시예에 따르면, 본 발명의 음향 인식 모델은, 복수 개의 음향 서브 데이터 간의 조합을 통해 생성된 조합 재 검증 음향 서브 데이터를 입력으로 하여 조합 재검증 음향 서브 데이터에 대응하는 출력을 제공하는 제2인식 모 델을 포함할 수 있다. 이 경우, 제2인식 모델은, 입력에 활용되는 음향 서브 데이터의 구간의 길이가 제1인식 모델과 상이 한 모델일 수 있다. 제2인식 모델은 제1인식 모델 보다 높은 성능을 가진 신경망 모델일 수 있다. 예 를 들어, 제1인식 모델은 1초의 구간의 음향 서브 데이터를 기반으로 음향 인식 결과를 도출하도록 학습된 신경망 모델이며, 제2인식 모델은 2초의 구간의 음향 서브 데이터를 기반으로 음향 인식 결과를 도출하는 신경망 모델일 수 있다. 즉, 제1인식 모델 및 제2인식 모델은 서로 상이한 성능을 가진 신경망 모델 들이며, 재검증에는 보다 성능이 좋은 제2인식 모델이 활용되게 된다. 실시예에서, 제1인식 모델은 비교적 짧은 구간의 음향 서브 데이터를 인식하여 결과를 출력하는 신경망 모델일 수 있으며, 제2인식 모델 은 비교적 긴 구간의 음향 서브 데이터를 인식하여 결과를 출력하는 신경망 모델일 수 있다. 실시예에서, 제2인식 모델은 클라우드 API를 통해 구현되는 것을 특징으로 할 수 있다. 제2인식 모델(22 0)이 클라우드 API를 통해 구현됨에 따라 저성능의 장치에서도 비교적 고성능의 제2인식 모델의 활용이 가 능해질 수 있다. 구체적인 예를 들어, 도 7을 참조하면, 먼저 비교적 저성능의 가벼운 제1인식 모델을 활용하여 1차적으로 음향 데이터에 대응하여 생성된 복수의 음향 서브 데이터(제1음향 서브 데이터, 제2음향 서브 데이터 및 제3음향 서브 데이터) 각각을 입력으로 하여 음향 인식 결과 정보를 출력할 수 있다. 여기서, 제2음향 서브 데이터에 대응하여 1차적으로 출력한 음향 인식 결과 정보에 대한 신뢰도가 다소 떨 어진다고 판단되는 경우, 음향 인식 결과 정보에 대응하는 음향 서브 데이터(즉 제2음향 서브 데이터)를 재검증 이 필요한 재검증 음향 서브 데이터로 선별할 수 있다. 이 경우, 서버는 제2음향 서브 데이터의 전, 후에 생성된 추가 음향 서브 데이터를 식별할 수 있다. 예컨대, 제2음향 서브 데이터와 인접 시점에 생성된 음향 서브 데이터인 제3음향 서브 데이터를 추가 음향 서브 데이터로 식별할 수 있다. 서버는 재검증 음향 서브 데이터와 추가 음향 서브 데이터를 조합하여 조합 재검증 음향 서브 데이터를 생 성하게 된다. 즉, 제2음향 서브 데이터와 제3음향 서브 데이터의 조합을 통해 조합 재검증 음향 서브 데이터가 생성될 수 있다.이 경우, 조합 재검증 음향 서브 데이터는, 음향 서브 데이터들의 조합을 통해 생성된 것임에 따라, 최초 제1인식 모델에 입력되는 음향 서브 데이터들 보다 긴 길이를 가질 수 있다. 즉, 음향 서브 데이터들에 대 한 인식 결과가 부정확할 것으로 판단되는 경우, 조합 재검증 음향 서브 데이터를 생성함으로써, 부정확한 출력 을 도출하는 음향 서브 데이터에 대한 재검증이 수행되도록 할 수 있다. 서버는 조합 재검증 음향 서브 데이터는 제2인식 모델에 입력으로 처리하여 음향 인식 결과 정보 를 출력할 수 있다. 이 경우, 제2인식 모델은 제1인식 모델 보다 긴 구간의 음향 서브 데이터에 대한 인식을 수 행하는 신경망 모델이므로, 제1인식 모델 보다 큰 범위의 음향 서브 데이터(즉, 조합 재검증 음향 서브 데이 터)에 대한 분석을 통해 음향 인식 결과를 도출하므로, 보다 정확도 높은 음향 인식 결과 정보를 생성해낼 수 있다. 즉, 서버는 비교적 가벼운 제1인식 모델을 활용하다가, 필요 시 제2모델을 활용하여 재검증만을 수행하도 록 함으로서 계산량을 효과적으로 줄이면서도 인식 결과의 신뢰도를 향상시키는 효과를 제공할 수 있다. 도 8은 본 발명의 일 실시예와 관련된 음향 서브 데이터 간의 연관관계에 따라 음향 인식 결과 정보에 대한 보 정을 수행하는 과정을 예시적으로 나타낸 순서도이다. 실시예에 따르면, 음향 인식 결과 정보를 생성하는 단계는, 복수 개의 음향 인식 결과 정보 간의 연관관계 정보 를 생성하는 단계(S321)를 포함할 수 있다. 연관관계 정보란, 각 음향 인실 결과 정보의 연관성을 나타낸 정보 일 수 있다. 예를 들어, 제1구간에 대응하는 제1음향 서브 데이터에 대한 인식 결과 생성된 제1음향 인식 결과 정보가 '총소리'이며, 제2구간에 대응하는 제2음향 서브 데이터에 대한 인식 결과 생성된 제2음향 인식 결과 정 보가 '박수소리'인 경우, 서버는 제1음향 인식 결과 정보와 제2음향 인식 결과 정보가 관련성이 없다는 하 다는 연관관계 정보를 생성할 수 있다. 전술한 각 음향 인식 결과 정보에 대한 구체적인 기재 및 연관관계 정보 에 대한 구체적인 기재는 예시일 뿐, 본 발명은 이에 제한되지 않는다. 또한, 음향 인식 결과 정보를 생성하는 단계는, 연관관계 정보를 기반으로 각 음향 서브 데이터에 대응하는 음 향 인식 결과 정보들 중 적어도 하나의 음향 인식 결과 정보에 대한 보정을 수행하는 단계(S322)를 포함할 수 있다. 서버는 음향 인식 결과 정보들 간의 연관관계 정보를 기반으로 적어도 하나의 음향 인식 결과 정보 에 대한 보정을 수행할 수 있다. 서버는 각 음향 인식 정보 간의 연관관계 정보에 기초하여 음향 인식 결 과 정보를 보정할 것인지 여부를 결정할 수 있다. 구체적인 실시예에 따르면, 적어도 하나의 음향 인식 결과 정보에 대한 보정을 수행하는 단계는, 제1음향 인식 결과 정보와 제2음향 인식 결과 정보가 기 설정된 시간 이내에 생성된 경우, 제1음향 인식 결과와 제2음향 인식 결과 정보에 대응하는 연관관계 정보를 기반으로 제1음향 인식 결과 및 제2음향 인식 결과 중 적어도 하나에 대 한 보정을 수행하는 것을 특징으로 할 수 있다. 즉, 서버는 일정 시간 내 출력되는 음향 인식 결과 정보들을 기반으로 음향 인식 결과 정보들 중 적어도 일부에 대한 후처리 보정을 수행할 수 있다. 음향 데이터는 일정 시간 간격으로 분할되어 프레임 형태로 신경망 에 입력되며, 각 분할된 데이터에 대응하여 음향 인식 결과 정보가 도출된다. 서버는 일정 시간 내에 출력 된 음향 인식 결과 간의 연관관계 정보를 생성하고, 이를 통해 인접 시점에 대응하는 생성된 음향 인식 결과 간 의 연관관계에 따라 특정 음향 인식 결과 정보를 다른 음향 인정 결과로 보정할 수 있다. 이러한 구성은, 단순히 음향 서브 데이터만을 기준으로 음향 인식 결과 정보를 생성하는 경우 보다 정확도를 보 다 향상시키기 위함이다. 예를 들어, 소리 A(예컨대, gunshot)라는 음향 인식 결과가 출력된 이후, n초 이내에 소리 B(예컨대, applause)라는 음향 인식 결과가 출력되는 경우, 소리 A의 인식 결과를 소리 C(예컨대, 폭죽소 리)로 보정할 수 있다. 즉, 일정 시간 내에 출력(또는 인식)되는 음향 인식 결과 간의 연관관계를 고려하여 음 향 인식 결과들 중 적어도 하나에 대한 보정을 수행함으로써, 인식 정확도를 향상시킬 수 있다. 보다 구체적인 예를 들어, 도 9의 (a)와 같은 단일 프레임(즉, 하나의 음향 서브 데이터)를 음향 인식 모델로 입력시키는 경우, 'gunshot'이라는 음향 인식 결과 정보가 생성될 수 있다. 이는 단순히 폭발음에 관련한 음향 서브 데이터 하나 만을 분석하여 도출한 결과이므로, 높은 정확도를 담보할 수 없다. 예컨대, gunshot의 경우, 폭죽소리나, 불꽃놀이 소리나, 또는 풍선 터지는 소리 등 유사한 음향적 특징을 가진 소리들이 많기 때문에, 정 확성이 다소 결여될 우려가 있다. 도 9의 (b)와 같이, 특정 음향 인식 결과 정보(즉, gunshot)를 기준으로 일정 시간 내 존재하는 프레임들에 대 응하는 음향 인식 결과 정보들이 생일축하노래를 부르는 소리, 박수소리, 환호소리 인 것을 식별할 수 있다. 서 버는 일정 시간 내에 출력된 다른 음향 인식 결과들을 통해 특정 음향 인식 결과(즉, gunshot)가 다른 음 향 인식 결과 정보들과 관련성이 없다는 연관관계 정보를 생성할 수 있다. 이에 따라, 특정 음향 인식 결과 정 보를 다른 음향 인식 결과로 후처리 보정하게 된다. 즉, 최초 출력된 gunshot이라는 음향 인식 결과 정보를, 일 정 시간 내 출력된 다른 음향 인식 결과 정보들(예컨대, 생일축하노래를 부르는 소리, 박수소리, 환호소리)과의 관련성을 기반으로 생성된 연관관게 정보를 기반으로 다른 음향 인식 결과 정보인 '폭죽 터뜨리는 소리'로 보정 할 수 있다. 실시예에서, 서버는 최초 출력된 gunshot이 특정 항목(예컨대, 폭발음에 대응하는 항목)에 포 함됨을 식별하고, 특정 항목에 포함된 다른 종류의 키워드를 선별하여 음향 인식 결과 정보에 대한 보정을 수행 할 수 있다. 서버는 특정 항목에 포함된 다른 종류의 음향들 중 다른 음향 인식 결과들과 연관성을 가진 키워드(예컨대, 폭죽 터뜨리는 소리)를 선별하여 최초 출력된 음향 인식 결과 정보에 대한 보정을 수행할 수 있 다. 이에 따라, 최초 출력된 gunshot이라는 음향 인식 결과 정보는 '폭죽 터뜨리는 소리'로 보정되게 된다. 즉, 서버는 일정 시간 내에 출력(또는 인식)되는 음향 인식 결과 정보 간의 연관관계를 고려하여 음향 인 식 결과 정보들 중 적어도 하나에 대한 후처리 보정을 수행함으로써, 인식의 정확도를 향상시킬 수 있다. 다시 말해, 근처 시점에서 출력된 음향 인식 결과 정보들과 유사성을 가지지 않은 특정 음향 인식 결과 정보를 식별 하고, 이를 다른 음향 인식 결과 정보들과 연관성을 가진 다른 음향 인식 결과 정보로 보정함으로써, 음향 인식 결과의 정확도를 향상시킬 수 있다. 도 10은 본 발명의 일 실시예와 관련된 주변 환경 및 분위기를 고려하여 음향 인식 결과 정보를 생성하는 과정 을 예시적으로 나타낸 순서도이다. 실시예에 따르면, 서버는 무드 감지 모델을 통해 음향 인식 결과 정보에 대응하는 무드 정보를 생성할 수 있다. 무드 감지 모델은, 음향 인식 결과 정보를 인식하여 시점 별 주변 상황에 대응하는 무드 정보를 출력하도 록 학습된 신경망 모델일 수 있다. 무드 정보는, 음향 데이터가 획득되는 공간에 관련한 분위기에 대한 예측 정보로, 장소 예측 정보 및 감정 예측 정보를 포함할 수 있다. 무드 감지 모델은 각 음향 서브 데이터를 통해 도출된 음향 인식 결과 정보를 기반으로, 실시간 분위기를 파악 하는 신경망 모델일 수 있다. 무드 감지 모델은 음향 인식 결과 정보를 통해, 현재 음향 데이터가 획득되는 장 소가 어디인지에 대한 예측 정보 및 음향 데이터가 획득되는 분위기에 대한 예측 정보 포함하는 무드 정보를 생 성할 수 있다. 무드 감지 모델은, 키워드를 분석 및 음성의 높낮이 분석을 통해 사용자의 감정을 분석할 수 있 으며, 대화가 수행되는 장소를 인식할 수 있다. 실시에에서, 무드 감지 모델은, 자연어 처리 모델 및 감정 분석 모델을 포함할 수 있다. 자연어 처리 모델은 텍스트 데이터(예컨대, 음향 인식 결과 정보)를 이해하고 처리하는 데 활용되며, 감정 분석 모델은, 문장에 포함된 감정을 감지하는데 활용될 수 있다. 예를 들어, 차량의 주행 소음에 관련한 음향 인식 결과 정보가 지속적으로 획득되는 것을 감지하여 현재 음향 데이터가 획득되는 장소가 '주행중인 차량'인 것으로 판단할 수 있다. 다른 예를 들어, 점차 높은 톤의 음향 인 식 결과 정보가 획득되는 것을 감지하여 실시간 분위기가 '분노' 감정에 관련한 것으로 판단할 수 있다. 전술한 장소 및 감정에 관한 구체적인 기재는 예시일 뿐, 본 발명은 이에 제한되지 않는다. 서버는 무드 감지 모델을 통해 생성된 무드 정보와 음향 서브 데이터를 기반으로 음향 인식 결과 정보를 생성할 수 있다. 이는, 음향 서브 데이터의 입력 전과 후의 상황 또는 분위기를 인지하고, 이를 고려하여 보다 정확도가 높은 음향 인식 결과 정보를 생성하기 위함이다. 도 11을 참조하면, 특정 음향 서브 데이터를 음향 인식 모델의 입력으로 처리하여 '아이의 비명(child scream)' 라는 음향 인식 결과 정보를 도출할 수 있다. 다만, 해당 아이의 비명이 위급한 상황에 관련한 비명인지, 노는 아이가 즐거움에 비명을 지르는지 구분하기 어려울 수 있다. 즉, 모든 비명이 위급한 상황을 의미하는 것은 아 니기 때문에, 비명이 위급 상황에 관련한 것인지, 또는 즐거움 상황에서 발생한 것인지를 구분해낼 필요가 있다. 본 발명은 무드 모델을 통해 특정 음향 서브 데이터의 주변 시점의 분위기에 대응하는 무드 정보를 생성 할 수 있으므로, 보다 적절한 상황에 맞는 음향 인식 결과 정보를 도출할 수 있게 된다. 서버는 무드 감지 모델을 활용하여 전후의 분위기 즉 무드 정보를 파악할 수 있으며, 이를 활용하여 보다 적절한 음향 인식 결과 정보를 생성할 수 있다. 예컨대, 서버는 도 12에 도시된 바와 같이, 인접 시점에서 '물에서 첨벙거리는 소리', '아이들 웃음소리' 및 '아이를 부르는 엄마의 목소리' 등을 감지하여 특정 음향 서브 데이터에 대응하여 '아이가 즐거운 상황에서 내지르는 비명'이라는 음향 인식 결과 정보를 생성할 수 있다. 구체적인 실시예에서, 음향 인식 결과 정보를 생성하는 단계는, 제1음향 서브 데이터에 대응하는 제1음향 인식 결과 정보와 제1음향 서브 데이터에 대응하는 무드 정보 간의 연관성 정보를 생성하는 단계(S331)를 포함할 수 있다. 실시예에서, 연관성 정보는, 실시간 생성되는 무드 정보와 음향 인식 결과 정보 간의 연관 정도를 수치화하여 나타낸 정보일 수 있다. 예를 들어, 무드 정보가 '행복한 감정'에 관련하며, 음향 인식 결과 정보가 '총소리'에 관련한 경우, 서버는 무드 정보와 음향 인식 결과 정보 간의 연관 정도가 낮은 것으로 판단하여 무드 정보 와 음향 인식 결과 정보 간의 연관성이 20%라는 연관성 정보를 생성할 수 있다. 다른 예를 들어, 무드 정보가 '분노 및 공포 감정'에 관련하며, 음향 인식 결과 정보가 '총소리'에 관련한 경우, 서버는 무드 정보와 음향 인식 결과 정보 간의 연관 정도가 높은 것으로 판단하여 무드 정보와 음향 인식 결과 정보 간의 연관성이 93%라는 연관성 정보를 생성할 수 있다. 전술한 연관성 정보의 생성에 대한 구체적인 기재는 예시일 뿐, 본 발 명은 이에 제한되지 않는다. 음향 인식 결과 정보를 생성하는 단계는, 연관성 정보가 기 설정된 기준치 이상하는 경우, 제1음향 인식 결과 정보에 대한 보정을 수행하지 않는 단계(S332)를 포함할 수 있다. 기 설정된 기준치는 사용자에 의해 사전 결정 되는 것으로, 실시간 출력된 음향 인식 결과 정보가 적정한지 여부를 판별하기 위한 기준이 될 수 있다. 음향 인식 결과 정보와 무드 정보 간의 연관성 정보가 기 설정된 기준치 이상인 경우, 현재 출력된 음향 인식 결과 정보가 적정한 것으로 판단하여 별도의 보정이 수행되지 않을 수 있다. 음향 인식 결과 정보를 생성하는 단계는, 연관성 정보가 기 설정된 기준치 미만인 경우, 제1음향 인식 결과 정 보에 대한 보정을 수행하는 단계(S333)를 포함할 수 있다. 음향 인식 결과 정보와 무드 정보 간의 연관성 정보 가 기 설정된 기준치 미만인 경우, 현재 출력된 음향 인식 결과 정보의 정확도가 저하된 것이므로 별도의 보정 이 수행되어야 한다. 보다 구체적으로, 서버는 제1음향 인식 결과 정보와 유사성을 가진 복수의 키워드를 식별할 수 있다. 예를 들어, 제1음향 인식 결과 정보가 '총소리'인 경우, 서버는 '폭죽 소리', '불꽃놀이 소리', '풍선 터지는 소리' 등을 복수의 키워드로써 식별할 수 있다. 전술한 제1음향 인식 결과 정보 및 복수의 키워드에 대한 구체 적인 설명은 예시일 뿐, 본 발명은 이에 제한되지 않는다. 또한, 서버는 복수의 키워드 각각과 무드 정보 간의 복수의 연관성 서브 정보를 생성할 수 있다. 즉, 각 키워드와 무드 정보 간의 연관성 정도를 산출하여 복수의 연관성 서브 정보를 생성할 수 있다. 예를 들어, 무드 정보가 \"행복한 분위기\"인 경우, 폭죽소리에 대응하여 93%라는 제1연관성 서브 정보가 생성되며, 불꽃놀이 소리 에 대응하여 82%라는 제2연관성 서브 정보가 생성되고, 그리고 풍선터지는 소리에 대응하여 76%라는 제3연관성 서브 정보가 생성될 수 있다. 각 연관성 서브 정보에 대한 구체적인 수치적 기재는 예시일 뿐, 본 발명은 이에 제한되지 않는다. 서버는 복수의 연관성 서브 정보 중 최대값에 해당하는 최대 연관성 서브 정보를 식별하여 최대 연관성 서 브 정보에 대응하는 키워드에 기초하여 제1음향 인식 결과 정보에 대한 보정을 수행할 수 있다. 예컨대, 서버 는 최대 연관성 서브 정보(93%)에 대응하는 키워드(즉, 불꽃놀이)를 기반으로 제1음향 인식 결과 정보에 대한 보정을 수행할 수 있다. 즉, 서버는 특정 음향 인식 결과 정보가 무드 정보와 어울리지 않는다고 판단하는 경우(즉, 음향 인식 결 과 정보와 무드 정보 간의 연관성 정보가 기 설정된 기준치 미만인 경우), 해당 음향 인식 결과와 유사한 키워 드들 중 무드 정보와 가장 연관성이 높은 키워드를 통해 특정 음향 인식 결과 정보에 대한 보정을 수행할 수 있 다. 본 발명의 실시예와 관련하여 설명된 방법 또는 알고리즘의 단계들은 하드웨어로 직접 구현되거나, 하드웨어에 의해 실행되는 소프트웨어 모듈로 구현되거나, 또는 이들의 결합에 의해 구현될 수 있다. 소프트웨어 모듈은 RAM(Random Access Memory), ROM(Read Only Memory), EPROM(Erasable Programmable ROM), EEPROM(Electrically Erasable Programmable ROM), 플래시 메모리(Flash Memory), 하드 디스크, 착탈형 디스크, CD-ROM, 또는 본 발명이 속하는 기술 분야에서 잘 알려진 임의의 형태의 컴퓨터 판독가능 기록매체에 상주할 수도 있다.본 발명의 구성 요소들은 하드웨어인 컴퓨터와 결합되어 실행되기 위해 프로그램(또는 애플리케이션)으로 구현 되어 매체에 저장될 수 있다. 본 발명의 구성 요소들은 소프트웨어 프로그래밍 또는 소프트웨어 요소들로 실행 될 수 있으며, 이와 유사하게, 실시 예는 데이터 구조, 프로세스들, 루틴들 또는 다른 프로그래밍 구성들의 조 합으로 구현되는 다양한 알고리즘을 포함하여, C, C++, 자바(Java), 어셈블러(assembler) 등과 같은 프로그래밍 또는 스크립팅 언어로 구현될 수 있다. 기능적인 측면들은 하나 이상의 프로세서들에서 실행되는 알고리즘으로 구현될 수 있다."}
{"patent_id": "10-2023-0105562", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "이상, 첨부된 도면을 참조로 하여 본 발명의 실시예를 설명하였지만, 본 발명이 속하는 기술분야의 통상의 기술 자는 본 발명이 그 기술적 사상이나 필수적인 특징을 변경하지 않고서 다른 구체적인 형태로 실시될 수 있다는 것을 이해할 수 있을 것이다. 그러므로, 이상에서 기술한 실시예들은 모든 면에서 예시적인 것이며, 제한적이 아닌 것으로 이해해야만 한다."}
{"patent_id": "10-2023-0105562", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일 실시예에 따른 향상된 신뢰도를 가진 음향 인식 결과 제공 방법을 수행하기 위한 시스템을 개략적으로 나타낸 도면이다. 도 2는 본 발명의 일 실시예와 관련된 향상된 신뢰도를 가진 음향 인식 결과 제공 방법을 수행하는 서버의 하드 웨어 구성도이다. 도 3은 본 발명의 일 실시예와 관련된 향상된 신뢰도를 가진 음향 인식 결과 제공 방법을 예시적으로 나타낸 순 서도를 도시한다. 도 4는 본 발명의 일 실시예와 관련된 음향 데이터의 분할 과정을 설명하기 위한 예시도이다. 도 5는 본 발명의 일 실시예와 관련된 복수의 인공지능 모델을 활용한 재검증을 통해 음향 인식 결과 정보를 생 성하는 과정을 예시적으로 나타낸 순서도이다. 도 6은 본 발명의 일 실시예와 관련된 음향 인식 모델이 음향 인식 결과를 도출하는 과정을 예시적으로 나타낸 예시도이다. 도 7은 본 발명의 일 실시예와 관련된 제1인식 모델 및 제2인식 모델을 활용하여 음향 데이터를 인식하는 과정 에 관한 예시도이다. 도 8은 본 발명의 일 실시예와 관련된 음향 서브 데이터 간의 연관관계에 따라 음향 인식 결과 정보에 대한 보정을 수행하는 과정을 예시적으로 나타낸 순서도이다. 도 9는 본 발명의 일 실시예와 관련된 음향 인식 결과 정보를 보정하는 과정을 설명하기 위한 예시도이다. 도 10은 본 발명의 일 실시예와 관련된 주변 환경 및 분위기를 고려하여 음향 인식 결과 정보를 생성하는 과정 을 예시적으로 나타낸 순서도이다. 도 11은 본 발명의 일 실시예와 관련된 일반적인 인식 과정을 통해 도출되는 음향 인식 결과 정보의 한계점을 설명하기 위한 예시도이다. 도 12는 본 발명의 일 실시예와 관련된 특정 음향 서브 데이터의 전, 후 시점에 대응하는 음향 서브 데이터들을 통해 전반적인 분위기를 파악하고, 파악된 분위기를 고려하여 보다 향상된 정확도의 음향 인식 결과 정보를 출 력하는 과정을 예시적으로 나타낸 예시도이다."}
