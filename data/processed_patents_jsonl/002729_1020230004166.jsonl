{"patent_id": "10-2023-0004166", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0109113", "출원번호": "10-2023-0004166", "발명의 명칭": "고품질 동영상 자율 촬영을 위해 카메라를 제어하는 방법 및 이를 위한 장치", "출원인": "고려대학교 산학협력단", "발명자": "노신영"}}
{"patent_id": "10-2023-0004166", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "프로세서 및 메모리를 포함하는 장치가 고품질 동영상 자율 촬영을 위해 카메라를 제어하는 방법에 있어서, (a) 복수 개의 카메라가 촬영한 영상을 수신하여 상기 영상이 포함하는 오브젝트(Object)를 탐지하고, 상기 오브젝트 탐지 결과를 이용하여 상기 복수 개의 카메라가 촬영한 영상의 정합, 상기 오브젝트 간 상호작용의 분석및 상기 오브젝트의 추적 중 어느 하나 이상을 수행하는 제1 단계; (b) 상기 제1 단계의 수행 결과를 이용하여 상기 탐지한 오브젝트가 상기 수신한 영상이 포함하는 프레임 단위의 이미지의 중심으로부터 얼마나 벗어나 있는지 탐지하고, 상기 이미지의 기울어진 정도를 탐지하여 상기 수신한 영상의 심미성을 평가하는 제2 단계; 및(c) 상기 제2 단계의 심미성 평과 결과를 이용하여 상기 오브젝트를 촬영하는 복수 개의 카메라를 개별적으로제어하는 제3 단계;를 포함하는 고품질 동영상 자율 촬영을 위해 카메라를 제어하는 방법."}
{"patent_id": "10-2023-0004166", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 제1 단계는,복수 개의 카메라가 촬영한 영상을 수신하는 제1-1 단계; 상기 수신한 영상이 포함하는 프레임 단위의 이미지에 오브젝트 탐지 알고리즘을 적용해 복수 개의 오브젝트를탐지하는 제1-2 단계; 상기 프레임 단위의 이미지에서 탐지한 복수 개의 오브젝트를 기준으로 상기 복수 개의 카메라가 촬영한 영상을정합하는 제1-3 단계; 상기 프레임 단위의 이미지에서 탐지한 복수 개의 오브젝트에 대한 정보 및 상기 복수 개의 카메라가 촬영한 영상의 정합에 대한 정보를 이용하여 상기 복수 개의 오브젝트 간 상호작용을 분석하는 제1-4 단계; 및상기 프레임 단위의 이미지에서 탐지한 복수 개의 오브젝트의 위치를 상기 수신한 영상 내에서 추적하는 제1-5단계;중 어느 하나 이상을 포함하는 고품질 동영상 자율 촬영을 위해 카메라를 제어하는 방법."}
{"patent_id": "10-2023-0004166", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서, 상기 제1-2 단계에서의 오브젝트 탐지 알고리즘은, YOLO(You Only Look Once) 알고리즘 및 CenterNet 알고리즘 중 어느 하나인, 고품질 동영상 자율 촬영을 위해 카메라를 제어하는 방법."}
{"patent_id": "10-2023-0004166", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제2항에 있어서, 상기 제1-2 단계에서의 복수 개의 오브젝트 탐지는, 상기 탐지한 복수 개의 오브젝트 각각이 상기 이미지 내에서 위치하는 영역을 경계 박스(Object Bounding Box)로 출력하는 것인,공개특허 10-2023-0109113-3-고품질 동영상 자율 촬영을 위해 카메라를 제어하는 방법."}
{"patent_id": "10-2023-0004166", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제2항에 있어서, 상기 제1-4 단계에서의 복수 개의 오브젝트 간 상호작용은, 상기 복수 개의 오브젝트가 사람과 사물인 경우, 이들 사이의 상호작용 및 상기 복수 개의 오브젝트가 사람과사람인 경우, 이들 사이의 상호작용 중 어느 하나 이상을 포함하는, 고품질 동영상 자율 촬영을 위해 카메라를 제어하는 방법."}
{"patent_id": "10-2023-0004166", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제2항에 있어서,상기 복수 개의 카메라가 촬영한 영상의 정합에 대한 정보, 상기 복수 개의 오브젝트 간 상호작용에 대한 정보및 복수 개의 오브젝트의 위치 추적 정보 중 어느 하나 이상을 이용하여 상기 복수 개의 오브젝트 각각에 대한향후 행동을 예측하는 제1-6 단계;를 더 포함하는 고품질 동영상 자율 촬영을 위해 카메라를 제어하는 방법."}
{"patent_id": "10-2023-0004166", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에 있어서, 상기 제2 단계는, 상기 탐지한 오브젝트가 상기 이미지 내에서 위치하는 영역을 출력한 경계 박스의 중심이 상기 이미지의 중심으로부터 얼마나 벗어나 있는지 탐지하는 제2-1 단계; 상기 이미지 내에서 수평선을 탐지하고, 상기 탐지한 수평선의 기울기를 산출하여 상기 이미지의 기울어진 정도를 탐지하는 제2-2 단계; 및상기 제2-1 단계의 탐지 결과와 제2-2 단계의 탐지 결과를 이용하여 상기 수신한 영상의 심미성을 평가하는 제2-3 단계; 중 어느 하나 이상을 포함하는 고품질 동영상 자율 촬영을 위해 카메라를 제어하는 방법."}
{"patent_id": "10-2023-0004166", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서, 상기 제2-1 단계 및 제2-2 단계 사이에, 상기 제2-1 단계의 탐지 결과에 따라 상기 이미지를 촬영한 카메라의 상대적인 위치를 산출하는 제2-1 ´단계; 를 더 포함하는 고품질 동영상 자율 촬영을 위해 카메라를 제어하는 방법."}
{"patent_id": "10-2023-0004166", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제7항에 있어서, 상기 제2-2 단계에서의 수평선의 탐지는, 상기 이미지 내에서 수평선이 탐지되지 않는 경우, 평행한 두 선을 탐지하고, 탐지한 두 평행선이 만나는 소실점을 산출하여 상기 수평선을 탐지하는 , 고품질 동영상 자율 촬영을 위해 카메라를 제어하는 방법."}
{"patent_id": "10-2023-0004166", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제7항에 있어서, 공개특허 10-2023-0109113-4-상기 제2-2 단계와 제2-3 단계 사이에, 상기 이미지가 실내 이미지인 경우, 상기 탐지한 오브젝트의 대칭선을 탐지하여 상기 이미지의 기울어진 정도를탐지하는 제2-2´ 단계;를 더 포함하는 고품질 동영상 자율 촬영을 위해 카메라를 제어하는 방법."}
{"patent_id": "10-2023-0004166", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제7항에 있어서, 상기 제2-3 단계에서의 심미성 평가의 결과는, 상기 복수 개의 카메라가 촬영한 영상 각각에 대한 심미성 평가 결과, 상기 복수 개의 카메라가 촬영한 영상 각각에 대한 심미성 평가 결과 중, 가장 높은 영상을 촬영한 카메라에 대한 정보, 상기 제2-1 단계의 탐지 결과에 따른 상기 이미지를 촬영한 카메라의 추천 촬영 위치에 대한 정보 및 상기 제2-2 단계의 탐지 결과에 따른상기 이미지를 촬영한 카메라의 추천 촬영 각도에 대한 정보 중 어느 하나 이상을 포함하는, 고품질 동영상 자율 촬영을 위해 카메라를 제어하는 방법."}
{"patent_id": "10-2023-0004166", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "하나 이상의 프로세서;네트워크 인터페이스;상기 프로세서에 의해 수행되는 컴퓨터 프로그램을 로드(Load)하는 메모리; 및대용량 네트워크 데이터 및 상기 컴퓨터 프로그램을 저장하는 스토리지를 포함하되,상기 컴퓨터 프로그램은 상기 하나 이상의 프로세서에 의해,(A) 복수 개의 카메라가 촬영한 영상을 수신하여 상기 영상이 포함하는 오브젝트(Object)를 탐지하고, 상기 오브젝트 탐지 결과를 이용하여 상기 복수 개의 카메라가 촬영한 영상의 정합, 상기 오브젝트 간 상호작용의 분석및 상기 오브젝트의 추적 중 어느 하나 이상을 수행하는 제1 오퍼레이션; (B) 상기 제1 단계의 수행 결과를 이용하여 상기 탐지한 오브젝트가 상기 수신한 영상이 포함하는 프레임 단위의 이미지의 중심으로부터 얼마나 벗어나 있는지 탐지하고, 상기 이미지의 기울어진 정도를 탐지하여 상기 수신한 영상의 심미성을 평가하는 제2 오퍼레이션; 및(C) 상기 제2 단계의 심미성 평과 결과를 이용하여 상기 오브젝트를 촬영하는 복수 개의 카메라를 개별적으로제어하는 오퍼레이션;을 실행하는 고품질 동영상 자율 촬영을 위해 카메라를 제어하는 장치."}
{"patent_id": "10-2023-0004166", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "컴퓨팅 장치와 결합하여,(AA) 복수 개의 카메라가 촬영한 영상을 수신하여 상기 영상이 포함하는 오브젝트(Object)를 탐지하고, 상기 오브젝트 탐지 결과를 이용하여 상기 복수 개의 카메라가 촬영한 영상의 정합, 상기 오브젝트 간 상호작용의 분석및 상기 오브젝트의 추적 중 어느 하나 이상을 수행하는 제1 단계; (BB) 상기 제1 단계의 수행 결과를 이용하여 상기 탐지한 오브젝트가 상기 수신한 영상이 포함하는 프레임 단위의 이미지의 중심으로부터 얼마나 벗어나 있는지 탐지하고, 상기 이미지의 기울어진 정도를 탐지하여 상기 수신한 영상의 심미성을 평가하는 제2 단계; 및(CC) 상기 제2 단계의 심미성 평과 결과를 이용하여 상기 오브젝트를 촬영하는 복수 개의 카메라를 개별적으로제어하는 단계;를 실행하는 컴퓨터로 판독 가능한 매체에 저장된 컴퓨터 프로그램."}
{"patent_id": "10-2023-0004166", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명의 일 실시 예에 따른 고품질 동영상 자율 촬영을 위해 카메라를 제어하는 방법은 (a) 복수 개의 카메라 가 촬영한 영상을 수신하여 상기 영상이 포함하는 오브젝트(Object)를 탐지하고, 상기 오브젝트 탐지 결과를 이 용하여 상기 복수 개의 카메라가 촬영한 영상의 정합, 상기 오브젝트 간 상호작용의 분석 및 상기 오브젝트의 추 적 중 어느 하나 이상을 수행하는 제1 단계, (b) 상기 제1 단계의 수행 결과를 이용하여 상기 탐지한 오브젝트가 상기 수신한 영상이 포함하는 프레임 단위의 이미지의 중심으로부터 얼마나 벗어나 있는지 탐지하고, 상기 이미 지의 기울어진 정도를 탐지하여 상기 수신한 영상의 심미성을 평가하는 제2 단계 및 (c) 상기 제2 단계의 심미성 평과 결과를 이용하여 상기 오브젝트를 촬영하는 복수 개의 카메라를 개별적으로 제어하는 제3 단계를 포함한다."}
{"patent_id": "10-2023-0004166", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 고품질 동영상 자율 촬영을 위해 카메라를 제어하는 방법 및 이를 위한 장치에 관한 것이다. 보다 자 세하게는 주어진 장면에 대하여 능동적으로 오브젝트를 선택하고, 구도 및 샷의 종류까지 선정하여 촬영을 진행 함으로써 고품질 동영상을 촬영할 수 있는 방법 및 이를 위한 장치에 관한 것이다."}
{"patent_id": "10-2023-0004166", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "영상과 관련된 다양한 콘텐츠가 기하급수적으로 쏟아져나오는 현 시대 속에서, 보다 고품질의 동영상을 촬영하 고자 하는 수요자들의 니즈는 나날이 증가하고 있으며, 관련된 촬영 기술 역시 활발하게 개발되고 있다. 종래에는 고품질 동영상을 제작하기 위해 전문적인 촬영 기술을 보유한 촬영 감독이나 촬영 기사가 현장에 배치 되어 스스로의 전문 지식을 활용해 촬영 대상인 오브젝트에 대한 촬영을 진행하였으나, 이들에 대한 인건비가 나날이 증가하고 있으며, 한 장면을 제작하기 위해 복수 개의 카메라로 동시에 촬영을 진행하는 것이 보편적인 촬영 방식이 된 현재의 촬영 현장 내에서 이들 전문가들을 여러명 두는 것은 콘텐츠의 제작비 증가에 치명적인 영향을 준다는 문제점이 있다. 이러한 문제점을 해결하기 위해 최근에는 수동적 시각 지능이라 하여 인공지능 기술을 활용해 특정 장치가 전문 촬영 감독이나 촬영 기사가 촬영한 영상을 수동적으로 학습하고, 학습한 결과에 따라 촬영을 담당하는 카메라를 제어하는 방식이 개발되었으며, 이는 인건비 절감에 도움을 주기는 하였으나, 학습 대상이 된 전문가들의 촬영 방식에서 크게 벗어날 수 없으며, 장치 스스로 촬영 대상인 피사체를 선택하거나 피사체를 기준으로 가장 효과 적인 구도나 샷의 종류를 선정할 수 없기에 전문가들을 완벽하게 대체할 수 있는 대체재로서 동작하지 못하고 보조자로서의 역할에만 그친다는 문제점이 있다. 한편, 수동적 시각 지능이 종래에 비하여 인건비 절감에 도움을 주기는 했어도 소규모 제작자(예를 들어, 개인 방송을 진행하거나 개인 단위의 유튜버 등)들의 입장에서는 여전히 전문가들을 활용할 인건비 부담을 느낄 수밖 에 없는바, 전문적인 촬영 지식을 보유한 전문가들을 보조하는 역할에서 한 걸음 더 나아가, 이들을 완벽하게 대체할 수 있는 새롭고 진보된 기술의 개발이 요구되는바, 본 발명은 이에 관한 것이며, 본 명세서를 통해 이를 능동적 시각 지능이라 명명하도록 한다. 선행기술문헌 특허문헌 (특허문헌 0001) 대한민국 공개특허공보 제 10-2020-0000104호(2020.01.02)"}
{"patent_id": "10-2023-0004166", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명이 해결하고자 하는 기술적 과제는 종래 고품질 동영상 제작을 위해 높은 인건비를 부담해야 하는 전문 촬영 감독이나 촬영 기사를 전혀 고용하지 않고, 장치만을 위한 비교적 적은 비용만으로 고품질 동영상을 제작 할 수 있는 고품질 동영상 자율 촬영을 위해 카메라를 제어하는 방법 및 이를 위한 장치를 제공하는 것이다. 본 발명이 해결하고자 하는 또 다른 기술적 과제는 수동적 시각 지능과 같이 학습 대상이 된 전문가들의 촬영 방식에서 벗어나 장치가 피사체를 기준으로 가장 효과적인 구도나 샷의 종류를 스스로 선정함으로써 이들 전문 가들을 완벽하게 대체하는 대체재로서 동작할 수 있는 고품질 동영상 자율 촬영을 위해 카메라를 제어하는 방법 및 이를 위한 장치를 제공하는 것이다. 본 발명이 해결하고자 하는 또 다른 기술적 과제는 전문가들을 완벽하게 대체하여 이들에 대한 인건비를 절약할 수 있게 됨으로써 소규모 제작자들 역시 고품질 동영상을 부담없이 제작할 수 있도록 이바지하는 고품질 동영상 자율 촬영을 위해 카메라를 제어하는 방법 및 이를 위한 장치를 제공하는 것이다. 본 발명의 기술적 과제들은 이상에서 언급한 기술적 과제들로 제한되지 않으며, 언급되지 않은 또 다른 기술적 과제들은 아래의 기재로부터 통상의 기술자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2023-0004166", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기 기술적 과제를 달성하기 위한 본 발명의 일 실시 예에 따른 고품질 동영상 자율 촬영을 위해 카메라를 제 어하는 방법은 (a) 복수 개의 카메라가 촬영한 영상을 수신하여 상기 영상이 포함하는 오브젝트(Object)를 탐지 하고, 상기 오브젝트 탐지 결과를 이용하여 상기 복수 개의 카메라가 촬영한 영상의 정합, 상기 오브젝트 간 상 호작용의 분석 및 상기 오브젝트의 추적 중 어느 하나 이상을 수행하는 제1 단계, (b) 상기 제1 단계의 수행 결 과를 이용하여 상기 탐지한 오브젝트가 상기 수신한 영상이 포함하는 프레임 단위의 이미지의 중심으로부터 얼 마나 벗어나 있는지 탐지하고, 상기 이미지의 기울어진 정도를 탐지하여 상기 수신한 영상의 심미성을 평가하는 제2 단계 및 (c) 상기 제2 단계의 심미성 평과 결과를 이용하여 상기 오브젝트를 촬영하는 복수 개의 카메라를 개별적으로 제어하는 제3 단계를 포함한다. 일 실시 예에 따르면, 상기 제1 단계는, 복수 개의 카메라가 촬영한 영상을 수신하는 제1-1 단계, 상기 수신한 영상이 포함하는 프레임 단위의 이미지에 오브젝트 탐지 알고리즘을 적용해 복수 개의 오브젝트를 탐지하는 제 1-2 단계, 상기 프레임 단위의 이미지에서 탐지한 복수 개의 오브젝트를 기준으로 상기 복수 개의 카메라가 촬 영한 영상을 정합하는 제1-3 단계, 상기 프레임 단위의 이미지에서 탐지한 복수 개의 오브젝트에 대한 정보 및 상기 복수 개의 카메라가 촬영한 영상의 정합에 대한 정보를 이용하여 상기 복수 개의 오브젝트 간 상호작용을 분석하는 제1-4 단계 및 상기 프레임 단위의 이미지에서 탐지한 복수 개의 오브젝트의 위치를 상기 수신한 영상 내에서 추적하는 제1-5 단계 중 어느 하나 이상을 포함할 수 있다. 일 실시 예에 따르면, 상기 제1-2 단계에서의 오브젝트 탐지 알고리즘은, YOLO(You Only Look Once) 알고리즘 및 CenterNet 알고리즘 중 어느 하나일 수 있다. 일 실시 예에 따르면, 상기 제1-2 단계에서의 복수 개의 오브젝트 탐지는, 상기 탐지한 복수 개의 오브젝트 각각이 상기 이미지 내에서 위치하는 영역을 경계 박스(Object Bounding Box) 로 출력하는 것일 수 있다. 일 실시 예에 따르면, 상기 제1-4 단계에서의 복수 개의 오브젝트 간 상호작용은, 상기 복수 개의 오브젝트가 사람과 사물인 경우, 이들 사이의 상호작용 및 상기 복수 개의 오브젝트가 사람과 사람인 경우, 이들 사이의 상 호작용 중 어느 하나 이상을 포함할 수 있다. 일 실시 예에 따르면, 상기 복수 개의 카메라가 촬영한 영상의 정합에 대한 정보, 상기 복수 개의 오브젝트 간 상호작용에 대한 정보 및 복수 개의 오브젝트의 위치 추적 정보 중 어느 하나 이상을 이용하여 상기 복수 개의 오브젝트 각각에 대한 향후 행동을 예측하는 제1-6 단계를 더 포함할 수 있다. 일 실시 예에 따르면, 상기 제2 단계는, 상기 탐지한 오브젝트가 상기 이미지 내에서 위치하는 영역을 출력한 경계 박스의 중심이 상기 이미지의 중심으로부터 얼마나 벗어나 있는지 탐지하는 제2-1 단계, 상기 이미지 내에 서 수평선을 탐지하고, 상기 탐지한 수평선의 기울기를 산출하여 상기 이미지의 기울어진 정도를 탐지하는 제2- 2 단계 및 상기 제2-1 단계의 탐지 결과와 제2-2 단계의 탐지 결과를 이용하여 상기 수신한 영상의 심미성을 평 가하는 제2-3 단계 중 어느 하나 이상을 포함할 수 있다. 일 실시 예에 따르면, 상기 제2-1 단계 및 제2-2 단계 사이에, 상기 제2-1 단계의 탐지 결과에 따라 상기 이미 지를 촬영한 카메라의 상대적인 위치를 산출하는 제2-1 ´단계를 더 포함할 수 있다. 일 실시 예에 따르면, 상기 제2-2 단계에서의 수평선의 탐지는, 상기 이미지 내에서 수평선이 탐지되지 않는 경 우, 평행한 두 선을 탐지하고, 탐지한 두 평행선이 만나는 소실점을 산출하여 상기 수평선을 탐지하는 것일 수 있다. 일 실시 예에 따르면, 상기 제2-2 단계와 제2-3 단계 사이에, 상기 이미지가 실내 이미지인 경우, 상기 탐지한 오브젝트의 대칭선을 탐지하여 상기 이미지의 기울어진 정도를 탐지하는 제2-2´ 단계를 더 포함할 수 있다. 일 실시 예에 따르면, 상기 제2-3 단계에서의 심미성 평가의 결과는, 상기 복수 개의 카메라가 촬영한 영상 각 각에 대한 심미성 평가 결과, 상기 복수 개의 카메라가 촬영한 영상 각각에 대한 심미성 평가 결과 중, 가장 높 은 영상을 촬영한 카메라에 대한 정보, 상기 제2-1 단계의 탐지 결과에 따른 상기 이미지를 촬영한 카메라의 추천 촬영 위치에 대한 정보 및 상기 제2-2 단계의 탐지 결과에 따른 상기 이미지를 촬영한 카메라의 추천 촬영 각도에 대한 정보 중 어느 하나 이상을 포함할 수 있다. 상기 기술적 과제를 달성하기 위한 본 발명의 또 다른 실시 예에 따른 고품질 동영상 자율 촬영을 위해 카메라 를 제어하는 장치는 하나 이상의 프로세서; 하나 이상의 프로세서, 네트워크 인터페이스, 상기 프로세서에 의해 수행되는 컴퓨터 프로그램을 로드(Load)하는 메모리 및 대용량 네트워크 데이터 및 상기 컴퓨터 프로그램을 저 장하는 스토리지를 포함하되, 상기 컴퓨터 프로그램은 상기 하나 이상의 프로세서에 의해, (A) 복수 개의 카메 라가 촬영한 영상을 수신하여 상기 영상이 포함하는 오브젝트(Object)를 탐지하고, 상기 오브젝트 탐지 결과를 이용하여 상기 복수 개의 카메라가 촬영한 영상의 정합, 상기 오브젝트 간 상호작용의 분석 및 상기 오브젝트의 추적 중 어느 하나 이상을 수행하는 제1 오퍼레이션, (B) 상기 제1 단계의 수행 결과를 이용하여 상기 탐지한 오브젝트가 상기 수신한 영상이 포함하는 프레임 단위의 이미지의 중심으로부터 얼마나 벗어나 있는지 탐지하고, 상기 이미지의 기울어진 정도를 탐지하여 상기 수신한 영상의 심미성을 평가하는 제2 오퍼레이션, (C) 상기 제2 단계의 심미성 평과 결과를 이용하여 상기 오브젝트를 촬영하는 복수 개의 카메라를 개별적으로 제어하는 오퍼레이션을 실행한다. 상기 기술적 과제를 달성하기 위한 본 발명의 또 다른 실시 예에 따른 매체에 저장된 컴퓨터 프로그램은 컴퓨팅 장치와 결합하여, (AA) 복수 개의 카메라가 촬영한 영상을 수신하여 상기 영상이 포함하는 오브젝트(Object)를 탐지하고, 상기 오브젝트 탐지 결과를 이용하여 상기 복수 개의 카메라가 촬영한 영상의 정합, 상기 오브젝트 간 상호작용의 분석 및 상기 오브젝트의 추적 중 어느 하나 이상을 수행하는 제1 단계, (BB) 상기 제1 단계의 수행 결과를 이용하여 상기 탐지한 오브젝트가 상기 수신한 영상이 포함하는 프레임 단위의 이미지의 중심으로 부터 얼마나 벗어나 있는지 탐지하고, 상기 이미지의 기울어진 정도를 탐지하여 상기 수신한 영상의 심미성을 평가하는 제2 단계 및 (CC) 상기 제2 단계의 심미성 평과 결과를 이용하여 상기 오브젝트를 촬영하는 복수 개의 카메라를 개별적으로 제어하는 단계를 실행한다."}
{"patent_id": "10-2023-0004166", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "상기와 같은 본 발명에 따르면, 고품질 동영상 제작을 위해 높은 인건비를 부담해야 하는 전문 촬영 감독이나 촬영 기사를 전혀 고용하지 않고, 장치에 대한 소정의 비용만을 부담하는 것만으로 고품질 동영상을 손쉽게 제 작할 수 있다는 효과가 있다. 또한, 수동적 시각 지능과 같이 학습 대상이 된 전문가들의 촬영 방식을 학습하는 것이 아닌 화면의 구도에 초 점을 맞춘 카메라 제어가 이루어지기 때문에 장치 스스로 피사체를 기준으로 가장 효과적인 구도나 샷의 종류를 스스로 선정함으로써 이들 전문가들을 완벽하게 대체하는 대체재로서 동작할 수 있다는 효과가 있다. 또한, 전문가들을 완벽하게 대체하여 이들에 대한 인건비를 절약할 수 있게 됨으로써 소규모 제작자들 역시 고 품질 동영상을 부담없이 제작할 수 있도록 이바지할 수 있다는 효과가 있다."}
{"patent_id": "10-2023-0004166", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 2, "content": "본 발명의 효과들은 이상에서 언급한 효과들로 제한되지 않으며, 언급되지 않은 또 다른 효과들은 아래의 기재 로부터 통상의 기술자에게 명확하게 이해 될 수 있을 것이다."}
{"patent_id": "10-2023-0004166", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명의 목적과 기술적 구성 및 그에 따른 작용 효과에 관한 자세한 사항은 본 발명의 명세서에 첨부된 도면 에 의거한 이하의 상세한 설명에 의해 보다 명확하게 이해될 것이다. 첨부된 도면을 참조하여 본 발명에 따른 실시 예를 상세하게 설명한다. 본 명세서에서 개시되는 실시 예들은 본 발명의 범위를 한정하는 것으로 해석되거나 이용되지 않아야 할 것이다. 이 분야의 통상의 기술자에게 본 명세서의 실시 예를 포함한 설명은 다양한 응용을 갖는다는 것이 당연 하다. 따라서, 본 발명의 상세한 설명에 기재된 임의의 실시 예들은 본 발명을 보다 잘 설명하기 위한 예시적인 것이며 본 발명의 범위가 실시 예들로 한정되는 것을 의도하지 않는다. 도면에 표시되고 아래에 설명되는 기능 블록들은 가능한 구현의 예들일 뿐이다. 다른 구현들에서는 상세한 설명 의 사상 및 범위를 벗어나지 않는 범위에서 다른 기능 블록들이 사용될 수 있다. 또한, 본 발명의 하나 이상의 기능 블록이 개별 블록들로 표시되지만, 본 발명의 기능 블록들 중 하나 이상은 동일 기능을 실행하는 다양한 하드웨어 및 소프트웨어 구성들의 조합일 수 있다. 또한, 어떤 구성요소들을 포함한다는 표현은 \"개방형\"의 표현으로서 해당 구성요소들이 존재하는 것을 단순히 지칭할 뿐이며, 추가적인 구성요소들을 배제하는 것으로 이해되어서는 안 된다. 나아가 어떤 구성요소가 다른 구성요소에 \"연결되어\" 있다거나 \"접속되어\" 있다고 언급될 때에는, 그 다른 구성 요소에 직접적으로 연결 또는 접속되어 있을 수도 있지만, 중간에 다른 구성요소가 존재할 수도 있다고 이해되 어야 한다. 이하에서는 도면들을 참조하여 본 발명의 세부적인 실시 예들에 대해 살펴보도록 한다. 도 1은 본 발명의 제1 실시 예에 따른 고품질 동영상 자율 촬영을 위해 카메라를 제어하는 장치가 포함하 는 전체 구성을 예시적으로 도시한 도면이다. 그러나 이는 본 발명의 목적을 달성하기 위한 바람직한 실시 예일 뿐이며, 필요에 따라 일부 구성이 추가되거나 삭제될 수 있고, 어느 한 구성이 수행하는 역할을 다른 구성이 함께 수행할 수도 있음은 물론이다. 본 발명의 제1 실시 예에 따른 고품질 동영상 자율 촬영을 위해 카메라를 제어하는 장치는 프로세서, 네트워크 인터페이스, 메모리, 스토리지 및 이들을 연결하는 데이터 버스를 포함할 수 있으며, 기타 본 발명의 목적을 달성함에 있어 요구되는 부가적인 구성들을 더 포함할 수 있음은 물론이라 할 것이다. 프로세서는 각 구성의 전반적인 동작을 제어한다. 프로세서는 CPU(Central Processing Unit), MPU(Micro Processer Unit), MCU(Micro Controller Unit) 또는 본 발명이 속하는 기술 분야에서 널리 알려져 있는 형태의 프로세서 중 어느 하나일 수 있다. 아울러, 프로세서는 본 발명의 제2 실시 예에 따른 고품질 동영상 자율 촬영을 위해 카메라를 제어하는 방 법을 수행하기 위한 적어도 하나의 애플리케이션 또는 프로그램에 대한 연산을 수행할 수 있으며, 추천 모델이 구현된 인공지능 프로세서일 수 있다. 네트워크 인터페이스는 본 발명의 제1 실시 예에 따른 고품질 동영상 자율 촬영을 위해 카메라를 제어하는 장치의 유무선 인터넷 통신을 지원하며, 그 밖의 공지의 통신 방식을 지원할 수도 있다. 따라서 네트워크 인터페이스는 그에 따른 통신 모듈을 포함하여 구성될 수 있다. 메모리는 각종 정보, 명령 및/또는 정보를 저장하며, 본 발명의 제2 실시 예에 따른 고품질 동영상 자율 촬 영을 위해 카메라를 제어하는 방법을 수행하기 위해 스토리지로부터 하나 이상의 컴퓨터 프로그램을 로 드할 수 있다. 도 1에서는 메모리의 하나로 RAM을 도시하였으나 이와 더불어 다양한 저장 매체를 메모리 로 이용할 수 있음은 물론이다. 스토리지는 하나 이상의 컴퓨터 프로그램 및 대용량 네트워크 정보를 비임시적으로 저장할 수 있다. 이러한 스토리지는 ROM(Read Only Memory), EPROM(Erasable Programmable ROM), EEPROM(Electrically Erasable Programmable ROM), 플래시 메모리 등과 같은 비휘발성 메모리, 하드 디스크, 착탈형 디스크, 또는 본 발명이 속하는 기술 분야에서 널리 알려져 있는 임의의 형태의 컴퓨터로 읽을 수 있는기록 매체 중 어느 하나일 수 있다. 컴퓨터 프로그램은 메모리에 로드되어, 하나 이상의 프로세서에 의해, (A) 복수 개의 카메라가 촬 영한 영상을 수신하여 상기 영상이 포함하는 오브젝트(Object)를 탐지하고, 상기 오브젝트 탐지 결과를 이용하 여 상기 복수 개의 카메라가 촬영한 영상의 정합, 상기 오브젝트 간 상호작용의 분석 및 상기 오브젝트의 추적 중 어느 하나 이상을 수행하는 제1 오퍼레이션, (B) 상기 제1 단계의 수행 결과를 이용하여 상기 탐지한 오브젝 트가 상기 수신한 영상이 포함하는 프레임 단위의 이미지의 중심으로부터 얼마나 벗어나 있는지 탐지하고, 상기 이미지의 기울어진 정도를 탐지하여 상기 수신한 영상의 심미성을 평가하는 제2 오퍼레이션 및 (C) 상기 제2 단 계의 심미성 평과 결과를 이용하여 상기 오브젝트를 촬영하는 복수 개의 카메라를 개별적으로 제어하는 오퍼레 이션을 실행할 수 있다. 이상 간단하게 언급한 컴퓨터 프로그램이 수행하는 오퍼레이션은 컴퓨터 프로그램의 일 기능으로 볼 수 있으며, 보다 자세한 설명은 본 발명의 제2 실시 예에 따른 고품질 동영상 자율 촬영을 위해 카메라를 제어하는 방법에 대한 설명에서 후술하도록 한다. 데이터 버스는 이상 설명한 프로세서, 네트워크 인터페이스, 메모리 및 스토리지 사이의 명령 및/또는 정보의 이동 경로가 된다. 이상 설명한 본 발명의 제1 실시 예에 따른 고품질 동영상 자율 촬영을 위해 카메라를 제어하는 장치는 독 립된 디바이스의 형태, 예를 들어 전자 기기나 서버(클라우드 포함)의 형태일 수 있으며, 후자의 경우 전용 애 플리케이션의 형태로 사용자 단말에 다운로드되어 설치될 수 있을 것이다. 아울러, 여기서 전자 기기는 스마트폰, 태블릿 PC, 노트북 PC, PDA, PMP 등과 같이 휴대가 용이한 포터블 기기 뿐만 아니라 한 장소에 고정 설치되어 사용하는 데스크톱 PC 등이라도 무방하며, 네트워크 기능만 보유하고 있 다면 전자 기기는 어떠한 것이라도 무방하다 할 것이다. 이하, 본 발명의 제1 실시 예에 따른 고품질 동영상 자율 촬영을 위해 카메라를 제어하는 장치가 독립된 디바이스 형태인 서버임을 전제로 본 발명의 제2 실시 예에 따른 고품질 동영상 자율 촬영을 위해 카메라를 제 어하는 방법에 대하여 도 2내지 도 7을 참조하여 설명하도록 한다. 도 2는 본 발명의 제2 실시 예에 따른 고품질 동영상 자율 촬영을 위해 카메라를 제어하는 방법을 수행하기 위 한 구성을 포함하는 전체 환경을 예시적으로 도시한 도면이다. 본 발명의 제2 실시 예에 따른 고품질 동영상 자율 촬영을 위해 카메라를 제어하는 방법은 본 발명의 제1 실시 예에 따른 고품질 동영상 자율 촬영을 위해 카메라를 제어하는 장치가 복수 개의 카메라와 네트워크 (N)를 통해 연결되어 있으며, 복수 개의 카메라는 서로 상이한 위치 및 각도에서 동일한 현장을 촬영할 수 있다. 여기서 동일한 현장이라 함은 복수 개의 카메라를 통해 동영상에 담고자 하는 하나의 촬영 현장을 의미하 는 것이며, 촬영 현장에는 오브젝트인 복수 개의 피사체가 존재할 수 있는바, 여기서 오브젝트 또는 피사 체는 사람과 사물을 가리지 않는 최광의의 개념이라 할 것이고, 복수 개의 카메라가 동일한 촬영 현 장을 촬영한다고 하여 이들 카메라 모두가 동일한 오브젝트 또는 피사체를 촬영하는 것은 아니라 할 것이다. 한편, 복수 개의 카메라는 명칭을 카메라로 하였을 뿐, 촬영 기능을 보유한 디바이스라면 어떠한 것이라도 카메라가 될 수 있는바, 예를 들어, 촬영용 드론, 카메라 로봇, 팬틸트 줌 카메라, 스마트폰 등과 같이 촬영 기 능을 보유한 디바이스가 모두 카메라가 될 수 있으며, 복수 개의 카메라 각각은 서로 동일한 종류일 필요는 없으며, 성능 역시 상이할 수도 있음은 물론이라 할 것이다. 도 3은 본 발명의 제2 실시 예에 따른 고품질 동영상 자율 촬영을 위해 카메라를 제어하는 방법의 대표적인 단 계를 나타낸 순서도이다. 그러나 이는 본 발명의 목적을 달성함에 있어서 바람직한 실시 예일 뿐이며, 필요에 따라 일부 단계가 추가 또 는 삭제될 수 있음은 물론이고, 어느 한 단계가 다른 단계에 포함되어 수행될 수도 있다. 한편, 각 단계는 본 발명의 제1 실시 예에 따른 고품질 동영상 자율 촬영을 위해 카메라를 제어하는 장치 를 통해 이루어지는 것을 전제로 하며, 설명의 편의를 위해 \"장치\"로 명명하도록 함을 미리 밝혀두는 바이 다. 또한, 이하의 설명에서 사용할 단어인 \"동영상\", \"영상\"과 \"이미지\"는 사전적인 의미는 상이하나, \"동영상\" 또 는 \"영상\"은 프레임 단위의 \"이미지\" 복수 개가 연속적으로 취합하여 이루어지는 것이기 때문에 이하의 \"이미지\"는 \"동영상\" 또는 \"영상\"의 특정 프레임에서의 정지 화면을 의미한다 할 것이며, 광의의 개념으로 해석 하여 \"동영상\", \"영상\", \"이미지\"는 큰 구별없이 혼용되어 사용될 수 있다 할 것이다. 우선, 장치가 복수 개의 카메라가 촬영한 영상을 수신하여 해당 영상이 포함하는 오브젝트를 탐 지하고, 오브젝트 탐지 결과를 이용하여 복수 개의 카메라가 촬영한 영상의 정합, 오브젝트 간 상호작용의 분석 및 오브젝트의 추적 중 어느 하나 이상을 수행한다(S310). 이와 같은 S310 단계를 제1 단계라고 하는바, 보다 구체적으로 제1 단계는 촬영 현장을 고차원적으로 탐지하여 장면을 인식하는 단계로 볼 수 있으며, 이하, 도 4를 참조하여 설명하도록 한다. 도 4는 본 발명의 제2 실시 예에 따른 고품질 동영상 자율 촬영을 위해 카메라를 제어하는 방법에 있어서, 고차 원적으로 장면을 인식하는 제1 단계를 구체화한 순서도이다. 그러나 이는 본 발명의 목적을 달성함에 있어서 바람직한 실시 예일 뿐이며, 필요에 따라 일부 단계가 추가 또 는 삭제될 수 있음은 물론이고, 어느 한 단계가 다른 단계에 포함되어 수행될 수도 있다. 우선, 장치가 복수 개의 카메라가 촬영한 영상을 수신한다(S310-1). 이와 같은 S310-1 단계를 제1-1 단계라 하며, 여기서 복수 개의 카메라는 앞서 도 2에 대한 설명에서 언급 한 카메라를 의미하고, 장치는 복수 개의 카메라 각각으로부터 각각의 카메라가 촬영한 영상을 개별적으로 수신할 수 있는바, 이하 설명할 단계들은 개별적인 카메라로부터 수신한 영상 각각에 대하여 수행될 수 있다 할 것이다. 이후, 장치가 수신한 영상이 포함하는 프레임 단위의 이미지에 오브젝트 탐지 알고리즘을 적용해 복수 개 의 오브젝트를 탐지한다(S310-2). 이와 같은 S310-2 단계를 제1-2 단계라 하며, 영상은 복수 개의 이미지가 연속적으로 연결되어 형성된 것이기 때문에 제1-2 단계에서는 복수 개의 카메라로부터 수신한 영상 각각에 대하여, 해당 영상이 포함하고 있 는 프레임 단위의 모든 이미지에서 복수 개의 오브젝트를 탐지할 수 있다. 여기서 복수 개의 오브젝트는 사람과 사물을 모두 포함하는 최광의의 개념임은 앞서 언급하였으며, 오브젝 트 탐지는 YOLO(You Only Look Once) 알고리즘 및 CenterNet 알고리즘 중 어느 하나를, 더 나아가 이상의 알고 리즘 외에 공지된 오브젝트 탐지 알고리즘 중 어느 하나라면 어떠한 것이라도 이용할 수 있다 할 것이다. 한편, 장치는 복수 개의 오브젝트를 탐지한 경우, 탐지한 복수 개의 오브젝트 각각이 이미지 내 에서 위치하는 영역을 경계 박스(Object Bounding Box)로 출력할 수 있는바, 여기서 경계 박스는 탐지한 오브젝 트의 개수만큼 출력될 수 있으며, 경계 박스 내에는 탐지한 오브젝트 각각이 전부 포함될 수 있다. 예를 들어, 장치가 하나의 이미지에서 한 명의 사람과 한 개의 공을 탐지한 경우, 경계 박스는 한 명의 사 람을 내부에 전부 포함하는 경계 박스와 한 개의 공을 내부에 전부 포함하는 경계 박스 총 두 개가 출력될 수 있을 것이며, 장치는 각각의 경계 박스에 대하여 하나의 이미지에서 동일한 색상 또는 상이한 색상으로도 출력할 수 있을 것이나, 서로 상이한 이미지에서 인식한 동일한 오브젝트에 대해서는 동일한 색상으로 경계 박 스를 출력할 수 있을 것이다. 이미지에서 복수 개의 오브젝트를 탐지했다면, 프레임 단위의 이미지에서 탐지한 복수 개의 오브젝트(30 0)를 기준으로 복수 개의 카메라가 촬영한 영상을 정합한다(S310-3). 이와 같은 S310-3 단계를 제1-3 단계라 하며, 제1-3 단계를 통해 서로 상이한 카메라로부터 수신한 영상들 을 서로 정합할 수 있다. 예를 들어, 제1 카메라(미도시)로부터 수신한 영상에서 탐지된 한 개의 공이, 제2 카메라(미도시)로부터 수신한 영상에서도 탐지된 경우, 두 개의 영상에서 모두 탐지된 공이라는 오브젝트를 기준으로 제1 카메라(미도시)로부 터 수신한 영상과 제2 카메라(미도시)로부터 수신한 영상을 정합할 수 있으며, 영상의 정합은 특정 영상에서 오 브젝트의 형상 전체가 탐지된 경우뿐만 아니라 오브젝트의 일 부분만 탐지된 경우에도 가능하다 할 것이나, 최 소한 오브젝트로 탐지되어 경계 박스 내에 포함될 정도의 일 부분은 탐지되어야 할 것이다. 또 다른 예를 들어, 제1 카메라(미도시)로부터 수신한 영상에서 탐지된 한 명의 사람이, 제3 카메라(미도시)로 부터 수신한 영상에서도 탐지된 경우, 두 개의 영상에서 모두 탐지된 동일한 사람이라는 오브젝트를 기준으로 제1 카메라(미도시)로부터 수신한 영상과 제3 카메라(미도시)로부터 수신한 영상을 정합할 수 있으며, 앞서 한 개의 공이라는 오브젝트를 기준으로 제1 카메라(미도시)로부터 수신한 영상과 제2 카메라(미도시)로부터 수신한 영상을 정합할 수 있다 하였으므로, 장치는 제1 카메라(미도시)로부터 수신한 영상 내지 제3 카메라(미도 시)로부터 수신한 영상 전부를 자연스럽게 정합할 수 있을 것이다. 영상까지 정합했다면, 장치가 프레임 단위의 이미지에서 탐지한 복수 개의 오브젝트에 대한 정보 및 복수 개의 카메라가 촬영한 영상의 정합에 대한 정보를 이용하여 복수 개의 오브젝트 간 상호작용을 분석한다(S310-4). 이와 같은 S310-4 단계를 제1-4 단계라 하며, 제1-4 단계에서의 복수 개의 오브젝트 간 상호작용은 복수 개의 오브젝트가 사람과 사물인 경우, 이들 사이의 상호작용 및 복수 개의 오브젝트가 사람과 사람인 경우, 이들 사이의 상호작용 중 어느 하나 이상을 포함할 수 있으며, 모두 포함하는 것이 가장 바람직하다 할 것이다. 한편, 여기서 상호작용은 복수 개의 오브젝트 간의 관계, 보다 구체적으로 각각의 오브젝트가 서로에게 어 떤 영향을 주고 있는지에 관한 것인바, 복수 개의 오브젝트가 한 명의 사람과 한 개의 공인 경우, 이들 사 이의 상호작용은 예를 들어, 사람이 공을 발로 찬다(공이 사람에게 발로 차인다), 사람이 공을 손으로 던진다 (공이 사람에게 손으로 던져진다), 사람이 공을 헤딩한다(공이 사람에게 헤딩당한다) 등일 수 있으며, 오브젝트 간 상호작용을 분석하기 위해서는 어느 한 오브젝트가 다른 오브젝트에게 어떻게 작용할 수 있는지를 반드시 확 인해야 하는바, 그에 따라 장치가 상호작용을 분석하기 위해서는 앞서 제1-2 단계에서 탐지한 복수 개의 오브젝트에 대한 정보가 요구되는 것이며(오브젝트가 무엇인지), 장치는 다양한 오브젝트 사이에서 작용할 수 있는 모든 예시에 대한 데이터베이스(미도시)를 포함할 수 있다. 예를 들어, 오브젝트가 공인 경우, 다른 오브젝트인 사람에 대하여 발로 차이는 작용, 손으로 던져지는 작용, 머리로 헤딩당하는 작용 등이 데이터베이스(미도시)에 저장되어 있을 수 있으며, 다른 오브젝트가 방망이인 경 우, 방망이로 쳐지는 작용이 데이터베이스(미도시)에 저장되어 있을 수 있다. 더 나아가, 장치는 앞서 제1-3 단계에서 복수 개의 카메라가 촬영한 영상의 정합에 대한 정보까지 상 호작용의 분석에 이용할 수 있는바, 영상의 정합에 대한 정보를 통해 다양한 시각 정보를 확인할 수 있기 때문 이다. 앞선 예에서 복수 개의 오브젝트가 한 명의 사람과 한 개의 공인 경우, 이들 사이의 상호작용이 사 람이 공을 발로 찬다(공이 사람에게 발로 차인다), 사람이 공을 손으로 던진다(공이 사람에게 손으로 던져진 다), 사람이 공을 헤딩한다(공이 사람에게 헤딩당한다) 등일 수 있다고 했던바, 장치가 복수 개의 오브젝 트에 대한 정보만을 이용한다면 사람과 공의 상호작용이 발로 차는 것인지, 손으로 던지는 것인지, 헤딩하 는 것인지 정확하게 파악하기가 어려울 것이나, 영상의 정합에 대한 정보를 통해 사람과 공에 대한 다양한 시각 정보를 확인함으로써 사람과 공의 상호 작용을 정확하게 구분할 수 있는 것이다. 예를 들어, 영상의 정합에 대한 정보를 통해 사람의 발과 공이 가까이 위치해있다면, 상호작용은 사람이 공을 발로 찬다가 될 것이며, 사람이 공을 손에 쥐고 있으면, 상호작용은 사람이 공을 손으로 던진다가 될 것이고, 공이 사람의 머리 부근에 위치해있다면, 상호작용은 사람이 공을 헤딩한다가 될 것인바, 이들 모두 하나의 영상 을 통해서만은 확인이 어려울 것이기에 영상의 정합에 대한 정보를 함께 이용하는 것이다. 복수 개의 오브젝트 간 상호작용을 분석했다면, 장치가 프레임 단위의 이미지에서 탐지한 복수 개의 오브젝트의 위치를 수신한 영상 내에서 추적하며 (S310-5), 복수 개의 카메라가 촬영한 영상의 정합 에 대한 정보, 복수 개의 오브젝트 간 상호작용에 대한 정보 및 복수 개의 오브젝트의 위치 추적 정 보 중 어느 하나 이상을 이용하여 복수 개의 오브젝트 각각에 대한 향후 행동을 예측한다(S310-6). 여기서 전자에 해당하는 S310-5 단계를 제1-5 단계라 하며, 후자에 해당하는 S310-6 단계를 제1-6 단계라 하는 바, 이들 단계를 통해 복수 개의 카메라가 촬영한 다수의 영상으로부터 오브젝트를 실시간으로 추척할 수 있으며, 전체 영상 내에서 등장한 사람의 수를 파악할 수 있고, 원하는 사람이 등장한 영상까지 파악할 수 있다. 더 나아가, 복수 개의 오브젝트 각각에 대한 향후 행동 예측 결과를 이용하여 오브젝트를 촬영하는 복수 개의 카메라를 개별적으로 제어할 수도 있는바, 예를 들어 공이라는 오브젝트에 대한 장치의 향후 행 동 예측 결과가 운동장의 사이드 라인을 벗어나는 것일 경우에, 공을 촬영하는 카메라를 운동장의 사이드 라인방향으로 이동하도록 제어함으로써 공을 화면에서 놓치지 않고 사이드 라인을 벗어나는 모습을 실시간으로 생동 감 있게 제공할 수 있을 것이며, 이는 복수 개의 카메라를 개별적으로 제어하는 제3 단계에 관한 설명인바, 뒤에서 자세히 설명하도록 한다. 다시 도 3에 대한 설명으로 돌아가도록 한다. 제1 단계를 수행했다면, 장치가 제1 단계의 수행 결과를 이용하여 탐지한 오브젝트가 수신한 영상이 포함 하는 프레임 단위의 이미지의 중심으로부터 얼마나 벗어나 있는지 탐지하고, 이미지의 기울어진 정도를 탐지하 여 수신한 영상의 심미성을 평가한다(S320). 이와 같은 S320 단계를 제2 단계라고 하는바, 보다 구체적으로 제1 단계에서 인식한 장면의 심미성을 평가하는 단계로 볼 수 있으며, 이하, 도 5를 참조하여 설명하도록 한다. 도 5는 본 발명의 제2 실시 예에 따른 고품질 동영상 자율 촬영을 위해 카메라를 제어하는 방법에 있어서, 심미 성을 평가하는 제2 단계를 구체화한 순서도이다. 그러나 이는 본 발명의 목적을 달성함에 있어서 바람직한 실시 예일 뿐이며, 필요에 따라 일부 단계가 추가 또 는 삭제될 수 있음은 물론이고, 어느 한 단계가 다른 단계에 포함되어 수행될 수도 있다. 우선, 장치가 탐지한 오브젝트가 이미지 내에서 위치하는 영역을 출력한 경계 박스의 중심이 이미지의 중 심으로부터 얼마나 벗어나 있는지 탐지한다(S320-1). 이와 같은 S320-1 단계를 제2-1 단계라 하며, 제2-1 단계는 영상에 대한 심미성 평가 항목 중, 촬영하고자 하는 피사체의 중심을 화면의 중심에 두어야하는 항목을 구현한 것이다. 앞서 제1-2 단계에 대한 설명에서 장치가 탐지한 복수 개의 오브젝트 각각이 이미지 내에서 위치하는 영역을 경계 박스로 출력한다고 했던바, 오브젝트는 경계 박스 내부에 전부 포함되므로 경계 박스의 중심이 해 당 오브젝트의 중심으로 볼 수 있으며, 장치는 경계 박스의 중심이 이미지의 중심으로부터 얼마나 벗어나 있는지를 탐지할 수 있다. 한편, 앞서 제1-2 단계에 대한 설명에서 오브젝트가 복수 개인 경우, 각각의 오브젝트에 대하여 경계 박스가 개 별적으로 출력된다고 했던바, 이러한 경우에는 경계 박스의 중심 역시 복수개가 되므로 어떠한 경계 박스의 중 심을 이미지의 중심으로부터 얼마나 벗어나 있는지 탐지해야 함이 문제될 수 있다. 이러한 경우 본 발명의 제2 실시 예에 따른 고품질 동영상 자율 촬영을 위해 카메라를 제어하는 방법은 탐지한 오브젝트가 복수 개임으로 인해 출력한 경계 박스 역시 복수 개가 되는 경우, 해당 복수 개의 경계 박스 전부를 내부에 포함할 수 있는 새 로운 경계 박스를 생성하여 출력할 수 있으며, 이를 종합 경계 박스(Union Box)라 한다. 종합 경계 박스는 그 내부에 복수 개의 오브젝트 각각을 내부에 포함하는 복수 개의 경계 박스를 전부 포 함하고 있는바, 종합 경계 박스의 중심은 각각의 경계 박스의 중심으로부터 벗어나 있을 수 있으나, 전체적으로 본다면 종합 경계 박스의 중심이 해당 이미지의 중심과 일치하는 경우, 피사체의 전체적인 중심이 화면의 중심 에 놓여진 것으로 볼 수 있기 때문이다. 도 6에 이를 예시적으로 도시한바, 도 6을 참조하면, 이미지 내에 두 개의 공이 존재하며, 각각의 공을 내부에 전부 포함하는 경계 박스가 두 개 출력되고 있음을 확인할 수 있으며, 두 개의 경계 박스를 내부에 전부 포함하 는 종합 경계 박스의 중심(p)이 이미지의 중심(P)으로부터 얼마나 벗어나 있는지 탐지하는 모습을 확인할 수 있 다. 장치는 종합 경계 박스의 중심이 이미지의 중심으로부터 얼마나 벗어나 있는지 탐지하여 탐지 결과에 따라 이미지를 촬영한 카메라의 상대적인 위치를 산출할 수 있는바(S320-1′), 이를 제2-1′ 단계라 하며, 후술할 제 3 단계에서 활용될 수 있다. 이후, 장치가 이미지 내에서 수평선을 탐지하고, 탐지한 수평선의 기울기를 산출하여 이미지의 기울어진 정도를 탐지한다(S320-2). 이와 같은 S320-2 단계를 제2-2 단계라 하며, 제2-2 단계는 영상에 대한 심미성 평가 항목 중, 수평 구도에 관 한 것으로써 화면의 전체적인 수평이 균형감있게 맞춰져야 하는 항목을 구현한 것이다. 장치는 이미지 내에서 주된 수평선을 탐지하고, 탐지한 수평선의 기울기를 산출하여 이미지의 기울어진 정 도를 탐지해 후술할 제3 단계에서 활용할 수 있으며, 여기서 수평선은 특정 오브젝트에 의한 것일 수 있고, 특정 오브젝트가 아닌 오브젝트의 뒤에 위치한 배경에 의한 것일 수도 있는바, 어느 것이든 이미지 내에서 주된 수평선으로 인식될 수 있는 것이어야 할 것이다. 한편, 이미지에 따라 수평선이 직접적으로 드러나지 않는 경우도 존재할 수있을 것인바, 이 경우, 장치는 이미지 내에서 평행한 두 선을 탐지하고, 탐지한 두 평행선이 만나는 소실점을 산출함으로써 수평선을 탐지할 수 있으며, 이에 대한 기울기를 산출하여 이미지의 기울어진 정도를 탐지할 수도 있다. 더 나아가, 본 발명의 제2 실시 예에 따른 고품질 동영상 자율 촬영을 위해 카메라를 제어하는 방법은 이미지가 실내 이미지인 경우, 제2-2 단계 이후에 탐지한 오브젝트의 대칭선을 탐지하여 이미지의 기울어진 정도를 탐지 할 수 있는바(S320-2′), 이를 제2-2 ′단계라 하며, 탐지 결과를 제2-2 단계와 함께 후술할 제3 단계에서 활용 할 수 있다. 이미지의 기울어진 정도까지 탐지했다면, 장치가 제2-1 단계의 탐지 결과와 제2-2 단계의 탐지 결과를 이 용하여 상기 수신한 영상의 심미성을 평가한다(S320-3). 여기서 제2-1 단계의 탐지 결과는 촬영하고자 하는 피사체의 중심을 화면의 중심에 두어야하는 항목에 관한 것 이며, 제2-2 단계의 탐지 결과는 화면의 전체적인 수평이 균형감있게 맞춰져야 하는 항목에 관한 것이라고 했던 바, 장치는 이를 이용하여 영상의 심미성을 평가할 수 있다. 여기서 심미성의 평가는 복수 개의 카메라가 촬영한 영상 각각에 대하여 개별적으로 이루어지는 것이며, 제2-1 탐지 결과 및 제2-2 탐지 결과를 이용한다 함은 영상의 심미성 평가에 있어서 화면의 구도를 평가한다는 의미이며, 장치는 화면의 구도뿐만 아니라 기타 고품질 동영상이라고 평가하는데 활용될 수 있는 항목에 대한 평가, 예를 들어 영상의 화질에 대한 항목, 영상의 색감에 대한 항목, 영상의 역동성에 대한 항목 등과 같 은 항목을 심미성 평가에 추가적으로 활용할 수 있다 할 것이다. 한편, 심미성 평가는 평가 결과가 일정한 수치로 산출될 수 있으며, 수치가 아니라 복수 개의 카메라가 촬 영한 영상 중, 심미성이 높은 순서만 평가 결과로 산출될 수도 있을 것이며, 이와 더불어 복수 개의 카메라 가 촬영한 영상 각각에 대한 심미성 평가 결과 중, 가장 높은 영상을 촬영한 카메라에 대한 정보, 제2-1 단계의 탐지 결과에 따른 이미지를 촬영한 카메라의 추천 촬영 위치에 대한 정보 및 제2-2 단계의 탐지 결과에 따른 이미지를 촬영한 카메라의 추천 촬영 각도에 대한 정보 중 어느 하나 이상을 포함할 수 있다. 영상의 심미성까지 평가했다면, 마지막으로 장치가 제2 단계의 심미성 평과 결과를 이용하여 오브젝트를 촬영하는 복수 개의 카메라를 개별적으로 제어한다(S330). 복수 개의 카메라에 대한 개별적인 제어는 제2 단계의 심미성 평가 결과를 이용하는 것이 우선적이며, 보 다 구체적으로, 제2-1 단계의 탐지 결과에 따른 이미지를 촬영한 카메라의 추천 촬영 위치에 대한 정보 및 제2- 2 단계의 탐지 결과에 따른 이미지를 촬영한 카메라의 추천 촬영 각도에 대한 정보를 모두 이용하는 것이 가장 바람직하다 할 것이고, 더 나아가, 제2-1′ 단계에서 산출한 카메라의 상대적인 위치에 대한 정보와 제2-2′ 단 계에서 탐지한 대칭선에 따른 이미지의 기울어진 정도를 추가적으로 반영함으로써 카메라 제어에 정확도를 향상 시킬 수도 있다 할 것이다. 이를 도 7에 예시적으로 도시한바, 카메라의 추천 촬영 위치에 대한 정보를 이용하여 해당 카메라의 촬영 위치 를 변경함으로써 도 6에 예시적으로 도시한 종합 경계 박스의 중심이 이미지의 중심과 일치하게 됨을 확인할 수 있다. 한편, 장치는 복수 개의 카메라를 개별적으로 제어하기에 앞서 제2-1 단계의 탐지 결과에 따른 이미 지를 촬영한 카메라의 추천 촬영 위치에 대한 정보에 따른 추천 경계 박스, 제2-2 단계의 탐지 결과에 따른 이 미지를 촬영한 카메라의 추천 촬영 각도에 대한 정보에 따른 추천 수평선을 현재 상태의 경계 박스와 수평선과 구별하여 출력할 수 있으며, 카메라의 제어에 따라 현재의 경계 박스 및 수평선이 추천 경계 박스 및 추천 수평 선과 일치하게 되는 경우 장치의 사용자에게 최적의 고품질 동영상을 촬영하고 있다는 알림을 발송할 수 있다 할 것이다. 이와 별개로 장치는 제3 단계에 따른 카메라 제어 결과, 보다 구체적으로 특정 오브젝트, 오브젝트간 상호 작용 그리고 심미성 평가 결과에 따른 카메라 제어 결과를 지속적으로 학습하여 추후 동일하거나 유사한 오브젝 트, 오브젝트간 상호작용, 심미성 평가 결과에 따른 카메라의 제어에 활용할 수 있을 것인바, 장치의 사용 에 따라 그 성능이 지속적으로 향상될 수 있을 것이다. 지금까지 본 발명의 제2 실시 예에 따른 고품질 동영상 자율 촬영을 위해 카메라를 제어하는 방법에 대하여 설 명하였다. 본 발명에 따르면, 고품질 동영상 제작을 위해 높은 인건비를 부담해야 하는 전문 촬영 감독이나 촬 영 기사를 전혀 고용하지 않고, 장치에 대한 소정의 비용만을 부담하는 것만으로 고품질 동영상을 손쉽게 제작할 수 있다. 또한, 수동적 시각 지능과 같이 학습 대상이 된 전문가들의 촬영 방식을 학습하는 것이 아닌 화면의 구도에 초점을 맞춘 카메라 제어가 이루어지기 때문에 장치 스스로 피사체를 기준으로 가장 효과적 인 구도나 샷의 종류를 스스로 선정함으로써 이들 전문가들을 완벽하게 대체하는 대체재로서 동작할 수 있다. 더 나아가, 전문가들을 완벽하게 대체하여 이들에 대한 인건비를 절약할 수 있게 됨으로써 소규모 제작자들 역 시 고품질 동영상을 부담없이 제작할 수 있도록 이바지할 수 있다. 한편, 본 발명의 제1 실시 예에 따른 고품질 동영상 자율 촬영을 위해 카메라를 제어하는 장치는 도 1과 같은 모습뿐만 아니라 도 8에 예시적으로 도시한 바와 같이 각각의 기능을 수행하는 기능적인 구성을 포함하는 장치로 나타낼 수도 있으며, 본 발명의 제1 실시 예에 따른 고품질 동영상 자율 촬영을 위해 카메라를 제 어하는 장치 및 본 발명의 제2 실시 예에 따른 고품질 동영상 자율 촬영을 위해 카메라를 제어하는 방법은 모든 기술적 특징을 동일하게 포함하는 본 발명의 제3 실시 예에 따른 컴퓨터로 판독 가능한 매체에 저장된 컴 퓨터 프로그램으로 구현할 수도 있는바, 이 경우 컴퓨팅 장치와 결합하여, (AA) 복수 개의 카메라가 촬영한 영 상을 수신하여 상기 영상이 포함하는 오브젝트(Object)를 탐지하고, 상기 오브젝트 탐지 결과를 이용하여 상기 복수 개의 카메라가 촬영한 영상의 정합, 상기 오브젝트 간 상호작용의 분석 및 상기 오브젝트의 추적 중 어느 하나 이상을 수행하는 제1 단계, (BB) 상기 제1 단계의 수행 결과를 이용하여 상기 탐지한 오브젝트가 상기 수 신한 영상이 포함하는 프레임 단위의 이미지의 중심으로부터 얼마나 벗어나 있는지 탐지하고, 상기 이미지의 기 울어진 정도를 탐지하여 상기 수신한 영상의 심미성을 평가하는 제2 단계 및 (CC) 상기 제2 단계의 심미성 평과 결과를 이용하여 상기 오브젝트를 촬영하는 복수 개의 카메라를 개별적으로 제어하는 단계를 실행할 수 있을 것 이며, 중복 서술을 위해 자세히 기재하지는 않았지만 본 발명의 제1 실시 예에 따른 고품질 동영상 자율 촬영을 위해 카메라를 제어하는 장치 및 본 발명의 제2 실시 예에 따른 고품질 동영상 자율 촬영을 위해 카메라를 제어하는 방법 에 적용된 모든 기술적 특징은 본 발명의 제3 실시 예에 따른 컴퓨터로 판독 가능한 매체에 저장 된 컴퓨터 프로그램에 모두 동일하게 적용될 수 있음은 물론이라 할 것이다. 이상 첨부된 도면을 참조하여 본 발명의 실시 예들을 설명하였지만, 본 발명이 속하는 기술 분야에서 통상의 지 식을 가진 자는 본 발명이 그 기술적 사상이나 필수적인 특징을 변경하지 않고서 다른 구체적인 형태로 실시될 수 있다는 것을 이해할 수 있을 것이다. 그러므로 이상에서 기술한 실시 예들은 모든 면에서 예시적인 것이며 한정적이 아닌 것으로 이해해야만 한다."}
{"patent_id": "10-2023-0004166", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 제1 실시 예에 따른 고품질 동영상 자율 촬영을 위해 카메라를 제어하는 장치가 포함하는 전 체 구성을 예시적으로 도시한 도면이다. 도 2는 본 발명의 제2 실시 예에 따른 고품질 동영상 자율 촬영을 위해 카메라를 제어하는 방법을 수행하기 위 한 구성을 포함하는 전체 환경을 예시적으로 도시한 도면이다. 도 3은 본 발명의 제2 실시 예에 따른 고품질 동영상 자율 촬영을 위해 카메라를 제어하는 방법의 대표적인 단 계를 나타낸 순서도이다. 도 4는 본 발명의 제2 실시 예에 따른 고품질 동영상 자율 촬영을 위해 카메라를 제어하는 방법에 있어서, 고차 원적으로 장면을 인식하는 제1 단계를 구체화한 순서도이다. 도 5는 본 발명의 제2 실시 예에 따른 고품질 동영상 자율 촬영을 위해 카메라를 제어하는 방법에 있어서, 심미 성을 평가하는 제2 단계를 구체화한 순서도이다. 도 6은 복수 개의 오브젝트에 대한 경계 박스와 이를 전부 포함하는 종합 경계 박스 그리고 이들의 중심과 이미 지의 중심을 예시적으로 도시한 도면이다. 도 7은 도 6에 도시된 도면을 기준으로 카메라를 제어함으로써 변경된 이미지를 예시적으로 도시한 도면이다.도 8은 본 발명의 제1 실시 예에 따른 고품질 동영상 자율 촬영을 위해 카메라를 제어하는 장치를 도 1의 경우 와 상이하게 기능적인 구성을 포함하는 형태로 도시한 도면이다."}
