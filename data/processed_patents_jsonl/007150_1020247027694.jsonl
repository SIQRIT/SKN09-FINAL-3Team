{"patent_id": "10-2024-7027694", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0134031", "출원번호": "10-2024-7027694", "발명의 명칭": "객체의 색상을 결정하는 방법, 그 장치 및 그 명령을 기록한 기록매체", "출원인": "주식회사 메디트", "발명자": "백종웅"}}
{"patent_id": "10-2024-7027694", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "전자 장치에 의해 수행되는 방법에 있어서,구강 스캐너로부터 획득된 객체에 관한 2차원 이미지 셋에 기초하여, 상기 객체의 3차원 이미지를 생성하는 단계 - 상기 객체는, 복수의 단위 객체를 포함함 -;상기 3차원 이미지의 제1 포인트에 대한 사용자의 선택에 기초하여, 상기 제1 포인트를 포함하는 제1 영역에 대응되는 제1 색상 정보 셋을 추출하는 단계;상기 제1 색상 정보 셋의 입력에 기초하여, 색상 유사도를 출력하는 인공지능 모델을 이용하는 단계; 및상기 색상 유사도의 크기에 기초하여, 상기 제1 포인트에 대응되는 제1 단위 객체의 대표 색상 정보를 결정하는단계를 포함하는, 방법."}
{"patent_id": "10-2024-7027694", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 제1 단위 객체의 상기 대표 색상 정보를 상기 전자 장치의 외부 단말에 전송하는 단계를 더 포함하는, 방법."}
{"patent_id": "10-2024-7027694", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,상기 대표 색상 정보를 상기 외부 단말에 전송하는 단계는,상기 제1 포인트를 포함하는 상기 제1 영역에 대한 정보를 상기 외부 단말에 전송하는 단계를 포함하는, 방법."}
{"patent_id": "10-2024-7027694", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,상기 제1 영역에 대응되는 상기 제1 색상 정보 셋을 추출하는 단계는,상기 제1 포인트로부터 기준 거리 이내의 복수의 포인트를 포함하는 상기 제1 영역을 결정하는 단계를포함하는, 방법."}
{"patent_id": "10-2024-7027694", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서,상기 3차원 이미지는, 유효 영역 및 예외 영역을 포함하고,상기 제1 영역에 대응되는 상기 제1 색상 정보 셋을 추출하는 단계는,상기 제1 영역에 상기 예외 영역이 포함되면, 상기 예외 영역을 제외한 상기 제1 영역에 대응되는 상기 제1 색상 정보 셋을 추출하는 단계를 포함하는, 방법."}
{"patent_id": "10-2024-7027694", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서,상기 제1 영역에 대응되는 상기 제1 색상 정보 셋을 추출하는 단계는,상기 제1 영역에 포함된 복수의 포인트 중 적어도 일부에 대응되는 제1 2차원 이미지 셋을 식별하는 단계 - 상기 제1 2차원 이미지 셋은, 상기 2차원 이미지 셋의 서브 셋임 -; 및공개특허 10-2024-0134031-3-상기 제1 2차원 이미지 셋에 포함된 2차원 이미지의 픽셀의 색상 코드를 추출하는 단계를 포함하는, 방법."}
{"patent_id": "10-2024-7027694", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6항에 있어서,상기 제1 2차원 이미지 셋은,상기 3차원 이미지의 생성에 이용된 2차원 이미지만을 포함하는, 방법."}
{"patent_id": "10-2024-7027694", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제6항에 있어서,상기 제1 2차원 이미지 셋에 포함된 2차원 이미지의 픽셀의 색상 코드를 추출하는 단계는,스캔 순서에 기초하여, 상기 제1 2차원 이미지 셋에 포함된 2차원 이미지의 추출 순서를 결정하는 단계; 및상기 추출 순서에 기초하여, 상기 제1 2차원 이미지 셋에 포함된 2차원 이미지의 픽셀의 색상 코드를 추출하는단계를 포함하는, 방법."}
{"patent_id": "10-2024-7027694", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제6항에 있어서,상기 제1 색상 정보 셋은, 기준 크기를 갖는 하나 이상의 제1 색상 정보를 포함하고,상기 제1 영역에 대응되는 상기 제1 색상 정보 셋을 추출하는 단계는,상기 기준 크기에 기초하여, 제1 색상 정보를 생성하는 단계를 더 포함하는, 방법."}
{"patent_id": "10-2024-7027694", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제6항에 있어서,상기 제1 영역에 대응되는 상기 제1 색상 정보 셋을 추출하는 단계는,추출된 색상 코드를 HSV 코드로 변환하는 단계를 더 포함하는, 방법."}
{"patent_id": "10-2024-7027694", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제1항에 있어서,상기 제1 색상 정보 셋은, N개(여기서, N은 자연수)의 제1 색상 정보를 포함하고,상기 인공지능 모델을 이용하는 단계는,기준 색상 그룹에 포함된 기준 색상 각각과 상기 제1 색상 정보 셋에 포함된 제1 색상 정보의 서브 색상 유사도를 산출하되, 상기 N개의 제1 색상 정보 각각의 서브 색상 유사도를 산출하는 단계; 및상기 N개의 서브 색상 유사도에 기초하여, 상기 색상 유사도를 산출하는 단계를 포함하는, 방법."}
{"patent_id": "10-2024-7027694", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제1항에 있어서,상기 인공지능 모델의 학습 데이터는,기준 색상 그룹에 포함된 제1 기준 색상을 나타내는 제1 라벨 및 상기 제1 기준 색상에 대응되는 제1 모형의 제1 스캔 결과의 쌍을 포함하는, 방법."}
{"patent_id": "10-2024-7027694", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제12항에 있어서,상기 인공지능 모델의 학습 데이터는,공개특허 10-2024-0134031-4-상기 제1 라벨 및 상기 제1 모형의 제2 스캔 결과의 쌍을 더 포함하고,상기 제2 스캔 결과의 제2 스캔 조건은,상기 제1 스캔 결과의 제1 스캔 조건과 적어도 일부가 상이한, 방법."}
{"patent_id": "10-2024-7027694", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제12항에 있어서,상기 인공지능 모델은,상기 제1 스캔 결과가 입력되면 상기 제1 라벨로 분류하도록 학습되는 모델인, 방법."}
{"patent_id": "10-2024-7027694", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제1항에 있어서,상기 대표 색상 정보를 결정하는 단계는,상기 색상 유사도의 크기에 기초하여, 추천 색상 정보를 결정하는 단계; 및추천 색상 정보에 대한 상기 사용자의 선택에 기초하여, 상기 대표 색상 정보를 결정하는 단계를 포함하는, 방법."}
{"patent_id": "10-2024-7027694", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제15항에 있어서,상기 추천 색상 정보를 결정하는 단계는,상기 색상 유사도의 크기가 기준치를 초과하는 기준 색상을 상기 추천 색상 정보에 포함시키는 단계를포함하는, 방법."}
{"patent_id": "10-2024-7027694", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "네트워크와의 통신이 가능하도록 구성된 통신 회로;하나 이상의 인스트럭션(instruction)을 포함하는 컴퓨터 프로그램을 실행하도록 구성된 프로세서; 및상기 컴퓨터 프로그램을 로드(load)하도록 구성된 메모리를 포함하고,상기 컴퓨터 프로그램은,구강 스캐너로부터 획득된 객체에 관한 2차원 이미지 셋에 기초하여, 상기 객체의 3차원 이미지를 생성하는 인스트럭션 - 상기 객체는, 복수의 단위 객체를 포함함 -;상기 3차원 이미지의 제1 포인트에 대한 사용자의 선택에 기초하여, 상기 제1 포인트를 포함하는 제1 영역에 대응되는 제1 색상 정보 셋을 추출하는 인스트럭션;상기 제1 색상 정보 셋의 입력에 기초하여, 색상 유사도를 출력하는 인공지능 모델을 이용하는 인스트럭션; 및상기 색상 유사도의 크기에 기초하여, 상기 제1 포인트에 대응되는 제1 단위 객체의 대표 색상 정보를 결정하는인스트럭션을 포함하는, 전자 장치."}
{"patent_id": "10-2024-7027694", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "프로세서에 의해 실행되기 위한 컴퓨터 프로그램을 기록한 비일시적 컴퓨터 판독 가능 기록 매체에 있어서,상기 컴퓨터 프로그램은,구강 스캐너로부터 획득된 객체에 관한 2차원 이미지 셋에 기초하여, 상기 객체의 3차원 이미지를 생성하는 인스트럭션 - 상기 객체는, 복수의 단위 객체를 포함함 -;상기 3차원 이미지의 제1 포인트에 대한 사용자의 선택에 기초하여, 상기 제1 포인트를 포함하는 제1 영역에 대응되는 제1 색상 정보 셋을 추출하는 인스트럭션;공개특허 10-2024-0134031-5-상기 제1 색상 정보 셋의 입력에 기초하여, 색상 유사도를 출력하는 인공지능 모델을 이용하는 인스트럭션; 및상기 색상 유사도의 크기에 기초하여, 상기 제1 포인트에 대응되는 제1 단위 객체의 대표 색상 정보를 결정하는인스트럭션을 포함하는, 기록 매체."}
{"patent_id": "10-2024-7027694", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 개시는 객체(예: 환자의 치아)의 색상을 결정하는 기술에 관한 것이다. 본 개시의 일 실시예에 따른 방법은, 전자 장치에 의해 수행되는 방법에 있어서, 구강 스캐너로부터 획득된 객체에 관한 2차원 이미지 셋에 기초하여, 상기 객체의 3차원 이미지를 생성하는 단계 - 상기 객체는, 복수의 단위 객체를 포함함 -, 상기 3차원 이미지의 제1 포인트에 대한 사용자의 선택에 기초하여, 상기 제1 포인트를 포함하는 제1 영역에 대응되는 제1 색상 정보 셋을 추출하는 단계, 상기 제1 색상 정보 셋의 입력에 기초하여, 색상 유사도를 출력하는 인공지능 모델을 이용 하는 단계 및 상기 색상 유사도의 크기에 기초하여, 상기 제1 포인트에 대응되는 제1 단위 객체의 대표 색상 정 보를 결정하는 단계를 포함할 수 있다."}
{"patent_id": "10-2024-7027694", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 객체(예: 환자의 치아)의 색상을 결정하는 기술에 관한 것이다."}
{"patent_id": "10-2024-7027694", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "치아 보철물(예: 인레인, 크라운, 임플란트 등)을 제작할 때, 환자의 치아와 자연스럽게 어울리도록 그 치아 보 철물의 색상을 결정할 필요가 있다. 치아 보철물의 색상을 결정하기 위한 종래의 방법으로서, 치과 의사가, 육안으로 관찰할 때, 미리 결정된 복수 의 색상 가이드(예: Vita Classic Shade Guide 등) 중 환자의 치아와 가장 유사한 색상의 색상 가이드를 선택하 였다. 다만, 이 방법은, 복수의 색상 가이드를 환자의 치아에 일일이 대조해야 하기 때문에, 치아 보철물의 색 상을 결정하기 위한 작업의 효율성이 현저히 낮았다. 또한, 이 방법은, 치과 의사의 임상적 경험에 전적으로 의존하는 방법이기 때문에, 다양한 휴먼에러를 발생시키기도 하였다. 대안적인 방법으로서, 디지털 장비를 이용하여, 환자의 치아의 색상을 직접 취득하거나 환자의 치아 이미지를 취득한 후 환자의 치아의 색상을 취득함으로써, 치아 보철물의 색상을 결정하였다. 다만, 이 방법은, 노이즈 (예: 스캔 조건 등에 따라 발생되는 외부 광 등)에 취약하여, 치아 보철물의 색상을 결정하기 위한 작업의 신뢰 도가 현저히 낮았다."}
{"patent_id": "10-2024-7027694", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 개시를 통해 해결하고자 하는 기술적 과제는, 환자의 치아의 색상을 신뢰도 높게 결정할 수 있는 기술을 제 공하는 것이다. 본 개시를 통해 해결하고자 하는 다른 기술적 과제는, 환자의 구강을 스캔하는 구강 스캐너를 이용함으로써, 환 자의 구강에 대한 스캔과 환자의 치아의 색상에 대한 결정을 동시에 처리할 수 있는 기술을 제공하는 것이다. 본 개시를 통해 해결하고자 하는 또 다른 기술적 과제는, 환자의 치아의 색상에 대한 결정이라는 객관적 정보와 치과 의사의 임상적 경험을 조화시킬 수 있는 기술을 제공하는 것이다. 본 개시를 통해 해결하고자 하는 또 다른 기술적 과제는, 환자의 치아의 색상에 대한 결정을 위해 인공지능 모 델이 지속적으로 이용됨으로써, 지속적인 학습 데이터의 확보를 통해 인공지능 모델의 색상 분류 성능을 강화할 수 있는 기술을 제공하는 것이다. 본 개시를 통해 해결하고자 하는 또 다른 기술적 과제는, 환자의 치아의 색상을 결정하도록 설계된 인공지능 모 델의 초기 학습 데이터를 생성할 수 있는 기술을 제공하는 것이다. 본 개시를 통해 해결하고자 하는 또 다른 기술적 과제는, 환자의 치아의 색상을 결정하고 그 색상을 치아 보철 물을 제작하는 치기공소에 전달함으로써, 환자의 치아와 자연스럽게 어울리도록 치아 보철물을 제작할 수 있는 기술을 제공하는 것이다. 본 개시의 기술적 과제들은 이상에서 언급한 기술적 과제들로 제한되지 않으며, 언급되지 않은 또 다른 기술적"}
{"patent_id": "10-2024-7027694", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 2, "content": "과제들은 명세서의 기재로부터 본 개시의 기술분야에서의 통상의 기술자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2024-7027694", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 개시의 일 실시예에 따른 방법은, 전자 장치에 의해 수행되는 방법에 있어서, 구강 스캐너로부터 획득된 객 체에 관한 2차원 이미지 셋에 기초하여, 상기 객체의 3차원 이미지를 생성하는 단계 - 상기 객체는, 복수의 단 위 객체를 포함함 -, 상기 3차원 이미지의 제1 포인트에 대한 사용자의 선택에 기초하여, 상기 제1 포인트를 포함하는 제1 영역에 대응되는 제1 색상 정보 셋을 추출하는 단계, 상기 제1 색상 정보 셋의 입력에 기초하여, 색 상 유사도를 출력하는 인공지능 모델을 이용하는 단계 및 상기 색상 유사도의 크기에 기초하여, 상기 제1 포인 트에 대응되는 제1 단위 객체의 대표 색상 정보를 결정하는 단계를 포함할 수 있다. 일 실시예에서, 상기 제1 단위 객체의 상기 대표 색상 정보를 상기 전자 장치의 외부 단말에 전송하는 단계를 더 포함할 수 있다. 일 실시예에서, 상기 대표 색상 정보를 상기 외부 단말에 전송하는 단계는, 상기 제1 포인트를 포함하는 상기 제1 영역에 대한 정보를 상기 외부 단말에 전송하는 단계를 포함할 수 있다. 일 실시예에서, 상기 제1 영역에 대응되는 상기 제1 색상 정보 셋을 추출하는 단계는, 상기 제1 포인트로부터 기준 거리 이내의 복수의 포인트를 포함하는 상기 제1 영역을 결정하는 단계를 포함할 수 있다. 일 실시예에서, 상기 3차원 이미지는, 유효 영역 및 예외 영역을 포함하고, 상기 제1 영역에 대응되는 상기 제1 색상 정보 셋을 추출하는 단계는, 상기 제1 영역에 상기 예외 영역이 포함되면, 상기 예외 영역을 제외한 상기 제1 영역에 대응되는 상기 제1 색상 정보 셋을 추출하는 단계를 포함할 수 있다. 일 실시예에서, 상기 제1 영역에 대응되는 상기 제1 색상 정보 셋을 추출하는 단계는, 상기 제1 영역에 포함된 복수의 포인트 중 적어도 일부에 대응되는 제1 2차원 이미지 셋을 식별하는 단계 - 상기 제1 2차원 이미지 셋은, 상기 2차원 이미지 셋의 서브 셋임 - 및 상기 제1 2차원 이미지 셋에 포함된 2차원 이미지의 픽셀의 색상 코드를 추출하는 단계를 포함할 수 있다. 일 실시예에서, 상기 제1 2차원 이미지 셋은, 상기 3차원 이미지의 생성에 이용된 2차원 이미지만을 포함할 수 있다. 일 실시예에서, 상기 제1 2차원 이미지 셋에 포함된 2차원 이미지의 픽셀의 색상 코드를 추출하는 단계는, 스캔 순서에 기초하여, 상기 제1 2차원 이미지 셋에 포함된 2차원 이미지의 추출 순서를 결정하는 단계 및 상기 추출 순서에 기초하여, 상기 제1 2차원 이미지 셋에 포함된 2차원 이미지의 픽셀의 색상 코드를 추출하는 단계를 포 함할 수 있다. 일 실시예에서, 상기 제1 색상 정보 셋은, 기준 크기를 갖는 하나 이상의 제1 색상 정보를 포함하고, 상기 제1 영역에 대응되는 상기 제1 색상 정보 셋을 추출하는 단계는, 상기 기준 크기에 기초하여, 제1 색상 정보를 생성 하는 단계를 더 포함할 수 있다. 일 실시예에서, 상기 제1 영역에 대응되는 상기 제1 색상 정보 셋을 추출하는 단계는, 추출된 색상 코드를 HSV 코드로 변환하는 단계를 더 포함할 수 있다. 일 실시예에서, 상기 제1 색상 정보 셋은, N개(여기서, N은 자연수)의 제1 색상 정보를 포함하고, 상기 인공지 능 모델을 이용하는 단계는, 기준 색상 그룹에 포함된 기준 색상 각각과 상기 제1 색상 정보 셋에 포함된 제1 색상 정보의 서브 색상 유사도를 산출하되, 상기 N개의 제1 색상 정보 각각의 서브 색상 유사도를 산출하는 단 계 및 상기 N개의 서브 색상 유사도에 기초하여, 상기 색상 유사도를 산출하는 단계를 포함할 수 있다. 일 실시예에서, 상기 인공지능 모델의 학습 데이터는, 기준 색상 그룹에 포함된 제1 기준 색상을 나타내는 제1 라벨 및 상기 제1 기준 색상에 대응되는 제1 모형의 제1 스캔 결과의 쌍을 포함할 수 있다. 일 실시예에서, 상기 인공지능 모델의 학습 데이터는, 상기 제1 라벨 및 상기 제1 모형의 제2 스캔 결과의 쌍을 더 포함하고, 상기 제2 스캔 결과의 제2 스캔 조건은, 상기 제1 스캔 결과의 제1 스캔 조건과 적어도 일부가 상 이할 수 있다. 일 실시예에서, 상기 인공지능 모델은, 상기 제1 스캔 결과가 입력되면 상기 제1 라벨로 분류하도록 학습되는 모델일 수 있다. 일 실시예에서, 상기 대표 색상 정보를 결정하는 단계는, 상기 색상 유사도의 크기에 기초하여, M개(여기서, M 은 자연수)의 추천 색상 정보를 결정하는 단계 및 추천 색상 정보에 대한 상기 사용자의 선택에 기초하여, 상기 대표 색상 정보를 결정하는 단계를 포함할 수 있다. 일 실시예에서, 상기 M개의 추천 색상 정보를 결정하는 단계는, 색상 유사도의 크기가 기준치 이하인 추천 색상 정보를 제외하는 단계를 포함할 수 있다. 본 개시의 다른 일 실시예에 따른 전자 장치는, 네트워크와의 통신이 가능하도록 구성된 통신 회로, 하나 이상 의 인스트럭션(instruction)을 포함하는 컴퓨터 프로그램을 실행하도록 구성된 프로세서 및 상기 컴퓨터 프로그 램을 로드(load)하도록 구성된 메모리를 포함하고, 상기 컴퓨터 프로그램은, 구강 스캐너로부터 획득된 객체에 관한 2차원 이미지 셋에 기초하여, 상기 객체의 3차원 이미지를 생성하는 인스트럭션 - 상기 객체는, 복수의 단 위 객체를 포함함 -, 상기 3차원 이미지의 제1 포인트에 대한 사용자의 선택에 기초하여, 상기 제1 포인트를 포 함하는 제1 영역에 대응되는 제1 색상 정보 셋을 추출하는 인스트럭션, 상기 제1 색상 정보 셋의 입력에 기초하 여, 색상 유사도를 출력하는 인공지능 모델을 이용하는 인스트럭션 및 상기 색상 유사도의 크기에 기초하여, 상 기 제1 포인트에 대응되는 제1 단위 객체의 대표 색상 정보를 결정하는 인스트럭션을 포함할 수 있다. 본 개시의 또 다른 일 실시예에 따른 기록 매체는, 프로세서에 의해 실행되기 위한 컴퓨터 프로그램을 기록한 비일시적 컴퓨터 판독 가능 기록 매체에 있어서, 상기 컴퓨터 프로그램은, 구강 스캐너로부터 획득된 객체에 관 한 2차원 이미지 셋에 기초하여, 상기 객체의 3차원 이미지를 생성하는 인스트럭션 - 상기 객체는, 복수의 단위 객체를 포함함 -, 상기 3차원 이미지의 제1 포인트에 대한 사용자의 선택에 기초하여, 상기 제1 포인트를 포함 하는 제1 영역에 대응되는 제1 색상 정보 셋을 추출하는 인스트럭션, 상기 제1 색상 정보 셋의 입력에 기초하여, 색상 유사도를 출력하는 인공지능 모델을 이용하는 인스트럭션 및 상기 색상 유사도의 크기에 기초하 여, 상기 제1 포인트에 대응되는 제1 단위 객체의 대표 색상 정보를 결정하는 인스트럭션을 포함할 수 있다."}
{"patent_id": "10-2024-7027694", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 개시에 따르면, 환자의 치아의 색상을 신뢰도 높게 결정할 수 있다. 본 개시에 따르면, 환자의 구강을 스캔하는 구강 스캐너를 이용함으로써, 환자의 구강에 대한 스캔과 환자의 치 아의 색상에 대한 결정을 동시 처리할 수 있다. 본 개시에 따르면, 환자의 치아의 색상에 대한 결정이라는 객관적 정보와 치과 의사의 임상적 경험을 조화시킬 수 있다. 본 개시에 따르면, 환자의 치아의 색상에 대한 결정을 위해 인공지능 모델이 지속적으로 이용됨으로써, 지속적 인 학습 데이터의 확보를 통해 인공지능 모델의 색상 분류 성능을 강화할 수 있다. 본 개시에 따르면, 환자의 치아의 색상을 결정하도록 설계된 인공지능 모델의 초기 학습 데이터를 생성할 수 있 다. 본 개시에 따르면, 환자의 치아의 색상을 결정하고 그 색상을 치아 보철물을 제작하는 치기공소에 전달함으로써, 환자의 치아와 자연스럽게 어울리도록 치아 보철물을 제작할 수 있다. 본 개시의 기술적 사상에 따른 효과들은 이상에서 언급한 효과들로 제한되지 않으며, 언급되지 않은 또 다른 효"}
{"patent_id": "10-2024-7027694", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 2, "content": "과들은 명세서의 기재로부터 본 개시의 기술분야에서의 통상의 기술자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2024-7027694", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 개시에 기재된 다양한 실시예는, 본 개시의 기술적 사상을 명확히 설명하기 위한 목적으로 예시된 것이며, 이를 특정한 실시 형태로 한정하려는 것이 아니다. 본 개시의 기술적 사상은, 본 개시에 기재된 각 실시예의 다양한 변경(modifications), 균등물(equivalents), 대체물(alternatives) 및 각 실시예의 전부 또는 일부로부 터 선택적으로 조합된 실시예를 포함한다. 또한, 본 개시의 기술적 사상의 권리범위는 이하에 제시되는 다양한 실시예나 이에 대한 구체적 설명으로 한정되지 않는다. 기술적이거나 과학적인 용어를 포함해서, 본 개시에서 사용되는 용어들은, 달리 정의되지 않는 한, 본 개시가"}
{"patent_id": "10-2024-7027694", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "속하는 기술분야에서 통상의 지식을 가진 자에게 일반적으로 이해되는 의미를 가질 수 있다. 본 개시에서 사용되는 \"포함한다\", \"포함할 수 있다\", \"구비한다\", \"구비할 수 있다\", \"가진다\", \"가질 수 있다\" 등과 같은 표현들은, 대상이 되는 특징(예: 기능, 동작 또는 구성요소 등)이 존재함을 의미하며, 다른 추 가적인 특징의 존재를 배제하지 않는다. 즉, 이와 같은 표현들은 다른 실시예를 포함할 가능성을 내포하는 개 방형 용어(open-ended terms)로 이해되어야 한다. 본 개시에서 사용되는 단수형의 표현은, 문맥상 다르게 뜻하지 않는 한 복수형의 의미를 포함할 수 있으며, 이 는 청구항에 기재된 단수형의 표현에도 마찬가지로 적용된다. 본 개시에서 사용되는 \"제1\", \"제2\", 또는 \"첫째\", \"둘째\" 등의 표현은, 문맥상 다르게 뜻하지 않는 한, 복수의 동종 대상들을 지칭함에 있어 한 대상을 다른 대상과 구분하기 위해 사용되며, 대상들 간의 순서 또는 중요도를 한정하는 것은 아니다. 본 개시에서 사용되는 \"A, B 및 C,\" \"A, B 또는 C,\" \"A, B 및 C 중 적어도 하나\" 또는 \"A, B 또는 C 중 적어도 하나\" 등의 표현은, 각각의 나열된 항목 또는 나열된 항목들의 가능한 모든 조합들을 의미할 수 있다. 예를 들 어, \"A 또는 B 중 적어도 하나\"는, 적어도 하나의 A, 적어도 하나의 B, 적어도 하나의 A 및 적어도 하나의 B를 모두 지칭할 수 있다. 본 개시에서 사용되는 \"~에 기초하여\"라는 표현은, 이 표현이 포함되는 어구 또는 문장에서 기술되는, 결정, 판 단의 행위 또는 동작에 영향을 주는 하나 이상의 인자를 기술하는 데에 사용되고, 이 표현은 그 결정, 판단의 행위 또는 동작에 영향을 주는 추가적인 인자를 배제하지 않는다. 본 개시에서 사용되는, 어떤 구성요소(예: 제1 구성요소)가 다른 구성요소(예: 제2 구성요소)에 \"연결되어\" 있 다거나 \"접속되어\" 있다는 표현은, 상기 어떤 구성요소가 상기 다른 구성요소에 직접적으로 연결 또는 접속되는 것뿐 아니라, 새로운 다른 구성요소(예: 제3 구성요소)를 매개로 하여 연결 또는 접속되는 것을 의미할 수 있다. 본 개시에서 사용된 표현 \"~하도록 구성된(configured to)\"은 문맥에 따라, \"~하도록 설정된\", \"~하는 능력을 가지는\", \"~하도록 변경된\", \"~하도록 만들어진\", \"~를 할 수 있는\" 등의 의미를 가질 수 있다. 이 표현은, \" 하드웨어적으로 특별히 설계된\"의 의미로 제한되지 않으며, 예를 들어 특정 동작을 수행하도록 구성된 프로세서 란, 소프트웨어를 실행함으로써 그 특정 동작을 수행할 수 있는 범용 프로세서(generic purpose processor)를 의미하거나, 그 특정 동작을 수행하도록 프로그래밍을 통해 구조화된 특수 목적 컴퓨터(special purpose computer)를 의미할 수 있다. 본 개시에서 사용되는 용어 \"인공지능(Artificial Intelligence, AI)\"은, 인간의 학습능력, 추론능력 또는 지각 능력을 모방하여, 이를 컴퓨터로 구현하는 기술을 의미할 수 있다. 이러한 인공지능은 광의의 개념으로, 예를 들어, 기계 학습 또는 심볼릭 로직의 개념을 포함할 수 있다. 구체적으로, 인공지능은 기계 학습의 알고리즘으로써 입력 데이터들을 분석하고, 그 분석의 결과를 학습하며, 그 학습의 결과에 기초한 판단이나 예측을 할 수 있다. 또한, 기계 학습의 알고리즘을 활용하여 인간 두뇌의인지 또는 판단의 기능을 모사하는 기술들 역시 인공지능의 범주로 이해될 수 있다. 예를 들어, 언어적 이해, 시각적 이해, 추론/예측, 지식 표현 또는 동작 제어의 기술 분야가 포함될 수 있다. 본 개시에서 사용되는 용어 \"기계 학습\"은, 데이터를 처리한 경험을 이용해 신경망 모델을 훈련시키는 처리를 의미할 수 있다. 이러한 기계 학습을 통해 컴퓨터 소프트웨어는 스스로 데이터 처리 능력을 향상시키는 것을 의미할 수 있다. 여기서, 신경망 모델은, 데이터 사이의 상관 관계를 모델링하여 구축된 것으로서, 그 상관 관 계는 복수의 파라미터에 의해 표현될 수 있다. 이러한 신경망 모델은 주어진 데이터로부터 특징들을 추출하고 분석하여 데이터 간의 상관 관계를 도출하는데, 이러한 과정을 반복하여 신경망 모델의 파라미터를 최적화 해나 가는 것이 기계 학습이라고 할 수 있다. 예를 들어, 신경망 모델은 입출력 쌍으로 주어지는 데이터에 대하여, 입력과 출력 사이의 매핑(상관 관계)을 학습할 수 있다. 또는, 신경망 모델은 입력 데이터만 주어지는 경우에 도 주어진 데이터 사이의 규칙성을 도출하여 그 관계를 학습할 수도 있다. 본 개시에서 사용되는 용어 \"인공지능 학습 모델\", \"기계 학습 모델\" 또는 \"신경망 모델\"은 인간의 뇌 구조를 컴퓨터 상에서 구현하도록 설계될 수 있으며, 인간의 신경망의 뉴런(neuron)을 모의하며 가중치를 가지는 복수 의 네트워크 노드들을 포함할 수 있다. 여기서, \"복수의 네트워크 노드들\"은 뉴런이 시냅스(synapse)를 통하여 신호를 주고 받는 뉴런의 시냅틱(synaptic) 활동을 모의하여, 서로 간의 연결 관계를 가질 수 있다. 구체적으 로, 인공지능 학습 모델에서 복수의 네트워크 노드들은 서로 다른 깊이의 레이어에 위치하면서 컨볼루션 (convolution) 연결 관계에 따라 데이터를 주고 받을 수 있다. 인공지능 학습 모델은, 예를 들어, 인공 신경망 모델(artificial neural network), 합성곱 신경망 모델(convolution neural network) 등일 수 있으나, 본 개시 의 범위가 전술한 예시들에 한정되는 것은 아니고, 공지된 다양한 신경망 모델들이 본 개시에 적용될 수 있음을 유의해야 한다. 이하, 첨부된 도면들을 참조하여, 본 개시에 기재된 다양한 실시예를 설명한다. 첨부된 도면 및 도면에 대한 설명에서, 동일하거나 실질적으로 동등한(substantially equivalent) 구성요소에는 동일한 참조부호가 부여될 수 있다. 또한, 이하 다양한 실시예의 설명에서, 동일하거나 대응하는 구성요소를 중복하여 기술하는 것이 생 략될 수 있으나, 이는 그 구성요소가 그 실시예에 포함되지 않는 것을 의미하지는 않는다. 도 1은 본 개시의 일 실시예에 따른 스캔 환경을 도시한다. 구체적으로, 도 1에 도시된 스캔 환경은, 본 개시 의 일 실시예에 따른 구강 스캐너를 이용하여 환자의 구강에 대한 이미지를 획득하는 환경이며, 여기 서, 구강 스캐너는 환자의 구강 내의 이미지를 획득하기 위한 치과용 의료 기기일 수 있다. 도 1에 도시된 것처럼 사용자(예: 치과 의사, 치과위생사)가 구강 스캐너를 이용하여 환자로부터 환자의 구강에 대한 이미지를 스캔할 수 있다. 또한, 인공지능 모델의 학습 데이터를 생성하기 위해, 사용 자가 구강 스캐너를 이용하여 색조 가이드(예: 도 5의 색조 가이드)에 대한 이미지를 스캔할 수 도 있다. 이하, 도 1에 도시된 구성요소의 동작에 대해 구체적으로 설명한다. 도 1에 도시된 전자 장치는, 구강 스캐너로부터 환자의 구강에 대한 2차원 이미지를 수신할 수 있다. 예를 들어, 전자 장치는, 구강 스캐너로부터 1초당 980개의 2차원 이미지를 수신할 수 있다. 만약, 14개의 2차원 이미지를 1개의 프레임으로 정의한다면, 전자 장치는, 구강 스캐너로부터 1초당 70프레임을 수신할 수 있다. 또한, 전자 장치는, 수신한 구강에 대한 2차원 이미지에 기초하여 구강의 내부 구조를 3차원적으로 구조화 하여 구강에 대한 3차원 이미지를 생성할 수 있다. 이러한 3차원 이미지의 생성 동작은, 추후 도 4를 참조하여 설명한다. 전자 장치에 의해 생성된 구강에 대한 3차원 이미지는, 전자 장치의 디스플레이를 통해 사용자 또는 환자에게 표시될 수 있다. 이때, 사용자는 전자 장치의 디스플레이에 표시된 3 차원 이미지를 참조하여, 환자에게 적절한 진료 서비스 등을 제공할 수 있다. 일 실시예에서, 전자 장치는, 구강 스캐너 또는 외부 장치가 생성한 구강에 대한 3차원 이미지를 수 신할 수 있다. 즉, 구강 스캐너가 3차원 이미지를 생성하거나 전자 장치와 구별되는 다른 외부 장치 가 3차원 이미지를 생성하는 것이 본 개시의 범위에서 배제되지 않는다. 또한, 전자 장치는, 환자의 하나 이상의 치아 각각의 대표 색상 정보를 결정할 수 있다. 이 대표 색 상 정보는 추후 치기공소 단말에 전송됨으로써, 환자의 보철물의 제작에 이용될 수 있다. 이러한, 대표 색 상 정보의 결정 동작은, 추후 도 6 이하의 도면을 참조하여 설명한다.또한, 전자 장치는, 클라우드 서버와 통신 연결할 수 있다. 이 경우, 전자 장치는 환자의 구강 에 대한 2차원 이미지 또는 구강에 대한 3차원 이미지를 클라우드 서버에 전송할 수 있고, 클라우드 서버는 전 자 장치로부터 수신한 환자의 구강에 대한 2차원 이미지 또는 구강에 대한 3차원 이미지를 저장할 수 있다. 또한, 전자 장치는, 치기공소 단말과 통신 연결할 수 있다. 이 경우, 전자 장치는 환자의 하나 이상의 치아 각각에 대한 대표 색상 정보를 결정하고, 이 대표 색상 정보를 치기공소 단말에 전송함으로써, 대 표 색상 정보에 대응하는 보철물의 제작을 요청할 수 있다. 지금까지 설명된 전자 장치는 컴퓨팅 장치로 구현될 수 있으며, 이러한 컴퓨팅 장치의 일례에 대해서는 추 후 도 2를 참조하여 설명한다. 도 1에 도시된 구강 스캐너는, 구강 내에 인입 및 인출이 가능한 형태를 가질 수 있으며, 스캔 거리와 스 캔 각도를 사용자가 자유롭게 조절할 수 있는 핸드헬드 스캐너(handheld scanner)일 수 있다. 이러한 구강 스캐너는, 구강 내에 삽입되어 비접촉식으로 구강 내부를 스캔함으로써, 구강에 대한 이미지 를 획득할 수 있다. 구강에 대한 이미지는 적어도 하나의 치아, 치은 및/또는 구강 내에 삽입 가능한 인공 구 조물(예: 브라켓 및 와이어를 포함하는 교정 장치, 임플란트, 의치(denture), 구강 내 삽입되는 교정 보조 도구 등)을 포함할 수 있다. 구체적으로, 구강 스캐너는 광원을 이용하여 환자의 구강에 광을 조사할 수 있고, 환자의 구강으로부터 반사된 광을 카메라를 통해 수신할 수 있다. 또한, 구강 스캐너는 카메라를 통해 수신한 정보에 기초하여, 환자의 구강에 대한 표면 이미지를 2차 원 이미지로서 획득할 수 있다. 여기서, 환자의 구강에 대한 표면 이미지는 환자의 치아, 치은, 인공 구조물, 볼, 혀 또는 입술 중 적어도 하나를 포함할 수 있다. 지금까지 설명된 구강 스캐너는 컴퓨팅 장치로 구현될 수 있으며, 이러한 컴퓨팅 장치의 일례에 대해서는 이하 도 2를 참조하여 구체적으로 설명하기로 한다. 도 2는 본 개시의 일 실시예에 따른 전자 장치 및 구강 스캐너 각각을 나타내는 블록 도면을 도시한 다. 도 2에 도시된 블록 도면은 본 개시의 목적을 달성하기 위한 바람직한 실시예를 도시하고 있을 뿐이며, 필 요에 따라 일부 구성 요소가 추가되거나 삭제될 수 있다. 또한, 도 2에 도시된 블록 도면의 구성 요소들은 기 능적으로 구분되는 기능 요소들을 나타낸 것으로써, 복수의 서로 다른 구성 요소가 실제 물리적 환경에서는 통 합되는 형태로 구현될 수도 있음을 유의해야 한다. 이하, 블록 도면에 도시된 각 구성 요소에 대해 구체적으로 설명하기로 한다. 도 2에 도시된 전자 장치는, 하나 이상의 프로세서, 하나 이상의 메모리, 통신 회로, 디스 플레이 또는 입력 장치를 포함할 수 있다. 앞서 설명된 바와 같이 얼마든지, 전자 장치에 포함 된 구성요소들 중 적어도 하나가 생략되거나, 다른 구성요소가 전자 장치에 추가될 수 있다. 또한, 추가 적으로 또는 대체적으로 일부의 구성요소들이 통합되어 구현되거나, 단수 또는 복수의 개체로 구현될 수 있다. 이러한, 전자 장치 내의 적어도 일부의 구성요소들은 버스(bus), GPIO(general purpose input/output), SPI(serial peripheral interface) 또는 MIPI(mobile industry processor interface) 등을 통해 서로 연결되어, 데이터 또는 시그널을 주고 받을 수 있다. 전자 장치의 하나 이상의 프로세서는, 전자 장치의 각 구성요소들(예: 메모리)의 제어 또 는 통신에 관한 연산이나 데이터 처리를 수행할 수 있는 구성일 수 있다. 하나 이상의 프로세서는, 예를 들어, 전자 장치의 구성요소들과 작동적으로 연결될 수 있다. 또한, 하나 이상의 프로세서는 전자 장치의 다른 구성요소로부터 수신된 명령 또는 데이터를 하나 이상의 메모리에 로드(load)하고, 하나 이상의 메모리에 저장된 명령 또는 데이터를 처리하고, 결과 데이터를 저장하도록 할 수 있다. 전자 장치의 하나 이상의 메모리는, 각종 데이터, 명령 또는 정보를 저장할 수 있다. 구체적인 예로 써, 하나 이상의 메모리는 프로세서의 동작에 대한 인스트럭션들을 컴퓨터 프로그램으로서, 저장할 수 있다. 또한, 하나 이상의 메모리는 기계 학습 알고리즘에 따라 구축된 인공지능 모델들을 저장할 수 있다. 또한, 하나 이상의 메모리는 구강 스캐너로부터 수신되는 데이터(예: 구강에 대한 2차원 이미 지, 구강에 대한 3차원 이미지)를 저장할 수 있다. 전자 장치의 통신 회로는, 외부 장치와 유선 또는 무선 통신 채널을 설립하고, 그 외부 장치와 다양 한 데이터를 송수신할 수 있다. 일 실시예에서, 통신 회로는 외부 장치와 유선으로 통신하기 위해서, 외부 장치와 유선 케이블로 연결되기 위한 적어도 하나의 포트를 포함할 수 있다. 이 경우, 통신 회로는 적 어도 하나의 포트를 통하여 유선 연결된 외부 장치와 통신을 수행할 수 있다. 다른 일 실시예에서, 통신 회로 는 셀룰러 통신 모듈을 포함하여 셀룰러 네트워크(예: 3G, LTE, 5G, Wibro 또는 Wimax)에 연결되도록 구성 될 수 있다. 또 다른 일 실시예에서, 통신 회로는 근거리 통신 모듈을 포함하여 근거리 통신(예를 들면, Wi-Fi, Bluetooth, Bluetooth Low Energy(BLE), UWB)을 이용해 외부 장치와 데이터 송수신을 할 수 있다. 또 다른 일 실시예에서, 통신 회로는 비접촉식 통신을 위한 비접촉 통신 모듈을 포함할 수 있다. 여기서 비 접촉식 통신은, 예를 들면, NFC(near field communication) 통신, RFID(radio frequency identification) 통신 또는 MST(magnetic secure transmission) 통신과 같이 적어도 하나의 비접촉 방식의 근접 통신 기술을 포함할 수 있다. 앞서 설명된 다양한 예시들 외에도, 외부 장치와 통신하기 위한 공지된 다양한 방식으로 전자 장치 가 구현될 수 있으며, 앞서 설명된 예시들에 본 개시의 범위가 제한되는 것은 아님을 유의해야 한다. 전자 장치의 디스플레이는, 프로세서의 제어에 기반하여 다양한 화면을 표시할 수 있다. 여기 서, 프로세서의 제어에 기반하여, 구강 스캐너로부터 수신한 환자의 구강에 대한 2차원 이미지 또는 구강의 내부 구조를 3차원적으로 모델링한 구강에 대한 3차원 이미지는 디스플레이를 통해 표시될 수 있다. 이때, 구강에 대한 2차원 이미지 또는 3차원 이미지를 디스플레이에 표시하기 위해서, 예를 들어, 웹 브라우저(Web browser) 또는 전용 애플리케이션이 전자 장치에 설치될 수 있다. 일 실시예에서, 전술 한 웹 브라우저 또는 전용 애플리케이션은, 구강에 대한 2차원 이미지 또는 3차원 이미지에 대한 편집 기능, 저 장 기능 또는 삭제 기능을 사용자 인터페이스를 통해 사용자에게 제공하도록 구현될 수 있다. 전자 장치의 입력 장치는, 전자 장치의 구성요소(예: 프로세서)에 사용될 명령 또는 데이 터를 전자 장치의 외부(예: 사용자)로부터 수신할 수 있다. 입력 장치는, 예를 들면, 마이크, 마우 스 또는 키보드 등을 포함할 수 있다. 일 실시예에서, 입력 장치는 디스플레이와 결합되어 다양한 외부 객체의 접촉 또는 근접을 인식할 수 있는 터치 센서 패널의 형태로 구현될 수 있다. 다만, 앞서 설명된 예시들에 본 개시의 범위가 제한되는 것은 아니고, 공지된 다양한 입력 장치가 사용자의 편의를 위해 얼마 든지 본 개시의 범위에 포함될 수 있다. 도 2에 도시된 구강 스캐너는, 프로세서, 메모리, 통신 회로, 광원, 카메라 또 는 입력 장치를 포함할 수 있다. 앞서 설명된 바와 같이 얼마든지, 구강 스캐너에 포함된 구성요소 들 중 적어도 하나가 생략되거나, 다른 구성요소가 구강 스캐너에 추가될 수 있다. 또한, 추가적으로 또 는 대체적으로 일부의 구성요소들이 통합되어 구현되거나, 단수 또는 복수의 개체로 구현될 수 있다. 이러한, 구강 스캐너 내의 적어도 일부의 구성요소들은 버스(bus), GPIO(general purpose input/output), SPI(serial peripheral interface) 또는 MIPI(mobile industry processor interface) 등을 통해 서로 연결되어, 데이터 또는 시그널을 주고 받을 수 있다. 구강 스캐너의 프로세서는, 구강 스캐너의 각 구성요소들의 제어 또는 통신에 관한 연산이나 데 이터 처리를 수행할 수 있는 구성으로써, 구강 스캐너의 구성요소들과 작동적으로 연결될 수 있다. 또한, 프로세서는 구강 스캐너의 다른 구성요소로부터 수신된 명령 또는 데이터를 메모리에 로드하고, 메모리에 저장된 명령 또는 데이터를 처리하고, 결과 데이터를 저장할 수 있다. 구강 스캐너의 메모리는, 앞서 설명된 프로세서의 동작에 대한 인스트럭션들을 저장할 수 있다. 구강 스캐너의 통신 회로는, 외부 장치(예: 전자 장치)와 유선 또는 무선 통신 채널을 설립하고, 외부 장치와 다양한 데이터를 송수신할 수 있다. 일 실시예에서, 통신 회로는 외부 장치와 유 선으로 통신하기 위해서, 외부 장치와 유선 케이블로 연결되기 위한 적어도 하나의 포트를 포함할 수 있다. 이 경우, 통신 회로는 적어도 하나의 포트를 통하여 유선 연결된 외부 장치와 통신을 수행할 수 있다. 다른 일 실시예에서, 통신 회로는 셀룰러 통신 모듈을 포함하여 셀룰러 네트워크(예: 3G, LTE, 5G, Wibro 또는 Wimax)에 연결되도록 구성할 수 있다. 또 다른 일 실시예에서, 통신 회로는 근거리 통신 모듈을 포함하여 근거리 통신(예를 들면, Wi-Fi, Bluetooth, Bluetooth Low Energy(BLE), UWB)을 이용해 외부 장치와 데이터 송 수신을 할 수 있다. 또 다른 일 실시예에서, 통신 회로는 비접촉식 통신을 위한 비접촉 통신 모듈을 포함 할 수 있다. 여기서, 비접촉식 통신은, 예를 들면, NFC(near field communication) 통신, RFID(radio frequency identification) 통신 또는 MST(magnetic secure transmission) 통신과 같이 적어도 하나의 비접촉 방식의 근접 통신 기술을 포함할 수 있다. 앞서 설명된 다양한 예시들 외에도, 외부 장치와 통신하기 위한 공 지된 다양한 방식으로 구강 스캐너가 구현될 수 있으며, 앞서 설명된 예시들에 본 개시의 범위가 제한되는 것은 아님을 유의해야 한다.구강 스캐너의 광원은, 환자의 구강을 향해 광을 조사할 수 있다. 예를 들어, 광원으로부 터 조사되는 광은 소정 패턴(예: 서로 다른 색상의 직선 무늬가 연속적으로 나타나는 스트라이프 패턴)을 갖는 구조광일 수 있다. 여기서, 구조광의 패턴은, 예를 들어, 패턴 마스크 또는 DMD(digital micro-mirror device)를 이용하여 생성될 수 있지만, 이에 제한되는 것은 아니다. 구강 스캐너의 카메라는, 환자의 구강에 의해 반사된 반사광을 수신함으로써, 환자의 구강에 대한 이미지를 획득할 수 있다. 여기서, 카메라는, 예를 들어, 광 삼각 측량 방식에 따라서 3차원 이미지 를 구축하기 위하여, 좌안 시야에 대응되는 좌측 카메라 및 우안 시야에 대응되는 우측 카메라를 포함할 수 있 다. 또한 여기서, 카메라는, CCD 센서 또는 CMOS 센서와 같은 적어도 하나의 이미지 센서를 포함할 수 있 다. 구강 스캐너의 입력 장치는, 구강 스캐너를 제어하기 위한 사용자 입력을 수신할 수 있다. 예 를 들어, 입력 장치는 사용자의 푸시 조작을 수신하는 버튼, 사용자의 터치를 감지하는 터치 패널, 마이크를 포함하는 음성 인식 장치를 포함할 수 있다. 이때, 사용자는 입력 장치를 이용하여 스캔 시작 또는 정지를 제어할 수 있다. 입력 장치를 통해 제어되는 구강 스캐너의 동작을 보다 구체적으로 설명하면, 구강 스캐너는, 구강 스캐너의 입력 장치 또는 전자 장치의 입력 장치를 통해 스캔을 시작하기 위한 사용 자 입력을 수신하고, 구강 스캐너의 프로세서 또는 전자 장치의 프로세서에서의 처리에 따 라, 스캔을 시작할 수 있다. 여기서, 사용자가 구강 스캐너를 통해 환자의 구강 내부를 스캔하는 경우, 구강 스캐너는 환자의 구강에 대한 2차원 이미지를 생성할 수 있고, 실시간으로 환자의 구 강에 대한 2차원 이미지를 전자 장치로 전송할 수 있다. 이때, 전자 장치는 수신한 환자의 구강 에 대한 2차원 이미지를 디스플레이를 통해 표시할 수 있다. 또한, 전자 장치는 환자의 구강에 대한 2차원 이미지에 기초하여, 환자의 구강에 대한 3차원 이미지를 생성(구축)할 수 있으며, 구강에 대한 3차원 이미지를 디스플레이를 통해 표시할 수 있다. 이때, 전자 장치는 생성되고 있는 3차원 이미지 를 실시간으로 디스플레이를 통해 표시할 수도 있다. 구강 스캐너의 센서 모듈은, 구강 스캐너의 작동 상태 또는 외부의 환경 상태(예: 사용자의 동 작)를 감지하고, 감지된 상태에 대응하는 전기 신호를 생성할 수 있다. 센서 모듈은, 예를 들어, 자이로 센서, 가속도 센서, 제스처 센서, 근접 센서 또는 적외선 센서 중 적어도 하나를 포함할 수 있다. 여기서, 사 용자는 센서 모듈을 이용하여 스캔 시작 또는 정지를 제어할 수 있다. 구체적인 예를 들어, 사용자 가 구강 스캐너를 손에 쥐고 움직이는 경우, 구강 스캐너는 센서 모듈을 통해 측정된 각속 도가 설정 값을 초과할 때, 프로세서 스캔 동작을 시작하도록 제어할 수 있다. 이하 도 3을 참조하여, 지금까지 설명된 구강 스캐너를 보다 구체적으로 설명하기로 한다. 도 3은 본 개 시의 일 실시예에 따른 구강 스캐너를 도시한다. 도 3에 도시된 구강 스캐너는, 본체 및 프로브 팁을 포함할 수 있다. 여기서, 구강 스캐너 의 본체는, 사용자가 손으로 그립하여 사용하기 용이한 모양으로 형성될 수 있고, 프로브 팁 은, 환자의 구강으로의 인입과 그로부터의 인출이 용이한 모양으로 형성될 수 있다. 또한, 본체(21 0)는 프로브 팁과 결합 및 분리될 수 있다. 또한, 본체 내부에는, 도 2에서 설명된 구강 스캐너 의 구성요소들이 배치될 수 있다. 이러한, 본체의 일측 단부에는 광원으로부터 출력된 광이 환 자에 조사될 수 있도록 개구된 개구부가 형성될 수 있다. 이렇게 개구부를 통해 조사된 광은, 환자에 의해 반사되어 다시 개구부를 통해 유입될 수 있다. 여기서, 개구부를 통해 유입된 반사광은 카메라에 의해 캡 쳐되어 환자에 대한 이미지를 생성할 수 있다. 또한, 사용자는 구강 스캐너의 입력 장치(예: 버튼)를 이용하여 스캔을 시작할 수 있다. 예를 들어, 사용자가 입력 장치를 터치하거 나 가압하는 경우, 광원으로부터 광이 환자에 조사될 수 있다. 도 4는 본 개시의 다양한 실시예에서 참조될 수 있는 환자의 구강에 대한 3차원 이미지의 생성 동작을 설명 하기 위한 도면을 도시한다. 앞서 설명된 바와 같이, 사용자는 구강 스캐너를 움직여가면서 환자(2 0)의 구강 내부를 스캔할 수 있고, 이 경우, 구강 스캐너는 환자의 구강에 대한 2차원 이미지 셋(30 0)을 획득할 수 있다. 예를 들어, 구강 스캐너는 환자의 앞니가 포함된 영역에 대한 2차원 이미지, 환자의 어금니가 포함된 영역에 대한 2차원 이미지 등을 획득할 수 있다. 이때, 구강 스캐너는 획득 한 2차원 이미지 셋을 전자 장치로 전송할 수 있다.전자 장치는, 2차원 이미지 셋을 이용하여, 환자의 구강에 대한 2차원 이미지 셋에 포함된 2차원 이미지 각각을 3차원 좌표 값을 갖는 복수의 포인트들의 집합으로 변환할 수 있다. 예를 들어, 전자 장 치는 2차원 이미지 셋에 포함된 2차원 이미지 각각을, 3차원 좌표 값을 갖는 데이터 포인트의 집합인 포인트 클라우드(point cloud)로 변환할 수 있다. 여기서, 2차원 이미지 셋을 기초로 하는 3차원 좌표값 인 포인트 클라우드는, 환자의 구강에 대한 로우 데이터(raw data)로서 저장될 수 있다. 또한, 전자 장치 는, 3차원 좌표값을 갖는 데이터 포인트의 집합인 포인트 클라우드를 정렬(align)함으로써, 환자의 구 강에 대한 3차원 이미지를 생성할 수 있다. 일 실시예에서, 전자 장치는 구강에 대한 3차원 이미지를 재구성(재구축)할 수 있다. 예를 들어, 전 자 장치는 푸아송 알고리즘을 사용하여, 로우 데이터로서 저장된 포인트 클라우드를 병합함으로써, 복수의 포인트들을 재구성하고, 폐쇄된 3차원 표면으로 변환하여 환자의 구강에 대한 3차원 이미지를 재구성 할 수 있다. 다만, 본 예시와 달리, 로우 데이터를 얼마든지 공지된 다양한 방식에 따라 가공할 수 있으며, 구 강에 대한 3차원 이미지를 재구성하기 위한 방식이라면 어떠한 방식이라도 본 개시의 범위에 포함될 수 있 음을 유의해야 한다. 도 5는 본 개시의 다양한 실시예에서 참조될 수 있는 색조 가이드를 도시한다. 여기서, 색조 가이드(50 0)는, 기준 색상을 나타내는 모형의 집합일 수 있다. 구체적으로, 색조 가이드는, 제1 기준 색상을 나타 내는 제1 모형 및 제2 기준 색상을 나타내는 제2 모형을 포함할 수 있다. 색조 가이드는, 예를 들어, VITA classical A1-D4® shade guide일 수 있다. 이 VITA classical A1-D4® shade guide는 16개의 기준 색상을 제각기 나타내는 16개의 모형의 집합일 수 있다. 다른 예를 들어, 색조 가 이드는, VITA SYSTEM 3D-MASTER®일 수 있다. 상술한 예시 외에도 다양한 모형의 집합이 색조 가이드 가 될 수 있고, 환자의 치아를 자연스럽게 표현하기 위한 기준 색상을 나타내는 모형의 집합이라면 얼마든 지 본 개시의 범위에 포함될 수 있다. 본 개시에서, 도 5의 색조 가이드에 표현된 기준 색상의 집합은 기준 색상 그룹으로 지칭될 수 있다. 이 러한 기준 색상 그룹은, 도 6 이하의 도면을 참조하여 설명될 방법에 있어서, 환자의 치아의 색상 분류의 기준, 즉, 라벨(Label)로 이용될 수 있다. 이하에서는, 본 개시의 다양한 실시예에 따른 방법에 대하여 상세하게 설명한다. 이하의 도면에서 동작들이 특 정한 순서로 도시되어 있지만, 반드시 동작들이 도시된 특정한 순서로 또는 순차적 순서로 실행되어야만 하거나 또는 모든 도시된 동작들이 실행되어야만 원하는 결과를 얻을 수 있는 것은 아님을 유의해야 한다. 또한, 이하의 도면을 참조하여 설명될 방법의 동작은 컴퓨팅 장치에 의해 수행될 수 있다. 다시 말하면, 방법 의 동작은 컴퓨팅 장치의 프로세서에 의해 실행되는 하나 이상의 인스트럭션들로 구현될 수 있다. 이러한 방법 에 포함되는 모든 동작은 하나의 물리적인 컴퓨팅 장치에 의하여 실행될 수도 있을 것이나, 방법의 제1 동작은 제1 컴퓨팅 장치에 의하여 수행되고, 방법의 제2 동작은 제2 컴퓨팅 장치에 의하여 수행될 수도 있다. 이하에서는, 전술한 방법의 동작이 도 1에 도시된 전자 장치에 의해 수행되는 것을 가정하여 설명한다. 다만, 설명의 편의상, 방법에 포함되는 동작의 주체가 생략될 수 있으나, 문맥상 다르게 뜻하지 않는 한, 전자 장치에 의해 동작이 수행되는 것으로 해석되어야 한다. 도 6은 본 개시의 일 실시예에 따른 방법을 나타내는 순서도를 도시한다. 도 6에 도시된 방법은, 환자의 치아의 대표 색상 정보를 결정하여 보철물의 제작을 요청하는 일련의 동작들을 포함할 수 있다. 이하, 도 6에 도시된 동작들에 대해 설명한다. 2차원 이미지 셋에 기초하여, 객체의 3차원 이미지가 생성될 수 있다(S610). 2차원 이미지 셋은, 구강 스캐너로부터 획득된 2차원 이미지의 집합일 수 있다. 이러한 2차원 이미지 셋 에 포함된 2차원 이미지 각각은, 객체(예: 환자의 구강)의 적어도 일부에 대한 2차원 이미지를 포함할 수 있다. 객체는 복수의 단위 객체(예: 개별 치아)를 포함할 수 있기 때문에, 2차원 이미지 셋에 포함된 2차원 이 미지 각각은, 단위 객체의 적어도 일부에 대한 2차원 이미지를 포함할 수도 있다. 3차원 이미지는 2차원 이미지 셋을 처리하여 생성된 이미지일 수 있다. 이러한 3차원 이미지의 생성에 있어서, 2차원 이미지 셋에 포함된 적어도 일부의 2차원 이미지가 3차원 이미지의 생성에 이용될 수 있다. 다시 말해, 2차원 이미지 셋에 포함된 적어도 일부의 2차원 이미지는 3차원 이미지의 생성에 이용되지 않을 수 있다. 3차 원 이미지의 생성에 관한 구체적인 설명은 상술한 도 4에 관한 설명을 참조하여 이해될 수 있다.3차원 이미지의 제1 포인트에 대한 사용자의 선택에 기초하여, 제1 포인트를 포함하는 제1 영역에 대응되는 제1 색상 정보 셋이 추출될 수 있다(S620). 제1 포인트는 사용자의 선택에 기초하여 결정된 포인트로서, 3차원 이미지 상의 어느 한 포인트일 수 있다. 이러한, 제1 포인트의 선택을 위해, 전자 장치는 디스플레이에 3차원 이미지를 표시하거나 입력 장치 를 통해 사용자의 선택을 받는 사용자 인터페이스를 구현할 수 있다. 사용자의 선택은, 3차원 이미지 상의 어느 한 포인트를 선택하는 입력일 수 있다. 이러한 사용자의 선 택은, 예를 들어, 3차원 이미지 상의 어느 한 포인트에 대한 클릭일 수 있으나 이에 국한되지 않고, 3차원 이미 지 상의 어느 한 포인트를 선택하게끔 정의된 동작이라면 어떠한 동작이라도 본 개시의 범위에 포함될 수 있다. 제1 영역은, 제1 포인트의 결정에 따라 동적으로 결정되는 3차원 이미지 상의 어느 한 영역일 수 있다. 일 실 시예에서, 제1 영역은 제1 포인트로부터 기준 거리 이내의 복수의 포인트를 포함하는 영역일 수 있다. 기준 거 리는 제1 영역의 반경을 결정하는 요소로서, 예를 들어, 2mm일 수 있다. 이 예시에 따르면, 제1 포인트로부터 2mm 내에 있는 복수의 포인트를 전부 포함하도록 제1 영역이 결정될 수 있다. 기준 거리는 3차원 이미지가 전 자 장치의 디스플레이 상에 표시되는 2차원 영역 상의 거리에 대응할 수 있으며, 이에 따라 제1 영역 은 제1 포인트가 중심이고 기준 거리가 반경인 정확한 원의 형태로 전자 장치의 디스플레이 상에 표 시될 수 있으나, 3차원 이미지 상에 투사된 제1 영역은 정확한 원의 형태를 가지지 않을 수 있다. 제1 색상 정보 셋은, 제1 색상 정보의 집합일 수 있다. 또한, 제1 색상 정보는, 제1 영역과 관계된 2차원 이미 지에 포함된 픽셀의 색상 코드(예: RGB 코드, HSV 코드 등)로부터 생성되는 정보일 수 있다. 즉, 제1 색상 정 보 셋은, 제1 영역과 관계된 색상 코드의 집합일 수도 있다. 제1 색상 정보의 생성 및 제1 색상 정보 셋의 생 성에 관해서는 추후 도 7 내지 8을 참조하여 설명한다. 본 동작에 따르면, 3차원 이미지 상의 사용자가 의도하는 지점(즉, 제1 포인트)의 색상에 관한 정보가, 그 지점을 기준으로 결정된 영역(즉, 제1 영역)과 관계된 색상 코드의 집합으로서 추출될 수 있다. 따라서, 사용 자가 의도하는 치아에 관계된 색상 코드의 집합이 추출될 수 있다. 제1 영역의 결정과 관련하여, 일 실시예에서, 제1 영역에 예외 영역이 포함되면, 예외 영역을 제외한 제1 영역 에 대응되는 제1 색상 정보 셋이 추출될 수 있다. 3차원 이미지는, 사용자의 관심 영역인 유효 영역(예: 치아 영역) 및 관심 영역을 제외한 영역인 예외 영역(예: 치은 영역)을 포함할 수 있다. 이와 같은 관점에 기 초하여 본 실시예에 따르면, 제1 영역에 사용자의 관심 영역이 아닌 예외 영역이 포함되더라도, 예외 영역 에 관계된 색상 코드는 배제된 제1 색상 정보 셋이 추출될 수 있다. 이에 따라, 치아의 색상과 무관한 치은의 색상에 관한 정보가 배제됨으로써, 후술될 동작들에 따라 치아의 대표 색상 정보가 신뢰도 높게 결정될 수 있다. 또한, 본 실시예를 구현하기 위해, 2차원 이미지 또는 3차원 이미지 상에서 치아 영역과 치은 영역을 구 별하는 기술이 참조될 수 있다. 흰색 계열로 표현되는 치아 영역과 붉은색 계열로 표현되는 치은 영역은 색상 의 차이 등에 기초하여 구별될 수 있으며, 예를 들어, 치아 영역과 치은 영역을 구별하기 위해 최적화된 인공지 능 모델이 본 개시에 참조될 수 있다. 일 실시예에서, 제1 영역에 두 개 이상의 치아가 포함되더라도(예: 제1 포인트가 두 개의 치아 사이의 경계에 가까운 곳에 지정된 경우), 제1 포인트를 포함되지 않은 치아의 영역에 관계된 색상 코드도 제1 색상 정보 셋으로서 추출될 수 있다. 이 경우, 흰색 계열로 표현되는 치아의 구분을 위해 소모되는 컴퓨팅 리소스가 절약될 수 있다. 또한, 동일 치아 내의 제1 포인트로부터 상대적으로 멀리 떨 어진 포인트보다, 다른 치아라도 제1 포인트로부터 인접한 포인트가 제1 포인트의 색상과 더 유사할 가능성이 높으므로, 사용자가 의도하는 제1 포인트에 대해 정확한 제1 색상 정보 셋이 추출될 수 있다. 다른 일 실시예 에서, 제1 영역에 두 개 이상의 치아가 포함되면(예: 제1 포인트가 두 개의 치아 사이의 경계에 가까운 곳에 지 정된 경우), 제1 포인트가 포함되지 않은 치아의 영역에 관계된 색상 코드는 배제된 제1 색상 정보 셋이 추출될 수 있다. 이 경우, 사용자가 의도하는 치아의 색상에 부합하도록 제1 색상 정보 셋이 추출될 수 있다. 제1 색상 정보 셋의 입력에 기초하여, 색상 유사도를 출력하는 인공지능 모델이 이용될 수 있다(S630). 이러한 인공지능 모델에는, 예를 들어, 제1 색상 정보 셋(즉, 입력 색상 정보)을 기준 색상 그룹에 포함된 어느 하나의 기준 색상으로 분류하는 분류 모델이 참조될 수 있다. 이에 관해서는 추후 도 10 내지 도 12를 참조하여 설명 한다. 색상 유사도는, 제1 색상 정보 셋이 기준 색상과 유사한 정도를 나타내는 수치일 수 있다. 예를 들어, 색상 유 사도가 상대적으로 높으면 제1 색상 정보 셋과 상대적으로 유사한 기준 색상으로 이해될 수 있고, 색상 유사도 가 상대적으로 낮으면 제1 색상 정보 셋과 상대적으로 비유사한 기준 색상으로 이해될 수 있다.색상 유사도와 관련하여, 일 실시예에서, 제1 색상 정보 셋은 제1 색상 정보의 집합이므로, 하나 이상의 제1 색 상 정보 각각과 기준 색상의 유사도(즉, 서브 색상 유사도)에 기초하여(예를 들어 서브 색상 유사도들의 평균을 산출함으로써), 색상 유사도가 산출될 수 있다. 이에 관해서는 추후 도 9를 참조하여 설명한다. 기준 색상 그룹은 기준 색상의 집합일 수 있으므로, 본 동작에 따르면, 제1 기준 색상과 제1 색상 정보 셋의 색 상 유사도가 산출될 수 있고, 제2 기준 색상과 제1 색상 정보 셋의 색상 유사도가 산출될 수 있다. 다시 말해, 본 동작에 따르면, 기준 색상 그룹에 포함된 기준 색상 마다 제1 색상 정보 셋에 관한 색상 유사도가 산출될 수 있다. 일 실시예에서, 기준 색상 그룹 내의 모든 기준 색상들과의 제1 색상 정보 셋의 색상 유사도의 총합이 일정 수치(예: 1)가 되도록 색상 유사도가 산출될 수 있다. 색상 유사도 크기에 기초하여, 제1 포인트에 대응되는 제1 단위 객체의 대표 색상 정보가 결정될 수 있다 (S640). 제1 단위 객체는, 객체에 포함된 단위 객체의 일종으로서, 제1 포인트를 포함하는 단위 객체(예: 치아)일 수 있 다. 즉, 제1 단위 객체는, 사용자의 관심의 대상이 되는 단위 객체일 수 있다. 대표 색상 정보는, 제1 단위 객체를 대표하는 색상 정보일 수 있다. 이 대표 색상 정보는 후술될 동작에 따라, 외부 단말(예: 치기공소 단말)에 전송됨으로써, 보철물의 색상을 결정하는 정보로써 이용될 수 있다. 본 동작에 따르면, 예를 들어, 색상 유사도의 크기가 가장 큰 기준 색상이 대표 색상 정보로 결정될 수 있으므 로, 제1 단위 객체의 실제 색상과 가장 유사할 것으로 추정되는 기준 색상으로 대표 색상 정보가 결정될 수 있 다. 제1 단위 객체의 대표 색상 정보가 외부 단말(예: 치기공소 단말, 클라우드 서버)에 전송될 수 있다(S650). 본 동작에 따르면, 제1 단위 객체에 대응하여 결정된 대표 색상 정보가 동적으로 외부 단말에 전송됨으로써, 보 철물의 제작을 위한 별도의 요청 없이도, 보철물의 제작이 개시될 수 있다. 구체적인 예를 들어, 제1 단위 객체의 대표 색상 정보가 치기공소 단말에 전송될 수 있다. 다른 예를 들어, 제 1 단위 객체의 대표 색상 정보가 클라우드 서버를 경유하여 치기공소 단말에 전송될 수 있다. 도 7은 도 6을 참조하여 설명된 색상 정보 셋의 추출 동작을 구체적으로 설명하기 위한 순서도를 도시한다. 도 7에 도시된 방법(S700)은, 도 6에 도시된 제1 색상 정보 셋의 추출 동작(S620)의 세부 동작들로서, 제1 색상 정 보의 생성 및 제1 색상 정보 셋의 생성에 관한 일련의 동작들을 포함할 수 있다. 이하, 도 7에 도시된 동작들 에 대해 설명한다. 제1 영역에 대응되는 제1 2차원 이미지 셋이 식별될 수 있다(S710). 제1 2차원 이미지 셋은, 구강 스캐너로부터 수신된 2차원 이미지 셋의 서브 셋일 수 있다. 다시 말해, 제 1 2차원 이미지 셋은, 구강 스캐너로부터 수신된 2차원 이미지 셋 중 제1 영역에 관계된 2차원 이미지의 집합일 수 있다. 본 동작에 따르면, 제1 영역에 포함된 복수의 포인트의 포인트 클라우드를 조회함으로써, 제1 2차원 이미지 셋 이 식별될 수 있다. 제1 2차원 이미지 셋과 관련하여, 일 실시예에서, 제1 2차원 이미지 셋은 3차원 이미지의 생성에 이용된 2차원 이미지만을 포함할 수 있다. 3차원 이미지의 생성에 있어서, 구강 스캐너로부터 수신된 2차원 이미지 셋 중 일부만이 이용될 수 있으므로, 3차원 이미지의 생성에 이용된 2차원 이미지만을 제1 2차원 이미지 셋에 포함 시키도록 할 수 있다. 본 실시예에 따르면, 3차원 이미지의 생성에 이용되지 않은 2차원 이미지, 예를 들어, 노이즈가 다수 포함된 이미지가 배제될 수 있다. 제1 2차원 이미지 셋에 포함된 2차원 이미지의 픽셀의 색상 코드에 기초하여, 제1 색상 정보가 생성될 수 있다 (S720). 본 동작에 따르면, 제1 영역과 관계된 2차원 이미지, 그 중에서도 3차원 이미지의 생성에 이용된 2차원 이미지 의 픽셀의 색상 코드가 추출될 수 있다. 이렇게 추출된 색상 코드는, 제1 색상 정보의 생성에 이용될 수 있다. 제1 색상 정보의 생성 시점과 관련하여, 일 실시예에서, 2차원 이미지의 픽셀이 색상 코드로서 전부 추출된 이 후에, 추출된 색상 코드의 개수가 기준 크기가 되도록 제1 색상 정보가 생성될 수 있다. 여기서, 기준 크기는, 제1 색상 정보의 정의된 크기일 수 있다. 예를 들어, 기준 크기는, 128 x 128, 즉, 16,384일 수 있다. 이러한기준 크기는, 추후 설명될 인공지능 모델의 입력 데이터로서 적합하도록 얼마든지 변형될 수 있다. 본 실시예 에 따르면, 추출된 색상 코드가 임의의 순서(예: 2차원 이미지의 스캔 순서, 색상 코드의 추출 순서 등)에 의해 제1 색상 정보의 일 항목으로서 순차적으로 할당될 수 있다. 예를 들어, 기준 크기가 128 x 128이면, 최초의 색상 코드는 제1 색상 정보의 [ 1, 1 ]에 할당될 수 있고, 후순위의 색상 코드는 [ 1, 2 ]에 할당될 수 있다. 이와 같은 순서에 따라, 제1 색상 정보의 [ 128, 128 ]에 대한 할당까지 수행될 수 있다. 이처럼 [ 128, 128 ]에 대한 할당이 완료되면, 제1 색상 정보(즉, 패치)의 생성이 완료될 수 있다. 만약, 제1 색상 정보의 생성 이 완료되었음에도 추출된 잔여 색상 코드가 남아 있다면, 상술한 방식과 동일한 방식으로, 추가의 제1 색상 정 보가 생성될 수 있다. 일 실시예에서, 추출된 잔여 색상 코드의 개수가 하나의 제1 색상 정보를 생성하기에 부 족하다면(위의 예에서 16,384개 미만이라면), 추출된 잔여 색상 코드는 삭제될 수 있다. 제1 색상 정보의 생성 시점과 관련하여, 다른 일 실시예에서, 2차원 이미지의 픽셀에 기초한 색상 코드의 추출 횟수가 기준 크기가 될 때마다 제1 색상 정보가 생성될 수 있다. 즉, 색상 코드의 추출과 제1 색상 정보의 생 성이 병렬적으로 수행될 수 있다. 본 실시예에 따르면, 순차적으로 추출된 색상 코드가 제1 색상 정보의 일 항 목으로서 순차적으로 할당될 수 있다. 예를 들어, 기준 크기가 128 x 128이면, 최초로 추출된 색상 코드는 제1 색상 정보의 [ 1, 1 ]에 할당될 수 있고, 후속하여 추출된 색상 코드는 [ 1, 2 ]에 할당될 수 있다. 이와 같은 순서에 따라, 제1 색상 정보의 [ 128, 128 ]에 대한 할당까지 수행될 수 있다. 이처럼 [ 128, 128 ]에 대한 할 당이 완료되면, 제1 색상 정보(즉, 패치)의 생성이 완료될 수 있다. 만약, 잔여 색상 코드가 존재하는 경우, 이에 대해서는, 전술한 실시예에 관하여 설명된 기술적 사상이 본 실시예에도 그대로 적용될 수 있다. 제1 색상 정보의 생성 시점과 관련하여, 상술한 실시예 외에도 얼마든지 다양한 변형이 있을 수 있다. 예를 들 어, 2차원 이미지의 픽셀이 색상 코드로서 적어도 일부가 추출된 이후에, 추출된 색상 코드의 개수가 기준 크기 가 되도록 제1 색상 정보가 생성될 수 있다. 즉, 제1 색상 정보의 생성 시점은 실제 구현 사례에 따라 달라질 수 있다. 색상 코드의 추출 방식과 관련하여, 일 실시예에서, 2차원 이미지의 전체 픽셀이 색상 코드로서 추출될 수 있다. 다른 일 실시예에서, 2차원 이미지의 적어도 일부 픽셀이 색상 코드로서 추출되지 않을 수도 있다. 상 술한 예시 외에도, 제1 영역과 관계된 픽셀의 색상 코드를 추출하기 위한 규칙이라면, 어떠한 규칙이라도 본 개 시의 범위에 포함될 수 있다. 추출된 색상 코드가 HSV 코드로 변환될 수 있다(S730). HSV 코드란, 색상을 표현하는 하나의 기준일 수 있다. 이러한 HSV 코드는, 색상(Hue), 채도(Saturation) 및 명 도(Value)를 각각 하나의 좌표로서 포함하는 3차원 코드일 수 있다. 본 동작에 따르면, 예를 들어, RGB 코드로 추출된 색상 코드가 HSV 코드로 변환될 수 있다. 만약, HSV 코드로 추출되었다면, 이 동작이 생략될 수 있다. 일 실시예에서, HSV 코드로의 변환 시점은, 색상 코드 추출 후의 임의의 시점일 수 있다. 예를 들어, 색상 코 드가 추출될 때마다 HSV 코드로 변환될 수 있다. 다른 예를 들어, 제1 색상 정보의 생성이 완료된 후, 제1 색 상 정보에 포함된 색상 코드 전부가 한 번에 HSV 코드로 변환될 수도 있다. 또 다른 예를 들어, 제1 색상 정보 셋의 생성이 완료된 후, 제1 색상 정보 셋에 포함된 색상 코드 전부가 한 번에 HSV 코드로 변환될 수도 있다. 도 8은 도 7을 참조하여 설명된 색상 코드의 추출 동작을 구체적으로 설명하기 위한 순서도를 도시한다. 도 8 에 도시된 방법(S800)은, 도 7에 도시된 제1 색상 정보의 생성 동작(S720)의 세부 동작들을 포함할 수 있다. 이하, 도 8에 도시된 동작들에 대해 설명한다. 스캔 순서에 기초하여, 제1 2차원 이미지 셋에 포함된 2차원 이미지의 추출 순서가 결정될 수 있고(S810), 추출 순서에 기초하여, 제1 2차원 이미지 셋에 포함된 2차원 이미지의 픽셀의 색상 코드가 순차적으로 추출될 수 있 다(S820). 스캔 순서는, 구강 스캐너로부터 스캔된 순서일 수 있다. 또한, 추출 순서는 제1 2차원 이미지 셋에 포함 된 2차원 이미지 중 색상 코드가 추출되는 순서일 수 있다. 본 동작에 따르면, 스캔 순서에 대응되도록 차례로 제1 2차원 이미지 셋에 포함된 2차원 이미지의 추출이 수행될 수 있다. 도 9는 도 6을 참조하여 설명된 인공지능 모델의 이용 동작을 구체적으로 설명하기 위한 순서도를 도시한다. 도 9에 도시된 방법(S900)은, 도 6에 도시된 인공지능 모델의 이용 동작(S630)의 세부 동작들로서, 인공지능 모 델을 통해 처리되는 기준 색상 그룹과 제1 색상 정보 셋의 유사도 산출에 관한 일련의 동작들을 포함할 수있다. 이하, 도 9에 도시된 동작들에 대해 설명한다. 기준 색상 그룹에 포함된 기준 색상 각각과 제1 색상 정보 셋에 포함된 제1 색상 정보의 서브 색상 유사도가 산 출될 수 있다(S910). 서브 색상 유사도는, 제1 색상 정보 셋에 포함된 제1 색상 정보가 기준 색상과 유사한 정도를 나타내는 수치일 수 있다. 색상 유사도와 마찬가지로, 예를 들어, 서브 색상 유사도가 상대적으로 높으면 제1 색상 정보와 상대 적으로 유사한 기준 색상으로 이해될 수 있고, 서브 색상 유사도가 상대적으로 낮으면 제1 색상 정보와 상대적 으로 비유사한 기준 색상으로 이해될 수 있다. 본 동작에 따르면, 제1 기준 색상과 제1 색상 정보의 서브 색상 유사도가 산출될 수 있고, 제2 기준 색상과 제1 색상 정보의 서브 색상 유사도가 산출될 수 있다. 다시 말해, 본 동작에 따르면, 기준 색상 그룹에 포함된 기 준 색상 마다 제1 색상 정보에 관한 서브 색상 유사도가 산출될 수 있다. 제1 색상 정보 셋에 포함된 모든 제1 색상 정보의 서브 색상 유사도가 산출되지 않았다면(S920), 기준 색상 그 룹에 포함된 기준 색상 각각과 제1 색상 정보 셋에 포함된 다른 제1 색상 정보의 서브 색상 유사도가 산출될 수 있다(S910). 제1 색상 정보 셋은, 제1 색상 정보의 집합일 수 있으므로, 본 동작에 따르면, 제1 색상 정보 셋에 포함된 모든 제1 색상 정보의 서브 색상 유사도가 산출될 수 있다. 예를 들어, 제1 색상 정보 셋이 N개(여기서, N은 자연수)의 제1 색상 정보를 포함한다면, N개의 제1 색상 정보에 제각기 대응하는 N개의 서브 색상 유사도가 산 출될 수 있다. 제1 색상 정보 셋에 포함된 모든 제1 색상 정보의 서브 색상 유사도가 산출되었다면(S920), 서브 색상 유사도에 기초하여 색상 유사도가 산출될 수 있다(S930). 예를 들어,산출된 서브 색상 유사도를 평균함으로써, 기준 색상 그룹에 포함된 기준 색상마다의 색상 유사도가 산출될 수 있다. 예를 들어, 제1 색상 정보 셋이 N개의 제1 색상 정보를 포함한다면, 제1 기준 색상과 제1 색 상 정보 셋의 N개의 서브 색상 유사도를 평균함으로써 제1 기준 색상과 제1 색상 정보 셋에 관한 색상 유사도가 산출될 수 있고, 제2 기준 색상과 제1 색상 정보 셋의 N개의 서브 색상 유사도를 평균함으로써 제2 기준 색상과 제1 색상 정보 셋에 관한 색상 유사도가 산출될 수 있다. 다른 예로서, 산출된 서브 색상 유사도를 합산하거나, 합산 후 정규화하거나, 가중 평균하는 등, 서브 색상 유사도에 기초하여 색상 유사도를 산출하는 다양한 방법 중 하나 이상이 사용될 수 있다. 이처럼, 제1 색상 정보 셋과 기준 색상 그룹에 포함된 기준 색상마다의 색상 유사도가 산출됨으로써, 제1 색상 정보 셋과 유사한 기준 색상의 순서가, 객관적 지표로서, 산출될 수 있다. 도 10은 본 개시의 다양한 실시예에서 참조될 수 있는 인공지능 모델의 학습 동작을 설명하기 위한 도면을 도시 한다. 구체적으로, 도 10은 기준 색상 그룹에 포함된 제1 기준 색상을 나타내는 제1 라벨 및 제1 기준 색상에 대응되는 제1 모형의 제1 스캔 결과를 학습 데이터로 이용하여, 인공지능 모델을 구축하는 일례를 도시한다. 제1 라벨은 분류의 기준으로서, 구체적으로, 지도 학습(supervised learning)의 라벨일 수 있다. 예를 들어, VITA classical A1-D4® shade guide를 색조 가이드로써 이용한다면, VITA classical A1-D4® shade guide의 \"A1,\" \"A2\" 또는 \"D4\" 등이 제1 라벨이 될 수 있다. 제1 스캔 결과는 제1 라벨에 대응되는 데이터 세트로서, 제1 라벨에 대응되는 제1 기준 색상을 갖 는 제1 모형의 스캔 결과일 수 있다. 이러한 제1 스캔 결과는 상술한 제1 색상 정보와 동일한 방식으로 생성될 수 있다. 이러한 제1 스캔 결과는 인공지능 모델의 1회의 입력 단위인 패치로서, 예를 들 어, 128 x 128 크기를 갖도록 생성될 수 있다. 이와 같이, 기준 색상을 갖는 모형에 대한 스캔 결과를 학습 데 이터로 활용함으로써, 인공지능 모델을 학습하기에 충분한 양의 학습 데이터가 확보될 수 있다. 도 10에 따르면, 제1 라벨과 제1 스캔 결과가 한 쌍으로 전자 장치에 입력됨으로써, 그 전자 장치에 저장된 인공지능 모델의 학습에 제1 라벨과 제1 스캔 결과가 이용될 수 있다. 구체적으로, 제1 스캔 결과가 인공지능 모델의 입력 데이터로 이용되고, 제1 라벨이 출력 데 이터로 이용됨으로써, 제1 스캔 결과를 입력하면 제1 라벨로 분류하도록 인공지능 모델을 학 습시킬 수 있다.구체적인 예를 들어, 2개의 기준 색상을 포함하는 기준 색상 그룹이 있고, 제1 스캔 결과에 포함된 색상 코드가 2차원이라면, 제1 라벨에 대응되는 기준 색상의 유사도가 가장 크게 산출되도록, 기준 색상의 유 사도를 산출하는 2개의 가중치 셋이 조정될 수 있다. 이러한 2개의 가중치 셋 각각은 2개의 스칼라를 갖는다. 다른 예를 들어, 16개의 기준 색상을 포함하는 기준 색상 그룹이 있고, 제1 스캔 결과에 포함된 색상 코 드가 3차원이라면, 제1 라벨에 대응되는 기준 색상의 유사도가 가장 크게 산출되도록, 기준 색상의 유사 도를 산출하는 16개의 가중치 셋이 조정될 수 있다. 이러한 16개의 가중치 셋 각각은 3개의 스칼라를 갖는다. 상술한 기계 학습은 도 1에 도시된 전자 장치에서 수행될 수 있으나, 외부에서 수행되고 그 학습된 인공지 능 모델이 전자 장치에 임베드될 수도 있다. 여기서, 인공지능 모델은 제1 스캔 결과에 포함된 색상 코드에 다양한 전처리를 수행함으로써, 기 준 색상의 유사도를 산출하는 수학식에 적합한 형태로 제1 스캔 결과가 변환될 수 있다. 일 실시예에서, 제1 스캔 결과의 차원이 축소될 수 있다. 예를 들어, 제1 스캔 결과가 2 x 2 크기를 갖는 3차원의 HSV 코드라면, H, S, V 각각의 평균을 산출함으로써, 제1 스캔 결과를 간단히 [ Hav, Sav, Vav ]로 표현 할 수 있다. 다른 일 실시예에서, 제1 스캔 결과를 정규화할 수도 있다. 예시되지는 않았으나, 지도 학 습 분야에서의 학습 데이터를 전처리하는 다양한 공지된 동작들이 참조되어, 인공지능 모델의 학습 성능 을 향상시키도록 할 수 있다. 학습 데이터와 관련하여, 일 실시예에서, 학습 데이터는 제1 라벨과 제1 스캔 결과의 쌍 외에도, 제1 라벨과 제1 모형에 관한 제2 스캔 결과의 쌍을 더 포함할 수 있다. 여기서, 제2 스캔 결과의 스캔 조건(예: 스캔 각도, 조명 등)은, 제1 스캔 결과의 스캔 조건과 적어도 일부가 상이할 수 있다. 본 실시예에 따르면, 동일한 제1 모형에 대해서 스캔 조건을 달리하여 다수의 학습 데이터가 확보될 수 있다. 이로써, 다양 한 스캔 조건 하에서 취득되는 입력 색상 정보가 기준 색상 그룹 중 어느 하나로 신뢰도 높게 분류될 수 있다. 도 11 및 도 12는 본 개시의 다양한 실시예에서 참조될 수 있는 인공지능 모델 기반의 색상 유사도의 산출 동작 을 설명하기 위한 도면을 도시한다. 도 10에서 설명된 바에 따라 학습된 인공지능 모델은, 제1 색상 정보 셋을 어느 하나의 기준 색상 의 라벨로 분류할 수 있다. 제1 색상 정보 셋은 하나 이상의 제1 색상 정보를 포함하므로, 제1 색상 정보가 패치로서 인공지능 모델에 입력되면, 표와 같이, 서브 색상 유사도가 산출 될 수 있고, 제1 색상 정보 셋에 포함된 모든 제1 색상 정보에 대한 서브 색상 유사도가 산출되면, 그에 기초하여(예: 서브 색상 유사도들의 평균을 계산하여) 색상 유사도가 산출될 수 있다. 도 13은 도 6을 참조하여 설명된 대표 색상 정보의 결정 동작을 구체적으로 설명하기 위한 순서도를 도시한다. 도 13에 도시된 방법(S1300)은, 도 6에 대표 색상 정보의 결정 동작(S640)의 세부 동작을 포함할 수 있다. 이 하, 도 13에 도시된 동작들에 대해 설명한다. 색상 유사도의 크기에 기초하여, 추천 색상 정보가 결정될 수 있다(S1310). 추천 색상 정보는, 사용자가 선택한 제1 포인트에 대응되는 제1 단위 객체에 대하여 추천 가능한 기준 색상 일 수 있다. 추천 색상 정보는, 색상 유사도의 크기의 순서대로 결정될 수 있다. 이러한 추천 색상 정보는, 사용자가 인식 가능한 형태로 전자 장치의 디스플레이에 표시됨으로써, 사용자에게 추천될 수 있다. 추천 색상 정보의 개수와 관련하여, 일 실시예에서, 추천 색상 정보의 개수는, 사용자의 선택 편의를 위해 제한될 수 있다. 즉, 추천 색상 정보의 개수가 많아지면, 사용자의 선택이 상대적으로 어려워질 수 있으므 로, 추천 색상 정보의 개수가 소정의 규칙에 따라 제한될 수 있다. 예를 들어, 색상 유사도의 크기의 순서대로 상위의 M개(여기서, M은 자연수)의 기준 색상이 추천 색상 정보로서 결정될 수 있다. 여기서, M은 3일 수 있으나, 실제 구현 사례에 따라 추천 색상 정보의 개수는 얼마든지 달라 질 수 있다. 다른 예를 들어, 색상 유사도의 크기가 기준치를 초과하는 기준 색상이 추천 색상 정보로서 결정될 수 있다. 다시 말해, 색상 유사도의 크기가 기준치 이하인 기준 색상은 추천 색상 정보에 포함되지 않을 수 있다. 이때, 색상 유사도의 크기가 기준치를 초과하는 기준 색상 중에서 색상 유사도의 크기의 순서대로 상위의 최대 M개까 지 추천 색상 정보로서 결정될 수 있다(즉, 기준치를 초과하는 기준 색상이 M개 미만이라면, 기준치를 초과하는 M개 미만의 기준 색상만이 추천 색상 정보로 결정됨). 색상 유사도가 기준치보다 낮은 경우는, 사용자로부터 추천 색상 정보가 실제 치아의 색상과 비유사하다고 판단될 수 있는 경우이므로, 본 동작에 따르면, 색상 유 사도의 크기가 기준치 이하인 기준 색상을 추천 색상 정보에 포함하지 않음으로써, 사용자가 체감하는 추천 의 신뢰도를 향상시킬 수 있다. 추천 색상 정보에 대한 사용자의 선택에 기초하여, 대표 색상 정보가 결정될 수 있다(S1320). 본 동작에 따르면, 색상 유사도의 크기가 가장 큰 기준 색상 정보라고 하더라도 사용자의 의도에 부합하지 않을 가능 성을 고려하여, 색상 유사도의 크기에 따라 자동으로 대표 색상 정보를 결정하는 대신, 추천 색상 정보로서 추 천된 것들 중 어느 하나를 사용자가 직접 선택하게 할 수 있게 된다. 이로써, 치아의 색상에 대한 결정이 라는 객관적 정보와 사용자의 임상적 경험을 조화시킬 수 있다. 도 14는 본 개시의 일 실시예에 따른 방법을 나타내는 순서도를 도시한다. 도 14는 객체의 3차원 이미지 상의 복수의 포인트(예: 제1 포인트, 제2 포인트)에 대한 사용자의 선택에 기초하여 유발되는 일련의 동작들을 포함할 수 있다. 이하, 도 14에 도시된 동작들에 대해 설명한다. 2차원 이미지 셋에 기초하여, 객체의 3차원 이미지가 생성될 수 있다(S1410). 본 동작은, 도 6의 3차원 이미지 의 생성 동작(S610)에 관한 설명을 참조하여 이해될 수 있다. 3차원 이미지의 제1 포인트 및 제2 포인트에 대한 사용자의 선택에 기초하여, 제1 포인트를 포함하는 제1 영역에 대응되는 제1 색상 정보 셋 및 제2 포인트를 포함하는 제2 영역에 대응되는 제2 색상 정보 셋이 추출될 수 있다(S1420). 제2 포인트는 제1 단위 객체에 포함된 어느 하나의 포인트로서, 제1 포인트와 구별되는 포인 트를 의미할 수 있다. 그 외에는 제2 포인트도 제1 포인트와 마찬가지로 취급될 수 있으므로, 제2 영역 및 제2 색상 정보 셋은, 각각, 제1 영역 및 제1 색상 정보 셋에 관한 도 6의 제1 색상 정보 셋을 추출하는 동작(S620) 에 관한 설명을 참조하여 이해될 수 있다. 기준 색상 그룹과 제1 색상 정보 셋의 색상 유사도가 산출될 수 있고, 기준 색상 그룹과 제2 색상 정보 셋의 색 상 유사도가 산출될 수 있다(S1430). 본 동작은, 제2 색상 정보 셋과 제1 색상 정보 셋 각각에 관하여, 개별적 으로 색상 유사도를 산출하는 것을 제외하고는 도 6의 인공지능 모델의 이용 동작(S630)과 동일하므로, 도 6의 인공지능 모델의 이용 동작(S630)에 관한 설명을 참조하여 이해될 수 있다. 색상 유사도의 크기에 기초하여, 제1 포인트 및 제2 포인트 각각에 대응되는 제1 단위 객체의 대표 색상 정보가 결정될 수 있다(S1440). 본 동작은, 제1 포인트와 제2 포인트 각각에 관하여, 개별적으로 대표 색상 정보를 결 정하는 것을 제외하고는 도 6의 대표 색상 정보의 결정 동작(S640)과 동일하므로, 도 6의 대표 색상 정보의 결 정 동작(S640)에 관한 설명을 참조하여 이해될 수 있다. 제1 단위 객체의 대표 색상 정보가 외부 단말에 전송될 수 있다(S1450). 본 동작은, 도 6의 대표 색상 정보의 전송 동작(S650)에 관한 설명을 참조하여 이해될 수 있다. 도 14에 도시된 실시예에 따르면, 하나의 치아에 대한 복수의 포인트(예: 제1 포인트, 제2 포인트)의 색상에 관 한 정보를 개별적으로 처리함으로써, 그 치아에 대한 대표 색상 정보의 결정에 있어서 그 치아의 여러 지점의 데이터를 고려할 수 있다(예: 도 18의 화면 참조). 이로써, 환자의 치아의 색상이 보다 신뢰도 높게 결정될 수 있다. 제1 포인트 및 제2 포인트를 사용자가 선택하고 나서 제1 포인트와 제2 포인트 각각에 관하여 개별적으로 대표 색상 정보를 결정하는 실시예가 도 14를 참조하여 설명되었으나, 제1 포인트만을 사용자가 선택하고 나서 제1 포인트에 관하여 대표 색상 정보를 결정한 후에, 제2 포인트를 사용자가 선택하여 제2 포인트에 관하여 대표 색 상 정보를 결정하는 경우 또는 제1 포인트에 관한 동작들과 제2 포인트에 관한 동작들이 임의의 시간 순서로 이 루어지는 경우에도 제1 포인트와 제2 포인트 각각에 대한 개별적인 동작이 동일하게 이루어질 수 있다. 도 15 내지 도 18은 본 개시의 일 실시예에 따른 방법이 적용된 프로그램의 화면을 도시한다. 도 15에 따르면, 화면은 환자의 구강(예: 상악)의 3차원 이미지를 포함할 수 있다. 이 3차원 이미지 는 유효 영역, 즉, 사용자의 관심 영역인 치아 영역과 예외 영역인 치은 영역을 포함할 수 있 다. 또한, 화면은 선택 도구를 포함할 수 있다. 사용자는 이 선택 도구를 입력 장치를 통해 이동시킴으로써, 3차원 이미지 상의 포인트를 선택할 수 있다. 이러한 선택 도구는, 사용자의 선택을 돕기 위해, 선택 도구가 위치하는 포인트를 가리키는 선택 포인트 및 선택 포인트가선택될 경우 색상에 관한 정보가 추출되는 영역을 가리키는 선택 영역을 포함할 수 있다. 도 16에 따르면, 화면은 사용자로부터 포인트가 선택되면, 그 포인트에 대응되는 치아의 추천 색상 정보를 포함할 수 있다. 이 추천 색상 정보는 사용자로부터 선택된 포인트에 대응되는 영역 에서 추출된 색상에 관한 정보로부터 결정된 것일 수 있다. 또한, 화면은 사용자의 사용성을 증진시키기 위해, 사용자가 선택한 포인트에 대응되는 치아의 색상을 수동으로 선택 가능하게 하는 버튼을 추가로 포함할 수 있다. 도 17에 따르면, 화면은 사용자가 선택한 포인트에 대응되는 치아의 대표 색상 정보를 포함할 수 있다. 사용자는 하나의 치아에 대해 복수의 포인트를 선택할 수 있다. 이 경우, 도 18에 도시된 화면과 같 이, 복수의 포인트(1810, 1820)마다 상술한 대표 색상 정보의 결정을 개별적으로 수행함으로써, 포인트마다 각 기 다른 대표 색상 정보를 결정할 수 있다. 일 실시예에서, 대표 색상 정보를 외부 단말(예: 치기공소 단말)로 전송 시에, 사용자로부터 선택된 포인트 또는 그 포인트에 대응되는 영역에 대한 정보를 함께 전송할 수 있다. 본 실시예에 따르면, 하나의 치아에 대 해 복수의 포인트가 선택될 수 있고, 그 복수의 포인트에 대응되는 대표 색상 정보가 상이할 수 있으므로, 하나 의 치아라도 각기 다른 부분 마다 서로 다른 대표 색상 정보가 적용되어 보철물의 제작이 요청될 수 있다. 본 개시의 다양한 실시예는 컴퓨팅 장치가 읽을 수 있는 저장매체(MRSM, Machine-Readable Storage Medium)에 소프트웨어로 구현될 수 있다. 소프트웨어는 본 개시의 다양한 실시예를 구현하기 위한 소프트웨어일 수 있다."}
{"patent_id": "10-2024-7027694", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "소프트웨어는 본 개시가 속하는 기술분야의 프로그래머들에 의해 본 개시의 다양한 실시예로부터 추론될 수 있 다. 예를 들어 소프트웨어는 컴퓨팅 장치가 읽을 수 있는 명령을 포함하는 컴퓨터 프로그램일 수 있다. 컴퓨 팅 장치는 저장 매체로부터 호출된 명령에 따라 동작이 가능한 장치로서, 예를 들어 전자 장치와 상호 교환적으 로 지칭될 수 있다. 일 실시예에서, 컴퓨팅 장치의 프로세서는 호출된 명령을 실행하여, 컴퓨팅 장치의 구성요 소들이 이 명령에 대응하는 기능을 수행하게 할 수 있다. 저장 매체는 기기에 의해 읽혀질 수 있는, 정보가 저 장되는 모든 종류의 기록 매체를 의미할 수 있다. 저장 매체는, 예를 들어 ROM, RAM, CD-ROM, 자기 테이프, 플 로피 디스크 또는 광 정보 저장장치 등을 포함할 수 있다. 일 실시예에서, 저장매체는 네트워크로 연결된 컴퓨 터 시스템 등에 분산된 형태로서 구현될 수 있다. 이때, 소프트웨어는 컴퓨터 시스템 등에 분산되어 저장되고, 실행될 수 있다. 다른 일 실시예에서, 저장 매체는 비일시적(non-transitory) 저장매체일 수 있다. 비일시적 저장매체는, 정보가 반영구적 또는 임시적으로 저장되는 것과 무관하게 실재하는 매체를 의미하며, 일시적 (transitory)으로 전파되는 신호를 포함하지 않는다. 이상 다양한 실시예에 의해 본 개시에 따른 기술적 사상이 설명되었지만, 본 개시에 따른 기술적 사상은 본 개"}
{"patent_id": "10-2024-7027694", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "시가 속하는 기술분야에서 통상의 지식을 가진 자가 이해할 수 있는 범위에서 이루어질 수 있는 다양한 치환, 변형 및 변경을 포함한다. 또한, 그러한 치환, 변형 및 변경은 첨부된 청구범위 내에 포함될 수 있는 것으로 이해되어야 한다.도면 도면1 도면2 도면3 도면4 도면5 도면6 도면7 도면8 도면9 도면10 도면11 도면12 도면13 도면14 도면15 도면16 도면17 도면18"}
{"patent_id": "10-2024-7027694", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 개시의 일 실시예에 따른 스캔 환경을 도시한다. 도 2는 본 개시의 일 실시예에 따른 전자 장치 및 구강 스캐너 각각을 나타내는 블록 도면을 도시한다. 도 3은 본 개시의 일 실시예에 따른 구강 스캐너를 도시한다. 도 4는 본 개시의 다양한 실시예에서 참조될 수 있는 환자의 구강에 대한 3차원 이미지의 생성 동작을 설명하기 위한 도면을 도시한다. 도 5는 본 개시의 다양한 실시예에서 참조될 수 있는 색조 가이드를 도시한다. 도 6은 본 개시의 일 실시예에 따른 방법을 나타내는 순서도를 도시한다. 도 7은 도 6을 참조하여 설명된 색상 정보 셋의 추출 동작을 구체적으로 설명하기 위한 순서도를 도시한다. 도 8은 도 7을 참조하여 설명된 색상 코드의 추출 동작을 구체적으로 설명하기 위한 순서도를 도시한다. 도 9는 도 6을 참조하여 설명된 인공지능 모델의 이용 동작을 구체적으로 설명하기 위한 순서도를 도시한다. 도 10은 본 개시의 다양한 실시예에서 참조될 수 있는 인공지능 모델의 학습 동작을 설명하기 위한 도면을 도시 한다.도 11 및 도 12는 본 개시의 다양한 실시예에서 참조될 수 있는 인공지능 모델 기반의 색상 유사도의 산출 동작 을 설명하기 위한 도면을 도시한다. 도 13은 도 6을 참조하여 설명된 대표 색상 정보의 결정 동작을 구체적으로 설명하기 위한 순서도를 도시한다. 도 14는 본 개시의 일 실시예에 따른 방법을 나타내는 순서도를 도시한다. 도 15 내지 도 18은 본 개시의 일 실시예에 따른 방법이 적용된 프로그램의 화면을 도시한다."}
