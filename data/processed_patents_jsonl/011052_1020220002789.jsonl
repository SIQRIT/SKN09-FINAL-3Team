{"patent_id": "10-2022-0002789", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0106977", "출원번호": "10-2022-0002789", "발명의 명칭": "재순위화를 통한 객체 검색", "출원인": "한화비전 주식회사", "발명자": "박성연"}}
{"patent_id": "10-2022-0002789", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "서로 이격된 복수의 카메라로부터 촬영된 영상 및 상기 영상의 메타 데이터가 저장되는 데이터베이스; 및관심 인물을 포함하는 프로브 영상이 입력된 경우, 상기 데이터베이스에서 적어도 하나의 미리 정해진 기준에기초하여 상기 관심 객체가 포함된 영상을 검색하기 위한 적어도 하나의 영상을 선별하고, 상기 프로브 영상의특징벡터와 상기 선별된 적어도 하나의 영상의 특징벡터 간의 거리(distance)에 기초하여 상기 프로브 영상과유사한 적어도 하나의 후보 영상을 추출하고, 상기 프로브 영상과 상기 후보 영상 간의 유사도(similarity) 에기초하여 상기 후보 영상에 대하여 재순위화(Re-ranking)하는 프로세서;를 포함하는 것을 특징으로 하는 영상 검색 장치."}
{"patent_id": "10-2022-0002789", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1 항에 있어서,상기 메타 데이터는,상기 영상에 포함된 사람의 성별, 특징벡터, 상기 영상의 촬영 시간, 촬영 위치를 포함하는 것을 특징으로 하는영상 검색 장치."}
{"patent_id": "10-2022-0002789", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 2 항에 있어서,상기 프로세서는,상기 프로브 영상이 입력되기 전 상기 복수의 영상 간의 특징벡터의 차이 값을 사전에 계산하여 상기 데이터 베이스에 저장하는 것을 특징으로 하는 영상 검색 장치."}
{"patent_id": "10-2022-0002789", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 3 항에 있어서,상기 프로세서는,상기 복수의 카메라 중 어느 하나로부터 새로운 제1 영상을 수신한 경우, 상기 제1 영상의 제1 특징벡터를 추출하고, 상기 제1 특징벡터와 상기 데이터 베이스에 사전에 저장된 복수의 영상 간 특징벡터의 차이값을 계산하여상기 데이터 베이스에 저장하는 것을 특징으로 하는 영상 검색 장치."}
{"patent_id": "10-2022-0002789", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제 2 항에 있어서,상기 프로세서는,상기 촬영 위치 및 촬영 시간이 서로 다른 복수의 영상을 입력 데이터로 하고, 상기 영상에 포함된 사람의 성별및 특징벡터를 추출하도록 신경망을 학습시키고, 학습된 신경망을 메모리에 저장하는 것을 특징으로 하는 영상검색 장치."}
{"patent_id": "10-2022-0002789", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제 2 항에 있어서,상기 미리 정해진 기준은, 상기 성별, 시간, 위치 정보를 포함하고,상기 프로세서는,공개특허 10-2023-0106977-3-상기 데이터베이스에 저장된 영상 데이터를 상기 프로브 영상에 포함된 사람의 성별을 기준으로 1차 필터링을수행하고, 상기 촬영 시간에 기초하여 2차 필터링을 수행하고, 상기 촬영 위치에 기초하여 3차 필터링을 수행하여 상기 프로브 영상에 포함된 사람과 동일한 사람이 포함된 영상의 검색범위를 한정하는 것을 특징으로 하는영상 검색 장치."}
{"patent_id": "10-2022-0002789", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제 6 항에 있어서,상기 프로세서는,상기 한정된 검색범위에 포함된 영상의 특징벡터와 상기 프로브 영상의 특징벡터의 유클리디언 거리(distance)를 산출하여, 상기 프로브 영상과 유사한 후보영상군을 추출하는 것을 특징으로 하는 영상 검색 장치."}
{"patent_id": "10-2022-0002789", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제 1 항에 있어서,상기 유사도는 자카드 거리(jaccard distance)에 따른 영상 유사도를 포함하는 것을 특징으로 하는 영상 검색장치."}
{"patent_id": "10-2022-0002789", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "서로 이격된 복수의 카메라로부터 촬영된 복수의 영상 및 상기 복수의 영상 간 특징정보의 차이값이 저장되는데이터 베이스;상기 영상에 포함된 사람의 성별 및 상기 영상의 특징벡터를 추출하는 특징 추출부;관심 인물을 포함하는 프로브 영상이 입력된 경우, 상기 관심 인물과의 유사도에 기초하여 상기 선별된 영상을순위화 하고, 상기 순위화된 영상을 유사도(similarity) 에 기초하여 재순위(Re-ranking) 하는 프로세서;를 포함하고,상기 특징 추출부는 촬영 위치 및 촬영 시간이 서로 다른 복수의 영상을 입력 데이터로 하고, 상기 영상에 포함된 사람의 성별 및 특징벡터를 추출하도록 학습된 신경망을 포함하고,상기 프로세서는 상기 프로브 영상이 입력되기 전 상기 복수의 영상 간 특징벡터의 차이값을 계산하는 것을 특징으로 하는 영상 검색 장치."}
{"patent_id": "10-2022-0002789", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제 9 항에 있어서,상기 프로세서는,상기 복수의 카메라로부터 촬영된 복수의 영상을 수신한 경우, 상기 영상의 촬영시간, 촬영위치, 상기 특징추출부를 통해 추출된 성별 및 상기 영상의 특징벡터를 상기 데이터 베이스에 저장하는 것을 특징으로 하는 영상 검색 장치."}
{"patent_id": "10-2022-0002789", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제 10 항에 있어서,상기 프로세서는,상기 복수의 카메라 중 어느 하나로부터 새로운 제1 영상을 수신한 경우, 상기 특징 추출부로부터 상기 제1 영상의 제1 특징벡터를 추출하고, 상기 제1 특징벡터와 상기 데이터 베이스에 사전에 저장된 복수의 영상 간 특징벡터의 차이값을 계산하여 상기 데이터 베이스에 저장하는 것을 특징으로 하는 영상 검색 장치."}
{"patent_id": "10-2022-0002789", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제 9 항에 있어서,상기 프로세서는,공개특허 10-2023-0106977-4-상기 프로브 영상에 포함된 사람의 성별, 상기 프로브 영상의 촬영 시간, 촬영 위치에 기초하여 상기 데이터베이스에 포함된 영상 중 상기 프로브 영상과 비교할 비교대상 범위를 한정하는 것을 특징으로 하는 영상 검색 장치."}
{"patent_id": "10-2022-0002789", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제 11 항에 있어서,상기 프로세서는,상기 프로브 영상의 특징벡터와 상기 비교대상 범위로 선별된 영상의 특징벡터 간의 유클리디언 거리(distance)에 기초하여, 상기 선별된 영상을 순위화 하는 것을 특징으로 하는 영상 검색 장치."}
{"patent_id": "10-2022-0002789", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제 9 항에 있어서,상기 프로브 영상은 상기 영상 검색 장치의 입력수단을 통해 사용자에 의해 입력되거나, 상기 데이터베이스로부터 선택되는 것을 특징으로 하는 영상 검색 장치."}
{"patent_id": "10-2022-0002789", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "서로 이격된 복수의 카메라로부터 촬영된 영상 및 상기 영상의 메타 데이터를 데이터 베이스에 저장하는 단계;관심 인물을 포함하는 프로브 영상이 입력된 경우, 상기 데이터베이스에서 적어도 하나의 미리 정해진 기준에기초하여 상기 관심 객체가 포함된 영상을 검색하기 위한 적어도 하나의 영상을 선별하는 단계;상기 프로브 영상의 특징벡터와 상기 선별된 적어도 하나의 영상의 특징벡터 간의 거리(distance)에 기초하여상기 프로브 영상과 유사한 적어도 하나의 후보 영상을 순위화하는 단계; 및상기 프로브 영상과 상기 후보 영상 간의 유사도(similarity)에 기초하여 상기 후보 영상에 대하여 재순위화(re-racking)하는 단계;를 포함하는 영상 검색 방법."}
{"patent_id": "10-2022-0002789", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제 15 항에 있어서,상기 메타 데이터는,상기 영상에 포함된 사람의 성별, 특징벡터, 상기 영상의 촬영 시간, 촬영 위치를 포함하는 것을 특징으로 하는영상 검색 방법."}
{"patent_id": "10-2022-0002789", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제 16 항에 있어서,상기 데이터 베이스에 저장하는 단계는,상기 프로브 영상이 입력되기 전 상기 복수의 영상 간의 특징벡터의 차이 값을 사전에 계산하여 저장하는 것을포함하는 것을 특징으로 하는 영상 검색 방법."}
{"patent_id": "10-2022-0002789", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제 17 항에 있어서,상기 복수의 카메라 중 어느 하나로부터 새로운 제1 영상을 수신한 경우, 상기 제1 영상의 제1 특징벡터를 추출하는 단계; 및상기 제1 특징벡터와 상기 데이터 베이스에 사전에 저장된 복수의 영상 간 특징벡터의 차이값을 계산하여 상기데이터 베이스에 저장하는 단계;를 더 포함하는 것을 특징으로 하는 영상 검색 방법.공개특허 10-2023-0106977-5-청구항 19 제 16 항에 있어서,상기 영상의 메타 데이터를 데이터 베이스에 저장하는 단계는,상기 촬영 위치 및 촬영 시간이 서로 다른 복수의 영상을 입력 데이터로 하고, 상기 영상에 포함된 사람의 성별및 특징벡터를 추출하도록 신경망을 학습시키는 단계;상기 학습된 신경망을 이용하여 상기 영상에 포함된 사람의 성별, 특징벡터를 획득하는 단계;를 포함하는 것을 특징으로 하는 영상 검색 방법."}
{"patent_id": "10-2022-0002789", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "서로 이격된 복수의 카메라로부터 촬영된 복수의 영상 및 상기 복수의 영상 간 특징정보의 차이값을 사전에 계산하여 데이터 베이스에 저장하는 단계;미리 학습된 인공 신경망을 이용하여 상기 영상에 포함된 사람의 성별 및 상기 영상의 특징벡터를 추출하는 단계;관심 인물을 포함하는 프로브 영상이 입력된 경우, 상기 데이터 베이스 중 상기 프로브 영상의 메타 데이터에기초하여 상기 프로브 영상과 비교할 적어도 하나의 영상을 선별하는 단계;상기 관심 인물과의 유사도에 기초하여 상기 선별된 영상을 순위화 하는 단계;상기 순위화된 영상을 자카드 거리(jaccard distance)에 기초하여 재순위화(Re-ranking) 하는 단계;를포함하고,상기 인공 신경망은 촬영 위치 및 촬영 시간이 서로 다른 복수의 영상을 입력 데이터로 하고, 상기 영상에 포함된 사람의 성별 및 특징벡터를 추출하도록 학습되어 저장되고,상기 프로브 영상이 입력되기 전 상기 복수의 영상 간 특징벡터의 차이값이 계산되어 상기 데이터 베이스에 저장되는 것을 특징으로 하는 영상 검색 방법."}
{"patent_id": "10-2022-0002789", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "감시 카메라 시스템에서의 영상 검색 장치 및 방법이 개시된다. 본 명세서의 일 실시예에 따른 영상 검색 장치는, 서로 이격된 복수의 카메라로부터 촬영된 영상 및 상기 영상의 메타 데이터를 저장하는 데이터베이스 및 프로브 영상이 입력되면 미리 정해진 기준에 따라 프로브 영상의 관심 인물과 동일한 인물을 검색하기 위한 검색 (뒷면에 계속)"}
{"patent_id": "10-2022-0002789", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 명세서는 재순위화 기법을 통해 사람을 검색하는 장치 및 방법에 관한 것이다."}
{"patent_id": "10-2022-0002789", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "재순위화 알고리즘은, 영상 검색 시스템의 내부적인 구조를 직접적으로 변경하는 대신, 검색된 결과에서 질의 (Query)와의 연관도를 독립적으로 계산하여, 검색 결과의 성능을 높이는 방식이다. 재순위화 알고리즘은 영상 검색 시스템의 내부 구조에 대해 구체적으로 인지할 필요가 없다는 점, 기존 시스템 을 정정하지 않은 채로 추가적인 알고리즘을 적용할 수 있다는 점 때문에 재순위화 알고리즘은 개발적인 측면에 서 장점이 있다. 재순위화 알고리즘은 그 기원을 잠정적 적합 피드백(Pseudo Relevance Feedback)에 기초하고 있다. 잠정적 적합 피드백은 일반적인 적합성 피드백(Relevance Feedback)과 달리, 인간이 결과에 따라 지도 학습(Supervised Learning) 방식으로 피드백을 주는 것이 아니라, 자율학습(Unsupervised Learning)의 방식으로 피드백을 주는 방식이다. 이러한 자율학습은 주로 재순위화 단계에서 사용할 수 있는 특징인, 초기 영상 검색의 순위 리스트에 대한 정보와, 검색 결과 영상들의 시각적 정보를 사용하여 이루어진다. 일반적으로 복수의 카메라에서 획득한 영상이 저장장치에 저장된 상태에서, 동일한 사람을 찾고 검색하는 기술 은 저장된 데이터가 방대할 경우, 동일한 사람을 정확하게 검색하기 쉽지 않다. 이를 위해 최근 다양한 시점에 서 촬영된 다수의 영상을 바탕으로 훈련된 딥러닝 네트워크를 바탕으로 추출된 특징정보를 활용하고 있지만, 이 러한 방법은 검색 시 추출된 특징이 유사한 사람들이 다수 존재할 경우 신뢰도 높은 검색 결과를 획득하기가 어려운 문제가 있다."}
{"patent_id": "10-2022-0002789", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "전술한 문제를 해결하기 위해 영상 간 유사도에 기초하여 1차적으로 순위화를 진행하고, 2차적으로 영상 간 자 카드 거리에 기초하여 재순위화를 수행함으로써, 서로 이격된 복수의 카메라를 통해 촬영된 영상에서 동일한 객 체를 보다 효율적으로 검색하는 방법을 제공하는 것을 목적으로 한다. 또한, 본 명세서는 영상 간 유사도 산출 및 자카드 거리 산출에 소요되는 연산량이 급증하는 문제를 해결하기 위하여 데이터 베이스 내의 검색 대상 크기를 한정함으로써, 서로 이격된 복수의 카메라를 통해 촬영된 영상에 서 동일한 객체를 보다 효율적으로 검색하는 방법을 제공하는 것을 목적으로 한다. 본 발명이 이루고자 하는 기술적 과제들은 이상에서 언급한 기술적 과제들로 제한되지 않으며, 언급되지 않은"}
{"patent_id": "10-2022-0002789", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 2, "content": "또 다른 기술적 과제들은 이하의 발명의 상세한 설명으로부터 본 발명이 속하는 기술분야에서 통상의 지식을 가 진 자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2022-0002789", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 명세서의 일 실시예에 따른 감시 카메라 시스템에서의 영상 검색 장치는, 서로 이격된 복수의 카메라로부터 촬영된 영상 및 상기 영상의 메타 데이터가 저장되는 데이터베이스; 및 관심 인물을 포함하는 프로브 영상이 입 력된 경우, 상기 데이터베이스에서 적어도 하나의 미리 정해진 기준에 기초하여 상기 관심 객체가 포함된 영상 을 검색하기 위한 적어도 하나의 영상을 선별하고, 상기 프로브 영상의 특징벡터와 상기 선별된 적어도 하나의 영상의 특징벡터 간의 거리(distance)에 기초하여 상기 프로브 영상과 유사한 적어도 하나의 후보 영상을 추출 하고, 상기 프로브 영상과 상기 후보 영상 간의 유사도(similarity) 에 기초하여 상기 후보 영상에 대하여 재순 위화(re-racking)하는 프로세서;를 포함한다. 상기 유사도는 자카드 거리에 기초하여 획득될 수 있다. 상기 메타 데이터는, 상기 영상에 포함된 사람의 성별, 특징벡터, 상기 영상의 촬영 시간, 촬영 위치를 포함할 수 있다. 상기 프로세서는, 상기 프로브 영상 입력을 통해 영상 검색 요청이 수신되기 전에 상기 복수의 영상 간의 특징 벡터의 차이 값을 계산하여 상기 데이터 베이스에 저장할 수 있다. 상기 프로세서는, 상기 복수의 카메라 중 어느 하나로부터 새로운 제1 영상을 수신한 경우, 상기 제1 영상의 제 1 특징벡터를 추출하고, 상기 제1 특징벡터와 상기 데이터 베이스에 사전에 저장된 복수의 영상 간 특징벡터의 차이값을 계산하여 상기 데이터 베이스에 저장할 수 있다. 상기 프로세서는, 상기 촬영 위치 및 촬영 시간이 서로 다른 복수의 영상을 입력 데이터로 하고, 상기 영상에 포함된 사람의 성별 및 특징벡터를 추출하도록 신경망을 학습시키고, 학습된 신경망을 메모리에 저장할 수 있다. 상기 미리 정해진 기준은, 상기 성별, 시간, 위치 정보를 포함하고, 상기 프로세서는, 상기 데이터베이스에 저 장된 영상 데이터를 상기 프로브 영상에 포함된 사람의 성별을 기준으로 1차 필터링을 수행하고, 상기 촬영 시 간에 기초하여 2차 필터링을 수행하고, 상기 촬영 위치에 기초하여 3차 필터링을 수행하여 상기 프로브 영상에 포함된 사람과 동일한 사람이 포함된 영상의 검색범위를 한정할 수 있다. 상기 프로세서는, 상기 한정된 검색범위에 포함된 영상의 특징벡터와 상기 프로브 영상의 특징벡터의 유클리디 언 거리(distance)를 산출하여, 상기 프로브 영상과 유사한 후보영상군을 추출할 수 있다. 본 명세서의 일 실시예에 따른 감시 카메라 시스템에서의 영상 검색 장치는, 서로 이격된 복수의 카메라로부터 촬영된 복수의 영상 및 상기 복수의 영상 간 특징정보의 차이값이 저장되는 데이터 베이스; 상기 영상에 포함된 사람의 성별 및 상기 영상의 특징벡터를 추출하는 특징 추출부; 관심 인물을 포함하는 프로브 영상이 입력된 경 우, 상기 데이터 베이스 중 상기 프로브 영상의 메타 데이터에 기초하여 상기 프로브 영상과 비교할 적어도 하 나의 영상을 선별하고, 상기 관심 인물과의 유사도에 기초하여 상기 선별된 영상을 순위화 하고, 상기 순위화된영상을 유사도(similarity)에 기초하여 재순위(Re-ranking) 하는 프로세서;를 포함하고, 상기 특징 추출부는 촬 영 위치 및 촬영 시간이 서로 다른 복수의 영상을 입력 데이터로 하고, 상기 영상에 포함된 사람의 성별 및 특 징벡터를 추출하도록 학습된 신경망을 포함하고, 상기 프로세서는 상기 프로브 영상이 입력되기 전 상기 복수의 영상 간 특징정보의 차이값을 계산할 수 있다. 상기 프로세서는, 상기 복수의 카메라로부터 촬영된 복수의 영상을 수신한 경우, 상기 영상의 촬영시간, 촬영위 치, 상기 특징추출부를 통해 추출된 성별 및 상기 영상의 특징벡터를 상기 데이터 베이스에 저장할 수 있다. 상기 데이터 베이스는, 상기 복수의 영상 간의 특징벡터의 차이값을 사전에 계산하여 저장하고, 상기 프로세서 는, 상기 복수의 카메라 중 어느 하나로부터 새로운 제1 영상을 수신한 경우, 상기 특징 추출부로부터 상기 제1 영상의 제1 특징벡터를 추출하고, 상기 제1 특징벡터와 상기 데이터 베이스에 사전에 저장된 복수의 영상 간 특 징벡터의 차이값을 계산하여 상기 데이터 베이스에 저장할 수 있다. 상기 프로세서는, 상기 프로브 영상에 포함된 사람의 성별, 상기 프로브 영상의 촬영 시간, 촬영 위치에 기초하 여 상기 데이터베이스에 포함된 영상 중 상기 프로브 영상과 비교할 비교대상 범위를 한정할 수 있다. 상기 프로세서는, 상기 프로브 영상의 특징벡터와 상기 비교대상 범위로 선별된 영상의 특징벡터 간의 유클리디 언 거리(distance)에 기초하여, 상기 선별된 영상을 순위화 할 수 있다. 상기 프로브 영상은 상기 영상 검색 장치의 입력수단을 통해 사용자에 의해 입력되거나, 상기 데이터베이스로부 터 선택될 수 있다. 본 명세서의 다른 실시예에 따른 감시 카메라 시스템에서의 영상 검색 방법은, 서로 이격된 복수의 카메라로부 터 촬영된 영상 및 상기 영상의 메타 데이터를 데이터 베이스에 저장하는 단계; 관심 인물을 포함하는 프로브 영상이 입력된 경우, 상기 데이터베이스에서 적어도 하나의 미리 정해진 기준에 기초하여 상기 관심 객체가 포 함된 영상을 검색하기 위한 적어도 하나의 영상을 선별하는 단계; 상기 프로브 영상의 특징벡터와 상기 선별된 적어도 하나의 영상의 특징벡터 간의 거리(distance)에 기초하여 상기 프로브 영상과 유사한 적어도 하나의 후 보 영상을 순위화하는 단계; 및 상기 프로브 영상과 상기 후보 영상 간의 유사도(similarity) 에 기초하여 상기 후보 영상에 대하여 재순위화(re-racking)하는 단계;를 포함한다. 상기 메타 데이터는, 상기 영상에 포함된 사람의 성별, 특징벡터, 상기 영상의 촬영 시간, 촬영 위치를 포함할 수 있다. 상기 데이터 베이스에 저장하는 단계는, 상기 프로브 영상 입력을 통해 영상 검색 요청이 수신되기 전에 상기 복수의 영상 간의 특징벡터의 차이 값을 계산하여 저장할 수 있다. 상기 영상 검색 방법은, 상기 복수의 카메라 중 어느 하나로부터 새로운 제1 영상을 수신한 경우, 상기 제1 영 상의 제1 특징벡터를 추출하는 단계; 및 상기 제1 특징벡터와 상기 데이터 베이스에 사전에 저장된 복수의 영상 간 특징벡터의 차이값을 계산하여 상기 데이터 베이스에 저장하는 단계;를 더 포함할 수 있다. 상기 영상의 메타 데이터를 데이터 베이스에 저장하는 단계는, 상기 촬영 위치 및 촬영 시간이 서로 다른 복수 의 영상을 입력 데이터로 하고, 상기 영상에 포함된 사람의 성별 및 특징벡터를 추출하도록 신경망을 학습시키 는 단계; 및 상기 학습된 신경망을 이용하여 상기 영상에 포함된 사람의 성별, 특징벡터를 획득하는 단계;를 포 함할 수 있다. 본 명세서의 일 실시예에 따른 감시 카메라 시스템에서의 영상 검색 방법은, 서로 이격된 복수의 카메라로부터 촬영된 복수의 영상 및 상기 복수의 영상 간 특징정보의 차이값을 데이터 베이스에 저장하는 단계; 미리 학습된 인공 신경망을 이용하여 상기 영상에 포함된 사람의 성별 및 상기 영상의 특징벡터를 추출하는 단계; 관심 인물 을 포함하는 프로브 영상이 입력된 경우, 상기 데이터 베이스 중 상기 프로브 영상의 메타 데이터에 기초하여 상기 프로브 영상과 비교할 적어도 하나의 영상을 선별하는 단계; 상기 관심 인물과의 유사도에 기초하여 상기 선별된 영상을 순위화 하는 단계; 상기 순위화된 영상을 유사도(similarity) 에 기초하여 재순위화(Re-ranking) 하는 단계;를 포함하고, 상기 인공 신경망은 촬영 위치 및 촬영 시간이 서로 다른 복수의 영상을 입력 데이터로 하고, 상기 영상에 포함된 사람의 성별 및 특징벡터를 추출하도록 학습되어 저장될 수 있다."}
{"patent_id": "10-2022-0002789", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 명세서의 일 실시예에 따르면, 영상 간 유사도에 기초하여 1차적으로 순위화를 진행하고, 2차적으로 영상 간 자카드 거리에 기초하여 재순위화를 수행함으로써, 서로 이격된 복수의 카메라를 통해 촬영된 영상에서 동일한객체를 보다 효율적으로 검색할 수 있다. 또한, 본 명세서의 일 실시예에 따르면, 영상 간 유사도 산출 및 자카드 거리 산출에 소요되는 연산량이 급증하 는 문제를 해결하기 위하여 데이터 베이스 내의 검색 대상 크기를 한정함으로써, 서로 이격된 복수의 카메라를 통해 촬영된 영상에서 동일한 객체를 보다 효율적으로 검색할 수 있다. 본 발명에서 얻을 수 있는 효과는 이상에서 언급한 효과로 제한되지 않으며, 언급하지 않은 또 다른 효과들은"}
{"patent_id": "10-2022-0002789", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 2, "content": "아래의 기재로부터 본 발명이 속하는 기술분야에서 통상의 지식을 가진 자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2022-0002789", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 첨부된 도면을 참조하여 본 명세서에 개시된 실시예를 상세히 설명하되, 도면 부호에 관계없이 동일하거 나 유사한 구성요소는 동일한 참조 번호를 부여하고 이에 대한 중복되는 설명은 생략하기로 한다. 이하의 설명 에서 사용되는 구성요소에 대한 접미사 \"모듈\" 및 \"부\"는 명세서 작성의 용이함만이 고려되어 부여되거나 혼용 되는 것으로서, 그 자체로 서로 구별되는 의미 또는 역할을 갖는 것은 아니다. 또한, 본 명세서에 개시된 실시 예를 설명함에 있어서 관련된 공지 기술에 대한 구체적인 설명이 본 명세서에 개시된 실시예의 요지를 흐릴 수 있다고 판단되는 경우 그 상세한 설명을 생략한다. 또한, 첨부된 도면은 본 명세서에 개시된 실시예를 쉽게 이 해할 수 있도록 하기 위한 것일 뿐, 첨부된 도면에 의해 본 명세서에 개시된 기술적 사상이 제한되지 않으며, 본 발명의 사상 및 기술 범위에 포함되는 모든 변경, 균등물 내지 대체물을 포함하는 것으로 이해되어야 한다. 제1, 제2 등과 같이 서수를 포함하는 용어는 다양한 구성요소들을 설명하는데 사용될 수 있지만, 상기 구성요소 들은 상기 용어들에 의해 한정되지는 않는다. 상기 용어들은 하나의 구성요소를 다른 구성요소로부터 구별하는 목적으로만 사용된다. 어떤 구성요소가 다른 구성요소에 \"연결되어\" 있다거나 \"접속되어\" 있다고 언급된 때에는, 그 다른 구성요소에 직접적으로 연결되어 있거나 또는 접속되어 있을 수도 있지만, 중간에 다른 구성요소가 존재할 수도 있다고 이 해되어야 할 것이다. 반면에, 어떤 구성요소가 다른 구성요소에 \"직접 연결되어\" 있다거나 \"직접 접속되어\" 있 다고 언급된 때에는, 중간에 다른 구성요소가 존재하지 않는 것으로 이해되어야 할 것이다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 출원에서, \"포함한다\" 또는 \"가지다\" 등의 용어는 명세서상에 기재된 특징, 숫자, 단계, 동작, 구성요소, 부 품 또는 이들을 조합한 것이 존재함을 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계,동작, 구성요소, 부품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되 어야 한다. 도 1은 본 명세서의 일 실시예에 따른 감시 카메라의 영상 처리 방법을 구현하기 위한 감시 카메라 시스템을 설 명하기 위한 도면이다. 도 1을 참조하면, 본 명세서의 일 실시예에 따른 영상 관리 시스템은 촬영 장치(100a, 100b, 100c, 이하, 설명의 편의를 위해 100으로 호칭) 및 영상 관리 서버을 포함할 수 있다. 촬영 장치는 특정 장소의 고정된 위치에 배치되는 촬영용 전자 장치일 수도 있고, 일정한 경로를 따라 자 동 또는 수동으로 움직일 수 있 는 촬영용 전자 장치일 수도 있고, 사람 또는 로봇 등에 의하여 이동될 수 있는 촬영용 전자 장치일 수도 있다. 촬영 장치는 유무선 인터넷에 연결하여 사용하는 IP 카메라일 수 있다. 촬영 장치는 팬(pan), 틸트 (tilt), 및 줌(zoom) 기능을 갖는 PTZ 카메라일 수 있다. 촬영 장치는 감시 하는 영역을 녹화하거나 사진 을 촬영하는 기능을 가질 수 있다. 촬영 장치는 감시하는 영역에서 발생하는 소리를 녹음하는 기능을 가질 수 있다. 촬영 장치는 감시하는 영역에서 움직임 또는 소리 등 변화가 발생 할 경우, 이에 대한 알림을 발 생시키거나 녹화 또는 사진 촬영을 수행하는 기능을 가질 수 있다. 상기 촬영 장치는 서로 다른 공간에 설치된 복수의 촬영 장치(100a, 100b, 100c)를 포함할 수 있다. 예를 들어, 제1 촬영 장치(100a)와 제2 촬영 장치(100b)는 제1 간격으로 이격되며, 제2 촬영 장치(100b)와 제3 촬영 장치(100c)는 제2 간격으로 이격되어 있을 수 있다. 즉, 각각의 촬영장치(100a, 100b, 100c)는 동일한 인물에 대하여 소정의 시간 간격을 두고 촬영 가능한 위치에 각각 배치되어 있는 CCTV 형태로 구현되는 시스템일 수 있 다. 영상 관리 서버는 촬영 장치를 통하여 촬영된 영상 자체 및/또는 해당 영상을 편집하여 얻어지는 영 상을 수신하여 저장 및/또는 검색기능을 갖는 장치일 수 있다. 영상 관리 서버는 수신한 용도에 대응되도 록 분석할 수 있다. 예를 들어, 영상 관리 서버는 영상에서 객체를 검출하기 위해 객체 검출 알고리즘을 이용하여 객체를 검출할 수 있다. 상기 객체 검출 알고리즘은 AI 기반 알고리즘이 적용될 수 있으며, 미리 학습 된 인공신경망 모델을 적용하여 객체를 검출할 수 있다. 본 명세서의 일 실시예에 따르면, 상기 영상 관리 서버는 영상 검색 장치로서의 기능을 수행할 수 있다. 상기 영상 검색 장치는, 복수의 감시 카메라 채널로부터 획득하는 영상들에 대하여 특정 영상, 특정 영상에 포 함된 객체 또는 특정 채널을 검색 조건으로 입력하면 빠르고 용이하게 검색할 수 있다. 영상 검색 장치는 사용 자가 영상을 용이하게 검색할 수 있도록 데이터 베이스를 구축하는 과정이 선행되어야 하며, 본 명세서의 일 실 시예는 특정 검색 조건에 따라 영상 검색을 수행함에 검색 대상의 크기를 제한하여 연산량을 제한하는 방법을 제안한다. 한편, 상기 영상 관리 서버는 네트워크를 통해 획득된 영상을 저장하는 기능을 수행하는 NVR(Network Video Recoder) 또는 DVR(Digital Video Recoder)일 수 있다. 또는 영상을 통합적으로 관리 및 제어하여, 원격 으로 영상을 모니터링할 수 있는 CMS(Central Management System)일 수도 있다. 한편, 이에 한정되지 않고 영상 관리 서버는 퍼스널 컴퓨터 또는 휴대용 단말기일 수도 있다. 다만, 이는 예시적인 것으로 본 명세서의 기 술적 사상은 이에 제한되는 것은 아니며, 네트워크를 통해 하나 이상의 감시 카메라로부터 멀티 미디어 개체를 전송 받아 디스플레이 및/또는 저장할 수 있는 장치이면 제한없이 사용될 수 있음은 물론이다. 한편, 영상 관리 서버는 영상 분석 목적에 맞는 다양한 학습 모델을 저장하고 있을 수 있다. 전술한 객체 검출을 위한 학습 모델 외에, 검출된 객체의 이동 속도를 획득할 수 있는 모델을 저장하고 있을 수도 있다. 여 기서 상기 학습된 모델들은 상기 복수의 촬영 장치(100a, 100b, 100c)를 통해 촬영된 영상 즉, 영상 촬영 시간 과 영상 촬영 위치가 서로 다른 영상을 입력데이터로 하여, 상기 촬영된 영상에 포함된 인물의 성별과 영상의 특징벡터 값을 출력하는 학습 모델을 포함할 수도 있다. 또한, 영상 관리 서버는 수신한 영상을 분석하여 메타 데이터와 해당 메타 데이터에 대한 인덱스 정보를 생성할 수 있다. 영상 관리 서버는 수신한 영상에 포함된 영상 정보 및 /또는 음향 정보를 함께 또는 별도 로 분석하여 메타 데이터와 해당 메타 데이터에 대한 인덱스 정보를 생성할 수 있다. 상기 메타 데이터는 영상 이 촬영된 시간정보, 촬영 위치 정보 등을 더 포함할 수도 있다. 영상 관리 시스템은 촬영 장치 및/또는 영상 관리 서버와 유무선 통신을 수행할 수 있는 외부 장 치를 더 포함할 수 있다. 외부 장치는 영상 관리 서버로 영상 전체 또는 일부의 제공을 요청하는 정보 제공 요청 신호를 송신 할 수 있다. 외부 장치는 영상 관리 서버로 영상 분석 결과 객체의 존재 여부, 객체의 이동 속도, 객 체의 이동 속도에 따른 셔터 속도 조절값, 객체의 이동 속도에 따른 노이즈 제거값, 센서 이득값 등을 요청하는 정보 제공 요청 신호를 송신할 수 있다. 또한 외부 장치는 영상 관리 서버로 영상을 분석하여 얻어진 메타 데이터 및/또는 메타 데이터에 대한 인덱스 정보를 요청하는 정보 제공 요청 신호를 송신할 수 있다. 영상 관리 시스템은 촬영 장치, 영상 관리 서버, 및/또는 외부 장치 간의 유무선 통신 경로 인 통신망을 더 포함할 수 있다. 통신망은 예컨대 LANs(Local Area Networks), WANs(Wide Area Networks), MANs(Metropolitan Area Networks), ISDNs(Integrated Service Digital Networks) 등의 유선 네트 워크나, 무선 LANs, CDMA, 블루투스, 위성 통신 등의 무선 네트워크를 망라할 수 있으나, 본 명세서의 범위가 이에 한정되는 것은 아니다. 도 2는 본 명세서의 일 실시예에 따른 영상 검색 장치의 구성을 나타낸 블록도이다. 도 2를 참조하면, 영상 검색장치는 통신부, 입력부, 인터페이스, 디스플레이부, AI 프로세서, 메모리, 데이터베이스를 포함할 수 있다. 영상 검색 장치는 카메라 로부터 전송받은 메타데이터를 분석하여, 영상에 포함된 객체의 특징 정보 를 추출할 수 있다. 그리고, 기 저장된 객체의 특징 정보와 비교하여 사용자가 검색할 수 있는 데이터베이스 (Database)를 구축한다. 이를 위해, 영상 검색 장치는 프로세서, 메모리, 입력부, 디스플 레이부를 포함한다. 그리고, 이들 구성요소들은 버스를 통해 상호간에 연결되어 통신할 수 있다. 통신부는 영상 데이터, 음성 데이터, 스틸 이미지, 및/또는 메타데이터를 카메라 장치로부터 수신할 수 있다. 일 실시예에 따른 통신부는 영상 데이터, 음성 데이터, 스틸 이미지, 및/또는 메타데이터를 카메 라로부터 실시간으로 수신할 수 있다. 통신 인터페이스는 유무선 LAN(Local Area Network), 와이파이(Wi- Fi), 지그비(ZigBee), 블루투스(Bluetooth), 근거리 통신(Near Field Communication) 중 적어도 하나의 통신 기능을 수행할 수 있다. 프로세서에 포함된 모든 구성요소들은 적어도 하나의 인터페이스 또는 어댑터를 통해 버스에 접속되거나, 직접 버스에 연결될 수 있다. 또한, 버스는 상기 기술한 구성요소 외에 다른 서브 시스템들과 연결될 수도 있다. 버스는 메모리 버스, 메모리 컨트롤러, 주변 버스(Peripheral Bus), 로컬 버스를 포함할 수 있다. 프로세서는 영상 검색 장치의 전반적인 동작을 제어한다. 예를 들어, 카메라 또는 별도의 VA 엔 진으로부터 메타데이터를 전송받으면, 메타데이터로부터 영상에 포함된 객체의 특징 정보를 추출하여 데이터 베 이스에 저장할 수 있다. 상기 메타데이터의 예시로서, 본 명세서는 영상에 포함된 객체(사람)의 성별, 영 상의 특징정보, 그리고 영상 촬영장치가 위치하는 위치정보, 촬영 시간 정보 등을 포함할 수 있다. 본 명세서의 일 실시예에 따르면 프로세서 및/또는 AI 프로세서가 영상으로부터 특징정보를 추출하는 특징 추출부(미도시)의 기능을 구현할 수 있으며, 상기 특징 추출부는 프로세서, AI 프로세서와 독립 된 모듈로 구성될 수도 있다. 본 명세서의 일 실시예에 따르면, 데이터베이스에 저장되는 모든 영상의 특징벡터 정보에 기초하여 각 영 상의 특징벡터의 차이값을 추가적으로 저장할 수 있다. 상기 특징벡터의 차이값은 1차적으로 각 영상들의 유사 도를 판단할 수 있는 근거로 활용할 수 있다. 따라서, 데이터베이스에 N개의 영상이 저장되어 있는 경우, 총 N(N-1) 개의 특징벡터 차이값을 구성하여 저장할 수 있다. 여기서, 감시 카메라를 통해 N+1 번째 영상이 수 신되는 경우, 프로세서는 ImageN+1을 I1, I2, I3,쪋IN 과 각각 특징벡터 차이값을 계산하여 총 N(N+1)개의 특징벡터 차이값을 구성하여 데이터베이스를 구성할 수 있다. 이에 따라, 본 명세서의 일 실시예에 따르면, 특정 검색 조건이 입력되기 전에 전술한 바와 같이 영상 간 특징 벡터 차이값이 모두 계산되어 저장되어 있는 상태이므로, 실제로 영상 검색이 수행되는 과정에서는 특징벡터 차 이를 계산하는데 소요되는 리소스를 최소한으로 줄일 수 있다. 프로세서로는 CPU(Central Processing Unit), MCU(Micro Controller nit) 또는 DSP(Digital Signal Processor) 등을 사용하는 것이 바람직하나, 이에 제한되지 않고 다양한 논리 연산 프로세서가 사용될 수 있다. 메모리는 각종 객체 정보들을 저장하고, 프로세서에 의해 데이터베이스가 구축된다. 메모리 는 비휘발성 메모리 장치 및 휘발성 메모리 장치를 포함한다. 비휘발성 메모리 장치는 부피가 작고 가벼우 며 외부의 충격에 강한 NAND 플래시 메모리이고, 휘발성 메모리 장치는 DDR SDRAM인 것이 바람직하다. 영상 검색 장치는 네트워크에 연결될 수도 있다. 따라서 영상 검색 장치는 다른 장치들과 네트워크를 통하여 연결되어, 메타데이터를 포함한 각종 데이터 및 신호들을 송수신할 수 있다. 디스플레이부는 사용자가 입력한 검색 조건에 따라 수행한 검색 결과를, 사용자가 볼 수 있도록 표시할 수 있다. 입력부로는 마우스, 키보드, 조이스틱, 리모콘 등이 있다. 이러한 입력부는 직렬 포트, 병렬포트, 게임 포 트, USB 등을 포함하는 입력 인터페이스를 통해 버스에 연결될 수 있다. 그러나 만약 영상 검색 장치(20 0)가 터치 기능을 제공한다면, 디스플레이부는 터치 센서를 포함할 수 있다. 이 경우에는 입력부가 별도로 마련될 필요가 없고, 사용자가 디스플레이부를 통해 직접 터치 신호를 입력할 수 있다. 영상 검색 장치가 터치 기능을 제공하더라도, 디스플레이부가 터치 센서를 포함하지 않는다면 별도의 터치 패드가 입력부로서 마련될 수도 있다. 디스플레이부는 LCD(Liquid Crystal Display), OLED(Organic Liquid Crystal Display), CRT(Cathode Ray Tube), PDP(Plasma Display Panel) 등 다양한 방식 이 사용될 수 있다. 이러한 디스플레이부는 비디오 인터페이스(미도시)를 통하여 버스에 연결되고, 디스플 레이부와 버스간의 데이터 전송은 그래픽 컨트롤러에 의해 제어될 수 있다. 인터페이스는 네트워크 인터페이스, 비디오 인터페이스, 입력 인터페이스 등을 포함할 수 있다. 네트워크 인터페이스는 네트워크 인터페이스 카드, 모뎀 등을 포함할 수 있다. AI 프로세서는 인공지능 영상 처리를 위한 것으로서, 본 명세서의 일 실시예에 따라 감시 카메라 시스템을 통해 획득된 영상에서 관심객체로 학습된 딥러닝 기반의 객체 탐지(Objection Detection) 알고리즘을 적용한다. 상기 AI 프로세서는 시스템 전반에 걸쳐 제어하는 프로세서와 하나의 모듈로 구현되거나 독립된 모듈 로 구현될 수 있다. 본 명세서의 일 실시예들은 객체 탐지에 있어서 YOLO(You Only Lock Once) 알고리즘을 적용 할 수 있다. YOLO은 객체 검출 속도가 빠르기 때문에 실시간 동영상을 처리하는 감시 카메라에 적당한 AI 알고 리즘이다. YOLO 알고리즘은 다른 객체 기반 알고리즘들(Faster R-CNN, R_FCN, FPN-FRCN 등)과 달리 한 장의 입 력 영상을 리사이즈(Resize)후 단일 신경망을 단 한 번 통과시킨 결과로 각 객체의 위치를 인디케이팅하는 바운 딩 박스(Bounding Box)와 객체가 무엇인지 분류 확률을 출력한다. 최종적으로 Non-max suppression을 통해 하나 의 객체를 한번 인식(detection)한다. 한편, 본 명세서에 개시되는 객체 인식 알고리즘은 전술한 YOLO에 한정되지 않고 다양한 딥러닝 알고리즘으로 구현될 수 있음을 밝혀둔다. 한편, 본 명세서에 적용되는 객체 인식을 위한 학습 모델은 전술한 영상에 포함된 객체가 사람인 경우, 사람의 성별을 추출할 수 있도록 학습된 신경망 모델을 포함할 수 있다. 상기 신경망 모델을 학습하기 위한 학습 데이 터로서, 일정 거리 이상 이격되어 있는 복수의 감시 카메라로부터 획득되는 영상의 촬영위치 정보, 촬영 시간 정보가 서로 다른 복수의 영상을 입력 데이터로 정의하고, 복수의 영상으로부터 성별과 영상의 특징정보가 추출 되도록 하는 네트워크가 설계되도록 학습될 수 있다. 도 3은 본 명세서의 일 실시예에 따른 영상 검색 장치에 적용되는 AI 장치(모듈)을 설명하기 위한 도면이다. 도 3을 살펴보면, AI 장치는 AI 프로세싱을 수행할 수 있는 AI 모듈을 포함하는 전자 기기 또는 AI 모듈을 포함하는 서버 등을 포함할 수 있다. 또한, AI 장치는 감시 카메라 또는 영상 관리 서버의 적어도 일부의 구성으로 포함되어 AI 프로세싱 중 적어도 일부를 함께 수행하도록 구비될 수도 있다. AI 프로세싱은 감시카메라 또는 영상 관리 서버의 제어부(프로세서)와 관련된 모든 동작들을 포함할 수 있다. 예를 들어, 감시 카메라 또는 영상 관리 서버는 획득된 영상 신호를 AI 프로세싱 하여 처리/판단, 제어 신호 생 성 동작을 수행할 수 있다. AI 장치는 AI 프로세싱 결과를 직접 이용하는 클라이언트 디바이스이거나, AI 프로세싱 결과를 다른 기기 에 제공하는 클라우드 환경의 디바이스일 수도 있다. AI 장치는 신경망을 학습할 수 있는 컴퓨팅 장치로서, 서버, 데스크탑 PC, 노트북 PC, 태블릿 PC 등과 같은 다양한 전자 장치로 구현될 수 있다. AI 장치는 AI 프로세서, 메모리 및/또는 통신부를 포함할 수 있다. AI 프로세서는 메모리에 저장된 프로그램을 이용하여 신경망을 학습할 수 있다. 특히, AI 프로세서(2 1)는 감시 카메라의 관련 데이터를 인식하기 위한 신경망을 학습할 수 있다. 여기서, 감시 카메라의 관련 데이 터를 인식하기 위한 신경망은 인간의 뇌 구조를 컴퓨터 상에서 모의하도록 설계될 수 있으며, 인간의 신경망의뉴런(neuron)을 모의하는, 가중치를 갖는 복수의 네트워크 노드들을 포함할 수 있다. 복수의 네트워크 모드들은 뉴런이 시냅스(synapse)를 통해 신호를 주고 받는 뉴런의 시냅틱 활동을 모의하도록 각각 연결 관계에 따라 데 이터를 주고 받을 수 있다. 여기서 신경망은 신경망 모델에서 발전한 딥러닝 모델을 포함할 수 있다. 딥러닝 모 델에서 복수의 네트워크 노드들은 서로 다른 레이어에 위치하면서 컨볼루션(convolution) 연결 관계에 따라 데 이터를 주고 받을 수 있다. 신경망 모델의 예는 심층 신경망(DNN, deep neural networks), 합성곱 신경망(CNN, convolutional deep neural networks), 순환 신경망(RNN, Recurrent Boltzmann Machine), 제한 볼츠만 머신 (RBM, Restricted Boltzmann Machine), 심층 신뢰 신경망(DBN, deep belief networks), 심층 Q-네트워크(Deep Q-Network)와 같은 다양한 딥 러닝 기법들을 포함하며, 컴퓨터비젼, 음성인식, 자연어처리, 음성/신호처리 등의 분야에 적용될 수 있다. 한편, 전술한 바와 같은 기능을 수행하는 프로세서는 범용 프로세서(예를 들어, CPU)일 수 있으나, 인공지능 학 습을 위한 AI 전용 프로세서(예를 들어, GPU)일 수 있다. 메모리는 AI 장치의 동작에 필요한 각종 프로그램 및 데이터를 저장할 수 있다. 메모리는 비 휘발 성 메모리, 휘발성 메모리, 플래시 메모리(flash-memory), 하드디스크 드라이브(HDD) 또는 솔리드 스테이트 드 라이브(SDD) 등으로 구현할 수 있다. 메모리는 AI 프로세서에 의해 액세스되며, AI 프로세서에 의 한 데이터의 독취/기록/수정/삭제/갱신 등이 수행될 수 있다. 또한, 메모리는 본 발명의 일 실시예에 따른 데이터 분류/인식을 위한 학습 알고리즘을 통해 생성된 신경망 모델(예를 들어, 딥 러닝 모델)을 저장할 수 있다. 한편, AI 프로세서는 데이터 분류/인식을 위한 신경망을 학습하는 데이터 학습부를 포함할 수 있다. 데 이터 학습부는 데이터 분류/인식을 판단하기 위하여 어떤 학습 데이터를 이용할지, 학습 데이터를 이용하여 데이터를 어떻게 분류하고 인식할지에 관한 기준을 학습할 수 있다. 데이터 학습부는 학습에 이용될 학습 데이터를 획득하고, 획득된 학습데이터를 딥러닝 모델에 적용함으로써, 딥러닝 모델을 학습할 수 있다. 데이터 학습부는 적어도 하나의 하드웨어 칩 형태로 제작되어 AI 장치에 탑재될 수 있다. 예를 들어, 데이터 학습부는 인공지능(AI)을 위한 전용 하드웨어 칩 형태로 제작될 수도 있고, 범용 프로세서(CPU) 또 는 그래픽 전용 프로세서(GPU)의 일부로 제작되어 AI 장치에 탑재될 수도 있다. 또한, 데이터 학습부 는 소프트웨어 모듈로 구현될 수 있다. 소프트웨어 모듈(또는 인스트럭션(instruction)을 포함하는 프로그램 모 듈)로 구현되는 경우, 소프트웨어 모듈은 컴퓨터로 읽을 수 있는 판독 가능한 비일시적 판독 가능 기록 매체 (non-transitory computer readable media)에 저장될 수 있다. 이 경우, 적어도 하나의 소프트웨어 모듈은 OS(Operating System)에 의해 제공되거나, 애플리케이션에 의해 제공될 수 있다. 데이터 학습부는 학습 데이터 획득부 및 모델 학습부를 포함할 수 있다. 학습 데이터 획득부는 데이터를 분류하고 인식하기 위한 신경망 모델에 필요한 학습 데이터를 획득할 수 있 다. 모델 학습부는 획득된 학습 데이터를 이용하여, 신경망 모델이 소정의 데이터를 어떻게 분류할지에 관한 판 단 기준을 가지도록 학습할 수 있다. 이 때 모델 학습부는 학습 데이터 중 적어도 일부를 판단 기준으로 이 용하는 지도 학습(supervised learning)을 통하여, 신경망 모델을 학습시킬 수 있다. 또는 모델 학습부는 지도 없이 학습 데이터를 이용하여 스스로 학습함으로써, 판단 기준을 발견하는 비지도 학습(unsupervised learning)을 통해 신경망 모델을 학습시킬 수 있다. 또한, 모델 학습부는 학습에 따른 상황 판단의 결과가 올바른지에 대한 피드백을 이용하여 강화 학습(reinforcement learning)을 통하여, 신경망 모델을 학습시킬 수 있다. 또한, 모델 학습부는 오류 역전파법(error back-propagation) 또는 경사 하강법(gradient decent)을 포함하는 학습 알고리즘을 이용하여 신경망 모델을 학습시킬 수 있다. 신경망 모델이 학습되면, 모델 학습부는 학습된 신경망 모델을 메모리에 저장할 수 있다. 모델 학습부 는 학습된 신경망 모델을 AI 장치와 유선 또는 무선 네트워크로 연결된 서버의 메모리에 저장할 수도 있다. 데이터 학습부는 인식 모델의 분석 결과를 향상시키거나, 인식 모델의 생성에 필요한 리소스 또는 시간을 절약하기 위해 학습 데이터 전처리부(미도시) 및 학습 데이터 선택부(미도시)를 더 포함할 수도 있다. 학습 데이터 전처리부는 획득된 데이터가 상황 판단을 위한 학습에 이용될 수 있도록, 획득된 데이터를 전처리 할 수 있다. 예를 들어, 학습 데이터 전처리부는, 모델 학습부가 이미지 인식을 위한 학습을 위하여 획득된 학습 데이터를 이용할 수 있도록, 획득된 데이터를 기 설정된 포맷으로 가공할 수 있다.또한, 학습 데이터 선택부는, 학습 데이터 획득부에서 획득된 학습 데이터 또는 전처리부에서 전처리된 학 습 데이터 중 학습에 필요한 데이터를 선택할 수 있다.선택된 학습 데이터는 모델 학습부에 제공될 수 있다. 또한, 데이터 학습부는 신경망 모델의 분석 결과를 향상시키기 위하여 모델 평가부(미도시)를 더 포함할 수 도 있다. 모델 평가부는, 신경망 모델에 평가 데이터를 입력하고, 평가 데이터로부터 출력되는 분석 결과가 소정 기준을 만족하지 못하는 경우, 모델 학습부로 하여금 다시 학습하도록 할 수 있다. 이 경우, 평가 데이터는 인식 모델을 평가하기 위한 기 정의된 데이터일 수 있다. 일 예로, 모델 평가부는 평가 데이터에 대한 학습된 인식 모델의 분석 결과 중, 분석 결과가 정확하지 않은 평가 데이터의 개수 또는 비율이 미리 설정되 임계치를 초과 하는 경우, 소정 기준을 만족하지 못한 것으로 평가할 수 있다. 통신부는 AI 프로세서에 의한 AI 프로세싱 결과를 외부 전자 기기로 전송할 수 있다. 예를 들어, 외부 전자 기기는 감시카메라, 블루투스 장치, 자율주행 차량, 로봇, 드론, AR 기기, 모바일 기기, 가전 기기 등을 포함할 수 있다. 한편, 도 3에 도시된 AI 장치는 AI 프로세서와 메모리, 통신부 등으로 기능적으로 구분하여 설 명하였지만, 전술한 구성요소들이 하나의 모듈로 통합되어 AI 모듈로 호칭될 수도 있음을 밝혀둔다. 본 명세서는 감시용 카메라, 자율주행 차량, 사용자 단말기 및 서버 중 하나 이상이 인공 지능(Artificial Intelligence) 모듈, 로봇, 증강현실(Augmented Reality, AR) 장치, 가상 현실(Virtual reality, VT) 장치, 5G, 6G 서비스와 관련된 장치 등과 연계될 수 있다. 도 4는 본 명세서의 일 실시예에 따른 감시 카메라 시스템에서의 영상 검색 방법의 흐름도이다. 도 4에 개시된 영상 검색 방법은, 도 2에서 설명한 영상 검색 장치의 프로세서를 통해 구현될 수 있다. 도 4를 참조하면, 프로세서는 영상 검색 장치(NVR)의 데이터 베이스를 구성할 수 있다(S400). 상기 데이터 베이스는, 기존 영상 데이터와 새로운 영상 데이터의 영상 디스턴스(distance)를 추출함으로써, 업데이트될 수 있다. 여기서 상기 영상 디스턴스라 함은 인공지능 학습모델을 통해 획득된 영상의 특징정보를 의미할 수 있다. 상기 영상의 특징정보는 영상의 특징벡터를 의미할 수 있으며, 두 영상 각각의 특징벡트의 차이값을 의미할 수 도 있다. 데이터 베이스를 구성 및 업데이트하는 과정에 대해서는 도 5를 통해 구체적으로 후술하기로 한다. 상기 데이터 베이스는 영상들 간의 사전에 계산된 특징벡터 차이값을 저장할 수 있으며, 이는 향후 영상 검색 장치의 사용자에 의해 특정 객체의 검색 요청을 수신한 경우, 데이터 베이스에 저장된 영상 디스턴스 정보를 활 용함으로써, 특징벡터 차이값을 추가적으로 계산할 필요가 없다. 프로세서는 프로브 영상이 입력여부를 확인할 수 있다(S410). 여기서, 프로브 영상은 영상 검색 장치(20 0)를 통해 검색하고자 하는 객체를 포함하는 영상을 의미할 수 있다. 상기 프로브 영상의 입력은, 영상 검색 장 치의 입력부를 통해 사용자에 의해 입력될 수 있다. 상기 프로브 영상은, 서로 이격된 복수의 감시 가카메 라를 통해 촬영되어 영상 검색 장치의 메모리에 저장된 영상들 중 하나가 선택되는 방법을 통해 영상 검색 장치를 통해 검색하고자 하는 영상으로 입력될 수도 있다. 프로세서는, 프로브 영상 입력을 통해 사용자로부터 특정 영상(또는 객체)의 검색 요청을 수신한 것으로 판단한 경우(S410:Y), 기 구성되어 있는 데이터 베이스에서 미리 정해진 기준에 따라 프로브 영상과의 비교 대 상군에 포함될 영상을 선별할 수 있다(S420). 상기 미리 정해진 기준은, 프로브 영상의 특징, 촬영된 카메라의 설치 장소, 촬영 시간 등 감시 카메라 전체 시스템이 고려될 수 있으며, 도 6을 통해 보다 구체적으로 설명한다. 프로세서는 S420을 통해 프로브 영상과 비교할 영상을 데이터 베이스에서 선별한 경우, 선별된 영상과 프 로브 영상의 유사도 비교를 통해 적어도 하나 이상의 영상을 후보 영상으로 추출하고, 추출된 후보 영상을 상기 유사도 기준으로 순위화(정렬) 할 수 있다(S430). 여기서, 영상의 유사도라 함은, 프로브 영상 데이터의 특징 벡터와 데이터베이스에서 선별된 영상에 대한 특징 벡터들 과의 유클리디언 거리(distance)를 의미할 수 있다. 타겟 영상과의 비교대상 영상의 유사도를 판단하는 방법 중, 예를 들어, 프로세서는 k-최근접 이웃 탐색(k-nearest neighbor search) 알고리즘을 적용하는 경우, 프로브 영상에 포함된 사람과, 데이터베이스의 비교 영상에 포함된 사람에 대한 특징정보가 명확하게 구 분되는 경우에는 효과적으로 동일한 사람인지 여부를 판단할 수 있다. 그러나, 데이터 베이스 내에, 검색하고자하는 사람과 체형 또는 의상이 유사한 사람이 다수 존재하는 경우, 유사도가 높은 것으로 판단되어 선순위 영상 으로 추출되는 영상들 중에 동일한 사람이 아닌 것으로 판단되는 경우가 발생될 수 있다. 본 명세서의 일 실시예에 따르면, 전술한 문제점을 개석하기 위해 S430 에서 1차적으로 순위화를 수행한 영상 그룹에 대하여 재순위화(Re-ranking)을 수행한다(S440) 프로세서는 유클리디언 거리를 계산하여 특징벡터가 유사한 순으로 1차적으로 순위화한 후, 아래 수학식 1 을 통해 자카드 거리(Jaccard distance)를 산출한다. 수학식 1"}
{"patent_id": "10-2022-0002789", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "여기서, 는 프로브 영상과 데이터 베이스에 저장된 후보 영상(1차 순위화된 영상) 중 i 번째 후보 영 상 간의 자카드 거리를 의미하며,"}
{"patent_id": "10-2022-0002789", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "는 프로브 영상과 데이터 베이스에 저장된 후보 영상(1차 순위화된 영상) 중 i 번째 후보 영상 간의 유클 리디언 거리를 의미하며, N은 데이터 베이스에 저장된 후보 영상의 개수를 의미한다. 자카드 거리(Jaccard distance)는, 프로브 영상과 데이터 베이스의 후보 영상 중 i 번째 영상이 유사해질수록 높은 값을 갖는다. 이는 상호간의 추출한 후보 영상의 집합이 유사한 경우에 보다 신뢰성을 부여하여 동일 인물 이라고 판단하는 근거로 활용할 수 있다. 일 실시예에 따라, 프로세서는 상기 계산된 자카드 거리와 유클리디언 거리의 가중합을 통해 최종 거리 (Final Distance)를 획득함으로써, 우선순위를 재조정할 수도 있다. 도 5는 본 명세서의 일 실시예에 따라 데이터 베이스를 구성하는 예를 설명하기 위한 도면이다. 도 5를 참조하면, 프로세서는 새로운 영상(이하, 제1 영상이라 함)을 수신할 수 있다(S500). 상기 새로운 영상은 데이터 베이스에 저장된 적이 없는 새로운 영상으로서, 서로 이격되어 있는 복수의 카메라를 통해 수신 된 영상이다. 본 명세서의 일 실시예는, 상기 제1 영상을 향후 영상 검색 과정에서 활용하기 위해, 상기 제1 영상과 관련된 정보들이 가공되어 데이터 베이스에 추가적으로 저장될 수 있다. 여기서 상기 제1 영상과 관련된 정보라 함은, 제1 영상의 메타 데이터를 포함할 수 있다. 상기 제1 영상의 메타 데이터는, 제1 영상의 촬영위치, 촬영시간 정보를 포함할 수 있다. 또한, 상기 제1 영상과 관련된 정보는, 상기 제1 영상의 특징정보를 포함할 수 있다. 상기 제1 영상의 특징 정 보는 AI 특징정보 추출과정을 통해 추출되는 특징벡터를 포함할 수 있다(S510). 프로세서는 상기 제1 영상의 특징벡터와, 데이터 베이스에 기 저장된 영상들의 특징벡터와의 차이를 추출 하여 데이터 베이스에 저장할 수 있다(S520). 즉, 상기 데이터 베이스에 저장된 모든 영상들은 상호간의 특징벡 터 차이값이 산출되어 저장되어 있다. 이에 따라, 데이터 베이스에 저장된 영상 중 특정 영상이 프로브 영상으 로 선택된 경우, 프로세서는 프로브 영상에 포함된 사람과 동일한 사람을 포함하는 영상을 검색하기 위하 여 영상 간 유사도를 추가적으로 계산할 필요가 없이, 데이터 베이스에 저장된 특징벡터 차이값에 기초하여 유 사 영상의 순위화를 수행할 수 있다. 한편, 프로세서 도 5에 도시된 바와 같이, 데이터 베이스에 특징정보 등이 저장되어 있지 않은 새로운 영상이 수신된 경우, 상기 새로운 영상의 특징정보(특징벡터 포함)를 추출하여, 데이터 베이스에 기 저장된 영상들의 특징벡터와 차이를 추출하는 연산을 수행하여, 새로운 영상이 기 저장된 영상과의 유사도를 판단할 수 있도록 데이터 베이스를 재구성할 수 있다. 도 6은 본 명세서의 일 실시예에 따라 검색 대상 인물과 동일한 인물을 포함하는 영상을 검색하기 위하여 데이 터 베이스에서 검색 범위를 필터링하는 예를 설명하기 위한 도면이다. 본 명세서의 일 실시예에 따르면, 영상 검색 장치의 사용자가 검색하고자 하는 대상 객체를 선택하면, 데이터 베이스 내에서 선택된 객체에 대한 특징 벡터와 사람의 성별 및 시공간 정보를 기반으로 관심 객체와 동일한 사 람 후보를 데이터 베이스 선별부에서 분류를 한다. 도 6을 참조하면, 프로세서는 프로브 영상의 특징정보를 확인할 수 있다(S600). 상기 프로브 영상의 특징 정보는, 전술한 바와 같이, 영상의 특징벡터, 영상의 촬영위치, 촬영시간, 영상에 포함된 사람의 성별 정보 등 을 포함할 수 있다. 전술한 바와 같이, 상기 영상의 촬영 위치정보, 촬영 시간 정보는 감시 카메라로부터 영상 을 수신할 경우, 메타 데이터 형식으로 함께 수신할 수 있으며, 상기 특징벡터 정보, 성별 정보 등은 영상 검색 장치에서 AI 영상 분석 과정을 통해 추출될 수 있다. 프로세서는 우선 프로브 영상에 포함된 관심 객체의 성별을 기반으로 데이터 베이스 내에 같은 성별에 대 한 데이터만 선별할 수 있다(S610). 이 때, 데이터 베이스에 저장된 영상 중 남성 및 여성이 함께 존재하는 영 상인 경우, 비교 대상 영상으로 선별되도록 구성될 수 있다. 그리고, 프로세서는 프로브 영상의 촬영 시간 정보와 유사한 시간에 대한 데이터만을 데이터 베이스에서 추가적으로 선별할 수 있다(S620). 동일 날짜 및 유사 시간에 대해서만 검색 범위를 제한하기 위함이다. 마지막으로, 프로세서는 프로브 영상의 촬영 위치 정보를 기반으로 데이터를 선별할 수 있다(S630). 한편, 영상 검색 장치는 공간적으로 이격되어 설치된 복수의 카메라의 정보를 획득하고 있는 상태이므로 인접한 장소 에 설치되어 있는 카메라들에 대한 정보 위주로 동일한 사람에 대한 검색 범위를 제한할 수 있다. 이와 같이, 본 명세서의 일 실시예는 재순위화(Re-ranking) 과정에서 소요되는 연산량을 줄이기 위해, 프로브 영상과의 유사도를 판단할 대상 범위를 성별, 촬영시간, 촬영위치 기반으로 축소할 수 있다. 도 7a는 본 명세서의 일 실시예에 따라 데이터 베이스에서 선별된 영상 중 검색 대상 인물과 유사한 영상을 1차 적으로 순위화한 예시이고, 도 7b는 1차 순위화 이후 재순위화화를 수행한 예시이다. 도 7a는 도 4의 S430(후보 영상을 선정하여 순위화)의 결과를 예시한다. 예를 들어, 선별된 데이터 베이스 내의 영상 중 프로브 영상과의 유클리디언 디스턴스 값의 비교를 통해 유사도를 판단한 결과, P1, N1, P2, N2, P3, N3, N4, N5, P4, N6의 순서로 유사도 순위가 결정될 수 있다. 그러나, 실제로 N1은 프로브 영상의 관심 인물과 동일한 인물이 아니지만, 동일한 인물인 P2 보다 우선순위가 높은 결과를 보여준다. 마찬가지고, N2가 P3 보다 우선순위가 높으며, N3, N4, N5는 P4 보다 우선순위가 높게 결정되었다. (프로브 영상의 관심 인물과 동일한 인 물을 포함하는 영상은 P1, P2, P3, P4로 가정) 즉, 도 7a의 경우, 단순히 영상간 특징벡터의 차이 값 만으로 비교한 결과, 관심 인물의 의상, 외형 등이 특징 벡터 값 설정에 고려되기 때문에 동일하지 않은 사람이 동일한 사람보다 유사도가 높은 결과가 나올 수 있다. 본 명세서는 도 7a의 결과에서 자카드 거리를 추가적으로 계산함으로써, 우선순위를 재 순위화 할 수 있으며, 재순위화 결과, P1, P2, P3, P4가 N1, N2, N3, N4, N5, N6 보다 우선순위가 높게 정렬되어, 영상 검색의 정확 도를 높일 수 있다. 전술한 본 명세서, 프로그램이 기록된 매체에 컴퓨터가 읽을 수 있는 코드로서 구현하는 것이 가능하다. 컴퓨터 가 읽을 수 있는 매체는, 컴퓨터 시스템에 의하여 읽혀질 수 있는 데이터가 저장되는 모든 종류의 기록장치를 포함한다. 컴퓨터가 읽을 수 있는 매체의 예로는, HDD(Hard Disk Drive), SSD(Solid State Disk), SDD(Silicon Disk Drive), ROM, RAM, CD-ROM, 자기 테이프, 플로피 디스크, 광 데이터 저장 장치 등이 있으며, 또한 캐리어 웨이브(예를 들어, 인터넷을 통한 전송)의 형태로 구현되는 것도 포함한다. 따라서, 상기의 상세한 설명은 모든 면에서 제한적으로 해석되어서는 아니되고 예시적인 것으로 고려되어야 한다. 본 명세서의 범위는 첨부된 청구 항의 합리적 해석에 의해 결정되어야 하고, 본 발명의 등가적 범위 내에서의 모든 변경은 본 명세서의 범위에 포함된다.도면 도면1 도면2 도면3 도면4 도면5 도면6 도면7a 도면7b"}
{"patent_id": "10-2022-0002789", "section": "도면", "subsection": "도면설명", "item": 1, "content": "본 명세서에 관한 이해를 돕기 위해 상세한 설명의 일부로 포함되는, 첨부 도면은 본 명세서에 대한 실시예를 제공하고, 상세한 설명과 함께 본 명세서의 기술적 특징을도 설명한다. 도 1은 본 명세서의 일 실시예에 따른 감시 카메라의 영상 처리 방법을 구현하기 위한 감시 카메라 시스템을 설 명하기 위한 도면이다. 도 2는 본 명세서의 일 실시예에 따른 감시 카메라의 개략적인 블록도이다. 도 3은 본 명세서의 일 실시예에 따른 감시 카메라 영상의 분석에 적용되는 AI 장치(모듈)을 설명하기 위한 도 면이다. 도 4는 본 명세서의 일 실시예에 따른 감시 카메라 시스템에서의 영상 검색 방법의 흐름도이다. 도 5는 본 명세서의 일 실시예에 따라 데이터 베이스를 구성하는 예를 설명하기 위한 도면이다. 도 6은 본 명세서의 일 실시예에 따라 검색 대상 인물과 동일한 인물을 포함하는 영상을 검색하기 위하여 데이 터 베이스에서 검색 범위를 필터링하는 예를 설명하기 위한 도면이다. 도 7a는 본 명세서의 일 실시예에 따라 데이터 베이스에서 선별된 영상 중 검색 대상 인물과 유사한 영상을 1차 적으로 순위화한 예시이고, 도 7b는 1차 순위화 이후 재순위화화를 수행한 예시이다. 본 발명에 관한 이해를 돕기 위해 상세한 설명의 일부로 포함되는, 첨부 도면은 본 발명에 대한 실시예를 제공 하고, 상세한 설명과 함께 본 발명의 기술적 특징을 설명한다."}
