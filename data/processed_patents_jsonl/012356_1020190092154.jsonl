{"patent_id": "10-2019-0092154", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2020-0045946", "출원번호": "10-2019-0092154", "발명의 명칭": "이동 단말기", "출원인": "엘지전자 주식회사", "발명자": "안예한"}}
{"patent_id": "10-2019-0092154", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "비주얼 컨텐츠를 제공하는 디스플레이부;피사체를 촬영하여 깊이 이미지를 획득하는 TOF(Time of Flight) 카메라; 및상기 디스플레이부 및 상기 TOF 카메라에 연결된 제어부;를 포함하고,상기 제어부는특정 오브젝트를 상기 TOF 카메라의 촬영 영역 중 인터렉션 영역으로 가이드하는 가이드 인터페이스를 제공하도록 상기 디스플레이부를 제어하는 것을 특징으로 하는 이동 단말기."}
{"patent_id": "10-2019-0092154", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 인터렉션 영역은상기 TOF 카메라에서 제1 거리 범위에 위치하는 것을 특징으로 하는 이동 단말기."}
{"patent_id": "10-2019-0092154", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 인터렉션 영역은상기 TOF 카메라에서 특정 화각 범위 내에 위치하는 것을 특징으로 하는 이동 단말기."}
{"patent_id": "10-2019-0092154", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,상기 인터렉션 영역은상기 TOF 카메라에 마주하는 평면 상의 특정 좌표 범위 내에 위치하는 것을 특징으로 하는 이동 단말기."}
{"patent_id": "10-2019-0092154", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서,상기 가이드 인터페이스는상기 인터렉션 영역에 대응되는 제1 인디케이터;상기 특정 오브젝트의 움직임에 대응하여 이동하는 제2 인디케이터;를 포함하는 것을 특징으로 하는 이동 단말기."}
{"patent_id": "10-2019-0092154", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5항에 있어서,상기 가이드 인터페이스는상기 제1 인디케이터를 기준으로 움직이는 상기 제2 인디케이터에 대응하여 그래픽 피드백을 제공하는 것을 특징으로 하는 이동 단말기."}
{"patent_id": "10-2019-0092154", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6항에 있어서,공개특허 10-2020-0045946-3-상기 그래픽 피드백은상기 제2 인디케이터가 상기 제1 인디케이터의 중앙 영역에 위하는 경우 제공되는 것을 특징으로 하는 이동 단말기."}
{"patent_id": "10-2019-0092154", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제6항에 있어서,상기 가이드 인터페이스는상기 제1 인디케이터의 중앙 영역을 감싸는 제3 인디케이터를 포함하고, 상기 그래픽 피드백은상기 제3 인디케이터에서 상기 제2 인디케이터가 오버렙된 부분을 표시하는 것을 특징으로 하는 이동 단말기."}
{"patent_id": "10-2019-0092154", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제6항에 있어서,상기 그래픽 피드백은상기 제1 인디케이터에서 상기 제2 인디케이터가 오버렙되는 경계 부분을 표시하는 것을 특징으로 하는 이동 단말기."}
{"patent_id": "10-2019-0092154", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제6항에 있어서,상기 그래픽 피드백은상기 제2 인디케이터에서 상기 제1 인디케이터가 벗어난 부분을 표시하는 것을 특징으로 하는 이동 단말기."}
{"patent_id": "10-2019-0092154", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제5항에 있어서,상기 제2 인티케이터는상기 사용자의 손과 상기 TOF 카메라와의 거리에 대응하여 크기가 가변되는 것을 특징으로 하는 이동 단말기."}
{"patent_id": "10-2019-0092154", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항에 있어서,상기 가이드 인터페이스는상기 제1 인디케이터를 기준으로 가변되는 상기 제2 인디케이터의 크기에 대응하여 그래픽 피드백을 제공하는것을 특징으로 하는 이동 단말기."}
{"patent_id": "10-2019-0092154", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제12항에 있어서,상기 가이드 인터페이스는상기 제1 인디케이터의 중앙 영역을 감싸는 제4 인디케이터를 더 포함하고, 상기 제2 인디케이터의 크기가 상기 제4 인디케이터의 경계 이상 상기 제1 인디케이터의 경계 이하에 대응되는경우 상기 그래픽 피드백을 제공하는 이동 단말기."}
{"patent_id": "10-2019-0092154", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제13항에 있어서,공개특허 10-2020-0045946-4-상기 그래픽 피드백은상기 제1 인디케이터를 기준으로 상기 제2 인디케이터의 크기에 대응하여 색깔, 명암, 또는 선명도가 가변되는것을 특징으로 하는 이동 단말기."}
{"patent_id": "10-2019-0092154", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제1항에 있어서,상기 제어부는상기 TOF 카메라를 통해 촬영된 상기 피사체가 제2 거리 범위에 위치하는 경우, 상기 피사체가 상기 특정 오브젝트에 대응되는지 분별하고,상기 피사체가 상기 특정 오브젝트에 대응되는 경우, 상기 가이드 인터페이스를 제공하도록 상기 디스플레이부를 제어하는 것을 특징으로 하는 이동 단말기."}
{"patent_id": "10-2019-0092154", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제1항에 있어서,상기 제어부는상기 특정 오브젝트가 상기 인터렉션 영역에 위치하는 경우, 상기 특정 오브젝트의 모션을 통해 입력 신호를 수신하는 그래픽 인터페이스를 제공하도록 상기 디스플레이 유닛을 제어하는 것을 특징으로 하는 이동 단말기."}
{"patent_id": "10-2019-0092154", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제16항에 있어서,상기 그래픽 인터페이스는상기 특정 오브젝트의 움직임 방향에 대응하여 실행되는 어플리케이션을 포함하는 것을 특징으로 하는 이동 단말기."}
{"patent_id": "10-2019-0092154", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제16항에 있어서,상기 그래픽 인터페이스는상기 특정 오브젝트의 회전 정도에 대응하여 볼륨 조절, 빨리 감기, 화면 밝기 제어 또는 다음 컨텐츠로 이동기능을 제공하는 인터페이스인 것을 특징으로 하는 이동 단말기."}
{"patent_id": "10-2019-0092154", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "이동 단말기에 있어서, 비주얼 컨텐츠를 제공하는 디스플레이부, 피사체를 촬영하여 깊이 이미지를 획득하는 TOF(Time of Flight) 카메라, 및 상기 디스플레이부 및 상기 TOF 카메라에 연결된 제어부를 포함하고, 상기 제어 부는 특정 오브젝트가 상기 TOF 카메라의 촬영 영역 중 인터렉션 영역에 위치하도록 가이드하는 가이드 인터렉션 을 제공하도록 상기 디스플레이부를 제어하는 것을 특징으로 하는 이동 단말기를 제공한다."}
{"patent_id": "10-2019-0092154", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 이동 단말기에 관한 것이다. 보다 상세하게는, 직접 터치 없이 사용자의 손 모션을 통해 입력 신호를 제공하는 기술 분야에 적용이 가능하다."}
{"patent_id": "10-2019-0092154", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "단말기는 이동 가능여부에 따라 이동 단말기(mobile/portable terminal) 및 고정 단말기(stationary termina l)으로 나뉠 수 있다. 다시 이동 단말기는 사용자의 직접 휴대 가능 여부에 따라 휴대(형) 단말기(handheld terminal) 및 거치형 단말기(vehicle mounted terminal)로 나뉠 수 있다. 이동 단말기의 기능은 다양화 되고 있다. 예를 들면, 데이터와 음성통신, 카메라를 통한 사진촬영 및 비디오 촬 영, 음성녹음, 스피커 시스템을 통한 음악파일 재생 그리고 디스플레이에 이미지나 비디오를 출력하는 기능이 있다. 일부 단말기는 전자게임 플레이 기능이 추가되거나, 멀티미디어 플레이어 기능을 수행한다. 특히 최근의 이동 단말기는 방송과 비디오나 텔레비전 프로그램과 같은 시각적 컨텐츠를 제공하는 멀티캐스트 신호를 수신할 수 있다. 이동 단말기는 삼차원 깊이 카메라 기술의 발전과 함께 삼차원 비전(Vision) 기술 기반으로 사용자의 모션 (motion)이나 제스처(gesture)를 감지하여 디바이스를 제어하는 사용자 인터페이스(User Interface, UI)도 발전 하고 있다. 삼차원 비전(Vision) 기반 UO는 기존 이차원 터치 기반 UI를 보완하여 다양한 어플리케이션에 적용 이 가능하다. 예를 들면, 증강현실(Augmented reality, AR) 어플리케이션에서 오브젝트를 삼차원으로 제어할 수 있고, 사용자가 터치할 수 없는 위치에 디바이스가 있는 경우에도 제어할 수 있으며, 사용자의 손이 오염되거나 장갑을 끼고 있을 경우 등 터치가 어려운 경우에도 디바이스를 제어할 수 있게 해준다. 이에, 삼차원 비전 (Vision) 기반 제스처 인식 기술이 각광 받고 있다."}
{"patent_id": "10-2019-0092154", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 직접 터치 없이 사용자의 손 모션을 통해 입력 신호를 제공하되, 사용자의 손 모션을 용이하게 인지 할 수 있도록 사용자의 손을 특정 영역으로 가이드하는 UI를 제공하는 것을 목적으로 한다."}
{"patent_id": "10-2019-0092154", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기 또는 다른 목적을 달성하기 위해, 본 발명 일 측면에 따라, 비주얼 컨텐츠를 제공하는 디스플레이부, 피사 체를 촬영하여 깊이 이미지를 획득하는 TOF(Time of Flight) 카메라, 및 상기 디스플레이부 및 상기 TOF 카메라 에 연결된 제어부를 포함하고, 상기 제어부는 특정 오브젝트가 상기 TOF 카메라의 촬영 영역 중 인터렉션 영역 에 위치하도록 가이드하는 가이드 인터페이스를 제공하도록 상기 디스플레이부를 제어하는 것을 특징으로 하는 이동 단말기를 제공한다. 또한, 본 발명의 일 측면에 따라, 상기 인터렉션 영역은 상기 TOF 카메라에서 제1 거리 범위에 위치하는 것을 특징으로 하는 이동 단말기를 제공한다. 또한, 본 발명의 일 측면에 따라, 상기 인터렉션 영역은 상기 TOF 카메라에서 특정 화각 범위 내에 위치하는 것 을 특징으로 하는 이동 단말기를 제공한다. 또한, 본 발명의 일 측면에 따라, 상기 인터렉션 영역은 상기 TOF 카메라에서 마주하는 평면 상의 특정 좌표 범 위 내에 위치하는 것을 특징으로 하는 이동 단말기를 제공한다. 또한, 본 발명의 일 측면에 따라, 상기 가이드 인터페이스는 상기 인터렉션 영역에 대응되는 제1 인디케이터 및 상기 특정 오브젝트의 움직임에 대응하여 이동하는 제 2인디케이터를 포함하는 것을 특징으로 하는 이동 단말기 를 제공한다. 또한, 본 발명의 일 측면에 따라, 상기 가이드 인터페이스는 상기 제1 인디케이터를 기준으로 움직이는 상기 제 2 인디케이터에 대응하여 그래픽 피드백을 제공하는 것을 특징으로 하는 이동 단말기를 제공한다. 또한, 본 발명의 일 측면에 따라, 상기 그래픽 피드백은 상기 제2 인디케이터가 상기 제1인티케이터의 중앙 영 역에 위치하는 경우 제공되는 것을 특징으로 하는 이동 단말기를 제공한다. 또한, 본 발명의 일 측면에 따라, 상기 가이드 인터페이스는 상기 제1 인디케이터의 중앙 영역을 감싸는 제3 인 티케이터를 포함하고, 상기 그래픽 피드백은 상기 제3 인디케이터에서 상기 제2 인디케이터가 오버렙된 부분을 표시하는 것을 특징으로 하는 이동 단말기를 제공한다. 또한, 본 발명의 일 측면에 따라, 상기 그래픽 피드백은 상기 제1 인디케이터에서 상기 제2 인디케이터가 오버 렙되는 경계 부분을 표시하는 것을 특징으로 하는 이동 단말기를 제공한다. 또한, 본 발명의 일 측면에 따라, 상기 그래픽 피드백은 상기 제2 인디케이터에서 상기 제1 인디케이터가 벗어 난 부분을 표시하는 것을 특징으로 하는 이동 단말기를 제공한다. 또한, 본 발명의 일 측면에 따라, 상기 제2 인디케이터는 상기 사용자의 손과 상기 TOF 카메라와의 거리에 대응 하여 크기가 가변되는 것을 특징으로 하는 이동 단말기를 제공한다. 또한, 본 발명의 일 측면에 따라, 상기 가이드 인터페이스는 상기 제1 인디케이터를 기준으로 가변되는 상기 제 2 인디케이터의 크기에 대응하여 그래픽 피드백을 제공하는 것을 특징으로 하는 이동 단말기를 제공한다. 또한, 본 발명의 일 측면에 따라, 상기 가이드 인터페이스는 상기 제1 인디케이터의 중앙 영역을 감싸는 제4 인 디케이터를 포함하고, 상기 제2 인디케이터의 크기가 상기 제4 인디케이터의 경계 이상 상기 제1 인디케이터의 경계 이하에 대응되는 경우 상기 그래픽 피드백을 제공하는 것을 특징으로 하는 이동 단말기를 제공한다. 또한, 본 발명의 일 측면에 따라, 상기 그래픽 피드백은 상기 제1 인디케이터를 기준으로 상기 제2 인디케이터 의 크기에 대응하여, 색깍, 명암, 또는 선명도가 가변되는 피드백인 것을 특징으로 하는 이동 단말기를 제공한 다. 또한, 본 발명의 일 측면에 따라, 상기 제어부는 상기 TOF 카메라를 통해 촬영된 상기 피사체가 제 2거리 범위 에 위치하는 경우, 상기 피사체가 상기 특정 오브젝트에 대응되는지 분별하고, 상기 피사체가 상기 특정 오브젝 트에 대응되는 경우, 상기 가이드 인터페이스르 제공하도록 상기 디스플레이부를 제어하는 것을 특징으로 하는 이동 단말기를 제공한다. 또한, 본 발명의 일 측면에 따라, 상기 제어부는 상기 특정 오브젝트가 상기 인터렉션 영역에 위치하는 경우, 상기 특정 오브젝트의 모션을 통해 입력 신호를 수신하는 그래픽 인터페이스를 제공하도록 상기 디스플레이 유 닛을 제어하는 것을 특징으로 하는 이동 단말기를 제공한다. 또한, 본 발명의 일 측면에 따라, 상기 그래픽 인터페이스는 상기 특정 오브젝트의 움직임 방향에 대응하여 실 행되는 어플리케이션을 포함하는 것을 특징으로 하는 이동 단말기를 제공한다.. 또한, 본 발명의 일 측면에 따라, 상기 그래픽 인터페이스는 상기 특정 오브젝트의 회전 정도에 대응하여 볼륨 조절, 빨리 감기, 밝기 조절 또는 다음 컨텐츠로 이동 기능을 제공하는 인터페이스인 것을 특징으로 하는 이동 단말기."}
{"patent_id": "10-2019-0092154", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명에 따른 이동 단말기의 효과에 대해 설명하면 다음과 같다. 본 발명의 실시 예들 중 적어도 하나에 의하면, 가이드 인터페이스를 통해 사용자의 손이 특정 영역으로 가이드 할 수 있다. 본 발명의 실시 예들 중 적어도 하나에 의하면, 사용자의 손이 특정 영역에 위치하는 경우 사용자의 손 모션을 통해 입력 신호를 입력할 수 있다. 본 발명의 실시 예들 중 적어도 하나에 의하면, 사용자의 손 모션을 통해 입력된 입력 신호를 통해 이동 단말기 를 직접 터치 없이 제어할 수 있다. 본 발명의 적용 가능성의 추가적인 범위는 이하의 상세한 설명으로부터 명백해질 것이다. 그러나 본 발명의 사 상 및 범위 내에서 다양한 변경 및 수정은 해당 기술 분야의 통상의 기술자에게 명확하게 이해될 수 있으므로, 상세한 설명 및 본 발명의 바람직한 실시 예와 같은 특정 실시 예는 단지 예시로 주어진 것으로 이해되어야 한 다."}
{"patent_id": "10-2019-0092154", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 첨부된 도면을 참조하여 본 명세서에 개시된 실시 예를 상세히 설명하되, 도면 부호에 관계없이 동일하거 나 유사한 구성요소는 동일한 참조 번호를 부여하고 이에 대한 중복되는 설명은 생략하기로 한다. 이하의 설명 에서 사용되는 구성요소에 대한 접미사 \"모듈\" 및 \"부\"는 명세서 작성의 용이함만이 고려되어 부여되거나 혼용 되는 것으로서, 그 자체로 서로 구별되는 의미 또는 역할을 갖는 것은 아니다. 또한, 본 명세서에 개시된 실시 예를 설명함에 있어서 관련된 공지 기술에 대한 구체적인 설명이 본 명세서에 개시된 실시 예의 요지를 흐릴 수 있다고 판단되는 경우 그 상세한 설명을 생략한다. 또한, 첨부된 도면은 본 명세서에 개시된 실시 예를 쉽게 이 해할 수 있도록 하기 위한 것일 뿐, 첨부된 도면에 의해 본 명세서에 개시된 기술적 사상이 제한되지 않으며, 본 발명의 사상 및 기술 범위에 포함되는 모든 변경, 균등물 내지 대체물을 포함하는 것으로 이해되어야 한다. 본 명세서에서 설명되는 이동 단말기에는 휴대폰, 스마트 폰(smart phone), 노트북 컴퓨터(laptop computer), 디지털방송용 단말기, PDA(personal digital assistants), PMP(portable multimedia player), 네비게이션, 슬 레이트 PC(slate PC), 태블릿 PC(tablet PC), 울트라북(ultrabook), 웨어러블 디바이스(wearable device, 예를 들어, 워치형 단말기 (smartwatch), 글래스형 단말기 (smart glass), HMD(head mounted display)) 등이 포함될 수 있다. 그러나, 본 명세서에 기재된 실시 예에 따른 구성은 이동 단말기에만 적용 가능한 경우를 제외하면, 디지털 TV,"}
{"patent_id": "10-2019-0092154", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "데스크탑 컴퓨터, 디지털 사이니지 등과 같은 고정 단말기에도 적용될 수도 있음을 본 기술분야의 해당 기술 분 야의 통상의 기술자라면 쉽게 알 수 있을 것이다. 도 1a 내지 도 1c를 참조하면, 도 1a는 본 발명과 관련된 이동 단말기를 설명하기 위한 블록도이고, 도 1b 및 1c는 본 발명과 관련된 이동 단말기의 일 예를 서로 다른 방향에서 바라본 개념도이다. 상기 이동 단말기는 무선 통신부, 입력부, 센싱부, 출력부, 인터페이스부, 메모 리, 제어부 및 전원 공급부 등을 포함할 수 있다. 도 1a에 도시된 구성요소들은 이동 단말기를 구현하는데 있어서 필수적인 것은 아니어서, 본 명세서 상에서 설명되는 이동 단말기는 위에서 열거된 구성요소 들 보다 많거나, 또는 적은 구성요소들을 가질 수 있다. 보다 구체적으로, 상기 구성요소들 중 무선 통신부는, 이동 단말기와 무선 통신 시스템 사이, 이동 단말기와 다른 이동 단말기 사이, 또는 이동 단말기와 외부서버 사이의 무선 통신을 가능하게 하는 하나 이상의 모듈을 포함할 수 있다. 또한, 상기 무선 통신부는, 이동 단말기를 하나 이상의 네 트워크에 연결하는 하나 이상의 모듈을 포함할 수 있다.이러한 무선 통신부는, 방송 수신 모듈, 이동통신 모듈, 무선 인터넷 모듈, 근거리 통신 모듈, 위치정보 모듈 중 적어도 하나를 포함할 수 있다. 입력부는, 영상 신호 입력을 위한 카메라 또는 영상 입력부, 오디오 신호 입력을 위한 마이크로폰 (microphone, 122), 또는 오디오 입력부, 사용자로부터 정보를 입력받기 위한 사용자 입력부(123, 예를 들어, 터치키(touch key), 푸시키(mechanical key) 등)를 포함할 수 있다. 입력부에서 수집한 음성 데이터나 이 미지 데이터는 분석되어 사용자의 제어명령으로 처리될 수 있다. 센싱부는 이동 단말기 내 정보, 이동 단말기를 둘러싼 주변 환경 정보 및 사용자 정보 중 적어도 하나를 센싱하기 위한 하나 이상의 센서를 포함할 수 있다. 예를 들어, 센싱부는 근접센서(141, proximity sensor), 조도 센서(142, illumination sensor), 터치 센서(touch sensor), 가속도 센서(acceleration sensor), 자기 센서(magnetic sensor), 중력 센서(G-sensor), 자이로스코프 센서(gyroscope sensor), 모션 센 서(motion sensor), RGB 센서, 적외선 센서(IR 센서: infrared sensor), 지문인식 센서(finger scan sensor), 초음파 센서(ultrasonic sensor), 광 센서(optical sensor, 예를 들어, 카메라(121 참조)), 마이크로폰 (microphone, 122 참조), 배터리 게이지(battery gauge), 환경 센서(예를 들어, 기압계, 습도계, 온도계, 방사 능 감지 센서, 열 감지 센서, 가스 감지 센서 등), 화학 센서(예를 들어, 전자 코, 헬스케어 센서, 생체 인식 센서 등) 중 적어도 하나를 포함할 수 있다. 한편, 본 명세서에 개시된 이동 단말기는, 이러한 센서들 중 적어 도 둘 이상의 센서에서 센싱되는 정보들을 조합하여 활용할 수 있다. 출력부는 시각, 청각 또는 촉각 등과 관련된 출력을 발생시키기 위한 것으로, 디스플레이, 음향 출력 부, 햅팁 모듈, 광 출력부 중 적어도 하나를 포함할 수 있다. 디스플레이는 터치 센서와 상호 레이어 구조를 이루거나 일체형으로 형성됨으로써, 터치 스크린을 구현할 수 있다. 이러한 터치 스크린은, 이동 단말기와 사용자 사이의 입력 인터페이스를 제공하는 사용자 입력부로써 기능함과 동시에, 이동 단말 기와 사용자 사이의 출력 인터페이스를 제공할 수 있다. 인터페이스부는 이동 단말기에 연결되는 다양한 종류의 외부 기기와의 통로 역할을 수행한다. 이러한 인터페이스부는, 유/무선 헤드셋 포트(port), 외부 충전기 포트(port), 유/무선 데이터 포트(port), 메모 리 카드(memory card) 포트, 식별 모듈이 구비된 장치를 연결하는 포트(port), 오디오 I/O(Input/Output) 포트 (port), 비디오 I/O(Input/Output) 포트(port), 이어폰 포트(port) 중 적어도 하나를 포함할 수 있다. 이동 단 말기에서는, 상기 인터페이스부에 외부 기기가 연결되는 것에 대응하여, 연결된 외부 기기와 관련된 적절할 제어를 수행할 수 있다. 또한, 메모리는 이동 단말기의 다양한 기능을 지원하는 데이터를 저장한다. 메모리는 이동 단말 기에서 구동되는 다수의 응용 프로그램(application program 또는 애플리케이션(application)), 이동 단 말기의 동작을 위한 데이터들, 명령어들을 저장할 수 있다. 이러한 응용 프로그램 중 적어도 일부는, 무선 통신을 통해 외부 서버로부터 다운로드 될 수 있다. 또한 이러한 응용 프로그램 중 적어도 일부는, 이동 단말기 의 기본적인 기능(예를 들어, 전화 착신, 발신 기능, 메시지 수신, 발신 기능)을 위하여 출고 당시부터 이 동 단말기상에 존재할 수 있다. 한편, 응용 프로그램은, 메모리에 저장되고, 이동 단말기 상에 설치되어, 제어부에 의하여 상기 이동 단말기의 동작(또는 기능)을 수행하도록 구동될 수 있다. 제어부는 상기 응용 프로그램과 관련된 동작 외에도, 통상적으로 이동 단말기의 전반적인 동작을 제 어한다. 제어부는 위에서 살펴본 구성요소들을 통해 입력 또는 출력되는 신호, 데이터, 정보 등을 처리하 거나 메모리에 저장된 응용 프로그램을 구동함으로써, 사용자에게 적절한 정보 또는 기능을 제공 또는 처 리할 수 있다. 또한, 제어부는 메모리에 저장된 응용 프로그램을 구동하기 위하여, 도 1a와 함께 살펴본 구성요소들 중 적어도 일부를 제어할 수 있다. 나아가, 제어부는 상기 응용 프로그램의 구동을 위하여, 이동 단말기 에 포함된 구성요소들 중 적어도 둘 이상을 서로 조합하여 동작시킬 수 있다. 전원공급부는 제어부의 제어 하에서, 외부의 전원, 내부의 전원을 인가 받아 이동 단말기에 포 함된 각 구성요소들에 전원을 공급한다. 이러한 전원공급부는 배터리를 포함하며, 상기 배터리는 내장형 배터리 또는 교체 가능한 형태의 배터리가 될 수 있다. 상기 각 구성요소들 중 적어도 일부는, 이하에서 설명되는 다양한 실시 예들에 따른 이동 단말기의 동작, 제어, 또는 제어방법을 구현하기 위하여 서로 협력하여 동작할 수 있다. 또한, 상기 이동 단말기의 동작, 제어, 또는 제어방법은 상기 메모리에 저장된 적어도 하나의 응용 프로그램의 구동에 의하여 이동 단말기 상에서 구현될 수 있다. 도 1 b 및 1c는 펼쳐진 상태의 폴더블 방식의 이동 단말기에서의 기본적인 특징에 대해 설명한다. 이동 단말기에는 디스플레이, 제1 및 제2 음향 출력부(152a, 152b), 근접 센서, 조도 센서 , 광 출력부, 제1 및 제2 카메라(121a, 121b), 제1 및 제2 조작유닛(123a, 123b), 마이크로폰, 인터페이스부 등이 구비될 수 있다. 이하에서는, 도 1b 및 도 1c에 도시된 바와 같이, 단말기 바디의 전면에 디스플레이, 제1 음향 출력부 (152a), 근접 센서, 조도 센서, 광 출력부, 제1 카메라(121a) 및 제1 조작유닛(123a)이 배치되고, 단말기 바디의 측면에 제2 조작유닛(123b), 마이크로폰 및 인터페이스부이 배치되며, 단말기 바디의 후면에 제2 음향 출력부(152b) 및 제2 카메라(121b)가 배치된 이동 단말기를 일 예로 들어 설명한다. 다만, 이들 구성은 이러한 배치에 한정되는 것은 아니다. 이들 구성은 필요에 따라 제외 또는 대체되거나, 다른 면에 배치될 수 있다. 예를 들어, 단말기 바디의 전면에는 제1 조작유닛(123a)이 구비되지 않을 수 있으며, 제2 음향 출력부(152b)는 단말기 바디의 후면이 아닌 단말기 바디의 측면에 구비될 수 있다. 디스플레이는 이동 단말기에서 처리되는 정보를 표시(출력)한다. 예를 들어, 디스플레이는 이동 단말기에서 구동되는 응용 프로그램의 실행화면 정보, 또는 이러한 실행화면 정보에 따른 UI(User Interface), GUI(Graphic User Interface) 정보를 표시할 수 있다. 디스플레이는 액정 디스플레이(liquid crystal display, LCD), 박막 트랜지스터 액정 디스플레이(thin film transistor-liquid crystal display, TFT LCD), 유기 발광 다이오드(organic light-emitting diode, OLED), 플렉서블 디스플레이(flexible display), 3차원 디스플레이(3D display), 전자잉크 디스플레이(e-ink display) 중에서 적어도 하나를 포함할 수 있다. 또한, 디스플레이는 이동 단말기의 구현 형태에 따라 2개 이상 존재할 수 있다. 이 경우, 이동 단말 기에는 복수의 디스플레이들이 하나의 면에 이격되거나 일체로 배치될 수 있고, 또한 서로 다른 면에 각각 배치될 수도 있다. 디스플레이는 터치 방식에 의하여 제어 명령을 입력 받을 수 있도록, 디스플레이에 대한 터치를 감지 하는 터치센서를 포함할 수 있다. 이를 이용하여, 디스플레이에 대하여 터치가 이루어지면, 터치센서는 상 기 터치를 감지하고, 제어부는 이에 근거하여 상기 터치에 대응하는 제어명령을 발생시키도록 이루어질 수 있다. 터치 방식에 의하여 입력되는 내용은 문자 또는 숫자이거나, 각종 모드에서의 지시 또는 지정 가능한 메 뉴항목 등일 수 있다. 한편, 터치센서는, 터치패턴을 구비하는 필름 형태로 구성되어 디스플레이를 덮는 윈도우(151a)와 디스플 레이를 구성하는 복수의 레이어 사이에 배치되거나, 윈도우(151a)의 배면에 직접 패터닝되는 메탈 와이어 가 될 수도 있다. 또는, 터치센서는 디스플레이와 일체로 형성될 수 있다. 예를 들어, 터치센서는, 디스플레이 의 기판 상에 배치되거나, 디스플레이의 내부에 구비될 수 있다. 이처럼, 디스플레이는 터치센서와 함께 터치 스크린을 형성할 수 있으며, 이 경우에 터치 스크린은 사용자 입력부(123, 도 1a 참조)로 기능할 수 있다. 경우에 따라, 터치 스크린은 제1조작유닛(123a)의 적어도 일부 기 능을 대체할 수 있다. 제1 음향 출력부(152a)는 통화음을 사용자의 귀에 전달시키는 리시버(receiver)로 구현될 수 있으며, 제2 음향 출력부(152b)는 각종 알람음이나 멀티미디어의 재생음을 출력하는 라우드 스피커(loud speaker)의 형태로 구현 될 수 있다. 디스플레이의 윈도우(151a)에는 제1 음향 출력부(152a)로부터 발생되는 사운드의 방출을 위한 음향홀이 형 성될 수 있다. 다만, 본 발명은 이에 한정되는 것은 아니고, 상기 사운드는 구조물 간의 조립틈(예를 들어, 윈 도우(151a)와 프론트 케이스 간의 틈)을 따라 방출되도록 구성될 수 있다. 이 경우, 외관상 음향 출력을 위하여 독립적으로 형성되는 홀이 보이지 않거나 숨겨져 이동 단말기의 외관이 보다 심플해질 수 있다. 광 출력부는 이벤트의 발생시 이를 알리기 위한 빛을 출력하도록 이루어진다. 상기 이벤트의 예로는 메시지 수 신, 호 신호 수신, 부재중 전화, 알람, 일정 알림, 이메일 수신, 애플리케이션을 통한 정보 수신 등을 들 수 있 다. 제어부는 사용자의 이벤트 확인이 감지되면, 빛의 출력이 종료되도록 광 출력부를 제어할 수 있다. 제1 카메라(121a)는 촬영 모드 또는 화상통화 모드에서 이미지 센서에 의해 얻어지는 정지영상 또는 동영상의 화상 프레임을 처리한다. 처리된 화상 프레임은 디스플레이에 표시될 수 있으며, 메모리에 저장될 수 있다. 제1 및 제2 조작유닛(123a, 123b)은 이동 단말기의 동작을 제어하기 위한 명령을 입력 받기 위해 조작되는 사용자 입력부의 일 예로서, 조작부(manipulating portion)로도 통칭될 수 있다. 제1 및 제2 조작유닛 (123a, 123b)은 터치, 푸시, 스크롤 등 사용자가 촉각적인 느낌을 받으면서 조작하게 되는 방식(tactile manner)이라면 어떤 방식이든 채용될 수 있다. 또한, 제1 및 제2 조작유닛(123a, 123b)은 근접 터치(proximity touch), 호버링(hovering) 터치 등을 통해서 사용자의 촉각적인 느낌이 없이 조작하게 되는 방식으로도 채용될 수 있다. 본 도면에서는 제1 조작유닛(123a)이 터치키(touch key)인 것으로 예시하나, 본 발명이 이에 한정되는 것은 아 니다. 예를 들어, 제1 조작유닛(123a)은 푸시키(mechanical key)가 되거나, 터치키와 푸시키의 조합으로 구성될 수 있다. 제1 및 제2 조작유닛(123a, 123b)에 의하여 입력되는 내용은 다양하게 설정될 수 있다. 예를 들어, 제1 조작유 닛(123a)은 메뉴, 홈키, 취소, 검색 등의 명령을 입력 받고, 제2 조작유닛(123b)은 제1 또는 제2 음향 출력부 (152a, 152b)에서 출력되는 음향의 크기 조절, 디스플레이의 터치 인식 모드로의 전환 등의 명령을 입력 받을 수 있다. 한편, 단말기 바디의 후면에는 사용자 입력부의 다른 일 예로서, 후면 입력부(미도시)가 구비될 수 있다. 이러한 후면 입력부는 이동 단말기의 동작을 제어하기 위한 명령을 입력 받기 위해 조작되는 것으로서, 입 력되는 내용은 다양하게 설정될 수 있다. 예를 들어, 전원의 온/오프, 시작, 종료, 스크롤 등과 같은 명령, 제1 및 제2 음향 출력부(152a, 152b)에서 출력되는 음향의 크기 조절, 디스플레이의 터치 인식 모드로의 전환 등과 같은 명령을 입력 받을 수 있다. 후면 입력부는 터치입력, 푸시입력 또는 이들의 조합에 의한 입력이 가능 한 형태로 구현될 수 있다. 후면 입력부는 단말기 바디의 두께방향으로 전면의 디스플레이와 중첩되게 배치될 수 있다. 일 예로, 사용 자가 단말기 바디를 한 손으로 쥐었을 때 검지를 이용하여 용이하게 조작 가능하도록, 후면 입력부는 단말기 바 디의 후면 상단부에 배치될 수 있다. 다만, 본 발명은 반드시 이에 한정되는 것은 아니며, 후면 입력부의 위치 는 변경될 수 있다. 이처럼 단말기 바디의 후면에 후면 입력부가 구비되는 경우, 이를 이용한 새로운 형태의 유저 인터페이스가 구 현될 수 있다. 또한, 앞서 설명한 터치 스크린 또는 후면 입력부가 단말기 바디의 전면에 구비되는 제1 조작유 닛(123a)의 적어도 일부 기능을 대체하여, 단말기 바디의 전면에 제1 조작유닛(123a)이 미배치되는 경우, 디스 플레이가 보다 대화면으로 구성될 수 있다. 한편, 이동 단말기에는 사용자의 지문을 인식하는 지문인식센서가 구비될 수 있으며, 제어부는 지문인식센서를 통하여 감지되는 지문정보를 인증수단으로 이용할 수 있다. 상기 지문인식센서는 디스플레 이 또는 사용자 입력부에 내장될 수도 있고, 별도의 위치에 구비될 수도 있다. 마이크로폰은 사용자의 음성, 기타 소리 등을 입력 받도록 이루어진다. 마이크로폰은 복수의 개소에 구비되어 스테레오 음향을 입력 받도록 구성될 수 있다. 인터페이스부는 이동 단말기를 외부기기와 연결시킬 수 있는 통로가 된다. 예를 들어, 인터페이스부 는 다른 장치(예를 들어, 이어폰, 외장 스피커)와의 연결을 위한 접속단자, 근거리 통신을 위한 포트[예를 들어, 적외선 포트(IrDA Port), 블루투스 포트(Bluetooth Port), 무선 랜 포트(Wireless LAN Port) 등], 또는 이동 단말기에 전원을 공급하기 위한 전원공급단자 중 적어도 하나일 수 있다. 이러한 인터페이스부 는 SIM(Subscriber Identification Module) 또는 UIM(User Identity Module), 정보 저장을 위한 메모리 카드 등의 외장형 카드를 수용하는 소켓의 형태로 구현될 수도 있다. 단말기 바디의 후면에는 제2카메라(121b)가 배치될 수 있다. 이 경우, 제2카메라(121b)는 제1카메라(121a)와 실 질적으로 반대되는 촬영 방향을 가지게 된다. 제2카메라(121b)는 적어도 하나의 라인을 따라 배열되는 복수의 렌즈를 포함할 수 있다. 복수의 렌즈는 행렬 (matrix) 형식으로 배열될 수도 있다. 이러한 카메라는, '어레이(array) 카메라'로 명명될 수 있다. 제2카메라 (121b)가 어레이 카메라로 구성되는 경우, 복수의 렌즈를 이용하여 다양한 방식으로 영상을 촬영할 수 있으며, 보다 나은 품질의 영상을 획득할 수 있다.플래시는 제2카메라(121b)에 인접하게 배치될 수 있다. 플래시는 제2카메라(121b)로 피사체를 촬영하 는 경우에 피사체를 향하여 빛을 비추게 된다. 단말기 바디에는 제2 음향 출력부(152b)가 추가로 배치될 수 있다. 제2 음향 출력부(152b)는 제1 음향 출력부 (152a)와 함께 스테레오 기능을 구현할 수 있으며, 통화시 스피커폰 모드의 구현을 위하여 사용될 수도 있다. 단말기 바디에는 무선 통신을 위한 적어도 하나의 안테나가 구비될 수 있다. 안테나는 단말기 바디에 내장되거 나, 케이스에 형성될 수 있다. 예를 들어, 방송 수신 모듈(111, 도 1a 참조)의 일부를 이루는 안테나는 단말기 바디에서 인출 가능하게 구성될 수 있다. 또는, 안테나는 필름 타입으로 형성되어 후면 커버의 내측면에 부착될 수도 있고, 도전성 재질을 포함하는 케이스가 안테나로서 기능하도록 구성될 수도 있다. 단말기 바디에는 이동 단말기에 전원을 공급하기 위한 전원 공급부(190, 도 1a 참조)가 구비된다. 전원 공 급부는 단말기 바디에 내장되거나, 단말기 바디의 외부에서 착탈 가능하게 구성되는 배터리를 포함할 수 있다. 배터리는 인터페이스부에 연결되는 전원 케이블을 통하여 전원을 공급받도록 구성될 수 있다. 또한, 배터리는 무선충전기기를 통하여 무선충전 가능하도록 구성될 수도 있다. 상기 무선충전은 자기유도방식 또는 공진방식(자기공명방식)에 의하여 구현될 수 있다. 한편, 본 도면에서는 후면 커버가 배터리를 덮도록 리어 케이스에 결합되어 배터리의 이탈 을 제한하고, 배터리를 외부 충격과 이물질로부터 보호하도록 구성된 것을 예시하고 있다. 배터리가 단말기 바디에 착탈 가능하게 구성되는 경우, 후면 커버는 리어 케이스에 착탈 가능하게 결합될 수 있다. 본 발명에 적용되는 카메라(도 1에 도시된 카메라 및 도 2A에 도시된 카메라(121a))는 모바일 디바이스의 터치 스크린 주변에 위치하고 있다. 따라서, 상기 모바일 디바이스의 터치 스크린으로부터 일정 거리이내의 오브젝트(예를 들어, 사용자의 손가락)에 대한 깊이 정보(depth information)를 디텍트 하는 것이 가능하다. 이와 같은 카메라를 깊이 카메라로 명명할 수 있다. 상기 깊이 카메라를 구현하는 방법으로 2가지 방안을 제시한다. 첫번째 방안은, 멀티 카메라(또는 렌즈)를 사 용하는 방법으로서 2개 이상의 카메라를 이용하여 가시광선을 포착하고, 깊이 정보(depth information)를 이용 하여 3D 이미지를 생성한다. 두번째 방안은, 카메라 모듈에 심도 센싱(Depth sensing)을 위한 별도의 센서를 탑재하는 방식으로서, 보다 구체적으로는 SL(Structured Light) 및 ToF(Time of Flight) 방식이 적용된다. 전술한 SL 방식은, 직선이나 격자 무늬 등 특정 패턴의 레이저를 촬영 대상에 방사한 후 대상 표면의 모양에 따 라 패턴이 변형된 정보를 분석한다. 나아가, 깊이 정보를 계산한 후, 이미지 센서가 촬영한 사진과 합성하여 3D 기반의 촬영 결과를 도출한다. 이를 구현하기 위하여, 특정 패턴을 송출하는 레이저 적외선(IR) 프로젝터, 적외선 심도 센서, 이미지 센서 및 3D 프로세서 등이 사용될 수 있다. 전술한 ToF 방식은, 레이저가 촬영 대상에 갔다가 반사되어 돌아오는 시간을 측정하여 깊이 정보를 계산한 후, 이미지 센서가 촬영한 사진과 합성하여 3D 기반의 촬영 결과를 도출한다. 이를 구현하기 위하여, 레이저 적외 선(IR) 프로젝터, 수신 센서, 이미지 센서 및 3D 프로세서 등이 사용될 수 있다. 도 2은 본 발명의 일 실시예에 따라, 깊이 카메라와 근접 센서와 근접센서를 기초로 삼차원 비전 기반 UI를 수 행하기 위한 본 발명의 구성도이다. 본 발명은 3차원 깊이 카메라와 근접 센서를 통해 사용자의 손을 감지하고 그에 따라 디바이스를 활 성화 또는 비활성화할 수 있는 시스템에 관한 발명이다. 본 발명의 디바이스는 이동 단말기를 포함할 수 있으나 반드시 이에 한정되지 않고, 삼차원 비전 기반 UI를 활 용할 수 있는 텔레비전, 인공지능 기기, 테블릿 등을 포함할 수 있다. 본 발명의 깊이 카메라는 TOF(Time-of-Flight) 방식의 카메라가 사용될 수 있으나, 반드시 이러한 방식의 카메라에 한정되지 않는다. 본 발명의 근접 센서는 빛을 조사하고 반사되는 빛의 세기를 통해 근접 여부를 판단하는 방식의 센서가 사 용될 수 있으나, 반드시 이러한 방식의 센서에 한정되지는 않는다. 근접센서 가 오브젝트의 근접여부를 판 단하는 방식과 관련하여서는 도 7에서 구체적으로 살펴본다.본 발명은 근접 센서를 통해 오브젝트가 근접한 것으로 감지한 경우, 깊이 카메라를 통해 깊이 이미 지를 획득하고, 획득한 깊이 이미지에서 오브젝트가 사용자의 손에 대응되는지 여부를 분별할 수 있다. 본 발명은 추가적으로 디바이스의 상태를 감지할 수 있는 모션 센서를 구비할 수 있다. 모션 센서는 디바이스가 삼차원 기반 UI를 수행하기 적합한 상태로 디바이스가 존재하는지 여부를 감지할 수 있다. 예를 들어, 모션 센서는 디바이스가 테이블 위에 있거나, 사용자를 향해 고정되어 있는 경우 등 사용자가 디바이스와 삼차원 기반 UI를 수행하기 적합한 안정된 상태인지 여부를 감지할 수 있다. 이를 위해, 모션 센서는 가속도 센서, 자이로 센서등을 포함할 수 있다. 모션 센서는 근접 센서를 활성화시키는 트리거 역할을 수행할 수 있다. 즉, 모션 센서를 통해 디바이스가 안정된 상태에서만 근접 센서를 통해 오브젝트의 근접 여부를 판단하는 데이터를 획득할 수 있 다. 다만, 디바이스가 텔레비전과 같이 고정되어 있는 경우에는 모션 센서가 필요 없을 수 있다. 이 경우, 모 션 센서는 항상 활성 상태로 구동하고 있을 수 있다. 구체적으로, 모션 센서와 근점 센서는 저전력으로 구동하는 저전력 프로세서(low power processor, 500)를 통해 제어될 수 있다. 저전력 프로세서는 모션 센서와 연결되어 모션 센서에서 획득한 데이터를 통해 디바이스의 모션 상태를 감지하는 디바이스 상태 감지부(Device state checker, 510)를 포함할 수 있다. 디바이스 상태 감지부는 디바이스의 모션이 사용자와 삼차원 비전 기반 UI를 수행하기 안정된 상태임을 감 지한 경우, 근접 센서 트리거(Proximity tigger, 520)를 통해 근접 센서를 활성화 시키고 오브젝트 근접 여부를 판단하기 위한 데이터를 획득할 수 있다. 근접 센서 트리거는 근접 센서를 통해 획득한 데이터로 초기 값(=베이스 라인, baseline)을 설정하고, 설정된 초기 값을 통해 오브젝트의 근접여부를 판단할 수 있다. 근접 센서 트리거를 통해 오브젝트가 근접한 상태임을 감지한 경우, 깊이 카레라를 활성화 시킬 수 있다. 깊이 카메라는 고사양 프로세서(high performance processor, 600)에 연결되며, 고사양 프로세서는 깊이 카메라를 제어하여 깊이 이미지를 획득하고, 삼차원 비전 기반 UI를 수행하기 위해 사용자의 인덱스 핑거를 트렉킹(tracking)하는 기능을 제공할 수 있다. 구체적으로, 고사양 프로세서는 깊이 카메라에서 깊이 이미지를 획득하도록 제어하고, 획득한 깊이 이미지로 오브젝트가 사용자의 손에 대응되는 여부를 분별하는 오브젝트 분별부를 포함할 수 있다. 깊이 카메라는 레디 모드(ready mode)에서 깊이 이미지를 획득하고 오브젝트 분별부를 통해 깊이 이 미지의 형상을 분별할 수 있다. 레디 모드(ready mode)는 근접 센서를 통해 오브젝트가 근접한 경우 활성화 될 수 있다. 오브젝트 분별부에서 오브젝트를 분별하고, 분별 결과에 따라 근접 센서의 초기 값을 업데이트 할 수 있다. 이는 근접 센서의 초기 값이 잘못 설정되거나, 근접 센서 부근이 오염되어 깊이 카메라가 불필 요하게 사용자 손의 인덱스 핑거(index finger)를 크랙킹하는 엑티브 모드(active mode)로 작동하는 것을 방지 하기 위함이다. 이와 관련하여서는 도 7에서 구체적으로 살펴본다. 고사양 프로세서는 오브젝트 분별부를 통해 사용자의 손을 인지한 경우, 사용자 손의 제스처를 감지 하거나, 사용자 손의 인덱스 핑거를 트랙킹하는 트랙킹부를 활성화할 수 있다. 고사양 프로세서는 경우에 따라 깊이 카메라를 통해 이차원 이미지를 획득하고 오브젝트 유무를 감지 하는 오브젝트 감지부를 더 포함할 수 있다. 오브젝트 감지부는 근접센서의 역할을 대신하는 구성일 수 있다. 즉, 깊이 카메라가 인텐서티 (intensity) 데이터에 대응되는 이차원 이미지를 획득할 수 있는 경우, 깊이 카메라는는 오브젝트 감지부를 통해 저전력 모드로 운영될 수 있다. 저전력 모드로 깊이 카메라를 운영하는 도중, 오브젝트가 존재하는 것으로 감지한 경우, 오브젝트 분별부 를 활성화 하여 레디 모드로 전환될 수 있다. 오브젝트 감지부는 근접 센서와 같은 역할을 하기 때문에, 본 발명에서 오브젝트 감지부가 포함 되는 경우 근접 센서 및 근접 센서 트리거가 생략되고, 오브젝트 감지부는 디바이스 상태 감지 부에 의해 활성되도록 구성될 수 있다. 또한, 저전력 프로세서 및 고사양 프로세서는 연산 및 처리능력으로 구분된 구성으로 반드시 분할되 지 않고 하나의 컨트롤러에 포함되는 구성일 수 있다. 도 3은 본 발명의 일 실시예에 따라, 삼차원 비전 기반 UI를 수행하기 위한 프로세서를 설명하는 흐름도이다. 도3은 도 2에 개시된 본 발명의 시스템을 기초로 삼차원 비전 기반 UI를 수행하기 위한 프로세서를 설명하는 흐 름도이다. 본 발명에 따른 프로세서는 모션 센서에서 획득한 데이터를 디바이스 통해 디바이스의 모션을 확인하고, 디바이스가 삼차원 비전 기반 UI를 수행하기 적합한 모션인 경우에 근접 센서를 활성화 시킬 수 있다. (S210) 다만, 디바이스가 이동 단말기와 같이 휴대용이 아닌 거치형인 경우 모션 센서를 통해 디바이스의 모션을 확인하는 단계는 생략될 수 있다. 이 경우, 근접 센서는 항상 활성화된 상태일 수 있다. 또한, 본 발명에 따른 깊이 카메라를 통해 2차원 이미지를 획득하고, 오브젝트의 존부를 감지할 수 있는 경우(=오브젝트 감지부가 존재하는 경우), 오브젝트 감지부가 근접 센서를 대신할 수 있다. 다 만, 이하에서는 근접 센서를 통해 근접한 오브젝트의 유부를 분별하는 프로세서를 기초하여 본 발명을 설 명한다. 근접 센서가 활성화 된 경우 데이터를 획득하여 오브젝트의 근접 여부를 확인하고 깊이 카메라를 활 성화 시킬 수 있다. (S220) 여기서 깊이 카메라를 활성화 시키는 의미는 깊이 카메라를 레디 모드로 작동 하는 것을 의미한다. 근접 센서는 다양한 방식의 센서가 사용될 수 있으나, 대표적으로 오브젝트에 반사되어 되돌아 오는 빛의 세기를 감지하여 오브젝트의 근접여부를 분별할 수 있다. 근접 센서는 오브젝트에 반사되어 되돌아 오는 빛을 감지하여 평균 값을 통해 베이스 라인(base line)을 설정하고, 설정된 베이스 라인에서 기 설정 값을 더하여 트레숄드(threshold) 값을 설정할 수 있다. 트레숄드 (threshold) 값이 설정되면 이후 감지된 빛의 세기를 트레숄드 값과 비교하여 오브젝트의 근접 여부를 분별할 수 있다. 오브젝트 분별부는 깊이 카메라가 레디 모드로 운영되는 경우 활성화 되고, 깊이 카메라에서 깊 이 이미지를 획득하여 오브젝트를 분별할 수 있다. (S230) 오브젝트는 깊이 이미지의 형상 및 기 저장된 데이터 베이스를 통해 분별할 수 있다. 본 발명은 사용자의 손을 트랙킹하여 삼차원 비전 기반 UI를 수행하는 것이기 때문에, 오브젝트가 손에 대응되 는지, 손이 아닌 다른 오브젝트인지를 분별하고, 경우에 따라서는 오브젝트가 없는 경우도 분별할 수 있다. 오브젝트가 손에 대응되는지, 손이 아닌 다른 오브젝트인지 또는 오브젝트가 없는 경우 각각에 대응하여 근접 센서의 초기 값을 재설정할 수 있다.(S240) 이는, 근접 센서의 잘못 설정된 초기 값을 정정하고, 인 접 부위가 오염되어 센싱에 착오가 생기는 것을 방지하기 위함이다. 근접 센서의 초기 값을 재설정하고, 재설정된 근접 센서에 기초하여 활성화된 깊이 카메라에서 오브젝트를 분별한 결과 사용자에 손에 대응되는 경우, 이에 대응하여 디바이스의 상태를 변경할 수 있 다.(S250) 예를 들어, 디바이스가 슬립 모드인 경우, 웨이크업 하고, 사용자 손의 인덱스 핑거를 추적하며 사용자와 삼차 원 비전 기반 UI를 수행할 수 있다. 도 4 는 본 발명의 일 실시예에 따라, 모션 센서를 통해 선별적으로 근접 센서를 활성화하는 프로세서를 설명하 는 흐름도이다. 도4는 도 2에 개시된 본 발명의 시스템을 기초로 모션 센서를 통해 삼차원 비전 기반 UI를실행하는 프로세서를 설명하기 위한 흐름도이다. 본 발명의 디바이스가 이동 단말기와 같이 휴대용인 경우 모션 센서를 통해 근접 센서를 활성화함이 전력 소모 방지 및 프로세서 안정화 측면에서 바람직할 수 있다. 모션 센서는 가속도 센서, 자이로 센서, 자기 센서등을 포함할 수 있으며, 이를 통해 디바이스의 모션을 판단하기 위한 데이터터를 획득할 수 있다. (S211) 디바이스 모션을 판단하기 위해 3축 데이터가 사용될 수 있지만, 경우에 따라서는 9축 이상의 데이터가 사용될 수 있다. 모션 센서를 통해 기 설정된 시간 간격으로 획득한 데이터를 통해 디바이스의 움직임 상태를 판단할 수 있 다.(S212) N번째 프레임과 N-1번째 프레임 간 데이터 차이를 정해진 기준 값과 비교하여 디바이스의 움직임을 판단할 수 있으며, 축 이동을 통해 디바이스가 고정된 바닥에 올려져 있는지, 사용자를 바라보며 고정된 상태로 있는지 여 부를 분별할 수 있다. 디바이스가 사용자의 손을 트랙킹 하여 삼차원 비전 기반 UI를 수행하기 적합한 안정 상태에 있는 경우(S213, Yes), 근접 센서를 활성화 하여 오브젝트의 근접 여부를 판단하기 위한 데이터를 획득할 수 있다. 근접 센서가 활성화 된 경우, 디바이스의 모션을 감지하기 위한 데이터를 획득하는 것을 일시적으로 중단 할 수 있다. 반면, 디바이스가 사용자의 손을 트랙킹 하여 삼차원 비전 기반 UI를 수행하기 어려운 상태에 있는 경우(S213, No), 깊이 이미지를 획득할 필요가 없는바 근접 센서를 비활성 상태로 두고 디바이스가 안정 상태에 도달 할 때까지 모션 센서를 통해 데이터를 획득하는 동작을 수행할 수 있다. 도 5는 본 발명의 일 실시예에 따라, 근접센서의 트레숄드(threshold) 값을 설정하고, 이를 기초로 깊이 카메라 를 활성화하는 프로세서를 설명하는 흐름도이다. 이하, 도 2에 개시된 본 발명의 시스템을 기초로 도 5를 설명 한다. 근접 센서는 활성화 되면, 오브젝트의 근접 여부를 판단하기 위해 빛을 조사하고 반사되어 돌아오는 빛의 세기에 대응되는 데이터를 획득할 수 있다.(S221) 다만, 근접 센서가 오브젝트의 근접 여부를 판단하는 방법은 반사된 빛을 감지하는데 한정되지 않는다. 근접 센서는 활성화된 후 획득한 기 설정 개수의 프레임의 데이터를 평균하여 초기 값(=baseline)을 설정 할 수 있다. (S222) 경우에 따라서는, 본 발명은 기 설정된 값을 초기 값으로 설정할 수 있다. 초기 값에 기 설정 값을 더하여 오브젝트의 근접 여부를 분별하는 기준 값인 트레숄드(threshold) 값을 설정할 수 있다. (S223) 근접 센서에서 획득한 데이터가 트레숄드 값 보다 큰 경우 오브젝트가 근접한 상태로 분별될 수 있다. 반 대로, 근접 센서에서 획득한 데이터가 트레숄드 값 보다 작은 경우 오브젝트가 멀리 떨어져 있는 상태로 분별될 수 있다. 근접 센서에서 획득한 데이터가 트레숄드 값을 초과하는 경우(S224, Yes) 오브젝트가 근접한 것으로 분별 하고 깊이 카메라를 (레디 모드로) 활성화 할 수 있다. (S225) 반면, 근접 센서 에서 획득한 데이터가 트레숄드 값을 초과하지 않는 경우, 깊이 카메라를 활성화하 지 않고 근접 센서를 통해 데이터를 계속적으로 획득할 수 있다. (S224, No) 이때, 디바이스의 모션이 안 정상태에서 벗어난 경우, 근접 센서를 비활성화 하고 데이터 획득을 중단할 수 있다. 도 6은 본 발명의 일 실시예에 따라, 분별된 오브젝트에 따라 근접 센서의 초기 값을 재설정하기 위한 모드를 달리하는 프로세서를 설명하는 흐름도이다. 이하에서 도 2를 기초로 도 6을 설명한다. 근접 센서를 통해 오브젝트가 근접한 것으로 판별한 경우, 깊이 카레라를 레디 모드로 활성화 한다. 레디 모드에서 깊이 카메라는 깊이 이미지를 획득한다. (S231) 오브젝트 분별부에서는 획득한 깊이 이미지를 통해 기 설정 거리 이내에 오브젝트가 존재하는 지 판별한다. (S232)기 설정 거리 이내에 오브젝트가 없는 경우(S232, No), 오브젝트가 없는 경우에 대응하여 근접 센서의 초 기 값을 재설정할 수 있다. (S234) 기 설정 거리 이내에 오브젝트가 없는 것은 근접 센서의 초기 값이 너 무 낮게 설정된 경우 이거나, 근접 센서 인근에 오염 물질이 끼인 상태일 수 있다 기 설정 거리 이내에 오브젝트가 있는 경우(S232, Yes), 오브젝트 분별부는 기 저장된 데이터 베이스를 통 해 오브젝트가 손인지 아닌지를 분별할 수 있다. (S233) 오브젝트가 손에 대응되는지 손이 아닌 다른 오브젝트인지에 대응하여 각각 근접 센서 초기 값 재설정할 수 있 다. (S234) 도 7은 본 발명의 일 실시예에 따라, 근접 센서의 초기 값을 재설정할 필요성을 설명하기 위한 도면이다. 기존에는 도 7(a)과 같이 절대값으로 트레숄드 값(302, 303)을 설정하고, 근접 센서를 통해 획득한 데이터 와 트레숄드 값(302, 302)를 비교하여 오브젝트의 근접 여부를 판단하였다. 트레숄드 값은 하나로 설정할 수 있으나, 보다 분명하게 분별하기 위해서 두 개의 트레숄드 값을 설정할 수 있 다. 즉, 데이터가 제1 트레숄드 값 보다 높은 경우, 오브젝트가 근접(Near)한 것으로 판단하고, 데이터가 제2 트레숄드 값보다 낮은 경우 오브젝트가 멀리 떨어져 있는 것으로 판단하였다. 다만, 도 7(b)와 같이 트레숄드 값을 절대적으로 설정한 경우, 제1 트레숄드 값와 제2 트레숄드 값 사이에 존재하는 데이터도 근접 센서 인접 부위에 오염이 발생하여 전체적인 데이터 값이 상승하면 오브젝 트가 근접(Near)한 것으로 잘못 판단할 수 있다. 따라서, 이러한 오판을 방지하기 위해서, 도 7(c)와 같이 근접 센서는 기 설정 프레임을 평균하여 초기 값 (= base line, 304)을 설정하고, 초기 값을 기초로 기 설정 값 이상으로 트레숄드 값을 상대적으로 설정하 는 경우, 근접 센서의 인접 부위 오염으로 데이터 값이 전체적으로 상승하더라도 오브젝트의 근접 여부를 착오 없이 분별할 수 있다. 다만, 이러한 근접 센서의 초기 값은 깊이 이미지를 기초하여 재설정할 수 있는데 이하에서 살펴보도록 한 다. 도 8 내지 10은 본 발명의 일 실시예에 따라, 오브젝트의 유무 또는 오브젝트의 종류에 따라 근접 센서의 트레 숄드(threshold) 값을 업데이트하는 프로세서를 설명하는 흐름도이다. 이하에서 도 2를 기초로 도 8 내지 10을 설명한다. 구체적으로, 도 8은 근접한 오브젝트가 사용자의 손에 대응되는 경우의 흐름도 이며, 도 9는 근접한 오브젝트가 사용자의 손이 아닌 다른 오브젝트에 대응되는 경우의 흐름도 이고, 도 10은 근접한 오브젝트가 없는 경우의 흐 름도이다. 근접한 오브젝트가 사용자의 손으로 분별되면, 근접 센서가 깊이 카메라를 활성화 한 것이 적적한 것 이었으므로 따로 근접 센서의 초기 값을 재설정하지 않는다. 구체적으로, 도 8을 살펴보면, 근접한 오브젝트가 사용자의 손으로 분별되면, (S2411), 오브젝트 분별부은 이를 근접 센서 트리거에 전달하고, 근접 센서 트리거는 근접 센서를 통해 데이터를 획득한 다.(S2412) 근접 센서를 통해 획득한 데이터는 기존에 설정된 트레숄드와 비교하여, (S2413) 작은 경우 오브젝트가 멀 리 있는 것으로 판단하고(S2414), 모션 센서를 통해 모션을 확인하는 (S2145) 기존의 흐름을 유지할 수 있 다. 이때, 깊이 카메라는 엑티브 모드로 작동하며 사용자 손의 인덱스 핑거를 트랙킹할 수 있다. 다만, 근접한 오브젝트가 사용자의 손이 아닌 다른 오브젝트인 경우, 깊이 카메라는 엑티브 모드로 작동하 지 않고, 획득한 깊이 이미지를 기초로 근접 센서의 초기 값을 재설할 수 있다. 구체적으로, 도 9를 살펴보면, 근접한 오브젝트가 사용자의 손이 아닌 다른 오브젝로 분별한 경우(S2421), 오브 젝트 분별부은 오브젝트가 기 설정 거리 이하에 존재하는지 여부를 판단(S2422)하고 이를 근접센서 트리거 에 전달한다. 근접 센서 트리거는 오브젝트가 기설정 거리 이하에 존재하는 경우 (S2422, Yes) 근접 센서의 초기 값을 재설정 하지 않고, 기존의 흐름을 유지할 수 있다. 즉, 오브 젝트가 근접 상태로 판단함을 유지하고(S2423), 이후 근접 센서를 통해 획득한 데이터를 통해(S2424), 기존의 트레숄드 값과 비교하여(S2425), 근접여부에 따라 데이터를 계속 획득하거나(S2424), 근접센서를 통해 데이터 획득하는 것을 중단(=근접 상태 정의(Far), S2426)하고 모션센서를 통해 모션을 확인(S2427)할 수 있다. 다만, 근접 센서 트리거는 오브젝트가 기설정 거리를 초과하여 오브젝트가 존재하는 경우, 이후 근접 센서 를 통해 획득한 데이터(S2424)를 기초로 베이스 라인 및 트레숄드 값을 업데이트 할 수 있다. (S2425) 즉, 업데이트 된 트레숄드 값에 의해 근접 상태가 재정의되므로(S2426), 근접 센서를 통해 데이터를 획득하는 것을 중단하고 모션센서를 통해 모션을 확인하는 단계로 넘어갈 수 있다. (S2427) 근접한 오브젝트가 존재 하지 않는 경우, 근접센서는 깊이 카메라를 잘못 활성화 한 것이므로 근접 센서 의 초기 값을 재설정할 필요가 있다. 구체적으로, 도 10를 살펴보면, 깊이 이미지를 통해 근접한 오브젝트가 없는 것으로 분별된 경우(S2431), 오브 젝트 분별부은 이를 근접센서 트리거에 전달하고, 근접센서를 통해 다시 데이터를 획득한다. (S2432) 다시 획득한 데이터가 기존의 트레숄드 미만인 경우(S2433, Yes), 기존의 트레숄드 값은 올바른데 다른 요인으 로 깊이 카메라가 잘못 엑티브 된 것으로 판단하고 오브젝트의 근접 여부를 멀리 있는 것으로 재정의하고 (S2435), 모션센서를 통해 모션을 확인(S2436)하는 단계로 넘어갈 수 있다. 다만, 다시 획득한 데이터가 기존의 트레숄드 이상인 경우(S2433, Yes), 이는 기존의 트레숄드 값이 올바르지 않는 것으로, 다시 획득한 데이터를 통해 베이스 라인 및 트레숄드 값을 재설정한다. (S2434) 업데이트 된 트레숄드 값에 의해 근접 상태가 재정의되므로(S2435), 근접 센서를 통해 데이터를 획득하는 것을 중단하고 모션센서를 통해 모션을 확인하는 단계로 넘어갈 수 있다. (S2436) ------------------------------------------------- 도 11은 본 발명의 일 실시예에 따라 특정 오브젝트가 TOF 카메라의 촬영 영역 중 인터렉션 영역에 위치하도록 가이드 인터페이스를 제공하는 프로세스를 설명하는 흐름도 이다. 본 발명은 비주얼 컨텐츠를 제공하는 디스플레이부, 피사체를 촬영하여 깊이 이미지를 획득하는 TOF(Time of Flight) 카메라 및 상기 디스플레이부 및 상기 TOF 카메라에 연결된 제어부를 포함하고, 상기 제어부는 특정 오 브젝트가 상기 TOF 카메라의 촬영 영역 중 인터렉션 영역에 위치하도록 가이드 하는 가이드 인터페이스를 제공 하도록 상기 디스플레이부를 제어할 수 있다. 여기서 상기 특정 오브젝트는 사용자의 손에 대응될 수 있다. 본 발명은 사용자의 손이 가이드 인터페이스를 통 해 상기 인터렉션 영역에 위치하는 경우, 사용자의 손 모션을 통해 입력 신호를 수신하는 그래픽 인터페이스를 제공할 수 있다. 상기 프로세스를 도 11을 통해 구체적으로 살펴보면 다음과 같다. 본 발명의 TOF 카메라는 전력 소모가 많은 전자 부품으로 항상 활성 상태로 작동하는 것은 에너지 효율면에서 부적합할 수 있다. 따라서, 본 발명은 근접 센서를 통해 TOF 카메라를 비활성 상태에서 활성 상태로 전환할 수 있다. 본 발명의 근접 센서는 조사광의 반사량을 통해 오브젝트가 근접 위치에 있는지 또는 멀리 위치에 있는지를 감 지하는 센서이다. 구체적으로 본 발명의 근접 센서는 감지 광량의 베이스 라인(Baseline)을 설정하고, 베이스 라인(Baseline)을 기초로 기 설정 과량 값을 더하여 오브젝트가 근접 위치에 있는 또는 멀리 위치에 있는지를 구분하는 트레숄드(Threshold)를 설정할 수 있다. (S3010) 본 발명의 근접 센서가 베이스 라인을 설정하고 이를 기초고 트레숄드를 설정하는 프로세스는 도 5 내지 도 10을 통해 구체적으로 설명하고 있다. 본 발명은 근접 센서를 통해 오브젝트가 근접한지 여부를 판별하고, (S3020) 오브젝트가 근접한 경우 TOF 카메 라를 활성 상태로 전환하여 깊이 이미지를 획득할 수 있다. 본 발명은 오브젝트가 근접한 경우, 활성 상태로 전환된 TOF 카메라를 통해 깊이 이미지를 획득하고, 근접한 오 브젝트가 특정 오브젝트에 대응되는지 확인할 수 있다. 여기서 특정 오브젝트는 사용자의 손에 대응될 수 있다. (S3030) 본 발명은 특정 오브젝트가 사용자의 손에 대응되는지, 사용사의 손에 대응되지 않고 다른 오브젝트인 지 또는 TOF 카메라가 착오로 활성 상태로 전환됬는지에 따라, 근접 센서의 베이스 라인을 재 설정 할 수 있다. 이와 관련하여서 도 5 내지 도 10을 통해 구체적으로 설명하고 있다. 본 발명은 TOF 카메라를 통해 획득한 깊이 이미지에서 사용자 손의 위치를 확인하고, 사용자의 손을 특정 위치 로 가이드 하는 가이드 인터페이스를 제공할 수 있다. (S3040) 본 발명은 가이드 인터페이스를 통해 사용자의 손이 특정 위치에 위치하는 경우 사용자의 손의 모션을 통해 입 력 신호를 수신하는 그래픽 인터페이스를 제공할 수 있다. (S3050) 이하에서 사용자의 손을 특정 위치로 가이드하는 프로세서를 구체적으로 살펴본다. 도 12는 본 발명의 일 실시예에 따라 특정 오브젝트를 특정 위치로 가이드하는 프로세스를 설명하는 흐름도이다. 본 발명의 TOF 카메라는 근접한 오브젝트가 사용자의 손에 대응되는 경우 활성 상태를 유지하고 깊이 이미지를 획득할 수 있다. (S3110) 본 발명은 획득한 깊이 이미지를 통해 사용자의 손의 위치를 확인할 수 있다. (S3120) 여기서 사용자의 손의 위 치는 사용자 손의 윤곽 좌표를 통해 확인하거나, 사용자 손의 위치를 대표하는 대표 좌표(ex, 중심 좌표)를 통 해 확인할 수 있다. 또한, 확인된 사용자 손의 위치는 TOF 카메라를 바라보는 평면상의 위치 및 TOF 카메라에서 떨어진 거리 정보를 포함할 수 있다. 본 발명은 확인된 사용자의 손의 위치가 인터렉션 영역 내에 위치하는지 확인할 수 있다. (S3130) 여기서 인터 렉션 영역은 TOF 카메라의 촬영 영역 내 영역으로 TOF 카메라를 통해 핑거 트랙킹이 용이한 영역일 수 있다. 이 하 도 13을 통해 인터렉션 영역을 구체적으로 살펴본다. 본 발명은 사용자의 손의 위치가 인터렉션 영역 내에 위치하는 경우 (S3130, Yes) 사용자 손의 모션을 통해 입 력 신호를 수신하는 그래픽 어플리케이션을 실행할 수 있다. (S31040) 경우에 따라서, 본 발명은 사용자의 손의 위치가 인터렉션 영역 내에 기 설정 시간 이상 위치하는 경우 상기 그래픽 어플리케이션을 실행할 수 있다. 본 발명은 사용자의 손의 위치가 인터렉션 영역을 벗어나 위치하거나, 인터렉션 영역에 걸쳐 위치하는 경우 (S3130, No) 가이드 인터페이스를 통해 핸드 포시션을 가이들 할 수 있다. (S3150) 경우에 따라서, 상기 가이드 인터페이스는 사용자의 손의 위치가 인터렉션 영역 내에 위치함을 사용자에게 인지시킬 수 있다. 도 13은 본 발명의 일 실시예에 따라, 인터렉션 영역을 설명하기 위한 도면이다. 본 발명의 이동 단말기는 일면에 TOF 카메라를 포함하고, TOF 카메라의 화각 내에서 깊이 이미지를 획득할 수 있다. 본 발명은 TOF 카메라의 촬영 영역 내의 특정 영역을 인터렉션 영역(722, 723)으로 설정할 수 있다. 인터 렉션 영역(722, 723)은 통상적으로 사용자가 손의 모션을 통해 입력 신호를 제공하고자 할 때 사용자의 손이 위 치하는 영역에 대응할 수 있다. 또는 인터렉션 영역(722, 723)은 오브젝트의 깊이 정보를 보다 세밀하게 분별할 수 있는 영역일 수 있다. 구체적으로 본 발명의 인터렉션 영역(722, 723)은 TOF 카메라에서 제1 거리 범위에 위치할 수 있다. 여기 서 제1 거리 범위는 TOF 카메라에서 Z 축을 따라 기 설정 거리 범위 내에 위치할 수 있다. 또한, 본 발명의 인터렉션 영역(722, 723)은 TOF 카메라의 화각 범위 내의 특정 화각 범위 내에 위치할 수 있다. 또한, 본 발명의 인터렉션 영역은 TOF 카메라에서 마주하는 평면(ex, xy 평면)상의 특정 좌표 범위 내에 위치하는 영역일 수 있다. 예를 들어, TOF 카메라가 xy 평면의 중심에 위치하는 경우, 인터렉션 영역(72 3)은 기 설정 반경 내에 위치할 수 있다. 또는, 인터렉션 영역은 (x1, y1), (x2, y2), (x3, y3), (x4, y4) 좌표 범위 내에 포함되는 영역일 수 있다. 도 14는 본 발명의 일 실시예에 따라, 가이드 인터페이스를 제공하는 프리뷰 윈도우를 설명하기 위한 도면이다. 본 발명의 이동 단말기는 일면에 TOF 카메라를 포함하고, TOF 카메라와 동일 면에 디스플레이부 를 포함할 수 있다. 본 발명의 디스플레이부는 사용자의 손을 가이드하는 가이드 인터페이스를 제공하는 프리뷰 윈도우을 포함할 수 있다. 프리뷰 윈도우는 도 14(a)에 도시된 바와 같이 디스플레이부가 차지하는 영역에 적 어도 일 부분을 차지할 수 있다. 또한, 도 14(b)와 같이 프리뷰 윈도우(831a 내지 831d)는 도 13에서 설명된 인 터렉션 영역(822, 823)의 형상에 대응되는 형상을 가질 수 있다. 도 15는 본 발명의 일 실시예에 따라, 프리뷰 윈도우에 표시되는 가이드 인터페이스를 설명하기 위한 도면이다. 본 발명은 프리뷰 윈도우에 사용자 손의 위치를 가이드 하는 가이드 인터페이스를 제공할 수 있다. 본 발명의 가이드 인터페이스는 도 13의 인터렉션 영역에 대응되는 제1 인디케이터 및 특정 오브젝트 의 움직임에 대응하여 이동하는 제2 인디케이터를 포함할 수 있다. 본 발명의 제2 인디케이터는 제1 인디케이터로 감싸는 영역 내에 포함될 수 있는 크기로 제공될 수 있다. 본 발명의 제2 인디케이터는 특정 오브젝트의 형상을 대표하는 형상으로 제공될 수 있다. 구체적으로, 도 15(a)는 사용자의 손의 형상에 대응하는 형상으로 제2 인디케이터를 제공하는 실시예를 도시하고 있다. 이 경우, 제2 인디케이터는 사용자 손의 좌표상 이동에 따라 움직일 수 있으며, 사용자 손의 형상에 따라 형 상이 가변될 수 있다. 본 발명의 제2 인디케이터는 특정 오브젝트의 형상과 무관한 형상으로 제공될 수 있다. 구체적으로, 도 15(b)는 사용자의 손의 형상과 무관한 직사각형 형상으로 제2 인디케이터을 제고하는 실시예를 도시하고 있다. 본 발명의 제1 인디케이터는 고정되며, 제2 인디케이터는 움직이거나 크기가 변할 수 있다. 본 발명 은 제1 인디케이터 대비 제2 인디케이터의 움직임 또는 크기 변화를 통해 사용자의 손을 가이드할 수 있다. 본 발명의 가이드 인터페이스는 보다 용이하게 사용자의 손을 가이드하기 위해서 그래픽 피드백을 제공할 수 있다. 이하에서 가이드 인터페이스가 제공하는 그래픽 피드백의 실시예를 살펴본다. 도 16는 본 발명의 일 실시예에 따라, TOF 카메라에 마주하는 평면상에서 사용자의 손이 인터렉션 영역을 벗어 나지 않게 가이드 하는 그래픽 피드백을 설명하기 위한 도면이다. 본 발명의 가이드 인터페이스는 사용자의 손이 TOF 카메라에 마주하는 평면 상에서 인터렉션 영역을 벗어 나지 않도록 가이드 하는 그래픽 피드백을 제공할 수 있다. 본 발명의 가이드 인터페이스는 제2 인디케이터가 제1 인디케이터의 중앙 영역에 위치하는 경우 그래픽 피드백을 제공할 수 있다. 도 16(a)는 제2 인디테이터의 제1 인디케이터의 중앙 영역에 위치 하는 경우, 제1 인디케이터의 색이 변하는 그래픽 피드백을 실시예를 도시하고 있다. 경우에 따라서, 본 발명은 제2 인디케이터가 제1 인디케이터의 중앙 영역에 위치하는 경우 색이 변하는 그래픽 피드백을 제공할 수 있다. 본 발명의 가이드 인터페이스는 제1 인디케이터의 중앙 영역을 감싸는 제3 인디케이터을 포함하 고, 제2 인디케이터의 움직임에 대응하여 제3 인디케이터과 오버랩된 부분을 표시하는 그래픽 피드백 을 제공할 수 있다. 도 16(b)는 제2 인디케이터의 움직임에 대응하여 제2 인디케이터가 제3 인디케이 터을 침범한 영역을 그래픽 피드백을 통해 제공하고 있다. 가이드 인터페이스는 제2 인디케이터(84 3)가 제3 인디케이터에 완전히 오버렙되도록 유도함으로써 사용자 손을 가이드할 수 있다. 본 발명의 가이드 인터페이스는 제2 인디케이터가 제1 인디케이터을 벗어남을 표시하는 그래픽 피드백을 제공할 수 있다. 구체적으로, 도 16(c)의 첫 번째는 제1 인디케이터에서 제2 인디케이터가 오버렙되는 경계 부분을 표시하도록 그래픽 피드백이 제공되는 실시예를 도시하고 있다. 사용자는 제2 인디케이 터가 제1 인디케이터에 오버랩되는 부분을 통해 손이 움직여야 하는 방향을 결정할 수 있다. 또한, 도 16(c)의 두 번째는 제2 인디케이터에서 제1 인디케이터에 벗어난 부분을 표시하도록 그래픽 피드 백을 제공하는 실시예를 도시하고 있다. 사용자는 벗어난 위치 및 크기를 통해 손이 움직여야하는 방향 및 정도 를 결정할 수 있다. 도 17 및 도 18는 본 발명의 일 실시예에 따라, TOF 카메라와의 거리에 있어서, 사용자의 손이 인터렉션 영역을 벗어나지 않게 가이드 하는 그래픽 피드백을 설명하기 위한 도면이다. 본 발명의 이동 단말기는 TOF 카메라의 화각 내에서, 사용자의 손과 TOF 카메라와의 거리에 대응하여 제2 인디케이터의 크기를 변경하여 제공할 수 있다. 구체적으로, 본 발명은 도 17(a)와 같이 사용자의 손이 TOF 카메라에서 멀어질수록 제2 인디케이터의 크기를 작게 제공할 수 있다. 이때, 제2 인디케이터의 크기는 TOF 카메라와의 거리에 따라, 제1 인티케이터의 크기 대비 결정 될 수 있다. 본 발명은 도 18(a)와 같이 제1 인디케이터의 중앙 영역을 감싸는 제4 인디케이터을 포함할 수 있다. 사용 자의 제4 인디케이터와 제2 인티케이터의 크기를 비교하여 사용자 손과 TOF 카메라와의 적 정 거리를 인지할 수 있다. 경우에 따라서는 본 발명은 제2 인디케이터의 크기가 제4 인디케이터의 경계 이상 제1 인디케이터의 경계 이하에 대응되는 경우, 적정 거리에 위치함을 알리는 그래픽 피드백을 제공할 수 있다. 본 발명의 이동 단말기는 도 17(b)와 같이 사용자의 손과 TOF 카메라와의 거리에 대응하여 가이 드 인터페이스의 색깔, 명암, 선명도를 가변할 수 있다. 구체적으로 도 18(b)은 사용자의 손과 TOF 카메라의 거리에 따라 제2 인디케이터의 명암이 달라 지는 실시예를 도시하고 있다. 도 18(c)는 사용자의 손과 TOF 카메라의 거리에 따라 제2 인디케이터 의 선명도가 달라지는 실시예를 도시하고 있다. 제2 인디케이터는 사용자의 손과 TOF 카메라 의 거리에 따라 채도, 명암, 선명도를 달리하면서 제1 인디케이터 대비 크기를 달리할 수 있다. 도 19는 본 발명의 일 실시예에 따라, 사용자의 손이 인터렉션 영역에 위치하는 경우 제공되는 그래픽 인터페이 스를 설명하기 위한 도면이다. 본 발명은 가이드 인터페이스를 통해 사용자의 손이 인터렉션 영역에 위치하는 경우, 디스플레이부를 통해 그래픽 인터페이스를 제공할 수 있다. 본 발명은 그래픽 인터페이스가 제공되는 경우, 제공되는 그래픽 인터페이스에 따라 사용자의 손 모 션을 통해 입력 신호를 수신할 수 있다. 본 발명의 그래픽 인터페이스는 도 19(a)와 같이 사용자의 손의 움직임 방향에 대응하여 실행 가능한 어플 리케이션를 제공할 수 있다. 이때, 그래픽 인터페이스는 사용자 손의 위치를 나타내는 그래픽 피드백 을 제공할 수 있다. 본 발명의 그래픽 인터페이스는 도 19(b)와 같이 사용자의 손 형상에 따라 실행 가능한 어플리케이션(85 2)을 달리 제공할 수 있다. 예를 들어, 사용자가 손을 펼친 상태인 경우, 그래픽 인터페이스는 좌우에 제1 어플리케이션 및 제2 어플리케이션을 제공하고, 본 발명의 이동 단말기는 사용자의 손의 움직임 방향 따라 제1 어플리케이션 또는 제2 어플리케이션을 실행할 수 있다. 또한, 사용자가 손을 움켜쥔 상태인 경우, 그래픽 인터 페이스는 좌우에 제3 어플리케이션 및 제4 어플리케이션을 제공하고, 본 발명의 이동 단말기는 사용자 손 의 움직임 방향에 따라 제3 어플리케이션 또는 제4 어플리케이션을 실행할 수 있다. 본 발명의 그래픽 인터페이스는 도 19(b)와 같이 사용자의 손의 회전에 대응하여 볼륨 조절 기능을 제공하 는 인터페이스일 수 있다. 경우에 따라서는 그래픽 인터페이스는 사용자의 손의 회전에 대응하여 빨리 감 기, 화면 밝기 제어 또는 다음 컨텐츠로 이동 기능을 제공하는 인터페이스일 수 있다. 상기의 상세한 설명은 모든 면에서 제한적으로 해석되어서는 아니되고 예시적인 것으로 고려되어야 한다. 본 발 명의 범위는 첨부된 청구항의 합리적 해석에 의해 결정되어야 하고, 본 발명의 등가적 범위 내에서의 모든 변경 은 본 발명의 범위에 포함된다."}
{"patent_id": "10-2019-0092154", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1a는 본 발명과 관련된 이동 단말기를 설명하기 위한 블록도이다. 도 1b 및 1c는 본 발명과 관련된 이동 단말기의 일 예를 서로 다른 방향에서 바라본 개념도이다. 도 2은 본 발명의 일 실시예에 따라, 깊이 카메라와 근접 센서와 근접센서를 기초로 삼차원 비전 기반 UI를 수 행하기 위한 본 발명의 구성도이다. 도 3은 본 발명의 일 실시예에 따라, 삼차원 비전 기반 UI를 수행하기 위한 프로세서를 설명하는 흐름도이다. 도 4 는 본 발명의 일 실시예에 따라, 모션 센서를 통해 선별적으로 근접 센서를 활성화하는 프로세서를 설명하 는 흐름도이다. 도 5는 본 발명의 일 실시예에 따라, 근접센서의 트레숄드(threshold) 값을 설정하고, 이를 기초로 깊이 카메라 를 활성화하는 프로세서를 설명하는 흐름도이다. 도 6은 본 발명의 일 실시예에 따라, 분별된 오브젝트에 따라 근접 센서의 초기 값을 재설정하기 위한 모드를 달리하는 프로세서를 설명하는 흐름도이다.도 7은 본 발명의 일 실시예에 따라, 근접 센서의 초기 값을 재설정할 필요성을 설명하기 위한 도면이다. 도 8 내지 10은 본 발명의 일 실시예에 따라, 오브젝트의 유무 또는 오브젝트의 종류에 따라 근접 센서의 트레 숄드(threshold) 값을 업데이트하는 프로세서를 설명하는 흐름도이다. 도 11은 본 발명의 일 실시예에 따라 특정 오브젝트가 TOF 카메라의 촬영 영역 중 인터렉션 영역에 위치하도록 가이드 인터페이스를 제공하는 프로세스를 설명하는 흐름도 이다. 도 12는 본 발명의 일 실시예에 따라 특정 오브젝트를 특정 위치로 가이드하는 프로세스를 설명하는 흐름도이다. 도 13은 본 발명의 일 실시예에 따라, 인터렉션 영역을 설명하기 위한 도면이다. 도 14는 본 발명의 일 실시예에 따라, 가이드 인터페이스를 제공하는 프리뷰 윈도우를 설명하기 위한 도면이다. 도 15는 본 발명의 일 실시예에 따라, 프리뷰 윈도우에 표시되는 가이드 인터페이스를 설명하기 위한 도면이다. 도 16는 본 발명의 일 실시예에 따라, TOF 카메라에 마주하는 평면상에서 사용자의 손이 인터렉션 영역을 벗어 나지 않게 가이드 하는 그래픽 피드백을 설명하기 위한 도면이다. 도 17 및 도 18은 본 발명의 일 실시예에 따라, TOF 카메라와의 거리에 있어서, 사용자의 손이 인터렉션 영역을 벗어나지 않게 가이드 하는 그래픽 피드백을 설명하기 위한 도면이다. 도 19는 본 발명의 일 실시예에 따라, 사용자의 손이 인터렉션 영역에 위치하는 경우 제공되는 그래픽 인터페이 스를 설명하기 위한 도면이다."}
