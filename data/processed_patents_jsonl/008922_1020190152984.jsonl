{"patent_id": "10-2019-0152984", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2021-0064591", "출원번호": "10-2019-0152984", "발명의 명칭": "차량용 다중 센서를 위한 딥러닝 처리 장치 및 방법", "출원인": "한국전자기술연구원", "발명자": "이상설"}}
{"patent_id": "10-2019-0152984", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "제1 타입의 제1 영상을 입력받는 제1 입력단계;제2 타입의 제2 영상을 입력받는 제2 입력단계;입력된 제1 영상과 제2 영상을 인공지능 모델에 함께 입력하는 제3 입력단계;인공지능 모델로 제1 영상의 특징과 제2 영상의 특징을 추출하는 단계; 및추출된 제1 영상의 특징과 제2 영상을 이용하여, 객체를 검출하고 검출된 객체를 분류하는 검출 및 분류단계;를포함하는 것을 특징으로 하는 다중 영상 처리 방법."}
{"patent_id": "10-2019-0152984", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "청구항 1에 있어서,제1 영상을 이용하여, 조도를 추정하는 단계;를 더 포함하고,제3 입력단계는,추정된 조도 정보를 제1 영상 및 제2 영상과 함께 인공지능 모델에 입력하는 것을 특징으로 하는 다중 영상 처리 방법."}
{"patent_id": "10-2019-0152984", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "청구항 2에 있어서,추출 단계는,추정된 조도 정보를 더 이용하여, 제1 영상의 특징과 제2 영상의 특징을 추출하는 것을 특징으로 하는 다중 영상 처리 방법."}
{"patent_id": "10-2019-0152984", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "청구항 2에 있어서,추정된 조도 정보를 참조하여, 차량 내부와 사각 지대에 대한 영상인 제3 영상을 생성하는 제3 센서의 WDR(WideDynamic Range)과 조명을 제어하는 단계;를 더 포함하는 것을 특징으로 하는 다중 영상 처리 방법."}
{"patent_id": "10-2019-0152984", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "청구항 4에 있어서,제3 센서에서 생성된 제3 영상을 이용하여, 사각 지대의 장애물을 검출하는 단계;를 더 포함하는 것을 특징으로하는 다중 영상 처리 방법."}
{"patent_id": "10-2019-0152984", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "공개특허 10-2021-0064591-3-청구항 5에 있어서,검출 및 분류단계에서 검출 및 분류된 객체와 검출 단계에서 검출된 장애물을 기초로, 상황을 인지하고 위험을판단하는 단계;를 더 포함하는 것을 특징으로 하는 다중 영상 처리 방법."}
{"patent_id": "10-2019-0152984", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "청구항 1에 있어서,제1 영상은,RGB 영상이고,제2 영상은,IR 영상인 것을 특징으로 하는 다중 영상 처리 방법."}
{"patent_id": "10-2019-0152984", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1 타입의 제1 영상을 생성하는 제1 센서;제2 타입의 제2 영상을 생성하는 제2 센서; 및제1 센서에 의해 생성된 제1 영상과 제2 센서에 의해 생성된 제2 영상을 인공지능 모델에 함께 입력하여, 인공지능 모델로 제1 영상의 특징과 제2 영상의 특징을 추출하고, 추출된 제1 영상의 특징과 제2 영상을 이용하여객체를 검출하고 검출된 객체를 분류하는 객체 분류/검출기;를 포함하는 것을 특징으로 하는 다중 센서 처리 장치."}
{"patent_id": "10-2019-0152984", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "차량에 설치된 이종의 센서들로부터 생성되는 영상들을 입력으로 객체를 검출/분류하는 경량의 임베디드향 딥러 닝 네트워크 구조 및 이를 이용한 처리 장치와 방법이 제공된다. 본 발명의 실시예에 따른 다중 영상 처리 방법 은 제1 타입의 제1 영상을 입력받는 제1 입력단계; 제2 타입의 제2 영상을 입력받는 제2 입력단계; 입력된 제1 영상과 제2 영상을 인공지능 모델에 함께 입력하는 제3 입력단계; 인공지능 모델로 제1 영상의 특징과 제2 영상 의 특징을 추출하는 단계; 및 추출된 제1 영상의 특징과 제2 영상을 이용하여, 객체를 검출하고 검출된 객체를 분류하는 검출 및 분류단계;를 포함한다. 이에 의해, 경량의 임베디드향 딥러닝 네트워크로 차량에 설치된 이종의 센서들로부터 생성되는 영상들을 입력받 아 객체를 검출/분류할 수 있게 된다."}
{"patent_id": "10-2019-0152984", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 인공지능 기술을 활용한 영상 처리 및 SoC(System on Chip) 기술에 관한 것으로, 더욱 상세하게는 이 종의 센서들로부터 영상들을 입력받아 딥러닝으로 처리하는 장치 및 방법에 관한 것이다."}
{"patent_id": "10-2019-0152984", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "카메라 등을 통해 생성한 영상 데이터로부터 추출한 특징 정보를 이용하여, 차량 외부에 대한 객체 검출, 차선 검출, 도로 검출 등 수 많은 응용에 대한 연구와 개발이 진행 중에 있다. 특히, 자율 주행 차량에 적용하기 위하여 외부에 RGB 카메라, 스테레오 카메라, ToF 센서, Lidar 등을 연동하여 외부 상황인지 개발에 대부분의 역량을 할애하고 있다. 하지만, 차량 내부 카메라 시스템은 운전자 상태 검출 정도로 아직 영상 기반의 다양한 센서 응용이 미약한 실 정이다. 특히, RGB 영상 센서와 함께 신종 RCCC, RGBIR 등 다기능 센서 신호 처리 전용 프로세서가 없어 고가의 DSP 및 GPU를 활용하고 있다. 뿐만 아니라, 차량 내부 시스템에 적용 가능한 초경량의 딥러닝 하드웨어 플랫폼도 전무한 실정이다."}
{"patent_id": "10-2019-0152984", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 상기와 같은 문제점을 해결하기 위하여 안출된 것으로서, 본 발명의 목적은, 차량에 설치된 이종의 센서들로부터 생성되는 영상들을 입력으로 객체를 검출/분류하는 경량의 임베디드향 딥러닝 네트워크 구조 및 이를 이용한 처리 장치와 방법을 제공함에 있다."}
{"patent_id": "10-2019-0152984", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기 목적을 달성하기 위한 본 발명의 일 실시예에 따른, 다중 영상 처리 방법은 제1 타입의 제1 영상을 입력받 는 제1 입력단계; 제2 타입의 제2 영상을 입력받는 제2 입력단계; 입력된 제1 영상과 제2 영상을 인공지능 모델 에 함께 입력하는 제3 입력단계; 인공지능 모델로 제1 영상의 특징과 제2 영상의 특징을 추출하는 단계; 및 추 출된 제1 영상의 특징과 제2 영상을 이용하여, 객체를 검출하고 검출된 객체를 분류하는 검출 및 분류단계;를 포함한다. 본 발명에 따른 다중 영상 처리 방법은 제1 영상을 이용하여, 조도를 추정하는 단계;를 더 포함하고, 제3 입력 단계는, 추정된 조도 정보를 제1 영상 및 제2 영상과 함께 인공지능 모델에 입력하는 단계일 수 있다. 추출 단계는, 추정된 조도 정보를 더 이용하여, 제1 영상의 특징과 제2 영상의 특징을 추출하는 단계일 수 있다. 본 발명에 따른 다중 영상 처리 방법은 추정된 조도 정보를 참조하여, 차량 내부와 사각 지대에 대한 영상인 제 3 영상을 생성하는 제3 센서의 WDR(Wide Dynamic Range)과 조명을 제어하는 단계;를 더 포함할 수 있다. 본 발명에 따른 다중 영상 처리 방법은 제3 센서에서 생성된 제3 영상을 이용하여, 사각 지대의 장애물을 검출 하는 단계;를 더 포함할 수 있다. 본 발명에 따른 다중 영상 처리 방법은 검출 및 분류단계에서 검출 및 분류된 객체와 검출 단계에서 검출된 장 애물을 기초로, 상황을 인지하고 위험을 판단하는 단계;를 더 포함할 수 있다. 제1 영상은, RGB 영상이고, 제2 영상은, IR 영상일 수 있다. 본 발명의 다른 측면에 따르면, 제1 타입의 제1 영상을 생성하는 제1 센서; 제2 타입의 제2 영상을 생성하는 제 2 센서; 및 제1 센서에 의해 생성된 제1 영상과 제2 센서에 의해 생성된 제2 영상을 인공지능 모델에 함께 입력 하여, 인공지능 모델로 제1 영상의 특징과 제2 영상의 특징을 추출하고, 추출된 제1 영상의 특징과 제2 영상을 이용하여 객체를 검출하고 검출된 객체를 분류하는 객체 분류/검출기;를 포함하는 것을 특징으로 하는 다중 센 서 처리 장치가 제공된다."}
{"patent_id": "10-2019-0152984", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "이상 설명한 바와 같이, 본 발명의 실시예들에 따르면, 경량의 임베디드향 딥러닝 네트워크로 차량에 설치된 이 종의 센서들로부터 생성되는 영상들을 입력받아 객체를 검출/분류할 수 있게 된다. 또한, 본 발명의 실시예들에 따르면, 차량 내부에 설치된 센서를 활용하여 외부 상황의 인지 및 위험 모니터링 이 가능해진다."}
{"patent_id": "10-2019-0152984", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하에서는 도면을 참조하여 본 발명을 보다 상세하게 설명한다. 본 발명의 실시예에서는, 차량용 다중 센서를 위한 딥러닝 처리 장치 및 방법을 제시한다. 구체적으로, 이종의 센서로 생성한 영상들인 RGB 영상과 IR 영상을 입력으로 객체를 검출/분류하는 딥러닝 네트워크의 새로운 구조 를 제시한다. 본 발명의 실시예를 통해 제시하는 딥러닝 네트워크는, 다중 센서 기반의 객체 인식이 가능한 경량의 임베디드 향 딥러닝 구조로, 모바일 반도체에 적용 가능하다. 나아가, 본 발명의 실시예에서는, 차량 내부와 차량 외부 사각 지대에서의 위험 상황까지 인지하여 경고를 발생 시키는 방법을 제시한다. 도 1은 단일 센서 기반 객체 검출용 딥러닝 네트워크의 구조를 제시하였다. 도시된 객체 검출용 딥러닝 네트워 크에서는 특징 생성과 객체 분류를 위한 딥러닝 네트워크가 센서 마다 별개로 구성된다. 나아가, 조도 예측을 위한 별도의 레이어를 추가하여야 하고, 각각의 센서들에서 생성된 영상들을 기반으로 딥 러닝 처리된 각각의 결과들을 융합하여 최종 결과를 추출하여야 한다. 딥러닝 처리가 2번에 걸쳐 이루어진다는 점에서, 모바일 단말에서의 임베디드 시스템에서 구현하기에는 다소 부 적합하다. 도 2는 본 발명의 일 실시예에 따른 차량용 다중 센서 기반의 객체 검출용 딥러닝 네트워크의 구조를 도시한 도 면이다. 도시된 바와 같이, RGB 센서에서 생성된 RGB 영상과 IR 센서에서 생성된 IR 영상이 각각의 채널로 객체 검출용 딥러닝 네트워크에 입력된다. 객체 검출용 딥러닝 네트워크는 입력된 RGB 영상으로부토 조도(Light Condition)를 추정하고, 추정된 조도 정보 를 RGB 영상 및 IR 영상과 함께 퓨전 레이어에 입력시킨다. 이에 의해, 객체 검출용 딥러닝 네트워크는, 하나의 네트워크로 RGB 영상와 IR 영상의 특징을 추출하며, 특징을 추출함에 있어서는 추정된 조도 정보까지 이용함으로써 조도 영향들을 보상하여 영상의 특징을 생성할 수 있다. 이 부분은 센서의 증가에 따른 확장성이 있다는 장점이 있고, 해당 네트워크를 적절히 수정할 경우 다양한 레이 어에서의 융합이 가능하다. 다음, 객체 검출용 딥러닝 네트워크는, 추출된 RGB 영상의 특징과 IR 영상의 특징을 이용하여, 영상에 존재하는 객체를 검출하고, 검출된 객체를 분류한다. 검출 및 분류 결과는 영상에서 객체를 표시한 BB(Boundary Boc)와 정확도/신뢰도를 나타내는 스코어로 제시된다. 도 3은 본 발명의 다른 실시예에 따른 다중 센서 처리 장치의 블럭도이다. 본 발명의 실시예에 따른 다중 센서 처리 장치는, 도 2에 도시된 객체 검출용 딥러닝 네트워크를 이용하여 상황 인지와 경보 발생 등의 추가적인 응 용 처리를 수행한다. 이와 같은 기능을 수행하는 본 발명의 실시예에 따른 다중 센서 처리 장치는, 도 3에 도시된 바와 같이, 외부 센서들(110-1, 110-2, ..., 110-n), 내부 센서, 센서 정보 추출부, 캘리브레이션부, 내부 센서 제어기, 객체 검출/분류기, 장애물 검출기 및 인지/판단부를 포함하여 구성된다. 외부 센서들(110-1, 110-2, ..., 110-n)은 차량 외부에 설치되어 있는 센서들로 이종의 영상들, 이를 테면, RGB 영상, IR 영상, ..., Lidar 영상을 생성한다. 센서들(110-1, 110-2, ..., 110-n)의 개수와 종류에 대한 제한은 없으며, 필요에 따른 자유로운 구현이 가능하다. 내부 센서은 차량 내부에 설치된 광각의 센서로, 차량 내부 외에도 차량 외부, 특히, 사각 지대의 영상 생 성이 가능하다. 도 4는 내부 센서의 설치예를 나타낸 도면이다. 도시된 바와 같이, 내부 센서는 차량 내부 천정 중간 보다 조금 앞부분에 설치할 수 있으며, RGBIR 센서로 구현할 수 있다. 내부 센서의 화각을 190도 이상으로 구현한다면, 차량의 내부는 물론 차량 후방 측면들에 나타나는 사각 지대까지 영상으로 생성할 수 있다. 센서 정보 추출부는 센서들(110-1, 110-2, ..., 110-n, 120)에 대한 내부 파라미터와 외부 파라미터를 추 출한다. 캘리브레이션부는 센서 정보 추출부에 의해 추출된 파라미터들을 참조하여, 센서들(110-1, 110-2, 110-n, 120)에 대한 캘리브레이션을 수행한다. 객체 검출/분류기는 외부 센서들(110-1, 110-2, 110-n)에 의해 생성된 이종의 영상들을 이용하여 영상에 존재하는 객체를 검출하고 분류하는 딥러닝 네트워크이다. 객체 검출/분류기는 전술한 도 2에 제시된 객체 검출용 딥러닝 네트워크로 구현할 수 있다. 내부 센서 제어기는 센서 정보 추출부에 의해 추출된 내부 센서의 파라미터와 객체 검출/분류기 에 의해 추정된 조도 정보를 기초로, IR 조명의 강도나 WDR(Wide Dynamic Range)을 능동적으로 조정한다. 차량 내부의 경우 IR cut filter를 사용하지 않는 RGBIR 센서의 경우 신호 처리 특성상 정상 조도에서의 색편향 문제 및 저조도 환경에서의 색 잡음, IR 투과율과 반사율이 서로 다른 물체들이 혼재된 환경이므로, 내부 센서 제어기에 의한 조명과 셔터의 능동적 조정을 통해 균일한 화질을 확보한다. 이를 통해, 내부 센서에 의해 생성되는 외부 영상 부분이 외부 환경(역광 상황, 저조도 상황 등)에 강인해 질 수 있다. 장애물 검출기는 내부 센서에 의해 생성된 사각 지대의 영상을 분석하여, 장애물을 검출한다. 인지/판단부는 객체 검출/분류기에 의한 객체 객체 검출/분류 결과와 장애물 검출기에 의한 사 각 지대의 장애물 검출 결과를 기초로, 현재 상황을 인지하고, 위험을 판단하여, 필요시 경보를 발생시킨다. 도 5는 본 발명의 또 다른 실시예에 따른 다중 센서 처리 방법의 설명에 제공되는 흐름도이다. 도시된 바와 같이, 먼저, 센서 정보 추출부가 센서들(110-1, 110-2, ..., 110-n, 120)에 대한 내부 파라 미터와 외부 파라미터를 추출하고(S210), 캘리브레이션부는 S210단계에서 추출된 파라미터들을 참조하여, 센서들(110-1, 110-2, 110-n, 120)에 대한 캘리브레이션을 수행한다(S220). 객체 검출/분류기는 객체 검출용 딥러닝 네트워크에 외부 센서들(110-1, 110-2, 110-n)에 의해 생성된 이 종의 영상들을 입력하여 영상에 존재하는 객체를 검출하고 분류한다(S230). 내부 센서 제어기는 객체 검출/분류기에 의해 추정된 조도 정보를 기초로, IR 조명의 강도나 내부 센 서의 WDR을 능동적으로 조정한다(S240). 장애물 검출기는 내부 센서에 의해 생성된 사각 지대의 영상을 분석하여, 장애물을 검출한다(S250). 인지/판단부는 S230단계에 의한 객체 객체 검출/분류 결과와 S250단계에 의한 사각 지대의 장애물 검출 결 과를 기초로, 현재 상황을 인지하고, 위험을 판단하여, 필요시 경보를 발생시킨다(S260). 지금까지, 차량용 다중 센서 딥러닝 처리 장치 및 방법에 대해 바람직한 실시예들을 들어 상세히 설명하였다. 본 발명의 실시예에서는, 막대한 연산을 최소화 할 수 있는 딥러닝 네트워크 구조를 적용하여, 임베디드 하드웨 어에 구현 가능한 수준의 다중 센서 기반 객체 인지가 가능하게 하였다. 특히, 이종 센서와 더불어 신규 센서가 추가된 경우에도 동시 적용 가능한 구조를 제시하였고, 유연한 딥러닝 장치 및 신종 센서 입력에도 유지보수가 가능한 모델을 제시하였다. 본 발명의 실시예는, 단일 센서 기반의 처리와 더불어 이종의 센서 간의 딥러닝 처리를 위한 융합 기술의 적용 으로 다양한 외부 센서 인터페이스에도 적용이 가능하다. 또한, 본 발명의 실시예에서는, 차량 내부에 설치된 센서를 활용하여, 차량 외부, 구체적으로는, 사각 지대의 상황/위험까지 모니터링할 수 있는 방법을 제시하였다. 한편, 본 실시예에 따른 장치와 방법의 기능을 수행하게 하는 컴퓨터 프로그램을 수록한 컴퓨터로 읽을 수 있는 기록매체에도 본 발명의 기술적 사상이 적용될 수 있음은 물론이다. 또한, 본 발명의 다양한 실시예에 따른 기 술적 사상은 컴퓨터로 읽을 수 있는 기록매체에 기록된 컴퓨터로 읽을 수 있는 코드 형태로 구현될 수도 있다. 컴퓨터로 읽을 수 있는 기록매체는 컴퓨터에 의해 읽을 수 있고 데이터를 저장할 수 있는 어떤 데이터 저장 장 치이더라도 가능하다. 예를 들어, 컴퓨터로 읽을 수 있는 기록매체는 ROM, RAM, CD-ROM, 자기 테이프, 플로피 디스크, 광디스크, 하드 디스크 드라이브, 등이 될 수 있음은 물론이다. 또한, 컴퓨터로 읽을 수 있는 기록매체 에 저장된 컴퓨터로 읽을 수 있는 코드 또는 프로그램은 컴퓨터간에 연결된 네트워크를 통해 전송될 수도 있다."}
{"patent_id": "10-2019-0152984", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "또한, 이상에서는 본 발명의 바람직한 실시예에 대하여 도시하고 설명하였지만, 본 발명은 상술한 특정의 실시 예에 한정되지 아니하며, 청구범위에서 청구하는 본 발명의 요지를 벗어남이 없이 당해 발명이 속하는 기술분야 에서 통상의 지식을 가진자에 의해 다양한 변형실시가 가능한 것은 물론이고, 이러한 변형실시들은 본 발명의 기술적 사상이나 전망으로부터 개별적으로 이해되어져서는 안될 것이다."}
{"patent_id": "10-2019-0152984", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 단일 센서 기반 객체 검출용 딥러닝 네트워크의 구조를 도시한 도면, 도 2는 본 발명의 일 실시예에 따른 차량용 다중 센서 기반의 객체 검출용 딥러닝 네트워크의 구조를 도시한 도 면, 도 3은 본 발명의 다른 실시예에 따른 다중 센서 처리 장치의 블럭도, 도 4는 내부 센서의 설치예를 나타낸 도면, 그리고, 도 5는 본 발명의 또 다른 실시예에 따른 다중 센서 처리 방법의 설명에 제공되는 흐름도이다."}
