{"patent_id": "10-2023-0093036", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2025-0012894", "출원번호": "10-2023-0093036", "발명의 명칭": "센서 융합 기반의 객체 추적 장치 및 방법", "출원인": "한국항공대학교산학협력단", "발명자": "이명진"}}
{"patent_id": "10-2023-0093036", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "센서 융합 기반의 객체 추적 방법에 있어서,(a) 영상 데이터에서 등장 객체의 경계 정보를 포함하는 제1특징 정보를 도출하는 단계;(b) 상기 영상 데이터에 대응하는 레이더 센서 정보로부터 객체 포인트를 검출하고, 상기 객체 포인트의 좌표정보 및 속도 정보를 포함하는 제2특징 정보를 도출하는 단계;(c) 상기 레이더 센서 정보에 대하여 적용되는 지표면 좌표계와 상기 영상 데이터에 대하여 적용되는 영상 평면좌표계 사이의 좌표계 변환을 수행하는 단계; 및(d) 상기 좌표계 변환 수행 결과를 반영하여, 상기 제1특징 정보 및 상기 제2특징 정보에 기초하여 상기 등장객체에 대한 이동 궤적을 생성하거나 기 구축된 상기 이동 궤적을 갱신하는 단계,를 포함하는, 객체 추적 방법."}
{"patent_id": "10-2023-0093036", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 영상 데이터는 복수의 프레임을 포함하고,상기 (d) 단계는,기준 프레임의 이전 프레임에 대하여 생성된 상기 이동 궤적을 이용하여 상기 기준 프레임에서의 상기 등장 객체의 추정 위치 정보를 도출하고, 상기 추정 위치 정보와 상기 제1특징 정보를 비교하여 상기 제1특징 정보를상기 기준 프레임에 대한 상기 이동 궤적에 반영하는 것인, 객체 추적 방법."}
{"patent_id": "10-2023-0093036", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,상기 (d) 단계는,상기 추정 위치 정보와 상기 경계 정보가 미중첩되면, 상기 추정 위치 정보로부터 미리 설정된 임계 거리 이내에 존재하는 상기 객체 포인트에 대한 상기 제2특징 정보를 상기 기준 프레임에 대한 상기 이동 궤적에 반영하는 것인, 객체 추적 방법."}
{"patent_id": "10-2023-0093036", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서,상기 (d) 단계는,상기 추정 위치 정보로부터 상기 임계 거리 이내이고, 상기 속도 정보가 상기 이전 프레임에서 상기 등장 객체에 대하여 도출된 속도와 미리 설정된 임계 수준 이내로 유사한 것으로 판단되는 상기 객체 포인트에 대한 상기제2특징 정보를 이용하여 상기 이동 궤적을 갱신하는 것인, 객체 추적 방법."}
{"patent_id": "10-2023-0093036", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서,상기 (c) 단계는,상기 객체 포인트를 상기 영상 평면 좌표계로 변환하거나, 상기 경계 정보에 따른 상기 등장 객체의 대표 좌표를 상기 지표면 좌표계로 변환하는 것인, 객체 추적 방법.공개특허 10-2025-0012894-3-청구항 6 제1항에 있어서,상기 (a) 단계는,(a1) 상기 영상 데이터에서 미리 정의된 유형의 객체를 상기 등장 객체로 검출하고, 상기 검출된 등장 객체의경계 영역을 표시하는 단계; 및(a2) 상기 등장 객체에 대한 상기 제1특징 정보와 관련하여 현재 속성값과 예상 속성값을 기초로 하여 상기 등장 객체의 시계열적인 상기 이동 궤적을 도출하는 단계,를 포함하는 것인, 객체 추적 방법."}
{"patent_id": "10-2023-0093036", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6항에 있어서,상기 제1특징 정보는,객체의 유형, 영상 내 위치, 속도, 색상, 상기 경계 영역 내부의 영상 신호를 입력으로 하여 기 학습된 인공지능 모델에 의해 출력된 특징 벡터 중 적어도 하나를 더 포함하는 것인, 객체 추적 방법."}
{"patent_id": "10-2023-0093036", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1항에 있어서,상기 (b) 단계는,(b1) 복수의 객체 포인트 각각에 대하여 도출된 상기 제2특징 정보를 이용한 클러스터링을 통해 상기 복수의 객체 포인트를 동일 객체에 대응하는 포인트로 그룹핑하는 단계; 및(b2) 상기 그룹핑된 포인트의 대표 속성을 결정하는 단계,를 포함하는 것인, 객체 추적 방법."}
{"patent_id": "10-2023-0093036", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1항에 있어서,(e) 상기 이동 궤적을 상기 지표면 좌표계 및 상기 영상 평면 좌표계 중 적어도 하나를 이용하여 표시하는단계,를 더 포함하는 것인, 객체 추적 방법."}
{"patent_id": "10-2023-0093036", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "센서 융합 기반의 객체 추적 장치에 있어서,영상 데이터에서 등장 객체의 경계 정보를 포함하는 제1특징 정보를 도출하는 객체 검출부;상기 영상 데이터에 대응하는 레이더 센서 정보로부터 객체 포인트를 검출하고, 상기 객체 포인트의 좌표 정보및 속도 정보를 포함하는 제2특징 정보를 도출하는 포인트 처리부;상기 레이더 센서 정보에 대하여 적용되는 지표면 좌표계와 상기 영상 데이터에 대하여 적용되는 영상 평면 좌표계 사이의 좌표계 변환을 수행하는 정합 수행부; 및상기 좌표계 변환 수행 결과를 반영하여, 상기 제1특징 정보 및 상기 제2특징 정보에 기초하여 상기 등장 객체에 대한 이동 궤적을 생성하거나 기 구축된 상기 이동 궤적을 갱신하는 트랙 추적부,를 포함하는, 객체 추적 장치."}
{"patent_id": "10-2023-0093036", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제10항에 있어서,공개특허 10-2025-0012894-4-상기 영상 데이터는 복수의 프레임을 포함하고,상기 트랙 추적부는,기준 프레임의 이전 프레임에 대하여 생성된 상기 이동 궤적을 이용하여 상기 기준 프레임에서의 상기 등장 객체의 추정 위치 정보를 도출하고, 상기 추정 위치 정보와 상기 제1특징 정보를 비교하여 상기 제1특징 정보를상기 기준 프레임에 대한 상기 이동 궤적에 반영하는 것인, 객체 추적 장치."}
{"patent_id": "10-2023-0093036", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항에 있어서,상기 트랙 추적부는,상기 추정 위치 정보와 상기 경계 정보가 미중첩되면, 상기 추정 위치 정보로부터 미리 설정된 임계 거리 이내에 존재하는 상기 객체 포인트에 대한 상기 제2특징 정보를 상기 기준 프레임에 대한 상기 이동 궤적에 반영하는 것인, 객체 추적 장치."}
{"patent_id": "10-2023-0093036", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제12항에 있어서,상기 트랙 추적부는,상기 추정 위치 정보로부터 상기 임계 거리 이내이고, 상기 속도 정보가 상기 이전 프레임에서 상기 등장 객체에 대하여 도출된 속도와 미리 설정된 임계 수준 이내로 유사한 것으로 판단되는 상기 객체 포인트에 대한 상기제2특징 정보를 이용하여 상기 이동 궤적을 갱신하는 것인, 객체 추적 장치."}
{"patent_id": "10-2023-0093036", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제10항에 있어서,상기 정합 수행부는,상기 객체 포인트를 상기 영상 평면 좌표계로 변환하거나, 상기 경계 정보에 따른 상기 등장 객체의 대표 좌표를 상기 지표면 좌표계로 변환하는 것인, 객체 추적 장치."}
{"patent_id": "10-2023-0093036", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제10항에 있어서,상기 이동 궤적을 상기 지표면 좌표계 및 상기 영상 평면 좌표계 중 적어도 하나를 이용하여 표시하는 트랙 출력부,를 더 포함하는 것인, 객체 추적 장치."}
{"patent_id": "10-2023-0093036", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제1항 내지 제9항 중 어느 한 항에 따른 방법을 컴퓨터에서 실행하기 위한 프로그램을 기록한 컴퓨터에서 판독가능한 기록매체."}
{"patent_id": "10-2023-0093036", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "센서 융합 기반의 객체 추적 장치 및 방법이 개시되며, 본원의 일 실시예에 따른 센서 융합 기반의 객체 추적 방 법은, (a) 영상 데이터에서 등장 객체의 경계 정보를 포함하는 제1특징 정보를 도출하는 단계, (b) 상기 영상 데 이터에 대응하는 레이더 센서 정보로부터 객체 포인트를 검출하고, 상기 객체 포인트의 좌표 정보 및 속도 정보 를 포함하는 제2특징 정보를 도출하는 단계, (c) 상기 레이더 센서 정보에 대하여 적용되는 지표면 좌표계와 상 기 영상 데이터에 대하여 적용되는 영상 평면 좌표계 사이의 좌표계 변환을 수행하는 단계 및 (d) 상기 좌표계 변환 수행 결과를 반영하여, 상기 제1특징 정보 및 상기 제2특징 정보에 기초하여 상기 등장 객체에 대한 이동 궤적을 생성하거나 기 구축된 상기 이동 궤적을 갱신하는 단계를 포함할 수 있다."}
{"patent_id": "10-2023-0093036", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본원은 센서 융합 기반의 객체 추적 장치 및 방법에 관한 것이다. 예를 들면, 본원은 레이더 센서와 광학 영상 센서 융합 기반의 객체 검출 및 추적 기법에 관한 것이다. 본 연구는 경기도지역협력연구센터(GRRC)의 “360도 영상 및 공간 융합 서비스 기술연구” (연구기간: 2017-08- 01 ~ 2023-06-30) 과제의 연구비에 의해 지원되었다(연구개발비재원기관: 경기도, 고양시, 주관기관: 경기도)."}
{"patent_id": "10-2023-0093036", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "컴퓨터 비전 기술의 발달로 광학 영상 내에 등장하는 객체에 대한 검출 성능이 지속적으로 향상되고 있고, 이를 통해 등장 객체의 크기가 비교적 작고, 다수의 객체가 등장하는 영상(예를 들면, 군중이 밀집한 영상 등)에 대 하여도 객체 검출기를 통해 객체 검출이 가능하게 되었다. 한편, 광학 영상 시퀀스에서 사용자가 관심을 가지는 객체를 실시간으로 보기 위해 객체를 추적할 때, 객체가 군중들 사이나 물체 뒤로 일시적으로 사라졌다 다시 나타나는 경우나 조명 등과 같이 환경적인 요인에 의해 객 체의 추적이 끊기는 경우가 발생할 수 있다. 이와 관련하여, 객체 추적 알고리즘의 발전으로 추적 객체의 트랙 을 파편화 하고 컨벌루션 신경망을 적용하여 파편화된 트랙들을 분류하고 이어 붙여 하나의 완성된 트랙으로 만 드는 방법들이 개발되고 있으나, 광학영상 시퀀스만을 이용한 성능 개선에는 한계가 존재한다. 레이더 센서를 이용하면 객체까지의 거리, 방위, 객체의 속도를 파악할 수 있어서, 광학 영상 센서를 이용한 객 체 추적을 보조할 수 있는 센서 융합 기법의 개발이 요구된다. 본원의 배경이 되는 기술은 한국등록특허공보 제10-2468927호에 개시되어 있다."}
{"patent_id": "10-2023-0093036", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본원은 전술한 종래 기술의 문제점을 해결하기 위한 것으로서, 광학 영상 시퀀스 내 등장하는 단일 객체를 단순 히 추적하는 것이 아닌, 레이더 센서 정보로부터 검출한 객체 추적 정보와 광학 영상 시퀀스를 이용한 객체 추 적 정보를 융합한 센서 융합 기반의 객체 추적 장치 및 방법을 제공하려는 것을 목적으로 한다. 다만, 본원의 실시예가 이루고자 하는 기술적 과제는 상기된 바와 같은 기술적 과제들로 한정되지 않으며, 또 다른 기술적 과제들이 존재할 수 있다."}
{"patent_id": "10-2023-0093036", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기한 기술적 과제를 달성하기 위한 기술적 수단으로서, 본원의 일 실시예에 따른 센서 융합 기반의 객체 추적 방법은, (a) 영상 데이터에서 등장 객체의 경계 정보를 포함하는 제1특징 정보를 도출하는 단계, (b) 상기 영상 데이터에 대응하는 레이더 센서 정보로부터 객체 포인트를 검출하고, 상기 객체 포인트의 좌표 정보 및 속도 정 보를 포함하는 제2특징 정보를 도출하는 단계, (c) 상기 레이더 센서 정보에 대하여 적용되는 지표면 좌표계와 상기 영상 데이터에 대하여 적용되는 영상 평면 좌표계 사이의 좌표계 변환을 수행하는 단계 및 (d) 상기 좌표 계 변환 수행 결과를 반영하여, 상기 제1특징 정보 및 상기 제2특징 정보에 기초하여 상기 등장 객체에 대한 이 동 궤적을 생성하거나 기 구축된 상기 이동 궤적을 갱신하는 단계를 포함할 수 있다. 또한, 상기 영상 데이터는 복수의 프레임을 포함할 수 있다. 또한, 상기 (d) 단계는, 기준 프레임의 이전 프레임에 대하여 생성된 상기 이동 궤적을 이용하여 상기 기준 프 레임에서의 상기 등장 객체의 추정 위치 정보를 도출하고, 상기 추정 위치 정보와 상기 제1특징 정보를 비교하 여 상기 제1특징 정보를 상기 기준 프레임에 대한 상기 이동 궤적에 반영할 수 있다. 또한, 상기 (d) 단계는, 상기 추정 위치 정보와 상기 경계 정보가 미중첩되면, 상기 추정 위치 정보로부터 미리 설정된 임계 거리 이내에 존재하는 상기 객체 포인트에 대한 상기 제2특징 정보를 상기 기준 프레임에 대한 상 기 이동 궤적에 반영할 수 있다. 또한, 상기 (d) 단계는, 상기 추정 위치 정보로부터 상기 임계 거리 이내이고, 상기 속도 정보가 상기 이전 프 레임에서 상기 등장 객체에 대하여 도출된 속도와 미리 설정된 임계 수준 이내로 유사한 것으로 판단되는 상기 객체 포인트에 대한 상기 제2특징 정보를 이용하여 상기 이동 궤적을 갱신할 수 있다. 또한, 상기 (c) 단계는, 상기 객체 포인트를 상기 영상 평면 좌표계로 변환하거나, 상기 경계 정보에 따른 상기 등장 객체의 대표 좌표를 상기 지표면 좌표계로 변환할 수 있다. 또한, 상기 (a) 단계는, (a1) 상기 영상 데이터에서 미리 정의된 유형의 객체를 상기 등장 객체로 검출하고, 상 기 검출된 등장 객체의 경계 영역을 표시하는 단계 및 (a2) 상기 등장 객체에 대한 상기 제1특징 정보와 관련하 여 현재 속성값과 예상 속성값을 기초로 하여 상기 등장 객체의 시계열적인 상기 이동 궤적을 도출하는 단계를 포함할 수 있다. 또한, 상기 제1특징 정보는, 객체의 유형, 영상 내 위치, 속도, 색상, 상기 경계 영역 내부의 영상 신호를 입력 으로 하여 기 학습된 인공지능 모델에 의해 출력된 특징 벡터 중 적어도 하나를 포함할 수 있다. 또한, 상기 (b) 단계는, (b1) 복수의 객체 포인트 각각에 대하여 도출된 상기 제2특징 정보를 이용한 클러스터 링을 통해 상기 복수의 객체 포인트를 동일 객체에 대응하는 포인트로 그룹핑하는 단계 및 (b2) 상기 그룹핑된 포인트의 대표 속성을 결정하는 단계를 포함할 수 있다. 또한, 본원의 일 실시예에 따른 센서 융합 기반의 객체 추적 방법은, (e) 상기 이동 궤적을 상기 지표면 좌표계 및 상기 영상 평면 좌표계 중 적어도 하나를 이용하여 표시하는 단계를 포함할 수 있다. 한편, 본원의 일 실시예에 따른 센서 융합 기반의 객체 추적 장치는, 영상 데이터에서 등장 객체의 경계 정보를 포함하는 제1특징 정보를 도출하는 객체 검출부, 상기 영상 데이터에 대응하는 레이더 센서 정보로부터 객체 포 인트를 검출하고, 상기 객체 포인트의 좌표 정보 및 속도 정보를 포함하는 제2특징 정보를 도출하는 포인트 처 리부, 상기 레이더 센서 정보에 대하여 적용되는 지표면 좌표계와 상기 영상 데이터에 대하여 적용되는 영상 평 면 좌표계 사이의 좌표계 변환을 수행하는 정합 수행부 및 상기 좌표계 변환 수행 결과를 반영하여, 상기 제1특 징 정보 및 상기 제2특징 정보에 기초하여 상기 등장 객체에 대한 이동 궤적을 생성하거나 기 구축된 상기 이동 궤적을 갱신하는 트랙 추적부를 포함할 수 있다. 또한, 상기 트랙 추적부는, 기준 프레임의 이전 프레임에 대하여 생성된 상기 이동 궤적을 이용하여 상기 기준 프레임에서의 상기 등장 객체의 추정 위치 정보를 도출하고, 상기 추정 위치 정보와 상기 제1특징 정보를 비교 하여 상기 제1특징 정보를 상기 기준 프레임에 대한 상기 이동 궤적에 반영할 수 있다. 또한, 상기 트랙 추적부는, 상기 추정 위치 정보와 상기 경계 정보가 미중첩되면, 상기 추정 위치 정보로부터 미리 설정된 임계 거리 이내에 존재하는 상기 객체 포인트에 대한 상기 제2특징 정보를 상기 기준 프레임에 대 한 상기 이동 궤적에 반영할 수 있다. 또한, 상기 트랙 추적부는, 상기 추정 위치 정보로부터 상기 임계 거리 이내이고, 상기 속도 정보가 상기 이전 프레임에서 상기 등장 객체에 대하여 도출된 속도와 미리 설정된 임계 수준 이내로 유사한 것으로 판단되는 상 기 객체 포인트에 대한 상기 제2특징 정보를 이용하여 상기 이동 궤적을 갱신할 수 있다. 또한, 상기 정합 수행부는, 상기 객체 포인트를 상기 영상 평면 좌표계로 변환하거나, 상기 경계 정보에 따른 상기 등장 객체의 대표 좌표를 상기 지표면 좌표계로 변환할 수 있다. 또한, 본원의 일 실시예에 따른 센서 융합 기반의 객체 추적 장치는, 상기 이동 궤적을 상기 지표면 좌표계 및 상기 영상 평면 좌표계 중 적어도 하나를 이용하여 표시하는 트랙 출력부를 포함할 수 있다. 상술한 과제 해결 수단은 단지 예시적인 것으로서, 본원을 제한하려는 의도로 해석되지 않아야 한다. 상술한 예 시적인 실시예 외에도, 도면 및 발명의 상세한 설명에 추가적인 실시예가 존재할 수 있다."}
{"patent_id": "10-2023-0093036", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "전술한 본원의 과제 해결 수단에 의하면, 광학 영상 시퀀스 내 등장하는 단일 객체를 단순히 추적하는 것이 아 닌, 레이더 센서 정보로부터 검출한 객체 추적 정보와 광학 영상 시퀀스를 이용한 객체 추적 정보를 융합한 센 서 융합 기반의 객체 추적 장치 및 방법을 제공할 수 있다. 전술한 본원의 과제 해결 수단에 의하면, 빈번한 객체 간 가려짐이 발생하는 환경에서 보다 장시간의 객체별 이 동 트랙을 검출할 수 있고, 광학 센서 정보만을 이용할 때에는 제공하지 못하는 실세계에서의 위치 정보와 속도 정보를 제공할 수 있어 객체 정보를 다각도로 제공할 수 있다. 다만, 본원에서 얻을 수 있는 효과는 상기된 바와 같은 효과들로 한정되지 않으며, 또 다른 효과들이 존재할 수 있다."}
{"patent_id": "10-2023-0093036", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "아래에서는 첨부한 도면을 참조하여 본원이 속하는 기술 분야에서 통상의 지식을 가진 자가 용이하게 실시할 수 있도록 본원의 실시예를 상세히 설명한다. 그러나 본원은 여러 가지 상이한 형태로 구현될 수 있으며 여기에서 설명하는 실시예에 한정되지 않는다. 그리고 도면에서 본원을 명확하게 설명하기 위해서 설명과 관계없는 부분 은 생략하였으며, 명세서 전체를 통하여 유사한 부분에 대해서는 유사한 도면 부호를 붙였다. 본원 명세서 전체에서, 어떤 부분이 다른 부분과 \"연결\"되어 있다고 할 때, 이는 \"직접적으로 연결\"되어 있는 경우뿐 아니라, 그 중간에 다른 소자를 사이에 두고 \"전기적으로 연결\" 또는 \"간접적으로 연결\"되어 있는 경우 도 포함한다. 본원 명세서 전체에서, 어떤 부재가 다른 부재 \"상에\", \"상부에\", \"상단에\", \"하에\", \"하부에\", \"하단에\" 위치 하고 있다고 할 때, 이는 어떤 부재가 다른 부재에 접해 있는 경우뿐 아니라 두 부재 사이에 또 다른 부재가 존 재하는 경우도 포함한다. 본원 명세서 전체에서, 어떤 부분이 어떤 구성 요소를 \"포함\"한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다른 구성 요소를 제외하는 것이 아니라 다른 구성 요소를 더 포함할 수 있는 것을 의미한다. 본원은 센서 융합 기반의 객체 추적 장치 및 방법에 관한 것이다. 예를 들면, 본원은 레이더 센서와 광학 영상 센서 융합 기반의 객체 검출 및 추적 기법에 관한 것이다. 보다 구체적으로 본원은 광학영상 촬영과 함께 레이더 센서를 이용하여 동일한 대상에 대한 정보를 수집하여 광 학영상 센서가 객체 추적시 가지는 한계인 거리 및 속도 정보의 부재, 가려진 객체 궤적 파편화 등의 문제를 보 완하는 객체 추적 시스템에 관한 것이다. 도 1은 본원의 일 실시예에 따른 센서 융합 기반의 객체 추적 장치를 포함하는 객체 인식 시스템의 개략적인 구 성도이다. 도 1을 참조하면, 본원의 일 실시예에 따른 객체 인식 시스템은 본원의 일 실시예에 따른 센서 융합 기반의 객체 추적 장치(이하, '객체 추적 장치'라 한다.), 광학 영상 센서, 레이더 센서 및 사용 자 단말을 포함할 수 있다. 객체 추적 장치, 광학 영상 센서, 레이더 센서 및 사용자 단말 상호간은 네트워크를 통해 통신할 수 있다. 네트워크는 단말들 및 서버들과 같은 각각의 노드 상호간에 정보 교환이 가능한 연결 구조를 의미하는 것으로, 이러한 네트워크의 일 예에는, 3GPP(3rd Generation Partnership Project) 네트 워크, LTE(Long Term Evolution) 네트워크, 5G 네트워크, WIMAX(World Interoperability for Microwave Access) 네트워크, 인터넷(Internet), LAN(Local Area Network), Wireless LAN(Wireless Local Area Network), WAN(Wide Area Network), PAN(Personal Area Network), wifi 네트워크, 블루투스(Bluetooth) 네트워 크, 위성 방송 네트워크, 아날로그 방송 네트워크, DMB(Digital Multimedia Broadcasting) 네트워크 등이 포함 되나 이에 한정되지는 않는다. 사용자 단말은 예를 들면, 스마트폰(Smartphone), 스마트패드(SmartPad), 태블릿 PC등과 PCS(Personal Communication System), GSM(Global System for Mobile communication), PDC(Personal Digital Cellular), PHS(Personal Handyphone System), PDA(Personal Digital Assistant), IMT(International Mobile Telecommunication)-2000, CDMA(Code Division Multiple Access)-2000, W-CDMA(W-Code Division MultipleAccess), Wibro(Wireless Broadband Internet) 단말기 같은 모든 종류의 무선 통신 장치일 수 있다. 본원의 일 실시예에 따르면, 레이더 센서가 객체를 검출하는 빈도는 광학 영상 센서의 화면률에 동기 화될 수 있으며, 이러한 이종의 두 센서의 동기화를 위해 외부 연산 유닛(예를 들면, 마이크로프로세서 등)에 의한 트리거 신호가 제공될 수 있다. 또한, 광학 영상 센서와 레이더 센서는 3차원 공간 상에서 서로 일정한 상대 위치와 포즈 관계가 유지되도록 배치되는 것일 수 있다. 도 2는 본원의 일 실시예에 따른 센서 융합 기반의 객체 추적 장치를 포함하는 객체 인식 시스템의 동작 프로세 스를 개략적으로 나타낸 개념도이다. 도 2를 참조하면, 레이더 센서로부터 샘플링 되는 원시 데이터(레이더 센서 정보)에 대하여 정합 필터링이 나 거리방향 신호처리와 방위방향 신호처리 등과 같은 신호처리(radar signal processing)가 적용됨으로써 객체 포인트가 검출되는 것일 수 있으며, 검출된 객체 포인트는 고유의 식별 정보(예를 들면, ID 등)와 객체의 지표 면 상의 위치(예를 들면, 레이더 센서의 위치를 원점으로 설정한 지표면 좌표계 상의 위치 등), 속도 등을 포인트의 속성으로서 보유할 수 있다. 또한, 객체 추적 장치는 레이더 센서에 의해 획득(검출)된 객체 포인트들에 대하여 동일 샘플링 시점 에 검출한 복수의 객체들에 대해 객체의 지표면상 위치(x, y, z)와 속도(v)를 이용하여 이루어지는 4차원 벡터 공간에서 클러스터링을 수행함으로써 대표 객체 포인트를 생성할 수 있으며, 각 클러스터의 대표 객체 포인트는 클러스터에 포함된 객체 포인트들의 위치와 속도를 대표하는 대표 속성을 갖는다. 예를 들어 대표 위치는 클러 스터 내 객체들의 평균 위치, 대표 속도는 클러스터 내 객체들의 평균 속도로 설정될 수 있으나, 이에만 한정되 는 것은 아니다. 또한, 객체 검출 장치는 인공지능 기반의 객체 검출기(도 2의 'object detector')를 구비할 수 있으며, 이 러한 객체 검출기를 통해 영상 데이터의 매 프레임 별로 검출된 객체들은 각각의 객체의 위치와 객체 영역의 경 계, 영상평면 내 속도, 객체 영역의 영상신호 또는 특징 벡터 등을 속성으로 보유할 수 있다. 또한, 객체 검출 장치는 현재 샘플링 시점의 객체 속성으로부터 다음 샘플링 시점의 객체의 속성을 예측하 고 다음 샘플링 시점에 검출된 객체들과의 유사도 비교 기반의 데이터 연관(Data Association)을 통해 동일 객 체 여부를 판정하여 동일 객체인 경우 현재 객체 위치와 다음 객체 위치를 이어서 객체 이동 궤적을 갱신할 수 있다(도 2의 'object tracker'). 이와 관련하여, 데이터 연관 프로세스에서 고려되는 각 객체의 속성은 위치, 속도, 광학 영상 센서의 경우 추가로 객체 영역에 대응하는 특징 벡터 등을 포함할 수 있다. 한편, 객체 추적 장치는 하기 식 1을 이용하여 제1객체(O1)와 제2객체(O2) 사이의 유사도(S)를 연산할 수 있다. [식 1]"}
{"patent_id": "10-2023-0093036", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "여기서, w1, w2, w3는 가중치이고, d(O1, O2)는 제1객체와 제2객체 사이의 거리 또는 겹침 비율(IOU, intersection over union)이고, v1, v2는 제1객체와 제2객체 각각의 속도이고, F1, F2는 제1객체와 제2객체에 각각 대응하는 객체 영역의 특징 벡터일 수 있다. 한편, 레이더 센서 기반의 레이더 센서 정보를 이용한 객체 간의 유사도 비교 시에는 관련 가중치(w3)가 0으로 설정될 수 있으며, 상기 식 1을 통해 도출된 유사도가 미리 설정된 임계값 미만인 경우(달리 말해, S(O1, O2) < th1 인 경우), 제1객체와 제2객체는 동일한 객체로 판 단될 수 있다. 또한, 도 2를 참조하면, 객체 추적 장치는 사전 캘리브레이션을 통해 내부 계수와 외부 계수를 추정할 수 있다. 이 때, 외부 계수는 특정 위치에서 광학 영상 센서가 특정 포즈로 고정된 상태에서 도출할 수 있으 며, 시간에 따라 광학 영상 센서의 위치와 포즈가 변화하는 경우, 광학 영상 센서에 부착된 측위 센 서(예를 들면, GPS 센서, RTK 센서 등)와 관성 센서(IMU 센서) 등을 이용하여 외부 계수를 계산할 수 있다. 또한, 도 2를 참조하면, 객체 추적 장치의 트랙 갱신기(EO track updater)는 각 광학 영상 내 객체의 트랙 과 경계 영역(bounding box)의 대표점(달리 말해, 객체의 위치)과 광학영상 평면으로 변환된 레이더 센서 정보기반의 객체 포인트 사이의 위치 관계를 파악(확인)할 수 있다. 이하에서는 도 3 내지 도 7을 참조하여 객체 추적 장치의 구체적인 기능 및 동작에 대하여 설명하도록 한 다. 도 3은 영상 데이터 및 레이더 센서 정보를 예시적으로 나타낸 도면이다. 도 3의 (a)를 참조하면, 객체 추적 장치는 영상 데이터에서 등장 객체의 경계 정보를 포함하는 제1특징 정 보를 도출할 수 있다. 구체적으로 객체 추적 장치는 복수의 프레임을 포함하는 영상 데이터(입력 광학 영 상) 내에 등장하는 객체를 검출하고, 영상 데이터로부터 검출된 객체의 경계 정보를 도출한 후, 전술한 바와 같 이 동일 객체로 판단된 객체의 이동 궤적을 추적할 수 있다. 달리 말해, 객체 추적 장치는 광학 영상 센서에 의해 획득된 영상 데이터에서 미리 정의된 유형의 객 체를 등장 객체로 검출할 수 있으며, 또한, 객체 추적 장치는 검출된 등장 객체의 경계 영역(Bonding Bo x)을 표시할 수 있다. 또한, 객체 추적 장치는 등장 객체에 대한 제1특징 정보와 관련하여 현재 속성값과 예상 속성값을 기초로 하여 등장 객체의 시계열적인 이동 궤적을 도출할 수 있다. 이와 관련하여, 제1특징 정보(속성값)는 객체의 유형, 영상 내 위치, 속도, 색상, 경계 영역 내부의 영상 신호 를 입력으로 하여 기 학습된 인공지능 모델에 의해 출력된 특징 벡터 중 적어도 하나를 포함할 수 있다. 또한, 도 3의 (b)를 참조하면, 객체 추적 장치는 영상 데이터에 대응하는 레이더 센서 정보로부터 객체 포 인트를 검출할 수 있다. 또한, 객체 추적 장치는 객체 포인트의 좌표 정보 및 속도 정보를 포함하는 제2특 징 정보를 도출할 수 있다. 달리 말해, 객체 추적 장치는 매 프레임별로 레이더 센서 정보로부터 객체 포인트를 검출하고, 각 개체 포 인트의 지표면 상의 좌표와 속도를 도출할 수 있다. 즉, 본원의 일 실시예에 따르면, 객체 추적 장치는 레이더 센서로부터 수신한 원시 데이터에 대하여 거리 방향과 방위 방향의 신호처리를 수행하여 객체 포인트를 검출하고, 검출된 객체 포인트의 지표면 상의 3차 원 좌표와 속도를 도출할 수 있다. 구체적으로 객체 추적 장치는 복수의 객체 포인트 각각에 대하여 도출된 제2특징 정보를 이용한 클러스터 링을 통해 복수의 객체 포인트를 동일 객체에 대응하는 포인트로 그룹핑할 수 있다. 또한, 객체 추적 장치(10 0)는 그룹핑된 포인트의 대표 속성을 결정할 수 있다. 즉, 본원의 일 실시예에 따르면, 객체 추적 장치는 검출된 객체 포인트들의 속성을 3차원의 지표면 좌표 및 속도로 정의하고, 4차원 속성 공간 상에서 클러스터링을 수행하여 객체 포인트 간의 속성 거리가 일정 문턱 치 이하인 경우 동일 객체 포인트로 병합하고, 병합 객체 포인트의 대표 속성을 설정할 수 있다. 한편, 객체 추적 장치는 프레임 n 시점의 객체의 추정 이동 속도는 동일 객체의 프레임 n-1 시점의 이동 속도를 이용하여 설정하거나, 해당 객체의 과거 위치와 속도 데이터로부터 예측된 속도 값으로 설정할 수 있으 며, 프레임 n 시점의 객체에 포함되는 레이더 센서 정보 기반의 객체 포인트가 하나 이상 결정된 경우, 해당 객 체 포인트의 속도값 또는 속도의 대표값으로 해당 객체의 속도를 설정할 수 있다. 도 4는 지표면 좌표계와 영상 평면 좌표계를 설명하기 위한 개념도이다. 도 4를 참조하면, 또한, 객체 추적 장치는 레이더 센서 정보에 대하여 적용되는 지표면 좌표계와 상기 영 상 데이터에 대하여 적용되는 영상 평면 좌표계 사이의 좌표계 변환을 수행할 수 있다. 이와 관련하여 도 5는 영상 평면 상에서 검출한 객체의 이동 궤적에 대해 특정 프레임 시점에서 각 이동 객체를 포함하는 경계 영역과 광학영상 평면으로 좌표 변환되어 표현된 객체 포인트를 예시적으로 나타낸 도면이고, 도 6은 지표면 좌표계 상에서 특정 프레임 시점에 획득된 객체 포인트들과 영상 평면에서 검출된 객체의 대표 좌표 를 지표면 좌표계로 변환하여 표현한 그래프이다. 도 5 및 도 6을 참조하면, 객체 추적 장치는 객체 포인트를 영상 평면 좌표계로 변환하거나, 경계 정보에 따른 등장 객체의 대표 좌표를 지표면 좌표계로 변환할 수 있으며, 이를 위하여 객체 추적 장치는 광학 영 상 센서와 레이더 센서의 동시 데이터 수집 과정에서, 레이더 센서와 연계된 평면인 지표면 좌 표계와 광학 영상 센서와 연계된 평면인 영상 평면 좌표계 사이의 복수의 동일 지점 쌍들을 이용한 좌표계간 변환 관계를 도출하기 위한 캘리브레이션을 수행할 수 있으며, 이를 위해 광학 영상 센서의 내부 계수 와 외부 계수를 획득(추정)할 수 있다. 달리 말해, 객체 추적 장치는 레이더 센서로 검출한 객체 포인트를 광학 영상 평면 좌표계로 변환할 수 있다. 구체적으로 객체 추적 장치는 광학 영상 센서에 대하여 파악(획득)된 내부 계수와 외부 계 수를 이용하여 레이더 센서에서 검출한 매 프레임 별 객체의 위치를 영상 내 좌표로 변환할 수 있다. 또한, 객체 추적 장치는 광학 영상(영상 데이터) 내에서 검출된 객체의 이동 궤적으로부터 매 프레임 별 객체의 대표 좌표를 지표면 좌표로 변환할 수 있다. 구체적으로 객체 추적 장치는 동일한 객체 검출 시점 의 광학 영상 센서의 내부 계수와 외부 계수를 이용하여 영상 평면 상의 객체의 이동 트랙 상의 매 프레임 별 대표 위치(좌표)를 지표면 좌표계로 변환할 수 있다. 이와 관련하여 객체 추적 장치는 도 2에 도시된 프레임 n에서 검출된 객체 포인트 k를 의미하는 Pr(k, n) 의 지표면상의 3차원 좌표를 광학 영상 센서의 내부 계수 및 외부 계수를 이용하여 광학 영상 평면상의 좌 표로 변환할 수 있으며, 이를 통해 객체 추적 장치는 레이더 센서 기반의 지표면 좌표계 상의 객체의 이동 궤적이 광학 영상 센서와 연계된 영상 평면상의 이동 궤적으로 위치를 변환할 수 있으며, 이 때 매 샘플링 시점의 이동 궤적 상의 객체의 속도는 변환되지 않고 유지될 수 있다. 또한, 본원의 일 실시예에 따르면, 지표면 좌표계 상의 소정의 위치(좌표)를 광학 영상 평면상의 위치(좌표)로 변환하기 위하여 하기 식 2가 적용될 수 있다. [식 2]"}
{"patent_id": "10-2023-0093036", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "상기 식 2에서 (X, Y, Z)는 지표면 좌표계(World coordinate) 공간에서의 3차원 점의 좌표를 나타내고, (u, v)는 픽셀 단위의 투영 지점의 좌표를 나타내고, A는 광학 영상 센서의 내부(고유) 파라미터에 대한 행렬 이고, (cx, cy)는 이미지 중앙의 기준 포인트(principal point)를 나타내고, fx 및 fy는 픽셀 단위의 초점 거리 를 나타낸다. 또한, 객체 추적 장치는 좌표계 변환 수행 결과를 반영하여, 제1특징 정보 및 제2특징 정보에 기초하여 등 장 객체에 대한 이동 궤적을 생성하거나 기 구축된 이동 궤적을 갱신할 수 있다. 구체적으로 객체 추적 장치는 광학 영상 기반의 객체의 이동 궤적에서 매 프레임별 객체의 대표 좌표와 이 동 속도를 이용하여 레이더 센서를 이용하여 획득된 객체 포인트의 해당 객체 대응 여부(포함 여부)를 판 단할 수 있다. 또한, 객체 추적 장치는 해당 객체의 현재 이동 궤적에 연결될 다음 프레임 상에서의 영상 데이터 기반의 검출 객체를 객체 간 속성을 이용하여 탐색할 뿐만 아니라, 해당 객체의 현재 이동 궤적에 연결될 다음 프레임 상의 레이더 센서 기반의 객체 포인트를 현재 객체에 포함된 레이더 센서 정보 기반의 객체 포인트의 대표 속성을 이용하여 탐색할 수 있다. 보다 구체적으로 객체 추적 장치는 영상 데이터의 복수의 프레임 중 기준 프레임(예를 들면, 현재 프레 임)의 이전 프레임에 대하여 생성된 이동 궤적을 이용하여 기준 프레임에서의 등장 객체의 추정 위치 정보를 도 출할 수 있다. 또한, 객체 추적 장치는 도출된 추정 위치 정보와 제1특징 정보를 비교하여 제1특징 정보를 기준 프레임에 대한 이동 궤적에 반영할 수 있다. 또한, 본원의 일 실시예에 따르면, 객체 추적 장치는 만일 기준 프레임에 대하여 예측된 추정 위치 정보와 실제 기준 프레임에서 도출된 등장 객체의 경계 정보가 미중첩되면, 추정 위치 정보로부터 미리 설정된 임계 거 리 이내에 존재하는 객체 포인트에 대한 제2특징 정보를 기준 프레임에 대한 이동 궤적에 반영할 수 있다. 이와 관련하여 본원의 일 실시예에 따르면, 객체 추적 장치는 추정 위치 정보로부터 임계 거리 이내이고, 속도 정보가 이전 프레임에서 등장 객체에 대하여 도출된 속도와 미리 설정된 임계 수준 이내로 유사한 것으로 판단되는 객체 포인트에 대한 제2특징 정보를 이용하여 해당 등장 객체의 이동 궤적을 갱신할 수 있다.도 7은 제1특징 정보 및 제2특징 정보에 기초하여 등장 객체에 대한 이동 궤적을 생성/갱신하는 프로세스를 설 명하기 위한 개념도이다. 구체적으로 도 7의 (a)는 광학 영상 평면에서 객체의 이동 트랙(i)에 대해 각 프레임 시점(n-1, n, n+1)별로 객 체의 경계 영역과 대표 좌표(객체 위치)를 나타낸 것이고, 도 7의 (b)는 광학 영상 평면에서 프레임 n까지 객체 의 이동 트랙(i)이 연결되었을 때, 해당 트랙에 대해 프레임 n+1 시점의 객체의 예측 위치(점선 박스)와 주변에 존재하는 프레임에서 검출된 특정 객체와의 위치 관계를 나타낸 것이며, 도 7의 (b)에서는 객체의 예측 위치에 서 객체의 경계 영역과 검출 객체의 경계 영역 간에 겹침이 발생한 것을 확인할 수 있다. 이와 대비하여, 도 7의 (c)는 도 7의 (b)와 동일하게 객체의 예측 위치를 파악하였을 때, 객체의 경계 영역과 검출 객체 간에 겹침이 발생하지 않은 경우를 나타낸 것이고, 도 7의 (d)는 광학 영상 평면에서 객체의 이동 트 랙(i)에 대해 프레임 n 시점에서 객체의 경계영역과 위치, 레이더 포인트들을 나타낸다. 즉, 도 7의 (b)와 도 7의 (c)는 n번째 프레임에서 검출한 객체 트랙(i)의 n+번째 프레임에서의 예상 객체 과 n+1번째 프레임에서 검출한 객체 k인 O(k, n+1) 사이의 위치 관계를 나타낸다. 특히, 도 7의 (d)를 참조하면, 객체의 위치를 중심으로 일정 거리(reo) 안의 레이더 포인트들의 속도가 직전 프 레임 n-1 시점의 동일 객체에 포함된 레이더 포인트들의 대표 속도로부터 일정 오차 범위 이내에 존재하는 경우 현 프레임 n 시점의 레이더 포인트들로 판정할 수 있다. 구체적으로 도 7의 (d)에서 파란색으로 도시된 포인트들은 객체의 위치(대표 위치)로부터 일정 거리 이내에 위 치하고, 해당 포인트의 속도가 직전 프레임 n 시점과 상대적으로 유사한 것으로 판단된 레이더 센서 정보 기반 의 객체 포인트를 나타낸 것이고, 도 7의 (d)에서 보라색으로 도시된 포인트는 객체의 위치로부터 일정 거리 이 내에 위치하지만, 속도 조건을 만족하지 않는 포인트를 나타낸 것이고, 도 7의 (d)에서 초록색으로 도시된 포인 트는 객체의 위치로부터 일정 거리 외측에 위치하는 포인트를 도시한 것이다. 또한, 도 7의 (e)는 도 7의 (c)에서와 동일하게 프레임 n+1에서 객체 예측 위치에서 객체의 경계영역과 검출 객 체들간의 겹침이 발생하지 않은 경우를 나타낸 것이며, 이 때 광학 영상만 이용하여 객체를 추적하는 종래의 객 체 추적 기법을 적용할 경우 해당 객체의 이동 트랙(i)이 끊어질 가능성이 존재하는 상황이다. 이 경우, 본원에 서 개시하는 객체 추적 장치는 예측 위치 주변에 레이더 센서 정보 기반의 객체 포인트가 일정 반경(거리) 이내에 존재하고, 해당 객체 포인트의 속도가 이전 프레임 n에서의 해당 객체에 대하여 기 파악된 속도와 상대 적으로 유사한 경우(달리 말해, 속도 조건을 만족하는 경우), 해당 프레임에서 파악된 객체의 위치(대표 위치) 를 중심으로 객체를 확정하고, 객체 이동 트랙을 연결할 수 있다. 이와 관련하여, 도 7의 (f)는 프레임 n+1에서 객체의 예측 위치를 지표면 좌표계(radar plane)에 표시하고, 일 정 반경 안에 레이더 포인트들이 속도 조건을 만족하면서 존재하는 경우, 이 예측 위치로 객체 이동 트랙을 연 결하고, 이들 레이더 포인트들을 해당 객체에 대응하는 포인트로 포함시키는 것을 나타낸 것이. 달리 말해, 본원의 일 실시예에 따르면, 객체 추적 장치는 영상 평면 상에서 객체 이동 트랙 상의 프레임 n 시점의 객체의 위치(대표 좌표)와 추정 이동 속도를 기준으로 영상 평면 상으로 변환된 레이더 포인트가 일정 거리 이내 조건과 동일 속도 조건을 만족하는 경우, 해당 객체에 대응하는 이동 트랙의 프레임 n 시점의 레이더 포인트로 포함시킬 수 있다. 또한, 객체 추적 장치는 현재(frame n)의 객체의 이동 트랙에 연결될 다음 프레임(frame n+1) 상의 검출된 객체를 프레임 n 상의 객체의 속성(구체적으로, 영상 평면 내 프레임 n+1에서의 예측 위치, 속도, 경계 영역, 경계 영역 내 영상 신호 또는 특징 벡터)과 프레임 n+1 상의 객체의 속성을 비교하여, 프레임 n+1 상의 특정 객 체를 현재 객체의 이동 트랙에 연결할지 여부를 판단하고, 판단 결과에 따라 이동 트랙을 연결시킬 수 있다. 이 때, 서로 다른 프레임에서 식별된 객체 간의 속성 비교는 프레임 n+1에서의 예측 위치에 위치시킨 예측된 경계 영역과 프레임 n+1에서 검출된 특정 객체의 경계영역 간의 겹침 비율, 특징 벡터 사이의 유사도 등을 이용하여 수행될 수 있다. 또한, 본원의 일 실시예에 따르면, 객체 추적 장치는 영상 평면상에서 프레임 n+1에서 검출된 객체가 현재 객체의 이동 트랙과 연결되지 못하는 상황인 경우, 현재의(frame n) 객체의 이동 트랙에 연결될 다음 프레임 (frame n+1) 상의 검출된 객체를 프레임 n 상의 객체의 속성(구체적으로 영상 평면 내 프레임 n+1에서의 예측위 치, 속도)와 프레임 n+1 상의 영상 평면으로 변환된 레이더 센서 정보 기반의 객체 포인트의 속성(즉, 위치, 속 도)를 비교하여 예측 위치로부터 일정 거리 이내에 직전 프레임 n에서의 속도와 차이가 일정 문턱치 이내인 객체 포인트가 하나 이상 존재하면 해당 예측 위치를 프레임 n+1의 객체 위치로 결정하고 해당 객체에 대응하는 이동 트랙(궤적)을 연결할 수 있다. 달리 말해, 도 7의 (e)에 도시된 바와 같이, 객체 추적 장치는 트랙 갱신 모듈(EO track updater)을 통해 이전 프레임의 객체 트랙 로부터 예측된 현재 프레임의 객체 트랙 위치와 일정 거리 이내 의 겹침이 존재하는 검출된 객체가 없는 경우, 광학영상만을 이용하면 객체 트랙이 종료될 수 있으며, 겹침이 존재하지 않는 경우 에이징 카운터(Aging counter)를 두어 향후 소정의 시간 동안 겹침 객체를 탐색할 수 있으 며, 이 경우 위치에서 미리 설정된 반경(거리) 내에 변환된 객체 포인트가 존재하고, 이러한 객체 포인트 중에서 이전 객체 트랙 의 속도와 소정의 범위 내에서 유사한 변환된 객체 포인트가 존재하면, 현재 예측 객체 트랙 을 해당 객체의 현재 객체 트랙으로 확정하고, 변환된 객체 포인트를 해당 객 체의 트랙의 부가정보로서 포함시키고, 이들의 대표 속도를 현재 객체 트랙의 속도로 설정할 수 있다. 또한, 도 7의 (f)에 도시된 바와 같이 객체 추적 장치는 예측된 객체 트랙 의 대표 위치를 전 술한 식 3 기반의 변환 모델에 기반하여 지표면 좌표계로 변환한 위치 에서 일정 거리 이내에 객 체 포인트들이 존재하고, 이들 객체 포인트들의 속도가 이전 객체 트랙 의 속도와 일정 범위 이내에서 유사할 때, 예측된 객체 트랙 을 현재 객체 트랙으로 확정할 수 있다. 또한, 객체 추적 장치는 등장 객체에 대한 이동 궤적을 지표면 좌표계 및 영상 평면 좌표계 중 적어도 하 나를 이용하여 표시할 수 있다. 즉, 전술한 과정을 통해 획득된 객체 관련 정보를 이용하여 객체 추적 장치 는 레이더 센서와 연계된 지표면 좌표계와 광학 영상 센서와 연계된 영상 좌표계 각각을 이용하 여 객체의 이동 궤적을 표시(표출)할 수 있다. 도 8은 본원의 일 실시예에 따른 센서 융합 기반의 객체 추적 장치의 개략적인 구성도이다. 도 8을 참조하면, 객체 추적 장치는 객체 검출부, 포인트 처리부, 정합 수행부, 트랙 추적 부 및 트랙 출력부를 포함할 수 있다. 객체 검출부는 영상 데이터에서 등장 객체의 경계 정보를 포함하는 제1특징 정보를 도출할 수 있다. 구체적으로 객체 검출부는 영상 데이터에서 미리 정의된 유형의 객체를 등장 객체로 검출하고, 검출된 등 장 객체의 경계 영역을 표시할 수 있다. 또한, 객체 검출부는 등장 객체에 대한 제1특징 정보와 관련하여 현재 속성값과 예상 속성값을 기초로 하 여 등장 객체의 시계열적인 이동 궤적을 도출할 수 있다. 이와 관련하여, 제1특징 정보(속성값)는 객체의 유형, 영상 내 위치, 속도, 색상, 경계 영역 내부의 영상 신호 를 입력으로 하여 기 학습된 인공지능 모델에 의해 출력된 특징 벡터 중 적어도 하나를 포함할 수 있다. 포인트 처리부는 영상 데이터에 대응하는 레이더 센서 정보로부터 객체 포인트를 검출할 수 있다. 또한, 포인트 처리부는 객체 포인트의 좌표 정보 및 속도 정보를 포함하는 제2특징 정보를 도출할 수 있다. 구체적으로 포인트 처리부는 복수의 객체 포인트 각각에 대하여 도출된 제2특징 정보를 이용한 클러스터링 을 통해 복수의 객체 포인트를 동일 객체에 대응하는 포인트로 그룹핑할 수 있다. 또한, 포인트 처리부는 그룹핑된 포인트의 대표 속성을 결정할 수 있다. 정합 수행부는 레이더 센서 정보에 대하여 적용되는 지표면 좌표계와 상기 영상 데이터에 대하여 적용되는 영상 평면 좌표계 사이의 좌표계 변환을 수행할 수 있다. 예를 들어, 정합 수행부는 객체 포인트를 영상 평면 좌표계로 변환하거나, 경계 정보에 따른 등장 객체의 대표 좌표를 지표면 좌표계로 변환할 수 있다. 트랙 추적부는 정합 수행부의 좌표계 변환 수행 결과를 반영하여, 제1특징 정보 및 제2특징 정보에 기초하여 등장 객체에 대한 이동 궤적을 생성하거나 기 구축된 이동 궤적을 갱신할 수 있다. 구체적으로 트랙 추적부는 영상 데이터의 복수의 프레임 중 기준 프레임(예를 들면, 현재 프레임)의 이전 프레임에 대하여 생성된 이동 궤적을 이용하여 기준 프레임에서의 등장 객체의 추정 위치 정보를 도출할 수 있 다. 또한, 트랙 추적부는 도출된 추정 위치 정보와 제1특징 정보를 비교하여 제1특징 정보를 기준 프레임 에 대한 이동 궤적에 반영할 수 있다. 또한, 본원의 일 실시예에 따르면, 트랙 추적부는 만일 기준 프레임에 대하여 예측된 추정 위치 정보와 실 제 기준 프레임에서 도출된 등장 객체의 경계 정보가 미중첩되면, 추정 위치 정보로부터 미리 설정된 임계 거리 이내에 존재하는 객체 포인트에 대한 제2특징 정보를 기준 프레임에 대한 이동 궤적에 반영할 수 있다. 이와 관련하여 본원의 일 실시예에 따르면, 트랙 추적부는 추정 위치 정보로부터 임계 거리 이내이고, 속 도 정보가 이전 프레임에서 등장 객체에 대하여 도출된 속도와 미리 설정된 임계 수준 이내로 유사한 것으로 판 단되는 객체 포인트에 대한 제2특징 정보를 이용하여 해당 등장 객체의 이동 궤적을 갱신할 수 있다. 트랙 출력부는 등장 객체에 대한 이동 궤적을 지표면 좌표계 및 영상 평면 좌표계 중 적어도 하나를 이용 하여 표시할 수 있다. 이하에서는 상기에 자세히 설명된 내용을 기반으로, 본원의 동작 흐름을 간단히 살펴보기로 한다. 도 9는 본원의 일 실시예에 따른 센서 융합 기반의 객체 추적 방법에 대한 동작 흐름도이다. 도 9에 도시된 센서 융합 기반의 객체 추적 방법은 앞서 설명된 객체 추적 장치에 의하여 수행될 수 있다. 따라서, 이하 생략된 내용이라고 하더라도 객체 추적 장치에 대하여 설명된 내용은 센서 융합 기반의 객체 추적 방법에 대한 설명에도 동일하게 적용될 수 있다. 도 9를 참조하면, 단계 S11에서 객체 검출부는 (a) 영상 데이터에서 등장 객체의 경계 정보를 포함하는 제 1특징 정보를 도출할 수 있다. 구체적으로 단계 S11에서 객체 검출부는 (a1) 영상 데이터에서 미리 정의된 유형의 객체를 등장 객체로 검 출하고, 검출된 등장 객체의 경계 영역을 표시할 수 있다. 또한, 단계 S11에서 객체 검출부는 (a2) 등장 객체에 대한 제1특징 정보와 관련하여 현재 속성값과 예상 속성값을 기초로 하여 등장 객체의 시계열적인 이동 궤적을 도출할 수 있다. 이와 관련하여, 제1특징 정보(속성값)는 객체의 유형, 영상 내 위치, 속도, 색상, 경계 영역 내부의 영상 신호 를 입력으로 하여 기 학습된 인공지능 모델에 의해 출력된 특징 벡터 중 적어도 하나를 포함할 수 있다. 다음으로, 단계 S12에서 포인트 처리부는 (b) 영상 데이터에 대응하는 레이더 센서 정보로부터 객체 포인 트를 검출할 수 있다. 또한, 단계 S12에서 포인트 처리부는 객체 포인트의 좌표 정보 및 속도 정보를 포함 하는 제2특징 정보를 도출할 수 있다. 구체적으로 단계 S12에서 포인트 처리부는 (b1) 복수의 객체 포인트 각각에 대하여 도출된 제2특징 정보를 이용한 클러스터링을 통해 복수의 객체 포인트를 동일 객체에 대응하는 포인트로 그룹핑할 수 있다. 또한, 단계 S12에서 포인트 처리부는 (b2) 그룹핑된 포인트의 대표 속성을 결정할 수 있다. 다음으로, 단계 S13에서 정합 수행부는 (c) 레이더 센서 정보에 대하여 적용되는 지표면 좌표계와 상기 영 상 데이터에 대하여 적용되는 영상 평면 좌표계 사이의 좌표계 변환을 수행할 수 있다. 구체적으로 단계 S13에서 정합 수행부는 객체 포인트를 영상 평면 좌표계로 변환하거나, 경계 정보에 따른 등장 객체의 대표 좌표를 지표면 좌표계로 변환할 수 있다. 다음으로, 단계 S14에서 트랙 추적부는 (d) 단계 S13에서의 좌표계 변환 수행 결과를 반영하여, 제1특징 정보 및 제2특징 정보에 기초하여 등장 객체에 대한 이동 궤적을 생성하거나 기 구축된 이동 궤적을 갱신할 수 있다. 구체적으로 단계 S14에서 트랙 추적부는 영상 데이터의 복수의 프레임 중 기준 프레임(예를 들면, 현재 프 레임)의 이전 프레임에 대하여 생성된 이동 궤적을 이용하여 기준 프레임에서의 등장 객체의 추정 위치 정보를 도출할 수 있다. 또한, 단계 S14에서 트랙 추적부는 도출된 추정 위치 정보와 제1특징 정보를 비교하여 제 1특징 정보를 기준 프레임에 대한 이동 궤적에 반영할 수 있다. 또한, 본원의 일 실시예에 따르면, 단계 S14에서 트랙 추적부는 만일 기준 프레임에 대하여 예측된 추정 위치 정보와 실제 기준 프레임에서 도출된 등장 객체의 경계 정보가 미중첩되면, 추정 위치 정보로부터 미리 설정된 임계 거리 이내에 존재하는 객체 포인트에 대한 제2특징 정보를 기준 프레임에 대한 이동 궤적에 반영할 수 있다. 이와 관련하여 본원의 일 실시예에 따르면, 단계 S14에서 트랙 추적부는 추정 위치 정보로부터 임계 거리 이내이고, 속도 정보가 이전 프레임에서 등장 객체에 대하여 도출된 속도와 미리 설정된 임계 수준 이내로 유사 한 것으로 판단되는 객체 포인트에 대한 제2특징 정보를 이용하여 해당 등장 객체의 이동 궤적을 갱신할 수 있 다. 다음으로, 단계 S15에서 트랙 출력부는 (e) 등장 객체에 대한 이동 궤적을 지표면 좌표계 및 영상 평면 좌 표계 중 적어도 하나를 이용하여 표시할 수 있다. 상술한 설명에서, 단계 S11 내지 S15는 본원의 구현예에 따라서, 추가적인 단계들로 더 분할되거나, 더 적은 단 계들로 조합될 수 있다. 또한, 일부 단계는 필요에 따라 생략될 수도 있고, 단계 간의 순서가 변경될 수도 있다. 본원의 일 실시예에 따른 센서 융합 기반의 객체 추적 방법은 다양한 컴퓨터 수단을 통하여 수행될 수 있는 프 로그램 명령 형태로 구현되어 컴퓨터 판독 가능 매체에 기록될 수 있다. 상기 컴퓨터 판독 가능 매체는 프로그 램 명령, 데이터 파일, 데이터 구조 등을 단독으로 또는 조합하여 포함할 수 있다. 상기 매체에 기록되는 프로 그램 명령은 본 발명을 위하여 특별히 설계되고 구성된 것들이거나 컴퓨터 소프트웨어 당업자에게 공지되어 사 용 가능한 것일 수도 있다. 컴퓨터 판독 가능 기록 매체의 예에는 하드 디스크, 플로피 디스크 및 자기 테이프 와 같은 자기 매체(magnetic media), CD-ROM, DVD와 같은 광기록 매체(optical media), 플롭티컬 디스크 (floptical disk)와 같은 자기-광 매체(magneto-optical media), 및 롬(ROM), 램(RAM), 플래시 메모리 등과 같 은 프로그램 명령을 저장하고 수행하도록 특별히 구성된 하드웨어 장치가 포함된다. 프로그램 명령의 예에는 컴 파일러에 의해 만들어지는 것과 같은 기계어 코드뿐만 아니라 인터프리터 등을 사용해서 컴퓨터에 의해서 실행 될 수 있는 고급 언어 코드를 포함한다. 상기된 하드웨어 장치는 본 발명의 동작을 수행하기 위해 하나 이상의 소프트웨어 모듈로서 작동하도록 구성될 수 있으며, 그 역도 마찬가지이다. 또한, 전술한 센서 융합 기반의 객체 추적 방법은 기록 매체에 저장되는 컴퓨터에 의해 실행되는 컴퓨터 프로그 램 또는 애플리케이션의 형태로도 구현될 수 있다."}
{"patent_id": "10-2023-0093036", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "전술한 본원의 설명은 예시를 위한 것이며, 본원이 속하는 기술분야의 통상의 지식을 가진 자는 본원의 기술적 사상이나 필수적인 특징을 변경하지 않고서 다른 구체적인 형태로 쉽게 변형이 가능하다는 것을 이해할 수 있을 것이다. 그러므로 이상에서 기술한 실시예들은 모든 면에서 예시적인 것이며 한정적이 아닌 것으로 이해해야만 한다. 예를 들어, 단일형으로 설명되어 있는 각 구성 요소는 분산되어 실시될 수도 있으며, 마찬가지로 분산된 것으로 설명되어 있는 구성 요소들도 결합된 형태로 실시될 수 있다. 본원의 범위는 상기 상세한 설명보다는 후술하는 특허청구범위에 의하여 나타내어지며, 특허청구범위의 의미 및 범위 그리고 그 균등 개념으로부터 도출되는 모든 변경 또는 변형된 형태가 본원의 범위에 포함되는 것으로 해 석되어야 한다."}
{"patent_id": "10-2023-0093036", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본원의 일 실시예에 따른 센서 융합 기반의 객체 추적 장치를 포함하는 객체 인식 시스템의 개략적인 구 성도이다. 도 2는 본원의 일 실시예에 따른 센서 융합 기반의 객체 추적 장치를 포함하는 객체 인식 시스템의 동작 프로세 스를 개략적으로 나타낸 개념도이다. 도 3은 영상 데이터 및 레이더 센서 정보를 예시적으로 나타낸 도면이다.도 4는 지표면 좌표계와 영상 평면 좌표계를 설명하기 위한 개념도이다. 도 5는 영상 평면 상에서 검출한 객체의 이동 궤적에 대해 특정 프레임 시점에서 각 이동 객체를 포함하는 경계 영역과 광학영상 평면으로 좌표 변환되어 표현된 객체 포인트를 예시적으로 나타낸 도면이다. 도 6은 지표면 좌표계 상에서 특정 프레임 시점에 획득된 객체 포인트들과 영상 평면에서 검출된 객체의 대표 좌표를 지표면 좌표계로 변환하여 표현한 그래프이다. 도 7은 제1특징 정보 및 제2특징 정보에 기초하여 등장 객체에 대한 이동 궤적을 생성/갱신하는 프로세스를 설 명하기 위한 개념도이다. 도 8은 본원의 일 실시예에 따른 센서 융합 기반의 객체 추적 장치의 개략적인 구성도이다. 도 9는 본원의 일 실시예에 따른 센서 융합 기반의 객체 추적 방법에 대한 동작 흐름도이다."}
