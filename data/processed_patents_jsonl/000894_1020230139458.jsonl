{"patent_id": "10-2023-0139458", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2025-0055826", "출원번호": "10-2023-0139458", "발명의 명칭": "DC-DC 컨버터 제어 시스템 및 이에 의한 DC-DC 컨버터 제어 방법", "출원인": "서울과학기술대학교 산학협력단", "발명자": "심민규"}}
{"patent_id": "10-2023-0139458", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "DC-DC 컨버터;상기 DC-DC컨버터의 현재 상태 정보를 생성하는 센서 모듈;상기 DC-DC 컨버터의 듀티비를 제어하는 PWM 모듈;상기 PWM 모듈에 제어지령치를 전달하기 위해, 상기 센서 모듈로부터 현재 상태 정보(st)를 수신하고 상기 현재 상태 정보를 시간지연을 반영한 수정 상태 정보(xt)로 변경하고 이로부터 행동값을 생성하는 행동값 생성부를포함하되,상기 행동값 생성부는 상기 수정 상태 정보에 따라 듀티비의 행동값이 출력되도록 강화학습된 모델로 구성되는, DC-DC 컨버터 제어 시스템."}
{"patent_id": "10-2023-0139458", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "청구항 1에 있어서,상기 행동값 생성부는 현재 상태 정보(st)와 이전 행동(at-1)의 쌍으로서, xt = (st, at-1)로 정의되는 상기 수정상태 정보(xt)를 사용하여 동작과 상태 사이의 시간 단계를 동기화하고, 에이전트가 상기 수정 상태(xt)를 입력받아 현재 행동(at)을 선택하고 상기 수정 상태의 함수로 표현된 보상을 피드백받아 정책 π를 도출하도록 실시간 심층 강화학습된 모델로 구성된 것인, DC-DC 컨버터 제어 시스템."}
{"patent_id": "10-2023-0139458", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "청구항 2에 있어서,상기 행동값에 기초한 상기 제어지령치는 상기 DC-DC 컨버터의 PWM 제어를 위한 듀티비(duty ratio)이며,상기 PWM 모듈은 상기 제어지령치를 전달받아 상기 DC-DC 컨버터의 제어를 위한 제어 펄스(pulse)를 생성하는것인, DC-DC 컨버터 제어 시스템."}
{"patent_id": "10-2023-0139458", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "청구항 3에 있어서,상기 행동값 생성부는 상기 수정 상태 정보에 따라 듀티비의 행동값이 출력되도록 강화학습된 모델로 구성되는것인, DC-DC 컨버터 제어 시스템."}
{"patent_id": "10-2023-0139458", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "에 있어서,상기 행동값 생성부는 상기 DC-DC 컨버터의 제어의 과정에서 시스템의 안전성을 위해 DC-DC 컨버터 전류()가 설정된 범위 내에 있도록 행동값을 출력하는 강화학습된 모델로 구성되는 것인, DC-DC 컨버터 제어 시스템."}
{"patent_id": "10-2023-0139458", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "청구항 6에 있어서,상기 현재 상태 정보(St)는 아래의 식으로 표현되며,( )는 이전 시점의 상태벡터로서 시간지연 값을 나타내고,( )은 현재 상태벡터의 값을 나타내며,상기 수정 상태 정보(xt)는, 로 표현되고,상기 행동값 생성부는 현재 상태 정보(st) 및 이전 시점의 행동값(at-1)을 동시에 입력으로 받아 시간 지연에 대응하도록 현재 행동값(at)을 도출하도록 강화학습된 모델로 구성되는 것인, DC-DC 컨버터 제어 시스템."}
{"patent_id": "10-2023-0139458", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "DC-DC 컨버터를 제어하는 방법에 있어서,센서 모듈이 DC-DC컨버터의 현재 상태 정보를 생성하는 단계;상기 센서 모듈로부터 현재 상태 정보(st)를 수신하고 상기 현재 상태 정보를 시간지연을 반영한 수정 상태 정보(xt)로 변경하고 이로부터 행동값을 생성하도록 강화학습된 모델로 구성되는 행동값 생성부가 상기 수정 상태정보로부터 행동값을 생성하고, 상기 행동값에 기초한 제어지령치를 PWM 모듈에 전달하는 단계;상기 PWM 모듈이 상기 제어지령치에 따라 PWM 펄스를 생성하여 상기 DC-DC 컨버터의 듀티비를 제어하는 단계;를 포함하는, DC-DC 컨버터 제어 방법."}
{"patent_id": "10-2023-0139458", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "청구항 8에 있어서,상기 현재 상태 정보를 생성하는 단계에서, 상기 현재 상태 정보는 시간지연을 포착하기 위해 이전 시점의 상태벡터를 포함하되, 아래의 식으로 표현되며,( )는 이전 시점의 상태벡터로서 시간지연 값을 나타내고,( )은 현재 상태벡터의 값을 나타내며,공개특허 10-2025-0055826-4-상기 행동값에 기초한 제어지령치를 PWM 모듈에 전달하는 단계에서, 상기 수정 상태 정보(xt)는, 로 표현되고,상기 행동값 생성부는 현재 상태 정보(st) 및 이전 시점의 행동값(at-1)을 동시에 입력으로 받아 시간 지연에 대응하도록 현재 행동값(at)을 도출하는 것인 DC-DC 컨버터 제어 방법."}
{"patent_id": "10-2023-0139458", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "청구항 9에 있어서,상기 행동값 생성부가 행동값에 기초한 제어지령치를 PWM 모듈에 전달하는 단계에서, 상기 제어지령치는 상기DC-DC 컨버터의 PWM 제어를 위한 듀티비(duty ratio)이며,상기 PWM 모듈은 상기 제어지령치를 전달받아 제어 펄스(pulse)를 생성하며,상기 행동값 생성부는 상기 수정 상태 정보에 따라 듀티비의 행동값이 출력되도록 미리 마련된 강화학습된 모델을 사용하여, 상기 DC-DC 컨버터의 입력전압()을 인풋으로 받아 출력전압()을 원하는 전압 레벨()에설정 시간 내에 도달하도록 행동값을 출력하되, 시스템의 안전성을 위해 DC-DC 컨버터 전류()는 설정된 범위내에 있도록 행동값을 출력하는, DC-DC 컨버터 제어 방법."}
{"patent_id": "10-2023-0139458", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명의 일 실시예는 DC-DC 컨버터; 상기 DC-DC컨버터의 현재 상태 정보를 생성하는 센서 모듈; 상기 DC-DC 컨버터의 듀티비를 제어하는 PWM 모듈; 상기 PWM 모듈에 제어지령치를 전달하기 위해, 상기 센서 모듈로 부터 현재 상태 정보(st)를 수신하고 상기 현재 상태 정보를 시간지연을 반영한 수정 상태 정보(xt)로 변경하고 이로부터 행동값을 생성하는 행동값 생성부를 포함하되, 상기 행동값 생성부는 상기 수정 상태 정보에 따라 듀티 비의 행동값이 출력되도록 강화학습된 모델로 구성되는, DC-DC 컨버터 제어 시스템 및 이에 의한 DC-DC 컨버 터 제어 방법을 제공한다."}
{"patent_id": "10-2023-0139458", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 DC-DC 컨버터 제어 시스템 및 이에 의한 DC-DC 컨버터 제어 방법 에 관한 것으로, 더욱 상세하게는 전기에너지의 교류/직류, 전압, 주파수 등을 변환하는 디지털 신호 프로세서로 구현된 강화학습 기반 DC-DC 컨 버터 제어 시스템 및 이에 의한 DC-DC 컨버터 제어 방법에 관한 것이다."}
{"patent_id": "10-2023-0139458", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "전력변환기(power converter)는 전기에너지의 교류/직류, 전압, 주파수등을 변경하는 장치이다. 신재생에너지, 핵융합발전 등의 에너지원의 다양화와 전기자동차, 선박, 항공기 등의 전기추진기기의 발전에 따라 전력변환기 에도 높은 수준의 기술조건이 요구되고 있다. 이러한 상황에서 전력변환 장치의 효율적인 운영과 전력 품질 개 선은 매우 중요한 요소이며, 적절한 제어기 설계가 필수적이다. 고품질의 제어기는 전력전자 기기의 작동을 최 적화하고 안정성을 유지함으로써, 지속가능한 에너지 이용과 시스템의 효율성을 향상시키는데 기여한다. 전력변환 장치의 제어 기법은 지난 수십 년간 사용해온 비례-적분-미분 제어기(Proportional-Integral- Differential controller, PID controller) 방식이 여전히 주를 이루고 있으며, 최근에는 모델기반 예측제어 기법(Model Predictive Control, MPC)이 등장하였다. 하지만 두 제어 기법의 본질적인 한계는 모델 기반 접근방 식(model-based strategy)이라는 점으로서, 전력변환 장치의 정확한 모델 해석이 요구된다. 하지만 일반적으로 규모가 비대한 시스템, 비선형성을 포함한 복잡한 구조, 환경요인들에 의한 불확실성 등과 같은 이유에서 요구 사항을 충족하기 매우 힘들다. 따라서 최근 인공지능 기법의 발전과 함께 전력변환 장치의 제어에도 인공지능 기법을 도입하려는 시도가 늘고 있다. 강화학습(Reinforcement learning, RL)은 정확한 모델의 정보가 주어지지 않은 환경(model-free environment)에서 효과적인 기법이다. 도 1은 강화학습 학습방법을 나타낸다. 도 1에서, 지능형 강화학습 에이전트(intelligent agent, or RL agen t)는 시행착오를 통해 경험을 축적하여 최적의 제어 기법을 학습한다. 이 방법은, 수리적 모델을 가정하지 않기 에 위에서 언급한 모델기반 접근방식의 본질적인 한계로부터 상대적으로 강건하다. 또한 강화학습 에이전트의최적 제어정책을 통해 전통적인 모델기반 제어에서 표현되지 못한 감춰져 있는 동특성의 발견을 기대할 수 있다 그러나, 현재까지 시도된 강화학습 기반의 접근방식은, 다음과 같은 이유들에서 실용적으로 산업에서 적용하기 힘들다. 첫째로, 대부분의 기존 방법들은 과전류 제한을 고려하지 않는 제한적인 시스템만을 고려하였으나, 실 제 사용에서, 과전류가 흐를 수 있는 가능성이 존재하며, 안전성이 담보되지 않는다. 둘째로, 인공 신경망을 포 함하여 과도한 연산량이 요구되었고, 이에따라 고가의 프로세서를 요구하며 경제적으로 실용성이 떨어진다. 경제성을 확보하기 위해 저가 프로세서에서도 고품질의 제어를 수행할 수 있도록 개발하는 것이 중요하다. 그러 나 저가 프로세서의 경우 계산처리 능력의 한계로 인해 제어 입력과, 실제 동작사이의 시간차이로 인해 기존 강 화학습 기법 적용이 매우 어렵다."}
{"patent_id": "10-2023-0139458", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명이 이루고자 하는 기술적 과제는 과전류 보호를 포함한 안전성을 담보하고 시간지연에 강건하여 경제적 으로 운영 가능한 산업수준의 고품질 디지털 신호 프로세서로 구현된 강화학습 기반 DC-DC 컨버터 제어 시스템 및 이에 의한 DC-DC 컨버터 제어 방법을 제공하는 것이다. 본 발명이 이루고자 하는 기술적 과제는 이상에서 언급한 기술적 과제로 제한되지 않으며, 언급되지 않은 또 다 른 기술적 과제들은 아래의 기재로부터 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2023-0139458", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기 기술적 과제를 달성하기 위하여, 본 발명의 일 실시예는 DC-DC 컨버터; 상기 DC-DC컨버터의 현재 상태 정보를 생성하는 센서 모듈; 상기 DC-DC 컨버터의 듀티비를 제어하는 PWM 모듈; 상기 PWM 모듈에 제어지 령치를 전달하기 위해, 상기 센서 모듈로부터 현재 상태 정보(st)를 수신하고 상기 현재 상태 정보를 시간지연 을 반영한 수정 상태 정보(xt)로 변경하고 이로부터 행동값을 생성하는 행동값 생성부를 포함하되, 상기 행동값 생성부는 상기 수정 상태 정보에 따라 듀티비의 행동값이 출력되도록 강화학습된 모델로 구성되는, DC-DC 컨 버터 제어 시스템을 제공한다. 본 발명의 실시예에 있어서, 상기 행동값 생성부는 현재 상태 정보(st)와 이전 행동(at-1)의 쌍으로서, xt = (st, at-1)로 정의되는 상기 수정 상태 정보(xt)를 사용하여 동작과 상태 사이의 시간 단계를 동기화하고, 에이전트가 상기 수정 상태(xt)를 입력받아 현재 행동(at)을 선택하고 상기 수정 상태의 함수로 표현된 보상을 피드백받아 정책 π를 도출하도록 실시간 심층 강화학습된 모델로 구성될 수 있다. 본 발명의 실시예에 있어서, 상기 행동값에 기초한 상기 제어지령치는 상기 DC-DC 컨버터의 PWM 제어를 위한 듀 티비(duty ratio)이며, 상기 PWM 모듈은 상기 제어지령치를 전달받아 상기 DC-DC 컨버터의 제어를 위한 제어 펄스(pulse)를 생성할 수 있다. 본 발명의 실시예에 있어서, 상기 행동값 생성부는 상기 수정 상태 정보에 따라 듀티비의 행동값이 출력되도록 강화학습된 모델로 구성될 수 있다. 본 발명의 실시예에 있어서, 상기 DC-DC 컨버터는 동기식 버크 컨버터(Synchronous buck converter)이고, 상기 행동값 생성부는 상기 DC-DC 컨버터의 입력전압( )를 인풋으로 받아 출력전압( )을 원하는 전압 레벨 ( )에 설정 시간 내에 도달하게 하는 행동값을 출력하도록 강화학습된 모델로 구성될 수 있다. 본 발명의 실시예에 있어서, 상기 행동값 생성부는 상기 DC-DC 컨버터의 제어의 과정에서 시스템의 안전성을 위해 DC-DC 컨버터 전류( )가 설정된 범위 내에 있도록 행동값을 출력하는 강화학습된 모델로 구성될 수 있다.본 발명의 실시예에 있어서, 상기 현재 상태 정보(St)는 아래의 식으로 표현되며,"}
{"patent_id": "10-2023-0139458", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 2, "content": "( )는 이전 시점의 상태벡터로서 시간지연 값을 나타내고, ( )은 현재 상태벡터의 값을 나타내며, 상기 수정 상태 정보(xt)는, 로 표현되고, 상기 행동값 생성부는 현재 상태 정보(st) 및 이전 시점의 행동값(at-1)을 동시에 입력으로 받아 시간 지연에 대 응하도록 현재 행동값(at)을 도출하도록 강화학습된 모델로 구성될 수 있다. 상기 기술적 과제를 달성하기 위하여, 본 발명의 다른 실시예는 DC-DC 컨버터를 제어하는 방법에 있어서, 센서 모듈이 DC-DC컨버터의 현재 상태 정보를 생성하는 단계; 상기 센서 모듈로부터 현재 상태 정보(st)를 수신하고 상기 현재 상태 정보를 시간지연을 반영한 수정 상태 정보(xt)로 변경하고 이로부터 행동값을 생성하도록 강화학 습된 모델로 구성되는 행동값 생성부가 상기 수정 상태 정보로부터 행동값을 생성하고, 상기 행동값에 기초한 제어지령치를 PWM 모듈에 전달하는 단계; 상기 PWM 모듈이 상기 제어지령치에 따라 PWM 펄스를 생성하여 상기 DC-DC 컨버터의 듀티비를 제어하는 단계;를 포함할 수 있다. 본 발명의 실시예에 있어서, 상기 현재 상태 정보를 생성하는 단계에서, 상기 현재 상태 정보는 시간지연을 포 착하기 위해 이전 시점의 상태벡터를 포함하되, 아래의 식으로 표현되며,"}
{"patent_id": "10-2023-0139458", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 3, "content": "( )는 이전 시점의 상태벡터로서 시간지연 값을 나타내고, ( )은 현재 상태벡터의 값을 나타내며, 상기 행동값에 기초한 제어지령치를 PWM 모듈에 전달하는 단계에서, 상기 수정 상태 정보(xt)는,"}
{"patent_id": "10-2023-0139458", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 4, "content": "로 표현되고, 상기 행동값 생성부는 현재 상태 정보(st) 및 이전 시점의 행동값(at-1)을 동시에 입력으로 받아 시 간 지연에 대응하도록 현재 행동값(at)을 도출할 수 있다. 본 발명의 실시예에 있어서, 상기 행동값 생성부가 행동값에 기초한 제어지령치를 PWM 모듈에 전달하는 단계에 서, 상기 제어지령치는 상기 DC-DC 컨버터의 PWM 제어를 위한 듀티비(duty ratio)이며, 상기 PWM 모듈은 상기 제어지령치를 전달받아 제어 펄스(pulse)를 생성하며, 상기 행동값 생성부는 상기 수정 상태 정보에 따라 듀티 비의 행동값이 출력되도록 미리 마련된 강화학습된 모델을 사용하여, 상기 DC-DC 컨버터의 입력전압( )를 인 풋으로 받아 출력전압( )을 원하는 전압 레벨( )에 설정 시간 내에 도달하도록 행동값을 출력하되, 시스템 의 안전성을 위해 DC-DC 컨버터 전류( )는 설정된 범위 내에 있도록 행동값을 출력할 수 있다."}
{"patent_id": "10-2023-0139458", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명의 실시예에 의하면, 강화학습에 기반한 DC-DC 전력변환 제어를 함으로써 다른 제어기보다 학습을 통해 더 최적제어를 할 수 있고, 또한 디지털 신호 프로세서(DSP)로 구현하되 전력 변환 장치(컨버터)를 제어하는 과 정에서 프로세서의 시간 지연 현상에도 불구하고 기존 강화학습보다 더 안정하게 동작하는 디지털 신호 프로세 서로 구현된 강화학습 기반 DC-DC 컨버터 제어 시스템 및 이에 의한 DC-DC 컨버터 제어 방법을 제공할 수 있 다."}
{"patent_id": "10-2023-0139458", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 2, "content": "본 발명의 효과는 상기한 효과로 한정되는 것은 아니며, 본 발명의 상세한 설명 또는 특허청구범위에 기재된 발 명의 구성으로부터 추론 가능한 모든 효과를 포함하는 것으로 이해되어야 한다."}
{"patent_id": "10-2023-0139458", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명은 다양한 변경을 가할 수 있고 여러 가지 형태를 가질 수 있는 바, 특정 실시예들을 도면에 예시하고 본문에 상세하게 설명하고자 한다. 그러나, 이는 본 발명을 특정한 개시 형태에 대해 한정하려는 것이 아니며, 본 발명의 사상 및 기술 범위에 포함되는 모든 변경, 균등물 내지 대체물을 포함하는 것으로 이해되어야 한다. 각 도면을 설명하면서 유사한 참조부호를 유사한 구성요소에 대해 사용하였다. 다르게 정의되지 않는 한, 기술적이거나 과학적인 용어를 포함해서 여기서 사용되는 모든 용어들은 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자에 의해 일반적으로 이해되는 것과 동일한 의미를 가지고 있다. 일 반적으로 사용되는 사전에 정의되어 있는 것과 같은 용어들은 관련 기술의 문맥 상 가지는 의미와 일치하는 의 미를 가지는 것으로 해석되어야 하며, 본 출원에서 명백하게 정의하지 않는 한, 이상적이거나 과도하게 형식적 인 의미로 해석되지 않는다. 이하, 첨부한 도면들을 참조하여, 본 발명의 바람직한 실시예를 보다 상세하게 설명하고자 한다. 도 2는 본 발명의 일 실시예에 따른 DC-DC 컨버터 제어 시스템을 나타낸다. 도 2를 참조하면, 본 실시예의 DC-DC 컨버터 제어 시스템은 DC-DC 컨버터, DC-DC컨버터의 현재 상태 정보를 생성하는 센서 모듈, DC-DC 컨버터의 듀티비를 제어하는 PWM 모듈 및 행동값 생성부 를 포함한다. 행동값 생성부는 PWM 모듈에 제어지령치를 전달하기 위해, 센서 모듈로부터 현재 상태 정보를 수신하고 현재 상태 정보를 시간지연을 반영한 수정 상태 정보로 변경하고 이로부터 행동값을 생성할 수 있다. 행동값 생성부는 현재 상태 정보에 따라 듀티비의 행동값이 출력되도록 강화학습된 모델 로 구성될 수 있다. 본 실시예의 DC-DC 컨버터 제어 시스템은 저비용으로 강화학습을 전력변환기 제어에 적용하는 기술로서, 기 존의 전통적인 모델 기반 접근 방식과는 다른 방법을 개시한다. 강화학습은 모델 기반 제어와는 다르게 정확한 모델 정보가 필요하지 않으며, 시스템의 상태와 환경에 따라 적응하여 최적의 제어 정책을 학습하는 능력이 있 다. 또한, 실시간 심층 강화학습(RTDRL) 프레임워크를 도입하여 시간 지연이 있는 저비용 프로세서에서도, 강건 한 강화학습 에이전트를 구축한다는 특징을 가진다. 이하, 각 구성을 더 상세히 설명한다. 도 3은 도 2에서 DC-DC 컨버터의 일 예로서 동기식 버크 컨버터를 나타낸다. 도 3에 도시된 동기식 버크 컨버터(Synchronous buck converter)는 DC-DC 컨버터의 일 예로서, DC-DC 컨 버터 제어 시스템의 PWM 모듈 및 행동값 생성부에 의해 제어될 수 있다. DC-DC 컨버터 제어 시스템의 목적은 입력전압( )를 인풋으로 받아 출력전압( )을 원하는 전압 레벨( )에 설정된 시간 내에 (최대한 빠르게) 도달하도록 제어하는 것이다. 또한 그 제어의 과정에서 시스템의 안전성을 위해 전류( )는 설 정된 범위 내에 있도록 제어되어야 한다. 도 3에 도시된 동기식 버크 컨버터의 회로도에서 전류 및 전압의 동역학은 아래의 식 및 식를 따른다."}
{"patent_id": "10-2023-0139458", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "동기식 버크 컨버터는 DC-DC 컨버터의 한 유형으로, 입력 전압은 일반적으로 AC 전압이지만 DC 전압도 사 용할 수 있다. 출력 전압은 입력 전압보다 낮은 전압으로 설정할 수 있다. 동기식 버크 컨버터는 다음과 같은 방식으로 작동할 수 있다. 스위치(예: MOSFET)가 닫히면 인덕터(L)에 전류가 흐른다. 인덕터의 전류가 증가함에 따라 인덕터의 전압이 증가한다. 전압이 출력 전압보다 높아지면 스위치가 열린다. 인덕터의 전류가 감소하면서 인덕터의 전압이 감소한다. 인덕터의 전압이 출력 전압보다 낮아지면 스위치가 닫힌다. 이 과정이 반복되면서 인덕터에 저장된 에너지가 출력 전원으로 전달될 수 있다. 센서 모듈은 DC-DC컨버터의 현재 상태 정보를 생성할 수 있다. 본 실시예에서는 현재 상태 정보(St)를 마코프 의사결정 과정(Markov decision process, MDP)를 사용하여 수식 화 한다. MDP는 강화 학습 (Reinforcement Learning) 분야에서 매우 중요한 개념으로서, MDP는 불확실성 하에서 순차적 의사결정과 관련된 문제를 해결하기 위해 설계된 수학적 프레임워크이다. 본 실시예에서의 강화학습의 적용에 대해서는 더 후술된다. MDP는 일반적으로 튜플(S, A, R, γ, P)로 정의된다. 여기서 S는 상태 공간을 나타내고, A는 행동 공간을 나타 내고, R은 보상 함수 r(s, a)를 나타낸다. S Х A → R 는 즉각적인 보상 가치를 결정하고, γ는 즉각적인 보상 과 미래 보상의 중요성의 균형을 맞추는 할인 요소이며, P는 현재 상태와 다음 상태 사이의 확률적 전환을 나타 낸다. 도 3에서 설명된 시스템을 설명하는 식 및 식를 기반으로 다음과 같이 상태, 행동, 보상 등 구성 요소가 정의될 수 있다. 시점 t에서의 상태, st ∈ S는 다음과 같이 정의된다."}
{"patent_id": "10-2023-0139458", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "위의 식으로 정의된 현재 상태 정보(St)는 시스템의 현재 상태를 표현하는 상태벡터 ( ) 뿐 만 아니라, 시간지연을 효과적으로 포착하기 위해 이전 시점의 상태벡터 ( )를 포함하도록 표현되어 있다. 시간 t, 에서의 행동 at(∈ A)는 at = dt ∈ [0, 1]와 같이 듀티값으로 정의된다. 행동에서 얻은 듀티값은 동기 식 벅 컨버터를 제어하기 위해 PWM 모듈을 통해 펄스를 생성하는 데 사용된다. 보상 rt ∈ R은 다음과 같이 정의된다."}
{"patent_id": "10-2023-0139458", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "여기서, 이고, 여기서 βi(>0), i = 1, 2, · · · , 6 및 η(>0)는 튜닝 매개변수이다. rvoltage는 두 가지 하위 항의 곱으로 표현될 수 있다. rerror는 출력 전압(output voltage)과 기준 전압(reference voltage) 간의 차이를 나타내고, rsteady는 듀티비 dt-1을 목표 정상 상태 값 로 유지하는 것을 목표로 한다. 이는 시스템이 정상 상태에 도달하면 식 을 사용하여 유도할 수 있다. 또한, rcurrent는 인덕터 전류 iL t가 한계 이내 로 유지되도록 정의된다. PWM 모듈은 행동값 생성부로부터의 제어지령치에 따라 DC-DC 컨버터의 듀티비(duty ratio)를 제 어할 수 있다. 즉, PWM(Pulse Width Modulation) 신호의 주기와 펄스 폭을 조절함으로써, DC-DC 컨버터의 스위 치(예: MOSFET)를 켜고 끄는 시간을 정밀하게 제어할 수 있다. 행동값 생성부는 PWM 모듈에 제어지령치를 전달하기 위해, 센서 모듈로부터 현재 상태 정보를 수신하고 현재 상태 정보를 시간지연을 반영한 수정 상태 정보로 변경하고 이로부터 행동값을 생성할 수 있다. 여기서 행동은 DC-DC 컨버터의 듀티비이며, 0에서 1의 값을 가질 수 있다. 이 값(제어지령치)는 PWM 모듈 로 전달되어 제어 펄스(pulse)를 만든다. 이러한 제어 펄스가 DC-DC 컨버터의 입력을 제어하고, 그 결과 출력이 제어될 수 있다. 행동값 생성부는 현재 상태 정보에 따라 듀티비의 행동값이 출력되도록 강화학습된 모델로 구성될 수 있다. 강화학습(RL)은 전술한 바와 같이 마코프 의사결정 과정(MDP)으로 모델링할 수 있는 순차적 의사결정 문 제를 해결하기 위한 알고리즘이다. MDP는 에이전트 (Agent)가 환경(Environment)과 상호 작용하면서 보상 (Reward)을 최대화하기 위해 어떤 행동(Action)을 취해야 할지 학습하는 문제를 기술하는 수학적 모델이다. 에 이전트의 목표는 시간에 따른 보상의 총합을 최대화하는 행동 정책 (Policy)을 찾는 것이다. 정책은 어떤 상태 에서 어떤 행동을 취할지 결정하는 함수이다. 더 구체적으로 설명하면, 에이전트는 상태 St에서 행동으로 매핑되는 정책 π를 기반으로 행동을 선택하고, 환경 은 보상 rt의 형태로 피드백을 제공하고 다음 상태 St+1로 전환한다. RL의 목적은 식 으로 표 시되는 미래 보상의 할인된 합계인 기대 수익을 최대화하는 정책을 결정하는 것이다. RL에서 행동-가치 함수 Qπ(st, at)는 주어진 상태 st에 대해 특정 행동을 수행한 후 이후 정책 π를 따르는 것과 관련된 기대 수익을 포착하는 기본 구성 요소이다. 또한 Bellman 방정식을 사용하여 다음 식와 같이 재귀적 으로 정의할 수도 있다."}
{"patent_id": "10-2023-0139458", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "이 행동-가치 함수(Qπ)는 각 상태에서 가장 높은 기대 수익을 갖는 행동을 선택함으로써 가치 기반 접근 방식에 서 최적의 정책을 도출하는 데 사용될 수도 있고, 정책 기반 접근 방식에서 암묵적으로 사용될 수도 있다. 행동자-비평자 방법(actor-critic method)은 가치 기반 방법과 정책 기반 방법을 결합한 하이브리드 접근 방식 이다. 이것은 다음과 같이 구성된다. 두 가지 구성요소 즉, 행동자 및 비평자는 일반적으로 매개변수화된다. 비 평자는 행동-가치 함수 Qπ(st, at)를 학습하고, 행동자는 비평자의 평가를 기반으로 정책 πθ를 업데이트한다.본 실시예에서는 SAC(Soft-Actor-Critic)라는 하이브리드 접근 방식을 사용한다. 도 4는 기존의 강화학습이 가정하는 일반적인 MDP 상황을 보여준다. 일반적으로 MDP는 행동 가 즉각적으로 다음 상태 에 영향을 미친다고 가정한다. 도 4에 표시된 것처럼 즉 각적인 영향의 표준 시나리오에서는 다음 상태 st+1은 현재 상태 st와 현재 동작 at의 함수이다. 즉, 에이전트는 관찰된 상태 에 기반하여 행동 를 결정하는 데 필요한 총 시간(즉, 처리 시간)과 결정된 행동 가 시스템 에 영향을 미치는 시간(즉, 제어 응답 시간)이 제어 시간 단위 간격 내에 있다고 가정한다. 도 5는 이전 시점의 행동이 시간이 지연되어 느리게 반영되는 상황을 보여준다. 그러나 고주파 제어를 포함하는 많은 공학 응용 시나리오에서는 전술한 일반적으로 MDP에서의 상기 가정이 성립 하지 않을 수 있다. 즉, 처리 시간과 제어 응답 시간의 합이 제어 시간 단위 간격의 길이를 초과할 수 있다. 이 경우, 행동을 선택한 효과는 지연된 방식으로 상태에 영향을 미친다. 즉, at은 st+1에 영향을 주지 않고 st+2에 영 향을 준다. 도 5에 묘사된 지연된 영향 시나리오에서는 다음 상태 st+1은 현재 상태 st와 이전 동작 at-1의 함수이 다. 이러한 경우 기존의 강화학습 적용은 적절하지 않다. 도 6은 도 2에서 행동값 생성부가 사용하는 강화학습 모델의 생성을 위한 실시간 심층 강화학습(RTDRL)을 나타낸다. 따라서 본 실시예에서는 SAC 알고리즘을 기반으로 하는 실시간 심층 강화학습(Real-Time Deep Reinforcement Learning, RTDRL) 프레임워크를 사용하여 시간 지연 문제를 해결한다. 다시 말해서, 시간 지연에 강건한 강화학습 에이전트를 구축한다. 구체적으로, 도 6에 도시된 바와 같이, 상태와 이전 동작 쌍을 포함하는 새로운 수정 상태(xt)로서, xt = (st, at-1) 를 도입하여 동작과 상태 사이의 시간 단계를 동기화한다. 이러한 본 실시예의 프레임워크 내에서 에이전 트 정책 π는 상태 st만 사용하는 대신 수정 상태 xt를 사용한다. 이러한 방식을 사용하는 이유는 상태 st만으로 는 지연이 있는 시스템의 미래 진화에 대한 충분한 통계가 아니기 때문이다. 이와 같은 본 실시예의 프레임워크 로 인해 기존의 행동 값(action- value) 함수 Qπ(st, at)와 다른 다음 식5와 같은 수정된 벨만 방정식이 생성된 다. 수정된 방정식에는 이전 작업(행동)이 입력으로 포함되며 세 가지 구성 요소, 즉 xt = (st, at-1) 및 at로 구 성된다. 또한, 보상도 수정된 상태의 함수로 표현된다."}
{"patent_id": "10-2023-0139458", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "본 실시예에서는 SAC 알고리즘을 활용하여 증가된 상태 xt = (st, at-1)을 행동 at에 매핑하는 수정된 최적 정책 과, RTDRL 설정에서 Q 함수 Qπ(xt, at)를 도출한다. SAC 알고리즘은 연속 제어를 위한 최첨단 RL 알고리즘으로, 그 목표는 다음 식6과 같이 누적 보상과 정책의 엔트로피를 모두 최대화하는 최적의 정책을 학습하는 것이다."}
{"patent_id": "10-2023-0139458", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 7, "content": "여기서 π*는 최적 정책이고, α는 보상의 중요도와 엔트로피 항의 균형을 맞추는 하이퍼파라미터이며, H(π(· |st))는 정책의 엔트로피이다. 엔트로피가 높을수록 더 많은 탐색이 촉진되어 학습 성능이 향상되고 정책이 로컬 최적 솔루션에서 벗어나는 것을 방지할 수 있다. 엔트로피 정규화된 목적 함수로 향상된 정책을 얻기 위해 다음 식7과 같이 KL(Kullback-Leibler) 발산을 사용하 여 정보 투영을 계산한다. 이 예측은 현재 정책과 목표 분포 간의 차이를 최소화한다."}
{"patent_id": "10-2023-0139458", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 8, "content": "여기서 Z(st)는 정책 분포의 합이 1이 되도록 보장하는 정규화 상수이다. Q-함수의 기대값에서 정책의 엔트로피 를 뺀 값을 최대화하는 소프트 Q-함수는 KL 발산을 최소화하는 것과 동일하며 다음과 같은 식8로 표현된다."}
{"patent_id": "10-2023-0139458", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 9, "content": "SAC와 결합된 RTDRL의 업데이트 절차는 다음과 같다. 비판자 업데이트에 있어서, 비판적 네트워크는 두 개의 Q-함수 근사기(approximators)인 및 와 소프 트 Q-함수 Q(xt, at)를 추정하기 위한 해당 대상 네트워크 및 로 구성된다. 다음 식9와 같이 손실 함수 를 최소화하여 업데이트된다."}
{"patent_id": "10-2023-0139458", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 10, "content": "여기서,"}
{"patent_id": "10-2023-0139458", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 11, "content": "행동자 업데이트에 있어서, 정책망 πθ(xt)가 다음 식10으로 표현되는 손실 함수 Jπ(θ)를 최소화하여 업데이트 된다."}
{"patent_id": "10-2023-0139458", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 12, "content": "이러한 본 실시예의 SAC 기반 RTDRL로 구성되는 행동값 생성부는 실제 변환기 시스템의 지연 문제를 처리하기 위해 RTDRL 접근 방식을 활용하는 새로운 접근법이다. 전술된 본 실시예의 Real-time Soft Actor-Critic의 알고 리즘은 도 7의 알고리즘 1에 의사코드로 제시되어 있다. 요컨데, 본 실시예의 RTDRL은 수정 상태 정보 를 사용하여, 즉 현재 상태 정보(st)와 이전 시점의 행동(at-1)을 동시에 입력으로 받아 시간 지연에 대응한다. 도 6에 제시된 실시간 심층 강화학습(RTDRL) 방법은 도 4에 제시된 기존 방법과 비교하여 RTDRL의 효과를 보여준다. 본 실시예의 실시간 심층 강화학습에 의해 마련 된 강화학습 모델을 사용하여 행동값 생성부는 수정 상태 정보를 기반으로 시간 지연이 있더라도 타임스텝 을 맞출 수 있어서 시간 지연에서도 효과적으로 행동하고 학습할 수 있다. 도 2 및 도 6을 참조하면, 본 실시예의 행동값 생성부가 사용하는 강화학습 모델은 현실에서 직접 경험을 통해 학습하기 어려운 경우를 위해 시뮬레이션 도구를 사용하여 학습할 수 있다. 예를 들어, 전력전자 시뮬레이 션 도구인 PLECS를 활용하여 원하는 전력변환장치를 설계한 후, 출력에 목표로 하는 시간 지연을 추가할 수 있 다. 상기 강화학습 모델의 학습 방법은 파이썬(Python)으로 코딩되고, 통신을 통해 서로 연결된 상태에서 신경 망(네트워크)을 학습할 수 있다. 이를 통해 행동값 생성부는 시간지연을 포함한 전력변환장치의 동작을 학 습할 수 있다. 도 8은 본 발명의 일 실시예에 따른 DC-DC 컨버터 제어 시스템이 전력변환장치에서 많이 사용되는 디지털 신호 프로세서(DSP)에 이식된 모습을 보여준다. 도 8을 참조하면, 완성된 RL-Agent가 전력변환장치에서 많이 사용되는 디지털 신호 프로세서(DSP)에 이식된 일 예가 나타나 있다. 학습이 완료된 Agent는 네트워크를 추출한 후 C 코드로 변환한 뒤, DSP에 이식될 수 있다. 이후 전력변환장치와 연결하여 제어를 수행할 수 있게 된다. 전술된 시간 지연은 최적 정책 학습의 어려움을 증가시키는 것으로 알려져 있다. 시간 지연 문제는 도 8에 도시 된 DSP(digital signal processor)의 PWM(pulse width modulation) 주변 장치에서도 발생할 수 있다. 예를 들 어, 처리 시간은 약 180μs이고 제어 응답 시간은 200μs이다. 전체 제어 시간 단위에 걸쳐 동작이 펄스로 발생 하기 때문에 이 두 번의 합이 제어 시간 단위 간격을 초과하여 시간 지연 문제가 발생할 수 있다. 이 문제를 피 하기 위해 기존에는 강화학습 과정 동안 처리 시간이 0이라고 가정했는데, 이는 값비싼 컨트롤러에서는 작동할 수 있지만 DSP와 같은 비용 효율적인 컨트롤러에서는 작동하지 않는다. 반면, 본 실시예의 DC-DC 컨버터 제어 시스템은 전술한 바와 같이 시간 지연에 강건한 강화학습 모델로 구성된 행동값 생성부에 의해 제어함으로써 전력변환장치의 제어를 DSP에서 수월하게 수행할 수 있다. 도 9는 본 발명의 일 실시예에 따른 DC-DC 컨버터 제어 방법을 나타낸다. 본 실시예의 DC-DC 컨버터 제어 방법에서, 센서 모듈이 DC-DC컨버터의 현재 상태 정보를 생성한다(S10). 상기 센서 모듈로부터 현재 상태 정보(st)를 수신하고 상기 현재 상태 정보를 시간지연을 반영한 수정 상태 정보 (xt)로 변경하고 이로부터 행동값을 생성하도록 강화학습된 모델로 구성되는 행동값 생성부가 상기 수정 상태 정보로부터 행동값을 생성하고, 상기 행동값에 기초한 제어지령치를 PWM 모듈에 전달할 수 있다 (S20). PWM 모듈이 상기 제어지령치에 따라 PWM 펄스를 생성하여 DC-DC 컨버터의 듀티비를 제어할 수 있다(S30). 제어 목표에 도달을 체크하여 이러한 과정을 반복할 수 있다. 현재 상태 정보를 생성하는 단계에서, 현재 상태 정보는 시간지연을 포착하기 위해 이전 시점의 상태벡터를 포 함하되, 아래의 식으로 표현되며,"}
{"patent_id": "10-2023-0139458", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 13, "content": "( )는 이전 시점의 상태벡터로서 시간지연 값을 나타내고, ( )은 현재 상태벡터의 값을 나타낼 수 있다. 상기 행동값에 기초한 제어지령치를 PWM 모듈에 전달하는 단계에서, 상기 수정 상태 정보(xt)는,"}
{"patent_id": "10-2023-0139458", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 14, "content": "로 표현되고, 상기 행동값 생성부는 현재 상태 정보(st) 및 이전 시점의 행동값(at-1)을 동시에 입력으로 받아 시 간 지연에 대응하도록 현재 행동값(at)을 도출할 수 있다. 행동값 생성부가 행동값에 기초한 제어지령치를 PWM 모듈에 전달하는 단계에서, 제어지령치는 DC-DC 컨버터의 PWM 제어를 위한 듀티비(duty ratio)이며, PWM 모듈은 제어지령치를 전달받아 제어 펄스 (pulse)를 생성하며, 행동값 생성부는 수정 상태 정보에 따라 듀티비의 행동값이 출력되도록 미리 마련된 강화학습된 모델을 사용하여, DC-DC 컨버터의 입력전압( )를 인풋으로 받아 출력전압( )을 원하는 전압 레벨( )에 설정 시간 내에 도달하도록 행동값을 출력하되, 시스템의 안전성을 위해 DC-DC 컨버터 전류 ( )는 설정된 범위 내에 있도록 행동값을 출력할 수 있다. 본 발명의 실시예들에 의하면, 기존의 비례-적분-미분 제어기(PID controller) 방식과 모델 기반 예측 제어기법 (MPC)을 대체하고, 강화학습을 기반으로 하는 DC-DC 컨버터 제어 시스템 및 이에 의한 DC-DC 컨버터 제어 방 법을 제공할 수 있다. 기존의 PID와 MPC는 정확한 모델 정보가 필요하고, 복잡한 시스템에서는 요구사항을 충족 하기 어려웠으며, 특히 저가의 프로세서에서 사용하기 어려운 단점이 있다. 이러한 한계를 극복하고, 강화학습 기반의 제어기를 도입하여 안전성과 경제성을 동시에 해결할 수 있다. 본 발명의 실시예들에 의하면, 전력변환기와 같은 전력전자 기기의 제어에 적용될 수 있다. 전력변환기는 다양 한 분야에서 사용되는 중요한 장치로, 신재생에너지, 전기자동차, 항공기, 선박 등 다양한 산업 분야에서 사용 되고 있다. 따라서 본 발명의 실시예들이 산업에 적용되면, 전력전자 기기의 효율적인 운영과 안정성 향상에 큰 영향을 미칠 수 있으며, 지속가능한 에너지 이용과 시스템의 효율성을 증가시킬 수 있다."}
{"patent_id": "10-2023-0139458", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 15, "content": "전술한 본 발명의 설명은 예시를 위한 것이며, 본 발명이 속하는 기술분야의 통상의 지식을 가진 자는 본 발명 의 기술적 사상이나 필수적인 특징을 변경하지 않고서 다른 구체적인 형태로 쉽게 변형이 가능하다는 것을 이해 할 수 있을 것이다. 그러므로 이상에서 기술한 실시예들은 모든 면에서 예시적인 것이며 한정적이 아닌 것으로 이해해야만 한다. 예를 들어, 단일형으로 설명되어 있는 각 구성 요소는 분산되어 실시될 수도 있으며, 마찬가 지로 분산된 것으로 설명되어 있는 구성 요소들도 결합된 형태로 실시될 수 있다. 본 발명의 범위는 후술하는 특허청구범위에 의하여 나타내어지며, 특허청구범위의 의미 및 범위 그리고 그 균등 개념으로부터 도출되는 모든 변경 또는 변형된 형태가 본 발명의 범위에 포함되는 것으로 해석되어야 한다.부호의 설명 10 : DC-DC 컨버터 제어 시스템 100 : DC-DC 컨버터 200 : 센서 모듈 300 : PWM 모듈 400 : 행동값 생성부"}
{"patent_id": "10-2023-0139458", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 강화학습 학습방법을 나타낸다. 도 2는 본 발명의 일 실시예에 따른 DC-DC 컨버터 제어 시스템을 나타낸다. 도 3은 도 2에서 DC-DC 컨버터의 일 예로서 동기식 버크 컨버터를 나타낸다. 도 4는 기존의 강화학습이 가정하는 일반적인 MDP 상황을 보여준다. 도 5는 이전 시점의 행동이 시간이 지연되어 느리게 반영되는 상황을 보여준다. 도 6은 도 2에서 행동값 생성부가 사용하는 강화학습 모델의 생성을 위한 실시간 심층 강화학습을 나타낸다. 도 7은 본 발명의 일 실시예의 Real-time Soft Actor-Critic의 알고리즘을 나타내는 의사코드이다. 도 8은 본 발명의 일 실시예에 따른 DC-DC 컨버터 제어 시스템이 전력변환장치에서 많이 사용되는 디지털 신호 프로세서(DSP)에 이식된 모습을 보여준다. 도 9는 본 발명의 일 실시예에 따른 DC-DC 컨버터 제어 방법을 나타낸다."}
