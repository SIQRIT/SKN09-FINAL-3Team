{"patent_id": "10-2025-7005729", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2025-0044699", "출원번호": "10-2025-7005729", "발명의 명칭": "이미지 데이터에서 세장형 객체를 추적하는 방법 및 이미지 처리 시스템", "출원인": "막스-플랑크-게젤샤프트 츄어 푀르더룽 데어 비쎈", "발명자": "슈미트, 마틴"}}
{"patent_id": "10-2025-7005729", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "이미지 데이터(40; 170)에서 세장형 객체(41)를 추적하는 방법에 있어서, 상기 이미지 데이터(40; 170)는 생물학적 또는 의학적 이미지 데이터(40; 170)이고, 이미지 처리 시스템(30)에 의해 수행되는 상기 방법은,3차원 3D 공간에서 세장형 객체(41)를 따라 일련의 점(60)의 위치를 결정하여 상기 이미지 데이터(40; 170)에서3D로 세장형 객체(41)를 추적하는 단계를 포함하고, 상기 일련의 점(60)의 위치를 결정하는 것은 반복적 프로세스를 포함하고, 상기 반복적 프로세스는, 인공 지능 AI(artificial intelligence) 모델(110; 130)을 사용하여, 상기 세장형 객체(41), 선택적으로 세장형 객체의 중심선(50)이 세장형 객체(41)를 따라 이전에 결정된 점에서 확장되는 방향에 따라 달라지는 조향 예측을 추론하는 단계, 여기서, 상기 AI 모델(110; 130)은 상기 이미지 데이터(40; 170)의 픽셀 또는 복셀 값을기반으로 하는 AI 모델 입력을 수신하도록 동작하는 입력 계층과 상기 반복 프로세스의 각 반복에서 조향 예측이나 이를 나타내는 상기 AI 모델(110; 130) 출력을 제공하도록 동작하는 출력 계층을 포함하고,상기 조향 예측을 최소한 사용하여 상기 일련의 점(60) 중 다음 점(62-65)을 계산하는 단계, 여기서, 상기 다음점은 상기 일련의 점(60) 중 이전에 결정된 점(61-64) 다음의 점이고; 및종료 기준이 충족될 때까지 상기 추론하는 단계 및 상기 계산하는 단계를 반복적으로 되풀이하여 상기 일련의점(60)의 위치를 결정하는 단계를 포함하는 방법."}
{"patent_id": "10-2025-7005729", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 AI 모델은 상기 입력 계층, 복수의 컨볼루션 계층, 드롭아웃 계층 및 상기 출력 계층을 포함하는 컨볼루션 신경망(CNN) 또는 순환 신경망(RNN)을 포함하고, 상기 반복 프로세스의 반복에서 상기 입력 계층에 입력되는 상기 AI 모델 입력은 상기 이미지 데이터(40; 170)에 의해 표현되는 조직 볼륨의 서브 볼륨(91, 93; 172-174)을 나타내고, 상기 AI 모델 입력은 상기 이미지 데이터(40;170)의 서브 볼륨을 나타내는 픽셀 또는 복셀 값을 포함하고, 또는상기 이미지 데이터(40; 170)의 서브 볼륨을 나타내는 픽셀 또는 복셀 값의 다변수 보간을 통해 얻어지며; 및상기 서브 볼륨(91, 93; 172-174)의 방향은 상기 반복 프로세스의 이전 반복에서 결정된 조향 예측에 따라 달라지는, 방법."}
{"patent_id": "10-2025-7005729", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,상기 조향 예측은 세장형 객체(41)의 중심선(50)의 2차 미분에 따라 달라지는, 방법."}
{"patent_id": "10-2025-7005729", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서, 상기 AI 모델은 상기 입력 계층, 복수의 컨볼루션 계층, 드롭아웃 계층 및 상기 출력 계층을 포함하는 컨볼루션 신경망(CNN) 또는공개특허 10-2025-0044699-3-순환 신경망(RNN);이고,여기서 상기 반복 프로세스의 반복에서 상기 입력 계층에 입력되는 상기 AI 모델 입력은 상기 이미지 데이터(40; 170)에 의해 표현되는 조직 볼륨의 서브 볼륨(91, 93; 172-174)을 표현하고;상기 조향 예측은 상기 서브 볼륨과 관련하여 주어진 참조 프레임에 대한 곡률 값으로, 이를 통해 세장형 객체의 중심선(50)에 위치한 일련의 점을 반복적으로 결정하기 위한 위치 오프셋을 생성하고; 및바로 앞의 반복 이후의 각 반복에서 처리되는 해당 서브 볼륨은 바로 앞의 반복에서 얻은 조향 예측에서 결정된세장형 객체의 확장 방향에 의해 결정되는 회전 방향을 갖도록 결정되는, 방법."}
{"patent_id": "10-2025-7005729", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서, 상기 일련의 점(60)의 다음 점을 결정하는 것은 상기 조향 예측을 적분하는 것을 포함하고;상기 일련의 점(60)의 다음 점을 결정하는 것은 조향 예측을 적분하는 것을 포함하고, 여기서 조향 예측을 적분하는 것은 비숍 기준 프레임의 곡률을 적분하는 것을 포함하고;상기 조향 예측은 세장형 객체(41)의 중심선(50)의 2차 도함수와 관련된 것인, 중 하나 이상이 적용된 방법."}
{"patent_id": "10-2025-7005729", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항 또는 제5항에 있어서,상기 반복적 프로세스의 반복에서 상기 입력 계층에 입력되는 AI 모델 입력은 상기 이미지 데이터(40; 170)로표현되는 조직 볼륨의 서브 볼륨(91, 93; 172-174)을 나타내고, 상기 서브 볼륨(91, 93; 172-174)은 상기 반복적 프로세스의 하나 이상의 이전 반복에서 결정된 위치 및/또는 방향 및/또는 조향 예측에 따라 달라지는,방법."}
{"patent_id": "10-2025-7005729", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6항에 있어서, 상기 서브 볼륨(91, 93; 172-174)의 방향(orientation)은 상기 이전 조향 예측에 따라 달라지는, 방법."}
{"patent_id": "10-2025-7005729", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제6항 또는 제7항에 있어서, 상기 서브 볼륨(91, 93; 172-174)의 중심은 상기 이전에 결정된 점에 대해 오프셋만큼 이동되고;상기 서브 볼륨(91, 93; 172-174)의 중심은 상기 이전에 결정된 점에 대해 오프셋만큼 이동되고, 여기서 상기오프셋은 이전 반복에서 결정된 조향 예측에 따라 달라진 것인, 중 하나가 적용된 방법."}
{"patent_id": "10-2025-7005729", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제6항 내지 제8항 중 어느 한 항에 있어서, 상기 AI 모델 입력을 결정하기 위한 상기 이미지 데이터(40; 170)의픽셀 또는 복셀(voxel) 값의 다변수 보간(interpolation)을 더 포함하는, 방법."}
{"patent_id": "10-2025-7005729", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9항에 있어서, 상기 다변량 보간은 상기 이미지 데이터(40; 170)의 픽셀 또는 복셀 그리드에 대해 기울어지거나 오프셋된 그리드에서 보간된 픽셀또는 복셀 값으로 AI 모델 입력을 생성하기 위해 픽셀 또는 복셀 값의 가중 평균을 내거나, 또는 삼선형 투영을 포함하는, 방법."}
{"patent_id": "10-2025-7005729", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "이전 청구항 중 어느 한 항에 있어서, 상기 반복적인 절차의 초기화를 수행하는 단계를 더 포함하고, 상기 초기화는 초기 방향이 사용할 수 있는지 여부에 따라 달라지는, 방법.공개특허 10-2025-0044699-4-청구항 12 제11항에 있어서, 상기 초기 방향이 사용할 수 없는 경우, 상기 반복적인 프로세스의 초기 반복에서 사용하기 위한 상기 초기 방향을 결정하는 단계를 더 포함하는 방법."}
{"patent_id": "10-2025-7005729", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제12항에 있어서, 상기 초기 방향을 결정하는 단계는:다양한 방향에 대한 예측의 불확실성 추정치를 결정하는 단계; 및상기 대응되는 예측에서 상기 불확실성 추정치가 최소인 상기 다양한 방향 중 방향과 조향 예측을 선택하는 단계를 포함하는, 방법."}
{"patent_id": "10-2025-7005729", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제13항에 있어서, 상기 불확실성 추정치는 몬테카를로(Monte-Carlo) 드롭아웃을 사용하여 결정되는, 방법."}
{"patent_id": "10-2025-7005729", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "이전 청구항 중 어느 한 항에 있어서, 상기 AI 모델(110; 130)은 컨볼루션 신경망(CNN) 또는 순환 신경망(RNN)을 포함하고,상기 AI 모델(110; 130)은 상기 입력 계층, 복수의 컨볼루션 계층, 드롭아웃 계층 및 상기 출력 계층을 포함하고,상기 AI 모델(110; 130)은 풀링 계층, 어텐션 모듈, 셀프 어텐션 모듈, 아트러스 컨볼루션, 정규화 계층, 배치정규화 계층, 변환기, 순환 계층 중 하나 이상을 포함하는, 중 하나가 적용된, 방법."}
{"patent_id": "10-2025-7005729", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "이전 청구항 중 어느 한 항에 있어서,상기 출력 계층은 선형 계층이고;상기 복수의 컨볼루션 계층은 하나 또는 복수의 스트라이드 컨볼루션 계층을 포함하고;상기 AI 모델(110; 130)은 완전 컨볼루션 네트워크이거나 이를 포함하고;상기 AI 모델(110; 130)은 하나 또는 복수의 비선형성을 포함하고;상기 AI 모델(110; 130)은 ELU(exponential linear units)를 포함하고; 상기 AI 모델(110; 130)은 ReLU(rectified linear units)를 포함하고;상기 AI 모델(110; 130)은 SELU(Scaled Exponential Linear units)를 포함하고;상기 AI 모델(110; 130)은 GELU(Gaussian Error Linear Units)를 포함하고 중 하나, 복수 또는 모두가 적용되는, 방법."}
{"patent_id": "10-2025-7005729", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "이전 청구항 중 어느 한 항에 있어서, 상기 세장형 객체(41)는 신경 돌기(neurite)인, 방법."}
{"patent_id": "10-2025-7005729", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제1항 내지 제16항 중 어느 한 항에 있어서, 상기 세장형 객체(41)는 혈관인, 방법."}
{"patent_id": "10-2025-7005729", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "이전 청구항 중 어느 한 항에 있어서, 상기 세장형 객체(41)는 중심선(50) 주위로 국부적으로 원통형으로 확장되는 표면을 갖는, 방법.공개특허 10-2025-0044699-5-청구항 20 이전 청구항 중 어느 한 항에 있어서, 상기 AI 모델(110; 130)을 훈련시키는 단계를 더 포함하는, 방법."}
{"patent_id": "10-2025-7005729", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_21", "content": "제20항에 있어서,상기 AI 모델(110; 130)은 지도 학습을 사용하여 훈련되고;상기 AI 모델(110; 130)을 훈련하는 것은 상기 AI 모델(110; 130) 파라미터의 경사 기반 업데이트를 포함하는것 중 하나 또는 모두가 적용된, 방법."}
{"patent_id": "10-2025-7005729", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_22", "content": "제20항 또는 제21항에 있어서, 상기 AI 모델(110; 130)을 훈련하는 것은 상기 이미지 데이터(40; 170) 내의 상기 세장형 객체(41)에서 벗어난위치에서 시작하거나 도달할 때 상기 반복적 프로세스가 상기 세장형 객체(41)로 수렴하도록 하는 비행 정책을준수하도록 AI 모델(110; 130)을 훈련하는 것을 포함하는 방법."}
{"patent_id": "10-2025-7005729", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_23", "content": "제22항에 있어서, 상기 비행 정책의 수렴 거리는 상기 반복적인 프로세스가 상기 세장형 객체(41)로 얼마나 빨리 다시 수렴하는지를 결정하는, 방법."}
{"patent_id": "10-2025-7005729", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_24", "content": "제23항에 있어서, 상기 수렴 거리는 AI 모델(110; 130) 훈련 및/또는 추론 중에 변화하는 동적 파라미터;상기 수렴 거리는 AI 모델(110; 130) 훈련 중에 생리적 경계로부터의 거리의 함수로 설정되는 것 중 하나 또는모두가 적용된 방법."}
{"patent_id": "10-2025-7005729", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_25", "content": "제24항에 있어서, 상기 수렴 거리는 AI 모델(110; 130) 훈련 중 생리적 경계로부터의 거리의 함수로 설정되고,상기 수렴 거리는 상기 생리적 경계로부터의 거리에 대한 단조 증가 함수인, 방법."}
{"patent_id": "10-2025-7005729", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_26", "content": "신경 조직을 포함하는 조직의 3D 이미지 또는 2D 이미지 세트를 포함하는 의료 이미지 데이터(40; 170)를 수신하는 단계;상기 의료 이미지 데이터(40; 170)에서 세장형 객체(41)를 추적하기 위해 이전 청구항 중 하나의 방법을 수행하는 단계; 및일련의 점(60) 또는 중심선(50)의 시각적 표현;일련의 점(60) 또는 중심선(50)의 기계 판독가능한 표현;중심선(50)을 따라 위치한 일련의 점(60)에 따라 달라지는 제어 신호;중심선(50)을 따라 위치한 일련의 점(60)에 따라 달라지는 아키텍처를 갖는 기계 학습, ML, 모델(110; 130) 중하나이상을 출력하는 단계를 포함하는 의료 이미지 처리 방법."}
{"patent_id": "10-2025-7005729", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_27", "content": "제1항 내지 제25항 중 어느 한 항의 세장형 객체(41) 추적 방법을 수행하는 것을 포함하는 연결체학(connectomics) 방법.공개특허 10-2025-0044699-6-청구항 28 제27항에 있어서, 시냅스 인터페이스 분류기를 실행하는 단계와 연결체를 결정하기 위해 상기 세장형 객체 추적방법의 출력과 상기 시냅스 인터페이스 분류기의 출력을 최소한 사용하는 단계를 더 포함하는 연결체학 방법."}
{"patent_id": "10-2025-7005729", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_29", "content": "생검을 분석하는 방법은, 상기 생검의 이미지 데이터(40; 170)을 획득하는 단계;제1항 내지 제25항 중 어느 한 항의 방법을 사용하여 상기 이미지 데이터(40; 170)를 처리하는 단계; 및 인터페이스를 통해 상기 이미지 데이터(40; 170) 처리 결과를 출력하는 단계를 포함하는 방법."}
{"patent_id": "10-2025-7005729", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_30", "content": "물리적 자산을 제어하기 위한 신호 처리 논리를 생성하는 방법은, 제1항 내지 제25항 중 어느 하나의 상기 세장형 객체 추적 방법을 수행하는 단계;적어도 하나의 컴퓨팅 시스템으로 기계 학습, ML, 모델(110; 130) 아키텍처를 선택하거나 생성하고;상기 ML 모델(110; 130) 아키텍처를 갖는 ML 모델(110; 130)을 훈련하고;상기 훈련된 ML 모델(110; 130)을 신호 처리 논리로 제어 장치에 배포하여 실행하고;상기 이미지 데이터(40; 170)를 수집하는 이미지 수집 시스템(20)을 제어하기 위해 상기 세장형 객체 추적 방법의 출력을 사용하는 단계를 포함하는 방법."}
{"patent_id": "10-2025-7005729", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_31", "content": "이미지 데이터(40; 170)에서 세장형 객체(41)를 추적하기 위한 이미지 처리 시스템(30)은상기 이미지 데이터(40; 170)를 수신하도록 동작하는 인터페이스, 상기 이미지 데이터(40; 170)는 생물학적 또는 의학적 이미지 데이터(40; 170)이고, 및3차원 3D 공간에서 세장형 객체(41)의 세장형 객체(41)를 따라 일련의 점(60)의 위치를 결정하여 상기 이미지데이터(40; 170)에서 3D로 세장형 객체(41)를 추적하도록 동작하는 적어도 하나의 처리 장치를 포함하고,여기서 상기 일련의 점(60)의 위치를 결정하는 것은 반복적 프로세스를 포함하며, 상기 반복적 프로세스는 인공 지능인 AI 모델(110; 130)을 사용하여 세장형 객체(41)가 따라가는 방향에 따라 달라지는 조향 예측을 추론하고, 선택적으로 세장형 객체(41)의 중심선(50)은 상기 세장형 객체(41)를 따라 이전에 결정된 점에서 확장되고, 상기 AI 모델(110; 130)은 상기 이미지 데이터(40; 170)의 픽셀 또는 복셀 값을 기반으로 하는 AI 모델입력을 수신하도록 동작하는 입력 계층과 반복적 프로세스의 각 반복에서 조향 예측이거나 이를 나타내는 AI 모델(110; 130) 출력을 제공하도록 동작하는 출력 계층을 포함하고;적어도 상기 조향 예측을 사용하여 상기 일련의 점(60)의 다음 점, 상기 일련의 점(60)에서 이전에 결정된 점다음의 다음 점을 계산하고; 및종료 기준이 충족될 때까지 상기 추론 및 상기 계산 단계를 반복적으로 되풀이하여 상기 일련의 점(60)의 위치를 결정하는 것을 포함하는, 이미지 처리 시스템(30)."}
{"patent_id": "10-2025-7005729", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_32", "content": "제30항에 있어서, 상기 AI 모델은 상기 입력 계층, 복수의 컨볼루션 계층, 드롭아웃 계층 및 상기 출력 계층을 포함하는 컨볼루션 신경망(CNN),또는 공개특허 10-2025-0044699-7-순환 신경망(RNN)을 포함하고, 상기 반복 프로세스의 반복에서 상기 입력 계층에 입력되는 상기 AI 모델 입력은 상기 이미지 데이터(40; 170)로 표현되는 조직 볼륨의 서브 볼륨(91, 93; 172-174)을 나타내고, 여기서 상기 AI 모델 입력은상기 이미지 데이터(40; 170)의 서브 볼륨을 나타내는 픽셀 또는 복셀 값을 포함하거나상기 이미지 데이터(40; 170)의 서브 볼륨을 나타내는 픽셀 또는 복셀 값의 다변량 보간을 통해 얻고,상기 서브 볼륨(91, 93; 172-174)의 방향은 상기 반복 프로세스의 이전 반복에서 결정된 조종 예측에 따라 달라지는 이미지 처리 시스템."}
{"patent_id": "10-2025-7005729", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_33", "content": "제32항에 있어서, 상기 이미지 처리 시스템은 상기 조향 예측이 상기 세장형 객체 (41)의 중심선(50)의 2차 미분에 따라 달라지도록 동작하는 이미지 처리 시스템(30)."}
{"patent_id": "10-2025-7005729", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_34", "content": "제31항에 있어서, 상기 AI 모델은상기 입력 계층, 복수의 컨볼루션 계층, 드롭아웃 계층 및 상기 출력 계층을 포함하는 컨볼루션 신경망(CNN) 또는순환 신경망(RNN)이고,상기 반복 프로세스의 반복에서 상기 입력 계층에 입력되는 상기 AI 모델 입력은 상기 이미지 데이터(40; 170)로 표현되는 조직 볼륨의 서브 볼륨(91, 93; 172-174)을 나타내고;상기 조향 예측은 서브 볼륨과 관련하여 주어진 참조 프레임에 대한 곡률 값으로, 세장형 객체의 중심선(50)에위치한 일련의 점을 반복적으로 결정하기 위한 위치 오프셋을 생성하고; 및바로 앞의 반복 이후의 각 반복에서 처리되는 해당 서브 볼륨은 상기 바로 앞의 반복에서 얻은 조향 예측에서결정된 대로 세장형 개체의 확장 방향에 의해 결정되는 회전 방향을 갖도록 결정되도록 동작하는, 이미지 프로세스 시스템."}
{"patent_id": "10-2025-7005729", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "이미지 데이터에서 세장형 객체를 추적하기 위한 방법 및 시스템이 공개된다. 방법 및 시스템은 예를 들어 신경 돌기 추적에 동작할 수 있다. AI 모델이 조향 예측을 추론하는데 사용된다. 조향 예측은 세장형 객체의 중심선 에 있는 일련의 점들 중 다음 점을 결정하기 위해 진행된다."}
{"patent_id": "10-2025-7005729", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 이미지 처리 방법 및 시스템에 관한 것이다. 본 발명의 실시예는 3차원 조직 볼륨을 나타내는 이미지 데이터에서 신경 돌기와 같은 세장형(elongate) 객체를 추적하기 위한 방법 및 시스템에 관한 것이다."}
{"patent_id": "10-2025-7005729", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "뉴런의 연결선과 이들의 시냅스 연결을 밀도 높게 매핑하여 뇌의 연산을 더 깊이 이해하는 것은 고해상도 연결 학(connectomics)의 주요 목표이다. mm³ 크기의 3차원 전자현미경(3D-EM) 데이터셋을 획득하는 것은 가능하지 만, 축삭돌기(axon)과 척추 목(spine neck) 의 재구성은 여전히 상당히 어려운 과제로 남아 있다. 3D 이미지 데이터를 사람이 주석(annotation)을 달면 낮은 오류율을 얻을 수 있지만, 이는 종종 너무 많은 시간 이 소요된다. 따라서, 3차원(3D) 조직 볼륨을 나타내는 이미지 데이터에서 세장형 객체를 추적할 수 있는 컴퓨 터 지원 또는 컴퓨터 구현 기술이 필요하다. 중심선을 따라 희소한 흔적을 통한 신경 돌기 재구성(\"골격화 (skeletonization)\")은 주석 속도를 약 50배 증가시켰다(예: M. Helmstaedter 외, 2011. \"High-Accuracy Neurite Reconstruction for High-Throughput Neuroanatomy.\" Nature Neuroscience 14: 1081-88 참조). 이 접근법은 최근 대규모 재구성 작업의 기반이 되고 있다(예: K. Eichler 외, 2017. \"The Complete Connectome of a Learning and Memory Centre in an Insect Brain.\" Nature 548: 175-82 참조). 스켈레톤 (skeleton) 재구성은 자동으로 얻어진 세분화(segmentations)와 결합하여 볼륨 재구성을 생성하였다(예: Helmstaedter 외, 2013. \"Connectomic Reconstruction of the Inner Plexiform Layer in the Mouse Retina.\" Nature 500: 168-74; Dorkenwald 외, 2017. \"Automated Synaptic Connectivity Inference for VolumeElectron Microscopy.\" Nature Methods 14: 435-42; Staffler 외, 2017. \"SynEM, Automated Synapse Detection for Connectomics.\" ELife 6(July): e26414 참조). 주석 작성자에게 3D-EM 볼륨의 자기 중심적 관점(\"비행 모드\")이 제공되는 사용자 인터페이스를 사용하여 신경 돌기를 골격화함으로써 추가적인 속도 향상이 달성되었다(예: Boergens 외, 2017. \"WebKnossos: Efficient Online 3D Data Annotation for Connectomics.\" Nature Methods 14: 691-94). 다른 접근법은 신경 돌기의 자동 재구성과 그에 따른 재구성 오류 감지를 통해 사람의 주석이 필요한 위치의 수를 줄이는 것을 목표로 한다 (참조: S.M. Plaza, 2016. \"Focused Proofreading to Reconstruct Neural Connectomes from EM Images at Scale.\" Deep Learning and Data Labeling for Medical Applications, Springer, Cham., 249-58; Y. Meirovitch 외, 2016. \"A Multi-Pass Approach to Large-Scale Connectomics.\" ArXiv E-Prints, 12월. http://arxiv.org/abs/1612.02120; D. Rolnick 외, 2017. \"Morphological Error Detection in 3D Segmentations.\" ArXiv E-Print. https://arxiv.org/pdf/1705.10882.pdf; J. Zung 외, 2017. \"An Error Detection and Correction Framework for Connectomics.\" NIPS, 6818-29; K. Dmitriev 외, 2018. \"Efficient Correction for EM Connectomics with Skeletal Representation.\" In British Machine Vision Conference (BMVC). http://bmvc2018.org/contents/papers/0064.pdf; A. Motta 외, 2019. \"Dense Connectomic Reconstruction in Layer 4 of the Somatosensory Cortex.\" Science, Vol. 366, Issue 6469, p. eaay3134). 추가적으로, 객체를 추적하기 위한 예시적인 기술은 다음 연구들에 공개되어 있다: Jelmer M. Wolrterink et al.: \"Coronary artery centerline extraction in cardiac CT angiography using a CNN-based orientation classifier\", MEDICAL IMAGE ANALYSIS, OXFORD UNIVERSITY PRESS, OXOFRD, GB, vol. 51, 22 October 2018 (2018-10-22), pages 46-60, ISSN:1361-8415,DOI:10.1016/J.MEDIA.2018.10.005; Rouchen Gao et al.: \"Joint Coronary Centerline Extraction And Lumen Segmentation From Ccta Using Cnntracker And Vascular Graph Convolutional Network\", 2021 IEEE 18TH INTERNATIONAL SYMPOSIUM ON BIOMEDICAL IMAGING (ISBI), IEEE, 13 April 2021 (2021-04-13), pages 1897-1901, DOI: 10.1109/ISBI4821120219433764; and Tianhong Dai et al.: \"Deep Reinforcement Learning for Subpixel Neural Tracking\", Proceedings of Machine Learning Research, 2019, pages 130-150, http://proceedings.mlr.press/v102/dai19a/dai19a.pdf."}
{"patent_id": "10-2025-7005729", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "이미지 처리의 향상된 기술에 대한 필요가 여전히 남아 있다. 특히, 신경 돌기와 같은 세장형 객체를 계산적으 로 효율적인 방식으로 및/또는 낮은 오류율로 추적할 수 있는 기술에 대한 필요가 남아 있다."}
{"patent_id": "10-2025-7005729", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 실시예에 따르면, 독립항에 언급된 방법 및 시스템이 제공된다. 종속항은 바람직한 실시예를 정의한 다. 이미지 데이터가 생물학적 또는 의료적 이미지 데이터인 경우, 이미지 데이터에서 세장형 객체를 추적하는 방법 은 이미지 처리 시스템을 통해 3차원 3D 공간에서 세장형 객체를 따라 일련의 점의 위치를 결정하여 이미지 데 이터에서 3D로 세장형 객체를 추적하는 것을 포함할 수 있다. 일련의 점은 세장형 객체의 중심선의 근사치를 따 라 위치하도록 결정될 수 있다. 일련의 점들의 위치를 결정하는 것은 반복적인 프로세스를 포함한다. 반복적인 프로세스는 AI(인공 지능) 모델을 사용하여 이전에 결정된 점에서 세장형 객체(예: 중심선 또는 중심 선의 근사치)가 세장형 객체를 따라(예: 중심선을 따라 또는 중심선의 근사치) 확장되는 방향에 따라 달라지는 (그리고 이를 나타낼 수 있는) 조향 예측을 추론하는 것을 포함할 수 있으며, AI 모델은 이미지 데이터의 픽셀 또는 복셀 값을 기반으로 하는 AI 모델 입력을 수신하도록 동작하는 입력 계층과 반복적인 프로세스의 각 반복 에서 조향 예측 또는 조향 예측을 나타내는 AI 모델 출력을 제공하도록 동작하는 출력 계층을 포함한다. 반복적인 프로세스는 적어도 조향 예측을 사용하여 일련의 점들의 다음 점 즉, 일련의 점들에서 이전에 결정된 점 다음의 다음 점을 계산하는 것을 포함할 수 있다. 반복적인 프로세스는 종료 기준이 충족될 때까지 추론 및 계산 단계를 반복적으로 되풀이하는 것을 포함할 수 있으며, 이를 통해 일련의 점을 결정할 수 있다. 바람직한 실시예에 따르면, AI 모델은 입력 계층, 복수의 컨볼루션 계층, 하나의 드롭아웃 계층 또는 여러 개의 드롭아웃 계층, 및 출력 계층을 포함하는 컨볼루션 신경망(CNN) 또는 순환 신경망(RNN)을 포함할 수 있으며, 여 기서 반복적인 프로세스의 반복에서 입력 계층에 입력되는 AI 모델 입력은 이미지 데이터로 표현된 조직 볼륨의 서브 볼륨을 나타내고, 여기서 AI 모델 입력은 이미지 데이터의 서브 볼륨을 나타내는 픽셀 또는 복셀 값을 포 함하거나 이미지 데이터의 서브 볼륨을 나타내는 픽셀 또는 복셀 값의 다변수 보간을 통해 얻어지고, 여기서 서 브 볼륨의 방향은 반복적인 프로세스의 이전 반복에서 결정된 조향 예측에 따라 달라진다. 바람직한 실시예에 따르면, 조향 예측은 세장형 객체의 2차 미분, 예를 들어 세장형 객체의 중심선에 따라 달라 질 수 있다. 다른 바람직한 실시예에 따르면, AI 모델은 입력 계층, 복수의 합성곱 계층, 하나의 드롭아웃 계층 또는 여러 개의 드롭아웃 계층, 및 출력 계층을 포함하는 컨볼루션 신경망(CNN)이거나 순환 신경망(RNN)일 수 있으며, 여 기서 반복적인 프로세스의 반복에서 입력 계층에 입력되는 AI 모델 입력은 이미지 데이터로 표현된 조직 볼륨의 서브 볼륨을 나타내고, 조향 예측은 서브 볼륨과 관련하여 주어진 참조 프레임에 대한 곡률 값으로, 세장형 객 체의 중심선에 위치한 일련의 점을 반복적으로 결정하기 위한 위치 오프셋을 생성하고, 바로 이전 반복에 이어 지는 각 반복에서 처리되는 해당 서브 볼륨은 바로 이전 반복에서 얻은 조향 예측에서 결정된 세장형 객체의 확 장 방향에 의해 결정되는 회전 방향을 갖도록 결정된다. 방법은 그래픽 사용자 인터페이스 또는 데이터 인터페이스를 통해 처리한 이미지의 결과를 출력하는 것을 포함 할 수 있다. 일련의 점들 중 다음 점을 결정하는 것은 조향 예측을 적분하는 것을 포함할 수 있다. 조향 예측은 세장형 객체의 중심선의 2차 미분에 따라 달라질 수 있다. 반복적인 프로세스의 반복에서 입력 계층에 입력되는 AI 모델 입력은 이미지 데이터에 의해 표현된 조직 볼륨의 서브 볼륨을 나타낼 수 있다. 서브 볼륨은 반복적인 프로세스의 이전 반복에서 결정된 이전 조향 예측 및/또는 반복적인 프로세스의 이전 반 복에서 결정된 점에 따라 달라질 수 있다. 서브 볼륨의 방향은 이전 조향 예측에 따라 달라질 수 있고/또는 여러 방향에 대한 AI 모델 예측의 불확실성에 따라 달라질 수 있다. 서브 볼륨의 방향은 세장형 객체가 서브 볼륨 내에서 또는 서브 볼륨에서 확장되는 방향에 따라 달라질 수 있다. 서브 볼륨의 방향은 세장형 객체가 서브 볼륨 내에서 또는 서브 볼륨에서 확장되는 방향과 대략적으로 정렬될 수 있다. 서브 볼륨의 중심은 오프셋에 의해 이전에 결정된 점에 대해 상대적으로 이동할 수 있으며, 선택적으로 오프셋 은 이전 반복에서 결정된 조향 예측에 따라 달라진다. 이 방법은 AI 모델 입력을 결정하기 위해 이미지 데이터의 픽셀이나 복셀 값을 다변량 보간(예: 평균화)하는 것 을 포함할 수 있다. 다변량 보간은 이미지 데이터의 픽셀 또는 복셀 그리드에 대해 상대적으로 기울어지거나 오프셋된 그리드에 보 간된 픽셀 또는 복셀 값으로 AI 모델 입력을 생성하기 위해 픽셀 또는 복셀 값의 가중화된 평균을 계산하는 것 을 포함할 수 있다. 다변량 보간은 삼선형(trilinear) 투영을 포함할 수 있다. 방법은 반복적인 절차의 초기화를 수행하는 것을 포함할 수 있다. 초기화는 초기 방향이 사전에 사용 가능한지 여부에 따라 달라질 수 있다. 초기 방향을 사용할 수 없는 경우, 해당 방법은 반복 프로세스의 초기 반복에 사용할 초기 방향을 결정하는 단 계를 포함할 수 있다. 초기 방향을 결정하는 것은 다양한 방향에 대한 AI 모델 예측의 불확실성 추정치를 결정하고 불확실성 추정치가 최소인 다양한 방향 중에서 방향을 선택하는 것을 포함할 수 있다. 불확실성 추정치는 몬테카를로(Monte-Carlo) 드롭아웃을 사용하여 결정될 수 있다. AI 모델은 CNN(convolutional neural network)을 포함할 수 있다. AI 모델은 RNN(recurrent neural network)을 포함할 수 있다. AI 모델은 입력 계층, 복수의 컨볼루션 계측, 하나 또는 여러 개의 드랍 아웃 계층 및 출력 계층을 포함할 수 있다. 출력 계층은 선형 계층일 수 있다. 복수의 컨볼루션 계층은 하나 또는 여러 개의 스트라이드(strided) 컨볼루션 계층을 포함할 수 있다. AI 모델은 완전 컨볼루션 네트워크(fully convolutional network)이거나 완전 컨볼루션 네트워크를 포함할 수 있다. AI 모델은 풀링 계층, 어텐션 모듈, 셀프 어텐션 모듈, 아트러스(atrous) 컨볼루션, 정규화 계층, 배치 정규화 계층, 변환기, 순환 계층 중 하나 또는 여러 개로 구성될 수 있다. AI 모델은 하나 또는 여러 개의 비선형성을 포함할 수 있다. AI 모델은 ELU(exponential linear units)를 포함할 수 있다. AI 모델은 ReLU(rectified linear units)를 포함할 수 있다. AI 모델은 SELU(Scaled Exponential Linear units)를 포함할 수 있다. AI 모델은 GELU(Gaussian Error Linear Unit)를 포함할 수 있다. 이미지 데이터는 조직의 체적(volumetric) 표현을 나타낼 수 있다. 이미지 데이터는 3D 이미지 또는 2D 이미지의 셋을 포함할 수 있다. 방법은 이미지 데이터를 획득하는 것을 더 포함할 수 있다. 이미지 데이터는 전자 현미경을 사용하여 획득될 수 있다. 이미지 데이터는 광학(optical) 현미경, 예를 들어 광학(light) 현미경을 사용하여 획득될 수 있다. 이미지 데이터는 양전자 방출 단층촬영(PET), 자기공명영상(MR), 엑스선 단층촬영 또는 다른 의료 영상 방식을 사용하여 획득될 수 있다. 세장형 객체는 신경 돌기일 수 있다. 세장형 객체는 혈관일 수 있다. 세장형 객체는 국부적으로, 원통형으로 중심선을 따라 확장되는 표면을 가질 수 있다. 방법은 축색돌기를 추적하기 위해 사용될 수 있다. 세장형 객체는 축색 돌기(axon)일 수 있다. 세장형 객체는 척추 목일 수 있다. 방법은 복수의 축색 돌기 및/또는 수상 돌기를 추적하기 위해 병렬로 및/또는 순차적으로 여러 차례 수행될 수 있다. 방법은 AI 모델을 훈련하는 단계를 포함할 수 있다. AI 모델은 지도 학습을 사용하여 훈련될 수 있다. AI 모델을 훈련하는 것은 AI 모델 파라미터의 경사 기반 업데이트를 포함할 수 있다. AI 모델을 훈련하는 것은 이미지 데이터의 초기 위치가 중심선을 벗어나 시작하는 경우 반복적인 프로세스가 세 장형 객체(예: 중심선을 따라 또는 중심선의 근사치)로 수렴하도록 하는 비행 정책을 준수하도록 AI 모델을 훈 련하는 것을 포함할 수 있다.비행 정책(flight policy)의 수렴 거리는 반복적인 프로세스가 중심선으로 얼마나 빨리 수렴되는지를 결정할 수 있다. 수렴 거리는 AI 모델 훈련 및/또는 추론 중에 변경되는 동적 파라미터일 수 있다. 수렴 거리는 AI 모델 훈련 중에 생리적 경계로부터의 거리의 함수로 설정될 수 있다. 수렴 거리는 생리적 경계로부터의 거리에 따른 단순 증가 함수일 수 있다. 이 방법은 일련의 점 또는 중심선에 대한 하나 이상의 시각적 표현, 일련의 점 또는 중심선에 대한 기계가 읽을 수 있는 표현, 중심선을 따라 위치한 일련의 점에 따라 달라지는 제어 신호, 예측된 제어 신호의 불확실성, 반 복적인 프로세스를 종료한 중지 기준 또는 기준에 대한 표현을 출력하는 단계를 포함할 수 있다. 출력은 그래픽 사용자 인터페이스와 같은 사용자 인터페이스 또는 데이터 인터페이스를 통해 수행될 수 있다. 의료 영상 방법 또는 의료 이미지 처리 방법은 신경 조직을 포함하는 조직의 3D 영상 또는 2D 이미지 세트를 포 함하고 조직 볼륨을 나타내는 의료 이미지 데이터를 수신하는 단계, 의료 이미지 데이터에서 세장형 객체를 추 적하기 위한 이미지 처리 방법을 수행하는 단계, 및 일련의 점 또는 중심선의 시각적 표현 중 하나 또는 여러 개를 출력하는 단계, 일련의 점 또는 중심선의 기계가 읽을 수 있는 표현, 중심선을 따라 위치한 일련의 점에 따라 달라지는 제어 신호, 중심선을 따라 위치한 일련의 점에 따라 달라지는 아키텍처를 갖는 기계 학습(ML) 모 델을 포함한다. 연결체학(connectomics) 방법은 세장형 객체를 추적하는 방법을 수행하는 것을 포함한다. 생검 샘플을 분석하는 방법은 생검 샘플의 이미지 데이터를 획득하고, 이미지 데이터를 처리하는 방법을 사용해 상기 이미지 데이터를 처리하고, 및 인터페이스를 통해 이미지 데이터 처리 결과를 출력하는 것을 포함할 수 있 다. 생검 샘플을 분석하는 방법은 연결체(connectome)의 일부를 결정하기 위해 수행될 수 있다. 생검 샘플은 동물이나 인간의 신체에 이식되지 않는 샘플이다. 물리적 자산을 제어하기 위한 신호 처리 논리를 생성하는 방법은 적어도 하나의 컴퓨팅 시스템에 의해 머신 러 닝, ML 모델 아키텍처를 선택하거나 생성하고, ML 모델 아키텍처를 갖는 ML 모델을 훈련하고, 훈련된 ML 모델을 실행을 위한 제어 장치에 신호 처리 논리로 배포하는 세장형 객체 추적 방법의 출력을 사용하여 이미지 데이터 를 처리하는 방법을 수행하는 것을 포함할 수 있다. 이미지 데이터에서 세장형 객체를 추적하기 위한 이미지 처리 시스템은 이미지 데이터를 수신하도록 동작하는 인터페이스를 포함할 수 있으며, 이미지 데이터는 생물학적 또는 의학적 이미지 데이터일 수 있다. 이미지 처리 시스템은 3차원 3D 공간에서 세장형 객체를 따라 일련의 점의 위치를 결정하고(예: 중심선 또는 중 심선의 근사치를 따라) 이미지 데이터에서 3D로 세장형 객체를 추적하도록 동작하는 적어도 하나의 처리 장치를 포함할 수 있으며, 여기서 일련의 점의 위치를 결정하는 것은 반복적 프로세스를 포함할 수 있다. 반복적인 프로세스는 인공 지능(AI) 모델을 사용하여 이전에 결정된 세장형 객체를 따르는 점으로부터 세장형 객체가 확장되는 방향에 따라 달라지는(그리고 이를 나타낼 수 있는) 조향 예측을 추론하는 단계를 포함할 수 있으며, AI 모델은 이미지 데이터의 픽셀 또는 복셀 값을 기반으로 하는 AI 모델 입력을 수신하도록 동작하는 입력 계층과 반복적인 프로세스의 각 반복에서 조향 예측이거나 조향 예측을 나타내는 AI 모델 출력을 제공하도 록 동작하는 출력 계층을 포함한다. 반복적인 프로세스는 조향 예측을 사용하여 일련의 점 중 다음 점, 즉 일련의 점 중 이전에 결정된 점 다음의 다음 점을 계산하는 것을 포함할 수 있다. 반복적인 프로세스는 종료 기준이 충족될 때까지 추론 및 계산 단계를 반복적으로 되풀이하는 것을 포함할 수 있으며, 이를 통해 일련의 점들을 결정할 수 있다. 바람직한 실시예에 따르면, 이미지 처리 시스템은 AI 모델이 입력 계층, 복수의 컨볼루션 계층, 하나의 드롭아 웃 계층 또는 여러 개의 드롭아웃 계층, 및 출력 계층을 포함하는 컨볼루션 신경망(CNN) 또는 순환 신경망(RN N)을 포함할 수 있도록 동작할 수 있으며, 여기서 반복적인 프로세스의 반복에서 입력 계층에 입력되는 AI 모델 입력은 이미지 데이터로 표현된 조직 볼륨의 서브 볼륨을 나타내고, 여기서 AI 모델 입력은 이미지 데이터의 서 브 볼륨을 나타내는 픽셀 또는 복셀 값을 포함하거나 이미지 데이터의 서브 볼륨을 나타내는 픽셀 또는 복셀 값의 다변수 보간을 통해 얻어지고, 여기서 서브 볼륨의 방향은 반복적인 프로세스의 이전 반복에서 결정된 조향 예측에 따라 달라진다. 바람직한 실시예에 따르면, 조향 예측은 세장형 객체의 2차 도함수, 예를 들어 세장형 객체의 중심선에 따라 달 라질 수 있다. 다른 바람직한 실시예에 따르면, 이미지 처리 시스템은 AI 모델이 입력 계층, 복수의 컨볼루션 계층, 하나의 드 롭아웃 계층 또는 여러 개의 드롭아웃 계층, 및 출력 계층을 포함하는 컨볼루션 신경망(CNN)이거나 순환 신경망 (RNN)일 수 있도록 동작할 수 있으며, 여기서 반복적인 프로세스의 반복에서 입력 계층에 입력되는 AI 모델 입 력은 이미지 데이터로 표현된 조직 볼륨의 서브 볼륨을 나타내고, 조향 예측은 서브 볼륨과 관련하여 제공된 참 조 프레임에 대한 곡률 값으로, 세장형 객체의 중심선에 위치한 일련의 점을 반복적으로 결정하기 위한 위치 오 프셋을 생성하고, 바로 앞의 반복에 이어지는 각 반복에서 처리되는 해당 서브 볼륨은 바로 앞의 반복에서 얻은 조향 예측에서 결정된 세장형 객체의 확장 방향에 의해 결정되는 회전 방향을 갖도록 결정된다. 이미지 처리 시스템은 실시예에 따른 방법을 수행하도록 동작할 수 있다. 이미지 처리 시스템은 이미지 데이터를 캡처하도록 동작하는 이미지 획득 시스템을 포함할 수 있다. 이미지 획득 시스템은 3D전자 현미경 또는 광학 현미경을 수행하도록 동작할 수 있다. 이미지 처리 시스템은 그래픽 사용자 인터페이스 또는 데이터 인터페이스를 통해 이미지 처리 결과를 출력하도 록 동작할 수 있다. 이미지 처리 시스템은 일련의 점 중 다음 점을 결정하는 것이 조향 예측을 통합하는 것을 포함할 수 있도록 동 작할 수 있다. 이미지 처리 시스템은 반복 프로세스의 반복에서 입력 계층에 입력되는 AI 모델 입력이 이미지 데이터로 표현되 는 조직 볼륨의 서브 볼륨을 나타낼 수 있도록 동작할 수 있다. 이미지 처리 시스템은 서브 볼륨이 반복적인 프로세스의 이전 반복에서 결정된 이전 조향 예측 및/또는 반복적 인 프로세스의 이전 반복에서 결정된 점에 따라 달라질 수 있도록 동작할 수 있다. 이미지 처리 시스템은 서브 볼륨의 방향이 이전 조향 예측에 따라 달라질 수 있도록 동작할 수 있다. 이미지 처리 시스템은 서브 볼륨의 방향이 세장형 객체가 서브 볼륨 내에서 또는 서브 볼륨에서 확장되는 방향 에 따라 달라질 수 있도록 동작할 수 있다. 이미지 처리 시스템은 서브 볼륨의 방향이 세장형 객체가 서브 볼륨 내에서 또는 서브 볼륨에서 확장되는 방향 과 대략적으로 정렬되도록 동작할 수 있다. 이미지 처리 시스템은 서브 볼륨의 중심이 오프셋에 의해 이전에 결정된 점에 대해 상대적으로 이동될 수 있도 록 동작할 수 있다. 이미지 처리 시스템은 오프셋이 이전 반복에서 결정된 조향 예측에 따라 달라질 수 있도록 동작할 수 있다. 이미지 처리 시스템은 AI 모델 입력을 결정하기 위해 이미지 데이터의 픽셀이나 복셀 값을 다변량 보간(예: 평 균화)하는 데 사용할 수 있다. 이미지 처리 시스템은 다변량 보간이 AI 모델 입력을 생성하기 위해 이미지 데이터의 픽셀 또는 복셀 그리드에 대해 상대적으로 기울어지거나 오프셋된 그리드 상의 보간된 픽셀 또는 복셀 값으로 픽셀 또는 복셀 값의 가중 평균화하는 것을 포함하도록 동작할 수 있다. 이미지 처리 시스템은 이미지 데이터의 픽셀 또는 복셀 그리드에 대해 상대적으로 기울어지거나 오프셋된 그리 드 상의 픽셀 또는 복셀 값을 결정하기 위해 투영을 수행하도록 동작할 수 있다. 이미지 처리 시스템은 반복적 절차의 초기화를 수행하도록 동작할 수 있다. 이미지 처리 시스템은 초기 조향 예측이 사전에 사용 가능한지 여부에 따라 초기화가 달라질 수 있도록 동작할 수 있다. 이미지 처리 시스템은 초기 방향을 사용할 수 없는 경우 반복적인 프로세스의 초기 반복에 사용할 초기 방향을 결정하도록 동작할 수 있다. 이미지 처리 시스템은 초기 방향을 결정하는 것이다양한 방향에 대한 불확실성 추정치를 결정하는 것과 불확실 성 추정치가 최소가 되는 다양한 방향 중에서 방향을 선택하는 것을 포함할 수 있도록 동작할 수 있다. 이미지 처리 시스템은 몬테카를로 드롭아웃을 사용하여 불확실성 추정치를 결정할 수 있도록 동작할 수 있다. AI 모델은 CNN(convolutional neural network)을 포함할 수 있다. AI 모델은 RNN(recurrent neural network)을 포함할 수 있다. AI 모델은 입력 계층, 복수의 컨볼루션 계층, 하나 또는 복수의 드랍 아웃 계층 및 출력 계층을 포함할 수 있다. 출력 계층은 선형 계층일 수 있다. 복수의 컨볼루션 계층은 하나 또는 여러 개의 스트라이드(stride)된 컨볼루션 계층을 포함할 수 있다. AI 모델은 완전 컨볼루션 네트워크(fully convolutional network)이거나 완전 컨볼루션 네트워크를 포함할 수 있다. AI 모델은 풀링 계층, 어텐션 모듈, 셀프 어텐션 모듈, 아트러스(atrous) 컨볼루션, 정규화 계층, 배치 정규화 계층, 변환기, 순환 계층 중 하나 또는 여러 개로 구성될 수 있다. AI 모델은 ELU(exponential linear units)를 포함할 수 있다. AI 모델은 ReLU(rectified linear units)를 포함할 수 있다. AI 모델은 SELU(Scaled Exponential Linear units)를 포함할 수 있다. AI 모델은 GELU(Gaussian Error Linear Unit)를 포함할 수 있다. 이미지 데이터는 조직의 체적(volumetric) 표현을 나타낼 수 있다. 이미지 데이터는 3D 이미지 또는 2D 이미지의 셋을 포함할 수 있다. 이미지 처리 시스템은 이미지 데이터를 획득하도록 동작할 수 있다. 이미지 데이터는 전자 현미경을 사용하여 획득될 수 있다. 이미지 데이터는 광학(optical) 현미경, 예를 들어 광학(light) 현미경을 사용하여 획득될 수 있다. 이미지 데이터는 양전자 방출 단층촬영(PET), 자기공명영상(MR), 엑스선 단층촬영 또는 다른 의료 영상 방식을 사용하여 획득될 수 있다. 세장형 객체는 신경 돌기일 수 있다. 세장형 객체는 혈관일 수 있다. 세장형 객체는 국부적으로 원통형으로 중심선을 따라 확장되는 표면을 가질 수 있다. 이미지 처리 시스템은 AI 모델을 훈련하도록 동작할 수 있다. AI 모델은 지도 학습을 사용하여 훈련될 수 있다. 이미지 처리 시스템은 AI 모델을 훈련하는 데 AI 모델 파라미터의 경사 기반 업데이트를 포함하도록 동작할 수 있다. 이미지 처리 시스템은 AI 모델을 훈련하는 것이 이미지 데이터의 초기 위치가 중심선에서 벗어나 시작하는 경우 반복적인 프로세스가 중심선으로 수렴되도록 하는 비행 정책을 준수하도록 AI 모델을 훈련하는 것을 포함하도록 동작할 수 있다. 이미지 처리 시스템은 비행 정책의 수렴 거리가 반복적인 프로세스를 얼마나 빠르게 중심선으로 다시 수렴하는 지 결정하도록 동작할 수 있다. 이미지 처리 시스템은 AI 모델 훈련 중에 수렴 거리가 변경되는 동적 파라미터가 되도록 동작할 수 있다. 이미지 처리 시스템은 AI 모델 훈련 중에 수렴 거리가 생리적 경계로부터의 거리의 함수로 설정되도록 동작할 수 있다.이미지 처리 시스템은 수렴 거리가 생리학적 경계로부터 거리에 따른 단순 증가 함수가 되도록 동작할 수 있다. 이미지 처리 시스템은 일련의 점 또는 중심선의 시각적 표현, 일련의 점 또는 중심선의 기계가 읽을 수 있는 표 현, 그리고 중심선을 따라 위치한 일련의 점에 따라 달라지는 제어 신호 중 하나 또는 여러 개를 출력하도록 동 작할 수 있다. 이미지 처리 시스템은 출력을 수행하기 위한 그래픽 사용자 인터페이스와 같은 사용자 인터페이스나 데이터 인 터페이스를 포함할 수 있다. 또한, AI 모델을 훈련하는 훈련 방법이 개시되는데, AI 모델은 조직 부피를 나타내는 이미지 데이터의 픽셀 또 는 복셀 값을 기반으로 하는 AI 모델 입력을 수신하도록 동작하는 입력 계층 및 조향 예측이거나 조향 예측을 나타내는 AI 모델 출력을 제공하도록 동작하는 출력 계층을 포함하고, 조향 예측은 세장형 객체(예: 중심선을 따라 또는 중심선의 근사치)가 확장되는 방향에 따라 달라진다(그리고 이를 나타낼 수 있음). 훈련 방법은 세장형 객체의 중심선이 확장하는 방향을 예측하는 목적으로 AI 모델을 훈련하는 것을 포함할 수 있다. 훈련 방법은 세장형 객체의 중심선이 확장하는 방향의 미분(예: 1차, 2차 또는 고차 미분)을 출력하는 목적으로 AI 모델을 훈련하는 단계를 포함할 수 있다. 훈련 방법은 경사 기반 지도 학습 방법일 수 있다. 훈련 방법에서, AI 모델은 지도 학습을 사용하여 훈련될 수 있다. 훈련 방법은 AI 모델 변수의 경사 기반 업데이트를 포함할 수 있다. 훈련 방법은 이미지 데이터에서 중심선을 벗어난 위치에서 시작하거나 해당 위치에 도달할 때 반복적인 프로세 스가 중심선으로 수렴되도록 하는 비행 정책을 준수하도록 AI 모델을 훈련하는 것을 포함할 수 있다. 비행 정책의 수렴 거리는 반복적인 프로세스가 얼마나 빨리 중심선으로 수렴되는지를 결정할 수 있다. 수렴 거리는 AI 모델 훈련 및/또는 추론 중에 변경되는 동적 파라미터일 수 있다. 수렴 거리는 장애물로부터의 거리에 따라 달라질 수 있다. 장애물은 세포 경계와 같은 생리적 경계일 수 있다. 수렴 거리는 AI 모델 훈련 중 생리적 경계로부터의 거리의 함수로 설정될 수 있다. 수렴 거리는 생리적 경계로부터의 거리의 단순 증가 함수일 수 있다. 입력 계층에 입력되는 AI 모델 입력은 훈련 데이터로 표현된 조직 볼륨의 서브 볼륨을 나타낼 수 있다. 훈련 방 법은 AI 모델 입력을 결정하기 위해 이미지 데이터의 픽셀 또는 복셀 값의 다변량 보간을 포함할 수 있다. 다변량 보간은 이미지 데이터의 픽셀 또는 복셀 그리드에 대해 상대적으로 기울어지거나 오프셋된 그리드 상에 서 보간된 픽셀 또는 복셀 값으로 AI 모델 입력을 생성하기 위해 픽셀 또는 복셀 값의 가중화된 평균을 계산하 는 단계를 포함할 수 있다. 훈련 방법에서 AI 모델은 컨볼루션 신경망(CNN)을 포함할 수 있다. 훈련 방법에서 AI 모델은 순환 신경망(RNN)을 포함할 수 있다. 훈련 방법에서 AI 모델은 입력 계층, 복수의 컨볼루션 계층, 하나 또는 복수의 드랍 아웃 계층 및 출력 계층을 포함할 수 있다. 훈련 방법에서 출력 계층은 선형 계층일 수 있다. 훈련 방법에서 복수의 컨볼루션 계층은 하나 또는 여러 개의 스트라이드(stride)된 컨볼루션 계층을 포함할 수 있다. 훈련 방법에서 AI 모델은 완전 컨볼루션 네트워크(fully convolutional network)이거나 완전 컨볼루션 네트워크 를 포함할 수 있다. 훈련 방법에서 AI 모델은 풀링 계층, 어텐션 모듈, 셀프 어텐션 모듈, 아트러스(atrous) 컨볼루션, 정규화 계층, 배치 정규화 계층, 변환기, 순환 계층 중 하나 또는 여러 개로 구성될 수 있다. 훈련 방법에서 AI 모델은 하나 또는 여러 개의 비선형성을 포함할 수 있다. 훈련 방법에서 AI 모델은 ELU(exponential linear units)를 포함할 수 있다. 훈련 방법에서 AI 모델은 ReLU(rectified linear units)를 포함할 수 있다. 훈련 방법에서 AI 모델은 SELU(Scaled Exponential Linear units)를 포함할 수 있다. 훈련 방법에서, AI 모델은 GELU(Gaussian Error Linear Unit)를 포함할 수 있다. 훈련 방법에서, 이미지 데이터는 조직의 체적 표현을 나타낼 수 있다. 훈련 방법에서, 이미지 데이터는 3D 이미지 또는 2D 이미지의 셋을 포함할 수 있다. 훈련 방법에서, 이미지 데이터는 전자 현미경(EM) 이미지일 수 있다. 훈련 방법에서, 이미지 데이터는 3D EM 이미지일 수 있다. 훈련 방법에서, 이미지 데이터는 X 선 단층촬영 이미지일 수 있다. 훈련 방법에서, 이미지 데이터는 광학(optical) 현미경 예를 들어, 광학(light) 현미경 이미지일 수 있다. 훈련 방법에서, 이미지 데이터는 양전자 방출 단층촬영(PET), 자기공명(MR) 영상 또는 기타 의료 이미지 데이터 일 수 있다. 훈련 방법에서, AI 모델에서 훈련되는 세장형 객체는 신경 돌기일 수 있다. 훈련 방법에서, AI 모델에서 훈련되는 세장형 객체는 혈관일 수 있다. 훈련 방법에서, AI 모델에서 훈련되는 세장형 객체는 국부적으로 원통형으로 중심선을 따라 확장되는 표면을 가 질 수 있다. 다른 실시 예에 따르면, 이미지 데이터에서 객체를 추적하는 방법이 제공된다. 이 방법은 이미지 데이터에서 객 체를 추적하기 위해 객체를 따라 일련의 점을 결정하는 것을 포함한다. 일련의 점을 결정하는 것은 반복적 프로세스를 포함할 수 있다. 반복적 프로세스는: 인공 지능(AI) 모델을 사용하여 조향 예측을 추론하고, 여기서 AI 모델은 이미지 데이터의 픽셀 또는 복셀 값을 기반으로 하는 AI 모델 입력을 수신하도록 동작하는 입력 계층과 반복적 프로세스의 각 반복에서 조향 예측이거 나 조향 예측을 나타내는 AI 모델 출력을 제공하도록 동작하는 출력 계층을 포함하고; 적어도 조향 예측을 사용하여 일련의 점의 다음 점, 일련의 점에서 이전에 결정된 점의 다음인 다음 점을 계산 하고; 및 종료 기준이 충족될 때까지 추론 및 계산 단계를 되풀이하여 반복하는 것을 포함할 수 있다. 이미지 데이터는 N차원 이미지 데이터일 수 있으며, N은 정수이다. N은 최소 2, 최소 3, 또는 최소 4일 수 있다. 객체는 N-D 차원에서 추적될 수 있으며, 여기서 D는 0보다 크거나 같고 N보다 작은 정수이다. 이미지 데이터의 차원 중 하나는 시간 축에 해당할 수 있다. 일련의 점 중 다음 점을 결정하는 것은 조향 예측을 적분하는 것을 포함할 수 있다. 조향 예측을 적분하는 것은 비숍(Bishop) 기준 프레임의 곡률을 적분하는 것을 포함할 수 있다. 조향 예측은 객체의 중심선의 2차 미분과 관련이 있다. 반복적인 프로세스의 반복에서 입력 계층에 입력되는 AI 모델 입력은 이미지 데이터의 서브 볼륨을 나타낼 수 있다. 서브 볼륨은 반복적인 프로세스의 하나 또는 여러 번의 이전 반복에서 결정된 위치 및/또는 방향 및/또는 조향 예측에 따라 달라질 수 있다.서브 볼륨의 방향은 이전 조향 예측에 따라 달라질 수 있다. 서브 볼륨의 중심은 오프셋에 의해 이전에 결정된 점에 대해 상대적으로 이동될 수 있다. 오프셋은 이전 반복에서 결정된 조향 예측에 따라 달라질 수 있다. 이 방법은 AI 모델 입력을 결정하기 위해 이미지 데이터의 픽셀 또는 복셀 값의 다변수 보간을 더 포함할 수 있 다. 다변량 보간은 이미지 데이터의 픽셀 또는 복셀 그리드에 대해 상대적으로 기울어지거나 오프셋된 그리드 상에 서 보간된 픽셀 또는 복셀 값으로 AI 모델 입력을 생성하기 위해 픽셀 또는 복셀 값의 가중화된 평균을 계산하 는 단계를 포함할 수 있다. 다변량 보간은 다중선형 투영을 포함할 수 있다. 이 방법은 반복적인 프로세스의 초기화를 수행하는 것을 더 포함할 수 있다. 초기화는 초기 방향이 사용 가능한지 여부에 따라 달라질 수 있다. 초기 방향을 사용할 수 없는 경우, 이 방법은 반복적인 프로세스의 초기 반복에서 사용할 초기 방향을 결정하는 것을 포함할 수 있다. 초기 방향을 결정하는 것은 다양한 방향에 대한 예측의 불확실성 추정치를 결정하는 것을 포함할 수 있다. 초기 방향을 결정하는 것은 해당 예측에서 불확실성 추정치가 최소인 다양한 방향 중에서 방향 및 조향 예측을 포함할 수 있다. 불확실성 추정치는 몬테카를로 드롭아웃을 사용하여 결정할 수 있다. AI 모델은 컨볼루션 신경망( CNN) 또는 순환 신경망( RNN)을 포함할 수 있다. AI 모델은 입력 계층, 복수의 컨볼루션 계층, 드롭아웃 계층 또는 여러 드롭아웃 계층, 출력 계층을 포함할 수 있다. AI 모델은 풀링 계층, 어텐션 모듈, 셀프 어텐션 모듈, 아트러스(atrous) 컨볼루션, 정규화 계층, 배치 정규화 계층, 변환기, 순환 계층 중 하나 또는 여러 개를 포함할 수 있다. 다음 중 하나, 여러 개 또는 전부가 적용될 수 있다: 출력 계층은 선형 계층이다; 다수의 컨볼루션 계층은 하나 또는 여러 개의 스트라이드 컨볼루션 계층을 포함한다; AI 모델은 완전 컨볼루션 네트워크이거나 이를 포함한다; AI 모델은 하나 또는 여러 개의 비선형성을 포함한다; AI 모델은 ELU(exponential linear units)를 포함한다; AI 모델은 ReLU(rectified linear units)를 포함한다; AI 모델은 SELU(Scaled Exponential Linear units)를 포함한다; AI 모델은 GELU(Gaussian Error Linear Unit)를 포함한다. 객체는 이미지 데이터의 시간 축을 따라 확장된 객체일 수 있다. 객체는 비디오 내의 객체일 수 있다. 객체는 일련의 이미지 프레임을 통해 추적할 객체일 수 있다. 객체는 생물학적, 특히 생리학적 객체일 수 있다. 객체는 사람 또는 동물의 신경 돌기일 수 있다. 객체는 사람 또는 동물의 혈관일 수 있다. 객체는 인프라스트럭처, 특히 유틸리티 시스템의 자산일 수 있다. 객체는 담수 또는 하수 시스템의 튜브일 수 있다. 객체는 산업 공장의 배관일 수 있다. 객체는 국부적으로 원통형 방식으로 객체의 중심 축 주위로 확장되는 표면을 가질 수 있다. 이 방법은 AI 모델을 훈련하는 것을 더 포함할 수 있다. AI 모델은 지도 학습을 사용하여 훈련될 수 있다. AI 모델을 훈련하는 것은 AI 모델 파라미터의 경사 기반 업데이트를 포함할 수 있다. AI 모델을 훈련하는 것은 이미지 데이터에서 객체 밖에 있는 위치에서 시작하거나 도달할 때 반복적 프로세스가 객체로 수렴되도록 하는 비행 정책을 준수하도록 AI 모델을 훈련하는 것을 포함할 수 있다. 비행 정책의 수렴 거리는 반복적 프로세스가 얼마나 빠르게 객체로 다시 수렴하는지를 결정할 수 있다. 수렴 거리는 AI 모델 훈련 중에 변경될 수 있는 동적 파라미터일 수 있다. 수렴 거리는 AI 모델 훈련 중에 이미지 데이터로 표현된 경계로부터의 거리의 함수로 설정될 수 있다. 수렴 거리는 경계로부터의 거리의 단순 증가 함수일 수 있다. 이미지 처리 방법은 이미지 데이터를 수신 및/또는 획득하고 객체 추적 방법을 수행하는 것을 포함할 수 있다. 이미지 처리 방법은 일련의 점 또는 중심선의 시각적 표현; 일련의 점 또는 중심선의 기계가 읽을 수 있는 표현; 중심선을 따라 위치한 일련의 점에 따라 달라지는 제어 신호; 중심선을 따라 위치한 일련의 점에 따라 달 라지는 아키텍처를 갖는 기계 학습(ML) 모델 중 하나 또는 여러 개의 출력을 포함할 수 있다. 이미지 데이터는 시간 순차적 이미지 프레임의 시계열을 포함할 수 있다. 객체를 추적하는 것은 시공간 좌표계에서 시간 축을 따라 물리적 객체를 추적하는 것을 포함할 수 있다. 제어 방법은 객체 추적 방법 또는 이미지 처리 방법을 포함하고, 객체 추적 방법의 결과에 따라 하나 이상의 제 어 가능한 자산을 제어하는 것을 더 포함한다. 또한 이미지 데이터를 수신하기 위한 인터페이스와 객체 추적 방법 또는 이미지 처리 방법을 수행하도록 동작하 는 하나 이상의 회로(예: 프로세서 세트 또는 기타 집적 회로)를 포함하는 처리 시스템이 개시된다. 또한, 제어 가능한 자산(예: 기계 또는 액추에이터) 적어도 하나와 처리 시스템을 포함하는 시스템이 개시되는 데, 여기서 제어 가능한 자산은 처리 시스템에 의해 생성된 제어 명령 또는 제어 신호에 반응한다. 본 발명의 실시예에 따른 방법 및 시스템에 의해 다양한 효과 및 이점이 달성된다. 이 방법 및 시스템은 낮은 오류율로 세장형 객체를 추적할 수 있게 한다. 이 방법 및 시스템은 연결체학과 같은 목적을 위해 신경 조직 이 미지와 같은 이미지의 자동 분석을 용이하게 한다. 이 방법과 시스템을 신경 돌기를 기존의 자동 또는 반자동 기술과 동등하거나 더 뛰어난 정확도로 추적할 수 있 게 하며, 인간 주석자의 정확도에 근접한다. 이 방법과 시스템은 수상 돌기 추적에만 적용할 수 있는 것이 아니 라, 예를 들어 수상 돌기보다 추적하기 어려운 축삭 돌기와 척추 목도 추적할 수 있다. 본 발명의 추가적인 측면에 따르면, 또한, 슬라이싱 방향을 따라 이미지 데이터의 슬라이스의 로컬 재정렬을 수 행하기 위해 실행되는 슬라이싱 방향을 따라 복수의 슬라이스에 대한 슬라이스 간 이동 벡터를 결정하는 단계, 슬라이스 간의 유효한 슬라이스 간 이동 벡터를 식별하는 단계, 유효한 슬라이스 간 이동 벡터를 사용하여 국부 적으로 재정렬된 서브 볼륨을 생성하는 단계를 포함할 수 있는 로컬 재정렬을 수행하도록 동작하는 이미지 처리 방법 및 이미지 처리 시스템도 공개되어 있다. 국부적으로 재정렬된 서브 볼륨은 컨볼루션 신경망 또는 순환신경망의 입력 계층이나 컨볼루션 신경망 또는 순 환신경망에서 처리되기 전에 재정렬된 서브 볼륨을 전처리하는 필터 또는 기타 전처리와 같은 AI 모델 입력에 공급될 수 있다. 슬라이스 간 이동(shift) 벡터를 결정하는 것은 슬라이스의 자기(auto) 상관관계와 교차(cross) 상관관계를 결 정하는 것을 포함할 수 있다. 슬라이스 간 이동 벡터 및/또는 그 유효성을 결정하는 것은 첫 번째 임계값 기준에 따라 상관 관계 가중 (correlation-weighted) 이동 벡터의 평균과 표준 편차를 결정하는 것을 포함할 수 있다. 유효한 슬라이스 간 이동 벡터를 식별하는 것은 결정된 자기 상관 관계가 첫 번째 기준(예: 원하는 이동, 예를 들어 0 이동에서 피크를 갖는 것)을 충족하는지 확인하는 것을 포함할 수 있다. 유효한 슬라이스 간 이동 벡터를 식별하는 것은 결정된 자기 상관 피크가 두 번째 기준을 충족하는 표준 편차를 갖는지 확인하는 것을 포함할 수 있다(예: 두 번째 임계값 기준을 충족하는 표준 편차를 갖는 것, 즉 특정 픽셀 수보다 적거나 같음).유효한 슬라이스 간 이동 벡터를 식별하는 것은 두 개의 연속적인 자기 및/또는 교차 상관 피크의 조합이 세 번 째 기준을 충족하는지 확인하는 것을 포함할 수 있다(예를 들어, 세 번째 임계값 기준을 충족하는 경우, 세 번 째 임계값 기준은 선택적으로 주변 자기 및/또는 교차 상관에 따라 달라질 수 있음). 유효한 슬라이스 간 이동 벡터를 식별하는 것은 결정된 교차 상관 관계가 두 슬라이스의 자기 상관 관계에 따라 달라지는 첫 번째 교차 상관 관계 기준을 충족하는지 확인하는 것을 포함할 수 있다(예: 언급된 자기 상관 관계 기준이 두 슬라이스 모두에 유효한 경우). 유효한 슬라이스 간 이동 벡터를 식별하는 것은 완전히 상관된 세기에 대한 예상 교차 상관 관계 값으로 정규화 된 결정된 교차 상관 관계가 두 번째 교차 상관 관계 기준(예: 완전히 상관된 세기에 대한 예상 교차 상관 관계 값으로 정규화된 교차 상관 관계의 피크가 또 다른 임계값 기준을 충족하는 경우, 예: 네 번째 임계값 이상)을 충족하는지 확인하는 것을 포함할 수 있다. 유효한 슬라이스 간 이동 벡터를 식별하는 것은 이동 벡터의 표준 편차가 세 번째 교차 상관 기준(예: 표준 편 차가 다섯 번째 임계값 이하)을 충족하는지를 검증하는 것을 포함할 수 있다. 유효한 이동 벡터를 사용한다는 것은 슬라이스 간 이동 벡터가 유효하지 않은 것으로 간주되더라도 재정렬할 하 나 또는 여러 슬라이스를 식별하고, 이 경우 이러한 하나 또는 여러 슬라이스의 이웃과 관련된 유효한 이동 벡 터에서 이동 벡터를 계산하는 것을 포함할 수 있다. 유효한 이동 벡터를 사용하는 것은 국부적으로 재정렬되고 삼선형 보간된 서브 볼륨을 생성하는 것을 포함할 수 있다. 국부적으로 재정렬되고 삼선형 보간된 서브 볼륨을 생성하는 것은 floor또는 ceil 연산을 수행하는 것을 포함할 수 있다. 국부적으로 재정렬되고 삼선형 보간된 서브 볼륨을 생성하는 것은 주요 축을 따라 선형 보간 시퀀스로 삼선형 보간을 수행하는 것을 포함할 수 있다. 선형 보간 시퀀스는 제1 차원을 따라 네 개의 선형 보간, 제2 차원을 따라 두 개의 선형 보간, 세 번째 차원을 따라 하나의 선형 보간을 포함할 수 있다. 국부적으로 재정렬된 서브 볼륨은 혈관 또는 신경 돌기와 같은 세장형 객체를 3D로 추적하도록 처리될 수 있다. 로컬 재정렬 기술은 세장형 객체를 추적하는 방법과 연관하여(예를 들어, 그 일부로서) 사용될 수 있지만, 이에 국한되지는 않는다. 이러한 로컬 재정렬 기술은 특히 효율적인 방식으로 슬라이스를 공통 기준 프레임에 참조하 는 것을 다룬다."}
{"patent_id": "10-2025-7005729", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "실시예는 도면을 참조하여 자세히 설명될 것이다. 도면에서 동일하거나 유사한 구성 요소는 동일하거나 유사한 참조 번호로 지정된다. 실시예는 신경 돌기, 축색 돌기 및 척추 목과 같은 특정 생리적 대상을 참조하여 자세히 설명되지만, 여기에 공 개된 기술은 이에 국한되지 않는다. 여기에 개시된 바와 같이 동작하는 방법 및 시스템은 혈관 또는 기타 세장 형 관내강(lumen) 벽과 같은 다양한 생리적 대상을 추적하기 위한 이미지 데이터를 처리하는 데 사용될 수 있다. 여기에 공개된 바와 같이 동작하는 방법 및 시스템은 원시 이미지 데이터에서 주석이 달린 이미지 데이터 를 생성하는 데에도 사용될 수 있다. 실시예는 3차원 전자 현미경(3D EM) 이미징 및 3D EM 이미지와 같은 특정 이미징 기술이나 특정 이미지 데이터 를 참조하여 자세히 설명되지만, 해당 방법 및 시스템은 광학 현미경, 자기 공명 영상, X선 홀로그램 나노 단층 촬영 등과 같은 다른 이미징 기술을 사용하여 획득한 이미지를 처리하는 데에도 사용될 수 있다. 세장형 객체 추적(Elongate Object Tracing) 여기에 공개된 시스템 및 방법은 이미지 데이터에서 세장형 객체(예: 신경 돌기, 이에 국한되지 않음)를 추적하 는 데 동작한다. 이미지 데이터는 3D 이미지 데이터이거나 시간 축을 축 중 하나로 갖는 시공간 좌표계의 이미 지 데이터일 수 있다. 이미지 데이터는 생물학적 또는 의학적 이미지 데이터일 수 있다. 이미지 데이터는 시간 순서대로 촬영될 수 있는 일련의 프레임을 포함할 수 있다. 여기에 공개된 기술은 다른 이미지 데이터에도 적용 가능하다. 시스템 및 방법은 세장형 객체의 중심선에 있을 것으로 예측되는 일련의 점을 결정하여 객체를 추적할 수 있다. 시스템 및 방법은 이미지 데이터에서 사전 객체 인식을 요구하지 않고도 이미지 데이터의 복셀 또는 픽셀 값을 처리하도록 동작할 수 있다. 여기에 공개된 시스템 및 방법은 (a) 이미지 데이터의 서브 볼륨을 선택하고, (b) 서브 볼륨에서 세장형 객체가 확장되는 방향에 대한 정보를 결정하고, (c) 중심 축을 따라 위치한 추가 점을 결정하기 위해 방향을 처리하여 객체 추적을 수행할 수 있다. 이러한 단계는 반복적으로 되풀이될 수 있다. 반복에서 처리되는 서브 볼륨은 이전 반복에서 결정된 객체의 확장 방향에 따라 방향이 달라질 수 있다. 따라서 방향은 자율 주행 또는 비행 기술과 유사하게 분석 프로세스를 조종한다. 따라서 세장형 객체의 중심 축이 확장 되는 방향을 여기에서 \"비행 방향\"이라고 한다. 이 방향은 여기에 공개된 기술이 동작하는 경로를 결정한다. 비행 방향의 변화는 최소한 조향 예측에 의해 결정된다. 조향 예측은 비행 방향의 미분(예: 1차 또는 2차 또는 고차 미분)을 정의하거나 이와 관련될 수 있다. 여기서 사용되는 용어 \"조향 예측\"은 세장형 객체가 세장형 객 체를 따라 이전에 결정된 점에서 어떻게 확장되는지에 따라 달라지는 양을 의미하며, 및/또는 여기서 공개되는 반복 기법이 어떻게(특히 어떤 서브 볼륨 방향 및/또는 위치) 진행될지 결정하는 양을 의미한다. 다음에 분석되는 서브 볼륨의 방향은 비행 방향 및/또는 조향 예측에 따라 설정될 수 있다. 조향 예측의 결정은 AI 모델을 사용할 수 있다. AI 모델은 이미지 데이터에서 결정된 복셀 값을 수신하도록 동 작하는 입력 계층을 가질 수 있다. AI 모델 입력은 이미지 데이터에서 가져올 수 있거나, 보다 일반적으로는 서 브 볼륨의 임의의 위치와 방향을 수용하기 위해 이미지 데이터의 인접한 복셀을 보간하여 얻을 수 있다. AI 모 델은 조향 예측을 출력하도록 동작하는 출력 계층을 가질 수 있다. 정확도와 안정성을 높이기 위해 AI 모델은 훈련 이미지 데이터에서 세장형 객체의 중심선을 따라 위치한 위치뿐만 아니라 훈련 이미지 데이터에서 세장형 객체의 중심선 밖에 위치한 위치에서도 훈련된 AI 모델일 수 있다. 따라서 추론 중에도 중심선으로의 수렴이 보 장될 수 있다. 중심선을 따라 새로운 점을 결정하는 것은 조향 예측의 적분을 사용하여 수행할 수 있다. 적분은 예를 들어, 조 향 예측이 세장형 객체의 중심선 방향의 고차 미분과 관련된 경우 여러 개의 후속 적분을 포함할 수 있다. 이 시스템과 방법은 개별 복셀의 친화도(affinity) 예측에 독립적이며 이미지 데이터의 명시적 볼륨 분할이 필 요하지 않다. 대신 이 시스템과 방법은 신경선과 같은 세장형 객체의 중심선을 따르는 문제를 직접 해결하기 위 해 동작한다. 이 시스템과 방법은 대규모 연결체 재구성을 용이하게 한다. 또한 컴퓨터적으로 효율적이기 때문 에 건강과 질병에서, 회로 장애 스크리닝과 임상 셋팅에서 병리 조직의 생검 분석을 위해 동물과 인간의 뇌에서 연결체를 획득하는 데 필요한 리소스 소비가 용이해진다. 이 시스템과 방법은 축삭 돌기 비행 모드 추적을 모방하는 AI 모델을 훈련하여 3D EM 데이터에서 자동 축삭 돌 기 재구성을 위한 접근 방식을 제공한다. 이 시스템과 방법은 컨볼루션 신경망을 사용할 수 있다. 컨볼루션 신 경망의 세부 사항은 예를 들어 Y. LeCun et al. 1989. \"Backpropagation Applied to Handwritten Zip Code Recognition.\" Neural Computation 1: 541-51에 설명되어 있다. 이 시스템과 방법은 M. Januszewski et al. 2018 \"High-Precision Automated Reconstruction of Neurons with Flood-Filling Networks.\" Nature Methods. https://doi.org/10.1038/s41592-018-0049-4의 컨볼루션 신경망 기반 기술과 비교했을 때 다양한 차이점과 효과를 제공한다. 이 시스템과 방법은 신경 돌기와 같은 세장형 객체의 (대략적인) 중심선을 결정하고 반복을 통해 중심선을 골격 적으로 재구성한다. 서브 볼륨 선택(예: 서브 볼륨 방향)과 문제 공식화는 분석이 세장형 축에 맞춰지도록 보장 한다. 정렬을 유지하려면 중심선이 직선(서브 볼륨 방향을 따라)으로 가는 편차만 예측해야 한다. 즉, 여기에 공개되는 시스템 및 방법은 반복적 프로세스의 여러 반복 각각에서 세장형 객체의 국소적 방향을 고 려하는 방식으로 방향이 지정된 서브 볼륨을 분석한다. 중심선이 직선이면 조향 예측은 0이다. 중심선이 직선에서 벗어나면 조향 예측은 예를 들어 현재 위치의 신경 돌기에 대한 포물선 근사를 통해 이 편차를 포착할 수 있다. 비교를 위해, M. Januszewski et al. 2018의 Flood-Filling Networks(FFN)의 서브 볼륨 \"High-Precision Automated Reconstruction of Neurons with Flood-Filling Networks.\" Nature Methods. https://doi.org/10.1038/s41592-018-0049-4는 이미지 데이터 세트의 주요 축을 따라 배향되므로 신경 돌기의 주요 축/중심선 방향을 포착하지 못한다. 이러한 기존 기술은 주요 축 또는 중심선을 포착하거나 재구성에 사용 하는 메커니즘을 제공하지 않는다. 대신 플러드 필링 네트워크(FFN)는 각 복셀의 친화도(affinity)를 예측하여 계산상 복잡성과 계산상 비용을 증가시킨다. 따라서 플러드 필링 네트워크는 여기에 공개된 기술보다 계산상 비 용이 더 많이 든다. 플러드 필링 네트워크는 정수 좌표로 제한되는 반면, 여기에 공개된 기술은 이미지 데이터 의 다변수 보간과 공간적으로 변하는 좌표 프레임을 기준으로 한 연속적인 문제 공식화를 제공하는데, 이는 입력 및/또는 출력을 위한 연속 좌표에 더 쉽게 적용할 수 있다. 여기에 공개된 기술의 경우, AI 모델은 예를 들어 신경 돌기-중심 및 신경 돌기-정렬 3D-EM 서브 볼륨에서 중심 선의 국소적 연속을 예측하는 작업에 대해 훈련된다. 이를 통해 오류율의 직접적인 최적화가 가능해지며, 이는 기존의 자동화된 방법에서는 거의 진전이 없었던 지표이며, 일반적인 신경 돌기 직경보다 훨씬 큰 3D-EM 볼륨에 서 연결체를 추출하는 데 있어서 복셀 기반 지표를 능가하는 지표이다. 추론 과정에서 시스템과 방법은 조향 예측을 새로운 위치와 방향으로 통합하여 동작하며, 이를 반복 적용하면 사람의 주석으로 생성한 골격과 유사한 방문 위치의 흔적이 생성된다. 세장형 객체(예: 신경 돌기)의 방향성과 연속성은 문제 공식화에 직접 통합될 수 있다. 테스트는 여기에 공개된 기술이 이전 방법에 비해 상당히 낮은 계산 비용으로 더 낮은 해상도의 데이터에서도 낮은 오류율을 산출한 것을 보여준다. 또한, 이 방법과 시스템은 분할에 대한 필요성을 없애고 사전 분할 없이 3D 이미지 데이터에서 동작할 수 있다. 도 1은 시스템 10의 블록도이다. 시스템 10은 3D 이미지 데이터(예: 3D-EM 이미지 데이터)에서 세장형 객체(예: 신경 돌기)를 추적하도록 동작한다. 시스템은 이미징 시스템20을 포함한다. 이미징 시스템 20은 3D EM 이미징 시스템일 수 있다. 이미징 시스템 20 은 소스 21을 포함한다. 소스 21는 예를 들어 전자빔을 출력하도록 동작할 수 있는 전자 소스를 포함할 수 있다. 이미징 시스템 20은 검출기 22를 포함한다. 검출기 22는 샘플(예: 생검 샘플) 내의 생리학적 객체에서 산 란, 반사 또는 굴절된 전자를 감지하도록 동작될 수 있다. 이미징 시스템 20은 재구성 전 이미지 정렬을 위한 이미지 정렬 구성요소 23을 포함할 수 있다. 이미징 시스템 20은 로컬 재정렬을 수행하도록 동작할 수 있다. 로컬 재정렬은 이미지 정렬 구성 요소 23에 의 해 수행될 수 있거나, 이미징 시스템 20은 이미지 정렬 구성 요소 23에 더하여 두 번째 로컬 이미지 재정렬 구 성 요소를 실행하도록 동작할 수 있다. 이미징 시스템 20(특히 로컬 이미지 재정렬 구성 요소)은 글로벌 이미지 좌표계에 매핑하기 위해 로컬 재정렬 및 비정렬을 수행하도록 동작할 수 있다. 예를 들어, 이미징 시스템 20은 P.H. Li et al., \"Automated Reconstruction of a Serial-Section EM Drosophila Brain with Flood-Filling Networks and Local Realignment.\" Preprint. https://doi.org/10.1101/605634의 방법, 특히 이 논문의 도 3과 관련하여 설명된 기술을 수행하도록 동작할 수 있다. 로컬 재정렬은 아래에 더 자세히 설명된 기술을 사용하여 수행될 수 있다. 이미징 시스템 20은 이미지 재구성 회로 24를 포함할 수 있다. 이미지 재구성 회로 24는 샘플의 3D 이미지 데이 터를 나타내는 복셀을 계산하도록 동작할 수 있다. 3D 이미지 데이터 40은 이미지 처리 시스템 30에 제공될 수 있다. 3D 이미지 데이터 대신 또는 이에 추가하여, 2차원(2D) 이미지 또는 투영 시리즈와 같은 체적 조직 표현 의 다른 형태가 사용될 수 있다. 이러한 표현의 한 예는 X선 홀로그램 나노 토모그래피(예를 들어, A.T. Kuan et al.의 기술, \"Dense neuronal reconstruction through X-ray holographic nano-tomography\", Nature Neuroscience volume 23, pages 1637-1643 을 사용하여 수행할 수 있음)이다. 이미지 처리 시스템 30은 하나 또는 여러 개의 처리 회로 31을 포함한다. 처리 회로 31은 FPGA(Field Programmable Gate Array), ASIC(Application Specific Integrated Circuit), 컨트롤러, 프로세서, 초전도 회 로, 양자 비트(qubit) 처리 회로와 같은 집적 회로를 포함하여 하나 또는 여러 개의 회로를 포함할 수 있지만 이에 국한되지 않는다. 처리 회로(들) 31은 조직의 체적 표현 40을 통해 세장형 객체(예: 신경 돌기, 이에 국한되지 않음)를 따라가는 세장형 객체 추적을 수행하도록 동작할 수 있다. 세장형 객체의 중심선의 한 위치에서 시작하여, AI 모델 32는 각각 이미지 데이터 40의 서브 체적에 따라 달라지는(그리고 이를 표현할 수 있는) AI 모델 입력으로 공급될 수 있다. AI 모델 32는 이 이미지 데이터에 반응하여 세장형 객체가 이미 알려진 점에서 확장되는 방향을 출력하도 록 훈련된다. 이 방향은 추적이 계속되는 방향을 결정하므로 조향 예측이라고도 한다. 조향 예측을 기반으로 중 심선을 따라 다음 점(이미 알려진 점에 인접한 점)이 계산된다. 이는 조향 예측 처리 33에 의해 수행될 수 있는 적분에 의해 수행될 수 있다. AI 모델에 의한 조향 예측의 결정과 조향 예측 처리에 의한 중심선을 따라 새로운 점의 결정은 반복되어 중심선에 위치한 일련의 점을 생성할 수 있다. 여기에 공개된 방식으로 시스템 또는 방법을 동작시키는 데에는 이미지 데이터 40의 분할이 필요하지 않다. 3D에서 중심선을 따라 위치한 점 각각을 결정하는 것은 이미지 데이터 40로 표현된 3D 볼륨 내에서 점의 위치를 결정하는 것을 포함한다. 점을 결정하는 것은 이미지 데이터 40로 표현된 볼륨에서 점의 세 좌표를 모두 지정할 수 있는 정보를 결정하는 것을 포함한다. 점을 결정하는 것은 점의 세 개의 직교 좌표를 결정하는 것을 포함할 수 있으며, 3D에서 점의 위치를 지정하는 데 많은 동등한 공식을 사용할 수 있다는 것을 이해해야 한다. 이미지 처리의 결과는 이미지 처리 시스템 30에 의해 출력될 수 있다. 이미지 처리 시스템 30은 세장형 객체의 일련의 점 및/또는 중심선의 그래픽 표현을 출력하기 위한 그래픽 사용자 인터페이스(GUI)를 포함할 수 있다. GUI는 세장형 객체의 중심선의 시각화를 출력하도록 동작할 수 있다. 대안적으로 또는 추가적으로, 이미지 처리 시스템 30은 출력 인터페이스 34를 포함할 수 있다. 출력 인터페이스 34는 세장형 객체 추적의 결과에 따라 달 라지는 기계 판독 가능 데이터를 출력하도록 동작할 수 있다. 기계 판독 가능 데이터는 세장형 객체 추적의 결 과에 따라 달라지는 제어 신호를 포함할 수 있다. 기계 판독 가능 데이터는 예를 들어 신경 과학에서 영감을 받 은 기계 학습(ML) 모델 설계 또는 훈련을 위해 신경 돌기 추적의 결과를 사용할 때 세장형 객체 추적의 결과에 따라 달라지는 제어 논리를 포함할 수 있다. 이미지 처리 시스템 30은 또한 GUI 30를 제어하여 사용자가 객체 추적을 위한 시작점을 입력할 수 있도록 동작 할 수 있다. 이미지 처리 시스템 30은 GUI 30를 제어하여 사용자가 선택적으로 객체 추적을 위한 시작 방향을 입력할 수 있도록 동작할 수 있다. 초기 방향에 대한 지식은 선택 사항이며, 여기에서 더 자세히 설명한다. 초 기 방향은 예를 들어 몬테카를로 드롭아웃에서 얻은 불확실성 추정치를 사용하여 자동으로 결정될 수 있다. 세장형 객체 추적은 다음에서 하나의 세장형 객체 추적과 관련하여 추가로 설명되지만, 이 시스템 및 방법은 복 수의 세장형 객체를 추적하는 데 동작한다. 이 기술은 복수의 세장형 객체 및/또는 객체의 복수의 세장형 부분 및/또는 세장형 객체의 복수의 부분에도 적용할 수 있다. 이는 병렬 또는 순차적인 방식으로 수행될 수 있다. 예를 들어, 여기에 공개된 이미지 처리 기술의 복수의 인스턴스를 인스턴스화하여 복수의 세장형 객체를 병렬로 동시에 추적할 수 있다. 대안적으로 또는 추가적으로, 시스템 및 방법은 서로 다른 세장형 객체에 대해 여기에 공개된 기술을 여러 번 반복할 수 있다. 이는 원하는 각 세장형 객체에 대한 3D 추적이 결정될 때까지 수행될 수 있다. 예를 들어, 복수의(예: 100개 이상 또는 1000개 이상) 신경 돌기, 축삭 돌기 및/또는 신경 척추 목의 3D 추적이 추적될 수 있다. 여기에 공개된 방법은 연결체학에 사용하기에 적합하지만 이에 국한되지는 않는다. 도 2는 이미지 데이터로 표현된 볼륨 40과 그 안에 확장된 세장형 객체 41를 보여준다. 여기에 공개된 시스템 및 방법은 세장형 객체 41의 중심선을 추적하도록 동작한다. 시스템과 방법은 서브 볼륨의 선택에 따른 조향 예 측, 조향 예측을 업데이트 하기 위해 서브 볼륨에서 이미지 데이터의 AI 모델 처리, 및 세장형 객체 41의 중심 선을 따르기 위한 조향 예측의 통합을 사용할 수 있다. 시스템 및 방법은 신경 돌기 추적을 위해 이러한 기술을 채용할 수 있지만, 이에 국한되지는 않는다. 도 3은 세장형 객체의 중심선 50을 나타낸다. 여기에 공개된 기술은 신경 돌기에만 적용할 수 있는 것이 아니라 혈관, 호흡기의 내강 등과 같은 다른 객체에도 더 광범위하게 적용할 수 있다. 이 기술은 또한 시공간 좌표계의 추적에도 적용할 수 있다(물리적 객체로 시간 축을 따라 세장형 경로를 추적하는 것이 반드시 물리적으로 세장 형 것은 아님). 이 기술은 또한 복수의 세장형 객체 및/또는 객체의 복수의 세장형 부분 및/또는 세장형 객체의 복수의 부분에도 적용할 수 있다. 여기서 개시된 방법 및 시스템은 국부적으로 원통형 외형을 갖는 객체(예: 세장형 객체의 중심선 50)를 추적하 는 데 사용될 수 있다. 용어 \"국부적으로 원통형\"은 세장형 객체의 외벽이 원통 세그먼트 42, 43에 의해 국부적 으로 근사될 수 있는 기하학을 지칭하는 데 사용된다. 다양한 원통 세그먼트 42, 43의 방향은 3D 공간에서 서로 에 대해 상대적으로 기울어질 수 있다. 원통 세그먼트 42, 43의 직경은 중심선 50을 따라 변할 수 있다(신경 돌 기의 경우에도 일반적으로 마찬가지임). 도 4는 여기에 공개된 방법 및 시스템의 동작을 설명한다. 프로세싱은 이미지 데이터와 추적할 세장형 객체에 위치한 초기 점 61으로 시작한다. 초기 점 61은 추적할 객체를 식별하기 위해 사용자가 설정할 수도 있다. 대안 적으로 자동 객체 인식이 객체의 시작 점 61을 식별하기 위해 채용될 수도 있다. 시작 점 61에서 세장형 객체의 방향을 지정하는 초기 비행 방향 70은 사용자 입력을 통해 수신되거나, 예를 들어 다른 방향에 대한 예측 추정 의 불확실성을 지정하는 예측 불확실성(몬테카를로 드롭아웃에서 얻을 수 있지만 이에 국한되지 않음)을 사용하 여 시스템에 의해 자동으로 추정될 수 있다. 시스템 및 방법은 다음과 같이 동작한다. - 시작 점 61 주변(그러나 일반적으로 시작 점 61에서 다소 오프셋된 첫 번째 중심을 갖는)에 위치한 첫 번째 서브 볼륨을 식별한다, - 첫 번째 서브 볼륨으로부터 이미지 정보를 처리하여 첫 번째 조향 예측 71을 결정한다, 및 - 적어도 첫 번째 조향 예측 71을 처리하여(예: 적분을 사용하여) 다음을 결정한다. ㆍ시작점 61 이후의 첫 번째 점 62을 제공하는 위치 오프셋 72, ㆍ후속 반복을 위한 새로운 서브 볼륨 방향(도시되지 않음). 이러한 단계는 시작 점 61과 시작 방향 70을 입력으로 활용할 수 있다. 이후 프로세스는 반복적인 방식으로 되풀이될 수 있다. 예를 들어, 시스템 및 방법은 다음과 같이 동작할 수 있 다. - 첫 번째 점 62 주변(그러나 일반적으로 첫 번째 점 62에서 다소 오프셋된 두 번째 중심을 갖는)에 위치한 두 번째 서브 볼륨을 식별한다, - 두 번째 서브 볼륨으로부터 이미지 정보를 처리하여 두 번째 조향 예측을 결정한다, 및 - 적어도 두 번째 조향 예측을 처리하고(예: 적분을 사용하여) 위치 오프셋 73과 새로운 서브 볼륨 방향(도시되 지 않음)을 결정하여 첫 번째 점 62 이후의 두 번째 점 63을 결정한다. 이 과정은 반복적인 추론에 의해 중심선 50에 위치한 일련의 60개의 점을 결정하기 위해 반복적인 방식으로 되 풀이될 수 있다. 이런 식으로, 추가적인 조향 예측이 추가적인 위치 오프셋 74, 75, 79와 일련 60의 추가적인 점 64, 65를 결정할 수 있다. 반복 프로세스의 반복에서 이미지 데이터 40로 표현된 볼륨의 서브 볼륨 76이 결정된다. 서브 볼륨 76에는 이전 반복에서 결정된 현재 점 65이 포함된다. 서브 볼륨 76은 이전 반복에서 결정된 이전 조향 예측에 따른 방향 (orientation)을 갖는다. 서브 볼륨 76의 이미지 데이터는 AI 모델에서 처리되어 반복 프로세스의 현재 반복에 대한 조향 예측 78을 결정한다. 현재 점 65 다음에 오는 다음 점과 방향은 현재 반복에 대한 조향 예측 78을 사 용하여 예를 들어 반복(예: 순간 비행 방향 77에 비례하는 벡터를 현재 점 65에 추가하여 다음 점을 결정하고 조향 예측에 비례하는 벡터를 순간 비행 방향/서브 볼륨 방향 77에 추가하여 다음 비행 방향/서브 볼륨 방향을 결정하거나, 또는 이전에 결정된 일련의 조향 예측에서 외삽(extrapolation)하기 위해 더 복잡한 외삽 기술을 사용함)에 의해 결정된다. 이전에 논의한 바와 같이, 서브 볼륨 76에 포함된 이미지 데이터의 분석은 조향 예측 78을 제공하며, 이를 통합하여 세장형 객체를 계속 추적하기 위한 다음 위치 오프셋 79을 결정한다. 따라서 여기에 공개된 방법 및 시스템은 추적 프로세스가 자동으로 중심선을 따라 조향되고, 각 단계에서 분석 되는 시야(즉, 서브 볼륨)가 중심선의 추정 접선을 따라 지시되는 접근 방식을 채용한다. 세장형 객체의 연속성 은 프로세스에서 자동으로 구축된다. 이 프로세스는 자율 주행(하지만 3D)에서 원하는 경로를 추적하는 것과 유 사하다. 도 5는 방법 80의 흐름도이다. 방법 80은 이미지 처리 시스템에 의해 자동으로 수행될 수 있다. 방법 80은 중심 선 50을 따라 일련의 점들 60을 결정한다. 81 단계에서, AI 모델 입력은 이미지 데이터와 현재 점(point)으로부터 결정된다. 첫 번째 반복에서, 현재 점은 사용자 입력에 의해 설정될 수 있는 시작 점 61이다. 이후의 각 반복에서, 현재 점은 이전 반복에서 결정된 중 심 선의 점 62-65일 수 있다. 81단계에서 AI 모델 입력의 결정은 볼륨 40의 서브 볼륨 76에서 이미지 데이터로 AI 모델 입력을 결정할 수 있 다. 서브 볼륨 76은 이전 반복의 결과일 수 있는 현재 점을 포함할 수 있다. 서브 볼륨 76은 이전 조향 예측 및 서브 볼륨 방향에 따라 달라지는 방향을 가질 수 있다. 서브 볼륨 76은 볼륨 40의 모서리에 대해 기울어질 수 있다(일반적으로 기울어짐). 첫 번째 반복에서 서브 볼륨 방향은 사용자 입력, 다양한 방향에 대한 계산된 예측 불확실성, 무작위 방향 또는 기타를 기반으로 결정될 수 있다. 이후의 각 반복에서 현재 위치와 서브 볼륨 방향 은 방법 80의 이전 반복에서 AI 모델이 결정한 것이다. 81단계에서 AI 모델 입력을 결정하는 것은 이미지 데이터 40의 복셀 또는 픽셀 값에 대해 수행되는 평균화(예: 가중화된 평균화) 또는 기타 보간 기술을 포함할 수 있으며, 여기에서 더 자세히 설명된다. 82단계에서, 이미지의 서브 볼륨이 처리된다. 이것은 AI 모델로 AI 모델 입력을 처리하는 것을 포함할 수 있다. AI 모델의 출력 계층은 업데이트된 조향 예측을 출력할 수 있다. 83단계에서, 82단계에서 얻은 조향 예측이 적어도 중심선 50을 따라 다음 점과 서브 볼륨에 대한 다음 방향을 결정하기 위해 처리된다. 여기에는 이전(및 선택적으로 여러 이전에 결정된) 조향 예측, 위치 및 방향의 벡터 추가 또는 통합이 포함될 수 있다. 84단계에서 종료 기준이 충족되는지 여부를 판단한다. 종료 기준은 다음 중 하나 또는 임의의 조합일 수 있지만 이에 국한되지 않는다: 이미지 데이터 40의 경계 또는 사용자 정의 경계와 분석될 서브 볼륨 및/또는 다음 위치 의 교차점; 반복 횟수 또는 누적 경로 길이에 대한 임계값 기준; 서브 볼륨에서 세장형 객체의 식별 가능한 연 속이 없음; 다른 수단으로 정의된 객체 내에서 경로 길이의 위치 또는 누적의 교차점(예: 추적 중인 신경 돌기 와 이전에 추적된 신경 돌기의 교차점). 종료 기준이 충족되지 않으면, 방법은 81단계로 돌아갈 수 있다. 그렇 지 않으면 세장형 객체 추적의 결과는 GUI 또는 데이터 인터페이스를 통해 출력되거나 85단계에서 다른 방식으 로 사용될 수 있다. 도 5의 기술은 보다 복잡한 프로세스 또는 방법의 일부로 사용될 수 있다. 또한 일부 고차 논리에 내장될 수도 있다. 예를 들어, 자동 재구성의 누락된 연속을 자동으로 감지하고, 해당 위치에서 누락된 연속의 감지에 응답 하여 도 5의 기술을 시작하고, 다른 자동 재구성된 구성 요소를 찾을 때까지 도 5의 기술을 실행하는 방법이 공 개된다. 그 점에서, 여기에 공개된 기술(및 도 5를 참조하여 설명된 대로)은 동일한 시작 위치에서 종료된다는 것을 다시 확인하기 위해 역방향으로 실행될 수 있다. 따라서 도 5의 기술은 더 복잡한 재구성 방법을 위한 기초로 사용될 수 있다. 도 6은 여기에 공개된 시스템 및 방법에서 분석을 위한 서브 볼륨의 위치 종속적 선택을 설명한다. 반복적인 추 론 프로세스의 반복에서 결정된 중심선 50을 따른 점 62와 순간 비행 방향 71은 볼륨 40의 어느 부분을 AI 모델 이 세장형 객체의 추적을 계속하기 위해 다음에 처리할 것인지를 결정하는 데 사용된다. 서브 볼륨 91은 직육면 체 모양을 가질 수 있으나, 이에 국한되지 않는다. 서브 볼륨 91의 네 모서리는 순간 비행 방향 71과 평행할 수 있다. 조향 예측 71과 평행한 네 개의 모서리는 일정하게 또는 이전 AI 모델 예측에 따라 서브 볼륨 91의 다른 모서리보다 짧거나 길거나 같은 길이로 선택될 수 있다. 서브 볼륨 91은 추적할 객체에 따라 크기가 달라질 수 있다. 점 62는 서브 볼륨 91 내에 포함될 수 있다. 서브 볼륨 91은 그 중심 92가 순간 비행 방향 73을 따라 오프셋으 로 점 62로부터 오프셋되도록 위치될 수 있다. 즉, 서브 볼륨은 점 62에서 볼 때 순간 비행 방향의 반대쪽보다 순간 비행 방향 73을 따라 더 큰 거리로 확장되도록 위치될 수 있다. 서브 볼륨의 방향은 이전 비행 방향과 이전 반복에서 결정된 조향 예측에 따라 가변적이다. 예를 들어, 중심선 50을 따르는 점 65와 반복 추론 프로세스의 반복에서 결정된 순간 비행 방향 77은 볼륨 40의 어느 부분을 AI 모델이 처리하여 세장형 객체의 추적을 계속할 것인지 결정하는 데 사용된다. 서브 볼륨 93은 입방체 모양을 가질 수 있으나 이에 국한되지 않는다. 서브 볼륨 93의 네 모서리는 순간 비행 방향 77과 평행할 수 있다. 순간 비행 방향 77과 평행한 네 모서리는 서브 볼륨 93의 다른 모서리보다 짧거나 길거나 길이가 같을 수 있으며 상수로 선택되거나 이전 반복의 AI 모델 예측에 따라 달라질 수 있다. 점 65는 서브 볼륨 93에 포함될 수 있다. 서브 볼륨 93은 그 중심 94이 순간 비행 방향 77을 따라 오프셋에 의 해 점 65에서 오프셋되도록 위치될 수 있다. 즉, 서브 볼륨은 점 65에서 볼 때 조향 예측의 반대쪽보다 순간 비 행 방향 77을 따라 더 큰 거리로 확장되도록 위치될 수 있다. 순간 비행 방향 73, 77과 평행하지 않은 서브 볼륨 91, 93의 모서리 방향은 적절하지 않다. 순간 비행 방향 73, 77 주위의 랜덤 회전 95, 96은 서브 볼륨 91, 93을 선택할 때 훈련 중 및/또는 추론 중에 도입될 수 있다. 이는 여기에 공개된 기술의 견고성을 더욱 향상시킨다. 랜덤 회전 95, 96은 AI 모델을 이 회전과 (대략적으로) 동등하게 만드는 방법으로 대체되거나 결합될 수 있다. 이는 회전된 입력을 공급하면 그에 따라 회전된 조향 예측이 생성된다는 효과가 있다. 이는 여기에 공개된 기술 의 견고성을 더욱 높일 수 있다. 조향 방향과 평행한 서브 볼륨 91, 93의 모서리는 일정하게 또는 이전 AI 모델 예측에 따라 조향 방향과 평행하 지 않은 서브 볼륨 91, 93의 모서리보다 짧거나 길거나 같은 길이로 선택될 수 있다. 이는 여기에 공개된 기술 의 견고성을 더욱 향상시킨다. 서브 볼륨 91, 93이 이전 조향 예측, 이전 비행 방향 및 이전 점에 종속되어 있기 때문에 서브 볼륨 91, 93의 복셀은 일반적으로 원본 이미지 데이터 40의 복셀과 일치하지 않는다. 보간은 도 7 및 8에 나와 있듯이 서브 볼 륨 91, 93의 임의의 방향 및 위치에 대해 서브 볼륨 91, 93 내의 복셀 값을 계산하는 데 사용될 수 있다. 도 7 및 8은 실선 원으로 표시된 이미지 데이터 40의 복셀(예: 복셀의 중심)을 보여준다. 서브 볼륨 91, 93의 복셀은 열린 원으로 표시되며 일반적으로 물리적 길이 척도 측면에서 이방성일 수 있다. 이미지 데이터 40의 복 셀은 그리드 100을 정의한다. 서브 볼륨의 복셀은 이방성이 될 수 있는 두 번째 그리드 105를 정의한다. 두 번 째 그리드 105의 두 번째 좌표 축 106은 원본 이미지 데이터 40의 복셀이 정의된 그리드 100의 좌표 축 105를 기준으로 3D로 회전되거나 3D로 이동될 수 있다. 보간 기술은 두 번째 그리드 105의 위치에 대한 복셀 값(예: 다양한 색상 채널을 사용한 흑백(grayscale) 또는 색상 값)을 결정하는 데 사용될 수 있으며, 이는 AI 모델 입력 중 하나이다. 투영은 두 번째 그리드 105의 복셀 값을 결정하는 데 사용될 수 있다. 예를 들어, 도 8에 표시된 대로 투영(예: 삼선형 투영)이 이미지 데이터를 그리드 105의 평면에 투영하는데 사용될 수 있다. 다른 기술이 사용될 수 있다. 예를 들어, 두 번째 그리드 105의 점(즉, 서브 볼륨 91, 93의 복셀 중심)은 원본 이미지 데이터 40의 여러 개(예: 8개)의 복셀 중심 103으로 정의된 큐브 내에 위치할 수 있다. 가중 평균을 수 행하여 원본 이미지 데이터의 복셀 값에서 서브 볼륨 91, 93의 점 106에 대한 복셀 값을 계산할 수 있다. 예를 들어, 점 106에 대한 복셀 값은 두 번째 그리드 105의 점 주변에 위치한 8개의 복셀 중심 103의 복셀 값의 가중 평균으로 계산될 수 있다. 다른 기술을 사용하여 이미지 데이터를 서브 볼륨에 대해 정의된 그리드 105로 보간 하여 삼선형 투영(위에서 설명한 대로)과 같은 AI 모델 입력을 결정할 수 있다. 이미 언급했듯이, 그리고 아래에서 더 자세히 논의할 것처럼, 로컬 재정렬이 적용될 수 있다. 도 7에서 로컬 재 정렬은 2D 이미지 평면(도 7에서 검은색 점의 평면으로 표시)의 (잠재적으로 정수가 아닌) x 및/또는 y 오프셋 (교차 상관에서 얻을 수 있음)에 대해 적용될 수 있다. 따라서, 삼선형 보간(도 7에서 검은색 점 위치의 복셀이 로컬 재정렬의 대상이 될 때 흰색 점 위치에서 복셀 값을 생성하기 위한)은 바닥 및 천장 z 좌표에서 별도로 결 정된 흰색 점 위치당 두 개의 쌍선형 보간을 사용하여 계산할 수 있으며, 잠재적으로 다른 x/y 오프셋이 검은색 점 위치에 적용된 다음, 쌍선형 보간의 두 중간 값을 z 축을 따라 다른 선형 보간으로 결합한다. AI 모델 구성과 관련하여, 컨볼루션 계층을 포함하는 AI 모델은 좋은 성능을 제공하기 위해 결정되었다. 예를 들어, AI 모델은 컨볼루션 신경망일 수도 있고 컨볼루션 신경망을 포함할 수도 있다. 도 9와 10은 여기에 개시된 시스템 및 방법에 사용될 수 있는 AI 모델을 보여준다 AI 모델 110은 이미지 데이터의 픽셀 또는 복셀 값에 기반한 AI 모델 입력을 수신하도록 동작하는 입력 계층 111을 포함한다. AI 모델 입력은 이미지 데이터 40의 복셀 값에서 결정된 대로 서브 볼륨 91, 93 내의 이미지 데이터를 포함하거나 이미지 데이터일 수 있다. 복셀 값은 정수에서 부동 소수점 표현으로 변환되고 AI 모델에 서 처리되기 전에 정규화될 수 있다. 정규화는 AI 모델 입력 값을 특정 범위로 제한하거나 AI 모델 입력 값의 통계적 속성을 변경하는 데 적용될 수 있으며 예를 들어, 평균 입력 값을 0으로 하고 입력 값에 대한 표준 편차 를 1로 만드는 것이다. AI 모델 110은 조향 예측 71-75이거나 이를 나타내는 AI 모델 출력을 제공하도록 동작하는 출력 계층 112를 포 함한다. AI 모델 110은 은닉 계층 113을 포함한다. 은닉 계층 113은 여러 개의 컨볼루션 계층 114, 115을 포함할 수 있 다. 은닉 계층 113은 스트라이드(strided) 컨볼루션 계층 및/또는 완전 연결 계층을 포함할 수 있다. 스트라이 드는 컨볼루션 계층마다 다를 수 있다. 은닉 계층 113은 여러 개의 컨볼루션 계층 114, 드롭아웃 및/또는 리셰이핑 계층 116, 및 하나 또는 여러 개의 완전 연결 계층 115를 포함할 수 있다. 은닉 계층 113은 마지막 계층으로 선형 계층을 포함할 수 있다. 다양한 활성화 함수가 사용될 수 있다. 예를 들어, 지수 선형 단위(ELU)와 정류 선형 단위(ReLU)는 모두 여기에 공개된 시스템 및 방법에서 성공적으로 사용되었다. 다양한 다른 활성화 함수가 추가적으로 또는 대안적으로 사 용될 수 있다. 이러한 활성화 함수에는 스케일링된 지수 선형 단위(SELU), 가우시안 오차 선형 단위(GELU) 활성 화 함수 중 하나 또는 임의의 조합이 포함될 수 있지만 이에 국한되지 않는다. 다양한 다른 인공 신경망 계층이추가적으로 또는 대안적으로 사용될 수 있다. 이러한 계층에는 완전 연결 계층, 풀링 계층(예: 최대 풀링), (자 기) 어텐션 모듈, 아트러스 합성곱, (배치) 정규화 계층, 변환기, 순환 계층(예: 장단기 메모리(LSTM), 게이트 순환 단위(GRU)) 중 하나 또는 임의의 조합이 포함될 수 있지만 이에 국한되지 않는다. 더욱 향상된 효율성과 견고성을 위해 AI 모델은 세장형 곡선을 따라 공간적으로 변하는 참조 프레임에서 조향 예측에 대한 정보를 제공하도록 훈련될 수 있다. 예를 들어, AI 모델은 (훈련 단계 동안) 훈련될 수 있으며 추 론 중에 동작하여 (로컬) 비숍 프레임에서 조향 예측에 대한 정보를 제공할 수 있으며, 예를 들어 두 개의 비숍 곡률을 출력한다(자세한 내용은 아래 참조). 도 11은 방법 120의 흐름도이다. 방법 120은 이미지 처리 시스템 30에 의해 자동으로 수행될 수 있다. 방법 120 은 반복되는 추론에 의해 중심선 50을 따라 일련의 점 60을 결정하기 위해 수행될 수 있다. 121단계에서 처리하기 위한 서브 볼륨이 선택된다. 서브 볼륨은 중심선을 따라 이전에 결정된 점에 따라 위치가 달라질 수 있다(첫 번째 반복에서 사용자 입력으로 지정하거나 이후 반복에서 이전 반복의 결과로 지정될 수 있 음). 서브 볼륨은 이전 서브 볼륨 방향과 이전에 결정된 조향 예측에 따라 방향이 달라질 수 있다(사용자 입력 으로 지정하거나 첫 번째 반복에서 자동으로 결정하고 이후 반복에서 이전 반복에서 가져올 수 있음). 122단계에서 AI 모델은 서브 볼륨 내의 이미지 데이터에서 동작한다. 이미지 데이터 복셀의 보간은 서브 볼륨의 임의의 방향 및/또는 위치에 대해 해당 서브 볼륨의 복셀 그리드에서 복셀 값을 결정하기 위해 수행될 수 있다. 123단계에서, AI 모델은 AI 모델 출력으로 업데이트된 조향 예측을 제공할 수 있다. 업데이트된 조향 예측은 로 컬 참조 프레임에 대해 지정될 수 있다. 예를 들어, 서브 볼륨(예: 비숍 좌표계)과 관련하여 제공된 참조 프레 임에 대한 곡률 값으로 지정될 수 있다. AI 모델은 장애물로부터의 거리에 대한 정보와 같은 추가 출력을 제공 할 수 있다. 124단계에서, 중심선을 따르는 새로운 점은 123단계의 조향 예측을 기반으로 결정될 수 있다. 예를 들어, 중심 선을 따르는 새로운 점을 결정하기 위해 적분이 수행될 수 있다. 도 12는 방법 125의 흐름도이다. 방법 125는 이미지 처리 시스템30에 의해 자동적으로 수행될 수 있다. 방법 125는 반복적인 추론에 의해 중심선 50을 따라 일련의 점들 60을 결정하도록 수행할 수 있다. 방법 125는 도 11 을 참조하여 설명된 단계 121-124를 포함할 수 있다. 방법 125는 또한 후속 반복에서 서브 볼륨을 지정하는데 사용되는 순간 비행 방향 주위의 회전을 결정하는 추가 단계 126을 포함할 수 있다. 예시 회전 95, 96은 도 6에 도시된다. 도 13은 여기에 공개된 방법 및 시스템에서 사용될 수 있는 AI 모델 아키텍처 및 데이터 처리를 설명한다. 각 반복에서 현재 위치에 중심을 둔(현재 비행 방향에 수직인 방향으로) 서브 볼륨 131이 분석된다. AI 모델 130은 서브 볼륨 131의 이미지 데이터에 대한 K × N × M 복셀 값을 수신하도록 동작하는 입력 계층을 포함할 수 있다. 최근 조향 예측에 대해 횡방향으로 복셀 K 및 N의 수는 최근 조향 예측과 평행한 복셀 M의 수 를 초과할 수 있다. 예를 들어, K = N = 96 및 M = 16이 사용될 수 있다. 또한, 서브 볼륨에 대한 단일 복셀의 물리적 크기는 이미지 데이터 40에서 단일 복셀의 물리적 크기와 이방성으로 및 독립적으로 선택될 수 있다. 값 K와 N은 추적되는 객체에 따라 설정될 수 있다. 예를 들어, 중심 축에 가로지르는 평면에서 타원형 단면을 갖거나 가질 것으로 예상되는 객체의 경우 K와 N을 다른 값으로 설정하는 것이 유용할 수 있다. 도 13의 구현에서 AI 모델은 7개의 스트라이드 컨볼루션 계층 conv1-conv7을 포함한다. 계층이 모두 동일할 필 요는 없다. 예를 들어, 컨볼루션 계층 중 3개 conv1-conv3는 스트라이드 2 × 2 × 1을 가지는 5 × 5 × 3 컨볼루션을 가질 수 있고, 컨볼루션 계층 중 4개 conv4-conv7는 스트라이드 1 × 1 × 1을 가지는 3 × 3 × 2 컨볼루션을 가질 수 있다. 도 13을 구현할 때, AI 모델은 드롭아웃 계층을 포함하며, 이 계층의 드롭아웃 비율은 0.5일 수 있다. 도 13을 구현할 때 AI 모델은 완전히 연결된 세 개의 계층(f.c.1-f.c.3)과 선형 계층을 포함한다. AI 모델 출력 132는 조향 예측일 수 있으며, 선택적으로 로컬 참조 프레임(예: 비숍 곡률)에서 결정될 수 있다. 처리는 AI 모델 출력 132를 기반으로 중심선을 따라 다음 점을 결정하기 위한 적분 133을 포함한다. 이후 반복 에서 분석되는 서브 볼륨은 추가적인 랜덤 회전(도 13의 일반 간섭 경로) 없이 설정되거나 추가적인 랜덤 회전 134와 함께 설정될 수 있다.도 14는 여기에 공개된 방법 및 시스템에서 사용될 수 있는 AI 모델 138의 추가 구현을 보여준다. 합성곱 계층 conv1-conv7의 파라미터 139는 도 13의 AI 모델과 비교하여 수정될 수 있다. 대안적으로 또는 추가적으로, 완전 연결 계층 f.c. 1-3의 파라미터는 도 13의 AI 모델과 비교하여 수정될 수 있다. 예를 들어, 도 14에 표시된 수 직 막대 앞이나 수직 막대 뒤의 파라미터 값이 활용될 수 있다. 한 구현에서, 도 14에서 수직 막대 뒤에 표시된 파라미터 값 139와 파라미터 값 139'이 사용될 수 있다. 이 시스템과 방법은 신경 돌기 추적에 사용될 수 있지만, 이에 국한되지 않는다. 이 시스템과 방법은 3D-EM 볼 륨에서 중심선 재구성 작업이 수행되어 신경 돌기 재구성을 허용할 수 있으며, 여기서 신경 돌기는 방문한 점의 시퀀스로 표현된다. 컨볼루션 신경망은 인간 주석 비행 모드와 유사하게 신경 돌기-중심의 및 -정렬된 3D-EM 서 브 볼륨에서 로컬 신경 돌기 연속을 예측하는 작업(task)에 대해 훈련한다(예: Boergens et al. 2017. \"WebKnossos: Efficient Online 3D Data Annotation for Connectomics.\" Nature Methods 14: 691-94). 예측된 신경 돌기 연속을 통합하면 새로운 위치와 방향이 생성되고, 이는 후속 컨볼루션 신경망 입력을 생성하 는 데 사용된다. 이 절차를 반복적으로 적용하면 시작 위치와 방향이 볼륨 분할과 같은 중간 단계 없이 3D-EM 데이터만 사용하여 신경 돌기 골격 재구성으로 전환된다. 도 13의 AI 모델의 경우 컨볼루션 신경망에 대한 입력은 96 × 96 × 16 복셀(Vx) 신경 돌기-중심 및 신경 돌기 -정렬 3D-EM 서브 볼륨 131으로 구성된다. 예를 들어, 축삭 돌기의 경우 서브 볼륨은 약 1 × 1 × 0.7 μm의 시야를 포함할 수 있다(도 13 참조). 시야는 따라서 Z 방향을 따라 비대칭이며, 역방향 비행 방향보다 전방 비행 방향에서 더 많은 문맥적 정보를 얻 을 수 있다. 이는 축삭 돌기 정맥류 내에서 '출구'를 향해 더 나은 조향을 가능하게 한다. EM 데이터는 삼선형 보간을 통해 축삭 돌기-정렬된 평면에 투영될 수 있다. 3D EM 서브 볼륨을 입력으로 사용해야만 단일 입력에서 신경 돌기의 연속에 대한 관련 정보를 추출할 수 있다. 또는 2D EM 이미지를 순환 신경망에 공급하여 이미지 시퀀스를 내부적으로 추적하고 신경 돌기의 연속도 추정할 수 있다. 도 13의 컨볼루션 신경망 아키텍처의 경우 7개의 3D 스트라이드 컨볼루션 계층이 사용되었고, 그 다음에 드롭아 웃 계층(드롭아웃 비율: 0.5), 3개의 완전 연결 계층, 그리고 두 개의 조향 명령과 멤브레인까지의 거리를 추정 하는 마지막 선형 계층이 사용되었다. 조향 예측으로 출력 계층에서 출력된 두 조향 값은 아래에서 더 자세히 설명하는 비숍 곡률을 나타낼 수 있다. 비선형성으로 ELU가 사용되었다(예: D.A-. Clevert et al. 2015. “ Fast and Accurate Deep Network Learning by Exponential Linear Units (ELUs).\" Iclr. 566 https://doi.org/10.3233/978-1-61499-672-9-1760). 네트워크의 입력 및 출력 공식화를 위해 비숍 프레임과 관련 비숍 곡률이 사용될 수 있으며, 이는 아래 기술 섹 션에서 설명된다. 비숍 프레임은 접선 벡터와 두 개의 법선 벡터로 확장된 로컬 직교 좌표계이며 접선 벡터 주 변의 모든 꼬임을 허용하지 않는 회전 최소화 속성을 따른다. AI 모델의 입력에 대한 신경 돌기 정렬 투영 평면 은 비숍 법선 벡터를 통해 정의할 수 있으며, 네트워크의 비행 방향은 접선 벡터에 해당할 수 있다. 비숍 프레임 단위 벡터의 진화는 각 법선 벡터 방향마다 하나씩 비숍 곡률을 통해 결합된다. 비숍 곡률은 조향에 사용되는 AI 모델 출력 계층의 출력일 수 있다. 두 비숍 곡률 각각은 해당 법선 벡터 방향 에 대한 부호있는 곡률과 유사하다. 부호있는 곡률은 평면 곡선에 해당하는 한 조향 방향에 대해서만 이미지 기 반 도로 추종을 위한 조향 명령으로 사용되었다(예: KM. Bojarski et al. 2016. \"End to End Learning for Self-Driving Cars.\" ArXiv E-Prints. https://arxiv.org/pdf/1604.07316.pdf 참조). 비숍 곡률의 형태로 신경 돌기 연속을 예측하는 작업은 신경 돌기의 중심선에 포물선을 맞추는 것으로 해석될 수 있다. 비숍 곡률의 합에 해당하는 비숍 법선 벡터를 곱하여 계산된 곡률 벡터는 이 포물선의 굽힘 방향과 크 기를 결정한다. 따라서 AI 모델 출력 계층에서 출력된 비숍 곡률은 중심선을 따라 있는 일련의 점 중 다음 점을 결정하는데 통 합될 수 있다(이 일련의 점은 사전에 알려지지 않았으며 중심선을 추적하도록 결정됨). 훈련(Training) 훈련된 AI 모델의 동작은 위에서 설명했다. 여기에 공개된 시스템 및 방법은 AI 모델을 의도된 용도에 맞게 훈 련하도록 동작할 수 있다. 도 15는 AI 모델 훈련 141과 추론 142 동안 훈련된 AI 모델의 동작을 모두 포함하는 방법 140의 흐름도이다. 142단계에서 훈련된 AI 모델을 사용하는 것은 여기에 설명된 세장형 객체가 확장되는 방향을 추론하는 기술 중 하나를 사용하여 구현될 수 있다. 141단계의 훈련은 감독 훈련일 수 있다. 주석이 달린 3D-EM 이미지 세트가 훈련에 사용될 수 있다. 훈련은 AI 모델 파라미터의 경사 기반 업데이트를 포함할 수 있다. 숙련된 사람에게 알려진 기술은 경사 하강 기술과 같은 모델 파라미터를 업데이트하는 데 사용될 수 있다. 141단계에서 훈련은 AI 모델이 중심선에서 시작하거나 중심선에서 벗어난 위치에 도달하더라도 AI 모델이 중심 선 50으로 다시 수렴하도록 하는 비행 정책을 준수하도록 AI 모델을 훈련하는 것을 포함할 수 있다. 이를 달성 하기 위해, 141단계 훈련은 AI 모델이 중심선 50에서 벗어난 위치에서 시작하는 시나리오에 대해서도 AI 모델을 훈련하는 것을 포함할 수 있고, 및/또는 훈련 중 AI 모델의 예측은 추론에서 수행된 것처럼 통합되고 피드백되 어 중심선에서 벗어난 위치도 잠재적으로 생성할 수 있다. 초기 서브 볼륨이 (i)중심선에서 오프셋된 위치에서 시작하고 및/또는 (ii)세장형 객체의 방향과 정렬되지 않더라도 중심선 50으로 다시 수렴하도록 강제하는 비행 정책을 구현할 수 있다. 따라서, 훈련은 또한 서브 볼륨 91, 93의 복셀 평면 중 어느 것도 중심선 50을 따라 위 치와 일치하는 중심을 갖지 않는 서브 볼륨을 사용하여 수행될 수 있다. 적어도 서브 볼륨의 일부는 의도적으로 선택될 수 있으며, 예를 들어, (도 13의 모델에 대한 서브 볼륨의 16개 평면 중) 4번째 평면의 중심은 주석이 달린 데이터 또는 이전 반복에서 결정된 중심선의 점으로부터 오프셋을 갖는다. 오프셋은 이전에 결정된 확장 방향에 대해 횡으로(즉, 비숍 프레임의 조향 예측에 대해 횡으로) 향할 수 있다. 훈련은 훈련 중에 가변적인 하나 또는 여러 훈련 파라미터를 사용하는 방식으로 구현될 수 있다. 이를 통해 훈 련 중에 다양한 정책을 시행할 수 있다. 이와 같은 학습 기법을 사용하면 세장형 객체 모델 학습의 결과가 더욱 향상된다. 141단계의 훈련에서 비행 정책의 수렴 거리는 반복적 프로세스가 중심선으로 얼마나 빨리 수렴하는지를 결정할 수 있다. 수렴 거리는 AI 모델 훈련 중에 변경되는 동적 파라미터일 수 있다. 수렴 거리는 AI 모델 훈련 중에 생리적 경계로부터의 거리의 함수로 설정될 수 있다. 수렴 거리는 생리적 경계로부터의 거리의 단순 증가하는 함수일 수 있으므로, 세포 경계와 같이 생리적 경계에 더 가까운 위치에서 중심선으로의 보다 공격적인 복귀를 구현할 수 있다. 수작업으로 만든 비행 정책을 이용한 지도 학습 대안으로, 비행 정책은 대신 세장형 객체의 안정적인 추적을 장 려하는 보상 함수를 정의하여 강화 학습을 사용하여 직접 학습할 수도 있다. 구체적인 예로, 도 13의 컨볼루션 신경망 아키텍처는 TensorFlow를 사용하여 신경 돌기 추적 과제에서 훈련될 수 있다(M. Abadi et al. 2016. \"TensorFlow: A System for Large-Scale Machine Learning.\" In 12th USENIX Symposium on Operating Systems Design and Implementation (OSDI '16), 265-537 84). AI 모델은 RMSProp(예: T. Tieleman and G. Hinton. 2015. \"Neural Networks for Machine Learning Lecture 6a: Overview of Mini-batch Gradient Descent.\" Lecture Notes. 2015. http://www.cs.toronto.edu/~tijmen/csc321/slides/lecture_slides_lec6.pdf)과 momentum (D.E. Rumelhart et al. 1986. \"Learning Representations by Back-Propagating Errors.\" Nature 323 : 533-36; I. Sutskever et al. 2013. \"On the Importance of Initialization and Momentum in Deep Learning.\" In International Conference on Machine Learning, 1139-1147) 또는 Adam(D.P. Kingma and J.L. Ba. 2015. \"Adam: A Method for Stochastic Optimization.\" In 3rd International Conference on Learning Representations, ICLR 2015 - Conference 607 Track Proceedings. https://arxiv.org/abs/1412.6980)을 사용 하여 평균 제곱 오차를 최소화하고 신경망 학습 파라미터에 L2 정규화 손실 항을 추가하여 128의 미니 배치 크 기로 학습될 수 있다. 훈련과 후속 테스트는 추론 중 성능이 중심선에서 벗어난 위치에서도 훈련함으로써 향상될 수 있음을 보여주었 다. 추론 중 현재 위치와 방향은 과거 AI 모델 결정에 따라 달라진다. 따라서 과거 네트워크의 조향 예측에서의 사소한 오류라도 네트워크를 신경 돌기 중심선에서 벗어나게 할 수 있다. 경로 추적(즉, 추적)의 안정성을 강화하기 위해 AI 모델은 또한 중심에서 벗어난 위치와 방향에서 훈련될 수 있 으며, 이에 따라 조정된 조향 예측은 신경 돌기 중심선으로 다시 이어질 수 있다. 신경 돌기 내에서 중심에서 벗어난 위치를 샘플링하려면 훈련 중에 신경 돌기 직경 및/또는 모양을 적어도 대략적으로 알아야 한다. 신경돌기의 체적 재구성이 신경 돌기 내에서 중심에서 벗어난 위치를 결정하기 위해 사용될 수 있다. 특정한 위치, 방향에서 벗어난 상태에서 적응된 조향으로의 매핑은 또한 비행 정책이라고도 한다. 탐욕스러운(greedy) 비행 정책은 AI 모델이 유한한 시야 내에서 사용할 수 있는 로컬 정보만을 기반으로 사용할 수 있으며, 이에 대한 자세한 내용은 이하에서 설명된다. 중심선으로 다시 수렴하는 거리는 이 비행 정책의 자 유 파라미터이다. 다른 수렴 거리가 시냅스 부통(bouton) 내의 중심에서 벗어난 위치에 대해 사용될 수 있다. 세포막에 '적중(hitting)'하는 데 더 가까울 때, 더 짧은 수렴 거리를 가진 더 공격적인 조향은 신경 돌기 내에 머무르는 데 유용하지만, 막까지의 거리가 더 클 경우 더 부드러운 조향이 저렴하고 입력 시야의 신경 돌기 정 렬을 더 잘 보존한다. 따라서 훈련 중 비행 방향을 따라 세포막까지의 거리에 따라 설정(예: 동일)될 수 있는 동적 수렴 거리가 사용될 수 있다. 이는 장애물, 즉 세포막, 회피의 개념을 유도하며, 훈련 중에 수렴 거리에 대한 상수 값을 사용하는 것보다 경험적으로 더 나은 성과를 보인다. 도 16은 3D 훈련 데이터의 볼륨 40을 보여준다. 신경 돌기 151은 3D 훈련 데이터에서 주석이 달려 있다. AI 모 델은 예시적인 점 152와 같은 점을 중심으로 한 예시적인 서브 볼륨 156과 같은 서브 볼륨을 사용하여 훈련되며, 예시적인 점 152(서브 볼륨 156의 하나의 복셀 평면 중심에 위치하고)는 신경 돌기 151의 중심선에서 오프셋된 위치에 있다. 비행 방향 153은 훈련 중에 서브 볼륨 156 내의 신경 돌기의 확장 방향과 (상당히) 다를 수 있다. 하나 또는 복수의 훈련 파라미터 예를 들어, 프로세스가 얼마나 빨리 신경 돌기의 중신선으로 다시 수 렴하는지를 지시하는 수렴 거리는 동적으로 변화할 수 있다. 예를 들어, 수렴 거리는 세포막 154와의 거리 155 에 따라 설정될 수 있으며, 이는 단지 개략적으로 나타나 있다. 이 거리 155는 순간적인 비행 방향을 따라 측정 될 수 있다. 오류율에 대한 성능(Performance with regard to Error Rates) 성능을 평가하기 위해 이미지 처리 시스템 및 방법은 검증 세트와 선형 축삭 돌기 브랜치(branch)의 두 테스트 세트에 대해 양쪽에서 시작하여 재귀적 추론을 실행하여 평가된다. 실제값(ground truth) 추적과 관련된 거리 또는 각도에 대한 임계값 세트에 도달하면 실제값 추적으로 재설정이 트리거되며, 이는 여기에서 더 자세히 설 명한다. 네트워크가 축삭 돌기 브랜치의 다른 끝에 도달하면 추적이 중지된다. 리셋으로 이어지는 각 조향 오류는 잘못된 프로세스로의 병합 오류와 관심 있는 신경 돌기를 계속하지 않아 발 생하는 분할 오류 모두에 해당한다. 각 리셋은 두 개의 오류로 계산된다. 오류율은 오류 수를 실제 스켈레톤의 경로 길이로 나눈 값이다. 이 지표는 검증 세트를 기반으로 여러 개의 훈련된 AI 모델이 있는 경우 모델을 선택 하고, 오류 간 거리, 즉 역 오류율이 보고되는 다른 자동화된 접근 방식과 대략적으로 비교하고, 사람 오류율과 비교할 수 있도록 한다. 이미지 처리 시스템 및 방법은 직렬 블록면 주사 전자 현미경(SBEM, (W. Denk 및 H. Horstmann. 2004. \"Serial Block-Face Scanning Electron Microscopy to Reconstruct Three-Dimensional Tissue Nanostructure.\" Kristen M. Harris 편집. PLoS Biology 2))을 사용하여 획득한 마우스 1차 체성 감각 피질 L4의 3D-EM 데 이터 세트에 대해 훈련되었다. 데이터 세트의 크기는 61.8 x 94.8 x 92.6 μm3이고 복셀 크기는 11.24 x 11.24 x 28 nm3이다. 모델 선택을 위해, 이미지 처리 시스템 및 방법은 1.4mm 경로 길이의 13개 축삭 돌기로 구성된 검증 세트에서 평가되었다. 검증 세트의 경우, 경로 길이가 5μm 미만인 축삭 돌기 분기(branch)는 오류에 대한 더 나은 휴리 스틱 감지를 위해 제외되었다. 훈련 및 검증 세트의 축삭 돌기는 B. Staffler et al. 2017. \"SynEM, Automated Synapse Detection for Connectomics.\" ELife 6 (July): e26414에 공개된 기술을 사용하여 얻은 시냅스 전 분 류 세그먼트를 통해 시작된(seeded) 축삭 돌기의 분리된 무작위 서브 집합이다. 모든 모델과 훈련 반복에 대한 평균으로, 무작위 추론 모드는 일반 모드 대응 모드보다 33% 더 우수하다(범위: 12-52%). 검증 세트에서 특히 좋은 성능을 보이는 것으로 확인된 AI 모델은 입력으로 EM 데이터만 사용하고, ELU 활성화 함수가 있으며, 700,000번의 훈련 반복을 통해 훈련되었으며, 휴리스틱 오류 감지에 기초하여 16.4 errors/mm를 산출한다. 창의적인 기술의 추적을 수동으로 검사하면 1개의 거짓 양성 및 0개의 거짓 음성 재설정(정밀도 96%, 재현율 100%)이 산출된다. 실제 오류율은 15.7 errors/mm이다. 선택된 AI 모델을 6.2mm 경로 길이의 59개 체세포(soma) 시작(seed) 축삭 돌기에 적용하면 185회 재설정에서 29.8 errors/mm가 발생하고 9개의 거짓 음성 재설정과 5개의 거짓 양성 재설정이 발생했다(정밀도 95%, 재현율 95%). 실제 오류율은 30.4 errors/mm이다.체세포에서 시작된 축삭 돌기가 더 큰 직경으로 편향되어 있다는 사실을 알고, 이전에 사람 오류율 정량화에 사 용된 1.6mm 경로 길이의 10개 축삭 돌기의 무작위 세트에 대한 테스트도 수행했다(예: Boergens et al. 2017. \"WebKnossos: Efficient Online 3D Data Annotation for Connectomics.\" Nature Methods 14: 691-94.). 여 기에 공개된 이미지 처리 시스템 및 방법은 이 테스트 세트에서 휴리스틱 오류 감지를 통해 58.1 errors/mm를 산출했다. 수동 검사에서 4개의 거짓 양성 및 2개의 거짓 음성 재설정(정밀도 96%, 재현율 98%)이 발견되어 실 제 오류율이 55.6 errors/mm가 되었다. 추가 훈련 및 테스트 구현 가능(Possible further training and test implementations) 예시적 훈련 데이터와 평가 기술은 이미 위에서 설명되었다. 신경 조직의 가능한 추가 3D-EM 데이터 세트와 이 러한 훈련 데이터 내에서, 여기에 공개된 방법 및 시스템과 연관하여 사용할 수 있는 검증 및 테스트 세트가 다 음에 제공된다. 방법 및 시스템은 92.6 x 61.8 x 94.8 μm3 SBEM 데이터 세트(W. Denk 및 H. Horstmann. Serial block- face scanning electron microscopy to reconstruct three-dimensional tissue nanostructure. PLoS Biology, 2, e329. doi:10.1371/journal.pbio.0020329)에서 훈련 및/또는 사용될 수 있으며, 이는 A. Motta et al. . Dense connectomic reconstruction in layer 4 of the somatosensory cortex. Science, eaay3134. doi:10.1126/science.aay3134. 에 의해 이전에 고밀도로 재구성된 28일 된 마우스의 L4 1차 체성 감각 피질에 서 추출되었다. 조직은 기존 방식으로 블록 염색(K. L. Briggman et al. . Wiring specificity in the direction-selectivity circuit of the retina. Nature, 471, 183-188. doi:10.1038/nature09818)되었고 11.24 x 11.24 nm² 및 공칭 절단 두께 28 nm에서 이미지화되었다. 훈련 및 검증의 축삭 돌기는 SynEM(B. Staffler et al. . SynEM, automated synapse detection for connectomics. Elife, 6, e26414. doi:10.7554/eLife.26414)을 사용하여 얻은 시냅스 전 분류 세그먼트를 통해 시작된 축삭 돌기 세트 및 주석자 에 의해 추적된 골격에서 샘플링될 수 있다. 훈련 축삭 돌기의 볼륨 재구성을 획득하기 위해, 피질 데이터 세트 의 전체 세포 분할에 대해 설정된 파라미터로 SegEM(M. Berning et al. . SegEM: Efficient Image Analysis for High-Resolution Connectomics. Neuron, 87, 1193-1206. doi:10.1016/j.neuron.2015.09.003)을 사용하여 얻은 과분할 세그먼트가 선택되고 결합될 수 있다. 볼륨 마스크는 또한 보간된 골격 추적을 반복적으 로 최적화하여 더 나은 중심선 근사값을 얻는 데에도 사용할 수 있다. 1.2mm 경로 길이를 갖는 14개 축삭 돌기 세트가 훈련에 사용될 수 있으며, ~260개 에포크(epochs)에 해당하는 최대 700,000개의 가중치 업데이트가 실행 되었다. 검증 세트는 1.4mm 경로 길이를 갖는 13개 축삭 돌기로 구성될 수 있으며, 5μm 미만인 분기는 더 나은 휴리스틱 오류 감지를 위해 제외되었다. (2.5μm)3 경계 상자에서 시작된 1.7mm 경로 길이를 갖는 10개 축삭 돌 기의 세 번째 세트는 테스트 세트로 사용될 수 있다. 이는 이전에 인간과 반자동 분할을 평가하는 데 사용된 것 과 동일한 축삭 돌기이다(K.M. Boergens et al. . webKnossos: efficient online 3D data annotation for connectomics. Nature Methods, 14, 691-694. doi:10.1038/nmeth.4331; Motta et al., 2019, loc. cit.). 이 데이터세트에서 자동화된 척추 헤드 부착의 경우, 축삭 돌기-훈련된 AI 모델(예: 도 14에 표시되어 있으며 여기에서 더 자세히 설명함)을 사람 주석자가 이전에 부착한 50개의 척추 헤드의 무작위 서브 집합과 Motta et al., 2019, loc. cit에서 이전에 테스트 세트로 사용된 척추 헤드 세트에서 평가할 수 있다. 다음으로, 여기에 개시된 방법 및 시스템의 AI 모델은 Y. Hua et al. . Large-volume en-bloc staining for electron microscopy-based connectomics. Nature Communications, 6, 7923. doi:10.1038/ncomms8923 with small modifications, sectioned at 35 nm using ATUM (K. J. Hayworth et al. . Automating the collection of ultrathin serial sections for large volume TEM reconstructions. Microscopy and Microanalysis: Cambridge University Press.)에 의한 프로토콜에 따라 염색될 수 있는 28일 된 마우스의 배럴 피질에서 1.3 x 1.3 x 0.25 mm3 데이터 세트의 서브 집합에 대해 훈련, 테스트 및 적용될 수 있고, 다중빔 주사 전자 현미경으로 4 x 4nm²에서 이미징했다(A. L. Eberle et al. . High-resolution, high-throughput imaging with a multibeam scanning electron microscope. Journal of Microscopy, 259, 114-120. doi:10.1111/jmi.12224). 8 x 8 x 35 nm3의 해상도에서 데이터 세트에 적용할 수 있는 분할 및 응집(x-y에서 2배로 다운샘플링)은 예를 들어 기존 방식이나 이를 기반으로 하는 기술을 사용하여 수행할 수 있다: 간단히 말해, 3D U-Net(O. Ronneberger et al. . U-net: Convolutional networks for biomedical image segmentation. Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and LectureNotes in Bioinformatics): Springer, Cham.)을 사용하여 Lee, K., Zung, J., Li, P., Jain, V., & Seung, H. S. . Superhuman Accuracy on the SNEMI3D Connectomics Challenge. arXiv e-prints 에 따른 주요 축당 복셀 친화도를 예측할 수 있으며, 이를 통해 유역 기반(watershed-based) 과분할이 생성되었다. 그런 다음 과분 할의 세그먼트를 J. Funke et al. . Large Scale Image Segmentation with Structured Loss Based Deep Learning for Connectome Reconstruction. IEEE Trans Pattern Anal Mach Intell, 41, 1669-1680. doi:10.1109/TPAMI.2018.2835450에서 제안한 계층적 응집을 사용하여 결합할 수 있다. 또한, 신경 돌기 유형 예 측, 혈관 및 핵 감지를 응집에 통합하여 병합 오류를 더욱 줄일 수 있다. 신경 돌기 유형 예측은 또한 척추 헤 드 감지에 사용되었으며, 이는 여기에 공개된 방법 및 시스템을 기반으로 척추 헤드 부착의 기초가 되었다. 축삭 돌기에서, 여기에 공개된 방법 및 시스템의 AI 모델을 훈련하기 위해, L4에서 10개의 체세포 시작 축삭 돌 기 세트를 기반으로 훈련 세트를 획득할 수 있으며, 주석자는 과분할에서 세그먼트를 선택하여 볼륨 재구성을 획득할 수 있다. Kimimaro(W. Silversmith et al. . Kimimaro: Skeletonize densely labeled 3D image segmentations. In GitHub repository (v 3.0.0 ed.))를 사용한 다음 서브 샘플링과 B-스플라인 보간을 수행하 여 볼륨 재구성에서 중심선 골격을 추출할 수 있다. 이를 통해 총 21mm 축삭 돌기 경로 길이의 훈련 세트를 생 성할 수 있다. 축삭 돌기 검증 세트로서, 크기가 (2μm)3인 경계 상자에서 시작된 L4로부터 20개 축삭 돌기 중 무작위 10개를 (50μm)3 경계 상자 내에서 추적하여 1mm 경로 길이를 얻을 수 있다. 축삭 돌기 테스트 세트의 경우, L4 내의 또 다른 (1.5μm)3 경계 상자가 밀접하게 주석 처리되었고, 무작위 5개 축삭 돌기 서브 집합이 (150μm)3 서브 볼륨 Si150L4(https://wklink.org/7122에서 접근 가능) 내에서 추적하여 1.7mm 경로 길이를 얻 을 수 있다. 여기서 공개된 방법 및 시스템에 따른 별도의 AI 모델은 척추 부착에 대해 훈련될 수 있다. 이 훈련 및 검증 세 트는 L4에서 샘플링되고 척추 헤드에 대한 주석이 달린 20개(5μm)3 경계 상자 세트에서 생성될 수 있다. 약 1000개의 척추 헤드 서브 집합은 척추 헤드에서 척추 목을 거쳐 수상 돌기 줄기까지 주석자에 의해 4 x 4 x 35 nm3에서 볼륨 주석이 달릴 수 있다. 여기서 우리는 다시 2mm의 척추 목 추적을 생성하는 훈련을 위해 Kimimaro(W. Silversmith et al., 2021, loc. cit.)를 사용하여 체적 마스크에서 중심선 골격을 추출하였다. 또한 20개의 경계 상자에서 경로 길이가 0.2mm인 76개의 척추 헤드의 무작위 서브 집합은 검증 집합으로 사용하 기 위해 골격 추적이 가능하다. 평가는 91개의 밀도있게 주석이 달린 척추 헤드에서 수상 돌기 몸통 골격 추적 을 포함하는 또 다른 무작위로 선택된 (5μm)3 경계 상자(Si11L3, https://wklink.org/2458에서 접근 가능)에서 수행될 수 있다. 여기에 공개된 방법 및 시스템을 사용하여 수행할 수 있는 또 다른 최첨단 분할의 오류 수정을 평가하기 위해, 여기에 공개된 방법 및 시스템은 최근 공개된 mm3 스케일의 multiSEM 데이터 세트에 적용될 수 있으며, 이는 복 셀 크기가 4 x 4 x 33 nm3(A. Shapson-Coe et al. . A connectomic study of a petascale fragment of human cerebral cortex. bioRxiv, 2021.2005.2029.446289. doi:10.1101/2021.05.29.446289)이고 플러드 필링 네트워크(FFN; M. Januszewski et al. . High-precision automated reconstruction of neurons with flood-filling networks. Nature Methods. doi:10.1038/s41592-018-0049-4)를 사용하여 분할 및 응집되었다. 구체적으로, 기술의 훈련 및 평가는 제공된 실제 골격 추적의 축삭 돌기 경로 길이가 6.5mm인 (150μm)3 경계 상자에 집중될 수 있다. 이 상자에 게시된 실제 골격 추적은 체세포에서 시작된 축삭 돌기의 플러드 필링 네트 워크를 평가하는 데 사용될 수 있다. 이 데이터 세트에 대해 여기에 공개된 방법 및 시스템에 의한 처리를 미세 조정하기 위해, 밀도가 높은 시작된 축삭 돌기의 실제 골격 추적은 중심(15μm)3 경계 상자 내에서 크기(2.5μ m)3의 경계 상자를 샘플링하고, 이 경계 상자의 모든 프로세스에 주석을 달고, 5개의 축삭 돌기의 무작위 서브 집합을 샘플링하여 생성할 수 있으며, 이는 (150μm)3 경계 상자 전체에서 추적하여 1.25mm 경로 길이를 생성할 수 있다. 여기서, 골격 주석은 이미 중심선을 따라 높은 정밀도로 수행되어 후처리가 필요하지 않았다. 훈련에 필요한 체적 신경 돌기 마스크는 c3 플러드 필링 네트워크 분할 (참조 Shapson-Coe et al., 2021, loc. cit.) 에서 세그먼트 픽업을 통해 생성될 수 있다. 실시 예에 따른 방법 및 시스템에서 사용하는 모델에 대한 최상의 모델 체크포인트는 마우스 피질 ATUM-multiSEM 데이터 세트에서 축삭 돌기 훈련의 검증 세트를 기반으로 초기화 로 사용되었다. 모델은 훈련 축삭 돌기에서 재설정 기반 오류율 측면에서 수렴될 때까지 약 200만 개의 기울기 업데이트에 대해 추가로 훈련될 수 있다. 플러드 필링 네트워크 및 여기에 공개된 방법 및 시스템(예: 도 26 및 해당 설명 참조)을 평가하기 위해, (1.5 μm)3 크기의 또 다른 경계 상자가 (150 μm)3 경계 상자 전체에서 추적된 5개 축삭 돌기의 무작위 서브 집합에 대해 주석이 달릴 수 있으며, 이를 통해 1.4mm 경로 길이가 생성될 수 있다. 또한, 여기에 공개된 방법 및 시스템은 추론 중에 추적할 세장형 객체의 모양을 모방한 인공적으로 생성된 데이 터, 하나 이상의 세장형 객체의 X선, 특히 X선 홀로그램 나노 단층촬영, 광학 현미경 또는 자기 공명 영상 중 하나 또는 여러 개에 대해 훈련되거나 사용될 수 있다. 여기에 공개된 방법 및 시스템이 설명된 대로 동작하기 위해 경로 길이에서 필요한 훈련 데이터 양은 일반적으 로 데이터의 해상도와 시각적 복잡성, 추적할 세장형 객체의 형태와 모양의 가변성, 훈련에 사용된 알고리즘 및 인공 신경망 아키텍처, 훈련에 사용된 이미지 데이터의 수, 종류 및 순서에 따라 달라질 수 있다. 다른 이미지 처리 접근 방식과 비교한 성능(Performance compared to Other Image Processing Approaches) 여기에 공개된 이미지 처리 시스템과 방법의 성능은 또한 다른 기술과 비교된다. 여기에서 공개된 기술이 인간 주석을 대체할 수 있는 정도와 어떤 종류의 연결체 분석이 완전히 자동화될 수 있 는지 조사했다. 이를 위해 우리는 포유류 신피질의 한 조각에 대한 고밀도 연결체 분석(A. Motta et al. 2019. \"Dense Connectomic Reconstruction in Layer 4 of the Somatosensory Cortex.\" Science. Vol 366. Issue 6469. p. eaay3134)으로 시작했는데, 여기서 자동 분할을 기반으로 사람 주석자는 총 4,000시간의 작업 시간을 소모하는 자동으로 식별된 문제 위치 집합을 해결하도록 요청받았다. 분할 오류를 해결하기 위해 인간 질의가 객체의 끝에 배치되어 가능한 경우 계속 진행하도록 요청하고 다른 자동 재구성된 객체에 도달하면 작업을 중지 했다. 병합 오류를 해결하기 위해 카이아스마(chiasmatic) 구성이 감지되었고, 다른 카이아스마 종료 중 하나로 적절하게 계속되도록 요청하는 쿼리가 종료에 배치되었다. 여기에 공개된 기술은 인간 주석자 쿼리와 유사하게 여기에 공개된 기술 쿼리를 시작하여 이러한 인간 주석을 대체하는 데 사용되었다. 실제로, 종료 작업의 76%와 카이아스마 작업의 78%가 여기에 공개된 기술에 의해 올바르게 추적되었다(인간: 각각 74%와 94%). 또한, 여기 에 공개된 기술을 종료 점에서 시작 점으로 다시 실행하면 오류 신호가 제공되어 대부분의 병합 오류를 피할 수 있으며, 여기에 공개된 새로운 기술을 적용하면 종료 작업에서 병합 오류가 4%, 카이아스마 작업에서 1%로 감소 하는데, 이는 인간이 한 주석과 비슷한 수준이다. 이 성과는 여기에 공개된 기술이 인간 주석을 충실하게 대체할 수 있음을 나타내지만, 우리는 재구성 성공에 대 한 척도로 직접 연결체 분석을 사용하여 이를 정량화하고자 했다. 일부 연결체 분석은 다른 연결체 분석보다 더 높은 재구성 정밀도가 필요하다. 특히, 다음 사항이 고려되었다: 연결체의 학습된 분율을 측정하기 위한 동 일한 축삭 돌기-동일한 수상 돌기 시냅스 분석(Motta et al., loc. cit.); 인터뉴런 수상 돌기 식별을 위한 척추 속도 분석; 축삭 돌기의 시냅스 표적 분포를 기반으로 한 축삭 돌기 유형 분석. 세 가지 유형의 연결 체가 비교에 사용되었다: (I) 집중된 인간 주석이 있기 전, (Motta et al., loc. cit.)에서 완전 자동화된 재구 성을 통해 얻은 연결체; (II) (Motta et al., loc. cit.)에서 4,000시간의 인간 주석을 포함한 연결체; (III) (Motta et al., loc. cit.)에서 완전 자동화된 재구성을 여기에 공개된 기술과 결합하여 얻은 연결체로 완전 자 동화되고 자동으로 교정된 연결체. 이 세 가지 유형의 연결체 분석(I), (II), (III)이 수행되었다. 쌍을 이룬 시냅스 분석은 창의적인 기술에 의해 달성된 교정 전 자동화 상태에서 이미 유사한 결과를 산출하지만, 정점 수 상 돌기의 정확한 척추 속도와 척추 헤드 선호도에 의해 정의된 흥분성 축삭 돌기의 진정한 분율은 인간의 수정 또는 창의적인 기술에 의해 달성된 수정을 필요로 한다. 또한, 창의적인 기술에 의해 달성된 수정은 정단 및 평 활 수상 돌기에 대한 억제 축삭 돌기의 축삭 돌기 표적 특이성을 회복하는 반면, 본 명세서에 공개된 기술과 인 간 수정 이전의 자동화된 상태에서는 이 특이성이 감지되지 않았다. 따라서 실제로, 자동으로 분석할 수 있는 연결체 문제 유형에 의해 자격이 부여된 자동화의 연결체 메트릭을 활용할 때, 여기서 개시된 기술을 사용한 오 류 수정은 자동화된 분석 성능을 더 간단한 연결체 문제에서 더 복잡한 연결체 문제로 바뀐다. 여기에 공개된 기술은 또한 상당히 더 크고 다른 이미지 해상도와 대비를 갖는 ATUM(Automatic Tape-collecting Ultra-Microtome)/multiSEM 이미징 접근법의 데이터 세트에 적용되었다. 여기에 공개된 기술의 유용성은 체세포 에서 시작하는 축삭 돌기 재구성인 시작된 축삭 돌기 재구성을 위해 테스트되었다. 초기 분할 및 응집 단계 후, 종료는 다음과 같은 방식으로 여기에 공개된 기술을 사용하여 쿼리되었다: 축삭 돌기 종료가 감지되었고 여기에 공개된 기술은 2.5μm 길이의 새로운 응집체가 발견되거나 여러 정지 기준 중 하나가 충족될 때까지 이를 추적 했다. 병합 오류를 피하기 위해, 새로운 응집체는 여기에 공개된 기술이 역방향 추적을 검증하고 여러 유형 및 각도 기준을 충족하는 경우에만 추가되었다. 여기에 공개된 축삭 돌기 훈련 기술이 실패하면 척추 목에서 훈련된 두 번째 창의적인 추적자가 사용되었다. 축삭 돌기당 20번의 반복을 수행한 결과, 여기에 공개된 기술은 축 삭 돌기 기억(recall)을 7%에서 37%로 확장할 수 있고(중간값: 6%에서 44%로, 정밀도는 >99%에서 74%로 감소), 이를 통해 마우스 피질의 국소적 층내 연결성에 해당하는 한 면이 약 200~300μm인 볼륨에서 국소 연결체 분석 이 가능해졌음이 확인되었다. 얇은 축삭 돌기와 유사하게 얇은 척추 목은 현재 재구성 파이프라인에 어려움을 줄 수 있다. 그러나 척추 헤드 에 대한 시냅스를 올바른 세포에 할당하려면 척추 목을 높은 정밀도로 재구성해야 한다. 따라서, 여기에 공개된 기술이 전역 응집(100%/43%)과 국소 응집(100%/75%)에서 척추 헤드 부착 정밀도/재현율을 개선할 수 있는지 테 스트되었다(Motta et al., loc. cit.에서와 유사한 전략). 이를 위해, 여기에 공개된 기술은 예측 불확실성이 가장 낮은 두 후보 방향에 대해 감지된 척추 헤드에서 추적을 시작한다. 여기에 공개된 창의적인 기술은 최대 7 μm 또는 충분한 크기의 수상 돌기 응집체에 도달할 때까지 추적한다. 후보자 순서, 유형 및 부착 정보를 사용 하여 척추 헤드를 수상 돌기 응집체에 추가한다. 이를 통해 척추 헤드 부착 리콜이 75%에서 94%로 향상되고 97% 의 높은 정밀도가 유지된다. 창의적인 기술은 또한 플러드 필링 네트워크(M. Januszewski et al. 2018. \"High-Precision Automated Reconstruction of Neurons with Flood-Filling Networks.\" Nature Methods. https://doi.org/10.1038/s41592-018-0049-4)와 같은 기술에 비해 향상된다. 플러드 필링 네트워크 분할에서 자동으로 감지된 종료에 대해 창의적인 기술을 적용하면 서브 볼륨 전체에서 추적된 축삭 돌기의 무작위 세트의 분할 중 60%를 해결하여 분할 비율을 65-70 splits/mm에서 28-31 splits /mm로 줄이는 반면, 새로운 병합 오류 는 거의 발생하지 않는다(병합 비율은 3-4 mergers/mm에서 5-6 mergers/mm로 증가). 특히, mm3-크기 볼륨 내의 체세포에 반드시 연결되지 않은 무작위 축삭 돌기에 대한 평가는 체세포 근위 축삭 돌기에 대한 제한보다 재구 성 품질에 대한 더 나은 그림을 제공한다. 볼륨 내의 체세포에 연결된 축삭 돌기에 국한된 플러드 필링 네트워 크를 평가한 것은 이전에 재구성 성능을 보여주기 위해 사용되었으며(Januszewski et al., 2018), 무작위 축삭 돌기의 분할 및 병합 오류를 3~4배(15~22 splits/mm, 0.2~1.1 mergers/mm) 과소평가한다. 이러한 결과에서 알 수 있듯이, 여기에 공개된 기술은 광범위한 사례에 대한 완전 자동 주석 기술로 사용될 수 있으며 현재 사용 가능한 모든 자동 분할을 개선할 수 있는 충분히 직교적인 데이터를 생성한다. 이는 현재 최 첨단 기술인 플러드 필링 네트워크(FNNs)를 사용하여 얻은 분할에서 특히 두드러졌다. 여기에 공개된 창의적 기 술의 계산 복잡도는 다른 접근 방식보다 유리하게 낮으며, 창의적 기술의 직접적인 엔드투엔드 전략을 통해 추 가 정확도와 계산 효율성 모두에 대한 최적화가 가능해질 수 있으며, 이는 엑사바이트 규모 데이터 세트에 대한 연결체학의 다음 주요 과제가 될 것이다 (A. Motta et al. 2019. \"Big data in nanoscale connectomics, and the greed for training labels\". CurrOpNeurobiol. Volume 55, April 2019, Pages 180-187). 다른 이미지 처리 접근 방식과 비교한 효율성(Efficiency compared to Other Image Processing Approaches) 계산 비용을 추정하기 위해, 우리는 (A. Motta et al. 2019. \"Dense Connectomic Reconstruction in Layer 4 of the Somatosensory Cortex.\" Science. Vol 366. Issue 6469. p. eaay3134)에 첫 번째 종료 감지 세트에서 ~128,000개의 종료 작업에 대해 여기에 공개된 창의적인 기술을 벤치마킹했다. 스텝 크기 계수는 f = 5로 설정 되었고, 포물선을 따라 비숍 프레임에 대한 분석적으로 도출된 방정식은 조향 예측을 통합하는 데 사용되었다. 32개 코어(Intel(R) Xeon(R) Gold 6130 CPU, 2 sockets), 단일 Tesla V100 GPU(PCIE-16GB) 및 128GB 미만 RAM 을 사용하는 단일 노드에서 총 런타임은 약 2.1m의 축삭 돌기를 재구성하는 데 13.6시간(역방향 검증 추적, 총 6,400만 개의 컨볼루션 신경망 추론 포함)이 소요되었으며, 따라서 재구성 속도는 약 160mm/h(~1,300 steps/s, 평균 단계 크기 33nm)였다. 이와 f = 1 및 전방 오일러 방법을 사용하여 적분한 창의적인 기술의 이전 실행에서 우리는 축삭 돌기 및 척추 목 추적(4.3미터)에 대해 총 27.9시간, 초기 방향 예측(~138,000개의 척추 헤드)에 대해 7.6시간이 소요되고, 이는 (Motta et al., 2019)의 재구성 상태에서 인간의 개입이 이루어지기 전 자동 오 류 수정에 대해 단일 노드에서의 결과로, 총 35 GPU 노드 시간이 소요될 것으로 추정했다. 플러드 필링 네트워 크(FFL)의 경우 6.964 GPU 노드 시간을 1000개(NVIDIA P100) GPU(Januszewski et al., 2018)로 곱했다. 로컬 셰이프 디스크립터(Local Shape Descriptors)의 경우, AcRLSD 아키텍처(Sheridan et al 2021. \"Local Shape Descriptors for Neuron Segmentation.\" bioRxiv, 2021.01.18.427039v1. doi: 10.1101/2021.01.18.427039v1) 는 유역(watershed)와 응집은 100개의 코어로 7.7개의 CPU 노드 시간이 걸렸다. (Motta et al., 2019)의 경우, 분할, 응집, 유형 및 시냅스 예측과 인간 골격 재구성 처리를 포함한 고밀도 재구성에는 각각 16개의 CPU 코어 가 있는 24개 노드에서 101시간이 소요되었다. 모든 방법에서 CPU 및 GPU 시간은 각 데이터 세트 크기의 비율로 곱해졌으며(Motta et al., 2019), 아래 표에 제공된 계산 비용 추정치가 도출되었다.표 1 접근법(approach) 하드웨어(hardware) RuntimeCPU core hoursGPU 노드 시 간Dataset size factorCompute cost estimates 플러드 필링 네트워크 (Januszewski et al., 2018)1000x NVIDIA Tesla P100 nodes 6.964 h- 69640.5 3482 GPU hours 밀도 재구성 (Motta et al., 2019)24x CPU nodes with 16 CPU cores each @ 16 GB RAM / core101 h 38.8 k 1 38800 CPU core hours LSD (AcRLSD) (Sheridan et al., 2021)24x NVIDIA Tesla V100 nodes for CNN inference (3.808 USD/h/V100) 100 CPU cores for watershed and agglomeration10.5 h 7.7 h- 770252 -0.7 176.4 GPU hours 539 CPU core hours 여기에 공개된 창의적인 기술1x NVIDIA Tesla V100 node with 32 CPU cores @ 128GB RAM35 h - 35 1 35 GPU hours 표: 비용 추정치 계산 다른 기술(예: 오류 교정기)과 결합된 이미지 처리 시스템 및 방법의 동작(Operation of the Image Processing Systems and Methods in Combination with Other Techniques (e.g., as Error Corrector)) 여기에서 공개된 3D EM 데이터 또는 기타 체적 이미지 데이터의 처리, 훈련된 AI 모델을 사용하는 것은 다른 재 구성 기술과 결합될 수 있다. 예를 들어, 여기에 공개된 기술은 기존 주석 또는 추적 기술과 관련하여 인간 주 석을 대체하기 위해 연결체 재구성(또는 기타 3D 세장형 객체 추적)을 수행하는 데 사용될 수 있다. 여기에 공 개된 기술은 오류 정정기로 사용될 때 관련 볼륨의 완전 자동화된 연결체 재구성을 가능하게 한다. 실시예에서, 여기에 공개된 이미지 처리 시스템 및 방법은 다른 재구성 기술과 연관하여 사용될 수 있다. 예를 들어, - 자동화된 재구성 프로세스가 실행될 수 있다, - 자동 재구성의 누락된 연속을 감지하는 것에 대응하여, 여기에 공개된 반복 기법은 해당 위치에서 시작될 수 있으며, 다른 자동 재구성된 구성 요소를 찾을 때까지 실행될 수 있다. 그리고, 그 점부터, - 선택적으로, 다른 자동 재구성된 구성 요소를 찾은 것에 대한 응답으로, 여기에 공개된 반복 기법은 동일한 시작 위치에서 종료되는지 재확인하기 위해 역방향으로 실행될 수 있고(확인 목적으로), - 위에 정의된 절차에 따른 골격 재구성은 자동 재구성의 오류를 수정하는데 사용될 수 있으며, 선택적으로 반 복적인 방식으로 사용될 수 있다. 또한, 예를 들어, - 자동화된 재구성 프로세스가 실행될 수 있다, - 자동화된 재구성의 잘못된 연속 또는 병합 오류를 감지하는 것에 대응하여 여기에 공개된 반복 기술은 오류 주변의 여러 위치에서 시작될 수 있으며 오류 위치 주변의 경계 상자를 벗어날 때까지 실행될 수 있고, 및 - 선택적으로, 오류 위치 주변에 경계 상자를 남겨두는 것에 대한 응답으로, 여기에 공개된 반복 기법은 동일한 시작 위치에서 끝나는지 다시 확인하기 위해 역방향으로 실행될 수 있고(검증 목적으로),- 위에 정의된 절차의 골격 재구성은 자동 재구성의 오류를 수정하는 데 사용될 수 있으며, 선택적으로 반복적 방식으로 사용될 수 있으며, 선택적으로 누락된 연속 부분을 탐지하고 수정하는 반복 작업과 함께 사용될 수도 있다. 도 17은 방법의 흐름도이다. 방법은 이미지 처리 시스템에 의해 자동으로 수행될 수 있다. 161단계에서 초기 3D 이미지 분석이 수행된다. 초기 3D 이미지 분석은 3D 연결체 재구성을 얻기 위해 수행될 수 있다. A. Motta et al. 2019. \"Dense Connectomic Reconstruction in Layer 4 of the Somatosensory Cortex.\" Science. Vol 366. Issue 6469. p. eaay3134 또는 M. Januszewski et al. 2018. \"High-Precision Automated Reconstruction of Neurons with Flood-Filling Networks.\" Nature Methods. https://doi.org/10.1038/s41592-018-0049-4에 기술된 것과 같은 기술을 사용하여 단계 161을 구현할 수 있지 만, 이에 국한되지는 않는다. 162단계에서, 여기에 공개된 이미지 처리 시스템 또는 방법은 오류 교정기 역할을 하는 데 사용될 수 있다. 이 미지 처리 시스템 또는 방법은 다른 자동화된 기술이 이미지 데이터에 주석을 달 수 없는 경우 신경 돌기(예: 축삭 돌기) 추적에 사용될 수 있다. 예를 들어, 여기에 공개된 기술은 이전에 인간 주석이 필요했던 A. Motta et al. 2019. \"Dense Connectomic Reconstruction in Layer 4 of the Somatosensory Cortex.\" Science. Vol 366. Issue 6469. p. eaay3134(모든 감지의 38%가 주석자의 약 900시간 작업 시간을 소모)의 기술을 사용하여 결정된 모든 감지된 척추 헤드에 적용 되었다. 89%/84%의 부착된 척추 헤드의 정밀도/재현율이 달성되었으며, 인간 결정의 정밀도에 근접했다. 인간 주석자에게 제공된 척추 헤드 감지의 시작 위치가 사용되었다. 그런 다음 여기에 공개된 기술의 방향 예측이 수 행되었다. 여기에 공개된 기술의 반복적 추론 모드는 예측 불확실성이 가장 낮은 후보 방향에 적용되었고, 수상 돌기 마스크에 의해 정의된 수상 돌기 줄기에 도달하거나 경로 길이 임계값을 초과할 때까지 추적이 수행되었다. 특히 위에 보고된 정밀도/재현율은 척추 목에서 여기에 공개된 기술을 재교육하지 않고도 달성되었 다. 척추 목에서 전용 훈련 세트로 훈련하면 더욱 개선할 수 있다. 이전에 주석자의 수천 시간 작업 시간을 소모했던 축삭 돌기 재구성에서 분할 및 병합 오류를 수정하기 위해 A. Motta et al. 2019. \"Dense Connectomic Reconstruction in Layer 4 of the Somatosensory Cortex.\" Science. Vol 366. Issue 6469. p. eaay3134 의 기술에서 시작 위치와 방향이 여기에 공개된 방법 및 시스템에 제공되었 다. 분할 오류 해결을 위해, 여기에 공개된 기술은 작은 구간에 적용되었고, 각 구간은 방법을 역순으로 실행하 여 검증되었다. 검증이 성공한 경우에만 알려진 축삭 돌기 또는 데이터 세트 끝에 도달할 때까지 다음 구간에서 추적이 계속되었다. 그 결과 생성된 골격 추적은 인간 주석과 유사하게 사용될 수 있다. 병합 오류 해결을 위해 정지 기준은 병합 오류 주변의 경계 상자를 기반으로 하며 - 다시 인간과 유사하게 - 역방향 검증에서 일부 오 류 허용 범위로 동일한 골격 재구성이 생성되면 추적이 허용되었다. 분할 및 병합 오류 해결은 나머지 오류가 임계값 아래로 떨어질 때까지 반복적으로 실행되었다. 이 완전 자동화된 접근 방식을 통해 최종 축삭 돌기를 재 구성한 결과, 대표적인 10개 축삭 돌기(1.7mm) 셋에서 12 split errors/mm와 16 merge errors/mm가 나타났으며, 이는 인간 주석의 오류율(5 split errors/mm 와 12 merge errors/mm)과 비슷하고 근접한 수치이며, 기존 자동 기술(인간 주석 이전 Motta et al 2019: 32 split errors/mm 와 14 merge errors/mm)보다 우수한 성능을 보였다. 방향 예측(Direction Prediction) 여기서 논의된 바와 같이, 이미지 처리 시스템 및 방법은 세장형 객체가 확장하는 로컬 방향(비행 방향이라고 함)을 반복적으로 결정하여 세장형 객체를 추적하도록 동작한다. 초기 방향(즉, 첫 번째 반복에서 AI 모델이 분석할 서브 볼륨을 선택하는 데 사용되는 방향)은 사용자 입력으로 지정할 수 있다. 이미지 처리 시스템은 GUI를 제어하여 여기에 공개된 세장형 객체 추적 기술에 의한 후속 사용 을 위한 해당 사용자 입력을 활성화하도록 동작할 수 있다. 또는 이런 방식으로 초기 방향을 얻을 수 없고 사전 에 알 수 없는 경우, 초기 방향을 임의의 방향으로 설정할 수 있다(AI 모델은 일반적으로 훈련을 고려하여 프로 세스를 중앙선으로 다시 안내한다). 또는, 보다 타겟팅된 접근 방식이 여러 후보 방향에 대해 사용되는 몬테카 를로 드롭아웃에서 사용될 수 있다. 후보자로부터 방향 선택을 구현하는 것은 이미지 처리 시스템 및 방법에 의 해 추정된 안정성에 따라 달라질 수 있다. 더 견고한 예측(즉, 불확실성이 더 작은 방향 예측)은 선택 프로세스 에서 불확실성이 더 높은 예측보다 우선시된다. 도 18은 방법 165의 흐름도이다. 방법 165는 이미지 처리 시스템 또는 방법에 의해 자동적으로 수행될 수 있다. 166 단계에서, 방향 샘플링이 수행된다. 단위 구의 표면에서 등거리 또는 대략 등거리일 수 있는 방향 집합을 샘플링할 수 있다. 167단계에서, 다양한 방향에 대한 불확실성 추정치가 계산될 수 있다. 불확실성 추정치의 계산은 다양한 방법으 로 수행될 수 있다. 예를 들어, 불확실성 추정치는 몬테카를로 드롭아웃을 실행하고, 방향 추정치(예: 비숍 곡 률)의 공분산을 방향당 계산하고, 방향 추정치의 공분산 행렬을 기반으로 불확실성 추정치를 결정하는 프로세스 를 사용하여 여러 방향에 대해 결정될 수 있다. 168단계에서 불확실성 추정치를 기반으로 하나 또는 여러 방향(예: 재귀 추론의 초기 방향)이 결정될 수 있다. 동작 및 효과(Operation & Effects) 이미지 처리 시스템과 방법은 자동화된 축삭 돌기 추적을 수행할 수 있는 기술 에 대한 필요성을 해결한다(다른 응용 프로그램에도 적용 가능). 이미지 처리 시스템 및 방법은 비행 재구성 작업과 유사한 방식으로 축삭 돌기 재구성을 처리하여 체적(복셀) 재구성이 아닌 방문한 점의 시퀀스를 통해 골격을 생성한다. 이미지 처리 시스템 및 방법은 원시 EM 데이터로부 터 직접 연결체학 분야에서 골격 재구성을 예측하기 위한 자동화된 접근 방식을 제공한다. 이미지 처리 시스템과 방법은 엔드 투 엔드(end to end) 최적화의 가능성을 제공한다. 이미지 처리 시스템과 방 법은 신경 돌기 재구성의 본질에 초점을 맞춘다: 즉, 데이터 세트를 통해 긴거리에 걸쳐 신경 돌기를 추적한다. 이미지 처리 시스템과 방법은 신경 돌기 재구성과 골격 수준의 오류 측정법이 염색이나 영상 인공물이 있는 경 우 등 개별 복셀의 친화도에 모호성이 발생하는 복셀 기반 방법보다 더욱 강력하다는 사실을 활용한다. 이미지 처리 시스템 및 방법은 복셀 기반이 아닌 골격 기반인 신경 돌기 추적을 위한 새로운 접근법을 제공하며, 좋은 결과를 보여준다. 도 19 및 20은 이미지 처리 시스템 및 방법의 동작을 보여준다. 이미지 처리 시스템 및 방법은 이미지 데이터로 표현된 3D 볼륨을 통해 신경 돌기(예: 축삭 돌기)를 추적하도록 동작한다. 여기서 추적은 3D에서 일련의 점을 결정하거나 3D에서 신경 돌기의 추적을 지정하는 연속적인 곡선을 결정하는 것을 의미한다. 서브 볼륨 172- 274의 시리즈 171은 여기에 공개된 기술을 사용하여 분석된다. 비행 방향을 따라 간격을 둔 여러 개의 평면 175(예: 16개 평면)에는 각각 보간 또는 투영(예: 삼선형 투영)과 같은 기술을 사용하여 원본 이미지 데이터에 서 결정된 이미지 데이터가 포함된다. 막으로부터의 거리와 같은 정보는 예를 들어 AI 모델 훈련에서 결정되어 사용될 수 있다. 또한, 다른 방법에 의해 예측된 막 확률 176은 AI 모델에 입력으로 제공될 수 있지만, 실험에 서 이는 초기 훈련 단계에서만 도움이 되었고, 궁극적으로 원시 EM 데이터 175는 이 방법이 성공하기에 충분한 신경 돌기 연속 정보를 제공한다. 도 20은 여기에 공개된 기술에서 사용될 수 있는 비숍 프레임과 같은 국소 가변 좌표 프레임 180을 보여준다. 효과적으로, 이미지 처리 시스템 및 방법은 더 큰 조직 볼륨의 서브 볼륨을 순차적으로 분석하여 동작하며, 서 브 볼륨은 3D에서 세장형 객체 중심선의 이미 추적된 부분을 따라 비행할 때 보이는 시야를 나타낸다. 비숍 곡 률 벡터 185는 AI 모델의 출력일 수 있으며 중심선을 따라 새로운 점을 결정하기 위해 적분될 수 있다. AI 모델을 훈련하는 기술도 자세히 설명된다. 설명한 대로, 중심선에서 벗어난 위치 및/또는 방향에 대해 AI 모 델을 훈련하면 안정성이 향상된다. 위에서 기존 기술과의 비교와 관련하여 설명한 바와 같이, 축삭 돌기 추적이 나 척추 목에 대한 응용 프로그램과 같은 복잡한 작업에서도 약 14 errors/mm의 낮은 오류율이 달성되었다. 오 류율은 도 21의 그래프 190에서 볼 수 있듯이 훈련 반복 횟수가 증가함에 따라 포화된다. 예시에서 약 700,000 번의 훈련 반복이 성능 평가를 위해 여기에 사용되었다. 더 큰 훈련 세트는 포화를 위해 더 많은 훈련 반복이 필요할 수 있다. 여기에 공개된 이미지 처리 시스템 및 방법은 연결체 재구성(도 22), 생검 샘플 분석(도 27) 및/또는 신경 과학 에서 영감을 받은 인공 지능(도 28)과 같은 다양한 응용 분야에 사용될 수 있다. 도 22는 방법 200의 흐름도이다. 방법 200은 여기에 공개된 바와 같이 이미지 처리 시스템을 사용하여 수행될 수 있다. 201단계에서 3D EM 이미지 획득이 수행된다. 3D EM 이미지 획득은 생검 샘플에서 수행될 수 있다. 생 검 샘플은 이미징 후 살아있는 동물이나 인간에게 다시 이식되지 않은 샘플이다. 202단계에서, 적어도 하나의 신경 돌기의 추적이 결정된다. 여러 신경 돌기의 추적은 예를 들어, 이미지 처리 시스템의 여러 인스턴스를 병렬로 동작하여 동시에 결정될 수 있다. 또한 이 단계는 반복적 재구성을 위한 보다복잡한 논리를 포함할 수 있으며, 도 5의 모듈 80을 서브 모듈로 포함할 수 있다. 203단계에서 종료 기준이 확인된다. 종료 기준이 충족되지 않으면 방법은 202단계로 돌아간다. 관심 있는 모든 신경 돌기가 추적될 때까지 방법은 계속될 수 있다. 이런 방식으로, 여러 신경 돌기가 볼륨에서 추적될 수 있다. 신경 돌기 추적은 예를 들어 축삭 돌기 연결체를 결정하는 것과 같은 축삭 돌기를 추적하는 것 및/또는 수상 돌기를 추적하는 것을 포함할 수 있다. 204 단계에서, 시냅스 정보가 계산된다. 이는 당업자에게 알려진 시냅스 인터페이스 분류기를 사용하여 수행할 수 있지만, 이에 국한되지 않는다. 205단계에서 종료 기준이 충족되면(예: 관심 있는 모든 신경 돌기가 추적된 경우) 결과가 출력될 수 있다. 결과 는 GUI 또는 데이터 인터페이스를 통해 출력될 수 있지만, 이에 국한되지 않는다. 도 23은 연결체학의(connectomics) 분석과 관련하여 다양한 용도에 필요한 오류율을 나타낸 그래프 210이다. 발 명의 방법 및 시스템을 통해 달성된 낮은 오류율과 연속적인 오류 간의 큰 간격은 영역 211에서 설명되는 바와 같이, 이러한 기술을 기존의 컴퓨터 기술로는 쉽게 해결할 수 없었던 사용 사례에 적용할 수 있는 여지를 제공 한다. 도 24는 최근 몇 년 동안 사용 가능한 기술의 함수로서 1mm 주석에 필요한 시간의 변화를 나타낸 그래프 220이 다. Motta et al. 2019. \"Dense Connectomic Reconstruction in Layer 4 of the Somatosensory Cortex.\" Science. Vol 366. Issue 6469. p. eaay3134의 기술은 개선 221을 제공한다. 더 나아가, 여기에 공개된 발명의 방법 및 시스템에 의해 주석 소비율의 매우 현저한 감소 222가 제공된다. 도 25는 무작위로 시작된 축삭 돌기에 대해 보고된 축삭 돌기 분할 및 병합 속도를 정량화한 그래프 230이다. 결과 231은 인간 대뇌 피질의 플러드 필링 네트워크 기반 재구성에 대해 얻어졌다(A. Shapson-Coe et al. . \"A connectomic study of a petascale fragment of human cerebral cortex.\" bioRxiv, 2021.2005.2029.446289. doi: 10.1101/2021.05.29.446289 ). 여기에 공개된 기술은 분석된 두 분할 상태 모두에서 상당히 개선된 결과 241을 제공하며, 병합 속도가 증가한다. 분할 속도 요구 사항은 축삭 돌기를 따라 시냅스 속도에 따라 달라진다: 축삭 돌기당 최소 5개의 시냅스의 경우 일반적인 마우스 축삭 돌기와 사람 축삭 돌기의 경우 각각 mm당 40개 미만의 분할 속도와 mm당 20개 미만의 분할 속도가 요구된다. 따라서 자동화를 이 러한 체제로 옮기는 것은 더 어려운 연결체학의 분석에 바람직하다. 여기에 공개된 방법 및 시스템은 마우스 피 질에서 얻은 대규모 데이터에 대한 고밀도로 시작된 축삭 돌기 재구성을 개선했다. 결과 232는 개선된 결과 242 를 제공하는 창의적인 기술과 비교했을 때 기존 기술(미공개)을 사용하여 얻었다. SBEM 데이터의 경우, 여기에 공개된 방법 및 시스템은 사용된 분석에 대한 인간 주석을 완전히 대체할 수 있게 하여 Motta et al., loc. cit.의 기존 기술을 사용하여 얻은 결과 233보다 개선되었다. 여기에 공개된 방법 및 시스템을 통해 얻은 개선 된 결과는 243에 표시되어 있다. 사람의 주석(검은색 대시 선)에서 얻을 수 있는 2배 추가 개선의 잠재적인 이 점은 수행된 분석에는 관련이 없다. 도 26은 무작위로 시작된 축삭 돌기에 대해 보고된 축삭 돌기 분할 및 합병 속도를 정량화한 추가 그래프 260이 다. 도 26의 경우, 이 기술은 최첨단 고처리량 3D EM 이미징 접근법을 사용하여 얻은 3D EM 데이터에 적용한 다 음 다중빔 주사 전자 현미경(multiSEM)을 사용했다. 데이터는 마우스 피질과 인간 피질 모두에서 얻었다. 데이 터 261, 262, 263은 기존 기술에 해당한다. 데이터 264는 인간 주석을 추가로 사용하여 얻은 데이터에 해당한다. 데이터 271, 272, 273은 여기에 공개된 방법 및 시스템을 사용하여 얻은 데이터에 해당한다. 자동화된 응집 후, 여기에 공개된 방법 및 시스템은 자동으로 감지된 축삭 돌기 응집체의 말단(ending)에서 시 작되었고, 분할된 축삭 돌기 응집체를 연결하는 데 사용되었다. 그 결과, 축삭 돌기의 분할 속도는 7배 감소(축 삭 돌기 경로 길이 mm당 42.7에서 6.0으로)한 반면, 병합 속도는 약간만 증가했다(도 26의 상단 데이터 포인트 262와 하단 데이터 포인트 272 비교에서 볼 수 있듯이 mm당 3.3에서 4.5로). 동일한 병합 오류율(mm 축삭 돌기 경로 길이당 3.9 병합 오류)에서 분할 속도를 더 높은 응집과 직접 비교할 때, 응집은 분할 오류의 25%만 해결 하여 mm당 31.9 분할을 생성하는 반면, 여기에 공개된 방법 및 시스템은 79%를 해결하여 mm당 9.0 분할을 생성 한다. 따라서 이 분할/병합 오류 체제에서 여기에 공개된 방법 및 시스템은 표준 응집에 비해 분할 해상도를 3.1배 향상시킨다(도 26, 데이터 포인트 262 대 최상위 데이터 포인트 272). 여기에 공개된 방법 및 시스템은 A. Shapson-Coe et al. . \"A connectomic study of a petascale fragment of human cerebral cortex.\" bioRxiv, 2021.2005.2029.446289. doi: 10.1101/2021.05.29.446289에서 크기 (150 μm)3의 서브 볼륨에서 평가되었으며, 여기에 공개된 방법 및 시스템을 플러드 필링 네트 워크 분할(M. Januszewski et al., \"High-precision automated reconstruction of neurons with flood- filling networks.\" Nat Methods. 2018 Aug;15:605-610. doi: 10.1038/s41592-018-0049-4. Epub 2018 Jul 16. PMID: 30013046)의 밀집 재구성에서 얻은 축삭 돌기 말단에 적용하면 서브 볼륨 전체에서 추적된 무작위 축 삭 돌기 세트의 분할의 57%를 해결한다는 것을 발견했다. 이는 분할 비율을 65 splits/mm에서 28 splits/mm로 줄여 자동화된 연결체 분석에 필요한 분할 길이에 도달하는 동시에 연구된 연결체 분석의 종류에 예를 들어 마 우스 피질 SBEM 재구성의 맥락에서 대해 허용 가능한 병합 비율인 새로운 병합 오류(도 26에서 데이터 포인트 261(아래)은 데이터 포인트 271(아래)와 비교한 것이 병합 비율은 1.7 mergers/mm에서 3.1 mergers/mm로 증가 했다)를 거의 도입하지 않았다. 플러드 필링 네트워크와 여기에 공개된 방법 및 시스템에 대해 동일한 병합 오 류율(c2: 1.7 mergers/mm)에서 분할 오류 감소를 비교할 때, c3에서 c2로의 플러드 필링 네트워크 기반 응집은 c3의 분할 오류의 8%만 해결한다는 것을 알 수 있다. 이와 대조적으로, 여기에 공개된 방법 및 시스템을 기반으 로 한 응집은 c2와 동일한 병합 오류율에서 c3의 분할 오류의 28%를 해결하여 플러드 필링 네트워크보다 분할 해결 측면에서 3.5배 더 효과적이다(도 26, 데이터 포인트 261(위)과 261(아래) 및 271(위) 비교). 더 자세히 설명하면, 도 26은 무작위로 시작된 축삭 돌기에 대해 보고된 축삭 돌기 분리 및 합병 속도의 정량화 를 보여준다. 인간 대뇌 피질의 재구성에 기반한 플러드 필링 네트워크의 경우(A. Shapson-Coe et al. . \"A connectomic study of a petascale fragment of human cerebral cortex.\" bioRxiv, 2021.2005.2029.446289. doi: 10.1101/2021.05.29.446289 ), 두 가지 응집 상태가 분석되었다(c2, c3). c3에서 c2로 플러드 필링 네트워크의 응집 파라미터를 변경하면 밀집 축삭 돌기에서 c3 분할의 8%만 해결되지만 (플러드 필링 네트워크 데이터 포인트 261), 여기에 공개된 방법 및 시스템을 사용하여 가장 높은 확실성으로 얻은 검증된 추적의 상위 40%를 c3 끝에서 적용하면 c2와 동일한 병합 오류율에서 분할 오류의 28%를 해결하여 분할 해상도가 3.5배 향상된다(데이터 포인트 271). mm당 1.4개의 병합 오류만 약간 증가하면, 여기에 공개된 방법과 시스템을 사용하여 얻은 모든 검증된 추적을 c2 엔딩에서 적용하면 분할 속도가 mm당 65개 분할에서 mm 당 28개 분할로 더욱 감소하여 c2 분할 오류의 57%를 해결한다. 예를 들어, 인간 피질 분할 속도가 mm당 30회 미만(약 ≥30μm 축삭 돌기 조각)이면 흥분성 축삭 돌기 조각과 억제성 축삭 돌기 조각을 정확하게 구별이 요구 되는(S. Loomba et al. . \"Connectomic comparison of mouse and human cortex.\" Science. 2022 Jul 8;377:eabo0924. doi: 10.1126/science.abo0924. Epub 2022 Jul 8. PMID: 35737810참조) 반면, 마우스 피질에서 동일한 분할 속도일 때 축삭 돌기 조각당 연관된 ≥10개 시냅스는 예를 들어 억제성 표적 특이성 분석 을 가능하게 한다 (A. Motta et al. . \"Dense connectomic reconstruction in layer 4 of the somatosensory cortex.\" Science: eaay3134). 따라서 자동화를 이 체제로 옮기는 것이 대부분의 연결체 분석에 중요하다. 마우스 피질의 대규모 데이터(Si150L4, https://wklink.org/7122에서 접근 가능)의 경우, 여기에 공 개된 방법과 시스템은 밀집되어 시작된 축삭 돌기 재구성을 7배 개선하는 반면, 병합 오류는 mm당 3.3에서 4.5 로 약간만 증가시킨다. 90% 응집 임계값을 기준으로, 여기에 공개된 방법 및 시스템을 사용하여 얻은 추적을 부 분적으로 적용하면 동일한 병합 오류율이 생성되고 응집보다 분할을 3.1배 더 효과적으로 줄일 수 있다. SBEM 데이터의 경우, 여기에 공개된 방법 및 시스템을 사용하면 사용된 분석에 대한 인간 주석을 완전히 대체할 수 있다(A. Motta et al. . \"Dense connectomic reconstruction in layer 4 of the somatosensory cortex.\" Science: eaay3134). 수동 주석(데이터 264에 대한 검은색 점선)의 2배의 추가 이점은 해당 연구에서 수행된 분석과 관련이 없었다. 국부 회로의 완전 자동화된 분석의 경우 mm당 10 미만의 오류율이 바람직하다. 이러한 오류율은 여기에 공개된 기술(데이터 272, 273)을 사용하여 얻을 수 있다. 여기에 공개된 방법 및 시스템(도 26)에 의해 수행된 오류 수정 전후 응집체의 분할 및 병합 오류 평가를 위해, 실제에서 2.2μm 이상 확장된 병합 오류가 감지되었고 이 휴리스틱이 병합 오류를 정확하게 감지하는지 수동으 로 검증했다. 여기에 공개된 방법 및 시스템에 의해 수행된 수정 이전의 응집체의 경우, 각 병합 오류는 1/2로 계산되고 실제 경로 길이로 나누어 병합 오류율을 산출했다. 이는 각 병합 오류가 일반적으로 두 개의 신경 돌 기를 연결하고 이를 1/2 대신 신경 돌기당 1개의 오류로 계산하면 병합 오류의 총량을 과대평가하기 때문이다. 여기에 공개된 방법 및 시스템에서 수행한 오류 수정의 희소 평가의 경우, 평가된 두 multiSEM 데이터 세트에서 수행된 것처럼 실제값과 겹치는 응집체로 제한되어, 여기에 공개된 방법 및 시스템에서 도입한 추가 병합은 0.5 대신 1로 계산되었으며, 이는 실제값과 겹치지 않는 응집체의 병합을 설명하며, 따라서 희소 평가에서 관찰할 수 없다. 분할 오류의 경우 응집체 집합은 실제값과 2.5μm 이상 겹치는 응집체로만 평가되도록 제한되었다. 이 오버랩 임계값은 얇은 축삭 돌기 구간을 따라 많은 작은 응집체 또는 응집되지 않은 세그먼트가 분할 오류를 지 배하는 것을 피하기 위해 도입되었다. 이 오버랩 길이 임계값에도 불구하고 실제값의 약 90%가 여전히 포함되었다. 여기에 공개된 방법 및 시스템을 기반으로 한 수정이 두 개의 multiSEM 데이터 세트에 대한 분할/응집과 동일한 병합 오류율에서 비교했을 때 분할 오류율도 감소시키는지 테스트하기 위해, 여기에 공개된 방법 및 시스템을 사용하여 얻은 추적의 서브 집합만 적용하여 병합 오류율을 제한하는 다음 전략을 사용했다: 몬테카를로 드롭아 웃을 사용한 예측 불확실성은 이전에 척추 목 방향을 식별하는데 사용된 것처럼 여기에 공개된 방법 및 시스템 에 의해 수행된 모든 단계에 대해 정량화되었다. 그런 다음 단계에 대한 최대 불확실성이 취해졌고, 전방 및 검 증 추적이 두 불확실성 점수의 최소값과 결합되었다. 따라서 이 접근 방식은 먼저 최대 불확실성을 가진 위치에 따라 검증된 추적의 모든 방향을 점수화한 다음, 전방 및 후방 추적이 동일한 비행 경로를 생성했기 때문에 두 불확실성 점수 중 최소값을 취해 추적 전체의 불확실성을 정량화하는 개념에 기반한다. 여기에 공개된 방법 및 시스템을 사용하여 얻은 검증된 추적을 추적 불확실성의 백분위수 0.2, 0.4, 0.6, 0.8까지 적용한 후 여기에 공 개된 방법 및 시스템에 의해 수행된 부분적 수정을 수행했다. 이것들은 분할 및 병합 오류율에 대해 평가되었으 며, 분할/응집과 동일한 병합 오류율에서 최소 분할 오류율을 가진 것들이 도 26의 분할 병합 오류 평면 내의 중간 점으로 추가되었다. 구체적으로, 마우스 피질 multiSEM 데이터 세트의 경우, 여기에 공개된 방법 및 시스 템을 사용하여 얻은 검증된 추적의 상위 80%를 85% 응집 임계값의 응집에 적용한 결과, 90% 응집 임계값의 응집 과 동일한 병합 오류율을 보였다. 마찬가지로, 인간 대뇌 피질 multiSEM 데이터 세트의 경우, 여기에 공개된 방 법 및 시스템을 사용하여 얻은 검증된 추적의 상위 40%를 플러드 필링 네트워크 c3 응집체에 적용한 결과 플러 드 필링 네트워크 c2 응집체와 동일한 병합 오류율이 나타났다 (A. Shapson-Coe et al. . \"A connectomic study of a petascale fragment of human cerebral cortex.\" bioRxiv, 2021.2005.2029.446289. doi: 10.1101/2021.05.29.446289 ). 도 27은 방법 240의 흐름도이다. 방법 240은 여기서 개시된 이미지 처리 시스템을 이용하여 또는 이미지 처리 시스템에 의해 수행될 수 있다. 241 단계에서 3D EM 이미지 획득이 수행된다. 3D EM 이미지 획득은 생검 샘플에 대해 수행될 수 있다. 생검 샘플은 이미징 후 살아있는 동물 또는 사람에게 다시 이식되지 않는 샘플이다. 241단계에서, 이미지 획득은 생검 샘플에 대해 수행된다. 이미지 획득은 이미징 후 폐기될 생검 샘플에 대한 3D EM 이미지 획득일 수 있다. 242단계에서, 적어도 하나의 신경 돌기의 흔적이 확인되었다. 여러 개의 신경 돌기의 흔적이 예를 들어, 이미지 처리 시스템의 여러 인스턴스를 병렬로 작동시키면 확인될 수 있다. 243단계에서 추적 결과가 출력된다. 결과는 GUI(예: 광학 출력 장치를 통해 연결체(connectome)의 일부에 대한 시각적 표현을 출력) 또는 데이터 인터페이스를 통해 출력될 수 있지만, 이에 국한되지는 않는다. 여기에 공개되는 이미지 처리 시스템 및 방법은 적어도 하나의 물리적 자산(예: 기계)을 제어하기 위한 처리 논 리(예: 신호 처리 논리)를 생성, 훈련 및/또는 작동하는 과정에서 사용될 수 있다. 도 28은 여기에 공개된 바와 같이 동작하는 이미지 처리 시스템을 포함하는 시스템 250을 나타낸다. 이미지 처 리 시스템은 인간 또는 다른 동물의 신경계의 연결체(부분) 및/또는 기타 구조적 정보에 대한 정보를 결정하도 록 작동할 수 있다. 시스템 250은 컨트롤러 251에 의해 제어되는 물리적 자산 252(예: 기계)를 포함한다. 컨트롤러 251은 기계 학습, ML 모델을 실행하여 신호 입력(센서 측정에서 센서 입력을 포함할 수 있음)을 처리하고 물리적 자산 252 의 동작에 영향을 미치는 제어 신호를 생성한다. 컨트롤러 251에 의해 실행되는 ML 모델은 처리 시스템 30의 제어 로직 생성 모듈 36에 의해 생성될 수 있다. 처 리 시스템 30의 제어 로직 생성 모듈 36은 연결체 분석의 결과를 다음 중 적어도 하나에 사용할 수 있다: (i) 연결체에 의존하는 ML 모델 아키텍처를 갖는 ML 모델을 선택 또는 생성; (ii) 연결체에 의존하는 ML 모델 아키 텍처를 갖는 ML 모델을 훈련; 및/또는 (iii) 연결체에 의존하는 훈련된 ML 모델을 컨트롤러 251에 신호 처리 로 직으로 배포하여 실행. 컨트롤러 251은 물리적 자산 252를 제어하기 위해 처리 시스템 30에 의해 결정된 연결체 에 의존하는 ML 모델을 실행할 수 있다. 컨트롤러 251은 또한 처리 시스템 30에 정보를 피드백할 수 있다. 예를 들어, 컨트롤러 251 및/또는 자산 252의 동작은 현장 사용 중에 모니터링될 수 있다. 처리 시스템 30은 컨트롤 러 251 및/또는 자산 252의 현장 사용 중에 객체 추적을 반복 및/또는 수정하도록 만들어질 수 있다. 이런 식으 로, 제어 논리는 현장 사용 중에 업데이트될 수 있다. 대안적으로 또는 추가적으로, 컨트롤러 251은 이미지 수집 시스템 20에 결합되어 그 동작을 제어할 수 있다. 이 는 이미지 처리 시스템 30이 수행한 이미지 처리 결과에 반응하여 수행될 수 있다. 기술(Techniques) 이미지 처리 시스템 및 방법에 구현될 수 있는 기술의 측면이 논의될 것이다. 이미지 처리 시스템 및 방법에 대 체 구현이 사용될 수 있다는 것을 알 수 있다. EM 이미지 데이터 셋(EM image data sets) 이미지 처리 시스템과 방법은 28일 된 마우스의 L4 1차 체성 감각 피질의 SBEM 데이터 세트에서 훈련 및 테스트 되었다. 조직은 기존 방식으로 en-bloc 염색(K.L. Briggman et al. 2011. \"Wiring Specificity in the Direction-Selectivity Circuit of the Retina.\" Nature 471 : 183-88)되었고, 11.24 x 11.24 nm² 및 공칭(nominal) 절단 두께 28 nm에서 이미지화되었다. 과분할은 훈련 세트 축삭 돌기의 볼륨 재구성을 생성하는 데 사용되었다. 과분할은 피질 데이터 세트의 전체 세포 분할에 대해 설정된 파라미터를 사용하여 M. Berning et al. 2015. \"SegEM: Efficient Image Analysis for High-Resolution Connectomics.\" Neuron 87 : 1193- 1206) 의 기술을 사용하여 얻어졌다. 이미지 처리 시스템과 방법은 또한 다중 빔 주사 전자 현미경으로 획득한 마우스의 배럴 피질에서 얻은 데이터 세트에서 훈련되고 테스트되었다. 조직은 Y. Hua et al. 2015. \"Large-Volume En-Bloc 599 Staining for Electron Microscopy-Based Connectomics.\" Nature Communications 6 (August): 7923의 프로토콜에 따라 약간 수정하여 염색되었고 4 x 4 nm² 및 공칭 절단 두께는 35 nm에서 이미지화되었다. 이미지 처리 시스템 및 방법은 또한 플러드 필링 네트워크(M. Januszewski et al. 2018. \"High-Precision Automated Reconstruction of Neurons with Flood-Filling Networks.\" Nature Methods. https://doi.org/10.1038/s41592-018-0049-4)를 사용하여 분할 및 응집된 복셀 크기 4 x 4 x 33 nm3(A. Shapson-Coe et al. . \"A connectomic study of a petascale fragment of human cerebral cortex.\" bioRxiv, 2021.2005.2029.446289. doi: 10.1101/2021.05.29.446289 )의 multiSEM 데이터 세트에서 평가 되었다. 골격 보간(Skeleton interpolation) 보간은 중심 축을 따라 희소하게 배치된 노드로부터 신경 돌기 가지(예: 축삭 돌기 가지)의 원하는 단계 크기로 연속적인 표현 및/또는 중앙선 노드를 얻는 데 사용될 수 있다. 보간은 4차 B-스플라인 보간(L. Piegl and W. Tiller. 1996. The NURBS Book. 2nd ed. Springer Science & Business Media.)으로 구현될 수 있다. 예를 들어, 곡선은 다음의 곡률 적응 단계 크기 를 얻기 위 해 파라미터화될 수 있다."}
{"patent_id": "10-2025-7005729", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "여기서 k 는 곡률이고, f 는 단계 크기 계수(step size factor)이고, d는 곡률이 0이고 f = 1이며, p가 투영 평면의 물리적 크기인 경우의기본 단계 크기이다. 기본 단계 크기 d는 복셀의 가장 작은 길이와 같도록 선택할 수 있다. 이 크기는 이미지 시스템에 따라 달라질 수 있으며, 예를 들어 여기의 일부 예에서 사용된 특정 SBEM 데이터 세트의 경우 11.24nm일 수 있다. 적응적 단계 크기는 컨볼루션 신경망의 현재 위치에서 투영 평면의 투영 평면 크기의 절반 반경까지의 복셀이 건너뛰어지지 않도록 보장한다. 동일한 적응적 단계 크기는 선택적으로 여기에 공개된 창의적인 기술에 대한 추 론 중에 사용되어 후속 위치 및 방향을 결정하는 통합 단계의 단계 크기를 결정할 수 있다. 비숍(Bishop) 프레임(Bishop frame) 브숍 프레임(R.L. Bishop. 1975. \"There Is More than One Way to Frame a Curve.\" The American Mathematical Monthly 82 : 246-51)은 세 개의 직교 벡터 즉, 곡선에 대한 접선 벡터(또한, 비행 벡터라고 도 함) , 그리고, 두 개의 벡터 와 로 구성된다. 비숍 프레임과 곡선 의 전개(evolution) 방정식은다음과 같다:"}
{"patent_id": "10-2025-7005729", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "여기서 s는 커브 의 호 길이이고, 곡선 를 파라미터화하여 이 성립하는 파라미터로 사용된 다. 곡선 의 임의의 파라미터화를 위해 계수까지의 유사한 방정식을 공식화할 수 있다. 여기서, k1 와 k2 는 법선 벡터 와 에 연관된 비숍 곡률이다. 여기에 개시된 기술에서 비숍 곡률은 AI 모델의 조향 예측에 해 당한다. 곡률 벡터는 + 로 정의된다. 곡선 의 곡률 k 는 이다. 특정 연산(예: 접선 벡터를 중심으로 한 플립 및 회전, 두 법선 벡터에 적용 및 비숍 곡률의 해당 변환) 하에서 곡률 벡터의 불변성 은 AI 모델과 관련하여 여기에 공개된 기술에 사용된다. 예를 들어 온라인 데이터 증강이 수행될 수 있다. 비행 방향도 플립(flip)될 수 있으며, 이는 시간 역전 대칭에 해당한다. 중심선에서 이 시간 역전 및 접선 벡터 플립 은 비숍 곡률에 영향을 미치지 않지만, 아래에서 설명하는 비행 정책의 경우 이 대칭은 깨질 수 있다. 비숍 프레임은 파라미터화된 곡선의 미분 기하학에서 로컬 좌표계로 자주 사용되는 다른 프레임(예: Frenet- Serret 프레임)보다 곡선 에 대한 요구 사항이 약하다. 예를 들어, 3D 유클리드 공간에서 파라미터화된 곡선에 대해 비숍 프레임은 를 요구하지 않는다. 비숍 곡률과 함께 초기 조건은 중심선 곡선 를 고유하게 정 의한다. 이는 비숍 곡률을 AI 모델 출력으로 특히 적합하게 만드는데, 이는 위의 전개 방정식을 통해 곡선을 재 구성할 수 있기 때문이다. N ≥ 3인 N차원 유클리드 공간에서 파라미터화된 곡선에 대해서도 비숍 프레임이 존 재하므로 동일한 수학적 프레임워크를 사용할 수 있으며 여기에 공개된 기술은 N차원 데이터에도 유사하게 적용 할 수 있다. 또한, 2차원 유클리드 공간에서 파라미터화된 곡선은 3차원 유클리드 공간에서 파라미터화된 곡선 의 특수한 경우로 간주할 수 있으므로 여기에 설명된 방법도 적용할 수 있다. 비행 정책(Flight policy) AI 모델 훈련(중심선에서 벗어난 위치에 AI 모델을 적용할 때 중심선으로의 수렴을 강제하기 위한) 중 사용 가 능한 비행 정책은 (a) 알려진 중심선 곡선 과 해당하는 비숍 프레임 , , 및 와 곡률 벡터 에 대한 2차 테일러 급수 전개, (b) 중심선에서 벗어난 위치 와 해당하는 비숍 프레임 , , 와 와 곡률 벡터 를 갖는 중심선으로 수렴하는 알려지지 않은 궤적에 대한 2차 테일러 급수 전개를 고려해 도출될 수 있 다: 중심에서 벗어난 선 위치 와 관련된 이탈 방향 와 축삭 돌기 중심선에 연관된 가장 가까운 위치 , 해당 중심선에 정렬된 방향 과 곡률 벡터 의 경우, 중심선 추적으로의 수렴은 다음과 같이 정의된 미래 거리 의 최소화로 공식화할 수 있다:"}
{"patent_id": "10-2025-7005729", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "sc의 거리(파라미터 s) 내에서 를 최소화하는 최적화 문제는 다음과 같이 표시할 수 있다:"}
{"patent_id": "10-2025-7005729", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "여기서 = . 투영 연산자(projection operator) 정의"}
{"patent_id": "10-2025-7005729", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "여기서 는 외적(outer product)을 나타내며, 최소화 문제의 해는 다음과 같이 표현될 수 있다."}
{"patent_id": "10-2025-7005729", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 7, "content": "파라미터 sc는 비행 정책의 자유 파라미터다. 위에서 논의한 바와 같이, 파라미터 sc는 막(예: 세포막)과 같은 장애물로부터 현재 중심에서 벗어난 선 위치의 거리에 따라 선택될 수 있다. 따라서 장애물(예: 막) 회피 기술 은 훈련 중에 구현될 수 있다. 위의 도출은 테일러 급수 전개(Taylor series expansion)에 기초하고 있으므로 중심선으로의 수렴은 위의 조향을 반복적으로 적용하여 달성된다. 몬테카를로 드롭아웃(Monte-Carlo Dropout)으로 방향 예측(Direction prediction with Monte-Carlo Dropout) 이 섹션에서 공개된 기술은 예를 들어 초기 조향 예측을 얻기 위한 방향 예측을 수행하는 데 사용될 수 있다. 단위 구의 표면에서 N(예: N = 256)개의 등거리 또는 대략 등거리 방향 를 샘플링할 수 있다. Monte-Carlo Dropout은 M(예: M = 128)개의 샘플로 실행할 수 있다. 샘플링된 비숍 곡률 예측 에서 비숍 곡률의 평균 곡률 및 공분산 covi를 각 방향에 대해 계산할 수 있다. 방향에 대한 불확실성 추정치는 공분산 행렬의 가 장 큰 고유값을 평균 곡률로 나눈 값의 제곱근으로 결정될 수 있다."}
{"patent_id": "10-2025-7005729", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 8, "content": "이 양은 편차 계수와 유사하다. 30도 이내의 이웃 각도에 대해 코사인 유사도를 사용하면 불확실성의 가중 평균을 다음과 같이 결정할 수 있다. 가중치로"}
{"patent_id": "10-2025-7005729", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 9, "content": "가중화된 평균이 향상된 안정성을 제공한다. 평균 불확실성이 가장 낮은 방향은 첫 번째 방향 후보로 사용될 수 있다. 척추 헤드의 경우, 첫 번째 후보로부터 적어도 110° 떨어져 있고 나머지 방향들 중에서 평균 불확실성이 가장 낮은 두 번째 후보가 선택될 수 있다. 로컬 재정렬(Local realignment) 이미 논의된 바와 같이, 로컬 재정렬은 방법 및/또는 이미징 시스템 20에서 수행될 수 있다. 로컬 재정렬은 이 미지 정렬 구성 요소 23에 의해 수행될 수 있거나, 이미징 시스템 20은 이미지 정렬 구성 요소 23에 더하여 두 번째 로컬 이미지 재정렬 구성 요소를 실행하도록 동작될 수 있다. 로컬 재정렬 기술은 적어도 부분적으로 3D EM 데이터와 연관하여 설명될 것이다. 이러한 기술은 다른 3D 이미지 데이터 또는 2D 이미지 데이터 세트와 연관하여 사용될 수도 있음이 이해될 수 있다. 로컬 재정렬은 슬라이싱 방향을 따라 이미지 데이터 슬라이스의 로컬 재정렬을 수행하기 위해 실행되는 다음 단 계를 포함할 수 있다: 슬라이싱 방향을 따라 복수의 슬라이스에 대한 슬라이스 간 이동 벡터를 결정하고; 슬라 이스 간의 유효한 슬라이스 간 이동 벡터를 식별하고; 유효한 슬라이스 간 이동 벡터를 사용하여 로컬 재정렬된 서브 볼륨을 생성한다. 로컬로 재정렬된 서브 볼륨은 AI 모델 입력, 예를 들어 컨볼루션 신경망 또는 순환 신경망의 입력 계층이나 컨 볼루션 신경망 또는 순환 신경망에서 처리되기 전에 재정렬된 서브 볼륨을 전처리하는 필터 또는 기타 전처리에 공급될 수 있다. 슬라이스 간 이동 벡터를 결정하는 것은 슬라이스의 자기 상관관계와 교차 상관관계를 결정하는 것을 포함할 수 있다. 슬라이스 간 이동 벡터 및/또는 그 유효성을 결정하는 것은 첫 번째 임계값 기준에 따라 상관 관계 가중 이동 벡터의 평균과 표준 편차를 결정하는 것을 포함할 수 있다. 유효한 슬라이스 간 이동 벡터를 식별하는 것은 결정된 자기 상관이 첫 번째 기준(예: 원하는 이동, 예를 들어 0 이동에서 피크를 갖는 것)을 충족하는지 확인하는 것을 포함할 수 있다. 유효한 슬라이스 간 이동 벡터를 식별하는 것은 결정된 자기 상관 피크가 두 번째 기준을 충족하는 표준 편차를 갖는지 확인하는 것을 포함할 수 있다(예: 두 번째 임계값 기준을 충족하는 표준 편차를 갖는 것, 즉 특정 픽셀 수보다 적거나 같음). 유효한 슬라이스 간 이동 벡터를 식별하는 것은 두 개의 연속적인 자기 및/또는 교차 상관 피크의 조합이 세 번 째 기준을 충족하는지 확인하는 것을 포함할 수 있다(예를 들어, 세 번째 임계값 기준을 충족시키는데, 여기서 세 번째 임계값 기준은 선택적으로 주변 자기 및/또는 교차 상관에 따라 달라질 수 있음). 유효한 슬라이스 간 이동 벡터를 식별하는 것은 결정된 교차 상관 관계가 두 슬라이스의 자기 상관 관계에 따라 달라지는(예: 언급된 자기 상관 관계 기준이 두 슬라이스 모두에 유효한 경우) 첫 번째 교차 상관 관계 기준을 충족하는지 확인하는 것을 포함할 수 있다. 유효한 슬라이스 간 이동 벡터를 식별하는 것은 완전히 상관된 세기에 대한 예상 교차 상관 관계 값으로 정규화 된 결정된 교차 상관 관계가 두 번째 교차 상관 관계 기준(예: 완전히 상관된 세기에 대한 예상 교차 상관 관계 값으로 정규화된 교차 상관 관계의 피크가 또 다른 임계값 기준을 충족하는 경우, 예: 네 번째 임계값 이상)을 충족하는지 확인하는 것을 포함할 수 있다. 유효한 슬라이스 간 이동 벡터를 식별하는 것은 이동 벡터의 표준 편차가 세 번째 교차 상관 기준(예: 표준 편 차가 다섯 번째 임계값 이하)을 충족하는지 확인하는 것을 포함할 수 있다. 유효한 이동 벡터를 사용하는 것은 슬라이스 간 이동 벡터가 유효하지 않은 것으로 간주되더라도 재정렬할 하나 또는 여러 슬라이스를 식별하고, 하나 또는 여러 슬라이스의 이웃과 관련된 유효한 이동 벡터에서 이동 벡터를 계산하는 것을 포함할 수 있다. 유효한 이동 벡터를 사용하는 것은 국부적으로 재정렬되고 삼선형으로 보간된 서브 볼륨을 생성할 수 있다. 국부적으로 재정렬되고 삼선형으로 보간된 서브 볼륨을 생성하는 것은 floor 또는 ceil연산을 수행하는 것을 포 함할 수 있다. 국부적으로 재정렬되고 삼선형 보간된 서브 볼륨을 생성하는 것은 기본 축을 따라 선형 보간 시퀀스로 삼선형 보간을 수행하는 것을 포함할 수 있다. 선형 보간 시퀀스는 첫 번째 차원을 따라 4개의 선형 보간, 두 번째 차원을 따라 2개의 선형 보간, 세 번째 차 원을 따라 1개의 선형 보간을 포함할 수 있다. 국부적으로 재정렬된 서브 볼륨은 혈관이나 신경 돌기와 같은 세장형 객체를 3D로 추적하도록 처리될 수 있다. 전역적으로 정렬된 3D 이미지 데이터의 불연속성을 가로질러 신경 돌기를 효율적으로 재구성하기 위해, 여기에 공개된 방법 및 시스템은 잠재적으로 불완전한 전역 정렬에 로컬 정렬 방법을 적용한 다음, 로컬 재정렬된 3D 서브 볼륨을 수신하는 신경 돌기 재구성 방법을 적용하는 데 효과적일 수 있으며, 이는 P.H. Li et al., \"Automated Reconstruction of a Serial-Section EM Drosophila Brain with Flood-Filling Networks and Local Realignment.\" Preprint. https://doi.org/10.1101/605634.의 기술과 유사하다. 그런 다음 서브 볼륨 내 의 재구성은 정렬 해제되어야 한다. 즉, 글로벌 참조 프레임으로 다시 투사되어야 한다(P.H. Li 등이 인용한 문 서에서 논의한 대로). 다음 논의는 중첩된 시야를 가진 2D 모자이크의 평면 내 스티칭에서 비롯된 문제를 무시하고 슬라이싱 축을 가 로지르는 2D 슬라이스의 로컬 재정렬에 초점을 맞춘다. 정확도와 효율성을 희생하여 로컬 재정렬을 위한 슬라이 스 간 이동 벡터는 전체 데이터 세트에 대한 그리드에서 미리 계산되고 선형 보간되어 대략적인 복셀당 로컬 정 렬이 생성되며, 여기서 미리 계산된 이동 벡터에 대한 그리드의 크기는 로컬 재정렬 방법의 하이퍼파라미터이다. 로컬 재정렬을 위한 슬라이스 간 이동 벡터를 미리 계산하기 위해, 예를 들어 N=512이고 [0,255] 범위의 픽셀 값을 갖는 8×8 nm2 해상도의 N×N 그레이스케일 EM 데이터의 슬라이스 zi에서 2D 이미지 데이터를 평균을 빼고 255로 나눌 수 있다. 그 후, 슬라이스 , 와 의 자기/교차 상관의 전역적 최댓값의 위치는 픽셀 수준 이동 벡터 에 대응하여 결정될 수 있다. 또한, 노이즈 레벨에 대한 최대 상 관관계의 최소 2/3의 상관관계에 도달하는 상관관계가 가중된 이동 벡터의 평균과 표준 편차가 계산된다. 특히, 상관 관계가 을 초과하면, 이동 벡터가 고려되고, 여기서 슬라이스 간 피크 교차 상관관계는 이고, 노이즈 레벨 (즉, 각 슬라이스 내에서 독립적이고 동일하게 분포 된 픽셀 강도 값을 가정할 때 예상되는 상관관계의 표준 오차)이다. 불규칙한 이동 벡터를 필터링하기 위해 여러 가지 기준이 사용될 수 있다. 예를 들어, 슬라이스 zi의 자기 상관 이 유효하려면 다음 조건이 적용되어야 하도록 재정렬을 구현할 수 있다: 자기 상관은 0 이동에서 피크를 이루어야 한다. 즉, 표준 편차가 ≤2픽셀로 충분히 선명해야 한다. 두 개의 연속적인 와 교차 상관의 완전 상관 강도값을 주변의 세 교차 상관 , 와 의 동일한 메트릭에서 빼서 예상 교차 상관 값 로 정규화한 피크 교차 상관 은 이어야 한다. 재정렬은 자기 상관 조건은 두 슬라이스 모두에 대해 참이어야 한다, 각각의 최대값으로 정규화된 피크 교차 상관은 ≥0.18이어야 한다, 이동 벡터 표준 편차는 ≤10픽셀이어야 한다가 적용되어 슬라이스 의 교차 상관으로부터 이동 벡터 이 유효하도록 구현될 수 있다. 재정렬은 (유효한 이동 벡터에 대한 위에 설명된 기준에 따라) 위치에 있어 이 유효하지 않은 경 우, 슬라이스의 이동 벡터 가 다음 기준을 충족하는 경우 고려되도록 구현될 수 있다: 자 기 상관 조건(위 참조)은 두 슬라이스 모두에 대해 참이어야 하고, 이동 벡터 표준 편차는 ≤11픽셀이어야 한다. 그외 유효하지 않은 이동 벡터 를 계산하기 위해 유효한 이동 벡터 및/또는 가 사용되도 록 재정렬이 구현될 수 있다. 일반성의 손실없이 로 설정하고, 유효한 이동 벡터 와 , 및 적어 도 하나의 유효한 이동 벡터 및/또는 이 주어지면 유효하지 않은 이동 벡터 는 , 또는 로 계산되거나 와 가 유효하면, 이들의 평균으로 계산된다. 비슷하게, 유효한 이동 벡터 , , 및 가 주어지면, 유효하지 않은 이동 벡터 와 가 대략적으로 로 된다. 남아있는 유효하지 않은 이동벡터 는 로 설정된다. 위에서 결정된 것과 같이 이동 벡터 는 평면 내 x-y 축을 따라 512 픽셀의 그리드 간격을 갖는 일반 그 리드의 모든 z-슬라이스에 대해 미리 계산될 수 있다. 전역 참조 프레임의 모든 위치에 대한 로컬화된 이동 벡 터를 근사화하기 위해, 쌍선형 보간이 사용될 수 있다. AI 모델(예: 컨볼루션 신경망 또는 다른 AI 모델 입력) 에 공급할 수 있는 로컬 재정렬 및 삼선형 보간된 서브 볼륨을 생성하려면, 현재 위치 는 로컬 이동 벡터를 계산하기 위한 참조로 사용될 수 있으며 에서 슬라이스는 0의 이동을 갖고, 여기서 는 슬라이스 축을 따르는 복셀 크기이고, 는 플로어(floor) 연산을 나타낸다. 이를 위해 먼 저, 위치에 대한 이웃 슬라이스의 이동 벡터 및 는 이 서브볼륨에 대한 모든 관련 슬 라이스간 이동 벡터 의 쌍선형 보간을 사용하여 결정될 수 있다. 그런 다음 누적 합을 사용하여 이웃 슬 라이스의 z 좌표에서 슬라이스 간 이동 벡터를 집계하고 그 결과 슬라이스 의 집계된 이동 벡터를 뺄 수 있다. 이것은 현재 위치 에 대한 이동 벡터를 생성하여 슬라이스 에서 0의 이동이 생성된 다. 이동 벡터를 고려하여 삼선형 보간을 하기 위해, 이 방법과 시스템은 삼선형 보간을 기본 축을 따라 선형 보간 시퀀스로 공식화할 수 있다: 1차원을 따라 4개의 선형 보간, 2차원을 따라 의 결과에 대한 2개의 선 형 보간, 3차원을 따라 의 결과에 대한 1개의 선형 보간. 구체적으로, 단일 복셀의 보간은 먼저 x와 y를 따라 상응하는 이동이 적용된 천장과 바닥 z 값에 대해 x와 y 축을 따라 독립적으로 선형 보간한 후 축을 따라 선형 보간하여 계산된다. 로컬 재정렬된 서브 볼륨에 대한 컨볼루션 신경망의 예측은 이 서브 볼륨 내에서만 유효하므로 3D EM 데이터 세 트의 글로벌 좌표계와 관련되도록 정렬을 해제해야 한다. 여기에 공개된 방법 및 시스템은 정렬 해제를 구현하 도록 동작할 수 있으며, 여기에는 예측된 비숍 곡률을 이전과 같이 에 통합한 다음, 서브 볼륨의 로컬 재정렬을 위한 참조로 사용된 시작 z 슬라이스 에서 대상 z 슬라이스 로 집계된 이 동 벡터를 에 적용하여 글로벌 좌표계 내의 위치를 산출하는 것이 포함된다. 비숍 프레임을 포함하는 단 위 벡터는 이 프로세스에서 변경되지 않을 수 있다. 정렬 기술은 공통 글로벌 참조 프레임이 있는 일관된 3D 이미지 볼륨으로 2D 이미지를 재조립하는 것과 관련하 여 사용될 수 있다. 이것은 정렬이라고 한다. 준비, 슬라이싱, 이미징 또는 재조립 단계 중 어느 단계에서 오류 가 발생하는 경우, 결과 3D 이미지 데이터 세트는 일반적으로 모든 위치에서 일관되지 않는다. 여기에 공개된 재정렬 기술은 여기에 공개된 많은 이미지 기술에 기술적으로 이점이 있다. 예를 들어, 3D EM을 사용하여 신경 조직을 이미지화하려면 신경 조직을 한 축을 따라 물리적으로 분해(슬라이스)하고, 전자 현미경으로 2D 이미지 화하고, 잠재적으로 시야가 겹치는 모자이크로 하여, 전역적으로 일관된 3D 이미지 데이터 세트를 이상적으로 생성하기 위해 가상으로 재조립한다. 재조립에서 및/또는 대강의 글로벌 재조립 후에, 여기에 공개된 재정렬 기 술이 적용될 수 있다. 여기에 공개된 정렬 기술은 과도한 계산 런타임을 피하는 동시에 우수한 일관성을 제공한 다. 여기에 공개된 정렬 기술은 여기에서 고려된 많은 애플리케이션에 유익하다. 실시예가 자세히 설명되었지만, 다양한 수정 및 변경이 다른 실시예에서 구현될 수 있다. 예를 들어, 여기에 공개된 기술은 다양한 세장형 객체를 추적하는 데 적용될 수 있다. 여기에 개시된 기술은 세장형 객체 추적 및/또는 3D 추적에 제한되지 않고, 일련의 이미지 프레임(예: 비디오) 을 통한 객체 추적, 시공간 좌표계에서 객체 추적 및/또는 다양한 제어 동작에 대한 이미지 처리 수행 등 다양 한 다른 사용 사례에 적용될 수 있다.도면 도면1 도면2 도면3 도면4 도면5 도면6 도면7 도면8 도면9 도면10 도면11 도면12 도면13 도면14 도면15 도면16 도면17 도면18 도면19 도면20 도면21 도면22 도면23 도면24 도면25 도면26 도면27 도면28"}
{"patent_id": "10-2025-7005729", "section": "도면", "subsection": "도면설명", "item": 1, "content": "실시예는 도면을 참조하여 상세하게 설명될 것이며, 도면에서 동일한 또는 유사한 구성은 동일한 또는 유사한 참조 기호에 의해 명시된다. 도 1은 실시예에 따른 시스템을 나타내는 블록도이다. 도 2는 3D 이미지 데이터에서 세장형 객체를 나타낸다. 도 3은 3D 이미지 데이터에서 세장형 객체를 나타낸다. 도 4는 실시예에 따른 시스템 및 방법의 동작을 설명하기 위한 일련의 점을 나타낸 도면이다. 도 5는 실시예에 따른 방법의 흐름도이다. 도 6은 실시예에 따른 시스템과 방법의 동작을 설명하기 위한 이미지화된 조직 볼륨의 서브-볼륨의 도면이다. 도 7은 복셀 그리드의 도면이다. 도 8은 AI 모델 입력의 결정을 설명하는 도면이다. 도 9는 실시예에 따른 시스템과 방법의 AI 모델을 나타낸다. 도 10은 실시예에 따른 시스템과 방법의 AI 모델을 나타낸다.도 11은 실시예에 따른 방법의 흐름도이다. 도 12는 실시예에 따른 방법의 흐름도이다. 도 13은 실시예에 따른 시스템 및 방법의 AI 모델을 나타내고 그 동작을 설명한다. 도 14는 실시예에 따른 시스템 및 방법의 추가 AI 모델을 나타내고 그 동작을 설명한다. 도 15는 실시예에 따른 방법의 흐름도이다. 도 16은 AI 모델 훈련 중 사용될 수 있는 비행 정책을 설명하는 도면이다. 도 17은 실시예에 따른 방법의 흐름도이다. 도 18은 실시예에 따른 방법의 흐름도이다. 도 19는 실시예에 따른 시스템 및 방법의 동작을 설명한다. 도 20은 실시예에 따른 방법 및 동작에 의해 사용될 수 있는 로컬 좌표 프레임을 설명한다. 도 21은 실시예에 따른 방법 및 시스템의 오류율을 훈련 반복의 함수로 나타낸다. 도 22는 실시예에 따른 방법의 흐름도이다. 도 23은 재구성 오류율이 낮고 재구성 오류간 간격이 크기 때문에 본 발명의 실시예가 적합한 응용 프로그램을 보여주는 다이어그램이다. 도 24는 종래 기술과 비교하여 실시예에 의해 달성한 개선 사항을 보여주는 다이어그램이다. 도 25는 종래 기술과 비교하여 실시예에 의해 달성한 개선 사항을 보여주는 다이어그램이다. 도 26은 종래 기술과 비교하여 실시예에 의해 달성한 개선 사항을 보여주는 추가 다이어그램이다. 도 27은 실시예에 따른 방법의 흐름도이다. 도 28은 실시예에 따른 시스템을 나타내는 블록도이다."}
