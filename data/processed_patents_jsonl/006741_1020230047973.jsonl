{"patent_id": "10-2023-0047973", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0133481", "출원번호": "10-2023-0047973", "발명의 명칭": "이미지 영상에 포함된 객체의 좌표 추정 방법 및 이를 이용한 객체 이송 장치", "출원인": "주식회사 윔", "발명자": "김화랑"}}
{"patent_id": "10-2023-0047973", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "컨베이어 수단에 의해 이동되는 객체를 촬영한 이미지 영상에 포함된 상기 객체의 좌표 추정 방법에 있어서,(a) 상기 컨베이어 수단의 폭 방향인 X 방향에 대하여, 상기 컨베이어 수단의 X 방향 실제 길이, 상기 이미지영상으로부터 얻은 상기 컨베이어 수단의 X 방향 픽셀 길이, 상기 이미지 영상으로부터 얻은 상기 객체 중심점의 X 방향 픽셀 좌표를 이용하여 상기 객체 중심점의 X 방향 실제 좌표를 연산하는 단계; (b) 상기 객체 중심점의 X 방향 픽셀 좌표와 실제 좌표, 상기 객체를 촬영한 카메라의 내부 파라미터(intrinsicparameter)를 이용하여 상기 객체 중심점의 depth를 연산하는 단계; 및(c) 상기 컨베이어 수단의 이동 방향이고 상기 X 방향에 수직한 방향인 Y 방향에 대하여, 상기 이미지 영상으로부터 얻은 상기 객체 중심점의 Y 방향 픽셀 좌표, 상기 객체 중심점의 depth, 상기 카메라의 내부 파라미터를이용하여 상기 객체 중심점의 Y 방향 실제 좌표를 연산하는 단계를 포함하는 것을 특징으로 하는 이미지 영상에포함된 객체의 좌표 추정 방법."}
{"patent_id": "10-2023-0047973", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에서,상기 (a) 단계는 아래의 수식을 이용하여 상기 객체 중심점의 X 방향 실제 좌표를 연산하는 것을 특징으로 하는이미지 영상에 포함된 객체의 좌표 추정 방법."}
{"patent_id": "10-2023-0047973", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에서,상기 (b) 단계는 아래의 수식을 이용하여 상기 객체 중심점의 depth를 연산하는 것을 특징으로 하는 이미지 영상에 포함된 객체의 좌표 추정 방법.(단, X는 객체 중심점의 X방향 실제 좌표, x는 객체 중심점의 X방향 픽셀 좌표, fx는 X방향 초점거리, cx는 X방향 주점, Z는 객체 중심점의 depth)"}
{"patent_id": "10-2023-0047973", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에서,상기 (c) 단계는 아래의 수식을 이용하여 상기 객체 중심점의 Y 방향 실제 좌표를 연산하는 것을 특징으로 하는이미지 영상에 포함된 객체의 좌표 추정 방법.공개특허 10-2024-0133481-3-(단, Y는 객체 중심점의 Y방향 실제 좌표, y는 객체 중심점의 Y방향 픽셀 좌표, fy는 Y방향 초점거리, cy는 Y방향 주점, Z는 객체 중심점의 depth)"}
{"patent_id": "10-2023-0047973", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "객체를 이동시키는 컨베이어 모듈;상기 컨베이어 모듈의 중도에 설치되어 이동하는 객체에 대한 이미지 영상을 획득하는 카메라 모듈;인공지능 기반의 객체 탐지(object detection) 알고리즘을 이용하여 상기 이미지 영상에 포함된 객체를 탐지하고, 탐지된 객체의 중심점에 대한 평면 픽셀 좌표를 포함하는 바운딩 박스(bounding box) 정보를 생성하는 영상처리 모듈;상기 탐지된 객체를 컨베이어 모듈 외부로 이송하는 이송로봇 모듈; 상기 바운딩 박스 정보로부터 상기 객체의 중심점에 대한 평면 실제 좌표를 연산하는 좌표 연산 모듈; 및상기 탐지된 객체의 중심점에 대한 평면 실제 좌표를 이용하여 상기 이송로봇 모듈의 동작을 제어하는 제어모듈을 포함하되,상기 좌표 연산 모듈은 제1항 내지 제4항 중 어느 하나의 방법에 의하여 상기 객체의 중심점에 대한 평면 실제좌표를 연산하는 것을 특징으로 하는 객체 이송 장치."}
{"patent_id": "10-2023-0047973", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5항에서,상기 좌표 연산 모듈은 상기 이미지 영상의 픽셀별 depth 정보를 더 연산하고,상기 탐지된 객체에 대하여 중심점을 포함하는 형태로 이루어진 중심 영역을 설정한 후, 상기 중심 영역에 포함된 픽셀들의 depth 값을 이용하여 상기 객체의 중심점 주변부에 관한 depth 정보인 중심점에 대한 depth 보정값을 연산하는 depth 보정모듈을 더 포함하되,상기 제어모듈은 상기 중심점에 대한 depth 보정값을 더 이용하여 상기 이송로봇 모듈의 동작을 제어하는 것을특징으로 하는 객체 이송 장치."}
{"patent_id": "10-2023-0047973", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6항에서,상기 depth 보정 모듈은, 탐지된 객체의 형상에 따라 상기 중심 영역의 형태를 다르게 설정하는 것을 특징으로하는 객체 이송 장치."}
{"patent_id": "10-2023-0047973", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에서,상기 바운딩 박스 정보는 탐지된 객체의 가로 길이, 세로 길이에 관한 정보를 더 포함하고,상기 depth 보정 모듈은 상기 중심 영역을 사각형 형태로 설정하되, 객체의 가로 길이와 세로 길이에 따라 상기중심 영역의 가로 길이와 세로 길이를 다르게 설정하는 것을 특징으로 하는 객체 이송 장치."}
{"patent_id": "10-2023-0047973", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에서,상기 depth 보정 모듈은, 상기 중심 영역에 포함된 각 픽셀별로 depth 값에 대한 가중치를 서로 다르게 부여하여 상기 객체의 중심점에 대한 depth 보정값을 연산하는 것을 특징으로 하는 객체 이송 장치."}
{"patent_id": "10-2023-0047973", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 컨베이어 수단에 의해 이동되는 객체를 촬영한 이미지 영상에 포함된 상기 객체의 좌표 추정 방법에 있어서, (a) 상기 컨베이어 수단의 폭 방향인 X 방향에 대하여, 상기 컨베이어 수단의 X 방향 실제 길이, 상기 이미지 영상으로부터 얻은 상기 컨베이어 수단의 X 방향 픽셀 길이, 상기 이미지 영상으로부터 얻은 상기 객체 (뒷면에 계속)"}
{"patent_id": "10-2023-0047973", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 과제(결과물)은 2022년도 교육부의 재원으로 한국연구재단의 지원을 받아 수행된 지자체-대학협력기반 지역 혁신 사업의 결과물입니다(2022RIS006). 본 발명은 이미지 영상에 포함된 객체의 좌표 추정 방법 및 이를 이용한 객체 이송 장치에 관한 것으로서, 더욱 구체적으로는 컨베이어 수단에 의해 이동되는 객체를 촬영한 이미지 영상으로부터 얻어진 객체의 중심점에 대한 픽셀 좌표를 이용하여 해당 객체의 중심점에 대한 실제 좌표를 추정하는 방법과, 상기 추정된 중심점의 실제 좌 표와 상기 중심점 주변부의 depth 정보를 이용하여 상기 객체를 파지하여 외부로 이송하는 이송로봇의 동작을 정확히 제어함으로써 해당 객체의 이송효율을 현저히 향상시킬 수 있는 객체 이송 장치에 관한 것이다."}
{"patent_id": "10-2023-0047973", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "근래 들어, 전세계적으로 급속한 기계화와 산업화로 인하여 다양한 종류의 농산품/공산품 등의 제품들이 대량으 로 생산되어 유통되고 있는데, 이로 인하여 제품의 생산 효율이나 유통 효율을 향상시키기 위해서는 제품의 생 산 단계 또는 유통 단계에서 이들 제품들을 다양한 기준에 따라 선별할 필요성이 있다. 즉, 제품의 생산 단계에서는 양품과 불량품의 선별이나 제품의 사이즈별 선별 작업이 요구될 수 있고, 제품의 유통 단계에서는 제품의 종류별 선별이나 크기/색상별 선별 작업이 요구될 수 있다. 그러나, 종래에는 제품의 선별 작업이 대부분 시간과 비용이 많이 소요되는 수작업으로 이루어지기 때문에 대규 모 작업시 경제성이 저하될 뿐만 아니라, 작업자의 숙련도나 컨디션에 따라 선별 작업의 정확성이 영향을 받기 때문에 제품의 선별효율이 일정하게 유지되기 곤란한 문제점이 있었다. 따라서, 최근에는 이와 같은 문제점을 해결하기 위하여 영상 기반의 딥러닝 기술을 이용하여 제품을 자동으로 정확하게 식별하여 선별하는 기술이 개발되었는데, 이에 대한 구체적인 내용은 하기 [문헌 1]과 [문헌 2]에 개 시되어 있다. 그러나, 하기 [문헌 1]과 [문헌 2]에 개시된 기술은 2차원의 객체 이미지 영상으로부터 얻은 객체의 좌표(이하, '픽셀 좌표'라 함)를 기준으로 상기 객체를 파지하여 이송하는 이송로봇을 제어하는 방식으로 이루어지는데, 이 경우 카메라의 설치 위치나 각도에 따라 달라지는 상기 픽셀 좌표의 특징으로 인하여 이송로봇이 실제 이동하는 좌표(이하, '실제 좌표'라 함)와의 차이가 발생됨으로써 객체의 이송 효율이 크게 저하되는 문제점이 있다. 이를 보완하기 위하여, 상기 픽셀 좌표를 실제 좌표로 변환하는 캘리브레이션(calibration) 작업을 수행하는 방 안을 고려해볼 수도 있으나, 이 경우에도 전술한 바와 같이 카메라의 설치 위치나 각도에 따라 달라지는 상기 픽셀 좌표의 특성상 개별 장치마다 상기 캘리브레이션 작업을 수행해야 하는 번거로움이 있다. 또한, 하기 [문헌 1]과 [문헌 2]에 개시된 기술은 2차원의 객체 이미지 영상을 이용하여 객체를 선별하는 방식 이기 때문에 객체의 식별은 종류별로 어느 정도 정확하게 이루어질 수 있으나, 식별된 객체를 이송로봇을 이용 하여 이송하는 경우 객체에 대한 높이(depth) 정보가 없기 때문에 객체의 이송 효율이 저하되어 전체적으로 객 체의 선별 효율이 저하되는 문제점이 있다. [문헌 1] 한국등록특허 제10-2222176호(2021. 2. 24. 공고) [문헌 2] 한국등록특허 제10-2222177호(2021. 2. 24. 공고)"}
{"patent_id": "10-2023-0047973", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 상술한 바와 같은 종래 기술의 문제점을 해결하기 위한 것으로서, 본 발명의 목적은 컨베이어 수단에 의해 이동되는 객체를 촬영한 이미지 영상으로부터 얻어진 객체의 픽셀 좌표를 이용하여 해당 객체의 실제 좌표 를 연산함으로써 카메라의 설치 위치나 각도에 상관없이 항상 상기 객체의 실제 좌표를 정확히 추정할 수 있는 이미지 영상에 포함된 객체의 좌표 추정 방법을 제공하기 위한 것이다. 또한, 본 발명의 다른 목적은 상술한 방법으로 상기 객체의 이미지 영상으로부터 얻어진 객체의 중심점의 실제 좌표와 상기 중심점 주변부의 depth 정보를 이용하여 상기 객체를 이송하는 이송로봇의 동작을 정확하게 제어함 으로써 객체의 이송 효율을 현저히 향상시킬 수 있는 객체 이송 장치를 제공하기 위한 것이다."}
{"patent_id": "10-2023-0047973", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기와 같은 목적을 달성하기 위하여 본 발명은 컨베이어 수단에 의해 이동되는 객체를 촬영한 이미지 영상에 포함된 상기 객체의 좌표 추정 방법에 있어서, (a) 상기 컨베이어 수단의 폭 방향인 X 방향에 대하여, 상기 컨 베이어 수단의 X 방향 실제 길이, 상기 이미지 영상으로부터 얻은 상기 컨베이어 수단의 X 방향 픽셀 길이, 상 기 이미지 영상으로부터 얻은 상기 객체 중심점의 X 방향 픽셀 좌표를 이용하여 상기 객체 중심점의 X 방향 실 제 좌표를 연산하는 단계, (b) 상기 객체 중심점의 X 방향 픽셀 좌표와 실제 좌표, 상기 객체를 촬영한 카메라 의 내부 파라미터(intrinsic parameter)를 이용하여 상기 객체 중심점의 depth를 연산하는 단계, 및 (c) 상기 컨베이어 수단의 이동 방향이고 상기 X 방향에 수직한 방향인 Y 방향에 대하여, 상기 이미지 영상으로부터 얻은 상기 객체 중심점의 Y 방향 픽셀 좌표, 상기 객체 중심점의 depth, 상기 카메라의 내부 파라미터를 이용하여 상 기 객체 중심점의 Y 방향 실제 좌표를 연산하는 단계를 포함하는 것을 특징으로 한다. 또한, 상기 (a) 단계는 아래의 수식을 이용하여 상기 객체 중심점의 X 방향 실제 좌표를 연산하는 것을 특징으 로 한다."}
{"patent_id": "10-2023-0047973", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 2, "content": "또한, 상기 (b) 단계는 아래의 수식을 이용하여 상기 객체 중심점의 depth를 연산하는 것을 특징으로 한다."}
{"patent_id": "10-2023-0047973", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 3, "content": "(단, X는 객체 중심점의 X방향 실제 좌표, x는 객체 중심점의 X방향 픽셀 좌표, fx는 X방향 초점거리, cx는 X방 향 주점, Z는 객체 중심점의 depth) 또한, 상기 (c) 단계는 아래의 수식을 이용하여 상기 객체 중심점의 Y 방향 실제 좌표를 연산하는 것을 특징으 로 한다."}
{"patent_id": "10-2023-0047973", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 4, "content": "(단, Y는 객체 중심점의 Y방향 실제 좌표, y는 객체 중심점의 Y방향 픽셀 좌표, fy는 Y방향 초점거리, cy는 Y방 향 주점, Z는 객체 중심점의 depth) 또한, 본 발명에 따른 객체 이송 장치는, 객체를 이동시키는 컨베이어 모듈, 상기 컨베이어 모듈의 중도에 설치 되어 이동하는 객체에 대한 이미지 영상을 획득하는 카메라 모듈, 인공지능 기반의 객체 탐지(object detection) 알고리즘을 이용하여 상기 이미지 영상에 포함된 객체를 탐지하고, 탐지된 객체의 중심점에 대한 평 면 픽셀 좌표를 포함하는 바운딩 박스(bounding box) 정보를 생성하는 영상처리 모듈, 상기 탐지된 객체를 컨베 이어 모듈 외부로 이송하는 이송로봇 모듈, 상기 바운딩 박스 정보로부터 상기 객체의 중심점에 대한 평면 실제 좌표를 연산하는 좌표 연산 모듈, 및 상기 탐지된 객체의 중심점에 대한 평면 실제 좌표를 이용하여 상기 이송 로봇 모듈의 동작을 제어하는 제어모듈을 포함하되, 상기 좌표 연산 모듈은 상술한 방법 중 어느 하나의 방법에 의하여 상기 객체의 중심점에 대한 평면 실제 좌표를 연산하는 것을 특징으로 한다. 또한, 상기 좌표 연산 모듈은 상기 이미지 영상의 픽셀별 depth 정보를 더 연산하고, 상기 탐지된 객체에 대하 여 중심점을 포함하는 형태로 이루어진 중심 영역을 설정한 후, 상기 중심 영역에 포함된 픽셀들의 depth 값을 이용하여 상기 객체의 중심점 주변부에 관한 depth 정보인 중심점에 대한 depth 보정값을 연산하는 depth 보정모듈을 더 포함하되, 상기 제어모듈은 상기 중심점에 대한 depth 보정값을 더 이용하여 상기 이송로봇 모듈의 동작을 제어하는 것을 특징으로 한다. 또한, 상기 depth 보정 모듈은, 탐지된 객체의 형상에 따라 상기 중심 영역의 형태를 다르게 설정하는 것을 특 징으로 한다. 또한, 상기 바운딩 박스 정보는 탐지된 객체의 가로 길이, 세로 길이에 관한 정보를 더 포함하고, 상기 depth 보정 모듈은 상기 중심 영역을 사각형 형태로 설정하되, 객체의 가로 길이와 세로 길이에 따라 상기 중심 영역 의 가로 길이와 세로 길이를 다르게 설정하는 것을 특징으로 한다. 또한, 상기 depth 보정 모듈은, 상기 중심 영역에 포함된 각 픽셀별로 depth 값에 대한 가중치를 서로 다르게 부여하여 상기 객체의 중심점에 대한 depth 보정값을 연산하는 것을 특징으로 한다."}
{"patent_id": "10-2023-0047973", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명에 따른 이미지 영상에 포함된 객체의 좌표 추정 방법은 컨베이어 수단에 의해 이동되는 객체를 촬영한 이미지 영상으로부터 얻어진 객체의 픽셀 좌표를 이용하여 해당 객체의 실제 좌표를 연산함으로써 카메라의 설 치 위치나 각도에 상관없이 항상 상기 객체의 실제 좌표를 정확히 추정할 수 있기 때문에 상기 객체를 파지하여 외부로 이송하는 이송로봇의 동작을 정확히 제어함으로써 해당 객체의 이송효율을 현저히 향상시킬 수 있다. 또한, 본 발명에 따른 객체 이송 장치는 상술한 방법으로 상기 객체의 이미지 영상으로부터 얻어진 객체의 중심 점의 실제 좌표와, depth 보정모듈을 이용하여 객체의 형상 특성, class 특성, 중심점의 비정상적 변형 특성 등 을 모두 고려하여 얻은 해당 객체의 중심점에 대한 depth 보정값을 이용하여 상기 객체를 이송하는 이송로봇의 동작을 더욱 정확하게 제어함으로써 객체의 이송 효율을 더욱 현저히 향상시킬 수 있다."}
{"patent_id": "10-2023-0047973", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하에서는 본 발명의 바람직한 실시예를 첨부한 도면을 이용하여 구체적으로 설명하기로 한다. 도1은 본 발명의 일실시예에 따른 객체 이송 장치의 전체 구성을 나타낸 도면이고, 도2는 도1에 도시한 장치의 동작구성을 설명하기 위한 블럭도이다. 또한, 도3은 카메라 캘리브레이션에 이용되는 좌표계를 설명하기 위한 도면이고, 도4는 도2에 도시한 좌표 연산 모듈에서 객체의 픽셀 좌표로부터 실제 좌표를 연산하여 추정하는 방법을 설명하기 위한 도면이다. 본 발명에 따른 객체 이송 장치는 객체(R)를 이동시키는 컨베이어 모듈, 상기 컨베이어 모듈의 중도 에 설치된 거치대, 및 상기 컨베이어 모듈의 일측에 설치되어 컨베이어 모듈의 이동속도를 측정하 는 엔코더(encoder) 모듈을 포함하여 구성된다.이때, 상기 거치대는 대략 'ㄷ'자 형상으로 이루어지는데, 지면에 수직하도록 각각 컨베이어 모듈의 일 측과 타측에 설치된 한 쌍의 수직부재(미도시)와 상기 수직부재의 상단을 연결하는 수평부재(미도시)로 구성된 다. 또한, 상기 거치대의 일측에는 컨베이어 모듈에 의해 이동되는 객체(R)를 촬영하는 카메라 모듈, 상기 카메라 모듈에서 촬영한 이미지 영상을 이용하여 이송하고자 하는 객체를 판단하여 식별하는 에지 디 바이스, 및 상기 에지 디바이스의 판단결과에 따라 이송 대상인 객체를 컨베이어 모듈의 외부로 이 송하는 이송로봇 모듈이 설치된다. 상기 카메라 모듈은 컨베이어 모듈에 의해 이동되는 객체(R)를 상부 방향에서 촬영할 수 있도록 상기 거치대의 수평부재 일측에 설치되는데, 객체(R)에 대한 이미지 영상 뿐만 아니라 상기 이미지 영상의 각 픽 셀별 depth(깊이) 정보를 동시에 획득하도록 구성된다. 이를 위하여, 상기 카메라 모듈은 복수의 카메라 또는 rgb-d 카메라 등으로 바람직하게 구성될 수 있는데, 본 실시예에서는 일예로서 상기 카메라 모듈을 좌우 한 쌍의 카메라로 이루어진 스테레오 카메라(stereo camera)로 구성하였다. 또한, 상기 에지 디바이스는 상기 거치대의 일측에 설치되어 본 발명에 따른 객체 이송 장치의 동작을 제어하는 일종의 제어유닛으로서의 기능을 수행하게 된다. 이를 위하여, 상기 에지 디바이스는 도2에 도시한 바와 같이 카메라 모듈에서 촬영한 이미지 영상을 판 단하여 이송 대상인 객체를 식별하는 영상처리 모듈, 식별된 객체의 중심점에 대한 평면 실제 좌표와 depth를 연산하는 좌표 연산 모듈, 식별된 객체의 중심점에 대한 depth 보정값을 연산하는 depth 보정모듈 , 및 후술하는 바와 같이 객체 이송 장치에 구비된 각 모듈의 동작을 제어하는 제어모듈을 포함하도 록 구성된다. 또한, 상기 영상처리 모듈은 인공지능 기반의 객체 탐지(object detection) 알고리즘을 이용하여 상기 카 메라 모듈에서 촬영된 이미지 영상에 포함된 객체를 탐지하는 기능을 수행하는데, 상기 객체 탐지 알고리즘 은 Faster R-CNN, R_FCN, FPN_FRCN, YOLO, SSD, RetinaNet 등의 알고리즘 중 어느 하나일 수 있다. 본 실시예에서는 상기 영상처리 모듈이 단일 단계 방식의 객체 탐지 알고리즘 중 하나인 YOLO(구체적으로 는 YOLO v5) 알고리즘을 이용하여 이송 대상인 객체를 탐지하고, 탐지된 객체에 대한 바운딩 박스(bounding box) 정보를 생성하는 기능을 수행하도록 구성하였다. 또한, 상기 바운딩 박스 정보는 객체의 중심점에 대한 평면 픽셀 좌표(X 방향 좌표와 Y 방향 좌표)에 관한 정보, 객체의 가로길이(W)와 세로길이(H)에 관한 정보, 객체의 분류 클래스(class)에 관한 정보(class 종류 및 정확도 확률)를 포함하도록 구성된다. 이를 위하여, 상기 영상처리 모듈에는 이송 대상인 객체에 관한 다양한 정보가 분류 class 별로 미리 학습 된 YOLO v5 알고리즘이 저장되어 있는데, 상기 YOLO v5 알고리즘은 에지 디바이스에 탑재가 용이하도록 하 기 위하여 TensorRT와 같은 딥러닝 모델 최적화 엔진에 의한 경량화 작업이 이루어지는 것이 더욱 바람직하다. 또한, 상기 좌표 연산모듈은 이미지 영상에 포함된 객체의 중심점(후술하는 도5의 202,302)에 대한 X,Y 방 향 픽셀 좌표로부터 X,Y 방향 실제 좌표와 depth를 연산하는 기능을 수행하는데, 상기 좌표 연산모듈은 필 요에 따라 각 픽셀별 실제 좌표와 depth를 연산할 수 있음은 물론이다. 이때, 본 발명의 상세한 설명 및 특허청구범위 전체에서 X 방향이라 함은 컨베이어 모듈의 폭 방향(구체적 으로는, 객체의 이동 방향으로 진행하는 컨베이어 벨트의 폭 방향)을 의미하고, Y 방향이라 함은 상기 컨베이어 모듈의 이동 방향이고 평면상에서 상기 X 방향에 수직인 방향을 의미하며, Z 방향은 상기 X,Y 방향에 수직 한 상하 방향을 의미한다. 이하에서는 도3과 도4를 이용하여 본 발명에 따른 좌표 연산모듈이 객체의 X,Y 방향 실제 좌표를 연산하는 방법을 구체적으로 설명하기로 한다. 일반적으로 카메라 캘리브레이션에 이용되는 좌표계는 도3에 도시한 바와 같이 월드 좌표계, 카메라 좌표계, 픽 셀 좌표계 및 정규 이미지 좌표계(또는 정규 좌표계)의 4개가 존재하는데, 각각의 좌표계에 대한 기하학적 의미 는 공지된 기술이기 때문에 여기에서는 각 좌표계에 대한 정의만 간략히 설명하고 구체적인 설명은 생략하기로한다. 먼저, 월드 좌표계는 사물의 위치를 표현하기 위한 좌표계로서 상기 이송로봇 모듈이 실제 이동하는 위치 (또는 좌표)를 제어하기 위해 사용되는 좌표계인데, 이러한 월드 좌표계는 3차원 좌표계로서 필요에 따라 임의 의 위치를 기준(또는 원점)으로 설정하여 사용할 수 있다. 본 실시예에서 상기 좌표 연산모듈에서 연산하는 객체의 실제 좌표는 월드 좌표계상의 좌표를 의미하며, 따라서 본 명세서의 발명의 상세한 설명 및 특허청구범위 전체에서 \"실제 좌표\"는 월드 좌표계상의 좌표를 의미 한다. 또한, 상기 카메라 좌표계는 카메라 렌즈의 중심을 원점(0,0,0)으로 하는 3차원 좌표계를 말하며, 카메라 렌즈 의 정면 방향을 Z축(도3의 Zc축)으로 설정하여 사용하는 좌표계이다. 또한, 상기 픽셀 좌표계는 카메라의 촬영을 통해서 얻은 이미지 영상에 대한 2차원 좌표계로서, 이미지 영상에 서 원점(0,0)은 좌측 상단 모서리로 설정하여 사용하는 좌표계이다. 한편, 상기 정규 이미지 좌표계는 픽셀 좌표계에서 카메라의 내부 파라미터(intrinsic parameter)의 영향을 제 거한 가상의 2차원 좌표계로서, 카메라 좌표계의 원점인 초점과의 거리가 1이고 정규 이미지 평면의 중점과 Zc 축과의 교점을 원점으로 설정한 좌표계이다. 도3의 (a)를 참조하여 상술한 좌표계 상호간의 관계를 살펴보면 카메라 좌표계가 정의하는 3차원 공간에서의 임 의의 점 P(X,Y,Z)는 2차원 좌표계인 픽셀 좌표계와 정규 이미지 좌표계에서 각각 점 PP(x,y)와 PN(u,v)로 투영 됨을 알 수 있다. 이 경우 도3의 (b)에 도시한 바와 같이 각 점(PN,PP,P)의 초점거리(렌즈중심과의 거리) 1, f, Z는 각각 Zc축 상 에서 카메라와 이격된 거리 즉, 3차원 점의 depth에 해당된다. 한편, 픽셀 좌표를 실제 좌표로 변환하는 카메라 캘리브레이션 작업은 픽셀 좌표계의 2차원 좌표를 월드 좌표계 의 3차원 좌표(즉, 실제 좌표)로 변환하기 위한 것으로서, 이를 위해서는 이른바 카메라 파라미터(camera parameter)를 추정하여야 한다. 상기 카메라 파라미터는 카메라의 설치 높이, 방향(팬,틸트) 등 카메라의 외부 공간과의 기하학적 관계에 관련 된 외부 파라미터(extrinsic parameter)와, 카메라의 초점거리, 중심점(주점) 등 카메라 자체의 내부적인 파라 미터인 내부 파라미터(intrinsic parameter)로 이루어진다. 이때, 상기 내부 파라미터는 각 카메라마다 고유값으로 주어지는 값이기 때문에 구하기 용이하나, 카메라 좌표 계와 월드 좌표계의 변환 관계를 나타내는 파라미터인 상기 외부 파라미터는 카메라의 각도와 관련된 방향을 측 정하기 어렵기 때문에 추정하기 곤란한 문제점이 있다. 따라서, 종래에는 상기 외부 파라미터를 정확히 추정하기 곤란하여 픽셀 좌표를 실제 좌표로 변환하는 것이 어 렵기 때문에 이송로봇 모듈의 위치를 정확히 제어하기 곤란한 문제점이 있었다. 이와 같은 종래 기술의 문제점을 해결하기 위하여 본 발명에서는 상기 월드 좌표계를 카메라 좌표계로 두고, 픽 셀 좌표계-정규 이미지 좌표계 상호간의 좌표 변환관계와, 정규 이미지 좌표계-카메라 좌표계의 좌표 변환관계 를 이용하여 픽셀 좌표로부터 실제 좌표를 연산하는 것을 기술적 특징으로 한다. 이를 구체적으로 살펴보면, 정규 이미지 좌표계는 픽셀 좌표계에서 카메라 내부 파라미터 영향을 제거한 좌표계 이기 때문에 두 좌표계 사이에는 하기 [수식 1]과 같은 관계가 성립한다. [수식 1]"}
{"patent_id": "10-2023-0047973", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "이때, 상기 카메라 내부 파라미터는 각 카메라마다 고유값으로 주어지는데, fx와 fy는 각각 X방향과 Y방향의 초 점거리(focal length), cx와 cy는 각각 X방향과 Y방향의 주점(principal point)을 의미한다. 따라서, 픽셀 좌표 x와 y는 각각 하기 [수식 2]와 같이 표시될 수 있다. [수식 2]"}
{"patent_id": "10-2023-0047973", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "한편, 도3에 도시한 바와 같이 정규 이미지 좌표계의 u,v는 각각 카메라 좌표계의 X,Y와 하기 [수식 3]과 같은 관계가 성립한다. [수식 3]"}
{"patent_id": "10-2023-0047973", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "따라서, [수식 2]와 [수식 3]을 연립하면 픽셀 좌표(x,y)와 월드 좌표계상(즉, 본 발명에서는 카메라 좌표계와 동일)의 실제 좌표(X,Y) 사이에는 하기 [수식 4]와 같은 관계가 성립하게 된다. [수식 4]"}
{"patent_id": "10-2023-0047973", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "본 실시예에 따른 상기 좌표 연산모듈은 상기 [수식 4]를 이용하여 픽셀 좌표로부터 실제 좌표와 depth를 추정 연산하게 되는데, 이에 대한 구체적인 예를 도4를 참조하여 설명하기로 한다. 먼저, 상기 좌표 연산모듈은 상기 컨베이어 모듈의 X 방향 실제 길이(도4의 L), 상기 이미지 영상으로 부터 얻은 상기 컨베이어 모듈의 X 방향 픽셀 길이(도4의 C), 상기 이미지 영상으로부터 얻은 상기 객체 (R)의 중심점(202,302)의 X 방향 픽셀 좌표(도4의 x)를 이용하여 상기 객체 중심점(202,302)의 X 방향 실제 좌 표를 연산하게 된다. 이를 위하여, 상기 좌표 연산모듈은 아래의 [수식 5]을 이용하여 상기 객체 중심점(202,302)의 X 방향 실 제 좌표를 연산하게 된다. [수식 5]"}
{"patent_id": "10-2023-0047973", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "예를 들어, 카메라 모듈에서 촬영된 영상 이미지의 X 방향 범위가 컨베이어 수단(즉, 컨베이어 벨트)의 폭 과 일치되도록 설정되고, 상기 컨베이어 모듈의 X 방향 실제 길이(L)가 800mmm, X 방향 픽셀 길이(C)가 1000, 객체(R) 중심점의 X 방향 픽셀 좌표(x)가 250인 경우, 상기 객체 중심점의 X방향 실제 좌표는 하기 [수식 6]의 연산식과 같이 -200으로 연산된다. [수식 6]"}
{"patent_id": "10-2023-0047973", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 7, "content": "이때, 상기 [수식 5]와 [수식 6]의 마지막 항(컨베이어 수단 전체길이의 1/2을 빼주는 항)은 픽셀 좌표계는 X 좌표의 원점(OP)이 왼쪽 단부임에 반하여, 월드 좌표계(본 발명의 경우 카메라 좌표계)의 경우 X 좌표의 원점 (O)이 카메라 렌즈의 중심(즉, 컨베이어 수단의 중앙 또는 이미지 영상의 중앙)이기 때문에 그 차이점을 보상하 기 위한 것이다. 이와 같이 상기 객체 중심점(202,302)의 X 방향 실제 좌표가 연산되면, 상기 좌표 연산모듈은 [수식 4]의 ①에 따라 상기 객체 중심점(202,302)의 X 방향 픽셀 좌표와 실제 좌표, 상기 객체를 촬영한 카메라의 카메라 내부 파라미터(intrinsic parameter)를 이용하여 상기 객체 중심점(202,302)의 depth(Z)를 연산하게 된다. 앞서 설명한 바와 같이 본 실시예에 따른 카메라 모듈은 스테레오 카메라로 구성되기 때문에 이미지 영상 획득시 각 픽셀별 depth 정보를 동시에 획득하게 되는데, 상기 카메라 모듈에 의하여 획득된 depth 정보는 픽셀 좌표계에 대하여 얻어진 정보로서 이미지 영상 왜곡에 의한 noise와 내부 연산 오차 등의 원인으로 인하여 그 정확성이 떨어지는 문제점이 있다. 따라서, 본 발명에서는 이송로봇 모듈의 정확한 위치 제어를 위하여 카메라 모듈에서 획득된 depth 정 보 대신에 [수식 4]의 ①에 따라 각 픽셀별 depth를 연산하게 된다. 상술한 바와 같이 객체 중심점(202,302)의 depth가 구해지면 상기 좌표 연산모듈은 [수식 4]의 ②에 따라 상기 이미지 영상으로부터 얻은 상기 객체 중심점(202,302)의 Y 방향 픽셀 좌표, 상기 객체 중심점(202,302)의 depth, 상기 카메라 내부 파라미터(intrinsic parameter)를 이용하여 상기 객체 중심점(202,302)의 Y 방향 실 제 좌표를 연산하게 된다. 본 발명에 따른 이미지 영상에 포함된 객체의 좌표 추정 방법은 컨베이어 수단에 의해 이동되는 객체를 촬영한 이미지 영상으로부터 얻어진 객체의 픽셀 좌표를 이용하여 해당 객체의 실제 좌표를 연산함으로써 카메라의 설 치 위치나 각도에 상관없이 항상 상기 객체의 실제 좌표를 정확히 추정할 수 있기 때문에 상기 객체를 파지하여 외부로 이송하는 이송로봇의 동작을 정확히 제어함으로써 해당 객체의 이송효율을 현저히 향상시킬 수 있다. 또한, 상기 depth 보정모듈은 상기 바운딩 박스 정보와 이미지 영상의 픽셀별 depth 정보를 이용하여 후술 하는 방식으로 상기 탐지된 객체의 중심점에 대한 depth 보정값을 연산하도록 구성되는데, 상기 depth 보정모듈 은 상술한 바와 같이 [수식 4]의 ①에 따라 얻어진 픽셀별 depth 정보를 이용하여 상기 depth 보정값을 연 산하게 된다. 또한, 상기 제어모듈은 상기 탐지된 객체의 바운딩 박스 정보와 중심점에 대한 depth 보정값을 이용하여 후술하는 이송로봇 모듈의 동작을 제어하는 기능을 수행하게 된다. 또한, 상기 이송로봇 모듈은 상기 카메라 모듈의 후방에 설치되어 상기 영상처리 모듈에서 탐지된 이송 대상인 객체를 파지하여 외부(즉, 해당 객체의 수거함 등)로 이송하는 기능을 수행하게 되는데, 본 실시예 에서는 일예로서 상기 거치대의 수평부재 하부면에 X,Y,Z의 3축 방향으로 이동가능하게 설치되도록 구성하 였다. 또한, 상기 이송로봇 모듈은 통상의 핑거 타입의 그립퍼(gripper)나 진공 흡착 방식의 그립퍼를 이용하여 바람직하게 구성될 수 있다. 본 실시예서는 일예로서 상기 이송로봇 모듈이 상대적으로 무게가 가벼운 PET 병이나 플라스틱 용기 등의 이송에 용이한 진공 흡착 방식의 그립퍼로 이루어지는 것으로 구성하였는데, 진공 흡착 방식 그립퍼의 일반적인 구성은 공지된 기술이기 때문에 여기에서는 구체적인 설명은 생략하기로 한다. 또한, 본 실시예에서는 상기 객체 좌표 추정 방법과 객체 이송 장치가 일예로서 PET 병이나 플라스틱 용기와 같은 재활용품을 이송하는 경우를 설명하나 이에 한정되지 아니하며, 필요에 따라서는 과일과 같은 농산품이나 공산품 등의 선별및 이송에도 적용될 수 있음은 물론이다. 다음으로 도5 내지 도9를 이용하여 상술한 상술한 바와 같이 구성되는 본 발명에 따른 객체 이송 장치의 동 작을 구체적으로 설명하기로 한다. 도5는 도1에 도시한 객체 이송 장치의 동작을 설명하기 위한 순서도이고, 도6 내지 도8은 각각 도1에 도시한 장 치에서 객체의 중심점에 대한 depth 보정값을 연산하는 방법을 설명하기 위한 도면이며, 도9는 도1에 도시한 장 치에서 객체의 중심점에 대한 depth 보정값을 연산하는 경우 적용되는 픽셀별 가중치 필터를 설명하기 위한 도 면이다. 먼저, 제어모듈의 제어신호에 의하여 객체(R)가 공급된 컨베이어 모듈의 동작이 이루어지면, 상기 카 메라 모듈은 이송 대상인 객체(R)에 대하여 이미지 영상을 획득하게 된다(S10).상기 S10 단계가 완료되면, 상기 제어모듈은 영상처리 모듈을 이용하여 이미지 영상에 포함된 객체를 탐지하고, 탐지된 객체에 대한 바운딩 박스(bounding box) 정보를 생성하게 된다(S20). 상기 S20 단계를 도6을 이용하여 구체적으로 살펴보면, 상기 영상처리 모듈은 객체 탐지(object detection) 알고리즘인 YOLO v5를 이용하여 이미지 영상에 포함된 객체(200,300)를 탐지하여 각각에 대하 여 알고리즘에 미리 정해진 방식에 따라 바운딩 박스(bounding box)(201,301)를 설정하게 된다. 이와 같이 바운딩 박스(201,301) 설정이 완료되면, 상기 영상처리 모듈은 객체(200,300) 각각에 대하여 중 심점(202,302)에 대한 X 좌표값과 Y 좌표값으로 이루어지는 평면 픽셀 좌표값, 객체(200,300) 각각의 가로 길이 와 세로 길이에 관한 정보, 및 객체(200,300) 각각의 분류 클래스에 관한 정보(class 종류, 정확도 확률)를 포 함하는 바운딩 박스 정보를 획득하게 된다. 예를 들어, 도6에서 상기 영상처리 모듈은 객체 1에 대해서 (x1,y1,w1,h1,class1,prob.1)의 형태로 이루어진 바운딩 박스 정보를 획득하게 되고, 객체 2에 대해서는 (x2,y2,w2,h2,class2,prob.2)의 형태로 이루어진 바운딩 박스 정보를 획득하게 된다. 상기 S20단계가 완료되면, 상기 제어모듈은 depth 보정모듈을 이용하여 객체(200,300) 각각의 중심점 (202,302)에 대한 depth 보정값을 연산하게 된다(S30). 이를 위하여, 본 발명에서는 상기 depth 보정모듈이 객체(200,300) 각각에 대하여 중심점(202,302)을 포함 하는 형태로 이루어진 중심 영역(203,303)을 설정한 후, 상기 중심 영역(203,303)에 포함된 픽셀들의 depth 값 을 이용하여 상기 상기 객체(200,300) 각각의 중심점(202,302)에 대한 depth 보정값을 연산하게 된다. 이 경우 상기 픽셀별 depth 값은 전술한 바와 같이 상기 카메라 모듈에서 얻어진 값이 아니라 상기 좌표 연 산모듈에서 [수식 4]의 ①에 따라 연산하여 얻은 depth 값이다. 본 발명의 해결 과제와 같이 객체 중심점의 평면 실제 좌표와 depth 정보를 이용하여 상기 객체를 이송하는 이 송로봇의 동작을 제어하는 경우, 객체의 상부 표면이 평면 형상이거나 제품 그대로의 완만한 형상이 유지된 상 태이면 단순히 해당 객체의 중심점에 대한 평면 실제 좌표와 depth 정보를 이용하더라도 객체의 분리 이송이 효 율적으로 이루어질 수 있다. 그러나, 객체의 중심점에서의 표면 형상이 비정상적으로 융기되거나 함몰되어 변형된 경우 단순히 중심점의 depth 정보만으로 이송로봇의 상하 위치 제어를 하게 되면, 파지력이 부족하여 객체 이송에 실패(중심점이 비정 상적 융기된 경우)하거나 이송로봇 말단이 과도한 힘(또는 깊이)으로 객체 표면을 압박하게 됨으로써 객체나 이 송로봇의 손상/파손을 야기(중심점이 비정상적 함몰된 경우)하게 되는 문제점이 발생된다. 따라서, 본 발명에서는 이와 같은 문제점을 방지하기 위하여 중심점을 포함하도록 설정된 중심 영역(203,303)에 포함된 복수 픽셀들의 depth 값을 종합적으로 고려하여 얻은 객체(200,300) 각각의 중심점(202,302)에 대한 depth 보정값을 기준으로 이송로봇 모듈의 상하방향 위치를 제어함으로써 객체(200,300)나 이송로봇 모듈 의 손상/파손을 방지하면서도 객체(200,300)의 안정적인 파지와 이송이 이루어지도록 한 것을 특징으로 한 다. 이 경우, 상기 중심 영역(203,303)은 해당 객체의 중심점(202,302)이 가장 중앙에 위치하도록 설정되는 것이 더 욱 바람직하다. 먼저, 탐지된 객체(200,300)의 중심점(202,302)이 포함되도록 중심 영역(203,303)이 설정되면, 상기 depth 보정 모듈은 중심 영역(203,303)에 포함된 복수 픽셀들의 depth 값을 이들의 평균값, 중간값, 최소값, 최대값 또는 rms값 등을 취하는 방식으로 이용하여 객체(200,300)의 중심점(202,302)에 대한 depth 보정값을 연산하게 되는데, 본 실시예에서는 일예로서 이들 픽셀들의 depth 값을 평균하여 상기 depth 보정값을 연산하는 경우로 구성하였다. 이때, 각 픽셀들의 depth 값이 Null인 경우를 제외시키기 위하여 depth 값이 미리 정해진 depth 값 범위를 초과 하거나 미만인 경우 이를 제외한 픽셀들에 대해서만 depth 값을 평균하도록 이루어질 수도 있다. 또한, 본 발명에서는 상술한 바와 같은 방식으로 얻어지는 depth 보정값이 객체의 형상 특성을 반영할 수 있도 록 하기 위하여, 상기 depth 보정모듈이 중심 영역을 설정하는 경우 S20 단계에서 탐지된 객체의 형상에 따라 상기 중심 영역(203,303)의 형태를 다르게 설정하도록 구성한 것을 추가적인 특징으로 한다. 이를 위하여, 본 실시예에서는 상기 depth 보정모듈이 상기 중심 영역(203,303)을 일예로서 사각형 형태로 설정하되, 객체의 가로 길이와 세로 길이에 따라 상기 중심 영역(203,303)의 가로 길이와 세로 길이를 다르게 설정하는 것으로 구성하였다. 도7을 예로서 살펴보면, 객체 1과 같이 지면에서 X축 방향(즉, 컨베이어 모듈의 폭 방향)으로 길이(즉, 세 로 길이)가 더 긴 형상의 객체에 대해서는 세로 길이가 더 긴 직사각형 형태로 중심 영역이 설정되고, 객 체 2와 같이 지면에서 Y축 방향으로 길이(즉, 가로 길이)가 더 긴 형상의 객체에 대해서는 가로 길이가 더 긴 직사각형 형태로 중심 영역이 설정된다. 이 경우 각 중심 영역(203,303)의 면적은 객체(200,300)의 크기(즉, 가로 길이와 세로 길이의 크기)에 따라 다 르게 설정됨은 물론이다. 이와 같이 S20 단계에서 탐지된 객체(200,300) 각각에 대하여 중심 영역(203,303) 설정이 완료되면, 상기 depth 보정모듈은 상술한 방식으로 객체(200,300) 각각의 중심점(202,302)에 대한 depth 보정값을 연산하게 된다. 이하에서는, 도8과 도9를 참조하여 도7의 객체 2의 중심점에 대한 depth 보정값을 연산하는 방식을 일예로서 설명하기로 한다. 상기 객체 2에 대해 설정된 중심 영역에 포함된 (a) 내지 (o) 픽셀(303a)들에 대한 depth 값이 도8과 같이 획득된 경우(이는 좌표 연산모듈에서 얻어진 값임), 상기 depth 보정모듈은 아래 [수식 7]에 의하여 중심점에 대한 보정값을 1.0(실제 연산값은 1.01)으로 연산하게 된다. [수식 7]"}
{"patent_id": "10-2023-0047973", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 8, "content": "또한, 상기 depth 보정모듈은 상술한 바와 같이 중심점에 대한 보정값을 연산하는 경우 중심점 의 depth 정보를 더 비중있게 반영하기 위하여, 상기 중심 영역에 포함된 픽셀들(303a)의 depth 값에 대한 가중치를 서로 다르게 부여하도록 구성될 수도 있다. 본 실시예에서는 일예로서 도9의 (a)에 도시한 바와 같은 가중치 필터(350a)를 이용하여 상기 중심 영역에 포함된 픽셀들(303a)과 중심점과의 거리에 따라 각 픽셀별 depth 값에 대한 가중치를 서로 다르게 부여하 도록 구성하였다. 이 경우 상기 depth 보정모듈은 아래 [수식 8]에 의하여 중심점에 대한 보정값을 0.8(실제 연산값은 0.81)으로 연산하게 된다. [수식 8]"}
{"patent_id": "10-2023-0047973", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 9, "content": "또한, 상기 depth 보정모듈은 객체의 분류 클래스별로 상기 중심 영역에 포함된 픽셀(303a)들의 depth 값에 대한 가중치를 다르게 부여하여 상기 객체의 중심점에 대한 depth 보정값을 연산하도록 구성될 수도 있다. 즉, 상기 depth 보정모듈은 일예로서 상기 객체 2의 분류 class가 \"CLASS 1\"일 경우 [수식 8]에서와 같이 도9의 (a)에 도시한 가중치 필터(350a)를 적용하여 중심점에 대한 보정값을 연산하게 되고, 상기 객 체 2의 분류 class가 \"CLASS 1\"과 재질,형상 등이 상이한 \"CLASS 2\"일 경우 도9의 (b)에 도시한 가중치 필터(350b)를 적용하여 중심점에 대한 보정값을 연산하게 된다. 또한, 상기 depth 보정모듈은 중심 영역에 포함된 픽셀들 중 일부 픽셀(일예로서, 픽셀 (a),(e),(k),(o))의 depth 값을 제외하고 중심점에 대한 depth 보정값을 연산하고자 하는 경우 상기 가중치 필터(350a, 350b)에서 해당 픽셀들에 대한 가중치를 \"0\"으로 부여하면 되는데, 이는 실질적으로 중심 영역의 형태를 마름모꼴 또는 육각형 형태로 설정한 것과 동일한 효과를 나타낸다. 또한, 필요에 따라 본 발명에 따른 객체 이송 장치는 탐지된 객체에 대한 상기 이송로봇 모듈의 이송 성 공확률(즉, 분리 수거 성공여부)에 따라 상기 가중치 필터(350a,350b)를 구성하는 각 픽셀별 가중치를 재설정하 도록 구성될 수도 있다. 이를 위하여, 본 발명에 따른 객체 이송 장치는 상기 탐지된 객체에 대한 상기 이송로봇 모듈의 이송 성 공여부를 기계학습하여, 상기 depth 보정모듈이 상술한 depth 보정값을 연산할 때 적용하는 픽셀별 가중치 의 값을 재설정하는 딥러닝학습 모듈을 더 포함하도록 구성될 수 있다. 이 경우, 상기 딥러닝학습 모듈은 상기 이송로봇 모듈의 이송 성공여부를 입력층으로 하고, 상기 가중 치 필터의 각 픽셀별 가중치 값을 출력층으로 하여 기계학습을 수행함으로써 객체의 형상이나 class 별로 가장 최적의 픽셀별 가중치 값을 획득할 수 있게 된다. 상술한 바와 같이 상기 S30 단계가 완료되면, 상기 제어모듈은 해당 객체(200,300)를 이송하기 위한 이송 로봇 모듈의 X,Y,Z 방향의 이동 좌표를 연산한 후 상기 이송로봇 모듈의 동작을 제어하게 된다(S40). 이때, 상기 이송로봇 모듈이 이동하게 되는 X,Y,Z 방향의 이동 좌표는 해당 객체(200,300)의 중심점 (202,302)에 대한 평면 실제 좌표와 depth 보정값으로 주어지는데, 상기 평면 실제 좌표는 앞서 설명한 바와 같 은 방법에 의하여 좌표 연산 모듈에서 평면 픽셀 좌표로부터 연산하여 추정한 좌표이고 상기 depth 보정값 은 [수식 4]에 의해 연산된 depth 값을 이용하여 얻어진 값이다. 한편, 상기 S10단계의 이미지 영상 획득 시점부터 S30 단계에서 객체(200,300)의 중심점(202,302)에 대한 depth 보정값의 연산이 완료되는 시점 동안 상기 컨베이어 모듈은 일정 거리만큼 이동하게 되는데, 상기 객체 (200,300)의 이송 효율을 향상시키기 위해서는 이를 고려하여 객체 중심점의 Y 방향(즉, 컨베이어 모듈이 이동 하는 방향) 좌표를 보정할 필요성이 있다. 이를 위하여, 본 발명에 따른 객체 이송 장치는 S40 단계에서 컨베이어 모듈의 일측에 설치된 엔코더 모 듈을 이용하여 S10 단계에서 S30 단계까지의 컨베이어 모듈의 이동속도를 측정하게 된다. 또한, 상기 제어모듈은 상기 엔코더 모듈에서 측정한 이동속도를 이용하여 상기 이미지 영상 획득 시 점부터 탐지된 객체의 중심점에 대한 depth 보정값을 연산한 시점까지의 상기 컨베이어 모듈의 이동거리(Δｙ) 를 연산하고, 상기 연산된 이동거리(Δｙ)를 더 이용하여 상기 이송로봇 모듈의 Y 방향 이동 좌표를 (Y+Δｙ)로 보정하여 이송로봇 모듈의 동작을 제어하게 된다. 이상에서 설명한 바와 같이 본 발명에 따른 객체 이송 장치는 상기 depth 보정모듈을 이용하여 객체 (200,300)의 형상 특성, class 특성, 중심점의 비정상적 변형 특성 등을 모두 고려하여 얻은 해당 객체의 중심 점(202,302)에 대한 depth 보정값을 이용하여 이송로봇 모듈의 동작을 제어하도록 구성되기 때문에 이송로 봇 모듈의 손상/파손을 방지하면서도 객체(200,300)의 안정적인 파지와 이송이 이루어질 수 있는 장점이 있 다."}
{"patent_id": "10-2023-0047973", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도1은 본 발명의 일실시예에 따른 객체 이송 장치의 전체 구성을 나타낸 도면, 도2는 도1에 도시한 장치의 동작구성을 설명하기 위한 블럭도, 도3은 카메라 캘리브레이션에 이용되는 좌표계를 설명하기 위한 도면, 도4는 도2에 도시한 좌표 연산 모듈에서 객체의 픽셀 좌표로부터 실제 좌표를 연산하여 추정하는 방법을 설명하 기 위한 도면, 도5는 도1에 도시한 장치의 동작을 설명하기 위한 순서도, 도6 내지 도8은 각각 도1에 도시한 장치에서 객체의 중심점에 대한 depth 보정값을 연산하는 방법을 설명하기 위한 도면, 및 도9는 도1에 도시한 장치에서 객체의 중심점에 대한 depth 보정값을 연산하는 경우 적용되는 픽셀별 가중치 필 터를 설명하기 위한 도면이다."}
