{"patent_id": "10-2022-7023190", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2022-0112813", "출원번호": "10-2022-7023190", "발명의 명칭": "신경망 모델 업데이트 방법, 및 이미지 처리 방법 및 디바이스", "출원인": "후아웨이 테크놀러지 컴퍼니 리미티드", "발명자": "장, 신위"}}
{"patent_id": "10-2022-7023190", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "신경망 모델 업데이트 방법으로서,신경망 모델의 구조 및 상기 신경망 모델의 관련 파라미터를 획득하는 단계 - 상기 신경망 모델의 관련 파라미터는 상기 신경망 모델의 하이퍼-파라미터(hyper-parameter), 손실 함수(loss function), 및 평가 방식(evaluation manner)을 포함함 - ;훈련 데이터(training data)를 처리를 위해 상기 신경망 모델에 입력하여 예측 라벨(prediction label)을 획득하는 단계;상기 예측 라벨 및 상기 훈련 데이터의 라벨에 기초하여 상기 손실 함수의 함수 값을 결정하고, 상기 손실 함수의 함수 값 및 상기 신경망 모델의 하이퍼-파라미터에 기초하여 상기 신경망 모델을 훈련시켜 훈련된 신경망 모델을 획득하는 단계; 및상기 훈련된 신경망 모델을 상기 평가 방식으로 평가하고, 상기 훈련된 신경망 모델의 평가 결과가 미리 설정된조건을 충족시키지 않으면, 업데이트된 신경망 모델의 평가 결과가 상기 미리 설정된 조건을 충족시키고/시키거나 업데이트 횟수가 미리 설정된 횟수에 도달할 때까지 상기 신경망 모델의 관련 파라미터와 상기 신경망 모델의 구조 중 적어도 2개를 업데이트하는 단계를 포함하는, 방법."}
{"patent_id": "10-2022-7023190", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 신경망 모델의 관련 파라미터는 전처리 방식을 추가로 포함하고,훈련 데이터를 처리를 위해 상기 신경망 모델에 입력하여 예측 라벨을 획득하는 단계는:상기 훈련 데이터를 상기 전처리 방식으로 전처리하는 단계; 및전처리된 훈련 데이터를 처리를 위해 상기 신경망 모델에 입력하여 상기 예측 라벨을 획득하는 단계를포함하는, 방법."}
{"patent_id": "10-2022-7023190", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항 또는 제2항에 있어서, 상기 신경망 모델의 관련 파라미터는 상기 신경망 모델의 압축 방식을 추가로 포함하고,훈련 데이터를 처리를 위해 상기 신경망 모델에 입력하여 예측 라벨을 획득하는 단계는:상기 신경망 모델을 상기 신경망 모델의 압축 방식으로 처리하여 처리된 신경망 모델을 획득하는 단계; 및상기 훈련 데이터를 상기 처리된 신경망 모델에 입력하여 상기 예측 라벨을 획득하는 단계를 포함하는, 방법."}
{"patent_id": "10-2022-7023190", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항 내지 제3항 중 어느 한 항에 있어서, 상기 신경망 모델의 관련 파라미터와 상기 신경망 모델의 구조 중적어도 2개를 업데이트하는 단계는:상기 신경망 모델의 관련 파라미터와 상기 신경망 모델의 구조 중 적어도 2개의 각각의 항목에 대응하는 제1 정보에 기초하여, 각각의 항목에 대응하는 복수의 후보 옵션들의 확률 분포를 결정하는 단계 - 각각의 항목에 대응하는 상기 제1 정보는 상기 평가 결과를 포함함 - ; 및각각의 항목에 대응하는 상기 복수의 후보 옵션들의 확률 분포에 기초하여 각각의 항목에 대응하는 상기 복수의후보 옵션들 내의 하나의 후보 옵션을 각각의 항목의 업데이트된 옵션으로서 결정하는 단계를 포함하는, 방법.공개특허 10-2022-0112813-3-청구항 5 제4항에 있어서, 각각의 항목에 대응하는 상기 제1 정보는 상기 신경망 모델의 관련 파라미터와 상기 신경망 모델의 구조 중 적어도 2개에서의 다른 항목의 관련 정보를 추가로 포함하고, 상기 다른 항목의 관련 정보는 상기다른 항목 및/또는 상기 다른 항목에 대응하는 복수의 후보 옵션들의 확률 분포를 포함하는, 방법."}
{"patent_id": "10-2022-7023190", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5항에 있어서, 각각의 항목에 대응하는 상기 제1 정보는 각각의 항목의 이력 관련 정보를 추가로 포함하고,각각의 항목의 상기 이력 관련 정보는 상기 이전 업데이트에서의 각각의 항목의 업데이트된 옵션 및/또는 상기이전 업데이트에서의 각각의 항목에 대응하는 상기 복수의 후보 옵션들의 확률 분포를 포함하는, 방법."}
{"patent_id": "10-2022-7023190", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제4항 내지 제6항 중 어느 한 항에 있어서, 각각의 항목에 대응하는 상기 제1 정보는 훈련 자원 상태 정보를 추가로 포함하고, 상기 훈련 자원 상태 정보는 훈련 머신들의 수량을 포함하는, 방법."}
{"patent_id": "10-2022-7023190", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1항 내지 제7항 중 어느 한 항에 있어서, 상기 신경망 모델의 하이퍼-파라미터는 상기 신경망 모델의 훈련 프로세스에서 변경되지 않은 채로 유지되는 파라미터를 포함하는, 방법."}
{"patent_id": "10-2022-7023190", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1항 내지 제8항 중 어느 한 항에 있어서, 상기 신경망 모델의 하이퍼-파라미터는: 상기 신경망 모델의학습률, 상기 신경망 모델의 가중치 감쇠 계수, 상기 신경망 모델의 라벨 평활 계수, 또는 상기 신경망 모델의드롭아웃 파라미터 중 하나 이상을 포함하는, 방법."}
{"patent_id": "10-2022-7023190", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "이미지 처리 방법으로서,처리될 이미지를 획득하는 단계; 및목표 신경망 모델을 사용함으로써 상기 처리될 이미지를 처리하여 상기 처리될 이미지의 처리 결과를 획득하는단계를 포함하고,상기 목표 신경망 모델은 업데이트된 신경망 모델의 평가 결과가 미리 설정된 조건을 충족시키고/시키거나 업데이트 횟수가 미리 설정된 횟수에 도달할 때까지 신경망 모델의 관련 파라미터와 상기 신경망 모델의 구조 중 적어도 2개를 업데이트함으로써 획득되고, 상기 신경망 모델의 관련 파라미터는 상기 신경망 모델의 하이퍼-파라미터, 손실 함수, 및 평가 방식을 포함하고, 상기 신경망 모델은 예측 라벨 및 훈련 데이터의 라벨에 기초하여상기 손실 함수의 함수 값을 결정하고 상기 신경망 모델의 하이퍼-파라미터 및 손실 함수의 함수 값에 기초하여훈련을 수행함으로써 획득되고, 상기 예측 라벨은 상기 훈련 데이터를 처리를 위해 상기 신경망 모델에 입력함으로써 획득되는, 방법."}
{"patent_id": "10-2022-7023190", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제10항에 있어서, 상기 신경망 모델의 관련 파라미터는 전처리 방식을 추가로 포함하고, 상기 예측 라벨은 상기훈련 데이터를 상기 전처리 방식으로 전처리하고 전처리된 훈련 데이터를 처리를 위해 상기 신경망 모델에 입력함으로써 획득되는, 방법."}
{"patent_id": "10-2022-7023190", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제10항 또는 제11항에 있어서, 상기 신경망 모델의 관련 파라미터는 상기 신경망 모델의 압축 방식을 추가로 포함하고, 상기 예측 라벨은 상기 신경망 모델을 상기 신경망 모델의 상기 압축 방식으로 처리하고 상기 훈련 데이터를 처리된 신경망 모델에 입력함으로써 획득되는, 방법."}
{"patent_id": "10-2022-7023190", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제10항 내지 제12항 중 어느 한 항에 있어서, 상기 신경망 모델의 관련 파라미터와 상기 신경망 모델의 구조 중공개특허 10-2022-0112813-4-적어도 2개를 업데이트하는 단계는:상기 신경망 모델의 관련 파라미터와 상기 신경망 모델의 구조 중 적어도 2개의 각각의 항목에 대응하는 제1 정보에 기초하여, 각각의 항목에 대응하는 복수의 후보 옵션들의 확률 분포를 결정하는 단계 - 각각의 항목에 대응하는 상기 제1 정보는 상기 평가 결과를 포함함 - ; 및각각의 항목에 대응하는 상기 복수의 후보 옵션들의 확률 분포에 기초하여 각각의 항목에 대응하는 상기 복수의후보 옵션들 내의 하나의 후보 옵션을 각각의 항목의 업데이트된 옵션으로서 결정하는 단계를 포함하는, 방법."}
{"patent_id": "10-2022-7023190", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제13항에 있어서, 각각의 항목에 대응하는 상기 제1 정보는 상기 신경망 모델의 관련 파라미터와 상기 신경망모델의 구조 중 적어도 2개에서의 다른 항목의 관련 정보를 추가로 포함하고, 상기 다른 항목의 관련 정보는 상기 다른 항목 및/또는 상기 다른 항목에 대응하는 복수의 후보 옵션들의 확률 분포를 포함하는, 방법."}
{"patent_id": "10-2022-7023190", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제14항에 있어서, 각각의 항목에 대응하는 상기 제1 정보는 각각의 항목의 이력 관련 정보를 추가로 포함하고,각각의 항목의 상기 이력 관련 정보는 상기 이전 업데이트에서의 각각의 항목의 업데이트된 옵션 및/또는 상기이전 업데이트에서의 각각의 항목에 대응하는 상기 복수의 후보 옵션들의 확률 분포를 포함하는, 방법."}
{"patent_id": "10-2022-7023190", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제13항 내지 제15항 중 어느 한 항에 있어서, 각각의 항목에 대응하는 상기 제1 정보는 훈련 자원 상태 정보를추가로 포함하고, 상기 훈련 자원 상태 정보는 훈련 머신들의 수량을 포함하는, 방법."}
{"patent_id": "10-2022-7023190", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제10항 내지 제16항 중 어느 한 항에 있어서, 상기 신경망 모델의 하이퍼-파라미터는 상기 신경망 모델의 훈련프로세스에서 변경되지 않은 채로 유지되는 파라미터를 포함하는, 방법."}
{"patent_id": "10-2022-7023190", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제10항 내지 제17항 중 어느 한 항에 있어서, 상기 신경망 모델의 하이퍼-파라미터는: 상기 신경망 모델의 학습률, 상기 신경망 모델의 가중치 감쇠 계수, 상기 신경망 모델의 라벨 평활 계수, 또는 상기 신경망 모델의 드롭아웃 파라미터 중 하나 이상을 포함하는, 방법."}
{"patent_id": "10-2022-7023190", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "신경망 모델 업데이트 장치로서,신경망 모델의 구조 및 상기 신경망 모델의 관련 파라미터를 획득하도록 구성되는 획득 유닛 - 상기 신경망 모델의 관련 파라미터는 상기 신경망 모델의 하이퍼-파라미터, 손실 함수, 및 평가 방식을 포함함 - ; 및평가 유닛을 포함하고, 상기 평가 유닛은:훈련 데이터를 처리를 위해 상기 신경망 모델에 입력하여 예측 라벨을 획득하고;상기 예측 라벨 및 상기 훈련 데이터의 라벨에 기초하여 상기 손실 함수의 함수 값을 결정하고, 상기 손실 함수의 함수 값 및 상기 신경망 모델의 하이퍼-파라미터에 기초하여 상기 신경망 모델을 훈련시켜 훈련된 신경망 모델을 획득하고;상기 훈련된 신경망 모델을 상기 평가 방식으로 평가하고, 상기 훈련된 신경망 모델의 평가 결과가 미리 설정된조건을 충족시키지 않으면, 업데이트된 신경망 모델의 평가 결과가 상기 미리 설정된 조건을 충족시키고/시키거나 업데이트 횟수가 미리 설정된 횟수에 도달할 때까지 상기 신경망 모델의 관련 파라미터와 상기 신경망 모델의 구조 중 적어도 2개를 업데이트하도록 구성되는, 장치."}
{"patent_id": "10-2022-7023190", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제19항에 있어서, 상기 신경망 모델의 관련 파라미터는 전처리 방식을 추가로 포함하고, 상기 평가 유닛은:공개특허 10-2022-0112813-5-상기 훈련 데이터를 상기 전처리 방식으로 전처리하고;전처리된 훈련 데이터를 처리를 위해 상기 신경망 모델에 입력하여 상기 예측 라벨을 획득하도록 구성되는, 장치."}
{"patent_id": "10-2022-7023190", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_21", "content": "제19항 또는 제20항에 있어서, 상기 신경망 모델의 관련 파라미터는 상기 신경망 모델의 압축 방식을 추가로 포함하고, 상기 평가 유닛은:상기 신경망 모델을 상기 신경망 모델의 압축 방식으로 처리하여 처리된 신경망 모델을 획득하고;상기 훈련 데이터를 상기 처리된 신경망 모델에 입력하여 상기 예측 라벨을 획득하도록 구성되는, 장치."}
{"patent_id": "10-2022-7023190", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_22", "content": "제19항 내지 제21항 중 어느 한 항에 있어서, 상기 평가 유닛은:상기 신경망 모델의 관련 파라미터와 상기 신경망 모델의 구조 중 적어도 2개의 각각의 항목에 대응하는 제1 정보에 기초하여, 각각의 항목에 대응하는 복수의 후보 옵션들의 확률 분포를 결정하고 - 각각의 항목에 대응하는상기 제1 정보는 상기 평가 결과를 포함함 - ; 및각각의 항목에 대응하는 상기 복수의 후보 옵션들의 확률 분포에 기초하여 각각의 항목에 대응하는 상기 복수의후보 옵션들 내의 하나의 후보 옵션을 각각의 항목의 업데이트된 옵션으로서 결정하도록 구성되는, 장치."}
{"patent_id": "10-2022-7023190", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_23", "content": "제22항에 있어서, 각각의 항목에 대응하는 상기 제1 정보는 적어도 2개에서의 다른 항목의 관련 정보를 추가로포함하고, 상기 다른 항목의 관련 정보는 상기 다른 항목 및/또는 상기 다른 항목에 대응하는 복수의 후보 옵션들의 확률 분포를 포함하는, 장치."}
{"patent_id": "10-2022-7023190", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_24", "content": "제23항에 있어서, 각각의 항목에 대응하는 상기 제1 정보는 각각의 항목의 이력 관련 정보를 추가로 포함하고,각각의 항목의 상기 이력 관련 정보는 상기 이전 업데이트에서의 각각의 항목의 업데이트된 옵션 및/또는 상기이전 업데이트에서의 각각의 항목에 대응하는 상기 복수의 후보 옵션들의 확률 분포를 포함하는, 장치."}
{"patent_id": "10-2022-7023190", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_25", "content": "제22항 내지 제24항 중 어느 한 항에 있어서, 각각의 항목에 대응하는 상기 제1 정보는 훈련 자원 상태 정보를추가로 포함하고, 상기 훈련 자원 상태 정보는 훈련 머신들의 수량을 포함하는, 장치."}
{"patent_id": "10-2022-7023190", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_26", "content": "제19항 내지 제25항 중 어느 한 항에 있어서, 상기 신경망 모델의 하이퍼-파라미터는 상기 신경망 모델의 훈련프로세스에서 변경되지 않은 채로 유지되는 파라미터를 포함하는, 장치."}
{"patent_id": "10-2022-7023190", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_27", "content": "제19항 내지 제26항 중 어느 한 항에 있어서, 상기 신경망 모델의 하이퍼-파라미터는: 상기 신경망 모델의 학습률, 상기 신경망 모델의 가중치 감쇠 계수, 상기 신경망 모델의 라벨 평활 계수, 또는 상기 신경망 모델의 드롭아웃 파라미터 중 하나 이상을 포함하는, 장치."}
{"patent_id": "10-2022-7023190", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_28", "content": "이미지 처리 장치로서,처리될 이미지를 획득하도록 구성되는 획득 유닛; 및목표 신경망 모델을 사용함으로써 상기 처리될 이미지를 처리하여 상기 처리될 이미지의 처리 결과를 획득하도록 구성되는 이미지 처리 유닛공개특허 10-2022-0112813-6-을 포함하고,상기 목표 신경망 모델은 업데이트된 신경망 모델의 평가 결과가 미리 설정된 조건을 충족시키고/시키거나 업데이트 횟수가 미리 설정된 횟수에 도달할 때까지 신경망 모델의 관련 파라미터와 상기 신경망 모델의 구조 중 적어도 2개를 업데이트함으로써 획득되고, 상기 신경망 모델의 관련 파라미터는 상기 신경망 모델의 하이퍼-파라미터, 손실 함수, 및 평가 방식을 포함하고, 상기 신경망 모델은 예측 라벨 및 훈련 데이터의 라벨에 기초하여상기 손실 함수의 함수 값을 결정하고 상기 신경망 모델의 하이퍼-파라미터 및 손실 함수의 함수 값에 기초하여훈련을 수행함으로써 획득되고, 상기 예측 라벨은 상기 훈련 데이터를 처리를 위해 상기 신경망 모델에 입력함으로써 획득되는, 장치."}
{"patent_id": "10-2022-7023190", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_29", "content": "제28항에 있어서, 상기 신경망 모델의 관련 파라미터는 전처리 방식을 추가로 포함하고, 상기 예측 라벨은 상기훈련 데이터를 상기 전처리 방식으로 전처리하고 전처리된 훈련 데이터를 처리를 위해 상기 신경망 모델에 입력함으로써 획득되는, 장치."}
{"patent_id": "10-2022-7023190", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_30", "content": "제28항 또는 제29항에 있어서, 상기 신경망 모델의 관련 파라미터는 상기 신경망 모델의 압축 방식을 추가로 포함하고, 상기 예측 라벨은 상기 신경망 모델을 상기 신경망 모델의 상기 압축 방식으로 처리하고 상기 훈련 데이터를 처리된 신경망 모델에 입력함으로써 획득되는, 장치."}
{"patent_id": "10-2022-7023190", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_31", "content": "제28항 내지 제30항 중 어느 한 항에 있어서, 상기 신경망 모델의 관련 파라미터와 상기 신경망 모델의 구조 중적어도 2개를 업데이트하는 것은:상기 신경망 모델의 관련 파라미터와 상기 신경망 모델의 구조 중 적어도 2개의 각각의 항목에 대응하는 제1 정보에 기초하여, 각각의 항목에 대응하는 복수의 후보 옵션들의 확률 분포를 결정하는 것 - 각각의 항목에 대응하는 상기 제1 정보는 상기 평가 결과를 포함함 - ; 및각각의 항목에 대응하는 상기 복수의 후보 옵션들의 확률 분포에 기초하여 각각의 항목에 대응하는 상기 복수의후보 옵션들 내의 하나의 후보 옵션을 각각의 항목의 업데이트된 옵션으로서 결정하는 것을 포함하는, 장치."}
{"patent_id": "10-2022-7023190", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_32", "content": "제31항에 있어서, 각각의 항목에 대응하는 상기 제1 정보는 상기 신경망 모델의 관련 파라미터와 상기 신경망모델의 구조 중 적어도 2개에서의 다른 항목의 관련 정보를 추가로 포함하고, 상기 다른 항목의 관련 정보는 상기 다른 항목 및/또는 상기 다른 항목에 대응하는 복수의 후보 옵션들의 확률 분포를 포함하는, 장치."}
{"patent_id": "10-2022-7023190", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_33", "content": "제32항에 있어서, 각각의 항목에 대응하는 상기 제1 정보는 각각의 항목의 이력 관련 정보를 추가로 포함하고,각각의 항목의 상기 이력 관련 정보는 상기 이전 업데이트에서의 각각의 항목의 업데이트된 옵션 및/또는 상기이전 업데이트에서의 각각의 항목에 대응하는 상기 복수의 후보 옵션들의 확률 분포를 포함하는, 장치."}
{"patent_id": "10-2022-7023190", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_34", "content": "제31항 내지 제33항 중 어느 한 항에 있어서, 각각의 항목에 대응하는 상기 제1 정보는 훈련 자원 상태 정보를추가로 포함하고, 상기 훈련 자원 상태 정보는 훈련 머신들의 수량을 포함하는, 장치."}
{"patent_id": "10-2022-7023190", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_35", "content": "제28항 내지 제34항 중 어느 한 항에 있어서, 상기 신경망 모델의 하이퍼-파라미터는 상기 신경망 모델의 훈련프로세스에서 변경되지 않은 채로 유지되는 파라미터를 포함하는, 장치."}
{"patent_id": "10-2022-7023190", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_36", "content": "제28항 내지 제35항 중 어느 한 항에 있어서, 상기 신경망 모델의 하이퍼-파라미터는: 상기 신경망 모델의 학습공개특허 10-2022-0112813-7-률, 상기 신경망 모델의 가중치 감쇠 계수, 상기 신경망 모델의 라벨 평활 계수, 또는 상기 신경망 모델의 드롭아웃 파라미터 중 하나 이상을 포함하는, 장치."}
{"patent_id": "10-2022-7023190", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_37", "content": "신경망 모델 업데이트 장치로서, 프로세서 및 메모리를 포함하고, 상기 메모리는 프로그램 명령어들을 저장하도록 구성되고, 상기 프로세서는 상기 프로그램 명령어들을 호출하여 제1항 내지 제9항 중 어느 한 항에 따른 방법을 수행하도록 구성되는, 장치."}
{"patent_id": "10-2022-7023190", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_38", "content": "이미지 처리 장치로서, 프로세서 및 메모리를 포함하고, 상기 메모리는 프로그램 명령어들을 저장하도록 구성되고, 상기 프로세서는 상기 프로그램 명령어들을 호출하여 제10항 내지 제18항 중 어느 한 항에 따른 방법을 수행하도록 구성되는, 장치."}
{"patent_id": "10-2022-7023190", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_39", "content": "컴퓨터 판독가능 저장 매체로서, 상기 컴퓨터 판독가능 저장 매체는 디바이스에 의해 실행될 프로그램 코드를저장하고, 상기 프로그램 코드는 제1항 내지 제9항 또는 제10항 내지 제18항 중 어느 한 항에 따른 방법을 수행하기 위해 사용되는, 컴퓨터 판독가능 저장 매체."}
{"patent_id": "10-2022-7023190", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_40", "content": "칩으로서, 상기 칩은 프로세서 및 데이터 인터페이스를 포함하고, 상기 프로세서는 상기 데이터 인터페이스를통해 메모리에 저장된 명령어들을 판독하여 제1항 내지 제9항 또는 제10항 내지 제18항 중 어느 한 항에 따른방법을 수행하는, 칩."}
{"patent_id": "10-2022-7023190", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 출원은 인공 지능 분야에서의 신경망 모델 업데이트 방법, 이미지 처리 방법, 및 장치를 개시한다. 신경망 모델 업데이트 방법은: 신경망 모델의 구조 및 신경망 모델의 관련 파라미터를 획득하는 단계; 신경망 모델의 관 련 파라미터에 기초하여 신경망 모델을 훈련시켜 훈련된 신경망 모델을 획득하는 단계; 훈련된 신경망 모델의 평 가 결과가 미리 설정된 조건을 충족시키지 않으면, 업데이트된 신경망 모델의 평가 결과가 미리 설정된 조건을 충족시키고/시키거나 업데이트 횟수가 미리 설정된 횟수에 도달할 때까지 신경망 모델의 관련 파라미터와 신경망 모델의 구조 중 적어도 2개를 업데이트하는 단계를 포함한다. 본 출원의 방법에 따르면, 신경망 모델을 업데이 트하는 효율이 향상될 수 있고, 더 양호한 성능을 갖는 신경망 모델의 구조 및/또는 신경망 모델의 관련 파라미 터가 획득될 수 있다."}
{"patent_id": "10-2022-7023190", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 출원은 2019년 12월 19일자로 중국 지적 재산권 관리국(China National Intellectual Property Administration)에 출원되고 발명의 명칭이 \"NEURAL NETWORK MODEL UPDATE METHOD, IMAGE PROCESSING METHOD, AND APPARATUS\"인 중국 특허 출원 제201911314332.6호에 대한 우선권을 주장하며, 그 전체가 본 명세서에 참조 로 포함된다. 본 출원은 인공 지능 분야에 관한 것으로, 특히, 신경망 모델 업데이트 방법, 이미지 처리 방법, 및 장치에 관 한 것이다."}
{"patent_id": "10-2022-7023190", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "인공 지능(artificial intelligence, AI)은 디지털 컴퓨터 또는 디지털 컴퓨터에 의해 제어되는 머신을 사용하 여 인간 지능을 시뮬레이션, 확대, 및 확장하고, 환경을 감지하고, 지식을 획득하고, 지식을 사용하여 최상의 결과를 획득하는 이론, 방법, 기술, 및 응용 시스템이다. 다시 말해서, 인공 지능은 컴퓨터 과학의 한 분야이 며, 지능의 본질을 이해하고 인간 지능과 유사한 방식으로 반응할 수 있는 새로운 지능형 머신을 생산하려는 것 이다. 인공 지능은 다양한 지능형 머신들의 설계 원리들 및 구현 방법들을 연구하여, 머신들이 인지, 추론, 및 의사 결정 기능들을 갖도록 하는 것이다. 인공 지능 분야에서의 연구들은 로봇, 자연어 처리, 컴퓨터 비전, 의 사 결정 및 추론, 인간-컴퓨터 상호작용, 추천 및 검색, AI 기본 이론 등을 포함한다. 인공 지능 기술의 급속한 발전에 따라, 신경망(예를 들어, 컨볼루션 신경망)의 성능이 지속적으로 개선되고, 신 경망은 이미지, 비디오, 및 음성과 같은 복수의 미디어 신호를 처리하고 분석하는데 있어서 큰 성취를 이루었다. 양호한 성능을 갖는 신경망은 일반적으로 미세한 네트워크 구조를 갖는다. 그러나, 실제 응용에서 는, 상이한 훈련 세트들, 지시자 요건들, 및 응용 목적들로 인해, 기존의 네트워크 구조가 직접 사용될 수 없다. 전체 서비스 프로세스의 경우, 종래의 해결책에서, 원시 데이터는 일반적으로 처리를 위해 전처리 모듈에 전송 되고, 처리된 데이터는 특징 학습을 위해 신경망에 전송되며, 그 후 손실 함수를 사용하여 신경망을 업데이트한 다. 현재, 종래의 해결책에서의 일반적인 관행은 서비스 프로세스에서의 각각의 모듈에 대해 자동화된 머신 학습(automated machine learning, AutoML) 태스크를 별개로 설계하고, AutoML에 기초하여 각각의 모듈을 자동으 로 검색하여, 각각의 모듈의 최적 모듈, 예를 들어, 전처리 방식, 네트워크 모델 구조, 및 손실 함수를 획득하 는 것이다. 그러나, 전술한 해결책들에서 획득된 모듈들이 조합된 후에, 최적의 성능이 획득되지 않을 수 있다. 일부 모듈들 사이에 충돌이 있을 때에도, 시스템 성능이 저하될 수 있다. 따라서, 신경망 모델을 효율적으로 업데이트하는 방법은 긴급히 해결될 필요가 있는 기술적 문제가 된다. 본 출원은 신경망 모델을 업데이트하는 효율을 개선하기 위한 신경망 모델 업데이트 방법, 이미지 처리 방법, 및 장치를 제공한다. 제1 양태에 따르면, 신경망 모델 업데이트 방법이 제공된다. 방법은: 신경망 모델의 구조 및 신경망 모델의 관 련 파라미터를 획득하는 단계; 훈련 데이터를 처리를 위해 신경망 모델에 입력하여 예측 라벨을 획득하는 단계; 예측 라벨 및 훈련 데이터의 라벨에 기초하여 손실 함수의 함수 값을 결정하고, 손실 함수의 함수 값 및 신경망 모델의 하이퍼-파라미터(hyper-parameter)에 기초하여 신경망 모델을 훈련시켜 훈련된 신경망 모델을 획득하는 단계; 및 훈련된 신경망 모델을 평가 방식으로 평가하고, 훈련된 신경망 모델의 평가 결과가 미리 설정된 조건 을 충족시키지 않으면, 업데이트된 신경망 모델의 평가 결과가 미리 설정된 조건을 충족시키고/시키거나 업데이 트 횟수가 미리 설정된 횟수에 도달할 때까지 신경망 모델의 관련 파라미터와 신경망 모델의 구조 중 적어도 2 개를 업데이트하는 단계를 포함한다. 신경망 모델의 관련 파라미터는 신경망 모델의 하이퍼-파라미터, 손실 함 수, 및 평가 방식을 포함한다. 구체적으로, 신경망 모델의 관련 파라미터와 신경망 모델의 구조 중 적어도 2개를 업데이트하는 것은 신경망 모 델의 구조를 업데이트하는 것 및/또는 신경망 모델의 관련 파라미터를 업데이트하는 것을 포함한다. 예를 들어, 신경망 모델의 관련 파라미터와 신경망 모델의 구조 중 적어도 2개를 업데이트하는 것은 신경망 모 델의 구조 및 손실 함수를 업데이트하는 것일 수 있다. 다른 예로서, 신경망 모델의 관련 파라미터와 신경망 모델의 구조 중 적어도 2개를 업데이트하는 것은 신경망 모델의 하이퍼-파라미터 및 손실 함수를 업데이트하는 것일 수 있다. 다시 말해서, 업데이트 프로세스에서, 신 경망 모델의 구조 및 평가 방식은 변경되지 않은 채로 유지될 수 있다. 이 경우, 신경망 모델의 손실 함수 및 하이퍼-파라미터의 최적 조합 방식이 획득될 수 있다. 조합 방식은 다른 신경망 모델에 적용되어, 신경망 모델 을 업데이트하는 효율을 향상시킬 수 있다. 예를 들어, 평가 방식은 평가 지시자에 관련된다. 평가 지시자는 신경망 모델의 목표 크기, 신경망 모델의 목 표 추론 정확도, 신경망 모델의 목표 추론 지연 등 중 적어도 하나를 포함할 수 있다. 신경망 모델의 목표 크 기는 신경망 모델에 의해 점유된 목표 메모리 공간으로서 이해될 수 있다. 예를 들어, 평가 방식은 신경망 모델의 크기 및 신경망 모델의 추론 정확도를 평가하는 것을 포함할 수 있다. 다른 예로서, 평가 방식은 신경망 모델의 추론 정확도를 평가하는 것을 포함할 수 있다. 평가 방식은 사용자 요건에 기초하여 설정될 수 있다는 것을 이해해야 한다. 평가 지시자의 특정 내용은 본 출 원의 이 실시예에서 제한되지 않는다. 본 출원의 이 실시예에서, 신경망 모델의 관련 파라미터와 신경망 모델의 구조 중 임의의 2개가 업데이트되고, 업데이트된 신경망 모델의 관련 파라미터와 신경망 모델의 구조가 평가되어, 복수의 파라미터들의 공동 평가를 구현한다. 이것은 각각의 파라미터가 별개로 업데이트될 때 존재하는 가능한 충돌을 회피한다. 따라서, 신경 망 모델의 관련 파라미터와 신경망 모델의 구조의 최종적으로 획득된 조합은 가능한 한 빨리 요구되는 성능 지 시자에 도달할 수 있다. 이것은 신경망 모델을 업데이트하는 효율을 향상시킨다. 제1 양태를 참조하면, 제1 양태의 일부 구현들에서, 신경망 모델의 관련 파라미터는 전처리 방식을 추가로 포함 한다. 훈련 데이터를 처리를 위해 신경망 모델에 입력하여 예측 라벨을 획득하는 단계는: 훈련 데이터를 전처 리 방식으로 전처리하는 단계; 및 전처리된 훈련 데이터를 처리를 위해 신경망 모델에 입력하여 예측 라벨을 획 득하는 단계를 포함한다. 제1 양태를 참조하면, 제1 양태의 일부 구현들에서, 신경망 모델의 관련 파라미터는 신경망 모델의 압축 방식을 추가로 포함한다. 훈련 데이터를 처리를 위해 신경망 모델에 입력하여 예측 라벨을 획득하는 단계는: 신경망 모델을 신경망 모델의 압축 방식으로 처리하여 처리된 신경망 모델을 획득하는 단계; 및 훈련 데이터를 처리된신경망 모델에 입력하여 예측 라벨을 획득하는 단계를 포함한다. 구체적으로, 신경망 모델을 신경망 모델의 압축 방식으로 처리하는 것은 신경망 모델을 압축하는 것 및/또는 신 경망 모델을 양자화하는 것을 포함한다. 제1 양태를 참조하면, 제1 양태의 일부 구현들에서, 신경망 모델의 관련 파라미터와 신경망 모델의 구조 중 적 어도 2개를 업데이트하는 단계는: 신경망 모델의 관련 파라미터와 신경망 모델의 구조 중 적어도 2개의 각각의 항목에 대응하는 제1 정보에 기초하여, 각각의 항목에 대응하는 복수의 후보 옵션들의 확률 분포를 결정하는 단 계 - 각각의 항목에 대응하는 제1 정보는 평가 결과를 포함함 - ; 및 각각의 항목에 대응하는 복수의 후보 옵션 들의 확률 분포에 기초하여 각각의 항목에 대응하는 복수의 후보 옵션들 내의 하나의 후보 옵션을 각각의 항목 의 업데이트된 옵션으로서 결정하는 단계를 포함한다. 예를 들어, 신경망 모델의 구조 및 손실 함수를 업데이트하는 단계는: 신경망 모델의 구조에 대응하는 제1 정보 에 기초하여 신경망 모델의 복수의 후보 구조들의 확률 분포를 결정하고, 신경망 모델의 복수의 구조들의 확률 분포에 기초하여 신경망 모델의 복수의 후보 구조들 중 하나를 신경망 모델의 업데이트된 구조로서 결정하는 단 계; 손실 함수에 대응하는 제1 정보에 기초하여 복수의 후보 손실 함수들의 확률 분포를 결정하는 단계; 및 손 실 함수에 대응하는 제1 정보에 기초하여 복수의 후보 손실 함수들의 확률 분포를 결정하고, 복수의 후보 손실 함수들의 확률 분포에 기초하여 복수의 후보 손실 함수들 중 하나를 업데이트된 손실 함수로서 결정하는 단계를 포함한다. 신경망 모델의 구조에 대응하는 제1 정보는 업데이트된 신경망 모델의 평가 결과를 포함한다. 손실 함수에 대응하는 제1 정보는 업데이트된 신경망 모델의 평가 결과를 포함한다. 본 출원의 이 실시예에서, 각각의 항목에 대응하는 복수의 후보 옵션들의 확률 분포에 기초하여 각각의 항목에 대응하는 복수의 후보 옵션들 중 하나가 각각의 항목의 업데이트된 옵션으로서 결정된다. 이러한 방식으로, 업 데이트 프로세스의 효율이 향상될 수 있고, 업데이트 프로세스의 로컬 최적화가 회피될 수 있다. 제1 양태를 참조하면, 제1 양태의 일부 구현들에서, 각각의 항목에 대응하는 제1 정보는 신경망 모델의 관련 파 라미터와 신경망 모델의 구조 중 적어도 2개에서의 다른 항목의 관련 정보를 추가로 포함한다. 나머지 항목의 관련 정보는 나머지 항목 및/또는 나머지 항목에 대응하는 복수의 후보 옵션들의 확률 분포를 포함한다. 본 출원의 이 실시예에서, 나머지 항목의 관련 정보는 업데이트 프로세스에서 획득되어, 공동 업데이트 및 최적 화를 구현한다. 파라미터들 사이의 가능한 충돌이 업데이트 프로세스에서 회피될 수 있어, 신경망 모델의 관련 파라미터와 신경망 모델의 구조의 최종적으로 획득된 조합이 가능한 한 빨리 요구되는 성능 지시자에 도달할 수 있다. 이것은 신경망 모델을 업데이트하는 효율을 향상시킨다. 제1 양태를 참조하면, 제1 양태의 일부 구현들에서, 방법은: 제1 빈도에 기초하여 나머지 항목의 관련 정보를 획득하는 단계를 추가로 포함하고, 제1 빈도는 훈련된 신경망 모델에 의해 처리되는 서비스의 규모와 관련된다. 제1 양태를 참조하면, 제1 양태의 일부 구현들에서, 각각의 항목에 대응하는 제1 정보는 각각의 항목의 이력 관 련 정보를 추가로 포함한다. 각각의 항목의 이력 관련 정보는 이전 업데이트에서의 각각의 항목의 업데이트된 옵션 및/또는 이전 업데이트에서의 각각의 항목에 대응하는 복수의 후보 옵션들의 확률 분포를 포함한다. 제1 양태를 참조하면, 제1 양태의 일부 구현들에서, 각각의 항목에 대응하는 제1 정보는 훈련 자원 상태 정보를 추가로 포함한다. 훈련 자원 상태 정보는 훈련 머신들의 수량을 포함한다. 훈련 자원 상태 정보는 현재 이용가능한 훈련 머신들의 수량을 추가로 포함할 수 있다. 제1 양태를 참조하면, 제1 양태의 일부 구현들에서, 신경망 모델의 하이퍼-파라미터는 신경망 모델의 훈련 프로 세스에서 변경되지 않은 채로 유지되는 파라미터를 포함한다. 제1 양태를 참조하면, 제1 양태의 일부 구현들에서, 신경망 모델의 하이퍼-파라미터는 다음 중 하나 이상을 포 함한다: 신경망 모델의 학습률, 신경망 모델의 가중치 감쇠 계수, 신경망 모델의 라벨 평활 계수, 또는 신경망 모델의 드롭아웃 파라미터. 제2 양태에 따르면, 이미지 처리 방법이 제공된다. 방법은: 처리될 이미지를 획득하는 단계; 및 목표 신경망 모델을 사용함으로써 처리될 이미지를 처리하여 처리될 이미지의 처리 결과를 획득하는 단계를 포함한다. 목표 신경망 모델은 업데이트된 신경망 모델의 평가 결과가 미리 설정된 조건을 충족시키고/시키거나 업데이트 횟수 가 미리 설정된 횟수에 도달할 때까지 신경망 모델의 관련 파라미터와 신경망 모델의 구조 중 적어도 2개를 업 데이트함으로써 획득된다. 신경망 모델의 관련 파라미터는 신경망 모델의 하이퍼-파라미터, 손실 함수, 및 평가 방식을 포함한다. 신경망 모델은 예측 라벨 및 훈련 데이터의 라벨에 기초하여 손실 함수의 함수 값을 결정 하고 신경망 모델의 하이퍼-파라미터 및 손실 함수의 함수 값에 기초하여 훈련을 수행함으로써 획득된다. 예측 라벨은 훈련 데이터를 처리를 위해 신경망 모델에 입력함으로써 획득된다. 제2 양태에서의 이미지 처리 방법에서 사용되는 목표 신경망 모델에 의해 이미지 분류가 수행되기 전에, 목표 신경망 모델은 훈련 이미지에 기초하여 추가로 훈련될 수 있고, 훈련된 목표 신경망 모델이 처리될 이미지를 분 류할 수 있다는 것을 이해해야 한다. 다시 말해서, 목표 신경망 모델은 제1 양태에서의 신경망 모델 업데이트 방법을 사용하여 획득될 수 있다. 그 후, 목표 신경망 모델은 훈련 이미지에 기초하여 훈련된다. 훈련이 완료된 후에, 목표 신경망 모델은 처리될 이미지를 분류할 수 있다. 대안적으로, 목표 신경망 모델은 제1 양태에서의 신경망 모델 업데이트 방법을 사용하여 획득될 수 있다. 목표 신경망 모델은 훈련된 신경망 모델일 수 있다. 훈련된 신경망 모델은 처리될 이미지를 분류할 수 있다. 본 출원에서, 목표 신경망 모델은 제1 양태에서의 방법을 사용하여 획득되기 때문에, 목표 신경망 모델은 신경 망 모델의 응용 요건을 충족시키거나 그에 접근한다. 이미지 분류를 위해, 신경망 모델은 양호한 이미지 분류 효과(예를 들어, 더 정확한 분류 결과)를 달성할 수 있다. 신경망 모델과 신경망 모델의 관련 파라미터 중 임 의의 2개가 업데이트되고, 업데이트된 신경망 모델과 신경망 모델의 관련 파라미터가 평가되어, 복수의 파라미 터들의 공동 평가를 구현한다. 이것은 각각의 파라미터가 별개로 업데이트될 때 존재하는 가능한 충돌을 회피 한다. 따라서, 신경망 모델과 신경망 모델의 관련 파라미터의 최종적으로 획득된 조합은 가능한 한 빨리 요구 되는 성능 지시자에 도달할 수 있다. 이것은 신경망 모델을 업데이트하는 효율을 향상시키고, 목표 신경망 모 델은 가능한 한 빨리 획득된다. 제2 양태를 참조하면, 제2 양태의 일부 구현들에서, 신경망 모델의 관련 파라미터는 전처리 방식을 추가로 포함 한다. 예측 라벨은 훈련 데이터를 전처리 방식으로 전처리하고 전처리된 훈련 데이터를 처리를 위해 신경망 모 델에 입력함으로써 획득된다. 제2 양태를 참조하면, 제2 양태의 일부 구현들에서, 신경망 모델의 관련 파라미터는 신경망 모델의 압축 방식을 추가로 포함한다. 예측 라벨은 신경망 모델을 신경망 모델의 압축 방식으로 처리하고 훈련 데이터를 처리된 신 경망 모델에 입력함으로써 획득된다. 제2 양태를 참조하면, 제2 양태의 일부 구현들에서, 신경망 모델의 관련 파라미터와 신경망 모델의 구조 중 적 어도 2개를 업데이트하는 단계는: 신경망 모델의 관련 파라미터와 신경망 모델의 구조 중 적어도 2개의 각각의 항목에 대응하는 제1 정보에 기초하여, 각각의 항목에 대응하는 복수의 후보 옵션들의 확률 분포를 결정하는 단 계 - 각각의 항목에 대응하는 제1 정보는 평가 결과를 포함함 - ; 및 각각의 항목에 대응하는 복수의 후보 옵션 들의 확률 분포에 기초하여 각각의 항목에 대응하는 복수의 후보 옵션들 내의 하나의 후보 옵션을 각각의 항목 의 업데이트된 옵션으로서 결정하는 단계를 포함한다. 제2 양태를 참조하면, 제2 양태의 일부 구현들에서, 각각의 항목에 대응하는 제1 정보는 신경망 모델의 관련 파 라미터와 신경망 모델의 구조 중 적어도 2개에서의 다른 항목의 관련 정보를 추가로 포함한다. 다른 항목의 관 련 정보는 다른 항목 및/또는 다른 항목에 대응하는 복수의 후보 옵션들의 확률 분포를 포함한다. 제2 양태를 참조하면, 제2 양태의 일부 구현들에서, 각각의 항목에 대응하는 제1 정보는 각각의 항목의 이력 관 련 정보를 추가로 포함한다. 각각의 항목의 이력 관련 정보는 이전 업데이트에서의 각각의 항목의 업데이트된 옵션 및/또는 이전 업데이트에서의 각각의 항목에 대응하는 복수의 후보 옵션들의 확률 분포를 포함한다. 제2 양태를 참조하면, 제2 양태의 일부 구현들에서, 각각의 항목에 대응하는 제1 정보는 훈련 자원 상태 정보를 추가로 포함한다. 훈련 자원 상태 정보는 훈련 머신들의 수량을 포함한다. 제2 양태를 참조하면, 제2 양태의 일부 구현들에서, 신경망 모델의 하이퍼-파라미터는 신경망 모델의 훈련 프로 세스에서 변경되지 않은 채로 유지되는 파라미터를 포함한다. 제2 양태를 참조하면, 제2 양태의 일부 구현들에서, 신경망 모델의 하이퍼-파라미터는 다음 중 하나 이상을 포 함한다: 신경망 모델의 학습률, 신경망 모델의 가중치 감쇠 계수, 신경망 모델의 라벨 평활 계수, 또는 신경망 모델의 드롭아웃 파라미터. 제3 양태에 따르면, 신경망 모델 업데이트 장치가 제공된다. 장치는 제1 양태 및 제1 양태의 구현들 중 어느 하나에서의 방법을 수행하도록 구성되는 모듈 또는 유닛을 포함한다. 제4 양태에 따르면, 이미지 처리 장치가 제공된다. 장치는 제2 양태 및 제2 양태의 구현들 중 어느 하나에서의 방법을 수행하도록 구성되는 모듈 또는 유닛을 포함한다. 제1 양태에서의 대응하는 내용에 대한 확장들, 그에 대한 제한들, 그에 대한 해석들, 및 그의 설명이 또한 제2 양태, 제3 양태, 및 제4 양태에서의 동일한 내용에 적용가능하다는 것을 이해해야 한다. 제5 양태에 따르면, 신경망 모델 업데이트 장치가 제공된다. 장치는: 프로그램을 저장하도록 구성되는 메모리; 및 메모리에 저장된 프로그램을 실행하도록 구성되는 프로세서를 포함한다. 메모리에 저장된 프로그램이 실행 될 때, 프로세서는 제1 양태 및 제1 양태의 구현들 중 어느 하나에서의 방법을 수행하도록 구성된다. 제5 양태에서의 프로세서는 중앙 처리 유닛(central processing unit, CPU)일 수 있거나, CPU와 신경망 연산 프로세서의 조합일 수 있다. 본 명세서에서의 신경망 연산 프로세서는 그래픽 처리 유닛(graphics processing unit, GPU), 신경망 처리 유닛(neural-network processing unit, NPU), 텐서 처리 유닛(tensor processing unit, TPU) 등을 포함할 수 있다. TPU는 머신 학습을 위해 구글(Google)에 의해 맞춤화된 인공 지능 가속기-특 정 집적 회로이다. 제6 양태에 따르면, 이미지 처리 장치가 제공된다. 장치는: 프로그램을 저장하도록 구성되는 메모리; 및 메모 리에 저장된 프로그램을 실행하도록 구성되는 프로세서를 포함한다. 메모리에 저장된 프로그램이 실행될 때, 프로세서는 제2 양태 및 제2 양태의 구현들 중 어느 하나에서의 방법을 수행하도록 구성된다. 제6 양태에서의 프로세서는 중앙 처리 유닛일 수 있거나, CPU와 신경망 연산 프로세서의 조합일 수 있다. 본 명세서에서의 신경망 연산 프로세서는 그래픽 처리 유닛, 신경망 처리 유닛, 텐서 처리 유닛 등을 포함할 수 있 다. TPU는 머신 학습을 위해 구글에 의해 맞춤화된 인공 지능 가속기-특정 집적 회로이다. 제7 양태에 따르면, 컴퓨터 판독가능 매체가 제공된다. 컴퓨터 판독가능 매체는 디바이스에 의해 실행될 프로 그램 코드를 저장하고, 프로그램 코드는 제1 양태 또는 제2 양태의 구현들 중 어느 하나에서의 방법을 수행하기 위해 사용된다. 제8 양태에 따르면, 명령어들을 포함하는 컴퓨터 프로그램 제품이 제공된다. 컴퓨터 프로그램 제품이 컴퓨터 상에서 실행될 때, 컴퓨터는 제1 양태 또는 제2 양태의 구현들 중 어느 하나에서의 방법을 수행할 수 있게 된다. 제9 양태에 따르면, 칩이 제공된다. 칩은 프로세서 및 데이터 인터페이스를 포함한다. 프로세서는 데이터 인 터페이스를 통해 메모리에 저장된 명령어들을 판독함으로써 제1 양태 또는 제2 양태의 구현들 중 어느 하나에서 의 방법을 수행한다. 선택적으로, 구현에서, 칩은 메모리를 추가로 포함할 수 있고, 메모리는 명령어들을 저장한다. 프로세서는 메 모리에 저장된 명령어들을 실행하도록 구성되고, 명령어들이 실행될 때, 프로세서는 제1 양태 또는 제2 양태의 구현들 중 어느 하나에서의 방법을 수행하도록 구성된다. 전술한 칩은 구체적으로 필드 프로그램가능 게이트 어레이(field-programmable gate array, FPGA) 또는 주문형 집적 회로(application-specific integrated circuit, ASIC)일 수 있다."}
{"patent_id": "10-2022-7023190", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하에서는 본 출원의 기술적 해결책들을 첨부 도면들을 참조하여 설명한다. 도 1은 인공 지능 메인 프레임워크의 개략도이다. 메인 프레임워크는 인공 지능 시스템의 전체 작업 절차를 설 명하고, 일반적인 인공 지능 분야의 요건에 적용가능하다. 다음은 \"지능형 정보 체인\"(수평축) 및 \"정보 기술(information technology, IT) 가치 체인\"(수직축)의 두 가 지 차원에서 전술한 인공 지능 메인 프레임워크를 상세히 설명한다. \"지능형 정보 체인\"은 데이터를 획득하는 것으로부터 데이터를 처리하는 것까지의 일련의 프로세스들을 반영한 다. 예를 들어, 프로세스는 지능형 정보 인지, 지능형 정보 표현 및 형성, 지능형 추론, 지능형 의사 결정, 및 지능형 실행 및 출력의 일반적인 프로세스일 수 있다. 이 프로세스에서, 데이터는 \"데이터-정보-지식-지혜 (data-information-knowledge-wisdom)\"의 응축 프로세스(condensation process)를 거친다. \"IT 가치 체인\"은 인간 지능의 기본 인프라스트럭처 및 정보(기술 제공 및 처리 구현)로부터 시스템의 산업 생 태학적 프로세스에 이르기까지 인공 지능이 정보 기술 산업에 가져오는 가치를 반영한다. 인프라스트럭처 인프라스트럭처는 인공 지능 시스템에 대한 계산 능력 지원을 제공하고, 외부 세계와 통신하고, 기본 플랫폼을 사용하여 지원을 구현한다. 인프라스트럭처는 센서를 사용함으로써 외부와 통신할 수 있고, 인프라스트럭처의 계산 능력은 지능형 칩에 의 해 제공될 수 있다. 본 명세서에서의 지능형 칩은 중앙 처리 유닛(central processing unit, CPU), 신경망 처리 유닛(neural- network processing unit, NPU), 그래픽 처리 유닛(graphics processing unit, GPU), 주문형 집적 회로 (application specific integrated circuit, ASIC), 또는 필드 프로그램가능 게이트 어레이(field programmable gate array, FPGA)와 같은 하드웨어 가속 칩일 수 있다. 인프라스트럭처의 기본 플랫폼은, 클라우드 스토리지 및 컴퓨팅, 상호연결 네트워크 등을 포함한, 보장 및 지원 을 위한, 분산 컴퓨팅 프레임워크 및 네트워크와 같은 관련 플랫폼들을 포함할 수 있다. 예를 들어, 인프라스트럭처는 센서를 사용함으로써 외부와 통신하여 데이터를 획득할 수 있다. 그 후, 데이터 는 컴퓨팅을 위해, 기본 플랫폼에 의해 제공되는 분산 컴퓨팅 시스템 내의 지능형 칩에 제공된다. 데이터 인프라스트럭처의 상위 계층으로부터의 데이터는 인공 지능 분야의 데이터 소스를 나타낸다. 데이터는 그래프, 이미지, 음성, 및 텍스트에 관련되고, 또한 종래의 디바이스의 사물 인터넷 데이터에 관련되고, 기존의 시스템 의 서비스 데이터 및 힘, 변위, 액체 레벨, 온도, 및 습도와 같은 감지 데이터를 포함한다. 데이터 처리 전술한 데이터 처리는 일반적으로 데이터 훈련, 머신 학습, 심층 학습, 검색, 추론, 또는 의사 결정과 같은 처 리 방식을 포함한다.머신 학습 및 심층 학습에서, 데이터의 지능형 정보는 기호화 및 형식화된 방식으로 모델링, 추출, 전처리, 훈 련 등이 될 수 있다. 추론은 컴퓨터들 또는 지능형 시스템들에서 지능형 인간 추론 방법들을 시뮬레이션하고, 추론 제어 정책에 기초 하여, 형식화된 정보를 사용해서 머신 사고(machine thinking)를 수행하고 문제들을 해결하는 프로세스이며, 전 형적인 기능들은 검색 및 매칭이다. 의사 결정은 지능형 정보 추론 후에 결정하는 프로세스이며, 일반적으로 분류, 순위, 및 예측과 같은 기능들을 제공한다. 일반적인 능력 위에서 언급한 데이터 처리가 데이터에 대해 수행된 후에, 데이터 처리 결과에 기초하여 일부 일반적인 능력들, 예를 들어, 번역, 텍스트 분석, 컴퓨터 비전 처리, 음성 인식, 및 이미지 인식과 같은 알고리즘 또는 일반적인 시스템이 추가로 형성될 수 있다. 스마트 제품 및 산업 응용 스마트 제품들 및 산업 응용들은 다양한 분야들에서의 인공 지능 시스템의 제품들 및 응용들이고, 인공 지능의 전체 솔루션의 패키지이다. 지능형 정보에 대한 의사 결정이 생성되고 응용이 구현된다. 응용 분야들은 주로 스마트 제조, 스마트 운송, 스마트 홈, 스마트 건강 관리, 스마트 보안, 자율 주행, 안전 도시, 지능형 단말 등 을 포함한다. 본 출원의 실시예들은 인공 지능의 많은 분야들, 예를 들어, 스마트 제조, 스마트 운송, 스마트 홈, 스마트 건 강 관리, 스마트 보안 보호, 자율 주행, 및 안전 도시와 같은 분야들에 적용될 수 있다. 구체적으로, 본 출원의 실시예들은 (심층) 신경망이 사용될 필요가 있는 분야들, 예를 들어, 자율 주행, 이미지 분류, 이미지 검색, 이미지 시맨틱 세그먼트화, 이미지 품질 향상, 이미지 초해상도 처리, 및 자연어 처리에 적 용될 수 있다. 다음은 3가지 응용 시나리오: 앨범 이미지 분류, 안전 도시, 및 자동 머신 학습(auto machine learning, AutoML) 클라우드 서비스를 간단히 설명한다. 앨범 이미지 분류: 사용자가 많은 양의 이미지들을 단말 디바이스(예를 들어, 모바일폰) 또는 클라우드 디스크에 저장할 때, 앨범 내의 이미지들의 인식은 사용자 또는 시스템이 앨범에 대한 분류 관리를 수행하는 것을 도울 수 있다. 이것은 사용자 경험을 향상시킨다. 본 출원의 실시예들에서의 신경망 모델 업데이트 방법에 따르면, 앨범 분류에 적용가능한 신경망이 획득되거나 최적화될 수 있다. 그 후, 신경망은 이미지들을 분류하여, 상이한 클래스들의 이미지들을 라벨링할 수 있다. 이것은 사용자에 의한 보기 및 찾기를 용이하게 한다. 게다가, 이미지들의 분류 라벨들은 또한 분류 관리를 수 행하기 위해 앨범 관리 시스템에 제공될 수 있다. 이것은 사용자의 관리 시간을 절약하고, 앨범 관리 효율을 개선하고, 사용자 경험을 개선한다. 안전 도시 시나리오에서의 속성 인식: 안전 도시 시나리오에서, 복수의 타입들의 속성 인식, 예를 들어, 보행자 속성 인식 및 탑승 속성 인식이 수행 될 필요가 있다. 심층 신경망은 심층 신경망의 강력한 능력을 사용함으로써 복수의 타입들의 속성 인식에서 중 요한 역할을 한다. 본 출원의 실시예들에서의 신경망 모델 업데이트 방법에 따르면, 안전 도시 시나리오에서의 속성 인식에 적용가능한 신경망이 획득되거나 최적화될 수 있다. 그 후, 입력 도로 이미지가 신경망을 사용하 여 처리되어, 도로 이미지 내의 상이한 속성 정보를 인식할 수 있다. 자동 머신 학습 클라우드 서비스: 자동 머신 학습 클라우드 서비스 플랫폼 상에서, 사용자는 사용자의 요건 및 태스크에 기초하여 신경망 모델을 맞춤화하고/하거나 신경망 모델의 관련 파라미터를 획득할 수 있다. 본 출원의 실시예들에서 제공되는 신경망 모델 업데이트 방법에 따르면, 신경망 모델 및/또는 신경망 모델의 관련 파라미터는 사용자의 요건에 기초하여 획득될 수 있다. 이것은 클라우드 서비스 플랫폼의 성능을 향상시킨다.본 출원의 실시예들은 신경망의 대규모 응용들과 관련되기 때문에, 이해의 용이함을 위해, 이하에서는 본 출원 의 실시예들에서 사용될 수 있는 신경망과 관련된 용어들 및 개념들을 설명한다. 신경망 신경망은 뉴런을 포함할 수 있다. 뉴런은 xs와 1의 절편을 입력으로 사용하는 연산 단위일 수 있다. 연산 단 위의 출력은 다음과 같을 수 있다:"}
{"patent_id": "10-2022-7023190", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "여기서, s = 1, 2, ..., n이고, n은 1보다 큰 자연수이고, Ws는 xs의 가중치이고, b는 뉴런의 바이어스이다. f 는 뉴런의 활성화 함수(activation functions)이고, 뉴런 내의 입력 신호를 출력 신호로 변환하기 위해, 비선형 특성을 신경망에 도입하는 데 사용된다. 활성화 함수의 출력 신호는 다음 컨볼루션 계층에 대한 입력으로서 사 용될 수 있고, 활성화 함수는 시그모이드 함수일 수 있다. 신경망은 복수의 단일 뉴런들을 함께 연결함으로써 구성된 네트워크이다. 구체적으로, 뉴런의 출력은 다른 뉴런에 대한 입력일 수 있다. 각각의 뉴런의 입력은 이전 계층의 로컬 수용 필드(local receptive field)에 연결되어 로컬 수용 필드의 특징을 추출할 수 있다. 로 컬 수용 필드는 여러 뉴런들을 포함하는 영역일 수 있다. 심층 신경망 심층 신경망(deep neural network, DNN)은 또한 다층 신경망으로 지칭되며, 복수의 은닉 계층들을 갖는 신경망 으로 이해될 수 있다. DNN은 상이한 계층들의 위치들에 기초하여 분할된다. DNN 내부의 신경망들은 3가지 타 입: 입력 계층, 은닉 계층, 및 출력 계층으로 분류될 수 있다. 일반적으로, 제1 계층은 입력 계층이고, 마지막 계층은 출력 계층이며, 중간 계층은 은닉 계층이다. 계층들은 완전히 연결된다(fully connected). 구체적으로, i번째 계층 내의 임의의 뉴런은 (i+1)번째 계층 내의 임의의 뉴런에 반드시 연결된다. DNN은 복잡한 것으로 보이지만, 각각의 계층에서의 연산은 실제로 복잡하지 않고 일반적으로 다음의 선형 관계 식에 의해 표현된다: . 여기서, 는 입력 벡터이고, 는 출력 벡터이고, 는 오프셋 벡터이고, 는 가중치 행렬(계수라고도 지칭됨)이고, 는 활성화 함수이다. 각각의 계층에서, 출력 벡 터 는 입력 벡터 에 대해 간단한 연산을 수행함으로써 획득된다. 대량의 DNN 계층들이 존재하기 때문에, 또한 대량의 계수들 및 오프셋 벡터들 이 존재한다. 이러한 파라미터들은 DNN에서 다음과 같이 정의된 다: 계수 가 예로서 사용된다. 3-층 DNN에서, 제2 계층에서의 제4 뉴런으로부터 제3 계층에서의 제2 뉴런까 지의 선형 계수가 로서 정의된다고 가정된다. 위첨자 3은 계수 가 위치하는 계층의 번호를 나타내고, 아래첨자는 출력을 위한 제3 계층의 인덱스 2 및 입력을 위한 제2 계층의 인덱스 4에 대응한다. 결론적으로, (L-1)번째 계층에서의 k번째 뉴런으로부터 L번째 계층에서의 j번째 뉴런까지의 계수는 로서 정 의된다. 입력 계층은 파라미터 를 갖지 않는다는 점에 유의해야 한다. 심층 신경망에서, 더 많은 은닉 계층들은 네 트워크가 실세계에서 복잡한 경우를 더 잘 설명할 수 있게 한다. 이론적으로, 더 많은 파라미터들을 갖는 모델 은 더 높은 복잡성 및 더 큰 \"용량\"을 갖는다. 이는 모델이 더 복잡한 학습 태스크를 완료할 수 있다는 것을 나타낸다. 심층 신경망의 훈련은 가중치 행렬을 학습하는 프로세스이고, 훈련의 최종 목적은 훈련된 심층 신경 망의 모든 계층들의 가중치 행렬(다수의 계층들의 벡터들 에 의해 형성된 가중치 행렬)을 획득하는 것이다. 컨볼루션 신경망 컨볼루션 신경망(convolutional neuron network, CNN)은 컨볼루션 구조를 갖는 심층 신경망이다. 컨볼루션 신 경망은 컨볼루션 계층 및 서브샘플링 계층을 포함하는 특징 추출기를 포함한다. 특징 추출기는 필터로서 간주 될 수 있다. 컨볼루션 계층은 컨볼루션 신경망에 있고 입력 신호에 대해 컨볼루션 처리를 수행하는 뉴런 계층이다. 컨볼루션 신경망의 컨볼루션 계층에서, 하나의 뉴런은 이웃 계층에서 뉴런들의 일부에만 연결될 수 있다. 컨볼루션 계층은 일반적으로 여러 특징 평면들을 포함하고, 각각의 특징 평면은 직사각형으로 배열된 일 부 뉴런들을 포함할 수 있다. 동일한 특징 평면의 뉴런들은 가중치를 공유하고, 본 명세서에서 공유된 가중치 는 컨볼루션 커널이다. 가중치를 공유하는 것은 이미지 정보를 추출하는 방식이 위치와 무관하다는 것으로서 이해될 수 있다. 컨볼루션 커널은 랜덤 크기의 행렬의 형태로 초기화될 수 있다. 컨볼루션 신경망의 훈련 프 로세스에서, 학습을 통해 컨볼루션 커널에 대해 적절한 가중치가 획득될 수 있다. 또한, 가중치를 공유하는 것 은, 컨볼루션 신경망의 계층들 사이의 연결들이 감소되고, 오버피팅의 위험이 감소되기 때문에 유리하다. 순환 신경망(recurrent neural networks, RNN)은 시퀀스 데이터를 처리한다. 종래의 신경망 모델에서는, 입력 계층으로부터 은닉 계층으로 그리고 이어서 출력 계층으로, 계층들이 완전히 연결되지만, 각각의 계층에서 의 노드들은 연결되지 않는다. 이러한 공통 신경망은 많은 문제들을 해결하지만, 여전히 많은 다른 문제들을 해결할 수 없다. 예를 들어, 문장 내의 다음 단어를 예측하기 위해서는, 문장 내의 인접한 단어들이 독립적이 지 않기 때문에, 일반적으로 이전 단어가 사용될 필요가 있다. RNN이 순환 신경망이라고 지칭되는 이유는 시퀀 스의 현재 출력이 이전 출력과 관련되기 때문이다. 구체적인 표현 형태는 네트워크가 이전 정보를 기억하고 이 전 정보를 현재 출력의 계산에 적용하는 것이다. 구체적으로, 은닉 계층에서의 노드들은 더 이상 연결되지 않 지만, 연결되어 있으며, 은닉 계층에 대한 입력은 입력 계층의 출력 및 또한 이전 순간에서의 은닉 계층의 출력 을 포함한다. 이론적으로, RNN은 임의의 길이의 시퀀스 데이터를 처리할 수 있다. RNN의 훈련은 종래의 CNN 또는 DNN의 훈련과 동일하다. 컨볼루션 신경망이 있을 때 순환 신경망이 요구되는 이유는 간단하다. 컨볼루션 신경망에서, 요소들은 서로 독 립적이고, 입력과 출력은 또한 고양이와 개와 같이 독립적이라는 전제가 있다. 그러나, 많은 요소들이 실세계 에서 상호연결된다. 예를 들어, 주식은 시간 경과에 따라 변한다. 다른 예로서, 어떤 사람이 나는 여행을 좋 아하고, 가장 좋아하는 장소가 Yunnan이고, 기회가 있다면 나는 미래에 거기에 갈 것이라고 말한다. 여기에 채 워질 빈칸이 있다면, 사람들은 \"Yunnan\"이 채워져야 한다는 것을 알아야 한다. 이것은 사람들이 컨텍스트로부 터 추론을 행할 수 있기 때문인데, 어떻게 머신이 이것을 할 수 있을까? RNN이 등장한다. RNN은 머신이 인간처 럼 기억하는 능력을 가질 수 있도록 설계된다. 따라서, RNN의 출력은 현재 입력 정보 및 이력 메모리 정보에 의존한다. 손실 함수 심층 신경망을 훈련하는 프로세스에서, 심층 신경망의 출력이 실제로 예측될 필요가 있는 값에 최대한 근접할 것으로 예상되기 때문에, 네트워크의 현재 예측 값과 실제 예상 목표 값이 비교될 수 있고, 그 후 신경망의 각 각의 계층의 가중치 벡터가 현재 예측 값과 목표 값 사이의 차이에 기초하여 업데이트된다(물론, 일반적으로 첫 번째 업데이트 전에 초기화 프로세스가 존재하고, 구체적으로, 파라미터들은 심층 신경망의 모든 계층들에 대해 미리 구성된다). 예를 들어, 네트워크의 예측 값이 큰 경우, 심층 신경망이 실제 예상 목표 값 또는 실제 예상 목표 값에 더 근접하는 값을 예측할 수 있을 때까지, 예측 값을 감소시키기 위해 가중치 벡터가 조정되고, 조정 이 계속 수행된다. 따라서, \"예측 값과 목표 값 사이의 차이를 비교를 통해 획득하는 방법\"은 미리 정의될 필 요가 있다. 이는 손실 함수(loss function) 또는 목적 함수(objective function)이다. 손실 함수와 목적 함 수는 예측 값과 목표 값 사이의 차이를 측정하는 중요한 방정식들이다. 손실 함수가 예로서 사용된다. 손실 함수의 더 높은 출력 값(loss)은 더 큰 차이를 지시한다. 따라서, 심층 신경망의 훈련은 loss를 가능한 한 많 이 감소시키는 프로세스가 된다. 역방향 전파 알고리즘 훈련 프로세스에서, 신경망은 에러 역방향 전파(back propagation, BP) 알고리즘을 사용함으로써 신경망 모델의 파라미터의 값을 정정할 수 있어, 신경망 모델의 재구성 에러 손실이 점점 더 작아지게 된다. 구체적으로, 입 력 신호는 에러 손실이 출력에서 생성될 때까지 순방향 전송되고, 신경망 모델의 파라미터는 에러 손실에 관한 정보의 역방향 전파를 통해 업데이트되어, 에러 손실을 수렴시킨다. 역방향 전파 알고리즘은 주로 에러 손실에 의존하는 역방향 전파 모션이고, 최적의 신경망 모델의 파라미터, 예를 들어, 가중치 행렬을 획득하기 위해 사 용된다. 도 2는 본 출원의 실시예에 따른 시스템 아키텍처를 도시한다. 도 2에서, 데이터 수집 디바이스는 훈련 데이터를 수집하도록 구성된다. 본 출원의 실시예들에서의 이미지 처리 방법의 경우, 훈련 데이터는 훈련 이미지 및 훈련 이미지에 대응하는 분류 결과를 포함할 수 있다. 훈련 이미지에 대응하는 결과는 수동 사전-라 벨링(manual pre-labeling)의 결과일 수 있다.훈련 데이터를 수집한 후, 데이터 수집 디바이스는 데이터베이스에 훈련 데이터를 저장한다. 훈련 디바이스는 데이터베이스에 유지된 훈련 데이터에 기초하여 훈련을 통해 목표 모델/규칙을 획득 한다. 다음은 훈련 데이터에 기초하여 훈련 디바이스에 의해 획득된 목표 모델/규칙을 설명한다. 훈련 디 바이스는 입력된 원시 이미지를 처리하고, 훈련 디바이스에 의해 출력된 이미지와 원시 이미지 사이 의 차이가 특정 임계값보다 작을 때까지 출력 이미지를 원시 이미지와 비교한다. 이러한 방식으로, 목표 모델/ 규칙의 훈련이 완료된다. 목표 모델/규칙은 본 출원의 실시예들에서의 이미지 처리 방법을 구현하기 위해 사용될 수 있다. 본 출원 의 이 실시예에서의 목표 모델/규칙은 구체적으로 신경망일 수 있다. 실제 응용들 동안, 데이터베이스 에 유지된 훈련 데이터는 모두 데이터 수집 디바이스에 의해 수집되지 않을 수 있거나, 또는 다른 디 바이스로부터 수신 및 획득될 수 있다는 점에 유의해야 한다. 훈련 디바이스는 데이터베이스에 유지 된 훈련 데이터에 기초하여 완전히 목표 모델/규칙을 반드시 훈련시킬 필요는 없을 수 있거나, 또는 모델 훈련을 수행하기 위해 클라우드 또는 다른 장소로부터 훈련 데이터를 획득할 수 있다는 점에 더 유의해야 한다. 전술한 설명은 본 출원의 실시예들에 대한 제한으로서 해석되어서는 안 된다. 훈련 디바이스에 의한 훈련을 통해 획득된 목표 모델/규칙은 상이한 시스템들 또는 디바이스들, 예를 들어, 도 2에 도시된 실행 디바이스에 적용될 수 있다. 실행 디바이스는 단말, 예를 들어, 이동 전 화 단말, 태블릿, 랩톱 컴퓨터, 증강 현실(augmented reality, AR) AR/가상 현실(virtual reality, VR) 단말, 또는 차량 탑재 단말일 수 있거나, 서버, 클라우드 등일 수 있다. 도 2에서, 실행 디바이스에는 외부 디 바이스와 데이터를 교환하도록 구성되는 입력/출력(input/output, I/O) 인터페이스가 제공된다. 사용자는 클라이언트 디바이스를 사용하여 I/O 인터페이스에 데이터를 입력할 수 있다. 본 출원의 이 실시예 에서의 입력 데이터는 클라이언트 디바이스에 의해 입력된 처리될 이미지를 포함할 수 있다. 전처리 모듈과 전처리 모듈은 I/O 인터페이스에 의해 수신된 입력 데이터(예를 들어, 처리될 이 미지)에 기초하여 전처리를 수행하도록 구성된다. 본 출원의 이 실시예에서, 전처리 모듈과 전처리 모듈 은 존재하지 않을 수 있다(또는 전처리 모듈과 전처리 모듈 중 하나만이 존재한다). 컴퓨팅 모 듈은 입력 데이터를 처리하도록 직접 구성된다. 실행 디바이스가 입력 데이터를 전처리하거나 실행 디바이스의 계산 모듈이 계산을 수행하는 관 련 프로세스에서, 실행 디바이스는 대응하는 처리를 위해 데이터 저장 시스템 내의 데이터, 코드 등 을 호출할 수 있고, 또한 대응하는 처리를 통해 획득된 데이터, 명령어들 등을 데이터 저장 시스템에 저장 할 수 있다. 마지막으로, I/O 인터페이스는 이미지의 전술한 획득된 분류 결과와 같은 처리 결과를 클라이언트 디바이 스에 반환하여, 처리 결과를 사용자에게 제공한다. 훈련 디바이스는 상이한 훈련 데이터에 기초하여 상이한 목표들 또는 상이한 태스크들에 대한 대응하는 목 표 모델들/규칙들을 생성할 수 있다는 점에 유의해야 한다. 대응하는 목표 모델들/규칙들은 전술한 목표들을 구현하거나 전술한 태스크들을 완료하기 위해 사용되어, 사용자에게 원하는 결과를 제공할 수 있다. 도 2에 도시된 경우에, 사용자는 입력 데이터를 수동으로 제공할 수 있고, 수동 제공(manual giving)은 I/O 인 터페이스에 의해 제공되는 인터페이스에서 수행될 수 있다. 다른 경우에, 클라이언트 디바이스는 입 력 데이터를 I/O 인터페이스에 자동으로 전송할 수 있다. 클라이언트 디바이스가 입력 데이터를 자 동으로 전송하기 위해 사용자로부터 인가를 획득할 필요가 있는 경우, 사용자는 클라이언트 디바이스에서 대응하는 허가를 설정할 수 있다. 사용자는, 클라이언트 디바이스에서, 실행 디바이스에 의해 출력 된 결과를 볼 수 있다. 구체적으로, 결과는 디스플레이, 사운드, 액션 등의 형태로 제시될 수 있다. 클라이언 트 디바이스는 또한, I/O 인터페이스에 입력되는 입력 데이터 및 도면에 도시된 I/O 인터페이스(11 2)로부터 출력되는 출력 결과를 새로운 샘플 데이터로서 수집하고, 새로운 샘플 데이터를 데이터베이스에 저장하기 위한 데이터 수집기로서 역할을 할 수 있다. 물론, 클라이언트 디바이스는 대안적으로 수집을 수행하지 않을 수 있다. 대신에, I/O 인터페이스는, 도면에서 I/O 인터페이스에 입력되는 입력 데이 터 및 I/O 인터페이스로부터 출력되는 출력 결과를 새로운 샘플 데이터로서 데이터베이스에 직접 저 장한다. 도 2는 본 출원의 실시예에 따른 시스템 아키텍처의 개략도일 뿐이라는 점에 유의해야 한다. 도면에 도시된 디 바이스들, 컴포넌트들, 모듈들 등 사이의 위치 관계는 어떠한 제한도 구성하지 않는다. 예를 들어, 도 2에서, 데이터 저장 시스템은 실행 디바이스에 대한 외부 스토리지이지만, 다른 경우에, 데이터 저장 시스템 은 대안적으로 실행 디바이스에 배치될 수 있다. 도 2에 도시된 바와 같이, 목표 모델/규칙은 훈련 디바이스에 의한 훈련을 통해 획득된다. 본 출원 의 이 실시예에서, 목표 모델/규칙은 본 출원에서의 신경망일 수 있다. 구체적으로, 본 출원의 이 실시예 에서 구성된 신경망은 CNN, 심층 컨볼루션 신경망(deep convolutional neural networks, DCNN), 순환 신경망 (recurrent neural network, RNN) 등일 수 있다. CNN은 매우 일반적인 신경망이기 때문에, CNN의 구조는 도 3을 참조하여 아래에 상세히 설명된다. 기본 개념들 의 전술한 설명에서 설명된 바와 같이, 컨볼루션 신경망은 컨볼루션 구조를 갖는 심층 신경망이고, 심층 학습 (deep learning) 아키텍처이다. 심층 학습 아키텍처는 신경망 모델 업데이트 알고리즘을 사용함으로써 상이한 추상화 레벨들에서 다중-레벨 학습을 수행하는 것이다. 심층 학습 아키텍처로서, CNN은 피드-포워드(feed- forward) 인공 신경망이다. 피드-포워드 인공 신경망 내의 각각의 뉴런은 피드-포워드 인공 신경망에 입력된 이미지에 응답할 수 있다. 본 출원의 실시예들에서 이미지 처리 방법에서 구체적으로 사용되는 신경망의 구조가 도 3에 도시될 수 있다. 도 3에서, 컨볼루션 신경망(CNN)은 입력 계층, 컨볼루션 계층/풀링 계층(풀링 계층은 선택적 임), 및 신경망 계층을 포함할 수 있다. 입력 계층은 처리될 이미지를 획득하고, 획득된 처리될 이 미지를 처리를 위해 컨볼루션 계층/풀링 계층 및 후속 신경망 계층에 전송하여, 이미지의 처리 결과 를 획득할 수 있다. 다음은 도 3의 CNN에서의 계층의 아키텍처를 상세히 설명한다. 컨볼루션 계층/풀링 계층: 컨볼루션 계층: 도 3에 도시된 바와 같이, 컨볼루션 계층/풀링 계층은, 예를 들어, 계층들(221 내지 226)을 포함할 수 있 다. 예를 들어, 일 구현에서, 계층은 컨볼루션 계층이고, 계층은 풀링 계층이고, 계층은 컨볼 루션 계층이고, 계층은 풀링 계층이고, 계층은 컨볼루션 계층이고, 계층은 풀링 계층이다. 다 른 구현에서, 계층들(221 및 222)은 컨볼루션 계층들이고, 계층은 풀링 계층이고, 계층들(224 및 225)은 컨볼루션 계층들이고, 계층은 풀링 계층이다. 구체적으로, 컨볼루션 계층의 출력은 후속 풀링 계층에 대 한 입력으로서 사용되거나, 또는 다른 컨볼루션 계층에 대한 입력으로서 사용되어, 컨볼루션 연산을 계속 수행 할 수 있다. 다음은 컨볼루션 계층의 내부 작동 원리를 설명하기 위해 컨볼루션 계층을 예로서 사용한다. 컨볼루션 계층은 복수의 컨볼루션 연산자를 포함할 수 있다. 컨볼루션 연산자는 또한 커널이라고도 지칭 된다. 이미지 처리에서, 컨볼루션 연산자는 입력 이미지 행렬로부터 특정 정보를 추출하는 필터로서 기능한다. 컨볼루션 연산자는 본질적으로 가중치 행렬일 수 있고, 가중치 행렬은 일반적으로 미리 정의된다. 이미지에 대 해 컨볼루션 연산을 수행하는 프로세스에서, 가중치 행렬은 일반적으로 입력 이미지 상에서 수평 방향으로 1 픽 셀(또는 스트라이드(stride)의 값에 따라 2 픽셀)의 입도 레벨로 픽셀들을 처리하여, 이미지로부터 특정 특징을 추출한다. 가중치 행렬의 크기는 이미지의 크기와 관련되어야 한다. 가중치 행렬의 깊이 차원(depth dimension)은 입력 이미지의 깊이 차원과 동일하다는 점에 유의해야 한다. 컨볼루션 연산 동안, 가중치 행렬은 입력 이미지의 전체 깊이까지 확장된다. 따라서, 단일 깊이 차원의 컨볼루션 출력은 단일 가중치 행렬과의 컨 볼루션을 통해 생성된다. 그러나, 대부분의 경우에, 단일 가중치 행렬이 사용되지 않지만, 동일한 크기(행들 x 열들)를 갖는 복수의 가중치 행렬, 즉, 복수의 동일-타입 행렬이 적용된다. 가중치 행렬들의 출력들은 컨볼루 션 이미지의 깊이 차원을 형성하도록 중첩된다. 본 명세서에서 차원은 전술한 \"복수\"에 기초하여 결정되는 것으로서 이해될 수 있다. 이미지로부터 상이한 특징들을 추출하기 위해 상이한 가중치 행렬들이 사용될 수 있다. 예를 들어, 하나의 가중치 행렬은 이미지의 에지 정보를 추출하기 위해 사용되고, 다른 가중치 행렬은 이미지의 특정 컬러를 추출하기 위해 사용되고, 추가의 가중치 행렬은 이미지에서 불필요한 잡음을 블러링하기 위해 사용된다. 복수의 가중치 행렬은 동일한 크기(행들 x 열들)를 갖고, 동일한 크기를 갖는 복수의 가중치 행렬로부터 추출된 컨볼루션 특징 맵들은 동일한 크기를 갖는다. 그 다음, 동일한 크기를 갖는 복수의 추출된 컨볼루션 특징 맵이 조합되어 컨볼루션 연산의 출력을 형성한다. 이들 가중치 행렬에서의 가중치 값들은 실제 응용들 동안 많은 훈련을 통해 획득될 필요가 있다. 훈련을 통해 획득된 가중치 값들을 사용하여 형성된 각각의 가중치 행렬은 입력 이미지로부터 정보를 추출하는데 사용될 수있어, 컨볼루션 신경망이 정확한 예측을 수행할 수 있게 할 수 있다. 컨볼루션 신경망이 복수의 컨볼루션 계층을 가질 때, 컨볼루션 계층(예를 들어, 계층)은 보통 더 일 반적인 특징들을 추출한다. 일반적인 특징들은 저레벨 특징들이라고도 지칭될 수 있다. 컨볼루션 신경망(20 0)의 깊이가 증가함에 따라, 더 깊은 컨볼루션 계층(예를 들어, 계층)은 고레벨 시맨틱 특징들과 같은 더 복잡한 특징들을 추출한다. 더 고레벨의 시맨틱 특징들은 해결될 문제에 더 적용가능하다. 풀링 계층: 훈련 파라미터들의 수량이 일반적으로 감소될 필요가 있기 때문에, 풀링 계층은 일반적으로 컨볼루션 계층 이후 에 주기적으로 도입될 필요가 있다. 구체적으로, 도 3에 도시된 계층에서의 계층들(221 내지 226)에 대해, 하나의 컨볼루션 계층에 이어서 하나의 풀링 계층이 뒤따를 수 있거나, 복수의 컨볼루션 계층에 이어서 하나 이상의 풀링 계층이 뒤따를 수 있다. 이미지 처리 동안, 풀링 계층은 이미지의 공간 크기를 감소시키기 위해서만 사용된다. 풀링 계층은 입력 이미지에 대해 샘플링을 수행하여 작은 크기를 갖는 이미지를 획득하기 위해 평균 풀링 연산자 및/또는 최대 풀링 연산자를 포함할 수 있다. 평균 풀링 연산자는 특정 범위 내에서 이 미지의 픽셀 값들을 계산하여 평균 값을 생성할 수 있다. 평균 값은 평균 풀링 결과로서 사용된다. 최대 풀링 연산자는 최대 풀링 결과로서 특정 범위 내에서 최대 값을 갖는 픽셀을 선택할 수 있다. 또한, 컨볼루션 계층 에서의 가중치 행렬의 크기가 이미지의 크기와 관련될 필요가 있다는 것과 유사하게, 풀링 계층에서의 연산자는 또한 이미지의 크기와 관련될 필요가 있다. 풀링 계층으로부터 출력되는 처리된 이미지의 크기는 풀링 계층에 입력되는 이미지의 크기보다 작을 수 있다. 풀링 계층으로부터 출력되는 이미지에서의 각각의 픽셀은 풀링 계 층에 입력되는 이미지의 대응하는 부분-영역의 평균 값 또는 최대 값을 나타낸다. 신경망 계층: 컨볼루션 계층/풀링 계층에 의해 처리가 수행된 후에, 컨볼루션 신경망은 여전히 요구된 출력 정보를 출력할 수 없다. 전술한 바와 같이, 컨볼루션 계층/풀링 계층에서는, 특징만이 추출되고, 입력 이미지로 부터 생기는 파라미터들이 감소된다. 그러나, 최종 출력 정보(요구되는 클래스 정보 또는 다른 관련 정보)를 생성하기 위해, 컨볼루션 신경망은 하나의 요구되는 클래스의 출력 또는 요구되는 클래스들의 그룹의 출력 들을 생성하기 위해 신경망 계층을 사용할 필요가 있다. 따라서, 신경망 계층은 복수의 은닉 계층 (도 3에 도시된 231, 232, ..., 및 23n) 및 출력 계층을 포함할 수 있다. 복수의 은닉 계층에 포함된 파 라미터들은 특정 태스크 타입의 관련 훈련 데이터에 기초한 사전-훈련을 통해 획득될 수 있다. 예를 들어, 태 스크 타입은 이미지 인식, 이미지 분류, 초해상도 이미지 재구성 등을 포함할 수 있다. 신경망 계층에서, 복수의 은닉 계층 다음에 출력 계층, 즉, 전체 컨볼루션 신경망의 마지막 계 층이 뒤따른다. 출력 계층은 분류 크로스 엔트로피(categorical cross entropy)와 유사한 손실 함수를 갖 고, 손실 함수는 예측 에러를 계산하도록 구체적으로 구성된다. 일단 전체 컨볼루션 신경망의 순방향 전 파(예를 들어, 도 3의 210으로부터 240으로의 방향으로의 전파)가 완료되면, 역방향 전파(예를 들어, 도 3의 240으로부터 210으로의 방향으로의 전파)가 시작되어 위에서 언급한 각각의 계층의 가중치 값 및 편차를 업데이 트하여, 컨볼루션 신경망의 손실 및 출력 계층을 사용하여 컨볼루션 신경망에 의해 출력된 결과와 이 상적인 결과 사이의 에러를 감소시킨다. 본 출원의 실시예들에서 이미지 처리 방법에서 구체적으로 사용되는 신경망의 구조가 도 4에 도시될 수 있다. 도 4에서, 컨볼루션 신경망(CNN)은 입력 계층, 컨볼루션 계층/풀링 계층(풀링 계층은 선택적 임), 및 신경망 계층을 포함할 수 있다. 도 3과 비교하여, 도 4에서는, 컨볼루션 계층/풀링 계층에 서, 복수의 컨볼루션 계층들/풀링 계층들이 병렬이고, 추출된 특징들은 처리를 위해 신경망 계층에 입력된 다. 도 3에 도시된 컨볼루션 신경망 및 도 4에 도시된 컨볼루션 신경망은 본 출원의 실시예들에서 이미지 처리 방법 에 사용되는 단지 2개의 예시적인 컨볼루션 신경망이라는 점에 유의해야 한다. 특정 응용에서, 본 출원의 실시 예들에서 이미지 처리 방법에 사용되는 컨볼루션 신경망은 대안적으로 다른 네트워크 모델의 형태로 존재할 수 있다. 또한, 본 출원의 실시예들에서 신경망 구조 검색 방법을 사용하여 획득된 컨볼루션 신경망의 구조는 도 3의 컨 볼루션 신경망의 구조 및 도 4의 컨볼루션 신경망의 구조로서 도시될 수 있다. 도 5는 본 출원의 실시예에 따른 칩의 하드웨어 아키텍처의 개략도이다. 칩은 신경망 처리 유닛을 포함한 다. 칩은 도 1에 도시된 실행 디바이스에 배치되어, 계산 모듈의 계산 작업을 완료할 수 있다. 칩은 대안적으로 도 1에 도시된 훈련 디바이스에 배치되어, 훈련 디바이스의 훈련 작업을 완료하고 목 표 모델/규칙을 출력할 수 있다. 도 3에 도시된 컨볼루션 신경망 및 도 4에 도시된 컨볼루션 신경망의 모 든 계층들에서의 알고리즘들은 도 5에 도시된 칩에 구현될 수 있다. 신경망 처리 유닛(NPU)은 코프로세서의 역할을 하고, 호스트 중앙 처리 유닛(central processing unit, CPU)(host CPU) 상에 배치될 수 있다. 호스트 CPU는 태스크를 할당한다. NPU의 코어부는 연산 회로이고, 제어기는 연산 회로를 제어하여 메모리(가중치 메모리 또는 입력 메모리)로부터 데이터를 추출하고 연산을 수행한다. 일부 구현들에서, 연산 회로는 복수의 처리 엔진(process engine, PE)을 내부에 포함한다. 일부 구현들에 서, 연산 회로는 2차원 시스톨릭 어레이(two-dimensional systolic array)이다. 대안적으로, 연산 회로 는 1차원 시스톨릭 어레이 또는 곱셈 및 덧셈과 같은 수학적 연산들을 수행할 수 있는 다른 전자 회로일 수 있다. 일부 구현들에서, 연산 회로는 범용 행렬 프로세서(general-purpose matrix processor)이다. 예를 들어, 입력 행렬 A, 가중 행렬 B, 및 출력 행렬 C가 있다고 가정한다. 연산 회로는 가중치 메모리로 부터 행렬 B의 대응하는 데이터를 추출하고, 대응하는 데이터를 연산 회로 내의 각각의 PE에 버퍼링한다. 연산 회로는 입력 메모리로부터 행렬 A의 데이터를 추출하고, 행렬 A와 행렬 B의 데이터 사이의 행렬 연산을 수 행하여 부분 행렬 결과 또는 최종 행렬 결과를 획득하고, 결과를 누산기(accumulator)에 저장한다. 벡터 계산 유닛은 연산 회로의 출력에 대한 추가 처리, 예를 들어, 벡터 곱셈, 벡터 덧셈, 지수 연산, 로 그 연산, 및 값 비교를 수행할 수 있다. 예를 들어, 벡터 계산 유닛은 신경망 내의 비-컨볼루션/비-FC 계 층에서 풀링(pooling), 배치 정규화(batch normalization), 또는 로컬 응답 정규화(local response normalization)와 같은 네트워크 계산을 수행하도록 구성될 수 있다. 일부 구현들에서, 벡터 계산 유닛은 처리된 출력 벡터를 통합 메모리에 저장할 수 있다. 예를 들어, 벡터 계산 유닛은 연산 회로의 출력, 예를 들어, 누적 값의 벡터에 비선형 함수를 적용하여, 활성화 값을 생성할 수 있다. 일부 구현들에서, 벡터 계산 유닛은 정규화된 값, 조합된 값, 또는 양자 모두를 생 성한다. 일부 구현들에서, 처리된 출력 벡터는, 예를 들어, 신경망 내의 후속 계층에서 사용되는, 연산 회로 에 대한 활성화 입력으로서 사용될 수 있다. 통합 메모리는 입력 데이터 및 출력 데이터를 저장하도록 구성된다. 가중치 데이터의 경우, 직접 메모리 액세스 제어기(direct memory access controller, DMAC)가 외부 메모 리의 입력 데이터를 입력 메모리 및/또는 통합 메모리에 전송하고, 외부 메모리의 가중치 데이터를 가중치 메모리에 저장하고, 통합 메모리의 데이터를 외부 메모리에 저장한다. 버스 인터페이스 유닛(bus interface unit, BIU)은 버스를 통해 호스트 CPU, DMAC, 및 명령어 페치 버퍼 사이의 상호작용을 구현하도록 구성된다. 제어기에 연결된 명령어 페치 버퍼(instruction fetch buffer)는 제어기에 의해 사용되는 명령 어들을 저장하도록 구성된다. 제어기는 명령어 페치 버퍼 내에 버퍼링된 명령어들을 호출하여, 연산 가속기의 작동 프로세스를 제 어하도록 구성된다. 보통, 통합 메모리, 입력 메모리, 가중치 메모리, 및 명령어 페치 버퍼는 각각 온-칩(On- Chip) 메모리이다. 외부 메모리는 NPU 외부의 메모리이다. 외부 메모리는 더블 데이터 레이트 동기식 동적 랜 덤 액세스 메모리(double data rate synchronous dynamic random access memory, 줄여서 DDR SDRAM), 고 대역 폭 메모리(high bandwidth memory, HBM), 또는 다른 판독가능 및 기입가능 메모리일 수 있다. 도 3에 도시된 컨볼루션 신경망 및 도 4에 도시된 컨볼루션 신경망에서의 각각의 계층의 연산은 연산 회로 또는 벡터 계산 유닛에 의해 수행될 수 있다. 전술한 도 2에서의 실행 디바이스는 본 출원의 실시예들에서의 이미지 처리 방법의 단계들을 수행할 수 있 다. 도 3에 도시된 CNN 모델 및 도 4에 도시된 CNN 모델 및 도 5에 도시된 칩은 또한 본 출원의 실시예들에서 의 이미지 처리 방법의 단계들을 수행하도록 구성될 수 있다. 이하에서는 첨부 도면들을 참조하여 본 출원의 실시예들에서의 신경망 구축 방법 및 본 출원의 실시예들에서의 이미지 처리 방법을 상세히 설명한다.도 6은 본 출원의 실시예에 따른 시스템 아키텍처를 도시한다. 시스템 아키텍처는 로컬 디바이스, 로컬 디바이스, 실행 디바이스 및 데이터 저장 시스템을 포함한다. 로컬 디바이스 및 로 컬 디바이스는 통신 네트워크를 통해 실행 디바이스에 연결된다. 실행 디바이스는 하나 이상의 서버에 의해 구현될 수 있다. 선택적으로, 실행 디바이스는 다른 컴퓨 팅 디바이스, 예를 들어, 데이터 메모리, 라우터, 또는 부하 균형기(load balancer)와 같은 디바이스와 협력할 수 있다. 실행 디바이스는 하나의 물리적 사이트 상에 배치되거나, 복수의 물리적 사이트 상에 분산될 수 있다. 실행 디바이스는 데이터 저장 시스템 내의 데이터를 사용함으로써 또는 데이터 저장 시스템 내의 프로그램 코드를 호출함으로써 본 출원의 실시예들에서의 신경망 모델 업데이트 방법을 구현할 수 있다. 구체적으로, 일 구현에서, 실행 디바이스는 다음의 프로세스를 수행할 수 있다: 신경망 모델 및 신경망 모델의 관련 파라미터를 획득하는 것 - 신경망 모델의 관련 파라미터는 신경망 모델의 하이퍼-파라미터, 손실 함수, 및 평가 방식을 포함함 - ; 훈련 데이터를 신경망 모델에 입력하여 예측 라벨을 획득하는 것; 예측 라벨 및 훈련 데이터의 라벨에 기초하여 손실 함수의 함수 값을 결정하고, 손실 함수의 함수 값 및 신경망 모델의 하이퍼-파라미터에 기초하여 신경망 모델을 훈련시켜 훈련된 신경망 모델을 획득하는 것; 및 훈련된 신경망 모델을 평가 방식으로 평가하고, 훈련된 신경망 모델의 평가 결과가 미리 설정된 조건을 충족시 키지 않으면, 업데이트된 결과가 종료 조건을 충족할 때까지 신경망 모델과 신경망 모델의 관련 파라미터 중 적 어도 2개를 업데이트하는 것. 전술한 프로세스에서, 실행 디바이스는 목표 신경망 및/또는 신경망의 관련 파라미터를 획득할 수 있다. 목표 신경망은 이미지 분류, 이미지 처리 등을 위해 사용될 수 있다. 사용자는 실행 디바이스와 상호작용하기 위해 사용자의 사용자 장비(예를 들어, 로컬 디바이스 및 로 컬 디바이스)를 동작시킬 수 있다. 각각의 로컬 디바이스는 개인용 컴퓨터, 컴퓨터 워크스테이션, 스마트 폰, 태블릿 컴퓨터, 지능형 카메라, 스마트 자동차, 다른 타입의 셀룰러 폰, 미디어 소비 디바이스, 웨어러블 디바이스, 셋톱 박스, 또는 게임 콘솔과 같은 임의의 컴퓨팅 디바이스일 수 있다. 각각의 사용자의 로컬 디바이스는 임의의 통신 메커니즘/통신 표준의 통신 네트워크를 통해 실행 디바이스(31 0)와 상호작용할 수 있다. 통신 네트워크는 광역 네트워크, 근거리 네트워크, 점대점 연결, 또는 이들의 임의 의 조합일 수 있다. 일 구현에서, 로컬 디바이스 및 로컬 디바이스는 실행 디바이스로부터 목표 신경망의 관련 파라 미터를 획득하고, 로컬 디바이스 및 로컬 디바이스 상에 목표 신경망을 배치하고, 목표 신경망을 사 용하여 이미지 분류, 이미지 처리 등을 수행한다. 다른 구현에서, 목표 신경망은 실행 디바이스 상에 직접 배치될 수 있다. 실행 디바이스는 로컬 디 바이스 및 로컬 디바이스로부터 처리될 이미지를 획득하고, 목표 신경망 모델을 사용하여 처리될 이 미지에 대해 분류 또는 다른 타입의 이미지 처리를 수행한다. 대안적으로, 실행 디바이스는 클라우드 디바이스일 수 있다. 이 경우, 실행 디바이스는 클라우드 상 에 배치될 수 있다. 대안적으로, 실행 디바이스는 단말 디바이스일 수 있다. 이 경우, 실행 디바이스 는 사용자 단말 측에 배치될 수 있다. 이것은 본 출원의 이러한 실시예에 제한되지 않는다. AutoML-기반 클라우드 플랫폼은 사용자에 의해 설정된 제한들에 기초하여 네트워크 설계 및 검색을 수행하고, 네트워크 설계 및 검색을 통해 획득된 네트워크 모델을 사용자에게 제공할 수 있다. 제한들은 네트워크 모델의 타입, 네트워크 모델의 정확도, 네트워크 모델의 지연, 네트워크 모델의 실행 플랫폼 등을 포함할 수 있다. 도 7은 AutoML 프레임워크의 구조의 개략도이다. 도 7에 도시된 바와 같이, AutoML은 검색 공간(search space), 최적화기(optimizer), 및 평가기(evaluator)를 포함한다. 검색 공간은 특정 AutoML 태스크에 기초하여 결정된다. 특정 AutoML 태스크는 도 7에서의 학습 프로세스이고, 학습될 필요가 있는 태스크/프로세스로서 이해될 수 있다. 특정 태스크는 전처리 방식, 신경망 모델, 손실 함 수 등을 포함할 수 있다. 예를 들어, 특정 태스크가 신경망 모델일 때, 검색 공간은 복수의 신경망 구조 유닛을 포함할 수 있고, 최종 신경망 모델은 검색 공간에서 이들 신경망 유닛들을 조합함으로써 형성된다. 최적화기는 검색 공간에서 상이한 구성들을 선택하고 평가를 위해 평가기에 구성들을 할당한 다음, 평가기에 의 해 피드백된 평가 결과에 기초하여 정책 업데이트 또는 구성 업데이트를 수행하도록 구성된다. 예를 들어, 특 정 태스크가 신경망 모델일 때, 최적화기는 검색 공간에서 신경망 구조 유닛들을 선택 또는 검색하고, 신경망 구조 유닛들을 하나 이상의 후보 모델로 조합하고, 조합을 통해 획득된 후보 모델들로부터 네트워크 모델을 선 택할 수 있다. 선택된 네트워크 모델은 구성으로서 이해될 수 있고, 구성은 평가를 위해 평가기에 할당된다. 평가기는 학습 플랫폼 상의 상이한 구성들의 성능 지시자들을 평가하고, 획득된 평가 결과를 최적화기에 피드백 하도록 구성된다. 예를 들어, 특정 태스크가 신경망 모델일 때, 평가기는 최적화기에 의해 선택된 네트워크 모 델을 훈련하고, 훈련된 네트워크 모델의 성능 지시자를 평가할 수 있다. 성능 지시자는 신경망 모델의 정확도, 네트워크 모델의 지연 등을 포함할 수 있다. 평가 결과는 최적화기가 구성들을 업데이트하도록 최적화기에 피 드백된다. 본 출원의 이 실시예에서, AutoML 프레임워크 내의 최적화기 및 평가기는 에이전트(agent) 또는 지능형 모듈로 서 사용될 수 있다. 에이전트는 학습을 위해 환경과 상호작용하여, 특정 AutoML 태스크를 완료한다. 에이전트 는 액션들을 통해 환경과 상호작용하는 엔티티이다. 환경은 에이전트가 상호작용하는 객체 또는 에이전트에 의 해 탐색되는 목표이고, 전술한 학습 플랫폼에 대응한다. 액션들은 환경 상에서 에이전트에 의해 수행되는 모든 동작들이고 최적화기에 의해 선택된 구성들에 대응한다. 최적화기가 검색 공간에서 상이한 구성들을 선택한다 는 것은 에이전트가 검색 공간에서 상이한 액션들(action)을 선택한다는 것과 동등하다. 상태는 에이전트에 의 해 획득된 환경 정보이다. 환경 정보는 보상(reward)을 포함할 수 있다. 보상은 환경에 의해 에이전트로 피드 백된 액션들의 효과이고, 평가기에 의해 획득된 상이한 구성들의 평가 결과에 대응한다. 최적화기가 평가 결과 에 기초하여 구성들을 업데이트한다는 것은 에이전트가 보상에 기초하여 액션들의 생성 방향을 조정할 수 있다 는 것과 동등하다. 서비스 프로세스에서, 데이터는 전처리 방식으로 전처리되고, 전처리된 데이터는 특징 학습 및 맵핑을 위해 신 경망 모델에 입력되고, 그 후 신경망 모델의 파라미터가 손실 함수를 사용하여 반복적으로 업데이트되거나, 신 경망 모델이 훈련된다. 훈련된 신경망 모델은 사용자에게 제공되는 신경망 모델이고, 사용자는 훈련된 신경망 모델을 사용하여 결과를 예측할 수 있다. 도 8은 서비스 프로세스에 AutoML을 적용하는 개략도이다. 일반적으로, AutoML 태스크들은 서비스 프로세스에 서 최적화될 필요가 있는 각각의 모듈/파라미터에 대해 개별적으로만 설계될 수 있다. 예를 들어, 전술한 서비 스 프로세스에서 최적화될 필요가 있는 파라미터들/모듈들은 3개의 독립적인 AutoML 태스크에 대응하는 전처리 방식, 신경망 모델, 및 손실 함수를 포함할 수 있다. 3개의 AutoML 태스크는 3개의 에이전트에 의해 각각 완료 된다. 3개의 에이전트는 각각 3개의 최적의 구성, 즉, 최적의 전처리 모드, 최적의 신경망 모델, 및 최적의 손 실 함수를 획득한다. 3개의 최적의 구성이 전술한 서비스 프로세스에 적용된다. 구체적으로, 데이터는 최적의 전처리 방식으로 전처 리되고, 전처리된 데이터는 특징 학습 및 맵핑을 위해 최적의 신경망 모델에 입력되고, 그 후 최적의 신경망 모 델의 파라미터가 최적의 손실 함수를 사용하여 반복적으로 업데이트되거나, 최적의 신경망 모델이 훈련된다. 훈련된 최적의 신경망 모델이 사용자의 제한들을 충족시킬 수 있는지가 결정된다. 사용자의 제한들이 충족되면, 신경망 모델은 사용자에게 제공되는 신경망 모델이다. 사용자는 신경망 모델을 사용하여 결과를 예 측할 수 있다. 사용자의 제한들이 충족되지 않으면, 3개의 에이전트는 3개의 최적의 구성을 획득하기 위해 재 사용될 필요가 있고, 전술한 프로세스는 사용자의 제한들이 충족될 때까지 반복된다. 3개의 AutoML 태스크는 서로 독립적이고, 3개의 에이전트는 서로 연관되지 않는다. 따라서, 엔드-투-엔드 설계 는 구현될 수 없다. 3개의 에이전트에 의해 획득된 최적의 전처리 방식, 최적의 신경망 모델, 및 최적의 손실 함수가 단순히 조합되는 경우, 훈련된 신경망 모델은 최적의 성능을 획득하지 못할 수 있다. 3개의 최적의 구 성에서의 일부 구성들이 어느 정도 서로 충돌할 때에도, 최종적으로 획득된 신경망 모델의 성능이 저하될 수 있 고, 예를 들어, 최종적으로 획득된 신경망 모델의 정확도가 감소된다. 최종적으로 획득된 신경망 모델의 성능 이 사용자의 제한들을 충족시키지 않을 때, 이전 프로세스가 반복될 필요가 있다. 이는 생산 효율에 영향을 미 친다. 이하에서는 도 9를 참조하여 본 출원의 실시예에 따른 신경망 모델 업데이트 방법을 상세히 설명한다. 도 9에 도시된 방법은 신경망 모델 업데이트 장치에 의해 수행될 수 있다. 신경망 모델 업데이트 장치는 클라우드서비스 디바이스일 수 있거나, 모바일 단말, 예를 들어, 컴퓨터 또는 서버와 같은 신경망 모델을 업데이트하기 에 충분한 컴퓨팅 능력을 갖는 장치일 수 있다. 방법은 단계 910 내지 단계 940을 포함한다. 다음은 단계 910 내지 단계 940을 상세히 설명한다. 910: 신경망 모델의 구조 및 신경망 모델의 관련 파라미터를 획득하며, 여기서 신경망 모델의 관련 파라미터는 신경망 모델의 하이퍼-파라미터, 손실 함수, 및 평가 방식을 포함한다. 신경망 모델의 파라미터는 데이터 훈련 또는 데이터 학습을 통해 획득된다. 예를 들어, 신경망 모델의 파라미 터는 신경망 모델의 가중치 및 바이어스일 수 있다. 신경망 모델의 하이퍼-파라미터는 신경망 모델의 훈련 프 로세스에서 변경되지 않은 채로 유지되는 파라미터를 포함한다. 하이퍼-파라미터는 데이터 훈련 또는 데이터 학습을 통해 획득되지 않고, 일반적으로 데이터 훈련 또는 데이터 학습 전에 결정된다. 예를 들어, 신경망 모델의 하이퍼-파라미터는 다음 중 하나 이상을 포함한다: 신경망 모델의 학습률, 신경망 모 델의 가중치 감쇠(weight decay) 계수, 신경망 모델의 라벨 평활(label smooth) 계수, 신경망 모델의 드롭아웃 (dropout) 파라미터, 또는 이와 유사한 것. 신경망 모델의 평가 방식은 신경망 모델의 특정 평가 지시자에 관련된다. 예를 들어, 신경망 모델의 평가 지시 자는 신경망 모델의 목표 크기, 신경망 모델의 목표 추론 정확도, 신경망 모델의 목표 추론 지연 등 중 적어도 하나를 포함할 수 있다. 신경망 모델의 목표 크기는 신경망 모델에 의해 점유된 목표 메모리 공간으로서 이해 될 수 있다. 본 출원의 이 실시예에서, \"추론\"은 \"예측\"이라고도 지칭될 수 있다. 이에 대응하여, 훈련된 신 경망 모델의 평가 결과는 훈련된 신경망 모델의 크기, 훈련된 신경망 모델의 추론 정확도, 훈련된 신경망 모델 의 추론 지연 등 중 적어도 하나를 포함할 수 있다. 예를 들어, 평가 방식은 신경망 모델의 크기 및 신경망 모델의 추론 정확도를 평가하는 것을 포함할 수 있다. 다른 예로서, 평가 방식은 신경망 모델의 추론 정확도를 평가하는 것을 포함할 수 있다. 평가 지시자 및 평가 방식은 사용자 요건에 기초하여 설정될 수 있다는 것을 이해해야 한다. 평가 지시자 및 평가 방식의 특정 내용은 본 출원의 이 실시예에서 제한되지 않는다. 신경망 모델의 관련 파라미터와 신경망 모델의 구조 중 어느 하나는 미리 설정될 수 있거나, 랜덤하게 획득될 수 있다. 920: 훈련 데이터를 처리를 위해 신경망 모델에 입력하여 예측 라벨을 획득한다. 선택적으로, 신경망 모델의 관련 파라미터는 훈련 데이터를 전처리하는 전처리 방식을 추가로 포함한다. 이 경 우, 단계 920은 다음을 포함한다: 921a: 훈련 데이터를 전처리 방식으로 전처리한다. 예를 들어, 신경망 모델은 이미지 처리에 적용될 수 있다. 훈련 데이터는 훈련 이미지를 포함한다. 전처리 방 식은 훈련 이미지를 뒤집거나 병진시키는 것을 포함할 수 있다. 922A: 전처리된 훈련 데이터를 처리를 위해 신경망 모델에 입력하여 예측 라벨을 획득한다. 선택적으로, 신경망 모델의 관련 파라미터는 신경망 모델의 압축 방식을 추가로 포함한다. 이 경우, 단계 920 은 다음을 포함한다: 921b: 신경망 모델을 신경망 모델의 압축 방식으로 처리하여 처리된 신경망 모델을 획득한다. 구체적으로, 신경망 모델을 신경망 모델의 압축 방식으로 처리하는 것은 신경망 모델을 압축하는 것 및/또는 신 경망 모델을 양자화하는 것을 포함한다. 예를 들어, 신경망 모델을 압축하는 것은: 중복 가중치 파라미터(redundancy weight parameter)를 폐기하는 것, 컨볼루션 코어 채널들의 수량을 감소시키는 것, 신경망 모델의 계층들의 수량을 감소시키는 것 등을 포함할 수 있다. 예를 들어, 신경망 모델을 양자화하는 것은: 각각의 가중치를 표현하기 위해 요구되는 비트들의 수량을 감소시 킴으로써 신경망 모델을 압축하는 것을 포함할 수 있다. 예를 들어, 가중치는 32 비트에서 8 비트로 변경된다. 신경망 모델을 신경망 모델의 압축 방식으로 처리하는 전술한 방식은 단지 예일 뿐이라는 것을 이해해야 한다. 신경망 모델의 압축 방식의 특정 내용은 본 출원의 이 실시예에서 제한되지 않는다.922b: 훈련 데이터를 처리된 신경망 모델에 입력하여 예측 라벨을 획득한다. 단계 921b에서, 신경망 모델을 처리하는 것은 훈련되지 않은 신경망 모델을 처리하는 것일 수 있거나, 또는 훈 련된 신경망 모델을 처리하는 것일 수 있다. 구체적으로, 단계 921b는 다음을 포함할 수 있다: 단계 910에서 획득된 신경망 모델을 직접 처리, 예를 들어, 압축 및/또는 양자화하는 단계; 및 그 후 훈련 데이터를 처리된 신경망 모델에 입력하여 예측 라벨을 획득하는 단계. 다시 말해서, 신경망 모델이 먼저 처리된 다음, 처리된 신경망 모델이 훈련된다. 예를 들어, 단계 930 이 수행된다. 대안적으로, 단계 921b는 다음을 포함할 수 있다: 신경망 모델의 관련 파라미터에 기초하여, 단계 910에서 획득 된 신경망 모델을 훈련시키고, 그 후 훈련된 신경망 모델을 처리, 예를 들어, 압축 및/또는 양자화하고, 그 후 훈련 데이터를 처리된 신경망 모델에 입력하여 예측 라벨을 획득하는 단계. 다시 말해서, 신경망 모델이 먼저 훈련된다. 예를 들어, 단계 930이 수행된다. 그 후, 훈련된 신경망 모델이 처리되고, 처리된 신경망 모델이 다시 훈련된다. 예를 들어, 단계 930이 다시 수행된다. 2회의 훈련에 사용되는 훈련 데이터는 동일할 수 있거 나 상이할 수 있다. 930: 예측 라벨 및 훈련 데이터의 라벨에 기초하여 손실 함수의 함수 값을 결정하고, 손실 함수의 함수 값 및 신경망 모델의 하이퍼-파라미터에 기초하여 신경망 모델을 훈련시켜 훈련된 신경망 모델을 획득한다. 손실 함수의 함수 값은 신경망 모델의 예측 라벨과 훈련 데이터의 라벨 사이의 차이를 측정하기 위해 사용될 수 있다. 신경망 모델의 예측 라벨이 훈련 데이터의 라벨에 매우 근접할 때까지 차이에 기초하여 신경망의 각각의 계층의 가중치 벡터가 업데이트된다. 예를 들어, 손실 함수의 더 높은 함수 값은 더 큰 차이를 지시한다. 따 라서, 신경망의 훈련은 함수값을 가능한 한 많이 감소시키는 프로세스가 된다. 일부 경우들에서, 손실 함수는 대안적으로 목적 함수일 수 있다. 신경망 모델은 신경망 모델의 파라미터의 값을 보정함으로써 훈련된다. 구체적으로, 신경망 모델은 신경망 모 델의 구조의 파라미터 값을 보정함으로써 훈련된다. 훈련 프로세스에서, 신경망 모델의 파라미터의 값은 에러 역방향 전파 알고리즘을 사용함으로써 정정될 수 있어, 신경망 모델의 에러 손실이 점점 더 작아지게 된다. 구 체적으로, 입력 신호는 에러 손실이 출력에서 생성될 때까지 순방향 전송되고, 신경망 모델의 파라미터는 에러 손실에 관한 정보의 역방향 전파를 통해 업데이트되어, 에러 손실을 수렴시킨다. 역방향 전파 알고리즘은 주로 에러 손실에 의존하는 역방향 전파 모션이고, 최적의 신경망 모델의 파라미터, 예를 들어, 가중치 행렬을 획득 하기 위해 사용된다. 940: 훈련된 신경망 모델을 평가 방식으로 평가하고, 훈련된 신경망 모델의 평가 결과가 미리 설정된 조건을 충 족시키지 않으면, 업데이트된 신경망 모델의 평가 결과가 미리 설정된 조건을 충족시키고/시키거나 업데이트 횟 수가 미리 설정된 횟수에 도달할 때까지 신경망 모델의 관련 파라미터와 신경망 모델의 구조 중 적어도 2개를 업데이트한다. 다시 말해서, 신경망 모델의 관련 파라미터와 신경망 모델의 구조 중 적어도 2개가 업데이트된 후에, 단계 920 내지 단계 940이 반복되어 신경망 모델을 평가한다. 업데이트된 신경망 모델의 평가 결과가 미리 설정된 조건 을 충족시키지 않고/않거나 업데이트 횟수가 미리 설정된 횟수에 도달하지 않으면, 업데이트된 신경망 모델의 평가 결과가 미리 설정된 조건을 충족시키고/시키거나 업데이트 횟수가 미리 설정된 횟수에 도달할 때까지 신경 망 모델의 관련 파라미터와 신경망 모델의 구조 중 적어도 2개가 계속 업데이트된다. 미리 설정된 조건은 평가 지시자에 관련된다. 평가 결과가 미리 설정된 조건을 충족시킨다는 것은, 훈련된 신 경망 모델의 성능이 평가 지시자에 도달한다는 것을 포함할 수 있거나, 또는 훈련된 신경망 모델의 성능이 평가 지시자에 관련된 범위 내에 있다는 것을 포함할 수 있다. 예를 들어, 평가 지시자가 신경망 모델의 목표 추론 정확도 및/또는 신경망 모델의 목표 추론 지연을 포함하는 경우, 훈련된 신경망 모델의 평가 결과가 미리 설정된 조건을 충족시킨다는 것은 훈련된 신경망 모델의 추론 정 확도 및/또는 훈련된 신경망 모델의 추론 지연이 신경망 모델의 목표 추론 정확도 및/또는 신경망 모델의 목표 추론 지연에 도달한다는 것일 수 있다. 구체적으로, 신경망 모델의 관련 파라미터와 신경망 모델의 구조 중 적어도 2개를 업데이트하는 것은 신경망 모 델의 구조를 업데이트하는 것 및/또는 신경망 모델의 관련 파라미터를 업데이트하는 것을 포함한다. 예를 들어, 신경망 모델의 관련 파라미터와 신경망 모델의 구조 중 적어도 2개를 업데이트하는 것은 신경망 모 델의 구조 및 손실 함수를 업데이트하는 것일 수 있다. 다시 말해서, 업데이트 프로세스에서, 신경망 모델의 하이퍼-파라미터 및 평가 방식은 변경되지 않은 채로 유지되고, 신경망 모델의 구조 및 손실 함수는 업데이트되 어 제1 신경망 모델의 구조 및 제1 손실 함수를 획득한다. 단계 920이 수행된다. 구체적으로, 훈련 데이터는 제1 신경망 모델에 입력되어 예측 라벨을 획득한다. 단계 930이 수행된다. 구체적으로, 예측 라벨 및 훈련 데 이터의 라벨에 기초하여 제1 손실 함수의 함수 값이 결정되고, 제1 손실 함수의 함수 값 및 신경망 모델의 하이 퍼-파라미터에 기초하여 제1 신경망 모델이 훈련되어 훈련된 신경망 모델을 획득한다. 단계 940이 수행된다. 구체적으로, 훈련된 신경망 모델은 평가 방식으로 평가된다. 업데이트된 신경망 모델의 평가 결과가 미리 설정된 조건을 충족시키지 않고/않거나 업데이트 횟수가 미리 설정된 횟수에 도달하지 않으면, 제1 신경망 모델의 구조 및 제1 손실 함수가 업데이트된다. 단계 920 내지 단계 940은, 업데이트된 신 경망 모델의 평가 결과가 미리 설정된 조건을 충족시키고/시키거나 업데이트 횟수가 미리 설정된 횟수에 도달할 때까지 전술한 방식으로 반복된다. 이 경우, 신경망 모델의 업데이트된 구조 및 업데이트된 손실 함수가 획득 될 수 있다. 예를 들어, 신경망 모델의 관련 파라미터와 신경망 모델의 구조 중 적어도 2개를 업데이트하는 것은 대안적으로 손실 함수와 평가 방식를 업데이트하는 것일 수 있다. 다시 말해서, 업데이트 프로세스에서, 신경망 모델의 구 조, 신경망 모델의 하이퍼-파라미터 등은 변경되지 않은 채로 유지된다. 이 경우, 손실 함수와 평가 방식의 최 적의 조합 방식이 획득될 수 있다. 조합 방식은, 신경망 모델을 업데이트하는 효율을 향상시키고 신경망 모델 의 성능을 향상시키기 위해, 다른 신경망 모델의 구조에 적용될 수 있다. 선택적으로, 단계 940에서 신경망 모델의 관련 파라미터와 신경망 모델의 구조 중 적어도 2개를 업데이트하는 것은 구체적으로 다음과 같은 단계들을 포함한다. 940a: 신경망 모델의 관련 파라미터와 신경망 모델의 구조 중 적어도 2개의 각각의 항목에 대응하는 제1 정보에 기초하여, 적어도 2개의 각각의 항목에 대응하는 복수의 후보 옵션들의 확률 분포를 결정하며, 여기서 각각의 항목에 대응하는 제1 정보는 훈련된 신경망 모델의 평가 결과를 포함하거나, 또는 이전 업데이트 후에 획득된 신경망 모델의 평가 결과일 수 있다. 이전 업데이트 후에 획득된 신경망 모델의 평가 결과는, 이전 업데이트 후에 획득된 신경망 모델의 구조 및/또 는 이전 업데이트 후에 획득된 신경망 모델의 관련 파라미터에 기초하여 신경망 모델을 훈련시키고 훈련된 신경 망 모델을 평가함으로써 획득된 평가 결과이다. 설명을 용이하게 하기 위해, 본 출원의 이 실시예에서, 이전 업데이트 후에 획득된 신경망 모델의 구조 및/또는 이전 업데이트 후에 획득된 신경망 모델의 관련 파라미터에 기초하여 신경망 모델을 훈련시키고 훈련된 신경망 모델을 평가함으로써 획득된 평가 결과는 업데이트된 신경망 모델의 평가라고도 지칭될 수 있다. 본 출원의 이 실시예에서, 신경망 모델의 관련 파라미터만이 업데이트되고, 신경망 모델의 구조는 업데이트되지 않는다는 것을 이해해야 한다. 업데이트된 신경망 모델의 관련 파라미터에 기초하여 신경망 모델을 훈련시키고 훈련된 신경망 모델을 평가함으로써 획득된 평가 결과는 업데이트된 신경망 모델을 평가함으로써 획득된 평가 결과라고도 지칭될 수 있다. 구체적으로, 각각의 항목에 대해, 각각의 항목에 대응하는 제1 정보가 처리되어 특징 맵을 획득할 수 있다. 예 를 들어, 각각의 항목에 대응하는 제1 정보가 순환 신경망을 사용하여 처리되어 특징 맵을 획득한다. 각각의 항목에 대응하는 복수의 후보 옵션들의 확률 분포는 특징 맵에 기초하여 결정된다. 예를 들어, 각각의 항목에 대응하는 복수의 후보 옵션들의 확률 분포는 완전-연결 네트워크(fully-connected network)를 사용하여 결정된 다. 각각의 항목에 대응하는 복수의 후보 옵션들의 확률 분포를 결정하는 전술한 방식은 단지 예일 뿐이고, 각각의 항목에 대응하는 복수의 후보 옵션들의 확률 분포를 결정하는 다른 방식들은 모두 단계 940a에 적용가능하다는 것을 이해해야 한다. 확률 분포를 계산하는 방식은 본 출원의 이 실시예에서 제한되지 않는다. 940b: 각각의 항목에 대응하는 복수의 후보 옵션들의 확률 분포에 기초하여 각각의 항목에 대응하는 복수의 후 보 옵션들 내의 하나의 후보 옵션을 업데이트된 옵션으로서 결정한다. 예를 들어, 각각의 항목에 대응하는 복수의 후보 옵션들의 확률 분포에 기초하여 복수의 후보 옵션들에서 확률 이 가장 높은 하나의 후보 옵션이 업데이트된 옵션으로서 결정될 수 있다. 다른 예로서, 각각의 항목에 대응하는 복수의 후보 옵션들의 확률 분포에 기초하여 샘플링이 수행될 수 있고, 샘플링을 통해 획득된 후보 옵션이 업데이트된 옵션이다. 이것은 업데이트 프로세스의 효율을 향상시키고 업데이트 프로세스에서의 로컬 최적화를 회피할 수 있다. 예를 들어, 단계 940에서 신경망 모델의 관련 파라미터와 신경망 모델의 구조 중 적어도 2개를 업데이트하는 것 은 신경망 모델의 관련 파라미터와 신경망 모델의 구조 중 2개의 항목을 업데이트하는 것일 수 있다. 2개의 항 목은 각각 신경망 모델의 구조 및 손실 함수이다. 단계 940은 구체적으로 다음을 포함한다: 940c: 신경망 모델의 구조에 대응하는 제1 정보에 기초하여, 신경망 모델의 구조에 대응하는 복수의 후보 옵션 들의 확률 분포를 결정하고 - 신경망 모델의 구조에 대응하는 복수의 후보 옵션들의 확률 분포는 또한 신경망 모델의 복수의 후보 구조들의 확률 분포로서 이해될 수 있고, 신경망 모델의 구조에 대응하는 제1 정보는 이전 업데이트 후에 획득된 신경망 모델의 평가 결과를 포함함 - ; 손실 함수에 대응하는 제1 정보에 기초하여, 손실 함수에 대응하는 복수의 후보 옵션들의 확률 분포를 결정한다 - 손실 함수에 대응하는 복수의 후보 옵션들의 확 률 분포는 또한 복수의 후보 손실 함수들의 확률 분포로서 이해될 수 있고, 손실 함수에 대응하는 제1 정보는 이전 업데이트 후에 획득된 신경망 모델의 평가 결과를 포함함 - . 940d: 신경망 모델의 구조에 대응하는 복수의 후보 옵션들의 확률 분포에 기초하여 신경망 모델의 구조에 대응 하는 복수의 후보 옵션들 내의 하나의 후보 옵션을 업데이트된 신경망 모델의 구조로서 결정하고; 손실 함수에 대응하는 복수의 후보 옵션들의 확률 분포에 기초하여 손실 함수에 대응하는 복수의 후보 옵션들 내의 하나의 후보 옵션을 업데이트된 손실 함수로서 결정한다. 선택적으로, 각각의 항목에 대응하는 제1 정보는 신경망 모델의 관련 파라미터와 신경망 모델의 구조 중 적어도 2개에서의 다른 항목의 관련 정보를 추가로 포함한다. 다른 항목의 관련 정보는 현재 업데이트 전에 획득된 다 른 항목 및 현재 업데이트 전에 획득된 다른 항목에 대응하는 복수의 후보 옵션들의 확률 분포 중 적어도 하나 를 포함한다. 예를 들어, 단계 940에서 신경망 모델의 관련 파라미터와 신경망 모델의 구조 중 적어도 2개를 업데이트하는 것 은 신경망 모델의 관련 파라미터와 신경망 모델의 구조 중 2개의 항목을 업데이트하는 것일 수 있다. 2개의 항 목은 각각 신경망 모델의 구조 및 손실 함수이다. 신경망 모델의 구조에 대응하는 제1 정보는 손실 함수의 관련 정보를 추가로 포함한다. 손실 함수의 관련 정보 는 현재 업데이트 전에 획득된 손실 함수 및/또는 현재 업데이트 전에 획득된 손실 함수에 대응하는 복수의 후 보 옵션들의 확률 분포를 포함한다. 예를 들어, 손실 함수의 관련 정보는 이전 업데이트 후에 획득된 손실 함 수 및/또는 이전 업데이트 후에 획득된 손실 함수에 대응하는 복수의 후보 옵션들의 확률 분포를 포함한다. 다 른 예로서, 손실 함수의 관련 정보는 이전의 여러 업데이트 후에 획득된 손실 함수 및/또는 이전의 여러 업데이 트 후에 획득된 손실 함수에 대응하는 복수의 후보 옵션들의 확률 분포를 포함한다. 손실 함수에 대응하는 제1 정보는 신경망 모델의 구조의 관련 정보를 추가로 포함한다. 신경망 모델의 구조의 관련 정보는 현재 업데이트 전에 획득된 신경망 모델의 구조 및/또는 현재 업데이트 전에 획득된 신경망 모델의 손실 함수에 대응하는 복수의 후보 옵션들의 확률 분포를 포함한다. 예를 들어, 신경망 모델의 구조의 관련 정 보는 이전 업데이트 후에 획득된 신경망 모델의 구조 및/또는 이전 업데이트 후에 획득된 신경망 모델의 구조에 대응하는 복수의 후보 옵션들의 확률 분포를 포함한다. 다른 예로서, 신경망 모델의 구조의 관련 정보는 이전 의 여러 업데이트 후에 획득된 신경망 모델의 구조 및/또는 이전의 여러 업데이트 후에 획득된 신경망 모델의 구조에 대응하는 복수의 후보 옵션들의 확률 분포를 포함한다. 선택적으로, 단계 940은 다음을 추가로 포함한다: 제1 빈도에 기초하여 적어도 2개에서의 다른 항목의 관련 정 보를 별개로 획득하는 단계. 다시 말해서, 적어도 2개의 업데이트 프로세스에서 제1 빈도에 기초하여 정보 교환이 수행될 수 있다. 예를 들어, 단계 940에서 신경망 모델의 관련 파라미터와 신경망 모델의 구조 중 적어도 2개를 업데이트하는 것 은 신경망 모델의 관련 파라미터와 신경망 모델의 구조 중 2개의 항목을 업데이트하는 것일 수 있다. 2개의 항 목은 각각 신경망 모델의 구조 및 손실 함수이다. 제1 빈도에 기초하여 신경망 모델의 관련 파라미터와 신경망 모델의 구조 중 적어도 2개에서 다른 항목의 관련 정보를 별개로 획득하는 것은: 제1 빈도에 기초하여 손실 함수의 관련 정보를 획득하는 것; 및 제1 빈도에 기초 하여 신경망 모델의 구조의 관련 정보를 획득하는 것을 포함할 수 있다. 다시 말해서, 신경망 모델의 손실 함 수 및 구조의 업데이트 프로세스에서 제1 빈도에 기초하여 정보 교환이 수행된다.예를 들어, 제1 빈도는 미리 설정된 고정 값일 수 있다. 대안적으로, 제1 빈도는 신경망 모델에 의해 처리되는 서비스의 타입 및 서비스의 규모와 관련될 수 있다. 서비스의 규모가 작을 때, 예를 들어, 신경망 모델이 이동 전화 앨범 분류를 위해 사용될 때, 훈련 데이터의 자 릿수(order of magnitude)는 대략 백만 레벨이다. 정보 교환은 즉각적인 정보 교환일 수 있다. 즉, 다른 현재 항목의 관련 정보의 획득은 이전 업데이트 후에 획득된 다른 항목의 관련 정보의 획득이다. 서비스의 규모가 클 때, 예를 들어, 신경망 모델이 얼굴 인식을 위해 사용될 때, 훈련 데이터의 자릿수는 수억에 도달할 수 있다. 정보 교환은 일정 기간 내에 다른 항목의 관련 정보를 획득하는 것일 수 있다. 선택적으로, 적어도 2개에서의 다른 아이템의 관련 정보의 내용은 신경망 모델에 의해 처리되는 서비스의 타입 및 서비스의 규모와 관련될 수 있다. 예를 들어, 서비스의 규모가 작을 때, 다른 항목의 관련 정보의 내용은 다른 항목만을 포함할 수 있다. 서비스 의 규모가 클 때, 다른 항목의 관련 정보의 내용은 다른 항목 및 다른 항목에 대응하는 복수의 후보 옵션들의 확률 분포를 포함할 수 있다. 본 출원의 이 실시예에서, 다른 항목의 관련 정보는 업데이트 프로세스에서 획득되어, 공동 업데이트 및 최적화 를 구현한다. 파라미터들 사이의 가능한 충돌이 업데이트 프로세스에서 회피될 수 있어, 신경망 모델의 관련 파라미터와 신경망 모델의 최종적으로 획득된 조합이 가능한 한 빨리 요구되는 성능 지시자에 도달할 수 있다. 이것은 신경망 모델을 업데이트하는 효율을 향상시킨다. 선택적으로, 각각의 항목에 대응하는 제1 정보는 각각의 항목의 이력 관련 정보를 추가로 포함한다. 각각의 항 목의 이력 관련 정보는 이전 업데이트에서의 각각의 항목의 업데이트된 옵션 및/또는 이전 업데이트에서의 각각 의 항목에 대응하는 복수의 후보 옵션들의 확률 분포를 포함한다. 예를 들어, 각각의 항목의 이력 관련 정보는 이전의 여러 업데이트에서의 각각의 항목의 업데이트된 옵션 및/또 는 이전의 여러 업데이트에서의 각각의 항목에 대응하는 복수의 후보 옵션들의 확률 분포를 포함할 수 있다. 본 출원의 이 실시예에서, 설명을 용이하게 하기 위해, 각각의 항목의 업데이트된 옵션은 각각의 업데이트된 항 목이라고도 지칭될 수 있다. 또한, 각각의 아이템의 이력 관련 정보는 이전의 여러 업데이트 후에 획득된 환경 상태 정보를 추가로 포함할 수 있다. 선택적으로, 각각의 항목에 대응하는 제1 정보는 훈련 자원 상태 정보를 추가로 포함한다. 훈련 자원 상태 정 보는 훈련 머신들의 수량을 포함한다. 예를 들어, 훈련 자원 상태 정보는 현재 이용가능한 훈련 머신들의 수량을 추가로 포함할 수 있다. 업데이트 프로세스에서의 각각의 파라미터에 대응하는 훈련 자원, 훈련 규모 등이 훈련 자원 상태 정보에 기초 하여 조정될 수 있어, 신경망 모델을 업데이트하는 효율을 추가로 향상시킨다. 예를 들어, 머신 학습 프로세스에서의 특징들의 수량은 훈련 자원에 기초하여 조정될 수 있다. 다른 예로서, 훈련 자원은 후보 옵션들의 수량에 기초하여 할당될 수 있다. 본 출원의 이 실시예에서, 신경망 모델의 관련 파라미터와 신경망 모델의 구조 중 임의의 2개가 업데이트되고, 업데이트된 신경망 모델의 관련 파라미터와 신경망 모델의 구조가 평가되어, 복수의 파라미터들의 공동 평가를 구현한다. 이것은 각각의 파라미터가 별개로 업데이트될 때 존재하는 가능한 충돌을 회피한다. 따라서, 신경 망 모델과 신경망 모델의 관련 파라미터의 최종적으로 획득된 조합은 가능한 한 빨리 요구되는 성능 지시자에 도달할 수 있다. 이것은 신경망 모델을 업데이트하는 효율을 향상시킨다. 도 10은 본 출원의 실시예에 따른 신경망 모델 업데이트 장치의 개략도이다. 신경망 모델 업데이트 장치는 환 경 상태 관측 모듈, 훈련 및 추론 모듈, 및 출력 모듈을 주로 포함한다. 본 출원의 이 실시예에서 신경망 모델을 업데이트하는 실행 프로세스를 더 잘 이해하기 위해, 이하에서는 도 10 에서의 모듈들의 기능들을 간단히 설명한다. 환경 관측 모듈은 환경 상태 정보를 수집하고, 환경 상태 정보를 훈련 및 추론 모듈에 입력하도록 구성된다. 환경 상태 정보는 훈련된 신경망 모델의 평가 결과를 포함한다.선택적으로, 환경 상태 정보는 훈련 자원 상태 정보를 추가로 포함할 수 있다. 예를 들어, 훈련 자원 상태 정 보는 훈련 머신들의 총 수량 및 현재 이용가능한 훈련 머신들의 수량을 포함할 수 있다. 신경망 모델 업데이트 장치는 하나의 환경 관측 모듈을 포함할 수 있거나, 또는 복수의 환경 관측 모듈을 포함 할 수 있다. 예를 들어, 업데이트될 적어도 2개의 항목 각각은 하나의 환경 관측 모듈에 대응한다. 훈련 및 추론 모듈은 수신된 정보에 기초하여 적어도 2개의 항목 각각을 업데이트하여 각각의 업데이트된 항목 을 획득하도록 구성된다. 신경망 모델 업데이트 장치는 하나의 훈련 및 추론 모듈을 포함할 수 있거나, 또는 복수의 훈련 및 추론 모듈을 포함할 수 있다. 예를 들어, 업데이트될 적어도 2개의 항목 각각은 하나의 훈련 및 추론 모듈에 대응한다. 출력 모듈은 훈련 및 추론 모듈에 의해 획득된 각각의 업데이트된 항목에 기초하여 신경망 모델을 평가하도록 구성된다. 신경망 모델 업데이트 장치는 이력 정보 저장 모듈 및 다른 항목 관련 정보 수집 모듈을 추가로 포함할 수 있다. 이력 정보 저장 모듈은 각각의 항목의 이력 관련 정보를 저장하고, 이력 관련 정보를 훈련 및 추론 모듈에 입력 하도록 구성된다. 이력 관련 정보는 이전의 여러 업데이트 후에 획득된 환경 상태 정보, 이전의 여러 업데이트 후에 획득된 각각의 항목, 및 이전의 여러 업데이트 후에 획득된 각각의 항목에 대응하는 네트워크 상태 중 적 어도 하나를 포함한다. 예를 들어, 각각의 항목에 대응하는 네트워크 상태는 각각의 항목에 대응하는 복수의 후보 옵션들의 확률 분포일 수 있다. 다른 항목 관련 정보 수집 모듈은 다른 항목의 관련 정보를 획득하고, 다른 항목의 관련 정보를 훈련 및 추론 모듈에 입력하도록 구성된다. 다른 항목의 관련 정보는 현재 업데이트 전에 획득된 다른 항목 및 현재 업데이 트 전에 획득된 다른 항목에 대응하는 네트워크 상태 중 적어도 하나를 포함한다. 예를 들어, 다른 항목에 대 응하는 네트워크 상태는 다른 항목에 대응하는 복수의 후보 옵션들의 확률 분포일 수 있다. 설명 및 이해를 용이하게 하기 위해, 적어도 2개의 항목을 업데이트하는 것은 적어도 2개의 에이전트가 적어도 2개의 업데이트 태스크를 각각 완료하고, 각각의 에이전트가 하나의 업데이트 태스크에 대응하는 것으로 이해될 수 있다. 복수의 에이전트는 전술한 업데이트 태스크들을 공동으로 구현하기 위해 다중-에이전트 시스템 (multi-agent system, MAS)을 형성할 수 있다. 예를 들어, 적어도 2개의 항목을 업데이트하는 것은 신경망 모 델 및 전처리 방식을 업데이트하는 것을 포함할 수 있다. 하나의 에이전트는 신경망 모델을 업데이트하도록 구 성되고, 다른 에이전트는 전처리 방식을 업데이트하도록 구성된다. 본 출원의 실시예들에서, \"에이전트\"는 설 명을 용이하게 하기 위해 도입된 개념일 뿐이고, 본 출원의 실시예들에 대한 제한을 구성하지 않는다는 것을 이 해해야 한다. N개의 항목이 업데이트되면, 도 10에 도시된 장치는 N개의 에이전트를 포함할 수 있다. 각각의 에이전트는 환 경 상태 관측 모듈, 훈련 및 추론 모듈, 및 출력 모듈을 포함할 수 있다. 선택적으로, 각각의 에이전트는 이력 정보 저장 모듈 및 다른 항목 관련 정보 수집 모듈을 추가로 포함할 수 있 다. 도 11은 본 출원의 실시예에 따른 신경망 모델을 업데이트하기 위한 시스템의 블록도이다. 도 11은 3개의 에이 전트: 에이전트 1, 에이전트 2, 및 에이전트 3을 도시한다. 업데이트될 3개의 항목은 각각 전처리 방식, 신경 망 모델의 구조, 및 손실 함수이다. 에이전트 1은 전처리 모드를 업데이트하도록 구성된다. 에이전트 2는 신 경망 모델의 구조를 업데이트하도록 구성된다. 에이전트 3은 손실 함수를 업데이트하도록 구성된다. 이하에서 는 도 11을 예로 이용하여 방법을 설명한다. (A-1) 에이전트 1, 에이전트 2, 및 에이전트 3은 각각 전처리 방식, 신경망 모델의 구조, 및 손실 함수를 출력 한다. 이 단계의 1차 수행은 3개의 에이전트의 초기화 프로세스로서 이해될 수 있고, 이 단계는 전술한 단계 910에 대응한다. 이 단계의 2차 수행 및 추가 수행은 3개의 에이전트의 업데이트 프로세스로서 이해될 수 있고, 전술한 단계 940에서의 업데이트 프로세스에 대응할 수 있다. 도 11은 3개의 항목을 업데이트하는 예를 도시하는 것일 뿐이고, 신경망 모델의 관련 파라미터에서의 다른 항목 은 고정될 수 있다. 예를 들어, 신경망 모델의 하이퍼-파라미터 및 평가 방식과 같은 파라미터들은 신경망 모 델의 업데이트 프로세스에서 미리 설정될 수 있다. 신경망 모델의 관련 파라미터가 신경망 모델의 압축 방식을포함하는 경우, 신경망 모델의 압축 방식도 역시 미리 설정될 수 있다. 도 11에서, 3개의 에이전트의 업데이트 프로세스들은 각자의 훈련 및 추론 모듈들에 의해 완료될 수 있다. 구체적으로, 에이전트 1의 경우, 환경 상태 관측 모듈은 훈련된 신경망의 평가 결과를 수집하고, 평가 결과를 훈련 및 추론 모듈에 입력한다. 훈련 및 추론 모듈은 환경 상태 관측 모듈에 의해 입력된 정보에 기초하여 훈 련 및 추론을 수행하여, 업데이트된 전처리 방식을 획득한다. 다른 2개의 에이전트는 동일한 동작을 수행하여 신경망 모델의 업데이트된 구조 및 업데이트된 손실 함수를 별개로 획득할 수 있다. 선택적으로, 환경 상태 관측 모듈은 훈련 자원 상태 정보를 추가로 수집하고, 훈련 자원 상태 정보를 훈련 및 추론 모듈에 입력할 수 있다. 선택적으로, 3개의 에이전트 각각은 다른-에이전트 정보 수집 모듈 및 이력 정보 저장 모듈을 추가로 포함할 수 있다. 다른-에이전트 정보 수집 모듈은 도 10의 다른-항목 관련 정보 수집 모듈이다. 구체적으로는, 에이전트 1의 경우, 훈련 및 추론 모듈은 환경 상태 관측 모듈, 다른-에이전트 정보 수집 모듈, 및 이력 정보 저장 모듈에 의해 입력된 정보에 기초하여 훈련 및 추론을 수행하여, 업데이트된 전처리 방식을 획득할 수 있다. 다른 2개의 에이전트는 동일한 동작을 수행하여 신경망 모델의 업데이트된 구조 및 업데이트 된 손실 함수를 별개로 획득할 수 있다. (A-2) 신경망 모델의 관련 파라미터가 신경망 모델의 압축 방식을 포함하지 않는 경우, 단계(A-2a)를 수행하거 나; 또는 신경망 모델의 관련 파라미터가 신경망 모델의 압축 방식을 포함하는 경우, 상황에 기초하여 단계(A- 2a) 또는 단계(A-2b)를 수행한다. (A-2a)는: 단계(A-1)에서의 전처리 방식으로 훈련 데이터를 전처리하고, 전처리된 훈련 데이터를 단계(A-1)에서의 신경망 모델에 입력하여 예측 라벨을 획득하는 단계를 포함한다. (A-2b)는: 단계(A-1)에서의 전처리 방식으로 훈련 데이터를 전처리하는 단계; 단계(A-1)에서의 신경망 모델을 신경망 모델의 전술한 압축 방식으로 처리하는 단계 - 신경망 모델을 처리하는 것은 신경망 모델을 양자화 및/또는 압축하는 것일 수 있음 - ; 및 전처리된 훈련 데이터를 처리된 신경망 모델에 입력하여 예측 라벨을 획득하는 단계를 포함한다. (A-3) 신경망 모델의 관련 파라미터가 신경망 모델의 압축 방식을 포함하지 않는 경우, 단계(A-3a)를 수행하거 나; 또는 신경망 모델의 관련 파라미터가 신경망 모델의 압축 방식을 포함하는 경우, 상황에 기초하여 단계(A- 3a) 또는 단계(A-3b)를 수행하고, 여기서 단계(A-2a)는 단계(A-3b)에 대응하고, 단계(A-2b)는 단계(A-3a)에 대 응하고, 단계(A-2) 및 단계(A-3)는 방법에서의 단계 920 및 단계 930에 대응한다. (A-3a)는: 예측 라벨 및 훈련 데이터의 라벨에 기초하여 손실 함수의 함수 값을 결정하고, 손실 함수의 함수 값 및 신경망 모델의 하이퍼-파라미터에 기초하여 신경망 모델을 훈련시켜 훈련된 신경망 모델을 획득하는 단계를 포함한다. (A-3b)는: 예측 라벨 및 훈련 데이터의 라벨에 기초하여 손실 함수의 함수 값을 결정하고, 손실 함수의 함수 값 및 신경망 모델의 하이퍼-파라미터에 기초하여 신경망 모델을 훈련시켜 훈련된 신경망 모델을 획득하는 단계를 포함한다. 단계(A-2a)에서의 훈련된 신경망 모델은 신경망 모델의 전술한 압축 방식으로 처리되어 처리된 신경망 모델을 획득하며, 여기서 훈련된 신경망 모델을 처리하는 것은 훈련된 신경망 모델을 양자화 및/또는 압축하는 것일 수 있다. 그 후, 처리된 신경망 모델은 훈련된 신경망 모델을 획득하도록 훈련된다. (A-4) 단계(A-1)에서의 평가 방식으로 훈련된 신경망 모델을 평가하여 훈련된 신경망 모델의 평가 결과를 획득 한다. 설명을 용이하게 하기 위해, 전술한 단계(A-2) 내지 단계(A-4)는 3개의 에이전트가 평가 결과를 획득하기 위한 액션들을 환경에 출력하는 것으로서 이해될 수 있다. (A-5) 업데이트된 신경망 모델의 평가 결과가 미리 설정된 조건을 충족시키지 않고/않거나 업데이트 횟수가 미 리 설정된 횟수에 도달하지 않으면, 단계(A-1) 내지 단계(A-4)를 반복한다. 평가 결과가 미리 설정된 조건에 도달한다는 것은 업데이트 프로세스가 수렴한다는 것일 수 있다. 미리 설정된 조건은 사용자에 의해 설정될 수 있다. 예를 들어, 미리 설정된 조건은 목표 추론 정확도, 목표 추론 지연, 및 목표 메모리 공간 중 적어도 하나일 수 있다. 이것은 예시일 뿐이다. 미리 설정된 조건은 대안적으로 사용자 에 의해 설정된 임의의 목표일 수 있다. 종료 조건이 충족되면, 3개의 에이전트는 3개의 에이전트에 의해 출력된 최종 액션들에 각각 대응하는 최종 전 처리 방식, 신경망 모델의 최종 구조, 및 최종 손실 함수를 각각 출력한다. 3개의 최종 액션은 구성, 즉, 출력 될 최종 결과로서 사용될 수 있다. 도 12는 본 출원의 다른 실시예에 따른 신경망 모델 업데이트 방법의 개략적인 흐름도이다. 도 12에 도시된 방 법은 도 11에서의 장치에 의해 수행될 수 있다. 도 12에 도시된 방법은 단계 1210 내지 단계 1280을 포함한다. 다음은 단계 1210 내지 단계 1280을 상세히 설명한다. 1210: 수집된 환경 상태 정보, 수집된 이력 관련 정보, 및 다른 에이전트의 수집된 정보에 기초하여 각각의 에 이전트의 액션을 획득한다. 도 12에서의 환경 상태 정보는 현재 훈련 환경에서의 훈련 자원 상태 및 평가 결과를 포함할 수 있다. 현재 훈 련 환경에서의 훈련 자원 상태는 훈련 머신들의 총 수량 및 현재 이용가능한 훈련 머신들의 수량을 포함할 수 있다. 환경 상태 정보는 도 11에서의 환경 상태 관측 모듈에 의해 수집될 수 있다. 도 12에서의 다른 에이전트의 정보는 다른 에이전트의 전술한 관련 정보이다. 구체적으로, 다른 에이전트의 정 보는 다른 에이전트의 액션 및 다른 에이전트의 네트워크 상태를 포함할 수 있다. 다른 에이전트의 액션은 다 른 항목이고, 다른 에이전트의 네트워크 상태는 다른 에이전트에 의해 출력된 액션에 대응하는 확률 분포를 포 함할 수 있다. 다른 에이전트의 정보는 도 11에서의 다른-에이전트 정보 수집 모듈에 의해 수집될 수 있다. 에이전트들 사이에서 다른 에이전트의 정보를 교환하는 빈도 및 다른 에이전트의 정보의 내용은 태스크 타입 및 태스크 규모에 기초하여 결정될 수 있다. 다른 에이전트의 정보의 교환은 즉각적인 정보 교환일 수 있거나, 또 는 미리 설정된 빈도로 또는 미리 설정된 시간 간격으로의 정보 교환일 수 있다. 예를 들어, 에이전트 1은 에 이전트 1의 액션, 네트워크 상태 등을 버퍼링하고, 다음 정보 교환을 기다릴 수 있다. 다른 예로서, 다른 에이 전트의 정보를 수신한 후에, 에이전트 1의 다른-에이전트 정보 수집 모듈은 정보를 저장하고, 미리 설정된 시간 간격 후에 정보를 훈련 및 추론 모듈에 송신한다. 도 12의 이력 관련 정보는 도 11의 이력 관련 정보 수집 모듈에 의해 획득될 수 있다. 이력 관련 정보는 환경 상태 정보, 에이전트의 이력 액션, 에이전트의 이력 네트워크 상태 등을 포함할 수 있다. 구체적으로, 단계 1210은 단계 1211 내지 단계 1215를 포함한다. 1211: 수집된 환경 상태 정보, 수집된 이력 관련 정보, 및 다른 에이전트의 수집된 정보를 다층 퍼셉트론 (multi-layer perceptron, MLP) 네트워크에 입력한다. 구체적으로, 환경 상태 정보, 이력 관련 정보, 및 다른 에이전트의 정보는 벡터에 스플라이싱(splice)될 수 있 고, 벡터는 MLP 네트워크에 입력된다. 1212: MLP 네트워크를 사용해서 환경 상태 정보, 이력 관련 정보, 및 다른 에이전트의 정보를 처리하여 맵핑된 벡터를 획득하고, 맵핑된 벡터를 장단기 메모리(long short term memory, LSTM) 네트워크에 입력한다. 구체적으로, 맵핑된 벡터의 차원은 LSTM 네트워크의 입력 차원에 기초하여 결정될 수 있다. 1213: LSTM 네트워크를 사용해서 맵핑된 벡터를 처리하여 특징 맵을 획득한다. 구체적으로, 특징 맵은 액션 공간의 차원, 즉, 출력 차원, 또는 완전-연결 계층의 입력 차원에 기초하여 획득될 수 있다. 1214: 특징 맵에 기초하여 완전-연결 계층을 사용해서, 에이전트에 의해 출력된 액션의 확률 분포를 획득한다. 구체적으로, 3개의 에이전트에서의 완전-연결 계층들은 각자의 특징 맵들에 기초하여 각자의 액션들의 확률 분 포들을 별개로 획득한다. 예를 들어, 에이전트 1, 에이전트 2, 및 에이전트 3이 전처리 방식, 신경망 모델의구조, 및 손실 함수에 각각 대응하는 경우, 전처리 방식의 확률 분포, 신경망 모델의 구조의 확률 분포, 및 손 실 함수의 확률 분포가 단계 1214에서 각각 획득될 수 있다. 1215: 3개의 에이전트의 각자의 액션들의 확률 분포들에 기초하여 액션 샘플링을 수행해서 출력 액션들을 획득 한다. 예를 들어, 에이전트 1, 에이전트 2, 및 에이전트 3이 전처리 방식, 신경망 모델의 구조, 및 손실 함수에 각각 대응하는 경우, 단계 1215에서, 에이전트 1은 출력 전처리 방식 π1을 획득하고, 에이전트 2는 신경망 모델의 출력 구조 π2를 획득하고, 에이전트 3은 출력 손실 함수 π3을 획득한다. 신경망 모델 π2는 훈련되지 않은 신경망 모델일 수 있다. 예를 들어, 에이전트 1에 의해 출력된 액션은 이산 값으로 표현될 수 있다. 에이전트 1에 의해 출력된 액션들 의 세트는 A={1, 2, 3..., N}이고, 대응하는 확률 분포 세트는 P={p1, p2, p3, ..., pN}이며, 여기서 N은 양의 정수이고, N은 에이전트 1의 현재 후보 액션들의 수량을 나타낸다. 단계 1215에서, 에이전트에 의해 출력된 현 재 액션은 액션들의 확률 분포 세트에 기초하여 액션들의 세트로부터 샘플링을 통해 획득된다. 1220: 환경에서 전술한 단계에서 3개의 에이전트에 의해 출력된 액션들을 평가한다. 3개의 에이전트에 의해 출력된 액션들 또는 정책들은 정책 그룹 π = {π1, π2, π3}으로서 이해될 수 있다. 구체적으로, 전처리 방식 π1, 신경망 모델의 구조 π2, 및 손실 함수 π3은 서비스 절차에 적용된다. 신경망 모델의 구조 π2를 훈련시키는 것은 신경망 모델의 구조 π2에서의 파라미터를 정정하는 것, 즉, 신경망 모델을 훈련시켜 훈련된 신경망 모델을 획득하는 것이다. 3개의 에이전트에 의해 출력된 액션들을 평가하는 것은 훈련 된 신경망 모델의 성능을 평가하는 것, 예를 들어, 훈련된 신경망 모델의 추론 정확도를 평가하는 것 또는 훈련 된 네트워크 모델의 추론 지연을 평가하는 것이다. 구체적인 프로세스는 전술한 단계들 (A-2) 내지 (A-4)에서 설명된다. 상세사항들은 여기서 다시 설명되지 않는다. 1230: 업데이트 결과가 종료 조건을 충족하는지를 결정한다. 종료 조건이 충족되지 않으면, 단계 1210 내지 단 계 1220이 반복된다. 종료 조건이 충족되면, 3개의 에이전트의 현재 액션들이 출력된다. 예를 들어, 업데이트 결과가 종료 조건을 충족한다는 것은, 업데이트된 신경망 모델의 평가 결과가 미리 설정된 조건을 충족시키거나 업데이트 횟수가 미리 설정된 횟수에 도달한다는 것일 수 있다. 다시 말해서, 신경망 모 델의 관련 파라미터와 신경망 모델의 구조 중 적어도 2개가 업데이트된 후에, 신경망 모델이 다시 평가된다. 업데이트 결과가 종료 조건을 충족하지 않으면, 신경망 모델의 관련 파라미터와 신경망 모델의 구조 중 적어도 2개는 업데이트 결과가 종료 조건을 충족할 때까지 계속 업데이트된다. 업데이트 결과가 종료 조건을 충족하지 않는다는 것은 업데이트된 신경망 모델의 평가 결과가 미리 설정된 조건을 충족하지 않고 업데이트 횟수가 미리 설정된 횟수에 도달하지 않는다는 것일 수 있다. 단계 1210 내지 단계 1220은 하나의 반복의 프로세스로서 이해될 수 있다. 신경망 모델의 관련 파라미터와 신경망 모델의 구조 중 어느 하나는 하나의 에이전트에 대응할 수 있다는 것을 이해해야 한다. 도 12는 3개의 에이전트를 업데이트하는 예를 도시하는 것일 뿐이고, 3개의 에이전트는 예로서 사용되는 것일 뿐이다. 특정 응용 시나리오에서, 에이전트들의 수량은 요건에 기초하여 설정될 수 있다. 다시 말해서, 업데이트될 필요가 있는 항목들의 수량은 요건에 기초하여 설정된다. 도 13은 본 출원의 실시예에 따른 이미지 처리 방법의 개략적인 흐름도이다. 방법은 이미지 처리를 수행 할 수 있는 장치 또는 디바이스에 의해 수행될 수 있다. 예를 들어, 방법은 단말 디바이스, 컴퓨터, 서버 등에 의해 수행될 수 있다. 도 13의 이미지 처리 방법에서 사용되는 목표 신경망은 도 9의 방법 또는 도 12의 방법을 사용하여 구성 될 수 있다. 방법은 단계 1310 내지 단계 1320을 포함한다. 방법의 특정 구현에 대해서는, 전술 한 방법을 참조한다. 불필요한 반복을 피하기 위해, 방법이 후술될 때 반복된 설명은 적절히 생략 된다. 1310: 처리될 이미지를 획득한다. 처리될 이미지는 카메라를 사용하여 단말 디바이스(또는 컴퓨터 또는 서버와 같은 다른 장치 또는 디바이스)에 의해 촬영된 이미지일 수 있거나, 처리될 이미지는 단말 디바이스(또는 컴퓨터 또는 서버와 같은 다른 장치 또는 디바이스)로부터 획득된 이미지(예를 들어, 단말 디바이스의 앨범에 저장된 이미지, 또는 단말 디바이스에 의해 클라우드로부터 획득된 이미지)일 수 있다. 이것은 본 출원의 이러한 실시예에 제한되지 않는다. 1320: 목표 신경망 모델을 사용함으로써 처리될 이미지를 처리하여 처리될 이미지의 처리 결과를 획득한다. 목표 신경망 모델은 업데이트된 신경망 모델의 평가 결과가 미리 설정된 조건을 충족시키고/시키거나 업데이트 횟수가 미리 설정된 횟수에 도달할 때까지 신경망 모델의 관련 파라미터와 신경망 모델의 구조 중 적어도 2개를 업데이트함으로써 획득된다. 신경망 모델의 관련 파라미터는 신경망 모델의 하이퍼-파라미터, 손실 함수, 및 평가 방식을 포함한다. 신경망 모델은 예측 라벨 및 훈련 데이터의 라벨에 기초하여 손실 함수의 함수 값을 결 정하고 신경망 모델의 하이퍼-파라미터 및 손실 함수의 함수 값에 기초하여 훈련을 수행함으로써 획득된다. 예 측 라벨은 훈련 데이터를 처리를 위해 신경망 모델에 입력함으로써 획득된다. 선택적으로, 신경망 모델의 관련 파라미터는 전처리 방식을 추가로 포함한다. 예측 라벨은 훈련 데이터를 전처 리 방식으로 전처리하고 전처리된 훈련 데이터를 처리를 위해 신경망 모델에 입력함으로써 획득된다. 선택적으로, 신경망 모델의 관련 파라미터는 신경망 모델의 압축 방식을 추가로 포함한다. 예측 라벨은 신경망 모델을 신경망 모델의 압축 방식으로 처리하고 훈련 데이터를 처리된 신경망 모델에 입력함으로써 획득된다. 선택적으로, 신경망 모델의 관련 파라미터와 신경망 모델의 구조 중 적어도 2개를 업데이트하는 단계는: 신경망 모델의 관련 파라미터와 신경망 모델의 구조 중 적어도 2개의 각각의 항목에 대응하는 제1 정보에 기초하여, 각 각의 항목에 대응하는 복수의 후보 옵션들의 확률 분포를 결정하는 단계 - 각각의 항목에 대응하는 제1 정보는 평가 결과를 포함함 - ; 및 각각의 항목에 대응하는 복수의 후보 옵션들의 확률 분포에 기초하여 각각의 항목에 대응하는 복수의 후보 옵션들 내의 하나의 후보 옵션을 각각의 항목의 업데이트된 옵션으로서 결정하는 단계를 포함한다. 선택적으로, 각각의 항목에 대응하는 제1 정보는 신경망 모델의 관련 파라미터와 신경망 모델의 구조 중 적어도 2개에서의 다른 항목의 관련 정보를 추가로 포함한다. 다른 항목의 관련 정보는 다른 항목 및/또는 다른 항목 에 대응하는 복수의 후보 옵션들의 확률 분포를 포함한다. 선택적으로, 각각의 항목에 대응하는 제1 정보는 각각의 항목의 이력 관련 정보를 추가로 포함한다. 각각의 항 목의 이력 관련 정보는 이전 업데이트에서의 각각의 항목의 업데이트된 옵션 및/또는 이전 업데이트에서의 각각 의 항목에 대응하는 복수의 후보 옵션들의 확률 분포를 포함한다. 선택적으로, 각각의 항목에 대응하는 제1 정보는 훈련 자원 상태 정보를 추가로 포함한다. 훈련 자원 상태 정 보는 훈련 머신들의 수량을 포함한다. 도 14는 본 출원의 실시예에 따른 신경망 모델 업데이트 장치의 하드웨어 구조의 개략도이다. 도 14에 도시된 신경망 모델 업데이트 장치(장치는 구체적으로 컴퓨터 디바이스일 수 있음)는 메모리, 프로 세서, 통신 인터페이스, 및 버스를 포함한다. 메모리, 프로세서, 및 통신 인 터페이스는 버스를 통해 서로 통신가능하게 연결된다. 메모리는 판독 전용 메모리(Read Only Memory, ROM), 정적 저장 디바이스, 동적 저장 디바이스, 또는 랜 덤 액세스 메모리(Random Access Memory, RAM)일 수 있다. 메모리는 프로그램을 저장할 수 있다. 메모 리에 저장된 프로그램이 프로세서에 의해 실행될 때, 프로세서는 본 출원의 실시예들에서의 신경망 모델 업데이트 방법의 단계들을 수행하도록 구성된다. 구체적으로, 프로세서는 도 9에 도시된 전 술한 방법에서의 단계 910 내지 단계 940을 수행할 수 있다. 프로세서는 범용 중앙 처리 유닛(central processing unit, CPU), 마이크로프로세서, 주문형 집적 회로 (application specific integrated circuit, ASIC), 그래픽 처리 유닛(graphics processing unit, GPU), 또는 하나 이상의 집적 회로일 수 있고, 관련 프로그램을 실행하여, 본 출원의 방법 실시예들에서의 신경망 모델 업 데이트 방법을 구현하도록 구성된다. 대안적으로, 프로세서는 집적 회로 칩일 수 있고 신호 처리 능력을 갖는다. 예를 들어, 프로세서 는 도 5에 도시된 칩일 수 있다. 구현 프로세스에서, 본 출원에서의 신경망 모델 업데이트 방법의 단계들은 프 로세서 내의 하드웨어 집적 논리 회로 또는 소프트웨어 형태의 명령어들을 사용하여 완료될 수 있다. 프로세서는 신경망 모델의 구조 및 신경망 모델의 관련 파라미터를 획득하도록 구성된다. 신경망 모델의 관련 파라미터는 신경망 모델의 하이퍼-파라미터, 손실 함수, 및 평가 방식을 포함한다. 프로세서는: 훈련 데이터를 처리를 위해 신경망 모델에 입력하여 예측 라벨을 획득하고; 예측 라벨 및 훈련 데이터의 라벨에 기초하여 손실 함수의 함수 값을 결정하고, 손실 함수의 함수 값 및 신경망 모델의 하이퍼-파라미터에 기초하여 신경망 모델을 훈련시켜 훈련된 신경망 모델을 획득하고; 훈련된 신경망 모델을 평가 방식으로 평가하고, 훈련 된 신경망 모델의 평가 결과가 미리 설정된 조건을 충족시키지 않으면, 업데이트된 신경망 모델의 평가 결과가 미리 설정된 조건을 충족시키고/시키거나 업데이트 횟수가 미리 설정된 횟수에 도달할 때까지 신경망 모델의 관 련 파라미터와 신경망 모델의 구조 중 적어도 2개를 업데이트하도록 추가로 구성된다. 선택적으로, 신경망 모델의 관련 파라미터는 전처리 방식을 추가로 포함한다. 프로세서는 훈련 데이터를 전처리 방식으로 전처리하고, 전처리된 훈련 데이터를 처리를 위해 신경망 모델에 입력하여 예측 라벨을 획득하 도록 구성된다. 선택적으로, 신경망 모델의 관련 파라미터는 신경망 모델의 압축 방식을 추가로 포함한다. 프로세서는 신경망 모델을 신경망 모델의 압축 방식으로 처리하고, 훈련 데이터를 처리된 신경망 모델에 입력하여 예측 라 벨을 획득하도록 구성된다. 선택적으로, 프로세서는: 신경망 모델의 관련 파라미터와 신경망 모델의 구조 중 적어도 2개의 각각의 항 목에 대응하는 제1 정보에 기초하여, 각각의 항목에 대응하는 복수의 후보 옵션들의 확률 분포를 결정하고 - 각 각의 항목에 대응하는 제1 정보는 평가 결과를 포함함 - ; 각각의 항목에 대응하는 복수의 후보 옵션들의 확률 분포에 기초하여 각각의 항목에 대응하는 복수의 후보 옵션들 내의 하나의 후보 옵션을 각각의 항목의 업데이트 된 옵션으로서 결정하도록 구성된다. 선택적으로, 각각의 항목에 대응하는 제1 정보는 적어도 2개에서의 다른 항목의 관련 정보를 추가로 포함한다. 다른 항목의 관련 정보는 다른 항목 및/또는 다른 항목에 대응하는 복수의 후보 옵션들의 확률 분포를 포함한다. 선택적으로, 각각의 항목에 대응하는 제1 정보는 각각의 항목의 이력 관련 정보를 추가로 포함한다. 각각의 항 목의 이력 관련 정보는 이전 업데이트에서의 각각의 항목의 업데이트된 옵션 및/또는 이전 업데이트에서의 각각 의 항목에 대응하는 복수의 후보 옵션들의 확률 분포를 포함한다. 선택적으로, 각각의 항목에 대응하는 제1 정보는 훈련 자원 상태 정보를 추가로 포함한다. 훈련 자원 상태 정 보는 훈련 머신들의 수량을 포함한다. 선택적으로, 신경망 모델의 하이퍼-파라미터는 신경망 모델의 훈련 프로세스에서 변경되지 않은 채로 유지되는 파라미터를 포함한다. 선택적으로, 신경망 모델의 하이퍼-파라미터는 다음 중 하나 이상을 포함한다: 신경망 모델의 학습률, 신경망 모델의 가중치 감쇠 계수, 신경망 모델의 라벨 평활 계수, 또는 신경망 모델의 드롭아웃 파라미터. 프로세서는 대안적으로 범용 프로세서, 디지털 신호 프로세서(digital signal processing, DSP), 주문형 집적 회로(ASIC), 필드 프로그램가능 게이트 어레이(field programmable gate array, FPGA) 또는 다른 프로그 램가능 로직 디바이스, 개별 게이트 또는 트랜지스터 로직 디바이스, 또는 개별 하드웨어 컴포넌트일 수 있다. 그것은 본 출원의 실시예들에서 개시되는 방법들, 단계들, 및 논리 블록도들을 구현하거나 수행할 수 있다. 범 용 프로세서는 마이크로프로세서일 수 있거나, 또는 프로세서는 임의의 종래의 프로세서 등일 수 있다. 본 출 원의 실시예들을 참조하여 개시되는 방법들의 단계들은 하드웨어 디코딩 프로세서에 의해 직접 수행되고 완료될 수 있거나, 또는 디코딩 프로세서 내의 하드웨어 및 소프트웨어 모듈들의 조합을 사용하여 수행되고 완료될 수 있다. 소프트웨어 모듈은, 랜덤 액세스 메모리, 플래시 메모리, 판독-전용 메모리, 프로그램가능 판독 전용 메"}
{"patent_id": "10-2022-7023190", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "모리, 전기적으로 소거가능한 프로그램가능 메모리, 레지스터 등과 같은 이 기술분야에서의 발달된(mature) 저 장 매체에 위치될 수 있다. 저장 매체는 메모리에 위치된다. 프로세서는 메모리 내의 정보 를 판독하고, 프로세서의 하드웨어와 조합하여, 본 출원의 이 실시예에서의 신경망 모델 업데이트 장치에 포함된 유닛에 의해 실행될 필요가 있는 기능을 완료하거나, 본 출원의 실시예들에서의 신경망 모델 업데이트 방법을 수행한다. 통신 인터페이스는, 장치와 다른 디바이스 또는 통신 네트워크 사이의 통신을 구현하기 위해, 트랜 시버와 같으나 이에 제한되지 않는, 트랜시버 장치를 사용한다. 예를 들어, 머신 학습 프로세스에서 요구되는 신경망 모델 및 훈련 데이터의 업데이트된 성능 지시자는 통신 인터페이스를 통해 획득될 수 있다. 버스는 장치의 컴포넌트들(예를 들어, 메모리, 프로세서, 및 통신 인터페이스) 사이에 정보를 송신하기 위한 경로를 포함할 수 있다. 도 15는 본 출원의 실시예에 따른 이미지 처리 장치의 하드웨어 구조의 개략도이다. 도 15에 도시된 이미지 처 리 장치는 메모리, 프로세서, 통신 인터페이스, 및 버스를 포함한다. 메모리 , 프로세서, 및 통신 인터페이스는 버스를 통해 서로 통신가능하게 연결된다. 메모리는 ROM, 정적 저장 디바이스, 또는 RAM일 수 있다. 메모리는 프로그램을 저장할 수 있다. 메모리에 저장된 프로그램이 프로세서에 의해 실행될 때, 프로세서 및 통신 인터페이스 는 본 출원의 실시예들에서의 이미지 처리 방법의 단계들을 수행하도록 구성된다. 구체적으로, 프로세서 는 도 13에 도시된 전술한 방법에서의 단계 1310 내지 단계 1320을 수행할 수 있다. 프로세서는 범용 CPU, 마이크로프로세서, ASIC, GPU, 또는 하나 이상의 집적 회로일 수 있고, 관련 프로 그램을 실행하여, 본 출원의 이 실시예에서의 이미지 처리 장치 내의 유닛에 의해 실행될 필요가 있는 기능을 구현하거나, 본 출원의 방법 실시예들에서의 이미지 처리 방법을 수행하도록 구성된다. 대안적으로, 프로세서는 집적 회로 칩일 수 있고 신호 처리 능력을 갖는다. 예를 들어, 프로세서 는 도 5에 도시된 칩일 수 있다. 구현 프로세스에서, 본 출원의 실시예들에서의 이미지 처리 방법의 단계들은 프로세서 내의 하드웨어 집적 논리 회로 또는 소프트웨어 형태의 명령어들을 사용하여 완료될 수 있다. 프로세서는 처리될 이미지를 획득하고, 목표 신경망 모델을 사용함으로써 처리될 이미지를 처리하여 처리 될 이미지의 처리 결과를 획득하도록 구성된다. 목표 신경망 모델은 업데이트된 신경망 모델의 평가 결과가 미 리 설정된 조건을 충족시키고/시키거나 업데이트 횟수가 미리 설정된 횟수에 도달할 때까지 신경망 모델의 관련 파라미터와 신경망 모델의 구조 중 적어도 2개를 업데이트함으로써 획득된다. 신경망 모델의 관련 파라미터는 신경망 모델의 하이퍼-파라미터, 손실 함수, 및 평가 방식을 포함한다. 신경망 모델은 예측 라벨 및 훈련 데이 터의 라벨에 기초하여 손실 함수의 함수 값을 결정하고 신경망 모델의 하이퍼-파라미터 및 손실 함수의 함수 값 에 기초하여 훈련을 수행함으로써 획득된다. 예측 라벨은 훈련 데이터를 처리를 위해 신경망 모델에 입력함으 로써 획득된다. 선택적으로, 신경망 모델의 관련 파라미터는 전처리 방식을 추가로 포함한다. 예측 라벨은 훈련 데이터를 전처 리 방식으로 전처리하고 전처리된 훈련 데이터를 처리를 위해 신경망 모델에 입력함으로써 획득된다. 선택적으로, 신경망 모델의 관련 파라미터는 신경망 모델의 압축 방식을 추가로 포함한다. 예측 라벨은 신경망 모델을 신경망 모델의 압축 방식으로 처리하고 훈련 데이터를 처리된 신경망 모델에 입력함으로써 획득된다. 선택적으로, 신경망 모델의 관련 파라미터와 신경망 모델의 구조 중 적어도 2개를 업데이트하는 단계는: 신경망 모델의 관련 파라미터와 신경망 모델의 구조 중 적어도 2개의 각각의 항목에 대응하는 제1 정보에 기초하여, 각 각의 항목에 대응하는 복수의 후보 옵션들의 확률 분포를 결정하는 단계 - 각각의 항목에 대응하는 제1 정보는 평가 결과를 포함함 - ; 및 각각의 항목에 대응하는 복수의 후보 옵션들의 확률 분포에 기초하여 각각의 항목에 대응하는 복수의 후보 옵션들 내의 하나의 후보 옵션을 각각의 항목의 업데이트된 옵션으로서 결정하는 단계를 포함한다. 선택적으로, 각각의 항목에 대응하는 제1 정보는 신경망 모델의 관련 파라미터와 신경망 모델의 구조 중 적어도 2개에서의 다른 항목의 관련 정보를 추가로 포함한다. 다른 항목의 관련 정보는 다른 항목 및/또는 다른 항목 에 대응하는 복수의 후보 옵션들의 확률 분포를 포함한다. 선택적으로, 각각의 항목에 대응하는 제1 정보는 각각의 항목의 이력 관련 정보를 추가로 포함한다. 각각의 항 목의 이력 관련 정보는 이전 업데이트에서의 각각의 항목의 업데이트된 옵션 및/또는 이전 업데이트에서의 각각 의 항목에 대응하는 복수의 후보 옵션들의 확률 분포를 포함한다. 선택적으로, 각각의 항목에 대응하는 제1 정보는 훈련 자원 상태 정보를 추가로 포함한다. 훈련 자원 상태 정 보는 훈련 머신들의 수량을 포함한다. 선택적으로, 신경망 모델의 하이퍼-파라미터는 신경망 모델의 훈련 프로세스에서 변경되지 않은 채로 유지되는 파라미터를 포함한다. 선택적으로, 신경망 모델의 하이퍼-파라미터는 다음 중 하나 이상을 포함한다: 신경망 모델의 학습률, 신경망 모델의 가중치 감쇠 계수, 신경망 모델의 라벨 평활 계수, 또는 신경망 모델의 드롭아웃 파라미터. 전술한 프로세서는 대안적으로 범용 프로세서, DSP, ASIC, FPGA 또는 다른 프로그램가능 로직 디바이스, 이산 게이트 또는 트랜지스터 로직 디바이스, 또는 이산 하드웨어 컴포넌트일 수 있다. 그것은 본 출원의 실시 예들에서 개시되는 방법들, 단계들, 및 논리 블록도들을 구현하거나 수행할 수 있다. 범용 프로세서는 마이크 로프로세서일 수 있거나, 또는 프로세서는 임의의 종래의 프로세서 등일 수 있다. 본 출원의 실시예들을 참조 하여 개시되는 방법들의 단계들은 하드웨어 디코딩 프로세서에 의해 직접 수행되고 완료될 수 있거나, 또는 디 코딩 프로세서 내의 하드웨어 및 소프트웨어 모듈들의 조합을 사용하여 수행되고 완료될 수 있다. 소프트웨어 모듈은, 랜덤 액세스 메모리, 플래시 메모리, 판독-전용 메모리, 프로그램가능 판독 전용 메모리, 전기적으로"}
{"patent_id": "10-2022-7023190", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "소거가능한 프로그램가능 메모리, 레지스터 등과 같은 이 기술분야에서의 발달된(mature) 저장 매체에 위치될 수 있다. 저장 매체는 메모리에 위치된다. 프로세서는 메모리 내의 정보를 판독하고, 프로 세서의 하드웨어와 조합하여, 본 출원의 이 실시예에서의 이미지 처리 장치에 포함된 유닛에 의해 실행될 필요가 있는 기능을 완료하거나, 본 출원의 방법 실시예들에서의 이미지 처리 방법을 수행한다. 통신 인터페이스는, 장치와 다른 디바이스 또는 통신 네트워크 사이의 통신을 구현하기 위해, 트랜 시버와 같으나 이에 제한되지 않는, 트랜시버 장치를 사용한다. 예를 들어, 처리될 이미지는 통신 인터페이스 를 통해 획득될 수 있다. 버스는 장치의 컴포넌트들(예를 들어, 메모리, 프로세서, 및 통신 인터페이스) 사이에 정보를 송신하기 위한 경로를 포함할 수 있다. 도 16은 본 출원의 실시예에 따른 신경망 모델 훈련 장치의 하드웨어 구조의 개략도이다. 전술한 장치 및 전술한 장치와 유사하게, 도 16에 도시된 신경망 모델 훈련 장치는 메모리, 프로세서 , 통신 인터페이스, 및 버스를 포함한다. 메모리, 프로세서, 및 통신 인터페 이스는 버스를 통해 서로 통신가능하게 연결된다. 신경망 모델 및/또는 신경망 모델의 파라미터가 도 14에 도시된 신경망 모델 업데이트 장치를 사용하여 획득될 수 있는 후에, 신경망 모델은 도 16에 도시된 신경망 모델 훈련 장치를 사용하여 훈련될 수 있고, 훈련된 신경망 모델은 본 출원의 실시예들에서의 이미지 처리 방법을 수행하기 위해 사용될 수 있다. 구체적으로, 도 16에 도시된 장치는 통신 인터페이스를 통해 외부로부터 훈련 데이터 및 훈련될 신경망 모델을 획득할 수 있고, 그 후 프로세서는 훈련 데이터에 기초하여 훈련될 신경망 모델을 훈련시킨다. 메모리, 프로세서, 및 통신 인터페이스만이 장치, 장치, 및 장치 각각에 도시되어 있지만,"}
{"patent_id": "10-2022-7023190", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "특정 구현 프로세스에서, 본 기술분야의 통상의 기술자는 장치, 장치, 및 장치 각각이 정상 실행에 필요한 다른 컴포넌트를 추가로 포함할 수 있다는 것을 이해해야 한다는 점에 유의해야 한다. 또한, 특"}
{"patent_id": "10-2022-7023190", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "정 요건에 기초하여, 본 기술분야의 통상의 기술자는 장치, 장치, 및 장치 각각이 다른 추가"}
{"patent_id": "10-2022-7023190", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 7, "content": "기능을 구현하기 위한 하드웨어 컴포넌트를 추가로 포함할 수 있다는 것을 이해해야 한다. 또한, 본 기술분야 의 통상의 기술자는 장치, 장치, 및 장치 각각이 본 출원의 실시예들을 구현하는 데 필요한 컴포넌트들만을 포함할 수 있지만, 도 14, 도 15, 및 도 16에 도시된 모든 컴포넌트들을 반드시 포함하는 것은 아니라는 것을 이해해야 한다. 본 출원의 이 실시예에서의 프로세서는 중앙 처리 유닛(central processing unit, CPU)일 수 있다는 것을 이해 해야 한다. 프로세서는 추가의 다른 범용 프로세서, 디지털 신호 프로세서(digital signal processor, DSP), 주문형 집적 회로(application specific integrated circuit, ASIC), 필드 프로그램가능 게이트 어레이(field programmable gate array, FPGA) 또는 다른 프로그램가능 로직 디바이스, 개별 게이트 또는 트랜지스터 로직 디 바이스, 개별 하드웨어 컴포넌트 등일 수 있다. 범용 프로세서는 마이크로프로세서일 수 있거나, 또는 프로세 서는 임의의 종래의 프로세서 등일 수 있다. 본 출원의 이 실시예에서 메모리는 휘발성 메모리 또는 비휘발성 메모리일 수 있거나, 휘발성 메모리 및 비휘발 성 메모리를 포함할 수 있다는 것을 추가로 이해할 수 있다. 비휘발성 메모리는 판독 전용 메모리(read-only memory, ROM), 프로그램가능 판독 전용 메모리(programmable ROM, PROM), 소거가능한 프로그램가능 판독 전용 메모리(erasable PROM, EPROM), 전기적으로 소거가능한 프로그램가능 판독 전용 메모리(electrically EPROM, EEPROM), 또는 플래시 메모리일 수 있다. 휘발성 메모리는 외부 캐시로서 사용되는 랜덤 액세스 메모리(random access memory, RAM)일 수 있다. 제한적인 설명이 아니라 예로서, 많은 형태들의 랜덤 액세스 메모리(random access memory, RAM), 예를 들어, 정적 랜덤 액세스 메모리(static RAM, SRAM), 동적 랜덤 액세스 메모리 (DRAM), 동기식 동적 랜덤 액세스 메모리(synchronous DRAM, SDRAM), 더블 데이터 레이트 동기식 동적 랜덤 액 세스 메모리(double data rate SDRAM, DDR SDRAM)), 증강된 동기식 동적 랜덤 액세스 메모리(enhanced SDRAM,ESDRAM), 싱크링크 동적 랜덤 액세스 메모리(synchlink DRAM, SLDRAM), 및 직접 램버스 동적 랜덤 액세스 메모 리(direct rambus RAM, DR RAM)가 사용될 수 있다. 전술한 실시예들의 전부 또는 일부는 소프트웨어, 하드웨어, 펌웨어, 또는 이들의 임의의 조합을 사용하여 구현 될 수 있다. 소프트웨어가 실시예들을 구현하기 위해 사용될 때, 전술한 실시예들의 전부 또는 일부는 컴퓨터 프로그램 제품의 형태로 구현될 수 있다. 컴퓨터 프로그램 제품은 하나 이상의 컴퓨터 명령어 또는 컴퓨터 프 로그램을 포함한다. 컴퓨터 명령어들 또는 컴퓨터 프로그램들이 컴퓨터 상에서 로딩되고 실행될 때, 본 출원의 실시예들에 따른 절차들 또는 기능들은 완전히 또는 부분적으로 생성된다. 컴퓨터는 범용 컴퓨터, 특수-목적 컴퓨터, 컴퓨터 네트워크, 또는 다른 프로그램가능 장치일 수 있다. 컴퓨터 명령어들은 컴퓨터 판독가능 저장 매체에 저장될 수 있거나, 컴퓨터 판독가능 저장 매체로부터 다른 컴퓨터 판독가능 저장 매체로 송신될 수 있다. 예를 들어, 컴퓨터 명령어들은, 유선(예를 들어, 적외선, 라디오, 및 마이크로웨이브 등) 방식으로 웹사 이트, 컴퓨터, 서버, 또는 데이터 센터로부터 다른 웹사이트, 컴퓨터, 서버, 또는 데이터 센터로 송신될 수 있 다. 컴퓨터 판독가능 저장 매체는 컴퓨터에 의해 액세스 가능한 임의의 사용가능 매체, 또는 하나 이상의 사용 가능 매체를 통합하는, 서버 또는 데이터 센터와 같은 데이터 저장 디바이스일 수 있다. 사용가능 매체는, 자 기 매체(예를 들어, 플로피 디스크, 하드 디스크, 또는 자기 테이프), 광학 매체(예를 들어, DVD), 또는 반도체 매체일 수 있다. 반도체 매체는 솔리드-스테이트 드라이브(solid-state drive)일 수 있다. 본 명세서에서의 \"및/또는\"이라는 용어는 연관된 객체들 사이의 연관 관계만을 설명하며 세 가지 관계가 존재할 수 있음을 나타낸다는 것을 이해해야 한다. 예를 들어, A 및/또는 B는 다음의 3가지 경우: A만 존재, A와 B 둘 다 존재, 및 B만 존재를 나타낼 수 있다. A 및 B는 단수 또는 복수일 수 있다. 또한, 본 명세서에서의 문자 \"/\"는 연관된 객체들 사이의 \"또는(or)\" 관계를 일반적으로 나타내거나, 또는 \"및/또는(and/or)\" 관계를 나타낼 수 있다. 구체적인 의미는 문맥에 의존한다. 본 출원에서, \"적어도 하나\"는 하나 이상을 의미하고, \"복수의\"는 둘 이상을 의미한다. \"다음 중 적어도 하나\" 또는 그의 유사한 표현은 다음 중 하나 이상의 임의의 조합을 포함하는 다음의 임의의 조합을 나타낸다. 예를 들어, a, b, 또는 c 중 적어도 하나의 항목(피스)은 a, b, c, a와 b, a와 c, b와 c, 또는 a, b, 및 c를 나타낼 수 있고, 여기서 a, b, 및 c는 단수 또는 복수일 수 있다. 본 출원의 실시예들에서, 전술한 프로세스들의 시퀀스 번호들은 실행 시퀀스들을 의미하지 않는다는 점을 이해 해야 한다. 프로세스들의 실행 시퀀스들은 프로세스들의 기능들 및 내부 로직에 기초하여 결정되어야 하며, 본 출원의 실시예들의 구현 프로세스들에 대한 임의의 제한을 구성하지 않아야 한다."}
{"patent_id": "10-2022-7023190", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 8, "content": "본 기술분야의 통상의 기술자는, 본 명세서에 개시된 실시예들에서 설명한 예들과 조합하여, 유닛들 및 알고리 즘 단계들이 전자 하드웨어 또는 컴퓨터 소프트웨어와 전자 하드웨어의 조합에 의해 구현될 수 있다는 것을 알 수 있다. 기능들이 하드웨어에 의해 수행되는지 또는 소프트웨어에 의해 수행되는지는 기술적 해결책들의 특정"}
{"patent_id": "10-2022-7023190", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 9, "content": "애플리케이션들 및 설계 제약 조건들에 의존한다. 본 기술분야의 기술자는 각각의 특정 애플리케이션에 대해 설명된 기능들을 구현하기 위해 상이한 방법들을 사용할 수 있지만, 이러한 구현이 본 출원의 범위를 벗어나는 것으로 고려되어서는 안 된다. 편리하고 간단한 설명을 위해, 전술한 시스템, 장치, 및 유닛의 상세한 작업 프로세스에 대해서는, 전술한 방법"}
{"patent_id": "10-2022-7023190", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 10, "content": "실시예들에서의 대응하는 프로세스를 참조하는 것이 본 기술분야의 통상의 기술자에 의해 명확하게 이해될 수 있다. 상세사항들은 여기서 다시 설명되지 않는다. 본 출원에 제공된 몇몇 실시예에서, 개시된 시스템, 장치, 및 방법은 다른 방식으로 구현될 수 있다는 것을 이 해해야 한다. 예를 들어, 설명된 장치 실시예는 예일 뿐이다. 예를 들어, 유닛들로의 분할은 논리적인 기능 분할일 뿐이며 실제 구현 동안 다른 분할이 될 수 있다. 예를 들어, 복수의 유닛 또는 컴포넌트가 다른 시스템 으로 조합 또는 통합될 수 있거나, 일부 특징들이 무시되거나 수행되지 않을 수 있다. 추가로, 디스플레이되거 나 논의된 상호 결합 또는 직접 결합 또는 통신 연결은 일부 인터페이스들을 통해 구현될 수 있다. 장치들 또 는 유닛들 사이의 간접 결합들 또는 통신 연결들은 전기적 형태, 머신적 형태, 또는 다른 형태로 구현될 수 있 다. 별개의 부분들로서 설명된 유닛들은 물리적으로 분리되어 있을 수 있거나 그렇지 않을 수 있고, 유닛들로서 디 스플레이된 부분들은 물리적 유닛들일 수 있거나 그렇지 않을 수 있고, 하나의 위치에 위치될 수 있거나, 복수 의 네트워크 유닛들 상에 분산될 수 있다. 유닛들의 일부 또는 전부는 실시예들의 해결책들의 목적을 달성하기 위해 실제 요건들에 기초하여 선택될 수 있다.게다가, 본 출원의 실시예들에서의 기능 유닛들은 하나의 처리 유닛으로 통합될 수 있거나, 유닛들 각각은 물리 적으로 단독으로 존재할 수 있거나, 2개 이상의 유닛이 하나의 유닛으로 통합될 수 있다. 기능들이 소프트웨어 기능 유닛의 형태로 구현되어 독립적인 제품으로서 판매 또는 사용될 때, 기능들은 컴퓨터 판독가능 저장 매체에 저장될 수 있다. 이러한 이해에 기초하여, 본질적으로 본 출원의 기술적 해결책들, 또는 종래 기술에 기여하는 부분, 또는 기술적 해결책들의 일부는, 소프트웨어 제품의 형태로 구현될 수 있다. 컴퓨 터 소프트웨어 제품은 저장 매체에 저장되고, 컴퓨터 디바이스(개인용 컴퓨터, 서버, 네트워크 디바이스 등일 수 있음)에게 본 출원의 실시예들에 설명되는 방법들의 단계들의 전부 또는 일부를 수행하라고 명령하는 수개의 명령어를 포함한다. 전술한 저장 매체는 USB 플래시 드라이브, 이동식 하드 디스크, 판독 전용 메모리(read- only memory, ROM), 랜덤 액세스 메모리(random access memory, RAM), 자기 디스크, 또는 광 디스크와 같은, 프로그램 코드를 저장할 수 있는 다양한 매체를 포함한다. 전술한 설명들은 본 출원의 특정 구현들일 뿐이지만, 본 출원의 보호 범위를 제한하도록 의도되지 않는다. 본"}
{"patent_id": "10-2022-7023190", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 11, "content": "출원에 개시되는 기술적 범위 내에서 본 기술분야의 기술자에 의해 쉽게 이해되는 임의의 변형 또는 대체는 본 출원의 보호 범위 내에 있어야 한다. 따라서, 본 출원의 보호 범위는 청구항들의 보호 범위에 종속될 것이다."}
{"patent_id": "10-2022-7023190", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 출원의 실시예에 따른 인공 지능 메인 프레임워크의 개략도이다. 도 2는 본 출원의 실시예에 따른 시스템 아키텍처의 구조의 개략도이다. 도 3은 본 출원의 실시예에 따른 컨볼루션 신경망의 구조의 개략도이다. 도 4는 본 출원의 실시예에 따른 다른 컨볼루션 신경망의 구조의 개략도이다. 도 5는 본 출원의 실시예에 따른 칩의 하드웨어 구조의 개략도이다. 도 6은 본 출원의 실시예에 따른 시스템 아키텍처의 개략도이다. 도 7은 신경망 모델의 자동 업데이트의 개략적인 흐름도이다. 도 8은 신경망 모델에 자동 머신 학습을 적용하는 개략적인 흐름도이다.도 9는 본 출원의 실시예에 따른 신경망 모델 업데이트 방법의 개략적인 흐름도이다. 도 10은 본 출원의 실시예에 따른 신경망 모델 업데이트 장치의 개략적인 블록도이다. 도 11은 본 출원의 실시예에 따른 다른 신경망 모델 업데이트 장치의 개략적인 블록도이다. 도 12는 본 출원의 실시예에 따른 다른 신경망 모델 업데이트 방법의 개략적인 흐름도이다. 도 13은 본 출원의 실시예에 따른 이미지 처리 방법의 개략적인 흐름도이다. 도 14는 본 출원의 실시예에 따른 신경망 모델 업데이트 장치의 개략적인 블록도이다. 도 15는 본 출원의 실시예에 따른 이미지 처리 장치의 개략적인 블록도이다. 도 16은 본 출원의 실시예에 따른 신경망 모델 훈련 장치의 개략적인 블록도이다."}
