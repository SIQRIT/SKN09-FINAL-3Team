{"patent_id": "10-2022-0157371", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0075418", "출원번호": "10-2022-0157371", "발명의 명칭": "시각적 다중 모달리티에 기초하여 수술 단계를 인식하는 방법 및 장치", "출원인": "(주)휴톰", "발명자": "박보규"}}
{"patent_id": "10-2022-0157371", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "장치에 의해 수행되는, 시각적 다중 모달리티(multiple modality)에 기초하여 수술 단계를 인식하는 방법에 있어서, 상기 방법은:복수의 수술 단계에 대응되는 복수의 프레임으로 구성된 수술 영상에 기초하여 복수의 시각적 키네마틱스 기반(visual kinematics-based) 인덱스를 추출하는 단계;상기 수술 영상에 대한 제1 특징 데이터를 획득하고, 상기 복수의 시각적 키네마틱스 기반 인덱스에 대한 제2특징 데이터를 획득하는 단계;데이터를 융합하도록 학습된 융합 모듈(fusion module)을 상기 제1 특징 데이터 및 상기 제2 특징 데이터에 적용함으로써 융합된 제3 특징 데이터를 획득하는 단계; 및상기 제3 특징 데이터에 기초하여 상기 복수의 수술 단계 각각을 인식하도록 제1 인공지능(artificialintelligence, AI) 모델을 학습시키는 단계를 포함하는, 방법."}
{"patent_id": "10-2022-0157371", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 복수의 시각적 키네마틱스 기반 인덱스를 추출하는 단계는,시맨틱 세그멘테이션(semantic segmentation) 알고리즘을 수행하도록 학습된 제2 AI 모델에 상기 복수의 프레임으로 구성된 상기 수술 영상을 입력하여 시맨틱 세그멘테이션 마스크(mask) 데이터를 획득하는 단계; 및상기 시맨틱 세그멘테이션 마스크 데이터 중 상기 수술 영상에 포함된 하나 이상의 수술 도구(surgicalinstrument)에 대응되는 시맨틱 세그멘테이션 마스크 데이터로부터 상기 복수의 시각적 키네마틱스 기반 인덱스를 추출하는 단계를 포함하는, 방법."}
{"patent_id": "10-2022-0157371", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,상기 복수의 시각적 키네마틱스 기반 인덱스는, 상기 하나 이상의 수술 도구의 움직임(movement) 및 상호 관계(interrelationship) 정보를 포함하는, 방법."}
{"patent_id": "10-2022-0157371", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서,상기 제1 특징 데이터 및 상기 제2 특징 데이터를 획득하는 단계는,상기 수술 영상 및 상기 복수의 시각적 키네마틱스 기반 인덱스 각각을 제3 AI 모델에 입력하여 상기 제1 특징데이터 및 상기 제2 특징 데이터를 획득하는 단계를 포함하고,상기 제3 AI 모델은, 트랜스포머(transformer), CNN(convolutional neural network) 모델 및 LSTM(long shortterm memory) 모델 중의 적어도 하나를 포함하는, 방법."}
{"patent_id": "10-2022-0157371", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서,상기 제3 특징 데이터를 획득하는 단계는,상기 제1 특징 데이터 및 상기 제2 특징 데이터를 연결(concatenation)하는 단계; 및상기 연결된 제1 특징 데이터 및 상기 제2 특징 데이터에 대해 상기 융합 모듈을 적용하여 상기 제3 특징 데이공개특허 10-2024-0075418-3-터를 획득하는 단계를 포함하고,상기 융합 모듈은, 다층 퍼셉트론(multi-layer perceptron) 기반 융합 모듈을 포함하는, 방법."}
{"patent_id": "10-2022-0157371", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제4항에 있어서,상기 융합 모듈은,상기 제1 특징 데이터 및 상기 제2 특징 데이터에 대해 스탑-그래디언트(stop-gradient) 알고리즘을 적용하여상기 제1 특징 데이터 및 상기 제2 특징 데이터 간의 상호 작용을 강화하기 위한 강화 데이터를 획득하고,상기 강화 데이터에 대해 컨볼루션(convolution) 연산을 수행하여 상기 제3 특징 데이터를 획득하는, 방법."}
{"patent_id": "10-2022-0157371", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6항에 있어서,상기 복수의 시각적 키네마틱스 기반 인덱스와 관련된 적어도 하나의 수술 도구의 움직임의 경로 및 움직임 패턴에 기초하여, 상기 적어도 하나의 수술 도구의 사용자의 수술 스킬 스코어를 산출하는 단계를 더 포함하는,방법."}
{"patent_id": "10-2022-0157371", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서,상기 제3 특징 데이터에 기초하여 학습된 상기 제1 모델은, 상기 장치에 의해 다른 수술 영상의 특정 프레임이 입력됨에 기반하여, 상기 특정 프레임이 나타내는 수술 단계에 대한 정보를 출력하는, 방법."}
{"patent_id": "10-2022-0157371", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "시각적 다중 모달리티(multiple modality)에 기초하여 수술 단계를 인식하는 장치에 있어서, 상기 장치는:하나 이상의 통신 모듈;하나 이상의 메모리(memory); 및하나 이상의 프로세서를 포함하고,상기 하나 이상의 프로세서는,복수의 수술 단계에 대응되는 복수의 프레임으로 구성된 수술 영상에 기초하여 복수의 시각적 키네마틱스 기반(visual kinematics-based) 인덱스를 추출하고;상기 수술 영상에 대한 제1 특징 데이터를 획득하고, 상기 복수의 시각적 키네마틱스 기반 인덱스에 대한 제2특징 데이터를 획득하고;데이터를 융합하도록 학습된 융합 모듈(fusion module)을 상기 제1 특징 데이터 및 상기 제2 특징 데이터에 적용함으로써 융합된 제3 특징 데이터를 획득하고; 및상기 제3 특징 데이터에 기초하여 상기 복수의 수술 단계 각각을 인식하도록 제1 인공지능(artificialintelligence, AI) 모델을 학습시키도록 설정되는, 장치."}
{"patent_id": "10-2022-0157371", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "하드웨어인 장치와 결합되어, 제1항 내지 제8항 중 어느 한 항의 시각적 다중 모달리티(multiple modality)에기초하여 수술 단계를 인식하는 방법을 실행시키기 위하여 컴퓨터 판독 가능 기록매체에 저장된 컴퓨터 프로그램."}
{"patent_id": "10-2022-0157371", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "시각적 다중 모달리티(multiple modality)에 기초하여 수술 단계를 인식하는 방법 및 장치가 개시된다. 본 개시 의 일 실시예에 따른, 시각적 다중 모달리티(multiple modality)에 기초하여 수술 단계를 인식하는 방법은, 복수 의 수술 단계에 대응되는 복수의 프레임으로 구성된 수술 영상에 기초하여 복수의 시각적 키네마틱스 기반 (visual kinematics-based) 인덱스를 추출하는 단계; 상기 수술 영상에 대한 제1 특징 데이터를 획득하고, 상기 복수의 시각적 키네마틱스 기반 인덱스에 대한 제2 특징 데이터를 획득하는 단계; 데이터를 융합하도록 학습된 융합 모듈(fusion module)을 상기 연결된 제1 특징 데이터 및 상기 제2 특징 데이터에 적용함으로써 융합된 제3 특징 데이터를 획득하는 단계; 및 상기 제3 특징 데이터에 기초하여 상기 복수의 수술 단계 각각을 인식하도록 제1 인공지능(aritificial intelligence, AI) 모델을 학습시키는 단계를 포함할 수 있다."}
{"patent_id": "10-2022-0157371", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 수술 단계를 인식하는 방법 및 장치에 관한 것이다. 보다 상세하게는, 본 개시는 시각적 다중 모달리 티에 기초하여 수술 단계를 인식하는 방법 및 장치에 관한 것이다."}
{"patent_id": "10-2022-0157371", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "수술 단계의 정확한 인식 및 분석은 수술을 진행하는 당사자 간의 효율적인 의사 소통 및 정확한 상황 판단을 야기함으로써, 수술 진행을 최적화 시킬 수 있다. 또한, 수술 단계를 정확히 인식하는 것은 수술 후 환자를 모 니터링할 때 및 일반적인 수술 절차를 분류하여 교육 자료를 제공할 때 유용할 수 있다. 다만, 수술 단계의 인식은 수술 도구, 수술이 진행되고 있는 영역에 포함된 기관, 및 카메라 청소 및 출혈 관리 와 같은 활동의 상호 작용을 포함하고 있는 어려운 작업이다. 기존에는 수술 이미지를 분석하여 수술 단계를 자 동으로 인식하는 기술이 연구되었으나, 수술 단계와 관련된 상술된 상호 작용을 모두 고려하지 못한다는 한계가 존재하였다. 선행기술문헌 특허문헌 (특허문헌 0001) 공개특허공보 KR 10-2020-0096155 (2019.05.13)"}
{"patent_id": "10-2022-0157371", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 개시에 개시된 실시예는 시각적 다중 모달리티에 기초하여 수술 단계를 인식하는 방법 및 장치를 제공하는데 그 목적이 있다. 본 개시가 해결하고자 하는 과제들은 이상에서 언급된 과제로 제한되지 않으며, 언급되지 않은 또 다른 과제들 은 아래의 기재로부터 통상의 기술자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2022-0157371", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 개시의 일 실시예에 따른, 장치에 의해 수행되는, 시각적 다중 모달리티(multiple modality)에 기초하여 수 술 단계를 인식하는 방법에 있어서, 상기 방법은: 복수의 수술 단계에 대응되는 복수의 프레임으로 구성된 수술 영상에 기초하여 복수의 시각적 키네마틱스 기반(visual kinematics-based) 인덱스를 추출하는 단계; 상기 수술 영상에 대한 제1 특징 데이터를 획득하고, 상기 복수의 시각적 키네마틱스 기반 인덱스에 대한 제2 특징 데이터 를 획득하는 단계; 데이터를 융합하도록 학습된 융합 모듈(fusion module)을 상기 제1 특징 데이터 및 상기 제2 특징 데이터에 적용함으로써 융합된 제3 특징 데이터를 획득하는 단계; 및 상기 제3 특징 데이터에 기초하여 상 기 복수의 수술 단계 각각을 인식하도록 제1 인공지능(artificial intelligence, AI) 모델을 학습시키는 단계를 포함할 수 있다. 그리고, 상기 복수의 시각적 키네마틱스 기반 인덱스를 추출하는 단계는, 시맨틱 세그멘테이션(semantic segmentation) 알고리즘을 수행하도록 학습된 제2 AI 모델에 상기 복수의 프레임으로 구성된 상기 수술 영상을 입력하여 시맨틱 세그멘테이션 마스크(mask) 데이터를 획득하는 단계; 및 상기 시맨틱 세그멘테이션 마스크 데 이터 중 상기 수술 영상에 포함된 하나 이상의 수술 도구(surgical instrument)에 대응되는 시맨틱 세그멘테이 션 마스크 데이터로부터 상기 복수의 시각적 키네마틱스 기반 인덱스를 추출하는 단계를 포함할 수 있다. 그리고, 상기 복수의 시각적 키네마틱스 기반 인덱스는, 상기 하나 이상의 수술 도구의 움직임(movement) 및 상 호 관계(interrelationship) 정보를 포함할 수 있다. 그리고, 상기 제1 특징 데이터 및 상기 제2 특징 데이터를 획득하는 단계는, 상기 수술 영상 및 상기 복수의 시 각적 키네마틱스 기반 인덱스 각각을 제3 AI 모델에 입력하여 상기 제1 특징 데이터 및 상기 제2 특징 데이터를 획득하는 단계를 포함하고, 상기 제3 AI 모델은, 트랜스포머(transformer), CNN(convolutional neural network) 모델 및 LSTM(long short term memory) 모델 중의 적어도 하나를 포함할 수 있다.그리고, 상기 제3 특징 데이터를 획득하는 단계는, 상기 제1 특징 데이터 및 상기 제2 특징 데이터를 연결 (concatenation)하는 단계; 및 상기 연결된 제1 특징 데이터 및 상기 제2 특징 데이터에 대해 상기 융합 모듈을 적용하여 상기 제3 특징 데이터를 획득하는 단계를 포함하고, 상기 융합 모듈은, 다층 퍼셉트론(multi-layer perceptron) 기반 융합 모듈을 포함할 수 있다. 그리고, 상기 융합 모듈은, 상기 제1 특징 데이터 및 상기 제2 특징 데이터에 대해 스탑-그래디언트(stop- gradient) 알고리즘을 적용하여 상기 제1 특징 데이터 및 상기 제2 특징 데이터 간의 상호 작용을 강화하기 위 한 강화 데이터를 획득하고, 상기 강화 데이터에 대해 컨볼루션(convolution) 연산을 수행하여 상기 제3 특징 데이터를 획득할 수 있다. 그리고, 상기 방법은, 상기 복수의 시각적 키네마틱스 기반 인덱스와 관련된 적어도 하나의 수술 도구의 움직임 의 경로 및 움직임 패턴에 기초하여, 상기 적어도 하나의 수술 도구의 사용자의 수술 스킬 스코어를 산출하는 단계를 더 포함할 수 있다. 그리고, 상기 제3 특징 데이터에 기초하여 학습된 상기 제1 모델은, 상기 장치에 의해 다른 수술 영상의 특정 프레임이 입력됨에 기반하여, 상기 특정 프레임이 나타내는 수술 단계에 대한 정보를 출력할 수 있다. 본 개시의 또 다른 실시예로, 시각적 다중 모달리티(multiple modality)에 기초하여 수술 단계를 인식하는 장치 는, 하나 이상의 통신 모듈; 하나 이상의 메모리(memory); 및 하나 이상의 프로세서를 포함하고, 상기 하나 이 상의 프로세서는, 복수의 수술 단계에 대응되는 복수의 프레임으로 구성된 수술 영상에 기초하여 복수의 시각적 키네마틱스 기반(visual kinematics-based) 인덱스를 추출하고; 상기 수술 영상에 대한 제1 특징 데이터를 획득 하고, 상기 복수의 시각적 키네마틱스 기반 인덱스에 대한 제2 특징 데이터를 획득하고; 데이터를 융합하도록 학습된 융합 모듈(fusion module)을 상기 연결된 제1 특징 데이터 및 상기 제2 특징 데이터에 적용함으로써 융 합된 제3 특징 데이터를 획득하고; 및 상기 제3 특징 데이터에 기초하여 상기 복수의 수술 단계 각각을 인식하 도록 제1 인공지능(artificial intelligence, AI) 모델을 학습시키도록 설정될 수 있다. 이 외에도, 본 개시를 구현하기 위한 실행하기 위한 컴퓨터 판독 가능한 기록 매체에 저장된 컴퓨터 프로그램이 더 제공될 수 있다. 이 외에도, 본 개시를 구현하기 위한 방법을 실행하기 위한 컴퓨터 프로그램을 기록하는 컴퓨터 판독 가능한 기 록 매체가 더 제공될 수 있다."}
{"patent_id": "10-2022-0157371", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 개시의 전술한 과제 해결 수단에 의하면, 시각적 다중 모달리티에 기초하여 수술 단계를 인식하는 방법 및 장치가 제공될 수 있다. 본 개시의 전술한 과제 해결 수단에 의하면, 수술 진행 상황을 나타내는 이미지 및 수술 동작과 관련된 정보에 기초하여 수술 단계를 보다 정확하게 인식하는 인공지능 모델을 학습시키는 방법 및 장치가 제공될 수 있다. 본 개시의 효과들은 이상에서 언급된 효과로 제한되지 않으며, 언급되지 않은 또 다른 효과들은 아래의 기재로 부터 통상의 기술자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2022-0157371", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 개시 전체에 걸쳐 동일 참조 부호는 동일 구성요소를 지칭한다. 본 개시가 실시예들의 모든 요소들을 설명"}
{"patent_id": "10-2022-0157371", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "하는 것은 아니며, 본 개시가 속하는 기술분야에서 일반적인 내용 또는 실시예들 간에 중복되는 내용은 생략한 다. 명세서에서 사용되는 '부, 모듈, 부재, 블록'이라는 용어는 소프트웨어 또는 하드웨어로 구현될 수 있으며, 실시예들에 따라 복수의 '부, 모듈, 부재, 블록'이 하나의 구성요소로 구현되거나, 하나의 '부, 모듈, 부재, 블 록'이 복수의 구성요소들을 포함하는 것도 가능하다. 명세서 전체에서, 어떤 부분이 다른 부분과 \"연결\"되어 있다고 할 때, 이는 직접적으로 연결되어 있는 경우 뿐 아니라, 간접적으로 연결되어 있는 경우를 포함하고, 간접적인 연결은 무선 통신망을 통해 연결되는 것을 포함 한다. 또한 어떤 부분이 어떤 구성요소를 \"포함\"한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다른 구성요소를 제외하는 것이 아니라 다른 구성요소를 더 포함할 수 있는 것을 의미한다. 명세서 전체에서, 어떤 부재가 다른 부재 \"상에\" 위치하고 있다고 할 때, 이는 어떤 부재가 다른 부재에 접해 있는 경우뿐 아니라 두 부재 사이에 또 다른 부재가 존재하는 경우도 포함한다. 제 1, 제 2 등의 용어는 하나의 구성요소를 다른 구성요소로부터 구별하기 위해 사용되는 것으로, 구성요소가 전술된 용어들에 의해 제한되는 것은 아니다. 단수의 표현은 문맥상 명백하게 예외가 있지 않는 한, 복수의 표현을 포함한다. 각 단계들에 있어 식별부호는 설명의 편의를 위하여 사용되는 것으로 식별부호는 각 단계들의 순서를 설명하는 것이 아니며, 각 단계들은 문맥상 명백하게 특정 순서를 기재하지 않는 이상 명기된 순서와 다르게 실시될 수 있다. 이하 첨부된 도면들을 참고하여 본 개시의 작용 원리 및 실시예들에 대해 설명한다. 본 명세서에서 '본 개시에 따른 장치'는 연산처리를 수행하여 사용자에게 결과를 제공할 수 있는 다양한 장치들 이 모두 포함된다. 예를 들어, 본 개시에 따른 장치는, 컴퓨터, 서버 장치 및 휴대용 단말기를 모두 포함하거나, 또는 어느 하나의 형태가 될 수 있다. 여기에서, 상기 컴퓨터는 예를 들어, 웹 브라우저(WEB Browser)가 탑재된 노트북, 데스크톱(desktop), 랩톱 (laptop), 태블릿 PC, 슬레이트 PC 등을 포함할 수 있다. 상기 서버 장치는 외부 장치와 통신을 수행하여 정보를 처리하는 서버로써, 애플리케이션 서버, 컴퓨팅 서버, 데이터베이스 서버, 파일 서버, 게임 서버, 메일 서버, 프록시 서버 및 웹 서버 등을 포함할 수 있다. 상기 휴대용 단말기는 예를 들어, 휴대성과 이동성이 보장되는 무선 통신 장치로서, PCS(Personal Communication System), GSM(Global System for Mobile communications), PDC(Personal Digital Cellular), PHS(Personal Handyphone System), PDA(Personal Digital Assistant), IMT(International Mobile Telecommunication)-2000, CDMA(Code Division Multiple Access)-2000, W-CDMA(W-Code Division Multiple Access), WiBro(Wireless Broadband Internet) 단말, 스마트 폰(Smart Phone) 등과 같은 모든 종류의 핸드헬드 (Handheld) 기반의 무선 통신 장치와 시계, 반지, 팔찌, 발찌, 목걸이, 안경, 콘택트 렌즈, 또는 머리 착용형 장치(head-mounted-device(HMD) 등과 같은 웨어러블 장치를 포함할 수 있다. 본 개시를 설명함에 있어서, \"사용자\"는 의료 전문가로서 의사, 간호사, 임상 병리사, 의료 영상 전문가 등이 될 수 있으며, 의료 장치를 수리/제어하는 기술자가 될 수 있으나, 이에 한정되지 않는다. 본 개시를 설명함에 있어서, “수술”은 질병이나 외상에 대하여 피부나 점막을 절개하여 시술하는 외과 치료 행위를 통칭하며, “수술 도구”는 수술을 진행하기 위해 이용되는 모든 도구를 통칭할 수 있다. 본 개시를 설명함에 있어서, “시각적 다중 모달리티”는 시각적으로 구현되는 복수의 유형의 데이터(예로, 수 술 영상 데이터 및 시각적 키네마틱스 기반 인덱스 등)를 의미할 수 있다. 도 1은 본 개시의 일 실시예에 따른, 시각적 다중 모달리티(multiple modality)에 기초하여 수술 단계를 인식하 는 방법을 구현하기 위한 시스템의 개략도이다. 도 1에 도시된 바와 같이, 시각적 다중 모달리티에 기초하여 수술 단계를 인식하는 방법을 구현하기 위한 시스 템은, 장치, 병원 서버, 데이터 베이스 및 AI 모델을 포함할 수 있다. 여기서, 도 1에는 장치가 하나의 데스크 탑의 형태로 구현될 것으로 도시되어 있으나, 이에 한정되는 것은 아니다. 장치는 상술한 바와 같이 다양한 유형의 장치 또는 하나 이상의 유형의 장치가 연결된 장치 군을 의미할 수 있다. 시스템에 포함된 장치, 병원 서버, 데이터 베이스, 및 인공 지능(artificial intelligence, AI) 모델은 네트워크(W)를 통해 통신을 수행할 수 있다. 여기서, 네트워크(W)는 유선 네트 워크와 무선 네트워크를 포함할 수 있다. 예를 들어, 네트워크는 근거리 네트워크(LAN: Local Area Network), 도시권 네트워크(MAN: Metropolitan Area Network), 광역 네트워크(WAN: Wide Area Network) 등의 다양한 네트 워크를 포함할 수 있다. 또한, 네트워크(W)는 공지의 월드 와이드 웹(WWW: World Wide Web)을 포함할 수도 있다. 그러나, 본 개시의 실 시예에 따른 네트워크(W)는 상기 열거된 네트워크에 국한되지 않고, 공지의 무선 데이터 네트워크나 공지의 전 화 네트워크, 공지의 유무선 텔레비전 네트워크를 적어도 일부로 포함할 수도 있다. 장치는 병원 서버 또는/및 데이터 베이스를 통해 복수의 수술 단계에 대응되는 복수의 프레임으 로 구성된 수술 영상을 획득할 수 있다. 다만, 이는 일 실시예에 불과하며, 장치는 장치에 무선/유선 으로 연결된 카메라를 통해 촬영되는 수술 영상을 획득할 수 있다. 장치는 수술 영상에 기초하여 복수의 시각적 키네마틱스 기반 인덱스를 추출할 수 있다. 복수의 시각적 키 네마틱스 기반 인덱스는, 수술 영상에 포함된 하나 이상의 수술 도구(surgical instrument)의 움직임(movement) 및 상호 관계(interrelationship) 정보를 포함할 수 있다. 장치는 수술 영상에 대한 제1 특징 데이터 및 복수의 시각적 키네마틱스 기반 인덱스에 대한 제2 특징 데 이터를 융합한 제3 특징 데이터를 획득할 수 있다. 그리고, 장치는 제3 특징 데이터에 기초하여 수술 단계 를 인식하도록 AI 모델을 학습시킬 수 있다. 이와 관련된 동작은 후술하는 도면을 참조하여 구체적으로 설명하도록 한다. 병원 서버(예로, 클라우드 서버 등)는 환자의 수술 영상을 촬영하고 저장할 수 있다. 병원 서버는 장 치, 데이터 베이스, 또는 AI 모델로 저장한 수술 영상을 전송할 수 있다. 병원 서버는 수술 영상의 당사자를 가명화 또는 익명화하여 수술 영상의 당사자의 개인 정보를 보호할 수 있다. 또한, 병원 서버는 사용자에 의해 입력된 수술 영상의 당사자가 되는 환자의 나이/성별/키/몸무게/출산 여부와 관련된 정보를 암호화하여 저장할 수 있다. 데이터 베이스는 장치에 의해 생성된 각종 특징 데이터 및 AI 모델을 활용하기 위한 하나 이상 의 파라미터/인스트럭션(instruction)을 저장할 수 있다. 도 1에서는 데이터 베이스가 장치 외부에 구현된 경우를 도시하고 있으나, 데이터 베이스는 장치의 일 구성 요소로 구현될 수도 있다. AI 모델은 수술 영상을 통해 수술 단계를 인식하도록 학습된 인공지능 모델이다. AI 모델은 실제 수 술 영상과 관련된 특징 데이터로 구축된 데이터 셋을 통해 수술 단계를 인식하도록 학습될 수 있다. 학습 방식 은 지도 학습(supervised training)/비지도 학습(unsupervised training) 등을 포함할 수 있으나, 이에 한정되 는 것은 아니다. AI 모델을 통해 출력된 검출 데이터는 데이터 베이스 또는/및 장치의 메모리에 저장될 수 있다. 도 1은 AI 모델이 장치 외부에 구현(예로, 클라우드 기반(cloud-based)으로 구현)된 경우를 도시하고 있으나, 이에 한정되는 것은 아니며, 장치에 일 구성 요소로 구현될 수 있다. 도 2는 본 개시의 일 실시예에 따른, 시각적 다중 모달리티에 기초하여 수술 단계를 인식하는 방법장치의 구성을 설명하기 위한 블록도이다. 도 2에 도시된 바와 같이, 장치는 메모리, 통신 모듈, 디스플레이, 입력 모듈 및 프 로세서를 포함할 수 있다. 다만, 이에 국한되는 것은 아니며, 장치는 필요한 동작에 따라 당업자 관 점에서 자명한 범위 내에서 소프트웨어 및 하드웨어 구성이 수정/추가/생략될 수 있다. 메모리는 본 장치의 다양한 기능을 지원하는 데이터와, 프로세서의 동작을 위한 프로그램을 저 장할 수 있고, 입/출력되는 데이터들(예를 들어, 복수의 프레임으로 구성된 전체 수술 영상, 하나 이상의 시각 적 키네마틱스 기반 인덱스 등 등)을 저장할 있고, 본 장치에서 구동되는 다수의 응용 프로그램(application program 또는 애플리케이션(application)), 본 장치의 동작을 위한 데이터들, 명령어들을 저장할 수 있다. 이러한 응용 프로그램 중 적어도 일부는, 무선 통신을 통해 외부 서버로부터 다운로드 될 수 있다. 이러한, 메모리는 플래시 메모리 타입(flash memory type), 하드디스크 타입(hard disk type), SSD 타입 (Solid State Disk type), SDD 타입(Silicon Disk Drive type), 멀티미디어 카드 마이크로 타입(multimedia card micro type), 카드 타입의 메모리(예를 들어 SD 또는 XD 메모리 등), 램(random access memory; RAM), SRAM(static random access memory), 롬(read-only memory; ROM), EEPROM(electrically erasable programmable read-only memory), PROM(programmable read-only memory), 자기 메모리, 자기 디스크 및 광디스 크 중 적어도 하나의 타입의 저장매체를 포함할 수 있다. 또한, 메모리는 본 장치와는 분리되어 있으나, 유선 또는 무선으로 연결된 데이터베이스를 포함할 수 있다. 즉, 도 1에 도시된 데이터 베이스는 메모리의 일 구성 요소로 구현될 수 있다. 통신 모듈는 외부 장치와 통신을 가능하게 하는 하나 이상의 구성 요소를 포함할 수 있으며, 예를 들어, 방송 수신 모듈, 유선통신 모듈, 무선통신 모듈, 근거리 통신 모듈, 위치정보 모듈 중 적어도 하나를 포함할 수 있다. 유선 통신 모듈은, 지역 통신(Local Area Network; LAN) 모듈, 광역 통신(Wide Area Network; WAN) 모듈 또는 부가가치 통신(Value Added Network; VAN) 모듈 등 다양한 유선 통신 모듈뿐만 아니라, USB(Universal Serial Bus), HDMI(High Definition Multimedia Interface), DVI(Digital Visual Interface), RS-232(recommended standard232), 전력선 통신, 또는 POTS(plain old telephone service) 등 다양한 케이블 통신 모듈을 포함할 수 있다. 무선 통신 모듈은 와이파이(Wifi) 모듈, 와이브로(Wireless broadband) 모듈 외에도, GSM(global System for Mobile Communication), CDMA(Code Division Multiple Access), WCDMA(Wideband Code Division Multiple Access), UMTS(universal mobile telecommunications system), TDMA(Time Division Multiple Access), LTE(Long Term Evolution), 4G, 5G, 6G 등 다양한 무선 통신 방식을 지원하는 무선 통신 모듈을 포함할 수 있 다. 디스플레이는 본 장치에서 처리되는 정보(예를 들어, 환자의 수술 영상, 수술 영상을 구성하는 특정 프레임에 대응되는 수술 단계 인식 정보, 수술 스킬 스코어(skill score) 등)를 표시(출력)한다. 예를 들어, 디 스플레이는 본 장치에서 구동되는 응용 프로그램(일 예로, 어플리케이션)의 실행화면 정보, 또는 이러한 실행화면 정보에 따른 UI(User Interface), GUI(Graphic User Interface) 정보를 표시할 수 있다. 입력 모듈는 사용자로부터 정보를 입력받기 위한 것으로서, 사용자 입력부를 통해 정보가 입력되면, 프로 세서는 입력된 정보에 대응되도록 본 장치의 동작을 제어할 수 있다. 이러한, 입력 모듈은 하드웨어식 물리 키(예를 들어, 본 장치의 전면, 후면 및 측면 중 적어도 하나에 위 치하는 버튼, 돔 스위치 (dome switch), 조그 휠, 조그 스위치 등) 및 소프트웨어식 터치 키를 포함할 수 있다. 일 예로서, 터치 키는, 소프트웨어적인 처리를 통해 터치스크린 타입의 디스플레이 상에 표시되는 가상 키 (virtual key), 소프트 키(soft key) 또는 비주얼 키(visual key)로 이루어지거나, 상기 터치스크린 이외의 부 분에 배치되는 터치 키(touch key)로 이루어질 수 있다. 한편, 상기 가상키 또는 비주얼 키는, 다양한 형태를 가지면서 터치스크린 상에 표시되는 것이 가능하며, 예를 들어, 그래픽(graphic), 텍스트(text), 아이콘(icon), 비디오(video) 또는 이들의 조합으로 이루어질 수 있다. 프로세서는 장치의 전반적인 동작 및 기능을 제어할 수 있다. 구체적으로, 프로세서는 본 장치 내의 구성요소들의 동작을 제어하기 위한 알고리즘 또는 알고리즘을 재현한 프로그램에 대한 데이터를 저 장하는 메모리, 및 메모리에 저장된 데이터를 이용하여 전술한 동작을 수행하는 적어도 하나의 프로세서(미도시)로 구현될 수 있다. 이때, 메모리와 프로세서는 각각 별개의 칩으로 구현될 수 있다. 또는, 메 모리와 프로세서는 단일 칩으로 구현될 수도 있다.또한, 프로세서는 이하의 도 3 내지 도 7에서 설명되는 본 개시에 따른 다양한 실시 예들을 본 장치 상에서 구현하기 위하여, 위에서 살펴본 구성요소들을 중 어느 하나 또는 복수를 조합하여 제어할 수 있다. 도 3은 본 개시의 일 실시예에 따른, 장치에 의해 수행되는 시각적 다중 모달리티(multiple modality)에 기초하 여 수술 단계를 인식하는 방법을 설명하기 위한 순서도이다. 장치는 복수의 수술 단계에 대응되는 복수의 프레임으로 구성된 수술 영상에 기초하여 복수의 시각적 키네마틱 스 기반 인덱스를 추출할 수 있다(S310). 여기서, 복수의 시각적 키네마틱스 기반 인덱스는, 수술 영상에 포함된 하나 이상의 수술 도구(surgical instrument)의 움직임(movement) 및 상호 관계(interrelationship) 정보를 나타내는 정보를 의미할 수 있다. 구체적으로, 장치는 시맨틱 세그멘테이션(semantic segmentation) 알고리즘을 수행하도록 학습된 제2 AI 모델에 복수의 프레임으로 구성된 수술 영상을 입력하여 시맨틱 세그멘테이션 마스크(mask) 데이터를 획득할 수 있다. 장치는 시맨틱 세그멘테이션 마스크 데이터로부터 복수의 시각적 키네마틱스 기반 인덱스를 추출할 수 있다. 여기서, 시맨틱 세그멘테이션 알고리즘은 영상(또는, 영상을 구성하는 복수의 프레임/이미지)의 모든 픽셀을 미 리 지정된 개수의 클래스로 분류하는 알고리즘을 의미한다. 시맨틱 세그멘테이션 알고리즘은 영상(또는, 영상을 구성하는 복수의 프레임/이미지)에서 수술 대상인 하나 이상의 신체 기관(organ)과 수술 도구를 구분/분류/식별 하고, 구분/분류/식별된 픽셀 영역을 마스킹(masking)할 수 있다. 따라서, 시맨틱 세그멘테이션 마스크 데이터는 영상(또는, 영상을 구성하는 복수의 프레임/이미지)에서 신체 기 관 및 수술 도구로 분류된 픽셀 영역을 마스킹한 데이터를 의미할 수 있다. 장치는 시맨틱 세그멘테이션 마스크 데이터 중 수술 영상에 포함된 하나 이상의 수술 도구에 대응되는 시맨틱 세그멘테이션 마스크 데이터로부터 복수의 시각적 키네마틱스 기반 인덱스를 추출할 수 있다. 구체적으로, 장치는 하나 이상의 수술 도구에 대응되는 시맨틱 세그멘테이션 마스트 데이터를 통해 수술 도구의 움직임과 관련된 특징 데이터를 추출할 수 있다. 장치는 추출된 수술 도구의 움직임과 관련된 특징 데이터를 통 해 복수의 시각적 키네마틱스 기반 인덱스를 추출할 수 있다. 도 4를 참조하면, 장치는 수술 영상을 구성하는 복수의 수술 단계를 나타내는 복수의 프레임(400-1, 400-2, … 400-N)(N은 1 이상의 자연수)을 획득할 수 있다. 여기서, 수술 영상은 전체 수술 과정을 나타내는 프레임으로 구성될 수 있으나, 이에 제한되는 것은 아니다. 일 예로, 도 5에 도시된 바와 같이, 수술이 복수의 과정(예로, 20 가지의 과정)으로 구분될 수 있으며, 장치는 전체 과정 별로 촬영한 영상을 획득할 수 있다. 도 4에 도시된 복수의 프레임(400-1, 400-2, …400-N)은 각 과 정 별로 촬영한 영상을 구성하는 프레임을 의미할 수 있다. 장치는 복수의 프레임(400-1, 400-2, …400-N)을 시각적 키네마틱 기반 인덱스 추출기(extractor)에 입력 하여 복수의 시각적 키네마틱 기반 인덱스(λ1, λ2 ..., λN)를 획득할 수 있다. 여기서, 시각적 키네마틱 기반 인덱스 추출기는 시맨틱 세그멘테이션 알고리즘을 수행하도록 학습된 제2 AI 모델을 포함할 수 있다. 장치는 복수의 프레임(400-1, 400-2, …400-N)을 제2 AI 모델에 입력하여 하나 이상의 수술 도구에 대응되 는 시맨틱 세그멘테이션 데이터(420-1, 420-2, …420-N)를 획득할 수 있다. 장치는 하나 이상의 수술 도구에 대 응되는 시맨틱 세그멘테이션 데이터(420-1, 420-2, …420-N)를 통해 복수의 시각적 키네마틱 기반 인덱스(λ1, λ2 ..., λN)를 획득할 수 있다. 시각적 키네마틱 기반 인덱스는 수술 도구의 움직임 또는 수술 도구 간의 관계에 기초하여 유형이 구분될 수 있 다. 수술 도구의 움직임은 경로 길이(path length), 속력(speed), 무게중심(centroid), 속도(velocity), 바운 딩 박스, 및 EOA(economy of area)로서 측정될 수 있다. (수술 도구의) 움직임 인덱스 측정은 수학식 1 내지 수학식 3과 같이 구현될 수 있다. 수학식 1"}
{"patent_id": "10-2022-0157371", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "수학식 2"}
{"patent_id": "10-2022-0157371", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "수학식 3"}
{"patent_id": "10-2022-0157371", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "여기서, PL은 현재 시간 프레임(t)에서 경로 길이를 나타내며, T는 인덱스의 계산(computing)을 위한 시간 범위 (time range)를 나타낼 수 있다. 경로 길이는 누적 경로(cumulative path length) 및 부분 경로 길이(partial path length)로 구성될 수 있다. D(x, t)는 이전 시간 프레임 및 현재 시간 프레임 내에서 x 축의 차이를 측정할 수 있다. x 및 y는 프레임 내의 객체의 무게 중심을 나타낼 수 있다. 무게 중심은 시맨틱 세그멘테이션 마스크의 x 및 y 좌표에서의 평균 위치 값을 나타낸다. s는 시간 범위 T에 대한 속도이고, v는 시간격 △에서 X 또는 Y 방향에서의 속도를 나타낼 수 있다. bw 및 bh 각각은 바운딩 박스(bounding box)의 너비 및 높이이고, W 및 H 각각은 이미지의 너비 및 높이 이다. 바운딩 박스는 네 개의 값(top, left, box width, box height (bx, by, bw, bh))로 구성될 수 있다. 장치는 수술 영상에 대한 제1 특징 데이터를 획득하고, 복수의 시각적 키네마틱스 기반 인덱스에 대한 제2 특징 데이터를 획득할 수 있다(S320). 구체적으로, 장치는 수술 영상 및 복수의 시각적 키네마틱스 기반 인덱스 각각을 제3 AI 모델에 입력하여 제1 특징 데이터 및 제2 특징 데이터를 획득할 수 있다. 여기서, 제3 AI 모델은, CNN(convolutional neural network) 모델 및 LSTM(long short term memory) 모델 중의 적어도 하나에 기초하여 구성될 수 있다. CNN 모델은 컨볼루션 연산을 수행하도록 학습된 신경망 모델의 구조를 의미하며, LSTM 모델은 RNN(recurrent neural network) 모델이 현재 출력되고 있는 데이터와 먼 위치에 있는 정보를 기억할 수 없다는 단점을 보완하 여 장/단기 기억을 가능하게 설계한 신경망 모델의 구조를 의미한다. 도 4를 참조하면, 장치는 수술 영상(즉, 수술 영상을 구성하는 복수의 프레임) (400-1, 400-2, …400-N) 및 복 수의 시각적 키네마틱 기반 인덱스(λ1, λ2 ..., λN) 각각을 제3 AI 모델에 입력하여 제1 특징 데이터 및 제2 특징 데이터를 획득할 수 있다. 도 4는 수술 영상(즉, 수술 영상을 구성하는 복수의 프레임) (400-1, 400-2, …400-N) 및 복수의 시각적 키네마 틱 기반 인덱스(λ1, λ2 ..., λN) 각각이 입력하는 AI 모델은 동일한 경우를 예시하고 있다. 다만, 이는 일 실 시예에 불과하며, 수술 영상(즉, 수술 영상을 구성하는 복수의 프레임) (400-1, 400-2, …400-N) 및 복수의 시 각적 키네마틱스 기반 인덱스(λ1, λ2 ..., λN)이 입력되는 모델은 상이할 수 있다. 일 예로, 제1 특징 데이터는 수술 영상을 구성하는 복수의 프레임에서 특정 객체(예로, 수술이 진행되는 신체 장기 또는 수술 도구)와 관련된 특징 데이터를 포함할 수 있다. 제2 특징 데이터는 수술 도구의 움직임 패턴 등을 포함할 수 있다. 본 개시의 또 다른 실시예로, 복수의 시각적 키네마틱스 기반 인덱스와 관련된 적어도 하나의 수술 도구의 움직 임의 경로 및 움직임 패턴에 기초하여 상기 적어도 하나의 수술 도구의 사용자의 수술 스킬 스코어를 산출할 수 있다. 장치는 미리 정의된 수술 도구의 경로 및 움직임 패턴에 기초하여 수술 스킬을 산출하도록 학습된 모듈을 활용할 수 있다. 장치는 수술 스킬 스코어에 따라 수술 도구 사용자가 초보자(novice)인지, 숙련되었는지, 전문 가인지 여부를 판단할 수 있다. 장치는 데이터를 융합하도록 학습된 융합 모듈을 제1 특징 데이터 및 제2 특징 데이터에 적용함으로써 융합된 제3 특징 데이터를 획득할 수 있다(S330). 도 4를 참조하면, 장치는 제1 특징 데이터 및 제2 특징 데이터에 대해 융합 모듈을 적용하여 제3 특징 데 이터를 획득할 수 있다. 장치는 각 특징 데이터를 연결(concatenation)하고, 연결된 특징 데이터에 대해 컨볼루 션 연산을 수행하여 제3 특징 데이터를 획득할 수 있다. 일 예시로, 도 6의 (a)를 참조하면, 장치는 제1 특징 데이터 및 제2 특징 데이터를 연결(concatenation)할 수 있다. 장치는 연결된 제1 특징 데이터 및 제2 특징 데이터에 대해 융합 모듈을 적용하여 융합된 제3 특징 데이 터를 획득할 수 있다. 여기서, 융합 모듈은, 다층 퍼셉트론(multi-layer perceptron, MLP)에 기초하여 구성될 수 있다. 또 다른 예로, 도 6의 (b)를 참조하면, 융합 모듈은, 장치 제어에 의해, 제1 특징 데이터 및 제2 특징 데이터에 대해 스탑-그래디언트(stop-gradient) 알고리즘을 적용하여 상기 제1 특징 데이터 및 상기 제2 특징 데이터 간 의 상호 작용을 강화하기 위한 강화 데이터를 획득할 수 있다. 그리고, 융합 모듈은, 장치 제어에 의해, 강화 데이터에 대해 컨볼루션(convolution) 연산을 수행하여 제3 특징 데이터를 획득할 수 있다. 제1 특징 데이터 및 제2 특징 데이터에 대해 스탑-그래디언트 알고리즘을적용하기 위하여, 장치는 수학식 4 내 지 6을 활용하여 대조 오차(contrastive loss)를 획득할 수 있다. 장치는 대조 오차를 활용하여 특징 데이터 간 의 유사도를 식별/학습할 수 있다. 수학식 4"}
{"patent_id": "10-2022-0157371", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "수학식 5"}
{"patent_id": "10-2022-0157371", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 7, "content": "수학식 6"}
{"patent_id": "10-2022-0157371", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 8, "content": "여기서, 및 각각은 제1 특징 데이터 및 제2 특징 데이터를 의미할 수 있다. 그리고, MLP로 구성된 프 로젝터를 통해 도일한 차원과 다른 시각(view)을 가지는 가 생성될 수 있다. ai 및 bi 각각은 다른 시각의 특 징 데이터를 의미하고, p는 수직 벡터(norm)의 순서를 나타내고, m1 및 m2 각각은 수술 영상 및 시각적 키네마틱 스 기반 인덱스를 의미할 수 있다. 그리고, 장치는 상기 제1 특징 데이터 및 상기 제2 특징 데이터 간의 상호 작용을 강화하기 위한 강화데이터에 대해 컨볼루션(convolution) 연산을 수행하여 제3 특징 데이터를 획득할 수 있다. 장치는 제3 특징 데이터에 기초하여 복수의 수술 단계 각각을 인식하도록 제1 AI 모델을 학습시킬 수 있다 (S340). 즉, 임의의 수술 영상의 특정 프레임이 입력되는 경우, 제1 AI 모델은 특정 프레임이 나타내는 수술 단계에 대 한 정보(즉, 수술 단계를 구분하기 위한 정보)를 출력하도록 제1 AI 모델이 장치에 의해 학습될 수 있다. 도 7을 참조하면, 장치는 7개의 수술 단계를 나타내는 프레임으로 구성된 수술 영상을 제1 AI 모델에 입력할 수 있다. 수술 영상 중 제1 프레임 및 제2 프레임이 재생/선택되는 경우, 제1 AI 모델은 각 프레임에 대 응되는 수술 단계로서 calot triangle dissection 및 gallbladder dissection을 출력하도록 학습될 수 있다. 한편, 개시된 실시예들은 컴퓨터에 의해 실행 가능한 명령어를 저장하는 기록매체의 형태로 구현될 수 있다. 명 령어는 프로그램 코드의 형태로 저장될 수 있으며, 프로세서에 의해 실행되었을 때, 프로그램 모듈을 생성하여 개시된 실시예들의 동작을 수행할 수 있다. 기록매체는 컴퓨터로 읽을 수 있는 기록매체로 구현될 수 있다. 컴퓨터가 읽을 수 있는 기록매체로는 컴퓨터에 의하여 해독될 수 있는 명령어가 저장된 모든 종류의 기록 매체 를 포함한다. 예를 들어, ROM(Read Only Memory), RAM(Random Access Memory), 자기 테이프, 자기 디스크, 플 래쉬 메모리, 광 데이터 저장장치 등이 있을 수 있다."}
{"patent_id": "10-2022-0157371", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 9, "content": "이상에서와 같이 첨부된 도면을 참조하여 개시된 실시예들을 설명하였다. 본 개시가 속하는 기술분야에서 통상 의 지식을 가진 자는 본 개시의 기술적 사상이나 필수적인 특징을 변경하지 않고도, 개시된 실시예들과 다른 형 태로 본 개시가 실시될 수 있음을 이해할 것이다. 개시된 실시예들은 예시적인 것이며, 한정적으로 해석되어서 는 안 된다."}
{"patent_id": "10-2022-0157371", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 개시의 일 실시예에 따른, 시각적 다중 모달리티(multiple modality)에 기초하여 수술 단계를 인식하 는 방법을 구현하기 위한 시스템의 개략도이다. 도 2는 본 개시의 일 실시예에 따른, 시각적 다중 모달리티(multiple modality)에 기초하여 수술 단계를 인식하 는 장치의 구성을 설명하기 위한 블록도이다. 도 3은 본 개시의 일 실시예에 따른, 시각적 다중 모달리티(multiple modality)에 기초하여 수술 단계를 인식 하는 방법을 설명하기 위한 순서도이다. 도 4는 시각적 다중 모달리티(multiple modality)에 기초하여 수술 단계를 인식하는 방법의 전체 구조를 나타내 는 도면이다. 도 5는 본 개시의 일 실시예에 따른, 수술 단계를 인식하기 위하여 수술 영상에 대한 특징 데이터를 추출하는 과정을 설명하기 위한 도면이다.도 6은 본 개시의 일 실시예에 따른, 융합 모듈을 통해 제3 특징 데이터를 추출하는 과정을 설명하기 위한 도면 이다. 도 7은 본 개시의 일 실시예에 따른, 장치가 학습된 AI 모델을 통해 수술 단계를 인식하는 과정을 설명하기 위 한 도면이다."}
