{"patent_id": "10-2021-0154333", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0068215", "출원번호": "10-2021-0154333", "발명의 명칭": "인공지능 모델, 인공지능 모델의 트레이닝 장치 및 인공지능 모델의 복제 방지 방법", "출원인": "주식회사 케이티", "발명자": "백성복"}}
{"patent_id": "10-2021-0154333", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "인공지능 모델을 포함하는 메모리; 및시계열적 데이터 집합들을 포함하는 트리거 시퀀스 데이터가 인공지능 모델에 입력되는 경우 상기 인공지능 모델에 포함되는 순환 신경망이 복제 방지 값을 출력하도록 상기 순환 신경망을 트레이닝 하고, 상기 순환 신경망의 트레이닝이 완료되면 상기 순환 신경망의 가중치를 고정시키고, 상기 순환 신경망의 가중치가 고정된 상태에서, 트레이닝 데이터를 이용하여 상기 인공지능 모델을 트레이닝 하는 제어부;를 포함하는인공지능 모델의 트레이닝 장치."}
{"patent_id": "10-2021-0154333", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1항에 있어서,상기 트리거 시퀀스 데이터는, 트리거 암호를 포함하고,상기 트리거 암호는,상기 시계열적 데이터 집합들 내 동일 위치의 요소가 시계열적으로 연결된 데이터인인공지능 모델의 트레이닝 장치."}
{"patent_id": "10-2021-0154333", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 2항에 있어서, 상기 순환 신경망에 포함되는 복수의 노드는, 상기 인공지능 모델 내 복수의 레이어에 배치되며, 상기 복수의 노드 중 시작 노드로부터 상기 복수의 노드 중끝 노드까지 끊김 없이 연결되는인공지능 모델의 트레이닝 장치."}
{"patent_id": "10-2021-0154333", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 3항에 있어서, 상기 시작 노드는, 상기 인공지능 모델의 입력 레이어에 배치되고,상기 입력 레이어에서의 상기 시작 노드의 위치는, 상기 시계열적 데이터 집합들에서 상기 트리거 암호가 배치되는 위치와 동일한인공지능 모델의 트레이닝 장치."}
{"patent_id": "10-2021-0154333", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제 3항에 있어서,상기 제어부는,상기 순환 신경망의 트레이닝이 완료되면, 상기 순환 신경망에 포함되는 노드 간 가중치를 고정시키고,상기 트리거 시퀀스 데이터 이외의 정상 데이터가 상기 인공지능 모델에 입력되는 경우에 상기 순환 신경망이출력하는 초기 값을 설정하는인공지능 모델의 트레이닝 장치."}
{"patent_id": "10-2021-0154333", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "공개특허 10-2023-0068215-3-제 5항에 있어서,상기 순환 신경망은,상기 트리거 시퀀스 데이터가 상기 인공지능 모델에 입력되면 상기 복제 방지 값을 출력하고,상기 트리거 시퀀스 데이터가 입력된 이후 상기 인공지능 모델에 정상 데이터가 입력되면, 상기 복제 방지 값의출력을 유지하는인공지능 모델의 트레이닝 장치."}
{"patent_id": "10-2021-0154333", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제 6항에 있어서,상기 순환 신경망은,상기 트리거 시퀀스 데이터가 상기 인공지능 모델에 입력됨에 따라 복제 탐지 값을 출력하는 복제 탐지부; 및상기 순환 신경망의 말단에 배치되고, 상기 복제 탐지부로부터 상기 복제 탐지 값이 수신되면 상기 복제 방지값을 출력하는 누적부;를 포함하는인공지능 모델의 트레이닝 장치."}
{"patent_id": "10-2021-0154333", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "시계열적 데이터 집합들을 포함하는 트리거 시퀀스 데이터가 인공지능 모델에 입력되는 경우 상기 인공지능 모델에 포함되는 순환 신경망이 복제 방지 값을 출력하도록, 상기 순환 신경망을 트레이닝 하는 단계;상기 순환 신경망의 트레이닝이 완료되면, 상기 순환 신경망의 가중치를 고정시키는 단계; 및상기 순환 신경망의 가중치가 고정된 상태에서, 트레이닝 데이터를 이용하여 상기 인공지능 모델을 트레이닝 하는 단계;를 포함하는인공지능 모델의 복제 방지 방법."}
{"patent_id": "10-2021-0154333", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제 8항에 있어서,상기 트리거 시퀀스 데이터는, 트리거 암호를 포함하고,상기 트리거 암호는,상기 시계열적 데이터 집합들 내 동일 위치의 요소가 시계열적으로 연결된 데이터인인공지능 모델의 복제 방지 방법."}
{"patent_id": "10-2021-0154333", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제 9항에 있어서, 상기 순환 신경망에 포함되는 복수의 노드는, 상기 인공지능 모델 내 복수의 레이어에 배치되며, 상기 복수의 노드 중 시작 노드로부터 끝 노드까지 끊김 없이 연결되는인공지능 모델의 복제 방지 방법."}
{"patent_id": "10-2021-0154333", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제 10항에 있어서, 상기 시작 노드는, 상기 인공지능 모델의 입력 레이어에 배치되고,상기 입력 레이어에서의 상기 시작 노드의 위치는, 상기 시계열적 데이터 집합들에서 상기 트리거 암호가 배치공개특허 10-2023-0068215-4-되는 위치와 동일한인공지능 모델의 복제 방지 방법."}
{"patent_id": "10-2021-0154333", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제 10항에 있어서,상기 순환 신경망의 가중치를 고정시키는 단계는,상기 순환 신경망의 트레이닝이 완료되면, 상기 순환 신경망에 포함되는 노드 간 가중치를 고정시키는 단계; 및상기 트리거 시퀀스 데이터 이외의 정상 데이터가 상기 인공지능 모델에 입력되는 경우에 상기 순환 신경망이출력하는 초기 값을 설정하는 단계;를 포함하는인공지능 모델의 복제 방지 방법."}
{"patent_id": "10-2021-0154333", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제 12항에 있어서,상기 순환 신경망은,상기 트리거 시퀀스 데이터가 상기 인공지능 모델에 입력되면 상기 복제 방지 값을 출력하고,상기 트리거 시퀀스 데이터가 입력된 이후 상기 인공지능 모델에 정상 데이터가 입력되면, 상기 복제 방지 값의출력을 유지하는인공지능 모델의 복제 방지 방법."}
{"patent_id": "10-2021-0154333", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제 13항에 있어서,상기 순환 신경망은,상기 트리거 시퀀스 데이터가 상기 인공지능 모델에 입력됨에 따라 복제 탐지 값을 출력하는 복제 탐지부; 및상기 순환 신경망의 말단에 배치되고, 상기 복제 탐지부로부터 상기 복제 탐지 값이 수신되면 상기 복제 방지값을 출력하는 누적부;를 포함하는인공지능 모델의 복제 방지 방법."}
{"patent_id": "10-2021-0154333", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "정상 데이터가 입력되는 경우 상기 정상 데이터에 기반한 예측 값을 출력하는 인공지능 모델에 있어서,시계열적 데이터 집합들을 포함하는 트리거 시퀀스 데이터가 상기 인공지능 모델에 입력되는 경우 복제 방지 값을 출력하도록 트레이닝된 순환 신경망;을 포함하고,상기 순환 신경망은,상기 트리거 시퀀스 데이터 이외의 상기 정상 데이터가 상기 인공지능 모델에 입력되면 초기 값을 출력하고,상기 트리거 시퀀스 데이터가 상기 인공지능 모델에 입력되면 상기 복제 방지 값을 출력하는인공지능 모델."}
{"patent_id": "10-2021-0154333", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제 15항에 있어서,상기 트리거 시퀀스 데이터는, 트리거 암호를 포함하고,상기 트리거 암호는,상기 시계열적 데이터 집합들 내 동일 위치의 요소가 시계열적으로 연결된 데이터인공개특허 10-2023-0068215-5-인공지능 모델."}
{"patent_id": "10-2021-0154333", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제 16항에 있어서,상기 순환 신경망에 포함되는 복수의 노드는, 상기 인공지능 모델 내 복수의 레이어에 배치되며, 상기 복수의 노드 중 시작 노드로부터 상기 복수의 노드 중끝 노드까지 끊김 없이 연결되는인공지능 모델."}
{"patent_id": "10-2021-0154333", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제 17항에 있어서,상기 시작 노드는, 상기 인공지능 모델의 입력 레이어에 배치되고,상기 입력 레이어에서의 상기 시작 노드의 위치는, 상기 시계열적 데이터 집합들에서 상기 트리거 암호가 배치되는 위치와 동일한인공지능 모델."}
{"patent_id": "10-2021-0154333", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제 15항에 있어서,상기 순환 신경망은,상기 트리거 시퀀스 데이터가 상기 인공지능 모델에 입력됨에 따라 복제 탐지 값을 출력하는 복제 탐지부; 및상기 순환 신경망의 말단에 배치되고, 상기 복제 탐지부로부터 상기 복제 탐지 값이 수신되면 상기 복제 방지값을 출력하는 누적부;를 포함하는인공지능 모델."}
{"patent_id": "10-2021-0154333", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "인공지능 모델의 트레이닝 장치가 개시된다. 본 발명에 따른 인공지능 모델의 트레이닝 장치는, 인공지능 모델을 포함하는 메모리, 및, 시계열적 데이터 집합들을 포함하는 트리거 시퀀스 데이터가 인공지능 모델에 입력되는 경 우 상기 인공지능 모델에 포함되는 순환 신경망이 복제 방지 값을 출력하도록 상기 순환 신경망을 트레이닝 하고, 상기 순환 신경망의 트레이닝이 완료되면 상기 순환 신경망의 가중치를 고정시키고, 상기 순환 신경망의 가중치가 고정된 상태에서, 트레이닝 데이터를 이용하여 상기 인공지능 모델을 트레이닝 하는 제어부를 포함한다."}
{"patent_id": "10-2021-0154333", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은, 트리거 시퀀스 데이터가 입력되는 경우, 인공지능 모델 내 삽입된 순환 신경망의 동작에 의해 인공 지능 모델의 기능을 훼손시킬 수 있는, 인공지능 모델, 인공지능 모델의 트레이닝 장치 및 인공지능 모델의 복 제 방지 방법에 관한 것이다."}
{"patent_id": "10-2021-0154333", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "인공 신경망을 포함하는 인공지능 모델을 생성하는 것은 많은 자원이 투입되는 작업이다. 구체적으로, GPU, 메모리, 디스크 등의 컴퓨팅 자원이 준비되어야 하고, 인공지능 모델의 구조가 복잡해질수록 긴 시간의 학습이 필요하다. 특히 신경망의 트레이닝을 위해서는 다량의 트레이닝 데이터가 필요한데, 이는 특 정 기관이나 단체가 해당 모델을 생성할 수 있는 능력이 있는지의 여부를 결정할 수 있는 중요한 요소가 된다. 이와 같이 인공지능 모델의 생성을 위해서는 많은 노력 및 자원의 투입이 필요한데 반해, 인공지능 모델의 복제 는 그리 어렵지 않다는 문제가 있다. 또한, 인공지능 모델의 불법 복제 방지를 위한 기존의 방식은 주로, 인공지능 모델 내에 워터마크를 생성하는 레이어를 추가시킴으로써, 인공지능 모델의 출력 값이 워터마크 생성 레이어에서 만들어낸 워터마크를 포함하도 록 하는 방식이다. 다만 이러한 방식은, 인공지능 모델을 열어봐야 하고, 인공지능 모델을 열어보기 위한 법적 절차나 사전 준비 등이 필요하며, 인공지능 모델 소유권자의 워터마크를 확인하여 인공지능 모델의 소유권을 간 접적으로 증명하는데 불과하다는 문제가 있다."}
{"patent_id": "10-2021-0154333", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 2, "content": "발명의 내용"}
{"patent_id": "10-2021-0154333", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 상술한 문제점을 해결하기 위한 것으로, 본 발명의 목적은, 트리거 시퀀스 데이터가 입력되는 경우, 인공지능 모델 내 삽입된 순환 신경망의 동작에 의해 인공지능 모델의 기능을 훼손시킬 수 있는, 인공지능 모델, 인공지능 모델의 트레이닝 장치 및 인공지능 모델의 복제 방지 방법을 제공하기 위함이다."}
{"patent_id": "10-2021-0154333", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명에 따른 인공지능 모델의 트레이닝 장치는, 인공지능 모델을 포함하는 메모리, 및, 시계열적 데이터 집 합들을 포함하는 트리거 시퀀스 데이터가 인공지능 모델에 입력되는 경우 상기 인공지능 모델에 포함되는 순환 신경망이 복제 방지 값을 출력하도록 상기 순환 신경망을 트레이닝 하고, 상기 순환 신경망의 트레이닝이 완료 되면 상기 순환 신경망의 가중치를 고정시키고, 상기 순환 신경망의 가중치가 고정된 상태에서, 트레이닝 데이 터를 이용하여 상기 인공지능 모델을 트레이닝 하는 제어부를 포함한다. 이 경우 상기 트리거 시퀀스 데이터는, 트리거 암호를 포함하고, 상기 트리거 암호는, 상기 시계열적 데이터 집 합들 내 동일 위치의 요소가 시계열적으로 연결된 데이터일 수 있다. 이 경우 상기 순환 신경망에 포함되는 복수의 노드는, 상기 인공지능 모델 내 복수의 레이어에 배치되며, 상기 복수의 노드 중 시작 노드로부터 상기 복수의 노드 중 끝 노드까지 끊김 없이 연결될 수 있다. 이 경우 상기 시작 노드는, 상기 인공지능 모델의 입력 레이어에 배치되고, 상기 입력 레이어에서의 상기 시작 노드의 위치는, 상기 시계열적 데이터 집합들에서 상기 트리거 암호가 배치되는 위치와 동일할 수 있다. 한편 상기 제어부는, 상기 순환 신경망의 트레이닝이 완료되면, 상기 순환 신경망에 포함되는 노드 간 가중치를 고정시키고, 상기 트리거 시퀀스 데이터 이외의 정상 데이터가 상기 인공지능 모델에 입력되는 경우에 상기 순 환 신경망이 출력하는 초기 값을 설정할 수 있다. 이 경우 상기 순환 신경망은, 상기 트리거 시퀀스 데이터가 상기 인공지능 모델에 입력되면 상기 복제 방지 값 을 출력하고, 상기 트리거 시퀀스 데이터가 입력된 이후 상기 인공지능 모델에 정상 데이터가 입력되면, 상기 복제 방지 값의 출력을 유지할 수 있다. 이 경우 상기 순환 신경망은, 상기 트리거 시퀀스 데이터가 상기 인공지능 모델에 입력됨에 따라 복제 탐지 값 을 출력하는 복제 탐지부, 및, 상기 순환 신경망의 말단에 배치되고, 상기 복제 탐지부로부터 상기 복제 탐지 값이 수신되면 상기 복제 방지 값을 출력하는 누적부를 포함할 수 있다. 한편 본 발명에 따른 인공지능 모델의 복제 방지 방법은, 시계열적 데이터 집합들을 포함하는 트리거 시퀀스 데 이터가 인공지능 모델에 입력되는 경우 상기 인공지능 모델에 포함되는 순환 신경망이 복제 방지 값을 출력하도 록, 상기 순환 신경망을 트레이닝 하는 단계, 상기 순환 신경망의 트레이닝이 완료되면, 상기 순환 신경망의 가 중치를 고정시키는 단계, 및, 상기 순환 신경망의 가중치가 고정된 상태에서, 트레이닝 데이터를 이용하여 상기 인공지능 모델을 트레이닝 하는 단계를 포함한다. 이 경우 상기 트리거 시퀀스 데이터는, 트리거 암호를 포함하고, 상기 트리거 암호는, 상기 시계열적 데이터 집 합들 내 동일 위치의 요소가 시계열적으로 연결된 데이터일 수 있다. 이 경우 상기 순환 신경망에 포함되는 복수의 노드는, 상기 인공지능 모델 내 복수의 레이어에 배치되며, 상기 복수의 노드 중 시작 노드로부터 끝 노드까지 끊김 없이 연결될 수 있다. 이 경우 상기 시작 노드는, 상기 인공지능 모델의 입력 레이어에 배치되고, 상기 입력 레이어에서의 상기 시작 노드의 위치는, 상기 시계열적 데이터 집합들에서 상기 트리거 암호가 배치되는 위치와 동일할 수 있다. 한편 상기 순환 신경망의 가중치를 고정시키는 단계는, 상기 순환 신경망의 트레이닝이 완료되면, 상기 순환 신 경망에 포함되는 노드 간 가중치를 고정시키는 단계, 및, 상기 트리거 시퀀스 데이터 이외의 정상 데이터가 상 기 인공지능 모델에 입력되는 경우에 상기 순환 신경망이 출력하는 초기 값을 설정하는 단계를 포함할 수 있다. 이 경우 상기 순환 신경망은, 상기 트리거 시퀀스 데이터가 상기 인공지능 모델에 입력되면 상기 복제 방지 값 을 출력하고, 상기 트리거 시퀀스 데이터가 입력된 이후 상기 인공지능 모델에 정상 데이터가 입력되면, 상기 복제 방지 값의 출력을 유지할 수 있다. 이 경우 상기 순환 신경망은, 상기 트리거 시퀀스 데이터가 상기 인공지능 모델에 입력됨에 따라 복제 탐지 값 을 출력하는 복제 탐지부, 및, 상기 순환 신경망의 말단에 배치되고, 상기 복제 탐지부로부터 상기 복제 탐지 값이 수신되면 상기 복제 방지 값을 출력하는 누적부를 포함할 수 있다. 한편 정상 데이터가 입력되는 경우 상기 정상 데이터에 기반한 예측 값을 출력하는 인공지능 모델에 있어서, 상 기 인공지능 모델은 시계열적 데이터 집합들을 포함하는 트리거 시퀀스 데이터가 상기 인공지능 모델에 입력되 는 경우 복제 방지 값을 출력하도록 트레이닝된 순환 신경망을 포함하고, 상기 순환 신경망은, 상기 트리거 시 퀀스 데이터 이외의 상기 정상 데이터가 상기 인공지능 모델에 입력되면 초기 값을 출력하고, 상기 트리거 시퀀 스 데이터가 상기 인공지능 모델에 입력되면 상기 복제 방지 값을 출력한다. 이 경우 상기 트리거 시퀀스 데이터는, 트리거 암호를 포함하고, 상기 트리거 암호는, 상기 시계열적 데이터 집 합들 내 동일 위치의 요소가 시계열적으로 연결된 데이터일 수 있다. 이 경우 상기 순환 신경망에 포함되는 복수의 노드는, 상기 인공지능 모델 내 복수의 레이어에 배치되며, 상기 복수의 노드 중 시작 노드로부터 상기 복수의 노드 중 끝 노드까지 끊김 없이 연결될 수 있다. 이 경우 상기 시작 노드는, 상기 인공지능 모델의 입력 레이어에 배치되고, 상기 입력 레이어에서의 상기 시작 노드의 위치는, 상기 시계열적 데이터 집합들에서 상기 트리거 암호가 배치되는 위치와 동일할 수 있다. 한편 상기 순환 신경망은, 상기 트리거 시퀀스 데이터가 상기 인공지능 모델에 입력됨에 따라 복제 탐지 값을 출력하는 복제 탐지부, 및, 상기 순환 신경망의 말단에 배치되고, 상기 복제 탐지부로부터 상기 복제 탐지 값이 수신되면 상기 복제 방지 값을 출력하는 누적부를 포함할 수 있다."}
{"patent_id": "10-2021-0154333", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명에 따르면, 인공지능 모델을 대상으로 트리거 시퀀스 데이터를 적용한 후 인공지능 모델의 예측 값을 검 토함으로써, 복제를 한 것으로 의심되는 자가 자체 개발한 인공지능 모델을 사용하는 것인지, 또는 불법 복제된 인공지능 모델을 사용하는 것인지 용이하게 확인할 수 있는 장점이 있다. 본 발명에 따르면, 트리거 시퀀스 데이터가 인공지능 모델에 입력되는 경우 인공지능 모델의 성능을 훼손시켜 더 이상 사용할 수 없도록 함으로써, 원 소유자의 인공지능 모델에 대한 권리를 완벽하게 보장해줄 수 있는 장 점이 있다."}
{"patent_id": "10-2021-0154333", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 첨부된 도면을 참조하여 본 명세서에 개시된 실시 예를 상세히 설명하되, 도면 부호에 관계없이 동일하거 나 유사한 구성요소는 동일한 참조 번호를 부여하고 이에 대한 중복되는 설명은 생략하기로 한다. 이하의 설명 에서 사용되는 구성요소에 대한 접미사 \"모듈\" 및 \"부\"는 명세서 작성의 용이함만이 고려되어 부여되거나 혼용 되는 것으로서, 그 자체로 서로 구별되는 의미 또는 역할을 갖는 것은 아니다. 또한, 본 명세서에 개시된 실시 예를 설명함에 있어서 관련된 공지 기술에 대한 구체적인 설명이 본 명세서에 개시된 실시 예의 요지를 흐릴 수 있다고 판단되는 경우 그 상세한 설명을 생략한다. 또한, 첨부된 도면은 본 명세서에 개시된 실시 예를 쉽게 이 해할 수 있도록 하기 위한 것일 뿐, 첨부된 도면에 의해 본 명세서에 개시된 기술적 사상이 제한되지 않으며, 본 발명의 사상 및 기술 범위에 포함되는 모든 변경, 균등물 내지 대체물을 포함하는 것으로 이해되어야 한다. 제1, 제2 등과 같이 서수를 포함하는 용어는 다양한 구성요소들을 설명하는데 사용될 수 있지만, 상기 구성요소 들은 상기 용어들에 의해 한정되지는 않는다. 상기 용어들은 하나의 구성요소를 다른 구성요소로부터 구별하는목적으로만 사용된다. 어떤 구성요소가 다른 구성요소에 \"연결되어\" 있다거나 \"접속되어\" 있다고 언급된 때에는, 그 다른 구성요소에 직접적으로 연결되어 있거나 또는 접속되어 있을 수도 있지만, 중간에 다른 구성요소가 존재할 수도 있다고 이 해되어야 할 것이다. 반면에, 어떤 구성요소가 다른 구성요소에 \"직접 연결되어\" 있다거나 \"직접 접속되어\" 있 다고 언급된 때에는, 중간에 다른 구성요소가 존재하지 않는 것으로 이해되어야 할 것이다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 출원에서, \"포함한다\" 또 는 \"가지다\" 등의 용어는 명세서상에 기재된 특징, 숫자, 단계, 동작, 구성요소, 부품 또는 이들을 조합한 것이 존재함을 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성요소, 부품 또는 이 들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되어야 한다. 본 발명을 구현함에 있어서 설명의 편의를 위하여 구성요소를 세분화하여 설명할 수 있으나, 이들 구성요소가 하나의 장치 또는 모듈 내에 구현될 수도 있고, 혹은 하나의 구성요소가 다수의 장치 또는 모듈들에 나뉘어져서 구현될 수도 있다. 도 1은 본 발명에 따른 인공지능 모델의 트레이닝 장치를 설명하기 위한 블록도이다. 본 발명에 따른 인공지능 모델의 트레이닝 장치(이하, 트레이닝 장치라 함.)는 통신부, 제어부 및 메모리를 포함할 수 있다. 통신부는 외부 장치와 통신하기 위한 통신 회로를 포함할 수 있다. 이 경우 통신부는 외부 장치와 유 선 또는 무선 네트워크로 연결되어, 데이터를 송수신 할 수 있다. 또한 통신부는, 제어부의 제어 하에, 인공지능 모델을 외부 장치에 전송할 수 있다. 또한 통신 부는, 제어부의 제어 하에, 외부 장치에 트리거 시퀀스 데이터를 전송할 수 있다. 한편 제어부는 트레이닝 장치의 전반적인 동작을 제어할 수 있다. 또한 제어부는 메모리로부터 인공지능 모델을 독출하여 실행할 수 있다. 이에 따라 아래에서 설 명하는 인공지능 모델의 동작은, 제어부의 동작인 것으로 볼 수도 있다. 메모리는, 트레이닝 장치의 동작을 위한 명령어 또는 기타 프로그램을 저장할 수 있다. 또한 메모리는 인공지능 모델을 저장할 수 있다. 구체적으로 인공지능 모델은 소프트웨어 또는 하드웨어와 소프트웨어의 조합으로 구현될 수 있으며, 인공지능 모델을 구성하는 하나 이상의 명령어는 메 모리에 저장될 수 있다. 한편 인공지능 모델은 인공 신경망을 포함할 수 있다. 여기서 인공 신경망은 생물학적 뉴런의 동작원리와 뉴런간의 연결 관계를 모델링한 것으로 노드(node) 또는 처리 요소(processing element)라고 하는 다수의 뉴런 들이 레이어(layer) 구조의 형태로 연결된 정보처리 시스템이다. 그리고 인공 신경망은 일반적으로 다음의 세가 지 인자, 즉 다른 레이어의 뉴런들 사이의 연결 패턴 연결의 가중치를 갱신하는 학습 과정 이전 레 이어로부터 수신되는 입력에 대한 가중 합으로부터 출력값을 생성하는 활성화 함수에 의해 정의될 수 있다. 한편 인공지능 모델은 트레이닝 데이터(training data)를 이용하여 트레이닝(training)될 수 있다. 여기서 트레이닝(training)이란, 입력 데이터를 분류(classification)하거나 회귀분석(regression)하거나 군집화 (clustering)하는 등의 목적을 달성하기 위하여, 트레이닝 데이터를 이용하여 인공 신경망의 파라미터 (parameter)를 결정하는 과정을 의미할 수 있다. 여기서 인공 신경망의 파라미터(parameter)는 시냅스에 부여되 는 가중치(weight) 및 뉴런에 적용되는 편향(bias) 중 적어도 하나를 포함할 수 있다. 그리고 인공지능 모델이 트레이닝 데이터를 이용하여 반복 트레이닝 됨에 따라, 인공지능 모델의 파 라미터(가중치, 편향 등)이 최적화 될 수 있다. 도 2는 본 발명에 따른 인공지능 모델의 복제 방지 방법을 설명하기 위한 순서도이다. 본 발명에 따른 인공지능 모델의 복제 방지 방법은, 시계열적 데이터 집합들을 포함하는 트리거 시퀀스 데이터 가 인공지능 모델에 입력되는 경우 상기 인공지능 모델에 포함되는 순환 신경망이 복제 방지 값을 출력하도록, 상기 순환 신경망을 트레이닝 하는 단계(S210), 상기 순환 신경망의 트레이닝이 완료되면, 상기 순환 신경망의 가중치를 고정시키는 단계(S220), 및, 상기 순환 신경망의 가중치가 고정된 상태에서, 트레이닝 데이터를 이용 하여 상기 인공지능 모델을 트레이닝 하는 단계(S230)를 포함할 수 있다.도 3은 본 발명에 따른 인공지능 모델의 구조를 도시한 도면이다. 인공지능 모델은 인공신경망을 포함할 수 있다. 이 경우 인공 신경망은 복수의 레이어(310, 320, 330, 340, 350)를 포함할 수 있으며, 복수의 레이어(310, 320, 330, 340, 350) 각각은 하나 이상의 노드를 포함할 수 있다. 도 3에서는 본 발명을 간단히 설명하기 위하여, 단순한 구조의 완전 연결된(Fully-connected) 다층 퍼셉트론을 예시하였다. 구체적으로 도 3의 인공지능 모델에서, 입력 레이어는 다섯 개의 노드를 포함하고, 다섯 개의 입력 특징(x1, x2, x3, x4, x5)를 입력 받는다. 또한 인공지능 모델은 출력 레이어에 두 개의 노드를 포함 하며, 두 개의 클래스에 대한 예측 결과 값(y1, y2)을 출력한다. 예를 들어 도 3의 인공지능 모델은 어느 중학생의 다섯 개의 과목의 점수를 입력 받아, 이 중학생에게 이 과가 유리한 정도(y1) 및 문과가 유리한 정도(y2)를 출력하는 신경망 시스템일 수 있다. 다만 이는 예시에 불과한 것으로, 본 발명은 다양한 유형의, 다양한 구조의 인공지능 모델에 적용이 가능하다. 예를 들어 인공지능 모델은, CNN(Convolutional Neural Network), DNN(Deep Neural Network), RNN(Recurrent Neural Network), BRDNN(Bidirectional Recurrent Deep Neural Network), MLP(Multilayer Perceptron) 등의 다양한 네트워크를 하나 이상 포함할 수 있다. 또한 인공지능 모델의 레이어의 수, 노드 의 수, 노드 간 연결 관계, 활성화 함수, 하이퍼 파라미터 등은, 다양하게 구성될 수 있다. 또한 인공지능 모델은, 지도학습(Supervised Learning), 비지도학습(Unsupervised Learning), 강화학습 (Reinforcement Learning), 반 지도학습(Semi-supervised Learning) 등 다양한 학습 알고리즘에 의해 트레이닝 될 수 있다. 이하에서는 인공지능 모델이 지도학습(Supervised Learning) 알고리즘에 기초하여 트레이닝 되는 것으로 가정하여 설명한다. 한편 인공지능 모델은, 설정된 목적에 따라 트레이닝 및 활용될 수 있다. 예를 들어 인공지능 모델은 CNN(Convolutional Neural Network)를 포함하여 이미지 내 특정 오브젝트를 검출하도록 트레이닝 및 활용될 수 있다. 다른 예를 들어 인공지능 모델은 DNN(Deep Neural Network)를 포함하여 통신 트래픽 또는 기타 데이 터부터 악성 사이트를 판단하도록 트레이닝 및 활용될 수 있다. 도 4는 본 발명에 따른, 인공지능 모델 내 순환 신경망을 설명하기 위한 도면이다. 인공지능 모델을 구성하는 복수의 노드 중, 복제 방지를 위해 사용될 복수의 노드가 선택될 수 있다. 도 4 에서는, 선택된 복수의 노드들(1,4 / 2,3 / 3,2 / 4,1)를 음영으로 표시하였다. 여기서 선택된 복수의 노드들(1,4 / 2,3 / 3,2 / 4,1)은 인공지능 모델 내에서 순환 신경망(Recurrent Neural Network, RNN)을 구성할 수 있다. 순환 신경망(Recurrent Neural Network, RNN)이란 시계열 데이터와 같이 시간의 흐름에 따라 동적으로 변화하는 데이터를 학습하기 위한 신경망으로, 본 발명에서 순환 신경망(Recurrent Neural Network, RNN)은 시계열적 데 이터 집합들을 포함하는 트리거 시퀀스 데이터가 입력되는 경우 복제 방지 값을 출력하여 불법 복제 여부를 탐 지하고 인공지능 모델을 더 이상 사용할 수 없도록 하는데 사용된다. 한편 순환 신경망에 포함되는 복수의 노드들(1,4 / 2,3 / 3,2 / 4,1)은, 인공지능 모델 내 복수의 레이어 에 배치되며, 복수의 노드(1,4 / 2,3 / 3,2 / 4,1) 중 시작 노드(1,4)로부터 끝 노드(4,1)까지 끊김 없이 연결 될 수 있다. 구체적으로 도 4에서는, 순환 신경망의 제1 노드(1,4)(순환 신경망의 시작 노드(1,4))가 제1 레이어에 배 치되고, 순환 신경망의 제2 노드(2,3) 가 제2 레이어에 배치되고, 순환 신경망의 제3 노드(3,2))가 제3 레 이어에 배치되고, 순환 신경망의 제4 노드(4,1)(순환 신경망의 끝 노드(4,1))가 제4 레이어에 배치되 는 것으로 도시하였다. 또한 제1 노드(1,4)와 제2 노드(2,3)는 시냅스로 연결되고, 제2 노드(2,3)와 제3 노드 (3,2)는 시냅스로 연결되고, 제3 노드(3,2)와 제4 노드(4,1)은 시냅스로 연결된다. 이에 따라 순환 신경망의 시 작 노드(1,4)로부터 끝 노드(4,1)까지 끊김 없이 연결될 수 있다. 한편 순환 신경망를 구성하는 복수의 노드(1,4 / 2,3 / 3,2 / 4,1)는, 인공지능 모델의 후단의 하나 이상 의 레이어에 배치되지 않을 수 있다. 예를 들어 순환 신경망를 구성하는 복수의 노드(1,4 / 2,3 / 3,2 / 4,1)는 인공지능 모델의 출력 레이어 에 배치되지 않을 수 있다. 다른 예를 들어 순환 신경망를 구성하는 복수의 노드(1,4 / 2,3 / 3,2 / 4,1)는 인공지능 모델의 출력 레 이어 및 출력 레이어와 연속되는 하나 이상의 이전 레이어(예를 들어 제4 레이어)에 배치되지 않을 수 있다. 다만 인공지능 모델의 기능이 훼손되었음을 명확하게 확인하기 위해서는, 순환 신경망를 구 성하는 복수의 노드(1,4 / 2,3 / 3,2 / 4,1)가 출력 레이어에 배치되지는 않되, 출력 레이어에 최대 한 근접해서 배치되는 것이 바람직하다. 한편 순환 신경망은 복제 탐지부 및 누적부를 포함할 수 있다. 여기서 복제 탐지부는 트리거 시퀀스 데이터를 검출하기 위한 것으로, 누적부의 앞에 위치할 수 있다. 예를 들 어 복제 탐지부는 1,4 노드, 2,3 노드, 3,2 노드를 포함할 수 있다. 또한 복제 탐지부는, 트리거 시퀀스 데이터 가 인공지능 모델에 입력됨에 따라 복제 탐지 값을 출력할 수 있다. 또한 누적부는 순환 신경망의 말단에 배치될 수 있다. 예를 들어 누적부는 순환 신경망을 구성하는 복수의 노드 (1,4 / 2,3 / 3,2 / 4,1) 중 끝 노드인 4,1 노드를 포함할 수 있다. 또한 복제 탐지부로부터 복제 탐지 값이 수 신되면, 누적부는 복제 방지 값을 출력할 수 있다. 한편 도 4에서는, 인공지능 모델 내 연속적인 레이어들(310, 320, 330, 340)에 순환 신경망을 구성하는 복수의 노드(1,4 / 2,3 / 3,2 / 4,1)가 배치되는 것으로 설명하였으나 이에 한정되지 않는다. 예를 들어 순환 신경망의 시작 노드(1,4)로부터 끝 노드(4,1)까지 끊김 없이 연결된다는 조건 하에, 제2 레이어나 제3 레이어 에는 순환 신경망을 구성하는 노드가 배치되지 않아도 무방하다. 또한 도 4에서의 순환 신경망을 구성하는 복수의 노드 각각의 레이어 상에서의 위치는 예시에 불과한 것으로, 순환 신경망의 시작 노드(1,4)로부터 끝 노드(4,1)까지 끊김 없이 연결된다는 조건 하에, 레이어에서의 노드의 위치가 변경되어도 무방하다. 한편 시작 노드(1,4)의 경우, 레이어에서의 위치에 제약을 받는데, 이와 관련해서는 도 5에서 설명한다. 도 5는 본 발명에 따른, 순환 신경망을 트레이닝 하는 방법을 설명하기 위한 도면이다. 이하에서는 인공지능 모델의 트레이닝에 사용되는 데이터에 “트레이닝용”이라는 용어를 붙이도록 한다. 제어부는, 시계열적 데이터 집합들을 포함하는 트리거 시퀀스 데이터가 인공지능 모델에 입력되는 경 우 인공지능 모델에 포함되는 순환 신경망이 복제 방지 값을 출력하도록 순환 신경망을 트레이닝 할 수 있 다. 구체적으로 제어부는 지도 학습 알고리즘에 기반하여 순환 신경망을 트레이닝 할 수 있다. 이 경우 제어부 는 트레이닝용 시퀀스 데이터 및 레이블링 데이터를 이용하여 순환 신경망을 트레이닝 할 수 있다. 여기서 레이블링 데이터는 트레이닝용 시퀀스 데이터가 입력되는 경우 순환 신경망이 추론해야 하는 정답으로, 여기서는 레이블링 데이터가 1인 것으로 가정하여 설명한다. 트레이닝용 시퀀스 데이터는 시계열적 데이터 집합들을 포함할 수 있다. 예를 들어 도 5에서 도시된 바와 같이, 트레이닝용 시퀀스 데이터는 제1 데이터 집합(A), 제2 데이터 집합(B) 및 제3 데이터 집합(C)을 포 함하고, 제1 데이터 집합(A), 제2 데이터 집합(B) 및 제3 데이터 집합(C)은 시계열적인 데이터일 수 있다. 즉 제1 데이터 집합(A)은 첫번째 데이터 집합, 제2 데이터 집합(B)은 두번째 데이터 집합, 제3 데이터 집합(C)은 세번째 데이터 집합일 수 있다. 한편 트레이닝용 시퀀스 데이터가 세 개의 데이터 집합을 포함하는 것으로 도시하였으나, 데이터 집합의 개수는 이에 한정되지 않는다. 또한 트레이닝용 시퀀스 데이터는 트리거 암호를 포함할 수 있다. 여기서 트리거 암호는 시계열 적 데이터 집합들(A, B, C) 내 동일 위치의 요소가 시계열적으로 연결된 데이터일 수 있다. 구체적으로 도 5를 참고하면, 인공지능 모델의 입력 레이어는 다섯 개의 입력 특징(x1, x2, x3, x4, x5)를 입력 받는 다섯 개의 노드를 포함한다. 따라서 시계열적 데이터 집합들(A, B, C) 역시, 입력 레이어에 포함되는 노드의 개수와 동일한 개수의 요 소들을 포함할 수 있다. 예를 들어 제1 데이터 집합(A)은 제1-1 요소(a1), 제1-2 요소(a2), 제1-3 요소(a3), 제1-4 요소(a4), 제1-5 요소(a5)를 포함할 수 있다. 그리고 시계열적 데이터 집합들(A, B, C) 내 동일 위치의 요소가 트리거 암호에 사용될 수 있다. 예를 들 어 제1 데이터 집합(A)의 네 번째 요소인 제1-4 요소(a4), 제2 데이터 집합(B)의 네 번째 요소인 제2-4 요소 (b4), 제3 데이터 집합(C)의 네 번째 요소인 제3-4 요소(c4)가 트리거 암호에 사용될 수 있다. 또한 앞서 설명한 바와 같이, 복수의 데이터 집합(A, B, C)는 시계열적 데이터 집합이다. 따라서 제1-4 요소 (a4), 제2-4 요소(b4), 제3-4 요소(c4) 역시 시계열적으로 연결되어 트리거 암호를 구성한다. 즉 제1-4 요 소(a4)는 트리거 암호를 구성하는 첫번째 요소, 제2-4 요소(b4)는 트리거 암호를 구성하는 두번째 요 소, 제3-4 요소(c4)는 트리거 암호를 구성하는 세번째 요소일 수 있다. 따라서 트리거 암호는 a4-b4- c4로 표현될 수 있다. 한편 순환 신경망의 시작 노드(1,4)는 인공지능 모델의 입력 레이어에 배치될 수 있다. 또한 입력 레 이어에서의 시작 노드의 위치는, 시계열적 데이터 집합들(A, B, C)에서 트리거 암호가 배치되는 위치 와 동일할 수 있다. 즉 입력 레이어에서의 네 번째 노드가 순환 신경망의 시작 노드(1,4)가 될 수 있다. 이에 따라 트리거 암호는 순환 신경망의 시작 노드(1,4)로 입력되게 된다. 한편 제어부는 트리거 암호를 포함하는 트레이닝용 트리거 시퀀스 데이터를 인공지능 모델(30 0)에 입력할 수 있다. 이 경우 순환 신경망의 복제 탐지부(1,4 / 2,3 / 3,2)는 자신의 파라미터에 기반하여 트 레이닝용 트리거 시퀀스 데이터를 처리하고, 복제 탐지부(1,4 / 2,3 / 3,2)의 끝 노드(3,2)는 예측 값을 출력할 수 있다. 이 경우 제어부는 끝 노드(3,2)에서 출력된 예측 값과 레이블링 데이터 간의 차이에 기초하여 손실 값을 산출하고, 산출된 손실 값에 기반하여 복제 탐지부(1,4 / 2,3 / 3,2)의 파라미터를 업데이트 할 수 있다. 한편 복제 탐지부(1,4 / 2,3 / 3,2)에 대한 트레이닝 과정에서 인공지능 모델을 구성하는 다른 노드들이나 시냅스의 파라미터가 변경될 수 있으나, 다른 노드들이나 시냅스의 파라미터는 인공지능 모델 전체에 대한 트레이닝 과정에서 다시 최적화 되기 때문에, 무시되어도 무방하다. 한편 제어부는 트리거 암호를 포함하는 다양한 트레이닝용 트리거 시퀀스 데이터를 이용하여, 그리고 트리거 암호를 포함하지 않는 다양한 트레이닝용 시퀀스 데이터를 이용하여 복제 탐지부(1,4 / 2,3 / 3, 2)를 트레이닝 할 수 있다(이 경우에는 레이블링 데이터로써 0이 주어질 수 있다). 그리고 트레이닝의 반복에 따라, 복제 탐지부(1,4 / 2,3 / 3,2)는 트리거 암호를 포함하는 트레이닝용 시 퀀스 데이터가 입력되는 경우에는 1, 트리거 암호를 포함하지 않는 트레이닝용 시퀀스 데이터가 입력되는 경우에는 0을 출력하도록, 파라미터가 설정될 수 있다. 한편 제어부는 1을 출력하는 경우의 정확도(확률 값)가 100%가 될 때까지 복제 탐지부(1,4 / 2,3 / 3,2)를 트레이닝 할 수 있다. 트리거 시퀀스 데이터에 정확하게 반응하도록 구현하는 것이 목표이기 때문에, 과적합의 문제는 무시하여도 무방하다. 한편 복제 탐지부(1,4 / 2,3 / 3,2)에서 출력하는 1은 복제 탐지 값으로 사용될 수 있으며, 복제 탐지부(1,4 / 2,3 / 3,2)에서 출력하는 0은 복제 미 탐지 값으로 사용될 수 있다. 한편 순환 신경망의 트레이닝이 완료되면, 제어부는 순환 신경망의 가중치를 고정시킬 수 있다(S220). 구체적으로, 순환 신경망의 트레이닝이 완료되면, 제어부는 순환 신경망의 노드 간 가중치를 고정시킬 수 있다. 예를 들어 제어부는 순환 신경망의 제1 노드(1,4)와 제2 노드(2,3)간의 가중치를 고정하고, 제2 노 드(2,3)와 제3 노드(3,2) 간의 가중치를 고정하고, 제3 노드(3,2)와 제4 노드(4,1) 간의 가중치를 고정할 수 있 다. 한편 제어부는, 트리거 시퀀스 데이터 이외의 정상 데이터가 인공지능 모델에 입력되는 경우에 순환 신경망이 출력하는 초기 값을 설정할 수 있다. 여기서 정상 데이터란 트리거 암호를 포함하지 않는 데이터 를 의미할 수 있다. 구체적으로 트리거 암호를 포함하지 않는 정상 데이터가 인공지능 모델에 입력되는 경우, 복제 탐지 부(1,4 / 2,3 / 3,2)는 복제 미 탐지 값인 0을 출력한다. 그리고 복제 탐지부(1,4 / 2,3 / 3,2)가 출력한 복제 미 탐지 값은 누적부(4,1)에 입력될 수 있다.그리고 제어부는 복제 미 탐지 값이 입력되는 경우에 누적부(4,1)가 출력하는 초기 값을 설정할 수 있다. 예를 들어 복제 미 탐지 값이 입력되는 경우에 누적부(4,1)가 출력하는 초기 값은 0일 수 있다. 한편 제어부는, 트리거 시퀀스 데이터가 인공지능 모델에 입력되는 경우에 순환 신경망이 출력하는 복제 방지 값을 설정할 수 있다. 여기서 트리거 시퀀스 데이터란, 트리거 암호를 포함하는 데이터일 수 있 다. 구체적으로 트리거 시퀀스 데이터가 인공지능 모델에 입력되는 경우, 복제 탐지부(1,4 / 2,3 / 3,2)는 복 제 탐지 값인 1을 출력한다. 그리고 복제 탐지부(1,4 / 2,3 / 3,2)가 출력한 복제 탐지 값은 누적부(4,1)에 입 력될 수 있다. 그리고 제어부는, 복제 탐지 값이 입력되는 경우에 누적부(4,1)가 출력하는 복제 방지 값을 설정할 수 있 다. 구체적으로 복제 방지 값은 초기 값과는 다른 값으로, 예를 들어 복제 탐지 값이 입력되는 경우에 누적부 (4,1)가 출력하는 복제 방지 값은 1일 수 있다. 추가적으로, 제어부는 누적부(4,1) 및 누적부(4,1)와 연결되는 다음 노드(5,1 / 5,2) 간의 가중치 역시 고 정시킬 수 있다. 한편 제어부는, 트리거 시퀀스 데이터가 입력된 이후 인공지능 모델에 정상 데이터가 입력되면, 복제 방지 값의 출력을 유지하도록 설정할 수 있다. 구체적으로 제어부는 일단 누적부(4,1)가 복제 방지 값을 출력하면, 이후에도 누적부(4,1)가 복제 방지 값 을 출력하도록 설정할 수 있다. 예를 들어 복제 탐지 값인 1이 누적부(4,1)에 입력되면, 누적부(4,1)는 복제 방지 값인 1 출력할 수 있다. 그리 고 나서 정상 데이터가 인공지능 모델에 입력됨에 따라 복제 탐지부(1,4 / 2,3 / 3,2)가 복제 미 탐지 값 인 0을 출력하더라도, 누적부(4,1)는 복제 방지 값인 1을 출력할 수 있다. 다음으로, 순환 신경망의 가중치가 고정된 상태에서, 제어부는 트레이닝 데이터를 이용하여 인공지능 모델 을 트레이닝 할 수 있다(S230). 여기서 트레이닝 데이터는, 본래의 목적에 따라 인공지능 모델을 트레이닝 하기 위한 데이터일 수 있다. 예를 들어 인공지능 모델이 이미지 내 고양이를 검출하기 위한 모델인 경우, 트레이닝 데이터는 고양이를 포함하는 이미지일 수 있다. 이 경우 제어부는 인공지능 모델이 출력한 예측 값에 기반하여, 인공지능 모델 내 파라미터(가 중치, 편향 등)를 업데이트 할 수 있다. 예를 들어 제어부는 예측 값과 정답 값 간의 차이에 기초하여 손 실 값을 산출하고, 오차 역전파(Backpropagation)를 통하여 노드 간 가중치를 업데이트 할 수 있다. 이에 따라 인공지능 모델 내 가중치는 계속적으로 변화하면서 최적화 될 수 있다. 한편 순환 신경망의 가중치는 고정된 상태이다. 따라서 인공지능 모델에 대한 트레이닝이 반복되더라도, 순환 신경망의 가중치는 변경되지 않는 상태에서, 나머지 노드 및 시냅스에 대한 가중치가 변경 및 최적화 될 수 있다. 즉 인공지능 모델에 대한 트레이닝이 반복되더라도, 순환 신경망은 계속 초기 값인 0을 출력할 수 있다. 또한 트레이닝 데이터는, 트리거 암호를 포함하지 않는 정상 데이터일 수 있다. 다시 말해서, 인공지능 모 델은 순환 신경망이 초기 값인 0을 출력하는 상태에서 트레이닝 될 수 있다. 한편 트레이닝이 완료되면, 인공지능 모델은 외부에 배포될 수 있다. 한편 인공지능 모델이 탑재된 장치를 “탑재 장치”라 명칭 하도록 한다. 도 6은 인공지능 모델이 사용되는 상황을 도시한 도면이다. 외부에 배포된 인공지능 모델은, 본연의 목적에 따라 사용될 수 있다. 즉 탑재 장치는, 인공지능 모델에 입력 데이터를 제공하고, 인공지능 모델은 자신의 파라미터에 기반 하여 입력 데이터를 처리하여 예측 값을 출력할 수 있다. 한편 트리거 암호를 포함하지 않는 입력 데이터가 인공지능 모델에 제공되는 경우, 인공지능 모델의 기능은 훼손되지 않는다.예를 들어 도 6a에서 도시된 바와 같이, 하나의 데이터 집합(D)을 포함하는 입력 데이터가 인공지능 모델 에 입력된 상황을 가정한다. 앞서 설명한 트리거 암호는 시계열적 데이터 집합들 내 동일 위치의 요소가 시계열 적으로 연결된 데이터인데 반해, 현재의 입력 데이터는 하나의 데이터 집합을 포함하므로 트리거 암호를 구성할 수 없다. 따라서, 현재의 입력 데이터는 정상 데이터이므로, 복제 탐지부(1,4 / 2,3 / 3,2) 내 끝 노드(3,2)는 복제 미 탐지 값인 0을 출력할 수 있다. 또한 누적부(4,1) 역시 초기 값인 0을 출력할 수 있다. 한편 인공지능 모델은 복제 탐지부(1,4 / 2,3 / 3,2)가 복제 미 탐지 값인 0을 출력하고 누적부(4,1)가 초 기 값인 0을 출력하는 상태에서 트레이닝 되었다. 즉 트레이닝에서의 환경과 현재 환경이 변화되지 않았기 때문 에, 인공지능 모델은 정확도가 높은 예측 값을 출력할 수 있다. 다음으로, 도 6b에서 도시된 바와 같이, 시계열적인 세 개의 데이터 집합들(H, I, J)을 포함하는 입력 데이터가 인공지능 모델에 입력된 상황을 가정한다. 현재의 입력 데이터를 참고하면, 시계열적 데이터 집합들 내 네 번째 위치의 요소들(h4, i4, j4)는 시계열적으로 연결된다. 다만 네 번째 위치의 요소들이 시계열적으로 연결된 데이터는, 앞서 설명한 트리거 암호와 상이하다. 따라서, 현재의 입력 데이터는 정상 데이터이므로, 복제 탐지부(1,4 / 2,3 / 3,2) 내 끝 노드(3,2)는 복제 미 탐지 값인 0을 출력할 수 있다. 또한 누적부(4,1) 역시 초기 값인 0을 출력할 수 있다. 그리고, 트레이닝에서의 환경과 현재 환경이 변화되지 않았기 때문에, 인공지능 모델은 정확도가 높은 예측 값을 출력할 수 있다. 도 7은 인공지능 모델을 훼손시키는 상황을 설명하기 위한 도면이다. 탑재 장치는 인공지능 모델에 입력 데이터를 제공할 수 있다. 이 경우 입력 데이터는, 시계열적 데이터 집 합들(E, F, G)을 포함하는 트리거 시퀀스 데이터일 수 있다. 또한 트리거 시퀀스 데이터는 트리거 암호를 포함할 수 있다. 여기서 트리거 암호는 시계열적 데이터 집합(E, F, G)들 내 동일 위치의 요소(a4, b4, c4)가 시계열적으로 연결된 데이터이다. 또한 도 7의 트 리거 암호는, 도 5에서 트레이닝용 트리거 시퀀스 데이터에 포함되었던 트리거 암호와 동일하다. 한편 a4-b4-c4로 표현되는 트리거 암호는 입력 레이어에 배치되는 순환 신경망의 시작 노드(1,4)에 시계열 적으로 입력될 수 있다. 이 경우 순환 신경망의 복제 탐지부(1,4 / 2,3 / 3,2)는 자신의 파라미터에 기 반하여 트리거 암호를 처리할 수 있다. 그리고 복제 탐지부(1,4 / 2,3 / 3,2)의 끝 노드(3,2)는 복제 탐지 값인 1을 출력할 수 있다. 한편 복제 탐지부(1,4 / 2,3 / 3,2)가 출력한 복제 탐지 값은 누적부(4,1)에 입력된다. 그리고 복제 탐지 값이 입력됨에 따라, 누적부(4,1)는 복제 방지 값인 1을 출력할 수 있다. 한편 인공지능 모델은 복제 탐지부(1,4 / 2,3 / 3,2)가 복제 미 탐지 값인 0을 출력하고 누적부(4,1)가 초 기 값인 0을 출력하는 상태에서 트레이닝 되었다. 즉 인공지능 모델은 누적부(4,1)가 초기 값을 출력하는 상태에서 내부 파라미터가 최적화된 상태이다. 예 를 들어 출력 레이어 내 제1 노드(5,1)는, 누적부(4,1)로부터 출력되는 값이 초기 값으로 고정된 상태에서, 제4 레이어 내 다른 노드들(4,2 / 4,3 /4,4 /4,5)이 출력하는 값에 기반하여 정답 값을 예측하도록 파라미터가 설정되었다. 따라서 트리거 시퀀스 데이터가 입력됨에 따라 누적부(4,1)가 복제 방지 값을 출력하면, 인공지능 모델은 엉뚱한 예측 값을 산출하게 되며 이에 따라 인공지능 모델의 기능이 훼손되게 된다. 또한 일단 누적부(4,1)가 복제 방지 값을 출력하면, 누적부(4,1)는 복제 방지 값의 출력을 유지할 수 있다. 즉 트리거 시퀀스 데이터가 입력된 이후에 인공지능 모델에 정상 데이터가 입력되더라도, 순환 신경망은 복제 방지 값의 출력을 유지한다. 이에 따라 인공지능 모델의 기능은 영구히 훼손될 수 있다. 이와 같이 본 발명에 따르면, 인공지능 모델을 대상으로 트리거 시퀀스 데이터를 적용한 후 인공지능 모델의 예 측 값을 검토함으로써, 복제를 한 것으로 의심되는 자가 자체 개발한 인공지능 모델을 사용하는 것인지, 또는 불법 복제된 인공지능 모델을 사용하는 것인지 용이하게 확인할 수 있는 장점이 있다. 또한, 인공지능 모델의 불법 복제 방지를 위한 기존의 방식은 주로, 인공지능 모델 내에 워터마크를 생성하는 레이어를 추가시킴으로써, 인공지능 모델의 예측 값이 워터마크 생성 레이어에서 만들어낸 워터마크를 포함하도록 하는 방식이다. 다만 이러한 방식은, 인공지능 모델을 열어봐야 하고, 인공지능 모델을 열어보기 위한 법적 절차나 사전 준비 등이 필요하며, 인공지능 모델 소유권자의 워터마크를 확인하여 인공지능 모델의 소유권을 간 접적으로 증명하는데 불과하다는 문제가 있다. 다만 본 발명에 따르면, 트리거 시퀀스 데이터가 인공지능 모델 에 입력되는 경우 인공지능 모델의 성능을 훼손시켜 더 이상 사용할 수 없도록 함으로써, 원 소유자의 인공지능 모델에 대한 권리를 완벽하게 보장해줄 수 있는 장점이 있다. 전술한 본 발명은, 프로그램이 기록된 매체에 컴퓨터가 읽을 수 있는 코드로서 구현하는 것이 가능하다. 컴퓨터 가 읽을 수 있는 매체는, 컴퓨터 시스템에 의하여 읽혀질 수 있는 데이터가 저장되는 모든 종류의 기록장치를 포함한다. 컴퓨터가 읽을 수 있는 매체의 예로는, HDD(Hard Disk Drive), SSD(Solid State Disk), SDD(Silicon Disk Drive), ROM, RAM, CD-ROM, 자기 테이프, 플로피 디스크, 광 데이터 저장 장치 등이 있다. 또한, 상기 컴 퓨터는 서버의 프로세서를 포함할 수도 있다. 따라서, 상기의 상세한 설명은 모든 면에서 제한적으로 해석 되어서는 아니 되고 예시적인 것으로 고려되어야 한다. 본 발명의 범위는 첨부된 청구항의 합리적 해석에 의해 결정되어야 하고, 본 발명의 등가적 범위 내에서의 모든 변경은 본 발명의 범위에 포함된다."}
{"patent_id": "10-2021-0154333", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명에 따른 인공지능 모델의 트레이닝 장치를 설명하기 위한 블록도이다. 도 2는 본 발명에 따른 인공지능 모델의 복제 방지 방법을 설명하기 위한 순서도이다. 도 3은 본 발명에 따른 인공지능 모델의 구조를 도시한 도면이다. 도 4는 본 발명에 따른, 인공지능 모델 내 순환 신경망을 설명하기 위한 도면이다. 도 5는 본 발명에 따른, 순환 신경망을 트레이닝 하는 방법을 설명하기 위한 도면이다. 도 6은 인공지능 모델이 사용되는 상황을 도시한 도면이다. 도 7은 인공지능 모델을 훼손시키는 상황을 설명하기 위한 도면이다."}
