{"patent_id": "10-2019-0137841", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2020-0050880", "출원번호": "10-2019-0137841", "발명의 명칭": "전자 장치, 전자 장치의 제어 방법 및 컴퓨터 판독 가능 매체.", "출원인": "삼성전자주식회사", "발명자": "유승학"}}
{"patent_id": "10-2019-0137841", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "통신부; 및텍스트가 입력되면, 기계 학습된 언어 모델을 이용하여 상기 입력된 텍스트를 포함하는 추천 메시지를획득하고, 상기 추천 메시지를 전송하기 위한 사용자 입력이 수신되면, 상기 추천 메시지를 외부 전자 장치로전송하도록 상기 통신부를 제어하는 프로세서;를 포함하고,상기 프로세서는, 상기 입력된 텍스트 및 상기 텍스트 입력 이전에 상기 통신부와 상기 외부 전자 장치 간에 송수신된 하나 이상의 메시지를 상기 언어 모델에 적용하여, 상기 추천 메시지를 획득하는, 전자 장치."}
{"patent_id": "10-2019-0137841", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 프로세서는,상기 텍스트 입력 이전에 송수신된 상기 하나 이상의 메시지에 대한 문맥 정보를 획득하고,상기 입력된 텍스트에 대응되는 단어 및 상기 획득된 문맥 정보를 이용하여, 상기 단어를 첫 단어로 포함하고상기 텍스트 입력 이전에 송수신된 상기 하나 이상의 메시지에 이어지는 상기 추천 메시지를 획득하는, 전자 장치."}
{"patent_id": "10-2019-0137841", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 프로세서는,입력된 제1 텍스트에 대응되는 제1 단어, 상기 제1 텍스트 입력 이후에 입력된 제2 텍스트에 대응되는 제2 단어및 상기 제1 텍스트 입력 이전에 상기 통신부 및 상기 외부 전자 장치 간에 송수신된 하나 이상의 메시지에 기초하여, 상기 제1 단어 및 상기 제2 단어를 포함하는 추천 메시지를 획득하고,상기 획득된 추천 메시지는, 상기 제1 단어를 첫 번째 단어로, 상기 제2 단어를 두 번째 단어로 포함하는, 전자 장치."}
{"patent_id": "10-2019-0137841", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,복수의 문장(sentence)을 포함하는 기본 데이터로 RNN(Recurrent Neural Network) 학습(training)된 임베딩 행렬(embedding matrix) 및 소프트맥스 행렬(softmax matrix)을 포함하는 상기 언어 모델이 저장된 스토리지;를더 포함하고,상기 프로세서는,상기 저장된 언어 모델을 이용하여, 상기 입력된 텍스트를 포함하는 상기 추천 메시지를 획득하는, 전자 장치."}
{"patent_id": "10-2019-0137841", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서,상기 프로세서는,상기 텍스트 입력 이전에 송수신된 상기 하나 이상의 메시지에 대응되는 문장 및 상기 입력된 텍스트에 대응되공개특허 10-2020-0050880-3-는 단어를 상기 언어 모델에 적용하여, 상기 입력된 텍스트에 대응되는 단어 다음의 제1 예상 단어를 판단하고,상기 텍스트 입력 이전에 송수신된 상기 하나 이상의 메시지에 대응되는 문장, 상기 입력된 텍스트에 대응되는단어 및 상기 판단된 제1 예상 단어를 상기 언어 모델에 적용하여 상기 판단된 제1 예상 단어 다음의 제2 예상단어를 판단하며,상기 입력된 텍스트에 대응되는 단어, 상기 제1 예상 단어 및 상기 제2 예상 단어를 순차적으로 포함하는 상기추천 메시지를 획득하는, 전자 장치."}
{"patent_id": "10-2019-0137841", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제4항에 있어서,상기 프로세서는,상기 복수의 문장 중 제1 문장에 포함된 하나 이상의 단어 및 문장 부호 각각에 대응되는 복수의 제1 벡터를 제1 랜덤 행렬에 기초하여 벡터 공간으로 매핑시킨 복수의 제1 데이터를 획득하고, 상기 제1 데이터에 기초하여 제2 데이터를 생성하며, 상기 제2 데이터를 제2 랜덤 행렬에 기초하여 복원한 복원 벡터를 획득하고, 상기 제1 문장 다음의 제2 문장에 포함된 첫번째 단어에 대응되는 제2 벡터 및 상기 복원 벡터 간의 오차에 기초하여 상기 제1 랜덤 행렬 및 상기 제2 랜덤 행렬의 엘리먼트를 업데이트하며, 상기 업데이트된 제1 랜덤 행렬 및 제2 랜덤 행렬을 각각 상기 임베딩 행렬 및 상기 소프트맥스 행렬로서 상기스토리지에 저장하는, 전자 장치."}
{"patent_id": "10-2019-0137841", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6항에 있어서,상기 프로세서는,상기 복수의 제1 벡터 및 상기 제2 벡터 각각을 상기 제1 랜덤 행렬에 기초하여 상기 벡터 공간으로 매핑시킨복수의 제3 데이터를 획득하고, 상기 복수의 제3 데이터에 기초하여 제4 데이터를 생성하며, 상기 제4 데이터를 상기 제2 랜덤 행렬에 기초하여 복원한 복원 벡터를 획득하고, 상기 제2 문장의 두번째 단어에 대응되는 제3 벡터 및 상기 제4 데이터를 복원한 복원 벡터 간의 오차에 기초하여 상기 제1 랜덤 행렬 및 상기 제2 랜덤 행렬의 엘리먼트를 업데이트하며, 상기 업데이트된 제1 랜덤 행렬 및 제2 랜덤 행렬을 각각 상기 임베딩 행렬 및 상기 소프트맥스 행렬로서 상기스토리지에 저장하는, 전자 장치."}
{"patent_id": "10-2019-0137841", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제6항 또는 제7항에 있어서,상기 프로세서는,상기 복수의 문장들 전부에 기초하여 상기 제1 랜덤 행렬 및 상기 제2 랜덤 행렬 각각의 엘리먼트를 업데이트하고,상기 나머지 문장에 기초하여 엘리먼트가 업데이트된 상기 제1 랜덤 행렬 및 상기 제2 랜덤 행렬을 각각 상기임베딩 행렬 및 상기 소프트맥스 행렬로서 상기 스토리지에 저장하는, 전자 장치."}
{"patent_id": "10-2019-0137841", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "전자 장치의 제어 방법에 있어서,텍스트가 입력되면, 기계 학습된 언어 모델을 이용하여 상기 입력된 텍스트를 포함하는 추천 메시지를 획득하는공개특허 10-2020-0050880-4-단계; 및상기 추천 메시지를 전송하기 위한 사용자 입력이 수신되면, 상기 추천 메시지를 외부 전자 장치로 전송하는 단계;를 포함하고,상기 추천 메시지를 획득하는 단계는,상기 입력된 텍스트 및 상기 텍스트 입력 이전에 상기 전자 장치와 상기 외부 전자 장치 간에 송수신된 하나 이상의 메시지를 상기 언어 모델에 적용하여, 상기 추천 메시지를 획득하는, 제어 방법."}
{"patent_id": "10-2019-0137841", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9항에 있어서,상기 추천 메시지를 획득하는 단계는,상기 텍스트 입력 이전에 송수신된 상기 하나 이상의 메시지에 대한 문맥 정보를 획득하고,상기 입력된 텍스트에 대응되는 단어 및 상기 획득된 문맥 정보를 이용하여, 상기 단어를 첫 단어로 포함하고상기 텍스트 입력 이전에 송수신된 상기 하나 이상의 메시지에 이어지는 상기 추천 메시지를 획득하는, 제어 방법."}
{"patent_id": "10-2019-0137841", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제9항에 있어서,입력된 제1 텍스트에 대응되는 제1 단어, 상기 제1 텍스트 입력 이후에 입력된 제2 텍스트에 대응되는 제2 단어및 상기 제1 텍스트 입력 이전에 상기 통신부 및 상기 외부 전자 장치 간에 송수신된 하나 이상의 메시지에 기초하여, 상기 제1 단어 및 상기 제2 단어를 포함하는 추천 메시지를 획득하는 단계;를 더 포함하고, 상기 추천 메시지는, 상기 제1 단어를 첫 번째 단어로, 상기 제2 단어를 두 번째 단어로 포함하는, 제어 방법."}
{"patent_id": "10-2019-0137841", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제9항에 있어서,복수의 문장(sentence)을 포함하는 기본 데이터로 임베딩 행렬(embedding matrix) 및 소프트맥스 행렬(softmaxmatrix)을 포함하는 상기 언어 모델을 RNN(Reccurent Neural Network) 학습시키는 단계;를 더 포함하는, 제어방법."}
{"patent_id": "10-2019-0137841", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제12항에 있어서,상기 추천 메시지를 획득하는 단계는,상기 텍스트 입력 이전에 송수신된 상기 하나 이상의 메시지에 대응되는 문장 및 상기 텍스트 입력에 대응되는단어를 상기 언어 모델에 적용하여, 상기 입력된 텍스트에 대응되는 단어 다음의 제1 예상 단어를 판단하고,상기 텍스트 입력 이전에 송수신된 상기 하나 이상의 메시지에 대응되는 문장, 상기 입력된 텍스트에 대응되는단어 및 상기 판단된 제1 예상 단어를 상기 언어 모델에 적용하여 상기 판단된 제1 예상 단어 다음의 제2 예상단어를 판단하며,상기 입력된 텍스트에 대응되는 단어, 상기 제1 예상 단어 및 상기 제2 예상 단어를 순차적으로 포함하는 상기추천 메시지를 획득하는, 제어 방법."}
{"patent_id": "10-2019-0137841", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제12항에 있어서,상기 언어 모델을 RNN 학습시키는 단계는,공개특허 10-2020-0050880-5-상기 복수의 문장 중 제1 문장에 포함된 하나 이상의 단어 및 문장 부호 각각에 대응되는 복수의 제1 벡터를 제1 랜덤 행렬에 기초하여 벡터 공간으로 매핑시킨 복수의 제1 데이터를 획득하고, 상기 제1 데이터에 기초하여 제2 데이터를 생성하며, 상기 제2 데이터를 제2 랜덤 행렬에 기초하여 복원한 복원 벡터를 획득하고, 상기 제1 문장 다음의 제2 문장에 포함된 첫번째 단어에 대응되는 제2 벡터 및 상기 복원 벡터 간의 오차에 기초하여 상기 제1 랜덤 행렬 및 상기 제2 랜덤 행렬의 엘리먼트를 업데이트하며, 상기 업데이트된 제1 랜덤 행렬 및 제2 랜덤 행렬을 각각 상기 임베딩 행렬 및 상기 소프트맥스 행렬로서 상기전자 장치의 스토리지에 저장하는, 제어 방법."}
{"patent_id": "10-2019-0137841", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제14항에 있어서,상기 언어 모델을 RNN 학습시키는 단계는,상기 복수의 제1 벡터 및 상기 제2 벡터 각각을 상기 제1 랜덤 행렬에 기초하여 상기 벡터 공간으로 매핑시킨복수의 제3 데이터를 획득하고, 상기 복수의 제3 데이터에 기초하여 제4 데이터를 생성하며, 상기 제4 데이터를 상기 제2 랜덤 행렬에 기초하여 복원한 복원 벡터를 획득하고, 상기 제2 문장의 두번째 단어에 대응되는 제3 벡터 및 상기 제4 데이터를 복원한 복원 벡터 간의 오차에 기초하여 상기 제1 랜덤 행렬 및 상기 제2 랜덤 행렬의 엘리먼트를 업데이트하며, 상기 업데이트된 제1 랜덤 행렬 및 제2 랜덤 행렬을 각각 상기 임베딩 행렬 및 상기 소프트맥스 행렬로서 상기스토리지에 저장하는, 제어 방법."}
{"patent_id": "10-2019-0137841", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제14항 또는 제15항에 있어서,상기 언어 모델을 RNN 학습시키는 단계는,상기 복수의 문장들 전부에 기초하여 상기 제1 랜덤 행렬 및 상기 제2 랜덤 행렬 각각의 엘리먼트를 업데이트하고,상기 나머지 문장에 기초하여 엘리먼트가 업데이트된 상기 제1 랜덤 행렬 및 상기 제2 랜덤 행렬을 각각 상기임베딩 행렬 및 상기 소프트맥스 행렬로서 상기 스토리지에 저장하는, 제어 방법."}
{"patent_id": "10-2019-0137841", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "전자 장치의 프로세서에 의해 실행되어, 상기 전자 장치로 하여금,텍스트가 입력되면, 기계 학습된 언어 모델을 이용하여 상기 입력된 텍스트를 포함하는 추천 메시지를 획득하는단계; 및상기 추천 메시지를 전송하기 위한 사용자 입력이 수신되면, 상기 추천 메시지를 외부 전자 장치로 전송하는 단계;를 포함하고,상기 추천 메시지를 획득하는 단계는,상기 입력된 텍스트 및 상기 텍스트 입력 이전에 상기 전자 장치와 상기 외부 전자 장치 간에 송수신된 하나 이상의 메시지를 상기 언어 모델에 적용하여, 상기 추천 메시지를 획득하는, 동작을 수행하도록 하는 명령어가 저장된 컴퓨터 판독 가능 매체."}
{"patent_id": "10-2019-0137841", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "전자 장치를 개시한다. 본 전자 장치는, 통신부, 텍스트가 입력되면, 기계 학습된 언어 모델을 이용하여 입력된 텍스트를 포함하는 추천 메시지를 획득하고, 추천 메시지를 전송하기 위한 사용자 입력이 수신되면, 추천 메시지 를 외부 전자 장치로 전송하도록 통신부를 제어하는 프로세서를 포함하고, 이 경우 프로세서는, 입력된 텍스트 및 텍스트 입력 이전에 통신부와 외부 전자 장치 간에 송수신된 하나 이상의 메시지를 언어 모델에 적용하여, 추 천 메시지를 획득할 수 있다."}
{"patent_id": "10-2019-0137841", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 사용자가 입력하고자 하는 문장을 선제적으로 추천하는 전자 장치에 대한 것이다. 보다 상세하게는, 외부 장치와 주고받았던 메시지의 내용에 기초하여, 해당 메시지 다음에 이어지고 사용자가 입력한 단어를 포함 하는 문장을 추천하는 전자 장치에 대한 것이다."}
{"patent_id": "10-2019-0137841", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "타이핑에 대한 사용자의 수고를 덜기 위해, 종래에 사용자가 입력한 단어에 기초하여 다음 단어를 예상하여 추 천하는 전자 장치에 대한 기술이 존재하였다. 다만, 종래의 전자 장치는 사용자가 입력한 단어 다음에 이어질 단어를 하나씩 추천한 결과, 사용자가 추천 단 어를 채택하더라도 하나의 선택 입력마다 하나의 단어만을 획득하기 때문에 타이핑은 줄더라도 선택의 횟수가 많아져 불편함에 있었다. 또한, 단순히 사용자가 입력한 단어만을 고려하는 경우, 적절한 추천 단어를 제시하지 못하는 경우가 많았다."}
{"patent_id": "10-2019-0137841", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 개시는, 이전에 외부 장치와 주고받은 메시지의 내용 및 사용자가 입력한 단어를 모두 고려하여 적절한 문장 을 추천하는 전자 장치를 제공함에 그 목적이 있다. 특히, 사용자 입력한 텍스트에 대응되는 단어 및 텍스트 입력 이전에 주고받은 메시지의 문맥 정보를 RNN(Recurrent Neural Network) 학습(training)된 언어 모델에 적용하여, 입력된 텍스트에 대응되는 단어를 포 함하는 문장을 추천함으로써, 사용자가 입력하고자 한 문장의 완성된 형태를 선제적으로 추천하는 전자 장치를 제공함에 그 목적이 있다."}
{"patent_id": "10-2019-0137841", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 개시의 일 실시 예에 따른 전자 장치는, 통신부, 텍스트가 입력되면, 기계 학습된 언어 모델을 이용하여 상 기 입력된 텍스트를 포함하는 추천 메시지를 획득하고, 상기 추천 메시지를 전송하기 위한 사용자 입력이 수신 되면, 상기 추천 메시지를 외부 전자 장치로 전송하도록 상기 통신부를 제어하는, 프로세서를 포함하고, 상기 프로세서는, 상기 입력된 텍스트 및 상기 텍스트 입력 이전에 상기 통신부와 상기 외부 전자 장치 간에 송수신 된 하나 이상의 메시지를 상기 언어 모델에 적용하여, 상기 추천 메시지를 획득한다. 이 경우, 상기 프로세서는, 상기 텍스트 입력 이전에 송수신된 상기 하나 이상의 메시지에 대한 문맥 정보를 획 득하고, 상기 입력된 텍스트에 대응되는 단어 및 상기 획득된 문맥 정보를 이용하여, 상기 단어를 첫 단어로 포 함하고 상기 텍스트 입력 이전에 송수신된 상기 하나 이상의 메시지에 이어지는 상기 추천 메시지를 획득할 수 있다. 또는, 상기 프로세서는, 입력된 제1 텍스트에 대응되는 제1 단어, 상기 제1 텍스트 입력 이후에 입력된 제2 텍 스트에 대응되는 제2 단어 및 상기 제1 텍스트 입력 이전에 상기 통신부 및 상기 외부 전자 장치 간에 송수신된 하나 이상의 메시지에 기초하여, 상기 제1 단어 및 상기 제2 단어를 포함하는 추천 메시지를 획득하고, 상기 획 득된 추천 메시지는, 상기 제1 단어를 첫 번째 단어로, 상기 제2 단어를 두 번째 단어로 포함할 수 있다. 또한, 본 전자 장치는, 복수의 문장(sentence)을 포함하는 기본 데이터로 RNN(Recurrent Neural Network) 학습 (training)된 임베딩 행렬(embedding matrix) 및 소프트맥스 행렬(softmax matrix)을 포함하는 상기 언어 모델 이 저장된 스토리지를 더 포함하고, 상기 프로세서는, 상기 저장된 언어 모델을 이용하여, 상기 입력된 텍스트 를 포함하는 상기 추천 메시지를 획득할 수 있다. 이때, 상기 프로세서는, 상기 텍스트 입력 이전에 송수신된 상기 하나 이상의 메시지에 대응되는 문장 및 상기 입력된 텍스트에 대응되는 단어를 상기 언어 모델에 적용하여, 상기 입력된 텍스트에 대응되는 단어 다음의 제1 예상 단어를 판단하고, 상기 텍스트 입력 이전에 송수신된 상기 하나 이상의 메시지에 대응되는 문장, 상기 입 력된 텍스트에 대응되는 단어 및 상기 판단된 제1 예상 단어를 상기 언어 모델에 적용하여 상기 판단된 제1 예 상 단어 다음의 제2 예상 단어를 판단하며, 상기 입력된 텍스트에 대응되는 단어, 상기 제1 예상 단어 및 상기 제2 예상 단어를 순차적으로 포함하는 상기 추천 메시지를 획득할 수 있다. 또한, 상기 프로세서는, 상기 복수의 문장 중 제1 문장에 포함된 하나 이상의 단어 및 문장 부호 각각에 대응되 는 복수의 제1 벡터를 제1 랜덤 행렬에 기초하여 벡터 공간으로 매핑시킨 복수의 제1 데이터를 획득하고, 상기 제1 데이터에 기초하여 제2 데이터를 생성하며, 상기 제2 데이터를 제2 랜덤 행렬에 기초하여 복원한 복원 벡터 를 획득하고, 상기 제1 문장 다음의 제2 문장에 포함된 첫번째 단어에 대응되는 제2 벡터 및 상기 복원 벡터 간 의 오차에 기초하여 상기 제1 랜덤 행렬 및 상기 제2 랜덤 행렬의 엘리먼트를 업데이트하며, 상기 업데이트된 제1 랜덤 행렬 및 제2 랜덤 행렬을 각각 상기 임베딩 행렬 및 상기 소프트맥스 행렬로서 상기 스토리지에 저장 할 수도 있다. 이때, 상기 프로세서는, 상기 복수의 제1 벡터 및 상기 제2 벡터 각각을 상기 제1 랜덤 행렬에 기초하여 상기 벡터 공간으로 매핑시킨 복수의 제3 데이터를 획득하고, 상기 복수의 제3 데이터에 기초하여 제4 데이터를 생성 하며, 상기 제4 데이터를 상기 제2 랜덤 행렬에 기초하여 복원한 복원 벡터를 획득하고, 상기 제2 문장의 두번 째 단어에 대응되는 제3 벡터 및 상기 제4 데이터를 복원한 복원 벡터 간의 오차에 기초하여 상기 제1 랜덤 행 렬 및 상기 제2 랜덤 행렬의 엘리먼트를 업데이트하며, 상기 업데이트된 제1 랜덤 행렬 및 제2 랜덤 행렬을 각 각 상기 임베딩 행렬 및 상기 소프트맥스 행렬로서 상기 스토리지에 저장할 수 있다. 그리고, 상기 프로세서는, 상기 복수의 문장들 전부에 기초하여 상기 제1 랜덤 행렬 및 상기 제2 랜덤 행렬 각 각의 엘리먼트를 업데이트하고, 상기 나머지 문장에 기초하여 엘리먼트가 업데이트된 상기 제1 랜덤 행렬 및 상 기 제2 랜덤 행렬을 각각 상기 임베딩 행렬 및 상기 소프트맥스 행렬로서 상기 스토리지에 저장할 수 있다. 본 개시의 일 실시 예에 따른 전자 장치의 제어 방법은, 텍스트가 입력되면, 기계 학습된 언어 모델을 이용하여 상기 입력된 텍스트를 포함하는 추천 메시지를 획득하는 단계, 상기 추천 메시지를 전송하기 위한 사용자 입력 이 수신되면, 상기 추천 메시지를 외부 전자 장치로 전송하는 단계를 포함하고, 상기 추천 메시지를 획득하는 단계는, 상기 입력된 텍스트 및 상기 텍스트 입력 이전에 상기 전자 장치와 상기 외부 전자 장치 간에 송수신된 하나 이상의 메시지를 상기 언어 모델에 적용하여, 상기 추천 메시지를 획득할 수 있다. 이때, 상기 추천 메시지를 획득하는 단계는, 상기 텍스트 입력 이전에 송수신된 상기 하나 이상의 메시지에 대 한 문맥 정보를 획득하고, 상기 입력된 텍스트에 대응되는 단어 및 상기 획득된 문맥 정보를 이용하여, 상기 단 어를 첫 단어로 포함하고 상기 텍스트 입력 이전에 송수신된 상기 하나 이상의 메시지에 이어지는 상기 추천 메 시지를 획득할 수 있다. 또는, 본 제어 방법은, 입력된 제1 텍스트에 대응되는 제1 단어, 상기 제1 텍스트 입력 이후에 입력된 제2 텍스 트에 대응되는 제2 단어 및 상기 제1 텍스트 입력 이전에 상기 통신부 및 상기 외부 전자 장치 간에 송수신된 하나 이상의 메시지에 기초하여, 상기 제1 단어 및 상기 제2 단어를 포함하는 추천 메시지를 획득하는 단계를 더 포함하고, 상기 추천 메시지는, 상기 제1 단어를 첫 번째 단어로, 상기 제2 단어를 두 번째 단어로 포함할 수 있다. 또한, 본 제어 방법은, 복수의 문장(sentence)을 포함하는 기본 데이터로 임베딩 행렬(embedding matrix) 및 소 프트맥스 행렬(softmax matrix)을 포함하는 상기 언어 모델을 RNN(Reccurent Neural Network) 학습시키는 단계 를 더 포함할 수 있다. 이 경우, 상기 추천 메시지를 획득하는 단계는, 상기 텍스트 입력 이전에 송수신된 상기 하나 이상의 메시지에 대응되는 문장 및 상기 텍스트 입력에 대응되는 단어를 상기 언어 모델에 적용하여, 상기 입력된 텍스트에 대응 되는 단어 다음의 제1 예상 단어를 판단하고, 상기 텍스트 입력 이전에 송수신된 상기 하나 이상의 메시지에 대 응되는 문장, 상기 입력된 텍스트에 대응되는 단어 및 상기 판단된 제1 예상 단어를 상기 언어 모델에 적용하여 상기 판단된 제1 예상 단어 다음의 제2 예상 단어를 판단하며, 상기 입력된 텍스트에 대응되는 단어, 상기 제1 예상 단어 및 상기 제2 예상 단어를 순차적으로 포함하는 상기 추천 메시지를 획득할 수 있다. 또한, 상기 언어 모델을 RNN 학습시키는 단계는, 상기 복수의 문장 중 제1 문장에 포함된 하나 이상의 단어 및 문장 부호 각각에 대응되는 복수의 제1 벡터를 제1 랜덤 행렬에 기초하여 벡터 공간으로 매핑시킨 복수의 제1 데이터를 획득하고, 상기 제1 데이터에 기초하여 제2 데이터를 생성하며, 상기 제2 데이터를 제2 랜덤 행렬에 기초하여 복원한 복원 벡터를 획득하고, 상기 제1 문장 다음의 제2 문장에 포함된 첫번째 단어에 대응되는 제2 벡터 및 상기 복원 벡터 간의 오차에 기초하여 상기 제1 랜덤 행렬 및 상기 제2 랜덤 행렬의 엘리먼트를 업데이 트하며, 상기 업데이트된 제1 랜덤 행렬 및 제2 랜덤 행렬을 각각 상기 임베딩 행렬 및 상기 소프트맥스 행렬로 서 상기 전자 장치의 스토리지에 저장할 수 있다. 이 경우, 상기 언어 모델을 RNN 학습시키는 단계는, 상기 복수의 제1 벡터 및 상기 제2 벡터 각각을 상기 제1 랜덤 행렬에 기초하여 상기 벡터 공간으로 매핑시킨 복수의 제3 데이터를 획득하고, 상기 복수의 제3 데이터에기초하여 제4 데이터를 생성하며, 상기 제4 데이터를 상기 제2 랜덤 행렬에 기초하여 복원한 복원 벡터를 획득 하고, 상기 제2 문장의 두번째 단어에 대응되는 제3 벡터 및 상기 제4 데이터를 복원한 복원 벡터 간의 오차에 기초하여 상기 제1 랜덤 행렬 및 상기 제2 랜덤 행렬의 엘리먼트를 업데이트하며, 상기 업데이트된 제1 랜덤 행 렬 및 제2 랜덤 행렬을 각각 상기 임베딩 행렬 및 상기 소프트맥스 행렬로서 상기 스토리지에 저장할 수 있다. 그리고, 상기 언어 모델을 RNN 학습시키는 단계는, 상기 복수의 문장들 전부에 기초하여 상기 제1 랜덤 행렬 및 상기 제2 랜덤 행렬 각각의 엘리먼트를 업데이트하고, 상기 나머지 문장에 기초하여 엘리먼트가 업데이트된 상 기 제1 랜덤 행렬 및 상기 제2 랜덤 행렬을 각각 상기 임베딩 행렬 및 상기 소프트맥스 행렬로서 상기 스토리지 에 저장할 수 있다. 본 개시의 일 실시 예에 따른 컴퓨터 판독 가능 매체에는, 전자 장치의 프로세서에 의해 실행되어, 상기 전자 장치로 하여금, 텍스트가 입력되면, 기계 학습된 언어 모델을 이용하여 상기 입력된 텍스트를 포함하는 추천 메 시지를 획득하는 단계, 상기 추천 메시지를 전송하기 위한 사용자 입력이 수신되면, 상기 추천 메시지를 외부 전자 장치로 전송하는 단계를 포함하고, 상기 추천 메시지를 획득하는 단계는, 상기 입력된 텍스트 및 상기 텍 스트 입력 이전에 상기 전자 장치와 상기 외부 전자 장치 간에 송수신된 하나 이상의 메시지를 상기 언어 모델 에 적용하여, 상기 추천 메시지를 획득하는, 동작을 수행하도록 하는 명령어가 저장될 수 있다."}
{"patent_id": "10-2019-0137841", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 개시에 따른 전자 장치 및 그 제어 방법은, 사용자가 의도한 문장을 사용자가 입력하는 과정에서, 설령 사용 자가 해당 문장에 포함되는 하나 혹은 두 개의 단어만을 타이핑한 경우라도, 사용자가 의도한 문장을 적절히 판 단하여 완성된 문장을 추천한다는 효과가 있다. 특히, 외부 장치와 메시지를 주고받음에 있어, 이전에 주고받은 메시지들의 문맥 정보를 이용한 결과, 현재 사 용자가 의도한 문장이 무엇인지 판단함에 있어 그 정확성이 향상된다는 장점이 있다."}
{"patent_id": "10-2019-0137841", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 개시에 대하여 구체적으로 설명하기에 앞서, 본 명세서 및 도면의 기재 방법에 대하여 설명한다. 먼저, 본 명세서 및 청구범위에서 사용되는 용어는 본 개시의 다양한 실시 예들에서의 기능을 고려하여 일반적 인 용어들을 선택하였다 하지만, 이러한 용어들은 당해 기술 분야에 종사하는 기술자의 의도나 법률적 또는 기 술적 해석 및 새로운 기술의 출현 등에 따라 달라질 수 있다. 또한, 일부 용어는 출원인이 임의로 선정한 용어 도 있다. 이러한 용어에 대해서는 본 명세서에서 정의된 의미로 해석될 수 있으며, 구체적인 용어 정의가 없으 면 본 명세서의 전반적인 내용 및 당해 기술 분야의 통상적인 기술 상식을 토대로 해석될 수도 있다. 또한, 본 명세서에 첨부된 각 도면에 기재된 동일한 참조번호 또는 부호는 실질적으로 동일한 기능을 수행하는 부품 또는 구성요소를 나타낸다. 설명 및 이해의 편의를 위해서 서로 다른 실시 예들에서도 동일한 참조번호 또 는 부호를 사용하여 설명한다. 즉, 복수의 도면에서 동일한 참조 번호를 가지는 구성요소를 모두 도시되어 있다 고 하더라도, 복수의 도면들이 하나의 실시 예를 의미하는 것은 아니다. 또한, 본 명세서 및 청구범위에서는 구성요소들 간의 구별을 위하여 \"제1\", \"제2\" 등과 같이 서수를 포함하는 용어가 사용될 수 있다. 이러한 서수는 동일 또는 유사한 구성요소들을 서로 구별하기 위하여 사용하는 것이며 이러한 서수 사용으로 인하여 용어의 의미가 한정 해석되어서는 안 된다. 일 예로, 이러한 서수와 결합된 구성 요소는 그 숫자에 의해 사용 순서나 배치 순서 등이 제한되어서는 안 된다. 필요에 따라서는, 각 서수들은 서로 교체되어 사용될 수도 있다. 본 명세서에서 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 출원에서, \"포함하다\" 또는 \"구성되다\" 등의 용어는 명세서상에 기재된 특징, 숫자, 단계, 동작, 구성요소, 부품 또는 이 들을 조합한 것이 존재함을 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성 요소, 부품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되어야 한다. 본 개시의 실시 예에서 \"모듈\", \"유닛\", \"부(part)\" 등과 같은 용어는 적어도 하나의 기능이나 동작을 수행하는 구성요소를 지칭하기 위한 용어이며, 이러한 구성요소는 하드웨어 또는 소프트웨어로 구현되거나 하드웨어 및 소프트웨어의 결합으로 구현될 수 있다. 또한, 복수의 \"모듈\", \"유닛\", \"부(part)\" 등은 각각이 개별적인 특정 한 하드웨어로 구현될 필요가 있는 경우를 제외하고는, 적어도 하나의 모듈이나 칩으로 일체화되어 적어도 하나 의 프로세서로 구현될 수 있다. 또한, 본 개시의 실시 예에서, 어떤 부분이 다른 부분과 연결되어 있다고 할 때, 이는 직접적인 연결뿐 아니라, 다른 매체를 통한 간접적인 연결의 경우도 포함한다. 또한, 어떤 부분이 어떤 구성요소를 포함한다는 의미는, 특별히 반대되는 기재가 없는 한 다른 구성요소를 제외하는 것이 아니라 다른 구성요소를 더 포함할 수 있는 것 을 의미한다. 도 1은 본 개시에 따른 전자 장치가 추천 문장을 제공하는 모습을 사용자에게 제공되는 화면을 통해 설명하기 위한 도면이다. 도 1의 (a) 및 (b)는, 외부 전자 장치와 메시지를 주고받을 수 있도록 하는 애플리케이션이 전 자 장치에서 실행된 결과, 해당 애플리케이션에 대한 UI(User Interface)를 포함하는 화면이 도시된 것이다. 이 러한 화면은 전자 장치에 디스플레이 된다. 도 1의 (a) 및 (b)는 전자 장치에서 실행된 애플리케이션을 통해 '친구'의 외부 전자 장치와 메시지를 주고받는 상황을 전제한다. 도 1의 (a) 및 (b)를 참고하면, '친구'의 외부 전자 장치로부터 \"어제 여행은 잘 갔다왔어?\" 라는 메시지가 수신되어 화면에 표시된 상태임을 확인할 수 있다. 도 1의 (a)는, '친구'의 외부 전자 장치로부터 수신된 메시지에 답하기 위해 사용자가 그래픽 키패드에 대한 터치를 통해 메시지를 입력하는 과정에서, \"응,\"이라는 텍스트가 입력창에 입력된 상황을 나타낸다. 이때, 본 개시에 따른 전자 장치는 \"어제 여행은 잘 갔다왔어?\"라는 문장의 문맥 정보 및 \"응,\"이라는 현재 입 력된 텍스트를 고려하여, 사용자가 의도한 메시지를 판단하고, 이를 추천할 수 있다. 도 1의 (a)를 참고하면, 입력되지 않은 \"잘 갔다 왔어.\" 부분이 \"응,\"보다는 연한 색으로 자동으로 표시됨으로 써, \"응, 잘 갔다 왔어.\"라는 문장이 입력창을 통해 추천된 것을 확인할 수 있다. 이때, 사용자로부터 추천된 문장을 선택하기 위한 입력이 수신되면, \"응, 잘 갔다 왔어.\"라는 문장이, 실제 사 용자로부터 입력받은 것과 마찬가지로 입력창에 진하게 표시되고 그 후 사용자의 전송 명령에 따라 \"응, 잘 갔다 왔어.\"라는 메시지가 외부 전자 장치로 전송될 수 있다. 또는 추천된 문장을 선택하기 위한 입력만으로 곧 바로 해당 메시지가 '친구'의 외부 전자 장치로 전송될 수도 있다. 도 1의 (b)는 도 1의 (a) 상황에서 사용자로부터 추천된 문장을 선택하는 입력이 수신되지 않고, 사용자로부터 추가적으로 \"정말\"이라는 텍스트가 입력창에 입력된 상황을 나타낸다. 이때, 본 개시에 따른 전자 장치는 \"어제 여행은 잘 갔다왔어?\"라는 문장의 문맥 정보 및 \"응, 정말\"이라는 현재 입력된 텍스트를 고려하여, 사용 자가 의도한 메시지를 판단하고, 이를 추천할 수 있다. 도 1의 (b)를 참고하면, 입력되지 않은 \"대박이었어.\" 부분이 \"응, 정말\"보다는 연한 색으로 자동으로 표시됨으 로써, \"응, 정말 대박이었어.\"라는 문장이 입력창을 통해 추천된 것을 확인할 수 있다. 이렇듯, 본 개시에 따른 전자 장치는, 이전에 송수신된 메시지의 문맥 정보를 이용하여, 사용자가 입력한 단어 및/또는 문장 부호를 사용자가 입력한 순서에 맞게 모두 포함하는 문장을 추천할 수 있다. 이하에서는 도 1과 같이 문장을 추천할 수 있는 전자 장치의 구체적인 구성 및 동작을 설명한다. 한편, 도 1의 (a) 및 (b)에 도시된 화면은 본 개시에 따른 전자 장치가 UI를 제공하는 일 예일 뿐이고 전자 장치가 제공하는 UI는 도 1처럼 시각적으로 제공되지 않고 청각적으로 제공될 수도 있다. 또한, 도 1과 같이 시각적으로 UI를 제공하는 경우라도 메시지/입력창/키패드 등의 배치, 추천 문장의 표시 형태, 화면의 구성 등은 도 1의 (a) 및 (b)와 다를 수 있다. 또한, 메시지의 입력 형태도 도 1의 (a) 및 (b)와 같이 그래픽 키보드인 경우에만 한정되 는 것은 아니다. 도 2는 본 개시의 일 실시 예에 따른 전자 장치의 구성을 설명하기 위한 블록도이다. 전자 장치는 스 마트폰, 노트북 PC, 데스크탑 PC, 태블릿 PC, 모니터, TV, 키오스크 등으로 구현될 수 있다. 또한, 전자 장치 는 셋탑박스나 서버 등으로 구현될 수도 있다. 도 2를 참조하면, 전자 장치는 통신부 및 프로세서를 포함할 수 있다. 통신부는 하나 이상의 외부 장치(도시되지 않음)와 무선 혹은 유선으로 데이터 통신을 수행하기 위한 수단 이다. 프로세서는 통신부를 이용하여 각종 외부 기기와 통신을 수행할 수 있다. 무선 통신 방식으로 외부 장치와 데이터 통신을 수행할 경우, 통신부는 와이파이 다이렉트(WIFI DIRECT) 통신 모듈, 블루투스(bluetooth)모듈, 적외선 통신(IrDA, infrared data association)모듈, NFC(Near Field Communication)모듈, 지그비(Zigbee) 모듈, 셀룰러 통신모듈, 3G(3세대) 이동통신 모듈, 4G(4세대) 이동통신 모듈, 4세대 LTE(Long Term Evolution) 통신 모듈 중 적어도 하나를 포함할 수 있다. 유선 통신 방식으로 외부 장치와 데이터 통신을 수행할 경우, 통신부는 동축 케이블, 광섬유 케이블 등과 연결되어 LAN(Local Area Network) 통신을 수행함으로써 다양한 데이터를 송수신할 수도 있다. 프로세서는 전자 장치의 전반적인 동작을 제어할 수 있다. 본 개시에 따른 인공지능과 관련된 기능은 프로세서와 메모리를 통해 수행된다. 프로세서는 하나 또 는 복수의 프로세서로 구성될 수 있다. 이때, 하나 또는 복수의 프로세서는 CPU, AP, DSP(Digital Signal Processor) 등과 같은 범용 프로세서, GPU, VPU(Vision Processing Unit)와 같은 그래픽 전용 프로세서 또는 NPU와 같은 인공지능 전용 프로세서일 수 있다. 하나 또는 복수의 프로세서는, 메모리에 저장된 기 정의된 동작 규칙 또는 인공지능 모델에 따라, 입력 데이터를 처리하도록 제어한다. 또는, 하나 또는 복수의 프로세서가 인 공지능 전용 프로세서인 경우, 인공지능 전용 프로세서는, 특정 인공지능 모델의 처리에 특화된 하드웨어 구조 로 설계될 수 있다. 기 정의된 동작 규칙 또는 인공지능 모델은 학습을 통해 만들어진 것을 특징으로 한다. 여기서, 학습을 통해 만 들어진다는 것은, 기본 인공지능 모델이 학습 알고리즘에 의하여 다수의 학습 데이터들을 이용하여 학습됨으로 써, 원하는 특성(또는, 목적)을 수행하도록 설정된 기 정의된 동작 규칙 또는 인공지능 모델이 만들어짐을 의미 한다. 이러한 학습은 본 개시에 따른 인공지능이 수행되는 기기 자체에서 이루어질 수도 있고, 별도의 서버 및/ 또는 시스템을 통해 이루어 질 수도 있다. 학습 알고리즘의 예로는, 지도형 학습(supervised learning), 비지도 형 학습(unsupervised learning), 준지도형 학습(semi-supervised learning) 또는 강화 학습(reinforcement learning)이 있으나, 전술한 예에 한정되지 않는다. 인공지능 모델은, 복수의 신경망 레이어들로 구성될 수 있다. 복수의 신경망 레이어들 각각은 복수의 가중치들 (weight values)을 갖고 있으며, 이전(previous) 레이어의 연산 결과와 복수의 가중치들 간의 연산을 통해 신경 망 연산을 수행한다. 복수의 신경망 레이어들이 갖고 있는 복수의 가중치들은 인공지능 모델의 학습 결과에 의 해 최적화될 수 있다. 예를 들어, 학습 과정 동안 인공지능 모델에서 획득한 로스(loss) 값 또는 코스트(cost) 값이 감소 또는 최소화되도록 복수의 가중치들이 갱신될 수 있다. 인공 신경망은 심층 신경망(DNN:Deep Neural Network)를 포함할 수 있으며, 예를 들어, CNN (Convolutional Neural Network), DNN (Deep Neural Network), RNN (Recurrent Neural Network), RBM (Restricted Boltzmann Machine), DBN (Deep Belief Network), BRDNN(Bidirectional Recurrent Deep Neural Network) 또는 심층 Q-네트워크 (Deep Q-Networks) 등이 있으나, 전술한 예에 한정되지 않는다. 프로세서는 외부 전자 장치(도시되지 않음)와 하나 이상의 메시지를 송수신하도록 통신부를 제어할 수 있다. 이때, 외부 전자 장치(도시되지 않음)는 스마트폰, 서버, 데스크탑 PC, 태블릿 PC, 노트북 PC 등 전자 적으로 통신 가능한 다양한 전자 기기일 수 있다. 구체적으로, 프로세서는 메시지의 내용, 메시지를 보내거나 받는 주체, 메시지가 전송된 시간 등에 대한 데이터를 외부 전자 장치(도시되지 않음)와 주고받도록 통신부를 제어할 수 있다. 이때, 메시지를 보낸 주 체는 메시지를 전송하거나 수신하는 장치의 식별 정보와 대응될 수 있다. 통신부와 외부 전자 장치(도시되지 않음) 간의 메시지 송수신은 직접적인 통신이 아니라 서버 등 다른 장 치를 거친 것일 수도 있다. 예로, 프로세서는, 통신부 및 외부 전자 장치(도시되지 않음)와 각각 연 결된 외부 장치(도시되지 않음)를 통해서 외부 전자 장치와 메시지를 송수신하도록 통신부를 제어할 수도 있다. 한편, 전자 장치가 외부 전자 장치와 연결된 입출력 포트(도시되지 않음)를 구비한 경우, 프로세서는 입출력 포트(도시되지 않음)를 통해 외부 전자 장치(도시되지 않음)와 하나 이상의 메시지를 송수신할 수도 있 다. 또는, 전자 장치의 입출력 포트(도시되지 않음)와 연결되고 외부 전자 장치(도시되지 않음)와 통신 가 능한 외부 장치(도시되지 않음)를 통해서, 전자 장치와 외부 전자 장치 간의 메시지 송수신이 수행될 수도 있다. 한편, 전자 장치가 입출력 포트를 포함하는 경우에 있어, 입출력 포트의 구성에 대한 구체적인 설명 은 도 5와 함께 후술한다. 프로세서는 텍스트가 입력되면, 기계 학습된 언어 모델을 이용하여 입력된 텍스트를 포함하는 추천 메시지 를 획득할 수 있다. 구체적으로, 입력된 텍스트, 텍스트 입력 이전에 통신부와 외부 전자 장치 간에 송수 신된 하나 이상의 메시지를 언어 모델에 적용하여, 추천 메시지를 획득할 수 있다. 기계 학습된 언어 모델에 대 해서는 도 3 내지 도 4를 통해 후술한다. 이때, 텍스트는 전자 장치의 사용자 입력부(도시되지 않음)를 통해 전자 장치에 직접 입력되거나 또 는 다른 외부 장치(도시되지 않음)에 입력된 후 그 정보가 전자 장치에 전송된 것일 수도 있다. 예로, 특 정한 텍스트를 입력하라는 사용자 명령이 사용자 입력부(도시되지 않음)에 수신되면, 해당 텍스트가 전자 장치 에 입력될 수 있다. 프로세서는 텍스트 입력 이전에 송수신된 하나 이상의 메시지에 대한 문맥 정보를 획득할 수 있다. 그리고, 입력된 텍스트에 대응되는 단어 및 획득된 문맥 정보를 이용하여, 추천 메시지를 획득할 수 있다. 이 경우, 추천 메시지는, 입력된 텍스트에 대응되는 단어를 첫 단어로 포함하고, 텍스트 입력 이전에 송수신된 하 나 이상의 메시지에 이어지는 메시지일 수 있다. 즉, 프로세서는 기저장된 복수의 메시지 중, 텍스트 입력 이전에 송수신된 하나 이상의 메시지에 뒤이어질 내용을 가지며 입력된 텍스트에 대응되는 단어를 첫 단어로 포함하는 메시지를 식별할 수 있다. 기저장된 복수 의 메시지는 기설정된 메시지, 과거에 입력된 텍스트에 대응되는 하나 이상의 단어 및/또는 문장 등을 포함할 수 있다. 이때, 입력된 텍스트가 단어뿐만 아니라 문장 부호도 포함하는 경우, 프로세서는 문장 부호 역시 고려하여 추천 메시지를 획득할 수 있다. 텍스트 입력 이전에 송수신된 하나 이상의 메시지는, 텍스트 입력으로부터 기설정된 시간 이내에 송수신된 메시 지일 수 있다. 또한, 텍스트가 입력된 시간과 가장 가까운 시간에 송수신된 메시지부터 N 번째로 가까운 시간에 송수신된 메시지를 포함하는 메시지들일 수도 있다('N'은 기설정된 숫자). 또한, 텍스트가 입력된 시간으로부터 기설정된 시간 이내에 송신된 메시지 및/또는 텍스트가 입력된 시간으로부터 기설정된 시간 이내에 수신된 메시 지를 포함할 수도 있다. 문맥 정보는, 하나 이상의 특정 메시지에 포함되는 단어 및 문장 부호에 대한 정보일 수 있다. 구체적으로, 문 맥 정보는, 특정 메시지에 포함되는 각 단어의 내용, 품사 및 순서에 대한 정보일 수 있다. 이러한 문맥 정보는, 기학습된 언어 모델을 이용하여 획득될 수도 있는데, 관련된 구체적인 실시 예는 도 3 내지 도 4를 통 해 후술한다. 상술한 도 1의 (a)를 예로 들면, 프로세서는 \"어제 여행은 잘 갔다왔어?\"라는 메시지의 문맥 정보 및 \"응,\"이라는 텍스트를 이용하여, \"응,\"을 포함하는 \"응, 잘 갔다 왔어.\"라는 문장을 추천 메시지로 획득할 수 있다. 입력된 텍스트에 대응되는 단어가 두 개 이상인 경우, 프로세서는 텍스트 입력 이전에 송수신된 하나 이상 의 메시지의 문맥 정보 및 두 개 이상의 단어를 이용하여, 두 개 이상의 단어를 모두 포함하는 추천 메시지를 획득할 수 있다. 구체적으로, 프로세서는, 제1 텍스트 입력 이전에 통신부와 외부 전자 장치 간에 송수신된 하나 이상 의 메시지, 제1 텍스트에 대응되는 제1 단어 및 제1 텍스트 입력 이후에 입력된 제2 텍스트에 대응되는 제2 단 어에 기초하여, 제1 단어를 첫 번째 단어로 포함하고 제2 단어를 두 번째로 포함하는 추천 메시지를 획득할 수 도 있다.입력된 텍스트에 대응되는 단어 및/또는 문장 부호가 세 개 이상인 경우, 마찬가지로 프로세서는 해당 단 어 및/또는 문장 부호들을 입력된 순서에 따라 포함하는 추천 메시지를 획득할 수 있다. 상술한 도 1의 (b)를 예로 들면, 프로세서는 \"어제 여행은 잘 갔다왔어?\"라는 메시지의 문맥 정보, \"응,\" 이라는 단어 및 \"정말\"이라는 단어를 이용하여, \"응, 정말 대박이었어.\"라는 추천 메시지를 획득할 수 있다. 프로세서는, 이렇듯 입력된 텍스트에 대응되는 하나 이상의 단어를 포함하는 추천 메시지를 획득한 뒤, 식 별된 문장을 추천 문장으로서 사용자에게 시각적 또는 청각적으로 제공할 수 있다. 그리고, 프로세서는, 제공된 추천 메시지를 외부 전자 장치로 전송하기 위한 사용자 입력이 수신되면, 추 천 메시지를 외부 전자 장치로 전송하도록 통신부를 제어할 수 있다. 이하 도 3 내지 도 4에서는, 입력된 텍스트에 대응되는 하나 이상의 단어를 포함하는 문장을 식별함에 있어, 기 계 학습된 언어 모델을 사용하는 실시 예를 설명한다. 도 3은 본 개시의 일 실시 예에 따라 언어 모델이 저장된 스토리지를 포함하는 전자 장치의 구성을 설명하 기 위한 블록도이다. 도 3을 참조하면, 전자 장치는 도 2에서 도시 및 설명된 통신부 및 프로세서 외에도, 스토리지 를 더 포함할 수 있다. 스토리지는 전자 장치의 구성요소들의 전반적인 동작을 제어하기 위한 운영체제(OS: Operating System) 및 전자 장치의 구성요소와 관련된 명령 또는 데이터를 저장하기 위한 구성이다. 이를 위해, 스토리지는 비휘발성 메모리(ex: 하드 디스크, SSD(Solid state drive), 플래시 메모리), 휘 발성 메모리 등으로 구현될 수 있다. 스토리지에는 사용자가 전자 장치를 통해 하나 이상의 외부 전자 장치(도시되지 않음)와 메시지를 송 수신할 수 있도록 하는 애플리케이션 및/또는 태스크가 저장되어 있을 수 있다. 스토리지에는 복수의 문장(sentence)을 포함하는 기본 데이터로 RNN(Recurrent Neural Network) 학습 (training)된 임베딩 행렬(embedding matrix) 및 소프트맥스 행렬(softmax matrix)을 포함하는 언어 모델이 저 장될 수 있으며, 프로세서는 저장된 언어 모델을 이용하여, 입력된 텍스트를 포함하는 추천 메시지를 획득 할 수 있다. 여기서, RNN은 순환 신경망을 의미하며, 시계열 데이터와 같이 시간의 흐름에 따라 변화하는 데이터를 학습하기 위한 딥 러닝 모델의 일종이다. RNN 학습의 구체적인 방법은 임베딩 행렬 및 소프트맥스 행렬과 함께 후술한다. 복수의 문장은 기설정된 문장, 이전에 수신된 사용자 입력에 대응되는 하나 이상의 문장 등을 포함할 수 있다. 이때, 프로세서는 순차적으로 이어질 단어를 하나씩 예상하면서 완성된 문장(추천 메시지)을 획득할 수 있 다. 구체적으로, 프로세서는 텍스트 입력 이전에 송수신된 하나 이상의 메시지에 대응되는 문장 및 입력된 텍 스트에 대응되는 단어를 언어 모델에 적용하여, 입력된 텍스트에 대응되는 단어 다음의 제1 예상 단어를 판단할 수 있다. 그리고, 텍스트 입력 이전에 송수신된 하나 이상의 메시지에 대응되는 문장, 입력된 텍스트에 대응되 는 단어 및 판단된 제1 예상 단어를 언어 모델에 적용하여, 판단된 제1 예상 단어 다음의 제2 예상 단어를 판단 할 수 있다. 이렇듯 순차적으로 이어지는 단어를 하나씩 예상한 결과, 프로세서는 입력된 텍스트에 대응되 는 단어, 제1 예상 단어 및 제2 예상 단어를 순차적으로 포함하는 메시지를 식별할 수 있다. 이를 위해, 언어 모델은 하나 이상의 문장 및 하나 이상의 단어를 입력받은 결과 입력된 단어 다음으로 이어질 단어를 식별하도록 학습될 수 있고, 학습된 데이터는 언어 모델에 포함되는 임베딩 행렬 및/또는 소프트맥스 행 렬의 엘리먼트로 저장될 수 있다. 스토리지에 저장된 언어 모델은, 서버 등의 외부 장치(도시되지 않음)에서 학습된 것일 수도 있고, 프로세 서에 의해 학습된 것일 수도 있다. 이하에서는 프로세서가 언어 모델을 학습시키는 경우로 가정하여 설명한다. 먼저, 프로세서는 복수의 문장 중 제1 문장에 포함된 하나 이상의 단어 및 문장 부호 각각에 대응되는 복 수의 제1 벡터를 제1 랜덤 행렬에 기초하여 벡터 공간으로 매핑시킨 복수의 제1 데이터를 획득할 수 있다. 예를 들어, 제1 문장이 \"I am a girl.\"인 경우라면, 프로세서는 \"I\", \"am\", \"a\", \"girl\", \".\" 각각에 대 응되는 복수의 벡터를 획득할 수 있다. 이때, 복수의 제1 벡터는 각각 1 × m의 크기를 갖는 벡터일 수 있고, 여기서 m은 언어 모델을 학습시키는 데에 이용되는 기본 데이터에 포함된 텍스트의 종류에 따라 결정될 수 있다. 예를 들어, 기본 데이터에는 서로 상이한 텍스트가 15000개라고 하면, 각 텍스트에 대응되는 벡터는 1 × 15000의 크기를 갖는 벡터일 수 있다. 그리고, 벡터의 15000개의 열 중 하나만이 값이 1이고, 나머지는 0이며, 값이 1인 열의 위치에 따라 텍스트가 결정될 수 있다. 예를 들어, 15000개의 열 중 첫 번째 열의 값이 1이면 \"I\"를 나타내고, 15000개의 열 중 두 번째 열의 값이 1이면 \"you\"를 나타낼 수 있다. 이러한 방식으로 프로세서 는 제1 문장에 포함되는 텍스트 각각에 대응되는 복수의 제1 벡터를 획득할 수 있다. 제1 랜덤 행렬은 m(행) × n(열) 개의 랜덤한 엘리먼트들을 갖는 행렬이며, 제1 벡터를 n차원의 벡터 공간으로 매핑하기 위한 행렬일 수 있다. 즉, 프로세서는 복수의 제1 벡터 각각을 제1 랜덤 행렬과 곱하여 n차원의 벡터 공간으로 매핑된 복수의 제1 데이터를 획득할 수 있다. 그리고, 프로세서는 제1 데이터에 기초하여 제2 데이터를 생성할 수 있다. 예를 들어, 프로세서는 LSTM(Long-Short term Memory) 방식을 이용하여 복수의 제1 데이터로부터 제2 데이터를 생성할 수 있다. LSTM 방식은 종래 기술이므로 구체적인 설명은 생략한다. 또는, 프로세서는 복수의 제1 데이터를 가중합하여 제 2 데이터를 생성할 수도 있다. 이렇듯, 제1 문장에 포함된 텍스트 각각에 대응되는 복수의 제1 데이터 및 복수의 제1 데이터로부터 생성된 제2 데이터 등은, 제1 문장에 대응되는 문맥 정보의 개념에 포함된다고 할 수 있다. 프로세서는 제2 데이터를 제2 랜덤 행렬에 기초하여 복원한 복원 벡터를 획득할 수 있다. 여기서, 제2 랜 덤 행렬은 n(행) × m(열) 개의 랜덤한 엘리먼트들을 갖는 행렬이며, n차원으로 매핑된 데이터를 벡터로 복원하 기 위한 행렬일 수 있다. 즉, 제1 랜덤 행렬 및 제2 랜덤 행렬의 전치 행렬(transposed matrix)은 크기가 동일 할 수 있다. 복원 벡터는 1 × m의 크기를 갖는 벡터일 수 있으나, 각 열의 값은 0에서 1사이의 값을 가지며, 모든 열의 값을 더하면 1이 될 수 있다. 프로세서는 제1 문장 다음에 올 수 있는 문장이 제2 문장이라는 것을 기본 데이터를 통해 식별한 뒤, 제2 문장에 포함된 첫번째 단어에 대응되는 제2 벡터 및 복원 벡터 간의 오차에 기초하여 제1 랜덤 행렬 및 제2 랜 덤 행렬의 엘리먼트를 업데이트할 수 있다. 이때, 제1 문장 다음에 올 수 있는 문장은 단 한 가지에 국한되는 것은 아니다. 그리고, 프로세서는 업데이트된 제1 랜덤 행렬 및 제2 랜덤 행렬을 각각 임베딩 행렬 및 소프트맥스 행렬 로서 스토리지에 저장하여 언어 모델을 학습시킬 수 있다. 프로세서는 제1 문장 및 제2 문장에 포함된 첫번째 단어뿐만 아니라, 제2 문장에 포함된 두번째 이후의 단 어 각각에 대해서도 언어 모델을 학습시킬 수 있다. 예로, 프로세서는, 복수의 제1 벡터 및 제2 벡터 각각을 제1 랜덤 행렬에 기초하여 벡터 공간으로 매핑시 킨 복수의 제3 데이터를 획득하고, 복수의 제3 데이터에 기초하여 제4 데이터를 생성하며, 제4 데이터를 제2 랜 덤 행렬에 기초하여 복원한 복원 벡터를 획득할 수 있다. 이 경우, 제2 문장의 두번째 단어에 대응되는 제3 벡 터 및 제4 데이터를 복원한 복원 벡터 간의 오차에 기초하여 제1 랜덤 행렬 및 제2 랜덤 행렬의 엘리먼트를 업 데이트할 수 있다. 그리고, 업데이트된 제1 랜덤 행렬 및 제2 랜덤 행렬을 각각 임베딩 행렬 및 소프트맥스 행 렬로서 스토리지에 저장할 수 있다. 이렇듯, 프로세서는 제2 문장에 포함되는 단어를 순서대로 이용하여 언어 모델을 학습시킬 수 있다. 그리고, 상술한 실시 예는 복수의 문장 중 제1 문장을 이용하여 그 뒤에 이어질 제2 문장에 대해 학습하는 내용 에 그치지만, 프로세서는 제1 문장 외에도 복수의 문장들 전부에 기초하여 제1 랜덤 행렬 및 제2 랜덤 행 렬 각각의 엘리먼트를 업데이트할 수 있다. 구체적으로, 프로세서는 복수의 문장들 중 제1 문장 외의 다른 나머지 문장들 각각에 대해 뒤이어지는 문장 내의 단어(및/또는 문장 부호) 각각에 대해 언어 모델을 학습시킬 수 있다. 그리고, 나머지 문장들 각각에 대해 업데이트된 제1 랜덤 행렬 및 제2 랜덤 행렬을 각각 임베딩 행렬 및 소프트 맥스 행렬로서 스토리지에 저장할 수 있다. 여기서, 임베딩 행렬 및 소프트맥스 행렬의 전치 행렬은 크기가 동일할 수 있다. 그리고, 임베딩 행렬 및 소프 트맥스 행렬의 전치 행렬은 대응되는 엘리먼트가 서로 다를 수 있다. 그에 따라, 동일한 문장 및/또는 단어가입력되더라도 추천되는 단어는 달라질 수 있다. 이렇듯 학습된 언어 모델을 통해, 프로세서는 텍스트 입력 이전에 송수신된 하나 이상의 메시지(문장) 및 입력된 텍스트에 대응되는 단어를 이용하여 적절한 문장(추천 메시지)을 획득할 수 있다. 구체적으로, 언어 모 델이 적용된 RNN(Recurrent Neural Network)를 이용할 수 있다. 도 4는 사용자 입력 이전에 입력된 메시지의 문맥 정보에 기초하여 순차적으로 다음 단어를 예상하는 예를 설명 하기 위한 도면이다. 도 4는 학습된 언어 모델이 적용된 RNN(Recurrent Neural Network)을 통한 순차적인 단어 예상 과정을 나타낸 것이다. 도 4는, 입력된 문장의 문맥 정보를 생성하는 Encoder, 입력된 문장의 문맥 정보를 이용하여 입력된 문장 다음 문장을 식별하는 Decoder를 개시한다. Decoder는, Encoder에서 생성된 문맥 정보를 이용하여 입력된 문장 다음으로 이어질 가능성이 높은 단어들을 순 차적으로 식별하고, 그 결과 순차적으로 식별된 단어들을 포함하는 문장을 실시간으로 획득할 수 있다. 도 4를 참조하면, \"How are you?\"라는 문장이 Encoder에 수신된 결과, 프로세서는 순차적으로 입력된 \"How\", \"are\", \"you\", \"?\" 각각에 대응하는 복수의 제1 벡터(x1, x2, x3, x4)를 획득할 수 있다. 각각의 제1 벡터 는 1 * m의 크기를 가진 행렬로서 하나의 열만 1이고 나머지는 0인 One-hot Vector에 해당할 수 있다. 이 경우, 프로세서는 Encoder Embedding Layer를 통해, 복수의 제1 벡터에 임베딩 행렬을 적용하여 복수의 제1 데이터(1, 2, 3, 4)를 획득할 수 있다. 그리고, Encoder Reccurent Layer를 통해, 대응되는 텍스트가 입력된 순서(i)에 따라 순차적으로 복수의 제1 데 이터를 적용하여 제2 데이터를 생성할 수 있다. 도 4의 경우, \"How\"에 대응되는 제1 데이터, \"are\"에 대응되는 제1 데이터, \"you\"에 대응되는 제1 데이터, \"?\"에 대응되는 제1 데이터를 순서대로 적용하여 데이터(z = h4(s)) 를 생성할 수 있다. 이후, 프로세서는 Decoder를 이용하여 \"How are you?\"라는 문장 다음에 이어질 단어를 순차적으로 판단할 수 있다. 이때, 입력된 텍스트에 대응되는 단어를 추가로 고려할 수도 있다. 구체적으로, 텍스트가 입력되지 않은 경우 또는 입력된 경우를 가정할 수 있다. 도 4는 입력되지 않은 경우에 해당된다. 도 4를 참조하면, 텍스트가 입력되지 않았으므로, 프로세서는 Decoder Output Layer를 통해 데이터(z = h4(s))에 소프트맥스 행렬을 적용하여 복원 벡터를 획득할 수 있고, 획득된 복원 벡터는 \"I\"에 대응됨을 확인할 수 있다. 이때, 프로세서는, Decoder Reccurent Layer를 통해, 데이터(z = h4(s))뿐만 아니라 \"I\"에 대응되는 데이터 를 추가로 적용하여 결과 데이터를 획득할 수 있고, Decoder Output Layer를 통해 결과 데이터에 소프트맥 스 행렬을 적용한 결과 도 4와 같이 \"I\" 다음에 이어질 \"am\"이라는 단어를 식별할 수 있다. 그리고, \"am\"에 대 응되는 데이터를 추가로 적용한 결과 \"am\" 다음에 이어질 \"fine\"을 식별하여 하나의 문장(\"I am fine\")을 추천 메시지로서 획득할 수 있다. 만약, 도 4와 달리 \"How are you?\" 이후에 텍스트가 입력된 경우, 프로세서는 \"How are you?\"뿐만 아니라 입력된 텍스트에 대응되는 단어를 추가로 Encoder에 입력시켜 다음 단어를 식별할 수 있다. 예를 들어, \"I\"에 대응되는 텍스트가 입력된 경우, 프로세서는 \"How\", \"are\", \"you\", \"?\" 각각에 대응되는 복수의 제1 데이 터 및 \"I\"에 대응되는 제2 데이터를 이용하여 제3 데이터를 획득하고, 제3 데이터를 Decoder에 입력시켜 \"I\" 다 음의 \"am\"을 식별할 수 있다. 그리고, \"am\"을 추가로 고려하여 \"am\"의 다음 단어인 \"fine\"을 식별할 수 있다. 그 결과, \"I am fine\"이라는 추천 메시지를 획득할 수 있다. 도 5는 본 개시의 다양한 실시 예에 따른 전자 장치의 상세한 구성을 설명하기 위한 블록도이다. 도 5를 참조하면, 전자 장치는 통신부 및 프로세서 외에도 스토리지, 사용자 입력부, 입출력 포트, 디스플레이, 오디오 출력부 및 방송 수신부 중 적어도 하나를 더 포함할 수있다. 사용자 입력부는 전자 장치가 사용자로부터 명령 또는 정보를 포함하는 사용자 입력을 수신할 수 있 게 하는 구성이다. 전자 장치는 사용자 입력부를 통해 적어도 하나의 텍스트를 입력받을 수 있으며, 전자 장치가 제공한 추천 메시지를 선택하는 사용자 명령을 수신할 수도 있다. 또한, 사용자 입력부를 통해 추천 메시 지를 전송하라는 사용자 명령을 수신할 수도 있다. 이를 위해, 사용자 입력부는 하나 이상의 버튼, 키보드, 마우스(이상 도시되지 않음) 등을 포함할 수 있다. 또한, 사용자 입력부는 사용자 입력/명령을 터치 형태로 입력받기 위해 디스플레이와 함께 구 현된 터치 패널(도시되지 않음) 또는 별도의 터치 패드(도시되지 않음)를 포함할 수 있다. 사용자 입력부는 적어도 하나의 텍스트 또는 명령을 음성 형태로 입력받기 위해 마이크(도시되지 않음)를 포함할 수도 있다. 입출력 포트를 통해, 전자 장치는 외부로부터 텍스트, 이미지, 음성에 대한 신호를 수신하거나 또는 외부에 텍스트, 이미지, 음성에 대한 신호를 전송할 수 있다. 이를 위해, 입출력 포트는 HDMI 포트, 디스플레이 포트, RGB 포트, DVI(Digital Visual Interface) 포트, 썬더볼트 및 컴포넌트 포트 등 유선 포트로 구현될 수 있다. 또는, 입출력 포트는 와이파이나 블루투스 통 신 등 무선 통신을 위한 포트로 구현될 수도 있다. 입출력 포트는 USB와 같은 인터페이스 모듈을 포함할 수 있으며, 이 같은 인터페이스 모듈을 통해 PC와 같 은 외부 단말 장치와 물리적으로 연결되어 텍스트, 음성, 이미지에 대한 데이터를 송수신하거나 혹은 펌웨어 업 그레이드를 수행하기 위한 펌웨어 데이터를 송수신할 수도 있다. 디스플레이는 하나 이상의 이미지를 표시하기 위한 구성이다. 이를 위해, 디스플레이는 LCD(Liquid Crystal Display), PDP(Plasma Display Panel), OLED(Organic Light Emitting Diodes), TOLED(Transparent OLED) 등으로 구현될 수 있다. LCD로 구성되는 경우, 디스플레이 내에는 a-si TFT, LTPS(low temperature poly silicon) TFT, OTFT(organic TFT) 등과 같은 형태로 구현될 수 있는 구동 회로(도시되지 않음), 백라이트 유닛(도시되지 않음) 등도 함께 포함될 수 있다. 한편, 디스플레이는 사용자의 터치 조작을 감지할 수 있는 터치 패널이 포함된 터치스크린 형태로 구현될 수도 있으며, 이 경우 사용자 입력부에 포함되는 것으로 볼 수 있다. 프로세서는 외부 전자 장치(도시되지 않음)와 메시지를 송수신하기 위한 애플리케이션의 화면을 표시하도 록 디스플레이를 제어할 수 있다. 이 경우, 프로세서는 입력된 텍스트, 텍스트 입력 이전에 송수신된 메시지, 입력된 텍스트에 대응되는 단어 및 텍스트 입력 이전에 송수신된 메시지의 문맥 정보에 따라 획득된 추 천 메시지 중 적어도 하나를 표시하도록 디스플레이를 제어할 수 있다. 오디오 출력부는 음성을 출력하기 위한 구성으로서, 스피커 및/또는 헤드폰/이어폰 출력 단자(도시되 지 않음)로 구현될 수 있다. 프로세서는 획득된 추천 메시지를 음성 형태로 출력하도록 오디오 출력부를 제어할 수 있다. 방송 수신부는 방송 컨텐츠에 대한 신호를 수신할 수 있다. 방송 컨텐츠는 텍스트, 영상, 오디오 등에 대 한 데이터를 포함할 수 있으며, 방송 수신부는 지상파 방송, 케이블 방송, 위성 방송, 인터넷 방송 등과 같이 다양한 소스로부터 방송 컨텐츠 신호를 수신할 수 있다. 방송 수신부는 방송국으로부터 전송되는 방송 컨텐츠를 수신하기 위해 튜너(미도시), 복조기(미도시), 등 화기(미도시) 등과 같은 구성을 포함하는 형태로 구현될 수 있다. 이하 도 6 내지 도 7을 통해서는, 본 개시에 따른 전자 장치의 제어 방법을 설명한다. 도 6은 본 개시의 일 실시 예에 따른 전자 장치의 제어 방법을 설명하기 위한 순서도이다. 도 6을 참조하면, 본 제어 방법은, 텍스트가 입력되면, 기계 학습된 언어 모델을 이용하여 입력된 텍스트를 포 함하는 추천 메시지를 획득할 수 있다(S610). 그리고, 추천 메시지를 전송하기 위한 사용자 입력이 수신되면, 추천 메시지를 외부 전자 장치로 전송할 수 있다(S620). 텍스트는 전자 장치에 대한 사용자 명령에 의해 전자 장치에 직접 입력되거나 또는 다른 외부 장치(도시되지 않음)에 입력된 후 그 정보가 전자 장치에 전송된 것일수도 있다. 추천 메시지를 획득함(S610)에 있어, 입력된 텍스트 및 텍스트 입력 이전에 전자 장치와 외부 전자 장치 간에 송수신된 하나 이상의 메시지를 언어 모델에 적용하여, 추천 메시지를 획득할 수도 있다. 구체적으로, 텍스트 입력 이전에 송수신된 하나 이상의 메시지에 대한 문맥 정보를 획득하고, 입력된 텍스트에 대응되는 단어 및 획득된 문맥 정보를 이용하여, 단어를 첫 단어로 포함하고 텍스트 입력 이전에 송수신된 하나 이상의 메시지에 이어지는 추천 메시지를 획득할 수도 있다. 예를 들어, \"I\"에 대응되는 텍스트가 입력되기 전에 \"How are you?\"라는 메시지가 외부 전자 장치로부터 전자 장치에 수신된 경우, \"How are you?\"에 대한 문맥 정보 및 입력된 \"I\"를 이용하여, \"I\"를 첫 단어로 포함하고 \"How are you?\"라는 메시지에 이어지는 \"I am fine.\"이라는 문장을 추천 메시지로서 획득할 수 있다. 문맥 정보는, 하나 이상의 특정 메시지에 포함되는 단어 및 문장 부호에 대한 정보일 수 있다. 구체적으로, 문 맥 정보는, 특정 메시지에 포함되는 각 단어의 내용, 품사 및 순서에 대한 정보일 수 있다. 이러한 문맥 정보는, 기학습된 언어 모델을 이용하여 획득될 수도 있다. 그리고, 본 제어 방법은, 입력된 제1 텍스트에 대응되는 제1 단어, 제1 텍스트 입력 이후에 입력된 제2 텍스트 에 대응되는 제2 단어 및 제1 텍스트 입력 이전에 전자 장치 및 외부 전자 장치 간에 송수신된 하나 이상의 메 시지에 기초하여, 제1 단어 및 제2 단어를 포함하는 추천 메시지를 획득할 수도 있다. 이때, 추천 메시지는, 제 1 단어를 첫 번째 단어로, 제2 단어를 두 번째 단어로 포함할 수 있다. 예를 들어, \"How are you?\"라는 메시지가 외부 전자 장치로부터 전자 장치에 수신된 후 \"I\"에 대응되는 텍스트 및 \"am\"에 대응되는 텍스트가 순차적으로 입력된 경우, \"How are you?\"에 대한 문맥 정보 및 입력된 \"I\" 및 \"am\"을 이용하여, \"I\"를 첫 번째 단어로 포함하고 \"am\"을 두 번째 단어로 포함하며 \"How are you?\"라는 메시지 에 이어지는 \"I am fine.\"이라는 문장을 추천 메시지로서 획득할 수 있다. 그리고, 본 제어 방법은, 복수의 문장(sentence)을 포함하는 기본 데이터로 임베딩 행렬(embedding matrix) 및 소프트맥스 행렬(softmax matrix)을 포함하는 언어 모델을 RNN(Reccurent Neural Network) 학습시킬 수 있다. 이때, 복수의 문장 중 제1 문장에 포함된 하나 이상의 단어 및 문장 부호 각각에 대응되는 복수의 제1 벡터를 제1 랜덤 행렬에 기초하여 벡터 공간으로 매핑시킨 복수의 제1 데이터를 획득하고, 제1 데이터에 기초하여 제2 데이터를 생성하며, 제2 데이터를 제2 랜덤 행렬에 기초하여 복원한 복원 벡터를 획득하고, 제1 문장 다음의 제 2 문장에 포함된 첫번째 단어에 대응되는 제2 벡터 및 복원 벡터 간의 오차에 기초하여 제1 랜덤 행렬 및 제2 랜덤 행렬의 엘리먼트를 업데이트할 수 있다. 그리고, 업데이트된 제1 랜덤 행렬 및 제2 랜덤 행렬을 각각 임베 딩 행렬 및 소프트맥스 행렬로서 전자 장치의 스토리지에 저장할 수 있다. 이 경우, 복수의 제1 벡터 및 제2 벡터 각각을 제1 랜덤 행렬에 기초하여 벡터 공간으로 매핑시킨 복수의 제3 데이터를 획득하고, 복수의 제3 데이터에 기초하여 제4 데이터를 생성하며, 제4 데이터를 제2 랜덤 행렬에 기초 하여 복원한 복원 벡터를 획득하고, 제2 문장의 두번째 단어에 대응되는 제3 벡터 및 제4 데이터를 복원한 복원 벡터 간의 오차에 기초하여 제1 랜덤 행렬 및 제2 랜덤 행렬의 엘리먼트를 업데이트할 수도 있다. 그리고, 앞서 와 마찬가지로, 업데이트된 제1 랜덤 행렬 및 제2 랜덤 행렬을 각각 임베딩 행렬 및 소프트맥스 행렬로서 전자 장치의 스토리지에 저장할 수 있다. 또한, 제1 문장만이 아니라, 복수의 문장들 전부에 기초하여 제1 랜덤 행렬 및 제2 랜덤 행렬 각각의 엘리먼트 를 업데이트할 수 있다. 이때, 제1 문장에 기초하여 업데이트하는 앞서 설명된 방식과 마찬가지 방식을 이용할 수 있다. 그리고, 업데이트된 제1 랜덤 행렬 및 제2 랜덤 행렬을 각각 임베딩 행렬 및 소프트맥스 행렬로서 전 자 장치의 스토리지에 저장할 수 있다. 한편, 상술한 학습 과정들에 있어 임베딩 행렬 및 소프트맥스 행렬은 전자 장치의 스토리지에 저장되는 것으로 서술하였으나, 다른 예로, 전자 장치가 아닌 다른 외부 장치를 통해 언어 모델이 학습된 결과 외부 장치의 스토 리지에 학습된 임베딩 행렬 및 소프트맥스 행렬이 저장되어 이용될 수도 있다. 도 7은 본 개시의 일 실시 예에 따른 전자 장치의 제어 방법이 학습된 언어 모델을 이용하여 추천 메시지(문 장)를 획득하는 구체적인 일 예를 설명하기 위한 순서도이다. 도 7을 참조하면, 본 제어 방법은, 텍스트 입력 이전에 송수신된 하나 이상의 메시지에 대응되는 문장 및 텍스 트 입력에 대응되는 단어를 언어 모델에 적용하여, 입력된 텍스트에 대응되는 단어 다음의 제1 예상 단어를 판단할 수 있다(S710). 예로, \"How are you?\"라는 메시지가 수신된 이후 \"I\"에 대응되는 텍스트가 입력된 경우, \"How are you?\" 및 \"I\"를 언어 모델에 적용하여 \"I\" 다음의 \"am\"을 제1 예상 단어로 판단할 수 있다. 그리고, 텍스트 입력 이전에 송수신된 하나 이상의 메시지에 대응되는 문장, 입력된 텍스트에 대응되는 단어 및 판단된 제1 예상 단어를 언어 모델에 적용하여, 판단된 제1 예상 단어 다음의 제2 예상 단어를 판단할 수 있다 (S720). 예로, \"How are you?\", \"I\" 및 \"am\"을 언어 모델에 적용하여, \"am\" 다음의 \"fine\"을 제2 예상 단어로 판단할 수 있다. 그리고, 입력된 텍스트에 대응되는 단어, 제1 예상 단어 및 제2 예상 단어를 순차적으로 포함하는 추천 메시지 를 획득할 수 있다(S730). 상술한 예에 따르면, 추천 메시지는 \"I am fine.\"이 된다. 도 6 내지 도 7을 통해 도시 및 설명된 전자 장치의 제어 방법은, 도 2 내지 도 3 및 도 5를 통해 도시 및 설명 된 전자 장치를 통해 구현될 수도 있다. 도 6 내지 도 7을 통해 도시 및 설명된 전자 장치의 제어 방법은, 전자 장치 및 하나 이상의 외부 장치(도 시되지 않음)를 포함하는 시스템을 통해 구현될 수도 있다. 일 예로, 언어 모델의 학습 및 언어 모델을 이용한 추천 메시지의 획득 과정이 서버(도시되지 않음)에서 수행되 는 한편, 전자 장치는 외부 전자 장치(도시되지 않음)와 메시지를 송수신하거나 추천 메시지를 제공하기만 할 수 있다. 구체적으로, 전자 장치는 외부 전자 장치와의 사이에서 송수신된 메시지에 대한 정보 및 입력된 텍스트에 대한 정보를 서버(도시되지 않음)로 전송하고, 서버(도시되지 않음)는 수신된 정보를 언어 모델에 적용하여 추 천 메시지를 획득한 뒤 추천 메시지에 대한 정보를 전자 장치로 전송할 수 있다. 그리고, 전자 장치 는 추천 메시지를 사용자에게 제공할 수 있다. 한편, 이상에서 설명된 다양한 실시 예들은 소프트웨어(software), 하드웨어(hardware) 또는 이들의 조합된 것 을 이용하여 컴퓨터 또는 이와 유사한 장치로 읽을 수 있는 기록 매체 내에서 구현될 수 있다. 하드웨어적인 구현에 의하면, 본 개시에서 설명되는 실시 예들은 ASICs(Application Specific Integrated Circuits), DSPs(digital signal processors), DSPDs(digital signal processing devices), PLDs(Programmable logic devices), FPGAs(field programmable gate arrays), 프로세서(processor), 제어기 (controller), 마이크로 컨트롤러(micro-controllers), 마이크로 프로세서(microprocessor), 기타 기능 수행을 위한 전기적인 유닛(unit) 중 적어도 하나를 이용하여 구현될 수 있다. 일부의 경우에 본 명세서에서 설명되는 실시 예들이 프로세서 자체로 구현될 수 있다. 소프트웨어적인 구 현에 의하면 본 명세서에서 설명되는 절차 및 기능과 같은 실시 예들은 별도의 소프트웨어 모듈들로 구현될 수 있다. 상술한 소프트웨어 모듈들 각각은 본 명세서에서 설명되는 하나 이상의 기능 및 작동을 수행할 수 있다. 한편, 상술한 본 개시의 다양한 실시 예들에 따른 전자 장치에서의 처리동작을 수행하기 위한 컴퓨터 명령 어(computer instructions)는 비일시적 컴퓨터 판독 가능 매체(non-transitory computer-readable medium)에 저장될 수 있다. 이러한 비일시적 컴퓨터 판독 가능 매체에 저장된 컴퓨터 명령어는 특정 기기의 프로세서에 의 해 실행되었을 때 상술한 다양한 실시 예에 따른 전자 장치의 처리 동작을 상술한 특정 기기가 수행하도록 한다. 비일시적 판독 가능 매체란 레지스터, 캐쉬, 메모리 등과 같이 짧은 순간 동안 데이터를 저장하는 매체가 아니 라 반영구적으로 데이터를 저장하며, 기기에 의해 판독(reading)이 가능한 매체를 의미한다. 구체적으로는, 상 술한 다양한 어플리케이션 또는 프로그램들은 CD, DVD, 하드 디스크, 블루레이 디스크, USB, 메모리카드, ROM 등과 같은 비일시적 판독 가능 매체에 저장되어 제공될 수 있다. 또한, 이상에서는 본 발명의 바람직한 실시 예에 대하여 도시하고 설명하였지만, 본 발명은 상술한 특정의 실시"}
{"patent_id": "10-2019-0137841", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "예에 한정되지 아니하며, 청구범위에서 청구하는 본 발명의 요지를 벗어남이 없이 당해 발명이 속하는 기술분야 에서 통상의 지식을 가진 자에 의해 다양한 변형실시가 가능한 것은 물론이고, 이러한 변형실시들은 본 발명의 기술적 사상이나 전망으로부터 개별적으로 이해돼서는 안 될 것이다."}
{"patent_id": "10-2019-0137841", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 개시에 따른 전자 장치가 추천 문장을 제공하는 예를 설명하기 위한 도면, 도 2는 본 개시의 일 실시 예에 따른 전자 장치의 구성을 설명하기 위한 블록도, 도 3은 본 개시의 일 실시 예에 따라 언어 모델이 저장된 스토리지를 포함하는 전자 장치의 구성을 설명하기 위 한 블록도, 도 4는 텍스트 입력 이전에 송수신된 메시지의 문맥 정보에 기초하여 순차적으로 다음 단어를 예상하는 예를 설 명하기 위한 도면, 도 5는 본 개시의 다양한 실시 예에 따른 전자 장치의 상세한 구성을 설명하기 위한 블록도, 도 6은 본 개시의 일 실시 예에 따른 전자 장치의 제어 방법을 설명하기 위한 순서도, 그리고 도 7은 본 개시의 일 실시 예에 따른 전자 장치의 제어 방법이 추천 메시지(문장)를 획득하는 일 예를 설명하기 위한 순서도이다."}
