{"patent_id": "10-2022-0179159", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0098218", "출원번호": "10-2022-0179159", "발명의 명칭": "채널 중첩 기반의 최적 신경망 구조 탐색 방법 및 서버", "출원인": "한국전자통신연구원", "발명자": "조현우"}}
{"patent_id": "10-2022-0179159", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "컴퓨터에 의해 수행되는 방법에 있어서,출력 특징맵에 상응하도록 입력 특징맵 후보군의 공간적 크기 정보를 조정하는 단계;상기 입력 특징맵 후보군을 대상으로 채널 기반의 중첩 연산을 수행하는 단계; 및상기 채널 중첩된 연산 결과인 출력 특징맵을 상기 입력 특징맵 후보군으로 추가 확장시키는 단계를 포함하는,채널 중첩 기반의 최적 신경망 구조 탐색 방법."}
{"patent_id": "10-2022-0179159", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 출력 특징맵의 공간적 크기 정보를 설정하는 단계; 및상기 출력 특징맵의 공간적 크기 정보에 따라 입력 특징맵 후보군에 포함될 입력 특징맵을 결정하는 단계를 더포함하는,채널 중첩 기반의 최적 신경망 구조 탐색 방법."}
{"patent_id": "10-2022-0179159", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,상기 출력 특징맵의 공간적 크기 정보를 설정하는 단계는,PAN 경로 순서를 따르는 해당 노드에서의 출력 특징맵의 공간적 크기 정보에 상응하도록 설정하는 것인,채널 중첩 기반의 최적 신경망 구조 탐색 방법."}
{"patent_id": "10-2022-0179159", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서,상기 출력 특징맵의 공간적 크기 정보에 따라 입력 특징맵 후보군에 포함될 입력 특징맵을 결정하는 단계는, 상기 PAN 경로 순서에 따른 제1 노드가 백본과 연결된 노드인 경우, 상기 백본으로부터의 동일 해상도의 입력 특징맵을 필수 입력 특징맵으로 설정하는 단계; 및상기 백본으로부터의 다른 해상도의 입력 특징맵을 후보 입력 특징맵으로 설정하되, 타 노드로부터의 출력 특징맵이 존재하는 경우 타 노드의 출력 특징맵을 상기 후보 입력 특징맵으로 설정하는 단계를 포함하는,채널 중첩 기반의 최적 신경망 구조 탐색 방법."}
{"patent_id": "10-2022-0179159", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제3항에 있어서,상기 출력 특징맵의 공간적 크기 정보에 따라 입력 특징맵 후보군에 포함될 입력 특징맵을 결정하는 단계는, 상공개특허 10-2024-0098218-3-기 PAN 경로 순서에 따른 제2 노드가 상기 백본이 아닌 제1 노드와 연결된 노드인 경우, 상기 제1 노드로부터의 동일 해상도의 입력 특징맵을 필수 입력 특징맵으로 설정하는 단계; 및상기 백본으로부터의 입력 특징맵을 후보 입력 특징맵으로 설정하되, 상기 제1 노드를 제외한 타 노드로부터의출력 특징맵이 존재하는 경우 타 노드의 출력 특징맵을 상기 후보 입력 특징맵으로 설정하는 단계를 포함하는,채널 중첩 기반의 최적 신경망 구조 탐색 방법."}
{"patent_id": "10-2022-0179159", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서,상기 출력 특징맵에 상응하도록 입력 특징맵 후보군의 공간적 크기 정보를 조정하는 단계는,상기 입력 특징맵 후보군에 포함된 어느 입력 특징맵의 공간적 크기 정보가 상기 출력 특징맵의 공간적 크기 정보보다 더 클 경우, 2 이상의 보폭 크기를 갖는 합성곱 연산 및 11 합성곱 연산을 적용하여 상기 입력 특징맵의 공간적 크기 정보를 상기 출력 특징맵의 공간적 크기 정보와 동일하도록 조정하는 것인,채널 중첩 기반의 최적 신경망 구조 탐색 방법."}
{"patent_id": "10-2022-0179159", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에 있어서,상기 출력 특징맵에 상응하도록 입력 특징맵 후보군의 공간적 크기 정보를 조정하는 단계는,상기 입력 특징맵 후보군에 포함된 어느 입력 특징맵의 공간적 크기 정보가 상기 출력 특징맵의 공간적 크기 정보보다 더 작은 경우, 업 샘플링 연산 및 11 합성곱 연산을 적용하여 상기 입력 특징맵의 공간적 크기 정보를상기 출력 특징맵의 공간적 크기 정보와 동일하도록 조정하는 것인,채널 중첩 기반의 최적 신경망 구조 탐색 방법."}
{"patent_id": "10-2022-0179159", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1항에 있어서,상기 입력 특징맵 후보군들을 대상으로 채널 기반의 중첩 연산을 수행하는 단계는,상기 입력 특징맵 후보군 중 필수 입력 특징맵을 제외한 후보 입력 특징맵들을 대상으로 각각 구조 파라미터 및소프트맥스 함수를 적용하는 단계를 포함하는,채널 중첩 기반의 최적 신경망 구조 탐색 방법."}
{"patent_id": "10-2022-0179159", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서,상기 추가 확장된 입력 특징맵 후보군에 상응하는 각 노드를 포함하는 슈퍼넷을 대상으로 원-샷 뉴럴 네트워크탐색을 위한 학습을 수행하는 단계를 더 포함하는,채널 중첩 기반의 최적 신경망 구조 탐색 방법."}
{"patent_id": "10-2022-0179159", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "공개특허 10-2024-0098218-4-제9항에 있어서,상기 슈퍼넷을 대상으로 원-샷 뉴럴 네트워크 탐색을 위한 학습을 수행하는 단계는,상기 학습이 완료된 슈퍼넷에서 소정 조건을 만족하는 상기 구조 파라미터를 갖는 노드로부터의 입력을 제거하는 단계를 포함하는,채널 중첩 기반의 최적 신경망 구조 탐색 방법."}
{"patent_id": "10-2022-0179159", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제1항에 있어서,상기 채널 중첩된 연산 결과인 출력 특징맵을 대상으로 채널 스케일링 연산을 수행하는 단계를 더 포함하는,채널 중첩 기반의 최적 신경망 구조 탐색 방법."}
{"patent_id": "10-2022-0179159", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "출력 특징맵의 공간적 크기 정보를 설정하는 단계;출력 특징맵에 상응하도록 입력 특징맵 후보군의 공간적 크기 정보를 조정하는 단계;상기 입력 특징맵 후보군들을 대상으로 채널 기반의 중첩 연산을 수행하는 단계;상기 채널 중첩된 연산 결과인 출력 특징맵을 상기 입력 특징맵 후보군으로 추가 확장시키는 단계 및상기 추가 확장된 입력 특징맵 후보군에 상응하는 각 노드를 포함하는 슈퍼넷을 대상으로 원-샷 뉴럴 네트워크탐색을 위한 학습을 수행하는 단계를 포함하는,채널 중첩 기반의 최적 신경망 구조 탐색 방법."}
{"patent_id": "10-2022-0179159", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "채널 중첩 기반의 최적 신경망 구조 탐색을 수행하기 위한 프로그램이 저장된 메모리 및상기 메모리에 저장된 프로그램을 실행시킴에 따라, 출력 특징맵에 상응하도록 입력 특징맵 후보군의 공간적 크기 정보를 조정하고, 상기 입력 특징맵 후보군들을 대상으로 채널 기반의 중첩 연산을 수행한 후, 상기 채널 중첩된 연산 결과인 출력 특징맵을 상기 입력 특징맵 후보군으로 추가 확장시키고, 상기 추가 확장된 입력 특징맵후보군에 상응하는 각 노드를 포함하는 슈퍼넷을 대상으로 원-샷 뉴럴 네트워크 탐색을 위한 학습을 수행하는프로세서를 포함하는,채널 중첩 기반의 최적 신경망 구조 탐색을 수행하는 서버."}
{"patent_id": "10-2022-0179159", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제13항에 있어서,상기 프로세서는 PAN 경로 순서를 따르는 해당 노드에서의 출력 특징맵의 공간적 크기 정보에 상응하도록 상기출력 특징맵의 공간적 크기 정보를 설정하고, 상기 출력 특징맵의 공간적 크기 정보에 따라 입력 특징맵 후보군에 포함될 입력 특징맵을 결정하는 것인,채널 중첩 기반의 최적 신경망 구조 탐색을 수행하는 서버."}
{"patent_id": "10-2022-0179159", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "공개특허 10-2024-0098218-5-제13항에 있어서,상기 프로세서는 상기 PAN 경로 순서에 따른 제1 노드가 백본과 연결된 노드인 경우, 상기 백본으로부터의 동일해상도의 입력 특징맵을 필수 입력 특징맵으로 설정하고, 상기 백본으로부터의 다른 해상도의 입력 특징맵을 후보 입력 특징맵으로 설정하되, 타 노드로부터의 출력 특징맵이 존재하는 경우 타 노드의 출력 특징맵을 상기 후보 입력 특징맵으로 설정하는 것인,채널 중첩 기반의 최적 신경망 구조 탐색을 수행하는 서버."}
{"patent_id": "10-2022-0179159", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제13항에 있어서,상기 프로세서는 상기 PAN 경로 순서에 따른 제2 노드가 상기 백본이 아닌 제1 노드와 연결된 노드인 경우, 상기 제1 노드로부터의 동일 해상도의 입력 특징맵을 필수 입력 특징맵으로 설정하고, 상기 백본으로부터의 입력특징맵을 후보 입력 특징맵으로 설정하되, 상기 제1 노드를 제외한 타 노드로부터의 출력 특징맵이 존재하는 경우 타 노드의 출력 특징맵을 상기 후보 입력 특징맵으로 설정하는 것인,채널 중첩 기반의 최적 신경망 구조 탐색을 수행하는 서버."}
{"patent_id": "10-2022-0179159", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제1항에 있어서,상기 프로세서는 상기 입력 특징맵 후보군에 포함된 어느 입력 특징맵의 공간적 크기 정보가 상기 출력 특징맵의 공간적 크기 정보보다 더 클 경우 2 이상의 보폭 크기를 갖는 합성곱 연산 및 11 합성곱 연산을 적용하고, 상기 출력 특징맵의 공간적 크기 정보보다 더 작은 경우, 업 샘플링 연산 및 11 합성곱 연산을 적용하여, 상기 입력 특징맵의공간적 크기 정보를 상기 출력 특징맵의 공간적 크기 정보와 동일하도록 조정하는 것인,채널 중첩 기반의 최적 신경망 구조 탐색을 수행하는 서버."}
{"patent_id": "10-2022-0179159", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제13항에 있어서,상기 프로세서는 상기 입력 특징맵 후보군 중 필수 입력 특징맵을 제외한 후보 입력 특징맵들을 대상으로 각각구조 파라미터 및 소프트맥스 함수를 적용하는 것인,채널 중첩 기반의 최적 신경망 구조 탐색을 수행하는 서버."}
{"patent_id": "10-2022-0179159", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제13항에 있어서,상기 프로세서는 상기 학습이 완료된 슈퍼넷에서 소정 조건을 만족하는 상기 구조 파라미터를 갖는 노드로부터의 입력을 제거하는 것인,채널 중첩 기반의 최적 신경망 구조 탐색을 수행하는 서버."}
{"patent_id": "10-2022-0179159", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "채널 중첩 기반의 최적 신경망 구조 탐색 방법이 제공된다. 상기 방법은 출력 특징맵에 상응하도록 입력 특징맵 후보군의 공간적 크기 정보를 조정하는 단계; 상기 입력 특징맵 후보군을 대상으로 채널 기반의 중첩 연산을 수 행하는 단계; 및 상기 채널 중첩된 연산 결과인 출력 특징맵을 상기 입력 특징맵 후보군으로 추가 확장시키는 단 계를 포함한다."}
{"patent_id": "10-2022-0179159", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 채널 중첩 기반의 최적 신경망 구조 탐색 방법 및 서버에 관한 것이다."}
{"patent_id": "10-2022-0179159", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "최근 딥러닝 분야에서 많은 인공지능 연구자들은 신경망의 사용 용도, 학습에 사용되는 데이터셋, 실제 추론할 동작 기기에 따라 더 정확하고 빠른 추론이 가능하도록 신경망 구조와 연산 동작 블록을 지속적으로 발전시켜왔 다. 그리고 특정 시나리오에 대해 NAS(Neural Architecture Search)와 같이 더 적합한 신경망 구조를 자동으로 찾아 내고자 하는 시도도 이루어지고 있다. 하지만, 종래 NAS의 경우 대부분 백본의 구조에 대한 연구만이 이루어지고 있어 백본 이후의 구조에 대한 기술 개발이 필요한 실정이다. 선행기술문헌 특허문헌 (특허문헌 0001) 공개특허공보 제10-2022-0125113호(2022.9.14)"}
{"patent_id": "10-2022-0179159", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명이 해결하고자 하는 과제는 합(Sum)이 아닌 중첩(Concatenation) 기반으로 구성되는 신경망 구조에 대해 최적의 구조 탐색이 가능한, 채널 중첩 기반의 최적 신경망 구조 탐색 방법 및 서버를 제공하는 것이다. 다만, 본 발명이 해결하고자 하는 과제는 상기된 바와 같은 과제로 한정되지 않으며, 또다른 과제들이 존재할 수 있다."}
{"patent_id": "10-2022-0179159", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상술한 과제를 해결하기 위한 본 발명의 제1 측면에 따른 채널 중첩 기반의 최적 신경망 구조 탐색 방법은 출력 특징맵에 상응하도록 입력 특징맵 후보군의 공간적 크기 정보를 조정하는 단계; 상기 입력 특징맵 후보군을 대 상으로 채널 기반의 중첩 연산을 수행하는 단계; 및 상기 채널 중첩된 연산 결과인 출력 특징맵을 상기 입력 특 징맵 후보군으로 추가 확장시키는 단계를 포함한다. 또한, 본 발명의 제2 측면에 따른 채널 중첩 기반의 최적 신경망 구조 탐색 방법은 출력 특징맵의 공간적 크기 정보를 설정하는 단계; 출력 특징맵에 상응하도록 입력 특징맵 후보군의 공간적 크기 정보를 조정하는 단계; 상 기 입력 특징맵 후보군들을 대상으로 채널 기반의 중첩 연산을 수행하는 단계; 상기 채널 중첩된 연산 결과인 출력 특징맵을 상기 입력 특징맵 후보군으로 추가 확장시키는 단계 및 상기 추가 확장된 입력 특징맵 후보군에 상응하는 각 노드를 포함하는 슈퍼넷을 대상으로 원-샷 뉴럴 네트워크 탐색을 위한 학습을 수행하는 단계를 포 함한다. 또한, 본 발명의 제3 측면에 따른 채널 중첩 기반의 최적 신경망 구조 탐색을 수행하는 서버는 채널 중첩 기반 의 최적 신경망 구조 탐색을 수행하기 위한 프로그램이 저장된 메모리 및 상기 메모리에 저장된 프로그램을 실 행시킴에 따라, 출력 특징맵에 상응하도록 입력 특징맵 후보군의 공간적 크기 정보를 조정하고, 상기 입력 특징 맵 후보군들을 대상으로 채널 기반의 중첩 연산을 수행한 후, 상기 채널 중첩된 연산 결과인 출력 특징맵을 상 기 입력 특징맵 후보군으로 추가 확장시키고, 상기 추가 확장된 입력 특징맵 후보군에 상응하는 각 노드를 포함 하는 슈퍼넷을 대상으로 원-샷 뉴럴 네트워크 탐색을 위한 학습을 수행하는 프로세서를 포함한다. 상술한 과제를 해결하기 위한 본 발명의 다른 면에 따른 컴퓨터 프로그램은, 하드웨어인 컴퓨터와 결합되어 채 널 중첩 기반의 최적 신경망 구조 탐색 방법을 실행하며, 컴퓨터 판독가능 기록매체에 저장된다. 본 발명의 기타 구체적인 사항들은 상세한 설명 및 도면들에 포함되어 있다."}
{"patent_id": "10-2022-0179159", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "전술한 본 발명의 일 실시예에 의하면, 객체 검출 신경망의 채널 중첩 기반 넥 구조에 대해 효과적으로 최적의 신경망 구조 탐색이 가능하다. 이를 통해, 기존의 백본 위주의 NAS에서 넥은 단순히 정해진 구조를 적용하였던 것에 비해 더욱 정밀한 신경망 생성이 가능하다는 장점이 있다."}
{"patent_id": "10-2022-0179159", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 2, "content": "본 발명의 효과들은 이상에서 언급된 효과로 제한되지 않으며, 언급되지 않은 또 다른 효과들은 아래의 기재로 부터 통상의 기술자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2022-0179159", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명의 이점 및 특징, 그리고 그것들을 달성하는 방법은 첨부되는 도면과 함께 상세하게 후술되어 있는 실시 예들을 참조하면 명확해질 것이다. 그러나, 본 발명은 이하에서 개시되는 실시예들에 제한되는 것이 아니라 서 로 다른 다양한 형태로 구현될 수 있으며, 단지 본 실시예들은 본 발명의 개시가 완전하도록 하고, 본 발명이 속하는 기술 분야의 통상의 기술자에게 본 발명의 범주를 완전하게 알려주기 위해 제공되는 것이며, 본 발명은 청구항의 범주에 의해 정의될 뿐이다. 본 명세서에서 사용된 용어는 실시예들을 설명하기 위한 것이며 본 발명을 제한하고자 하는 것은 아니다. 본 명 세서에서, 단수형은 문구에서 특별히 언급하지 않는 한 복수형도 포함한다. 명세서에서 사용되는 \"포함한다 (comprises)\" 및/또는 \"포함하는(comprising)\"은 언급된 구성요소 외에 하나 이상의 다른 구성요소의 존재 또는 추가를 배제하지 않는다. 명세서 전체에 걸쳐 동일한 도면 부호는 동일한 구성 요소를 지칭하며, \"및/또는\"은 언급된 구성요소들의 각각 및 하나 이상의 모든 조합을 포함한다. 비록 \"제1\", \"제2\" 등이 다양한 구성요소들을 서술하기 위해서 사용되나, 이들 구성요소들은 이들 용어에 의해 제한되지 않음은 물론이다. 이들 용어들은 단 지 하나의 구성요소를 다른 구성요소와 구별하기 위하여 사용하는 것이다. 따라서, 이하에서 언급되는 제1 구성 요소는 본 발명의 기술적 사상 내에서 제2 구성요소일 수도 있음은 물론이다. 다른 정의가 없다면, 본 명세서에서 사용되는 모든 용어(기술 및 과학적 용어를 포함)는 본 발명이 속하는 기술 분야의 통상의 기술자에게 공통적으로 이해될 수 있는 의미로 사용될 수 있을 것이다. 또한, 일반적으로 사용되 는 사전에 정의되어 있는 용어들은 명백하게 특별히 정의되어 있지 않는 한 이상적으로 또는 과도하게 해석되지않는다. 이하에서는 먼저 통상의 기술자의 이해를 돕기 위해 본 발명이 착안된 배경에 대해 설명한 후, 본 발명에 대해 상세히 설명하도록 한다. 대개의 NAS 연구는 백본(backbone; 특징 추출 신경망)의 구조에 대한 연구이며, 비전 분야에서는 주로 이미지 분류(classification)에 백본 구조를 직접 적용할 수 있다. 그런데 객체 검출(object detection) 신경망은 백 본도 중요하지만 그 이후에 백본에서 추출된 특징들을 잘 융합하는 것도 매우 중요하다. 왜냐하면, 이미지 분류 와는 달리 객체 검출을 위해서는 단순히 어떤 객체인지 구분하는데 그치지 않고, 그 객체의 위치를 예측할 수 있어야 하기 때문이다. 현재 좋은 성능을 보이고 있는 대부분의 객체 검출 신경망은 공통적으로 특징 추출 신경망(백본), 특징 병합 신 경망(넥; neck), 그리고 결과 예측 신경망(헤드; head)로 구분할 수 있다. 여기에서, 특징 병합 신경망(이하, '넥'이라 한다)은 특징 추출 신경망(이하, '백본'이라 한다)에서 추출된 여러 해상도의 특징맵을 서로 융합하 여 결과 예측 신경망(이하, '헤드'라 한다)에 전달해 주어야 하며, 이것은 특히 위치 예측의 정확도에 큰 영향 을 미친다. 객체 검출 신경망의 넥 구조에 대해서도 많은 연구자들의 공헌에 힘입어, 초기의 단순히 여러 해상도의 특징맵 을 각각 헤드에 전달하던 방식에서 시작하여, 저해상도의 특징맵을 고해상도의 특징맵에 중첩해가는 FPN(Feature Pyramid Network), 그리고 FPN의 출력 특징맵에 대해 다시 고해상도 특징맵을 저해상도 특징맵에 중첩하는 PAN(Path Aggregation Network), 여기에 일부 경로를 누락시키고 PAN에 백본으로부터 동일 해상도의 특징맵을 추가로 중첩시키는 BiFPN 등으로 발전되고 있다. 이와 같은 넥 구조는 기본적으로 서로 다른 입력을 원소 대 원소로 합하는 것이 아니라 채널 방향으로 중첩합으 로써 다른 해상도의 정보를 유지시키는 역할을 할 수 있다. 하지만, 채널 중첩 기반의 신경망에 대해 자동으로 최적의 구조를 찾아내는 NAS 알고리즘에 대한 연구는 부재한 실정이다. 도 1은 원소 대 원소의 합 기반 NAS를 설명하기 위한 도면이다. 이때, 도 1의 구조는 특정 노드의 입력과 출력 사이에서 복수 개의 연산 후보 중 어느 하나의 연산 후보를 선정하는 것을 목표로 한다. 기존의 합 기반의 원-샷 NAS는 여러 개의 연산 동작(operation) 후보를 두고, 입력 텐서(Tensor, 110)는 어떤 후보의 동작을 수행한 후라도 같은 텐서 크기(채널 높이 너비)의 출력이 나온다는 것을 가정한 다. 그렇지 않으면 테서 사이의 원소 대 원소 합(element-wise sum)이 불가능하기 때문이다. 또한, 여러 후보 연산의 입력을 합한 연산 이후에도 같은 텐서의 크기로 출력된다. 이때, 원소 대 원소의 합은 단순한 합 뿐만이 아닌 각 연산 후보 사이의 가중치를 주어 합하는 가중합(weighted sum)일 수도 있다. 하지만, 객체 검출 신경망의 넥은 백본과는 달리 서로 다른 해상도 사이의 연결 구조가 매우 중요하다. 그리고 위치 정보를 온전히 보존하기 위해서는 특징맵을 합(Sum)하는 것이 아닌 채널 중첩(Concatenation)을 통해 다른 해상도의 특징맵을 병합할 필요가 있다. 그런데 기존의 백본에서의 NAS는 입력 후보군에 대해 합 기반 구조에 대한 알고리즘으로 개발되어 최적의 넥 구조를 탐색하는 데는 부적합하다. 이에, 본 발명의 일 실시예는 객체 검출 신경망의 넥 구조와 같이 채널 중첩 기반으로 구성되는 신경망 구조에 대해 자동으로 최적의 구조 탐색이 가능하도록 하는 새로운 알고리즘을 제시한다. 이하, 도 2 내지 도 12를 참조하여 본 발명의 일 실시예에 따른 채널 중첩 기반의 최적 신경망 구조 탐색 방법 에 대해 설명하도록 한다. 도 2는 본 발명의 일 실시예에 따른 채널 중첩 기반의 최적 신경망 구조 탐색 방법(이하, 최적 신경망 구조 탐 색 방법)의 순서도이다. 본 발명의 일 실시예에 따른 최적 신경망 구조 탐색 방법은 출력 특징맵의 공간적 크기 정보를 설정하는 단계와 (S210), 출력 특징맵에 상응하도록 입력 특징맵 후보군의 공간적 크기 정보를 조정하는 단계와(S220), 상기 입 력 특징맵 후보군들을 대상으로 채널 기반의 중첩 연산을 수행하는 단계와(S230), 상기 채널 중첩된 연산 결과인 출력 특징맵을 대상으로 채널 스케일링 연산을 수행하는 단계와(S240), 상기 채널 중첩된 연산 결과인 출력 특징맵을 상기 입력 특징맵 후보군으로 추가 확장시키는 단계(S250) 및 추가 확장된 입력 특징맵 후보군에 상응 하는 각 노드를 포함하는 슈퍼넷을 대상으로 원-샷 뉴럴 네트워크 탐색을 위한 학습을 수행하는 단계(S260)를 포함하여 수행된다. 한편, 도 2에 도시된 각 단계들은 후술하는 채널 중첩 기반의 최적 신경망 구조 탐색을 수행하는 서버에 의해 수행되는 것으로 이해될 수 있으나 반드시 이에 한정되는 것은 아니다. 도 3은 본 발명의 일 실시예에서 채널 중첩 기반의 NAS를 설명하기 위한 도면이다. 이때, 도 3의 구조는 채널 중첩 노드의 입력으로 이전 노드들 중 어느 노드들이 연결될지 정하는 것을 목표로 한다. 본 발명의 일 실시예에서의 채널 중첩 기반의 one-shot NAS는 여러 개의 연산 동작 후보의 출력 결과(32 0)가 반드시 동일한 텐서 모양을 가지고 있지 않을 수도 있다. 즉, 공간적인 크기(높이 너비)만 동일하면 된 다. 이 경우 각 후보 연산의 출력값들은 합이 아닌 채널 방향으로 중첩해야 한다. 그러므로 여러 후 보 연산들의 입력(후보 입력 특징맵)을 중첩한 연산 이후에는 채널 길이가 늘어난 텐서의 크기로 출력된다. 따라서, 중첩 연산을 지속적으로 진행하는 경우, 뒤로 갈수록 채널 방향이 무한정 길어지는 결과를 가질 수 있 다. 한편, 도 3에서의 모든 후보 입력 특징맵들은 이미 출력 텐서(출력 특징맵)의 공간적 크기 정보(높이 및 너비) 에 맞추어 다운샘플링 또는 업 샘플링이 완료된 상태이다. 도 4는 본 발명의 일 실시예에서의 중첩 노드의 구성을 설명하기 위한 도면이다. 본 발명의 일 실시예는 전술한 채널 방향이 무한정 길어지는 문제를 극복하기 위하여, 채널 중첩된 연산 결과인 출력 특징맵을 대상으로 채널 스케일링 연산을 수행하는 것을 특징으로 한다(S240). 일 실시예로, 가장 간단한 채널 스케일링 방법으로는 1 1 커널 크기 및 커널 보폭(kernel stride) 1을 가지는 합성곱을 이용하여 공간적 크기 정보(h, w)는 유지시키되 출력 채널의 길이만 변경할 수 있다. 도 5는 컨볼루션 신경망 네트워크를 설명하기 위한 도면이다. 도 6은 업 샘플링 및 채널 감소 예시를 도시한 도 면이다. 한편, 기존의 성공적인 컨볼루션 신경망 네트워크(CNN; Convolution Neural Network)의 경우 공간적 크기(높이, 너비)가 변경될 때, 이에 상응하여 채널도 스케일링하는 것을 알 수 있다. 예를 들어, 합성곱 연산을 하는 경우 높이, 너비가 반으로 줄어들게 될 때, 그 합성곱 연산의 출력 채널은 2배가 늘어나도록 설정할 수 있다. 역으로, 업 샘플링(up-sampling) 연산을 통해 특징 맵의 공간적 크기(높이, 너비)를 2배로 증가시킬 경우는 출력 채널을 줄이기 위한 별도의 연산을 두었다. 참고로, 합성곱 연산 후 출력 텐서의 공간적 크기(높이, 너비)는 합성곱 커널이 이동하는 보폭에 따라 달라진다. 예를 들어, 보폭이 1이면 입력 텐서와 동일한 크기의 텐서가 출력되며, 보폭이 2 이상이면 더 작은 크기의 텐서가 출력된다. 또한, 합성곱 연산 후 출력 텐서의 채널 길이는 합성곱 커널의 개수와 일치한다. 도 7은 본 발명의 일 실시예에서의 샘플링 구조를 설명하기 위한 도면이다. 본 발명의 일 실시예는 다운 샘플링 및 업 샘플링 수행을 위한 구조를 도 7과 같이 일관성 있게 구성하였다. 즉, 다운(또는 업) 샘플링 연산과 채널 스케일링 연산으로 구성하였다. 여기에서 다운(또는 업) 샘플링 연산은 입력된 텐서의 채널과 동일한 길이의 텐서를 출력한다(701, 702). 또한, 채널 스케일링 연산은 입력된 텐서의 공간적 크기 정보와 동일한 공간적 크기 정보를 갖는 텐서를 출력한다 (711, 712). 이때, 도 5에서 설명한 바와 같이 다운 샘플링시 합성곱 연산만으로도 채널을 증가시킬 수 있지만, 본 발명의 일 실시예는 업 샘플링과의 구조를 대칭적으로 만들기 위해 다운 샘플링에서의 합성곱에서는 채널을 변동시키지 않고 별도의 1 1 합성곱을 추가하였다. 도 8은 본 발명의 일 실시예에 따른 최적 신경망 구조 탐색을 위한 특징 병합 셀 구조를 설명하기 위한 도면이 다. 객체 검출 신경망의 넥 구조는 보통 서로 다른 공간적 크기 정보를 가지는 특징맵을 하나의 공간적 크기 정보를 갖는 특징맵으로 중첩하여 만들게 된다. 도 8은 이와 같은 과정을 도시한 것으로, 본 발명에서 제안하는 채널 중첩 기반 최적 신경망 구조 탐색을 위한 기본 셀(cell) 구조이다. 먼저, 출력 특징맵의 공간적 크기 정보를 설정한다(S210, 출력 해상도 설정). 다음으로, 출력 특징맵에 상응하도록 입력 특징맵 후보군의 공간적 크기 정보를 조정한다(S220, 입력 해상 도 조정). 이때, 단계 S220는 해상도 조정 및 채널 스케일링을 통해 공간적 크기 정보를 조정하는 것 이며, 경우에 따라 복수 회 수행될 수도 있다. 일 실시예로 단계 S220에서는 입력 특징맵 후보군에 포함된 어느 입력 특징맵의 공간적 크기 정보가 출력 특징 맵의 공간적 크기 정보보다 더 클 경우, 2 이상의 보폭 크기를 갖는 합성곱 연산 또는 해당 합성곱이 포함된 연 산 집합을 이용하여 공간적 크기를 감소시킨다. 이후, 1 1 합성곱 연산을 적용하여 채널의 길이를 늘림으로써 입력 특징맵의 공간적 크기 정보를 출력 특징맵의 공간적 크기 정보와 동일하도록 조정할 수 있다. 이와 달리, 입력 특징맵 후보군에 포함된 어느 입력 특징맵의 공간적 크기 정보가 출력 특징맵의 공간적 크기 정보보다 더 작은 경우, 업 샘플링 연산을 이용하여 공간적 크기를 증가시킨다. 이후, 1 1 합성곱 연산을 적용 하여 채널의 길이를 줄임으로써 입력 특징맵의 공간적 크기 정보를 출력 특징맵의 공간적 크기 정보와 동일하도 록 조정할 수 있다. 다음으로, 입력 특징맵 후보군을 대상으로 채널 기반의 중첩 연산을 수행한다(S230, 입력 중첩). 단계 S230에서는 입력 특징맵 후보군을 모두 중첩 연산의 입력으로 넣는다. 이때, 각 입력은 동일한 공간적 크기를 가지므로 채널 길이로 중첩된다. 다음으로, 채널 중첩된 연산 결과인 특징맵을 대상으로 채널 스케일링 연산을 수행하며, 이 과정에서는 1 1 합성곱을 이용하여 채널의 길이를 줄인다(S240, 출력 채널 감소). 다음으로, 채널 중첩된 연산 결과인 출력 특징맵을 입력 특징맵 후보군으로 추가 확장시킨다(S250, 입력 특징맵 후보군 확장). 도 9는 본 발명의 일 실시예에서의 PAN 구조를 따르는 노드 선택 순서의 일 예시를 도시한 도면이다. 한편, 본 발명의 일 실시예는 출력 특징맵의 공간적 크기 정보를 설정하는 S210 단계를 수행함에 있어서 완전히 임의의 노드를 선택하여 해당 노드에 상응하는 공간적 크기 정보로 설정하는 것이 아니라, 다음과 같은 제약을 두어 설정할 수 있다. 먼저, 출력 특징맵의 해상도는 임의로 설정하는 것이 아닌, PAN 경로 순서를 따르는 해당 노드에서의 출력 특징 맵의 공간적 크기 정보에 상응하도록 설정할 수 있다. 일 예로, 도 9에서 번호로 나타낸 노드(셀)을 순서대로 선택할 수 있다. 이때, 도 9에서의 숫자가 쓰인 노드는 채널 중첩이 포함된 노드를 의미하며, 숫자는 해당 노드 를 선택하는 순서를 의미한다. 또한, 특징 병합 부분(넥)이 없다 하더라도 반드시 필요한 경로는 해당 노드의 입력으로 언제나 선택된다고 가 정하였다. 따라서, 도 9에서 실선으로 표시된 화살표는 반드시 입력(필수 입력 특징맵)으로 들어간다. 이때, 각 중첩 노드에 대한 필수 입력 특징맵은 동일한 공간적 크기 정보를 갖는 특징맵이며, 가장 최근에 생성된 노드로 부터 출력되는 것이다. 또한, 필수 입력 특징맵 이외의 후보 입력 특징맵(도 10에서의 점선)들은 구조 파라미터를 곱한 후 입력된다. 이때, 구조 파라미터에는 실수값에 소프트맥스(softmax) 함수를 취한다. 이는 구조 파라미터를 0~1 사이의 값으 로 만들고, 모두 합하면 1이 되도록 하여 일종의 확률값 성질을 갖게 하면서 미분 가능한 값이다. 도 10a 내지 10f는 본 발명의 일 실시예에서의 PAN 구조에서의 후보 입력 특징맵을 설정하는 내용을 설명하기 위한 도면이다. 일 실시예로, 본 발명은 출력 특징맵의 공간적 크기 정보에 따라 입력 특징맵 후보군에 포함될 입력 특징맵이 결정된다. 구체적으로 PAN 경로 순서에 따른 제1 노드가 백본과 연결된 노드인 경우, 백본으로부터의 동일 해상도의 입력 특징맵을 필수 입력 특징맵으로 설정한다. 또한, 백본으로부터 다른 해상도의 입력 특징맵을 후보 입력 특징맵 으로 설정한다. 이때, 타 노드로부터의 출력 특징맵이 존재하는 경우 타 노드의 출력 특징맵도 후보 입력 특징 맵으로 설정할 수 있다. 이와 관련하여 도 10a 내지 도 10c를 참조하면, 1번 노드의 필수 입력 특징맵은 백본으로부터 오는 동일 해상도 의 입력이다. 그리고 선택할 수 있는 나머지 후보 입력 특징맵은 백본으로부터 오는 중간 해상도 및 큰 해상도의 입력으로 총 2개(1002, 1003)이다(도 10a). 2번 노드의 필수 입력 특징맵은 백본으로부터 오는 동일 해상도의 입력이다. 그리고 선택할 수 있는 나머 지 후보 입력 특징맵은 백본으로부터 오는 큰 해상도 및 작은 해상도의 입력과(1012, 1013), 1번 노드에서 출력 된 텐서로 총 3개이다(도 10b). 3번 노드의 필수 입력 특징맵은 백본으로부터 오는 동일 해상도의 입력이다. 그리고 선택할 수 있는 나머 지 후보 입력 특징맵은 백본으로부터 오는 중간 해상도 및 작은 해상도의 입력(1022, 1023)과, 1번, 2번 노드에 서 출력된 텐서(1024, 1025)로 총 4개이다(도 10c). 또한, PAN 경로 순서에 따른 제2 노드가 백본이 아닌 제1 노드와 연결된 노드인 경우, 제1 노드로부터의 동일 해상도의 입력 특징맵을 필수 입력 특징맵으로 설정한다. 또한, 백본으로부터의 입력 특징맵을 후보 입력 특징 맵으로 설정한다. 이때, 타 노드로부터의 출력 특징맵이 존재하는 경우 타 노드의 출력 특징맵도 후보 입력 특 징맵으로 설정할 수 있다. 이와 관련하여 도 10d 내지 도 10f를 참조하면, 4번 노드의 필수 입력 특징맵은 3번 노드로부터 오는 동일 해상 도의 입력이다. 그리고 선택할 수 있는 나머지 후보 입력 특징맵은 백본으로부터 오는 3가지 해상도 입력 (1032, 1033, 1034)과, 1번, 2번 노드에서 출력된 텐서(1035, 1036)로 총 5개이다(도 10d). 5번 노드의 필수 입력 특징맵은 2번 노드로부터 오는 동일 해상도의 입력이다. 그리고 선택할 수 있는 나 머지 후보 입력 특징맵은 백본으로부터 오는 3가지 해상도 입력(1042, 1043, 1044)과, 1번, 3번, 4번 노드에서 출력된 텐서(1045, 1046, 1047)로 총 6개이다(도 10e). 6번 노드의 필수 입력 특징맵은 1번 노드로부터 오는 동일 해상도의 입력이다. 그리고 선택할 수 있는 나 머지 후보 입력 특징맵은 백본으로부터 오는 3가지 해상도 입력(1052, 1053, 1054)과, 2번 내지 5번 노드에서 출력된 텐서(1055, 1056, 1057, 1058)로 총 7개이다(도 10f). 도 11은 본 발명의 일 실시예에서 입력 특징맵 후보군의 공간적 크기 정보를 조정하는 과정을 설명하기 위한 도 면이다. 일 실시예로, 본 발명은 출력 특징맵의 공간적 크기 정보가 설정되면, 출력 특징맵에 상응하도록 입력 특징맵 후보군의 공간적 크기 정보를 조정한다(S220). 이때, 입력 특징맵 후보군의 공간적 크기 정보의 조정은 해상도 조정 및 채널 스케일링을 통해 이루어진다. 해상도 조정 과정에서는 입력 특징맵을 대상으로 특징 연산이 수행된다. 특징 연산은 주로 백본에서 사용한 연산 블록을 적용하는 경우가 많다. 예를 들어, 단순한 '합성곱 + 배치정규화 + 활성화 함수' 의 반복일 수도 있고, MobileNet V.2에서 도입한 Bottleneck 구조일 수도 있으며, CSP(Cross Stage Partial network) 형태일 수도 있다. 또한, 다운(또는 업) 샘플링(1112, 1113)은 특징 맵 피라미드 층에 맞추어 단계적으로 수행되도록 하였다. 즉, 다운(또는 업) 샘플링(1112, 1113)을 한 번에 수행할 수도 있지만, 시스템적인 접근을 위해 넥 구조에 따라 2층 이상 해상도 차이가 날 경우 단계적으로 샘플링(1112, 1113)을 수행하는 구조를 택하였다. 또한, 다운(또는 업) 샘플링(1112, 1113)은 채널 길이가 변하지 않게 하도록 샘플링 이후에 채널 증가(또는 감소)를 위한 블록(112 1)을 추가하였다. 도 12는 본 발명의 일 실시예에서의 입력 특징맵 후보군에 대한 구조 파라미터를 적용하는 내용을 설명하기 위 한 도면이다. 본 발명의 일 실시예는 입력 특징맵 후보군을 대상으로 공간적 크기 정보를 조정하면, 입력 특징맵 후보군을 대 상으로 채널 기반의 중첩 연산을 수행한다(S230). 도 12를 참조하면, 필수 입력 특징맵을 제외한 후보 입력 특징맵이 총 N개가 있다고 가정하면, 각 입력은 공간적 크기 정보가 조정된 후 채널 방향으로 중첩된다. 이때, 각 후보 입력 특징맵들은 구조 파라미터값이 곱한 후 중첩된다. 여기에서, 구조 파라미터는 학습이 진행되면서 함께 학습되는 파라미터이 다. 또한, 구조 파라미터에는 실수값에 소프트맥스(softmax) 함수를 취한다. 소프트맥스 함수는 구조 파라미터를 0~1 사이의 값으로 만들고, 모두 합하면 1이 되도록 하여 일종의 확률값 성질을 갖게 하 면서 미분 가능한 값이다. 단계 S230에 따른 채널 기반의 중첩 연산이 완료되면, 채널 스케일링 연산(S240) 및 입력 특징맵 후보군 추가 과정(S250)이 진행되며, 추가 확장된 입력 특징맵 후보군에 상응하는 각 노드를 포함하는 슈퍼넷을 대상으로 원 -샷 뉴럴 네트워크 탐색(One-Shot NAS)을 위한 학습을 수행한다(S260). 구체적으로, 본 발명은 미분 가능한 구조 파라미터를 학습 경로에 포함시켰기 때문에 하강 경사 학습법(SGD; Stochastic Gradient Descent)으로도 원-샷 뉴럴 네트워크 탐색이 가능하다. 즉, 여러 후보군에 대해 모두 학습 하고 비교하는 방식이나, 여러 후보군 중 어떤 조합을 선택하는지를 샘플링하기 위한 유전 알고리즘(evolution algorithm)이나 별도의 강화 학습(reinforcement learning)이 필요 없다. 본 발명의 일 실시예는 하나의 슈퍼 넷(super-net)에 대해 학습함으로써 원-샷 뉴럴 네트워크 탐색이 가능하다. 학습 과정에 있어, 본 발명은 슈퍼넷에 대한 손실 함수를 줄이는 방향으로 학습이 진행되며, 구조 파라미터 값 역시 갱신된다. 이에 따라 도 12의 중첩 노드의 출력 텐서에 대해 특정 입력 후보에 의한 채널의 공헌도는 증가 하고, 다른 입력 후보의 채널의 공헌도는 감소하게 될 것이다. 미리 설정한 학습 횟수나 손실 값 등을 통해 슈 퍼넷 학습을 완료한다. 학습이 완료된 슈퍼넷에 대해 최적의 넥 구조를 도출하는 방식은 다음과 같은 여러 방법을 사용할 수 있으나, 공통적인 목적은 필요 없는 입력을 가지치기(Pruning)하는 것이다. 즉, 본 발명의 일 실시예는 학습이 완료된 슈퍼넷에서 소정 조건을 만족하는 구조 파라미터를 갖는 노드로부터의 입력을 제거할 수 있다. 이때, 소정의 조건으로는, 기준값을 설정하고 기준값 이하의 구조 파라미터 값을 지니는 입력을 제거하는 것일 수 있다. 다른 조건으로는 전체 노드에 대해 구조 파라미터 값 순서대로 입력을 정렬하고, 하위권(예를 들어 하 위 10% 이하)의 입력을 제거하는 것일 수 있다. 또 다른 조건으로는 각 노드에 대해 구조 파라미터 값 순서대로 입력을 정렬한 후, 미리 설정한 입력 개수(예를 들어, 필수 입력을 포함한 2개의 입력)만큼만 남기고 나머지 입 력과의 연결선을 제거하는 것일 수 있다. 최적의 넥 구조를 도출하면, 가지치기를 완료한 구조에 대해 재학습을 수행할 수 있으며, 검증 데이터를 통해 최종 정확도 결과를 도출할 수 있다. 한편, 상술한 설명에서, 단계 S210 내지 S260는 본 발명의 구현예에 따라서, 추가적인 단계들로 더 분할되거나, 더 적은 단계들로 조합될 수 있다. 또한, 일부 단계는 필요에 따라 생략될 수도 있고, 단계 간의 순서가 변경될 수도 있다. 아울러, 기타 생략된 내용이라 하더라도 도 1 내지 도 12의 내용은 도 13의 내용에도 적용될 수 있 다. 이하에서는 도 13을 참조하여 본 발명의 일 실시예에 따른 채널 중첩 기반의 최적 신경망 구조 탐색을 수행하는 서버를 설명하도록 한다. 본 발명의 일 실시예에 따른 서버는 메모리 및 프로세서를 포함하여 구성된다. 메모리에는 채널 중첩 기반의 최적 신경망 구조 탐색을 수행하기 위한 프로그램이 저장된다. 프로세서는 메모리에 저장된 프로그램을 실행시킴에 따라, 출력 특징맵에 상응하도록 입력 특징맵 후보군의 공간적 크기 정보를 조정하고 입력 특징맵 후보군들을 대상으로 채널 기반의 중첩 연산을 수행한다. 그리고 프로세서는 채널 중첩된 연산 결과인 출력 특징맵을 입력 특징맵 후보군으로 추가 확장시키고, 추 가 확장된 입력 특징맵 후보군에 상응하는 각 노드를 포함하는 슈퍼넷을 대상으로 원-샷 뉴럴 네트워크 탐색을 위한 학습을 수행한다. 이상에서 전술한 본 발명의 일 실시예는, 하드웨어인 컴퓨터와 결합되어 실행되기 위해 프로그램(또는 어플리케 이션)으로 구현되어 매체에 저장될 수 있다. 상기 전술한 프로그램은, 상기 컴퓨터가 프로그램을 읽어 들여 프로그램으로 구현된 상기 방법들을 실행시키기 위하여, 상기 컴퓨터의 프로세서(CPU)가 상기 컴퓨터의 장치 인터페이스를 통해 읽힐 수 있는 C, C++, JAVA, Ruby, 기계어 등의 컴퓨터 언어로 코드화된 코드(Code)를 포함할 수 있다. 이러한 코드는 상기 방법들을 실행하는 필요한 기능들을 정의한 함수 등과 관련된 기능적인 코드(Functional Code)를 포함할 수 있고, 상기 기능들 을 상기 컴퓨터의 프로세서가 소정의 절차대로 실행시키는데 필요한 실행 절차 관련 제어 코드를 포함할 수 있 다. 또한, 이러한 코드는 상기 기능들을 상기 컴퓨터의 프로세서가 실행시키는데 필요한 추가 정보나 미디어가 상기 컴퓨터의 내부 또는 외부 메모리의 어느 위치(주소 번지)에서 참조되어야 하는지에 대한 메모리 참조관련 코드를 더 포함할 수 있다. 또한, 상기 컴퓨터의 프로세서가 상기 기능들을 실행시키기 위하여 원격(Remote)에 있는 어떠한 다른 컴퓨터나 서버 등과 통신이 필요한 경우, 코드는 상기 컴퓨터의 통신 모듈을 이용하여 원격에 있는 어떠한 다른 컴퓨터나 서버 등과 어떻게 통신해야 하는지, 통신 시 어떠한 정보나 미디어를 송수신해야 하 는지 등에 대한 통신 관련 코드를 더 포함할 수 있다. 상기 저장되는 매체는, 레지스터, 캐쉬, 메모리 등과 같이 짧은 순간 동안 데이터를 저장하는 매체가 아니라 반 영구적으로 데이터를 저장하며, 기기에 의해 판독(reading)이 가능한 매체를 의미한다. 구체적으로는, 상기 저 장되는 매체의 예로는 ROM, RAM, CD-ROM, 자기 테이프, 플로피디스크, 광 데이터 저장장치 등이 있지만, 이에 제한되지 않는다. 즉, 상기 프로그램은 상기 컴퓨터가 접속할 수 있는 다양한 서버 상의 다양한 기록매체 또는 사용자의 상기 컴퓨터상의 다양한 기록매체에 저장될 수 있다. 또한, 상기 매체는 네트워크로 연결된 컴퓨터 시 스템에 분산되어, 분산방식으로 컴퓨터가 읽을 수 있는 코드가 저장될 수 있다."}
{"patent_id": "10-2022-0179159", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "전술한 본 발명의 설명은 예시를 위한 것이며, 본 발명이 속하는 기술분야의 통상의 지식을 가진 자는 본 발명 의 기술적 사상이나 필수적인 특징을 변경하지 않고서 다른 구체적인 형태로 쉽게 변형이 가능하다는 것을 이해 할 수 있을 것이다. 그러므로 이상에서 기술한 실시예들은 모든 면에서 예시적인 것이며 한정적이 아닌 것으로 이해해야만 한다. 예를 들어, 단일형으로 설명되어 있는 각 구성 요소는 분산되어 실시될 수도 있으며, 마찬가 지로 분산된 것으로 설명되어 있는 구성 요소들도 결합된 형태로 실시될 수 있다. 본 발명의 범위는 상기 상세한 설명보다는 후술하는 특허청구범위에 의하여 나타내어지며, 특허청구범위의 의미 및 범위 그리고 그 균등 개념으로부터 도출되는 모든 변경 또는 변형된 형태가 본 발명의 범위에 포함되는 것으 로 해석되어야 한다."}
{"patent_id": "10-2022-0179159", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 원소 대 원소의 합 기반 NAS를 설명하기 위한 도면이다. 도 2는 본 발명의 일 실시예에 따른 채널 중첩 기반의 최적 신경망 구조 탐색 방법의 순서도이다. 도 3은 본 발명의 일 실시예에서 채널 중첩 기반의 NAS를 설명하기 위한 도면이다. 도 4는 본 발명의 일 실시예에서의 중첩 노드의 구성을 설명하기 위한 도면이다. 도 5는 컨볼루션 신경망 네트워크를 설명하기 위한 도면이다. 도 6은 업 샘플링 및 채널 감소 예시를 도시한 도면이다. 도 7은 본 발명의 일 실시예에서의 샘플링 구조를 설명하기 위한 도면이다. 도 8은 본 발명의 일 실시예에 따른 최적 신경망 구조 탐색을 위한 특징 병합 셀 구조를 설명하기 위한 도면이 다. 도 9는 본 발명의 일 실시예에서의 PAN 구조를 따르는 노드 선택 순서의 일 예시를 도시한 도면이다. 도 10a 내지 10f는 본 발명의 일 실시예에서의 PAN 구조에서의 후보 입력 특징맵을 설정하는 내용을 설명하기 위한 도면이다. 도 11은 본 발명의 일 실시예에서 입력 특징맵 후보군의 공간적 크기 정보를 조정하는 과정을 설명하기 위한 도 면이다. 도 12는 본 발명의 일 실시예에서의 입력 특징맵 후보군에 대한 구조 파라미터를 적용하는 내용을 설명하기 위 한 도면이다. 도 13은 본 발명의 일 실시예에 따른 채널 중첩 기반의 최적 신경망 구조 탐색 서버의 블록도이다."}
