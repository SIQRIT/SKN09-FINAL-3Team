{"patent_id": "10-2023-0021759", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0128780", "출원번호": "10-2023-0021759", "발명의 명칭": "주변 환경을 고려하여 증강 현실 기반으로 마케팅 컨텐츠를 제공하는 방법 및 장치", "출원인": "제이케이앤디 주식회사", "발명자": "이민형"}}
{"patent_id": "10-2023-0021759", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "카메라에서 영상을 획득하는 단계;네트워크를 통한 날씨 정보, GNSS(Global Navigation Satellite System)에 기반한 위치 정보 및 중 상기 영상에 포함된 인물의 컨벌루션 신경망에 기반하여 판단된 자세 정보 중 어느 하나를 확인하는 단계;획득된 상기 영상을 디스플레이에 표시하는 단계; 및상기 날씨 정보, 상기 위치 정보 및 상기 자세 정보 중 하나에 연관되어 미리 설정된 오브젝트를 상기 영상에증강 현실 기반으로 정합하여 상기 디스플레이에 표시하는 단계를 포함하는,증강 현실에 기반한 단말기의 마케팅 컨텐츠 제공 방법."}
{"patent_id": "10-2023-0021759", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1 항에 있어서,상기 오브젝트를 상기 디스플레이에 표시하는 단계는,날씨에 연관되어 미리 설정된 복수의 의류 오브젝트 중 상기 날씨 정보에 매칭되는 의류 오브젝트를 결정하는단계; 및상기 의류 오브젝트를 상기 영상에 증강 현실 기반으로 정합하여 상기 디스플레이에 표시하는 단계를 포함하는,증강 현실에 기반한 단말기의 마케팅 컨텐츠 제공 방법."}
{"patent_id": "10-2023-0021759", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2 항에 있어서, 상기 디스플레이에 표시하는 단계는,인체 객체를 3차원 카메라로 촬영하여 스캔된 스캔 데이터로부터 생성되어 미리 저장된 3차원 모델링 데이터에상기 의류 오브젝트를 피팅하여 디스플레이하는 단계를 포함하는,증강 현실에 기반한 단말기의 마케팅 컨텐츠 제공 방법."}
{"patent_id": "10-2023-0021759", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제2 항에 있어서,상기 날씨 정보에 매칭되는 상기 의류 오브젝트를 결정하는 단계는,상기 날씨 정보에 포함된 계절 정보, 기온 정보, 습도 정보, 강수량 정보 및 일사량 정보를 확인하는 단계;상기 계절 정보, 상기 기온 정보, 상기 습도 정보, 상기 강수량 정보 및 상기 일사량 정보 중 적어도 어느 하나에 기반하여 기온, 습도, 강수량 및 일사량에 연관되어 미리 저장된 상기 의류 오브젝트를 결정하는 단계를 포함하는,증강 현실에 기반한 단말기의 마케팅 컨텐츠 제공 방법.공개특허 10-2024-0128780-3-청구항 5 제4 항에 있어서,상기 의류 오브젝트를 결정하는 단계는,계절, 기온, 습도, 강수량 및 일사량 중 적어도 어느 하나가 원단 두께, 원사 종류 및 의류 길이 중 적어도 어느 하나로 레이블링(labeling)된 훈련 데이터로 훈련된 인공 지능 기반의 학습 모델에, 상기 기온 정보, 상기습도 정보, 상기 강수량 정보 및 상기 일사량 정보 중 적어도 어느 하나를 입력하여 획득한 결과와 연관성이 가장 높은 것으로 판단된 의류에 맵핑된 상기 의류 오브젝트를 결정하는 단계를 포함하는,증강 현실에 기반한 단말기의 마케팅 컨텐츠 제공 방법."}
{"patent_id": "10-2023-0021759", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1 항에 있어서,상기 오브젝트를 상기 디스플레이에 표시하는 단계는,인체 객체를 3차원 카메라로 촬영하여 스캔된 스캔 데이터로부터 생성되어 미리 저장된 복수의 3차원 모델링 데이터 중, 상기 자세 정보에 연관되어 미리 설정된 상기 3차원 모델링 데이터를 상기 영상에 증강 현실 기반으로정합하여 상기 디스플레이에 표시하는 단계를 포함하는,증강 현실에 기반한 단말기의 마케팅 컨텐츠 제공 방법."}
{"patent_id": "10-2023-0021759", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1 항에 있어서,상기 위치 정보를 확인하는 단계는,GNSS 좌표에 기반하여 상기 카메라가 설치된 단말기의 위치를 도심, 산 및 바닷가를 포함하는 미리 설정된 장소유형 중 어느 하나로 결정하는 단계를 포함하고,상기 오브젝트를 상기 디스플레이에 표시하는 단계는,장소에 연관되어 미리 설정된 복수의 의류 오브젝트 중 상기 장소 유형에 매칭되는 의류 오브젝트를 결정하는단계; 및상기 의류 오브젝트를 상기 영상에 증강 현실 기반으로 정합하여 상기 디스플레이에 표시하는 단계를 포함하는,증강 현실에 기반한 단말기의 마케팅 컨텐츠 제공 방법."}
{"patent_id": "10-2023-0021759", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1 항에 있어서,상기 위치 정보를 확인하는 단계는,상기 카메라가 설치된 단말기의 위치가 실내 또는 실외인지를 판단한 결과를 상기 위치 정보로 결정하는 단계를포함하고,상기 오브젝트를 상기 디스플레이에 표시하는 단계는,실내 또는 실외에 연관되어 미리 설정된 복수의 의류 오브젝트 중 상기 위치 정보에 매칭되는 의류 오브젝트를결정하는 단계; 및상기 의류 오브젝트를 상기 영상에 증강 현실 기반으로 정합하여 상기 디스플레이에 표시하는 단계를 포함하는,공개특허 10-2024-0128780-4-증강 현실에 기반한 단말기의 마케팅 컨텐츠 제공 방법."}
{"patent_id": "10-2023-0021759", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "컴퓨터에 의해 실행될 때, 컴퓨터로 하여금 청구항 제 1 항의 방법을 실행하도록 구성된 컴퓨터 프로그램이 저장된 컴퓨터 판독가능 기록매체."}
{"patent_id": "10-2023-0021759", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "영상을 촬영하는 카메라;상기 영상을 표시하는 디스플레이;상기 카메라 및 디스플레이를 제어하는 프로세서; 및상기 프로세서와 전기적으로 연결되고, 상기 프로세서에서 수행되는 적어도 하나의 코드(code)가 저장되는 메모리를 포함하고,상기 메모리는, 상기 프로세서를 통해 실행될 때 상기 프로세서가 네트워크를 통한 날씨 정보, GNSS(Global NavigationSatellite System)에 기반한 위치 정보 및 중 상기 영상에 포함된 인물의 컨벌루션 신경망에 기반하여 판단된자세 정보 중 어느 하나를 확인하고, 상기 날씨 정보, 상기 위치 정보 및 상기 자세 정보 중 하나에 연관되어미리 설정된 오브젝트를 상기 영상에 증강 현실 기반으로 정합하여 상기 영상과 함께 상기 디스플레이에 표시하도록 야기하는 코드를 저장하는,증강 현실에 기반하여 마케팅 컨텐츠를 제공하는 단말기 장치."}
{"patent_id": "10-2023-0021759", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제10 항에 있어서,상기 메모리는, 상기 프로세서를 통해 실행될 때 상기 프로세서가,날씨에 연관되어 미리 설정된 복수의 의류 오브젝트 중 상기 날씨 정보에 매칭되는 의류 오브젝트를 결정하고,상기 의류 오브젝트를 상기 영상에 증강 현실 기반으로 정합하여 상기 디스플레이에 표시하도록 야기하는 코드를 더 저장하는,증강 현실에 기반하여 마케팅 컨텐츠를 제공하는 단말기 장치."}
{"patent_id": "10-2023-0021759", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11 항에 있어서, 상기 메모리는,상기 프로세서를 통해 실행될 때 상기 프로세서가 인체 객체를 3차원 카메라로 촬영하여 스캔된 스캔 데이터로부터 생성되어 미리 저장된 3차원 모델링 데이터에 상기 의류 오브젝트를 피팅하여 디스플레이하도록 야기하는코드를 더 저장하는,증강 현실에 기반하여 마케팅 컨텐츠를 제공하는 단말기 장치."}
{"patent_id": "10-2023-0021759", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "공개특허 10-2024-0128780-5-제11 항에 있어서,상기 메모리는,상기 프로세서를 통해 실행될 때 상기 프로세서가 상기 날씨 정보에 포함된 기온 정보, 습도 정보, 강수량 정보및 일사량 정보를 확인하고, 상기 기온 정보, 상기 습도 정보, 상기 강수량 정보 및 상기 일사량 정보 중 적어도 어느 하나에 기반하여기온, 습도, 강수량 및 일사량에 연관되어 미리 저장된 상기 의류 오브젝트를 결정하도록 야기하는 코드를 더저장하는,증강 현실에 기반하여 마케팅 컨텐츠를 제공하는 단말기 장치."}
{"patent_id": "10-2023-0021759", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제13 항에 있어서,상기 메모리는,상기 프로세서를 통해 실행될 때 상기 프로세서가 기온, 습도, 강수량 및 일사량 중 적어도 어느 하나가 원단두께, 원사 종류 및 의류 길이 중 적어도 어느 하나로 레이블링(labeling)된 훈련 데이터로 훈련된 신경망 기반의 학습 모델에, 상기 기온 정보, 상기 습도 정보, 상기 강수량 정보 및 상기 일사량 정보 중 적어도 어느 하나를 입력하여 획득한 결과와 연관성이 가장 높은 것으로 판단된 의류에 맵핑된 상기 의류 오브젝트를 결정하도록야기하는 코드를 더 저장하는,증강 현실에 기반하여 마케팅 컨텐츠를 제공하는 단말기 장치."}
{"patent_id": "10-2023-0021759", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제10 항에 있어서,상기 메모리는,상기 프로세서를 통해 실행될 때 상기 프로세서가 인체 객체를 3차원 카메라로 촬영하여 스캔된 스캔 데이터로부터 생성되어 미리 저장된 복수의 3차원 모델링 데이터 중 상기 자세 정보에 연관되어 미리 설정된 상기 3차원모델링 데이터를 상기 영상에 증강 현실 기반으로 정합하여 상기 디스플레이에 표시하도록 야기하는 코드를 더저장하는,증강 현실에 기반하여 마케팅 컨텐츠를 제공하는 단말기 장치."}
{"patent_id": "10-2023-0021759", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제10 항에 있어서,상기 메모리는,상기 프로세서를 통해 실행될 때 상기 프로세서가 GNSS 좌표에 기반하여 상기 카메라가 설치된 단말기의 위치를도심, 산 및 바닷가를 포함하는 미리 설정된 장소 유형 중 어느 하나로 결정하고, 장소에 연관되어 미리 설정된복수의 의류 오브젝트 중 상기 장소 유형에 매칭되는 의류 오브젝트를 결정하고, 상기 의류 오브젝트를 상기 영상에 증강 현실 기반으로 정합하여 상기 디스플레이에 표시하도록 야기하는 코드를 더 저장하는,증강 현실에 기반하여 마케팅 컨텐츠를 제공하는 단말기 장치."}
{"patent_id": "10-2023-0021759", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제10 항에 있어서,공개특허 10-2024-0128780-6-상기 메모리는,상기 프로세서를 통해 실행될 때 상기 프로세서가 상기 카메라가 설치된 단말기의 위치가 실내 또는 실외인지를판단한 결과를 상기 위치 정보로 결정하고, 실내 또는 실외에 연관되어 미리 설정된 복수의 의류 오브젝트 중상기 위치 정보에 매칭되는 의류 오브젝트를 결정하고, 상기 의류 오브젝트를 상기 영상에 증강 현실 기반으로정합하여 상기 디스플레이에 표시하도록 야기하는 코드를 더 저장하는,증강 현실에 기반하여 마케팅 컨텐츠를 제공하는 단말기 장치."}
{"patent_id": "10-2023-0021759", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 개시의 일 실시 예에 따른 단말기의 마케팅 컨텐츠 제공 방법은 카메라에서 영상을 획득하는 단계, 네트워크 를 통한 날씨 정보, GNSS(Global Navigation Satellite System)에 기반한 위치 정보 및 중 영상에 포함된 인물 의 컨벌루션 신경망에 기반하여 판단된 자세 정보 중 어느 하나를 확인하는 단계, 획득된 영상을 디스플레이에 표시하는 단계 및 날씨 정보, 위치 정보 및 자세 정보 중 하나에 연관되어 미리 설정된 오브젝트를 영상에 증강 현실 기반으로 정합하여 디스플레이에 표시하는 단계를 포함할 수 있다."}
{"patent_id": "10-2023-0021759", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 증강현실 기반의 마케팅 영상을 제공하는 장치 및 방법에 관한 것으로서, 더욱 상세하게는 날씨, 위 치 또는 실내외 등의 주변 환경을 고려하여 증강현실 기반의 마케팅 영상을 제공하는 장치 및 방법에 관한 것이다."}
{"patent_id": "10-2023-0021759", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "종래 오프라인과 온라인을 함께 묶어 구현하는 온 앤 오프라인(On & Off Line) 스타일의 광고 방법을 개발하는 시도가 있고, 그 결과 한국 등록특허 제10-2395953호와 같이 증강 현실에 기반하여 마케팅 영상을 제공하는 선 행 기술이 존재한다. 선행 기술은 마케팅 컨텐츠로서 가상의 오브젝트를 현실의 카메라 영상과 함께 증강 현실에 기반하여 디스플레 이 함으로써, 소비자의 관심을 증가시킴으로써 해당 마케팅 컨텐츠를 제공한 특정 브랜드에 대한 호감도를 상승 시킬 수 있다. 하지만, 선행 기술은 인체를 스캔한 데이터에 기반하여 가상의 오브젝트를 생성하는 것에만 관심 이 있고, 가상 오브젝트는 미리 설정된 특징이 항상 동일하게 표시됨으로써 소비자의 관심을 지속적으로 유지하 거나 실제 제품의 홍보 효과를 거두기는 어려운 문제점이 있다. 선행기술문헌 특허문헌 (특허문헌 0001) 선행기술: 한국 등록특허공보 제 10-2395953호(2022.05.04. 등록)"}
{"patent_id": "10-2023-0021759", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 개시의 일 실시 예는 마케팅 컨텐츠가 표시되는 단말기의 주변 환경을 고려하여 가상의 오브젝트를 변화시켜 마케팅 컨텐츠를 공급하는 방법 및 장치를 제공한다."}
{"patent_id": "10-2023-0021759", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 개시의 일 실시 예에 따른 마케팅 컨텐츠 제공 방법은 카메라에서 영상을 획득하는 단계, 네트워크를 통한 날씨 정보, GNSS(Global Navigation Satellite System)에 기반한 위치 정보 및 중 상기 영상에 포함된 인물의 컨벌루션 신경망에 기반하여 판단된 자세 정보 중 어느 하나를 확인하는 단계, 획득된 상기 영상을 디스플레이 에 표시하는 단계 및 상기 날씨 정보, 상기 위치 정보 및 상기 자세 정보 중 하나에 연관되어 미리 설정된 오브 젝트를 상기 영상에 증강 현실 기반으로 정합하여 상기 디스플레이에 표시하는 단계를 포함할 수 있다. 본 개시의 일 실시 예에 따른 마케팅 컨텐츠를 제공하는 단말기 장치 는 영상을 촬영하는 카메라, 상기 영상을 표시하는 디스플레이, 상기 카메라 및 디스플레이를 제어하는 프로세서, 상기 프로세서와 전기적으로 연결되고,상기 프로세서에서 수행되는 적어도 하나의 코드(code)가 저장되는 메모리를 포함하고, 상기 메모리는 상기 프 로세서를 통해 실행될 때 상기 프로세서가 네트워크를 통한 날씨 정보, GNSS(Global Navigation Satellite System)에 기반한 위치 정보 및 중 상기 영상에 포함된 인물의 컨벌루션 신경망에 기반하여 판단된 자세 정보 중 어느 하나를 확인하고, 상기 날씨 정보, 상기 위치 정보 및 상기 자세 정보 중 하나에 연관되어 미리 설정된 오브젝트를 상기 영상에 증강 현실 기반으로 정합하여 상기 영상과 함께 상기 디스플레이에 표시하도록 야기하 는 코드를 저장할 수 있다."}
{"patent_id": "10-2023-0021759", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 개시의 실시 예에 따른 마케팅 컨텐츠 제공 방법 및 장치는 주변 환경을 고려하여 가상의 오브젝트를 변경함 으로써, 소비자의 흥미를 지속적으로 유지할 수 있고 다양한 제품을 직접적으로 홍보할 수 있는 효과가 있다."}
{"patent_id": "10-2023-0021759", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 첨부된 도면을 참조하여 본 명세서에 개시된 실시 예를 상세히 설명하되, 도면 부호에 관계없이 동일하거 나 유사한 구성요소는 동일한 참조 번호를 부여하고 이에 대한 중복되는 설명은 생략하기로 한다. 이하의 설명 에서 사용되는 구성요소에 대한 접미사 \"모듈\" 및 \"부\"는 명세서 작성의 용이함만이 고려되어 부여되거나 혼용 되는 것으로서, 그 자체로 서로 구별되는 의미 또는 역할을 갖는 것은 아니다. 또한, 본 명세서에 개시된 실시 예를 설명함에 있어서 관련된 공지 기술에 대한 구체적인 설명이 본 명세서에 개시된 실시 예의 요지를 흐릴 수 있다고 판단되는 경우 그 상세한 설명을 생략한다. 또한, 첨부된 도면은 본 명세서에 개시된 실시 예를 쉽게 이 해할 수 있도록 하기 위한 것일 뿐, 첨부된 도면에 의해 본 명세서에 개시된 기술적 사상이 제한되지 않으며, 본 발명의 사상 및 기술 범위에 포함되는 모든 변경, 균등물 내지 대체물을 포함하는 것으로 이해되어야 한다. 제1, 제2 등과 같이 서수를 포함하는 용어는 다양한 구성요소들을 설명하는데 사용될 수 있지만, 상기 구성요소 들은 상기 용어들에 의해 한정되지는 않는다. 상기 용어들은 하나의 구성요소를 다른 구성요소로부터 구별하는 목적으로만 사용된다. 어떤 구성요소가 다른 구성요소에 \"연결되어\" 있다거나 \"접속되어\" 있다고 언급된 때에는, 그 다른 구성요소에 직접적으로 연결되어 있거나 또는 접속되어 있을 수도 있지만, 중간에 다른 구성요소가 존재할 수도 있다고 이 해되어야 할 것이다. 반면에, 어떤 구성요소가 다른 구성요소에 \"직접 연결되어\" 있다거나 \"직접 접속되어\" 있 다고 언급된 때에는, 중간에 다른 구성요소가 존재하지 않는 것으로 이해되어야 할 것이다.도 1을 참조하여 본 개시의 일 실시 예에 따른 마케팅 컨텐츠 제공 방법을 수행하거나 마케팅 컨텐츠를 제공하 는 단말기 장치를 구동하기 위한 환경을 설명한다. 본 개시의 실시 예에 따른 작물 생육 방법을 수행하거나 작물 생육 장치를 구동하기 위한 환경은 마케팅 컨텐츠 를 제공하는 단말기 장치(이하, '단말기 장치'로 설명한다) 및 서버 장치를 포함할 수 있다. 단말기 장치는 카메라를 포함하고, 카메라에서 촬영된 전방 영상을 디스플레이에 표시한다. 단말기 장치 는 촬영된 영상에 가상의 오브젝트를 상기 촬영된 영상에 증강 현실 기반으로 정합하여 디스플레이에 표시 한다. 가상의 오브젝트는 서버 장치에서 제공하고 단말기 장치에 설치된 증강 현실 소프트웨어에서 생성하여 증강 현실 기반으로 카메라에서 촬영된 영상에 정합된 후 디스플레이에 표시될 수 있다. 단말기 장치 장치는 증강 현실을 지원하는 스마트폰, 태블릿 PC, 카메라 및 소형 디스플레이 장치를 포함하는 글래스형 단말기 (smart glass), HMD(head mounted display)일 수 있다. 일 실시 예에서, 단말기 장치는 단말기 장치가 위치한 장소의 날씨 또는 위치에 기반하여 영상에 정 합되는 가상의 오브젝트를 결정하거나 가상의 오브젝트의 일부를 다른 가상의 오브젝트를 이용 하여 변경한 후, 결정된 오브젝트 또는 일부가 변경된 오브젝트를 카메라에서 촬영된 영상에 정합하여 디스플레 이에 표시할 수 있다. 오브젝트의 일부를 다른 가상의 오브젝트를 이용하여 변경하는 경우, 인체 객체를 3차원 카메라로 촬 영하여 스캔된 스캔 데이터로부터 생성되어 미리 저장된 인체 객체의 3차원 모델링 데이터에 의류 오브젝트 를 피팅하여 디스플레이하는 것일 수 있다. 일 실시 예에서, 단말기 장치는 컨벌루션 신경망이 포함된 딥 러닝 학습 모델에 기반하여 카메라에서 촬영 된 영상에 포함된 인물의 자세를 판단하고, 판단된 자세에 기반하여 영상에 정합되는 가상의 오브젝트 를 결정하거나 가상의 오브젝트의 일부를 변경한 후, 결정된 오브젝트 또는 일부가 변경된 오브젝트를 카 메라에서 촬영된 영상에 정합하여 디스플레이에 표시할 수 있다. 인물의 자세를 판단하는 학습 모델은 CNN(Convolutional Neural Network) 또는 R-CNN(Region based CNN), C- RNN(Convolutional Recursive Neural Network), Fast R-CNN, Faster R-CNN, R-FCN(Region based Fully Convolutional Network), YOLO(You Only Look Once) 또는 SSD(Single Shot Multibox Detector)구조의 신경망 을 포함할 수 있다. 학습 모델은 하드웨어, 소프트웨어 또는 하드웨어와 소프트웨어의 조합으로 구현될 수 있으며, 신경망의 일부 또는 전부가 소프트웨어로 구현되는 경우 신경망을 구성하는 하나 이상의 명령어, 파라미터는 저장부에 저 장되고 메모리에 로딩되어 학습 모델에 적용된 후, 파라미터가 적용된 학습 모델에 카메라에서 촬영된 영 상이 입력될 수 있다. 도 2를 참조하여 본 개시의 일 실시 예에 단말기 장치의 구성을 설명한다. 단말기 장치는 증강 현실에 기반하여 마케팅 컨텐츠를 제공하는 소프트웨어를 서버 장치로부터 전송 받는 통신부, 사용자의 입력을 수신하거나 단말기 장치의 처리 결과를 표시하는 인터페이스부, 카메라에서 촬영한 영상에 포함된 인물의 자세를 판단하는 신경망 또는 날씨 정보에 기반하여 적절한 의류의 파 라미터를 결정하는 학습 모델 등을 로딩하는 메모리, 가상의 오브젝트가 정합된 영상을 표시하는 디스플레 이부, 신경망 또는 학습 모델의 파라미터 등을 저장하거나 가상의 오브젝트를 저장하는 저장부, 영상 을 촬영하는 카메라부, 단말기 장치의 컴포넌트들의 구동을 위한 전력을 공급하는 전원 공급부 및 컴포넌트들을 제어하고 신경망 또는 학습 모델에 영상을 입력하여 결과를 획득하거나 증강 현실 기반으로 영 상을 정합하는 프로세서를 포함할 수 있다. 통신부는 서버 장치로부터 가상의 오브젝트를 증강 현실에 기반하여 디스플레이에 표시하는 소프트웨 어, 영상에 포함된 인물의 자세를 판단하는 컨벌루션 신경망이 포함된 학습 모델을 전송받은 후 저장부에 저장할 수 있다. 일 실시 예에서, 통신부는 다른 사용자 단말 또는 서버 장치와 통신을 수행하기 위한 통신 인터페이 스를 포함할 수 있다. 통신 인터페이스는 서버 장치로부터 증강 현실에 표시될 오브젝트 또는 그 일부를 전송 받을 수 있다. 예를 들어, 가상의 오브젝트가 도 1의 인물인 경우, 통신 인터페이스가 인물 오브젝트 에 피팅되는 의류 오브젝트(147, 149)를 서버 장치로부터 전송 받아 프로세서가 인물 오브젝트 에 피팅하여 디스플레이에 표시할 수 있다. 통신 인터페이스는 무선 통신 인터페이스 또는 유선 통신 인터페이스를 포함할 수 있다. 무선 통신 인터페이스는, 이동통신 모듈, 무선 인터넷 모듈, 근거리 통신 모듈, 위치정보 모듈 중 적어도 하나 를 포함할 수 있다. 이동통신 모듈은, 이동통신을 위한 통신방식인 LTE(Long Term Evolution) 등에 따라 구축된 이동 통신망 상에서 기지국, 외부의 단말, 서버 중 적어도 하나와 무선 신호를 송수신한다. 무선 인터넷 모듈은 무선 인터넷 접속을 위한 모듈로서, 단말기 장치에 내장되거나 외장될 수 있고, WLAN(Wireless LAN), Wi-Fi(Wireless-Fidelity), Wi-Fi(Wireless Fidelity) Direct, DLNA(Digital Living Network Alliance) 등이 사용될 수 있다. 근거리 통신 모듈은 근거리 통신을 통하여 데이터 송수신을 위한 모듈로서, 블루투스(Bluetooth™), RFID(Radio Frequency Identification), 적외선 통신(Infrared Data Association; IrDA), UWB(Ultra Wideband), ZigBee, NFC(Near Field Communication) 등을 사용할 수 수 있다. 위치정보 모듈은 단말기 장치 의 위치를 획득하기 위한 모듈로서, 위성 항법 기술(Global Navigation Satellite System; GNSS)에 기반한 GPS(Global Positioning System) 모듈이거나, 무선 통신 기지국, 무선 액세 스 포인트와의 무선 통신에 기반하여 위치를 획득하는 모듈일 수 있다. 위치정보 모듈은 WiFi 모듈을 포함할 수 있다. 단말기 장치는 사용자의 입력을 받거나 단말기 장치의 처리 결과를 표시하는 인터페이스부를 포 함할 수 있다. 일 실시 예에서, 인터페이스부는 증강 현실 기반으로 현실을 촬영한 영상에 가상의 오브젝트가 위치할 지 점을 지정 받거나, 카메라부를 포함한 단말기 장치의 컴포넌트들을 제어하기 위한 사용자의 입력을 받기 위한 입력 인터페이스 또는 출력 인터페이스를 포함할 수 있다. 입력 인터페이스는 마이크로폰, 사용자로부터 정보를 입력 받기 위한 물리적 버튼, 터치 인터페이스를 포 함하는 사용자 인터페이스(UI: User Interface)를 포함하고, 사용자 인터페이스는 마우스, 키보드뿐 만 아니라 장치에 구현된 기계식, 전자식 인터페이스 등을 포함할 수 있고 사용자의 명령을 입력 가능한 것이라 면 특별히 그 방식과 형태를 한정하지 않는다. 전자식 인터페이스는 터치 입력 가능한 디스플레이로서, 터치 전 극을 포함한다. 출력 인터페이스는 단말기 장치의 출력을 외부에 표출하여 사용자에게 정보를 전달하기 위한 것으로서, 시 각적 출력, 청각적 출력 또는 촉각적 출력을 표출하기 위한 디스플레이, LED, 스피커 등을 포함할 수 있다. 단말기 장치는 다양한 종류의 외부 기기와 연결되어 데이터 전송을 수행하기 위한 주변 장치와 연결을 위 한 인터페이스를 포함할 수 있고, 메모리 카드(memory card) 포트, 외부 장치 I/O(Input/Output) 포트(port) 등을 포함할 수 있다. 메모리는 휘발성 메모리인 DRAM(dynamic random access memory)으로 구현될 수 있고, 저장부에 저장 된 신경망이 포함된 학습 모델 또는 날씨에 연관되어 적합한 의류를 결정하는 랜덤 포레스트 모델을 로딩할 수 있다. 카메라부는 CIS(CMOS image sensor)를 포함하는 적어도 한 개 이상의 카메라를 포함할 수 있고, 단말기 장 치의 전면 또는 후면에 장착되어, 현실 영상을 획득한다. 획득된 영상은 프로세서에서 메모리에 로딩된 컨벌루션 신경망이 포함된 학습 모델에 입력하여 객체를 인식하고, 객체가 인물인 경우 인물의 자세를판단할 수 있다. 카메라는 RGB 센서 카메라 또는 심도 센서 카메라를 포함할 수 있다. RGB 센서 카메라는 스테 레오 비전 카메라일 수 있다. 도 3을 참조하여 본 개시의 일 실시 예에 따른 단말기 장치의 마케팅 컨텐츠 제공 방법을 설명한다. 단말기 장치는 카메라에서 현실의 영상을 획득한다(S110). 단말기 장치는 GNSS 센서에 기반하여 위치 정보를 확인하거나, 통신 인터페이스로 연결된 유선 또는 무선 네트워크를 통하여 날씨 정보를 획득하거나, 카메라에서 획득한 영상을 신경망이 포함된 학습 모델에 입력하여 자세 정보를 결정할 수 있다(S120). 단말기 장치는 GNSS 센서에 기반하여 단말기 장치가 위치한 위치 정보를 확인하는 경우, 위치 정보는 경도, 위도로 표현되는 GNSS 좌표이거나 획득된 좌표를 행정 주소로 변환한 주소 정보일 수 있다. 또는, 위치 정보는 GNSS 좌표에 기반한 위치의 장소 유형일 수 있다. 장소 유형은 도심, 산 및 바닷가를 포함하는 미리 설 정된 장소 유형 중 하나일 수 있다. 단말기 장치는 획득한 GNSS 좌표를 지도 서버(미도시)에 전송하고, 지 도 서버에서 해당 좌표에 연관되어 저장된 지적 용도, 고도 등의 맵핑된 정보를 획득하여 장소 유형의 결정에 이용할 수 있다. 예를 들어, GNSS 좌표가 특정 고도 이상인 경우 해당 위치의 유형을 산으로 결정하거나, GNSS 좌표가 바다로부 터 일정 거리 이내인 경우 해당 위치의 유형을 바닷가로 결정하거나, 지적 용도가 주거지역, 상업지역이거나 변 환한 주소 정보가 생활권인 경우 해당 위치의 유형을 도심으로 결정할 수 있다. 단말기 장치는 통신 인터페이스로 연결된 유선 또는 무선 네트워크를 통하여 날씨 정보를 획득하는 경우, 날씨 정보는 기온 정보, 습도 정보, 강수량 정보 및 일사량 정보일 수 있다. 날씨 정보는 기상 정보 서버 또는 인터넷 포털 서버로부터 전송받을 수 있다. 일사량 정보는 맑음, 흐림, 약간 흐림 등의 정량적 평가를 의미하는 정보일 수 있다. 단말기 장치가 카메라에서 획득한 영상을 신경망이 포함된 학습 모델에 입력하여 자세 정보를 결정하는 경 우, 컨벌루션 신경망은 객체를 인식하는 객체 인식 신경망, 인식된 객체에서 신체 부위에 대한 키포인트 감지 (Keypoint Detection)를 추정하고, 키포인트 감지로부터 자세를 추정하는 자세 추정 신경망을 포함할 수 있다. 키포인트는 관절일 수 있다. 단말기 장치는 카메라에서 획득한 영상을 디스플레이에 표시하고(S130), 날씨 정보, 위치 정보 및 자세 정 보 중 하나에 연관되어 미리 설정된 가상의 오브젝트를 영상에 증강 현실 기반으로 정합하여 디스플레이에 표시 한다(S140). 도 4를 참조하면, 가상의 오브젝트는 인체 객체를 3차원 카메라(310a~310d)로 촬영하여 스캔된 스캔 데이 터로부터 증강 현실에 적합하게 생성한 AR 데이터일 수 있다. AR 데이터는 인체 객체의 스캔 데이터에 리깅화 (Rigging) 모델링, 애니메이션화(Animation) 모델링 및 SNS 플랫폼에 기반하여 증강 현실로 출력하기 위한 블렌 딩(blending)을 적용한 최적화(Optimizing) 모델링이 수행된 데이터일 수 있다. 스캔 데이터는 3차원 모델을 생 성하기 위한 복장을 장착한 인체로부터 생성된 데이터로 구성되고, 인체 이외에 인체에 착용되는 객체가 3차원 모델링된 오브젝트가 인체의 스캔 데이터에 피팅된 후 AR 데이터로 생성될 수 있다. 피팅되는 오브젝트는 의복, 모자, 신발, 액세서리, 시계 등을 포함하는 의류 오브젝트일 수 있다. 단말기 장치가 날씨 정보에 연관되어 미리 설정된 오브젝트를 디스플레이에 표시하는 경우, 일 실시 예에 서 단말기 장치는 날씨 정보를 서버 장치에 전송하여 날씨 정보에 연관된 의류 오브젝트를 전송 받거나, 단말기 장치에 저장된 의류 오브젝트들에 맵핑된 날씨 정보의 파라미터에 기반하여 증강 현실로 표시할 의 류 오브젝트를 결정할 수 있다. 증강 현실 기반으로 표시되는 의류 오브젝트는 날씨 정보에 포함된 계절 정보, 기온 정보, 습도 정보, 강수량 정보 및 일사량 정보 중 어느 하나의 정보 또는 복수의 정보의 정도에 따라 맵핑되어 저장된 서로 다른 의류들 중 어느 하나에 대한 의류 오브젝트일 수 있다. 예를 들어, 기온 정보에 의류 오브젝트가 맵핑된 경우 기온의 범위에 따라 서로 다른 의류 오브젝트가 맵핑되어 저장되어 있고, 그 중 하나가 선택될 수 있다. 의류 오브젝트 는 단말기 장치에 저장되거나 서버 장치로부터 전송 받을 수 있다. 따라서, 종래에 동일한 의류를 착용한 오브젝트가 증강 현실로 표시되어 단순히 소비자들의 특정 브랜드에 대한 호감도를 상승시키는 것뿐만 아 니라 계절 등의 날씨에 적합한 실제 제품의 홍보 효과를 가질 수 있다. 단말기 장치 또는 서버 장치는 날씨 정보에 기반하여 날씨에 적합한 의류의 원단 두께, 원사 종류 및 의류 길이를 결정하고, 결정된 원단 두께, 원사 종류 및 의류 길이와 가장 유사한 의류를 결정한 후, 결정된 의 류에 맵핑된 의류 오브젝트를 인체 오브젝트에 피팅하여 증강 현실에 기반하여 디스플레이에 표시할 수 있다. 도 5를 참조하면, 날씨에 적합한 의류의 원단 두께, 원사 종류 및 의류 길이는 계절, 기온, 습도, 강수량 및 일 사량 중 적어도 어느 하나가 원단 두께, 원사 종류 및 의류 길이 중 적어도 어느 하나로 레이블링(labeling)된 훈련 데이터로 훈련된 인공 지능 기반의 학습 모델에 계절, 기온, 습도, 강수량 및 일사량 중 적어도 어느 하나 를 입력하여 획득될 수 있다. 일 실시 예에서, 날씨에 따라 원단 두께, 원사 종류 및 의류 길이 중 적어도 어느 하나를 추정하는 학습 모델은 멀티 레이블 분류를 수행하는 신경망을 포함하고, 신경망의 최종 레이어는 복수의 분류에 대한 확률을 출력하는 복수의 노드를 포함하고, 최종 레이어의 복수의 노드는 시그모이드 함수 또는 복수의 소프트 맥스 함수가 적용 될 수 있다. 신경망은 멀티 레이블 분류를 수행하는 종래의 알려진 네트워크 구조에 기반할 수 있다. 다른 실시 예에서, 날씨에 따라 원단 두께, 원사 종류 및 의류 길이 중 적어도 어느 하나를 추정하는 학습 모델 은 복수의 트리를 포함하는 랜덤 포레스트 모델에 기반할 수 있다. 랜덤 포레스트 모델이 복수의 트리로 구성된 경우, 원단 두께, 원사 종류 및 의류 길이 중 적어도 어느 하나로 레이블링된 훈련 데이터를 랜덤 샘플링하여 복수의 서브셋(subset)을 구성하고 각각의 서브셋에 대응하는 복수의 미리 설정되거나 훈련 데이터에 따른 깊이 (depth)를 가지는 트리를 생성하도록 훈련될 수 있다. 훈련된 랜덤 포레스트 모델에 기반한 학습 모델에 계절, 기온, 습도, 강수량 및 일사량 중 적어도 어느 하나를 포함하는 날씨에 관한 데이터를 입력하고, 복수의 트리에 서 결정(출력)되는 응답값 중에서 최대 빈도값(Majority-Voting)을 최종 응답값(출력값)으로 결정하여 원단 두 께, 원사 종류 및 의류 길이 중 적어도 어느 하나를 추정할 수 있다. 도 6을 참조하면, 단말기 장치 또는 서버 장치는 날씨에 기반하여 결정된 원단 두께, 원사 종류 및 의류 길이 등의 파라미터와 실제 의류들(621, 623, 625)의 파라미터인 원단 두께, 원사 종류 및 의류 길이와 비 교하여 가장 유사한 의류에 맵핑된 의류 오브젝트를 날씨 정보에 매칭되는 의류 오브젝트로 결정하고, 인체의 가상 오브젝트에 피팅하여 디스플레이에 표시할 수 있다. 단말기 장치 또는 서버 장치는 학습 모델에서 결정된 원단 두께, 원사 종류 및 의류 길이를 값으로 하는 벡터의 유사도 비교를 위해, 거리 기반(L2 norm) 유사도를 측정하거나, 가중치가 적용된 L2 norm에 기반하 여 유사도 또는 코사인(cosine) 유사도 등 종래 알려진 다양한 벡터 유사도 방법을 사용할 수 있다. 일 실시 예로서, 단말기 장치 또는 서버 장치는 장소 유형에 따라 의류 오브젝트를 다르게 결정할 수 있다. 예를 들어, 단말기 장치가 위치한 곳이 바닷가로 결정되는 경우 수영복, 산으로 결정되는 경우 등산 복, 도심으로 결정되는 경우 일상복으로 의류 오브젝트의 대분류를 결정하고, 추가적으로 날씨에 기반하여 특정 대분류에 속한 의류들 중 계절 정보, 기온 정보, 습도 정보, 강수량 정보 및 일사량 정보를 이용하여 앞에서 설 명한 방법으로 더 세부적으로 의류 오브젝트를 결정할 수 있다. 다른 실시 예로서 장소 유형은 실내 또는 실외로 결정될 수 있다. 단말기 장치 또는 서버 장치는 실 내 또는 실외에 따라 의류 오브젝트를 다르게 결정할 수 있다. 예를 들어, 단말기 장치가 위치한 곳이 실 내로 결정되는 경우 잠옷, 속옷 등의 실내복으로 의류 오브젝트의 대분류를 결정할 수 있다. 장소 유형이 실내 로 결정되는 경우, 단말기 장치 또는 서버 장치는 최종 의류 결정에 날씨 정보를 반영하지 않을 수 있다. 장소 유형이 실외로 결정되는 경우, 다시 장소 유형을 구체적으로 GNSS 좌표에 기반하여 세부적으로 결정 한 후 최종 의류 오브젝트가 결정될 수 있다. 단말기 장치는 GNSS 위성의 전파 세기, GNSS 위성의 개수, GNSS 위성의 앙각 정보, 광 센서에서 판단되는 수신 광의 스펙트럼, 단말기 장치가 연결된 WiFi 네트워크 이름 또는 ID 등에 기반하여 단말기 장치 가 위치한 장소의 실내외 여부를 판단할 수 있다. 실내외 판단 방법은 종래에 알려진 다양한 방법을 활용할 수 있다.다른 실시 예로서, 단말기 장치 또는 서버 장치는 카메라에서 촬영된 영상에 포함된 실제 인물의 자 세에 따라 의류 오브젝트를 다르게 결정할 수 있다. 예를 들어, 다시 도 1을 참조하여 설명하면, 단말기 장치 가 영상에 포함된 실제 인물이 미리 설정된 자세들 중 '하이 파이브' 자세로 판단하면, 단말기 장치 는 '하이 파이브'에 대응하는 오브젝트를 저장부에서 로딩하거나 서버 장치로부터 전송 받아 상기 실제 인 물의 자세에 맞게 변형하여 증강 현실 기반으로 표시할 수 있다. 실제 인물의 자세에 맞게 변형은 '하이 파이브'인 경우, 해당 실제 인물에 손을 맞닿는 자세가 되도록 오브젝트의 좌우 반전 처리, 오브젝트의 높이 등 의 크기 변경 등을 의미할 수 있다. 실제 인물이 '하트'자세인 경우, '하트'자세와 미리 연관되어 저장된 오브 젝트를 결정하고, 이를 크기, 위치 등을 변경하여 증강 현실 기반으로 표시할 수 있다. 도 7을 참조하여 설명하면, 단말기 장치가 카메라에서 획득한 영상을 신경망이 포함된 학습 모델에 입력하여 자세 정보를 결정하는 경우, 컨벌루션 신경망은 객체를 인식하는 객체 인식 신경망, 인식된 객체에서 신체 부위에 대한 키포인트 감지(Keypoint Detection)를 추정하고, 키포인트 감지로부터 자세를 추정하는 자세 추정 신경망을 포함할 수 있고, 서로 분리되어 구성될 수 있다. 키포인트는 관절일 수 있다. 자세 추정 신경망은 객체 인식 신경망에서 바운딩 박스로 구분된(segmented) 인물의 영역을 입력받아, 신 체 부위에서 관절로 예측된 신뢰도 값 분포의 정점을 이용하여 2차원 좌표로 구성하고, 2차원 좌표를 이용하여 스켈레톤 모델을 구성할 수 있다. 단말기 장치는 스켈레톤 모델의 파라미터들(각 관절 사이의 각도 등)에 미리 설정된 자세로 레이블링(labeling)된 훈련 데이터로 자세 추정 신경망에 카메라에서 획득한 인물의 스켈레톤 모델의 특징점들을 입력하여 자세를 추정할 수 있다. 단말기 장치는 미리 설정된 몇 가지 유형의 자세 중 하나로 인물의 자세 정보를 결정할 수 있다. 예를 들어, 자세는 하이 파이브 동작, 하트 표시 동작 등 일 수 있다. 전술한 본 개시는, 프로그램이 기록된 매체에 컴퓨터가 읽을 수 있는 코드로서 구현하는 것이 가능하다. 컴퓨터 가 읽을 수 있는 매체는, 컴퓨터 시스템에 의하여 읽혀질 수 있는 데이터가 저장되는 모든 종류의 기록장치를 포함한다. 컴퓨터가 읽을 수 있는 매체의 예로는, HDD(Hard Disk Drive), SSD(Solid State Disk), SDD(Silicon Disk Drive), ROM, RAM, CD-ROM, 자기 테이프, 플로피 디스크, 광 데이터 저장 장치 등이 있다. 또한, 상기 컴 퓨터는 각 장치의 프로세서를 포함할 수도 있다. 한편, 상기 프로그램은 본 개시를 위하여 특별히 설계되고 구성된 것이거나 컴퓨터 소프트웨어 분야의 통상의 기술자에게 공지되어 사용 가능한 것일 수 있다. 프로그램의 예에는, 컴파일러에 의하여 만들어지는 것과 같은 기계어 코드뿐만 아니라 인터프리터 등을 사용하여 컴퓨터에 의해서 실행될 수 있는 고급 언어 코드도 포함될 수 있다. 본 개시의 명세서(특히 특허청구범위에서)에서 \"상기\"의 용어 및 이와 유사한 지시 용어의 사용은 단수 및 복수 모두에 해당하는 것일 수 있다. 또한, 본 개시에서 범위(range)를 기재한 경우 상기 범위에 속하는 개별적인 값 을 적용한 발명을 포함하는 것으로서(이에 반하는 기재가 없다면), 발명의 상세한 설명에 상기 범위를 구성하는 각 개별적인 값을 기재한 것과 같다. 본 개시에 따른 방법을 구성하는 단계들에 대하여 명백하게 순서를 기재하거나 반하는 기재가 없다면, 상기 단 계들은 적당한 순서로 행해질 수 있다. 반드시 상기 단계들의 기재 순서에 따라 본 개시가 한정되는 것은 아니 다. 본 개시에서 모든 예들 또는 예시적인 용어(예들 들어, 등등)의 사용은 단순히 본 개시를 상세히 설명하기 위한 것으로서 특허청구범위에 의해 한정되지 않는 이상 상기 예들 또는 예시적인 용어로 인해 본 개시의 범위 가 한정되는 것은 아니다. 또한, 통상의 기술자는 다양한 수정, 조합 및 변경이 부가된 특허청구범위 또는 그 균등물의 범주 내에서 설계 조건 및 인자(factor)에 따라 구성될 수 있음을 알 수 있다. 따라서, 본 개시의 사상은 상기 설명된 실시 예에 국한되어 정해져서는 아니 되며, 후술하는 특허청구범위뿐만 아니라 이 특허청구범위와 균등한 또는 이로부터 등가적으로 변경된 모든 범위는 본 개시의 사상의 범주에 속한 다고 할 것이다.부호의 설명 100: 단말기 장치 200: 서버 장치 310a, 310b, 310c: 카메라"}
{"patent_id": "10-2023-0021759", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 개시의 일 실시 예에 따른 마케팅 컨텐츠 제공 방법을 수행하거나 마케팅 컨텐츠를 제공하는 단말기 장치가 구동하기 위한 환경을 개략적으로 설명하는 도면이다. 도 2는 본 개시의 일 실시 예에 따른 마케팅 컨텐츠를 제공하는 단말기 장치의 구성을 나타낸 블록도이다. 도 3은 본 개시의 일 실시 예에 따른 증강 현실에 기반한 단말기의 마케팅 컨텐츠 제공 방법을 설명하기 위한 순서도이다. 도 4는 본 개시의 일 실시 예에 따른 의류 오브젝트를 피팅하기 위한 3차원 모델링 데이터를 생성하는 방법을 설명하기 위한 도면이다. 도 5는 본 개시의 일 실시 예에 따른 날씨 정보에 매칭되는 의류 오브젝트를 결정하는 방법을 설명하기 위한 도 면이다. 도 6은 본 개시의 일 실시 예에 따른 날씨 정보에 매칭되는 의류 오브젝트를 결정하는 방법을 설명하기 위한 도 면이다. 도 7은 본 개시의 일 실시 예에 따른 영상에 포함된 인물의 자세에 기반하여 가상 오브젝트를 결정하는 방법을 설명하기 위한 도면이다."}
