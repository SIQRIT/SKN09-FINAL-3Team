{"patent_id": "10-2021-0176112", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0087294", "출원번호": "10-2021-0176112", "발명의 명칭": "실제 공간을 주행하는 이동형 로봇의 안전을 위한 정보를 제공하는 방법 및 이를 수행하는 전", "출원인": "삼성전자주식회사", "발명자": "송동신"}}
{"patent_id": "10-2021-0176112", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "실제 공간을 주행하는 이동형 로봇의 안전을 위한 정보를 제공하는 전자 장치에 있어서,상기 인공지능 모델을 저장하는 메모리;상기 메모리와 전기적으로 연결되는 적어도 하나의 프로세서; 및상기 프로세서는 상기 실제 공간을 주행하는 상기 이동형 로봇의 복수의 센서들로부터 수집되는 센싱 데이터를이용하여, 상기 실제 공간을 나타내는 가상 공간 및 상기 가상 공간 내의 정적 오브젝트들을 생성하고,상기 이동형 로봇에 대응되는 가상 이동형 로봇으로서, 상기 복수의 센서들에 대응되는 복수의 가상 센서들을포함하는 상기 가상 이동형 로봇을 생성하고,상기 복수의 가상 센서들에 관련된 복수의 레이어를 포함하는 상기 동적 오브젝트를 생성하고,상기 가상 이동형 로봇이 상기 가상 공간 내에서 주행하도록 상기 가상 이동형 로봇을 제어하고,상기 주행 중인 가상 이동형 로봇 내의 상기 복수의 가상 센서들로부터 상기 정적 오브젝트들에 대한 정적 센싱데이터를 획득하고, 및상기 시뮬레이터를 이용하여, 상기 주행 중인 가상 이동형 로봇 내의 상기 복수의 가상 센서들로부터 상기 동적오브젝트들에 대한 동적 센싱 데이터를 획득하고,상기 프로세서는 상기 정적 센싱 데이터 및 상기 동적 센싱 데이터를 이용하여, 상기 가상 로봇이 상기 정적 오브젝트들 및 상기 동적 오브젝트들과 충돌되지 않도록, 상기 이동형 로봇의 안전을 위한 상기 인공지능 모델을훈련하고,상기 훈련된 인공지능 모델을 상기 실제 공간 내에서의 상기 이동형 로봇에게 제공하고,상기 복수의 레이어는 제1 환경 요소에 대응되는 제1 레이어 및 제2 환경 요소에 대응되는 제2 레이어를 포함하는 전자 장치."}
{"patent_id": "10-2021-0176112", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 정적 오브젝트들은 상기 실제 공간 내를 이동하는 사용자에 의해 착용된 VR(Virtual Reality) 장치로부터수집되는 상기 센싱 데이터를 이용하여 생성되는 전자 장치."}
{"patent_id": "10-2021-0176112", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 동적 오브젝트는 상기 실제 공간 내를 이동하는 사용자에 의해 착용된 모션 트래커(motion tracker)로부터수집되는 모션 센싱 데이터를 이용하여 생성되고,상기 모션 센싱 데이터는 상기 사용자가 상기 실제 공간 내를 이동한 자취에 대한 정보를 포함하는 전자 장치."}
{"patent_id": "10-2021-0176112", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서,상기 동적 오브젝트는 상기 실제 공간을 나타내는 상기 가상 공간 내에서, 상기 사용자가 상기 실제 공간 내 이동한 자취를 따라 이동하는 전자 장치."}
{"patent_id": "10-2021-0176112", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "공개특허 10-2023-0087294-3-제1항에 있어서,상기 제1 레이어는 상기 복수의 가상 센서들 중에서 적어도 제1 가상 센서에 의해 감지되며, 상기 제2 레이어는상기 복수의 가상 센서들 중에서 적어도 제2 가상 센서에 의해 감지되는 전자 장치."}
{"patent_id": "10-2021-0176112", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서,상기 제1 프로세서는,상기 제1 환경 요소의 정도를 측정하고, 및상기 측정된 상기 제1 환경 요소의 정도에 따라, 상기 제1 가상 센서가 상기 제1 레이어를 감지함으로써 생성되는 센싱 데이터를 변경하는 전자 장치."}
{"patent_id": "10-2021-0176112", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에 있어서,상기 동적 센싱 데이터는 제1 동적 센싱 데이터 및 제2 동적 센싱 데이터를 포함하고,상기 제1 동적 센싱 데이터는 상기 복수의 가상 센서들에 의해 상기 제1 레이어를 감지하여 획득되고,상기 제2 동적 센싱 데이터는 상기 복수의 가상 센서들에 의해 상기 제2 레이어를 감지하여 획득되는 전자장치."}
{"patent_id": "10-2021-0176112", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1항에 있어서,상기 제2 프로세서는,상기 가상 이동형 로봇이 상기 가상 공간 내에서 주행하는 동안, 상기 정적 센싱 데이터 및 상기 동적 센싱 데이터를 이용하여 상기 가상 로봇이 상기 정적 오브젝트들 및 상기 동적 오브젝트들과 충돌하였는지 여부를 확인하고,상기 가상 로봇이 상기 정적 오브젝트들 및 상기 동적 오브젝트들과 충돌한 경우, 상기 가상 이동형 로봇의 주행 조건을 수정하고, 및상기 수정된 주행 조건에 따라, 상기 가상 이동형 로봇이 상기 가상 공간 내에서 주행하도록 상기 가상 이동형로봇을 제어하는 전자 장치."}
{"patent_id": "10-2021-0176112", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1항에 있어서,상기 정적 센싱 데이터는 상기 정적 오브젝트들의 위치에 관한 정보를 포함하고,상기 동적 센싱 데이터는 상기 가상 공간 내에서 이동하는 상기 동적 오브젝트의 위치 변화에 관한 정보를 포함하고,상기 제2 프로세서는 상기 정적 센싱 데이터 및 상기 동적 센싱 데이터를 이용하여 상기 가상 이동형 로봇의 위치와 상기 정적 오브젝트들 및 상기 동적 오브젝트들의 위치가 중첩되는지 여부를 통해, 상기 가상 이동형 로봇이 상기 정적 오브젝트들 및 상기 동적 오브젝트들과 충돌하는지 여부를 판단하는 전자 장치."}
{"patent_id": "10-2021-0176112", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "실제 공간을 주행하는 이동형 로봇의 안전을 위한 정보를 제공하는 방법에 있어서,상기 실제 공간을 주행하는 상기 이동형 로봇의 복수의 센서들로부터 수집되는 센싱 데이터를 이용하여, 상기실제 공간을 나타내는 가상 공간 및 상기 가상 공간 내의 정적 오브젝트들을 생성하는 단계;상기 이동형 로봇에 대응되는 가상 이동형 로봇을 생성하는 단계로서, 상기 가상의 이동형 로봇은 상기 복수의공개특허 10-2023-0087294-4-센서들에 대응되는 복수의 가상 센서들을 포함하는 단계;상기 복수의 가상 센서들에 관련된 복수의 레이어를 포함하는 동적 오브젝트를 생성하는 단계로서, 상기 복수의레이어는 제1 환경 요소에 대응되는 제1 레이어 및 제2 환경 요소에 대응되는 제2 레이어를 포함하는 단계;상기 가상 이동형 로봇이 상기 가상 공간 내에서 주행하도록 상기 가상 이동형 로봇을 제어하는 단계;시뮬레이터를 이용하여, 상기 주행 중인 가상 이동형 로봇 내의 상기 복수의 가상 센서들로부터 상기 정적 오브젝트들에 대한 정적 센싱 데이터를 획득하는 단계;상기 시뮬레이터를 이용하여, 상기 주행 중인 가상 이동형 로봇 내의 상기 복수의 가상 센서들로부터 상기 동적오브젝트들에 대한 동적 센싱 데이터를 획득하는 단계;상기 정적 센싱 데이터 및 상기 동적 센싱 데이터를 이용하여, 상기 가상 이동형 로봇이 상기 정적 오브젝트들및 상기 동적 오브젝트들과 충돌하지 않도록, 상기 이동형 로봇의 안전을 위한 상기 인공지능 모델을 훈련하는단계; 및상기 훈련된 인공지능 모델을 상기 실제 공간 내에서의 상기 이동형 로봇에게 제공하는 단계를 포함하는 방법."}
{"patent_id": "10-2021-0176112", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제10항에 있어서,상기 실제 공간을 나타내는 가상 공간 내의 정적 오브젝트들을 생성하는 단계는,상기 실제 공간 내를 이동하는 사용자에 의해 착용된 VR(Virtual Reality) 장치로부터 수집되는 상기 센싱 데이터를 이용하여, 상기 실제 공간을 나타내는 상기 가상 공간 내의 정적 오브젝트들을 생성하는 것을 포함하는 방법."}
{"patent_id": "10-2021-0176112", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제10항에 있어서,상기 동적 오브젝트를 생성하는 단계는,상기 실제 공간 내를 이동하는 사용자에 의해 착용된 모션 트래커(motion tracker)로부터 수집되는 모션 센싱데이터를 이용하여, 상기 실제 공간을 나타내는 상기 가상 공간 내의 상기 동적 오브젝트를 생성하는 것을 포함하고,상기 모션 센싱 데이터는 상기 사용자가 상기 실제 공간 내를 이동한 자취에 대한 정보를 포함하는 방법."}
{"patent_id": "10-2021-0176112", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제12항에 있어서,상기 모션 센싱 데이터를 이용하여 생성된 상기 동적 오브젝트는, 상기 실제 공간을 나타내는 상기 가상 공간내에서, 상기 사용자가 상기 실제 공간 내 이동한 자취를 따라 이동하는 방법."}
{"patent_id": "10-2021-0176112", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제10항에 있어서,상기 제1 레이어는 상기 복수의 가상 센서들 중에서 적어도 제1 가상 센서에 의해 감지되며, 상기 제2 레이어는상기 복수의 가상 센서들 중에서 적어도 제2 가상 센서에 의해 감지되는 방법."}
{"patent_id": "10-2021-0176112", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제10항에 있어서,상기 동적 센싱 데이터를 획득하는 단계는,상기 제1 환경 요소의 정도를 측정하는 단계; 및상기 측정된 상기 제1 환경 요소의 정도에 따라, 상기 제1 가상 센서가 상기 제1 레이어를 감지함으로써 생성되공개특허 10-2023-0087294-5-는 센싱 데이터를 변경하는 단계를 포함하는 방법."}
{"patent_id": "10-2021-0176112", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제10항에 있어서,상기 동적 센싱 데이터는 제1 동적 센싱 데이터 및 제2 동적 센싱 데이터를 포함하고,상기 제1 동적 센싱 데이터는 상기 복수의 가상 센서들에 의해 상기 제1 레이어를 감지하여 획득되고,상기 제2 동적 센싱 데이터는 상기 복수의 가상 센서들에 의해 상기 제2 레이어를 감지하여 획득되는 방법."}
{"patent_id": "10-2021-0176112", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제10항에 있어서,상기 주행 중인 가상 이동형 로봇 내의 상기 복수의 가상 센서들로부터 상기 동적 오브젝트들에 대한 동적 센싱데이터를 획득하는 단계는,상기 복수의 가상 센서들이 상기 동적 오브젝트들을 인식하도록 데이터를 통합하는 브로커를 이용하여, 상기 가상 공간을 나타내는 데이터를 상기 동적 센싱 데이터와 통합하는 단계,상기 주행 중인 가상 이동형 로봇 내의 상기 복수의 가상 센서들이 상기 동적 오브젝트들을 인식하는 단계를 포함하는 방법."}
{"patent_id": "10-2021-0176112", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제10항에 있어서,상기 이동형 로봇의 안전을 위한 상기 인공지능 모델을 훈련하는 단계는,가상 이동형 로봇의 주행 조건을 설정하는 단계,상기 가상 이동형 로봇이 상기 가상 공간 내에서 주행하는 동안, 상기 가상 이동형 로봇이 상기 정적 센싱 데이터 및 상기 동적 센싱 데이터를 이용하여, 상기 가상 이동형 로봇과, 상기 정적 오브젝트들 및 상기 동적 오브젝트들의 거리를 측정하는 단계;상기 거리를 이용하여 가상 이동형 로봇과, 상기 정적 오브젝트들 및 상기 동적 오브젝트들이 충돌하는지 여부를 판단하는 단계;상기 가상 로봇이 상기 정적 오브젝트들 및 상기 동적 오브젝트들과 충돌한 경우, 상기 가상 이동형 로봇의 안전 보장 조건을 추가하는 단계; 및상기 주행 조건 및 추가된 안전 보장 조건에 따라, 상기 가상 이동형 로봇이 상기 가상 공간 내에서 주행하도록상기 가상 이동형 로봇을 제어하는 단계를 포함하는 방법."}
{"patent_id": "10-2021-0176112", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제10항에 있어서,상기 정적 센싱 데이터는 상기 정적 오브젝트들의 위치에 관한 정보를 포함하고,상기 동적 센싱 데이터는 상기 가상 공간 내에서 이동하는 상기 동적 오브젝트의 위치 변화에 관한 정보를 포함하고,상기 가상 이동형 로봇이 상기 정적 오브젝트들 및 상기 동적 오브젝트들과 충돌하는지 여부는, 상기 정적 센싱데이터 및 상기 동적 센싱 데이터를 이용하여 상기 가상 이동형 로봇의 위치와 상기 정적 오브젝트들 및 상기동적 오브젝트들의 위치가 중첩되는지 여부를 통해 판단하는 방법."}
{"patent_id": "10-2021-0176112", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제10항 내지 제19항 중 어느 한 항의 방법을 컴퓨터에서 수행하기 위한 프로그램이 기록된 컴퓨터로 읽을 수 있는 기록 매체.공개특허 10-2023-0087294-6-"}
{"patent_id": "10-2021-0176112", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 문서에 개시되는 일 실시 예에 따른, 실제 공간을 주행하는 이동형 로봇의 안전을 위한 정보를 제공하는 방법 은, 상기 실제 공간을 주행하는 상기 이동형 로봇의 복수의 센서들로부터 수집되는 센싱 데이터를 이용하여, 상 기 실제 공간을 나타내는 가상 공간 및 상기 가상 공간 내의 정적 오브젝트들을 생성하는 단계, 상기 이동형 로 (뒷면에 계속)"}
{"patent_id": "10-2021-0176112", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 문서에서 개시되는 실시 예들은 실제 공간을 주행하는 이동형 로봇의 안전을 위한 정보를 제공하는 방법 및 이를 수행하는 전자 장치에 관한 것이다."}
{"patent_id": "10-2021-0176112", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "인공지능(Artificial Intelligence, AI) 시스템은 인간 수준의 지능을 구현하는 컴퓨터 시스템이며, 기존 Rule 기반 스마트 시스템과 달리 기계가 스스로 학습하고 판단하며 똑똑해지는 시스템이다. 인공지능 시스템은 사용 할수록 인식률이 향상되고 사용자 취향을 보다 정확하게 이해할 수 있게 되어, 기존 Rule 기반 스마트 시스템은 점차 딥러닝 기반 인공지능 시스템으로 대체되고 있다. 인공지능 기술은 기계학습(딥러닝) 및 기계학습을 활용한 요소 기술들로 구성된다. 기계학습은 입력 데이터들의 특징을 스스로 분류/학습하는 알고리즘 기술이며, 요소기술은 딥러닝 등의 기계학 습 알고리즘을 활용하여 인간 두뇌의 인지, 판단 등의 기능을 모사하는 기술로서, 언어적 이해, 시각적 이해, 추론/예측, 지식 표현, 동작 제어 등의 기술 분야로 구성된다. 멀티 미디어 기술 및 네트워크 기술이 발전함에 따라, 사용자는 이동형 로봇 장치를 이용하여 다양한 서비스를 제공받을 수 있게 되었다. 하지만, 종래에는, 안전 메커니즘을 개발하였음에도 이동형 로봇 장치의 주행중 충돌 사고 발생 가능성을 배제 할 수 없는 문제가 있었다. 이에 따라, 이동형 로봇 장치의 충돌로 인한 피해가 큰 경우를 고려하여 이동형 로 봇 장치를 제어함으로써, 사용자가 안전하면서도 효과적으로 서비스를 제공받을 수 있는 기술이 요구되고 있다."}
{"patent_id": "10-2021-0176112", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명이 해결하고자 하는 기술적 과제는 실제 공간을 주행하는 이동형 로봇이 안전하게 주행할 수 있도록 정 보를 제공하는 방법 및 전자 장치를 제공하는 것이다. 본 발명의 기술적 과제들은 이상에서 언급한 기술적 과제로 제한되지 않으며, 언급되지 않은 또 다른 기술적 과 제들은 아래의 기재로부터 당업자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2021-0176112", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 개시의 일 실시예에 따르면, 실제 공간을 주행하는 이동형 로봇의 안전을 위한 정보를 제공하는 전자 장치는, 상기 인공지능 모델을 저장하는 메모리, 상기 메모리와 전기적으로 연결되는 적어도 하나의 제1 프로세 서, 및 상기 메모리 및 상기 제1 프로세서와 전기적으로 연결되는 제2 프로세서를 포함하고, 상기 제1 프로세서 는 상기 실제 공간을 주행하는 상기 이동형 로봇의 복수의 센서들로부터 수집되는 센싱 데이터를 이용하여, 상 기 실제 공간을 나타내는 가상 공간 및 상기 가상 공간 내의 정적 오브젝트들을 생성하고, 상기 이동형 로봇에 대응되는 가상 이동형 로봇으로서, 상기 복수의 센서들에 대응되는 복수의 가상 센서들을 포함하는 상기 가상 이동형 로봇을 생성하고, 상기 복수의 가상 센서들에 관련된 복수의 레이어를 포함하는 상기 동적 오브젝트를 생성하고, 상기 가상 이동형 로봇이 상기 가상 공간 내에서 주행하도록 상기 가상 이동형 로봇을 제어하고, 상 기 주행 중인 가상 이동형 로봇 내의 상기 복수의 가상 센서들로부터 상기 정적 오브젝트들에 대한 정적 센싱 데이터를 획득하고, 및 상기 시뮬레이터를 이용하여, 상기 주행 중인 가상 이동형 로봇 내의 상기 복수의 가상 센서들로부터 상기 동적 오브젝트들에 대한 동적 센싱 데이터를 획득하고, 상기 제2 프로세서는 상기 정적 센싱 데이터 및 상기 동적 센싱 데이터를 이용하여, 상기 가상 로봇이 상기 정적 오브젝트들 및 상기 동적 오브젝트 들과 충돌되지 않도록, 상기 이동형 로봇의 안전을 위한 상기 인공지능 모델을 훈련하고, 및 상기 훈련된 인공 지능 모델을 상기 실제 공간 내에서의 상기 이동형 로봇에게 제공하고, 상기 복수의 레이어는 제1 환경 요소에 대응되는 제1 레이어 및 제2 환경 요소에 대응되는 제2 레이어를 포함하는 것을 특징으로 할 수 있다. 본 개시의 일 실시예의 또 다른 측면에 따르면, 실제 공간을 주행하는 이동형 로봇의 안전을 위한 정보를 제공 하는 방법은 상기 실제 공간을 주행하는 상기 이동형 로봇의 복수의 센서들로부터 수집되는 센싱 데이터를 이용하여, 상기 실제 공간을 나타내는 가상 공간 및 상기 가상 공간 내의 정적 오브젝트들을 생성하는 단계, 상기 이동형 로봇에 대응되는 가상 이동형 로봇을 생성하는 단계로서, 상기 가상의 이동형 로봇은 상기 복수의 센서 들에 대응되는 복수의 가상 센서들을 포함하는 단계, 상기 복수의 가상 센서들에 관련된 복수의 레이어를 포함 하는 상기 동적 오브젝트를 생성하는 단계로서, 상기 복수의 레이어는 제1 환경 요소에 대응되는 제1 레이어 및 제2 환경 요소에 대응되는 제2 레이어를 포함하는 단계, 상기 가상 이동형 로봇이 상기 가상 공간 내에서 주행 하도록 상기 가상 이동형 로봇을 제어하는 단계, 시뮬레이터를 이용하여, 상기 주행 중인 가상 이동형 로봇 내 의 상기 복수의 가상 센서들로부터 상기 정적 오브젝트들에 대한 정적 센싱 데이터를 획득하는 단계, 상기 시뮬 레이터를 이용하여, 상기 주행 중인 가상 이동형 로봇 내의 상기 복수의 가상 센서들로부터 상기 동적 오브젝트 들에 대한 동적 센싱 데이터를 획득하는 단계, 상기 정적 센싱 데이터 및 상기 동적 센싱 데이터를 이용하여, 상기 가상 로봇이 상기 정적 오브젝트들 및 상기 동적 오브젝트들과 충돌되지 않도록, 상기 이동형 로봇의 안전 을 위한 상기 인공지능 모델을 훈련하는 단계, 및 상기 훈련된 인공지능 모델을 이용하여 상기 실제 공간 내에 서의 상기 이동형 로봇의 주행을 제어하는 단계를 포함하는 것을 특징으로 할 수 있다. 본 개시의 일 실시예의 또 다른 측면에 따르면, 실제 공간을 주행하는 이동형 로봇이 상기 이동형 로봇의 안전 을 위한 인공지능 모델을 학습하는 방법을 컴퓨터에서 수행하기 위한 프로그램이 기록된 컴퓨터로 읽을 수 있는 기록 매체가 제공된다."}
{"patent_id": "10-2021-0176112", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "아래에서는 첨부한 도면을 참조하여 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자가 용이하게 실시할 수 있도록 본 발명의 실시예를 상세히 설명한다. 그러나 본 발명은 여러 가지 상이한 형태로 구현될 수 있으며 여기에서 설명하는 실시예에 한정되지 않는다. 그리고 도면에서 본 발명을 명확하게 설명하기 위해서 설명과 관계없는 부분은 생략하였으며, 명세서 전체를 통하여 유사한 부분에 대해서는 유사한 도면 부호를 붙였다. 명세서 전체에서, 어떤 부분이 다른 부분과 \"연결\"되어 있다고 할 때, 이는 \"직접적으로 연결\"되어 있는 경우뿐 아니라, 그 중간에 다른 소자를 사이에 두고 \"전기적으로 연결\"되어 있는 경우도 포함한다. 또한 어떤 부분이 어떤 구성요소를 \"포함\"한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다른 구성요소를 제외하는 것이 아 니라 다른 구성요소를 더 포함할 수 있는 것을 의미한다. 본 개시에 따른 인공지능과 관련된 기능은 프로세서와 메모리를 통해 동작된다. 프로세서는 하나 또는 복수의 프로세서로 구성될 수 있다. 이때, 하나 또는 복수의 프로세서는 CPU, AP, DSP(Digital Signal Processor) 등 과 같은 범용 프로세서, GPU, VPU(Vision Processing Unit)와 같은 그래픽 전용 프로세서 또는 NPU와 같은 인 공지능 전용 프로세서일 수 있다. 하나 또는 복수의 프로세서는, 메모리에 저장된 기 정의된 동작 규칙에 따라 또는 인공지능 모델을 이용하여, 입력 데이터를 처리하도록 제어한다. 또는, 하나 또는 복수의 프로세서가 인공 지능 전용 프로세서인 경우, 인공지능 전용 프로세서는, 특정 인공지능 모델의 처리에 특화된 하드웨어 구조로 설계될 수 있다. 기 정의된 동작 규칙 또는 인공지능 모델은 학습을 통해 만들어진 것을 특징으로 한다. 여기서, 학습을 통해 만 들어진다는 것은, 기본 인공지능 모델이 학습 알고리즘에 의하여 다수의 학습 데이터들을 이용하여 학습됨으로 써, 원하는 특성(또는, 목적)을 수행하도록 설정된 기 정의된 동작 규칙 또는 인공지능 모델이 만들어짐을 의미 한다. 이러한 학습은 본 개시에 따른 인공지능이 수행되는 기기 자체에서 이루어질 수도 있고, 별도의 서버 및/ 또는 시스템을 통해 이루어 질 수도 있다. 학습 알고리즘의 예로는, 지도형 학습(supervised learning), 비지도 형 학습(unsupervised learning), 준지도형 학습(semi-supervised learning) 또는 강화 학습(reinforcement learning)이 있으나, 전술한 예에 한정되지 않는다. 인공지능 모델은, 복수의 신경망 레이어들로 구성될 수 있다. 복수의 신경망 레이어들 각각은 복수의 노드들과 가중치들(weight values)을 갖고 있으며, 이전(previous) 레이어의 연산 결과와 복수의 가중치들 간의 연산을 통해 신경망 연산을 수행한다. 복수의 신경망 레이어들이 갖고 있는 복수의 가중치들은 인공지능 모델의 학습 결과에 의해 최적화될 수 있다. 예를 들어, 학습 과정 동안 인공지능 모델에서 획득한 로스(loss) 값 또는 코스 트(cost) 값이 감소 또는 최소화되도록 복수의 가중치들이 갱신될 수 있다. 또한, 손실값 또는 코스트 값을 최 소화하기 위해, 손실값 또는 코스트값과 관련된 그래디언트를 최소화하는 방향으로 복수의 가중치들이 갱신될 수 있다. 인공 신경망은 심층 신경망(DNN:Deep Neural Network)를 포함할 수 있으며, 예를 들어, CNN (Convolutional Neural Network), DNN (Deep Neural Network), RNN (Recurrent Neural Network), RBM (Restricted Boltzmann Machine), DBN (Deep Belief Network), BRDNN(Bidirectional Recurrent Deep Neural Network) 또는 심층 Q-네트워크 (Deep Q-Networks) 등이 있으나, 전술한 예에 한정되지 않는다. 이하 첨부된 도면을 참고하여 본 발명을 상세히 설명하기로 한다. 도 1은 일 실시 예에 따른, 전자 장치가 이동형 로봇의 안전을 위한 인공지능 모델을 훈련시키는 방법을 나타내 는 도면이다. 도 1을 참조하면, 이동형 로봇의 안전을 위한 인공지능 모델을 훈련시키는 방법에서, 전자 장치는 가상 환 경을 구성할 수 있다. 가상 환경은 가상 공간, 정적 오브젝트 및 가상 이동형 로봇을 포함할 수 있다. 즉, 전자 장치는 정적 오브젝트 를 생성할 수 있고, 가상 이동형 로봇을 생성할 수 있다. 실제 공간을 주행하는 이동형 로봇의 복수 의 센서들로부터 수집되는 센싱 데이터를 이용하여, 가상 공간 및 정적 오브젝트가 생성될 수 있다. 가상 공간은 실제 공간을 주행하는 이동형 로봇이 이동형 로봇의 안전을 위한 인공지능 모델을 학습하기 위해, 실제 공간에 대응되는 공간일 수 있다. 가상 공간 및 가상 공간 내의 정적 오브젝트들은 실제 공간을 주행하는 이동형 로봇의 복수의 센서들로부터 수집되는 센싱 데이터를 이용하여 생성될 수 있다. 가상 이동형 로봇은 가상 공간 내에서 주행하면서, 이동형 로봇의 안전을 위한 인공지능 모델을 학습할 수 있다. 가상 이동형 로봇은 가상 공간 내에서 오브젝트들, 예를 들어, 정적 오브젝트에 충돌하지 않도록 인공지 능 모델을 학습할 수 있다. 가상 이동형 로봇은 실제 이동형 로봇에 대응될 수 있다. 가상 이동형 로봇은 복수 의 가상 센서들을 포함할 수 있다. 가상 이동형 로봇의 복수의 가상 센서들은 실제 이동형 로봇의 복수의 센서 들에 대응될 수 있다. 정적 오브젝트들은 가상 공간 내에 생성될 수 있다. 정적 오브젝트는 움직임을 갖지 않는 물체일 수 있다. 정적 오브젝트는 고정된 물체일 수 있다. 예를 들어, 정적 오브젝트는 벽일 수 있고, 테이블(table)일 수 있다. 전자 장치는 또한, 동적 오브젝트를 생성할 수 있다. 동적 오브젝트는 복수의 가상 센서들에 관련된 복수 의 레이어(도 6의 310, 320)를 포함할 수 있다. 동적 오브젝트는 움직임을 갖는 물체일 수 있다. 예를 들어, 동적 오브젝트는 움직이는 반려동물, 움직이는 다 수의 사람, 움직이는 행인, 아기 등일 수 있다. 다양한 실시 예에서, 정적 오브젝트 및 동적 오브젝트과 관련된 내용은 도 9 및 도 10에서 상세하게 설명된다. 가상 환경에 대한 데이터 및 동적 오브젝트에 대한 데이터는 통합될 수 있다. 가상 환경에 대한 데이터는 정적 오브젝트 및 가상 이동형 로봇에 대한 데이터일 수 있다. 즉, 가상 환경에 대 한 데이터는 정적 오브젝트의 위치, 배치에 관한 정보를 포함할 수 있고, 가상 이동형 로봇의 위치, 배치, 이동 속도, 이동 방향, 경로 등에 관한 정보를 포함할 수 있다. 동적 오브젝트에 대한 데이터는 동적 오브젝트의 위치, 배치, 이동 속도, 이동 방향, 경로, 이동 성향에 관한 정보를 포함할 수 있다. 가상 환경에 대한 데이터 및 동적 오브젝트에 대한 데이터를 통합함으로써, 가상 이동형 로봇과 동적 오브젝트 간의 상대적인 위치 관계가 파악될 수 있다. 이에 따라, 실시간으로 움직이는 동적 오브젝트에 대해, 가상 이동 형 로봇과의 충돌 유무가 파악될 수 있다. 전자 장치는 가상 이동형 로봇이 주행하도록 제어할 수 있다. 가상 이동형 로봇은 가상 공간 내에서 주행 할 수 있다. 가상 이동형 로봇의 이동 메커니즘은 프로세서에 의해 설정될 수 있다. 즉, 가상 이동형 로봇의 경 로, 속도 등은 프로세서에 의해 설정될 수 있다. 센싱부(도 3의 1400)는 오브젝트들에 대한 센싱 데이터를 획득할 수 있다. 상기 센싱 데이터는 가상 이동 형 로봇을 기준으로 오브젝트들의 상대적인 위치를 나타낼 수 있다. 구체적으로, 시뮬레이터를 이용하여, 주행 중인 가상 이동형 로봇 내의 복수의 가상 센서들로부터, 정적 오브젝트들에 대한 정적 센싱 데이터가 획득될 수 있다. 또한, 시뮬레이터를 이용하여, 주행 중인 가상 이동형 로봇 내의 복수의 가상 센서들로부터, 동적 오브젝 트들에 대한 동적 센싱 데이터가 획득될 수 있다. 예를 들어, 센싱부는 어느 순간에 가상 이동형 로봇과 적어도 하나의 오브젝트가 중첩된 위치에 배치된다는 센 싱 데이터를 획득할 수 있다. 즉, 가상 이동형 로봇과 적어도 하나의 오브젝트가 충돌하였다는 센싱 데이터를 획득할 수 있다. 전자 장치는 센싱 데이터를 참고하여, 이동형 로봇의 안전을 위한 인공지능 모델을 훈련할 수 있다. 구체 적으로, 정적 센싱 데이터 및 동적 센싱 데이터를 이용하여, 가상 이동형 로봇이 정적 오브젝트들 및 동적 오브 젝트들과 충돌하지 않도록, 이동형 로봇의 안전을 위한 인공지능 모델을 훈련할 수 있다. 예를 들어, 가상 이동형 로봇의 주행 조건이 설정될 수 있다. 시뮬레이션 내에서, 가상 이동형 로봇이 주행 조 건에 따라 주행하는 동안, 가상 이동형 로봇 내의 복수의 가상 센서들은 정적 오브젝트 및 동적 오브젝트를 감 지할 수 있다. 가상 이동형 로봇의 주행 조건에 따른, 가상 이동형 로봇과, 정적 오브젝트 및 동적 오브젝트 사 이의 거리 데이터는 생성될 수 있다. 가상 이동형 로봇의 주행 조건은, 예를 들어, 가상 이동형 로봇이 주행하 는 경로, 주행 속도 등을 포함할 수 있다. 상기 거리 데이터를 이용하여, 가상 이동형 로봇의 주행이 안전한지 판단될 수 있다. 예를 들어, 가상 이동형 로봇이 주행하는 동안, 가상 이동형 로봇과 정적 오브젝트의 거리가 0 이하가 되는 구간이 존재하는 경우, 가상 이동형 로봇과 정적 오브젝트는 충돌하는 것으로 판단될 수 있다. 다른 예로, 가상 이동형 로봇이 주행하는 동 안, 가상 이동형 로봇과 동적 오브젝트의 거리가 위험 범위 내에 있는지 확인될 수 있다. 가상 이동형 로봇과, 정적 오브젝트 및 동적 오브젝트의 충돌 여부, 및 가상 이동형 로봇과, 정적 오브젝트 및 동적 오브젝트의 거리가 위험 범위 내에 있는지 여부를 통하여, 이동형 로봇의 안전을 위한 인공지능 모델은 훈 련될 수 있다. 예를 들어, 가상 이동형 로봇이 주행하는 동안, 가상 이동형 로봇과 동적 오브젝트가 1회 이상 충돌한다면, 안전 보장 조건을 추가할 수 있다. 예를 들어, 가상 이동형 로봇이 동적 오브젝트를 만났을 때, 일 시정지한다는 조건이 추가될 수 있다. 다른 예로, 가상 이동형 로봇의 가상 센서들의 사각지대가 발생하는 경우, 가상 이동형 로봇의 주행 속도를 낮추는 조건이 추가될 수 있다. 안전 보장 조건이 추가된 후, 가상 이동형 로봇은 설정된 주행 조건에 따라 재주행할 수 있다. 가상 이동형 로 봇의 주행 조건 및 안전 보장 조건에 따라, 가상 이동형 로봇과, 정적 오브젝트 및 동적 오브젝트 사이의 거리 데이터는 재생성될 수 있다. 상기 거리 데이터를 이용하여, 가상 이동형 로봇의 주행이 안전한지 재판단될 수 있다. 다양한 실시예들에서, 이동형 로봇의 안전을 위한 인공지능 모델은 이동형 로봇이 가상 공간 내에서 안전하게 주행하도록 시뮬레이션하기 위해 입력값을 전달받을 수 있다. 예를 들어, 입력값은 가상 공간 내 동적 오브젝트 의 위치 변화를 나타내는 데이터, 가상 이동형 로봇의 형상을 나타내는 데이터, 가상 이동형 로봇의 주행 조건 을 나타내는 데이터 등을 포함할 수 있다. 단, 이는 예시일 뿐, 본 발명의 기술적 사상은 이에 한정되지 않는다. 다양한 실시예들에서, 이동형 로봇이 가상 공간 내에서 안전하게 주행하는지 시뮬레이션한 결과, 이동형 로봇의 안전을 위한 인공지능 모델은 출력값을 얻을 수 있다. 출력값은 가상 이동형 로봇이 주행하는 동안 정적 오브젝 트 및 동적 오브젝트와 충돌하였는지 여부를 판단할 수 있는 데이터일 수 있다. 예를 들어, 출력값은 가상 이동 형 로봇이 주행하는 동안, 가상 이동형 로봇과 동적 오브젝트 사이의 거리에 대한 데이터일 수 있다. 다른 예로, 출력값은 가상 이동형 로봇이 주행하는 동안, 가상 이동형 로봇과 정적 오브젝트 사이의 거리에 대한 데 이터일 수 있다. 단, 이는 예시일 뿐, 본 발명의 기술적 사상은 이에 한정되지 않는다. 도 2는 일 실시 예에 따른, 전자 장치의 내부 구성을 도시한 블록도이다. 도 3은 일 실시 예에 따른, 이동형 로봇의 안전을 위한 인공지능 모델을 학습하기 위한 정보 처리를 수행하는 전자 장치의 블록도이다. 도 2 및 도 3에서는 전자 장치가 이동형 로봇인 경우를 예로 들어 설명하기로 한다. 도 2 및 도 3을 참조하면, 이동형 로봇은 메모리 및 프로세서를 포함할 수 있다. 그러나, 도 2에 도시된 구성 요소 모두가 이동형 로봇의 필수 구성 요소인 것은 아니다. 도 2에 도시된 구성 요소보 다 많은 구성 요소에 의해 이동형 로봇이 구현될 수도 있고, 도 2에 도시된 구성 요소보다 적은 구성 요 소에 의해 이동형 로봇이 구현될 수도 있다. 예를 들면, 이동형 로봇은 도 3에 도시된 바와 같이, 일부 실시예에 따른 이동형 로봇은, 메모리 및 프로세서 이외에 사용자 입력부, 출력부, 센싱부 및 통신 인터페이스 를 더 포함할 수도 있다. 사용자 입력부는, 사용자가 이동형 로봇을 제어하기 위한 데이터를 입력하는 수단을 의미한다. 예 를 들어, 사용자 입력부에는 키 패드(key pad), 돔 스위치 (dome switch), 터치 패드(접촉식 정전 용량 방식, 압력식 저항막 방식, 적외선 감지 방식, 표면 초음파 전도 방식, 적분식 장력 측정 방식, 피에조 효과 방 식 등), 조그 휠, 조그 스위치 등이 있을 수 있으나 이에 한정되는 것은 아니다. 일 실시 예에 의하면, 사용자 입력부는, 인공지능 모델에 따라 수행될 수 있는 소정의 동작(ex. 이동 경 로 추천, 객체 인식, 음성 인식)을 요청하는 사용자의 입력을 수신할 수 있다. 또한, 사용자 입력부는 이 동형 로봇의 인공지능 모델에 의해 수행된 시뮬레이션에 대한 피드백 정보를 포함하는 사용자의 입력을 수신할 수 있다. 출력부는, 오디오 신호 또는 비디오 신호 또는 진동 신호를 출력할 수 있으며, 출력부는 디스플레 이부, 음향 출력부, 및 진동 모터를 포함할 수 있다. 일 실시 예에 의한 출력부는, 인 공지능 모델에 의해 수행된 시뮬레이션의 결과를 출력할 수 있다. 디스플레이부는 이동형 로봇에서 처리되는 정보를 표시 출력한다. 일 실시 예에 의하면, 디스플레 이부는, 사용자의 입력에 따라 인공지능 모델에 의해 수행된 시뮬레이션의 결과를 표시할 수 있다. 한편, 디스플레이부와 터치패드가 레이어 구조를 이루어 터치 스크린으로 구성되는 경우, 디스플레이부 는 출력 장치 이외에 입력 장치로도 사용될 수 있다. 디스플레이부는 액정 디스플레이(liquid crystal display), 박막 트랜지스터 액정 디스플레이(thin film transistor-liquid crystal display), 유기 발 광 다이오드(organic light-emitting diode), 플렉시블 디스플레이(flexible display), 3차원 디스플레이(3D display), 전기영동 디스플레이(electrophoretic display) 중에서 적어도 하나를 포함할 수 있다. 그리고 이동 형 로봇의 구현 형태에 따라 이동형 로봇은 디스플레이부를 2개 이상 포함할 수도 있다. 음향 출력부는 통신 인터페이스로부터 수신되거나 메모리에 저장된 오디오 데이터를 출력한 다. 일 실시 예에 의한 음향 출력부는 인공지능 모델에 의해 수행된 시뮬레이션의 결과를 나타내는 오디 오 데이터를 출력할 수 있다. 진동 모터는 진동 신호를 출력할 수 있다. 또한, 진동 모터는 터치스크린에 터치가 입력되는 경우 진동 신호를 출력할 수도 있다. 일 실시 예에 의한 진동 모터는 인공지능 모델에 의해 수행된 시뮬레이션 의 결과를 나타내는 진동 신호를 출력할 수 있다. 예를 들어, 진동 모터는 인공지능 모델에 의해 수행된 시뮬레이션의 결과, 가상 이동형 로봇이 정적 오브 젝트 또는 동적 오브젝트와 충돌하는 경우 진동 신호를 출력할 수 있다. 프로세서는, 통상적으로 이동형 로봇의 전반적인 동작을 제어한다. 예를 들어, 프로세서는, 메모리에 저장된 프로그램들을 실행함으로써, 사용자 입력부, 출력부, 센싱부, 통신부 등을 전반적으로 제어할 수 있다. 이동형 로봇은 적어도 하나의 프로세서를 포함할 수 있다. 프로세서는 기본적인 산술, 로직 및 입출력 연산을 수행함으로써, 컴퓨터 프로그램의 명령을 처리하도록 구성될 수 있다. 명령은 메모리로부터 프로세서에 제공되거나, 통신부를 통해 수신되어 프로 세서로 제공될 수 있다. 예를 들면 프로세서는 메모리와 같은 기록 장치에 저장된 프로그램 코드에 따라 명령을 실행하도록 구성될 수 있다. 구체적으로, 프로세서는 제1 프로세서 및 AI 프로세싱 유닛을 포함할 수 있다. AI 프로세싱 유닛은 제2 프로세서 및 제2 메모리를 포함할 수 있다. 제1 프로세서는 이동형 로봇에 포함된 구성(예를 들어, 메모리)들과 전기적으로 연결되어, 이동형 로봇에 포함된 구성들의 제어 및/또는 통신에 관한 연산이나 데이터 처리를 실행할 수 있다. 일 실시 예에 따르면, 제1 프로세서는 다른 구성들 중 적어도 하나로부터 수신된 명령 또는 데이터를 메모리 에 로드하여 처리하고, 결과 데이터를 메모리에 저장할 수 있다. 다양한 실시 예에 따르면, 제1 프 로세서는 CPU(central processing unit), AP(application processor), GPU(graphic processing unit), 또는 NPU(neural processing unit) 중 적어도 하나를 포함할 수 있다. 일 실시 예에 따르면, 제1 프로세서는, 제2 프로세서가 하나 이상의 모듈을 실행시킴으로써 적어도 하나의 인공지능 모델에 대한 훈련 또는 적용을 수행하도록 제2 프로세서에 대하여 제어 신호를 전 달할 수 있다. 일 실시 예에 따르면, 제1 프로세서는, 제2 프로세서가 하나 이상의 모듈을 실행시킬 수 있도록, 메모리에 저장되어 있는 하나 이상의 모듈 또는 적어도 하나의 인공지능 모델 중 어느 하나의 인공지능 모델을 제2 메모리에 로드시킬 수 있다. 예를 들면, 제1 프로세서는 제2 프로세서가 메모리 에 저장되어 있는 적어도 하나의 인공지능 모델 중 어느 하나의 인공지능 모델에 대한 동작을 수행할 수 있도록, 상기 어느 하나의 모델을 제2 메모리에 로드시킬 수 있다. 다양한 실시 예에서, 제1 프로세서 가 어느 하나의 모듈 또는 어느 하나의 인공지능 모델을 제2 메모리에 로드시키는 것은 상기 어느 하나의 모듈 또는 어느 하나의 인공지능 모델을 AI 프로세싱 유닛에 전달하는 동작으로 이해될 수도 있다. AI 프로세싱 유닛은 센싱부를 제어하고 적어도 하나의 인공지능 모델에 대한 훈련 및 적용을 수행하기 위한 구성으로서, 제2 프로세서 및 제2 메모리를 포함할 수 있다. 일 실시 예에 따르면, AI 프로세싱 유닛은 인공지능 기술을 이용한 적어도 하나의 인공지능 모델을 이용하여 가상 이동형 로봇의 주행 시뮬레이션을 수행하기 위한 전용의 프로세싱 유닛으로 이해될 수 있고, 제2 프로세서은 상 기 적어도 하나의 인공지능 모델을 이용하여 가상 이동형 로봇의 주행 시뮬레이션을 수행하기 위한 전용 의 프로세서로 이해될 수 있다. 일 실시 예에 따르면, AI 프로세싱 유닛은 도 3에 도시된 바와 다르게, 제1 프로세서에 포함되는 구성일 수도 있고, 인공지능 전용의 프로세서인 NPU(미도시)의 일부로 구현될 수도 있다. 제2 프로세서는 이동형 로봇에 포함된 구성(예를 들어, 메모리 및 제1 프로세서)들과 전기적으로 연결되어, 이동형 로봇에 포함된 구성들의 제어 및/또는 통신에 관한 연산이나 데이터 처리를 실행할 수 있다. 일 실시 예에 따르면, 제2 프로세서는 단독으로 또는 제1 프로세서의 제어 신호에 응답하여, 센싱부를 이용하여 생성되는 데이터, 예컨대, 정적 오브젝트, 동적 오브젝트 및 가상 이동형 로봇에 대한 센싱 데이터에 대한 처리를 수행할 수 있다. 제2 프로세서가 처리하는 데이터는 상기 열거된바에 한정되지는 않으며, 객체에 대응하는 센싱 데이터를 생성하는 과정에서 생성되는 데이터를 모두 포함할 수 있다. 일 실시 예에 따르면, 제2 프로세서는 단독으로 또는 제1 프로세서의 제어 신호에 응답하여, 적어 도 하나의 인공지능 모델에 대한 훈련, 재훈련, 다운로딩, 평가, 또는 적용을 수행할 수 있다. 다양한 실 시 예에서, 제2 프로세서는 메모리에 저장되어 있는 적어도 하나의 인공지능 모델 중 어느 하나의 인공지능 모델이 제2 메모리에 로드되면, 상기 어느 하나의 인공지능 모델에 대한 학습, 재훈련, 평가, 또는 적용을 수행할 수 있다. 인공지능 모델에 대한 학습, 재훈련, 평가, 또는 적용은 센싱부 를 이용하여 생성되는 데이터, 예컨대, 정적 오브젝트, 동적 오브젝트 및 가상 이동형 로봇에 대한 센싱 데이터를 기반으로 수행될 수 있다. 구체적으로, 제2 프로세서는 정적 오브젝트의 위치에 관한 정적 센싱 데이터와 동적 오브젝트의 위치에 관한 동적 센싱 데이터를 이용하여, 가상 로봇이 정적 오브젝트들 및 동적 오브젝트들과 충돌되지 않도록, 이동 형 로봇의 안전을 위한 인공지능 모델을 훈련할 수 있다. 제2 프로세서는 가상 이동형 로봇이 가상 공간 내에서 주행하는 동안, 정적 센싱 데이터 및 동적 센싱 데 이터를 이용하여 가상 로봇이 정적 오브젝트들 및 동적 오브젝트들과 충돌하였는지 여부를 확인할 수 있다. 예 를 들어, 가상 이동형 로봇이 이동하는 동안, 가상 로봇 내의 복수의 가상 센서들은 동적 오브젝트를 감지하여 동적 센싱 데이터를 확보할 수 있다. 이에 따라, 가상 로봇의 위치와 동적 오브젝트의 위치를 비교하면, 가상 이동형 로봇이 동적 오브젝트와 충돌하였는지 여부를 확인할 수 있다. 정적 센싱 데이터는 정적 오브젝트들의 위치에 관한 정보를 포함할 수 있다. 동적 센싱 데이터는 가상 공간 내 에서 이동하는 동적 오브젝트의 위치 변화에 관한 정보를 포함할 수 있다. 제2 프로세서는 정적 센싱 데 이터 및 동적 센싱 데이터를 이용하여, 가상 이동형 로봇의 위치와 정적 오브젝트들 및 동적 오브젝트들의 위치 가 중첩되는지 여부를 판단할 수 있다. 이를 통해, 제2 프로세서는 가상 이동형 로봇이 정적 오브젝트들 및 동적 오브젝트들과 충돌하였는지 여부를 판단할 수 있다. 가상 로봇이 정적 오브젝트들 및 동적 오브젝트들과 충돌한 경우, 가상 이동형 로봇의 주행 조건을 수정할 수 있다. 그 후, 수정된 주행 조건에 따라, 가상 이동형 로봇이 가상 공간 내에서 주행하도록 가상 이동형 로봇을 제어할 수 있다. 구체적인 예는 도 12 내지 도 15에서 후술한다. 제2 메모리는 제2 프로세서의 처리 및 제어를 위한 하나 이상의 모듈, 인공지능 모델, 프로 그램, 명령어 또는 데이터를 저장할 수 있다. 예를 들어, 제2 메모리는 메모리에 저장된 적어도 하 나의 인공지능 모델 중 어느 하나의 인공지능 모델을 저장할 수 있으며, 제2 메모리에 저장된 인공지능 모델은 제2 프로세서에 의해 실행될 수 있다. 다양한 실시 예에서, 제2 메모리는 플래시 메 모리 타입(flash memory type), 하드디스크 타입(hard disk type), 멀티미디어 카드 마이크로 타입(multimedia card micro type), 카드 타입의 메모리(예를 들어 SD 또는 XD 메모리 등), 램(RAM, Random Access Memory) SRAM(Static Random Access Memory), 롬(ROM, Read-Only Memory), EEPROM(Electrically Erasable Programmable Read-Only Memory), PROM(Programmable Read-Only Memory), 자기 메모리, 자기 디스크, 광디스크 중 적어도 하나의 타입의 저장매체를 포함할 수 있다. 센싱부는, 이동형 로봇의 상태 또는 이동형 로봇 주변 환경의 상태를 감지하고, 감지된 정보 를 프로세서로 전달할 수 있다. 일 실시 예에 의한 센싱부에 의해 감지된 다양한 정보에 기초하여, 인공지능 모델을 갱신하는데 이용되는 상황 정보가 획득될 수 있다. 예를 들면, 센싱부에 의해 감지된 사용자 또는 주변환경에 관한 다양한 종 류의 센싱 정보에 기초하여, 상황 정보 중 주변 환경에 관한 정보가 획득될 수 있다. 센싱부는 보조 센서, 제1 센서, 제2 센서, 제3 센서 등을 포함할 수 있다. 보조 센서는 현실 공간의 환경을 감지할 수 있다. 보조 센서는 현실 공간의 환경 요소의 정도를 측 정할 수 있다. 예를 들어, 보조 센서는 물체의 색상, 물체의 투명도, 주변 밝기, 온도, 습도, 소음, 풍량, 풍향, 먼지 농도 등을 측정할 수 있다. 단, 이는 예시일 뿐, 본 발명의 기술적 사상은 이에 한정되지 않 는다. 제1 센서 내지 제3 센서 등(1410, 1420, 1430)은 현실 공간의 물체의 위치를 감지할 수 있다. 예를 들어, 제1 센서는 라이다(Lidar) 센서일 수 있고, 제2 센서는 카메라 센서일 수 있고, 제3 센서는 초음파 센서일 수 있고, 제4 센서는 ToF(Time of Flight) 센서일 수 있다. 단, 이는 예시일 뿐, 본 발명의 기술적 사상은 이에 한정되지 않는다. 제1 센서 내지 제3 센서 등(1410, 1420, 1430)이 감지한 물체의 위치 데이터는 보조 센서에 의해 측정된 환경 요소의 정도에 따라 달라질 수 있다. 예를 들어, 대상 물체가 투명한 경우에, 라이다 센서에 의해 감지된 대상 물체의 위치는 명확히 인식되지 않을 수 있다. 이에 반해, 대상 물체가 투명하지 않은 경우에, 라이다 센 서에 의해 감지된 대상 물체의 위치는 명확하게 인식될 수 있다. 센싱부는, 그 외에도 지자기 센서(Magnetic sensor), 가속도 센서(Acceleration sensor), 온/습도 센서, 적외선 센서, 자이로스코프 센서, 위치 센서(예컨대, GPS), 기압 센서, 근접 센서, 및 RGB 센서(illuminance sensor) 중 적어도 하나를 포함할 수 있으나, 이에 한정되는 것은 아니다. 한편, 프로세서는 시뮬레이터를 실행하여, 복수의 가상 센서들을 포함하는 가상의 이동형 로봇을 주행시 킬 수 있다. 시뮬레이션 내에서, 가상 센서들은 정적 오브젝트 및 동적 오브젝트를 감지하여, 정적 센싱 데이터 및 동적 센싱 데이터를 획득할 수 있다. 참고적으로, 정적 오브젝트 및 동적 오브젝트는 센싱부에 의해 수집된 데이터를 이용하여 가상 공간 내에 생성될 수 있다. 시뮬레이터를 통해, 가상 이동형 로봇은 주행하는 동안 정적 오브젝트 및 동적 오브젝트와 충돌없이 안전하게 주행하였는지 확인할 수 있다. 통신 인터페이스는 이동형 로봇과 외부 디바이스 또는 서버 사이의 유선 또는 무선 통 신 채널의 수립 및 수립된 통신 채널을 통한 통신 수행을 지원할 수 있다. 일 실시 예에 따르면, 통신 인터페이 스는 유선 통신 또는 무선 통신을 통해 외부 디바이스 또는 서버로부터 데이터를 수신하거나 또는 외부 디바이스 또는 서버에 대해 데이터를 송신할 수 있다. 다양한 실시 예에 따르면, 통신 인터페이스는 무선 통신 모듈(예: 셀룰러 통신 모듈, 근거리 무선 통신 모듈, 또는 GNSS(global navigation satellite system) 통신 모듈) 또는 유선 통신 모듈(예: LAN(local area network) 통신 모듈, 또는 전력선 통신 모듈)을 포함할 수 있고, 그 중 어느 하나의 통신 모듈을 이용하여 적어도 하나의 네트워크, 예컨대, 근거리 통신 네트워크 (예: 블루투스, WiFi direct 또는 IrDA(infrared data association)) 또는 원거 리 통신 네트워크(예: 셀룰러 네트워크, 인터넷, 또는 컴퓨터 네트워크(예: LAN 또는 WAN))를 통하여 외부 디바 이스 또는 서버와 통신할 수 있다. 메모리는, 프로세서의 처리 및 제어를 위한 프로그램을 저장할 수 있고, 이동형 로봇으로 입 력되거나 이동형 로봇으로부터 출력되는 데이터를 저장할 수도 있다. 또한, 일 실시 예에 의한 메모리는 적어도 하나의 시뮬레이션을 수행하는데 이용될 수 있는 적어도 하나 의 인공지능 모델과, 인공지능 모델을 갱신하는데 이용될 수 있는 이동형 로봇의 상황 정보를 저장할 수 있다. 메모리는 플래시 메모리 타입(flash memory type), 하드디스크 타입(hard disk type), 멀티미디어 카드 마이크로 타입(multimedia card micro type), 카드 타입의 메모리(예를 들어 SD 또는 XD 메모리 등), 램(RAM, Random Access Memory) SRAM(Static Random Access Memory), 롬(ROM, Read-Only Memory), EEPROM(Electrically Erasable Programmable Read-Only Memory), PROM(Programmable Read-Only Memory), 자기 메모리, 자기 디스크, 광디스크 중 적어도 하나의 타입의 저장매체를 포함할 수 있다. 상기에서는 전자 장치가 이동형 로봇인 경우를 예로 들어 설명하였지만, 이에 제한되지 않는다. 전자 장치는 서버일 수 있으며, 이 경우, 서버는 통신 인터페이스(미도시)를 통하여, 이동형 로봇 의 센싱부가 수집한 센싱 데이터를 이용하여, 실제 공간을 나타내는 가상 공간, 가상 공간 내의 정 적 오브젝트 및 동적 오브젝트를 생성할 수 있다. 서버는 이동형 로봇에 대응되는 가상 이동형 로 봇을 생성할 수 있다. 가상 이동형 로봇은 복수의 가상 센서를 포함할 수 있다. 서버는 가상 이동형 로봇이 가상 공간 내에서 주행하도록 제어할 수 있다. 가상 이동형 로봇이 주행하는 동안, 가상 이동형 로봇의 복수의 가상 센서들은 정적 오브젝트 및 동적 오브젝트를 감지하여, 정적 센싱 데이 터 및 동적 센싱 데이터를 획득할 수 있다. 서버는 정적 센싱 데이터 및 동적 센싱 데이터를 이용하여, 가상 이동형 로봇이 정적 오브젝트들 및 동적 오브젝트들과 충돌하지 않도록, 이동형 로봇의 안전을 위한 인공지능 모델을 훈련시킬 수 있다. 서버는 훈련된 인공지능 모델을 이동형 로봇에게 제공할 수 있다. 서버 내의 프로세서는 이동형 로봇의 제어부와 같이, 인공지능 모델을 위한 제2 프로세서(미 도시) 및 서버의 동작 제어를 위한 제1 프로세서(미도시)를 포함할 수 있다. 도 4는 일 실시 예에 따른, 전자 장치가 이동형 로봇의 안전을 위한 인공지능 모델을 재훈련시키는 방법을 나타 내는 도면이다. 설명의 편의상, 도 1을 이용하여 설명한 것과 중복되는 부분은 간략히 하거나 생략한다. 도 4을 참조하면, 이동형 로봇의 안전을 위한 인공지능 모델을 훈련시키는 방법에서, 프로세서는 혼합 현 실(Mixed Reality)을 구현한다. 프로세서는 가상 환경(Virtual Reality)을 구성할 수 있다. 가상 환경은 가상 공간, 정적 오브젝트 및 가 상 이동형 로봇을 포함할 수 있다. 즉, 프로세서는 정적 오브젝트를 생성할 수 있고(도 2의 111), 가상 이동형 로봇을 생성할 수 있다(도 2의 112). 프로세서는 가상 환경 내에 동적 오브젝트(Augmented Reality)를 생성할 수 있다. 가상 환경에 대응되는 실제 환경에서 실시간으로 이동하는 객체에 대응하여, 프로세서는 가상 환경 내에 동적 오브젝트를 생성할 수 있다. 가상 이동형 로봇과 동적 오브젝트 간의 상대적인 위치 관계를 파악할 수 있도록, 가상 환경에 대한 데이터(VR) 및 동적 오브젝트에 대한 데이터(AR)는 통합될 수 있다. 가상 환경에 대한 데이터 및 동적 오브젝트에 대한 데이터를 이용하여, 이동형 로봇의 안전을 위한 인공지능 모 델이 학습될 수 있다. 즉, 정적 오브젝트의 위치, 배치에 관한 정보와, 가상 이동형 로봇의 위치, 배치, 이동 속도, 이동 방향, 경로 등에 관한 정보, 및 동적 오브젝트의 위치, 배치, 이동 속도, 이동 방향, 경로, 이 동 성향에 관한 정보는, 이동형 로봇의 안전을 위한 적어도 하나의 인공지능 모델의 훈련에 사용될 수 있다. 이동형 로봇의 안전을 위한 인공지능 모델은 가상 이동형 로봇이 가상 공간 내에서 주행하는 시뮬레이션을 수행 함으로써, 오브젝트들과 충돌하는지 여부에 대한 데이터를 출력할 수 있다. 오브젝트들과 충돌하는지 여부는, 인공지능 모델에서 가상 이동형 로봇이 안전하게 주행하는지 판단하기 위한 척도일 수 있다. 단, 이는 예시일 뿐, 본 발명의 기술적 사상은 이에 한정되지 않는다. 예를 들어, 가상 이동형 로봇과 오브젝트 간의 충돌을 방지하기 위한 보호 정지 거리가 설정될 수 있다. 가상 이동형 로봇과 오브젝트 간의 거리가 보호 정지 거리보다 큰 경우, 인공지능 모델에서 가상 이동형 로봇이 안전하게 주행했다고 판단될 수 있다. 즉, 가상 이동형 로봇 및 오브젝트 간의 거리와 보호 정지 거리 간의 비교는 인공지능 모델에서 가상 이동형 로봇이 안전 하게 주행하는지 판단하기 위한 척도일 수 있다. 시뮬레이션을 통해 가상 이동형 로봇이 안전하지 못하게 주행한 것으로 판단되는 경우, 인공지능 모델은 새로운 안전 보장 조건을 추가할 수 있다. 즉, 오브젝트들과 충돌하였는지 여부에 대해 출력한 데이터를 이용하여, 인공지능 모델은 새로운 안전 보장 조건을 추가할 수 있다. 안전 보장 조건은 가상 이동형 로봇이 오브젝트와의 충돌없이 안전하게 주행하도록 하는 주행 조건일 수 있다. 예를 들어, 안전 보장 조건은 가상 이동형 로봇의 주행 속도, 보호 정지 거리, 주행 경로, 정지 조건(거리 및 속도), 가속도(출발 또는 정지시) 등을 포함할 수 있다. 일 예로, 인공지능 모델은 다가오는 동적 오브젝트와의 충돌을 방지하기 위해, 가상 이동형 로봇의 주행 속도를 줄일 수 있다. 다른 예로, 인공지능 모델은 경로가 겹치는 동적 오브젝트와의 충돌을 방지하기 위해, 가상 이동 형 로봇의 이동 경로를 수정할 수 있다. 가상 환경에 대한 데이터, 동적 오브젝트에 대한 데이터 및 새로운 안전 보장 조건을 이용하여, 이동형 로봇의 안전을 위한 인공지능 모델이 재학습될 수 있다. 이동형 로봇의 안전을 위한 인공지능 모델은 가상 이동형 로봇이 가상 공간 내에서 주행하는 시뮬레이션을 재수행함으로써, 오브젝트들과 충돌하는지 여부에 대한 데이터 를 재출력할 수 있다. 오브젝트들과 충돌하였는지 여부에 대해 재출력한 데이터를 이용하여, 인공지능 모델은 새로운 안전 보장 조건을 추가할 수 있다. 가상 환경에 대한 데이터, 동적 오브젝트에 대한 데이터 및 새로운 안전 보장 조건을 이용하여, 이동형 로봇의 안전을 위한 인공지능 모델은 반복적으로 학습될 수 있다. 반복적으로 학습된 인공지능 모델은 실제 이동형 로 봇에 반영될 수 있다. 즉, 훈련된 인공지능 모델을 이용하여 실제 공간 내에서의 이동형 로봇의 주행은 제 어될 수 있다. 이를 통해, 인공지능 모델이 반영된 실제 이동형 로봇은 실제 공간 내에서 정적 오브젝트 및 동 적 오브젝트와의 충돌없이 안정적으로 주행할 수 있다.도 5는 일 실시 예에 따른, 전자 장치가 이동형 로봇의 안전을 위한 인공지능 모델을 학습하기 위한 정보 처리 를 수행하는 방법을 나타내는 도면이다. 설명의 편의상, 도 1 내지 도 4를 이용하여 설명한 점과 중복되는 것은 간략히 하거나 생략한다. 도 5을 참조하면, 제1 프로세서는 시뮬레이터 및 브로커를 포함할 수 있다. 시뮬레이터는 가상 환경(Virtual Reality)을 구성할 수 있다. 시뮬레이터는 실제 공간을 나타내는 가 상 공간, 가상 이동형 로봇 및 가상 공간 내의 정적 오브젝트들을 생성할 수 있다. 실제 공간을 주행 하는 이동형 로봇의 복수의 센서들은 센싱 데이터를 수집할 수 있다. 또한, 사용자는 VR(Virtual Reality) 장치를 착용한 후, 실제 공간 내를 이동할 수 있다. 사용자가 실제 공간 내를 이동하는 동안, VR 장 치는 실제 공간 내의 센싱 데이터를 수집할 수 있다. 시뮬레이터는 복수의 센서들 및 VR 장치(100 4)가 수집한 센싱 데이터를 이용하여, 가상 공간, 가상 이동형 로봇 및 정적 오브젝트들을 생성할 수 있다. 시뮬레이터는 가상 공간, 가상 이동형 로봇 및 정적 오브젝트들의 위치에 관한 정보를 수 집할 수 있다. 브로커는 가상 공간 내의 동적 오브젝트들을 생성할 수 있다. 실제 공간을 주행하는 이동형 로봇의 복수의 센서들은 센싱 데이터를 수집할 수 있다. 또한, 사용자는 모션 트래커(motion tracker)를 착 용한 후, 실제 공간 내를 이동할 수 있다. 사용자가 실제 공간 내를 이동하는 동안, 모션 트래커는 사용자가 실제 공간 내를 이동한 자취에 관한 모션 센싱 데이터를 수집할 수 있다. 브로커는 복수의 센서들 및 모션 트래커가 수집한 모션 센싱 데이터를 이용하여, 동적 오브젝트들을 생성할 수 있다. 브로커는 동적 오브젝트들의 위치에 관한 정보를 수집할 수 있다. 예를 들어, 모션 트래커가 수집한 모션 센싱 데이터를 이용하여 생성된 동적 오브젝트는 실제 공간 을 나타내는 가상 공간 내에서, 사용자가 실제 공간 내 이동한 자취를 따라 이동할 수 있다. 브로커는 시뮬레이터로부터 가상 공간, 가상 이동형 로봇 및 정적 오브젝트들의 위치에 관 한 정보를 수집할 수 있다. 브로커는 가상 공간, 가상 이동형 로봇 및 정적 오브젝트들의 위치 에 관한 정보와, 동적 오브젝트들의 위치에 관한 정보를 통합할 수 있다. 이에 따라, 가상 이동형 로봇 과 동적 오브젝트들 간의 상대적인 위치 관계가 파악될 수 있다. AI 프로세싱 유닛은 브로커로부터 가상 공간, 가상 이동형 로봇 및 정적 오브젝트들의 위 치에 관한 정보와, 동적 오브젝트들의 위치에 관한 정보를 전달받을 수 있다. AI 프로세싱 유닛은 통합된 정보를 활용하여, 가상 이동형 로봇이 주행하는 동안 동적 오브젝트들과 충돌하는지 여부를 파악할 수 있다. AI 프로세싱 유닛은 적어도 하나의 인공지능 모델에 대한 훈련 및 적용을 수행할 수 있다. 또한, 사용자는 생성된 정적 오브젝트, 가상 이동형 로봇 및 동적 오브젝트를 VR 장치 , 예를 들어, VR Glass를 통해 관찰할 수 있다. VR 장치는 사용자에 의해 착용될 수 있다. 도 6은 일 실시 예에 따른, 이동형 로봇의 안전을 위한 인공지능 모델에 입력되는, 가상 센서에 의해 감지된 동 적 오브젝트의 레이어에 대한 도면이다. 도 7은 일 실시 예에 따른, 이동형 로봇의 안전을 위한 인공지능 모델에 입력되는, 가상 센서에 의해 감지된 동 적 오브젝트의 레이어의 속성에 대한 표이다. 도 6을 참조하면, 가상 이동형 로봇의 복수의 가상 센서들은 동적 오브젝트로서, 구체적으로 움직이는 사 람을 감지한다. 동적 오브젝트는 복수의 가상 센서들에 관련된 복수의 레이어(310, 320)를 포함한다. 구체적으로, 동적 오브젝트는 복수의 가상 센서들이 복수의 레이어(310, 320)를 각각 감지함으로써, 인식 될 수 있다. 복수의 레이어(310, 320)는 제1 레이어 및 제2 레이어를 포함한다. 즉, 복수의 가상 센서 중 적어도 하나의 가상 센서는 제1 레이어를 동적 오브젝트로 인식한다. 복수의 가상 센서 중 적어도 하나의 가 상 센서는 제2 레이어를 동적 오브젝트로 인식한다. 가상 이동형 로봇은 제1 레이어 및 제 2 레이어를 종합하여 동적 오브젝트를 인식한다. 구체적으로, 복수의 가상 센서는 동적 오브젝트에 대한 동적 센싱 데이터를 감지할 수 있다. 동적 센싱 데 이터는 동적 오브젝트의 위치에 관한 정보를 포함한다. 동적 센싱 데이터는 제1 동적 센싱 데이터 및 제2 동적 센싱 데이터를 포함할 수 있다. 제1 동적 센싱 데이터는 복수의 가상 센서들에 의해 제1 레이어를 감지하여 획득될 수 있다. 제2 동적 센 싱 데이터는 복수의 가상 센서들에 의해 제2 레이어를 감지하여 획득될 수 있다. 즉, 제1 레이어를 감지하여 획득한 제1 동적 센싱 데이터와, 제2 레이어를 감지하여 획득한 제2 동적 센싱 데이터를 종합하 여 동적 오브젝트는 인식될 수 있다. 복수의 레이어(310, 320)는 환경 요소를 반영하여, 복수의 가상 센서들에 의해 감지될 수 있다. 제1 레이어 는 제1 환경 요소에 대응되고, 제2 레이어는 제2 환경 요소에 대응된다. 즉, 제1 레이어는 제1 환경 요소를 반영하여, 복수의 가상 센서들에 의해 감지될 수 있다. 제2 레이어는 제2 환경 요소를 반영하 여, 복수의 가상 센서들에 의해 감지될 수 있다. 다시 말해, 제1 프로세서(도 3의 1310)는 제1 환경 요소의 정도를 측정할 수 있다. 측정된 제1 환경 요소의 정 도에 따라, 제1 프로세서(도 3의 1310)는 제1 가상 센서가 제1 레이어를 감지함으로써 생성되는 센싱 데이 터를 변경할 수 있다. 즉, 제1 레이어는 제1 환경 요소를 반영하여, 제1 가상 센서에 의해 감지될 수 있다. 일 예로, 제1 환경 요소는 주변 밝기일 수 있다. 복수의 가상 센서 중, 예를 들어, 라이다(Lidar) 센서 또는 ToF(Time of Flight) 센서는 태양광 환경에서 인식이 어려울 수 있다. 마찬가지로, 복수의 가상 센서 중, 예를 들어, 카메라 센서는 어두운 환경에서 인식이 어려울 수 있다. 다른 예로, 제1 환경 요소는 물체의 투명도일 수 있다. 복수의 가상 센서 중, 예를 들어, 라이다 센서 또는 카 메라 센서는 투명한 물체를 인식하지 못할 수 있다. 이에 반해, 초음파 센서는 투명한 물체를 인식할 수 있다. 다른 예로, 제1 환경 요소는 주변 온도일 수 있다. 복수의 가상 센서 중, 예를 들어, 초음파 센서의 경우, 주변 온도가 높으면 실제 물체와의 거리보다 측정 거리가 길게 측정된다. 도 7을 참조하면, 동적 오브젝트를 나타내는 복수의 레이어는 다양한 환경 요소를 반영할 수 있다. 환경 요소는 물체의 색상 및 투명도, 주변 밝기, 온도 및 습도, 소음의 크기, 바람 및 먼지의 양일 수 있다. 예를 들어, 도시된 바와 같이, 제1 레이어는 물체의 색상 및 투명도를 반영할 수 있다. 제2 레이어는 주변 밝기 를 반영할 수 있다. 제3 레이어는 온도 및 습도를 반영할 수 있다. 제4 레이어는 소음의 크기를 반영할 수 있다. 제5 레이어는 바람의 양 및 방향과, 먼지의 양 등을 반영할 수 있다. 동적 오브젝트의 복수의 레이어는 복수의 가상 센서에 의해 감지될 수 있다. 예를 들어, 제1 레이어는 복수의 가상 센서들 중에서 적어도 제1 가상 센서에 의해 감지될 수 있다. 제2 레이어는 복수의 가상 센서들 중에서 적 어도 제2 가상 센서에 의해 감지될 수 있다. 복수의 가상 센서는 도 6에 도시된 바와 같이, 라이다(Lidar) 센서, 카메라 센서, 초음파 센서, ToF(Time of Flight) 센서를 포함할 수 있다. 단, 가상 센서의 종류는 예시일 뿐, 본 발명의 기술적 사상은 이에 한정되지 않는다. 제1 레이어는 물체의 색상 및 투명도를 반영하여, 복수의 가상 센서들에 의해 감지될 수 있다. 예를 들어, 검은 색이거나 투명한 물체의 경우, 제1 레이어는 라이다 센서 및 ToF 센서에 의해 감지되지 않을 수 있다. 다른 예 로, 투명한 물체의 경우, 제1 레이어는 카메라 센서에 의해 감지되지 않을 수 있다. 제2 레이어는 주변의 밝기를 반영하여, 복수의 가상 센서들에 의해 감지될 수 있다. 예를 들어, 태양광이 비치 는 환경에서, 제2 레이어는 라이다 센서 및 ToF 센서에 의해 감지되지 않을 수 있다. 다른 예로, 어두운 환경에 서, 제2 레이어는 카메라 센서에 의해 감지되지 않을 수 있다. 제3 레이어는 주변의 온도 및 습도를 반영하여, 복수의 가상 센서들에 의해 감지될 수 있다. 예를 들어, 주변 온도가 높은 환경에서, 제3 레이어와 초음파 센서에 의해 측정된 거리가 정확하지 않을 수 있다. 구체적으로, 주변 온도가 높은 환경에서, 초음파 센서에 의해 측정된 거리는 실제 거리보다 길 수 있다. 제4 레이어는 주변의 소음의 크기를 반영하여, 복수의 가상 센서들에 의해 감지될 수 있다. 예를 들어, 주변의 소음의 크기가 큰 경우, 제4 레이어와 초음파 센서에 의해 측정된 거리는 정확하지 않을 수 있다. 제5 레이어는 바람의 양, 방향 및 먼지의 양을 반영하여, 복수의 가상 센서들에 의해 감지될 수 있다. 예를 들 어, 바람의 양 및 먼지의 양이 많은 경우, 제5 레이어와 초음파 센서에 의해 측정된 거리는 정확하지 않을 수 있다. 도 8 및 도 9는 일 실시 예에 따른 이동형 로봇의 안전을 위한 인공지능 모델에서, 동적 오브젝트가 인식되는 방식을 설명하기 위한 도면들이다. 도 8 및 도 9를 참조하면, 가상 이동형 로봇은 복수의 가상 센서와 가상 센서를 통해 감지한 복수의 레이 어를 이용하여, 동적 오브젝트를 인식할 수 있다. 참고적으로, 도 8은 복수의 레이어(310, 320)를 감지함으로써, 복수의 가상 센서가 동적 오브젝트를 감지 하는 것을 설명하기 위한 도면이다. 도시되지는 않았지만, 가상 이동형 로봇은 복수의 가상 센서를 포함할 수 있다. 복수의 가상 센서 중 적어 도 제1 가상 센서는 제1 레이어를 감지할 수 있다. 제1 레이어는 제1 환경 요소를 반영하여, 복수의 가상 센서 중 적어도 제1 가상 센서에 의해 감지될 수 있다. 예를 들어, 제1 환경 요소는 물체의 색상, 물체의 투명도, 주변 밝기, 온도, 습도, 소음, 풍량, 풍향, 먼지 농 도 중 적어도 하나를 포함할 수 있다. 복수의 가상 센서 중 적어도 제1 가상 센서는 제2 레이어를 감지할 수 있다. 제2 레이어는 제2 환경 요소를 반영하여, 복수의 가상 센서 중 적어도 제1 가상 센서에 의해 감지될 수 있다. 예를 들어, 제2 환경 요소는 물체의 색상, 물체의 투명도, 주변 밝기, 온도, 습도, 소음, 풍량, 풍향, 먼지 농 도 중 적어도 하나를 포함할 수 있다. 단, 제2 환경 요소는 제1 환경 요소와 다를 수 있다. 제1 가상 센서는 제1 레이어 및 제2 레이어를 감지함으로써, 동적 오브젝트를 인식할 수 있다. 제1 가상 센서는 제1 레이어 및 제2 레이어를 동적 오브젝트로 인식할 수 있다. 참고적으로 도 9는 단일 레이어(310a, 310b)가 서로 다른 복수의 가상 센서를 통해 감지됨으로써, 복수의 가상 센서가 동적 오브젝트를 감지하는 것을 설명하기 위한 도면이다. 복수의 가상 센서 중 적어도 제1 가상 센서는 제1 레이어를 감지할 수 있다. 제1 레이어는 제1 환경 요소를 반영하여, 복수의 가상 센서 중 적어도 제1 가상 센서에 의해 감지될 수 있다. 복수의 가상 센서 중 적어도 제2 가상 센서는 제1 레이어를 감지할 수 있다. 제1 레이어는 제1 환경 요소를 반영하여, 복수의 가상 센서 중 적어도 제2 가상 센서에 의해 감지될 수 있다. 예를 들어, 제1 환경 요소는 물체의 색상, 물체의 투명도, 주변 밝기, 온도, 습도, 소음, 풍량, 풍향, 먼지 농 도 중 적어도 하나를 포함할 수 있다. 예를 들어, 물체가 투명한 경우, 제1 가상 센서로서 카메라 센서는 제1 레이어를 인식하기 어려울 수 있다. 동 시에, 물체가 투명한 경우, 제2 가상 센서로서 초음파 센서는 제1 레이어를 인식하기 쉬울 수 있다. 따라서, 제 2 가상 센서에 의해 인식한 제1 레이어(310b)를 중점적으로 하여, 동적 오브젝트는 인식될 수 있다. 도 8 및 도 9에서 설명한 가상 센서의 종류, 개수 및 레이어의 개수는 예시일 뿐, 본 발명의 기술적 사상은 이 에 한정되지 않는다. 도 10은 일 실시 예에 따른, 이동형 로봇의 안전을 위한 인공지능 모델에 입력되는 가상 공간, 정적 오브젝트 및 동적 오브젝트에 대한 도면이다. 도 11은 일 실시 예에 따른 이동형 로봇의 안전을 위한 인공지능 모델에서, 동적 오브젝트가 가상 공간 내에서 이동하는 경로를 설명하기 위한 도면이다. 도 10을 참조하면, 프로세서가 구성한 가상 환경이 도시된다. 가상 환경은 가상 공간, 정적 오브젝트, 가상 이동형 로봇 및 동적 오브젝트를 포함할 수 있다. 정적 오브젝트는 가상 공간 내에 배치될 수 있다. 정적 오브젝트는 움직임이 없는 물체를 의미할 수 있다. 예를 들어, 정적 오브젝트는 탁자이거나, 벽일 수 있다. 이는 예시일 뿐, 본 발명의 기술 적 사상은 이에 한정되지 않는다.가상 이동형 로봇은 가상 공간 내에 배치될 수 있다. 가상 이동형 로봇은 가상 공간 내에서 주행할 수 있다. 가상 이동형 로봇의 이동 방식은 본 발명의 기술적 사상을 한정하지 않는다. 예를 들어, 가상 이 동형 로봇은 바닥면에 배치된 바퀴를 통해 주행할 수 있다. 동적 오브젝트는 가상 공간 내에 배치될 수 있다. 동적 오브젝트는 움직임이 있는 물체를 의미할 수 있다. 예를 들어, 동적 오브젝트는 움직이는 반려동물, 움직이는 다수의 사람, 움직이는 행인 , 아기 등일 수 있다. 동적 오브젝트의 종류는 예시일 뿐, 본 발명의 기술적 사상은 이에 한정 되지 않는다. 예를 들어, 움직이는 반려동물은 강아지로 도시되었으나, 고양이일 수 있다. 다른 예로, 동적 오브젝트 는 굴러가는 공일 수 있다. 동적 오브젝트가 움직이는 성향은 동적 오브젝트의 종류에 따라 다를 수 있다. 동적 오브젝트가 움직이는 성향은 예를 들어, 이동 속도, 이동 방향, 이동 궤도 등을 포함할 수 있다. 예를 들어, 움직이는 반려동물은 빠른 이동 속도를 가질 수 있고, 무작위의 이동 방향을 가질 수 있다. 다른 예로, 움직이는 다수의 사람은 보통의 이동 속도를 가질 수 있고, 출구를 향하여 이동할 수 있다. 여 기서, 보통의 이동 속도는 반려동물의 빠른 이동 속도보다는 상대적으로 느린 것을 의미한다. 다른 예로, 움직이는 행인은 보통의 이동 속도를 가질 수 있고, 임의로 설정된 이동 방향을 가질 수 있다. 다른 예로, 아기는 느린 이동 속도를 가질 수 있고, 무작위의 이동 방향을 가질 수 있다. 여기서, 느린 이 동 속도는 다수의 사람 및 움직이는 행인의 보통 이동 속도보다는 상대적으로 느린 것을 의미한다. 도 11a 및 도 11b를 참조하여, 움직이는 행인의 이동 방향을 설정하는 것을 설명한다. 도 11a를 참조하면, 실제 공간 내를 이동하는 사용자는 모션 트래커(motion tracker)를 착용 할 수 있다. 모션 트래커를 착용한 사용자는 실제 공간 내를 이동할 수 있다. 동시에, 모션 트래커 는 모션 센싱 데이터(motion sensing data)를 수집할 수 있다. 모션 센싱 데이터는 사용자가 실제 공간 내를 이동한 자취(631a)에 관한 정보를 포함할 수 있다. 예를 들 어, 모션 센싱 데이터는 사용자의 이동 속도, 이동 방향, 이동 경로 등을 포함할 수 있다. 모션 센싱 데이터를 이용하여, 실제 공간과 대응되는 가상 공간 내의 동적 오브젝트, 즉, 움직이는 행인이 생성될 수 있다. 도 11b에 도시된 바와 같이, 움직이는 행인은 사용자가 이동한 자취(631a)와 동일한 경로(631b)로 이동할 수 있다. 도 12 내지 도 15는 일 실시 예에 따른, 전자 장치가 이동형 로봇의 안전을 위한 인공지능 모델을 훈련시키는 방법을 나타내는 도면이다. 도 12 내지 도 15를 참조하면, 프로세서는 가상 이동형 로봇이 이동하기 전, 가상 이동형 로봇의 주 행 조건을 설정할 수 있다. 예를 들어, 주행 조건은 가상 이동형 로봇의 주행 속도, 주행 경로, 주행 가속 도(출발 또는 정지시) 등을 포함할 수 있다. 참고적으로, 도 12 내지 도 15에서, 가상 이동형 로봇의 주행 경로는 일직선 방향으로 설정되었으나, 이는 예시일 뿐, 본 발명의 기술적 사상은 이에 한정되지 않는다. 주행 조건이 설정된 후, 프로세서는 시뮬레이터를 실행하여 가상 이동형 로봇을 출발 지점에서 도착 지점으로 이동시킬 수 있다. 가상 이동형 로봇은 정적 오브젝트와 충돌하지 않는 주행 경로를 따라 이동할 수 있다. 도 12에 도시된 바와 같이, 가상 이동형 로봇이 주행하는 동안, 동적 오브젝트로서 아기가 출현할 수 있다. 아기는 가상 이동형 로봇의 전방에 위치한 교차로에서, 가상 이동형 로 봇의 진행 방향과 수직한 방향으로 이동하는 것으로 도시되었으나, 이는 예시일 뿐, 본 발명의 기술적 사 상은 이에 한정되지 않는다. 가상 이동형 로봇은 설정된 주행 조건 하에서, 아기와 충돌하거나, 충돌하지 않을 수 있다. 가상 이동형 로봇이 아기와 충돌하는 경우, 인공지능 모델로부터 출력되는 충돌 여부에 관한 정보에 기초하여, 프로세서는 새로운 안전 보장 조건을 추가(도 4의 250)할 수 있다. 예를 들어, 안전 보장 조건은 가상 이동형 로봇의 주행 속도, 보호 정지 거리, 주행 경로, 정지 조건(거리 및 속도), 가속도(출발 또는 정지시) 등을 포함할 수 있다. 구체적으로, 측면 방향에서 통로가 인식되는 경우, 가상 이동형 로봇은 일시 정지한다는 안전 보장 조건이 설정될 수 있다. 다른 예로, 가상 이동형 로봇의 진행 방향에 교차로가 출현시, 교차로 진입 전 가상 이동형 로봇은 일시정지한다는 안전 보장 조건이 추가될 수 있다. 단, 이는 예시일 뿐, 본 발명의 기술적 사상은 이에 한정되 지 않는다. 가상 이동형 로봇이 아기와 충돌하지 않는 경우, 프로세서는 또다른 시뮬레이션을 수행할 수 있다. 예를 들어, 도 13 내지 도 15에 도시된 상황에 따른 시뮬레이션이 수행될 수 있다. 도 13에 도시된 바와 같이, 가상 이동형 로봇이 주행하는 동안, 동적 오브젝트로서 다수의 사람이 출 현할 수 있다. 다수의 사람은 가상 이동형 로봇의 전방에 무리지어 배치되는 것으로 도시되었으나, 이는 예시일 뿐, 본 발명의 기술적 사상은 이에 한정되지 않는다. 예를 들어, 다수의 사람은 가상 이동형 로봇의 사방에 흩어져 배치될 수 있다. 가상 이동형 로봇은 설정된 주행 조건 하에서, 다수의 사람과 충돌하거나, 충돌하지 않을 수 있다. 가상 이동형 로봇이 다수의 사람과 충돌하는 경우, 인공지능 모델로부터 출력되는 충돌 여부에 관한 정보에 기초하여, 프로세서는 새로운 안전 보장 조건을 추가(도 4의 250)할 수 있다. 예를 들어, 가상 이동형 로봇의 진행 방향에 다수의 사람이 출현시, 가상 이동형 로봇은 우회한다는 안전 보장 조건이 추가될 수 있다. 단, 이는 예시일 뿐, 본 발명의 기술적 사상은 이에 한정되지 않는다. 가상 이동형 로봇이 다수의 사람과 충돌하지 않는 경우, 프로세서는 또다른 시뮬레이션을 수행할 수 있다. 예를 들어, 도 12, 도 14 및 도 15에 도시된 상황에 따른 시뮬레이션이 수행될 수 있다. 도 14에 도시된 바와 같이, 가상 이동형 로봇이 주행하는 동안, 동적 오브젝트로서 움직이는 반려동물 이 출현할 수 있다. 반려동물은 가상 이동형 로봇의 전방에 앉아있는 것으로 도시되었으나, 이 는 예시일 뿐, 본 발명의 기술적 사상은 이에 한정되지 않는다. 예를 들어, 반려동물은 가상 이동형 로봇 을 향해 이동할 수 있다. 가상 이동형 로봇은 설정된 주행 조건 하에서, 반려동물과 충돌하거나, 충돌하지 않을 수 있다. 가상 이동형 로봇이 반려동물과 충돌하는 경우, 인공지능 모델로부터 출력되는 충돌 여부에 관한 정 보에 기초하여, 프로세서는 새로운 안전 보장 조건을 추가(도 4의 250)할 수 있다. 예를 들어, 가상 이동형 로 봇의 진행 방향에 반려동물이 출현시 가상 이동형 로봇은 일시정지하고, 반려동물이 가상 이동형 로봇으로부터 멀어지면 가상 이동형 로봇은 다시 이동한다는 안전 보장 조건이 추가될 수 있 다. 단, 이는 예시일 뿐, 본 발명의 기술적 사상은 이에 한정되지 않는다. 가상 이동형 로봇이 반려동물과 충돌하지 않는 경우, 프로세서는 또다른 시뮬레이션을 수행할 수 있 다. 예를 들어, 도 12, 도 13 및 도 15에 도시된 상황에 따른 시뮬레이션이 수행될 수 있다. 도 15에 도시된 바와 같이, 가상 이동형 로봇이 주행하는 동안, 동적 오브젝트로서 좁은 통로벽이 출 현할 수 있다. 좁은 통로벽은 가상 이동형 로봇의 양 측면에 배치될 수 있다. 좁은 통로벽은 움 직임이 없을 수 있으나, 이는 예시일 뿐, 본 발명의 기술적 사상은 이에 한정되지 않는다. 예를 들어, 좁은 통 로벽은 공(Ball)의 집합일 수 있다. 즉, 공이 측벽 상에 나열되어 좁은 통로벽을 형성할 수 있다. 공 이 측벽 상에 나열되어 형성한 좁은 통로벽은, 공이 구름으로써 가상 이동형 로봇에 접근할 수 있다. 가상 이동형 로봇은 설정된 주행 조건 하에서, 좁은 통로벽과 충돌하거나, 충돌하지 않을 수 있다. 가상 이동형 로봇이 좁은 통로벽과 충돌하는 경우, 인공지능 모델로부터 출력되는 충돌 여부에 관한 정보에 기초하여, 프로세서는 새로운 안전 보장 조건을 추가(도 4의 250)할 수 있다. 예를 들어, 가상 이동형 로봇의 진행 방향에 좁은 통로벽이 출현시 가상 이동형 로봇은 속도를 줄이고 좁은 통로벽 사이로 직선주행한다는 안전 보장 조건이 추가될 수 있다. 단, 이는 예시일 뿐, 본 발명의 기술적 사상은 이에 한정되지 않는다. 가상 이동형 로봇이 좁은 통로벽과 충돌하지 않는 경우, 프로세서는 또다른 시뮬레이션을 수행할 수 있다. 예를 들어, 도 12 내지 도 15에 도시된 상황에 따른 시뮬레이션이 수행될 수 있다. 일부 실시예는 컴퓨터에 의해 실행되는 프로그램 모듈과 같은 컴퓨터에 의해 실행가능한 명령어를 포함하는 기 록 매체의 형태로도 구현될 수 있다. 컴퓨터 판독 가능 매체는 컴퓨터에 의해 액세스될 수 있는 임의의 가용 매 체일 수 있고, 휘발성 및 비휘발성 매체, 분리형 및 비분리형 매체를 모두 포함한다. 또한, 컴퓨터 판독가능 매 체는 컴퓨터 저장 매체 및 통신 매체를 모두 포함할 수 있다. 컴퓨터 저장 매체는 컴퓨터 판독가능 명령어, 데 이터 구조, 프로그램 모듈 또는 기타 데이터와 같은 정보의 저장을 위한 임의의 방법 또는 기술로 구현된 휘발 성 및 비휘발성, 분리형 및 비분리형 매체를 모두 포함한다. 통신 매체는 전형적으로 컴퓨터 판독가능 명령어, 데이터 구조, 프로그램 모듈, 또는 반송파와 같은 변조된 데이터 신호의 기타 데이터, 또는 기타 전송 메커니즘 을 포함하며, 임의의 정보 전달 매체를 포함한다. 기기로 읽을 수 있는 저장매체는, 비일시적(non-transitory) 저장매체의 형태로 제공될 수 있다. 여기서, ‘비 일시적 저장매체'는 실재(tangible)하는 장치이고, 신호(signal)(예: 전자기파)를 포함하지 않는다는 것을 의미 할 뿐이며, 이 용어는 데이터가 저장매체에 반영구적으로 저장되는 경우와 임시적으로 저장되는 경우를 구분하 지 않는다. 예로, '비일시적 저장매체'는 데이터가 임시적으로 저장되는 버퍼를 포함할 수 있다. 일 실시예에 따르면, 본 문서에 개시된 다양한 실시예들에 따른 방법은 컴퓨터 프로그램 제품(computer program product)에 포함되어 제공될 수 있다. 컴퓨터 프로그램 제품은 상품으로서 판매자 및 구매자 간에 거래될 수 있 다. 컴퓨터 프로그램 제품은 기기로 읽을 수 있는 저장 매체(예: compact disc read only memory (CD-ROM))의 형태로 배포되거나, 또는 어플리케이션 스토어를 통해 또는 두개의 사용자 장치들(예: 스마트폰들) 간에 직접, 온라인으로 배포(예: 다운로드 또는 업로드)될 수 있다. 온라인 배포의 경우에, 컴퓨터 프로그램 제품(예: 다운 로더블 앱(downloadable app))의 적어도 일부는 제조사의 서버, 어플리케이션 스토어의 서버, 또는 중계 서버의 메모리와 같은 기기로 읽을 수 있는 저장 매체에 적어도 일시 저장되거나, 임시적으로 생성될 수 있다."}
{"patent_id": "10-2021-0176112", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 일 실시 예에 따른, 전자 장치가 이동형 로봇의 안전을 위한 인공지능 모델을 훈련시키는 방법을 나타내 는 도면이다. 도 2는 일 실시 예에 따른, 전자 장치의 내부 구성을 도시한 블록도이다. 도 3은 일 실시 예에 따른, 이동형 로봇의 안전을 위한 인공지능 모델을 학습하기 위한 정보 처리를 수행하는 전자 장치의 블록도이다. 도 4는 일 실시 예에 따른, 전자 장치가 이동형 로봇의 안전을 위한 인공지능 모델을 재훈련시키는 방법을 나타 내는 도면이다. 도 5는 일 실시 예에 따른, 전자 장치가 이동형 로봇의 안전을 위한 인공지능 모델을 학습하기 위한 정보 처리 를 수행하는 방법을 나타내는 도면이다. 도 6은 일 실시 예에 따른, 이동형 로봇의 안전을 위한 인공지능 모델에 입력되는, 가상 센서에 의해 감지된 동 적 오브젝트의 레이어에 대한 도면이다. 도 7은 일 실시 예에 따른, 이동형 로봇의 안전을 위한 인공지능 모델에 입력되는, 가상 센서에 의해 감지된 동 적 오브젝트의 레이어의 속성에 대한 표이다. 도 8 및 도 9는 일 실시 예에 따른 이동형 로봇의 안전을 위한 인공지능 모델에서, 동적 오브젝트가 인식되는 방식을 설명하기 위한 도면들이다. 도 10은 일 실시 예에 따른, 이동형 로봇의 안전을 위한 인공지능 모델에 입력되는 가상 공간, 정적 오브젝트 및 동적 오브젝트에 대한 도면이다. 도 11a 및 도 11b는 일 실시 예에 따른 이동형 로봇의 안전을 위한 인공지능 모델에서, 동적 오브젝트가 가상 공간 내에서 이동하는 경로를 설명하기 위한 도면이다. 도 12 내지 도 15는 일 실시 예에 따른, 전자 장치가 이동형 로봇의 안전을 위한 인공지능 모델을 훈련시키는 방법을 나타내는 도면이다. 도면의 설명과 관련하여, 동일 또는 유사한 구성요소에 대해서는 동일 또는 유사한 참조 부호가 사용될 수 있다."}
