{"patent_id": "10-2022-0107179", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0028874", "출원번호": "10-2022-0107179", "발명의 명칭": "외부 디바이스에 의해 제어되는 증강 현실 디바이스 및 그 동작 방법", "출원인": "삼성전자주식회사", "발명자": "김기현"}}
{"patent_id": "10-2022-0107179", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "외부 디바이스에 의해 제어되는 증강 현실 디바이스(100)에 있어서, 웨이브가이드(waveguide)(122);상기 웨이브가이드(122)에 가상 객체를 투사하도록 구성되는 광학 엔진(124);웨어러블 디바이스(200)와 페어링(pairing)하고, 상기 웨어러블 디바이스(200)와 데이터를 송수신하도록 구성되는 통신 인터페이스(150);적어도 하나의 명령어들(instructions)를 저장하는 메모리(140); 및상기 적어도 하나의 명령어들을 실행하는 적어도 하나의 프로세서(130); 를 포함하고, 상기 적어도 하나의 프로세서(130)는, 상기 가상 객체 상에 오버레이되는(overlaid) 웨어러블 디바이스(200)를 인식하고,상기 인식된 웨어러블 디바이스(200)에 상기 가상 객체와 관련된 기능을 실행 또는 제어하기 위한 제어 권한의제공을 결정하고,상기 통신 인터페이스(150)를 제어하여, 상기 기능의 제어 권한, 상기 가상 객체의 특성 정보, 및 상기 기능과관련된 데이터 값 중 적어도 하나를 상기 웨어러블 디바이스(200)에 전송하고, 상기 전송된 제어 권한에 기초하여 상기 웨어러블 디바이스(200)에 의해 변경된 데이터 값을 상기 웨어러블 디바이스(200)로부터 수신하고,상기 수신된 데이터 값에 기초하여 상기 가상 객체와 관련된 기능의 데이터 값을 업데이트하는, 증강 현실 디바이스(100)."}
{"patent_id": "10-2022-0107179", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1 항에 있어서,상기 적어도 하나의 프로세서(130)는, 상기 웨어러블 디바이스(200)를 착용 또는 파지하고 있는 사용자의 손을 인식하고,상기 가상 객체가 상기 인식된 손에 의해 오버레이되는 시간이 기 설정된 시간을 초과하는지 여부에 기초하여,상기 웨어러블 디바이스(200)에 제어 권한을 제공할 것을 결정하는, 증강 현실 디바이스(100)."}
{"patent_id": "10-2022-0107179", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1 항에 있어서,상기 적어도 하나의 프로세서(130)는, 상기 웨어러블 디바이스(200)를 착용 또는 파지하고 있는 사용자의 손의 제스처를 인식하고, 상기 인식된 제스처에 기초하여 상기 웨어러블 디바이스(200)에 제어 권한을 제공할 것을 결정하는, 증강 현실디바이스(100).공개특허 10-2024-0028874-3-청구항 4 제1 항에 있어서,상기 적어도 하나의 프로세서(130)는, 상기 웨어러블 디바이스(200)를 착용 또는 파지하고 있는 사용자의 손에 의해 기 설정된 횟수 이상 반복되는 반복 동작을 인식하고, 상기 인식된 반복 동작에 기초하여 상기 웨어러블 디바이스(200)에 제어 권한을 제공할 것을 결정하는, 증강 현실 디바이스(100)."}
{"patent_id": "10-2022-0107179", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1 항 내지 제4 항 중 어느 하나의 항에 있어서,상기 가상 객체는 애플리케이션에 의해 제공되는 복수의 기능을 실행하기 위한 복수의 기능 UI(User Interface)를 포함하고, 상기 적어도 하나의 프로세서(130)는, 상기 복수의 기능 UI(User Interface) 중 상기 웨어러블 디바이스(200)에 제어 권한을 제공할 적어도 하나의 기능에 관한 기능 UI를 선택하는, 증강 현실 디바이스(100)."}
{"patent_id": "10-2022-0107179", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5 항에 있어서,상기 적어도 하나의 프로세서(130)는, 상기 복수의 기능 UI 중 상기 웨어러블 디바이스(200)를 착용 또는 파지하고 있는 사용자의 손에 의해 오버레이되는 기능 UI를 식별하고, 상기 식별된 기능 UI에 의해 실행 또는 제어되는 기능에 관한 제어 권한을 상기 웨어러블 디바이스(200)에 제공할 것을 결정하는, 증강 현실 디바이스(100)."}
{"patent_id": "10-2022-0107179", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제5 항에 있어서, 상기 적어도 하나의 프로세서(130)는, 상기 애플리케이션의 복수의 기능 각각에 관한 API(Application Programming Interface)의 제공 가능 여부에기초하여, 상기 적어도 하나의 기능 UI를 선택하는, 증강 현실 디바이스(100)."}
{"patent_id": "10-2022-0107179", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제5 항 내지 제7 항 중 어느 하나의 항에 있어서,상기 적어도 하나의 프로세서(130)는, 상기 광학 엔진(124)을 제어하여, 상기 선택된 적어도 하나의 기능 UI의 제어 영역을 상기 가상 객체 내의 다른영역과 구별되는 컬러로 표시하는, 증강 현실 디바이스(100)."}
{"patent_id": "10-2022-0107179", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "공개특허 10-2024-0028874-4-제1 항에 있어서,사용자의 좌안 및 우안의 시선 방향을 추적하여, 상기 좌안 및 우안의 시선 방향 정보를 획득하도록 구성되는시선 추적 센서;를 더 포함하고, 상기 적어도 하나의 프로세서(130)는,복수의 애플리케이션을 실행함으로써, 상기 복수의 애플리케이션에 의해 제공되는 복수의 가상 객체를 상기 웨이브가이드(122)를 통해 표시하고, 상기 시선 추적 센서를 통해 상기 사용자의 좌안의 시선 방향과 우안의 시선 방향이 수렴하는 응시점을 인식하고, 상기 인식된 응시점의 위치에 기초하여 실행 중인 상기 복수의 애플리케이션 중 어느 하나의 애플리케이션을 선택하고, 상기 선택된 애플리케이션에 의해 표시되는 적어도 하나의 가상 객체와 관련된 기능의 제어 권한을 상기 웨어러블 디바이스(200)에 제공할 것을 결정하는, 증강 현실 디바이스(100)."}
{"patent_id": "10-2022-0107179", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "증강 현실 디바이스(100)가 외부 디바이스에 의해 제어되는 방법에 있어서, 가상 객체 상에 오버레이되는(overlaid) 웨어러블 디바이스(200)를 인식하는 단계(S310); 상기 인식된 웨어러블 디바이스(200)에 상기 가상 객체와 관련된 기능을 실행 또는 제어하기 위한 제어 권한의제공을 결정하는 단계(S320); 상기 기능의 제어 권한, 상기 가상 객체의 특성 정보, 및 상기 기능과 관련된 데이터 값 중 적어도 하나를 상기웨어러블 디바이스(200)에 전송하는 단계(S330); 상기 전송된 제어 권한에 기초하여 상기 웨어러블 디바이스(200)에 의해 변경된 데이터 값을 상기 웨어러블 디바이스(200)로부터 수신하는 단계(S340); 및 상기 수신된 데이터 값에 기초하여 상기 가상 객체와 관련된 기능의 데이터 값을 업데이트하는 단계(S350);를 포함하는, 방법."}
{"patent_id": "10-2022-0107179", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제10 항에 있어서,상기 웨어러블 디바이스(200)를 인식하는 단계(S310)는, 상기 웨어러블 디바이스(200)를 착용 또는 파지하고 있는 사용자의 손을 인식하는 단계를 포함하고,상기 제어 권한의 제공을 결정하는 단계(S320)는,상기 가상 객체가 상기 인식된 손에 의해 오버레이되는 시간이 기 설정된 시간을 초과하는지 여부에 기초하여,상기 웨어러블 디바이스(200)에 제어 권한을 제공할 것을 결정하는, 방법."}
{"patent_id": "10-2022-0107179", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제10 항에 있어서,상기 웨어러블 디바이스(200)를 인식하는 단계(S310)는, 상기 웨어러블 디바이스(200)를 착용 또는 파지하고 있는 사용자의 손의 제스처를 인식하는 단계를 포함하고, 공개특허 10-2024-0028874-5-상기 제어 권한의 제공을 결정하는 단계(S320)는,상기 인식된 제스처에 기초하여 상기 웨어러블 디바이스(200)에 제어 권한을 제공할 것을 결정하는, 방법."}
{"patent_id": "10-2022-0107179", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제10 항에 있어서,상기 웨어러블 디바이스(200)를 인식하는 단계(S310)는, 상기 웨어러블 디바이스(200)를 착용 또는 파지하고 있는 사용자의 손에 의해 기 설정된 횟수 이상 반복되는 반복 동작을 인식하는 단계를 더 포함하고, 상기 제어 권한의 제공을 결정하는 단계(S320)는,상기 인식된 반복 동작에 기초하여 상기 웨어러블 디바이스(200)에 제어 권한을 제공할 것을 결정하는, 방법."}
{"patent_id": "10-2022-0107179", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제10 항 내지 제13 항 중 어느 하나의 항에 있어서,상기 가상 객체는 애플리케이션에 의해 제공되는 복수의 기능을 실행하기 위한 복수의 기능 UI(User Interface)를 포함하고, 상기 제어 권한의 제공을 결정하는 단계(S320)는,상기 복수의 기능 UI(User Interface) 중 상기 웨어러블 디바이스(200)에 제어 권한을 제공할 적어도 하나의 기능에 관한 기능 UI를 선택하는 단계를 포함하는, 방법."}
{"patent_id": "10-2022-0107179", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제14 항에 있어서,상기 웨어러블 디바이스(200)에 제어 권한을 제공할 적어도 하나의 기능 UI를 선택하는 단계는, 상기 복수의 기능 UI 중 상기 웨어러블 디바이스(200)를 착용 또는 파지하고 있는 사용자의 손에 의해 오버레이되는 기능 UI를 식별하는 단계(710); 및 상기 식별된 기능 UI에 의해 실행 또는 제어되는 기능에 관한 제어 권한을 상기 웨어러블 디바이스(200)에 제공할 것을 결정하는 단계(720);를 포함하는, 방법."}
{"patent_id": "10-2022-0107179", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제14 항에 있어서, 상기 웨어러블 디바이스(200)에 제어 권한을 제공할 적어도 하나의 기능 UI를 선택하는 단계는, 상기 애플리케이션의 복수의 기능 각각에 관한 API(Application Programming Interface)의 제공 가능 여부에기초하여, 상기 적어도 하나의 기능 UI를 선택하는, 방법."}
{"patent_id": "10-2022-0107179", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제14 항 내지 제16 항 중 어느 하나의 항에 있어서,상기 선택된 적어도 하나의 기능 UI의 제어 영역을 상기 가상 객체 내의 다른 영역과 구별되는 컬러로 표시하는공개특허 10-2024-0028874-6-단계(S730);를 더 포함하는, 방법."}
{"patent_id": "10-2022-0107179", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제10 항에 있어서,복수의 애플리케이션을 실행함으로써, 상기 복수의 애플리케이션에 의해 제공되는 복수의 가상 객체를 표시하는단계(S910);를 더 포함하고, 상기 제어 권한의 제공을 결정하는 단계는,사용자의 좌안의 시선 방향과 우안의 시선 방향이 수렴하는 응시점을 인식하는 단계(S920);상기 인식된 응시점의 위치에 기초하여 실행 중인 상기 복수의 애플리케이션 중 어느 하나의 애플리케이션을 선택하는 단계(S930); 및상기 선택된 애플리케이션에 의해 표시되는 적어도 하나의 가상 객체와 관련된 기능의 제어 권한을 상기 웨어러블 디바이스(200)에 제공할 것을 결정하는 단계(S940);를 포함하는, 방법."}
{"patent_id": "10-2022-0107179", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "증강 현실 디바이스(100)와 인터랙션하는 웨어러블 디바이스(200)에 있어서, 상기 증강 현실 디바이스(100)와 근거리 통신 방식을 통해 연결되고, 상기 증강 현실 디바이스(100)와 데이터통신을 수행하는 통신 인터페이스(210);사용자 입력을 수신하는 사용자 입력부(220);적어도 하나의 명령어들(instructions)를 저장하는 메모리(240); 및상기 적어도 하나의 명령어들을 실행하는 적어도 하나의 프로세서(230); 를 포함하고, 상기 적어도 하나의 프로세서(230)는, 상기 증강 현실 디바이스(100)에 의해 실행되는 애플리케이션을 통해 표시되는 가상 객체와 관련된 기능을 실행또는 제어하기 위한 제어 권한을 상기 증강 현실 디바이스(100)로부터 획득하고, 상기 가상 객체의 타입, 상기 기능의 특성, 및 상기 기능과 관련된 데이터 값 중 적어도 하나에 기초하여, 상기획득된 제어 권한에 기초하여 상기 기능을 제어하기 위한 조작 방식을 결정하고,상기 결정된 조작 방식에 따라 상기 사용자 입력부(220)를 통해 수신된 사용자 입력에 기초하여, 상기 기능과관련된 데이터 값을 변경하고, 상기 통신 인터페이스(150)를 제어함으로써, 상기 변경된 데이터 값을 상기 증강 현실 디바이스(100)에 전송하는, 웨어러블 디바이스(200)."}
{"patent_id": "10-2022-0107179", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제19 항에 있어서, 디스플레이부(250); 를 더 포함하고, 공개특허 10-2024-0028874-7-상기 적어도 하나의 프로세서(230)는, 상기 증강 현실 디바이스(100)로부터 제어 권한이 획득되는 경우 상기 제어 권한의 획득 여부 및 상기 제어 권한과 관련된 기능에 관한 정보를 알리는 알림 메시지를 상기 디스플레이부(250) 상에 디스플레이하는, 웨어러블디바이스(200)."}
{"patent_id": "10-2022-0107179", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "사용자의 조작 편의성을 향상시키기 위하여, 외부 디바이스에 의해 제어되는 증강 현실 디바이스 및 그 동작 방 법을 제공한다. 본 개시의 일 실시예에 따른 증강 현실 디바이스는 웨이브가이드를 통해 표시되는 가상 객체 상 에 오버레이되는(overlaid) 웨어러블 디바이스를 인식하고, 인식된 웨어러블 디바이스에 가상 객체와 관련된 기 능을 실행 또는 제어하기 위한 제어 권한의 제공을 결정하고, 기능의 제어 권한을 웨어러블 디바이스에 전송하고, 전송된 제어 권한에 기초하여 웨어러블 디바이스에 의해 변경된 데이터 값을 웨어러블 디바이스로부터 수신하고, 수신된 데이터 값에 기초하여 기능의 데이터 값을 업데이트할 수 있다."}
{"patent_id": "10-2022-0107179", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 외부 디바이스에 의해 제어되는 증강 현실 디바이스(augment reality device) 및 그 동작 방법에 관 한 것이다. 구체적으로, 본 개시는 사용자가 착용 또는 파지하고 있는 웨어러블 디바이스(wearable device)를 통해 수신되는 사용자 입력에 의해 제어되는 증강 현실 디바이스 및 그 동작 방법을 개시한다."}
{"patent_id": "10-2022-0107179", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "증강 현실(Augmented Reality)은 현실 세계의 물리적 환경 공간이나 현실 객체(real world object) 상에 가상 객체를 오버레이(overlay)하여 함께 보여주는 기술로서, 증강 현실 기술을 활용한 증강 현실 디바이스(예를 들 어, 스마트 글래스(Smart Glass))가 정보 검색, 길 안내, 카메라 촬영과 같이 일상 생활에서 유용하게 사용되고 있다. 특히, 스마트 글래스는 패션 아이템으로도 착용되고, 실외 활동에 주로 사용되고 있다. 증강 현실 디바이스는 특성 상 터치 조작이 불가능하므로, 증강 현실 서비스를 제공하기 위해서는 입력 수단으 로써 사용자의 손의 3차원적 자세(pose)와 손 동작(hand gesture)를 이용하는 핸드 인터랙션(hand interaction)이 입력 인터페이스로서 사용된다. 일반적인 증강 현실 디바이스는 카메라를 이용하여 촬영된 이미 지로부터 사용자의 손을 인식하는 비젼 기반 핸드 트래킹(Vision-based Hand tracking) 기술을 사용하고 있다. 사용자는 증강 현실 디바이스를 통해 증강 현실 서비스를 이용하기 위하여, 손 등 신체를 이용하여 표시된 가상 객체를 제어하여야 한다. 그러나, 가상 객체의 크기가 작거나 정밀한 조작이 요구되는 가상 객체를 제어하는 경 우, 제어의 정확도가 떨어지고, 사용자가 피로감을 느낄 수 있다. 가상 객체와 사용자의 손과의 거리가 멀어서 가상 객체의 조작을 위하여 큰 동작이 필요하거나, 슬라이드 바(slide bar), 스피너(spinner), 또는 스크롤 바 (scroll bar) 등과 같이 정밀한 조작을 요구하는 UI(User Interface)의 경우 사용자의 의도에 부합되는 정확한 조작이 어려울 수 있다. UI에 관한 정확한 조작이 어려운 경우, 증강 현실 디바이스에 의해 제공되는 기능 또는 서비스를 제대로 제공받을 수 없고, 따라서 사용자 편의성이 떨어질 수 있다."}
{"patent_id": "10-2022-0107179", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상술한 기술적 과제를 해결하기 위하여 본 개시는 외부 디바이스에 의해 제어되는 증강 현실 디바이스를 제공한 다. 본 개시의 일 실시예에 따른 증강 현실 디바이스는 카메라, 웨이브가이드, 웨이브가이드에 가상 객체를 투 사하도록 구성되는 광학 엔진, 웨어러블 디바이스와 페어링(pairing)하고, 웨어러블 디바이스와 데이터를 송수 신하도록 구성되는 통신 인터페이스, 적어도 하나의 명령어들(instructions)를 저장하는 메모리, 및 적어도 하 나의 명령어들을 실행하는 적어도 하나의 프로세서를 포함할 수 있다. 상기 적어도 하나의 프로세서는 가상 객 체 상에 오버레이되는(overlaid) 웨어러블 디바이스를 인식할 수 있다. 상기 적어도 하나의 프로세서는 인식된 웨어러블 디바이스에 가상 객체와 관련된 기능을 실행 또는 제어하기 위한 제어 권한의 제공을 결정할 수 있다. 상기 적어도 하나의 프로세서는 통신 인터페이스를 제어하여, 기능의 제어 권한, 가상 객체의 특성 정보, 및 기 능과 관련된 데이터 값 중 적어도 하나를 웨어러블 디바이스에 전송할 수 있다. 상기 적어도 하나의 프로세서는 전송된 제어 권한에 기초하여 웨어러블 디바이스에 의해 변경된 데이터 값을 웨어러블 디바이스로부터 수신할 수 있다. 상기 적어도 하나의 프로세서는 수신된 데이터 값에 기초하여 가상 객체와 관련된 기능의 데이터 값을업데이트할 수 있다. 상술한 기술적 과제를 해결하기 위하여 본 개시는 증강 현실 디바이스가 외부 디바이스에 의해 제어되는 방법을 제공한다. 본 개시의 일 실시예에서, 상기 방법은 가상 객체 상에 오버레이되는 웨어러블 디바이스를 인식하는 단계를 포함할 수 있다. 상기 방법은 인식된 웨어러블 디바이스에 가상 객체와 관련된 기능을 실행 또는 제어하 기 위한 제어 권한의 제공을 결정하는 단계를 포함할 수 있다. 상기 방법은 기능의 제어 권한, 가상 객체의 특 성 정보, 및 기능과 관련된 데이터 값 중 적어도 하나를 웨어러블 디바이스에 전송하는 단계를 포함할 수 있다. 상기 방법은 전송된 제어 권한에 기초하여 웨어러블 디바이스에 의해 변경된 데이터 값을 웨어러블 디바이스로 부터 수신하는 단계를 포함할 수 있다. 상기 방법은 수신된 데이터 값에 기초하여 가상 객체와 관련된 기능의 데이터 값을 업데이트하는 단계를 포함할 수 있다. 상술한 기술적 과제를 해결하기 위하여, 본 개시는 증강 현실 디바이스와 인터랙션하는 웨어러블 디바이스를 제 공한다. 본 개시의 일 실시예에 따른 웨어러블 디바이스는 증강 현실 디바이스와 근거리 통신 방식을 통해 연결 되고, 증강 현실 디바이스와 데이터 통신을 수행하는 통신 인터페이스, 사용자 입력을 수신하는 사용자 입력부, 적어도 하나의 명령어들(instructions)를 저장하는 메모리, 및 적어도 하나의 명령어들을 실행하는 적어도 하나 의 프로세서를 포함할 수 있다. 상기 적어도 하나의 프로세서는 증강 현실 디바이스에 의해 실행되는 애플리케 이션을 통해 표시되는 가상 객체와 관련된 기능을 실행 또는 제어하기 위한 제어 권한을 증강 현실 디바이스로 부터 획득할 수 있다. 상기 적어도 하나의 프로세서는 가상 객체의 타입, 기능의 특성, 및 기능과 관련된 데이 터 값 중 적어도 하나에 기초하여, 획득된 제어 권한에 기초하여 기능을 제어하기 위한 조작 방식을 결정할 수 있다. 상기 적어도 하나의 프로세서는 결정된 조작 방식에 따라 사용자 입력부를 통해 수신된 사용자 입력에 기 초하여, 기능과 관련된 데이터 값을 변경할 수 있다. 상기 적어도 하나의 프로세서는 통신 인터페이스를 제어함 으로써, 변경된 데이터 값을 증강 현실 디바이스에 전송할 수 있다."}
{"patent_id": "10-2022-0107179", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 명세서의 실시예들에서 사용되는 용어는 본 개시의 기능을 고려하면서 가능한 현재 널리 사용되는 일반적인 용어들을 선택하였으나, 이는 당 분야에 종사하는 기술자의 의도 또는 판례, 새로운 기술의 출현 등에 따라 달 라질 수 있다. 또한, 특정한 경우는 출원인이 임의로 선정한 용어도 있으며, 이 경우 해당되는 실시예의 설명 부분에서 상세히 그 의미를 기재할 것이다. 따라서 본 명세서에서 사용되는 용어는 단순한 용어의 명칭이 아닌, 그 용어가 가지는 의미와 본 개시의 전반에 걸친 내용을 토대로 정의되어야 한다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함할 수 있다. 기술적이거나 과학적인 용어를 포함해서 여기서 사용되는 용어들은 본 명세서에 기재된 기술 분야에서 통상의 지식을 가진 자에 의해일반적으로 이해되는 것과 동일한 의미를 가질 수 있다. 본 개시 전체에서 어떤 부분이 어떤 구성요소를 \"포함\"한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다 른 구성요소를 제외하는 것이 아니라 다른 구성요소를 더 포함할 수 있음을 의미한다. 또한, 본 명세서에 기재 된 \"...부\", \"...모듈\" 등의 용어는 적어도 하나의 기능이나 동작을 처리하는 단위를 의미하며, 이는 하드웨어 또는 소프트웨어로 구현되거나 하드웨어와 소프트웨어의 결합으로 구현될 수 있다. 본 개시에서 사용된 표현 \"~하도록 구성된(또는 설정된)(configured to)\"은 상황에 따라, 예를 들면, \"~에 적합 한(suitable for)\", \"~하는 능력을 가지는(having the capacity to)\", \"~하도록 설계된(designed to)\", \"~하도 록 변경된(adapted to)\", \"~하도록 만들어진(made to)\", 또는 \"~를 할 수 있는(capable of)\"과 바꾸어 사용될 수 있다. 용어 \"~하도록 구성된(또는 설정된)\"은 하드웨어적으로 \"특별히 설계된(specifically designed to)\" 것만을 반드시 의미하지 않을 수 있다. 대신, 어떤 상황에서는, \"~하도록 구성된 시스템\"이라는 표현은, 그 시 스템이 다른 장치 또는 부품들과 함께 \"~할 수 있는\" 것을 의미할 수 있다. 예를 들면, 문구 \"A, B, 및 C를 수 행하도록 구성된(또는 설정된) 프로세서\"는 해당 동작을 수행하기 위한 전용 프로세서(예: 임베디드 프로세서), 또는 메모리에 저장된 하나 이상의 소프트웨어 프로그램들을 실행함으로써, 해당 동작들을 수행할 수 있는 범용 프로세서(generic-purpose processor)(예: CPU 또는 application processor)를 의미할 수 있다. 또한, 본 개시에서 일 구성요소가 다른 구성요소와 \"연결된다\" 거나 \"접속된다\" 등으로 언급된 때에는, 상기 일 구성요소가 상기 다른 구성요소와 직접 연결되거나 또는 직접 접속될 수도 있지만, 특별히 반대되는 기재가 존 재하지 않는 이상, 중간에 또 다른 구성요소를 매개하여 연결되거나 또는 접속될 수도 있다고 이해되어야 할 것 이다. 본 개시에서, '증강 현실(Augmented Reality)'은 현실 세계(Real world)의 물리적 환경 공간 내에 가상 이미지 를 함께 보여주거나 현실 객체와 가상 이미지를 함께 보여주는 것을 의미한다. 본 개시에서, '증강 현실 디바이스'는 증강 현실을 표현할 수 있는 장치로서, 일반적으로 사용자가 안면부(顔面 部)에 착용하는 안경 형상의 증강 현실 안경 장치(Augmented Reality Glasses) 뿐만 아니라, 두부(頭部)에 착용 하는 헤드 마운트 디스플레이 장치 (HMD : Head Mounted Display Apparatus)나, 증강 현실 헬멧(Augmented Reality Helmet) 등을 포괄한다. 그러나, 이에 한정되는 것은 아니다. 본 개시에서, '현실 장면(real scene)'이란 사용자가 증강 현실 장치를 통해서 보는 현실 세계의 장면으로서, 현실 객체(real world object)를 포함할 수 있다. 본 개시에서, '가상 객체(virtual object)'는 광학 엔진을 통해 생성되는 이미지로 정적 이미지와 동적 이미지 를 모두 포함할 수 있다. 이러한 가상 객체는 현실 장면과 함께 관측되며, 현실 장면 속의 현실 객체에 대한 정 보 또는 증강 현실 장치의 동작에 대한 정보나 제어 메뉴 등을 나타내는 이미지일 수 있다. 본 개시의 일 실시 예에서, '가상 객체'는 증강 현실 디바이스에 의해 실행되는 애플리케이션(application) 또는 프로그램 (program)을 통해 제공되는 기능을 실행 또는 제어하기 위한 기능 UI(User Interface)를 포함할 수 있다. 일반적인 증강 현실 디바이스는 광원에서 생성된 광으로 구성되는 가상 객체를 생성하기 위한 광학 엔진과 광학 엔진에서 생성된 가상 객체를 사용자의 눈까지 안내하고 현실 세계의 장면도 함께 볼 수 있도록 투명한 재질로 형성된 웨이브 가이드(waveguide, 또는 도광판)을 구비한다. 전술한 바와 같이, 증강 현실 디바이스는 가상 객 체 뿐만 아니라 현실 세계의 장면도 함께 관측할 수 있어야 하므로, 광학 엔진에서 생성된 광을 웨이브 가이드 를 통해 사용자의 눈까지 안내하기 위해서는 기본적으로 직진성을 가지는 광의 경로를 변경하기 위한 광학 소자 (Optical element)가 필요하다. 이 때, 미러 등에 의한 반사를 이용하여 광 경로를 변경할 수도 있고, DOE(Diffractive optical element), HOE(Holographic optical element) 등과 같은 회절 소자에 의한 회절을 통 해 광 경로를 변경할 수도 있으나 이에 한정되는 것은 아니다. 본 개시에서, '시선 방향(gaze direction)'은 사용자가 응시하는 방향을 의미하며, '시선(gaze)'이란 사용자의 눈동자에서 시선 방향으로 향하는 가상의 선을 의미한다. 주로 시선 추적 센서에서 획득된 정보로부터 시선 방 향을 계산하고 시선을 추정한다. 본 개시에서, '응시점(gaze point)'은 사용자가 응시하는 지점을 가리키며, 사용자의 양안의 시선이 교차하는 지점으로 산출될 수 있다. 본 개시에서, '외부 디바이스(external device)'는 증강 현실 디바이스가 아닌 별개의 디바이스를 의미한다. 외 부 디바이스는 예를 들어, 모바일 디바이스, 스마트 폰(smart phone), 노트북 컴퓨터(laptop computer), 데스크탑, 태블릿 PC, 전자책 단말기, 디지털 방송용 단말기, PDA(Personal Digital Assistants), PMP(Portable Multimedia Player), 네비게이션, MP3 플레이어, 캠코더, IPTV(Internet Protocol Television), DTV(Digital Television), 웨어러블 디바이스 등과 같은 다양한 전자 장치로 구현될 수 있다. 본 개시에서, '웨어러블 디바이스(wearable device)'는 사용자의 신체 일부에 착용하고, 착용 상태로 휴대하는 장치이다. 예를 들어, 웨어러블 디바이스는 스마트 워치, 링, 팔찌, 발찌, 목걸이, 콘택트 렌즈, 의류 일체형 장치(예컨대, 전자 의복), 신체 부착형 장치(예컨대, 스킨 패드(skin pad)), 또는 생체 이식형 장치(예: implantable circuit) 중 적어도 하나일 수 있으나, 이에 한정되는 것은 아니다. 아래에서는 첨부한 도면을 참고하여 본 개시의 실시예에 대하여 본 개시가 속하는 기술 분야에서 통상의 지식을 가진 자가 용이하게 실시할 수 있도록 상세히 설명한다. 그러나 본 개시는 여러 가지 상이한 형태로 구현될 수 있으며 여기에서 설명하는 실시 예에 한정되지 않는다. 이하에서는 도면을 참조하여 본 개시의 실시예들을 상세하게 설명한다. 도 1a는 본 개시의 일 실시예에 따른 증강 현실 디바이스가 외부 디바이스에 의해 제어되는 동작을 설명하 기 위한 개념도이다. 도 1a를 참조하면, 사용자는 증강 현실 디바이스를 안면부(顔面部)에 착용하고, 증강 현실 디바이스 의 렌즈를 통해 가상 객체(10, 12, 14)를 볼 수 있다. 도 1a에 도시된 실시예에서, 증강 현실 디바이스는 증강 현실을 표현할 수 있는 장치로서, 안경 형상의 증강 현실 안경 장치(Augmented Reality Glasses) 또는 스 마트 글래스(smart glass)일 수 있다. 그러나, 이에 한정되는 것은 아니고, 증강 현실 디바이스는 사용자 의 두부(頭部)에 착용하는 헤드 마운트 디스플레이 장치 (HMD : Head Mounted Display Apparatus)나, 증강 현 실 헬멧(Augmented Reality Helmet) 등으로 구현될 수도 있다. 증강 현실 디바이스는 광학 엔진(124, 도 3 참조)을 이용하여 웨이브가이드(122, 도 3 참조)에 가상 객체 (10, 12, 14)를 투사(project)하고, 사용자는 웨이브가이드를 통해 가상 객체(10, 12, 14)를 볼 수 있다. 본 개시에서, '가상 객체(10, 12, 14)'는 광학 엔진을 통해 생성되는 이미지로 정적 이미지와 동적 이미지 를 모두 포함할 수 있다. 가상 객체(10, 12, 14)는 현실 장면과 함께 관측되며, 현실 장면 속의 현실 객체에 대 한 정보 또는 증강 현실 장치의 동작에 대한 정보나 제어 메뉴 등을 나타내는 이미지일 수 있다. 본 개시의 일 실시예에서, '가상 객체(10, 12, 14)'는 증강 현실 디바이스에 의해 실행되는 애플리케이션(application) 또는 프로그램(program)을 통해 제공되는 기능을 실행 또는 제어하기 위한 적어도 하나의 기능 UI(User Interface)(12, 14)를 포함할 수 있다. 가상 객체(10, 12, 14)는 애플리케이션 또는 프로그램의 실행 화면(1 0)을 포함할 수도 있다. 사용자는 웨어러블 디바이스를 착용하고, 증강 현실 디바이스는 가상 객체(10, 12, 14) 상에 오버레 이(overlaid)되는 웨어러블 디바이스를 인식할 수 있다. 본 개시의 일 실시예에서, '웨어러블 디바이스 (wearable device)'는 사용자의 신체 일부에 착용하고, 착용 상태로 휴대하는 장치이다. 도 1a에 도시된 실시예에서, 웨어러블 디바이스는 사용자의 손목에 착용하는 스마트 워치(smart watch)일 수 있다. 그러나, 이에 한정되는 것은 아니고, 웨어러블 디바이스는 예를 들어, 링, 팔찌, 발찌, 목걸이, 콘택트 렌 즈, 의류 일체형 장치(예컨대, 전자 의복), 신체 부착형 장치(예컨대, 스킨 패드(skin pad)), 또는 생체 이식형 장치(예: implantable circuit) 중 적어도 하나일 수도 있다. 웨어러블 디바이스는 증강 현실 디바이스 와 근거리 통신 방식을 통해 연결되고, 데이터 송수신을 수행할 수 있다. 예를 들어, 웨어러블 디바이스 는 증강 현실 디바이스와 블루투스 통신(Bluetooth)을 통해 페어링(pairing)될 수 있다. 도 1b는 본 개시의 증강 현실 디바이스 및 웨어러블 디바이스의 상호 간의 동작을 설명하기 위한 개 념도이다. 이하에서는, 도 1a와 도 1b를 함께 참조하여 증강 현실 디바이스와 웨어러블 디바이스의 동작을 설명하기로 한다. 도 1b를 참조하면, 증강 현실 디바이스는 웨어러블 디바이스를 인식할 수 있다(동작 ①). 본 개시의 일 실시예에서, 증강 현실 디바이스는 카메라(110, 도 3 참조)를 포함하고, 카메라를 통해 웨어러블 디바이스 및 웨어러블 디바이스를 착용 또는 파지하고 있는 사용자의 손을 촬영함으로써, 이미지 프 레임을 획득할 수 있다. 증강 현실 디바이스는 딥 러닝(deep learning) 기반의 객체 인식 모델 또는 이미 지 프로세싱 기술 등을 이용하여 이미지 프레임으로부터 웨어러블 디바이스 및 사용자의 손을 인식할 수있다. 증강 현실 디바이스는 인식된 웨어러블 디바이스에 애플리케이션에 의해 제공되는 기능에 관한 제어 권한을 제공할 수 있다 (동작 ②). 도 1a를 함께 참조하면, 증강 현실 디바이스는 애플리케이션에 의해 제 공되는 기능을 실행 또는 제어하기 위한 기능 UI(12, 14) 중 사용자의 손에 의해 오버레이되는 제1 기능 UI(1 2)를 식별하고, 식별된 제1 기능 UI에 대응되는 제1 기능의 제어 권한을 웨어러블 디바이스에 제공할 것으로 결정할 수 있다. 도 1a에 도시된 실시예에서, 증강 현실 디바이스에 의해 실행되는 애플리케이션은 동영상을 플레이 또는 스트리밍하는 애플리케이션이고, 애플리케이션의 실행 화면(예를 들어, 동영상 플레이 화 면), 동영상의 플레이 타임을 제어하기 위한 제1 기능 UI, 및 동영상의 볼륨 업/다운을 제어하기 위한 제2 기능 UI가 웨이브가이드를 통해 표시될 수 있다. 증강 현실 디바이스는 표시되는 사용자의 손에 의해 오버레이되는 제1 기능 UI를 통해 실행 또는 제어되는 플레이 타임 제어 기능을 식별하고, 식별 된 플레이 타임 제어 기능에 관한 제어 권한을 웨어러블 디바이스에 전송할 수 있다. 본 개시의 일 실시예에서, 증강 현실 디바이스는 제어 권한을 웨어러블 디바이스에 전송하는 경우, 전송되는 제어 권한에 관한 기능 UI의 특성 정보 및 기능에 관한 데이터 값을 함께 전송할 수 있다. 도 1a에 도 시된 실시예에서, 증강 현실 디바이스는 플레이 타임 제어 기능의 제어 권한 뿐만 아니라, 제1 기능 UI의 특성 정보 및 플레이 타임 제어 기능의 데이터 값인 플레이 타임(도 1a의 경우, 2시간 5분 2초)을 웨 어러블 디바이스에 전송할 수 있다. 다시 도 1b를 참조하면, 웨어러블 디바이스는 증강 현실 디바이스로부터 획득한 제어 권한에 기초하 여 기능에 관한 데이터 값을 변경할 수 있다 (동작 ③). 본 개시의 일 실시예에서, 웨어러블 디바이스는 획득된 제어 권한과 관련된 기능의 특성, 기능 UI의 타입(type), 및 데이터 값 중 적어도 하나에 기초하여, 기 능에 대응되는 조작 방식을 결정할 수 있다. 도 1a 및 도 1b에 도시된 실시예에서, 웨어러블 디바이스는 회전식 베젤 링 및 버튼을 포함하고, 획득된 제어 권한과 관련된 동영상의 플레이 타임 제어 기능의 특성, 제1 기능 UI의 슬라이더(slider) 타입, 및 플레이 타임의 데이터 값(예를 들어, 2시간 5분 2초) 중 적어도 하나에 기초하여 회전식 베젤 링을 조작 방식으로 결정할 수 있다. 웨어러블 디바이스는 회전 식 베젤 링을 시계 방향 또는 반시계 방향으로 회전시키는 사용자 입력을 수신하고, 수신된 사용자 입력에 기초하여 기능에 관한 데이터 값을 변경할 수 있다. 도 1a에 도시된 실시예에서, 웨어러블 디바이스는 동 영상의 플레이 타임을 변경할 수 있다. 다시 도 1b를 참조하면, 웨어러블 디바이스는 변경된 데이터 값을 증강 현실 디바이스에 전송할 수 있다 (동작 ④). 증강 현실 디바이스는 웨어러블 디바이스로부터 수신된 데이터 값을 이용하여 기능 UI와 관련된 데이터 값을 업데이트(update)할 수 있다. 도 1a를 함께 참조하면, 증강 현실 디바이스는 웨 어러블 디바이스의 회전식 베젤 링을 시계 방향 또는 반시계 방향으로 회전하는 사용자 입력에 의해 변경된 동영상의 플레이 타임에 관한 데이터를 웨어러블 디바이스로부터 수신하고, 수신된 플레이 타임 데 이터를 이용하여 제1 기능 UI에 관한 동영상 플레이 타임을 업데이트할 수 있다. 도 1a 및 도 1b에서, 증강 현실 디바이스는 웨어러블 디바이스에 의해 제어되는 것으로 도시되고, 설 명되었지만, 본 개시가 이에 한정되는 것은 아니다. 본 개시의 일 실시예에서, 증강 현실 디바이스는 외부 디바이스, 예를 들어, 모바일 디바이스, 스마트 폰(smart phone), 노트북 컴퓨터(laptop computer), 데스크 탑, 태블릿 PC, 전자책 단말기, 디지털 방송용 단말기, PDA(Personal Digital Assistants), PMP(Portable Multimedia Player), 네비게이션, MP3 플레이어, 또는 캠코더에 기능에 관한 제어 권한을 제공하고, 외부 디바 이스에 의해 제어될 수도 있다. 증강 현실 디바이스가 외부 디바이스를 인식하고, 외부 디바이스에 의해 제어되는 구체적인 실시예에 대해서는 도 17a 및 도 17b에서 상세하게 설명하기로 한다. 증강 현실 디바이스는 특성 상 터치 조작이 불가능하므로, 증강 현실 서비스를 제공하기 위해서는 입력 수 단으로써 사용자의 손의 3차원적 자세(pose)와 손 동작(hand gesture)를 이용하는 핸드 인터랙션(hand interaction)이 입력 인터페이스로서 사용된다. 사용자는 증강 현실 디바이스를 통해 증강 현실 서비스를 이용하기 위하여, 손 등 신체를 이용하여 표시된 가상 객체를 제어하여야 한다. 그러나, 가상 객체(10, 12, 1 4)의 크기가 작거나 정밀한 조작이 요구되는 가상 객체(예를 들어, 기능 UI(12, 14))를 제어하는 경우, 사용자 가 피로감을 느낄 수 있고, 제어의 정확도가 떨어질 수 있다. 가상 객체(10, 12, 14)와 사용자의 손과의 거리가 멀어서 가상 객체(10, 12, 14)의 조작을 위하여 큰 동작이 필요하거나, 슬라이더(slider), 스피너(spinner), 또 는 스크롤 바(scroll bar) 등과 같이 정밀한 조작을 요구하는 UI(User Interface)의 경우 사용자의 의도에 부합 되는 정확한 조작이 어려울 수 있다. UI에 관한 정확한 조작이 어려운 경우, 증강 현실 디바이스에 의해제공되는 기능 또는 서비스를 제대로 제공받을 수 없고, 따라서 사용자 편의성이 낮아질 수 있다. 본 개시는 사용자의 손 또는 신체 일부를 이용하여 조작하기 어려운 가상 객체를 실행 또는 제어하기 위하여, 외부 디바이스와 연동하여 외부 디바이스에 의해 제어되는 증강 현실 디바이스 및 그 동작 방법을 제공하 는 것을 목적으로 한다. 도 1a 및 도 1b에 도시된 실시예에 따른 증강 현실 디바이스는 실행 중인 애플리케이션에 의해 제공되는 가상 객체(10, 12, 14) 중 웨어러블 디바이스를 착용하고 있는 손에 의해 오버레이되는(overlaid) 가상 객 체(도 1a의 실시예에서는 제1 UI)를 식별하고, 식별된 가상 객체와 관련된 기능에 관한 제어 권한을 웨어러 블 디바이스에 제공하며, 제공된 제어 권한에 기초하여 웨어러블 디바이스에 의해 변경된 데이터 값 을 수신하고, 수신된 데이터 값을 반영하여 기능의 데이터 값을 업데이트할 수 있다. 본 개시의 일 실시예에 따 른 증강 현실 디바이스는 가상 객체(10, 12, 14) 중 크기가 작거나 정밀한 조작이 필요한 가상 객체와 관 련된 기능을 웨어러블 디바이스를 통해 실행 또는 제어함으로써, 기능 제어의 정확도 및 사용자의 조작 편 의성을 향상시키는 기술적 효과를 제공한다. 도 2는 본 개시의 일 실시예에 따른 증강 현실 디바이스의 구성 요소를 도시한 블록도이다. 증강 현실 디바이스는 사용자의 안면부에 착용하는 안경 형태의 증강 현실 글래스(Augmented Reality Glass)일 수 있다. 증강 현실 디바이스는 애플리케이션을 실행함으로써, 시야(Field Of View, FOV) 내의 현실 객체 뿐만 아니라 웨이브가이드(waveguide)에 표시되는 가상 객체를 제공할 수 있다. 증강 현실 디바이스 는 예를 들어, 무비 애플리케이션, 뮤직 애플리케이션, 포토 애플리케이션, 갤러리 애플리케이션, 웹 브라 우저 애플리케이션, 전자책(e-book reader) 애플리케이션, 게임 애플리케이션, 증강 현실 애플리케이션, SNS 애 플리케이션, 메신저 애플리케이션, 오브젝트 인식 애플리케이션 등을 실행함으로써, 각각의 애플리케이션에서 표시되는 가상 객체를 사용자에게 제공할 수 있다. 본 개시의 일 실시예에서, 가상 객체는 애플리케이션에 의해 제공되는 기능을 실행 또는 제어하기 위한 기능 UI(User Interface)를 포함할 수 있다. 도 2를 참조하면, 증강 현실 디바이스는 카메라, 출력부, 프로세서, 메모리, 및 통신 인터페이스를 포함할 수 있다. 카메라, 출력부의 광학 엔진, 프로세서, 메모리, 및 통신 인터페이스는 각각 전기적 및/또는 물리적으로 서로 연결될 수 있다. 도 2에는 증강 현실 디바이 스의 동작을 설명하기 위한 필수적 구성 요소만이 도시되었고, 증강 현실 디바이스가 포함하는 구성 요소가 도 2에 도시된 바와 같이 한정되는 것은 아니다. 본 개시의 일 실시예에서, 증강 현실 디바이스는 사용자의 시선 방향 정보를 획득하도록 구성되는 시선 추적 센서를 더 포함할 수 있다. 본 개시의 일 실시예에 서, 증강 현실 디바이스는 카메라, 광학 엔진, 프로세서, 및 통신 인터페이스에 전원 을 공급하는 배터리를 더 포함할 수 있다. 카메라는 현실 공간의 객체를 촬영함으로써, 객체에 관한 이미지를 획득하도록 구성된다. 본 개시의 일 실 시예에서, 카메라는 렌즈 모듈, 이미지 센서, 및 영상 처리 모듈을 포함할 수 있다. 카메라는 이미지 센서(예를 들어, CMOS 또는 CCD)에 의해 얻어지는 정지 이미지 또는 동영상을 획득할 수 있다. 영상 처리 모듈 은 이미지 센서를 통해 획득된 정지 이미지 또는 동영상을 가공하여, 필요한 정보를 추출하고, 추출된 정보를 프로세서에 전달할 수 있다. 본 개시의 일 실시예에서, 카메라는 웨어러블 디바이스(200, 도 1a 및 도 1b 참조) 및 웨어러블 디바이스를 착용 또는 파지하고 있는 사용자의 손을 촬영함으로써, 이미지 프레 임을 획득할 수 있다. 카메라는 단일 이미지 프레임으로 구성된 이미지 또는 복수의 이미지 프레임으로 구 성된 동영상 데이터를 획득하고, 획득된 이미지 프레임을 프로세서에 제공할 수 있다. 출력부는 현실 공간의 현실 객체와 광학 엔진에 의해 생성된 가상 객체를 표시하도록 구성된다. 출력 부는 웨이브가이드 및 광학 엔진을 포함할 수 있다. 도 2에는 도시되지 않았지만, 출력부 는 렌즈를 더 포함할 수도 있다. 렌즈는 투명 소재로 형성되고, 외부의 광을 투과하도록 구성된다. 본 개시의 일 실시예에서, 렌즈는 웨이브가이드와 통합되어 단일 엘리먼트를 구성할 수도 있다. 웨이브가이드는 투명 소재로 형성되는 광학 소자이다. 웨이브 가이드는 사용자가 증강 현실 디바이스 를 착용할 때, 배면의 일부 영역이 보이는 투명한 소재로 구성될 수 있다. 웨이브 가이드는 광이 내 부에서 반사되면서 전파될 수 있는 투명 재질의 단층 혹은 다층 구조의 평판으로 구성될 수 있다. 웨이브 가이 드는 광학 엔진의 출사면에 마주하여, 광학 엔진으로부터 투사된 가상 객체의 광을 수광할 수 있다. 웨이브 가이드로 투사된 가상 객체의 광은 전반사(total reflection) 원리에 의해 웨이브 가이드 내에서 전파될 수 있다. 웨이브 가이드는 광의 경로를 변경하여, 최종적으로는 사용자의 눈으로 출 력하도록 하는 복수의 영역을 포함할 수 있다. 복수의 영역에는 회절 격자가 형성될 수 있다. 웨이브 가이드 는 도광판(導光板, Light Guide Panel)과 같은 기능을 수행할 수 있다. 웨이브 가이드는 사용자의 좌 안에 인접하게 배치되는 좌안 웨이브가이드 및 우안에 인접하게 배치되는 우안 웨이브가이드를 포함할 수 있다. 광학 엔진은 가상 객체를 웨이브 가이드에 투사하도록 구성된다. 광학 엔진은 프로젝터 (projector)와 같은 기능을 수행할 수 있다. 광학 엔진은 조명 광학계, 광경로 변환기, 화상 패널, 빔 스 필리터, 및 투사 광학계를 더 포함할 수 있다. 조명 광학계는 광을 조명하는 광학부품으로서, 광원과 렌즈들을 포함할 수 있다. 광원은 RGB의 컬러를 조절함으 로써, 광을 생성하는 구성 요소로서, 예를 들어 발광 다이오드(LED)로 구성될 수 있다. 화상 패널은 광원에 의해 조명된 광을 2차원 이미지를 담은 광으로 변조하면서 반사하는 반사형 화상 패널일 수 있다. 반사형 화상 패널은 예를 들어, DMD (Digital Micromirror Device) 패널 또는 LCoS (Liquid Crystal on Silicon) 패널이나, 그밖의 공지의 반사형 화상 패널일 수 있다. DMD 패널은 광원에서 출력된 광의 RGB를 각각 픽셀 크기의 복수의 거울로 조명하고, 복수의 거울들 각각을 on/off로 스위칭함으로써, 광의 RGB를 혼합하여 가 상 객체의 이미지를 투사하는 DLP(Digital Light Processing) 방식으로 동작될 수 있다. LCoS 패널은 광원에서 출력된 광을 특정 파장의 광만을 통과시키는 미러(mirror)를 통해 RGB로 각각 분리하여 화상 패널로 입력되고, RGB가 혼합되어 생성된 가상 객체의 이미지를 투사하는 LCD(Liquid Crystal Display) 방식으로 동작될 수 있다. 빔 스플리터는 화상 패널과 투사 광학계 사이에 배치될 수 있다. 빔 스플리터는 광원에서 출력된 광을 반사하여 화상 패널에 의해 반사된 광을 투과하도록 구성될 수 있다. 투사 광학계는 화상 패널에 의해 반사된 이미지를 담은 광을 웨이브 가이드에 투사하는 구성 요소로서, 하 나 또는 복수의 투사 렌즈들을 포함할 수 있다. 광학 엔진은 프로세서로부터 가상 객체를 구성하는 이미지 데이터를 획득하고, 획득된 이미지 데이터 에 기초하여 가상 객체를 생성하고, 가상 객체를 광원으로부터 출력된 광과 함께 출사면을 통해 웨이브 가이드 에 투사할 수 있다. 본 개시의 일 실시예에서, 프로세서는 가상 객체를 구성하는 복수의 픽셀의 RGB 컬러 및 휘도 값을 포함하는 이미지 데이터를 광학 엔진에 제공할 수 있다. 광학 엔진은 복수의 픽셀 각각의 RGB 컬러 값과 휘도 값을 이용하여 이미지 프로세싱을 수행하고, 광원을 제어함으로써 가상 객체를 웨이 브 가이드에 투사할 수 있다. 광학 엔진은 좌안 웨이브 가이드 및 우안 웨이브 가이드에 동일한 가상 객체를 투사하거나, 또는 좌안 웨 이브 가이드 및 우안 웨이브 가이드에 상이한 가상 객체를 투사할 수 있다. 프로세서는 메모리에 저장된 프로그램의 하나 이상의 명령어들(instructions)을 실행할 수 있다. 프 로세서는 산술, 로직 및 입출력 연산과 시그널 프로세싱을 수행하는 하드웨어 구성 요소로 구성될 수 있다. 프로세서는 예를 들어, 중앙 처리 장치(Central Processing Unit), 마이크로 프로세서 (microprocessor), 그래픽 프로세서(Graphic Processing Unit), ASICs(Application Specific Integrated Circuits), DSPs(Digital Signal Processors), DSPDs(Digital Signal Processing Devices), PLDs(Programmable Logic Devices), 및 FPGAs(Field Programmable Gate Arrays) 중 적어도 하나로 구성될 수 있으나, 이에 한정되는 것은 아니다. 도 2에는 프로세서가 하나의 엘리먼트로 도시되었으나, 이에 한정되는 것은 아니다. 본 개시의 일 실시예 에서, 프로세서는 하나 이상의 복수 개의 엘리먼트들로 구성될 수 있다. 메모리는 예를 들어, 플래시 메모리 타입(flash memory type), 하드디스크 타입(hard disk type), 멀티미 디어 카드 마이크로 타입(multimedia card micro type), 카드 타입의 메모리(예를 들어 SD 또는 XD 메모리 등), 램(RAM, Random Access Memory) SRAM(Static Random Access Memory), 롬(ROM, Read-Only Memory), EEPROM(Electrically Erasable Programmable Read-Only Memory), PROM(Programmable Read-Only Memory), 또는 광 디스크 중 적어도 하나의 타입의 저장매체로 구성될 수 있다. 메모리에는 증강 현실 디바이스가 외부 디바이스에 기능에 관한 제어 권한을 제공하고, 제공된 제어 권한에 기초하여 외부 디바이스에 의해 제어되는 동작들과 관련된 명령어들(instructions)이 저장될 수 있다. 본 개시의 일 실시예에서, 메모리에는 프로세서가 판독할 수 있는 명령어들, 알고리즘(algorithm), 데이터 구조, 프로그램 코드(program code), 및 애플리케이션 프로그램(application program) 중 적어도 하나가 저장될 수 있다. 메모리에 저장되는 명령어들, 알고리즘, 데이터 구조, 및 프로그램 코드는 예를 들어, C, C++, 자바(Java), 어셈블러(assembler) 등과 같은 프로그래밍 또는 스크립팅 언어로 구현될 수 있다. 이하의 실시예에서, 프로세서는 메모리에 저장된 명령어들 또는 프로그램 코드들을 실행함으로써 구 현될 수 있다. 프로세서는 카메라로부터 웨어러블 디바이스를 촬영한 이미지 프레임을 획득하고, 획득한 이미지 프 레임으로부터 웨어러블 디바이스를 인식할 수 있다. 본 개시의 일 실시예에서, 웨어러블 디바이스는 웨이브 가 이드를 통해 투사되는 가상 객체 상에 오버레이될 수 있다. 프로세서는 이미지 프레임으로부터 가상 객체 상에 오버레이되는 웨어러블 디바이스를 인식할 수 있다. 본 개시의 일 실시예에서, 프로세서는 인공지능 모델(Artificial Intelligent model, AI model)을 이용하 여 이미지 프레임으로부터 웨어러블 디바이스를 인식할 수 있다. '인공지능 모델'은 카메라로부터 획득한 이미지 데이터로부터 객체를 인식하고, 객체를 타입에 따라 분류(classify)하도록 학습된 심층 신경망 모델 (deep neural network)을 포함할 수 있다. 인공지능 모델은 메모리에 저장될 수 있지만, 이에 한정되는 것 은 아니다. 본 개시의 일 실시예에서, 인공지능 모델은 외부 서버에 저장되어 있고, 증강 현실 디바이스는 서버에 이미지 프레임의 데이터를 전송하고, 서버의 인공지능 모델로부터 추론 결과인 객체의 타입에 관한 정보 를 수신할 수도 있다. 인공지능 모델은 수만 내지 수억장의 이미지를 입력 데이터로 적용하고, 이미지에 포함되는 객체의 라벨값 (label)을 출력 정답값(groundtruth)로 적용하여 학습된(trained) 모델 파라미터로 구성되는 심층 신경망 모델 (Deep Neural Network)을 포함할 수 있다. 심층 신경망 모델은 예를 들어, 컨볼루션 신경망 모델 (Convolutional Neural Network; CNN), 순환 신경망 모델(Recurrent Neural Network; RNN), RBM(Restricted Boltzmann Machine), DBN(Deep Belief Network), BRDNN(Bidirectional Recurrent Deep Neural Network) 및 심 층 Q-네트워크 (Deep Q-Networks) 중 적어도 하나를 포함할 수 있다. 그러나, 인공지능 모델이 심층 신경망 모 델만을 포함하는 것은 아니고, SVM(Support Vector Machine), 선형 회귀(linear regression), 로지스틱 회귀 (logistic regression), 나이브 베이즈 분류(Naive Bayes), 랜덤 포레스트(random forest), decision tree, 또 는 k-nearest neighbor algorithm 중 적어도 하나로 구성될 수도 있다. 프로세서는 인공 지능 모델의 트레이닝(training) 및 인공지능 모델을 이용한 추론을 수행하는 인공지능 (AI) 프로세서를 포함할 수 있다. 인공 지능(AI) 프로세서는, 인공 지능(AI)을 위한 전용 하드웨어 칩 형태로 구성될 수도 있고, 범용 프로세서(예를 들어, CPU 또는 애플리케이션 프로세서) 또는 그래픽 전용 프로세서(예 를 들어, GPU)의 일부로서 프로세서에 포함될 수 있다. 인공지능 프로세서는 인공지능 모델을 이용하여, 카메라를 통해 획득된 이미지 프레임으로부터 웨어러블 디바이스를 인식할 수 있다. 프로세서는 이미지 프레임으로부터 가상 객체 상에 오버레이되는 사용자의 손을 인식할 수 있다. 본 개시 의 일 실시예에서, 프로세서는 인공지능 모델을 이용하여, 이미지 프레임으로부터 웨어러블 디바이스를 착 용 또는 파지하고 있는 사용자의 손을 인식할 수 있다. 프로세서는 인공지능 모델을 이용하여 웨어러블 디바이스 또는 사용자의 손을 인식한다고 기재되었지만, 본 개시가 전술한 실시예로 한정되는 것은 아니다. 본 개시의 일 실시예에서, 프로세서는 공지의 이미지 프로세싱(image processing) 기술을 이용하여 이미지 프레임으로부터 웨어러블 디바이스 또는 사용자의 손을 인 식할 수 있다. 프로세서는 인식된 웨어러블 디바이스에 가상 객체와 관련된 기능을 실행 또는 제어하기 위한 제어 권한의 제공을 결정할 수 있다. 본 개시의 일 실시예에서, 프로세서는 인식된 손에 의해 가상 객체가 오버레이되 는 시간을 측정하고, 측정된 시간을 기 설정된 시간과 비교하며, 비교 결과에 따라 웨어러블 디바이스에 제어 권한을 제공할 지 여부를 결정할 수 있다. 프로세서는 손에 의해 가상 객체가 오버레이되는 시간이 기 설 정된 시간을 초과하는 경우 웨어러블 디바이스에 기능의 제어 권한을 제공할 것을 결정할 수 있다. 프로세서 가 가상 객체가 오버레이되는 시간에 기초하여 웨어러블 디바이스에 제어 권한의 제공을 결정하는 구체적 인 실시예에 대해서는 도 4에서 상세하게 설명하기로 한다. 본 개시의 일 실시예에서, 프로세서는 웨어러블 디바이스를 착용 또는 파지하고 있는 사용자의 손의 제스 처(gesture)를 인식할 수 있다. 프로세서는 인공지능 모델을 이용하거나, 또는 공지의 이미지 프로세싱을 통해 이미지 프레임으로부터 사용자의 손의 제스처를 인식할 수 있다. 프로세서는 인식된 손의 제스처에 기초하여 웨어러블 디바이스에 기능의 제어 권한을 제공할 지 여부를 결정할 수 있다. 예를 들어, 인식된 제스처가 기 설정된 제스처와 동일 또는 유사한 경우, 프로세서는 인식된 제스처를 기 설정된 제스처와 비교하 고, 비교 결과에 따라 제스처를 식별하며, 식별 결과에 따라 웨어러블 디바이스에 기능의 제어 권한을 제공할 것을 결정할 수 있다. 본 개시의 일 실시예에서, 이미 웨어러블 디바이스에 기능의 제어 권한이 제공된 상태에 서 특정 제스처가 인식되는 경우, 프로세서는 웨어러블 디바이스로부터 기능의 제어 권한을 회수할 수 있 다. 프로세서가 손의 제스처에 기초하여 기능의 제어 권한을 웨어러블 디바이스에 제공하거나, 또는 회수 하는 구체적인 실시예에 대해서는 도 5a 및 도 5b에서 상세하게 설명하기로 한다. 본 개시의 일 실시예에서, 프로세서는 웨어러블 디바이스를 착용 또는 파지하고 있는 사용자의 손에 의해 기 설정된 횟수 이상 반복되는 반복 동작을 인식할 수 있다. 예를 들어, 프로세서는 현실 공간에서의 사용 자의 손에 의한 스크롤(scroll) 동작 또는 스와이프(swipe) 동작이 기 설정된 횟수 이상 반복됨을 인식할 수 있 다. 기 설정된 횟수는 예를 들어, 5회일 수 있으나, 이에 한정되지 않는다. 프로세서는 인식된 반복 동작 에 기초하여 웨어러블 디바이스에 기능의 제어 권한을 제공할 것을 결정할 수 있다. 예를 들어, 스크롤 동작이 5회 이상 반복되는 경우 프로세서는 스크롤 기능에 관한 제어 권한을 웨어러블 디바이스에 제공할 것을 결 정할 수 있다. 프로세서가 반복 동작에 기초하여 기능의 제어 권한을 웨어러블 디바이스에 제공하는 구체 적인 실시예에 대해서는 도 6에서 상세하게 설명하기로 한다. 본 개시의 일 실시예에서, 프로세서는 가상 객체에 포함되는 복수의 기능 UI 중 웨어러블 디바이스에 제어 권한을 제공할 기능에 관한 기능 UI를 선택할 수 있다. 가상 객체는 애플리케이션에 의해 제공되는 복수의 기능 을 실행하기 위한 복수의 기능 UI(User Interface)를 포함할 수 있다. 프로세서는 복수의 기능 UI 중 웨어 러블 디바이스를 착용 또는 파지하고 있는 사용자의 손에 의해 오버레이되는 기능 UI를 식별할 수 있다. 프로세 서는 식별된 기능 UI에 의해 실행 또는 제어되는 기능에 관한 제어 권한을 웨어러블 디바이스에 제공할 것 을 결정할 수 있다. 프로세서는 선택된 기능 UI의 제어 영역을 가상 객체 내의 다른 영역(예를 들어, 애플리케이션의 실행 화 면 또는 선택되지 않은 적어도 하나의 기능 UI의 제어 영역)과 구별되는 컬러로 표시할 수 있다. 본 개시의 일 실시예에서, 프로세서는 선택된 기능 UI의 제어 영역에 선택되지 않은 적어도 하나의 기능 UI의 제어 영역 과는 다른 컬러를 할당하고, 선택된 기능 UI를 할당된 컬러로 표시하는 이미지 데이터를 생성할 수 있다. 프로 세서는 생성된 이미지 데이터를 광학 엔진에 제공하고, 광학 엔진은 이미지 데이터에 기초하여 웨이브가이드에 광을 투사함으로써, 선택된 기능 UI를 선택되지 않은 적어도 하나의 기능 UI의 제어 영역 과 다른 컬러로 표시할 수 있다. 프로세서가 복수의 기능 UI 중 일부의 기능 UI에 대응되는 기능의 제어 권한을 선택적으로 웨어러블 디바이스에 제공하는 구체적인 실시예에 대해서는 도 7, 도 8a 내지 도 8c에서 상 세하게 설명하기로 한다. 프로세서는 애플리케이션에 의해 제공되는 복수의 기능 UI의 개별 제어 가능 여부에 기초하여 일부 기능 UI에 대응되는 기능의 제어 권한을 웨어러블 디바이스에 제공할 지 여부를 결정할 수 있다. 본 개시의 일 실시 예에서, 프로세서는 애플리케이션의 API(Application Programmable Interface) 제공 여부를 확인하고, API 제공 여부에 기초하여 복수의 기능 UI 중 일부 기능 UI에 대응되는 기능의 제어 권한을 웨어러블 디바이스 에 제공할 지 여부를 결정할 수 있다. 예를 들어, 애플리케이션이 복수의 기능 UI 전체에 관한 API 를 제공할 수 있는 경우, 프로세서는 사용자의 손에 의해 선택된 일부 기능 UI에 대응되는 기능의 제어 권한을 선택 적으로 웨어러블 디바이스에 제공할 수 있다. 반대의 예를 들어, 애플리케이션이 API를 제공하지 않는 써드파티 애플리케이션(third party application)인 경 우, 프로세서는 복수의 기능 UI 중 일부 기능 UI에 대응되는 기능의 제어 권한을 웨어러블 디바이스에 제 공할 수 없다. 이 경우 웨어러블 디바이스는 터치 패드로 동작하여 애플리케이션의 기능을 제어할 수 있다. 본 개시의 일 실시예에서, 증강 현실 디바이스는 시선 추적 센서를 더 포함할 수 있다. 시선 추적 센서는 사용자의 눈의 시선을 추적함으로써, 시선 방향에 관한 정보를 획득할 수 있다. 시선 추적 센서는 광원을 이용 하여 사용자의 눈에 근적외선 등의 광을 조사되고, 눈의 각막에 의해 반사되는 반사광을 수광함으로써, 사용자 의 시선 방향을 검출할 수 있다. 본 개시의 일 실시예에서, 시선 추적 센서는 사용자의 눈을 촬영함으로써, 눈 동자 또는 동공의 이미지를 획득할 수 있다. 이러한 시선 추적 센서는 좌안용 시선 추적 센서와 우안용 시선 추 적 센서를 포함하며, 각기 사용자의 좌안의 시선 방향 및 사용자의 우안의 시선 방향을 검출할 수 있다. 본 개시의 일 실시예에서, 프로세서는 복수의 애플리케이션을 실행함으로써, 광학 엔진을 통해 복수 의 애플리케이션에 의해 제공되는 복수의 가상 객체를 웨이브 가이드에 투사할 수 있다. 프로세서는 시선 추적 센서로부터 사용자의 좌안의 시선 방향과 우안의 시선 방향이 수렴하는 응시점(gaze point)를 인식하고, 인식된 응시점의 위치에 기초하여 복수의 애플리케이션 중 어느 하나의 애플리케이션을 선택할 수 있다. 프 로세서는 선택된 애플리케이션에 의해 표시되는 가상 객체와 관련된 기능의 제어 권한을 웨어러블 디바이 스에 제공할 것을 결정할 수 있다. 프로세서가 사용자의 응시점의 위치에 기초하여 애플리케이션을 선택하 고, 선택된 애플리케이션에 의해 제공되는 가상 객체와 관련된 기능의 제어 권한을 웨어러블 디바이스에 제공할 것을 결정하는 구체적인 실시예에 대해서는 도 9 및 도 10에서 상세하게 설명하기로 한다. 프로세서는 기능의 제어 권한을 웨어러블 디바이스에 전송하도록 통신 인터페이스를 제어할 수 있다. 프로세서는 웨어러블 디바이스에 기능의 제어 권한을 전송할 뿐만 아니라, 가상 객체의 특성 정보 및 기능 과 관련된 데이터 값을 함께 웨어러블 디바이스에 전송할 수 있다. 본 개시에서, '가상 객체의 특성 정보'는 가 상 객체에 포함되는 기능 UI의 타입(type)에 관한 정보를 포함할 수 있다. 기능 UI의 타입은 예를 들어, 슬라이 더(slider), 스크롤 바(scroll bar), 스피너(spinner), 버튼, 휠, 또는 드롭다운(drop down)을 포함할 수 있으 나, 이에 한정되는 것은 아니다. 본 개시에서, '기능에 관한 데이터 값'은 예를 들어, 플레이 시간, 스크롤 바 위치, 또는 선택된 아이템 값 등과 같은 증강 현실 디바이스에 의해 제공되는 기능의 현재 데이터 값일 수 있으나, 이에 한정되지 않는다. 웨어러블 디바이스는 증강 현실 디바이스로부터 획득한 제어 권한을 이용하여 기능과 관련된 데이터 값을 변경할 수 있다. 웨어러블 디바이스는 제어 권한에 기초하여, 사용자 입력에 의해 기능의 데이터 값을 변경할 수 있다. 프로세서는 통신 인터페이스를 통해, 웨어러블 디바이스로부터 변경된 데이터 값을 수신할 수 있다. 프로세서는 웨어러블 디바이스로부터 수신된 데이터 값을 이용하여 가상 객체와 관련된 기능의 데이터 값을 업데이트할 수 있다. 통신 인터페이스는 외부 디바이스(예를 들어, 웨어러블 디바이스), 또는 서버와 데이터 통신을 수행하도록 구성된다. 본 개시의 일 실시예에서, 통신 인터페이스는 근거리 무선 통신 모듈 및 이동 통신 모듈을 포함 할 수 있다. 근거리 무선 통신 모듈(short-range wireless communication unit)은 무선 통신 네트워크를 이용하여 외부 디 바이스와 연결하고, 데이터 송수신을 수행하도록 구성된다. 근거리 무선 통신 모듈은 예를 들어, 와이파이 (WiFi), WFD(Wi-Fi Direct) 통신부, 블루투스 통신부, BLE(Bluetooth Low Energy) 통신부, NFC(Near Field Communication unit), 지그비(Zigbee) 통신부, Ant+ 통신부, 또는 마이크로 웨이브(μWave) 통신부 중 적어도 하나의 하드웨어 모듈로 구성될 수 있으나, 이에 한정되는 것은 아니다. 본 개시의 일 실시예에서, 통신 인터페 이스는 블루투스 통신을 통해 웨어러블 디바이스와 페어링(pairing)되고, 블루투스 통신을 이용하여 웨어 러블 디바이스와 데이터 송수신을 수행할 수 있다. 그러나, 이에 한정되는 것은 아니고, 통신 인터페이스 는 와이파이(WiFi), WFD(Wi-Fi Direct), BLE(Bluetooth Low Energy), NFC(Near Field Communication unit), 지그비(Zigbee), Ant+, 또는 마이크로 웨이브(μWave) 중 적어도 하나의 근거리 무선 통신 네트워크를 이용하여, 웨어러블 디바이스와 데이터 송수신을 수행할 수 있다. 이동 통신 모듈은 이동 통신망 상에서 기지국, 외부 디바이스, 또는 서버 중 적어도 하나와 무선 신호를 송수신 하도록 구성되는 통신 모듈이다. 이동 통신 모듈은 예를 들어, 5G mmWave 통신, 5G Sub 6 통신, LTE(Long Term Evolution) 통신, 또는 3G 이동 통신 중 적어도 하나의 통신 방식을 이용하여 데이터를 송수신할 수 있다. 본 개시의 일 실시예에서, 이동 통신 모듈은 프로세서의 제어에 의해 서버와 데이터를 송수신할 수 있다. 도 3은 본 개시의 일 실시예에 따른 증강 현실 디바이스의 동작 방법을 도시한 흐름도이다. 단계 S310에서, 증강 현실 디바이스는 가상 객체 상에 오버레이되는(overlaid) 웨어러블 디바이스를 인식 한다. 증강 현실 디바이스는 카메라(110, 도 2 참조)로부터 웨어러블 디바이스를 촬영한 이미지 프레임을 획득하고, 획득한 이미지 프레임으로부터 웨어러블 디바이스를 인식할 수 있다. 본 개시의 일 실시예에서, 웨어 러블 디바이스는 웨이브 가이드를 통해 투사되는 가상 객체 상에 오버레이될 수 있다. 증강 현실 디바이스 는 이미지 프레임으로부터 가상 객체 상에 오버레이되는 웨어러블 디바이스를 인식할 수 있다. 증강 현실 디바이스는 인공지능 모델을 이용하여, 이미지 프레임으로부터 웨어러블 디바이스를 인식할 수 있다. 인공 지능 모델은 예를 들어, 컨볼루션 신경망 모델(Convolutional Neural Network; CNN), 순환 신경망 모델 (Recurrent Neural Network; RNN), RBM(Restricted Boltzmann Machine), DBN(Deep Belief Network), BRDNN(Bidirectional Recurrent Deep Neural Network) 및 심층 Q-네트워크 (Deep Q-Networks) 중 적어도 하나 를 포함하는 심층 신경망 모델로 구현될 수 있다. 그러나, 이에 한정되는 것은 아니고, 증강 현실 디바이스는 공지의 이미지 프로세싱(image processing) 방식을 통해 이미지 프레임으로부터 웨어러블 디바이스를 인식할 수 있다. 본 개시의 일 실시예에서, 증강 현실 디바이스는 웨어러블 디바이스를 착용 또는 파지하고 있는 사용자의 손을 인식할 수 있다. 본 개시의 일 실시예에서, 증강 현실 디바이스는 웨어러블 디바이스를 착용 또는 파 지하고 있는 사용자의 손의 제스처를 인식할 수 있다. 본 개시의 일 실시예에서, 증강 현실 디바이스는 웨 어러블 디바이스를 착용 또는 파지하고 있는 사용자의 손에 의해 기 설정된 횟수 이상 반복되는 반복 동작을 인 식할 수 있다. 단계 S320에서, 증강 현실 디바이스는 인식된 웨어러블 디바이스에 가상 객체와 관련된 기능을 실행 또는 제어하기 위한 제어 권한의 제공을 결정한다. 본 개시의 일 실시예에서, 증강 현실 디바이스는 이미지 프 레임으로부터 인식된 손에 의해 가상 객체가 오버레이되는 시간에 기초하여 웨어러블 디바이스에 기능의 제어 권한을 제공할 지 여부를 결정할 수 있다. 증강 현실 디바이스는 손에 의해 가상 객체가 오버레이되는 시 간이 기 설정된 시간을 초과하는 경우 웨어러블 디바이스에 기능의 제어 권한을 제공할 것을 결정할 수 있다. 본 개시의 일 실시예에서, 증강 현실 디바이스는 인식된 손의 제스처에 기초하여 웨어러블 디바이스에 기 능의 제어 권한을 제공할 지 여부를 결정할 수 있다. 예를 들어, 인식된 제스처가 기 설정된 제스처와 동일 또 는 유사한 경우, 증강 현실 디바이스는 인식된 제스처를 기 설정된 제스처와 비교하고, 비교 결과에 따라 제스처를 식별하며, 식별 결과에 따라 웨어러블 디바이스에 기능의 제어 권한을 제공할 것을 결정할 수 있다. 본 개시의 일 실시예에서, 증강 현실 디바이스는 인식된 반복 동작에 기초하여 웨어러블 디바이스에 기능 의 제어 권한을 제공할 것을 결정할 수 있다. 예를 들어, 스크롤 동작이 5회 이상 반복되는 경우 프로세서(13 0)는 스크롤 기능에 관한 제어 권한을 웨어러블 디바이스에 제공할 것을 결정할 수 있다 본 개시의 일 실시예에서, 증강 현실 디바이스는 가상 객체에 포함되는 복수의 기능 UI 중 웨어러블 디바 이스에 제어 권한을 제공할 기능에 관한 기능 UI를 선택할 수 있다. 가상 객체는 애플리케이션에 의해 제공되는 복수의 기능을 실행하기 위한 복수의 기능 UI(User Interface)를 포함할 수 있다. 증강 현실 디바이스는 복수의 기능 UI 중 웨어러블 디바이스를 착용 또는 파지하고 있는 사용자의 손에 의해 오버레이되는 기능 UI를 식별할 수 있다. 증강 현실 디바이스는 식별된 기능 UI에 의해 실행 또는 제어되는 기능에 관한 제어 권한 을 웨어러블 디바이스에 제공할 것을 결정할 수 있다. 본 개시의 일 실시예에서, 증강 현실 디바이스는 제어 권한을 웨어러블 디바이스에 제공하는 것으로 결정 된 기능 UI의 제어 영역을 가상 객체 내의 다른 영역(예를 들어, 애플리케이션의 실행 화면 또는 선택되지 않은 적어도 하나의 기능 UI의 제어 영역)과 구별되는 컬러로 표시할 수 있다. 단계 S330에서, 증강 현실 디바이스는 기능의 제어 권한, 가상 객체의 특성 정보, 및 기능과 관련된 데이 터 값 중 적어도 하나를 웨어러블 디바이스에 전송한다. 본 개시의 일 실시예에서, '가상 객체의 특성 정보'는 가상 객체에 포함되는 기능 UI의 타입(type)에 관한 정보를 포함할 수 있다. 기능 UI의 타입은 예를 들어, 슬라 이더(slider), 스크롤 바(scroll bar), 스피너(spinner), 버튼, 휠, 또는 드롭다운(drop down)을 포함할 수 있 으나, 이에 한정되는 것은 아니다. '기능에 관한 데이터 값'은 예를 들어, 플레이 시간, 스크롤 바 위치, 또는 선택된 아이템 값 등과 같은 증강 현실 디바이스에 의해 제공되는 기능의 현재 데이터 값일 수 있으나, 이 에 한정되지 않는다. 단계 S340에서, 증강 현실 디바이스는 전송된 제어 권한에 기초하여 웨어러블 디바이스에 의해 변경된 데 이터 값을 외부 디바이스로부터 수신한다. 웨어러블 디바이스는 증강 현실 디바이스로부터 획득한 제어 권 한을 이용하여 기능과 관련된 데이터 값을 변경할 수 있다. 웨어러블 디바이스는 제어 권한에 기초하여, 사용자 입력에 의해 기능의 데이터 값을 변경할 수 있다. 증강 현실 디바이스는 웨어러블 디바이스로부터 변경된 데이터 값을 수신할 수 있다. 단계 S350에서, 증강 현실 디바이스는 수신된 데이터 값에 기초하여 기능의 데이터 값을 업데이트한다. 도 2 및 도 3에 도시된 실시예에서, 증강 현실 디바이스는 웨어러블 디바이스에 기능의 제어 권한을 제공 하고, 웨어러블 디바이스에 의해 제어된다고 기재하였지만, 본 개시가 이에 한정되는 것은 아니다. 본 개시의 일 실시예에서, 증강 현실 디바이스는 외부 디바이스, 예를 들어 모바일 디바이스, 스마트 폰(smart phone), 노트북 컴퓨터(laptop computer), 데스크 탑, 태블릿 PC, 전자책 단말기, 디지털 방송용 단말기, PDA(Personal Digital Assistants), PMP(Portable Multimedia Player), 네비게이션, MP3 플레이어, 또는 캠코더에 기능에 관한 제어 권한을 제공하고, 외부 디바이스에 의해 제어될 수도 있다. 도 4는 본 개시의 일 실시예에 따른 증강 현실 디바이스가 웨어러블 디바이스에 제어 권한의 제공을 결정하는 동작을 도시한 도면이다. 도 4를 참조하면, 증강 현실 디바이스는 웨이브가이드 상에 가상 객체를 표시할 수 있다. 가상 객체는 프로세서(130, 도 2 참조)의 제어에 의해 광학 엔진(124, 도 3 참조)에 의해 생성되고, 광학 엔진 에 의해 웨이브가이드 상에 투사됨으로써, 사용자에게 표시될 수 있다. 도 4를 포함한 본 개시의 도 면들에서, 가상 객체는 좌안의 웨이브가이드 상에 투사되는 것으로 도시되었으나, 이는 설명의 편의 를 위한 것이고, 도면에 도시된 바와 같이 한정되는 것은 아니다. 본 개시에서, 가상 객체는 좌안의 웨이 브가이드 뿐만 아니라, 우안의 웨이브가이드를 통해서도 투사될 수 있다. 가상 객체는 증강 현 실 디바이스에 의해 실행되는 애플리케이션을 통해 제공되는 적어도 하나의 기능 UI(410, 412, 414, 420) 를 포함할 수 있다. 도 4에 도시된 실시예에서, 증강 현실 디바이스에 의해 실행되는 애플리케이션은 동영 상 플레이 애플리케이션이거나 또는 동영상 스트리밍 애플리케이션일 수 있다. 동영상 플레이 애플리케이션인 경우, 가상 객체는 애플리케이션의 실행 화면(예를 들어, 동영상 플레이 화면)을 더 포함할 수 있다. 증강 현실 디바이스는 비젼 인식 기술을 통해 가상 객체와 오버레이되는(overlaid) 웨어러블 디바이 스를 인식할 수 있다. 본 개시의 일 실시예에서, 증강 현실 디바이스의 프로세서는 카메라(110, 도 2 참조)를 통해 웨어러블 디바이스 및 웨어러블 디바이스를 착용 또는 파지하고 있는 사용자의 손 을 촬영하여 이미지 프레임을 획득하고, 인공지능 모델을 이용하여 이미지 프레임으로부터 웨어러블 디바이스 를 인식할 수 있다. '인공지능 모델'은 이미지 데이터로부터 객체를 인식하고, 객체를 타입에 따라 분류 (classify)하도록 학습된 심층 신경망 모델(deep neural network)을 포함할 수 있다. 심층 신경망 모델은 예를 들어, 컨볼루션 신경망 모델(Convolutional Neural Network; CNN), 순환 신경망 모델(Recurrent Neural Network; RNN), RBM(Restricted Boltzmann Machine), DBN(Deep Belief Network), BRDNN(Bidirectional Recurrent Deep Neural Network) 및 심층 Q-네트워크 (Deep Q-Networks) 중 적어도 하나를 포함할 수 있다. 프 로세서는 이미지 프레임을 심층 신경망 모델에 입력하는 추론을 통해, 사용자의 손을 인식할 수 있다. 그러나, 본 개시가 이에 한정되는 것은 아니고, 프로세서는 공지의 이미지 프로세싱(image processing) 기 술을 이용하여 이미지 프레임으로부터 웨어러블 디바이스 또는 사용자의 손을 인식할 수 있다. 프로세서는 인식된 손에 의해 가상 객체가 오버레이되는 시간을 측정하고, 측정된 시간이 기 설정된 시간 을 초과하는지 여부에 기초하여 웨어러블 디바이스에 기능의 제어 권한을 제공할 지 여부를 결정할 수 있 다. 도 4에 도시된 실시예에서, 프로세서는 가상 객체에 포함되는 복수의 기능 UI(410, 412, 414, 420) 중 웨어러블 디바이스를 착용하고 있는 사용자의 손에 의해 제1 기능 UI가 오버레이되는 시간을 측정할 수 있다. 프로세서는 측정된 시간을 나타내는 제2 기능 UI 및 제3 기능 UI를 웨이브가이 드를 통해 표시할 수 있다. 제2 기능 UI는 예를 들어, 가상 객체가 사용자의 손에 의해 오버레이되는 시간을 나타내는 시계 아이콘이고, 제3 기능 UI는 기 설정된 시간에 대하여 측정된 시간의 경과 정도를 나 타내는 프로그레스 바(progress bar)일 수 있으나, 이에 한정되지 않는다. 측정된 시간이 기 설정된 시간을 초 과하는 경우, 프로세서는 웨어러블 디바이스에 기능의 제어 권한을 제공할 것을 결정할 수 있다. 프로세서는 사용자의 손에 의해 오버레이되는 가상 객체에 의해 실행 또는 제어되는 기능에 관한 제 어 권한을 웨어러블 디바이스에 제공할 수 있다. 도 4에 도시된 실시예에서, 프로세서는 제1 기능 UI를 통해 실행 또는 제어되는 플레이 타임 제어 기능에 관한 제어 권한을 웨어러블 디바이스에 전송 할 수 있다. 도 5a는 본 개시의 일 실시예에 따른 증강 현실 디바이스가 사용자의 제스처에 기초하여 웨어러블 디바이 스에 제어 권한의 제공을 결정하는 동작을 도시한 도면이다. 도 5a를 참조하면, 증강 현실 디바이스는 웨이브가이드 상에 가상 객체(500a)를 표시할 수 있다. 가 상 객체(500a)는 프로세서(130, 도 2 참조)의 제어에 의해 광학 엔진(124, 도 3 참조)에 의해 생성되고, 광학 엔진에 의해 웨이브가이드 상에 투사됨으로써, 사용자에게 표시될 수 있다. 증강 현실 디바이스는 비젼 인식 기술을 통해 가상 객체(500a)와 오버레이되는(overlaid) 웨어러블 디바이 스를 인식할 수 있다. 증강 현실 디바이스는 웨어러블 디바이스를 착용 또는 파지하고 있는 사 용자의 손의 제스처(gesture)를 인식할 수 있다. 증강 현실 디바이스의 프로세서는 카메라(110, 도 2 참조)를 이용하여 사용자의 손을 촬영한 복수의 이미지 프레임으로부터 손의 제스처를 인식할 수 있다. 본 개시 의 일 실시예에서, 프로세서는 인공지능 모델을 이용하여 복수의 이미지 프레임으로부터 사용자의 손의 제 스처를 인식할 수 있다. 그러나, 이에 한정되는 것은 아니고, 프로세서는 공지의 이미지 프로세싱 기술을 이용하여 복수의 이미지 프레임으로부터 사용자의 손의 제스처를 인식할 수 있다. 도 5a에 도시된 실시예에서, 프로세서는 웨어러블 디바이스를 착용하고 있는 손의 검지와 엄지를 이용하여 원을 그리는 제스처(OK 제스처)를 인식할 수 있다. 프로세서는 인식된 손의 제스처에 기초하여 웨어러블 디바이스에 기능의 제어 권한을 제공할 지 여부 를 결정할 수 있다. 예를 들어, 인식된 제스처가 기 설정된 제스처와 동일 또는 유사한 경우, 프로세서는 인식된 제스처를 기 설정된 제스처와 비교하고, 비교 결과에 따라 제스처를 식별하며, 식별 결과에 따라 웨어러 블 디바이스에 기능의 제어 권한을 제공할 것을 결정할 수 있다. 프로세서는 제어 권한을 웨어러블 디바이스에 제공할 지 여부를 사용자에게 안내하는 팝 업 메시지 (pop-up message)를 생성하고, 팝 업 메시지를 웨이브가이드 상에 투사하도록 광학 엔진(124, 도 2 참조)을 제어할 수 있다. 팝 업 메시지는 예를 들어, \"스마트 워치로 제어권을 획득하시려면 손가락 으로 OK 표시를 해주세요~\"와 같이 사용자에게 제스처를 유도하고, 웨어러블 디바이스에 제어 권한을 제공 할 것을 안내하는 메시지일 수 있다. 프로세서는 팝 업 메시지를 기 설정된 시간이 경과 후에 웨이브 가이드 상에서 사라지도록 광학 엔진을 제어할 수 있다. 예를 들어, 프로세서는 팝 업 메시지 가 표시된 이후 2초가 경과한 경우, 팝 업 메시지를 표시하지 않을 수 있다. 도 5a의 실시예에서는, 팝 업 메시지가 표시된 것으로 도시되고, 설명되었으나, 본 개시가 이에 한정되는 것은 아니다. 본 개시의 일 실시예에서, 프로세서는 팝 업 메시지를 표시하지 않고도, 사용자의 손의 제스처를 인식하고, 인식된 제스처에 기초하여 웨어러블 디바이스에 제어 권한의 제공을 결정할 수 있다. 도 5b는 본 개시의 일 실시예에 따른 증강 현실 디바이스가 사용자의 제스처에 기초하여 웨어러블 디바이 스로부터 제어 권한을 회수하는 동작을 도시한 도면이다. 도 5b에 도시된 실시예는 사용자의 손의 제스처의 종류 및 그에 따른 증강 현실 디바이스의 동작을 제외하 고는 도 5a의 실시예와 동일하므로, 중복되는 설명은 생략한다. 도 5b를 참조하면, 증강 현실 디바이스는 일부 기능에 관한 제어 권한을 이미 웨어러블 디바이스에 제공한 상태에서, 사용자의 손의 제스처를 인식할 수 있다. 증강 현실 디바이스의 프로세서(130, 도 2 참 조)는 웨어러블 디바이스를 착용하고 있는 손의 손가락을 펼친 채 손을 좌우로 흔드는 제스처를 인식할 수 있다. 프로세서는 인식된 손의 제스처에 기초하여 웨어러블 디바이스에 제공된 제어 권한을 회수할 지 여부 를 결정할 수 있다. 예를 들어, 프로세서는 인식된 제스처를 기 설정된 제스처와 비교하고, 비교 결과에 따라 제스처를 식별하며, 식별 결과에 따라 웨어러블 디바이스로부터 기능의 제어 권한을 회수할 것을 결 정할 수 있다. 도 5b에 도시된 실시예에서, 프로세서는 손가락을 펼친 채로 손을 좌우로 흔드는 제스처를 인식하고, 인식 결과에 기초하여 웨어러블 디바이스에 제공되었던 제어 권한을 회수할 것을 결정할 수 있 다. 웨어러블 디바이스에 아직 제어 권한이 제공되지 않은 상태인 경우, 프로세서는 인식된 제스처에 따라 제어 권한의 제공 프로세스를 종료할 수 있다. 도 6은 본 개시의 일 실시예에 따른 증강 현실 디바이스가 사용자의 반복 동작에 기초하여 웨어러블 디바 이스에 제어 권한의 제공을 결정하는 동작을 도시한 도면이다. 도 6을 참조하면, 증강 현실 디바이스는 웨이브가이드 상에 가상 객체를 표시할 수 있다. 가상 객체는 프로세서(130, 도 2 참조)의 제어에 의해 광학 엔진(124, 도 3 참조)에 의해 생성되고, 광학 엔진 에 의해 웨이브가이드 상에 투사됨으로써, 사용자에게 표시될 수 있다. 증강 현실 디바이스는 비젼 인식 기술을 통해 가상 객체와 오버레이되는(overlaid) 웨어러블 디바이 스를 인식할 수 있다. 증강 현실 디바이스는 웨어러블 디바이스를 착용 또는 파지하고 있는 사용자의 손에 의해 기 설정된 횟수 이상 반복되는 반복 동작을 인식할 수 있다 (동작 ①). 증강 현실 디바이스 의 프로세서는 예를 들어, 사용자의 손에 의해 가상 객체 상의 일부 영역을 반복적으로 스크롤 (scroll)하는 동작 또는 반복적으로 스와이프(swipe)하는 동작을 인식할 수 있다. 도 6에 도시된 실시예에서, 가상 객체는 웹툰 등 컨텐츠를 제공하는 웹 브라우저 실행 화면이고, 프로세서는 웹 브라우저의 웹툰 표시 영역을 기 설정된 횟수 이상 반복적으로 스크롤하는 동작을 인식할 수 있다. 기 설정된 횟수는 예를 들어, 5회일 수 있으나, 이에 한정되지 않는다. 프로세서는 인식된 반복 동작에 기초하여 웨어러블 디바이스에 기능의 제어 권한을 제공할 것을 결정 할 수 있다. 예를 들어, 스크롤 동작이 5회 이상 반복되는 경우 프로세서는 스크롤 기능에 관한 제어 권한 을 웨어러블 디바이스에 제공할 것을 결정할 수 있다. 본 개시의 일 실시예에서, 프로세서는 사용자의 손에 의해 가상 객체를 통해 제어되는 기능이 이전 시점에 웨어러블 디바이스에 의해 제어되었던 이력이 있는 경우, 제어 중인 기능의 제어 권한을 웨어러블 디바이스에 전송할 것을 결정할 수 있다. 웨어러블 디바이스는 증강 현실 디바이스로부터 제어 권한을 획득하고, 획득된 제어 권한을 사용자에 게 알리는 알림 메시지를 출력할 수 있다(동작 ②). 웨어러블 디바이스는 알림 메시지를 디스플 레이부 상에 표시할 수 있다. 도 6에 도시된 실시예에서, 알림 메시지는 \"인터넷의 스크롤(scroll)을 제어하시겠습니까?\"와 같이, 웨어러블 디바이스를 통해 증강 현실 디바이스의 특정 기능(예를 들어, 웹 브라우저의 스크롤 기능)의 제어 권한을 획득 여부를 알리고, 웨어러블 디바이스를 통해 기능을 제어할 것인지 여부를 사용자에게 확인하는 메시지일 수 있다. 본 개시의 일 실시예에서, 웨어러블 디바이스는 증강 현실 디바이스로부터 제어 권한의 획득 여부를 알리는 진동 신호를 출력할 수 있다. 도 7은 본 개시의 일 실시예에 따른 증강 현실 디바이스가 기능 UI(User Interface)에 관한 제어 권한을 웨어러블 디바이스에 전송하는 방법을 도시한 흐름도이다. 도 7에 도시된 단계 S710 및 S720은 도 3에 도시된 단계 S320을 구체화한 단계들이다. 도 7에 도시된 단계 S710 은 도 3의 단계 S310이 수행된 이후에 수행될 수 있다. 도 7에 도시된 단계 S730이 수행된 이후에는 도 3의 단 계 S330이 수행될 수 있다. 도 8a는 본 개시의 일 실시예에 따른 증강 현실 디바이스가 웨어러블 디바이스에 제어 권한을 제공할 기능에 관한 기능 UI를 디스플레이하는 동작을 도시한 도면이다. 이하에서는, 도 7과 도 8a를 함께 참조하여 증 강 현실 디바이스의 동작 방법에 관하여 설명하기로 한다. 도 7의 단계 S710를 참조하면, 증강 현실 디바이스는 가상 객체에 포함되는 복수의 기능 UI(User Interface) 중 웨어러블 디바이스(200, 도 8a 참조)를 착용하고 있는 사용자의 손에 의해 오버레이되는 기능 UI 를 식별한다. 도 8a를 함께 참조하면, 증강 현실 디바이스는 웨이브가이드를 통해 표시되는 가상 객 체(800a)의 일부와 오버레이되는 사용자의 손을 인식할 수 있다. 사용자의 손은 웨어러블 디바이스를 착용 또는 파지하고 있을 수 있다. 증강 현실 디바이스의 프로세서(130, 도 2 참조)는 가상 객체(800a)에 포함 되는 복수의 기능 UI(810, 812, 814, 820) 중 사용자의 손에 의해 오버레이되는 기능 UI를 식별할 수 있다. 도 8a에 도시된 실시예에서, 프로세서는 손에 의해 오버레이되는 제1 기능 UI를 식별할 수 있다. 본 개시의 일 실시예에서, 프로세서는 사용자의 손이 기능 UI 상에서 호버(hover) 상태로 오버레이되는 시 간을 측정하고, 측정된 시간이 기 설정된 시간(예를 들어, 2초)을 초과하는 기능 UI를 식별할 수 있다. 도 8a에 도시된 실시예에서, 프로세서는 사용자의 손이 호버 상태로 제1 기능 UI 상에서 오버레이되는 시간을 측정하고, 측정된 시간이 2초를 경과하는지 여부를 판단할 수 있다. 이 경우, 프로세서는 사용자의 손에 의해 제1 기능 UI가 오버레이되는 시간을 나타내는 제2 UI 및 제3 UI를 웨이브가이드를 통 해 표시할 수 있다. 제2 UI는 예를 들어, 제1 기능 UI가 사용자의 손에 의해 오버레이되는 시간을 나 타내는 시계 아이콘이고, 제3 UI는 기 설정된 시간에 대하여 측정된 시간의 경과 정도를 나타내는 프로그 레스 바(progress bar)일 수 있으나, 이에 한정되지 않는다. 도 7의 단계 S720을 참조하면, 증강 현실 디바이스는 식별된 기능 UI에 의해 실행 또는 제어되는 기능에 관한 제어 권한을 웨어러블 디바이스에 제공할 것을 결정할 수 있다. 도 8a를 함께 참조하면, 프로세서는 실행 중인 애플리케이션의 복수의 기능 UI(810, 812, 814, 820) 각각에 관한 API (Application Programming Interface)의 제공 가능 여부에 기초하여, 식별된 기능 UI에 관한 기능의 제어 권한을 선택적으로 웨어러블 디바이스에 제공할 지 여부를 결정할 수 있다. 예를 들어, 애플리케이션이 복수의 기능 UI(810, 812, 814, 820) 전체에 관한 API 를 제공할 수 있는 경우, 프로세서는 사용자의 손에 의해 선택된 제1 기 능 UI에 대응되는 기능의 제어 권한만을 선택적으로 웨어러블 디바이스에 제공할 수 있다. 반대의 예를 들어, 애플리케이션이 API를 제공하지 않는 써드파티 애플리케이션(third party application)인 경 우, 프로세서는 복수의 기능 UI(810, 812, 814, 820) 중 일부 기능 UI에 대응되는 기능의 제어 권한을 웨 어러블 디바이스에 제공할 수 없다. 도 8c는 본 개시의 일 실시예에 따른 증강 현실 디바이스가 웨어러블 디바이스에 제어 권한을 제공할 기능에 관한 기능 UI를 선택하는 동작을 도시한 도면이다. 도 8c를 함께 참조하면, 실행 중인 애플리케이션에 의해 웨이브가이드 상에 투사되는 가상 객체(800c)는 복수의 기능 UI(810, 820, 830)을 포함할 수 있다. 도 8c에 도시된 실시예에서, 애플리케이션은 복수의 기능 UI(810, 820, 830) 각각에 관한 API를 제공하지 않는 써드파티 애플리케이션일 수 있다. 프로세서는 복수의 기능 UI(810, 820, 830)을 모두 포함하도록 손가락을 한바퀴 돌리는 제스처를 인식하고, 인식된 제스처에 기초하여 복수의 기능 UI(810, 820, 830) 전체에 각각 대응되는 복수의 기능들의 제어 권한을 웨어러블 디바이스에 제공할 것을 결정할 수 있다. 복수의 기능 UI(810, 820, 830) 각각에 관한 API가 제공되지 않는 경우, 웨어러블 디바이스는 디스플레이부(250, 도 11 및 도 16 참조)를 터치 패드로 활용하여, 터치 패드를 통해 수신되는 터치 입력에 따라 증강 현실 디바이스의 애플리케이션에 의해 제공되는 전체 기능을 제어할 수 있다. 웨어 러블 디바이스가 디스플레이부를 터치 패드로 활용하여 증강 현실 디바이스의 전체 기능을 제어 하는 구체적인 실시예에 대해서는 도 16 및 도 21에서 상세하게 설명하기로 한다. 다시 도 7을 참조하면, 단계 S730에서 증강 현실 디바이스는 식별된 기능 UI의 제어 영역을 가상 객체 내 다른 영역과 구별되는 컬러로 표시한다. 도 8a를 함께 참조하면, 증강 현실 디바이스의 프로세서는 웨어러블 디바이스로 기능의 제어 권한이 제공되는 기능 UI인 제1 기능 UI를 다른 기능 UI(812, 814, 820)과는 다른 컬러로 표시할 수 있다. 도 8b는 본 개시의 일 실시예에 따른 증강 현실 디바이스가 웨어러블 디바이스에 제어 권한을 제공할 기능에 관한 기능 UI를 디스플레이하는 동작을 도시한 도면이다. 도 8b를 참조하면, 증강 현실 디바이스 는 복수의 기능 UI(810, 820, 830)를 포함하는 가상 객체(800c)를 웨이브가이드 상에 투사하고, 웨이 브가이드를 통해 사용자에게 표시할 수 있다. 도 8b를 도 7의 단계 S730과 함께 참조하면, 증강 현실 디바 이스의 프로세서는 사용자의 손에 의해 오버레이되는 제3 기능 UI에 의해 실행 또는 제어되는 기능의 제어 권한을 웨어러블 디바이스에 제공할 것을 결정하고, 제3 기능 UI의 크기를 다른 기능 UI(810, 820) 보다 크게 표시할 수 있다. 본 개시의 일 실시예에서, 프로세서는 제3 기능 UI의 제어 영역을 나타내는 박스형 UI를 더 표시할 수도 있다. 도 9는 본 개시의 일 실시예에 따른 증강 현실 디바이스가 사용자의 응시점에 기초하여 제어 권한을 제공 할 기능과 관련된 가상 객체를 결정하는 방법을 도시한 흐름도이다. 도 9에 도시된 단계 S920 내지 S940은 도 3에 도시된 단계 S320을 구체화한 단계들이다. 도 9에 도시된 단계 S940이 수행된 이후에는 도 3의 단계 S330이 수행될 수 있다. 도 10은 본 개시의 일 실시예에 따른 증강 현실 디바이스가 사용자의 응시점에 기초하여 웨어러블 디바이 스에 제어 권한을 제공할 기능과 관련된 가상 객체를 결정하는 동작을 도시한 도면이다. 이하에서는, 도 9 와 도 10을 함께 참조하여 증강 현실 디바이스가 사용자의 응시점에 기초하여 웨어러블 디바이스에 제공할 제어 권한과 관련된 가상 객체를 결정하는 동작을 설명하기로 한다. 도 9의 단계 S910을 참조하면, 증강 현실 디바이스는 복수의 애플리케이션을 실행하여 복수의 가상 객체를 표시할 수 있다. 도 10을 함께 참조하면, 증강 현실 디바이스의 프로세서(130, 도 2 참조)는 2개의 애플리 케이션을 실행하고, 2개의 애플리케이션에 의해 각각 제공되는 복수의 가상 객체(1010, 1020)를 웨이브가이드 상에 투사하도록 광학 엔진(124, 도 2 참조)을 제어할 수 있다. 사용자는 웨이브가이드를 통해 투사 된 복수의 가상 객체(1010, 1020)를 볼 수 있다. 복수의 가상 객체(1010, 1020) 각각은 서로 다른 애플리케이션 의 실행 화면일 수 있다. 예를 들어, 제1 가상 객체는 음악 애플리케이션의 실행 화면인 음악 플레이 화 면이고, 제2 가상 객체는 전자책 애플리케이션(e-book application)의 실행 화면인 전자 책의 텍스트를표시하는 화면일 수 있다. 제1 가상 객체와 제2 가상 객체는 각각 적어도 하나의 기능 UI를 포함할 수 있다. 도 10에는 증강 현실 디바이스가 2개의 애플리케이션을 실행하는 것으로 도시되고, 설명되었으나, 본 개시가 이에 한정되는 것은 아니다. 본 개시의 일 실시예에서, 증강 현실 디바이스는 3 개 이상의 복수 개의 애플리케이션을 동시에 실행하여 복수의 가상 객체를 표시할 수 있다. 도 9의 단계 S920를 참조하면, 증강 현실 디바이스는 사용자의 좌안의 시선 방향 및 우안의 시선 방향이 수렴하는 응시점을 인식한다. 도 10을 함께 참조하면, 증강 현실 디바이스는 사용자의 좌안의 시선 방향을 검출하여 시선 방향 정보를 획득하는 제1 시선 추적 센서(160L) 및 우안의 시선 방향을 검출하여 시선 방향 정 보를 획득하는 제2 시선 추적 센서(160R)를 포함할 수 있다. 증강 현실 디바이스의 프로세서는 제1 시선 추적 센서(160L)로부터 좌안의 시선 방향 정보를 획득하고, 제2 시선 추적 센서(160R)로부터 우안의 시선 방향 정보를 획득할 수 있다. 프로세서는 양안 시차(binocular disparity), 좌안의 시선 방향, 및 우안의 시선 방향에 관한 시선 정보를 이용하여, 응시점(gaze point)(G)를 인식할 수 있다. 프로세서는 인식된 응 시점(G)의 3차원 위치 좌표값을 획득할 수 있다. 도 9의 단계 S930을 참조하면, 증강 현실 디바이스는 응시점의 위치에 기초하여 실행 중인 복수의 애플리 케이션 중 어느 하나의 애플리케이션을 선택한다. 도 10을 함께 참조하면, 증강 현실 디바이스의 프로세서 는 응시점(G)의 위치가 전자책 애플리케이션에 의해 표시되는 제2 가상 객체의 제어 영역 내인 것을 인식하고, 인식 결과에 기초하여 음악 애플리케이션과 전자책 애플리케이션 중 전자책 애플리케이션을 선택할 수 있다. 도 9의 단계 S940을 참조하면, 증강 현실 디바이스는 선택된 애플리케이션에 의해 표시되는 적어도 하나의 가상 객체와 관련된 기능의 제어 권한을 웨어러블 디바이스에 제공할 것을 결정한다. 도 10을 함께 참조하 면, 증강 현실 디바이스의 프로세서는 응시점(G)의 위치에 기초하여 선택된 전자책 애플리케이션에 의해 표시되는 제2 기능 UI에 의해 실행 또는 제어되는 기능의 제어 권한을 웨어러블 디바이스에 제 공할 것을 결정할 수 있다. 예를 들어, 제2 기능 UI는 제2 가상 객체를 통해 표시되는 전자책의 화 면을 스크롤(scroll)하는 기능을 제어하는 UI일 수 있다. 제2 기능 UI와 관련된 스크롤 기능의 제어 권한 이 웨어러블 디바이스에 제공되는 경우, 웨어러블 디바이스는 회전식 베젤 링을 시계 방향 또는 반시 계 방향으로 회전하는 사용자 입력을 수신하고, 수신된 사용자 입력에 기초하여 증강 현실 디바이스에 의 해 표시되는 전자책 화면을 위아래 방향으로 스크롤할 수 있다. 사용자의 응시점(G)의 위치가 음악 애플리케이션의 실행 화면인 제1 가상 객체로 변경되는 경우, 프로세 서는 웨어러블 디바이스에 제공되는 제어 권한을 갖는 기능을 제1 기능 UI에 의해 실행 또는 제어되는 기능으로 변경할 수 있다. 제1 기능 UI는 제1 가상 객체를 통해 제공되는 음악의 볼륨을 제어하기 위한 스크롤 바 UI(scroll bar user interface)일 수 있다. 프로세서는 응시점(G)의 위치가 변 경됨에 따라 제1 기능 UI에 의해 실행 또는 제어되는 볼륨 컨트롤 기능에 관한 제어 권한을 웨어러블 디 바이스에 제공할 수 있다. 제1 기능 UI와 관련된 볼륨 컨트롤 기능의 제어 권한이 웨어러블 디바이 스에 제공되는 경우, 웨어러블 디바이스는 회전식 베젤 링을 시계 방향 또는 반시계 방향으로 회전하 는 사용자 입력에 기초하여 증강 현실 디바이스에 의해 출력되는 음악의 볼륨을 조절할 수 있다. 도 11은 본 개시의 일 실시예에 따른 웨어러블 디바이스의 구성 요소를 도시한 블록도이다. 웨어러블 디바이스는 사용자의 신체 일부에 착용하고, 착용 상태로 휴대하는 장치이다. 본 개시의 일 실시 예에서, 웨어러블 디바이스는 사용자의 손목에 착용하는 스마트 워치(smart watch)일 수 있다. 그러나, 이 에 한정되는 것은 아니고, 웨어러블 디바이스는 예를 들어, 링, 팔찌, 발찌, 목걸이, 콘택트 렌즈, 의류 일체형 장치(예컨대, 전자 의복), 신체 부착형 장치(예컨대, 스킨 패드(skin pad)), 또는 생체 이식형 장치(예: implantable circuit) 중 적어도 하나일 수도 있다. 도 11을 참조하면, 웨어러블 디바이스는 통신 인터페이스, 사용자 입력부, 프로세서, 메모 리, 및 디스플레이부를 포함할 수 있다. 통신 인터페이스, 사용자 입력부, 프로세서, 메모리, 및 디스플레이부는 각각 전기적 및/또는 물리적으로 서로 연결될 수 있다. 도 11에는 웨어러 블 디바이스의 동작을 설명하기 위한 필수적 구성 요소만이 도시되었고, 웨어러블 디바이스가 포함하 는 구성 요소가 도 11에 도시된 바와 같이 한정되는 것은 아니다. 본 개시의 일 실시예에서, 웨어러블 디바이스 는 통신 인터페이스, 사용자 입력부, 프로세서, 및 디스플레이부에 전원을 공급하는배터리를 더 포함할 수 있다. 예를 들어, 웨어러블 디바이스가 스마트 워치인 경우, 웨어러블 디바이스 는 사용자의 손목에 착용하기 위한 스트랩(260, 도 13 참조)를 더 포함할 수 있다. 통신 인터페이스는 증강 현실 디바이스와 근거리 무선 통신 방식을 통해 연결되고, 증강 현실 디바이 스와 데이터 통신을 수행하도록 구성된다. 본 개시의 일 실시예에서, 통신 인터페이스는 블루투스 통 신 방식을 통해 증강 현실 디바이스와 페어링(pairing)될 수 있다. 통신 인터페이스는 블루투스 통신 방식을 통해 증강 현실 디바이스와 데이터를 송수신할 수 있다. 그러나, 이에 한정되는 것은 아니고, 통신 인터페이스는 예를 들어, 와이파이(WiFi), WFD(Wi-Fi Direct) 통신부, 블루투스 통신부, BLE(Bluetooth Low Energy) 통신부, NFC(Near Field Communication unit), 지그비(Zigbee) 통신부, Ant+ 통신부, 또는 마이크 로 웨이브(μWave) 통신부 중 적어도 하나의 하드웨어 모듈로 구성되고, 상기 하드웨어 통신 모듈을 이용하여 증강 현실 디바이스와 데이터 통신을 수행할 수 있다. 사용자 입력부는 사용자 입력을 수신하도록 구성되는 하드웨어 장치이다. 본 개시의 일 실시예에서, 사용 자 입력부는 회전식 베젤 링(222, 도 13 참조), 버튼(224, 226, 도 13 참조), 및 터치스크린 패널 중 적어 도 하나를 포함할 수 있다. 회전식 베젤 링은 디스플레이부의 외곽의 둘레(베젤)를 따라 원형의 고리 형태로 형성될 수 있다. 본 개시의 일 실시예에서, 디스플레이부는 원형으로 형성될 수 있고, 회전식 베젤 링은 디스플레이부 의 외곽을 따라 형성된 로터리(Rotary)일 수 있다. 사용자 입력부는 회전식 베젤 링을 시계 방 향 또는 반시계 방향으로 회전시키는 사용자 입력을 수신할 수 있다. 버튼(224, 226)은 웨어러블 디바이스의 하우징의 외부로 돌출되는 방향으로 형성된 물리적 인터페이스로 구성된다. 본 개시의 일 실시예에서, 버튼(224, 226)은 홈 스크린으로 진입하기 위한 사용자 입력을 수신하는 홈 버튼 및 이전 작업 또는 이전 동작으로 이동하기 위한 사용자 입력을 수신하는 뒤로가기 버튼을 포함할 수 있다. 그러나, 이에 한정되는 것은 아니다. 회전식 베젤 링과 버튼(224, 226)의 구조에 대해서는 도 13에서 상세하게 설명하기로 한다. 터치스크린 패널은 사용자의 터치 입력을 감지하고, 감지된 터치 신호에 해당하는 터치 이벤트 값을 출력하도록 구성된다. 터치스크린 패널은 디스플레이부와 결합되어 터치스크린을 구성할 수 있다. 터치스크린은 정전 식, 감압식, 또는 압전식 등과 같은 다양한 유형의 터치 센서로 구현될 수 있다. 본 개시의 일 실시예에서, 사용자 입력부는 용두(crown)를 더 포함할 수 있다. 용두는 웨어러블 디바이스 의 외부 하우징의 일측면에 형성될 수 있다. 용두는 일종의 태엽으로, 시계 방향 또는 반시계 방향으로 회 전시키는 사용자 입력을 수신할 수 있다. 또한, 용두는 상기 사용자 입력을 수신함에 따라 시계 방향 또는 반시 계 방향으로 회전될 수 있다. 프로세서는 메모리에 저장된 프로그램의 하나 이상의 명령어들(instructions)을 실행할 수 있다. 프 로세서는 산술, 로직 및 입출력 연산과 시그널 프로세싱을 수행하는 하드웨어 구성 요소로 구성될 수 있다. 프로세서는 예를 들어, 중앙 처리 장치(Central Processing Unit), 마이크로 프로세서 (microprocessor), 그래픽 프로세서(Graphic Processing Unit), ASICs(Application Specific Integrated Circuits), DSPs(Digital Signal Processors), DSPDs(Digital Signal Processing Devices), PLDs(Programmable Logic Devices), 및 FPGAs(Field Programmable Gate Arrays) 중 적어도 하나로 구성될 수 있으나, 이에 한정되는 것은 아니다. 도 11에는 프로세서가 하나의 엘리먼트로 도시되었으나, 이에 한정되는 것은 아니다. 본 개시의 일 실시예 에서, 프로세서는 하나 이상의 복수 개의 엘리먼트들로 구성될 수 있다. 메모리는 예를 들어, 플래시 메모리 타입(flash memory type), 하드디스크 타입(hard disk type), 멀티미 디어 카드 마이크로 타입(multimedia card micro type), 카드 타입의 메모리(예를 들어 SD 또는 XD 메모리 등), 램(RAM, Random Access Memory) SRAM(Static Random Access Memory), 롬(ROM, Read-Only Memory), EEPROM(Electrically Erasable Programmable Read-Only Memory), PROM(Programmable Read-Only Memory), 또는 광 디스크 중 적어도 하나의 타입의 저장매체로 구성될 수 있다. 메모리에는 웨어러블 디바이스가 증강 현실 디바이스로부터 기능의 제어 권한을 획득하고, 사용 자 입력에 기초하여 제어 권한에 따른 기능을 실행 또는 제어하는 동작들과 관련된 명령어들(instructions)이 저장될 수 있다. 본 개시의 일 실시예에서, 메모리에는 프로세서가 판독할 수 있는 명령어들, 알고리즘(algorithm), 데이터 구조, 프로그램 코드(program code), 및 애플리케이션 프로그램(application program) 중 적어도 하나가 저장될 수 있다. 메모리에 저장되는 명령어들, 알고리즘, 데이터 구조, 및 프로그램 코 드는 예를 들어, C, C++, 자바(Java), 어셈블러(assembler) 등과 같은 프로그래밍 또는 스크립팅 언어로 구현 될 수 있다. 이하의 실시예에서, 프로세서는 메모리에 저장된 명령어들 또는 프로그램 코드들을 실행함으로써 구 현될 수 있다. 프로세서는 증강 현실 디바이스에 의해 실행되는 애플리케이션을 통해 표시되는 가상 객체와 관련된 기능을 실행 또는 제어하기 위한 제어 권한을 획득할 수 있다. 본 개시의 일 실시예에서, 프로세서는 통신 인터페이스를 통해 증강 현실 디바이스로부터 기능의 제어 권한을 획득할 수 있다. 프로세서는 기능의 제어 권한 뿐만 아니라, 가상 객체의 타입, 기능의 특성, 및 기능과 관련된 데이터 값 중 적어도 하나를 증강 현실 디바이스로부터 획득할 수 있다. 프로세서는 가상 객체의 타입, 기능의 특성, 및 기능과 관련된 데이터 값 중 적어도 하나에 기초하여, 획 득된 제어 권한에 따라 기능을 제어하기 위한 조작 방식을 결정할 수 있다. 본 개시의 일 실시예에서, 프로세서 는 기 설정된 매핑 관계에 따라 증강 현실 디바이스로부터 획득된 제어 권한을 특정 조작 방식에 매 핑할 수 있다. 프로세서는 기 설정된 매핑 관계에 기초하여 가상 객체의 타입, 기능의 특성, 및 기능과 관 련된 데이터 값과 매핑되는 조작 방식을 결정할 수 있다. 프로세서가 기능의 제어 권한에 매핑되는 조작 방식을 결정하는 구체적인 실시예에 대해서는 도 13 내지 도 16에서 상세하게 설명하기로 한다. 프로세서는 결정된 조작 방식에 따라 사용자 입력부를 통해 수신된 사용자 입력에 기초하여, 기능과 관련된 데이터 값을 변경할 수 있다. 본 개시의 일 실시예에서, 프로세서는 회전식 베젤 링, 버튼 (224, 226), 또는 터치스크린을 통해 수신된 사용자 입력에 기초하여 데이터 값을 변경할 수 있다. 예를 들어, 프로세서는 회전식 베젤 링을 시계 방향 또는 반시계 방향으로 회전하는 사용자 입력에 기초하여, 동 영상의 플레이 타임을 변경하거나, 웹 브라우저의 스크롤을 위아래 방향으로 조절할 수 있다. 다른 예를 들어, 프로세서는 터치스크린을 통해 수신되는 사용자의 터치 입력에 기초하여 특정 사진 또는 아이콘을 선택할 수 있다. 프로세서는 통신 인터페이스를 제어함으로써, 변경된 데이터 값을 증강 현실 디바이스에 전송할 수 있다. 디스플레이부는 제어 권한의 획득 여부 및 제어 권한과 관련된 기능에 관한 정보를 표시하도록 구성된다. 본 개시의 일 실시예에서, 디스플레이부는 원형으로 형성될 수 있으나, 이에 한정되는 것은 아니다. 디스 플레이부는 디스플레이 패널 및 디스플레이 패널을 제어하는 컨트롤러를 포함할 수 있다. 디스플레이 패 널은 예를 들어, LCD(Liquid Crystal Display), OLED(Organic Light Emitting Diodes) 디스플레이, AM- OLED(Active-Matrix Organic Light-Emitting Diode), PDP(Plasma Display Panel) 등과 같은 다양한 형태의 디 스플레이로 구현될 수 있다. 본 개시의 일 실시예에서, 디스플레이부는 사용자 입력부의 터치스크린 패널과 결합되어 터치스크린 으로 제공될 수 있다. 예를 들어, 터치 스크린은 디스플레이 패널과 터치스크린 패널이 적층 구조로 결합된 일 체형의 모듈을 포함할 수 있다. 디스플레이부는 프로세서의 제어에 의해, 웨어러블 디바이스에 설치된 복수의 애플리케이션의 실행 결과를 디스플레이할 수 있다. 본 개시의 일 실시예에서, 디스플레이부에는 웨어러블 디바이스 에 설치된 복수의 애플리케이션의 아이콘을 포함하는 애플리케이션 목록이 디스플레이될 수 있다. 본 개시의 일 실시예에서, 디스플레이부는 프로세서의 제어에 의해, 증강 현실 디바이스로부터 기능의 제어 권한을 획득하였는지 여부를 사용자에게 알리는 알림 메시지를 표시할 수 있다. 도 12는 본 개시의 일 실시예에 따른 증강 현실 디바이스 및 웨어러블 디바이스의 동작 방법을 도시 한 흐름도이다. 단계 S1210에서, 증강 현실 디바이스는 웨어러블 디바이스 및 웨어러블 디바이스를 착용한 사용 자의 손을 인식한다. 본 개시의 일 실시예에서, 증강 현실 디바이스는 가상 객체와 오버레이되는 웨어러블 디바이스 및 웨어러블 디바이스를 착용하고 있는 사용자의 손을 인식할 수 있다. 본 개시의 일 실시예에서, 증강 현실 디바이스는 인공지능 모델 또는 공지의 이미지 프로세싱 기술을 이용하여 웨어러블 디 바이스 및 사용자의 손을 인식할 수 있다. 증강 현실 디바이스가 웨어러블 디바이스 및 사용자 의 손을 인식하는 구체적인 방법은 도 3의 단계 S310과 동일하므로, 중복되는 설명은 생략한다. 단계 S1220에서, 증강 현실 디바이스는 인식된 웨어러블 디바이스를 제어 권한 제공 대상으로 인식한 다. 본 개시의 일 실시예에서, 증강 현실 디바이스는 가상 객체에 포함되는 적어도 하나의 기능 UI에 의해 실행 또는 제어되는 기능에 관한 제어 권한을 제공할 대상 디바이스로서, 웨어러블 디바이스에 인식할 수 있다. 단계 S1230에서, 증강 현실 디바이스는 웨어러블 디바이스에 제어 권한을 제어할 지 여부를 판단한다. 단계 S1230은 도 3에서 도시되고, 설명된 단계 S320과 동일하므로, 중복되는 설명은 생략한다. 웨어 러블 디바이스에 기능의 제어 권한을 제공하지 않기로 결정한 경우(NO), 증강 현실 디바이스는 단계 S1210로 돌아가서 웨어러블 디바이스를 인식하는 동작을 다시 수행할 수 있다. 웨어러블 디바이스에 기능의 제어 권한을 제공하기로 결정한 경우(YES), 증강 현실 디바이스는 애플 리케이션에 의해 제공되는 복수의 기능 중 가상 객체와 관련된 기능을 선택한다(단계 S1240). 본 개시의 일 실 시예에서, 증강 현실 디바이스는 가상 객체에 포함되는 복수의 기능 UI(User Interface) 중 웨어러블 디바 이스를 착용하고 있는 사용자의 손에 의해 오버레이되는 기능 UI를 식별하고, 식별된 기능 UI에 의해 실행 또는 제어되는 기능에 관한 제어 권한을 웨어러블 디바이스에 제공할 것을 결정할 수 있다. 단계 S1240은 도 7의 단계 S710 및 S720, 도 8a 및 도 8b에 도시되고, 설명된 것과 동일하므로, 중복되는 설명은 생략한다. 단계 S1250에서, 증강 현실 디바이스는 기능의 제어 권한, 가상 객체의 특성 정보, 및 기능과 관련된 데이 터 값 중 적어도 하나를 전송한다. 본 개시의 일 실시예에서, '가상 객체의 특성 정보'는 가상 객체에 포함되는 기능 UI의 타입(type)에 관한 정보를 포함할 수 있다. 기능 UI의 타입은 예를 들어, 슬라이더(slider), 스크롤 바(scroll bar), 스피너(spinner), 버튼, 휠, 또는 드롭다운(drop down)을 포함할 수 있으나, 이에 한정되는 것은 아니다. '기능에 관한 데이터 값'은 예를 들어, 플레이 시간, 스크롤 바 위치, 또는 선택된 아이템 값 등 과 같은 증강 현실 디바이스에 의해 제공되는 기능의 현재 데이터 값일 수 있으나, 이에 한정되지 않는다. 단계 S1260에서, 웨어러블 디바이스는 제어 권한을 조작 방식과 매핑하고, 데이터 값을 연동한다. 본 개시 의 일 실시예에서, 웨어러블 디바이스는 기 설정된 매핑 관계에 따라 증강 현실 디바이스로부터 획득 된 제어 권한을 특정 조작 방식에 매핑할 수 있다. 웨어러블 디바이스는 기 설정된 매핑 관계에 기초하여 가상 객체의 타입, 기능의 특성, 및 기능과 관련된 데이터 값과 매핑되는 조작 방식을 결정할 수 있다. 웨어러 블 디바이스는 증강 현실 디바이스로부터 획득한 데이터 값을 사용자 입력부(220, 도 11 참조)에 의 해 변경 또는 조절되는 데이터 값과 실시간으로 연동할 수 있다. 예를 들어, 웨어러블 디바이스는 기능의 제어 권한을 회전식 베젤 링(222, 도 13 참조)을 시계 방향 또는 반시계 방향으로 회전하는 조작 방식, 버튼 (224, 226, 도 13 참조)을 누르는 조작 방식, 또는 터치스크린을 터치, 스와이프(swipe), 또는 스크롤하는 조작 방식으로 매핑할 수 있다. 단계 S1270에서, 웨어러블 디바이스는 조작 방식에 따른 사용자 입력에 기초하여 데이터 값을 변경한다. 본 개시의 일 실시예에서, 웨어러블 디바이스는 회전식 베젤 링, 버튼(224, 226), 또는 터치스크린 중 결정된 조작 방식에 따라 사용자로부터 수신된 입력에 기초하여 데이터 값을 변경할 수 있다. 웨어러블 디바 이스가 조작 방식에 따라 사용자 입력에 기초하여 데이터 값을 변경하는 구체적인 실시예는 도 18 내지 도 21에서 상세하게 설명하기로 한다. 단계 S1280에서, 웨어러블 디바이스는 변경된 데이터 값을 증강 현실 디바이스에 전송한다. 본 개시 의 일 실시예에서, 웨어러블 디바이스는 블루투스 통신 방식을 통해 증강 현실 디바이스와 페어링되 고, 블루투스 통신 방식을 통해 증강 현실 디바이스에 데이터 값을 전송할 수 있다. 그러나, 이에 한정되 는 것은 아니고, 웨어러블 디바이스는 와이파이(WiFi), WFD(Wi-Fi Direct), BLE(Bluetooth Low Energy), NFC(Near Field Communication unit), 지그비(Zigbee), Ant+, 또는 마이크로 웨이브(μWave) 중 적어도 하나의 근거리 무선 통신 네트워크를 이용하여, 증강 현실 디바이스에 변경된 데이터 값을 전송할 수 있다. 본 개시의 일 실시예에서, 웨어러블 디바이스는 변경된 데이터 값 뿐만 아니라, 데이터 값이 변경된 기능 의 식별 정보를 증강 현실 디바이스에 전송할 수도 있다. 단계 S1290에서, 증강 현실 디바이스는 수신된 데이터 값을 이용하여 기능의 데이터 값을 업데이트 (update) 한다. 증강 현실 디바이스는 웨어러블 디바이스에 의해 변경된 기능을 식별하고, 식별된 기능에 관한 데이터 값을 웨어러블 디바이스로부터 수신한 데이터 값에 기초하여 업데이트할 수 있다. 도 13는 본 개시의 일 실시예에 따른 웨어러블 디바이스가 증강 현실 디바이스로부터 획득한 제어 권 한에 기초하여 기능을 제어하기 위한 조작 방식을 설명하기 위한 도면이다. 도 13을 참조하면, 웨어러블 디바이스는 회전식 베젤 링, 버튼(224, 226), 디스플레이부, 및 스 트랩을 포함할 수 있다. 회전식 베젤 링은 웨어러블 디바이스의 몸체부의 일측부에 형성될 수 있다. 본 개시의 일 실시예에서, 디 스플레이부는 원형으로 형성되고, 회전식 베젤 링은 원형 디스플레이부의 외곽의 둘레를 따라 원형의 고리 형태로 형성될 수 있다. 본 개시의 일 실시예에서, 회전식 베젤 링은 원형 디스플레이부(25 0)의 외곽을 따라 형성된 로터리(Rotary)일 수 있다. 회전식 베젤 링은 하드웨어 모듈로 구현될 수 있다. 본 개시의 일 실시예에서, 회전식 베젤 링은 일정 간격으로 회전하는 동작을 멈출 수 있는 멈춤쇠(deten t)를 포함할 수 있다. 회전식 베젤 링은 시계 방향 또는 반시계 방향으로 회전시키는 사용자 입력을 수신 할 수 있다. 회전식 베젤 링은 사용자 입력을 수신함에 따라 시계 방향 또는 반시계 방향으로 회전될 수 있다. 사용자 입력에 의해 회전식 베젤 링이 회전되는 경우, 웨어러블 디바이스는 곡선 경로를 따라 회전식 베젤 링의 회전 방향과 회전 정도를 나타내는 회전 스크롤 UI를 디스플레이부 상에 디 스플레이할 수 있다. 회전식 베젤 링이 하드웨어 장치로 한정되는 것은 아니다. 본 개시의 일 실시예에서, 회전식 베젤 링(22 2)은 디스플레이부와 결합되어, 그래픽 인터페이스(Graphic User Interface, GUI)로 구현될 수도 있다. 이 경우, 회전식 베젤 링은 디스플레이부를 통해 디스플레이되는 그래픽 인터페이스를 터치하고, 회 전시키는 사용자 입력을 수신할 수 있다. 버튼(224, 226)은 웨어러블 디바이스의 하우징의 외부로 돌출되는 방향으로 형성된 물리적 인터페이스로 구성된다. 본 개시의 일 실시예에서, 버튼(224, 226)은 홈 스크린으로 진입하기 위한 사용자 입력을 수신하는 홈 버튼 및 이전 작업 또는 이전 동작으로 이동하기 위한 사용자 입력을 수신하는 뒤로가기 버튼을 포함할 수 있다. 그러나, 이에 한정되는 것은 아니다. 디스플레이부는 증강 현실 디바이스로부터 획득한 제어 기능의 명칭 및 제어 기능의 상태 를 나타내는 UI(User Interface)를 디스플레이할 수 있다. 본 개시의 일 실시예에서, 디스플레이부 는 터치 패널을 포함하는 터치스크린으로 구현될 수 있다. 디스플레이부는 사용자의 터치 입력을 수신하고, 수신된 터치 입력에 대응되는 동작을 수행할 수 있다. 본 개시의 일 실시예에서, 디스플레이부는 좌우 방향으로 스와이프(swipe)하는 사용자의 스와이프 입력을 수신할 수 있다. 스와이프 입력이 수신되면, 웨어러블 디바이스는 디스플레이부 상에 디스플레이되는 제어 기능을 변경하고, 변경된 제어 기능의 명칭 및 상태를 디스플레이할 수 있다. 도 13에 도시된 실시예에서, 좌방향으로 스와이프하는 입력이 수신되는 경우, 웨어러블 디바이스는 현재 실행 또는 제어하는 기능을 제 1 제어 기능에서 제2 제어 기능으로 스위칭하고, 스위칭된 제2 제어 기능의 명칭 및 제2 제어 기능의 상 태를 디스플레이부 상에 디스플레이할 수 있다. 마찬가지로, 우방향으로 스와이프하는 입력이 수신되는 경 우, 웨어러블 디바이스는 현재 실행 또는 제어하는 기능을 제1 제어 기능에서 제3 제어 기능으로 스 위칭하고, 스위칭된 제3 제어 기능의 명칭 및 제3 제어 기능의 상태를 디스플레이부 상에 디스플레이할 수 있다. 웨어러블 디바이스는 기 설정된 매핑 관계에 기초하여, 기능 UI의 타입, 기능의 특성, 및 기능과 관련된 데이터 값과 매핑되는 조작 방식을 결정할 수 있다. 본 개시의 일 실시예에서, 웨어러블 디바이스는 애플 리케이션 별로 제공되는 기능 UI와 조작 방식 간의 기 설정된 매핑 관계에 기초하여, 웨어러블 디바이스의 조작 방식을 결정할 수 있다. 기 설정된 매핑 관계의 예시는 하기의 표 1을 참조한다. 표 1 구분 애플리케이션 1 탐색 1 동영상 스틸 이미지음악 프로바이더 애 플리케이션회전식 베젤 링탐색(빠른)플레이 시간 조 절확대 시 화면 이동 상하/좌우플레이 시간 조 절- 디스플레이부 터치-선택 스와이프-컨텐 츠 탐색(느린)정지/실행 터치-스와이프 확대/축소정지/실행 터치 패드/커 서 형태로 제 어 권한 획득 제1 버튼 초기 화면 초기 화면 초기 화면 초기 화면 - 제2 버튼 이전 이전 이전 이전 - 도 14a는 본 개시의 일 실시예에 따른 웨어러블 디바이스가 증강 현실 디바이스로부터 획득한 제어 권한에 따라 기능 UI를 조작 방식과 매핑하는 동작을 도시한 도면이다. 도 14a를 참조하면, 웨어러블 디바이스는 증강 현실 디바이스로부터 획득한 제어 권한과 관련된 기능 UI를 조작 방식과 매핑할 수 있다. 본 개시의 일 실시예에서, 웨어러블 디바이스는 기능 UI의 타입, 기능 의 특성, 및 기능과 관련된 데이터 값 중 적어도 하나에 기초하여, 기능 UI에 매핑되는 조작 방식을 결정할 수 있다. 도 14a에 도시된 실시예에서, 증강 현실 디바이스에 표시되는 제1 기능 UI는 슬라이더 (slider) 타입이고, 기능과 관련된 데이터 값은 플레이 시간이므로(예를 들어, 2:30), 웨어러블 디바이스 는 회전식 베젤 링을 조작 방식으로 결정할 수 있다. 웨어러블 디바이스는 증강 현실 디바이스 로부터 획득한 기능의 특성 및 기능과 관련된 데이터 값에 기초하여, 디스플레이부 상에 제어 중인 기능의 명칭 및 현재 데이터 값(예를 들어, 2:30)을 디스플레이할 수 있다. 도 14b는 본 개시의 일 실시예에 따른 웨어러블 디바이스가 증강 현실 디바이스로부터 획득한 제어 권한에 따라 기능 UI를 조작 방식과 매핑하는 동작을 도시한 도면이다. 도 14b에 도시된 실시예는, 제2 기능 UI의 타입을 제외하고는 도 14a에 도시된 실시예와 동일하므로, 중 복되는 설명은 생략한다. 도 14b를 참조하면, 증강 현실 디바이스에 표시되는 제2 기능 UI는 스크롤 바(scroll bar) 타입이고, 기능과 관련된 데이터 값은 현재 스크롤 바 위치이다. 웨어러블 디바이스는 제2 기능 UI의 타입 및 기능의 특성, 및 기능과 관련된 데이터 값 중 적어도 하나에 기초하여, 제2 기능 UI에 매핑되는 조작 방식을 회전식 베젤 링으로 결정할 수 있다. 웨어러블 디바이스는 증강 현 실 디바이스로부터 획득한 기능의 특성 및 기능과 관련된 데이터 값에 기초하여, 디스플레이부 상에 제어 중인 기능의 명칭 및 현재 스크롤 위치를 나타내는 회전 스크롤 UI를 디스플레이할 수 있다. 도 14c는 본 개시의 일 실시예에 따른 웨어러블 디바이스가 증강 현실 디바이스로부터 획득한 제어 권한에 따라 기능 UI를 조작 방식과 매핑하는 동작을 도시한 도면이다. 도 14c에 도시된 실시예는, 제3 기능 UI의 타입을 제외하고는 도 14a에 도시된 실시예와 동일하므로, 중 복되는 설명은 생략한다. 도 14c를 참조하면, 증강 현실 디바이스에 표시되는 제3 기능 UI는 스피너 (spinner) 타입이고, 기능과 관련된 데이터 값(예를 들어, 2)이다. 웨어러블 디바이스는 제3 기능 UI의 타입 및 기능의 특성, 및 기능과 관련된 데이터 값 중 적어도 하나에 기초하여, 제3 기능 UI 에 매핑되는 조작 방식을 회전식 베젤 링으로 결정할 수 있다. 웨어러블 디바이스는 디스플레이부 상에 현재 데이터 값(예를 들어, 2)을 디스플레이부 상에 디스플레이할 수 있다. 도 14a 내지 도 14c는 웨어러블 디바이스의 회전식 베젤 링으로 매핑되는 기능 UI들(1410 내지 143 0)을 도시한다. 회전식 베젤 링으로 매핑되는 기능 UI들(1410 내지 1430)은 예를 들어, 동영상 애플리케이 션(동영상 플레이 또는 동영상 스트리밍)의 플레이 시간 UI, 웹 브라우저 애플리케이션의 스크롤 바 UI, 또는 캘린더 애플리케이션의 년도 스핀 UI(years spinner) 등일 수 있다. 그러나, 이에 한정되는 것은 아니다. 도 15a는 본 개시의 일 실시예에 따른 웨어러블 디바이스가 증강 현실 디바이스로부터 획득한 제어 권한에 따라 기능 UI를 조작 방식과 매핑하는 동작을 도시한 도면이다. 도 15a를 참조하면, 웨어러블 디바이스는 증강 현실 디바이스로부터 획득한 제어 권한과 관련된 기능 UI를 조작 방식과 매핑할 수 있다. 본 개시의 일 실시예에서, 웨어러블 디바이스는 기능 UI의 타입, 기능 의 특성, 및 기능과 관련된 데이터 값 중 적어도 하나에 기초하여, 기능 UI에 매핑되는 조작 방식을 결정할 수있다. 도 15a에 도시된 실시예에서, 증강 현실 디바이스에 표시되는 제1 기능 UI는 버튼 타입 UI이 고, 웨어러블 디바이스는 디스플레이부 상에 버튼 UI를 디스플레이할 수 있다. 디스플레이부는 터치스크린으로 구현되고, 웨어러블 디바이스는 터치스크린을 통해 버튼 UI를 터치하는 사용자의 터치 입 력을 수신할 수 있다. 도 15b는 본 개시의 일 실시예에 따른 웨어러블 디바이스가 증강 현실 디바이스로부터 획득한 제어 권한에 따라 기능 UI를 조작 방식과 매핑하는 동작을 도시한 도면이다. 도 15b에 도시된 실시예는, 제2 기능 UI(1520, 1522)의 타입을 제외하고는 도 15a에 도시된 실시예와 동일하므 로, 중복되는 설명은 생략한다. 도 15b를 참조하면, 증강 현실 디바이스에 표시되는 제2 기능 UI(1520, 1522)는 드롭 다운 UI 및 콤보 박스 UI를 포함할 수 있다. 웨어러블 디바이스는 제2 기능 UI(1520, 1522)의 타입 및 기능의 특성, 및 기능과 관련된 데이터 값 중 적어도 하나에 기초하여, 제2 기능 UI(1520, 1522)에 매핑되는 조작 방식을 터치스크린을 통한 터치 입력으로 결정할 수 있다. 웨어러블 디바이스 의 디스플레이부는 터치스크린으로 구현되고, 터치스크린을 통해 드롭 다운 UI를 터치하는 사용자의 터치 입력을 수신하는 경우, 아이템을 선택하도록 하는 콤보 박스 UI를 디스플레이할 수 있다. 웨어러블 디바이 스는 터치스크린을 통해 특정 아이템을 선택하는 사용자의 터치 입력을 수신할 수 있다. 도 15a 및 도 15b는 웨어러블 디바이스의 터치스크린을 통해 수신되는 터치 입력에 매핑되는 기능 UI들 (1510, 1520, 1522)을 도시한다. 터치스크린을 통한 터치 입력으로 매핑되는 기능 UI들(1510, 1520, 1522)은 예를 들어, 동영상 애플리케이션(동영상 플레이 또는 동영상 스트리밍)의 플레이/정지(play/pause), 웹 브라우 저 애플리케이션의 다음 페이지(next page), 캘린더 애플리케이션의 신규 스케줄 추가(Add New Schedule)일 수 있다. 그러나, 이에 한정되는 것은 아니다. 도 14a 내지 도 14c에 도시된 회전식 베젤 링 조작과 도 15a 및 도 15b에 도시된 터치스크린 조작이 결합 된 방식으로 제어되는 기능 UI로는 예를 들어, 동영상 애플리케이션(동영상 플레이 또는 동영상 스트리밍)의 자 막 UI, 플레이 속도 설정 UI, 또는 웹 브라우저 애플리케이션의 즐겨찾기 UI 등이 있을 수 있다. 그러나, 이에 한정되는 것은 아니다. 도 16은 본 개시의 일 실시예에 따른 웨어러블 디바이스가 증강 현실 디바이스로부터 획득한 제어 권 한에 따라 기능 UI를 조작 방식과 매핑하는 동작을 도시한 도면이다. 도 16을 참조하면, 증강 현실 디바이스는 API(Application Programmable Interface)를 제공하지 않는 애 플리케이션을 실행할 수 있다. 증강 현실 디바이스는 예를 들어, 써드파티 애플리케이션(third party application)을 실행함으로써, 가상 객체를 표시할 수 있다. 가상 객체는 복수의 기능 UI(1610, 1612, 1614) 및 애플리케이션의 실행 화면을 포함할 수 있다. 애플리케이션이 API를 제공하지 않기 때문 에, 증강 현실 디바이스는 복수의 기능 UI(1610, 1612, 1614) 각각에 관한 제어 권한을 개별적으로 웨어러 블 디바이스에 제공할 수 없다. 이 경우, 증강 현실 디바이스는 복수의 기능 UI(1610, 1612, 1614) 전체에 관한 제어 권한을 웨어러블 디바이스에 제공할 수 있다. 웨어러블 디바이스는 증강 현실 디바이스로부터 획득한 제어 권한을 특정 조작 방식에 매핑할 수 있 다. 본 개시의 일 실시예에서, 웨어러블 디바이스는 터치스크린으로 구성된 디스플레이부를 터치 패 드로 활용하여, 터치 패드 상의 특정 영역을 터치하는 사용자의 터치 입력을 수신할 수 있다. 웨어러블 디바이 스는 수신된 터치 입력의 위치 좌표값을 증강 현실 디바이스를 통해 표시되는 가상 객체의 특 정 영역 상의 커서와 매핑할 수 있다. 웨어러블 디바이스는 사용자의 터치 입력에 따라 가상 객체 상의 특정 위치 상에 매핑된 커서를 이용하여 복수의 기능 UI(1610, 1612, 1614)를 제어할 수 있다. 도 17a는 본 개시의 일 실시예에 따른 증강 현실 디바이스가 외부 디바이스를 인식하고, 인식된 외부 디바 이스에 제어 권한의 제공을 결정하는 동작을 도시한 도면이다. 도 17a를 참조하면, 증강 현실 디바이스는 웨이브가이드를 통해 표시되는 가상 객체와 오버레 이되는 외부 디바이스를 인식할 수 있다. 외부 디바이스는 예를 들어, 모바일 디바이스, 스마트 폰(smart phone), 노트북 컴퓨터(laptop computer), 데스크 탑, 태블릿 PC, 전자책 단말기, 디지털 방송용 단말기, PDA(Personal Digital Assistants), PMP(Portable Multimedia Player), 네비게이션, MP3 플레이어, 또는 캠코더 중 어느 하나일 수 있으나, 이에 한정되는 것은 아니다. 도 17a에 도시된 실시예에서, 외부 디바이스는 모바 일 디바이스(300a)일 수 있다. 증강 현실 디바이스는 인식된 모바일 디바이스(300a)에 기능에 관한 제어 권한을 제공하고, 모바일 디바이 스(300a)에 의해 제어될 수 있다. 본 개시의 일 실시예에서, 증강 현실 디바이스는 제어 권한에 기초하여 모바일 디바이스(300a)에 의해 변경된 데이터 값을 수신하고, 수신된 데이터 값을 이용하여 기능에 관한 데이터 값을 업데이트할 수 있다. 도 17b는 본 개시의 일 실시예에 따른 증강 현실 디바이스가 외부 디바이스를 인식하고, 인식된 외부 디바 이스에 제어 권한의 제공을 결정하는 동작을 도시한 도면이다. 도 17b에 도시된 실시예는 외부 디바이스의 종류를 제외하고는 도 17a에 도시된 실시예와 동일하므로, 중복되는 설명은 생략한다. 도 17b를 참조하면, 증강 현실 디바이스는 웨이브가이드를 통해 표시되는 가상 객 체와 오버레이되는 컨트롤러(300b)를 인식할 수 있다. 컨트롤러(300b)는 사용자의 손에 의해 파지되고, 손의 조작에 따라 이동됨으로써 3차원 위치 좌표값 정보를 획득할 수 있다. 본 개시의 일 실시예에서, 컨트롤러 (300b)는 3차원 위치 좌표값을 획득하는 GPS 센서, IMU(Inertial Measurement Unit) 센서 등을 포함할 수 있다. 증강 현실 디바이스는 인식된 컨트롤러(300b)에 기능에 관한 제어 권한을 제공하고, 컨트롤러(300b)에 의 해 제어될 수 있다. 본 개시의 일 실시예에서, 증강 현실 디바이스는 컨트롤러(300b)의 3차원 위치 좌표값 을 실시간으로 획득하고, 획득된 컨트롤러(300b)의 3차원 위치 좌표값에 기초하여 가상 객체에 포함되는 기능 UI를 실행 또는 제어할 수 있다. 도 18은 본 개시의 일 실시예에 따른 사용자가 증강 현실 디바이스 및 웨어러블 디바이스를 이용하여 기능을 실행 또는 제어하는 동작을 도시한 도면이다. 도 18을 참조하면, 사용자는 증강 현실 디바이스를 통해 표시되는 기능 UI를 웨어러블 디바이스 에 제어 권한을 제공할 기능 UI로 선택한다(동작 ①). 증강 현실 디바이스는 실행 중인 애플리케이션 을 통해 웨이브가이드에 가상 객체를 투사할 수 있다. 도 18에 도시된 실시예에서, 가상 객체(180 0)는 동영상을 플레이하거나 스트리밍하는 동영상 애플리케이션이고, 동영상의 플레이 타임을 제어하는 슬라이 더 형태의 기능 UI를 포함할 수 있다. 증강 현실 디바이스는 가상 객체 상에 오버레이되는 웨 어러블 디바이스를 인식할 수 있다. 증강 현실 디바이스는 웨어러블 디바이스를 착용하고 있는 사용자의 손을 인식할 수 있다. 본 개시의 일 실시예에서, 증강 현실 디바이스는 인식된 사용자의 손에 의 해 오버레이되는 기능 UI를 식별할 수 있다. 증강 현실 디바이스는 식별된 기능 UI에 의해 실 행 또는 제어되는 기능(예를 들어, 동영상의 플레이 타임 제어 기능)의 제어 권한을 웨어러블 디바이스에 제공할 것을 결정할 수 있다. 웨어러블 디바이스는 증강 현실 디바이스로부터 기능 UI의 제어 권한을 획득하고, 플레이 타임 기능을 제어한다(동작 ②). 본 개시의 일 실시예에서, 웨어러블 디바이스는 증강 현실 디바이스로부 터 기능 UI와 관련된 기능의 제어 권한 뿐만 아니라, 기능 UI의 타입, 플레이 타임 제어 기능의 특 성, 및 플레이 타임 제어 기능과 관련된 데이터 값(예를 들어, 동영상 플레이 타임)을 획득하고, 획득된 기능 UI의 타입, 기능의 특성, 및 데이터 값에 기초하여 조작 방식을 결정할 수 있다. 도 18에 도시된 실시예 에서, 웨어러블 디바이스는 회전식 베젤 링(222, 도 13 참조)을 조작 방식으로 결정할 수 있다. 웨어러블 디바이스는 회전식 베젤 링을 시계 방향 또는 반시계 방향으로 회전시키는 사용자 입력을 수신하고, 수신된 사용자 입력에 기초하여 동영상의 플레이 타임을 변경할 수 있다. 사용자는 증강 현실 디바이스를 통해 일시 정지 기능을 실행한다(동작 ③). 본 개시의 일 실시예에서, 증 강 현실 디바이스는 동영상 플레이를 일시 정지하기 위한 일시 정지 UI를 표시하고, 일시 정지 UI를 선택하는 사용자 입력을 수신할 수 있다. 증강 현실 디바이스는 수신된 사용자 입력에 기초하 여, 동영상 플레이를 일시 정지할 수 있다. 사용자는 증강 현실 디바이스를 통해 스크린 캡쳐 기능을 실행한다(동작 ④). 본 개시의 일 실시예에서, 증강 현실 디바이스는 현재 실행 중인 애플리케이션의 화면을 캡쳐하기 위한 스크린 캡쳐 UI를 표시하고, 스크린 캡쳐 UI를 선택하는 사용자 입력을 수신할 수 있다. 증강 현실 디바이스는 수신된 사 용자 입력에 기초하여, 실행 중인 화면을 캡쳐하여 이미지로 저장할 수 있다. 사용자는 웨어러블 디바이스에 대한 스와이프 입력(swipe)을 통해 제어 기능을 변경한다(동작 ⑤). 웨어러 블 디바이스는 터치스크린을 좌우로 스와이프하는 사용자의 스와이프 입력을 수신하고, 수신된 스와이프 입력에 기초하여 제어 기능을 스위칭할 수 있다. 도 18에 도시된 실시예에서, 웨어러블 디바이스는 스와이 프 입력이 수신됨에 따라 동영상 플레이 타임 제어 기능을 동영상 리스트 기능으로 스위칭할 수 있다. 사용자는 웨어러블 디바이스를 이용하여 동영상 리스트를 선택한다(동작 ⑥). 웨어러블 디바이스는 동영상 리스트 기능과 매핑되는 조작 방식을 회전식 베젤 링(222, 도 13 참조)으로 결정하고, 회전식 베젤 링 을 시계 방향 또는 반시계 방향으로 회전시키는 사용자 입력을 수신할 수 있다. 웨어러블 디바이스는 사용자 입력에 기초하여, 동영상 리스트를 선택할 수 있다. 도 18에 도시된 실시예에서, 증강 현실 디바이스 는 복수의 동영상(video 20, video 21, video 22, ...)의 리스트를 포함하는 동영상 리스트 UI를 표시하고, 웨어러블 디바이스의 회전식 베젤 링을 회전시키는 사용자 입력에 기초하여 특정 동영상 리스트를 선택할 수 있다. 사용자는 작업 완료 후 웨어러블 디바이스를 통해 홈 화면으로 복귀한다(동작 ⑦). 웨어러블 디바이 스는 홈 버튼을 누르는 사용자 입력을 수신할 수 있다. 홈 버튼을 누르는 사용자 입력이 수신됨 에 따라, 증강 현실 디바이스는 동영상 리스트 UI를 표시하다가 홈 화면으로 전환하여, 홈 화 면을 표시할 수 있다. 일반적으로 사용자는 가상 객체 상의 기능 UI를 정확하게 선택하여 동영상의 플레이 타임을 세밀하 게 조작하기 어렵다. 도 18에 도시된 실시예에서, 증강 현실 디바이스는 동영상 플레이 타임 기능에 관한 제어 권한을 웨어러블 디바이스에 제공하고, 웨어러블 디바이스을 통해 동영상의 플레이 타임을 제어 하게 함으로써, 사용자의 조작 편의성을 향상시킬 수 있다. 또한, 본 개시의 일 실시예는 상대적으로 제어가 쉬 운 일시 정지 기능 또는 스크린 캡쳐 기능은 증강 현실 디바이스의 웨이브가이드를 통해 표시되는 가상 객 체인 일시 정지 UI 또는 스크린 캡쳐 UI를 통해 실행하게 함으로써, 편의성을 향상시킬 수 있다. 도 19는 본 개시의 일 실시예에 따른 증강 현실 디바이스가 웨어러블 디바이스에 제어 권한을 제공하 고, 제공된 제어 권한에 기초하여 웨어러블 디바이스에 의해 제어되는 동작을 도시한 도면이다. 도 19를 참조하면, 증강 현실 디바이스는 가상 객체 상에 오버레이되는 웨어러블 디바이스를 인식하여, 제어 권한을 제공한다(동작 ①). 증강 현실 디바이스는 웨이브가이드를 통해 가상 객체 를 표시할 수 있다. 증강 현실 디바이스는 가상 객체 상에 오버레이되는 웨어러블 디바이스 를 인식할 수 있다. 본 개시의 일 실시예에서, 증강 현실 디바이스는 인식된 웨어러블 디바이스(20 0)에 기능에 관한 제어 권한을 제공할 수 있다. 도 19에 도시된 실시예에서, 가상 객체는 증강 현실 디바 이스에 의해 실행되는 웹 브라우저 애플리케이션의 실행 화면일 수 있다. 예를 들어, 웹 브라우저는 웹툰 사이트에 접속하여, 웹툰을 표시할 수 있다. 증강 현실 디바이스는 웹 브라우저 애플리케이션의 기능에 관 한 제어 권한을 웨어러블 디바이스에 제공할 수 있다. 증강 현실 디바이스는 사용자의 손의 반복 동작을 인식한다(동작 ②). 증강 현실 디바이스는 웨어러 블 디바이스를 착용 또는 파지하고 있는 사용자의 손을 인식할 수 있다. 본 개시의 일 실시예에서, 증강 현실 디바이스는 사용자의 손에 의해 기 설정된 횟수 이상 반복되는 반복 동작을 인식할 수 있다. 예를 들 어, 증강 현실 디바이스는 현실 공간에서의 사용자의 손에 의한 스크롤(scroll) 동작 또는 스와이프 (swipe) 동작이 기 설정된 횟수 이상 반복됨을 인식할 수 있다. 기 설정된 횟수는 예를 들어, 5회일 수 있으나, 이에 한정되지 않는다. 증강 현실 디바이스는 인식된 반복 동작에 기초하여 웨어러블 디바이스에 기능의 제어 권한을 제공할 것을 결정할 수 있다. 웨어러블 디바이스는 제어 권한 획득 알림 메시지를 출력한다(동작 ③). 웨어러블 디바이스는 증강 현실 디바이스로부터 기능의 제어 권한을 획득하고, 제어 권한 획득을 사용자에게 알리는 알림 메시지를 디스플레이부 상에 디스플레이할 수 있다. 알림 메시지는 증강 현실 디바이스에 의해 실행되고 있는 애플리케이션의 명칭 및 증강 현실 디바이스로부터 획득된 제어 권한과 관련된 기능의 명칭이 포함될 수 있다. 도 19에 도시된 실시예에서, 웨어러블 디바이스는 \"인터넷의 스크롤을 제어하시겠습니까?\"와 같이 애플리케이션 명칭(예를 들어, 'Internet')과 기능의 명칭(예를 들어, '스크롤')을 포함하는 알림 메시지를 출력할 수 있다. 도 19에서는, 웨어러블 디바이스가 디스플레이부를 통해 알림 메시지를 디스플레이하는 것으로 도시 되고, 설명되었지만, 본 개시가 이에 한정되는 것은 아니다. 본 개시의 일 실시예에서, 기능의 제어 권한이 획 득되는 경우 웨어러블 디바이스는 진동 모터를 통해 진동 알림을 제공할 수도 있다. 증강 현실 디바이스는 웨어러블 디바이스를 통해 수신된 사용자 입력에 기초하여, 기능을 제어한다 (동작 ④). 본 개시의 일 실시예에서, 웨어러블 디바이스는 회전식 베젤 링(222, 도 13 참조)을 시계 방향 또는 반시계 방향으로 회전시키는 사용자 입력을 수신하고, 수신된 사용자 입력에 기초하여 기능과 관련된 데이 터 값을 변경할 수 있다. 예를 들어, 웨어러블 디바이스는 사용자 입력에 기초하여 웹 브라우저의 스크롤 바의 위치를 변경할 수 있다. 증강 현실 디바이스는 웨어러블 디바이스에 의해 변경된 데이터 값에 기초하여 제어될 수 있다. 도 19에 도시된 실시예에서, 증강 현실 디바이스는 변경된 스크롤 바의 위치에 관한 정보를 웨어러블 디바이스로부터 수신하고, 수신된 정보에 기초하여 웹 브라우저의 실행 화면인 가상 객체의 표시 화면을 위아래 방향으로 스크롤할 수 있다. 도 20은 본 개시의 일 실시예에 따른 증강 현실 디바이스가 웨어러블 디바이스에 제어 권한을 제공하 고, 제공된 제어 권한에 기초하여 웨어러블 디바이스에 의해 제어되는 동작을 도시한 도면이다. 도 20을 참조하면, 증강 현실 디바이스는 가상 객체 상에 오버레이되는 웨어러블 디바이스를 인식하여, 제어 권한을 제공한다(동작 ①). 증강 현실 디바이스는 웨이브가이드를 통해 가상 객체 를 표시하고, 가상 객체 상에 오버레이되는 웨어러블 디바이스를 인식할 수 있다. 도 20에 도 시된 실시예에서, 가상 객체는 증강 현실 디바이스에 의해 실행되는 사진 갤러리 애플리케이션의 실 행 화면일 수 있다. 예를 들어, 사진 갤러리 애플리케이션은 복수의 사진들의 썸네일 이미지(thumbnail image s)를 디스플레이할 수 있다. 증강 현실 디바이스는 인식된 웨어러블 디바이스에 사진 갤러리 애플리 케이션의 기능에 관한 제어 권한을 제공할 수 있다. 웨어러블 디바이스는 회전식 베젤 링(222, 도 13 참조)을 이용하여 사진 갤러리의 빠른 탐색을 실행한다 (동작 ②). 웨어러블 디바이스는 회전식 베젤 링을 시계 방향 또는 반시계 방향으로 회전시키는 사용 자 입력을 수신하고, 수신된 사용자 입력에 기초하여 기능과 관련된 데이터 값을 변경할 수 있다. 도 20에 도시 된 실시예에서, 웨어러블 디바이스는 회전식 베젤 링을 통해 수신된 사용자 입력에 기초하여 사진 갤 러리 애플리케이션에 대하여 빠른 탐색을 실행할 수 있다. '빠른 탐색'은 사진 갤러리 애플리케이션에 의해 표 시되는 복수의 사진들의 썸네일 이미지를 사진이 촬영된 년도에 따라 스크롤하는 기능을 의미한다. 예를 들어, 회전식 베젤 링을 시계 방향으로 회전시키는 사용자 입력이 수신되는 경우, 웨어러블 디바이스는 사 진 촬영 년도를 최근 시점을 향하여 빠른 탐색하고, 회전식 베젤 링을 반시계 방향으로 회전시키는 사용자 입력이 수신되는 경우, 웨어러블 디바이스는 사진 촬영 년도를 이전 과거 시점을 향하여 빠른 탐색을 수행 할 수 있다. 웨어러블 디바이스는 스와이프(swipe) 입력을 통해 사진 갤러리 애플리케이션의 느린 탐색을 실행한다(동 작 ③). 웨어러블 디바이스는 터치스크린으로 구성된 디스플레이부를 통해 사용자의 스와이프 입력을 수신할 수 있다. 웨어러블 디바이스는 수신된 스와이프 입력의 방향에 기초하여, 사진 갤러리 애플리케이 션의 느린 탐색 기능을 실행할 수 있다. '느린 탐색' 기능은 사진 갤러리 애플리케이션에 의해 표시되는 복수의 사진들의 썸네일 이미지를 사진이 촬영된 일자, 시점, 인물, 또는 장소에 따라 스크롤하는 기능을 의미한다. 느 린 탐색 기능은 빠른 탐색 기능에 비하여 상대적으로 적은 개수의 사진들의 썸네일 이미지를 스크롤한다. 예를 들어, 터치스크린을 통해 아래에서 위를 향하는 스와이프 입력이 수신되는 경우, 웨어러블 디바이스는 사 진 촬영 년도를 기준으로 최근 시점에서 과거 시점을 향하여 느린 탐색을 수행할 수 있다. 웨어러블 디바이스는 사용자로부터 터치 입력을 수신하여 사진을 선택한다(동작 ④). 본 개시의 일 실시예 에서, 웨어러블 디바이스는 터치스크린으로 구성된 디스플레이부 상에 버튼 UI를 디스플레이하고, 버 튼 UI를 터치하는 사용자의 터치 입력을 수신할 수 있다. 웨어러블 디바이스에 의해 터치 입력이 수신되는 경우, 증강 현실 디바이스는 사용자 입력에 의해 선택된 사진을 웨이브가이드를 통해 표시할 수 있다. 도 21은 본 개시의 일 실시예에 따른 증강 현실 디바이스가 웨어러블 디바이스에 제어 권한을 제공하 고, 제공된 제어 권한에 기초하여 웨어러블 디바이스에 의해 제어되는 동작을 도시한 도면이다. 도 21을 참조하면, 증강 현실 디바이스는 써드파티 애플리케이션(third party application)을 실행한다(동 작 ①). 증강 현실 디바이스는 써드파티 애플리케이션을 실행함으로써, 광학 엔진(124, 도 2 참조)를 통해 웨이브가이드에 가상 객체를 투사할 수 있다. 사용자는 웨이브가이드에 투사된 가상 객체 를 볼 수 있다. 가상 객체는 복수의 기능 UI(2112, 2114, 2116)를 포함할 수 있다. 웨어러블 디바이스는 증강 현실 디바이스로부터 기능의 제어 권한을 획득한다(동작 ②). 증강 현실 디바이스는 가상 객체 상에 오버레이되는 웨어러블 디바이스를 인식하고, 인식된 웨어러블 디 바이스에 기능에 관한 제어 권한을 제공할 수 있다. 써드파티 애프리케이션의 경우 API(Application Programmable Interface)를 제공하지 않을 수 있고, 이 경우 증강 현실 디바이스는 복수의 기능 UI(2112, 2114, 2116) 각각에 관한 제어 권한을 웨어러블 디바이스에 제공할 수 없다. 증강 현실 디바이스로부 터 API를 제공받지 않은 경우, 웨어러블 디바이스는 터치스크린을 터치 패드로 동작하도록 제어하여 써드 파티 애플리케이션의 기능을 제어할 수 있다. 웨어러블 디바이스가 터치 패드로 동작되는 경우, 증강 현실 디바이스는 터치 패드를 통해 수신되는 터치 입력을 가상 객체 상의 커서 위치로 매핑하고, 커서 UI를 표시할 수 있다. 웨어러블 디바이스는 터치스크린을 통해 커서를 조작하고, 기능을 제어한다(동작 ③). 웨어러블 디바이스 는 터치스크린을 통해 수신되는 터치 입력에 기초하여 가상 객체 상의 커서의 위치를 변경할 수 있 다. 웨어러블 디바이스를 통한 조작에 따라 증강 현실 디바이스는 가상 객체 상에서 커서 UI를 위치가 변경할 수 있다. 웨어러블 디바이스는 커서의 위치 이동 뿐만 아니라, 터치 입력에 기 초하여 커서를 통한 기능 UI를 선택할 수 있다. 도 21에 도시된 실시예에서, 웨어러블 디바이스는 터치스 크린을 통해 수신되는 터치 입력에 기초하여, 가상 객체에 포함되는 복수의 기능 UI(2112, 2114, 2116) 중 어느 하나의 기능 UI를 선택할 수 있다. 웨어러블 디바이스에 제어에 의해 기능 UI가 선택되는 경우, 증강 현실 디바이스는 선택된 기능 UI에 매핑되는 기능을 실행할 수 있다. 웨어러블 디바이스로부터 터치 입력이 수신된 이후 기 설정된 시간이 경과하는 경우, 증강 현실 디바이스 는 가상 객체 상에서 커서 UI를 표시하지 않고, 웨어러블 디바이스에 제공되었던 제어 권한을 회수할 수 있다. 본 개시는 외부 디바이스에 의해 제어되는 증강 현실 디바이스를 제공한다. 본 개시의 일 실시예에 따른 증강 현실 디바이스는 카메라(110, 도 2 참조), 웨이브가이드(122, 도 2 참조), 웨이브가이드에 가상 객체를 투사하도록 구성되는 광학 엔진(124, 도 2 참조), 웨어러블 디바이스(200, 도 11 참조)와 페어링 (pairing)하고, 웨어러블 디바이스와 데이터를 송수신하도록 구성되는 통신 인터페이스(150, 도 2 참조), 적어도 하나의 명령어들(instructions)를 저장하는 메모리(140, 도 2 참조), 및 적어도 하나의 명령어들을 실행 하는 적어도 하나의 프로세서를 포함할 수 있다. 상기 적어도 하나의 프로세서는 가상 객체 상에 오 버레이되는(overlaid) 웨어러블 디바이스를 인식할 수 있다. 상기 적어도 하나의 프로세서는 인식된 웨어러블 디바이스에 가상 객체와 관련된 기능을 실행 또는 제어하기 위한 제어 권한의 제공을 결정할 수 있다. 상기 적어도 하나의 프로세서는 통신 인터페이스를 제어하여, 기능의 제어 권한, 가상 객체의 특성 정보, 및 기능과 관련된 데이터 값 중 적어도 하나를 웨어러블 디바이스에 전송할 수 있다. 상기 적 어도 하나의 프로세서는 전송된 제어 권한에 기초하여 웨어러블 디바이스에 의해 변경된 데이터 값을 웨어러블 디바이스로부터 수신할 수 있다. 상기 적어도 하나의 프로세서는 수신된 데이터 값에 기초 하여 가상 객체와 관련된 기능의 데이터 값을 업데이트할 수 있다. 본 개시의 일 실시예에서, 상기 적어도 하나의 프로세서는 웨어러블 디바이스를 착용 또는 파지하고 있는 사용자의 손을 인식할 수 있다. 상기 적어도 하나의 프로세서는 가상 객체가 인식된 손에 의해 오버 레이되는 시간이 기 설정된 시간을 초과하는지 여부에 기초하여, 웨어러블 디바이스에 제어 권한을 제공할 것을 결정할 수 있다. 본 개시의 일 실시예에서, 상기 적어도 하나의 프로세서는 웨어러블 디바이스를 착용 또는 파지하고 있는 사용자의 손의 제스처를 인식할 수 있다. 상기 적어도 하나의 프로세서는 인식된 제스처에 기초하여 웨어러블 디바이스에 제어 권한을 제공할 것을 결정할 수 있다. 본 개시의 일 실시예에서, 상기 적어도 하나의 프로세서는 웨어러블 디바이스를 착용 또는 파지하고 있는 사용자의 손에 의해 기 설정된 횟수 이상 반복되는 반복 동작을 인식할 수 있다. 상기 적어도 하나의 프로 세서는 인식된 반복 동작에 기초하여 웨어러블 디바이스에 제어 권한을 제공할 것을 결정할 수 있다. 본 개시의 일 실시예에서, 가상 객체는 애플리케이션에 의해 제공되는 복수의 기능을 실행하기 위한 복수의 기 능 UI(User Interface)를 포함하고, 적어도 하나의 프로세서는 복수의 기능 UI(User Interface) 중 웨어 러블 디바이스에 제어 권한을 제공할 적어도 하나의 기능에 관한 기능 UI를 선택할 수 있다. 본 개시의 일 실시예에서, 상기 적어도 하나의 프로세서는 복수의 기능 UI 중 웨어러블 디바이스를 착용 또는 파지하고 있는 사용자의 손에 의해 오버레이되는 기능 UI를 식별할 수 있다. 적어도 하나의 프로세서 는 식별된 기능 UI에 의해 실행 또는 제어되는 기능에 관한 제어 권한을 웨어러블 디바이스에 제공할 것을 결정할 수 있다. 본 개시의 일 실시예에서, 상기 적어도 하나의 프로세서는 애플리케이션의 복수의 기능 각각에 관한 API(Application Programming Interface)의 제공 가능 여부에 기초하여, 적어도 하나의 기능 UI를 선택할 수 있다. 본 개시의 일 실시예에서, 상기 적어도 하나의 프로세서는 광학 엔진을 제어하여, 선택된 적어도 하 나의 기능 UI의 제어 영역을 가상 객체 내의 다른 영역과 구별되는 컬러로 표시할 수 있다. 본 개시의 일 실시예에서, 증강 현실 디바이스는 사용자의 좌안 및 우안의 시선 방향을 추적하여, 상기 좌 안 및 우안의 시선 방향 정보를 획득하도록 구성되는 시선 추적 센서를 더 포함할 수 있다. 상기 적어도 하나의 프로세서는 복수의 애플리케이션을 실행함으로써, 복수의 애플리케이션에 의해 제공되는 복수의 가상 객체 를 상기 웨이브가이드를 통해 표시할 수 있다. 상기 적어도 하나의 프로세서는 시선 추적 센서를 통 해 사용자의 좌안의 시선 방향과 우안의 시선 방향이 수렴하는 응시점을 인식할 수 있다. 상기 적어도 하나의 프로세서는 인식된 응시점의 위치에 기초하여 실행 중인 복수의 애플리케이션 중 어느 하나의 애플리케이 션을 선택할 수 있다. 상기 적어도 하나의 프로세서는 선택된 애플리케이션에 의해 표시되는 적어도 하나 의 가상 객체와 관련된 기능의 제어 권한을 웨어러블 디바이스에 제공할 것을 결정할 수 있다. 본 개시는 증강 현실 디바이스가 외부 디바이스에 의해 제어되는 방법을 제공한다. 본 개시의 일 실시예에 서, 상기 방법은 가상 객체 상에 오버레이되는(overlaid) 웨어러블 디바이스를 인식하는 단계(S310)를 포 함할 수 있다. 상기 방법은 인식된 웨어러블 디바이스에 가상 객체와 관련된 기능을 실행 또는 제어하기 위한 제어 권한의 제공을 결정하는 단계(S320)를 포함할 수 있다. 상기 방법은 기능의 제어 권한, 가상 객체의 특성 정보, 및 기능과 관련된 데이터 값 중 적어도 하나를 웨어러블 디바이스에 전송하는 단계(S330)를 포 함할 수 있다. 상기 방법은 전송된 제어 권한에 기초하여 웨어러블 디바이스에 의해 변경된 데이터 값을 웨어러블 디바이스로부터 수신하는 단계(S340)를 포함할 수 있다. 상기 방법은 수신된 데이터 값에 기초하 여 가상 객체와 관련된 기능의 데이터 값을 업데이트하는 단계(S350)를 포함할 수 있다. 본 개시의 일 실시예에서, 상기 웨어러블 디바이스를 인식하는 단계(S310)는 웨어러블 디바이스를 착 용 또는 파지하고 있는 사용자의 손을 인식하는 단계를 포함할 수 있다. 상기 제어 권한의 제공을 결정하는 단 계(S320)는 가상 객체가 인식된 손에 의해 오버레이되는 시간이 기 설정된 시간을 초과하는지 여부에 기초하여, 웨어러블 디바이스에 제어 권한을 제공할 것을 결정할 수 있다. 본 개시의 일 실시예에서, 상기 웨어러블 디바이스를 인식하는 단계(S310)는 웨어러블 디바이스를 착 용 또는 파지하고 있는 사용자의 손의 제스처를 인식하는 단계를 포함할 수 있다. 상기 제어 권한의 제공을 결 정하는 단계(S320)는 인식된 제스처에 기초하여 웨어러블 디바이스에 제어 권한을 제공할 것을 결정할 수 있다. 본 개시의 일 실시예에서, 상기 웨어러블 디바이스를 인식하는 단계(S310)는 웨어러블 디바이스를 착 용 또는 파지하고 있는 사용자의 손에 의해 기 설정된 횟수 이상 반복되는 반복 동작을 인식하는 단계를 더 포 함할 수 있다. 상기 제어 권한의 제공을 결정하는 단계(S320)는 인식된 반복 동작에 기초하여 웨어러블 디바이 스에 제어 권한을 제공할 것을 결정할 수 있다. 본 개시의 일 실시예에서, 가상 객체는 애플리케이션에 의해 제공되는 복수의 기능을 실행하기 위한 복수의 기 능 UI(User Interface)를 포함하고, 상기 제어 권한의 제공을 결정하는 단계(S320)는 복수의 기능 UI(User Interface) 중 웨어러블 디바이스에 제어 권한을 제공할 적어도 하나의 기능에 관한 기능 UI를 선택하는 단계를 포함할 수 있다. 본 개시의 일 실시예에서, 상기 웨어러블 디바이스에 제어 권한을 제공할 적어도 하나의 기능 UI를 선택하 는 단계는 복수의 기능 UI 중 상기 웨어러블 디바이스를 착용 또는 파지하고 있는 사용자의 손에 의해 오 버레이되는 기능 UI를 식별하는 단계를 포함할 수 있다. 상기 웨어러블 디바이스에 제어 권한을 제공 할 적어도 하나의 기능 UI를 선택하는 단계는 식별된 기능 UI에 의해 실행 또는 제어되는 기능에 관한 제어 권 한을 웨어러블 디바이스에 제공할 것을 결정하는 단계를 포함할 수 있다. 본 개시의 일 실시예에서, 상기 웨어러블 디바이스에 제어 권한을 제공할 적어도 하나의 기능 UI를 선택하 는 단계는 애플리케이션의 복수의 기능 각각에 관한 API(Application Programming Interface)의 제공 가능 여 부에 기초하여, 적어도 하나의 기능 UI를 선택할 수 있다. 본 개시의 일 실시예에서, 상기 방법은 선택된 적어도 하나의 기능 UI의 제어 영역을 가상 객체 내의 다른 영역 과 구별되는 컬러로 표시하는 단계(S730)를 더 포함할 수 있다. 본 개시의 일 실시예에서, 상기 방법은 복수의 애플리케이션을 실행함으로써, 상기 복수의 애플리케이션에 의해 제공되는 복수의 가상 객체를 표시하는 단계(S910)를 더 포함할 수 있다. 상기 제어 권한의 제공을 결정하는 단 계는 사용자의 좌안의 시선 방향과 우안의 시선 방향이 수렴하는 응시점을 인식하는 단계(S920) 및 인식된 응시 점의 위치에 기초하여 실행 중인 복수의 애플리케이션 중 어느 하나의 애플리케이션을 선택하는 단계(S930)를 포함할 수 있다. 상기 제어 권한의 제공을 결정하는 단계는 선택된 애플리케이션에 의해 표시되는 적어도 하나 의 가상 객체와 관련된 기능의 제어 권한을 상기 웨어러블 디바이스에 제공할 것을 결정하는 단계(S940)를 포함할 수 있다. 본 개시는 증강 현실 디바이스와 인터랙션하는 웨어러블 디바이스를 제공한다. 본 개시의 일 실시예 에 따른 웨어러블 디바이스는 증강 현실 디바이스와 근거리 통신 방식을 통해 연결되고, 증강 현실 디바이스와 데이터 통신을 수행하는 통신 인터페이스, 사용자 입력을 수신하는 사용자 입력부, 적어도 하나의 명령어들(instructions)를 저장하는 메모리, 및 적어도 하나의 명령어들을 실행하는 적어도 하나의 프로세서를 포함할 수 있다. 상기 적어도 하나의 프로세서는 증강 현실 디바이스에 의해 실행되는 애플리케이션을 통해 표시되는 가상 객체와 관련된 기능을 실행 또는 제어하기 위한 제어 권한을 증강 현실 디바이스로부터 획득할 수 있다. 상기 적어도 하나의 프로세서는 가상 객체의 타입, 기능의 특 성, 및 기능과 관련된 데이터 값 중 적어도 하나에 기초하여, 획득된 제어 권한에 기초하여 기능을 제어하기 위 한 조작 방식을 결정할 수 있다. 상기 적어도 하나의 프로세서는 결정된 조작 방식에 따라 사용자 입력부 를 통해 수신된 사용자 입력에 기초하여, 기능과 관련된 데이터 값을 변경할 수 있다. 상기 적어도 하나의 프로세서는 통신 인터페이스를 제어함으로써, 변경된 데이터 값을 증강 현실 디바이스에 전송할 수 있다. 본 개시의 일 실시예에서, 상기 웨어러블 디바이스는 디스플레이부 를 더 포함할 수 있다. 상기 적어 도 하나의 프로세서는 증강 현실 디바이스로부터 제어 권한이 획득되는 경우 제어 권한의 획득 여부 및 제어 권한과 관련된 기능에 관한 정보를 알리는 알림 메시지를 디스플레이부 상에 디스플레이할 수 있 다. 본 개시에서 설명된 증강 현실 디바이스에 의해 실행되는 프로그램은 하드웨어 구성요소, 소프트웨어 구성 요소, 및/또는 하드웨어 구성요소 및 소프트웨어 구성요소의 조합으로 구현될 수 있다. 프로그램은 컴퓨터로 읽 을 수 있는 명령어들을 수행할 수 있는 모든 시스템에 의해 수행될 수 있다. 소프트웨어는 컴퓨터 프로그램(computer program), 코드(code), 명령어(instruction), 또는 이들 중 하나 이상 의 조합을 포함할 수 있으며, 원하는 대로 동작하도록 처리 장치를 구성하거나 독립적으로 또는 결합적으로 (collectively) 처리 장치를 명령할 수 있다. 소프트웨어는, 컴퓨터로 읽을 수 있는 저장 매체(computer-readable storage media)에 저장된 명령어를 포함하 는 컴퓨터 프로그램으로 구현될 수 있다. 컴퓨터가 읽을 수 있는 기록 매체로는, 예를 들어 마그네틱 저장 매체 (예컨대, ROM(read-only memory), RAM(random-access memory), 플로피 디스크, 하드 디스크 등) 및 광학적 판 독 매체(예컨대, 시디롬(CD-ROM), 디브이디(DVD: Digital Versatile Disc)) 등이 있다. 컴퓨터가 읽을 수 있 는 기록 매체는 네트워크로 연결된 컴퓨터 시스템들에 분산되어, 분산 방식으로 컴퓨터가 판독 가능한 코드가 저장되고 실행될 수 있다. 매체는 컴퓨터에 의해 판독 가능하며, 메모리에 저장되고, 프로세서에서 실행될 수 있다. 컴퓨터로 읽을 수 있는 저장매체는, 비일시적(non-transitory) 저장매체의 형태로 제공될 수 있다. 여기서, '비 일시적'은 저장매체가 신호(signal)를 포함하지 않으며 실재(tangible)한다는 것을 의미할 뿐 데이터가 저장매 체에 반영구적 또는 임시적으로 저장되는 경우를 구분하지 않는다. 예를 들어, '비일시적 저장매체'는 데이터가 임시적으로 저장되는 버퍼를 포함할 수 있다. 또한, 본 명세서에 개시된 실시예들에 따른 프로그램은 컴퓨터 프로그램 제품(computer program product)에 포 함되어 제공될 수 있다. 컴퓨터 프로그램 제품은 상품으로서 판매자 및 구매자 간에 거래될 수 있다. 컴퓨터 프로그램 제품은 소프트웨어 프로그램, 소프트웨어 프로그램이 저장된 컴퓨터로 읽을 수 있는 저장 매체 를 포함할 수 있다. 예를 들어, 컴퓨터 프로그램 제품은 증강 현실 디바이스의 제조사 또는 전자 마켓(예 를 들어, 삼성 갤럭시 스토어)을 통해 전자적으로 배포되는 소프트웨어 프로그램 형태의 상품(예를 들어, 다운 로드 가능한 애플리케이션(downloadable application))을 포함할 수 있다. 전자적 배포를 위하여, 소프트웨어 프로그램의 적어도 일부는 저장 매체에 저장되거나, 임시적으로 생성될 수 있다. 이 경우, 저장 매체는 증강 현 실 디바이스의 제조사의 서버, 전자 마켓의 서버, 또는 소프트웨어 프로그램을 임시적으로 저장하는 중계 서버의 저장 매체가 될 수 있다. 컴퓨터 프로그램 제품은, 증강 현실 디바이스 및/또는 서버로 구성되는 시스템에서, 서버의 저장매체 또는 증강 현실 디바이스의 저장매체를 포함할 수 있다. 또는, 증강 현실 디바이스와 통신 연결되는 제3 장치(예를 들어, 웨어러블 디바이스)가 존재하는 경우, 컴퓨터 프로그램 제품은 제3 장치의 저장매체를 포함할 수 있다. 또는, 컴퓨터 프로그램 제품은 증강 현실 디바이스로부터 제3 장치로 전송되거나, 제3 장치로부 터 전자 장치로 전송되는 소프트웨어 프로그램 자체를 포함할 수 있다. 이 경우, 증강 현실 디바이스 또는 제3 장치 중 하나가 컴퓨터 프로그램 제품을 실행하여 개시된 실시예들 에 따른 방법을 수행할 수 있다. 또는, 증강 현실 디바이스 및 제3 장치 중 적어도 하나 이상이 컴퓨터 프 로그램 제품을 실행하여 개시된 실시예들에 따른 방법을 분산하여 실시할 수 있다. 예를 들면, 증강 현실 디바이스가 메모리(140, 도 2 참조)에 저장된 컴퓨터 프로그램 제품을 실행하여, 증 강 현실 디바이스와 통신 연결된 타 전자 장치(예를 들어, 웨어러블 디바이스)가 개시된 실시예들에 따른 방법을 수행하도록 제어할 수 있다. 또 다른 예로, 제3 장치가 컴퓨터 프로그램 제품을 실행하여, 제3 장치와 통신 연결된 전자 장치가 개시된 실시 예에 따른 방법을 수행하도록 제어할 수 있다. 제3 장치가 컴퓨터 프로그램 제품을 실행하는 경우, 제3 장치는 증강 현실 디바이스로부터 컴퓨터 프로그 램 제품을 다운로드하고, 다운로드된 컴퓨터 프로그램 제품을 실행할 수 있다. 또는, 제3 장치는 프리로드(pre- load)된 상태로 제공된 컴퓨터 프로그램 제품을 실행하여 개시된 실시예들에 따른 방법을 수행할 수도 있다."}
{"patent_id": "10-2022-0107179", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "이상과 같이 실시예들이 비록 한정된 실시예와 도면에 의해 설명되었으나, 해당 기술분야에서 통상의 지식을 가 진 자라면 상기의 기재로부터 다양한 수정 및 변형이 가능하다. 예를 들어, 설명된 기술들이 설명된 방법과 다 른 순서로 수행되거나, 및/또는 설명된 컴퓨터 시스템 또는 모듈 등의 구성요소들이 설명된 방법과 다른 형태로 결합 또는 조합되거나, 다른 구성요소 또는 균등물에 의하여 대치되거나 치환되더라도 적절한 결과가 달성될 수 있다. 도면 도면1a 도면1b 도면2 도면3 도면4 도면5a 도면5b 도면6 도면7 도면8a 도면8b 도면8c 도면9 도면10 도면11 도면12 도면13 도면14a 도면14b 도면14c 도면15a 도면15b 도면16 도면17a 도면17b 도면18 도면19 도면20 도면21"}
{"patent_id": "10-2022-0107179", "section": "도면", "subsection": "도면설명", "item": 1, "content": "본 개시는, 다음의 자세한 설명과 그에 수반되는 도면들의 결합으로 쉽게 이해될 수 있으며, 참조 번호 (reference numerals)들은 구조적 구성요소(structural elements)를 의미한다. 도 1a는 본 개시의 증강 현실 디바이스가 외부 디바이스에 의해 제어되는 동작을 설명하기 위한 개념도이다. 도 1b는 본 개시의 증강 현실 디바이스 및 웨어러블 디바이스의 상호 간의 동작을 설명하기 위한 개념도이다. 도 2는 본 개시의 일 실시예에 따른 증강 현실 디바이스의 구성 요소를 도시한 블록도이다. 도 3은 본 개시의 일 실시예에 따른 증강 현실 디바이스의 동작 방법을 도시한 흐름도이다. 도 4는 본 개시의 일 실시예에 따른 증강 현실 디바이스가 웨어러블 디바이스에 제어 권한의 제공을 결정하는 동작을 도시한 도면이다. 도 5a는 본 개시의 일 실시예에 따른 증강 현실 디바이스가 사용자의 제스처에 기초하여 웨어러블 디바이스에 제어 권한의 제공을 결정하는 동작을 도시한 도면이다. 도 5b는 본 개시의 일 실시예에 따른 증강 현실 디바이스가 사용자의 제스처에 기초하여 웨어러블 디바이스로부 터 제어 권한을 회수하는 동작을 도시한 도면이다. 도 6은 본 개시의 일 실시예에 따른 증강 현실 디바이스가 사용자의 반복 동작에 기초하여 웨어러블 디바이스에 제어 권한의 제공을 결정하는 동작을 도시한 도면이다. 도 7은 본 개시의 일 실시예에 따른 증강 현실 디바이스가 기능 UI(User Interface)에 관한 제어 권한을 웨어러 블 디바이스에 전송하는 방법을 도시한 흐름도이다. 도 8a는 본 개시의 일 실시예에 따른 증강 현실 디바이스가 웨어러블 디바이스에 제어 권한을 제공할 기능에 관 한 기능 UI를 디스플레이하는 동작을 도시한 도면이다. 도 8b는 본 개시의 일 실시예에 따른 증강 현실 디바이스가 웨어러블 디바이스에 제어 권한을 제공할 기능에 관 한 기능 UI를 디스플레이하는 동작을 도시한 도면이다. 도 8c는 본 개시의 일 실시예에 따른 증강 현실 디바이스가 웨어러블 디바이스에 제어 권한을 제공할 기능에 관한 기능 UI를 선택하는 동작을 도시한 도면이다. 도 9는 본 개시의 일 실시예에 따른 증강 현실 디바이스가 사용자의 응시점에 기초하여 제어 권한을 제공할 기 능과 관련된 가상 객체를 결정하는 방법을 도시한 흐름도이다. 도 10은 본 개시의 일 실시예에 따른 증강 현실 디바이스가 사용자의 응시점에 기초하여 웨어러블 디바이스에 제어 권한을 제공할 기능과 관련된 가상 객체를 결정하는 동작을 도시한 도면이다. 도 11은 본 개시의 일 실시예에 따른 웨어러블 디바이스의 구성 요소를 도시한 블록도이다. 도 12는 본 개시의 일 실시예에 따른 증강 현실 디바이스 및 웨어러블 디바이스의 동작 방법을 도시한 흐름도이 다. 도 13은 본 개시의 일 실시예에 따른 웨어러블 디바이스가 증강 현실 디바이스로부터 획득한 제어 권한에 기초 하여 기능을 제어하기 위한 조작 방식을 설명하기 위한 도면이다. 도 14a는 본 개시의 일 실시예에 따른 웨어러블 디바이스가 증강 현실 디바이스로부터 획득한 제어 권한에 따라 기능 UI를 조작 방식과 매핑하는 동작을 도시한 도면이다. 도 14b는 본 개시의 일 실시예에 따른 웨어러블 디바이스가 증강 현실 디바이스로부터 획득한 제어 권한에 따라 기능 UI를 조작 방식과 매핑하는 동작을 도시한 도면이다. 도 14c는 본 개시의 일 실시예에 따른 웨어러블 디바이스가 증강 현실 디바이스로부터 획득한 제어 권한에 따라 기능 UI를 조작 방식과 매핑하는 동작을 도시한 도면이다. 도 15a는 본 개시의 일 실시예에 따른 웨어러블 디바이스가 증강 현실 디바이스로부터 획득한 제어 권한에 따라 기능 UI를 조작 방식과 매핑하는 동작을 도시한 도면이다. 도 15b는 본 개시의 일 실시예에 따른 웨어러블 디바이스가 증강 현실 디바이스로부터 획득한 제어 권한에 따라 기능 UI를 조작 방식과 매핑하는 동작을 도시한 도면이다. 도 16은 본 개시의 일 실시예에 따른 웨어러블 디바이스가 증강 현실 디바이스로부터 획득한 제어 권한에 따라 기능 UI를 조작 방식과 매핑하는 동작을 도시한 도면이다. 도 17a는 본 개시의 일 실시예에 따른 증강 현실 디바이스가 외부 디바이스를 인식하고, 인식된 외부 디바이스 에 제어 권한의 제공을 결정하는 동작을 도시한 도면이다. 도 17b는 본 개시의 일 실시예에 따른 증강 현실 디바이스가 외부 디바이스를 인식하고, 인식된 외부 디바이스 에 제어 권한의 제공을 결정하는 동작을 도시한 도면이다. 도 18은 본 개시의 일 실시예에 따른 본 개시의 일 실시예에 따른 사용자가 증강 현실 디바이스 및 웨어러블 디 바이스를 이용하여 기능을 실행 또는 제어하는 동작을 도시한 도면이다. 도 19는 본 개시의 일 실시예에 따른 증강 현실 디바이스가 웨어러블 디바이스에 제어 권한을 제공하고, 제공된 제어 권한에 기초하여 웨어러블 디바이스에 의해 제어되는 동작을 도시한 도면이다. 도 20은 본 개시의 일 실시예에 따른 증강 현실 디바이스가 웨어러블 디바이스에 제어 권한을 제공하고, 제공된 제어 권한에 기초하여 웨어러블 디바이스에 의해 제어되는 동작을 도시한 도면이다. 도 21은 본 개시의 일 실시예에 따른 증강 현실 디바이스가 웨어러블 디바이스에 제어 권한을 제공하고, 제공된 제어 권한에 기초하여 웨어러블 디바이스에 의해 제어되는 동작을 도시한 도면이다."}
