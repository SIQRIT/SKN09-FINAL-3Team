{"patent_id": "10-2025-7005193", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2025-0053066", "출원번호": "10-2025-7005193", "발명의 명칭": "단백질 정제 개선을 위한 컴퓨팅 기반 방법", "출원인": "제넨테크, 인크.", "발명자": "마이어, 앤드류 제임스"}}
{"patent_id": "10-2025-7005193", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "하나 이상의 컴퓨팅 장치에 의해, 하나 이상의 단백질의 분자 결합 특성을 예측하기 위한 방법으로서, 하나 이상의 단백질에 상응하는 아미노산 서열 세트를 나타내는 분자 설명자 행렬에 액세스하는 단계, 및상기 하나 이상의 단백질의 분자 결합 특성의 예측치를 생성하도록 훈련된 머신 러닝 모델과 관련된 하이퍼 매개변수 세트를 정밀화하는 단계이며, 여기서 상기 하이퍼 매개변수 세트를 정밀화하는 것은 원하는 정밀도에 도달할 때까지 프로세스를 반복적으로 실행하는 것을 포함하고, 상기 프로세스는,복수의 특징 벡터 클러스터 각각에 대해 하나의 대표 특징 벡터를 선택함으로써 상기 분자 설명자 행렬을 감소시키고, 여기서 각각의 특징 벡터 클러스터는 유사한 특징 벡터를 포함하고,상기 하나 이상의 단백질과 관련된 사전결정된 일괄(batch) 결합 데이터 및 상기 선택된 대표 특징 벡터 간의상관관계에 기초하여 각각의 특징 벡터 클러스터에 대해 상기 선택된 대표 특징 벡터 중 하나 이상의 가장 예측적인 특징 벡터를 결정하며,상기 하나 이상의 가장 예측적인 특징 벡터 및 상기 사전결정된 일괄 결합 데이터에 적어도 부분적으로 기초하여 하나 이상의 교차 검증 손실을 계산하고,상기 하나 이상의 교차 검증 손실에 기초하여 상기 하이퍼 매개변수 세트를 업데이트하는 것을 포함하는 것인 단계, 및상기 머신 러닝 모델에 의해, 상기 업데이트된 하이퍼 매개변수 세트에 적어도 부분적으로 기초하여 상기 하나이상의 단백질의 분자 결합 특성의 예측치를 출력하는 단계를 포함하는 방법."}
{"patent_id": "10-2025-7005193", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 하나 이상의 교차 검증 손실을 계산하는 것은, 상기 하나 이상의 가장 예측적인 특징 벡터, 상기 사전결정된 일괄 결합 데이터, 상기 하이퍼 매개변수 세트,및 상기 머신 러닝 모델과 관련된 학습가능 매개변수 세트에 기초하여 교차 검증 손실 함수를 평가하고,상기 하나 이상의 가장 예측적인 특징 벡터, 상기 사전결정된 일괄 결합 데이터, 및 상기 하이퍼 매개변수 세트는 일정하게 유지시키면서 상기 학습가능 매개변수 세트를 변경함으로써 상기 교차 검증 손실 함수를 최소화하는 것을 더 포함하는 것인 방법."}
{"patent_id": "10-2025-7005193", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서, 상기 교차 검증 손실 함수를 최소화하는 것은 상기 하이퍼 매개변수 세트를 최적화하는 것을 포함하고, 상기 하이퍼 매개변수 세트는 일반 매개변수 세트, 부스터 매개변수 세트, 또는 학습 과제 매개변수 세트 중 하나 이상을 포함하는 것인 방법."}
{"patent_id": "10-2025-7005193", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제2항에 있어서, 상기 교차 검증 손실 함수를 최소화하는 것은 상기 하나 이상의 단백질에 대한 단백질 결합 백분율의 예측치 및 상기 하나 이상의 단백질에 대한 실험적으로 결정된 단백질 결합 백분율 간의 손실을 최소화공개특허 10-2025-0053066-3-하는 것을 포함하는 것인 방법."}
{"patent_id": "10-2025-7005193", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제2항에 있어서, 상기 사전결정된 일괄 결합 데이터는 상기 하나 이상의 단백질의 분자 결합 특성과 관련된 하나 이상의 pH 값 및 염 농도에 대해 실험적으로 결정된 단백질 결합 백분율을 포함하는 것인 방법."}
{"patent_id": "10-2025-7005193", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제2항에 있어서, 상기 학습가능 매개변수 세트는 상기 하나 이상의 가장 예측적인 특징 벡터 및 상기 사전결정된 일괄 결합 데이터에 적어도 부분적으로 기초하여 상기 머신 러닝 모델에 의해 결정되는 하나 이상의 가중치또는 결정 변수를 포함하는 것인 방법."}
{"patent_id": "10-2025-7005193", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에 있어서,상기 하이퍼 매개변수 세트를 정밀화한 후:하나 이상의 제2 단백질에 상응하는 제2 아미노산 서열 세트를 나타내는 제2 분자 설명자 행렬에 액세스하는 단계,상기 제2 분자 설명자 행렬의 제2 복수의 특징 벡터 클러스터 각각에 대해 하나의 대표 특징 벡터를 선택함으로써 상기 제2 분자 설명자 행렬을 감소시키는 단계,상기 하나 이상의 제2 단백질과 관련된 사전결정된 일괄 결합 데이터 및 상기 선택된 대표 특징 벡터 간의 제2상관관계에 기초하여 각각의 특징 벡터 클러스터에 대해 상기 선택된 대표 특징 벡터 중 하나 이상의 제2 가장예측적인 특징 벡터를 결정하는 단계,상기 하나 이상의 제2 단백질의 분자 결합 특성의 예측치를 생성하도록 훈련된 상기 머신 러닝 모델에 상기 하나 이상의 제2 가장 예측적인 특징 벡터를 입력하는 단계, 및상기 머신 러닝 모델에 의해, 상기 업데이트된 하이퍼 매개변수 세트에 적어도 부분적으로 기초하여 상기 하나이상의 제2 단백질의 분자 결합 특성의 예측치를 출력하는 단계를 더 포함하는 방법."}
{"patent_id": "10-2025-7005193", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서, 상기 하나 이상의 제2 단백질의 분자 결합 특성의 예측치는 상기 하나 이상의 제2 단백질에 대한 단백질 결합 백분율의 예측치를 포함하는 것인 방법."}
{"patent_id": "10-2025-7005193", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1항에 있어서, 업데이트된 하이퍼 매개변수 세트는 업데이트된 일반 매개변수 세트, 업데이트된 부스터 매개변수 세트, 또는 업데이트된 학습 과제 매개변수 세트 중 하나 이상을 포함하는 것인 방법."}
{"patent_id": "10-2025-7005193", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제1항에 있어서, 상기 하나 이상의 교차 검증 손실을 계산하는 것은 n개의 교차 검증 손실을 계산하는 것을 포함하고, n은 1 내지 n으로부터의 정수를 포함하는 것인 방법."}
{"patent_id": "10-2025-7005193", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제1항에 있어서, 상기 하나 이상의 교차 검증 손실을 계산하는 것은 상기 하나 이상의 가장 예측적인 특징 벡터 및 상기 사전결정된 일괄 결합 데이터에 기초하여 n개의 개별 훈련-테스트 분할을 결정하는 것을 포함하고, n은 1 내지 n으로부터의 정수를 포함하는 것인 방법.공개특허 10-2025-0053066-4-청구항 12 제1항에 있어서, 상기 하나 이상의 교차 검증 손실을 계산하는 것은 n개의 교차 검증 손실을 계산하는 것을 포함하고, 상기 방법은 상기 n개의 교차 검증 손실의 평균에 기초하여 상기 하나 이상의 단백질의 분자 결합 특성의 예측치를 생성하는 단계를 더 포함하는 방법."}
{"patent_id": "10-2025-7005193", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제1항에 있어서, 상기 분자 설명자 행렬은 2n개의 특징 벡터를 포함하고, n은 상기 분자 설명자 행렬의 차원을 포함하는 것인 방법."}
{"patent_id": "10-2025-7005193", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제1항에 있어서, 상기 분자 설명자 행렬은 상기 머신 러닝 모델과는 별개의 제1 머신 러닝 모델에 의해 생성되었던 것인 방법."}
{"patent_id": "10-2025-7005193", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제14항에 있어서, 상기 제1 머신 러닝 모델은 상기 아미노산 서열 세트에 기초하여 상기 분자 설명자 행렬을 생성하도록 훈련되었던 것인 방법."}
{"patent_id": "10-2025-7005193", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제14항에 있어서, 상기 제1 머신 러닝 모델은 상기 아미노산 서열 세트를 나타내는 M x N 설명자 행렬을 생성하도록 훈련된 신경망을 포함하고, N은 상기 아미노산 서열 세트의 수를 포함하고, M은 상기 신경망의 출력 계층 내 노드의 수를 포함하는 것인 방법."}
{"patent_id": "10-2025-7005193", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제1항에 있어서, 상기 머신 러닝 모델은 그래디언트 부스팅 모델, 적응형 부스팅(AdaBoost) 모델, 익스트림 그래디언트 부스팅(XGBoost) 모델, 라이트 그래디언트 부스티드 머신(LightGBM) 모델, 또는 범주형 부스팅(CatBoost) 모델 중 하나 이상을 포함하는 것인 방법."}
{"patent_id": "10-2025-7005193", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제1항에 있어서, 상기 머신 러닝 모델은 상기 하나 이상의 단백질의 분자 용출 특성의 예측치를 생성하도록 추가로 훈련되는 것인 방법."}
{"patent_id": "10-2025-7005193", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제1항에 있어서, 상기 머신 러닝 모델은 상기 하나 이상의 단백질의 유출(flow-through) 특성의 예측치를 생성하도록 추가로 훈련되는 것인 방법."}
{"patent_id": "10-2025-7005193", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제1항에 있어서, 상기 분자 설명자 행렬을 감소시키는 것은 상기 분자 설명자 행렬의 특징 벡터의 피어슨 상관관계(Pearson's correlation)를 수행하여 복수의 특징 벡터 클러스터를 생성하는 것을 포함하는 것인 방법."}
{"patent_id": "10-2025-7005193", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_21", "content": "제20항에 있어서, 상기 복수의 특징 벡터 클러스터 각각에 대해 선택된 하나의 대표 특징 벡터는 유사한 특징벡터 중 2개 이상을 나타내는 데 사용되는 복수의 특징 벡터 클러스터 각각에 대한 중심 특징 벡터를 포함하는공개특허 10-2025-0053066-5-것인 방법."}
{"patent_id": "10-2025-7005193", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_22", "content": "제1항에 있어서, 상기 복수의 특징 벡터 클러스터 각각에 대해 선택된 대표 특징 벡터 중 하나 이상의 대표 특징 벡터를 결정하는 것은 상기 복수의 특징 벡터 클러스터 각각에 대해 선택된 대표 특징 벡터 중 k-베스트(best) 특징 벡터 행렬을 선택하는 것을 포함하는 것인 방법."}
{"patent_id": "10-2025-7005193", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_23", "content": "제22항에 있어서, 상기 선택된 대표 특징 벡터의 k-베스트 특징 벡터 행렬은 사전결정된 k-베스트 프로세스에기초하여 결정되는 것인 방법."}
{"patent_id": "10-2025-7005193", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_24", "content": "제1항에 있어서, 상기 선택된 대표 특징 벡터 및 상기 사전결정된 일괄 결합 데이터 간의 상관관계는 상기 선택된 대표 특징 벡터 및 상기 사전결정된 일괄 결합 데이터 간의 최대 정보 계수(MIC)에 기초하여 결정되는 것인방법."}
{"patent_id": "10-2025-7005193", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_25", "content": "제1항에 있어서, 상기 하나 이상의 단백질의 분자 결합 특성의 예측치는 컴퓨팅 모델(computational model) 기반 크로마토그래피 프로세스를 포함하는 것인 방법."}
{"patent_id": "10-2025-7005193", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_26", "content": "제25항에 있어서, 상기 컴퓨팅 모델 기반 크로마토그래피 프로세스는 컴퓨팅 모델 기반 친화성 크로마토그래피프로세스, 이온 교환 크로마토그래피(IEX) 프로세스, 소수성 상호작용 크로마토그래피(HIC) 프로세스, 또는 혼합 모드 크로마토그래피(MMC) 프로세스 중 하나 이상을 포함하는 것인 방법."}
{"patent_id": "10-2025-7005193", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_27", "content": "제1항에 있어서, 베이지안 모델 최적화 프로세스(Bayesian model-optimization process)에 기초하여 상기 머신 러닝 모델을 최적화하는 단계를 더 포함하는 방법."}
{"patent_id": "10-2025-7005193", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_28", "content": "제27항에 있어서, 그룹 K-폴드 교차 검증을 활용하여 상기 하나 이상의 가장 예측적인 특징 벡터, 상기 사전결정된 일괄 결합 데이터, 상기 하이퍼 매개변수 세트, 및 상기 학습가능 매개변수 세트에 기초하여 최적화된 머신 러닝 모델을 훈련 및 평가하는 단계를 더 포함하는 방법."}
{"patent_id": "10-2025-7005193", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_29", "content": "제1항에 있어서, 상기 하나 이상의 단백질의 분자 결합 특성의 예측치는 상기 하나 이상의 단백질의 표적 단백질의 확인을 포함하는 것인 방법."}
{"patent_id": "10-2025-7005193", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_30", "content": "제1항에 있어서, 상기 하나 이상의 단백질의 분자 결합 특성의 예측치는 상기 하나 이상의 단백질의 정량적 구조 특성 관계(QSPR) 또는 정량적 구조 활성 관계(QSAR) 모델링을 포함하는 것인 방법."}
{"patent_id": "10-2025-7005193", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_31", "content": "제1항에 있어서, 상기 하나 이상의 단백질의 분자 결합 특성의 예측치는 상기 하나 이상의 단백질에 상응하는공개특허 10-2025-0053066-6-아미노산 서열 세트의 각 아미노산 서열에 대한 분자 결합 특성의 예측치를 포함하는 것인 방법."}
{"patent_id": "10-2025-7005193", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_32", "content": "하나 이상의 컴퓨팅 장치를 포함하는 시스템으로서, 명령어를 포함하는 하나 이상의 비일시적 컴퓨터 판독가능 저장 매체, 및상기 하나 이상의 저장 매체에 결합된 하나 이상의 프로세서를 더 포함하며, 상기 하나 이상의 프로세서는 상기 명령어를 실행하여하나 이상의 단백질에 상응하는 아미노산 서열 세트를 나타내는 분자 설명자 행렬에 액세스하고,상기 하나 이상의 단백질의 분자 결합 특성의 예측치를 생성하도록 훈련된 머신 러닝 모델과 관련된 하이퍼 매개변수 세트를 정밀화하도록 구성되고, 여기서 상기 하이퍼 매개변수 세트를 정밀화하는 것은 원하는 정밀도에 도달할 때까지 프로세스를 반복적으로실행하는 것을 포함하고, 상기 프로세스는,복수의 특징 벡터 클러스터 각각에 대해 하나의 대표 특징 벡터를 선택함으로써 상기 분자 설명자 행렬을 감소시키고, 여기서 각각의 특징 벡터 클러스터는 유사한 특징 벡터를 포함하고,상기 하나 이상의 단백질과 관련된 사전결정된 일괄 결합 데이터 및 상기 선택된 대표 특징 벡터 간의 상관관계에 기초하여 상기 복수의 특징 벡터 클러스터 각각에 대해 선택된 대표 특징 벡터 중 하나 이상의 대표 특징 벡터를 결정하며,하나 이상의 가장 예측적인 특징 벡터 및 상기 사전결정된 일괄 결합 데이터에 적어도 부분적으로 기초하여 하나 이상의 교차 검증 손실을 계산하고,상기 하나 이상의 교차 검증 손실에 기초하여 상기 하이퍼 매개변수 세트를 업데이트하기 위한명령어를 포함하고,상기 머신 러닝 모델에 의해, 상기 업데이트된 하이퍼 매개변수 세트에 적어도 부분적으로 기초하여 상기 하나이상의 단백질의 분자 결합 특성의 예측치를 출력하기 위한명령어를 실행하도록 구성되는 것인 시스템."}
{"patent_id": "10-2025-7005193", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_33", "content": "제32항에 있어서, 상기 하나 이상의 교차 검증 손실을 계산하기 위한 명령어는,상기 하나 이상의 가장 예측적인 특징 벡터, 상기 사전결정된 일괄 결합 데이터, 상기 하이퍼 매개변수 세트,및 상기 머신 러닝 모델과 관련된 학습가능 매개변수 세트에 기초하여 교차 검증 손실 함수를 평가하고,상기 하나 이상의 가장 예측적인 특징 벡터, 상기 사전결정된 일괄 결합 데이터, 및 상기 하이퍼 매개변수 세트는 일정하게 유지시키면서 상기 학습가능 매개변수 세트를 변경함으로써 상기 교차 검증 손실 함수를 최소화하기 위한명령어를 더 포함하는 것인 시스템."}
{"patent_id": "10-2025-7005193", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_34", "content": "제33항에 있어서, 상기 교차 검증 손실 함수를 최소화하기 위한 명령어는 상기 하이퍼 매개변수 세트를 최적화하기 위한 명령어를포함하고, 상기 하이퍼 매개변수 세트는 일반 매개변수 세트, 부스터 매개변수 세트, 또는 학습 과제 매개변수 세트 중 하나 이상을 포함하는 것인 시스템.공개특허 10-2025-0053066-7-청구항 35 제33항에 있어서, 상기 교차 검증 손실 함수를 최소화하기 위한 명령어는 상기 하나 이상의 단백질에 대한 단백질 결합 백분율의 예측치 및 상기 하나 이상의 단백질에 대한 실험적으로 결정된 단백질 결합 백분율 간의 손실을 최소화하기 위한 명령어를 포함하는 것인 시스템."}
{"patent_id": "10-2025-7005193", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_36", "content": "제33항에 있어서, 상기 사전결정된 일괄 결합 데이터는 상기 하나 이상의 단백질의 분자 결합 특성과 관련된 하나 이상의 pH 값 및 염 농도에 대해 실험적으로 결정된 단백질 결합 백분율을 포함하는 것인 시스템."}
{"patent_id": "10-2025-7005193", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_37", "content": "제33항에 있어서, 상기 학습가능 매개변수 세트는 상기 하나 이상의 가장 예측적인 특징 벡터 및 상기 사전결정된 일괄 결합 데이터에 적어도 부분적으로 기초하여 상기 머신 러닝 모델에 의해 결정되는 하나 이상의 가중치또는 결정 변수를 포함하는 것인 시스템."}
{"patent_id": "10-2025-7005193", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_38", "content": "제32항에 있어서, 상기 명령어는상기 하이퍼 매개변수 세트를 정밀화한 후,하나 이상의 제2 단백질에 상응하는 제2 아미노산 서열 세트를 나타내는 제2 분자 설명자 행렬에 액세스하고,상기 제2 분자 설명자 행렬의 제2 복수의 특징 벡터 클러스터 각각에 대해 하나의 대표 특징 벡터를 선택함으로써 상기 제2 분자 설명자 행렬을 감소시키며,상기 하나 이상의 제2 단백질과 관련된 사전결정된 일괄 결합 데이터 및 상기 선택된 대표 특징 벡터 간의 제2상관관계에 기초하여 각각의 특징 벡터 클러스터에 대해 상기 선택된 대표 특징 벡터 중 하나 이상의 제2 가장예측적인 특징 벡터를 결정하고,상기 하나 이상의 제2 단백질의 분자 결합 특성의 예측치를 생성하도록 훈련된 상기 머신 러닝 모델에 상기 하나 이상의 제2 가장 예측적인 특징 벡터를 입력하고, 상기 머신 러닝 모델에 의해, 상기 업데이트된 하이퍼 매개변수 세트에 적어도 부분적으로 기초하여 상기 하나이상의 제2 단백질의 분자 결합 특성의 예측치를 출력하기 위한명령어를 더 포함하는 것인 시스템."}
{"patent_id": "10-2025-7005193", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_39", "content": "제38항에 있어서, 상기 하나 이상의 제2 단백질의 분자 결합 특성의 예측치는 상기 하나 이상의 제2 단백질에대한 단백질 결합 백분율의 예측치를 포함하는 것인 시스템."}
{"patent_id": "10-2025-7005193", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_40", "content": "제32항에 있어서, 상기 업데이트된 하이퍼 매개변수 세트는 업데이트된 일반 매개변수 세트, 업데이트된 부스터매개변수 세트, 또는 업데이트된 학습 과제 매개변수 세트 중 하나 이상을 포함하는 것인 시스템."}
{"patent_id": "10-2025-7005193", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_41", "content": "제32항에 있어서, 상기 하나 이상의 교차 검증 손실을 계산하기 위한 명령어는 n개의 교차 검증 손실을 계산하기 위한 명령어를더 포함하고, n은 1 내지 n으로부터의 정수를 포함하는 것인 시스템."}
{"patent_id": "10-2025-7005193", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_42", "content": "제32항에 있어서, 공개특허 10-2025-0053066-8-상기 하나 이상의 교차 검증 손실을 계산하기 위한 명령어는 상기 하나 이상의 가장 예측적인 특징 벡터 및 상기 사전결정된 일괄 결합 데이터에 기초하여 n개의 개별 훈련-테스트 분할을 결정하기 위한 명령어를 더 포함하고, n은 1 내지 n으로부터의 정수를 포함하는 것인 시스템."}
{"patent_id": "10-2025-7005193", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_43", "content": "제32항에 있어서, 상기 하나 이상의 교차 검증 손실을 계산하기 위한 명령어는 n개의 교차 검증 손실을 계산하기 위한 명령어를더 포함하고, 상기 명령어는 상기 n개의 교차 검증 손실의 평균에 기초하여 상기 하나 이상의 단백질의 분자 결합 특성의 예측치를 생성하기 위한 명령어를 더 포함하는 것인 시스템."}
{"patent_id": "10-2025-7005193", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_44", "content": "제32항에 있어서, 상기 분자 설명자 행렬은 2n개의 특징 벡터를 포함하고, n은 상기 분자 설명자 행렬의 차원을 포함하는 것인 시스템."}
{"patent_id": "10-2025-7005193", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_45", "content": "제32항에 있어서, 상기 분자 설명자 행렬은 상기 머신 러닝 모델과는 별개의 제1 머신 러닝 모델에 의해 생성되었던 것인 시스템."}
{"patent_id": "10-2025-7005193", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_46", "content": "제45항에 있어서, 상기 제1 머신 러닝 모델은 상기 아미노산 서열 세트에 기초하여 상기 분자 설명자 행렬을 생성하도록 훈련되었던 것인 시스템."}
{"patent_id": "10-2025-7005193", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_47", "content": "제45항에 있어서, 상기 제1 머신 러닝 모델은 상기 아미노산 서열 세트를 나타내는 M x N 설명자 행렬을 생성하도록 훈련된 신경망을 포함하고, N은 상기 아미노산 서열 세트의 수를 포함하고, M은 상기 신경망의 출력 계층 내 노드의 수를 포함하는 것인 시스템."}
{"patent_id": "10-2025-7005193", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_48", "content": "제32항에 있어서, 상기 머신 러닝 모델은 그래디언트 부스팅 모델, 적응형 부스팅(AdaBoost) 모델, 익스트림 그래디언트 부스팅(XGBoost) 모델, 라이트 그래디언트 부스티드 머신(LightGBM) 모델, 또는 범주형 부스팅(CatBoost) 모델 중 하나 이상을 포함하는 것인 시스템."}
{"patent_id": "10-2025-7005193", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_49", "content": "제32항에 있어서, 상기 머신 러닝 모델은 상기 하나 이상의 단백질의 분자 용출 특성의 예측치를 생성하도록 추가로 훈련되는 것인 시스템."}
{"patent_id": "10-2025-7005193", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_50", "content": "제32항에 있어서, 상기 머신 러닝 모델은 상기 하나 이상의 단백질의 유출 특성의 예측치를 생성하도록 추가로훈련되는 것인 시스템."}
{"patent_id": "10-2025-7005193", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_51", "content": "공개특허 10-2025-0053066-9-제32항에 있어서, 상기 분자 설명자 행렬을 감소시키기 위한 명령어는 상기 분자 설명자 행렬의 특징 벡터의 피어슨 상관관계를 수행하여 상기 복수의 특징 벡터 클러스터를 생성하기 위한 명령어를 더 포함하는 것인시스템."}
{"patent_id": "10-2025-7005193", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_52", "content": "제51항에 있어서, 상기 복수의 특징 벡터 클러스터 각각에 대해 선택된 하나의 대표 특징 벡터는 유사한 특징벡터 중 2개 이상을 나타내는 데 사용되는 복수의 특징 벡터 클러스터 각각에 대한 중심 특징 벡터를 포함하는것인 시스템."}
{"patent_id": "10-2025-7005193", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_53", "content": "제32항에 있어서, 상기 복수의 특징 벡터 클러스터 각각에 대해 선택된 대표 특징 벡터 중 하나 이상의 대표 특징 벡터를 결정하기 위한 명령어는 상기 복수의 특징 벡터 클러스터 각각에 대해 선택된 대표 특징 벡터 중 k-베스트 특징 벡터 행렬을 선택하기 위한 명령어를 더 포함하는 것인 시스템."}
{"patent_id": "10-2025-7005193", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_54", "content": "제53항에 있어서, 상기 선택된 대표 특징 벡터의 k-베스트 특징 벡터 행렬은 사전결정된 k-베스트 프로세스에기초하여 결정되는 것인 시스템."}
{"patent_id": "10-2025-7005193", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_55", "content": "제32항에 있어서, 상기 선택된 대표 특징 벡터 및 상기 사전결정된 일괄 결합 데이터 간의 상관관계는 상기 선택된 대표 특징 벡터 및 상기 사전결정된 일괄 결합 데이터 간의 최대 정보 계수(MIC)에 기초하여 결정되는 것인 시스템."}
{"patent_id": "10-2025-7005193", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_56", "content": "제32항에 있어서, 상기 하나 이상의 단백질의 분자 결합 특성의 예측치는 컴퓨팅 모델 기반 크로마토그래피 프로세스를 포함하는 것인 시스템."}
{"patent_id": "10-2025-7005193", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_57", "content": "제56항에 있어서, 상기 컴퓨팅 모델 기반 크로마토그래피 프로세스는 컴퓨팅 모델 기반 친화성 크로마토그래피프로세스, 이온 교환 크로마토그래피(IEX) 프로세스, 소수성 상호작용 크로마토그래피(HIC) 프로세스, 또는 혼합 모드 크로마토그래피(MMC) 프로세스 중 하나 이상을 포함하는 것인 시스템."}
{"patent_id": "10-2025-7005193", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_58", "content": "제32항에 있어서, 상기 명령어는 베이지안 모델 최적화 프로세스에 기초하여 상기 머신 러닝 모델을 최적화하기위한 명령어를 더 포함하는 것인 시스템."}
{"patent_id": "10-2025-7005193", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_59", "content": "제58항에 있어서, 상기 명령어는 그룹 K-폴드 교차 검증을 활용하여 상기 하나 이상의 가장 예측적인 특징벡터, 상기 사전결정된 일괄 결합 데이터, 상기 하이퍼 매개변수 세트, 및 상기 학습가능 매개변수 세트에 기초하여 최적화된 머신 러닝 모델을 훈련 및 평가하기 위한 명령어를 더 포함하는 것인 시스템."}
{"patent_id": "10-2025-7005193", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_60", "content": "제32항에 있어서, 상기 하나 이상의 단백질의 분자 결합 특성의 예측치는 상기 하나 이상의 단백질의 표적 단백질의 확인을 포함하는 것인 시스템."}
{"patent_id": "10-2025-7005193", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_61", "content": "제32항에 있어서, 상기 하나 이상의 단백질의 분자 결합 특성의 예측치는 상기 하나 이상의 단백질의 정량적 구조 특성 관계(QSPR) 또는 정량적 구조 활성 관계(QSAR) 모델링을 포함하는 것인 시스템.공개특허 10-2025-0053066-10-청구항 62 제32항에 있어서, 상기 하나 이상의 단백질의 분자 결합 특성의 예측치는 상기 하나 이상의 단백질에 상응하는아미노산 서열 세트의 각 아미노산 서열에 대한 분자 결합 특성의 예측치를 포함하는 것인 시스템."}
{"patent_id": "10-2025-7005193", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_63", "content": "명령어를 포함하는 비일시적 컴퓨터 판독가능 매체로서, 상기 명령어는 하나 이상의 컴퓨팅 장치의 하나 이상의 프로세서에 의해 실행될 때 상기 하나 이상의 프로세서로 하여금 하나 이상의 단백질에 상응하는 아미노산 서열 세트를 나타내는 분자 설명자 행렬에 액세스하게 하고, 상기 하나 이상의 단백질의 분자 결합 특성의 예측치를 생성하도록 훈련된 머신 러닝 모델과 관련된 하이퍼 매개변수 세트를 정밀화하게 하며, 여기서 상기 하이퍼 매개변수 세트를 정밀화하는 것은 원하는 정밀도에 도달할 때까지 프로세스를 반복적으로실행하는 것을 포함하고, 상기 프로세스는,복수의 특징 벡터 클러스터 각각에 대해 하나의 대표 특징 벡터를 선택함으로써 상기 분자 설명자 행렬을 감소시키고, 여기서 각각의 특징 벡터 클러스터는 유사한 특징 벡터를 포함하고,상기 하나 이상의 단백질과 관련된 사전결정된 일괄 결합 데이터 및 상기 선택된 대표 특징 벡터 간의 상관관계에 기초하여 상기 복수의 특징 벡터 클러스터 각각에 대해 선택된 대표 특징 벡터 중 하나 이상의 대표 특징 벡터를 결정하며,하나 이상의 가장 예측적인 특징 벡터 및 상기 사전결정된 일괄 결합 데이터에 적어도 부분적으로 기초하여 하나 이상의 교차 검증 손실을 계산하고,상기 하나 이상의 교차 검증 손실에 기초하여 상기 하이퍼 매개변수 세트를 업데이트하게 하는 명령어를 포함하며,상기 머신 러닝 모델에 의해, 상기 업데이트된 하이퍼 매개변수 세트에 적어도 부분적으로 기초하여 상기 하나이상의 단백질의 분자 결합 특성의 예측치를 출력하게 하는 것인 비일시적 컴퓨터 판독가능 매체."}
{"patent_id": "10-2025-7005193", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_64", "content": "제63항에 있어서, 상기 하나 이상의 교차 검증 손실을 계산하기 위한 명령어는,상기 하나 이상의 가장 예측적인 특징 벡터, 상기 사전결정된 일괄 결합 데이터, 상기 하이퍼 매개변수 세트,및 상기 머신 러닝 모델과 관련된 학습가능 매개변수 세트에 기초하여 교차 검증 손실 함수를 평가하고,상기 하나 이상의 가장 예측적인 특징 벡터, 상기 사전결정된 일괄 결합 데이터, 및 상기 하이퍼 매개변수 세트는 일정하게 유지시키면서 상기 학습가능 매개변수 세트를 변경함으로써 상기 교차 검증 손실 함수를 최소화하기 위한명령어를 더 포함하는 것인 비일시적 컴퓨터 판독가능 매체."}
{"patent_id": "10-2025-7005193", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_65", "content": "제64항에 있어서, 상기 교차 검증 손실 함수를 최소화하기 위한 명령어는 상기 하이퍼 매개변수 세트를 최적화하기 위한 명령어를포함하고, 상기 하이퍼 매개변수 세트는 일반 매개변수 세트, 부스터 매개변수 세트, 또는 학습 과제 매개변수 세트 중 하나 이상을 포함하는 것인 비일시적 컴퓨터 판독가능 매체."}
{"patent_id": "10-2025-7005193", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_66", "content": "공개특허 10-2025-0053066-11-제64항에 있어서, 상기 교차 검증 손실 함수를 최소화하기 위한 명령어는 상기 하나 이상의 단백질에 대한 단백질 결합 백분율의 예측치 및 상기 하나 이상의 단백질에 대한 실험적으로 결정된 단백질 결합 백분율 간의 손실을 최소화하기 위한 명령어를 포함하는 것인 비일시적 컴퓨터 판독가능 매체."}
{"patent_id": "10-2025-7005193", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_67", "content": "제64항에 있어서, 상기 사전결정된 일괄 결합 데이터는 상기 하나 이상의 단백질의 분자 결합 특성과 관련된 하나 이상의 pH 값 및 염 농도에 대해 실험적으로 결정된 단백질 결합 백분율을 포함하는 것인 비일시적 컴퓨터판독가능 매체."}
{"patent_id": "10-2025-7005193", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_68", "content": "제64항에 있어서, 상기 학습가능 매개변수 세트는 상기 하나 이상의 가장 예측적인 특징 벡터 및 상기 사전결정된 일괄 결합 데이터에 적어도 부분적으로 기초하여 상기 머신 러닝 모델에 의해 결정되는 하나 이상의 가중치또는 결정 변수를 포함하는 것인 비일시적 컴퓨터 판독가능 매체."}
{"patent_id": "10-2025-7005193", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_69", "content": "제63항에 있어서, 상기 명령어는,상기 하이퍼 매개변수 세트를 정밀화한 후:하나 이상의 제2 단백질에 상응하는 제2 아미노산 서열 세트를 나타내는 제2 분자 설명자 행렬에 액세스하고,상기 제2 분자 설명자 행렬의 제2 복수의 특징 벡터 클러스터 각각에 대해 하나의 대표 특징 벡터를 선택함으로써 상기 제2 분자 설명자 행렬을 감소시키며,상기 하나 이상의 제2 단백질과 관련된 사전결정된 일괄 결합 데이터 및 상기 선택된 대표 특징 벡터 간의 제2상관관계에 기초하여 각각의 특징 벡터 클러스터에 대해 상기 선택된 대표 특징 벡터 중 하나 이상의 제2 가장예측적인 특징 벡터를 결정하고,상기 하나 이상의 제2 단백질의 분자 결합 특성의 예측치를 생성하도록 훈련된 상기 머신 러닝 모델에 상기 하나 이상의 제2 가장 예측적인 특징 벡터를 입력하며, 및상기 머신 러닝 모델에 의해, 상기 업데이트된 하이퍼 매개변수 세트에 적어도 부분적으로 기초하여 상기 하나이상의 제2 단백질의 분자 결합 특성의 예측치를 출력하기 위한명령어를 더 포함하는 것인 비일시적 컴퓨터 판독가능 매체."}
{"patent_id": "10-2025-7005193", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_70", "content": "제68항에 있어서, 상기 하나 이상의 제2 단백질의 분자 결합 특성의 예측치는 상기 하나 이상의 제2 단백질의제2 단백질 결합 백분율의 예측치를 포함하는 것인 비일시적 컴퓨터 판독가능 매체."}
{"patent_id": "10-2025-7005193", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_71", "content": "제63항에 있어서, 업데이트된 하이퍼 매개변수 세트는 업데이트된 일반 매개변수 세트, 업데이트된 부스터 매개변수 세트, 또는 업데이트된 학습 과제 매개변수 세트 중 하나 이상을 포함하는 것인 비일시적 컴퓨터 판독가능매체."}
{"patent_id": "10-2025-7005193", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_72", "content": "제63항에 있어서, 상기 하나 이상의 교차 검증 손실을 계산하기 위한 명령어는 n개의 교차 검증 손실을 계산하기 위한 명령어를더 포함하고, n은 1 내지 n으로부터의 정수를 포함하는 것인 비일시적 컴퓨터 판독가능 매체."}
{"patent_id": "10-2025-7005193", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_73", "content": "제63항에 있어서, 공개특허 10-2025-0053066-12-상기 하나 이상의 교차 검증 손실을 계산하기 위한 명령어는, 상기 하나 이상의 가장 예측적인 특징 벡터 및 상기 사전결정된 일괄 결합 데이터에 기초하여 n개의 개별 훈련-테스트 분할을 결정하기 위한 명령어를 더 포함하고, n은 1 내지 n으로부터의 정수를 포함하는 것인 비일시적 컴퓨터 판독가능 매체."}
{"patent_id": "10-2025-7005193", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_74", "content": "제63항에 있어서, 상기 하나 이상의 교차 검증 손실을 계산하기 위한 명령어는 n개의 교차 검증 손실을 계산하기 위한 명령어를더 포함하고, 상기 명령어는 상기 n개의 교차 검증 손실의 평균에 기초하여 상기 하나 이상의 단백질의 분자 결합 특성의 예측치를 생성하기 위한 명령어를 더 포함하는 것인 비일시적 컴퓨터 판독가능 매체."}
{"patent_id": "10-2025-7005193", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_75", "content": "제63항에 있어서, 상기 분자 설명자 행렬은 2n개의 특징 벡터를 포함하고, n은 상기 분자 설명자 행렬의 차원을 포함하는 것인 비일시적 컴퓨터 판독가능 매체."}
{"patent_id": "10-2025-7005193", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_76", "content": "제63항에 있어서, 상기 분자 설명자 행렬은 상기 머신 러닝 모델과는 별개의 제1 머신 러닝 모델에 의해 생성되었던 것인 비일시적 컴퓨터 판독가능 매체."}
{"patent_id": "10-2025-7005193", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_77", "content": "제76항에 있어서, 상기 제1 머신 러닝 모델은 상기 아미노산 서열 세트에 기초하여 상기 분자 설명자 행렬을 생성하도록 훈련되었던 것인 비일시적 컴퓨터 판독가능 매체."}
{"patent_id": "10-2025-7005193", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_78", "content": "제76항에 있어서, 상기 제1 머신 러닝 모델은 상기 아미노산 서열 세트를 나타내는 M x N 설명자 행렬을 생성하도록 훈련된 신경망을 포함하고, N은 상기 아미노산 서열 세트의 수를 포함하고, M은 상기 신경망의 출력 계층 내 노드의 수를 포함하는 것인 비일시적 컴퓨터 판독가능 매체."}
{"patent_id": "10-2025-7005193", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_79", "content": "제63항에 있어서, 상기 머신 러닝 모델은 그래디언트 부스팅 모델, 적응형 부스팅(AdaBoost) 모델, 익스트림 그래디언트 부스팅(XGBoost) 모델, 라이트 그래디언트 부스티드 머신(LightGBM) 모델, 또는 범주형 부스팅(CatBoost) 모델 중 하나 이상을 포함하는 것인 비일시적 컴퓨터 판독가능 매체."}
{"patent_id": "10-2025-7005193", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_80", "content": "제63항에 있어서, 상기 머신 러닝 모델은 상기 하나 이상의 단백질의 분자 용출 특성의 예측치를 생성하도록 추가로 훈련되는 것인 비일시적 컴퓨터 판독가능 매체."}
{"patent_id": "10-2025-7005193", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_81", "content": "제63항에 있어서, 상기 머신 러닝 모델은 상기 하나 이상의 단백질의 유출 특성의 예측치를 생성하도록 추가로훈련되는 것인 비일시적 컴퓨터 판독가능 매체."}
{"patent_id": "10-2025-7005193", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_82", "content": "공개특허 10-2025-0053066-13-제63항에 있어서, 상기 분자 설명자 행렬을 감소시키기 위한 명령어는 상기 분자 설명자 행렬의 특징 벡터의 피어슨 상관관계를 수행하여 상기 복수의 특징 벡터 클러스터를 생성하기 위한 명령어를 더 포함하는 것인 비일시적 컴퓨터 판독가능 매체."}
{"patent_id": "10-2025-7005193", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_83", "content": "제82항에 있어서, 상기 복수의 특징 벡터 클러스터 각각에 대해 선택된 하나의 대표 특징 벡터는 유사한 특징벡터 중 2개 이상을 나타내는 데 사용되는 복수의 특징 벡터 클러스터 각각에 대한 중심 특징 벡터를 포함하는것인 비일시적 컴퓨터 판독가능 매체."}
{"patent_id": "10-2025-7005193", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_84", "content": "제63항에 있어서, 상기 복수의 특징 벡터 클러스터 각각에 대해 선택된 대표 특징 벡터 중 하나 이상의 대표 특징 벡터를 결정하기 위한 명령어는 상기 복수의 특징 벡터 클러스터 각각에 대해 선택된 대표 특징 벡터 중 k-베스트 특징 벡터 행렬을 선택하기 위한 명령어를 더 포함하는 것인 비일시적 컴퓨터 판독가능 매체."}
{"patent_id": "10-2025-7005193", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_85", "content": "제84항에 있어서, 상기 선택된 대표 특징 벡터의 k-베스트 특징 벡터 행렬은 사전결정된 k-베스트 프로세스에기초하여 결정되는 것인 비일시적 컴퓨터 판독가능 매체."}
{"patent_id": "10-2025-7005193", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_86", "content": "제63항에 있어서, 상기 선택된 대표 특징 벡터 및 상기 사전결정된 일괄 결합 데이터 간의 상관관계는 상기 선택된 대표 특징 벡터 및 상기 사전결정된 일괄 결합 데이터 간의 최대 정보 계수(MIC)에 기초하여 결정되는 것인 비일시적 컴퓨터 판독가능 매체."}
{"patent_id": "10-2025-7005193", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_87", "content": "제63항에 있어서, 상기 하나 이상의 단백질의 분자 결합 특성의 예측치는 컴퓨팅 모델 기반 컬럼 크로마토그래피 프로세스를 포함하는 것인 비일시적 컴퓨터 판독가능 매체."}
{"patent_id": "10-2025-7005193", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_88", "content": "제87항에 있어서, 상기 컴퓨팅 모델 기반 크로마토그래피 프로세스는 컴퓨팅 모델 기반 친화성 크로마토그래피프로세스, 이온 교환 크로마토그래피(IEX) 프로세스, 소수성 상호작용 크로마토그래피(HIC) 프로세스, 또는 혼합 모드 크로마토그래피(MMC) 프로세스 중 하나 이상을 포함하는 것인 비일시적 컴퓨터 판독가능 매체."}
{"patent_id": "10-2025-7005193", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_89", "content": "제63항에 있어서, 상기 명령어는 베이지안 모델 최적화 프로세스에 기초하여 상기 머신 러닝 모델을 최적화하기위한 명령어를 더 포함하는 비일시적 컴퓨터 판독가능 매체."}
{"patent_id": "10-2025-7005193", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_90", "content": "제89항에 있어서, 상기 명령어는 그룹 K-폴드 교차 검증을 활용하여 상기 하나 이상의 가장 예측적인 특징벡터, 상기 사전결정된 일괄 결합 데이터, 상기 하이퍼 매개변수 세트, 및 상기 학습가능 매개변수 세트에 기초하여 최적화된 머신 러닝 모델을 훈련 및 평가하기 위한 명령어를 더 포함하는 것인 비일시적 컴퓨터 판독가능매체."}
{"patent_id": "10-2025-7005193", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_91", "content": "제63항에 있어서, 상기 하나 이상의 단백질의 분자 결합 특성의 예측치는 상기 하나 이상의 단백질의 표적 단백질의 확인을 포함하는 것인 비일시적 컴퓨터 판독가능 매체."}
{"patent_id": "10-2025-7005193", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_92", "content": "제63항에 있어서, 상기 하나 이상의 단백질의 분자 결합 특성의 예측치는 상기 하나 이상의 단백질의 정량적 구조 특성 관계(QSPR) 또는 정량적 구조 활성 관계(QSAR) 모델링을 포함하는 것인 비일시적 컴퓨터 판독가능공개특허 10-2025-0053066-14-매체."}
{"patent_id": "10-2025-7005193", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_93", "content": "제63항에 있어서, 상기 하나 이상의 단백질의 분자 결합 특성의 예측치는 상기 하나 이상의 단백질에 상응하는아미노산 서열 세트의 각 아미노산 서열에 대한 분자 결합 특성의 예측치를 포함하는 것인 비일시적 컴퓨터 판독가능 매체."}
{"patent_id": "10-2025-7005193", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_94", "content": "하나 이상의 컴퓨팅 장치에 의해, 하나 이상의 단백질의 분자 결합 특성을 예측하기 위한 방법으로서, 하나 이상의 단백질에 상응하는 아미노산 서열 세트를 나타내는 분자 설명자 행렬에 액세스하는 단계, 및머신 러닝 모델에 의해, 상기 분자 설명자 행렬에 적어도 부분적으로 기초하여 상기 하나 이상의 단백질의 분자결합 특성의 예측치를 획득하는 단계를 포함하고, 상기 머신 러닝 모델은,하나 이상의 실증적으로 평가된 단백질에 상응하는 아미노산 서열의 훈련 세트를 나타내는 훈련 분자 설명자 행렬에 액세스하고,요망 정밀도에 도달할 때까지 상기 머신 러닝 모델과 관련된 하이퍼 매개변수 세트를 정밀화하도록 프로세스를반복적으로 실행하는 것에 의해 훈련되며, 상기 프로세스는,복수의 특징 벡터 클러스터 각각에 대해 하나의 대표 특징 벡터를 선택함으로써 상기 훈련 분자 설명자 행렬을감소시키고, 여기서 각각의 특징 벡터 클러스터는 유사한 특징 벡터를 포함하고,상기 하나 이상의 실증적으로 평가된 단백질과 관련된 사전결정된 일괄 결합 데이터 및 상기 선택된 대표 특징벡터 간의 상관관계에 기초하여 각각의 특징 벡터 클러스터에 대해 상기 선택된 대표 특징 벡터 중 하나 이상의가장 예측적인 특징 벡터를 결정하며,상기 하나 이상의 가장 예측적인 특징 벡터 및 상기 사전결정된 일괄 결합 데이터에 적어도 부분적으로 기초하여 하나 이상의 교차 검증 손실을 계산하고,상기 하나 이상의 교차 검증 손실에 기초하여 상기 하이퍼 매개변수 세트를 업데이트하는 것인 방법."}
{"patent_id": "10-2025-7005193", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_95", "content": "제94항에 있어서, 상기 예측치를 획득하는 단계는,상기 분자 설명자 행렬의 복수의 특징 벡터 클러스터 각각에 대해 하나의 대표 특징 벡터를 선택함으로써 상기분자 설명자 행렬을 감소시키고,상기 하나 이상의 단백질과 관련된 사전결정된 일괄 결합 데이터 및 상기 선택된 특징 벡터 간의 상관관계에 기초하여 각각의 특징 벡터 클러스터에 대해 상기 선택된 대표 특징 벡터 중 하나 이상의 가장 예측적인 특징 벡터를 결정하며,상기 하나 이상의 단백질의 분자 결합 특성의 예측치를 획득하도록 상기 머신 러닝 모델에 상기 하나 이상의 가장 예측적인 특징 벡터를 입력하는 것을 포함하는 것인 방법."}
{"patent_id": "10-2025-7005193", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_96", "content": "제94항에 있어서, 상기 하나 이상의 단백질의 분자 결합 특성의 예측치는 상기 하나 이상의 단백질에 대한 단백질 결합 백분율의 예측치를 포함하는 것인 방법.공개특허 10-2025-0053066-15-청구항 97 제94항에 있어서, 상기 하나 이상의 교차 검증 손실을 계산하는 것은, 상기 하나 이상의 가장 예측적인 특징 벡터, 상기 사전결정된 일괄 결합 데이터, 상기 하이퍼 매개변수 세트,및 상기 머신 러닝 모델과 관련된 학습가능 매개변수 세트에 기초하여 교차 검증 손실 함수를 평가하고,상기 하나 이상의 가장 예측적인 특징 벡터, 상기 사전결정된 일괄 결합 데이터, 및 상기 하이퍼 매개변수 세트는 일정하게 유지시키면서 상기 학습가능 매개변수 세트를 변경함으로써 상기 교차 검증 손실 함수를 최소화하는 것을 더 포함하는 것인 방법."}
{"patent_id": "10-2025-7005193", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_98", "content": "제97항에 있어서, 상기 교차 검증 손실 함수를 최소화하는 것은 상기 하이퍼 매개변수 세트를 최적화하는 것을 포함하고, 상기 하이퍼 매개변수 세트는 일반 매개변수 세트, 부스터 매개변수 세트, 또는 학습 과제 매개변수 세트 중 하나 이상을 포함하는 것인 방법."}
{"patent_id": "10-2025-7005193", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_99", "content": "제97항에 있어서, 상기 교차 검증 손실 함수를 최소화하는 것은 상기 하나 이상의 단백질에 대한 단백질 결합백분율의 예측치 및 상기 하나 이상의 단백질에 대한 실험적으로 결정된 단백질 결합 백분율 간의 손실을 최소화하는 것을 포함하는 것인 방법."}
{"patent_id": "10-2025-7005193", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_100", "content": "제97항에 있어서, 상기 사전결정된 일괄 결합 데이터는 상기 하나 이상의 단백질의 분자 결합 특성과 관련된 하나 이상의 pH 값 및 염 농도에 대해 실험적으로 결정된 단백질 결합 백분율을 포함하는 것인 방법."}
{"patent_id": "10-2025-7005193", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_101", "content": "제97항에 있어서, 상기 학습가능 매개변수 세트는 상기 하나 이상의 가장 예측적인 특징 벡터 및 상기 사전결정된 일괄 결합 데이터에 적어도 부분적으로 기초하여 상기 머신 러닝 모델에 의해 결정되는 하나 이상의 가중치또는 결정 변수를 포함하는 것인 방법."}
{"patent_id": "10-2025-7005193", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_102", "content": "제94항에 있어서, 상기 분자 설명자 행렬은 하나 이상의 제1 단백질에 상응하는 제1 아미노산 서열 세트를 나타내는 제1 분자 설명자 행렬을 포함하고, 상기 분자 결합 특성의 예측치는 상기 하나 이상의 제1 단백질의 분자 결합 특성의 제1 예측치를 포함하며, 상기 방법은,하나 이상의 제2 단백질에 상응하는 제2 아미노산 서열 세트를 나타내는 제2 분자 설명자 행렬에 액세스하는 단계, 및상기 머신 러닝 모델에 의해, 상기 제2 분자 설명자 행렬에 적어도 부분적으로 기초하여 상기 하나 이상의 제2단백질의 분자 결합 특성의 제2 예측치를 획득하는 단계를 더 포함하는 방법."}
{"patent_id": "10-2025-7005193", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_103", "content": "제102항에 있어서, 상기 머신 러닝 모델은,상기 제2 분자 설명자 행렬의 제2 복수의 특징 벡터 클러스터 각각에 대해 하나의 대표 특징 벡터를 선택함으로공개특허 10-2025-0053066-16-써 상기 제2 분자 설명자 행렬을 감소시키고,상기 하나 이상의 제2 단백질과 관련된 사전결정된 일괄 결합 데이터 및 상기 선택된 대표 특징 벡터 간의 제2상관관계에 기초하여 각각의 특징 벡터 클러스터에 대해 상기 선택된 대표 특징 벡터 중 하나 이상의 제2 가장예측적인 특징 벡터를 결정하며,상기 제2 예측치를 생성하도록 훈련된 상기 머신 러닝 모델에 상기 하나 이상의 제2 가장 예측적인 특징 벡터를입력하도록훈련되는 것인 방법."}
{"patent_id": "10-2025-7005193", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_104", "content": "제102항에 있어서, 상기 하나 이상의 제2 단백질의 분자 결합 특성의 제2 예측치는 상기 하나 이상의 제2 단백질에 대한 단백질 결합 백분율의 예측치를 포함하는 것인 방법."}
{"patent_id": "10-2025-7005193", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_105", "content": "제94항에 있어서, 업데이트된 하이퍼 매개변수 세트는 업데이트된 일반 매개변수 세트, 업데이트된 부스터 매개변수 세트, 또는 업데이트된 학습 과제 매개변수 세트 중 하나 이상을 포함하는 것인 방법."}
{"patent_id": "10-2025-7005193", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_106", "content": "제94항에 있어서, 상기 하나 이상의 단백질의 분자 결합 특성의 예측치를 생성하는데 사용되는 머신 러닝 모델은 업데이트된 하이퍼 매개변수 세트를 포함하는 것인 방법."}
{"patent_id": "10-2025-7005193", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_107", "content": "제94항에 있어서, 상기 하나 이상의 교차 검증 손실을 계산하는 것은 n개의 교차 검증 손실을 계산하는 것을 포함하고, n은 1 내지 n으로부터의 정수를 포함하는 것인 방법."}
{"patent_id": "10-2025-7005193", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_108", "content": "제94항에 있어서, 상기 하나 이상의 교차 검증 손실을 계산하는 것은 상기 하나 이상의 가장 예측적인 특징 벡터 및 상기 사전결정된 일괄 결합 데이터에 기초하여 n개의 개별 훈련-테스트 분할을 결정하는 것을 포함하고, n은 1 내지 n으로부터의 정수를 포함하는 것인 방법."}
{"patent_id": "10-2025-7005193", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_109", "content": "제94항에 있어서, 상기 하나 이상의 교차 검증 손실을 계산하는 것은 n개의 교차 검증 손실을 계산하는 것을 포함하고, 상기 방법은 상기 n개의 교차 검증 손실의 평균에 기초하여 상기 하나 이상의 단백질의 분자 결합 특성의 예측치를 생성하는 단계를 더 포함하는 방법."}
{"patent_id": "10-2025-7005193", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_110", "content": "제94항에 있어서, 상기 분자 설명자 행렬은 상기 머신 러닝 모델과는 별개의 제1 머신 러닝 모델에 의해 생성되었던 것인 방법."}
{"patent_id": "10-2025-7005193", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_111", "content": "제110항에 있어서, 상기 제1 머신 러닝 모델은 상기 아미노산 서열 세트에 기초하여 상기 분자 설명자 행렬을생성하도록 훈련되었던 것인 방법."}
{"patent_id": "10-2025-7005193", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_112", "content": "공개특허 10-2025-0053066-17-제111항에 있어서, 상기 제1 머신 러닝 모델은 상기 아미노산 서열 세트를 나타내는 M x N 설명자 행렬을 생성하도록 훈련된 신경망을 포함하는 것인 방법."}
{"patent_id": "10-2025-7005193", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_113", "content": "제112항에 있어서, N은 상기 아미노산 서열 세트의 수를 포함하고, M은 상기 신경망의 출력 계층 내 노드의 수를 포함하는 것인 방법."}
{"patent_id": "10-2025-7005193", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_114", "content": "제94항에 있어서, 상기 머신 러닝 모델은 그래디언트 부스팅 모델, 적응형 부스팅(AdaBoost) 모델, 익스트림 그래디언트 부스팅(XGBoost) 모델, 라이트 그래디언트 부스티드 머신(LightGBM) 모델, 또는 범주형 부스팅(CatBoost) 모델 중 하나 이상을 포함하는 것인 방법."}
{"patent_id": "10-2025-7005193", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_115", "content": "제94항에 있어서, 상기 머신 러닝 모델은 상기 하나 이상의 단백질의 분자 용출 특성의 예측치를 생성하도록 추가로 훈련되는 것인 방법."}
{"patent_id": "10-2025-7005193", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_116", "content": "제94항에 있어서, 상기 머신 러닝 모델은 상기 하나 이상의 단백질의 유출 특성의 예측치를 생성하도록 추가로훈련되는 것인 방법."}
{"patent_id": "10-2025-7005193", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_117", "content": "제94항에 있어서, 상기 분자 설명자 행렬을 감소시키는 것은 상관관계 거리에 기초하여 유사한 특징 벡터를 복수의 특징 벡터 클러스터로 클러스터링하는 것을 포함하는 것인 방법."}
{"patent_id": "10-2025-7005193", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_118", "content": "제117항에 있어서, 상기 상관관계 거리는 피어슨 상관관계를 사용하여 계산되는 것인 방법."}
{"patent_id": "10-2025-7005193", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_119", "content": "제117항에 있어서, 상기 복수의 특징 벡터 클러스터 각각에 대해 선택된 하나의 대표 특징 벡터는 유사한 특징벡터 중 2개 이상을 나타내는 데 사용되는 복수의 특징 벡터 클러스터 각각에 대한 중심 특징 벡터를 포함하는것인 방법."}
{"patent_id": "10-2025-7005193", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_120", "content": "제94항에 있어서, 상기 복수의 특징 벡터 클러스터 각각에 대해 선택된 대표 특징 벡터 중 하나 이상의 예측적인 특징 벡터를 결정하는 것은 상기 복수의 특징 벡터 클러스터 각각에 대해 선택된 대표 특징 벡터 중 k-베스트 특징 벡터 행렬을 선택하는 것을 포함하는 것인 방법."}
{"patent_id": "10-2025-7005193", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_121", "content": "제120항에 있어서, 상기 선택된 대표 특징 벡터의 k-베스트 특징 벡터 행렬은 사전결정된 k-베스트 프로세스에기초하여 결정되는 것인 방법."}
{"patent_id": "10-2025-7005193", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_122", "content": "제94항에 있어서, 상기 선택된 대표 특징 벡터 및 상기 사전결정된 일괄 결합 데이터 간의 상관관계는 상기 선택된 대표 특징 벡터 및 상기 사전결정된 일괄 결합 데이터 간의 최대 정보 계수(MIC)에 기초하여 결정되는 것인 방법."}
{"patent_id": "10-2025-7005193", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_123", "content": "공개특허 10-2025-0053066-18-제94항에 있어서, 상기 하나 이상의 단백질의 분자 결합 특성의 예측치는 컴퓨팅 모델 기반 크로마토그래피 프로세스를 포함하는 것인 방법."}
{"patent_id": "10-2025-7005193", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_124", "content": "제123항에 있어서, 상기 컴퓨팅 모델 기반 크로마토그래피 프로세스는 컴퓨팅 모델 기반 친화성 크로마토그래피프로세스, 이온 교환 크로마토그래피(IEX) 프로세스, 소수성 상호작용 크로마토그래피(HIC) 프로세스, 또는 혼합 모드 크로마토그래피(MMC) 프로세스 중 하나 이상을 포함하는 것인 방법."}
{"patent_id": "10-2025-7005193", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_125", "content": "제94항에 있어서, 베이지안 모델 최적화 프로세스에 기초하여 상기 머신 러닝 모델을 최적화하는 단계를 더 포함하는 방법."}
{"patent_id": "10-2025-7005193", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_126", "content": "제125항에 있어서, 그룹 K-폴드 교차 검증을 활용하여 상기 하나 이상의 가장 예측적인 특징 벡터, 상기 사전결정된 일괄 결합 데이터, 상기 하이퍼 매개변수 세트, 및 상기 학습가능 매개변수 세트에 기초하여 최적화된 머신 러닝 모델을 훈련 및 평가하는 단계를 더 포함하는 방법."}
{"patent_id": "10-2025-7005193", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_127", "content": "제125항에 있어서, 계층적 K-폴드 교차 검증을 활용하여 상기 하나 이상의 가장 예측적인 특징 벡터, 상기 사전결정된 일괄 결합데이터, 상기 하이퍼 매개변수 세트, 및 상기 학습가능 매개변수 세트에 기초하여 최적화된 머신 러닝 모델을훈련 및 평가하는 단계를 더 포함하는 방법."}
{"patent_id": "10-2025-7005193", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_128", "content": "제94항에 있어서, 상기 하나 이상의 단백질의 분자 결합 특성의 예측치는 상기 하나 이상의 단백질의 표적 단백질의 확인을 포함하는 것인 방법."}
{"patent_id": "10-2025-7005193", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_129", "content": "제94항에 있어서, 상기 하나 이상의 단백질의 분자 결합 특성의 예측치는 상기 하나 이상의 단백질의 정량적 구조 특성 관계(QSPR) 또는 정량적 구조 활성 관계(QSAR) 모델링을 포함하는 것인 방법."}
{"patent_id": "10-2025-7005193", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_130", "content": "제94항에 있어서, 상기 하나 이상의 단백질의 분자 결합 특성의 예측치는 상기 하나 이상의 단백질에 상응하는아미노산 서열 세트의 각 아미노산 서열에 대한 분자 결합 특성의 예측치를 포함하는 것인 방법."}
{"patent_id": "10-2025-7005193", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_131", "content": "제94항에 있어서, 상기 하나 이상의 실증적으로 평가된 단백질 각각에 대해, 상응하는 사전결정된 일괄 결합이실험 조건 세트 각각에 대해 측정되는 것인 방법."}
{"patent_id": "10-2025-7005193", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_132", "content": "제131항에 있어서, 상기 실험 조건 세트는 24개의 실험 조건을 포함하는 것인 방법."}
{"patent_id": "10-2025-7005193", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_133", "content": "공개특허 10-2025-0053066-19-제131항에 있어서, 상기 실험 조건 세트는 염 농도의 제1 서브세트 및 pH 값의 제2 서브세트를 포함하는 것인 방법."}
{"patent_id": "10-2025-7005193", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_134", "content": "제131항에 있어서, 상기 실험 조건 세트는 상기 분자 설명자 행렬을 사용하여 상기 머신 러닝 모델에 입력되고, 상기 하나 이상의 단백질의 분자 결합 특성의 예측치는 상기 실험 조건 세트 각각에 대한 하나 이상의 단백질의분자 결합 특성의 예측치를 포함하는 것인 방법."}
{"patent_id": "10-2025-7005193", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_135", "content": "제94항에 있어서,상기 하나 이상의 단백질의 분자 결합 특성의 예측치를 선형 표현으로 변환하는 단계를 더 포함하는 방법."}
{"patent_id": "10-2025-7005193", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_136", "content": "제135항에 있어서, 상기 선형 표현을 생성하기 위해 로짓 변환(logit transformation)이 사용되는 것인 방법."}
{"patent_id": "10-2025-7005193", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_137", "content": "제135항에 있어서, 상기 선형 표현에 주성분 분석(PCA)을 수행하여 적어도 제1 주성분을 획득하는 단계를 더 포함하는 방법."}
{"patent_id": "10-2025-7005193", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_138", "content": "제94항에 있어서, 상기 하나 이상의 실증적으로 평가된 단백질과 관련된 사전결정된 일괄 결합 데이터는, 상기하나 이상의 실증적으로 평가된 단백질 각각에 대해, 실험 조건 세트 각각에 대해 측정된 실험적으로 결정된 결합 값을 포함하는 것인 방법."}
{"patent_id": "10-2025-7005193", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_139", "content": "제138항에 있어서, 상기 선택된 대표 특징 벡터 및 상기 사전결정된 일괄 결합 데이터 간의 상관관계는,상기 하나 이상의 실증적으로 평가된 단백질 각각 및 상기 실험 조건 세트 각각에 대해,상기 실증적으로 평가된 단백질의 실험적으로 결정된 결합 값에 적용된 로짓 변환에 기초하여 상기 실증적으로평가된 단백질의 실험적으로 결정된 결합 값의 선형 표현을 생성하고,상기 하나 이상의 실증적으로 평가된 단백질의 실험적으로 결정된 결합 값의 선형 표현에 주성분 분석(PCA)을수행하여 적어도 제1 주성분을 획득하는 것을 포함하는 것인 방법."}
{"patent_id": "10-2025-7005193", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_140", "content": "제139항에 있어서, 상기 머신 러닝 모델을 사용하여, 상기 하나 이상의 실증적으로 평가된 단백질의 분자 결합 특성의 훈련 예측치를 생성하는 단계, 및상기 훈련 예측치 및 상기 제1 주성분을 비교하여 상기 하나 이상의 교차 검증 손실을 계산하는 단계공개특허 10-2025-0053066-20-를 더 포함하는 방법."}
{"patent_id": "10-2025-7005193", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_141", "content": "제139항에 있어서, 상기 제1 주성분은 평균 일괄 결합 값을 기술하는 것인 방법."}
{"patent_id": "10-2025-7005193", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_142", "content": "제94항에 있어서, 상기 예측치에 기초하여, 실험 조건 세트에 대한 상기 하나 이상의 단백질의 거동을 나타내는 함수 세트를 생성하는 단계, 및상기 실험 조건 세트에 대한 상기 하나 이상의 단백질의 거동에 기초하여, 하나 이상의 약물 발견 검정을 위해상기 하나 이상의 단백질 중 적어도 하나를 선택하는 단계를 더 포함하는 방법."}
{"patent_id": "10-2025-7005193", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_143", "content": "제94항에 있어서, 상기 하나 이상의 실증적으로 평가된 단백질과 관련된 상기 사전결정된 일괄 결합 데이터 및상기 선택된 대표 특징 벡터 간의 상관관계는, 상기 사전결정된 일괄 결합 데이터에 기초하여 계산된 주성분 및상기 대표 특징 벡터 간의 상관관계를 포함하는 것인 방법."}
{"patent_id": "10-2025-7005193", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_144", "content": "제143항에 있어서, 예측된 분자 결합 특성 및 실증적 분자 결합 특성에 기초하여 상기 하나 이상의 교차 검증손실이 계산되는 것인 방법."}
{"patent_id": "10-2025-7005193", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_145", "content": "제144항에 있어서, 상기 예측된 분자 결합 특성은 상기 대표 특징 벡터에 기초하여 계산된 주성분을 포함하고, 상기 실증적 분자 결합 특성은 상기 사전결정된 일괄 결합 데이터에 기초하여 계산된 주성분을 포함하는 것인방법."}
{"patent_id": "10-2025-7005193", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_146", "content": "제94항에 있어서, 상기 하나 이상의 가장 예측적인 특징 벡터를 결정하는 것은 (i) 상기 대표 특징 벡터에 모델을 맞추고(fitting),(ii) 상기 모델에 기초하여, 상기 대표 특징 벡터 각각에 대한 특징 중요도 점수를 계산하며, (iii) 상기 대표 특징 벡터 각각의 특징 중요도 점수에 기초하여 상기 대표 특징 벡터 중 하나 이상의 특징 벡터를 제거하여 대표 특징 벡터의 서브세트를 획득하는 것을 더 포함하며, 여기서 상기 하나 이상의 가장 예측적인 특징 벡터는 상기 대표 특징 벡터의 서브세트로부터의 하나 이상의 특징 벡터를 포함하는 것인 방법."}
{"patent_id": "10-2025-7005193", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_147", "content": "제146항에 있어서, 상기 서브세트에 포함된 특징 벡터의 수가 특징 수량 기준을 충족할 때까지 단계 (i)-(iii)를 반복적으로 수행하는 단계를 더 포함하는 방법."}
{"patent_id": "10-2025-7005193", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_148", "content": "공개특허 10-2025-0053066-21-제147항에 있어서, 상기 특징 수량 기준이 충족되는 것은 상기 대표 특징 벡터의 서브세트에 포함된 특징 벡터의 수가 특징 벡터의 임계 수보다 작거나 같은 것을 포함하는 것인 방법."}
{"patent_id": "10-2025-7005193", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_149", "content": "제148항에 있어서, 상기 특징 벡터의 임계 수는 상기 머신 러닝 모델 훈련에 사용된 훈련 데이터로부터의 동일하거나 유사한 수의 특징을 포함하는 것인 방법."}
{"patent_id": "10-2025-7005193", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_150", "content": "제147항에 있어서, 상기 대표 특징 벡터의 서브세트에 포함된 특징 벡터의 수는 하이퍼 매개변수 세트 중 하나를 포함하는 것인 방법."}
{"patent_id": "10-2025-7005193", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_151", "content": "제94항에 있어서, 상기 하이퍼 매개변수 세트 중 하나는 상기 복수의 특징 벡터 클러스터에 포함된 특징 벡터클러스터의 수를 나타내는 것인 방법."}
{"patent_id": "10-2025-7005193", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_152", "content": "하나 이상의 컴퓨팅 장치를 포함하는 시스템으로서, 명령어를 포함하는 하나 이상의 비일시적 컴퓨터 판독가능 저장 매체, 및상기 하나 이상의 저장 매체에 결합된 하나 이상의 프로세서를 더 포함하며, 상기 하나 이상의 프로세서는 상기 명령어를 실행하여하나 이상의 단백질에 상응하는 아미노산 서열 세트를 나타내는 분자 설명자 행렬에 액세스하고,머신 러닝 모델에 의해, 상기 분자 설명자 행렬에 적어도 부분적으로 기초하여 상기 하나 이상의 단백질의 분자결합 특성의 예측치를 획득하도록 구성되고, 상기 머신 러닝 모델은,하나 이상의 실증적으로 평가된 단백질에 상응하는 아미노산 서열의 훈련 세트를 나타내는 훈련 분자 설명자 행렬에 액세스하고, 복수의 특징 벡터 클러스터 각각에 대해 하나의 대표 특징 벡터를 선택함으로써 상기 훈련 분자 설명자 행렬을감소시키며, 여기서 각각의 특징 벡터 클러스터는 유사한 특징 벡터를 포함하고,상기 하나 이상의 실증적으로 평가된 단백질과 관련된 사전결정된 일괄 결합 데이터 및 상기 선택된 대표 특징벡터 간의 상관관계에 기초하여 각각의 특징 벡터 클러스터에 대해 상기 선택된 대표 특징 벡터 중 하나 이상의가장 예측적인 특징 벡터를 결정하며,원하는 정밀도에 도달할 때까지 상기 머신 러닝 모델과 관련된 하이퍼 매개변수 세트를 정밀화하기 위한 프로세스를 반복적으로 실행하는 것에 의해 훈련되며, 상기 프로세스는,상기 하나 이상의 가장 예측적인 특징 벡터 및 상기 사전결정된 일괄 결합 데이터에 적어도 부분적으로 기초하여 하나 이상의 교차 검증 손실을 계산하고,상기 하나 이상의 교차 검증 손실에 기초하여 상기 하이퍼 매개변수 세트를 업데이트하는 것을 포함하는 것인시스템."}
{"patent_id": "10-2025-7005193", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_153", "content": "하나 이상의 컴퓨팅 장치의 하나 이상의 프로세서에 의해 실행될 때 상기 하나 이상의 프로세서로 하여금 동작공개특허 10-2025-0053066-22-을 수행하게 하는 명령어를 포함하는 비일시적 컴퓨터 판독가능 매체로서, 상기 동작은,하나 이상의 단백질에 상응하는 아미노산 서열 세트를 나타내는 분자 설명자 행렬에 액세스하고,머신 러닝 모델에 의해, 상기 분자 설명자 행렬에 적어도 부분적으로 기초하여 상기 하나 이상의 단백질의 분자결합 특성의 예측치를 획득하는 것을 포함하고,상기 머신 러닝 모델은,하나 이상의 실증적으로 평가된 단백질에 상응하는 아미노산 서열의 훈련 세트를 나타내는 훈련 분자 설명자 행렬에 액세스하고, 복수의 특징 벡터 클러스터 각각에 대해 하나의 대표 특징 벡터를 선택함으로써 상기 훈련 분자 설명자 행렬을감소시키고, 여기서 각각의 특징 벡터 클러스터는 유사한 특징 벡터를 포함하고,상기 하나 이상의 실증적으로 평가된 단백질과 관련된 사전결정된 일괄 결합 데이터 및 상기 선택된 대표 특징벡터 간의 상관관계에 기초하여 각각의 특징 벡터 클러스터에 대해 상기 선택된 대표 특징 벡터 중 하나 이상의가장 예측적인 특징 벡터를 결정하며,원하는 정밀도에 도달할 때까지 상기 머신 러닝 모델과 관련된 하이퍼 매개변수 세트를 정밀화하기 위한 프로세스를 반복적으로 실행하는 것에 의해 훈련되며, 상기 프로세스는,상기 하나 이상의 가장 예측적인 특징 벡터 및 상기 사전결정된 일괄 결합 데이터에 적어도 부분적으로 기초하여 하나 이상의 교차 검증 손실을 계산하고,상기 하나 이상의 교차 검증 손실에 기초하여 상기 하이퍼 매개변수 세트를 업데이트하는 것을 포함하는 것인 비일시적 컴퓨터 판독가능 매체."}
{"patent_id": "10-2025-7005193", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "하나 이상의 컴퓨터 장치에 의해 구현되는 방법은 단백질에 상응하는 아미노산 서열 세트를 나타내는 분자 설명 자 행렬에 액세스하는 단계, 및 단백질의 분자 결합 특성의 예측치를 생성하도록 훈련된 머신 러닝 모델과 관련 된 하이퍼 매개변수 세트를 정밀화하는 단계를 포함한다. 하이퍼 매개변수 세트를 정밀화하는 단계는 원하는 정 밀도에 도달할 때까지 반복적으로 프로세스를 실행하는 단계를 포함하며, 여기에는 복수의 특징 벡터 클러스터 각각에 대해 하나의 대표 특징 벡터를 선택함으로써 분자 설명자 행렬을 감소시키고, 상관관계에 기초하여 상기 선택된 대표 특징 벡터의 가장 예측적인 특징 벡터를 결정하며, 상기 가장 예측적인 특징 벡터 및 사전결정된 일 괄 결합 데이터에 기초하여 교차 검증 손실을 계산하고, 상기 교차 검증 손실에 기초하여 하이퍼 매개변수 세트 를 업데이트하는 것이 포함된다. 이 방법은 단백질의 분자 결합 특성의 예측치를 생성하는 단계를 더 포함한다."}
{"patent_id": "10-2025-7005193", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "관련 출원에 대한 교차 참조 본 출원은 2022년 8월 15일에 출원된 \"COMPUTATIONAL-BASED METHODS FOR IMPROVING PROTEIN PURIFICATION\"이라 는 제목의 미국 가출원 제63/398,168호에 대한 우선권을 주장하며, 해당 출원의 개시 내용은 본원에 전체적으로 참조로 포함된다. 기술 분야 본 출원은 일반적으로 단백질 정제와 관련되며, 보다 구체적으로 단백질 정제 개선을 위한 컴퓨팅 기반 방법과 관련된다."}
{"patent_id": "10-2025-7005193", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "엔지니어링된 포유류 또는 박테리아 세포주를 활용하는 세포 배양은 예를 들어, 표적 단백질에 대한 유전자를 포함하는 재조합 플라스미드를 삽입함으로써, 관심 있는 표적 단백질을 생산하는 데 사용될 수 있다. 세포주 자 체가 살아있는 유기체이기 때문에, 세포주는 표적 단백질 이외의 다른 단백질을 생산하며, 예를 들어, 다양한 당, 아미노산 및 성장 인자를 포함한, 복잡한 성장 배지가 필요할 수 있다. 표적 단백질이 치료적 항체인 경우 와 같이, 표적 단백질이 치료적 활성제로 사용될 때 특히, 표적 단백질의 고순도 조성물을 얻는 것이 꼭 필요한 것은 아니더라도 종종 바람직하다. 따라서 생성된 표적 단백질은 세포 배양에서 이러한 다른 성분으로부터 정제 되어야 하며, 여기에는 각각 크로마토그래피 고정상, 이동상, 염 농도, pH 및 기타 작동 조건, 가령, 온도와 같 은 많은 변수가 포함된 복잡한 일련의 프로세스가 포함될 수 있다.예를 들어, 단백질 정제 프로세스의 순서는, (a) 표적 단백질을 포함하는 세포 배양 샘플을 얻는 단계; (b) 예 를 들어 단백질 A를 사용하는 친화성 포획 단계와 같은 하나 이상의 포획 단계; (c) 하나 이상의 컨디셔닝 단계; (d) 하나 이상의 심층 여과 단계; (e) 양이온 교환 또는 음이온 교환 크로마토그래피와 같은 하나 이상의 이온 교환 크로마토그래피 단계 또는 선택적으로 소수성 상호작용 크로마토그래피를 포함할 수 있는 그 혼합 모 드; (f) 하나 이상의 소수성 상호작용 크로마토그래피 단계 또는 그 혼합 모드; (g) 바이러스 여과 단계; 및 (h) 하나 이상의 초-여과 단계를 포함할 수 있다. 이러한 컬럼 크로마토그래피 기술 각각에는 표적 단백질을 정 제하는 데 사용되는 다양한 조건이 포함될 수 있다. 구체적으로, 정제 기술에는 표적 단백질의 고순도 조성물을 효율적으로 생성하는 데 중요한 많은 변수가 포함된다. 표적 단백질 자체에 대한 고려 사항 외에도, 예를 들어 크로마토그래피 고정상, 이동상, 염 농도, pH, 및 기타 작동 조건, 가령, 온도를 고려해야 한다. 현재, 정제 기술 및 이러한 작동 조건은 실험실에서 실험적으로 결정된다. 따라서 표적 단백질을 정제하는 방법 을 결정하는 것은 매우 번거롭고 시간이 많이 걸릴 수 있다. 또한, 표적 단백질을 선별하여 분리하기 위해 앞서 언급한 실험적 정제 기술에만 의존하면, 정제하기 어려울 수 있는 후보 단백질에 대한 유용한 피드백을 힘든 실 험 없이 확인할 수 없을 수 있다. 따라서 이는 치료용 항체 또는 기타 유사한 면역 요법의 개발 및 제조 공정에 서 비용이 많이 드는 비효율성을 초래할 수 있다. 따라서 표적 단백질(예: 항체)을 식별하고 치료용 항체 후보 의 선택 프로세스를 가속화하기 위한 단백질 정제 프로세스를 최적화하고 간소화하는 기술을 제공하는 것이 유 용할 수 있다."}
{"patent_id": "10-2025-7005193", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 개시의 실시예는 하나 이상의 컴퓨팅 장치, 방법 및 비일시적 컴퓨터 판독가능 매체에 관한 것이며, 이는 표 적 단백질(가령, 항체)을 식별하기 위해, 그리고 가장 유망한 치료 항체 후보의 조기 식별을 통해 치료 항체 후 보 또는 기타 면역 요법 후보의 선택 프로세스를 가속화하기 위해, 단백질 정제의 간소화된 프로세스의 일부로 서 하나 이상의 표적 단백질의 분자 결합 특성의 예측치를 생성하도록 반복적으로 훈련된 머신 러닝 모델을 활 용할 수 있다. 예를 들어, 인-실리코(in-silico) 표적 단백질(예: 항체)을 식별하는 이 간소화된 프로세스는 다 양한 환자 질병을 치료하는 데 사용될 수 있는 하나 이상의 치료 단일 클론 항체(mAb), 이중 특이 항체(bsAb), 삼중 특이 항체(tsAb) 또는 기타 유사한 면역 요법의 다운스트림 개발 및 제조를 용이하게 하고 가속화할 수 있 다. 일부 실시예에서, 머신 러닝 모델은 복수의 모델을 포함하는 앙상블(ensemble) 머신 러닝 모델을 포함한다. 예를 들어, 일단 훈련되면, 머신 러닝 모델(예: \"부스팅\" 앙상블 러닝 모델)은 최적화된 하이퍼 매개변수(예: 일반 매개변수, 부스터 매개변수, 학습 과제 매개변수) 및 머신 러닝 모델의 훈련 중에 학습된 학습가능 매개변 수(예: 회귀 모델 가중치, 결정 변수) 및 하나 이상의 관심 단백질에 상응하는 아미노산 서열 세트를 나타내는 분자 설명자 행렬의 특징 벡터의 선택된 k-베스트 행렬을 활용함으로써 하나 이상의 단백질의 분자 결합 특성의 예측치(예: 하나 이상의 특정 pH 값 및 특정 염 농도 및/또는 특정 염 종 및 크로마토그래피 수지에서 결합된 단백질 백분율 예측치)를 생성하는 데 활용될 수 있다. 구체적으로, 현재 공개된 실시예에 따라, 일단 훈련되면, 머신 러닝 모델은 훈련 중에 학습된 최적화된 하이퍼 매개변수(예: 일반 매개변수, 부스터 매개변수, 학습 과제 매개변수) 및 학습가능 매개변수(예: 회귀 모델 가중 치, 결정 변수)를 활용하여, 하나 이상의 관심 단백질에 상응하는 아미노산 서열 세트와 하나 이상의 관심 단백 질의 결합 특성과 관련된 pH 값 및 염 농도의 하나 이상의 세트를 나타내는 분자 설명자 행렬의 특징 벡터의 선 택된 k-베스트 행렬만을 입력으로 하여, 하나 이상의 표적 단백질에 대한 단백질 결합 백분율(예: 주어진 pH 값 및 염 농도에 대한 용액 내 리간드에 결합될 것으로 예측되는 단백질 세트의 백분율)을 예측할 수 있다. 이런 방식으로, 하나 이상의 관심 단백질에 대한 단백질 결합 백분율의 컴퓨팅 모델 기반 예측치를 제공함으로 써, 상당한 업스트림 실험 없이 하나 이상의 관심 단백질의 분자 결합 특성 및 용출 특성을 결정할 수 있다. 즉, 하나 이상의 관심 단백질 중 바람직한 단백질은 인-실리코 환경에서 하나 이상의 관심 단백질 중 바람직하 지 않은 단백질과 식별 및 구별될 수 있으며, 인-실리코 환경에서 식별된 이러한 바람직한 단백질은 다양한 환 자 질병을 치료하는 데 사용될 수 있는 하나 이상의 치료용 mAb, bsAb, tsAb 또는 기타 유사한 면역 요법의 다 운스트림 개발 및 제조를 용이하게 하고 가속화하는 데 추가로 활용될 수 있다(예: 업스트림 실험 기간 및 실험 비효율성을 줄이고 어떤 후보 단백질이 정제하기 어려울 수 있는지, 그리고 확장하여 궁극적으로 제조하기 어려 울 수 있는지에 대한 인-실리코 피드백을 제공함으로써). 예를 들어, 머신 러닝 모델(예: \"부스팅\" 앙상블 러닝 모델)을 훈련하는 동안 하이퍼 매개변수(예: 일반 매개변 수, 부스터 매개변수, 학습 과제 매개변수) 및 학습가능 매개변수(예: 회귀 모델 가중치, 의사 결정 변수)를 반 복적으로 정밀화하고 최적화할 수 있다. 반복에는 1) 거리 메트릭에 따라 분자 설명자 행렬의 유사한 특징 벡터 를 클러스터링하여 아미노산 서열 세트를 나타내는 분자 설명자 행렬을 줄이는 것이 포함될 수 있다. 예를 들어, 거리 메트릭은 피어슨 상관관계(Pearson's correlation), 상호 정보 또는 최대 정보 계수(MIC) 또는 기타 거리 메트릭에 따라 계산될 수 있다. 클러스터 중심에 가장 가까운 것이 아닌 다른 특징 벡터는 삭제되어, 감소 된 분자 설명자 행렬을 생성할 수 있다. 반복은 다음으로 k-베스트 프로세스와 최대 정보 계수(MIC)에 기초하여 감소된 분자 설명자 행렬의 k-베스트 가장 예측적인 특징 벡터를 결정하는 것을 포함할 수 있으며, 감소된 분자 설명자 행렬의 특징 벡터와 하나 이상의 특정 pH 값과 염 농도에 대한 실험적으로 결정된 단백질 결합 백분율 및/또는 제1 주성분(PC) 값 간의 상관관계를 결정할 수 있다. 반복은 다음으로 k-베스트 가장 예측적인 특징 벡 터와 실험적으로 결정된 단백질 결합 백분율 및/또는 제1 PC 값에 기초하여 n개의 교차 검증 손실을 계산하는 것을 포함할 수 있다. 마지막으로, 반복은 n개의 교차 검증 손실에 기초하여 하이퍼 매개변수(예: 일반 매개변 수, 부스터 매개변수, 학습 과제 매개변수)를 업데이트하는 것을 포함할 수 있다. 특정 실시예에서, 전술한 특징 차원수 감소 및 특징 선택 기술을 통해 아미노산 서열 기반 설명자의 대규모 세 트를 포함할 수 있는 분자 설명자 행렬을 감소시키면, 불필요하거나 노이즈 많은 설명자로 인해 과적합되는 것 과는 대조적으로 회귀 모델이 정확하게 훈련된 회귀 모델로 성공적으로 수렴할 수 있다. 또한, 일부 실시예에서, 감소된 분자 설명자 행렬의 특징 벡터와 실험적으로 결정된 단백질 결합 백분율 및/또는 제1 PC 값 간 상관관계의 결정의 일부로서 MIC를 활용하는 것 대신, 거리 상관관계, 상호 정보 또는 기타 유사한 비선형 상관관계 메트릭 또는 선형 상관관계 메트릭(예: 피어슨 상관관계)을 활용할 수 있다는 점을 인식해야 한다. 특정 실시예에서, 하나 이상의 컴퓨팅 장치, 방법 및 비일시적 컴퓨터 판독가능 매체는 하나 이상의 단백질에 상응하는 아미노산 서열 세트를 나타내는 분자 설명자 행렬에 액세스할 수 있다. 일부 실시예에서, 분자 설명자 행렬은 머신 러닝 모델(예: 앙상블 러닝 모델)과는 다른 제1 머신 러닝 모델(예: 행렬 생성 머신 러닝 모델)에 의해 생성될 수 있다. 일부 실시예에서, 제1 머신 러닝 모델은 아미노산 서열 세트에 기초하여 분자 설명자 행 렬을 생성하도록 훈련되었다. 예를 들어, 일부 실시예에서, 제1 머신 러닝 모델은 아미노산 서열 세트를 나타내 는 M x N 설명자 행렬을 생성하도록 훈련된 신경망을 포함할 수 있으며, 여기서 N은 아미노산 서열 세트의 수를 포함하고 M은 신경망의 출력 계층 내 노드의 수를 포함한다. 특정 실시예에서, 하나 이상의 컴퓨팅 장치는 그런 다음 하나 이상의 단백질의 분자 결합 특성의 예측치를 생성 하도록 훈련된 머신 러닝 모델과 관련된 하이퍼 매개변수 세트를 정밀화할 수 있다. 일부 실시예에서, 머신 러 닝 모델은 그래디언트 부스팅 모델, 적응형 부스팅(AdaBoost) 모델, eXtreme 그래디언트 부스팅(XGBoost) 모델, 라이트 그래디언트 부스티드 머신(LightGBM) 모델 또는 범주형 부스팅(CatBoost) 모델 중 하나 이상을 포함할 수 있다. 일부 실시예에서, 하나 이상의 단백질의 분자 결합 특성의 예측치는 컴퓨팅 모델 기반 컬럼 프로세스에 의해 생 성될 수 있다. 일부 실시예에서, 컴퓨팅 모델 기반 크로마토그래피 프로세스는 컴퓨팅 모델 기반 친화성 크로마 토그래피 프로세스, 이온 교환 크로마토그래피(IEC) 프로세스, 소수성 상호작용 크로마토그래피(HIC) 프로세스, 또는 혼합 모드 크로마토그래피(MMC) 프로세스 중 하나 이상을 포함할 수 있다. 여기에 제공된 방법은 크로마토그래피 기술 시리즈 또는 특정 작동 조건의 조합을 포함한, 임의의 크로마토그래 피 설정에서 하나 이상의 단백질의 분자 결합 특성을 예측하는 데 사용될 수 있다. 일반적으로, 크로마토그래피 기술은 고정상과 이동상을 포함한다. 고정상은 표적 단백질과 상호작용하도록 설계된 부분(예: 결합 및 용출 모 드 스타일의 크로마토그래피) 또는 표적 단백질과 상호작용하지 않도록 설계된 부분(예: 유출 스타일의 크로마 토그래피)을 포함할 수 있다. 크로마토그래피 기술에 사용되는 이동상(예: 로딩, 세척 또는 용출 이동상)은 하 나 이상의 염의 농도, pH 및 용매 구배를 포함한, 여러 변수를 가질 수 있다. 또한 크로마토그래피 기술은 고온 과 같은 다양한 조건에서 수행될 수 있다. 일부 실시예에서, 컴퓨팅 모델 기반 크로마토그래피 프로세스는 친화성 크로마토그래피 프로세스를 포함한다. 일부 실시예에서, 친화성 크로마토그래피 프로세스는 단백질 A 크로마토그래피, 단백질 G 크로마토그래피, 단백 질 A/G 크로마토그래피, 단백질 L 크로마토그래피 및 카파 크로마토그래피 중 어느 하나에 따른 것과 같은, 친 화성 리간드를 포함할 수 있다. 일부 실시예에서, 친화성 크로마토그래피 프로세스는 용출 이동상, 예를 들어 설정된 pH를 갖는 이동상을 포함할 수 있다. 일부 실시예에서, 컴퓨팅 모델 기반 크로마토그래피 프로세스는 이온 교환 크로마토그래피 프로세스를 포함할 수 있다. 이온 교환 크로마토그래피는 이온 교환 고정상의 리간드와 샘플의 구성 요소, 예를 들어 표적 또는 비표적 단백질 간의 정전기적 상호작용(음이온 및 양이온)에 기초하여 분리를 허용한다. 일부 실시예에서, 이온 교환 크로마토그래피는 양이온 교환(CEX) 고정상을 처리한다. 일부 실시예에서, 이온 교환 크로마토그래피는 강 한 CEX 고정상을 포함할 수 있다. 일부 실시예에서, 이온 교환 크로마토그래피는 약한 CEX 고정상을 포함할 수 있다. 일부 실시예에서, 이온 교환 크로마토그래피 수지는 카르복실기 또는 설포네이트기와 같은 음이온성 작용 기를 포함하는 리간드로 작용화될 수 있다. 일부 실시예에서, 이온 교환 크로마토그래피 고정상은 음이온 교환(AEX) 고정상을 포함할 수 있다. 일부 실시예 에서, 이온 교환 크로마토그래피는 강한 AEX 고정상을 포함할 수 있다. 일부 실시예에서, 이온 교환 크로마토그 래피는 약한 AEX 고정상을 포함할 수 있다. 일부 실시예에서, 이온 교환 크로마토그래피 수지는 4차 아민과 같 은 양이온 작용기를 포함하는 리간드로 작용화될 수 있다. 일부 실시예에서, 이온 교환 크로마토그래피는 다중 모드 이온 교환(MMIEX) 고정상을 포함할 수 있다. MMIEX 크로마토그래피 고정상은 양이온 교환 및 음이온 교환 성분 및/또는 특징을 모두 포함할 수 있다. 일부 실시예에서, MMIEX 고정상은 다중 모드 음이온/양이온 교환 (MM-AEX/CEX) 고정상을 포함할 수 있다. 일부 실시예에서, 이온 교환 크로마토그래피는 세라믹 하이드록시아파타이트 크로마토그래피 고정상을 포함할 수 있다. 일부 실시예에서, 이온 교환 크로마토그래피 고정상은 설포프로필(SP) Sepharose® Fast Flow (SPSFF), 4차 암모늄(Q) Sepharose® Fast Flow (QSFF), SP Sepharose® XL (SPXL), Streamline™ SPXL, ABx ™ (MM-AEX/ CEX medium), Poros™ XS, Poros™ 50HS, 디에틸아미노에틸(DEAE), 디메틸아미노에틸(DMAE), 트리 메틸아미노에틸(TMAE), 4차 아미노에틸(QAE), 머캅토에틸피리딘(MEP)-Hypercel™, HiPrep™ Q XL, Q Sepharose ® XL, 및 HiPrep™ SP XL으로 구성된 그룹에서 선택될 수 있다. 일부 실시예에서, 이온 교환 크로마토그래피 프로세스는 결합 또는 세척 이동상에 비해 증가한 것과 같은, 증가된 염 농도를 포함하는, 용출 단계 이동상을 포함할 수 있다. 일부 실시예에서, 컴퓨팅 모델 기반 크로마토그래피 프로세스는 혼합 모드 크로마토그래피 프로세스를 포함할 수 있다. 혼합 모드 크로마토그래피 프로세스는 전하 기반(즉, 이온 교환 크로마토그래피 특징) 및 소수성 기반 요소를 결합하는 고정상을 포함할 수 있다. 일부 실시예에서, 혼합 모드 크로마토그래피 프로세스는 결합 및 용 출 작동 모드를 포함할 수 있다. 일부 실시예에서, 혼합 모드 크로마토그래피 프로세스는 유출 작동 모드를 포 함할 수 있다. 일부 실시예에서, 혼합 모드 크로마토그래피 프로세스는 Capto MMC 및 Capto Adhere로 구성된 그 룹에서 선택된 고정상을 포함할 수 있다. 일부 실시예에서, 컴퓨팅 모델 기반 크로마토그래피 프로세스는 소수성 상호작용 크로마토그래피(HIC) 공정을 포함할 수 있다. 소수성 상호작용 크로마토그래피 프로세스는 소수성 고정상을 포함할 수 있다. 일부 실시예에 서, 혼합 모드 크로마토그래피 프로세스는 결합 및 용출 작동 모드를 포함할 수 있다. 일부 실시예에서, 소수성 상호작용 크로마토그래피 프로세스는 유출 작동 모드를 포함할 수 있다. 일부 실시예에서, 소수성 상호작용 크 로마토그래피 프로세스는 불활성 매트릭스, 예를 들어 가교된 아가로스, 세파로스 또는 수지 매트릭스와 같은, 기질을 포함하는 고정상을 포함할 수 있다. 일부 실시예에서, 소수성 상호작용 크로마토그래피 고정상의 기질의 적어도 일부는 소수성 리간드를 포함하는 표면 개질을 포함할 수 있다. 일부 실시예에서, 소수성 상호작용 크로마토그래피 리간드는 약 1 내지 18개의 탄소를 포함하는 리간드이다. 일 부 실시예에서, 소수성 상호작용 크로마토그래피 리간드는 2개 이상의 탄소, 3개 이상의 탄소, 4개 이상의 탄소, 5개 이상의 탄소, 6개 이상의 탄소, 7개 이상의 탄소, 8개 이상의 탄소, 9개 이상의 탄소, 10개 이상의 탄소, 11개 이상의 탄소, 12개 이상의 탄소, 13개 이상의 탄소, 14개 이상의 탄소, 15개 이상의 탄소, 16개 이 상의 탄소, 17개 이상의 탄소 또는 18개 이상의 탄소 중 임의의 것과 같이, 1개 이상의 탄소를 포함할 수 있다. 일부 실시예에서, 소수성 상호작용 크로마토그래피 리간드는 1개 탄소, 2개 탄소, 3개 탄소, 4개 탄소, 5개 탄 소, 6개 탄소, 7개 탄소, 8개 탄소, 9개 탄소, 10개 탄소, 11개 탄소, 12개 탄소, 13개 탄소, 14개 탄소, 15개 탄소, 16개 탄소, 17개 탄소 또는 18개 탄소 중 임의의 것을 포함할 수 있다. 일부 실시예에서, 소수성 리간드 는 에테르기, 메틸기, 에틸기, 프로필기, 이소프로필기, 부틸기, t-부틸기, 헥실기, 옥틸기, 페닐기 및 폴리프 로필렌 글리콜기로 구성된 그룹에서 선택된다. 일부 실시예에서, HIC 매체는 소수성 전하 유도 크로마토그래피 매체이다. 일부 실시예에서, 소수성 상호작용 크로마토그래피 프로세스는 고염 조건을 포함하는 이동상을 포함할 수 있다. 예를 들어, 고염 조건을 이용하여 표적의 용매화를 감소시켜 소수성 영역을 노출시키고, 이 영역은 소수성 상호작용 크로마토그래피 고정상과 상 호작용할 수 있다. 일부 실시예에서, 소수성 상호작용 크로마토그래피 프로세스는 저염 조건, 예를 들어 염이 없거나 염이 첨가되지 않은 이동상을 포함할 수 있다. 일부 실시예에서, 소수성 상호작용 크로마토그래피 고정상은 Bakerbond WP HI-Propyl™, Phenyl Sepharose® Fast Flow(Phenyl-SFF), Phenyl Sepharose® Fast Flow Hi-sub(Phenyl-SFF HS), Toyopearl® Hexyl-650, Poros™ Benzyl Ultra 및 Sartobind® 페닐로 구성된 그룹에 서 선택된다. 일부 실시예에서, Toyopearl® Hexyl-650은 Toyopearl® Hexyl-650M이다. 일부 실시예에서, Toyopearl® Hexyl-650은 Toyopearl® Hexyl-650C이다. 일부 실시예에서, Toyopearl® Hexyl-650은 Toyopearl ® Hexyl-650S이다. 특정 실시예에서, 하나 이상의 단백질의 분자 결합 특성의 예측치는 하나 이상의 단백질의 표적 단백질의 확인 을 포함할 수 있다. 다른 실시예에서, 하나 이상의 단백질의 분자 결합 특성의 예측치는 하나 이상의 단백질의 정량적 구조 특성 관계(QSPR) 또는 정량적 구조 활성 관계(QSAR) 모델링을 사용할 수 있다. 또 다른 실시예에서, 하나 이상의 단백질의 분자 결합 특성의 예측치는 하나 이상의 단백질에 상응하는 아미노산 서열 세트의 각 아미노산 서열에 대한 분자 결합 특성의 예측치를 포함할 수 있다. 또 다른 실시예에서, 각 아미노산 서열에 대한 분자 결합 특성의 예측치는 바람직하지 않은 아미노산 분자로부터 바람직한 아미노산 분자의 컴퓨 팅 모델 기반 분리를 포함할 수 있다. 한 실시예에서, 머신 러닝 모델(예: 앙상블 러닝 모델)은 하나 이상의 단 백질의 분자 용출 특성의 예측치를 생성하도록 추가로 학습될 수 있다. 다른 실시예에서, 머신 러닝 모델은 하 나 이상의 단백질의 유출 특성의 예측치를 생성하도록 추가로 학습될 수 있다. 특정 실시예에서, 하나 이상의 컴퓨팅 장치는 원하는 정밀도에 도달할 때까지 프로세스를 실행하여 하이퍼 매개 변수 세트를 반복적으로 정밀화할 수 있다. 예를 들어, 특정 실시예에서, 하나 이상의 컴퓨팅 장치는 복수의 특 징 벡터 클러스터 각각에 대해 하나의 대표 특징 벡터를 선택함으로써 분자 설명자 행렬을 먼저 감소시켜 프로 세스를 실행할 수 있다. 한 실시예에서, 각각의 특징 벡터 클러스터는 유사한 특징 벡터를 포함한다. 예를 들어, 일부 실시예에서, 분자 설명자 행렬을 감소시키는 것은 예를 들어, 분자 설명자 행렬의 특징 벡터의 피어 슨 상관관계에 기초하여 계산된, 상관관계 거리 메트릭을 사용하여 클러스터링을 수행하여, 복수의 특징 벡터 클러스터를 생성하는 것을 포함할 수 있다. 일부 경우에, 설명자 세트의 클러스터링은 피어슨 상관관계(예: 1 - abs(피어슨 상관관계))에서 계산될 수 있는 설명자 간의 상관관계에 기반할 수 있다. 한 실시예에서, 복수의 특 징 벡터 클러스터 각각에 대한 선택된 하나의 대표 특징 벡터는 두 개 이상의 유사한 특징 벡터를 나타내는 데 사용되는 복수의 특징 벡터 클러스터 각각에 대한 중심 특징 벡터를 포함할 수 있다. 특정 실시예에서, 하나 이상의 컴퓨팅 장치는 선택된 대표 특징 벡터와 하나 이상의 단백질과 관련된 사전결정 된 일괄 결합 데이터 간의 상관관계에 기초하여 복수의 특징 벡터 클러스터 각각에 대한 선택된 대표 특징 벡터 중 하나 이상의 가장 예측적인 특징 벡터를 결정함으로써 프로세스를 실행할 수 있다. 예를 들어, 일부 실시예 에서, 복수의 특징 벡터 클러스터 각각에 대해 선택된 대표 특징 벡터 중 하나 이상의 대표 특징 벡터를 결정하 는 것은 복수의 특징 벡터 클러스터 각각에 대해 선택된 대표 특징 벡터 중 특징 벡터의 k-베스트 행렬을 선택 하는 것을 포함할 수 있다. 한 실시예에서, 선택된 대표 특징 벡터 중 특징 벡터의 k-베스트 행렬은 사전결정된 k-베스트 프로세스에 기초하여 결정된다. 특정 실시예에서, 선택된 대표 특징 벡터와 사전결정된 일괄 결합 데 이터 간의 상관관계는 선택된 대표 특징 벡터와 사전결정된 일괄 결합 데이터 간의 피어슨 상관관계, 상호 정보, 최대 정보 계수(MIC) 또는 기타 메트릭에 따라 결정된다. 다른 실시예에서는, 상관관계 결정의 일부로 MIC를 활용하는 것의 대안으로 거리 상관관계, 상호 정보 또는 기타 유사한 비선형 상관관계 메트릭 및/또는 선 형 상관관계 메트릭을 활용할 수 있다. 특정 실시예에서, 하나 이상의 컴퓨팅 장치는 하나 이상의 가장 예측적인 특징 벡터 및 사전결정된 일괄 결합 데이터에 적어도 부분적으로 기반하여 하나 이상의 교차 검증 손실을 계산하여 프로세스를 실행할 수 있다. 예 를 들어, 일부 실시예에서, 하나 이상의 교차 검증 손실을 계산하는 것은 또한 하나 이상의 가장 예측적인 특징 벡터, 사전결정된 일괄 결합 데이터, 하이퍼 매개변수 세트 및 머신 러닝 모델과 연관된 학습가능 매개변수 세 트에 기초하여 교차 검증 손실 함수를 평가하고, 또한 하나 이상의 가장 예측적인 특징 벡터, 사전결정된 일괄 결합 데이터 및 하이퍼 매개변수 세트를 일정하게 유지시키면서 학습가능 매개변수 세트를 변경함으로써 교차 검증 손실 함수를 최소화하는 것을 포함할 수 있다. 예를 들어, 일부 실시예에서, 교차 검증 손실 함수를 최소화하는 것은 하이퍼 매개변수 세트를 최적화하는 것을 포함할 수 있다. 예를 들어, 한 실시예에서 하이퍼 매개변수 세트는 일반 매개변수 세트, 부스터 매개변수 세트 또는 학습 과제 매개변수 세트 중 하나 이상을 포함할 수 있다. 일부 실시예에서 교차 검증 손실 함수를 최소화 하는 것은 하나 이상의 단백질에 대한 단백질 결합 백분율의 예측치와 하나 이상의 단백질에 대한 실험적으로 결정된 단백질 결합 백분율 간의 손실을 최소화하는 것을 더 포함할 수 있다. 한 실시예에서, 사전결정된 일괄 결합 데이터는 하나 이상의 단백질의 분자 결합 특성과 관련된 하나 이상의 pH 값 및 염 농도에 대한 실험적으 로 결정된 단백질 결합 백분율을 포함할 수 있다. 한 실시예에서, 학습가능 매개변수 세트는 하나 이상의 가장예측적인 특징 벡터 및 사전결정된 일괄 결합 데이터에 기초하여 머신 러닝 모델에 의해 결정된 하나 이상의 가 중치 또는 결정 변수를 포함할 수 있다. 일부 실시예에서, 하나 이상의 교차 검증 손실을 계산하는 것은 n개의 교차 검증 손실을 계산하는 것을 포함할 수 있으며, 여기서 n은 1 내지 n으로부터의 정수를 포함한다. 일부 실시예에서, 하나 이상의 교차 검증 손실을 계산하는 것은 하나 이상의 가장 예측적인 특징 벡터와 사전결정된 일괄 결합 데이터에 기초하여 n개의 개별 훈 련-테스트 분할을 결정하는 것을 포함할 수 있으며, 여기서 n은 1 내지 n으로부터의 정수를 포함한다. 일부 실 시예에서, 하나 이상의 교차 검증 손실을 계산하는 것은 n개의 교차 검증 손실을 계산하고 n개의 교차 검증 손 실의 평균에 기초하여 하나 이상의 단백질의 분자 결합 특성의 예측치를 생성하는 것을 포함할 수 있다. 특정 실시예에서, 하나 이상의 컴퓨팅 장치는 하나 이상의 교차 검증 손실에 따라 하이퍼 매개변수 세트를 업데 이트하여 프로세스를 실행할 수 있다. 예를 들어, 업데이트된 하이퍼 매개변수 세트에는 업데이트된 일반 매개 변수 세트, 업데이트된 부스터 매개변수 세트 또는 업데이트된 학습 과제 매개변수 세트 중 하나 이상이 포함될 수 있다. 일부 실시예에서, 하이퍼 매개변수 세트를 정밀화한 후, 하나 이상의 컴퓨팅 장치는 머신 러닝 모델을 통해, 업데이트된 하이퍼 매개변수 세트에 적어도 부분적으로 기초하여 하나 이상의 단백질의 분자 결합 특성의 예측치를 출력할 수 있다. 특정 실시예에서, 하이퍼 매개변수 세트를 정밀화한 후, 하나 이상의 컴퓨팅 장치는 하나 이상의 제2 단백질에 상응하는 제2 아미노산 서열 세트를 나타내는 제2 분자 설명자 행렬에 추가로 액세스하고, 제2 분자 설명자 행 렬의 제2 복수의 특징 벡터 클러스터 각각에 대해 하나의 대표 특징 벡터를 선택하여 제2 분자 설명자 행렬을 감소시키고, 선택된 대표 특징 벡터와 하나 이상의 제2 단백질과 관련된 사전결정된 일괄 결합 데이터 간의 제2 상관관계에 기초하여 각 특징 벡터 클러스터에 대한 선택된 대표 특징 벡터 중 하나 이상의 제2 가장 예측적인 특징 벡터를 결정하여, 하나 이상의 제2 단백질의 분자 결합 특성의 예측치를 생성하도록 훈련된 머신 러닝 모 델에 하나 이상의 제2 가장 예측적인 특징 벡터를 입력하고, 머신 러닝 모델에 의해, 업데이트된 하이퍼 매개변 수 세트에 적어도 부분적으로 기반하여 하나 이상의 제2 단백질의 분자 결합 특성의 예측치를 출력할 수 있다. 예를 들어, 하나 이상의 제2 단백질의 분자 결합 특성의 예측치는 하나 이상의 제2 단백질에 대한 제2 단백질 결합 백분율의 예측치를 포함할 수 있다. 특정 실시예에서, 하나 이상의 컴퓨팅 장치는 베이지안 모델 최적화 프로세스(Bayesian model-optimization process)에 따라 머신 러닝 모델을 더욱 최적화할 수 있다. 일부 실시예에서, 하나 이상의 컴퓨팅 장치는 그룹 K-폴드 교차 검증을 활용하여 하나 이상의 가장 예측적인 특징 벡터, 사전결정된 일괄 결합 데이터, 하이퍼 매 개변수 세트 및 학습가능 매개변수 세트에 기초하여 최적화된 머신 러닝 모델을 훈련 및 평가할 수 있다. 일부 실시예에서, 그룹 K-폴드 교차 검증은 교차 검증 훈련 및 평가 분할에 다양한 범위의 회귀 대상 값이 포함되도 록 하기 위해 계층화될 수 있다. 일부 실시예에서, 계층화는 회귀 대상 값을 여러 분위수로 구분하여 생성된 레 이블을 사용하여 달성될 수 있다. 특정 실시예에서, 하나 이상의 컴퓨팅 장치, 방법 및 비일시적 컴퓨터 판독가능 매체는 하나 이상의 단백질에 상응하는 아미노산 서열 세트를 나타내는 분자 설명자 행렬에 액세스할 수 있고, 머신 러닝 모델을 통해, 분자 설명자 행렬에 적어도 부분적으로 기초하여 하나 이상의 단백질의 분자 결합 특성의 예측치를 얻을 수 있으며, 여기서 머신 러닝 모델은: 하나 이상의 실증적으로 평가된 단백질에 상응하는 아미노산 서열의 훈련 세트를 나 타내는 훈련 분자 설명자 행렬에 액세스함으로써, 그리고 원하는 정밀도에 도달할 때까지 머신 러닝 모델과 관 련된 하이퍼 매개변수 세트를 정밀화하기 위해 프로세스를 반복적으로 실행함으로써, 훈련되며, 이 프로세스는: 복수의 특징 벡터 클러스터 각각에 대해 하나의 대표 특징 벡터를 선택함으로써 훈련 분자 설명자 행렬을 줄이 고, 여기서 각 특징 벡터 클러스터는 유사한 특징 벡터를 포함하며, 선택된 대표 특징 벡터와 하나 이상의 실증 적으로 평가된 단백질과 관련된 사전결정된 일괄 결합 데이터 간의 상관관계에 기초하여 각 특징 벡터 클러스터 에 대한 선택된 대표 특징 벡터 중 하나 이상의 가장 예측적인 특징 벡터를 결정하고; 하나 이상의 가장 예측적 인 특징 벡터와 사전결정된 일괄 결합 데이터에 기초하여 하나 이상의 교차 검증 손실을 계산하고; 하나 이상의 교차 검증 손실에 따라 하이퍼 매개변수 세트를 업데이트하는 것을 포함한다."}
{"patent_id": "10-2025-7005193", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 개시의 실시예는 간소화된 단백질 정제 프로세스의 일부로서 하나 이상의 표적 단백질의 분자 결합 특성의 예측치를 생성하도록 반복적으로 훈련된 머신 러닝 모델을 활용하여 표적 단백질(예: 항체)을 식별하고 가장 유 망한 치료적 항체 후보의 조기 식별을 통해 치료적 항체 후보 또는 기타 면역 요법 후보의 선택 프로세스를 가 속화하기 위한 하나 이상의 컴퓨팅 장치, 방법 및 비일시적 컴퓨터 판독가능 매체에 관한 것이다. 예를 들어, 인-실리코 표적 단백질(예: 항체)을 식별하는 이 간소화된 프로세스는 다양한 질병을 치료하는 데 사용될 수 있 는 하나 이상의 치료적 단일클론 항체(mAb), 이중특이적 항체(bsAb), 삼중특이적 항체(tsAb) 또는 기타 유사한 면역 요법의 다운스트림 개발 및 제조를 용이하게 하고 가속화할 수 있다. 예를 들어, 일단 훈련되면, 머신 러닝 모델(예: 앙상블 러닝 모델 또는 \"부스팅\" 앙상블 러닝 모델)은 최적화된 하이퍼 매개변수(예: 일반 매개변수, 부스터 매개변수, 학습 과제 매개변수) 및 머신 러닝 모델의 훈련 중에 학 습된 학습가능 매개변수(예: 회귀 모델 가중치, 결정 변수)와 하나 이상의 관심 단백질에 상응하는 아미노산 서 열 세트를 나타내는 분자 설명자 행렬 중 특징 벡터의 선택된 k-베스트 행렬을 활용하여 하나 이상의 단백질의 분자 결합 특성의 예측치(예: 하나 이상의 특정 pH 값 및 특정 염 농도 및/또는 특정 염 종 및 크로마토그래피 수지에서의 단백질 결합 백분율의 예측치)를 생성하는 데 사용될 수 있다. 구체적으로, 공개된 실시예에 따르면, 일단 훈련되면, 머신 러닝 모델은 훈련 중에 학습된 최적화된 하이퍼 매 개변수(예: 일반 매개변수, 부스터 매개변수, 학습 과제 매개변수) 및 학습가능 매개변수(예: 회귀 모델 가중치, 결정 변수)를 활용하여 (i) 주어진 pH 값 및 염 농도 또는 pH 값 및 염 농도의 복수의 다양한 조합에 대한 단백질 결합 백분율(예: 용액 내의 리간드에 결합될 것으로 예측되는 단백질 세트의 백분율)을 예측하고, (ii) pH 값 및 염 농도 세트에 대한 단백질 결합 백분율(예: 용액 내의 리간드에 결합될 것으로 예측되는 단백질 세트의 백분율)을 예측하고, (iii) 하나 이상의 관심 단백질에 상응하는 아미노산 서열 세트를 나타내는 분 자 설명자 행렬의 특징 벡터의 선택된 k-베스트 행렬만을 입력으로 하여 하나 이상의 표적 단백질에 대한 pH 값 및 염 농도 세트와, 하나 이상의 관심 단백질의 결합 특성과 관련된 pH 값 및 염 농도의 하나 이상의 세트를 나 타내는 주성분(PC)을 예측할 수 있다. 이런 방식으로, 하나 이상의 관심 단백질에 대한 단백질 결합 백분율 및/또는 PC 값의 컴퓨팅 모델 기반 예측치 를 제공함으로써, 하나 이상의 관심 단백질의 분자 결합 특성 및 용출 특성은 상당한 업스트림 실험 없이 결정 될 수 있다. 즉, 하나 이상의 관심 단백질 중 바람직한 단백질은 인-실리코 환경에서 하나 이상의 관심 단백질 중 바람직하지 않은 단백질과 식별 및 구별될 수 있으며, 인-실리코 환경에서 식별된 이러한 바람직한 단백질은 다양한 질병을 치료하는 데 사용될 수 있는 하나 이상의 치료용 mAb, bsAb, tsAb 또는 기타 유사한 면역 요법의 다운스트림 개발을 촉진하고 용이하게 하는 데 추가로 활용될 수 있다(예: 업스트림 실험 기간 및 실험 비효율 성을 줄이고 정제하기 어려울 수 있는, 확장하여 궁극적으로 제조하기 어려울 수 있는, 후보 단백질에 대한 인- 실리코 피드백을 제공함으로써). 예를 들어, 머신 러닝 모델(예: \"부스팅\" 앙상블 러닝 모델)의 훈련 동안, 하이퍼 매개변수(예: 일반 매개변수, 부스터 매개변수, 학습 과제 매개변수) 및 학습가능 매개변수(예: 회귀 모델 가중치, 결정 변수)는: 1) 피어슨 상관관계에 기초하여 계산될 수 있는 상관관계 거리 메트릭에 기초하여 분자 설명자 행렬의 유사한 특징 벡터를 클러스터링하고 그리고 중심 클러스터에 가장 가까운 것 외의 특징 벡터를 폐기함으로써 아미노산 서열 세트를 나타내는 분자 설명자 행렬을 줄이고; 2) k-베스트 프로세스와 상관 계수(예: 최대 정보 계수(MIC))에 기초하여 감소된 분자 설명자 행렬의 k-베스트 가장 예측적인 특징 벡터를 결정하여 감소된 분자 설명자 행렬의 특징 벡 터와 하나 이상의 특정 pH 값과 염 농도에 대한 실험적으로 결정된 단백질 결합 백분율 간의 상관관계를 결정하 며; 3) k-베스트 가장 예측적인 특징 벡터와 실험적으로 결정된 단백질 결합 백분율에 기초하여 n개의 교차 검 증 손실을 계산하고; 4) n개의 교차 검증 손실에 기초하여 하이퍼 매개변수(예: 일반 매개변수, 부스터 매개변 수, 학습 과제 매개변수)를 업데이트함으로써, 반복적으로 정밀화되고 최적화될 수 있다. 하나 이상의 예에서, 하나 이상의 설명자 세트의 클러스터링은 피어슨 상관관계(예: 1 - abs(피어슨 상관관계))에서 계산된 설명자 간의 상관관계 거리에 기초할 수 있다. 특정 실시예에서, 전술한 특징 차원수 감소 및 특징 선택 기술을 통해, 아미노산 서열 기반 설명자의 대규모 세 트를 포함할 수 있는 분자 설명자 행렬을 감소시키면, 불필요하거나 노이즈 많은 설명자로 인해 과적합되는 것 과는 대조적으로 회귀 모델이 정확하게 훈련된 회귀 모델로 성공적으로 수렴할 수 있다. 또한, 일부 실시예에서 는, 감소된 분자 설명자 행렬의 특징 벡터와 실험적으로 결정된 단백질 결합 백분율 간의 상관관계 결정의 일부 로 MIC를 활용하는 것 대신, 거리 상관관계, 상호 정보 또는 기타 유사한 비선형 상관관계 메트릭 및/또는 선형 상관관계 메트릭(예: 피어슨 상관관계, f-통계량 기반 메트릭)을 활용할 수 있다. 본원에서 사용되는 용어 \"폴리펩타이드\" 및 \"단백질\"은 아미노산 잔기의 중합체를 상호 교환하여 지칭할 수 있 으며, 최소 길이로 제한되지 않는다. 예를 들어, 아미노산 잔기의 이러한 중합체는 천연 또는 비천연 아미노산 잔기를 포함할 수 있으며, 아미노산 잔기의 펩타이드, 올리고펩타이드, 다이머, 트라이머 및 멀티머를 포함하되 이에 국한되지 않는다. 예를 들어, 전체 길이의 단백질과 그 단편이 모두 정의에 포함된다. 용어 \"폴리펩타이드\" 및 \"단백질\"은 또한 폴리펩타이드의 번역 후 변형(post-translational modifications), 예를 들어 글리코실화, 시알릴화, 아세틸화, 인산화 등을 포함할 수 있다. 도 1은 공개된 실시예에 따라 하나 이상의 단백질 정제 프로세스를 수행하기 위한 컴퓨팅 모델 기반 예와 비교하여 하나 이상의 단백질 정제 프로세스를 수행하기 위한 실험적 예를 도시하는 다이어그램을 도 시한다. 도시된 바와 같이, 한편으로, 하나 이상의 단백질 정제 프로세스를 수행하기 위한 실험적 예에 대 한 실험 기간은 수 주에 걸쳐 있을 수 있다. 반면, 하나 이상의 단백질 정제 과정을 수행하기 위한 컴퓨팅 모델 기반 예의 실행 시간은 불과 몇 분일 수 있다. 예를 들어, 하나 이상의 단백질 정제 프로세스를 수행하기 위한 실험적 예는 블록에서 아미노산 서열 을 수신하고, 블록에서 플라스미드를 선택하고, 블록(110 및 112)에서 각각 세포주 및 세포 배양을 통해 단백질을 엔지니어링하고, 블록에서 하나 이상의 크로마토그래피 프로세스(예: 친화성 크로마토그래피 프 로세스, 이온 교환 크로마토그래피(IEX) 프로세스, 소수성 상호작용 크로마토그래피(HIC) 프로세스, 또는 혼합 모드 크로마토그래피(MMC) 프로세스)를 수행하고, 블록에서 고처리량 스크리닝(HTS)을 수행하고 분배 계수 (Kp)를 컴퓨팅하여 단백질 결합을 정량화하는 것을 포함할 수 있으며, 이는 모두 번거롭고 시간이 많이 소요되는 단백질 정제 프로세스의 일부이다. 그런 다음, 하나 이상의 표적 단백질의 분자적 평가가 블록에서 수행될수 있다. 특정 실시예에서, 현재 공개된 기술에 따라, 하나 이상의 단백질 정제 프로세스를 수행하기 위한 컴퓨팅 모델 기반 예는 현재 공개된 실시예에 따라, 블록에서 하나 이상의 관심 단백질에 상응하는 아미노산 서열 에 액세스하고, 블록에서 아미노산 서열에 기초하여 분자 설명자 행렬을 생성하고 분자 설명자 행렬을 감 소시키며, 블록에서 표적 단백질(예: 항체)을 식별하고 치료적 항체 후보 또는 기타 면역 요법 후보의 선 택 프로세스를 가속화하는 최적화되고 간소화된 단백질 정제 프로세스의 일부로, 머신 러닝 모델(예: 앙상블 러 닝 모델)을 활용하여 하나 이상의 표적 단백질의 분자 결합 특성의 예측치를 생성하는 것을 포함할 수 있다. 실제로, 도 2-4와 관련하여 아래에서 더 자세히 논의되는 바와 같이, 머신 러닝 모델은 블록에서 생성된 분자 설명자 행렬의 특징 벡터의 선택된 k-베스트 행렬과 하나 이상의 관심 단백질의 결합 특성과 관련된 pH 값 및 염 농도의 하나 이상의 세트만을 입력으로 하여 하나 이상의 표적 단백질에 대한 단백질 결합 백분율(예: 주 어진 pH 값 및 염 농도에 대한 용액 내의 리간드에 결합될 것으로 예측되는 단백질 세트의 백분율)을 예측하기 위해 훈련 중에 학습된 최적화된 하이퍼 매개변수(예: 일반 매개변수, 부스터 매개변수, 학습 과제 매개변수) 및 학습가능 매개변수(예: 회귀 모델 가중치, 결정 변수)를 활용할 수 있다. 하나 이상의 표적 단백질의 분자적 평가는 상당한 업스트림 실험 없이(예: 하나 이상의 단백질 정제 프로세스를 수행하기 위한 실험적 예와 비교했을 때) 블록에서 수행될 수 있다. 즉, 하나 이상의 관심 단백질 중 바람직한 단백질은 인-실리코 환 경에서 하나 이상의 관심 단백질 중 바람직하지 않은 단백질과 식별 및 구별될 수 있으며, 인-실리코 환경에서 식별된 바람직한 단백질은 다양한 질병을 치료하는 데 사용될 수 있는 하나 이상의 치료용 mAb, bsAb, tsAb 또 는 기타 유사한 면역 요법의 다운스트림 개발을 촉진하고 용이하게 하는 데 추가로 활용될 수 있다(예: 업스트 림 실험 기간 및 실험 비효율성을 줄이고 어떤 후보 단백질이 정제하기 어려울 수 있는지, 그리고 확장하여 궁 극적으로 제조하기 어려울 수 있는지에 대한 인-실리코 피드백을 제공함으로써). 예를 들어, 분자 설명자 행렬 에 적어도 부분적으로 기초하여, 머신 러닝 모델은 하나 이상의 단백질의 분자 결합 특성의 예측치를 얻도록 구 성될 수 있다. 분자 결합 특성으로부터 바람직한 단백질을 식별할 수 있다. 도 2는 공개된 실시예에 따라 특징 생성, 특징 차원수 감소, 모델 출력 기반 특징 선택 및 회귀 모델 최적화를 수행하기 위한 고수준 워크플로 다이어그램을 도시한다. 구체적으로, 도 2와 관련하여 논의된 특징 생성, 특징 차원수 감소, 모델 출력 기반 특징 선택 및 회귀 모델 최적화를 수행하기 위한 고수준 예는 도 3a 및 3b와 관련하여 아래에서 더 자세히 논의될 수 있으며, 현재 공개된 실시예 에 따라 다른 머신 러닝 모델(예: 앙상블 러닝 모델)과 함께 머신 러닝(예: 행렬 생성 머신 러닝 모델)에 의해 수행될 수 있다. 즉, 도 3a 및 도 3b와 관련하여 아래에서 논의하는 바와 같이, 특징 생성은 머신 러닝 모델에 의해 수행될 수 있고, 특징 차원수 감소는 머신 러닝 모델(302A, 302B)의 특징 차원수 감소 모델(307A, 307B)에 의해 수행될 수 있고, 모델 출력 기반 특징 선택은 머신 러닝 모델(302A, 302B)의 특징 선택 모델(309A, 309B)에 의해 수행될 수 있고, 회귀 모델 최적화는 머신 러닝 모델(302A, 302B)의 회귀 모델(311A, 311 B)에 의해 수행될 수 있다. 예를 들어, 아래에서 더 자세히 설명될 바와 같이, 특징 생성을 수행하는 것은 예를 들어 1024개의 분자 설명자(예: 아미노산 서열 기반 설명자)를 생성하는 것을 포함할 수 있다. 특정 실시예에서, 특징 차원수 감소 를 수행하는 것은 예를 들어, 1024개의 분자 설명자(예: 아미노산 서열 기반 설명자)를 클러스터링 및 감 소시켜 중복된 특징 또는 매우 유사한 것으로 판단된 기타 특징을 제거하는 것을 포함할 수 있다. 특정 실시예 에서, 모델 출력 기반 특징 선택을 수행하는 것은 분자 설명자를 해당 분자 설명자 중 k-베스트 가장 예측 적인 특징으로만 감소시키기 위해 k-베스트 특징 행렬을 생성하는 것을 포함할 수 있다. 예를 들어, 분자 설명 자의 수는 설명자를 생성하는 데 사용된 특정 모델에 따라 1024개일 수 있다. 또 다른 예로, 분자 설명자의 수 는 더 많거나 적을 수 있다. 예를 들어, 2048개 설명자, 320개 설명자 등이다. 특정 실시예에서, 회귀 모델 최 적화를 수행하는 것은 예를 들어, 머신 러닝 모델(302A, 302B)의 회귀 모델(311A, 311B)과 연관된 하이퍼 매개변수 및 학습가능 매개변수를 최적화하는 것을 포함할 수 있다. 특정 실시예에서, 아래에서 더 자세히 논의 될 것처럼, 특징 차원수 감소 및 모델 출력 기반 특징 선택은 일부 실시예에서 특징 생성의 일 부로 생성될 수 있는 아미노산 서열 기반 설명자의 대규모 세트를 필터링하기 위해 제공될 수 있다. 이런 방식 으로, 특징 차원수 감소 및 모델 출력 기반 특징 선택을 통해 아미노산 서열 기반 설명자의 대규모 세트를 줄이면 회귀 모델이, 불필요하거나 노이즈 많은 설명자로 인해 과적합되는 것과는 대조적으로, 정확하게 훈련된 회귀 모델로 성공적으로 수렴될 수 있다.도 3a는 머신 러닝 모델(302A)(예: 앙상블 러닝 모델)의 하이퍼 매개변수 및 학습가능 매개변수를 최적화하고, 머신 러닝 모델(302A)을 활용하여 하나 이상의 표적 단백질의 분자 결합 특성의 예측치를 생성하여 표적 단백질 (예: 항체)을 식별하고, 가장 유망한 치료 항체 후보의 조기 식별을 통해 치료 항체 또는 기타 면역 요법 후보 의 선택 프로세스를 가속화하는 간소화된 단백질 정제 프로세스의 일부로, 공개된 실시예에 따른 자세한 워크플 로 다이어그램(300A)을 설명한다. 도 3a에 도시된 바와 같이, 특정 실시예에서, 워크플로 다이어그램(300A)은, 하드웨어(예: 범용 프로세서, 그래픽 처리 장치(GPU), 애플리케이션 특정 집적 회로(ASIC), 시스템 온 칩(SoC), 마이크로컨트롤러, 필드 프로그래밍가능 게이트 어레이(FPGA), 중앙 처리 장치(CPU), 애플리케이션 프로세서 (AP), 시각 처리 장치(VPU), 신경 처리 장치(NPU), 신경 결정 프로세서(NDP), 딥 러닝 프로세서(DLP), 텐서 처 리 장치(TPU), 신경형 처리 장치(NPU) 또는 게놈학 데이터, 단백체학 데이터, 대사체학 데이터, 메타게놈학 데 이터, 전사체학 데이터 또는 기타 오믹스 데이터를 처리하고 이에 기초하여 하나 이상의 결정을 내리는 데 적합 할 수 있는 기타 처리 장치), 소프트웨어(예: 하나 이상의 프로세서에서 실행/실행하는 명령어), 펌웨어(예: 마 이크로코드) 또는 이들의 조합을 포함할 수 있는, 하나 이상의 처리 장치(예: 도 5 및 도 6과 관련하여 아래에 서 논의될 컴퓨팅 장치 및 인공 지능 아키텍처)를 활용하여 실행되는 머신 러닝 모델(예: 행렬 생성 머신 러닝 모델) 및 머신 러닝 모델(302A)(예: 점선으로 표시됨)에 의해 함께 수행될 수 있다. 특정 실시예에서, 머신 러닝 모델(302A)은, 최종 전체 예측이 출력(예, \"부스팅\")될 때까지 파이프라인 내 하나 이상의 초기 모델의 출력이 앙상블 내 하나 이상의 후속 모델에 대한 입력으로 기능하도록, 순서대로 하나 이상 의 예측을 수행하도록 연계하여 훈련 및 실행(예: 직렬, 병렬 또는 종단 간 훈련 및/또는 실행)될 수 있는, 예 를 들어, 임의의 수의 개별 머신 러닝 모델 또는 기타 예측 모델(예: 특징 차원수 감소 모델(307A), 특징 선택 모델(309A) 및 회귀 모델(311A))을 포함할 수 있다. 예를 들어, 일부 실시예에서, 머신 러닝 모델(302A)은 그래 디언트 부스팅 모델, 적응형 부스팅(AdaBoost) 모델, eXtreme 그래디언트 부스팅(XGBoost) 모델, 라이트 그래디 언트 부스티드 머신(LightGBM) 모델 또는 범주형 부스팅(CatBoost) 모델을 포함할 수 있다. 도 3a에 도시되고 아래에서 더 자세히 논의될 바와 같이, 특정 실시예에서, 머신 러닝 모델은 하나 이상의 특징 생성 및 데이터 임포팅 작업을 수행할 수 있는 반면, 머신 러닝 모델(302A)은 특징 차원수 감소 모델 (307A), 특징 선택 모델(309A) 및 회귀 모델(311A)를 포함할 수 있다. 하나 이상의 하이퍼 매개변수 최적화 작 업은 머신 러닝 모델(302A)과 연관된 하이퍼 매개변수 세트를 정밀화하기 위해 추가로 수행될 수 있다. 워크플로 다이어그램(300A)은 머신 러닝 모델이 하나 이상의 P 단백질 세트에 대한 아미노산 서열을 가져 오는 기능 블록에서 시작할 수 있다. 예를 들어, 특정 실시예에서, 머신 러닝 모델은 하나 이상의 사 전 훈련된 인공 신경망(ANN), 합성곱 신경망(CNN), 또는 예를 들어, 감시형, 약감시형, 반감시형, 또는 비감시 형 방식으로 아미노산 서열 기반 설명자의 대규모 세트를 생성하는 데 적합할 수 있는, 기타의 신경망을 포함할 수 있다. 현재 공개된 실시예에 따라, 아미노산 서열 기반 설명자는 (예를 들어, 구조 기반 설명자와 대조적으 로) 활용될 수 있는데, 아미노산 서열 기반 설명자는 (예를 들어, 구조 기반 설명자를 활용하는 것과 비교했을 때) 하나 이상의 표적 단백질의 분자 결합 특성의 예측치를 생성하도록 머신 러닝 모델(302A)를 훈련하는 데 더 효과적일 수 있기 때문이다. 실제로, 아래에서 더 자세히 논의될 것처럼, 특징 차원수 감소 모델(307A, 307B) 및 특징 선택 모델(309A, 309B)은 일부 실시예에서 머신 러닝 모델에 의해 출력될 수 있는 아미노산 서열 기반 설명자의 대규모 세트를 필터링하기 위해 제공될 수 있다. 이런 방식으로, 특징 차원수 감소 모델(307A, 307B) 및 특징 선택 모델(309A, 309B)을 통해 아미노산 서열 기반 설명자의 대규모 세트를 줄이면, 회귀 모델 (311A, 311B)이 불필요하거나 노이즈 많은 설명자로 인해 과적합되는 대신 정확하게 훈련된 회귀 모델로 성공적 으로 수렴할 수 있다. 기능 블록에서, 하나 이상의 P 단백질 세트에 대한 사전결정된 일괄 결합 데이터도 머신 러닝 모델(302A) 에서 사용하도록 가져올 수 있다. 예를 들어, 특정 실시예에서, 사전결정된 일괄 결합 데이터는 하나 이상의 특 정 pH 값 및 염 농도(예: 염화나트륨(NaCl) 농도, 인산염(PO43-) 농도) 및/또는 염 종(예: 아세트산나트륨 (CH3COONa) 종, 인산나트륨(Na3PO4) 종) 및 크로마토그래피 수지에 대해 실험적으로 결정된 단백질 결합 백분율 을 포함할 수 있다. 그런 다음 워크플로 다이어그램(300A)은 기능 블록에서 계속 진행되어 머신 러닝 모델 이 크기 M x N의 분자 설명자 행렬을 생성할 수 있다. 예를 들어, 특정 실시예에서, 하나 이상의 P 단백질 세트의 각 단백질의 아미노산 서열로부터, 머신 러닝 모델(예: 신경망, 합성곱 신경망(CNN), 딥 신경망 (DNN))은 크기가 M x N인 분자 설명자 행렬을 생성할 수 있는데, 여기서 M은 설명자의 수(M = 1024)이고 N은 하 나 이상의 P 단백질 세트 중 주어진 단백질 내 아미노산의 수이다. 특정 실시예에서, 워크플로 다이어그램(300A)은 이어서 기능 블록에서 계속되어, 모든 아미노산(N)에 걸쳐 분자 설명자 행렬의 설명자(M)의 가중 평균을 생성한다. 예를 들어, 특정 실시예에서, 모든 아미노산(N)에 걸쳐 분자 설명자 행렬의 설명자(M)의 가중 평균을 계산하여 하나 이상의 P 단백질 세트의 각 단백질에 대해 M x 1 크기의 설명자 벡터를 생성할 수 있다. 예를 들어, 일부 실시예에서, 머신 러닝 모델은 하나 이상의 P 단 백질 세트의 각 단백질에 대한 하나 이상의 M x 1 설명자 벡터를 생성할 수 있다. 특정 실시예에서, 워크플로 다이어그램(300A)은 이어서 기능 블록에서 계속되어, 모든 단백질(P)에 대한 설명자 벡터를 M x P 크기의 단백질 설명자 행렬로 표현한다. 특정 실시예에서, 워크플로 다이어그램(300A)의 기능 블록은 이미 훈련된 머신 러닝 모델(302A)의 반복을 나타낼 수 있으며, 여기서 하이퍼 매개변수 세트(예: 일반 매개변수, 부스터 매개변수, 학습 과제 매개변수) 및 학습가능 매개변수 세트(예: 회귀 모델 가중치, 결정 변수)가 머신 러닝 모델(302A)의 훈련 중에 식별되었다. 구체적으로, 머신 러닝 모델(302A)와 관련하여 수행되는 하나 이상의 하이퍼 매개변수 최적화 과제의 일부 로서, 기능 블록에서 머신 러닝 모델(302A)의 n-사이클 회귀 기반 모델의 평균 점수를 최소화하는 하이퍼 매개변수가 결정된다. 예를 들어, 한 실시예에서, 하이퍼 매개변수(예: 일반 매개변수, 부스터 매개변수, 학습 과제 매개변수)의 기준 세트가 선택되고, 그 후 반복적으로 업데이트되어, 머신 러닝 모델(302A)의 10주기 회귀 기반 모델의 평균 점수 를 최소화할 수 있다. 특정 실시예에서, 기능 블록에서, 머신 러닝 모델(302A)은 원하는 정밀도에 도달할 때까지 반복적으로 훈련되어, 선택된 하이퍼 매개변수(예: 일반 매개변수, 부스터 매개변수, 학습 과제 매개변 수)를 각각의 연속적인 반복으로 업데이트하여 하이퍼 매개변수 세트를 정밀화할 수 있다. 선택된 하이퍼 매개 변수는 하나 이상의 교차 검증 손실에 따라 업데이트될 수 있다. 예를 들어, 한 실시예에서, 선택된 주어진 하 이퍼 매개변수 세트가 하나 이상의 교차 검증 손실을 최소화할 때(예: 0.0~1.0의 척도에서 가장 낮은 가능한 값 또는 오류에 도달할 때) 원하는 정밀도에 도달한다. 예를 들어, 아래에서 더 자세히 설명하겠지만, 일부 실시예 에서, 하나 이상의 교차 검증 손실을 최소화하는 것은 예측된 단백질 결합 백분율과 실험적으로 결정된 단백질 결합 백분율 사이의 손실을 최소화하는 것을 포함할 수 있다. 따라서 일부 실시예에서, 선택된 주어진 하이퍼 매개변수 세트가 예측된 단백질 결합 백분율과 실험적으로 결정된 단백질 결합 백분율 사이의 손실을 최소화할 때 머신 러닝 모델(302A)의 원하는 정밀도에 도달한다. 현재 공개된 기술에 따라, 특정 실시예에서, 기능 블록에서, 하이퍼 매개변수는 사전결정된 일괄 결합 데 이터의 가장 예측적인 K-베스트 특징 벡터, 사전결정된 일괄 결합 데이터(예: 하나 이상의 특정 pH 값 및 염 농 도 및/또는 염 종 및 크로마토그래피 수지에 대한 실험적으로 결정된 단백질 백분율), 하이퍼 매개변수의 기준 세트(예: 일반 매개변수, 부스터 매개변수, 학습 과제 매개변수) 및 머신 러닝 모델(302A)와 관련되어 이에 의 해 결정된 학습가능 매개변수 세트(예: 회귀 모델 가중치, 결정 변수)에 기초하여 교차 검증 손실 함수를 평가 하여 최적화될 수 있다. 그런 다음 머신 러닝 모델(302A)은 k-베스트 가장 예측적인 특징 벡터, 사전결정된 일 괄 결합 데이터 및 하이퍼 매개변수 세트를 일정하게 유지시키면서 학습가능 매개변수 세트를 변경하여 교차 검 증 손실 함수를 최소화할 수 있다. 특정 실시예에서, 앞서 언급된 바와 같이, 머신 러닝 모델(302A)은 특징 차원수 감소 모델(307A), 특징 선택 모 델(309A) 및 회귀 모델(311A)를 포함할 수 있다. 특징 차원수 감소 작업은 복수의 특징 벡터 클러스터 각각에 대해 하나의 대표적 특징 벡터를 선택하여 분자 설명자 행렬을 줄일 수 있다. 특징 차원수 감소 모델(307A)로 시작하여, 특정 실시예에서, 워크플로 다이어그램(300A)은 기능 블록에서 계속되어, 머신 러닝 모델(302 A)이 크기가 1 x P인 M개의 특징 벡터 세트를 비교하여 상이한 설명자들의 유사성을 평가한다. 예를 들어, 특정 실시예에서, 단백질 설명자 행렬(M x P)의 경우, 상이한 설명자들의 유사성은 크기가 1 x P인 M개의 특징 벡터 세트를 비교하여 평가될 수 있다. 특정 실시예에서, 워크플로 다이어그램(300A)은 이어서 기능 블록에서 계속되어, 머신 러닝 모델(302A)이 특징 벡터(크기 1 x P) 간의 상관관계를 계산한다. 예를 들어, 특정 실시예에서, 머신 러닝 모델(302A)은 각 특징 벡터(크기 1 x P) 간에 상관관계 거리 메트릭을 계산 할 수 있으며, 이는 예를 들어 피어슨 상관관계를 사용하여 계산될 수 있다. 하나 이상의 예에서, 설명자의 클 러스터링은 피어슨 상관관계에서 계산된 설명자들 간의 상관관계(예: 1 - abs(피어슨 상관관계))에 기초할 수 있다. 특정 실시예에서, 워크플로 다이어그램(300A)은 이어서 기능 블록에서 계속되어, 유사한 정보를 포착하는 중복된 특징을 함께 그룹화하기 위해 머신 러닝 모델(302A)이 특징 벡터를 클러스터링한다. 예를 들어, 특정 실 시예에서, 피어슨 상관관계에 기초하여 계산될 수 있는 집계 클러스터링 프로세스 및 계산된 거리 상관관계 메 트릭을 활용하여, 머신 러닝 모델(302A)은 유사한 정보(유사한 특징 벡터)를 포함하는 임의의 모든 중복된 특징을 함께 그룹화하기 위해 특징 벡터를 클러스터링할 수 있다. 특정 실시예에서, 워크플로 다이어그램(300A)은 이어서 기능 블록에서 계속되어, 머신 러닝 모델(302A)이 특징 선택에 유용한 클러스터를 대표하는 각 클 러스터의 중심을 결정한다. 또한, 각 클러스터의 중심을 선택하면 직교 특징 세트를 선택할 수 있어 다중공선성 을 줄일 수 있다. 특정 실시예에서, 워크플로 다이어그램(300A)은 이어서 기능 블록으로 계속되어, 머신 러닝 모델(302A)이 클러스터 수(C)를 반복적으로 평가하여 머신 러닝 모델(302A)의 최적 성능을 가져오는 클러 스터 수를 결정할 수 있다. 특정 실시예에서, 머신 러닝 모델(302A)은 또한 각 특징 벡터 클러스터에 대해 선택된 대표 특징 벡터 중 하나 이상의 가장 예측적인 특징 벡터를 결정할 수 있는 특징 선택 모델(309A)를 포함할 수 있다. 워크플로 다이어그 램(300A)은 기능 블록에서 계속되어, 머신 러닝 모델(302A)이 감소된 설명자 행렬(크기 C x P)로 시작하여, 블록에서 감소된 설명자 행렬(C x P)의 특징 벡터(1 x P)와 사전결정된 일괄 결합 데이터 간의 상관관계를 계산한다. 예를 들어, 특정 실시예에서, 비선형 상관관계 메트릭(예: 최대 정보 계수(MIC), 거리 상 관관계, 상호 정보 또는 기타 유사한 비선형 상관관계 메트릭)을 활용하고/하거나 선형 상관관계 메트릭(예: 피 어슨 상관관계)을 활용하여 머신 러닝 모델(302A)은 감소된 설명자 행렬(C x P)의 선택된 대표적 특징 벡터(1 x P) 및 사전결정된 일괄 결합 데이터(하나 이상의 단백질과 관련됨) 간의 상관관계를 계산하여, 출력을 예측하는 데 적합한 정보를 캡처하는 특징 및/또는 설명자를 순위화할 수 있다. 특정 실시예에서, 워크플로 다이어그램(300A)은 이어서 기능 블록에서 계속 진행되어, 머신 러닝 모델 (302A)이 사전결정된 일괄 결합 데이터를 가장 잘 예측하는 상위 K 특징 벡터(1 x P)를 결정하여 k-베스트 특징 행렬(K x P)을 생성할 수 있다. 예를 들어, 특정 실시예에서, k-베스트 프로세스를 활용하여 머신 러닝 모델 (302A)은 (가령, MIC, 거리 상관관계, 상호 정보 또는 기타 유사한 비선형 상관관계 메트릭에 의해 점수화되는) 사전결정된 일괄 결합 데이터를 가장 잘 예측하는 상위 K 특징 벡터(1xP)를 선택하여 k-베스트 특징 행렬(K x P)을 생성할 수 있다. 구체적으로, 한 실시예에서, k-베스트 특징 행렬(K x P)은 상위 K 특징 벡터(1xP)를 유지 할 수 있으며, 여기서 K는 유지되는 특징 벡터의 수를 나타내는 정수 값이다. 다른 실시예에서, k-베스트 특징 행렬(K x P)은 상위 K 특징 벡터를 유지할 수 있으며, 여기서 K는 유지되는 특징 벡터의 백분율을 나타내는 백 분율 값이다. 특정 실시예에서, 워크플로 다이어그램(300A)은 이어서 기능 블록에서 계속되어, 머신 러닝 모델(302A)이 K 특징 벡터를 반복적으로 평가하여 머신 러닝 모델(302A)의 최적 성능을 가져오는 수를 결정할 수 있다. 특정 실시예에서, 머신 러닝 모델(302A)은 또한 회귀 모델을 포함할 수 있다. 예를 들어, 워크플로 다이어 그램(300A)은 기능 블록에서 계속되어, 머신 러닝 모델(302A)이, 하이퍼 매개변수 최적화 작업의 일 부로 선택되고 업데이트된 기준 하이퍼 매개변수로 시작하여, 머신 러닝 모델(302A)은 n개의 고유한 훈련-테스 트 분할을 활용하여 교차 검증(예: 그룹 K-폴드 교차 검증, 계층화된 K-폴드 교차 검증)을 수행할 수 있다. 교 차 검증은 하나 이상의 가장 예측적인 특징 벡터 및 사전결정된 일괄 결합 데이터에 기초하여 하나 이상의 교차 검증 손실을 계산하는 것을 포함할 수 있다. 예를 들어, 하이퍼 매개변수 최적화 작업의 일부로 선택 및 업데이트된 기준 하이퍼 매개변수, k-베스트 특징 행렬 및 사전결정된 일괄 결합 데이터로 시작하여, 머신 러닝 모델(302A)은 k-베스트 특징 행렬 및 사전결 정된 일괄 결합 데이터(예: 훈련 데이터 세트)의 10개의 고유한 훈련-테스트 분할을 활용하여 교차 검증을 수행 할 수 있다. 한 실시예에서, 머신 러닝 모델(302A)은 k-베스트 특징 행렬 및 사전결정된 일괄 결합 데이터(예: 훈련 데이터 세트)의 2개 이상, 5개 이상, 10개 이상 또는 다른 양의 고유 훈련-테스트 분할을 활용하여 교차 검증을 수행하여, 예를 들어 훈련-테스트 분할로 인해 머신 러닝 모델(302A)의 정확도가 과적합되거나 잘못 계 산될 가능성을 줄일 수 있다. 다른 실시예에서, 머신 러닝 모델(302A)은 정수 n이 예를 들어, 훈련 데이터 세트 에 상응하는 데이터 포인트 수보다 작거나 같은 한, 임의의 n 정수 개수의 고유한 훈련-테스트 분할을 활용하여 교차 검증을 수행할 수 있다. 특정 실시예에서, 워크플로 다이어그램(300A)은 이어서 기능 블록에서 머신 러닝 모델(302A)이 사전결정된 일괄 결합 데이터(예: 다양한 pH 값 및 염 농도에서의 단백질 결합 백분율 및/또는 염 종 및 크로마토그래피 수 지)의 데이터에 부여된 가중치를 더 큰 중요성을 갖는 전이 영역의 가중치 데이터로 조정하면서 계속될 수 있다. 예를 들어, 머신 러닝 모델(302A)은 사전결정된 일괄 결합 데이터의 각 지점에 부여된 가중치를 완전히 결합된 단백질 또는 완전히 결합되지 않은 단백질보다 더 큰 중요성을 갖는 전이 영역(예: 부분적으로 결합된 단백질)의 가중치 데이터로 조정할 수 있다. 특정 실시예에서, 워크플로 다이어그램은 에서는 머신 러닝 모델(302A)이 단백질 P 세트에 대한 단백질 결합 백분율을 예측하고, 예측된 단백질 결합 백분율 및 실험적으로 결정된 단백질 결합 백분율 사이의 손실을 최소화하여 머신 러닝 모델(302A)를 최적화한다. 특정 실시예에서,워크플로 다이어그램(300A)은 이어서 기능 블록에서 머신 러닝 모델가 고유한 훈련-테스트 분할로 모 델 최적화를 n번 반복하고 평균 점수를 보고하는 것으로 계속될 수 있다. 구체적으로, 머신 러닝 모델(302A)의 회귀 작업에는 사전결정된 일괄 결합 데이터와 k-베스트 특징 행렬을 수신 하고, 사전결정된 일괄 결합 데이터와 k-베스트 특징 행렬에 기초하여 단백질 P 세트에 대한 단백질 결합 백분 율을 예측하는 것(기능 블록)이 포함될 수 있다. 그런 다음, 머신 러닝 모델(302A)은 하나 이상의 특정 pH 값 및 염 농도(예: 염화나트륨(NaCl) 농도, 인산염(PO43-) 농도) 및/또는 염 종(예: 아세트산나트륨(CH3COONa) 종, 인산나트륨(Na3PO4) 종) 및 크로마토그래피 수지에 대해 예측된 단백질 결합 백분율 및 실험적으로 결정된 단백질 결합 백분율 간의 손실(예: 제곱 오차 합(SSE))을 최소화(기능 블록)하여 최적화될 수 있다. 일부 실시예에서, pH 값 및 염 농도 및/또는 염 종 및 크로마토그래피 수지는 하나 이상의 단백질의 분자 결합 특성 과 관련될 수 있다. 따라서, 도 3a의 워크플로 다이어그램(300A)에 의해 제시된 바와 같이, 머신 러닝 모델(302A)은 표적 단백질(예: 항체)을 식별하고 가장 유망한 치료 항체 후보의 조기 식별을 통해 치료 항체 후보 또는 기타 면역 요법 후보의 선택 프로세스를 가속화하기 위한 단백질 정제의 간소화된 프로세스의 일부로서 하나 이상의 표적 단백질의 분자 결합 특성의 예측치를 생성하도록 반복적으로 훈련될 수 있다. 예를 들어, 인-실리코 환경에서 표적 단백질(예: 항체)을 식별하는 간소화된 프로세스는 다양한 질병을 치료하는 데 사용될 수 있는 하나 이상 의 치료용 mAb, bsAb, tsAb, 2+1 Ab 또는 기타 유사한 면역 요법의 다운스트림 개발 및 제조를 용이하게 하고 가속화할 수 있다. 예를 들어, 일단 훈련되면, 머신 러닝 모델(302A)(예: \"부스팅\" 머신 러닝 모델)은 최적화된 하이퍼 매개변수 (예: 일반 매개변수, 부스터 매개변수, 학습 과제 매개변수) 및 머신 러닝 모델(302A)의 훈련 중에 학습된 학습 가능 매개변수(예: 회귀 모델 가중치, 결정 변수)와 하나 이상의 관심 단백질에 상응하는 아미노산 서열 세트를 나타내는 분자 설명자 행렬의 특징 벡터의 선택된 k-베스트 행렬을 활용하여 하나 이상의 단백질의 분자 결합 특성의 예측치(예: 하나 이상의 특정 pH 값 및 특정 염 농도 및/또는 특정 염 종 및 크로마토그래피 수지에서의 단백질 결합 백분율의 예측치)를 생성하는 데 활용될 수 있다. 구체적으로, 공개된 실시예에 따라, 일단 훈련되면, 머신 러닝 모델(302A)은 훈련 중에 학습된 최적화된 하이퍼 매개변수(예: 일반 매개변수, 부스터 매개변수, 학습 과제 매개변수) 및 학습가능 매개변수(예: 회귀 모델 가중 치, 결정 변수)를 활용하여, 하나 이상의 관심 단백질에 상응하는 아미노산 서열 세트와, 하나 이상의 관심 단 백질의 결합 특성과 관련된 pH 값 및 염 농도 및/또는 염 종 및 크로마토그래피 수지의 하나 이상의 세트를 나 타내는 분자 설명자 행렬의 특징 벡터의 선택된 k-베스트 행렬만을 입력으로 하여, 하나 이상의 표적 단백질에 대한 단백질 결합 백분율(예: 주어진 pH 값 및 염 농도에 대한 용액 내의 리간드에 결합될 것으로 예측되는 단 백질 세트의 백분율) 및/또는 Log(Kp) 값의 제1 주성분(PC1)(결합 백분율의 로짓 변환)을 예측할 수 있다. 일부 실시예에서, 도 7-13을 참조하여 아래에 설명된 바와 같이, 주어진 pH 및 염 농도에 대한 결합 백분율을 예측하 는 대신, Log(Kp) 값의 제1 주성분(PC1)(결합 백분율의 로짓 변환)이 주어진 수지에 대한 설계 공간(일부 데이 터 포인트 세트가 소정 범위의 pH/염 농도를 포괄함)에 걸친 데이터에서 예측될 수 있다. 이런 방식으로, 하나 이상의 관심 단백질에 대한 결합된 단백질 백분율에 대한 컴퓨팅 모델 기반 예측치를 제공 함으로써, 상당한 업스트림 실험 없이 하나 이상의 관심 단백질의 분자 결합 특성 및 용출 특성을 결정할 수 있 다. 즉, 하나 이상의 관심 단백질 중 바람직한 단백질은 인-실리코 환경에서 하나 이상의 관심 단백질 중 바람 직하지 않은 단백질과 식별되고 구별될 수 있으며, 인-실리코 환경에서 식별된 바람직한 단백질은 다양한 질병 을 치료하는 데 사용될 수 있는 하나 이상의 치료용 mAb, bsAb, tsAb 또는 기타 유사한 면역 요법의 다운스트림 개발을 촉진하고 용이하게 하는 데 추가로 활용될 수 있다(예: 업스트림 실험 기간 및 실험 비효율성을 줄이고 어떤 후보 단백질이 정제하기 어려울 수 있는지, 그리고 확장하여 궁극적으로 제조하기 어려울 수 있는지에 대 한 인-실리코 피드백을 제공함으로써). 예를 들어, 분자 설명자 행렬을 적어도 부분적으로 기반으로, 머신 러닝 모델은 하나 이상의 단백질의 분자 결합 특성의 예측치를 얻도록 구성될 수 있다. 분자 결합 특성으로부터 바람 직한 단백질을 식별할 수 있다. 본 실시예는 주로 하나 이상의 표적 단백질의 분자 결합 특성의 예측치를 생성 하는 머신 러닝 모델(302A)와 관련하여 논의되지만, 훈련된 머신 러닝 모델(302A)은 현재 공개되는 실시예에 따 라 하나 이상의 단백질의 용출 특성의 예측치를 생성하거나 하나 이상의 단백질의 유출 특성의 예측치를 생성할 수도 있다는 점을 이해해야 한다. 도 3b는 도 3a와 관련하여 위에서 논의한 바와 같이 머신 러닝 모델(302A)를 최적화하고 최적화된 머신 러닝 모 델(302B)을 활용하여 하나 이상의 표적 단백질의 분자 결합 특성의 예측치를 생성하여, 표적 단백질(예: 항체) 을 식별하고 가장 유망한 치료 항체 후보의 조기 식별을 통해 치료 항체 후보 또는 기타 면역 요법 후보의 선택 프로세스를 가속화하는 단백질 정제의 간소화된 프로세스의 일부로, 공개된 실시예에 따라 자세한 워크플로 다 이어그램(300B)을 도시한다. 구체적으로, 아래에서 추가로 이해할 수 있듯이, 워크플로 다이어그램(300B)은 도 3a와 관련하여 위에서 논의한 바와 같이 워크플로 다이어그램(300A)보다 개선된 것을 나타낼 수 있다. 예를 들 어, 아래에 논의된 바와 같이, 워크플로 다이어그램(300B)은 하나 이상의 베이지안 최적화 프로세스(예: 순차적 모델 기반 최적화(SMBO), 예상 개선(EI))를 수행하여 예를 들어, 특징 차원수 감소 모델(307B), 특징 선택 모델 (309B) 및 회귀 모델(311B) 중 어떤 기능 블록을 실행할지, 그리고 특징 차원수 감소 모델(307B), 특징 선택 모 델(309B) 및 회귀 모델(311B)의 결정된 기능 블록을 실행할 순서를 선택적으로 결정함으로써, 머신 러닝 모델 (302B)을 반복적으로 최적화하고 평가하는 것을 포함할 수 있다. 도 3b에 도시된 바와 같이, 특정 실시예에서, 워크플로 다이어그램(300B)은 하나 이상의 처리 장치(예: 도 5 및 도 6과 관련하여 아래에서 논의될 컴퓨팅 장치 및 인공 지능 아키텍처)를 활용하여 수행될 수 있으며, 여기에는 하드웨어(예: 범용 프로세서, 그래픽 처리 장치(GPU), 애플리케이션 특정 집적 회로(ASIC), 시스템 온 칩(SoC), 마이크로컨트롤러, 필드 프로그래밍가능 게이트 어레이(FPGA), 중앙 처리 장치(CPU), 애플 리케이션 프로세서(AP), 시각 처리 장치(VPU), 신경 처리 장치(NPU), 신경 결정 프로세서(NDP), 딥 러닝 프로세 서(DLP), 텐서 처리 장치(TPU), 신경형 처리 장치(NPU), 또는 게놈 데이터, 프로테오믹스 데이터, 대사체학 데 이터, 메타게놈학 데이터, 전사체학 데이터 또는 기타 오믹스 데이터를 처리하고 이에 기초하여 하나 이상의 결 정을 내리는 데 적합할 수 있는 기타 처리 장치), 소프트웨어(예: 하나 이상의 프로세서에서 구동/실행되는 명 령어), 펌웨어(예: 마이크로코드) 또는 이들의 조합을 포함할 수 있다. 특정 실시예에서, 워크플로 다이어그램(300B)은 하나 이상의 P 단백질 세트에 대한 아미노산 서열을 가져오는 기능 블록에서 시작할 수 있다. 예를 들어, 일부 실시예에서, 기능 블록에서, 하나 이상의 P 단백질 세트에 대한 실험 아미노산 서열 및/또는 하나 이상의 P 단백질 세트에 대한 분자 아미노산 서열의 하나 이상의 분배 계수(Kp) 스크린을 가져올 수 있다. 그런 다음, 워크플로 다이어그램(300B)은 하나 이상의 P 단백질 세트 에 대한 아미노산 서열을 포맷하고 크기가 M-x-N인 분자 설명자 행렬을 생성하는 기능 블록에서 계속될 수 있다. 특정 실시예에서 M은 설명자 수(M = 1024)일 수 있고 N은 경쇄(LC) 및 중쇄(HC) 아미노산 서열 모두에 대한 하 나 이상의 P 단백질 세트의 주어진 단백질의 아미노산 수일 수 있다. 기능 블록에서, 워크플로 다이어그램 (300B)은 또한 모든 아미노산(N)에 걸쳐 분자 설명자 행렬의 설명자(M)의 가중 평균을 생성하는 것을 포함할 수 있다. 예를 들어, 특정 실시예에서, 모든 아미노산(N)에 걸쳐 분자 설명자 행렬의 설명자(M)의 가중 평균을 계 산하여 하나 이상의 P 단백질 세트의 각 단백질에 대해 크기가 Mx1인 설명자 벡터를 생성할 수 있다. 예를 들어, 일부 실시예에서, 머신 러닝 모델(도 3a와 관련하여 위에서 설명한 바와 같음)은 하나 이상의 P 단 백질 세트의 각 단백질에 대한 설명자의 하나 이상의 Mx1 벡터를 생성할 수 있다. 특정 실시예에서, 워크플로 다이어그램(300B)은 이어서 높은 염 농도에서 침전을 통해 아미노산 서열 데이터를 제거하고 결합 전이 영역을 우선시하기 위해 실험 데이터에 가중치를 두어 설명자 벡터를 전처리하는 기능 블록 에서 계속될 수 있다(예: -2 < Log[Kp] < +2, 또는 -0.5 < Log[Kp] < +2). 특정 실시예에서, 이전에 논의 된 바와 같이, 워크플로 다이어그램(300B)은 도 3a와 관련하여 위에서 논의된 바와 같이 머신 러닝 모델(302A) 를 최적화하기 위해 제공될 수 있으며, 이어서 최적화된 머신 러닝 모델(302B)은 현재 공개된 실시예에 따라 하 나 이상의 표적 단백질의 분자 결합 특성의 예측치를 생성하는 데 활용될 수 있다. 예를 들어, 워크플로 다이어 그램(300B)은 기능 블록에서 특징 차원수 감소 모델(307B) 특징 선택 모델(309B) 및 회귀 모델(311B) 중 어떤 기능 블록을 실행할지, 그리고 특징 차원수 감소 모델(307B), 특징 선택 모델(309B) 및 회귀 모델(311B)의 기능 블록을 실행할 순서를 선택적으로 결정할 수 있다. 예를 들어, 특정 실시예에서, 머신 러닝 모델(302B)(예: 앙상블 러닝 모델)을 최적화하기 위한 프로세스의 일부 로서, 기능 블록에서 워크플로 다이어그램(300B)은 하나 이상의 베이지안 최적화 프로세스(예: 순차적 모 델 기반 최적화(SMBO), 예상 개선(EI))를 수행하여 머신 러닝 모델(302B)을 최적화하고 평가할 수 있다. 예를 들어, 한 실시예에서, 베이지안 최적화 프로세스(예: SMBO, EI)는 예를 들어, 특징 차원수 감소 모델(307B), 특 징 선택 모델(309B) 및 회귀 모델(311B)의 기능 블록 중 가장 예측가능하거나 가장 유망한 것을 선택하여 실행 하고/하거나 이러한 기능 블록을 실행하는 순서를 선택하기 위해 구성되고 활용될 수 있는 하나 이상의 확률 기 반 목적 함수를 포함할 수 있다. 특징 차원수 감소 모델(307B), 특징 선택 모델(309B) 및 회귀 모델(311B)의 이러한 기능 블록은 아래에서 논의된다. 특정 실시예에서, 실행을 위해 선택된 기능 블록인 특징 차원수 감소 모델(307B), 특징 선택 모델(309B) 및 회 귀 모델(311B)에 기초하여, 기능 블록에서 워크플로 다이어그램(300B)은 예를 들어, 그룹 K-폴드 교차 검 증을 사용한 네스티드(nested) 교차 검증을 활용하여, 머신 러닝 모델(302B)의 정확도를 추정하도록 더 진행될 수 있다. 이런 방식으로, 워크플로 다이어그램(300B)은 머신 러닝 모델(302B)을 최적화하여 예를 들어 위에서 도 3a와 관련하여 논의한 머신 러닝 모델(302A)와 비교하여, 하나 이상의 표적 단백질의 분자 결합 특성의 예측 치를 보다 효율적으로 생성할 수 있다(예: 머신 러닝 모델(302B)의 실행 시간 감소 및 머신 러닝 모델(302B)을 저장하기에 적합한 데이터베이스 용량 감소). 특정 실시예에서, 워크플로 다이어그램(300B)은 이어서 기능 블록에서 최적화된 머신 러닝 모델(302B)을 훈련하고 평가하면서 계속될 수 있다. 예를 들어, 일부 실시예에서 최적화된 머신 러닝 모델(302B)(예: 기능 블 록에서 최적화된 대로)은 하나 이상의 P 단백질 세트에 대한 아미노산 서열을 나타내는 설명자 벡터(예: 기능 블록에서 계산된 대로)와 실행을 위해 선택된 특징 차원수 감소 모델(307B), 특징 선택 모델(309B) 및 회귀 모델(311B)의 기능 블록에 기초하여 훈련되고 평가될 수 있다. 특정 실시예에서, 기능 블록의 워크플로 다이어그램(300B)은 또한 최적화된 하이퍼 매개변수 세트(예: 일 반 매개변수, 부스터 매개변수, 학습 과제 매개변수) 및 최적화된 학습가능 매개변수 세트(예: 회귀 모델 가중 치, 결정 변수)(예: 도 3a의 워크플로 다이어그램(300A)와 관련하여 위에서 반복적으로 최적화되고 논의된 대로)를 최적화된 머신 러닝 모델(302B)에 적용하고, 최적화된 머신 러닝 모델(302B)을 활용하여 현재 공개된 실시예에 따라 하나 이상의 표적 단백질의 분자 결합 특성의 예측치를 생성하는 것을 추가로 포함할 수 있다. 특정 실시예에서, 워크플로 다이어그램(300B)은 이어서 기능 블록에서, 하나 이상의 표적 단백질의 분자 결합 특성에 대한 후속 예측에 활용될, 최적화된 머신 러닝 모델(302B), 최적화된 하이퍼 매개변수 세트(예: 일 반 매개변수, 부스터 매개변수, 학습 과제 매개변수) 및 최적화된 학습가능 매개변수 세트(예: 회귀 모델 가중 치, 결정 변수)를 저장할 수 있다. 특정 실시예에서, 예를 들어 추론 단계(예: 최적화된 머신 러닝 모델(302B)이 상술한 바와 같이 최적화된 하이 퍼 매개변수 세트 및 학습가능 세트와 함께 훈련 및 저장된 후) 동안, 도 3b에서 추가로 설명된 바와 같이, 머 신 러닝 모델(302B)의 특징 차원수 감소 모델(307B)은 분자 설명자 행렬을 수신하거나 가져와서 설명자 행렬의 하나 이상의 설명자 세트를 확대/축소 및 정규화할 수 있다. 예를 들어, 분자 설명자 행렬은 P 단백질 세트에 상응하는 아미노산 서열 세트를 나타낼 수 있다. 특정 실시예에서, 특징 차원수 감소 모델(307B)은 설명자 간의 상관관계 거리(예: 1 - abs(피어슨 상관관계))를 결정하여 하나 이상의 설명자 세트의 클러스터링을 수행한 다 음, 중심에 가장 가까운 설명자만 저장할 수 있다. 예를 들어, 일부 실시예에서, 피어슨 상관관계에 따라 계산 될 수 있는 계산된 상관관계 거리 메트릭을 활용하여, 특징 차원수 감소 모델(307B)은 유사한 정보(유사한 특징 벡터)를 포함하는 모든 중복된 특징을 그룹화하고 클러스터를 나타내는 각 클러스터의 중심을 결정하기 위해 특 징 벡터를 클러스터링할 수 있다. 특정 실시예에서, 특징 차원수 감소 모델(307B)은 선택된 설명자의 수를 최적 화할 수 있다. 특정 실시예에서, MIC 지표, 거리 상관관계, 상호 정보 또는 기타 유사한 비선형 상관관계 지표 및/또는 기타 선형 상관관계 메트릭(예: 피어슨 상관관계)를 활용하여, 특징 선택 모델(309B)은 설명자 간의 비선형 상관관계 를 계산하고 단백질 결합 백분율을 출력할 수 있다. 하나 이상의 다른 실시예에서, 특징 선택 모델(309B)은 설 명자 간의 비선형 상관관계를 계산하고 거리 상관관계, 상호 정보 또는 기타 유사한 비선형 상관관계 메트릭을 활용하여 단백질 결합 백분율을 출력할 수 있다. 예를 들어, 특징 선택 모델(309B)은 k-베스트 프로세스 및 MIC 에 기초하여 감소된 분자 설명자 행렬의 k-베스트 가장 예측적인 특징 벡터를 결정하여, 감소된 분자 설명자 행 렬의 특징 벡터와 하나 이상의 특정 pH 값 및 염 농도 및/또는 염 종 및 크로마토그래피 수지에 대한 실험적으 로 결정된 단백질 결합 백분율 간의 상관관계를 결정할 수 있다. 다른 실시예에서는 상관관계 결정의 일부로 MIC를 활용하는 것의 대안으로, 거리 상관관계, 상호 정보 또는 기타 유사한 비선형 상관관계 메트릭을 활용할 수 있다. 그런 다음 특징 선택 모델(309B)은 높은 상관관계를 갖는 설명자를 선택하고 선택된 설명자를 최적화 할 수 있다. 특정 실시예에서는 특징 선택 모델(309B)은 머신 러닝 모델(302B)의 전체 성능(예: 처리 속도, 저 장 용량)에 대한 영향에 따라 설명자 세트를 선택할 수 있다. 예를 들어, 일부 실시예에서는 특징 선택 모델 (309B)이 K개의 설명자를 반복적으로 평가하여 머신 러닝 모델(302B)의 최적 성능을 가져오는 설명자의 수를 결 정할 수 있다. 일부 실시예에서는 특징 선택 모델(309B)이 전체 성능에 대한 영향에 따라 설명자 세트 선택을 전적으로 선택적으로 수행할 수 있다.예를 들어, 다른 실시예에서, 특징 선택 모델(309B)은 예를 들어 하나 이상의 Boruta 특징 선택 알고리즘, 하나 이상의 SHapley Additive exPlanations(SHAP) 특징 선택 알고리즘 또는 다른 유사한 재귀적 특징 제거 알고리 즘을 수행하여 K 설명자를 선택하고 선택된 K 설명자의 수의 백분율을 최적화할 수 있다. 특정 실시예에서, 머 신 러닝 모델(302B)의 회귀 모델(311B)는 그런 다음 pH 값, 염 농도 및 설명자 시퀀스 기반 설명자를 입력으로 수신한 다음, 단백질 P 세트에 대한 단백질 결합 백분율의 예측치를 출력하고, 예측된 단백질 결합 백분율과 실 험적으로 결정된 단백질 결합 백분율 사이의 손실을 최소화하여 머신 러닝 모델(302B)을 최적화할 수 있다. 따라서, 도 3b의 워크플로 다이어그램에 의해 추가로 설명된 바와 같이, 머신 러닝 모델(302B)은 표적 단백질을 식별하고 가장 유망한 치료 항체 후보의 조기 식별을 통해 치료 항체 후보 또는 기타 면역 요법 후보의 선택 프 로세스를 가속화하기 위한 단백질 정제의 간소화된 프로세스의 일부로 하나 이상의 표적 단백질의 분자 결합 특 성의 예측치를 생성하도록 반복적으로 훈련된다. 예를 들어, 인-실리코 표적 단백질(예: 항체)을 식별하는 간소 화된 프로세스는 다양한 환자 질병을 치료하는 데 사용될 수 있는 하나 이상의 치료용 mAb, bsAb, tsAb 또는 기 타 유사한 면역 요법의 다운스트림 개발 및 제조를 용이하게 하고 가속화할 수 있다. 예를 들어, 일단 훈련되면, 머신 러닝 모델(302B)(예: \"부스팅\" 머신 러닝 모델)은 최적화된 하이퍼 매개변수 (예: 일반 매개변수, 부스터 매개변수, 학습 과제 매개변수) 및 머신 러닝 모델(302B)의 훈련 중에 학습된 학습 가능 매개변수(예: 회귀 모델 가중치, 결정 변수)와 하나 이상의 관심 단백질에 상응하는 아미노산 서열 세트를 나타내는 분자 설명자 행렬의 특징 벡터의 선택된 k-베스트 행렬을 활용하여 하나 이상의 단백질의 분자 결합 특성의 예측치(예: 하나 이상의 특정 pH 값 및 특정 염 농도 및/또는 특정 염 종 및 크로마토그래피 수지에서의 단백질 결합 백분율의 예측치)를 생성하는 데 활용될 수 있다. 구체적으로, 공개된 실시예에 따라, 일단 훈련되면, 머신 러닝 모델(302B)은 훈련 동안 학습된 최적화된 하이퍼 매개변수(예: 일반 매개변수, 부스터 매개변수, 학습 과제 매개변수) 및 학습가능 매개변수(예: 회귀 모델 가중 치, 결정 변수)를 활용하여 하나 이상의 관심 단백질에 상응하는 아미노산 서열 세트와, 하나 이상의 관심 단백 질의 결합 특성과 관련된 하나 이상의 관심 단백질의 pH 값 및 염 농도 및/또는 염 종 및 크로마토그래피 수지 세트를 나타내는 분자 설명자 행렬의 특징 벡터의 선택된 k-베스트 행렬만을 입력으로 하여 하나 이상의 관심 단백질에 대한 단백질 결합 백분율(예: 주어진 pH 값 및 염 농도에 대한 용액 내의 리간드에 결합될 것으로 예 측되는 단백질 세트의 백분율)을 예측할 수 있다. 또한, 공개된 실시예에 따라, 앙상블 러닝(302B)은하나 이상 의 베이지안 최적화 프로세스를 활용하여 더욱 최적화되어 분자 결합 특성의 예측치(예: 하나 이상의 특정 pH 값 및 특정 염 농도 및/또는 특정 염 종 및 크로마토그래피 수지에서의 단백질 결합 백분율의 예측치)를 보다 효율적으로 생성할 수 있다. 이런 방식으로, 하나 이상의 관심 단백질에 대한 단백질 결합 백분율의 컴퓨팅 모델 기반 및 최적화된 예측치를 제공함으로써, 상당한 업스트림 실험 없이 하나 이상의 관심 단백질의 분자 결합 특성 및 용출 특성을 결정할 수 있다. 즉, 하나 이상의 관심 단백질 중 바람직한 단백질은 인-실리코 환경에서 하나 이상의 관심 단백질 중 바람직하지 않은 단백질과 식별되고 구별될 수 있으며, 인-실리코 환경에서 식별된 바람직한 단백질은 다양한 질병을 치료하는 데 사용될 수 있는 하나 이상의 치료용 mAb, bsAb, tsAb 또는 기타 유사한 면역 요법의 다운스 트림 개발을 촉진하고 용이하게 하는 데 추가로 활용될 수 있다(예: 업스트림 실험 기간 및 실험 비효율성을 줄 이고 어떤 후보 단백질이 정제하기 어려울 수 있는지, 그리고 확장하여 궁극적으로 제조하기 어려울 수 있는지 에 대한 인-실리코 피드백을 제공함으로써). 예를 들어, 분자 설명자 행렬을 적어도 부분적으로 기반으로 머신 러닝 모델은 하나 이상의 단백질의 분자 결합 특성의 예측치를 얻도록 구성될 수 있다. 분자 결합 특성으로부터 바람직한 단백질을 식별할 수 있다. 본 실시예는 주로 하나 이상의 표적 단백질의 분자 결합 특성의 예측치를 생성하는 머신 러닝 모델(302B)과 관련하여 논의되지만, 훈련된 머신 러닝 모델(302B)은 현재 공개된 실시예에 따라 하나 이상의 단백질의 용출 특성의 예측치를 생성하거나 하나 이상의 단백질의 유출 특성의 예측치를 생성 할 수도 있다는 점을 인식해야 한다. 도 4는 공개된 실시예에 따라 표적 단백질(예: 항체)을 식별하고 가장 유망한 치료적 항체 후보의 조기 식별을 통해 치료적 항체 후보 또는 기타 면역 요법 후보의 선택 프로세스를 가속화하기 위한 간소화된 단백질 정제 프 로세스의 일부로서 하나 이상의 표적 단백질의 분자 결합 특성의 예측치를 생성하는 방법의 흐름도를 보여 준다. 방법은 하나 이상의 처리 장치(예: 도 5 및 도 6과 관련하여 아래에서 논의되는 컴퓨팅 장치 및 인 공 지능 아키텍처)를 활용하여 수행될 수 있으며, 여기에는 하드웨어(예: 범용 프로세서, 그래픽 처리 장치 (GPU), 애플리케이션 특정 집적 회로(ASIC), 시스템 온 칩(SoC), 마이크로컨트롤러, 필드 프로그래밍가능 게이 트 어레이(FPGA), 중앙 처리 장치(CPU), 애플리케이션 프로세서(AP), 시각 처리 장치(VPU), 신경 처리 장치 (NPU), 신경 결정 프로세서(NDP), 딥 러닝 프로세서(DLP), 텐서 처리 장치(TPU), 신경형 처리 장치(NPU), 또는게놈 데이터, 프로테오믹스 데이터, 대사체학 데이터, 메타게놈학 데이터, 전사체학 데이터 또는 기타 오믹스 데이터를 처리하고 하나 이상의 프로세서를 만드는 데 적합할 수 있는 기타 처리 장치), 펌웨어(예: 마이크로코 드) 또는 이들의 일부 조합이 포함될 수 있다. 방법은 하나 이상의 단백질에 상응하는 아미노산 서열 세트를 나타내는 분자 설명자 행렬에 액세스하는 하 나 이상의 처리 장치로 블록에서 시작할 수 있다. 그런 다음 방법은 하나 이상의 단백질의 분자 결합 특성의 예측치를 생성하도록 훈련된 머신 러닝 모델과 관련된 하이퍼 매개변수 세트를 정밀화하는 하나 이상의 처리 장치로 블록에서 계속될 수 있다. 도시된 바와 같이, 방법은 머신 러닝 모델에 대해 원하는 정 밀도에 도달할 때까지 하위 프로세스(예: 도 4의 방법의 일부를 둘러싼 점선으로 표시)를 반복적으로 실행 하여 하이퍼 매개변수 세트를 최적화하는 반복적 하위 프로세스로 진행할 수 있다. 예를 들어, 방법은 하나 이상의 처리 장치가 복수의 특징 벡터 클러스터 각각에 대해 하나의 대표 특징 벡 터를 선택하여 분자 설명자 행렬을 줄이는 블록에서 계속될 수 있으며, 여기서 각 특징 벡터 클러스터는 유사한 특징 벡터를 포함한다. 방법은 이어서 블록에서 하나 이상의 처리 장치가 선택된 대표 특징 벡터와 하나 이상의 단백질과 관련된 사전결정된 일괄 결합 데이터 간의 상관관계에 기초하여 복수의 특징 벡터 클러스터 각각에 대한 선택된 대표 특징 벡터 중 하나 이상의 가장 예측적인 특징 벡터를 결정하도록 계속될 수 있다. 방법은 이어서 블록에서 하나 이상의 처리 장치가 하나 이상의 가장 예측적인 특징 벡터 및 사 전결정된 일괄 결합 데이터에 기초하여 하나 이상의 교차 검증 손실을 계산하도록 계속될 수 있다. 방법은 이어서 블록에서 하나 이상의 처리 장치가 하나 이상의 교차 검증 손실에 따라 하이퍼 매개변수 세트를 업 데이트하면서 종료될 수 있다. 도 5는 공개된 실시예에 따라 표적 단백질(예: 항체)을 식별하고 유망한 치료 항체 후보의 조기 식별을 통해 치 료 항체 후보 또는 기타 면역 요법 후보의 선택 프로세스를 가속화하기 위한 간소화된 단백질 정제 프로세스의 일부로서 하나 이상의 표적 단백질의 분자 결합 특성의 예측치를 생성하는 데 사용될 수 있는 하나 이상의 컴퓨 팅 장치의 예를 도시한다. 특정 실시예에서, 하나 이상의 컴퓨팅 장치는 여기에 설명되거나 예시된 하나 이상의 방법의 하나 이상의 단계를 수행할 수 있다. 특정 실시예에서, 하나 이상의 컴퓨팅 장치는 여 기에 설명되거나 예시된 기능을 제공한다. 특정 실시예에서, 하나 이상의 컴퓨팅 장치에서 실행되는 소프 트웨어는 여기에 설명되거나 예시된 하나 이상의 방법의 하나 이상의 단계를 수행하거나 여기에 설명되거나 예 시된 기능을 제공한다. 특정 실시예에는 하나 이상의 컴퓨팅 장치의 하나 이상의 부분이 포함된다. 본 개시는 임의의 적절한 수의 컴퓨팅 시스템을 고려한다. 본 개시는 임의의 적절한 물리적 형태를 취하는 하나 이상의 컴퓨팅 장치를 고려한다. 제한이 아닌 예로서, 하나 이상의 컴퓨팅 장치는 임베디드 컴 퓨터 시스템, 시스템 온 칩(SOC), 단일 보드 컴퓨터 시스템(SBC)(예: 컴퓨터 온 모듈(COM) 또는 시스템 온 모듈 (SOM)), 데스크톱 컴퓨터 시스템, 랩톱 또는 노트북 컴퓨터 시스템, 대화형 키오스크, 메인프레임, 컴퓨터 시스 템 메시, 모바일 전화, 개인용 디지털 보조기(PDA), 서버, 태블릿 컴퓨터 시스템, 증강/가상 현실 장치 또는 이 들 중 두 개 이상의 조합일 수 있다. 적절한 경우, 하나 이상의 컴퓨팅 장치는 단일이거나 분산될 수 있고; 여러 위치에 걸쳐 있을 수 있고; 여러 머신에 걸쳐 있을 수 있고; 여러 데이터 센터에 걸쳐 있을 수 있고; 또는 하나 이상의 네트워크에 하나 이상의 클라우드 구성 요소를 포함할 수 있는 클라우드에 상주할 수 있다. 적절한 경우, 하나 이상의 컴퓨팅 장치는 실질적인 공간적 또는 시간적 제한 없이 여기에 설명되거나 예시 된 하나 이상의 방법의 하나 이상의 단계를 수행할 수 있다. 제한이 아닌 예로서, 하나 이상의 컴퓨팅 장치 는 여기에 설명되거나 예시된 하나 이상의 방법의 하나 이상의 단계를 실시간 또는 일괄 모드로 수행할 수 있다. 적절한 경우, 하나 이상의 컴퓨팅 장치는 상이한 시간 또는 상이한 위치에서 여기에 설명되거나 예 시된 하나 이상의 방법의 하나 이상의 단계를 수행할 수 있다. 특정 실시예에서, 하나 이상의 컴퓨팅 장치는 프로세서, 메모리, 데이터베이스, 입출력 (I/O) 인터페이스, 통신 인터페이스 및 버스를 포함한다. 이 공개는 특정 배열로 특정 수의 특 정 구성 요소를 갖는 특정 컴퓨터 시스템을 설명하고 예시하지만, 이 공개는 임의의 적절한 배열로 임의의 적절 한 수의 임의의 적절한 구성 요소를 갖는 임의의 적절한 컴퓨터 시스템을 고려한다. 특정 실시예에서, 프로세서 는 컴퓨터 프로그램을 구성하는 것과 같은 명령어를 실행하기 위한 하드웨어를 포함한다. 제한이 아닌 예 로서, 명령어를 실행하기 위해 프로세서는 내부 레지스터, 내부 캐시, 메모리 또는 데이터베이스 로부터 명령어를 불러들이고(또는 페치), 이를 디코딩하고 실행하며, 그리고 하나 이상의 결과를 내부 레 지스터, 내부 캐시, 메모리 또는 데이터베이스에 기록할 수 있다. 특정 실시예에서 프로세서는데이터, 명령어 또는 주소에 대한 하나 이상의 내부 캐시를 포함할 수 있다. 이 공개는 프로세서가 적절한 경우 적절한 수의 적절한 내부 캐시를 포함하는 것을 고려한다. 제한이 아닌 예로서, 프로세서는 하나 이 상의 명령어 캐시, 하나 이상의 데이터 캐시 및 하나 이상의 변환 룩어사이드 버퍼(TLB)를 포함할 수 있다. 명 령어 캐시의 명령어는 메모리 또는 데이터베이스의 명령어 사본일 수 있으며, 명령어 캐시는 프로세 서가 해당 명령어를 불러들이는 속도를 높일 수 있다. 데이터 캐시의 데이터는 프로세서에서 실행되는 명령어가 작동하도록 메모리 또는 데이터베이스(50 6)의 데이터 사본이거나, 프로세서에서 실행되는 후속 명령어에 의해 액세스하기 위한 또는 메모리 또는 데이터베이스에 쓰기 위한, 프로세서에서 실행된 이전 명령어의 결과, 또는 다른 적합한 데이터 이다. 데이터 캐시는 프로세서에 의한 읽기 또는 쓰기 작업을 가속화할 수 있다. TLB는 프로세서에 대한 가상 주소 변환을 가속화할 수 있다. 특정 실시예에서 프로세서는 데이터, 명령어 또는 주소를 위한 하나 이상의 내부 레지스터를 포함할 수 있다. 이 공개는 적절한 경우 프로세서가 임의의 적절한 수의 임 의의 적절한 내부 레지스터를 포함하는 것을 고려한다. 적절한 경우 프로세서는 하나 이상의 산술 논리 장 치(ALU)를 포함할 수 있고, 멀티 코어 프로세서일 수 있고, 또는 하나 이상의 프로세서를 포함할 수 있다. 이 공개는 특정 프로세서를 설명하고 예시하지만, 이 공개는 임의의 적절한 프로세서를 고려한다. 특정 실시예에서, 메모리는 프로세서가 실행하기 위한 명령어 또는 프로세서가 작동하기 위한 데이터를 저장하기 위한 주 메모리를 포함한다. 제한이 아닌 예시로서, 하나 이상의 컴퓨팅 장치는 데이터 베이스 또는 다른 소스(예를 들어, 다른 하나 이상의 컴퓨팅 장치)로부터 메모리로 명령어를 로 드할 수 있다. 그런 다음 프로세서는 메모리로부터 내부 레지스터 또는 내부 캐시로 명령어를 로드할 수 있다. 명령어를 실행하기 위해, 프로세서는 내부 레지스터 또는 내부 캐시로부터 명령어를 불러들여 디 코딩할 수 있다. 명령어를 실행하는 동안 또는 실행 후에 프로세서는 하나 이상의 결과(중간 또는 최종 결 과일 수 있음)를 내부 레지스터 또는 내부 캐시에 쓸 수 있다. 프로세서는 그 결과 중 하나 이상을 메모리 에 쓸 수 있다. 특정 실시예에서 프로세서는 (데이터베이스 또는 다른 곳에 반해) 하나 이상의 내부 레지스터, 내부 캐시 또는 메모리에서만 명령어를 실행하고 (데이터베이스 또는 다른 곳에 반해) 하나 이상의 내부 레지스터, 내부 캐시 또는 메모리에서의 데이터에 대해서만 작동한다. 하나 이상의 메모리 버스(각각 주소 버스와 데이터 버스를 포함할 수 있음)는 프로세서를 메모리에 결합할 수 있다. 버스는 아래에 설명된 대로 하나 이상의 메모리 버스를 포함할 수 있다. 특정 실시예에서, 하나 이상의 메모리 관리 유닛(MM U)이 프로세서와 메모리 사이에 상주하며 프로세서가 요청한 메모리에 대한 액세스를 용이 하게 한다. 특정 실시예에서, 메모리에는 랜덤 액세스 메모리(RAM)가 포함된다. 이 RAM은 적절한 경우 휘 발성 메모리일 수 있다. 적절한 경우, 이 RAM은 동적 RAM(DRAM) 또는 정적 RAM(SRAM)일 수 있다. 또한, 적절한 경우, 이 RAM은 단일 포트 또는 다중 포트 RAM일 수 있다. 이 공개는 임의의 적합한 RAM을 고려한다. 메모리 는 적절한 경우 하나 이상의 메모리 장치를 포함할 수 있다. 이 공개는 특정 메모리를 설명하고 예시 하지만, 이 공개는 임의의 적합한 메모리를 고려한다. 특정 실시예에서, 데이터베이스에는 데이터 또는 명령어를 위한 대용량 저장소가 포함된다. 제한이 아닌 예시로서, 데이터베이스는 하드 디스크 드라이브(HDD), 플로피 디스크 드라이브, 플래시 메모리, 광 디스 크, 자기광학 디스크, 자기 테이프 또는 USB(Universal Serial Bus) 드라이브 또는 이들 중 두 개 이상의 조합 을 포함할 수 있다. 데이터베이스는 적절한 경우 이동식 또는 이동불가(또는 고정) 매체를 포함할 수 있다. 데이터베이스는 적절한 경우 하나 이상의 컴퓨팅 장치의 내부 또는 외부에 있을 수 있다. 특정 실시예에서, 데이터베이스는 비휘발성 솔리드 스테이트 메모리이다. 특정 실시예에서, 데이터베이스 는 읽기 전용 메모리(ROM)를 포함한다. 적절한 경우, 이 ROM은 마스크 프로그래밍 ROM, 프로그래밍가능 ROM(PROM), 소거가능 PROM(EPROM), 전기적으로 소거가능가능 PROM(EEPROM), 전기적으로 변경가능 ROM(EAROM), 플래시 메모리 또는 이들 중 두 개 이상의 조합일 수 있다. 이 공개는 대량 데이터베이스가 임의의 적절한 물리적 형태를 취하는 것을 고려한다. 데이터베이스는 적절한 경우, 프로세서와 데이터베이스 사이의 통신을 용이하게 하는 하나 이상의 저장 제어 유닛을 포함할 수 있다. 적절한 경우, 데이터베이스 는 하나 이상의 데이터베이스를 포함할 수 있다. 이 공개는 특정 저장소를 설명하고 예시하지만, 이 공개 는 임의의 적합한 저장소를 고려한다. 특정 실시예에서, I/O 인터페이스는 하나 이상의 컴퓨팅 장치와 하나 이상의 I/O 장치 사이의 통신을 위한 하나 이상의 인터페이스를 제공하는 하드웨어, 소프트웨어 또는 둘 다를 포함한다. 하나 이상의 컴퓨팅 장 치는 적절한 경우 이러한 I/O 장치 중 하나 이상을 포함할 수 있다. 이러한 I/O 장치 중 하나 이상은 사람과 하나 이상의 컴퓨팅 장치 간의 통신을 가능하게 할 수 있다. 제한이 아닌 예로서, I/O 장치에는 키보드, 키패드, 마이크, 모니터, 마우스, 프린터, 스캐너, 스피커, 스틸 카메라, 스타일러스, 태블릿, 터치 스 크린, 트랙볼, 비디오 카메라, 다른 적합한 I/O 장치 또는 이들 중 두 개 이상의 조합이 포함될 수 있다. I/O 장치에는 하나 이상의 센서가 포함될 수 있다. 이 공개는 임의의 적합한 I/O 장치 및 이를 위한 임의의 적합한 I/O 인터페이스을 고려한다. 적절한 경우, I/O 인터페이스에는 프로세서가 이러한 I/O 장치 중 하나 이상을 구동할 수 있도록 하는 하나 이상의 장치 또는 소프트웨어 드라이버가 포함될 수 있다. I/O 인터페 이스에는 적절한 경우 하나 이상의 I/O 인터페이스가 포함될 수 있다. 이 공개는 특정 I/O 인터페이 스를 설명하고 예시하지만, 이 공개는 임의의 적합한 I/O 인터페이스를 고려한다. 특정 실시예에서, 통신 인터페이스는 하나 이상의 컴퓨팅 장치와 하나 이상의 다른 컴퓨팅 장치 또는 하나 이상의 네트워크 간의 통신(예를 들어, 패킷 기반 통신)을 위한 하나 이상의 인터페이스를 제공하는 하드웨어, 소프트웨어 또는 둘 다를 포함한다. 제한 없이 예시로서, 통신 인터페이스는 이더넷 또는 다른 유선 기반 네트워크와 통신하기 위한 네트워크 인터페이스 컨트롤러(NIC) 또는 네트워크 어댑터, 또는 WI-FI 네 트워크와 같은 무선 네트워크와 통신하기 위한 무선 NIC(WNIC) 또는 무선 어댑터를 포함할 수 있다. 이 공개는 임의의 적합한 네트워크 및 이를 위한 임의의 적합한 통신 인터페이스를 고려한다. 제한이 아닌 예로서, 하나 이상의 컴퓨팅 장치는 임시(ad hoc) 네트워크, 개인 영역 네트워크(PAN), 근거 리 네트워크(LAN), 광역 네트워크(WAN), 대도시역 네트워크(MAN), 인터넷의 하나 이상의 부분 또는 이들 중 두 개 이상의 조합과 통신할 수 있다. 이들 네트워크 중 하나 이상의 하나 이상의 부분은 유선 또는 무선일 수 있 다. 예로서, 하나 이상의 컴퓨팅 장치는 무선 PAN(WPAN)(예를 들어, BLUETOOTH WPAN), WI-FI 네트워크, WI-MAX 네트워크, 셀룰러 전화 네트워크(예를 들어, GSM(Global System for Mobile Communications) 네트워 크), 기타 적합한 무선 네트워크 또는 이들 중 두 개 이상의 조합과 통신할 수 있다. 하나 이상의 컴퓨팅 장치 는 적절한 경우 이러한 네트워크 중 하나에 적합한 임의의 통신 인터페이스를 포함할 수 있다. 통신 인터페이스는 적절한 경우 하나 이상의 통신 인터페이스를 포함할 수 있다. 이 공개는 특정 통신 인 터페이스를 설명하고 예시하지만, 이 공개는 임의의 적합한 통신 인터페이스를 고려한다. 특정 실시예에서, 버스는 하나 이상의 컴퓨팅 장치의 구성 요소를 서로 결합하는 하드웨어, 소프트웨 어 또는 둘 다를 포함한다. 제한이 아닌 예시로서, 버스는 AGP(Accelerated Graphics Port) 또는 다른 그 래픽 버스, EISA(Enhanced Industry Standard Architecture) 버스, FSB(Front-side Bus), HT(HYPERTRANSPORT) 인터커넥트, ISA(Industry Standard Architecture) 버스, INFINIBAND 인터커넥트, LPC(Low-Pin-Count) 버스, 메모리 버스, MCA(Micro Channel Architecture) 버스, PCI(Peripheral Component Interconnect) 버스, PCIe(PCI-Express) 버스, SATA(Serial Advanced Technology Attachment) 버스, VLB(Video Electronics Standards Association Local) 버스, 다른 적합한 버스 또는 이들 중 두 개 이상의 조합을 포함할 수 있다. 버 스는 적절한 경우 하나 이상의 버스를 포함할 수 있다. 이 공개는 특정 버스를 설명하고 예시하지만, 이 공개는 임의의 적합한 버스 또는 인터커넥트를 고려한다. 여기서, 컴퓨터 판독가능한 비일시적 저장 매체 또는 매체들은 하나 이상의 반도체 기반 또는 다른 집적 회로 (IC)(예를 들어, 현장 프로그래밍가능 게이트 어레이(FPGA) 또는 애플리케이션 특정 IC(ASIC)), 하드 디스크 드 라이브(HDD), 하이브리드 하드 드라이브(HHD), 광 디스크, 광 디스크 드라이브(ODD), 자기광 디스크, 자기광 드 라이브, 플로피 디스켓, 플로피 디스크 드라이브(FDD), 자기 테이프, 솔리드 스테이트 드라이브(SSD), RAM 드라 이브, SECURE DIGITAL 카드 또는 드라이브, 다른 임의의 적합한 컴퓨터 판독가능 비일시적 저장 매체 또는 이들 중 두 개 이상의 적합한 조합을 포함할 수 있다(적절한 경우). 컴퓨터 판독가능 비일시적 저장 매체는 휘발성, 비휘발성 또는 휘발성과 비휘발성의 조합일 수 있다(적절한 경우). 도 6은 (위에서 도 5와 관련하여 논의한 바와 같이 하나 이상의 컴퓨팅 장치의 일부로 포함될 수 있는) 예 시적인 인공지능(AI) 아키텍처의 다이어그램을 도시하며, 이는 공개된 실시예에 따라 표적 단백질(예: 항체)을 식별하고 가장 유망한 치료용 항체 후보의 조기 식별을 통해 치료용 항체 후보 또는 기타 면역 요법 후보의 선택 프로세스를 가속화하기 위한 간소화된 단백질 정제 프로세스의 일부로 하나 이상의 표적 단백질의 분자 결합 특성의 예측치를 생성하는 데 사용될 수 있다. 특정 실시예에서, AI 아키텍처는 예를 들어, 하드웨어(예: 범용 프로세서, 그래픽 처리 장치(GPU), 애플리케이션 특정 집적 회로(ASIC), 시스템 온 칩 (SoC), 마이크로컨트롤러, 필드 프로그래밍가능 게이트 어레이(FPGA), 중앙 처리 장치(CPU), 애플리케이션 프로 세서(AP), 시각 처리 장치(VPU), 신경 처리 장치(NPU), 신경 결정 프로세서(NDP), 딥 러닝 프로세서(DLP), 텐서 처리 장치(TPU), 신경형 처리 장치(NPU) 및/또는 다양한 분자 데이터를 처리하고 이에 기초하여 하나 이상의 결 정을 내리는 데 적합할 수 있는 기타 처리 장치), 소프트웨어(예: 하나 이상의 처리 장치에서 구동/실행되는 명령어), 펌웨어(예: 마이크로코드) 또는 이들의 일부 조합을 포함할 수 있는 하나 이상의 처리 장치를 활용하여 구현될 수 있다. 일부 실시예에서, 도 6에 도시된 바와 같이, AI 아키텍처는 머신 러닝(ML) 알고리즘 및 기능, 자연어 처리(NLP) 알고리즘 및 기능, 전문가 시스템, 컴퓨터 기반 비전 알고리즘 및 기능, 음성 인식 알고리즘 및 기능, 계획 알고리즘 및 기능, 로봇 알고리즘 및 기능을 포함할 수 있다. 특정 실 시예에서, ML 알고리즘 및 기능은 대량의 데이터(예: 유전체학 데이터, 프로테오믹스 데이터, 대사체학 데 이터, 메타게놈학 데이터, 전사체학 데이터 또는 기타 오믹스 데이터와 같은 \"빅 데이터\")에서 패턴을 찾는 데 적합할 수 있는 임의의 통계 기반 알고리즘을 포함할 수 있다. 예를 들어, 특정 실시예에서, ML 알고리즘 및 기 능은 딥 러닝 알고리즘, 지도 학습 알고리즘, 비지도 학습 알고리즘을 포함할 수 있다. 특정 실시예에서, 딥 러닝 알고리즘은 대량의 데이터로부터 깊은 수준의 표현 및 추상화를 학습하는 데 활 용될 수 있는 임의의 인공 신경망(ANN)을 포함할 수 있다. 예를 들어, 딥 러닝 알고리즘은 퍼셉트론, 다층 퍼셉트론(MLP), 오토인코더(AE), 합성곱 신경망(CNN), 순환 신경망(RNN), 장단기 메모리(LSTM), 격자 순환 단위 (GRU), 제한된 볼츠만 머신(RBM), 딥 신념 네트워크(DBN), 양방향 순환 딥 신경망(BRDNN), 생성적 적대적 네트 워크(GAN), 딥 Q-네트워크, 신경 자기 회귀 분포 추정(NADE), 적대적 네트워크(AN), 주의 모델(AM), 스파이킹 신경망(SNN), 딥 강화 학습 등과 같은 ANN을 포함할 수 있다. 특정 실시예에서, 지도 학습 알고리즘은 예를 들어, 레이블이 지정된 예시를 사용하여 과거에 학습한 내용 을 미래 이벤트를 예측하기 위한 새로운 데이터에 적용하는 데 사용될 수 있는 임의의 알고리즘을 포함할 수 있 다. 예를 들어, 알려진 훈련 데이터 세트의 분석에서 시작하여, 지도 학습 알고리즘은 출력 값을 예측하기 위해 추론된 함수를 생성할 수 있다. 지도 학습 알고리즘은 또한 해당 출력을 정확하고 의도된 출력과 비 교하고 오류를 찾아, 지도 학습 알고리즘을 그에 따라 수정할 수 있다. 반면, 비지도 학습 알고리즘 은 예를 들어 비지도 학습 알고리즘를 훈련하는 데 사용된 데이터가 분류되지 않았거나 레이블이 지정되지 않은 경우 적용될 수 있는 임의의 알고리즘을 포함할 수 있다. 예를 들어, 비지도 학습 알고리즘은 시스템 이 레이블이 지정되지 않은 데이터에서 은닉 구조를 설명하는 함수를 어떻게 추론할 수 있는지 연구하고 분석할 수 있다. 특정 실시예에서, NLP 알고리즘 및 기능은 음성 및/또는 텍스트와 같은 자연어를 자동으로 조작하는 데 적 합할 수 있는 알고리즘 또는 기능을 포함할 수 있다. 예를 들어, 일부 실시예에서, NLP 알고리즘 및 기능 은 콘텐츠 추출 알고리즘 또는 기능, 분류 알고리즘 또는 기능, 기계 번역 알고리즘 또는 기능, 질문 답변(QA) 알고리즘 또는 기능, 및 텍스트 생성 알고리즘 또는 기능을 포함할 수 있다. 특정 실 시예에서, 콘텐츠 추출 알고리즘 또는 기능은 예를 들어 다른 애플리케이션에서 활용하기 위해 전자 문서 (예: 웹페이지, 텍스트 편집기 문서 등)로부터 텍스트 또는 이미지를 추출하는 수단을 포함할 수 있다. 특정 실시예에서, 분류 알고리즘 또는 기능은 지도 학습 모델(예: 로지스틱 회귀, 나이브 베이즈, 확률적 경사 하강법(SGD), k-최근접 이웃, 의사결정 트리, 랜덤 포레스트, 지원 벡터 머신(SVM) 등)을 활용하여 지도 러닝 모델에 대한 데이터 입력으로부터 학습하고 이에 기초하여 새로운 관찰 또는 분류를 수행할 수 있는 임의 의 알고리즘을 포함할 수 있다. 기계 번역 알고리즘 또는 기능은 예를 들어 한 언어의 소스 텍스트를 다른 언어의 텍스트로 자동 변환하는 데 적합할 수 있는 임의의 알고리즘 또는 기능을 포함할 수 있다. QA 알고리즘 또는 기능은 음성 제어 개인 비서 장치에서 수행하는 것과 같이, 예를 들어, 자연어로 인간이 제기한 질문 에 자동으로 답하는 데 적합할 수 있는 임의의 알고리즘 또는 기능을 포함할 수 있다. 텍스트 생성 알고리즘 또 는 기능은 자연어 텍스트를 자동으로 생성하는 데 적합할 수 있는 임의의 알고리즘 또는 기능을 포함할 수 있다. 특정 실시예에서, 전문가 시스템은 특정 분야(예: 주식 거래, 의학, 스포츠 통계 등)에 대한 전문 지식과 경험을 가진 인간 또는 조직의 판단 및 행동을 시뮬레이션하는 데 적합할 수 있는 임의의 알고리즘 또는 기능을 포함할 수 있다. 컴퓨터 기반 비전 알고리즘 및 기능은 이미지(예: 사진 이미지, 비디오 이미지)에서 정보 를 자동으로 추출하는 데 적합할 수 있는 임의의 알고리즘 또는 기능을 포함할 수 있다. 예를 들어, 컴퓨터 기 반 비전 알고리즘 및 기능은 이미지 인식 알고리즘 및 머신 비전 알고리즘을 포함할 수 있다. 이미지 인식 알고리즘은 예를 들어 하나 이상의 이미지 프레임 또는 기타 표시된 데이터에 포함될 수 있는 객체, 장소, 사람 등을 자동으로 식별 및/또는 분류하는 데 적합할 수 있는 임의의 알고리즘을 포함할 수 있다. 머신 비전 알고리즘에는 컴퓨터가 \"볼 수 있도록 하는\", 예를 들어, 의사 결정 목적으로 다양한 데이터 특 성을 처리, 분석, 및/또는 측정하기 위한 이미지를 획득하기 위해 특수화된 광학 수단을 갖춘 이미지 센서 카메라에 의존하도록 하는 데 적합할 수 있는 임의의 알고리즘을 포함할 수 있다. 특정 실시예에서, 음성 인식 알고리즘 및 기능은 예를 들어, 컴퓨팅이 한 명 이상의 사용자와 음성으로 통 신할 수 있도록 자동 음성 인식(ASR), 컴퓨터 음성 인식, 음성-텍스트(STT) 또는 텍스트-음성(TTS)을 통해 음성 언어를 인식하고 텍스트로 번역하는 데 적합할 수 있는 임의의 알고리즘 또는 기능을 포함할 수 있다. 특정 실시예에서, 계획 알고리즘 및 기능은, 각 동작이 동작을 수행하기 전에 충족해야 하는 고유한 전제 조건 세트를 포함할 수 있는, 동작 시퀀스를 생성하는 데 적합할 수 있는 임의의 알고리즘 또는 기능을 포 함할 수 있다. AI 계획의 예로는 고전적 계획, 다른 문제로의 축소, 시간적 계획, 확률적 계획, 선호도 기반 계 획, 조건적 계획 등이 있다. 마지막으로, 로봇 알고리즘 및 기능에는 예를 들어 모션, 제스처, 수행 작업, 의사 결정, 감정 등을 통해 하나 이상의 장치가 인간의 거동을 복제할 수 있도록 하는 임의의 알고리즘, 기능 또는 시스템이 포함될 수 있다. 여기에 설명된 것은 위에서 설명한 바와 같이 하나 이상의 단백질의 분자 결합 특성을 예측하는 것과 관련된 프 로세스를 포함한다. 여기에는 단백질의 아미노산 서열을 가져오고 아미노산 서열에 기초하여 분자 설명자 행렬 을 생성하는 것이 포함될 수 있다. 단백질 분자는 아미노산 서열로 구성된다. 아미노산 서열은 문자열(예: 철자 열)로 표현될 수 있다. 하나 이상의 예에서, 아미노산 서열은 분자 설명자 행렬을 생성하기 위해 머신 러닝 모 델(예: 신경망)에 입력될 수 있다. 하나 이상의 예에서 머신 러닝 모델은 아미노산 서열을 사용하여 사전 훈련 될 수 있다. 예를 들어, 머신 러닝 모델은 단백질 언어 모델을 포함할 수 있다. 다른 예에서 머신 러닝 모델은 비지도 방식으로 사전 훈련될 수 있다. 일부 실시예에서, 머신 러닝 모델은 단백질 구조를 생성하는 데 사용된 시퀀스를 나타내는 구조 기반 설명자를 생성하도록 구성될 수 있다. 생성되는 분자적 특징 행렬은 상응하는 단백질의 분자 결합 특성을 예측하는 데 사용될 수 있다. 일부 실시예에 서, 분자 설명자 행렬은 각 단백질의 서열에서 각 아미노산에 대한 설명자를 나타내는 복수의 특징 벡터로 구성 된 다차원 행렬(즉, 텐서)일 수 있다. 예측되는 분자 결합 특성을 결정하기 위해, 하나 이상의 예에서, 다차원 분자 설명자 행렬(예: 설명자 텐서)의 차원이 감소될 수 있다. 일부 실시예에서, 다차원 분자 설명자 행렬은(각 분자에 대한 아미노산별 특징 벡터 포함) 각 분자의 모든 아미노산에 걸쳐 특징 벡터를 평균화함으로써 2차원 분자적 특징 행렬(각 분자에 대한 분자적 특징 벡터 포함)로 감소될 수 있다. 일부 실시예에서, 분자 설명자 행 렬의 특징 벡터 수를 줄이는 데 사용되는 특징 차원수 감소 기술은 특히 평균화 이후 중복 특징 벡터를 제거하 는 것을 포함할 수 있다. 예를 들어, 일부 특징 벡터(및/또는 여기에 포함된 특징)가 높은 상관관계를 가질 수 있기 때문에, 단일 대표 특징 벡터가 높은 상관관계를 가진 특징 벡터의 컬렉션을 나타내도록 식별될 수 있다. 일부 실시예에서, 클러스터링 기술(예: 계층적/집계적 클러스터링 기술)을 사용하여 유사한(예: 해당 임베딩이 임베딩 공간에서 서로로부터 임계 거리보다 짧은) 특징 벡터를 식별할 수 있다. 식별된 특징 벡터에서, 하나 이 상의 대표 특징 벡터가 유사한 특징 벡터의 각 클러스터로부터 해당 클러스터의 \"대표\"로 선택될 수 있다. 위에서 언급했듯이, 대표 특징 벡터는 머신 러닝 모델에 입력되어 단백질의 분자 결합 특성의 예측치를 얻을 수 있다. 이러한 단백질은 잠재적인 약물 발견 검정에 관심 있는 단백질일 수 있다. 머신 러닝 모델은 하나 이상의 단백질을 설명하는 하나 이상의 대표 특징 벡터를 입력으로 받고, 대표 특징 벡터에 기초하여 단백질의 분자 결 합 특성의 예측치를 출력하도록 훈련될 수 있다. 일부 실시예에서, 머신 러닝 모델은 (하나 이상의 실증적으로 평가된 단백질의 가져온 아미노산 서열에 기초하 여 도 3a의 머신 러닝 모델에 의해 생성된 훈련 분자 설명자 행렬로부터의) 분자 설명자와 실증적으로 평 가된 단백질과 관련된 사전결정된 일괄 결합 데이터를 정렬하여 훈련될 수 있다. 정렬된 후, 머신 러닝 모델을 훈련하기 위해 지도 회귀가 수행될 수 있다. 하나 이상의 예에서, 사용된 회귀자는 배깅된(bagged) 의사결정 트 리, 배깅된 선형 모델, 비-배깅된 선형 모델, 랜덤 포레스트, 선형 포레스트 또는 다른 유형의 회귀자 또는 이 들의 조합을 포함할 수 있다. 일부 실시예에서, 훈련 단계의 일부는 머신 러닝 모델의 하이퍼 매개변수 세트를 최적화하는 것을 포함한다. 하 나 이상의 예에서, 하이퍼 매개변수는 정규화 매개변수, 추정자 수, 최대 트리 깊이 등을 포함할 수 있다. 하나 이상의 예에서, 파이프라인(예: 특징 차원수 감소 모델(307A), 특징 선택 모델(309A, 309B) 및 회귀 모델(311A, 311B))은 공동으로 최적화될 수 있다. 특징 차원수 감소 모델은 상관관계 클러스터링, 재귀적 특징 제거 및/또 는 분자 설명자 행렬의 특징 벡터 수를 줄이기 위한 기타 기술을 사용하도록 구성될 수 있다. 일부 실시예에서, 훈련 단계는 또한, 머신 러닝 모델의 최적화된 학습가능 매개변수 세트가 식별된 다음, 최적 화된 학습가능 매개변수 세트가 결정될 때까지 교차 검증 테스트가 반복적으로 수행되는, 교차 검증 단계를 포 함할 수 있다. 예를 들어, 머신 러닝 모델에 의사 결정 트리 구조(예: 랜덤 포레스트)가 포함된 경우, 학습가능매개변수의 수는 트리 수 및/또는 트리의 깊이를 포함할 수 있다. 최적화된 학습가능 매개변수 세트는 머신 러 닝 모델의 성능을 최적화하도록 선택된다. 최적화된 학습가능 매개변수 세트를 사용하여 머신 러닝 모델은 훈련 세트에 포함되지 않은 새로운 아미노산 서열의 분자 결합 특성의 예측치를 생성하도록 훈련될 수 있다. 일부 실시예에서, 하나 이상의 추가 단계를 수행하여 아미노산 서열에 기초하여 하나 이상의 단백질 분자의 분 자 결합 특성을 예측할 수 있다. 공개된 기술의 목표 중 하나는 평가할 분자의 특성을 예측하는 것을 포함한다. 특히, 단백질 분자가 수지에 얼마나 잘 결합하는지는 새로운 치료제의 개발에 사용될 수 있는 귀중한 임상 정보 및/또는 가치있는 제조 공정 개발 가능성 정보를 제공한다. 상기 내용은 아미노산 서열에 기초하여 분자 결합 특성을 예측하기 위해 수행할 수 있는 상기 언급된 단계에 대한 추가/대체 단계 세트를 설명한다. 여기에 설명된 기술은 많은 기술적 이점을 실현한다. 예를 들어, 도 1과 관련하여 설명된 바와 같이, 약물 발견 목적과 같은 분자의 결합 특성을 테스트하는 것은 복잡하고 시간이 많이 걸리는 프로세스이다. 예를 들어, 하나 이상의 단백질 정제 프로세스를 수행하기 위한 도 1의 실험적 예의 실험 기간은 수 주에 걸칠 수 있다. 반 면에, 하나 이상의 단백질 정제 프로세스를 수행하기 위한 컴퓨팅 모델 기반 예(예: 여기에 설명된 머신 러닝 모델)의 실행 시간은 몇 분에 불과할 수 있다. 따라서, 실험 예는 모든 잠재적 분자를 테스트하기 위 한 비이상적인 프로세스를 설명한다. 여기에 설명된 머신 러닝 모델은 주어진 시간 내에 스크리닝할 수 있는, 또는, 주어진 연구자에 의해 스크리닝될 수 있는 분자의 수를 늘림으로써 테스트에 소요되는 시간을 줄일 수 있 고, 이것이 모델의 목적이다. 또 다른 예로, 분자 설명자 행렬은 다양한 기존 단백질 언어 모델(예: 도 1의 분 자 설명자)을 사용하여 생성할 수 있다. 따라서 기존 기술을 활용하여 머신 러닝 모델의 입력을 생성함으 로써 수집해야 하는 추가 데이터의 양을 줄이고 필요한 추가 모델 훈련의 양을 줄일 수 있다. 또 다른 예로, 여 기에 설명된 머신 러닝 모델은 모델의 정확도를 유지하거나 높이면서 더 적은 데이터를 사용하여 훈련될 수 있 다. 예를 들어, 분자 설명자 행렬을 머신 러닝 모델(매우 많은 양의 설명자를 포함할 수 있음)에 입력하는 대신, 분자 설명자 행렬을 축소하여 가장 예측적인 특징 벡터를 결정할 수 있다(머신 러닝 모델에 대한 입력으 로 사용). 이 설명자 축소 프로세스는 머신 러닝 모델에 대한 훈련 프로세스를 더욱 최적화할 수 있다. 예를 들 어, 각 훈련 분자 설명자 행렬은 가장 예측적인 특징 벡터를 결정함으로써 감소될 수 있으며, 모델은 가장 예측 적인 특징 벡터에 기초하여 훈련될 수 있다. 도 7은 다양한 실시예에 따라 특징 생성, 특징 차원수 감소, 특징 필터링, 재귀적 모델 기반 특 징 제거 및 회귀 모델 최적화를 수행하기 위한 또 다른 고수준 워크플로 다이어그램을 도시한다. 특징 생성, 특징 차원수 감소, 특징 필터링 및 회귀 모델 최적화에 대한 설명은 여기에도 동일하게 적용될 수 있다. 그러나 다이어그램과 달리 다이어그램은 재귀적 모델 기반 특징 제거를 추가로 포함할 수 있다. 재귀적 모델 기반 특징 제거는 특징 세트의 특징 수를 추가로 줄이기 위한 추가 모델을 포함할 수 있다. 특히, 재귀적 모델 기반 특징 제거는 과적합(overfitting)의 가능성을 방지하거나 줄이는 데 도움이 될 수 있다. 예를 들어, 도 8을 참조하면, 재귀적 모델 기반 특징 제거는 도 8의 머신 러닝 모델을 구현할 수 있다. 도 8은 도 3a와 유사한 구성 요소를 포함하며, 유사한 레이블이 이러한 구성 요소를 참조하는 데 사용 된다. 예를 들어, 워크플로는 모델 및 머신 러닝 모델을 포함할 수 있다. 머신 러닝 모델 은 특징 차원수 감소 모델(307A), 특징 필터링 모델(309A), 재귀적 특징 제거 모델 및 회귀 모델(311A)를 포함할 수 있다. 워크플로는 워크플로(300A)와 유사한 경로를 따를 수 있지만, 가장 예측적인 특징 벡터가 재귀적 특징 제거 모델을 통해 감소된 특징 벡터를 포함한다는 점에 차이가 있다. 예를 들어, 하나 이상의 가장 예측적인 특징 벡터를 결정하는 것은 또한 재귀적 특징 제거 모델을 구현하여 특징 벡터의 수를 더욱 줄이는 것을 포함할 수 있다. 특히, 일부 실시예에는 훈련 항목 수보다 작거나 같은 추가로 감소된 특징 벡터의 수에 포함된 다수의 특징 벡터가 포함된다. 일부 실시예에서, 기능 블록에서 재귀적 특징 제거 모델은 대표 특징 벡터에 모델을 맞추도록 구성될 수 있다. 예를 들어, 모델은 회귀 모델일 수 있다. 기능 블록에서, 적합 모델에 기초하여 특징 중요도 점 수를 계산할 수 있다. 특징 중요도 점수는 각 대표 특징 벡터의 중요도를 나타낼 수 있다. 기능 블록에서, 대표 특징 벡터의 하나 이상의 특징 벡터는 각 대표 특징 벡터의 특징 중요도 점수에 따라 제거되어 대표 특징 벡터의 서브세트를 얻을 수 있다. 예를 들어, 가장 중요하지 않은 특징 또는 특징 벡터는 대표 특징 벡터에서 제거될 수 있다. 하나 이상의 예에서, 가장 예측적인 특징 벡터는 대표 특징 벡터의 서브세트에서 하나 이상의 특징 벡터를 포함할 수 있다. 기능 블록에서, 재귀적 특징 제거 모델은 서브세트에 포함된 특징 벡터 의 수가 특징 수량 기준을 충족할 때까지 블록(802-806)을 반복적으로 수행할 수 있다. 예를 들어, 충족되는 특 징 수량 기준은 대표 특징 벡터의 서브세트에 포함된 특징 벡터의 수가 특징 벡터의 임계 수보다 적거나 같은것을 포함한다. 일부 예에서, 임계 수의 특징 벡터는 머신 러닝 모델을 훈련하는 데 사용된 훈련 데이터에 서 동일하거나 유사한 수의 특징을 포함할 수 있다. 일부 예에서, 대표 특징 벡터의 서브세트에 포함된 특징 벡 터의 수는 하이퍼 매개변수 세트 중 하나를 포함할 수 있다. 일부 예에서, 복수의 특징 벡터 클러스터에 포함된 특징 벡터 클러스터의 수는 하이퍼 매개변수 세트 중 하나를 포함한다. 도 9는 다양한 실시예에 따라 분자 결합 특성을 예측하기 위해 머신 러닝 모델을 훈련하는 프로세스를 도시한다. 예를 들어, 도 3a-4와 관련하여 위에서 설명한 프로세스와 비교했을 때, 여기에 설명된 도 9의 프로 세스는 회귀 모델을 훈련하는 데 사용된 데이터(예: 단계 930에서)를 다른 방식으로 구성할 수 있다. 예를 들어, 이전에 설명한 프로세스에서, 실증적으로 평가된 각 단백질에 대해, 머신 러닝 모델(예: 머신 러닝 파이 프라인)을 훈련하는 데 사용된 데이터에는 미리 정의된 양의 실험 조건이 포함된다. 실험 조건은 주어진 실험 조건 세트에 대한 단백질의 분자 결합 특성을 지정할 수 있다. 예를 들어, 데이터는 제1 염 농도 및 제1 pH 수준에서 단백질의 측정된 분자 결합 수준, 제2 염 농도 및 제1 pH 수준에서 단백질의 측정된 분자 결합 수 준, 제1 염 농도 및 제2 pH 수준에서 단백질의 측정된 분자 결합 수준 등을 포함할 수 있다. 하나 이상의 예에 서, 사전결정된 일괄 결합을 위한 미리 정의된 양의 실험 조건은 12개 이상의 실험 조건(예: 4개의 염 농도, 3 개의 pH 수준), 24개 이상의 실험 조건(예: 6개의 염 농도, 4개의 pH 수준) 등을 포함할 수 있다. 위에서 설명 한 대로, 훈련된 머신 러닝 모델은 분자 설명자 행렬 외에도 실험 조건(예: pH 수준 및 염 농도)을 입력으로 사 용하여 하나 이상의 단백질의 분자 결합 특성을 예측할 수 있다. 일부 실시예에서, 실험 조건은 머신 러닝 모델에 입력될 필요가 없으며 대신 예측된 분자 결합 특성이 실험 조 건의 연속체에 대해 결정될 수 있다. 그러나 그렇게 하기 위해서는 도 9에 도시된 바와 같이 훈련 데이터 및 훈 련 프로세스를 조정할 수 있다. 도 9는 다양한 실시예에 따라 하나 이상의 컴퓨팅 모델 기반 단백질 정제 프로세스를 수행하기 위한 머신 러닝 모델의 하이퍼 매개변수 및 학습가능 매개변수를 최적화하기 위한 프로세스의 워크플로 다이어그램을 도시 한다. 프로세스는 도 3a-4와 관련하여 위에서 설명한 것과 달리, 실증적으로 평가된 훈련 단백질의 분자 결합 특성의 변환된 표현을 사용하여 머신 러닝 모델을 훈련할 수 있다. 훈련된 머신 러닝 모델은 분자 결합 특 성의 변환된 표현에 상응하는 값을 출력할 수 있으며, 이는 다시, 주어진 단백질 분자에 대한 모든 실험 조건에 대한 모든 결합 조건을 예측하는 데 사용될 수 있다. 따라서, 머신 러닝 모델을 학습하는 데 필요한 훈련 데이 터의 양은 N개의 서로 다른 실험 조건(예: 염 농도 수준 및 pH 수준)에 대한 N개의 실증적으로 도출된 결합 측 정값으로부터, N개의 실증적으로 도출된 결합 측정값을 해결하는 데 사용할 수 있는 단일 변환된 결합 측정값으 로 줄어들 수 있다. 프로세스에서, 단백질 P의 하나 이상의 아미노산 서열에 상응하는 서열 데이터가 행렬 생성 머신 러 닝(ML) 모델에 제공될 수 있다. 일부 실시예에서, 머신 러닝 모델은 도 3a의 머신 러닝 모델과 동일하거나 유사할 수 있으며, 이전 설명이 적용될 수 있다. 일부 실시예에서, 행렬 생성 ML 모델은 P 단 백질의 아미노산 서열을 나타내는 서열 데이터로부터 분자 설명자 행렬을 생성하도록 훈련될 수 있다. 행렬 생성 ML 모델은 분자 설명자 행렬으로 구조화된 특징 X를 생성할 수 있는 신경망을 포함 할 수 있다. 분자 설명자 행렬은 도 3a의 기능 블록에서 생성된 분자 설명자 행렬과 동일하거나 유사 할 수 있다. 하나 이상의 예에서, 분자 설명자 행렬은 100개 이상의 특징, 500개 이상의 특징, 1,000개 이 상의 특징, 2,000개 이상의 특징, 10,000개 이상의 특징 또는 다른 양의 특징을 포함할 수 있다. 그런 다음 분 자 설명자 행렬의 특징을 분석하여, 해당 단백질 분자의 분자 결합 특성과 상관관계가 있는 특징을 (해당 될 경우) 확인할 수 있다. 분자 설명자 행렬은 분자 수 M에 설명자 수(예: 특징) N을 곱한 차원을 가질 수 있다. 주어진 분자의 경우, 아미노산 서열은 테스트되는 단백질을 형성하는 문자열(예: 알파벳)을 사용하여 표현될 수 있다. 일부 실시예에서, 서열는 또한 실험적으로 분석될 수 있다. 실험은 실증적으로 도출된 단백질 결합 데이터 를 생성할 수 있다. 실증적으로 도출된 단백질 결합 데이터는 일련의 실험 조건에 대한 분자 결 합 특성 값을 포함할 수 있다. 예를 들어, 실증적으로 도출된 단백질 결합 데이터는 주어진 서열(예: 서열 A) 및 제1 실험 조건(예: 제1 염 농도 수준 및 제1 pH 수준)에 대해 분자 결합 특성이 Y1임을 나타낼 수 있다. 마찬가지로, 실증적으로 도출된 단백질 결합 데이터는 해당 서열(예: 서열 A) 및 제2 실험 조건(예: 제2 염 농도 수준 및 제1 pH 수준)에 대해 분자 결합 특성이 Y2임을 나타낼 수 있다. 또한, 실증적으로 도출된 단백 질 결합 데이터는 해당 서열(예: 서열 A) 및 제3 실험 조건(예: 제1 염 농도 수준 및 제2 pH 수준)에 대해 분자 결합 특성이 Y3임을 나타낼 수 있다. 일부 실시예에서, 사전결정된 일괄 결합 데이터는 분자를 행으로, 실험 조건를 열로 하여 공식화될 수 있다. 프로세스는 머신 러닝 모델(예: 머신 러닝 모델)을 훈련하여 일련의 실험 조건에 대한 단백질의 분자 결합 특성을 예측하도록 구성될 수 있다. 가령, 약물 발견 용도로, 분자의 결합 특성을 테스트하는 것은 복잡하 고 시간이 많이 걸리는 프로세스이다(예: 분자를 성장시키고 정제한 다음 테스트하는 데 2~6주가 걸리므로 각 분자를 완전히 평가하는 데 수 주가 걸릴 수 있음). 모든 잠재적 분자를 테스트하는 것은 이상적이지 않다. 따 라서 주어진 시간 내에 스크리닝할 수 있는 분자의 수를 늘리거나 주어진 연구자가 스크리닝할 수 있는 분자의 수를 늘리는 것이 모델의 목표이다. 또 다른 목표는 타임라인 지연이나 추가적인 실험 부담을 초래하지 않고 스 크리닝할 수 있는 분자의 수를 늘리는 것이다. 프로세스는 소수의 학습 예제(예: 소수의 분자)와 다수의 설명자(예: 100개 이상의 특징, 500개 이상의 특 징, 1,000개 이상의 특징, 2,000개 이상의 특징, 10,000개 이상의 특징 등)를 사용하여 훈련될 수 있다. 프로세 스는 머신 러닝 모델을 훈련하여 분자 결합 특성을 예측하기 위해 체계적인 방식으로 설명자를 정렬 할 수 있다. 또한 프로세스는 단백질의 하나 이상의 물리적 특성과 관련이 있는 설명자를 활용할 수 있다. 머신 학습 파이프라인은 분자 설명자 행렬에 기초하여 단백질의 분자 결합 특성을 가장 잘 예측하는 설명 자(예: 특징)를 찾도록 구성될 수 있다. 그런 다음 ML 모델은 어떤 설명자가 가장 예측성이 높은지 시도하여 결 정할 수 있다. 설명적인 예에서, 사전결정된 일괄 결합 데이터는 실험 조건 세트에 대한 각 분석된 단백질의 실증적으로 측정된 결합 특성을 포함한다. 일부 실시예에서, 프로세스는 예를 들어 도 5의 컴퓨팅 시스템을 사용 하여 실증적으로 측정된 결합 특성에 대한 선형화 변환을 수행하는 세트를 포함할 수 있다. 예를 들어, 실 증적으로 측정된 결합 특성은 백분율 결합 측정(예: 단백질이 수지에 Y% 결합됨)을 포함할 수 있다. 프로세스 은 사전결정된 일괄 결합 데이터에 저장된 백분율 결합 실증적으로 측정된 결합 특성을 해당 실증적 으로 측정된 결합 특성의 선형화된 또는 의사 선형 표현으로 변환할 수 있다. 예를 들어, 로짓 변환 연산이 수 행될 수 있다. 로짓 변환에는 결합/비결합 단백질 농도 비율의 로그를 계산하는 것이 포함된다. 이 변환의 결과로, 경계는 0.0-1.0(즉, 0% 결합에서 100% 결합)에서 음의 무한대에서 양의 무한대(log(Kp) 공간)로 변환된다. 데이터가 선 형화되면 더 잘 수렴하는 PCA 모델과 같은 선형 모델을 사용할 수 있다. 일부 실시예에서, 프로세스는 하나 이상의 차원수 감소 기술(예: 주성분 분석(PCA))을 각 분석된 단 백질의 실증적으로 측정된 결합 특성의 선형 표현에 적용하는 것을 포함할 수 있다. PCA는 실증적으로 측 정된 결합 특성의 선형화 변환(예: 로짓 변환)의 제1, 제2 및 이와 유사한 주성분(PC)을 도출하도록 구성될 수 있다. 수행된 PCA는 실증적으로 측정된 단백질 결합 특성의 선형 표현을 보다 간결한 표현으로 나타낼 수 있다. 특히, 실험 조건 C의 수는 사전결정된 일괄 결합 데이터의 데이터 포인트 수를 정의한다. PCA 는 데이터 포인트 수를 C에서 C 이하로 줄일 수 있다. 예를 들어, 사전결정된 일괄 결합 데이터를 얻기 위 해 24개의 실험 조건이 사용된 경우, PCA는 사전결정된 일괄 결합 데이터를 24개 이하(또는 동일)의 데이 터 포인트로 허용할 수 있다. PCA는 실증적으로 측정된 분자 결합 특성의 변환된 버전을 나타내는 변환된 표현을 출력하도록 구성될 수 있다. 테스트하는 분자의 수는 1 이상, 5 이상, 10 이상, 20 이상, 50 이상 또는 다른 값이 될 수 있다. PCA 모델은 데이터(예: 사전결정된 일괄 결합 데이터)를 일련의 저차원성 벡터로 분해할 수 있다. 예를 들 어, 24개의 실험 조건(예: 24개의 실험 데이터 포인트)의 경우, PCA 모델은 데이터의 제1 고유 벡터를 식별할 수 있으며, 이는 데이터 세트의 복수의 분산을 포착할 수 있다. 따라서 PCA는 결합 데이터의 거동을 설명하는 데 사용할 수 있는 저차원 투영을 가능하게 한다. 하나 이상의 예에서, 분자의 평균 결합 효율을 예측하려는 경 우, PCA는 개별적으로 실험 조건을 사용하는 것보다 더 대표적이고 가치 있는 결과를 제공한다. 또한, PCA가 노"}
{"patent_id": "10-2025-7005193", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "이즈가 있는 다차원 데이터의 추세를 간결하게(저차원 표현으로) 요약할 수 있는 능력은 과학자들에게 유용할 수 있다. 해당 분야의 통상의 지식을 가진 자는 PCA에 의해 제1 주성분 및/또는 제2 주성분을 포함하되 이 에 국한되지 않는 임의의 수의 주성분을 식별할 수 있다는 것을 알 것이다. 일부 실시예에서, 예측된 분자 결합 특성은 실증적으로 측정된 분자 결합 특성의 변환된 표현과 비교 될 수 있다. 하나 이상의 예에서, 교차 검증 손실은 머신 러닝 모델이 주어진 단백질의 실증적으로 측정된 분자 결합 특성을 얼마나 잘 예측했는지를 결정하기 위해 계산될 수 있다. 특히, 예측치는 머신 러닝 파이프라 인이 실증적으로 측정된 분자 결합 특성의 변환된 표현을 얼마나 잘 예측하는지를 나타낸다.일부 실시예에서, 930에서 교차 검증 손실이 계산될 수 있다. 이전에 설명한 바와 같이, 하나 이상의 예는 k-폴 드 교차 검증 기술을 사용할 수 있다. 추가적으로 또는 대안적으로, 930에서 계층화된 k-폴드 교차 검증이 계산 될 수 있다. 계층화된 k-폴드 교차 검증은 훈련 세트의 분자를 취하고 분자 결합 특성에 따라 빈으로 순위화하 는 것을 포함한다. 예를 들어, 빈은 약하게 결합하는 단백질에 상응하는 제1 빈, 적당히 결합하는 단백질에 상 응하는 제2 빈, 단단히 결합하는 단백질에 상응하는 제3 빈, 등을 포함할 수 있다. 계층화된 k-폴드 교차 검증 은 빈에 포함된 각 단백질의 짝수 대표와 같은, 대표 서브세트를 선택하여 머신 러닝 파이프라인의 성능을 평가할 수 있다. 도 10a-10d는 다양한 실시예에 따라 주성분 분석을 사용하여 분자 결합 특성을 예측하는 방법을 설명하는 예시 플롯을 보여준다. 예를 들어, 도 10a는 분자 세트의 주성분 분석 결과의 플롯을 보여준다. 플롯에 서 X축은 세트의 각 분자의 제1 주성분 값에 해당하고 Y축은 각 분자의 제2 주성분에 해당한다. 빨간색 타원과 녹색 타원은 데이터 포인트 클러스터의 중심으로부터 제1 및 제2 표준 편차를 나타낸다. 플롯에서 볼 수 있듯이, 분자(예: 데이터 포인트)는 x축을 중심으로 상당히 잘 분포되어 있다. 도 10b는 다양한 실시예에 따라 제1 주성분의 다양한 값에 대한 주어진 분자의 등온 곡선 플롯을 설명한 다. 플롯에서 x축은 분자의 단백질 결합 특성을 결정하기 위해 해당 실험 중에 사용된 염 농도 수준을 나 타내고, y축은 단백질 결합 수준을 나타낸다. 등온 곡선(1022-1030)은 상이한 주성분(PC) 값에 상응한다. 예를 들어, 등온 곡선은 제1 PC(예: PC = -6)에 대해 염 농도 수준이 변함에 따라 단백질 결합이 어떻게 변하 는지를 나타낸다. 등온 곡선은 제2 PC(예: PC = -3)에 대해 염 농도 수준이 변함에 따라 단백질 결합이 어떻게 변하는지를 나타낸다. 등온 곡선은 제3 PC(예: PC = 0)의 염 농도 수준이 변함에 따라 단백질 결 합이 어떻게 변하는지를 나타낸다. 등온 곡선은 제4 PC(예: PC = +3)의 염 농도 수준이 변함에 따라 단백 질 결합이 어떻게 변하는지를 나타낸다. 등온 곡선은 제5 PC(예: PC = +6)의 염 농도 수준이 변함에 따라 단백질 결합이 어떻게 변하는지를 나타낸다. 플롯의 등온 곡선(1022-1030)은 고정된 pH 수준을 사용하여 계산할 수 있다. 플롯에서 볼 수 있듯 이, 제1 PC의 값(예: 곡선의 -6)이 매우 큰 값으로(예: 곡선의 +6) 증가함에 따라, 결합 거동이 변 한다. 플롯의 예에서, 결합 백분율은 낮은 염 농도의 경우 약 100%이고 높은 염 농도 값의 경우 약 0%이 다. 단백질을 제조할 때, 관심 단백질이 아닌 분자를 걸러내기 위해 하나 이상의 단백질 정제 단계를 수행할 수 있 다. 단백질 정제 단계에는 관심 단백질이 수지(예: 크로마토그래피 컬럼)에 결합되도록 하거나 다른 방식으로 촉진하는 것이 포함된다. 이상적으로는 수지가 관심 단백질 모두에 결합한다. 그런 다음 수지에서 단백질을 제 거하기 위해 세척을 적용하여 관심 단백질을 용액에 침전시킬 수 있다. 세척에는 특정 염 농도 수준(및/또는 pH 수준)의 염이 포함될 수 있다. 염 농도 수준은 단백질이 수지에서 분리되는지 여부에 영향을 미칠 수 있다. 예 를 들어, 염 농도 수준이 낮으면 단백질이 수지에 결합된 상태로 유지될 수 있지만 염 농도 수준이 높으면 단백 질이 수지에서 분리될 수 있다. 제거되면 용액/단백질에 대한 검정 또는 기타 연구가 수행될 수 있다. 일반적으로 모든 수지의 경우 전체 설계 공간(단백질이 안정된 통상적인 pH 및 염 범위)에서 완전히 또는 대부 분 결합된 분자는 단백질을 용출할 수 없어 수율이 낮아져 호환되지 않을 수 있다. 일반적으로 결합 및 용출 모 드에서 작동하는 수지의 경우 전체 설계 공간에서 완전히 또는 대부분 결합되지 않은 분자는 단백질을 결합할 수 없어 호환되지 않을 수 있다. 따라서 결합에서 가변성을 표현하는 단백질을 갖는 것이 바람직하다. 결합은 결합 상태(예: 90% 초과 결합)에서 비결합 상태(예: 10% 미만 결합)로 전이되어야 한다. 도 10a-10b에 도시된 바와 같이 제1 주성분은 실험 조건 세트(예: 24가지 염/pH 조합) 대신 단일 값(예: 주성분)을 사용하여 결합 상 태에서 비결합 상태로의 단백질 전이(예: 등온 곡선(822-830)에서 볼 수 있음)를 설명한다. 일부 실시예에서, 도 10b의 플롯에 도시된 바와 같이, 제1 주성분은 결합 백분율로 평균 결합을 시각적으 로 설명할 수 있다. 예를 들어, 등온 곡선에서 볼 수 있듯이, -6의 제1 주성분의 경우 단백질은 수지에 단단히 결합될 수 있다. 등온 곡선은 염 농도 수준에 관계없이 특정 pH 수준 및 제1 주성분 값에 대해 분 석 중인 단백질이 수지에서 분리될 가능성이 낮기 때문에 문제가 있는 것으로 표시될 수 있다. 도 10c의 플롯을 살펴보면, 상이한 주성분 값 세트를 분석할 수 있다. 플롯의 예에서 사용된 분석 중인 단백질과 pH 수준은 도 10b의 플롯과 유사할 수 있지만 반드시 그럴 필요는 없다. 플롯에서 볼 수 있듯이 등온 곡선(1042-1050)은 세척액의 염 농도 수준이 제1 주성분의 상이한 값에 대해 변함에 따라 결 합 백분율이 어떻게 달라지는지 보여준다. 예를 들어, 등온 곡선은 제1 PC(예: PC = -10)에 대해 염 농도 수준이 변함에 따라 단백질 결합이 어떻게 달라지는지 나타낸다. 등온 곡선은 제2 PC(예: PC = -5)의 염농도 수준이 변함에 따라 단백질 결합이 어떻게 변하는지를 나타낸다. 등온 곡선은 제3 PC(예: PC = 0)의 염 농도 수준이 변함에 따라 단백질 결합이 어떻게 변하는지를 나타낸다. 등온 곡선은 제4 PC(예: PC = +5)의 염 농도 수준이 변함에 따라 단백질 결합이 어떻게 변하는지를 나타낸다. 등온 곡선은 제5 PC(예: PC = +10)의 염 농도 수준이 변함에 따라 단백질 결합이 어떻게 변하는지를 나타낸다. 등온 곡선을 살펴보면 염 농도 수준이 변함에 따라 단백질의 결합 백분율이 크게 변하지 않는다. 그러면 등온 곡선도 단백질이 수지에 결합되어 제거할 수 없기 때문에 문제가 있는 것으로 표시될 수 있다. 또 다른 예로, 등온 곡선은 염 농도 수준에 관계없이 실질적으로 정적인 퍼센트 결합을 가질 수 있다. 그러 나 등온 곡선과 달리 이 예의 단백질은 수지에 결합할 수 없다. 따라서 등온 곡선은 모든 단백질이 씻겨 나감에 따라 정제를 수행할 수 없기 때문에 문제가 있는 것으로 표시될 수도 있다. 등온 곡선(1044- 1048)은 염 농도 수준이 변함에 따라 퍼센트 결합이 결합에서 비결합으로 전환되는 더 바람직한 상태를 나타낸 다. 일부 실시예에서, 제1 주성분을 예측하면 무한한 양의 염 농도(및/또는 pH)에 대한 결합 백분율을 결정할 수 있 다. 반면, PCA를 사용하지 않으면 모든 실험 조건(예: 등온 곡선을 따라 있는 지점)에 대한 결합 백분율의 예측 치가 필요할 것이다. 따라서 PCA를 사용하여 제1 주성분을 예측하면 정확도를 희생하지 않고도 단백질의 분자 결합 특성을 예측하는 프로세스가 크게 간소화된다. 일부 실시예에서, PCA는 제1 주성분보다 더 많은 것을 출력할 수 있다. 예를 들어, 제2 주성분도 결정될 수 있 으며 의사 결정 단계를 안내하는 데 사용될 수 있다. 예를 들어, 도 10d를 참조하여 플롯은 단백질에 대 한 제2 주성분의 등온 곡선(1062-1070)을 묘사한다. 등온 곡선(1062-1070)은 염 농도 수준이 제2 주성분 값 세 트에 대해 변함에 따라 단백질의 결합 백분율이 어떻게 변하는지 보여준다. 예를 들어, 등온 곡선은 제1 PC 값(예: 제2 PC 값 = -6)에 대해 염 농도 수준이 변함에 따라 단백질 결합이 어떻게 변하는지를 나타낸다. 등 온 곡선는 제2 PC 값(예: 제2 PC 값 = -3)에 대해 염 농도 수준이 변함에 따라 단백질 결합이 어떻게 변 하는지를 나타낸다. 등온 곡선은 제3 PC 값(예: 제2 PC 값 = 0)에 대해 염 농도 수준이 변함에 따라 단백 질 결합이 어떻게 변하는지를 나타낸다. 등온 곡선은 제4 PC 값(예: 제2 PC 값 = +1)에 대해 염 농도 수 준이 변함에 따라 단백질 결합이 어떻게 변하는지를 나타낸다. 등온 곡선은 제1 PC 값(예: 제2 PC 값 = +2)에 대해 염 농도 수준이 변함에 따라 단백질 결합이 어떻게 변하는지를 나타낸다. 제1 주성분은 결합에서 비 결합으로 전환되는 곳을 이동시킬 수 있다. 일부 예에서, 그러한 전환은 발생하지 않을 수도 있다. 제2 주성분 은 전환을 그렇게 많이 이동시키지 않지만 등온선 곡선(1062-1070)의 가파른 정도를 변경한다. 예를 들어, 등온 선 곡선은 -6의 제2 PC 값을 포함할 수 있으며, 이는 그림에서 보듯이 +2의 제2 PC 값을 갖는 등온선 곡 선에 비해 매우 가파르다(그리고 ~0%의 백분율 한계에 도달하지 않음). 일부 실시예에서, 다른 주성분을 사용하여 이를 수행할 수 있다. 도 10d의 플롯에서 등온 곡선은 \"이상적인\" 곡선을 나타낼 수 있다. 이 예에서, 제1 주성분은 0으로 설정될 수 있고 제2 주성분은 다양할 수 있다. 일부 실시예에서, 머신 러닝 파이프라인은 제1 주성분, 제2 주성분, 다른 주성분 또는 이들의 조합을 출력 하도록 훈련될 수 있다. 머신 러닝 파이프라인은 주성분을 함께 또는 차례로 출력할 수 있다. 일부 실시예에서, 프로세스는 머신 러닝 모델을 훈련하는 데 필요한 데이터 포인트 수를 줄일 수 있다. 예 를 들어, 주성분의 수는 실증적으로 측정된 단백질의 데이터 포인트 수에 의해 제한될 수 있다. 하나 이상의 예 에서, 주성분의 수는 실험 조건의 수보다 적거나 같을 수 있다. 예를 들어, 도 3a-4에 의해 설명된 프로세스는 N개의 실험 조건에 대해 N개의 데이터 포인트를 필요로 할 수 있는 반면, 도 9의 프로세스는 그 수를 1개 의 데이터 포인트로 줄일 수 있다. 도 11a-11f는 다양한 실시예에 따라 실험 조건과 실험적 Kp 값, 그리고 실험 조건과 모델링된 Kp 값 간의 관계를 각각 보여주는 예시적 히트 맵(heat map)(1100-1150)을 도시한다. 히트 맵(1100-1150)은 단백질이 얼마나 단단 히 결합되었는지(결합 비율 단위)를 나타내는 색상 그라디언트를 포함한다. 맵(1100-1150)의 x축은 염 농도 수 준을 나타내고 y축은 pH 수준을 나타낸다. \"빨간색\"인 히트 맵(1100-1150)의 부분은 보다 높은 log(Kp) 값(예: 분자 결합 특성)을 나타내고 \"녹색\"은 보다 낮은 log(Kp) 값을 나타낸다. 히트 맵(1100-1150)은 하나 이상의 실 증적으로 평가된 단백질에 기초하여 생성될 수 있다. 예를 들어, 도 11a-11b는 이온 교환 수지에 대한 실험적 Kp 스크린과 모델 예측 Kp 스크린을 나타내는 히트 맵(1100-1110)을 나타낼 수 있다. 도 11c-11d는 소수성 수지 에 대한 실험적 Kp 스크린과 모델 예측 Kp 스크린을 묘사하는 히트 맵(1120-1130)을 묘사할 수 있다. 도 11e- 11f는 혼합 모드 수지에 대한 실험적 Kp 스크린과 모델 예측 Kp 스크린을 묘사하는 히트 맵(1140-1150)을 묘사할수 있다. 예를 들어, pH = 5.5의 pH 수준에서 관심 단백질은 사용된 염 농도 수준이 실험 데이터에서 약 250mM 에 도달할 때까지 결합될 수 있다. 반면, 모델링된 데이터는 pH = 5.5의 pH 수준에서 염 농도 수준이 약 175mM 에 도달할 때까지 관심 단백질이 결합될 수 있음을 나타낼 수 있다. 도 12는 다양한 실시예에 따라 표적 단백질을 식별하기 위한 단백질 정제의 또 다른 간소화된 프로세스의 일부 로서 하나 이상의 표적 단백질의 분자 결합 특성의 예측치를 생성하는 방법의 흐름도를 도시한다. 방법 은 공개된 실시예에 따라 가장 유망한 치료용 항체 후보의 조기 식별을 통해 치료용 항체 후보 또는 기타 면역요법 후보의 선택 프로세스를 가속화할 수 있다. 방법은 하나 이상의 처리 장치(예: 도 5 및 도 6과 관련하여 아래에서 논의되는 컴퓨팅 장치 및 인공 지능 아키텍처)를 활용하여 수행될 수 있으며, 여기에는 하드 웨어(예: 범용 프로세서, 그래픽 처리 장치(GPU), 애플리케이션 특정 집적 회로(ASIC), 시스템 온 칩(SoC), 마 이크로컨트롤러, 필드 프로그래밍가능 게이트 어레이(FPGA), 중앙 처리 장치(CPU), 애플리케이션 프로세서(AP), 시각 처리 장치(VPU), 신경 처리 장치(NPU), 신경 결정 프로세서(NDP), 딥 러닝 프로세서(DLP), 텐서 처리 장치 (TPU), 신경형 처리 장치(NPU), 또는 게놈 데이터, 프로테오믹스 데이터, 대사체 데이터, 메타게놈 데이터, 전 사체 데이터 또는 기타 오믹스 데이터를 처리하고 하나 이상의 프로세서를 만드는 데 적합할 수 있는 기타 처리 장치), 펌웨어(예: 마이크로코드) 또는 이들의 일부 조합이 포함될 수 있다. 일부 실시예에서, 방법은 블록에서 시작할 수 있다. 블록은 머신 러닝 파이프라인을 훈 련하기 위해 수행되는 단계의 일부를 형성할 수 있다. 블록에서, 하나 이상의 실증적으로 평가된 단백질 에 상응하는 아미노산 서열의 훈련 세트를 나타내는 훈련 분자 설명자 행렬에 액세스할 수 있다. 예를 들어, 훈 련 분자 행렬은 하나 이상의 실험 조건(예: 염 농도 수준, pH 수준 등)에서 실험적으로 평가된 단백질에 대해 생성될 수 있다. 블록에서, 반복적 프로세스가 실행되어 앙상블 러닝 모델과 연관된 하이퍼 매개변수 세트를 원하는 정밀 도에 도달할 때까지 정제할 수 있다. 예를 들어, 프로세스는 머신 러닝 파이프라인이 임계 수준의 정확도 로 분자 결합 특성을 예측할 때까지 반복될 수 있다. 블록은 블록의 각 반복 동안 수행되는 단계를 포함할 수 있다. 예를 들어, 단계에서, 훈련 분자 설명자 행렬은 복수의 특징 벡터 클러스터 각각에 대해 하나의 대표 특징 벡터를 선택함으로써 감소될 수 있다. 각 특징 벡터 클러스터는 유사한 특징 벡터를 포함할 수 있다. 예를 들어, 임계 거리보다 작은 거리를 갖는 두 개의 특징 벡터(예: 임베딩 공간에서)는 \"유사하다\"고 분류될 수 있다. 선택된 대표 특징 벡터는 주어진 특징 벡터 클러스터 내에 포함된 모든 특징 벡터를 나타낼 수 있다. 단계에서, 각 특징 벡터 클러스터에 대한 선택된 대표 특징 벡터 중 하나 이상의 가장 예측적인 특징 벡 터는 선택된 대표 특징 벡터와 실증적으로 평가된 단백질과 관련된 사전결정된 일괄 결합 데이터 간의 상관관계 에 기초하여 결정될 수 있다. 가장 예측적인 특징 벡터는 제1 주성분을 식별하는 주성분 분석에 기초하여 결정 될 수 있다. 단계, 하나 이상의 교차 검증 손실은 가장 예측적인 특징 벡터 및 사전결정된 일괄 결합 데이터에 적어도 부분적으로 기초하여 계산될 수 있다. 머신 러닝 파이프라인의 하이퍼 매개변수 세트는 교차 검증 손실에 따라 업데이트될 수 있다. 단계에서, 하이퍼 매개변수 세트는 하나 이상의 교차 검증 손실에 따라 업데이 트될 수 있다. 블록(1210-1220)(단계(1222-1228) 포함)은 \"훈련\" 부분을 포함할 수 있다. 블록(1210-1220)의 결과는 추론 중 에 사용될 수 있는 훈련된 머신 러닝 모델(예: 머신 러닝 모델)을 포함할 수 있다. 예를 들어, 블록(123 0)에서, 하나 이상의 단백질에 상응하는 아미노산 서열 세트를 나타내는 분자 설명자 행렬에 액세스할 수 있다. 블록에서, 하나 이상의 단백질의 분자 결합 특성의 예측치는 분자 설명자 행렬에 적어도 부분적으로 기초 하여 훈련된 ML 모델에 의해 얻어질 수 있다. 일부 실시예에서, 단백질은 관심 단백질일 수 있다. 하나 이상의 예에서, 머신 러닝 모델(예: 신경망을 사용하 여 구현된 단백질 언어 모델)은 단백질에 상응하는 아미노산 서열 세트를 나타내는 데이터를 수신하고 아미노산 서열을 설명하는 분자 설명자 행렬을 생성하도록 훈련될 수 있다. 일부 예에서, 분자 설명자 행렬은 복수의 설 명자(예: 특징)를 포함할 수 있다. 설명자는 특징 벡터로 구조화될 수 있다. 일부 실시예에서, 머신 러닝 파이프라인은 분자 설명자 행렬을 분석하고 차원수 감소를 수행하도록 훈련될 수 있다. 차원수 감소는 대표 특징 벡터를 선택하여 분자 설명자 행렬을 감소시킬 수 있다. 선택된 대표 특징 벡터는 분자 설명자 행렬의 유사한 특징 벡터의 클러스터에서 선택될 수 있다. 하나 이상의 예에서, 각 클러스터는 대표 특징 벡터를 가질 수 있다. 대표 특징 벡터의 가장 예측적인 특징 벡터가 결정될 수 있다. 그런 다음 가장 예측적인 특징 벡터를 사용하여 예측된 분자 결합 특성을 생성할 수 있다. 하나 이상의 예에서, 예측된 분 자 결합 특성은 제1 주성분을 나타낼 수 있다. 여기서, \"또는\"은 명시적으로 달리 표시되거나 맥락에 의해 달리 표시되지 않는 한 포괄적이며 배타적이지 않다. 따라서 여기서 \"A 또는 B\"는 명시적으로 달리 표시되거나 맥락에 의해 달리 표시되지 않는 한 \"A, B 또는 둘 다\"를 의미한다. 또한, \"및\"는 문맥상 달리 명시적으로 표시되거나 달리 표시되지 않는 한, 공동 및 개별 모 두이다. 따라서 본 명세서에서 \"A 및 B\"는 문맥상 달리 명시적으로 표시되거나 달리 표시되지 않는 한, \"A 및 B, 공동 또는 개별\"을 의미한다. 본 명세서에서 \"자동으로\" 및 그 파생어는 문맥상 달리 명시적으로 표시되거나 달리 표시되지 않는 한, \"인간의 개입 없이\"를 의미한다. 본 명세서에 공개된 실시예는 단지 예일뿐이며, 본 개시의 범위는 이에 국한되지 않는다. 본 개시에 따른 실시 예는 특히 방법, 저장 매체, 시스템 및 컴퓨터 프로그램 제품에 대한 첨부된 청구항에 공개되어 있으며, 여기서 한 청구항 범주(예: 방법)에 언급된 임의의 특징은 다른 청구항 범주(예: 시스템)에서도 청구될 수 있다. 첨부 된 청구항에서의 종속성 또는 참조는 형식적인 이유로만 선택된다. 그러나 이전의 청구항(특히 다중 종속성)에 대한 의도적인 참조로 인해 발생하는 모든 주제는 청구될 수 있으므로, 청구항과 그 특징의 모든 조합이 공개되 고 첨부된 청구항에서 선택된 종속성과 관계없이 청구될 수 있다. 청구될 수 있는 주제는 첨부된 청구항에 명시 된 특징의 조합뿐만 아니라 청구항 내 특징들의 다른 조합도 포함하며, 청구항에 언급된 각 특징은 청구항 내 다른 특징 또는 다른 특징의 조합과 결합될 수 있다. 더욱이, 여기에 설명 또는 묘사된 모든 실시예 및 특징은 별도의 청구항에서 청구될 수 있으며, 여기에 설명 또는 묘사된 모든 실시예 또는 특징 또는 첨부된 청구항의 특징 중 하나와 임의의 조합으로 청구될 수 있다. 본 개시의 범위는 본 기술 분야의 통상의 기술을 가진 사람이 이해할 수 있는 본 개시의 실시예에 대한 모든 변 화, 대체, 변형, 변경 및 수정을 포함한다. 본 개시의 범위는 여기에 설명 또는 묘사된 예시적인 실시예에 국한 되지 않는다. 또한, 본 개시에서는 여기에 포함된 각각의 실시예를 특정 구성 요소, 요소, 특징, 기능, 작업 또 는 단계로 기술 및 예시하고 있지만, 이러한 실시예는 본 명세서에 기술 또는 예시된 구성 요소, 요소, 특징, 기능, 작업 또는 단계의 임의의 조합 또는 변형을 포함할 수 있으며, 이는 해당 기술 분야의 통상의 기술을 가 진 사람이 이해할 수 있는 것이다. 또한, 첨부된 청구항에서 특정 기능을 수행하도록 적응되거나, 배열되거나, 할 수 있거나, 구성되거나, 할 수 있게 되거나, 작동가능하거나, 작동하도록 장치 또는 시스템 또는 장치 또는 시스템의 구성 요소에 대한 참조는 해당 장치, 시스템, 구성 요소가 활성화되거나, 켜지거나, 잠금 해제되었는 지 여부와 관계없이 해당 장치, 시스템 또는 구성 요소가 그렇게 적응되거나, 배열되거나, 할 수 있거나, 구성 되거나, 할 수 있거나, 작동가능하거나, 작동되는 한 해당 장치, 시스템, 구성 요소를 포함한다. 또한, 본 개시 에서 특정 이점을 제공하는 것으로 특정 실시예를 설명하거나 예시하지만, 특정 실시예는 이러한 이점을 전혀 제공하지 않거나, 일부 또는 전부 제공할 수 있다. 예시 실시예 여기에 공개된 실시예는 다음을 포함할 수 있다: 1. 하나 이상의 컴퓨팅 장치에 의해, 하나 이상의 단백질의 분자 결합 특성을 예측하기 위한 방법으로서, 하나 이상의 단백질에 상응하는 아미노산 서열 세트를 나타내는 분자 설명자 행렬에 액세스하는 단계, 및 상기 하나 이상의 단백질의 분자 결합 특성의 예측치를 생성하도록 훈련된 머신 러닝 모델과 관련된 하이퍼 매 개변수 세트를 정밀화하는 단계이며, 여기서 상기 하이퍼 매개변수 세트를 정밀화하는 것은 원하는 정밀도에 도 달할 때까지 프로세스를 반복적으로 실행하는 것을 포함하고, 상기 프로세스는, 복수의 특징 벡터 클러스터 각각에 대해 하나의 대표 특징 벡터를 선택함으로써 상기 분자 설명자 행렬을 감소 시키고, 여기서 각각의 특징 벡터 클러스터는 유사한 특징 벡터를 포함하고, 상기 하나 이상의 단백질과 관련된 사전결정된 일괄(batch) 결합 데이터 및 상기 선택된 대표 특징 벡터 간의 상관관계에 기초하여 각각의 특징 벡터 클러스터에 대해 상기 선택된 대표 특징 벡터 중 하나 이상의 가장 예측 적인 특징 벡터를 결정하며,상기 하나 이상의 가장 예측적인 특징 벡터 및 상기 사전결정된 일괄 결합 데이터에 적어도 부분적으로 기초하 여 하나 이상의 교차 검증 손실을 계산하고, 상기 하나 이상의 교차 검증 손실에 기초하여 상기 하이퍼 매개변수 세트를 업데이트하는 것 을 포함하는 것인 단계, 및 상기 머신 러닝 모델에 의해, 상기 업데이트된 하이퍼 매개변수 세트에 적어도 부분적으로 기초하여 상기 하나 이상의 단백질의 분자 결합 특성의 예측치를 출력하는 단계 를 포함하는 방법. 2. 제1 실시예에 있어서, 상기 하나 이상의 교차 검증 손실을 계산하는 것은, 상기 하나 이상의 가장 예측적인 특징 벡터, 상기 사전결정된 일괄 결합 데이터, 상기 하이퍼 매개변수 세트, 및 상기 머신 러닝 모델과 관련된 학습가능 매개변수 세트에 기초하여 교차 검증 손실 함수를 평가하고, 상기 하나 이상의 가장 예측적인 특징 벡터, 상기 사전결정된 일괄 결합 데이터, 및 상기 하이퍼 매개변수 세트 는 일정하게 유지시키면서 상기 학습가능 매개변수 세트를 변경함으로써 상기 교차 검증 손실 함수를 최소화하 는 것 을 더 포함하는 것인 방법. 3. 제2 실시예에 있어서, 상기 교차 검증 손실 함수를 최소화하는 것은 상기 하이퍼 매개변수 세트를 최적화하는 것을 포함하고, 상기 하이퍼 매개변수 세트는 일반 매개변수 세트, 부스터 매개변수 세트, 또는 학습 과제 매개변수 세트 중 하 나 이상을 포함하는 것인 방법. 4. 제2 또는 제3 실시예에 있어서, 상기 교차 검증 손실 함수를 최소화하는 것은 상기 하나 이상의 단백질에 대 한 단백질 결합 백분율의 예측치 및 상기 하나 이상의 단백질에 대한 실험적으로 결정된 단백질 결합 백분율 간 의 손실을 최소화하는 것을 포함하는 것인 방법. 5. 제2 내지 제4 실시예 중 어느 하나에 있어서, 상기 사전결정된 일괄 결합 데이터는 상기 하나 이상의 단백질 의 분자 결합 특성과 관련된 하나 이상의 pH 값 및 염 농도에 대해 실험적으로 결정된 단백질 결합 백분율을 포 함하는 것인 방법. 6. 제2 내지 제5 실시예 중 어느 하나에 있어서, 상기 학습가능 매개변수 세트는 상기 하나 이상의 가장 예측적 인 특징 벡터 및 상기 사전결정된 일괄 결합 데이터에 적어도 부분적으로 기초하여 상기 머신 러닝 모델에 의해 결정되는 하나 이상의 가중치 또는 결정 변수를 포함하는 것인 방법. 7. 제1 내지 제6 실시예 중 어느 하나에 있어서, 상기 하이퍼 매개변수 세트를 정밀화한 후: 하나 이상의 제2 단백질에 상응하는 제2 아미노산 서열 세트를 나타내는 제2 분자 설명자 행렬에 액세스하는 단 계, 상기 제2 분자 설명자 행렬의 제2 복수의 특징 벡터 클러스터 각각에 대해 하나의 대표 특징 벡터를 선택함으로 써 상기 제2 분자 설명자 행렬을 감소시키는 단계, 상기 하나 이상의 제2 단백질과 관련된 사전결정된 일괄 결합 데이터 및 상기 선택된 대표 특징 벡터 간의 제2 상관관계에 기초하여 각각의 특징 벡터 클러스터에 대해 상기 선택된 대표 특징 벡터 중 하나 이상의 제2 가장 예측적인 특징 벡터를 결정하는 단계, 상기 하나 이상의 제2 단백질의 분자 결합 특성의 예측치를 생성하도록 훈련된 상기 머신 러닝 모델에 상기 하 나 이상의 제2 가장 예측적인 특징 벡터를 입력하는 단계, 및 상기 머신 러닝 모델에 의해, 상기 업데이트된 하이퍼 매개변수 세트에 적어도 부분적으로 기초하여 상기 하나 이상의 제2 단백질의 분자 결합 특성의 예측치를 출력하는 단계 를 더 포함하는 방법. 8. 제7 실시예에 있어서, 상기 하나 이상의 제2 단백질의 분자 결합 특성의 예측치는 상기 하나 이상의 제2 단 백질에 대한 단백질 결합 백분율의 예측치를 포함하는 것인 방법. 9. 제1 내지 제8 실시예 중 어느 하나에 있어서, 업데이트된 하이퍼 매개변수 세트는 업데이트된 일반 매개변수 세트, 업데이트된 부스터 매개변수 세트, 또는 업데이트된 학습 과제 매개변수 세트 중 하나 이상을 포함하는 것인 방법. 10. 제1 내지 제9 실시예 중 어느 하나에 있어서, 상기 하나 이상의 교차 검증 손실을 계산하는 것은 n개의 교차 검증 손실을 계산하는 것을 포함하고, n은 1 내지 n으로부터의 정수를 포함하는 것인 방법. 11. 제1 내지 제10 실시예 중 어느 하나에 있어서, 상기 하나 이상의 교차 검증 손실을 계산하는 것은 상기 하나 이상의 가장 예측적인 특징 벡터 및 상기 사전결 정된 일괄 결합 데이터에 기초하여 n개의 개별 훈련-테스트 분할을 결정하는 것을 포함하고, n은 1 내지 n으로부터의 정수를 포함하는 것인 방법. 12. 제1 내지 제11 실시예 중 어느 하나에 있어서, 상기 하나 이상의 교차 검증 손실을 계산하는 것은 n개의 교차 검증 손실을 계산하는 것을 포함하고, 상기 방법은 상기 n개의 교차 검증 손실의 평균에 기초하여 상기 하나 이상의 단백질의 분자 결합 특성의 예측 치를 생성하는 단계를 더 포함하는 방법. 13. 제1 내지 제12 실시예 중 어느 하나에 있어서, 상기 분자 설명자 행렬은 2n개의 특징 벡터를 포함하고, n은 상기 분자 설명자 행렬의 차원을 포함하는 것인 방법. 14. 제1 내지 제13 실시예 중 어느 하나에 있어서, 상기 분자 설명자 행렬은 상기 머신 러닝 모델과는 별개의 제1 머신 러닝 모델에 의해 생성되었던 것인 방법. 15. 제14 실시예에 있어서, 상기 제1 머신 러닝 모델은 상기 아미노산 서열 세트에 기초하여 상기 분자 설명자 행렬을 생성하도록 훈련되었던 것인 방법. 16. 제14 또는 제15 실시예에 있어서, 상기 제1 머신 러닝 모델은 상기 아미노산 서열 세트를 나타내는 M x N 설명자 행렬을 생성하도록 훈련된 신경 망을 포함하고, N은 상기 아미노산 서열 세트의 수를 포함하고, M은 상기 신경망의 출력 계층 내 노드의 수를 포함하는 것인 방법. 17. 제1 내지 제16 실시예 중 어느 하나에 있어서, 상기 머신 러닝 모델은 그래디언트 부스팅 모델, 적응형 부 스팅(AdaBoost) 모델, 익스트림 그래디언트 부스팅(XGBoost) 모델, 라이트 그래디언트 부스티드 머신(LightGBM) 모델, 또는 범주형 부스팅(CatBoost) 모델 중 하나 이상을 포함하는 것인 방법. 18. 제1 내지 제17 실시예 중 어느 하나에 있어서, 상기 머신 러닝 모델은 상기 하나 이상의 단백질의 분자 용 출 특성의 예측치를 생성하도록 추가로 훈련되는 것인 방법. 19. 제1 내지 제18 실시예 중 어느 하나에 있어서, 상기 머신 러닝 모델은 상기 하나 이상의 단백질의 유출 (flow-through) 특성의 예측치를 생성하도록 추가로 훈련되는 것인 방법. 20. 제1 내지 제19 실시예 중 어느 하나에 있어서, 상기 분자 설명자 행렬을 감소시키는 것은 상기 분자 설명자 행렬의 특징 벡터의 피어슨 상관관계(Pearson's correlation)를 수행하여 복수의 특징 벡터 클러스터를 생성하 는 것을 포함하는 것인 방법. 21. 제20 실시예에 있어서, 상기 복수의 특징 벡터 클러스터 각각에 대해 선택된 하나의 대표 특징 벡터는 유사 한 특징 벡터 중 2개 이상을 나타내는 데 사용되는 복수의 특징 벡터 클러스터 각각에 대한 중심 특징 벡터를포함하는 것인 방법. 22. 제1 내지 제21 실시예 중 어느 하나에 있어서, 상기 복수의 특징 벡터 클러스터 각각에 대해 선택된 대표 특징 벡터 중 하나 이상의 대표 특징 벡터를 결정하는 것은 상기 복수의 특징 벡터 클러스터 각각에 대해 선택 된 대표 특징 벡터 중 k-베스트(best) 특징 벡터 행렬을 선택하는 것을 포함하는 것인 방법. 23. 제22 실시예에 있어서, 상기 선택된 대표 특징 벡터의 k-베스트 특징 벡터 행렬은 사전결정된 k-베스트 프 로세스에 기초하여 결정되는 것인 방법. 24. 제1 내지 제23 실시예 중 어느 하나에 있어서, 상기 선택된 대표 특징 벡터 및 상기 사전결정된 일괄 결합 데이터 간의 상관관계는 상기 선택된 대표 특징 벡터 및 상기 사전결정된 일괄 결합 데이터 간의 최대 정보 계 수(MIC)에 기초하여 결정되는 것인 방법. 25. 제1 내지 제24 실시예 중 어느 하나에 있어서, 상기 하나 이상의 단백질의 분자 결합 특성의 예측치는 컴퓨 팅 모델(computational model) 기반 크로마토그래피 프로세스를 포함하는 것인 방법. 26. 제25 실시예에 있어서, 상기 컴퓨팅 모델 기반 크로마토그래피 프로세스는 컴퓨팅 모델 기반 친화성 크로마 토그래피 프로세스, 이온 교환 크로마토그래피(IEX) 프로세스, 소수성 상호작용 크로마토그래피(HIC) 프로세스, 또는 혼합 모드 크로마토그래피(MMC) 프로세스 중 하나 이상을 포함하는 것인 방법. 27. 제1 내지 제26 실시예 중 어느 하나에 있어서, 베이지안 모델 최적화 프로세스(Bayesian model-optimization process)에 기초하여 상기 머신 러닝 모델을 최 적화하는 단계 를 더 포함하는 방법. 28. 제27 실시예에 있어서, 그룹 K-폴드 교차 검증을 활용하여 상기 하나 이상의 가장 예측적인 특징 벡터, 상기 사전결정된 일괄 결합 데 이터, 상기 하이퍼 매개변수 세트, 및 상기 학습가능 매개변수 세트에 기초하여 최적화된 머신 러닝 모델을 훈 련 및 평가하는 단계 를 더 포함하는 방법. 29. 제1 내지 제28 실시예 중 어느 하나에 있어서, 상기 하나 이상의 단백질의 분자 결합 특성의 예측치는 상기 하나 이상의 단백질의 표적 단백질의 확인을 포함하는 것인 방법. 30. 제1 내지 제29 실시예 중 어느 하나에 있어서, 상기 하나 이상의 단백질의 분자 결합 특성의 예측치는 상기 하나 이상의 단백질의 정량적 구조 특성 관계(QSPR) 또는 정량적 구조 활성 관계(QSAR) 모델링을 포함하는 것인 방법. 31. 제1 내지 제30 실시예 중 어느 하나에 있어서, 상기 하나 이상의 단백질의 분자 결합 특성의 예측치는 상기 하나 이상의 단백질에 상응하는 아미노산 서열 세트의 각 아미노산 서열에 대한 분자 결합 특성의 예측치를 포 함하는 것인 방법. 32. 하나 이상의 컴퓨팅 장치에 의해, 하나 이상의 단백질의 분자 결합 특성을 예측하기 위한 방법으로서, 하나 이상의 단백질에 상응하는 아미노산 서열 세트를 나타내는 분자 설명자 행렬에 액세스하는 단계, 및 머신 러닝 모델에 의해, 상기 분자 설명자 행렬에 적어도 부분적으로 기초하여 상기 하나 이상의 단백질의 분자 결합 특성의 예측치를 획득하는 단계 를 포함하고, 상기 머신 러닝 모델은, 하나 이상의 실증적으로 평가된 단백질에 상응하는 아미노산 서열의 훈련 세트를 나타내는 훈련 분자 설명자 행 렬에 액세스하고, 요망 정밀도에 도달할 때까지 상기 머신 러닝 모델과 관련된 하이퍼 매개변수 세트를 정밀화하도록 프로세스를 반복적으로 실행하는 것에 의해 훈련되며, 상기 프로세스는, 복수의 특징 벡터 클러스터 각각에 대해 하나의 대표 특징 벡터를 선택함으로써 상기 훈련 분자 설명자 행렬을 감소시키고, 여기서 각각의 특징 벡터 클러스터는 유사한 특징 벡터를 포함하고, 상기 하나 이상의 실증적으로 평가된 단백질과 관련된 사전결정된 일괄 결합 데이터 및 상기 선택된 대표 특징 벡터 간의 상관관계에 기초하여 각각의 특징 벡터 클러스터에 대해 상기 선택된 대표 특징 벡터 중 하나 이상의 가장 예측적인 특징 벡터를 결정하며, 상기 하나 이상의 가장 예측적인 특징 벡터 및 상기 사전결정된 일괄 결합 데이터에 적어도 부분적으로 기초하 여 하나 이상의 교차 검증 손실을 계산하고, 상기 하나 이상의 교차 검증 손실에 기초하여 상기 하이퍼 매개변수 세트를 업데이트하는 것인 방법. 33. 제32 실시예에 있어서, 상기 예측치를 획득하는 단계는, 상기 분자 설명자 행렬의 복수의 특징 벡터 클러스터 각각에 대해 하나의 대표 특징 벡터를 선택함으로써 상기 분자 설명자 행렬을 감소시키고, 상기 하나 이상의 단백질과 관련된 사전결정된 일괄 결합 데이터 및 상기 선택된 특징 벡터 간의 상관관계에 기 초하여 각각의 특징 벡터 클러스터에 대해 상기 선택된 대표 특징 벡터 중 하나 이상의 가장 예측적인 특징 벡 터를 결정하며, 상기 하나 이상의 단백질의 분자 결합 특성의 예측치를 획득하도록 상기 머신 러닝 모델에 상기 하나 이상의 가 장 예측적인 특징 벡터를 입력하는 것 을 포함하는 것인 방법. 34. 제32 또는 제33 실시예에 있어서, 상기 하나 이상의 단백질의 분자 결합 특성의 예측치는 상기 하나 이상의 단백질에 대한 단백질 결합 백분율의 예측치를 포함하는 것인 방법. 35. 제32 내지 제34 실시예 중 어느 하나에 있어서, 상기 하나 이상의 교차 검증 손실을 계산하는 것은, 상기 하나 이상의 가장 예측적인 특징 벡터, 상기 사전결정된 일괄 결합 데이터, 상기 하이퍼 매개변수 세트, 및 상기 머신 러닝 모델과 관련된 학습가능 매개변수 세트에 기초하여 교차 검증 손실 함수를 평가하고, 상기 하나 이상의 가장 예측적인 특징 벡터, 상기 사전결정된 일괄 결합 데이터, 및 상기 하이퍼 매개변수 세트 는 일정하게 유지시키면서 상기 학습가능 매개변수 세트를 변경함으로써 상기 교차 검증 손실 함수를 최소화하 는 것 을 더 포함하는 것인 방법. 36. 제35 실시예에 있어서, 상기 교차 검증 손실 함수를 최소화하는 것은 상기 하이퍼 매개변수 세트를 최적화하는 것을 포함하고, 상기 하이퍼 매개변수 세트는 일반 매개변수 세트, 부스터 매개변수 세트, 또는 학습 과제 매개변수 세트 중 하 나 이상을 포함하는 것인 방법. 37. 제35 또는 제36 실시예에 있어서, 상기 교차 검증 손실 함수를 최소화하는 것은 상기 하나 이상의 단백질에 대한 단백질 결합 백분율의 예측치 및 상기 하나 이상의 단백질에 대한 실험적으로 결정된 단백질 결합 백분율 간의 손실을 최소화하는 것을 포함하는 것인 방법. 38. 제35 내지 제37 실시예 중 어느 하나에 있어서, 상기 사전결정된 일괄 결합 데이터는 상기 하나 이상의 단 백질의 분자 결합 특성과 관련된 하나 이상의 pH 값 및 염 농도에 대해 실험적으로 결정된 단백질 결합 백분율 을 포함하는 것인 방법. 39. 제35 내지 제38 실시예 중 어느 하나에 있어서, 상기 학습가능 매개변수 세트는 상기 하나 이상의 가장 예 측적인 특징 벡터 및 상기 사전결정된 일괄 결합 데이터에 적어도 부분적으로 기초하여 상기 머신 러닝 모델에 의해 결정되는 하나 이상의 가중치 또는 결정 변수를 포함하는 것인 방법.40. 제32 내지 제39 실시예 중 어느 하나에 있어서 상기 분자 설명자 행렬은 하나 이상의 제1 단백질에 상응하는 제1 아미노산 서열 세트를 나타내는 제1 분자 설 명자 행렬을 포함하고, 상기 분자 결합 특성의 예측치는 상기 하나 이상의 제1 단백질의 분자 결합 특성의 제1 예측치를 포함하며, 상기 방법은, 하나 이상의 제2 단백질에 상응하는 제2 아미노산 서열 세트를 나타내는 제2 분자 설명자 행렬에 액세스하는 단 계, 및 상기 머신 러닝 모델에 의해, 상기 제2 분자 설명자 행렬에 적어도 부분적으로 기초하여 상기 하나 이상의 제2 단백질의 분자 결합 특성의 제2 예측치를 획득하는 단계 를 더 포함하는 방법. 41. 제40 실시예에 있어서, 상기 머신 러닝 모델은, 상기 제2 분자 설명자 행렬의 제2 복수의 특징 벡터 클러스터 각각에 대해 하나의 대표 특징 벡터를 선택함으로 써 상기 제2 분자 설명자 행렬을 감소시키고, 상기 하나 이상의 제2 단백질과 관련된 사전결정된 일괄 결합 데이터 및 상기 선택된 대표 특징 벡터 간의 제2 상관관계에 기초하여 각각의 특징 벡터 클러스터에 대해 상기 선택된 대표 특징 벡터 중 하나 이상의 제2 가장 예측적인 특징 벡터를 결정하며, 상기 제2 예측치를 생성하도록 훈련된 상기 머신 러닝 모델에 상기 하나 이상의 제2 가장 예측적인 특징 벡터를 입력하도록 훈련되는 것인 방법. 42. 제40 또는 41 실시예에 있어서, 상기 하나 이상의 제2 단백질의 분자 결합 특성의 제2 예측치는 상기 하나 이상의 제2 단백질에 대한 단백질 결합 백분율의 예측치를 포함하는 것인 방법. 43. 제32 내지 제42 실시예 중 어느 하나에 있어서, 업데이트된 하이퍼 매개변수 세트는 업데이트된 일반 매개 변수 세트, 업데이트된 부스터 매개변수 세트, 또는 업데이트된 학습 과제 매개변수 세트 중 하나 이상을 포함 하는 것인 방법. 44. 제32 내지 제43 실시예 중 어느 하나에 있어서, 상기 하나 이상의 단백질의 분자 결합 특성의 예측치를 생 성하는데 사용되는 머신 러닝 모델은 업데이트된 하이퍼 매개변수 세트를 포함하는 것인 방법. 45. 제32 내지 제44 실시예 중 어느 하나에 있어서, 상기 하나 이상의 교차 검증 손실을 계산하는 것은 n개의 교차 검증 손실을 계산하는 것을 포함하고, n은 1 내지 n으로부터의 정수를 포함하는 것인 방법. 46. 제32 내지 제45 실시예 중 어느 하나에 있어서, 상기 하나 이상의 교차 검증 손실을 계산하는 것은 상기 하나 이상의 가장 예측적인 특징 벡터 및 상기 사전결 정된 일괄 결합 데이터에 기초하여 n개의 개별 훈련-테스트 분할을 결정하는 것을 포함하고, n은 1 내지 n으로부터의 정수를 포함하는 것인 방법. 47. 제32 내지 제46 실시예 중 어느 하나에 있어서, 상기 하나 이상의 교차 검증 손실을 계산하는 것은 n개의 교차 검증 손실을 계산하는 것을 포함하고, 상기 방법은 상기 n개의 교차 검증 손실의 평균에 기초하여 상기 하나 이상의 단백질의 분자 결합 특성의 예측 치를 생성하는 단계를 더 포함하는 방법. 48. 제32 내지 제48 실시예 중 어느 하나에 있어서, 상기 분자 설명자 행렬은 상기 머신 러닝 모델과는 별개의 제1 머신 러닝 모델에 의해 생성되었던 것인 방법. 49. 제48 실시예에 있어서, 상기 제1 머신 러닝 모델은 상기 아미노산 서열 세트에 기초하여 상기 분자 설명자 행렬을 생성하도록 훈련되었던 것인 방법. 50. 제49 실시예에 있어서, 상기 제1 머신 러닝 모델은 상기 아미노산 서열 세트를 나타내는 M x N 설명자 행렬 을 생성하도록 훈련된 신경망을 포함하는 것인 방법. 51. 제49 또는 제50 실시예에 있어서, N은 상기 아미노산 서열 세트의 수를 포함하고, M은 상기 신경망의 출력 계층 내 노드의 수를 포함하는 것인 방법. 52. 제32 내지 제51 실시예 중 어느 하나에 있어서, 상기 머신 러닝 모델은 그래디언트 부스팅 모델, 적응형 부 스팅(AdaBoost) 모델, 익스트림 그래디언트 부스팅(XGBoost) 모델, 라이트 그래디언트 부스티드 머신(LightGBM) 모델, 또는 범주형 부스팅(CatBoost) 모델 중 하나 이상을 포함하는 것인 방법. 53. 제32 내지 제52 실시예 중 어느 하나에 있어서, 상기 머신 러닝 모델은 상기 하나 이상의 단백질의 분자 용 출 특성의 예측치를 생성하도록 추가로 훈련되는 것인 방법. 54. 제32 내지 제53 실시예 중 어느 하나에 있어서, 상기 머신 러닝 모델은 상기 하나 이상의 단백질의 유출 특 성의 예측치를 생성하도록 추가로 훈련되는 것인 방법. 55. 제32 내지 제54 실시예 중 어느 하나에 있어서, 상기 분자 설명자 행렬을 감소시키는 것은 상관관계 거리에 기초하여 유사한 특징 벡터를 복수의 특징 벡터 클러스터로 클러스터링하는 것을 포함하는 것인 방법. 56. 제55 실시예에 있어서, 상기 상관관계 거리는 피어슨 상관관계를 사용하여 계산되는 것인 방법. 57. 제55 또는 제56 실시예에 있어서, 상기 복수의 특징 벡터 클러스터 각각에 대해 선택된 하나의 대표 특징 벡터는 유사한 특징 벡터 중 2개 이상을 나타내는 데 사용되는 복수의 특징 벡터 클러스터 각각에 대한 중심 특 징 벡터를 포함하는 것인 방법. 58. 제32 내지 제57 실시예 중 어느 하나에 있어서, 상기 복수의 특징 벡터 클러스터 각각에 대해 선택된 대표 특징 벡터 중 하나 이상의 예측적인 특징 벡터를 결정하는 것은 상기 복수의 특징 벡터 클러스터 각각에 대해 선택된 대표 특징 벡터 중 k-베스트 특징 벡터 행렬을 선택하는 것을 포함하는 것인 방법. 59. 제58 실시예에 있어서, 상기 선택된 대표 특징 벡터의 k-베스트 특징 벡터 행렬은 사전결정된 k-베스트 프 로세스에 기초하여 결정되는 것인 방법. 60. 제32 내지 제59 실시예 중 어느 하나에 있어서, 상기 선택된 대표 특징 벡터 및 상기 사전결정된 일괄 결합 데이터 간의 상관관계는 상기 선택된 대표 특징 벡터 및 상기 사전결정된 일괄 결합 데이터 간의 최대 정보 계 수(MIC)에 기초하여 결정되는 것인 방법. 61. 제32 내지 제60 실시예 중 어느 하나에 있어서, 상기 하나 이상의 단백질의 분자 결합 특성의 예측치는 컴 퓨팅 모델 기반 크로마토그래피 프로세스를 포함하는 것인 방법. 62. 제61 실시예에 있어서, 상기 컴퓨팅 모델 기반 크로마토그래피 프로세스는 컴퓨팅 모델 기반 친화성 크로마 토그래피 프로세스, 이온 교환 크로마토그래피(IEX) 프로세스, 소수성 상호작용 크로마토그래피(HIC) 프로세스, 또는 혼합 모드 크로마토그래피(MMC) 프로세스 중 하나 이상을 포함하는 것인 방법. 63. 제32 내지 제62 실시예 중 어느 하나에 있어서 베이지안 모델 최적화 프로세스에 기초하여 상기 머신 러닝 모델을 최적화하는 단계 를 더 포함하는 방법. 64. 제63 실시예에 있어서 그룹 K-폴드 교차 검증을 활용하여 상기 하나 이상의 가장 예측적인 특징 벡터, 상기 사전결정된 일괄 결합 데 이터, 상기 하이퍼 매개변수 세트, 및 상기 학습가능 매개변수 세트에 기초하여 최적화된 머신 러닝 모델을 훈 련 및 평가하는 단계 를 더 포함하는 방법. 65. 제63 또는 제64 실시예에 있어서 계층적 K-폴드 교차 검증을 활용하여 상기 하나 이상의 가장 예측적인 특징 벡터, 상기 사전결정된 일괄 결합 데이터, 상기 하이퍼 매개변수 세트, 및 상기 학습가능 매개변수 세트에 기초하여 최적화된 머신 러닝 모델을 훈련 및 평가하는 단계 를 더 포함하는 방법. 66. 제32 내지 제65 실시예 중 어느 하나에 있어서, 상기 하나 이상의 단백질의 분자 결합 특성의 예측치는 상 기 하나 이상의 단백질의 표적 단백질의 확인을 포함하는 것인 방법. 67. 제32 내지 제66 실시예 중 어느 하나에 있어서, 상기 하나 이상의 단백질의 분자 결합 특성의 예측치는 상 기 하나 이상의 단백질의 정량적 구조 특성 관계(QSPR) 또는 정량적 구조 활성 관계(QSAR) 모델링을 포함하는 것인 방법. 68. 제32 내지 제67 실시예 중 어느 하나에 있어서, 상기 하나 이상의 단백질의 분자 결합 특성의 예측치는 상 기 하나 이상의 단백질에 상응하는 아미노산 서열 세트의 각 아미노산 서열에 대한 분자 결합 특성의 예측치를 포함하는 것인 방법. 69. 제32 내지 제68 실시예 중 어느 하나에 있어서, 상기 하나 이상의 실증적으로 평가된 단백질 각각에 대해, 상응하는 사전결정된 일괄 결합이 실험 조건 세트 각각에 대해 측정되는 것인 방법. 70. 제69 실시예에 있어서, 상기 실험 조건 세트는 24개의 실험 조건을 포함하는 것인 방법. 71. 제70 실시예에 있어서, 상기 실험 조건 세트는 염 농도의 제1 서브세트 및 pH 값의 제2 서브세트 를 포함하는 것인 방법. 72. 제70 또는 제71 실시예에 있어서, 상기 실험 조건 세트는 상기 분자 설명자 행렬을 사용하여 상기 머신 러닝 모델에 입력되고, 상기 하나 이상의 단백질의 분자 결합 특성의 예측치는 상기 실험 조건 세트 각각에 대한 하나 이상의 단백질의 분자 결합 특성의 예측치를 포함하는 것인 방법. 73. 제32 내지 제72 실시예 중 어느 하나에 있어서, 상기 하나 이상의 단백질의 분자 결합 특성의 예측치를 선형 표현으로 변환하는 단계 를 더 포함하는 방법. 74. 제73 실시예에 있어서, 상기 선형 표현을 생성하기 위해 로짓 변환(logit transformation)이 사용되는 것인 방법. 75. 제73 또는 제74 실시예에 있어서, 상기 선형 표현에 주성분 분석(PCA)을 수행하여 적어도 제1 주성분을 획득하는 단계 를 더 포함하는 방법. 76. 제32 내지 제75 실시예 중 어느 하나에 있어서, 상기 하나 이상의 실증적으로 평가된 단백질과 관련된 사전 결정된 일괄 결합 데이터는, 상기 하나 이상의 실증적으로 평가된 단백질 각각에 대해, 실험 조건 세트 각각에 대해 측정된 실험적으로 결정된 결합 값을 포함하는 것인 방법. 77. 제76 실시예에 있어서, 상기 선택된 대표 특징 벡터 및 상기 사전결정된 일괄 결합 데이터 간의 상관관계는, 상기 하나 이상의 실증적으로 평가된 단백질 각각 및 상기 실험 조건 세트 각각에 대해, 상기 실증적으로 평가된 단백질의 실험적으로 결정된 결합 값에 적용된 로짓 변환에 기초하여 상기 실증적으로 평가된 단백질의 실험적으로 결정된 결합 값의 선형 표현을 생성하고, 상기 하나 이상의 실증적으로 평가된 단백질의 실험적으로 결정된 결합 값의 선형 표현에 주성분 분석(PCA)을 수행하여 적어도 제1 주성분을 획득하는 것 을 포함하는 것인 방법. 78. 제77 실시예에 있어서, 상기 머신 러닝 모델을 사용하여, 상기 하나 이상의 실증적으로 평가된 단백질의 분자 결합 특성의 훈련 예측치 를 생성하는 단계, 및 상기 훈련 예측치 및 상기 제1 주성분을 비교하여 상기 하나 이상의 교차 검증 손실을 계산하는 단계 를 더 포함하는 방법. 79. 제77 또는 제78 실시예에 있어서, 상기 제1 주성분은 평균 일괄 결합 값을 기술하는 것인 방법. 80. 제32 내지 제79 실시예 중 어느 하나에 있어서, 상기 예측치에 기초하여, 실험 조건 세트에 대한 상기 하나 이상의 단백질의 거동을 나타내는 함수 세트를 생성 하는 단계, 및 상기 실험 조건 세트에 대한 상기 하나 이상의 단백질의 거동에 기초하여, 하나 이상의 약물 발견 검정을 위해 상기 하나 이상의 단백질 중 적어도 하나를 선택하는 단계 를 더 포함하는 방법. 81. 제32 내지 제80 실시예 중 어느 하나에 있어서, 상기 하나 이상의 실증적으로 평가된 단백질과 관련된 상기 사전결정된 일괄 결합 데이터 및 상기 선택된 대표 특징 벡터 간의 상관관계는, 상기 사전결정된 일괄 결합 데 이터에 기초하여 계산된 주성분 및 상기 대표 특징 벡터 간의 상관관계를 포함하는 것인 방법. 82. 제81 실시예에 있어서, 예측된 분자 결합 특성 및 실증적 분자 결합 특성에 기초하여 상기 하나 이상의 교 차 검증 손실이 계산되는 것인 방법. 83. 제82 실시예에 있어서, 상기 예측된 분자 결합 특성은 상기 대표 특징 벡터에 기초하여 계산된 주성분을 포함하고, 상기 실증적 분자 결합 특성은 상기 사전결정된 일괄 결합 데이터에 기초하여 계산된 주성분을 포함하는 것인 방법. 84. 제32 내지 제33 실시예 중 어느 하나에 있어서, 상기 하나 이상의 가장 예측적인 특징 벡터를 결정하는 것 은 (i) 상기 대표 특징 벡터에 모델을 맞추고(fitting), (ii) 상기 모델에 기초하여, 상기 대표 특징 벡터 각각에 대한 특징 중요도 점수를 계산하며, (iii) 상기 대표 특징 벡터 각각의 특징 중요도 점수에 기초하여 상기 대표 특징 벡터 중 하나 이상의 특징 벡 터를 제거하여 대표 특징 벡터의 서브세트를 획득하는 것 을 더 포함하며, 여기서 상기 하나 이상의 가장 예측적인 특징 벡터는 상기 대표 특징 벡터의 서브세트로부터의 하나 이상의 특 징 벡터를 포함하는 것인 방법. 85. 제84 실시예에 있어서, 상기 서브세트에 포함된 특징 벡터의 수가 특징 수량 기준을 충족할 때까지 단계 (i)-(iii)를 반복적으로 수행 하는 단계 를 더 포함하는 방법. 86. 제85 실시예에 있어서, 상기 특징 수량 기준이 충족되는 것은 상기 대표 특징 벡터의 서브세트에 포함된 특 징 벡터의 수가 특징 벡터의 임계 수보다 작거나 같은 것을 포함하는 것인 방법. 87 제86 실시예에 있어서, 상기 특징 벡터의 임계 수는 상기 머신 러닝 모델 훈련에 사용된 훈련 데이터로부터 의 동일하거나 유사한 수의 특징을 포함하는 것인 방법.88. 제84 내지 제87 실시예 중 어느 하나에 있어서, 상기 대표 특징 벡터의 서브세트에 포함된 특징 벡터의 수 는 하이퍼 매개변수 세트 중 하나를 포함하는 것인 방법. 89. 제32 내지 제88 실시예 중 어느 하나에 있어서, 상기 하이퍼 매개변수 세트 중 하나는 상기 복수의 특징 벡 터 클러스터에 포함된 특징 벡터 클러스터의 수를 나타내는 것인 방법. 90. 하나 이상의 컴퓨팅 장치를 포함하는 시스템으로서, 명령어를 포함하는 하나 이상의 비일시적 컴퓨터 판독가능 저장 매체, 및 상기 하나 이상의 저장 매체에 결합되어, 제1 내지 제89 실시예의 방법을 수행하기 위한 명령어를 실행하도록 구성된 하나 이상의 프로세서 를 더 포함하는, 시스템. 91. 하나 이상의 컴퓨팅 장치의 하나 이상의 프로세서에 의해 실행될 때 상기 하나 이상의 프로세서로 하여금 제1 내지 제89 실시예 중 어느 하나의 방법을 포함하는 동작을 수행하게 하는 명령어를 포함하는 비일시적 컴퓨 터 판독가능 매체."}
{"patent_id": "10-2025-7005193", "section": "도면", "subsection": "도면설명", "item": 1, "content": "본 특허 또는 출원 파일에는 컬러로 실행된 도면이 하나 이상 포함되어 있다. 컬러 도면이 있는 이 특허 또는 특허 출원 공개물의 사본은 요청 및 필요한 수수료 지불 시 특허청에서 제공될 것이다. 도 1은 다양한 실시예에 따라 하나 이상의 단백질 정제 프로세스를 수행하기 위한 컴퓨팅 모델 기반 예와 비교하여 하나 이상의 단백질 정제 프로세스를 수행하기 위한 실험적 예를 설명하는 다이어그램을 보여준다. 도 2는 다양한 실시예에 따라 특징 생성, 특징 차원 축소, 회귀 모델 최적화 및 모델 출력 기반 특징 선택을 수 행하기 위한 고수준 워크플로 다이어그램을 보여준다. 도 3a는 다양한 실시예에 따라 하나 이상의 컴퓨팅 모델 기반 단백질 정제 프로세스를 수행하기 위한 머신 러닝 모델의 하이퍼 매개변수 및 학습가능 매개변수를 최적화하기 위한 워크플로 다이어그램을 보여준다. 도 3b는 다양한 실시예에 따라 하나 이상의 컴퓨팅 모델 기반 단백질 정제 프로세스를 수행하기 위한 머신 러닝 모델을 최적화하기 위한 워크플로 다이어그램을 보여준다. 도 4는 다양한 실시예에 따라 표적 단백질을 식별하기 위한 단백질 정제의 간소화된 프로세스의 일부로서 하나 이상의 표적 단백질의 분자 결합 특성의 예측치를 생성하는 방법의 흐름도를 도시한다. 도 5는 다양한 실시예에 따라 예시 컴퓨팅 시스템을 도시한다. 도 6은 다양한 실시예에 따라 도 5의 예시 컴퓨팅 시스템의 일부로 포함된 예시 인공지능(AI) 아키텍처의 다이 어그램을 도시한다. 도 7은 다양한 실시예에 따라 특징 생성, 특징 차원수 감소, 회귀 모델 최적화 및 모델 출력 기반 특징 선택을 수행하기 위한 또 다른 고수준 워크플로 다이어그램을 도시한다. 도 8은 다양한 실시예에 따라 하나 이상의 컴퓨팅 모델 기반 단백질 정제 프로세스를 수행하기 위한 머신 러닝 모델의 하이퍼 매개변수 및 학습가능 매개변수를 최적화하기 위한 또 다른 워크플로 다이어그램을 도시한다. 도 9는 다양한 실시예에 따라 분자 결합 특성을 예측하기 위해 머신 러닝 모델을 학습하기 위한 프로세스를 도 시한다. 도 10a-10d는 다양한 실시예에 따라 주성분 분석을 사용하여 분자 결합 특성을 예측하는 방법을 설명하는 예시 플롯을 도시한다. 도 11a-11f는 다양한 실시예에 따라 실험 조건과 실험 Kp 값, 그리고 실험 조건과 모델링된 Kp 값 간의 관계를 설명하는 예시 히트 맵을 도시한다. 도 12는 다양한 실시예에 따라 표적 단백질을 식별하기 위한 또 다른 간소화된 단백질 정제 프로세스의 일부로 서 하나 이상의 표적 단백질의 분자 결합 특성의 예측치를 생성하는 방법의 흐름도를 도시한다."}
