{"patent_id": "10-2023-0044355", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0109156", "출원번호": "10-2023-0044355", "발명의 명칭": "이미지를 처리하는 전자 장치 및 그 동작 방법", "출원인": "삼성전자주식회사", "발명자": "최이삭"}}
{"patent_id": "10-2023-0044355", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "전자 장치(3000)가 이미지를 처리하는 방법에 있어서,카메라를 이용하여 객체의 이미지를 획득하는 단계(S310);상기 객체의 표면의 관심 영역을 검출하는 단계(S320);상기 객체의 외곽선을 나타내는, 객체 키 포인트들을 검출하는 단계(S330);상기 객체 키 포인트들에 기초하여, 상기 객체의 3차원 모양을 나타내는 3차원 파라미터의 값들을 추론하되, 상기 3차원 파라미터는, 상기 객체의 3차원의 기하학적 정보를 나타내는 피처들을 포함하는 것인, 단계(S340);상기 3차원 파라미터에 기초하여 상기 이미지에 대해 원근 변환을 수행함으로써, 상기 관심 영역이 평면으로 수정된 왜곡 제거 이미지를 획득하는 단계(S350); 및상기 왜곡 제거 이미지로부터 상기 관심 영역 내 정보를 추출하는 단계(S360)를 포함하는, 방법."}
{"patent_id": "10-2023-0044355", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 3차원 파라미터의 피처들은,상기 객체의 3차원 회전, 이동, 치수, 스케일링, 카메라 파라미터 중 적어도 하나에 대응하는 것인, 방법."}
{"patent_id": "10-2023-0044355", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 객체의 3차원 모양을 나타내는 3차원 파라미터의 값들을 추론하는 단계는,기 설정된 값을 갖는 초기 3차원 파라미터를 획득하는 단계;상기 초기 3차원 파라미터에 기초하여, 가상 객체의 3차원 모양을 렌더링하는 단계;상기 가상 객체의 외곽선을 나타내는 초기 키 포인트들을 생성하는 단계; 및상기 초기 키 포인트들이 상기 객체 키 포인트들에 정합하도록 상기 초기 3차원 파라미터의 값들을 조정함으로써, 상기 객체의 원본 3차원 모양을 나타내는 3차원 파라미터의 값들을 획득하는 단계를 포함하는, 방법."}
{"patent_id": "10-2023-0044355", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,상기 방법은,상기 관심 영역의 모양을 식별하는 단계; 및상기 관심 영역의 모양이 정형화된 디자인에 포함되는지 여부를 식별하는 단계를 더 포함하고,상기 객체 키 포인트들을 검출하는 단계는,공개특허 10-2024-0109156-3-상기 관심 영역의 모양이 비정형화된 디자인인 것에 기초하여 상기 객체 키 포인트들을 검출하는 것인, 방법."}
{"patent_id": "10-2023-0044355", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서,상기 방법은,상기 관심 영역의 모양이 정형화된 디자인에 포함되는 것에 기초하여, 상기 관심 영역의 외곽선을 나타내는, 관심 영역 키 포인트들을 획득하는 단계를 더 포함하고,상기 객체의 3차원 모양을 나타내는 3차원 파라미터의 값들을 추론하는 단계는,상기 관심 영역 키 포인트들에 기초하여, 상기 3차원 파라미터의 값들을 추론하는 단계를 포함하는, 방법."}
{"patent_id": "10-2023-0044355", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서,상기 객체의 표면의 관심 영역을 검출하는 단계는, 라벨 검출 모델을 이용하는 것이고,상기 라벨 검출 모델은, 상기 이미지를 입력 받아 상기 객체의 상기 라벨을 나타내는 데이터를 출력하도록 훈련된 인공지능 모델인 것인, 방법."}
{"patent_id": "10-2023-0044355", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6항에 있어서,상기 객체 키 포인트들을 검출하는 단계는, 객체 검출 모델을 이용하는 것이고,상기 객체 검출 모델은, 상기 이미지를 입력 받아 상기 객체의 외곽선을 나타내는 키 포인트들을 출력하도록 훈련된 인공지능 모델인 것인, 방법."}
{"patent_id": "10-2023-0044355", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1항에 있어서,상기 방법은,상기 객체의 3차원 모양 타입을 식별하는 단계를 더 포함하고,상기 객체의 3차원 모양을 나타내는 3차원 파라미터의 값들을 추론하는 단계는, 상기 객체의 3차원 모양 타입에기초하여 상기 3차원 파라미터의 값들을 추론하는 것인, 방법."}
{"patent_id": "10-2023-0044355", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서,상기 객체의 3차원 모양을 나타내는 3차원 파라미터의 값들을 추론하는 단계는,복수의 3차원 모양 타입들 중에서, 상기 식별된 3차원 모양 타입에 대응하는 피처들이 포함되는 3차원 파라미터를 선택하는 단계를 포함하고,상기 기 설정된 값을 갖는 초기 3차원 파라미터는, 상기 식별된 3차원 모양 타입에 대응하는 피처들의 기 설정된 값들이 획득되는 것인, 방법.공개특허 10-2024-0109156-4-청구항 10 제1항에 있어서,상기 관심 영역 내 정보를 추출하는 단계는,상기 왜곡 제거 이미지에 광학 문자 인식(Optical character recognition; OCR)을 적용하는 단계를 포함하는,방법."}
{"patent_id": "10-2023-0044355", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "이미지를 처리하는 전자 장치(3000)에 있어서,하나 이상의 카메라들(3200);하나 이상의 인스트럭션을 저장하는 메모리(3300); 및상기 메모리(3300)에 저장된 상기 하나 이상의 인스트럭션을 실행하는 적어도 하나의 프로세서(3400)를 포함하고,상기 적어도 하나의 프로세서(3400)는, 상기 하나 이상의 인스트럭션을 실행함으로써,상기 하나 이상의 카메라들을 통해 객체의 이미지를 획득하고,상기 객체의 표면의 관심 영역을 검출하고,상기 객체의 외곽선을 나타내는, 객체 키 포인트들을 검출하고,상기 객체 키 포인트들에 기초하여, 상기 객체의 3차원 모양을 나타내는 3차원 파라미터의 값들을 추론하되, 상기 3차원 파라미터는, 상기 객체의 3차원의 기하학적 정보를 나타내는 피처들을 포함하는 것이고,상기 3차원 파라미터에 기초하여 상기 이미지에 대해 원근 변환을 수행함으로써, 상기 관심 영역이 평면으로 수정된 왜곡 제거 이미지를 획득하고,상기 왜곡 제거 이미지로부터 상기 관심 영역 내 정보를 추출하는, 전자 장치."}
{"patent_id": "10-2023-0044355", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항에 있어서,상기 3차원 파라미터의 피처들은,상기 객체의 3차원 회전, 이동, 치수, 스케일링, 카메라 파라미터 중 적어도 하나에 대응하는 것인, 전자 장치."}
{"patent_id": "10-2023-0044355", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제11항에 있어서,상기 적어도 하나의 프로세서는, 상기 하나 이상의 인스트럭션을 실행함으로써,기 설정된 값을 갖는 초기 3차원 파라미터를 획득하고,상기 초기 3차원 파라미터에 기초하여, 가상 객체의 3차원 모양을 렌더링하고,상기 가상 객체의 외곽선을 나타내는 초기 키 포인트들을 생성하고,상기 초기 키 포인트들이 상기 객체 키 포인트들에 정합하도록 상기 초기 3차원 파라미터의 값들을 조정함으로써, 상기 객체의 원본 3차원 모양을 나타내는 3차원 파라미터의 값들을 획득하는, 전자 장치.공개특허 10-2024-0109156-5-청구항 14 제11항에 있어서,상기 적어도 하나의 프로세서는, 상기 하나 이상의 인스트럭션을 실행함으로써,상기 관심 영역의 모양을 식별하고,상기 관심 영역의 모양이 정형화된 디자인에 포함되는지 여부를 식별하고,상기 관심 영역의 모양이 비정형화된 디자인인 것에 기초하여 상기 객체 키 포인트들을 검출하는, 전자 장치."}
{"patent_id": "10-2023-0044355", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제14항에 있어서,상기 적어도 하나의 프로세서는, 상기 하나 이상의 인스트럭션을 실행함으로써,상기 관심 영역의 모양이 정형화된 디자인에 포함되는 것에 기초하여, 상기 관심 영역의 외곽선을 나타내는, 관심 영역 키 포인트들을 획득하고,상기 관심 영역 키 포인트들에 기초하여, 상기 3차원 파라미터의 값들을 추론하는, 전자 장치."}
{"patent_id": "10-2023-0044355", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제11항에 있어서,상기 객체의 표면의 관심 영역을 검출하는 것은, 라벨 검출 모델을 이용하는 것이고,상기 라벨 검출 모델은, 상기 이미지를 입력 받아 상기 객체의 상기 라벨을 나타내는 데이터를 출력하도록 훈련된 인공지능 모델인 것인, 전자 장치."}
{"patent_id": "10-2023-0044355", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제16항에 있어서,상기 객체 키 포인트들을 검출하는 것은, 객체 검출 모델을 이용하는 것이고,상기 객체 검출 모델은, 상기 이미지를 입력 받아 상기 객체의 외곽선을 나타내는 키 포인트들을 출력하도록 훈련된 인공지능 모델인 것인, 전자 장치."}
{"patent_id": "10-2023-0044355", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제11항에 있어서,상기 적어도 하나의 프로세서는, 상기 하나 이상의 인스트럭션을 실행함으로써,상기 객체의 3차원 모양 타입을 식별하고,상기 객체의 3차원 모양 타입에 기초하여 상기 3차원 파라미터의 값들을 추론하는, 전자 장치."}
{"patent_id": "10-2023-0044355", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제18항에 있어서,공개특허 10-2024-0109156-6-상기 적어도 하나의 프로세서는, 상기 하나 이상의 인스트럭션을 실행함으로써,복수의 3차원 모양 타입들 중에서, 상기 식별된 3차원 모양 타입에 대응하는 피처들이 포함되는 3차원 파라미터를 선택하고,상기 기 설정된 값을 갖는 초기 3차원 파라미터는, 상기 식별된 3차원 모양 타입에 대응하는 피처들의 기 설정된 값들이 획득되는 것인, 전자 장치."}
{"patent_id": "10-2023-0044355", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제1항 내지 제10항 중 어느 한 항의 방법을 컴퓨터에서 실행시키기 위한 프로그램을 기록한 컴퓨터로 읽을 수있는 기록매체."}
{"patent_id": "10-2023-0044355", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "전자 장치가 이미지를 처리하는 방법이 제공된다. 상기 방법은, 카메라를 이용하여 객체의 이미지를 획득하는 단 계; 상기 객체의 표면의 관심 영역을 검출하는 단계; 상기 객체의 외곽선을 나타내는, 객체 키 포인트들을 검출 하는 단계; 상기 객체 키 포인트들에 기초하여, 상기 객체의 3차원 모양을 나타내는 3차원 파라미터의 값들을 추 론하되, 상기 3차원 파라미터는, 상기 객체의 3차원의 기하학적 정보를 나타내는 피처들을 포함하는 것인, 단계; 상기 3차원 파라미터에 기초하여 상기 이미지에 대해 원근 변환을 수행함으로써, 상기 관심 영역이 평면으로 수 정된 왜곡 제거 이미지를 획득하는 단계; 및 상기 왜곡 제거 이미지로부터 상기 관심 영역 내 정보를 추출하는 단계를 포함한다."}
{"patent_id": "10-2023-0044355", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "이미지 내 관심 영역의 왜곡을 제거하는 알고리즘을 적용하는, 전자 장치 및 그 동작 방법이 제공된다."}
{"patent_id": "10-2023-0044355", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "3차원 공간을 촬영한 디지털 이미지에서는, 3차원 객체의 곡면 등으로 인한 물리적인 왜곡, 촬영 관점 (perspective)으로 인한 왜곡 등이 존재한다. 이러한 3차원 특성으로 인한 왜곡을 제거하기 위해 3차원 정보를 활용하는 다양한 기술/기법이 개발되고 있다. 3차원 정보를 활용한 이미지 왜곡 제거 방법에 있어서, 3차원 정 보 획득을 위한 센서 등의 하드웨어 없이, 알고리즘을 이용하여 객체의 3차원 정보를 추론하고, 이미지 내 왜곡 을 제거하기 위한 알고리즘들이 최근 사용되고 있다."}
{"patent_id": "10-2023-0044355", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 개시의 일 측면에 따르면, 전자 장치가 이미지를 처리하는 방법이 제공될 수 있다. 상기 방법은, 카메라를 이용하여 객체의 이미지를 획득하는 단계를 포함할 수 있다. 상기 방법은, 상기 객체의 표면의 관심 영역을 검 출하는 단계를 포함할 수 있다. 상기 방법은, 상기 객체의 외곽선을 나타내는, 객체 키 포인트들을 검출하는 단 계 를 포함할 수 있다. 상기 방법은, 상기 객체 키 포인트들에 기초하여, 상기 객체의 3차원 모양을 나타내는 3 차원 파라미터의 값들을 추론하되, 상기 3차원 파라미터는, 상기 객체의 3차원의 기하학적 정보를 나타내는 피 처들을 포함하는 것인, 단계를 포함할 수 있다. 상기 방법은, 상기 3차원 파라미터에 기초하여 상기 이미지에 대해 원근 변환을 수행함으로써, 상기 관심 영역이 평면으로 수정된 왜곡 제거 이미지를 획득하는 단계를 포함 할 수 있다. 상기 방법은, 상기 왜곡 제거 이미지로부터 상기 관심 영역 내 정보를 추출하는 단계를 포함할 수 있다. 본 개시의 일 측면에 따르면, 이미지를 처리하는 전자 장치가 제공될 수 있다. 상기 전자 장치는, 하나 이상의 카메라들; 하나 이상의 인스트럭션을 저장하는 메모리; 및 상기 메모리에 저장된 상기 하나 이상의 인스트럭션 을 실행하는 적어도 하나의 프로세서를 포함할 수 있다. 상기 적어도 하나의 프로세서는, 상기 하나 이상의 인 스트럭션을 실행함으로써, 상기 하나 이상의 카메라들을 통해 객체의 이미지를 획득할 수 있다. 상기 적어도 하 나의 프로세서는, 상기 하나 이상의 인스트럭션을 실행함으로써, 상기 객체의 표면의 관심 영역을 검출할 수 있 다. 상기 적어도 하나의 프로세서는, 상기 하나 이상의 인스트럭션을 실행함으로써, 상기 객체의 외곽선을 나타 내는, 객체 키 포인트들을 검출할 수 있다. 상기 적어도 하나의 프로세서는, 상기 하나 이상의 인스트럭션을 실 행함으로써, 상기 객체 키 포인트들에 기초하여, 상기 객체의 3차원 모양을 나타내는 3차원 파라미터의 값들을 추론하되, 상기 3차원 파라미터는, 상기 객체의 3차원의 기하학적 정보를 나타내는 피처들을 포함하는 것일 수 있다. 상기 적어도 하나의 프로세서는, 상기 하나 이상의 인스트럭션을 실행함으로써, 상기 3차원 파라미터에기초하여 상기 이미지에 대해 원근 변환을 수행함으로써, 상기 관심 영역이 평면으로 수정된 왜곡 제거 이미지 를 획득할 수 있다. 상기 적어도 하나의 프로세서는, 상기 하나 이상의 인스트럭션을 실행함으로써, 상기 왜곡 제거 이미지로부터 상기 관심 영역 내 정보를 추출할 수 있다. 본 개시의 일 측면에 따르면, 전자 장치가 이미지를 처리하여 왜곡을 제거하는, 전술 및 후술하는 방법들 중 어 느 하나를 실행시키기 위한 프로그램이 기록된 컴퓨터 판독 가능 기록매체를 제공할 수 있다."}
{"patent_id": "10-2023-0044355", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 개시에서, \"a, b 또는 c 중 적어도 하나\" 표현은 \" a\", \" b\", \" c\", \"a 및 b\", \"a 및 c\", \"b 및 c\", \"a, b 및 c 모두\", 혹은 그 변형들을 지칭할 수 있다. 본 개시에서 사용되는 용어는 본 개시에서의 기능을 고려하면서 가능한 현재 널리 사용되는 일반적인 용어들을 선택하였으나, 이는 당 분야에 종사하는 기술자의 의도 또는 판례, 새로운 기술의 출현 등에 따라 달라질 수 있 다. 또한, 특정한 경우는 출원인이 임의로 선정한 용어도 있으며, 이 경우 해당되는 설명 부분에서 상세히 그 의미를 기재할 것이다. 따라서 본 개시에서 사용되는 용어는 단순한 용어의 명칭이 아닌, 그 용어가 가지는 의 미와 본 개시의 전반에 걸친 내용을 토대로 정의되어야 한다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함할 수 있다. 기술적이거나 과학적인 용어를 포함해서 여기서 사용되는 용어들은 본 명세서에 기재된 기술 분야에서 통상의 지식을 가진 자에 의해 일반적으로 이해되는 것과 동일한 의미를 가질 수 있다. 또한, 본 명세서에서 사용되는 '제1' 또는 '제2' 등과 같이 서수를 포함하는 용어는 다양한 구성 요소들을 설명하는데 사용할 수 있지만, 상기 구성 요소들은 상기 용 어들에 의해 한정되어서는 안 된다. 상기 용어들은 하나의 구성 요소를 다른 구성 요소로부터 구별하는 목적으 로만 사용된다. 명세서 전체에서 어떤 부분이 어떤 구성요소를 \"포함\"한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다른 구성요소를 제외하는 것이 아니라 다른 구성요소를 더 포함할 수 있음을 의미한다. 또한, 명세서에 기재된 \"부\", \"모듈\" 등의 용어는 적어도 하나의 기능이나 동작을 처리하는 단위를 의미하며, 이는 하드웨어 또는 소 프트웨어로 구현되거나 하드웨어와 소프트웨어의 결합으로 구현될 수 있다. 본 개시에서, 3차원 파라미터란, 객체의 3차원 모양과 관련된 기하학적 특징을 나타내는 피처들로 구성된다. 3 차원 파라미터는 예를 들어, 객체의 높이 및 반지름 정보(또는, 가로, 세로 정보), 객체의 3차원 공간 상에서의 3차원 기하학적 변환을 위한 이동(translation) 및 회전(rotation) 정보, 객체를 촬영한 카메라의 초점 거리 정 보 등을 포함할 수 있으나, 이에 한정되는 것은 아니다. 3차원 파라미터는 변수이며, 3차원 파라미터 중 어느 하나의 값이 변경됨에 따라 3차원 모양 또한 변경될 수 있다. 이러한 3차원 파라미터에 따라 결정되는, 객체의 3차원 모양을 나타낼 수 있는 정보를 본 개시에서는 \"3차원 정보\"로 지칭한다. 본 개시에서, 객체의 3차원 정보란 이미지에 포함되는 객체의 3차원 모양을 나타낼 수 있는 정보(예를 들어, 가 로 값, 세로 값, 높이 값, 반지름 값 등)를 말한다. 객체의 3차원 정보는 반드시 객체의 절대적인 가로, 세로, 높이, 반지름 등의 값을 나타내는 3차원 파라미터들로 구성될 필요는 없으며, 객체의 3차원 비율을 나타내는 상 대적인 값을 나타내는 3차원 파라미터들로 구성될 수 있다. 본 개시의 전자 장치는 객체의 3차원 정보가 있으면, 객체와 동일한 비율을 갖는 3차원 모양의 객체를 렌더링할 수 있다.아래에서는 첨부한 도면을 참고하여 본 개시의 실시예에 대하여 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자가 용이하게 실시할 수 있도록 상세히 설명한다. 그러나 본 개시는 여러 가지 상이한 형태로 구현될 수 있으며 여기에서 설명하는 실시예에 한정되지 않는다. 그리고 도면에서 본 개시를 명확하게 설명하기 위해서 설 명과 관계없는 부분은 생략하였으며, 명세서 전체를 통하여 유사한 부분에 대해서는 유사한 도면 부호를 붙였다. 또한, 각각의 도면에서 사용된 도면 부호는 각각의 도면을 설명하기 위한 것일 뿐, 상이한 도면들 각각 에서 사용된 상이한 도면 부호가 상이한 요소를 나타내기 위한 것은 아니다. 이하 첨부된 도면을 참고하여 본 개시를 상세히 설명하기로 한다. 도 1은 본 개시의 일 실시예에 따른 전자 장치가 이미지의 왜곡을 제거하는 일 예시를 나타내는 도면이다. 도 1을 참조하면, 일 실시예에 따른 전자 장치는 카메라 및/또는 디스플레이를 포함하는 장치일 수 있다. 전자 장치는 카메라를 통해 이미지(정지 이미지 및/또는 비디오)를 촬영하고, 디스플레이를 통해 이미지 를 출력하는 장치일 수 있다. 예를 들어, 전자 장치는 스마트 TV, 스마트 폰, 태블릿 PC, 랩톱 PC, 스마 트 냉장고, 스마트 와인 냉장고 등을 포함할 수 있으나, 이에 한정되는 것은 아니다. 전자 장치는 카메라 및/또는 디스플레이를 포함하는 다양한 종류 및 형태의 전자 장치로 구현될 수 있다. 또한, 전자 장치는 오디오를 출력하기 위한 스피커를 포함할 수도 있다. 일 실시예에서, 전자 장치의 사용자는, 전자 장치의 카메라를 이용하여 객체를 촬영할 수 있 다. 전자 장치는 객체의 적어도 일부를 포함하는 이미지를 획득할 수 있다. 본 개시에서, 이미지 내의 객체의 표면에 인식되어야 할 정보가 있는 경우, 이를 \"관심 영역\"이라 지 칭한다. 예를 들어, 객체의 표면에 부착된 라벨 영역이 관심 영역이 될 수 있다. 일 실시예에서, 전자 장 치는 객체의 관심 영역으로부터, 객체와 관련된 정보를 추출할 수 있다. 본 개시에서는, 관심 영역의 일 예시로, 상품의 '라벨'에 대한 왜곡을 제거하는 것을 설명한다. 여기서 라 벨이란, 종이, 스티커, 천 등으로 제작되어 상품에 부착되는 것으로, 라벨에는 상품의 상표나 상품명 등이 인쇄 되어 있을 수 있다. 한편, 관심 영역은 반드시 라벨로 한정되는 것은 아니다. 예를 들면, 이미지 내 관심 영역은 상품의 라벨이 아닌, 상품의 성분, 사용법, 사용량 등 상품(객체)에 관련된 정보를 나타내는 영역일 수 도 있다. 본 개시에서 설명되는 예시는, 전자 장치는 객체에 포함된 적어도 하나의 라벨에 대응하는 영역을 관심 영역으로 식별하고, 적어도 하나의 라벨에 대응하는 영역으로부터 객체와 관련된 정보를 획득하 는 것이다. 객체가 3차원 모양인 경우, 2차원적인 이미지 내에서 객체의 라벨의 모양이 왜곡될 수 있다. 이에 따라, 전자 장치가 객체의 라벨로부터 획득한 정보(예를 들어, 로고, 아이콘, 텍스트 등)의 정확도가 저하될 수 있다. 일 실시예에 따른 전자 장치는, 관심 영역으로부터 정확한 정보를 추출하기 위해, 객체의 이미지를 이용하여 왜곡 제거 이미지를 획득할 수 있다. 여기서, 왜곡 제거 이미지는 객체의 관심 영역의 왜곡을 감소시키거나 및/또는 제거한 이미지를 말한다. 예를 들어, 왜곡 제거 이미지는 라벨의 굴곡 왜곡이 감소되거나 제거되어 평평하게 수정된 이미지일 수 있다. 일 실시예에 따른 전자 장치는, 관심 영역의 왜곡을 제거하는 이미지 처리 동작을 수행하기 위해, 객체의 적어도 일부를 포함하는 이미지로부터 관심 영역 및 객체 키 포인트들을 식별하고, 객체 의 3차원 정보를 추정할 수 있다. 그리고 전자 장치는 객체의 3차원 정보에 기초하여 왜곡 제 거 이미지를 생성할 수 있다. 일 실시예에 의하면, 전자 장치는 왜곡 제거 이미지로부터 객체 정보를 추출하고, 왜곡 제거 이미지 및/또는 왜곡 제거 이미지로부터 추출된 객체 정보를 사용자에게 제공할 수도 있다. 본 개시의 이해를 위해, 어떠한 도면들에서는 전자 장치의 동작이 개략적으로 설명될 것이고, 어떠한 도 면들에서는 전자 장치의 동작이 보다 상세하게 설명될 것이다. 도 2는 본 개시의 일 실시예에 따른 전자 장치가 처리하는 이미지 내의 객체의 관심 영역 및 왜곡 제거 방법을 개략적으로 설명하기 위한 도면이다. 도 2를 참조하면, 관심 영역은 관심 영역의 모양에 따라 분류될 수 있다. 예를 들어, 비정형화된 디자인의 관심 영역 및 정형화된 디자인의 관심 영역로 구별될 수 있다. 비정형화된 디자인이란, 관심 영역의 모양을 특정할 수 없는 디자인을 말한다. 관심 영역이 와인 라벨인 것을 예로 들면, 모양이 불규칙한 스티커 라벨, 멀티 스티커 라벨, 투명 스티커 라벨, 와인 병의 표면에 인쇄된라벨, 와인 병 전체를 커버하는 라벨 등이 비정형화된 디자인의 관심 영역으로 구별될 수 있으나, 이에 한 정되는 것은 아니다. 정형화된 디자인이란, 관심 영역의 모양을 특정할 수 있는 디자인을 말하며, 전자 장치에 기 저장되어 있 는 모양의 디자인이거나, 알고리즘 및/또는 인공지능 모델을 이용하여 식별 가능한 모양의 디자인을 말한다. 관 심 영역이 와인 라벨인 것을 예로 면, 정사각형 스티커 라벨, 직사각형 스티커 라벨 등이 정형화된 디자인의 관 심 영역으로 구별될 수 있으나, 이에 한정되는 것은 아니다. 전자 장치는 객체의 관심 영역의 왜곡을 제거할 때, 다양한 방식을 이용할 수 있다. 비정형화된 디자인의 관심 영역은, 관심 영역의 모양, 경계 등을 특정하기 어렵다. 즉, 관심 영역의 3차원 왜곡을 제거하기 위해 관심 영역의 3차원 정보(예를 들어, 3차원 왜곡 정보)가 필요하지만, 관심 영역의 특정이 어려우므로 관심 영역의 3차원 정보 추론 또한 어렵다. 따라서, 전자 장치는 객체 특징을 기초하여 객체 3차원 정보를 추론하여, 객체의 표면의 관심 영역의 3차원 정보를 획득할 수 있다. 정형화된 디자인의 관심 영 역의 경우, 전자 장치는 객체 특징에 기초하여 객체 3차원 정보를 획득할 수도 있고, 관심 영역의 특정이 가능하므로 관심 영역의 특징에 기초하여 객체 3차원 정보를 획득할 수도 있다. 일 실시예에서, 전자 장치는 객체 모양 기반 왜곡 제거 방식을 이용할 수 있다. 관심 영역이 비정형화된 디자인의 관심 영역인 경우, 관심 영역의 모양을 특정할 수 없으므로, 객체 자체의 3차원 정보를 추론하는 것이 적합할 수 있다. 객체 모양 기반 왜곡 제거 방식은, 객체를 기반으로 객체의 3차원 모양을 추론하여 객체 의 3차원 정보를 획득하고, 획득된 3차원 정보를 기반으로 3차원 왜곡을 제거할 수 있다. 객체 모양 기반 왜곡 제거 방식에 대해서는, 도 3 내지 도 10b를 참조하여 더 기술한다. 일 실시예에서, 전자 장치는 관심 영역 모양 기반 왜곡 제거 방식을 이용할 수 있다. 관심 영역이 정형화 된 디자인의 관심 영역인 경우, 관심 영역의 모양이 특정되므로, 관심 영역을 기준으로 객체의 3차원 정보 를 추론하는 것이 적합할 수 있다. 관심 영역 모양 기반 왜곡 제거 방식은, 관심 영역을 기반으로 객체의 3차원 모양을 추론하여 객체의 3차원 정보를 획득하고, 획득된 3차원 정보를 기반으로 3차원 왜곡을 제거할 수 있다. 관심 영역 모양 기반 왜곡 제거 방식에 대해서는, 도 11a 내지 도 11d를 참조하여 더 기술한다. 일 실시예에서, 전자 장치는 관심 영역 모양 및 객체 모양 기반 왜곡 제거 방식을 조합하여 이용할 수 있 다. 전자 장치는 객체 모양 기반 및 관심 영역 모양 기반 왜곡 제거 방식을 통합하여 객체의 3차원 정보 를 획득하고, 3차원 왜곡을 제거할 수 있다. 관심 영역 모양 및 객체 모양 기반 왜곡 제거 방식에 대해서는 도 12 내지 도 15b를 참조하여 더 기술한다. 도 3은 본 개시의 일 실시예에 따른 전자 장치가 이미지를 처리하는 방법을 설명하기 위한 흐름도이다. 단계 S310에서, 전자 장치는 카메라를 이용하여 객체의 이미지를 획득한다. 전자 장치는 사용자의 조작에 의해 카메라를 활성화할 수 있다. 예를 들어, 사용자는 객체에 관한 정보를 얻기 위해 전자 장치의 카메라를 활성화하고, 객체를 촬영할 수 있다. 사용자는 하드웨어 버튼을 누르거 나 전자 장치의 화면의 애플리케이션 아이콘을 터치하여 카메라를 활성화할 수 있고, 음성 명령(예: 카메 라 켜줘)을 통해 카메라를 활성화할 수도 있다. 전자 장치는 카메라를 활성화하고, 사용자의 조작에 의해 객체가 포함된 이미지를 캡처할 수 있다. 단계 S320에서, 전자 장치는 객체의 표면의 관심 영역을 검출한다. 관심 영역은, 객체에 관련된 정보가 포함되는 영역일 수 있다. 일 실시예에서, 객체는 '상품'이고, 관심 영역은 상품의 '라벨'일 수 있다. 이에 따라, 관심 영역에는 상품에 관련된 정보인 상표나 상품명 등이 포함될 수 있다. 또한, 관심 영역에는 상품에 관련된 정보인 상품의 성분, 사용법, 사용량, 취급상의 주의 사항, 상품의 가격, 부피, 용량 등이 포함될 수 있다. 일 실시예에서, 전자 장치는 인공지능 모델인 관심 영역 검출 모델을 이용하여 객체의 관심 영역을 검출 할 수 있다. 관심 영역 검출 모델은, 이미지를 입력 받아 이미지 내의 관심 영역을 나타내는 데이터를 출력하도 록 훈련된 인공지능 모델일 수 있다. 관심 영역 검출 모델은, 알려진 다양한 심층 신경망 아키텍처 및 알고리즘 을 이용하거나, 알려진 다양한 심층 신경망 아키텍처 및 알고리즘의 변형을 통해 구현될 수 있다. 본 개시에서 는, 객체의 예시를 '상품'으로 하고, 관심 영역의 예시를 '라벨'로 하므로, 관심 영역 검출 모델이 \"라벨 검출 모델\"로 지칭될 것이다. 전자 장치가 관심 영역을 검출하는 구체적인 동작에 대해서는, 도 6a 내지 도 6d를 참조하여 더 기술하기로 한다. 단계 S330에서, 전자 장치는 객체의 외곽선을 나타내는, 객체 키 포인트들을 검출한다. 일 실시예에서, 전자 장치는 인공지능 모델인 객체 검출 모델을 이용하여 객체의 키 포인트들을 검출할 수 있다. 객체 검출 모델은, 이미지를 입력 받아 이미지 내의 객체의 외곽선을 나타내는 키 포인트들을 출력하 도록 훈련된 인공지능 모델일 수 있다. 객체 검출 모델은, 알려진 다양한 심층 신경망 아키텍처 및 알고리즘을 이용하거나, 알려진 다양한 심층 신경망 아키텍처 및 알고리즘의 변형을 통해 구현될 수 있다. 전자 장치(300 0)가 객체 키 포인트들을 검출하는 구체적인 동작에 대해서는, 도 5a 내지 도 5b를 참조하여 더 기술하기로 한 다. 단계 S340에서, 전자 장치는 객체 키 포인트들에 기초하여, 객체의 3차원 모양을 나타내는 3차원 파라미 터의 값들, 예를 들어, 객체의 원본 모양을 나타내는 3차원 파라미터 값들을 추론한다. 전자 장치가 카메라를 이용하여 3차원의 모양을 갖는 객체의 이미지를 획득하면, 3차원 객체가 2차원 평 면에 투영된다. 이로 인해, 3차원 장면에 있는 객체의 상대적인 크기, 위치 및 모양이 2차원의 이미지 내에서 다르게 나타나는, 원근 왜곡이 발생할 수 있다. 전자 장치는 3차원 장면의 객체의 원본 3차원 모양을 추 론하기 위해, 3차원 파라미터의 값들을 추론할 수 있다. 일 실시예에서, 3차원 파라미터는 객체의 원본 3차원 모양을 묘사할 수 있는 다양한 피처들을 포함할 수 있다. 3차원 파라미터의 피처들은 예를 들어, 객체의 3차원 회전, 이동, 치수, 스케일링, 카메라 파라미터 중 적어도 하나에 대응할 수 있다. 또한, 카메라 파라미터는 카메라의 내부 파라미터로, 초점거리(focal length), 주점 (principal point), 종횡비(aspect ratio), 비대칭 계수(skew coefficient) 등을 포함할 수 있으나, 이에 한정 되는 것은 아니다. 전자 장치가 객체의 원본 3차원 모양을 나타내는 3차원 파라미터의 값들을 추론하는 구체적인 동작에 대 해서는, 도 7a 내지 도 9c를 참조하여 더 기술하기로 한다. 한편, 전자 장치가 3차원 파라미터의 값들을 추론할 때, 객체의 3차원 모양에 관한 정보가 이용될 수 있 다. 예를 들어, 객체의 3차원 모양 타입이 실린더 타입이면, 3차원 파라미터 또한 실린더의 3차원 특징을 나타 내는 피처들로 구성될 수 있다. 전자 장치는 3차원 모양에 관한 정보를 이용하기 위해, 객체의 3차원 모 양을 식별할 수 있다. 전자 장치가 객체의 3차원 모양을 식별하는 동작에 대해서는, 도 16 내지 도 18d를 참조하여 더 기술하기로 한다. 단계 S350에서, 전자 장치는 3차원 파라미터에 기초하여 이미지에 대해 원근 변환(perspective transform)을 수행함으로써, 관심 영역이 평면으로 수정된 왜곡 제거 이미지를 획득한다. 전자 장치가 3차원 파라미터의 값들을 추론하면, 3차원 파라미터의 값들이 객체의 3차원 정보를 나타내게 된다. 따라서, 전자 장치는 이미지 내에 존재하는 객체의 3차원 왜곡을 제거할 수 있다. 일 실시예에서, 전자 장치는 객체의 표면의 3차원 왜곡(예를 들어, 곡면 왜곡 등)을 나타내는, 2차원 메 시(mesh) 데이터를 생성할 수 있다. 2차원 메시 데이터는 3차원 파라미터 값들을 이용하여, 3차원 공간 상의 객 체의 표면 포인트들을 2차원으로 투영한 결과로써, 객체의 표면 왜곡 정보를 의미할 수 있다. 다만, 이에 한정 되는 것은 아니며, 전자 장치는 3차원 파라미터를 이용하여 3차원 왜곡을 제거하는 데 이용될 수 있는 다 양한 타입의 데이터를 생성할 수 있다. 일 실시예에서, 전자 장치는 이미지에 대해 원근 변환을 수행할 수 있다. 예를 들어, 전자 장치는 객체의 왜곡을 포함하는 2차원 메시 데이터에 기초하여, 왜곡을 포함하는 원본 이미지와 왜곡이 제거된 변환 이 미지가 서로 대응되는 포인트들을 선택할 수 있다. 전자 장치는 선택된 포인트들에 기초하여, 원근 변환 을 수행하기 위한 호모그래피 행렬을 계산할 수 있다. 전자 장치는 호모그래피 행렬을 이용하여, 원근 변 환을 적용하고, 왜곡이 제거된 이미지를 획득할 수 있다. 이에 따라, 전자 장치는 객체의 관심 영역의 3 차원 왜곡을 제거할 수 있다. 한편 본 개시에서, 전자 장치가 왜곡을 제거한다는 것은, 왜곡을 제거하기 위해 일련의 동작들을 수행한다는 것을 말하며, 반드시 왜곡을 완전히 제거한다는 의미를 내포하는 것은 아니다. 즉, 왜곡 제거 결과, 왜곡이 없는 이미지 또는 왜곡이 감소된 이미지가 획득될 수 있다. 일 실시예에서, 전자 장치는 왜곡 제거 이미지로부터 관심 영역에 대응하는 영역만을 잘라낼 수 있다. 단계 S360에서, 전자 장치는 왜곡 제거 이미지로부터 관심 영역 내 정보를 추출한다. 전자 장치는 왜곡 제거 이미지로부터 관심 영역 내 정보를 추출함으로써, 객체와 관련된 정보를 획득할 수 있다. 일 실시예에서, 전자 장치는 광학 문자 인식(Optical character recognition; OCR) 모델을 이용하여 관 심 영역 내의 텍스트를 식별할 수 있다. 전자 장치는 이미지 내 객체의 3차원 정보를 추론하고, 추론된 객체의 3차원 정보를 이용하여 정밀한 원근 변환을 수행함으로써 관심 영역의 왜곡을 제거한다. 따라서, 3차원 왜곡이 존재하는 원본 이미지에 대하여 OCR을 적용하는 것보다 향상된 정확도로 관심 영역 내의 텍스트를 추출 할 수 있다. 일 실시예에서, 전자 장치는 인공지능 모델인 정보 검출 모델을 이용하여 관심 영역 내의 정보를 검출할 수 있다. 정보 검출 모델은, 이미지를 입력 받아 이미지 내에서 식별 가능한 정보를 출력하도록 훈련된 인공지 능 모델일 수 있다. 예를 들어, 정보 검출 모델을 통해 관심 영역 내 그림, 로고, 아이콘 등이 식별될 수 있으 나, 이에 한정되는 것은 아니다. 관심 영역 검출 모델은, 알려진 다양한 심층 신경망 아키텍처 및 알고리즘을 이용하거나, 알려진 다양한 심층 신경망 아키텍처 및 알고리즘의 변형을 통해 구현될 수 있다. 일 실시예에 따른 전자 장치는, OCR 모델 및/또는 정보 검출 모델을 이용하여 객체와 관련된 정보를 추출 하고, 추출된 정보를 출력할 수 있다. 예를 들어, 객체와 관련된 정보는 전자 장치의 화면에 출력되어 사 용자에게 제공될 수 있다. 한편, OCR 모델 및/또는 정보 검출 모델은 전자 장치의 메모리에 저장될 수도 있고, 외부 서버에 저장될 수도 있다. 따라서, 정보 검출 동작은 전자 장치에서 수행될 수 있고, 외부 서버에서 수행될 수도 있다. 전자 장치가 OCR 모델 및/또는 정보 검출 모델을 이용하여 왜곡 제거 이미지로부터 객체와 관련된 정보를 획득하는 동작에 대해서는 도 10b를 참조하여 더 기술하기로 한다. 도 4a는 본 개시의 일 실시예에 따른 전자 장치가 이미지를 처리하는 동작을 전반적으로 설명하기 위한 도면이 다. 도 4a를 설명함에 있어서, 객체가 와인 보틀인 것을 예시로 들어 설명한다. 이에 따라, 후술되는 동작들은 와인 보틀 내 와인 라벨의 이미지를 처리하는 것을 가정하여 설명될 것이다. 예를 들어, 객체 키 포인트들은 와 인 보틀의 키 포인트들이 검출되는 것이고, 3차원 파라미터는 와인 보틀의 모양을 나타내기 위한 피처들을 포함 하는 것이다. 다만, 이는 예시일 뿐, 객체가 와인 보틀이 아닌 다른 객체인 경우, 해당 객체에 적합한 설정 값 들(예를 들어, 3차원 파라미터의 피처 등)이 적용될 수 있다. 도 4a를 참조하면, 일 실시예에 따른 전자 장치는 객체 이미지를 획득할 수 있다. 객체 이미지(40 2)는 전자 장치의 사용자가 객체를 촬영함으로써 획득될 수 있다. 또는, 객체 이미지는 전자 장치에 기 저장되어 있던, 객체를 촬영한 이미지가 획득되는 것일 수 있다. 또는, 객체 이미지(40 2)는 객체를 촬영한 이미지가 다른 전자 장치(예를 들어, 외부 서버, 다른 사용자의 전자 장치 등)로부터 수신된 것일 수 있다. 일 실시예에서, 전자 장치는 객체의 외곽선을 나타내는 객체 키 포인트들을 검출할 수 있다. 전자 장치는 객체 검출 모델을 이용하여, 객체 이미지로부터 객체 키 포인트들을 검출할 수 있 다. 객체 검출 모델은, 이미지를 입력 받아 이미지 내의 객체의 외곽선을 나타내는 키 포인트들을 출 력하도록 훈련된 인공지능 모델일 수 있다. 일 실시예에서, 전자 장치는 객체 이미지를 전처리하여 객체 검출 모델에 입력할 수 있다. 예 를 들어, 전자 장치는 객체 이미지의 일부를 잘라낼 수 있다. 잘라낸 영역은 객체 이미지 내에 서 객체 이외의 영역일 수 있다. 예를 들어, 전자 장치는 데이터 양을 감소시키기 위해 객체 이미지(40 2)의 해상도가 감소되도록 객체 이미지를 리사이즈 할 수 있다. 일 실시예에서, 전자 장치는 객체 검출 모델을 이용하여 획득된 객체 키 포인트들 중 일부를 선택할 수 있다. 예를 들어, 객체 키 포인트들이 와인 보틀 모양에 대응되는 경우, 전자 장치는 보 틀 넥 부분에 대응하는 키 포인트들을 제외하고 보틀 바디 부분에 대응되는, 객체 키 포인트들을 객체 키 포인 트들의 서브셋으로 선택할 수 있다. 객체 키 포인트들의 서브셋 또한 객체의 외곽선을 나타내는 키 포인트들이므로, 이하에서는 객체 키 포인트들으로 통합하여 기술한다. 일 실시예에서, 전자 장치는 객체 키 포인트들에 기초하여, 객체의 원본 3차원 모양을 묘사할 수 있 는 3차원 파라미터의 값들을 추론할 수 있다. 3차원 파라미터는 객체의 원본 3차원 모양을 묘사할 수 있는 다양한 피처들을 포함할 수 있다. 3차원 파라미터의 피처들은 예를 들어, 객체의 3차원 회전, 이동,치수, 스케일링, 카메라 파라미터 중 적어도 하나에 대응할 수 있다. 또한, 카메라 파라미터는 카메라의 내부 파라미터로, 초점거리(focal length), 주점(principal point), 종횡비(aspect ratio), 비대칭 계수(skew coefficient) 등을 포함할 수 있으나, 이에 한정되는 것은 아니다. 3차원 파라미터의 피처들은, 3차원 모 양을 나타내기 위한 것이므로, 3차원 모양마다 각각 대응하는 3차원 파라미터의 피처가 다를 수 있다. 예 를 들어, 3차원 모양 타입이 구 타입인 경우, 구 타입에 대응하는 3차원 파라미터가 이용되고, 3차원 모양 타입이 정육면체 타입인 경우, 정육면체 타입에 대응하는 3차원 파라미터가 이용될 수 있다. 이 경우, 3차 원 파라미터를 구성하는 피처들은 3차원 모양 타입 마다 상이할 수 있다. 예를 들어, 구 타입의 3차원 파 라미터에는 반지름 및/또는 직경 등의 피처가 포함될 수 있으며, 정육면체 타입의 3차원 파라미터에 는 가로, 세로, 높이 등의 피처가 포함될 수 있다. 마찬가지로, 도 4a에 도시된 것과 같이 객체가 와인 보틀인 경우, 3차원 파라미터는 실린더 타입 또는 보틀 타입에 대응하는 3차원 파라미터가 이용될 수 있다. 전자 장치는 3차원 파라미터의 초기 값들을 획득하고, 객체 키 포인트들을 이용하여 3차원 파 라미터의 초기 값들을 튜닝할 수 있다. 본 개시에서, 전자 장치가 3차원 파라미터의 값들을 튜 닝하는 과정을 \"3D 피팅 과정(또는, 3D 피팅 동작)\"이라고 지칭될 수 있다. 3D 피팅은, 알고리즘 및/또는 인공 지능 모델을 이용하여 수행될 수 있다. 3D 피팅을 위한 알고리즘 및/또는 인공지능 모델은 도 8a 내지 도 9c를 참조하여 더 기술하기로 한다. 전자 장치가 3차원 파라미터의 값들을 튜닝하여 최종 값들을 획득하 면, 3차원 파라미터의 최종 값들은 객체의 원본 3차원 모양을 나타내게 된다. 즉, 3차원 파라미터의 최종 값들은 객체의 3차원 정보를 나타낸다. 전자 장치는 객체의 3차원 정보에 기초하여, 객체의 3차원 왜곡을 제거하기 위한 데이터를 생성할 수 있다. 예를 들어, 전자 장치는 객체의 표면의 3차원 왜곡(예를 들어, 곡면 왜곡 등)을 나타내는, 2차원 메시(mesh) 데이터를 생성할 수 있다. 2차원 메시 데이터는, 획득된 3차원 파라미터 값들에 기초하여, 3차원 공간 상에서 객체의 관심 영역 좌표를 2차원으로 투영하여 생성된 데이터를 말하며, 객체의 관심 영역의 왜곡 정보를 포함한다. 예를 들어, 굴곡 형상을 갖는 3차원 객체 인 \"와인 병\"의 표면에 부착된 관심 영역은 \"와인 라벨\"일 수 있다. 이 경우, 2차원 메시 데이터는 와인 병의 표면에 부착된 와인 라벨의 3차원 공간상 좌표를 2차원으로 투영한 것으로, 와인 병을 포함하는 이미지 내 에서 관심 영역인 와인 라벨의 왜곡 정보를 나타낼 수 있다. 일 실시예에서, 전자 장치는 객체 이미지에 원근 변환을 적용할 수 있다. 예를 들어, 전자 장 치는 객체의 왜곡을 포함하는 2차원 메시 데이터에 기초하여, 왜곡을 포함하는 원본 이미지와 왜곡 이 제거된 변환 이미지가 서로 대응되는 포인트들을 선택할 수 있다. 전자 장치는 선택된 포인트들에 기 초하여, 원근 변환을 수행하기 위한 호모그래피 행렬을 계산할 수 있다. 전자 장치는 호모그래피 행렬을 이용하여, 원근 변환을 적용하고, 왜곡이 제거된 이미지를 획득할 수 있다. 전자 장치는 원근 변환을 수행하기 이전에, 객체 이미지에서 객체에 대응되는 영역만을 잘라낼 수 있다. 일 실시 예에 따른 전자 장치는 객체의 3차원 정보 추론하고, 3차원 정보를 이용하여 원근 변환을 수행하므 로, 객체의 3차원 정보 없이 일반적으로 원근 변환을 수행하는 것보다 정밀하게 이미지 내 왜곡을 제거할 수 있 다. 일 실시예에서, 전자 장치는 왜곡이 제거된 이미지 내에서 관심 영역 검출을 수행할 수 있다. 예를 들어, 전자 장치는 관심 영역 검출 모델을 이용하여, 관심 영역을 나타내는 히트 맵을 생성할 수 있 으나, 이에 한정되는 것은 아니다. 일 실시예에서, 전자 장치는 관심 영역을 검출하면, 관심 영역에 대응하는 영역을 잘라내어, 관심 영역 이미지를 획득할 수 있다. 일 실시예에 따른 전자 장치는 왜곡이 제거된 관심 영역 이미지로부 터 관심 영역 내 정보를 추출함으로써, 객체와 관련된 정보를 획득할 수 있다. 도 4b는 본 개시의 일 실시예에 따른 전자 장치가 이미지를 처리하는 동작을 개략적으로 설명하기 위한 도면이 다. 도 4b를 참조하면, 전자 장치는 3차원 객체를 포함하는 객체 이미지를 처리할 수 있다. 전자 장치 가 3차원 객체를 촬영하면, 3차원 객체가 2차원 평면(예를 들어, 카메라의 이미지 센서 등)에 투영되므로, 3차원 장면에 있는 객체의 상대적인 크기, 위치 및 모양이 2차원의 이미지 내에서 다르게 나타나는 원근 왜곡이 발생할 수 있다. 왜곡을 제거하기 위한 전자 장치의 동작들은 적어도 아래의 동작들을 포함 할 수 있다. 전자 장치의 동작은 객체 외곽 추정 동작을 포함할 수 있다. 전자 장치는 객체 이미지를 분석하여 객체 외곽을 추정한, 객체 외곽 정보 (예를 들어, 객체 키 포인트들)를 획득할 수 있다. 또한, 전자장치의 동작은 관심 영역 추정 동작을 포함할 수 있다. 전자 장치는 객체 이미지를 분석 하여 객체의 관심 영역을 추정한, 관심 영역 정보를 획득할 수 있다. 객체 외곽 추정 동작에 대해서는 도 5a 내지 도 5b에 대한 설명에서 더 기술하고, 관심 영역 추정 동작에 대해서는 도 6a 내지 도 6d에 대한 설명에서 더 기술할 것이다. 전자 장치의 동작은 객체 3차원 정보 추정 동작을 포함할 수 있다. 전자 장치는 객체 외곽 정 보 및 관심 영역 정보 중 적어도 일부에 기초하여, 객체 3차원 정보를 획득할 수 있다. 전자 장치는, 객 체 3차원 정보를 추정하기 위한 알고리즘을 이용하거나, 객체 3차원 정보를 추정하기 위해 훈련된 인공지능 모 델을 이용할 수 있다. 객체 3차원 정보 추정 동작에 대해서는 도 8a 내지 도 9c에 대한 설명에서 더 기술할 것 이다. 전자 장치의 동작은, 왜곡 제거 동작을 포함할 수 있다. 전자 장치는 객체 3차원 정보에 기초 하여, 관심 영역의 3차원 왜곡을 제거할 수 있다. 예를 들어, 전자 장치는 3차원 왜곡을 제거하기 위해, 객체 3차원 정보에 기초한 원근 변환을 수행할 수 있다. 다만, 왜곡 제거 동작은 3차원 왜곡을 제거하기 위한 또다른 알고리즘들이 적용될 수도 있다. 전자 장치의 동작은, 배경 제거 동작을 포함할 수 있다. 일부 실시예에서, 배경 제거 동작은 생략될 수 있다. 예를 들어, 관심 영역의 모양이 정형화된 디자인(예를 들어, 사각형)인 경우 또는 3차원 왜곡 을 제거한 후 획득된 관심 영역 이미지에 배경이 없는 경우, 배경 제거 동작은 생략될 수 있다. 또는 관심 영역의 모양이 비정형화된 디자인인 경우, 배경 제거 동작을 통해 관심 영역 이외의 픽셀들이 제거될 수 있다. 도 5a는 본 개시의 일 실시예에 따른 전자 장치가 객체 키 포인트들을 검출하는 동작을 설명하기 위한 도면이다. 일 실시예에서, 전자 장치는 객체 검출 모델을 이용하여 객체 키 포인트들을 검출할 수 있다. 전자 장치는 객체 이미지를 객체 검출 모델에 입력하고, 객체 검출 모델로부터 출력되는 객체 키 포인트들을 획득할 수 있다. 객체 검출 모델은, 백본(backbone) 네트워크 및 회귀 모듈을 포함할 수 있다. 백본 네트워크는 입력 이미 지로부터 다양한 피처들을 추출하기 위한 알려진 신경망(예를 들어, 컨볼루션 신경망(Convolutional Neural Networks; CNNs) 기반의 네트워크 등) 아키텍처가 사용될 수 있다. 백본 네트워크는 미리-훈련된(pre- trained) 네트워크일 수 있으며, 입력 이미지를 입력 받아 피처맵을 출력할 수 있다. 회귀 모듈은 백본 네 트워크로부터 출력되는 피처맵을 이용하여, 객체 키 포인트들을 검출하는 태스크를 수행한다. 회귀 모듈은 객체 외곽선을 나타내는 객체 키 포인트들이 정답 값에 수렴하도록 학습하기 위한 회귀 알고리즘을 이용할 수 있다. 회귀 모듈은 객체 키 포인트들을 검출하기 위한 신경망 레이어 및 가중치들을 포함할 수 있다. 예를 들어, 회귀 모듈은 객체를 검출하기 위해 특별하게 설계된 일련의 완전 연결 레이어들 및 컨볼루션 레이어 를 포함하도록 구성될 수 있으나, 이에 한정되는 것은 아니다. 전자 장치가 객체 검출 모델의 트레 이닝 데이터셋을 이용하여 객체 검출 모델을 훈련시키면, 훈련 과정에서 백본 네트워크 및 회귀 모듈의 가 중치들이 업데이트될 수 있다. 도 5b는 본 개시의 일 실시예에 따른 객체 검출 모델의 트레이닝 데이터를 설명하기 위한 도면이다. 일 실시예에서, 객체 검출 모델은 객체를 포함하는 다양한 이미지들로 구성되는 트레이닝 데이터셋을 이용 하여 훈련된 것일 수 있다. 객체 검출 모델의 트레이닝 데이터셋은, 객체 이미지 및 객체 이미지 에 대응하는, 객체의 외곽선을 나타내는 정답 주석들(ground-truth annotations)이 포함될 수 있다. 정답 주석들은 예를 들어, 객체 검출을 위한 키 포인트들의 좌표 등일 수 있으나, 이에 한정되는 것은 아 니다. 구체적으로, 객체 키 포인트들은, 객체의 원본 3차원 모양을 추론하기 위해 설정되는 포인트들로, 객체의 외곽 영역을 나타내는 포인트들일 수 있다. 3차원 객체의 표면에 관심 영역이 있는 경우, 키 포인트들의 일부는 관심 영역의 외곽 영역을 나타내는 포인트들일 수도 있다. 전자 장치는 객체 검출 모델의 트레이닝 데이터셋을 이용하여 객체 검출 모델을 훈련시킬 수 있다. 객체 검출 모델은 이미지를 입력 받아 객체 키 포인트들을 예측하고, 손실 함수를 이용하여 정답 주 석들과 예측된 객체 키 포인트들 사이의 에러를 계산할 수 있다. 계산된 에러에 기초하여, 객체 검출 모델 의 백본 네트워크 및 회귀 모듈의 가중치들이 업데이트될 수 있다. 한편, 객체의 외곽선을 나타내는 정답 주석들은, 미리 설정된 형태일 수 있다. 예를 들어, 정답 주석들 이 객체의 외곽선을 나타내는 키 포인트들이고, 객체는 와인 보틀인 경우, 객체 외곽선을 나타내는 키 포 인트들은 보틀 넥 부분에 대응하는 키 포인트들 및 보틀 바디 부분에 대응되는 키 포인트들을 포함할 수 있다. 이 경우, 키 포인트들의 위치 및 개수가 미리 설정되어 있을 수 있다. 예를 들어, 정답 주석들은, 보틀 넥 부분에 대응되는 키 포인트들은 제외하고, 실린더 모양의 보틀 바디 부분에 대응되는 키 포인트들만 포함하는 것일 수 있다. 또한, 정답 주석들은 객체 외곽선을 나타내는 18개의 키 포인트들일 수 있으며, 구체적으로, 객체 왼쪽의 9개의 키 포인트들 및 객체 오른쪽의 9개의 키 포인트들일 수 있다. 이 경우, 전자 장 치는 객체 검출 모델을 이용하여 객체의 외곽선을 나타내는 18개의 키 포인트들을 검출할 수 있다. 도 5c는 본 개시의 일 실시예에 따른 객체 검출 모델의 트레이닝 데이터를 추가적으로 설명하기 위한 도면이다. 일 실시예에서, 트레이닝 데이터셋에 포함되는 객체 이미지는 다양한 타입의 3차원 모양의 객체 이미지로 구성 될 수 있다. 따라서, 객체의 3차원 모양 타입에 따라, 객체의 외곽선을 나타내는 정답 주석들이 상이할 수 있다. 예를 들어, 정답 주석들이 객체의 외곽선을 나타내는 키 포인트들이고, 객체는 컵 누들인 경우, 객체 외곽 선을 나타내는 키 포인트들은 컵 누들의 위쪽 원형면의 외곽 부분에 대응되는 키 포인트들과 컵 누들의 아래쪽 원형면의 외곽 부분에 대응되는 키 포인트들을 포함하는 것일 수 있다. 또는, 정답 주석들이 객체의 외곽선을 나타내는 키 포인트들이고, 객체는 곽 우유인 경우, 객체 외곽선을 나타내는 키 포인트들은, 직육면체 형상의 곽 우유를 특정 시점에서 바라볼 때를 기준으로 보여지는 모서리들 부분에 대응되는 키 포인트들을 포함하는 것일 수 있다. 한편, 전술한 와인 보틀, 컵 누들, 곽 우유 등의 객체에 대하여, 객체의 3차원 모양 타입에 따라 객체의 키 포 인트들을 나타내는 정답 주석들이 설정된 위치는, 일 예시일 뿐이다. 객체의 외곽선을 나타내는 정답 주석 들은, 객체의 3차원 정보를 획득하기 위해 객체의 특징을 나타낼 수 있는 또다른 위치로 설정될 수도 있다. 일 실시예에서, 전자 장치는 다양한 3차원 모양을 갖는 객체 이미지들로 구성되는 트레이닝 데이터셋을 이용하여 객체 검출 모델을 훈련시킬 수 있다. 훈련된 객체 검출 모델은 전자 장치가 새로운 이미지를 획득하고 이미지 내 객체의 키 포인트들을 검출할 수 있다. 도 6a는 본 개시의 일 실시예에 따른 전자 장치가 객체의 표면의 관심 영역을 식별하는 동작을 설명하기 위한 도면이다. 일 실시예에서, 전자 장치는 관심 영역 검출 모델을 이용하여 관심 영역을 검출할 수 있다. 전 자 장치는 객체 이미지를 관심 영역 검출 모델에 입력하고, 관심 영역 검출 모델로부터 출력되는, 관심 영역을 획득할 수 있다. 도 6a의 관심 영역은, 관심 영역을 히트 맵(heat map) 으로 시각화한 것이다. 관심 영역 검출 모델은, 백본(backbone) 네트워크 및, 관심 영역을 검출하기 위한 태스크-특화 레이어들 (또는, \"헤드(head)\" 라고도 지칭됨)을 포함할 수 있다. 백본 네트워크는 입력 이미지로부터 다양한 피처 들을 추출하기 위한 알려진 신경망(예를 들어, 컨볼루션 신경망(Convolutional Neural Networks; CNNs) 등) 아 키텍처가 사용될 수 있다. 백본 네트워크는 미리-훈련된(pre-trained) 네트워크일 수 있으며, 객체 이미지(60 0)를 입력 받아 피처맵을 출력할 수 있다. 태스크-특화 레이어(Task-specific layer)들은 관심 영역을 검출하기 위한 레이어들 및 가중치들로 구성되는 블록일 수 있다. 예를 들어, 태스크-특화 레이어들은 히트 맵을 출력하 기 위한 컨볼루션 레이어들로 구성되는 블록일 수 있으나, 이에 한정되는 것은 아니다. 태스크-특화 레이어들은 도 5a에 도시된 것과 같이 회귀 모듈을 포함하는 것일 수 있다. 회귀 모듈은 백본 네트워크로부터 출력되는 피 처맵을 이용하여, 관심 영역을 검출하는 태스크를 수행한다. 회귀 모듈은 관심 영역을 검출하기 위한 신경 망 레이어 및 가중치들을 포함할 수 있다. 예를 들어, 회귀 모듈은 관심 영역을 검출하기 위해 설계된 일련의 완전 연결 레이어들 및 컨볼루션 레이어를 포함하도록 구성될 수 있으나, 이에 한정되는 것은 아니다. 전자 장 치가 관심 영역 검출 모델의 트레이닝 데이터셋을 이용하여 관심 영역 검출 모델을 훈련시키면, 훈련 과정에서 관심 영역 검출 모델의 가중치들이 업데이트될 수 있다. 도 6b는 본 개시의 일 실시예에 따른 관심 영역 검출 모델의 트레이닝 데이터를 설명하기 위한 도면이다. 일 실시예에서, 관심 영역 검출 모델은 관심 영역을 포함하는 다양한 이미지들로 구성되는 트레이닝 데이 터셋을 이용하여 훈련된 것일 수 있다. 관심 영역 검출 모델의 트레이닝 데이터셋은, 객체 이미지 및 객체이미지에 대응하는, 관심 영역을 나타내는 정답 주석들이 포함될 수 있다. 정답 주석들은 예를 들어, 이진 마스크일 수 있다. 구체적으로, 객체 이미지 내에서 관심 영역 외의 영역에 대응하는 픽셀들은 0으로 마스 킹되고, 관심 영역에 대응하는 픽셀들은 1로 마스킹된 것일 수 있으나, 이에 한정되는 것은 아니다. 전자 장치는 관심 영역 검출 모델의 트레이닝 데이터셋을 이용하여 관심 영역 검출 모델을 훈 련시킬 수 있다. 관심 영역 검출 모델은 이미지를 입력 받아 객체의 표면의 관심 영역을 예측하고, 손실 함수를 이용하여 정답 주석들과 예측된 관심 영역 사이의 에러를 계산할 수 있다. 계산된 에러에 기초하여, 관심 영역 검출 모델의 가중치들이 업데이트될 수 있다. 도 6c는 본 개시의 일 실시예에 따른 전자 장치가 관심 영역을 검출한 결과를 설명하기 위한 도면이다. 도 6c를 참조하면, 전자 장치는 이미지 내에서 관심 영역을 검출하여 관심 영역 데이터를 획득할 수 있다. 예를 들어, 전자 장치는 관심 영역을 나타내는 히트 맵 이미지를 획득할 수 있다. 이 경우, 전자 장치는 전술한 관심 영역 검출 모델을 이용할 수 있다. 전자 장치는 다양한 방식으로 히트 맵 이미지를 이용할 수 있다. 일 실시예에서, 전자 장치는 관심 영역을 나타내는 히트 맵 이미지에 기초하여, 관심 영역만을 잘라 낸 관심 영역 이미지를 생성할 수 있다. 관심 영역 이미지는, 왜곡이 제거된 이미지일 수 있다. 일 실시예에서, 전자 장치는 관심 영역 이미지를 획득하고, 전술한 실시예에 따라 획득된 객체의 원본 3차원 모양에 관한 정보에 기초하여, 관심 영역 이미지의 3차원 왜곡을 제거할 수 있다. 일 실시예에서, 전자 장치는 전술한 실시예에 따라 입력 이미지를 이용하여 객체의 원본 3차원 모양에 관한 정보를 획득 하고, 객체 표면의 관심 영역의 3차원 왜곡을 제거한 후에, 관심 영역만을 잘라내어 관심 영역 이미지를 획득할 수 있다. 일 실시예에서, 전자 장치는 관심 영역을 나타내는 히트 맵 이미지 및/또는 관심 영역 이미지 에 기초하여, 배경을 제거한 관심 영역 이미지를 생성할 수 있다. 배경을 제거한 관심 영역 이미지란, 관심 영역에 대응하는 픽셀들 외에 다른 영역에 대응하는 픽셀들이 제거된 이미지일 수 있다. 또한, 배경을 제거한 관심 영역 이미지란, 전술한 실시예에 따라 3차원 왜곡이 제거된 관심 영역의 이미지 일 수 있다. 전자 장치는 배경을 제거한 관심 영역 이미지를 사용자에게 제공할 수 있다. 예를 들어, 관심 영역이 상품의 라벨인 경우, 배경을 제거한 관심 영역 이미지는 \"라벨 이미지\"로 지칭될 수 있 다. 전자 장치는 사용자가 상품의 정보를 쉽게 식별할 수 있도록, 라벨 이미지와 상품 정보를 함께 저장 하여 제공할 수 있다. 또는, 전자 장치는 라벨 이미지를 객체에 합성(예를 들어, 라벨 워핑 등)하여 사용 자에게 제공할 수 있다. 도 6d는 본 개시의 일 실시예에 따른 전자 장치가 관심 영역의 이미지를 처리하는 동작을 설명하기 위한 도면이 다. 도 6d를 참조하면, 도 6d에 도시된 히트 맵 이미지는 입력 이미지에 관심 영역에 대응하는 영역을 히트 맵 의 방식으로 오버랩하여 시각화한 것이다. 일 실시예에서, 전자 장치는 관심 영역 이미지를 생성할 때, 히트 맵 데이터에 기초하여 관심 영역 이미지를 생성할 수 있다. 예를 들어, 히트 맵 이미지에서, 관심 영역에 대응하는 영역의 픽셀들은 1 로 마스킹 되어 있고, 관심 영역 외 영역의 픽셀들은 0으로 마스킹 되어 있다. 전자 장치는 이진 마스크 에 기초하여, 관심 영역에 대응하는 영역의 픽셀들을 제외한 나머지 픽셀들을 제거함으로써, 관심 영역 이미지 를 획득할 수 있다. 일 실시예에서, 전자 장치가 관심 영역 이미지를 히트 맵 데이터에 기초하여 생성하면, 이진 마스크 의 값인 0 또는 1에 의해 관심 영역이 추출되므로, 관심 영역의 가장자리가 들쭉날쭉하고 거칠어서, 관심 영역 의 모양이 불규칙하고 고르지 않게 나타날 수 있다. 전자 장치는 관심 영역 이미지를 전자 장치 의 사용자에게 제공하기 이전에, 히트 맵 데이터의 이진 마스크에 가우시안 필터를 적용하여 관심 영역 이미지를 부드럽게 할 수 있다. 예를 들어, 전자 장치는 가우시안 필터를 이용하여 0과 1로 구성되는 히트 맵 이미지에 컨볼루션을 적용하고 주변 픽셀들 간의 가중 합을 계산할 수 있다. 전자 장치는 픽셀 강도를 임계값과 비교하여 임계 값 이상의 강도를 갖는 픽셀만을 선택하고, 그 외의 픽셀들은 선택하지 않을 수 있다. 임계 값은 기 설정된 값 일 수 있다. 예를 들어, 임계 값은 0.5일 수 있으나, 이에 한정되는 것은 아니다. 가우시안 필터를 적용하는 구체적인 알고리즘은 알려진 기술이므로, 구체적인 설명은 생략한다. 전자 장치는 가우시안 필터를 적용한 계산 결과를 관심 영역 이미지에 적용함으로써, 관심 영역의 가장자리를 부드럽게 하는 처리를 할 수 있다. 즉, 전자 장치는 관심 영역 이미지를 보다 보기 좋은 형태로 사용자에게 제공하기 위해, 관심 영역 이미지에 가우시안 필터를 적용하고, 가우시안 필터가 적용된 관심 영역 이미지를 사용자에게 제공할 수 있다. 한편, 관심 영역 이미지 및/또는 가우시안 필터가 적용된 관심 영역 이미지는, 전술한 실시예에 따라 왜곡 제거 처리가 적용된 왜곡 제거 이미지일 수 있다. 또는, 전자 장치는 왜곡 제거 처리 이전에 관심 영역 이미지 및/또는 가우시안 필터가 적용된 관심 영역 이미지를 획득하고, 왜곡 제거 처리를 적용 하여 관심 영역이 평면으로 수정된 왜곡 제거 이미지를 획득할 수 있다. 도 7a는 본 개시의 일 실시예에 따른 전자 장치가 객체의 3차원 모양을 추론하기 위해 사용하는 3차원 파라미터 를 설명하기 위한 도면이다. 도 7a에서 설명하는 3차원 파라미터는 객체의 3차원 특징을 나타내는 것으로, \"객체 모양 기반 3차원 파라 미터\"라고 지칭될 수 있다. 객체 3차원 파라미터는 도 11a에서 후술되는, 객체 표면의 관심 영역의 3차원 특징 을 나타내는 \"관심 영역 모양 기반 3차원 파라미터\"와 구별된다. 예를 들어, 객체 3차원 파라미터와 관심 영역 3차원 파라미터에 포함되는 피처들이 상이할 수 있다. 도 7a에 도시된 3차원 파라미터를 설명함에 있어서, 설명의 편의를 위해 객체의 3차원 모양 타입이 실린더 이고, 3차원 파라미터가 실린더 타입에 대응하는 피처들을 포함하는 경우를 예시로 들어 설명한다. 다만, 객체의 3차원 타입은 실린더에 한정되는 것은 아니다. 예를 들어, 객체의 3차원 모양 타입이 구인 경우, 3차원 파라미터는 구 타입에 대응하는 피처들을 포함할 수 있다. 일 실시예에서, 실린더 타입에 대응하는 3차원 파라미터의 피처들은 예를 들어, 실린더의 반지름 r, 실린 더의 높이 h, 3차원 공간상에서의 실린더의 회전 정보 R, 3차원 공간상에서의 실린더의 이동 정보 T, 카메라 파 라미터(예를 들어, 카메라의 초점거리 정보 F) 등을 포함할 수 있으나, 이에 한정되는 것은 아니다. 3차원 파라 미터에 포함되는 각각의 피처들은, 초기값이 설정되어 있을 수 있다. 일 실시예에서, 전자 장치는 3차원 파라미터의 피처들의 초기값에 기초하여, 가상 객체를 렌더 링할 수 있다. 이 경우, 3차원 파라미터가 실린더 타입에 대응하는 것이므로, 가상 객체의 3차원 모 양은 실린더 모양이다. 또한, 3차원 파라미터의 초기값(r, h, R, T, F)이 가상 객체의 3차원 정보로 설정 된다. 다시 말해, 가상 객체의 3차원 정보는, 가상 객체가 3차원 공간 상에서 반지름 r, 높이 h를 갖고, 회전 정보 R, 이동 정보 T를 가지며, 가상 객체에 대한 카메라 촬영을 가정하였을 때 초점 거리가 F임을 의미할 수 있다. 전자 장치는 가상 객체의 외곽선을 나타내는 가상 객체 키 포인트들을 설정할 수 있다. 가상 객체 키 포인트들은, 전자 장치가 현실 객체의 이미지를 촬영하여 검출하는 현실 객체 키 포인트들 과 구별된다. 본 개시에서, 별도의 '가상' 이라는 언급이 없는 한, 객체 키 포인트들이라는 단어는 현실 객체의 키 포인트들을 의미한다. 전자 장치는 가상 객체 키 포인트들 및 객체 키 포인트들을 이용하여, 3차원 파라미터의 초기 값들을 튜닝할 수 있다. 본 개시에서, 전자 장치가 3차원 파라미 터의 값들을 튜닝하는 과정은 \"3D 피팅 과정(또는, 3D 피팅 동작)\"이라고 지칭될 수 있다. 3D 피팅은, 알 고리즘 및/또는 인공지능 모델을 이용하여 수행될 수 있다. 전자 장치가 3D 피팅 과정을 완료하면, 3차원 파라미터의 최종 값들은 현실 객체의 원본 3차원 모양을 나타내도록 튜닝된다. 즉, 현실 객체의 3차원 정 보가 획득될 수 있다. 도 7b는 본 개시의 일 실시예에 따른 전자 장치가 객체 모양 기반으로 객체의 3차원 정보를 추론하는 동작을 설 명하기 위한 도면이다. 일 실시예에서, 전자 장치는 객체 3차원 정보 획득을 위해 3D 피팅 모델 및/또는 3D 피팅 알고 리즘을 이용할 수 있다. 객체 3차원 정보는, 객체의 3차원 왜곡(예를 들어, 곡면 왜곡 등)을 나타내 는 메시 데이터일 수 있으나 이에 한정되는 것은 아니다. 3D 피팅 모델 및/또는 3D 피팅 알고리즘은 객체 키 포인트들을 이용하여 3D 피팅을 수행할 수 있다. 3D 피팅이란, 도 7a에서 설명한 것과 같이, 3차 원 파라미터의 초기 값을 획득하고, 3차원 파라미터의 튜닝을 거쳐 객체의 원본 3차원 모양을 나타내는 3차원 파라미터를 획득하는 것을 말한다. 3D 피팅 모델은 인공지능 모델을 이용하여 구현될 수 있다. 일 실시예에서, 전자 장치는 3D 피팅을 수행할 때, 3D 피팅 알고리즘을 이용할 지 또는 3D 피팅 모 델을 이용할 지 여부를 결정할 수 있다. 예를 들어, 가볍고 빠른 연산이 필요한 경우, 전자 장치는 3D 피팅 알고리즘을 이용할 것으로 결정할 수 있다. 또는, 보다 많은 컴퓨팅 자원을 이용하여 정확한 연산 이 필요한 경우, 전자 장치는 3D 피팅 모델을 이용할 것으로 결정할 수 있다. 3D 피팅이 3D 피팅 알고리즘으로 구현되는 것은 도 8a 내지 도 8b에서 설명하고, 3D 피팅 모델이 인 공지능 모델로 구현되는 것은 도 9a 내지 도 9c에서 설명한다. 도 8a는 본 개시의 일 실시예에 따른 객체 모양 기반 3D 피팅 알고리즘을 설명하기 위한 도면이다. 일 실시예에서, 3D 피팅 알고리즘은 객체 키 포인트들을 입력 받아, 최적화 알고리즘을 적용하 고, 객체 3차원 파라미터를 출력할 수 있다. 예를 들어, 3D 피팅 알고리즘은 실린더 모양의 3차원 객 체의 외곽선을 나타내는 키 포인트들의 데이터를 입력 받을 수 있다. 이 경우, 3D 피팅 알고리즘은 객체의 원본 3차원 모양을 나타내는, 객체 3차원 파라미터를 출력할 수 있다. 구체적 예를 들면, 3D 피팅 알고리 즘은 실린더 모양을 갖는 객체의 반지름, 높이, 회전 벡터, 이동 벡터, 카메라 초점 거리 등을 포함하는 객체 3차원 파라미터를 출력할 수 있다. 일 실시예에서, 최적화 알고리즘은 객체 3차원 파라미터를 추론하기 위한 다양한 알고리즘이 이용되 는 것일 수 있다. 예를 들어, 함수의 최소값을 찾기 위한 최적화 알고리즘인 BFGS (Broyden-Fletcher- Goldfarb-Shanno), L-BFGS-B (Limited-Memory BFGS with Bounds), CG (Conjugate Gradient), Nelder-Mead, Powell 등이 이용될 수 있으나, 이에 한정되는 것은 아니다. 3D 피팅 알고리즘 및 최적화 알고리즘에 관하여, 도 8b를 참조하여 더 기술한다. 도 8b는 본 개시의 일 실시예에 따른 객체 모양 기반 3D 피팅 알고리즘을 설명하기 위한 도면이다. 일 실시예에서, 전자 장치는 기 설정된 초기 값을 갖는 초기 3차원 파라미터를 획득할 수 있다. 초 기 3차원 파라미터는 객체의 3차원 모양 타입에 대응할 수 있다. 예를 들어, 객체의 3차원 모양 타입이 실 린더인 경우, 3차원 파라미터의 피처들은, 실린더의 3차원 정보를 나타내기 위한 피처들로 구성된다. 전자 장치는 3차원 파라미터를 획득하기 이전에, 객체의 3차원 모양을 식별할 수 있다. 예를 들어, 전자 장치 는 사용자 입력에 기초하여 객체의 3차원 모양이 실린더임을 결정할 수 있다. 또는, 전자 장치는 객체 3차원 모양 분류 모델을 이용하여, 이미지 내 객체의 3차원 모양이 실린더임을 식별할 수 있다. 또는, 전 자 장치는 기 설정된 객체 인식 모드(예를 들어, 와인 병/와인 라벨 인식 모드)가 실행되는 것에 기초하 여, 객체의 3차원 모양이 실린더임을 결정할 수 있다. 전자 장치는 객체의 3차원 모양에 대응하고 기 설 정된 초기 값을 갖는, 초기 3차원 파라미터를 획득할 수 있다. 전자 장치는 초기값을 갖는 초기 3차원 파라미터를 이용하여 가상 객체를 생성할 수 있다. 여 기서 가상 객체는, 3차원 모양이 실린더 모양이고, 초기 3차원 파라미터의 반지름, 높이, 회전 벡터, 이동 벡터, 초점 거리를 3차원 정보로 갖는 객체이다. 전자 장치는 현실 객체의 원본 3차원 모양을 나타내는 3차원 파라미터를 추론하기 위하여, 초기 3차원 파 라미터의 값들을 업데이트할 수 있다. 전자 장치는 가상 객체를 2차원으로 투영하고, 가상 객 체의 외곽선을 나타내는 가상 객체 키 포인트들을 설정할 수 있다. 전자 장치는 가상 객체 키 포인트들이 객체 키 포인트들에 정합하도록 초기 3차원 파라미터의 값들을 변경할 수 있다. 객 체 키 포인트들은, 현실 객체를 촬영한 이미지로부터 획득될 수 있다. 전자 장치가 이미지 내 객체 의 외곽선을 나타내는 객체 키 포인트들을 획득하는 동작은 전술하였으므로, 간결함을 위해 반복되는 설명 은 생략한다. 전자 장치가 초기 3차원 파라미터의 값들을 변경할 때, 손실 함수가 이용될 수 있다. 손실 함수는 가상 객체 키 포인트들과 객체 키 포인트들의 차이를 최소화하도록 설정된 함수일 수 있다. 전자 장 치는 손실 함수에 기초하여 초기 3차원 파라미터를 변경하고, 업데이트된 3차원 파라미터를 획 득할 수 있다. 이 경우, 업데이트된 3차원 파라미터를 계산할 때, 최적화 알고리즘이 이용될 수 있다. 전자 장치는 전술한 3D 피팅 동작들을 반복할 수 있다. 예를 들어, 전자 장치는 전술한 3D 피팅 동 작들을 기 설정된 수 N회 만큼 반복함으로써, 3차원 파라미터가 객체의 원본 3차원 모양을 나타내도록 조정할 수 있다. 구체적으로, 전자 장치는 업데이트된 3차원 파라미터에 기초하여 가상 객체를 재생성 (업데이트)하고, 가상 객체의 키 포인트들과 객체 키 포인트들을 비교할 수 있다. 예를 들어, 전자 장치는 3차원 파라미터의 값들을 조정하여 업데이트 된 3차원 파라미터를 획득하고, 변경된 3 차원 정보를 갖는 가상 객체를 생성하고, 가상 객체 키 포인트들과 객체 키 포인트들의 차이가 최소화 되는 3차원 파라미터의 값들을 획득하도록 3차원 파라미터의 값들의 조정 작업을 반복할 수 있다. 3차원 파 라미터의 값들의 조정 작업이 반복됨에 따라, 초기 3차원 파라미터의 값들이 최종적으로는 객체의 3차원 모양을 나타내는 3차원 파라미터의 정답 값에 근사하도록 조정될 수 있다. 가상 객체 키 포인트들이 객체 키 포인트들에 정합되면, 이 때의 가상 객체의 3차원 파라미터의 값들은, 이미지 내의 객체의 3차원 정보를 나타내게 된다. 즉, 전자 장치는 3D 피팅 동작의 반복을 통해 이미지 내 객체의 3차원 정보를 나 타내는 3차원 파라미터를 최종적으로 획득할 수 있다. 도 9a는 본 개시의 일 실시예에 따른 객체 모양 기반 3D 피팅 모델을 설명하기 위한 도면이다. 일 실시예에서, 3D 피팅 모델은 인공지능 모델로 구현될 수 있다. 3D 피팅 모델은 객체 키 포인트들 을 입력 받아, 3차원 파라미터를 출력하도록 훈련된 인공지능 모델일 수 있다. 예를 들어, 3D 피팅 모델은 실린더 모양의 3차원 객체의 외곽선을 나타내는 키 포인트들의 데이터를 입력 받을 수 있다. 이 경 우, 3D 피팅 모델은 객체의 원본 3차원 모양을 나타내는, 객체 3차원 파라미터를 출력할 수 있다. 구 체적 예를 들면, 3D 피팅 모델은 실린더 모양을 갖는 객체의 반지름, 높이, 회전 벡터, 이동 벡터, 카메라 초점 거리 등을 포함하는 객체 3차원 파라미터를 출력할 수 있다. 3D 피팅 모델은 하나 이상의 선형 블록(linear block)을 포함할 수 있다. 각각의 선형 블록은 적어도 선형 레이어(linear layer), 배치 정규화 레이어(batch normalization layer), 활성화 함수 레이어 (activation function layer)(예를 들어, ReLU)를 포함할 수 있다. 선형 레이어는 완전 연결 레이어(fully connected layer)라고 지칭될 수도 있다. 선형 레이어는, 입력 피처들을 받아 가중치들과 바이어스들을 사용하 여 입력 피처들을 선형으로 결합하여 출력할 수 있다. 배치 정규화 레이어는 여러 입력값을 모은 배치에 대해, 각 레이어의 입력값의 평균과 표준편차를 다시 맞추어 줄 수 있다. 활성화 함수 레이어는 뉴런의 출력을 결정할 수 있다. 일 실시예에 따른 전자 장치는 3D 피팅 모델의 트레이닝 데이터에 기초하여 3D 피팅 모델을 훈 련시킬 수 있다. 이를 도 9b 및 도 9c를 참조하여 더 기술한다. 도 9b는 본 개시의 일 실시예에 따른 객체 모양 기반 3D 피팅 모델의 트레이닝 데이터 생성 방법을 설명하기 위 한 도면이다. 일 실시예에서, 전자 장치는 3D 피팅 모델을 훈련시키기 위한 트레이닝 데이터를 생성할 수 있 다. 전자 장치는 임의의 객체에 대한 객체의 3차원 모양을 나타내는 3차원 파라미터를 생성할 수 있다. 3차원 파라미터는 객체의 3차원 모양에 따라 상이한 피처들을 포함할 수 있다. 예를 들어, 전자 장치 는 임의의 실린더 타입의 3차원 모양을 나타내는 3차원 파라미터를 생성할 수 있으며, 이 경우, 3차 원 파라미터는 실린더 반지름, 실린더 높이, 회전 벡터, 이동 벡터 및 카메라 초점거리를 포함할 수 있다. 전자 장치는 임의의 객체에 대한 3차원 파라미터에 기초하여, 임의의 3차원 객체를 렌더링할 수 있 다. 예를 들어, 전자 장치는 3차원 파라미터에 포함되는 실린더 반지름, 실린더 높이, 회전 벡터, 이동 벡터 및 카메라 초점거리의 값들에 기초하여, 3차원 실린더 모양을 렌더링할 수 있다. 전자 장치는 생성된 3차원 객체의 외곽선을 나타내는, 객체 키 포인트들을 생성할 수 있다. 전자 장치가 임의의 객체를 가정하여 생성한 3차원 파라미터 및 임의의 객체의 외곽선을 나타내는 객체 키 포인트들은, 3D 피팅 모델을 훈련시키기 위한 트레이닝 데이터가 될 수 있다. 3D 피팅 모델의 트레이닝 데이터에는, 전자 장치가 생성한 트레이닝 데이터 및 전자 장치 가 획득한 트레이닝 데이터가 포함될 수 있다. 전자 장치가 획득한 트레이닝 데이터란, 특정 3차원 객체의 3차원 파라미터 및 객체 키 포인트들의 정답 값일 수 있다. 전자 장치는 트레이닝 데이터를 이용하여 3D 피팅 모델을 훈련시킬 수 있다. 3D 피팅 모델의 훈련 과정에 대해서, 도 9c를 참조하여 더 기 술한다. 도 9c는 본 개시의 일 실시예에 따른 전자 장치가 객체 모양 기반 3D 피팅 모델을 훈련시키는 동작을 설명하기 위한 도면이다. 도 9c를 참조하면, 전자 장치는 객체의 3차원 파라미터를 추론하도록 3D 피팅 모델을 훈련시킬 수 있다. 또한 도 9c에서, 정답 객체 키 포인트들 및 정답 3차원 파라미터는, 도 9b에서 설명한 동작에 의해 생성된 것일 수 있다. 이하에서 3D 피팅 모델의 개략적인 훈련 과정을 설명한다. 전자 장치는 3D 피팅 모델의 훈련 과정에서, 정답 객체 키 포인트들을 3D 피팅 모델에 입 력할 수 있다. 3D 피팅 모델은, 일련의 신경망 연산을 통해 객체 3차원 파라미터를 추론한 결과를 출 력한다. 3D 피팅 모델로부터 3차원 파라미터가 출력되면, 전자 장치는 추론된 3차원 파라미터에 기초하여 3차원 객체를 렌더링한다. 전자 장치는 3차원 객체를 2차원으로 투영하고, 3차원 객 체의 외곽선을 나타내는 객체 키 포인트들을 설정할 수 있다. 전자 장치는 손실 함수에 기초하여 3D 피팅 모델의 가중치들을 업데이트할 수 있다. 전자 장치 는 추론된 3차원 파라미터와 정답 3차원 파라미터의 오차를 계산하는 손실 함수에 기초하여 3D 피팅 모델을 업데이트할 수 있다. 또한, 전자 장치는 추론된 3차원 파라미터에 기초하여 생성 된 객체 키 포인트들과 정답 객체 키 포인트들의 오차를 계산하는 손실 함수에 기초하여 3D 피팅 모 델을 업데이트할 수 있다. 전술한 훈련 동작들은 기 설정된 횟수만큼 반복되거나, 손실 함수로부터 계산되 는 오차율이 기 설정된 값을 충족할 때까지 반복될 수 있다. 전자 장치가 3D 피팅 모델의 훈련 과정을 완료하면, 전자 장치는 3D 피팅 모델을 이용하 여 객체의 3차원 정보를 추론할 수 있다. 즉, 전자 장치는 객체 키 포인트들을 3D 피팅 모델에 입력 하고, 객체의 원본 3차원 모양을 나타내는 3차원 파라미터를 획득할 수 있다. 도 10a는 본 개시의 일 실시예에 따른 전자 장치가 이미지를 처리하는 과정을 설명하기 위한 도면이다. 도 10a를 참조하면, 전자 장치가 객체 이미지를 이용하여 일련의 이미지 처리 동작들을 수행함에 따라 산출되는 데이터들을 도시한 것이다. 전자 장치는 입력 이미지 내 객체의 외곽선을 나타내는 객체 키 포인트 데이터를 검출할 수 있다. 전자 장치는 객체 검출 모델을 이용하여 객체 키 포인트 데이터를 획득할 수 있다. 전자 장 치가 객체 키 포인트 데이터를 검출하는 것에 대한 설명은 전술하였으므로, 간결함을 위해 반복되 는 설명은 생략한다. 전자 장치는 입력 이미지 내 객체의 표면의 관심 영역 데이터를 검출할 수 있다. 전자 장치 는 관심 영역 검출 모델을 이용하여 관심 영역 데이터를 획득할 수 있다. 전자 장치가 관심 영역 데이터를 검출하는 것에 대한 설명은 전술하였으므로, 간결함을 위해 반복되는 설명은 생략한다. 전자 장치는 입력 이미지 내 객체의 3차원 정보를 획득할 수 있다. 객체의 3차원 정보(104 0)는 객체의 3차원 모양을 나타내는 메시 데이터일 수 있으나 이에 한정되는 것은 아니다. 객체의 3차원 정보 는 3차원 파라미터에 기초하여 획득될 수 있다. 전자 장치는 3D 피팅 모델을 이용하여 객체의 원본 3차원 모양을 나타내는 3차원 파라미터를 획득할 수 있다. 전자 장치가 객체의 3차원 정보를 획득 하는 것에 대한 설명은 전술하였으므로, 간결함을 위해 반복되는 설명은 생략한다. 전자 장치는 입력 이미지, 객체 키 포인트 데이터, 관심 영역 데이터 및 객체 3차원 정보의 적어도 일부를 이용하여, 왜곡 제거 이미지를 획득할 수 있다. 왜곡 제거 이미지는, 객체의 표면의 관심 영역이 평면으로 수정된 이미지일 수 있다. 전자 장치는 객체 3차원 정보를 기 초로, 입력 이미지 원근 변환을 적용하여 이미지 내 객체 표면의 관심 영역이 평면으로 수정된, 왜곡 제 거 이미지를 획득할 수 있다. 도 10b는 본 개시의 일 실시예에 따른 전자 장치가 왜곡 제거 이미지로부터 정보를 추출한 예시를 설명하기 위 한 도면이다. 도 10b를 참조하면, 원본 이미지, 잘라낸 이미지, 및 왜곡 제거 이미지가 도시되어 있다. 일 실시예에서, 전자 장치는 정보 검출 모델을 이용하여 이미지 내 존재하는 정보를 추출할 수 있다. 전 자 장치는 왜곡 제거 이미지를 획득하면, 일반적인 정보 검출 모델을 이용하여 관심 영역 내 정보 를 검출할 수 있다. 즉, 전자 장치는 왜곡된 이미지 내에서 정보를 추출하기 위해 이미지 내의 왜곡을 반 영하여 별도로 검출 모델을 훈련시키지 않더라도, 왜곡 제거 이미지를 생성하고, 왜곡 제거 이미지(105 0)에 일반적인 검출 모델을 적용할 수 있다. 이에 따라, 전자 장치는 별도로 정보 검출 모델을 훈련/업데 이트하기 위한 컴퓨팅 자원을 절약할 수 있다.예를 들어, 전자 장치는 OCR 모델을 이용하여, 이미지 내 존재하는 텍스트들을 검출할 수 있다. 이하에서, 전자 장치가 OCR 모델을 이용하여 이미지로부터 텍스트를 추출하는 것을 예시로 설명한다. 일 실시예에서, 원본 이미지는 전자 장치가 카메라를 이용하여 획득한 원시 이미지(raw image)이다. 원본 이미지는 객체의 3차원 모양으로 인한 관심 영역의 왜곡이 포함될 수 있으며, 이미지 내에 관심 영역 외에 다른 여백 공간들이 더 포함될 수 있다. 즉, 관심 영역 외 노이즈 픽셀들이 포함될 수 있 다. 전자 장치가 원본 이미지에 대하여 OCR을 적용한다면, 전술한 원본 이미지의 특징들로 인하여, 관심 영역 내 텍스트들 중 적어도 일부가 미인식되거나, 오인식 될 수 있다. 예를 들어, 원본 이미지 내에서, 텍스트의 검출 영역은 사각 박스로 표시되어 있으며, 텍스트가 검출된 영역들 중에서 검출 영역 내 검출 텍스트가 오인식된 것은 빗금친 화살표로 표시(오인식된 경우)되어 있다. 또한, 텍스트가 있으나 검출 영역으로 식별되지 않은 것은 검은 화살표로 표시(미인식된 경우)되어 있다. 보다 구체적인 예시로, 관심 영역 내에서 검출해야하는 텍스트 블록의 수가 14개일 때, 원본 이미지에 대하여 OCR을 적용한 결과(즉, 원본 이미지로부터 검출된 텍스트를 참조하면), 검출된 텍스트 블록은 8개이며, 이 중 적어도 일부는 텍 스트 검출 결과가 정확하지 않을 수 있다. 보다 명확한 이해를 돕기 위해, 원본 이미지로부터 검출된 텍스트를 참조하여, 본 개시에서 예시적 으로 설명하는 미인식된 경우 및 오인식된 경우를 더 설명하고, 잘라낸 이미지 및 왜곡 제거 이미지 로부터 정보를 추출한 예시적인 결과를 설명한다. 일 실시예에서, OCR 모델은 이미지 내에서 텍스트를 검출하고, 검출된 텍스트를 인식하며, 인식한 결과를 신뢰 도가 소정 임계값(예를 들어, 0.5) 이상인 것에 기초하여 인식 결과를 출력할 수 있다. 본 개시의 예시들에서 \"미인식된 경우\"란 이미지에 대하여 텍스트 검출 및 인식을 수행하였음에도 불구하고, 이 미지로부터 텍스트 검출 및 인식 결과가 출력되지 않은 것을 의미할 수 있다. 예를 들어, 미인식된 경우란, 1) 텍스트가 검출되지 않은 경우, 2) 텍스트가 검출되고 텍스트 인식이 수행되었으나, 인식 결과의 신뢰도가 소정 임계값(예를 들어, 0.5) 미만이어서 인식 결과가 출력되지 않은 경우를 포함할 수 있다. 본 개시의 예시들에서, \"인식된 경우\"란 텍스트가 검출되고 텍스트 인식이 수행되었으며, 인식 결과의 신뢰도가 소정 임계값(예를 들어, 0.5) 이상이어서 인식 결과가 출력된 것을 포함할 수 있다. 여기서, \"인식된 경우\"는 \"잘 인식된 경우\"와 \"오인식된 경우\"로 구별될 수 있다. 본 개시의 예시들에서 \"잘 인식된 경우\"와 \"오인식된 경우\"는 상대적인 개념으로써 사용될 수 있다. 예를 들어, \"오인식된 경우\"란, 인식된 결과의 신뢰도가 낮은 경 우(예를 들어, 신뢰도 0.5 이상 0.8 미만)를 의미할 수 있으며, \"잘 인식된 경우\"란, 인식된 결과의 신뢰도가 \"오인식된 경우\"보다 상대적으로 높은 경우(예를 들어, 신뢰도 0.8 이상)를 의미할 수 있다. 이에 따라, \"오인 식된 경우\"에 해당하는 텍스트 인식 결과들은, 인식 결과가 출력되었으나 실제 텍스트의 정확한 인식 결과가 아 닐 수 있다. 예를 들어, 원본 이미지로부터 검출된 텍스트의 인식 결과들 중에서 두번째 인식 텍스 트를 나타내는, '2: \"A *^\"mfr~ y*D' 는 인식 결과의 신뢰도가 0.598 이므로 상대적으로 낮은 값이고, 인식 결 과 또한 부정확한 텍스트이므로, \"오인식된 경우\"로 지칭될 수 있다. 마찬가지의 예시로, 원본 이미지로 부터 검출된 텍스트의 인식 결과들 중에서 첫번째 인식 텍스트를 나타내는 '1: ELEVE'는 인식 결과의 신 뢰도가 0.888이므로 상대적으로 높은 값이고, 인식 결과 또한 정확한 텍스트이므로 \"잘 인식된 경우\"로 지칭될 수 있다. 한편, OCR 모델에 의해 텍스트를 검출/인식한 결과의 신뢰도가 높더라도, 이미지 자체의 왜곡으로 인해 텍스트 검출/인식의 결과가 정확하지 않을 수 있다. 예를 들어, 원본 이미지로부터 검출된 텍스트의 인식 결과들 중에서 세번째 인식 텍스트를 나타내는 '3: pour cette cuv6e'는 인식 결과의 신뢰도가 0.960이지만, 실 제 정확한 텍스트는 'pour cette cuvee'이다. 이는, 원본 이미지 자체에 존재하는 곡면 왜곡으로 인해 발 생하는 것으로, 별도로 왜곡에 관련된 특징들을 학습한 것이 아닌 일반적인 OCR 모델을 이용함으로 인한 것일 수 있다. 일 실시예에 따른 전자 장치는 왜곡 제거 이미지를 생성하고, 왜곡 제거 이미지에 대하여 OCR을 수행하므로, 일반적인 OCR 모델을 이용하더라도 정확한 텍스트가 검출되도록 할 수 있다. 이하에서, 서로 다른 특징을 갖는 이미지들인 잘라낸 이미지 및 왜곡 제거 이미지에 대하여, 일반 적인 OCR 모델을 이용하여 텍스트를 검출하는 예시를 더 설명할 것이다. 전술한 미인식/오인식에 관련된 설명은, 후술되는 잘라낸 이미지로부터 검출된 텍스트 왜곡 제거 이미지로부터 검출된 텍스 트에도 동일하게 적용될 수 있다. 일 실시예에서, 잘라낸 이미지는 원본 이미지로부터 관심 영역을 검출하고, 관심 영역만을 잘라낸 이미지이다. 잘라낸 이미지는 객체의 3차원 모양으로 인한 관심 영역의 왜곡이 포함될 수 있다. 전자 장 치가 잘라낸 이미지에 대하여 OCR을 적용한다면, 전술한 잘라낸 이미지의 특징으로 인하여, 관심 영역 내 텍스트들 중 적어도 일부가 미인식되거나, 오인식될 수 있다. 구체적인 예시로, 관심 영역 내에서 검출해야하는 텍스트 블록의 수가 14개일 때, 잘라낸 이미지에 대하여 OCR을 적용한 결과(즉, 잘라낸 이 미지로부터 검출된 텍스트를 참조하면), 검출된 텍스트 블록은 9개이며, 이 중 적어도 일부는 텍스 트 검출 결과가 정확하지 않을 수 있다. 일 실시예에서, 왜곡 제거 이미지는 전술한 실시예에 따라, 전자 장치가 객체의 3차원 정보를 나타 내는 3차원 파라미터 값들을 추론하고, 3차원 파라미터 값들에 기초하여 원근 변환을 수행한 이미지이다. 왜곡 제거 이미지는 3차원 정보에 기초하여 정밀하게 2차원으로 원근 변환된 이미지이므로, 전자 장치는 보다 정확한 텍스트 검출 결과를 획득할 수 있다. 전자 장치가 왜곡 제거 이미지에 대하여 OCR을 적용한다면, 관심 영역 내 텍스트들이 정확하게 검출될 수 있다. 구체적인 예시로, 관심 영역 내에서 검출해야 하는 텍스트 블록의 수가 14개일 때, 왜곡 제거 이미지에 대하여 OCR을 적용한 결과(즉, 왜곡 제거 이미 지로부터 검출된 텍스트를 참조하면), 검출된 텍스트 블록은 14개이며, 정확한 텍스트 검출 결과가 획득될 수 있다. 한편, 전술한 검출해야 하는 텍스트 블록의 수, 미인식된 텍스트 블록들, 오인식된 텍스트 블록들은 설명의 편 의를 위한 예시일 뿐, 텍스트 인식 결과를 단정하기 위한 것은 아니다. 즉, 원본 이미지 및 잘라낸 이미 지에 대하여 텍스트를 검출한 결과보다, 왜곡 제거 이미지에 대하여 텍스트를 검출한 결과가 상대 적으로 정확도가 높다는 것을 설명하고자 하는 것임이 이해되어야 할 것이다. 도 11a는 본 개시의 일 실시예에 따른 전자 장치가 관심 영역의 3차원 모양을 추론하기 위해 사용하는 3차원 파 라미터를 설명하기 위한 도면이다. 도 11a에 도시된 3차원 파라미터를 설명함에 있어서, 설명의 편의를 위해 객체의 3차원 모양 타입이 실린 더이고, 3차원 파라미터가 실린더 타입에 대응하는 피처들을 포함하는 경우를 예시로 들어 설명한다. 다 만, 객체의 3차원 타입은 실린더에 한정되는 것은 아니다. 예를 들어, 객체의 3차원 모양 타입이 구인 경우, 3 차원 파라미터는 구 타입에 대응하는 피처들을 포함할 수 있다. 또한, 도 11a에 도시된 3차원 파라미터는, 도 7a에 도시된 3차원 파라미터와 구별될 수 있다. 예를 들어, 도 7a의 3차원 파라미터는 \"객체 모양 기반 3차원 파라미터\"로 지칭될 수 있고, 도 11a의 3차원 파 라미터는 \"관심 영역 모양 기반 3차원 파라미터\"로 지칭될 수 있다. 또는, 도 7a의 3차원 파라미터 가 \"제1 3차원 파라미터\", 도 11a의 3차원 파라미터가 \"제2 3차원 파라미터\"로 지칭될 수도 있다. 다만, 객체의 원본 3차원 모양을 추론하기 위해 사용된다는 점은 유사하므로, 이하에서는 단순히 3차원 파라미터 라고 지칭될 것이다. 일 실시예에서, 실린더 타입에 대응하는 3차원 파라미터의 피처들은 예를 들어, 실린더의 반지름 r, 3차 원 공간상에서의 실린더의 회전 정보 R, 3차원 공간상에서의 실린더의 이동 정보 T, 카메라 파라미터(예를 들어, 카메라의 초점거리 정보 F) 등을 포함할 수 있다. 또한, 3차원 파라미터의 피처들은 관심 영역과 관련된 피처인, 실린더 표면의 관심 영역의 높이 h, 실린더 표면에서 관심 영역(예를 들어, 상품의 라벨 등)이 차지하는 각도 θ 등을 포함할 수 있으나, 이에 한정되는 것은 아니다. 3차원 파라미터에 포함되는 각각 의 피처들은, 초기값이 설정되어 있을 수 있다. 일 실시예에서, 전자 장치는 3차원 파라미터의 피처들의 초기값에 기초하여, 가상 객체를 렌 더링할 수 있다. 이 경우, 3차원 파라미터가 실린더 타입에 대응하는 것이므로, 가상 객체의 3차원 모양은 실린더 모양이다. 또한, 가상 객체의 3차원 정보는 3차원 파라미터의 초기값(r, R, T, h, θ, F)으로 설 정된다. 즉, 가상 객체의 반지름이 r이고, 가상 객체 표면의 관심 영역의 높이는 h이고, 가상 객체 표면에서 관심 영역이 차지하는 각도는 θ로 설정된다. 전자 장치는 가상 객체의 표면의 관심 영역의 외곽선을 나타내는 가상 객체의 관심 영역 키 포인트 들을 설정할 수 있다. 가상 객체의 관심 영역 키 포인트들은, 전자 장치가 현실 객체의 이미 지를 촬영하여 검출하는 현실 객체 관심 영역 키 포인트들과 구별된다. 본 개시에서, 별도의 '가상' 이라 는 언급이 없는 한, 객체의 관심 영역 키 포인트들이라는 단어는 현실 객체의 관심 영역 키 포인트들을 의미한 다. 현실 객체의 관심 영역 키 포인트들은, 관심 영역의 키 포인트들을 검출하기 위한 별도의 인공지능 모델에 의해 획득되거나, 전술한 관심 영역 검출 모델로부터 획득되는 히트 맵 이미지에 기초하여 획득할 수 있다. 전자 장치는 가상 객체의 관심 영역 키 포인트들 및 객체의 관심 영역 키 포인트들을 이용하여, 3차원 파라미터의 초기 값들을 튜닝할 수 있다. 전자 장치가 3차원 파라미터의 값 들을 튜닝하는 과정은 3D 피팅 과정이라고 지칭될 수 있다. 이를 도 11b 내지 도 11c를 참조하여 더 기술한다. 도 11b는 본 개시의 일 실시예에 따른 전자 장치가 관심 영역 모양 기반으로 객체의 3차원 정보를 추론하는 동 작을 설명하기 위한 도면이다. 일 실시예에서, 전자 장치는 객체 3차원 정보 획득을 위해 3D 피팅 모델 및/또는 3D 피팅 알 고리즘을 이용할 수 있다. 도 11b에 도시된 3D 피팅 모델 및 3D 피팅 알고리즘은, 도 7b에 도시된 3D 피팅 모델 및 3D 피팅 알고리즘과 구별될 수 있다. 예를 들어, 도 7b의 3D 피팅 모델/3D 피팅 알고리즘은 객체 키 포인트들을 이용하는 것이므로 \"객체 모양 기반 3D 피팅 모델/객체 모양 기반 3D 피팅 알고리즘\"으로 지칭될 수 있고, 도 11b의 3D 피팅 모델은 관심 영역 키 포인트들을 이용하는 것이므로 \"관심 영역 모양 기반 3D 피팅 모델/관심 영역 모양 기반 3D 피팅 알고리즘\"으로 지칭될 수 있다. 또는, 도 7b의 3D 피팅 모델/3D 피팅 알고리즘과 도 11b의 3D 피팅 모델/3D 피팅 알고리즘이 각각 \"제1 3D 피팅 모델/제1 3D 피팅 알고리즘\" 및 \"제2 3D 피팅 모델/제2 3D 피팅 알고리즘\"으로 지칭될 수도 있다. 다만, 객체의 원본 3차원 모양을 추론하기 위해 3D 피팅을 수행한다는 점은 유사하므로, 이하에서는 단순히 3D 피팅 모델이라고 지 칭될 것이다. 일 실시예에서, 전자 장치는 객체 3차원 정보 획득을 위해 3D 피팅 모델 및/또는 3D 피팅 알 고리즘을 이용할 수 있다. 객체 3차원 정보는, 객체의 관심 영역의 3차원 왜곡(예를 들어, 곡면 왜 곡 등)을 나타내는 메시 데이터일 수 있으나 이에 한정되는 것은 아니다. 3D 피팅 모델 및/또는 3D 피팅 알고리즘은 객체의 관심 영역 키 포인트들을 이용하여 3D 피팅을 수행할 수 있다. 일 실시예에서, 전자 장치는 3D 피팅을 수행할 때, 3D 피팅 알고리즘을 이용할 지 또는 3D 피팅 모 델을 이용할 지 여부를 결정할 수 있다. 예를 들어, 가볍고 빠른 연산이 필요한 경우, 전자 장치는 3D 피팅 알고리즘을 이용할 것으로 결정할 수 있다. 또는, 보다 많은 컴퓨팅 자원을 이용하여 정확한 연 산이 필요한 경우, 전자 장치는 3D 피팅 모델을 이용할 것으로 결정할 수 있다. 한편, 전자 장치는 3D 피팅을 수행할 때, 객체 기반 3D 피팅을 수행할 지 또는 관심 영역 기반 3D 피팅을 수행할 지를 결정할 수 있다. 이는 관심 영역의 모양이 정형화된 디자인인지 비정형화된 디자인인지 여부에 기 초하여 결정될 수 있다. 또한, 3D 피팅이 3D 피팅 알고리즘으로 구현되는 것은 도 11c에서 설명하고, 3D 피팅 모델이 인공지능 모델로 구현되는 것은 도 11d에서 설명한다. 도 11c는 본 개시의 일 실시예에 따른 관심 영역 모양 기반 3D 피팅 알고리즘을 설명하기 위한 도면이다. 전자 장치는 초기값을 갖는 초기 3차원 파라미터를 이용하여 가상 객체를 생성할 수 있다. 여기서, 가상 객체는, 3차원 모양이 실린더 모양이고, 초기 3차원 파라미터의 반지름, 회전 벡터, 이동 벡터, 관심 영역 각도, 관심 영역 높이, 카메라 초점 거리를 3차원 정보로 갖는 객체이다. 전자 장치는 현실 객체의 원본 3차원 모양을 나타내는 3차원 파라미터를 추론하기 위하여, 초기 3차원 파 라미터의 값들을 업데이트할 수 있다. 전자 장치는 가상 객체를 2차원으로 투영하고, 가상 객체의 관심 영역의 외곽선을 나타내는, 가상 객체의 관심 영역 키 포인트들을 설정할 수 있다. 전 자 장치는 가상 객체의 관심 영역 키 포인트들이 객체의 관심 영역 키 포인트들에 정합하도 록 초기 3차원 파라미터의 값들을 변경할 수 있다. 한편, 도 11c에 도시된 관심 영역 키 포인트들 기반 3D 피팅은, 3차원 파라미터가 관심 영역과 관련된 피처들을 포함하고, 3D 관심 영역 키 포인트들을 이용한다는 점만 상이할 뿐, 일반적인 동작들은 도 8b에 도시된 객체 키 포인트들 기반 3D 피팅과 동일/유사하다. 따라서, 반복되는 설명은 생략한다. 도 11d는 본 개시의 일 실시예에 따른 전자 장치가 관심 영역 모양 기반 3D 피팅 모델을 훈련시키는 동작을 설 명하기 위한 도면이다. 도 11d를 참조하면, 전자 장치는 객체의 3차원 파라미터를 추론하도록 3D 피팅 모델을 훈련 시킬 수 있다. 전자 장치는 3D 피팅 모델의 훈련 과정에서, 정답 관심 영역 키 포인트들을 3D 피팅 모델에 입력할 수 있다. 3D 피팅 모델은, 일련의 신경망 연산을 통해 객체 3차원 파라미터 를 추론한 결과를 출력한다. 이 경우, 3차원 파라미터에는 관심 영역과 관련된 피처(예를 들어, 객체 표면에서 관심 영역이 차지하는 각도, 관심 영역의 높이 등)를 포함할 수 있다. 3D 피팅 모델로부터 3차원 파라미터가 출력되면, 전자 장치는 추론된 3차원 파라미터 에 기초하여 3차원 객체를 렌더링한다. 이 경우, 3차원 객체에는 3차원 파라미터에 기초하여 결정된 관심 영역이 포함될 수 있다. 전자 장치는 3차원 객체를 2차원으로 투영하고, 3차원 객체 표면의 관심 영역의 외곽선을 나타내는 관심 영역 키 포인트들을 설정할 수 있다. 전자 장치는 손실 함수에 기초하여 3D 피팅 모델의 가중치들을 업데이트할 수 있다. 전자 장치 는 추론된 3차원 파라미터와 정답 3차원 파라미터의 오차를 계산하는 손실 함수에 기초하여 3D 피팅 모델을 업데이트할 수 있다. 또한, 전자 장치는 추론된 3차원 파라미터에 기초하여 생성된 관심 영역 키 포인트들과 정답 관심 영역 키 포인트들의 오차를 계산하는 손실 함수에 기초 하여 3D 피팅 모델을 업데이트할 수 있다. 전술한 훈련 동작들은, 기 설정된 횟수만큼 반복되거나, 손실 함수로부터 계산되는 오차율이 기 설정된 값을 충족할 때까지 반복될 수 있다. 전자 장치가 3D 피팅 모델의 훈련 과정을 완료하면, 전자 장치는 3D 피팅 모델을 이용 하여 객체의 3차원 정보를 추론할 수 있다. 즉, 전자 장치는 객체의 관심 영역 키 포인트들을 3D 피팅 모 델에 입력하고, 객체의 원본 3차원 모양을 나타내는 3차원 파라미터를 획득할 수 있다. 도 12는 본 개시의 일 실시예에 따른 객체 특징 추출 모델을 설명하기 위한 도면이다. 일 실시예에서, 전자 장치는 객체 특징 추출 모델을 이용할 수 있다. 객체 특징 추출 모델은, 객체 이미지를 입력 받아, 이전의 도면들에서 전술했던, 관심 영역 키 포인트들, 객 체 키 포인트들, 및 관심 영역 히트 맵을 출력하도록 훈련된 모델일 수 있다. 즉, 도 5a의 객체 검 출 모델 및 도 6a의 관심 영역 검출 모델등의 기능이 통합되어 하나의 모델인 객체 특징 추출 모델 로 구현될 수 있다. 객체 특징 추출 모델은 백본 네트워크를 포함할 수 있다. 백본 네트워크는 미리-훈련된(pre- trained) 네트워크일 수 있으며, 객체 이미지를 입력 받아 피처맵을 출력할 수 있다. 백본 네트워크 는 객체 이미지로부터 특징 추출을 위한 알려진 신경망(예를 들어, ResNet50)의 아키텍처가 사용될 수 있다. 또는 백본 네트워크는 경량화된 신경망(예를 들어, MobileNetV2; MV2)의 아키텍처가 사용될 수 있다. 객체 특징 추출 모델은 관심 영역 키 포인트 헤드를 포함할 수 있다. 관심 영역 키 포인트 헤드 는 백본 네트워크로부터 출력되는 피처맵을 받아 관심 영역을 나타내는, 관심 영역 키 포인트들 을 출력하기 위한 신경망 레이어들로 구성되는 블록일 수 있다. 객체 특징 추출 모델은 객체 키 포인트 헤드를 포함할 수 있다. 객체 키 포인트 헤드는 백본 네트워크로부터 출력되는 피처맵을 받아 객체 외곽선을 나타내는 객체 키 포인트들을 출력하기 위 한 신경망 레이어들로 구성되는 블록일 수 있다. 객체 특징 추출 모델은 관심 영역 히트 맵 헤드를 포함할 수 있다. 관심 영역 히트 맵 헤드 는 백본 네트워크로부터 출력되는 피처맵을 받아 관심 영역을 나타내는 히트 맵을 출력하기 위한 신경망 레이어들로 구성되는 블록일 수 있다. 관심 영역 키 포인트 헤드, 객체 키 포인트 헤드 및 관심 영역 히트 맵 헤드 각각은, 2차원 의 컨볼루션 연산 수행이 가능한, 컨볼루션 블록을 포함할 수 있다. 컨볼루션 블록은 적어도, 컨볼 루션 레이어, 배치 정규화 레이어, 활성화 함수 레이어를 포함할 수 있다. 일 실시예에서, 전자 장치는 객체 특징 검출 모델을 이용하여, 관심 영역 키 포인트들, 객체 키 포인트들 및 관심 영역 히트 맵을 획득할 수 있다. 전자 장치는 관심 영역 키 포인트들 , 객체 키 포인트들 및 관심 영역 히트 맵 중 적어도 일부에 기초하여, 객체의 3차원 정보를 추론하고, 객체의 3차원 왜곡을 제거하여 평면으로 수정된, 왜곡 제거 이미지를 획득할 수 있다. 한편, 도 3의 단계 S320 및 단계 S330은 객체 특징 검출 모델에 의하여 통합되어 수행될 수도 있다. 도 13a는 본 개시의 일 실시예에 따른 전자 장치가 3차원 파라미터를 추론하기 위해 이용할 데이터를 결정하는 동작을 설명하기 위한 흐름도이다. 단계 S1310은 도 3의 단계 S320이 수행된 이후에 수행될 수 있다. 단계 S1310에서, 전자 장치는 관심 영역의 모양을 식별한다. 전자 장치는 관심 영역 키 포인트들 및 관심 영역 히트 맵 중 적어도 하나에 기초하여, 관심 영역의 모양을 식별할 수 있다. 일 실시예에서, 관심 영역의 모양에 따라 전자 장치가 3차원 왜곡을 제거하기에 적합한 알고리즘이 상이 할 수 있다. 예를 들어, 관심 영역의 모양이 정형화된 디자인에 포함되는 경우, 관심 영역을 기반으로 3차원 정 보를 추론하는 것이 적합하고, 관심 영역의 모양이 비정형화된 디자인인 경우, 객체 자체의 모양을 기반으로 3 차원 정보를 추론하는 것이 적합할 수 있다. 따라서, 전자 장치는 식별된 관심 영역의 모양이 정형화된 디자인에 포함되는지 여부를 식별할 수 있다. 정형화된 디자인이란, 전자 장치에 기 저장되어 있는 디자 인으로, 예를 들어, 정사각형, 직사각형 등일 수 있으나, 이에 한정되는 것은 아니다. 전자 장치는 관심 영역의 모양이 정형화된 디자인에 포함되는 경우, 단계 S1320을 수행하고, 관심 영역의 모양이 비정형화된 디자 인에 포함되는 경우, 단계 S1330을 수행할 수 있다. 단계 S1320에서, 전자 장치는 관심 영역 모양을 기반으로 3차원 파라미터를 추론한다. 전자 장치는 관심 영역의 모양이 정형화된 디자인에 포함되는 것에 기초하여, 관심 영역의 외곽선을 나타내는 관심 영역 키 포인트들을 획득할 수 있다. 관심 영역 키 포인트들은 전자 장치의 이전의 동작(단계 S320) 중에서 이미 검출되어 있을 수 있다. 또는, 이전의 동작(단계 S320) 중에서 관심 영역의 히트 맵 만이 검출된 경우, 전자 장 치는 별도로 관심 영역의 키 포인트들을 검출할 수 있다. 단계 S1320은 도 3의 단계 S330 내지 단계 S340 을 대체할 수 있다. 따라서, 단계 S1320 이후에 도 3의 단계 S350이 수행될 수 있다. 전자 장치가 관심 영역 키 포인트들을 이용하여 객체 3차원 파라미터를 추론하는 동작은 도 11a 내지 도 11d에서 전술하였으므로, 간결함을 위해 반복되는 설명은 생략한다. 단계 S1330에서, 전자 장치는 객체 모양을 기반으로 3차원 파라미터를 추론한다. 전자 장치는 관심 영역의 모양이 비정형화된 디자인인 것에 기초하여, 객체 키 포인트들을 검출할 수 있다. 단계 S1330은 도 3의 단계 S330 내지 단계 S340을 대체할 수 있다. 따라서, 단계 S1330 이후에 도 3의 단계 S350이 수행될 수 있다. 전자 장치가 객체 키 포인트들을 이용하여 객체 3차원 파라미터를 추론하는 동작은 도 8a 내지 도 9c에서 전술하였으므로, 간결함을 위해 반복되는 설명은 생략한다. 도 13b는 본 개시의 일 실시예에 따른 전자 장치가 관심 영역의 모양에 기초하여 이미지를 처리하는 동작을 설 명하기 위한 도면이다. 도 13b 내지 도 13c를 설명함에 있어서, 객체가 와인 병이고, 관심 영역이 와인 라벨이며, 정형화된 관심 영역 의 모양은 직사각형으로 설정되어 있는, 구체적 예시를 들어 설명한다. 다만, 이는 일반화 가능한 개념을 설명 의 편의를 위해 구체적인 예시를 이용하는 것일 뿐, 특정 실시예를 한정하기 위한 것은 아니다. 도 13b를 참조하면, 전자 장치는 객체 이미지를 객체 특징 검출 모델에 입력할 수 있다. 객 체 특징 검출 모델은 도 12에서 전술하였으므로, 반복되는 설명은 생략한다. 객체 특징 검출 모델 은 관심 영역 키 포인트들, 객체 키 포인트들, 관심 영역 히트 맵을 출력할 수 있다. 관심 영역 키 포인트들은 정형화된 디자인(예를 들어, 직사각형)을 위한 관심 영역 추출기(이하, 제1 관 심 영역 추출기)에 제공될 수 있다. 객체 키 포인트들 및 관심 영역 히트 맵은 비정형화된 디자인 (예를 들어, 비 직사각형)을 위한 관심 영역 추출기(이하, 제2 관심 영역 추출기)로 제공될 수 있다. 제1 관심 영역 추출기는 관심 영역 키 포인트들에 기초하여, 관심 영역을 디워핑한다. 제1 관심 영 역 추출기는 관심 영역 3D 피팅 모델을 포함할 수 있다. 관심 영역 3D 피팅 모델은 관심 영역 및 객체와 관련된 3차원 파라미터를 추론할 수 있다. 이는, 도 11a 내지 도 11d에서 전술하였으므로, 간결함을 위해 반복되는 설명은 생략한다. 이하에서, 제1 관심 영역 추출기의 동작은 \"관심 영역 모양 기반 왜곡 제거 알고리즘\"으로 지칭될 수 있다. 제1 관심 영역 추출기는 추론된 3차원 파라미터에 기초하여 관심 영역의 3차원 정보(예를 들어, 관심 영 역 메시)를 획득하고, 관심 영역을 디워핑함으로써, 디워핑된 관심 영역을 나타내는, 제1 왜곡 제거 이미 지를 생성할 수 있다. 제2 관심 영역 추출기는 객체 키 포인트들 및 관심 영역 히트 맵 중 적어도 하나에 기초하여, 관심 영역을 디워핑한다. 제2 관심 영역 추출기는 객체 3D 피팅 모델을 포함할 수 있다. 객체 3D 피팅 모델은 객체와 관련된 3차원 파라미터를 추론할 수 있다. 이는, 도 8a 도 9c에서 전술하였으므로, 간결함을 위해 반복되는 설명은 생략한다. 이하에서, 제2 관심 영역 추출기의 동작은 \" 객체 모양 기반 왜곡 제거 알고리즘\"으로 지칭될 수 있다.제2 관심 영역 추출기는 추론된 3차원 파라미터에 기초하여 객체의 3차원 정보(예를 들어, 객체 메시 )를 획득하고, 객체를 디워핑함으로써, 객체 표면의 디워핑된 관심 영역을 나타내는, 왜곡 제거 이미지를 생성할 수 있다. 예를 들어, 제2 관심 영역 추출기는, 디워핑을 수행한 후에, 관심 영역에 대응하는 영역 을 잘라냄으로써, 디워핑된 관심 영역을 나타내는 제2 왜곡 제거 이미지를 생성할 수 있다. 또는, 제2 관 심 영역 추출기는, 디워핑을 수행한 후에, 관심 영역 히트 맵에 기초하여 관심 영역을 잘라내거나, 관심 영역을 잘라내고 배경을 제거함으로써, 디워핑된 관심 영역을 나타내는 제3 왜곡 제거 이미지를 생 성할 수 있다. 일 실시예에서, 전자 장치는 신뢰도 체커를 이용하여, 최종 왜곡 제거 이미지를 결정할 수 있다. 예를 들어, 신뢰도 체커에 의해, 제1 왜곡 제거 이미지, 제2 왜곡 제거 이미지 및 제3 왜곡 제거 이미지 중에서 제3 왜곡 제거 이미지가 최종 왜곡 제거 이미지로 결정될 수 있다. 신뢰도 체커의 동작은 도 13c를 참조하여 더 기술한다. 도 13c는 본 개시의 일 실시예에 따른 신뢰도 체커의 개략적인 동작을 설명하기 위한 도면이다. 일 실시예에서, 신뢰도 체커는 체크리스트 내 항목들을 체크하여 이미지 내 3차원 왜곡 제거 과정을 최적 화할 수 있다. 신뢰도 체커는 관심 영역의 모양이 정형화된 디자인인 경우, 관심 영역 모양 기반으로 동 작하는 제1 관심 영역 추출기의 왜곡 제거 알고리즘이 적용되도록 하고, 관심 영역의 모양이 비정형화된 디자인인 경우, 객체 모양 기반으로 동작하는 제2 관심 영역 추출기의 왜곡 제거 알고리즘이 적용되도록 하는 것을 목적으로 한다. 신뢰도 체커는 정형화된 디자인의 관심 영역 체크리스트를 먼저 체크하 고, 체크리스트 내 항목이 하나라도 충족되지 않으면 비정형화된 디자인의 관심 영역 체크리스트를 체크 함으로써, 최종 왜곡 제거 이미지를 결정할 수 있다. 도 13c의 설명을 도 13b를 함께 참조하여 설명한다. 도 13b를 참조하면, 신뢰도 체커가 이미지 왜곡을 제 거하는 전체 알고리즘 파이프라인의 최종 과정에서 동작하는 것처럼 도시되어 있으나, 이는 알고리즘의 시각화 로 인한 것이며, 신뢰도 체커는 알고리즘 파이프라인의 전반적인 과정들에서 중간 산출물둘의 신뢰도를 검토할 수 있다. 제1 관심 영역 추출기는 정형화된 디자인의 관심 영역을 위한 알고리즘을 사용한다. 제1 관심 영역 추출 기의 중간 산출물들은 관심 영역 키 포인트들, 관심 영역 모양 기반 3차원 파라미터, 관심 영역 메시 등을 포함할 수 있다. 이 경우, 신뢰도 체커는 각각의 산출물이 획득될 때, 산출물 의 신뢰도를 평가할 수 있다. 예를 들어, 신뢰도 체커는 정형화된 디자인의 관심 영역 체크리스트 에 기초하여, 관심 영역 키 포인트들의 유사도가 정상인지 여부, 관심 영역 키 포인트들의 히트 맵이 정상인지 여부, 관심 영역 메시가 정상인지 여부 등을 체크할 수 있다. 신뢰도 체커에 의한 체크 결과, 정형화된 디자인의 관심 영역 체크리스트 내 모든 항목들이 통과되는 경우, 제1 왜곡 제거 이미지가 최종 왜 곡 제거 이미지로 결정될 수 있다. 제1 왜곡 제거 이미지는 관심 영역 3D 피팅을 적용하여 획득된 이미지를 의 미할 수 있다. 제2 관심 영역 추출기는 비정형화된 디자인의 관심 영역을 위한 알고리즘을 사용한다. 제2 관심 영역 추 출기의 중간 산출물들은 객체 키 포인트들, 관심 영역 키 히트 맵, 객체 모양 기반 3 차원 파라미터, 객체 메시 등을 포함할 수 있다. 이 경우, 신뢰도 체커는 각각의 산출물이 획득될 때, 산출물의 신뢰도를 평가할 수 있다. 예를 들어, 신뢰도 체커는 비정형화된 디자인의 관심 영 역 체크 리스트에 기초하여, 객체 키 포인트들의 유사도가 정상인지 여부, 객체 키 포인트들의 히트 맵이 정상인지 여부, 관심 영역 히트 맵이 정상인지 여부, 객체 메시가 정상인지 여부 등을 체크할 수 있다. 신뢰도 체커에 의한 체크 결과, 비정형화된 디자인의 관심 영역 체크 리스트 내 모든 항목들이 통과되는 경우, 신뢰도 체커는 엔트로피 맵을 체크하여 최종 왜곡 제거 이미지를 결정할 수 있다. 이 경우, 엔트로 피 체크 결과가 '나쁨'이면, 제2 왜곡 제거 이미지가 최종 왜곡 제거 이미지로 결정될 수 있다. 제2 왜곡 제거 이미지는 객체 3D 피팅을 적용하여 획득된 이미지를 의미할 수 있다. 다시 말해, 엔트로피 체크 결 과가 '나쁨'이면, 전자 장치는 관심 영역을 정밀하게 추출하지 않고 대략적으로 추출할 수 있다. 예를 들 어, 제2 왜곡 제거 이미지는 관심 영역 히트 맵을 포함하는 경계 박스 영역을 기초로 대략적으로 잘라낸 이미지일 수 있다. 또한, 엔트로피 체크 결과가 '좋음'이면, 제3 왜곡 제거 이미지가 최종 왜곡 제거 이미지로 결정될 수 있 다. 제3 왜곡 제거 이미지는 객체 3D 피팅을 적용하고, 관심 영역 히트 맵의 마스크 정보에 기초하여, 관 심 영역 잘라내기 및/또는 배경 제거가 된 이미지를 의미할 수 있다. 다시 말해, 엔트로피 체크 결과가 '좋음'이면, 전자 장치는 관심 영역을 정밀하게 추출할 수 있다. 예를 들어, 관심 영역 히트 맵을 기초로 관심 영역 잘라내기 및/또는 배경 제거가 수행될 수 있다. 일 실시예에 따른 전자 장치가 신뢰도 체커를 이용하여 산출물들의 신뢰도를 평가하는 구체적인 동 작들에 대해서는, 도 14a 내지 도 14e를 참조하여 더 설명한다. 도 14a는 본 개시의 일 실시예에 따른 신뢰도 체커의 구체적인 동작을 설명하기 위한 도면이다. 일 실시예에서, 전자 장치는 키 포인트들의 유사도가 정상인지 여부를 체크할 수 있다. 전자 장치 는 객체 키 포인트들 유사도(Object Key points Similarity; OKS)를 계산할 수 있다. 객체 키 포인트들 유사도 는, 검출된 객체 키 포인트들과 3D 피팅 후 재투영 된 객체 키 포인트들 간의 유사도를 말한다. 검 출된 객체 키 포인트들은, 객체 검출 모델 및/또는 객체 특징 추출 모델로부터 획득될 수 있다. 3D 피팅 후 재투영 된 객체 키 포인트들은, 3D 피팅 후 획득된 3차원 파라미터에 기초하여 3차원 객체를 렌더링하 고, 렌더링 된 3차원 객체의 키 포인트들을 설정함으로써 획득될 수 있다. 전자 장치는 객체 키 포인트들의 유사도가 기 설정된 임계값 이상인 것에 기초하여, 키 포인트들의 유사 도가 정상이라고 판단할 수 있다. 기 설정된 임계값은 예를 들어, 0.9일 수 있으나, 이에 한정되는 것은 아니다. 구체적으로, 제1 체크 결과를 참조하면, 객체 키 포인트들의 유사도가 0.9662 이므로, 전자 장치 는 객체 키 포인트들의 유사도 체크 결과를 '좋음'이라고 결정할 수 있다. 또한, 제2 체크 결과를 참조하면, 객체 키 포인트들의 유사도가 0.6245이므로, 전자 장치는 객체 키 포인트들의 유사도 체크 결 과를 '나쁨'이라고 결정할 수 있다. 한편, 도 14a에서 전자 장치가 객체 키 포인트들 유사도를 계산하는 것을 설명하였으나, 이는 관심 영역 키 포인트들 유사도를 계산하는 것에도 동일하게 적용될 수 있다. 도 14b는 본 개시의 일 실시예에 따른 신뢰도 체커의 구체적인 동작을 설명하기 위한 도면이다. 일 실시예에서, 전자 장치는 키 포인트들(객체 키 포인트들 또는 관심 영역 키 포인트들)의 히트 맵이 정 상인지 여부를 체크할 수 있다. 전자 장치는 검출된 키 포인트들의 히트 맵을 획득할 수 있다. 전자 장치 는 키 포인트의 위치에 대응하는 히트 맵의 픽셀 강도가 기 설정된 제1 임계값 이상인 경우, 키 포인트가 정상 키 포인트라고 판단할 수 있다. 기 설정된 제1 임계값은 예를 들어, 0.5일 수 있으나, 이에 한정되는 것은 아니다. 또한, 전자 장치는 정상 키 포인트의 개수가 상/하 또는 좌/우에서 기 설정된 제2 임계값 보다 큰 경우, 키 포인트들의 히트 맵이 정상이라고 판단할 수 있다. 기 설정된 제2 임계 값은 예를 들어, 7일 수 있 으나, 이에 한정되는 것은 아니다. 제1 체크 결과는 관심 영역의 키 포인트들에 대하여 키 포인트들의 히트 맵이 정상인지 여부를 체크한 결 과를 나타낸다. 제1 체크 결과를 참조하면, 픽셀 강도가 제1 임계값(예를 들어, 0.5) 이상인지 여부에 기 초하여 정상 키 포인트들을 체크한 결과, 관심 영역 위쪽에 유효한 키 포인트들이 9개, 관심 영역 아래쪽에 유 효한 키 포인트들이 9개라고 판단될 수 있다. 이 경우, 관심 영역의 상/하에서 정상 키 포인트의 개수가 기 설 정된 제2 임계값인 7보다 크므로, 전자 장치는 키 포인트들의 히트 맵 체크 결과를 '좋음'이라고 결정할 수 있다. 제2 체크 결과는 관심 영역의 키 포인트들의 대하여 키 포인트들의 히트 맵이 정상인지 여부를 체크한 또 다른 결과를 나타낸다. 제2 체크 결과를 참조하면, 픽셀 강도가 제1 임계값(예를 들어, 0.5) 이상인지 여 부에 기초하여 정상 키 포인트들을 체크한 결과, 관심 영역 위쪽에 유효한 키 포인트들이 9개, 관심 영역 아래 쪽에 유효한 키 포인트들이 6개라고 판단될 수 있다. 이 경우, 관심 영역의 위쪽에서 정상 키 포인트의 개수는 9개이므로 기 설정된 제2 임계값인 7보다 크지만, 관심 영역의 아래쪽에서 정상 키 포인트의 개수는 6개이므로 기 설정된 임계값인 7보다 작다. 따라서, 전자 장치는 키 포인트들의 히트 맵 체크 결과를 '나쁨'이라고 결정할 수 있다. 제3 체크 결과는 객체의 키 포인트들에 대하여 키 포인트들의 히트 맵이 정상인지 여부를 체크한 결과를 나타낸다. 제3 체크 결과를 참조하면, 픽셀 강도가 제1 임계값(예를 들어, 0.5) 이상인지 여부에 기초하 여 정상 키 포인트들을 체크한 결과, 유효한 키 포인트들이 없다. 따라서, 전자 장치는 키 포인트들의 히 트 맵 체크 결과를 '나쁨'이라고 결정할 수 있다. 도 14c는 본 개시의 일 실시예에 따른 신뢰도 체커의 구체적인 동작을 설명하기 위한 도면이다. 일 실시예에서, 전자 장치는 관심 영역 히트 맵이 정상인지 여부를 체크할 수 있다. 전자 장치는 관심 영역의 히트 맵을 획득할 수 있다. 전자 장치는 관심 영역을 검출한 히트 맵의 픽셀들에 대하여, 픽 셀 강도가 기 설정된 제1 임계값 이상이고, 제1 임계값 이상의 픽셀의 개수가 제2 임계값 이상인 경우 관심 영 역 히트 맵이 정상이라고 판단할 수 있다. 예를 들어, 전자 장치는 히트 맵의 픽셀들에 대하여, 픽셀 강 도가 0.35 이상의 픽셀이 3000개 이상인 경우 관심 영역 히트 맵이 정상이라고 판단할 수 있으나, 이에 한정되 는 것은 아니다. 구체적 예를 들면, 제1 히트 맵 체크 결과를 참조하면, 픽셀 강도가 0.35 이상의 픽셀이 3359개로 3000개 보다 많으므로, 전자 장치는 관심 영역 히트 맵 체크 결과를 '좋음'이라고 결정할 수 있다. 또한, 제2 히 트 맵 체크 결과를 참조하면, 픽셀 강도가 0.35 이상의 픽셀이 1504개로 3000개 보다 적으므로, 전자 장 치는 관심 영역 히트 맵 체크 결과를 '나쁨'이라고 결정할 수 있다. 도 14d는 본 개시의 일 실시예에 따른 신뢰도 체커의 구체적인 동작을 설명하기 위한 도면이다. 일 실시예에서, 전자 장치는 엔트로피 체크 결과가 정상인지 여부를 체크할 수 있다. 전자 장치는 관심 영역 히트 맵에 기초하여 엔트로피 맵을 생성할 수 있다. 전자 장치는 관심 영역 히트 맵을 이용하 여, 픽셀 별 엔트로피를 계산함으로써 엔트로피 맵을 생성할 있다. 전자 장치는 엔트로피 맵에 기초하여, 전체 엔트로피 값의 합이 기 설정된 임계값 이하인 경우 엔트로피 체크 결과가 정상이라고 판단할 수 있다. 엔 트로피 값의 합에 대한 기 설정된 임계값은 예를 들어, 200일 수 있으나, 이에 한정되는 것은 아니다. 구체적 예를 들면, 제1 엔트로피 맵 체크 결과를 참조하면, 계산된 엔트로피 총합이 150으로 200보다 작 으므로, 전자 장치는 엔트로피 체크 결과를 '좋음'이라고 결정할 수 있다. 또한, 제2 엔트로피 맵 체크 결과를 참조하면, 엔트로피 총합이 326으로 200보다 크므로, 전자 장치는 엔트로피 체크 결과를 ' 나쁨'이라고 결정할 수 있다. 도 14e는 본 개시의 일 실시예에 따른 신뢰도 체커의 구체적인 동작을 설명하기 위한 도면이다. 일 실시예에서, 전자 장치는 객체 메시 또는 관심 영역 메시가 정상인지 여부를 체크할 수 있다. 전자 장 치는 3D 피팅 결과 추론된 3차원 파라미터에 기초하여, 객체/관심 영역을 나타내는 메시를 생성하고, 메 시 포인트가 객체에 기 설정된 범위 내에서 오버랩되는지 여부를 체크할 수 있다. 예를 들어, 제1 체크 결과를 참조하면, 객체 키 포인트들이 정상적으로 검출되어 있다. 전자 장치 가 객체 키포인트들에 기초하여 3차원 파라미터를 추론하고, 객체 메시를 생성한 결과, 생성된 메시의 포인트들 이 객체에 매치되므로, 전자 장치는 객체 메시 체크 결과가 '좋음'이라고 결정할 수 있다. 예를 들어, 제2 체크 결과를 참조하면, 관심 영역 키 포인트들이 비정상적으로 검출되어 있다. 전자 장치 가 관심 영역 키포인트들에 기초하여 3차원 파라미터를 추론하고, 관심 영역 메시를 생성한 결과, 생성된 메시의 포인트들이 객체에 매치되지 않으므로, 전자 장치는 관심 영역 메시 체크 결과가 '나쁨'이라고 결 정할 수 있다. 도 15a는 본 개시의 일 실시예에 따른 전자 장치가 신뢰도 체커를 이용하여 최종 왜곡 제거 이미지를 선택하는 동작을 설명하기 위한 도면이다. 일 실시예에서, 전자 장치는 왜곡 제거 이미지를 획득하기 위한 과정들에서 중간 산출물들의 신뢰도를 체 크하고, 최종 왜곡 제거 이미지를 획득할 수 있다. 중간 산출물들은, 관심 영역/객체 키 포인트들, 관심 영역 히트 맵, 관심 영역 엔트로피 맵, 3D 피팅 결과, 메시 결과 등을 의미할 수 있다. 중간 산출물들의 신뢰도 체크는 신뢰도 체커에 의해 수행될 수 있다. 신뢰도 체커는 관심 영역의 모양이 정형화 된 디자인인 경우, 관심 영역 모양 기반으로 동작하는 왜곡 제거 알고리즘이 적용되도록 하고, 관심 영역의 모 양이 비정형화된 디자인인 경우, 객체 모양 기반으로 동작하는 왜곡 제거 알고리즘이 적용되도록 하는 것을 목 적으로 한다. 도 15a를 참조하면, 객체의 관심 영역의 모양이 정형화된 디자인에 포함된다. 즉, 와인의 라벨이 직사각형 이므 로 신뢰도 체커는 관심 영역 모양 기반으로 동작하는 왜곡 제거 알고리즘이 먼저 적용되도록 한다. 이에 따라, 관심 영역 기반 왜곡 제거 이미지 및 객체 기반 왜곡 제거 이미지 중에서, 관심 영역 기반 왜곡 제 거 이미지가 최종 왜곡 제거 이미지로 선택될 수 있다. 단, 관심 영역 기반 왜곡 제거 이미지가 최 종 왜곡 제거 이미지로 선택된다는 것은, 신뢰도 체커에 의해 관심 영역 기반 왜곡 제거 알고리즘 과정에서의 모든 신뢰도 체크가 통과된 것을 전제로 한다. 이 경우, 객체의 관심 영역의 모양이 정형화된 디자인에 포함되 므로, 관심 영역 모양 기반 왜곡 제거 알고리즘이 정상적으로 동작하여 관심 영역 기반 왜곡 제거 이미지가 최종 왜곡 제거 이미지로 선택된 것을 의미한다. 도 15b는 본 개시의 일 실시예에 따른 전자 장치가 신뢰도 체커를 이용하여 최종 왜곡 제거 이미지를 선택하는 동작을 설명하기 위한 도면이다. 도 15b를 참조하면, 객체의 관심 영역의 모양이 비정형화된 디자인이다. 즉, 와인의 라벨이 직사각형이 아니므 로, 객체 모양 기반 왜곡 제거 알고리즘이 보다 정확도가 높을 수 있다. 따라서, 신뢰도 체커는 객체 모양 기반 왜곡 제거 알고리즘이 적용되도록 한다. 이에 따라, 관심 영역 기반 왜곡 제거 이미지 및 객체 기반 왜곡 제거 이미지 중에서, 객체 기반 왜곡 제거 이미지가 최종 왜곡 제거 이미지로 선택될 수 있다. 단, 객체 기반 왜곡 제거 이미지가 최종 왜곡 제거 이미지로 선택된다는 것은, 신뢰도 체커에 의해 관심 영역 기반 왜곡 제거 알고리즘 과정에서의 신뢰도 체크가 통과되지 않은 것을 전제로 한다. 이 경우, 관심 영역의 모 양이 비정형화된 디자인에 포함되므로, 관심 영역 모양 기반 왜곡 제거 알고리즘은 정상적으로 동작하지 않을 수 있다. 즉, 관심 영역 기반 왜곡 제거 이미지에 도시된 것과 같이, 3차원 왜곡이 불완전하게 제거되어 있을 수 있다. 이 경우, 객체의 관심 영역의 모양이 비정형화된 디자인에 포함되므로, 객체 모양 기반 왜곡 제 거 알고리즘이 정상적으로 동작하여 관심 영역 기반 왜곡 제거 이미지가 최종 왜곡 제거 이미지로 선택된 것을 의미한다. 도 16은 본 개시의 일 실시예에 따른 전자 장치가 객체의 3차원 모양을 식별하는 동작을 설명하기 위한 도면이 다. 단계 S1610은, 도 3의 단계 S330이 수행되기 이전에 수행될 수 있다. 단계 S1610에서, 전자 장치는 객체의 3차원 모양 타입을 식별한다. 전자 장치는 카메라를 통해 획득된 객체 이미지에 기초하여, 이미지 내 객체의 3차원 모양 타입을 식별할 수 있다. 이 경우, 객체 3차원 모양 타입을 식별하기 위한 인공지능 모델인 객체 3차원 모양 분류 모델이 이용 될 수 있다. 객체 3차원 모양 분류 모델은, 이미지를 입력 받아 이미지 내 객체의 3차원 모양 타입에 관련된 데이터를 출력 하도록 훈련된 인공지능 모델일 수 있다. 예를 들어, 전자 장치는 3차원 객체 모양 분류 모델을 이용하여, 이미지 내에 포함된 객체의 3차원 모양 타입(예를 들어, 구, 정육면체, 실린더 등)을 분류할 수 있다. 전자 장치가 3차원 객체 모양 분류 모델을 이용하여 객체의 3차원 모양 타입을 분류하는 동작은, 도 17a에 대한 설명에서 더 기술한다. 단계 S1620에서, 전자 장치는 객체의 외곽선을 나타내는 객체 키 포인트들을 검출한다. 일 실시예에서, 전자 장치는 인공지능 모델인 객체 검출 모델을 이용하여 객체의 키 포인트들을 검출할 수 있다. 일 실시예에서, 객체 검출 모델은 객체의 3차원 모양 타입을 입력 데이터로 받는 모델일 수 있다. 예를 들어, 객체 검출 모델은 객체의 3차원 모양 타입 및 객체를 포함하는 이미지를 입력 받아, 이미지 내의 객체의 외곽선 을 나타내는 키 포인트들을 출력하도록 훈련된 인공지능 모델일 수 있다. 구체적으로, 객체 검출 모델은 객체의 3차원 모양 타입 \"실린더\"와 실린더 모양의 객체를 포함하는 \"이미지\"를 입력 받아, 실린더 모양의 외곽선을 나 타내는 키 포인트들을 출력할 수 있다. 추가적인 예를 들면, 객체 검출 모델은 구, 정육면체, 각뿔, 원뿔, 잘린 원뿔, 반구, 직육면체 등의 3차원 모양 타입을 입력 받고, 이미지 내에서 각각의 3차원 모양의 외곽선을 나타내 는 키 포인트들을 출력할 수 있다. 일 실시예에서, 객체 검출 모델은 객체의 3차원 모양 타입에 대응하는 모델일 수 있다. 예를 들어, 식별된 객체 의 3차원 모양 타입이 \"실린더\"인 경우, 실린더 모양 객체의 키 포인트들을 검출하도록 훈련된 \"실린더용 객체 검출 모델\"이 이용될 수 있다. 또는, 식별된 객체의 3차원 모양 타입이 \"직육면체\"인 경우, 직육면체 모양 객체 의 키 포인트들을 검출하도록 훈련된 \"직육면체용 객체 검출 모델\"이 이용될 수 있다. 즉, 전자 장치는 객체의 3차원 모양 타입을 식별하면, 객체의 키 포인트들을 검출할 때 객체의 3차원 모 양 타입에 관한 정보를 이용할 수 있다. 전자 장치가 객체의 3차원 모양 타입에 기초하여 객체 키 포인트 들을 검출하는 것에 대하여, 도 17b를 참조하여 더 기술한다. 단계 S1630에서, 전자 장치는 객체의 3차원 모양 타입 및 객체 키 포인트들에 기초하여, 객체의 원본 3차 원 모양을 나타내는 3차원 파라미터의 값들을 추론한다.일 실시예에서, 3차원 파라미터의 피처는 객체의 3차원 모양에 대응하도록 결정된다. 즉, 각각의 3차원 모양 타 입마다 대응하는 3차원 파라미터의 피처가 상이할 수 있다. 예를 들어, 3차원 모양이 실린더 타입인 경우, 실린 더 타입에 대응하는 3차원 파라미터는 반지름을 포함할 수 있으나, 3차원 모양이 정육면체 타입인 경우, 정육면 체 타입에 3차원 파라미터는 반지름을 포함하지 않을 수 있다. 구체적으로, 실린더 타입의 3차원 파라미터의 피처들은 예를 들어, 객체의 3차원 회전, 이동, 치수, 스케일링, 카메라 파라미터 중 적어도 하나에 대응할 수 있다. 또한, 카메라 파라미터는 카메라의 내부 파라미터로, 초점 거리(focal length), 주점(principal point), 종횡비(aspect ratio), 비대칭 계수(skew coefficient) 등을 포 함할 수 있으나, 이에 한정되는 것은 아니다. 3차원 파라미터가 객체의 3차원 모양에 대응하도록 결정되는 것에 대하여, 도 17b를 참조하여 더 기술한다. 또 한, 전자 장치가 객체의 원본 3차원 모양을 나타내는 3차원 파라미터의 값들을 추론하는 것은 객체의 3차 원 모양 타입에 따라 전술한 3D 피팅 동작을 동일/유사하게 적용함으로써 구현될 수 있다. 3D 피팅의 구체적인 동작은 전술하였으므로, 반복되는 설명은 생략한다. 한편, 도 16에서는 3차원 모양을 이용하는 것을 객체 키 포인트들을 이용하는 객체 모양 기반 왜곡 제거 알고리 즘에 대한 예로 설명하였으나, 식별된 3차원 모양은 관심 영역 키 포인트들을 이용하는 관심 영역 모양 기반 왜 곡 제거 알고리즘에도 동일하게 적용될 수 있다. 도 17a는 본 개시의 일 실시예에 따른 전자 장치가 객체의 3차원 모양을 분류하는 동작을 설명하기 위한 도면이 다. 일 실시예에서, 전자 장치는 객체 3차원 모양 분류 모델을 이용하여 객체의 3차원 모양 타입(172 0)을 식별할 수 있다. 전자 장치는 객체의 이미지를 입력 받아 피처들을 추출하는 객체 3차원 모양 분류 모델의 신 경망 연산을 통해 객체의 3차원 모양 타입을 식별할 수 있다. 객체 3차원 모양 분류 모델은, 3차원 모양의 객체를 포함하는 다양한 이미지들로 구성되는 트레이닝 데이 터셋에 기초하여 훈련된 것일 수 있다. 객체 3차원 모양 분류 모델의 트레이닝 데이터셋의 객체 이미지들 에는, 객체의 3차원 모양 타입의 정답 레이블이 주석되어 있을 수 있다. 객체의 3차원 모양 타입은 예를 들어, 구, 정육면체, 각뿔, 원뿔, 잘린 원뿔, 반구, 직육면체 등이 포함될 수 있으나, 이에 한정되는 것은 아니다. 일 실시예에서, 전자 장치는 식별된 3차원 모양 타입에 기초하여 객체의 3차원 모양 타입에 대응하는 3차원 파라미터를 획득할 수 있다. 예를 들어, 3차원 모양 타입이 '구'인 경우, '구'의 3 차원 파라미터가 획득되고, 3차원 모양 타입이 '정육면체'인 경우, '정육면체'의 3차원 파라미터 가 획득될 수 있다. 3차원 파라미터를 구성하는 피처들은 3차원 모양 타입 마다 상이할 수 있다. 예를 들어, '구'의 3차원 파라미터에는 반지름 및/또는 직경 등의 피처가 포함될 수 있으며, '정육 면체'의 3차원 파라미터에는 가로, 세로, 높이 등의 피처가 포함될 수 있다. 한편, 도 17a에 도시된 3차원 파라미터는 설명의 편의를 위해 기하학적 특징인 가로, 세로, 반지름, 깊이 등의 피처들만 도시되었으나, 3차원 파라미터는 이에 한정되는 것은 아니다. 3차원 파라미터는 공 간 상에서 객체의 회전 정보, 공간 상에서 객체의 이동 정보, 객체를 촬영한 카메라 파라미터(예를 들어, 초점 거리) 및 객체의 관심 영역에 관한 3차원 정보(예를 들어, 관심 영역의 가로, 세로, 곡률 등) 등을 더 포함할 수 있다. 즉, 도시된 3차원 파라미터는 시각적 이해를 돕기 위한 예시일 뿐이며, 3차원 파라미터, 는 전술한 예시들 외에 이미지 내 객체의 3차원 정보를 추정하기 위해 활용 가능한 어떠한 유형의 피처든지 더 포함될 수 있고, 전술한 예시들 중에서 일부 피처들이 제외될 수도 있다. 다시 구체적인 예를 들면, 일 실시예에 따른 전자 장치는 이미지를 객체 3차원 모양 분류 모델 에 적용하여, 이미지 내의 객체의 3차원 모양 타입인 실린더 타입을 식별할 수 있다. 전자 장치는 실린더 타입에 대응하는, 실린더의 3차원 파라미터를 획득할 수 있다. 실린더의 3차원 파라미터는 예를 들어, 실린더의 직경 D, 실린더의 반지름 r, 3차원 공간상에서의 실린더의 회전 정보 R, 3차원 공간상에서의 실린더의 이동 정보 T, 실린더의 높이 h, 카메라의 초점거리 정보 F 등을 포함할 수 있으나, 이에 한정되는 것은 아니다. 한편, 본 개시의 도면들에서는 이미지 내 객체가 '와인' 이고 관심 영역이 '와인 라벨'인 것을 예시로 설 명하지만, 본 개시는 이에 한정되는 것은 아니다. 예를 들어, 본 개시에서 와인 병의 3차원 모양 타입은 실린더 타입로 식별되는 것을 설명하였지만, 객체 3차원 모양 분류 모델의 훈련 및 튜닝에 따라서는 와인 병이 병(bottle) 타입으로 식별될 수도 있고, 이에 따라 획득되는 3차원 파라미터도 병 타입에 대응하는 3차원 파라미터일 수 있다. 또 다른 예를 들면, 이미지 내 객체가 다른 타입의 3차원 모양인 '구, 원뿔, 직육면체' 등의 객체일 수도 있다. 이 경우, 전자 장치는 각각의 객체 별로 3차원 모양 타입을 식별하고, 3차원 파라미터를 획 득할 수 있다. 도 17b는 객체의 3차원 모양 타입에 따라 결정되는 객체 키 포인트들 및 객체의 3차원 모양 타입에 대응하는 3 차원 파라미터를 설명하기 위한 도면이다. 도 17a에서 설명한 것과 같이, 객체의 모양 타입 마다 3차원 파라미터가 각각 대응한다. 또한, 객 체의 3차원 모양 타입 마다 객체의 외곽선을 나타내는 객체 키 포인트들이 상이할 수 있다. 예를 들어, 도 17b에 도시된 객체인 컵 누들의 경우, 객체의 3차원 모양 타입이 잘린 원뿔(또는, 컵 모양)으로 식별될 수 있다. 이 경우, 잘린 원뿔의 3차원 파라미터가 3차원 모양 타입(잘린 원뿔 )에 대응하는 3차원 파라미터로 획득된다. 잘린 원뿔의 3차원 파라미터는 객체 아랫부분 지름 D, 객체 윗부분 지름 d, 3차원 공간상에서의 잘린 원뿔의 회전 정보 R, 3차원 공간상에서의 잘린 원뿔(172 4)의 이동 정보 T, 카메라의 초점거리 정보 F 등을 포함할 수 있으나, 이에 한정되는 것은 아니다. 이 경우, 전 자 장치는 객체의 3차원 모양 타입인 잘린 원뿔 및 잘린 원뿔 객체의 외곽선을 나타내는 키 포인트 들에 기초하여, 3D 피팅 동작을 수행함으로써 객체의 원본 3차원 모양을 나타내는 3차원 파라미터의 값들을 추 론할 수 있다. 전자 장치가 3D 피팅을 통해 객체의 3차원 정보를 획득하는 동작은, 객체의 3차원 모양이 실린더인 경우를 예시로 하여 이전의 도면들에서 이미 기술하였으므로, 반복되는 설명은 생략한다. 나아가, 도 17b에 도시된 상품인 곽 우유의 경우, 객체의 3차원 모양 타입이 직사각형으로 식별될 수 있다. 이 경우, 직사각형의 3차원 파라미터가 3차원 모양 타입(직사각형)에 대응하는 3차원 파 라미터로 획득된다. 직사각형의 3차원 파라미터는 높이 a, 가로 b, 세로 c, 3차원 공간상에서의 직사각형 의 회전 정보 R, 3차원 공간상에서의 직사각형의 이동 정보 T, 카메라의 초점거리 정보 F 등을 포 함할 수 있으나, 이에 한정되는 것은 아니다. 이 경우, 전자 장치는 객체의 3차원 모양 타입인 직사각형 및 직사각형 객체의 외곽선을 나타내는 키 포인트들에 기초하여, 3D 피팅 동작을 수행함으로써 객체의 원본 3차원 모양을 나타내는 3차원 파라미터의 값들을 추론할 수 있다. 전자 장치가 3D 피팅을 통해 객체 의 3차원 정보를 획득하는 동작은, 객체의 3차원 모양이 실린더인 경우를 예시로 하여 이전의 도면들에서 이미 기술하였으므로, 반복되는 설명은 생략한다. 도 18a는 본 개시의 일 실시예에 따른 전자 장치가 객체 3차원 모양 분류 모델을 훈련시키는 동작을 설명하기 위한 도면이다. 일 실시예에서, 전자 장치는 객체 3차원 모양 분류 모델을 훈련시킬 수 있다. 전자 장치는 3 차원 객체를 포함하는 다양한 이미지들로 구성되는 트레이닝 데이터셋을 이용하여, 객체 3차원 모양 분류 모델 을 훈련시킬 수 있다. 트레이닝 데이터셋에는 객체의 3차원 모양 전체를 포함하는 트레이닝 이미지 (들)가 포함될 수 있다. 일 실시예에서, 전자 장치는 객체 3차원 모양 분류 모델의 추론 성능을 향상시키기 위하여 3차원 모양 객체의 일부분을 포함하는 트레이닝 이미지들을 이용할 수 있다. 3차원 모양 객체의 일부분을 포함 하는 트레이닝 이미지들은, 다양한 각도, 거리에서 객체의 전체 또는 일부를 촬영함으로써 획득된 것일 수 있다. 예를 들어, 제1 방향(1812-1)에서 객체의 전체 또는 일부를 촬영한 이미지가 획득될 수 있으며, 제2 방향(1812-2)에서 객체의 전체 또는 일부를 촬영한 이미지가 획득될 수 있다. 전술한 예시와 같이, 객체를 촬영 가능한 모든 방향에서 객체의 전체 또는 일부를 촬영한 이미지가 트레이닝 이미지들에 포함되어, 트레이 닝 데이터로 사용될 수 있다. 일부 실시예에서, 객체의 3차원 모양 일부를 포함하는 트레이닝 이미지들은 트레이닝 데이터셋에 이미 포 함되어 있을 수 있다. 일부 실시예에서, 전자 장치는 객체의 3차원 모양 일부를 포함하는 트레이닝 이미 지들을 외부 장치(예를 들어, 서버 등)로부터 수신할 수 있다. 일부 실시예에서, 전자 장치는 카메 라를 이용하여 3차원 모양 객체의 일부를 포함하는 트레이닝 이미지들을 획득할 수 있다. 이 경우, 전자 장치는 트레이닝 데이터 획득을 위해 사용자에게 객체의 일부를 촬영하도록 가이드하는 그래픽 인터페이스를 사용자에게 제공할 수 있다. 일 실시예에 따른 전자 장치는, 3차원 모양 객체의 전체를 포함하는 트레이닝 이미지(들) 및 3차원 모양 객체의 일부를 포함하는 트레이닝 이미지들을 이용하여 훈련된 객체 3차원 모양 분류 모델을 이용하 여, 객체의 3차원 모양을 추론할 수 있다. 예를 들어, 객체의 일부만이 촬영된 입력 이미지만이 입력되더 라도, 전자 장치는 입력 이미지 내 객체의 3차원 모양 타입이 실린더임을 추론할 수 있다. 도 18b는 본 개시의 일 실시예에 따른 전자 장치가 객체 3차원 모양 분류 모델을 훈련시키는 동작을 설명하기 위한 도면이다. 도 18b를 참조하면, 전자 장치는 객체 3차원 모양 분류 모델을 훈련시키기 위한 트레이닝 데이터들 을 생성할 수 있다. 일 실시예에서, 트레이닝 데이터셋에는 객체의 3차원 모양 전체를 포함하는 트레이닝 이미지(들)가 포함 될 수 있다. 전자 장치는 트레이닝 데이터셋에 포함되는 이미지들에 대하여 소정의 데이터 증강 작업을 수행함으로써, 트레이닝 데이터들을 생성할 수 있다. 예를 들어, 전자 장치는 객체의 3차원 모양 전체를 포함하는 트레이닝 이미지(들)를 크롭하여, 객체의 3차원 모양 일부를 포함하는 트레이닝 이미지들(181 4)을 생성할 수 있다. 구체적인 예를 들면, 전자 장치는 트레이닝 이미지를 6분할함으로써, 1개의 트레이닝 데이터가 6개의 트레이닝 데이터가 되도록 데이터를 증강할 수 있다. 예를 들어, 트레이닝 이미지 의 제1 영역(1814-1)이 분할 영역으로 결정되면, 잘라낸 제1 이미지(1814-2)가 트레이닝 데이터로 사용될 수 있다. 한편, 도 18b에는 크롭만이 예시로 도시되어 있으나, 로테이션, 플립 등 다양한 다른 데이터 증강 방 식이 적용될 수도 있다. 일 실시예에 따른 전자 장치는, 객체의 3차원 모양 전체를 포함하는 트레이닝 이미지(들) 및 객체 의 3차원 모양 일부를 포함하는 트레이닝 이미지들을 이용하여 훈련된 객체 3차원 모양 분류 모델 을 이용하여, 객체의 3차원 모양을 추론할 수 있다. 예를 들어, 객체의 일부만이 촬영된 입력 이미지만이 입력되더라도, 전자 장치는 입력 이미지 내 객체의 3차원 모양 타입이 실린더임을 추론할 수 있다. 한편, 전자 장치는 전술한 트레이닝 데이터들에 대하여도, 소정의 데이터 증강 작업을 수행하고, 증강된 데이터를 더 이용하여 객체 3차원 모양 분류 모델을 훈련시킴으로써, 객체 3차원 모양 분류 모델의 추론 성능을 향상시킬 수 있다. 예를 들어, 전자 장치는 3차원 모양 객체의 전체를 포함하는 트레이닝 이 미지(들), 3차원 모양 객체의 일부를 포함하는 트레이닝 이미지들(1812, 1814)에 대하여, 크롭, 로테이션, 플립 등의 다양한 데이터 증강 방식을 적용하고, 증강된 데이터를 트레이닝 데이터셋에 포함시킬 수 있다. 도 18c는 본 개시의 일 실시예에 따른 전자 장치가 객체의 3차원 모양을 식별하는 실시예를 설명하기 위한 도면 이다. 일 실시예에서, 전자 장치는 객체의 일부만이 촬영된 입력 이미지(이하에서, 입력 이미지)를 객체 3차원 모양 분류 모델에 입력하고, 객체 3차원 모양 추론 결과를 획득할 수 있다. 이 경우, 입력 이미지가 객체의 전체 모양을 포함하지 않기 때문에, 객체 3차원 모양 추론 결과의 보완이 필요할 수 있다. 예를 들어, 객체 3차원 모양 추론 결과는 실린더 타입일 확률 50%, 잘린 원뿔 타입일 확률 50% 일 수 있으며, 객체 3차원 모양 분류 모델이 객체 3차원 모양을 확정하기 위한 임계 값은 확률 값: 80% 이상일 수 있다. 이 경우, 실린더 타입일 확률(50%)과 원뿔 타입일 확률(50%) 모두 객체 3차원 모양을 확정하기 위한 임계 값(80%)을 초과하지 않으므로, 전자 장치는 객체 3차원 모양 추론 결과를 보완하기 위한 동작을 수행할 수 있다. 일 실시예에서, 전자 장치는 객체 3차원 모양 추론 결과 값이 기 설정된 임계 값 미만인 것에 기초 하여, 객체 3차원 모양 추론 결과를 보완하기 위한 정보 검출 동작을 수행할 수 있다. 정보 검출 동작은 예를 들어, 이미지 내에서 로고, 아이콘, 텍스트 등의 정보를 검출하는 것일 수 있으나, 이에 한정되는 것은 아 니다. 보다 구체적 예를 들면, 전자 장치는 입력 이미지에 대하여 OCR을 수행하여, 입력 이미지 내에서 텍스트를 검출할 수 있다. 이 경우, 검출된 텍스트는 상품명인 'ABCDE'일 수 있다. 전자 장치 는 검출된 텍스트에 기초하여, 데이터베이스 내에서 또는 외부 서버를 통해서 상품을 검색할 수 있다. 예 를 들어, 전자 장치는 'ABCDE'의 상품을 데이터베이스에서 검색할 수 있다. 전자 장치는 상품 검색 결과에 기초하여, 3차원 모양 타입의 가중치를 결정할 수 있다. 예를 들어, 'ABCDE' 상품의 검색 결과, 시중에서 유통되는 'ABCDE' 상품의 95% 이상이 실린더 타입임을 식별할 수 있다. 이 경우, 전자 장치는 실린더 타입에 가중치를 적용할 것으로 결정할 수 있다. 전자 장치는 객체 3차원 모양 추론 결과에 결정된 가중치를 적용할 수 있다. 가중치 적용 결과, 최종적으로 결정된 객체의 3차원 모양 타입은 실린더로 결 정될 수 있다. 일 실시예에서, 전자 장치는 객체 3차원 모양 분류 모델에 입력 이미지를 입력하는 것과 병 렬적으로, 정보 검출 동작을 수행할 수 있다 예를 들어, 전자 장치는 입력 이미지에 대하여 OCR을 수행할 수 있다. 전자 장치는 병렬적으로 수행한 OCR 결과에 기초하여, 객체 3차원 모양 추론 결과(182 6)에 적용될 가중치를 결정할 수 있다. 도 18d는 본 개시의 일 실시예에 따른 전자 장치가 객체의 3차원 모양을 식별하는 실시예를 설명하기 위한 도면 이다. 일 실시예에서, 전자 장치는 입력 이미지를 객체 3차원 모양 분류 모델에 입력하고, 객체 3 차원 모양 추론 결과를 획득할 수 있다. 전자 장치는 입력 이미지를 객체 3차원 모양 분류 모델에 적용하기 이전에, 객체 검색 도메 인 선택을 위한 사용자 인터페이스를 표시할 수 있다. 예를 들어, 전자 장치는 유제품, 와인, 통조림 등 의 선택 가능한 도메인을 표시하고, 도메인을 선택하는 사용자 입력을 수신할 수 있다. 전자 장치는 검색 도메인을 선택하는 사용자 입력에 기초하여, 3차원 모양 타입의 가중치를 결정할 수 있 다. 예를 들어, 사용자가 와인 라벨 검색을 선택한 경우, 시중에서 유통되는 와인 상품의 95% 이상이 실린더 타 입임을 식별할 수 있다. 이 경우, 전자 장치는 실린더 타입에 가중치를 적용할 것으로 결정할 수 있다. 전자 장치는 객체 3차원 모양 추론 결과에 결정된 가중치를 적용할 수 있다. 가중치 적용 결과, 최 종적으로 결정된 객체의 3차원 모양 타입은 실린더로 결정될 수 있다. 도 19는 본 개시의 일 실시예에 따른 전자 장치에 포함될 수 있는 멀티 카메라를 설명하기 위한 도면이다. 일 실시예에서, 전자 장치는 멀티 카메라를 포함할 수 있다. 예를 들어, 전자 장치는 제1 카메라 , 제2 카메라 및 제3 카메라를 포함할 수 있다. 도 19에서 도시된 카메라는 3개이지만, 카메 라 개수를 한정하기 위한 것은 아니고, 멀티 카메라는 2개 이상의 카메라를 의미한다. 멀티 카메라에 포함되는 각각의 카메라의 사양은 서로 상이할 수 있다. 예를 들어, 제1 카메라는 망원 카 메라, 제2 카메라는 광각 카메라, 제3 카메라는 초광각 카메라로 구성될 수 있다. 다만, 카메라의 종류는 이에 한정되는 것은 아니며, 표준 카메라 등이 포함될 수 있다. 각각의 카메라는 서로 다른 특징의 이미지를 획득할 수 있다. 예를 들어, 제1 카메라에 의해 획득된 제1 이미지는, 객체를 확대하여 촬영하여 객체의 일부가 포함되는 이미지일 수 있다. 제2 카메라에 의 해 획득된 제2 이미지는, 제1 카메라보다 넓은 화각으로 객체를 촬영하여 객체의 전체가 포함되는 이미지일 수 있다. 제3 카메라에 의해 획득된 제3 이미지는, 제1 카메라, 제2 카메라 보다 더 넓은 화각으로 객체를 촬영하여 객체의 전체 및 장면의 넓은 영역이 포함되는 이미지일 수 있다. 일 실시예에서, 전자 장치에 포함되는 멀티 카메라의 각각으로부터 획득되는 이미지의 특징이 상이하므로, 어떠한 카메라를 이용하여 획득된 이미지가 이용되는지에 따라, 전술한 동작들에 따른 전자 장치 가 이미지 내 객체의 3차원 왜곡을 제거하고, 왜곡 제거 이미지로부터 정보를 추출하는 결과 또한 상이할 수 있다. 보다 정확하고 효율적으로 이미지에 포함되는 객체를 인식하고 객체의 관심 영역으로부터 정보를 추출 하기 위해, 전자 장치는 멀티 카메라 중 어느 카메라를 활성화할지 여부를 결정할 수 있다. 일 실시예에서, 전자 장치는 제1 카메라를 활성화하고 객체를 촬영하여 제1 이미지를 획득할 수 있다. 전자 장치는 제1 이미지를 이용하여 이미지 내의 객체의 3차원 모양 타입 및 객체의 관심 영역을 식별할 수 있다. 일부 실시예에서, 전술한 예시에 따르면 제1 이미지는 망원 카메라인 제1 카메라 를 이용하여 획득된 이미지일 수 있다. 이 경우, 제1 이미지에는 객체의 일부만이 포함되어, 제1 이미지 내의 객체의 관심 영역은 충분한 신뢰도(예를 들어, 소정의 값 이상)로 식별되나, 제1 이미지 내의 객체의 3차원 모양 타입은 불충분한 신뢰도로 식별될 수 있다. 전자 장치는 객체의 3차원 모 양 타입을 식별하기 위해, 제2 카메라 및/또는 제3 카메라를 활성화함으로써, 객체의 전체를 포함 하는 제2 이미지 및/또는 제3 이미지를 획득하고, 제2 이미지 및/또는 제3 이미지를 이용하여 객체의 3차원 모양 타입을 식별할 수 있다. 즉, 전자 장치는 객체의 관심 영역과 3차원 모양 타입을 식별하기에 적합한 이미지를 선택적으로 이용할 수 있다. 일 실시예에서, 전자 장치는 제1 카메라 및 제2 카메라를 활성화하고 객체를 촬영하여 제1 이미지 및 제2 이미지를 획득할 수 있다. 전자 장치는 객체의 일부를 포함하는 제1 이미지 를 이용하여 객체의 관심 영역을 식별하고, 객체의 전체를 포함하는 제2 이미지 및/또는 제3 이미 지를 이용하여 객체의 3차원 모양 타입을 식별할 수 있다. 일 실시예에 따른 전자 장치가 카메라를 활성화하는 동작은, 전술한 예시에 한정되지 않는다. 전자 장치 는 멀티 카메라에 포함되는 카메라의 가능한 모든 조합을 이용할 수 있다. 예를 들어, 전자 장치는 제2 카메라 및 제3 카메라만을 활성화하거나, 제1 카메라, 제2 카메라 및 제3 카메라 모두를 활성화할 수 있다. 한편, 일 실시예에 따른 전자 장치가 객체의 키 포인트들을 획득하는 동작, 객체의 관심 영역을 식별하는 동작, 객체의 3차원 모양 타입을 식별하는 동작 등은, 이전의 도면들에서 전술하였으므로, 간결함을 위해 반복 되는 설명은 생략한다. 전자 장치가 멀티 카메라를 이용하여 획득된 이미지들을 처리하고 왜곡을 제거하는 구체적인 동작들은, 후술하는 도면들을 참조하여 더 기술하기로 한다. 도 20a는 본 개시의 일 실시예에 따른 전자 장치가 멀티 카메라를 이용하는 동작을 설명하기 위한 흐름도이다. 단계 S2010에서, 전자 장치는 제1 카메라를 이용하여 획득된 객체의 제1 이미지로부터 객체의 3차원 모양 타입이 식별되었는지 여부를 체크한다. 예를 들어, 제1 카메라를 이용하여 획득한 제1 이미지가 객체의 일부만 을 포함하고 있는 경우, 전자 장치가 제1 이미지를 객체 3차원 모양 분류 모델에 입력하더라도 객체 3차 원 모양 분류 모델은 객체의 3차원 모양 타입을 정확히 추론할 수 없다. 이 때, 객체 3차원 모양 분류 모델은 객체의 3차원 모양 타입을 추론할 수 없다는 결과를 출력하거나, 3차원 모양 타입 추론에 대한 낮은 신뢰도 값 을 출력할 수 있다. 전자 장치는 객체 3차원 모양 분류 모델로부터 임계값 이하의 신뢰도 값을 갖는 결과 가 출력되는 경우, 제1 이미지로부터 객체의 3차원 모양 타입이 식별되지 않았다고 판단할 수 있다. 일 실시예에서, 전자 장치는 제1 이미지로부터 객체의 3차원 모양 타입이 식별되지 않는 경우, 단계 S2020을 수행할 수 있다. 한편, 단계 S2020는 전자 장치는 도 18c 및 도 18d에서 전술한, 3차원 모양 타 입에 가중치를 결정하고, 가중치를 적용하여 3차원 모양을 식별하는 동작과 선택적 또는 중복적으로 적용될 수 있다. 전자 장치는 객체의 3차원 모양 타입이 식별되는 경우, 왜곡 제거 동작을 계속하기 위해 단계 S2050의 동작을 수행할 수 있다. 단계 S2020에서, 전자 장치는 제2 카메라를 활성화한다. 제2 카메라는 제1 카메라보다 넓은 화각을 갖는 카메라일 수 있다. 제2 카메라는 예를 들어, 광각 카메라, 초광각 카메라 등일 수 있으나, 이에 한정되는 것은 아니다. 단계 S2030에서, 전자 장치는 제2 카메라를 이용하여 제2 이미지를 획득한다. 제2 카메라는 제1 카메라보 다 화각이 넓으므로, 제1 카메라를 이용하여 획득한 제1 이미지에는 객체의 일부 3차원 모양만이 포함되더라도, 제2 카메라를 이용하여 획득한 제2 이미지에는 객체의 전체 3차원 모양이 포함될 수 있다. 단계 S2040에서, 전자 장치는 제2 이미지를 객체 3차원 모양 분류 모델에 적용함으로써 객체의 3차원 모 양 타입에 관한 데이터를 획득한다. 제2 이미지에는 객체의 전체 3차원 모양이 포함될 수 있다. 단계 S2040의 동작은 도 16의 단계 S1610의 동작과 동일하므로, 구체적인 설명은 생략한다. 단계 S2050에서, 전자 장치는 제1 이미지 및 제2 이미지 중 적어도 하나를 이용하여 객체 관심 영역 및 객체 키 포인트들을 검출한다. 일 실시예에서, 제1 이미지에는 객체의 일부 3차원 모양만이 포함되더라도, 관심 영역은 온전히 포함될 수 있다. 전자 장치는 제1 이미지를 관심 영역 검출 모델에 적용함으로써, 제1 이미지 내에서 관심 영역을 검출할 수 있다. 일 실시예에서, 제2 이미지에는 객체의 전체 3차원 모양이 포함되므로, 객체의 온전한 모양 및 관심 영역이 전 부 포함될 수 있다. 전자 장치는 제2 이미지를 관심 영역 검출 모델 및/또는 객체 검출 모델에 각각 적용 함으로써, 제2 이미지 내에서 관심 영역 및/또는 객체 키 포인트들을 검출할 수 있다. 일 실시예에서, 전자 장치는 제1 이미지 및 제2 이미지를 각각 관심 영역 검출 모델 및/또는 객체 검출 모델에 적용하고, 각각의 이미지로부터 획득된 관심 영역 식별 결과를 선택하거나, 조합할 수 있다. 전자 장치 는 단계 S2050을 수행한 후, 도 3의 단계 S340 또는 도 16의 단계 S1610을 수행할 수 있다. 도 20b는 도 20a를 보충적으로 설명하기 위한 도면이다. 일 실시예에서, 전자 장치가 제1 카메라를 이용하여 획득한 제1 이미지는, 객체의 일부만이 포함될 수 있다. 이때, 객체 3차원 모양 분류 모델은 제1 이미지로부터 객체의 3차원 모양 타입을 식별하 지 못할 수 있다. 이 경우, 전자 장치는 단계 S2020을 수행하여, 제1 카메라보다 화각이 넓은 제2 카메라 를 활성화하고, 활성화된 제2 카메라를 이용하여 제2 이미지를 획득할 수 있다. 전자 장치는 제2 이미지를 객체 3차원 모양 분류 모델에 입력함으로써, 객체의 3차원 모양 타입을 식별할 수 있다. 한편, 전자 장치가 제2 이미지를 이용하여 객체의 3차원 모양 타입을 식별하는 동작은, 도 18c 및 도 18d 에서 전술한, 전자 장치가 3차원 모양 타입에 가중치를 결정하고, 가중치를 적용하여 3차원 모양을 식별 하는 동작과 선택적 또는 중복적으로 적용될 수 있다. 도 21a는 본 개시의 일 실시예에 따른 전자 장치가 멀티 카메라를 이용하는 동작을 설명하기 위한 흐름도이다. 단계 S2110에서, 전자 장치는 제1 카메라를 이용하여 객체의 일부(예를 들어, 라벨)를 포함하는 제1 이미 지를 획득하고, 제2 카메라를 이용하여 객체의 전체를 포함하는 제2 이미지를 획득한다. 제2 카메라는, 제1 카 메라보다 화각이 넓은 카메라일 수 있다. 예를 들어, 제1 카메라는 망원 카메라이고, 제2 카메라는 광각 카메라, 초광각 카메라 등일 수 있으나, 이에 한정되는 것은 아니다. 일 실시예에서, 사용자는 전자 장치(300 0)의 카메라를 활성화하여 객체를 촬영할 수 있다. 사용자는 카메라를 실행하기 위한 하드웨어 버튼 또는 아이 콘을 터치하여 카메라를 활성화할 수도 있고, 음성 명령을 통해 카메라를 활성화할 수도 있다 사용자가 객체의 관심 영역(예를 들어, 라벨)로부터 정보를 추출하기 위해, 제1 카메라에 대응하는 프리뷰 영역 에 관심 영역이 전반적으로 나타나도록 전자 장치의 위치를 조정하는 경우, 전자 장치가 제1 카메 라를 이용하여 획득한 제1 이미지에는 객체의 관심 영역은 명확히 나타날 수 있으나, 객체의 전체 모양은 나타 나지 않을 수 있다. 하지만, 제1 카메라보다 화각이 넓은 제2 카메라를 이용하여 획득된 제2 이미지에는 객체의 전체 모양이 나타날 수 있다. 단계 S2120에서, 전자 장치는 제1 이미지를 이용하여 객체의 표면의 관심 영역을 검출한다. 제1 이미지는 관심 영역이 포커싱된 이미지이므로, 관심 영역을 정확히 식별하기에 적합할 수 있다. 단계 S2120은, 도 3의 단 계 S320에 대응하므로, 반복되는 설명은 생략한다. 단계 S2130에서, 전자 장치는 제2 이미지를 이용하여 객체의 3차원 모양을 식별한다. 단계 S2130은, 도 16의 단계 S1610, 도 20a의 단계 S2040에 대응하므로, 반복되는 설명은 생략한다. 단계 S2140에서, 전자 장치는 제2 이미지를 이용하여 객체 외곽선을 나타내는 객체 키 포인트들을 검출한 다. 제2 이미지는 객체 전체 모양이 포함되도록 촬영된 이미지이므로, 객체 외곽선을 정확히 식별하기에 적합할 수 있다. 단계 S2140은, 도 3의 단계 S330에 대응하므로, 반복되는 설명은 생략한다. 단계 S2150에서, 전자 장치는 객체의 3차원 모양 타입에 대응하는 3차원 파라미터 값들을 추론한다. 추론 된 3차원 파라미터는 객체의 원본 3차원 모양을 나타낸다. 단계 S2150은, 도 3의 단계 S340에 대응하므로, 반복 되는 설명은 생략한다. 도 21b는 도 21a를 보충적으로 설명하기 위한 도면이다. 일 실시예에서, 전자 장치가 제1 카메라를 이용하여 획득한 제1 이미지는, 망원 카메라를 이용하여 획득된 이미지일 수 있다. 제1 이미지는 객체의 전체 3차원 모양을 포함하지 않고 관심 영역을 확대하여 포함하고 있으므로, 관심 영역을 식별하기에 적합한 이미지일 수 있다. 이 경우, 전자 장치는 제1 이미지 를 이용하여 관심 영역 특징을 추출할 수 있다. 예를 들어, 전자 장치는 제1 이미지로부터 관심 영역 키 포인트들, 관심 영역 히트 맵 등을 검출할 수 있으나, 이에 한정되는 것은 아니다. 일 실시예에서, 전자 장치가 제2 카메라를 이용하여 획득한 제2 이미지는, 광각 카메라 및/또는 초 광각 카메라를 이용하여 획득된 이미지일 수 있다. 제2 이미지는 객체의 전체 3차원 모양을 포함하고 있 으므로, 객체의 3차원 모양 및 객체의 특징을 식별하기에 적합한 이미지일 수 있다. 이 경우, 전자 장치 는 제2 이미지를 이용하여 객체 특징을 추출할 수 있다. 예를 들어, 전자 장치는 제2 이미지(210 4)로부터 객체 3차원 모양 타입, 객체 키 포인트들 등을 검출할 수 있으나, 이에 한정되는 것은 아니다.도 22a는 본 개시의 일 실시예에 따른 전자 장치가 멀티 카메라를 이용하는 동작을 설명하기 위한 흐름도이다. 단계 S2210에서, 일 실시예에 따른 전자 장치는 제1 카메라를 이용하여 실시간으로 촬영되는 제1 이미지 를 객체 검출 모델에 적용하여 관심 영역의 신뢰도를 획득한다. 제1 카메라는 망원 카메라일 수 있으며, 제1 이 미지는 관심 영역을 포커싱한 이미지일 수 있다. 일 실시예에서, 전자 장치의 사용자가 객체를 인식하고자 하는 경우(예를 들어, 상품의 라벨을 검색하고 자 하는 경우 등), 사용자는 카메라 애플리케이션을 활성화할 수 있다. 사용자는 전자 장치의 화면에 표 시되는 프리뷰 이미지 등을 보면서 카메라가 객체를 응시하도록 카메라의 시야를 계속하여 조정할 수 있다. 전 자 장치는 제1 카메라를 통해 실시간으로 획득되는 제1 이미지 프레임들에 대하여, 각각의 제1 이미지 프 레임들을 관심 영역 검출 모델에 입력할 수 있다. 전자 장치는 각각의 제1 이미지 프레임들에 대한 관심 영역 검출의 정확도를 나타내는, 관심 영역의 신뢰도를 획득할 수 있다. 단계 S2220에서, 일 실시예에 따른 전자 장치는 제2 카메라를 이용하여 실시간으로 촬영되는 제2 이미지 를 객체 3차원 모양 분류 모델에 적용하여 객체의 3차원 모양 타입의 신뢰도를 획득한다. 제2 카메라는, 광각 카메라 또는 초광각 카메라일 수 있으며, 제2 이미지는 객체에 대한 이미지일 수 있다. 일 실시예에서, 전자 장치는 제2 카메라를 통해 실시간으로 획득되는 제2 이미지 프레임들에 대하여, 각 각의 제2 이미지 프레임들을 객체 3차원 모양 분류 모델에 입력할 수 있다. 전자 장치는 각각의 제2 이미 지 프레임들에 대한 객체 3차원 모양 분류의 정확도를 나타내는, 객체의 3차원 모양 타입의 신뢰도를 획득할 수 있다. 단계 S2230에서, 일 실시예에 따른 전자 장치는 관심 영역의 신뢰도가 제1 임계 값을 초과하는지 여부를 판단한다. 제1 임계 값은 관심 영역에 대하여 기 설정된 임계 값일 수 있다. 전자 장치는 관심 영역의 신 뢰도가 제1 임계 값 이하인 경우, 제1 임계 값을 초과하는 신뢰도가 획득될 때까지 단계 S2210을 계속하여 수행 할 수 있다. 단계 S2240에서, 일 실시예에 따른 전자 장치는 객체의 3차원 모양 타입의 신뢰도가 제2 임계 값을 초과 하는지 여부를 판단한다. 제2 임계 값은 객체의 3차원 모양에 대하여 기 설정된 임계 값일 수 있다. 전자 장치 는 객체의 3차원 모양 타입의 신뢰도가 제2 임계 값 이하인 경우, 제2 임계 값을 초과하는 신뢰도가 획득 될 때까지 단계 S2220을 계속하여 수행할 수 있다. 단계 S2250에서, 일 실시예에 따른 전자 장치는 제1 이미지 및 제2 이미지를 각각 캡쳐한다. 일 실시예에서, 단계 S2250이 수행되는 조건은 관심 영역의 신뢰도가 제1 임계 값을 초과하고, 3차원 모양 타입 의 신뢰도가 제2 임계 값을 초과하는 AND 조건이다. 전자 장치는 제1 이미지 및 제2 이미지를 각각 캡쳐 하여 저장하고, 단계 S1520 및 그 이후의 단계들을 수행할 수 있다. 이 경우, 전자 장치는 제1 이미지를 관심 영역 검출 모델에 적용함으로써 객체의 표면의 관심 영역을 식별하고, 제2 이미지를 객체 3차원 모양 분류 모델에 적용함으로써 객체의 3차원 모양을 식별할 수 있다. 이에 대한 구체적인 동작들은 전술하였으므로, 반복 되는 설명은 생략한다. 단계 S2250이 수행된 이후에, 도 21a의 단계 S2130이 수행될 수 있다. 이 경우, 객체 3 차원 모양을 식별하는 단계 S2140은 이미 수행 되었으므로, 생략될 수 있다. 도 22b는 도 22a를 보충적으로 설명하기 위한 도면이다. 도 22b 및 도 22c를 설명함에 있어서, 사용자가 와인의 라벨을 인식하고자 하는 경우를 예시로 설명한다. 도 22b를 참조하면, 일 실시예에 따른 전자 장치는 객체 인식을 위한 제1 화면을 표시할 수 있다. 제1 화면은 전자 장치의 사용자가 객체 인식을 수행할 수 있도록 가이드하는 인터페이스를 포함할 수 있다. 예를 들어, 전자 장치는 제1 화면에 객체의 관심 영역이 포함되도록 가이드하는 사각 박 스(다만, 사각형에 한정되지 않으며 원형 등 유사한 기능을 할 수 있는 다른 형태를 포함함)를 표시하고, '와인 라벨을 검색합니다' 등의 가이드를 표시할 수 있다. 일부 실시예에서, 전자 장치는 제1 화면 에 표시되는 이미지로부터 객체가 인식되지 않는 경우, '카메라를 통해 상품을 비춰 주세요' 등의 가이드 를 출력할 수 있다. 일 실시예에서, 전자 장치는 카메라로부터 획득되는 프리뷰 이미지를 나타내는 제2 화면을 표시할 수 있다. 사용자는 제2 화면을 보면서, 객체가 이미지 내에 완전히 포함되도록 카메라의 시야를 조정할 수 있다. 전자 장치는 카메라의 프리뷰 이미지인 제2 화면이 표시되는 동안, 관심 영역의 신뢰도및 객체의 3차원 모양 타입의 신뢰도를 계산할 수 있다. 이는, 전술하였으므로 반복되는 설명은 생략한다. 관심 영역의 신뢰도가 제1 임계값을 초과하고, 객체의 3차원 모양 타입의 신뢰도가 제2 임계값을 초과하는 경우, 전자 장치는, 객체의 원본 3차원 모양을 나타내는 3차원 파라미터 값들을 추론할 수 있다. 그리고 전자 장치는 객체와 관련된 3차원 파라미터 값에 기초하여 원근 변환을 수행하고, 3차원 왜곡을 제거함으 로써, 관심 영역이 평평하게 수정된 왜곡 제거 이미지를 획득할 수 있다. 전자 장치는 왜곡 제거 이미지 가 획득되고 왜곡 제거 이미지로부터 객체에 관련된 정보가 추출되는 경우(즉, 상품이 인식되는 경우), '와인 정보가 검색되었습니다'와 같은 알림을 프리뷰 이미지 상에 출력할 수 있다. 그리고 전자 장치는 왜곡 제거 이미지로부터 추출된 객체에 관련된 정보를 출력할 수 있다. 예를 들어, 전자 장치는 와 인 라벨 이미지 및 와인에 관한 상세 정보를 출력할 수 있다. 도 22c는 도 22a를 보충적으로 설명하기 위한 도면이다. 도 22c를 참조하면, 일 실시예에 따른 전자 장치는 객체 인식을 위한 제1 화면을 표시할 수 있다. 제1 화면은 전자 장치의 사용자가 객체 인식을 수행할 수 있도록 가이드하는 인터페이스를 포함할 수 있다. 예를 들어, 전자 장치는 제1 화면에 객체의 관심 영역이 포함되도록 가이드하는 사각 박 스(다만, 사각형에 한정되지 않으며 원형 등 유사한 기능을 할 수 있는 다른 형태를 포함함)를 표시하고, '와인 라벨을 검색합니다' 등의 가이드를 표시할 수 있다. 일부 실시예에서, 전자 장치는 제1 화면 에 표시되는 이미지로부터 객체가 인식되지 않는 경우, '카메라를 통해 상품을 비춰 주세요' 등의 가이드 를 출력할 수 있다. 일 실시예에서, 전자 장치는 카메라의 프리뷰 이미지인 제2 화면이 표시되는 동안, 관심 영역의 신 뢰도 및 객체의 3차원 모양 타입의 신뢰도를 계산할 수 있다. 전자 장치는 관심 영역의 신뢰도가 제1 임 계 값을 초과하고, 객체의 3차원 모양 타입의 신뢰도가 제2 임계 값을 초과하여야 이미지로부터 왜곡을 제거하 기 위한 이후의 동작들을 수행한다. 따라서, 관심 영역의 신뢰도가 제1 임계 값 이하 및/또는 객체의 3차원 모 양 타입의 신뢰도가 제2 임계 값 이하인 경우, 전자 장치는 제1 이미지 및 제2 이미지를 획득하기 위해 사용자에게 카메라 시야를 조정할 수 있도록 가이드하는 알림을 출력할 수 있다. 예를 들어, 전자 장치 는 '와인 라벨을 인식할 수 없습니다. 카메라 각도를 조정해 주세요'와 같은 알림을 화면에 표시하 거나, 오디오로 출력할 수 있다. 도 23a는 본 개시의 일 실시예에 따른 전자 장치가 이미지를 처리하여 추출된 정보를 제공하는 동작을 설명하기 위한 도면이다. 일 실시예에서, 전자 장치는 왜곡 제거 이미지인 플랫 라벨 이미지를 생성하고, 플랫 라벨 이미지로부터 객체와 관련된 정보를 추출하여 사용자에게 제공할 수 있다. 일 실시예에서, 전자 장치는 객체 인식을 시작하기 위한 제1 화면을 표시할 수 있다. 제1 화면 에는 '와인 라벨 스캔'과 같은 사용자 인터페이스가 포함될 수 있다. 전자 장치의 사용자는 사용자 인터페이스를 통해 객체 인식 동작을 시작할 수 있다. 일 실시예에서, 전자 장치는 객체 인식을 수행하기 위한 제2 화면을 표시할 수 있다. 제2 화면 은 전자 장치의 사용자가 객체 인식을 수행할 수 있도록 가이드하는 인터페이스를 포함할 수 있다. 예를 들어, 전자 장치는 제2 화면에 객체의 관심 영역이 포함되도록 가이드하는 가이드 영역(2302- 1)을 표시하고, '와인 전면 라벨을 촬영하세요' 등의 가이드 문구(2302-2)를 표시할 수 있다. 전자 장치 는 멀티 카메라를 통해 복수의 이미지들(예를 들어, 망원 이미지, 광각 이미지, 초광각 이미지 등)을 획득하고, 전술한 실시예에서 설명한, 3차원 정보에 기초한 왜곡 제거 동작들을 수행할 수 있다. 즉, 전자 장치는 이미지 내에서 관심 영역인 와인 라벨 영역을 추출하고, 왜곡을 제거하는 보정을 수행하여 왜곡이 제거된 와인 라벨 이미지를 생성한다. 또한, 전자 장치는 왜곡 제거 와인 라벨 이미지에 OCR을 적용하여, 와인과 관련 된 정보들을 추출할 수 있다. 전자 장치는 와인 라벨에서 식별된 텍스트 정보를 이용하여, 와인 정보를 검색할 수 있다. 일 실시예에서, 전자 장치가 1)와인 라벨 영역을 추출/보정하고, 2)와인 라벨에서 식별된 텍스트 정보를 이용하여 와인 정보를 검색 하면, 전자 장치는 객체 인식 및 검색 결과를 나타내는 제3 화면을 표 시할 수 있다. 제3 화면에는 전자 장치가 전술한 실시예에 따라 생성한 왜곡 제거 이미지가 표시될 수 있다. 도 23a의 예시에서 왜곡 제거 이미지는, 와인 라벨 이미지일 수 있다. 와인 라벨 이미지는 와인 병에 곡선형으로 부착된 와인 라벨이 평평하게 변환된, 플랫 라벨 이미지일 수 있다.제3 화면에는, 전자 장치가 전술한 실시예에 따라 획득한 객체와 관련된 정보가 표시될 수 있다. 도 23a의 예시에서 객체와 관련된 정보는, 와인 상세 정보일 수 있다. 이 경우, 와인 라벨 이미지로부터 OCR을 수행한 결과인, 와인 이름, 원산지, 생산 년도 등이 표시될 수 있다. 일 실시예에서, 제3 화면에는, 와인 라벨 이미지로부터 획득된 객체와 관련된 정보 외에도, 서버로부터 획득되거나 전자 장치의 데이터베이스로부터 획득된, 객체에 관련된 추가 정보가 더 표시될 수 있다. 예 를 들어, 와인 라벨 이미지로부터 획득될 수 없는 와인의 산도, 바디감, 알코올 도수 등이 표시될 수 있다. 일 실시예에서, 제3 화면에는 다른 전자 장치로부터 획득되는 정보 및/또는 사용자 입력에 기초하여 획득 되는 정보가 더 표시될 수 있다. 예를 들어, 와인의 별명, 입고일, 보관 위치, 등이 표시될 수 있다. 다만, 와인 라벨 이미지로부터 획득 가능한 정보 및 와인 라벨 이미지 외 다른 경로로부터 획득 되어 표시되는 정보는 예시적으로 설명한 것이며, 전술한 것으로 한정되는 것은 아니다. 일 실시예에서, 전자 장치는 객체 인식 및 검색 결과를 데이터베이스화한 제4 화면을 표시할 수 있 다. 이 경우, 전자 장치는 왜곡 제거 이미지인 플랫 라벨 이미지들을 미리보기 형태로 표시할 수 있다. 각각의 플랫 라벨 이미지들을 선택하면, 제 3화면과 같이, 선택된 플랫 라벨 이미지에 대응하는 와 인 정보들이 다시 표시될 수 있다. 도 23b는 본 개시의 일 실시예에 따른 또다른 형태의 전자 장치의 동작을 설명하기 위한 도면이다. 전술한 도면들의 예시에서, 일 실시예에 따른 전자 장치가 카메라를 포함하는 스마트폰임을 가정하여 설 명하였으나, 전술한 전자 장치의 동작들은 카메라 및/또는 디스플레이를 포함하는 다양한 종류 및 형태의 다른 전자 장치에 의해 수행될 수도 있다. 도 23b를 참조하여, 다른 형태의 전자 장치에 의한 동작들의 예시를 설명할 것이다. 도 23b를 설명함에 있어서, 전자 장치 및 다른 종류의 전자 장치 각각을 제1 전자 장치 및 제2 전자 장치라고 구별하여 지칭할 것이다. 다만, 전자 장치의 접두사로 사용되는 제1, 제2 등의 서수 번호는 각각의 독립적인 전자 장치들을 구별하기 위한 것일 뿐, 어떠한 순서 등을 한정하기 위한 것은 아니다. 즉, 전술한 도면들에서 설명한 동작들이 제1 전자 장치에서 독립적으로 수행될 수 있고, 제2 전자 장치 에서 독립적으로 수행될 수도 있다. 또한, 제1 전자 장치와 제2 전자 장치가 통신 연결되어 데이터 통신을 수행하고, 이전의 도면들에서 서술한 동작들을 연계하여 수행할 수도 있다. 도 23b를 참조하면, 제2 전자 장치는 와인 냉장고(또는, 스마트 냉장고)일 수 있다. 제2 전자 장치(300 2)는 하나 이상의 카메라들(제1 카메라, 제2 카메라, 및 제3 카메라)을 포함할 수 있다. 또 한, 제2 전자 장치는 몸체 및 도어를 포함할 수 있다. 일 실시예에서, 제2 전자 장치는, 제2 전자 장치의 외부를 바라보도록 배치된 제1 카메라를 포함할 수 있다. 예를 들어, 제1 카메라는 제2 전자 장치의 전면부 중앙(도어 외측)에 위치할 수 있다. 다만, 제1 카메라의 배치 위치는 이에 한정되는 것은 아니다. 예를 들어, 제1 카메라는 제2 전자 장치의 측면, 상부 등에 배치될 수 있고, 하나 이상의 제1 카메라들이 배치될 수도 있다. 제2 전자 장치의 사용자는 제1 카메라를 이용하여 객체를 촬영할 수 있다. 예를 들어, 사용자는 제2 전 자 장치에 상품을 보관하기 이전에, 제2 전자 장치의 도어가 닫힌 상태에서 객체의 관심 영 역이 촬영될 수 있도록, 객체의 관심 영역(예를 들어, 와인 라벨)을 제1 카메라에 비출 수 있다. 제2 전 자 장치는 제1 카메라를 이용하여 객체 이미지를 획득하고, 객체 모양 기반 및/또는 관심 영역 모 양 기반으로 3D 피팅을 수행하고, 관심 영역에 대한 왜곡 제거 이미지와 객체 정보를 생성할 수 있다. 일 실시 예에서, 제2 전자 장치는 추출된 객체(상품) 정보에 기초하여 촬영된 상품의 보관 위치 및 보관 모드 중 적어도 하나를 사용자에게 추천할 수 있다. 예를 들어, 제2 전자 장치는 촬영된 상품을 제2 전자 장치 의 수납 공간 중 멀티 팬트리에 보관할 것을 추천할 수 있다. 또는, 제2 전자 장치는 촬영된 상품 이 와인으로 식별되는 경우, 와인 보관 모드를 실행할 것을 사용자에게 추천할 수 있다. 또는, 제2 전자 장치 는 와인 보관 모드를 자동으로 실행할 수 있다. 일 실시예에서, 제2 전자 장치는, 제2 전자 장치의 수납 공간 내부를 바라보도록 배치된 카메라를 포함할 수 있다. 예를 들어, 제2 전자 장치의 몸체에 제2 카메라가 위치할 수 있다. 제2 카 메라는 제2 전자 장치의 몸체 내부를 촬영하여, 제2 전자 장치 몸체 내부 수납 공간(예를 들어, 와인 랙, 와인 박스, 멀티 팬트리 등)에 수납된 객체(예를 들어, 와인 병)를 촬영할 수 있다.제2 전자 장치는 제2 카메라를 이용하여 객체 이미지를 획득하고, 객체 모양 기반 및/또는 관심 영 역 모양 기반으로 3D 피팅을 수행하고, 관심 영역에 대한 왜곡 제거 이미지와 객체 정보를 생성할 수 있다. 일 실시예에서, 제2 전자 장치는 수납된 객체(상품) 정보에 기초하여 제2 전자 장치의 동작 모드를 사 용자에게 추천하거나, 최적의 동작 모드를 자동으로 실행할 수 있다. 예를 들어, 제2 전자 장치는 수납된 상품이 와인으로 식별되는 경우, 와인 보관 모드를 실행할 것을 사용자에게 추천할 수 있다. 또는, 제2 전자 장 치는 와인 보관 모드를 자동으로 실행할 수 있다. 한편, 제2 카메라의 배치 위치는 도 23b에 도시 된 예시에 한정되는 것은 아니며, 제2 전자 장치의 수납 공간 내부를 바라볼 수 있는 가능한 또다른 위치 들을 포함할 수 있다. 또한, 제2 카메라는 하나 이상일 수 있다. 일 실시예에서, 제2 전자 장치는, 제2 전자 장치의 도어 내측을 바라보는 제3 카메라 를 포함할 수 있다. 사용자는 제2 전자 장치의 제3 카메라를 이용하여 객체를 촬영할 수 있다. 예 를 들어, 사용자는 제2 전자 장치의 도어를 열고, 제2 전자 장치에 상품을 보관하기 이전에, 객체의 관심 영역이 촬영될 수 있도록 객체의 관심 영역(예를 들어, 와인 라벨)을 제3 카메라에 비출 수 있다. 제2 전자 장치는 제3 카메라를 이용하여 객체 이미지를 획득하고, 객체 모양 기반 및/또는 관심 영역 모양 기반으로 3D 피팅을 수행하고, 관심 영역에 대한 왜곡 제거 이미지와 객체 정보를 생성할 수 있 다. 일 실시예에서, 제2 전자 장치는 추출된 객체(상품) 정보에 기초하여 촬영된 상품의 보관 위치 및 보 관 모드 중 적어도 하나를 사용자에게 추천할 수 있다. 예를 들어, 제2 전자 장치는 촬영된 상품을 제2 전자 장치의 수납 공간 중 멀티 팬트리에 보관할 것을 추천할 수 있다. 또는, 제2 전자 장치는 촬 영된 상품이 와인으로 식별되는 경우, 와인 보관 모드를 실행할 것을 사용자에게 추천할 수 있다. 또는, 제2 전 자 장치는 와인 보관 모드를 자동으로 실행할 수도 있다. 일 실시예에서, 제2 전자 장치는 디스플레이를 포함할 수 있다. 제2 전자 장치는 디스플레이를 이 용하여 카메라를 이용하여 촬영되는 객체의 프리뷰 이미지를 표시하거나, 왜곡 제거 이미지, 객체 정보 등을 디 스플레이의 화면에 표시할 수 있다. 또한, 제2 전자 장치는 상품 관리 및 동작 모드 제어 등이 가능한 애 플리케이션의 실행 화면을 디스플레이를 이용하여 표시할 수도 있다. 일 실시예에서, 제2 전자 장치에 포함되는 하나 이상의 카메라들(제1 카메라, 제2 카메라, 및 제3 카메라)를 이용하여 객체가 촬영되면, 제2 전자 장치는 객체를 등록하고, 객체가 등록되었 음을 나타내는 알림을 사용자에게 제공할 수 있다. 알림은 제2 전자 장치에서 시각적 및/또는 청각적인 형태로 출력될 수 있다. 또는, 알림은 제2 전자 장치와 연계된 제1 전자 장치를 통해 시각적 및/ 또는 청각적인 형태로 출력될 수도 있다. 일 실시예에서, 객체가 등록되면, 왜곡 제거 이미지 및/또는 객체 정보가 제2 전자 장치 및/또는 제1 전 자 장치에 설치된 애플리케이션 등을 통해 사용자에게 제공될 수 있다. 객체 정보는 객체에 대한 상세 정 보, 객체와 관련된 정보, 객체와 연계 가능한 전자 장치와 관련된 정보를 포함할 수 있으나, 이에 한정되는 것 은 아니다. 객체가 와인인 경우를 구체적인 예로 들면, 와인에 대한 상세 정보인 '이름, 입고일, 보관 위치' 등 이 사용자에게 제공될 수 있다. 또한, 와인과 관련된 정보인 '와인 마시는 방법, 곁들이면 좋은 음식, 와인에 대한 리뷰' 등이 사용자에게 제공될 수 있다. 또한, 와인과 연계 가능한 전자 장치와 관련된 정보인 '와인 냉장 고의 동작 모드, 와인 냉장고 내 재고 현황, 와인과 곁들일 음식을 조리하기 위한 냉장고 식재료 현황, 조리를 위한 오븐의 동작 모드' 등이 사용자에게 제공될 수 있다. 일 실시예에서, 제2 전자 장치는 카메라를 이용하여 촬영된 이미지를 처리할 때, 서버를 이용할 수도 있 다. 제2 전자 장치는 객체 이미지를 서버로 전송하고, 서버로부터 왜곡 제거 이미지와 객체 정보를 수신 할 수 있다. 수신된 왜곡 제거 이미지 및 객체 정보는, 제2 전자 장치 및/또는 제1 전자 장치에 설 치된 애플리케이션 등을 통해 사용자에게 제공될 수 있다. 도 24는 본 개시의 일 실시예에 따른 전자 장치가 왜곡 제거 이미지를 활용하는 동작을 설명하기 위한 도면이다. 전자 장치는 객체 이미지를 획득할 수 있다. 전자 장치는 전술한 도면들에서 설명한 동작들 을 통해 객체 이미지 내 관심 영역만을 추출하고 3차원 왜곡을 제거한, 왜곡 제거 이미지를 획득할 수 있 다. 일 실시예에서, 전자 장치는 왜곡 제거 이미지를 객체에 합성한, 제1 상품 이미지를 생성할 수 있다. 제1 상품 이미지는, 객체 이미지에 왜곡 제거 이미지를 합성함으로써 획득될 수 있다. 제1 상품 이미지를 참조하면, 객체인 와인 병에는 빛 반사가 있지만, 왜곡 제거 이미지에는 빛 반사가 없어 합성된 상품 이미지가 부자연스럽게 나타난다. 전자 장치는 제1 상품 이미지에 소정의 이미지 처리 알고리즘을 적용하여, 상품 이미지에 왜곡 제거 이미지가 보다 자연스럽게 합성된, 제2 상품 이미지를 획 득할 수 있다. 제2 상품 이미지를 참조하면, 제1 상품 이미지와 달리 이미지 처리 알고리즘을 통해 생성된 빛 반사 영역이 포함된다. 이미지 처리 알고리즘은 예를 들어, 알파 블렌딩 알고리즘일 수 있으나, 이에 한정되는 것은 아니다. 전자 장치는 제2 상품 이미지를 생성함으로써, 매끄럽고 자연스럽게 보이는 방식으로 상품 이미지 를 생성하여 보다 사실적이고 시각적으로 매력적인 이미지를 사용자에게 제공할 수 있다. 도 25는 본 개시의 일 실시예에 따른 전자 장치가 이미지를 처리하는 동작에 관련된 시스템의 일 예시를 설명하 기 위한 도면이다. 일 실시예에서, 전자 장치가 사용하는 모델들은, 신경망 연산을 수행하기에 적합한 다른 전자 장치(예를 들어, 로컬 PC 등)에서 훈련된 것일 수 있다. 예를 들어, 객체 검출 모델, 관심 영역 검출 모델, 객체 3차원 모 양 분류 모델, 3D 피팅 모델, 정보 추출 모델 등이 다른 전자 장치에서 훈련되어 학습 완료된 상태로 저장되어 있을 수 있다. 일 실시예에서, 전자 장치는 다른 전자 장치에 저장된, 훈련된 모델들을 수신할 수 있다. 전자 장치 는 수신된 모델들에 기초하여, 전술한 이미지 처리 동작들을 수행할 수 있다. 이 경우, 전자 장치 는 훈련된 모델들을 실행하여 추론 동작을 수행하고, 관심 영역에 대한 왜곡 제거 이미지와 객체에 관련된 정보 를 생성할 수 있다. 생성된 왜곡 제거 이미지 및 객체에 관련된 정보는, 애플리케이션 등을 통해 사용자에게 제 공될 수 있다. 도 25에서는, 전자 장치의 예시로 모바일 폰에 모델이 저장되어 사용되는 것을 예시로 설 명하였으나, 이에 한정되는 것은 아니다. 전자 장치는 TV, 태블릿 PC, 스마트 냉장고 등, 애플리케이션의 실행이 가능하고 디스플레이 및 카메라가 탑재된 모든 종류의 전자 장치를 포함할 수 있다. 한편, 이전 도면들의 설명에서 기술한 것처럼, 전자 장치가 사용하는 모델들은, 전자 장치의 컴퓨 팅 자원을 이용하여 훈련될 수 있다. 이에 대한 구체적인 설명은 전술하였으므로, 반복되는 설명은 생략한다. 도 26은 본 개시의 일 실시예에 따른 전자 장치가 서버를 이용하여 이미지를 처리하는 동작에 관련된 시스템의 일 예시를 설명하기 위한 도면이다. 일 실시예에서, 전자 장치가 사용하는 모델들은, 신경망 연산을 수행하기에 적합한 다른 전자 장치(예를 들어, 로컬 PC 등)에서 훈련된 것일 수 있다. 예를 들어, 객체 검출 모델, 관심 영역 검출 모델, 객체 3차원 모 양 분류 모델, 3D 피팅 모델, 정보 추출 모델 등이 다른 전자 장치에서 훈련되어 학습 완료된 상태로 저장되어 있을 수 있다. 또한, 다른 전자 장치(예를 들어, 로컬 PC 등)에서 훈련된 모델들은, 또다른 전자 장치(예를 들 어, 서버 등)로 전송되어 저장될 수 있다. 일 실시예에서, 전자 장치는 서버를 이용하여 이미지 처리 동작들을 수행할 수 있다. 전자 장치는 카메라를 이용하여 객체 이미지들(예를 들어, 망원 이미지, 광각 이미지, 초광각 이미지 등)을 촬영하고, 이미 지들을 서버로 전송할 수 있다. 이 경우, 서버는 훈련된 모델들을 실행하여 추론 동작을 수행하고, 관심 영역에 대한 왜곡 제거 이미지와 객체 정보를 생성할 수 있다. 전자 장치는 서버로부터 왜곡 제거 이미지와 객체 정보를 수신할 수 있다. 수신된 왜곡 제거 이미지 및 객체 정보는, 애플리케이션 등을 통해 사용자에게 제공될 수 있다. 도 26에서는, 전자 장치의 예시로 모바일 폰에 모델이 저장되어 사용되는 것을 예시로 설명하였 으나, 이에 한정되는 것은 아니다. 전자 장치는 TV, 태블릿 PC, 스마트 냉장고 등등, 애플리케이션을 실 행 가능하고 디스플레이 및 카메라가 탑재된 모든 종류의 전자 장치를 포함할 수 있다. 한편, 이전 도면들의 설명에서 기술한 것처럼, 전자 장치가 사용하는 모델들은, 전자 장치의 컴퓨 팅 자원을 이용하여 훈련될 수 있다. 이에 대한 구체적인 설명은 전술하였으므로, 반복되는 생략한다. 도 27은 본 개시의 일 실시예에 따른 전자 장치의 구성을 도시한 블록도이다. 일 실시예에 따른 전자 장치는 통신 인터페이스, 카메라(들), 메모리 및 프로세서 를 포함할 수 있다. 통신 인터페이스는 프로세서의 제어에 의해 다른 전자 장치들과 데이터 통신을 수행할 수 있다. 통신 인터페이스는 통신 회로를 포함할 수 있다. 통신 인터페이스는 예를 들어, 유선 랜, 무선 랜 (Wireless LAN), 와이파이(Wi-Fi), 블루투스(Bluetooth), 지그비(ZigBee), WFD(Wi-Fi Direct), 적외선 통신 (IrDA, infrared Data Association), BLE (Bluetooth Low Energy), NFC(Near Field Communication), 와이브로 (Wireless Broadband Internet, Wibro), 와이맥스(World Interoperability for Microwave Access, WiMAX), SWAP(Shared Wireless Access Protocol), 와이기그(Wireless Gigabit Alliances, WiGig) 및 RF 통신을 포함하 는 데이터 통신 방식 중 적어도 하나를 이용하여, 전자 장치와 다른 디바이스들 간의 데이터 통신을 수행 할 수 있는, 통신 회로를 포함할 수 있다. 통신 인터페이스는 전자 장치의 이미지 처리 동작을 수행하기 위한 데이터를 외부 전자 장치와 송 수신할 수 있다. 예를 들어, 통신 인터페이스는 전자 장치가 이용하는 인공지능 모델들을 송수신하 거나, 인공지능 모델들의 훈련 데이터셋을 서버 등과 송수신할 수 있다. 또한, 전자 장치는 왜곡이 제거 되어야 할 이미지를 서버 등으로부터 획득할 수 있다. 또한, 전자 장치는 객체와 관련된 정보를 검색하기 위해 서버 등과 데이터를 송수신할 수 있다. 카메라(들)는 객체를 촬영하여 비디오 및/또는 이미지를 획득할 수 있다. 카메라(들)는 하나 이상 일 수 있다. 카메라(들)는 예를 들어, RGB 카메라, 망원 카메라, 광각 카메라, 초광각 카메라 등을 포함 할 수 있으나, 이에 한정되는 것은 아니다. 카메라(들)는 복수의 프레임들을 포함하는 비디오를 획득할 수 있다. 카메라(들)의 구체적인 종류 및 세부 기능은 통상의 기술자가 명확하게 추론할 수 있으므로, 설 명을 생략한다. 메모리는 프로세서가 판독할 수 있는 명령어들, 데이터 구조, 및 프로그램 코드(program code)가 저장될 수 있다. 메모리는 하나 이상일 수 있다. 개시된 실시예에서, 프로세서가 수행하는 동작들 은 메모리에 저장된 프로그램의 명령어들 또는 코드들을 실행함으로써 구현될 수 있다. 메모리는 플래시 메모리 타입(flash memory type), 하드디스크 타입(hard disk type), 멀티미디어 카드 마이크로 타입(multimedia card micro type), 카드 타입의 메모리(예를 들어 SD 또는 XD 메모리 등)를 포함할 수 있으며, 롬(ROM, Read-Only Memory), EEPROM(Electrically Erasable Programmable Read-Only Memory), PROM(Programmable Read-Only Memory), 자기 메모리, 자기 디스크, 광디스크 중 적어도 하나를 포함하는 비 휘 발성 메모리 및 램(RAM, Random Access Memory) 또는 SRAM(Static Random Access Memory)과 같은 휘발성 메모 리를 포함할 수 있다. 일 실시예에 따른 메모리는 전자 장치가 이미지 내 왜곡을 제거하기 위해 동작하도록 하는 하나 이 상의 인스트럭션 및/또는 프로그램을 저장할 수 있다. 예를 들어, 메모리에는 객체 검출 모듈, 관 심 영역 검출 모듈, 객체 3차원 모양 식별 모듈, 3D 피팅 모듈, 왜곡 제거 모듈, 정 보 추출 모듈이 저장될 수 있다. 프로세서는 전자 장치의 전반적인 동작들을 제어할 수 있다. 예를 들어, 프로세서는 메모리 에 저장된 프로그램의 하나 이상의 명령어들(instructions)을 실행함으로써, 전자 장치가 이미지에 서 왜곡을 제거하기 위한 전반적인 동작들을 제어할 수 있다. 프로세서는 하나 이상일 수 있다. 본 개시에 따른 하나 이상의 프로세서는 CPU (Central Processing Unit), GPU (Graphics Processing Unit), APU (Accelerated Processing Unit), MIC (Many Integrated Core), DSP (Digital Signal Processor), 및 NPU (Neural Processing Unit) 중 적어도 하나를 포함할 수 있다. 하나 이상의 프로세서는, 하나 이 상의 전자부품을 포함하는 집적된 시스템 온 칩(SoC) 형태로 구현될 수 있다. 하나 이상의 프로세서 각각은 별 개의 하드웨어(H/W)로 구현될 수도 있다. 프로세서는 객체 검출 모듈을 실행하여 이미지 내에서 객체를 검출하고 객체의 외곽선을 나타내는 객체 키 포인트들을 획득할 수 있다. 객체 검출 모듈은 인공지능 모델인 객체 검출 모델을 포함할 수 있 다. 객체 검출 모듈에 관련된 전자 장치의 동작들은, 이전의 도면들에서 상세하게 설명하였으므로, 반복되는 설명은 생략한다. 프로세서는 관심 영역 검출 모듈을 실행하여 객체의 관심 영역을 검출할 수 있다. 예를 들어, 프로 세서는 관심 영역 검출 모듈을 이용하여 관심 영역 히트 맵, 관심 영역 키 포인트들을 검출할 수 있다. 관심 영역 검출 모듈은 인공지능 모델인 관심 영역 검출 모델을 포함할 수 있다. 관심 영역 검출 모듈에 관련된 전자 장치의 동작들은, 이전의 도면들에서 상세하게 설명하였으므로, 반복되는 설명 은 생략한다. 프로세서는 객체 3차원 모양 식별 모듈을 실행하여 객체의 3차원 모양 타입을 분류할 수 있다. 객 체 3차원 모양 식별 모듈은 인공지능 모델인 객체 3차원 분류 모델을 포함할 수 있다. 객체 3차원 모양 식별 모듈에 관련된 전자 장치의 동작들은, 이전의 도면들에서 상세하게 설명하였으므로, 반복되는 설명은 생략한다. 프로세서는 3D 피팅 모듈을 실행하여 객체의 3차원 정보를 추론할 수 있다. 프로세서는 3D 피팅 모듈을 이용하여 객체의 원본 3차원 모양을 나타내는 3차원 파라미터를 추론할 수 있다. 3D 피팅 모듈 에 관련된 전자 장치의 동작들은, 이전의 도면들에서 상세하게 설명하였으므로, 반복되는 설명은 생략한다. 프로세서는 왜곡 제거 모듈을 실행하여 이미지 내 3차원 왜곡을 제거할 수 있다. 프로세서는 원근 변환 알고리즘을 이용하여 객체의 3차원 정보를 바탕으로 관심 영역을 디워핑할 수 있다. 왜곡 제거 모듈 에 관련된 전자 장치의 동작들은, 이전의 도면들에서 상세하게 설명하였으므로, 반복되는 설명은 생략한다. 프로세서는 정보 추출 모듈을 실행하여, 왜곡 제거 이미지로부터 정보를 추출할 수 있다. 정보 추 출 모듈은 인공지능 모델인 정보 추출 모델을 포함할 수 있다. 프로세서는 정보 추출 모듈을 이용하여 관심 영역 내 정보를 추출하며, 예를 들어, 관심 영역 내의 로고, 아이콘, 텍스트 등을 식별할 수 있 다. 정보 추출 모듈에 관련된 전자 장치의 동작들은, 이전의 도면들에서 상세하게 설명하였으므로, 동일한 설명은 생략한다. 한편, 전술한 메모리에 저장된 모듈들은, 설명의 편의를 위한 것이며 반드시 이에 한정되는 것은 아니다. 전술한 실시예를 구현하기 위해 다른 모듈이 추가될 수 있으며, 전술한 모듈들 중 일부의 모듈들은 하나의 모듈 로 구현될 수도 있다. 본 개시의 일 실시예에 따른 방법이 복수의 동작을 포함하는 경우, 복수의 동작은 하나의 프로세서에 의해 수행 될 수도 있고, 복수의 프로세서에 의해 수행될 수도 있다. 예를 들어, 일 실시예에 따른 방법에 의해 제1 동작, 제2 동작, 제3 동작이 수행될 때, 제1 동작, 제2 동작, 및 제3 동작 모두 제1 프로세서에 의해 수행될 수도 있 고, 제1 동작 및 제2 동작은 제1 프로세서(예를 들어, 범용 프로세서)에 의해 수행되고 제3 동작은 제2 프로세 서(예를 들어, 인공지능 전용 프로세서)에 의해 수행될 수도 있다. 여기서, 제2 프로세서의 예시인 인공지능 전 용 프로세서는, 인공지능 모델의 훈련/추론을 위한 연산들이 수행될 수도 있다. 그러나, 본 개시의 실시예가 이 에 한정되는 것은 아니다. 본 개시에 따른 하나 이상의 프로세서는 싱글 코어 프로세서(single-core processor)로 구현될 수도 있고, 멀티 코어 프로세서(multi-core processor)로 구현될 수도 있다. 본 개시의 일 실시예에 따른 방법이 복수의 동작을 포함하는 경우, 복수의 동작은 하나의 코어에 의해 수행될 수도 있고, 하나 이상의 프로세서에 포함된 복수의 코어에 의해 수행될 수도 있다. 도 27에 도시 되지는 않았지만, 전자 장치는 사용자 인터페이스를 더 포함할 수 있다. 사용자 인터페이스 는 사용자의 입력을 수신하는 입력 인터페이스와 정보를 출력하는 출력 인터페이스를 포함할 수 있다. 출력 인터페이스는 비디오 신호 또는 오디오 신호의 출력을 위한 것이다. 출력 인터페이스는 디스플레이부, 음 향 출력부, 진동 모터 등을 포함할 수 있다. 디스플레이부와 터치패드가 레이어 구조를 이루어 터치스크린으로 구성되는 경우, 디스플레이부는 출력 인터페이스 이외에 입력 인터페이스로도 사용될 수 있다. 디스플레이부는 액정 디스플레이(liquid crystal display), 박막 트랜지스터 액정 디스플레이(thin film transistor-liquid crystal display), 발광 다이오드(LED, light-emitting diode), 유기 발광 다이오드(organic light-emitting diode), 플렉시블 디스플레이(flexible display), 3차원 디스플레이(3D display), 전기영동 디스플레이 (electrophoretic display) 중에서 적어도 하나를 포함할 수 있다. 그리고 전자 장치의 구현 형태에 따라 전자 장치는 디스플레이부를 2개 이상 포함할 수도 있다. 음향 출력부는 통신 인터페이스로부터 수신되거나 메모리에 저장된 오디오 신호를 출력할 수 있다. 또한, 음향 출력부는 전자 장치에서 수행되는 기능과 관련된 음향 신호를 출력할 수 있다. 음향 출력부는 스피커(speaker), 부저(Buzzer) 등을 포함할 수 있다. 입력 인터페이스는, 사용자로부터의 입력을 수신하기 위한 것이다. 입력 인터페이스는, 키 패드(key pad), 돔 스위치 (dome switch), 터치 패드(접촉식 정전 용량 방식, 압력식 저항막 방식, 적외선 감지 방식, 표면 초음파 전도 방식, 적분식 장력 측정 방식, 피에조 효과 방식 등), 조그 휠, 조그 스위치 중 적어도 하나일 수 있으나,이에 한정되는 것은 아니다. 입력 인터페이스는, 음성 인식 모듈을 포함할 수 있다. 예를 들어, 전자 장치는 마이크로폰을 통해 아날 로그 신호인 음성 신호를 수신하고, ASR(Automatic Speech Recognition) 모델을 이용하여 음성 부분을 컴퓨터로 판독 가능한 텍스트로 변환할 수 있다. 전자 장치는 자연어 이해(Natural Language Understanding, NLU) 모델을 이용하여 변환된 텍스트를 해석하여, 사용자의 발화 의도를 획득할 수 있다. 여기서 ASR 모델 또는 NLU 모델은 인공지능 모델일 수 있다. 언어적 이해는 인간의 언어/문자를 인식하고 응용/처리하는 기술로서, 자연어 처리(Natural Language Processing), 기계 번역(Machine Translation), 대화 시스템(Dialog System), 질의 응 답(Question Answering), 음성 인식/합성(Speech Recognition/Synthesis) 등을 포함한다. 도 28은 본 개시의 일 실시예에 따른 서버의 구성을 도시한 블록도이다. 일 실시예에서, 전술한 전자 장치의 동작들은, 서버에서 수행될 수 있다. 일 실시예에 따른 서버는 통신 인터페이스, 메모리 및 프로세서를 포함할 수 있다. 서 버의 통신 인터페이스, 메모리 및 프로세서는 도 27의 전자 장치의 통신 인터페 이스, 메모리 및 프로세서에 각각 대응되므로, 동일한 설명은 생략한다. 일 실시예에 따른 서버는, 전자 장치 보다 연산량이 많은 연산을 수행 가능하도록, 컴퓨팅 성능이 전자 장치보다 높은 장치일 수 있다. 서버는 추론에 비해 상대적으로 많은 연산량이 요구되는, 인 공지능 모델의 훈련을 수행할 수 있다. 서버는 인공지능 모델을 이용하여 추론을 수행하고, 추론 결과를 전자 장치로 전송할 수 있다. 본 개시는, 3차원 정보를 활용한 이미지 왜곡 제거 방법에 있어서, 3차원 정보 획득을 위한 센서 등의 하드웨어 없이, 알고리즘을 이용하여 객체의 3차원 정보를 추론하고, 이미지 내 왜곡을 제거하는 이미지 처리 방법을 제 시한다. 본 개시에서 이루고자 하는 기술적 과제는, 이상에서 언급한 것으로 제한되지 않으며, 언급되지 않은 또 다른"}
{"patent_id": "10-2023-0044355", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "기술적 과제들은 아래의 기재로부터 본 발명이 속하는 기술분야에서 통상의 지식을 가진 자에게 명확하게 이해 될 수 있을 것이다. 본 개시의 일 측면에 따르면, 전자 장치가 이미지를 처리하는 방법이 제공될 수 있다. 상기 방법은, 카메라를 이용하여 객체의 이미지를 획득하는 단계를 포함할 수 있다. 상기 방법은, 상기 객체의 표면의 관심 영역을 검 출하는 단계를 포함할 수 있다. 상기 방법은, 상기 객체의 외곽선을 나타내는, 객체 키 포인트들을 검출하는 단 계 를 포함할 수 있다. 상기 방법은, 상기 객체 키 포인트들에 기초하여, 상기 객체의 3차원 모양을 나타내는 3 차원 파라미터의 값들을 추론하되, 상기 3차원 파라미터는, 상기 객체의 3차원의 기하학적 정보를 나타내는 피 처들을 포함하는 것인, 단계를 포함할 수 있다. 상기 방법은, 상기 3차원 파라미터에 기초하여 상기 이미지에 대해 원근 변환을 수행함으로써, 상기 관심 영역이 평면으로 수정된 왜곡 제거 이미지를 획득하는 단계를 포함 할 수 있다. 상기 방법은, 상기 왜곡 제거 이미지로부터 상기 관심 영역 내 정보를 추출하는 단계를 포함할 수 있다. 상기 3차원 파라미터의 피처들은, 상기 객체의 3차원 회전, 이동, 치수, 스케일링, 카메라 파라미터 중 적어도 하나에 대응하는 것일 수 있다. 상기 객체의 3차원 모양을 나타내는 3차원 파라미터의 값들을 추론하는 단계는, 기 설정된 값을 갖는 초기 3차 원 파라미터를 획득하는 단계를 포함할 수 있다. 상기 객체의 3차원 모양을 나타내는 3차원 파라미터의 값들을 추론하는 단계는, 상기 초기 3차원 파라미터에 기 초하여, 가상 객체의 3차원 모양을 렌더링하는 단계를 포함할 수 있다. 상기 객체의 3차원 모양을 나타내는 3차원 파라미터의 값들을 추론하는 단계는, 상기 가상 객체의 외곽선을 나 타내는 초기 키 포인트들을 생성하는 단계를 포함할 수 있다. 상기 객체의 3차원 모양을 나타내는 3차원 파라미터의 값들을 추론하는 단계는, 상기 초기 키 포인트들이 상기 객체 키 포인트들에 정합하도록 상기 초기 3차원 파라미터의 값들을 조정함으로써, 상기 객체의 원본 3차원 모 양을 나타내는 3차원 파라미터의 값들을 획득하는 단계를 포함할 수 있다. 상기 방법은, 상기 관심 영역의 모양을 식별하는 단계를 포함할 수 있다. 상기 방법은, 상기 관심 영역의 모양이 정형화된 디자인에 포함되는지 여부를 식별하는 단계를 포함할 수 있다. 상기 객체 키 포인트들을 검출하는 단계는, 상기 관심 영역의 모양이 비정형화된 디자인인 것에 기초하여 상기 객체 키 포인트들을 검출하는 것일 수 있다. 상기 방법은, 상기 관심 영역의 모양이 정형화된 디자인에 포함되는 것에 기초하여, 상기 관심 영역의 외곽선을 나타내는, 관심 영역 키 포인트들을 획득하는 단계를 포함할 수 있다. 상기 객체의 3차원 모양을 나타내는 3차원 파라미터의 값들을 추론하는 단계는, 상기 관심 영역 키 포인트들에 기초하여, 상기 3차원 파라미터의 값들을 추론하는 단계를 포함할 수 있다. 상기 객체의 표면의 관심 영역을 검출하는 단계는, 라벨 검출 모델을 이용하는 것일 수 있다. 상기 라벨 검출 모델은, 상기 이미지를 입력 받아 상기 객체의 상기 라벨을 나타내는 데이터를 출력하도록 훈련 된 인공지능 모델인 것일 수 있다. 상기 객체 키 포인트들을 검출하는 단계는, 객체 검출 모델을 이용하는 것일 수 있다. 상기 객체 검출 모델은, 상기 이미지를 입력 받아 상기 객체의 외곽선을 나타내는 키 포인트들을 출력하도록 훈 련된 인공지능 모델인 것일 수 있다. 상기 방법은, 상기 객체의 3차원 모양 타입을 식별하는 단계를 포함할 수 있다. 상기 객체의 3차원 모양을 나타내는 3차원 파라미터의 값들을 추론하는 단계는, 상기 객체의 3차원 모양 타입에 기초하여 상기 3차원 파라미터의 값들을 추론하는 것일 수 있다. 상기 객체의 3차원 모양을 나타내는 3차원 파라미터의 값들을 추론하는 단계는, 복수의 3차원 모양 타입들 중에 서, 상기 식별된 3차원 모양 타입에 대응하는 피처들이 포함되는 3차원 파라미터를 선택하는 단계를 포함할 수 있다. 상기 기 설정된 값을 갖는 초기 3차원 파라미터는, 상기 식별된 3차원 모양 타입에 대응하는 피처들의 기 설정 된 값들이 획득되는 것일 수 있다. 상기 관심 영역 내 정보를 추출하는 단계는, 상기 왜곡 제거 이미지에 광학 문자 인식(Optical character recognition; OCR)을 적용하는 단계를 포함할 수 있다. 본 개시의 일 측면에 따르면, 이미지를 처리하는 전자 장치가 제공될 수 있다. 상기 전자 장치는, 하나 이상의 카메라들; 하나 이상의 인스트럭션을 저장하는 메모리; 및 상기 메모리에 저장된 상기 하나 이상의 인스트럭션 을 실행하는 적어도 하나의 프로세서를 포함할 수 있다. 상기 적어도 하나의 프로세서는, 상기 하나 이상의 인 스트럭션을 실행함으로써, 상기 하나 이상의 카메라들을 통해 객체의 이미지를 획득할 수 있다. 상기 적어도 하 나의 프로세서는, 상기 하나 이상의 인스트럭션을 실행함으로써, 상기 객체의 표면의 관심 영역을 검출할 수 있 다. 상기 적어도 하나의 프로세서는, 상기 하나 이상의 인스트럭션을 실행함으로써, 상기 객체의 외곽선을 나타 내는, 객체 키 포인트들을 검출할 수 있다. 상기 적어도 하나의 프로세서는, 상기 하나 이상의 인스트럭션을 실 행함으로써, 상기 객체 키 포인트들에 기초하여, 상기 객체의 3차원 모양을 나타내는 3차원 파라미터의 값들을 추론하되, 상기 3차원 파라미터는, 상기 객체의 3차원의 기하학적 정보를 나타내는 피처들을 포함하는 것일 수 있다. 상기 적어도 하나의 프로세서는, 상기 하나 이상의 인스트럭션을 실행함으로써, 상기 3차원 파라미터에 기초하여 상기 이미지에 대해 원근 변환을 수행함으로써, 상기 관심 영역이 평면으로 수정된 왜곡 제거 이미지 를 획득할 수 있다. 상기 적어도 하나의 프로세서는, 상기 하나 이상의 인스트럭션을 실행함으로써, 상기 왜곡 제거 이미지로부터 상기 관심 영역 내 정보를 추출할 수 있다. 상기 3차원 파라미터의 피처들은, 상기 객체의 3차원 회전, 이동, 치수, 스케일링, 카메라 파라미터 중 적어도 하나에 대응하는 것일 수 있다. 상기 적어도 하나의 프로세서는, 상기 하나 이상의 인스트럭션을 실행함으로써, 기 설정된 값을 갖는 초기 3차 원 파라미터를 획득할 수 있다. 상기 적어도 하나의 프로세서는, 상기 하나 이상의 인스트럭션을 실행함으로써, 상기 초기 3차원 파라미터에 기 초하여, 가상 객체의 3차원 모양을 렌더링할 수 있다. 상기 적어도 하나의 프로세서는, 상기 하나 이상의 인스트럭션을 실행함으로써, 상기 가상 객체의 외곽선을 나 타내는 초기 키 포인트들을 생성할 수 있다. 상기 적어도 하나의 프로세서는, 상기 하나 이상의 인스트럭션을 실행함으로써, 상기 초기 키 포인트들이 상기 객체 키 포인트들에 정합하도록 상기 초기 3차원 파라미터의 값들을 조정함으로써, 상기 객체의 원본 3차원 모 양을 나타내는 3차원 파라미터의 값들을 획득할 수 있다. 상기 적어도 하나의 프로세서는, 상기 하나 이상의 인스트럭션을 실행함으로써, 상기 관심 영역의 모양을 식별 할 수 있다. 상기 적어도 하나의 프로세서는, 상기 하나 이상의 인스트럭션을 실행함으로써, 상기 관심 영역의 모양이 정형 화된 디자인에 포함되는지 여부를 식별할 수 있다. 상기 적어도 하나의 프로세서는, 상기 하나 이상의 인스트럭션을 실행함으로써, 상기 관심 영역의 모양이 비정 형화된 디자인인 것에 기초하여 상기 객체 키 포인트들을 검출할 수 있다. 상기 적어도 하나의 프로세서는, 상기 하나 이상의 인스트럭션을 실행함으로써, 상기 관심 영역의 모양이 정형 화된 디자인에 포함되는 것에 기초하여, 상기 관심 영역의 외곽선을 나타내는, 관심 영역 키 포인트들을 획득할 수 있다. 상기 적어도 하나의 프로세서는, 상기 하나 이상의 인스트럭션을 실행함으로써, 상기 관심 영역 키 포인트들에 기초하여, 상기 3차원 파라미터의 값들을 추론할 수 있다. 상기 객체의 표면의 관심 영역을 검출하는 것은, 라벨 검출 모델을 이용하는 것일 수 있다. 상기 라벨 검출 모델은, 상기 이미지를 입력 받아 상기 객체의 상기 라벨을 나타내는 데이터를 출력하도록 훈련 된 인공지능 모델인 것일 수 있다. 상기 객체 키 포인트들을 검출하는 것은, 객체 검출 모델을 이용하는 것일 수 있다. 상기 객체 검출 모델은, 상기 이미지를 입력 받아 상기 객체의 외곽선을 나타내는 키 포인트들을 출력하도록 훈 련된 인공지능 모델인 것일 수 있다. 상기 적어도 하나의 프로세서는, 상기 하나 이상의 인스트럭션을 실행함으로써, 상기 객체의 3차원 모양 타입을 식별할 수 있다. 상기 적어도 하나의 프로세서는, 상기 하나 이상의 인스트럭션을 실행함으로써, 상기 객체의 3차원 모양 타입에 기초하여 상기 3차원 파라미터의 값들을 추론할 수 있다. 상기 적어도 하나의 프로세서는, 상기 하나 이상의 인스트럭션을 실행함으로써, 복수의 3차원 모양 타입들 중에 서, 상기 식별된 3차원 모양 타입에 대응하는 피처들이 포함되는 3차원 파라미터를 선택할 수 있다. 상기 기 설정된 값을 갖는 초기 3차원 파라미터는, 상기 식별된 3차원 모양 타입에 대응하는 피처들의 기 설정 된 값들이 획득되는 것일 수 있다. 한편, 본 개시의 실시예들은 컴퓨터에 의해 실행되는 프로그램 모듈과 같은 컴퓨터에 의해 실행 가능한 명령어 를 포함하는 기록 매체의 형태로도 구현될 수 있다. 컴퓨터 판독 가능 매체는 컴퓨터에 의해 액세스 될 수 있는 임의의 가용 매체일 수 있고, 휘발성 및 비휘발성 매체, 분리형 및 비분리형 매체를 모두 포함한다. 또한, 컴퓨 터 판독 가능 매체는 컴퓨터 저장 매체 및 통신 매체를 포함할 수 있다. 컴퓨터 저장 매체는 컴퓨터 판독 가능 명령어, 데이터 구조, 프로그램 모듈 또는 기타 데이터와 같은 정보의 저장을 위한 임의의 방법 또는 기술로 구 현된 휘발성 및 비휘발성, 분리형 및 비분리형 매체를 모두 포함한다. 통신 매체는 전형적으로 컴퓨터 판독 가 능 명령어, 데이터 구조, 또는 프로그램 모듈과 같은 변조된 데이터 신호의 기타 데이터를 포함할 수 있다. 또한, 컴퓨터에 의해 읽을 수 있는 저장매체는, 비일시적(non-transitory) 저장매체의 형태로 제공될 수 있다. 여기서, '비일시적 저장매체'는 실재(tangible)하는 장치이고, 신호(signal)(예: 전자기파)를 포함하지 않는다 는 것을 의미할 뿐이며, 이 용어는 데이터가 저장매체에 반영구적으로 저장되는 경우와 임시적으로 저장되는 경 우를 구분하지 않는다. 예로, '비일시적 저장매체'는 데이터가 임시적으로 저장되는 버퍼를 포함할 수 있다. 일 실시예에 따르면, 본 문서에 개시된 다양한 실시예들에 따른 방법은 컴퓨터 프로그램 제품(computer program product)에 포함되어 제공될 수 있다. 컴퓨터 프로그램 제품은 상품으로서 판매자 및 구매자 간에 거래될 수 있 다. 컴퓨터 프로그램 제품은 기기로 읽을 수 있는 저장 매체(예: compact disc read only memory (CD-ROM))의 형태로 배포되거나, 또는 어플리케이션 스토어를 통해 또는 두개의 사용자 장치들(예: 스마트폰들) 간에 직접,온라인으로 배포(예: 다운로드 또는 업로드)될 수 있다. 온라인 배포의 경우에, 컴퓨터 프로그램 제품(예: 다운 로더블 앱(downloadable app))의 적어도 일부는 제조사의 서버, 어플리케이션 스토어의 서버, 또는 중계 서버의 메모리와 같은 기기로 읽을 수 있는 저장 매체에 적어도 일시 저장되거나, 임시적으로 생성될 수 있다."}
{"patent_id": "10-2023-0044355", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "전술한 본 개시의 설명은 예시를 위한 것이며, 본 개시가 속하는 기술분야의 통상의 지식을 가진 자는 본 개시 의 기술적 사상이나 필수적인 특징을 변경하지 않고서 다른 구체적인 형태로 쉽게 변형이 가능하다는 것을 이해 할 수 있을 것이다. 그러므로 이상에서 기술한 실시예들은 모든 면에서 예시적인 것이며 한정적이 아닌 것으로 이해해야만 한다. 예를 들어, 단일형으로 설명되어 있는 각 구성 요소는 분산되어 실시될 수도 있으며, 마찬가 지로 분산된 것으로 설명되어 있는 구성 요소들도 결합된 형태로 실시될 수 있다. 본 개시의 범위는 상기 상세한 설명보다는 후술하는 특허청구범위에 의하여 나타내어지며, 특허청구범위의 의미 및 범위 그리고 그 균등 개념으로부터 도출되는 모든 변경 또는 변형된 형태가 본 개시의 범위에 포함되는 것으 로 해석되어야 한다.도면 도면1 도면2 도면3 도면4a 도면4b 도면5a 도면5b 도면5c 도면6a 도면6b 도면6c 도면6d 도면7a 도면7b 도면8a 도면8b 도면9a 도면9b 도면9c 도면10a 도면10b 도면11a 도면11b 도면11c 도면11d 도면12 도면13a 도면13b 도면13c 도면14a 도면14b 도면14c 도면14d 도면14e 도면15a 도면15b 도면16 도면17a 도면17b 도면18a 도면18b 도면18c 도면18d 도면19 도면20a 도면20b 도면21a 도면21b 도면22a 도면22b 도면22c 도면23a 도면23b 도면24 도면25 도면26 도면27 도면28"}
{"patent_id": "10-2023-0044355", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 개시의 일 실시예에 따른 전자 장치가 이미지의 왜곡을 제거하는 일 예시를 나타내는 도면이다. 도 2는 본 개시의 일 실시예에 따른 전자 장치가 처리하는 이미지 내의 객체의 관심 영역 및 왜곡 제거 방법을 개략적으로 설명하기 위한 도면이다. 도 3은 본 개시의 일 실시예에 따른 전자 장치가 이미지를 처리하는 방법을 설명하기 위한 흐름도이다. 도 4a는 본 개시의 일 실시예에 따른 전자 장치가 이미지를 처리하는 동작을 전반적으로 설명하기 위한 도면이 다. 도 4b는 본 개시의 일 실시예에 따른 전자 장치가 이미지를 처리하는 동작을 개략적으로 설명하기 위한 도면이 다. 도 5a는 본 개시의 일 실시예에 따른 전자 장치가 객체 키 포인트들을 검출하는 동작을 설명하기 위한 도면이다. 도 5b는 본 개시의 일 실시예에 따른 객체 검출 모델의 트레이닝 데이터를 설명하기 위한 도면이다. 도 5c는 본 개시의 일 실시예에 따른 객체 검출 모델의 트레이닝 데이터를 추가적으로 설명하기 위한 도면이다. 도 6a는 본 개시의 일 실시예에 따른 전자 장치가 객체의 표면의 관심 영역을 식별하는 동작을 설명하기 위한 도면이다. 도 6b는 본 개시의 일 실시예에 따른 관심 영역 검출 모델의 트레이닝 데이터를 설명하기 위한 도면이다. 도 6c는 본 개시의 일 실시예에 따른 전자 장치가 관심 영역을 검출한 결과를 설명하기 위한 도면이다. 도 6d는 본 개시의 일 실시예에 따른 전자 장치가 관심 영역의 이미지를 처리하는 동작을 설명하기 위한 도면이 다. 도 7a는 본 개시의 일 실시예에 따른 전자 장치가 객체의 3차원 모양을 추론하기 위해 사용하는 3차원 파라미터 를 설명하기 위한 도면이다. 도 7b는 본 개시의 일 실시예에 따른 전자 장치가 객체 모양 기반으로 객체의 3차원 정보를 추론하는 동작을 설 명하기 위한 도면이다. 도 8a는 본 개시의 일 실시예에 따른 객체 모양 기반 3D 피팅 알고리즘을 설명하기 위한 도면이다. 도 8b는 본 개시의 일 실시예에 따른 객체 모양 기반 3D 피팅 알고리즘을 설명하기 위한 도면이다. 도 9a는 본 개시의 일 실시예에 따른 객체 모양 기반 3D 피팅 모델을 설명하기 위한 도면이다. 도 9b는 본 개시의 일 실시예에 따른 객체 모양 기반 3D 피팅 모델의 트레이닝 데이터 생성 방법을 설명하기 위 한 도면이다. 도 9c는 본 개시의 일 실시예에 따른 전자 장치가 객체 모양 기반 3D 피팅 모델을 훈련시키는 동작을 설명하기 위한 도면이다. 도 10a는 본 개시의 일 실시예에 따른 전자 장치가 이미지를 처리하는 과정을 설명하기 위한 도면이다. 도 10b는 본 개시의 일 실시예에 따른 전자 장치가 왜곡 제거 이미지로부터 정보를 추출한 예시를 설명하기 위 한 도면이다. 도 11a는 본 개시의 일 실시예에 따른 전자 장치가 관심 영역의 3차원 모양을 추론하기 위해 사용하는 3차원 파 라미터를 설명하기 위한 도면이다.도 11b는 본 개시의 일 실시예에 따른 전자 장치가 관심 영역 모양 기반으로 객체의 3차원 정보를 추론하는 동 작을 설명하기 위한 도면이다. 도 11c는 본 개시의 일 실시예에 따른 관심 영역 모양 기반 3D 피팅 알고리즘을 설명하기 위한 도면이다. 도 11d는 본 개시의 일 실시예에 따른 전자 장치가 관심 영역 모양 기반 3D 피팅 모델을 훈련시키는 동작을 설 명하기 위한 도면이다. 도 12는 본 개시의 일 실시예에 따른 객체 특징 추출 모델을 설명하기 위한 도면이다. 도 13a는 본 개시의 일 실시예에 따른 전자 장치가 3차원 파라미터를 추론하기 위해 이용할 데이터를 결정하는 동작을 설명하기 위한 흐름도이다. 도 13b는 본 개시의 일 실시예에 따른 전자 장치가 관심 영역의 모양에 기초하여 이미지를 처리하는 동작을 설 명하기 위한 도면이다. 도 13c는 본 개시의 일 실시예에 따른 신뢰도 체커의 개략적인 동작을 설명하기 위한 도면이다. 도 14a는 본 개시의 일 실시예에 따른 신뢰도 체커의 구체적인 동작을 설명하기 위한 도면이다. 도 14b는 본 개시의 일 실시예에 따른 신뢰도 체커의 구체적인 동작을 설명하기 위한 도면이다. 도 14c는 본 개시의 일 실시예에 따른 신뢰도 체커의 구체적인 동작을 설명하기 위한 도면이다. 도 14d는 본 개시의 일 실시예에 따른 신뢰도 체커의 구체적인 동작을 설명하기 위한 도면이다. 도 14e는 본 개시의 일 실시예에 따른 신뢰도 체커의 구체적인 동작을 설명하기 위한 도면이다. 도 15a는 본 개시의 일 실시예에 따른 전자 장치가 신뢰도 체커를 이용하여 최종 왜곡 제거 이미지를 선택하는 동작을 설명하기 위한 도면이다. 도 15b는 본 개시의 일 실시예에 따른 전자 장치가 신뢰도 체커를 이용하여 최종 왜곡 제거 이미지를 선택하는 동작을 설명하기 위한 도면이다. 도 16은 본 개시의 일 실시예에 따른 전자 장치가 객체의 3차원 모양을 식별하는 동작을 설명하기 위한 도면이 다. 도 17a는 본 개시의 일 실시예에 따른 전자 장치가 객체의 3차원 모양을 분류하는 동작을 설명하기 위한 도면이 다. 도 17b는 객체의 3차원 모양 타입에 따라 결정되는 객체 키 포인트들 및 객체의 3차원 모양 타입에 대응하는 3 차원 파라미터를 설명하기 위한 도면이다. 도 18a는 본 개시의 일 실시예에 따른 전자 장치가 객체 3차원 모양 분류 모델을 훈련시키는 동작을 설명하기 위한 도면이다. 도 18b는 본 개시의 일 실시예에 따른 전자 장치가 객체 3차원 모양 분류 모델을 훈련시키는 동작을 설명하기 위한 도면이다. 도 18c는 본 개시의 일 실시예에 따른 전자 장치가 객체의 3차원 모양을 식별하는 실시예를 설명하기 위한 도면 이다. 도 18d는 본 개시의 일 실시예에 따른 전자 장치가 객체의 3차원 모양을 식별하는 실시예를 설명하기 위한 도면 이다. 도 19는 본 개시의 일 실시예에 따른 전자 장치에 포함될 수 있는 멀티 카메라를 설명하기 위한 도면이다. 도 20a는 본 개시의 일 실시예에 따른 전자 장치가 멀티 카메라를 이용하는 동작을 설명하기 위한 흐름도이다. 도 20b는 도 20a를 보충적으로 설명하기 위한 도면이다. 도 21a는 본 개시의 일 실시예에 따른 전자 장치가 멀티 카메라를 이용하는 동작을 설명하기 위한 흐름도이다. 도 21b는 도 21a를 보충적으로 설명하기 위한 도면이다.도 22a는 본 개시의 일 실시예에 따른 전자 장치가 멀티 카메라를 이용하는 동작을 설명하기 위한 흐름도이다. 도 22b는 도 22a를 보충적으로 설명하기 위한 도면이다. 도 22c는 도 22a를 보충적으로 설명하기 위한 도면이다. 도 23a는 본 개시의 일 실시예에 따른 전자 장치가 이미지를 처리하여 추출된 정보를 제공하는 동작을 설명하기 위한 도면이다. 도 23b는 본 개시의 일 실시예에 따른 또다른 형태의 전자 장치의 동작을 설명하기 위한 도면이다. 도 24는 본 개시의 일 실시예에 따른 전자 장치가 왜곡 제거 이미지를 활용하는 동작을 설명하기 위한 도면이다. 도 25는 본 개시의 일 실시예에 따른 전자 장치가 이미지를 처리하는 동작에 관련된 시스템의 일 예시를 설명하 기 위한 도면이다. 도 26은 본 개시의 일 실시예에 따른 전자 장치가 서버를 이용하여 이미지를 처리하는 동작에 관련된 시스템의 일 예시를 설명하기 위한 도면이다. 도 27은 본 개시의 일 실시예에 따른 전자 장치의 구성을 도시한 블록도이다. 도 28은 본 개시의 일 실시예에 따른 서버의 구성을 도시한 블록도이다."}
