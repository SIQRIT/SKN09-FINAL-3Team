{"patent_id": "10-2022-0190564", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0108851", "출원번호": "10-2022-0190564", "발명의 명칭": "인공지능 기반의 내시경 자율주행을 위한 가이드 정보 제공 방법 및 장치, 그리고 이를 포함", "출원인": "한국항공대학교산학협력단", "발명자": "김병규"}}
{"patent_id": "10-2022-0190564", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "인공지능 기반의 내시경 자율주행을 위한 가이드 정보 제공 방법에 있어서,(a) 대상자의 체내에 삽입된 내시경 모듈에 의해 촬영된 이미지 데이터를 획득하는 단계; 및(b) 기 학습된 인공지능 기반의 분석 모델에 상기 이미지 데이터를 입력하고, 상기 분석 모델을 이용하여 상기이미지 데이터에 대응하는 주행 목표 정보 및 충돌 위험 정보 중 적어도 하나를 포함하는 가이드 정보를 도출하는 단계,를 포함하고,상기 분석 모델은,적정 주행 방향에 대한 라벨 정보가 부여된 복수의 학습 데이터를 이용한 학습을 통해 구축되는 것인, 방법."}
{"patent_id": "10-2022-0190564", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 복수의 학습 데이터는,상기 내시경 모듈이 삽입되는 대상 부위의 곡선 구간에 대응하는 이미지 데이터에 대하여 슬라럼(Slalom) 기법이 적용되도록 상기 라벨 정보가 부여된 제1데이터 셋을 포함하는 것인, 방법."}
{"patent_id": "10-2022-0190564", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 복수의 학습 데이터는,상기 내시경 모듈이 삽입되는 대상 부위를 이루는 벽면에 시계열적으로 근접하도록 촬영된 이미지 데이터에 대하여 면벽주행(Slide-by) 기법이 적용되도록 상기 라벨 정보가 부여된 제2데이터 셋을 포함하는 것인, 방법."}
{"patent_id": "10-2022-0190564", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,상기 복수의 학습 데이터는,상기 내시경 모듈이 삽입되는 대상 부위에서 개방된 내강을 따라 주행하도록 촬영된 이미지 데이터에 대하여 상기 내강의 중심 영역 대비 상기 대상 부위의 벽면 측으로 치우진 상기 라벨 정보가 부여된 제3데이터 셋을 포함하는 것인, 방법."}
{"patent_id": "10-2022-0190564", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "인공지능 기반의 내시경 자율주행 제어 방법에 있어서,(a) 대상자의 체내에 삽입된 내시경 모듈에 의해 촬영된 이미지 데이터를 획득하는 단계;(b) 기 학습된 인공지능 기반의 분석 모델에 상기 이미지 데이터를 입력하고, 상기 분석 모델을 이용하여 상기이미지 데이터에 대응하는 주행 목표 정보 및 충돌 위험 정보 중 적어도 하나를 포함하는 가이드 정보를 도출하는 단계; 및(c) 상기 가이드 정보를 기초로 하여 상기 내시경 모듈을 제어하는 단계,를 포함하고,공개특허 10-2024-0108851-3-상기 분석 모델은,적정 주행 방향에 대한 라벨 정보가 부여된 복수의 학습 데이터를 이용한 학습을 통해 구축되는 것인, 방법."}
{"patent_id": "10-2022-0190564", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5항에 있어서,상기 (c) 단계는,상기 충돌 위험 정보에 기초하여 상기 내시경 모듈의 전진 주행이 불가한 것으로 판단되면, 상기 내시경 모듈을후진하도록 제어하는 것인, 방법."}
{"patent_id": "10-2022-0190564", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제5항에 있어서,상기 (c) 단계는,상기 충돌 위험 정보에 기초하여 상기 내시경 모듈의 전진 주행이 가능한 것으로 판단되면, 상기 주행 목표 정보를 기초로 하여 상기 내시경 모듈의 조향을 제어하는 것인, 방법."}
{"patent_id": "10-2022-0190564", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제5항에 있어서,상기 (a) 단계는,상기 내시경 모듈의 삽입 위치 정보 및 상기 내시경 모듈의 자세 정보 중 적어도 하나를 획득하도록 상기 내시경 모듈에 대하여 구비되는 감지 센서의 센서 데이터를 더 획득하고,상기 (b) 단계는,상기 삽입 위치 정보 및 상기 자세 정보 중 적어도 하나를 이용하여 상기 내시경 모듈의 루프 발생 정보를 도출하는 것인, 방법."}
{"patent_id": "10-2022-0190564", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서,상기 루프 발생 정보는 상기 내시경 모듈에 발생한 루프 유형에 대한 정보를 포함하고,상기 (c) 단계는,상기 루프 유형에 따라 미리 설정된 루프 해소 기법에 따라 상기 내시경 모듈을 제어하는 것인, 방법."}
{"patent_id": "10-2022-0190564", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "인공지능 기반의 내시경 자율주행을 위한 가이드 정보 제공 장치에 있어서,대상자의 체내에 삽입된 내시경 모듈에 의해 촬영된 이미지 데이터를 획득하는 수집부; 및기 학습된 인공지능 기반의 분석 모델에 상기 이미지 데이터를 입력하고, 상기 분석 모델을 이용하여 상기 이미지 데이터에 대응하는 주행 목표 정보 및 충돌 위험 정보 중 적어도 하나를 포함하는 가이드 정보를 도출하는분석부,를 포함하고,상기 분석 모델은,적정 주행 방향에 대한 라벨 정보가 부여된 복수의 학습 데이터를 이용한 학습을 통해 구축되는 것인, 장치."}
{"patent_id": "10-2022-0190564", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제10항에 있어서,공개특허 10-2024-0108851-4-상기 복수의 학습 데이터는,상기 내시경 모듈이 삽입되는 대상 부위의 곡선 구간에 대응하는 이미지 데이터에 대하여 슬라럼(Slalom) 기법이 적용되도록 상기 라벨 정보가 부여된 제1데이터 셋;상기 대상 부위를 이루는 벽면에 시계열적으로 근접하도록 촬영된 이미지 데이터에 대하여 면벽주행(Slide-by)기법이 적용되도록 상기 라벨 정보가 부여된 제2데이터 셋; 및상기 대상 부위에서 개방된 내강을 따라 주행하도록 촬영된 이미지 데이터에 대하여 상기 내강의 중심 영역 대비 상기 대상 부위의 벽면 측으로 치우진 상기 라벨 정보가 부여된 제3데이터 셋을 포함하는 것인, 장치."}
{"patent_id": "10-2022-0190564", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "인공지능 기반의 내시경 자율주행 제어 장치에 있어서,대상자의 체내에 삽입된 내시경 모듈에 의해 촬영된 이미지 데이터를 획득하는 수집부;기 학습된 인공지능 기반의 분석 모델에 상기 이미지 데이터를 입력하고, 상기 분석 모델을 이용하여 상기 이미지 데이터에 대응하는 주행 목표 정보 및 충돌 위험 정보 중 적어도 하나를 포함하는 가이드 정보를 도출하는분석부; 및상기 가이드 정보를 기초로 하여 상기 내시경 모듈을 제어하는 제어부,를 포함하고,상기 분석 모델은,적정 주행 방향에 대한 라벨 정보가 부여된 복수의 학습 데이터를 이용한 학습을 통해 구축되는 것인, 장치."}
{"patent_id": "10-2022-0190564", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제12항에 있어서,상기 제어부는,상기 충돌 위험 정보에 기초하여 상기 내시경 모듈의 전진 주행이 불가한 것으로 판단되면, 상기 내시경 모듈을후진하도록 제어하고,상기 충돌 위험 정보에 기초하여 상기 전진 주행이 가능한 것으로 판단되면, 상기 주행 목표 정보를 기초로 하여 상기 내시경 모듈의 조향을 제어하는 것인, 장치."}
{"patent_id": "10-2022-0190564", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제12항에 있어서,상기 수집부는,상기 내시경 모듈의 삽입 위치 정보 및 상기 내시경 모듈의 자세 정보 중 적어도 하나를 획득하도록 상기 내시경 모듈에 대하여 구비되는 감지 센서의 센서 데이터를 더 획득하고,상기 분석부는,상기 삽입 위치 정보 및 상기 자세 정보 중 적어도 하나를 이용하여 상기 내시경 모듈에 발생한 루프 유형에 대한 정보를 포함하는 루프 발생 정보를 도출하고,상기 제어부는,상기 루프 유형에 따라 미리 설정된 루프 해소 기법에 따라 상기 내시경 모듈을 제어하는 것인, 장치."}
{"patent_id": "10-2022-0190564", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "인공지능 기반의 내시경 자율주행 시스템에 있어서,대상자의 체내의 대상 부위에 삽입되어, 상기 대상 부위에 대한 이미지 데이터를 촬영하는 내시경 모듈; 및상기 내시경 모듈로부터 상기 이미지 데이터를 수신하고, 기 학습된 인공지능 기반의 분석 모델에 상기 이미지공개특허 10-2024-0108851-5-데이터를 입력하고, 상기 분석 모델을 이용하여 상기 이미지 데이터에 대응하는 주행 목표 정보 및 충돌 위험정보 중 적어도 하나를 포함하는 가이드 정보를 도출하고, 상기 가이드 정보를 기초로 하여 상기 내시경 모듈을제어하는 가이드 정보 제공 장치,를 포함하는, 자율주행 시스템."}
{"patent_id": "10-2022-0190564", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "인공지능 기반의 내시경 자율주행을 위한 가이드 정보 제공 방법 및 장치, 그리고 이를 포함하는 내시경 자율주 행 제어 방법 및 장치가 개시되며, 본원의 일 실시예에 따른 인공지능 기반의 내시경 자율주행을 위한 가이드 정 보 제공 방법은, (a) 대상자의 체내에 삽입된 내시경 모듈에 의해 촬영된 이미지 데이터를 획득하는 단계 및 (b) 기 학습된 인공지능 기반의 분석 모델에 상기 이미지 데이터를 입력하고, 상기 분석 모델을 이용하여 상기 이미 지 데이터에 대응하는 주행 목표 정보 및 충돌 위험 정보 중 적어도 하나를 포함하는 가이드 정보를 도출하는 단 계를 포함할 수 있다."}
{"patent_id": "10-2022-0190564", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본원은 인공지능 기반의 내시경 자율주행을 위한 가이드 정보 제공 방법 및 장치, 그리고 이를 포함하는 내시경 자율주행 제어 방법 및 장치에 관한 것이다. 예를 들면, 본원은 인공신경망 기반의 대장내시경 자율주행을 위한 학습 기법 및 제어 알고리즘, 그리고 이러한 학습 기법과 제어 알고리즘이 적용된 장치에 관한 것이다."}
{"patent_id": "10-2022-0190564", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "대장암(Colorectal cancer, CRC)은 전세계적으로 흔히 발생하며, 암으로 인한 사망의 주요 원인으로 평가된다. 구체적으로 2020년에는 약 190만명이 대장암 진단을 받았고, 91만명 이상이 대장암으로 사망한 것으로 나타났다. 이와 같이 사망률이 높은 대장암은 조기진단이 환자의 생존율을 높이기 위하여 매우 중요하며, 굴곡 성 대장내시경(flexible colonoscope)은 대장암의 조기진단을 위한 가장 정확한 선별검사법이다. 대상자의 체내로 삽입되는 긴 튜브를 이용한 굴곡성 대장내시경은 내시경 전진, 샤프트 회전, 팁 스티어링 등의 방식으로 내시경 모듈을 제어할 수 있으나, 각 환자의 대장(결장, colon)이 고유한 크기와 모양을 가지고 있어 내시경 모듈을 제어하는 방식을 익히는 것이 어려울 뿐만 아니라, 이러한 제어의 어려움 외에도 대장 내시경의 조향 모듈에 비인체공학적 작동 메커니즘이 사용되어 작업자에게 손목 터널 증후군과 같은 근골격계 부상을 유 발할 수 있다는 문제가 있다. 한편, 이러한 문제에 대한 해결책으로서 다양한 로봇 시스템이 연구되고 있으며, 로봇 시스템은 작업자의 작업 량을 줄이거나 보다 인체공학적인 제어로 술기 학습을 용이하게 할 수 있다고는 하나 이러한 로봇 시스템에서도 로봇 장치를 능숙하게 제어하는 것은 여전히 어려운 작업이다. 또한, 이러한 문제점을 해결하기 위해 대장내시경 자동화에 대한 연구가 진행되고 있으나, 인공신경망을 대장내 시경에 접목한 종래의 알고리즘은 용종을 탐지하는 알고리즘이 대부분을 차지하며, 대장내시경 자율주행을 위한 알고리즘은 대장 내에서 오픈 루멘(Open Lumen)이 탐지되어야만 주행이 가능하며 벽에 충돌할 경우 조작자의 간 섭이 불가피하다는 한계가 있었다. 본원의 배경이 되는 기술은 한국등록특허공보 제10-2297070호에 개시되어 있다."}
{"patent_id": "10-2022-0190564", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본원은 전술한 종래 기술의 문제점을 해결하기 위한 것으로서, 내시경 모듈에 의해 획득된 이미지 데이터로부터 주행 목표(조향 방향)를 탐지하고, 충돌 위험을 예측할 수 있는 인공지능 기반의 내시경 자율주행을 위한 가이 드 정보를 제공하고 이를 기반으로 내시경 로봇 시스템을 제어하는 것을 목적으로 한다. 다만, 본원의 실시예가 이루고자 하는 기술적 과제는 상기된 바와 같은 기술적 과제들로 한정되지 않으며, 또 다른 기술적 과제들이 존재할 수 있다."}
{"patent_id": "10-2022-0190564", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기한 기술적 과제를 달성하기 위한 기술적 수단으로서, 본원의 일 실시예에 따른 인공지능 기반의 내시경 자 율주행을 위한 가이드 정보 제공 방법은, (a) 대상자의 체내에 삽입된 내시경 모듈에 의해 촬영된 이미지 데이 터를 획득하는 단계 및 (b) 기 학습된 인공지능 기반의 분석 모델에 상기 이미지 데이터를 입력하고, 상기 분석 모델을 이용하여 상기 이미지 데이터에 대응하는 주행 목표 정보 및 충돌 위험 정보 중 적어도 하나를 포함하는 가이드 정보를 도출하는 단계를 포함할 수 있다. 또한, 상기 분석 모델은 적정 주행 방향에 대한 라벨 정보가 부여된 복수의 학습 데이터를 이용한 학습을 통해 구축될 수 있다. 또한, 상기 복수의 학습 데이터는, 상기 내시경 모듈이 삽입되는 대상 부위의 곡선 구간에 대응하는 이미지 데 이터에 대하여 슬라럼(Slalom) 기법이 적용되도록 상기 라벨 정보가 부여된 제1데이터 셋을 포함할 수 있다. 또한, 상기 복수의 학습 데이터는, 상기 내시경 모듈이 삽입되는 대상 부위를 이루는 벽면에 시계열적으로 근접 하도록 촬영된 이미지 데이터에 대하여 면벽주행(Slide-by) 기법이 적용되도록 상기 라벨 정보가 부여된 제2데 이터 셋을 포함할 수 있다. 또한, 상기 복수의 학습 데이터는, 상기 내시경 모듈이 삽입되는 대상 부위에서 개방된 내강을 따라 주행하도록 촬영된 이미지 데이터에 대하여 상기 내강의 중심 영역 대비 상기 대상 부위의 벽면 측으로 치우진 상기 라벨 정보가 부여된 제3데이터 셋을 포함할 수 있다. 한편, 본원의 일 실시예에 따른 인공지능 기반의 내시경 자율주행 제어 방법은, (a) 대상자의 체내에 삽입된 내 시경 모듈에 의해 촬영된 이미지 데이터를 획득하는 단계, (b) 기 학습된 인공지능 기반의 분석 모델에 상기 이 미지 데이터를 입력하고, 상기 분석 모델을 이용하여 상기 이미지 데이터에 대응하는 주행 목표 정보 및 충돌 위험 정보 중 적어도 하나를 포함하는 가이드 정보를 도출하는 단계 및 (c) 상기 가이드 정보를 기초로 하여 상 기 내시경 모듈을 제어하는 단계를 포함할 수 있다. 또한, 상기 (c) 단계는, 상기 충돌 위험 정보에 기초하여 상기 내시경 모듈의 전진 주행이 불가한 것으로 판단 되면, 상기 내시경 모듈을 후진하도록 제어할 수 있다. 또한, 상기 (c) 단계는, 상기 충돌 위험 정보에 기초하여 상기 내시경 모듈의 전진 주행이 가능한 것으로 판단 되면, 상기 주행 목표 정보를 기초로 하여 상기 내시경 모듈의 조향을 제어할 수 있다. 또한, 상기 (a) 단계는, 상기 내시경 모듈의 삽입 위치 정보 및 상기 내시경 모듈의 자세 정보 중 적어도 하나 를 획득하도록 상기 내시경 모듈에 대하여 구비되는 감지 센서의 센서 데이터를 획득할 수 있다. 또한, 상기 (b) 단계는, 상기 삽입 위치 정보 및 상기 자세 정보 중 적어도 하나를 이용하여 상기 내시경 모듈 의 루프 발생 정보를 도출할 수 있다. 또한, 상기 루프 발생 정보는 상기 내시경 모듈에 발생한 루프 유형에 대한 정보를 포함할 수 있다. 또한, 상기 (c) 단계는, 상기 루프 유형에 따라 미리 설정된 루프 해소 기법에 따라 상기 내시경 모듈을 제어할 수 있다. 한편, 본원의 일 실시예에 따른 인공지능 기반의 내시경 자율주행을 위한 가이드 정보 제공 장치는, 대상자의 체내에 삽입된 내시경 모듈에 의해 촬영된 이미지 데이터를 획득하는 수집부 및 기 학습된 인공지능 기반의 분 석 모델에 상기 이미지 데이터를 입력하고, 상기 분석 모델을 이용하여 상기 이미지 데이터에 대응하는 주행 목 표 정보 및 충돌 위험 정보 중 적어도 하나를 포함하는 가이드 정보를 도출하는 분석부를 포함할 수 있다. 한편, 본원의 일 실시예에 따른 인공지능 기반의 내시경 자율주행 제어 장치는, 대상자의 체내에 삽입된 내시경 모듈에 의해 촬영된 이미지 데이터를 획득하는 수집부, 기 학습된 인공지능 기반의 분석 모델에 상기 이미지 데 이터를 입력하고, 상기 분석 모델을 이용하여 상기 이미지 데이터에 대응하는 주행 목표 정보 및 충돌 위험 정 보 중 적어도 하나를 포함하는 가이드 정보를 도출하는 분석부 및 상기 가이드 정보를 기초로 하여 상기 내시경 모듈을 제어하는 제어부를 포함할 수 있다. 또한, 상기 제어부는, 상기 충돌 위험 정보에 기초하여 상기 내시경 모듈의 전진 주행이 불가한 것으로 판단되 면, 상기 내시경 모듈을 후진하도록 제어하고, 상기 충돌 위험 정보에 기초하여 상기 전진 주행이 가능한 것으 로 판단되면, 상기 주행 목표 정보를 기초로 하여 상기 내시경 모듈의 조향을 제어할 수 있다. 또한, 상기 수집부는, 상기 내시경 모듈의 삽입 위치 정보 및 상기 내시경 모듈의 자세 정보 중 적어도 하나를 획득하도록 상기 내시경 모듈에 대하여 구비되는 감지 센서의 센서 데이터를 획득할 수 있다. 또한, 상기 분석부는, 상기 삽입 위치 정보 및 상기 자세 정보 중 적어도 하나를 이용하여 상기 내시경 모듈에 발생한 루프 유형에 대한 정보를 포함하는 루프 발생 정보를 도출할 수 있다. 또한, 상기 제어부는, 상기 루프 유형에 따라 미리 설정된 루프 해소 기법에 따라 상기 내시경 모듈을 제어할 수 있다. 상술한 과제 해결 수단은 단지 예시적인 것으로서, 본원을 제한하려는 의도로 해석되지 않아야 한다. 상술한 예 시적인 실시예 외에도, 도면 및 발명의 상세한 설명에 추가적인 실시예가 존재할 수 있다."}
{"patent_id": "10-2022-0190564", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "전술한 본원의 과제 해결 수단에 의하면, 내시경 모듈에 의해 획득된 이미지 데이터로부터 주행 목표(조향 대상)을 탐지하고, 충돌 위험을 예측할 수 있는 인공지능 기반의 내시경 자율주행을 위한 가이드 정보 제공 장 치 및 방법을 제공할 수 있다. 전술한 본원의 과제 해결 수단에 의하면, 오픈 루멘(Open Lumen)에 내시경 모듈이 위치하는 경우가 아니더라도, 적절한 후진 제어 또는 조향 제어를 통해 루멘을 찾아 주행하며, 주행 시 전문의의 술기를 모사하며 주행할 수 있어 피시술자의 안전성을 보장할 수 있다. 전술한 본원의 과제 해결 수단에 의하면, 내시경 모듈을 조작하는 사용자에게 적용되는 부하 및 피로도를 최소 화하여 부담없이 시술을 수행할 수 있도록 하고, 환자에게는 시술 안전성을 제공할 수 있다. 다만, 본원에서 얻을 수 있는 효과는 상기된 바와 같은 효과들로 한정되지 않으며, 또 다른 효과들이 존재할 수 있다."}
{"patent_id": "10-2022-0190564", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "아래에서는 첨부한 도면을 참조하여 본원이 속하는 기술 분야에서 통상의 지식을 가진 자가 용이하게 실시할 수 있도록 본원의 실시예를 상세히 설명한다. 그러나 본원은 여러 가지 상이한 형태로 구현될 수 있으며 여기에서 설명하는 실시예에 한정되지 않는다. 그리고 도면에서 본원을 명확하게 설명하기 위해서 설명과 관계없는 부분 은 생략하였으며, 명세서 전체를 통하여 유사한 부분에 대해서는 유사한 도면 부호를 붙였다. 본원 명세서 전체에서, 어떤 부분이 다른 부분과 \"연결\"되어 있다고 할 때, 이는 \"직접적으로 연결\"되어 있는 경우뿐 아니라, 그 중간에 다른 소자를 사이에 두고 \"전기적으로 연결\" 또는 \"간접적으로 연결\"되어 있는 경우 도 포함한다. 본원 명세서 전체에서, 어떤 부재가 다른 부재 \"상에\", \"상부에\", \"상단에\", \"하에\", \"하부에\", \"하단에\" 위치 하고 있다고 할 때, 이는 어떤 부재가 다른 부재에 접해 있는 경우뿐 아니라 두 부재 사이에 또 다른 부재가 존 재하는 경우도 포함한다. 본원 명세서 전체에서, 어떤 부분이 어떤 구성 요소를 \"포함\"한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다른 구성 요소를 제외하는 것이 아니라 다른 구성 요소를 더 포함할 수 있는 것을 의미한다. 본원은 인공지능 기반의 내시경 자율주행을 위한 가이드 정보 제공 장치 및 방법에 관한 것이다. 예를 들면, 본 원은 인공신경망 기반의 대장내시경 자율주행을 알고리즘 및 학습 기법에 관한 것이다. 도 1은 본원의 일 실시예에 따른 인공지능 기반의 내시경 자율주행 시스템의 개략적인 구성도이다. 도 1을 참조하면, 본원의 일 실시예에 따른 인공지능 기반의 내시경 자율주행 시스템은 본원의 일 실시예에 따른 인공지능 기반의 내시경 자율주행을 위한 가이드 정보 제공 장치(이하, '가이드 정보 제공 장치 '라 한다.), 내시경 모듈, 데이터베이스 및 사용자 단말을 포함할 수 있다. 가이드 정보 제공 장치, 내시경 모듈, 데이터베이스 및 사용자 단말 상호간은 네트워크 를 통해 통신할 수 있다. 네트워크는 단말들 및 서버들과 같은 각각의 노드 상호간에 정보 교환이 가능 한 연결 구조를 의미하는 것으로, 이러한 네트워크의 일 예에는, 3GPP(3rd Generation Partnership Project) 네트워크, LTE(Long Term Evolution) 네트워크, 5G 네트워크, WIMAX(World Interoperability for Microwave Access) 네트워크, 인터넷(Internet), LAN(Local Area Network), Wireless LAN(Wireless Local Area Network), WAN(Wide Area Network), PAN(Personal Area Network), wifi 네트워크, 블루투스(Bluetooth) 네트워크, 위성 방송 네트워크, 아날로그 방송 네트워크, DMB(Digital Multimedia Broadcasting) 네트워크 등 이 포함되나 이에 한정되지는 않는다. 사용자 단말은 예를 들면, 스마트폰(Smartphone), 스마트패드(SmartPad), 태블릿 PC등과 PCS(Personal Communication System), GSM(Global System for Mobile communication), PDC(Personal Digital Cellular), PHS(Personal Handyphone System), PDA(Personal Digital Assistant), IMT(International Mobile Telecommunication)-2000, CDMA(Code Division Multiple Access)-2000, W-CDMA(W-Code Division Multiple Access), Wibro(Wireless Broadband Internet) 단말기 같은 모든 종류의 무선 통신 장치일 수 있다. 예를 들어, 사용자 단말은 내시경 모듈에 의해 촬영된 이미지 데이터 및 해당 이미지 데이터에 대하여 가 이드 정보 제공 장치가 도출한 가이드 정보를 표출하기 위한 디스플레이 모듈(미도시)을 구비할 수 있다. 또한, 예시적으로 사용자 단말은 내시경 모듈의 조작자(의료진 등)가 보유한 단말을 지칭하는 것일 수 있다. 본원의 실시예에 관한 설명에서 내시경 모듈은 대상자의 체내로 삽입되는 튜브를 포함할 수 있으며, 대상 자의 체내에 삽입되어 대상자의 신체 내부를 촬영한 이미지를 획득하는 카메라 모듈을 구비할 수 있다. 예시적 으로, 내시경 모듈은 굴곡성 대장내시경(flexible colonoscople)일 수 있으나, 이에만 한정되는 것은 아니 다. 또한, 본원에서 개시하는 가이드 정보 제공 장치는 내시경 모듈을 주행(전진 또는 후진), 조향, 롤링, 벤딩, 샤프트(튜브) 회전, 의 체내 삽입 단부(팁) 조향 등의 방식으로 구동하기 위한 가이드 정보 및 제 어 정보를 생성하는 것일 수 있다. 또한, 본원의 실시예에 관한 설명에서 데이터베이스는 이하에서 상세히 설명하는 인공지능 기반의 분석 모 델을 훈련(학습)시키기 위한 학습 데이터를 저장하는 디바이스 또는 서버일 수 있다. 또한, 데이터베이스 는 대상자의 체내에 삽입된 내시경 모듈에 의해 촬영되어 인공지능 기반의 분석 모델을 이용한 분석의 대 상이 되는 이미지 데이터와 해당 이미지 데이터로부터 도출된 가이드 정보를 저장하도록 동작할 수 있다. 도 2는 본원의 일 실시예에 따른 인공지능 기반의 내시경 자율주행을 위한 가이드 정보 제공 장치의 동작 프로 세스를 설명하기 위한 개념도이다. 도 2를 참조하면, 가이드 정보 제공 장치는 내시경 모듈을 이용하여 이미지 데이터를 획득하고(도 2 의 '이미지 수집'), 획득한 이미지 데이터를 기 학습된 인공지능 기반의 분석 모델(도 2의 '인공신경망')에 입 력하여 내시경 모듈의 충돌 위험 정보(보다 구체적으로, 대상자의 체내로 삽입된 내시경 모듈의 단부 (팁)와 대상 부위의 벽면 등의 체내 구조물과의 충돌 가능성에 대한 정보)를 도출하여 내시경 모듈의 주행 가능성을 판단할 수 있다(도 2의 '주행 가능성 판단'). 또한, 도 2를 참조하면, 가이드 정보 제공 장치는 내시경 모듈이 주행 가능한 상태인 것으로 판단되 면, 목표부위(예시적으로, 내시경 모듈이 대장 내시경 유형인 경우, 맹장 부위 등)에 도달하도록 인공지능 기반의 분석 모델에 의해 도출된 주행 목표 정보를 이용하여 내시경 모듈을 제어할 수 있다(도 2의 '조향/ 전진'). 반대로, 내시경 모듈의 주행이 불가능한 상태(예를 들면, 내시경 모듈의 체내 삽입 단부(팁)가 대상 부위의 벽면에 대하여 미리 설정된 허용 거리 이내로 근접한 상태 등)인 것으로 판단되면, 내시경 모듈을 후진 제어하고, 내시경 모듈의 카메라 모듈(미도시)의 촬영 방향을 미리 설정된 방향으로 조 정할 수 있다(도 2의 '카메라 중앙화 및 후진'). 이하에서는 도 3 내지 도 6을 참조하여 가이드 정보 제공 장치에 탑재되는 인공지능 기반의 분석 모델에 대하여 상세히 설명하도록 한다. 도 3은 인공지능 기반의 분석 모델의 네트워크 구조를 예시적으로 나타낸 도면이다. 도 3을 참조하면, 가이드 정보 제공 장치의 분석 모델은 대상자의 체내에 삽입된 내시경 모듈에 의해 촬영되고, 내시경 모듈로부터 가이드 정보 제공 장치로 전송된 이미지 데이터(도 3의 'Input imag e')를 기초로 하여 해당 이미지 데이터에 대응하는 주행 목표 정보(도3 의 'Steering target') 및 충돌 위험 정 보(도 3의 'Prob. Collision')를 포함하는 가이드 정보를 출력으로서 제공하도록 동작할 수 있다. 또한, 도 3의 출력 데이터(도3 의 'Outputs')를 참조하면, 가이드 정보 제공 장치의 분석 모델을 통해 도 출되는 주행 목표 정보는 입력된 이미지 데이터의 내부 영역 중 해당 이미지 데이터의 촬영 시점 이후에 내시경 모듈의 적정 주행 방향(달리 말해, 내시경 모듈의 체내 삽입 단부(팁)가 해당 대상 부위를 대상자의 체내에 대한 손상을 야기하지 않으면서 적절히 통과할 수 있도록 주행하여야 하는 목표 지점을 향하는 방향)을 나타내는 영역을 특정하도록 도출될 수 있다. 또한, 충돌 위험 정보는 해당 이미지 데이터의 픽셀별 색상 정보, 객체 식별 정보 등에 비추어 파악되는 대상 부위의 체내 구조물(예를 들면, 장기 내벽 등) 등과 내시경 모듈의 체내 삽입 단부(팁)의 거리 등을 기초 로 하여 내시경 모듈과 대상 부위의 체내 구조물 간의 충돌 발생 확률을 나타내도록 수치화된 값으로 출력 되는 것일 수 있으나, 이에만 한정되는 것은 아니다. 다른 예로, 본원의 구현예에 따라서는 분석 모델에 의해 도출되는 충돌 위험 정보는 충돌 위험성이 소정 수준 이상인 경우와 충돌 위험성이 소정 수준 미만인 경우로 구 분하여 이진화된 값(예를 들면, 충돌 위험성이 높은 경우 '1'의 출력값, 충돌 위험성이 낮은 경우 '0'의 출력값 등)으로 도출되는 것일 수 있다. 즉, 가이드 정보 제공 장치의 분석 모델은 내시경 모듈을 이용한 내 시경 시술 시 대상 부위의 구조물(내벽 등)과의 충돌 여부를 판단하여 내시경 모듈의 주행 가능 여부를 판 단하도록 보조할 수 있다. 또한, 도 3을 참조하면, 본원의 일 실시예에 따른 인공지능 기반의 분석 모델은 이미지 데이터로부터 특징 (Feature)을 추출하도록 사전 훈련된 Resnet-34 아키텍쳐 기반의 모델일 수 있으나, 이에만 한정되는 것은 아니 며 본원에서는 종래에 이미 공지되었거나 향후 개발되는 다양한 인공지능 기반의 학습 알고리즘이 적용될 수 있 다. 한편, 전술한 Resnet-34 아키텍쳐는 주행 목표 정보 및 충돌 위험 정보와 연계된 두 가지 특징(Feature)을 통합 예측하도록 설계되어 훈련 시간 및 훈련에 필요한 데이터의 양을 줄일 수 있는 이점이 있다. 또한, Resnet-34 아키텍쳐는 특징(Feature) 추출 후, 두 개의 서로 다른 완전 연결 레이어(Fully-connected layer)로 분할되어, 첫 번째 출력 데이터로서 내시경 모듈의 팁을 조종하는데 사용되는 2차원 지점에 대한 정보인 주행 목표 정보를 도출하고, 두 번째 출력 데이터로서 내시경 모듈의 삽입 속도 조정 및 후진 제어 를 위한 1차원 정보인 충돌 위험 정보를 도출할 수 있다. 예시적으로 분석 모델은 평균 제곱 오차(MSE) 기반의 손실 및 이진 교차 엔트로피(BCE) 기반의 손실을 사용하여 주행 목표 정보 및 충돌 위험 정보를 개별 출력하도록 훈련될 수 있으며, 두 손실 함수의 규모를 조정하기 위해 학습 과정에서 이진 교차 엔트로피 손실에 가중치(예를 들면, 0.05)가 적용될 수 있다. 또한, 분석 모델의 학습 시에 과적합 문제를 방지하기 위해 특징 추출 후 드롭아웃 비율을 0.5 수준으로 적용할 수 있다. 또한, 학습용 데이터의 임의의 수평 반전, 수직 반전, 뒤집기, 회전 등의 데이터 가공이 학습 데이터의 균형을 확보하기 위해 적용될 수 있으며, 마찬가지로 데이터 균형을 위해 사용되며 밝기, 대비, 채도, 색조 변경 등이 적용될 수 있다. 한편, 본원에서 개시하는 인공지능 기반의 분석 모델은 내시경 모듈의 적정 주행 방향에 대한 라벨 정보가 부여된 복수의 학습 데이터를 이용한 학습을 통해 구축될 수 있다. 보다 구체적으로, 학습 데이터에 해당하는 이미지 데이터 각각에 대하여 할당되는 라벨 정보는 내시경 모듈 의 전진 주행이 불가하여 해당 이미지 데이터에 반영된 영역 외부를 향하도록 주행 목표를 결정하여야 하 는 상태(충돌 상태)와 해당 이미지 데이터에 반영된 영역 내부에서 주행 목표를 탐색할 수 있는 상태(미충돌 상태)를 구분하기 위하여 부여되는 제1라벨 정보 및 해당 이미지 데이터가 미충돌 상태를 나타내는 경우, 해당 이 미지 데이터에 반영된 영역 내부에서 설정되는 적정 목표 지점(적정 주행 방향)을 나타내는 제2라벨 정보를 포 함할 수 있다. 예를 들어, 제1라벨 정보는 각 이미지 데이터가 내시경 모듈의 체내 삽입 단부(팁)이 대상 부위의 내벽 등 에 충돌하였거나 충돌 위험이 소정 수준 이상인 충돌 상태를 나타내는 충돌 이미지에 해당하는지 여부에 대한 정보일 수 있으며, 이러한 제1라벨 정보가 부여된 이미지 데이터를 이용한 학습을 통해 분석 모델은 입력된 이 미지 데이터가 충돌 상태를 나타내는지를 파악하고, 이에 따라 충돌 상태에 해당하는 경우 내시경 모듈의 적정 주행 방향을 후진 방향으로 설정할 수 있게 된다. 이와 관련하여, 도 4는 인공지능 기반의 분석 모델의 학습을 위한 복수의 학습 데이터의 제1라벨 정보를 설명하 기 위한 도면이다. 도 4를 참조하면, 내시경 모듈의 체내 삽입 단부(팁)와 대상 부위를 이루는 체내 구조물(예를 들면, 내벽 등)과의 거리가 소정 수준 이상인 상태에서 촬영되어 내시경 모듈의 충돌 위험이 낮은 상태를 나타내도록 촬영된 학습용 이미지 데이터(도 4의 (a) 참조)와 내시경 모듈의 체내 삽입 단부(팁)와 대상 부위를 이루 는 체내 구조물과의 거리가 소정 수준 미만인 상태에서 촬영되어 내시경 모듈의 충돌 위험이 다소 높거나 내시경 모듈과 체내 구조물 간의 충돌이 발생한 상태를 나타내도록 촬영된 학습용 이미지 데이터(도 4의 (b) 참조)에 대하여 구분된 제1라벨 정보가 부여되는 것일 수 있다. 예시적으로, 제1라벨 정보는 각 학습용 이 미지 데이터의 테두리 영역의 형상(색상 등)을 상호 구분되도록 하는 방식으로 할당되는 것일 수 있으나, 이에 만 한정되는 것은 아니다. 달리 말해, 제1라벨 정보는 학습용 이미지 데이터 각각이 내시경 모듈의 체내 삽입 단부(팁)와 대상 부위를 이루는 체내 구조물 간의 충돌 위험이 높거나 충돌이 발생한 상태를 나타내는 충 돌 이미지인지 여부를 구분하기 위하여 할당되는 라벨 정보일 수 있다. 또한, 도 5는 인공지능 기반의 분석 모델의 학습을 위한 복수의 학습 데이터의 제2라벨 정보를 설명하기 위한 도면이다. 도 5를 참조하면, 인공지능 기반의 분석 모델의 학습을 위해 활용되는 학습용 이미지 데이터 각각에는 해당 이 미지 데이터가 촬영된 시점 이후에 내시경 모듈의 체내 삽입 단부(팁)가 해당 대상 부위를 적절히 통과하 기 위하여 조향되어야 하는 적정 주행 방향을 표시한 제2라벨 정보가 할당될 수 있다. 따라서, 제2라벨 정보가 할당(표시)된 복수의 학습 데이터를 이용하여 구축되는 분석 모델은 내시경 모듈로부터 촬영된 이미지 데 이터를 획득하면, 해당 이미지 데이터에 대응하는 주행 목표 정보를 제2라벨 정보의 할당 방식과 유사하게 해당 이미지 데이터 내부에서 내시경 모듈의 적정 주행 방향을 나타내는 특정 영역을 표시하는 방식으로 출력할 수 있게 된다. 또한, 도 5를 참조하면, 복수의 학습 데이터에는 실제 내시경 시술 시 내시경 모듈의 체내 삽입 단부(팁) 가 통과하고 있는 대상 부위 환경의 특성에 따라 적절한 주행 기법(달리 말해, 전문의에 의해 수행되는 주행 상 황에 따른 술기 방식 등)이 적용될 수 있도록 주행 기법을 고려한 제2라벨 정보가 할당됨으로써, 학습 데이터를 이용하여 학습되는 분석 모델이 내시경 모듈에 의해 획득된 이미지 데이터에 반영된 대상 부위 환경에 적 합한 주행 기법에 따라 설정되는 주행 목표 정보를 제공하도록 할 수 있다. 구체적으로 도 5의 (a)를 참조하면, 데이터베이스 등을 통해 수집되는 복수의 학습 데이터는 내시경 모듈 이 삽입되는 대상 부위의 곡선 구간에 대응하는 이미지 데이터에 대하여 슬라럼(Slalom) 기법이 적용되도 록 제2라벨 정보가 부여된 제1데이터 셋을 포함할 수 있다. 또한, 도 5의 (b)를 참조하면, 데이터베이스 등을 통해 수집되는 복수의 학습 데이터는 내시경 모듈 이 삽입되는 대상 부위를 이루는 벽면에 시계열적으로 근접하도록 촬영된 이미지 데이터에 대하여 면벽주행 (Slide-by) 기법이 적용되도록 제2라벨 정보가 부여된 제2데이터 셋을 포함할 수 있다. 또한, 도 5의 (c)를 참조하면, 데이터베이스 등을 통해 수집되는 복수의 학습 데이터는 내시경 모듈 이 삽입되는 대상 부위에서 개방된 내강(Open Lumen)을 따라 주행하도록 촬영된 이미지 데이터에 대하여, 내강 의 중심 영역 대비 대상 부위의 벽면 측으로 치우진 위치에 제2라벨 정보가 부여된 제3데이터 셋을 포함할 수 있다. 이와 관련하여 슬라럼(Slalom) 기법을 적용하면 대상 부위의 연속적인 커브 구간 사이의 최단 거리를 따라 내시 경 모듈을 전진시켜야 하므로, 도 5의 (a)와 같이 제1데이터 셋의 학습용 데이터는 대상 부위의 주름진 영 역에 최대로 근접한 루벤 공간에 제2라벨 정보가 부여되는 것을 확인할 수 있으며, 면벽주행(Slide-by) 기법의경우, 도 5의 (b)에 도시된 바와 같이 루멘 공간이 명확하게 식별되지 않을 때, 루멘 공간을 향하여 내시경 모 듈이 전진하여야 할 것으로 예상되는 지점이 제2라벨 정보로 할당될 수 있으며, 이러한 면벽주행(Slide- by) 기법을 적용하면 내시경 모듈이 대상 부위의 벽면을 향하거나 대상 부위의 일부 구간이 접혀 있는 경 우에도 적절한 조향 목표 지점을 찾을 수 있게 된다. 또한, 내시경 모듈의 역설적인 움직임(물리적으로 불가능한 움직임)을 피하기 위해서는 내시경 모듈 의 튜브 본체가 고리를 형성하지 않고, 완만한 만곡을 유지하면서 주행하도록 제어되어야 하며, 대상 부위의 해 부학적 형태 역시 고려해야 한다. 이를 고려하여, 제3데이터 셋은 대상 부위의 형상, 연장 방향 등이 비교적 잘 식별되는 이미지 데이터에 대하여 완만한 곡선을 이루며 내시경 모듈이 주행하도록 루멘 공간의 중심이 아 닌 우측 또는 벽면의 곡률 외부 반경 측으로 치우친 위치에 제2라벨 정보가 부여될 수 있다. 또한, 가이드 정보 제공 장치는 앞서 상세히 설명한 주행 목표 정보 및 충돌 위험 정보를 포함하도록 입력 이미지 데이터에 대하여 도출된 가이드 정보를 기초로 하여 내시경 모듈의 주행을 제어할 수 있다. 구체적으로 가이드 정보 제공 장치는 분석 모델을 통해 도출된 충돌 위험 정보에 기초하여 내시경 모듈 의 전진 주행이 불가한 것으로 판단되면, 내시경 모듈을 후진하도록 제어하고, 내시경 모듈의 카메라 모듈(미도시)의 촬영 방향을 미리 설정된 방향으로 조정할 수 있다. 예를 들어, 미리 설정된 방향은 해 당 이미지 데이터의 프레임 중앙을 향하는 방향, 해당 이미지 데이터로부터 식별되는 대상 부위의 내강(루멘) 영역의 중심점을 향하는 방향 등으로 설정될 수 있다. 또한, 본원의 일 실시예에 따르면, 가이드 정보 제공 장치는 분석 모델을 통해 도출된 충돌 위험 정보에 기초하여 내시경 모듈의 전진 주행이 불가한 것으로 판단되면, 내시경 모듈의 이후의 삽입 속도를 소 정 수준 미만으로 감소시키도록 내시경 모듈을 제어할 수 있다. 이와 달리, 분석 모델을 통해 도출된 충돌 위험 정보에 기초하여 내시경 모듈의 전진 주행이 가능한 것으 로 판단(달리 말해, 내시경 모듈의 체내 삽입 단부(팁) 등이 대상 부위의 체내 구조물과의 간섭이 발생하 지 않는 상태인 것으로 파악)되면, 가이드 정보 제공 장치는 분석 모델을 통해 도출된 주행 목표 정보를 기초로 하여 내시경 모듈의 조향을 제어할 수 있다. 달리 말해, 가이드 정보 제공 장치는 입력된 이 미지 데이터에 대하여 충돌 위험성이 낮은 것으로 분석되면, 해당 이미지 데이터에 대하여 도출된 주행 목표 정 보에 대응하는 지점을 향하여 내시경 모듈의 체내 삽입 단부(팁)가 거동하도록 내시경 모듈의 주행 방향(조향)을 제어할 수 있다. 한편, 본원의 일 실시예에 따르면, 가이드 정보 제공 장치는 분석 모델에 의해 도출되는 주행 목표 정보의 연속된 이미지 데이터에서의 시계열 변화를 기초로 하여 내시경 모듈의 체내 삽입 단부(팁)가 통과 중인 대상 부위의 체내 구간 유형, 해당 체내 구간에 대하여 적용된 주행 기법(술기) 유형 등을 파악하도록 동작할 수 있다. 예시적으로, 주행 목표 정보의 시계열 변화는 각 이미지 데이터를 이루는 프레임 좌표계를 기준으로 한 주행 목표 지점의 프레임 간 변화 정보, 각 이미지 데이터에 대한 객체 분석 결과를 고려하여 식별된 대상 부위의 체내 구조물(내벽, 루멘 등) 영역을 이용한 주행 목표 지점의 프레임 간 변화 정보 등의 형태로 파악되 는 것일 수 있다. 예를 들어, 도 5의 (a)에 도시된 5개의 이미지 데이터가 연속적으로 입력(좌측에 표시된 이미지가 먼저 입력된 것을 가정)되고, 인공지능 기반의 분석 모델에 의해 도 5의 (a)의 각 이미지 데이터에 표시된 주행 목표 정보가 도출된 경우, 가이드 정보 제공 장치는 해당 이미지 데이터가 입력된 구간이 대상 부위를 이루는 영역 중 연속적인 커브가 존재하는 구간을 나타내고, 이에 대응하여 슬라럼(Slalom) 기법이 적용된 것으로 파악할 수 있 게 된다. 또한, 본원의 일 실시예에 따르면, 가이드 정보 제공 장치는 충돌 위험 정보 도출 시, 해당 이미지 데이터 에 비하여 상대적으로 이전 시점에 입력된 이전 프레임 데이터에 대하여 기 도출된 충돌 위험 정보 및 주행 목 표 정보를 고려하여 해당 이미지 데이터(현재 프레임)에 대한 충돌 위험 정보를 결정하도록 동작할 수 있다. 예 를 들어, 가이드 정보 제공 장치는 현재 이미지 데이터의 직전 프레임에 해당하는 이미지 데이터에 대한 분석 결과, 내시경 모듈이 대상 부위의 오픈 루멘에 위치하는 상태로 분석된 후, 현재 프레임에서 내시경 모듈이 충돌 위험 상태인 것으로 판단되면, 해당 프레임에 대한 충돌 위험 정보가 유효하지 않은 것으로 판단하여, 해당 프레임 이후에 새로이 획득되는 이미지 데이터에 대한 분석 결과에 따른 충돌 위험 정보로 대체 하도록 동작할 수 있다. 도 6은 본원의 일 실시예에 따른 인공지능 기반의 내시경 자율주행을 위한 가이드 정보 제공 기법과 연계된 실 험예로서, 테스트 데이터에 대하여 도출된 가이드 정보와 해당 테스트 데이터에 기 부여된 라벨 정보를 비교하 여 나타낸 도면이다. 도 6을 참조하면, 본원의 일 실시예에 따른 인공지능 기반의 내시경 자율주행을 위한 가이드 정보 제공 기법과 연계된 실험예서 Grad-CAM을 이용한 정성 평가가 수행되었으며, 제1라벨 정보 및 제2라벨 정보(도 6에서 청색으 로 표시)가 부여된 그라운드 트루스 데이터와 분석 모델에 의해 도출된 주행 목표 정보(도 6에서 주황색으로 표 시) 및 충돌 위험 정보를 비교한 결과, 조향 목표 예측의 오차가 매우 적은 높은 정확도의 결과를 보이는 것을 확인할 수 있다. 이하에서는 도 7을 참조하여 가이드 정보 제공 장치가 내시경 모듈에 탑재되는 센싱 모듈을 이용하여 내시경 모듈의 루프 발생을 판단하고, 루프를 해소하기 위한 가이드 정보를 제공하는 실시예를 설명하도록 한다. 가이드 정보 제공 장치는 내시경 모듈의 삽입 위치 정보(보다 구체적으로, 내시경 모듈의 체내 삽입 단부(팁)의 위치 정보) 및 내시경 모듈의 자세 정보(보다 구체적으로, 대상자의 체내의 삽입된 내시 경 모듈의 튜브 또는 단부의 적어도 일부의 구간의 기울임 각도, 배향, 구부러짐 정도, 궤적, 꼬임 등) 중 적어도 하나를 획득하도록 내시경 모듈에 대하여 구비되는 감지 센서(미도시)의 센서 데이터를 획득할 수 있다. 한편, 본원의 일 실시예에 따르면, 전술한 삽입 위치 정보 및 자세 정보를 획득하도록 내시경 모듈에 탑재 되는 감지 센서(미도시)는 광섬유 센서(Optical fiber sensor)를 포함할 수 있다. 본원의 일 실시예에 따르면, 대상자의 체내로 삽입되도록 연장 형성되는 튜브를 이루는 적어도 일부 구간에 튜브의 거동과 연동하도록 배치 되되, 광섬유 재질로 이루어지는 감지 센서(미도시)가 배치될 수 있다. 이러한 광섬유 센서 유형의 감지 센서는, 광섬유에 가해지는 외부 물리량의 변화(신호)에 의해 광섬유 속을 진 행하는 빛에 유도되는 다양한 특성 변화를 측정하기 위한 구성일 수 있으며, 이 때 외부에서 가해지는 신호에는 온도, 압력, 전기장, 자기장, 회전, 화학물질의 농도, 기계적인 움직임 등 거의 모든 종류의 물리량들이 포함될 수 있다. 또한, 이러한 신호들에 의해 변화되는 빛의 성질에는 세기, 위상, 편광, 파장 등이 있으며, 감지 센서 (미도시)는 이러한 빛의 성질의 미세 변화를 측정하도록 동작할 수 있다. 보다 구체적으로 예시하면, 감지 센서(미도시)는 내시경 모듈의 주행에 따라 튜브에 가해지는 압력, 인장 력 등의 변화에 의해 광섬유 내부로 진행하는 빛의 성질 중 굴절률이 변화하는 정도를 계측하여 이를 기초로 내 시경 모듈의 자세 정보를 파악하는 것일 수 있으나, 이에만 한정되는 것은 아니다. 또한, 본원의 구현예에 따라서는 광섬유 센서 이외의 관성 측정 센서 등의 다양한 감지 센서가 적용될 수 있음 은 물론이다. 또한, 가이드 정보 제공 장치는 획득한 센서 데이터에 대한 분석을 통해 내시경 모듈의 루프 발생 정 보를 도출할 수 있다. 달리 말해, 가이드 정보 제공 장치는 이미지 센서(카메라 모듈)뿐만 아니라 위치, 자세 측정 수단을 활용하여 내시경의 형상, 궤적 등을 파악하여 상황에 맞는 루프 해소 기법을 적용하기 위한 분석 정보인 루프 발생 정보를 도출하도록 동작할 수 있다. 한편, 본원의 일 실시예에 따르면, 가이드 정보 제공 장치는 내시경 모듈의 삽입 위치 정보 및 자세 정보 중 적어도 하나를 이용하여 내시경 모듈에 발생한 루프 유형에 대한 정보를 포함하는 루프 발생 정보 를 도출하고, 각각의 루프 유형에 따라 미리 설정된 루프 해소 기법에 따라 내시경 모듈을 제어하도록 동 작할 수 있다. 이와 관련하여 본원의 일 실시예에 따르면, 가이드 정보 제공 장치는 내시경 모듈의 감지 센서(미도 시)로부터 수신한 센서 데이터를 입력으로 하여, 내시경 모듈의 루프 발생 유무 정보, 루프 유형 정보 등 을 포함하는 루프 발생 정보를 출력하도록 미리 학습되는 인공지능 기반의 루프 분석 모델을 보유할 수 있다. 이와 관련하여 가이드 정보 제공 장치는 루프 분석 모델과 전술한 이미지 데이터 기반의 분석 모델을 활용 하여 내시경 모듈의 주행 상태, 내시경 모듈이 삽입된 체내 대상 부위의 환경 등에 대한 분석을 보다 정밀하게 수행하고, 분석 결과를 고려하여 내시경 모듈의 최적화 된 주행(자율 주행)을 지원하는 것일 수 있다. 도 7은 루프 유형에 따른 루프 해소 기법을 설명하기 위한 개념도이다. 도 7을 참조하면, 가이드 정보 제공 장치에 의해 파악 가능한 루프 유형(루프 발생 유형)은 α-loop 타입, N-loop 타입, γ-loop 타입 등을 포함할 수 있다. 구체적으로, 도 7의 (a)는 시그모이드 알파 루프(sigmoid alpha loop) 유형을 나타내고, 도 7의 (b)는 시그모이드 엔 루프(sigmoid N loop) 유형을 나타내고, 도 7의 (c)는 리버스 알파 루프(reverse alpha loop) 유형을 나타내고, 도 7의 (d)는 비장 굴곡(splenic flexure; hockey stick) 유형을 나타내고, 도 7의 (e)는 가로 루프(transverse loop) 유형을 나타내고, 도 7의 (f)는 가 로 감마 루프(transverse gamma loop) 유형을 나타낸 것이다. 또한, 본원의 일 실시예에 따르면, 루프 유형에 따라 미리 설정되는 루프 해소 기법과 관련하여, 예시적으로 도 7의 (a)와 같은 시그모이드 알파 루프의 경우에는 내시경 모듈을 시계방향으로 회전시켜 루프를 해소하도 록 내시경 모듈을 제어할 수 있으며, 도 7의 (b)와 같은 엔 루프(N-loop)의 경우에는 점진적(반복적)으로 내시경 모듈을 전진 및 후진시킴으로써 루프를 해소하도록 내시경 모듈을 제어할 수 있다. 도 8은 본원의 일 실시예에 따른 인공지능 기반의 내시경 자율주행을 위한 가이드 정보 제공 장치의 개략적인 구성도이다. 도 8을 참조하면, 가이드 정보 제공 장치는 수집부, 분석부 및 제어부를 포함할 수 있다. 수집부는 대상자의 체내에 삽입된 내시경 모듈에 의해 촬영된 이미지 데이터를 획득할 수 있다. 분석부는 기 학습된 인공지능 기반의 분석 모델에 이미지 데이터를 입력하고, 분석 모델을 이용하여 이미 지 데이터에 대응하는 주행 목표 정보 및 충돌 위험 정보를 포함하는 가이드 정보를 도출할 수 있다. 제어부는 가이드 정보를 기초로 하여 내시경 모듈을 제어할 수 있다. 구체적으로 제어부는 충돌 위험 정보에 기초하여 내시경 모듈의 전진 주행이 불가한 것으로 판단되면, 내시경 모듈을 후진하도록 제어할 수 있다. 반대로, 충돌 위험 정보에 기초하여 내시경 모듈 의 전진 주행이 가능한 것으로 판단되면, 제어부는 주행 목표 정보를 기초로 하여 내시경 모듈 의 조향을 제어할 수 있다. 이하에서는 상기에 자세히 설명된 내용을 기반으로, 본원의 동작 흐름을 간단히 살펴보기로 한다. 도 9는 본원의 일 실시예에 따른 인공지능 기반의 내시경 자율주행을 위한 가이드 정보 제공 방법에 대한 동작 흐름도이다. 도 9에 도시된 인공지능 기반의 내시경 자율주행을 위한 가이드 정보 제공 방법은 앞서 설명된 가이드 정보 제 공 장치에 의하여 수행될 수 있다. 따라서, 이하 생략된 내용이라고 하더라도 가이드 정보 제공 장치(10 0)에 대하여 설명된 내용은 인공지능 기반의 내시경 자율주행을 위한 가이드 정보 제공 방법에 대한 설명에도 동일하게 적용될 수 있다. 도 9를 참조하면, 단계 S11에서 수집부는 (a) 대상자의 체내에 삽입된 내시경 모듈에 의해 촬영된 이 미지 데이터를 획득할 수 있다. 다음으로, 단계 S12에서 분석부는 (b) 기 학습된 인공지능 기반의 분석 모델에 이미지 데이터를 입력하고, 분석 모델을 이용하여 이미지 데이터에 대응하는 주행 목표 정보 및 충돌 위험 정보를 포함하는 가이드 정보를 도출할 수 있다. 다음으로, 단계 S13에서 제어부는 (c) 도출된 가이드 정보를 기초로 하여 내시경 모듈을 제어할 수 있다. 구체적으로 단계 S13에서 제어부는 충돌 위험 정보에 기초하여 내시경 모듈의 전진 주행이 불가한 것으로 판단되면, 내시경 모듈을 후진하도록 제어할 수 있다. 또한, 단계 S13에서 제어부는 충돌 위험 정보에 기초하여 내시경 모듈의 전진 주행이 가능한 것으로 판단되면, 주행 목표 정보를 기초로 하여 내시경 모듈의 조향을 제어할 수 있다. 상술한 설명에서, 단계 S11 내지 S13은 본원의 구현예에 따라서, 추가적인 단계들로 더 분할되거나, 더 적은 단 계들로 조합될 수 있다. 또한, 일부 단계는 필요에 따라 생략될 수도 있고, 단계 간의 순서가 변경될 수도 있다. 본원의 일 실시예에 따른 인공지능 기반의 내시경 자율주행을 위한 가이드 정보 제공 방법은 다양한 컴퓨터 수 단을 통하여 수행될 수 있는 프로그램 명령 형태로 구현되어 컴퓨터 판독 가능 매체에 기록될 수 있다. 상기 컴 퓨터 판독 가능 매체는 프로그램 명령, 데이터 파일, 데이터 구조 등을 단독으로 또는 조합하여 포함할 수있다. 상기 매체에 기록되는 프로그램 명령은 본 발명을 위하여 특별히 설계되고 구성된 것들이거나 컴퓨터 소 프트웨어 당업자에게 공지되어 사용 가능한 것일 수도 있다. 컴퓨터 판독 가능 기록 매체의 예에는 하드 디스크, 플로피 디스크 및 자기 테이프와 같은 자기 매체(magnetic media), CD-ROM, DVD와 같은 광기록 매체 (optical media), 플롭티컬 디스크(floptical disk)와 같은 자기-광 매체(magneto-optical media), 및 롬 (ROM), 램(RAM), 플래시 메모리 등과 같은 프로그램 명령을 저장하고 수행하도록 특별히 구성된 하드웨어 장치 가 포함된다. 프로그램 명령의 예에는 컴파일러에 의해 만들어지는 것과 같은 기계어 코드뿐만 아니라 인터프리 터 등을 사용해서 컴퓨터에 의해서 실행될 수 있는 고급 언어 코드를 포함한다. 상기된 하드웨어 장치는 본 발 명의 동작을 수행하기 위해 하나 이상의 소프트웨어 모듈로서 작동하도록 구성될 수 있으며, 그 역도 마찬가지 이다. 또한, 전술한 인공지능 기반의 내시경 자율주행을 위한 가이드 정보 제공 방법은 기록 매체에 저장되는 컴퓨터 에 의해 실행되는 컴퓨터 프로그램 또는 애플리케이션의 형태로도 구현될 수 있다."}
{"patent_id": "10-2022-0190564", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "전술한 본원의 설명은 예시를 위한 것이며, 본원이 속하는 기술분야의 통상의 지식을 가진 자는 본원의 기술적 사상이나 필수적인 특징을 변경하지 않고서 다른 구체적인 형태로 쉽게 변형이 가능하다는 것을 이해할 수 있을 것이다. 그러므로 이상에서 기술한 실시예들은 모든 면에서 예시적인 것이며 한정적이 아닌 것으로 이해해야만 한다. 예를 들어, 단일형으로 설명되어 있는 각 구성 요소는 분산되어 실시될 수도 있으며, 마찬가지로 분산된 것으로 설명되어 있는 구성 요소들도 결합된 형태로 실시될 수 있다. 본원의 범위는 상기 상세한 설명보다는 후술하는 특허청구범위에 의하여 나타내어지며, 특허청구범위의 의미 및 범위 그리고 그 균등 개념으로부터 도출되는 모든 변경 또는 변형된 형태가 본원의 범위에 포함되는 것으로 해 석되어야 한다."}
{"patent_id": "10-2022-0190564", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본원의 일 실시예에 따른 인공지능 기반의 내시경 자율주행 시스템의 개략적인 구성도이다. 도 2는 본원의 일 실시예에 따른 인공지능 기반의 내시경 자율주행을 위한 가이드 정보 제공 장치의 동작 프로 세스를 설명하기 위한 개념도이다. 도 3은 인공지능 기반의 분석 모델의 네트워크 구조를 예시적으로 나타낸 도면이다. 도 4는 인공지능 기반의 분석 모델의 학습을 위한 복수의 학습 데이터의 제1라벨 정보를 설명하기 위한 도면이 다. 도 5는 인공지능 기반의 분석 모델의 학습을 위한 복수의 학습 데이터의 제2라벨 정보를 설명하기 위한 도면이 다. 도 6은 본원의 일 실시예에 따른 인공지능 기반의 내시경 자율주행을 위한 가이드 정보 제공 기법과 연계된 실 험예로서, 테스트 데이터에 대하여 도출된 가이드 정보와 해당 테스트 데이터에 기 부여된 라벨 정보를 비교하 여 나타낸 도면이다. 도 7은 루프 유형에 따른 루프 해소 기법을 설명하기 위한 개념도이다. 도 8은 본원의 일 실시예에 따른 인공지능 기반의 내시경 자율주행을 위한 가이드 정보 제공 장치의 개략적인 구성도이다. 도 9는 본원의 일 실시예에 따른 인공지능 기반의 내시경 자율주행을 위한 가이드 정보 제공 방법에 대한 동작 흐름도이다."}
