{"patent_id": "10-2023-0054612", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0157916", "출원번호": "10-2023-0054612", "발명의 명칭": "벡터 연산을 가속하기 위한 외적 기반 행렬-백터곱 연산 장치 및 이를 이용한 방법", "출원인": "한국전자통신연구원", "발명자": "김혜지"}}
{"patent_id": "10-2023-0054612", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "각각, MAC(Multiply-Accumulation) 연산을 수행하여 누적값을 생성하는 내부 연산기들;벡터의 원소를 동시에 두 개 이상의 내부 연산기들로 제공하는 내부 데이터 전송 경로; 및상기 벡터의 원소 및 행렬의 벡터 중 어느 하나를 선택하는 적어도 하나의 멀티플렉서를 포함하고,상기 내부 연산기들 각각의 제1 입력 포트는 행렬의 벡터들 중 하나가 연결되고, 상기 내부 연산기들 각각의 제2 입력 포트는 상기 벡터의 원소가 연결되는 것을 특징으로 하는 외적 기반 행렬-벡터곱 연산 장치."}
{"patent_id": "10-2023-0054612", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "청구항 1에 있어서,상기 내부 연산기들로 구성된 어레이(ARRAY)의 데이터 입력 포트들 중 하나의 원소 포트는 상기 벡터의 원소에할당되고, 상기 데이터 입력 포트들 중 상기 하나의 원소 포트를 제외한 벡터 포트들은 상기 행렬의 벡터들에할당되는 것을 특징으로 하는 외적 기반 행렬-벡터곱 연산 장치."}
{"patent_id": "10-2023-0054612", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "청구항 2에 있어서,상기 행렬의 벡터들이 각각 부동소수점 데이터 타입에서 가수(MANTISSA) 및 지수(EXPONENT)의 비트(BIT)를 줄여정밀도를 낮춘 두 개의 반정밀도(HALF-PRECISION) 데이터가 결합된 다중 데이터일 경우, 상기 다중 데이터는 두개의 내부 연산기들로 동시에 입력되는 것을 특징으로 하는 외적 기반 행렬-벡터곱 연산 장치."}
{"patent_id": "10-2023-0054612", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "청구항 3에 있어서,상기 두 개의 내부 연산기들 중 하나는 상기 다중 데이터에서 하위 비트를 마스킹(MASKING)하여 상위 비트를 기반으로 연산을 수행하고, 상기 두 개의 내부 연산기들 중 나머지 하나는 상기 다중 데이터에서 상위 비트를 마스킹하여 하위 비트를 기반으로 연산을 수행하는 것을 특징으로 하는 외적 기반 행렬-벡터곱 연산 장치."}
{"patent_id": "10-2023-0054612", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "청구항 4에 있어서,상기 두 개의 내부 연산기들은 상기 어레이에서 같은 행(ROW) 또는 같은 열(COLUMN)에 위치하되, 상위 비트를기반으로 연산을 수행하는 제1 내부 연산기 및 하위 비트를 기반으로 연산을 수행하는 제2 내부 연산기의 순서로 위치하는 것을 특징으로 외적 기반 행렬-벡터곱 연산 장치."}
{"patent_id": "10-2023-0054612", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "청구항 2에 있어서,상기 적어도 하나의 멀티플렉서는상기 원소 포트의 위치를 고려하여, 상기 행렬의 벡터가 할당된 모든 내부 연산기들로 상기 벡터의 원소가 제공될 수 있도록 구비되는 것을 특징으로 하는 외적 기반 행렬-벡터곱 연산 장치."}
{"patent_id": "10-2023-0054612", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "청구항 3에 있어서,공개특허 10-2024-0157916-3-상기 다중 데이터는상기 반정밀도(HALF-PRECISION) 데이터 또는 반정밀도 데이터보다 크기가 작은 데이터의 데이터 타입을 고려한형변환을 수행하여 생성되는 것을 특징으로 하는 외적 기반 행렬-벡터곱 연산 장치."}
{"patent_id": "10-2023-0054612", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "청구항 7에 있어서,상기 반정밀도 데이터의 데이터 타입이 지수 편향 부동 소수점(EXPONEBT-BIASED FLOATING-POINT)인 경우, 행렬-벡터곱 연산의 결과 값에 기설정된 지수 편향 값(EXPONENT BIAS)을 감산하여 상기 결과 값의 범위를 보정하는것을 특징으로 하는 외적 기반 행렬-벡터곱 연산 장치."}
{"patent_id": "10-2023-0054612", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "내부 데이터 전송 경로에 의하여, 벡터의 원소를 동시에 두 개 이상의 내부 연산기들로 제공하는 단계;적어도 하나의 멀티플렉서에 의하여, 상기 벡터의 원소 및 행렬의 벡터 중 어느 하나를 선택하는 단계; 및내부 연산기들이 각각, MAC(Multiply-Accumulation) 연산을 수행하여 누적값을 생성하는 단계를 포함하고,상기 내부 연산기들 각각의 제1 입력 포트는 행렬의 벡터들 중 하나가 연결되고, 상기 내부 연산기들 각각의 제2 입력 포트는 상기 벡터의 원소가 연결되는 것을 특징으로 하는 외적 기반 행렬-벡터곱 연산 방법."}
{"patent_id": "10-2023-0054612", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "청구항 9에 있어서,상기 내부 연산기들로 구성된 어레이(ARRAY)의 데이터 입력 포트들 중 하나의 원소 포트는 상기 벡터의 원소에할당되고, 상기 데이터 입력 포트들 중 상기 하나의 원소 포트를 제외한 벡터 포트들은 상기 행렬의 벡터들에할당되는 것을 특징으로 하는 외적 기반 행렬-벡터곱 연산 방법."}
{"patent_id": "10-2023-0054612", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "청구항 10에 있어서,상기 행렬의 벡터들이 각각 부동소수점 데이터 타입에서 가수(MANTISSA) 및 지수(EXPONENT)의 비트(BIT)를 줄여정밀도를 낮춘 두 개의 반정밀도(HALF-PRECISION) 데이터가 결합된 다중 데이터일 경우, 상기 다중 데이터는 두개의 내부 연산기들로 동시에 입력되는 것을 특징으로 하는 외적 기반 행렬-벡터곱 연산 방법."}
{"patent_id": "10-2023-0054612", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "청구항 11에 있어서,상기 두 개의 내부 연산기들 중 하나는 상기 다중 데이터에서 하위 비트를 마스킹(MASKING)하여 상위 비트를 기반으로 연산을 수행하고, 상기 두 개의 내부 연산기들 중 나머지 하나는 상기 다중 데이터에서 상위 비트를 마스킹하여 하위 비트를 기반으로 연산을 수행하는 것을 특징으로 하는 외적 기반 행렬-벡터곱 연산 방법."}
{"patent_id": "10-2023-0054612", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "청구항 12에 있어서,상기 두 개의 내부 연산기들은 상기 어레이에서 같은 행(ROW) 또는 같은 열(COLUMN)에 위치하되, 상위 비트를기반으로 연산을 수행하는 제1 내부 연산기 및 하위 비트를 기반으로 연산을 수행하는 제2 내부 연산기의 순서로 위치하는 것을 특징으로 하는 외적 기반 행렬-벡터곱 연산 방법."}
{"patent_id": "10-2023-0054612", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "청구항 10에 있어서,상기 적어도 하나의 멀티플렉서는공개특허 10-2024-0157916-4-상기 원소 포트의 위치를 고려하여, 상기 행렬의 벡터가 할당된 모든 내부 연산기들로 상기 벡터의 원소가 제공될 수 있도록 구비되는 것을 특징으로 하는 외적 기반 행렬-벡터곱 연산 방법."}
{"patent_id": "10-2023-0054612", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "청구항 11에 있어서,상기 다중 데이터는상기 반정밀도(HALF-PRECISION) 데이터의 데이터 타입을 고려한 형변환을 수행하여 생성되는 것을 특징으로 하는 외적 기반 행렬-벡터곱 연산 방법."}
{"patent_id": "10-2023-0054612", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "청구항 15에 있어서,상기 반정밀도 데이터의 데이터 타입이 지수 편향 부동 소수점(EXPONEBT-BIASED FLOATING-POINT)인 경우, 행렬-벡터곱 연산의 결과 값에 기설정된 지수 편향 값(EXPONENT BIAS)을 감산하여 상기 결과 값의 범위를 보정하는것을 특징으로 하는 외적 기반 행렬-벡터곱 연산 방법."}
{"patent_id": "10-2023-0054612", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "외적 기반 행렬-백터곱 연산 장치 및 이를 이용한 방법이 개시된다. 본 발명의 일실시예에 따른 외적 기반 행렬 -벡터곱 연산 장치는 각각, MAC(Multiply-Accumulation) 연산을 수행하여 누적값을 생성하는 내부 연산기들; 벡 터의 원소를 동시에 두 개 이상의 내부 연산기들로 제공하는 내부 데이터 전송 경로; 및 상기 벡터의 원소 및 행 렬의 벡터 중 어느 하나를 선택하는 적어도 하나의 멀티플렉서를 포함하고, 상기 내부 연산기들 각각의 제1 입력 포트는 행렬의 벡터들 중 하나가 연결되고, 상기 내부 연산기들 각각의 제2 입력 포트는 상기 벡터의 원소가 연 결된다."}
{"patent_id": "10-2023-0054612", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 벡터 연산을 가속하기 위한 외적 기반 행렬-벡터곱 연산 기술에 관한 것으로, 특히 외적 연산기 (Outer-Product)를 기반으로 신경망 가속 반도체 회로의 행렬-벡터 연산을 데이터 경량화 기법과 혼합하여 고속 으로 처리하기 위한 하드웨어 구조와 이를 이용한 연산 방법에 관한 것이다."}
{"patent_id": "10-2023-0054612", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "기존의 인공신경망을 가속하는 하드웨어 구조는 행렬-행렬곱 연산을 빠르게 처리하는데 집중하고 있다. 그러나, 최근 인공신경망의 구조가 다각화되면서 행렬-행렬곱 연산뿐만 아니라 행렬-벡터곱 연산의 사용량이 증가하는 추세이다. 특히, 어텐션 레이어(Attention Layer)가 중심이 되는 트랜스포머 신경망 구조는 주요 연산이 행렬- 벡터곱으로 구성되어 있어, 그 필요성이 더욱 두각되고 있다. 그러나, 현재 개발되어 있는 인공지능 가속기의 구조는 가장 연산복잡도가 높은 행렬-행렬곱 연산에 최적화되어 있기 때문에 행렬-벡터곱 연산에 대해서는 행렬-행렬곱 연산 대비 속도 증가량이 현저히 떨어지며, 가속기 운용 량(utilization)이 줄어드는 문제가 있다. 이러한 현상은 이론적으로 메모리 대역폭의 한계에 의해 발생한다. 즉, 행렬-벡터곱 연산을 빠르게 하고 가속기 운용량(utilization)을 늘리기 위해서는 메모리로부터 초당 전달받을 수 있는 데이터량을 늘리면 된다. 그러나 이는 하드웨어 면적과 전체 연산기의 복잡도에 직결되는 문제이며, 기존의 행렬-행렬곱 연산에서는 이미 메모리 대역폭을 완전히 사용하여 연산을 수행하고 있다. 즉, 행렬-벡터곱 연산을 가속하기 위해 메모리 대역폭만 늘린 다면, 오히려 행렬-행렬곱 연산에서는 메모리 대역폭을 온전히 다 사용하지 못하는 문제가 발생하여 전체 시스 템 상에서 복잡도만 증가하고 불필요한 시스템 운용을 야기할 수 있다. 따라서, 추가적인 하드웨어 사용을 최소화하기 위해 행렬-행렬곱에 최적화된 종래의 가속기 구조를 그대로 활용 하고, 메모리 대역폭을 완전히 사용하여 연산기 운용률을 증가시킴으로써 행렬-벡터곱 연산 속도를 향상시킬 수 있는 전용의 연산 구조 및 방법론이 요구된다. 선행기술문헌 특허문헌 (특허문헌 0001) 한국 공개 특허 제10-2020-0070088호, 2020년 6월 17일 공개(명칭: GEMM 데이터플로우 가속기"}
{"patent_id": "10-2023-0054612", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 2, "content": "반도체 회로) 발명의 내용"}
{"patent_id": "10-2023-0054612", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명의 목적은 AI 반도체의 행렬-행렬곱 연산기 구조를 그대로 재활용하면서 행렬-벡터곱 연산을 가속할 수 있는 하드웨어 구조를 제공하는 것이다. 또한, 본 발명의 목적은 데이터 경량화 기법과 혼합하여 동일한 메모리 밴드위스(Memory Bandwidth)에 더 많은 데이터량을 전송함으로써 메모리 인터페이스 이용률을 최대화하고, 연산기의 운용량(Utilization)을 향상시키는 것이다. 또한, 본 발명의 목적은 차세대 신경망 구조의 주요 연산(행렬-벡터곱) 속도를 향상시켜 AI 반도체의 활용 범위 를 넓히고, 학습 능력을 향상시키는 것이다."}
{"patent_id": "10-2023-0054612", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기한 목적을 달성하기 위한 본 발명에 따른 외적 기반 행렬-벡터곱 연산 장치는, 각각, MAC(Multiply- Accumulation) 연산을 수행하여 누적값을 생성하는 내부 연산기들; 벡터의 원소를 동시에 두 개 이상의 내부 연 산기들로 제공하는 내부 데이터 전송 경로; 및 상기 벡터의 원소 및 행렬의 벡터 중 어느 하나를 선택하는 적어 도 하나의 멀티플렉서를 포함하고, 상기 내부 연산기들 각각의 제1 입력 포트는 행렬의 벡터들 중 하나가 연결 되고, 상기 내부 연산기들 각각의 제2 입력 포트는 상기 벡터의 원소가 연결된다. 이 때, 내부 연산기들로 구성된 어레이(ARRAY)의 데이터 입력 포트들 중 하나의 원소 포트는 상기 벡터의 원소 에 할당되고, 상기 데이터 입력 포트들 중 상기 하나의 원소 포트를 제외한 벡터 포트들은 상기 행렬의 벡터들 에 할당될 수 있다. 이 때, 행렬의 벡터들이 각각 부동소수점 데이터 타입에서 가수(MANTISSA) 및 지수(EXPONENT)의 비트(BIT)를 줄 여 정밀도를 낮춘 두 개의 반정밀도(HALF-PRECISION) 데이터가 결합된 다중 데이터일 경우, 상기 다중 데이터는 두 개의 내부 연산기들로 동시에 입력될 수 있다. 이 때, 두 개의 내부 연산기들 중 하나는 상기 다중 데이터에서 하위 비트를 마스킹(MASKING)하여 상위 비트를 기반으로 연산을 수행하고, 상기 두 개의 내부 연산기들 중 나머지 하나는 상기 다중 데이터에서 상위 비트를 마스킹하여 하위 비트를 기반으로 연산을 수행할 수 있다. 이 때, 두 개의 내부 연산기들은 상기 어레이에서 같은 행(ROW) 또는 같은 열(COLUMN)에 위치하되, 상위 비트를 기반으로 연산을 수행하는 제1 내부 연산기 및 하위 비트를 기반으로 연산을 수행하는 제2 내부 연산기의 순서 로 위치할 수 있다. 이 때, 적어도 하나의 멀티플렉서는 상기 원소 포트의 위치를 고려하여, 상기 행렬의 벡터가 할당된 모든 내부 연산기들로 상기 벡터의 원소가 제공될 수 있도록 구비될 수 있다. 이 때, 다중 데이터는 상기 반정밀도(HALF-PRECISION) 데이터 또는 반정밀도 데이터보다 크기가 작은 데이터의 데이터 타입을 고려한 형변환을 수행하여 생성될 수 있다. 이 때, 반정밀도 데이터의 데이터 타입이 지수 편향 부동 소수점(EXPONEBT-BIASED FLOATING-POINT)인 경우, 행 렬-벡터곱 연산의 결과 값에 기설정된 지수 편향 값(EXPONENT BIAS)을 감산하여 상기 결과 값의 범위를 보정할 수 있다. 또한, 본 발명의 일실시예에 따른 외적 기반 행렬-벡터곱 연산 방법은, 내부 데이터 전송 경로에 의하여, 벡터 의 원소를 동시에 두 개 이상의 내부 연산기들로 제공하는 단계; 적어도 하나의 멀티플렉서에 의하여, 상기 벡 터의 원소 및 행렬의 벡터 중 어느 하나를 선택하는 단계; 및 내부 연산기들이 각각, MAC(Multiply- Accumulation) 연산을 수행하여 누적값을 생성하는 단계를 포함하고, 상기 내부 연산기들 각각의 제1 입력 포트 는 행렬의 벡터들 중 하나가 연결되고, 상기 내부 연산기들 각각의 제2 입력 포트는 상기 벡터의 원소가 연결된 다. 이 때, 내부 연산기들로 구성된 어레이(ARRAY)의 데이터 입력 포트들 중 하나의 원소 포트는 상기 벡터의 원소 에 할당되고, 상기 데이터 입력 포트들 중 상기 하나의 원소 포트를 제외한 벡터 포트들은 상기 행렬의 벡터들 에 할당될 수 있다.이 때, 행렬의 벡터들이 각각 부동소수점 데이터 타입에서 가수(MANTISSA) 및 지수(EXPONENT)의 비트(BIT)를 줄 여 정밀도를 낮춘 두 개의 반정밀도(HALF-PRECISION) 데이터가 결합된 다중 데이터일 경우, 상기 다중 데이터는 두 개의 내부 연산기들로 동시에 입력될 수 있다. 이 때, 두 개의 내부 연산기들 중 하나는 상기 다중 데이터에서 하위 비트를 마스킹(MASKING)하여 상위 비트를 기반으로 연산을 수행하고, 상기 두 개의 내부 연산기들 중 나머지 하나는 상기 다중 데이터에서 상위 비트를 마스킹하여 하위 비트를 기반으로 연산을 수행할 수 있다. 이 때, 두 개의 내부 연산기들은 상기 어레이에서 같은 행(ROW) 또는 같은 열(COLUMN)에 위치하되, 상위 비트를 기반으로 연산을 수행하는 제1 내부 연산기 및 하위 비트를 기반으로 연산을 수행하는 제2 내부 연산기의 순서 로 위치할 수 있다. 이 때, 적어도 하나의 멀티플렉서는 상기 원소 포트의 위치를 고려하여, 상기 행렬의 벡터가 할당된 모든 내부 연산기들로 상기 벡터의 원소가 제공될 수 있도록 구비될 수 있다. 이 때, 다중 데이터는 상기 반정밀도(HALF-PRECISION) 데이터 또는 반정밀도 데이터보다 크기가 작은 데이터의 데이터 타입을 고려한 형변환을 수행하여 생성될 수 있다. 이 때, 반정밀도 데이터의 데이터 타입이 지수 편향 부동 소수점(EXPONEBT-BIASED FLOATING-POINT)인 경우, 행 렬-벡터곱 연산의 결과 값에 기설정된 지수 편향 값(EXPONENT BIAS)을 감산하여 상기 결과 값의 범위를 보정할 수 있다."}
{"patent_id": "10-2023-0054612", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명에 따르면, AI 반도체의 행렬-행렬곱 연산기 구조를 그대로 재활용하면서 행렬-벡터곱 연산을 가속할 수 있는 하드웨어 구조를 제공할 수 있다. 또한, 본 발명은 데이터 경량화 기법과 혼합하여 동일한 메모리 밴드위스(Memory Bandwidth)에 더 많은 데이터 량을 전송함으로써 메모리 인터페이스 이용률을 최대화하고, 연산기의 운용량(Utilization)을 향상시킬 수 있다. 또한, 본 발명은 차세대 신경망 구조의 주요 연산(행렬-벡터곱) 속도를 향상시켜 AI 반도체의 활용 범위를 넓히 고, 학습 능력을 향상시킬 수 있다."}
{"patent_id": "10-2023-0054612", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명을 첨부된 도면을 참조하여 상세히 설명하면 다음과 같다. 여기서, 반복되는 설명, 본 발명의 요지를 불 필요하게 흐릴 수 있는 공지 기능, 및 구성에 대한 상세한 설명은 생략한다. 본 발명의 실시형태는 당 업계에서 평균적인 지식을 가진 자에게 본 발명을 보다 완전하게 설명하기 위해서 제공되는 것이다. 따라서, 도면에서의 요소들의 형상 및 크기 등은 보다 명확한 설명을 위해 과장될 수 있다. 본 문서에서, \"A 또는 B\", \"A 및 B 중 적어도 하나\", \"A 또는 B 중 적어도 하나\", \"A, B 또는 C\", \"A, B 및 C 중 적어도 하나\", 및 \"A, B, 또는 C 중 적어도 하나\"와 같은 문구들 각각은 그 문구들 중 해당하는 문구에 함께 나열된 항목들 중 어느 하나, 또는 그들의 모든 가능한 조합을 포함할 수 있다. 이하, 본 발명에 따른 바람직한 실시예를 첨부된 도면을 참조하여 상세하게 설명한다. 도 1 내지 도 2는 Outer-Product 기반 행렬곱 연산기 구조의 일 예를 나타낸 도면이다. 먼저, 도 1을 참조하면, 행렬-행렬곱 연산(Matrix-Matrix Multiplication)인 경우, 두 개의 입력 행렬들에서 각각 파생된 L-dimension 벡터(도 1의 A0~A3 및 B0~B3)를 연산기의 입력으로 받을 수 있고, 벡터에 대한 연산 결과는 각 데이터의 모든 조합으로 구성된 LxL행렬로 생성될 수 있다. 또한, 도 2는 행렬-벡터곱 연산(Matrix-Vector Multiplication)에 해당한다. 도 2와 같이 기존의 행렬-행렬곱 연산 구조를 그대로 가져간다면, 각 연산 사이클마다 벡터의 원소(도 2의 B0)와 행렬의 L-dimension 벡터(도 2 의 A0~A3)를 입력받아 연산을 수행할 수 있고, 출력으로 L-dimension 벡터 데이터를 생성할 수 있다. 그러나, 도 2와 같은 연산 구조는 원소(B0) 입력에 의해 메모리 대역폭 점유율이 현저히 떨어지고, 연산기 운용 량(utilization) 또한 줄어들게 된다. 따라서 본 발명에서는 주어진 메모리 대역폭을 완전히 사용하면서도, 종래의 행렬-벡터곱 연산과 비교하였을 때 연산기 운용량(utilization)을 약 4배 향상시켜서 연산 속도를 약 4배 빠르게 할 수 있는 외적 기반 행렬-벡터 곱 연산 장치의 구조와 방법을 제안하도록 한다. 도 3 내지 도 5는 본 발명의 일실시예에 따른 Outer-Product 기반 행렬-벡터곱 연산 장치의 구조를 나타낸 도면 이다. 도 3 내지 도 5를 참조하면, 본 발명의 일실시예에 따른 Outer-Product 기반 행렬-벡터곱 연산 장치는 기존에 벡터의 원소(도 3 내지 도 5에서 B0)를 입력받던 메모리 인터페이스에 행렬의 벡터(도 3 내지 도 5에서 A0~A6) 를 확장하여 할당하는 방식으로 동작할 수 있다. 이 때, 도 3에 도시된 실시예는 벡터에서 파생된 원소(B0)를 입력받아 (2L-1)개의 내부 연산기들을 활용하는 외 적 기반 행렬-벡터곱 연산 장치의 구조를 나타낸 것이고, 도 4 내지 도 5에 도시된 실시예는 벡터에서 파생된 원소(B0)를 입력받아 (4L-2)개의 내부 연산기들을 활용하는 외적 기반 행렬-벡터곱 연산 장치의 구조를 나타낸 것이다. 도 3 내지 도 5를 참조하면, 본 발명의 일실시예에 따른 Outer-Product 기반 행렬-벡터곱 연산 장치는, 각각 MAC(Multiply-Accumulation) 연산을 수행하여 누적값을 생성하는 내부 연산기들, 벡터의 원소를 동시에 두 개 이상의 내부 연산기들로 제공하는 내부 데이터 전송 경로(310, 410, 510), 벡터의 원소 및 행렬의 벡터 중 어느 하나를 선택하는 적어도 하나의 멀티플렉서(320, 421~427, 521~529)를 포함한다. 이 때, 내부 연산기들 각각의 제1 입력 포트는 행렬의 벡터들 중 하나가 연결되고, 내부 연산기들 각각의 제2 입력 포트는 벡터의 원소가 연결된다. 이 때, 내부 연산기들로 구성된 어레이(ARRAY)의 데이터 입력 포트들 중 하나의 원소 포트는 벡터의 원소에 할 당되고, 데이터 입력 포트들 중 하나의 원소 포트를 제외한 벡터 포트들은 행렬의 벡터들에 할당될 수 있다. 이 때, 적어도 하나의 멀티플렉서는 원소 포트의 위치를 고려하여, 행렬의 벡터가 할당된 모든 내부 연산기들로 벡터의 원소가 제공될 수 있도록 구비될 수 있다. 예를 들어, 도 3은 2:1 멀티플렉서를 1개만 추가하여 도 2에 도시된 종래 구조보다 연산 속도를 약 2배 향상시 킬 수 있는 행렬-벡터곱 연산 장치의 구조의 일실시예에 해당한다. 이 때, 본 발명에 따른 2:1 멀티플렉서는 도 6에 도시된 형태에 상응할 수 있다. 예를 들어, 도 6에 도시된 멀 티플렉서를 참조하면, 하나의 원소 포트를 통해 입력되는 벡터의 원소(B)와 여러 벡터 포트들을 통해 입력 되는 행렬의 벡터(A)를 입력값으로 동작할 수 있다. 이 때, 멀티플렉서는 S의 값이 0일 때 행렬의 벡터 (A)를 출력(OUT)으로 결정하여 전달하고, 또는 S의 값이 1일 때 벡터의 원소(B)를 출력(OUT)으로 결정하여 전달 하도록 동작할 수 있다. 이 때, 멀티플렉서에서 S의 값은 멀티플렉서의 출력(OUT)이 전달되는 내부 연산기로 어떤 값이 입력 되어 있는지 여부에 따라 결정될 수 있다. 예를 들어, 본 발명에 따른 내부 연산기들은 각각 행렬의 벡터와 벡 터의 원소를 1개씩만 입력받아 동작해야하므로, 멀티플렉서의 출력(OUT)이 전달되는 내부 연산기로 이미 벡터의 원소(B)가 입력되어 있다면, 멀티플렉서의 S 값을 0으로 설정하여 행렬의 벡터(A)가 내부 연산기로 전달되도록 제어할 수 있다. 반대로, 멀티플렉서의 출력(OUT)이 전달되는 내부 연산기로 이미 행렬의 벡터 (A)가 입력되어 있다면, 멀티플렉서의 S 값을 1로 설정하여 벡터의 원소(B)가 내부 연산기로 전달되도록 제어할 수 있다. 도 3에 도시된 구조는 벡터에서 파생된 원소(B0)를 입력받아 (2L-1)개의 내부 연산기들을 활용하는 실시예로, 기본적으로 행(Row)과 열(Column)에 해당하는 인터페이스는 L-dimension 벡터의 입력을 허용할 수 있다. 이 때, 도 3에 도시된 행(Row)과 열(Column)에 해당하는 인터페이스, 즉 어레이의 데이터 입력 포트 중 하나는 벡터의 원소가 입력되는 원소 포트로 고정될 수 있다. 따라서, 하나의 원소 포트를 제외한 나머지 (2L-1)개의 데이터 입력 포트들은 행렬에서 파생된 벡터(A0~A6)에 할당되는 벡터 포트에 상응할 수 있다. 결국, 도 3에 도시된 구조에 따르면 매 사이클당 (2L-1)개의 벡터(A0~A6)를 입력받아 연산을 수행할 수 있으며, 이는 도 2에 도시된 종래의 연산방식과 비교하였을 때 연산 속도를 약 2배 향상시켜 연산 시간을 단축시킬 수 있다. 이 때, 벡터의 원소가 입력되는 원소 포트(B0)는 행(Row) 또는 열(Column)에 해당하는 인터페이스 중 어디에도 위치할 수 있으며, 원소 포트로 입력되는 벡터의 원소가 나머지 벡터 포트들(A0~A6)을 통해 행렬의 벡터가 할당 된 모든 내부 연산기들(A3B0, A4B0, A5B0, A6B0, B0A0, B0A1, B0A2)로 전달되면 연산이 가능하게 된다. 즉, 원소 포트를 통해 입력되는 벡터의 원소는 각 벡터 포트에 할당된 내부 연산기로 일괄적으로 전달되어야 하 므로, 종래의 행렬곱 구조에서 추가적으로 내부 데이터 전송 경로 및 멀티플렉서(2:1 MUX Logic)가 요구된다. 도 3에 도시된 실시예에서는 원소 포트(B0)가 각각 벡터 포트(A0, A1, A2)에 할당된 내부 연산기(B0A0, B0A1, B0A2)에 모두 할당되기 위해, A3와 B0의 2:1 MUX를 통해 B0 입력이 브로드캐스팅(Broadcasting)되도록 구성되었 다. 이 때, 행렬의 벡터들이 각각 부동소수점 데이터 타입에서 가수(MANTISSA) 및 지수(EXPONENT)의 비트(BIT)를 줄 여 정밀도를 낮춘 두 개의 반정밀도(HALF-PRECISION) 데이터가 결합된 다중 데이터일 경우, 다중 데이터는 두 개의 내부 연산기들로 동시에 입력될 수 있다. 이 때, 두 개의 내부 연산기들 중 하나는 다중 데이터에서 하위 비트를 마스킹(MASKING)하여 상위 비트를 기반 으로 연산을 수행하고, 두 개의 내부 연산기들 중 나머지 하나는 다중 데이터에서 상위 비트를 마스킹하여 하위 비트를 기반으로 연산을 수행할 수 있다. 이 때, 두 개의 내부 연산기들은 어레이에서 같은 행(ROW) 또는 같은 열(COLUMN)에 위치하되, 상위 비트를 기반 으로 연산을 수행하는 제1 내부 연산기 및 하위 비트를 기반으로 연산을 수행하는 제2 내부 연산기의 순서로 위 치할 수 있다. 예를 들어, 도 4 내지 도 5는 2:1 멀티플렉서를 최소 7개 추가하여 도 2에 도시된 종래 구조보다 연산 속도를 약 4배 향상시킬 수 있는 행렬-벡터곱 연산 장치의 구조의 일실시예에 해당한다. 도 4 내지 도 5에 도시된 구조는 벡터에서 파생된 원소(B0)를 입력받아 (4L-2)개의 내부 연산기들을 활용하는 실시예이다. 이 때, 도 4 내지 도 5에 도시된 구조는 어레이의 데이터 입력 포트 하나에 행렬에서 파생된 벡터데이터가 2개 집적된 형태로 입력되므로, 하나의 벡터 포트에 2개의 내부 연산기가 동시에 할당될 수 있다. 결국, 도 4 내지 도 5에 도시된 구조에 따르면 매 사이클당 (4L-2)개의 벡터(A0~A6 UP파트, A0~A6 DOWN파트)를 입력받아 연산을 수행할 수 있으며, 이는 도 2에 도시된 종래의 연산방식과 비교하였을 때 연산 속도를 약 4배 향상시켜 연산 시간을 단축시킬 수 있다. 이 때, 도 3과 마찬가지로 도 4 내지 도 5에서도 원소 포트를 통해 입력되는 벡터의 원소가 각 벡터 포트에 할 당된 내부 연산기로 일괄적으로 전달되어야 하므로, 종래의 행렬곱 구조에서 추가로 내부 데이터 전송 경로 (410, 410) 및 최소 7개의 멀티플렉서들(421~427, 521~529)(2:1 MUX Logic)이 요구된다. 이 때, 도 4 내지 도 5에 내부 연산기들로 입력되는 행렬의 벡터(A0~A6)는 내부에 2개의 데이터에 해당하는 상 위 비트(UP)와 하위 비트(DOWN)를 포함하는 다중 데이터일 수 있다. 따라서, 각각의 내부 연산기는 상위 비트 또는 하위 비트를 마스킹한 뒤 필요한 데이터만 활용하여 연산을 수행할 수 있다. 도 4에 도시된 실시예에서는 원소 포트(B0)가 모든 내부 연산기에 할당되기 위해, A3와 B0의 2:1 MUX, A0 와 B0의 2:1 MUX, A4와 B0의 2:1 MUX, A0와 B0의 2:1 MUX, A1와 B0의 2:1 MUX, A5와 B0 의 2:1 MUX, A6와 B0의 2:1 MUX를 통해 B0 입력이 브로드캐스팅(Broadcasting)되도록 구성되었다. 도 5에 도시된 실시예에서는 원소 포트(B0)가 모든 내부 연산기에 할당되기 위해, A3와 B0의 2:1 MUX, A0 와 B0의 2:1 MUX, A4와 B0의 2:1 MUX, A0와 B0의 2:1 MUX, A1와 B0의 2:1 MUX, A2와 B0 의 2:1 MUX, A5와 B0의 2:1 MUX, A2와 B0의 2:1 MUX, A6와 B0의 2:1 MUX를 통해 B0 입력 이 브로드캐스팅(Broadcasting)되도록 구성되었다. 또한, 도 4 내지 도 5를 참조하면, 하나의 다중 데이터가 동일하게 입력되는 두 개의 내부 연산기들은 같은 행 (ROW) 또는 같은 열(COLUMN)에 위치하는 것을 알 수 있다. 예를 들어, 도 4에서 A3 입력을 받는 두 개의 내부 연산기들에 해당하는 A3B0(UP)와 A3B0(DOWN)이 같은 행에 위 치하는 것을 알 수 있다. 다른 예를 들어, A0 입력을 받는 두 개의 내부 연산기들에 해당하는 B0A0(UP)와 B0A0(DOWN)이 같은 열에 위치하는 것을 알 수 있다. 이 때, 하나의 다중 데이터가 동일하게 입력되는 두 개의 내부 연산기들은 각 행과 열에서 상위 비트를 기반으 로 연산을 수행하는 제1 내부 연산기 및 하위 비트를 기반으로 연산을 수행하는 제2 내부 연산기의 순서로 위치 할 수 있다. 예를 들어, 도 4에서 A4 입력을 받는 두 개의 내부 연산기들은 같은 행에서 A4B0(UP)와 A4B0(DOWN)의 순서로 위 치할 수 있다. 다른 예를 들어, A1 입력을 받는 두 개의 내부 연산기들은 같은 열에서 B0A1(UP)와 B0A1(DOWN) 의 순서로 위치할 수 있다. 이 때, 도 3 내지 도 5에 도시된 벡터 포트들(A0~A6)은 행(Row) 또는 열(Column) 방향으로 위치하는 복수의 내 부 연산기들 중 지정된 내부 연산기로만 데이터를 전송할 수 있다. 따라서, 지정되지 않은 나머지 내부 연산기 에게는 데이터가 전송되지 않도록 입력이 바이패스(bypass) 될 수 있다. 이 때, 벡터 포트들(A0~A6)마다 지정되는 내부 연산기의 개수는 각 포트로 입력되는 데이터가 하나의 데이터인 지 혹은 복수개의 데이터가 집적된 다중 데이터인지에 따라 결정될 수 있다. 예를 들어, 각 벡터 포트로 입력되 는 데이터가 하나의 데이터라면, 도 3에 도시된 것처럼 벡터 포트들(A0~A6)마다 행(Row) 또는 열(Column) 방향 으로 1개의 내부 연산기만 지정하여 데이터가 전송되도록 할 수 있다. 다른 예를 들어, 각 벡터 포트로 입력되 는 데이터가 2개의 데이터가 집적된 형태의 다중 데이터라면, 도 4 내지 도 5에 도시된 것처럼 벡터 포트들 (A0~A6)마다 행(Row) 또는 열(Column) 방향으로 2개의 내부 연산기들을 지정하여 데이터가 전송되도록 할 수 있 다. 즉, 다중 데이터가 몇 개의 데이터들을 집적하여 생성되었는지에 따라 지정되는 내부 연산기의 개수가 결정될 수 있는데, 다중 데이터에 집적 가능한 데이터의 수는 내부 연산기들로 구성된 어레이의 크기와 관련될 수 있다. 예를 들어, 어레이의 크기가 도 3 내지 도 5에 도시된 것처럼 4X4인 경우, 행(Row) 또는 열(Column)마다 내부 연산기들을 4개씩 배치할 수 있으므로 최대 2개의 데이터까지 집적 가능하다. 만약, 3개의 데이터들을 집적한 다중 데이터에 대한 연산을 수행하기 위해서는 행(Row) 또는 열(Column)마다 6개의 내부 연산기들을 배치할 수 있는 6X6 형태의 어레이 크기를 갖는 연산 장치가 필요할 수 있다.이 때, 도 7 내지 도 9는 종래의 행렬-벡터곱 연산 구조와 본 발명에 따른 행렬-벡터곱 연산 구조에서 각 데이 터 입력 포트를 통해 할당된 데이터의 구조를 나타낸 실시예이다. 먼저, 도 7에 도시된 Conventional Matrix-Vector Multiplication은 도 2에 도시된 종래의 행렬-벡터곱 연산 구조에 관한 것으로, 매 cycle당 행렬에서 파생된 N-bit의 벡터(Matrix Element) L개를 N-bit의 벡터 원소 (Vector Element) 1개와 곱셈 연산하는 구조에 상응할 수 있다. 이 때, L개의 연산 결과는 각각 L개의 내부 연 산기들을 통해 병렬 처리되며, 다음 cycle에서 다시 L개의 벡터(Matrix Element)와 1개의 원소(Vector Element)를 곱셈한 결과와 누적연산하는 방식이다. 또한, 도 8에 도시된 Port-Extended Matrix-Vector Multiplication은 도 3에 도시된 본 발명의 일실시예에 따 른 행렬-벡터곱 연산 구조에 관한 것으로, 매 cycle당 행렬에서 파생된 N-bit의 벡터(Matrix Element) (2L- 1)개를 N-bit의 벡터 원소(Vector Element) 1개와 곱셈 연산하는 구조에 상응할 수 있다. 또한, 도 9에 도시된 Port-Flipped Half-Precision Matrix-Vector Multiplication은 도 8에 도시된 Port- Extended 기법에서 확장된 것으로, 도 4 내지 도 5에 도시된 본 발명의 일실시예에 따른 행렬-벡터곱 연산 구조 에 관한 것이다. 도 9를 참조하면, 매 cycle당 (2L-1)개의 벡터 포트를 통해 행렬에서 파생된 N/2-bit의 벡터 (Blocked Matrix Element) (4L-2)개를 N-bit의 벡터 원소(Vector Element) 1개와 곱셈 연산하는 구조에 상응할 수 있다. 이 때, (2L-1)개의 벡터포트들에는 각각 N/2-bit 데이터 2개가 결합된 다중 데이터가 할당되며, 다중 데이터를 구성하는 N/2-bit 데이터 타입은 Floating-Point, Integer, Blocked Floating-Point 등 다양한 저정 밀도 데이터 포맷을 포함할 수 있다. 이 때, 본 발명에 따르면, 벡터의 원소가 입력되는 원소 포트는 행(Row) 또는 열(Column)에 해당하는 인터페이 스 중 어디에도 위치할 수 있으므로, 도 3에서 열(Column)에 위치했던 원소 포트를 행(Row)으로 이동시키는 경 우에 도 10에 도시된 구조로 변경되어 동작할 수 있으며, 동일한 방식으로 도 4에 도시된 구조는 도 11에 도시 된 구조로 변경되어 동작할 수도 있다. 이 때, 다중 데이터는 반정밀도(HALF-PRECISION) 데이터 또는 반정밀도 데이터보다 크기가 작은 데이터의 데이 터 타입을 고려한 형변환을 수행하여 생성될 수 있다. 예를 들어, 16Bit 크기의 반정밀도 데이터 혹은 그보다 작은 8Bit 크기의 FP8 데이터에 해당하는 데이터 타입을 고려하여 형변환을 수행할 수 있다. 이 때, 반정밀도 데이터의 데이터 타입이 지수 편향 부동 소수점(EXPONEBT-BIASED FLOATING-POINT)인 경우, 행 렬-벡터곱 연산의 결과 값에 기설정된 지수 편향 값(EXPONENT BIAS)을 감산하여 결과 값의 범위를 보정할 수 있 다. 이하에서는, 도 12 내지 도 13을 참조하여, 반정밀도(HALF-PRECISION) 데이터를 블록 부동 소수점(Block Floating Point) 포맷으로 사용하는 경우와 지수 편향 부동 소수점(EXPONEBT-BIASED FLOATING-POINT) 포맷으로 사용하는 경우의 처리 과정을 상세하게 설명하도록 한다. 먼저, 블록 부동 소수점(Block Floating Point) 포맷을 사용하는 도 12를 참조하면, 피연산자인 행렬과 벡터가 입력되면(S1210), 행렬에서 파생된 (4L-2)개의 벡터들(N-bit Matrix Element) 중 최대값을 탐색할 수 있다 (S1220). 이 후, 탐색된 최대값의 지수(Exponent)와 행렬의 벡터들(N-bit Matrix Element) 각각의 지수(Exponent) 간의 차이만큼 행렬의 벡터들(N-bit Matrix Element)의 가수(Mantissa)를 Shift-Right하여 데이터 크기를 축소시키 는 형변환을 수행할 수 있다(S1230). 이 때, 단계(S1230)이 행렬의 벡터들(N-bit Matrix Element)을 블록 부동 소수점(Block Floating Point) 포맷 으로 변환하는 구체적인 과정에 해당할 수 있고, 해당 과정은 [수학식 1]처럼 나타낼 수 있다.[수학식 1]"}
{"patent_id": "10-2023-0054612", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "이 때, [수학식 1]을 통해 행렬의 벡터들(N-bit Matrix Element)을 공통된 Exponent 최대값으로 표현할 수 있 다. 따라서, 행렬의 벡터들(N-bit Matrix Element)에서 공통된 Exponent 정보는 제거되고, 부호(Sign)와 가수 (Mantissa) 정보만 담는 N/2-bit Matrix Element를 메모리에 저장할 수 있다(S1240). 이 때, Exponent 최대값은 단계(S1210)에서 입력된 피연산자 벡터 원소의 지수(Exponent)에 더하여 표현될 수 있다. 이 후, 본 발명에 따른 외적 기반 행렬-벡터곱 연산 장치에서 내부 연산기들로 구성된 어레이의 데이터 입력 포 트(N-bit Port)에 2개의 N/2-bit Matrix Element를 전송하여 행렬-벡터곱 연산(General Matrix Vector Multiplication; GEMV)를 수행할 수 있다(S1250). 또한, 지수 편향 부동 소수점(EXPONEBT-BIASED FLOATING-POINT) 포맷을 사용하는 도 13을 참조하면, 피연산자 인 행렬과 벡터가 입력되면(S1310), 행렬에서 파생된 (4L-2)개의 벡터들(N-bit Matrix Element)의 지수 (Exponent)에 기설정된 지수 편향 값(Exponent Bias)을 합산하여 값의 범위(Dynamic Range)를 보정할 수 있다 (S1320). 이 후, 보정된 벡터들(N-bit Matrix Element)을 저정밀도 부동 소수점(N/2-bit Low-Precision Floating-Point) 타입으로 형변환 수행할 수 있다(S1330). 이 때, 단계(S1320) 내지 단계(S1330)의 과정은 [수학식 2]처럼 나타낼 수 있다. [수학식 2]"}
{"patent_id": "10-2023-0054612", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "이 후, 본 발명에 따른 외적 기반 행렬-벡터곱 연산 장치에서 내부 연산기들로 구성된 어레이의 데이터 입력 포 트(N-bit Port)에 2개의 N/2-bit Matrix Element를 전송하여 행렬-벡터곱 연산(General Matrix Vector Multiplication; GEMV)를 수행할 수 있다(S1340).이 후, 행렬-벡터곱 연산(GEMV) 결과값의 지수(Exponent)에서 단계(S1320)에서 사용했던 기설정된 지수 편향 값 (Exponent Bias)을 감산하여 최종적인 결과 값의 범위를 보정할 수 있다(S1350). 이 때, 본 발명의 실시예에 따른 저정밀도 부동 소수점(N/2-bit Low-Precision Floating-Point)은 N/2-bit 범 위 안에서 지수(Exponent)와 가수(Mantissa)의 비트폭(bitwidth)으로 발생 가능한 모든 경우를 포함할 수 있다. 상술한 바와 같이 본 발명에 따른 확장형 입력 구조를 도 2에 도시된 종래 연산기 구조에 그대로 활용하기 위해 서는 다양한 동작 조건들을 만족해야하며, 동작 조건을 정리하면 다음과 같다. 1. 내부 연산기마다 행렬의 벡터와 벡터의 원소에 해당하는 2개의 입력 데이터만 허용한다. 2. 도 3에 도시된 구조일 경우, Row Operand (A3~A6)와 Column Operand(A0~A2)에 상응하게 입력되는 행렬의 벡 터는 하나의 내부 연산기에 할당되어 처리된다. 예를 들어, 도 3에서 A3에 해당하는 벡터 포트는 가로 방향으로 위치하는 4개의 내부 연산기들 중 하나(A3B0)에만 할당되며, 나머지 3개의 내부 연산기들(B0A0, B0A1, B0A2)로 향하는 입력은 바이패스(bypass)할 수 있다. 다른 예로, 도 3에서 A0에 해당하는 벡터 포트는 세로 방향으로 위 치하는 4개의 내부 연산기들 중 하나(B0A0)에만 할당되며, 나머지 3개의 내부 연산기들로 향하는 입력은 바이패 스(bypass)할 수 있다. 3. 도 4 내지 도 5에 도시된 구조일 경우, Row Operand(A3~A6)와 Column Operand(A0~A2)에 상응하게 입력되는 행렬의 벡터는 동시에 두 개의 내부 연산기들에 할당되어 처리된다. 예를 들어, 도 4에서 A3에 해당하는 벡터 포트는 가로 방향으로 위치하는 4개의 내부 연산기들 중 2개의 내부 연산기들(A3B0-UP, A3B0-DOWN)에 할당되며, 나머지 2개의 내부 연산기들(B0A1-UP, B0A2-UP)로 향하는 입력은 바이패스(bypass)할 수 있다. 다른 예로, 도 4 에서 A0에 해당하는 벡터 포트는 세로 방향으로 위치하는 4개의 내부 연산기들 중 2개의 내부 연산기들(B0A0- UP, B0A0-DOWN)에 할당되며, 나머지 2개의 내부 연산기들(A3B0-UP, A4B0-UP)로 향하는 입력은 바이패스 (bypass)할 수 있다. 이 때, 행렬의 벡터를 전송하기 위한 N-bit 입력포트 1개는 2개의 N/2-bit 벡터 데이터(다 중 데이터)를 포함하며, 각각의 내부 연산기는 다중 데이터의 상위 N/2-bit 데이터 또는 하위 N/2-bit 데이터를 마스킹(Masking)하여 마스킹되지 않은 나머지 부분을 연산에 활용할 수 있다. 이와 같은 외적 기반 행렬-벡터곱 연산 장치를 통해, AI 반도체의 행렬-행렬곱 연산기 구조를 그대로 재활용하 면서 행렬-벡터곱 연산을 가속할 수 있다. 또한, 데이터 경량화 기법과 혼합하여 동일한 메모리 밴드위스(Memory Bandwidth)에 더 많은 데이터량을 전송함 으로써 메모리 인터페이스 이용률을 최대화하고, 연산기의 운용량(Utilization)을 향상시킬 수 있다. 또한, 차세대 신경망 구조의 주요 연산(행렬-벡터곱) 속도를 향상시켜 AI 반도체의 활용 범위를 넓히고, 학습 능력을 향상시킬 수 있다. 도 14는 본 발명의 일실시예에 따른 외적 기반 행렬-백터곱 연산 방법을 나타낸 동작 흐름도이다. 도 14를 참조하면, 본 발명의 일실시예에 따른 외적 기반 행렬-백터곱 연산 방법은, 내부 데이터 전송 경로에 의하여, 벡터의 원소를 동시에 두 개 이상의 내부 연산기들로 제공한다(S1410). 또한, 본 발명의 일실시예에 따른 외적 기반 행렬-백터곱 연산 방법은, 적어도 하나의 멀티플렉서에 의하여, 상 기 벡터의 원소 및 행렬의 벡터 중 어느 하나를 선택한다(S1420). 또한, 본 발명의 일실시예에 따른 외적 기반 행렬-백터곱 연산 방법은, 내부 연산기들이 각각, MAC(Multiply- Accumulation) 연산을 수행하여 누적값을 생성한다(S1430). 이 때, 내부 연산기들 각각의 제1 입력 포트는 행렬의 벡터들 중 하나가 연결되고, 내부 연산기들 각각의 제2 입력 포트는 벡터의 원소가 연결된다. 이 때, 내부 연산기들로 구성된 어레이(ARRAY)의 데이터 입력 포트들 중 하나의 원소 포트는 벡터의 원소에 할 당되고, 데이터 입력 포트들 중 하나의 원소 포트를 제외한 벡터 포트들은 행렬의 벡터들에 할당될 수 있다. 이 때, 적어도 하나의 멀티플렉서는 원소 포트의 위치를 고려하여, 행렬의 벡터가 할당된 모든 내부 연산기들로 벡터의 원소가 제공될 수 있도록 구비될 수 있다. 이 때, 행렬의 벡터들이 각각 부동소수점 데이터 타입에서 가수(MANTISSA) 및 지수(EXPONENT)의 비트(BIT)를 줄 여 정밀도를 낮춘 두 개의 반정밀도(HALF-PRECISION) 데이터가 결합된 다중 데이터일 경우, 다중 데이터는 두 개의 내부 연산기들로 동시에 입력될 수 있다. 이 때, 두 개의 내부 연산기들 중 하나는 다중 데이터에서 하위 비트를 마스킹(MASKING)하여 상위 비트를 기반 으로 연산을 수행하고, 두 개의 내부 연산기들 중 나머지 하나는 다중 데이터에서 상위 비트를 마스킹하여 하위 비트를 기반으로 연산을 수행할 수 있다. 이 때, 두 개의 내부 연산기들은 어레이에서 같은 행(ROW) 또는 같은 열(COLUMN)에 위치하되, 상위 비트를 기반 으로 연산을 수행하는 제1 내부 연산기 및 하위 비트를 기반으로 연산을 수행하는 제2 내부 연산기의 순서로 위 치할 수 있다. 이 때, 다중 데이터는 반정밀도(HALF-PRECISION) 데이터 또는 반정밀도 데이터보다 크기가 작은 데이터의 데이 터 타입을 고려한 형변환을 수행하여 생성될 수 있다. 이 때, 반정밀도 데이터의 데이터 타입이 지수 편향 부동 소수점(EXPONEBT-BIASED FLOATING-POINT)인 경우, 행 렬-벡터곱 연산의 결과 값에 기설정된 지수 편향 값(EXPONENT BIAS)을 감산하여 결과 값의 범위를 보정할 수 있 다. 이와 같은 외적 기반 행렬-벡터곱 연산 방법을 통해, AI 반도체의 행렬-행렬곱 연산기 구조를 그대로 재활용하 면서 행렬-벡터곱 연산을 가속할 수 있다. 또한, 데이터 경량화 기법과 혼합하여 동일한 메모리 밴드위스(Memory Bandwidth)에 더 많은 데이터량을 전송함 으로써 메모리 인터페이스 이용률을 최대화하고, 연산기의 운용량(Utilization)을 향상시킬 수 있다. 또한, 차세대 신경망 구조의 주요 연산(행렬-벡터곱) 속도를 향상시켜 AI 반도체의 활용 범위를 넓히고, 학습 능력을 향상시킬 수 있다. 이상에서와 같이 본 발명에 따른 외적 기반 행렬-백터곱 연산 장치 및 이를 이용한 방법은 상기한 바와 같이 설 명된 실시예들의 구성과 방법이 한정되게 적용될 수 있는 것이 아니라, 상기 실시예들은 다양한 변형이 이루어 질 수 있도록 각 실시예들의 전부 또는 일부가 선택적으로 조합되어 구성될 수도 있다."}
{"patent_id": "10-2023-0054612", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1 내지 도 2는 Outer-Product 기반 행렬곱 연산 장치 구조의 일 예를 나타낸 도면이다. 도 3 내지 도 5는 본 발명의 일실시예에 따른 Outer-Product 기반 행렬-벡터곱 연산 장치 구조를 나타낸 도면이 다. 도 6은 본 발명에 따른 행렬-벡터곱 연산 장치에 적용된 멀티플렉서의 일 예를 나타낸 도면이다. 도 7은 도 1에 도시된 행렬-벡터곱 연산 시 어레이의 데이터 입력 포트에 할당되는 데이터 구조의 일 예를 나타 낸 도면이다. 도 8은 도 3에 도시된 행렬-벡터곱 연산 시 어레이의 데이터 입력 포트에 할당되는 데이터 구조의 일 예를 나타 낸 도면이다. 도 9는 도 4 내지 도 5에 도시된 행렬-벡터곱 연산 시 어레이의 데이터 입력 포트에 할당되는 데이터 구조의 일 예를 나타낸 도면이다. 도 10은 도 3에 도시된 행렬-벡터곱 연산 장치에서 B0가 입력되는 원소 포트의 위치를 변경한 일 예를 나타낸 도면이다. 도 11은 도 4에 도시된 행렬-벡터곱 연산 장치에서 B0가 입력되는 원소 포트의 위치를 변경한 일 예를 나타낸 도면이다. 도 12 내지 도 13은 본 발명에 따른 반정밀도(Half-Precision) 데이터가 Block Floating Point 타입 또는 Exponent-biased Floating-Point 타입일 경우의 처리 과정의 실시예를 나타낸 동작 흐름도이다.도 14는 본 발명의 일실시예에 따른 외적 기반 행렬-백터곱 연산 방법을 나타낸 동작 흐름도이다."}
