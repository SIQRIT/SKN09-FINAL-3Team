{"patent_id": "10-2022-0120308", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0041144", "출원번호": "10-2022-0120308", "발명의 명칭": "AI를 사용한 자동번역 및 더빙 방법", "출원인": "(주)아이디어 콘서트", "발명자": "전달용"}}
{"patent_id": "10-2022-0120308", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "AI를 사용한 자동 번역 및 더빙 방법을 포함하고, 자동 번역 방법은 a)자동번역을 하기 위해 말풍선, 텍스트를 추출하는 단계;(b)추출한 텍스트를 사용자가 원하는 언어로 번역하는 단계;(c)단계는 기존 텍스트를 번역된 텍스트로 교체하는 단계;(d)자동번역 작업이 완료된 후, 오류가 발생했을 경우 해당 이슈를 검수 후 수정하는 단계;를 포함하고,a)단계는 pre-processing , text detection, text recognition, post-processing 과정을 순차 진행하여 텍스트 인지 및 추출 작업을 수행하고, b)단계는 웹툰이미지의 말풍선 정보가 저장된 json 파일에서 텍스트 내용만을 뽑아서 가공한 뒤 자동번역 API를 통해 번역하고, 자동번역 API가 번역된 텍스트 내용이 저장된 json 파일을 반환하면 해당 내용을 기존 json 파일과 교체하고,c)단계는 기존 말풍선 정보가 담긴 json파일에서 말풍선의 위치정보와 번역된 텍스트를 받아와서, 기존 말풍선위치에 번역된 텍스트를 배치하여 텍스트를 교체하고,d)단계는 에러가 발생된 텍스트 크기를 작게하거나, 말풍선을 크게 하여 텍스트가 다시 말풍선 영역 안으로 들어오도록 수정하고, 또는 번역이 잘못되었을 경우에 검수하고,더빙 방법은 자동 더빙 단계와 실시간 더빙 단계 중 적어도 하나를 포함하고, 이중 자동더빙 단계는 음성파일 텍스트 변환단계와, 이미지, 음성파일 매칭 단계와, 음성파일 적용단계를 포함하고,음성파일 텍스 변환 단계는 녹화된 음성파일을 텍스트로 변환하는 단계이고,이미지, 음성파일 매칭 단계는 음성파일 텍스트를 이미지 말풍선 텍스트와 일치하는 정도를 비교하여 매칭하는단계로서 가장 일치율이 높은 음성파일과 이미지를 매칭하고,음성 파일 적용단계는 해당 이미지의 타임라인에 음성파일 데이터를 담은 바를 배치하여 영상 재생시 해당 음성파일에 녹음된 목소리가 나오도록 하여 영상더빙을 진행하고, 실시간 더빙은 더빙 대상 이미지를 선택하여 타임라인 상에서 음성파일 바를 생성하여 해당 바에 저장될 음성데이터를 녹음하는 것; 을 특징으로 하는 AI를 사용한 자동 번역 및 더빙 방법."}
{"patent_id": "10-2022-0120308", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 AI를 사용한 자동번역 및 더빙 방법에 관한 것으로, 프로그램이 자동으로 진행하여 해당 작업을 훨씬 빠르고 간편하게 할 수 있는 AI를 사용한 번역 및 더빙 방법을 제공함에 있다. 본 발명은 서울특별시 서울산업진흥원 2021년도 인공지능 기술사업화 지원사업(CY210022) \"AI기반 웹툰을 자동으 로 영상으로 만드는 저작툴 개발\"을 통해 개발된 기술이다."}
{"patent_id": "10-2022-0120308", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 AI를 사용한 자동번역 및 더빙 방법에 관한 것이다."}
{"patent_id": "10-2022-0120308", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "최근의 만화콘텐츠는 대부분은 웹툰 및 영상을 통해 감상이 이루어진다. 특히. 모바일 기기 사용자가 대폭 늘 어나면서 영상시장의 성장세는 웹툰에 비해 크게 두드러진다. IPTV, VOD와 같이 TV와 연동하여 영상서비스를 제공하는 업체뿐만 아니라, Netflix, Watcha, Wavve 등 영상콘텐 츠만을 다루는 OTT 플랫폼이 크게 늘어남에 따라 영상 콘텐츠 규모는 폭발적으로 성장하였다. 뿐만 아니라, 라 프텔과 같이 만화영상만을 다루는 플랫폼들이 속속들이 생기면서 만화/웹툰 콘텐츠의 영상시장 진출은 선택이 아닌 필수가 되었다. 이에 따라, 새롭게 제작되는 신작 콘텐츠는 제작 시점부터 소비자가 영상플랫폼에 연재 및 유통하는 것을 염두 에 두고 애니메이션 같은 영상콘텐츠로 만들어지는 추세이다. 다만 한국만화 영상콘텐츠는 넷플릭스, 디즈니와 같은 다국적 OTT 플랫폼의 등장과 오징어 게임, BTS 등으로 대표되는 K-culture 열풍에 힙입어 국내뿐만 아니라 해외시장에서도 수요가 많은 만큼, 영상 콘텐츠 저작시 해외 수출을 전제로 하여 반드시 다른 외국어로의 번역 과 더빙작업을 염두에 두어야 한다. 종래에는 번역과 더빙 작업을 사람이 수동으로 직접 하였다. 번역 같은 경우, 일러스트 혹은 디자이너가 웹툰이 미지를 포토샵에서 불러와 말풍선의 기존 텍스트 영역을 지운 뒤, 번역가로부터 전달받은 번역된 텍스트를 해당 말풍선에 넣어주는 방식이었다. 더빙 같은 경우, 영상편집자가 해당 애니메이션 영상을 프레임 단위로 편집하면 서 해당하는 장면에 일치하는 음성파일을 수동으로 넣어주는 방식이었다. 이와 같은 수동적 작업방식은, 일러스 트, 번역가, 영상편집자 등 많은 인력을 필요로 하고 한편의 작품을 제작하는데 시간도 오래걸려 비효율적이므 로 많은 기성작가와 기존만화업체가 번역 및 더빙 작업을 망설이게 하는 높은 기술적 진입장벽으로 존재하였다."}
{"patent_id": "10-2022-0120308", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 2, "content": "따라서 본 발명은 위와 배경기술 및 문제점을 해소하기 위하여 서울특별시 서울산업진흥원 2021년도 인공지능 기술사업화 지원사업(CY210022)\"AI기반 웹툰을 자동으로 영상으로 만드는 저작툴 개발\"을 통해 개발된 기술이다."}
{"patent_id": "10-2022-0120308", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "그러므로 본 발명은 상기와 같은 종래의 문제점을 해결하기 위하여 안출된 것으로, 본 발명의 목적은 프로그램 이 자동으로 진행하여 해당 작업을 훨씬 빠르고 간편하게 할 수 있는 AI를 사용한 번역 및 더빙 방법을 제공함 에 있다."}
{"patent_id": "10-2022-0120308", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 실시예는 AI를 사용한 자동 번역 및 더빙 방법을 포함하고, 자동 번역 방법은 a)자동번역을 하기 위 해 말풍선, 텍스트를 추출하는 단계; (b)추출한 텍스트를 사용자가 원하는 언어로 번역하는 단계; (c)단계는 기 존 텍스트를 번역된 텍스트로 교체하는 단계; (d)자동번역 작업이 완료된 후, 오류가 발생했을 경우 해당 이슈 를 검수 후 수정하는 단계;를 포함하고, a)단계는 pre-processing , text detection, text recognition, post-processing 과정을 순차 진행하여 텍스트 인지 및 추출 작업을 수행하고, b)단계는 웹툰이미지의 말풍선 정보가 저장된 json 파일에서 텍스트 내용만을 뽑아서 가공한 뒤 자동번역 API를 통해 번역하고, 자동번역 API 가 번역된 텍스트 내용이 저장된 json 파일을 반환하면 해당 내용을 기존 json 파일과 교체하고, c)단계는 기존 말풍선 정보가 담긴 json파일에서 말풍선의 위치정보와 번역된 텍스트를 받아와서, 기존 말풍선 위치에 번역된 텍스트를 배치하여 텍스트를 교체하고, d)단계는 에러가 발생된 텍스트 크기를 작게하거나, 말풍선을 크게 하여 텍스트가 다시 말풍선 영역 안으로 들어오도록 수정하고, 또는 번역이 잘못되었을 경우에 검수하고, 더빙 방법 은 자동 더빙 단계와 실시간 더빙 단계 중 적어도 하나를 포함하고, 이중 자동더빙 단계는 음성파일 텍스트 변 환단계와, 이미지, 음성파일 매칭 단계와, 음성파일 적용단계를 포함하고, 음성파일 텍스 변환 단계는 녹화된 음성파일을 텍스트로 변환하는 단계이고, 이미지, 음성파일 매칭 단계는 음성파일 텍스트를 이미지 말풍선 텍스 트와 일치하는 정도를 비교하여 매칭하는 단계로서 가장 일치율이 높은 음성파일과 이미지를 매칭하고, 음성 파 일 적용단계는 해당 이미지의 타임라인에 음성파일 데이터를 담은 바를 배치하여 영상 재생시 해당 음성파일에 녹음된 목소리가 나오도록 하여 영상더빙을 진행하고, 실시간 더빙은 더빙 대상 이미지를 선택하여 타임라인 상 에서 음성파일 바를 생성하여 해당 바에 저장될 음성데이터를 녹음하는 것; 을 특징으로 하는 AI를 사용한 자동 번역 및 더빙 방법을 포함한다."}
{"patent_id": "10-2022-0120308", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명에 따르면, AI기술과 자동번역 라이브러리를 통해 사용자가 입력한 웹툰원본파일 이미지 내 말풍선 텍스 트들에 대한 자동번역 및 더빙을 을 수행함에 따라 번역에 필요한 시간을 단축하고, 인력을 절감할 수 있는 효 과가 있다."}
{"patent_id": "10-2022-0120308", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명은 다양한 변경을 가할 수 있고 여러 가지 실시예를 가질 수 있지만, 특정 실시예를 도면에 예시하여 상 세하게 설명하고자 한다. 이는 본 발명을 특정한 실시 형태에 대해 한정하려는 것이 아니며, 서로 다른 방향으 로 연장되는 구조물을 연결 및/또는 고정시키기 위한 본 발명의 사상 및 기술 범위에 포함되는 모든 변경, 균등 물 내지 대체물중 어느 하나에 해당되는 것으로 이해되어야 한다. 본 명세서에서 사용한 용어는 단지 특정한 실시예를 설명하기 위해 사용된 것으로, 본 발명을 한정하려는 의도 가 아니다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 또한, 본 발명을 설명함에 있어 관련된 공지 기술에 대한 구체적인 설명이 본 발명의 요지를 불필요하게 흐릴 수 있다고 판단되는 경우 그 상세한 설명을 생략한다. 도 1은 본 발명의 개요를 도시한 블럭도이다. 도 1을 참조하면, 본 발명은 웹툰원본파일 형식(.psd 등)의 이미지를 영상콘텐츠로 저작할 때, AI기술을 사용하 여 이미지 내 말풍선 텍스트 번역 및 목소리 더빙을 자동으로 수행함으로써 사용자가 영상콘텐츠를 보다 동적으 로 감상할 수 있게 하는 것을 특징으로 한다. 특히 본 발명은 A1) 말풍선, 텍스트 추출을 통한 자동번역기술, A2) 텍스트, 음성파일을 이용한 자동더빙기술로 이루어져 있다. 먼저, 자동번역 기능은 도 2를 참조하여 설명한다. 도 2는 본 발명의 자동번역과정을 도시한 순서도이다. 도 2를 참조하면, 자동번역은 a) 말풍선, 텍스트 추출, b) 텍스트 번역, c) 텍스트 교체, d) 번역오류 수정의 단계를 포함한다. 이중, (a)단계는 자동번역을 하기 위해 말풍선, 텍스트를 추출하는 단계이다. 말풍선의 영역을 인식하여 분리한 뒤, 말풍선 내에서 텍스트의 내용을 추출한다. 추출한 텍스트의 내용은 하나의 파일로 저장하여 보관한다. (b)단계는 추출한 텍스트를 사용자가 원하는 언어로 번역하는 단계다. 오픈소스 자동 번역 API를 사용해 기존 텍스트 전부를 번역한다. 해당 작업이 완료된 후, 번역된 텍스트 역시 하나의 파일로 저장되어 반환된다. (c)단계는 기존 텍스트를 번역된 텍스트로 교체하는 단계이다. 기존 텍스트를 지우고, 번역된 텍스트를 기존 텍 스트가 위치했던 말풍선에 배치하는 방식으로 진행한다. (d)단계는 자동번역 작업이 완료된 후, 오류가 발생했을 경우 해당 이슈를 검수 후 수정하는 단계이다. 이 단계 를 완료하면 자동번역 작업이 완전히 마무리된다. 말풍선, 텍스트 추출 과정은 다음과 같다. 본 발명에서는 OCR 기술을 사용하여 텍스트 영역 인식 및 내용 추출 작업을 수행하였다. 예를 들면, OCR(Optimal Character Recognition)은 광학문자 인식기술로 사람이 직접 쓰거나 이미지 속 문자를 스캔을 통해 얻은 뒤, 이를 컴퓨터가 인식할 수 있도록 디지털 문자화를 진행한다. 디지털 문자화를 진행한 뒤, 딥러닝 'pattern matching’ 기법을 기반으로 문자의 특징을 인식하는 방법으로 텍스트가 존재하는 영역을 찾아 낸다. OCR은 ①pre-processing -> ②text detection -> ③text recognition ->④post-processing 4단계를 거쳐 텍스트 인지 및 추출 작업을 수행하였다.① pre-processing 텍스트가 존재하는 말풍선 영역을 인지하는 단계로서, Contour, Morph Close와 같은 이미지 전처리 기술을 통해 문자특징이 존재하는 영역을 분류하여 인지한다. ② text detection pre-processing을 통해 인지한 말풍선 영역 내에서 텍스트만 존재하는 영역을 인지하는 단계이고, Long Line Remove, R-CNN을 통해 공백 및 배경 부분을 제외하고 오로지 텍스트만 인식하도록 최적화 및 텍스트 영역 좌표 를 획득한다. ③ text recognition 글자인식과정으로 텍스트 영역의 글자 내용 인지 및 추출 단계로서 text detection 단계에서 인식한 텍스트 영 역을 추출하여 글자별 세부영역으로 분 리한 뒤, 문자별로 학습시킨 문자인식모델 ConvNet을 기반으로 각 영역내 글자가 무엇인지를 인식한다. ④ post-processing 추출한 텍스트 내용을 확인하여 맥락상 부자연스러운 부분을 수정하는 단계이고, post-processing과정을 통해 텍스트 인식 정확도를 높이는 효과를 거둘 수 있다. 추출한 파일에는 텍스트가 있는 말풍선에 관한 모든 정보가 담겨져 있음. 말풍선 색상, 말풍선 위치, 텍스트 내 용, 텍스트 상대적 위치등이 담겨져 있어 이후 이를 활용하여 자동번역작업을 진행할 수 있다. 본 발명에서는 기존 웹툰이미지의 말풍선 정보가 저장된 json 파일에서 텍스트 내용만을 뽑아서 가공한 뒤, 이 를 자동번역 API에 넣어서 번역작업을 수행한다. 이후, 자동번역 API가 번역된 텍스트 내용이 저장된 json 파 일을 반환하면 해당 내용을 기존 json 파일과 교체하면 텍스트 번역이 완료된다. 텍스트 교체는 웹툰화시 기존 텍스트를 번역 텍스트로 교체하기 위해서 기존 텍스트를 지우고, 번역된 텍스트 로 교체하는 방법을 사용하였다. 기존 텍스트는 이미 적혀있으므로 텍스트 삭제는 불가능하다. 그래서 본 발명에서는 텍스트가 적혀있는 말풍선 을 말풍선내 배경색으로 말풍선을 다시 칠하는 방법으로 기존 텍스트를 지운다. 해당 작업을 수행하기 위해서는 말풍선의 배경색을 학습하는 기술이 필요한데 본 발명에서는 GAN 기법을 활용하 였다. GAN 기법은 비지도학습에 사용되는 머신러닝 프레임워크 중 한 종류로, 2가지 종류의 신경망을 가지고 학습을 하는 특징을 가지고 있다. GAN기법을 사용하면, 말풍선 배경색상을 학습하여 텍스트 영역을 배경색으로 칠해 지울 수 있다. 그 다음 기존 말풍선 정보가 담긴 json파일에서 말풍선의 위치정보와 번역된 텍스트를 받아와서, 기존 말풍선 위치에 번역된 텍스트를 배치하는 방식으로 텍스트를 교체하여 자동번역 작업을 완료할 수 있다. 번역오류수정은 텍스트가 길어질 경우와 번역이 잘못된 경우로 구분될 수 있다. 먼저 텍스트가 길어질 경우는 다른언어로 변경을 하다보면, 텍스트가 너무 길어져서 말풍선 바깥으로 나가는 에 러가 발생하는데 본 발명에서는 이와 같은 에러를 텍스트 크기를 작게하거나, 말풍선을 크게 하여 텍스트가 다 시 말풍선 영역 안으로 들어오게 하였다. 그리고 번역이 잘못된 경우는 자동번역API를 사용해 번역을 하기 때문에, 번역이 부자연스럽거나 잘못된 실수들 이 곳곳에서 발견될 수 있다. 이런 번역 에러들을 잡기 위해, 본 발명에서는 사람이 영상화 이전 번역된 텍스트 를 보고 한번 더 검수하고 수정하는 작업을 추가하는 방식으로 진행할 수 있다. 더빙은 도 3의영상음성 편집 페이지를 통하여 이루어질 수 있다. 예를 들면, 본 발명에서는 기존 이미지를 영상 으로 저작하던 영상 편집페이지에서 더빙작업을 추가로 수행하기 위해 음성파일을 편집할 수 있는 기능을 추가 하였다. 도 3을 참조하면, 본 발명은 더빙작업을 수행하기 위한 영상음성편집페이지의 A영역은 타임라인 내에서 영상 연 출효과를 처리하는 영역이고, B영역은 타임라인 내에서 음성파일을 처리하는 영역이다. 영상재생 시, 연출효과 애니메이션바와 음성파일이 동시에 이미지에 적용되면서 영상화와 더빙 2가지 작업이 동 시에 이루어질 수 있다. 자동더빙 기능은 다음과 같이 (a) 음성파일 텍스트 변환, (b) 이미지, 음성파일 매칭, (c) 음성파일 적용 이라 는 3단계 과정을 거쳐 실행된다. (a)단계는 이미 녹화된 음성파일을 텍스트로 변환하는 단계다. 텍스트로 변환하는 이유는 이를 텍스트로 변 환하여 해당 음성파일이 어떤 이미지의 말풍선에 해당하는지 알아보기 위함이다. 구체적으로 음성파일 텍스트 변환은 STT(speech-to-text) 기술을 활용하여 음성파일을 텍스트로 변환하였다. STT는 사람의 음성을 분석하여 텍스트 데이터를 추출하는 딥러닝 기술로서, 기존에 학습한 음향모델, 언어모델, 발음사전을 토대로 입력된 음성 데이터의 특징 벡터를 모델 내 데이터와 비교하여 텍스트 단어를 최종 결정짓는 방식으로 데이터를 추출한다. (b)단계는 음성파일 텍스트를 이미지 말풍선 텍스트와 일치하는 정도를 비교하여 매칭하는 단계. 가장 일치율이 높은 음성파일과 이미지를 매칭할 수 있다. 이미지, 음성파일 매칭은 해당 음성파일이 어느 이미지에 속하는 지를 확인 하기 위하여 이미지 텍스트와 음성 파일 텍스트의 일치도를 비교한다. 따라서 본 발명은 텍스트 비교를 위해 자연어처리(Natural Language Processing) 기술을 적용ㅎ알 수 있다. 자연어처리는 기계가 인간의 언어인 자연어를 이해하고 처리할 수 있게 돕는 기술로, 텍스트 전처리(대/소문자 변경, 특수문자 삭제 같은 텍스트 정규화) -> 피처 백터화(텍스트 특징값 추출) -> 머신러닝 모델링(데이터 모 델링 수립 및 예측) 3단계를 거쳐서 텍스트를 다룬다. 본 발명은 NLP 라이브러리 중 Python 환경에서 구동하는 NLTK 패키지를 사용한다. 많은 데이터 세트와 훈련모델 이 있어 즉시 자연어처리를 통해 원하는 기능을 쓸 수 있다는 장점이 있다. 영상저작툴에 NLTK 라이브러리를 탑재한 뒤, 이를 사용해 모든 이미지 내 텍스트와 음성파일 추출 텍스트를 1:1로 전부 비교하였다. 이를 통해 각 파일별로 일치도가 가장 높은 이미지-음성파일을 1쌍씩 매칭하여 이미지 한 개당 하나의 음성파일이 할당되도록 정렬하였다. (c)단계는 음성파일을 매칭된 이미지에 적용하는 단계. 해당하는 이미지의 타임라인에 음성파일 데이터를 담은 바를 배치하여 영상 재생시 해당 음성파일에 녹음된 목소리가 나오도록 하여 영상더빙을 진행할 수 있다. 여기서 이미지와 음성파일이 매칭되었다면, 음성파일을 해당하는 이미지에 적용하여야 하며, 본 발명에서는 영 상화를 진행할 때, 타임라인을 통해 연출효과를 부여했기 때문에 음성파일도 타임라인 시스템을 통해 적용하였 음. 음성파일 데이터를 JSON화 한뒤, 해당 데이터 값을 가진 음성파일 바를 매칭된 이미지의 애니메이션 바가 배치된 시간대와 동일한 위치에 배치하여 더빙을 진행한다. 따라서 영상을 재생하면, 같은 시간대에 해당 이미지에 적용된 연출효과 애니메이션바와 음성파일 바를 동시에 읽어들이면서 영상속에 목소리 더빙이 같이 이루어지는 것을 확인할 수 있다. 실시간 더빙은 위의 자동 더빙과 달리, 미리 녹화된 음성파일이 있는 것이 아니라 화면이미지에 사용자가 실시 간으로 본인 목소리를 녹음하여 더빙을 진행하는 개념이다. 따라서 실시간 더빙은 자동 더빙과 달리 준비된 음성파일이 없기 때문에, 사용자가 더빙하고자 하는 이미지를 선택하여 타임라인 상에서 음성파일 바를 생성한다. 본 발명은 타임라인 보이스 영역 우클릭시 생성되도록 함. 이후 해당 음성파일바를 선택하여 길이 및 그 외 속성들을 타임라인 상에서 조정할 수 있게 하여 목소리 더빙의 유연성을 높일 수 있다. 음성파일 바를 생성하면, 해당 바에 저장될 음성데이터가 필요함. 음성파일 바를 생성한 뒤 한번 더 클릭하면, 목소리 녹음을 할 수 있도록 설정한다. 본 발명은 오픈소스 라이브러리인 오더시티(Audacity)를 본 저작툴에 탑재하여 사용자의 목소리를 녹음하였다. 오더시티는 Window 환경에서 구동하는 오디오 녹화 프로그램으로, 오픈소스 라이브러리이며 MP3 encoder인 Lame을 통해 사용자의 음성을 음성파일로 변환한다. 이후, 이를 Export 하여 음성파일을 공유하거나 원하는 곳에 저장할 수 있다. 녹음 완료시, 해당 음성파일은 서버내에 저장되고 해당 음성을 json화 한 데이터가 선택한 음성파일 바에 저장 됨. 이후 영상을 재생하면, 해당 이미지가 나오는 장면에 사용자 목소리가 실시간 더빙된 것을 확인할 수 있다."}
{"patent_id": "10-2022-0120308", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 개요를 도시한 블럭도이다. 도 2는 번역 단계를 도시한 순서도이다. 도 3은 영상음성편집페이지를 도시한 도면이다."}
