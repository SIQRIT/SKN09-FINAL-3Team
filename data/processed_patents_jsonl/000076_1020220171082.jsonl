{"patent_id": "10-2022-0171082", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0002668", "출원번호": "10-2022-0171082", "발명의 명칭": "활동성 갑상선 눈병증 진료를 위한 내원 안내 방법 및 이를 수행하는 시스템", "출원인": "주식회사 타이로스코프", "발명자": "신규보"}}
{"patent_id": "10-2022-0171082", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "결막 충혈 예측 모델, 결막 부종 예측 모델, 눈물언덕 부종 예측 모델, 눈꺼풀 발적 예측 모델 및 눈꺼풀 부종예측 모델을 준비하고,대상의 얼굴 이미지를 획득하고,상기 얼굴 이미지로부터 제1 처리된 이미지(first processed image) 및 제2 처리된 이미지(second processedimage)를 획득하고 - 이때, 상기 제1 처리된 이미지는 상기 제2 처리된 이미지와 상이함 -,상기 제1 처리된 이미지를 상기 결막 충혈 예측 모델, 상기 결막 부종 예측 모델 및 상기 눈물언덕 부종 예측모델에 입력하여 결막 충혈, 결막 부종 및 눈물언덕 부종 각각에 대한 예측값들을 획득하고,상기 제2 처리된 이미지를 상기 눈꺼풀 발적 예측 모델 및 상기 눈꺼풀 부종 예측 모델에 입력하여 눈꺼풀 발적및 눈꺼풀 부종 각각에 대한 예측값들을 획득하고,상기 결막 충혈에 대한 상기 예측값, 상기 결막 부종에 대한 상기 예측값, 상기 눈물언덕 부종에 대한 상기 예측값, 상기 눈꺼풀 발적에 대한 상기 예측값 및 상기 눈꺼풀 부종에 대한 상기 예측값에 기초하여, 상기 대상이갑상선 안병증 (thyroid eye disease)을 가지고 있을 가능성(possibility)을 판단하는 것을 포함하고,상기 제1 처리된 이미지는 상기 눈의 아웃라인에 대응되는 픽셀들의 위치 정보 및 상기 눈에 포함된 홍채의 아웃라인에 대응되는 픽셀들의 위치정보에 기초하여, 상기 눈의 아웃라인의 외부 및 상기 홍채의 아웃라인의 내부에 대응되는 영역들을 마스킹하고 상기 눈의 아웃라인을 포함하는 제1 영역을 따라서 크로핑된 이미지이며,상기 제2 처리된 이미지는 상기 눈의 아웃라인에 대응되는 픽셀들의 위치 정보 및 상기 눈에 포함된 홍채의 아웃라인에 대응되는 픽셀들의 위치정보에 기초하여, 상기 제1 영역 보다 더 넓게 확장된 제2 영역을 따라서 크로핑된 이미지인컴퓨터로 실행가능한 갑상선 안병증의 예측방법."}
{"patent_id": "10-2022-0171082", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 출원에 의하면, 퓨터로 실행가능한 갑상선 안병증의 예측방법이 개시된다. 상기 방법은, 결막 충혈 예측 모델, 결막 부종 예측 모델, 눈물언덕 부종 예측 모델, 눈꺼풀 발적 예측 모델 및 눈꺼풀 부종 예측 모델을 준비 하고, 대상의 얼굴 이미지를 획득하고, 상기 얼굴 이미지로부터 제1 처리된 이미지(first processed image) 및 (뒷면에 계속)"}
{"patent_id": "10-2022-0171082", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 활동성 갑상선 눈병증 진료를 위한 내원 안내 방법 및 이를 수행하는 시스템에 관한 것이다."}
{"patent_id": "10-2022-0171082", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "안질환은 안구 및 이를 둘러싸고 있는 주변부에 발생하는 질병이다. 안질환은 전 세계적으로 많은 사람들에게 발병되고 있으며, 심각한 경우 시력 손상을 유발하는 등 생활에 큰 불편함을 야기하는 질병이므로, 안질환의 발 생 여부 또는 정도에 대한 모니터링이 필요하다. 한편, 안질환은 다른 질병으로 인해 유발되는 여러 합병증 중 하나일 수 있다. 예컨대, 갑상선 기능 이상으로 인해 유발되는 합병증으로 갑상선 눈병증이 있다. 갑상선 안병증이 심해지는 경우, 안구가 돌출되어 수술을 하지 않으면 치료를 할 수 없게 되어 조기에 갑상선 안병증을 진단하는 것이 갑상선 안병증의 치료에 매우 중요하다. 그러나, 갑상선 안병증은 전조증상이 뚜렷하게 나타나지 않아 조기 진단에 어려움이 있어, 의학계에서는 1989년부터 제안되어 온 임상활동점수(Clinical Activity Score, CAS)를 통해 평가하는 방법을 통해 갑상선 안병증은 조기에 진단하기 위한 노력을 기울이고 있 다. 갑상선 안병증에 대한 임상활동점수를 판단함에 있어서 총 7가지 항목이 고려되며, 고려되는 총 7가지 항목은 1) 구후부의 자발적인 통증 (Spontaneous retrobulbar pain), 2) 안구운동 시 통증 (Pain on attempted upward or downward gaze), 3) 눈꺼풀의 발적 (Redness of eyelid), 4) 결막의 충혈 (Redness of conjunctiva), 5) 눈꺼풀의 부종 (Swelling of eyelid), 6) 결막의 부종 (Swelling of conjunctiva), 및 7) 눈물언덕의 부종 (Swelling of lacrimal caruncle)이다. 이러한 임상활동점수를 판단하기 위해서는, 개인이 직접 병원 또는 클리닉에 방문하고, 의사의 문진 및 육안 관 찰에 의한 검진이 필수적이다. 예를 들어, 구후부의 자발적인 통증 및 안구 운동 시 통증은 의사의 문진을 통해 서 확인될 수 있고, 눈꺼풀의 발적, 결막의 충혈, 눈꺼풀의 부종, 결막의 부종 및 눈물언덕의 부종은 의사의 육 안 관찰에 의해 확인될 수 있다. 이와 같은 임상활동점수의 확인을 위한 의사 육안 검진 및 문진 방식은 갑상선 안병증의 진단을 위해 환자의 병원 직접 방문을 선결조건으로 하는 바, 갑상선 안병증을 조기에 진단하는 데에 어려움이 있었다. 이에, 병원 직접 방문 없이도, 개개인이 보다 간편하고 신속하게 안질환 위험도를 확인함으로써 지속적인 모니 터링이 수행될 수 있도록 함과 더불어, 필요한 경우 안질환의 위험을 안내하여 환자의 내원을 유도하는 방법의 개발이 요구되고 있다. 선행기술문헌 (특허문헌 0001) 대한민국 특허 등록번호 제10-2223478호 (2021년02월26일 등록) (특허문헌 0002) 대한민국 특허 등록번호 제10-2047237호 (2019년11월15일 등록) (특허문헌 0003) 대한민국 특허 등록번호 제10-2058883호 (2019년12월18일 등록) (특허문헌 0004) 대한민국 특허 등록번호 제10-2347551호 (2022년01월02일 등록)"}
{"patent_id": "10-2022-0171082", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 출원에 의해 개시되는 내용들이 해결하고자 하는 과제는 전문적인 의학 진단 기기가 아닌 일반인들이 사용할 수 있는 디지털 카메라로 획득된 이미지를 활용하여 갑상선 안병증에 관한 임상활동점수를 예측하는 데에 사용 되는 학습 모델을 제공하는 것이다. 본 출원에 의해 개시되는 내용들이 해결하고자 하는 다른 과제는 일반인들이, 의사의 도움없이 그리고 병원 직 접 방문 없이, 지속적으로 갑상선 안병증에 관한 임상활동점수를 모니터링할 수 있는 방법 및 시스템을 제공하 는 것이다. 본 출원에 의해 개시되는 내용들이 해결하고자 하는 또 다른 과제는, 임상활동점수의 모니터링 결과에 따라서 활동성 갑상선 안병증 진료를 위한 병원 방문을 추천하는 방법 및 이를 수행하는 시스템을 제공하는 것이다. 본 출원이 해결하고자 하는 과제가 상술한 과제로 제한되는 것은 아니며, 언급되지 아니한 과제들은 본 명세서"}
{"patent_id": "10-2022-0171082", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 2, "content": "및 첨부된 도면으로부터 본 출원에 의해 개시되는 기술이 속하는 기술분야에서 통상의 지식을 가진 자에게 명확 하게 이해될 수 있을 것이다."}
{"patent_id": "10-2022-0171082", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 출원의 일 양태에 의하면, 컴퓨터로 실행가능한 갑상선 안병증의 예측방법이 개시된다. 상기 방법은, 결막 충혈 예측 모델, 결막 부종 예측 모델, 눈물언덕 부종 예측 모델, 눈꺼풀 발적 예측 모델 및 눈꺼풀 부종 예측 모델을 준비하고, 대상의 얼굴 이미지를 획득하고, 상기 얼굴 이미지로부터 제1 처리된 이미지(first processed image) 및 제2 처리된 이미지(second processed image)를 획득하고 - 이때, 상기 제1 처리된 이미지는 상기 제 2 처리된 이미지와 상이함 -, 상기 제1 처리된 이미지를 상기 결막 충혈 예측 모델, 상기 결막 부종 예측 모델 및 상기 눈물언덕 부종 예측 모델에 입력하여 결막 충혈, 결막 부종 및 눈물언덕 부종 각각에 대한 예측값들을 획득하고, 상기 제2 처리된 이미지를 상기 눈꺼풀 발적 예측 모델 및 상기 눈꺼풀 부종 예측 모델에 입력하여 눈꺼풀 발적 및 눈꺼풀 부종 각각에 대한 예측값들을 획득하고, 상기 결막 충혈에 대한 상기 예측값, 상기 결막 부종에 대한 상기 예측값, 상기 눈물언덕 부종에 대한 상기 예측값, 상기 눈꺼풀 발적에 대한 상기 예측값 및 상기 눈꺼풀 부종에 대한 상기 예측값에 기초하여, 상기 대상이 갑상선 안병증 (thyroid eye disease)을 가지고 있을 가능성(possibility)을 판단하는 것을 포함한다. 이때, 상기 제1 처리된 이미지는 상기 눈의 아웃라인에 대응되는 픽셀들의 위치 정보 및 상기 눈에 포함된 홍채의 아웃라인에 대응되는 픽셀들의 위치정보에 기초하여, 상기 눈의 아웃라인의 외부 및 상기 홍채의 아웃라인의 내부에 대응되는 영역들을 마스킹하고 상기 눈의 아웃라인을 포함하는 제1 영역을 따라서 크로핑된 이미지이며, 상기 제2 처리된 이미지는 상기 눈의 아웃라인에 대응 되는 픽셀들의 위치 정보 및 상기 눈에 포함된 홍채의 아웃라인에 대응되는 픽셀들의 위치정보에 기초하여, 상 기 제1 영역 보다 더 넓게 확장된 제2 영역을 따라서 크로핑된 이미지이다. 몇몇 실시예들에 있어서, 상기 눈의 아웃라인에 대응되는 픽셀들의 위치정보 및 상기 눈에 포함된 홍채의 아웃 라인에 대응되는 픽셀들의 위치정보는 세그멘테이션 모델에 의해 획득될 수 있다. 몇몇 실시예들에 있어서, 상기 제1 처리된 이미지는 제1 처리된 좌안 이미지(first processed left eye image) 및 제1 처리된 우안 이미지(first processed right eye image)를 포함하며, 상기 제2 처리된 이미지는 제2 처 리된 좌안 이미지(second processed left eye image) 및 제2 처리된 우안 이미지(second processed right eye image)를 포함할 수 있다. 몇몇 실시예들에 있어서, 상기 결막 충혈 예측 모델은 좌안 결막 충혈 예측 모델 및 우안 결막 충혈 예측 모델 을 포함하고, 상기 결막 부종 예측 모델은 좌안 결막 부종 예측 모델 및 우안 결막 부종 예측 모델을 포함하며, 상기 눈물언덕 부종 예측 모델은 좌안 눈물언덕 부종 예측 모델 및 우안 눈물언덕 부종 예측 모델을 포함하고, 상기 눈꺼풀 발적 예측 모델은 좌안 눈꺼풀 발적 예측 모델 및 우안 눈꺼풀 발적 예측 모델을 포함하며, 상기 눈꺼풀 부종 예측 모델은 좌안 눈꺼풀 부종 예측 모델 및 우안 눈꺼풀 부종 예측 모델을 포함할 수 있다. 몇몇 실시예들에 있어서, 상기 결막 충혈에 대한 상기 예측값은 상기 제1 전처리된 좌안 이미지를 상기 좌안 결 막 충혈 모델에 입력하여 획득한 결과와 상기 제1 전처리된 우안 이미지를 상기 우안 결막 충혈 모델에 입력하 여 획득한 결과에 기초하여 결정되고, 상기 결막 부종에 대한 상기 예측값은 상기 제1 전처리된 좌안 이미지를 상기 좌안 결막 부종 모델에 입력하여 획득한 결과와 상기 제1 전처리된 우안 이미지를 상기 우안 결막 부종 모 델에 입력하여 획득한 결과에 기초하여 결정되고, 상기 눈물언덕 부종에 대한 상기 예측값은 상기 제1 전처리된 좌안 이미지를 상기 좌안 눈물언덕 부종 모델에 입력하여 획득한 결과와 상기 제1 전처리된 우안 이미지를 상기 우안 눈물언덕 부종 모델에 입력하여 획득한 결과에 기초하여 결정되고, 상기 눈꺼풀 발적에 대한 상기 예측값 은 상기 제2 전처리된 좌안 이미지를 상기 좌안 눈꺼풀 발적 모델에 입력하여 획득한 결과와 상기 제2 전처리된 우안 이미지를 상기 우안 눈꺼풀 발적 모델에 입력하여 획득한 결과에 기초하여 결정되며, 상기 눈꺼풀 부종에 대한 상기 예측값은 상기 제2 전처리된 좌안 이미지를 상기 좌안 눈꺼풀 부종 모델에 입력하여 획득한 결과와 상기 제2 전처리된 우안 이미지를 상기 우안 눈꺼풀 부종 모델에 입력하여 획득한 결과에 기초하여 결정될 수 있다. 몇몇 실시예들에 있어서, 상기 방법은 상기 제1 처리된 좌안 이미지(first processed left eye image) 및 상기 제1 처리된 우안 이미지(first processed right eye image) 중 하나를 좌우 반전 처리하고, 상기 제2 처리된 좌안 이미지(second processed left eye image) 및 상기 제2 처리된 우안 이미지(second processed right eye image) 중 하나를 좌우 반전 처리하는 것을 더 포함할 수 있다. 몇몇 실시예들에 있어서, 상기 결막 충혈에 대한 상기 예측값은 상기 좌우 반전 처리된 이미지와 좌우 반전 처 리되지 않은 이미지를 상기 결막 충혈 모델에 각각 입력하여 획득한 결과값들에 기초하여 결정되고, 상기 결막 부종에 대한 상기 예측값은 상기 좌우 반전 처리된 이미지와 좌우 반전 처리되지 않은 이미지를 상기 결막 부종 모델에 각각 입력하여 획득한 결과값들에 기초하여 결정되고, 상기 눈물언덕 부종에 대한 상기 예측값은 상기 좌우 반전 처리된 이미지와 좌우 반전 처리되지 않은 이미지를 상기 눈물언덕 부종 모델에 각각 입력하여 획득 한 결과값들에 기초하여 결정되고, 상기 눈꺼풀 발적에 대한 상기 예측값은 상기 좌우 반전 처리된 이미지와 좌 우 반전 처리되지 않은 이미지를 상기 눈꺼풀 발적 모델에 각각 입력하여 획득한 결과값들에 기초하여 결정되고, 상기 눈꺼풀 부종에 대한 상기 예측값은 상기 좌우 반전 처리된 이미지와 좌우 반전 처리되지 않은 이미지를 상기 눈꺼풀 부종 모델에 각각 입력하여 획득한 결과값들에 기초하여 결정될 수 있다. 몇몇 실시예들에 있어서, 상기 방법은 상기 제1 처리된 좌안 이미지(first processed left eye image) 및 상기 제1 처리된 우안 이미지(first processed right eye image)를 리사이징하고, 상기 제2 처리된 좌안 이미지 (second processed left eye image) 및 상기 제2 처리된 우안 이미지(second processed right eye image)를 리 사이징하는 것을 더 포함할 수 있다."}
{"patent_id": "10-2022-0171082", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 출원에 의하여 개시되는 내용에 의하면, 전문적인 의학 진단 기기가 아닌 일반인들이 사용할 수 있는 디지털 카메라로 획득된 이미지를 활용하여 갑상선 안병증에 관한 임상활동점수를 예측할 수 있다.또한, 본 출원에 의하여 개시되는 내용에 의하면, 일반인들이, 의사의 도움없이 그리고 병원 직접 방문 없이, 지속적으로 갑상선 안병증에 관한 임상활동점수를 모니터링할 수 있고, 필요한 경우 병원에 대한 방문을 추천받 을 수 있게 된다."}
{"patent_id": "10-2022-0171082", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 출원의 상술한 목적, 특징들 및 장점은 첨부된 도면과 관련된 다음의 상세한 설명을 통해 보다 분명해질 것 이다. 다만, 본 출원은 다양한 변경을 가할 수 있고 여러 가지 실시예들을 가질 수 있는 바, 이하에서는 특정 실시예들을 도면에 예시하고 이를 상세히 설명하고자 한다.명세서 전체에 걸쳐서 동일한 참조번호들은 원칙적으로 동일한 구성요소들을 나타낸다. 또한, 각 실시예의 도면 에 나타나는 동일한 사상의 범위 내의 기능이 동일한 구성요소는 동일한 참조부호를 사용하여 설명하며, 이에 대한 중복되는 설명은 생략하기로 한다. 본 출원과 관련된 공지 기능 혹은 구성에 대한 구체적인 설명이 본 출원의 요지를 불필요하게 흐릴 수 있다고 판단되는 경우 그 상세한 설명을 생략한다. 또한, 본 명세서의 설명 과정에서 이용되는 숫자(예를 들어, 제1, 제2 등)는 하나의 구성요소를 다른 구성요소와 구분하기 위한 식별기호에 불과하다. 또한, 이하의 실시예에서 사용되는 구성요소에 대한 접미사 \"모듈\" 및 \"부\"는 명세서 작성의 용이함만이 고려되 어 부여되거나 혼용되는 것으로서, 그 자체로 서로 구별되는 의미 또는 역할을 갖는 것은 아니다. 이하의 실시예에서, 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 이하의 실시예에서, 포함하다 또는 가지다 등의 용어는 명세서상에 기재된 특징, 또는 구성요소가 존재함을 의 미하는 것이고, 하나 이상의 다른 특징들 또는 구성요소가 부가될 가능성을 미리 배제하는 것은 아니다. 도면에서는 설명의 편의를 위하여 구성 요소들이 그 크기가 과장 또는 축소될 수 있다. 예컨대, 도면에서 나타 난 각 구성의 크기 및 두께는 설명의 편의를 위해 임의로 나타낸 것으로, 본 발명이 반드시 도시된 바에 한정되 지 않는다. 어떤 실시예가 달리 구현 가능한 경우에 특정한 프로세스의 순서는 설명되는 순서와 다르게 수행될 수도 있다. 예를 들어, 연속하여 설명되는 두 프로세스가 실질적으로 동시에 수행될 수도 있고, 설명되는 순서와 반대의 순 서로 진행될 수 있다. 이하의 실시예에서, 구성 요소 등이 연결되었다고 할 때, 구성 요소들이 직접적으로 연결된 경우뿐만 아니라 구 성요소들 중간에 구성 요소들이 개재되어 간접적으로 연결된 경우도 포함한다. 예컨대, 본 명세서에서 구성 요 소 등이 전기적으로 연결되었다고 할 때, 구성 요소 등이 직접 전기적으로 연결된 경우뿐만 아니라, 그 중간에 구성 요소 등이 개재되어 간접적으로 전기적 연결된 경우도 포함한다. 본 출원의 일 양태에 의하면, 퓨터로 실행가능한 갑상선 안병증의 예측방법이 개시된다. 상기 방법은, 결막 충 혈 예측 모델, 결막 부종 예측 모델, 눈물언덕 부종 예측 모델, 눈꺼풀 발적 예측 모델 및 눈꺼풀 부종 예측 모 델을 준비하고, 대상의 얼굴 이미지를 획득하고, 상기 얼굴 이미지로부터 제1 처리된 이미지(first processed image) 및 제2 처리된 이미지(second processed image)를 획득하고 - 이때, 상기 제1 처리된 이미지는 상기 제 2 처리된 이미지와 상이함 -, 상기 제1 처리된 이미지를 상기 결막 충혈 예측 모델, 상기 결막 부종 예측 모델 및 상기 눈물언덕 부종 예측 모델에 입력하여 결막 충혈, 결막 부종 및 눈물언덕 부종 각각에 대한 예측값들을 획득하고, 상기 제2 처리된 이미지를 상기 눈꺼풀 발적 예측 모델 및 상기 눈꺼풀 부종 예측 모델에 입력하여 눈꺼풀 발적 및 눈꺼풀 부종 각각에 대한 예측값들을 획득하고, 상기 결막 충혈에 대한 상기 예측값, 상기 결막 부종에 대한 상기 예측값, 상기 눈물언덕 부종에 대한 상기 예측값, 상기 눈꺼풀 발적에 대한 상기 예측값 및 상기 눈꺼풀 부종에 대한 상기 예측값에 기초하여, 상기 대상이 갑상선 안병증 (thyroid eye disease)을 가지고 있을 가능성(possibility)을 판단하는 것을 포함한다. 이때, 상기 제1 처리된 이미지는 상기 눈의 아웃라인에 대응되는 픽셀들의 위치 정보 및 상기 눈에 포함된 홍채의 아웃라인에 대응되는 픽셀들의 위치정보에 기초하여, 상기 눈의 아웃라인의 외부 및 상기 홍채의 아웃라인의 내부에 대응되는 영역들을 마스킹하고 상기 눈의 아웃라 인을 포함하는 제1 영역을 따라서 크로핑된 이미지이며, 상기 제2 처리된 이미지는 상기 눈의 아웃라인에 대응 되는 픽셀들의 위치 정보 및 상기 눈에 포함된 홍채의 아웃라인에 대응되는 픽셀들의 위치정보에 기초하여, 상 기 제1 영역 보다 더 넓게 확장된 제2 영역을 따라서 크로핑된 이미지이다. 몇몇 실시예들에 있어서, 상기 눈의 아웃라인에 대응되는 픽셀들의 위치정보 및 상기 눈에 포함된 홍채의 아웃 라인에 대응되는 픽셀들의 위치정보는 세그멘테이션 모델에 의해 획득될 수 있다. 몇몇 실시예들에 있어서, 상기 제1 처리된 이미지는 제1 처리된 좌안 이미지(first processed left eye image) 및 제1 처리된 우안 이미지(first processed right eye image)를 포함하며, 상기 제2 처리된 이미지는 제2 처 리된 좌안 이미지(second processed left eye image) 및 제2 처리된 우안 이미지(second processed right eye image)를 포함할 수 있다. 몇몇 실시예들에 있어서, 상기 결막 충혈 예측 모델은 좌안 결막 충혈 예측 모델 및 우안 결막 충혈 예측 모델 을 포함하고, 상기 결막 부종 예측 모델은 좌안 결막 부종 예측 모델 및 우안 결막 부종 예측 모델을 포함하며, 상기 눈물언덕 부종 예측 모델은 좌안 눈물언덕 부종 예측 모델 및 우안 눈물언덕 부종 예측 모델을 포함하고,상기 눈꺼풀 발적 예측 모델은 좌안 눈꺼풀 발적 예측 모델 및 우안 눈꺼풀 발적 예측 모델을 포함하며, 상기 눈꺼풀 부종 예측 모델은 좌안 눈꺼풀 부종 예측 모델 및 우안 눈꺼풀 부종 예측 모델을 포함할 수 있다. 몇몇 실시예들에 있어서, 상기 결막 충혈에 대한 상기 예측값은 상기 제1 전처리된 좌안 이미지를 상기 좌안 결 막 충혈 모델에 입력하여 획득한 결과와 상기 제1 전처리된 우안 이미지를 상기 우안 결막 충혈 모델에 입력하 여 획득한 결과에 기초하여 결정되고, 상기 결막 부종에 대한 상기 예측값은 상기 제1 전처리된 좌안 이미지를 상기 좌안 결막 부종 모델에 입력하여 획득한 결과와 상기 제1 전처리된 우안 이미지를 상기 우안 결막 부종 모 델에 입력하여 획득한 결과에 기초하여 결정되고, 상기 눈물언덕 부종에 대한 상기 예측값은 상기 제1 전처리된 좌안 이미지를 상기 좌안 눈물언덕 부종 모델에 입력하여 획득한 결과와 상기 제1 전처리된 우안 이미지를 상기 우안 눈물언덕 부종 모델에 입력하여 획득한 결과에 기초하여 결정되고, 상기 눈꺼풀 발적에 대한 상기 예측값 은 상기 제2 전처리된 좌안 이미지를 상기 좌안 눈꺼풀 발적 모델에 입력하여 획득한 결과와 상기 제2 전처리된 우안 이미지를 상기 우안 눈꺼풀 발적 모델에 입력하여 획득한 결과에 기초하여 결정되며, 상기 눈꺼풀 부종에 대한 상기 예측값은 상기 제2 전처리된 좌안 이미지를 상기 좌안 눈꺼풀 부종 모델에 입력하여 획득한 결과와 상기 제2 전처리된 우안 이미지를 상기 우안 눈꺼풀 부종 모델에 입력하여 획득한 결과에 기초하여 결정될 수 있다. 몇몇 실시예들에 있어서, 상기 방법은 상기 제1 처리된 좌안 이미지(first processed left eye image) 및 상기 제1 처리된 우안 이미지(first processed right eye image) 중 하나를 좌우 반전 처리하고, 상기 제2 처리된 좌안 이미지(second processed left eye image) 및 상기 제2 처리된 우안 이미지(second processed right eye image) 중 하나를 좌우 반전 처리하는 것을 더 포함할 수 있다. 몇몇 실시예들에 있어서, 상기 결막 충혈에 대한 상기 예측값은 상기 좌우 반전 처리된 이미지와 좌우 반전 처 리되지 않은 이미지를 상기 결막 충혈 모델에 각각 입력하여 획득한 결과값들에 기초하여 결정되고, 상기 결막 부종에 대한 상기 예측값은 상기 좌우 반전 처리된 이미지와 좌우 반전 처리되지 않은 이미지를 상기 결막 부종 모델에 각각 입력하여 획득한 결과값들에 기초하여 결정되고, 상기 눈물언덕 부종에 대한 상기 예측값은 상기 좌우 반전 처리된 이미지와 좌우 반전 처리되지 않은 이미지를 상기 눈물언덕 부종 모델에 각각 입력하여 획득 한 결과값들에 기초하여 결정되고, 상기 눈꺼풀 발적에 대한 상기 예측값은 상기 좌우 반전 처리된 이미지와 좌 우 반전 처리되지 않은 이미지를 상기 눈꺼풀 발적 모델에 각각 입력하여 획득한 결과값들에 기초하여 결정되고, 상기 눈꺼풀 부종에 대한 상기 예측값은 상기 좌우 반전 처리된 이미지와 좌우 반전 처리되지 않은 이미지를 상기 눈꺼풀 부종 모델에 각각 입력하여 획득한 결과값들에 기초하여 결정될 수 있다. 몇몇 실시예들에 있어서, 상기 방법은 상기 제1 처리된 좌안 이미지(first processed left eye image) 및 상기 제1 처리된 우안 이미지(first processed right eye image)를 리사이징하고, 상기 제2 처리된 좌안 이미지 (second processed left eye image) 및 상기 제2 처리된 우안 이미지(second processed right eye image)를 리 사이징하는 것을 더 포함할 수 있다. 본 출원에 의하면, 사용자의 갑상선 안병증에 대한 임상활동점수(Clinical Activity Score, CAS)를 예측하고, 이에 기초하여 사용자의 병원 방문 필요성에 대한 안내를 하기 위한 시스템이 개시된다. 1. 전체 시스템 시스템의 하드웨어적 구성 도 1은 본 출원에 의해 개시되는 일실시예에 따른 갑상선 안병증에 관한 임상활동점수를 예측하기 위한 시스템 을 도시하는 도면이다. 도 1을 참조하면, 상기 시스템은 복수의 사용자 단말기들 및 서버를 포함한다. 이하에서는, 상기 복수의 사용자 단말기들 및 상기 서버에 대해 보다 구체적으로 설명한다. 사용자 단말기의 기능 상기 복수의 사용자 단말기들은 각종 네트워크를 통해 상기 서버에 정보를 전송하고, 또 상기 서버(2 0)로부터 정보를 수신한다. 상기 복수의 사용자 단말기들은 사용자의 상안검(upper eyelid), 하안검(lower eyelid) 및 상기 상안검 및 하안검 등에 의해 외부로 노출되는 안구(exposed eyeball)에 관한 이미지(이하, 눈 이미지, eye image)를 획득 할 수 있으며, 상기 획득된 눈 이미지에 대한 필요한 처리를 하거나 혹은 상기 획득된 눈 이미지 또는 처리된눈 이미지를 상기 서버로 전송할 수 있다. 상기 복수의 사용자 단말기들은 상기 서버에 의해 처리된 임상활동점수에 관한 예측결과를 상기 서버 로부터 수신할 수 있다. 서버의 기능 상기 서버는 각종 네트워크를 통해 상기 복수의 사용자 단말기들에 정보를 전송하고, 또 상기 복수의 사용자 단말기들로부터 정보를 수신한다. 상기 서버는 상기 복수의 사용자 단말기들로부터 상기 눈 이미지를 수신할 수 있다. 이때, 상기 서버 는 상기 눈 이미지를 처리할 수 있다. 또는 상기 서버는 처리된 눈 이미지를 수신할 수 있다. 상기 서버는 상기 처리된 눈 이미지에 기초하여 사용자의 갑상선 안병증에 관한 임상활동점수에 대한 예측 결과를 획득할 수 있다. 상기 서버는 상기 임상활동점수에 대한 예측결과를 상기 복수의 사용자 단말기들로 전송할 수 있다. 시스템의 소프트웨어적 구성 상기 시스템이 동작하기 위하여, 몇몇 소프트웨어적 구성들이 필요하다. 상기 사용자 단말기들과 상기 서버 사이의 통신을 수행하기 위하여, 상기 복수의 사용자 단말기들 에 단말기 소프트웨어가 설치될 필요가 있으며, 상기 서버에 서버 소프트웨어가 설치될 필요가 있다. 상기 눈 이미지에 필요한 전처리(pre-processing)를 수행하기 위하여, 다양한 전처리 알고리즘들이 사용될 수 있다. 상기 전처리된 눈 이미지에 기초하여 임상활동점수를 예측하기 위한 복수의 학습모델들이 사용될 수 있다. 상기 복수의 전처리 알고리즘들은 상기 사용자 단말기들에 설치되는 단말기 소프트웨어에 의해 구동될 수도 있고, 상기 서버에 설치되는 소프트웨어에 의해 구동될 수도 있다. 또는 상기 복수의 전처리 알고리즘들의 일부는 상기 사용자 단말기들에 의해 실행되고, 나머지 일부는 상기 서버에 의해 실행될 수 있다. 상기 복수의 학습모델들은 상기 서버에 설치되는 소프트웨어에 의해 구동될 수도 있다. 또는 상기 복수의 학습모델들은 상기 사용자 단말기들에 설치되는 단말기 소프트웨어에 의해 구동될 수 있다. 또는 상기 복수 의 학습모델들의 일부는 상기 사용자 단말기들에 의해 실행되고, 나머지 일부는 상기 서버에 의해 실행 될 수 있다. 사용자 단말기의 구성요소 도 2는 본 출원에 의해 개시되는 사용자 단말기의 블록도이다. 도 2를 참조하면, 본 출원에 의해 개시되는 사용자 단말기는 출력부, 통신부, 메모리, 카메 라 및 컨트롤러를 포함한다. 출력부는 컨트롤러의 제어 명령에 따라 각종 정보를 출력한다. 일 실시예에 따르면, 출력부는 사용자에게 정보를 시각적으로 출력하는 디스플레이를 포함할 수 있다. 또는, 도면에 도시하지는 않았지만, 사용자에게 정보를 청각적으로 출력하는 스피커, 사용자에게 정보를 촉각적으로 출력하는 진동모터를 포함할 수 있다. 통신부는 무선 통신 모듈 및/또는 유선 통신 모듈을 포함할 수 있다. 여기서, 무선 통신 모듈은 와이파이 (Wi-Fi) 통신 모듈, 셀룰러 통신 모듈 등을 포함할 수 있다. 메모리는 컨트롤러에 의해 읽힐 수 있는 실행 코드, 처리된 결과값 및 필요한 데이터 등을 저장한다. 상기 메모리는 HDD(Hard Disk Drive), SSD(Solid State Disk), SDD(Silicon Disk Drive), ROM, RAM 등을 포함할 수 있다. 메모리는 전술한 단말기 소프트웨어를 저장할 수 있고, 전술한 다양한 전처리 알고리즘 및/또는 학습모델들을 구현하기 위한 실행코드들을 저장할 수 있다. 나아가, 메모리는 상기 카메라를 통해 획득되는 눈 이미지 및 상기 전처리된 눈 이미지 등을 저장할 수 있다. 카메라는 디지털 카메라로, 이미지 센서와 영상처리부를 포함할 수 있다. 이미지 센서는 광학 영상(imag e)을 전기적 신호로 변환하는 장치로, 다수개의 광 다이오드(photo diode)가 집적된 칩으로 구성될 수 있다. 예시적으로, 이미지 센서는 CCD(Charge Coupled Device), CMOS(Complementary Metal Oxide Semiconductor) 등을 포함할 수 있다. 한편, 영상처리부는 촬영된 결과를 영상 처리하여, 영상 정보를 생성할 수 있다. 컨트롤러는 적어도 하나의 프로세서를 포함할 수 있다. 이때, 각각의 프로세서는 메모리에 저장된 적 어도 하나의 명령어를 실행시킴으로써, 소정의 동작을 실행할 수 있다. 구체적으로, 컨트롤러는 상기 사용 자 단말기에서 구동되는 단말기 소프트웨어, 전처리 알고리즘 및/또는 학습모델에 따라 정보를 처리할 수 있다. 한편, 상기 컨트롤러는 상기 사용자 단말기의 전반적인 동작을 제어한다. 도면에 도시하지는 않았지만, 상기 사용자 단말기는 사용자 입력부를 포함할 수 있다. 상기 사용자 단말기 는 상기 사용자 입력부를 통해 사용자 단말기의 동작에 필요한 여러 정보를 사용자로부터 입력 받을 수 있다. 서버의 구성요소 도 3은 본 출원에 의해 개시되는 서버의 블록도이다. 도 3을 참조하면, 본 출원에 의해 개시되는 서버는 통신부, 메모리 및 컨트롤러를 포함한다. 통신부는 무선 통신 모듈 및/또는 유선 통신 모듈을 포함할 수 있다. 여기서, 무선 통신 모듈은 와이파이 (Wi-Fi) 통신 모듈, 셀룰러 통신 모듈 등을 포함할 수 있다. 메모리는 컨트롤러에 의해 읽힐 수 있는 실행 코드, 처리된 결과값 및 필요한 데이터 등을 저장한다. 상기 메모리는 HDD(Hard Disk Drive), SSD(Solid State Disk), SDD(Silicon Disk Drive), ROM, RAM 등을 포함할 수 있다. 메모리는 전술한 서버 소프트웨어를 저장할 수 있고, 전술한 다양한 전처리 알고리즘 및/ 또는 학습모델들을 구현하기 위한 실행코드들을 저장할 수 있다. 나아가, 메모리는 상기 사용자 단말기 로부터 수신한 눈 이미지 및 상기 전처리된 눈 이미지 등을 저장할 수 있다. 컨트롤러는 적어도 하나의 프로세서를 포함할 수 있다. 이때, 각각의 프로세서는 메모리에 저장된 적 어도 하나의 명령어를 실행시킴으로써, 소정의 동작을 실행할 수 있다. 구체적으로, 컨트롤러는 상기 서버 에서 구동되는 서버 소프트웨어, 전처리 알고리즘 및/또는 학습모델에 따라 정보를 처리할 수 있다. 한편, 상기 컨트롤러는 상기 서버의 전반적인 동작을 제어한다. 이하에서는, 본 출원에 의해 개시되는 기술을 보다 더 명확하고 용이하게 이해하기 위하여 눈(eye), 안구 (eyeball) 및 상안검(upper eyelid), 하안검(lower eyelid) 및 눈물언덕(lacrimal caruncle)을 포함하는 안구 주변의 조직들에 대해 간략하게 설명하고, 본 명세서에 사용되는 눈과 그 주변에 관한 용어들을 정의한다. 2. 눈의 구성 및 용어의 정의 안구 및 그 주변 조직 도 4는 카메라를 이용하여 얼굴을 촬영하였을 때 카메라에 의해 캡쳐될 수 있도록 외부로 노출되어 있는 눈 및 그 주변 조직을 설명하기 위한 도면이다. 도 4에는, 눈꺼풀(상안검, upper eyelid), 하안검(lower eyelid), 눈물언덕(lacrimal caruncle), 그리고 상기 상안검, 하안검 및 눈물언덕에 의해 일부는 가려지고 일부만 노출되어 있는 결막(conjunctiva) 및 각막(corne a)가 도시되어 있다. 일반적으로 눈(eye) 또는 안구(eyeball)는 도 4에 도시된 것보다 더 크다. 그러나, 안구는 상안검, 하안검과 같 은 조직에 의해 외부로부터 보호되고 있고, 이에 따라, 사람이 눈을 뜨고 있을 때에도 안구의 일부만 외부로 노 출된다. 용어의 정의 결막, 흰자위 이하에서는, 결막은 일반적으로 흰자위(the white of the eye)의 위치에 대응되므로, 결막과 흰자위라는 용어가 혼용될 수 있다. 각막, 홍채 이하에서는, 각막은 일반적으로 홍채(the iris of the eye)의 위치에 대응되므로, 각막과 홍채라는 용어가 혼용 될 수 있다. 한편, 본 명세서에서는 용어 '홍채'는 동공영역도 포함하는 의미로 사용된다. 눈꺼풀 안구의 앞 부분을 덮고 있는 아래위 2장의 주름있는 피부이다. 안검(眼瞼)이라고도 한다. 안구의 윗부분에 있는 눈꺼풀을 상안검, 안구의 아래부분에 있는 눈꺼풀을 하안검이라 한다. 외면은 피부로 되어 있고, 내면은 결막으 로 되어 있으며, 그 사이에는 눈꺼풀을 움직이게 하는 근육과, 분비선인 마이봄선[瞼板腺]을 품고 있는 검판(瞼 板)조직이 있어서 눈꺼풀의 형태를 유지하고 있다. 눈꺼풀은 안구를 보호함과 동시에, 눈을 깜박임으로서 눈물 로 안구를 청정하게 하거나 각막을 윤기 있고 투명하게 하는 일을 한다. 눈썹(eyebrow) 눈썹은 눈 위의 뼈가 융기한 부분을 따라 활 모양으로 자란 털을 말한다. 속눈썹(eyelash) 아래위의 눈꺼풀 가장자리에 나 있는 길이 10mm 정도의 털을 말한다. 외부로 노출된 안구 이하에서, \"외부로 노출된 안구\"는, 사람이 눈을 뜨고 있을 때, 상안검, 하안검 및 눈물언덕에 의해 가려지지 않은 부분, 즉 상안검, 하안검 및 눈물언덕에 의해 외부로 노출된 부분을 의미한다. 예를 들어, 도 5에 도시된 점선의 내부를 \"외부로 노출된 안구\"라고 일컫는다. 눈의 아웃라인(outline of eye) 이하에서는, \"눈의 아웃라인\"은, 사람이 눈을 뜨고 있을 때, 외부로 노출된 안구와 눈물언덕 영역을 모두 포함 하는 부분의 아웃라인을 의미한다. 즉, 외부로 노출된 안구와 눈물 언덕을 합한 영역의 아웃라인을 \"눈의 아웃 라인\"이라고 일컫는다. 예를 들어, 도 6에 도시된 점선을 \"눈의 아웃라인\"이라고 한다. 외부로 노출된 각막(외부로 노출된 홍채) 이하에서, \"외부로 노출된 각막\"은, 사람이 눈을 뜨고 있을 때, 상안검 및 하안검에 의해 가려지지 않은 각막 부분, 즉 상안검, 하안검에 의해 외부로 노출된 각막 부분을 의미한다. 예를 들어, 도 7에 도시된 점선의 내부 를 \"외부로 노출된 각막\"이라고 일컫는다. 외부로 노출된 결막(외부로 노출된 흰자위) 이하에서, \"외부로 노출된 결막\"은, 사람이 눈을 뜨고 있을 때, 상안검, 하안검 및 눈물언덕에 의해 가려지지 않은 결막 부분, 즉 상안검, 하안검 및 눈물언덕에 의해 외부로 노출된 결막 부분을 의미한다. 예를 들어, 도 8 에 도시된 점선의 내부를 \"외부로 노출된 결막\"이라고 일컫는다. 이하에서는, 본 출원에 의해 개시되는 이미지 전처리를 수행하는 다양한 이미지 전처리 알고리즘에 대해 설명한 다. 3. 이미지 전처리 알고리즘 이미지 전처리의 필요성 본 출원의 일 목적은 전문적인 의학 진단 기기가 아닌 일반인들이 사용할 수 있는 디지털 카메라로 획득된 이미 지를 활용하여 갑상선 안병증에 관한 임상활동점수를 예측할 수 있는 학습 모델을 제공하는 것에 있다. 이를 위해서는, 갑상선 안병증에 관한 임상활동점수를 예측함에 있어서, 일반인들이 안구 및 안구 주변의 조직 에 대하여 손쉽게 획득할 수 있는 이미지가 사용되어야 한다. 예를 들어, 의료기관 등에서 활용될 수 있는 전문 화된 의료기기 등으로 획득되는 디지털 이미지가 아닌 일반인들이 손쉽게 활용할 수 있는 디지털 카메라 혹은 스마트폰 등에 내장되어 있는 카메라에 의해 획득되는 디지털 이미지가 이미지 분석에 사용되어야 한다. 이러한 환경 하에서, 사용자 등에 의해 획득되는 디지털 이미지는 정형화되거나, 표준화되기에 어려움이 있으며, 사용자 등에 의해서 획득된 디지털 이미지를 보다 더 정확하고 빠르게 인식하기 위해서는, 획득된 이미 지에 대한 여러가지 전처리가 되어야 할 필요가 있다. 제1 크롭 (양안 이미지 크롭) 갑상선 안병증에 관한 임상활동점수를 예측에 사용되는 이미지는 좌안과 우안 및 그 주변 영역들을 포함되어 있 어야 한다. 다만, 더 빠르고 정확한 분석을 위해서는, 얼굴 전체가 캡쳐된 이미지(이하, 얼굴 이미지) 보다는 이미지 분석 에 불필요한 여러 영역들(예를 들어, 코, 입, 이마 등에 대응되는 영역들)은 포함되어 있지 않고, 양안 및 그 주변 영역만 캡쳐된 이미지(이하, 양안 이미지)를 사용하는 것이 더 효과적이다. 따라서, 사용자에 의해서 획득된 얼굴 전체가 캡쳐된 이미지(이하, 얼굴 이지미)로부터 양안(좌안/우안)을 포함 하되, 이미지(이하, 양안 이미지)를 잘라낼 필요가 있다. 예를 들어, 도 9의 (a)에 도시된 사용자에 의해 획득된 얼굴 이미지로부터 도 9의 (b)에 도시된 바와 같이 양안 이미지(점선으로 표시된 사각형의 내부 영역)가 획득될 수 있다. 이하에서는, 이렇게 사용자에 의해 획득된 얼 굴 이미지로부터 양안 이미지를 획득하는 것을 양안 이미지 크롭 또는 제1 크롭이라고 한다. 추가 크롭 방식 적용의 필요성 본 출원의 발명자들은 전술한 제1 크롭 이미지(양안 이미지)를 이용하여 나중에 후술할 예측모델들을 이용하여 갑상선 안병증에 관한 5가지 항목에 대한 점수들을 예측하는 시스템을 구축하여 보았으나 예측의 정확도가 높지 않음을 확인하였다. 이에, 본 출원의 발명자들은 낮은 예측 정확도의 이유가 양안 이미지 내에도 분석에 불필요한 영역이 많기 때문 이라고 판단하였고, 이에 보다 더 세밀한 크롭 이미지를 확보할 필요성이 있다고 판단하였다. 즉, 도 10의 (a) 에 도시된 바와 같이 좌안과 우안이 하나의 이미지에 포함되어 있는 양안 이미지를 활용하는 것보다는 도 10의 (b)에 도시된 바와 같이 좌안 이미지와 우안 이미지를 각각 확보하여 활용하는 것이 더 효과적일 것이라고 판단 하였다. 서로 다른 크롭 방식 적용의 필요성 갑상선 안병증에 관한 임상활동점수를 평가하기 위한 7가지 항목들 중 5가지 항목은 사용자의 안구 및 그 주변 영역에 대한 의사의 육안 관찰에 따라 평가되는 항목임을 이미 설명한 바 있다. 상기 5가지 항목들은 다음과 같 다. 1) 결막의 충혈 (Redness of conjunctiva), 2) 결막의 부종 (Swelling of conjunctiva), 3) 눈물언덕의 부종 (Swelling of lacrimal caruncle), 4) 눈꺼풀의 발적 (Redness of eyelid), 및 5) 눈꺼풀의 부종 (Swelling of eyelid), 이하에서, 후술하겠지만, 본 출원에 의해 제공되는 갑상선 안병증에 관한 임상활동점수를 평가하기 위하여, 상 기 5가지의 증상에 대해 서로 독립적인 예측 모델을 적용하였다. 이에, 5개의 독립적인 예측 모델에 서로 다른 크롭 방식이 적용된 이미지를 활용하는 방법도 있을 수 있으나, 본 출원의 발명자들은 결막과 눈물언덕을 분석하기 위한 이미지 크롭 방식과 눈꺼풀을 분석하기 위한 이미지 크 롭 방식을 적용하면 충분한 예측 정확성이 나올 수 있을 것이라고 판단하였다. 제2 크롭 (눈 아웃라인 베이스 크롭) 이하에서, 눈 아웃라인 베이스 크롭(eye-outline-based crop)(제2 크롭)에 대해 설명한다. 제2 크롭은 우안 이 미지와 좌안 이미지 모두에 대해서 적용될 수 있는 것이지만, 설명의 편의를 위하여, 우안 크롭 이미지를 확보 하는 것을 기준으로 설명하도록 한다. 제2 크롭의 목적 제2 크롭의 목적은 후술할 예측모델들 중 결막의 충혈 (Redness of conjunctiva) 여부를 예측하기 위한 모델, 결막의 부종 (Swelling of conjunctiva) 여부를 예측하기 위한 모델, 및 눈물언덕의 부종 (Swelling of lacrimal caruncle) 여부를 예측하기 위한 모델에 인풋 이미지로 사용하기 위한 이미지를 생성하는 목적을 가지 는 것으로, 각막과 눈물언덕에 관한 정보가 최대화되고, 그 외의 영역에 대한 정보가 최소화된 이미지를 생성하 는 것에 그 목적이 있다. 입력 이미지 제2 크롭은 얼굴 이미지에 대해 적용될 수도 있고, 양안 이미지(제1 크롭 이미지)에 대해 적용될 수도 있다. 눈의 아웃라인 검출 일 실시예에 따르면, 우안의 아웃라인을 검출하기 위하여, 상안검과 안구의 경계, 하안검과 안구의 경계에 대응 되는 픽셀들을 검출할 수 있다. 또한, 우안의 아웃라인을 검출하기 위하여, 상안검과 하안검이 서로 만나는 지 점에 대응되는 픽셀들을 검출할 수 있다. 나아가, 우안의 아웃라인을 검출하기 위하여, 눈물언덕에 대응되는 픽 셀들을 검출할 수 있다. 다른 실시예에 따르면, 후술할 눈 아웃라인 세그멘테이션 모델을 활용하여 눈 아웃라인의 최외곽에 대응되는 아 웃라인 픽셀들을 검출할 수 있다. 아웃라인 픽셀들의 X,Y 좌표의 최대값, 최소값 확인 검출된 픽셀들을 확인하여, X 좌표값들의 최대값(Xmax), X 좌표값들의 최소값(Xmin), Y 좌표값들의 최대값(Ymax) 및 Y 좌표값들의 최소값(Ymin)을 확인한다. 도 11은 아웃라인 픽셀들의 Xmax, Xmin, Ymax, Ymin을 도식화한 도면이다. 크롭 영역 결정 확인된 아웃라인 픽셀들의 Xmax, Xmin, Ymax, Ymin에 기초하여, 다음과 같은 4개의 점들을 꼭지점으로 하는 사각형 을 생성하고, 해당 사각형의 내부에 포함되는 영역을 크롭 영역으로 결정한다. (Xmin, Ymax), (Xmax, Ymax), (Xmax, Ymin), 및 (Xmin, Ymin) 도 12는 결정된 제2 크롭 영역을 도시한 도면이다. 전술한 바와 같이, 상기 제2 크롭 영역은 좌안에 대해서도 동일한 방식으로 결정될 수 있다. 제2 크롭 이미지의 생성 제2 크롭 영역이 결정되면, 결정된 제2 크롭 영역에 기초하여, 도 13에 도시된 바와 같이, 얼굴 이미지 또는 양 안 이미지로부터 전술한 바와 같이 결정된 제2 크롭 영역의 내부에 포함된 픽셀들을 이용하여 제2 크롭 이미지 들(제2 우안 크롭 이미지, 제2 좌안 크롭 이미지)이 생성될 수 있다. 이하에서, 용어 \"제2 우안 크롭 이미지\"는 용어 \"우안 아웃라인 크롭 이미지\"와 혼용될 수 있으며, 용어 \"제2 좌안 크롭 이미지\"는 용어 \"좌안 아웃라인 크롭 이미지\"와 혼용될 수 있다. 아울러, 이하에서 특별한 언급없이, 용어 \"제2 크롭 이미지(또는 아웃라인 크롭 이미지)\"는 제2 우안 크롭 이미 지 및 제2 좌안 크롭 이미지 중 어느 하나를 의미하거나 또는 맥락에 따라 둘 모두를 의미할 수 있다. 제2 크롭 이미지는 '눈의 아웃라인'을 기준으로 크롭된 이미지를 의미하는 것으로, 전술한 방식과 상이한 방식 에 따라 생성된 크롭 이미지라고 하여도, '눈의 아웃라인'의 최상측, 최하측, 최우측, 및 최좌측의 픽셀들이 크 롭 영역에 포함되도록 생성된 것이라면, 제2 크롭 이미지(아웃라인 크롭 이미지)라 하여야 할 것이다. 한편, 본 출원에서 말하는 X 좌표값와 Y 좌표값은 기준점에 대한 상대적인 위치에 따라서 그 크기와 방향이 달 라지기 때문에, 최대값과 최소값이라는 용어는 상대적인 의미로 이해되어야 할 것이지, 절대적인 의미로 해석되 어서는 안될 것이다. 즉, 좌표계의 원점의 위치가 변경됨에 따라서, 전술한 X 좌표값의 최대값은 원점이 변경된 좌표계에서의 X 좌표값의 최소값이 될 수도 있으며, X 좌표값의 최소값은 원점이 변경된 좌표계에서의 X 좌표값 의 최대값이 될 수도 있다. 이는 Y좌표값에 대해서도 동일하게 적용될 수 있다. 제3 크롭 (눈꺼풀을 포함하는 크롭) 이하에서, 눈꺼풀 포함 크롭 (eyelid-included crop)(제3 크롭)에 대해 설명한다. 제3 크롭은 우안 이미지와 좌 안 이미지 모두에 대해서 적용될 수 있는 것이지만, 설명의 편의를 위하여, 우안 크롭 이미지를 확보하는 것을 기준으로 설명하도록 한다. 제3 크롭의 목적 제3 크롭의 목적은 후술할 예측모델들 중 눈꺼풀의 발적 (Redness of eyelid) 여부를 예측하기 위한 모델 및 눈 꺼풀의 부종 (Swelling of eyelid) 여부를 예측하기 위한 모델에 대한 인풋 이미지로 사용하기 위한 이미지를 생성하는 목적을 가지는 것으로, 눈꺼풀에 관한 정보가 상기 이미지 내에 포함될 수 있도록 하는 것에 그 목적 이 있다. 이때, 눈꺼풀에 대응되는 픽셀들만으로 크롭을 하는 것보다는 눈의 아웃라인 내에 포함되어 있는 픽셀 들도 모두 포함될 수 있도록 크롭 이미지를 생성하는 것이 더 좋을 수 있다. 왜냐하면, 눈꺼풀의 발적 여부를 예측하기 위해서는 컬러값에 대한 추론 및 판단이 이루어져야 하는데, 이 때 홍채 및/또는 흰자위에 대응되는 픽셀들의 컬러값이 활용될 수 있기 때문이다. 입력 이미지 제3 크롭은 얼굴 이미지에 대해 적용될 수도 있고, 양안 이미지(제1 크롭 이미지)에 대해 적용될 수도 있다. 눈의 아웃라인 검출 및 아웃라인 픽셀들의 X,Y 좌표의 최대값, 최소값 확인 일 실시예에 따르면, 제2 크롭에서 설명한 눈의 아웃라인 검출 방식이 그대로 적용될 수 있으며, 눈 아웃라인의 최외곽에 대응되는 아웃라인 픽셀들이 검출될 수 있으며, 검출된 픽셀들을 확인하여, X 좌표값들의 최대값 (Xmax), X 좌표값들의 최소값(Xmin), Y 좌표값들의 최대값(Ymax) 및 Y 좌표값들의 최소값(Ymin)을 확인할 수 있다. 크롭 영역 결정 #1 확인된 Ymax값 및 Ymin값에 기초하여, 미리 정해진 기준에 따라 결정되는 제1 확장값 (expansion value, Ye)을 Ymax값에 더하고, 미리 정해진 기준에 따라 결정되는 제2 확장값(Ye')을 Ymin값에서 뺀 후, 전술한 제2 크롭 영역 결정방법과 유사하게 제3 크롭 영역을 결정할 수 있다. 즉, 다음과 같은 4개의 점들을 꼭지점으로 하는 사각형을 생성하고, 해당 사각형의 내부에 포함되는 영역을 제3 크롭 영역으로 결정할 수 있다. (Xmin, Ymax+Ye), (Xmax, Ymax+Ye), (Xmax, Ymin-Ye') 및 (Xmin, Ymin-Ye') 이와 같이 제3 크롭 영역을 결정하게 되면, 제2 크롭 영역에 비하여 상안검 및 하안검에 대응되는 픽셀이 이미 지 내에 보다 더 많이 포함될 수 있게 된다. 이때, 상기 제1 확장값과 상기 제2 확장값은 서로 동일할 수 있으나, 반드시 서로 동일하여야 하는 것은 아니다. 한편, 상기 제1 확장값과 상기 제2 확장값을 결정하는 기준은 서로 동일할 수 있으나, 반드시 동일하여야 하는 것은 아니다. 상기 제1 확장값 및 상기 제2 확장값은 상기 제2 크롭 영역의 크기에 기초하여 결정될 수 있다. 예를 들어, 상 기 제1 확장값 및 상기 제2 확장값은 상기 제2 크롭 영역의 가로 길이에 대한 확장 비율을 곱한 길이를 산출하 고, 상기 산출된 길이에 대응되는 픽셀의 개수로 결정될 수 있다. 다른 예를 들어, 제1 확장값 및 상기 제2 확 장값은 상기 제2 크롭 영역의 세로 길이에 대한 확장 비율을 곱한 길이를 산출하고, 상기 산출된 길이에 대응되 는 픽셀의 개수로 결정될 수 있다. 이때, 상기 특정 비율은 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60% 중 어느 하나일 수 있다.상기 제1 확장값을 결정할 때 사용되는 확장 비율과 상기 제2 확장값을 결정할 때 사용되는 확장 비율은 서로 동일할 수 있으나, 반드시 동일하여야 하는 것은 아니면, 서로 다를 수도 있다. 상기 제1 확장값을 결정할 때 상기 제2 크롭 영역의 가로길이가 사용되었다면, 상기 제2 확장값을 결정할 때도 상기 가로길이가 사용될 수 있으나, 반드시 이에 한정되지는 않고, 상기 제2 확장값을 결정할 때는 상기 세로길 이가 사용될 수 있다. 크롭 영역 결정 #2 확인된 Xmax값 및 Xmin값에 기초하여, 미리 정해진 기준에 따라 제1 가로 확장값(width expansion value, Xwe)을 결정하고, 미리 정해진 기준에 따라 제2 가로 확장값(Xwe')을 결정한다. 확인된 Ymax값 및 Ymin값에 기초하여, 미리 정해진 기준에 따라 결정되는 제1 세로 확장값 (height expansion value, Yhe)을 결정하고, 미리 정해진 기준에 따라 제2 세로 확장값(Yhe')을 결정한다. Xmax값에 상기 제1 가로 확장값(Xwe)을 더한 값, Xmin값에 상기 제2 가로 확장값(Xwe')을 뺀 값, Ymax값에 상기 제1 세로 확장값(Yhe)을 더한 값 및 Ymin값에 상기 제2 세로 확장값(Yhe')을 뺀 값에 기초하여, 전술한 제2 크롭 영역 결정방법과 유사하게 제3 크롭 영역을 결정할 수 있다. 즉, 다음과 같은 4개의 점들을 꼭지점으로 하는 사각형을 생성하고, 해당 사각형의 내부에 포함되는 영역을 제3 크롭 영역으로 결정할 수 있다. (Xmin-Xwe', Ymax+Yhe), (Xmax+Xwe, Ymax+Yhe), (Xmax+Xwe, Ymin-Yhe') 및 (Xmin-Xwe', Ymin-Yhe') *이와 같이 제3 크롭 영역을 결정하게 되면, 제2 크롭 영역에 비하여 상안검 및 하안검에 대응되는 픽셀이 이미 지 내에 보다 더 많이 포함될 수 있게 된다. 나아가, \"크롭 영역 결정 #1\" 방법에 의해 크롭된 이미지 보다 좌우로 보다 더 많은 픽셀들이 크롭된 이미지 내 에 포함될 수 있게 된다. 그 결과, 상안검 및 하안검에 대한 정보가 더 많이 크롭된 이미지 내에 포함될 수 있 다. 왜냐하면, 상안검과 하안검의 폭은 외부로 노출된 안구의 폭보다 더 넓은 것이 일반적이기 때문에, 상하로 의 확장 뿐만 아니라 좌우로의 확장을 통해 상안검 및 하안검에 대응되는 픽셀들이 더 많아지게 된다. 이때, 상기 제1 가로 확장값과 상기 제2 가로 확장값은 서로 동일할 수 있으나, 반드시 서로 동일하여야 하는 것은 아니다. 한편, 상기 제1 세로 확장값과 상기 제2 세로 확장값을 결정하는 기준은 서로 동일할 수 있으나, 반드시 동일하 여야 하는 것은 아니다. 상기 제1 가로 확장값 및 상기 제2 가로 확장값은 상기 제2 크롭 영역의 크기에 기초하여 결정될 수 있다. 예를 들어, 상기 제1 가로 확장값 및 상기 제2 가로 확장값은 상기 제2 크롭 영역의 가로 길이에 대한 확장 비율을 곱한 길이를 산출하고, 상기 산출된 길이에 대응되는 픽셀의 개수로 결정될 수 있다. 다른 예를 들어, 제1 가로 확장값 및 상기 제2 가로 확장값은 상기 제2 크롭 영역의 세로 길이에 대한 확장 비율을 곱한 길이를 산출하고, 상기 산출된 길이에 대응되는 픽셀의 개수로 결정될 수 있다. 이때, 상기 특정 비율은 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60% 중 어느 하나일 수 있다. 상기 제1 가로 확장값을 결정할 때 사용되는 확장 비율과 상기 제2 가로 확장값을 결정할 때 사용되는 확장 비 율은 서로 동일할 수 있으나, 반드시 동일하여야 하는 것은 아니면, 서로 다를 수도 있다. 상기 제1 가로 확장값을 결정할 때 상기 제2 크롭 영역의 가로길이가 사용되었다면, 상기 제2 가로 확장값을 결 정할 때도 상기 가로길이가 사용될 수 있으나, 반드시 이에 한정되지는 않고, 상기 제2 확장값을 결정할 때는 상기 세로길이가 사용될 수 있다. 한편, 제1 세로 확장값과 제2 세로 확장값을 결정하는 방법은 전술한 제1 확장값 및 제2 확장값을 결정하는 방 법과 동일하므로 이에서는 자세한 설명을 생략한다. 제3 크롭 이미지의 생성 제3 크롭 영역이 결정되면, 결정된 제3 크롭 영역에 기초하여, 도 14에 도시된 바와 같이, 얼굴 이미지 또는 양 안 이미지로부터 전술한 바와 같이 결정된 제2 크롭 영역의 내부에 포함된 픽셀들을 이용하여 제3 크롭 이미지 들(제3 우안 크롭 이미지, 제3 좌안 크롭 이미지)이 생성될 수 있다. 참고로, 도 14의 (a)는 전술한 '크롭 영역 결정 #1'의 방식에 의해 크롭된 제3 크롭 이미지이고, 도 14의 (b)는 전술한 '크롭 영역 결정 #2'의 방식에 의해 크롭된 제3 크롭 이미지이다. 이하에서, 용어 \"제3 우안 크롭 이미지\"는 용어 \"우안 눈꺼풀-포함 크롭 이미지 (right eyelid-included- cropped image)\"와 혼용될 수 있으며, 용어 \"제3 좌안 크롭 이미지\"는 용어 \"좌안 눈꺼풀-포함 크롭 이미지 (left eyelid-included-cropped image)\"와 혼용될 수 있다. 아울러, 이하에서 특별한 언급없이, 용어 \"제3 크롭 이미지(또는 눈꺼풀-포함 크롭 이미지)\"는 제3 우안 크롭 이미지 및 제3 좌안 크롭 이미지 중 어느 하나를 의미하거나 또는 맥락에 따라 둘 모두를 의미할 수 있다. 제3 크롭 이미지는 이미지 내에 눈꺼풀에 대한 정보가 포함되도록 생성된 이미지를 의미하는 것으로, 전술한 방 식과 상이한 방식에 따라 생성된 크롭 이미지라고 하여도, 눈꺼풀에 대응되는 픽셀들이 추가적으로 포함될 수 있도록 크롭 영역의 경계가 결정된 것이라면, 제3 크롭 이미지(눈꺼풀-포함 크롭 이미지)라 하여야 할 것이다. 홍채 세그멘테이션 이하에서는, 홍채 세그멘테이션에 대해 설명한다. 홍채 세그멘테이션은 안구 및 그 주변에 관한 이미지로부터 홍채 혹은 각막에 대응되는 영역을 구별해내는 모델 에 의해 수행될 수 있다. 홍채 세그멘테이션을 활용하면, 도 15에 도시된 바와 같이, 이미지 내에서 홍채에 대응되는 픽셀들을 추론해낼 수 있다. 홍채 세그멘테이션을 활용하면, 도 16에 도시된 바와 같이, 이미지 내에서 외부로 노출된 홍채에 대응되는 픽셀 들을 추론해낼 수 있다. 상기 홍채 세그멘테이션을 위한 모델은 얼굴 이미지를 입력 데이터로 입력받고, 얼굴 이미지 내에서 홍채에 대 응되는 픽셀들이라고 추론된 픽셀들에 대해서는 '1'을 출력하고, 그 외의 픽셀들에 대해서는 '0'을 출력할 수 있다. 상기 홍채 세그멘테이션 모델은 얼굴 이미지 및 얼굴 이미지 내에서 홍채에 대응되는 픽셀의 픽셀값은 '1'이고, 나머지 픽셀들의 픽셀값은 '0'인 이미지를 포함하는 학습 데이터를 이용하여 학습될 수 있다. 다만, 얼굴 이미지를 입력 데이터로 입력받아 홍채 세그멘테이션을 하는 것으로 설명하였으나, 전술한 양안 이 미지를 입력 데이터로 활용하여 홍채 세그멘테이션을 수행하는 것도 가능하다. 눈 아웃라인 (outline of eye) 세그멘테이션 이하에서는, 눈의 아웃라인 세그멘테이션에 대해 설명한다. 눈 아웃라인 세그멘테이션은 안구 및 그 주변에 관한 이미지로부터 눈의 아웃라인의 내부에 대응되는 영역을 구 별해내는 모델에 의해 수행될 수 있다. 눈 아웃라인 세그멘테이션을 활용하면, 도 17에 도시된 바와 같이, 이미지 내에서 눈의 아웃라인의 내부에 대응 되는 픽셀들을 추론해낼 수 있다. 상기 눈 아웃라인 세그멘테이션을 위한 모델은 얼굴 이미지를 입력 데이터로 입력받고, 얼굴 이미지 내에서 눈 아웃라인의 내부에 대응되는 픽셀들이라고 추론된 픽셀들에 대해서는 '1'을 출력하고, 그 외의 픽셀들에 대해서 는 '0'을 출력할 수 있다.상기 눈 아웃라인 세그멘테이션 모델은 얼굴 이미지 및 얼굴 이미지 내에서 눈 아웃라인의 내부에 대응되는 픽 셀의 픽셀값은 '1'이고, 나머지 픽셀들의 픽셀값은 '0'인 이미지를 포함하는 학습 데이터를 이용하여 학습될 수 있다. 마스킹 제1 마스킹 본 출원에 있어서, 제1 마스킹은 이미지 내에서 결막과 눈물 언덕에 대응되는 픽셀들을 남기고 그 외의 영역들 에 대응되는 픽셀값들에 반영되어 있는 정보는 제거하는 것을 의미한다. 픽셀값들에 반영되어 있는 정보를 제거한다는 것의 의미는 정보를 제거하고자 하는 픽셀들의 픽셀값들을 미리 결정된 특정값으로 변경하는 것을 의미할 수 있다. 예를 들어, 정보를 제거하고자 하는 픽셀들의 픽셀값들이 모 두 0으로 변경될 수 있다. 제1 마스킹은 전술한 갑상선 안병증에 관한 임상활동점수를 예측하기 위한 예측모델들 중 결막 및 눈물언덕과 관련된 증상을 예측하기 위한 모델에 이미지를 입력하기 전에 수행될 수 있다. 제2 마스킹 본 출원에 있어서, 제2 마스킹은 이미지 내에서 외부로 노출된 각막(외부로 노출된 홍채)에 대응되는 픽셀들을 남기고 그 외의 영역들에 대응되는 픽셀값들에 반영되어 있는 정보는 제거하는 것을 의미한다. 제2 마스킹은 전술한 갑상선 안병증에 관한 임상활동점수를 예측하기 위한 예측모델들 중 눈꺼풀(상안검 및 하 안검)과 관련된 증상을 예측하기 위한 모델에 이미지를 입력하기 전에 수행될 수 있다. 제1 마스킹의 방법 제1 마스킹은 얼굴 이미지, 제1 크롭 이미지(양안 이미지), 제2 크롭 이미지(아웃라인 크롭 이미지) 중 어느 하 나에서 선택되는 제1 마스킹 대상 이미지에 대해 수행될 수 있다. 상기 제1 마스킹 대상 이미지, 상기 눈 아웃라인 세그멘테이션 결과 및 상기 홍채 세그멘테이션 결과에 기초하 여, 제1 마스킹 이미지가 생성될 수 있다. 예를 들어, 상기 제1 마스킹 대상 이미지로부터 상기 눈 아웃라인의 내부에 대응되는 픽셀들을 제외한 나머지 픽셀들의 값 및 홍채(또는 외부로 노출된 홍채)에 대응되는 픽셀들에 대응되는 픽셀들의 값을 제거할 수 있다. 도 18은 제1 마스킹 이미지에 대한 예시적인 도면이다. 제2 마스킹의 방법 제2 마스킹은 얼굴 이미지, 제1 크롭 이미지(양안 이미지), 제3 크롭 이미지(눈꺼풀-포함 크롭 이미지) 중 어느 하나에서 선택되는 제2 마스킹 대상 이미지에 대해 수행될 수 있다. 상기 제2 마스킹 대상 이미지, 상기 눈 아웃라인 세그멘테이션 결과 및 상기 홍채 세그멘테이션 결과에 기초하 여, 제2 마스킹 이미지가 생성될 수 있다. 예를 들어, 상기 제2 마스킹 대상 이미지로부터 상기 눈 아웃라인의 내부에 대응되면서 동시에 상기 홍채(또는 외부로 노출된 홍채)에 대응되는 픽셀들의 픽셀값들을 제거할 수 있 다. 도 19는 제2 마스킹 이미지에 대한 예시적인 도면이다. 제1 마스킹의 다른 실시예 전술한 설명에 의하면, 제1 마스킹은 결막과 눈물언덕에 대응되는 픽셀들을 남기고 그 외의 영역들에 대응되는 픽셀들의 픽셀값들을 모두 제거하는 것으로 설명하였으나, 필요에 따라 각막(홍채)에 대응되는 픽셀들의 픽셀값 들은 제거하지 않을 수 있다. 다만, 홍채의 색상은 인종에 따라 서로 다른 색상을 가질 수 있기 때문에 홍채에 대응되는 픽셀들의 픽셀값을 제거하는 것이 보다 더 빠른 학습 및 보다 더 높은 정확도를 위해 유리할 수 있다. 제2 마스킹의 선택성 전술한 설명에 의하면, 제2 마스킹은 홍채에 대응되는 픽셀들의 픽셀값들을 모두 제거하는 것으로 설명하였으나, 제2 마스킹은 아예 수행하지 않아도 무방할 수 있다.다만, 홍채의 색상은 인종에 따라 서로 다른 색상을 가질 수 있기 때문에 제2 마스킹을 수행하여 홍채에 대응되 는 픽셀들의 픽셀값을 제거하는 것이 보다 더 빠른 학습 및 보다 더 높은 정확도를 위해 유리할 수 있다. 좌우 반전 좌우 반전의 필요성 본 출원에 의해 제공되는 갑상선 안병증에 관한 임상활동점수를 예측하는 방법에 의하면, 양안 이미지를 사용하 는 대신 좌안과 우안 각각에 대하여 크롭된 크롭 이미지를 사용한다. 한편, 눈의 아웃라인은 비대칭적이다. 예를 들어, 우안을 기준으로 하면, 우안의 왼쪽 끝에는 눈물언덕이 있지 만 우안의 오른쪽 끝에는 상안검과 하안검이 자연스럽게 만나는 지점이 존재한다. 이에 따라서, 보다 더 빠른 학습 및 보다 더 정확한 예측을 위하여, 우안을 기준으로 학습한 학습모델과 좌안을 기준으로 학습한 학습모델을 구별하여 사용하는 것이 보다 더 효과적이다. 그러나, 좌안과 우안의 선대칭성에 기인하여, 좌안을 우안으로 반전하게 되면 우안과 좌안의 형상적 특징이 서 로 유사해지게 된다. 이에 따라, 본 출원의 일 실시예에 따르면, 우안과 좌안 중 어느 하나는 좌우반전을 시키지 않은 채로 사용하고, 다른 하나는 좌우반전을 시켜서 사용하면 하나의 학습모델만 사용할 수 있게 된다. 좌우 반전의 방법 이미지를 좌우 반전시킨다(converting left and right of image)는 것은, 반전시키고자하는 이미지를 상하로 가 로지르면서 이미지를 좌우로 반으로 나누고 있는 좌우 기준선이 X=a라 할 때, 이미지 내에서의 (a+△, Y) 픽셀 에 제1 픽셀값이 대응되어 있고 (a-△, Y) 픽셀에 제2 픽셀값이 대응되어 있는 경우, (a+△, Y)의 픽셀값을 제1 픽셀값에서 제2 픽셀값으로 변경하고, (a-△, Y)의 픽셀값을 제2 픽셀값에서 제1 픽셀값으로 변경하는 것을 의 미한다. 좌우 반전 대상 이미지 좌안에 관한 이미지와 우안에 관한 이미지 중 어느 하나의 이미지만 좌우 반전을 시키면 충분하다. 좌안 이미지 와 우안 이미지 중 어느 이미지를 좌우반전 시킬 것인지는 후술할 예측모델들의 학습 시에 좌안 이미지와 우안 이미지 중 어느 이미지를 기준으로 학습되었는지 여부에 따라 결정된다. 한편, 마스킹과 크롭(제2 크롭 또는 제3 크롭)이 모두 완료된 이미지를 좌우반전시킬 수도 있으나, 크롭만 완료 되고 마스킹은 완료되지 않은 이미지를 좌우반전시킬 수도 있다. 도 20 내지 도 22는 원본 이미지와 좌우 반전 이미지의 다양한 예시를 도시하는 도면들이다. 좌우 반전의 선택성 다만, 좌우 반전은 전술한 바와 같이, 좌안에 대한 예측모델과 우안에 대한 예측모델을 일원화시키기 위하여 도 입되는 것이기 때문에, 만약 좌안에 대한 예측모델과 우안에 대한 예측모델을 서로 다른 모델로 구현하는 경우, 좌우 반전 전처리는 생략될 수 있다. 리사이징 리사이징의 필요성 전술한 바와 같이, 눈의 아웃라인을 기준으로 이미지를 크롭하여 사용하게 되는 경우, 사람마다 눈의 크기가 서 로 달라서, 크롭된 이미지는 사람마다 서로 다른 크기를 가지게 된다. 한편, 좌안 이미지와 우안 이미지를 독립적으로 크롭하여 획득하게 되는 경우, 좌안과 우안의 크기 차이로 인해 동일한 사람의 좌안 크롭 이미지와 우안 크롭 이미지가 서로 다르다. 이러한 이유로, 후술할 예측모델에 눈 이미지를 입력하기 전에, 눈 이미지의 크기를 각 예측모델에 대응되는 표 준 크기로 리사이징할 필요가 있다. 예측모델별 표준 크기 제1 예측모델 내지 제5 예측모델들 각각에 대응되어 있는 표준 크기는 서로 다를 수 있다. 제2 크롭 이미지를 인풋이미지로 사용하는 예측모델들에 대응되어 있는 표준 크기는 서로 동일할 수 있다. 제3 크롭 이미지를 인풋이미지로 사용하는 예측모델들에 대응되어 있는 표준 크기는 서로 동일할 수 있다. 제2 크롭 이미지를 인풋이미지로 사용하는 예측모델들에 대응되어 있는 표준 크기는 제3 크롭 이미지를 인풋이 미지로 사용하는 예측모델들에 대응되어 있는 표준 크기와 다를 수 있다. 또는, 제1 예측모델 내지 제5 예측모델들 각각에 대응되어 있는 표준 크기는 모두 동일할 수 있다. 리사이징의 방법 리사이징 대상 이미지의 크기를 표준 크기로 조절한다. 리사이징 대상 이미지의 너비 또는 높이가 표준 크기의 너비 또는 높이 보다 더 큰 경우, 상기 리사이징 대상 이미지의 너비 또는 높이를 늘일 수 있다. 리사이징 대상 이미지의 너비 또는 높이가 표준 크기의 너비 또는 높이 보다 더 작은 경우, 상기 리사이징 대상 이미지의 너비 또는 높이를 줄일 수 있다. 리사이징 시에, 리사이징 전 이미지의 종횡비(aspect ratio)는 리사이징 후 이미지의 종횡비와 다를 수 있다. 4. 예측 모델 제1 예측모델 제1 예측모델의 목적 및 동작 제1 예측모델은 결막의 충혈 여부를 예측하기 위한 모델이다. 제1 예측모델은 눈 이미지를 입력 데이터로 받고 입력된 눈 이미지에 캡쳐된 결막이 충혈되었을 확률값을 출력 할 수 있다. 제1 예측모델이 제1 좌안 예측모델 및 제1 우안 예측모델을 포함하는 경우, 상기 제1 좌안 예측모델은 좌안 이 미지를 입력받아 좌안 이미지에 캡쳐된 결막이 충혈되었을 확률값을 출력하고, 상기 제1 우안 예측모델은 우안 이미지를 입력받아 우안 이미지에 캡쳐된 결막이 충혈되었을 확률값을 출력할 수 있다. 제1 예측모델이 이원화되어 있지 않고 하나의 모델로 구현된 경우, 상기 제1 예측모델은 우안 이미지와 좌안 이 미지 중 하나를 입력받아 입력된 이미지에 캡쳐된 결막이 충혈되었을 확률값을 출력하고, 다른 하나를 다시 입 력받아 입력된 이미지에 캡쳐된 결막이 충혈되었을 확률값을 출력할 수 있다. 상기 눈 이미지는 전술한 전처리 알고리즘들에 의해 전처리가 된 이미지일 수 있다. 예를 들어, 상기 눈 이미지는 제2 크롭에 따른 전처리가 된 이미지일 수 있다. 다른 예를 들어, 상기 눈 이미지는 제2 크롭 및 리사이징을 포함하는 전처리가 된 이미지일 수 있다. 또 다른 예를 들어, 상기 눈 이미지는 제2 크롭, 제1 마스킹 및 리사이징을 포함하는 전처리가 된 이미지일 수 있다. 또 다른 예를 들어, 상기 눈 이미지는 제2 크롭, 제1 마스킹, 좌우 반전 및 리사이징을 포함하는 전처리가 된 이미지일 수 있다. 본 명세서에서, 제1 예측모델은 결막 충혈 예측 모델이라고 할 수 있다. 제1 예측모델의 학습 제1 예측모델을 학습시키기 위하여, 복수의 학습 데이터 셋들을 준비할 수 있다. 학습 데이터 셋은 눈 이미지 및 상기 눈 이미지에 캡쳐된 결막의 충혈에 관한 평가값을 포함할 수 있다. 상기 눈 이미지는 전술한 전처리 알 고리즘에 의해 전처리가 된 이미지일 수 있다. 예를 들어, 상기 눈 이미지는 제2 크롭, 제1 마스킹 및 리사이징 을 포함하는 전처리가 된 이미지일 수 있다. 제1 예측모델을 학습시키기 위하여, 인공지능 모델을 준비할 수 있다. 상기 인공지능 모델은 SVM(Support Vector Machine), Random Forest, Gradient Boosting Algorithm, ResNet, VGG, GoogLeNet, MobileNet 및 Vision Transformer 등일 수 있다.이어서, 상기 인공지능 모델에 준비된 복수의 학습 데이터 셋들에 포함된 눈 이미지들을 입력하고, 입력된 눈 이미지들 각각에 대응되는 평가값과 상기 인공지능 모델에서 출력되는 출력값을 이용하여 학습시킬 수 있다. 만약, 제1 예측모델이 제1 좌안 예측모델 및 제1 우안 예측모델을 포함하는 경우, 제1 좌안 예측모델을 학습시 키기 위한 복수의 학습 데이터 셋들은 좌안 이미지 및 상기 좌안 이미지에 캡쳐된 결막의 충혈에 관한 평가값을 포함할 수 있고, 제2 우안 예측모델을 학습시키기 위한 복수의 학습 데이터 셋들은 우안 이미지 및 상기 우안 이미지에 캡쳐된 결막의 충혈에 관한 평가값을 포함할 수 있다. 한편, 학습 데이터 셋들의 수를 늘리기 위하여, 제1 좌안 예측모델을 학습시키기 위한 복수의 학습 데이터 셋들은 좌우반전 처리된 우안 이미지 및 상기 우안 이미지에 캡쳐된 결막의 충혈에 관한 평가값을 포함할 수 있으며, 제1 우안 예측모델을 학습시키기 위한 복수의 학습 데이터 셋들은 좌우반전 처리된 좌안 이미지 및 상기 좌안 이미지에 캡쳐된 결막의 충혈에 관한 평가값을 포함할 수 있다. 만약, 제1 예측모델을 이원화시키지 않고 하나의 모델로 구현하고자 하는 경우, 복수의 학습데이터 셋들은 우안 이미지 및 상기 우안 이미지에 캡쳐된 결막의 충혈에 관한 평가값을 포함하거나 또는 좌우반전된 좌안 이미지 및 상기 좌안 이미지에 캡쳐된 결막의 충혈에 관한 평가값을 포함할 수 있다. 또는 복수의 학습 데이터 셋들은 좌안 이미지 및 상기 좌안 이미지에 캡쳐된 결막의 충혈에 관한 평가값을 포함하거나 또는 좌우반전된 우안 이 미지 및 상기 우안 이미지에 캡쳐된 결막의 충혈에 관한 평가값을 포함할 수 있다. 한편, 상기 제1 예측모델을 학습시킴에 있어서, 우안 이미지와 좌안 이미지의 구별없이 결막의 충혈 여부에 대 한 예측을 할 수 있도록 하기 위하여 우안 이미지, 좌우 반전된 우안 이미지, 좌안 이미지 및 좌우 반전된 좌안 이미지를 모두 하나의 모델을 학습시키기 위한 학습데이터로 사용될 수 있다. 예를 들어, 제1 예측모델이 제1 좌안 예측모델 및 제1 우안 예측모델을 포함하는 경우, 제1 좌안 예측모델을 학 습시키기 위한 복수의 학습 데이터 셋들은 좌안 이미지 및 상기 좌안 이미지에 캡쳐된 결막의 충혈에 관한 평가 값, 좌우반전된 우안 이미지 및 상기 우안 이미지에 캡쳐된 결막의 충혈에 관한 평가값을 포함할 수 있고, 제1 우안 예측모델을 학습시키기 위한 복수의 학습 데이터 셋들은 우안 이미지 및 상기 우안 이미지에 캡쳐된 결막 의 충혈에 관한 평가값, 좌우반전된 좌안 이미지 및 상기 좌안 이미지에 캡쳐된 결막의 충혈에 관한 평가값을 포함할 수 있다. 만약, 제1 예측모델을 이원화시키지 않고 하나의 모델로 구현하고자 하는 경우, 복수의 학습데이터 셋들은 우안 이미지 및 상기 우안 이미지에 캡쳐된 결막의 충혈에 관한 평가값, 좌우 반전된 우안 이미지 및 상기 우안 이미 지에 캡쳐된 결막의 충혈에 관한 평가값, 좌안 이미지 및 상기 좌안 이미지에 캡쳐된 결막의 충혈에 관한 평가 값, 그리고 좌우반전된 좌안 이미지 및 상기 좌안 이미지에 캡쳐된 결막의 충혈에 관한 평가값을 포함할 수 있 다. 제2 예측모델 제2 예측모델의 목적 및 동작 제2 예측모델은 결막의 부종 여부를 예측하기 위한 모델이다. 제2 예측모델은 눈 이미지를 입력 데이터로 받고 입력된 눈 이미지에 캡쳐된 결막에 부종이 존재할 확률값을 출 력할 수 있다. 제2 예측모델이 제2 좌안 예측모델 및 제2 우안 예측모델을 포함하는 경우, 상기 제2 좌안 예측모델은 좌안 이 미지를 입력받아 좌안 이미지에 캡쳐된 결막에 부종이 존재할 확률값을 출력하고, 상기 제2 우안 예측모델은 우 안 이미지를 입력받아 우안 이미지에 캡쳐된 결막에 부종이 존재할 확률값을 출력할 수 있다. 제2 예측모델이 이원화되어 있지 않고 하나의 모델로 구현된 경우, 상기 제2 예측모델은 우안 이미지와 좌안 이 미지 중 하나를 입력받아 입력된 이미지에 캡쳐된 결막에 부종이 존재할 확률값을 출력하고, 다른 하나를 다시 입력받아 입력된 이미지에 캡쳐된 결막에 부종이 존재할 확률값을 출력할 수 있다. 상기 눈 이미지는 전술한 전처리 알고리즘들에 의해 전처리가 된 이미지일 수 있다. 예를 들어, 상기 눈 이미지는 제2 크롭에 따른 전처리가 된 이미지일 수 있다. 다른 예를 들어, 상기 눈 이미지는 제2 크롭 및 리사이징을 포함하는 전처리가 된 이미지일 수 있다. 또 다른 예를 들어, 상기 눈 이미지는 제2 크롭, 제1 마스킹 및 리사이징을 포함하는 전처리가 된 이미지일 수 있다. 또 다른 예를 들어, 상기 눈 이미지는 제2 크롭, 제1 마스킹, 좌우 반전 및 리사이징을 포함하는 전처리가 된 이미지일 수 있다. 본 명세서에서, 제2 예측모델은 결막 부종 예측 모델이라고 할 수 있다. 제2 예측모델의 학습 제2 예측모델을 학습시키기 위하여, 복수의 학습 데이터 셋들을 준비할 수 있다. 학습 데이터 셋은 눈 이미지 및 상기 눈 이미지에 캡쳐된 결막에 부종이 존재하는지에 관한 평가값을 포함할 수 있다. 상기 눈 이미지는 전 술한 전처리 알고리즘에 의해 전처리가 된 이미지일 수 있다. 예를 들어, 상기 눈 이미지는 제2 크롭, 제1 마스 킹 및 리사이징을 포함하는 전처리가 된 이미지일 수 있다. 제2 예측모델을 학습시키기 위하여, 인공지능 모델을 준비할 수 있다. 상기 인공지능 모델은 SVM(Support Vector Machine), Random Forest, Gradient Boosting Algorithm, ResNet, VGG, GoogLeNet, MobileNet 및 Vision Transformer 등일 수 있다. 이어서, 상기 인공지능 모델에 준비된 복수의 학습 데이터 셋들에 포함된 눈 이미지들을 입력하고, 입력된 눈 이미지들 각각에 대응되는 평가값과 상기 인공지능 모델에서 출력되는 출력값을 이용하여 학습시킬 수 있다. 만약, 제2 예측모델이 제2 좌안 예측모델 및 제2 우안 예측모델을 포함하는 경우, 제2 좌안 예측모델을 학습시 키기 위한 복수의 학습 데이터 셋들은 좌안 이미지 및 상기 좌안 이미지에 캡쳐된 결막에 부종이 존재하는지에 관한 평가값을 포함할 수 있고, 제2 우안 예측모델을 학습시키기 위한 복수의 학습 데이터 셋들은 우안 이미지 및 상기 우안 이미지에 캡쳐된 결막에 부종이 존재하는지에 관한 평가값을 포함할 수 있다. 한편, 학습 데이터 셋들의 수를 늘리기 위하여, 제2 좌안 예측모델을 학습시키기 위한 복수의 학습 데이터 셋들은 좌우반전 처리된 우안 이미지 및 상기 우안 이미지에 캡쳐된 결막에 부종이 존재하는지에 관한 평가값을 포함할 수 있으며, 제2 우안 예측모델을 학습시키기 위한 복수의 학습 데이터 셋들은 좌우반전 처리된 좌안 이미지 및 상기 좌안 이미 지에 캡쳐된 결막에 부종이 존재하는지에 관한 평가값을 포함할 수 있다. 만약, 제2 예측모델을 이원화시키지 않고 하나의 모델로 구현하고자 하는 경우, 복수의 학습데이터 셋들은 우안 이미지 및 상기 우안 이미지에 캡쳐된 결막에 부종이 존재하는지에 관한 평가값을 포함하거나 또는 좌우반전된 좌안 이미지 및 상기 좌안 이미지에 캡쳐된 결막에 부종이 존재하는지에 관한 평가값을 포함할 수 있다. 또는 복수의 학습 데이터 셋들은 좌안 이미지 및 상기 좌안 이미지에 캡쳐된 결막에 부종이 존재하는지에 관한 평가 값을 포함하거나 또는 좌우반전된 우안 이미지 및 상기 우안 이미지에 캡쳐된 결막에 부종이 존재하는지에 관한 평가값을 포함할 수 있다. 한편, 상기 제2 예측모델을 학습시킴에 있어서, 우안 이미지와 좌안 이미지의 구별없이 결막의 부종 여부에 대 한 예측을 할 수 있도록 하기 위하여 우안 이미지, 좌우 반전된 우안 이미지, 좌안 이미지 및 좌우 반전된 좌안 이미지를 모두 하나의 모델을 학습시키기 위한 학습데이터로 사용될 수 있다. 예를 들어, 제2 예측모델이 제2 좌안 예측모델 및 제2 우안 예측모델을 포함하는 경우, 제2 좌안 예측모델을 학 습시키기 위한 복수의 학습 데이터 셋들은 좌안 이미지 및 상기 좌안 이미지에 캡쳐된 결막의 부종에 관한 평가 값, 좌우반전된 우안 이미지 및 상기 우안 이미지에 캡쳐된 결막의 부종에 관한 평가값을 포함할 수 있고, 제2 우안 예측모델을 학습시키기 위한 복수의 학습 데이터 셋들은 우안 이미지 및 상기 우안 이미지에 캡쳐된 결막 의 부종에 관한 평가값, 좌우반전된 좌안 이미지 및 상기 좌안 이미지에 캡쳐된 결막의 부종에 관한 평가값을 포함할 수 있다. 만약, 제2 예측모델을 이원화시키지 않고 하나의 모델로 구현하고자 하는 경우, 복수의 학습데이터 셋들은 우안 이미지 및 상기 우안 이미지에 캡쳐된 결막의 부종에 관한 평가값, 좌우 반전된 우안 이미지 및 상기 우안 이미 지에 캡쳐된 결막의 부종에 관한 평가값, 좌안 이미지 및 상기 좌안 이미지에 캡쳐된 결막의 부종에 관한 평가 값, 그리고 좌우반전된 좌안 이미지 및 상기 좌안 이미지에 캡쳐된 결막의 부종에 관한 평가값을 포함할 수 있 다. 제3 예측모델 제3 예측모델의 목적 및 동작 제3 예측모델은 눈물언덕의 부종 여부를 예측하기 위한 모델이다. 제3 예측모델은 눈 이미지를 입력 데이터로 받고 입력된 눈 이미지에 캡쳐된 눈물언덕에 부종이 존재할 확률값 을 출력할 수 있다. 제3 예측모델이 제3 좌안 예측모델 및 제3 우안 예측모델을 포함하는 경우, 상기 제3 좌안 예측모델은 좌안 이 미지를 입력받아 좌안 이미지에 캡쳐된 눈물언덕에 부종이 존재할 확률값을 출력하고, 상기 제3 우안 예측모델 은 우안 이미지를 입력받아 우안 이미지에 캡쳐된 눈물언덕에 부종이 존재할 확률값을 출력할 수 있다. 제3 예측모델이 이원화되어 있지 않고 하나의 모델로 구현된 경우, 상기 제3 예측모델은 우안 이미지와 좌안 이 미지 중 하나를 입력받아 입력된 이미지에 캡쳐된 눈물언덕에 부종이 존재할 확률값을 출력하고, 다른 하나를 다시 입력받아 입력된 이미지에 캡쳐된 눈물언덕에 부종이 존재할 확률값을 출력할 수 있다. 상기 눈 이미지는 전술한 전처리 알고리즘들에 의해 전처리가 된 이미지일 수 있다. 예를 들어, 상기 눈 이미지는 제2 크롭에 따른 전처리가 된 이미지일 수 있다. 다른 예를 들어, 상기 눈 이미지는 제2 크롭 및 리사이징을 포함하는 전처리가 된 이미지일 수 있다. 또 다른 예를 들어, 상기 눈 이미지는 제2 크롭, 제1 마스킹 및 리사이징을 포함하는 전처리가 된 이미지일 수 있다. 또 다른 예를 들어, 상기 눈 이미지는 제2 크롭, 제1 마스킹, 좌우 반전 및 리사이징을 포함하는 전처리가 된 이미지일 수 있다. 본 명세서에서, 제3 예측모델은 눈물언덕 부종 예측 모델이라고 할 수 있다. 제3 예측모델의 학습 제3 예측모델을 학습시키기 위하여, 복수의 학습 데이터 셋들을 준비할 수 있다. 학습 데이터 셋은 눈 이미지 및 상기 눈 이미지에 캡쳐된 눈물언덕에 부종이 존재하는지에 관한 평가값을 포함할 수 있다. 상기 눈 이미지는 전술한 전처리 알고리즘에 의해 전처리가 된 이미지일 수 있다. 예를 들어, 상기 눈 이미지는 제2 크롭, 제1 마 스킹 및 리사이징을 포함하는 전처리가 된 이미지일 수 있다. 제3 예측모델을 학습시키기 위하여, 인공지능 모델을 준비할 수 있다. 상기 인공지능 모델은 SVM(Support Vector Machine), Random Forest, Gradient Boosting Algorithm, ResNet, VGG, GoogLeNet, MobileNet 및 Vision Transformer 등일 수 있다. 이어서, 상기 인공지능 모델에 준비된 복수의 학습 데이터 셋들에 포함된 눈 이미지들을 입력하고, 입력된 눈 이미지들 각각에 대응되는 평가값과 상기 인공지능 모델에서 출력되는 출력값을 이용하여 학습시킬 수 있다. 만약, 제3 예측모델이 제3 좌안 예측모델 및 제3 우안 예측모델을 포함하는 경우, 제3 좌안 예측모델을 학습시 키기 위한 복수의 학습 데이터 셋들은 좌안 이미지 및 상기 좌안 이미지에 캡쳐된 눈물언덕에 부종이 존재하는 지에 관한 평가값을 포함할 수 있고, 제3 우안 예측모델을 학습시키기 위한 복수의 학습 데이터 셋들은 우안 이 미지 및 상기 우안 이미지에 캡쳐된 눈물언덕에 부종이 존재하는지에 관한 평가값을 포함할 수 있다. 한편, 학 습 데이터 셋들의 수를 늘리기 위하여, 제3 좌안 예측모델을 학습시키기 위한 복수의 학습 데이터 셋들은 좌우 반전 처리된 우안 이미지 및 상기 우안 이미지에 캡쳐된 눈물언덕에 부종이 존재하는지에 관한 평가값을 포함할 수 있으며, 제3 우안 예측모델을 학습시키기 위한 복수의 학습 데이터 셋들은 좌우반전 처리된 좌안 이미지 및 상기 좌안 이미지에 캡쳐된 눈물언덕에 부종이 존재하는지에 관한 평가값을 포함할 수 있다. 만약, 제3 예측모델을 이원화시키지 않고 하나의 모델로 구현하고자 하는 경우, 복수의 학습데이터 셋들은 우안 이미지 및 상기 우안 이미지에 캡쳐된 눈물언덕에 부종이 존재하는지에 관한 평가값을 포함하거나 또는 좌우반 전된 좌안 이미지 및 상기 좌안 이미지에 캡쳐된 눈물언덕에 부종이 존재하는지에 관한 평가값을 포함할 수 있 다. 또는 복수의 학습 데이터 셋들은 좌안 이미지 및 상기 좌안 이미지에 캡쳐된 눈물언덕에 부종이 존재하는지 에 관한 평가값을 포함하거나 또는 좌우반전된 우안 이미지 및 상기 우안 이미지에 캡쳐된 눈물언덕에 부종이 존재하는지에 관한 평가값을 포함할 수 있다. 한편, 상기 제3 예측모델을 학습시킴에 있어서, 우안 이미지와 좌안 이미지의 구별없이 눈물언덕의 부종 여부에 대한 예측을 할 수 있도록 하기 위하여 우안 이미지, 좌우 반전된 우안 이미지, 좌안 이미지 및 좌우 반전된 좌안 이미지를 모두 하나의 모델을 학습시키기 위한 학습데이터로 사용될 수 있다. 예를 들어, 제3 예측모델이 제3 좌안 예측모델 및 제3 우안 예측모델을 포함하는 경우, 제3 좌안 예측모델을 학 습시키기 위한 복수의 학습 데이터 셋들은 좌안 이미지 및 상기 좌안 이미지에 캡쳐된 눈물언덕의 부종에 관한 평가값, 좌우반전된 우안 이미지 및 상기 우안 이미지에 캡쳐된 눈물언덕의 부종에 관한 평가값을 포함할 수 있 고, 제3 우안 예측모델을 학습시키기 위한 복수의 학습 데이터 셋들은 우안 이미지 및 상기 우안 이미지에 캡쳐 된 눈물언덕의 부종에 관한 평가값, 좌우반전된 좌안 이미지 및 상기 좌안 이미지에 캡쳐된 눈물언덕의 부종에 관한 평가값을 포함할 수 있다. 만약, 제3 예측모델을 이원화시키지 않고 하나의 모델로 구현하고자 하는 경우, 복수의 학습데이터 셋들은 우안 이미지 및 상기 우안 이미지에 캡쳐된 눈물언덕의 부종에 관한 평가값, 좌우 반전된 우안 이미지 및 상기 우안 이미지에 캡쳐된 눈물언덕의 부종에 관한 평가값, 좌안 이미지 및 상기 좌안 이미지에 캡쳐된 눈물언덕의 부종 에 관한 평가값, 그리고 좌우반전된 좌안 이미지 및 상기 좌안 이미지에 캡쳐된 눈물언덕의 부종에 관한 평가값 을 포함할 수 있다. 제4 예측모델 제4 예측모델의 목적 및 동작 제4 예측모델은 눈꺼풀의 발적 여부를 예측하기 위한 모델이다. 제4 예측모델은 눈 이미지를 입력 데이터로 받고 입력된 눈 이미지에 캡쳐된 눈꺼풀 발적이 있을 확률값을 출력 할 수 있다. 제4 예측모델이 제4 좌안 예측모델 및 제4 우안 예측모델을 포함하는 경우, 상기 제4 좌안 예측모델은 좌안 이 미지를 입력받아 좌안 이미지에 캡쳐된 눈꺼풀 발적이 있을 확률값을 출력하고, 상기 제4 우안 예측모델은 우안 이미지를 입력받아 우안 이미지에 캡쳐된 눈꺼풀 발적이 있을 확률값을 출력할 수 있다. 제4 예측모델이 이원화되어 있지 않고 하나의 모델로 구현된 경우, 상기 제4 예측모델은 우안 이미지와 좌안 이 미지 중 하나를 입력받아 입력된 이미지에 캡쳐된 눈꺼풀 발적이 있을 확률값을 출력하고, 다른 하나를 다시 입 력받아 입력된 이미지에 캡쳐된 눈꺼풀 발적이 있을 확률값을 출력할 수 있다. 상기 눈 이미지는 전술한 전처리 알고리즘들에 의해 전처리가 된 이미지일 수 있다. 예를 들어, 상기 눈 이미지는 제3 크롭에 따른 전처리가 된 이미지일 수 있다. 다른 예를 들어, 상기 눈 이미지는 제3 크롭 및 리사이징을 포함하는 전처리가 된 이미지일 수 있다. 또 다른 예를 들어, 상기 눈 이미지는 제3 크롭, 좌우 반전 및 리사이징을 포함하는 전처리가 된 이미지일 수 있다. 또 다른 예를 들어, 상기 눈 이미지는 제3 크롭, 제2 마스킹 및 리사이징을 포함하는 전처리가 된 이미지일 수 있다. 또 다른 예를 들어, 상기 눈 이미지는 제3 크롭, 제2 마스킹, 좌우 반전 및 리사이징을 포함하는 전처리가 된 이미지일 수 있다 본 명세서에서, 제4 예측모델은 눈꺼풀 발적 예측 모델이라고 할 수 있다. 제4 예측모델의 학습 제4 예측모델을 학습시키기 위하여, 복수의 학습 데이터 셋들을 준비할 수 있다. 학습 데이터 셋은 눈 이미지 및 상기 눈 이미지에 캡쳐된 눈꺼풀의 발적에 관한 평가값을 포함할 수 있다. 상기 눈 이미지는 전술한 전처리 알고리즘에 의해 전처리가 된 이미지일 수 있다. 예를 들어, 상기 눈 이미지는 제2 크롭, 제1 마스킹 및 리사이 징을 포함하는 전처리가 된 이미지일 수 있다. 제4 예측모델을 학습시키기 위하여, 인공지능 모델을 준비할 수 있다. 상기 인공지능 모델은 SVM(Support Vector Machine), Random Forest, Gradient Boosting Algorithm, ResNet, VGG, GoogLeNet, MobileNet 및 Vision Transformer 등일 수 있다. 이어서, 상기 인공지능 모델에 준비된 복수의 학습 데이터 셋들에 포함된 눈 이미지들을 입력하고, 입력된 눈 이미지들 각각에 대응되는 평가값과 상기 인공지능 모델에서 출력되는 출력값을 이용하여 학습시킬 수 있다. 만약, 제4 예측모델이 제4 좌안 예측모델 및 제4 우안 예측모델을 포함하는 경우, 제4 좌안 예측모델을 학습시 키기 위한 복수의 학습 데이터 셋들은 좌안 이미지 및 상기 좌안 이미지에 캡쳐된 눈꺼풀의 발적에 관한 평가값 을 포함할 수 있고, 제2 우안 예측모델을 학습시키기 위한 복수의 학습 데이터 셋들은 우안 이미지 및 상기 우 안 이미지에 캡쳐된 눈꺼풀의 발적에 관한 평가값을 포함할 수 있다. 한편, 학습 데이터 셋들의 수를 늘리기 위 하여, 제4 좌안 예측모델을 학습시키기 위한 복수의 학습 데이터 셋들은 좌우반전 처리된 우안 이미지 및 상기 우안 이미지에 캡쳐된 눈꺼풀의 발적에 관한 평가값을 포함할 수 있으며, 제4 우안 예측모델을 학습시키기 위한 복수의 학습 데이터 셋들은 좌우반전 처리된 좌안 이미지 및 상기 좌안 이미지에 캡쳐된 눈꺼풀의 발적에 관한 평가값을 포함할 수 있다. 만약, 제4 예측모델을 이원화시키지 않고 하나의 모델로 구현하고자 하는 경우, 복수의 학습데이터 셋들은 우안 이미지 및 상기 우안 이미지에 캡쳐된 눈꺼풀의 발적에 관한 평가값을 포함하거나 또는 좌우반전된 좌안 이미지 및 상기 좌안 이미지에 캡쳐된 눈꺼풀의 발적에 관한 평가값을 포함할 수 있다. 또는 복수의 학습 데이터 셋들 은 좌안 이미지 및 상기 좌안 이미지에 캡쳐된 눈꺼풀의 발적에 관한 평가값을 포함하거나 또는 좌우반전된 우 안 이미지 및 상기 우안 이미지에 캡쳐된 눈꺼풀의 발적에 관한 평가값을 포함할 수 있다. 한편, 상기 제1 예측모델을 학습시킴에 있어서, 우안 이미지와 좌안 이미지의 구별없이 눈꺼풀의 발적 여부에 대한 예측을 할 수 있도록 하기 위하여 우안 이미지, 좌우 반전된 우안 이미지, 좌안 이미지 및 좌우 반전된 좌 안 이미지를 모두 하나의 모델을 학습시키기 위한 학습데이터로 사용될 수 있다. 예를 들어, 제4 예측모델이 제4 좌안 예측모델 및 제4 우안 예측모델을 포함하는 경우, 제4 좌안 예측모델을 학 습시키기 위한 복수의 학습 데이터 셋들은 좌안 이미지 및 상기 좌안 이미지에 캡쳐된 눈꺼풀의 발적에 관한 평 가값, 좌우반전된 우안 이미지 및 상기 우안 이미지에 캡쳐된 눈꺼풀의 발적에 관한 평가값을 포함할 수 있고, 제4 우안 예측모델을 학습시키기 위한 복수의 학습 데이터 셋들은 우안 이미지 및 상기 우안 이미지에 캡쳐된 눈꺼풀의 발적에 관한 평가값, 좌우반전된 좌안 이미지 및 상기 좌안 이미지에 캡쳐된 눈꺼풀의 발적에 관한 평 가값을 포함할 수 있다. 만약, 제4 예측모델을 이원화시키지 않고 하나의 모델로 구현하고자 하는 경우, 복수의 학습데이터 셋들은 우안 이미지 및 상기 우안 이미지에 캡쳐된 눈꺼풀의 발적에 관한 평가값, 좌우 반전된 우안 이미지 및 상기 우안 이 미지에 캡쳐된 눈꺼풀의 발적에 관한 평가값, 좌안 이미지 및 상기 좌안 이미지에 캡쳐된 눈꺼풀의 발적에 관한 평가값, 그리고 좌우반전된 좌안 이미지 및 상기 좌안 이미지에 캡쳐된 눈꺼풀의 발적에 관한 평가값을 포함할 수 있다. 제5 예측모델 제5 예측모델의 목적 및 동작 제5 예측모델은 눈꺼풀의 부종 여부를 예측하기 위한 모델이다. 제5 예측모델은 눈 이미지를 입력 데이터로 받고 입력된 눈 이미지에 캡쳐된 눈꺼풀에 부종이 존재할 확률값을 출력할 수 있다. 제5 예측모델이 제5 좌안 예측모델 및 제5 우안 예측모델을 포함하는 경우, 상기 제5 좌안 예측모델은 좌안 이 미지를 입력받아 좌안 이미지에 캡쳐된 눈꺼풀에 부종이 존재할 확률값을 출력하고, 상기 제5 우안 예측모델은 우안 이미지를 입력받아 우안 이미지에 캡쳐된 눈꺼풀에 부종이 존재할 확률값을 출력할 수 있다. 제5 예측모델이 이원화되어 있지 않고 하나의 모델로 구현된 경우, 상기 제5 예측모델은 우안 이미지와 좌안 이 미지 중 하나를 입력받아 입력된 이미지에 캡쳐된 눈꺼풀에 부종이 존재할 확률값을 출력하고, 다른 하나를 다 시 입력받아 입력된 이미지에 캡쳐된 눈꺼풀에 부종이 존재할 확률값을 출력할 수 있다. 상기 눈 이미지는 전술한 전처리 알고리즘들에 의해 전처리가 된 이미지일 수 있다. 예를 들어, 상기 눈 이미지는 제3 크롭에 따른 전처리가 된 이미지일 수 있다. 다른 예를 들어, 상기 눈 이미지는 제3 크롭 및 리사이징을 포함하는 전처리가 된 이미지일 수 있다. 또 다른 예를 들어, 상기 눈 이미지는 제3 크롭, 좌우 반전 및 리사이징을 포함하는 전처리가 된 이미지일 수 있다.또 다른 예를 들어, 상기 눈 이미지는 제3 크롭, 제2 마스킹 및 리사이징을 포함하는 전처리가 된 이미지일 수 있다. 또 다른 예를 들어, 상기 눈 이미지는 제3 크롭, 제2 마스킹, 좌우 반전 및 리사이징을 포함하는 전처리가 된 이미지일 수 있다. 본 명세서에서, 제5 예측모델은 눈꺼풀 부종 예측 모델이라고 할 수 있다. 제5 예측모델의 학습 제5 예측모델을 학습시키기 위하여, 복수의 학습 데이터 셋들을 준비할 수 있다. 학습 데이터 셋은 눈 이미지 및 상기 눈 이미지에 캡쳐된 눈꺼풀에 부종이 존재하는지에 관한 평가값을 포함할 수 있다. 상기 눈 이미지는 전술한 전처리 알고리즘에 의해 전처리가된 이미지일 수 있다. 예를 들어, 상기 눈 이미지는 제3 크롭, 제2 마 스킹 및 리사이징을 포함하는 전처리가 된 이미지일 수 있다. 제5 예측모델을 학습시키기 위하여, 인공지능 모델을 준비할 수 있다. 상기 인공지능 모델은 SVM(Support Vector Machine), Random Forest, Gradient Boosting Algorithm, ResNet, VGG, GoogLeNet, MobileNet 및 Vision Transformer 등일 수 있다. 이어서, 상기 인공지능 모델에 준비된 복수의 학습 데이터 셋들에 포함된 눈 이미지들을 입력하고, 입력된 눈 이미지들 각각에 대응되는 평가값과 상기 인공지능 모델에서 출력되는 출력값을 이용하여 학습시킬 수 있다. 만약, 제5 예측모델이 제5 좌안 예측모델 및 제5 우안 예측모델을 포함하는 경우, 제5 좌안 예측모델을 학습시 키기 위한 복수의 학습 데이터 셋들은 좌안 이미지 및 상기 좌안 이미지에 캡쳐된 눈꺼풀에 부종이 존재하는지 에 관한 평가값을 포함할 수 있고, 제5 우안 예측모델을 학습시키기 위한 복수의 학습 데이터 셋들은 우안 이미 지 및 상기 우안 이미지에 캡쳐된 눈꺼풀에 부종이 존재하는지에 관한 평가값을 포함할 수 있다. 한편, 학습 데 이터 셋들의 수를 늘리기 위하여, 제5 좌안 예측모델을 학습시키기 위한 복수의 학습 데이터 셋들은 좌우반전 처리된 우안 이미지 및 상기 우안 이미지에 캡쳐된 눈꺼풀에 부종이 존재하는지에 관한 평가값을 포함할 수 있 으며, 제5 우안 예측모델을 학습시키기 위한 복수의 학습 데이터 셋들은 좌우반전 처리된 좌안 이미지 및 상기 좌안 이미지에 캡쳐된 눈꺼풀에 부종이 존재하는지에 관한 평가값을 포함할 수 있다. 만약, 제5 예측모델을 이원화시키지 않고 하나의 모델로 구현하고자 하는 경우, 복수의 학습데이터 셋들은 우안 이미지 및 상기 우안 이미지에 캡쳐된 눈꺼풀에 부종이 존재하는지에 관한 평가값을 포함하거나 또는 좌우반전 된 좌안 이미지 및 상기 좌안 이미지에 캡쳐된 눈꺼풀에 부종이 존재하는지에 관한 평가값을 포함할 수 있다. 또는 복수의 학습 데이터 셋들은 좌안 이미지 및 상기 좌안 이미지에 캡쳐된 눈꺼풀에 부종이 존재하는지에 관 한 평가값을 포함하거나 또는 좌우반전된 우안 이미지 및 상기 우안 이미지에 캡쳐된 눈꺼풀에 부종이 존재하는 지에 관한 평가값을 포함할 수 있다. 한편, 상기 제5 예측모델을 학습시킴에 있어서, 우안 이미지와 좌안 이미지의 구별없이 눈꺼풀의 부종 여부에 대한 예측을 할 수 있도록 하기 위하여 우안 이미지, 좌우 반전된 우안 이미지, 좌안 이미지 및 좌우 반전된 좌 안 이미지를 모두 하나의 모델을 학습시키기 위한 학습데이터로 사용될 수 있다. 예를 들어, 제5 예측모델이 제5 좌안 예측모델 및 제5 우안 예측모델을 포함하는 경우, 제5 좌안 예측모델을 학 습시키기 위한 복수의 학습 데이터 셋들은 좌안 이미지 및 상기 좌안 이미지에 캡쳐된 눈꺼풀의 부종에 관한 평 가값, 좌우반전된 우안 이미지 및 상기 우안 이미지에 캡쳐된 눈꺼풀의 부종에 관한 평가값을 포함할 수 있고, 제5 우안 예측모델을 학습시키기 위한 복수의 학습 데이터 셋들은 우안 이미지 및 상기 우안 이미지에 캡쳐된 눈꺼풀의 부종에 관한 평가값, 좌우반전된 좌안 이미지 및 상기 좌안 이미지에 캡쳐된 눈꺼풀의 부종에 관한 평 가값을 포함할 수 있다. 만약, 제5 예측모델을 이원화시키지 않고 하나의 모델로 구현하고자 하는 경우, 복수의 학습데이터 셋들은 우안 이미지 및 상기 우안 이미지에 캡쳐된 눈꺼풀의 부종에 관한 평가값, 좌우 반전된 우안 이미지 및 상기 우안 이 미지에 캡쳐된 눈꺼풀의 부종에 관한 평가값, 좌안 이미지 및 상기 좌안 이미지에 캡쳐된 눈꺼풀의 부종에 관한 평가값, 그리고 좌우반전된 좌안 이미지 및 상기 좌안 이미지에 캡쳐된 눈꺼풀의 부종에 관한 평가값을 포함할 수 있다. 예측모델들의 학습은 전자기기에 의해 수행될 수 있으며, 특히 전술한 서버에 의해 수행될 수 있다. 아울러, 전자기기 또는 서버에 의해 예측모델들이 학습된다는 것의 의미는 입력 데이터에 대한 예측모델의출력값이 해당 입력 데이터에 대해 라벨링되어 있는 출력값과 유사한 값을 출력하도록 만드는 일련의 과정들을 의미하며, 이를 위해 전자기기 또는 서버는 예측모델의 출력값과 라벨링값들의 차이를 이용하여 예측모델에 포함되어 있는 각 노드들의 가중치(weight value)를 변경할 수 있다. 이 때, 전자기기 또는 서버는 여러가 지 피드백 함수들을 사용하여 각 노드들의 가중치 값의 변경량 등을 결정할 수 있다. 이하에서는, 전술한 시스템을 통해서, 눈 이미지를 전처리하고, 전처리된 눈 이미지를 전술한 예측모델에 입 력하여, 갑상선 안병증 임상활동점수에 관련된 각 증상에 대해 예측하는 방법, 각 증상에 대한 예측결과에 기초 하여 임상활동점수를 예측하는 방법, 나아가 임상활동점수의 예측 결과를 모니터링하여 모니터링 결과에 따라 사용자에게 병원에 방문하여 검진을 받을 수 있도록 안내하거나 혹은 추천하는 방법에 대해서 설명한다. 5. 결막 충혈 예측방법 본 출원에 의해 개시되는 결막 충혈 예측 방법은 서버에 의해 수행될 수 있다. 도 23은 결막 충혈 예측 방법을 설명하기 위한 흐름도이다. 도 23을 참고하면, 서버는 얼굴 이미지를 획득하고(S100), 상기 획득된 얼굴 이미지를 전처리하고(S110), 상기 전처리된 이미지를 전술한 제1 예측모델(결막 충혈 예측모델)에 입력하고(S120), 상기 제1 예측모델의 출 력값을 획득한다(S130). 얼굴 이미지의 획득 상기 서버는 얼굴 이미지를 획득한다(S100). 상기 서버는 상기 얼굴 이미지를 상기 사용자 단말기 로부터 획득할 수 있다. 얼굴 이미지의 전처리 상기 서버는 상기 획득된 얼굴 이미지를 전처리할 수 있다(S110). 상기 서버는 상기 획득된 얼굴 이미 지에 전술한 홍채 세그멘테이션, 눈 아웃라인 세그멘테이션, 마스킹, 크롭 및 리사이징을 할 수 있다. 세그멘테이션 처리 상기 서버는 상기 홍채 세그멘테이션 및 눈 아웃라인 세그멘테이션을 수행하고, 그 결과에 따라 상기 획득 된 얼굴 이미지 내에서 홍채에 대응되는 픽셀들과 눈 아웃라인의 내부에 대응되는 픽셀들을 확인할 수 있다. 상 기 서버는 상기 홍채에 대응되는 픽셀들의 좌표값들 및 상기 눈 아웃라인의 내부에 대응되는 픽셀들의 좌표 값들을 확인할 수 있다. 마스킹 처리 상기 서버는 상기 확인된 픽셀들에 관한 정보에 기초하여, 상기 얼굴 이미지에 상기 제1 마스킹을 처리할 수 있다. 상기 서버는 상기 제1 마스킹 처리를 통해 상기 얼굴 이미지에 포함된 픽셀들 중 외부로 노출된 결막 및 눈물언덕에 대응되는 픽셀들을 제외한 나머지 픽셀들의 픽셀값들을 제거할 수 있다. 이에 따라, 좌안의 결막 및 눈물언덕, 그리고 우안의 결막 및 눈물언덕에 대응되는 픽셀들의 픽셀값은 원래 픽셀값(original pixel value)으로 유지될 수 있으나, 좌안의 홍채(또는 각막), 우안의 홍채(또는 각막), 그리고 좌안의 아웃라인 외부 및 우안의 아웃라인 외부에 대응되는 픽셀들의 픽셀값은 제거되거나 다른 값으로 변경될 수 있다. 크롭 처리 상기 서버는 상기 마스킹된 얼굴 이미지를 크롭할 수 있다. 상기 서버는 상기 마스킹된 얼굴 이미지를 크롭하여 좌안 크롭 이미지 및 우안 크롭 이미지를 생성할 수 있다. 결막 충혈 예측 방법을 수행할 때, 상기 서 버는 전술한 2가지의 크롭 방법들 중 제2 크롭(눈 아웃라인 크롭) 방법을 사용할 수 있다. 제2 크롭 방법에 관해서는 이미 상세히 설명한 바 있으므로 여기서는 자세한 설명을 생략한다. 리사이징 처리 및 좌우 반전 처리 상기 서버는 상기 좌안 크롭 이미지 및 상기 우안 크롭 이미지의 크기를 미리 정해진 사이즈로 리사이징 할 수 있다. 한편, 상기 제1 예측모델을 이원화시키지 않고 하나의 모델로 구현한 경우, 상기 서버는 상기 좌안 크롭 이 미지 및 상기 우안 크롭 이미지 중 하나를 전술한 바와 같이 좌우 반전시킬 수 있다. 상기 서버는 상기 좌 안 크롭 이미지 및 상기 우안 크롭 이미지 중 다른 하나는 좌우 반전시키지 않는다. 이때, 좌안 이미지와 좌안이미지 중 어느 이미지를 좌우반전시킬지를 결정하는 기준은 상기 제1 예측모델을 학습시킬 때 적용하였던 기준 과 동일한 기준으로 결정한다. 즉, 제1 예측 모델을 학습시킬 때, 좌안 이미지를 반전시키고 우안 이미지를 반 전시키지 않은 경우, 이와 동일하게 상기 서버는 좌안 이미지를 반전시키고 우안 이미지를 반전시키지 않는 다. 만약, 전술한 바와 같이, 제1 예측모델을 구현함에 있어서, 제1 좌안 예측모델 및 제1 우안 예측모델로 이원화 한 경우, 상기 서버는 좌우 반전 처리를 수행하지 않을 수 있다. 한편, 전처리를 수행함에 있어서, 세그멘테이션, 마스킹 처리, 크롭 처리, 리사이징 처리, 좌우 반전 처리를 하 는 것으로 설명하였으나, 각 전처리들의 순서는 본 출원에 의해 개시되는 결막 충혈 예측방법의 목적을 달성할 수 있는 범위 내에서 변경될 수 있다. 전처리된 이미지의 입력 상기 서버는 상기 전처리된 이미지를 상기 제1 예측모델에 입력할 수 있다(S120). 상기 서버는, 상기 제1 예측모델을 이원화시키지 않고 하나의 모델로 구현한 경우, 상기 우안 전처리 이미 지 및 좌우 반전된 좌안 전처리 이미지를 순차적으로 상기 제1 예측모델에 입력한다. 만약, 제1 예측모델을 구현함에 있어서 제1 좌안 예측모델 및 제1 우안 예측모델로 이원화한 경우, 상기 서버 는 상기 좌안 전처리 이미지를 상기 제1 좌안 예측모델에 입력하고, 상기 우안 전처리 이미지를 상기 제1 우안 예측모델에 입력한다. 또는 상기 서버는 상기 좌안 전처리 이미지를 상기 제1 좌안 예측모델에 입력하 고, 상기 좌우 반전된 좌안 전처리 이미지를 상기 제1 우안 예측모델에 입력하고, 상기 우안 전처리 이미지를 상기 제1 우안 예측모델에 입력하고, 상기 좌우 반전된 우안 전처리 이미지를 상기 제1 좌안 예측모델에 입력할 수 있다. 만약, 제1 예측모델을 구현함에 있어서, 제1 예측모델을 이원화시키지 않고 하나의 모델로 구현하면서 동시에 좌안 이미지와 우안 이미지를 구별하지 않고 결막의 충혈 여부를 판단할 수 있도록 학습된 경우, 상기 서버(2 0)는 상기 좌안 전처리 이미지 및 상기 우안 전처리 이미지를, 좌우반전 없이, 상기 제1 예측모델에 입력할 수 있다. 또는 상기 서버는 상기 좌안 전처리 이미지, 상기 좌우 반전된 좌안 전처리 이미지, 상기 우안 전처 리 이미지 및 상기 좌우 반전된 우안 전처리 이미지를 상기 제1 예측모델에 입력할 수 있다. 결막 충혈 예측 결과 상기 서버는 상기 제1 예측모델로부터 출력되는 결과값을 획득할 수 있다(S130). 상기 결과값은 이미지에 캡쳐된 결막이 충혈되어있을 예측되는 확률값일 수 있다. 상기 서버는 미리 정해진 쓰레숄드값(threshold value)을 기준으로 상기 예측되는 확률값이 상기 쓰레숄드값 이상이면 결막이 충혈되어 있는 것으로 판단하고, 상기 예측되는 확률값이 상기 쓰레숄드값 미만이면 결막이 충혈되어 있지 않은 것으로 판단할 수 있다. 상기 서버는 좌안에 대한 예측결과와 우안에 대한 예측 결과를 모두 획득할 수 있다. 만약, 상기 서버가 상기 좌안 전처리 이미지를 상기 제1 좌안 예측모델에 입력하고, 상기 좌우 반전된 좌안 전처리 이미지를 상기 제1 우안 예측모델에 입력하고, 상기 우안 전처리 이미지를 상기 제1 우안 예측모델에 입 력하고, 상기 좌우 반전된 우안 전처리 이미지를 상기 제1 좌안 예측모델에 입력한 경우, 상기 서버는 상기 좌안 전처리 이미지를 상기 제1 좌안 예측모델에 입력하여 획득한 결과와 상기 좌우 반전된 좌안 전처리 이미지 를 상기 제1 우안 예측모델에 입력하여 획득한 결과를 모두 고려하여 상기 좌안에 대한 예측 결과를 획득할 수 있다. 이때, 상기 서버는 상기 우안 전처리 이미지를 상기 제1 우안 예측모델에 입력하여 획득한 결과와 상 기 좌우 반전된 우안 전처리 이미지를 상기 제1 좌안 예측모델에 입력하여 획득한 결과를 모두 고려하여 상기 우안에 대한 예측 결과를 획득할 수 있다. 예를 들어, 상기 서버는 상기 좌안 전처리 이미지를 상기 제1 좌안 예측모델에 입력하여 획득한 결과와 상 기 좌우 반전된 좌안 전처리 이미지를 상기 제1 우안 예측모델에 입력하여 획득한 결과의 평균값이 상기 쓰레숄 드값 이상인지 여부에 기초하여 상기 좌안에 대한 예측 결과를 획득할 수 있다. 다른 예를 들어, 상기 서버는 상기 좌안 전처리 이미지를 상기 제1 좌안 예측모델에 입력하여 획득한 결과 와 상기 좌우 반전된 좌안 전처리 이미지를 상기 제1 우안 예측모델에 입력하여 획득한 결과 중 어느 하나의 값 이 전술한 쓰레숄드값 이상인 경우, 상기 좌안의 결막이 충혈되었다고 예측할 수 있다. 또 다른 예를 들어, 상기 서버는 상기 좌안 전처리 이미지를 상기 제1 좌안 예측모델에 입력하여 획득한 결 과와 상기 좌우 반전된 좌안 전처리 이미지를 상기 제1 우안 예측모델에 입력하여 획득한 결과 모두가 전술한 쓰레숄드값 이상인 경우, 상기 좌안의 결막이 충혈되었다고 예측할 수 있다. 만약, 상기 서버는 상기 좌안 전처리 이미지, 상기 좌우 반전된 좌안 전처리 이미지, 상기 우안 전처리 이 미지 및 상기 좌우 반전된 우안 전처리 이미지를 이원화되지 않은 상기 제1 예측모델에 입력한 경우, 상기 서버 는 상기 좌안 전처리 이미지를 상기 제1 예측모델에 입력하여 획득한 결과와 상기 좌우 반전된 좌안 전처리 이미지를 상기 제1 예측모델에 입력하여 획득한 결과를 모두 고려하여 상기 좌안에 대한 예측 결과를 획득할 수 있다. 이때, 상기 서버는 상기 우안 전처리 이미지를 상기 제1 예측모델에 입력하여 획득한 결과와 상기 좌 우 반전된 우안 전처리 이미지를 상기 제1 예측모델에 입력하여 획득한 결과를 모두 고려하여 상기 우안에 대한 예측 결과를 획득할 수 있다. 예를 들어, 상기 서버는 상기 좌안 전처리 이미지를 상기 제1 예측모델에 입력하여 획득한 결과와 상기 좌 우 반전된 좌안 전처리 이미지를 상기 제1 예측모델에 입력하여 획득한 결과의 평균값이 상기 쓰레숄드값 이상 인지 여부에 기초하여 상기 좌안에 대한 예측 결과를 획득할 수 있다. 다른 예를 들어, 상기 서버는 상기 좌안 전처리 이미지를 상기 제1 예측모델에 입력하여 획득한 결과와 상 기 좌우 반전된 좌안 전처리 이미지를 상기 제1 예측모델에 입력하여 획득한 결과 중 어느 하나의 값이 전술한 쓰레숄드값 이상인 경우, 상기 좌안의 결막이 충혈되었다고 예측할 수 있다. 또 다른 예를 들어, 상기 서버는 상기 좌안 전처리 이미지를 상기 제1 예측모델에 입력하여 획득한 결과와 상기 좌우 반전된 좌안 전처리 이미지를 상기 제1 예측모델에 입력하여 획득한 결과 모두가 전술한 쓰레숄드값 이상인 경우, 상기 좌안의 결막이 충혈되었다고 예측할 수 있다. 전술한 방식은 우안의 결막 충혈 여부를 판단하는 데에도 유사하게 적용될 수 있다. 6. 결막 부종 예측방법 본 출원에 의해 개시되는 결막 부종 예측 방법은 서버에 의해 수행될 수 있다. 도 24는 결막 부종 예측 방법을 설명하기 위한 흐름도이다. 도 24를 참고하면, 서버는 얼굴 이미지를 획득하고(S200), 상기 획득된 얼굴 이미지를 전처리하고(S210), 상기 전처리된 이미지를 전술한 제2 예측모델(결막 부종 예측모델)에 입력하고(S220), 상기 제2 예측모델의 출 력값을 획득한다(S230). 상기 결막 부종 예측방법은 제1 예측모델 대신 제2 예측모델을 사용한다는 점, 그리고 최종적으로 획득되는 결 과값이 결막에 부종이 있는지 여부에 대한 예측값이라는 점을 제외하면, 결막 충혈 예측방법과 동일하거나 매우 유사하기 때문에, 자세한 설명은 생략하기로 한다. 7. 눈물언덕 부종 예측방법 본 출원에 의해 개시되는 눈물언덕 부종 예측 방법은 서버에 의해 수행될 수 있다. 도 25는 눈물언덕 부종 예측 방법을 설명하기 위한 흐름도이다. 도 25를 참고하면, 서버는 얼굴 이미지를 획득하고(S300), 상기 획득된 얼굴 이미지를 전처리하고(S310), 상기 전처리된 이미지를 전술한 제3 예측모델(눈물언덕 부종 예측모델)에 입력하고(S320), 상기 제3 예측모델의 출력값을 획득한다(S330). 상기 결막 부종 예측방법은 제1 예측모델 대신 제3 예측모델을 사용한다는 점을 제외하면, 결막 충혈 예측방법 과 동일하거나 매우 유사하기 때문에, 자세한 설명은 생략하기로 한다. 전술한 바와 같이, 결막 충혈 예측방법, 결막 부종 예측방법 및 눈물언덕 부종 예측방법에서 사용되는 이미지의 전처리 방법은 서로 동일하고, 다만 전처리된 이미지가 입력되는 예측모델들이 서로 다를 뿐이다. 따라서, 전술 한 바와 같은 이미지 전처리를 한 후, 그 이미지가 서로 다른 예측모델들에 입력될 수 있다. 다만, 본 눈물언덕 부종에 대해서는 결막 충혈 및 결막 부종의 예측방법에서 사용하는 이미지 전처리 방식과 동 일한 방식이 적용되는 것으로 설명하고 있으나, 경우에 따라서는, 눈물언덕 부종을 예측하는 방법에 있어서, 다 른 방식으로 전처리된 이미지가 사용될 수도 있다. 예를 들어, 홍채의 일부와 눈물언덕이 이미지에 포함되도록 크롭된 전처리 이미지를 사용할 수도 있다. 혹은 홍채는 포함되지 않고 눈물언덕과 눈물언덕이 이미지에 포함되도록 크롭된 전처리 이미지를 사용할 수도 있다. 8. 눈꺼풀 발적 예측방법 본 출원에 의해 개시되는 눈꺼풀 발적 예측 방법은 서버에 의해 수행될 수 있다. 도 26은 눈꺼풀 발적 예측 방법을 설명하기 위한 흐름도이다. 도 26을 참고하면, 서버는 얼굴 이미지를 획득하고(S400), 상기 획득된 얼굴 이미지를 전처리하고(S410), 상기 전처리된 이미지를 전술한 제4 예측모델(눈꺼풀 발적 예측모델)에 입력하고(S420), 상기 제4 예측모델의 출력값을 획득한다(S430). 얼굴 이미지의 획득 상기 서버는 얼굴 이미지를 획득한다(S400). 상기 서버는 상기 얼굴 이미지를 상기 사용자 단말기 로부터 획득할 수 있다. 얼굴 이미지의 전처리 상기 서버는 상기 획득된 얼굴 이미지를 전처리할 수 있다(S410). 상기 서버는 상기 획득된 얼굴 이미 지에 전술한 홍채 세그멘테이션, 눈 아웃라인 세그멘테이션, 마스킹, 크롭 및 리사이징을 할 수 있다. 세그멘테이션 처리 상기 서버는 상기 홍채 세그멘테이션 및 눈 아웃라인 세그멘테이션을 수행하고, 그 결과에 따라 상기 획득 된 얼굴 이미지 내에서 홍채에 대응되는 픽셀들과 눈 아웃라인의 내부에 대응되는 픽셀들을 확인할 수 있다. 상 기 서버는 상기 홍채에 대응되는 픽셀들의 좌표값들 및 상기 눈 아웃라인의 내부에 대응되는 픽셀들의 좌표 값들을 확인할 수 있다. 다만, 눈꺼풀 발적 예측방법을 수행함에 있어서, 후술하는 바와 같이, 별도의 마스킹 처리를 하는 경우에는 홍 채 세그멘테이션을 수행하여야 하지만, 만약 별도의 마스킹 처리를 하지 않는 경우에는 홍채 세그멘테이션을 수 행하지 않아도 무방하다. 마스킹 처리 상기 서버는 상기 확인된 픽셀들에 관한 정보에 기초하여, 상기 얼굴 이미지에 상기 제2 마스킹을 처리할 수 있다. 상기 서버는 상기 제2 마스킹 처리를 통해 상기 얼굴 이미지에 포함된 픽셀들 중 외부로 노출된 홍채(각막)에 대응되는 픽셀들의 픽셀값들을 제거할 수 있다. 이에 따라, 좌안의 홍채(각막), 그리고 우안의 홍 채(각막)을 제외한 영역에 대응되는 픽셀들의 픽셀값은 원래 픽셀값(original pixel value)으로 유지될 수 있으 나, 좌안의 홍채(또는 각막), 우안의 홍채(또는 각막)에 대응되는 픽셀들의 픽셀값은 제거되거나 다른 값으로 변경될 수 있다. 다만, 눈꺼풀 발적 예측방법을 수행함에 있어서, 홍채(각막)을 마스킹하는 전처리를 수행하는 것이 여러가지 측 면에서 장점이 있으나, 홍채의 마스킹을 하지 않아도 무방하다. 크롭 처리 상기 서버는 상기 마스킹된 얼굴 이미지를 크롭할 수 있다. 상기 서버는 상기 마스킹된 얼굴 이미지를 크롭하여 좌안 크롭 이미지 및 우안 크롭 이미지를 생성할 수 있다. 결막 충혈 예측 방법을 수행할 때, 상기 서 버는 전술한 2가지의 크롭 방법들 중 제3 크롭(눈꺼풀을 포함하는 크롭)방법을 사용할 수 있다. 제3 크롭 방법에 관해서는 이미 상세히 설명한 바 있으므로 여기서는 자세한 설명을 생략한다. 리사이징 처리 및 좌우 반전 처리 상기 서버는 상기 좌안 크롭 이미지 및 상기 우안 크롭 이미지의 크기를 미리 정해진 사이즈로 리사이징 할 수 있다. 한편, 상기 제4 예측모델을 이원화시키지 않고 하나의 모델로 구현한 경우, 상기 서버는 상기 좌안 크롭 이 미지 및 상기 우안 크롭 이미지 중 하나를 전술한 바와 같이 좌우 반전시킬 수 있다. 상기 서버는 상기 좌 안 크롭 이미지 및 상기 우안 크롭 이미지 중 다른 하나는 좌우 반전시키지 않는다. 이때, 좌안 이미지와 좌안 이미지 중 어느 이미지를 좌우반전시킬지를 결정하는 기준은 상기 제4 예측모델을 학습시킬 때 적용하였던 기준 과 동일한 기준으로 결정한다. 즉, 제4 예측 모델을 학습시킬 때, 좌안 이미지를 반전시키고 우안 이미지를 반전시키지 않은 경우, 이와 동일하게 상기 서버는 좌안 이미지를 반전시키고 우안 이미지를 반전시키지 않는 다. 만약, 전술한 바와 같이, 제4 예측모델을 구현함에 있어서, 제4 좌안 예측모델 및 제4 우안 예측모델로 이원화 한 경우, 상기 서버는 좌우 반전 처리를 수행하지 않을 수 있다. 한편, 전처리를 수행함에 있어서, 세그멘테이션, 마스킹 처리, 크롭 처리, 리사이징 처리, 좌우 반전 처리를 하 는 것으로 설명하였으나, 각 전처리들의 순서는 본 출원에 의해 개시되는 눈꺼풀 발적 예측방법의 목적을 달성 할 수 있는 범위 내에서 변경될 수 있다. 전처리된 이미지의 입력 상기 서버는 상기 전처리된 이미지를 상기 제1 예측모델에 입력할 수 있다(S420). 상기 서버는, 상기 제4 예측모델을 이원화시키지 않고 하나의 모델로 구현한 경우, 상기 우안 전처리 이미 지 및 좌우 반전된 좌안 전처리 이미지를 순차적으로 상기 제4 예측모델에 입력한다. 만약, 제4 예측모델을 구현함에 있어서 제4 좌안 예측모델 및 제4 우안 예측모델로 이원화한 경우, 상기 서버 는 상기 좌안 전처리 이미지를 상기 제4 좌안 예측모델에 입력하고, 상기 우안 전처리 이미지를 상기 제4 우안 예측모델에 입력한다. 또는 상기 서버는 상기 좌안 전처리 이미지를 상기 제4 좌안 예측모델에 입력하 고, 상기 좌우 반전된 좌안 전처리 이미지를 상기 제4 우안 예측모델에 입력하고, 상기 우안 전처리 이미지를 상기 제4 우안 예측모델에 입력하고, 상기 좌우 반전된 우안 전처리 이미지를 상기 제4 좌안 예측모델에 입력할 수 있다. 만약, 제4 예측모델을 구현함에 있어서, 제4 예측모델을 이원화시키지 않고 하나의 모델로 구현하면서 동시에 좌안 이미지와 우안 이미지를 구별하지 않고 결막의 충혈 여부를 판단할 수 있도록 학습된 경우, 상기 서버(2 0)는 상기 좌안 전처리 이미지 및 상기 우안 전처리 이미지를, 좌우반전 없이, 상기 제4 예측모델에 입력할 수 있다. 또는 상기 서버는 상기 좌안 전처리 이미지, 상기 좌우 반전된 좌안 전처리 이미지, 상기 우안 전처 리 이미지 및 상기 좌우 반전된 우안 전처리 이미지를 상기 제4 예측모델에 입력할 수 있다. 눈꺼풀 발적 예측 결과 상기 서버는 상기 제4 예측모델로부터 출력되는 결과값을 획득할 수 있다(S430). 상기 결과값은 이미지에 캡쳐된 눈꺼풀에 발적이 있을 예측되는 확률값일 수 있다. 상기 서버는 미리 정해진 쓰레숄드값(threshold value)을 기준으로 상기 예측되는 확률값이 상기 쓰레숄드값 이상이면 눈꺼풀에 발적이 있는 것으로 판단하고, 상기 예측되는 확률값이 상기 쓰레숄드값 미만이면 눈꺼풀에 발적이 있지 않은 것으로 판단할 수 있다. 상기 서버는 좌안에 대한 예측결과와 우안에 대한 예측 결과를 모두 획득할 수 있다. 만약, 상기 서버가 상기 좌안 전처리 이미지를 상기 제4 좌안 예측모델에 입력하고, 상기 좌우 반전된 좌안 전처리 이미지를 상기 제4 우안 예측모델에 입력하고, 상기 우안 전처리 이미지를 상기 제4 우안 예측모델에 입 력하고, 상기 좌우 반전된 우안 전처리 이미지를 상기 제4 좌안 예측모델에 입력한 경우, 상기 서버는 상기 좌안 전처리 이미지를 상기 제4 좌안 예측모델에 입력하여 획득한 결과와 상기 좌우 반전된 좌안 전처리 이미지 를 상기 제4 우안 예측모델에 입력하여 획득한 결과를 모두 고려하여 상기 좌안에 대한 예측 결과를 획득할 수 있다. 이때, 상기 서버는 상기 우안 전처리 이미지를 상기 제4 우안 예측모델에 입력하여 획득한 결과와 상 기 좌우 반전된 우안 전처리 이미지를 상기 제4 좌안 예측모델에 입력하여 획득한 결과를 모두 고려하여 상기 우안에 대한 예측 결과를 획득할 수 있다. 예를 들어, 상기 서버는 상기 좌안 전처리 이미지를 상기 제4 좌안 예측모델에 입력하여 획득한 결과와 상 기 좌우 반전된 좌안 전처리 이미지를 상기 제4 우안 예측모델에 입력하여 획득한 결과의 평균값이 상기 쓰레숄 드값 이상인지 여부에 기초하여 상기 좌안에 대한 예측 결과를 획득할 수 있다. 다른 예를 들어, 상기 서버는 상기 좌안 전처리 이미지를 상기 제4 좌안 예측모델에 입력하여 획득한 결과 와 상기 좌우 반전된 좌안 전처리 이미지를 상기 제4 우안 예측모델에 입력하여 획득한 결과 중 어느 하나의 값 이 전술한 쓰레숄드값 이상인 경우, 상기 좌안의 결막이 충혈되었다고 예측할 수 있다. 또 다른 예를 들어, 상기 서버는 상기 좌안 전처리 이미지를 상기 제4 좌안 예측모델에 입력하여 획득한 결 과와 상기 좌우 반전된 좌안 전처리 이미지를 상기 제4 우안 예측모델에 입력하여 획득한 결과 모두가 전술한 쓰레숄드값 이상인 경우, 상기 좌안의 결막이 충혈되었다고 예측할 수 있다.만약, 상기 서버는 상기 좌안 전처리 이미지, 상기 좌우 반전된 좌안 전처리 이미지, 상기 우안 전처리 이 미지 및 상기 좌우 반전된 우안 전처리 이미지를 이원화되지 않은 상기 제4 예측모델에 입력한 경우, 상기 서버 는 상기 좌안 전처리 이미지를 상기 제4 예측모델에 입력하여 획득한 결과와 상기 좌우 반전된 좌안 전처리 이미지를 상기 제4 예측모델에 입력하여 획득한 결과를 모두 고려하여 상기 좌안에 대한 예측 결과를 획득할 수 있다. 이때, 상기 서버는 상기 우안 전처리 이미지를 상기 제4 예측모델에 입력하여 획득한 결과와 상기 좌 우 반전된 우안 전처리 이미지를 상기 제4 예측모델에 입력하여 획득한 결과를 모두 고려하여 상기 우안에 대한 예측 결과를 획득할 수 있다. 예를 들어, 상기 서버는 상기 좌안 전처리 이미지를 상기 제4 예측모델에 입력하여 획득한 결과와 상기 좌 우 반전된 좌안 전처리 이미지를 상기 제4 예측모델에 입력하여 획득한 결과의 평균값이 상기 쓰레숄드값 이상 인지 여부에 기초하여 상기 좌안에 대한 예측 결과를 획득할 수 있다. 다른 예를 들어, 상기 서버는 상기 좌안 전처리 이미지를 상기 제4 예측모델에 입력하여 획득한 결과와 상 기 좌우 반전된 좌안 전처리 이미지를 상기 제4 예측모델에 입력하여 획득한 결과 중 어느 하나의 값이 전술한 쓰레숄드값 이상인 경우, 상기 좌안의 눈꺼풀에 발적이 있다고 예측할 수 있다. 또 다른 예를 들어, 상기 서버는 상기 좌안 전처리 이미지를 상기 제4 예측모델에 입력하여 획득한 결과와 상기 좌우 반전된 좌안 전처리 이미지를 상기 제4 예측모델에 입력하여 획득한 결과 모두가 전술한 쓰레숄드값 이상인 경우, 상기 좌안의 눈꺼풀에 발적이 있다고 예측할 수 있다. 전술한 방식은 우안의 눈꺼풀 발적 여부를 판단하는 데에도 유사하게 적용될 수 있다. 9. 눈꺼풀 부종 예측방법 본 출원에 의해 개시되는 눈꺼풀 부종 예측 방법은 서버에 의해 수행될 수 있다. 도 27는 눈꺼풀 부종 예측 방법을 설명하기 위한 흐름도이다. 도 27을 참고하면, 서버는 얼굴 이미지를 획득하고(S500), 상기 획득된 얼굴 이미지를 전처리하고(S510), 상기 전처리된 이미지를 전술한 제5 예측모델(눈꺼풀 부종 예측모델)에 입력하고(S520), 상기 제5 예측모델의 출력값을 획득한다(S530). 상기 눈꺼풀 부종 예측방법은 제4 예측모델 대신 제5 예측모델을 사용한다는 점, 그리고 최종적으로 획득되는 결과값이 눈꺼풀에 부종이 있는지 여부에 대한 예측값이라는 점을 제외하면, 눈꺼풀 발적 예측방법과 동일하거 나 매우 유사하기 때문에, 자세한 설명은 생략하기로 한다. 전술한 바와 같이, 눈꺼풀 발적 예측방법 및 눈꺼풀 부종 예측방법에서 사용되는 이미지의 전처리 방법은 서로 동일하고, 다만 전처리된 이미지가 입력되는 예측모델들이 서로 다를 뿐이다. 따라서, 전술한 바와 같은 이미지 전처리를 한 후, 그 이미지가 서로 다른 예측모델들에 입력될 수 있다. 10. 갑상선 안병증에 관한 임상활동점수 예측방법 이하에서는, 본 출원에 의해 개시되는 갑상선 안병증에 관한 임상활동점수의 예측방법에 대해 설명한다. 도 28은 갑상선 안병증에 관한 임상활동점수의 예측방법을 설명하기 위한 도면이다. 서버는 얼굴 이미지를 획득할 수 있다. 서버는 하나의 얼굴 이미지에 대해 2가지의 서로 다른 전처리를 수행한다. 첫번째 전처리(이하, 제1 전처리)는 홍채 세그멘테이션, 눈 아웃라인 세그멘테이션, 제1 마스킹, 제2 크롭(눈 아웃라인 크롭), 리사이징 및 좌우 반전하는 것을 포함하며, 두번째 전처리(이하, 제2 전처리)는 홍채 세그멘테이션, 눈 아웃라인 세그멘 테이션, 제2 마스킹, 제3 크롭(눈꺼풀 포함 크롭), 리사이징 및 좌우 반전하는 것을 포함한다. 다만, 눈꺼풀 발 적 예측방법에서 설명한 바와 같이, 홍채 세그멘테이션 및 제2 마스킹은 생략될 수 있다. 서버는 상기 획득된 얼굴 이미지에 대해 제1 전처리를 수행하여 제1 전처리 이미지를 획득하며, 상기 제1 전처리 이미지는 제1 좌안 전처리 이미지 및 제1 우안 전처리 이미지를 포함한다. 이 때, 제1 좌안 전처리 이미 지 및 제1 우안 전처리 이미지 중 하나는 좌우반전처리된 이미지이다. 또한, 이미 상세하게 설명한 바와 같이, 상기 제1 전처리 이미지는 제2 크롭을 이용하여 획득되는 이미지이기 때문에, 상기 제1 전처리 이미지 내에서 눈꺼풀에 대응되는 픽셀들의 수는 최소화되어 있고 외부로 노출된 결막 및 눈물언덕에 대응되는 픽셀들이 포함 되어 있다. 또한, 상기 제1 전처리 이미지는 제1 마스킹을 이용하여 획득되는 이미지이기 때문에, 홍채(또는 각막) 및 눈꺼풀(상안검, 하안검)에 대응되는 픽셀들의 픽셀값은 제거되어 있으나, 외부로 노출된 결막 및 눈물언 덕에 대응되는 픽셀들의 픽셀값은 유지되어 있다. 또한, 서버는 상기 획득된 얼굴 이미지에 대해 제2 전처리를 수행하여 제2 전처리 이미지를 획득하며, 상기 제2 전처리 이미지는 제2 좌안 전처리 이미지 및 제2 우안 전처리 이미지를 포함한다. 이 때, 상기 제1 좌안 전 처리 이미지 및 제2 우안 전처리 이미지 중 하나는 좌우반전처리된 이미지이다. 또한, 이미 상세하게 설명한 바 와 같이, 상기 제2 전처리 이미지는 제3 크롭을 이용하여 획득되는 이미지이기 때문에, 상기 제2 전처리 이미지 는 눈꺼풀에 대응되는 픽셀들을 충분히 포함하고 있다. 또한, 상기 제2 전처리 이미지를 획득할 때, 제2 마스킹 방법이 이용된 경우, 홍채(또는 각막) 및 눈꺼풀(상안검, 하안검)에 대응되는 픽셀들의 픽셀값은 제거되어있을 수 있다. 서버는 상기 제1 전처리 이미지(제1 좌안 전처리 이미지 및 제1 우안 전처리 이미지)를 제1 예측모델에 순 차적으로 입력한다. 서버는 제1 좌안 전처리 이미지에 대한 제1 예측모델의 결과값(확률값)을 획득하고, 그 에 기초하여 왼쪽 눈에 대한 결막 충혈 여부에 대해서 판단한다. 아울러, 서버는 제1 우안 전처리 이미지에 대한 제1 예측모델의 결과값(확률값)을 획득하고, 그에 기초하여 오른쪽 눈에 대한 결막 충혈 여부에 대해서 판 단한다. 서버는 왼쪽 눈에 대한 판단결과와 오른쪽 눈에 대한 판단결과를 종합하여, 최종적으로 양쪽 눈에 대한 결 막 충혈여부를 판단한다. 예를 들어, 왼쪽 눈과 오른쪽 눈 중 하나 이상에 대해 결막 충혈이 있다고 판단된 경 우, 서버는 최종적으로 결막 충혈이 있다고 판단한다. 이어서, 서버는 서버는 상기 제1 전처리 이미지(제1 좌안 전처리 이미지 및 제1 우안 전처리 이미지)를 제2 예측모델에 순차적으로 입력한다. 서버는 제1 좌안 전처리 이미지에 대한 제2 예측모델의 결과값(확률 값)을 획득하고, 그에 기초하여 왼쪽 눈에 대한 결막 부종 여부에 대해서 판단한다. 아울러, 서버는 제1 우 안 전처리 이미지에 대한 제2 예측모델의 결과값(확률값)을 획득하고, 그에 기초하여 오른쪽 눈에 대한 결막 부 종 여부에 대해서 판단한다. 서버는 왼쪽 눈에 대한 판단결과와 오른쪽 눈에 대한 판단결과를 종합하여, 최종적으로 양쪽 눈에 대한 결 막 부종 여부를 판단한다. 예를 들어, 왼쪽 눈과 오른쪽 눈 중 하나 이상에 대해 결막 부종이 있다고 판단된 경 우, 서버는 최종적으로 결막 부종이 있다고 판단한다. 계속하여, 서버는 서버는 상기 제1 전처리 이미지(제1 좌안 전처리 이미지 및 제1 우안 전처리 이미 지)를 제3 예측모델에 순차적으로 입력한다. 서버는 제1 좌안 전처리 이미지에 대한 제3 예측모델의 결과값 (확률값)을 획득하고, 그에 기초하여 왼쪽 눈에 대한 눈물언덕 부종 여부에 대해서 판단한다. 아울러, 서버(2 0)는 제1 우안 전처리 이미지에 대한 제3 예측모델의 결과값(확률값)을 획득하고, 그에 기초하여 오른쪽 눈에 대한 눈물언덕 부종 여부에 대해서 판단한다. 서버는 왼쪽 눈에 대한 판단결과와 오른쪽 눈에 대한 판단결과를 종합하여, 최종적으로 양쪽 눈에 대한 눈 물언덕 부종 여부를 판단한다. 예를 들어, 왼쪽 눈과 오른쪽 눈 중 하나 이상에 대해 눈물언덕 부종이 있다고 판단된 경우, 서버는 최종적으로 눈물언덕 부종이 있다고 판단한다. 서버는 상기 제2 전처리 이미지(제2 좌안 전처리 이미지 및 제2 우안 전처리 이미지)를 제4 예측모델에 순 차적으로 입력한다. 서버는 제2 좌안 전처리 이미지에 대한 제4 예측모델의 결과값(확률값)을 획득하고, 그 에 기초하여 왼쪽 눈에 대한 눈꺼풀 발적 여부에 대해서 판단한다. 아울러, 서버는 제2 우안 전처리 이미지 에 대한 제4 예측모델의 결과값(확률값)을 획득하고, 그에 기초하여 오른쪽 눈에 대한 눈꺼풀 발적 여부에 대해 서 판단한다. 서버는 왼쪽 눈에 대한 판단결과와 오른쪽 눈에 대한 판단결과를 종합하여, 최종적으로 양쪽 눈에 대한 눈 꺼풀 발적 여부를 판단한다. 예를 들어, 왼쪽 눈과 오른쪽 눈 중 하나 이상에 대해 눈꺼풀 발적이 있다고 판단 된 경우, 서버는 최종적으로 눈꺼풀 발적이 있다고 판단한다. 서버는 상기 제2 전처리 이미지(제2 좌안 전처리 이미지 및 제2 우안 전처리 이미지)를 제5 예측모델에 순 차적으로 입력한다. 서버는 제2 좌안 전처리 이미지에 대한 제5 예측모델의 결과값(확률값)을 획득하고, 그 에 기초하여 왼쪽 눈에 대한 눈꺼풀 부종 여부에 대해서 판단한다. 아울러, 서버는 제2 우안 전처리 이미지 에 대한 제5 예측모델의 결과값(확률값)을 획득하고, 그에 기초하여 오른쪽 눈에 대한 눈꺼풀 부종 여부에 대해 서 판단한다.서버는 왼쪽 눈에 대한 판단결과와 오른쪽 눈에 대한 판단결과를 종합하여, 최종적으로 양쪽 눈에 대한 눈 꺼풀 부종 여부를 판단한다. 예를 들어, 왼쪽 눈과 오른쪽 눈 중 하나 이상에 대해 눈꺼풀 부종이 있다고 판단 된 경우, 서버는 최종적으로 눈꺼풀 부종이 있다고 판단한다. 서버는 예측모델에 의해서 증상이 있다고 판단된 경우에는, 해당 증상에 대해 미리 정해진 점수(예를 들어, 1점)을 부여할 수 있고, 서버는 5개의 예측모델들에 대한 판단 결과에 따라 5가지 증상 각각에 대한 점수를 부 여할 수 있고, 또한 이 점수들을 모두 더한 값을 획득할 수 있다. 전술한 본 출원에 의해 개시되는 갑상선 안병증 임상활동점수 예측방법은 서버에 의해서 수행되는 것으로 설명하였다. 그러나, 전술한 방법은 사용자 단말기에서 수행될 수도 있다. 또는 전술한 방법들 중 전처리는 사용자 단말기에서 수행되고 각 증상들에 대한 판단은 서버에 의해 수행될 수도 있다. 즉, 전술한 단계들은 사용자 단말기와 서버에 적절하게 분산되어 실시될 수 있다. 11. 갑상선 안병증에 관한 임상활동점수의 지속적인 모니터링에 기초한 병원 방문 추천 방법 이하에서는, 본 출원에 의해 개시되는 갑상선 안병증에 관한 임상활동점수의 지속적인 모니터링 방법 및 이에 기초한 병원 방문 추천 방법에 대해 설명한다. 도 29는 본 출원에 의해 개시되는 갑상선 안병증에 관한 임상활동점수의 지속적인 모니터링 방법 및 이에 기초 한 병원 방문 추천 방법을 설명하기 위한 도면이다. 사용자 단말기는 디스플레이를 통해 얼굴 이미지 획득을 위한 가이드를 출력할 수 있다(S600). 사용자 단말기는 카메라를 통해 실시간으로 캡쳐되는 이미지(예를 들어, 사용자의 얼굴을 반영하는 이 미지)를 상기 디스플레이를 통해 출력할 수 있으며, 이때 상기 가이드를 함께 출력할 수 있다. 사용자 단말기는 카메라를 통해 사용자의 얼굴에 대한 얼굴 이미지를 획득할 수 있다(S610). 사용자 단말기는 상기 획득된 얼굴 이미지를 상기 서버로 전송할 수 있다(S620). 사용자 단말기는 갑상선 안병증에 대한 임상활동점수를 판단함에 있어서 고려되는 총 7가지의 항목들 중 구 후부의 자발적인 통증 (Spontaneous retrobulbar pain) 및 안구운동 시 통증 (Pain on attempted upward or downward gaze)에 대한 사용자 입력을 받기 위한 그래피컬 유저 인터페이스(graphical user interface, GUI)를 상기 디스플레이를 통해 출력할 수 있다. 이어서, 사용자 단말기는 상기 2가지 항목에 대한 사용자의 응답 을 입력받을 수 있다(S630). 사용자 단말기는 상기 입력된 사용자의 응답에 기초하여, 각 항목들에 대해 미 리 정해진 점수(예를 들어, 1점)을 부여할 수 있다. 예를 들어, 사용자가 구후부의 자발적인 통증이 있다고 입 력한 경우, 상기 사용자 단말기는 해당 항목에 대해 1점을 부여할 수 있으며, 또한 사용자가 안구운동 시 통증이 있다고 입력한 경우, 상기 사용자 단말기는 해당 항목에 대해 1점을 부여할 수 있다. 사용자 단말기는 상기 획득된 얼굴 이미지에 기초하여, 갑상선 안병증에 대한 임상활동점수를 판단함에 있 어서 고려되는 총 7가지의 항목들 중 결막의 충혈 (Redness of conjunctiva), 결막의 부종 (Swelling of conjunctiva), 눈물언덕의 부종 (Swelling of lacrimal caruncle), 눈꺼풀의 발적 (Redness of eyelid) 및 눈 꺼풀의 부종 (Swelling of eyelid)에 대한 판단결과 또는 이들에 대한 합산 점수를 상기 서버로부터 수신할 수 있다(S640). 사용자 단말기는 사용자 입력에 의해 결정된 점수와 서버로부터 수신한 점수 또는 서버로부터 수신한 판단결과에 기초하여 결정된 점수에 기초하여, 최종적인 갑상선 안병증에 대한 임상활동점수를 산출할 수 있다 (S650). 사용자 단말기는 상기 사용자의 얼굴 이미지를 획득한 시각 또는 상기 최종적인 갑상선 안병증에 대한 임상 활동점수의 산출값이 획득된 시각 또는 이에 준하는 시각(이하, 측정 시각, yy/mm/dd, hh:mm)을 상기 산출된 임 상활동점수와 함께 메모리에 저장할 수 있다. 또는 사용자 단말기는 전술한 측정 시각과 그에 대응되 는 임상활동점수를 상기 서버에 전송할 수 있다. 이때, 서버는 상기 측정 시각 및 임상활동점수를 상기 사용자 단말기 또는 상기 사용자에 대응하여 저장할 수 있다(S660). 한편, 상기 측정 시각은 일자(date)에 대한 정보를 포함한다. 상기 측정 시각은 일자(date)에 대한 정보와 시 (hour) 및/또는 분(minute)에 관한 정보를 모두 가지고 있을 수도 있고, 상기 측정 시각은 일자(date)에 대한 정보만을 가지고 있고, 시(hour) 또는 분(minute)에 관한 정보는 포함하고 있지 않을 수도 있다.사용자 단말기는 상기 산출된 임상활동점수에 기초하여, 사용자에게 병원 방문 및 정밀 검진을 받을 것을 추천하는 정보를 상기 디스플레이를 통해 출력할 수 있다(S670). 사용자 단말기는 상기 산출된 임상활동점수가 3점 미만인 경우에는, 갑상선 안병증에 대한 위험이 없다는 취지의 정보를 상기 디스플레이를 통해 출력할 수 있다. 사용자 단말기는 상기 산출된 임상활동점수가 3점 또는 4점인 경우에는, 선택적으로 갑상선 안병증에 대한 위험이 없다는 취지의 정보를 상기 디스플레이를 통해 출력하거나 또는 사용자에게 병원 방문 및 정밀 검 진을 받을 것을 추천하는 정보를 상기 디스플레이를 통해 출력할 수 있다. 사용자 단말기는 상기 산출된 임상활동점수가 5점이상인 경우에는, 사용자에게 병원 방문 및 정밀 검진을 받을 것을 추천하는 정보를 상기 디스플레이를 통해 출력할 수 있다. 상기 산출된 임상활동점수가 3점 또는 4점인 경우에는, 해당 시점을 기준으로 미리 정해진 기간(예를 들어, 1주 일) 이전에 측정된 임상활동점수를 확인하고, 해당 구간(이하, 모니터링 구간) 동안 임상활동점수가 3점 또는 4 점이었던 적이 있는지 여부가 확인될 수 있다. 이때, 만약 모니터링 구간 동안 3점 또는 4점이었던 적이 한번 이상인 경우, 사용자 단말기는 사용자에게 병원 방문 및 정밀 검진을 받을 것을 추천하는 정보를 상기 디스 플레이를 통해 출력하며, 모니터링 구간 동안 3점 또는 4점이었던 적이 없는 경우, 사용자 단말기는 갑상선 안병증에 대한 위험이 없다는 취지의 정보를 상기 디스플레이를 통해 출력한다. 다만, 사용자 단말기는 상기 산출된 임상활동점수가 3점 이상인 경우에는, 과거 이력에 대한 추가 판단 없 이, 사용자에게 병원 방문 및 정밀 검진을 받을 것을 추천하는 정보를 상기 디스플레이를 통해 출력할 수 있다. 전술한 바에 의하면, 상기 사용자 단말기를 통해 사용자에게 정보를 출력함에 있어서, 디스플레이를 통해 시각적으로 정보를 출력하는 것을 예시하여 설명하였으나, 경우에 따라서 상기 정보는 스피커 등을 통해 청각적으로 출력될 수 있다. 아울러, 전술한 본 출원에 의해 개시되는 갑상선 안병증에 관한 임상활동점수의 지속적인 모니터링 방법 및 이 에 기초한 병원 방문 추천 방법은 사용자 단말기에 의해서 수행되는 것으로 설명하였다. 그러나, 전술한 방 법의 각 단계들은 사용자 단말기와 서버에 적절하게 분산되어 실시될 수 있다. 예를 들어, 측정 시각 및 임상활동점수가 서버에 전송되어 저장되어 있는 경우, 모니터링 구간에 3점 또는 4점이 있었는지 여부를 판단하는 것은 서버에 의해 수행될 수 있다. 12. 실험예 #1 얼굴 이미지의 준비 1,020 장의 얼굴 이미지를 준비하였다. 얼굴 이미지 각각은 좌안과 우안을 모두 포함하는 이미지이며, 미리 정 해진 촬영 구도에 따라서 촬영된 이미지이다. 얼굴 이미지에 대한 라벨링 정보 확보 1,020 장의 얼굴 이미지 각각에 대하여, 좌안에 대한 결막 충혈, 결막 부종, 눈물언덕 부종, 눈꺼풀 발적 및 눈 꺼풀 부종에 대한 정보 및 우안에 대한 결막 충혈, 결막 부종, 눈물언덕 부종, 눈꺼풀 발적 및 눈꺼풀 부종에 대한 정보를 확보하였고, 이 데이터들을 라벨링 데이터로 활용하였다. 1,020개의 데이터세트들 중 714개를 학습데이터 세트(training set)로, 102개를 밸리데이션 세트(validation set)로, 204개를 검증 세트(test set)로 사용하였다. 또한, 1,020개를 학습데이터 세트, 밸리데이션 세트, 검증 세트로 나누는 것을 랜덤하게 30번을 수행하였으며, 이에 따라, 제1 학습데이터 세트 그룹 내지 제30 학습데이터 세트 그룹이 생성되었다. 얼굴 이미지에 대한 제1 전처리 이미지 및 제2 전처리 이미지 확보 1,020 장의 얼굴 이미지 각각에 대하여, 좌안과 우안 각각에 대하여 전술한 방식으로 제1 크롭 처리(눈 아웃라 인 크롭)를 하여, 제1 좌안 전처리 이미지 및 제1 우안 전처리 이미지를 확보하였다. 이때, 제1 우안 전처리 이 미지는 좌우반전된 이미지를 사용하였고, 제1 좌안 전처리 이미지는 좌우반전되지 않은 이미지를 사용하였다. 한편, 이때 제1 좌안 전처리 이미지 및 제1 우안 전처리 이미지는 모두 전술한 제1 마스킹 처리를 한 이미지들 이었다.1,020 장의 얼굴 이미지 각각에 대하여, 좌안과 우안 각각에 대하여 전술한 방식으로 제2 크롭 처리(눈꺼풀 포 함 크롭)를 하여, 제2 좌안 전처리 이미지 및 제2 우안 전처리 이미지를 확보하였다. 이때, 제2 우안 전처리 이 미지는 좌우반전된 이미지를 사용하였고, 제2 좌안 전처리 이미지는 좌우반전되지 않은 이미지를 사용하였다. 한편, 이때 제2 좌안 전처리 이미지 및 제2 우안 전처리 이미지는 모두 마스킹처리를 하지 않은 이미지들이었다. 실험예 #1에 따른 제1 내지 제5 예측모델들의 학습 확보된 제1 전처리 이미지들 및 이들에 대해 확보된 라벨링 정보들, 그리고 확보된 제2 전처리 이미지들 및 이 들에 대해 확보된 라벨링 정보들을 이용하여 제1 내지 제5예측모델들의 학습을 수행하였다. 예측모델은 전술한 ViT을 백본 아키텍쳐로 사용한 모델을 사용하였으며, 각 예측모델들은 좌안 예측모델과 우안 예측모델을 분리하지 않고 하나의 모델로 일원화하여 학습시켰다. 예측모델들을 이용한 각 증상에 대한 예측 결과의 획득 학습된 제1 내지 제5 예측모델들에 대해 검증 데이터 세트들을 이용하여 예측 결과를 획득하였다. 이때, 우안 이미지는 좌우반전 시킨 전처리 이미지를 사용하였고, 좌안 이미지는 좌우반전되지 않은 전처리 이미지를 사용 하였다. 실험예 #1에 따른 눈꺼풀 발적 예측모델의 정확도, 민감도(Sensitivity), 특이도(Specificity), 양성 예측 도(Positive Predictive Value, PPV) 및 음성 예측도(Negative Predictive Value, NPV) [표1]에 나타낸 값들은 전술한 실험예 #1에 따라 30개의 데이터세트 그룹들 각각에 대해 학습한 제1 내지 제5 예측모델들에 대해 측정된 정확도, 민감도, 특이도, PPV, NPV의 평균값들이다. 표 1 정확도(%)민감도(%) 특이도(%) PPV(%) NPV(%) 결막 충혈 (제1 예측 모델)80.80 86.84 76.40 73.58 89.10 결막 부종 (제2 예측모델)89.12 42.18 94.82 50.39 93.15 눈물언덕 부종 (제3 예측모델)88.14 55.54 92.52 53.14 93.96 눈꺼풀 발적 (제4 예측모델)72.42 73.94 71.55 59.10 84.17 눈꺼풀 부종 (제5 예측모델)81.29 86.38 53.52 91.16 43.59 13. 실험예 #2 얼굴 이미지의 준비 실험예 #1에서 사용한 얼굴 이미지를 그대로 사용하였다. 얼굴 이미지에 대한 라벨링 정보 확보 실험예 #1에서 사용한 얼굴 이미지에 대한 라벨링 정보들을 그대로 활용하였다. 얼굴 이미지에 대한 제1 전처리 이미지 및 제2 전처리 이미지 확보 1,020 장의 얼굴 이미지 각각에 대하여, 좌안과 우안 각각에 대하여 전술한 방식으로 제1 크롭 처리(눈 아웃라 인 크롭)를 하여, 제1 전처리 이미지들을 확보하였다. 실험예 #1과 달리, 좌우반전 되지 않은 제1 좌안 전처리 이미지, 좌우반전된 제1 좌안 전처리 이미지, 좌우반전 되지 않은 제1 우안 전처리 이미지 및 좌우반전된 제1 우안 전처리 이미지를 모두 확보하고, 이들을 학습하는 데에 사용하였다. 이때 제1 좌안 전처리 이미지 및 제1 우안 전처리 이미지는 모두 전술한 제1 마스킹 처리를 한 이미지들이었다. 1,020 장의 얼굴 이미지 각각에 대하여, 좌안과 우안 각각에 대하여 전술한 방식으로 제2 크롭 처리(눈꺼풀 포 함 크롭)를 하여, 제2 전처리 이미지들을 확보하였다. 실험예 #1과 달리, 좌우반전 되지 않은 제2 좌안 전처리이미지, 좌우반전된 제2 좌안 전처리 이미지, 좌우반전 되지 않은 제2 우안 전처리 이미지 및 좌우반전된 제2 우안 전처리 이미지를 모두 확보하고, 이들을 학습하는 데에 사용하였다. 이때 제2 좌안 전처리 이미지 및 제2 우안 전처리 이미지는 모두 마스킹처리를 하지 않은 이미지들이었다. 실험예 #2에 따른 제1 내지 제5 예측모델들의 학습 확보된 제1 전처리 이미지들 및 이들에 대해 확보된 라벨링 정보들, 그리고 확보된 제2 전처리 이미지들 및 이 들에 대해 확보된 라벨링 정보들을 이용하여 제1 내지 제5예측모델들의 학습을 수행하였다. 예측모델은 전술한 ViT을 백본 아키텍쳐로 사용한 모델을 사용하였으며, 각 예측모델들은 좌안 예측모델과 우안 예측모델로 이원화 하여 학습시켰다. 특히, 좌안 예측모델들을 학습시킬 때, 좌우반전되지 않은 좌안 전처리 이 미지와 좌우반전된 우안 전처리 이미지를 사용하였고, 우안 예측모델들을 학습시킬 때, 좌우반전되지 않은 우안 전처리 이미지와 좌우반전된 좌안 전처리 이미지를 사용하였다. 예측모델들을 이용한 각 증상에 대한 예측 결과의 획득 학습된 제1 내지 제5 예측모델들에 대해 검증 데이터 세트들을 이용하여 예측 결과를 획득하였다. 이때, 우안에 대한 예측 결과는 각 우안 예측모델들에 좌우반전 하지 않은 우안 전처리 이미지를 입력하여 획득하였고, 좌안 에 대한 예측 결과는 각 좌안 예측모델들에 좌우반전하지 않은 좌안 전처리 이미지를 입력하여 획득하였다. 실험예 #2에 따른 눈꺼풀 발적 예측모델의 정확도, 민감도(Sensitivity), 특이도(Specificity), 양성 예측 도(Positive Predictive Value, PPV) 및 음성 예측도(Negative Predictive Value, NPV) [표2]에 나타낸 값들은 전술한 실험예 #2에 따라 30개의 데이터세트 그룹들 각각에 대해 학습한 제1 내지 제5 예측모델들에 대해 측정된 정확도, 민감도, 특이도, PPV, NPV의 평균값들이다. 표 2 정확도(%)민감도(%) 특이도(%) PPV(%) NPV(%) 결막 충혈 (제1 예측 모델)79.54 87.26 73.99 71.84 89.19 결막 부종 (제2 예측모델)89.22 45.04 94.61 52.53 93.48 눈물언덕 부종 (제3 예측모델)88.35 49.51 93.70 55.48 93.20 눈꺼풀 발적 (제4 예측모델)76.13 70.65 79.08 64.63 83.86 눈꺼풀 부종 (제5 예측모델)81.47 86.51 54.44 91.22 44.62"}
{"patent_id": "10-2022-0171082", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 출원에 의해 개시되는 일실시예에 따른 갑상선 안병증에 관한 임상활동점수를 예측하기 위한 시스템 을 도시하는 도면이다. 도 2는 본 출원에 의해 제공되는 사용자 단말기의 블록도이다. 도 3은 본 출원에 의해 개시되는 서버의 블록도이다. 도 4는 카메라를 이용하여 얼굴을 촬영하였을 때 카메라에 의해 캡쳐될 수 있도록 외부로 노출되어 있는 눈 및 그 주변 조직을 설명하기 위한 도면이다. 도 5는 외부로 노출된 안구를 설명하기 위한 도면이다. 도 6은 눈의 아웃라인을 설명하기 위한 도면이다. 도 7은 외부로 노출된 각막을 설명하기 위한 도면이다. 도 8은 외부로 노출된 결막을 설명하기 위한 도면이다. 도 9는 얼굴 이미지와 양안 이미지를 설명하기 위한 도면이다. 도 10은 좌안 이미지와 우안 이미지를 설명하기 위한 도면이다. 도 11은 아웃라인 픽셀들의 Xmax, Xmin, Ymax, Ymin을 도식화한 도면이다. 도 12는 결정된 제2 크롭 영역을 도시한 도면이다. 도 13는 제2 크롭 이미지에 대한 예시적인 도면이다. 도 14는 제3 크롭 이미지에 대한 예시적인 도면이다. 도 15 및 도 16은 홍채 세그멘테이션을 설명하기 위한 도면들이다. 도 17은 눈 아웃라인 세그멘테이션을 설명하기 위한 도면이다. 도 18은 제1 마스킹 이미지에 대한 예시적인 도면이다. 도 19는 제2 마스킹 이미지에 대한 예시적인 도면이다. 도 20 내지 도 22는 원본 이미지와 좌우 반전 이미지의 다양한 예시를 도시하는 도면들이다. 도 23은 결막 충혈 예측 방법을 설명하기 위한 흐름도이다. 도 24는 결막 부종 예측 방법을 설명하기 위한 흐름도이다. 도 25는 눈물언덕 부종 예측 방법을 설명하기 위한 흐름도이다. 도 26은 눈꺼풀 발적 예측 방법을 설명하기 위한 흐름도이다. 도 27는 눈꺼풀 부종 예측 방법을 설명하기 위한 흐름도이다. 도 28은 갑상선 안병증에 관한 임상활동점수의 예측방법을 설명하기 위한 도면이다. 도 29는 갑상선 안병증에 관한 임상활동점수의 지속적인 모니터링 방법 및 이에 기초한 병원 방문 추천 방법을 설명하기 위한 도면이다."}
