{"patent_id": "10-2023-0101682", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0019743", "출원번호": "10-2023-0101682", "발명의 명칭": "지능형 교통 시스템에서 데이터를 처리하기 위한 전자장치 및 방법", "출원인": "팅크웨어", "발명자": "고석필"}}
{"patent_id": "10-2023-0101682", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "지능형 교통 시스템에서 데이터를 처리하는 서버 내의 전자 장치의 방법에 있어서,차량들로부터 자기 차량의 절대 좌표를 포함하는 자기 차량의 정보 및 상기 자기 차량이 인식한 외부 객체의 상대 좌표를 포함하는 외부 객체의 정보를 수신하는 단계; 및상기 수신한 정보들에 기초하여, 상기 차량들 각각의 절대 좌표를 포함하는 통합 객체 정보를 생성하는 단계를포함하는, 서버 내의 전자 장치의 방법."}
{"patent_id": "10-2023-0101682", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 자기 차량의 정보는, 상기 자기 차량의 번호판 정보를 포함하고,상기 외부 객체의 정보는, 상기 외부 객체가 차량이면 상기 외부 객체인 차량의 번호판 정보를 포함하는, 서버내의 전자 장치의 방법."}
{"patent_id": "10-2023-0101682", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서, 상기 통합 객체 정보를 생성하는 단계는, 복수 개의 차량들로부터 수신한, 상기 자기 차량의 번호판 정보 및 상기 외부 객체인 차량의 번호판 정보를 이용하여, 상기 차량들의 고유 식별자를 생성하는 단계; 및상기 생성된 고유 식별자를 갖는 차량들의 절대 좌표를 생성하는 단계를 포함하는, 서버 내의 전자 장치의방법."}
{"patent_id": "10-2023-0101682", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서,상기 자기 차량의 정보는, 상기 자기 차량의 주행 정보를 포함하며,상기 주행 정보는, 상기 자기 차량의 이동 방향, 속력, 차량 타입 중 적어도 하나를 포함하는, 서버 내의 전자장치의 방법."}
{"patent_id": "10-2023-0101682", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서, 상기 통합 객체 정보를 생성하는 단계는,상기 자기 차량의 주행 정보에 기초하여, 상기 고유 식별자를 갖는 차량들의 주행 정보를 생성하는 단계를 포함하는, 서버 내의 전자 장치의 방법."}
{"patent_id": "10-2023-0101682", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서, 상기 차량들은,상기 서버와 통신할 수 있는 복수 개의 통신 차량과, 상기 서버와 통신할 수 없는 적어도 하나의 비통신 차량을포함하는, 서버 내의 전자 장치의 방법."}
{"patent_id": "10-2023-0101682", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6항에 있어서, 상기 비통신 차량의 상기 절대 좌표는,상기 복수 개의 통신 차량들 중 적어도 두 개의 소정 개수의 통신 차량들로부터 수신한 상기 비통신 차량의 상기 상대 좌표에 기초하여 생성되는, 서버 내의 전자 장치의 방법.공개특허 10-2024-0019743-3-청구항 8 제7항에 있어서, 상기 소정 개수는,차량들의 평균 속도, 차량들의 밀집도 및 차량의 종류 중 적어도 하나에 기초하여 결정되는, 서버 내의 전자 장치의 방법."}
{"patent_id": "10-2023-0101682", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "지능형 교통 시스템에서 데이터를 처리하는 차량 내의 전자 장치의 방법에 있어서,상기 차량이 인식한 외부 객체의 상대 좌표를 획득하는 단계;상기 차량의 절대 좌표를 포함하는 자기 차량의 정보 및 상기 외부 객체의 상대 좌표를 포함하는 외부 객체의정보를 서버로 송신하는 단계; 및상기 송신된 정보에 기초하여 생성된 외부 차량들 각각의 절대 좌표를 포함하는 통합 객체 정보를 수신하는 단계를 포함하는, 차량 내의 전자 장치의 방법."}
{"patent_id": "10-2023-0101682", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9항에 있어서, 상기 자기 차량의 정보는, 상기 자기 차량의 번호판 정보를 포함하고,상기 외부 객체의 정보는, 상기 외부 객체가 차량이면 상기 외부 객체인 차량의 번호판 정보를 포함하는, 차량내의 전자 장치의 방법."}
{"patent_id": "10-2023-0101682", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제10항에 있어서, 상기 통합 객체 정보는, 복수 개의 차량들로부터 수신한, 상기 자기 차량의 번호판 정보 및 상기 외부 객체인 차량의 번호판 정보를 이용하여 생성된 상기 차량들의 고유 식별자를 갖는 차량들에 대해 생성되는 절대 좌표를 포함하는, 차량 내의 전자 장치의 방법."}
{"patent_id": "10-2023-0101682", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항에 있어서,상기 자기 차량의 정보는, 상기 자기 차량의 주행 정보를 포함하며,상기 주행 정보는, 상기 자기 차량의 이동 방향, 속력, 차량 타입 중 적어도 하나를 포함하는, 차량 내의 전자장치의 방법."}
{"patent_id": "10-2023-0101682", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제12항에 있어서, 상기 통합 객체 정보는,상기 자기 차량의 주행 정보에 기초하여, 상기 고유 식별자를 갖는 차량들에 생성되는 주행 정보를 포함하는,차량 내의 전자 장치의 방법."}
{"patent_id": "10-2023-0101682", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제9항에 있어서, 상기 외부 차량들은,상기 서버와 통신할 수 있는 복수 개의 통신 차량과, 상기 서버와 통신할 수 없는 적어도 하나의 비통신 차량을포함하는, 차량 내의 전자 장치의 방법."}
{"patent_id": "10-2023-0101682", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제14항에 있어서, 상기 비통신 차량의 상기 절대 좌표는,상기 복수 개의 통신 차량들 중 적어도 두 개 이상의 소정 개수의 통신 차량들로부터 수신한 상기 비통신 차량공개특허 10-2024-0019743-4-의 상기 상대 좌표에 기초하여 생성되는, 차량 내의 전자 장치의 방법."}
{"patent_id": "10-2023-0101682", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제15항에 있어서, 상기 소정 개수는,차량들의 평균 속도, 차량들의 밀집도 및 차량의 종류 중 적어도 하나에 기초하여 결정되는, 차량 내의 전자 장치의 방법."}
{"patent_id": "10-2023-0101682", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "지능형 교통 시스템에서 데이터를 처리하는 서버 내의 전자 장치에 있어서,차량들로부터 자기 차량의 절대 좌표를 포함하는 자기 차량의 정보 및 상기 자기 차량이 인식한 외부 객체의 상대 좌표를 포함하는 외부 객체의 정보를 수신하는 통신부; 및상기 수신한 정보들에 기초하여, 상기 차량들 각각의 절대 좌표를 포함하는 통합 객체 정보를 생성하는 프로세서를 포함하는, 서버 내의 전자 장치."}
{"patent_id": "10-2023-0101682", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제17항에 있어서, 상기 자기 차량의 정보는, 상기 자기 차량의 번호판 정보를 포함하고,상기 외부 객체의 정보는, 상기 외부 객체가 차량이면 상기 외부 객체인 차량의 번호판 정보를 포함하는, 서버내의 전자 장치."}
{"patent_id": "10-2023-0101682", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제17항에 있어서, 상기 프로세서는, 복수 개의 차량들로부터 수신한, 상기 자기 차량의 번호판 정보 및 상기 외부 객체인 차량의 번호판 정보를 이용하여, 상기 차량들의 고유 식별자를 생성하고, 상기 생성된 고유 식별자를 갖는 차량들의 절대 좌표를 생성하는, 서버 내의 전자 장치."}
{"patent_id": "10-2023-0101682", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제19항에 있어서,상기 자기 차량의 정보는, 상기 자기 차량의 주행 정보를 포함하며,상기 주행 정보는, 상기 자기 차량의 이동 방향, 속력, 차량 타입 중 적어도 하나를 포함하는, 서버 내의 전자장치."}
{"patent_id": "10-2023-0101682", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_21", "content": "제20항에 있어서, 상기 프로세서는,상기 자기 차량의 주행 정보에 기초하여, 상기 고유 식별자를 갖는 차량들의 주행 정보를 생성하는, 서버 내의전자 장치."}
{"patent_id": "10-2023-0101682", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_22", "content": "제17항에 있어서, 상기 차량들은,상기 서버와 통신할 수 있는 복수 개의 통신 차량과, 상기 서버와 통신할 수 없는 적어도 하나의 비통신 차량을포함하는, 서버 내의 전자 장치."}
{"patent_id": "10-2023-0101682", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_23", "content": "제22항에 있어서, 상기 비통신 차량의 상기 절대 좌표는,상기 복수 개의 통신 차량들 중 적어도 두 개의 소정 개수의 통신 차량들로부터 수신한 상기 비통신 차량의 상공개특허 10-2024-0019743-5-기 상대 좌표에 기초하여 생성되는, 서버 내의 전자 장치."}
{"patent_id": "10-2023-0101682", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_24", "content": "제23항에 있어서, 상기 소정 개수는,차량들의 평균 속도, 차량들의 밀집도 및 차량의 종류 중 적어도 하나에 기초하여 결정되는, 서버 내의 전자 장치."}
{"patent_id": "10-2023-0101682", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_25", "content": "지능형 교통 시스템에서 데이터를 처리하는 차량 내의 전자 장치에 있어서,상기 차량이 인식한 외부 객체의 상대 좌표를 획득하는 프로세서; 및상기 차량의 절대 좌표를 포함하는 자기 차량의 정보 및 상기 외부 객체의 상대 좌표를 포함하는 외부 객체의정보를 서버로 송신하고, 상기 송신된 정보에 기초하여 생성된 외부 차량들 각각의 절대 좌표를 포함하는 통합객체 정보를 수신하는 통신부를 포함하는, 차량 내의 전자 장치."}
{"patent_id": "10-2023-0101682", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_26", "content": "제25항에 있어서, 상기 자기 차량의 정보는, 상기 자기 차량의 번호판 정보를 포함하고,상기 외부 객체의 정보는, 상기 외부 객체가 차량이면 상기 외부 객체인 차량의 번호판 정보를 포함하는, 차량내의 전자 장치."}
{"patent_id": "10-2023-0101682", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_27", "content": "제26항에 있어서, 상기 통합 객체 정보는, 복수 개의 차량들로부터 수신한, 상기 자기 차량의 번호판 정보 및 상기 외부 객체인 차량의 번호판 정보를 이용하여 생성된 상기 차량들의 고유 식별자를 갖는 차량들에 대해 생성되는 절대 좌표를 포함하는, 차량 내의 전자 장치."}
{"patent_id": "10-2023-0101682", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_28", "content": "제27항에 있어서,상기 자기 차량의 정보는, 상기 자기 차량의 주행 정보를 포함하며,상기 주행 정보는, 상기 자기 차량의 이동 방향, 속력, 차량 타입 중 적어도 하나를 포함하는, 차량 내의 전자장치."}
{"patent_id": "10-2023-0101682", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_29", "content": "제28항에 있어서, 상기 통합 객체 정보는,상기 자기 차량의 주행 정보에 기초하여, 상기 고유 식별자를 갖는 차량들에 생성되는 주행 정보를 포함하는,차량 내의 전자 장치."}
{"patent_id": "10-2023-0101682", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_30", "content": "제25항에 있어서, 상기 외부 차량들은,상기 서버와 통신할 수 있는 복수 개의 통신 차량과, 상기 서버와 통신할 수 없는 적어도 하나의 비통신 차량을포함하는, 차량 내의 전자 장치."}
{"patent_id": "10-2023-0101682", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_31", "content": "제30항에 있어서, 상기 비통신 차량의 상기 절대 좌표는,상기 복수 개의 통신 차량들 중 적어도 두 개 이상의 소정 개수의 통신 차량들로부터 수신한 상기 비통신 차량공개특허 10-2024-0019743-6-의 상기 상대 좌표에 기초하여 생성되는, 차량 내의 전자 장치."}
{"patent_id": "10-2023-0101682", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_32", "content": "제31항에 있어서, 상기 소정 개수는,차량들의 평균 속도, 차량들의 밀집도 및 차량의 종류 중 적어도 하나에 기초하여 결정되는, 차량 내의 전자 장치."}
{"patent_id": "10-2023-0101682", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "일 실시예에 따른 지능형 교통 시스템에서 데이터를 처리하는 서버 내의 전자 장치의 방법은, 차량들로부터 자기 차량의 절대 좌표를 포함하는 자기 차량의 정보 및 상기 자기 차량이 인식한 외부 객체의 상대 좌표를 포함하는 외부 객체의 정보를 수신하는 단계 및 상기 수신한 정보들에 기초하여, 상기 차량들 각각의 절대 좌표를 포함하 는 통합 객체 정보를 생성하는 단계를 포함한다."}
{"patent_id": "10-2023-0101682", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 지능형 교통 시스템(Intelligent Transportation Systems: ITS)에서 데이터를 처리하기 위한 전자 장치 및 방법에 관한 것이다."}
{"patent_id": "10-2023-0101682", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "차량의 주행 시 가장 중요한 것은 안전 주행 및 교통 사고의 예방이며, 이를 위해 차량의 자세 제어, 차량 구성 장치들의 기능 제어 등을 수행하는 다양한 보조장치 및 안전 벨트, 에어백 등의 안전장치가 차량에 장착되어 있 다. 뿐만 아니라, 최근에는 블랙박스 등과 같이 차량에 위치하여 차량의 주행 영상 및 각종 센서들로부터 전송되는 데이터를 저장함으로써, 차량의 사고 발생시 차량의 사고 원인을 규명하는 장치들도 차량에 구비되는 추세이다. 스마트폰, 태블릿과 같은 휴대용 단말기들도 블랙박스 또는 네비게이션 어플리케이션 등이 탑재 가능하여 이와 같은 차량용 장치로 활용되고 있는 실정이다."}
{"patent_id": "10-2023-0101682", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "자율 주행과 관련하여 도로의 교통 정보를 수집하고 차량들에게 제공하는 지능형 교통 시스템에서, 서버는 차량 들과의 통신을 통하여 차량들의 정보를 수집하고 수집된 데이터를 가공 및 처리할 수 있다. 한편, 도로 상에는 서버와 통신이 가능하지 않은 차량들이 다수 존재한다. 또한, 자율 주행 기술의 발전으로 자율주행 차량이 많아 지더라고 자율주행 차량과 비자율주행 차량은 상당 기간 공존해야 한다. 따라서 도로 상의 객체들의 위치와 상 태 등에 대한 정확한 데이터를 수집 및 가공하여 각 차량들에게 제공될 필요가 있다. 이러한 관점에서 일 실시예는, 차량들이 인식한 객체의 데이터들을 이용하여 도로의 차량들의 위치 정보를 생성 하는 방법 및 장치를 제공한다. 일 실시예는, 차량들로부터 수신한 객체 데이터들을 이용하여 통합된 교통 정보를 생성하는 방법 및 장치를 제 공한다. 일 실시예는, 서버와 통신할 수 없는 차량의 위치 및 주행 정보를 생성하는 방법 및 장치를 제공한다."}
{"patent_id": "10-2023-0101682", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "일 실시예가 제공하는 지능형 교통 시스템에서 데이터를 처리하는 서버 내의 전자 장치의 방법은, 차량들로부터 자기 차량의 절대 좌표를 포함하는 자기 차량의 정보 및 상기 자기 차량이 인식한 외부 객체의 상대 좌표를 포 함하는 외부 객체의 정보를 수신하는 단계 및 상기 수신한 정보들에 기초하여, 상기 차량들 각각의 절대 좌표를 포함하는 통합 객체 정보를 생성하는 단계를 포함할 수 있다. 여기서, 상기 자기 차량의 정보는, 상기 자기 차량의 번호판 정보를 포함하고, 상기 외부 객체의 정보는, 상기 외부 객체가 차량이면 상기 외부 객체인 차량의 번호판 정보를 포함할 수 있다. 여기서, 상기 통합 객체 정보를 생성하는 단계는, 복수 개의 차량들로부터 수신한, 상기 자기 차량의 번호판 정 보 및 상기 외부 객체인 차량의 번호판 정보를 이용하여, 상기 차량들의 고유 식별자를 생성하는 단계 및 상기 생성된 고유 식별자를 갖는 차량들의 절대 좌표를 생성하는 단계를 포함할 수 있다.여기서, 상기 자기 차량의 정보는, 상기 자기 차량의 주행 정보를 포함하며, 상기 주행 정보는, 상기 자기 차량 의 이동 방향, 속력, 차량 타입 중 적어도 하나를 포함할 수 있다. 여기서, 상기 통합 객체 정보를 생성하는 단계는, 상기 자기 차량의 주행 정보에 기초하여, 상기 고유 식별자를 갖는 차량들의 주행 정보를 생성하는 단계를 포함할 수 있다. 여기서, 상기 차량들은, 상기 서버와 통신할 수 있는 복수 개의 통신 차량과, 상기 서버와 통신할 수 없는 적어 도 하나의 비통신 차량을 포함할 수 있다. 여기서, 상기 비통신 차량의 상기 절대 좌표는, 상기 복수 개의 통신 차량들 중 적어도 두 개의 소정 개수의 통 신 차량들로부터 수신한 상기 비통신 차량의 상기 상대 좌표에 기초하여 생성될 수 있다. 여기서, 상기 소정 개수는, 차량들의 평균 속도, 차량들의 밀집도 및 차량의 종류 중 적어도 하나에 기초하여 결정될 수 있다. 일 실시예가 제공하는 지능형 교통 시스템에서 데이터를 처리하는 차량 내의 전자 장치의 방법은, 상기 차량이 인식한 외부 객체의 상대 좌표를 획득하는 단계, 상기 차량의 절대 좌표를 포함하는 자기 차량의 정보 및 상기 외부 객체의 상대 좌표를 포함하는 외부 객체의 정보를 서버로 송신하는 단계 및 상기 송신된 정보에 기초하여 생성된 외부 차량들 각각의 절대 좌표를 포함하는 통합 객체 정보를 수신하는 단계를 포함할 수 있다. 여기서, 상기 자기 차량의 정보는, 상기 자기 차량의 번호판 정보를 포함하고, 상기 외부 객체의 정보는, 상기 외부 객체가 차량이면 상기 외부 객체인 차량의 번호판 정보를 포함할 수 있다. 여기서, 상기 통합 객체 정보는, 복수 개의 차량들로부터 수신한, 상기 자기 차량의 번호판 정보 및 상기 외부 객체인 차량의 번호판 정보를 이용하여 생성된 상기 차량들의 고유 식별자를 갖는 차량들에 대해 생성되는 절대 좌표를 포함할 수 있다. 여기서, 상기 자기 차량의 정보는, 상기 자기 차량의 주행 정보를 포함하며, 상기 주행 정보는, 상기 자기 차량 의 이동 방향, 속력, 차량 타입 중 적어도 하나를 포함할 수 있다. 여기서, 상기 통합 객체 정보는, 상기 자기 차량의 주행 정보에 기초하여, 상기 고유 식별자를 갖는 차량들에 생성되는 주행 정보를 포함할 수 있다. 여기서, 상기 외부 차량들은, 상기 서버와 통신할 수 있는 복수 개의 통신 차량과, 상기 서버와 통신할 수 없는 적어도 하나의 비통신 차량을 포함할 수 있다. 여기서, 상기 비통신 차량의 상기 절대 좌표는, 상기 복수 개의 통신 차량들 중 적어도 두 개 이상의 소정 개수 의 통신 차량들로부터 수신한 상기 비통신 차량의 상기 상대 좌표에 기초하여 생성될 수 있다. 여기서, 상기 소정 개수는, 차량들의 평균 속도, 차량들의 밀집도 및 차량의 종류 중 적어도 하나에 기초하여 결정될 수 있다. 일 실시예가 제공하는 지능형 교통 시스템에서 데이터를 처리하는 서버 내의 전자 장치는, 차량들로부터 자기 차량의 절대 좌표를 포함하는 자기 차량의 정보 및 상기 자기 차량이 인식한 외부 객체의 상대 좌표를 포함하는 외부 객체의 정보를 수신하는 통신부 및 상기 수신한 정보들에 기초하여, 상기 차량들 각각의 절대 좌표를 포함 하는 통합 객체 정보를 생성하는 프로세서를 포함할 수 있다. 여기서, 상기 자기 차량의 정보는, 상기 자기 차량의 번호판 정보를 포함하고, 상기 외부 객체의 정보는, 상기 외부 객체가 차량이면 상기 외부 객체인 차량의 번호판 정보를 포함할 수 있다. 여기서, 상기 프로세서는, 복수 개의 차량들로부터 수신한, 상기 자기 차량의 번호판 정보 및 상기 외부 객체인 차량의 번호판 정보를 이용하여, 상기 차량들의 고유 식별자를 생성하고, 상기 생성된 고유 식별자를 갖는 차량 들의 절대 좌표를 생성한다. 여기서, 상기 자기 차량의 정보는, 상기 자기 차량의 주행 정보를 포함하며, 상기 주행 정보는, 상기 자기 차량 의 이동 방향, 속력, 차량 타입 중 적어도 하나를 포함할 수 있다. 여기서, 상기 프로세서는, 상기 자기 차량의 주행 정보에 기초하여, 상기 고유 식별자를 갖는 차량들의 주행 정 보를 생성한다. 여기서, 상기 차량들은, 상기 서버와 통신할 수 있는 복수 개의 통신 차량과, 상기 서버와 통신할 수 없는 적어 도 하나의 비통신 차량을 포함할 수 있다. 여기서, 상기 비통신 차량의 상기 절대 좌표는, 상기 복수 개의 통신 차량들 중 적어도 두 개의 소정 개수의 통 신 차량들로부터 수신한 상기 비통신 차량의 상기 상대 좌표에 기초하여 생성될 수 있다. 여기서, 상기 소정 개수는, 차량들의 평균 속도, 차량들의 밀집도 및 차량의 종류 중 적어도 하나에 기초하여 결정될 수 있다. 일 실시예가 제공하는 지능형 교통 시스템에서 데이터를 처리하는 차량 내의 전자 장치는, 상기 차량이 인식한 외부 객체의 상대 좌표를 획득하는 프로세서 및 상기 차량의 절대 좌표를 포함하는 자기 차량의 정보 및 상기 외부 객체의 상대 좌표를 포함하는 외부 객체의 정보를 서버로 송신하고, 상기 송신된 정보에 기초하여 생성된 외부 차량들 각각의 절대 좌표를 포함하는 통합 객체 정보를 수신하는 통신부를 포함할 수 있다. 여기서, 상기 자기 차량의 정보는, 상기 자기 차량의 번호판 정보를 포함하고, 상기 외부 객체의 정보는, 상기 외부 객체가 차량이면 상기 외부 객체인 차량의 번호판 정보를 포함할 수 있다. 여기서, 상기 통합 객체 정보는, 복수 개의 차량들로부터 수신한, 상기 자기 차량의 번호판 정보 및 상기 외부 객체인 차량의 번호판 정보를 이용하여 생성된 상기 차량들의 고유 식별자를 갖는 차량들에 대해 생성되는 절대 좌표를 포함할 수 있다. 여기서, 상기 자기 차량의 정보는, 상기 자기 차량의 주행 정보를 포함하며, 상기 주행 정보는, 상기 자기 차량 의 이동 방향, 속력, 차량 타입 중 적어도 하나를 포함할 수 있다. 여기서, 상기 통합 객체 정보는, 상기 자기 차량의 주행 정보에 기초하여, 상기 고유 식별자를 갖는 차량들에 생성되는 주행 정보를 포함할 수 있다. 여기서, 상기 외부 차량들은, 상기 서버와 통신할 수 있는 복수 개의 통신 차량과, 상기 서버와 통신할 수 없는 적어도 하나의 비통신 차량을 포함할 수 있다. 여기서, 상기 비통신 차량의 상기 절대 좌표는, 상기 복수 개의 통신 차량들 중 적어도 두 개 이상의 소정 개수 의 통신 차량들로부터 수신한 상기 비통신 차량의 상기 상대 좌표에 기초하여 생성될 수 있다. 여기서, 상기 소정 개수는, 차량들의 평균 속도, 차량들의 밀집도 및 차량의 종류 중 적어도 하나에 기초하여 결정될 수 있다."}
{"patent_id": "10-2023-0101682", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "실시예들에 따르면, 지능형 교통 시스템에서 도로상의 객체들의 상태에 대한 정확도 높은 데이터를 생성하고, 이를 각 차량들에게 제공할 수 있어, 차량들의 효율적인 운행에 도움을 줄 수 있고, 자율주행 차량의 운행 판단 에 있어 사전에 정보를 제공할 수 있다. 또한, 비통신 차량과 통신 차량이 공존하는 환경, 또는 비자율주행 차 량과 자율주행 차량이 공존하는 동안에도 비통신 차량 또는 비자율주행 차량의 위치 및 상태를 정확도 높게 추 정할 수 있어, 안정적이고 정확한 지능형 교통 시스템을 구축할 수 있다."}
{"patent_id": "10-2023-0101682", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 본 명세서의 일부 실시 예들을 예시적인 도면을 통해 상세하게 설명한다. 각 도면의 구성요소들에 참조부 호를 부가함에 있어서, 동일한 구성요소들에 대해서는 비록 다른 도면상에 표시되더라도 가능한 한 동일한 부호 를 가지도록 하고 있음에 유의해야 한다. 또한, 실시 예를 설명함에 있어, 관련된 공지 구성 또는 기능에 대한 구체적인 설명이 실시 예에 대한 이해를 방해한다고 판단되는 경우에는 그 상세한 설명은 생략한다. 본 명세서의 구성 요소를 설명하는 데 있어서, 제 1, 제 2, A, B, (a), (b) 등의 용어를 사용할 수 있다. 이러 한 용어는 그 구성 요소를 다른 구성 요소와 구별하기 위한 것일 뿐, 그 용어에 의해 해당 구성 요소의 본질이 나 차례 또는 순서 등이 한정되지 않는다. 또한, 다르게 정의되지 않는 한, 기술적이거나 과학적인 용어를 포함 해서 여기서 사용되는 모든 용어들은 기술 분야에서 통상의 지식을 가진 자에 의해 일반적으로 이해되는 것과 동일한 의미를 가진다. 일반적으로 사용되는 사전에 정의되어 있는 것과 같은 용어들은 관련 기술의 문맥상 가 지는 의미와 일치하는 의미를 가진 것으로 해석되어야 하며, 본 출원에서 명백하게 정의하지 않는 한, 이상적이 거나 과도하게 형식적인 의미로 해석되지 않는다. 본 명세서에서 \"A 또는 B(A or B)\"는 \"오직 A\", \"오직 B\" 또는 \"A와 B 모두\"를 의미할 수 있다. 달리 표현하면, 본 명세서에서 \"A 또는 B(A or B)\"는 \"A 및/또는 B(A and/or B)\"으로 해석될 수 있다. 예를 들어, 본 명세서에 서 \"A, B 또는 C(A, B or C)\"는 \"오직 A\", \"오직 B\", \"오직 C\", 또는 \"A, B 및 C의 임의의 모든 조합(any combination of A, B and C)\"를 의미할 수 있다. 본 명세서에서 사용되는 슬래쉬(/)나 쉼표(comma)는 \"및/또는(and/or)\"을 의미할 수 있다. 예를 들어, \"A/B\"는 \"A 및/또는 B\"를 의미할 수 있다. 이에 따라 \"A/B\"는 \"오직 A\", \"오직 B\", 또는 \"A와 B 모두\"를 의미할 수 있다. 예를 들어, \"A, B, C\"는 \"A, B 또는 C\"를 의미할 수 있다. 본 명세서에서 \"A 및 B 중 적어도 하나(at least one of A and B)\"는, \"오직 A\", \"오직 B\" 또는 \"A와 B 모두\" 를 의미할 수 있다. 또한, 본 명세서에서 \"적어도 하나의 A 또는 B(at least one of A or B)\"나 \"적어도 하나의 A 및/또는 B(at least one of A and/or B)\"라는 표현은 \"적어도 하나의 A 및 B(at least one of A and B)\"와 동일하게 해석될 수 있다. 또한, 본 명세서에서 \"적어도 하나의 A, B 및 C(at least one of A, B and C)\"는, \"오직 A\", \"오직 B\", \"오직 C\", 또는 \"A, B 및 C의 임의의 모든 조합(any combination of A, B and C)\"를 의미할 수 있다. 또한, \"적어도 하나의 A, B 또는 C(at least one of A, B or C)\"나 \"적어도 하나의 A, B 및/또는 C(at least one of A, B and/or C)\"는 \"적어도 하나의 A, B 및 C(at least one of A, B and C)\"를 의미할 수 있다. 도 1은 일 실시 예에 따른 차량 서비스 시스템을 나타내는 블록도이다. 본 명세서에서 차량(vehicle)은 이동체(moving body)의 일 예시로서, 차량에 한정되는 것은 아니다. 본 명세서 에 따른 이동체(moving body)는 차량, 사람, 자전거, 선박, 열차 등과 같이 이동할 수 있는 다양한 객체를 포함 할 수 있다. 이하에서는 설명의 편의를 위하여, 이동체가 차량인 경우를 예로 설명하기로 한다. 또한 본 명세서에서 차량용 전자장치는 차량용 적외선(Infra-Red) 카메라, 차량용 블랙박스(black-box), Car dash cam 또는 Car video recorder 등 다른 명칭으로 불릴 수도 있다. 또한 본 명세서에서 차량 서비스 시스템은 차량 블랙박스 서비스 시스템, 첨단 운전자 보조 시스템(advanced driver assistance systems: ADAS), 교통 관제 시스템, 자율주행 차량 서비스 시스템, 차량 원격 주행 시스템 (Teleoperated Driving System), AI(Artificial Intelligence) 차량 제어 시스템, V2X(Vehicle to everything) 서비스 시스템 중 적어도 하나의 차량 관련 서비스 시스템을 포함할 수 있다. 도 1을 참조하면, 차량 서비스 시스템은 차량용 전자 장치, 차량 서비스 제공 서버 및 사용자 단말 장치를 포함한다. 차량용 전자 장치는 유/무선 통신 네트워크에 무선으로 접속할 수 있고, 유/ 무선 통신 네트워크에 접속한 차량 서비스 제공 서버, 사용자 단말 장치와 데이터를 교환할 수 있다. 차량용 전자 장치는 사용자 단말 장치를 통해 입력된 사용자 제어에 의해 제어될 수 있다. 예컨대 사 용자가 사용자 단말 장치에 설치된 실행 가능한 객체를 선택할 경우, 차량용 전자 장치는 상기 실행 가능한 객체에 대한 사용자 입력에 의해 발생된 이벤트에 대응하는 동작들을 수행할 수 있다. 여기서 상기 실행 가능한 객체는, 사용자 단말 장치에 설치되어 차량용 전자 장치를 원격에서 제어할 수 있는 일종의 애플리케이션이 될 수 있다. 도 2는 일 실시예에 따른 차량용 전자 장치를 나타내는 블록도이다. 도 2를 참조하면, 차량용 전자 장치는 프로세서, 전원 관리 모듈, 배터리, 디스플레이부 , 사용자 입력부, 센서부, 촬영부, 메모리, 통신부, 하나 이상의 안테나, 스피커 및 마이크 중 적어도 일부를 포함한다. 프로세서는 차량용 전자 장치의 전반적인 동작을 제어하며, 본 명세서에서 설명된 제안된 기능, 절차 및/또는 방법을 구현하도록 구성될 수 있다. 프로세서는 ASIC(application-specific integrated circuit), 다른 칩셋, 논리 회로 및/또는 데이터 처리 장치를 포함할 수 있다. 프로세서는 AP(application processor)일 수 있다. 프로세서는 DSP(digital signal processor), CPU(central processing unit), GPU(graphics processing unit), 모뎀(Modem; modulator and demodulator) 중 적어도 하나를 포함할 수 있다. 프로세서는 전원 관리 모듈, 배터리, 디스플레이부, 사용자 입력부, 센서부, 촬 영부, 메모리, 통신부, 하나 이상의 안테나, 스피커 및 마이크의 전부 또는 일 부를 제어할 수 있다. 특히, 프로세서는 통신부를 통해 각종 데이터가 수신되면, 수신된 데이터를 처 리해서 유저 인터페이스를 생성하고, 생성된 유저 인터페이스를 표시하도록 디스플레이부를 제어할 수 있 다. 프로세서의 전부 또는 일부는 차량용 전자 장치 내의 다른 구성 요소(예를 들면, 전원 관리 모듈 , 배터리, 디스플레이부, 사용자 입력부, 센서부, 촬영부, 메모리, 통신 부, 하나 이상의 안테나, 스피커 및 마이크)와 전기적으로(electrically) 또는 기능적으 로(operably) 결합(coupled with)되거나 연결될(connected to) 수 있다. 프로세서는 촬영부에서 획득한 영상 데이터를 처리하는 신호 처리 기능과, 영상으로부터 현장 상황에 대한 정보를 얻기 위한 영상 분석 기능을 수행할 수 있다. 일례로서, 신호 처리 기능은 촬영부로부터 촬영 된 영상 데이터의 용량을 줄이기 위해 압축하는 기능을 포함한다. 영상 데이터는 X축을 기준으로, 촬영된 각 프 레임이 일정 시간 간격으로 나열된 형태로 구성될 수 있다. 즉, 영상 데이터는 일정 시간 동안 연속으로 촬영된 이미지들이라고 볼 수 있다. 이러한 영상 데이터의 원본 데이터(Raw data) 용량은 매우 크기 때문에, 압축하지 않고 그대로 메모리에 저장하는 경우에는 매우 비효율적이므로, 디지털 변환된 영상에 대해 다양한 방식으로 압 축되어 메모리에 저장될 수 있다. 동영상 압축에는 프레임 간의 상관 관계, 공간적인 상관관계 및 저주파 성분 에 민감한 시각의 특성을 이용한 방법 등이 사용된다. 원본 데이터는 압축으로 인해 손실되기 때문에, 차량의 교통 사고 상황을 식별할 수 있을 만큼 적절한 비율로 압축될 수 있다. 동영상의 압축 방식으로는 H.264, MPEG4, H.265/HEVC, H.266/VVC, AV-1, VP9 등의 다양한 비디오 코덱 중 하나가 사용될 수 있고 차량용 전자 장 치에서 지원하는 방식으로 영상 데이터가 압축될 수 있다. 본 발명의 일 실시 예에 따른 영상 분석 기능은, 영상 내 존재하는 객체를 검출 및 분류(Detection & Classification)하고, 검출된 객체를 추적(Tracking)하는 기능을 포함할 수 있다. 본 발명의 일 실시 예에 따른 영상 내 존재하는 객체를 검출하기 위한 객체 검출(Object Detection)은 딥 러닝 기반의 객체 검출 모델이 사용될 수 있다. 구체적으로, 일 실시 예에 따른 딥 러닝 기반의 객체 검출 모델은, R-CNN 계열(R-CNN(Regions with Convolutional Neural Networks features), Fast R-CNN, Faster R-CNN, Mask R-CNN 등)과 같이 Regional Proposal과 Detection이 순차적으로 이루이지는 2단계 검출기(Two-stage Detector) 모델과 YOLO(You Only Look), SSD(Single-Shot Multibox Detector)과 같이 Regional Proposal과 Detection이 동시에 수행되는(즉, Region proposal을 One-stage로 진행하는) 1단계 검출기(One-stage Detector) 모델 등이 사용될 수 있으나, 이 에 한정되지는 않는다. 영상 분석 기능은 딥러닝(deep learning)에 기반할 수 있으며, 컴퓨터 비전(computer vision) 기법에 의해 구현 될 수 있다. 구체적으로, 영상분석 기능은 이미지를 여러 영역 또는 조각으로 분할하여 각기 따로 검사하는 이 미지 분할 기능, 이미지 속의 특정 객체를 식별하는 객체 감지 기능, 하나의 이미지에 존재하는 다수의 객체(예: 승용차(sedan), 픽업 트럭(Pickup truck), SUV(Sports Utility Vehicle), 버스(Bus), 트럭(Truck), 보행자(Pedestrian), 자전거, 오토바이, 신호등, 도로, 횡단보도 등)를 인식하는 고급 객체 감지 모델(XY 좌표 를 사용하여 경계 박스를 생성하고 그 안의 모든 것을 식별), 이미지 속의 사람 얼굴을 인식할 뿐만 아니라 개 인의 신원을 식별하는 안면 인식 기능, 이미지의 내용을 보다 정확히 파악하기 위해 객체 또는 풍경의 바깥쪽 경계를 식별하는 데 사용되는 경계 감지 기능, 이미지에서 반복되는 모양이나 색상, 기타 시각적 표시를 인식하 는 패턴 감지 기능, 이미지의 유사성을 대조하여 분류하는 특징 매칭 기능 등을 포함할 수 있다. 이러한 영상 분석 기능은 차량용 전자 장치의 프로세서가 아닌, 차량 서비스 제공 서버에서 수 행될 수도 있다. 전력 관리 모듈은 프로세서 및/또는 통신부에 대한 전력을 관리한다. 배터리는 전력 관리 모듈에 전력을 공급한다. 디스플레이부는 프로세서에 의해 처리된 결과를 출력한다. 디스플레이부는 컨텐츠, 데이터, 또는 신호를 출력할 수 있다. 다양한 실시예들에서, 디스플레이부는 프로세서에 의해 가공된 영상 신호를 표시할 수 있다. 예를 들면, 디스플레이부는 캡쳐(capture) 또 는 스틸(still) 이미지를 표시할 수 있다. 다른 예를 들면, 디스플레이부는 동영상 또는 카메라 프리뷰 (preview) 이미지를 표시할 수 있다. 또 다른 예를 들면, 디스플레이부는 차량용 전자장치와 상호작 용할 수 있도록 GUI(graphical user interface)를 표시할 수 있다. 디스플레이부는 액정 디스플레이 (liquid crystal display: LCD), 박막 트랜지스터 액정 디스플레이(thin film transistor-liquid crystal display), 유기 발광 다이오드(organic light-emitting diode: OLED), 플렉시블 디스플레이(flexible display), 3차원 디스플레이(3D display) 중에서 적어도 하나를 포함할 수 있다. 디스플레이부는 터치 입 력 등을 수신할 수 있는 센서와 함께 결합됨으로써, 일체형의 터치 스크린(touch screen)으로 구성될 (configured with) 수도 있다. 사용자 입력부는 프로세서에 의해 사용될 입력을 수신한다. 사용자 입력부는 디스플레이부 상에 표시될 수 있다. 사용자 입력부는 손가락 및 펜의 터치 또는 호버링(hovering) 입력을 감지(sense)할 수 있다. 사용자 입력부는 회전 가능한 구조체 또는 물리적 버튼을 통해 야기되는 입력을 감지할 수 있다. 사용자 입력부는 다양한 종류의 입력들을 감지하기 위한 센서들을 포함할 수 있다. 사용자 입력부에 수신되는 입력은 다양한 유형들을 가질 수 있다. 예를 들면, 사용자 입력부에 수신되는 입력은 터치 및 릴 리즈(touch and release), 드래그 앤 드롭(drag and drop), 롱 터치(long touch), 포스 터치(force touch), 물 리적 누름(depression) 등을 포함할 수 있다. 입력부는 수신된 입력 및 수신된 입력과 관련된 데이터를 제 어부에게 제공할 수 있다. 다양한 실시예들에서, 사용자 입력부는, 사용자의 음성 명령을 수신할 수 있는 마이크로폰(microphone 또는 트랜스듀서(transducer))를 포함할 수 있다. 다양한 실시예들에서, 사용자 입 력부는, 사용자의 모션을 수신할 수 있는 이미지 센서(image sensor) 또는 카메라(camera)를 포함할 수 있 다. 센서부는 하나 이상의 센서들을 포함한다. 센서부는 차량에 가해지는 충격을 감지하거나 가속도의 변 화량이 일정 이상일 경우를 감지하는 기능을 구비한다. 일부 실시 예에서, 센서부는 높은 동적 범위 카메 라들(high dynamic range cameras)과 같은 이미지 센서들일 수 있다. 일부 실시 예에서, 센서부는 비-시 각적 센서들(non-visual sensors)을 포함한다. 일부 실시 예에서, 센서부는 이미지 센서 외에도 레이더 (RADAR), LiDAR(Light Detection And Ranging), 및/또는 초음파 센서들을 포함할 수 있다. 일부 실시 예에서,센서부는 충격이나 가속도를 감지하기 위해 가속도 센서, 지자계 센서 등을 포함할 수 있다. 다양한 실시 예에서, 센서부는 차량의 상이한 위치들에, 및/또는 하나 이상의 상이한 방향들을 향하게 부 착될 수 있다. 예를 들어, 센서부는 전면(forward-facing), 후면(rear-facing), 측면(side-facing) 등 방 향들로 차량의 앞(front), 옆(sides), 뒤(rear), 및/또는 루프(roof)에 부착될 수 있다 촬영부는 차량의 주차, 정차 및 주행 중 적어도 하나의 상황에서 영상을 촬영할 수 있다. 여기서, 촬영 영 상은 주차장에 관한 촬영 영상인 주차장 영상을 포함할 수 있다. 주차장 영상은 차량의 주차장 진입 시점으로부 터 차량의 주차장 출차 시점까지의 기간 동안 촬영된 영상을 포함할 수 있다. 즉, 주차장 영상은 차량의 주차장 진입 시점으로부터 차량의 주차 시점(ex. 주차하기 위해 차량 시동 오프(OFF) 시점) 전까지 촬영된 영상, 차량 의 주차 기간 동안 촬영된 영상, 차량의 주차 완료 시점(ex. 출차 하기 위해 차량 시동 온(on))부터 차량의 주 차장 출차 시점까지의 촬영 영상을 포함할 수 있다. 그리고, 촬영 영상은 차량의 전방, 후방, 측면 및 내부 중 적어도 하나의 영상을 포함할 수 있다. 또한, 촬영부는 운전자의 얼굴 또는 동공을 모니터링할 수 있는 적 외선(Infra Red) 카메라를 포함할 수도 있다. 이러한 촬영부는 렌즈부와 촬상 소자를 포함할 수 있다. 렌즈부(lens unit)는 광학 신호를 집광하는 기능 을 수행할 수 있고, 렌즈부를 투과한 광학 신호는 촬상 소자의 촬상 영역에 이르러 광학상을 결상한다. 여기서 촬상 소자는 광학 신호를 전기 신호로 변환하는 CCD(Charge Coupled Device), CIS(Complementary Metal Oxide Semiconductor Image Sensor) 또는 고속 이미지 센서 등을 사용할 수 있다. 그리고, 촬영부는 렌즈부 구 동부, 조리개, 조리개 구동부, 촬상 소자 제어부 및 이미지 프로세서의 전부 또는 일부를 더 포함할 수 있다. 차량용 전자장치의 동작 모드는 상시 녹화 모드, 이벤트 녹화 모드, 수동 녹화 모드, 주차 녹화 모드를 포 함할 수 있다. 상시 녹화 모드는 차량의 시동을 걸고 주행을 시작하면 실행되는 모드로, 차량의 주행이 계속되는 동안 상시 녹 화 모드를 유지할 수 있다. 상시 녹화 모드에서 차량용 영상 촬영 장치는 소정 시간 단위(일 예로, 1 ~ 5 분)로 녹화를 수행할 수 있다. 본 발명에서 상시 녹화 모드와 상시 모드는 동일한 의미로 사용될 수 있다. 주차 녹화 모드는 차량의 시동이 꺼지거나, 차량의 주행을 위한 배터리 공급이 중단되어 주차 상태에서 작동하 는 모드를 의미할 수 있다. 주차 녹화 모드에서 차량용 전자장치는 주차 중 상시 녹화를 수행하는 주차 상 시 녹화 모드로 동작할 수 있다. 또한, 주차 녹화 모드에서 차량용 전자장치는 주차 중 충격 이벤트가 감 지되면 녹화를 수행하는 주차 이벤트 녹화 모드로 동작할 수 있다. 이 경우, 이벤트 발생 소정 시간 이전부터 소정시간 이후까지의 일정 구간의 녹화(일 예로, 이벤트 발생 10초 전 내지 10초 후 녹화)를 수행할 수 있다. 본 명세서에서 주차 녹화 모드와 주차 모드는 동일한 의미로 사용될 수 있다. 이벤트 녹화 모드는 차량의 주행 중에 각종 이벤트가 발생하면 작동하는 모드를 의미할 수 있다. 수동 녹화 모드는 사용자가 수동으로 녹화를 작동하는 모드를 의미할 수 있다. 수동 녹화 모드에서 차량용 전자 장치는 사용자의 수동 녹화 요청 발생 소정시간 이전부터 소정시간 이후까지 시간의 녹화(일 예로, 이벤트 발생 10초 전 내지 10초 후 녹화)를 수행할 수 있다. 메모리는 프로세서와 동작 가능하게 결합되고, 프로세서를 동작시키기 위한 다양한 정보를 저장 한다. 메모리는 ROM(read-only memory), RAM(random access memory), 플래시 메모리, 메모리 카드, 저장 매체 및/또는 다른 저장 장치를 포함할 수 있다. 실시예가 소프트웨어로 구현되는 경우, 본 명세서에서 설명된 기술들은 본 명세서에서 설명된 기능을 수행하는 모듈(예컨대, 절차, 기능 등)로 구현될 수 있다. 모듈은 메모 리에 저장될 수 있고 프로세서에 의해 실행될 수 있다. 메모리는 프로세서 내부에 구현될 수 있다. 또는, 메모리는 프로세서 외부에 구현될 수 있으며, 기술 분야에서 공지된 다양한 수단을 통해 프로세서에 통신 가능하게 연결될 수 있다. 메모리는 차량용 전자장치의 내부에 구성되거나 차량용 전자장치 에 구비된 포트를 통해 착탈식 으로 구성되거나 차량용 전자장치의 외부에 존재할 수 있다. 메모리가 차량용 전자장치의 내부 에 구성된 경우, 하드 디스크 드라이브나 플래쉬 메모리 형태로 존재할 수 있다. 메모리가 차량용 전자장 치에 착탈식으로 구성된 경우, SD카드, Micro SD카드, USB메모리 등의 형태로 존재할 수 있다. 메모리 가 차량용 전자장치의 외부에 구성된 경우 통신부를 통해 다른 기기 또는 데이터베이스 서버에 있는 저장공간에 존재할 수 있다. 통신부는 프로세서와 동작 가능하게 결합되고, 무선 신호를 송신 및/또는 수신한다. 통신부는 전송기와 수신기를 포함한다. 통신부는 무선 주파수 신호를 처리하기 위한 기저 대역 회로를 포함할 수 있 다. 송수신부는 무선 신호를 송신 및/또는 수신하도록 하나 이상의 안테나을 제어한다. 통신부는 차 량용 전자장치가 타 디바이스와 통신 가능하게 할 수 있고, 여기서, 통신부는 셀룰러 방식의 이동 통 신 모듈, Wireless LAN(Local Area Network) 방식 등과 같은 근거리 무선 통신 모듈, 저전력 광역 통신(Low- Power Wide-Area : LPWA) 기술을 이용한 통신 모듈 등 기 공지된 다양한 통신 모듈들의 적어도 하나의 결합으로 제공될 수 있다. 또한, 통신부는 GPS(Global Positioning System) Tracker와 같이 위치 추적 기능도 수행 할 수 있다. 스피커는 프로세서에 의해 처리된 소리 관련 결과를 출력한다. 예를 들어 스피커는 주차 이벤트 가 발생하였음을 나타내는 오디오 데이터를 출력할 수 있다. 마이크는 프로세서에 의해 사용될 소리 관련 입력을 수신한다. 수신된 소리는 외부 충격에 의한 소리나 차량 내/외부의 상황과 관련된 사람의 음성으로 촬영부에서 촬영된 영상과 함께 당시의 상황을 인식하는 데 도움을 줄 수 있다. 마이크를 통해 수신 된 소리는 메모리에 저장될 수 있다. 도 3은 일 실시예에 따른 차량 서비스 제공 서버를 나타내는 블록도이다. 도 3을 참조하면, 차량 서비스 제공 서버는 통신부, 프로세서 및 저장부를 포함한다. 차량 서비스 제공 서버의 통신부는 차량용 전자장치 및/또는 사용자 단말 장치와 유/무선 통신 네트워크를 통해 접속되어 데이터를 송수신한다. 도 4는 일 실시예에 따른 사용자 단말 장치의 블록 구성도이다. 도 4를 참조하면, 사용자 단말 장치는 통신부, 프로세서, 표시부 및 저장부를 포함한 다. 통신부는 차량용 전자장치 및/또는 차량 서비스 제공 서버와 유/무선 통신 네트워크를 통해 접속되어 데이터를 송수신한다. 프로세서는 사용자 단말 장치의 전반적인 기능을 제어하며, 본 명세 서의 실시예에 따라 사용자로부터 입력된 명령을 통신부를 통해 차량 서비스 시스템으로 송신한다. 프로세서는 차량 서비스 제공 서버로부터 차량 서비스에 관련된 제어 메시지가 수신되면, 표시부 를 통해 사용자에게 표시하도록 제어한다. 도 5는 차량의 자율 주행 시스템을 도시한 블록도이다. 도 5에 따른 차량의 자율 주행 시스템은 센서들, 이미지 전처리기, 딥 러닝 네트워크, 인 공 지능(AI) 프로세서, 차량 제어 모듈, 네트워크 인터페이스, 및 통신부를 포함하는 딥러 닝 네트워크일 수 있다. 다양한 실시 예에서, 각 요소들은 다양한 인터페이스를 통해 연결될 수 있다. 예를 들 어, 센서들에 의해 센싱되어 출력되는 센서 데이터는 이미지 전처리기로 피드(feed)될 수 있다. 이미 지 전처리기에 의해 처리된 센서 데이터는 AI 프로세서에서 실행(run)하는 딥 러닝 네트워크에 피드될 수 있다. AI 프로세서에 의해 실행(run)하는 딥 러닝 네트워크의 출력은 차량 제어 모듈(51 1)에 피드될 수 있다. AI 프로세서에서 실행(run)되는 딥 러닝 네트워크의 중간 결과들은 AI 프로세 서로 피드될 수 있다. 다양한 실시 예에서, 네트워크 인터페이스는 차량 내 전자 장치와 통신을 수행 함으로써, 차량의 자율 주행을 위한 자율 주행 경로 정보 및/또는 자율 주행 제어 명령들을 내부 블록 구성들로 전달한다. 일 실시예에서, 네트워크 인터페이스는 센서(들)를 통해 획득된 센서 데이터를 외부 서버 로 전송하기 위해 이용될 수 있다. 일부 실시 예에서, 자율 주행 제어 시스템은 적절하게(as appropriate) 추가적인 또는 보다 더 적은 구성 요소들을 포함할 수 있다. 예를 들어, 일부 실시 예에서, 이미지 전처리기 는 선택적인(optional) 구성요소일 수 있다. 다른 예를 들면, 후처리 구성 요소(미도시)는 출력이 차량 제 어 모듈로 제공되기 전에 딥 러닝 네트워크의 출력에서 후처리를 수행하기 위해 자율 주행 제어 시스 템 내에 포함될 수 있다. 일부 실시 예에서, 센서들은 하나 이상의 센서들을 포함할 수 있다. 다양한 실시 예에서, 센서들은 차량의 상이한 위치들에 부착될 수 있다. 센서들은 하나 이상의 상이한 방향들을 향할 수 있다. 예를 들어, 센서들은 전면(forward-facing), 후면(rear-facing), 측면(side-facing) 등 방향들을 향하도록 차 량의 앞(front), 옆(sides), 뒤(rear), 및/또는 루프(roof)에 부착될 수 있다. 일부 실시 예에서, 센서들(50 3)은 높은 동적 범위 카메라들(high dynamic range cameras)과 같은 이미지 센서들일 수 있다. 일부 실시 예에 서, 센서들은 비-시각적 센서들(non-visual sensors)을 포함한다. 일부 실시 예에서, 센서들은 이미 지 센서 외에도 레이더(RADAR), LiDAR(Light Detection And Ranging), 및/또는 초음파 센서들을 포함한다. 일 부 실시 예에서, 센서들은 차량 제어 모듈을 갖는 차량에 장착(mounted)되지 않는다. 예를 들어, 센서들은 센서 데이터를 캡쳐하기 위한 딥 러닝 시스템의 부분으로서 포함되고 환경 또는 도로에 부착 및/또 는 주변의 차량들에 장착될 수 있다. 일부 실시 예에서, 이미지 전처리기(Image pre-processor)는 센서들의 센서 데이터를 전처리하기 위 해 사용될 수 있다. 예를 들어, 이미지 전처리기는 센서 데이터를 전처리하기 위해, 하나 이상의 구성 요 소들로 센서 데이터를 스플릿(split)하기 위해, 및/또는 하나 이상의 구성 요소들을 후처리 하기 위해 사용될 수 있다. 일부 실시 예에서, 이미지 전처리기는 그래픽 처리 장치(graphics processing unit; GPU), 중앙 처리 장치(central processing unit; CPU), 이미지 신호 프로세서, 또는 전문화된 이미지 프로세서 (specialized image processor)일 수 있다. 다양한 실시 예에서, 이미지 전처리기는 높은 동적 범위 데이 터(high dynamic range data)를 처리하기 위한 톤-맵퍼(tone-mapper) 프로세서일 수 있다. 일부 실시 예에서, 이미지 전처리기는 AI 프로세서의 구성 요소일 수 있다. 일부 실시 예에서, 딥 러닝 네트워크(Deep learning network)는 자율 차량을 제어하기 위한 제어 명령들을 구현하기 위한 딥 러닝 네트워크일 수 있다. 예를 들어, 딥 러닝 네트워크는 센서 데이터를 사용하여 트레 이닝된 컨볼루션 뉴럴 네트워크(CNN)와 같은 인공 뉴럴 네트워크일 수 있고, 딥 러닝 네트워크의 출력은 차량 제어 모듈로 제공된다. 일부 실시 예에서, 인공 지능(AI) 프로세서는 딥 러닝 네트워크를 실행(run)하기 위한 하드웨어 프로 세서일 수 있다. 일부 실시 예에서, AI 프로세서는 센서 데이터에 대하여 컨볼루션 뉴럴 네트워크(CNN)를 통한 추론(Inference)을 수행하기 위한 전문화된 AI 프로세서이다. 일부 실시 예에서, AI 프로세서는 센서 데이터의 비트 깊이(bit depth)를 위해 최적화될 수 있다. 일부 실시 예에서, AI 프로세서는 컨볼루션, 내 적, 벡터 및/또는 행렬 연산들을 포함하는 뉴럴 네트워크의 연산들과 같은 딥 러닝 연산들을 위해 최적화될 수 있다. 일부 실시 예에서, AI 프로세서는 병렬 처리를 효과적으로 수행할 수 있는 복수의 그래픽 처리 장치 (GPU)들을 통해 구현될 수 있다. 다양한 실시 예에서, AI 프로세서는 AI 프로세서가 실행되는 동안 센서(들)로부터 수신된 센서 데이터에 딥러닝 분석을 수행하고, 차량을 적어도 부분적으로 자율적으로 작동하는 데 사용된 머신 러닝 결과를 결정하도록 유발하는 명령어들을 갖는 AI 프로세서를 제공하도록 구성된 메모리에 입출력 인터페이스를 통해 커 플링될 수 있다. 일부 실시 예에서, 차량 제어 모듈(Vehicle Control Module)은 인공 지능(AI) 프로세서 로부터 출력된 차량 제어를 위한 명령들을 처리하고, 차량의 각종 모듈을 제어하기 위해 AI 프로세서 의 출력을 각 차량의 모듈을 제어하기 위한 명령어들로 트랜슬레이트(translate)하기 위해 이용될 수 있다. 일부 실시 예에서, 차량 제어 모듈은 자율 주행을 위한 차량을 제어하기 위해 이용된다. 일부 실시 예에서, 차량 제어 모듈은 차량의 스티어링 및/또는 속력을 조정할 수 있다. 예를 들어, 차량 제어 모듈 은 감속, 가속, 스티어링, 차선 변경, 차선 유지 등의 차량의 주행을 제어하기 위해 사용될 수 있다. 일부 실시 예에서, 차량 제어 모듈은 브레이크 등들(brake lights), 방향 지시등들(turns signals), 헤드라이 트(headlights) 등과 같은 차량 조명(vehicle lighting)을 제어하기 위한 제어 신호들을 생성할 수 있다. 일부 실시 예에서, 차량 제어 모듈은 차량의 사운드 시스템(vehicle's sound system), 차량의 오디오 경고들 (vehicle's audio warnings), 차량의 마이크 시스템(vehicle's microphone system), 차량의 경적 시스템 (vehicle's horn system) 등과 같은 차량 오디오 관련 시스템들을 제어하기 위해 사용될 수 있다. 일부 실시 예에서, 차량 제어 모듈은 의도된 목적지의 접근 또는 잠재적인 충돌(potential collision)과 같은 주행 이벤트들의 승객들 및/또는 운전자를 알리기 위한 경고 시스템들을 포함하는 통지 시스템들 (notification systems)을 제어하기 위해 사용될 수 있다. 일부 실시 예에서, 차량 제어 모듈은 차량의 센 서들과 같은 센서들을 조정하기 위해 사용될 수 있다. 예를 들어, 차량 제어 모듈은 센서들의 지향 방향을 수정(modifying the orientation), 센서들의 출력 해상도 및/또는 포맷 유형을 변화, 캡쳐 비율(capture rate)을 증가 또는 감소, 동적 범위(dynamic range)를 조정, 카메라의 초점을 조정할 수 있다. 또 한, 차량 제어 모듈은 센서들의 동작을 개별적으로 또는 집단적으로 온/오프 시킬 수 있다. 일부 실시 예에서, 차량 제어 모듈은 필터들의 주파수 범위를 수정하거나, 특징들(features) 및/또는 객체 검출을 위한 엣지 검출 파라미터들(edge detection parameter)을 조정하거나, 비트 깊이 및 채널들을 조정 (adjusting channels and bit depth)하는 등과 같은 방식으로 이미지 전처리기의 파라미터들을 변화하기 위해 사용될 수 있다. 다양한 실시 예에서, 차량 제어 모듈은 차량의 자율 주행 및/또는 차량의 운전자-보 조(Driver assistance) 기능을 제어하기 사용될 수 있다. 일부 실시 예에서, 네트워크 인터페이스는 자율 주행 제어 시스템의 블록 구성들과 통신부간의 내부 인터페이스를 담당할 수 있다. 구체적으로, 네트워크 인터페이스는 음성 데이터를 포함하는 데이터를 수신 및/또는 발신하기 위한 의사 소통 인터페이스일 수 있다. 다양한 실시 예에서, 네트워크 인터페이스 는 통신부를 통해 음성 통화들을 연결하거나 문자 메시지들을 수신 및/또는 발신하거나, 센서 데이터를 전 송하거나, 자율 주행 시스템으로 차량의 소프트웨어를 업데이트하거나, 차량의 자율 주행 시스템의 소프트웨어 를 업데이트하기 위하여 외부의 서버들과 연결될 수 있다. 다양한 실시 예에서, 통신부는 셀룰러 또는 WiFi 방식의 다양한 무선 인터페이스를 포함할 수 있다. 예를 들어, 네트워크 인터페이스는 통신부를 통해 접속된 외부 서버로부터 센서들, 이미지 전처리기 , 딥 러닝 네트워크, AI 프로세서, 차량 제어 모듈을 위한 작동 파라미터들 및/또는 명령 어들에 대한 업데이트를 수신하기 위해 사용될 수 있다. 예를 들어, 딥 러닝 네트워크의 머신 러닝 모델은 통신부를 사용하여 업데이트될 수 있다. 또 다른 예시에 따르면, 통신부는 이미지 프로세싱 파라미터 들과 같은 이미지 전처리기의 작동 파라미터들 및/또는 센서들의 펌웨어를 업데이트하기 위해 이용될 수 있다. 다른 실시 예에서, 통신부는 사고 또는 사고가 발생할 뻔한(near-accident) 이벤트에서 긴급 서비스들 (emergency services)과 긴급 연락(emergency contact)을 위한 통신을 활성화시키기 위해 사용될 수 있다. 예 를 들어, 충돌 이벤트에서, 통신부는 도움을 위한 긴급 서비스들을 호출하기 위해 사용될 수 있고, 충돌 세부사항들 및 차량의 위치의 긴급 서비스들을 외부로 알리기 위해 사용될 수 있다. 다양한 실시 예에서, 통신 부는 예상된 도착 시간 및/또는 목적지 위치를 업데이트 하거나 획득할 수 있다. 일 실시 예에 따르면, 도 5에 도시된 자율 주행 시스템은 차량의 전자 장치로 구성될 수도 있다. 일 실시 예에 따르면, 자율 주행 시스템의 AI 프로세서는 차량의 자율 주행 시에 사용자로부터 자율 주행 해 제 이벤트가 발생하면, 자율 주행 해제 이벤트 관련 정보를 딥 러닝 네트워크의 트레이닝 셋 데이터로 입력하도 록 제어함으로써 차량의 자율 주행 소프트웨어를 학습시키도록 제어할 수 있다. 도 6 및 도 7은, 일 실시 예에 따른, 자율 주행 이동체를 나타내는 블록도의 일 예를 도시한다. 도 6을 참조하 면, 본 실시예에 따른 자율 주행 이동체는 제어 장치, 센싱 모듈(604a, 604b, 604c, 604d), 엔진 , 및 사용자 인터페이스를 포함할 수 있다. 자율 주행 이동체는 자율 주행 모드 또는 매뉴얼 모드를 구비할 수 있다. 일 예로, 사용자 인터페이스 를 통해 수신된 사용자 입력에 따라 매뉴얼 모드에서 자율 주행 모드로 전환되거나, 자율 주행 모드에서 매뉴얼 모드로 전환될 수 있다. 이동체가 자율 주행 모드로 운행되는 경우 자율 주행 이동체는 제어 장치의 제어 하에 운행될 수 있다. 본 실시예에서 제어 장치는 메모리와 프로세서를 포함하는 컨트롤러, 센서, 통신 장 치, 오브젝트 검출 장치를 포함할 수 있다. 여기서, 오브젝트 검출 장치는 거리 측정 장치(예, 전자 장치)의 전부 또는 일부의 기능을 수행할 수 있다. 즉, 본 실시 예에서, 오브젝트 검출 장치는 이동체 외부에 위치하는 오브젝트를 검출하기 위한 장치 로, 오브젝트 검출 장치는 이동체 의 외부에 위치하는 오브젝트를 검출하고, 검출 결과에 따른 오브 젝트 정보를 생성할 수 있다. 오브젝트 정보는 오브젝트의 존재 유무에 대한 정보, 오브젝트의 위치 정보, 이동체와 오브젝트와의 거리 정보 및 이동체와 오브젝트와의 상대 속도 정보를 포함할 수 있다. 오브젝트는, 차선, 타 차량, 보행자, 교통 신호, 빛, 도로, 구조물, 과속 방지턱, 지형물, 동물 등을 이동체 의 외부에 위치한 다양한 객체를 포함할 수 있다. 여기서, 교통 신호는 교통 신호등, 교통 표지판, 도로 면에 그려진 문양 또는 텍스트를 포함하는 개념일 수 있다. 그리고, 빛은 타 차량에 구비된 램프에서 생성된 빛 이거나 가로등에서 생성된 빛이거나 태양광일 수 있다. 그리고, 구조물은 도로 주변에 위치하고, 지면에 고정된 물체일 수 있다. 예를 들면, 구조물은, 가로등, 가로수, 건물, 전봇대, 신호등, 다리를 포함할 수 있다. 지형물은, 산, 언덕, 등을 포함할 수 있다. 이러한 오브젝트 검출 장치는 카메라 모듈을 포함할 수 있다. 컨트롤러는 카메라 모듈에서 촬영되는 외부 이미지로부터 객체 정보를 추출하고 이에 대한 정보를 컨트롤러가 처리하도록 할 수 있다. 또한, 오브젝트 검출 장치는 외부 환경을 인식하기 위한 이미징 장치들이 더욱 포함할 수 있다. LIDAR 외 에 RADAR, GPS 장치, 주행 거리 측정 장치(Odometry) 및 기타 컴퓨터 비전 장치, 초음파 센서, 적외선 센서 들 이 이용될 수 있으며, 이들의 장치는 필요에 따라 선택 또는 동시에 동작하여 보다 정밀한 감지가 가능하도록 한다. 한편, 본 발명의 일 실시 예에 따른 거리 측정 장치는 자율 주행 이동체와 오브젝트 사이의 거리를 산출하 고, 자율 주행 이동체의 제어 장치와 연계하여 산출된 거리를 기초로 이동체의 동작을 제어할 수 있 다. 일 예로, 자율 주행 이동체와 오브젝트 간의 거리에 따라 추돌 가능성이 있는 경우, 자율 주행 이동체 는 속도를 낮추거나 또는 정지하도록 브레이크를 제어할 수 있다. 다른 예로, 오브젝트가 이동하는 오브젝 트인 경우, 자율 주행 이동체는 오브젝트와 소정 거리 이상을 유지하도록 자율 주행 이동체의 주행 속도를 제어할 수 있다. 이러한 본 발명의 일 실시 예에 따른 거리 측정 장치는 자율 주행 이동체 의 제어 장치 내의 일 모듈 로 구성될 수 있다. 즉, 제어 장치의 메모리와 프로세서가 본 발명에 따른 추돌 방지 방법을 소 프트웨어적으로 구현하도록 할 수 있다. 또한, 센서는 이동체 내부/외부 환경을 센싱 모듈(604a, 604b, 604c, 604d)와 연결되어 각종 센싱 정보를 획득할 수 있다. 여기서, 센서는 자세 센서(예를 들면, 요 센서(yaw sensor), 롤 센서(roll sensor), 피 치 센서(pitch sensor), 충돌 센서, 휠 센서(wheel sensor), 속도 센서, 경사 센서, 중량 감지 센서, 헤딩 센 서(heading sensor), 자이로 센서(gyro sensor), 포지션 모듈(position module), 이동체 전진/후진 센서, 배터 리 센서, 연료 센서, 타이어 센서, 핸들 회전에 의한 스티어링 센서, 이동체 내부 온도 센서, 이동체 내부 습도 센서, 초음파 센서, 조도 센서, 가속 페달 포지션 센서, 브레이크 페달 포지션 센서, 등을 포함할 수 있다. 이에 따라, 센서는 이동체 자세 정보, 이동체 충돌 정보, 이동체 방향 정보, 이동체 위치 정보(GPS 정보), 이동체 각도 정보, 이동체 속도 정보, 이동체 가속도 정보, 이동체 기울기 정보, 이동체 전진/후진 정보, 배터 리 정보, 연료 정보, 타이어 정보, 이동체 램프 정보, 이동체 내부 온도 정보, 이동체 내부 습도 정보, 스티어 링 휠 회전 각도, 이동체 외부 조도, 가속 페달에 가해지는 압력, 브레이크 페달에 가해지는 압력 등에 대한 센 싱 신호를 획득할 수 있다. 또한, 센서는, 그 외, 가속페달센서, 압력센서, 엔진 회전 속도 센서(engine speed sensor), 공기 유량 센 서(AFS), 흡기 온도 센서(ATS), 수온 센서(WTS), 스로틀 위치 센서(TPS), TDC 센서, 크랭크각 센서(CAS), 등을 더 포함할 수 있다. 이와 같이, 센서는 센싱 데이터를 기초로 이동체 상태 정보를 생성할 수 있다. 무선 통신 장치는 자율 주행 이동체 간의 무선 통신을 구현하기 위해 구성된다. 예를 들어, 사용자의 모바일 폰, 또는 다른 무선 통신 장치, 다른 이동체, 중앙 장치(교통 제어 장치), 서버 등과 자율 주행 이 동체이 통신할 수 있도록 한다. 무선 통신 장치는 무선 신호를 접속 무선 프로토콜에 따라 송수신할 수 있다. 무선 통신 프로토콜은 Wi-Fi, Bluetooth, Long-Term Evolution (LTE), Code Division Multiple Access (CDMA), Wideband Code Division Multiple Access (WCDMA), Global Systems for Mobile Communications (GSM)일 수 있으며, 통신 프로토콜은 이에 제한되지 않는다. 또한 본 실시 예에서 자율 주행 이동체은 무선 통신 장치를 통해 이동체 간 통신을 구현하는 것도 가 능하다. 즉, 무선 통신 장치는 차량 대 차량 간(V2V) 통신(vehicle-to-vehicle communication)으로 도로 상의 다른 이동체 및 다른 이동체들과 통신을 수행할 수 있다. 자율 주행 이동체는 주행 경고, 교통 정보 와 같은 정보를 차량 간 통신으로 통해 송수신할 수 있으며, 다른 이동체 에게 정보를 요청하거나 요청을 수신 하는 것도 가능하다. 예를 들어, 무선 통신 장치는 V2V 통신을 단 거리 통신(DSRC, dedicated short- range communication) 장치 또는 C-V2V(Cellular-V2V) 장치로 수행할 수 있다. 또한 차량 간의 통신 외에 차량 과 다른 사물(예컨대 보행자가 휴대하는 전자 기기 등) 간의 통신(V2X, Vehicle to Everything communicatio n)도 무선 통신 장치를 통해 구현할 수 있다. 본 실시 예에서 컨트롤러는 이동체 내의 각 유닛의 전반적인 동작을 제어하는 유닛으로, 이동체의 제 조사에 의해 제조 시에 구성되거나 또는 제조 후에 자율 주행의 기능 수행을 위해 추가 구성될 수 있다. 또는,제조 시에 구성된 컨트롤러의 업그레이드를 통해 지속적인 부가 기능 수행을 위한 구성이 포함될 수 있다. 이러한 컨트롤러는 ECU(Electronic Control Unit)로 명명될 수도 있다. 컨트롤러는 연결된 센서, 오브젝트 검출 장치, 통신 장치 등으로부터 각종 데이터를 수집 하고, 수집된 데이터를 기반으로 제어 신호를 이동체 내 다른 구성들로 포함된 센서, 엔진, 사용자 인터페이스, 통신 장치, 오브젝트 검출 장치에 전달할 수 있다. 또한, 도시 되지는 않았으나 이 동체의 주행과 관련된 가속 장치, 브레이킹 시스템, 조향 장치, 또는 네비게이션 장치에도 제어 신호를 전달할 수 있다. 본 실시예에서, 컨트롤러는 엔진을 제어할 수 있으며 예를 들어 자율 주행 이동체가 주행 중인 도로의 제한 속도를 감지하고 주행 속도가 제한 속도를 초과하지 않도록 엔진을 제어하거나, 제한 속도를 초과하지 않는 범위 내에서 자율 주행 이동체의 주행 속도를 가속하도록 엔진을 제어할 수 있다. 또한, 컨트롤러는 자율 주행 이동체의 주행 중 자율 주행 이동체 가 차선에 근접하거나 차선을 이탈하고 있다면, 이러한 차선 근접 및 이탈이 정상 주행 상황에 따른 것인지 또는 그 외의 주행 상황에 따른 것인지 판단하며, 판단 결과에 따라 이동체의 주행을 제어하도록 엔진을 제어할 수 있다. 구체적으로, 자 율 주행 이동체는 이동체가 주행 중인 차로의 양 측에 형성된 차선을 검출할 수 있다. 이 경우, 컨트롤러 는 자율 주행 이동체가 차선에 근접하거나 차선을 이탈하고 있는지 여부를 판단하고, 만약, 자율 주 행 이동체가 차선에 근접하거나 차선을 이탈하고 있다고 판단되면 이러한 주행이 정확한 주행 상황에 따른 것인지 또는 그 외의 주행 상황에 따른 것인지 판단할 수 있다. 여기서, 정상 주행 상황의 예로, 이동체의 차로 변경이 필요한 상황일 수 있다. 그리고, 그 외의 주행 상황의 예로, 이동체의 차로 변경이 필요하지 않은 상황 일 수 있다. 만약, 컨트롤러는 이동체의 차로 변경이 필요하지 않은 상황에서 자율 주행 이동체가 차 선에 근접하거나 차선을 이탈하고 있다고 판단되면, 자율 주행 이동체가 차선을 이탈하지 않고 해당 이동 체에서 정상적으로 주행하도록 자율 주행 이동체의 주행을 제어할 수 있다. 이동체의 전방에 다른 이동체 또는 방해물이 존재하는 경우에는 주행 이동체를 감속하도록 엔진 또는 브레 이킹 시스템을 제어할 수 있으며, 속도 외에도 궤적, 운행 경로, 조향 각을 제어할 수 있다. 또는 컨트롤러 는 이동체의 주행 차선, 주행 신호 등 기타 외부 환경의 인식 정보에 따라 필요한 제어 신호를 생성하여 이동체의 주행을 제어할 수 있다. 컨트롤러는 자체적인 제어 신호의 생성 외에 주변 이동체 또는 중앙 서버와의 통신을 수행하고 수신된 정 보를 통해 주변 장치들을 제어하기 위한 명령을 전송함으로써, 이동체의 주행을 제어하는 것도 가능하다. 또한, 컨트롤러는 카메라 모듈의 위치가 변경되거나 화각이 변경될 경우, 본 실시예에 따른 정확한 이동체 또는 차선 인식이 어려울 수 있으므로, 이를 방지하기 위해 카메라 모듈의 캘리브레이션 (calibration)을 수행하도록 제어하는 제어 신호를 생성할 수도 있다. 따라서, 본 실시예에서는 컨트롤러 는 카메라 모듈로 캘리브레이션 제어 신호를 발생시킴으로써, 자율 주행 이동체의 움직임에 따라 발 생되는 진동 또는 충격 등에 의해 카메라 모듈의 장착 위치가 변경되더라도, 카메라 모듈의 정상적인 장착 위치, 방향, 화각 등을 지속적으로 유지할 수 있다. 컨트롤러는 미리 저장된 카메라 모듈의 최 초 장착 위치, 방향, 화각 정보와 자율 주행 이동체의 주행 중에 측정되는 카메라 모듈의 최초 장착 위치, 방향, 화각 정보 등이 임계 값 이상으로 달라질 경우, 카메라 모듈의 캘리브레이션을 수행하도록 제 어 신호를 발생할 수 있다. 본 실시 예에서 컨트롤러는 메모리와 프로세서를 포함할 수 있다. 프로세서는 메모리(72 2)에 저장된 소프트웨어를 컨트롤러의 제어 신호에 따라 실행시킬 수 있다. 구체적으로 컨트롤러는 본 발명에 따른 차선 검출 방법을 수행하기 위한 데이터 및 명령들은 메모리에 저장하고, 명령들은 여기에 개시된 하나 이상의 방법들을 구현하기 위해 프로세서에 의해 실행될 수 있다. 이때, 메모리는 비 휘발성의 프로세서에서 실행 가능한 기록 매체에 저장될 수 있다. 메모리는 적절한 내 외부 장치를 통해 소프트웨어와 데이터를 저장할 수 있다. 메모리는 RAM(random access memory), ROM(read only memory), 하드디스크, 동글과 연결된 메모리 장치로 구성될 수 있다. 메모리는 운영체제(OS, Operating system), 사용자 어플리케이션, 실행 가능한 명령들을 적어도 저장할 수 있다. 메모리는 어플리케이션 데이터, 배열 데이터 구조들도 저장할 수 있다. 프로세서는 마이크로 프로세서 또는 적절한 전자적 프로세서로 컨트롤러, 마이크로 컨트롤러 또는 스테이 트 머신 일 수 있다. 프로세서는 컴퓨팅 장치들의 조합으로 구현될 수 있으며, 컴퓨팅 장치는 디지털 신호 프로세서, 마이크로 프로세서 이거나 이들의 적절한 조합으로 구성될 수 있다. 한편, 자율 주행 이동체는 상술한 제어 장치에 대한 사용자의 입력을 위한 사용자 인터페이스를 더 포함할 수 있다. 사용자 인터페이스는 적절한 상호작용으로 사용자가 정보를 입력하도록 할 수 있다. 예를 들어 터치스크린, 키패드, 조작 버튼 등으로 구현될 수 있다. 사용자 인터페이스는 입력 또는 명령을 컨트롤러에 전송하고, 컨트롤러는 입력 또는 명령에 대한 응답으로 이동체의 제어 동작을 수행할 수 있다. 또한, 사용자 인터페이스는 자율 주행 이동체 외부의 장치로 무선 통신 장치를 통해 자율 주행 이동체와 통신을 수행하도록 할 수 있다. 예를 들어 사용자 인터페이스는 모바일 폰, 태블릿, 또는 기타 컴퓨터 장치와 연동 가능하도록 할 수 있다. 나아가, 본 실시예에서 자율 주행 이동체는 엔진을 포함하는 것으로 설명하였으나, 다른 타입의 추진 시스템을 포함하는 것도 가능하다. 예를 들어 이동체는 전기 에너지로 운행될 수 있으며, 수소 에너지 또는 이 들을 조합한 하이브리드 시스템을 통해 운행될 수 있다. 따라서 컨트롤러는 자율 주행 이동체의 추진 시스템에 따른 추진 메커니즘을 포함하고, 이에 따른 제어 신호를 각 추진 메커니즘의 구성들에 제공할 수 있다. 이하, 도 7을 참조하여 본 실시예에 따른 본 발명에 따른 제어 장치의 세부 구성에 대하여 보다 상세히 설 명한다. 제어 장치는 프로세서를 포함한다. 프로세서는 범용 단일 또는 다중 칩 마이크로프로세서, 전용 마이크로프로세서, 마이크로 제어기, 프로그램가능 게이트 어레이 등일 수도 있다. 프로세서는 중앙 처리 장치 (CPU)로 지칭될 수도 있다. 또한 본 실시예에서 프로세서는 복수의 프로세서들의 조합으로 사용되는 것도 가능하다. 제어 장치는 또한 메모리를 포함한다. 메모리는 전자 정보를 저장할 수 있는 임의의 전자 컴포 넌트일 수도 있다. 메모리 역시 단일 메모리 외에 메모리들의 조합을 포함할 수 있다. 본 발명에 따른 거리 측정 장치의 거리 측정 방법을 수행하기 위한 데이터 및 명령어(722a)들은 메모리에 저장될 수도 있다. 프로세서가 명령어(722a)들을 실행할 때, 명령어(722a)들과 명령의 수행에 필요한 데이 터(722b)의 전부 또는 일부가 프로세서상으로 로딩(724a, 1024b)될 수도 있다. 제어 장치는 신호들의 송신 및 수신을 허용하기 위한 송신기(730a), 수신기(730b) 또는 트랜시버(730c)를 포함할 수도 있다. 하나 이상의 안테나(732a, 732b)들은 송신기(730a), 수신기(730b) 또는 각 트랜시버(730c)에 전기적으로 연결될 수도 있으며 추가적으로 안테나들을 포함할 수도 있다. 제어 장치는 디지털 신호 프로세서(DSP)를 포함할 수도 있다. DSP를 통해 디지털 신호를 이동체 가 빠르게 처리할 수 있도록 할 수 있다. 제어 장치는 통신 인터페이스를 포함할 수도 있다. 통신 인터페이스는 다른 장치들을 제어 장치 와 연결하기 위한 하나 이상의 포트들 및/또는 통신 모듈 들을 포함할 수도 있다. 통신 인터페이스는 사용자와 제어 장치가 상호 작용할 수 있게 할 수 있다. 제어 장치의 다양한 구성들은 함께 하나 이상의 버스들에 의해 연결될 수도 있고, 버스들은 전 력 버스, 제어 신호 버스, 상태 신호 버스, 데이터 버스 등을 포함할 수도 있다. 프로세서의 제어에 따라 구성들은 버스를 통해 상호 정보를 전달하고 목적하는 기능을 수행하도록 할 수 있다. 한편, 다양한 실시 예들에서, 제어 장치는 보안 클라우드와의 통신을 위해 게이트웨이와 관련될 수 있다. 예를 들어, 도 8을 참조하면, 제어 장치는 차량의 구성 요소들 내지 중 적어도 하나로부 터 획득되는 정보를 보안 클라우드에게 제공하기 위한 게이트웨이와 관련될 수 있다. 예를 들면, 게 이트웨이는 제어 장치 내에 포함될 수 있다. 다른 예를 들면, 게이트웨이는 제어 장치과 구별되는 차량 내의 별도의 장치로 구성될 수도 있다. 게이트웨이는 서로 다른 네트워크를 갖는 소프 트웨어 관리 클라우드, 보안 클라우드 및 차 내 보안 소프트웨어에 의해 보안화된 차량 내 네트워크를 통신 가능하도록 연결한다. 예를 들면, 구성 요소은, 센서일 수 있다. 예를 들면, 상기 센서는 차량의 상태 또는 차량 주변 의 상태 중 적어도 하나에 대한 정보를 획득하기 위해 이용될 수 있다. 예를 들면, 구성 요소은, 센서 1410을 포함할 수 있다. 예를 들면, 구성 요소는, ECU(electronic control unit)들일 수 있다. 예를 들면, 상기 ECU들은 엔진 제 어, 변속기의 제어, 에어백의 제어, 타이어 공기압 관리를 위해 이용될 수 있다. 예를 들면, 구성 요소은, 인스트루먼트 클러스터(instrument cluster)일 수 있다. 예를 들면, 상기 인스트 루먼트 클러스터는, 대시 보드(dashboard) 중 운전석 정면에 위치된 패널을 의미할 수 있다. 예를 들면, 상기 인스트루먼트 클러스터는 운전에 필요한 정보를 운전자(또는 탑승자)에게 보여주기 위해 구성될 수 있다. 예를 들면, 상기 인스트루먼트 클러스터는, 엔진의 분당 회전수(RPM, revolutions per minute 또는 rotate per minute)를 지시하기 위한 시각적 요소들, 차량의 속도를 지시하기 위한 시각적 요소들, 잔여 연료량을 지 시하기 위한 시각적 요소들, 기어의 상태를 지시하기 위한 시각적 요소들, 또는 구성 요소을 통해 획득된 정보를 지시하기 위한 시각적 요소들 중 적어도 하나를 표시하기 위해, 이용될 수 있다. 예를 들면, 구성 요소는, 텔레매틱스(telematics) 장치일 수 있다. 예를 들면, 상기 텔레매틱스 장치는, 무선 통신 기술과 GPS(global positioning system) 기술을 결합하여 차량 내에서 위치 정보, 안전 운전 등의 다양한 이동통신 서비스를 제공하는 장치를 의미할 수 있다. 예를 들면, 상기 텔레매틱스 장치는, 운전자, 클라우드(예: 보안 클라우드), 및/또는 주변 환경과 차량을 연결하기 위해 이용될 수 있다. 예를 들 면, 상기 텔레매틱스 장치는, 5G NR 규격의 기술(예: 5G NR의 V2X 기술)을 위해, 고대역폭과 저지연을 지원하도 록, 구성될 수 있다. 옐르 들면, 상기 텔레매틱스 장치는, 차량의 자율 주행을 지원하도록, 구성될 수 있 다. 예를 들면, 게이트웨이는, 차량 내 네트워크와 차량 외 네트워크인 소프트웨어 관리 클라우드와 보안 클라우드를 연결하기 위해 이용될 수 있다. 예를 들면, 소프트웨어 관리 클라우드는, 차량(80 0)의 주행 및 관리에 필요한 적어도 하나의 소프트웨어를 갱신하거나 관리하기 위해 이용될 수 있다. 예를 들면, 소프트웨어 관리 클라우드는, 차량 내에 설치된 차 내 보안 소프트웨어(in-car security software) (810과 연동될 수 있다. 예를 들면, 차 내 보안 소프트웨어은, 차량 내의 보안 기능을 제공하기 위해 이용될 수 있다. 예를 들면, 차 내 보안 소프트웨어은 차량 내 네트워크의 암호화를 위해 외부의 공인된 (authorized) 서버로부터 획득된 암호화 키를 이용하여 차 내 네트워크를 통해 송수신되는 데이터들을 암호화할 수 있다. 다양한 실시 예들에서, 차 내 보안 소프트웨어에 의해 이용되는 상기 암호화 키는, 차량의 식별 정보(차량 번호판, 차 VIN(vehicle identification number)) 또는 사용자 별로 고유하게 부여된 정보(에: 사용 자 식별 정보)에 대응하여 생성될 수 있다. 다양한 실시 예들에서, 게이트웨이는, 상기 암호화 키에 기반하여 차 내 보안 소프트웨어에 의해 암 호화된 데이터들을, 소프트웨어 관리 클라우드 및/또는 보안 클라우드으로 송신할 수 있다. 소프트웨 어 관리 클라우드 및/또는 보안 클라우드는 차 내 보안 소프트웨어의 상기 암호화 키 (Encryption Key)에 의해 암호화된 상기 데이터를 해독할 수 있는 해독 키(Decryption Key)를 이용하여 해독함 으로써, 상기 데이터가 어떤 차량 또는 어떤 사용자로부터 수신된 데이터인지를 식별할 수 있다. 예를 들면, 상 기 해독 키는 상기 암호화 키에 대응되는 고유의 키이기 때문에, 소프트웨어 관리 클라우드 및/또는 보안 클라우드는 상기 해독 키를 통해 해독된 상기 데이터에 기반하여 상기 데이터의 송신 주체(예: 상기 차량 또는 상기 사용자)를 식별할 수 있다. 예를 들면, 게이트웨이는, 차 내 보안 소프트웨어을 지원할 수 있도록 구성되고, 제어 장치와 관련될 수 있다. 예를 들면, 게이트웨이는, 보안 클라우드와 연결된 클라이언트 장치와 제어 장 치 사이의 연결을 지원하기 위해, 제어 장치와 관련될 수 있다. 다른 예를 들면, 게이트웨이는, 보안 클라우드와 연결된 써드 파티 클라우드와 제어 장치 사이의 연결을 지원하기 위해, 제어 장치와 관련될 수 있다. 하지만, 이에 제한되지 않는다. 다양한 실시 예들에서, 게이트웨이는, 차량의 운영 소프트웨어를 관리하기 위한 소프트웨어 관리 클 라우드와 차량을 연결하기 위해 이용될 수 있다. 예를 들면, 소프트웨어 관리 클라우드는, 차량 의 운영 소프트웨어의 갱신이 요구되는지 여부를 모니터링하고, 차량의 운영 소프트웨어의 갱신이 요 구됨을 모니터링하는 것에 기반하여 게이트웨이를 통해 차량의 운영 소프트웨어를 갱신하기 위한 데 이터를 제공할 수 있다. 다른 예를 들면, 소프트웨어 관리 클라우드는, 차량의 운영 소프트웨어의 갱 신을 요구하는 사용자 요청을 차량으로부터 게이트웨이를 통해 수신하고, 상기 수신에 기반하여 차량의 운영 소프트웨어를 갱신하기 위한 데이터를 제공할 수 있다. 하지만, 이에 제한되지 않는다. 도 9는, 일 실시예에 따른, 학습 데이터의 세트에 기반하여 뉴럴 네트워크를 트레이닝하는 전자 장치의 동 작을 설명하기 위한 도면이다. 도 9를 참고하면, 동작에서, 일 실시예에 따른, 전자 장치는 학습 데이터의 세트를 획득할 수 있다. 전자 장치는 지도 학습(supervised learning)을 위한 학습 데이터의 세트를 획득할 수 있다. 학습 데이터는, 입력 데 이터 및 상기 입력 데이터에 대응하는 기저 진리(ground truth) 데이터의 페어(pair)를 포함할 수 있다. 기저 진리 데이터는, 상기 기저 진리 데이터의 페어인 입력 데이터를 수신한 뉴럴 네트워크로부터 획득하고자 하는 출력 데이터를 나타낼 수 있다. 예를 들어, 이미지의 인식을 위해 뉴럴 네트워크를 트레이닝하는 경우, 학습 데이터는 이미지 및 상기 이미지에 포함된 하나 이상의 피사체들에 대한 정보를 포함할 수 있다. 상기 정보는, 이미지를 통해 식별가능한 피사체의 분류(category 또는 class))를 포함할 수 있다. 상기 정보는, 이미지 내에서, 피사체에 대응하는 시각적 객체의 위치, 너비, 높이 및/또는 사이즈를 포함할 수 있다. 동작를 통해 식별되는 학습 데이터의 세트는, 복수의 학습 데이터의 페어들을 포함할 수 있다. 이미지의 인식을 위해 뉴럴 네트워크를 트레이닝하는 상기 예시 내에 서, 전자 장치에 의해 식별되는 학습 데이터의 세트는, 복수의 이미지들 및 상기 복수의 이미지들 각각에 대응 하는 기저 진리 데이터를 포함할 수 있다. 도 9를 참고하면, 동작에서, 일 실시예에 따른, 전자 장치는, 학습 데이터의 세트에 기반하여, 뉴럴 네트 워크에 대한 트레이닝을 수행할 수 있다. 뉴럴 네트워크가 지도 학습에 기반하여 트레이닝되는 일 실시예에서, 전자 장치는 학습 데이터에 포함된 입력 데이터를, 상기 뉴럴 네트워크의 입력 레이어에 입력할 수 있다. 상기 입력 레이어를 포함하는 뉴럴 네트워크의 일 예가, 도 10을 참고하여 설명된다. 입력 레이어를 통해 상기 입력 데이터를 수신한 뉴럴 네트워크의 출력 레이어로부터, 전자 장치는 상기 입력 데이터에 대응하는 상기 뉴럴 네 트워크의 출력 데이터를 획득할 수 있다. 일 실시예에서, 동작의 트레이닝은, 상기 출력 데이터 및, 상기 학습 데이터에 포함되고, 상기 입력 데이 터에 대응하는 기저 진리 데이터 사이의 차이에 기반하여, 수행될 수 있다. 예를 들어, 전자 장치는 경사 하강 알고리즘(gradient descent)에 기반하여, 상기 차이가 감소되도록 상기 뉴럴 네트워크와 관련된 하나 이상의 파 라미터들(예, 도 13을 참고하여 후술되는 가중치)을 조절할 수 있다. 상기 하나 이상의 파라미터들을 조절하는 전자 장치의 동작은, 뉴럴 네트워크에 대한 튜닝으로 지칭될 수 있다. 전자 장치는, 출력 데이터에 기반하는 뉴 럴 네트워크의 튜닝을, 비용 함수(cost function)와 같이, 뉴럴 네트워크의 성능을 평가하기 위해 정의된 함수 를 이용하여 수행할 수 있다. 상술된 출력 데이터 및 기저 진리 데이터 사이의 차이는, 상기 비용 함수의 일 예 로 포함될 수 있다. 도 9를 참고하면, 동작에서, 일 실시예에 따른, 전자 장치는 동작에 의해 트레이닝된 뉴럴 네트워크 로부터, 유효한 출력 데이터가 출력되는지 여부를 식별할 수 있다. 출력 데이터가 유효하다는 것은, 출력 데이 터 및 기저 진리 데이터 사이의 차이(또는 비용 함수)가, 상기 뉴럴 네트워크의 사용을 위해 설정된 조건을 만 족함을 의미할 수 있다. 예를 들어, 출력 데이터 및 기저 진리 데이터 사이의 차이의 평균 값 및/또는 최대 값 이 지정된 임계 값 이하인 경우, 전자 장치는, 유효한 출력 데이터가 뉴럴 네트워크로부터 출력되는 것으로 결 정할 수 있다. 뉴럴 네트워크로부터 유효한 출력 데이터가 출력되지 않는 경우(906-아니오), 전자 장치는 동작에 기반하 는 뉴럴 네트워크의 트레이닝을 반복적으로 수행할 수 있다. 실시예가 이에 제한되는 것은 아니며, 전자 장치는 동작들(902, 904)을 반복적으로 수행할 수 있다. 뉴럴 네트워크로부터 유효한 출력 데이터를 획득한 상태에서(906-예), 동작에 기반하여, 일 실시예에 따른, 전자 장치는 트레이닝된 뉴럴 네트워크를 사용할 수 있다. 예를 들어, 전자 장치는 학습 데이터로써 상기 뉴럴 네트워크에 입력되었던 입력 데이터와 구분되는 다른 입력 데이터를, 뉴럴 네트워크로 입력할 수 있다. 상 기 다른 입력 데이터를 수신한 뉴럴 네트워크로부터 획득된 출력 데이터를, 전자 장치는 뉴럴 네트워크에 기반 하여 상기 다른 입력 데이터에 대한 추론을 수행한 결과로써 이용할 수 있다. 도 10은, 일 실시예에 따른, 전자 장치의 블록도이다. 도 10을 참고하면, 전자 장치의 프로세서는, 메모리에 저장된 뉴럴 네트워크와 관련된 계산들(computations)을 수행할 수 있다. 프로세서는, CPU(center processing unit), GPU(graphic processing unit) 또는 NPU(neural processing unit) 중 적어도 하나를 포함할 수 있다. NPU는, CPU와 분리된칩으로 구현되거나, 또는 SoC(system on a chip)의 형태로 CPU와 같은 칩에 집적될(integrated) 수 있다. CPU 에 집적된 NPU는, 뉴럴 코어 및/또는 AI(artificial intelligence) 가속기로 지칭될 수 있다. 도 10을 참고하면, 프로세서는, 메모리에 저장된 뉴럴 네트워크를 식별할 수 있다. 뉴럴 네 트워크는, 입력 레이어(Input ayer), 하나 이상의 히든 레이어들(Hidden layers)(또는 중간 레이어들(Intermediate layers) 및 출력 레이어(Output layers)의 결합을 포함할 수 있다. 상술된 레이 어들(예, 입력 레이어, 하나 이상의 히든 레이어들 및 출력 레이어)은, 복수의 노드들을 포 함할 수 있다. 히든 레이어들의 개수는, 실시예에 따라 다를 수 있으며, 복수의 히든 레이어들을 포함하는 뉴럴 네트워크가 딥(deep) 뉴럴 네트워크로 지칭될 수 있다. 상기 딥 뉴럴 네트워크를 트레이닝 하는 동작이, 딥 러닝(deep learning)으로 지칭될 수 있다. 일 실시예에서, 뉴럴 네트워크가 피드 포워드 뉴럴 네트워크(feed forward neural network)의 구조를 가 지는 경우, 특정 레이어에 포함된 제1 노드는, 상기 특정 레이어 이전의 다른 레이어에 포함된 제2 노드들 전부 와 연결될 수 있다. 메모리 내에서, 뉴럴 네트워크를 위해 저장된 파라미터들은, 상기 제2 노드들 과 상기 제1 노드 사이의 연결들에 할당된(assigned) 가중치(weight)들을 포함할 수 있다. 피드 포워드 뉴럴 네 트워크의 구조를 가지는 뉴럴 네트워크에서, 상기 제1 노드의 값은, 상기 제2 노드들 및 상기 제1 노드를 연결하는 연결들에 할당된 가중치들에 기반하는, 상기 제2 노드들에 할당된 값들의 가중 합(weighted sum)에 대 응할 수 있다. 일 실시예에서, 뉴럴 네트워크가 콘볼루션(convolution) 뉴럴 네트워크의 구조를 가지는 경우, 특정 레이 어에 포함된 제1 노드는, 상기 특정 레이어 이전의 다른 레이어에 포함된 제2 노드들 중 일부에 대한 가중 합에 대응할 수 있다. 상기 제1 노드에 대응하는 상기 제2 노드들 중 일부는, 상기 특정 레이어에 대응하는 필터에 의해 식별될 수 있다. 메모리 내에서, 뉴럴 네트워크를 위해 저장된 파라미터들은, 상기 필터를 나 타내는 가중치들을 포함할 수 있다. 필터는, 상기 제2 노드들 중에서, 상기 제1 노드의 가중합을 계산하는데 이 용될 하나 이상의 노드들, 및 상기 하나 이상의 노드들 각각에 대응하는 가중치들을 포함할 수 있다. 일 실시예에 따른, 전자 장치의 프로세서는, 메모리에 저장된 학습 데이터 세트를 이용 하여, 뉴럴 네트워크에 대한 트레이닝을 수행할 수 있다. 학습 데이터 세트에 기반하여, 프로세서 는 도 9를 참고하여 설명된 동작을 수행하여, 뉴럴 네트워크를 위해 메모리에 저장된 하나 이상의 파라미터들을 조절할 수 있다. 일 실시예에 따른, 전자 장치의 프로세서는, 학습 데이터 세트에 기반하여 트레이닝된 뉴럴 네트워크를 이용하여, 객체 탐지, 객체 인식 및/또는 객체 분류를 수행할 수 있다. 프로세서는, 카 메라를 통해 획득된 이미지(또는 비디오)를, 뉴럴 네트워크의 입력 레이어에 입력할 수 있다. 이미지가 입력된 입력 레이어에 기반하여, 프로세서는 뉴럴 네트워크에 포함된 레이어 들의 노드들의 값들을 순차적으로 획득하여, 출력 레이어의 노드들의 값들의 세트(예, 출력 데이터)를 획 득할 수 있다. 상기 출력 데이터는, 뉴럴 네트워크를 이용하여 상기 이미지에 포함된 정보를 추론한 결과 로써 이용될 수 있다. 실시예가 이에 제한되는 것은 아니며, 프로세서는, 통신 회로를 통해 전자 장치에 연결된 외부 전자 장치로부터 획득된 이미지(또는 비디오)를, 뉴럴 네트워크에 입력할 수 있 다. 일 실시예에서, 이미지를 처리하기 위해 트레이닝된 뉴럴 네트워크는, 상기 이미지 내에서, 피사체에 대 응하는 영역을 식별하거나(객체 탐지), 및/또는 상기 이미지 내에 표현된 피사체의 클래스를 식별(객체 인식 및 /또는 객체 분류)하는데 이용될 수 있다. 예를 들어, 전자 장치는 뉴럴 네트워크를 이용하여, 상기 이미지 내에서, 상기 피사체에 대응하는 영역을, 바운딩 박스와 같은 사각형의 형태에 기반하여 분할(segment) 할 수 있다. 예를 들어, 전자 장치는 뉴럴 네트워크를 이용하여, 복수의 지정된 클래스들 중에서, 상기 피사체에 매칭되는 적어도 하나의 클래스를 식별할 수 있다. 이하의 실시예들은 도 1 내지 도 10의 장치 또는 장치의 구성요소, 도 1 내지 도 10에 설명된 기능, 방법, 절차 에 기반하여 구현될 수 있다. 최근 블랙박스 보급이 보편화되면서, 카메라를 통한 영상 및 차량주행정보를 저장하는 본래의 기능과 함께 첨단 운전자 보조 시스템(Advanced Driver Assistance Systems: ADAS) 기능들과AI 주차 녹화와 같이 영상정보를 활 용하는 제품들이 출시되고 있다. 또한, 최근에는 기존의 애프터 마켓(After Market) 제품이던 블랙박스가, 자동 차의 순정 기능으로 탑재되고 있고, 그에 따라 블랙박스의 비중과 블랙박스에 구비된 카메라의 기능을 활용하기위한 연구가 계속되고 있다. 특히, 전기차와 자율주행 차량들이 등장하면서 자동차의 전력 문제가 해결되고, 자율주행에 필요한 다수의 카메 라 센서들을 통합하려는 움직임에 따라, 블랙박스는 단순 저장장치가 아니라 자율주행을 구현하는 수단의 일부 로 활용하려는 요구가 대두하고 있다. 차량 주행에 있어 카메라를 이용한 영상취득장치는 스마트 크루즈 기능과 같이 주행 중 원거리 피사체 인식하여 차량의 속도를 조절하고, 차선을 인식하여 차선 유지 장치를 동작하도록 하는 등 차량의 기본 기능으로 활용되 고 있다. 또한, 근거리의 피사체를 인식하기 위하여 화각이 넓은 카메라들을 이용하여 전방의 보행자를 인식하 고 후/측방의 사물을 인식하는 기술이 점점 더 빠르고 정확해지고 있다. 이와 같이 자율주행 레벨(Level) 2에 필요한 카메라들은 자율주행 레벨 3 이상에서는 차량 운행에 필요한 통합 제어기의 형태로 진화되고 있는데, 블랙박스는 이러한 통합 과정에서 반드시 필요하고, 또한 차량용ADAS 카메라 와 중첩되지 않는 기능들을 제공할 필요가 있다. 이에 블랙박스를 포함한 다수의 카메라로부터 얻어지는 영상정 보와 다른 센서들(Radar, LiDAR)로부터 획득되는 정보들은, 차량운행을 위하여 통합되고, 자율주행에 필요한 V2X의 정보 송/수신에 사용될 필요가 있다. 많은 차량에서 얻어지는 정보들을 초고속 통신망을 통해 정보들을 전송하고, 공유하게 될 경우 자율주행 레벨 4 에 필요한V2X 기술들을 준비해 나갈 수 있을 것으로 예상된다. 그러나 이러한 V2X를 위해 필요한 정보들을 어떻 게 수집하고 어떻게 사용해야 할지에 대한 방안은 마련되어 있지 않다. 특히 자율주행을 위해 차량의 주행 환경 을 파악하기 위해서 통상 차량 내에 8 개 이상의 카메라, 레이더, 라이다 및 초음파 센서로부터의 데이터가 필 요한데, 이로부터 얻어진 데이터들은 주행을 위한 사물 인식과 판단 및 제어에 사용된 이후 대부분의 데이터는 소멸된다. 따라서 본 실시예에서는, 차량 내의 여러 센서들로부터 획득되는 데이터들을 통합하고, 이를 가공하여 자율주행 에 필요한 데이터베이스를 생성하기 위한 방안을 제안한다. 일 실시예에서는, 차량 내의 블랙박스의 카메라 및 레이더(Radar)/라이다(LiDAR)와 같은 센서를 통해 인식된 객 체에 대하여 해당 차량의 주행 위치를 기준으로 상대 좌표를 생성하고, 이 데이터르 서버에게 송신하고 서버는 각 차량별로 수신되는 데이터들을 종합하여 각 객체들의 절대 좌표를 생성하여, 도로 전체의 상황에 대한 협력 적 지능형 교통 시스템에서 (Cooperative-Intelligent Transport Systems: C-ITS)에서 데이터를 처리하는 방안 을 제안한다. 본 실시예의 주요 개념은, 도로 상의 각 차량들은 카메라 블랙박스의 카메라 및 레이더(Radar)/라이다(LiDAR)와 같은 센서를 통하여 외부 차량의 상대 좌표를 획득하고, 상기 획득한 외주 차량의 상대 좌표와 자신의 절대 좌 표를 서버(또는 교통정보센터)로 송신하고, 서버는 각 차량들로부터 획득한 각 차량의 절대 좌표 및 외부 차량 들의 상대 좌표들을 이용하여 도로 상의 차량들의 절대 좌표를 생성하는 것이다. 특히, 서버와 통신이 불가능한 비통신 차량들의 절대 좌표를 통신 차량들이 인식한 비통신 차량들의 상대 좌표들을 조합하여 생성할 수 있다. 또한, 일 실시예에서, 차량 번호가 인식된 차량에 대하 고유 식별자를 생성하고, 고유 식별자가 부여된 차량에 대해 절대 좌표를 생성하여, 차량 번호의 중복에 의하여 생길 수 있는 에러를 방지한다. 상술한 본 실시예의 기 본 개념에 기초하여 이하에서 일 실시예를 설명한다. 도 11은 일 실시예에 따른 지능형 교통 시스템의 일 예를 설명하는 도면이다. 도 11을 참조하면, 지능형 교통 시스템은, 교통 정보 센터, 노변 기지국(Road Side Unit)(RSU)(1120a, 1120b) 및 도로 위의 차량들(1130a, 1130b, 1130c 등)을 포함한다. 교통 정보 센터은 차량 들로부터 수 신된 데이터를 통합 관리하는 서버의 역할을 할 수 있다. 따라서 '서버'로 칭해질 수 있다. RSU(Road Side Unit)(1120a, 1120b)는 차량들과 무선으로 통신을 수행할 수 있고, 서버와 유/무선 통신을 수행할 수 있 는 인프라 장치로써, 기지국 또는 중계국이 될 수 있으며, 그 형태에 특별히 제한을 두지는 않는다. 차량들(1130a, 1130b, 1130c 등)은 카메라 및 레이더/라이더 센서 등을 이용하여 다른 차량, 도로, 신호등, 표 지판 또는 보행자 등과 같은 차량들(1130a, 1130b, 1130c 등)의 주행에 영향을 주는 주변 객체를 검출하고, 상 기 검출된 주변 객체의 정보를 획득할 수 있다. 상기 주변 객체의 정보는 자기 차량(ego-vehicle)을 기준으로 한 상대 좌표를 포함할 수 있다. 또한, 주변 객체의 정보는, 상기 자기 차량(ego-vehicle)dl 상기 주변 객체를 식별할 수 있는 정보, 일 예로, 상기 주변 객체가 차량이면, 상기 검출된 주변 객체가 차량임을 나타내는 객체 식별자(Object Identifier)와 해당 차량의 번호판 정보를 포함할 수 있다. 도 11에서는, 도로 상을 주행하는 자기 차량(ego vehicle)은, 자기 차량의 주변에 위치하는 주변 차량들의 식별 정보와 상기 주변 차량의 위치만을 상대 좌표의 정보로 서버로 전송하는 것을 설명하였으나, 이는 설명의 편의를 위한 것일 뿐 자기 차량(ego-vehicle)의 통행에 영향을 주는 다른 객체들에 대한 식별 정보와 그 객체들 의 상대 위치 정보도 서버로 전송할 수 있다. 도 11을 참고하면, 일 실시 예에서 서버는 도로 상을 주행 중인 차량들의 상대 위치 정보를 용이하게 측 정하기 위해, 도로 주변에 미리 설치된 RSU(1120a, 1120b)의 위치를 정보를 절대 위치 좌표로 설정하는 것이 바 람직하다. 시간의 흐름에 따라 도로 상을 주행 중인 차량의 위치는 계속 가변되나, RSU(1120a, 1120b)의 위치는 고정되어 있으므로, 서버는 도로 상에 위치한 RSU들(1120a, 1120b)의 위치 정보를 사전에 획득하고, 해당 RSU(1120a, 1120b)로부터 차량들(1130a, 1130b, 1130c 등)의 상대적인 위치를 확인하고, 시간에 따른 차량들 (1130a, 1130b, 1130c 등)의 위치를 추적하는 것도 가능할 것이다. 차량들(1130a, 1130b, 1130c 등)은 상기 식별된 주변 객체의 정보와 함께 자기 차량의 정보를 RSU(1120a, 1120b)를 통해 서버에게 송신할 수 있다. 상기 자기 차량의 정보는, 일 예로, 자기 차량의 절대 좌표를 포함할 수 있다. 절대 좌표는 GPS 정보에 의한 자기 차량의 위도, 경도 정보가 될 수 있다. 자기 차량의 정보는 자기 차량의 차량 번호판 정보를 포함할 수 있다. 통상적으로 자기 차량의 정보는 차량에 저장되지 않는 것이 일반적이지만, 일 실시예에서 자기 차량의 차량 번호 정보가 차량에 미리 저장되어 서버에게 송신될 수 있다. 또한, 자기 차량의 정보는, 자기 차량의 네비게이션 정보와 같이 차량의 이동 목적지, 이동 방향, 속력 등의 주행 정보를 포함할 수 있고, 자기 차량의 차량 타입 또는 차종 정보를 포함할 수도 있다. 서버는 각 차량들(1130a, 1130b, 1130c 등)로부터 자기 차량의 정보 및 외부 객체의 정보를 수신하고, 수 신한 정보들을 이용하여 통합된 교통 정보를 생성할 수 있다. 상기 통합된 교통 정보는, 외부의 차량, 보행자, 신호등 또는 도로의 공사, 사고 등의 상태에 대한 정보를 포함할 수 있다. 상기 통합된 교통 정보는 '통합 교통 객체 정보' 또는 '통합 객체 정보' 등의 용어로 칭해질 수 있다. 이하에서는 도로 상의 차량들의 정보에 중점을 두는 의미에서 '통합 객체 정보'라는 용어로 사용하기로 한다. 통합 객체 정보를 생성하는 일 예로, 서버는 각 차량들(1130a, 1130b, 1130c 등)로부터 수신한 객체들(즉, 차량들)의 번호판 정보를 이용하여, 각 차량들(1130a, 1130b, 1130c 등)의 고유 식별자를 생성할 수 있다. 또한, 서버는 각 차량들(1130a, 1130b, 1130c 등)로부터 수신한 객체들(즉, 차량들)의 절대 좌표 및 상대 좌표를 이용하여, 도로 상의 차량들에 대한 절대 좌표를 결정할 수 있다. 즉, 각 차량들(1130a, 1130b, 1130c 등)로부터 수신한 자기 차량의 번호 정보 또는 외부 차량의 번호 정보들을 종합하여, 차량의 번호가 식별된 차량에 대해 고유 식별자를 생성할 수 있다. 또한, 상기 차량의 절대 좌표는 각 차량들(1130a, 1130b, 1130c 등)이 송신한 자기 차량의 정보에 포함된 절대 좌표 및/또는 외부 객체의 정보 에 포함된 외부 객체의 상대 좌표에 기초하여 생성될 수 있다. 도로 위의 차량들 중에는 서버와 통신을 수행할 수 있어 자신의 절대 좌표를 송신할 수 있는 차량도 있고, 통신을 수행하지 못하는 차량도 있다. 통신을 수행하지 못하는 차량의 절대 좌표는, 통신을 수행할 수 있는 다른 차량들 인식한 외부 객체의 상대 좌표를 종 합하여 생성될 수 있다. 참고로, 상기 고유 식별자는 일 예로, 범용 고유 식별자(Universally Unique Identifier: UUID)가 사용될 수 있다. 참고로, 상기 UUID는 네트워크 상에서 서로 모르는 개체들을 식별하고 구별하기 위해서 해당 개체에 고유 한 식별자를 부여할 수 있는 기술이다. 일반적으로, 시스템 상에서 개체 식별자의 고유성을 보장하려면 중앙 관 리 시스템에서 각 개체마다 고유의 일련번호를 부여하고 관리하는 것이 바람직하지만, 컴퓨터 네트워크와 같이 복수 개의 주체들 간에 여러 개체들 간에 동시 다발적인 데이터 송수신이 발생하는 환경에서는, 중앙에서 일괄 적으로 관리하는 것은 실시간 처리 면에서 불리할 수 있다. 특히, 도로 네트워크와 같이, 실시간 객체 인식을 수행하고, 인식된 객체의 정보를 고려하여, 자율 주행 또는 운전자 보조 시스템을 제공해야 하는 차량 플랫폼에 서는 중앙 집중적인 시스템보다는 네트워크에 연결된 각 주체마다 독립적으로 서로를 구분하기 위한 고유 식별 자를 할당하고, 이를 통해 상대방을 식별하는 것이 바람직할 것이다. 예컨대, 상기 UUID는 이러한 비집중화된 네트워크 환경에서 네트워크에 연결된 각 주체가 서로를 용이하게 식별 하기 위한 용도로 만들어졌으며, ITU(International Telecommunication Union), OSF (Open Software Foundation)과 같은 국제 단체에서 표준으로 사용하고 있다. 한편, 고유 식별자가 부여된 차량에 대해서, 서버는 해당 차량의 절대 좌표를 예측 또는 추적할 수 있다. 따라서 해당 차량이 다른 차량에게 인식될 수 있는 한도에서 이미 부여된 고유 식별자는 유지될 수 있다. 예를들어, 고유 식별자가 부여된 차량이 통신을 수행할 수 없는 차량인 경우, 해당 차량은 자신의 차량 번호를 서버 에게 제공할 수 없다. 그러나 다른 차량들이 지속적으로 해당 차량의 차량 번호를 인식하여 해당 차량의 차량 번호를 서버에게 제공할 수 있다. 또는, 차량 번호의 인식률의 문제로 해당 차량 번호의 인식이 어 렵더라도 차량이 운행 중인 한도에서 차량의 존재는 다른 차량들에 이행 인식될 수 있으므로, 지속적으로 해당 차량의 상대 좌표는 서버에게 제공될 수 있다. 따라서, 일단 고유 식별자가 부여된 차량에 대해서, (차량 번호 인식률 등의 문제로 인하여) 다른 차량이 해당 차량의 번호를 지속적으로 인식할 수 없는 경우라도, 다른 차량들에 의해 해당 차량의 존재가 인식되어 해당 차 량의 상대 좌표가 지속적으로 서버에게 송신되고 있다면, 서버는 이미 고유 식별자가 부여된 해당 차량의 위치를 예측 또는 추적하고 있었기 때문에, 지속적으로 보고되는 상대 좌표와 서버가 예측한 차량 의 절대 좌표를 비교할 수 있다. 이렇게 하여 차량 번호 없이 상대 좌표가 보고되는 차량이 해당 차량인지 여부 를 결정할 수 있고, 또한, 해당 차량의 절대 좌표도 추정할 수 있다. 다만, 고유 식별자가 부여된 차량이라도, 일단 운행을 종료하여 다른 차량들에 의해 인식될 수 없다면 고유 식별자는 유지되지 않을 수 있다. 한편, 서버는 자기 차량 정보에 포함된 자기 차량의 주행 정보, 차량의 타입/차종 정보에 기초하여 각 차 량들의 고유 식별자 별 주행 정보 및/또는 차량 정보를 생성할 수 있다. 즉, 서버와 통신할 수 있는 각 차량들 이 송신한 자기 차량의 주행 정보 및 차량 정보에 기초하여, 각 차량들의 주행 정보 및 차량 정보를 생성할 수 있다. 또한, 각 차량들의 주행 정보들을 통합하여 서버와 통신할 수 없는 차량에 대한 주행 정보(예: 차량 속도 등)도 추정할 수 있다. 상술한 바에 따라 서버는 각 차량들(1130a, 1130b, 1130c 등)로부터 수집한 정보들에 기초하여, 통합 교 통 정보(또는 통합 객체 정보)를 생성할 수 있다. 이후, 이 정보 중 적어도 일부를 각 차량들(1130a, 1130b, 1130c 등) 중 적어도 일부에게 송신할 수 있다. 도 11의 예에서는 교통정보센터가 RSU(1120a)를 통하여 교통 정보를 차량(1130b)에게 제공하고, 차량(1130b)은 이웃한 차량과 사이드 링크(side link)를 통하여 차량 (1130c) 등에게 정보를 중계하는 상황이 도시되었다. 위의 설명에서는 주로 하나의 차량이 외부 객체로써 다른 차량들만을 인식하고, 이에 대한 정보를 서버에 게 송신하는 예가 설명되었다. 그러나 각 차량들(1130a, 1130b, 1130c 등) 외부 객체로써 보행자, 가로등, 교통 사고 발생 등의 발생도 인식하고, 상술한 상대 좌표 정보를 서버에게 송신할 수 있다. 서버는 특히, 이러한 정보들을 종합하여, 도로의 교통 상황, 즉, 도로의 차선 별 평균 속도, 사고 정보, 신호등 인식 정보 등의 통계화된 C-ITS 데이터를 실시간으로 생성하여 각 차량들에게 제공할 수 있다. 이하에서는 상술한 내용에 기초하여, 각 차량들의 정보를 통합 관리하는 구체적인 예를 설명한다. 도 12는 일 실시예에 따라 차량 데이터를 처리하는 일 예를 설명하는 도면이다. 도 12에서는, 도로에 4개의 차량들(A, B, C, D)이 운행 중이고, 각 차량들에는 복수 개의 카메라, 예를 들어, 적어도 전방 카메라 및 후방 카메라가 구비되어 있어서, 외부의 사물들을 인식할 수 있다. 또한, 레이다/라이다 와 같은 센서를 구비하여 차량 외부의 사물들의 해당 차량에 대한 상대좌표를 구할 수 있다. 또한, 각 차량들은 RSU(Road Side Unit: RSU) 또는 다른 차량을 경유하여(예: 사이드 링크) 기지국과 연결되어 무선 통신을 통하여 서버(미도시)와 통신할 수 있다고 가정한다. 일 실시예에서, 각 차량들은 카메라, 라이다/레이더 등의 센서를 이용하여 외부 차량을 인식하고, 인식된 외부 차량의 상대 좌표를 획득할 수 있다. 도 12를 참조하면, 차량 A는 후방 카메라를 이용하여 후방의 차량 B 및 차량 D의 차량 번호 들을 인식하고, 차량 A를 기준으로 차량 B 및 차량 D의 상대 좌표를 획득할 수 있다. 차량 B는 전방 카메라를 이용하여 전방의 차량 A 및 차량 D의 차량 번호들을 인식하고, 차량 B를 기준으로 차량 A 및 차량 D의 상대 좌표를 획득할 수 있다. 차량 C는 후방 카메라 를 이용하여 후방의 차량 B 및 차량 D의 차량 번호들을 인식하고 해당 차량들의 상대 좌표를 획득 할 수 있다. 차량 D는 전방 카메라를 이용하여 차량 A 및 차량 C의 차량 번호를 인식하고, 각 차량들의 상대 좌표를 획득할 수 있다. 또한, 차량 D는 후방 카메라를 이용하여 차량 B의 차량 번호를 인식하고, 차량 B의 상대 좌표를 획득할 수 있다. 여기서, 차량 A, 차량 B 및 차량 C은 '서버와 통신 가능한 차량(통신 차량)'이고, 차량 D은 '통신이 불가능한 차량(=비통신 차량)'으로 가정할 수 있다. 차량 A, 차량 B 및 차량 C는 자신의 절대 좌표를 서버에게 송신할 수 있지만, 차량 D(124 0)는 자신의 절대 좌표를 서버에게 송신할 수 없다. 따라서 차량 D의 절대 좌표는 다른 차량들(A, B, C) 이 각 차량들(A, B, C)을 기준으로 획득한 차량 D의 상대 좌표들의 정보에 기초하여 결정하여야 한다. 서 버는 이렇게 통신 차량들(A, B, C)로부터 수신한 비통신 차량(D)의 상대 좌표들과 차량 번호 정보를 이용하여 비통신 차량 D에 고유 식별자를 부여하고, 또한, 비통신 차량 D의 절대 좌표도 결정할 수 있게 된 다. 구체적으로, 서버는 차량 C의 절대 좌표와 차량 C를 기준으로 \"제1 차량 번호\"를 갖는 차량의 상대 좌표를 수신할 수 있다. 또한, 서버는 차량 B의 절대 좌표와 차량 B를 기준으로 제1 차량 번호를 갖는 차량의 상대 좌표를 수신한다. 서버는 차량 C 및 차량 B로부터 수신한 정보를 종합하면, 상기 \"제1 차량 번호\"를 갖는 차량(=차량 D가 된다.)의 절대 좌표를 획득할 수 있다. 즉, 이론적으로 두 개의 차량으로부터 수신한 정보를 이용하면 비통신 차량의 절대 좌표를 알 수 있다. 다만, 절대 좌표의 정확도를 높 이기 위해서 정보들의 출처가 되는 차량들의 개수는 많을수록 좋을 것이다. 이러한 점을 고려할 때, 차량의 절대 좌표의 정확도가 낮아질 가능성이 큰 경우, 예를 들어, 차량들의 평균 속 도가 매우 빠르거나, 단위 면적당 차량들의 밀집도가 큰 경우, 또는 차량의 종류가 이륜차(오토바이)인 경우, 비통신 차량의 절대 좌표는 더 많은 개수의 통신 차량들로부터 수신한 정보들을 종합하여 결정하도록 설정될 수 있다. 한편, 도 11에서 설명된 것처럼, 각 차량들의 차량 번호가 확인되면 차량 번호로부터 해당 차량의 고유 식별자 를 생성하고, 차량 번호 대신 고유 식별자로 차량을 식별할 수도 있다. 차량 번호 대신에 고유 식별자를 사용하 는 이유는, 경우에 따라 행정상의 실수로 서로 다른 차량이 동일한 차량 번호를 가지는 경우가 있기 때문이다. 즉, 이 경우, 서울에 있는 제네시스 차량의 차량 번호와 부산의 BMW 차량의 차량 번호가 동일할 수가 있는데, 이러한 경우 통합 교통 정보 생성 시 오류가 생기는 원인이 될 수 있다. 또한, 도 11에서 상술한 것처럼, 서버는 종합 교통 정보를 생성할 때 각 차량들의 절대 좌표와, 통신 차량들의 주행 정보 등을 추가로 고려할 수 있다. 이 경우, 전체 통신 차량 및 비통신 차량의 현재 절대 좌표는 물론 통 신 차량 및 비통신 차량들의 일정 시간 경과 이후의 절대 좌표, 차량 속도, 운행 방향 등을 예측할 수 있기 때 문에, 전체 도로는 물론 세부적인 차선 별 진행 속도 등도 예측할 수 있다. 따라서 더 상세하고 정확도 높은 종 합 교통 정보를 생성하고, 이를 각 차량들에게 제공할 수 있다. 도 13은 일 실시예에 따라 차량 내의 전자 장치의 동작을 설명하는 도면이다. 차량 내의 전자 장치는 외부 객체를 인식하고 외부 객체(들)의 정보를 획득할 수 있다(S1310). 상기 외부 객체 의 정보는 자기 차량을 기준으로 한 상대 좌표를 포함할 수 있다. 또한, 외부 객체의 정보는 상기 외부 객체를 식별할 수 있는 정보, 일 예로, 상기 외부 객체가 차량이면 차량 번호판 정보를 포함할 수 있다. 차량 내의 전자 장치는 상기 외부 객체의 정보와 함께 자기 차량의 정보를 서버에게 송신할 수 있다(S1320). 상 기 자기 차량의 정보는, 일 예로, 자기 차량의 절대 좌표를 포함할 수 있다. 절대 좌표는 GPS 정보에 의한 자기 차량의 위도, 경도 정보가 될 수 있다. 자기 차량의 정보는 자기 차량의 차량 번호판 정보를 포함할 수 있다. 통상적으로 자기 차량의 정보는 차량에 저장되지 않는 것이 일반적이지만, 일 실시예에서 자기 차량의 차량 번 호 정보가 차량에 미리 저장되어 서버에게 송신될 수 있다. 또한, 자기 차량의 정보는, 자기 차량의 네비게이션 정보와 같이 차량의 이동 목적지, 이동 방향, 속력 등의 주행 정보를 포함할 수 있고, 자기 차량의 차량 타입 또는 차종 정보를 포함할 수도 있다. 차량 내의 전자 장치는 서버에서 생성된 통합 교통 정보(또는 통합 객체 정보)를 수신할 수 있고(S1330), 수신 한 정보를 주행에 반영할 수 있다(S1340). 도 14는 일 실시예에 따라 서버 내의 전자 장치의 동작을 설명하는 도면이다. 서버 내의 전자 장치는 각 차량들로부터 자기 차량의 차량 정보 및 외부 객체의 정보를 수신하고(S1410), 수신 한 정보들에 기초하여 통합 객체 정보(=통합 교통 정보)를 생성할 수 있다(S1420). 또한, 생성된 통합 객체 정 보 중 적어도 일부를 차량들 중 적어도 일부에게 송신할 수 있다(S1430). 상기 자기 차량의 정보는, 일 예로, 자기 차량의 절대 좌표를 포함할 수 있다. 절대 좌표는 GPS 정보에 의한 자 기 차량의 위도, 경도 정보가 될 수 있다. 자기 차량의 정보는 자기 차량의 차량 번호판 정보를 포함할 수 있다. 또한, 자기 차량의 정보는, 자기 차량의 네비게이션 정보와 같이 차량의 이동 목적지, 이동 방향, 속력등의 주행 정보를 포함할 수 있고, 자기 차량의 차량 타입 또는 차종 정보를 포함할 수도 있다. 상기 통합 객체 정보는, 외부의 차량, 보행자, 신호등 또는 도로의 공사, 사고 등의 상태에 대한 정보를 포함할 수 있다. 통합 객체 정보를 생성하는 일 예로, 서버는 각 차량들로부터 수신한 객체들(즉, 차량들)의 번호판 정보를 이용 하여, 각 차량들의 고유 식별자를 생성할 수 있다. 또한, 서버는 각 차량들로부터 수신한 객체들(즉, 차량들)의 절대 좌표 및 상대 좌표를 이용하여, 도로 상의 차량들에 대한 절대 좌표를 결정할 수 있다. 즉, 각 차량들부터 수신한 자기 차량의 번호 정보 또는 외부 차량의 번호 정보들을 종합하여, 차량의 번호가 식 별된 차량에 대해 고유 식별자를 생성할 수 있다. 또한, 상기 차량의 절대 좌표는 각 차량들이 송신한 자기 차 량의 정보에 포함된 절대 좌표 및/또는 외부 객체의 정보에 포함된 외부 객체의 상대 좌표에 기초하여 생성될 수 있다. 도로 위의 차량들 중에는 서버와 통신을 수행할 수 있어 자신의 절대 좌표를 송신할 수 있는 차 량도 있고, 통신을 수행하지 못하는 차량도 있다. 통신을 수행하지 못하는 차량의 절대 좌표는, 통신을 수행할 수 있는 다른 차량들 인식한 외부 객체의 상대 좌표를 종합하여 생성될 수 있다. 도 15는 본 발명의 일 실시 예에 따라 도로 네트워크를 주행 중인 자기 차량(ego vehicle)이 자기 차량의 절대 좌표 정보와 주변 차량의 상대 좌표 정보를 획득하는 예를 설명하기 위한 도면이다. 도 15를 참고하면, 도로 주변에는 RSU 1 ~ RSU 5가 설치되어 있으며, 각 RSU들(RSU 1 ~ RSU 5)은 서버에 의해 관리된다. 예컨대, 서버의 프로세서는 도로에 설치된 RSU들을 식별하기 위한 식별자(Identification)(ID)를 각 RSU 마다 할당하고, 각 RSU마다 할당된 ID를 각 RSU가 설치된 위치 정보에 매핑하여 메모리에 저장할 수 있다. 또한, 서버의 프로세서는 네트워크 인터페이스를 통해 각 RSU들(RSU 1 ~ RSU 5)과 통신을 수행할 수 있다. 그리고, 서버의 프로세서는 각 RSU의 커버리지(coverage)내에 차량이 진입하거나 진출할 때마다 RSU를 통해 차량과 무선으로 연결될 수 있다. 구체적으로, 서버의 프로세서는 RSU의 커버리지에 진 입한 차량이 서비스 제공 요청(자율 주행 서비스 요청, 주행 보조 정보 제공 서비스 요청, 주행 안내 정보 제공 요청 등)이 수신되면, 서비스를 요청한 차량이 위치한 RSU 커버리지를 통해 상기 서비스 요청 차량의 서빙 RSU 를 식별하고, 상기 서비스 요청 차량을 식별하기 위한 차량 식별자를 생성하고, 상기 생성된 차량 식별자에 해 당하는 차량으로 서비스 제공을 위한 정보를 전달한다. 다시 도 15를 참고하면, 도로를 주행 중인 자기 차량(ego vehicle)(1520-1), 그 주변 차량들(1520-2, 1520-3, 1520-4, 1520-5, 1520-6) 및 도로에 설치된 RSU들(1500, 1502, 1504, 1506 및 1508)이 도시된다. 그리고, 도 15에서 참조번호 1570a는 자기 차량(ego vehicle)(1520-1)의 주행 방향(driving direction)과 동일한 방향을 나타내며, 참조번호 1570b는 자기 차량(ego vehicle)(1520-1)의 주행 방향 (driving direction)과 반대인 방향을 나타낸다. 그리고, 서버의 프로세서는 서비스를 요청한 자기 차량(ego vehicle)(1520-1)의 서빙 RSU인 RSU 2의 위치 정보와 자기 차량(ego vehicle)(1520-1)의 위치 정보를 이용하여(based on), 자기 차량(ego vehicle)(1520-1)의 절대 좌표(absolute coordinates) 정보를 획득한다. 예컨대, 서버의 프로세서(155 2)는 자기 차량(ego vehicle)(1520-1)의 서빙 RSU인 RSU 2의 위치 정보와 자기 차량(ego vehicle)(1520- 1)의 위치 정보를 아래의 <표 1>와 같이 매핑하여 메모리에 절대 좌표 정보로 저장할 수 있다. 표 1 절대 좌표 정보 필드 설명(Description) RSU 위치 정보 RSU ID, RSU의 위도, 경도 정보 자기 차량의 위치 정보 자기 차량이 측위하여 전송한 자기 차량의 위도, 경 도 정보(GPS 위치 정보) 상기 <표 1>에서 RSU 위치 정보는, 서버의 프로세서가 RSU 마다 할당된 ID 및 위치 정보를 통해 사 전에 획득할 수 있는 정보로, 도로 네트워크에 변화가 없는 한 변하지 않는 고정된 정보이며, 자기 차량의 위치 정보는, RSU를 통해 자기 차량으로부터 수신된 이후에 획득이 가능한 정보로, 자기 차량의 위치에 따라 가변되 는 정보이다. 그리고, 서버의 프로세서는 서비스를 요청한 자기 차량(ego vehicle)(1520-1)의 위치 및 자기 차량(ego vehicle)(1520-1)의 서빙 RSU 정보를 근거로, 자기 차량(ego vehicle)(1520-1)의 절대 위치를 생성한 후에, 생성된 절대 위치를 이용하여 자기 차량(ego vehicle)(1520-1)의 주변에 위치한 이웃 차량들 (1520-2, 1520-3, 1520-4, 1520-5, 1520-6)의 상대 위치(자기 차량(ego vehicle)(1520-1)으로부터의 상대적인 위치)를 계산하기 위해 자기 차량(ego vehicle)(1520-1)의 주변이 위치한 도로 네트워크 상에 가상의 메쉬 네트 워크(virtual mesh network)인 가상의 상대 좌표계(virtually relative coordinate system)를 생성한다. 본 발명의 일 실시 예에서는, 자기 차량(ego vehicle)(1520-1)의 주변에 위치한 모든 이웃 차량들(1520-2, 1520-3, 1520-4, 1520-5, 1520-6)의 상대 위치를 계산할 수도 있으며, 자기 차량(ego vehicle)(1520-1)의 진행 방향(1570a)과 동일한 진행 방향을 갖는 이웃 차량들(1520-2, 1520-3, 1520-4)이 위치한 도로 네트워크에 대해 서만 상대 위치를 계산할 수도 있다. 본 발명에서 절대 좌표 (absolute coordinate) 정보는, 도로 상에 이미 설치되어 그 위치 정보가 고정된 RSU의 위치 정보, 전체 도로 네트워크를 기준으로 해당 RSU의 절대적인 위치를 나타내는 정보를 나타내고, 가상의 상 대 좌표(virtually relative coordinate) 정보는, 절대 좌표로 설정된 RSU의 커버리지 내에 존재하는 차량들 간의 상대적인 위치를 나타내는 좌표로, 자기 차량(ego vehicle)을 기준점(0, 0)으로, 그 기준점으로부터 상대 차량들의 상대적인 위치를 나타내는 정보를 나타낸다. 그리고, 서버의 프로세서는 본 발명의 실시 예에 따라 상기 절대 좌표 정보와 상기 가상의 상대 좌 표 정보를 메모리에 저장하고, 자기 차량(ego vehicle)의 위치가 변경될 때마다 상기 메모리에 저 장된 상기 절대 좌표 정보와 상기 가상의 상대 좌표 정보를 갱신할 수 있다. 도 16은 일 실시 예에 따라 자기 차량(ego vehicle)의 절대 좌표와 상대 좌표를 획득하는 방식을 설명하기 위한 도면이다. 도 16을 참고하면, 자기 차량(ego vehicle)은 서빙 RSU를 기준으로, 전역 범위(global range)의 절대 좌표를 생성하고, 자신의 중심 차량의 전장 중심과 전폭 중심의 교점)을 원점(0, 0)으로 설정하고, x 축 (x-axis)과 y축(y-axis)의 가상의 좌표계(virtual coordinate system)을 생성한다. 이때 일 실시 예에 따라 가상의 좌표계의 최대 범위는, 자기 차량의 서빙 RSU의 커버리지에 해당하 는 영역 또는 서빙 RSU을 기준으로, 도로 네트워크 상에서 자기 차량의 전방 영역 일부와 후방 영 역 일부를 포함하는 거리로 설정할 수 있으나, 본 발명은 이에 한정되지 않는다. 다시 도 16에서, 자기 차량은 원점(0, 0)을 기준으로, 주변의 차량들의 위치를 가상의 상대 좌표계 (virtually relative coordinate system) 상에서 계산할 수 있다. 구체적으로, 자기 차량은 차량의 위치를 +x 방향(오른쪽)으로 1차로 떨어진 지점에 위치함을 식별 하고, 차량의 위치를 원점(0, 0)을 기준으로, 1사분면에 위치함을 식별하고, 차량의 위치를 +y 방 향(위쪽)으로 소정 거리만큼 떨어진 지점(0, +y/top)에 위치함을 식별하고, 차량의 위치를 원점(0, 0)을 기준으로, 3사분면에 위치함을 식별하고, 차량의 위치를 -y 방향(아래 쪽)으로 소정 거리만큼 떨어진 지 점(0, -y/bottom)에 위치함을 식별할 수 있다. 도 16에 도시된 방식으로, 자기 차량의 위치를 원점(기준점)으로 하여, 주변 차량들(1611, 1612, 1613, 1614, 1615)의 위치를 측정할 경우, 자기 차량으로부터 정확한 상대적인 위치를 측위하는 것이 어려울 수 있다. 따라서, 일 실시 예에서는, 자기 차량의 위치를 원점(기준점)으로 하여, 일정한 크기를 갖는 사각형 형태 의 가상의 메쉬 네트워크(virtual mesh network) 형태의 가상 좌표계를 생성할 수 있다. 도 17은 일 실시 예에 따라 자기 차량의 위치를 원점(기준점)으로 생성된 사각형 형태의 가상의 메쉬 네 트워크(virtual mesh network) 좌표계에 도시한 도면이다. 도 17을 참조하면, 자기 차량은, 차량의 위치를 가상의 메쉬 네트워크 좌표계 상에서 (+1, 0)로 식 별하고, 차량의 위치를 가상의 메쉬 네트워크 좌표계 상에서 (+1, +2)로 식별하고, 차량의 위치를 가상의 메쉬 네트워크 좌표계 상에서 (0, +3)로 식별하고, 차량의 위치를 가상의 메쉬 네트워크 좌표계 상에서 (0, -2)에 위치함을 식별하고, 차량의 위치를 가상의 메쉬 네트워크 좌표계 상에서 (-1, -1)에 위 치함을 식별할 수 있다. 도 17에서, 참조번호 1720은, 가상의 메쉬 네트워크 좌표계를 구성하는 하나의 셀을 나타낸 것으로, 정사각형 또는 직사각형으로 구성될 수 있으며, 각 국가의 도로 폭에 따라 상이하게 구성될 수 있다. 예컨대, 가상의 메쉬 네트워크 좌표계를 구성하는 하나의 셀의 가로 폭을 5m 및 세로 폭을 5m 설정하거나, 가로 폭을 3m로, 세로 폭을 5m 로 설정할 수도 있다. 본 발명의 일 실시 예에 따르면, 자기 차량(ego vehicle)은 상술한 자신에 대한 절대 좌표 정보와 주변 차량들(1611, 1612, 1613, 1614, 1615)에 대한 상대 좌표 정보를 획득한 후, 서빙 RSU을 통해 서버 로 전송할 수 있다. 서버는, 상기 서빙 RSU을 통해 자기 차량(ego vehicle)의 절대 좌표 정보와 주변 차량들에 대한 상대 좌표 정보를 수신하면, 상기 자기 차량(ego vehicle)과 주변 차량 들(1611, 1612, 1613, 1614, 1615)에 대한 정보를 추적할 수 있다. 그리고, 일 실시 예에서는, 자기 차량(ego vehicle)의 주변 차량들(1611, 1612, 1613, 1614, 1615)에 대 한 상대 좌표 정보를 자기 차량의 전자 장치가 계산하는 것으로 설명하였으나, 서버의 프로세서 가 자기 차량(ego vehicle)의 주변 차량들(1611, 1612, 1613, 1614, 1615)에 대한 상대 좌표 정보 를 계산하고, 그 계산 결과를 자기 차량으로 통지할 수도 있다. 또한, 본 발명의 일 실시 예에 따른 자기 차량(ego vehicle)과 주변 차량들(1611, 1612, 1613, 1614, 1615)에 대한 상대 좌표 정보는 아래의 <표 2>와 같은 데이터를 포함할 수 있다. 표 2 Field Description 자기 차량 ID(Ego vehicle ID) 자기 차량 식별 정보(고유 정보) 시간 정보 상대 좌표 정보 생성 시간 주변 차량 ID 자기 차량 주변 차량 식별 정보(임시 정보) 상대 좌표 정보 주변 차량 ID에 해당하는 상대 좌표 정보 그리고, 자기 차량(ego vehicle)은, 상기 <표 2>의 상대 좌표 정보와 함께, 주변 차량 ID에 해당하는 센싱 정보 등도 함께 메모리에 저장하거나, 서빙 RSU를 통해 서버로 전송할 수 있다. 구체적으로, 자치 차량은 아래의 <표 3>과 같이 주변 차량들에 대한 상대 좌표 정보와 함께 상기 주변 차량들에 대한 센싱 정보를 생성하여 저장할 수 있다. 표 3 Field Description 자기 차량 ID(Ego vehicle ID) 자기 차량 식별 정보(고유 정보) 시간 정보 상대 좌표 정보 생성 시간 주변 차량 ID 자기 차량 주변 차량 식별 정보(임시 정보) 상대 좌표 정보 주변 차량 ID에 해당하는 상대 좌표 정보 센싱 정보 주변 차량을 센싱한 센서의 특성에 해당하는 센싱 데 이터 1) Vision sensor : 주변 차량에 대한 이미지 프레임 2) Lidar sensor: 주변 차량에 대한 Point cloud 데 이터 3) Radar sensor: 주변 차량에서 반사되어 수신된 Radar 신호 정보 도 18은 일 실시 예에 따른 자기 차량(ego vehicle)의 동작 흐름도이다. 자기 차량(ego vehicle) 은 주행이 시작되면(S1805), 현재 서빙 RSU ID를 식별한다(S1810). 그리고, 자기 차량(ego vehicle)은 식별된 서빙 RSU ID의 위치 정보를 식별하고(S1815), 자신의 위치 정보를 획득한다(S1820). S1820단계에 서 자기 차량(ego vehicle)은 GPS 신호 등을 이용하여 자신의 위치 정보를 식별할 수 있다. 상기 S1820단계에서 자신의 위치 정보를 식별한 자기 차량(ego vehicle)은 서빙 RSU의 위치 정보와 자신의 위치 정보를 이용하여 절대 좌표를 설정하고(S1825), 상기 설정된 절대 좌표를 기준으로 가상의 상대 좌 표계를 생성한다(S1830). 그리고, 자기 차량(ego vehicle)은 상기 가상의 상대 좌표계가 생성되면, 상기 자기 차량(ego vehicle)의 주변에 위치한 주변 차량들을 상기 설정된 상대 좌표계 상에서 식별하고(S1835), 상기 식별된주변 차량에 대한 임시 식별자를 할당하고(S1840), 상기 임시 식별자가 할당된 주변 차량을 상기 설정된 상대 좌표계에 매핑한다(S1845). 자기 차량(ego vehicle)은 상기 매핑된 주변 차량의 상대 좌표 정보를 획득하고(S1850), 상기 절대 좌표 정보와 상기 주변 차량에 대한 상대 좌표 정보를 서버로 전송하고(S1855), 상기 주변 차량의 상대 좌표의 변화 에 따라 상기 주변 차량의 미래 움직임을 예측한다(S1860). 그리고, 자기 차량(ego vehicle)은 상기 S1860단계에서 예측되는 주변 차량의 미래 움직임을 고려하여, 자율 주행(autonomous driving)을 위한 차량 동작(스티어링 휠 조절, 브레이킹, 가속 등의 차량 움직임을 제어 하기 위한 신호 발생)을 제어한다(S1865). 또한, S1865단계에서 자기 차량(ego vehicle)은 차량의 자동화 레벨 (automation level)이 제한적 조건의 자율 주행 또는 운전자 보조 정보를 제공할 수 있는 기능만 구현이 가능한 경우에는, 상기 예측된 주변 차량의 미래 움직임을 고려하여, 운전자에게 운전 보조(driving assistance) 정보 를 제공할 수 있다. 구체적으로, 자기 차량(ego vehicle)은 S1865단계에서 차량 동작을 제어하기 위해 차량에 장착된 LiDAR, Radar, Computer vision, 고정밀 지도 중 적어도 하나를 이용하여 자기 차량(ego vehicle) 주변 상황을 인식하고, 딥 러닝/머신 러닝 모델을 이용하여 주변 상황에 존재하는 객체들을 식별하고, 추적할 수 있다. 자기 차량(ego vehicle)은 주행이 완료되었는지를 식별하고(S1870), 주행이 완료되었다면(S1870의 \"예\"), 절대 좌표 정보와 상대 좌표 정보를 반환(S1875)하고, 주행이 완료되지 않았다면(S1870의 \"아니오\"), S1865단계 에서 차량 동작 제어를 계속 수행한다. 그리고, 상기 S1870의 단계는, 사용자의 입력/조작에 의해 식별될 수 있다. 도 18의 동작은, 자기 차량(ego vehicle)의 전자 장치가 수행하는 것으로 설명하였으나, 이는 일 실시 예 에 불과할 뿐, 도 18의 단계 자기 차량의 서빙 RSU ID를 식별하는 단계(S1815단계), 자기 차량의 위치 정보를 획득하는 단계(S1820 단계), 자기 차량의 절대 좌표를 설정하는 단계(S1825단계), 가상의 상 대 좌표계를 설정하는 단계(S1830 단계), 자기 차량의 주변에 위치한 주변 차량을 식별하는 단계(S1835단 계), 상기 자기 차량의 주변 차량에 대한 임시 식별자를 할당하는 단계(S1840단계), 상기 임시 식별자가 할당된 주변 차량을 상기 상대 좌표계에 매핑하는 단계(S1845단계), 상기 상대 좌표계에 매핑된 주변 차량에 대 한 상대 좌표계 정보를 획득하는 단계 (S1850단계), 상기 획득된 주변 차량에 대한 상대 좌표계 정보를 이용하 여, 상기 주변 차량의 미래 움직임을 예측하는 단계 (S1860단계), 상기 예측된 주변 차량의 미래 움직임을 고려 하여 차량 동작 제어를 위한 제어 명령을 생성하는 단계(S1865단계)는 서버의 프로세서에서 수행될 수도 있다. 물론, 서버의 프로세서가 S1815단계, S1820 단계, S1825단계, S1830 단계, S1835단계, S1840단계, S1845단계, S1850단계, S1860단계, S1865단계를 수행하기 위해서는, 자기 차량에 대한 원격에서의 차량 운행 제어 서비스가 가능해야만 할 것이다. 상술한 본 발명에서는, 자기 차량(ego vehicle)이 서버와 통신하기 위한 무선 액세스를 제공하는 주체로, RSU를 설명하였지만, 이는 일 실시 예에 불과할 뿐, eNode B, AP(Access Point)와 같은 air interface를 제공 할 수 있는 다른 entity들까지 포함될 수 있음은 당연할 것이다. 지금까지 설명된 실시예들에 따라, 통신 차량(예: 자율주행 차량)과 비통신 차량(비자율주행 차량)이 공존하는 도로 상황에서, 통신 차량이 인식하여 서버에 제공하는 비 통신 차량의 정보들을 이용하여 비통신 차량들의 위 치와 주행 정보를 추적 및 예측할 수 있어 안정적이고 정확한 지능형 교통 시스템을 구축할 수 있다. 본 명세서에서 개시된 차량용 전자장치, 차량 서비스 제공 서버, 사용자 단말 장치의 기능, 방법, 절차의 실시 예들은 소프트웨어를 통해 실행될 수 있다. 상기 각 기능, 방법, 절차의 구성 수단들은 필요한 작업을 실행하는 코드 세그먼트들이다. 프로그램 또는 코드 세그먼트들은 프로세서 판독 가능 매체에 저장되거나 전송 매체 또는 통신망에서 반송파와 결합된 컴퓨터 데이터 신호에 의하여 전송될 수 있다. 컴퓨터가 읽을 수 있는 기록매체는 컴퓨터 시스템에 의하여 읽혀질 수 있는 데이터가 저장되는 모든 종류의 기 록 장치를 포함한다. 컴퓨터가 읽을 수 있는 기록 장치의 예로는, ROM, RAM, CD-ROM, DVD±ROM, DVD-RAM, 자기 테이프, 플로피 디스크, 하드 디스크(hard disk), 광데이터 저장장치 등이 있다. 또한 컴퓨터가 읽을 수 있는 기록매체는 네트워크로 연결된 컴퓨터 장치에 분산되어 분산방식으로 컴퓨터가 읽을 수 있는 코드가 저장되고"}
{"patent_id": "10-2023-0101682", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "실행될 수 있다.이상에서 설명한 본 발명은, 본 발명이 속하는 기술분야에서 통상의 지식을 가진 자에 있어 본 발명의 기술적 사상을 벗어나지 않는 범위 내에서 여러 가지 치환, 변형 및 변경이 가능하므로 전술한 실시예 및 첨부된 도면 에 의해 한정되는 것이 아니다. 또한 본 문서에서 설명된 실시예들은 한정되게 적용될 수 있는 것이 아니라, 다 양한 변형이 이루어질 수 있도록 각 실시예들의 전부 또는 일부가 선택적으로 조합되어 구성될 수도 있다."}
{"patent_id": "10-2023-0101682", "section": "도면", "subsection": "도면설명", "item": 1, "content": "이하의 도면은 본 명세서의 구체적인 일례를 설명하기 위해 작성되었다. 도면에 기재된 구체적인 장치의 명칭이 나 구체적인 신호/메시지/필드의 명칭은 예시적으로 제시된 것이므로, 본 명세서의 기술적 특징이 이하의 도면 에 사용된 구체적인 명칭에 제한되지 않는다. 도 1은 일 실시 예에 따른 차량 서비스 시스템을 나타내는 블록도이다. 도 2는 일 실시예에 따른 차량용 전자장치를 나타내는 블록도이다. 도 3은 일 실시예에 따른 차량 서비스 제공 서버를 나타내는 블록도이다. 도 4는 일 실시예에 따른 사용자 단말 장치의 블록 구성도이다. 도 5는 차량의 자율 주행 시스템을 도시한 블록도이다. 도 6 및 도 7은, 일 실시 예에 따른, 자율 주행 이동체를 나타내는 블록도의 일 예를 도시한다. 도 8은 차량의 구성요소들을 나타내는 도면이다.도 9는, 일 실시예에 따른, 학습 데이터의 세트에 기반하여 뉴럴 네트워크를 트레이닝하는 전자 장치의 동 작을 설명하기 위한 도면이다. 도 10은, 일 실시예에 따른, 전자 장치의 블록도이다. 도 11은 일 실시예에 따른 지능형 교통 시스템의 일 예를 설명하는 도면이다. 도 12는 일 실시예에 따라 차량 데이터를 처리하는 일 예를 설명하는 도면이다. 도 13은 일 실시예에 따라 차량 내의 전자 장치의 동작을 설명하는 도면이다. 도 14는 일 실시예에 따라 서버 내의 전자 장치의 동작을 설명하는 도면이다. 도 15는 본 발명의 일 실시 예에 따라 도로 네트워크를 주행 중인 자기 차량(ego vehicle)이 자기 차량의 절대 좌표 정보와 주변 차량의 상대 좌표 정보를 획득하는 예를 설명하기 위한 도면이다. 도 16은 일 실시 예에 따라 자기 차량(ego vehicle)의 절대 좌표와 상대 좌표를 획득하는 방식을 설명하기 위한 도면이다. 도 17은 일 실시 예에 따라 자기 차량의 위치를 원점(기준점)으로 생성된 사각형 형태의 가상의 메쉬 네 트워크(virtual mesh network) 좌표계 도시한 도면이다. 도 18은 일 실시 예에 따른 자기 차량(ego vehicle)의 동작 흐름도이다."}
