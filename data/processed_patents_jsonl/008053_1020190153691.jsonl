{"patent_id": "10-2019-0153691", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2021-0064928", "출원번호": "10-2019-0153691", "발명의 명칭": "전자장치와 그의 제어방법, 및 기록매체", "출원인": "삼성전자주식회사", "발명자": "박지훈"}}
{"patent_id": "10-2019-0153691", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "전자장치에 있어서,음성 수신부와;상기 음성 수신부를 통해 수신되는 사용자 음성의 문자 구간을 변환한 인식 문자를 획득하고,상기 획득된 인식 문자와의 혼동 가능성에 기초하여 획득한 복수의 후보 문자 중 상기 문자 구간과의 음향 특징관련 유사도가 높은 후보 문자를 상기 문자 구간의 발화 문자로 인식하는프로세서를 포함하는 전자장치."}
{"patent_id": "10-2019-0153691", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 프로세서는,상기 음성 수신부를 통해 수신되는 사용자 음성을 문자열로 변환하고,상기 문자열을 문자 별로 분할하는 전자장치."}
{"patent_id": "10-2019-0153691", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,상기 프로세서는,상기 문자열의 문자 간 휴지구간이 존재하는지를 분석하는 전자장치."}
{"patent_id": "10-2019-0153691", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서,상기 프로세서는,상기 휴지구간이 존재하는 인식 문자의 혼동 가능성에 낮은 가중치를 부여하는 전자장치."}
{"patent_id": "10-2019-0153691", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서,메모리를 더 포함하며,상기 프로세서는,상기 후보 문자의 인식 결과에 대한 이력정보를 상기 메모리에 저장하는 전자장치."}
{"patent_id": "10-2019-0153691", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5항에 있어서,상기 프로세서는,상기 복수의 후보 문자에 대해 혼동행렬을 기초로 혼동확률을 검출하는 전자장치."}
{"patent_id": "10-2019-0153691", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6항에 있어서,공개특허 10-2021-0064928-3-상기 프로세서는,상기 후보 문자의 인식 결과에 대한 이력정보를 기초로 상기 혼동행렬을 업데이트하는 전자장치."}
{"patent_id": "10-2019-0153691", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1항에 있어서,상기 프로세서는,기저장된 복수의 후보 문자의 음향특징모델을 기초로 상기 문자 구간의 음향 특징과의 유사도를 검출하는 전자장치."}
{"patent_id": "10-2019-0153691", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서,상기 프로세서는,상기 후보 문자의 인식 결과에 대한 이력정보를 기초로 상기 음성특성모델을 업데이트하는 전자장치."}
{"patent_id": "10-2019-0153691", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제1항에 있어서,상기 프로세서는,상기 복수의 후보 문자에 대해 혼동행렬을 기초로 검출한 혼동확률과 기저장된 복수의 후보 문자의 음향특징모델을 기초로 검출한 상기 문자 구간의 음향 특징과의 유사도를 적용하여 보정확률을 검출하는 전자장치."}
{"patent_id": "10-2019-0153691", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "전자장치의 제어방법에 있어서,음성 수신부를 통해 수신되는 사용자 음성의 문자 구간을 변환한 인식 문자를 획득하는 단계와;상기 획득된 인식 문자와의 혼동 가능성에 기초하여 획득한 복수의 후보 문자 중 상기 문자 구간과의 음향 특징관련 유사도가 높은 후보 문자를 상기 문자 구간의 발화 문자로 인식하는 단계를 포함하는 전자장치의제어방법."}
{"patent_id": "10-2019-0153691", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항에 있어서,상기 음성 수신부를 통해 수신되는 사용자 음성을 문자열로 변환하고,상기 문자열을 문자 별로 분할하는 단계를 더 포함하는 전자장치의 제어방법."}
{"patent_id": "10-2019-0153691", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제12항에 있어서,상기 문자열의 문자 간 휴지구간이 존재하는지를 분석하고, 상기 휴지구간이 존재하는 인식 문자의 혼동 가능성에 낮은 가중치를 부여하는 단계를 더 포함하는 전자장치의제어방법."}
{"patent_id": "10-2019-0153691", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제11항에 있어서,상기 후보 문자의 인식 결과에 대한 이력정보를 저장하는 단계를 더 포함하는 전자장치의 제어방법."}
{"patent_id": "10-2019-0153691", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "공개특허 10-2021-0064928-4-제14항에 있어서,상기 복수의 후보 문자에 대해 혼동행렬을 기초로 혼동확률을 검출하는 단계를 더 포함하는 전자장치의 제어방법."}
{"patent_id": "10-2019-0153691", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제15항에 있어서,상기 후보 문자의 인식 결과에 대한 이력정보를 기초로 상기 혼동행렬을 업데이트하는 단계를 더 포함하는 전자장치의 제어방법."}
{"patent_id": "10-2019-0153691", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제11항에 있어서,기저장된 복수의 후보 문자의 음향특징모델을 기초로 상기 문자 구간의 음향 특징과의 유사도를 검출하는 단계를 더 포함하는 전자장치의 제어방법."}
{"patent_id": "10-2019-0153691", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제11항에 있어서,상기 복수의 후보 문자에 대해 혼동행렬을 기초로 검출한 혼동확률과 기저장된 복수의 후보 문자의 음향특징모델을 기초로 검출한 상기 문자 구간의 음향 특징과의 유사도를 적용하여 보정확률을 검출하는 단계를 더 포함하는 전자장치의 제어방법."}
{"patent_id": "10-2019-0153691", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "컴퓨터에 의해 실행되는 컴퓨터 프로그램이 저장되는, 컴퓨터 판독 가능 기록매체에 있어서,상기 컴퓨터 프로그램은,음성 수신부를 통해 수신되는 사용자 음성의 문자 구간을 변환한 인식 문자를 획득하고,상기 획득된 인식 문자와의 혼동 가능성에 기초하여 획득한 복수의 후보 문자 중 상기 문자 구간과의 음향 특징관련 유사도가 높은 후보 문자를 상기 문자 구간의 발화 문자로 인식하는,동작을 실행하는 컴퓨터 판독가능 기록매체."}
{"patent_id": "10-2019-0153691", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제19항에 있어서,상기 음성 수신부를 통해 수신되는 사용자 음성을 문자열로 변환하고,상기 문자열을 문자 별로 분할하는 동작을 실행하는 컴퓨터 판독가능 기록매체."}
{"patent_id": "10-2019-0153691", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "낱자 단위의 발화 음성을 인식하는 전자장치가 개시된다. 전자장치는, 음성 수신부와, 상기 음성 수신부를 통해 수신되는 사용자 음성의 문자 구간을 변환한 인식 문자를 획득하고, 상기 획득된 인식 문자와의 혼동 가능성에 기초하여 획득한 복수의 후보 문자 중 상기 문자 구간과의 음향 특징의 유사도가 높은 후보 문자를 상기 문자 구 간의 발화 문자로 인식하는 프로세서를 포함한다."}
{"patent_id": "10-2019-0153691", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 사용자 음성을 인식할 수 있는 전자장치와 그의 제어방법, 및 기록매체에 관한 것이다."}
{"patent_id": "10-2019-0153691", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "TV와 같은 대형 디스플레이 장치는 알파벳, 숫자, 기호 등의 문자 입력을 위한 가상의 온 스크린(On-screen) 키 보드를 제공하고 있다. 또한, 대형 디스플레이 장치는 문자를 입력할 수 있는 수단으로 물리적 키보드 등의 연 결이 지원되고는 있으나 사실상 리모컨으로 제한되어 있다. 특히, 리모컨은 소형화, 키 간소화로 인해 숫자를 제외한 알파벳, 기호에 매핑되는 물리 버튼이 지원되지 않는 상황에서 온 스크린 키보드 화면에서 방향키를 다수 눌러서 원하는 문자로 포커스를 이동하면서 확인 버튼을 눌 러 문자 입력을 수행하고 있다. 이에 대한 입력 사용성 개선으로 온 스크린 키보드에 보이는 문자를 음성으로입력하는 방법이 고려되고 있으며, 이를 위해 단어 및 문장 단위 입력 처리가 아닌 낱자 단위 문자 인식이 요구 되고 있다."}
{"patent_id": "10-2019-0153691", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명의 목적은 음성인식 성능을 향상시킬 수 있는 전자장치와 그의 제어방법, 및 컴퓨터 프로그램이 저장된 기록매체를 제공하는 데에 있다."}
{"patent_id": "10-2019-0153691", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기 목적을 달성하기 위한 본 발명의 일 실시예에 따른 전자장치가 제공된다. 전자장치는, 음성 수신부와, 상 기 음성 수신부를 통해 수신되는 사용자 음성의 문자 구간을 변환한 인식 문자를 획득하고, 상기 획득된 인식 문자와의 혼동 가능성에 기초하여 획득한 복수의 후보 문자 중 상기 문자 구간과의 음향 특징 관련 유사도가 높 은 후보 문자를 상기 문자 구간의 발화 문자로 인식하는 프로세서를 포함한다. 상기 프로세서는, 상기 음성 수신부를 통해 수신되는 사용자 음성을 문자열로 변환하고, 상기 문자열을 문자 별 로 분할할 수 있다. 상기 프로세서는, 상기 문자열의 문자 간 휴지구간이 존재하는지를 분석할 수 있다. 상기 프로세서는, 상기 휴지구간이 존재하는 인식 문자의 혼동 가능성에 낮은 가중치를 부여할 수 있다. 상기 전자장치는 메모리를 더 포함하며, 상기 프로세서는, 상기 후보 문자의 인식 결과에 대한 이력정보를 상기 메모리에 저장할 수 있다. 상기 프로세서는, 상기 복수의 후보 문자에 대해 혼동행렬을 기초로 혼동확률을 검출할 수 있다. 상기 프로세서는, 상기 후보 문자의 인식 결과에 대한 이력정보를 기초로 상기 혼동행렬을 업데이트할 수 있다. 상기 프로세서는, 기저장된 복수의 후보 문자의 음향특징모델을 기초로 상기 문자 구간의 음향 특징과의 유사도 를 검출할 수 있다. 상기 프로세서는, 상기 후보 문자의 인식 결과에 대한 이력정보를 기초로 상기 음성특성모델을 업데이트할 수 있다. 상기 프로세서는, 상기 복수의 후보 문자에 대해 혼동행렬을 기초로 검출한 혼동확률과 기저장된 복수의 후보 문자의 음향특징모델을 기초로 검출한 상기 문자 구간의 음향 특징과의 유사도를 적용하여 보정확률을 검출할 수 있다. 본 발명의 실시예에 따른 전자장치의 제어방법이 제공된다. 전자장치의 제어방법은 음성 수신부를 통해 수신되 는 사용자 음성의 문자 구간을 변환한 인식 문자를 획득하는 단계와, 상기 획득된 인식 문자와의 혼동 가능성에 기초하여 획득한 복수의 후보 문자 중 상기 문자 구간과의 음향 특징 관련 유사도가 높은 후보 문자를 상기 문 자 구간의 발화 문자로 인식하는 단계를 포함한다. 본 발명의 실시예에 따른 컴퓨터에 의해 실행되는 컴퓨터 프로그램이 저장되는, 컴퓨터 판독 가능 기록매체가 제공된다. 상기 컴퓨터 프로그램은, 음성 수신부를 통해 수신되는 사용자 음성의 문자 구간을 변환한 인식 문자 를 획득하고, 상기 획득된 인식 문자와의 혼동 가능성에 기초하여 획득한 복수의 후보 문자 중 상기 문자 구간 과의 음향 특징 관련 유사도가 높은 후보 문자를 상기 문자 구간의 발화 문자로 인식하는 동작을 실행한다."}
{"patent_id": "10-2019-0153691", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명에 의한 전자장치는 인식 문자에 대해 사전에 저장 및 학습된 혼동행렬로 혼동 가능성이 있는 복수의 후 보문자를 추출하고, 음향특징모델을 기초로 복수의 후보문자 중 음향특징이 가장 유사한 후보문자로 보정(인 식)함으로써 낱자 단위 음성의 인식성능을 향상시킬 수 있다. 또한, 본 발명에 의한 전자장치는 로그인, 사용자등록, URL 입력 시 알파벳, 숫자, 기호 등을 음성으로 입력하 고, 인식하고, 보정하는 인식 결과 이력을 이용하여 혼동행렬 및 음향특징모델을 점차 사용자 친화적으로 업데 이트 함으로써 사용자 발화 음성의 인식성능을 향상시킬 수 있다."}
{"patent_id": "10-2019-0153691", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하에서는 첨부 도면을 참조하여 본 발명의 실시예들을 상세히 설명한다. 도면에서 동일한 참조번호 또는 부호 는 실질적으로 동일한 기능을 수행하는 구성요소를 지칭하며, 도면에서 각 구성요소의 크기는 설명의 명료성과 편의를 위해 과장되어 있을 수 있다. 다만, 본 발명의 기술적 사상과 그 핵심 구성 및 작용이 이하의 실시예에 설명된 구성 또는 작용으로만 한정되지는 않는다. 본 발명을 설명함에 있어서 본 발명과 관련된 공지 기술 또는 구성에 대한 구체적인 설명이 본 발명의 요지를 불필요하게 흐릴 수 있다고 판단되는 경우에는 그 상세한 설명 을 생략하기로 한다. 본 문서에서, \"가진다,\" \"가질 수 있다,\" \"포함한다,\" 또는 \"포함할 수 있다\" 등의 표현은 해당 특징(예: 수치, 기능, 동작, 또는 부품 등의 구성요소)의 존재를 가리키며, 추가적인 특징의 존재를 배제하지 않는다. 본 문서에서, \"A 또는 B,\" \"A 또는/및 B 중 적어도 하나,\" 또는 \"A 또는/및 B 중 하나 또는 그 이상\"등의 표현 은 함께 나열된 항목들의 모든 가능한 조합을 포함할 수 있다. 예를 들면, \"A 또는 B,\" \"A 및 B 중 적어도 하나,\" 또는 \"A 또는 B 중 적어도 하나\"는, 적어도 하나의 A를 포함, 적어도 하나의 B를 포함, 또는 적어도 하나의 A 및 적어도 하나의 B 모두를 포함하는 경우를 모두 지칭할 수 있다. 본 발명의 실시예에서, 제1, 제2 등과 같이 서수를 포함하는 용어는 하나의 구성요소를 다른 구성요소로부터 구 별하는 목적으로만 사용되며, 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 또한, 본 발명의 실시예에서 '상부', '하부', '좌측', '우측', '내측', '외측', '내면', '외면', '전방', '후방' 등의 용어는 도면을 기준으로 정의한 것이며, 이에 의해 각 구성요소의 형상이나 위치가 제한되는 것은 아니다. 본 문서에서 사용된 표현 \"~하도록 구성된(또는 설정된)(configured to)\"은 상황에 따라, 예를 들면, \"~에 적 합한(suitable for),\" \"~하는 능력을 가지는(having the capacity to),\" \"~하도록 설계된(designed to),\" \"~하 도록 변경된(adapted to),\" \"~하도록 만들어진(made to),\" 또는 \"~를 할 수 있는(capable of)\"과 바꾸어 사용 될 수 있다. 용어 \"~하도록 구성된(또는 설정된)\"은 하드웨어적으로 \"특별히 설계된(specifically designed to)\" 것만을 반드시 의미하지 않을 수 있다. 대신, 어떤 상황에서는, \"~하도록 구성된 장치\"라는 표현은, 그 장 치가 다른 장치 또는 부품들과 함께 \"~할 수 있는\" 것을 의미할 수 있다. 예를 들면, 문구 \"A, B, 및 C를 수행 하도록 구성된(또는 설정된) 서브 프로세서\"는 해당 동작을 수행하기 위한 전용 프로세서(예: 임베디드 프로세 서), 또는 메모리 장치에 저장된 하나 이상의 소프트웨어 프로그램들을 실행함으로써, 해당 동작들을 수행할 수 있는 범용 프로세서(generic-purpose processor)(예: CPU 또는 application processor)를 의미할 수 있다. 본 문서의 다양한 실시예들에 따른 전자장치는, 음성 명령을 인식하는 예를 들면, 스마트폰, 태블릿 PC, 이 동 전화기, 영상 전화기, 전자책 리더기, 데스크탑 PC, 랩탑 PC, 넷북 컴퓨터, 워크스테이션, 서버, PDA, PMP(portable multimedia player), MP3 플레이어, 의료기기, 카메라, 또는 웨어러블 장치 중 적어도 하나를 포함할 수 있다. 어떤 실시예들에서, 전자장치는, 예를 들면, 텔레비전, 블루 레이 플레이어, DVD(digital video disk) 플레이어, 오디오, 냉장고, 에어컨, 청소기, 오븐, 전자레인지, 세탁기, 공기 청정기, 셋톱 박스, 홈 오토매이션 컨트롤 패널, 보안 컨트롤 패널, 미디어 박스, 게임 콘솔, 전자 사전, 전자 키, 캠코더, 또는 전 자 액자 중 적어도 하나를 포함할 수 있다. 다른 실시예에서, 전자장치는, 각종 의료기기(예: 각종 휴대용 의료측정기기(혈당 측정기, 심박 측정기, 혈 압 측정기, 또는 체온 측정기 등), MRA(magnetic resonance angiography), MRI(magnetic resonance imaging), CT(computed tomography), 촬영기, 또는 초음파기 등), 네비게이션 장치, 위성 항법 시스템(GNSS(global navigation satellite system)), EDR(event data recorder), FDR(flight data recorder), 자동차 인포테인먼 트 장치, 선박용 전자 장비(예: 선박용 항법 장치, 자이로 콤파스 등), 항공 전자기기(avionics), 보안 기기, 차량용 헤드 유닛(head unit), 산업용 또는 가정용 로봇, 드론(drone), 금융 기관의 ATM, 상점의 POS(point of sales), 또는 사물 인터넷 장치 (예: 전구, 각종 센서, 스프링클러 장치, 화재 경보기, 온도조절기, 가로등, 토 스터, 운동기구, 온수탱크, 히터, 보일러 등) 중 적어도 하나를 포함할 수 있다. 본 문서에서, 사용자라는 용어는 전자장치를 사용하는 사람 또는 전자장치를 사용하는 장치(예: 인공지능 전자 장치)를 지칭할 수 있다. 도 1은 본 발명의 제1실시예에 따른 전자장치의 음성인식 시나리오를 나타내는 모식도이다. 전자장치는 사용 자가 발화한 음성을 인식하여 동작을 수행하는 텔레비전(TV)으로 구현될 수 있다. 물론, 전자장치는 TV로만 한정되지 않고, 사용자가 발화한 음성 명령을 수신 및 인식할 수 있는 다양한 전자기기로 구현될 수 있다. 도 1을 참조하면, 전자장치는 리모컨에 의해 제어되고, 서버에 네트워크로 연결될 수 있다. 일 실시예로서, 전자장치는 사용자로부터 예를 들면 아이디(ID)영역과 패스워드(PW) 영역에 아이디와 패스워 드를 음성으로 입력 받을 수 있다. 이때, 전자장치는 사용자 발화 음성을 인식하고, 사용자 발화 음성에 대 응하는 문자열로 변환하여 아이디(ID)영역과 패스워드(PW) 영역에 표시할 수 있다. 다른 실시예로서, 전자장치는 답변, 질의, 명령을 단어나 문장이 아닌 알파벳 단위로 음성 입력하거나, URL 입력 시 예를 들면 알파벳, 숫자, 기호 등으로 음성 입력하는 경우에, 이를 문자 단위로 인식하고 보정할 수 있 다. 전자장치는 사용자 발화 음성을 인식하여 변환한 문자열을 문자 단위로 분할하고, 각 인식 문자 별로 혼동 가능성에 기초한 복수의 후보 문자를 획득하고, 복수의 후보 문자 중에 인식 문자 구간의 음향특징과 유사한 음 향특징을 가진 후보 문자로 보정하는 동작을 수행할 수 있다. 리모컨은 전자장치를 제어하는 IR신호 또는 획득한 음성 신호를 무선통신 모듈을 이용하여 전자장치에 전달할 수 있다. 리모컨은 자신이 수신한 음성신호를 그대로 전자장치에 전달할 수 있다. 또한, 리모컨 은 자신이 수신한 음성신호를 인식하여 문자열로 변환한 후에 전자장치에 전달할 수도 있다. 서버는 음성신호를 그대로, 또는 음성신호로부터 변환된 문자열 및/또는 추출된 음향특징을 전자장치로부 터 수신할 수 있다. 서버는 전자장치가 제공하는 음성신호에 대해 인식을 수행하여 대응하는 문자열을 추출하고, 추출된 문자 열을 검증하여 오인식을 보정하는 음성인식 서비스, 컨텐츠를 제공하는 서비스 등을 제공할 수 있다. 서버는 각 서비스에 대하여 하나 이상의 서버로 구현될 수 있다. 도 2는 도 1의 전자장치의 구성을 나타내는 블록도이다. 전자장치는 인터페이스부, 제1마이크, 제1사용자입력부, 제1메모리, 디스플레이, 및 제1프로세서를 포함할 수 있다. 인터페이스부는 각종 컨텐츠, 비디오 데이터, 오디오 데이터 등을 외부장치로부터 수신할 수 있다. 또한, 인터페이스부는 외부장치로부터 인식 대상의 음성을 간접으로 수신할 수 있다. 인터페이스부는 유선인터페이스부1~6과 무선인터페이스부1~3을 포함할 수 있다. 유선인터페이스부1은 방송신호를 수신하기 위한 지상파/위성방송 안테나 연결 튜너, 케이블 방송 케이블 연결 인터페이스 등을 포함할 수 있다. 유선인터페이스부2는 영상기기 연결을 위한 HDMI, DP, DVI, Component, S-Video, 컴포지트(RCA 단자) 등을 포 함할 수 있다.유선인터페이스부3은 범용 전자기기 연결을 위한 USB 인터페이스 등을 포함할 수 있다. 유선인터페이스부4는 광케이블 기기의 연결 인터페이스를 포함할 수 있다. 유선인터페이스부5는 헤드셋, 이어폰, 외부 스피커 등의 오디오기기 연결 인터페이스를 포함할 수 있다. 유선인터페이스부6은 이더넷 등 유선 네트워크 기기의 연결 인터페이스를 포함할 수 있다. 무선인터페이스부1은 Wi-fi, 블루투스, ZigBee, Z-wave, RFID, WiGig, WirelessHD, UWB(Ultra-Wide Band), Wireless USB, NFC(Near Field Communication) 등 무선 네트워크 기기의 연결 인터페이스를 포함할 수 있다. 무선인터페이스부2는 리모컨신호 송신 및/또는 수신을 위한 IR 송수신 모듈을 포함할 수 있다. 무선인터페이스3은 2G ~ 5G 등 이동통신기기 연결 인터페이스를 포함할 수 있다. 인터페이스부는 모바일장치, 서버 각각에 대해 전용으로 통신을 수행하는 전용통신모듈을 포함할 수 있다. 인터페이스부는 외부장치와 통신을 수행하는 공용통신모듈 등을 포함할 수 있다. 인터페이스부는 입력인터페이스부와 출력인터페이스부를 포함할 수도 있다. 이때, 입력인터페이스부와 출력 인터페이스부는 하나의 모듈로 통합되거나 별도의 모듈로 구현될 수도 있다. 제1마이크는 음성수신부로서, 사용자가 발화한 음성, 예컨대 아이디 및 패스워드로 알파벳, 숫자, 기호 등 의 음성을 직접 수신할 수 있다. 여기서, 사용자 발화 음성은 전자장치 또는 전자장치에 유무선 네트워크 로 연결된 장치, 예를 들면 IoT장치의 제어를 위한 다양한 음성 답변, 질의, 명령 등을 포함할 수 있다. 제1사용자입력부는 사용자의 입력에 의해, 기설정된 다양한 제어 커맨드 또는 한정되지 않은 정보를 제1프 로세서에 전달한다. 제1사용자입력부는 전자장치에 마련된 전원키, 메뉴키 등의 버튼을 포함하는 키패드(또는 입력패널) 또 는 디스플레이에 표시되는 사용자 인터페이스(UI)를 포함할 수 있다. 일 실시예에서 제1사용자입력부는 전자장치를 원격으로 제어 가능하게 기설정된 커맨드/데이터/정보/신 호를 생성하여 전자장치로 전송하는 입력장치를 포함한다. 입력장치는 리모컨과 같이 전자장치 본체와 이격 분리되어 사용자 입력을 수신 가능하게 마련된다. 리모컨에는 사용자의 터치입력을 수신하는 터치 감지 부 및/또는 사용자에 의한 자체 모션을 감지하는 모션 감지부가 마련될 수 있다. 입력장치는 리모컨 어플리케이 션이 설치된 스마트폰과 같은 단말장치를 포함하며, 이 경우 터치스크린을 통한 사용자의 터치입력이 수신 가능 하다. 입력장치는 전자장치 본체와 무선통신이 가능한 외부장치가 되며, 무선통신은 블루투스, 적외선 통신, RF 통 신, 무선랜, 와이파이 다이렉트 등을 포함한다. 제1메모리는 컴퓨터에 의해 판독 가능한 기록매체로서, 한정되지 않은 데이터가 저장된다. 제1메모리는 제1프로세서에 의해 액세스 되며, 이들에 의한 데이터의 독취, 기록, 수정, 삭제, 갱신 등이 수행된다. 제1메모리는 리모컨, 서버, USB, 무선으로 연결된 모바일장치 등으로부터 인터페이스부를 통해 수신된 각종 정보 및 컨텐츠를 저장할 수 있다. 제1메모리에 저장되는 데이터는, 예를 들면 사용자의 음성을 인식하여 텍스트 문자열로 변환하는 음성인식 모듈(음성인식엔진)을 포함할 수 있다. 음성인식모듈은 전자장치에서 배제될 수 있다. 이때, 수신된 음성신호는 서버(음성인식서버)로 전송될 수 있다. 서버(음성인식서버)는 음성신호를 적절한 텍스트 문자열로 변환하는 기능을 가진 STT(Speech To Tex t)서버이거나 STT서버 기능도 함께 수행하는 메인 서버일 수도 있다. STT서버는 음성 인식 결과 데이터를 전자 장치에 다시 전송하거나 다른 서버로 바로 전송할 수도 있다. 제1메모리는 음성인식모듈에서 인식한 텍스트 문자열을 문자단위로 분할하는 음성분할모듈, 텍스트 문자열 이 끊어서 발화되었는지 연속으로 발화되었는지, 즉 문자 간 휴지구간이 존재하는지를 분석하는 발화형태 분석 모듈, 각 인식 문자의 혼동 가능성에 기초하여 정해진 각 후보 문자의 혼동확률을 검출하는 혼동행렬, 및 각 후 보 문자에 대응하는 음향특징모델이 저장될 수 있다. 제1메모리는 운영체제, 운영체제 상에서 실행 가능한 다양한 애플리케이션, 영상데이터, 부가데이터 등을 포함할 수 있다. 제1메모리는 제어프로그램이 설치되는 비휘발성의 메모리, 설치된 제어프로그램의 적어도 일부가 로드되는 휘발성의 메모리를 포함한다. 제1메모리는 플래시 메모리 타입(flash memory type), 하드디스크 타입(hard disk type), 멀티미디어 카드 마이크로 타입(multimedia card micro type), 카드 타입의 메모리(예를 들어 SD 또는 XD 메모리 등), 램(RAM, Random Access Memory) SRAM(Static Random Access Memory), 롬(ROM, Read-Only Memory), EEPROM(Electrically Erasable Programmable Read-Only Memory), PROM(Programmable Read-Only Memory) 자기 메모리, 자기 디스크, 광디스크 중 적어도 하나의 타입의 저장매체를 포함할 수 있다. 디스플레이는 처리된 영상신호에 기초하여 영상을 표시할 수 있다. 디스플레이는 사용자가 직접 문자, 알파벳, 숫자, 기호 등을 입력하는 UI를 표시할 수 있다. 디스플레이의 구현 방식은 한정되지 않는 바, 액정(liquid crystal), 플라즈마(plasma), 발광 다이오드 (light-emitting diode), 유기발광 다이오드(organic light-emitting diode), 면전도 전자총(surface- conduction electron-emitter), 탄소 나노 튜브(carbon nano-tube), 나노 크리스탈(nano-crystal) 등의 다양한 디스플레이 패널로 구현될 수 있다. 디스플레이는 구현 방식에 따라서 부가적인 구성을 추가적으로 포함할 수 있다. 예를 들면, 디스플레이(1 5)는 LCD 패널, LCD패널을 구동시키는 LCD패널 구동부, 및 LCD 패널에 광을 공급하는 백라이트 유닛을 포함할 수 있다. 디스플레이는 백라이트 유닛이 없는 OLED패널, 및 OLED패널을 구동시키는 OLED패널 구동부를 포함할 수 있 다. OLED패널은 형광성 유기화합물에 전류가 인가됨에 따라 발광하는 자체 발광 표시소자를 포함할 수 있다. 제1프로세서는 전자장치의 각 구성 부품을 제어할 수 있다. 제1프로세서는 제1메모리에 저장된 음성인식모듈을 실행하여 사용자가 발화한 음성을 텍스트 문자열로 변환할 수 있다. 제1프로세서는 제1메모리에 저장된 발화형태 분석모듈을 실행하여 인식된 텍스트 문자열의 각 문자간 휴지구간이 존재하는지를 확인하여 사용자 발화 형태를 분석할 수 있다. 즉, 제1프로세서는 각 인식 문자가 끊어서 발화되었는지 연속해서 발화되었는지를 나타내는 사용자 발화 형태를 알아낼 수 있다. 제1프로세서는 제1메모리에 저장된 음성분할모듈을 실행하여 인식된 문자열 및 시간정보로 이용하여 입 력 음성을 각 문자 단위로 분할할 수 있다. 제1프로세서는 인식된 문자에 대해 혼동 가능성에 기초하여 마련된 혼동행렬로부터 혼동 가능한 후보 문자 를 추출하고, 혼동 가능한 후보 문자에 대한 혼동 확률을 구하고, 인식 문자 발화구간의 음향특징과 복수의 후 보 문자에 대한 음향특징모델을 통해 유사도를 구하고, 사용자 발화 형태에 따른 확률적 가중치 부여를 통해 최 종적으로 보정할 수 있다. 여기서, 후보 문자는 인식 문자와 동일한 문자를 포함할 수 있다. 또한, 보정은 인식 문자가 오인식 없이 정상적으로 인식된 경우를 포함할 수 있다. 제1프로세서는 전자장치의 음성 인식 및 보정의 결과 이력을 이용하여 혼동행렬 및 음향특징모델을 사용 자에 적합하도록 업데이트 할 수 있다. 여기서, 음성 인식 및 보정의 결과는 성공적인 결과뿐만 아니라 실패한 결과를 포함할 수 있다. 혼동행렬 및 음향특징모델은 사용자에 의한 이력이 축적되기 전의 초기 상태에 마련된 표준 혼동행렬 및 표준 음향특징모델에 사용자가 지속적으로 사용하면서 인식 및 보정 이력이 반영되어 업데이트될 수 있다. 특히, 제1프로세서는 음성인식모델, 혼동행렬, 음향특징모델을 생성하기 위한 데이터를 수집하고, 수집된 데이터를 분석, 처리, 및 결과 정보 생성 중 적어도 일부를 규칙 기반 또는 인공지능(Artificial Intelligence) 알고리즘으로서 기계학습, 신경망 네트워크(neural network), 또는 딥러닝 알고리즘 중 적어도 하나를 이용하여 수행할 수 있다. 일 예로, 제1프로세서는 학습부 및 인식부의 기능을 수행할 수 있다. 학습부는, 예를 들면, 학습된 신경망 네트워크를 생성하는 기능을 수행하고, 인식부는 학습된 신경망 네트워크를 이용하여 데이터를 인식(또는, 추론, 예측, 추정, 판단)하는 기능을 수행할 수 있다. 학습부는 신경망 네트워크를 생성하거나 갱신할 수 있다.학습부는 신경망 네트워크를 생성하기 위해서 학습 데이터를 획득할 수 있다. 예를 들면, 학습부는 학습 데이터 를 제1메모리 또는 외부로부터 획득할 수 있다. 학습 데이터는, 신경망 네트워크의 학습을 위해 이용되는 데이터일 수 있다. 학습부는 학습 데이터를 이용하여 신경망 네트워크를 학습시키기 전에, 획득된 학습 데이터에 대하여 전처리 작 업을 수행하거나, 또는 복수 개의 학습 데이터들 중에서 학습에 이용될 데이터를 선별할 수 있다. 예를 들면, 학습부는 학습 데이터를 기 설정된 포맷으로 가공하거나, 필터링하거나, 또는 노이즈를 추가/제거하여 학습에 적절한 데이터의 형태로 가공할 수 있다. 학습된 신경망 네트워크는, 복수의 신경망 네트워크(또는, 레이어)들 로 구성될 수 있다. 복수의 신경망 네트워크의 노드들은 가중치를 가지며, 복수의 신경망 네트워크들은 일 신경 망 네트워크의 출력 값이 다른 신경망 네트워크의 입력 값으로 이용되도록 서로 연결될 수 있다. 신경망 네트워 크의 예로는, CNN (Convolutional Neural Network), DNN (Deep Neural Network), RNN (Recurrent Neural Network), RBM (Restricted Boltzmann Machine), DBN (Deep Belief Network), BRDNN(Bidirectional Recurrent Deep Neural Network) 및 심층 Q-네트워크 (Deep Q-Networks)과 같은 모델을 포함할 수 있다. 한편 인식부는 사용자 발화 음성을 인식하고 보정하기 위한, 타겟 데이터를 획득할 수 있다. 타겟 데이터는 제1 메모리 또는 외부로부터 획득된 것일 수 있다. 타겟 데이터는, 신경망 네트워크의 인식 대상이 되는 데이터 일 수 있다. 인식부는 타겟 데이터를 학습된 신경망 네트워크에 적용하기 전에, 획득된 타겟 데이터에 대하여 전처리 작업을 수행하거나, 또는 복수 개의 타겟 데이터들 중에서 인식에 이용될 데이터를 선별할 수 있다. 예 를 들면, 인식부는 타겟 데이터를 기 설정된 포맷으로 가공하거나, 필터링 하거나, 또는 노이즈를 추가/제거하 여 인식에 적절한 데이터의 형태로 가공할 수 있다. 인식부는 전처리된 타겟 데이터를 신경망 네트워크에 적용 함으로써, 신경망 네트워크로부터 출력되는 출력값을 획득할 수 있다. 다양한 실시예에 따르면, 인식부는 출력 값과 함께 학률값(또는, 신뢰도값)을 함께 획득할 수 있다. 제1프로세서는 제어프로그램이 설치된 비휘발성의 메모리로부터 명령어들(instructions)을 포함하는 제어프 로그램의 적어도 일부를 휘발성의 메모리로 로드하고, 로드된 제어프로그램의 명령어를 실행하는 적어도 하나의 범용 프로세서를 포함하며, 예를 들면 CPU(Central Processing Unit), AP(application processor), 또는 마이 크로프로세서(microprocessor)로 구현될 수 있다. 제1프로세서는 싱글 코어, 듀얼 코어, 트리플 코어, 쿼드 코어 및 그 배수의 코어를 포함할 수 있다. 제1프 로세서는 복수 개 마련될 수 있다. 제1프로세서는 예를 들어, 메인 프로세서(main processor) 및 슬립 모드(sleep mode, 예를 들어, 대기 전원만 공급되는 모드)에서 동작하는 서브 프로세서(sub processor)를 포함 할 수 있다. 또한, 프로세서, 롬 및 램은 내부 버스(bus)를 통해 상호 연결된다. 제1프로세서는 전자장치에 내장되는 PCB 상에 실장되는 메인 SoC(Main SoC)에 포함되는 형태로서 구현 가능하다. 다른 실시예에서 메인 SoC는 영상처리부를 더 포함할 수 있다. 제어프로그램은, BIOS, 디바이스드라이버, 운영체계, 펌웨어, 플랫폼 및 응용프로그램(어플리케이션) 중 적어도 하나의 형태로 구현되는 프로그램(들)을 포함할 수 있다. 응용프로그램은, 전자장치의 제조 시에 미리 설치 또는 저장되거나, 혹은 추후 사용 시에 외부로부터 응용프로그램의 데이터를 수신하여 수신된 데이터에 기초하 여 설치될 수 있다. 응용 프로그램의 데이터는, 예컨대, 어플리케이션 마켓과 같은 외부 서버로부터 전자장치 로 다운로드될 수도 있다. 이와 같은 외부 서버는, 컴퓨터프로그램제품의 일례이나, 이에 한정되는 것은 아 니다. 리모컨은 제2사용자입력부, 제2마이크, 제1통신부 및 제2프로세서를 포함할 수 있다. 리모컨은 IR신호만을 기반으로 2비트 제어정보를 전송하는 IR리모컨, 또는 예를 들면 버튼, 음성, 터치, 드 래그 등으로 입력된 사용자입력 정보를 IR신호, 블루투수신호, 와이파이신호 등으로 전송하는 통합리모컨(MBR), 또는 리모컨 앱(app)이 설치된 스마트폰 등의 모바일단말기 등으로 구현될 수 있다. 제2사용자입력부는 각종 기능키 버튼을 통한 버튼입력, 터치센서를 통한 터치 또는 드래그 입력, 제2마이크 을 통한 음성입력, 동작감지센서를 통한 모션입력 등을 수신할 수 있다. 제2마이크는 음성신호를 수신할 수 있다. 이와 같이, 수신된 음성신호는 아날로그 신호를 디지털신호로 변 환되어, 제1통신부, 예를 들면 블루투수통신 모듈, 와이파이통신 모듈, 적외선통신 모듈 등을 통해 제어대 상, 예를 들면 전자장치로 전송될 수 있다. 만일 리모컨이 음성인식기능을 가진 스마트폰과 같은 모바일 단말기로 구현되는 경우, 입력된 음성입력은 음성인식을 통해 인식된 문자열에 대응하는 코드신호 형태로 전자장치에 전송될 수도 있다. 제2마이크로 수신된 아날로그 음성신호는 디지털신호로 변환되어 예를 들면 블루투스 등을 통해 전자장치 로 전송될 수 있다. 제1통신부는 제2마이크로부터 입력된 아날로그 음성신호를 디지털 소리신호로 전자장치에 전송할 수 있다. 제1통신부는 무선 통신을 수행하기 위해, IR, RF(Radio Frequency), Wi-fi, 블루투스, 지그비(Zigbee), UWB(Ultra-Wide Band), Wireless USB, NFC(Near Field Communication) 중 하나 이상의 통신을 수행하도록 구성 될 수 있다. 제2프로세서는 리모컨의 각 구성 부품을 제어할 수 있다. 제2프로세서는 버튼입력, 터치입력, 드래 그입력, 모션입력에 대응한 제어명령을 제1통신부를 통해 전자장치로 전송할 수 있다. 제2프로세서는 제2마이크를 통해 입력된 아날로그 음성신호를 디지털 소리신호로 변환하여 제1통신부 를 통해 전자장치로 전송할 수 있다. 제2프로세서는 음성인식모듈을 실행하여 입력된 음성신호를 인 식하여 변환된 텍스트를 제1통신부를 통해 전자장치로 전송할 수 있다. 도 3은 본 발명의 제2실시예에 따른 전자장치의 구성을 나타내는 블록도이다. 제2실시예에 따른 전자장치 는 영상컨텐츠 또는 제어신호를 외부장치로 출력할 수 있다. 예를 들면, 전자장치는 디스플레이 장치 로 영상을, 오디오 장치로 오디오를, IoT장치로 제어신호를 출력할 수 있다. 물론, 제2실시예에 따른 전자장치는 간단한 알림, 제어 메뉴 등을 표시하기 위한 디스플레이를 포함할 수도 있다. 제2실시예에 따른 전자장치는 인터페이스부, 제1마이크 제1사용자입력부, 제1메모리, 및 제 1프로세서을 포함할 수 있다. 이하, 도 2와 동일한 구성은 설명을 생략하고 다른 구성에 대해서만 설명한다. 제2실시예에 따른 전자장치는 제1실시예에 따른 전자장치와 다르게, 제1프로세서에서 처리된 데이터, 예컨대 음성, 또는 영상, 제어신호를 인터페이스부를 통해 외부장치에 전송할 수 있다. 도 4는 본 발명의 실시예에 따른 서버의 구성을 나타내는 블록도이다. 도 4를 참조하면, 서버는 제2통신부, 제2메모리 및 제3프로세서를 포함할 수 있다. 서버는 음성인식서버 또는 컨텐츠 서버일 수 있다. 서버는 음성인식 서버와 컨텐츠 서버를 모두 포함할 수 있다. 제2통신부는 다수의 전자장치(1-1~1-n)와 네트워크 통신을 수행한다. 전자장치(1-1~1-n)는 음성신호의 인식 기능이 없을 경우, 식별된 사용자가 발화한 음성신호를 서버에 전송할 수 있다. 제2통신부는 다수의 전 자장치(1-1~1-n) 각각이 음성신호를 인식 및 보정할 때에 사용한 음성인식모델, 혼동행렬, 음향특징모델을 수집 할 수 있다. 제2통신부는 제3프로세서의 제어 하에 수집, 학습 및 생성된 표준 음성인식모델, 표준 혼동행렬, 표준 음향특징모델을 등을 전자장치(1-1~1-n)에 전송하거나 또는 업데이트할 수 있다. 제2통신부는 전자장치(1-1~1-n) 중에 음성인식을 위해 음성신호를 전송한 전자장치에 음성인식을 수행한 결 과를 전송할 수 있다. 제2통신부는 예컨대, 다수의 전자장치(1-1~1-n)와 무선 통신을 수행하기 위해 RF(Radio Frequency)신호를 송/수신하는 RF회로를 포함할 수 있으며, Wi-fi, 블루투스, 지그비(Zigbee), UWB(Ultra-Wide Band), Wireless USB, NFC(Near Field Communication) 중 하나 이상의 통신을 수행하도록 구성될 수 있다. 제2통신부는 유 선 LAN(Local Area Network)을 통해 다수의 전자장치(1-1~1-n) 그리고 다른 장치들과 유선 통신을 수행할 수 있 다. 유선 접속을 위한 커넥터 또는 단자를 포함하는 접속부 이외에도 다양한 다른 통신 방식으로 구현될 수 있 다. 제2메모리는 한정되지 않는 다양한 데이터들을 포함할 수 있다. 제2메모리는 서버가 음성인식서버인 경우에 음성인식모듈(음성인식엔진)이 저장될 수 있다. 제3프로세서는 제2메모리에 저장된 음성인식모듈(음성인식엔진)과 음성인식모델을 기초로 사용자가 발 화한 음성신호를 텍스트로 변환한 문자열을 획득할 수 있다. 제3프로세서는 사전에 음성 인식 및 보정에 관련된 데이터를 수집, 처리, 분석 및 학습하여 음성인식모델, 혼동행렬, 음향특징모델을 생성할 수 있다. 음성인식모델, 혼동행렬 및 음향특징모델은 데이터 처리와 모델 생성에 의해 데이터 수집, 가공 및 이를 이용하 는 음성 인식에 필요한 각종 모델 학습 과정을 통해 생성될 수 있다. 데이터 처리는 데이터를 수집하고, 선별하 고, 가공하여 음성 코퍼스, 단어 발음에 관한 정보 및 문장 코퍼스를 생성할 수 있다. 그리고 모델 생성은 데이 터 처리된 정보들을 이용하여 음향 모델링, 발음 모델링 및 언어 모델링을 수행하여, 음소 적응모델, 발음 사전 모델 및 언어 모델이 각각 생성될 수 있다. 제3프로세서는 음성인식모델, 표준 혼동행렬 및 표준 음향특징모델을 생성하여 전자장치(1-1~1-n)에 배포할 수 있다. 도 5는 본 발명의 실시예에 따른 전자장치에서 사용자 발화 음성을 인식 처리하는 구성을 나타내는 블록도이 다. 도 5를 참조하면, 전자장치는 음성수신 모듈, 음성인식 모듈, 발화형태분석 모듈, 음성분할 모듈, 후보정 모듈, 및 업데이트 모듈을 포함할 수 있다. 각 모듈은 제1프로세서가 실행할 수 있는 소프트웨어 프로그램일 수 있다. 음성수신 모듈은 제1마이크를 이용하여 또는 제3의 장치를 경유하여 음성신호를 입력 받는다. 음성신 호는 인식하고자 하는 사용자 발화음성으로, 사용자 답변, 질의, 명령 음성에 대한 아날로그 신호 또는 아날로 그신호를 변환한 디지털신호를 포함할 수 있다. 일 실시예로서, 음성은 아이디, 패스워드, URL, 답변 입력을 위해 입력한 알파벳, 숫자, 기호로 사용자가 발화 한 문자 단위의 음성을 포함할 수 있다. 음성인식 모듈은 음성인식모델(DB1)을 기초로 수신된 사용자 발화 음성신호에 대응하는 텍스트 문자열로 인식할 수 있다. 음성인식 모듈은 각 문자구간의 음향특징을 추출할 수 있다. 발화형태분석 모듈은 수신된 사용자 발화 음성이 연속으로 발화된 것인지, 끊어서 발화된 것인지를 분석할 수 있다. 즉, 사용자 발화 음성을 인식하여 텍스트로 변환된 문자열에서 각 문자 간에 휴지구간이 존재하는지 여부를 검출할 수 있다. 음성분할 모듈은 음성인식모듈에서 인식된 텍스트 문자열을 각 문자 단위로 분할할 수 있다. 후보정 모듈은 음성분할 모듈에서 분할된 각 인식 문자에 대해 검증(보정)을 수행할 수 있다. 후보정 모듈은 인식 문자에 대해 혼동 가능성에 기초로 하여 마련된 혼동행렬(DB2)을 이용하여 복수의 후 보 문자를 추출하고, 각 후보 문자 별로 혼동확률을 얻을 수 있다. 여기서, 후보 문자는 혼동 가능성이 없는, 즉 오인식되지 않고 명확한 경우 인식문자와 동일한 하나의 문자만을 포함할 수 있다. 후보정 모듈은 음향특징모델(DB3)을 기초로 인식 문자 구간의 음향특징에 대한 각 후보 문자의 유사도를 검출할 수 있다. 후보정 모듈은 혼동확률과 음향 특징간 유사도의 곱에 발화형태 정보에 따른 가중치 정보를 반영하여 인식 된 문자에 대한 보정확률을 구할 수 있다. 후보정 모듈은 후보정 모듈에서 인식 또는 보정된 이력정보, 예를 들면 인식 문자, 인식 문자 구간의 음향특징, 추출된 후보 문자, 최종 결정된 후보 문자 등의 정보를 사용이력 DB(DB4)에 저장할 수 있다. 업데이트 모듈은 사용이력 DB(DB4)를 참조하여 혼동행렬(DB2) 및 음향특징모델(DB3)를 업데이트할 수 있다. 이하, 본 발명의 실시예에 따른 사용자 음성 인식 및 보정 방법을 상세히 설명한다. 도 6은 사용자가 발화한 음성을 인식 및 보정하는 방법을 나타내는 순서도이고, 도 7은 인식 문자의 음향특징을 나타내는 도면이고, 도 8 내지 11은 각각 후보 문자 'v', 'b', 've', 'be'의 음향특징모델을 나타낸다. 단계 S11에서, 음성수신 모듈은 제1마이크를 이용하여 또는 제3의 장치를 경유하여 음성신호를 입력 받는다. 음성신호는 아이디, 패스워드, URL, 답변 입력을 위해 입력한 알파벳, 숫자, 기호로 사용자가 발화한문자 단위의 음성신호를 포함할 수 있다. 음성수신 모듈은 예를 들면, 사용자가 아이디 'vod'를 발화한 음 성신호로 수신할 수 있다. 단계 S12에서, 음성인식 모듈은 음성인식모델(DB1)을 기초로 수신된 사용자 발화 음성신호로부터 텍스트 문자열로 인식(변환)할 수 있다. 예를 들면, 음성인식 모듈은 사용자가 발화한 아이디 'vod'를 \"veod\"로 인식할 수 있다. 또한, 음성인식 모듈은 각 인식 문자 구간의 음향특징을 추출할 수 있다. 사용자 발화 음성신호의 인식은 자연어 이해(Natural Language Understanding, NLU), 자연어 생성(Natural Language Generation, NLG), 텍스트-문장 변환(Text-to-Sentence) 과정을 포함할 수 있다. 음성인식모델(DB1)은 사전에 음성 인식에 관련된 데이터를 수집, 가공, 및 학습하여 생성될 수 있다. 음성인식모델(DB1)은 데이터 처리와 모델 생성에 의해 데이터 수집, 가공 및 이를 이용하는 음성 인식에 필요한 각종 모델 학습 과정이 수행될 수 있다. 데이터 처리는 데이터를 수집하고, 선별하고, 가공하여 음성 코퍼스, 단어 발음에 관한 정보 및 문장 코퍼스를 생성할 수 있다. 그리고 모델 생성은 데이터 처리된 정보들을 이용하 여 음향 모델링, 발음 모델링 및 언어 모델링을 수행하여, 음소 적응모델, 발음 사전 모델 및 언어 모델이 각각 생성될 수 있다. 단계 S13에서, 발화형태분석 모듈은 수신된 사용자 발화 음성이 연속으로 발화된 것인지, 끊어서 발화된 것인지를 분석할 수 있다. 즉, 사용자 발화 음성을 인식하여 텍스트로 변환된 문자열에서 각 문자 간에 휴지구 간이 존재하는지 여부를 검출할 수 있다. 예를 들면 아이디나 패스워드로 입력되는 음성은 각 문자 별로 끊어서 발음한, 즉 휴지구간이 존재하는 인식 문자는 혼동 가능성에 대해 가중치를 낮게 적용할 수 있다. 발화형태분석 모듈은 예를 들면, 'v e o d'로 모두 끊어서 발화했는지, 또는 've o d'로 일부만 연속적으로 이어서 발화 했는지, 또는 'veod' 모두 연속적으로 이어서 발화했는지를 분석할 수 있다. 이와 같이, 사용자 발화형태가 연음인지 단음인지를 구별하여 혼동확률에 반영함으로써 낱자 단위의 문자 인식 률을 향상시킬 수 있다. 단계 S14에서, 음성분할 모듈은 음성인식모듈에서 인식된 텍스트 문자열을 각 문자 단위로 분할할 수 있다. 예를 들면, 사용자 발화 음성이 'veod'로 인식되었을 때 'v', 'e', 'o', 'd'로 분할할 수 있다. 특히, 2 번째 인식 문자를 포함한 've'가 'v'와 혼동 가능한 문자이므로 'v' 뿐만 아니라 've'까지 함께 고려한다. 이와 같이, 사용자 발화 음성에 대응하는 문자열을 낱자 단위의 문자로 분할함으로써 혼동 가능한 후보 문자들과의 대비를 위한 보정 대상을 명확하게 할 수 있다. 단계 S15에서, 후보정 모듈은 음성분할 모듈에서 분할된 각 인식 문자에 대해 다음과 같이 검증(보정)을 수행할 수 있다. 첫째, 후보정 모듈은 인식 문자에 대해 혼동 가능성에 기초로 하여 마련된 혼동행렬(DB2)을 이용하여 복수 의 후보 문자를 추출하고, 각 후보 문자 별로 혼동확률을 얻을 수 있다. 여기서, 후보 문자는 혼동 가능성이 없 는, 즉 오인식되지 않고 명확한 경우 인식문자와 동일한 하나의 문자만을 포함할 수 있다. 혼동행렬(DB2)은 사용자 발화 음성의 인식 문자에 대해 혼동 가능한 후보 문자들을 매핑시킨, 예를 들면, 인식 문자 'v'가 'v', 'b', 've', 'be'로 혼동된 횟수를 매핑시킨 테이블이다. 혼동행렬(DB2)은 모든 문자, 즉 알파 벳, 숫자, 기호들에 대한 혼동 가능한 후보 문자에 대한 이력을 수집, 가공, 학습하여 생성될 수 있다. 일 실시예로서, 전장장치는 사용자 발화 음성의 인식 및 보정이 이루어지지 않은 초기에 표준 혼동행렬이 적 용될 수 있다. 표준 혼동행렬은 예를 들면 서버에 연결된 많은 전자장치들로부터 수신한 음성 인식 및 보정 데 이터 들을 수집, 가공 및 학습을 통해 생성되고, 각 전자장치들로 배포 또는 업데이트 될 수 있다. 표준 혼동행렬은 전자장치에 마련된 상태에서 사용자 발화 음성 인식 및 보정을 수행하면서 그 결과를 지속 적으로 축적됨으로써 사용자 친화적인 혼동행렬(DB2)로 점차 업데이트될 수 있다. 혼동행렬(DB2)은 사용자 발화 인식 및 보정 결과를 반영하면서 사용자마다의 독특한 발화에 따른 새로운 후보 문자도 추가될 수 있다. 아래 표 1은 인식 문자 v에 대한 후보 문자의 혼동행렬을 나타내고 있다. 예를 들면, 100번의 인식 및 보정 결 과를 기준으로 할 때, 인식 문자 v가 후보 문자 v로 인식될 정인식 확률(Pc(v/v)은 65%, b로 인식될 혼동 확률 (Pc(b/v)은 9%, ve로 인식될 혼동 확률(Pc(ve/v)은 24%, be로 인식될 혼동 확률(Pc(be/v)은 2%이다. 이와 같은 표준 혼동행렬에 의하면, v는 v-65%로 정인식, 즉 혼동 가능성이 없는 확률과, b-9%, ve-24%, be-2%로 혼동될 확률을 획득할 수 있다.표 1 v (후보 문자)b (후보 문자)ve (후보 문자)be (후보 문자) v (인식 문자)65 9 24 2 둘째, 후보정 모듈은 음향특징모델(DB3)을 기초로 인식 문자 구간의 음향특징에 대한 각 후보 문자의 유사 도를 검출할 수 있다. 예를 들면, 'v'로 분할된 음성구간의 음향특징과 이전 사용 이력을 통해 기 저장되어 있 는 음향특징모델 간의 템플릿 정합을 통해 각 후보 문자 v, b, ve, be의 유사도 Pt(v/v), Pt(b/v), Pt(ve/v), Pt(be/v)를 구할 수 있다. 음향특징모델(DB3)은 이전 사용 이력을 통해 기 저장되어 있는 각 후보 문자의 음향특징, 예를 들면 피치, 발성 패턴 등을 수집, 가공, 및 학습하여 생성될 수 있다. 음향특징은 같은 문자를 발화하더라도 사용자마다 서로 다 를 수 있다. 사용자가 발화한 'v'의 음향특징은 도 7에 나타낸 바와 같다. 음향특징은 인식된 음성신호의 주파수 및 시간으 로 나타낸 예를 들면 스펙트로그램으로 나타낼 수 있다. 음향특징모델(DB3)에 기저장된 후보 문자 'v', 'b', 've', 'be'의 음향특징은 각각 도 8 내지 11에 나타낸 바와 같다. 후보정 모듈은 도 7의 음향특징을 도 8 내지 11의 음향특징모델과 템플릿 정합을 통해 유사도를 추 출할 수 있다. 음향특징의 템플릿 정합은 인식 문자 'v'와 후보 문자 'v', 'b', 've', 'be' 각각의 파형을 오버 랩시켜 중첩되는 포인트로 유사도를 결정할 수 있다. 예를 들면, 도 7로 인식된 음향특성을 도 8~11에 각각 나 타낸 기저장된 후보 문자 'v', 'b', 've', 'be'의 음향특징과 비교할 수 있다. 후보정 모듈은 사용자 발화 음성을 인식 및 보정을 수행한 결과 이력이 축적되기 전의 초기에는 서버 또는 외부장치에서 생성하여 배포한 표준 음향특징모델을 적용할 수 있다. 표준 음향특징모델은 전자장치에서 지 속적으로 사용자 발화 음성을 인식 및 보정한 결과 이력이 축적됨에 따라 사용자에 적합한, 즉 사용자 발화 음 성의 음향특징이 반영된 음향특징모델(DB3)로 업데이트될 수 있다. 셋째, 후보정 모듈은 혼동확률과 음향 특징간 유사도의 곱에 발화형태 정보에 따른 가중치 정보를 반영하 여 인식된 문자 'v'에 대한 보정확률을 구할 수 있다."}
{"patent_id": "10-2019-0153691", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "여기서, 발화형태 정보에 따른 가중치 정보는 문자 별로 끊어서 발화한 경우에는 연음의 영향이 적고, 이로 인 해 'v', 'b'가 've', 'be' 대비 상대적으로 정인식일 확률이 높을 수 있다. 따라서, , 는 , 보다 높은 가중치 값을 갖도록 설정할 수 있다. 또한, 연속적으로 이어서 발화한 경우에는 모두 균일한 값을 갖도록 설정할 수 있다. 다음으로, 인식된 문자 've'에 대해서도 'v'와 동일하게 혼동확률, 음향특징의 유사도를 구한 후, 보정확률을 구할 수 있다."}
{"patent_id": "10-2019-0153691", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "후보정 모듈은 'v'와 've'에 대해 구해진 보정확률을 비교한 후, 보정확률이 최고값을 갖는 후보 문자로 최종 인식 결과를 보정할 수 있다."}
{"patent_id": "10-2019-0153691", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "예를 들어, 가 보다 크고, 가 'v'라고 하면 인식된 문자 've'는 'v'로 보정되어 출력될 수 있다. 이상과 같이, 후보정 모듈은 사용자가 의도한 발화 문자가 'v'인데, 이를 've'로 오인식할 경우, 'v' 또는 've'의 혼동 가능한 후보문자 'v', 'b', 've', 'be'를 결정한 후에, 도 7의 인식된 문자의 음향특징을 도 8 내지 11의 기저장된 후보문자 'v', 'b', 've', 'be'의 음향특징들과의 비교를 통한 유사도를 결정하고, 인식된 've'를 도 8의 v'의 음향특징과 가장 유사하므로 'v'로 보정할 수 있다. 후보정 모듈은 'v'가 정인식이거나 보정된 경우, 이어서 'e', 'o', 'd'에 대해서도 순차적으로 후보정 과 정을 진행할 수 있다. 만일, 've'가 정인식이거나 보정된 경우는 'o', 'd'에 대해서 순차적으로 후보정 과정을 거쳐 최종 인식결과를 출력할 수 있다. 후보정 모듈은 마지막으로 이전 단계들 S11-15의 실행 결과의 이력정보를 사용이력 DB(DB4)에 저장할 수 있다. 이력 정보는 인식 및/또는 보정 성공 결과 정보뿐만 아니라 인식 실패 정보를 포함할 수 있다. 단계 S16에서, 업데이트 모듈은 사용이력 DB(DB4)에 저장된 이력정보를 참조하여 혼동행렬(DB2)과 음향특 징모델(DB3)를 업데이트할 수 있다. 업데이트된 혼동행렬(DB2)과 음향특징모델(DB3)은 향후 사용자 음성 인식 및 보정에 적용됨으로써 점차 사용자 친화적으로 변화되어 인식률을 향상시킬 수 있다. 상술한 바와 같이, 본 발명의 음성인식 및 보정방법은 사용자의 이력에 기반하여 혼동 가능한 문자의 혼동확률 과 음성특징에 의한 유사확률을 검출하여 인식된 문자를 후보정함으로써, 문자 단위의 인식률을 높일 수 있다. 다른 실시예로서, 사용자는 전자장치의 제1사용자입력부를 통하여 문자 또는 문자열을 입력하고, 이에 대응하는 음성을 발화하여 인식 문자에 대응하는 음향특징을 사전 등록할 수 있다. 이와 같이, 문자 단위의 사 용자 음성의 음향특징을 등록함으로써 향후 낱자 단위 문자의 인식률을 높일 수 있다. 다른 실시예로서, 음성인식모델(DB1), 혼동행렬(DB2), 음향특징모델(DB3), 사용이력 DB(DB4)는 음성인식 성공률 을 높이기 위해서 대규모의 데이터들 및 고성능 하드웨어/소프트웨어가 요구되기 때문에, 음성인식모델(DB1), 혼동행렬(DB2), 음향특징모델(DB3), 사용이력 DB(DB4)를 전자장치에서 배제하고 서버에 마련할 수도 있다. 전자장치는 음성인식 어시스턴트가 설치되어 음성 인식 및 보정을 수행할 수 있다. 전자장치는 하나의 어 시스턴트 또는 다수의 어시스턴트가 설치될 수 있다. 만일, 전자장치에 다수의 어시스턴트가 설치된 경우에, 본 발명의 실시예에 따른 음성 인식 및 보정 방법은 각 어시스턴트 모두에 적용되거나 특정 어시스턴트에만 적 용될 수 있다. 다른 실시예로서, 인식된 결과를 이용하는 주체는 전자장치가 아닌 서버 또는 제3의 장치일 수도 있다. 본 발명의 실시예에 따른, 음성 인식 및 보정을 위한 모듈들은 컴퓨터 판독 가능 기록매체로서 메모리에 저장된 컴퓨터프로그램 제품 또는 네트워크통신으로 송수신되는 컴퓨터프로그램 제품으로 구현될 수 있다. 또한, 상술 한 사용자 식별 모듈들은 단독 또는 통합되어 컴퓨터프로그램으로 구현될 수 있다. 컴퓨터프로그램 제품 또는 컴퓨터프로그램은, 앞서 언급된 바와 같이, 프로세서에 의해 실행되는 명령어들을 포함할 수 있다. 본 발명의 실시예에 따른 컴퓨터 프로그램은 음성 수신부를 통해 수신되는 사용자 음성의 문자 구간을 변환한 인식 문자를 획득하고, 상기 획득된 인식 문자와의 혼동 가능성에 기초하여 정해지는 복수의 후보 문자를 획득 하고, 상기 획득된 복수의 후보 문자 중 상기 문자 구간과의 음향 특징의 유사도가 높은 후보 문자를 상기 문자 구간의 발화 문자로 인식하는 동작을 실행할 수 있다."}
{"patent_id": "10-2019-0153691", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 제1실시예에 따른 전자장치의 음성인식 시나리오를 나타내는 모식도이다. 도 2는 도 1의 전자장치의 구성을 나타내는 블록도이다. 도 3은 본 발명의 제2실시예에 따른 전자장치의 구성을 나타내는 블록도이다. 도 4는 본 발명의 실시예에 따른 서버의 구성을 나타내는 블록도이다. 도 5는 본 발명의 실시예에 따른 전자장치에서 사용자 발화 음성을 인식 처리하는 구성을 나타내는 블록도이다. 도 6은 사용자가 발화한 음성을 인식 및 보정하는 방법을 나타내는 순서도이다. 도 7은 인식 문자의 음향특징을 나타내는 도면이다. 도 8은 후보 문자 'v'의 음향특징모델을 나타낸 도면이다. 도 9는 후보 문자 'b'의 음향특징모델을 나타낸 도면이다. 도 10은 후보 문자 've'의 음향특징모델을 나타낸 도면이다. 도 11은 후보 문자 'be'의 음향특징모델을 나타낸 도면이다."}
