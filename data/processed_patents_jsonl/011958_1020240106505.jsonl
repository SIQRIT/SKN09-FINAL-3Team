{"patent_id": "10-2024-0106505", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2025-0023958", "출원번호": "10-2024-0106505", "발명의 명칭": "통신 시스템에서 채널 상태 정보 피드백을 위한 양면 AI/ML 모델의 순차 학습 방법 및 장치", "출원인": "한국전자통신연구원", "발명자": "이안석"}}
{"patent_id": "10-2024-0106505", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "에 있어서,상기 구성 정보는 상기 순차 학습을 위한 상기 순차 학습 데이터의 각 샘플 별 중요도 또는 밀도 정보 중 적어도 하나의 정보를 포함하고, 상기 적어도 하나의 정보는 상기 순차 학습을 위한 상기 순차 학습 데이터를 축소하는 방법에 따라 결정되는,제1 학습 노드의 방법."}
{"patent_id": "10-2024-0106505", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "청구항 1에 있어서,상기 제1 양면 AI/ML 모델은 제1 인코더(encoder) 모델 또는 제1 디코더(decoder) 모델 증 적어도 하나를 포함하고,상기 제1 학습 노드가 기지국일 경우, 상기 제1 인코더 모델은 상기 CSI 피드백 동작에서 이용되지 않고, 상기CSI 피드백은 상기 제1 학습 노드에서의 추론(inference)에 대응되는,제1 학습 노드의 방법."}
{"patent_id": "10-2024-0106505", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "청구항 1에 있어서,상기 구성 정보는 상기 원시 학습 데이터의 샘플 개수, 상기 원시 학습 데이터의 추가 정보, 상기 순차 학습 데이터의 샘플 개수, 상기 순차 학습 데이터 개수의 축소율, 상기 채널 정보의 종류, 상기 채널 정보의 양자화 여부 및 양자화 방법, 상기 매핑 정보의 양자화 방법 또는 상기 제1 학습 노드의 모델 및 학습에 따른 성능치 중적어도 하나를 포함하는,제1 학습 노드의 방법."}
{"patent_id": "10-2024-0106505", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "청구항 1에 있어서,상기 구성 정보는 상기 순차 학습 데이터의 축소 방법에 대한 정보를 포함하고, 상기 축소 방법은 임의 샘플링기반 축소 방법, 채널 정보의 밀도 기반 축소 방법, 매핑 정보의 밀도 기반 축소 방법 또는 모델 기반 중요도기반 축소 방법 중 적어도 하나를 포함하는,제1 학습 노드의 방법.공개특허 10-2025-0023958-3-청구항 5"}
{"patent_id": "10-2024-0106505", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "청구항 1에 있어서,상기 제1 학습 노드는,상기 제2 학습 노드로부터 데이터 증강(augmentation)이 적용되었음을 지시하는 제1 지시 정보를 수신하는 단계를 더 포함하며,상기 제1 지시 정보는 상기 데이터 증강에 적용되는 방법에 관련된 정보를 포함하고, 상기 방법은 잡음 추가 방법, 회전 방법 또는 생성형 AI 모델을 이용한 방법 중 적어도 하나의 방법이고, 상기 방법은 상기 제1 양면AI/ML 모델에서 학습에 고려되는,제1 학습 노드의 방법,"}
{"patent_id": "10-2024-0106505", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "청구항 6에 있어서,상기 제1 지시 정보에 따라 상기 제2 노드가 데이터 증강을 적용한 것으로 확인될 경우, 상기 제1 학습 노드는상기 방법을 적용하여 상기 양면 AI/ML 모델에 대해 새로운 학습 또는 추가 학습을 수행하는,제1 학습 노드의 방법."}
{"patent_id": "10-2024-0106505", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "청구항 1에 있어서,상기 축소된 순차 학습 데이터셋이 상기 제2 학습 노드로 전달된 이후, 상기 제1 학습 노드는,추가 학습을 위한 제2 축소된 순차 학습 데이터셋을 생성하는 단계; 및상기 제2 축소된 순차 학습 데이터셋 또는 제2 순차 학습 데이터 구성 정보 중 적어도 하나를 포함하는 제2 양면 AI/ML 학습 데이터 정보를 상기 제2 학습 노드로 전달하는 단계를 더 포함하며,상기 제2 순차 학습 데이터 구성 정보는 상기 제2 축소된 순차 학습 데이터셋이 추가 학습에 이용됨을 지시하는정보를 포함하는,제1 학습 노드의 방법."}
{"patent_id": "10-2024-0106505", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "청구항 1에 있어서,상기 제1 학습 노드는,상기 제2 학습 노드로부터 추가 학습을 요청하는 추가 학습 요청을 수신하는 단계;상기 추가 학습 요청에 기초하여 제2 축소된 순차 학습 데이터셋을 생성하는 단계; 및상기 추가 학습 요청에 대한 응답으로 상기 제2 축소된 순차 학습 데이터셋 또는 제2 순차 학습 데이터 구성 정보 중 적어도 하나를 포함하는 제2 양면 AI/ML 학습 데이터 정보를 상기 제2 학습 노드로 전달하는 단계를 더포함하며,상기 추가 학습 요청의 정보는 추가 학습이 필요한 채널 정보의 샘플 또는 추가 학습이 필요한 채널 정보의 성공개특허 10-2025-0023958-4-능치 중 적어도 하나를 포함하고, 상기 제2 순차 학습 데이터 구성 정보는 상기 제2 축소된 순차 학습 데이터셋이 추가 학습에 이용됨을 지시하는 정보를 포함하는,제1 학습 노드의 방법."}
{"patent_id": "10-2024-0106505", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "청구항 1에 있어서,상기 제1 학습 노드는,상기 순차 학습 데이터셋 또는 순차 학습 데이터 구성 정보 중 적어도 하나를 포함하는 양면 AI/ML 학습 데이터정보를 상기 제2 학습 노드로 전송하는 단계; 및상기 제2 학습 노드로부터 상기 순차 학습 데이터셋에 대해 매핑 정보가 변경되었음을 지시하는 매핑 변경 지시정보를 수신하는 단계를 더 포함하며,상기 제1 양면 AI/ML 모델을 학습한 결과에 따른 제1 성능이 상기 제2 학습 노드에서의 양면 AI/ML 모델을 학습한 결과에 따른 제2 성능 보다 낮을 경우, 상기 변경 지시 정보는 상기 제2 학습 노드로부터 수신되고, 상기 제1 양면 AI/ML 모델에 대한 학습은 상기 순차 학습 데이터셋을 이용하여 수행되는,제1 학습 노드의 방법."}
{"patent_id": "10-2024-0106505", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "청구항 1에 있어서,상기 제1 학습 노드는,상기 순차 학습 데이터셋 또는 순차 학습 데이터 구성 정보 중 적어도 하나를 포함하는 양면 AI/ML 학습 데이터정보를 상기 제2 학습 노드로 전송하는 단계; 및상기 제2 학습 노드로부터 상기 순차 학습 데이터셋에 적용된 축소 방법을 지시하는 축소 방법 정보를 수신하는단계를 더 포함하며,상기 적용된 축소 방법은 임의 샘플링 기반 축소 방법, 채널 정보의 밀도 기반 축소 방법, 매핑 정보의 밀도 기반 축소 방법 또는 모델 기반 중요도 기반 축소 방법 중 적어도 하나를 포함하는,제1 학습 노드의 방법."}
{"patent_id": "10-2024-0106505", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "에 있어서,상기 제2 학습 노드는,상기 제1 학습 노드로부터 순차 학습 데이터셋 또는 순차 학습 데이터 구성 정보 중 적어도 하나를 포함하는 양면 AI/ML 학습 데이터 정보를 수신하는 단계;상기 순차 학습 데이터셋을 이용하여 상기 양면 AI/ML 모델에 대해 학습을 수행하는 단계;상기 학습의 결과에 따라 상기 순차 학습 데이터셋에 대해 매핑 정보 변경을 수행하는 단계; 및상기 순차 학습 데이터셋에 대해 매핑 정보가 변경되었음을 지시하는 매핑 변경 지시 정보를 상기 제1 학습 노드로 전송하는 단계를 포함하며,제1 성능이 제2 성능 보다 낮을 경우, 상기 변경 지시 정보는 상기 제2 학습 노드로 전송되고, 상기 제1 성능은상기 제1 학습 노드에서의 제1 양면 AI/ML 모델을 학습한 결과에 따른 성능이고, 상기 제2 성능은 상기 양면AI/ML 모델을 학습한 결과에 따른 성능인,제2 학습 노드의 방법."}
{"patent_id": "10-2024-0106505", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "청구항 12에 있어서,상기 제2 학습 노드가 데이터 증강의 적용을 결정할 경우, 상기 제2 학습 노드는,공개특허 10-2025-0023958-5-상기 데이터 증강 방법이 적용되었음을 지시하는 제1 지시 정보를 상기 제1 학습 노드로 전송하는 단계를 더 포함하며,상기 제1 지시 정보가 상기 제1 학습 노드로 전송되기 이전에, 상기 제1 양면 AI/ML 모델은 상기 데이터 증강방법을 적용하여 학습되고,상기 제1 지시 정보는 상기 제2 학습 노드에서의 데이터 증강의 적용 여부를 지시하는 정보, 상기 제2 학습 노드가 상기 데이터 증강을 결정하였음을 지시하는 정보 또는 상기 데이터 증강에 적용되는 방법을 지시하는 정보중 적어도 하나를 포함하고,상기 데이터 증강에 적용되는 방법은 잡음 추가 방법, 회전 방법 또는 생성형 AI 모델 이용 방법 중 적어도 하나의 방법인.제2 학습 노드의 방법."}
{"patent_id": "10-2024-0106505", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "청구항 12에 있어서,상기 제2 학습 노드는,상기 제1 학습 노드로부터 추가 학습을 위한 제2 축소된 순차 학습 데이터셋 또는 제2 순차 학습 데이터 구성정보 중 적어도 하나를 포함하는 제2 양면 AI/ML 학습 데이터 정보를 수신하는 단계; 및상기 제2 축소된 순차학습 데이터셋을 이용하여 상기 제1 양면 AI/ML 모델에 대한 추가 학습을 수행하는 단계를더 포함하며,상기 제2 순차 학습 구성 정보는 상기 제2 축소된 순차 학습 데이터셋이 추가 학습에 이용됨을 지시하는 정보를포함하는,제2 학습 노드의 방법."}
{"patent_id": "10-2024-0106505", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "청구항 12에 있어서,상기 제2 학습 노드는,상기 양면 AI/ML 모델에 대해 추가 학습을 요청하는 추가 학습 요청을 상기 제1 학습 노드로 전송하는 단계;상기 추가 학습 요청에 대한 응답으로 제2 축소된 순차 학습 데이터셋 또는 제2 순차 학습 구성 정보 중 적어도하나를 포함하는 제2 양면 AI/ML 학습 데이터 정보를 수신하는 단계; 및상기 제2 축소된 순차 학습 데이터셋을 이용하여 상기 제1 양면 AI/ML 모델에 대한 상기 추가 학습을 수행하는단계를 포함하며,상기 추가 학습 요청의 정보는 추가 학습이 필요한 채널 정보의 샘플 또는 추가 학습이 필요한 채널 정보의 성능 중 적어도 하나를 포함하고, 상기 제2 순차 학습 구성 정보는 상기 제2 축소된 순차 학습 데이터셋이 추가학습에 이용됨을 지시하는 정보를 포함하는,제2 학습 노드의 방법."}
{"patent_id": "10-2024-0106505", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "청구항 15에 있어서,상기 추가 학습 요청을 상기 제1 학습 노드로 전송하는 단계는,상기 제1 학습 노드의 상기 양면 AI/ML 모델 학습에 따른 제1 성능을 상기 제2 학습 노드의 상기 양면 AI/ML 모델 학습에 따른 제2 성능을 비교하는 단계를 포함하며,상기 추가 학습 요청 정보는 상기 제2 성능이 상기 제1 성능 보다 낮을 경우, 상기 제1 학습 노드로 전송되는,제2 학습 노드의 방법.공개특허 10-2025-0023958-6-청구항 17"}
{"patent_id": "10-2024-0106505", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "청구항 14에 있어서,상기 제2 학습 노드는,상기 제1 학습 노드로부터 순차 학습 데이터셋 또는 순차 학습 데이터 구성 정보 중 적어도 하나를 포함하는 양면 AI/ML 학습 데이터 정보를 수신하는 단계;상기 순차 학습 데이터셋에 대해 축소 과정을 수행하여 축소된 순차 학습 데이터셋을 생성하는 단계;상기 축소된 순차 학습 데이터셋을 이용하여 상기 양면 AI/ML 모델에 대해 제2 순차 학습을 수행하는 단계; 및상기 순차 학습 데이터셋에 적용된 축소 방법을 지시하는 축소 방법 정보를 상기 제1 학습 노드로 전송하는 단계를 더 포함하며,상기 적용된 축소 방법은 임의 샘플링 기반 축소 방법, 채널 정보의 밀도 기반 축소 방법, 매핑 정보의 밀도 기반 축소 방법 또는 모델 기반 중요도 기반 축소 방법 중 적어도 하나를 포함하는,제2 학습 노드의 방법."}
{"patent_id": "10-2024-0106505", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제1 학습 노드로서,적어도 하나의 프로세서를 포함하며,상기 적어도 하나의 프로세서는 상기 제1 학습 노드가:CSI(channel state information) 피드백(feedback)을 위해 수집된 원시 학습 데이터셋(dataset)을 이용하여 제1 양면 AI/ML(two-sided artificial intelligence/machine learning) 모델에 대한 학습을 수행하고;상기 제1 양면 AI/ML 모델에 대해 순차 학습(sequential training)을 위한 순차 학습 데이터셋을 생성하고; 그리고,상기 순차 학습 데이터셋 및 상기 제1 양면 AI/ML 모델 정보를 제2 학습 노드로 전송하도록 야기하며,상기 양면 AI/ML 모델 정보는 인코더(encoder) 모델과 관련된 정보 또는 디코더(decoder) 모델과 관련된 정보중 적어도 하나를 포함하는,제1 학습 노드."}
{"patent_id": "10-2024-0106505", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "공개특허 10-2025-0023958-7-청구항 19에 있어서,상기 양면 AI/ML 모델 정보는 백본 인공 신경망의 종류, 입력 데이터의 종류, 입력 데이터의 크기, 출력 데이터의 종류, 출력 데이터의 크기, 연산량, 인공 신경망 파라미터의 개수, 저장 공간 크기, 인공 신경망 파라미터의양자화 방법, 인공 신경망 파라미터, 학습 데이터 식별자 또는 인공 신경망의 성능 관련 정보 중 적어도 하나를포함하는,제1 학습 노드."}
{"patent_id": "10-2024-0106505", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "제1 학습 노드의 방법은, CSI 피드백을 위해 수집된 원시 학습 데이터셋을 이용하여 제1 양면 AI/ML 모델에 대한 학습을 수행하는 단계; 상기 제1 양면 AI/ML 모델에 대해 순차 학습을 위한 순차 학습 데이터셋을 생성하는 단계; 상기 순차 학습 데이터셋에 대해 프루닝을 수행하여 축소된 순차 학습 데이터셋을 획득하는 단계; 및 상기 축소된 순차 학습 데이터셋 또는 순차 학습 데이터 구성 정보 중 적어도 하나를 포함하는 양면 AI/ML 학습 데이 터 정보를 제2 학습 노드로 전송하는 단계를 포함할 수 있다."}
{"patent_id": "10-2024-0106505", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 통신 시스템에서 AI/ML 모델을 학습하는 기술에 관한 것으로, 더욱 상세하게는 채널 상태 정보 피드 백을 위한 양면 AI/ML 모델을 위한 순차 학습 기술에 관한 것이다."}
{"patent_id": "10-2024-0106505", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "정보 통신 기술의 발전과 더불어 다양한 무선 통신 기술이 개발될 수 있다. 대표적인 무선 통신 기술로 3GPP(3rd generation partnership project) 표준에서 규정된 LTE(long term evolution), NR(new radio), 6G(6th Generation) 등이 있을 수 있다. LTE는 4G(4th Generation) 무선 통신 기술들 중에서 하나의 무선 통신 기술일 수 있고, NR은 5G(5th Generation) 무선 통신 기술들 중에서 하나의 무선 통신 기술일 수 있다. 4G 통신 시스템(예를 들어, LTE를 지원하는 통신 시스템)의 상용화 이후에 급증하는 무선 데이터의 처리를 위해, 4G 통신 시스템의 주파수 대역(예를 들어, 6GHz 이하의 주파수 대역)뿐만 아니라 4G 통신 시스템의 주파 수 대역보다 높은 주파수 대역(예를 들어, 6GHz 이상의 주파수 대역)을 사용하는 5G 통신 시스템(예를 들어, NR 을 지원하는 통신 시스템)이 고려될 수 있다. 5G 통신 시스템은 eMBB(enhanced Mobile BroadBand), URLLC(Ultra-Reliable and Low Latency Communication) 및 mMTC(massive Machine Type Communication)을 지원 할 수 있다. 최근 AI(artificial intelligence) 및 ML(machine learning) 기술을 이동 통신에 적용하는 연구가 활발히 진행 중에 있다. AI/ML 기반으로 채널 상태 정보(channel state information, CSI) 피드백 등의 피드백 절차의 성능 을 향상시키는 방안이 연구되고 있다. CSI 피드백을 위한 양면 기계 학습 모델의 경우, 추론이 단말 및 기지국 측에 각각 존재하는 모델들에 의하여 통합적으로 수행되기 위한 기술이 요구될 수 있다."}
{"patent_id": "10-2024-0106505", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "상기한 요구를 달성하기 위한 본 개시의 목적은, 통신 시스템에서 채널 상태 정보 피드백을 위한 양면 AI/ML 모 델의 순차 학습 방법 및 장치를 제공하는데 있다."}
{"patent_id": "10-2024-0106505", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기 목적을 달성하기 위한 본 개시의 실시예들에 따른 제1 학습 노드의 방법은, CSI(channel state information) 피드백(feedback)을 위해 수집된 원시 학습 데이터셋(dataset)을 이용하여 제1 양면 AI/ML(two- sided artificial intelligence/machine learning) 모델에 대한 학습을 수행하는 단계; 상기 제1 양면 AI/ML 모델에 대해 순차 학습(sequential training)을 위한 순차 학습 데이터셋을 생성하는 단계; 상기 순차 학습 데 이터셋에 대해 프루닝(pruning)을 수행하여 축소된 순차 학습 데이터셋을 획득하는 단계; 및 상기 축소된 순차 학습 데이터셋 또는 순차 학습 데이터 구성 정보 중 적어도 하나를 포함하는 양면 AI/ML 학습 데이터 정보를 제 2 학습 노드로 전송하는 단계를 포함할 수 있으며, 상기 원시 학습 데이터셋은 복수의 원시 학습 데이터를 포함 하고, 상기 원시 학습 데이터는 채널 정보, 셀 정보, 지역 정보 또는 SNR(signal to noise ratio) 정보 중 적어 도 하나를 포함할 수 있고, 상기 순차 학습 데이터셋과 상기 축소된 순차 학습 데이터셋은 각각은 복수의 순차 학습 데이터를 포함할 수 있고, 상기 순차 학습 데이터는 상기 채널 정보 및 상기 채널 정보에 대한 매핑 정보 의 쌍을 포함할 수 있고, 상기 채널 정보는 채널 행렬 또는 프리코딩 벡터일 수 있다.상기 제1 양면 AI/ML 모델은 제1 인코더(encoder) 모델 또는 제1 디코더(decoder) 모델 증 적어도 하나를 포함 할 수 있고, 상기 제1 학습 노드가 기지국일 경우, 상기 제1 인코더 모델은 상기 CSI 피드백 동작에서 이용되지 않을 수 있고, 상기 CSI 피드백은 상기 제1 학습 노드에서의 추론(inference)에 대응될 수 있다. 상기 구성 정보는 상기 원시 학습 데이터의 샘플 개수, 상기 원시 학습 데이터의 추가 정보, 상기 순차 학습 데 이터의 샘플 개수, 상기 순차 학습 데이터 개수의 축소율, 상기 채널 정보의 종류, 상기 채널 정보의 양자화 여 부 및 양자화 방법, 상기 매핑 정보의 양자화 방법 또는 상기 제1 학습 노드의 모델 및 학습에 따른 성능치 중 적어도 하나를 포함할 수 있다. 상기 구성 정보는 상기 순차 학습 데이터의 축소 방법에 대한 정보를 포함할 수 있고, 상기 축소 방법은 임의 샘플링 기반 축소 방법, 채널 정보의 밀도 기반 축소 방법, 매핑 정보의 밀도 기반 축소 방법 또는 모델 기반 중요도 기반 축소 방법 중 적어도 하나를 포함할 수 있다. 상기 구성 정보는 상기 순차 학습을 위한 상기 순차 학습 데이터의 각 샘플 별 중요도 또는 밀도 정보 중 적어 도 하나의 정보를 포함할 수 있고, 상기 적어도 하나의 정보는 상기 순차 학습을 위한 상기 순차 학습 데이터를 축소하는 방법에 따라 결정될 수 있다. 상기 제1 학습 노드는, 상기 제2 학습 노드로부터 데이터 증강(augmentation)이 적용되었음을 지시하는 제1 지 시 정보를 수신하는 단계를 더 포함할 수 있으며, 상기 제1 지시 정보는 상기 데이터 증강에 적용되는 방법에 관련된 정보를 포함할 수 있고, 상기 방법은 잡음 추가 방법, 회전 방법 또는 생성형 AI 모델을 이용한 방법 중 적어도 하나의 방법일 수 있고, 상기 방법은 상기 제1 양면 AI/ML 모델에서 학습에 고려될 수 있다. 상기 제1 지시 정보에 따라 상기 제2 노드가 데이터 증강을 적용한 것으로 확인될 경우, 상기 제1 학습 노드는 상기 방법을 적용하여 상기 양면 AI/ML 모델에 대해 새로운 학습 또는 추가 학습을 수행할 수 있다. 상기 축소된 순차 학습 데이터셋이 상기 제2 학습 노드로 전달된 이후, 상기 제1 학습 노드는, 추가 학습을 위 한 제2 축소된 순차 학습 데이터셋을 생성하는 단계; 및 상기 제2 축소된 순차 학습 데이터셋 또는 제2 순차 학 습 데이터 구성 정보 중 적어도 하나를 포함하는 제2 양면 AI/ML 학습 데이터 정보를 상기 제2 학습 노드로 전 달하는 단계를 더 포함할 수 있으며, 상기 제2 순차 학습 데이터 구성 정보는 상기 제2 축소된 순차 학습 데이 터셋이 추가 학습에 이용됨을 지시하는 정보를 포함할 수 있다. 상기 제1 학습 노드는, 상기 제2 학습 노드로부터 추가 학습을 요청하는 추가 학습 요청을 수신하는 단계; 상기 추가 학습 요청에 기초하여 제2 축소된 순차 학습 데이터셋을 생성하는 단계; 및 상기 추가 학습 요청에 대한 응답으로 상기 제2 축소된 순차 학습 데이터셋 또는 제2 순차 학습 데이터 구성 정보 중 적어도 하나를 포함하 는 제2 양면 AI/ML 학습 데이터 정보를 상기 제2 학습 노드로 전달하는 단계를 더 포함할 수 있으며, 상기 추가 학습 요청의 정보는 추가 학습이 필요한 채널 정보의 샘플 또는 추가 학습이 필요한 채널 정보의 성능치 중 적 어도 하나를 포함할 수 있고, 상기 제2 순차 학습 데이터 구성 정보는 상기 제2 축소된 순차 학습 데이터셋이 추가 학습에 이용됨을 지시하는 정보를 포함할 수 있다. 상기 제1 학습 노드는, 상기 순차 학습 데이터셋 또는 순차 학습 데이터 구성 정보 중 적어도 하나를 포함하는 양면 AI/ML 학습 데이터 정보를 상기 제2 학습 노드로 전송하는 단계; 및 상기 제2 학습 노드로부터 상기 순차 학습 데이터셋에 대해 매핑 정보가 변경되었음을 지시하는 매핑 변경 지시 정보를 수신하는 단계를 더 포함할 수 있으며, 상기 제1 양면 AI/ML 모델을 학습한 결과에 따른 제1 성능이 상기 제2 학습 노드에서의 양면 AI/ML 모델을 학습한 결과에 따른 제2 성능 보다 낮을 경우, 상기 변경 지시 정보는 상기 제2 학습 노드로부터 수신될 수 있고, 상기 제1 양면 AI/ML 모델에 대한 학습은 상기 순차 학습 데이터셋을 이용하여 수행될 수 있다. 상기 제1 학습 노드는, 상기 순차 학습 데이터셋 또는 순차 학습 데이터 구성 정보 중 적어도 하나를 포함하는 양면 AI/ML 학습 데이터 정보를 상기 제2 학습 노드로 전송하는 단계; 및 상기 제2 학습 노드로부터 상기 순차 학습 데이터셋에 적용된 축소 방법을 지시하는 축소 방법 정보를 수신하는 단계를 더 포함할 수 있으며, 상기 적용된 축소 방법은 임의 샘플링 기반 축소 방법, 채널 정보의 밀도 기반 축소 방법, 매핑 정보의 밀도 기반 축 소 방법 또는 모델 기반 중요도 기반 축소 방법 중 적어도 하나를 포함할 수 있다. 상기 목적을 달성하기 위한 본 개시의 실시예들에 따른 제2 학습 노드의 방법은, 제1 학습 노드로부터 축소된 순차 학습(sequential training) 데이터셋(dataset)을 포함하는 양면 AI/ML(two-sided artificial intelligence/machine learning) 학습 데이터 정보를 수신하는 단계; 상기 축소된 순차 학습 데이터셋을 이용하 여 CSI(channel state information) 피드백(feedback)을 위한 양면 AI/ML 모델에 대해 순차 학습(sequentialtraining)을 수행하는 단계; 및 상기 양면 AI/ML 모델에 기초하여 CSI 피드백 정보를 상기 제1 학습 노드로 전 송하는 단계를 포함할 수 있으며, 상기 양면 AI/ML 모델은 인코더(encoder) 또는 디코더(decoder) 모델 중 적어 도 하나를 포함할 수 있고, 상기 축소된 순차 학습 데이터셋은 복수의 순차 학습 데이터를 포함할 수 있고, 상 기 복수의 순차 학습 데이터 각각은 채널 정보 및 상기 채널 정보에 대한 매핑 정보의 쌍을 포함할 수 있고, 상 기 채널 정보는 적어도 하나의 샘플을 포함하고, 상기 채널 정보는 채널 행렬 또는 프리코딩 벡터로 표현될 수 있다. 상기 제2 학습 노드가 데이터 증강의 적용을 결정할 경우, 상기 제2 학습 노드는, 상기 데이터 증강 방법이 적 용되었음을 지시하는 제1 지시 정보를 상기 제1 학습 노드로 전송하는 단계를 더 포함할 수 있으며, 상기 제1 지시 정보가 상기 제1 학습 노드로 전송되기 이전에, 상기 제1 양면 AI/ML 모델은 상기 데이터 증강 방법을 적 용하여 학습될 수 있고, 상기 제1 지시 정보는 상기 제2 학습 노드에서의 데이터 증강의 적용 여부를 지시하는 정보, 상기 제2 학습 노드가 상기 데이터 증강을 결정하였음을 지시하는 정보 또는 상기 데이터 증강에 적용되 는 방법을 지시하는 정보 중 적어도 하나를 포함할 수 있고, 상기 데이터 증강에 적용되는 방법은 잡음 추가 방 법, 회전 방법 또는 생성형 AI 모델 이용 방법 중 적어도 하나의 방법일 수 있다. 상기 제2 학습 노드는, 상기 제1 학습 노드로부터 추가 학습을 위한 제2 축소된 순차 학습 데이터셋 또는 제2 순차 학습 데이터 구성 정보 중 적어도 하나를 포함하는 제2 양면 AI/ML 학습 데이터 정보를 수신하는 단계; 및 상기 제2 축소된 순차학습 데이터셋을 이용하여 상기 제1 양면 AI/ML 모델에 대한 추가 학습을 수행하는 단계를 더 포함할 수 있으며, 상기 제2 순차 학습 구성 정보는 상기 제2 축소된 순차 학습 데이터셋이 추가 학습에 이 용됨을 지시하는 정보를 포함할 수 있다. 상기 제2 학습 노드는, 상기 양면 AI/ML 모델에 대해 추가 학습을 요청하는 추가 학습 요청을 상기 제1 학습 노 드로 전송하는 단계; 상기 추가 학습 요청에 대한 응답으로 제2 축소된 순차 학습 데이터셋 또는 제2 순차 학습 구성 정보 중 적어도 하나를 포함하는 제2 양면 AI/ML 학습 데이터 정보를 수신하는 단계; 및 상기 제2 축소된 순차 학습 데이터셋을 이용하여 상기 제1 양면 AI/ML 모델에 대한 상기 추가 학습을 수행하는 단계를 포함할 수 있으며, 상기 추가 학습 요청의 정보는 추가 학습이 필요한 채널 정보의 샘플 또는 추가 학습이 필요한 채널 정 보의 성능 중 적어도 하나를 포함할 수 있고, 상기 제2 순차 학습 구성 정보는 상기 제2 축소된 순차 학습 데이 터셋이 추가 학습에 이용됨을 지시하는 정보를 포함할 수 있다. 상기 추가 학습 요청을 상기 제1 학습 노드로 전송하는 단계는, 상기 제1 학습 노드의 상기 양면 AI/ML 모델 학 습에 따른 제1 성능을 상기 제2 학습 노드의 상기 양면 AI/ML 모델 학습에 따른 제2 성능을 비교하는 단계를 포 함할 수 있으며, 상기 추가 학습 요청 정보는 상기 제2 성능이 상기 제1 성능 보다 낮을 경우, 상기 제1 학습 노드로 전송될 수 있다. 상기 제2 학습 노드는, 상기 제1 학습 노드로부터 순차 학습 데이터셋 또는 순차 학습 데이터 구성 정보 중 적 어도 하나를 포함하는 양면 AI/ML 학습 데이터 정보를 수신하는 단계; 상기 순차 학습 데이터셋을 이용하여 상 기 양면 AI/ML 모델에 대해 학습을 수행하는 단계; 상기 학습의 결과에 따라 상기 순차 학습 데이터셋에 대해 매핑 정보 변경을 수행하는 단계; 및 상기 순차 학습 데이터셋에 대해 매핑 정보가 변경되었음을 지시하는 매핑 변경 지시 정보를 상기 제1 학습 노드로 전송하는 단계를 포함할 수 있으며, 제1 성능이 제2 성능 보다 낮을 경 우, 상기 변경 지시 정보는 상기 제2 학습 노드로 전송될 수 있고, 상기 제1 성능은 상기 제1 학습 노드에서의 제1 양면 AI/ML 모델을 학습한 결과에 따른 성능일 수 있고, 상기 제2 성능은 상기 양면 AI/ML 모델을 학습한 결과에 따른 성능일 수 있다. 상기 제2 학습 노드는, 상기 제1 학습 노드로부터 순차 학습 데이터셋 또는 순차 학습 데이터 구성 정보 중 적 어도 하나를 포함하는 양면 AI/ML 학습 데이터 정보를 수신하는 단계; 상기 순차 학습 데이터셋에 대해 축소 과 정을 수행하여 축소된 순차 학습 데이터셋을 생성하는 단계; 상기 축소된 순차 학습 데이터셋을 이용하여 상기 양면 AI/ML 모델에 대해 제2 순차 학습을 수행하는 단계; 및 상기 순차 학습 데이터셋에 적용된 축소 방법을 지 시하는 축소 방법 정보를 상기 제1 학습 노드로 전송하는 단계를 더 포함할 수 있으며, 상기 적용된 축소 방법 은 임의 샘플링 기반 축소 방법, 채널 정보의 밀도 기반 축소 방법, 매핑 정보의 밀도 기반 축소 방법 또는 모 델 기반 중요도 기반 축소 방법 중 적어도 하나를 포함할 수 있다. 상기 목적을 달성하기 위한 본 개시의 실시예들에 따른 제1 학습 노드는, 적어도 하나의 프로세서를 포함하며, 상기 적어도 하나의 프로세서는 상기 제1 학습 노드가: CSI(channel state information) 피드백(feedback)을 위해 수집된 원시 학습 데이터셋(dataset)을 이용하여 제1 양면 AI/ML(two-sided artificial intelligence/machine learning) 모델에 대한 학습을 수행하고; 상기 제1 양면 AI/ML 모델에 대해 순차 학습(sequential training)을 위한 순차 학습 데이터셋을 생성하고; 그리고, 상기 순차 학습 데이터셋 및 상기 제1 양면 AI/ML 모델 정보를 제2 학습 노드로 전송하도록 야기할 수 있으며, 상기 양면 AI/ML 모델 정보는 인코더 (encoder) 모델과 관련된 정보 또는 디코더(decoder) 모델과 관련된 정보 중 적어도 하나를 포함할 수 있다. 상기 양면 AI/ML 모델 정보는 백본 인공 신경망의 종류, 입력 데이터의 종류, 입력 데이터의 크기, 출력 데이터 의 종류, 출력 데이터의 크기, 연산량, 인공 신경망 파라미터의 개수, 저장 공간 크기, 인공 신경망 파라미터의 양자화 방법, 인공 신경망 파라미터, 학습 데이터 식별자 또는 인공 신경망의 성능 관련 정보 중 적어도 하나를 포함할 수 있다."}
{"patent_id": "10-2024-0106505", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 개시의 실시예들에 따르면, 통신 시스템에서 CSI 피드백을 수행하기 위한 AI/ML 모델의 순차 학습 방법이 제 공될 수 있다. AI/ML 모델의 순차 학습 방법에서는, 축소된 순차 학습용 학습 데이터를 이용한 학습 방법이 제공될 수 있다. 제공된 학습 방법은 순차 학습을 더 용이하도록 할 수 있다. 축소된 순차 학습용 학습 데이터는 샘플의 개수를 축소하여 구성될 수 있다. AI/ML 모델의 순차 학습 방안에서, 제1 학습 노드는 AI/ML 모델에 대한 전체 또는 부분 정보를 구성할 수 있다. 제1 학습 노드는 AI/ML 모델에 대한 전체 또는 부분 정보를 제2 학습 노드로 전달하는 방법을 제공할 수 있다. 제2 학습 노드는 제1 학습 노드로부터 제공된 AI/ML 모델에 대한 전체 또는 부분 정보를 이용하여 효율적인 AI/ML 모델을 구성할 수 있다."}
{"patent_id": "10-2024-0106505", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 개시는 다양한 변경을 가할 수 있고 여러 가지 실시예를 가질 수 있는 바, 특정 실시예들을 도면에 예시하고 상세하게 설명하고자 한다. 그러나, 이는 본 개시를 특정한 실시 형태에 대해 한정하려는 것이 아니며, 본 개시 의 사상 및 기술 범위에 포함되는 모든 변경, 균등물 내지 대체물을 포함하는 것으로 이해되어야 한다. 제1, 제2 등의 용어는 다양한 구성요소들을 설명하는데 사용될 수 있지만, 상기 구성요소들은 상기 용어들에 의 해 한정되어서는 안 된다. 상기 용어들은 하나의 구성요소를 다른 구성요소로부터 구별하는 목적으로만 사용된 다. 예를 들어, 본 개시의 권리 범위를 벗어나지 않으면서 제1 구성요소는 제2 구성요소로 명명될 수 있고, 유 사하게 제2 구성요소도 제1 구성요소로 명명될 수 있다. 및/또는 이라는 용어는 복수의 관련된 기재된 항목들의 조합 또는 복수의 관련된 기재된 항목들 중의 어느 항목을 포함한다. 어떤 구성요소가 다른 구성요소에 \"연결되어\" 있다거나 \"접속되어\" 있다고 언급된 때에는, 그 다른 구성요소에 직접적으로 연결되어 있거나 또는 접속되어 있을 수도 있지만, 중간에 다른 구성요소가 존재할 수도 있다고 이해되어야 할 것이다. 반면에, 어떤 구성요소가 다른 구성요소에 \"직접 연결되어\" 있다거나 \"직접 접속되어\" 있 다고 언급된 때에는, 중간에 다른 구성요소가 존재하지 않는 것으로 이해되어야 할 것이다. 본 개시에서 사용한 용어는 단지 특정한 실시예를 설명하기 위해 사용된 것으로, 본 개시를 한정하려는 의도가 아니다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 개시에서, \"포함 하다\" 또는 \"가지다\" 등의 용어는 명세서상에 기재된 특징, 숫자, 단계, 동작, 구성요소, 부품 또는 이들을 조 합한 것이 존재함을 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성요소, 부 품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되어야 한다. 다르게 정의되지 않는 한, 기술적이거나 과학적인 용어를 포함해서 여기서 사용되는 모든 용어들은 본 개시가 속하는 기술 분야에서 통상의 지식을 가진 자에 의해 일반적으로 이해되는 것과 동일한 의미를 가지고 있다. 일 반적으로 사용되는 사전에 정의되어 있는 것과 같은 용어들은 관련 기술의 문맥 상 가지는 의미와 일치하는 의 미를 가진 것으로 해석되어야 하며, 본 개시에서 명백하게 정의하지 않는 한, 이상적이거나 과도하게 형식적인 의미로 해석되지 않는다. 본 개시에 따른 실시예들이 적용되는 통신 시스템(communication system)이 설명될 것이다. 본 개시에 따른 실 시예들이 적용되는 통신 시스템은 아래 설명된 내용에 한정되지 않으며, 본 개시에 따른 실시예들은 다양한 통 신 시스템에 적용될 수 있다. 여기서, 통신 시스템은 통신 네트워크(network)와 동일한 의미로 사용될 수 있다. 명세서 전체에서 망(network)은, 예를 들어, WiFi(wireless fidelity)와 같은 무선인터넷, WiBro(wireless broadband internet) 또는 WiMax(world interoperability for microwave access)와 같은 휴대인터넷, GSM(global system for mobile communication) 또는 CDMA(code division multiple access)와 같은 2G 이동통 신망, WCDMA(wideband code division multiple access) 또는 CDMA2000과 같은 3G 이동통신망, HSDPA(high speed downlink packet access) 또는 HSUPA(high speed uplink packet access)와 같은 3.5G 이동통신망, LTE(long term evolution)망 또는 LTE-Advanced망과 같은 4G 이동통신망, 및 5G 이동통신망 등을 포함할 수 있 다. 명세서 전체에서 단말(terminal)은 이동국(mobile station), 이동 단말(mobile terminal), 가입자국 (subscriber station), 휴대 가입자국(portable subscriber station), 사용자 장치(user equipment), 접근 단 말(access terminal) 등을 지칭할 수도 있고, 단말, 이동국, 이동 단말, 가입자국, 휴대 가입자 국, 사용자 장 치, 접근 단말 등의 전부 또는 일부의 기능을 포함할 수도 있다. 여기서, 단말로 통신이 가능한 데스크탑 컴퓨터(desktop computer), 랩탑 컴퓨터(laptop computer), 태블릿 (tablet) PC, 무선전화기(wireless phone), 모바일폰(mobile phone), 스마트 폰(smart phone), 스마트 워치 (smart watch), 스마트 글래스(smart glass), e-book 리더기, PMP(portable multimedia player), 휴대용 게임 기, 네비게이션(navigation) 장치, 디지털 카메라(digital camera), DMB (digital multimedia broadcasting) 재생기, 디지털 음성 녹음기(digital audio recorder), 디지털 음성 재생기(digital audio player), 디지털 영 상 녹화기(digital picture recorder), 디지털 영상 재생기(digital picture player), 디지털 동영상 녹화기 (digital video recorder), 디지털 동영상 재생기(digital video player) 등을 사용할 수 있다. 명세서 전체에서 기지국(base station)은 접근점(access point), 무선 접근국(radio access station), 노드 B(node B), 고도화 노드B(evolved nodeB), 송수신 기지국(base transceiver station), MMR(mobile multihop relay)-BS 등을 지칭할 수도 있고, 기지국, 접근점, 무선 접근국, 노드B, eNodeB, 송수신 기지국, MMR-BS 등의 전부 또는 일부의 기능을 포함할 수도 있다. 이하, 첨부한 도면들을 참조하여, 본 개시의 바람직한 실시예를 보다 상세하게 설명하고자 한다. 본 개시를 설 명함에 있어 전체적인 이해를 용이하게 하기 위하여 도면상의 동일한 구성요소에 대해서는 동일한 참조부호를 사용하고 동일한 구성요소에 대해서 중복된 설명은 생략한다. 도 1은 통신 시스템의 일 실시예를 도시한 개념도이다. 도 1을 참조하면, 통신 시스템은 복수의 통신 노드들(110-1, 110-2, 110-3, 120-1, 120-2, 130-1, 130-2, 130-3, 130-4, 130-5, 130-6)을 포함할 수 있다. 복수의 통신 노드들은 3GPP(3rd generation partnership project) 표준에서 규정된 4G 통신(예를 들어, LTE(long term evolution), LTE-A(advanced)), 5G 통신(예를 들 어, NR(new radio)) 등을 지원할 수 있다. 4G 통신은 6GHz 이하의 주파수 대역에서 수행될 수 있고, 5G 통신은 6GHz 이하의 주파수 대역뿐만 아니라 6GHz 이상의 주파수 대역에서 수행될 수 있다.예를 들어, 4G 통신 및 5G 통신을 위해 복수의 통신 노드들은 CDMA(code division multiple access) 기반의 통 신 프로토콜, WCDMA(wideband CDMA) 기반의 통신 프로토콜, TDMA(time division multiple access) 기반의 통신 프로토콜, FDMA(frequency division multiple access) 기반의 통신 프로토콜, OFDM(orthogonal frequency division multiplexing) 기반의 통신 프로토콜, Filtered OFDM 기반의 통신 프로토콜, CP(cyclic prefix)-OFDM 기반의 통신 프로토콜, DFT-s-OFDM(discrete Fourier transform-spread-OFDM) 기반의 통신 프로토콜, OFDMA(orthogonal frequency division multiple access) 기반의 통신 프로토콜, SC(single carrier)-FDMA 기반 의 통신 프로토콜, NOMA(Non-orthogonal Multiple Access), GFDM(generalized frequency division multiplexing) 기반의 통신 프로토콜, FBMC(filter bank multi-carrier) 기반의 통신 프로토콜, UFMC(universal filtered multi-carrier) 기반의 통신 프로토콜, SDMA(Space Division Multiple Access) 기반 의 통신 프로토콜 등을 지원할 수 있다. 또한, 통신 시스템은 코어 네트워크(core network)를 더 포함할 수 있다. 통신 시스템이 4G 통신을 지원하는 경우, 코어 네트워크는 S-GW(serving-gateway), P-GW(PDN(packet data network)-gateway), MME(mobility management entity) 등을 포함할 수 있다. 통신 시스템이 5G 통신을 지원하는 경우, 코어 네트워크는 UPF(user plane function), SMF(session management function), AMF(access and mobility management function) 등을 포함할 수 있다. 한편, 통신 시스템을 구성하는 복수의 통신 노드들(110-1, 110-2, 110-3, 120-1, 120-2, 130-1, 130-2, 130-3, 130-4, 130-5, 130-6) 각각은 다음과 같은 구조를 가질 수 있다. 도 2는 통신 시스템을 구성하는 통신 노드의 일 실시예를 도시한 블록도이다. 도 2를 참조하면, 통신 노드는 적어도 하나의 프로세서, 메모리 및 네트워크와 연결되어 통신을 수행하는 송수신 장치를 포함할 수 있다. 또한, 통신 노드는 입력 인터페이스 장치, 출력 인터 페이스 장치, 저장 장치 등을 더 포함할 수 있다. 통신 노드에 포함된 각각의 구성 요소들은 버 스(bus)에 의해 연결되어 서로 통신을 수행할 수 있다. 다만, 통신 노드에 포함된 각각의 구성요소들은 공통 버스가 아니라, 프로세서를 중심으로 개별 인터페이스 또는 개별 버스를 통하여 연결될 수도 있다. 예를 들어, 프로세서는 메모리, 송수신 장치 , 입력 인터페이스 장치, 출력 인터페이스 장치 및 저장 장치 중에서 적어도 하나와 전용 인터페이스를 통하여 연결될 수도 있다. 프로세서는 메모리 및 저장 장치 중에서 적어도 하나에 저장된 프로그램 명령(program comman d)을 실행할 수 있다. 프로세서는 중앙 처리 장치(central processing unit, CPU), 그래픽 처리 장치 (graphics processing unit, GPU), 또는 본 개시의 실시예들에 따른 방법들이 수행되는 전용의 프로세서를 의미 할 수 있다. 메모리 및 저장 장치 각각은 휘발성 저장 매체 및 비휘발성 저장 매체 중에서 적어도 하 나로 구성될 수 있다. 예를 들어, 메모리는 읽기 전용 메모리(read only memory, ROM) 및 랜덤 액세스 메 모리(random access memory, RAM) 중에서 적어도 하나로 구성될 수 있다. 다시 도 1을 참조하면, 통신 시스템은 복수의 기지국들(base stations)(110-1, 110-2, 110-3, 120-1, 120-2), 복수의 단말들(130-1, 130-2, 130-3, 130-4, 130-5, 130-6)을 포함할 수 있다. 기지국(110-1, 110-2, 110-3, 120-1, 120-2) 및 단말(130-1, 130-2, 130-3, 130-4, 130-5, 130-6)을 포함하는 통신 시스템은 \" 액세스 네트워크\"로 지칭될 수 있다. 제1 기지국(110-1), 제2 기지국(110-2) 및 제3 기지국(110-3) 각각은 매크 로 셀(macro cell)을 형성할 수 있다. 제4 기지국(120-1) 및 제5 기지국(120-2) 각각은 스몰 셀(small cell)을 형성할 수 있다. 제1 기지국(110-1)의 셀 커버리지(cell coverage) 내에 제4 기지국(120-1), 제3 단말(130-3) 및 제4 단말(130-4)이 속할 수 있다. 제2 기지국(110-2)의 셀 커버리지 내에 제2 단말(130-2), 제4 단말(130- 4) 및 제5 단말(130-5)이 속할 수 있다. 제3 기지국(110-3)의 셀 커버리지 내에 제5 기지국(120-2), 제4 단말 (130-4), 제5 단말(130-5) 및 제6 단말(130-6)이 속할 수 있다. 제4 기지국(120-1)의 셀 커버리지 내에 제1 단 말(130-1)이 속할 수 있다. 제5 기지국(120-2)의 셀 커버리지 내에 제6 단말(130-6)이 속할 수 있다. 여기서, 복수의 기지국들(110-1, 110-2, 110-3, 120-1, 120-2) 각각은 노드B(NodeB), 고도화 노드B(evolved NodeB), BTS(base transceiver station), 무선 기지국(radio base station), 무선 트랜시버(radio transceiver), 액세스 포인트(access point), 액세스 노드(node), RSU(road side unit), RRH(radio remote head), TP(transmission point), TRP(transmission and reception point), eNB, gNB 등으로 지칭될 수 있다. 복수의 단말들(130-1, 130-2, 130-3, 130-4, 130-5, 130-6) 각각은 UE(user equipment), 터미널(terminal), 액 세스 터미널(access terminal), 모바일 터미널(mobile terminal), 스테이션(station), 가입자 스테이션 (subscriber station), 모바일 스테이션(mobile station), 휴대 가입자 스테이션(portable subscriber station), 노드(node), 다바이스(device), IoT(Internet of Thing) 장치, 탑재 장치(mounted module/device/terminal 또는 on board device/terminal 등) 등으로 지칭될 수 있다. 한편, 복수의 기지국들(110-1, 110-2, 110-3, 120-1, 120-2) 각각은 서로 다른 주파수 대역에서 동작할 수 있 고, 또는 동일한 주파수 대역에서 동작할 수 있다. 복수의 기지국들(110-1, 110-2, 110-3, 120-1, 120-2) 각각 은 아이디얼 백홀 링크(ideal backhaul link) 또는 논(non)-아이디얼 백홀 링크를 통해 서로 연결될 수 있고, 아이디얼 백홀 링크 또는 논-아이디얼 백홀 링크를 통해 서로 정보를 교환할 수 있다. 복수의 기지국들(110-1, 110-2, 110-3, 120-1, 120-2) 각각은 아이디얼 백홀 링크 또는 논-아이디얼 백홀 링크를 통해 코어 네트워크와 연결될 수 있다. 복수의 기지국들(110-1, 110-2, 110-3, 120-1, 120-2) 각각은 코어 네트워크로부터 수신한 신 호를 해당 단말(130-1, 130-2, 130-3, 130-4, 130-5, 130-6)에 전송할 수 있고, 해당 단말(130-1, 130-2, 130- 3, 130-4, 130-5, 130-6)로부터 수신한 신호를 코어 네트워크에 전송할 수 있다. 또한, 복수의 기지국들(110-1, 110-2, 110-3, 120-1, 120-2) 각각은 MIMO 전송(예를 들어, SU(single user)- MIMO, MU(multi user)-MIMO, 대규모(massive) MIMO 등), CoMP(coordinated multipoint) 전송, CA(carrier aggregation) 전송, 비면허 대역(unlicensed band)에서 전송, 단말 간 직접 통신(device to device communication, D2D)(또는, ProSe(proximity services)) 등을 지원할 수 있다. 여기서, 복수의 단말들(130-1, 130-2, 130-3, 130-4, 130-5, 130-6) 각각은 기지국(110-1, 110-2, 110-3, 120-1, 120-2)과 대응하는 동작, 기 지국(110-1, 110-2, 110-3, 120-1, 120-2)에 의해 지원되는 동작을 수행할 수 있다. 예를 들어, 제2 기지국 (110-2)은 SU-MIMO 방식을 기반으로 신호를 제4 단말(130-4)에 전송할 수 있고, 제4 단말(130-4)은 SU-MIMO 방 식에 의해 제2 기지국(110-2)으로부터 신호를 수신할 수 있다. 또는, 제2 기지국(110-2)은 MU-MIMO 방식을 기반 으로 신호를 제4 단말(130-4) 및 제5 단말(130-5)에 전송할 수 있고, 제4 단말(130-4) 및 제5 단말(130-5) 각 각은 MU-MIMO 방식에 의해 제2 기지국(110-2)으로부터 신호를 수신할 수 있다. 제1 기지국(110-1), 제2 기지국(110-2) 및 제3 기지국(110-3) 각각은 CoMP 방식을 기반으로 신호를 제4 단말 (130-4)에 전송할 수 있고, 제4 단말(130-4)은 CoMP 방식에 의해 제1 기지국(110-1), 제2 기지국(110-2) 및 제 3 기지국(110-3)으로부터 신호를 수신할 수 있다. 복수의 기지국들(110-1, 110-2, 110-3, 120-1, 120-2) 각각 은 자신의 셀 커버리지 내에 속한 단말(130-1, 130-2, 130-3, 130-4, 130-5, 130-6)과 CA 방식을 기반으로 신 호를 송수신할 수 있다. 제1 기지국(110-1), 제2 기지국(110-2) 및 제3 기지국(110-3) 각각은 제4 단말(130- 4)과 제5 단말(130-5) 간의 D2D를 제어할 수 있고, 제4 단말(130-4) 및 제5 단말(130-5) 각각은 제2 기지국 (110-2) 및 제3 기지국(110-3) 각각의 제어에 의해 D2D를 수행할 수 있다. 다음으로, 통신 시스템에서 무선 인터페이스의 설정 및 관리 방법들이 설명될 것이다. 통신 노드들 중에서 제1 통신 노드에서 수행되는 방법(예를 들어, 신호의 전송 또는 수신)이 설명되는 경우에도 이에 대응하는 제2 통신 노드는 제1 통신 노드에서 수행되는 방법과 상응하는 방법(예를 들어, 신호의 수신 또는 전송)을 수행할 수 있 다. 즉, 단말의 동작이 설명된 경우에 이에 대응하는 기지국은 단말의 동작과 상응하는 동작을 수행할 수 있다. 반대로, 기지국의 동작이 설명된 경우에 이에 대응하는 단말은 기지국의 동작과 상응하는 동작을 수행할 수 있 다. 한편, 통신 시스템에서 기지국은 통신 프로토콜의 모든 기능들(예를 들어, 원격 무선 송수신 기능, 기저대역 (baseband) 처리 기능)을 수행할 수 있다. 또는, 통신 프로토콜의 모든 기능들 중에서 원격 무선 송수신 기능은 TRP(transmission reception point)(예를 들어, f(flexible)-TRP)에 의해 수행될 수 있고, 통신 프로토콜의 모 든 기능들 중에서 기저대역 처리 기능은 BBU(baseband unit) 블록에 의해 수행될 수 있다. TRP는 RRH(remote radio head), RU(radio unit), TP(transmission point) 등일 수 있다. BBU 블록은 적어도 하나의 BBU 또는 적 어도 하나의 DU(digital unit)를 포함할 수 있다. BBU 블록은 \"BBU 풀(pool)\", \"집중화된(centralized) BBU\" 등으로 지칭될 수 있다. TRP는 유선 프론트홀(fronthaul) 링크 또는 무선 프론트홀 링크를 통해 BBU 블록에 연 결될 수 있다. 백홀 링크 및 프론트홀 링크로 구성되는 통신 시스템은 다음과 같을 수 있다. 통신 프로토콜의 기능 분리(function split) 방식이 적용되는 경우, TRP는 BBU의 일부 기능 또는 MAC(medium access control)/RLC(radio link control)의 일부 기능을 선택적으로 수행할 수 있다. ITU(International Telecommunication Union)에서는 IMT(International Mobile Telecommunication) 프레임워 크 및 표준에 대해서 개발하고 있다. 최근에는 \"IMT for 2030 and beyond\"라는 프로그램을 통하여 6 세대(6G) 통신을 위한 논의가 진행 중이다. 6G를 구현하기 위한 기술 중 크게 주목을 받고 있는 분야는 인공지능(artificial intelligence, AI)/머신러닝(machine learning, ML)이다. 3GPP(3rd generation partnership project)에서는 에어 인터페이스(air interface)를 위한 AI/ML 기술에 대한 연구를 수행하는 것을 릴리즈 18(Release 18)에서 시작하였다. 3GPP에서 수행하는 연구의 주요 사용 예(use case)는 아래와 같다. - 채널 상태 정보(channel state information, CSI) 피드백 개선을 위한 AI/ML; - 빔 관리를 위한 AI/ML; - 측위 성능 향상(positioning performance enhancement)을 위한 AI/ML. 본 개시는 CSI 피드백에 대한 성능을 개선하기 위한 첫번째 사용 예와 높은 관련이 있다. 구체적으로, 통신 시스템에서, 송신기는 수신기로 데이터 전송을 수행하기 위하여 데이터 신호의 부호화 레벨, 전력할당, 그리고 다중 송신 안테나를 이용한 빔포밍 등을 수행한다. 이를 위하여 송신기 및 수신기의 안테나 사이의 무선 채널에 대한 정보를 송신기에서 획득해야 한다. 하지만 송신기로부터 수신기까지의 채널을 송신단 에서 직접 관찰할 수 없기 때문에 수신기에서 측정한 채널 정보를 송신기로 보고하는 절차인 CSI 보고 절차가 필요하다. CSI는 송신기에서 수신기로 데이터 전송을 스케줄링 하기위한 정보이며 랭크(rank), 채널 품질 인덱 스(channel quality index) 및 프리코딩(precoding) 정보가 이에 해당한다. 수신기에서 채널 상태를 측정하기 위하여 CSI-RS(reference signal)와 같은 참조 신호가 설계된다. 송신기가 주 기적 혹은 비주기적으로 CSI-RS를 전송하며, 수신기가 이를 수신할 수 있도록 전송 관련 정보를 사전에 설정한 다. 수신기가 CSI-RS를 수신한 이후 CSI를 생성하여 이를 다시 송신기로 전달하는 CSI 보고 절차가 수행된다. 채널 정보를 정밀하게 표현하기 위해서는 정보량이 매우 커야 하며, 이는 무선전송자원의 점유량 및 오버헤드를 증대시켜 시스템 성능을 감소시키는 요인이 된다. 송신기에서 프리코딩을 결정하기 위한 채널 변화를 표현하기 위한 채널 정보, 또는 적절한 프리코딩 벡터를 수신기에서 추천하기 위한 프리코딩 정보를 정밀하게 표현하는 것은 큰 오버헤드를 야기할 수 있다. 통신 시스템에서 이러한 문제를 해결하기 위하여 AI/ML 기술을 이용하여 전송 정보량을 최소화하면서도 높은 정 확도로 채널 상태 정보를 송신기에서 획득할 수 있는 기술에 대해 연구가 시작되었다. AI/ML 기술을 5세대 이후 통신 시스템에서도 적용하기 위한 논의가 시작되고 있다. 채널 정보를 전달하기 위한 AI/ML 구조로 오토 인코더 (auto encoder) 기반 신경망이 제안되었다. 무선 채널 정보를 이미지 형태로 입력하고, 인코더 네트워크를 통해 저차원 잠재 공간에서 코드 벡터로 압축하여 원래의 무선 상태를 복원하는 CNN(convolution neural network) 기 반의 인공 신경망이 제안되었다. CNN 기반 인공신경망은 효과적으로 압축 및 복원이 가능함을 보였다. 전체 채 널 정보를 전송할 때 전송되는 정보의 양이 많고 압축된 저차원 코드 벡터에 실수가 포함되어 있으므로 수신기 에서 송신기로 정보를 전송하기 위해서는 추가적인 양자화 과정이 고려되어야 한다. CSI 피드백을 위한 양면 AI/ML 모델의 경우, 추론은 단말 측과 기지국 측에 각각 존재하는 모델에 의하여 통합 적으로 수행될 수 있다. 추론을 위하여 사용되는 AI/ML 모델은 상호 동작해야 하는 제약이 존재할 수 있다. 위에서 언급한 제약이 충족되도록 하기 위해, AI/ML 모델의 쌍은 조인트 학습(joint training) 또는 순차 학습 (sequential training)을 통해 학습될 수 있다. 조인트 학습에서, AI/ML 모델의 쌍은 제1 노드(예를 들어, 기지 국)에서 학습하여 배포될 수 있다. 순차 학습은 제1 노드에서 학습된 결과를 제2 노드(예들 들어, 단말)로 전달 하여 학습하는 형태일 수 있다. 앞에서 언급한 바와 같이, 순차 학습에서, 제1 노드는 학습 데이터를 제2 노드로 전달할 수 있다. 제2 노드는 제1 노드로부터 전달된 학습 데이터를 이용하여 학습을 수행할 수 있다. 순차 학습의 경우, 학습 데이터의 크기 가 매우 커지는 문제가 발생할 수 있다. 제1 노드에서 구성한 인공 신경망(artificial neural network, ANN)의 정보는 제2 노드에 존재하기 않을 수 있고, 해당 ANN이 효율적으로 구성될 수 없는 문제가 발생할 수 있다. 본 개시에서는 CSI 피드백을 수행하기 위한 효율적인 AI/ML 모델의 순차 학습 방법이 다음과 같이 제공될 수 있 다. <<순차 학습을 위한 효율적인 학습 데이터 구성 방법>> [방법 1] 본 개시에서 통신 시스템은 기지국과 적어도 하나의 단말을 포함할 수 있다. 기지국(또는 단말)(이하, 제1 학습 노드)이 원시 학습 데이터를 이용하여 양면 AI/ML 모델 중 일부를 학습할 수 있다. 제1 학습 노드는 단말(또는 기지국)(이하, 제2 학습 노드)의 학습을 위한 순차 학습용 학습 데이터를 구성할 수 있다. 본 개시에서는, 제1학습 노드가 순차 학습용 학습 데이터를 제2 학습 노드로 전달하여 제2 학습 노드가 순차 학습용 학습 데이터를 이용한 학습을 수행하도록 하는 것이 제안될 수 있다. 도 3은 본 개시의 실시예들에 따른 채널 상태 정보 피드백을 위한 양면 AI/ML 모델의 순차 학습 방법을 설명하 기 위해 도시한 순서도이다. 도 3을 참조하면, 통신 시스템은 제1 학습 노드 및 제2 학습 노드를 포함할 수 있다. 제1 학습 노드 는 도 1에 도시된 기지국(110-1, 110-2, 110-3, 120-1, 120-2)일 수 있고, 제2 학습 노드는 도 1에 도시된 단 말(130-1, 130-2, 130-3, 130-4, 130-5, 130-6)일 수 있다. 제1 학습 노드 및 제2 학습 노드는 도 2에 도시된 통신 노드와 동일 또는 유사하게 구성될 수 있다. 제1 학습 노드는 원시 학습 데이터를 이용하여 AI/ML 모 델 중 일부를 학습할 일부를 학습할 수 있다. 제2 학습 노드는 제1 학습 노드로부터 전달된 학습된 일부를 이용하여 AI/ML 모델을 학습할 수 있다. AI/ML 모델은 채널 상태 정보(channel state information, CSI) 피드백을 위한 양면 AI/ML 모델을 의미할 수 있다. 양면 AI/ML 모델은 인코더(encoder) 모델 및/또는 디코 더(decoder) 모델을 포함할 수 있다. 도 3에서, 설명의 편의상 하나의 제2 학습 노드가 도시되었지만, 복 수의 제2 학습 노드가 통신 시스템에 존재할 수 있다. 단계 S310에서, 제1 학습 노드는 AI/ML 모델 학습을 위한 데이터셋을 수집할 수 있다. 수집된 데이터셋은 복수의 원시 학습 데이터를 포함할 수 있다. 수집된 데이터셋은 원시 학습 데이터셋으로 표현될 수 있다. AI/ML 모델은 CSI 피드백을 위한 양면 AI/ML 모델을 의미할 수 있다. 양면 AI/ML 모델은 인코더(encoder) 모델 및/또 는 디코더(decoder) 모델을 포함할 수 있다. 단계 S320에서, 제1 학습 노드는 AI/ML 모델을 정의할 수 있다. 단계 S310에서 수집된 데이터셋을 이용하 여, 제1 학습 노드는 AI/ML 모델에 대한 학습을 수행할 수 있다. 제1 학습 노드는 AI/ML 모델에 대해 순차 학습을 위한 데이터셋을 생성할 수 있다. 순차 학습을 위한 데이터셋은 순차 학습 데이터셋으로 표현될 수 있고, 순차 학습을 위한 데이터는 순차 학습 데이터로 표현될 수 있다. 순차 학습 데이터셋은 복수의 순차 학습 데이터를 포함할 수 있다. 원시 학습 데이터는 채널 정보의 샘플(들)을 포함할 수 있다. 채널 정보는 채널 행렬(channel matrix) 또는 프 리코딩 벡터(precoding vector)일 수 있다. 채널 정보가 프리코딩 벡터일 경우, 채널 정보는 원시 정보를 그대 로 표현하거나 표준 규격에서 정의하는 코드북(codebook) 형태(예를 들어, 3GPP의 enhanced TypeII)로 표현될 수 있다. 채널 정보가 표준 규격에서 정의하는 코드북 형태로 표현될 경우, 코드북 파라메터는 표준 규격에서 정의된 가장 높은 파라미터(예를 들어, paramCombination 6 또는 8) 또는 이보다 더 큰 파라미터를 이용하여 표 현될 수 있다. 채널 정보가 원시 정보를 그대로 표현할 경우, 채널 정보는 양자화되지 않거나, 양자화될 수 있다. 양자화 여부 및/또는 양자화 방법은 순차 학습 데이터 정보로 전달될 수 있다. 매핑 정보는 양자화되지 않거나, 양자화될 수 있다. 양자화 여부 및/또는 양자화 방법은 순차 학습 데이터 정보에 포함되어 전달될 수 있다. 순차 학습 데이 터는 순차 학습을 위한 학습 데이터를 의미할 수 있다. 순차 학습 데이터는 채널 정보(예를 들어, 채널 행렬 또는 고유 벡터 등)와 채널 정보에 대한 매핑 정보의 쌍을 포함할 수 있고, 매핑 정보는 제1 학습 노드(예를 들어, 기지국)의 학습 결과에 따라 결정될 수 있다. 원시 학 습 데이터에는 채널 정보 외에도 사이트/셀 정보, 지역 정보 등이 포함될 수 있으며, 샘플 별 신호대 잡음비 (signal to noise ratio, SNR) 등도 포함될 수 있다. 순차 학습 데이터는 각 샘플 또는 전체 샘플에 대한 제1 학습 노드의 성능 값(예를 들어, 복원 성능 정보)을 더 포함할 수 있다. 순차 학습 데이터는 원시 학습 데이터의 채널 정보에 포함된 샘플보다 적은 개수의 샘플을 포함할 수 있다. 단계 S330에서, 제1 학습 노드는 단계 320에서 생성된 순차 학습 데이터셋에 대해 프루닝(pruning)을 수행 하여 축소된 순차 학습 데이터셋을 획득(또는 결정)할 수 있다. 제1 학습 노드는 미리 결정된 방법에 따라 순차 학습 데이터셋에 대해 프루닝을 수행할 수 있다. 축소된 순차 학습 데이터셋은 복수의 순차 학습 데이터를 포함할 수 있다. 앞에서 언급한 바와 같이, 순차 학습 데이터는 채널 정보와 채널 정보에 대한 매핑 정보의 쌍을 포함할 수 있다. 매핑 정보는 제1 학습 노드(예를 들 어, 기지국)의 학습 결과에 따라 결정될 수 있다. 제2 학습 노드는 단계 330에서 획득(또는 결정) 축소된 순차 학습 데이터셋을 AI/ML 모델을 학습하는데 사 용할 수 있다. 제1 학습 노드는 단계 330에서 획득(또는 결정) 축소된 순차 학습 데이터셋을 제2 헉숩 노드로 전달(또는 전송)하기 위해 단계 S340을 수행할 수 있다. 앞에서 언급한 바와 같이, AI/ML 모델은 CSI 피드백을 위한 양면 AI/ML 모델을 의미할 수 있다. 단계 S340에서, 제1 학습 노드는 축소된 순차 학습 데이터셋을 제2 학습 노드로 전달(또는 전송)할 수 있다. 제2 학습 노드는 제1 학습 노드로부터 축소된 순차 학습 데이터셋을 수신할 수 있다. 제1 학습 노드는 축소된 순차 학습 데이터셋 및/또는 순차 학습 데이터 구성 정보를 포함하는 양면 AI/ML 학습 데이터 정보를 제2 학습 노드로 전달(또는 전송)할 수 있다. 제2 학습 노드는 제1 학습 노드 로부터 축소된 순차 학습 데이터셋 및/또는 순차 학습 데이터 구성 정보를 포함하는 양면 AI/ML 학습 데이 터 정보를 수신할 수 있다. 순차 학습 데이터 구성 정보는 후술될 것이다. 일 실시예로, 축소된 순차 학습 데이터셋은 양면 AI/ML 학습 데이터 정보에 포함될 수 있다. 제1 학습 노드 는 축소된 순차 학습 데이터셋을 포함하는 양면 AI/ML 학습 데이터 정보를 제2 학습 노드로 전달(또 는 전송)할 수 있다. 제2 학습 노드는 축소된 순차 학습 데이터셋을 포함하는 양면 AI/ML 학습 데이터 정 보를 수신할 수 있다. 단계 S350에서, 제2 학습 노드는 AI/ML 모델을 정의할 수 있다. 제2 학습 노드는 단계 S340에서 수신 된 축소된 순차 학습 데이터셋을 이용하여 AI/ML 모델에 대한 학습을 수행할 수 있다. 앞에서 언급한 바와 같이, AI/ML 모델은 CSI 피드백을 위한 양면 AI/ML 모델을 의미할 수 있다. 상술한 채널 상태 정보 피드백을 위한 양면 AI/ML 모델의 순차 학습 방법은 단계 S350가 수행된 이후, 제2 학습 노드가 CSI 피드백 정보를 전송하는 단계(이하, CSI 피드백 전송 단계)를 더 포함할 수 있다. CSI 피드백 전송 단계에서, 제2 학습 노드는 단계 S350에서 학습된 AI/ML 모델에 기초하여 CSI 피드백 정 보를 제1 학습 노드로 전송할 수 있다. 제1 학습 노드은 제2 학습 노드로부터 AI/ML 모델에 기 초한 CSI 피드백 정보를 수신할 수 있다. 설명에 편의상에, 제1 학습 노드는 단계 S310에서 CSI 피드백을 위한 양면 AI/ML 모델의 순차 학습을 위한 데이터셋을 수집하지만 이에 제한되지는 않는다. 제1 학습 노드는 단계 S320에서 CSI 피드백을 위한 양면 AI/ML 모델을 정의하지만 이에 제한되지는 않는다. 제2 학습 노드는 단계 S350에서 CSI 피드백을 위한 양 면 AI/ML 모델을 정의하지만 이에 제한되지는 않는다. 일 실시예로, 도 3에 도시한 채널 상태 정보 피드백을 위한 양면 AI/ML 모델의 순차 학습 방법에서, 제1 학습 노드에서의 데이터셋은 수집에 완료되었다고 가정할 수 있다. 제1 학습 노드에서의 AI/ML 모델과 제2 학습 노드에서의 AI/ML 모델은 미리 정의되어 있다고 가정할 수 있다. 앞에서 언급한 바와 같이, AI/ML 모 델은 CSI 피드백을 위한 양면 AI/ML 모델을 의미할 수 있다. 상술한 채널 상태 정보 피드백을 위한 양면 AI/ML 모델의 순차 학습 방법에서, 단계 S310 내지 단계 S350이 개 별적으로 설명되었지만, 이는 단계가 수행되는 순서를 제한하기 위한 것은 아니며, 필요한 경우에는 각각의 단 계가 동시에 수행되거나, 상이한 순서로 수행되거나 또는 단계들이 결합될 수도 있다. 본 개시의 일 실시예로, 기지국 및 단말은 CSI 피드백을 위한 양면 AI/ML 모델을 순차적으로 학습할 수 있다. 제1 학습 노드는 기지국으로, 제2 학습 노드는 단말로 가정할 수 있다. 양면 AI/ML 모델은 인코더 모델 및/또는 디코더 모델을 포함할 수 있다. 기지국이 제1 학습 노드일 경우, 기지국에서의 양면 AI/ML 모델은 인코더 모델과 디코더 모델을 포함할 수 있다. 기지국은 인코더 모델과 디코더 모델을 정의할 수 있다. 기지국은 원시 학습 데이터를 이용하여 양면 AI/ML 모델을 학습할 수 있다. 인코더 모델은 명목상의 모델일 수 있고, 실제 추론(예를 들어, CSI 피드백 동작)에서는 사용되지 않을 수 있다. 기지국에서의 양면 AI/ML 모델이 원시 학습 데이터를 이용하여 학습된 이후, 기지국은 원시 학습 데이터를 축소 하여 순차 학습 데이터를 구성하는 과정을 수행할 수 있다. 이때, 양자화가 원시 학습 데이터의 각 샘플의 채널 정보에 적용될 수 있고, 샘플의 개수가 축소될 수도 있다. 이러한 과정을 통하여, 순차 학습 데이터는 원시 학 습데이터에 비하여 크기가 작아질 수 있다. 도 4는 본 개시의 실시예들에 따른 양면 AI/ML 모델의 순차 학습을 위한 학습 데이터를 설명하기 위해 도시한 개념도이다. 도 4를 참조하면, 순차 학습을 위한 학습 데이터셋은 축소된 학습 데이터셋(reduced training dataset)을 포함 할 수 있다. 축소된 학습 데이터셋은 전체 학습 데이터셋의 일부분일 수 있다. 도 4에서 도시된 전체 학습 데이 터셋은 순차 학습을 위한 학습 데이터셋을 의미할 수 있다. 단말이 제2 학습 노드일 경우, 기지국은 축소된 학습 데이터셋을 단말로 전달(또는 전송)하여 단말이 양면 AI/ML에 포함되는 인코더 모델에 대해 순차 학습을 수행할 수 있도록 할 수 있다. 기지국과 마찬가지로 단말에 서의 양면 AI/ML 모델은 인코더 모델과 디코더 모델을 포함할 수 있고, 단말은 인코더 모델과 디코더 모델을 정 의할 수 있다. 단말은 기지국으로부터 수신된 순차 학습 데이터를 이용하여 양면 AI/ML 모델에 대해 학습을 수 행할 수 있다. 단말이 양면 AI/ML 모델을 학습할 경우, 양면 AI/ML 모델에 포함되는 디코더 모델은 실제 추론 과정에서 사용되지 않을 수 있다. [방법 1-1] 제1 학습 노드는 순차 학습 데이터 구성 정보를 제2 학습 노드로 전달(전송)할 수 있다. 순차 학습 데이터 구성 정보는 다음 중 적어도 하나를 포함할 수 있다. - 원시 학습 데이터의 샘플 개수; - 원시 학습 데이터의 추가 정보; > 예를 들어, 원시 학습데이터의 추가 정보는 사이트/셀 정보, 지역 정보, SNR 등을 포함할 수 있다. - 순차 학습 데이터의 샘플 개수; - 순차 학습 데이터 개수의 축소율; - 채널 정보의 종류; - 채널 정보의 양자화 여부 및 양자화 방법; - 매핑 정보의 양자화 방법; 또는 - 제1 학습 노드의 모델 및 학습에 따른 성능치. 상술한 바와 같이, 채널 상태 정보 피드백을 위한 양면 AI/ML 모델의 순차 학습 방법에서, 제1 학습 노드(예를 들어, 기지국)는 양면 AI/ML 학습 데이터 정보를 제2 학습 노드(예를 들어, 단말)로 전달(또는 전송)할 수 있다. 순차 학습 데이터 구성 정보는 양면 AI/ML 학습 데이터 정보에 포함될 수 있다. 일 실시예로, 제1 학습 노드는 순차적으로 제1 양면 AI/ML 학습 데이터 정보 및 제2 양면 AI/ML 학습 데이터 정 보를 제2 학습 노드로 전송할 수 있다. 제1 양면 AI/ML 학습 데이터 정보는 축소된 순차 학습 데이터셋을 포함 할 수 있고, 제2 양면 AI/ML 학습 데이터 정보는 순차 학습 데이터 구성 정보를 포함할 수 있다. 다른 실시예로, 제1 학습 노드는 축소된 순차 학습 데이터셋과 순차 학습 데이터 구성 정보를 포함하는 양면 AI/ML 학습 데이터 정보를 제2 학습 노드로 전송할 수 있다. [방법 1-2] 제1 학습 노드는 순차 학습 데이터를 다음 중 적어도 하나의 방법으로 축소할 수 있다. 앞에서 언급한 바와 같 이, 순차 학습 데이터는 양면 AI/ML 모델에 대해 순차 학습을 위한 학습 데이터를 의미할 수 있다. - 임의 샘플링 기반 축소; - 채널 정보의 밀도 기반 축소; - 매핑 정보의 밀도 기반 축소; 또는 - 모델 기반 중요도 기반 축소. 제1 학습 노드는 순차 학습 데이터 구성 정보에 순차 학습 데이터의 축소 방법에 대한 정보를 더 포함하여 제2 학습 노드로 전달(또는 전송)할 수 있다. 일 실시예로, 제1 학습 노드가 기지국, 제2 학습 노드는 단말로 가정할 수 있다. 기지국이 원시 학습데이터에서 샘플의 개수를 감소하기 위한 축소 과정을 수행할 경우, 기지국은 여러 방법 중 하나를 적용할 수 있다. 첫째, 임의 샘플링 기반 축소가 수행될 수 있으며, 이는 전체 샘플 중 임의로 선택된 샘플들로 순차 학습 데이 터를 구성하는 것을 의미할 수 있다. 둘째, 채널 정보의 밀도 기반 축소가 수행될 수 있으며, 이는 유사한 채널 정보를 가지는 샘플의 수를 감소시키 기 위한 방법일 수 있다. 이 방법에서는, 각 샘플의 채널 정보와 다른 샘플의 채널 정보 사이의 거리에 기반하 여 샘플의 선택 여부가 결정될 수 있다. 셋째, 매핑 정보의 밀도 기반 축소가 적용될 수 있으며, 이는 유사한 매핑 정보를 가지는 샘플의 수를 감소시키 기 위한 방법일 수 있다. 이 방법에서는, 각 샘플의 매핑 정보와 다른 샘플의 매핑 정보 사이의 거리에 기반하 여 샘플의 선택 여부가 결정될 수 있다. 넷째, 양면 AI/ML 모델 기반 중요도 기반 축소가 적용될 수 있으며, 이는 해당 샘플이 모델의 학습을 위하여 중 요한 정도에 따라 샘플을 선택하는 방법일 수 있다. 이 방법에서는, 훈련된 양면 AI/ML 모델(인코더 모델 및/또 는 디코더 모델)을 이용하여 샘플의 중요도가 선택될 수 있다. 모델 기반 샘플의 중요도는 각 채널 정보 입력에 대한 손실 함수의 크기 및/또는 변화량을 이용하여 측정할 수 있다. 상술한 방법들 외에 다른 방법(들)으로 샘플의 개수가 축소될 수도 있으며, 이 경우에도 축소 방법에 대한 정보 가 제2 학습 노드로 전달될 수 있다. [방법 1-3] 제1 학습 노드는 순차 학습 데이터의 각 샘플 별 중요도 및/또는 밀도 정보를 포함하는 순차 학습 데이터 구성 정보를 제2 학습 노드로 전달(또는 전송)할 수 있다. 각 샘플 별 중요도 및/또는 밀도 정보는 순차 학습 데이터 를 축소하는 방법에 따라 결정될 수 있다. 앞에서 언급한 바와 같이, 순차 학습 데이터는 양면 AI/ML 모델의 순 차 학습을 위한 학습 데이터를 의미할 수 있다. 예를 들어, 순차 학습 데이터를 축소하는 방법이 중요도 기반 방법일 경우, 제1 학습 노드는 순차 학습 데이터 의 각 샘플 별 중요도 정보를 포함하는 순차 학습 데이터 구성 정보를 제2 학습 노드로 전달(또는 전송)할 수 있다. 순차 학습 데이터를 축소하는 방법이 밀도 기반 방법일 경우, 제1 학습 노드는 순차 학습 데이터의 각 샘 플 별 밀도 정보를 포함하는 순차 학습 데이터 구성 정보를 제2 학습 노드로 전달(또는 전송)할 수 있다. [방법 1-4] 제2 학습 노드는 제1 학습 노드로부터 순차 학습 데이터를 수신할 수 있다. 제2 학습 노드는 제1 학습 노드로부 터 수신한 순차 학습 데이터에 데이터 증강(augmentation) 방법을 적용하여 양면 AI/ML 모델과 관련된 인공 신 경망을 학습할 수 있다. 제2 학습 노드가 데이터 증강 방법을 수행할 경우, 제2 학습 노드는 순차 학습 데이터 의 각 샘플 별 중요도 및/또는 밀도 정보를 이용할 수 있다. 방법 1-3에서 상술한 바와 같이 순차 학습 데이터 구성 정보는 순차 학습 데이터의 각 샘플 별 중요도 및/또는 밀도 정보를 포함할 수 있다. 도 5는 본 개시의 실시예들에 따른 데이터 증강을 이용한 양면 AI/ML 모델의 순차 학습 방법을 설명하기 위해 도시한 순서도이다. 도 5를 참조하면, 제1 학습 노드는 순차 학습을 위한 데이터셋에 대해 프루닝(pruning)을 수행하여 축소된 데이 터셋을 생성할 수 있다. 제2 학습 노드는 제1 학습 노드로부터 축소된 데이터셋을 수신할 수 있다. 제2 학습 노 드는 축소된 데이터셋에서 데이터 증강을 적용하여 양면 AI/ML 모델에 대한 학습을 수행할 수 있다. 데이터 증 강의 적용은 제2 학습 노드가 결정하거나 제1 학습 노드로부터 지정될 수 있다. 제2 학습 노드가 데이터 증강의 적용을 결정할 경우, 제2 학습 노드는 \"제2 학습 노드가 데이터 증강의 적용 을 결정하였음\"을 지시하는 정보를 제1 학습 노드로 전송할 수 있다. 제1 학습 노드는 도 3에 도시된 제1 학습 노드일 수 있고, 제2 학습 노 드는 도 3에 도시된 제2 학습 노드일 수 있다. 설명의 편의를 위해, 도 5에 도시한 데이터 증강을 이용한 순차 학습 방법에서, \"제2 학습 노드가 데이터 증강의 적용을 결정하였음\"을 지시하는 정보를 전송하는 단계가 생략되었지만, 데이터 증강을 이용한 순차 학습 방법은 \"제2 학습 노드가 데이터 증강의 적용 을 결정하였음\"을 지시하는 정보를 전송하는 단계를 포함할 수 있다. 단계 S510에서, 제1 학습 노드는 순차 학습을 위한 데이터셋에 대한 프루닝을 수행하여 제1 축소된 데이터셋을 생성(또는 획득)할 수 있다. 순차 학습을 위한 데이터셋은 순차 학습 데이터셋으로 표현될 수 있다. 축소된 데 이터셋은 축소된 순차 학습 데이터셋로 표현될 수 있다. 단계 S520에서, 제1 학습 노드는 단계 510에서 생성(또는 획득)된 제1 축소된 데이터셋을 제2 학습 노드로 전송 할 수 있다. 제2 학습 노드는 제1 학습 노드로부터 제1 축소된 데이터셋을 수신할 수 있다.단계 S530에서, 제2 단말 노드는 AI/ML 모델을 정의할 수 있다. 제2 학습 노드는 단계 S520에서 수신된 제1 축 소된 데이터셋을 이용하여 AI/ML 모델에 대한 학습을 수행할 수 있다. 앞에서 언급한 바와 같이, AI/ML 모델은 CSI 피드백을 위한 양면 AI/ML 모델을 의미할 수 있다. 양면 AI/ML 모델에 대한 학습은 데이터 증강을 축소된 데이터셋에 적용하여 수행될 수 있다. 데이터 증강 (augmentation) 방법이 적용될 경우, 양면 AI/ML 모델과 관련된 인공 신경망에 대해 학습이 수행될 수 있다. 데 이터 증강 방법은 다음 중 적어도 하나를 적용할 수 있다. 앞에서 언급한 바와 같이, 양면 AI/ML 모델은 CSI 피 드백을 위한 양면 AI/ML 모델을 의미할 수 있다. 양면 AI/ML 모델은 인코더 모델 및/또는 디코더 모델을 포함할 수 있다. - 잡음 추가 방법; - 회전 방법; 또는 - 생성형 AI 모델(generative AI model)을 이용한 방법. 본 개시에 실시예들에 따르면, 원시 학습 데이터에 대하여 샘플 개수의 축소가 적용될 경우, 제2 학습 노드는 순차 학습 데이터에 데이터 증강을 적용하여 양면 AI/ML 모델의 학습을 수행할 수 있다. 일 실시예에서, 잡음 추가 방법의 데이터 증강이 적용될 수 있다. 잡음 추가 방법의 데이터 증강이 적용될 경우, 하나의 원시 샘플의 채널 정보에 임의의 잡음이 추가된 하나 이상의 샘플이 추가로 생성될 수 있다. 추가 된 매핑 정보는 원시 샘플의 매핑 정보를 동일하게 사용할 수 있다. 다른 실시예에서, 데이터 증강 방법으로, 회전 방법이 적용될 수 있다. 하나의 원시 샘플의 채널 정보에 대하여 임의의 회전 변환을 적용한 하나 이상의 샘플이 추가로 생성될 수 있다. 추가된 매핑 정보는 원시 샘플의 매핑 정보를 동일하게 사용할 수 있다. 또 다른 실시예에서, 데이터 증강 방법으로, 생성형 AI 모델을 이용한 방법이 적용될 수 있다. 적어도 하나의 샘플은 생성형 AI 모델을 이용하여 생성될 수 있다. 적어도 하나의 샘플 각각은 채널 정보 및 매핑 정보의 쌍으 로 구성될 수 있다. 앞에서 언급한 바와 같이, 데이터 증강의 적용은 제2 학습 노드가 결정하거나 제1 학습 노드로부터 지정될 수 있다. 제2 학습 노드가 데이터 증강의 적용을 결정할 경우, 제2 학습 노드는 \"제2 학습 노드가 데이터 증강의 적용을 결정하였음\"을 지시하는 정보를 제1 학습 노드로 전송할 수 있다. 설명의 편의를 위해, 도 5에 도시한 데이터 증강을 이용한 순차 학습 방법에서, \"제2 학습 노드가 데이터 증강의 적용을 결정하였음\"을 지시하는 정 보를 전송하는 단계(이하, 데이터 증강의 적용을 지시하는 단계)를 생략되었지만, 데이터 증강을 이용한 순차 학습 방법은 데이터 증강의 적용을 지시하는 단계가 포함될 수 있다. 데이터 증강의 적용을 지시하는 단계에서, 제2 학습 노드는 \"제2 학습 노드가 데이터 증강의 적용을 결정하였음\"을 지시하는 정보를 제1 학습 노드로 전송할 수 있다. 제1 학습 노드는 \"제2 학습 노드가 데이터 증 강의 적용을 결정하였음\"을 지시하는 정보를 제2 학습 노드로부터 수신할 수 있다. 제1 학습 노드는 제2 학습 노드에서 양면 AI/ML 모델에 대한 학습에 데이터 증강이 적용되었음을 확인할 수 있다. 일 실시예로, \"제2 학습 노드가 데이터 증강의 적용 을 결정하였음\"을 지시하는 정보는 데이터 증강에 적용되는 방법에 관련된 정보를 포함할 수 있다. 상술한 바와 같이 데이터 증강에 적용되는 방법은 잡음 추가 방법, 회전 방법 또는 생성형 AI 모델을 이용한 방법 중 적어도 하나일 수 있다. 상술한 데이터 증강 방법 외에 다른 데이터 증강 방법(들)이 데이터 증강을 수행하기 위해 적용될 수 있다. 데이터 증강을 이용한 양면 AI/ML 모델의 순차 학습 방법에서, 단계 S510 내지 단계 S530이 개별적으로 설명되 었지만, 이는 단계가 수행되는 순서를 제한하기 위한 것은 아니며, 필요한 경우에는 각각의 단계가 동시에 수행 되거나, 상이한 순서로 수행되거나 또는 단계들이 결합될 수도 있다. [방법 1-5] 제1 학습 노드는 순차 학습 데이터를 이용하여 인공 신경망을 새롭게 또는 추가로 학습할 수 있다. 제1 학습 노 드는 학습된 인공 신경망을 추론(예를 들어, CSI 피드백) 과정에서 사용할 수 있다. 제2 학습 노드에서는 데이 터 증강 방법이 제1 학습 노드에서 고려될 수 있다. 제2 학습 노드가 데이터 증강을 수행할 경우, 제1 학습 노 드는 제2 학습 노드와 동일한 데이터 증강 방법을 적용하여 인공 신경망 학습을 수행할 수 있다.상술한 바와 같이, 데이터 증강의 적용을 지시하는 단계에서, 제1 학습 노드는 제1 학습 노드는 \"제2 학습 노드 가 데이터 증강의 적용을 결정하였음\"을 지시하는 정보를 제2 학습 노드로부터 수신할 수 있다. 제1 학습 노드 는 제2 학습 노드에서 AI/ML 모델에 대한 학습에 데이터 증강이 적용되었음을 확인할 수 있다. 제1 학습 노드는 제2 학습 노드에서 양면 AI/ML 모델에 대한 학습에 적용된 데이터 증강 방법을 확인할 수 있다. 제1 학습 노드 는 제2 학습 노드에서 AI/ML 모델에 대한 학습에 적용된 데이터 증강 방법과 동일한 방법을 인공 신경망 학습을 수행할 수 있다. [방법 1-6] 제1 학습 노드는 제1 축소된 순차 학습 데이터를 제2 학습 노드로 전달(또는 전송)할 수 있다. 이후, 제1 학습 노드는 추가 학습을 위한 제2 축소된 순차 학습 데이터를 구성(또는 생성)할 수 있다. 제1 학습 노드는 제2 축 소된 학습 데이터를 제2 학습 노드로 전달(또는 전송)할 수 있다. 제2 학습 노드는 제1 학습 노드로부터 제2 축 소된 순차 학습 데이터를 수신할 수 있다. 제2 학습 노드는 제2 축소된 순차 학습 데이터를 사용하여 양면 AI/ML 모델에 대해 추가 학습을 수행할 수 있다. 앞에서 언급한 바와 같이, 양면 AI/ML 모델은 CSI 피드백을 위 한 양면 AI/ML 모델을 의미할 수 있다. 양면 AI/ML 모델은 인코더 모델 및/또는 디코더 모델을 포함할 수 있다. 도 6은 본 개시의 실시예들에 따른 양면 AI/ML 모델의 순차 학습 방법에서 추가 학습 방법을 설명하기 위해 도 시한 순서도이다. 도 6을 참조하면, 통신 시스템은 제1 학습 노드 및 제2 학습 노드를 포함할 수 있다. 제1 학습 노드는 추가 학 습을 위한 축소된 데이터셋을 생성하여 제2 학습 노드로 전달(또는 전송)할 수 있다. 제2 학습 노드는 제1 학습 노드로부터 추가 학습을 위한 축소된 데이터셋을 수신하여 양면 AI/ML 모델에 대한 학습을 수행할 수 있다. 제1 학습 노드에서, 양면 AI/ML 모델에 대한 순차 학습 데이터셋이 생성되었다고 가정할 수 있다. 제1 학습 노드는 도 3에 도시된 제1 학습 노드일 수 있고, 제2 학습 노드는 도 3에 도시된 제2 학습 노드일 수 있다. 양면 AI/ML 모델은 채널 상태 정보(channel state information, CSI) 피드백을 위한 양면 AI/ML 모델을 의미할 수 있다. 양면 AI/ML 모델은 인코더(encoder) 모델 및/또는 디코더(decoder) 모델을 포함할 수 있다. 단계 S610에서, 제1 학습 노드는 순차 학습 데이터셋에 대해 프루닝을 수행하여 제1 축소된 순차 학습 데이터셋 을 생성(또는 획득)할 수 있다. 앞에서 언급한 바와 같이, 제1 학습 노드는 미리 결정된 방법에 따라 프루닝을 수행할 수 있다. 단계 S620에서, 제1 학습 노드는 단계 S610에서 생성(또는 획득)된 제1 축소된 순차 학습 데이터셋을 제2 학습 노드로 전송할 수 있다. 제2 학습 노드는 제1 학습 노드로부터 제1 축소된 순차 학습 데이터셋을 수신할 수 있 다. 앞에서 언급한 바와 같이, 제1 학습 노드는 제1 축소된 순차 학습 데이터셋 및/또는 제1 순차 학습 데이터 구성 정보를 포함하는 제1 양면 AI/ML 학습 데이터 정보를 제2 학습 노드로 전달(또는 전송)할 수 있다. 제2 학습 노 드는 제1 학습 노드로부터 제1 축소된 순차 학습 데이터셋 및/또는 제1 순차 학습 데이터 구성 정보를 포함하는 제1 양면 AI/ML 학습 데이터 정보를 수신할 수 있다. 일 실시예로, 제1 축소된 순차 학습 데이터셋은 제1 양면 AI/ML 학습 데이터 정보에 포함될 수 있다. 제1 학습 노드는 제1 축소된 순차 학습 데이터셋을 포함하는 제1 양면 AI/ML 학습 데이터 정보를 제2 학습 노드로 전달 (또는 전송)할 수 있다. 제2 학습 노드는 제1 축소된 순차 학습 데이터셋을 포함하는 제1 양면 AI/ML 학습 데이 터 정보를 수신할 수 있다. 단계 S630에서, 제2 학습 노드는 AI/ML 모델을 정의할 수 있다. 제2 학습 노드는 단계 S620에서 수신된 축소된 순차 학습 데이터셋을 이용하여 AI/ML 모델에 대한 학습을 수행할 수 있다. 앞에서 언급한 바와 같이, AI/ML 모 델은 CSI 피드백을 위한 양면 AI/ML 모델을 의미할 수 있다. 양면 AI/ML 모델은 인코더 모델 및/또는 디코더 모 델을 포함할 수 있다. 제1 학습 노드는 미리 결정된 방법에 따라 AI/ML 모델에 대해 추가 학습의 수행 여부를 확인할 수 있다. 제1 학 습 노드에서 AI/ML 모델에 대해 추가 학습이 필요하다고 확인될 경우, 제1 학습 노드는 단계 S640을 수행할 수 있다. 단계 S640에서, 제1 학습 노드는 추가 학습을 위한 제2 축소된 데이터셋을 생성(또는 획득)할 수 있다. 제2 축 소된 데이터셋은 AI/ML 모델에 대해 추가 학습을 수행하기 사용될 수 있다. 재1 학습 노드는 미리 결정된 방법 에 따라 제2 축소된 데이터셋을 생성(또는 획득)할 수 있다.단계 S650에서, 제1 학습 노드는 단계 S640에서 생성(또는 획득)된 제2 축소된 데이터셋을 제2 학습 노드로 전 달(또는 전송)할 수 있다. 제2 학습 노드는 제1 학습 노드로부터 제2 축소된 데이터셋을 수신할 수 있다.단계 S660에서, 제2 학습 노드는 단계 S650에서 수신된 제2 축소된 데이터셋을 이용하여 AI/ML 모델에 대해 추가 학 습을 수행할 수 있다. 제1 학습 노드는 제2 축소된 순차 학습 데이터셋 및/또는 제2 순차 학습 데이터 구성 정보를 포함하는 제2 양면 AI/ML 학습 데이터 정보를 제2 학습 노드로 전달(또는 전송)할 수 있다. 제2 학습 노드는 제1 학습 노드로부터 제2 축소된 순차 학습 데이터셋 및/또는 제2 순차 학습 데이터 구성 정보를 포함하는 제2 양면 AI/ML 학습 데이 터 정보를 수신할 수 있다. 제2 순차 학습 데이터 구성 정보는 제2 축소된 순차 학습 데이터셋이 추가 학습에 이용됨을 지시하는 정보를 포함할 수 있다. 일 실시예로, 제2 양면 AI/ML 학습 데이터 정보는 제2 축소된 순차 학습 데이터셋 및 제2 순차 학습 데이터 구 성 정보를 포함할 수 있다. 제2 순차 학습 데이터 구성 정보는 제2 축소된 순차 학습 데이터셋이 추가 학습에 이용됨을 지시하는 정보를 포함할 수 있다. 제1 학습 노드는 제2 축소된 순차 학습 데이터셋 및 제2 순차 학습 데이터 구성 정보를 포함하는 제2 양면 AI/ML 학습 데이터 정보를 제2 학습 노드로 전달(또는 전송)할 수 있다. 제2 학습 노드는 제1 학습 노드로부터 제2 축소된 순차 학습 데이터셋 및 제2 순차 학습 데이터 구성 정보를 포함하는 제2 양면 AI/ML 학습 데이터 정 보를 수신할 수 있다. 제2 학습 노드는 제2 순차 학습 데이터 구성 정보를 이용하여 제2 축소된 순차 학습 데이 터셋 추가 학습에 이용됨을 확인할 수 있다. 제2 학습 노드는 제2 축소된 순차 학습 데이터셋을 이용하여 제1 양면 AI/ML 모델에 대한 추가 학습을 수행하는 단계를 더 포함할 수 있다. 양면 AI/ML 모델의 순차 학습 방법 중 추가 학습 방법에서, 단계 S610 내지 단계 S660이 개별적으로 설명되었지 만, 이는 단계가 수행되는 순서를 제한하기 위한 것은 아니며, 필요한 경우에는 각각의 단계가 동시에 수행되거 나, 상이한 순서로 수행되거나 또는 단계들이 결합될 수도 있다. [방법 1-7] 제2 학습 노드는 제1 학습 노드로부터 제1 축소된 순차 학습 데이터를 수신할 수 있다. 제1 축소된 순차 학습 데이터가 수신된 이후, 제2 학습 노드는 제1 축소된 학습 데이터셋을 이용하여 학습을 수행할 수 있다. 제2 학 습 노드는 학습된 양면 AI/ML 모델의 성능을 평가할 수 있다. 제2 학습 노드에서의 양면 AI/ML 모델 학습에 따 른 성능치는 제1 학습 에서의 양면 AI/ML 모델 학습에 따른 성능치와 비교될 수 있다. 제2 학습 노드에서의 양 면 AI/ML 모델 학습에 따른 성능치가 제1 학습 노드에서의 AI/ML 모델학습에 따른 성능치 보다 낮을 경우, 제2 학습 노드는 제1 학습 노드로 추가 학습을 요청하는 추가 학습 요청 정보를 전송할 수 있다. 추가 학습 요청 정 보는 다음 중 적어도 하나를 포함할 수 있다. - 추가 학습이 필요한 채널 정보의 샘플; 또는 - 추가 학습이 필요한 채널 정보의 성능치. 제1 학습 노드는 제2 학습 노드로부터 수신한 제2 학습 데이터의 요청 정보에 기초하여 제2 축소된 순차 학습 데이터셋을 생성(또는 구성) 할 수 있다. 제2 학습 데이터가 생성(도는 구성_된 이후, 제1 학습 노드는 제2 축 소된 학습 데이터를 제2 학습 노드로 전달(또는 전송)할 수 있다. 방법 1-7에서, 다음과 같은 단계들이 수행될 수 있다. 단계 S1-7-1에서, 제2 학습 노드는 양면 AI/ML 모델에 대해 추가 학습을 요청하는 추가 학습 요청을 상기 제1 학습 노드로 전송할 수 있다. 제1 학습 노드는 제2 학습 노드로부터 양면 AI/ML 모델에 대해 추가 학습을 요청 하는 추가 학습 요청을 수신할 수 있다. 추가 학습 요청의 정보는 추가 학습이 필요한 채널 정보의 샘플 또는 추가 학습이 필요한 채널 정보의 성능치 중 적어도 하나를 포함할 수 있다. 단계 S1-7-2에서, 제1 학습 노드는 단계 S1-7-1에서 수신된 추가 학습 요청에 기초하여 추가 학습을 위한 축소 된 순차 학습 데이터셋을 생성(또는 구성)할 수 있다. 단계 S1-7-3에서, 제1 학습 노드는 단계 S1-7-2에서 생성(또는 구성)된 추가 학습을 위한 축소된 순차 학습 데 이터셋 및/또는 순차 학습 데이터 구성 정보를 포함하는 양면 AI/ML 학습 데이터 정보를 제2 학습 노드로 전송 할 수 있다. 제2 학습 노드는 제1 학습 노드로부터 추가 학습을 위한 축소된 순차 학습 데이터셋 및/또는 순차학습 데이터 구성 정보를 포함하는 양면 AI/ML 학습 데이터 정보를 수신할 수 있다. 순차 학습 데이터 구성 정 보는 축소된 순차 학습 데이터셋이 추가 학습에 이용됨을 지시하는 정보를 포함할 수 있다. 단계 S1-7-4에서, 제2 학습 노드는 단계 S1-7-3에 수신된 양면 AI/ML 학습 데이터 정보에 따라 양면 AI/ML 모델 에 대한 추가 학습을 수행할 수 있다. 일 실시예로, 제1 학습 노드는 추가 학습을 위한 축소된 순차 학습 데이터셋 및 순차 학습 데이터 구성 정보를 포함하는 양면 AI/ML 학습 데이터 정보를 제2 학습 노드로 전달(전송)할 수 있다. 제2 학습 노드는 제1 학습 노 드로부터 추가 학습을 위한 축소된 순차 학습 데이터셋 및 순차 학습 데이터 구성 정보를 포함하는 양면 AI/ML 학습 데이터 정보를 수신할 수 있다. 제2 학습 노드는 단계 S1-7-3에서 수신된 순차 학습 데이터 구성 정보를 이용하여 단계 S1-7-3에서 수신된 축소 된 순차 학습 데이터셋이 추가 학습에 이용됨을 확인할 수 있다. 수신된 축소된 순차 학습 데이터셋이 확인될 경우, 제2 학습 노드는 수신된 축소된 순차 학습 데이터셋을 이용하여 양면 AI/ML 모델에 대한 추가 학습을 수 행할 수 있다. 단계 S1-7-3에서 수신된 축소된 순차 학습 데이터셋 및 수신된 순차 학습 데이터 구성 정보는 단 계 S1-7-3에서 수신된 양면 AI/ML 학습 데이터 정보에 포함될 수 있다. 방법 1-7에서, 단계 S1-7-1 내지 단계 S1-7-4이 개별적으로 설명되었지만, 이는 단계가 수행되는 순서를 제한하 기 위한 것은 아니며, 필요한 경우에는 각각의 단계가 동시에 수행되거나, 상이한 순서로 수행되거나 또는 단계 들이 결합될 수도 있다. [방법 1-8] 제2 학습 노드는 제1 학습 노드로부터 순차 학습 데이터를 수신할 수 있다. 순차 학습 데이터가 수신된 이후, 제2 학습 노드는 각 샘플의 채널 정보만을 이용하여 제1 학습 노드와 같은 학습 과정을 수행할 수 있다. 제2 학 습 노드는 제1 학습 노드에서의 모델 및 학습의 결과에 따른 성능치보다 더 좋은 성능치를 가지는 매핑 정보를 학습할 수 있다. 이 경우, 제2 학습 노드는 순차 학습 데이터의 매핑 정보를 변경할 수 있다. 제2 학습 노드는 변경된 순차 학습 데이터의 매핑 정보를 제1 학습 노드로 전달할 수 있다. 일 실시예에서, 제1 학습 노드는 축소되지 않은 순차 학습 데이터를 제2 학습 노드로 전달(또는 전송)할 수 있 다. 축소되지 않은 순차 학습 데이터가 수신된 이후, 제2 학습 노드는 채널 정보만을 이용하여 새롭게 학습을 수행할 수 있다. 제2 학습 노드는 새로운 학습에 따른 성능치를 제1 학습 노드의 학습에 따른 성능치와 비교할 수 있다. 새로운 학습에 따른 성능치가 제1 학습 노드의 학습에 따른 성능치보다 높을 경우, 제2 학습 노드는 축소되지 않은 순차 학습 데이터에서의 매핑 정보를 변경할 수 있다. 제2 학습 노드는 변경된 매핑 정보를 제1 학습 노드로 전달할 수 있다. 제1 학습 노드는 제2 학습 노드로부터 변경된 매핑 정보를 수신할 수 있다. 제1 학습 노드는 변경된 매핑 정보에 사용하여 학습을 다시 수행할 수 있다. 방법 1-8에서, 다음과 같은 단계들이 수행될 수 있다. 단계 S1-8-1에서, 제1 학습 노드는 순차 학습 데이터셋 또는 순차 학습 데이터 구성 정보 중 적어도 하나를 포 함하는 양면 AI/ML 학습 데이터 정보를 제2 학습 노드로 전송할 수 있다. 제2 학습 노드는 제1 학습 노드로부터 순차 학습 데이터셋 또는 순차 학습 데이터 구성 정보 중 적어도 하나를 포함하는 양면 AI/ML 학습 데이터 정보 를 수신할 수 있다. 순차 학습 데이터셋은 축소되지 않은 순차 학습 데이터셋일 수 있다. 예를 들어, 순차 학습 데이터셋은 도 3에 도시된 단계 S320에서 생성될 수 있다. 단계 S1-8-2에서, 제2 학습 노드는 단계 S1-8-1에서 제1 학습 노드로부터 수신된 순차 학습 데이터셋을 이용하 여 양면 AI/ML 모델에 대한 학습을 수행할 수 있다. 단계 S1-8-3에서, 제2 학습 노드는 단계 S1-8-2에서 수행된 양면 AI/ML 모델에 대한 학습의 결과에 따라 순차 학습 데이터셋에 대해 매핑 정보 변경을 수행할 수 있다. 단계 S1-8-4에서, 제2 학습 노드는 단계 S1-8-1에서 제1 학습 노드로부터 수신된 순차 학습 데이터셋에 대해 매 핑 정보가 변경되었음을 지시하는 매핑 변경 지시 정보를 제1 학습 노드로 전송할 수 있다. 제1 학습 노드는 제 2 학습 노드로부터 순차 학습 데이터셋에 대해 매핑 정보가 변경되었음을 지시하는 매핑 변경 지시 정보를 수신 할 수 있다. 제1 학습 노드는 단계 S1-8-4에서 수신된 매핑 변경 지시 정보에 따라 제2 학습 노드에서 양면 AI/ML 모델에 학 습에 이용된 순차 학습 데이터셋에 대한 매핑 정보가 변경되었음을 확인할 수 있다. 일 실시예로, 제1 학습 노드는 순차 학습 데이터셋을 이용한 양면 AI/ML 모델을 학습한 결과에 따른 성능치(이 하, 제1 성능치)를 획득할 수 있다. 제2 학습 노드는 제1 학습 노드로부터 수신된 순차 학습 데이터셋을 이용한 양면 AI/ML 모델을 학습한 결과에 따른 성능치(이하, 제2 성능치)를 획득할 수 있다. 제2 학습 노드가 제1 학습 노드로부터 수신된 순차 학습 데이터셋을 이용한 양면 AI/ML 모델 학습을 수행할 경우, 제2 학습 노드는 순차 학습 데이터의 채널 정보만을 셋에 이용하여 양면 AI/ML 모델의 학습을 수행할 수 있다. 제1 학습 노드로부터 수신된 순차 학습 데이터셋은 복수의 순차 학습 데이터를 포함할 수 있다. 제2 학습 노드는 제1 학습 노드로부 터 제1 성능치를 수신하였다고 가정할 수 있다. 제2 학습 노드는 제1 성능치와 제2 성능치를 비교할 수 있다. 제1 성능치가 제2 성능치 보다 낮을 경우, 제2 학 습 노드는 제1 학습 노드로부터 수신된 순차 데이터셋에 대해 매핑 정보 변경을 수행할 수 있다. 제2 학습 노드 는 순차 학습 데이터셋에 대해 매핑 변경 정보가 변경되었음을 지시하는 매핑 변경 지시 정보를 제1 학습 노드 로 전송할 수 있다. 제1 학습 노드는 제2 학습 노드로부터 순차 학습 데이터셋에 대해 매핑 변경 정보가 변경되었음을 지시하는 매 핑 변경 지시 정보를 수신할 수 있다. 매핑 변경 지시 정보가 수신될 경우, 제1 학습 노드는 매핑 변경 지시 정 보에 따라 순차 학습 데이터셋을 이용하여 양면 AI/ML 모델 학습을 다시 수행할 수 있다. 방법 1-8에서, 단계 S1-8-1 내지 단계 S1-8-4이 개별적으로 설명되었지만, 이는 단계가 수행되는 순서를 제한하 기 위한 것은 아니며, 필요한 경우에는 각각의 단계가 동시에 수행되거나, 상이한 순서로 수행되거나 또는 단계 들이 결합될 수도 있다. [방법 1-9] 순차 학습 데이터셋이 제1 학습 노드로부터 수신된 이후, 제2 학습 노드는 자체적으로 순차 학습 데이터셋에 대 해 축소하는 과정을 수행하여 축소된 순차 학습 데이터셋을 생성(또는 구성)할 수 있다. 제2 학습 노드는 양면 AI/ML 모델에 대해 축소된 순차 학습 데이터셋을 이용한 학습을 수행할 수 있다. 제2 학습 노드는 순차 학습 데 이터셋에 적용된 축소 방법을 지시하는 축소 방법 정보를 제1 학습 노드로 전달(또는 전송)할 수 있다. 방법 1-9에서, 다음과 같은 단계들이 수행될 수 있다. 단계 S1-9-1에서, 제1 학습 노드는 순차 학습 데이터셋 또는 순차 학습 데이터 구성 정보 중 적어도 하나를 포 함하는 양면 AI/ML 학습 데이터 정보를 전달(또는 전송)할 수 있다. 제2 학습 노드는 제2 학습 노드로부터 순차 학습 데이터셋 또는 순차 학습 데이터 구성 정보 중 적어도 하나를 포함하는 양면 AI/ML 학습 데이터 정보를 수 신할 수 있다. 제2 학습 노드는 축소된 순차 학습 데이터셋을 생성(또는 구성)하기 위해 단계 S1-9-2를 수행할 수 있다. 단계 S1-9-3에서, 제2 학습 노드는 단계 S1-9-1에서 수신된 순차 학습 데이터셋에 대해 축소 과정을 수행하여 축소된 순차 학습 데이터셋을 생성(또는 구성)할 수 있다. 축소 과정에서 축소된 순차 학습 데이터셋을 생성(또는 구성)하기 위해, 제2 학습 노드는 축소 방법을 적용할 수 있다. 축소 방법은 임의 샘플링 기반 축소 방법, 채널 정보의 밀도 기반 축소 방법, 매핑 정보의 밀도 기반 축소 방법 또는 모델 기반 중요도 기반 축소 방법 중 적어도 하나를 포함할 수 있다. 단계 S1-9-4에서, 제2 학습 노드는 단계 S1-9-3에서 축소된 순차 데이터셋을 생성(또는 구성)하기 위해 적용된 축소 방법을 지시하는 축소 방법 정보를 제1 학습 노드로 전송할 수 있다. 제1 학습 노드는 제2 학습 노드로부 터 축소 방법 정보를 수신할 수 있다. 방법 1-9에서, 단계 S1-9-1 내지 단계 S1-9-3이 개별적으로 설명되었지만, 이는 단계가 수행되는 순서를 제한하 기 위한 것은 아니며, 필요한 경우에는 각각의 단계가 동시에 수행되거나, 상이한 순서로 수행되거나 또는 단계 들이 결합될 수도 있다. <<순차 학습을 위한 효율적인 모델 정보 전달 방법>> [방법 2] 본 개시에서는 양면 AI/ML 모델에 대한 순차 학습 과정에서, 제1 학습 노드가 정의한 양면 AI/ML 모델 정보를 제2 학습 노드로 전달(또는 전송)하는 것이 제안될 수 있다. 양면 AI/ML 모델은 인코더 모델 및/또는 디코더 모델을 포함할 수 있다. 제1 학습 노드가 정의한 양면 AI/ML 모델 정보는 인코더 모델 및/또는 디코더 모델과 관 련된 정보를 포함할 수 있다. 제1 학습 노드는 양면 AI/ML 모델 정보를 정의하여 제2 학습 노드로 전달(또는 전송)할 수 있다. 제2 학습 노드 는 제1 학습 노드에서 정의한 양면 AI/ML 모델 정보에 기초하여 양면 AI/ML 모델을 생성(또는 구성)할 수 있다. 도 7은 본 개시의 실시예들에 따른 양면 AI/ML 모델 정보 전송 방법을 설명하기 위해 도시한 순서도이다. 도 7을 참조하면, 통신 시스템은 제1 학습 노드 및 제2 학습 노드를 포함할 수 있다. 제1 학습 노드는 양면 AI/ML 모델을 정의할 수 있고, 정의된 양면 AI/ML 모델 정보를 제2 학습 노드로 전달(또는 전송)할 수 있다. 제 2 학습 노드는 제1 학습 노드로부터 수신된 양면 AI/ML 모델 정보에 기초하여 양면 AI/ML 모델을 구성(또는 획 득)하여 학습을 수행할 수 있다. 제1 학습 노드는 도 3에 도시된 제1 학습 노드일 수 있고, 제2 학습 노드는 도 3에 도시된 제2 학습 노드일 수 있다. 양면 AI/ML 모델은 CSI 피드백을 위한 양면 AI/ML 모델을 의미할 수 있다. 양면 AI/ML 모델은 인코더(encoder) 모델 및/또는 디코더(decoder) 모델을 포함할 수 있다. 단계 S710에서, 제1 학습 노드는 AI/ML 모델 학습을 위한 데이터셋을 수집할 수 있다. 수집된 데이터셋은 복수 의 원시 학습 데이터를 포함할 수 있다. 수집된 데이터셋은 원시 학습 데이터셋으로 표현될 수 있다. AI/ML 모 델은 CSI 피드백을 위한 양면 AI/ML 모델을 의미할 수 있다. 단계 S720에서, 제1 학습 노드는 AI/ML 모델을 정의할 수 있다. 단계 S710에서 수집된 데이터셋을 이용하여, 제 1 학습 노드는 AI/ML 모델에 대한 학습을 수행할 수 있다. 제1 학습 노드는 AI/ML 모델에 대해 순차 학습을 위 한 데이터셋을 생성(또는 획득)할 수 있다. 순차 학습을 위한 데이터셋은 순차 학습 데이터셋으로 표현될 수 있 고, 순차 학습을 위한 데이터는 순차 학습 데이터로 표현될 수 있다. 순차 학습 데이터셋은 복수의 순차 학습 데이터를 포함할 수 있다. 단계 S730에서, 제1 학습 노드는 단계 S720에서 생성(또는 획득)된 순차 학습을 위한 데이터셋 및 AI/ML 모델 정보를 제2 학습 노드로 전달(전송)할 수 있다. 제2 학습 노드는 제1 학습 노드로부터 순차 학습을 위한 데이터 셋 및 AI/ML 모델 정보를 수신할 수 있다. 앞에서 언급한 바와 같이, 제1 학습 노드가 정의한 양면 AI/ML 모델 정보는 인코더 모델 및/또는 디코더 모델과 관련된 정보를 포함할 수 있다. 제1 학습 노드가 정의한 양면 AI/ML 모델 정보는 다음 중 적어도 하나를 포함할 수 있다. - 백본 인공 신경망의 종류; - 입력 데이터의 종류; - 입력 데이터의 크기; - 출력 데이터의 종류; - 출력 데이터의 크기; - 연산량; - 인공 신경망 파라미터 개수; - 저장공간 크기; - 인공 신경망 파라미터의 양자화 방법; - 인공 신경망 파라미터; > 사전 학습된 파라미터, 또는 최종 학습된 파라미터. - 학습 데이터 식별자; 또는 - 인공 신경망의 성능관련 정보. 단계 S730에서, 제2 학습 노드는 AI/ML 모델을 정의할 수 있다. 제2 학습 노드는 AI/ML 모델 정보에 기초하여 순차 학습 데이터셋에 대해 축소 과정을 수행하여 축소된 순차 학습 데이터셋을 생성(또는 구성)할 수 있다. 제 2 학습 노드는 AI/ML 모델에 대해 축소된 순차 학습 데이터셋을 이용한 학습을 수행할 수 있다. AI/ML 모델 정 보는 단계 S720에서 수신된 AI/ML 모델 정보일 수 있고, 순차 학습 데이터셋은 단계 S720에서 수신된 순차 학습데이터셋일 수 있다. 앞에서 언급한 바와 같이, AI/ML 모델은 CSI 피드백을 위한 양면 AI/ML 모델을 의미할 수 있다. 축소된 순차 학습 데이터셋은 복수의 순차 학습 데이터를 포함할 수 있다. 순차 학습 데이터는 채널 정보와 채 널 정보에 대한 매핑 정보의 쌍을 포함할 수 있다. 매핑 정보는 제2 학습 노드(예를 들어, 단말)에서의 AI/ML 학습 결과에 따라 결정될 수 있다. 상술한 모델 정보 전달 방법은 단계 S740이 수행된 이후, 제2 학습 노드가 CSI 피드백 정보를 전송하는 단계(이 하, 피드백 전송 단계)를 더 포함할 수 있다. 피드백 전송 단계에서, 제2 학습 노드는 단계 S740에서 학습된 AI/ML 모델에 기초하여 CSI 피드백 정보를 제1 학습 노드로 전송할 수 있다. 제1 학습 노드는 제2 학습 노드로부터 AI/ML 모델에 기초한 CSI 피드백 정보를 수 신할 수 있다. 설명에 편의상에, 제1 학습 노드는 단계 S710에서 CSI 피드백을 위한 양면 AI/ML 모델의 순차 학습을 위한 데이 터셋을 수집할 수 있지만 이에 제한되지는 않는다. 제1 학습 노드는 단계 S720에서 CSI 피드백을 위한 양면 AI/ML 모델을 정의하지만 이에 제한되지는 않는다. 제2 학습 노드는 단계 S740에서 CSI 피드백을 위한 양면 AI/ML 모델을 정의하지만 이에 제한되지는 않는다. 일 실시예로, 도 7에 도시한 양면 AI/ML 모델 정보 전송 방법에서, 제1 학습 노드에서의 데이터셋은 수집이 완 료되었다고 가정할 수 있다. 제1 학습 노드에서의 AI/ML 모델과 제2 학습 노드에서의 AI/ML 모델은 미리 정의되 어 있다고 가정할 수 있다. 앞에서 언급한 바와 같이, AI/ML 모델은 CSI 피드백을 위한 양면 AI/ML 모델을 의미 할 수 있다. 양면 AI/ML 모델은 인코더 모델 및/또는 디코더 모델을 포함할 수 있다. 모델 정보 전달 방법에서, 단계 S710 내지 단계 S740이 개별적으로 설명되었지만, 이는 단계가 수행되는 순서를 제한하기 위한 것은 아니며, 필요한 경우에는 각각의 단계가 동시에 수행되거나, 상이한 순서로 수행되거나 또 는 단계들이 결합될 수도 있다. 본 개시의 일 실시예로, 기지국 및 단말은 CSI 피드백을 위한 양면 AI/ML 모델을 순차적으로 학습할 수 있다. 제1 학습 노드는 기지국으로, 제2 학습 노드는 단말로 가정할 수 있다. [방법 2-1] 제1 학습 노드는 양면 AI/ML 모델 정보를 정의할 수 있다. 제1 학습 노드가 정의한 양면 AI/ML 모델 정보는 하 나 또는 둘 이상의 인코더 모델 정보 및/또는 디코더 모델 정보를 포함할 수 있다. 제2 학습 노드는 제1 학습 노드가 정의한 양면 AI/ML 모델 정보를 요청하는 양면 AI/ML 모델 요청을 제1 학습 노드로 전달(또는 전송)할 수 있다. 제2 학습 노드는 제1 학습 노드로부터 수신된 양면 AI/ML 모델 정보를 기초로 양면 AI/ML 모델을 구성 (또는 생성)하고, 양면 AI/ML 모델에 대한 학습을 수행할 수 있다. 도 8은 본 개시의 실시예들에 따른 요청 기반 양면 AI/ML 모델 정보의 전송 방법을 설명하기 위해 도시한 순서 도이다. 도 8을 참조하면, 통신 시스템은 제1 학습 노드 및 제2 학습 노드를 포함할 수 있다. 제1 학습 노드는 AI/ML 모 델을 정의할 수 있다. 제1 학습 노드는 제2 학습 노드의 요청에 따라 AI/ML 모델 정보를 제2 학습 노드로 전달 (또는 전송)할 수 있다. 제1 학습 노드는 도 3에 도시된 제1 학습 노드일 수 있고, 제2 학습 노드는 도 3에 도 시된 제2 학습 노드일 수 있다. 제1 학습 노드에서, AI/ML 모델 정보가 정의되어 있다고 가정할 수 있다. 앞에서 언급한 바와 같이, AI/ML 모델은 CSI 피드백을 위한 양면 AI/ML 모델을 의미할 수 있다. 양면 AI/ML 모 델은 인코더 모델 및/또는 디코더 모델을 포함할 수 있다. 단계 S810에서, 제1 학습 노드는 순차 학습을 위한 데이터셋을 제2 학습 노드로 전달(또는 전송)할 수 있다. 제 2 학습 노드는 제1 학습 노드로부터 순차 학습을 위한 데이터셋을 수신할 수 있다. 앞에서 언급한 바와 같이, 순차 학습을 위한 데이터셋은 순차 학습 데이터셋으로 표현될 수 있고, 순차 학습을 위한 데이터는 순차 학습 데이터로 표현될 수 있다. 순차 학습 데이터셋은 복수의 순차 학습 데이터를 포함할 수 있다. 제2 학습 노드가 단계 S810을 수행하여 순차 학습 데이터셋을 수신할 경우, 제2 학습 노드는 제1 학습 노드에 AI/ML 모델 정보를 요청하기 위해 단계 S820을 수행할 수 있다. 단계 S820에서, 제2 학습 노드는 제1 학습 노드가 정의한 AI/ML 모델 정보를 요청하는 AI/ML 모델 요청을 제1 학습 노드로 전달(또는 전송)할 수 있다. 제1 학습 노드는 제2 학습 노드로부터 AI/ML 모델 요청을 수신할 수 있다. 단계 S830에서, 제1 학습 노드는 단계 S820에서 제2 학습 노드로부터 수신한 AI/ML 모델 요청에 대한 응답으로 AI/ML 모델 정보를 제1 학습 노드로 전달(또는 전송)할 수 있다. 제2 학습 노드는 제1 학습 노드로부터 AI/ML 모델 정보를 수신할 수 있다. 제2 학습 노드가 단계 S840를 수행하여 AI/ML 모델 정보를 수신할 경우, 제2 학습 노드는 AI/ML 모델 정보에 기 초하여 AI/ML 모델을 구성(또는 생성)하고, AI/ML 모델에 대한 학습을 수행하기 위해 단계 S840을 수행할 수 있 다. 단계 S840에서, 제2 학습 노드는 AI/ML 모델을 정의할 수 있다. 제2 학습 노드는 AI/ML 모델 정보에 기초하여 순차 학습 데이터셋에 대해 축소 과정을 수행하여 축소된 순차 학습 데이터셋을 생성(또는 구성)할 수 있다. 제 2 학습 노드는 AI/ML 모델에 대해 축소된 순차 학습 데이터셋을 이용한 학습을 수행할 수 있다. AI/ML 모델 정 보는 단계 S830에서 수신된 AI/ML 모델 정보일 수 있고, 순차 학습 데이터셋은 단계 S810에서 수신된 순차 학습 데이터셋일 수 있다. 앞에서 언급한 바와 같이, AI/ML 모델은 CSI 피드백을 위한 양면 AI/ML 모델을 의미할 수 있다. 앞에서 언급한 바와 같이, 축소된 순차 학습 데이터셋은 복수의 순차 학습 데이터를 포함할 수 있다. 순차 학습 데이터는 채널 정보와 채널 정보에 대한 매핑 정보의 쌍을 포함할 수 있다. 매핑 정보는 제2 학습 노드(예를 들 어, 단말)에서의 AI/ML 학습 결과에 따라 결정될 수 있다. 상술한 요청 기반 인공지능/기계학습 모델 정보의 전송 방법은 단계 S840이 수행된 이후, 제2 학습 노드가 CSI 피드백 정보를 전송하는 단계를 더 포함할 수 있다. 제2 학습 노드가 CSI 피드백 정보를 전송하는 단계에서, 제2 학습 노드는 단계 S740에서 학습된 AI/ML 모델에 기초하여 CSI 피드백 정보를 제1 학습 노드로 전송할 수 있다. 제1 학습 노드는 제2 학습 노드로부터 AI/ML 모 델에 기초한 CSI 피드백 정보를 수신할 수 있다. 요청 기반 인공지능/기계학습 모델 정보의 전송 방법에서, 단계 S810 내지 단계 S840이 개별적으로 설명되었지 만, 이는 단계가 수행되는 순서를 제한하기 위한 것은 아니며, 필요한 경우에는 각각의 단계가 동시에 수행되거 나, 상이한 순서로 수행되거나 또는 단계들이 결합될 수도 있다. [방법 2-2] 양면 AI/ML 모델에 대한 순차 학습 과정에서, 제2 학습 노드는 양면 AI/ML 모델 정보를 정의할 수 있다. 제2 학 습 노드가 정의한 양면 AI/ML 모델 정보는 하나 또는 둘 이상의 인코더 모델 정보 및/또는 디코더 모델 정보를 포함할 수 있다. 제2 학습 노드가 정의한 양면 AI/ML 모델 정보는 제1 학습 노도로 전달(또는 전송)될 수 있다. 제1 학습 노드는 제2 학습 노드가 정의한 양면 AI/ML 모델 정보에 기초하여 제1 학습 노드에서의 양면 AI/ML 모 델을 결정할 수 있다. 제1 학습 노드는 결정된 양면 AI/ML 모델을 이용하여 학습을 수행할 수 있다. 다음, 제1 학습 노드는 순차 학습을 위한 학습 데이터셋을 구성(또는 생성)할 수 있다. 앞에서 언급한 바와 같이, 순차 학습을 위한 데이터셋은 순차 학습 데이터셋으로 표현될 수 있고, 순차 학습을 위한 데이터는 순차 학습 데이터로 표현될 수 있다. 순차 학습 데이터셋은 복수의 순차 학습 데이터를 포함할 수 있다. 방법 2-2에서, 다음과 같은 단계들이 수행될 수 있다. 단계 S2-2-1에서, 제2 학습 노드는 양면 AI/ML 모델 정보를 정의할 수 있다. 정의에서, 제2 학습 노드는 미리 결정된 방법에 따라 양면 AI/ML 모델 정보를 정의할 수 있다. 제2 학습 노드가 정의한 양면 AI/ML 모델 정보는 하나 또는 둘 이상의 인코더 모델 정보 및/또는 디코더 모델 정보를 포함할 수 있다. 제2 학습 노드는 정의된 양면 AI/ML 모델 정보를 제1 학습 노드로 전송하기 위해 단계 S2-2-2를 수행할 수 있다. 단계 S2-2-2에서, 제2 학습 노드는 단계 S2-2-1에서 정의된 양면 AI/ML 모델 정보를 제1 학습 노드로 전송할 수 있다. 제1 학습 노드는 제2 학습 노드로부터 양면 AI/ML 모델 정보를 수신할 수 있다. 제1 학습 노드는 단계 S2-2-3을 수행할 수 있다. 단계 S2-2-3에서, 제1 학습 노드는 단계 S2-2-2에서 제2 학습 노드로부터 수신된 양면 AI/ML 모델 정보에 기초 하여 양면 AI/ML 모델을 결정할 수 있다. 제1 학습 노드는 단계 S2-2-4에서, 제1 학습 노드는 단계 S2-2-3에서결정된 양면 AI/ML 모델에 대한 학습을 수행할 수 있다. 제1 학습 노드는 단계 S2-2-4를 수행할 수 있다. 단계 S2-2-4에서, 제1 학습 노드는 단계 S2-2-3에서 학습된 양면 AI/ML 모델에 대해 순차 학습 데이터셋을 구성 (또는 생성)할 수 있다. 방법 2-2에서, 단계 S2-2-1 내지 단계 S2-2-4가 개별적으로 설명되었지만, 이는 단계가 수행되는 순서를 제한하 기 위한 것은 아니며, 필요한 경우에는 각각의 단계가 동시에 수행되거나, 상이한 순서로 수행되거나 또는 단계 들이 결합될 수도 있다. [방법 2-4] 양면 AI/ML 모델에 대한 순차 학습 과정에서, 양면 AI/ML 모델 정보는 별도의 서버에 저장될 수 있다. 별도의 서버에 저장된 양면 AI/ML 모델 정보는 모델 식별자(identifier, ID)에 따라 구별될 수 있다. 제1 학습 노드 및 제2 학습 노드는 모델 ID를 이용하여 양면 AI/ML 모델 정보를 송수신할 수 있다. 본 개시의 실시 예에 따른 방법의 동작은 컴퓨터로 읽을 수 있는 기록매체에 컴퓨터가 읽을 수 있는 프로그램 또는 코드로서 구현하는 것이 가능하다. 컴퓨터가 읽을 수 있는 기록매체는 컴퓨터 시스템에 의해 읽혀질 수 있 는 정보가 저장되는 모든 종류의 기록장치를 포함한다. 또한 컴퓨터가 읽을 수 있는 기록매체는 네트워크로 연 결된 컴퓨터 시스템에 분산되어 분산 방식으로 컴퓨터로 읽을 수 있는 프로그램 또는 코드가 저장되고 실행될 수 있다. 또한, 컴퓨터가 읽을 수 있는 기록매체는 롬(rom), 램(ram), 플래시 메모리(flash memory) 등과 같이 프로그램 명령을 저장하고 수행하도록 특별히 구성된 하드웨어 장치를 포함할 수 있다. 프로그램 명령은 컴파일러 (compiler)에 의해 만들어지는 것과 같은 기계어 코드뿐만 아니라 인터프리터(interpreter) 등을 사용해서 컴퓨 터에 의해 실행될 수 있는 고급 언어 코드를 포함할 수 있다. 본 개시의 일부 측면들은 장치의 문맥에서 설명되었으나, 그것은 상응하는 방법에 따른 설명 또한 나타낼 수 있 고, 여기서 블록 또는 장치는 방법 단계 또는 방법 단계의 특징에 상응한다. 유사하게, 방법의 문맥에서 설명된 측면들은 또한 상응하는 블록 또는 아이템 또는 상응하는 장치의 특징으로 나타낼 수 있다. 방법 단계들의 몇몇 또는 전부는 예를 들어, 마이크로프로세서, 프로그램 가능한 컴퓨터 또는 전자 회로와 같은 하드웨어 장치에 의 해(또는 이용하여) 수행될 수 있다. 몇몇의 실시 예에서, 가장 중요한 방법 단계들의 적어도 하나 이상은 이와 같은 장치에 의해 수행될 수 있다. 실시 예들에서, 프로그램 가능한 로직 장치(예를 들어, 필드 프로그래머블 게이트 어레이)가 여기서 설명된 방 법들의 기능의 일부 또는 전부를 수행하기 위해 사용될 수 있다. 실시 예들에서, 필드 프로그래머블 게이트 어 레이(field-programmable gate array)는 여기서 설명된 방법들 중 하나를 수행하기 위한 마이크로프로세서 (microprocessor)와 함께 작동할 수 있다. 일반적으로, 방법들은 어떤 하드웨어 장치에 의해 수행되는 것이 바 람직하다. 이상 본 개시의 바람직한 실시 예를 참조하여 설명하였지만, 해당 기술 분야의 숙련된 당업자는 하기의 특허 청 구의 범위에 기재된 본 개시의 사상 및 영역으로부터 벗어나지 않는 범위 내에서 본 개시를 다양하게 수정 및 변경시킬 수 있음을 이해할 수 있을 것이다.도면 도면1 도면2 도면3 도면4 도면5 도면6 도면7 도면8"}
{"patent_id": "10-2024-0106505", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 통신 시스템의 일 실시예를 도시한 개념도이다. 도 2는 통신 시스템을 구성하는 통신 노드의 일 실시예를 도시한 블록도이다. 도 3은 본 개시의 실시예들에 따른 채널 상태 정보 피드백을 위한 양면 AI/ML 모델의 순차 학습 방법을 설명하 기 위해 도시한 순서도이다. 도 4는 본 개시의 실시예들에 따른 양면 AI/ML 모델의 순차 학습을 위한 학습 데이터를 설명하기 위해 도시한 개념도이다. 도 5는 본 개시의 실시예들에 따른 데이터 증강을 이용한 양면 AI/ML 모델의 순차 학습 방법을 설명하기 위해 도시한 순서도이다. 도 6은 본 개시의 실시예들에 따른 양면 AI/ML 모델의 순차 학습 방법에서 추가 학습 방법을 설명하기 위해 도 시한 순서도이다. 도 7은 본 개시의 실시예들에 따른 양면 AI/ML 모델 정보 전송 방법을 설명하기 위해 도시한 순서도이다. 도 8은 본 개시의 실시예들에 따른 요청 기반 양면 AI/ML 모델 정보의 전송 방법을 설명하기 위해 도시한 순서 도이다."}
