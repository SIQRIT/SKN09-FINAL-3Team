{"patent_id": "10-2016-7000926", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2016-0037162", "출원번호": "10-2016-7000926", "발명의 명칭": "실제 3-D 시나리오에서의 가상 물체", "출원인": "라인메탈 디펜스 일렉트로닉스 게엠베하", "발명자": "벤트, 클라우스"}}
{"patent_id": "10-2016-7000926", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "근거리에서 그리고 사람들과 함께 훈련 목적을 위한 시나리오에서 실제 전투 작전을 시뮬레이션하기 위한 방법으로서,훈련 참여자들은 훈련 무기를 갖추고 서로 경합하며 훈련 중 훈련 참여자들의 실제 행동은, 영상 시스템에 의해기록되고, 준-실시간으로 변화하는 3-D 모델로서 계산되며, 무기 효과는, 무기의 물체 인식, 사격 중 상태 변화와 배향 및 유효 방향에서의 물체와 그 손상 모델에 의해 계산되며, 표시되는, 방법에 있어서,훈련의 개시 전에, 온전한, 명중된 그리고 파괴된 상태에서 시나리오의 모든 관련 개별 물체들의 3-차원 모델및, 관련 음향 효과를 포함하는 해당 상태 전이의 애니메이션이 생성되고 데이터베이스에 저장되는 것을 특징으로 하는,근거리에서 그리고 사람들과 함께 훈련 목적을 위한 시나리오에서 실제 전투 작전을 시뮬레이션하기 위한 방법."}
{"patent_id": "10-2016-7000926", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,훈련 상황 중의 소음이 시나리오에서 적어도 하나의 마이크로폰, 특히 복수의 마이크로폰을 이용하여 서라운드사운드 기록 방식으로 기록되는 것을 특징으로 하는, 근거리에서 그리고 사람들과 함께 훈련 목적을 위한 시나리오에서 실제 전투 작전을 시뮬레이션하기 위한 방법."}
{"patent_id": "10-2016-7000926", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항 또는 제2항에 있어서,상기 방법을 수행하기 위해 컴퓨터 시스템이 이용되며, 이 시스템은 다중채널 오디오/비디오 송신/수신 시스템으로 확장되는 것을 특징으로 하는, 근거리에서 그리고 사람들과 함께 훈련 목적을 위한 시나리오에서 실제 전투 작전을 시뮬레이션하기 위한 방법."}
{"patent_id": "10-2016-7000926", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항 내지 제3항 중 어느 한 항에 있어서,훈련 참여자는 시야 방향으로 지향된 비디오 카메라와 디스플레이 시스템의 조합 및 이어폰을 갖춘 안경 형태로의 이미지 및 사운드를 위한 무선 송신/수신 유닛을 추가로 착용하며, 이 장치 조합들은 실제 시나리오 안으로시야를 차단하기 위해 그리고 원래의 소음을 감추기 위해 설계되고 사용되는 것을 특징으로 하는, 근거리에서그리고 사람들과 함께 훈련 목적을 위한 시나리오에서 실제 전투 작전을 시뮬레이션하기 위한 방법."}
{"patent_id": "10-2016-7000926", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "선행하는 항들 중 어느 한 항에 있어서,하나 이상의 중앙 컴퓨터에 의해 생성되고 훈련 참여자 자신들이 그 안에서 이동하는 3-차원 시나리오 모델은크기 및 관점의 측면에서 맞춤 방식으로 그리고 디스플레이 시스템을 이용하여 실시간으로 훈련 참여자들에게표시되며, 음향 오리엔테이션을 위해 어울리는 사운드 효과는 서라운드 사운드 방식으로 이어폰을 통해 재생되는 것을 특징으로 하는, 근거리에서 그리고 사람들과 함께 훈련 목적을 위한 시나리오에서 실제 전투 작전을 시뮬레이션하기 위한 방법."}
{"patent_id": "10-2016-7000926", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "선행하는 항들 중 어느 한 항에 있어서,적어도 한 명의 훈련 참여자가 착용하는 카메라는, 훈련받는 사람 자신이 영상 시스템으로부터 시나리오를 감추공개특허 10-2016-0037162-3-는 경우, 훈련받는 사람의 눈 바로 앞에서 시나리오를 추가로 기록하기 위해 사용되는 것을 특징으로 하는, 근거리에서 그리고 사람들과 함께 훈련 목적을 위한 시나리오에서 실제 전투 작전을 시뮬레이션하기 위한 방법."}
{"patent_id": "10-2016-7000926", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "선행하는 항들 중 어느 한 항에 있어서,카메라는, 훈련받는 사람의 시야 방향을 결정하기 위해 그리고 맞춤 방식으로 3-차원 모델의 해당 시야를 생성하기 위해 그리고 그것을 헬멧 디스플레이에 표시하기 위해, 보조장치로서 사용되는 것을 특징으로 하는, 근거리에서 그리고 사람들과 함께 훈련 목적을 위한 시나리오에서 실제 전투 작전을 시뮬레이션하기 위한 방법."}
{"patent_id": "10-2016-7000926", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "선행하는 항들 중 어느 한 항에 있어서,훈련받을 사람 외에도, 모든 다른 참여자들이 인공 수행자에 의해 완전히 표현되며, 후자는 훈련 목적 및 훈련받는 사람의 행동에 따라 인공지능에 의해 제어되는 것을 특징으로 하는, 근거리에서 그리고 사람들과 함께 훈련 목적을 위한 시나리오에서 실제 전투 작전을 시뮬레이션하기 위한 방법."}
{"patent_id": "10-2016-7000926", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "선행하는 항들 중 어느 한 항에 있어서,훈련 참여자들이 터치할 물체들만 실제 실체가 있게 생성함으로써, 현실적인 훈련 지역이 비용-효율적으로 구성되는 것을 특징으로 하는, 근거리에서 그리고 사람들과 함께 훈련 목적을 위한 시나리오에서 실제 전투 작전을시뮬레이션하기 위한 방법."}
{"patent_id": "10-2016-7000926", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "선행하는 항들 중 어느 한 항에 있어서,훈련받는 사람의 실제 이미지는 디스플레이 시스템을 갖춘 컴퓨터에 의해 생성된 이미지로 대체되는 것을 특징으로 하는, 근거리에서 그리고 사람들과 함께 훈련 목적을 위한 시나리오에서 실제 전투 작전을 시뮬레이션하기위한 방법."}
{"patent_id": "10-2016-7000926", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 사람들과 함께 그리고 근거리에서의 훈련 목적을 위한 시나리오에서 실제 전투 작전을 시뮬레이션하기 위한 방법에 관한 것이다. 상기 방법에서, 훈련 무기를 갖춘 훈련 참여자들은 서로 경합하며, 훈련 중 훈련 참 여자들의 실제 작전 이벤트는 영상 시스템에 의해 기록되고 준-실시간으로 변화하는 3-D 모델로서 계산된다. 무 기 효과는, 무기의 물체 인식에 의해, 사격 중 상태 변화와 배향에 의해, 그리고 유효 방향으로 위치된 물체와 상기 물체의 손상 모델에 의해, 계산되며, 표시된다. 본 방법은, 훈련의 개시 전에, 시나리오의 모든 관련 개별 물체들에 대해, 상기 개별 물체들의 온전한, 명중된 그리고 파괴된 상태에서 상기 개별 물체들의 3-차원 모델과, 관련 음향 효과를 포함하는 상기 개별 물체들의 해당 상태 전이의 애니메이션이 생성되고 데이터베이스 (database)에 저장되는 것을 특징으로 한다."}
{"patent_id": "10-2016-7000926", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 사람들과 함께 그리고 근거리에서의 훈련 목적을 위한 시나리오에서 실제 전투 작전을 시뮬레이션하 기 위한 방법에 관한 것이며, 특허 청구항 제1항의 전제부의 특징들에 따르면, 훈련 참여자들은 훈련 무기를 갖 추고 서로 경합하며, 훈련 중 훈련 참여자들의 실제 행동은 영상 시스템(imaging system)에 의해 기록되고 준- 실시간(quasi real time)으로 변화하는 3-D 모델로 계산되며, 무기 효과는, 무기의 물체 인식, 사격(shot) 중 상태 변화와 배향(orientation) 및 유효 방향에서의 물체와 그 손상 모델(injury model)에 의해 계산되며, 표시 된다."}
{"patent_id": "10-2016-7000926", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "사람들과 함께 그리고 근거리에서의 훈련 목적을 위한 실제 전투 작전 중에 (예를 들어, 군사 도시 및 호별 전 투 및/또는 광란 또는 인질극 상황과 같은 경찰 시나리오 중에), 훈련 참여자들은, 상대에게 사격의 효과를 무 해하게 전달하기 위해서 색상 충전물(color fill)을 갖는 화기 발사체(fire projectile) 또는 광 신호(light signal)를 방출하는, 훈련 무기를 갖추고 서로 경합한다. 이후에, 명중(hit)은 광 센서에 의해 감지되며 광학 및/또는 음향 신호를 이용하여 명중된 사람에게 신호로 알려지거나 또는, 다른 경우에는, 색상 표시에 의해 명 중된 사람에게 간단히 표시된다. 이러한 경우에, 훈련받는 사람들은 안경, 헬멧 및 실드(shield)와 같은 복잡 한 보호구를 착용해야 하거나 또는 실제 시나리오에는 해당하지 않는 광 방출기 및 센서와 같은 추가 장비를 휴 대해야 한다. 이러한 문제는, 본 출원인에 의해 제출되었으나 아직 공개되지는 않은, 출원 DE 10 2012 207 112.1에서 이미 해 결되었다. 거기에서 개시된 가르침에 따르면, 훈련 환경 및 훈련받는 사람들의 도구화를 위한 어떠한 필요도더 이상 없으며 훈련 무기를 변화시킬 어떠한 필요도 더 이상 없다. 실제 행동은 영상 시스템에 의해 기록되며, 준-실시간으로 변화하는 3-차원 모델(3-D 모델)로 계산된다. 이러한 경우에, 무기 효과는 무기의 물 체 인식, 사격 중 상태 변화와 배향 및 유효 방향에서의 물체와 그 손상 모델에 의해 계산되며, 표시된다. 서두에서 기술된 근거리에서의 총격전 훈련 중에는, 훈련 행동의 더 현실적인 진행을 위해 명중의 경우에 명중 된 사람으로부터 그에 상응하여 올바른 반응에 대한 필요가 있다 (넘어짐, 쓰러짐 등). 이러한 목적을 위해, 명중된 사람은 명중을 인지해야 하고 가능한 한 사전에 합의된 관련 반응을 의식적으로 보여주어야 한다. 정신 적으로 그리고 육체적으로 모두 매우 요구가 많고 빠르게 일어나는 상황 중에서, 이러한 반응은 올바르게 일어 나지 않거나 너무 늦게 일어나거나 또는 전혀 일어나지 않을 수 있으며, 결과적으로 사격하는 사람을 혼란스럽 게 하고 훈련 행동을 비현실적으로 왜곡한다."}
{"patent_id": "10-2016-7000926", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 종래 기술에 비해 개선된 방법을 제공하는 데 목적을 두고 있다. 특히, 그 방법은 노력의 양을 감소 시키고 시뮬레이션의 효율성을 증가시키기 위한 것이다."}
{"patent_id": "10-2016-7000926", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "이러한 목적은 특허 청구항 제1항의 특징에 의해 달성된다. 본 발명은, 훈련의 개시 전에, 온전한, 명중된 그리고 파괴된 상태에서 시나리오의 모든 관련 개별 물체들의 3- 차원 모델과, 관련 음향 효과를 포함하는 해당 상태 전이의 애니메이션이, 생성되고 데이터베이스(database)에 저장되는 것을 제공한다. 따라서, 예를 들어 DE 10 2012 207 112.1에 기재된 가르침 외에도, 이러한 과제에 대한 해결책은, 훈련의 개시 전에, 온전한, 명중된 그리고 파괴된 상태에서 참여자들, 무기, 장비 품목, 가구 등과 같은, 시나리오의 모든 관련 개별 물체들의 3-D 모델과, 관련 음향 효과를 포함하는 해당 상태 전이의 애니메이션을, 생성하는 것 및 그것들을 데이터베이스에 저장하는 것을 수반한다. 본 발명의 일 실시형태는 훈련 상황 중의 소음(noise)이 시나리오에서 적어도 하나의 마이크로폰(microphone), 특히 복수의 마이크로폰을 이용하여 서라운드 사운드 기록 방식(surround sound recording method)으로 기록되 는 것을 제공한다. 따라서, 훈련 상황 중의 소음은, 시나리오에서, 적어도 하나의 마이크로폰, 특히 복수의 마이크로폰을 이용하여 적합한 서라운드 사운드 기록 방식으로 기록된다. DE 10 2012 207 112.1에 개시된 컴퓨터 시스템을 이용하는 경우, 상기 시스템은 다중채널 오디오/비디오 송신/수신 시스템으로 확장된다. 본 발명은 출원 DE 10 2012 207 112.1에서의 발명의 요지를 기초로 할 수 있고 거기에서 개시된 시스템과 결합 하여 사용될 수도 있지만, 그럴 필요는 없다. 그러나, 임의의 원하는 대안적인 시스템과 함께 사용하는 것은, 상기 시스템이 본 발명과 양립가능한 경우라면, 또한 생각될 수 있다. 본 발명의 일 실시형태에서, 훈련 참여자는 시야 방향으로 지향된 비디오 카메라와 적합한 작고 빠른 디스플레 이 시스템(비디오 안경, 망막 프로젝터 등)의 조합 및 이어폰을 갖춘 안경 형태로의 이미지 및 사운드를 위한 무선 송신/수신 유닛을 추가로 착용해야 한다. 이러한 장치 조합은 실제 시나리오 안으로 시야를 차단하고 원 래의 소음을 감추도록 구성된다. 본 발명에 따른 방법의 추가 개선 형태들은 각각의 장점들과 관련하여 이하에서 설명되는 추가 하위 청구항들에 서 명시된다. 하나 이상의 중앙 컴퓨터(central computer)에 의해 생성되고 훈련 참여자 자신들이 그 안에서 이동하는 3-D 시 나리오 모델은 크기 및 관점의 측면에서 맞춤 방식으로 그리고 디스플레이 시스템을 이용하여 실시간으로 훈련 참여자들에게 표시되며, 음향 오리엔테이션(acoustic orientation)을 위해 어울리는 사운드 효과는 서라운드 사 운드 방식으로 이어폰을 통해 재생된다. 이러한 경우에, 관찰자가 착용하는 카메라는, 훈련받는 사람 자신이, 예를 들어 DE 10 2012 207 112.1에서 개시 된 바와 같이, 영상 시스템으로부터 시나리오를 감추는 경우, 훈련받는 사람의 눈 바로 앞에서 시나리오를 추가로 기록하기 위해 바람직하게는 사용된다. 또한, 카메라는, 3-D 모델에서 훈련받는 사람의 자세 및 위치로부터 계산이 이에 충분하지 않은 경우, 관찰자의 시야 방향을 결정하기 위해 그리고 맞춤 방식으로 3-D 모델의 해당 시야를 생성하기 위해 그리고 그것을 헬멧 디스플레이에 표시하기 위해, 매우 정확한 보조장치(aid)로서 바람직하게는 사용된다. 따라서, 행동에 대한 오리엔테이션 및 기준을 위해, 참여자들은 실제 이미지를 이용하지 않고, 대신에 중앙 컴 퓨터(들)에 의해 그들에게 제시되는 해당 사운드 효과와 함께 시나리오의 사실감 있는 3-D 모델을 이용한다. 처음에 보여지는 모델 표현은 실제로 존재하는 세상에 해당하기 때문에, 훈련 참여자들은 거기에서 해당하는 물 체들을 터치할 수 있고, 이동시킬 수 있으며, 소리를 들을 수 있다. 시나리오는 저장된 3-D 모델의 도움으로 임의의 원하는 방식으로 변경될 수 있다. 예를 들어 화분(flowerpot) 의 계산된 명중의 경우, 컴퓨터(들)는 산산이 부서지는 조각들을 보여주며, 명중된 사람은 해당하는 방식으로 행동하는 아바타(avatar)로 대체되며, 그리고, 이에 맞춰, 해당하는 소음이 각각 재생된다. 이러한 착시(optical illusion)는, 훈련 참여자들이 대체된 물체 또는 그 원물(original)과 만나지 않는 한, 훈 련 참여자들에게 현실적이다. 그러나, 위에서 언급된 시나리오의 대부분의 경우에는 그렇지 않다. 바람직한 일 실시형태에서는, 훈련받을 사람들 외에도, 별개의 세력, 적, 동물(예를 들어 감시견) 등과 같은, 모든 다른 참여자들이 인공 수행자(아바타)에 의해 완전히 표현된다. 후자는 훈련 목적 및 훈련받는 사람의 행 동에 따라 인공지능에 의해 제어된다. 또 다른 바람직한 실시형태에 따르면, 훈련 참여자들이 터치할 물체들(예를 들어 프레임 내의 도어 핸들 및 도 어)만 실제 실체가 있게 생성되는, 현실적인 훈련 지역이 비용-효율적으로 구성된다. 이것은 동시 상호작용과 함께 가상 영역에서 자유로운 움직임을 다시 가능하게 한다. 바람직한 실시형태들은 또한 결합될 수 있다. 본 발명의 매우 중요한 장점은 서두에 기술된 과제들이 서로 대립하는 목적들의 협력적 상호작용과 함께 비용- 효율적이고 현실적인 방식으로 해결된다는 것이다. 시스템 변형에 따라, 훈련 중 해당 수행자를 제공할 때 그 리고 훈련 지역을 구성 및 이용할 때, 상당한 비용이 절감될 수 있다. 또한, 본 발명은 시나리오의 완전한 조작을 가능하게 하고, 그에 따라, 예를 들어 근접 필드에서 강력한 무기 효과(폭발 및 파괴) 및 이와 관련된 극도의 손상과 같은, 더욱 동적인 행동 시퀀스 및 훈련 가능성을 가능하게 한다. 훈련 참여자들은 실제 접근가능하고 상호작용하는 시나리오 내에 존재하고, 예를 들어 비디오 화면의 전방에서 와 같이, 고정된 위치에서 행동할 필요가 없다. 참여자의 위치 및 시야 방향을 결정하기 위한 추가 추적 방법 에 대한 필요가 없다. 이것은 시스템에서 고유한 특징이며, 이를테면, 본 발명에 따른 시스템에서의 자체-조절 성(self-adjusting)이다. 본 발명에 따르면, 관찰자의 실제 이미지는 디스플레이 시스템을 갖춘 컴퓨터에 의해 생성된 이미지로 대체된다. 따라서, 예를 들어 부분적으로 투명한 거울을 기초로 하는 디스플레이 시스템에서 발생하는 것처럼, 실제 배경 앞에 투명하고 떠 있는 물체와 같은 아티팩트(artefact)가 없다. 공지된 블루 박스 방법(blue box method)을 이용하여 물체를 대체하는 비디오 시스템에서와는 달리, 여기에 기 재된 시스템은, 이러한 목적을 위해 미리 정해진 컬러 영역에서뿐만 아니라 영역에서의 임의의 지점에서, 이미 지를 변경하기 위해 사용될 수 있다. 이러한 경우, 표현은 시야각에 따라 달라지고, 극도의 비스듬한 시야의 경우에 선명한 효과(vivid effect)를 또한 갖는다. 가상 물체는, 예를 들어 블루 박스 효과의 경우에서처럼, 중첩되지 않으며, 오히려 실제 시나리오 안으로 계산 되고 3-D 모델의 일부가 되기 때문에, 시야 방향 추적 및 오버레이(overlay)로부터 각각의 좌표계의 부정확한 차이(incorrect divergence) 또는 불량한 조정의 결과로서의 에러는 또한 생성되지 않는다. 근거리에서 그리고 사람들과 함께 훈련 목적을 위한 시나리오에서 실제 전투 작전을 시뮬레이션하기 위해 본 발 명에 따른 방법을 수행하기 위한 장치 및 개관(overview)은 이하에서 기술되며 도면을 이용하여 설명된다."}
{"patent_id": "10-2016-7000926", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명에 의하면 종래 기술에 비해 개선된 방법이 제공된다. 특히, 그 방법은 노력의 양을 감소시키고 시뮬레 이션의 효율성을 증가시킨다."}
{"patent_id": "10-2016-7000926", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "item": 1, "content": "도 1의 좌측 상단은 훈련 참여자가 위치되는 훈련 지역을 도시한다. 이러한 훈련 영역에 한 명 이상의 훈련 참 여자가 또한 배치될 수 있다는 것은 말할 것도 없다. 예를 들어 다른 훈련 참여자들, 훈련 아이템, 무기 등과 같은, 시나리오의 개별 물체들은 도시되어 있지 않지만 존재한다. 훈련 참여자들이 훈련 무기를 갖추고 서로 경합하는 훈련 영역에서 실제 행동은 오디오/비디오 송신/수신 시스 템을 이용하여 훈련 중 기록되고, 컴퓨터 시스템(미도시)을 이용하여 준-실시간으로 변화하는 3-D 모델로서 계산된다. 이러한 경우에, 무기 효과는, 훈련 참여자, 다른 아이템 또는 다른 사람의 방향으로 또는 허공으로 사격 중 상태 변화와 배향, 무기의 물체 인식에 의해, 그리고 유효 방향에서의 물체와 그 손상 모델에 의해, 계 산되며, 컴퓨터 시스템을 이용하여 표시된다. 이러한 목적을 위해, 훈련 지역에 마이크로폰이 먼저 설치되 고 거기에서 지배적인 음향을 기록한다. 마이크로폰을 포함하는 시스템을 이용하여 이미지들이 또한 기록된 다. 예를 들어 비디오 카메라를 이용하여 훈련 지역에서 기록된, 이러한 이미지들 및, 훈련 지역에서 지배적이 고 훈련에 기초하여 언제라도 변화하는, 3-D 모델은 마이크로폰을 이용하여 컴퓨터 시스템에 의해 준-실 시간으로 계산된다. 컴퓨터 시스템을 이용하여 계산된 3-D 모델은 컴퓨터 시스템의 데이터베이스에 저장된다. 이후에 그것은 적합한 재생에 의해 훈련 참여자에게 이용가능하게 될 수 있고, 그 결과 훈련 참여자는, 시나리오의 현재 상태 에 따라 온전한, 명중된 그리고 파괴된 상태에 있는, 참여자, 무기, 장비 품목, 가구 등과 같은, 시나리오의 관 련 개별 물체들의 모든 상태들에 관련된 해당 정보를 수신한다. 이것은 훈련 참여자가 더 이상 시나리오의 다 른 훈련 참여자들 또는 물체들과 직접 상호작용해야 할 필요는 없으며, 훈련 지역에 그 자체로 존재하게 될, 이 러한 실제 물체들의 순전히 가상의 디스플레이가 제공되며, 상기 물체들과 상호작용할 수 있다는 장점을 갖는다. 이것은 도 1의 우측 상단에서 훈련 지역에 의해 도시되며, 이 경우 거기에 도시된 구(sphere)는 이제 더 이상 존재하지 않는 실제 이벤트(event)의 가상 표현을 상징한다. 오디오/비디오 송신/수신 시스템을 이용하여 시나리오의 기록(recording)이 관찰 시스템에 의해 제어되며 그 리고/또는 모니터링되며 그리고/또는 관찰되는 것을 상상할 수 있다. 참여자들이 도 1에 도시된 훈련 지역에서 가상으로 행동하는 것을 가능하게 하기 위해, 우선, 데이터베이스 에 저장되고 연속적으로 변하는, 가상 시나리오를 각각의 훈련 참여자에게, 적절하게, 제시하는 것이 필요할 뿐 만 아니라, 마찬가지로 기록되어야 하는 훈련 참여자의 행동의 상호작용의 결과로서, 훈련 지역 내에서 각각의 훈련 참여자가 어디에 위치되어 있는지 그리고 그가 거기에 존재하는 다른 훈련 참여자, 상대 및 물체와 어떻게 상호작용하는지에 관한 정보를 컴퓨터 시스템에 제공하는 것이 또한 필요하다. 이러한 목적을 위해, 도 2는 안경 형태의 장치를 도시하며, 적어도 한 명의 참여자가, 바람직하게는 각각의 훈 련 참여자가, 그것을 착용할 수 있다. 이러한 장치는, 시야 방향으로 지향된 비디오 카메라와 적합한 작고 빠른 디스플레이 시스템의 조합 및 이어폰을 갖춘 안경 형태로, 이미지 및 사운드에 대한 무선 송신/수신 유닛으로서 구성된다. 훈련 참여자가 착용할 이러한 유닛은 훈련 중 원래의 소음을 감추고 실제 시나리오 안으로 시야를 차단하도록 구성된다. 이것은 각각의 훈련 참여자가 훈련 지역에서 자유롭게 이동할 수 있고 그 의 움직임에 기초하여 거기에 실제 시나리오를 생성할 수 있는 것을 가능하게 하며, 여기서 시나리오는 컴퓨터 시스템에 의해 그에 따라 기록되고 처리될 수 있으며 데이터베이스에 저장될 수 있다. 동시에, 컴퓨터 시스템은, 헬멧에서 데이터를 전송하기 위해 필요한 송신/수신 유닛과 시나리오를 기록하기 위해 필요한 비디오 카메라와 디스플레이 시스템을 통해 그리고 이어폰을 통해 거기에 가상 음향 시나리오를 통합시킴 으로써, 훈련 참여자에게 속하는 안경 형태의 유닛과 상응하는 방식으로 작용한다. 대안으로, 안경 하나에 이 어폰, 디스플레이 시스템 및 비디오 카메라를 통합시키는 것, 그리고, 그것들을 케이블(cable)을 통해, 예를 들어 의류(예를 들어 보호 조끼(protective vest), 전투복 등)와 같은, 훈련 참여자의 다른 위치에 배치될 필요가 있는 송신/수신 유닛에 연결하는 것을 또한 상상할 수 있다. 이것은, 훈련 참여자의 머리 영역에서 지장을 줄, 요소들(4 내지 7)을 위한 적절하게 치수화된 전원 공급장치가 거기에 또한 수용될 수 있다는 장점을 가질 것이다. 마이크로폰 및/또는 비디오 카메라에 의해 기록된 정보를 컴퓨터 시스템에, 무선으로뿐만 아니라 유선 방식으로도 또한, 전송하는 것을 예상하는 것이 마찬가지로 가능하다. 특히 바람직한 일 실시형태에서, 마이크 로폰은 훈련 지역에 정적으로 배치되며 컴퓨터 시스템에 유선연결된다. 훈련 참여자가 훈련 지역 내에서 이동하기 때문에, 참여자와 컴퓨터 시스템 사이에서 무선으로, 바람직하게는 라디오(radio)를 통해, 데이터 를 전송하는 것이 특히 유리하다. 데이터를 전송할 목적을 위해 컴퓨터 시스템에 관찰 장치가 마찬가지로 연결된다. 따라서, 관찰자를 위 해 훈련 지역에서 시나리오의 실제 및/또는 가상 이벤트를 제시하는 것이 가능하며, 그리고/또는, 예를 들어 데 이터베이스에 저장된 데이터를 변화시킴으로써, 관찰자가 이벤트에 개입하는 것이 가능하게 된다. 이러한 목적을 위해, 관찰 유닛은 그에 따라 구성된 재생 장치(예를 들어 스크린) 및/또는 그에 따라 구성된 입력 유닛(예를 들어 키보드, 조이스틱(joystick) 등)를 구비한다."}
{"patent_id": "10-2016-7000926", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 시나리오에서 전투 작전을 시뮬레이션하기 위한 시스템을 개략적으로 도시한다. 도 2는 훈련 참여자가 착용할 수 있는, 안경 형태의 장치를 개략적으로 도시한다."}
