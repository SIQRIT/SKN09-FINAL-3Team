{"patent_id": "10-2022-0021445", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0124306", "출원번호": "10-2022-0021445", "발명의 명칭": "비고정형 다중 단안 카메라를 이용한 사용자 3차원 관절 좌표 보정 방법 및 장치", "출원인": "한국전자통신연구원", "발명자": "김주영"}}
{"patent_id": "10-2022-0021445", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "사용자 관절 좌표 추출 방법에 있어서,제 1 사용자 스마트 디바이스가 상기 제 1 사용자 스마트 디바이스 위치에 기초하여 사용자에 대한 제 1 이미지를 획득하는 단계;상기 획득된 제 1 이미지를 관절 위치 추출 서버로 전송하는 단계로써, 상기 관절 위치 추출 서버는 상기 제 1이미지를 포함하는 적어도 하나 이상의 이미지를 획득하되, 상기 적어도 하나 이상의 이미지 각각은 서로 다른위치를 갖는 각각의 사용자 스마트 디바이스로부터 획득된 이미지이고; 및상기 관절 위치 추출 서버로부터 사용자 관절 좌표 정보를 수신하는 단계;를 포함하되,상기 제 1 이미지를 포함하는 상기 적어도 하나 이상의 이미지 각각으로부터 사용자 관절 좌표가 추출되고, 상기 추출된 사용자 관절 좌표는 상기 제 1 이미지를 기준으로 보정되어 상기 사용자 관절 좌표 정보로 도출되는,사용자 관절 좌표 추출 방법."}
{"patent_id": "10-2022-0021445", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 사용자 관절 좌표 추출 방법에 있어서, 제 1 사용자 스마트 디바이스가 제 1 사용자 스마트 디바이스 위치에 기초하여 사용자에 대한 제 1 이미지를 획득하는 단계, 획득된 제 1 이미지를 관절 위치 추출 서버로 전 송하는 단계로써, 관절 위치 추출 서버는 제 1 이미지를 포함하는 적어도 하나 이상의 이미지를 획득하되, 적어 도 하나 이상의 이미지 각각은 서로 다른 위치를 갖는 각각의 사용자 스마트 디바이스로부터 획득된 이미지이고, 및 관절 위치 추출 서버로부터 사용자 관절 좌표 정보를 수신하는 단계를 포함할 수 있다."}
{"patent_id": "10-2022-0021445", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 복수 개의 단안 카메라를 이용하여 사용자 관절 좌표를 추출하는 방법 및 장치에 대한 것이다. 구체 적으로, 복수 개의 단안 카메라를 이용하여 사용자 관절 위치를 더욱 정확하게 추출하기 위한 방법 및 장치에 관한 것으로 사용자의 이미지를 수집하는 모바일 디바이스 및 다른 디바이스를 통해 수집한 정보를 바탕으로 사 용자 관절 위치를 추출하는 방법 및 장치에 대한 것이다."}
{"patent_id": "10-2022-0021445", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "이미지에서 오브젝트를 추출하고, 추출된 오브젝트를 활용하는 기술이 다양한 분야에서 활용되고 있다. 또한, 깊이 정보를 이용한 카메라를 이용하여 사용자 움직임을 분석하고, 콘텐츠에 적용하는 기술이 다양하게 사용되 고 있다. 그러나, 깊이 정보를 이용하는 이미지를 획득하기 위해서는 깊이 정보를 고려하여 이미지를 촬영하는 카메라가 필요할 수 있고, 깊이 정보 전처리 동작이 필요할 수 있다. 상술한 점을 고려하여, 하기에서는 깊이 정보 없이 단안 카메라에 기초하여 획득한 이미지를 통해 사용자의 3차원 관절 좌표를 추출하는 방법에 대해 서 술한다."}
{"patent_id": "10-2022-0021445", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 깊이 정보 없는 이미지를 이용하여 사용자의 3차원 관절 위치를 추출하는 방법 및 장치를 제공하는데 목적이 있다. 본 발명은 복수 개의 사용자 스마트 디바이스를 통해 수집된 이미지를 사용하여 관절 위치를 추출하는 방법, 장 치 및 시스템을 제공하는데 목적이 있다. 본 발명은 사용자 스마트 디바이스를 통해 수집된 이미지를 관절 위치 추출 서버로 전송하고, 관절 위치 추출 서버에 기초하여 추출된 사용자 관절 좌표 정보를 수신하는 방법 및 장치를 제공하는데 목적이 있다."}
{"patent_id": "10-2022-0021445", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 일 실시예에 따르면, 사용자 관절 좌표 추출 방법에 있어서, 제 1 사용자 스마트 디바이스가 제 1 사 용자 스마트 디바이스 위치에 기초하여 사용자에 대한 제 1 이미지를 획득하는 단계, 획득된 제 1 이미지를 관 절 위치 추출 서버로 전송하는 단계로써, 관절 위치 추출 서버는 제 1 이미지를 포함하는 적어도 하나 이상의 이미지를 획득하되, 적어도 하나 이상의 이미지 각각은 서로 다른 위치를 갖는 각각의 사용자 스마트 디바이스 로부터 획득된 이미지이고, 및 관절 위치 추출 서버로부터 사용자 관절 좌표 정보를 수신하는 단계를 포함할 수 있다. 이때, 제 1 이미지를 포함하는 적어도 하나 이상의 이미지 각각으로부터 사용자 관절 좌표가 추출되고, 추출된 사용자 관절 좌표는 제 1 이미지를 기준으로 보정되어 사용자 관절 좌표 정보로 도출될 수 있다."}
{"patent_id": "10-2022-0021445", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명에 따르면, 깊이 정보 없는 이미지를 이용하여 사용자의 3차원 관절 위치를 추출하는 방법 및 장치를 제 공할 수 있다. 본 발명에 따르면, 복수 개의 사용자 스마트 디바이스를 통해 수집된 이미지를 사용하여 관절 위치를 추출하는 방법, 장치 및 시스템을 제공할 수 있다. 본 발명에 따르면, 사용자 스마트 디바이스를 통해 수집된 이미지를 관절 위치 추출 서버로 전송하고, 관절 위 치 추출 서버에 기초하여 추출된 사용자 관절 좌표 정보를 수신하는 방법 및 장치를 제공할 수 있다. 본 개시에서 얻을 수 있는 효과는 이상에서 언급한 효과들로 제한되지 않으며, 언급하지 않은 또 다른 효과들은"}
{"patent_id": "10-2022-0021445", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 2, "content": "아래의 기재로부터 본 개시가 속하는 기술분야에서 통상의 지식을 가진 자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2022-0021445", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하에서 는 첨부한 도면을 참고로 하여 본 개시의 실시 예에 대하여 본 개시가 속하는 기술 분야에서 통상의 지식을 가진 자가 용이하게 실시할 수 있도록 상세히 설명한다. 그러나, 본 개시는 여러 가지 상이한 형태로 구 현될 수 있으며 여기에서 설명하는 실시 예에 한정되지 않는다. 본 개시의 실시 예를 설명함에 있어서 공지 구성 또는 기능에 대한 구체적인 설명이 본 개시의 요지를 흐릴 수 있다고 판단되는 경우에는 그에 대한 상세한 설명은 생략한다. 그리고, 도면에서 본 개시에 대한 설명과 관계없 는 부분은 생략하였으며, 유사한 부분에 대해서는 유사한 도면 부호를 붙였다. 본 개시에 있어서, 어떤 구성요소가 다른 구성요소와 \"연결\", \"결합\" 또는 \"접속\"되어 있다고 할 때, 이는 직접 적인 연결관계뿐만 아니라, 그 중간에 또 다른 구성요소가 존재하는 간접적인 연결관계도 포함할 수 있다. 또한 어떤 구성요소가 다른 구성요소를 \"포함한다\" 또는 \"가진다\"고 할 때, 이는 특별히 반대되는 기재가 없는 한 다 른 구성요소를 배제하는 것이 아니라 또 다른 구성요소를 더 포함할 수 있는 것을 의미한다. 본 개시에 있어서, 제1, 제2 등의 용어는 하나의 구성요소를 다른 구성요소로부터 구별하는 목적으로만 사용되 며, 특별히 언급되지 않는 한 구성요소들간의 순서 또는 중요도 등을 한정하지 않는다. 따라서, 본 개시의 범위 내에서 일 실시 예에서의 제1 구성요소는 다른 실시 예에서 제2 구성요소라고 칭할 수도 있고, 마찬가지로 일 실시 예에서의 제2 구성요소를 다른 실시 예에서 제1 구성요소라고 칭할 수도 있다. 본 개시에 있어서, 서로 구별되는 구성요소들은 각각의 특징을 명확하게 설명하기 위함이며, 구성요소들이 반드 시 분리되는 것을 의미하지는 않는다. 즉, 복수의 구성요소가 통합되어 하나의 하드웨어 또는 소프트웨어 단위 로 이루어질 수도 있고, 하나의 구성요소가 분산되어 복수의 하드웨어 또는 소프트웨어 단위로 이루어질 수도 있다. 따라서, 별도로 언급하지 않더라도 이와 같이 통합된 또는 분산된 실시 예도 본 개시의 범위에 포함된다. 본 개시에 있어서, 다양한 실시 예에서 설명하는 구성요소들이 반드시 필수적인 구성요소들을 의미하는 것은 아 니며, 일부는 선택적인 구성요소일 수 있다. 따라서, 일 실시 예에서 설명하는 구성요소들의 부분집합으로 구성 되는 실시 예도 본 개시의 범위에 포함된다. 또한, 다양한 실시 예에서 설명하는 구성요소들에 추가적으로 다른 구성요소를 포함하는 실시 예도 본 개시의 범위에 포함된다. 본 발명의 이점 및 특징, 그리고 그것들을 달성하는 방법은 첨부되는 도면과 함께 상세하게 후술되어 있는 실시 예들을 참조하면 참조하면 명확해질 것이다. 그러나 본 발명은 이하에서 제시되는 실시예들에 한정되는 것이 아 니라 서로 다른 다양한 형태로 구현될 수 있으며, 단지 본 실시예들은 본 발명의 개시가 완전하도록 하고, 본"}
{"patent_id": "10-2022-0021445", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "발명이 속하는 기술분야에서 통상의 지식을 가진 자에게 발명의 범주를 완전하게 알려주기 위해 제공되는 것이다. 하기에서는 깊이 정보를 이용하지 않고, 단안 카메라의 입력 영상을 이용하여 사용자의 3차원 관절 위치를 추출 하는 방법에 대해 서술한다. 일 예로, 깊이 정보를 이용하는 카메라는 TOF(Time-of-Flight)에 기초하여 이미지 내에서 물체들의 거리 정보를 실시간으로 측정할 수 있다. 여기서, 상술한 바에 기초하여 측정된 값은 깊이 영 상으로 출력되어 양안식 또는 다시점 카메라와 함께 장면의 고화질 깊이 맵이 제작될 수 있다. 다만, 깊이 카메 라 자체가 가지는 기술적 한계가 존재할 수 있으며, 깊이 카메라를 이용하지 않고 사용자의 관절 위치 추출하여 활용하는 방안이 필요할 수 있다. 일 예로, 단안 카메라를 통해 사용자를 촬영하고, 이에 기초하여 사용자의 3차원 관절 위치를 추출할 수 있다. 이때 , 이미지에서 사용자의 3D 관절 좌표를 추출하는 알고리즘을 통해 이미지에서 3차원 관절 위치 좌표가 추 출될 수 있다. 보다 구체적인 일 예로, 인공지능(artificial intelligence)에 기초하여 딥러닝 방식을 통해 이 미지에서 3차원 관절 위치 좌표가 추출될 수 있다. 즉, 복수 개의 이미지로 학습된 학습모델을 통해 단안 카메 라를 통해 촬영한 이미지에서 3D 관절 좌표가 추출될 수 있다. 상술한 알고리즘 또는 학습모델을 통해 단안 카 메라를 통해 획득한 하나의 이미지를 통해서도 3D 관절 좌표가 추출될 수 있다. 다만, 3D 관절 좌표 추출 정확 도를 높이기 위해 복수 개의 이미지를 활용하는 것도 가능할 수 있다. 관절 위치 추출 정확도는 다른 위치의 단 안 카메라 입력 영상을 통해 향상될 수 있다. 일 예로, 다른 위치의 단안 카메라도 사용자를 촬영하고, 이에 기 초하여 3차원 관절 위치를 확인함으로써, 관절 위치 추출 정확도를 높일 수 있다. 또한, 일 예로, 사용자의 3D 관절 좌표 추출 알고리즘에 대한 구체적인 사항은 도 7에서 후술한다. 구체적인 일 예로, 도 1 은 본 개시의 일 실시예에 따라 복수 개의 단안 카메라를 이용하여 사용자 관절 위치를 추출하는 방법을 나타낸 도면이다. 도 1을 참조하면, 관절 위치 추출 서버는 복수 개의 사용자 스마트 디 바이스(120-1, 120-2, 120-3)와 네트워크를 통해 통신을 수행할 수 있다. 이때, 사용자 스마트 디바이스 (120-1, 120-2, 120-3)는 상술한 바와 같이 깊이 정보를 이용하지 않는 단안 카메라를 통해 타겟(또는 사용자) 를 촬영하고, 이에 기초하여 획득한 정보를 관절 위치 추출 서버로 전송할 수 있다. 일 예로, 사용자 스마트 디바이스는 스마트폰, 태블릿, 노트북, 웨어러블 디바이스, HMD(head mounted display) 및 그 밖의 단안 카메라를 구비하여 타겟을 촬영할 수 있는 장치를 지칭할 수 있으며, 특정 형태로 한정되지 않 는다. 또한, 일 예로, 사용자 스마트 디바이스는 IoT (Internet of Things) 디바이스일 수 있다. 또한, 사용자 스마트 디바이스는 특정 위치에 고정된 디바이스이거나 이동성을 갖는 장치일 수 있으며, 특정 형태로 한정되지 않는다. 또한, 하기에서 서술하는 디바이스는 어플리케이션 동작이 가능한 기기들을 지칭할 수 있으며, 특정 타 입으로 한정되지 않는다. 하기에서는 설명의 편의를 위해 사용자 스마트 디바이스로 지칭하지만, 이에 한정되지 않는다. 일 예로, 도 2는 본 개시의 일 실시예에 따라 사용자 스마트 디바이스 및 관절 위치 서버를 나타낸 도면이다. 도 2를 참조하면, 사용자 스마트 디바이스는 사용자 이미지 수집부, 사용자 관절 추출부 및 사 용자 관절 수신부 중 적어도 어느 하나로 구성될 수 있다. 이때, 사용자 스마트 디바이스는 카메라 입력에 기초하여 사용자 이미지(또는 타겟 이미지)를 수집할 수 있다. 일 예로, 카메라 입력에 기초하여 수집되 는 사용자 이미지는 깊이 정보를 이용하지 않는 단안 카메라에 기초하여 획득되는 사용자 이미지일 수 있으며, 상술한 실시예로 한정되지 않는다. 이때, 사용자 스마트 디바이스의 사용자 이미지 수집부는 카메라 입력에 기초하여 획득한 이미지를 수집하여 사용자 관절 추출부로 전달할 수 있다. 이때, 사용자 관절 추 출부는 사용자 관절 좌표를 추출할 수 있다. 이때, 사용자 관절은 머리(코), 목, 어깨, 팔꿈치, 손목, 골 반, 무릎 및 발목 중 적어도 어느 하나 이상으로 신체 어느 부위나 해당할 수 있으며, 특정 부위로 한정되는 것 은 아닐 수 있다. 이때, 사용자 스마트 디바이스는 추출된 사용자 관절 정보를 관절 위치 추출 서버로 전송할 수 있다. 일 예로, 관절 위치 추출 서버는 복수 개의 사용자 스마트 디바이스(120-1, 120-2, 120-3)로부터 추출된 사용자 관절 좌표 정보를 획득할 수 있으며, 이를 통해 사용자 관절 위치 정확도를 높일 수 있다. 이와 관련해 서는 후술한다. 사용자 스마트 디바이스는 사용자 관절 위치 좌표에 대한 정확도를 높이기 위해 사용자 관 절 수신부를 통해 정밀하게 보정된 관절 좌표 및 사용자 스마트 디바이스에서 추출하지 못한 관절 좌 표 정보 중 적어도 어느 하나 이상을 수신할 수 있다. 일 예로, 관절 위치 추출 서버는 사용자 이미지 수신부, 사용자 관절 추출부 및 사용자 관절 보 정부 중 적어도 어느 하나 이상으로 구성될 수 있다. 이때, 사용자 스마트 디바이스가 획득한 이미 지에 기초하여 관절 위치 추출이 충분하지 않은 경우, 사용자 스마트 디바이스는 획득한 이미지만 관절 위 치 서버로 전송할 수 있다. 이때, 위치 관절 서버의 사용자 이미지 수신부는 적어도 어느 하나 이상의 사용자 스마트 디바이스로부터 사용자(또는 타겟)에 대한 이미지를 획득할 수 있다. 그 후, 관절 위치 추출 서버의 사용자 관절 추출부는 수신한 이미지에 기초하여 사용자의 관절 좌표 정보를 추출 할 수 있다. 이때, 관절 위치 추출 서버의 사용자 관절 보정부는 복수 개의 사용자 스마트 디바이스 로부터 획득한 이미지를 통해 추출된 관절 좌표 정보에 기초하여 관절 좌표를 보정하여 관절 좌표 정보를 업데이트할 수 있다. 그 후, 관절 위치 추출 서버는 보정된 관절 좌표 정보를 사용자 스마트 디바이스 로 전송할 수 있다. 보다 구체적인 일 예로, 도 3을 참조하면, 복수 개의 사용자 스마트 디바이스(310-1, 310-2, 310-3, 310-4)로써 4대의 사용자 스마트 디바이스를 통해 관절 위치 좌표를 추출하고 보정하는 방법에 대해 서술한다. 다만, 이는 하나의 일 예일 뿐, 사용자 스마트 디바이스의 수가 상이할 수 있다. 도 3을 참조하면, 장애물(e.g. 책상, 의자)이 존재하는 환경에서 복수의 사용자 A, B, C 및 D가 존재하고, 각각 의 사용자는 각각의 사용자 스마트 디바이스(310-1, 310-2, 310-3, 310-4)를 구비한 경우를 고려할 수 있다. 이 때, 사용자 A, 사용자 B 및 사용자 D는 사용자 C를 바라볼 수 있다. 즉, 사용자 A에 대응되는 사용자 스마트 디 바이스(310-1), 사용자 B에 대응되는 사용자 스마트 디바이스(310-2), 사용자 D에 대응되는 사용자 스마트 디바 이스(310-4) 각각을 통해서 사용자 C를 촬영하여 이미지를 획득할 수 있다. 일 예로, 도 3에서 사용자 A에 대응 되는 사용자 스마트 디바이스(310-1) 및 사용자 D에 대응되는 사용자 스마트 디바이스(310-4)는 태블릿일 수 있 고, 사용자 B에 대응되는 사용자 스마트 디바이스(310-2) 및 사용자 C에 대응되는 사용자 스마트 디바이스(310- 3)는 HMD일 수 있다. 다만, 이는 하나의 일 예일 뿐, 상술한 실시예로 한정되지 않는다. 즉, 사용자에 의해 사 용되는 사용자 스마트 디바이스는 다양한 형태일 수 있으며, 특정 형태로 한정되는 것은 아닐 수 있다. 이때, 일 예로, 도 4(a)를 참조하면, 사용자 D에 대응되는 사용자 스마트 디바이스(310-4)가 사용자 C를 촬영하고, 이에 기초하여 도 4(b)처럼 관절 좌표 정보가 도출될 수 있다. 또한, 일 예로, 도 5(a)를 참조하면, 사용자 A에 대응되는 사용자 스마트 디바이스(310-1)가 사용자 C를 촬영하고, 이에 기초하여 도 5(b)처럼관절 좌표 정보가 도출될 수 있다. 또한, 일 예로, 도 6(a)를 참조하면, 사용자 B에 대응되는 사용자 스마트 디 바이스(310-2)가 사용자 C를 촬영하고, 이에 기초하여 도 6(b)처럼 관절 좌표 정보가 도출될 수 있다. 이 때, 사용자 A에 대응되는 사용자 스마트 디바이스(310-1)에서 촬영되는 이미지에는 사용자 C의 관절 좌표 를 정면에서 바라 본 모습이나 관절 일부가 책상에 가려져 보이지 않는 상태일 수 있다. 이때, 관절 위치 추출 서버는 각각의 사용자 스마트 디바이스 (310-1, 310-2, 310-4)로부터 촬영된 이미지 정보를 사용자 이미지 수신부를 통해 획득할 수 있다. 즉, 관절 위치 추출 서버는 사용자 C를 기준으로 서로 다른 위 치에서 사용자 C에 대한 이미지를 획득할 수 있다. 이때, 일 예로, 각각의 사용자 스마트 디바이스 (310- 1, 310-2, 310-4)는 고정된 위치에 존재하는 디바이스이거나 사용자에 의해 이동되는 디바이스일 수 있으며, 특 정 형태로 한정되는 것은 아닐 수 있다. 관절 위치 추출 서버는 관절 추출부를 통해 획득한 이미지로부터 관절 좌표를 추출할 수 있다. 다만, 상술한 바처럼 일부 관절 좌표는 장애물에 기초하여 추출되지 못할 수 있다. 관절 위치 추출 서버의 관절 보정부는 서로 다른 위치에서 촬영된 이미지에 기초하여 관절 좌표를 추출할 수 있다. 일 예로, 관절 추출 부는 사용자 A, 사용자 B 및 사용자 D에 대응되는 사용자 스마트 디바이스(310-1, 310-2, 310-4)로부터 획 득한 이미지 각각으로부터 관절 좌표 정보를 획득할 수 있다. 그 후, 관절 보정부는 사용자 A, B 및 D로부 터 수신한 관절 좌표 중 어느 한 좌표를 기준으로 다른 관절 좌표를 정합시킬 수 있으며, 이를 통해 관절 좌표 를 보정할 수 있다. 구체적인 일 예로, 사용자 A에 대응되는 사용자 스마트 디바이스(310-1)에 의해 도출된 관절 좌표를 기준으로 다른 관절 좌표가 정합될 수 있다. 다만, 이는 하나의 일 예일 뿐, 다른 관절 좌표를 기준으로도 수행될 수 있 다. 이때, 사용자 A에 대응되는 사용자 스마트 디바이스(310-1)에 의해 도출된 관절 좌표를 기준으로 하기 수학 식 1에 기초하여 사용자 D에 대응되는 사용자 스마트 디바이스(310-4)에서 추출된 C의 관절 좌표 값이 변환을 통해 사용자 A에 대응되는 사용자 스마트 디바이스(310-1)에 의해 도출된 관절 좌표 값으로 변환될 수 있다. 이 때, 사용자 A에 대응되는 사용자 스마트 디바이스(310-1)에 의해 추출된 관절 좌표값은 테이블에 가려져 손목, 골반 및 왼쪽 무릎 부분의 신뢰도가 낮은 값으로 추출될 수 있다. 일 예로, 기 설정된 신뢰도 값 이하에 기초하 여 관절 좌표가 추출될 수 있다. 따라서, 신뢰도가 낮은 관절 좌표 값을 대신하여 다른 관절 좌표 값을 정합할 필요성이 있다. 사용자 D에 대응되는 사용자 스마트 디바이스(310-4)에 의해 도출된 관절 좌표 값을 신뢰도가 낮은 관절 좌표 값에 정합하여 대체할 수 있다. 또한, 일 예로, 사용자 B에 대응되는 사용자 스마트 디바이스(310-2)에서 추출한 사용자 C의 관절 좌표 값도 하 기 수학식 1에 기초하여 사용자 A에 대응되는 사용자 스마트 디바이스(310-1)에 의해 도출된 관절 좌표 값으로 변환될 수 있다. 이때, 먼저 통합된 사용자 D에 대응되는 사용자 스마트 디바이스(310-4)의 추출된 관절 좌표 값은 왼쪽 측면에서 바라본 모습으로 오른쪽 관절 부위의 신뢰도가 낮을 수 있다. 일 예로, 기 설정된 신뢰도 값 이하에 기초하여 관절 좌표 값이 추출될 수 있다. 이때, 신뢰도가 낮은 오른쪽 손목과 팔꿈치 및 그 밖의 오 른쪽 관절 부위에 대한 관절 좌표를 사용자 B에 대응되는 사용자 스마트 디바이스(310-2)에서 추출하여 변환된 관절 좌표 값을 정합하여 대체할 수 있다. 상술한 바에 기초하여, 모든 사용자가 추출한 관절 좌표를 고려하여 사용자 C의 관절 좌표 보정이 완료된 경우, 관절 추출 위치 서버는 각각의 사용자는 각각의 사용자 스마트 디바이스(310-1, 310-2, 310-3, 310-4)에게 결과 값 정보를 전송할 수 있다. 즉, 상술한 바를 통해, 환경과 조 건이 상이하고, 다른 위치에서 촬영된 이미지를 통해 3차원 관절 좌표 정확도를 높일 수 있다. 즉, 기준 사용자 좌표계로 모든 사용자들이 추출한 관절 좌표 값을 변환한 후, 각 관절 부위 좌표 값의 신뢰도를 비교하여 신뢰 도가 더 높은 좌표 값으로 대체함으로써 더 정확한 관절 좌표를 얻는 후 모든 사용자와 공유할 수 있다. [수학식 1]"}
{"patent_id": "10-2022-0021445", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "item": 3, "content": "도 7은 본 개시의 일 실시예에 따라 3D 사용자 관절 좌표 추출 알고리즘 방식을 나타낸 도면이다. 일 예로, 도 7을 참조하면, 3D 사용자 관절 좌표 추출과 관련하여, 프레임 방식으로써 한 순간의 이미지만을 사용하는 방식 을 고려할 수 있다. 또 다른 일 예로, 시퀀스 방식으로써 시간 순서대로 복수의 이미지를 사용해서 과거 좌표를 참조하여 사용자의 관절 좌표를 추출하는 방식을 고려할 수 있다. 이때, 프레임 방식 및 시퀀스 방식 각각은 하 나의 카메라에 기초한 이미지를 이용하는 단안(monocular) 방식과 복수 개의 카메라를 여러 각도에서 사용자를 바라볼 수 있도록 고정적으로 설치한 후 동시에 다각도에서 복수 개의 이미지를 획득해서 사용자의 관절 좌표를 추출하는 멀티-뷰(multi-view) 방식을 고려할 수 있다. 또 다른 일 예로, 도 7를 참조하면, 3D 사용자 관절 좌표 추출과 관련하여 사용자의 관절 좌표만을 추출하는 스 켈레톤(skeleton) 방식과 사용자의 신체 실루엣까지 추출하는 세이프(Shape) 방식을 고려할 수 있다. 또한, 3D 사용자 관절 좌표 추출과 관련하여 이미지 내에서 특정 인물을 먼저 검색하고, 검색된 특정 인물에 대한 손목, 발목 및 그 밖의 관절 부위를 찾는 탑-다운(top-down) 방식을 고려할 수 있다. 또한, 이미지 내에서 손목, 발목 및 그 밖의 관절 부위를 찾은 후 이를 연결하여 특정 사람을 검색하는 버텀-업(bottom-up) 방식을 고려할 수 있 다. 상술한 도 1 내지 도 6에 기초하여 수행되는 3D 사용자 관절 좌표 추출은 프레임 방식 및 시퀀스 방식 중 어느 하나를 통해 수행될 수 있으며, 특정 방식으로 한정되지 않을 수 있다. 다만, 도 1 내지 도 6에 기초하여 수행 되는 3D 사용자 관절 좌표 추출은 단안 카메라로써 단안(monocular) 방식에 기초하여 수행될 수 있으며, 여러 각도에서 사용자 관절 좌표 추출 후 정합하여 정확도를 향상시킬 수 있다. 또한, 일 예로, 3D 사용자 관절 좌표 추출 알고리즘은 상술한 스켈레톤 방식일 수 있으나, 탑-다운 방식 및 버텀-업 방식 중 어느 하나를 통해 수행 될 수 있고, 특정 방식으로 한정되지 않을 수 있다. 도 8은 본 개시의 일 실시예에 따라 사용자 스마트 디바이스에서 관절 위치 추출 방법을 나타낸 순서도이다. 도 8을 참조하면, 사용자 스마트 디바이스는 사용자 스마트 디바이스만을 통해 사용자 관절 위치 좌표 정보를 획득할 수 있다. 보다 상세하게는, 사용자 스마트 디바이스는 사용자 이미지를 획득할 수 있다.(S810) 이때, 사 용자 스마트 디바이스는 사용자(또는 타겟)이 포함된 이미지를 획득하고, 이미지에서 특정 사용자를 선택할 수 있다. 그 후, 사용자 스마트 디바이스는 획득한 사용자 이미지로부터 사용자 관절 위치 좌표를 추출할 수 있 다.(S820) 일 예로, 사용자 이미지는 상술한 바와 같이 깊이 정보를 이용하지 않는 단안 카메라를 통해 획득된 이미지일 수 있으며, 사용자 관절 위치 좌표를 추출하기 위해 알고리즘 및 딥러닝 방식이 사용될 수 있으며, 이 는 상술한 바와 같다. 그 후, 사용자 스마트 디바이스가 추출된 사용자 관절 위치 좌표에 기초하여 관절 위치 좌표를 보정할 수 있다.(S830) 이때, 일 예로, 사용자 스마트 디바이스는 딥러닝에 기초하여 학습모델을 통해 상술한 관절 위치 좌표를 보정할 수 있다. 또 다른 일 예로, 사용자 스마트 디바이스는 다른 사용자 스마트 디 바이스 또는 서버로부터 획득한 정보를 이용하여 추출된 관절 위치 좌표를 보정할 수 있으며, 이를 통해 최종 사용자 관절 위치 좌표를 획득할 수 있다. 도 9는 본 개시의 일 실시예에 따라 관절 위치 추출 서버에 기초하여 관절 위치 추출 방법을 나타낸 순서도이다. 도 9를 참조하면, 사용자 스마트 디바이스는 사용자 이미지를 획득할 수 있다.(S910) 이때, 도 8에 서처럼 사용자 스마트 디바이스가 스스로 사용자 관절 위치 좌표를 추출할 수 있는 경우(S920), 사용자 스마트 디바이스는 스스로 사용자 관절 위치 좌표를 추출할 수 있으며, 이는 도 8과 같을 수 있다.(S930) 반면, 사용자 스마트 디바이스 스스로 사용자 관절 위치 좌표를 추출하지 못할 수 있다. 일 예로, 사용자 이미 지에서 관절 좌표를 추출하고자 하는 사용자에 대해서 장애물이 존재하는 경우, 사용자 스마트 디바이스는 사용 자의 관절 위치 좌표를 추출하지 못할 수 있다. 또 다른 일 예로, 사용자 스마트 디바이스는 이미지에서 특정 사용자(또는 타겟)을 명확하게 인식하기 어렵거나 인식률이 떨어지면 사용자 관절 좌표를 추출하지 못할 수 있 다. 이때, 사용자 스마트 디바이스는 획득한 사용자 이미지를 관절 위치 추출 서버로 전송할 수 있다.(S940) 이 때, 일 예로, 관절 위치 추출 서버는 상술한 바와 같이 복수 개의 사용자 스마트 디바이스로부터 각각의 이미지 를 획득할 수 있다. 이때, 관절 위치 추출 서버는 사용자(또는 타겟)를 기준으로 서로 다른 위치에서 사용자에 대한 이미지를 획득하는 각각의 사용자 스마트 디바이스로부터 이미지를 획득할 수 있다. 일 예로, 사용자 스마 트 디바이스들은 고정된 위치에 존재하는 디바이스이거나 사용자에 의해 이동되는 디바이스일 수 있으며, 특정 형태로 한정되는 것은 아닐 수 있다. 이때, 각각의 이미지에서 동일한 사용자(또는 동일한 타겟)에 대한 관절 위치 좌표를 추출할 수 있으며, 각각의 관절 위치 좌표에 대한 신뢰도 값이 결정될 수 있다. 또한, 관절 위치 추출 서버는 특정 사용자 스마트 디바이스에서 촬영된 이미지에서 추출된 관절 위치 좌표를 기준으로 다른 관절 위치 좌표를 정합할 수 있으며, 상술한 수학식 1에 기초하여 관절 위치 좌표가 전환될 수 있다. 이때, 일 예로, 각각의 사용자 스마트 디바이스에서 촬영된 이미지에서 추출된 관절 위치 좌표에 대해서 각각의 값의 신뢰도가부여될 수 있으며, 신뢰도에 따라 사용 여부가 상이할 수 있다. 일 예로, 상술한 바처럼 장애물이 존재하는 위 치에 대응되는 관절 위치 좌표에 대해서는 신뢰도가 낮을 수 있으며, 다른 사용자 스마트 디바이스를 통해 촬영 된 이미지에서 추출된 관절 위치 좌표에 기초하여 관절 위치 좌표가 전환되어 보정될 수 있으며, 이는 상술한 바와 같다. 그 후, 관절 위치 추출 서버는 복수 개의 사용자 스마트 디바이스들로 관절 위치 좌표 정보를 전송 할 수 있으며, 상술한 사용자 스마트 디바이스도 이를 통해 관절 위치 좌표를 수신할 수 있다.(S950) 도 10은 본 발명에 따른 장치 구성을 나타낸 도면이다. 상술한 바와 같이, 관절 위치 좌표를 추출하는 사용자 스마트 디바이스 및 관절 위치 추출 서버가 존재할 수 있다. 이때, 사용자 스마트 디바이스 및 관절 위치 추출 서버 각각은 도 10과 같이, 메모리, 프로세서 및 송수신부 중 적어도 어느 하나를 더 포함할 수 있다. 이때, 일 예로, 메모리는 사용자 관절 위치 좌표 정보나 이미지 정보 및 그 밖의 표본 정보를 저장할 수 있다. 이때, 프로세서는 상술한 바에 기초하여 메모리에 포함된 정보들을 제어할 수 있 다. 또한, 프로세서는 송수신부를 통해 다른 사용자 스마트 디바이스 또는 관절 위치 추출 서버와 통신을 수행할 수 있으며, 특정 실시예로 한정되지 않는다. 본 개시에 따른 방법을 구현하기 위해서, 예시하는 단계에 추가적으로 다른 단계를 포함하거나, 일부의 단계를 제외하고 나머지 단계를 포함하거나, 또는 일부의 단계를 제외하고 추가적인 다른 단계를 포함할 수도 있다. 본 개시의 다양한 실시 예는 모든 가능한 조합을 나열한 것이 아니고 본 개시의 대표적인 양상을 설명하기 위한 것이며, 다양한 실시 예에서 설명하는 사항들은 독립적으로 적용되거나 또는 둘 이상의 조합으로 적용될 수도 있다. 또한, 본 개시의 다양한 실시 예는 하드웨어, 펌웨어(firmware), 소프트웨어, 또는 그들의 결합 등에 의해 구현 될 수 있다. 하드웨어에 의한 구현의 경우, 하나 또는 그 이상의 ASICs(Application Specific Integrated Circuits), DSPs(Digital Signal Processors), DSPDs(Digital Signal Processing Devices), PLDs(Programmable Logic Devices), FPGAs(Field Programmable Gate Arrays), 범용 프로세서(general processor), 컨트롤러, 마이크로 컨트롤러, 마이크로 프로세서 등에 의해 구현될 수 있다. 본 개시의 범위는 다양한 실시 예의 방법에 따른 동작이 장치 또는 컴퓨터 상에서 실행되도록 하는 소프트웨어 또는 머신-실행가능한 명령들(예를 들어, 운영체제, 애플리케이션, 펌웨어(firmware), 프로그램 등), 및 이러한 소프트웨어 또는 명령 등이 저장되어 장치 또는 컴퓨터 상에서 실행 가능한 비-일시적 컴퓨터-판독가능 매체 (non-transitory computer-readable medium)를 포함한다."}
{"patent_id": "10-2022-0021445", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 개시의 일 실시예에 따라 사용자 스마트 디바이스와 관절 위치 추출 서버가 네트워크를 통해 통신을 수행하는 방법을 나타낸 도면이다. 도 2는 본 개시의 일 실시예에 따라 사용자 스마트 디바이스 및 관절 위치 추출 서버의 구성을 나타낸 도면이다. 도 3은 본 개시의 일 실시예에 따라 사용자 관절 위치를 추출하는 방법을 나타낸 도면이다. 도 4는 본 개시의 일 실시예에 따라 사용자 스마트 디바이스에 기초하여 사용자 이미지 및 사용자 관절 위치를 추출하는 방법을 나타낸 도면이다. 도 5는 본 개시의 일 실시예에 따라 사용자 스마트 디바이스에 기초하여 사용자 이미지 및 사용자 관절 위치를 추출하는 방법을 나타낸 도면이다. 도 6은 본 개시의 일 실시예에 따라 사용자 스마트 디바이스에 기초하여 사용자 이미지 및 사용자 관절 위치를 추출하는 방법을 나타낸 도면이다. 도 7은 본 개시의 일 실시예에 따라 3D 사용자 관절 좌표 추출 알고리즘 방식을 나타낸 도면이다.도 8은 본 개 시의 일 실시예에 따라 사용자 스마트 디바이스에서 관절 위치 추출 방법을 나타낸 순서도이다. 도 9는 본 개시의 일 실시예에 따라 관절 위치 추출 서버에 기초하여 관절 위치 추출 방법을 나타낸 순서도이다. 도 10은 본 발명에 따른 장치 구성을 나타낸 도면이다."}
