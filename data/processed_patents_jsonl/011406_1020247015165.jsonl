{"patent_id": "10-2024-7015165", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0107119", "출원번호": "10-2024-7015165", "발명의 명칭": "정보 처리 장치, 정보 처리 방법, 프로그램", "출원인": "소니 세미컨덕터 솔루션즈 가부시키가이샤", "발명자": "나가오 신이치"}}
{"patent_id": "10-2024-7015165", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "애플리케이션에 관한 유저 요구와, 상기 애플리케이션을 구성하는 소프트웨어 컴포넌트의 요구 사양에 따라, 상기 소프트웨어 컴포넌트마다 실행 주체가 되는 대상을 결정하는 결정 처리부를 구비한,정보 처리 장치."}
{"patent_id": "10-2024-7015165", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 애플리케이션은 복수의 소프트웨어 컴포넌트에 의해 구성되고,상기 결정 처리부는, 상기 복수의 소프트웨어 컴포넌트에 대해서 복수의 대상을 상기 실행 주체가 되는 대상으로서 결정하는, 정보 처리 장치."}
{"patent_id": "10-2024-7015165", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서, 상기 소프트웨어 컴포넌트의 요구 사양은, 개인 특정이 가능한 정보인 개인 특정 정보가 상기소프트웨어 컴포넌트에 대한 입력 데이터에 포함되어 있는지 여부를 나타내는 정보가 포함된, 정보 처리 장치."}
{"patent_id": "10-2024-7015165", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서, 상기 실행 주체가 되는 대상의 후보에 에지측 정보 처리 장치와 클라우드측 정보 처리 장치가포함된, 정보 처리 장치."}
{"patent_id": "10-2024-7015165", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제3항에 있어서, 상기 실행 주체가 되는 대상의 후보에 에지측 정보 처리 장치와 클라우드측 정보 처리 장치가포함되고,상기 결정 처리부는, 상기 입력 데이터에 상기 개인 특정 정보가 포함되어 있는 상기 소프트웨어 컴포넌트에 대해서, 상기 에지측 정보 처리 장치를 상기 실행 주체가 되는 대상으로서 결정하는, 정보 처리 장치."}
{"patent_id": "10-2024-7015165", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제3항에 있어서, 상기 개인 특정 정보는 촬상 화상 데이터로 된, 정보 처리 장치."}
{"patent_id": "10-2024-7015165", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6항에 있어서, 상기 결정 처리부는, 상기 입력 데이터에 상기 촬상 화상 데이터가 포함되어 있는 상기 소프트웨어 컴포넌트에 대해서, 이미지 센서를 상기 실행 주체가 되는 대상으로서 결정하는, 정보 처리 장치."}
{"patent_id": "10-2024-7015165", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서, 상기 결정 처리부는, 상기 입력 데이터에 상기 개인 특정 정보가 포함되어 있는 모든 상기 소프트웨어 컴포넌트에 대해서, 이미지 센서를 상기 실행 주체가 되는 대상으로서 결정하는, 정보 처리 장치."}
{"patent_id": "10-2024-7015165", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제4항에 있어서, 상기 에지측 정보 처리 장치는, 카메라 장치를 포함하는, 정보 처리 장치."}
{"patent_id": "10-2024-7015165", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9항에 있어서, 상기 카메라 장치는, 연산 처리부를 구비한 이미지 센서와 상기 이미지 센서 밖에 마련된 연산처리부를 구비하고,상기 이미지 센서 밖에 마련된 연산 처리부와 상기 이미지 센서는 각각 상기 실행 주체가 되는 대상의 후보로공개특허 10-2024-0107119-3-된, 정보 처리 장치."}
{"patent_id": "10-2024-7015165", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제1항에 있어서, 상기 요구 사양은, 하드웨어 요구 사양과 소프트웨어 요구 사양을 포함하는, 정보 처리 장치."}
{"patent_id": "10-2024-7015165", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제1항에 있어서, 상기 애플리케이션은, 인공 지능 모델을 사용한 처리를 행하는 상기 소프트웨어 컴포넌트를 포함하는, 정보 처리 장치."}
{"patent_id": "10-2024-7015165", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제1항에 있어서, 상기 애플리케이션은, 센싱 정보 또는 센싱 정보에 기초해서 얻어진 인식 정보에 관한 처리를행하는 상기 소프트웨어 컴포넌트를 포함하는, 정보 처리 장치."}
{"patent_id": "10-2024-7015165", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제13항에 있어서, 상기 센싱 정보는 촬상 화상 데이터로 된, 정보 처리 장치."}
{"patent_id": "10-2024-7015165", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "애플리케이션에 관한 유저 요구와, 상기 애플리케이션을 구성하는 소프트웨어 컴포넌트의 요구 사양에 따라, 상기 소프트웨어 컴포넌트마다 실행 주체가 되는 대상을 결정하는 처리를 컴퓨터 장치가 실행하는,정보 처리 방법."}
{"patent_id": "10-2024-7015165", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "애플리케이션에 관한 유저 요구와, 상기 애플리케이션을 구성하는 소프트웨어 컴포넌트의 요구 사양에 따라, 상기 소프트웨어 컴포넌트마다 실행 주체가 되는 대상을 결정하는 결정 기능을 연산 처리 장치에 실행시키는,프로그램."}
{"patent_id": "10-2024-7015165", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 기술에 관한 정보 처리 장치는, 애플리케이션에 관한 유저 요구와, 상기 애플리케이션을 구성하는 소프트웨어 컴포넌트의 요구 사양에 따라, 상기 소프트웨어 컴포넌트마다 실행 주체가 되는 대상을 결정하는 결정 처리부를 구비한 것이다."}
{"patent_id": "10-2024-7015165", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 기술은, 애플리케이션을 실현하기 위한 소프트웨어 컴포넌트를 각 장치에 배신하는 정보 처리 장치, 정보 처 리 방법 및 프로그램의 기술 분야에 관한 것이다."}
{"patent_id": "10-2024-7015165", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "애플리케이션을 실현하기 위해서는 적절한 장치에 당해 애플리케이션을 전개(디플로이)하는 것이 필요하다. 선행기술문헌 특허문헌 (특허문헌 0001) 일본 특허 제6126193호 공보"}
{"patent_id": "10-2024-7015165", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "예를 들어, 상기 특허문헌 1에서는, 단말기측의 OS(Operating System) 정보에 따라서 적절한 애플리케이션을 선 택하여 자동적으로 배분하는 기술이 개시되어 있다. 그러나, 애플리케이션을 적합한 환경에서 실현하기 위해서는, OS 정보에 따라서 당해 OS 상에서 동작하는 애플 리케이션을 선택하는 것만으로는 불충분할 가능성이 높다.본 기술은 이러한 문제를 감안해서 이루어진 것이며, 애플리케이션을 적절하게 실현하기 위한 환경을 제공하는 것을 목적으로 한다."}
{"patent_id": "10-2024-7015165", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 기술에 관한 정보 처리 장치는, 애플리케이션에 관한 유저 요구와, 상기 애플리케이션을 구성하는 소프트웨 어 컴포넌트의 요구 사양에 따라, 상기 소프트웨어 컴포넌트마다 실행 주체가 되는 대상을 결정하는 결정 처리 부를 구비한 것이다. 즉, 장치의 성능 등뿐만 아니라, 애플리케이션에 대한 유저의 요구를 가미해서 소프트웨어 컴포넌트의 실행 주 체가 되는 대상(전개처의 장치 등)이 결정된다."}
{"patent_id": "10-2024-7015165", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 첨부 도면을 참조하여, 본 기술에 관한 정보 처리 장치의 실시 형태를 다음의 순서로 설명한다. <1. 정보 처리 시스템> <1-1. 시스템 전체 구성> <1-2. AI 모델 및 AI 애플리케이션의 등록> <1-3. 시스템의 기능 개요> <1-4. 촬상 장치의 구성> <1-5. 정보 처리 장치의 하드웨어 구성> <2. 제1 실시 형태> <3. 제2 실시 형태> <4. 제3 실시 형태> <5. 기타> <6. 마켓 플레이스의 화면예> <7. 정리> <8. 본 기술> <1. 정보 처리 시스템> <1-1. 시스템 전체 구성> 도 1은 본 기술에 관한 실시 형태로서의 정보 처리 시스템의 개략 구성예를 도시한 블록도이다. 도시된 바와 같이 정보 처리 시스템은, 클라우드 서버와, 유저 단말기와, 복수의 카메라와, 포그 서버와, 관리 서버를 적어도 구비하고 있다. 본 예에서는, 적어도 클라우드 서버, 유저 단말기, 포그 서버 및 관리 서버는, 예를 들어 인터넷 등으로 된 네트워크를 통한 상호 통신을 행하는 것이 가 능하게 구성되어 있다. 클라우드 서버, 유저 단말기, 포그 서버 및 관리 서버는, CPU(Central Processing Unit), ROM(Read Only Memory) 및 RAM(Random Access Memory)을 갖는 마이크로컴퓨터를 구비한 정보 처리 장치로서 구 성되어 있다. 여기서, 유저 단말기는, 정보 처리 시스템을 사용한 서비스의 수혜자인 유저에 의해 사용되는 것이 상 정되는 정보 처리 장치이다. 또한, 관리 서버는, 서비스의 제공자에 의해 사용되는 것이 상정되는 정보 처 리 장치이다. 각 카메라는, 예를 들어 CCD(Charge Coupled Device)형 이미지 센서나 CMOS(Complementary Metal Oxide Semiconductor)형 이미지 센서 등의 이미지 센서를 구비하고, 피사체를 촬상해서 디지털 데이터로서의 화상 데 이터(촬상 화상 데이터)를 얻는다. 또한, 후술하는 바와 같이 각 카메라는, 촬상 화상에 대해서 AI(Artificial Intelligence: 인공 지능)를 사용한 처리(예를 들어, 화상 인식 처리나 화상 검출 처리 등)를 행 하는 기능도 갖고 있다. 이후의 설명에서는, 화상 인식 처리나 화상 검출 처리 등, 화상에 대한 각종 처리를 단순히 「화상 처리」라고 기재한다. 예를 들어, AI(혹은 AI 모델)를 사용한 화상에 대한 각종 처리는 「AI 화 상 처리」라고 기재한다. 각 카메라는, 포그 서버와 데이터 통신 가능하게 구성되며, 예를 들어 AI를 사용한 처리(화상 처리 등)의 결과를 나타내는 처리 결과 정보 등의 각종 데이터를 포그 서버에 송신하거나, 포그 서버로부터 각종 데 이터를 수신하거나 하는 것이 가능하게 된다. 여기서, 도 1에 나타내는 정보 처리 시스템에 대해서는, 예를 들어 각 카메라의 화상 처리에서 얻어지 는 처리 결과 정보에 기초하여, 포그 서버 또는 클라우드 서버가 피사체의 분석 정보를 생성하고, 생성한 분석 정보를 유저 단말기를 통해서 유저에게 열람시킨다는 용도가 상정된다. 이 경우, 각 카메라의 용도로서는, 각종 감시 카메라의 용도를 생각할 수 있다. 예를 들어, 점포나 오피스, 주택 등의 옥내에 대한 감시 카메라, 주차장이나 거리 등의 옥외를 감시하기 위한 감시 카메라(교통 감시 카메 라 등을 포함함), FA(Factory Automation)나 IA(Industrial Automation)에서의 제조 라인의 감시 카메라, 차내 나 차외를 감시하는 감시 카메라 등의 용도를 들 수 있다. 예를 들어, 점포에서의 감시 카메라의 용도라면, 복수의 카메라를 점포 내의 소정 위치에 각각 배치하여, 유 저가 내점객의 고객층(성별이나 연령층 등)이나 점포 내에서의 행동(동선) 등을 확인할 수 있도록 하는 것을 생 각할 수 있다. 그 경우, 상기한 분석 정보로서는, 이러한 내점객의 고객층의 정보나 점포 내에서의 동선의 정 보 및 정산 계산대에서의 혼잡 상태의 정보(예를 들어, 정산 계산대의 대기 시간) 등을 생성하는 것을 생각할 수 있다. 혹은, 교통 감시 카메라의 용도라면, 각 카메라를 도로 근방의 각 위치에 배치하여, 유저가 통과 차량에 관 한 넘버(차량 번호)나 차의 색, 차종 등의 정보를 인식할 수 있도록 하는 것을 생각할 수 있으며, 그 경우, 상 기한 분석 정보로서는, 이러한 넘버나 차의 색, 차종 등의 정보를 생성하는 것을 생각할 수 있다. 또한, 주차장에 교통 감시 카메라를 사용한 경우는, 주차되어 있는 각 차량을 감시할 수 있도록 카메라를 배치 하여, 의심스러운 행동을 하고 있는 수상한 사람이 각 차량의 주변에 없는지 등을 감시하고, 수상한 사람이 있 을 경우에는, 수상한 사람이 있는 것이나 그 수상한 사람의 속성(성별이나 연령층) 등을 통지하는 것을 생각할 수 있다. 또한, 거리나 주차장의 빈 공간을 감시하여, 유저에게 차를 주차할 수 있는 공간의 장소를 통지하는 것도 생각 할 수 있다. 포그 서버는, 예를 들어 상기한 점포의 감시 용도에서는 각 카메라와 함께 감시 대상의 점포 내에 배치되 는 등, 감시 대상마다 배치되는 것이 상정된다. 이와 같이 점포 등의 감시 대상마다 포그 서버를 마련함으 로써, 감시 대상에 있어서의 복수의 카메라로부터의 송신 데이터를 클라우드 서버가 직접 수신할 필요가 없어져, 클라우드 서버의 처리 부담 경감이 도모된다. 또한, 포그 서버는, 감시 대상으로 하는 점포가 복수 있고, 그러한 점포가 모두 동일 계열에 속하는 점포일 경우에는, 점포마다 마련하는 것이 아니라, 그러한 복수의 점포에 대해 하나 마련하는 것도 생각할 수 있다. 즉, 포그 서버는, 감시 대상마다 하나 마련하는 것에 한정되지는 않고, 복수의 감시 대상에 대해서 하나의 포그 서버를 마련하는 것도 가능한 것이다. 또한, 클라우드 서버, 혹은 각 카메라측에 처리 능력이 있는 등의 이유로, 포그 서버의 기능을 클라우 드 서버 혹은 각 카메라측에 부여할 수 있는 경우는, 정보 처리 시스템에 있어서 포그 서버를 생 략하고, 각 카메라를 직접 네트워크에 접속시켜, 복수의 카메라로부터의 송신 데이터를 클라우드 서버 가 직접 수신하도록 해도 된다. 상기 각종 장치는, 이하의 설명에서, 클라우드측 정보 처리 장치와 에지측 정보 처리 장치로 대별할 수 있다. 클라우드측 정보 처리 장치에는 클라우드 서버나 관리 서버가 해당하고, 복수의 유저에 의한 이용이 상정 되는 서비스를 제공하는 장치군이다. 또한, 에지측 정보 처리 장치에는 카메라와 포그 서버가 해당하고, 클라우드 서비스를 이용하는 유저에 의해 준비되는 환경 내에 배치되는 장치군으로서 파악하는 것이 가능하다. 단, 클라우드측 정보 처리 장치와 에지측 정보 처리 장치 양쪽이 동일한 유저에 의해 준비된 환경 하에 있어도 된다. 또한, 포그 서버는, 온프레미스 서버로 되어 있어도 된다. <1-2. AI 모델 및 AI 애플리케이션의 등록> 상술한 바와 같이, 정보 처리 시스템에서는, 에지측의 정보 처리 장치인 카메라에서 AI 화상 처리를 행 하고, 클라우드측의 정보 처리 장치인 클라우드 서버에서, 에지측에서의 AI 화상 처리의 결과 정보(예를 들 어 AI를 사용한 화상 인식 처리의 결과 정보)를 사용하여 고도의 애플리케이션 기능을 실현하는 것이다. 여기서, 클라우드측의 정보 처리 장치인 클라우드 서버(혹은 포그 서버를 포함함)에 애플리케이션 기능을 등록하는 방법은 다양하게 생각할 수 있다. 그 일례에 대해서, 도 2를 참조하여 설명한다. 또한, 포그 서버에 대해서는 도 2에서의 도시를 생략하고 있지만, 포그 서버를 구비한 구성으로 되어도 된다. 그 때의 포그 서버는, 에지측의 기능의 일부를 부담해도 된다. 상술한 클라우드 서버와 관리 서버는, 클라우드측의 환경을 구성하는 정보 처리 장치이다. 또한, 카메라는 에지측의 환경을 구성하는 정보 처리 장치이다. 또한, 카메라의 전체적인 제어를 행하는 제어부를 구비한 장치로서 카메라를 파악함과 함께, 촬상 화상에 대한 AI 화상 처리를 포함하는 각종 처리를 행하는 연산 처리부를 구비한 이미지 센서(IS)로서의 다른 장치를 구비한 장치로서 카메라를 파악할 수 있다. 즉, 에지측 정보 처리 장치인 카메라의 내부에 다른 에지측 정보 처리 장치인 이미지 센서(IS)가 탑재되어 있다고 파악해도 된다. 또한, 클라우드측의 정보 처리 장치가 제공하는 각종 서비스를 이용하는 유저가 사용하는 유저 단말기로서는, AI 화상 처리에 사용되는 애플리케이션을 개발하는 유저가 사용하는 애플리케이션 개발자 단 말기(2A)와, 애플리케이션을 이용하는 유저가 사용하는 애플리케이션 이용자 단말기(2B)와, AI 화상 처리에 사 용되는 AI 모델을 개발하는 유저가 사용하는 AI 모델 개발자 단말기(2C) 등이 있다. 또한, 물론, 애플리케이션 개발자 단말기(2A)는 AI 화상 처리를 사용하지 않는 애플리케이션을 개발하는 유저에 의해 사용되어도 된다. 클라우드측의 정보 처리 장치에는, AI에 의한 학습을 행하기 위한 학습용 데이터 세트가 준비되어 있다. AI 모 델을 개발하는 유저는, AI 모델 개발자 단말기(2C)를 이용하여 클라우드측의 정보 처리 장치와 통신을 행하고, 이들의 학습용 데이터 세트를 다운로드한다. 이때, 학습용 데이터 세트가 유료로 제공되어도 된다. 예를 들어, AI 모델 개발자는, 클라우드측의 기능으로서 준비되어 있는 마켓 플레이스(전자 시장)에 개인 정보를 등 록함으로써 마켓 플레이스에 등록된 각종 기능이나 소재의 구입을 가능하게 한 상태에서, 학습용 데이터 세트의 구입을 행해도 된다. AI 모델 개발자는, 학습용 데이터 세트를 사용하여 AI 모델의 개발을 행한 후, AI 모델 개발자 단말기(2C)를 사 용하여 당해 개발 완료된 AI 모델을 마켓 플레이스에 등록한다. 이에 의해, 당해 AI 모델이 다운로드되었을 때 AI 모델 개발자에게 인센티브가 지불되도록 해도 된다. 또한, 애플리케이션을 개발하는 유저는, 애플리케이션 개발자 단말기(2A)를 이용하여 마켓 플레이스로부터 AI 모델을 다운로드하고, 당해 AI 모델을 이용한 애플리케이션(이후, 「AI 애플리케이션」이라고 기재)의 개발을 행한다. 이때, 상술한 바와 같이, AI 모델 개발자에게 인센티브가 지불되어도 된다. 애플리케이션 개발 유저는, 애플리케이션 개발자 단말기(2A)를 사용하여 당해 개발 완료된 AI 애플리케이션을 마켓 플레이스에 등록한다. 이에 의해, 당해 AI 애플리케이션이 다운로드되었을 때 AI 애플리케이션을 개발한 유저에게 인센티브가 지불되도록 해도 된다. AI 애플리케이션을 이용하는 유저는, 애플리케이션 이용자 단말기(2B)를 이용하여 마켓 플레이스로부터 AI 애플 리케이션 및 AI 모델을 자신이 관리하는 에지측의 정보 처리 장치로서의 카메라에 전개(디플로이)하기 위한 조작을 행한다. 이때, AI 모델 개발자에게 인센티브가 지불되도록 해도 된다. 이에 의해, 카메라에 있어서 AI 애플리케이션 및 AI 모델을 사용한 AI 화상 처리를 행하는 것이 가능하게 되 고, 화상을 촬상할 뿐만 아니라 AI 화상 처리에 의해 내점객의 검출이나 차량의 검출을 행하는 것이 가능해진다. 여기서, AI 애플리케이션 및 AI 모델의 전개란, 실행 주체로서의 대상(장치)이 AI 애플리케이션 및 AI 모델을 이용할 수 있도록, 바꾸어 말하면, AI 애플리케이션으로서의 적어도 일부 프로그램을 실행할 수 있도록, AI 애 플리케이션이나 AI 모델이 실행 주체로서의 대상에 인스톨되는 것을 가리킨다.또한, 카메라에서는, AI 화상 처리에 의해, 카메라로 촬상된 촬상 화상으로부터 내점객의 속성 정보가 추 출 가능하게 되어 있어도 된다. 이러한 속성 정보는, 카메라로부터 네트워크를 통해서 클라우드측의 정보 처리 장치에 송신된다. 클라우드측의 정보 처리 장치에는, 클라우드 애플리케이션이 전개되어 있고, 각 유저는, 네트워크를 통해서 클라우드 애플리케이션을 이용 가능하게 되어 있다. 그리고 클라우드 애플리케이션 중에는, 내점객의 속성 정 보나 촬상 화상을 사용하여 내점객의 동선을 분석하는 애플리케이션 등이 준비되어 있다. 이러한 클라우드 애 플리케이션은, 애플리케이션 개발 유저 등에 의해 업로드된다. 애플리케이션 이용 유저는, 애플리케이션 이용자 단말기(2B)를 사용하여 동선 분석을 위한 클라우드 애플리케이 션을 이용함으로써, 자신의 점포에 대한 내점객의 동선 분석을 행하고, 해석 결과를 열람하는 것이 가능하게 되 어 있다. 해석 결과의 열람이란, 예를 들어 점포의 맵 상에 내점객의 동선이 그래피컬하게 제시됨으로써 행해 진다. 또한, 동선 분석의 결과가 히트 맵의 형태로 표시되어, 내점객의 밀도 등이 제시됨으로써 해석 결과의 열람이 행해져도 된다. 또한, 그러한 정보는, 내점객의 속성 정보마다 표시의 분류가 이루어져 있어도 된다. 클라우드측의 마켓 플레이스에서는, 유저마다 최적화된 AI 모델이 각각 등록되어 있어도 된다. 예를 들어, 어 떤 유저가 관리하고 있는 점포에 배치된 카메라에서 촬상된 촬상 화상이 적절하게 클라우드측의 정보 처리 장치에 업로드되어 축적된다. 클라우드의 정보 처리 장치에서는, 업로드된 촬상 화상이 일정 매수 쌓일 때마다 AI 모델의 재학습 처리를 행하 여, AI 모델을 갱신해서 마켓 플레이스에 다시 등록하는 처리가 실행된다. 또한, AI 모델의 재학습 처리는, 예를 들어 마켓 플레이스 상에서 유저가 옵션으로서 선택할 수 있도록 해도 된 다. 예를 들어, 점포 내에 배치된 카메라로부터의 어두운 화상을 사용하여 재학습된 AI 모델이 당해 카메라에 전개됨으로써, 어두운 장소에서 촬상된 촬상 화상에 관한 화상 처리의 인식율 등을 향상시킬 수 있다. 또한, 점포 밖에 배치된 카메라로부터의 밝은 화상을 사용하여 재학습된 AI 모델이 당해 카메라에 전개됨으로써, 밝은 장소에서 촬상된 화상에 관한 화상 처리의 인식율 등을 향상시킬 수 있다. 즉, 애플리케이션 이용 유저는, 갱신된 AI 모델을 다시 카메라에 재전개함으로써, 항상 최적화된 처리 결과 정보를 얻는 것이 가능해진다. 또한, AI 모델의 재학습 처리에 대해서는 다시 후술한다. 또한, 카메라로부터 클라우드측의 정보 처리 장치에 업로드되는 정보(촬상 화상 등)에 개인 정보가 포함되어 있는 경우에는, 프라이버시의 보호 관점에서 프라이버시에 관한 정보를 삭제한 데이터가 업로드되도록 해도 되 고, 프라이버시에 관한 정보가 삭제된 데이터를 AI 모델 개발 유저나 애플리케이션 개발 유저가 이용 가능하게 해도 된다. 상기한 처리의 흐름을 흐름도로서 도 3 및 도 4에 나타낸다. 또한, 클라우드측 정보 처리 장치는, 도 1에서의 클라우드 서버나 관리 서버 등이 해당한다. AI 모델 개발자가 LCD(Liquid Crystal Display) 혹은 유기 EL(Electro Luminescence) 패널 등을 포함하는 표시 부를 갖는 AI 모델 개발자 단말기(2C)를 사용하여 마켓 플레이스에 등록되어 있는 데이터 세트의 일람을 열람하 여 원하는 데이터 세트를 선택한 것에 따라, AI 모델 개발자 단말기(2C)는 스텝 S21에서, 당해 선택된 데이터 세트의 다운로드 요구를 클라우드측 정보 처리 장치에 송신한다. 이것을 받아, 클라우드측 정보 처리 장치에서는, 스텝 S1에서, 해당 요구를 접수하고, 스텝 S2에서, 요구된 데 이터 세트를 AI 모델 개발자 단말기(2C)에 송신하는 처리를 행한다. AI 모델 개발자 단말기(2C)에서는, 스텝 S22에서, 데이터 세트를 수신하는 처리를 행한다. 이에 의해, AI 모델 개발자는, 데이터 세트를 사용한 AI 모델의 개발이 가능해진다. AI 모델 개발자가 AI 모델의 개발을 종료한 후, AI 모델 개발자가 개발 완료된 AI 모델을 마켓 플레이스에 등록 하기 위한 조작을 행하면(예를 들어, AI 모델의 명칭이나, 그 AI 모델이 놓여 있는 어드레스 등을 지정하면), AI 모델 개발자 단말기(2C)는, 스텝 S23에서, AI 모델의 마켓 플레이스에의 등록 요구를 클라우드측 정보 처리 장치에 송신한다. 이것을 받아, 클라우드측 정보 처리 장치는, 스텝 S3에서, 해당 등록 요구를 접수하고, 스텝 S4에서, AI 모델의 등록 처리를 행함으로써, 예를 들어 마켓 플레이스 상에서 AI 모델을 표시시킬 수 있다. 이에 의해, AI 모델 개발자 이외의 유저가 AI 모델의 다운로드를 마켓 플레이스로부터 행하는 것이 가능해진다. 예를 들어, AI 애플리케이션의 개발을 행하고자 하는 애플리케이션 개발자는, 애플리케이션 개발자 단말기(2A) 를 사용하여 마켓 플레이스에 등록되어 있는 AI 모델의 일람을 열람한다. 애플리케이션 개발자 단말기(2A)는, 애플리케이션 개발자의 조작(예를 들어, 마켓 플레이스 상의 AI 모델의 하나를 선택하는 조작)에 따라, 스텝 S31에서, 당해 선택된 AI 모델의 다운로드 요구를 클라우드측 정보 처리 장치에 송신한다. 클라우드측 정보 처리 장치는 스텝 S5에서 당해 요구를 접수하고, 스텝 S6에서 AI 모델의 송신을 애플리케이션 개발자 단말기(2A)에 대해서 행한다. 애플리케이션 개발자 단말기(2A)는, 스텝 S32에서, AI 모델의 수신을 행한다. 이에 의해, 애플리케이션 개발자 는, 다른 사람이 개발한 AI 모델을 사용하는 AI 애플리케이션의 개발이 가능해진다. 애플리케이션 개발자가 AI 애플리케이션의 개발을 종료한 후, AI 애플리케이션을 마켓 플레이스에 등록하기 위 한 조작(예를 들어, AI 애플리케이션의 명칭이나 그 AI 모델이 놓여 있는 어드레스 등을 지정하는 조작)을 행하 면, 애플리케이션 개발자 단말기(2A)는 스텝 S33에서, AI 애플리케이션의 등록 요구를 클라우드측 정보 처리 장 치에 송신한다. 클라우드측 정보 처리 장치는, 스텝 S7에서, 당해 등록 요구를 접수하고, 스텝 S8에서, AI 애플리케이션의 등록 을 행함으로써, 예를 들어 마켓 플레이스 상에서 AI 애플리케이션을 표시시킬 수 있다. 이에 의해, 애플리케이 션 개발자 이외의 유저가 AI 애플리케이션을 마켓 플레이스 상에서 선택해서 다운로드하는 것이 가능해진다. 예를 들어, 도 4에 도시하는 바와 같이, AI 애플리케이션을 이용하고자 하는 유저에 의해, 애플리케이션 이용자 단말기(2B)는 스텝 S41에서, 목적 선택을 행한다. 목적 선택에서는, 선택된 목적이 클라우드측 정보 처리 장치 에 송신된다. 이것을 받아, 클라우드측 정보 처리 장치는 스텝 S9에서, 목적에 따른 AI 애플리케이션을 선택하고, 스텝 S10에 서, AI 애플리케이션이나 AI 모델을 각 장치에 전개하기 위한 준비 처리(전개 준비 처리)를 행한다. 전개 준비 처리에서는, AI 모델이나 AI 애플리케이션의 전개 처리의 대상이 된 장치의 정보, 예를 들어 카메라 나 포그 서버의 정보나, 유저가 요구하는 성능 등에 따라, AI 모델의 결정 등을 행한다. 또한, 전개 준비 처리에서는, 각 장치의 성능 정보나 유저의 요구 정보에 기초하여, 유저가 원하는 기능을 실현 하기 위한 AI 애플리케이션을 구성하는 각 SW(Software) 컴포넌트를 어느 장치에서 실행시킬지를 결정한다. 각 SW 컴포넌트는, 후술하는 컨테이너로 되어도 되고, 마이크로서비스로 되어도 된다. 또한, SW 컴포넌트는, 웹 어셈블리(WebAssembly) 기술을 사용해도 실현 가능하다. 내점객의 인원수를 성별이나 연령 등의 속성마다 카운트하는 AI 애플리케이션이라면, AI 모델을 사용하여 촬상 화상으로부터 인물의 얼굴을 검출하는 SW 컴포넌트와, 얼굴의 검출 결과로부터 인물의 속성 정보를 추출하는 SW 컴포넌트와, 결과를 집계하는 SW 컴포넌트와, 집계 결과를 가시화하는 SW 컴포넌트 등이 포함되어 있다. 전개 준비 처리에 대해서는 몇 가지의 예를 다시 후술한다. 클라우드측 정보 처리 장치는, 스텝 S11에서, 각 SW 컴포넌트를 각 장치에 전개하는 처리를 행한다. 이 처리에 서는, AI 애플리케이션 및 AI 모델이 카메라 등의 각 장치에 송신된다. 이에 따라, 카메라에서는, 스텝 S51에 의해 AI 애플리케이션 및 AI 모델의 전개 처리가 행해진다. 이에 의 해, 카메라에서 촬상된 촬상 화상에 대해서 AI 화상 처리가 가능해진다. 또한, 도 4에는 도시되어 있지 않지만, 포그 서버에서도 마찬가지로 AI 애플리케이션 및 AI 모델의 전개 처 리가 필요에 따라서 행해진다. 단, 모든 처리를 카메라에서 실행하는 경우에는 포그 서버에 대한 전개 처리는 행해지지 않는다. 카메라는, 스텝 S52에서, 촬상 동작을 행함으로써 화상의 취득을 행한다. 그리고 카메라는 스텝 S53에서, 취득한 화상에 대한 AI 화상 처리를 행하여, 예를 들어 화상 인식 결과를 얻는다. 카메라는, 스텝 S54에서, 촬상 화상이나 AI 화상 처리의 결과 정보의 송신 처리가 행해진다. 스텝 S54의 정 보 송신에서는, 촬상 화상과 AI 화상 처리의 결과 정보 양쪽을 송신해도 되고, 어느 한쪽만을 송신해도 된다. 이들 정보를 수신한 클라우드측 정보 처리 장치는, 스텝 S12에서, 분석 처리를 행한다. 이 분석 처리에 의해, 예를 들어 내점객의 동선 분석이나, 교통 감시를 위한 차량 분석 처리 등이 행해진다. 클라우드측 정보 처리 장치는 스텝 S13에서, 분석 결과의 제시 처리를 행한다. 이 처리는, 예를 들어 상술한 클라우드 애플리케이션을 유저가 이용함으로써 실현된다. 애플리케이션 이용자 단말기(2B)는, 분석 결과의 제시 처리를 받아, 스텝 S42에서 분석 결과를 모니터 등에 표 시시키는 처리를 행한다. 여기까지의 처리로, AI 애플리케이션의 이용자인 유저는, 스텝 S41에서 선택한 목적에 따른 분석 결과를 얻을 수 있다. 또한, 클라우드측 정보 처리 장치에서는, 스텝 S13 후에 AI 모델의 갱신을 행해도 된다. AI 모델의 갱신 및 전 개를 행함으로써, 유저의 사용 환경에 적합한 분석 결과를 얻는 것이 가능해진다. <1-3. 시스템의 기능 개요> 본 실시 형태에서는, 정보 처리 시스템을 사용한 서비스로서, 고객으로서의 유저가 각 카메라의 AI 화 상 처리에 관한 기능의 종별을 선택할 수 있는 서비스를 상정하고 있다. 기능의 종별 선택이란, 예를 들어 화 상 인식 기능과 화상 검출 기능 등을 선택해도 되고, 특정한 피사체에 관한 화상 인식 기능이나 화상 검출 기능 을 발휘하도록 더욱 자세한 종별을 선택해도 된다. 예를 들어, 비지니스 모델로서, 서비스 제공자는, AI에 의한 화상 인식 기능을 가진 카메라나 포그 서버 를 유저에게 판매하여, 그러한 카메라나 포그 서버를 감시 대상이 되는 장소에 설치시킨다. 그리고 상술 한 바와 같은 분석 정보를 유저에게 제공하는 서비스를 전개한다. 이때, 점포 감시의 용도나 교통 감시의 용도 등, 고객마다 시스템에 요구하는 용도가 다르기 때문에, 고객이 요 구하는 용도에 대응한 분석 정보가 얻어지도록, 카메라가 갖는 AI 화상 처리 기능을 선택적으로 설정하는 것 을 가능하게 한다. 본 예에서는, 이러한 카메라의 AI 화상 처리 기능을 선택적으로 설정하는 기능을 관리 서버가 갖는다. 또한, 관리 서버의 기능을 클라우드 서버나 포그 서버가 구비하고 있어도 된다. 여기서, 클라우드측의 정보 처리 장치인 클라우드 서버나 관리 서버와, 에지측의 정보 처리 장치인 카메 라의 접속에 대해서, 도 5을 참조하여 설명한다. 클라우드측의 정보 처리 장치에는, Hub를 통해서 이용 가능한 기능인 재학습 기능과 디바이스 관리 기능과 마켓 플레이스 기능이 실장되어 있다. Hub는, 에지측 정보 처리 장치에 대해서 시큐리티로 보호된 신뢰성이 높은 통신을 행한다. 이에 의해, 에지측 정보 처리 장치에 대해서 각종 기능을 제공할 수 있다. 재학습 기능은, 재학습을 행하여 새롭게 최적화된 AI 모델의 제공을 행하는 기능이며, 이에 의해, 새로운 학습 소재에 기초하는 적절한 AI 모델의 제공이 행해진다. 디바이스 관리 기능은, 에지측 정보 처리 장치로서의 카메라 등을 관리하는 기능이며, 예를 들어 카메라 에 전개된 AI 모델의 관리나 감시, 그리고 문제의 검출이나 트러블 슈팅 등의 기능을 제공할 수 있다. 또한, 디바이스 관리 기능은, 카메라나 포그 서버의 정보를 관리하는 기능이기도 하다. 카메라나 포 그 서버의 정보란, 연산 처리부로서 사용되고 있는 칩의 정보나, 메모리 용량 및 기억 용량, 그리고 CPU나 메모리의 사용률 등의 정보, 또한, 각 장치에 인스톨되어 있는 OS(Operating System) 등의 소프트웨어의 정보 등이다. 또한, 디바이스 관리 기능은, 인증된 유저에 의한 안전한 액세스를 보호한다. 마켓 플레이스 기능은, 상술한 AI 모델 개발자에 의해 개발된 AI 모델이나 애플리케이션 개발자에 의해 개발된 AI 애플리케이션을 등록하는 기능이나, 그러한 개발물을 허가된 에지측 정보 처리 장치에 전개하는 기능 등을 제공한다. 또한, 마켓 플레이스 기능은, 개발물의 전개에 따른 인센티브의 지불에 관한 기능도 제공된다. 에지측 정보 처리 장치로서의 카메라에는, 에지 런타임이나 AI 애플리케이션 및 AI 모델이나 이미지 센서 (IS)를 구비하고 있다. 에지 런타임은, 카메라에 전개된 애플리케이션의 관리나 클라우드측 정보 처리 장치와의 통신을 행하기 위한 임베디드 소프트웨어 등으로서 기능한다. AI 모델은, 상술한 바와 같이, 클라우드측 정보 처리 장치에서의 마켓 플레이스에 등록된 AI 모델을 전개한 것 이며, 이에 의해 카메라는 촬상 화상을 사용하여 목적에 따른 AI 화상 처리의 결과 정보를 얻을 수 있다. 도 6을 참조하여, 클라우드측 정보 처리 장치가 갖는 기능의 개요를 설명한다. 또한, 클라우드측 정보 처리 장 치란, 클라우드 서버 및 관리 서버 등의 장치를 통합해서 호칭한 것이다. 도시된 바와 같이 클라우드측 정보 처리 장치는, 라이센스 인가 기능(F1), 어카운트 서비스 기능(F2), 디바이스 감시 기능(F3), 마켓 플레이스 기능(F4) 및 카메라 서비스 기능(F5)을 갖는다. 라이센스 인가 기능(F1)은, 각종 인증에 관한 처리를 행하는 기능이다. 구체적으로, 라이센스 인가 기능(F1)에 서는, 각 카메라의 디바이스 인증에 관한 처리나, 카메라에서 사용되는 AI 모델, 소프트웨어, 펌웨어 각 각에 관한 인증에 관한 처리가 행해진다. 여기서, 상기한 소프트웨어는, 카메라에서 AI 화상 처리를 적절하게 실현시키기 위해서 필요하게 되는 소프 트웨어를 의미한다. 촬상 화상에 기초하는 AI 화상 처리가 적절하게 행해지고, AI 화상 처리의 결과가 적절한 형식으로 포그 서버 나 클라우드 서버에 송신되도록 하기 위해서는, AI 모델에의 데이터 입력을 제어하거나, AI 모델의 출력 데이터를 적절하게 처리할 것이 요청된다. 상기 소프트웨어는, AI 화상 처리를 적절하게 실현시키기 위해서 필 요한 주변 처리를 포함한 소프트웨어가 된다. 이러한 소프트웨어는, AI 모델을 이용하여 원하는 기능을 실현하 기 위한 소프트웨어이며, 상술한 AI 애플리케이션에 해당한다. 또한, AI 애플리케이션으로서는, 하나의 AI 모델만을 이용하는 것에 한정되지는 않고, 2 이상의 AI 모델을 이용 하는 것도 생각할 수 있다. 예를 들어, 촬상 화상을 입력 데이터로 해서 AI 화상 처리를 실행하는 AI 모델에서 얻어진 인식 결과의 정보(화상 데이터 등이며, 이후, 「인식 결과 정보」라고 기재)를, 다른 AI 모델에 입력해 서 제2 AI 화상 처리를 실행시킨다는 처리의 흐름을 갖는 AI 애플리케이션도 존재할 수 있다. 라이센스 인가 기능(F1)에 있어서, 카메라의 인증에 대해서는, 카메라와 네트워크를 통해서 접속되었 을 경우에, 카메라마다 디바이스 ID(Identification)를 발행하는 처리가 행해진다. 또한, AI 모델이나 소프트웨어의 인증에 대해서는, AI 모델 개발자 단말기(2C)나 소프트웨어 개발자 단말기 로부터 등록 신청된 AI 모델, AI 애플리케이션에 대해서, 각각 고유의 ID(AI 모델 ID, 소프트웨어 ID)를 발행하 는 처리가 행해진다. 또한, 라이센스 인가 기능(F1)에서는, 카메라나 AI 모델 개발자 단말기(2C), 소프트웨어 개발자 단말기와 클라우드 서버의 사이에서 안전한 통신이 행해지도록 하기 위한 각종 키나 증명서 등을 카메라의 제조업 자(특히 후술하는 이미지 센서(IS)의 제조업자)나 AI 모델 개발자, 소프트웨어 개발자에게 발행하는 처리가 행 해짐과 함께, 증명 효력의 갱신이나 정지를 위한 처리도 행해진다. 또한, 라이센스 인가 기능(F1)에서는, 이하에서 설명하는 어카운트 서비스 기능(F2)에 의해 유저 등록(유저 ID 의 발행을 수반하는 어카운트 정보의 등록)이 행해진 경우에, 유저가 구입한 카메라(상기 디바이스 ID)와 유 저 ID를 관련짓는 처리도 행해진다. 어카운트 서비스 기능(F2)은, 유저의 어카운트 정보의 생성이나 관리를 행하는 기능이다. 어카운트 서비스 기 능(F2)에서는, 유저 정보의 입력을 접수하고, 입력된 유저 정보에 기초하여 어카운트 정보를 생성한다(적어도 유저 ID와 패스워드 정보를 포함하는 어카운트 정보의 생성을 행한다). 또한, 어카운트 서비스 기능(F2)에서는, AI 모델 개발자나 AI 애플리케이션의 개발자(이하, 「소프트웨어 개발 자」라고 약칭하기도 함)에 관한 등록 처리(어카운트 정보의 등록)도 행해진다.디바이스 감시 기능(F3)은, 카메라의 사용 상태를 감시하기 위한 처리를 행하는 기능이다. 예를 들어, 카메 라의 사용 장소나, AI 화상 처리의 출력 데이터의 출력 빈도, AI 화상 처리에 사용되는 CPU나 메모리의 빈 용량 등, 카메라의 사용 상태에 관한 각종 요소로서 상술한 CPU나 메모리의 사용률 등의 정보에 관한 감시를 행한다. 마켓 플레이스 기능(F4)은, AI 모델이나 AI 애플리케이션을 판매하기 위한 기능이다. 예를 들어 유저는, 마켓 플레이스 기능(F4)에 의해 제공되는 판매용 WEB 사이트(판매용 사이트)를 통해서 AI 애플리케이션 및 AI 애플리 케이션이 이용하는 AI 모델을 구입하는 것이 가능해진다. 또한, 소프트웨어 개발자는, 상기 판매용 사이트를 통해서 AI 애플리케이션의 제작을 위해서 AI 모델을 구입하는 것이 가능해진다. 카메라 서비스 기능(F5)은, 카메라의 이용에 관한 서비스를 유저에게 제공하기 위한 기능이 된다. 이 카메라 서비스 기능(F5)의 하나로서는, 예를 들어 상술한 분석 정보의 생성에 관한 기능을 들 수 있다. 즉, 카메라에서의 화상 처리의 처리 결과 정보에 기초하여 피사체의 분석 정보를 생성하고, 생성한 분석 정보를 유저 단말기를 통해서 유저에게 열람시키기 위한 처리를 행하는 기능이다. 또한, 카메라 서비스 기능(F5)에는, 촬상 설정 탐색 기능이 포함된다. 구체적으로, 이 촬상 설정 탐색 기능은, 카메라로부터 AI 화상 처리의 인식 결과 정보를 취득하고, 취득한 인식 결과 정보에 기초하여, 카메라의 촬상 설정 정보를 AI를 사용하여 탐색하는 기능이다. 여기서, 촬상 설정 정보란, 촬상 화상을 얻기 위한 촬상 동작에 관한 설정 정보를 넓게 의미하는 것이다. 구체적으로는, 포커스나 조리개 등과 같은 광학적인 설정이나, 프레임 레이트, 노광 시간, 게인 등과 같은 촬상 화상 신호의 판독 동작에 관한 설정, 나아가 감마 보정 처리, 노이즈 리덕션 처리, 초해상 처리 등, 읽어내어진 촬상 화상 신호에 대한 화상 신호 처리에 관한 설 정 등을 넓게 포함하는 것이다. 또한, 카메라 서비스 기능(F5)에는, AI 모델 탐색 기능도 포함된다. 이 AI 모델 탐색 기능은, 카메라로부터 AI 화상 처리의 인식 결과 정보를 취득하고, 취득한 인식 결과 정보에 기초하여, 카메라에서의 AI 화상 처리 에 사용되는 최적의 AI 모델의 탐색을 AI를 사용하여 행하는 기능이다. 여기서 말하는 AI 모델의 탐색이란, 예 를 들어 AI 화상 처리가 컨볼루션 연산을 포함하는 CNN(Convolutional Neural Network) 등에 의해 실현되는 경 우에 있어서, 가중 계수 등의 각종 처리 파라미터나 뉴럴 네트워크 구조에 관한 설정 정보(예를 들어, 커널 사 이즈의 정보 등을 포함함) 등을 최적화하는 처리를 의미한다. 또한, 카메라 서비스 기능(F5)은, 처리 분담 결정 기능을 구비한다. 처리 분담 결정 기능에서는, AI 애플리케 이션을 에지측 정보 처리 장치에 전개할 때, 상술한 전개 준비 처리로서, SW 컴포넌트 단위에서의 전개처의 장 치를 결정하는 처리를 행한다. 또한, 일부 SW 컴포넌트는, 클라우드측의 장치에서 실행되는 것으로서 결정해도 되고, 이 경우에는 이미 클라우드측의 장치에 전개 완료인 것으로 보고 전개 처리가 행해지지 않아도 된다. 예를 들어, 상술한 예와 같이, 인물의 얼굴을 검출하는 SW 컴포넌트와, 인물의 속성 정보를 추출하는 SW 컴포넌 트와, 추출 결과를 집계하는 SW 컴포넌트와, 집계 결과를 가시화하는 SW 컴포넌트를 구비한 AI 어플리케이션인 경우에, 카메라 서비스 기능(F5)은, 인물의 얼굴을 검출하는 SW 컴포넌트에 대해서는 카메라의 이미지 센서 (IS)를 전개처의 장치로서 결정하고, 인물의 속성 정보를 추출하는 SW 컴포넌트에 대해서는 카메라를 전개처 의 장치로서 결정하고, 추출 결과를 집계하는 SW 컴포넌트에 대해서는 포그 서버를 전개처의 장치로서 결정 하고, 집계 결과를 가시화하는 SW 컴포넌트에 대해서는 장치에 새롭게 전개하지 않고 클라우드 서버에서 실 행하는 것을 결정한다. 이와 같이 하여, 각 SW 컴포넌트의 전개처를 결정함으로써 각 장치에서의 처리 분담을 결정한다. 또한, 이러한 결정은, 각 장치의 사양이나 성능, 그리고 유저의 요구를 고려해서 결정된다. 상기와 같은 촬상 설정 탐색 기능 및 AI 모델 탐색 기능을 가짐으로써, AI 화상 처리의 결과를 양호하게 하는 촬상 설정이 행해지도록 도모됨과 함께, 실제의 사용 환경에 따른 적절한 AI 모델을 사용하여 AI 화상 처리가 행해지도록 도모할 수 있다. 그리고 이것에 더하여 처리 분담 결정 기능을 가짐으로써, AI 화상 처리 및 그 해석 처리가 적절한 장치에서 실 행되도록 도모할 수 있다. 또한, 카메라 서비스 기능(F5)은, 각 SW 컴포넌트를 전개하기에 앞서, 애플리케이션 설정 기능을 갖는다. 애플 리케이션 설정 기능은, 유저의 목적에 따라서 적절한 AI 애플리케이션을 설정하는 기능이다.예를 들어, 유저가 점포 감시나 교통 감시 등의 용도를 선택한 것에 따라, 적절한 AI 애플리케이션을 선택한다. 이에 의해, AI 애플리케이션을 구성하는 SW 컴포넌트에 대해서도 저절로 결정된다. 또한, 후술하지만, AI 애플 리케이션을 사용하여 유저의 목적을 실현하기 위한 SW 컴포넌트의 조합이 복수 종류 있어도 되고, 이 경우에는, 에지측 정보 처리 장치의 정보나 유저의 요구에 따라서 하나의 조합이 선택된다. 예를 들어, 유저가 점포 감시를 목적으로 한 경우에, 유저의 요구가 프라이버시 중시일 경우와, 속도 중시일 경 우에, SW 컴포넌트의 조합이 달라도 된다. 애플리케이션 설정 기능에서는, 유저 단말기(도 2에서의 애플리케이션 이용자 단말기(2B)에 상당)에서 유저 가 목적(애플리케이션)을 선택하는 조작을 접수하는 처리나, 선택된 애플리케이션에 따라서 적절한 AI 애플리케 이션을 선택하는 처리 등이 행해진다. 여기서, 상기에서는, 클라우드 서버 단체에서 라이센스 인가 기능(F1), 어카운트 서비스 기능(F2), 디바이스 감시 기능(F3), 마켓 플레이스 기능(F4) 및 카메라 서비스 기능(F5)을 실현하는 구성을 예시하였지만, 이들 기 능을 복수의 정보 처리 장치가 분담해서 실현하는 구성으로 하는 것도 가능하다. 예를 들어, 상기 기능을 각각 1대의 정보 처리 장치가 담당하는 구성으로 하는 것을 생각할 수 있다. 혹은, 상기한 기능 중 단일 기능을 복 수의 정보 처리 장치(예를 들어, 클라우드 서버와 관리 서버)가 분담해서 행하는 것도 가능하다. 도 1에서, AI 모델 개발자 단말기(2C)는, AI 모델의 개발자가 사용하는 정보 처리 장치이다. 또한, 소프트웨어 개발자 단말기는, AI 애플리케이션의 개발자가 사용하는 정보 처리 장치이다. <1-4. 촬상 장치의 구성> 도 7은 카메라의 내부 구성예를 나타낸 블록도이다. 도시된 바와 같이 카메라는, 촬상 광학계, 광학계 구동부, 이미지 센서(IS), 제어부, 메모리부 , 통신부를 구비하고 있다. 이미지 센서(IS)와 제어부와 메모리부와 통신부는 버스를 통해서 접속되어, 서로 데이터 통신을 행하는 것이 가능하게 되어 있다. 촬상 광학계는, 커버 렌즈, 줌 렌즈, 포커스 렌즈 등의 렌즈나 조리개(아이리스) 기구를 구비한다. 이 촬 상 광학계에 의해, 피사체로부터의 광(입사광)이 유도되어, 이미지 센서(IS)의 수광면에 집광된다. 광학계 구동부는, 촬상 광학계가 갖는 줌 렌즈, 포커스 렌즈 및 조리개 기구의 구동부를 포괄적으로 나 타낸 것이다. 구체적으로, 광학계 구동부는, 이들 줌 렌즈, 포커스 렌즈, 조리개 기구 각각을 구동하기 위 한 액추에이터 및 해당 액추에이터의 구동 회로를 갖고 있다. 제어부는, 예를 들어 CPU, ROM 및 RAM을 갖는 마이크로컴퓨터를 구비해서 구성되며, CPU가 ROM에 기억되어 있는 프로그램, 또는 RAM에 로드된 프로그램에 따라서 각종 처리를 실행함으로써, 카메라의 전체 제어를 행 한다. 또한, 제어부는, 광학계 구동부에 대해서 줌 렌즈, 포커스 렌즈, 조리개 기구 등의 구동 지시를 행한다. 광학계 구동부는 이들 구동 지시에 따라서 포커스 렌즈나 줌 렌즈의 이동, 조리개 기구의 조리개 블레이드의 개폐 등을 실행시키게 된다. 또한, 제어부는, 메모리부에 대한 각종 데이터의 기입이나 판독에 관한 제어를 행한다. 메모리부는, 예를 들어 HDD(Hard Disk Drive)나 플래시 메모리 장치 등의 불휘발성 기억 디바이스로 되고, 이미지 센서(IS)로부터 출력된 화상 데이터의 보존 장소(기록처)로서 사용된다. 또한, 제어부는, 통신부를 통해서 외부 장치와의 사이에서 각종 데이터 통신을 행한다. 본 예에서의 통신부는, 적어도 도 1에 나타낸 포그 서버(혹은 클라우드 서버)와의 사이에서의 데이터 통신을 행하 는 것이 가능하게 구성되어 있다. 이미지 센서(IS)는, 예를 들어 CCD형, CMOS형 등의 이미지 센서로서 구성되어 있다. 이미지 센서(IS)는, 촬상부, 화상 신호 처리부, 센서내 제어부, AI 화상 처리부, 메모리부 , 통신 I/F를 구비하고, 각각이 버스를 통해서 서로 데이터 통신 가능하게 되어 있다. 촬상부는, 포토다이오드 등의 광전 변환 소자를 갖는 화소가 2차원으로 배열된 화소 어레이부와, 화소 어레 이부가 구비하는 각각의 화소로부터 광전 변환에 의해 얻어진 전기 신호를 읽어내는 판독 회로를 구비하고있어, 해당 전기 신호를 촬상 화상 신호로서 출력하는 것이 가능하게 되어 있다. 판독 회로에서는, 광전 변환에 의해 얻어진 전기 신호에 대해서, 예를 들어 CDS(Correlated Double Sampling) 처리, AGC(Automatic Gain Control) 처리 등을 실행하고, 또한 A/D(Analog/Digital) 변환 처리를 행한다. 화상 신호 처리부는, A/D 변환 처리 후의 디지털 데이터로서의 촬상 화상 신호에 대해서, 전처리, 동시화 처리, YC 생성 처리, 해상도 변환 처리, 코덱 처리 등을 행한다. 전처리에서는, 촬상 화상 신호에 대해서 R, G, B의 흑색 레벨을 소정의 레벨로 클램프하는 클램프 처리나, R, G, B의 색 채널간의 보정 처리 등을 행한다. 동시화 처리에서는, 각 화소에 관한 화상 데이터가, R, G, B 모든 색 성분을 갖도록 하는 색 분리 처리를 실시한다. 예를 들어, 베이어 배열의 컬러 필터를 사용한 촬상 소자의 경우는, 색 분리 처리로서 디모자이크 처리가 행해진다. YC 생성 처리에서는, R, G, B의 화상 데이터로부터, 휘도(Y) 신호 및 색(C) 신호를 생성(분리)한다. 해상도 변환 처리에서는, 각종 신호 처리가 실시된 화상 데이 터에 대해서, 해상도 변환 처리를 실행한다. 코덱 처리에서는, 상기 각종 처리가 실시된 화상 데이터에 대해서, 예를 들어 기록용이나 통신용의 부호화 처리, 파일 생성을 행한다. 코덱 처리에서는, 동화상의 파일 형식으로서, 예를 들어 MPEG-2(MPEG: Moving Picture Experts Group)나 H.264 등의 형식에 의한 파일 생성을 행하는 것이 가능해진다. 또한 정지 화상 파일 로서 JPEG(Joint Photographic Experts Group), TIFF(Tagged Image File Format), GIF(Graphics Interchange Format) 등의 형식의 파일 생성을 행하는 것도 생각할 수 있다. 센서내 제어부는, 촬상부에 대한 지시를 행하여 촬상 동작의 실행 제어를 행한다. 마찬가지로, 화상 신호 처리부에 대해서도 처리의 실행 제어를 행한다. AI 화상 처리부는, 촬상 화상에 대해서 AI 화상 처리로서의 화상 인식 처리를 행한다. AI를 사용한 화상 인식 기능은, 예를 들어 CPU나 FPGA(Field Programmable Gate Array), DSP(Digital Signal Processor) 등, 프로그래머블한 연산 처리 장치를 사용하여 실현할 수 있다. AI 화상 처리부에서 실현 가능한 화상 인식의 기능은, AI 화상 처리의 알고리즘을 변경함으로써 전환하는 것이 가능해진다. 바꾸어 말하면, AI 화상 처리에 사용되는 AI 모델을 전환함으로써, AI 화상 처리의 기능 종 별을 전환할 수 있다. AI 화상 처리의 기능 종별에 대해서는 다양하게 생각할 수 있지만, 예를 들어 이하에 예 시하는 바와 같은 종별을 들 수 있다. ·클래스 식별 ·시맨틱 세그멘테이션 ·인물 검출 ·차량 검출 ·타깃의 트래킹 ·OCR(Optical Character Recognition: 광학 문자 인식) 상기 기능 종별 중, 클래스 식별은, 타깃의 클래스를 식별하는 기능이다. 여기서 말하는 「클래스」란, 물체의 카테고리를 나타내는 정보이며, 예를 들어 「사람」 「자동차」 「비행기」 「배」 「트럭」 「새」 「고양이」 「개」 「사슴」 「개구리」 「말」 등을 구별하는 것이다. 타깃의 트래킹이란, 타깃으로 된 피사체의 추미를 행하는 기능이며, 해당 피사체의 위치의 이력 정보를 얻는 기 능이라고 환언할 수 있는 것이다. 메모리부에는, 화상 신호 처리부에 의해 얻어진 촬상 화상 데이터 등의 각종 데이터의 보존 장소로서 사용된다. 또한, 본 예에서 메모리부는, AI 화상 처리부가 AI 화상 처리의 과정에서 사용하는 데이터 의 일시적인 기억에도 사용하는 것이 가능해진다. 또한, 메모리부에는, AI 화상 처리부에서 사용되는 AI 애플리케이션이나 AI 모델의 정보가 기억된다. 또한, AI 애플리케이션이나 AI 모델의 정보는, 후술하는 컨테이너 기술을 사용하여, 컨테이너 등으로서 메모리 부에 전개되어도 되고, 마이크로서비스 기술을 사용하여 전개되어도 된다. AI 화상 처리에 사용되는 AI 모 델을 메모리부에 전개함으로써, AI 화상 처리의 기능 종별을 변경하거나, 재학습에 의해 성능의 향상이 도모된 AI 모델로 변경하거나 할 수 있다. 또한, 상술한 바와 같이 본 실시 형태에서는 화상 인식에 사용되는 AI 모델이나 AI 애플리케이션에 관한 예에 기초한 설명을 행하고 있지만, 이것에 한정되지는 않고, AI 기술을 사용하여 실행되는 프로그램 등이 대상으로 되어 있어도 된다. 또한, 메모리부의 용량이 작은 경우에는, AI 애플리케이션이나 AI 모델의 정보는, 컨테이너 기술을 사용하 여, 컨테이너 등으로서 메모리부 등 이미지 센서(IS) 밖의 메모리에 전개한 후, AI 모델만을 하기에서 설명 하는 통신 I/F를 통해서 이미지 센서(IS) 내의 메모리부에 저장시키도록 해도 된다. 통신 I/F는, 이미지 센서(IS)의 외부에 있는 제어부나 메모리부 등과의 통신을 행하는 인터페이스 이다. 통신 I/F는, 화상 신호 처리부가 실행하는 프로그램이나 AI 화상 처리부가 이용하는 AI 애 플리케이션이나 AI 모델 등을 외부로부터 취득하기 위한 통신을 행하고, 이미지 센서(IS)가 구비하는 메모리부 에 기억시킨다. 이에 의해, AI 모델이 이미지 센서(IS)가 구비하는 메모리부의 일부에 기억되어, AI 화상 처리부에 의 한 이용이 가능해진다. AI 화상 처리부는, 이와 같이 하여 얻어진 AI 애플리케이션이나 AI 모델을 사용하여 소정의 화상 인식 처리 를 행함으로써 목적에 준한 피사체의 인식을 행한다. AI 화상 처리의 인식 결과 정보는, 통신 I/F를 통해서 이미지 센서(IS)의 외부에 출력된다. 즉, 이미지 센서(IS)의 통신 I/F로부터는, 화상 신호 처리부로부터 출력되는 화상 데이터뿐만 아니라, AI 화상 처리의 인식 결과 정보가 출력된다. 또한, 이미지 센서(IS)의 통신 I/F로부터는, 화상 데이터와 인식 결과 정보 중 어느 한쪽만을 출력시킬 수 도 있다. 예를 들어, 상술한 AI 모델의 재학습 기능을 이용하는 경우에는, 재학습 기능에 사용되는 촬상 화상 데이터가 통신 I/F 및 통신부를 통해서 이미지 센서(IS)로부터 클라우드측 정보 처리 장치에 업로드된다. 또한, AI 모델을 사용한 추론을 행하는 경우에는, AI 화상 처리의 인식 결과 정보가 통신 I/F 및 통신부 를 통해서 이미지 센서(IS)로부터 카메라 밖의 다른 정보 처리 장치에 출력된다. 이미지 센서(IS)의 구성은 다양하게 생각할 수 있다. 여기서는, 이미지 센서(IS)가 2층으로 적층된 구조를 구 비하고 있는 예를 설명한다. 이미지 센서(IS)는, 도 8에 도시하는 바와 같이, 2개의 다이가 적층된 1칩의 반도체 장치로서 구성되어 있다. 이미지 센서(IS)는, 도 7에 나타내는 촬상부로서의 기능을 구비하는 다이 D1과, 화상 신호 처리부와 센 서내 제어부와 AI 화상 처리부와 메모리부와 통신 I/F를 구비한 다이 D2가 적층되어 구성되어 있다. 다이 D1과 다이 D2는, 예를 들어 Cu-Cu 접합에 의해 전기적으로 접속되어 있다. 카메라에 AI 모델이나 AI 애플리케이션 등을 전개하는 방법은 다양하게 생각할 수 있다. 일례로서 컨테이너 기술을 사용한 예를 설명한다. 카메라에서는, 도 7에 나타내는 제어부로서의 CPU나 GPU(Graphics Processing Unit)나 ROM이나 RAM 등 의 각종 하드웨어 상에 오퍼레이션 시스템이 인스톨되어 있다(도 9 참조). 오퍼레이션 시스템은, 카메라에서의 각종 기능을 실현하기 위해서 카메라의 전체 제어를 행하는 기본 소프트 웨어이다. 오퍼레이션 시스템 상에는, 범용 미들웨어가 인스톨되어 있다. 범용 미들웨어는, 예를 들어 하드웨어로서의 통신부를 사용한 통신 기능이나, 하드웨어로서의 표시부(모니터 등)를 사용한 표시 기능 등의 기본적 동작을 실현하기 위한 소프트웨어이다. 오퍼레이션 시스템 상에는, 범용 미들웨어뿐만 아니라 오케스트레이션 툴 및 컨테이너 엔진이 인스톨되어 있다.오케스트레이션 툴 및 컨테이너 엔진은, 컨테이너의 동작 환경으로서의 클러스터를 구축함으로 써, 컨테이너의 전개나 실행을 행한다. 또한, 도 5에 나타내는 에지 런타임은 도 9에 나타내는 오케스트레이션 툴 및 컨테이너 엔진에 상당한 다. 오케스트레이션 툴은, 컨테이너 엔진에 대해서 상술한 하드웨어 및 오퍼레이션 시스템의 리소 스의 할당을 적절하게 행하게 하기 위한 기능을 갖는다. 오케스트레이션 툴에 의해 각 컨테이너가 소 정의 단위(후술하는 포드)로 모아지고, 각 포드가 논리적으로 다른 에어리어로 된 워커 노드(후술)에 전개된다. 컨테이너 엔진은, 오퍼레이션 시스템에 인스톨되는 미들웨어의 하나이며, 컨테이너를 동작시키는 엔진이다. 구체적으로는, 컨테이너 엔진은, 컨테이너 내의 미들웨어가 구비하는 설정 파일 등에 기초 하여 하드웨어 및 오퍼레이션 시스템의 리소스(메모리나 연산 능력 등)를 컨테이너에 할당하는 기 능을 갖는다. 또한, 본 실시 형태에서 할당되는 리소스는, 카메라가 구비하는 제어부 등의 리소스뿐만 아니라, 이미지 센서(IS)가 구비하는 센서내 제어부나 메모리부나 통신 I/F 등의 리소스도 포함된다. 컨테이너는, 소정의 기능을 실현하기 위한 애플리케이션과 라이브러리 등의 미들웨어를 포함하여 구성된다. 컨테이너는, 컨테이너 엔진에 의해 할당된 하드웨어 및 오퍼레이션 시스템의 리소스를 사용하 여 소정의 기능을 실현하기 위해서 동작한다. 본 실시 형태에서는, 도 5에 나타내는 AI 애플리케이션 및 AI 모델은 컨테이너 중 1개에 상당한다. 즉, 카 메라에 전개된 각종 컨테이너 중 1개는, AI 애플리케이션 및 AI 모델을 사용한 소정의 AI 화상 처리 기 능을 실현한다. 컨테이너 엔진 및 오케스트레이션 툴에 의해 구축되는 클러스터의 구체적인 구성예에 대해서 도 10 을 참조하여 설명한다. 또한 클러스터는, 하나의 카메라가 구비하는 하드웨어뿐만 아니라 다른 장 치가 구비하는 다른 하드웨어의 리소스를 이용하여 기능이 실현되도록 복수의 기기에 걸쳐서 구축되어도 된다. 오케스트레이션 툴은, 컨테이너의 실행 환경의 관리를 워커 노드 단위로 행한다. 또한, 오케스트 레이션 툴은, 워커 노드 전체를 관리하는 마스터 노드를 구축한다. 워커 노드에서는, 복수의 포드가 전개된다. 포드는, 1개 또는 복수의 컨테이너를 포함하여 구 성되며, 소정의 기능을 실현한다. 포드는, 오케스트레이션 툴에 의해 컨테이너를 관리하기 위한 관리 단위가 된다. 워커 노드에서의 포드의 동작은, 포드 관리 라이브러리에 의해 제어된다. 포드 관리 라이브러리는, 논리적으로 할당된 하드웨어의 리소스를 포드에 이용시키기 위한 컨테이 너 런타임이나 마스터 노드로부터 제어를 접수하는 에이전트나 포드간의 통신이나 마스터 노드와의 통신을 행하는 네트워크 프록시 등을 갖고 구성되어 있다. 즉, 각 포드는, 포드 관리 라이브러리에 의해 각 리소스를 사용한 소정의 기능을 실현 가능하게 된다. 마스터 노드는, 포드의 전개를 행하는 애플리케이션 서버와, 애플리케이션 서버에 의한 컨테이 너의 전개 상황을 관리하는 매니저와, 컨테이너를 배치하는 워커 노드를 결정하는 스케줄러 와, 데이터 공유를 행하는 데이터 공유부를 포함하여 구성되어 있다. 도 9 및 도 10에 나타내는 구성을 이용함으로써, 컨테이너 기술을 사용하여 상술한 AI 애플리케이션 및 AI 모델 을 카메라의 이미지 센서(IS)에 전개하는 것이 가능해진다. 또한, 상술한 바와 같이, AI 모델에 대해서, 도 7의 통신 I/F를 통해서 이미지 센서(IS) 내의 메모리부(4 5)에 저장시켜, 이미지 센서(IS) 내에서 AI 화상 처리를 실행시키도록 해도 되고, 도 9 및 도 10에 나타내는 구 성을 이미지 센서(IS) 내의 메모리부 및 센서내 제어부에 전개하여, 이미지 센서(IS) 내에서 컨테이너 기술을 사용하여 상술한 AI 애플리케이션 및 AI 모델을 실행시켜도 된다. 또한, 후술하는 바와 같이, AI 애플리케이션 및/또는 AI 모델을 포그 서버나 클라우드측 정보 처리 장치에 전개하는 경우에도 컨테이너 기술을 사용할 수 있다.그 때는, AI 애플리케이션이나 AI 모델의 정보는, 컨테이너 등으로서, 후술하는 도 11의 불휘발성 메모리부 , 기억부 또는 RAM 등의 메모리에 전개되어 실행된다. <1-5. 정보 처리 장치의 하드웨어 구성> 정보 처리 시스템이 구비하는 클라우드 서버, 유저 단말기, 포그 서버, 관리 서버 등의 정보 처리 장치의 하드웨어 구성에 대해서 도 11을 참조하여 설명한다. 정보 처리 장치는 CPU를 구비하고 있다. CPU는, 상술한 각종 처리를 행하는 연산 처리부로서 기능하며, ROM이나 예를 들어 EEP-ROM(Electrically Erasable Programmable Read-Only Memory) 등의 불휘 발성 메모리부에 기억되어 있는 프로그램 또는 기억부로부터 RAM에 로드된 프로그램에 따라서 각종 처리를 실행한다. RAM에는 또한, CPU가 각종 처리를 실행하는데 있어서 필요한 데이터 등도 적절하게 기억된다. 또한, 클라우드 서버로서의 정보 처리 장치가 구비하는 CPU는, 상술한 각 기능을 실현하기 위해서 라이 센스 인가부, 어카운트 서비스 제공부, 디바이스 감시부, 마켓 플레이스 기능 제공부, 카메라 서비스 제공부로 서 기능한다. CPU, ROM, RAM, 불휘발성 메모리부는, 버스를 통해서 서로 접속되어 있다. 이 버스 에는 또한, 입출력 인터페이스(I/F)도 접속되어 있다. 입출력 인터페이스에는, 조작자나 조작 디바이스를 포함하는 입력부가 접속된다. 예를 들어 입력부로서는, 키보드, 마우스, 키, 다이얼, 터치 패널, 터치 패드, 리모트 컨트롤러 등의 각종 조작자나 조작 디바이스가 상정된다. 입력부에 의해 유저의 조작이 검지되고, 입력된 조작에 따른 신호는 CPU에 의해 해석된다. 또한 입출력 인터페이스에는, LCD 혹은 유기 EL 패널 등을 포함하는 표시부나, 스피커 등을 포함하는 음성 출력부가 일체 또는 별체로서 접속된다. 표시부는 각종 표시를 행하는 표시부이며, 예를 들어 컴퓨터 장치의 하우징에 마련되는 디스플레이 디바이 스나, 컴퓨터 장치에 접속되는 별체의 디스플레이 디바이스 등에 의해 구성된다. 표시부는, CPU의 지시에 기초하여 표시 화면 상에 각종 화상 처리를 위한 화상이나 처리 대상의 동화상 등의 표시를 실행한다. 또한 표시부는 CPU의 지시에 기초하여, 각종 조작 메뉴, 아이콘, 메시지 등, 즉 GUI(Graphical User Interface)로서의 표시를 행한다. 입출력 인터페이스에는, 하드 디스크나 고체 메모리 등으로 구성되는 기억부나, 모뎀 등으로 구성되는 통신부가 접속되는 경우도 있다. 통신부는, 인터넷 등의 전송로를 통한 통신 처리나, 각종 기기와의 유선/무선 통신, 버스 통신 등에 의한 통신을 행한다. 입출력 인터페이스에는 또한, 필요에 따라 드라이브가 접속되고, 자기 디스크, 광 디스크, 광자기 디스 크, 혹은 반도체 메모리 등의 리무버블 기억 매체가 적절하게 장착된다. 드라이브에 의해, 리무버블 기억 매체로부터 각 처리에 사용되는 프로그램 등의 데이터 파일 등을 읽어 낼 수 있다. 읽어내어진 데이터 파일은 기억부에 기억되거나, 데이터 파일에 포함되는 화상이나 음성이 표 시부나 음성 출력부에서 출력되거나 한다. 또한 리무버블 기억 매체로부터 읽어내어진 컴퓨터 프 로그램 등은 필요에 따라서 기억부에 인스톨된다. 이 컴퓨터 장치에서는, 예를 들어 본 실시 형태의 처리를 위한 소프트웨어를, 통신부에 의한 네트워크 통신 이나 리무버블 기억 매체를 통해서 인스톨할 수 있다. 혹은 당해 소프트웨어는 미리 ROM이나 기억부 등에 기억되어 있어도 된다. 또한, 카메라에서 촬상된 촬상 화상이나 AI 화상 처리에 의한 처리 결과를 수취하여, 기억부나 드라이브 를 통해서 리무버블 기억 매체에 기억시켜도 된다. CPU가 각종 프로그램에 기초하여 처리 동작을 행함으로써, 상술한 연산 처리부를 구비한 정보 처리 장치인 클라우드 서버로서의 필요한 정보 처리나 통신 처리가 실행된다.또한, 클라우드 서버는, 도 6과 같은 컴퓨터 장치가 단일하게 구성되는 것에 한정되지는 않고, 복수의 컴퓨 터 장치가 시스템화되어 구성되어도 된다. 복수의 컴퓨터 장치는, LAN(Local Area Network) 등에 의해 시스템 화되어 있어도 되고, 인터넷 등을 이용한 VPN(Virtual Private Network) 등에 의해 원격지에 배치된 것이어도 된다. 복수의 컴퓨터 장치에는, 클라우드 컴퓨팅 서비스에 의해 이용 가능한 서버군(클라우드)으로서의 컴퓨터 장치가 포함되어도 된다. <2. 제1 실시 형태> 클라우드측 정보 처리 장치가 실행하는 앞의 스텝 S10의 전개 준비 처리와 스텝 S11의 AI 애플리케이션 및 AI 모델의 전개 처리에 대한 일례를 설명한다. 제1 실시 형태는, 클라우드측 정보 처리 장치가, 에지측 정보 처리 장치의 사양 및 능력과 유저의 요구에 맞추 어서 SW 컴포넌트마다의 전개처의 장치를 결정함으로써, 에지측 정보 처리 장치의 환경(즉 유저의 환경)에서 적 합한 분석 결과를 유저에게 제시하는 것이다. 본 예에서는, 복수의 AI 애플리케이션(A1, A2, …AN) 중에서 유저가 선택한 애플리케이션에 기초하여, 하나의 AI 애플리케이션을 선택한다. 또한, AI 애플리케이션의 선택은 AI 모델을 선택하는 것이기도 하다. AI 애플리케이션에서는, 특정 기능을 실현하기 위해서 복수의 SW 컴포넌트(컨테이너나 마이크로서비스)가 정의 되어 있다. 또한, AI 애플리케이션에 포함되는 SW 컴포넌트는, 다른 AI 애플리케이션에 포함되는 것과 동일한 SW 컴포넌트이어도 된다. 클라우드측 정보 처리 장치는, 복수의 SW 컴포넌트(B1, B2, …Bn)마다 설정되어 있는 요구 사양에 따라서 각 SW 컴포넌트가 전개되어야 하는 적절한 장치를 결정한다. 구체적으로 도 12 및 도 13을 참조하여 설명한다. 도 12는, 복수의 AI 애플리케이션(A1, A2, …)과 각 AI 애플리케이션마다 정의되어 있는 복수의 SW 컴포넌트를 예시한 것이다. AI 애플리케이션(A1)은, SW 컴포넌트(B1, B2, B3, …Bn)가 정의되어 있다. 바꾸어 말하면, SW 컴포넌트(B1, B2, B3, …Bn)를 소정의 순서로 실행함으로써, AI 애플리케이션(A1)으로서의 원하는 기능을 실현할 수 있다. SW 컴포넌트(B1)는, 도 13에 도시하는 바와 같이, 원하는 처리를 실현하기 위한 프로그램과 함께, SW 컴포넌트 (B1)가 전개되는 장치를 결정하기 위한 요구 사양 등을 포함하는 정보(부가 정보)가 부수되어 있다. SW 컴포넌트(B1)의 부가 정보로서는, 「처리 내용」, 「입력 데이터」, 「출력 데이터」, 「HW(Hardware) 요구 사양」, 「SW 요구 사양」, 「이용 비용」 등이 설정되어 있다. 또한, 예를 들어 「추론의 정확성」 등 다른 부가 정보를 포함하고 있어도 된다. 「처리 내용」은, SW 컴포넌트가 실행하는 처리의 내용을 나타낸 것이며, SW 컴포넌트(B1)의 처리 내용은 「얼 굴 검출」로 되어 있다. 「입력 데이터」는, SW 컴포넌트에 입력되는 데이터의 사양 등을 나타낸 것이며, SW 컴포넌트(B1)의 입력 데이 터는, 1920x1080의 RGB 화상으로 되어 있다. 또한, 더 큰 화상이어도 되며, 그 경우에는, 해상도 변환을 행하 는 SW 컴포넌트를 사용해도 되고, SW 컴포넌트(B1)가 해상도 변환의 처리가 가능하게 되어 있어도 된다. 또한, 해상도 변환 처리를 다른 AI 애플리케이션에서 이용하는 것을 고려하면, 해상도 변환을 행하는 SW 컴포넌 트가 별도 마련되어 있는 편이 적합하다. 또한, SW 컴포넌트(B1)의 입력 데이터는, 개인을 특정 가능한 정보(개인 특정 정보)를 포함하고 있는 것을 알 수 있다. 개인 특정 정보의 유무 정보는, 유저에 의해 프라이버시 보호를 우선적으로 실현할 것이 요구되었을 경우에 사용되는 정보이다. 또한, 「입력 데이터」는, SW 요구 사양으로서 파악하는 것이 가능하다. 「출력 데이터」는, SW 컴포넌트로부터 출력되는 데이터의 사양 등을 나타낸 것이며, SW 컴포넌트(B1)의 출력 데이터는, 검출한 얼굴의 좌표 정보로 되어 있다. 또한, 출력 데이터는, 개인 특정 정보를 포함하고 있지 않은 것을 알 수 있다. 즉, SW 컴포넌트(B1)의 출력 데이터를 수취해서 처리를 행하는 후단의 SW 컴포넌트는, 에지측 정보 처리 장치와 클라우드측 정보 처리 장치의 어느 곳에 전개되었다고 해도, 프라이버시에 관한 문제가 생기지 않는다. 「HW(Hardware) 요구 사양」은, SW 컴포넌트를 전개하는 장치에 요구되는 HW의 사양이며, SW 컴포넌트(B1)의 HW 요구 사양은, xx프로세서와 DSP가 필요하게 되어 있다. 「SW(Software) 요구 사양」은, SW 컴포넌트를 전개하는 장치에 요구되는 SW의 사양이며, SW 컴포넌트(B1)의 SW 요구 사양은, xxOS가 인스톨되어 있을 필요가 있고, CPU 사용률이 15％ 필요할 것, 그리고 필요한 메모리 사이 즈가 xxMB로 되어 있다. 즉, SW 컴포넌트(B1)를 전개하기 전의 상태에서, CPU 사용률이 85％ 이상인 경우에는, SW 컴포넌트(B1)의 처리를 적절하게 실행할 수 없을 가능성이 있는 것을 알 수 있다. 「이용 비용」은, SW 컴포넌트를 이용하기 위해서 필요한 비용이며, SW 컴포넌트를 장치에 전개한 후에 비용이 불필요한 것을 나타내고 있다. 또한, 이용 비용과는 별도로 도입 비용이 부가 정보로서 포함되어 있어도 된다. 도입 비용은, 예를 들어 상술 한 마켓 플레이스 기능을 사용하여 SW 컴포넌트(B1)를 구입했을 때 지불하는 비용이다. SW 컴포넌트는, 예시한 「얼굴 검출」을 행하는 SW 컴포넌트 이외에도, 「머리부 검출」이나 「자세 검출」이나 「속성 검출」이나 「결과 집계」를 행하는 SW 컴포넌트 등이 있다. 이러한 부가 정보에 기초하여 SW 컴포넌트를 전개시키는 장치를 결정하는 예에 대해서 설명한다. 도 14는, SW 컴포넌트의 전개처가 되는 장치, 바꾸어 말하면, SW 컴포넌트로서의 프로그램이 기억되는 기억부를 발췌해서 나타낸 것이다. 구체적으로, 에지측 정보 처리 장치의 기억부로서, 정보 처리 시스템은, 카메라(3A)가 구비하는 메모리부 와, 카메라(3A)가 내부에 구비하는 이미지 센서(IS)의 메모리부와, 포그 서버의 기억부와, 클라 우드측 정보 처리 장치로서의 클라우드 서버 및 관리 서버가 구비하는 각 기억부를 구비하고 있다. 또한, 본 도면에서는, 1대의 카메라(3A)를 예시하였지만, 용도에 사용되는 카메라의 대수분만큼 메모리부 와 메모리부가 전개처의 후보로 된다. 또한, 포그 서버도 필요에 따라서 복수대 마련되어 있어도 된다. 도 15는, 장치에 전개되는 AI 애플리케이션(A1)의 기능을 실현하기 위한 SW 컴포넌트(B1, B2, B3, B4)의 내용의 일부를 나타낸 것이다. SW 컴포넌트(B1)는 얼굴 검출을 행하는 프로그램으로 되고, SW 컴포넌트(B2)는 인물의 속성 정보를 추출하기 위 한 프로그램으로 되고, SW 컴포넌트(B3)는 인원수의 카운트 결과를 집계하기 위한 프로그램으로 되고, SW 컴포 넌트(B4)는 집계 결과를 가시화하기 위한 프로그램으로 되어 있다. 또한, SW 컴포넌트(B1)는, 도 13에 도시하는 바와 같이 개인 특정 정보를 포함하는 정보를 입력 데이터로 해서 처리를 행하고, 개인 특정 정보를 포함하지 않는 정보를 출력 데이터로서 출력한다. 클라우드측 정보 처리 장치는, 이들 SW 컴포넌트마다의 특성이나 유저의 요구에 따라서 각 SW 컴포넌트의 전개 처의 장치를 결정한다. 도 16에 각 SW 컴포넌트의 전개예를 나타낸다. 카메라(3A)가 구비하는 이미지 센서(IS)의 메모리부에 SW 컴포넌트(B1)가 기억됨으로써, SW 컴포넌트(B1)에 의한 얼굴 검출 처리가 이미지 센서(IS) 내에서 실행된다. 이미지 센서(IS) 내에서 SW 컴포넌트(B1)의 처리가 실현됨으로써, 개인 특정 정보가 이미지 센서(IS) 밖으로 출 력되지 않기 때문에, 프라이버시의 보호 및 시큐리티의 향상이 견고하게 도모된다. 카메라(3A)의 메모리부에 SW 컴포넌트(B2)가 기억됨으로써, SW 컴포넌트(B2)에 의한 속성 정보 추출 처리가 카메라(3A)의 처리부에 의해 실현된다. 포그 서버의 기억부에 SW 컴포넌트(B3)가 기억됨으로써, SW 컴포넌트(B3)에 의한 집계 처리가 포그 서버 의 처리부에 의해 실현된다. 포그 서버에는, 복수의 카메라가 접속되어 있기 때문에, 각 카메라로부터의 출력 데이터의 수집이 용 이하다. 따라서, 인원수의 카운트 집계를 포그 서버에서 행하는 것은 적합하다.클라우드측 정보 처리 장치의 기억부에 SW 컴포넌트(B4)가 기억됨으로써, SW 컴포넌트(B4)에 의한 가시화 처리가 클라우드측 정보 처리 장치의 처리부에 의해 실현된다. 유저는, 애플리케이션 이용자 단말기(2B)를 사용하여 클라우드측 정보 처리 장치에 의한 가시화 처리의 결과를 열람하는 것이 가능해진다. 또한, 클라우드 서버가 또 다른 SW 컴포넌트를 갖도록 구성하고, AI 애플리케이션(A1)의 결과 정보(본 실시 형태에서는 SW 컴포넌트(B4)에 의한 가시화 처리의 결과 등의 출력 데이터)가 당해 다른 SW 컴포넌트에 입력되 도록 해도 된다. 즉, 각 SW 컴포넌트의 출력 데이터가 1개 또는 복수의 다른 SW 컴포넌트에 적절하게 출력되어 해당 다른 SW 컴포넌트 각각에서 다양한 처리가 실행됨으로써, 유저에 대해서 다양한 분석 결과를 제시하는 것 등이 가능하게 되고, 또한, 유저에게 제시하는 정보를 다종다양하게 조합해서 커스터마이즈하는 것이 가능해진 다. 또한, 도 16에 나타내는 예는, 각 기억부(메모리부)에 각 SW 컴포넌트를 평등하게 할당한 예라고도 할 수 있다. 즉, 이와 같이 각 SW 컴포넌트를 전개함으로써, 처리 부담이 일부 장치에 치우쳐 버리는 것을 방지할 수 있다. 바꾸어 말하면, 처리 부담의 균일화를 도모하는 것을 유저가 설정하고 있는 경우에 도 16에 도시하는 바와 같이 전개처의 장치를 결정해도 된다. 유저에 의한 요구는 다양하게 생각할 수 있다. 예를 들어, 비용을 억제하는 것을 중시하고자 하는 경우나, 실 행 속도를 중시하고자 하는 경우나, 프라이버시의 보호를 중시하고자 하는 경우 등이 있다. 유저의 요구마다 각 SW 컴포넌트의 전개처의 장치가 다른 예를 도 17에 나타낸다. 유저의 요구가 비용 최적일 경우에는, 예를 들어 가능한 한 많은 SW 컴포넌트를 에지측 정보 처리 장치에 전개 함으로써, 클라우드 정보 처리 장치가 제공하는 기능을 계속적으로 사용함으로 인한 애플리케이션 사용료를 억 제하는 것을 생각할 수 있다. 도 17에 나타내는 예는, 가시화 처리만을 클라우드측 정보 처리 장치에서 행하기로 하고, 그 이외의 처리에 대 해서는 에지측 정보 처리 장치에서 행하기로 한 예이다. 구체적으로는, SW 컴포넌트(B1, B2)에 의한 얼굴 검출 처리와 속성 정보 추출 처리가 카메라(3A)에서 실행되고, SW 컴포넌트(B3)에 의한 집계 처리가 포그 서버에서 실행된다. 또한, 예를 들어 SW 컴포넌트(B4)가 단순한 가시화 처리(예를 들어, 클라우드측 정보 처리 장치가 갖는 표시 장 치에 표시시키기 위한 처리) 등을 행하는 경우에는, SW 컴포넌트(B4)의 전개처의 장치는 클라우드측 정보 처리 장치로 되기 때문에 이미 전개 완료일 가능성이 높으며, 그 경우에는 클라우드측 정보 처리 장치에서의 전개 처 리를 다시 실행하지 않아도 된다. 유저의 요구가 속도 최적일 경우에는, 단위 시간당 연산량이 많은 고성능의 장치에서 처리를 실행하기 위해 고 성능 장치가 전개처의 장치로서 선택되기 쉬워진다. 도 17에 나타내는 예에서는, SW 컴포넌트(B1)만이 에지측 정보 처리 장치인 포그 서버에서 실행된다. 이것 은, SW 컴포넌트(B1)의 입력 데이터가 화상 데이터이기 때문에, 에지측 정보 처리 장치와 클라우드측 정보 처리 장치의 사이의 통신 속도를 고려해서 SW 컴포넌트(B1)에 의한 얼굴 검출 처리를 에지측 정보 처리 장치에서 끝 내는 편이 좋다고 판단된 것에 의한 것이다. 또한, 에지측 정보 처리 장치 중에서 포그 서버가 전개처의 장치로서 선택된 이유는, 카메라(3A)의 처리 능 력보다 포그 서버의 처리 능력쪽이 높기 때문이다. 카메라(3A)와 포그 서버의 사이의 통신 속도가 느려, 화상 데이터를 포그 서버에 송신함으로써 처리 시간 이 길어지는 경우에는, SW 컴포넌트(B1)의 전개처의 장치로서 카메라(3A)나 이미지 센서(IS)를 선택해도 된다. 유저의 요구가 프라이버시의 보호일 경우에는, 개인을 특정 가능한 개인 특정 정보, 예를 들어 내점객의 얼굴을 인식할 수 있는 촬상 화상 데이터가 클라우드측 정보 처리 장치에 송신되지 않도록 각 SW 컴포넌트의 전개처의 장치를 선택한다. 보다 적합하게는, 촬상 화상 데이터는 이미지 센서(IS) 내에서 생성 가능한데, 촬상 화상 데이터가 이미지 센서 (IS) 밖으로 출력되지 않도록 함으로써 보다 견고한 프라이버시의 보호를 도모하는 것이 가능해진다. 도 17에 나타내는 예에서는, SW 컴포넌트(B1, B2)에 의한 얼굴 검출 처리와 속성 정보 추출 처리를 카메라(3A) 의 이미지 센서(IS) 내에서 실행하도록 결정한 예이다. 또한, 각 SW 컴포넌트의 전개처의 장치는, 장치의 접속 양태(네트워크 토폴러지)를 고려해서 결정해도 된다. 예를 들어, SW 컴포넌트(B3)는, 인원수 카운트의 집계 처리이며, 각종 카메라에서 촬상된 촬상 화상 데이터 에 기초하여 검출된 내점객과 그 속성 정보를 사용하는 SW 컴포넌트이다. 따라서, SW 컴포넌트(B3)를 카메라 (3A)나 이미지 센서(IS)에 전개해 버리면, 각종 장치로부터 추출 결과를 수신하는 처리를 카메라(3A)나 이미지 센서(IS)에서 행하지 않으면 안된다. 이러한 양태를 실현하기 위해서는, 전개처의 카메라가 다른 카메라와 통신 가능하게 구성되어 있는 편이 적합하다. 그러나, 도 1에 도시하는 바와 같이, 카메라끼리는 포그 서버를 통해서 접속되어 있기 때문에, 각 장치에 서의 통신 처리에 요하는 처리 부담이 커져 버린다. 따라서, SW 컴포넌트(B3)의 전개처의 장치는, 도 17에 도시하는 바와 같이, 포그 서버나 클라우드측 정보 처 리 장치의 어느 것으로 되어도 된다. 즉, 클라우드측 정보 처리 장치를 상류측으로 하고, 카메라를 하류측 으로 한 경우에, 전단의 SW 컴포넌트로부터 후단의 SW 컴포넌트에의 데이터의 흐름이 상류로부터 하류를 향하는 방향으로 되지 않도록 SW 컴포넌트의 전개처의 장치가 결정되어도 된다. 바꾸어 말하면, 후단의 SW 컴포넌트일 수록 상류측의 장치에 전개되도록 되어도 된다. 각 SW 컴포넌트의 전개처의 장치를 결정하기 위해서 클라우드측 정보 처리 장치가 실행하는 처리의 흐름에 대해 서 일례를 도 18 및 도 19에 나타낸다. 또한, 도 18은, 앞의 도 4에서의 스텝 S9, S10 및 S11의 각 처리를 자 세하게 나타낸 것이다. 클라우드측 정보 처리 장치의 CPU는, 스텝 S101에서, 애플리케이션의 선택을 접수하는 처리를 행한다. 이 처리에 의해, 유저에 의해 선택된 교통 감시나 동선 분석이나 내점객 카운트 등의 애플리케이션이 특정된다. 클라우드측 정보 처리 장치의 CPU는, 스텝 S102에서, 선택된 애플리케이션에 따라서 AI 애플리케이션을 선 택한다. 이 처리에서는, 유저에 의해 선택된 애플리케이션에 기초할 뿐만 아니라, 애플리케이션을 실현하기 위 한 유저 환경에 기초하여 AI 애플리케이션을 선택해도 된다. 바꾸어 말하면, 유저 환경에 따라서 복수의 AI 애플리케이션 중에서 하나의 AI 애플리케이션을 선택해도 된다. 클라우드측 정보 처리 장치의 CPU는, 스텝 S103에서, AI 애플리케이션을 구축하는 SW 컴포넌트를 선택한다. 클라우드측 정보 처리 장치의 CPU는, 스텝 S104에서, SW 컴포넌트마다 전개처의 장치를 결정한다. 이 처리 는 도 19를 참조하여 다시 설명한다. 클라우드측 정보 처리 장치의 CPU는 스텝 S105에서, SW 컴포넌트의 배신 처리를 행한다. 이에 의해, 각 장치에서 배신된 SW 컴포넌트의 전개 처리가 행해진다. SW 컴포넌트마다 전개처의 장치를 결정하는 스텝 S104의 처리의 구체예를 도 19에 나타낸다. 클라우드측 정보 처리 장치의 CPU는, 스텝 S201에서, 처리 대상의 SW 컴포넌트를 하나 선택한다. 클라우드측 정보 처리 장치의 CPU는, 스텝 S202에서, SW 컴포넌트의 HW 요구 사양과 SW 요구 사양을 취득한 다(도 13 참조). 클라우드측 정보 처리 장치의 CPU는, 스텝 S203에서, 요구 사양을 충족하지 않는 장치를 제외한다. 이 처 리에서는, 에지측 정보 처리 장치와 클라우드측 정보 처리 장치 양쪽의 각 장치의 사양 정보를 취득하고, 그것 들과 요구 사양을 비교함으로써, 요구 사양을 충족하지 않는 장치를 특정해서 제외한다. 또한, 에지측 정보 처리 장치와 클라우드측 정보 처리 장치 양쪽의 각 장치의 사양 정보는, 미리 장치가 접속되 었을 때 등에 취득해 두어도 된다. 클라우드측 정보 처리 장치의 CPU는, 스텝 S204에서, 유저의 요구에 적합하지 않은 장치를 또한 제외한다. 이 처리에서는, 예를 들어 유저의 요구가 처리 속도이었을 경우에, 처리 시간이 소정 시간보다 길어지는 장치를 제외하거나, 유저의 요구가 프라이버시의 보호이었을 경우에, 개인 특정 정보를 클라우드측 정보 처리 장치에 보내지 않아도 되도록 클라우드측 정보 처리 장치를 제외하거나 한다.클라우드측 정보 처리 장치의 CPU는, 스텝 S205에서, 남은 후보의 장치로부터 하나의 장치를 전개처의 장치 로서 선택한다. 이 선택에서는, 유저의 요구에 따라서 가장 적절한 장치를 선택해도 된다. 클라우드측 정보 처리 장치의 CPU는, 스텝 S206에서, 전개처의 장치가 미결정인 SW 컴포넌트가 있는지 여부 를 판정한다. 미결정의 SW 컴포넌트가 있을 경우, 클라우드측 정보 처리 장치의 CPU는, 스텝 S201로 돌아가서, 미결정의 SW 컴포넌트를 하나 선택하여, 스텝 S202로 진행한다. 한편, 미결정의 SW 컴포넌트가 없을 경우, 즉, 모든 SW 컴포넌트에 대해서 전개처의 장치의 결정을 종료했을 경 우, 클라우드측 정보 처리 장치의 CPU는, 도 19에 나타내는 일련의 처리를 종료한다. <3. 제2 실시 형태> 제2 실시 형태는, 처리 내용이 동일하게 된 복수의 SW 컴포넌트 중에서 상황에 따라 적절한 SW 컴포넌트를 선택 하는 것이다. 이에 의해, AI 모델의 선택도 행해진다. 도 20은, 얼굴 검출을 행하는 SW 컴포넌트(B1)로서, 3종류의 SW 컴포넌트(B1-1, B1-2, B1-3)가 준비되어 있는 것을 나타내고 있다. 구체적으로, SW 컴포넌트(B1-1)와 SW 컴포넌트(B1-2)는, HW 요구 사양이나 SW 요구 사양이 다르다. 또한, SW 컴포넌트(B1-3)는, SW 컴포넌트(B1-1, B1-2)와 비교해서 성능이 높지만 이용 비용이 높다. 클라우드측 정보 처리 장치에서는, AI 애플리케이션(A1)으로서의 기능을 실현하기 위한 SW 컴포넌트의 하나인 SW 컴포넌트(B1)로서, SW 컴포넌트(B1-1, B1-2, B1-3) 중에서 하나를 선택한다. 마찬가지로, SW 컴포넌트(B2)나 SW 컴포넌트(B3)에 대해서도 복수 종류가 준비되어 있을 경우에는, 그 중에서 각각 하나의 SW 컴포넌트를 선택한다. 또한, 카메라마다 다른 SW 컴포넌트를 선택해도 된다. 구체적인 예를 도 21에 나타낸다. 포그 서버에 접속되어 있는 카메라(3A)와 카메라(3B)는, HW 사양이나 SW 사양이 다르게 되어 있다. 그리고 카메라(3A)는, SW 컴포넌트(B1-1)의 HW 요구 사양과 SW 요구 사양 양쪽을 충족하고, SW 컴포넌트(B1-2)의 HW 요 구 사양과 SW 요구 사양의 적어도 일부를 충족하지 않는 것으로 한다. 마찬가지로, 카메라(3B)는, SW 컴포넌트(B1-1)의 HW 요구 사양과 SW 요구 사양의 적어도 일부를 충족하지 않고, SW 컴포넌트(B1-2)의 HW 요구 사양과 SW 요구 사양 양쪽을 충족하는 것으로 한다. 이때, 클라우드측 정보 처리 장치는, 카메라(3A)에 SW 컴포넌트(B1-1)를 전개하는 것을 결정하고, 카메라(3B)에 SW 컴포넌트(B1-2)를 전개하는 것을 결정한다. 이와 같이 하여 유저 환경이 갖는 각 장치의 사양 등에 따라서 적절한 SW 컴포넌트가 전개됨으로써, 유저 환경 에 있어서 AI 애플리케이션을 적합하게 실시하는 것이 가능해진다. 전개하는 SW 컴포넌트와 전개처의 장치를 결정하기 위해서 클라우드측 정보 처리 장치가 실행하는 처리의 흐름 에 대해서, 도 22 및 도 23에 나타낸다. 또한, 상술한 도 18 및 도 19와 마찬가지의 처리에 대해서는 동일한 스텝 번호를 부여하고 적절하게 설명을 생 략한다. 처리의 흐름을 설명함에 있어서, 앞의 SW 컴포넌트(B1-1, B1-2, B1-3)를 「SW 컴포넌트군」이라고 호칭한다. 즉, SW 컴포넌트군은, 처리 내용이 동일(예를 들어 얼굴 인식)하게 된 SW 컴포넌트를 하나 이상 포함하고 있다. 클라우드측 정보 처리 장치의 CPU는, 도 22의 스텝 S101에서, 애플리케이션의 선택을 접수하는 처리를 행함 으로써 애플리케이션을 특정한다. 클라우드측 정보 처리 장치의 CPU는, 스텝 S102에서, 선택된 애플리케이션에 따라서 AI 애플리케이션을 선 택한다. 클라우드측 정보 처리 장치의 CPU는, 스텝 S106에서, 전개처의 장치와 전개하는 SW 컴포넌트를 결정하는 처 리를 행하고, 스텝 S105에서, SW 컴포넌트의 배신 처리를 행한다.스텝 S106의 전개처의 장치와 전개하는 SW 컴포넌트를 결정하는 처리에 대해서, 구체적으로 도 23에 나타낸다. 클라우드측 정보 처리 장치의 CPU는, 스텝 S210에서, SW 컴포넌트군을 하나 선택한다. 클라우드측 정보 처리 장치의 CPU는, 스텝 S211에서, 선택된 SW 컴포넌트군은 복수의 SW 컴포넌트를 포함하 고 있는지 여부를 판정한다. 복수의 SW 컴포넌트를 포함하고 있다고 판정한 경우, 클라우드측 정보 처리 장치의 CPU는, 스텝 S212에서, 유저의 요구에 따라 SW 컴포넌트를 하나 선택한다. 예를 들어, 유저의 요구가 처리 속도이었을 경우에 처리 속도가 빠른 하나의 SW 컴포넌트를 선택한다. 여기서 처리 속도가 빠른 SW 컴포넌트란, SW 컴포넌트군에 포함되는 각 SW 컴포넌트의 평균적인 처리 속도보다 높은 처 리 속도로 된 SW 컴포넌트를 선택해도 되고, 가장 처리 속도가 높은 SW 컴포넌트를 선택해도 된다. 또한, 유저의 요구가 비용 최적일 경우에는, 이용 비용이 싼 SW 컴포넌트를 선택한다. 예를 들어, 도 20에 나 타내는 예라면, SW 컴포넌트(B1-1, B1-2)의 어느 것을 선택한다. 이때, 상술한 도입 비용을 또한 고려해서 SW 컴포넌트를 선택해도 된다. 클라우드측 정보 처리 장치의 CPU는, 스텝 S202에서, 선택된 SW 컴포넌트의 HW 요구 사양과 SW 요구 사양을 취득하고, 계속되는 스텝 S203에서, 요구 사양을 충족하지 않는 장치를 제외하는 처리를 행한다. 다음으로, 클라우드측 정보 처리 장치의 CPU는, 스텝 S213에서, 1개 이상의 장치가 후보로서 남아있는지 여 부를 판정한다. 후보의 장치가 하나도 남아있지 않을 경우에는, 클라우드측 정보 처리 장치의 CPU는 다시 스텝 S212로 돌아 가서 SW 컴포넌트를 하나 선택하고, 당해 SW 컴포넌트를 전개하는데 적절한 장치가 존재하는지 여부를 판정한다. 한편, 후보의 장치가 하나 이상 남아있을 경우에는, 클라우드측 정보 처리 장치의 CPU는 스텝 S205에서, 하 나의 장치를 전개처의 장치로서 선택하고, 스텝 S214에서 미처리의 SW 컴포넌트군이 존재하는지 여부를 판정한 다. 미처리의 SW 컴포넌트군이 존재하는 경우, 클라우드측 정보 처리 장치의 CPU는 스텝 S210으로 돌아가서, 미 처리의 SW 컴포넌트군의 하나를 선택하여, 마찬가지의 처리를 계속한다. 스텝 S211에서, 선택된 SW 컴포넌트군이 포함하는 SW 컴포넌트는 하나뿐이라고 판정한 경우, 클라우드측 정보 처리 장치의 CPU는, 스텝 S202, S203, S204를 각각 실행하고, 스텝 S205로 진행한다. 이에 의해, SW 컴포넌트의 HW 요구 사양과 SW 요구 사양에 따라서 적절한 장치가 전개처의 장치로서 선택된다. 또한, 본 예에서는, 스텝 S212에서, 하나의 SW 컴포넌트를 선택하는 예를 설명하였지만, 유저의 요구를 충족시 키는 복수의 SW 컴포넌트를 선택해도 된다. 예를 들어, 유저의 요구가 처리 속도이었을 경우에, 제1 OS 상에서 동작하는 처리 속도가 빠른 SW 컴포넌트와 제2 OS 상에서 동작하는 처리 속도가 빠른 SW 컴포넌트 양쪽을 선택해도 된다. 그 경우에는, 스텝 S203에서, 요구 사양에 기초하여 당해 2개의 SW 컴포넌트 모두 전개할 수 없는 장치를 제외 한 후, 스텝 S205에서 후보로서 남은 장치 중에서 하나를 선택한다. 그리고 스텝 S205 후에, 그 장치에 전개 가능한 SW 컴포넌트를 최종적으로 하나 선택하면 된다. <4. 제3 실시 형태> 제3 실시 형태는, 전개처의 장치의 일부를 「장치군」으로서 파악하는 예이다. 예를 들어, 카메라의 메모리부와 해당 카메라가 구비하는 이미지 센서(IS)의 메모리부를 장치군 (기억부군)으로서 파악한다. 앞의 예에서는, 전개 대상의 SW 컴포넌트의 SW 요구 사양으로서 필요 메모리 사이즈를 이미지 센서(IS)가 충족 하지 못한 경우에는, 이미지 센서(IS)는 전개처의 장치의 후보에서 제외된다. 또한, 당해 이미지 센서(IS)가 탑재되어 있는 카메라가 필요 메모리 사이즈의 요구를 충족하지 못한 경우에 는, 당해 카메라는 전개처의 장치의 후보에서 제외된다.이 경우에는, 당해 SW 컴포넌트는, 포그 서버나 클라우드측 정보 처리 장치에 전개되게 된다. 이에 반해, 본 예에서는, 카메라의 메모리부와 이미지 센서(IS)의 메모리부를 장치군으로서 파악하 여, 양쪽을 합쳐서 전개 대상의 SW 컴포넌트의 SW 요구 사양을 충족하고 있는지 여부를 판정한다. 그리고 메모리부와 메모리부 양쪽을 합침으로써 SW 컴포넌트의 요구 사양을 충족할 수 있는 경우에는, 전개처의 장치로서 카메라가 선택되어도 된다. 제3 실시 형태의 다른 예로서, 복수의 카메라를 카메라군으로서 다루는 것을 생각할 수 있다. 예를 들어, 포그 서버에 접속되는 카메라군이 3대의 카메라(3A, 3B, 3C)를 포함하고 있다고 하자. 카메라(3A, 3B, 3C) 각각에 대해서, 어떤 SW 컴포넌트(C1-1)를 전개하는 것을 생각한다. 카메라(3C)가 SW 컴포 넌트의 요구 사양을 충족하지 못한 경우에는, 카메라(3C)의 HW 사양이나 SW 사양에 따라서 당초 선택하고 있었 던 SW 컴포넌트(C1-1)보다 성능이 낮은 SW 컴포넌트(C1-2) 등이 다시 선택되어, 각 카메라(3A, 3B, 3C)에 전개 되어도 된다. 그러나, 본 실시 형태에서는, 카메라(3A, 3B, 3C)를 하나의 카메라군으로서 파악하므로, 카메라(3C)의 처리 부담을 카메라(3A)나 카메라(3B)에 의해 보충할 수 있는지 여부를 고려한다. 그리고 보충할 수 있다고 판정된 경우에는, 각 카메라(3A, 3B, 3C)에 당초 선택된 SW 컴포넌트(C1-1)를 전개해도 된다. 그리고 SW 컴포넌트(C1-1)에 의한 처리를 실행할 때, 카메라(3C)에서 실행해야 하는 처리의 일부를 카메라(3A, 3B)가 대신함으로써, 카메라군으로서 성능이 높은 SW 컴포넌트(C1-1)를 사용한 분석 처리 등을 실현할 수 있다. 예를 들어, 카메라(3A, 3B, 3C)의 평균 성능이 SW 컴포넌트의 요구 사양을 상회하고 있었을 경우에 당해 카메라 (3A, 3B, 3C)를 포함하는 카메라군을 전개처의 장치로서 선택하면 된다. 구체적으로는, 제1 실시 형태에 제3 실시 형태를 적용하는 경우, 도 19에 나타내는 스텝 S203에서, 장치군의 평 균 성능이 SW 컴포넌트의 요구 사양을 충족하지 못하는 경우에, 당해 장치군을 제외하면 된다. 또한, 제2 실시 형태에 제3 실시 형태를 적용하는 경우, 도 23의 스텝 S203에서 마찬가지의 처리를 행하면 된다. <5. 기타> 상술한 바와 같이, AI 애플리케이션의 SW 컴포넌트 및 AI 모델이 전개된 후, 서비스의 제공자나 이용자(유저)의 조작을 트리거로 해서 AI 모델의 재학습과 각 카메라 등에 전개된 AI 모델(이후, 「에지측 AI 모델」이라고 기재)이나 AI 애플리케이션의 갱신을 행할 때의 처리의 흐름에 대해서, 구체적으로 도 24를 참조하여 설명한다. 또한, 도 24는 복수의 카메라 중 1대의 카메라에 주목해서 기재한 것이다. 또한, 이하의 설명에서 갱신 대상이 된 에지측 AI 모델은, 일례로서, 카메라가 구비하는 이미지 센서(IS)에 전개되어 있는 것이지만, 물 론, 에지측 AI 모델은 카메라에서의 이미지 센서(IS) 밖에 전개되어 있는 것이어도 된다. 우선, 처리 스텝 PS1에서, 서비스의 제공자나 이용자에 의한 AI 모델의 재학습 지시가 행해진다. 이 지시는, 클라우드측 정보 처리 장치가 구비하는 API(Application Programming Interface) 모듈이 구비하는 API 기능을 이용하여 행해진다. 또한, 당해 지시에서는, 학습에 사용하는 화상량(예를 들어 매수)이 지정된다. 이후, 학 습에 사용하는 화상량을 「소정 매수」라고도 기재한다. API 모듈은, 당해 지시를 받아, 처리 스텝 PS2에서 Hub(도 5에 나타낸 것과 마찬가지의 것)에 대해서 재학습의 리퀘스트와 화상량의 정보를 송신한다. Hub는, 처리 스텝 PS3에서, 에지측 정보 처리 장치로서의 카메라에 대해서 업데이트 통지와 화상량의 정보를 송신한다. 카메라는, 촬영을 행함으로써 얻어진 촬상 화상 데이터를 처리 스텝 PS4에서 스토리지군의 화상 DB(Database)에 송신한다. 이 촬영 처리와 송신 처리는, 재학습에 필요한 소정 매수에 달성할 때까지 행해진다. 또한, 카메라는, 촬상 화상 데이터에 대한 추론 처리를 행함으로써 추론 결과를 얻었을 경우에는, 처리 스텝 PS4에서 촬상 화상 데이터의 메타데이터로서 추론 결과를 화상 DB에 기억해도 된다.카메라에서의 추론 결과가 메타데이터로서 화상 DB에 기억됨으로써, 클라우드측에서 실행되는 AI 모델의 재 학습에 필요한 데이터를 엄선할 수 있다. 구체적으로는, 카메라에서의 추론 결과와 클라우드측 정보 처리 장치에서 윤택한 컴퓨터 자원을 사용하여 실행되는 추론의 결과가 상이한 화상 데이터만을 사용하여 재학습을 행할 수 있다. 따라서, 재학습에 요하는 시간을 단축하는 것이 가능해진다. 소정 매수의 촬영과 송신을 종료한 후, 카메라는 처리 스텝 PS5에서, 소정 매수의 촬상 화상 데이터의 송신 이 완료된 것을 Hub에 통지한다. Hub는, 해당 통지를 받아, 처리 스텝 PS6에서, 재학습용 데이터의 준비가 완료된 것을 오케스트레이션 툴에 통 지한다. 오케스트레이션 툴은, 처리 스텝 PS7에서, 라벨링 처리의 실행 지시를 라벨링 모듈에 대해서 송신한다. 라벨링 모듈은, 라벨링 처리의 대상이 된 화상 데이터를 화상 DB로부터 취득해서(처리 스텝 PS8), 라벨링 처리 를 행한다. 여기서 말하는 라벨링 처리란, 상술한 클래스 식별을 행하는 처리이어도 되고, 화상의 피사체에 관한 성별이나 연령을 추정해서 라벨을 부여하는 처리이어도 되고, 피사체에 관한 포즈를 추정해서 라벨을 부여하는 처리이어 도 되고, 피사체의 행동을 추정해서 라벨을 부여하는 처리이어도 된다. 라벨링 처리는, 수동으로 행해져도 되고, 자동으로 행해져도 된다. 또한, 라벨링 처리는 클라우드측의 정보 처 리 장치에서 완결해도 되고, 다른 서버 장치가 제공하는 서비스를 이용함으로써 실현되어도 된다. 라벨링 처리를 종료한 라벨링 모듈은, 처리 스텝 PS9에서, 라벨이 달린 결과 정보를 데이터 세트 DB에 기억한다. 여기서 데이터 세트 DB에 기억되는 정보는, 라벨 정보와 화상 데이터의 조가 되어도 되고, 화상 데 이터 그 자체 대신에 화상 데이터를 특정하기 위한 화상 ID(Identification) 정보가 되어도 된다. 라벨이 달린 결과 정보가 기억된 것을 검출한 스토리지 관리부는, 처리 스텝 PS10에서 오케스트레이션 툴에 대 한 통지를 행한다. 해당 통지를 수신한 오케스트레이션 툴은, 소정 매수의 화상 데이터에 대한 라벨링 처리가 종료된 것을 확인하 고, 처리 스텝 PS11에서, 재학습 모듈에 대한 재학습 지시를 송신한다. 재학습 지시를 수신한 재학습 모듈은, 처리 스텝 PS12에서 데이터 세트 DB로부터 학습에 사용하는 데이터 세트 를 취득함과 함께, 처리 스텝 PS13에서 학습 완료된 AI 모델 DB로부터 업데이트 대상의 AI 모델을 취득한다. 재학습 모듈은, 취득한 데이터 세트와 AI 모델을 사용하여 AI 모델의 재학습을 행한다. 이와 같이 하여 얻어진 업데이트 완료된 AI 모델은, 처리 스텝 PS14에 서 다시 학습 완료된 AI 모델 DB에 기억된다. 업데이트 완료된 AI 모델이 기억된 것을 검출한 스토리지 관리부는, 처리 스텝 PS15에서 오케스트레이션 툴에 대한 통지를 행한다. 해당 통지를 수신한 오케스트레이션 툴은, 처리 스텝 S16에서, AI 모델의 변환 지시를 변환 모듈에 대해서 송신 한다. 변환 지시를 수신한 변환 모듈은, 처리 스텝 PS17에서 학습 완료된 AI 모델 DB로부터 업데이트 완료된 AI 모델 을 취득하여, AI 모델의 변환 처리를 행한다. 해당 변환 처리에서는, 전개처의 기기인 카메라의 스펙 정보 등에 맞추어서 변환하는 처리를 행한다. 이 처 리에서는, AI 모델의 성능을 가능한 한 떨어뜨리지 않도록 다운사이징을 행함과 함께, 카메라 상에서 동작 가능하도록 파일 형식의 변환 등이 행해진다. 변환 모듈에 의해 변환 완료된 AI 모델은 상술한 에지측 AI 모델로 된다. 이 변환 완료된 AI 모델은, 처리 스 텝 PS18에서 변환 완료된 AI 모델 DB에 기억된다. 변환 완료된 AI 모델이 기억된 것을 검출한 스토리지 관리부는, 처리 스텝 PS19에서 오케스트레이션 툴에 대한 통지를 행한다. 해당 통지를 수신한 오케스트레이션 툴은, 처리 스텝 PS20에서, AI 모델의 업데이트를 실행시키기 위한 통지를 Hub에 대해서 송신한다. 이 통지에는, 업데이트에 사용하는 AI 모델이 기억되어 있는 장소를 특정하기 위한 정 보를 포함하고 있다.해당 통지를 수신한 Hub는, 카메라에 대해서 AI 모델의 업데이트 지시를 송신한다. 업데이트 지시에 대해서 도, AI 모델이 기억되어 있는 장소를 특정하기 위한 정보가 포함되어 있다. 카메라는, 처리 스텝 PS22에서, 변환 완료된 AI 모델 DB로부터 대상의 변환 완료된 AI 모델을 취득해서 전개 하는 처리를 행한다. 이에 의해, 카메라의 이미지 센서(IS)에서 이용되는 AI 모델의 갱신이 행해진다. AI 모델을 전개함으로써 AI 모델의 갱신을 종료한 카메라는, 처리 스텝 PS23에서 Hub에 대해서 갱신 완료 통 지를 송신한다. 해당 통지를 수신한 Hub는, 처리 스텝 PS24에서 오케스트레이션 툴에 대해서 카메라의 AI 모델 갱신 처리가 완료된 것을 통지한다. 또한, 여기서는 카메라의 이미지 센서(IS) 내(예를 들어, 도 7에 나타내는 메모리부)에 AI 모델이 전개 되어 이용되는 예에 대해서 설명하였지만, 카메라에서의 이미지 센서 밖(예를 들어, 도 7의 메모리부)이 나 포그 서버 내(도 14의 기억부)에 AI 모델이 전개되어 이용된 경우라도, 마찬가지로 AI 모델의 갱신을 행할 수 있다. 그 경우에는, AI 모델이 전개되었을 때 당해 AI 모델이 전개된 장치(장소)를 클라우드측의 스토리지 관리부 등 에 기억해 두고, Hub는, 스토리지 관리부로부터 AI 모델이 전개된 장치(장소)를 읽어내고, AI 모델이 전개된 장 치에 대해서 AI 모델의 업데이트 지시를 송신한다. 업데이트 지시를 받은 장치는, 처리 스텝 PS22에서, 변환 완료된 AI 모델 DB로부터 대상의 변환 완료된 AI 모델 을 취득해서 전개하는 처리를 행한다. 이에 의해, 업데이트 지시를 받은 장치의 AI 모델의 갱신이 행해진다. 또한, AI 모델의 갱신만을 행하는 경우는, 여기까지의 처리로 완결한다. AI 모델에 더하여 AI 모델을 이용하는 AI 애플리케이션의 갱신을 행하는 경우에는, 후술하는 처리가 더 실행된 다. 구체적으로, 오케스트레이션 툴은 처리 스텝 PS25에서, 전개 제어 모듈에 대해서 업데이트된 펌웨어 등의 AI 애 플리케이션의 다운로드 지시를 송신한다. 전개 제어 모듈은, 처리 스텝 PS26에서, Hub에 대해서 AI 애플리케이션의 전개 지시를 송신한다. 이 지시에는, 업데이트된 AI 애플리케이션이 기억되어 있는 장소를 특정하기 위한 정보가 포함되어 있다. Hub는, 처리 스텝 PS27에서, 당해 전개 지시를 카메라에 대해서 송신한다. 카메라는, 처리 스텝 PS28에서, 전개 제어 모듈의 컨테이너 DB로부터 업데이트된 AI 애플리케이션을 다운로 드해서 전개한다. 또한, 상기 설명에서는, 카메라의 이미지 센서(IS) 상에서 동작하는 AI 모델의 갱신과 카메라에서의 이미 지 센서(IS) 밖에서 동작하는 AI 애플리케이션의 갱신을 시퀀셜하게 행하는 예를 설명하였다. 또한, 여기서는 설명의 간단화를 위해서, AI 애플리케이션으로서 설명하였지만, 상술한 바와 같이, AI 애플리케 이션은 SW 컴포넌트(B1, B2, B3, …Bn) 등 복수의 SW 컴포넌트로 정의되어 있고, AI 애플리케이션이 전개되었을 때, 각 SW 컴포넌트가 어디에 전개되었는지를 클라우드측의 스토리지 관리부 등에 기억해 두고, Hub는, 처리 스 텝 PS27을 처리할 때, 스토리지 관리부로부터 각 SW 컴포넌트가 전개된 장치(장소)를 읽어내고, 그 전개된 장치 에 대해서, 전개 지시를 송신하도록 되어 있다. 전개 지시를 받은 장치는, 처리 스텝 PS28에서, 전개 제어 모 듈의 컨테이너 DB로부터 업데이트된 SW 컴포넌트를 다운로드해서 전개한다. 또한, 여기서 언급하는 AI 애플리케이션이란, AI 모델 이외의 SW 컴포넌트이다. 또한, AI 모델과 AI 애플리케이션 양쪽이 하나의 장치에서 동작한다고 되어 있었을 경우에는, AI 모델과 AI 애 플리케이션 양쪽을 하나의 컨테이너로서 통합해서 갱신해도 된다. 그 경우에는, AI 모델의 갱신과 AI 애플리케 이션의 갱신이 시퀀셜이 아니라 동시에 행해져도 된다. 그리고 처리 스텝 PS25, PS26, PS27, PS28의 각 처리를 실행함으로써, 실현 가능하다. 예를 들어, 카메라의 이미지 센서(IS)에 AI 모델과 AI 애플리케이션 양쪽의 컨테이너를 전개하는 것이 가능 한 경우, 상술한 바와 같이 처리 스텝 PS25, PS26, PS27, PS28의 각 처리를 실행함으로써, AI 모델이나 AI 애플 리케이션의 갱신을 행할 수 있다.상술한 처리를 행함으로써, 유저의 사용 환경에서 촬상된 촬상 화상 데이터를 사용하여 AI 모델의 재학습이 행 해진다. 따라서, 유저의 사용 환경에서 고정밀도의 인식 결과를 출력할 수 있는 에지측 AI 모델을 생성할 수 있다. 또한, 점내의 레이아웃을 변경한 경우나 카메라의 설치 장소를 변경한 경우 등, 유저의 사용 환경이 변화하 였다고 해도, 그 때마다 적절하게 AI 모델의 재학습을 행할 수 있기 때문에, AI 모델에 의한 인식 정밀도를 저 하시키지 않고 유지하는 것이 가능해진다. 또한, 상술한 각 처리는, AI 모델의 재학습 시뿐만 아니라, 유저의 사용 환경 하에서 시스템을 처음으로 가동시 킬 때 실행해도 된다. <6. 마켓 플레이스의 화면예> 마켓 플레이스에 관해서 유저에게 제시되는 화면의 일례에 대해서, 각 도면을 참조하여 설명한다. 도 25는 로그인 화면 G1의 일례를 나타낸 것이다. 로그인 화면 G1에는, 유저 ID(로그인 ID)를 입력하기 위한 ID 입력란과, 패스워드를 입력하기 위한 패스워 드 입력란이 마련되어 있다. 패스워드 입력란의 하방에는, 로그인을 행하기 위한 로그인 버튼과, 로그인을 중지하기 위한 캔슬 버튼 이 배치되어 있다. 또한, 또한 그 하방에는, 패스워드를 잊은 유저용 페이지로 천이하기 위한 조작자나, 신규로 유저 등록을 행하 기 위한 페이지로 천이하기 위한 조작자 등이 적절하게 배치되어 있다. 적절한 유저 ID와 패스워드를 입력한 후에 로그인 버튼을 누르면, 유저 고유의 페이지로 천이하는 처리가 클라우드 서버 및 유저 단말기 각각에서 실행된다. 도 26은, 예를 들어 애플리케이션 개발자 단말기(2A)를 이용하는 AI 애플리케이션 개발자나, AI 모델 개발자 단 말기(2C)를 이용하는 AI 모델 개발자에게 제시되는 화면의 일례이다. 각 개발자는, 개발을 위해서 학습용 데이터 세트나 AI 모델이나 AI 애플리케이션을 마켓 플레이스를 통해서 구 입하는 것이 가능하게 되어 있다. 또한, 자신이 개발한 AI 애플리케이션이나 AI 모델을 마켓 플레이스에 등록 하는 것이 가능하게 되어 있다. 도 26에 나타내는 개발자용 화면 G2에는, 구입 가능한 학습용 데이터 세트나 AI 모델이나 AI 애플리케이션 등 (이후, 통합해서 「데이터」라고 기재)이 좌측에 표시되어 있다. 또한, 도시하고 있지 않지만, 학습용 데이터 세트의 구입 시에, 학습용 데이터 세트의 화상을 디스플레이 상에 표시시키고, 마우스 등의 입력 장치를 사용하여 화상의 원하는 부분만을 프레임으로 둘러싸서, 이름을 입력하는 것만으로, 학습의 준비를 할 수 있다. 예를 들어, 고양이의 화상으로 AI 학습을 행하고자 하는 경우, 화상 상의 고양이의 부분만을 프레임으로 둘러쌈 과 함께, 텍스트 입력으로서 「고양이」라고 입력함으로써, 고양이의 애노테이션이 부가된 화상을 AI 학습용으 로 준비할 수 있다. 또한, 원하는 데이터를 발견하기 쉽도록, 「교통 감시」, 「동선 분석」, 「내점객 카운트」와 같은 목적을 선 택 가능하게 되어 있어도 된다. 즉, 선택된 목적에 적합한 데이터만이 표시되는 표시 처리가 클라우드 서버 및 유저 단말기 각각에서 실행된다. 또한, 개발자용 화면 G2에서는, 각 데이터의 구입 가격이 표시되어 있어도 된다. 또한, 개발자용 화면 G2의 우측에는, 개발자가 수집 또는 작성한 학습용 데이터 세트나, 개발자가 개발한 AI 모 델이나 AI 애플리케이션을 등록하기 위한 입력란이 마련되어 있다. 각 데이터마다, 명칭이나 데이터의 보존 장소를 입력하기 위한 입력란이 마련되어 있다. 또한, AI 모델에 대해서는, 리트레인의 필요/불필요를 설정하기 위한 체크 박스가 마련되어 있다. 또한, 등록 대상의 데이터를 구입할 때 필요한 가격을 설정 가능한 가격 설정란(도면 중에서는 입력란으로 서 기재) 등이 마련되어 있어도 된다.또한, 개발자용 화면 G2의 상부에는, 유저 정보의 일부로서 유저명이나 최종 로그인 날짜 등이 표시되어 있다. 또한, 이외에도, 유저가 데이터 구입 시에 사용 가능한 통화량이나 포인트수 등이 표시되어 있어도 된다. 도 27은, 예를 들어 자신이 관리하는 에지측의 정보 처리 장치로서의 카메라에 AI 애플리케이션이나 AI 모델 을 전개함으로써, 각종 분석 등을 행하는 유저(상술한 애플리케이션 이용 유저)에게 제시되는 이용자용 화면 G3 의 일례이다. 유저는, 마켓 플레이스를 통해서 감시 대상의 공간에 배치하는 카메라를 구입 가능하게 되어 있다. 따라서, 이용자용 화면 G3의 좌측에는, 카메라에 탑재되는 이미지 센서(IS)의 종류나 성능, 그리고 카메라의 성능 등을 선택 가능한 라디오 버튼이 배치되어 있다. 또한, 유저는, 마켓 플레이스를 통해서 포그 서버로서의 정보 처리 장치를 구입 가능하게 되어 있다. 따라 서, 이용자용 화면 G3의 좌측에는, 포그 서버의 각 성능을 선택하기 위한 라디오 버튼이 배치되어 있다. 또한, 이미 포그 서버를 갖고 있는 유저는 포그 서버의 성능 정보를 여기에 입력함으로써, 포그 서버 의 성능을 등록할 수 있다. 유저는, 자신이 경영하는 점포 등의 임의의 장소에 구입한 카메라(혹은, 마켓 플레이스를 통하지 않고 구입 한 카메라이어도 됨)를 설치함으로써 원하는 기능을 실현하는데, 마켓 플레이스에서는, 각 카메라의 기능 을 최대한 발휘시키기 위해서, 카메라의 설치 장소에 관한 정보를 등록하는 것이 가능하게 되어 있다. 이용자용 화면 G3의 우측에는, 카메라가 설치되는 환경에 관한 환경 정보를 선택 가능한 라디오 버튼이 배치되어 있다. 유저는, 카메라가 설치되는 환경에 관한 환경 정보를 적절하게 선택함으로써, 상술한 최적 의 촬상 설정이 대상의 카메라에 설정된다. 또한, 카메라를 구입함과 함께 해당 구입 예정인 카메라의 설치 장소가 정해져 있는 경우에는, 이용자용 화면 G3의 좌측의 각 항목과 우측의 각 항목을 선택함으로써, 설치 예정 장소에 따라 최적의 촬상 설정이 미리 설정된 카메라를 구입할 수 있다. 이용자용 화면 G3에는 실행 버튼이 마련되어 있다. 실행 버튼을 누름으로써, 구입에 관한 확인을 행하 는 확인 화면이나, 환경 정보의 설정을 확인하기 위한 확인 화면으로 천이한다. 이에 의해, 유저는, 원하는 카 메라나 포그 서버를 구입하는 것이나, 카메라에 관한 환경 정보의 설정을 행하는 것이 가능해진다. 마켓 플레이스에서는, 카메라의 설치 장소를 변경했을 때를 위해서, 각 카메라의 환경 정보를 변경하는 것이 가능하게 되어 있다. 도시하지 않은 변경 화면에서 카메라의 설치 장소에 관한 환경 정보를 다시 입력 함으로써, 카메라에 최적의 촬상 설정을 재설정하는 것이 가능해진다. <7. 정리> 상술한 각 예에서 설명한 바와 같이, 클라우드측 정보 처리 장치(클라우드 서버나 관리 서버)는, 애플리 케이션(예를 들어 AI 애플리케이션)에 관한 유저 요구와, 애플리케이션을 구성하는 소프트웨어 컴포넌트(SW 컴 포넌트)의 요구 사양에 따라, SW 컴포넌트마다 실행 주체가 되는 대상(장치 등)을 결정하는 결정 처리부(카메라 서비스 기능(F5))를 구비하고 있다. 즉, 장치의 성능 등뿐만 아니라, 애플리케이션에 대한 유저의 요구를 가미해서 소프트웨어 컴포넌트의 실행 주 체가 되는 대상(전개처의 장치 등)이 결정된다. 따라서, 성능적으로 SW 컴포넌트의 실행 주체가 되는 대상으로 될 수 없는 장치가 제외될 뿐만 아니라, 유저의 요구에 대해서 부적절한 장치에 대해서도 제외된 뒤에 실행 주체가 되는 대상이 결정된다. 이에 의해, 유저의 요구에 따라서 애플리케이션이 적절한 성능을 발휘하도록 각 SW 컴포넌트가 전개된다. 또한 SW 컴포넌트의 요구 사양과 실행 주체가 되는 대상의 후보 사양을 비교함으로써 실행 주체가 되는 대상을 결정할 수 있기 때문에, 애플리케이션을 실행하기 위한 시뮬레이션 환경을 구축해서 사전에 시뮬레이션을 행하 지 않아도 되어, 처리 부담의 경감이나 전개를 종료할 때까지의 시간 단축을 도모할 수 있다. 또한, 유저에게 선택되는 애플리케이션으로서는, 상술한 각 예 이외에도, 「소비자 행동 파악, 분석」, 「결함 물품 검지」, 「이용자수 카운트」, 「이용자수 예측」, 「이용자 트래킹」, 「혼잡 검출」, 「혼잡 분석」, 「 위험 찰지」, 「바코드 리딩」, 「위험 지역에 대한 침입자 검출」, 「부적절한 위험물 취급 방법의 검출」, 「 헬멧·마스크 착용 검출」, 「통행인 카운트」, 「행렬 검출」 등, 다양하게 생각할 수 있다.상술한 바와 같이, 애플리케이션은 복수의 소프트웨어 컴포넌트(SW 컴포넌트)에 의해 구성되며, 결정 처리부(카 메라 서비스 기능(F5))는, 복수의 소프트웨어 컴포넌트에 대해서 복수의 대상을 실행 주체가 되는 대상으로서 결정해도 된다. 이에 의해, 애플리케이션을 실현하는 복수의 SW 컴포넌트가 하나의 장치에 전개되는 것이 방지된다. 따라서, 복수의 장치에서의 분산 처리에 의해 애플리케이션을 실현할 수 있기 때문에, 각 장치의 처리 부담의 경감을 도모할 수 있다. 또한, SW 컴포넌트가 분산되어 전개되기 때문에, 장치가 고장났을 때의 영향을 작게 할 수 있어, 내고장성을 높일 수 있다. 도 13 등을 참조하여 설명한 바와 같이, 소프트웨어 컴포넌트(SW 컴포넌트)의 요구 사양은, 개인 특정이 가능한 정보인 개인 특정 정보가 소프트웨어 컴포넌트에 대한 입력 데이터에 포함되어 있는지 여부를 나타내는 정보가 포함되어 있어도 된다. 이에 의해, 개인 특정 정보를 입력 데이터에 포함하는 SW 컴포넌트인지 여부를 고려해서 SW 컴포넌트의 배치를 결정할 수 있다. 따라서, 프라이버시의 보호를 도모할 수 있도록 SW 컴포넌트의 실행 주체가 되는 대상을 결정 할 수 있다. 도 16 등을 참조하여 설명한 바와 같이, 실행 주체가 되는 대상의 후보에 에지측 정보 처리 장치(이미지 센서 (IS), 카메라, 포그 서버)와 클라우드측 정보 처리 장치(클라우드 서버, 관리 서버)가 포함되어 있 어도 된다. 이에 의해, 에지측 정보 처리 장치로부터 클라우드측 정보 처리 장치에 걸쳐서 각 SW 컴포넌트를 넓게 전개할 수 있다. 따라서, 처리의 분산을 보다 도모할 수 있다. 도 16 등을 참조하여 설명한 바와 같이, 실행 주체가 되는 대상의 후보에 에지측 정보 처리 장치(이미지 센서 (IS), 카메라, 포그 서버)와 클라우드측 정보 처리 장치(클라우드 서버, 관리 서버)가 포함되고, 결정 처리부(카메라 서비스 기능(F5))는, 입력 데이터에 개인 특정 정보가 포함되어 있는 소프트웨어 컴포넌트 (SW 컴포넌트)에 대해서, 에지측 정보 처리 장치를 실행 주체가 되는 대상으로서 결정해도 된다. 이에 의해, 입력 데이터로서의 개인 특정 정보를 클라우드측 정보 처리 장치에 송신하지 않아도 된다. 따라서, 프라이버시 보호를 도모할 수 있다. 도 16, 도 17 등을 참조하여 설명한 바와 같이, 개인 특정 정보는 촬상 화상 데이터로 되어도 된다. 이에 의해, 촬상 화상 데이터를 입력 데이터에 포함할지 여부에 따라서 SW 컴포넌트의 실행 주체가 되는 대상이 결정된다. 또한, 그러한 SW 컴포넌트를 에지측 정보 처리 장치(이미지 센서(IS), 카메라, 포그 서버)에 전개함으로써, 입력 데이터로서의 촬상 화상 데이터를 클라우드측 정보 처리 장치(클라우드 서버, 관리 서버 )에 송신하지 않아도 되기 때문에, 통신 대역의 낭비를 억제할 수 있다. 도 16, 도 17 등을 참조하여 설명한 바와 같이, 결정 처리부(카메라 서비스 기능(F5))는, 입력 데이터에 촬상 화상 데이터가 포함되어 있는 소프트웨어 컴포넌트(SW 컴포넌트)에 대해서, 이미지 센서(IS)를 실행 주체가 되 는 대상으로서 결정해도 된다. 이에 의해, 개인 특정 정보가 이미지 센서(IS) 밖으로 출력되는 것이 방지된다. 따라서, 프라이버시의 보호 및 시큐리티의 향상을 도모할 수 있다. 도 16 등을 참조하여 설명한 바와 같이, 결정 처리부(카메라 서비스 기능(F5))는, 입력 데이터에 개인 특정 정 보가 포함되어 있는 모든 소프트웨어 컴포넌트(SW 컴포넌트)에 대해서, 이미지 센서(IS)를 실행 주체가 되는 대 상으로서 결정해도 된다. 이에 의해, 촬상 화상 데이터 이외의 개인 특정 정보가 포함된 입력 데이터를 다루는 SW 컴포넌트에 대해서는 이미지 센서(IS)에 전개되기 때문에, 일체의 개인 특정 정보가 이미지 센서(IS) 밖으로 출력되지 않는다. 따라 서, 프라이버시의 보호 및 시큐리티의 향상을 보다 견고하게 도모할 수 있다. 도 16 등을 참조하여 설명한 바와 같이, 에지측 정보 처리 장치는, 카메라 장치(카메라(3, 3A, 3B, 3C))를 포함 하고 있어도 된다. 클라우드측 정보 처리 장치는, 다수의 유저에 의해 이용되는 것을 생각할 수 있으며, 그 경우에는, 많은 처리를 클라우드측 정보 처리 장치에서 실행해 버리면, 다른 유저의 이용에 의해 클라우드측 정보 처리 장치에서 사용가능한 컴퓨터 리소스가 저하되어 버려, 처리 지연이 일어나 버릴 우려나, 통신 시간이 증대해 버릴 우려가 있 다. 그러나, 본 구성과 같이, 카메라(3(3A, 3B, 3C))에서 실행 가능한 SW 컴포넌트에 대해서는 카메라에 전 개됨으로써, 보다 말단의 장치에서 적어도 일부 처리가 실행되기 때문에, 처리 분담의 분산을 도모할 수 있어, 클라우드측 정보 처리 장치의 처리 부담의 경감을 도모하는 것이나, 통신 지연 증대의 억제를 도모하는 것이나, 처리 시간이 증대해 버리는 것의 억제를 도모할 수 있다. 도 16 등을 참조하여 설명한 바와 같이, 카메라 장치(카메라(3, 3A, 3B, 3C))는, 연산 처리부(센서내 제어부 , AI 화상 처리부)를 구비한 이미지 센서(IS)와 이미지 센서(IS) 밖에 마련된 연산 처리부(제어부(3 3))를 구비하고, 이미지 센서(IS) 밖에 마련된 연산 처리부와 이미지 센서(IS)는 각각 실행 주체가 되는 대상의 후보로 되어도 된다. 이에 의해, 이미지 센서(IS) 내에서 실행되는 SW 컴포넌트와 이미지 센서(IS) 밖이면서 또한 카메라 내에서 실행되는 SW 컴포넌트를 나누어 전개할 수 있어, 처리 분담의 분산을 도모할 수 있다. 도 12 등을 참조하여 설명한 바와 같이, 소프트웨어 컴포넌트(SW 컴포넌트)의 요구 사양은, 하드웨어(HW) 요구 사양과 소프트웨어(SW) 요구 사양을 포함하고 있어도 된다. 이에 의해, HW의 사양이 요구 사양을 충족하지 못한 장치를 실행 주체가 되는 대상의 후보에서 제외할 수 있을 뿐만 아니라, 인스톨되어 있는 OS가 다른 등 SW의 사양이 요구 사양에 합치하지 않는 장치에 대해서도 실행 주 체가 되는 대상의 후보에서 제외할 수 있다. 따라서, 정상적으로 동작하지 않는 장치에 SW 컴포넌트를 전개해 버릴 가능성을 저감시킬 수 있다. 도 12 등을 참조하여 설명한 바와 같이, 애플리케이션은, 인공 지능 모델(AI 모델)을 사용한 처리를 행하는 소 프트웨어 컴포넌트(SW 컴포넌트)를 포함하고 있어도 된다. 이에 의해, AI 모델을 사용한 처리를 사용하여 유저의 요구를 실현하는 애플리케이션에 대해서 상기한 각종 효 과를 얻을 수 있다. 도 16 등을 참조하여 설명한 바와 같이, 애플리케이션은, 센싱 정보(예를 들어 RGB 화상) 또는 센싱 정보에 기 초해서 얻어진 인식 정보(예를 들어 얼굴 검출의 결과 정보)에 관한 처리를 행하는 소프트웨어 컴포넌트를 포함 하고 있어도 된다. 센싱 정보란, 예를 들어 가시광 센서나 적외 센서나, ToF(Time of Flight) 센서나, 서멀 센서나, 멀티 스펙트럼 센서 등에 의해 얻어지는 데이터이다. 또한, 가속도 센서의 출력 데이터 등, 화상 데이터 이외의 센싱 정보를 다루는 SW 컴포넌트가 포함되어 있어도 된다. 이러한 다종다양한 센싱 정보를 사용한 AI 애플리케이션에 대해서 상술한 효과를 얻을 수 있다. 도 12 등을 참조하여 설명한 바와 같이, 센싱 정보는 촬상 화상 데이터로 되어도 된다. 촬상 화상 데이터를 얻기 위한 이미지 센서(IS)로서는, 예를 들어 가시광 센서나 적외 센서나, ToF(Time of Flight) 센서나, EVS(Event based Vision Sensor), 서멀 센서나, 멀티 스펙트럼 센서나, 편광 센서, SWIR(Short Wavelength infrared) 센서, 습도 센서, 수분 센서 등을 들 수 있다. 이러한 센서 출력을 사용한 처리는, 처리 부담이 증대할 가능성이 있어, 실행 환경이 한정되는 경우가 있다. 본 구성에 의하면, 애플리케이션을 실현하기 위한 SW 컴포넌트를 각종 장치에 분산시켜 전개하는 것이 가능하게 되기 때문에, 처리 부담이 큰 처리에 대해서도 적절한 실행 주체가 할당되어 실행됨으로써 처리 부담의 분산을 도모할 수 있다. 본 기술에서의 정보 처리 방법은, 애플리케이션에 관한 유저 요구와, 상기 애플리케이션을 구성하는 소프트웨어 컴포넌트의 요구 사양에 따라, 상기 소프트웨어 컴포넌트마다 실행 주체가 되는 대상을 결정하는 처리를 컴퓨터 장치가 실행하는 것이다. 상술한 정보 처리 장치(클라우드 서버, 관리 서버)에 실행시키는 프로그램은, 컴퓨터 장치 등의 기기에 내장되어 있는 기록 매체로서의 HDD(Hard Disk Drive)나, CPU를 갖는 마이크로컴퓨터 내의 ROM 등에 미리 기록 해 둘 수 있다. 혹은 또한 프로그램은, 플렉시블 디스크, CD-ROM(Compact Disk Read Only Memory), MO(Magneto Optical) 디스크, DVD(Digital Versatile Disc), 블루레이 디스크(Blu-ray Disc(등록 상표)), 자기 디스크, 반도체 메모리, 메모리 카드 등의 리무버블 기록 매체에, 일시적 혹은 영속적으로 저장(기록)해 둘 수있다. 이러한 리무버블 기록 매체는, 소위 패키지 소프트웨어로서 제공할 수 있다. 또한, 이러한 프로그램은, 리무버블 기록 매체로부터 퍼스널 컴퓨터 등에 인스톨하는 것 외에, 다운로드 사이트 로부터, LAN(Local Area Network), 인터넷 등의 네트워크를 통해서 다운로드할 수도 있다. 또한, 본 명세서에 기재된 효과는 어디까지나 예시이며 한정되는 것이 아니고, 또한 다른 효과가 있어도 된다. 또한, 상술한 각 예는 어떻게 조합해도 되며, 각종 조합을 사용한 경우라도 상술한 다양한 작용 효과를 얻는 것 이 가능하다. <8. 본 기술> 본 기술은 이하와 같은 구성을 취할 수도 있다. 애플리케이션에 관한 유저 요구와, 상기 애플리케이션을 구성하는 소프트웨어 컴포넌트의 요구 사양에 따라, 상기 소프트웨어 컴포넌트마다 실행 주체가 되는 대상을 결정하는 결정 처리부를 구비한, 정보 처리 장치. 상기 애플리케이션은 복수의 소프트웨어 컴포넌트에 의해 구성되고, 상기 결정 처리부는, 상기 복수의 소프트웨어 컴포넌트에 대해서 복수의 대상을 상기 실행 주체가 되는 대상으 로서 결정하는, 상기 에 기재된 정보 처리 장치. 상기 소프트웨어 컴포넌트의 요구 사양은, 개인 특정이 가능한 정보인 개인 특정 정보가 상기 소프트웨어 컴포넌트에 대한 입력 데이터에 포함되어 있는지 여부를 나타내는 정보가 포함된, 상기 내지 상기 중 어느 것에 기재된 정보 처리 장치. 상기 실행 주체가 되는 대상의 후보에 에지측 정보 처리 장치와 클라우드측 정보 처리 장치가 포함된, 상기 내지 상기 중 어느 것에 기재된 정보 처리 장치. 상기 실행 주체가 되는 대상의 후보에 에지측 정보 처리 장치와 클라우드측 정보 처리 장치가 포함되고, 상기 결정 처리부는, 상기 입력 데이터에 상기 개인 특정 정보가 포함되어 있는 상기 소프트웨어 컴포넌트에 대 해서, 상기 에지측 정보 처리 장치를 상기 실행 주체가 되는 대상으로서 결정하는, 상기 에 기재된 정보 처 리 장치. 상기 개인 특정 정보는 촬상 화상 데이터로 된, 상기 또는 상기 중 어느 것에 기재된 정보 처리 장 치. 상기 결정 처리부는, 상기 입력 데이터에 상기 촬상 화상 데이터가 포함되어 있는 상기 소프트웨어 컴포넌 트에 대해서, 이미지 센서를 상기 실행 주체가 되는 대상으로서 결정하는, 상기 에 기재된 정보 처리 장치. 상기 결정 처리부는, 상기 입력 데이터에 상기 개인 특정 정보가 포함되어 있는 모든 상기 소프트웨어 컴포 넌트에 대해서, 이미지 센서를 상기 실행 주체가 되는 대상으로서 결정하는, 상기 에 기재된 정보 처리 장치. 상기 에지측 정보 처리 장치는, 카메라 장치를 포함하는, 상기 에 기재된 정보 처리 장치. 상기 카메라 장치는, 연산 처리부를 구비한 이미지 센서와 상기 이미지 센서 밖에 마련된 연산 처리부를 구비하고, 상기 이미지 센서 밖에 마련된 연산 처리부와 상기 이미지 센서는 각각 상기 실행 주체가 되는 대상의 후보로 된, 상기 에 기재된 정보 처리 장치. 상기 요구 사양은, 하드웨어 요구 사양과 소프트웨어 요구 사양을 포함하는, 상기 내지 상기 중 어느 것에 기재된 정보 처리 장치. 상기 애플리케이션은, 인공 지능 모델을 사용한 처리를 행하는 상기 소프트웨어 컴포넌트를 포함하는, 상 기 내지 상기 중 어느 것에 기재된 정보 처리 장치. 상기 애플리케이션은, 센싱 정보 또는 센싱 정보에 기초해서 얻어진 인식 정보에 관한 처리를 행하는 상기 소프트웨어 컴포넌트를 포함하는, 상기 내지 상기 중 어느 것에 기재된 정보 처리 장치. 상기 센싱 정보는 촬상 화상 데이터로 된, 상기 에 기재된 정보 처리 장치. 애플리케이션에 관한 유저 요구와, 상기 애플리케이션을 구성하는 소프트웨어 컴포넌트의 요구 사양에 따 라, 상기 소프트웨어 컴포넌트마다 실행 주체가 되는 대상을 결정하는 처리를 컴퓨터 장치가 실행하는, 정보 처리 방법. 애플리케이션에 관한 유저 요구와, 상기 애플리케이션을 구성하는 소프트웨어 컴포넌트의 요구 사양에 따 라, 상기 소프트웨어 컴포넌트마다 실행 주체가 되는 대상을 결정하는 결정 기능을 연산 처리 장치에 실행시키 는, 프로그램."}
{"patent_id": "10-2024-7015165", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 정보 처리 시스템의 구성예를 도시하는 도면이다. 도 2는 클라우드측 정보 처리 장치가 구비하는 마켓 플레이스 기능을 통해서 AI 모델이나 AI 애플리케이션의 등 록이나 다운로드를 행하는 각 기기에 대해서 설명하기 위한 도면이다. 도 3은 도 4와 함께 마켓 플레이스 기능을 통해서 AI 모델이나 AI 애플리케이션의 등록이나 다운로드를 행할 때 각 장치가 실행하는 처리의 흐름의 일례를 도시한 도면이다. 도 4는 도 3과 함께 마켓 플레이스 기능을 통해서 AI 모델이나 AI 애플리케이션의 등록이나 다운로드를 행할 때 각 장치가 실행하는 처리의 흐름의 일례를 도시한 도면이다. 도 5는 클라우드측의 정보 처리 장치와 에지측의 정보 처리 장치의 접속 양태에 대해서 설명하기 위한 도면이다. 도 6은 클라우드측 정보 처리 장치의 기능 블록도이다. 도 7은 카메라의 내부 구성예를 도시한 블록도이다. 도 8은 이미지 센서의 구성예를 도시하는 도면이다. 도 9는 카메라의 소프트웨어 구성을 도시하는 블록도이다. 도 10은 컨테이너 기술을 사용한 경우의 컨테이너의 동작 환경을 도시하는 블록도이다. 도 11은 정보 처리 장치의 하드웨어 구성의 일례를 도시하는 블록도이다. 도 12는 AI 애플리케이션이 복수의 SW 컴포넌트를 포함하여 구성되어 있는 예를 도시하는 도면이다. 도 13은 SW 컴포넌트에 관한 부가 정보를 예시한 도면이다. 도 14는 SW 컴포넌트가 전개되는 기억부 등을 도시한 도면이다. 도 15는 전개의 대상이 된 복수의 SW 컴포넌트를 예시한 도면이다. 도 16은 각 기억부에 SW 컴포넌트가 각각 전개된 상태를 도시하는 도면이다. 도 17은 유저의 요구에 따라서 전개처의 장치가 다른 상태를 나타내는 표이다. 도 18은 제1 실시 형태에서 클라우드측 정보 처리 장치가 실행하는 처리의 흐름을 나타내는 흐름도이다. 도 19는 SW 컴포넌트의 전개처의 장치를 결정하는 처리의 흐름을 나타내는 흐름도이다. 도 20은 제2 실시 형태에서 동일한 처리 내용으로 된 SW 컴포넌트가 복수 준비되어 있는 상태를 도시하는 도면 이다. 도 21은 복수의 카메라 각각에 다른 SW 컴포넌트가 전개된 상태를 도시하는 도면이다. 도 22는 제2 실시 형태에서 클라우드측 정보 처리 장치가 실행하는 처리의 흐름을 나타내는 흐름도이다. 도 23은 전개처의 장치와 전개하는 SW 컴포넌트를 결정하는 처리의 흐름을 나타내는 흐름도이다. 도 24는 그 외의 설명에서의 처리의 흐름을 설명하는 도면이다.도 25는 마켓 플레이스에 로그인하기 위한 로그인 화면의 일례를 도시하는 도면이다. 도 26은 마켓 플레이스를 이용하는 각 개발자에게 제시되는 개발자용 화면의 일례를 도시하는 도면이다. 도 27은 마켓 플레이스를 이용하는 애플리케이션 이용 유저에게 제시되는 이용자용 화면의 일례를 도시하는 도 면이다."}
