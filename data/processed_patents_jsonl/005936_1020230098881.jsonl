{"patent_id": "10-2023-0098881", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2025-0017896", "출원번호": "10-2023-0098881", "발명의 명칭": "텍스트로 특정 객체의 검출이 가능한 비디오 서머리 시스템", "출원인": "주식회사 지오비전", "발명자": "김윤"}}
{"patent_id": "10-2023-0098881", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "원본 영상에서 객체를 검출하고 상기 객체의 프레임 내 위치 및 크기, 객체 ID를 포함하는 객체 정보를 생성하는 객체 추출 모듈; 원본 영상에서 서로 다른 시간의 객체들 중 적어도 일부가 동일 시간에 위치하도록 상기 원본 영상을 압축하여서머리 영상을 생성하는 압축 모듈; 및 사용자가 텍스트를 입력하면 입력한 텍스트에 해당하는 객체를 검출하는 이미지 검출 모듈;을 포함하고, 상기 이미지 검출 모듈은 이미지를 설명하는 텍스트를 텍스트 엔코더를 통해 텍스트 임베딩 유닛 벡터(TextEmbedding Unit Vector)로 변환하고, 이미지를 이미지 엔코더를 통해 이미지 임베딩 유닛 벡터(ImageEmbedding Unit Vector)로 변환하여 상기 텍스트 임베딩 유닛 벡터와 상기 이미지 임베딩 유닛 벡터의 유사도를계산함으로써 찾고자 하는 객체를 검출하는 비디오 서머리 시스템."}
{"patent_id": "10-2023-0098881", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 이미지 검출 모듈은 이미지에 캡션이 기재되어 있는 학습데이터로 학습된 인공지능 모델인 것을 특징으로하는 비디오 서머리 시스템."}
{"patent_id": "10-2023-0098881", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,상기 학습데이터의 영어 캡션은 거대 자연어 생성 모델을 이용하여 한글 캡션으로 번역하여 학습데이터에 추가한 것을 특징으로 하는 비디오 서머리 시스템."}
{"patent_id": "10-2023-0098881", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제2항에 있어서,상기 학습데이터의 캡션을 거대 자연어 생성 모델을 이용하여 동일 또는 유사한 의미를 가지는 다양한 표현의한글 또는 영어 캡션을 생성하여 학습데이터에 추가하는 것을 특징으로 하는 비디오 서머리 시스템."}
{"patent_id": "10-2023-0098881", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제2항에 있어서,적절하지 않은 캡션을 가지는 의사(Pseudo) 레이블링 이미지를 학습데이터에 추가하는 것을 특징으로 하는 비디오 서머리 시스템."}
{"patent_id": "10-2023-0098881", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서,상기 이미지 검출 모듈이 찾고자 하는 객체를 검출한 경우에 서머리 영상에는 원본 영상에서 검출된 객체와 동일한 시간에 위치하는 객체가 함께 노출되는 것을 특징으로 하는 비디오 서머리 시스템."}
{"patent_id": "10-2023-0098881", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명의 일 실시예에 따른 비디오 서머리 시스템은 이미지를 설명하는 텍스트를 텍스트 엔코더를 통해 텍스트 임베딩 유닛 벡터(Text Embedding Unit Vector)로 변환하고, 이미지를 이미지 엔코더를 통해 이미지 임베딩 유닛 벡터(Image Embedding Unit Vector)로 변환하여 양자의 유사도를 계산함으로써 객체를 찾을 수 있다. 따라서, 본 발명의 일 실시예에 따른 비디오 서머리 시스템을 이용할 경우 사용자는 객체에 대한 설명이나 객체가 하고 있는 행동을 텍스트로 입력하여 그 설명에 해당하는 객체 또는 그 행동을 하고 있는 객체를 검출 할 수 있다. 그 러므로 본 발명의 일 실시예에 따른 비디오 서머리 시스템을 이용할 경우 서머리 영상에 등장하는 객체의 수가 원본 영상에 비해 많아져 모니터링이 힘들어지는 문제를 해결할 수 있다."}
{"patent_id": "10-2023-0098881", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 텍스트로 특정 객체의 검출이 가능한 이미지 검출이 가능한 비디오 서머리 시스템에 관한 것이다."}
{"patent_id": "10-2023-0098881", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "현대 사회에서는 CCTV와 같은 다양한 비디오 캡쳐 장치를 이용하여 공간을 모니터링하고 있다. 그러나 이러한 장치들이 생성하는 대량의 비디오 데이터를 실시간으로 재생하여 분석하고 필요한 이벤트를 찾는 것은 인력과 시간이 매우 많이 필요하다. 반대로 비디오를 빠르게 재생하면 객체의 움직임이 너무 빠르게 되어 이벤트를 찾 는 것이 어렵다. 트레이드-오프(Trade-off) 관계 있다. 이러한 문제를 해결하기 위해 비디오 서머리 기술이 제 안되었다. 비디오 서머리 기술은 원본 비디오 영상을 짧은 시간으로 압축한 영상을 만드는 방법이다. 이 때 압축의 주요 관심사는 원본 영상에서의 객체(사람, 동물, 차량 등)이다. 이 기술은 원본 영상에서 동적 객체가 등장하는 프 레임을 선별하고, 이들을 합쳐서 서머리 영상을 만든다. 동적 객체의 (X, Y) 좌표는 그대로 유지시켜 서머리 영 상에서 객체의 동선은 실제를 그대로 반영하도록 한다. 원본 비디오 영상에서 서로 다른 시간에 등장한 객체가 서머리 영상에서는 같은 시간에 등장할 수 있다. 이러한 비디오 서머리 기술은 이벤트 검출 시에 또 다른 문제를 야기하였다. 이벤트를 검출하기 위해서는 객체 를 식별하거나, 객체의 행동을 식별하여야 한다. 그런데 비디오 서머리 기술은 일 시점에 영상에 등장하는 객체 의 수가 원본 영상에 비해 현저히 많다. 즉, 객체 또는 그 움직임을 식별하기 더 어려워졌다는 것이다. 이 문제를 해결하기 위해서는 객체를 검출하는 기능이 필요하다. 예를 들어서, 작업자가 \"아이를 업은 사람\"이 라고 텍스트를 입력하면 \"아이를 업은 사람\"만을 서머리 영상에서 보여주고, 다른 객체들은 제외하여 찾고자 하 는 이벤트에 관련된 객체만을 노출시키는 것이다. 종래에 이처럼 텍스트로 이미지으로부터 객체를 검출하는 기술이 없었던 것은 아니다. 그런데 종래에는 그 한계 가 명확했다. 텍스트로 \"발길질을 하는 사람\"을 입력하여 \"발길질을 하는 사람\"이 포함된 이미지를 찾는 것을 예를 들어 종래 기술에 대해 살펴보면 다음과 같다. 네이버나 다음 등에서 이미지를 검색하는 방법은 객체를 검출하는 것이 아니라, 콘텐츠 작성자가 써놓은 캡션을 이용하는 것이다. 이 방법은 비디오 서머리 기술처럼 영상 내의 객체에 캡션이 달려있지 않은 경우에는 사용할 수 없다. 다른 방법으로는 인공지능을 이용하는 방법이다. \"발길질을 하는 사람\"이 있는 다양한 사진을 모아서 학습시켜 모델을 구축한다. 학습된 모델을 이용하면 영상 내에서 \"발길질을 하는 사람\"을 찾을 수 있다. 문제는 찾고자 하는 행동마다 학습을 시켜야 한다는 점이다. \"만세를 하는 사람\", \"고개를 돌리는 사람\"을 찾기 위해서는 각각 학습된 모델이 필요하다. 너무 다양한 상황이 존재하기 때문에 이 방법도 현실적으로 불가능하다. 본 발명은 이러한 문제를 해결할 수 있는 새로운 방안을 제시한다."}
{"patent_id": "10-2023-0098881", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명의 일 목적은 이미지를 설명하는 텍스트를 텍스트 엔코더를 통해 텍스트 임베딩 유닛 벡터(Text Embedding Unit Vector)로 변환하고, 이미지를 이미지 엔코더를 통해 이미지 임베딩 유닛 벡터(Image Embedding Unit Vector)로 변환하여 양자의 유사도를 계산함으로써 객체를 찾을 수 있는 이미지 검출 시스템과 이를 이용한 비디오 서머리 시스템을 제공하는 것이다. 본 발명의 또 다른 목적은 한국어 텍스트에 대해서도 높은 성능을 가지는 이미지 검출 시스템과 이를 이용한 비 디오 서머리 시스템을 제공하는 것이다. 한편, 본 발명의 명시되지 않은 또 다른 목적들은 하기의 상세한 설명 및 그 효과로부터 용이하게 추론할 수 있 는 범위 내에서 추가적으로 고려될 것이다."}
{"patent_id": "10-2023-0098881", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "이상에서 제안한 목적을 달성하기 위해 다음과 같은 해결수단을 제안한다. 본 발명의 일 실시예에 따른 비디오 서머리 시스템은 원본 영상에서 객체를 검출하고 상기 객체의 프레임 내 위 치 및 크기, 객체 ID를 포함하는 객체 정보를 생성하는 객체 추출 모듈; 원본 영상에서 서로 다른 시간의 객체 들 중 적어도 일부가 동일 시간에 위치하도록 상기 원본 영상을 압축하여 서머리 영상을 생성하는 압축 모듈; 및 사용자가 텍스트를 입력하면 입력한 텍스트에 해당하는 객체를 검출하는 이미지 검출 모듈;을 포함하고, 상 기 이미지 검출 모듈은 이미지를 설명하는 텍스트를 텍스트 엔코더를 통해 텍스트 임베딩 유닛 벡터(Text Embedding Unit Vector)로 변환하고, 이미지를 이미지 엔코더를 통해 이미지 임베딩 유닛 벡터(Image Embedding Unit Vector)로 변환하여 상기 텍스트 임베딩 유닛 벡터와 상기 이미지 임베딩 유닛 벡터의 유사도를 계산함으로써 찾고자 하는 객체를 검출할 수 있다. 일 실시예에 있어서, 상기 이미지 검출 모듈은 이미지에 캡션이 기재되어 있는 학습데이터로 학습된 인공지능 모델인 것을 특징으로 할 수 있다. 이때, 상기 학습데이터의 영어 캡션은 거대 자연어 생성 모델을 이용하여 한글 캡션으로 번역하여 학습데이터에 추가한 것을 특징으로 할 수 있다. 이때, 상기 학습데이터의 캡션을 거대 자연어 생성 모델(NLP)을 이용하여 동일 또는 유사한 의미를 가지는 다양 한 표현의 한글 또는 영어 캡션을 생성하여 학습데이터에 추가하는 것을 특징으로 할 수 있다. 이때, 적절하지 않은 캡션을 가지는 의사(Pseudo) 레이블링 이미지를 학습데이터에 추가하는 것을 특징으로 할 수 있다. 일 실시예에 있어서, 상기 이미지 검출 모듈이 찾고자 하는 객체를 검출한 경우에 서머리 영상에는 원본 영상에 서 검출된 객체와 동일한 시간에 위치하는 객체가 함께 노출되는 것을 특징으로 할 수 있다. 본 발명의 다른 실시예에 따른 텍스트로 특정 객체의 검출이 가능한 이미지 검출 시스템은 이미지를 설명하는 텍스트를 텍스트 엔코더를 통해 텍스트 임베딩 유닛 벡터(Text Embedding Unit Vector)로 변환하고, 이미지 엔 코더를 통해 이미지 임베딩 유닛 벡터(Image Embedding Unit Vector)로 변환하여 상기 텍스트 임베딩 유닛 벡터 와 상기 이미지 임베딩 유닛 벡터의 유사도를 계산함으로써 찾고자 하는 객체를 검출할 수 있다. 다른 실시예에 있어서, 상기 이미지 검출 모듈은 이미지에 캡션이 기재되어 있는 학습데이터로 학습된 인공지능 모델인 것을 특징으로 할 수 있다. 다른 실시예에 있어서, 상기 학습데이터의 영어 캡션은 거대 자연어 생성 모델을 이용하여 한글 캡션으로 번역 하여 학습데이터에 추가한 것을 특징으로 할 수 있다. 다른 실시예에 있어서, 상기 학습데이터의 캡션을 거대 자연어 생성 모델을 이용하여 동일 또는 유사한 의미를 가지는 다양한 표현의 한글 또는 영어 캡션을 생성하여 학습데이터에 추가하는 것을 특징으로 할 수 있다. 다른 실시예에 있어서, 적절하지 않은 캡션을 가지는 의사(Pseudo) 레이블링 이미지를 학습데이터에 추가하는 것을 특징으로 할 수 있다."}
{"patent_id": "10-2023-0098881", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명의 일 실시예에 따른 비디오 서머리 시스템은 이미지를 설명하는 텍스트를 텍스트 엔코더를 통해 텍스트 임베딩 유닛 벡터(Text Embedding Unit Vector)로 변환하고, 이미지를 이미지 엔코더를 통해 이미지 임베딩 유 닛 벡터(Image Embedding Unit Vector)로 변환하여 양자의 유사도를 계산함으로써 객체를 찾을 수 있다. 따라서, 본 발명의 일 실시예에 따른 비디오 서머리 시스템을 이용할 경우 사용자는 객체에 대한 설명이나 객체 가 하고 있는 행동을 텍스트로 입력하여 그 설명에 해당하는 객체 또는 그 행동을 하고 있는 객체를 검출 할 수 있다. 그러므로 본 발명의 일 실시예에 따른 비디오 서머리 시스템을 이용할 경우 서머리 영상에 등장하는 객체 의 수가 원본 영상에 비해 많아져 모니터링이 힘들어지는 문제를 해결할 수 있다. 또한, 본 발명의 일 실시예에 따른 비디오 서머리 시스템의 이미지 검출 모듈은 이미지에 캡션이 기재되어 있는 학습데이터로 학습된 인공지능 모델을 이용하는데, 현재 학습데이터들은 캡션이 거의 대부분 영어로 되어 있다. 이와 같이 영어 캡션의 학습데이터만으로 학습시킬 경우 한글에 대해서는 제대로 동작하지 못하는 문제가 있다. 이를 해결하기 위해 종래에는 번역기를 이용하여 한글 캡션을 생성하려는 시도가 없었던 것은 아니지만, 여전히 한글 텍스트에 대해서는 성능이 낮다는 문제가 있다. 본 발명의 일 실시예에 따른 비디오 서머리 시스템은 거대 자연어 모델을 이용하여 영어 캡션을 한글 캡션으로 번역하고, 한글 캡션을 가지는 이미지를 학습데이터로 추가 하였다. 번역기는 실제 사람이 사용하는 언어와 차이가 있지만 거대 자연어 모델은 실제 사람이 사용하는 언어와 유사하므로, 거대 자연어 모델을 이용하여 생성된 한글 캡션을 가지는 이미지를 학습데이터로 추가한 경우 번역기를 이용한 경우에 비해 한글 텍스트에 의한 이미지 검출 성능이 향상된다. 또한, 본 발명의 일 실시예에 따른 비디오 서머리 시스템의 이미지 검출 모듈은 이미지에 캡션이 기재되어 있는 학습데이터로 학습된 인공지능 모델을 이용하는데, 학습데이터의 캡션을 거대 자연어 생성 모델을 이용하여 동 일 또는 유사한 의미를 가지는 다양한 표현의 한글 또는 영어 캡션을 생성하여 학습데이터에 추가함으로써 텍스 트에 의한 이미지 검출 성능이 현저히 향상된다. 한편, 여기에서 명시적으로 언급되지 않은 효과라 하더라도, 본 발명의 기술적 특징에 의해 기대되는 이하의 명 세서에서 기재된 효과 및 그 잠정적인 효과는 본 발명의 명세서에 기재된 것과 같이 취급됨을 첨언한다."}
{"patent_id": "10-2023-0098881", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 도면을 참조하여 본 발명의 다양한 실시예가 안내하는 본 발명의 구성과 그 구성으로부터 비롯되는 효과 에 대해 살펴본다. 본 발명을 설명함에 있어서 관련된 공지기능에 대하여 이 분야의 기술자에게 자명한 사항으 로서 본 발명의 요지를 불필요하게 흐릴 수 있다고 판단되는 경우에는 그 상세한 설명을 생략한다. 본 문서에서 사용된 용어 \"모듈\"은 하드웨어, 소프트웨어 또는 펌웨어로 구현된 유닛을 포함할 수 있으며, 예를 들면, 로직, 논리 블록, 부품, 또는 회로 등의 용어와 상호 호환적으로 사용될 수 있다. 모듈은, 일체로 구성된 부품 또는 하나 또는 그 이상의 기능을 수행하는, 상기 부품의 최소 단위 또는 그 일부가 될 수 있다. 본 문서에서 \"모듈\"이나 \"노드\"는 CPU, AP 등과 같은 연산 장치를 이용하여 데이터를 이동, 저장, 변환 등의 작 업을 수행한다. 예컨대 \"모듈\"이나 \"노드\"는 서버, PC, 태블릿 PC, 스마트폰 등과 같은 장치로 구현될 수 있다. 본 문서에서 \"딥러닝 모델“이라는 것은 인간의 두뇌 작동 방식을 기반으로 모델링한 알고리즘인 신경망을 학습 시켜 신경을 구성시킨 것을 의미하며, 당업계에서 널리 사용되는 의미로 넓게 해석된다. 도 1은 본 발명의 일 실시예에 따른 비디오 서머리 시스템의 개략적 구성도이다. 도 1을 참조하면, 본 발명의 일 실시예에 따른 비디오 서머리 시스템은 입력 모듈, 객체 추출 모듈, 이 미지 검출 모듈 및 출력 모듈을 포함한다. 입력 모듈을 통해 사용자는 시스템을 제어하기 위한 명령어를 입력하거나, 찾고자하는 객체를 설명하거나 객체의 행동을 설명하는 텍스트를 입력한다. 객체 추출 모듈은 원본 영상에서 객체를 검출하고 상기 객체의 프레임 내 위치 및 크기, 객체 ID를 포함하 는 객체 정보를 생성한다. 객체 추출 모듈은 원본영상을 수신하면 원본영상의 각 프레임으로부터 동적객체를 탐지하여 분리하고, 분리 된 객체에 대해서 객체 정보를 탐지한다. 객체정보에는 프레임 내 좌표(x, y), 폭과 높이, 사람, 동물, 차량 등객체의 분류를 포함한다. 객체정보는 기설정된 것으로서, 색상, 움직임 방향(좌에서 우로 등) 등을 포함할 수 있다. 동적객체가 나오는 모든 프레임에서 상기한 작업을 수행한다. 객체에 대한 분리 및 탐지가 완료되면, 여 러 프레임에 걸쳐서 등장하는 객체의 동일성을 판단하여, 같은 객체로 판단되면 동일한 ID를 부여한다. 객체들 은 움직임의 연속성을 가지므로, 동적객체가 나타난 프레임들을 이용하거나, 객체정보를 함께 이용하여, 여러장 에 걸쳐서 등장하는 객체의 동일성 여부를 판단할 수 있다. 상기한 바와 같이 동적객체를 분리(segmentation)하 는 과정, 객체를 탐지하여 객체정보를 생성하는 과정(detecting) 및 동일성을 판단하여 객체별로 ID를 부여하는 과정(tracking)은 지능형 CCTV 등 영상처리 분야에서 널리 사용되는 기술이므로, 이에 대한 구체적인 설명은 생 략하기로 한다. 압축 모듈은 원본 영상에서 서로 다른 시간의 객체들 중 적어도 일부가 동일 시간에 위치하도록 원본 영상 을 압축하여 서머리 영상을 생성한다. 원본 영상에서 서로 다른 시간의 객체라고 하면 그 객체들이 동시에 동일 한 프레임에 위치한 적이 없는 경우, 그 객체들이 동시에 동일한 프레임에 위치한 적이 일부만 있는 경우를 포 함한다. 나아가 등장시간이 긴 객체 A가 있고, 등장시간이 짧으며 객체 A의 등장 중에 나타났다가 사라진 객체 B가 있을 때 객체 A의 등장시간을 기준으로 객체 B의 등장시간이 원본 영상과 달라지는 경우도 포함한다. 도 2는 3시간 분량의 원본 영상의 스크린 샷이며, 도 3은 압축 모듈에 의해 압축된 2분 분량의 서머리 영상의 스크린 샷이다. 도 2 및 도 3을 비교해보면 원본 영상에서 서로 다른 시간에 위치하던 다양한 객체(사람, 자동 차 등)이 하나의 화면 안에 위치하는 것을 알 수 있다. 그런데 문제는 서머리 영상의 일 시점에 등장하는 객체 가 너무 많아서, 제대로 모니터링을 할 수 없다는 것이다. 도 4는 종래의 방법으로 필터링을 한 후의 스크린 샷으로서 \"남성\"과 \"여성\"을 태그(tag)로 한 것이다. 도 4에 서 보는 바와 같이 \"남성\"과 \"여성\"을 태그로 한 경우 여전히 너무 많은 객체가 출력되고 있고, 무엇보다 어떤 행동이나 외형을 가지는 객체를 찾을 수 없다는 문제가 있다. 이 문제를 해결하기 위해 본 발명은 이미지 검출 모듈(시스템)을 이용한다. 도 5는 본 발명의 일 실시예에 따른 비디오 서머리 시스템의 이미지 검출 모듈(시스템)의 개략적 구성도이다. 이미지 검출 모듈(시스템, 아래에서는 \"시스템\"을 생략한다)은 사용자가 텍스트를 입력하면 입력한 텍스트 에 해당하는 객체를 검출한다. 이를 위해 이미지 검출 모듈은 이미지를 설명하는 텍스트를 텍스트 엔코더를 통해 텍스트 임베딩 유닛 벡터(Text Embedding Unit Vector)로 변환하고, 이미지를 이미지 엔코더를 통해 이미 지 임베딩 유닛 벡터(Image Embedding Unit Vector)로 변환하여 상기 텍스트 임베딩 유닛 벡터와 상기 이미지 임베딩 유닛 벡터의 유사도를 계산함으로써 찾고자 하는 객체를 검출한다. 이미지 검출 모듈은 사용자가 텍스트를 입력하면, 그 텍스트와 관련된 객체를 이미지에서 찾아내는 기능을 수행 한다. 예를 들어, 사용자가 \"하얀색 반팔과 반바지를 입은 여자아이\"라는 텍스트를 입력하면, 도 6에서 보는 바와 같 이 이미지 검출물 모듈은 서머리 영상에서 \"하얀색 반팔과 반바지를 입은 여자아이\"를 검출하는 것을 알 수 있다. 마찬가지로 사용자가 \"검은색 상의를 입고 노란색 가방을 메고있는 여성\"이라는 텍스트를 입력하면, 도 7에서 보는 바와 같이 이미지 검출 모듈은 서머리 영상에서 \"검은색 상의를 입고 노란색 가방을 메고있는 여성\"를 검출한다. 이를 수행하기 위해서, 이미지 검출 모듈은 두 가지 주요 단계를 거친다. 첫번째 단계는 텍스트와 이미지의 임베딩이며, 두번째 단계는 임베딩 벡터들 간의 유사도 계산이다. 먼저, 입력 텍스트는 텍스트 엔코더를 통해 텍스트 임베딩 유닛 벡터라는 형태로 변환된다. 텍스트 엔코더는 텍 스트 데이터를 저차원(예를 들어, 512 차원 등)의 실수 벡터로 변환하는 역할을 수행한다. 같은 방식으로, 이미 지는 이미지 엔코더를 통해 이미지 임베딩 유닛 벡터로 변환된다. 이미지 엔코더는 이미지를 저차원(예를 들어, 512 차원 등)의 벡터 형태로 변환하는 역할을 한다. 이렇게 변환된 벡터는 해당 텍스트나 이미지의 주요 특징을 나타내며, 이를 통해 텍스트와 이미지를 비교하거나 분석할 수 있게 되는 것이다. 변환된 텍스트 임베딩 유닛 벡터와 이미지 임베딩 유닛 벡터 간의 유사도는 코사인 유사도(cosine similarity) 등의 유사도 계산 방법을 통해 계산될 수 있다. 유사도 계산 방법은 코사인 유사도 이외에 다른 방법을 이용하 는 것도 가능하다. 유사도는 두 벡터가 얼마나 비슷한 방향을 가리키고 있는지를 측정하는 방법이며, 이를 통해 특정 텍스트가 특정 이미지와 얼마나 관련이 있는지를 알 수 있게 된다. 보다 구체적으로는 이미지와 텍스트 사이의 유사도를 계산하고, 임계값보다 높은 이미지를 검출 결과로 출력하게 되는 것이다. 이러한 동작을 위해 이미지 검출 모듈은 이미지에 캡션이 기재되어 있는 학습데이터로 학습된 인공지능 모 델을 이용한다. 캡션과 이미지의 쌍을 이용하면, 모델은 이미지의 내용을 설명하는 캡션의 정보를 학습하여, 이 미지와 텍스트 간의 연관성을 파악하게 된다. 보다 구체적으로 본 발명에서는 학습을 통해 텍스트 엔코더 및/또는 이미지 엔코더를 구축하게 된다. 텍스트 엔 코더는 캡션(텍스트)을 임베딩 벡터로 변환하는 방법을, 이미지 엔코더는 이미지를 임베딩 벡터로 변환하는 방 법을 학습한다. 이렇게 학습된 엔코더들은 이후 새로운 텍스트나 이미지가 주어졌을 때, 이를 임베딩 벡터로 변 환하는 역할을 수행하게 된다. 도 8은 학습데이터로 이용한 공개데이터인 CoCo Captioning Data의 예시이며, 도 9는 학습데이터로 이용한 공개 데이터인 Flickr30k의 예시이다. CoCo Captioning Data는 약 40만장의 train data, 약 20만장의 validation data로 구성되며, Image-caption pair Data이다. Flickr30k는 약 3만장의 train data, 1천장의 validation data로 구성되며, Image-caption pair Data이다. 학습데이터로 의사(Pseudo) 레이블링 데이터를 이용할 수 있다. 의사(Pseudo) 레이블링 데이터는 레이블이 없는 데이터에 대해 모델의 예측을 레이블로 대체하여 사용한 데이터를 의미하며, 학습데이터에 일부 의사(Pseudo) 레이블링 데이터를 포함할 경우 이미지 검출 모듈의 객체 검출 성능이 향상된다. 의사(Pseudo) 레이블링 데 이터를 생성하기 위해 캡션이 없는 이미지로로부터 캡션을 생성하는 캡셔닝 모델(Captioning Model)을 활용하여 약 500만 장의 이미지에서 캡션을 생성하였으며, 생성한 의사(Pseudo) 레이블링 데이터를 학습데이터에 추가하 였다. 한편, 또한, 본 발명의 일 실시예에 따른 비디오 서머리 시스템의 이미지 검출 모듈은 이미지에 캡션이 기재되 어 있는 학습데이터로 학습된 인공지능 모델을 이용하는데, 현재 학습데이터들은 캡션이 거의 대부분 영어로 되 어 있다. 이와 같이 영어 캡션의 학습데이터만으로 학습시킬 경우 한글에 대해서는 제대로 동작하지 못하는 문 제가 있다. 이를 해결하기 위해 종래에는 번역기를 이용하여 한글 캡션을 생성하려는 시도가 없었던 것은 아니 지만, 여전히 한글 텍스트에 대해서는 성능이 낮다는 문제가 있다. 본 발명의 일 실시예에 따른 비디오 서머리 시스템은 거대 자연어 모델을 이용하여 영어 캡션을 한글 캡션으로 번역하고, 한글 캡션을 가지는 이미지를 학 습데이터로 추가하였다. 번역기는 실제 사람이 사용하는 언어와 차이가 있지만 거대 자연어 모델은 실제 사람이 사용하는 언어와 유사하므로, 거대 자연어 모델을 이용하여 생성된 한글 캡션을 가지는 이미지를 학습데이터로 추가한 경우 번역기를 이용한 경우에 비해 한글 텍스트에 의한 이미지 검출 성능이 향상된다. 참고로 거대 자연 어 모델로는 GPT(Generative Pretrained Transformer), BERT (Bidirectional Encoder Representations from Transformers), 구글의 BARD, T5 (Text-to-Text Transfer Transformer) 등이 있다. 여기서는 GPT와 T5를 이용 하였다. 다만, 거대 자연어 모델은 현시점에서 신규한 것들이 계속 나오고 있으며, 본 발명이 특정한 거대 자연 어 모델의 종류 한정되지는 않을 것이다. 또한, 본 발명의 일 실시예에 따른 비디오 서머리 시스템의 이미지 검출 모듈은 이미지에 캡션이 기재되어 있는 학습데이터로 학습된 인공지능 모델을 이용하는데, 학습데이터의 캡션을 거대 자연어 생성 모델을 이용하여 동 일 또는 유사한 의미를 가지는 다양한 표현의 한글 또는 영어 캡션을 생성하여 학습데이터에 추가함으로써 텍스 트에 의한 이미지 검출 성능이 현저히 향상된다. 상술한 바와 같이 학습은 텍스트 인코더와 이미지 인코더를 모두 학습하여야 한다. 인코더를 학습은 이미지-캡 션 사이 대조 손실(Contrastive Loss)를 이용해 진행하였다. 대조 손실는 텍스트 임베딩 유닛 벡터를 행 또는 열에 배치하고, 이미지 임베딩 유닛 벡터를 열 또는 행에 배치한 후 텍스트 임베딩 유닛 벡터와 이미지 임베딩 유닛 벡터의 쌍 데이터(pair data, 만들어지는 행렬의 중앙 대각선 부분)이 1이 되도록 학습시키는 방법을 의미 한다. 따라서 이미지 검출 시에도 텍스트 임베딩 유닛 벡터와 이미지 임베딩 유닛 벡터의의 코사인 유사도가 1 에 가까운 이미지를 입력한 텍스트에 대한 결과로 출력하게 된다. 추가로 본 발명은 성능을 높이기 위해 사이 대조 손실과 이미지 텍스트 매칭 손실(image text matching loss)를 함께 사용하였다. 이미지 텍스트 매칭 손실(image-text matching loss)는 이미지와 텍스트를 크로스 어텐션 모 듈(cross attention model)을 통해 이진 분류(binary classification)하여 손실을 계산한다. 크로스 어텐션 모 델은 이미지와 텍스트 사이의 복잡한 관계를 분석하고 이해하는데 도움이 되는 기술이며, 이를 통해 이미지의 특정 부분과 텍스트의 특정 부분이 얼마나 관련되어 있는지를 측정하게 된다. 이런 과정을 통해, 인공지능은 결국 이미지와 텍스트 사이의 관계를 이진 분류로 나누게 된다. 즉, 주어진 이미지와 텍스트가 서로 연관되어 있 으면 \"1\"로, 아니면 \"0\"으로 분류하게 되는 것이다. 마지막으로 손실을 계산한다. 손실이란 인공지능의 예측이 실제 결과와 얼마나 차이나는지를 나타내는 수치이며, 손실이 작을수록 인공지능은 이미지와 텍스트를 잘 매칭 하고 있다는 것을 의미하며, 반대로 손실이 클수록 인공지능의 예측이 틀린 경우가 많다는 것을 의미한다. 그러 므로 손실을 최소화하도록 학습을 수행한다. 본 발명은 사전학습(Pretrained) 이미지 인코더를 프리즈(freeze)하여 텍스트 인코더부터 학습을 진행하였다. 한편, 정부(과학기술정보통신부)의 재원으로 지원을 받아 수행된 연구의 결과로 VL-KE-T5라는 이미지 검출 모델 을 코드와 함께 공개하고 있다. VL-KE-T5는 다음의 표 1과 같이 학습데이터로 공개 데이터를 이용하였으며, 번역은 구글의 번역 API를 이용하 였다. [표 1]"}
{"patent_id": "10-2023-0098881", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "또한, VL-KE-T5는 이미지 인코더로 google/vit-base-patch16-384 사용하였으며, 텍스트 인코더로 KETI-AIR/ke- t5-base 사용하였다. 본 발명에 비해 더 큰 모델을 사용하였다. VL-KE-T5과 본 발명의 이미지 검출 모듈들의 성능을 비교하였다. Coco validation data 1000장으로 테스트한 결과는 다음과 같다. 아래의 표 2는 KETI의 VL-KE-T5와 본 발명의 이미지 검출 모듈의 성능을 비교한 것이다. [표 2] 여기서 Recall@5는 5개의 이미지 중에 정답이 있는 경우를 의미하며, 영상 모니터링시에 객체가 5개 정도 출력 될 경우 사람이 쉽게 원하는 객체를 찾을 수 있으므로 5개를 기준으로 성능을 평가한 것을 의미한다. 이미지 검출 모듈이 찾고자 하는 객체를 검출하면 그 결과를 출력 모듈을 통해 사용자에게 출력한다. 이미지 검출 모듈이 찾고자 하는 객체를 검출한 경우에 서머리 영상에는 원본 영상에서 검출된 객체와 동일한 시간에 위치하는 객체가 함께 노출시켜 객체 사이의 견련성을 확인할 수 있다. 상술한 바와 같은 비디오 서머리 시스템 및/또는 객체 검출 시스템은 컴퓨터에서 실행될 수 있는 실행가능한 알 고리즘을 포함하는 프로그램(또는 어플리케이션)으로 구현될 수 있다. 상기 프로그램은 비일시적 판독 가능 매 체(non-transitory computer readable medium)에 저장되어 제공될 수 있다. 여기서 비일시적 판독 가능 매체란 레지스터, 캐쉬, 메모리 등과 같이 짧은 순간 동안 데이터를 저장하는 매체가 아니라 반영구적으로 데이터를 저 장하며, 기기에 의해 판독(reading)이 가능한 매체를 의미한다. 구체적으로는, 상술한 다양한 어플리케이션 또 는 프로그램들은 CD, DVD, 하드 디스크, 블루레이 디스크, USB, 메모리카드, ROM등과 같은 비일시적 판독 가능 매체에 저장되어 제공될 수 있다. 본 발명의 보호범위가 이상에서 명시적으로 설명한 실시예의 기재와 표현에 제한되는 것은 아니다. 또한, 본 발"}
{"patent_id": "10-2023-0098881", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "명이 속하는 기술분야에서 자명한 변경이나 치환으로 말미암아 본 발명이 보호범위가 제한될 수도 없음을 다시 한번 첨언한다."}
{"patent_id": "10-2023-0098881", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일 실시예에 따른 비디오 서머리 시스템의 개략적 구성도이다. 도 2는 3시간 분량의 원본 영상의 스크린 샷이다. 도 3은 압축 모듈에 의해 압축된 2분 분량의 서머리 영상의 스크린 샷이다. 도 4는 종래의 방법으로 필터링을 한 후의 스크린 샷으로서 \"남성\"과 \"여성\"을 태그(tag)로 한 것이다. 도 5는 본 발명의 일 실시예에 따른 비디오 서머리 시스템의 이미지 검출 모듈(시스템)의 개략적 구성도이다. 도 6 및 도 7은 이미지 검출 모듈에 텍스트를 입력한 경우의 스크린 샷이다. 도 8은 학습데이터로 이용한 공개데이터인 CoCo Captioning Data의 예시이다. 도 9는 학습데이터로 이용한 공개데이터인 Flickr30k의 예시이다. 첨부된 도면은 본 발명의 기술사상에 대한 이해를 위하여 참조로서 예시된 것임을 밝히며, 그것에 의해 본 발명 의 권리범위가 제한되지는 아니한다."}
