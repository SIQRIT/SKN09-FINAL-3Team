{"patent_id": "10-2019-0090232", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2019-0095189", "출원번호": "10-2019-0090232", "발명의 명칭": "로봇 시스템 및 그 제어방법", "출원인": "엘지전자 주식회사", "발명자": "이원희"}}
{"patent_id": "10-2019-0090232", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "로봇;상기 로봇의 동작에 관한 정보를 저장하는 서버; 및상기 로봇 및 상기 서버와 통신하고, 상기 로봇으로부터 상기 로봇의 동작을 전송받고, 상기 서버로부터 저장된캐릭터의 동작을 전송받고, 상기 로봇에 대응하는 캐릭터를 영상으로 디스플레이하는 단말을 포함하고,상기 로봇은,상기 로봇의 각 부위를 움직이도록 작동하는 액추에이터;상기 로봇의 각 부위에 구비되고, 사용자의 신체가 일정범위 내에 있으면 이를 감지하는 근접센서(proximitysensor);상기 액추에이터 및 상기 근접센서와 연결되고, 상기 근접센서로부터 사용자의 신체가 일정범위 내에 있다는 신호를 전송받아 상기 액추에이터에 작동을 명령하는 제어부; 및상기 제어부와 연결되는 통신부를 포함하는,로봇 시스템."}
{"patent_id": "10-2019-0090232", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,캐릭터 동작 입력모드에서,상기 로봇은 복수의 동작을 생성하여 상기 단말에 전송하고,상기 단말은 상기 로봇의 동작을 상기 서버로 전송하고,상기 서버는,전송받은 복수의 상기 로봇의 동작을 조합하여 상기 캐릭터의 동작을 생성하는, 로봇 시스템."}
{"patent_id": "10-2019-0090232", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,상기 캐릭터의 동작은 상기 서버에 저장되는, 로봇 시스템."}
{"patent_id": "10-2019-0090232", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,캐릭터 동작 재생모드에서,상기 서버는 상기 캐릭터의 동작을 상기 단말에 전송하고,상기 단말은 상기 캐릭터의 동작을 영상으로 디스플레이하는, 로봇 시스템."}
{"patent_id": "10-2019-0090232", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서,공개특허 10-2019-0095189-3-캐릭터 동작 재생모드에서,상기 로봇은 동작을 상기 단말로 전송하고,상기 단말은 상기 로봇의 동작을 상기 서버로 전송하고,상기 서버는,전송받는 상기 로봇의 동작을 기반으로 상기 캐릭터의 동작을 변형하고, 상기 캐릭터의 변형된 동작을 상기 단말로 전송하고,상기 단말은 상기 캐릭터의 변형된 동작을 영상으로 디스플레이하는, 로봇 시스템."}
{"patent_id": "10-2019-0090232", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5항에 있어서,상기 로봇 및 상기 캐릭터는 복수로 구비되고,상기 서버는,복수의 상기 로봇으로부터 전송되는 각각의 동작을 조합하여 동일한 가상공간에 존재하는 복수의 캐릭터 전체의동작을 생성하는, 로봇 시스템."}
{"patent_id": "10-2019-0090232", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제5항에 있어서,상기 캐릭터의 변형된 동작은 상기 서버에 저장되는, 로봇 시스템."}
{"patent_id": "10-2019-0090232", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1항에 있어서,상기 로봇에 구비되고, 상기 로봇의 동작을 입력받는 입력부를 더 포함하고,상기 로봇은 입력부에 입력되는 신호에 대응하는 동작을 생성하는, 로봇 시스템."}
{"patent_id": "10-2019-0090232", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서,상기 제어부는 상기 입력부와 연결되고, 상기 입력부로부터 신호를 전송받아 상기 액추에이터를 작동하고, 상기 액추에이터는 입력되는 신호에 대응하는 상기 로봇의 동작을 생성하는, 로봇 시스템."}
{"patent_id": "10-2019-0090232", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제8항에 있어서,상기 입력부는,광학센서 및 가속도센서 중 적어도 하나로 구비되는, 로봇 시스템."}
{"patent_id": "10-2019-0090232", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "로봇 시스템 제어방법으로서,단말이 로봇 및 서버와 연결되는 단계;상기 로봇 시스템이 캐릭터 동작 입력모드에 있는지 확인하는 단계;캐릭터 동작 입력모드인 경우, 상기 서버가 상기 캐릭터의 동작을 생성하는 단계; 및캐릭터 동작 재생모드인 경우, 상기 단말이 상기 캐릭터 동작을 영상으로 디스플레이하는 단계를 포함하고,공개특허 10-2019-0095189-4-상기 로봇은,상기 로봇의 각 부위를 움직이도록 작동하는 액추에이터;상기 로봇의 각 부위에 구비되고, 사용자의 신체가 일정범위 내에 있으면 이를 감지하는 근접센서(proximitysensor);상기 액추에이터 및 상기 근접센서와 연결되고, 상기 근접센서로부터 사용자의 신체가 일정범위 내에 있다는 신호를 전송받아 상기 액추에이터에 작동을 명령하는 제어부; 및상기 제어부와 연결되는 통신부를 포함하는,로봇 시스템 제어방법."}
{"patent_id": "10-2019-0090232", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항에 있어서,상기 단말이 상기 로봇 및 상기 서버와 연결되는 단계는,상기 로봇이 상기 단말과 통신가능하도록 연결되는 단계;상기 단말이 상기 로봇의 맥주소 및 ID를 인식하는 단계;상기 단말이 상기 서버와 통신가능하도록 연결되는 단계; 및상기 단말이 상기 서버가 제공하는 컨텐츠를 선택하는 단계를 포함하는, 로봇 시스템 제어방법."}
{"patent_id": "10-2019-0090232", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제11항에 있어서,상기 서버가 상기 캐릭터의 동작을 생성하는 단계는,상기 로봇이 복수의 동작을 생성하여 상기 단말에 전송하는 단계;상기 단말이 상기 로봇의 동작을 상기 서버로 전송하는 단계;상기 서버가 전송받은 복수의 상기 로봇의 동작을 조합하여 상기 캐릭터의 동작을 생성하는 단계; 및상기 서버가 생성된 상기 캐릭터의 동작을 저장하는 단계를 포함하는, 로봇 시스템 제어방법."}
{"patent_id": "10-2019-0090232", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제11항에 있어서,상기 단말이 상기 캐릭터 동작을 영상으로 디스플레이하는 단계는,상기 서버가 상기 캐릭터 동작을 상기 단말에 전송하는 단계;상기 단말이 상기 캐릭터 동작을 영상으로 디스플레이하는 단계; 및상기 캐릭터 동작을 변형하는 단계를 포함하는, 로봇 시스템 제어방법."}
{"patent_id": "10-2019-0090232", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제14항에 있어서,상기 캐릭터 동작을 변형하는 단계는,공개특허 10-2019-0095189-5-상기 로봇이 동작을 상기 단말로 전송하는 단계;상기 단말이 상기 로봇의 동작을 상기 서버로 전송하는 단계;상기 서버가 전송받는 상기 로봇의 동작을 기반으로 상기 캐릭터의 동작을 변형하는 단계;상기 서버가 상기 캐릭터의 변형된 동작을 저장하는 단계;상기 서버가 상기 캐릭터의 변형된 동작을 상기 단말로 전송하는 단계; 및상기 단말이 상기 캐릭터의 변형된 동작을 영상으로 디스플레이하는 단계를 포함하는, 로봇 시스템 제어방법."}
{"patent_id": "10-2019-0090232", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "로봇 시스템 및 그 제어방법이 개시된다. 로봇 시스템은 로봇, 로봇의 동작에 관한 정보를 저장하는 서버, 및 로 봇 및 서버와 통신하고, 로봇으로부터 로봇의 동작을 전송받고, 서버로부터 저장된 캐릭터의 동작을 전송받고, 로봇에 대응하는 캐릭터를 영상으로 디스플레이하는 단말을 포함할 수 있다. 로봇 시스템은 5G(Generation) 통신 에 따라 구축된 이동 통신망 상에서 무선신호를 송수신할 수 있다."}
{"patent_id": "10-2019-0090232", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "실시예는, 로봇 시스템 및 그 제어방법에 관한 것으로, 더욱 상세하게는 가상현실을 구현하는 로봇 시스템 및 그 제어방법에 관한 것이다."}
{"patent_id": "10-2019-0090232", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "이 부분에 기술된 내용은 단순히 실시예에 대한 배경 정보를 제공할 뿐 종래기술을 구성하는 것은 아니다. 가상현실(virtual reality)에 관한 연구가 활발히 진행되고 있고, 가상현실 기술을 이용한 다양한 컨텐츠가 제 공되고 있다. 이러한 가상현실은 게임, 로봇, 음악, 의학 기타 다양한 산업분야에서 응용이 확산되고 있다. 사용자는 가상현실로 진행되는 장면을 단순히 감상하는 것을 넘어서, 이러한 가상현실에 직접 참여하기를 원한 다. 예를 들어, 가상현실 게임에서 사용자는 가상공간에 존재하는 캐릭터가 자신이 원하는 대로 움직이도록 캐 릭더의 동작을 수시로 변경하는 것을 원할 수 있다. 이러한 이유로, 가상공간에 존재하는 캐릭터의 동작을 변경하기 위해, 사용자에게 편리한 캐릭터의 동작 입력장 치가 요구된다. 컴퓨터를 사용하여 캐릭터의 동작을 입력하는 경우 키보드, 마우스, 조이스틱 등을 사용할 수 있는데, 이러한 장치들은 사용자에게 불편할 뿐만 아니라, 다양한 동작의 입력하기가 어렵다. 한편, 사용자의 편의를 위해 캐릭터의 동작 입력장치는 비접촉식으로 구비되는 것이 적절하다. 비접촉식 입력장 치는 사용자의 피로, 스트레스 등을 줄일 수 있기 때문이다. 따라서, 캐릭터의 동작 입력장치로 움직이는 로봇 을 사용하고, 이러한 로봇을 비접촉식으로 움직일 수 있는 시스템을 고려해볼 필요가 있다. 미국등록특허 US 8734242 B2에는 액션 피규어와 함께 제공되는 시리얼 넘버를 이용해 온라인상의 게임에 접속해 아이템을 활용할 수 있는 시스템이 개시된다. 한국등록특허 10-1234111에는 손가락이나 손의 움직임만으로 시스템에 입력을 전달할 수 있는 비접촉 입력 인터 페이싱 장치 및 그 방법이 개시된다. 그러나, 상기 문헌들에는 로봇를 비접촉식으로 움직여 캐릭터의 동작을 입력하는 구성은 개시되지 않는다."}
{"patent_id": "10-2019-0090232", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "실시예에서는, 가상공간에 존재하는 캐릭터의 동작을 생성하기 위한 입력장치로 움직이는 로봇을 사용하는 방안 을 제시한다. 실시예에서는, 캐릭터의 동작을 입력하는 로봇이 비접촉식으로 작동하는 구성을 가질 수 있다. 실시예에서는, 로봇의 비접촉식 작동을 위해 근접센서(proximity sensor)를 사용하는 방안을 제시한다. 실시예가 이루고자 하는 기술적 과제는 이상에서 언급한 기술적 과제로 제한되지 않으며 언급되지 않은 또 다른"}
{"patent_id": "10-2019-0090232", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 2, "content": "기술적 과제들은 아래의 기재로부터 실시예가 속하는 기술분야에서 통상의 지식을 가진자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2019-0090232", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "전술한 과제를 달성하기 위해, 로봇은 사용자가 각 부위를 움직여 가상현실로 구현되는 캐릭터의 동작을 생성할 수 있다. 로봇 시스템은 로봇, 로봇의 동작에 관한 정보를 저장하는 서버, 및 로봇 및 서버와 통신하고, 로봇으로부터 로 봇의 동작을 전송받고, 서버로부터 저장된 캐릭터의 동작을 전송받고, 로봇에 대응하는 캐릭터를 영상으로 디스 플레이하는 단말을 포함할 수 있다. 로봇은 로봇의 각 부위를 움직이도록 작동하는 액추에이터, 로봇의 각 부위에 구비되고, 사용자의 신체가 일정 범위 내에 있으면 이를 감지하는 근접센서(proximity sensor), 액추에이터 및 근접센서와 연결되고, 근접센서로 부터 사용자의 신체가 일정범위 내에 있다는 신호를 전송받아 액추에이터에 작동을 명령하는 제어부, 및 제어부 와 연결되는 통신부를 포함할 수 있다. 캐릭터 동작 입력모드에서, 로봇은 복수의 동작을 생성하여 단말에 전송하고, 단말은 로봇의 동작을 서버로 전 송하고, 서버는, 전송받은 복수의 로봇의 동작을 조합하여 캐릭터의 동작을 생성할 수 있다. 캐릭터 동작 재생모드에서, 서버는 캐릭터의 동작을 단말에 전송하고, 단말은 캐릭터의 동작을 영상으로 디스플 레이할 수 있다. 캐릭터 동작 재생모드에서, 로봇은 동작을 단말로 전송하고, 단말은 로봇의 동작을 서버로 전송하고, 서버는, 전송받는 로봇의 동작을 기반으로 캐릭터의 동작을 변형하고, 캐릭터의 변형된 동작을 단말로 전송하고, 단말은 캐릭터의 변형된 동작을 영상으로 디스플레이할 수 있다. 로봇 시스템 제어방법은, 단말이 로봇 및 서버와 연결되는 단계, 로봇 시스템이 캐릭터 동작 입력모드에 있는지 확인하는 단계, 캐릭터 동작 입력모드인 경우, 서버가 캐릭터의 동작을 생성하는 단계, 및 캐릭터 동작 재생모 드인 경우, 단말이 캐릭터 동작을 영상으로 디스플레이하는 단계를 포함할 수 있다. 단말이 로봇 및 서버와 연결되는 단계는, 로봇이 단말과 통신가능하도록 연결되는 단계, 단말이 로봇의 맥주소 및 ID를 인식하는 단계, 단말이 서버와 통신가능하도록 연결되는 단계, 및 단말이 서버가 제공하는 컨텐츠를 선 택하는 단계를 포함할 수 있다. 서버가 캐릭터의 동작을 생성하는 단계는, 로봇이 복수의 동작을 생성하여 단말에 전송하는 단계, 단말이 로봇 의 동작을 서버로 전송하는 단계, 서버가 전송받은 복수의 로봇의 동작을 조합하여 캐릭터의 동작을 생성하는 단계, 및 서버가 생성된 캐릭터의 동작을 저장하는 단계를 포함할 수 있다. 단말이 캐릭터 동작을 영상으로 디스플레이하는 단계는, 서버가 캐릭터 동작을 단말에 전송하는 단계, 단말이 캐릭터 동작을 영상으로 디스플레이하는 단계, 및 캐릭터 동작을 변형하는 단계를 포함할 수 있다. 캐릭터 동작을 변형하는 단계는, 로봇이 동작을 단말로 전송하는 단계, 단말이 로봇의 동작을 서버로 전송하는 단계, 서버가 전송받는 로봇의 동작을 기반으로 캐릭터의 동작을 변형하는 단계, 서버가 캐릭터의 변형된 동작 을 저장하는 단계, 서버가 캐릭터의 변형된 동작을 단말로 전송하는 단계, 및 단말이 캐릭터의 변형된 동작을 영상으로 디스플레이하는 단계를 포함할 수 있다."}
{"patent_id": "10-2019-0090232", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "실시예에서, 사용자가 입체적인 형상을 가진 로봇을 사용하여 동작을 입력하므로, 게임, 디스플레이 컨텐츠에 대한 사용자의 몰입감을 향상시킬 수 있다. 실시예에서, 사용자가 근접센서를 구비한 로봇을 사용함으로써, 사용자는 편리하게 원하는 캐릭터 동작을 생성 할 수 있다. 실시예에서, 서버는 인공지능 모델 학습을 통해 로봇의 동작을 기반으로 캐릭터 동작을 생성하므로, 다양하고 복잡한 캐릭터 동작을 생성할 수 있다."}
{"patent_id": "10-2019-0090232", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 첨부된 도면들을 참조하여 실시예를 상세히 설명한다. 실시예는 다양한 변경을 가할 수 있고 여러 가지 형태를 가질 수 있는바, 특정 실시예들을 도면에 예시하고 본문에 상세하게 설명하고자 한다. 그러나 이는 실시 예를 특정한 개시 형태에 대해 한정하려는 것이 아니며, 실시예의 사상 및 기술 범위에 포함되는 모든 변경, 균 등물 내지 대체물을 포함하는 것으로 이해되어야 한다. \"제1\", \"제2\" 등의 용어는 다양한 구성요소들을 설명하는 데 사용될 수 있지만, 상기 구성요소들은 상기 용어들 에 의해 한정되어서는 안 된다. 상기 용어들은 하나의 구성요소를 다른 구성요소로부터 구별하는 목적으로 사용 된다. 또한, 실시예의 구성 및 작용을 고려하여 특별히 정의된 용어들은 실시예를 설명하기 위한 것일 뿐이고, 실시예의 범위를 한정하는 것이 아니다. 실시예의 설명에 있어서, 각 element의 \"상(위)\" 또는 \"하(아래)(on or under)\"에 형성되는 것으로 기재되는 경 우에 있어, 상(위) 또는 하(아래)(on or under)는 두개의 element가 서로 직접(directly)접촉되거나 하나 이상 의 다른 element가 상기 두 element사이에 배치되어(indirectly) 형성되는 것을 모두 포함한다. 또한 “상(위)\" 또는 \"하(아래)(on or under)”로 표현되는 경우 하나의 element를 기준으로 위쪽 방향뿐만 아니라 아래쪽 방향 의 의미도 포함할 수 있다. 또한, 이하에서 이용되는 \"상/상부/위\" 및 \"하/하부/아래\" 등과 같은 관계적 용어들은, 그런 실체 또는 요소들 간의 어떠한 물리적 또는 논리적 관계 또는 순서를 반드시 요구하거나 내포하지는 않으면서, 어느 한 실체 또는 요소를 다른 실체 또는 요소와 구별하기 위해서 이용될 수도 있다. 도 1은 일 실시예에 따른 로봇 시스템을 설명하기 위한 도면이다. 로봇 시스템은 사용자가 동작을 입 력하고, 입력된 동작은 단말에 캐릭터의 동작으로 디스플레이될 수 있다. 이때, 사용자가 로봇을 움 직여 동작을 생성하고, 로봇의 동작을 기반으로 캐릭터의 동작이 생성되고, 생성된 캐릭터의 동작이 단말 에 디스플레이될 수 있다. 로봇은 현실공간에 존재하는 것이고, 캐릭터는 가상공간에 존재하는 것으 로 단말에 디스플레이되어 사용자가 눈으로 볼 수 있다. 로봇 시스템은 로봇, 서버 및 단말을 포함할 수 있다. 로봇은 사용자가 각 부위를 움직여 가상현실로 구현되는 캐릭터의 동작을 생성할 수 있다. 따라서, 로봇 은 팔, 다리, 머리를 가진 인체와 유사한 형상을 가질수 있고, 각 부위가 움직일 수 있도록 마디와 관절로 구성될 수 있다. 서버는 상기 로봇의 동작에 관한 정보를 저장할 수 있다. 서버는 단말을 통해 전송받은 로 봇의 동작을 기반으로, 단말에 디스플레이되는 캐릭터의 동작을 생성할 수 있다. 단말은 상기 로봇 및 상기 서버와 통신할 수 있다. 단말은 상기 로봇으로부터 상기 로봇의 동작을 전송받고, 상기 서버로부터 저장된 상기 캐릭터의 동작을 전송받고, 상기 로봇에 대응하는 캐릭터를 영상으로 디스플레이할 수 있다. 단말은 움직이는 캐릭터를 영상으로 디스플레이할 수 있는 것으로, 스마트폰, 랩탑 컴퓨터, 데스크탑 컴퓨 터, 타블랫PC 기타 다양한 형태의 것일 수 있다.한편, 로봇과 서버도 서로 통신할 수 있다. 예를 들어, 로봇은 서버로부터 동작에 필요한 소프트웨어를 전송받을 수 있고, 이러한 소프트웨어를 수시로 업데이트받을 수 있다. 도 2는 일 실시예에 따른 캐릭터를 설명하기 위한 도면이다. 도 3은 다른 실시예에 따른 캐릭터를 설명하기 위 한 도면이다. 도 2 및 도 3을 참조하면, 단말에 함께 디스플레이되는 캐릭터는 복수일 수 있다. 이때, 하나의 캐릭터는 하나의 로봇과 대응할 수 있다. 따라서, 상기 로봇 및 상기 캐릭터는 복수로 구비될 수 있고, 서로 다른 복수의 로봇으로부터 입력되는 로봇의 동작은 서버에서 조합되어 동일한 가상공간에서 복 수의 캐릭터들이 동시에 디스플레이될 수 있다. 물론, 동시에 디스플레이되는 복수의 캐릭터들의 동작은 서로 다를 수도 있다. 일 실시예에 따른 로봇 시스템에서는 하나의 캐릭터가 가상공간에 존재하여 단말에 디스플레이되고, 캐릭터의 동작 생성에 하나의 로봇이 사용될 수 있다. 한편, 다른 실시예에 따른 로봇 시스템에서는, 서로 다른 사용자가 각각의 로봇과 단말을 사용 하고, 동일한 서버로 서로 연결되고, 각 사용자가 담당하는 캐릭터들은 동일한 가상공간에 존재할 수 있다. 이하에서는 복수의 캐릭터들이 동일한 가상공간에 존재하는 경우를 중심으로 설명한다. 하나의 캐릭터가 가상공간에 존재하는 경우의 로봇 시스템 및 그 제어방법은 이하의 설명에서 자명하게 도출된다. 도 2를 참조하면, 서로 결투를 하는 게임에서, 캐릭터1과 캐릭터2는 동시에 서로 다른 로봇으로부터 입력 되는 동작을 기반으로 서로 다른 동작을 실시간으로 구현할 수 있다. 도 3을 참조하면, 각 캐릭터들은 단말에서 음악이 재생되는 경우, 재생되는 음악에 맞춰 춤을 출 수 있다. 이때, 캐릭터1 내지 캐릭터3은 동시에 서로 다른 로봇으로부터 입력되는 동작을 기반으로 서로 다른 동작 을 실시간으로 구현할 수 있다. 또한, 캐릭터1 내지 캐릭터3의 군무의 특징상 동일한 동작을 구현할 수도 있다. 도 2 및 도 3을 참조하여 전술한 경우 외에도, 실시예에 따른 로봇 시스템은 다양한 종류와 상황에서 캐릭 터의 동작을 구현하기 위해 사용될 수 있다. 이하에서는 명확한 설명을 위해, 도 2와 도 3에서 구현된 캐릭터를 중심으로 설명한다. 명확한 설명을 위해, 도 2의 경우를 '게임시나리오', 도 3의 경우를 '춤시나리오'라고 명명 한다. 도 4는 일 실시예에 따른 로봇의 구조를 설명하기 위한 도면이다. 로봇은 인체와 유사한 형상을 가질 수 있고, 각 부위가 움직일 수 있도록 마디와 관절로 구성될 수 있다. 로봇은 액추에이터, 근접센서 , 제어부, 통신부, 입력부를 포함할 수 있다. 액추에이터는 로봇의 관절에 구비되어 상기 로봇의 각 부위를 움직이도록 작동할 수 있다. 액추 에이터는 제어부의 작동명령에 따라 작동하여 관절을 회전시킴으로써 각 부위를 움직이고, 이로써 로 봇은 다양한 동작을 생성할 수 있다. 근접센서(proximity sensor)는 로봇의 각 부위에 구비되고, 사용자의 신체가 일정범위 내에 있으면 이를 감지할 수 있다. 상기 근접센서는 사용자의 신체가 일정거리 내로 들어오면 이를 감지할 수 있다. 근접센서는 예를 들어, 감지수단으로 초음파를 사용하는 초음파센서, 광(light)를 사용하는 광학센서 , 감지대상의 유전상수를 측정하여 감지하는 용량성(capacitive) 센서, 기타 전기장 또는 자기장을 이용하 는 센서 등이 있다. 근접센서는 사용자의 신체가 로봇에 접근하면 이를 감지하여 상기 제어부에 감지신호를 전송할 수 있다. 근접센서는 로봇의 각 부위에 적어도 하나 구비될 수 있다. 따라서, 사용자가 손가락 등을 근접센서 에 근접시키면, 각 근접센서들은 이를 감지하고, 액추에이터가 작동함으로써, 사용자는 원하는 로봇의 동작을 생성할 수 있다. 제어부는 상기 액추에이터 및 상기 근접센서와 연결되고, 액추에이터를 작동시킬 수 있다. 즉, 제어부는 상기 근접센서로부터 사용자의 신체가 일정범위 내에 있다는 신호를 전송받아 상기 액 추에이터에 작동을 명령할 수 있다. 액추에이터, 근접센서, 제어부에 의한 로봇의 동작생성은 도 5를 참조하여 하기에 구체적 으로 설명한다. 통신부는 상기 제어부와 연결되고, 로봇은 통신부를 통해 서버 및 단말과 연결 되어 통신할 수 있다. 통신부는 이동통신 모듈 및 무선 인터넷 모듈 중에서 적어도 하나를 포함하도록 구성될 수 있다. 그 밖에 통신부는 근거리 통신 모듈을 추가로 포함할 수 있다. 이동통신 모듈은, 이동통신을 위한 기술표준들 또는 통신방식(예를 들어, GSM(Global System for Mobile communication), CDMA(Code Division Multi Access), CDMA2000(Code Division Multi Access 2000), EV- DO(Enhanced Voice-Data Optimized or Enhanced Voice-Data Only), WCDMA(Wideband CDMA), HSDPA(High Speed Downlink Packet Access), HSUPA(High Speed Uplink Packet Access), LTE(Long Term Evolution), LTE-A(Long Term Evolution-Advanced), 5G 이동통신 등)에 따라 구축된 이동 통신망 상에서 기지국, 외부의 단말, 서 버 중 적어도 하나와 무선 신호를 송수신한다. 무선 인터넷 모듈은 무선 인터넷 접속을 위한 모듈을 말하는 것으로, 로봇에 내장되거나 외장될 수 있다. 무선 인터넷 모듈은 무선 인터넷 기술들에 따른 통신망에서 무선 신호를 송수신하도록 이루어진다. 로봇은 5G 네트워크를 통해 서버, 각종의 통신가능한 단말과 데이터를 전송하고 수신할 수 있다. 특히 로봇은 5G 네트워크를 통해 모바일 브로드밴드(Enhanced Mobile Broadband, eMBB), URLLC(Ultra-reliable and low latency communications) 및 mMTC(Massive Machine-type communications) 중에 서 적어도 하나의 서비스를 이용하여 서버, 단말과 데이터 통신을 할 수 있다. eMBB(Enhanced Mobile Broadband)는 모바일 브로드밴드 서비스로, 이를 통해 멀티미디어 콘텐츠, 무선데이터 액 세스 등이 제공된다. 또한, 폭발적으로 증가하고 있는 모바일 트래픽을 수용하기 위한 핫스팟 (hot spot)과 광 대역 커버리지 등 보다 향상된 모바일 서비스가 eMBB를 통해 제공될 수 있다. 핫스팟을 통해 사용자 이동성이 작고 밀도가 높은 지역으로 대용량 트래픽이 수용될 수 있다. 광대역 커버리지를 통해 넓고 안정적인 무선 환경 과 사용자 이동성이 보장될 수 있다. URLLC(Ultra-reliable and low latency communications) 서비스는 데이터 송수신의 신뢰성과 전송 지연 측면에 서 기존 LTE 보다 훨씬 엄격한 요구사항을 정의하고 있으며, 산업 현장의 생산 프로세스 자동화, 원격 진료, 원 격 수술, 운송, 안전 등을 위한 5G 서비스가 여기에 해당한다. mMTC(Massive Machine-type communications)는 비교적 작은 양의 데이터 전송이 요구되는 전송지연에 민감하지 않은 서비스이다. 센서 등과 같이 일반 휴대폰 보다 훨씬 더 많은 수의 단말들이 동시에 무선액세스 네트 워크에 mMTC에 의해 접속할 수 있다. 이 경우, 단말의 통신모듈 가격은 저렴해야 하고, 배터리 교체나 재 충전 없이 수년 동안 동작할 수 있도록 향상된 전력 효율 및 전력 절감 기술이 요구된다. 도 5는 일 실시예에 따른 로봇의 동작을 설명하기 위한 도면이다. 예를 들어, 사용자가 손가락으로 로봇 의 동작을 생성하는 경우, 손가락을 로봇의 일부에 가져다 대면, 로봇에 구비되는 근접센서 가 손가락이 설정된 범위 내로 들어왔다는 것을 감지할 수 있다. 손가락을 감지한 근접센서는 제어부에 신호를 전송하고, 제어부는 감지신호를 받으면 액추에이 터를 작동시키고, 액추에이터는 로봇의 형태를 변경하여 로봇의 동작을 생성한다. 근접센서는 사용자의 손가락과 접촉하지 않고 손가락을 감지하고 액추에이터는 근접센서가 손가 락을 감지하는 동안 계속 작동할 수 있으므로, 사용자의 손가락이 계속 이동하면 근접센서와 손가락은 일 정거리를 유지하면서 손가락이 이동하는 방향으로 이동할 수 있다. 이러한 방식으로, 도 5에 도시된 바와 같이, 사용자는 손가락을 지속적으로 이동하여 로봇의 형태를 (a)에 서 (d)까지 이동시켜 로봇의 동작을 생성할 수 있다. 도 6은 다른 실시예에 따른 로봇의 동작을 설명하기 위한 도면이다. 로봇은 입력부를 구비하고, 사용자는 입력부를 이용하여 로봇의 동작을 생성할 수 있다. 입력부는 상기 로봇에 구비되고, 상기 로봇의 동작을 입력받을 수 있다. 이에 따라, 상기 로봇 은 입력부에 입력되는 신호에 대응하는 동작을 생성할 수 있다. 제어부는 상기 입력부와 연결되고, 상기 입력부로부터 신호를 전송받아 상기 액추에이터를 작동할 수 있다. 액추에이터는 입력되는 신호에 대응하는 상기 로봇의 동작을 생성할 수 있다. 여기 서, 입력되는 신호에 대응하는 로봇의 동작은 설정된 것일 수 있다. 입력부는 광학센서 및 가속도센서 중 적어도 하나로 구비될 수 있다. 도 6을 참조하면, 광학센서 와 가속도센서는 예를 들어, 형태의 변경이 없는 로봇의 지지대에 구비될 수 있다. 이때, 가속 도센서는 지지대에 내장되어 도 6에 도시되지 않는다. 입력부가 광학센서로 구비되는 경우, 예를 들어, 사용자는 광학센서에 근접한 위치에서 손가락 을 움직임으로써 로봇의 동작을 구현할 수 있다. 광학센서는 손가락의 움직임을 감지하고, 이에 따라 액추에이터가 작동하여 로봇의 동작을 생성할 수 있다. 예를 들어, 광학센서에 사용자의 손가락 움직임이 감지되면 로봇은 걸어가는 동작을 연출하는 것으로 설정되는 경우, 액추에이터는 연속적으로 작동하여, 도 6의 (b)에 도시된 바와 같이, 팔을 전후로 움직이 는 동작을 계속 연출할 수 있다. 다시 광학센서에 손가락 움직임이 감지되면 이러한 걸어가는 동작을 멈추 도록 설정될 수도 있다. 입력부가 가속도센서로 구비되는 경우, 예를 들어, 사용자는 로봇을 밀거나 당겨 로봇의 위치를 전체적으로 이동시킴으로써 로봇의 동작을 구현할 수 있다. 가속도센서는 로봇의 위치이동을 감지하 고, 이에 따라 액추에이터가 작동하여 로봇의 동작을 생성할 수 있다. 예를 들어, 가속도센서에 로봇의 위치이동이 감지되면 로봇은 달려가는 동작을 연출하는 것으로 설정 되는 경우, 액추에이터는 연속적으로 작동하여 로봇의 달려가는 동작을 계속 연출할 수 있다. 다시 사용자가 로봇을 밀거나 당기면 이러한 달려가는 동작을 멈추도록 설정될 수도 있다. 근접센서의 경우와 마찬가지로, 입력부를 이용하여 생성되는 로봇의 동작은 캐릭터의 동작으로 구현될 수 있다. 로봇은 동작의 입력을 위해 움직일 수 있으나, 단말로부터 작동명령을 전송받아, 단말에 디스플 레이되는 캐릭터의 동작과 동일 또는 유사한 동작을 재생할 수도 있다. 예를 들어, 서버는 캐릭터의 동작에 관한 정보를 단말로 전송하고, 단말은 전송받은 정보를 기 반으로 캐릭터가 움직이는 모습을 디스플레이할 수 있다. 또한 단말은 캐릭터의 동작에 관한 정보를 로봇 의 제어부로 전송하고, 제어부는 전송받은 정보를 기반으로 액추에이터를 작동하여, 로봇 은 캐릭터와 동일 또는 유사한 동작을 재생할 수 있다. 로봇 시스템은 캐릭터 동작 입력모드 또는 캐릭터 동작 재생모드로 작동할 수 있다. 즉, 로봇 시스템 은 입력모드에서 캐릭터의 동작을 생성하고 재생모드에서 캐릭터의 동작을 단말에 디스플레이할 수 있다. 캐릭터 동작 입력모드에서는 사용자가 로봇을 움직여 캐릭터의 동작을 입력할 수 있다. 캐릭터 동작 입력 모드에서, 상기 로봇은 복수의 동작을 생성하여 상기 단말에 전송할 수 있다. 사용자는 로봇의 각 관절과 마디를 움직이고, 이에 따라 로봇은 액추에이터를 작동하여 동작을 생성할 수 있다. 로봇 의 동작은 복수로 생성될 수 있고, 각 동작은 순차적으로 생성될 수 있다. 상기 단말은 상기 로봇의 동작을 상기 서버로 전송할 수 있다. 서버는 로봇의 동작을 기반으로 캐릭터의 동작을 생성할 수 있다. 서버로 입력되는 로봇의 동작은 제한된 움직임이 가능한 구조의 로봇을 움직여 생성된 것이므로, 이를 그대로 캐릭터의 동작으로 하면 원하는 캐릭터의 동작을 생성하기 어려울 수 있다. 또한 서버 로 순차적으로 입력되는 복수의 로봇의 동작들은 불연속적일 수 있으므로, 이들을 서로 조합하여 연 속적인 캐릭터 동작을 생성할 필요가 있다. 따라서, 서버는 단말로부터 전송받은 복수의 상기 로봇의 동작을 조합하여 상기 캐릭터의 동작 을 생성할 수 있고, 생성된 캐릭터의 동작은 로봇의 동작보다 다양한 움직임을 가지고 연속적일 수 있다. 즉, 로봇의 동작과 캐릭터의 동작은 차이가 있을 수 있고, 이러한 차이는 서버에서 생성될 수 있다. 즉, 서버는 로봇의 동작으로부터 차이를 가진 캐릭터의 동작을 생성하기 위해, 예를 들어, 인공지능 모델 학습을 진행할 수 있다. 인공지능 모델 학습을 위해 서버에는 인공지능모듈이 구비되고, 인공지능모 듈에서 인공지능 모델 학습이 진행될 수 있다.인공 지능(artificial intelligence, AI)은 인간의 지능으로 할 수 있는 사고, 학습, 자기계발 등을 컴퓨터가 할 수 있도록 하는 방법을 연구하는 컴퓨터 공학 및 정보기술의 한 분야로, 컴퓨터가 인간의 지능적인 행동을 모방할 수 있도록 하는 것을 의미한다. 인공지능모듈은 인공지능 모델 학습을 통해, 로봇의 동작으로부터 캐릭터의 동작을 도출할 수 있다. 인공 지능모듈로 일련의 로봇의 동작이 입력되면, 인공지능모듈은 학습을 통해 캐릭터의 동작을 도출할 수 있다. 인공지능 모델은 예를 들어, 의사결정나무(Decision Tree)나 베이지안 망(Bayesian network), 서포트벡터머신 (SVM: support vector machine), 그리고 인공 신경망(ANN: Artificial Neural Network) 등이 있다. 인공 신경망은 예를 들어, DNN(Deep Neural Network), RNN(Recurrent Neural Network), BRDNN(Bidirectional Recurrent Deep Neural Network), MLP(Multilayer Perceptron), CNN(Convolutional Neural Network)와 같은 방식의 인공지능 모델들을 포함할 수 있으나, 이에 한정되지 않는다. 예를 들어, 인공지능 모델 중 RNN을 사용하여 학습하는 경우, 입력인자인 순차적으로 생성된 복수의 로봇 의 동작이 인공 신경망에 입력되고, 인경 신경망 내부에서 복수의 로봇의 동작의 조합, 연산이 진행되어, 로봇의 동작에 대응하는 캐리터의 동작이 도출될 수 있다. 이때, 도출된 캐릭터의 동작은 로봇의 동 작을 다소 변경하여 로봇의 동작보다 다양하고 연속적인 동작일 수 있다. 인공지능 모델 학습을 통해 서버는 캐릭터의 동작을 생성하고, 생성된 상기 캐릭터의 동작은 상기 서버 에 저장될 수 있다. 서버에 저장된 캐릭터의 동작은 캐릭터 동작 재생모드에서 단말에 디스플레 이될 수 있다. 캐릭터 동작 재생모드에서는 생성된 캐릭터 동작을 단말에서 디스플레이할 수 있다. 캐릭터 동작 재생모드 에서, 상기 서버는 상기 캐릭터 동작을 상기 단말에 전송하고, 상기 단말은 상기 캐릭터의 동작 을 영상으로 디스플레이할 수 있다. 이때, 캐릭터의 동작은 전술한 캐릭터 동작 입력모드에서 서버에 저장 된 것일 수 있다. 도 2를 참조하면, 게임시나리오의 경우, 캐릭터 동작 재생모드에서 캐릭터1과 캐릭터2는 서로 공격과 방어를 주 고받는 동작을 연출하고, 캐릭터1과 캐릭터2의 동작은 서로 다른 로봇의 동작이 서버로 전송되고, 서 버에서 로봇의 동작을 기반으로 인공지능 모델 학습을 거쳐 생성한 것일 수 있다. 도 3을 참조하면, 춤시나리오의 경우, 캐릭터 동작 재생모드에서 캐릭터1 내지 캐릭터3은 부분적으로 서로 다른 동작과 부분적으로 서로 일치된 동작을 연출하고, 캐릭터1 내지 캐릭터3의 동작은 서로 다른 로봇의 동작 이 서버로 전송되고, 서버에서 로봇의 동작을 기반으로 인공지능 모델 학습을 거쳐 생성한 것일 수 있다. 도 2 및 도 3에서, 단말에 디스플레이되는 캐릭터 동작은 복수의 캐릭터들이 서로 다르거나 일치된 동작을 연출하는데, 이러한 복수의 캐릭터들의 전체적인 동작은 서버가 인공지능 모델 학습을 거쳐 생성할 수 있 다. 한편, 캐릭터 동작 재생모드에서, 캐릭터의 동작이 재생되는 동안에 사용자가 개입하여 캐릭터의 동작을 실시간 으로 변형할 필요가 있다. 특히, 게임시나리오에서 게임을 진행하기 위해, 사용자는 재생되는 캐릭터 동작을 그 대로 두지않고 수시로 변경할 필요가 있다. 춤시나리오에서는, 사용자가 단말에서 재생되는 음악에 맞춰 재생되는 캐릭터의 동작을 실시간으로 변경하 려는 욕구를 가질 수 있으므로, 역시 캐릭터의 동작을 수시로 변경할 수 있도록 함이 적절하다. 따라서, 로봇 시스템은 캐릭터 동작 재생모드에서 로봇의 동작을 기반으로 캐릭터의 동작을 수시로 변경할 수 있다. 캐릭터 동작 재생모드에서, 사용자는 로봇을 움직여 로봇의 동작을 생성할 수 있다. 상기 로봇은 동작을 상기 단말로 전송하고, 상기 단말은 상기 로봇의 동작을 상기 서버 로 전송할 수 있다. 서버는, 전송받는 상기 로봇의 동작을 기반으로 상기 캐릭터의 동작을 변형하고, 상기 캐릭터의 변형 된 동작을 상기 단말로 전송하고, 상기 단말은 상기 캐릭터의 변형된 동작을 영상으로 디스플레이할 수 있다. 캐릭터의 변형된 동작은 전술한 캐릭터 동작 입력모드에서 서버가 생성하고, 서버에 저장된 것일 수 있다. 즉, 캐릭터 동작 재생모드에서, 서버가 로봇의 동작을 전송받으면, 서버는 저장된 캐릭터 의 동작들 중 전송받은 로봇의 동작에 대응하는 것을 선택하여 캐릭터의 변형된 동작을 단말로 전송 하고, 단말은 전송받은 캐릭터의 변형된 동작을 디스플레이할 수 있다. 한편, 전술한 바와 같이, 로봇 및 캐릭터는 복수로 구비될 수 있다. 따라서, 서버는 복수의 로봇 으로부터 복수의 동작을 각각 전송받을 수 있고, 이에 따라 각각의 캐릭터마다 변형된 동작을 생성할 수 있다. 이때, 서버는 복수의 상기 로봇으로부터 전송되는 각각의 동작을 조합하여 동일한 가상공간에 존재하 는 복수의 캐릭터 전체의 동작을 생성할 수 있다. 다시 도 2 및 도 3을 참조하면, 단말에 디스플레이되는 캐릭터의 변형된 동작은 복수의 캐릭터들이 서로 다르거나 일치된 동작을 연출하여 전체적으로 조화를 이룰 수 있다. 이러한 복수의 캐릭터들의 전체적인 동작은, 전술한 바와 같이, 서버가 인공지능 모델 학습을 거쳐 생성할 수 있다. 서버에서 생성된 상기 캐릭터의 변형된 동작은 상기 서버에 저장될 수 있다. 서버에 저장된 캐 릭터의 변형된 동작은 캐릭터 동작 재생모드에서 캐릭터의 동작을 연출하는데 사용될 수 있다. 즉, 서버는 캐릭터 동작 입력모드와 캐릭터 동작 재생모드에서 생성된 캐릭터의 동작을 저장하여 다른 캐릭터 동작 재생모 드에서 사용할 수 있다. 도 7은 일 실시예에 따른 로봇 시스템 제어방법을 설명하기 위한 도면이다. 이하에서, 로봇 시스템의 제어방법의 설명에 있어서 전술한 내용과 중복되는 부분은 설명이 생략될 수 있다. 로봇 시스템의 제어를 위해, 단말이 로봇 및 서버와 연결될 수 있다(S110). 연결 완료 후, 상기 로봇 시스템이 캐릭터 동작 입력모드에 있는지 확인할 수 있다(S120). 이러한 확인은 단말과 서버가 진행할 수 있다. 예를 들어, 단말은 사용자가 모드를 선택하는 입력을 받고, 이 에 따라 단말과 상기 단말에 연결된 서버는 캐릭터 동작 입력모드인지 캐릭터 동작 재생모드인 지 확인할 수 있다. 캐릭터 동작 입력모드인 경우, 상기 서버가 상기 캐릭터의 동작을 생성할 수 있다(S130). 캐릭터 동작 재 생모드인 경우, 상기 단말이 상기 캐릭터 동작을 영상으로 디스플레이할 수 있다(S140). 이하에서, S110, S130, S140 단계에 대해 구체적으로 설명한다. 도 8은 일 실시예에 따른, 단말이 로봇 및 서버와 연결되는 단계(S110)를 설명하기 위한 도면이 다. S110 단계에서, 로봇이 상기 단말과 통신가능하도록 연결될 수 있다(S111). 로봇의 통신부(14 0)와 단말이 서로 통신가능하도록 연결될 수 있다. 단말이 상기 로봇의 맥주소 및 ID를 인식할 수 있다(S112). 이로써, 단말과 로봇의 연결은 완료되고, 단말은 로봇의 맥주소 및 ID를 파악하여 상기 로봇의 작동특성을 알 수 있고, 이에 따라 로봇의 동작에 관한 정보는 단말로 전송될 수 있다. 상기 단말이 상기 서버와 통신가능하도록 연결될 수 있다(S113). 단말이 상기 로봇 및 상 기 서버와 각각 연결됨으로써, 로봇은 서버와 연결될 수 있다. 상기 단말이 상기 서버가 제공하는 컨텐츠를 선택할 수 있다(S114). 사용자는 서버가 제공하는 컨텐츠를 단말을 통해 선택하고, 이에 따라 단말에 의해 서버가 제공하는 컨텐츠가 선택된다. 선택가능한 컨텐츠는 예를 들어 도 2에 도시된 게임시나리오, 도 3에 도시된 춤시나리오 기타 다양한 것일 수 있다. 로봇 시스템은 선택된 컨텐츠가 가진 내용에 따라 캐릭터의 동작생성, 캐릭터의 동작재생, 음악의 재생 기 타 다양한 작업을 진행할 수 있다. 한편, 로봇은 서버와 직접 연결되어, 서버로부터 업데이트 등을 제공받을 수 있다. 로봇과 서버의 연결은 전술한 로봇과 단말의 연결과 유사한 방식으로 진행될 수 있다. 도 9는 일 실시예에 따른, 서버가 캐릭터의 동작을 생성하는 단계(S130)를 설명하기 위한 도면이다. S130 단계에서, 로봇이 복수의 동작을 생성하여 상기 단말에 전송할 수 있다(S131). 로봇의 동 작은 사용자가 로봇을 움직여 생성하고, 복수의 동작이 순차적으로 생성될 수 있다. 단말이 상기 로봇의 동작을 상기 서버로 전송할 수 있다(S132). 서버가 전송받은 복수의 상기 로봇의 동작을 조합하여 상기 캐릭터의 동작을 생성할 수 있다(S133). 서버가 생성하는 캐릭터의 동작은 로봇의 동작보다 다양한 움직임을 가지고 연속적일 수 있다. 전술한 바와 같이, 서버는 로봇의 동작으로부터 차이를 가진 캐릭터의 동작을 생성하기 위해, 예를 들어, 인공지능 모델 학습을 진행할 수 있다. 서버가 생성된 상기 캐릭터의 동작을 저장할 수 있다(S134). 서버에 저장된 캐릭터의 동작은 캐릭터 동작 재생모드에서 단말에 디스플레이될 수 있다. 도 10은 일 실시예에 따른, 단말이 캐릭터 동작을 영상으로 디스플레이하는 단계(S140)를 설명하기 위한 도면이다. S140 단계에서, 서버가 상기 캐릭터 동작을 상기 단말에 전송할 수 있다(S141). 단말이 상기 캐 릭터 동작을 영상으로 디스플레이할 수 있다(S142). 캐릭터 동작이 디스플레이되는 상황에서, 캐릭터 동작을 변 형할 수 있다(S143). 도 11은 일 실시예에 따른, 캐릭터 동작을 변형하는 단계(S143)를 설명하기 위한 도면이다. S143 단계에서, 로봇이 생성된 로봇의 동작을 상기 단말로 전송할 수 있다(S1431). 이때, 로봇 의 동작은 캐릭터 동작이 디스플레이되는 상황에서 사용자가 생성한 것이다. 단말이 상기 로봇의 동작을 상기 서버로 전송할 수 있다(S1432). 서버가 전송받는 상기 로봇의 동작을 기반으로 상기 캐릭터의 동작을 변형할 수 있다(S1433). 캐릭터 의 변형된 동작은 전술한 캐릭터 동작 입력모드에서 서버가 생성하고, 서버에 저장된 것일 수 있다. 즉, 캐릭터 동작 재생모드에서, 서버가 로봇의 동작을 전송받으면, 서버는 저장된 캐릭터의 동 작들 중 전송받은 로봇의 동작에 대응하는 것을 선택하여 캐릭터의 동작을 변형할 수 있다. 서버가 상기 캐릭터의 변형된 동작을 저장할 수 있다(S1434). 서버에 저장된 캐릭터의 변형된 동작은 캐릭터 동작 재생모드에서 캐릭터의 동작을 연출하는데 사용될 수 있다. 즉, 서버는 캐릭터 동작 입력모드 와 캐릭터 동작 재생모드에서 생성된 캐릭터의 동작을 저장하여 다른 캐릭터 동작 재생모드에서 사용할 수 있다. 서버가 상기 캐릭터의 변형된 동작을 상기 단말로 전송할 수 있다(S1435). 단말이 상기 캐릭터의 변형된 동작을 영상으로 디스플레이할 수 있다(S1436). 사용자가 입체적인 형상을 가진 로봇을 사용하여 동작을 입력하므로, 게임, 디스플레이 컨텐츠에 대한 사 용자의 몰입감을 향상시킬 수 있다. 사용자가 근접센서를 구비한 로봇을 사용함으로써, 사용자는 편리하게 원하는 캐릭터 동작을 생성할 수 있다. 서버는 인공지능 모델 학습을 통해 로봇의 동작을 기반으로 캐릭터 동작을 생성하므로, 다양하고 복 잡한 캐릭터 동작을 생성할 수 있다. 실시예와 관련하여 전술한 바와 같이 몇 가지만을 기술하였지만, 이외에도 다양한 형태의 실시가 가능하다. 앞 서 설명한 실시예들의 기술적 내용들은 서로 양립할 수 없는 기술이 아닌 이상은 다양한 형태로 조합될 수 있으 며, 이를 통해 새로운 실시형태로 구현될 수도 있다."}
{"patent_id": "10-2019-0090232", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 일 실시예에 따른 로봇 시스템을 설명하기 위한 도면이다. 도 2는 일 실시예에 따른 캐릭터를 설명하기 위한 도면이다.도 3은 다른 실시예에 따른 캐릭터를 설명하기 위한 도면이다. 도 4는 일 실시예에 따른 로봇의 구조를 설명하기 위한 도면이다. 도 5는 일 실시예에 따른 로봇의 동작을 설명하기 위한 도면이다. 도 6은 다른 실시예에 따른 로봇의 동작을 설명하기 위한 도면이다. 도 7은 일 실시예에 따른 로봇 시스템 제어방법을 설명하기 위한 도면이다. 도 8은 일 실시예에 따른, 단말이 로봇 및 서버와 연결되는 단계를 설명하기 위한 도면이다. 도 9는 일 실시예에 따른, 서버가 캐릭터의 동작을 생성하는 단계를 설명하기 위한 도면이다. 도 10은 일 실시예에 따른, 단말이 캐릭터 동작을 영상으로 디스플레이하는 단계를 설명하기 위한 도면이다. 도 11은 일 실시예에 따른, 캐릭터 동작을 변형하는 단계를 설명하기 위한 도면이다."}
