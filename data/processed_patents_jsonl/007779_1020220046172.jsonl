{"patent_id": "10-2022-0046172", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0054242", "출원번호": "10-2022-0046172", "발명의 명칭": "전자 장치 및 그 제어 방법", "출원인": "삼성전자주식회사", "발명자": "박소윤"}}
{"patent_id": "10-2022-0046172", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "전자 장치에 있어서,마이크;통신 회로를 포함하는 통신 인터페이스;제1 언어에 대응되는 제1 인코더 및 제1 디코더를 저장하는 메모리; 및상기 마이크를 통해 상기 제1 언어의 사용자 음성이 수신되면, 상기 사용자 음성에 대응되는 상기 제1 언어의텍스트를 획득하고, 상기 제1 언어의 텍스트를 상기 제1 인코더에 입력하여 제1 특징 벡터를 획득하고,상기 통신 인터페이스를 통해 상기 제1 특징 벡터를 외부 장치로 전송하며,상기 통신 인터페이스를 통해 상기 외부 장치로부터 제2 특징 벡터가 수신되면, 상기 제2 특징 벡터를 상기 제1디코더에 입력하여 상기 제2 특징 벡터에 대응되는 상기 제1 언어의 텍스트를 획득하는 프로세서;를 포함하는,전자 장치."}
{"patent_id": "10-2022-0046172", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 제1 인코더는,제1 언어의 제1 텍스트 및 벡터 공간 상의 특징 벡터를 입력 데이터 및 출력 데이터로 하여 학습된 모델이고,상기 제1 언어와 상이한 제2 언어에 대응되는 제2 인코더는, 상기 제1 텍스트와 임계 값 이상의 유사도를 가지는 제2 언어의 제2 텍스트 및 상기 벡터 공간 상의 상기 특징벡터를 입력 데이터 및 출력 데이터로 하여 학습된 모델인, 전자 장치."}
{"patent_id": "10-2022-0046172", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,상기 제2 언어에 대응되는 상기 제2 인코더는, 상기 외부 장치에 포함되며, 상기 제2 언어의 사용자 음성에 대응되는 텍스트가 입력되면, 상기 제2 특징 벡터를 출력하는, 전자 장치."}
{"patent_id": "10-2022-0046172", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,상기 제1 디코더는,벡터 공간 상의 특징 벡터 및 제1 언어의 제1 텍스트를 입력 데이터 및 출력 데이터로 하여 학습된 모델이고,상기 제1 언어와 상이한 제2 언어에 대응되는 제2 디코더는, 상기 벡터 공간 상의 상기 특징 벡터 및 상기 제1 텍스트와 임계 값 이상의 유사도를 가지는 제2 언어의 제2 텍스트를 입력 데이터 및 출력 데이터로 하여 학습된 모델인, 전자 장치."}
{"patent_id": "10-2022-0046172", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서,상기 제2 언어에 대응되는 상기 제2 디코더는, 상기 외부 장치에 포함되며, 공개특허 10-2023-0054242-3-상기 전자 장치로부터 수신된 상기 제1 특징 벡터가 입력되면, 상기 제2 언어의 텍스트를 출력하는, 전자 장치."}
{"patent_id": "10-2022-0046172", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제4항에 있어서,상기 프로세서는,상기 외부 장치와 통신을 수행하여 상기 외부 장치가 상기 제2 언어에 대응되는 제2 디코더를 포함하는지 여부를 식별하고, 상기 외부 장치가 상기 제2 디코더를 포함하는 것으로 식별되면, 상기 제1 특징 벡터를 상기 외부장치로 전송하고, 상기 외부 장치가 상기 제2 디코더를 포함하지 않는 것으로 식별되면, 상기 제1 특징 벡터를 서버로 전송하는,전자 장치."}
{"patent_id": "10-2022-0046172", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에 있어서,스피커;를 더 포함하며, 상기 프로세서는,TTS(Text to speech)를 이용하여 상기 제1 언어의 텍스트에 대응되는 상기 제1 언어의 사운드를 획득하고, 상기 제1 언어의 사운드를 상기 스피커를 통해 출력하는, 전자 장치."}
{"patent_id": "10-2022-0046172", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1항에 있어서,상기 메모리는,컴프레서(compressor) 및 디컴프레서(decompressor)를 더 포함하며,상기 프로세서는,상기 컴프레서에 기초하여 상기 제1 특징 벡터를 압축하며, 상기 압축된 제1 특징 벡터를 상기 통신 인터페이스를 통해 상기 외부 장치로 전송하고, 상기 외부 장치로부터 압축된 제2 특징 벡터가 수신되면, 상기 디컴프레서에 기초하여 상기 압축된 제2 특징 벡터를 압축 해제하고, 상기 압축 해제된 제2 특징 벡터를 상기 제1 디코더에 입력하는, 전자 장치."}
{"patent_id": "10-2022-0046172", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1항에 있어서,상기 제1 인코더 및 상기 제1 디코더는,신경망 기계 번역(Neural machine translation, NMT) 모델에 포함되며,상기 신경망 기계 번역 모델은, 상기 사용자 음성이 입력되면, 상기 사용자 음성에 대응되는 텍스트를 벡터 값으로 변환하여 상기 제1 특징 벡터를 획득하며,상기 제2 특징 벡터가 입력되면, 상기 제2 특징 벡터를 상기 제1 언어의 텍스트로 변환하는, 전자 장치."}
{"patent_id": "10-2022-0046172", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "전자 장치의 제어 방법에 있어서,상기 제1 언어의 사용자 음성이 수신되면, 상기 사용자 음성에 대응되는 상기 제1 언어의 텍스트를 획득하는 단계;공개특허 10-2023-0054242-4-상기 제1 언어의 텍스트를 상기 제1 언어에 대응되는 제1 인코더에 입력하여 제1 특징 벡터를 획득하는 단계;상기 제1 특징 벡터를 외부 장치로 전송하는 단계; 및상기 외부 장치로부터 제2 특징 벡터가 수신되면, 상기 제2 특징 벡터를 상기 제1 언어에 대응되는 제1 디코더에 입력하여 상기 제2 특징 벡터에 대응되는 상기 제1 언어의 텍스트를 획득하는 단계;를 포함하는 제어 방법."}
{"patent_id": "10-2022-0046172", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제10항에 있어서,상기 제1 인코더는,제1 언어의 제1 텍스트 및 벡터 공간 상의 특징 벡터를 입력 데이터 및 출력 데이터로 하여 학습된 모델이고,상기 제1 언어와 상이한 제2 언어에 대응되는 제2 인코더는, 상기 제1 텍스트와 임계 값 이상의 유사도를 가지는 제2 언어의 제2 텍스트 및 상기 벡터 공간 상의 상기 특징벡터를 입력 데이터 및 출력 데이터로 하여 학습된 모델인, 제어 방법."}
{"patent_id": "10-2022-0046172", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항에 있어서,상기 제2 언어에 대응되는 상기 제2 인코더는, 상기 외부 장치에 포함되며, 상기 제2 언어의 사용자 음성에 대응되는 텍스트가 입력되면, 상기 제2 특징 벡터를 출력하는, 제어 방법."}
{"patent_id": "10-2022-0046172", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제12항에 있어서,상기 제1 디코더는,벡터 공간 상의 특징 벡터 및 제1 언어의 제1 텍스트를 입력 데이터 및 출력 데이터로 하여 학습된 모델이고,상기 제1 언어와 상이한 제2 언어에 대응되는 제2 디코더는, 상기 벡터 공간 상의 상기 특징 벡터 및 상기 제1 텍스트와 임계 값 이상의 유사도를 가지는 제2 언어의 제2 텍스트를 입력 데이터 및 출력 데이터로 하여 학습된 모델인, 제어 방법."}
{"patent_id": "10-2022-0046172", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제13항에 있어서,상기 제2 언어에 대응되는 상기 제2 디코더는, 상기 외부 장치에 포함되며, 상기 전자 장치로부터 수신된 상기 제1 특징 벡터가 입력되면, 상기 제2 언어의 텍스트를 출력하는, 제어 방법."}
{"patent_id": "10-2022-0046172", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제14항에 있어서,상기 외부 장치와 통신을 수행하여 상기 외부 장치가 상기 제2 언어에 대응되는 제2 디코더를 포함하는지 여부를 식별하는 단계;상기 외부 장치가 상기 제2 디코더를 포함하는 것으로 식별되면, 상기 제1 특징 벡터를 상기 외부 장치로 전송하는 단계; 및 상기 외부 장치가 상기 제2 디코더를 포함하지 않는 것으로 식별되면, 상기 제1 특징 벡터를 서버로 전송하는단계;를 더 포함하는, 제어 방법."}
{"patent_id": "10-2022-0046172", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제10항에 있어서,공개특허 10-2023-0054242-5-TTS(Text to speech)를 이용하여 상기 제1 언어의 텍스트에 대응되는 상기 제1 언어의 사운드를 획득하는 단계;및상기 제1 언어의 사운드를 출력하는 단계;를 포함하는, 제어 방법."}
{"patent_id": "10-2022-0046172", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제10항에 있어서,컴프레서에 기초하여 상기 제1 특징 벡터를 압축하는 단계;상기 압축된 제1 특징 벡터를 상기 통신 인터페이스를 통해 상기 외부 장치로 전송하는 단계;상기 외부 장치로부터 압축된 제2 특징 벡터가 수신되면, 디컴프레서에 기초하여 상기 압축된 제2 특징 벡터를압축 해제하는 단계; 및상기 압축 해제된 제2 특징 벡터를 상기 제1 디코더에 입력하는 단계;를 더 포함하는, 전자 장치."}
{"patent_id": "10-2022-0046172", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제11항에 있어서,상기 제1 인코더 및 상기 제1 디코더는,신경망 기계 번역(Neural machine translation, NMT) 모델에 포함되며,상기 신경망 기계 번역 모델은, 상기 사용자 음성이 입력되면, 상기 사용자 음성에 대응되는 텍스트를 벡터 값으로 변환하여 상기 제1 특징 벡터를 획득하며,상기 제2 특징 벡터가 입력되면, 상기 제2 특징 벡터를 상기 제1 언어의 텍스트로 변환하는, 제어 방법."}
{"patent_id": "10-2022-0046172", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "전자 장치가 개시된다. 전자 장치는 마이크, 통신 회로를 포함하는 통신 인터페이스, 제1 언어에 대응되는 제1 인코더 및 제1 디코더를 저장하는 메모리 및 마이크를 통해 제1 언어의 사용자 음성이 수신되면, 사용자 음성에 대응되는 제1 언어의 텍스트를 획득하고, 제1 언어의 텍스트를 제1 인코더에 입력하여 제1 특징 벡터를 획득하고, 통신 인터페이스를 통해 제1 특징 벡터를 외부 장치로 전송하며, 통신 인터페이스를 통해 외부 장치로 부터 제2 특징 벡터가 수신되면, 제2 특징 벡터를 제1 디코더에 입력하여 제2 특징 벡터에 대응되는 제1 언어의 텍스트를 획득하는 프로세서를 포함한다."}
{"patent_id": "10-2022-0046172", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 전자 장치 및 그 제어 방법에 관한 것으로, 더욱 상세하게는, 사용자 음성을 수신하는 전자 장치 및 그 제어 방법에 관한 것이다."}
{"patent_id": "10-2022-0046172", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "최근, 다수의 전자 장치에 번역 기능이 탑재되고 있다. 전자 장치에 탑재되는 번역 기능은 기본적으로 사용자의 음성을 인코딩하는 인코더와, 번역(또는, 통역)하고자 하는 타 언어로 디코딩하는 디코더를 이용하여 수행가능하다. 통신을 수행하는 외부 장치 예를 들어, 통화 상대방의 언어를 전자 장치의 사용자의 언어로 번역하기 위해서는, 전자 장치가 통화 상대방의 언어에 대응되는 인코더와 디코더를 구비하여야 한다. 따라서, 다양한 언어를 모두 사용자의 언어로 번역하기 위해서는 다양한 언어 모두에 대응되는 인코더와 디코더 를 구비하여야 하므로, 온 디바이스(On device) 형태로 번역 기능을 제공하기에는 전자 장치의 리소스 상 한계 가 있으며, 전자 장치의 제품 사양이 높아야만 원활한 번역이 가능하다는 문제가 있다. 전자 장치가 외부 서버로 사용자 음성을 전송한 뒤에, 번역하고자 하는 언어(예를 들어, 타겟 언어)의 텍스트를 수신하는 경우에는, 다양한 언어 모두에 대응되는 인코더와 디코더를 구비할 필요는 없으나, 해킹의 위험, 개인 정보 또는 사생활 노출 위험 등 보안 관련 이슈가 있다. 따라서, 다양한 언어 모두에 대응되는 인코더와 디코더를 구비하지 않아도, 온 디바이스로 원활한 번역 기능을"}
{"patent_id": "10-2022-0046172", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 2, "content": "제공하는 전자 장치, 방법에 대한 필요성이 대두되었다.발명의 내용"}
{"patent_id": "10-2022-0046172", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 개시는 상술한 필요성에 따른 것으로, 본 개시의 목적은, 전자 장치가 외부 장치와 특징 벡터를 송수신하여 번역 기능을 제공하는 전자 장치 및 그 제어 방법을 제공함에 있다."}
{"patent_id": "10-2022-0046172", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "이상과 같은 목적을 달성하기 위한 본 개시의 일 실시 예에 따른 전자 장치는, 마이크, 통신 회로를 포함하는 통신 인터페이스, 제1 언어에 대응되는 제1 인코더 및 제1 디코더를 저장하는 메모리 및 상기 마이크를 통해 상 기 제1 언어의 사용자 음성이 수신되면, 상기 사용자 음성에 대응되는 상기 제1 언어의 텍스트를 획득하고, 상 기 제1 언어의 텍스트를 상기 제1 인코더에 입력하여 제1 특징 벡터를 획득하고, 상기 통신 인터페이스를 통해 상기 제1 특징 벡터를 외부 장치로 전송하며, 상기 통신 인터페이스를 통해 상기 외부 장치로부터 제2 특징 벡 터가 수신되면, 상기 제2 특징 벡터를 상기 제1 디코더에 입력하여 상기 제2 특징 벡터에 대응되는 상기 제1 언 어의 텍스트를 획득하는 프로세서를 포함한다. 여기서, 상기 제1 인코더는, 제1 언어의 제1 텍스트 및 벡터 공간 상의 특징 벡터를 입력 데이터 및 출력 데이 터로 하여 학습된 모델이고, 상기 제1 언어와 상이한 제2 언어에 대응되는 제2 인코더는, 상기 제1 텍스트와 임 계 값 이상의 유사도를 가지는 제2 언어의 제2 텍스트 및 상기 벡터 공간 상의 상기 특징 벡터를 입력 데이터 및 출력 데이터로 하여 학습된 모델일 수 있다. 여기서, 상기 제2 언어에 대응되는 상기 제2 인코더는, 상기 외부 장치에 포함되며, 상기 제2 언어의 사용자 음 성에 대응되는 텍스트가 입력되면, 상기 제2 특징 벡터를 출력할 수 있다. 또한, 상기 제1 디코더는, 벡터 공간 상의 특징 벡터 및 제1 언어의 제1 텍스트를 입력 데이터 및 출력 데이터 로 하여 학습된 모델이고, 상기 제1 언어와 상이한 제2 언어에 대응되는 제2 디코더는, 상기 벡터 공간 상의 상 기 특징 벡터 및 상기 제1 텍스트와 임계 값 이상의 유사도를 가지는 제2 언어의 제2 텍스트를 입력 데이터 및 출력 데이터로 하여 학습된 모델일 수 있다. 여기서, 상기 제2 언어에 대응되는 상기 제2 디코더는, 상기 외부 장치에 포함되며, 상기 전자 장치로부터 수신 된 상기 제1 특징 벡터가 입력되면, 상기 제2 언어의 텍스트를 출력할 수 있다. 또한, 상기 프로세서는, 상기 외부 장치와 통신을 수행하여 상기 외부 장치가 상기 제2 언어에 대응되는 제2 디 코더를 포함하는지 여부를 식별하고, 상기 외부 장치가 상기 제2 디코더를 포함하는 것으로 식별되면, 상기 제1 특징 벡터를 상기 외부 장치로 전송하고, 상기 외부 장치가 상기 제2 디코더를 포함하지 않는 것으로 식별되면, 상기 제1 특징 벡터를 서버로 전송할 수 있다. 또한, 스피커를 더 포함하며, 상기 프로세서는, TTS(Text to speech)를 이용하여 상기 제1 언어의 텍스트에 대 응되는 상기 제1 언어의 사운드를 획득하고, 상기 제1 언어의 사운드를 상기 스피커를 통해 출력할 수 있다. 또한, 상기 메모리는, 컴프레서(compressor) 및 디컴프레서(decompressor)를 더 포함하며, 상기 프로세서는, 상 기 컴프레서에 기초하여 상기 제1 특징 벡터를 압축하며, 상기 압축된 제1 특징 벡터를 상기 통신 인터페이스를 통해 상기 외부 장치로 전송하고, 상기 외부 장치로부터 압축된 제2 특징 벡터가 수신되면, 상기 디컴프레서에 기초하여 상기 압축된 제2 특징 벡터를 압축 해제하고, 상기 압축 해제된 제2 특징 벡터를 상기 제1 디코더에 입력할 수 있다. 또한, 상기 제1 인코더 및 상기 제1 디코더는, 신경망 기계 번역(Neural machine translation, NMT) 모델에 포 함되며, 상기 신경망 기계 번역 모델은, 상기 사용자 음성이 입력되면, 상기 사용자 음성에 대응되는 텍스트를 벡터 값으로 변환하여 상기 제1 특징 벡터를 획득하며, 상기 제2 특징 벡터가 입력되면, 상기 제2 특징 벡터를 상기 제1 언어의 텍스트로 변환할 수 있다. 한편, 본 개시의 일 실시 예에 따른 전자 장치의 제어 방법은, 상기 제1 언어의 사용자 음성이 수신되면, 상기 사용자 음성에 대응되는 상기 제1 언어의 텍스트를 획득하는 단계, 상기 제1 언어의 텍스트를 상기 제1 언어에 대응되는 제1 인코더에 입력하여 제1 특징 벡터를 획득하는 단계, 상기 제1 특징 벡터를 외부 장치로 전송하는 단계 및 상기 외부 장치로부터 제2 특징 벡터가 수신되면, 상기 제2 특징 벡터를 상기 제1 언어에 대응되는 제1 디코더에 입력하여 상기 제2 특징 벡터에 대응되는 상기 제1 언어의 텍스트를 획득하는 단계를 포함할 수 있다.여기서, 상기 제1 인코더는, 제1 언어의 제1 텍스트 및 벡터 공간 상의 특징 벡터를 입력 데이터 및 출력 데이 터로 하여 학습된 모델이고, 상기 제1 언어와 상이한 제2 언어에 대응되는 제2 인코더는, 상기 제1 텍스트와 임 계 값 이상의 유사도를 가지는 제2 언어의 제2 텍스트 및 상기 벡터 공간 상의 상기 특징 벡터를 입력 데이터 및 출력 데이터로 하여 학습된 모델일 수 있다. 또한, 상기 제2 언어에 대응되는 상기 제2 인코더는, 상기 외부 장치에 포함되며, 상기 제2 언어의 사용자 음성 에 대응되는 텍스트가 입력되면, 상기 제2 특징 벡터를 출력할 수 있다. 여기서, 상기 제1 디코더는, 벡터 공간 상의 특징 벡터 및 제1 언어의 제1 텍스트를 입력 데이터 및 출력 데이 터로 하여 학습된 모델이고, 상기 제1 언어와 상이한 제2 언어에 대응되는 제2 디코더는, 상기 벡터 공간 상의 상기 특징 벡터 및 상기 제1 텍스트와 임계 값 이상의 유사도를 가지는 제2 언어의 제2 텍스트를 입력 데이터 및 출력 데이터로 하여 학습된 모델일 수 있다. 여기서, 상기 제2 언어에 대응되는 상기 제2 디코더는, 상기 외부 장치에 포함되며, 상기 전자 장치로부터 수신 된 상기 제1 특징 벡터가 입력되면, 상기 제2 언어의 텍스트를 출력할 수 있다. 여기서, 상기 외부 장치와 통신을 수행하여 상기 외부 장치가 상기 제2 언어에 대응되는 제2 디코더를 포함하는 지 여부를 식별하는 단계, 상기 외부 장치가 상기 제2 디코더를 포함하는 것으로 식별되면, 상기 제1 특징 벡터 를 상기 외부 장치로 전송하는 단계 및 상기 외부 장치가 상기 제2 디코더를 포함하지 않는 것으로 식별되면, 상기 제1 특징 벡터를 서버로 전송하는 단계를 더 포함할 수 있다. 또한, TTS(Text to speech)를 이용하여 상기 제1 언어의 텍스트에 대응되는 상기 제1 언어의 사운드를 획득하는 단계 및 상기 제1 언어의 사운드를 출력하는 단계를 더 포함할 수 있다. 또한, 컴프레서에 기초하여 상기 제1 특징 벡터를 압축하는 단계, 상기 압축된 제1 특징 벡터를 상기 통신 인터 페이스를 통해 상기 외부 장치로 전송하는 단계, 상기 외부 장치로부터 압축된 제2 특징 벡터가 수신되면, 디컴 프레서에 기초하여 상기 압축된 제2 특징 벡터를 압축 해제하는 단계 및 상기 압축 해제된 제2 특징 벡터를 상 기 제1 디코더에 입력하는 단계를 더 포함할 수 있다. 또한, 상기 제1 인코더 및 상기 제1 디코더는, 신경망 기계 번역(Neural machine translation, NMT) 모델에 포 함되며, 상기 신경망 기계 번역 모델은, 상기 사용자 음성이 입력되면, 상기 사용자 음성에 대응되는 텍스트를 벡터 값으로 변환하여 상기 제1 특징 벡터를 획득하며, 상기 제2 특징 벡터가 입력되면, 상기 제2 특징 벡터를 상기 제1 언어의 텍스트로 변환할 수 있다."}
{"patent_id": "10-2022-0046172", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "상술한 바와 같이 본 개시의 다양한 실시 예에 따르면, 복수의 전자 장치 각각은 사용자의 주된 언어에 대응되 는 인코딩 및 디코딩을 구비하므로, 과도한 리소스 요구 없이도 원활한 번역 기능 제공이 가능하다."}
{"patent_id": "10-2022-0046172", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하에서는 첨부 도면을 참조하여 본 개시를 상세히 설명한다. 본 개시의 실시 예에서 사용되는 용어는 본 개시에서의 기능을 고려하면서 가능한 현재 널리 사용되는 일반적인 용어들을 선택하였으나, 이는 당 분야에 종사하는 기술자의 의도 또는 판례, 새로운 기술의 출현 등에 따라 달 라질 수 있다. 또한, 특정한 경우는 출원인이 임의로 선정한 용어도 있으며, 이 경우 해당되는 개시의 설명 부 분에서 상세히 그 의미를 기재할 것이다. 따라서 본 개시에서 사용되는 용어는 단순한 용어의 명칭이 아닌, 그 용어가 가지는 의미와 본 개시의 전반에 걸친 내용을 토대로 정의되어야 한다. 본 명세서에서, \"가진다,\" \"가질 수 있다,\" \"포함한다,\" 또는 \"포함할 수 있다\" 등의 표현은 해당 특징(예: 수 치, 기능, 동작, 또는 부품 등의 구성요소)의 존재를 가리키며, 추가적인 특징의 존재를 배제하지 않는다. A 또는/및 B 중 적어도 하나라는 표현은 \"A\" 또는 \"B\" 또는 \"A 및 B\" 중 어느 하나를 나타내는 것으로 이해되어 야 한다. 본 명세서에서 사용된 \"제1,\" \"제2,\" \"첫째,\" 또는 \"둘째,\"등의 표현들은 다양한 구성요소들을, 순서 및/또는 중요도에 상관없이 수식할 수 있고, 한 구성요소를 다른 구성요소와 구분하기 위해 사용될 뿐 해당 구성요소들 을 한정하지 않는다. 어떤 구성요소(예: 제1 구성요소)가 다른 구성요소(예: 제2 구성요소)에 \"(기능적으로 또는 통신적으로) 연결되 어((operatively or communicatively) coupled with/to)\" 있다거나 \"접속되어(connected to)\" 있다고 언급된 때에는, 어떤 구성요소가 다른 구성요소에 직접적으로 연결되거나, 다른 구성요소(예: 제3 구성요소)를 통하여 연결될 수 있다고 이해되어야 할 것이다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 출원에서, \"포함하다\" 또 는 \"구성되다\" 등의 용어는 명세서상에 기재된 특징, 숫자, 단계, 동작, 구성요소, 부품 또는 이들을 조합한 것 이 존재함을 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성요소, 부품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되어야 한다. 본 개시에서 \"모듈\" 혹은 \"부\"는 적어도 하나의 기능이나 동작을 수행하며, 하드웨어 또는 소프트웨어로 구현되 거나 하드웨어와 소프트웨어의 결합으로 구현될 수 있다. 또한, 복수의 \"모듈\" 혹은 복수의 \"부\"는 특정한 하드 웨어로 구현될 필요가 있는 \"모듈\" 혹은 \"부\"를 제외하고는 적어도 하나의 모듈로 일체화되어 적어도 하나의 프 로세서(미도시)로 구현될 수 있다. 본 명세서에서, 사용자라는 용어는 전자 장치를 사용하는 사람 또는 전자 장치를 사용하는 장치(예: 인공지능 전자 장치)를 지칭할 수 있다. 이하 첨부된 도면들을 참조하여 본 개시의 일 실시 예를 보다 상세하게 설명한다. 도 1은 종래에 따른 번역 기능을 제공하는 전자 장치에 구비된 인코더 및 디코더를 설명하기 위한 도면이다. 도 1을 참조하면, 종래의 전자 장치는 제1 언어를 제2 언어로 번역(또는, 변환)하기 위해 제1 언어의 인코더와 제2 언어의 디코더를 구비하였다. 예를 들어, 종래의 전자 장치는 한국어(KR)의 사용자 음성 또는 텍스트를 영어(EN)로 번역하기 위해 한국어 인 코더(Encoder) 및 영어 디코더(Decoder)를 구비하였다. 일 실시 예에 따라 종래의 전자 장치는 한국어의 사용자 음성이 수신되면, 사용자 음성을 한국어 텍스트로 변환 한다. 이어서, 한국어 인코더는 한국어 텍스트를 특징 벡터로 변환한다. 이어서, 영어 디코더는 특징 벡터를 영 어 텍스트로 변환하며, 종래의 전자 장치는 영어 디코더를 통해 획득된 영어 텍스트를 디스플레이하거나 사운드 로 출력할 수 있고, 전자 장치와 통신을 수행하는 외부 장치로 전송할 수도 있다. 도 1에 도시된 바와 같이, 종래의 전자 장치는 다양한 언어에 대한 번역 기능을 제공하기 위해 복수의 인코더 및 복수의 디코더를 구비하였다. 예를 들어, 종래의 전자 장치는 한국어에서 영어로의 변역 기능을 제공하기 위 해 한국어 인코더 및 영어 디코더를 구비하였으며, 영어에서 한국어로의 번역 기능을 제공하기 위해 영어 인코 더 및 한국어 디코더를 구비하였다. 이외에도, 도 1에 도시된 바와 같이 한국어에서 중국어로의 번역 기능, 중국어에서 한국어로의 번역 기능 등 다 양한 언어에 대한 번역 기능을 제공하기 위해서는 각 언어에 대응되는 인코더와 디코더를 구비하여야 하므로,종래의 전자 장치는 복수의 인코더와 디코더를 구동하기 위한 매우 큰 리소스(resource), 높은 제품 사양 (specification)을 구비하여야하는 문제가 있었다. 특히, 종래의 전자 장치는 리소스 한계로 인하여 복수의 인코더와 디코더를 원활히 구동하기 어렵거나, 실시간 으로 번역 기능을 제공하기 어려운 경우, 서버로 제1 언어의 텍스트를 전송한 뒤, 서버로부터 제2 언어로 번역 된 텍스트를 수신하여 번역 기능을 제공하였다. 이 경우, 네트워크나 서버를 거치지 않고 전자 장치 자체에서 번역을 수행하는 온 디바이스(On device) 형태의 번역 기능을 제공하지 못하므로, 사용자 음성이나 텍스트가 해 킹에 외부로 노출될 우려가 있으며, 이는 보안과 관련된 중요한 이슈가 있다. 이하에서는 본 개시의 다양한 실시 예에 따라 종래와 달리 리소스 또는 제품 사양에 따른 한계 없이도, 온 디바 이스 형태의 번역 기능을 제공 가능한 전자 장치, 시스템 및 제어 방법에 대해 설명하도록 한다. 도 2는 본 개시의 일 실시 예에 따른 전자 장치에 구비된 인코더 및 디코더를 설명하기 위한 도면이다. 도 2를 참조하면, 전자 장치는 다양한 외부 장치와 통신을 수행할 수 있다. 예를 들어, 전자 장치의 사용자는 주된 언어로 한국어를 이용하며, 제2 외부 장치의 사용자는 주된 언어로 영어를 이용하고, 제3 외부 장치의 사용자는 주된 언어로 중국어를 이용하는 경우를 상정할 수 있 다. 종래의 방법에 따라 전자 장치가 한국어의 사용자 음성을 제1 외부 장치와 제2 외부 장치 각각 의 사용자가 이용하는 주된 언어로 번역한 뒤, 제1 외부 장치와 제2 외부 장치 각각으로 전송하기 위 해서 전자 장치는 한국어 인코더, 영어 디코더 및 중국어 디코더를 구비하여야 했다. 본 개시의 일 실시 예에 따르면, 전자 장치는 전자 장치의 사용자의 주된 언어(이하, 제1 언어)에 대 응되는 제1 인코더 및 제1 디코더를 구비할 수 있다. 전자 장치와 통신을 수행하는 제1 외부 장치는 제1 외부 장치의 사용자의 주된 언어(이하, 제2 언어)에 대응되는 제2 인코더 및 제2 디코더를 구비할 수 있다. 또한, 제2 외부 장치는 제2 외부 장치의 사용자의 주된 언어 즉, 제3 언어에 대응되는 제3 인코더 및 제3 디코더를 구비할 수 있다. 도 2를 참조하면, 전자 장치는 복수의 인코더와 복수의 디코더를 구비하지 않으며, 제1 언어에 대응되는 제1 인코더와 제1 디코더만을 구비할 수 있다. 일 실시 예에 따라 전자 장치는 제1 언어의 사용자 음성이 수신되면, 사용자 음성을 텍스트로 변환한 뒤, 텍스트를 제1 인코더에 입력할 수 있다. 이어서, 제1 인코더는 텍스트에 대응되는 제1 특징 벡터를 획득할 수 있다. 이어서, 전자 장치는 제1 특징 벡터를 전자 장치와 통신을 수행하는 제1 외부 장치로 전송할 수 있다. 제1 외부 장치는 전자 장치로부터 수신된 제1 특징 벡터를 제2 디코더에 입력하여 제1 특징 벡터에 대응되 는 제2 언어의 텍스트를 획득할 수 있다. 상술한 과정을 통해, 전자 장치가 제2 언어에 대응되는 제2 디코더를 구비하지 않아도, 전자 장치는 제1 특징 벡터를 전송하고 제1 외부 장치는 전자 장치로부터 수신된 제1 특징 벡터를 제2 언어의 텍 스트로 변환하여, 결과적으로 제1 언어의 사용자 음성을 대응되는 제2 언어의 텍스트로 변환하여 전자 장치 의 사용자와 제1 외부 장치의 사용자 간 커뮤니케이션이 가능할 수 있다. 다른 예로, 제1 외부 장치가 제2 언어의 사용자 음성(또는, 사용자 음성에 대응되는 텍스트)을 제2 인코더 에 입력하여 제2 특징 벡터를 획득할 수 있다. 이어서, 제1 외부 장치는 제2 특징 벡터를 전자 장치 로 전송하며, 전자 장치는 제2 특징 벡터를 제1 디코더에 입력하여 제1 언어의 텍스트를 획득할 수 있다. 일 실시 예에 따라 전자 장치, 제1 외부 장치 및 제2 외부 장치) 각각은, 자체적으로 구비된 인 코더를 이용하여 사용자 음성을 특징 벡터로 변환한 뒤, 변환된 특징 벡터를 전송한다. 또한, 전자 장치와 제1 외부 장치(또는, 제2 외부 장치) 각각은, 특징 벡터를 수신한 뒤, 자체적으로 구비된 디코더를 이용하여 특징 벡터를 텍스트로 변환할 수 있다.도 3은 본 개시의 일 실시 예에 따른 전자 장치의 구성을 설명하기 위한 블록도이다. 도 3을 참조하면, 전자 장치는 마이크, 메모리, 통신 인터페이스 및 프로세서를 포함 한다. 우선, 마이크는 사용자 음성을 수신할 수 있다. 다만, 마이크는 입력부의 일 예시이며, 전자 장치 는 키보드(key board), 마우스(mouse), 키 패드(key pad), 터치 패드 등을 통해 사용자 입력을 수신할 수 도 있음은 물론이다. 메모리는 본 개시의 다양한 실시 예를 위해 필요한 데이터를 저장할 수 있다. 메모리는 데이터 저장 용도에 따라 전자 장치에 임베디드된 메모리 형태로 구현되거나, 전자 장치에 탈부착이 가능한 메모 리 형태로 구현될 수도 있다. 예를 들어, 전자 장치의 구동을 위한 데이터는 전자 장치에 임베디드된 메모리에 저장되고, 전자 장 치의 확장 기능을 위한 데이터는 전자 장치에 탈부착이 가능한 메모리에 저장될 수 있다. 한편, 전자 장치에 임베디드된 메모리의 경우 휘발성 메모리(예: DRAM(dynamic RAM), SRAM(static RAM), 또는 SDRAM(synchronous dynamic RAM) 등), 비휘발성 메모리(non-volatile Memory)(예: OTPROM(one time programmable ROM), PROM(programmable ROM), EPROM(erasable and programmable ROM), EEPROM(electrically erasable and programmable ROM), mask ROM, flash ROM, 플래시 메모리(예: NAND flash 또는 NOR flash 등), 하드 드라이브, 또는 솔리드 스테이트 드라이브(solid state drive(SSD)) 중 적어도 하나로 구현될 수 있다. 또 한, 전자 장치에 탈부착이 가능한 메모리의 경우 메모리 카드(예를 들어, CF(compact flash), SD(secure digital), Micro-SD(micro secure digital), Mini-SD(mini secure digital), xD(extreme digital), MMC(multi-media card) 등), USB 포트에 연결가능한 외부 메모리(예를 들어, USB 메모리) 등과 같은 형태로 구 현될 수 있다. 일 예에 따라 메모리는 전자 장치를 제어하기 위한 적어도 하나의 인스트럭션(instruction) 또는 인 스트럭션들을 포함하는 컴퓨터 프로그램을 저장할 수 있다. 특히, 메모리는 복수의 레이어를 포함하는 인공 지능 모델에 관한 정보를 저장할 수 있다. 여기서, 인공 지능 모델에 관한 정보를 저장한다는 것은 인공 지능 모델의 동작과 관련된 다양한 정보, 예를 들어 인공 지능 모델에 포함된 복수의 레이어에 대한 정보, 복수의 레이어 각각에서 이용되는 파라미터(예를 들어, 필터 계수, 바이어스 등)에 대한 정보 등을 저장한다는 것을 의미할 수 있다. 예를 들어, 메모리는 본 개시의 일 실시 예에 따라 제1 언어의 텍스트를 특징 벡터로 변환하도록 학습된 제1 인코더, 특징 벡터를 제1 언어의 텍스트로 변환하도록 학습된 제1 디코더를 포함하는 신경망 기계 번역 (Neural machine translation, NMT) 모델을 저장할 수 있다. NMT 모델에 대한 구체적인 설명은 후술하도록 한 다. 본 개시의 일 실시 예에 따른 통신 인터페이스는 다양한 데이터를 입력받는다. 예를 들어, 통신 인터페이 스는 AP 기반의 Wi-Fi(와이파이, Wireless LAN 네트워크), 블루투스(Bluetooth), 지그비(Zigbee), 유/무 선 LAN(Local Area Network), WAN(Wide Area Network), 이더넷(Ethernet), IEEE 1394, HDMI(High-Definition Multimedia Interface), USB(Universal Serial Bus), MHL(Mobile High-Definition Link), AES/EBU(Audio Engineering Society/ European Broadcasting Union), 옵티컬(Optical), 코액셜(Coaxial) 등과 같은 통신 방식 을 통해 외부 장치(예를 들어, 제1 외부 장치, 제2 외부 장치 등 사용자 단말 장치), 외부 저장 매체 (예를 들어, USB 메모리), 외부 서버(예를 들어, 번역 기능 제공 서버) 등으로부터 다양한 데이터를 입력받을 수 있다. 특히, 통신 인터페이스는 프로세서의 제어에 따라 외부 장치로 특징 벡터를 전송하거나, 외부 장치로 부터 특징 벡터를 수신할 수 있다. 이에 대한 구체적인 설명은 후술하도록 한다. 본 개시의 일 실시 예에 따른 프로세서는 전자 장치의 전반적인 동작을 제어한다. 일 실시 예에 따라 프로세서는 디지털 영상 신호를 처리하는 디지털 시그널 프로세서(digital signal processor(DSP), 마이크로 프로세서(microprocessor), AI(Artificial Intelligence) 프로세서, T-CON(Timing controller)으로 구현될 수 있다. 다만, 이에 한정되는 것은 아니며, 중앙처리장치(central processing unit(CPU)), MCU(Micro Controller Unit), MPU(micro processing unit), 컨트롤러(controller), 어플리케이션 프로세서(application processor(AP)), 또는 커뮤니케이션 프로세서(communication processor(CP)), ARM 프로세서 중 하나 또는 그 이상을 포함하거나, 해당 용어로 정의될 수 있다. 또한, 프로세서는 프로세싱 알고 리즘이 내장된 SoC(System on Chip), LSI(large scale integration)로 구현될 수도 있고, FPGA(Field Programmable gate array) 형태로 구현될 수도 있다. 특히, 프로세서는 사용자 음성을 인식하여 사용자 음성에 대응되는 텍스트 또는, 사용자 입력에 따른 텍스 트를 제1 인코더에 입력하여 텍스트에 대응되는 특징 벡터를 획득할 수 있다. 예를 들어, 프로세서에 구비 된 음성 인식(Automatic speech recognition, ASR) 모듈은 마이크를 통해 수신된 사용자 음성을 인식하여 사용자 음성에 대응되는 제1 언어의 텍스트를 획득할 수 있다. 또한, 프로세서는 외부 장치로부터 통신 인터페이스를 통해 수신된 특징 벡터를 제1 디코더에 입력하 여 특징 벡터에 대응되는 제1 언어의 텍스트를 획득할 수 있다. 한편, 메모리는 제1 인코더로 동작하는 신경망 모델, 제1 디코더로 동작하는 신경망 모델 즉, 적어도 두개 의 신경망 모델을 저장할 수 있다. 다른 예로, 메모리는 제1 인코더 및 제1 디코더를 포함하여, 제1 언어의 텍스트가 입력되면 특징 벡터로 변환하고, 특징 벡터가 입력되면 제1 언어의 텍스트로 변환하도록 학습된 하나의 신경망 모델을 저장할 수도 있 음은 물론이다. 여기서, 제1 언어에 대응되는 제1 인코더는, 제1 언어의 제1 텍스트를 입력 데이터로, 벡터 공간 상의 특징 벡 터를 출력 데이터로 하여 학습된 모델일 수 있다. 일 실시 예에 따라 제1 언어와 상이한 제2 언어에 대응되는 제2 인코더는, 제1 텍스트와 임계 값 이상의 유사도 를 가지는 제2 언어의 제2 텍스트를 입력 데이터로, 벡터 공간 상의 특징 벡터를 출력 데이터로 하여 학습된 모 델일 수 있다. 한편, 제1 인코더의 입력 데이터인 제1 텍스트와 제2 인코더의 입력 데이터인 제2 텍스트의 의미가 임계 값 이 상의 유사도를 가지면, 제1 인코더의 출력 데이터인 특징 벡터와 제2 인코더의 출력 데이터인 특징 벡터는 동일 또는 유사할 수 있다. 여기서, 유사도는, 제1 언어의 제1 텍스트와 제2 언어의 제2 텍스트 간에 의미가 유사한 지를 수치화한 값으로 서, 0 내지 1의 값으로 표현될 수 있다. 유사도가 1에 가까울수록 제1 언어의 제1 텍스트와 제2 언어의 제2 텍 스트의 의미가 동일, 유사함을 의미할 수 있다. 한편, 제1 임계 값은 0.9일 수 있으며, 이는 일 예시일 뿐 이에 한정되지 않음은 물론이다. 제1 언어에 대응되는 제1 디코더는, 벡터 공간 상의 특징 벡터를 입력 데이터로, 제1 언어의 제1 텍스트를 출력 데이터로 하여 학습된 모델일 수 있다. 일 실시 예에 따라 제1 언어와 상이한 제2 언어에 대응되는 제2 디코더는, 벡터 공간 상의 특징 벡터를 입력 데 이터로, 제2 언어의 제2 텍스트를 출력 데이터로 하여 학습된 모델일 수 있다. 한편, 제1 디코더의 입력 데이터인 특징 벡터와 제2 디코더의 입력 데이터인 특징 벡터가 동일하면, 제1 디코더 의 출력 데이터인 제1 언어의 제1 텍스트와 제2 디코더의 출력 데이터인 제2 언어의 제2 텍스트의 의미는 임계 값 이상의 유사도를 가질 수 있다. 한편, 메모리에 저장된 신경망 모델은 통계적 기계 번역(Statistical machine translation, SMT) 모델에 기반한 모델일 수도 있고, 신경망 기계 번역(Neural machine translation, NMT)에 기반한 모델일 수도 있다. 여기서, 신경망 기계 번역 모델(NMT)은 단어를 개별적으로 번역하는 것이 아닌, 전체 문장, 구 단위로 번역을 수행함에 따라 자연스럽고 완성도 높은 번역물을 출력하는 효과가 있다. 이에 대한 구체적인 설명은 도 8을 참 조하여 후술하도록 한다. 도 4는 본 개시의 일 실시 예에 따른 전자 장치와 외부 장치의 통신을 설명하기 위한 도면이다. 도 4를 참조하면, 프로세서는 마이크를 통해 제1 언어의 사용자 음성(예를 들어, 안녕)이 수신되면, 제1 언어에 대응되는 제1 인코더(1-1)에 입력하여 제1 특징 벡터를 획득할 수 있다. 이어서, 프로세서는 통신 인터페이스를 이용하여 제1 특징 벡터를 제1 외부 장치, 제2 외부 장 치 등으로 전송할 수 있다. 한편, 제1 외부 장치는 수신된 제1 특징 벡터를 제2 언어에 대응되는 제2 디코더(2-2)에 입력하여 제2 언 어의 제2 텍스트(예를 들어, Hello)를 획득할 수 있다. 다른 예로, 제1 외부 장치는 제2 언어의 사용자 음성(예를 들어, Hello)이 수신되면, 제2 언어에 대응되는 제2 인코더(1-2)에 입력하여 제2 특징 벡터를 획득할 수 있다. 이어서, 제1 외부 장치는 제2 특징 벡터를 전자 장치 또는 제2 외부 장치 등으로 전송할 수 있 다. 전자 장치에 구비된 프로세서는 수신된 제2 특징 벡터를 제1 언어에 대응되는 제1 디코더(2-1)에 입 력하여 제1 언어의 제1 텍스트(예를 들어, 안녕)를 획득할 수 있다. 이어서, 프로세서는 TTS(Text to speech) 모델을 이용하여 제1 언어의 제1 텍스트에 대응되는 제1 언어의 사운드를 획득할 수 있고, 제1 언어의 사운드를 출력부를 통해 출력할 수 있다. 여기서, 출력부는 스피커로 구현될 수 있으며, 다른 예로, 디스플레이 등으로 구현될 수도 있음은 물론이다. 도 5는 본 개시의 일 실시 예에 따른 압축 과정을 설명하기 위한 도면이다. 도 5는 전자 장치와 외부 장치 간의 통신 효율을 증대시키기 위하여 특징 벡터를 압축한 뒤 전송하는 방법 을 설명하기 위한 도면이다. 도 4에서 설명한 바와 같이, 프로세서는 마이크를 통해 제1 언어의 사용자 음성(예를 들어, 안녕)이 수신되면, 제1 언어에 대응되는 제1 인코더(1-1)에 입력하여 제1 특징 벡터를 획득할 수 있다. 여기서, 메모리는 특징 벡터를 압축하기 위한 다양한 압축 알고리즘(이하, 컴프레서(compressor)을 저장할 수 있다. 프로세서는 컴프레서를 이용하여 제1 특징 벡터를 압축한 뒤, 압축된 제1 특징 벡터를 통신 인터 페이스를 이용하여 제1 외부 장치, 제2 외부 장치 등으로 전송할 수 있다. 한편, 제1 외부 장치는 다양한 압축 해제 알고리즘(이하, 디컴프레서(decompressor))을 이용하여 압축된 제1 특징 벡터의 압축을 해제할 수 있다. 이어서, 제1 외부 장치는 제1 특징 벡터를 제2 언어에 대응되는 제2 디코더(2-2)에 입력하여 제2 언어의 제2 텍스트(예를 들어, Hello)를 획득할 수 있다. 다른 예로, 제1 외부 장치는 제2 언어의 사용자 음성(예를 들어, Hello)이 수신되면, 제2 언어에 대응되는 제2 인코더(1-2)에 입력하여 제2 특징 벡터를 획득하고, 제2 특징 벡터를 압축한 뒤 전자 장치로 전송할 수 있다. 전자 장치에 구비된 프로세서는 압축된 제2 특징 벡터를 메모리에 저장된 디컴프세서를 이용하 여 압축을 해제할 수 있다. 이어서, 프로세서는 제2 특징 벡터를 제1 언어에 대응되는 제1 디코더(2-1)에 입력하여 제1 언어의 제1 텍스트(예를 들어, 안녕)를 획득할 수 있다. 한편, 전자 장치, 외부 장치 각각에 구비된 컴프레서 및 디컴프레서는 종래의 공간 영역 성분인 벡터를 압 축(또는, 압축 해제)하는 알고리즘을 이용할 수 있다. 여기서, 벡터 압축 알고리즘은 손실 또는 무손실 압축 알 고리즘 중 적어도 하나를 포함할 수 있다. 예를 들어, 프로세서는 전자 장치와 외부 장치 간의 통신 상태를 식별하며, 통신 상태에 따른 대역폭, 속도 등이 기준치 미만이면, 손실 압축 알고리즘을 이용하여 특징 벡터를 상대적으로 높은 압축률로 압 축할 수 있다. 다른 예로, 프로세서는 전자 장치와 외부 장치 간의 통신 상태를 식별하며, 통신 상태에 따른 대역폭, 속도 등이 기준치 이상이면, 무손실 압축 알고리즘을 이용하여 특징 벡터를 상대적으로 낮은 압축률로 압축할 수 있다. 또 다른 예로, 프로세서는 압축하지 않은 특징 벡터를 외부 장치로 전송할 수도 있음은 물론이다. 도 6은 본 개시의 일 실시 예에 따른 특징 벡터를 전송하는 과정을 설명하기 위한 시퀀스도이다. 도 6을 참조하면, 마이크를 통해 수신된 제1 언어의 사용자 음성이 프로세서로 전송된다(S610). 프로 세서는 ASR 모듈을 이용하여 사용자 음성에 대응되는 제1 텍스트를 획득할 수 있다(S620). 이어서, 프로세서는 제1 언어에 대응되는 인코더(1-1)를 이용하여 제1 텍스트에 대응되는 제1 특징 벡터를 획득할 수 있다(S630). 이어서, 프로세서는 제1 특징 벡터를 컴프레서 모듈로 전송할 수 있다(S640). 프로세서는 컴프레서 모듈을 이용하여 제1 특징 벡터를 압축하며(S650), 압축된 제1 특징 벡터를 통신 인터페이스로 전송할 수있다(S660). 이어서, 프로세서는 통신 인터페이스를 통해 압축된 제1 특징 벡터를 제1 외부 장치로 전송할 수 있다(S670). 도 7은 본 개시의 일 실시 예에 따른 특징 벡터를 수신하는 과정을 설명하기 위한 시퀀스도이다. 도 7을 참조하면, 통신 인터페이스를 통해 제1 외부 장치로부터 압축된 제2 특징 벡터를 수신한다 (S710). 이어서, 프로세서는 통신 인터페이스로부터 압축된 제2 특징 벡터가 수신되면(S720), 디컴프 레서 모듈을 이용하여 압축된 제2 특징 벡터를 압축 해제할 수 있다(S730). 이어서, 프로세서는 제2 특징 벡터를 제1 언어에 대응되는 제1 디코더(2-1)에 입력하여 제1 언어에 대응되 는 제2 텍스트를 획득할 수 있다(S750). 프로세서는 제1 언어에 대응되는 제2 텍스트를 TTS 모델에 입력하 여 제2 텍스트에 대응되는 사운드를 획득할 수 있으며, 사운드를 출력부로 전송할 수 있다. 이어서, 전자 장치는 출력부를 이용하여 사운드를 출력할 수 있다. 도 8은 본 개시의 일 실시 예에 따른 인코더와 디코더의 학습 과정을 설명하기 위한 도면이다. 우선, 복수의 언어 각각에 대응되는 인코더 및 복수의 언어 각각에 대응되는 디코더가 구비된다. 여기서, 복수의 언어 중 제1 언어에 대응되는 제1 인코더는 제1 언어의 제1 텍스트를 입력 데이터(Source sentence)로 하며, 복수의 언어 중 제2 언어에 대응되는 제2 인코더는 제2 언어의 제2 텍스트를 입력 데이터 (Source sentence)로 한다. 여기서, 제1 언어의 제1 텍스트와 제2 언어의 제2 텍스트는 언어는 상이하나 의미가 동일할 수 있다(또는, 의미 가 임계 값 이상의 유사도를 가질 수 있다). 한편, 제1 인코더와 제2 인코더 각각은, 시퀀스-투-시퀀스(sequence-to-sequence) 모델일 수 있다. 여기서, 시 퀀스(sequence)란 서로 연관된 연속의 데이터를 의미하며, 본 개시에 있어서 시퀀스(sequence)란 개별적인 단어 가 아닌, 문장, 구 단위를 의미할 수 있다. 예를 들어, 제1 언어의 제1 텍스트, 제2 언어의 제2 텍스트 등은 서 로 연관된 연속의 데이터 즉, 문장(sentence)일 수 있다. <복수의 언어 각각에 대응되는 의미가 유사한 Source sentence 획득 방법> 예를 들어, 프로세서는 언어 모델(Language Model, LM)을 이용하여 복수의 언어 각각에 대응되는 텍스트를 획득할 수 있다. 여기서, 언어 모델은 제1 언어의 문장이 입력되면, 임계 값 이상의 유사도를 갖는 제2 언어의 문장을 출력하도록 학습된 인공 지능 모델을 의미할 수 있다. 언어 모델은 시퀀스-투-시퀀스(sequence-to-sequence) 모델일 수 있으며, 입력 데이터의 처리를 위한 인코더 (encoder) 및 출력 데이터의 처리를 위한 디코더(decoder)를 포함할 수 있다. 여기서, 인코더 및 디코더 각각은 복수의 순환 신경망(Recurrent Neural Network, RNN) 셀을 포함할 수 있다. 예를 들어, 복수의 RNN 셀은 LSTM(Long Short-Term Memory) 또는 GRU(Gated Recurrent Unit)로 구성될 수 있다. 일 실시 예에 따른 언어 모델은 신경망 기계 번역(NMT) 모델이며, 프로세서는 제1 언어의 제1 텍스트가 수 신되면, NMT 모델에 입력하여 제2 언어의 제2 텍스트를 획득할 수 있다. 여기서, 신경망 기계 번역 모델은 병렬 코퍼스(parallel corpus)에 기초하여 학습된 모델일 수 있다. 여기서, 병렬 코퍼스는 서로 다른 언어의 문장들이 서로 대응되도록 병렬적으로 구성된 코퍼스일 수 있다. 신경망 기계 번역 모델은 제1 언어의 제1 텍스트를 제2 언어의 제2 텍스트로 번역하기 위한 병렬 코퍼스에 포함된 복수의 문 장에 기초하여 학습될 수 있다. <인코더의 학습 방법> 한편, 프로세서는 신경망 기계 번역 모델을 이용하여 획득된 제1 언어의 제1 텍스트 및 제2 언어의 제2 텍 스트 각각을 제1 인코더 및 제2 인코더에 입력할 수 있다. 여기서, 제1 텍스트와 제2 텍스트는 언어는 상이하나, 의미가 동일하므로, 제1 인코더가 제1 텍스트를 변환하여 출력한 특징 벡터와 제2 인코더가 제2 텍스트를 변환하여 출력한 특징 벡터가 동일하도록 제1 인코더와 제2 인 코더는 학습될 수 있다. 한편, 특징 벡터는 컨텍스트 벡터(context vector)로 불릴 수도 있다. 인코더는 입력 데이터 즉, 문장을 구성하 는 복수의 단어들을 순차적으로 입력받은 뒤, 복수의 단어들을 포함하는 문장을 하나의 컨텍스트 벡터로 표현할 수 있다. 컨텍스트 벡터는 차원, 사이즈는 다양할 수 있다. 이하에서는 설명의 편의를 위해 특징 벡터로 통칭하 도록 한다. <디코더의 학습 방법> 일 실시 예에 따라, 프로세서는 제1 인코더를 이용하여 획득된 특징 벡터를 제2 디코더에 입력하며, 제2 디코더를 이용하여 획득된 특징 벡터를 제1 디코더에 입력할 수 있다. 한편, 제1 디코더와 제2 디코더 각각에 입력되는 특징 벡터가 동일하므로, 제1 디코더가 출력하는 제1 언어의 제1 텍스트와 제2 디코더가 출력하는 제2 언어의 제2 텍스트는 언어는 상이하나, 의미가 동일하도록 제1 디코더 및 제2 디코더가 학습될 수 있다. <인코더와 디코더의 동작 방법> 일 실시 예에 따른, 인코더는 토큰화(tokenization)를 통해 텍스트를 단어 단위로 나누며, 워드 임베딩(word embedding)을 통해 나누어진 각각의 단어를 특징 벡터로 변환할 수 있다. 그리고, 디코더는 특징 벡터로 변환된 각각의 단어를 언어 모델에 포함되는 각각의 RNN 셀에 대한 각 시점(time-step)에 입력하며, 각 시점(time step)의 RNN 셀에서 출력 벡터가 나오면, 출력 벡터를 소프트맥스 함수를 통해 출력 시퀀스의 각 단어별 확률값 으로 변환하고, 디코더는 출력 단어 즉, 텍스트를 결정할 수 있다. 도 9는 본 개시의 일 실시 예에 따른 서버와 통신을 수행하는 전자 장치를 설명하기 위한 도면이다. 상술한 실시 예들에서 전자 장치가 제1 언어에 대응되는 제1 인코더와 제1 디코더를 포함하며, 제1 외부 장치가 제2 언어에 대응되는 제2 인코더와 제2 디코더를 포함하므로, 전자 장치와 제1 외부 장치 가 특징 벡터를 전송 또는 수신하여도 제1 언어에서 제2 언어로의 번역 기능 또는 제2 언어에서 제1 언어 로의 번역 기능을 원활히 제공할 수 있었다. 다만, 전자 장치가 통신을 수행하는 제1 외부 장치가 제2 언어에 대응되는 제2 인코더와 제2 디코더 를 포함하지 않으면, 전자 장치가 제1 언어의 텍스트를 특징 벡터로 변환한 뒤, 특징 벡터를 제1 외부 장 치로 전송하여도 제1 외부 장치는 특징 벡터를 제2 언어의 텍스트로 변환하기 위한 제2 디코더가 부 재하므로, 제2 언어의 텍스트를 획득할 수 없다는 문제가 있다. 본 개시의 다른 실시 예에 따라 전자 장치는 제1 외부 장치와 통신을 수행하여 제1 외부 장치가 제2 언어에 대응되는 제2 디코더를 포함하는지 여부를 식별할 수 있다. 이어서, 프로세서는 제1 외부 장치가 제2 디코더를 포함하는 것으로 식별되면, 특징 벡터를 제1 외부 장치로 전송할 수 있다. 다른 예로, 프로세서는 제1 외부 장치가 제2 디코더를 포함하지 않는 것으로 식별되면, 특징 벡터를 서버로 전송할 수 있다. 이어서, 프로세서는 전송에 따라 서버로부터 제2 언어의 텍스트가 수신되면, 수신된 제2 언어의 텍 스트를 제1 외부 장치로 전송할 수 있다. 따라서, 제1 외부 장치가 전자 장치처럼 사용자의 주된 언어에 대응되는 인코더 및 디코더를 구비하 지 않은 경우에도, 전자 장치의 사용자와 제1 외부 장치의 사용자 간의 커뮤니케이션이 가능할 수 있 다. 도 3으로 돌아와서, 본 개시의 일 실시 예에 따른 전자 장치, 외부 장치는 예를 들면, 스마트폰, 태블릿 PC, 이동 전화기, 영상 전화기, 전자책 리더기, 데스크탑 PC, 랩탑 PC, 넷북 컴퓨터, 워크스테이션, 서버, PDA, PMP(portable multimedia player), MP3 플레이어, 의료기기, 카메라, 가상 현실(virtual reality(VR)) 구현 장 치 또는 웨어러블 장치 중 적어도 하나를 포함할 수 있다. 웨어러블 장치는 액세서리형(예: 시계, 반지, 팔찌, 발찌, 목걸이, 안경, 콘택트 렌즈, 또는 머리 착용형 장치(head-mounted-device(HMD)), 직물 또는 의류 일체형 (예: 전자 의복), 신체 부착형(예: 스킨 패드 또는 문신), 또는 생체 이식형 회로 중 적어도 하나를 포함할 수 있다. 어떤 실시 예들에서, 전자 장치는 예를 들면, 텔레비전, DVD(digital video disk) 플레이어, 오디오, 냉장 고, 에어컨, 청소기, 오븐, 전자레인지, 세탁기, 공기 청정기, 셋톱 박스, 홈 오토매이션 컨트롤 패널, 보안 컨트롤 패널, 미디어 박스(예: 삼성 HomeSyncTM, 애플TVTM, 또는 구글 TVTM), 게임 콘솔(예: XboxTM, PlayStationTM), 전자 사전, 전자 키, 캠코더, 또는 전자 액자 중 적어도 하나를 포함할 수 있다. 다른 실시 예에서, 전자 장치는 각종 의료기기(예: 각종 휴대용 의료측정기기(혈당 측정기, 심박 측정기, 혈압 측정기, 또는 체온 측정기 등), MRA(magnetic resonance angiography), MRI(magnetic resonance imaging), CT(computed tomography), 촬영기, 또는 초음파기 등), 네비게이션 장치, 위성 항법 시스템 (GNSS(global navigation satellite system)), EDR(event data recorder), FDR(flight data recorder), 자동 차 인포테인먼트 장치, 선박용 전자 장비(예: 선박용 항법 장치, 자이로 콤파스 등), 항공 전자기기(avionics), 보안 기기, 차량용 헤드 유닛(head unit), 산업용 또는 가정용 로봇, 드론(drone), 금융 기관의 ATM, 상점의 POS(point of sales), 또는 사물 인터넷 장치 (예: 전구, 각종 센서, 스프링클러 장치, 화재 경보기, 온도조절 기, 가로등, 토스터, 운동기구, 온수탱크, 히터, 보일러 등) 중 적어도 하나를 포함할 수 있다. 본 개시에서, 인공 지능 모델이 학습된다는 것은, 기본 인공 지능 모델(예를 들어 임의의 랜덤한 파라미터를 포 함하는 인공 지능 모델)이 학습 알고리즘에 의하여 다수의 훈련 데이터들을 이용하여 학습됨으로써, 원하는 특 성(또는, 목적)을 수행하도록 설정된 기 정의된 동작 규칙 또는 인공 지능 모델이 만들어짐을 의미한다. 이러한 학습은 별도의 서버 및/또는 시스템을 통해 이루어질 수 있으나, 이에 한정되는 것은 아니며 전자 장치에 서 이루어질 수도 있다. 학습 알고리즘의 예로는, 지도형 학습(supervised learning), 비지도형 학습 (unsupervised learning), 준지도형 학습(semi-supervised learning), 전이 학습(transfer learning) 또는 강 화 학습(reinforcement learning)이 있으나, 전술한 예에 한정되지 않는다. 여기서, 인공 지능 모델 각각은, 예를 들어, CNN (Convolutional Neural Network), RNN (Recurrent Neural Network), RBM (Restricted Boltzmann Machine), DBN (Deep Belief Network), BRDNN(Bidirectional Recurrent Deep Neural Network) 또는 심층 Q-네트워크 (Deep Q-Networks) 등으로 구현될 수 있으나, 이에 한정되지 않는 다. 본 개시의 일 실시 예에 따른 인공 지능 모델을 실행하기 위한 프로세서는 CPU, AP, DSP(Digital Signal Processor) 등과 같은 범용 프로세서, GPU, VPU(Vision Processing Unit)와 같은 그래픽 전용 프로세서 또는 NPU와 같은 인공 지능 전용 프로세서와 소프트웨어의 조합을 통해 구현될 수 있다. 프로세서는, 메모리 에 저장된 기 정의된 동작 규칙 또는 인공 지능 모델에 따라, 입력 데이터를 처리하도록 제어할 수 있다. 또는, 프로세서가 전용 프로세서(또는 인공 지능 전용 프로세서)인 경우, 특정 인공 지능 모델의 처리에 특화된 하드웨어 구조로 설계될 수 있다. 예를 들어, 특정 인공 지능 모델의 처리에 특화된 하드웨어는 ASIC, FPGA 등의 하드웨어 칩으로 설계될 수 있다. 프로세서가 전용 프로세서로 구현되는 경우, 본 개시의 실시 예를 구현하기 위한 메모리를 포함하도록 구현되거나, 외부 메모리를 이용하기 위한 메모리 처리 기능을 포함하 도록 구현될 수 있다. 다른 예에 따라, 메모리는 복수의 레이어를 포함하는 인공 지능 모델에 관한 정보를 저장할 수 있다. 여기 서, 인공 지능 모델에 관한 정보를 저장한다는 것은 인공 지능 모델의 동작과 관련된 다양한 정보, 예를 들어 인공 지능 모델에 포함된 복수의 레이어에 대한 정보, 복수의 레이어 각각에서 이용되는 파라미터(예를 들어, 필터 계수, 바이어스 등)에 대한 정보 등을 저장한다는 것을 의미할 수 있다. 도 10은 본 개시의 일 실시 예에 따른 전자 장치의 제어 방법을 설명하기 위한 흐름도이다. 본 개시의 일 실시 예에 따른 전자 장치의 제어 방법은, 우선, 제1 언어의 사용자 음성이 수신되면, 사용자 음 성에 대응되는 제1 언어의 텍스트를 획득한다(S1010). 이어서, 제1 언어의 텍스트를 제1 언어에 대응되는 제1 인코더에 입력하여 제1 특징 벡터를 획득한다(S1020). 이어서, 제1 특징 벡터를 외부 장치로 전송한다(S1030). 이어서, 외부 장치로부터 제2 특징 벡터가 수신되면, 제2 특징 벡터를 제1 언어에 대응되는 제1 디코더에 입력 하여 제2 특징 벡터에 대응되는 제1 언어의 텍스트를 획득한다(S1040). 일 실시 예에 따른 제1 인코더는, 제1 언어의 제1 텍스트 및 벡터 공간 상의 특징 벡터를 입력 데이터 및 출력 데이터로 하여 학습된 모델이고, 제1 언어와 상이한 제2 언어에 대응되는 제2 인코더는, 제1 텍스트와 임계 값 이상의 유사도를 가지는 제2 언어의 제2 텍스트 및 벡터 공간 상의 특징 벡터를 입력 데이터 및 출력 데이터로 하여 학습된 모델일 수 있다. 또한, 제2 언어에 대응되는 제2 인코더는, 외부 장치에 포함되며, 제2 언어의 사용자 음성에 대응되는 텍스트가 입력되면, 제2 특징 벡터를 출력할 수 있다. 여기서, 제1 디코더는, 벡터 공간 상의 특징 벡터 및 제1 언어의 제1 텍스트를 입력 데이터 및 출력 데이터로 하여 학습된 모델이고, 제1 언어와 상이한 제2 언어에 대응되는 제2 디코더는, 벡터 공간 상의 특징 벡터 및 제 1 텍스트와 임계 값 이상의 유사도를 가지는 제2 언어의 제2 텍스트를 입력 데이터 및 출력 데이터로 하여 학습 된 모델일 수 있다. 여기서, 제2 언어에 대응되는 제2 디코더는, 외부 장치에 포함되며, 전자 장치로부터 수신된 제1 특징 벡터가 입력되면, 제2 언어의 텍스트를 출력할 수 있다. 여기서, 외부 장치와 통신을 수행하여 외부 장치가 제2 언어에 대응되는 제2 디코더를 포함하는지 여부를 식별 하는 단계, 외부 장치가 제2 디코더를 포함하는 것으로 식별되면, 제1 특징 벡터를 외부 장치로 전송하는 단계 및 외부 장치가 제2 디코더를 포함하지 않는 것으로 식별되면, 제1 특징 벡터를 서버로 전송하는 단계를 더 포 함할 수 있다. 일 실시 예에 따른 제어 방법은 TTS(Text to speech)를 이용하여 제1 언어의 텍스트에 대응되는 제1 언어의 사 운드를 획득하는 단계 및 제1 언어의 사운드를 출력하는 단계를 더 포함할 수 있다. 일 실시 예에 따른 제어 방법은 컴프레서에 기초하여 제1 특징 벡터를 압축하는 단계, 압축된 제1 특징 벡터를 통신 인터페이스를 통해 외부 장치로 전송하는 단계, 외부 장치로부터 압축된 제2 특징 벡터가 수신되면, 디컴 프레서에 기초하여 압축된 제2 특징 벡터를 압축 해제하는 단계 및 압축 해제된 제2 특징 벡터를 제1 디코더에 입력하는 단계를 더 포함할 수 있다. 일 실시 예에 따른 제1 인코더 및 제1 디코더는, 신경망 기계 번역(Neural machine translation, NMT) 모델에 포함되며, 신경망 기계 번역 모델은, 사용자 음성이 입력되면, 사용자 음성에 대응되는 텍스트를 벡터 값으로 변환하여 제1 특징 벡터를 획득하며, 제2 특징 벡터가 입력되면, 제2 특징 벡터를 제1 언어의 텍스트로 변환할 수 있다. 다만, 본 개시의 다양한 실시 예들은 전자 장치 뿐 아니라, 음성 신호를 수신할 수 있는 모든 전자 장치에 적용 될 수 있음은 물론이다. 한편, 이상에서 설명된 다양한 실시 예들은 소프트웨어(software), 하드웨어(hardware) 또는 이들의 조합을 이 용하여 컴퓨터(computer) 또는 이와 유사한 장치로 읽을 수 있는 기록 매체 내에서 구현될 수 있다. 일부 경우 에 있어 본 명세서에서 설명되는 실시 예들이 프로세서 자체로 구현될 수 있다. 소프트웨어적인 구현에 의하면, 본 명세서에서 설명되는 절차 및 기능과 같은 실시 예들은 별도의 소프트웨어 모듈들로 구현될 수 있다. 소프트 웨어 모듈들 각각은 본 명세서에서 설명되는 하나 이상의 기능 및 동작을 수행할 수 있다. 한편, 상술한 본 개시의 다양한 실시 예들에 따른 전자 장치의 프로세싱 동작을 수행하기 위한 컴퓨터 명 령어(computer instructions)는 비일시적 컴퓨터 판독 가능 매체(non-transitory computer-readable medium) 에 저장될 수 있다. 이러한 비일시적 컴퓨터 판독 가능 매체에 저장된 컴퓨터 명령어는 특정 기기의 프로세서에 의해 실행되었을 때 상술한 다양한 실시 예에 따른 음향 출력 장치에서의 처리 동작을 특정 기기가 수행하 도록 한다. 비일시적 컴퓨터 판독 가능 매체란 레지스터, 캐쉬, 메모리 등과 같이 짧은 순간 동안 데이터를 저장하는 매체 가 아니라 반영구적으로 데이터를 저장하며, 기기에 의해 판독(reading)이 가능한 매체를 의미한다. 비일시적 컴퓨터 판독 가능 매체의 구체적인 예로는, CD, DVD, 하드 디스크, 블루레이 디스크, USB, 메모리카드, ROM 등 이 있을 수 있다. 이상에서는 본 개시의 바람직한 실시 예에 대하여 도시하고 설명하였지만, 본 개시는 상술한 특정의 실시 예에"}
{"patent_id": "10-2022-0046172", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "한정되지 아니하며, 청구범위에서 청구하는 본 개시의 요지를 벗어남이 없이 당해 개시에 속하는 기술분야에서 통상의 지식을 가진자에 의해 다양한 변형실시가 가능한 것은 물론이고, 이러한 변형실시들은 본 개시의 기술적 사상이나 전망으로부터 개별적으로 이해되어져서는 안될 것이다."}
{"patent_id": "10-2022-0046172", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 종래에 따른 번역 기능을 제공하는 전자 장치에 구비된 인코더 및 디코더를 설명하기 위한 도면이다. 도 2는 본 개시의 일 실시 예에 따른 전자 장치에 구비된 인코더 및 디코더를 설명하기 위한 도면이다. 도 3은 본 개시의 일 실시 예에 따른 전자 장치의 구성을 설명하기 위한 블록도이다. 도 4는 본 개시의 일 실시 예에 따른 전자 장치와 외부 장치의 통신을 설명하기 위한 도면이다. 도 5는 본 개시의 일 실시 예에 따른 압축 과정을 설명하기 위한 도면이다. 도 6은 본 개시의 일 실시 예에 따른 특징 벡터를 전송하는 과정을 설명하기 위한 시퀀스도이다. 도 7은 본 개시의 일 실시 예에 따른 특징 벡터를 수신하는 과정을 설명하기 위한 시퀀스도이다. 도 8은 본 개시의 일 실시 예에 따른 인코더와 디코더의 학습 과정을 설명하기 위한 도면이다. 도 9는 본 개시의 일 실시 예에 따른 서버와 통신을 수행하는 전자 장치를 설명하기 위한 도면이다. 도 10은 본 개시의 일 실시 예에 따른 전자 장치의 제어 방법을 설명하기 위한 흐름도이다."}
