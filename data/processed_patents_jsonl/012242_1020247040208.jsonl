{"patent_id": "10-2024-7040208", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2025-0004080", "출원번호": "10-2024-7040208", "발명의 명칭": "무선 통신 시스템에서 AI 및 ML 미디어 서비스를 제공하기 위한 방법 및 장치", "출원인": "삼성전자주식회사", "발명자": "입에릭"}}
{"patent_id": "10-2024-7040208", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "무선 통신 시스템에서의 사용자 단말(UE)에 의해 수행되는 방법으로서, 제1 네트워크 엔티티로부터 적어도 하나의 인공 지능(AI) 모델에 관한 정보를 수신하는 단계; 상기 적어도 하나의 AI 모델에 관한 정보에 기반하여 AI 모델을 결정하는 단계; AI 분할 추론 서비스를 위해 상기 AI 모델을 사용할지 여부를 결정하는 단계; 상기 제1 네트워크 엔티티에 상기 AI 분할 추론 서비스를 요청하는 단계; 상기 AI 모델을 위한 AI 모델 전달 파이프라인을 수립하는 단계; 및 상기 AI 모델에서 사용되는 미디어 데이터를 전달하기 위한 미디어 전달 파이프라인을 수립하는 단계를 포함하는, 방법."}
{"patent_id": "10-2024-7040208", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 적어도 하나의 AI 모델에 관한 정보는 상기 적어도 하나의 AI 모델의 리스트를 획득하기 위한 URL(uniformresource locator)을 포함하는, 방법."}
{"patent_id": "10-2024-7040208", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서, 상기 방법은,제2 네트워크 엔티티로부터, 미디어 전달 파이프라인 상의 중간 데이터를 수신하는 단계를 더 포함하는, 방법."}
{"patent_id": "10-2024-7040208", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서, 상기 방법은,상기 AI 분할 추론 서비스에 대한 정보에 관한 상태 보고를 상기 제1 네트워크 기능에 전송하는 단계를 더 포함하는, 방법."}
{"patent_id": "10-2024-7040208", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서, 상기 방법은,상기 AI 분할 추론 서비스에 대한 정보와 네트워크 상태에 대한 정보에 기반하여 상기 AI 모델과 상기 AI 모델전달 파이프라인을 업데이트하는 단계를 더 포함하는, 방법."}
{"patent_id": "10-2024-7040208", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "무선 통신 시스템에서의 제1 네트워크 엔티티에 의해 수행되는 방법으로서, 적어도 하나의 인공 지능(AI) 모델에 관한 정보를 사용자 단말(UE)에 전송하는 단계; 적어도 하나의 AI 모델에 관한 정보에 기반하여 결정된 AI 모델을 식별하는 단계; 상기 AI 모델을 사용하여 AI 분할 추론 서비스에 대한 요청을 수신하는 단계; 상기 AI 모델을 위한 AI 모델 전달 파이프라인을 수립하는 단계; 및 상기 AI 모델에서 사용되는 미디어 데이터를 전달하기 위한 미디어 전달 파이프라인을 수립하는 단계를 포함하는, 방법. 공개특허 10-2025-0004080-3-청구항 7 제6항에 있어서, 적어도 하나의 AI 모델에 관한 상기 정보는 상기 적어도 하나의 AI 모델의 리스트를 획득하기 위한 URL(uniformresource locator)을 포함하는, 방법."}
{"patent_id": "10-2024-7040208", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제6항에 있어서, 상기 방법은,상기 사용자 단말로부터 상기 AI 분할 추론 서비스에 대한 정보에 관한 상태 보고를 수신하는 단계를 더 포함하는, 방법."}
{"patent_id": "10-2024-7040208", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서, 상기 방법은,상기 AI 분할 추론 서비스에 대한 정보와 네트워크 상태에 대한 정보에 기반하여 상기 AI 모델과 상기 AI 모델전달 파이프라인을 업데이트하는 단계를 더 포함하는, 방법."}
{"patent_id": "10-2024-7040208", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제6항에 있어서, 상기 방법은,제2 네트워크 엔티티에서 추론 프로세스를 트리거하는 단계를 더 포함하는, 무선 통신 시스템에서의 제1 네트워크 엔티티에 의해 수행되는 방법."}
{"patent_id": "10-2024-7040208", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "무선 통신 시스템에서의 사용자 단말(UE)로서, 적어도 하나의 트랜시버; 및 상기 적어도 하나의 트랜시버와 동작 가능하게 연결된 적어도 하나의 프로세서를 포함하며, 상기 적어도 하나의 프로세서는: 제1 네트워크 엔티티로부터 적어도 하나의 인공 지능(AI) 모델에 관한 정보를 수신하고, 적어도 하나의 AI 모델에 관한 정보에 기반하여 AI 모델을 결정하고, AI 분할 추론 서비스를 위해 상기 AI 모델을 사용할지 여부를 결정하고, 상기 제1 네트워크 엔티티에 상기 AI 분할 추론 서비스를 요청하고, 상기 AI 모델을 위한 AI 모델 전달 파이프라인을 수립하고, 그리고 상기 AI 모델에서 사용되는 미디어 데이터를 전달하기 위한 미디어 전달 파이프라인을 수립하도록 구성되는, 사용자 단말."}
{"patent_id": "10-2024-7040208", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항에 있어서, 적어도 하나의 AI 모델에 관한 상기 정보는 상기 적어도 하나의 AI 모델의 리스트를 획득하기 위한 URL(uniformresource locator)을 포함하는, 사용자 단말."}
{"patent_id": "10-2024-7040208", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제11항에 있어서, 상기 적어도 하나의 프로세서는:제2 네트워크 엔티티로부터, 미디어 전달 파이프라인 상의 중간 데이터를 수신하도록 추가로 구성되는, 사용자공개특허 10-2025-0004080-4-단말."}
{"patent_id": "10-2024-7040208", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제11항에 있어서, 상기 적어도 하나의 프로세서는:상기 AI 분할 추론 서비스에 대한 정보에 관한 상태 보고를 상기 제1 네트워크 기능에 전송하도록 추가로 구성되는, 사용자 단말."}
{"patent_id": "10-2024-7040208", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "무선 통신 시스템에서의 제1 네트워크 엔티티로서, 적어도 하나의 트랜시버; 및 상기 적어도 하나의 트랜시버와 동작 가능하게 연결된 적어도 하나의 프로세서를 포함하며, 상기 적어도 하나의 프로세서는: 적어도 하나의 인공 지능(AI) 모델에 관한 정보를 사용자 단말(UE)에 전송하고, 적어도 하나의 AI 모델에 관한 정보에 기반하여 결정된 AI 모델을 식별하고, 상기 AI 모델을 사용하여 AI 분할 추론 서비스에 대한 요청을 수신하고, 상기 AI 모델을 위한 AI 모델 전달 파이프라인을 수립하고, 그리고 상기 AI 모델에서 사용되는 미디어 데이터를 전달하기 위한 미디어 전달 파이프라인을 수립하도록 구성되는, 제1 네트워크 엔티티."}
{"patent_id": "10-2024-7040208", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 개시는 보다 높은 데이터 레이트를 지원하기 위한 5G 또는 6G 통신 시스템에 관한 것이다. 본 개시의 다양한 실시예에 따르면, 무선 통신 시스템에서의 사용자 단말(UE)에 의해 수행되는 방법은, 제1 네트워크 엔티티로부터 적어도 하나의 인공 지능(AI) 모델에 관한 정보를 수신하는 단계, 적어도 하나의 AI 모델에 관한 정보에 기반하 여 AI 모델을 결정하는 단계, AI 분할 추론 서비스를 위해 AI 모델을 사용할지 여부를 결정하는 단계, 제1 네트 워크 엔티티에 AI 분할 추론 서비스를 요청하는 단계, AI 모델을 위한 AI 모델 전달 파이프라인을 수립하는 단계, 및 AI 모델에서 사용되는 미디어 데이터를 전달하기 위한 미디어 전달 파이프라인을 수립하는 단계를 포함 한다."}
{"patent_id": "10-2024-7040208", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 일반적으로 무선 통신 시스템에 관한 것으로, 보다 구체적으로는 무선 통신 시스템에서 인공 지능 (AI) 및 머신 러닝(ML) 미디어 서비스를 제공하기 위한 방법 및 장치에 관한 것이다."}
{"patent_id": "10-2024-7040208", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "5세대(5G) 이동 통신 기술은 높은 전송률과 새로운 서비스가 가능하도록 넓은 주파수 대역을 정의하고 있으며, 3.5 기가헤르츠(GHz)와 같은 \"6GHz 미만\" 대역뿐만 아니라 28GHz 및 39GHz를 포함한 밀리미터파(mmWave)라고 지 칭되는 \"6GHz 초과\" 대역에서도 구현될 수 있다. 또한, 5G 이동 통신 기술보다 50배 빠른 전송률과 5G 이동 통 신 기술의 10분의 1 수준인 초저지연을 달성하기 위해 테라헤르츠 대역(예를 들어, 95GHz 내지 3THz 대역)에서 6세대(6G) 이동 통신 기술(Beyond 5G 시스템이라고 지칭됨)을 구현하는 것이 고려되어 왔다. 5G 이동 통신 기술의 개발 초기 단계에서, eMBB(enhanced Mobile BroadBand), URLLC(Ultra Reliable Low Latency Communications), 및 mMTC(massive Machine-Type Communications)와 관련된 서비스 지원 및 성능 요구 사항 충족을 위해, mmWave에서 전파 경로 손실을 완화하고, 전파 전송 거리를 증가시키기 위한 빔포밍 및 대규 모 다중 입력 다중 출력(multi input multi output)(MIMO)과, mmWave 리소스를 효율적으로 활용하고, 슬롯 형 식의 동적 운영을 위한 지원 뉴머롤로지(예를 들어, 다수의 동작 서브캐리어 간격)와, 다중 빔 전송 및 광대역 지원을 위한 초기 액세스 기술과, BWP(BandWidth Part)의 정의 및 운용과, 대용량 데이터 전송을 위한 LDPC(Low Density Parity Check) 코드 및 고신뢰성의 제어 정보 전송을 위한 폴라 코드(polar code) 등의 새로운 채널 코딩 방법과, L2 전처리와, 특정 서비스에 특화된 전용 네트워크를 제공하기 위한 네트워크 슬라이싱에 대한 표 준화가 진행 중이다. 현재, 5G 이동 통신 기술에 의해 지원될 서비스의 측면에서 초기 5G 이동 통신 기술의 개선 및 성능 향상에 대 한 논의가 진행 중이며, 자율주행 차량이 전송하는 차량의 위치 및 상태에 관한 정보를 기반으로 자율주행 차량 의 주행 판단을 돕고, 사용자 편의성을 향상시키기 위한 V2X(Vehicle-to-everything), 비면허 대역에서 다양한 규제 관련 요구사항에 부합하는 시스템 운용을 목표로 하는 NR-U(New Radio Unlicensed), NR(new radio)UE(user equipment) 전력 절감(Power Saving), 지상 네트워크와의 통신이 불가능한 지역에서 커버리지를 제공하 고, 포지셔닝을 위한 UE-위성 직접 통신인 비지상 네트워크(Non-Terrestrial Network)(NTN)와 같은 기술에 관한 물리 계층 표준화가 진행 중이다. 또한, 타 산업과의 연동 및 융합을 통해 새로운 서비스를 지원하기 위한 IIoT(Industrial Internet of Things), 무선 백홀 링크와 액세스 링크를 통합 방식으로 지원함으로써 네트워크 서비스 영역 확장을 위한 노드 를 제공하기 위한 IAB(Integrated Access and Backhaul), 조건부 핸드오버 및 DAPS(Dual Active Protocol Stack) 핸드오버를 포함한 이동성 향상, 및 랜덤 액세스 절차 간소화를 위한 2-단계 랜덤 액세스(2-step random-access channel(RACH) for NR) 등의 기술에 관한 무선 인터페이스 아키텍처/프로토콜의 표준화가 진행 중이다. 또한 NFV(Network Functions Virtualization) 및 SDN(Software-Defined Networking) 기술을 결합하기 위한 5G 기본 아키텍처(예를 들어, 서비스 기반 아키텍처 또는 서비스 기반 인터페이스)와 UE 위치에 기반한 서 비스를 수신하기 위한 MEC(Mobile Edge Computing)에 관한 시스템 아키텍처/서비스의 표준화가 진행 중이다. 5G 이동 통신 시스템이 상용화됨에 따라, 기하급수적으로 증가하고 있는 커넥티드 디바이스들이 통신 네트워크 에 접속될 것이며, 이에 따라 5G 이동 통신 시스템의 기능 및 성능의 향상과 커넥티드 디바이스들의 통합 운용 이 필요할 것으로 예상된다. 이를 위해, 인공 지능(Artificial Intelligence)(AI) 및 머신 러닝(Machine Learning)(ML), AI 서비스 지원, 메타버스 서비스 지원, 및 드론 통신을 활용하여, 증강 현실(Augmented Reality)(AR), 가상 현실(Virtual Reality)(VR), 혼합 현실(Mixed Reality)(MR) 등을 효율적으로 지원하기 위 한 확장 현실(eXtended Reality)(XR), 5G 성능 향상, 및 복잡성 감소와 연계한 새로운 연구가 예정되어 있다. 또한, 이러한 5G 이동 통신 시스템 개발은, 6G 이동 통신 기술, 테라헤르츠 대역 신호의 커버리지를 향상시키기 위한 FD-MIMO(Full Dimensional MIMO), 어레이 안테나 및 대규모 안테나, 메타물질 기반의 렌즈 및 안테나 등의 다중 안테나 전송 기술, OAM(Orbital Angular Momentum), 및 RIS(Reconfigurable Intelligent Surface)를 이용 한 고차원 공간 다중화 기술의 테라헤르츠 대역의 커버리지를 제공하기 위한 새로운 파형뿐만 아니라, 6G 이동 통신 기술의 주파수 효율을 증가시키고 시스템 네트워크를 향상시키기 위한 전이중 기술(full-duplex technology), 설계 단계부터 인공위성과 인공 지능(Artificial Intelligence)(AI)을 활용하고 종단간 AI 지원 기능을 내재화하여 시스템 최적화를 구현하기 위한 AI 기반 통신 기술, 및 초고성능 통신 및 컴퓨팅 리소스를 활용하여 UE 운용 능력의 한계를 뛰어넘는 복잡성 수준의 서비스를 구현하기 위한 차세대 분산형 컴퓨팅 기술을 개발하기 위한 토대로서 기능할 것이다. 위의 정보는 본 개시의 이해를 돕기 위한 배경 정보로서만 제공된다. 위의 내용 중 어느 것이 본 개시와 관련한 선행 기술로서 적용될 수 있는지 여부에 대해 어떠한 결정도 이루어지지 않았으며, 어떠한 단정도 이루어지지 않았다."}
{"patent_id": "10-2024-7040208", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "위의 논의에 기반하여, 본 개시의 다양한 실시예는 무선 통신 시스템에서 인공 지능(AI) 및 머신 러닝(ML) 미디 어 서비스를 제공하기 위한 방법 및 장치를 제공하는 것이다."}
{"patent_id": "10-2024-7040208", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "예시적인 실시예의 일 양태에 따르면, 무선 통신에서의 통신 방법이 제공된다."}
{"patent_id": "10-2024-7040208", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 개시의 다양한 실시예에서는 무선 통신 시스템에서 인공 지능(AI) 및 머신 러닝(ML) 미디어 서비스를 제공하 기 위한 방법 및 장치를 제공할 수 있다. 본 개시에서 획득 가능한 효과는 위에 언급된 효과에 국한되지 않으며, 언급되지 않은 다른 효과가 아래의 설명 을 통해 당업자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2024-7040208", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 개시의 다양한 실시예에 따르면, 무선 통신 시스템에서의 사용자 단말(UE)에 의해 수행되는 방법을 제공하며, 이 방법은, 제1 네트워크 엔티티로부터 적어도 하나의 인공 지능(AI) 모델에 관한 정보를 수신하는 단계, 적어도 하나의 AI 모델에 관한 정보에 기반하여 AI 모델을 결정하는 단계, AI 분할 추론 서비스를 위해 상기 AI 모델을 사용할지 여부를 결정하는 단계, 제1 네트워크 엔티티에 AI 분할 추론 서비스를 요청하는 단계, AI 모델을 위한 AI 모델 전달 파이프라인을 수립하는 단계, 및 AI 모델에서 사용되는 미디어 데이터를 전달하기 위한 미디어 전달 파이프라인을 수립하는 단계를 포함한다. 적어도 하나의 AI 모델에 관한 정보는 적어도 하나의 AI 모델의 리스트를 획득하기 위한 URL(uniform resource locator)을 포함한다. 방법은 제2 네트워크 엔티티로부터 미디어 전달 파이프라인 상의 중간 데이터를 수신하는 단계를 더 포함할 수 있다. 방법은 AI 분할 추론 서비스에 대한 정보에 관한 상태 보고를 제1 네트워크 기능부에 전송하는 단계를 더 포함 할 수 있다. 방법은 AI 분할 추론 서비스에 대한 정보와 네트워크 상태에 대한 정보에 기반하여 AI 모델과 AI 모델 전달 파 이프라인을 업데이트하는 단계를 더 포함할 수 있다. 본 개시의 다양한 실시예에 따르면, 무선 통신 시스템에서의 제1 네트워크 엔티티에 의해 수행되는 방법을 제공 하며, 이 방법은, 적어도 하나의 인공 지능(AI) 모델에 관한 정보를 사용자 단말(UE)에 전송하는 단계, 적어도 하나의 AI 모델에 관한 정보에 기반하여 결정된 AI 모델을 식별하는 단계, AI 모델을 사용하여 AI 분할 추론 서 비스에 대한 요청을 수신하는 단계, AI 모델을 위한 AI 모델 전달 파이프라인을 수립하는 단계, 및 AI 모델에서 사용되는 미디어 데이터를 전달하기 위한 미디어 전달 파이프라인을 수립하는 단계를 포함한다. 적어도 하나의 AI 모델에 관한 정보는 적어도 하나의 AI 모델의 리스트를 획득하기 위한 URL(uniform resource locator)을 포함한다. 방법은 UE로부터 AI 분할 추론 서비스에 대한 정보에 관한 상태 보고를 수신하는 단계를 더 포함할 수 있다. 방법은 AI 분할 추론 서비스에 대한 정보와 네트워크 상태에 대한 정보에 기반하여 AI 모델과 AI 모델 전달 파 이프라인을 업데이트하는 단계를 더 포함할 수 있다. 방법은 제2 네트워크 엔티티에서 추론 프로세스를 트리거하는 단계를 더 포함할 수 있다. 본 개시의 다른 실시예에 따르면, 무선 통신 시스템에서의 사용자 단말(UE)은: 적어도 하나의 트랜시버; 및 상 기 적어도 하나의 트랜시버와 동작 가능하게 연결된 적어도 하나의 프로세서를 포함하며, 상기 적어도 하나의 프로세서는: 제1 네트워크 엔티티로부터 적어도 하나의 인공 지능(AI) 모델에 관한 정보를 수신하고, 적어도 하 나의 AI 모델에 관한 정보에 기반하여 AI 모델을 결정하고, AI 분할 추론 서비스를 위해 AI 모델을 사용할지 여 부를 결정하고, 제1 네트워크 엔티티에 AI 분할 추론 서비스를 요청하고, AI 모델을 위한 AI 모델 전달 파이프 라인을 수립하고, 그리고 AI 모델에서 사용되는 미디어 데이터를 전달하기 위한 미디어 전달 파이프라인을 수립 하도록 구성된다. 적어도 하나의 AI 모델에 관한 정보는 적어도 하나의 AI 모델의 리스트를 획득하기 위한 URL(uniform resource locator)을 포함한다. 적어도 하나의 프로세서는 제2 네트워크 엔티티로부터 미디어 전달 파이프라인 상의 중간 데이터를 수신하도록 추가로 구성된다. 적어도 하나의 프로세서는 AI 분할 추론 서비스에 대한 정보에 관한 상태 보고를 제1 네트워크 기능부에 전송하 도록 추가로 구성된다. 적어도 하나의 프로세서는 AI 분할 추론 서비스에 대한 정보와 네트워크 상태에 대한 정보에 기반하여 AI 모델 과 AI 모델 전달 파이프라인을 업데이트하도록 추가로 구성된다. 본 개시의 다른 실시예에 따르면, 무선 통신 시스템에서의 제1 네트워크 엔티티는: 적어도 하나의 트랜시버; 및 상기 적어도 하나의 트랜시버와 동작 가능하게 연결된 적어도 하나의 프로세서를 포함하며, 상기 적어도 하나의 프로세서는: 적어도 하나의 인공 지능(AI) 모델에 관한 정보를 사용자 단말(UE)에 전송하고, 적어도 하나의 AI 모델에 관한 정보에 기반하여 결정된 AI 모델을 식별하고, AI 모델을 사용하여 AI 분할 추론 서비스에 대한 요 청을 수신하고, AI 모델을 위한 AI 모델 전달 파이프라인을 수립하고, 그리고 AI 모델에서 사용되는 미디어 데 이터를 전달하기 위한 미디어 전달 파이프라인을 수립하도록 구성된다. 적어도 하나의 AI 모델에 관한 정보는 적어도 하나의 AI 모델의 리스트를 획득하기 위한 URL(uniform resource locator)을 포함한다. 적어도 하나의 프로세서는 UE로부터 AI 분할 추론 서비스에 대한 정보에 관한 상태 보고를 수신하도록 추가로 구성된다. 적어도 하나의 프로세서는 AI 분할 추론 서비스에 대한 정보와 네트워크 상태에 대한 정보에 기반하여 AI 모델 과 AI 모델 전달 파이프라인을 업데이트하도록 추가로 구성된다. 적어도 하나의 프로세서는 제2 네트워크 엔티티에서 추론 프로세스를 트리거하도록 추가로 구성된다. 발명의 모드 본 개시에 사용된 용어는 특정 실시예를 설명하는 데에만 사용되며, 다른 실시예의 범위를 제한하기 위한 것이 아닐 수 있다. 단수의 표현은 문맥상 분명히 달리 규정되지 않는 한 복수의 표현을 포함할 수 있다. 본원에 사용되는 용어는 기술적 또는 과학적 용어를 포함하여, 본 개시에 기술된 기술 분야에서 통상의 기술을 가진 사 람이 일반적으로 이해하는 것과 동일한 의미를 가질 수 있다. 본 개시에서 사용되는 용어 중 일반 사전에 정의 되어 있는 용어는 관련 기술의 문맥상 의미와 동일 또는 유사한 의미를 가지는 것으로 해석될 수 있으며, 본 개 시에서 명시적으로 정의되어 있지 않는 한, 이상적이거나 과도하게 형식적인 의미로 해석되지 않는다. 어떤 경 우에는 본 개시에 정의된 용어라 하더라도 본 개시의 실시예를 배제하는 것으로 해석될 수는 없다. 아래에 설명되는 본 개시의 다양한 실시예에서는 하드웨어 접근 방법을 예로 들어 설명한다. 그러나, 본 개시 의 다양한 실시예는 하드웨어와 소프트웨어를 모두 사용하는 기술을 포함하므로, 본 개시의 다양한 실시예는 소 프트웨어 기반 접근 방법을 배제하지는 않는다. 도 1은 본 개시의 다양한 실시예에 따른 무선 통신 시스템을 도시한 것이다. 도 1은 무선 통신 시스템에서 무 선 채널을 사용하는 일부 노드로서 기지국, 단말, 및 단말을 도시한 것이다. 도 1에서는 단 하 나의 기지국만을 도시하였지만, 기지국과 동일하거나 유사한 다른 기지국이 추가로 포함될 수 있다. 기지국은 단말(120 및 130)에 무선 액세스를 제공하는 네트워크 인프라 구조(network infrastructure)이 다. 기지국은 신호를 전송할 수 있는 거리에 기반한 특정 지리적 영역으로 정의되는 커버리지를 갖는다. 기지국은 기지국 외에도, '액세스 포인트(AP)', 'eNodeB (eNB)', '5세대 노드(5G 노드)', '차세대 nodeB (gNB)', '무선 포인트', '전송/수신 포인트(TRP)', 또는 동등한 기술적 의미를 갖는 다른 용어로 지칭될 수 있 다. 단말과 단말 각각은 사용자에 의해 사용되는 디바이스이며, 무선 채널을 통해 기지국과 통신한 다. 어떤 경우에는 단말과 단말 중 적어도 하나는 사용자의 개입 없이 작동될 수 있다. 다시 말해 서, 단말과 단말 중 적어도 하나는 머신 유형 통신(machine type communication)(MTC)을 수행하는 디바이스이고, 사용자에 의해 휴대되지 않을 수 있다. 단말과 단말 각각은 '단말' 외에도, '사용자 단말(UE)', '이동국', '가입자국', '원격 단말', '무선 단말', '사용자 디바이스', 또는 동등한 기술적 의미를 갖는 다른 용어로 지칭될 수 있다. 기지국, 단말, 및 단말은 mmWave 대역(예컨대, 28GHz, 30GHz, 38GHz, 및 60GHz)에서 무선 신호 를 전송 및 수신할 수 있다. 이 때, 채널 이득을 향상시키기 위해, 기지국, 단말, 및 단말은 빔포밍을 수행할 수 있다. 여기서, 빔포밍은 전송 빔포밍과 수신 빔포밍을 포함할 수 있다. 다시 말해서, 기 지국, 단말, 및 단말은 전송된 신호 또는 수신된 신호에 방향성을 제공할 수 있다. 이를 위해, 기지국, 단말, 및 단말은 빔 탐색 또는 빔 관리 절차를 통해 서빙 빔(112, 113, 121, 및 131) 을 선택할 수 있다. 서빙 빔(112, 113, 121, 및 131)이 선택된 후, 통신은 서빙 빔(112, 113, 121, 및 131)을 전송한 리소스와 준 동일 위치(QCL) 관계에 있는 리소스를 통해 수행될 수 있다. 제1 안테나 포트 상에서 심볼을 전달하는 채널의 대규모 특성이 제2 안테나 포트 상에서 심볼을 전달하는 채널 로부터 추론될 수 있는 경우, 제1 안테나 포트와 제2 안테나 포트는 QCL 관계에 있는 것으로 평가될 수 있다. 예를 들어, 대규모 특성은 지연 확산, 도플러 확산, 도플러 시프트, 평균 이득, 평균 지연, 및 공간 수신기 파 라미터 중 적어도 하나를 포함할 수 있다. 도 2는 본 개시의 다양한 실시예에 따른 무선 통신 시스템에서 기지국의 구성을 도시한 것이다. 도 2에 도시된 구성은 기지국의 구성으로 이해될 수 있다. 아래에서 사용되는 '...유닛' 및 '...부분' 과 같은 용어는 적어도 하나의 기능이나 동작을 처리하는 유닛을 지칭하며, 하드웨어나 소프트웨어에 의해 구현될 수 있거나, 하드웨어와 소프트웨어의 조합에 의해 구현될 수 있다. 도 2를 참조하면, 기지국은 무선 통신 유닛, 백홀 통신 유닛, 저장 유닛, 및 제어 유닛을 포함한다. 무선 통신 유닛은 무선 채널을 통해 신호를 전송 및 수신하기 위한 기능을 수행한다. 예를 들어, 무선 통 신 유닛은 시스템의 물리 계층 표준에 따라 기저대역 신호와 비트 스트림 간의 변환 기능을 수행한다. 예 를 들어, 데이터를 전송하는 경우, 무선 통신 유닛은 전송 비트 스트림을 인코딩 및 변조함으로써 복소 심볼을 제공한다. 또한, 데이터를 수신하는 경우, 무선 통신 유닛은 기저대역 신호를 복조 및 디코딩함으로 써 수신 비트 스트림을 복원한다. 또한, 무선 통신 유닛은 기저대역 신호를 무선 주파수(RF) 대역 신호로 상향변환하고, 해당 신호를 안테나 를 통해 전송하고, 그리고 안테나를 통해 수신된 RF 대역 신호를 기저대역 신호로 하향변환한다. 이를 위해, 무선 통신 유닛은 전송 필터, 수신 필터, 증폭기, 믹서, 발진기, 디지털-아날로그 변환기(digital to analog converter)(DAC), 아날로그-디지털 변환기(analog to digital convertor)(ADC) 등을 포함할 수 있다. 또한, 무선 통신 유닛은 복수의 전송 및 수신 경로를 포함할 수 있다. 또한, 무선 통신 유닛은 복수 의 안테나 요소로 구성된 적어도 하나의 안테나 어레이를 포함할 수 있다. 하드웨어 측면에서, 무선 통신 유닛은 디지털 유닛과 아날로그 유닛으로 구성될 수 있으며, 아날로그 유닛 은 동작 전력, 동작 주파수 등에 따라 복수의 서브 유닛으로 구성될 수 있다. 디지털 유닛은 적어도 하나의 프 로세서(예컨대, 디지털 신호 프로세서(DSP))로 구현될 수 있다. 무선 통신 유닛은 전술한 바와 같이 신호를 전송 및 수신한다. 따라서, 무선 통신 유닛의 전체 또는 일부는 '송신기', '수신기', 또는 '트랜시버'라고 지칭될 수 있다. 또한, 이하의 설명에서 무선 채널을 통해 수행되는 전송 및 수신은 전술한 처리가 무선 통신 유닛에 의해 수행된다는 것을 포함하는 의미로 사용된 다. 백홀 통신 유닛은 네트워크 내의 다른 노드와 통신하기 위한 인터페이스를 제공한다. 다시 말해서, 백홀 통신 유닛은 기지국으로부터 다른 노드로, 예를 들어, 다른 액세스 노드, 다른 기지국, 상위 노드, 코어 네트워크 등으로 전송된 비트 스트림을 물리적 신호로 변환하고, 다른 노드로부터 수신되는 물리적 신호를 비트 스트림으로 변환한다. 저장 유닛은 기지국의 동작을 위한 기본 프로그램, 애플리케이션 프로그램, 설정 정보 등의 데이터를 저장 한다. 저장 유닛은 휘발성 메모리, 비휘발성 메모리, 또는 휘발성 메모리와 비휘발성 메모리의 조합으로 구성될 수 있다. 그리고, 저장 유닛은 제어 유닛의 요청에 따라 저장된 데이터를 제공한다. 제어 유닛은 기지국의 전반적인 동작을 제어한다. 예를 들어, 제어 유닛은 무선 통신 유닛 또 는 백홀 통신 유닛을 통해 신호를 전송 및 수신한다. 또한, 제어 유닛은 저장 유닛에 데이터를 기입하고 저장 유닛의 데이터를 판독한다. 그리고, 제어 유닛은 통신 표준에서 요구하는 프로토콜 스택의 기능을 수행할 수 있다. 다른 구현예에 따르면, 프로토콜 스택은 무선 통신 유닛에 포함될 수 있 다. 이를 위해, 제어 유닛은 적어도 하나의 프로세서를 포함할 수 있다. 도 3은 본 개시의 다양한 실시예에 따른 무선 통신 시스템에서 단말의 구성을 도시한 것이다. 도 3에 도시된 구성은 단말의 구성으로 이해될 수 있다. 아래에서 사용되는 '...유닛' 및 '...부분' 과 같은 용어는 적 어도 하나의 기능이나 동작을 처리하는 유닛을 지칭하며, 하드웨어나 소프트웨어에 의해 구현될 수 있거나, 하 드웨어와 소프트웨어의 조합에 의해 구현될 수 있다. 도 3을 참조하면, 단말은 통신 유닛, 저장 유닛, 및 제어 유닛을 포함한다. 통신 유닛은 무선 채널을 통해 신호를 전송 및 수신하기 위한 기능을 수행한다. 예를 들어, 통신 유닛 은 시스템의 물리 계층 표준에 따라 기저대역 신호와 비트 스트림 간의 변환 기능을 수행한다. 예를 들어, 데이터를 전송하는 경우, 통신 유닛은 전송 비트 스트림을 인코딩 및 변조함으로써 복소 심볼을 제 공한다. 또한, 데이터를 수신하는 경우, 통신 유닛은 기저대역 신호를 복조 및 디코딩함으로써 수신 비트 스트림을 복원한다. 또한, 통신 유닛은 기저대역 신호를 RF 대역 신호로 상향변환하고, 해당 신호를 안테 나를 통해 전송하고, 그리고 안테나를 통해 수신된 RF 대역 신호를 기저대역 신호로 하향변환한다. 예를 들어, 통신 유닛은 전송 필터, 수신 필터, 증폭기, 믹서, 발진기, DAC, ADC 등을 포함할 수 있다. 또한, 통신 유닛은 복수의 전송/수신 경로를 포함할 수 있다. 또한, 통신 유닛은 복수의 안테나 요 소로 구성된 적어도 하나의 안테나 어레이를 포함할 수 있다. 하드웨어 측면에서, 통신 유닛은 디지털 회 로와 아날로그 회로(예컨대, 무선 주파수 집적 회로(RFIC))로 구성될 수 있다. 본원에서는 디지털 회로와 아날 로그 회로가 하나의 패키지로 구현될 수 있다. 또한, 통신 유닛은 복수의 RF 체인을 포함할 수 있다. 또 한, 통신 유닛은 빔포밍을 수행할 수 있다. 통신 유닛은 전술한 바와 같이 신호를 전송 및 수신한다. 따라서, 통신 유닛의 전체 또는 일부는 ' 송신기', '수신기', 또는 '트랜시버'라고 지칭될 수 있다. 또한, 이하의 설명에서 무선 채널을 통해 수행되는전송 및 수신은 전술한 처리가 통신 유닛에 의해 수행된다는 것을 포함하는 의미로 사용된다. 저장 유닛은 단말의 동작을 위한 기본 프로그램, 애플리케이션 프로그램, 설정 정보 등의 데이터를 저장한 다. 저장 유닛은 휘발성 메모리, 비휘발성 메모리, 또는 휘발성 메모리와 비휘발성 메모리의 조합으로 구 성될 수 있다. 그리고, 저장 유닛은 제어 유닛의 요청에 따라 저장된 데이터를 제공한다. 제어 유닛은 단말의 전반적인 동작을 제어한다. 예를 들어, 제어 유닛은 통신 유닛을 통해 신 호를 전송 및 수신한다. 또한, 제어 유닛은 저장 유닛에 데이터를 기입하고 저장 유닛의 데이 터를 판독한다. 또한, 제어 유닛은 통신 표준에서 요구하는 프로토콜 스택의 기능을 수행할 수 있다. 이 를 위해, 제어 유닛은 적어도 하나의 프로세서 또는 마이크로프로세서를 포함할 수 있거나, 또는 프로세서 의 일부일 수 있다. 또한, 통신 유닛 및 제어 유닛의 일부는 통신 프로세서(CP)로 지칭될 수 있다. 본 개시의 다양한 실시예는 이하의 주제에 관한 것이다: 분할 AI(인공 지능)/ML(머신 러닝) 추론 미디어 서비스를 위한 메커니즘 본 개시의 다양한 실시예의 기술 분야는 다음을 포함한다: 멀티미디어를 위한 5G 네트워크 시스템, 5G를 통한 AI/ML 모델 전송 및 전달을 위한 아키텍처 및 절차, AI 강화 멀티미디어 서비스를 위한 5G를 통한 AI/ML 모델 전송 및 전달. 본 개시의 다양한 실시예의 배경 기술은 다음을 포함한다: 인공 지능(AI)은 2가지 주요 조건에 따라 시스템이 작동할 수 있는 능력을 정의하는 일반적인 개념이다: - 작업이 수행되어야 하는 컨텍스트, 즉 다양한 입력 파라미터의 값 또는 상태를 의미한다. - 서로 다른 파라미터 값을 사용하여 동일한 작업을 달성한 과거 경험과 각 파라미터 값으로 잠재적으로 성공했 던 기록. 머신 러닝(ML)은 종종 애플리케이션이 과거 경험으로부터 학습할 수 있는 능력을 갖추고 있는 AI의 서브세트로 설명된다. 이러한 학습 특징은 일반적으로 서비스에 투입되었을 때 최소 수준의 성능을 보장하기 위해 초기 트 레이닝 단계로부터 시작된다. 최근, AI/ML은 이미지 분류, 음성/얼굴 인식과 같은 레거시 애플리케이션에서부터 비디오 품질 향상과 같은 보 다 최근의 애플리케이션에까지 이르는 미디어 관련 애플리케이션에 도입되어 일반화되었다. 이 분야에 대한 연 구가 성숙해짐에 따라, 더 높은 수준의 계산 처리를 요구하는 더욱 더 복잡한 AI/ML 기반 애플리케이션이 예상 될 수 있으며; 이러한 처리는 AI/ML 모델의 입력 및 출력뿐만 아니라 AI/ML 모델 자체의 데이터 크기와 복잡성 의 증가로 인해 상당한 양의 데이터를 처리하는 것을 포함한다. 이러한 AI/ML 관련 데이터의 양이 증가하고, 처 리 집약적인 모바일 애플리케이션(예를 들어, VR, AR/MR, 게임 등)을 지원해야 할 필요성이 커지면서, 다양한 애플리케이션의 필수적인 지연 시간 요건을 충족하기 위해, 5G 시스템을 통해 서버가 AI/ML 처리의 특정 측면을 처리하는 것이 중요해지고 있다. 본 개시의 다양한 실시예에서 기존 기술의 문제점은 다음을 포함한다: 현재 AI/ML의 구현예는 다른 시장 해결책과 호환되지 않는 애플리케이션을 통해 활성화되는 주요 독점적인 해결 책이다. 5G를 통해 멀티미디어 애플리케이션을 위한 AI/ML을 지원하려면 AI/ML 모델은 다양한 MNO의 애플리케이 션 공급자와 UE 디바이스 간의 호환성을 지원해야 한다. 이뿐만 아니라, AI/ML 미디어 서비스를 위한 AI/ML 모 델 전달은 미디어 컨텍스트, UE 상태, 및 네트워크 상태에 기반한 AI/ML 모델의 선택 및 전달을 지원해야 한다. UE 디바이스의 처리 능력은 AI/ML 미디어 서비스에 대한 제한이기도 한데, 그 이유는 일반적으로 긴 배터리 수 명이 주요 설계적 장애물/제한이기도 한, AR 안경과 같은 가볍고 처리 능력이 낮은 디바이스 상에서 AR과 같은 차세대 미디어 서비스가 소비되기 때문이다. 본 개시의 다양한 실시예에서 문제점(들)에 대한 해결책(들)으로서의 발명의 목적은 다음과 같다: 본 발명은 다음의 AI/ML 미디어 서비스를 지원하기 위해 5G 미디어 스트리밍(5GMS)을 위한 현재 프레임워크 및 아키텍처를 확장한다: - 멀티미디어 서비스를 위한 네트워크에서 UE로의 AI/ML 모델의 전달. - 새롭게 정의된 네트워크 및 UE 엔티티에 의한, 해당 AI/ML 모델의 선택, 설정, 및 관리와, 해당 AI/ML 모델의 전달, 이들은 AI/ML 모델 전달과 관련된 결정을 위한 입력으로서, 5G 네트워크 상태, UE 처리/런타임 상태 및/ 또는 능력, 및 미디어 특성을 고려할 수 있다. - 네트워크 내의 엔티티 또는 UE 내의 엔티티에 의한, 해당 AI/ML 모델의 선택, 설정 및 관리와, 해당 AI/ML 모 델의 전달을 가능하게 하기 위한 필요한 정보를 포함하는 AI 설정 파일. 네트워크에 의해 생성되어 UE로 전송되 는 해당 AI 설정 파일, UE는 또한 네트워크에 대한 요청을 업데이트하고 네트워크에 요청을 다시 전송할 수 있 다. - AI/ML 모델을 제공하기 위한 다양한 전달 방법 파이프라인에 대한 가능성을 포함할 수도 있는 정보, 즉: 전체 다운로드, 스트리밍 방식에서의 부분 다운로드, 토폴로지 정보 다운로드/업데이트, 및 파라미터 정보 다운로드/ 업데이트를 포함하는 AI 설정 파일. - AI 설정 파일은 또한 네트워크와 UE 간 분할 추론에 대한 선택적 지원을 나타내는 정보를 포함할 수 있으며, 이러한 정보는 UE나 네트워크에 의해 선택될 수 있다. 본 개시의 다양한 실시예의 발명의 결과는 다음과 같다: 이하는 본 발명에 의해 가능해진다: - 네트워크 상태, UE 상태, 및 멀티미디어 컨텍스트 기반의 멀티미디어 서비스를 위한 네트워크와 UE 간의 AI/ML 모델 선택, 전달 및 관리. 도 4는 TS 26.501의 전반적인 5G 미디어 스트리밍 아키텍처를 도시한 것으로, 이는 TS 23.501에 정의된 바와 같 은 5GS 내의 지정된 5GMS 기능을 나타낸다. 도 5는 TS 26.501의 5G 미디어 스트리밍 일반 아키텍처를 도시한 것으로, 이러한 아키텍처는 해당 사양 내에 어 떤 미디어 스트리밍 기능 엔티티와 인터페이스가 명시되어 있는지를 식별한다. 도 6은 TS 26.501에 명시된 바와 같은 미디어 하향링크 스트리밍을 위한 상위 레벨 절차를 도시한 것이다. 도 7은 TS 26.501에 의해 정의된 바와 같은 유니캐스트 미디어 하향링크 스트리밍 세션의 수립을 설명하는 기준 절차를 참고로 도시한 것이다. 도 8은 AI/ML 모델이 네트워크에서 UE(종단 디바이스)로 전달되어야 하는 간단한 AI/ML 미디어 서비스 시나리오 를 도시한 것이다. UE 디바이스는 AI 모델을 수신하면 모델 추론을 수행하고 관련 미디어를 AI 모델에 입력으로 제공한다. 전형적인 예: - 존은 여름 휴가 동안 서울에 있으며, 관광을 위해 잠실에 있는 롯데 타워를 방문하려고 한다. 존은 한국어를 읽을 수 없고, 롯데 타워까지 가는 길을 찾는 데 어려움을 겪는다. - 존은 자신의 모바일폰(UE)을 꺼내서 모바일폰 상에서 증강 현실 내비게이션 서비스를 연다. 해당 네트워크 사 업자는 5G를 통해 서비스를 제공하고, 다양한 정보의 분석을 통해, 적합한 AI 모델이 그의 모바일폰에 전달된다. 이러한 정보는 네트워크로부터 이용 가능한 정보, 예를 들어, 존의 UE 위치, 요금 청구 정책, 네트워 크 가용성 및 조건(대역폭, 지연 시간) 등, UE의 처리 능력 및 상태, 그리고 AI 모델의 입력으로 사용될 미디어 속성을 포함한다. - AI 모델이 존의 모바일폰에 전달되면, AR 내비게이션 서비스는 모바일폰 상의 카메라를 작동시켜 존의 주변 환경을 캡처한다. - 모바일폰의 카메라로부터의 캡처된 비디오는 AI 모델에 입력으로 공급되고, AI 모델 추론이 시작된다. - AI 모델의 출력은 존을 롯데 타워로 안내하기 위해 모바일폰의 스크린 라이브 카메라에서 오버레이로 표시되 는 방향 라벨(예를 들어, 내비게이션 화살표)을 제공한다. 한국어로 된 도로 표지판에는 AI 모델로부터 출력된 영어 라벨이 오버레이로 표시된다. 도 9는, AI 모델이 UE에 전달되고, 미디어(예를 들어, 비디오)가 또한 UE로 스트리밍되는 시나리오를 도시한 것 이다. UE에서, 스트리밍된 비디오는 처리를 위해 수신된 AI 모델에 입력으로 공급된다. AI 모델은 임의의 미디어 관련 처리, 예를 들어, 비디오 업스케일링, 비디오 품질 향상, 비전 애플리케이션, 예 를 들어, 객체 인식, 얼굴 인식 등을 수행할 수 있다.필요한 단계에 대한 간단한 설명은 다음과 같다(구체적인 세부 사항은 도 15 및 도 16 참조): * 서비스 안내 * UE 또는 네트워크에 의한 요청/선택(UE가 수행하고자 하는 작업, 미디어 요구 사항, 네트워크 상태 파라미터, UE 상태 파라미터를 고려하는 것, 네트워크 또는 UE가 적합한 AI 모델을 선택하는 것) * 네트워크에서의 모델 제공 및 수집 * 네트워크에서의 미디어 제공 * 세션(들) 수립(들) * 네트워크에서 UE로의 AI 모델 전달 * 미디어 세션 하향링크 설정 * 네트워크로부터의 미디어 스트리밍 * UE에서의 AI 미디어 추론 도 10은 AI 미디어 서비스에 필요한 추론이 네트워크와 UE 사이에서 분할되는 시나리오를 도시한 것이다. UE에 서 추론될 AI 모델의 일부는 네트워크로부터 UE로 전달된다. 네트워크에서 추론될 AI 모델의 다른 일부는 네트 워크에 의해 네트워크에서 추론을 수행하는 엔티티에 프로비저닝된다. 추론을 위한 미디어는 AI 모델의 네트워 크 부분에 입력으로 공급되는 경우, 먼저 네트워크에 의해 프로비저닝되어 네트워크 추론 엔티티로 수집된다. 그 후 네트워크 측 추론의 출력(중간 데이터)이 UE로 전송되고, UE는 이 중간 데이터를 수신하여 AI 모델의 UE 측 부분에 입력으로 제공함으로써 전체 모델의 추론을 완료한다. 이 시나리오에서, 분할 결정 및 설정은 UE와 네트워크 사이에서 협상되며 필요한 단계에 대한 간단한 설명은 다 음과 같다(구체적인 세부 정보는 도 17 및 도 18 참조): * 서비스 안내 * UE에 의한 요청/선택(수행하고자 하는 작업, 미디어 요구 사항을 제공하는 것, AF가 적합한 모델 헤드를 선택 하는 것) * 네트워크에서의 UE 작업 모델 헤드 및 코어 모델 제공 * 네트워크에서의 미디어 제공 * 분할 설정 셋업 및 수립 * 세션(들) 수립(들) * 중간 데이터 세션 하향링크 설정 * 네트워크로부터의 모델 헤드 다운로드/스트리밍 * 네트워크 코어 모델 추론 수행 * 네트워크로부터의 중간 데이터 스트리밍 * UE에서의 작업 모델 추론 하나의 분할 설정 예에서, AI 모델 서비스는 핵심 부분과 작업별 부분(예컨대, 교통 표지판 인식 작업이나 얼굴 인식 작업)으로 구성될 수 있으며, 여기서 AI 모델의 핵심 부분은 다수의 가능한 작업에 공통적이다. 이 경우, 분할 설정은, 네트워크가 모델의 핵심 부분에 대한 추론을 수행하고, UE가 모델의 작업 부분에 대한 추론을 (수 신하여) 수행하는 방식으로 핵심 부분과 작업 부분을 일치시킬 수 있다. 도 11은 본 발명에서 미디어 서비스를 위한 AI 모델 전달을 가능하게 하는 다양한 기능적 엔티티와 인터페이스 를 식별하는 미디어용 AI(AI4Media) 아키텍처를 도시한 것이다. \"M\" 인터페이스는 TS 26.501에 명시된 인터페이"}
{"patent_id": "10-2024-7040208", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "스에 해당하고, \"A\" 인터페이스는 본 발명의 내용에 의해 정의된다. \"AM\" 인터페이스는 5GMS(TS 26.501)의 범위"}
{"patent_id": "10-2024-7040208", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "와 본 발명의 내용의 범위 내에 있는 인터페이스에 해당한다. AI 미디어 AF: TS 23.501 조항 6.2.10에 정의된 것과 유사한, AI 미디어 서비스에 전용되는 애플리케이션 기능 부이다. 일반적으로 UE 상의 AI 미디어 세션 핸들러 및/또는 AI 미디어 애플리케이션 공급자에게 다양한 제어 기능을 제공한다. 이는 (AI/ML 엔드포인트 및/또는 3GPP 코어 네트워크와 상호 작용하여 AI 미디어 AF에 필요한 정보를 수집하는) 데이터 수집 프록시(Data Collection Proxy)(DCP) 기능 엔티티와 같은 다른 5GC 네트워크 기 능부와 상호 작용할 수 있다. DCP는 NWDAF 기능부를 포함할 수도 있고 포함하지 않을 수도 있다. AI AS: 도 13에 도시된 바와 같은 AI 전달 기능부, AI 모델 공급자 기능부 등과 같은 5G AI 미디어 (서브) 기능 부를 호스팅하는, AI 미디어 서비스에 전용되는 애플리케이션 서버이다. AI AS는, 일반적으로 AI 미디어 애플리 케이션 공급자로부터 AI 모델을 수집하고 네트워크 추론을 위해 미디어 AS와 같은 다른 네트워크 기능부에 모델 을 배출함으로써, AI 모델 호스팅을 지원한다. 미디어 AS: 이는 TS 26.501의 미디어 AS에 해당하지만, AI 모델 추론을 수행하는 AI 엔진 기능부를 포함할 수도 있다. AI 미디어 애플리케이션 공급자: 이는 콘텐츠별 미디어 기능부 및/또는 AI별 미디어 기능부(AI 모델 생성, 분할, 업데이트 등)을 갖춘 외부 애플리케이션이다. UE의 AI 미디어 클라이언트에는 세 개의 서브 기능부가 포함되어 있다: AI 미디어 세션 핸들러: 이는 AI 미디어 AF와 통신하여 AI 모델 세션 및/또는 미디어 세션의 전달을 수립, 제어 및 지원하는 UE의 기능부이며, 소비 및 QoE 메트릭 수집 및 보고와 같은 추가 기능을 수행할 수 있다. AI 미디 어 세션 핸들러는 AI 미디어 애플리케이션에 의해 사용될 수 있는 API를 노출할 수 있다. AI 클라이언트: 이는 AI AS와 통신하여 AI 모델 데이터를 다운로드/스트리밍(또는 심지어는 업로드)하는 UE의 기능부이며, UE에서 AI 모델 추론을 위한 AI 미디어 애플리케이션(도 13의 AI 엔진 런타임)에, 그리고 AI 모델 세션 제어를 위한 AI 미디어 세션 핸들러(AI 모델(예컨대, ONNX 파일)을 관리하기 위한 AI 모델 관리자)에, 그 리고 토폴로지 데이터 및/또는 AI 모델 파라미터(가중치, 바이어스)와 같은 AI 모델 데이터에 액세스하기 위한 AI 액세스 기능부에 API를 제공할 수 있다. 미디어 플레이어: 이는 TS 26.501에 명시된 것과 동일한 것에 해당하는 UE의 기능부이다. 미디어 플레이어는 AI 클라이언트에서 AI 모델 추론을 위한 데이터 입력으로서 미디어 콘텐츠를 AI 클라이언트에 배출할 수 있다. 본 발명의 다른 실시예에서, UE의 AI 추론 엔진은 AI 클라이언트 대신 미디어 플레이어에 존재할 수 있다. 이는 또한 UE의 다른 기능부에도 존재할 수 있다. 본 발명의 다른 실시예에서, 네트워크의 AI 엔진은 미디어 AS 대신 AI AS에 존재할 수 있다. 도 12는 도 8의 시나리오에 해당하는 AL 모델 하향링크 전달을 위한 상위 레벨 절차를 도시한 것이다. 단계: 1. AI 미디어 애플리케이션 공급자는 AI 미디어 AF와 함께 프로비저닝 세션을 생성하고, AI4Media 시스템 사용 에 대한 프로비저닝을 시작한다. 수립 단계 동안, 사용된 특징들은 협상되고 세부적인 설정들이 교환된다. AI 미디어 AF는 A5(AI 모델 세션 처리)에 대한 서비스 액세스 정보를 수신하고, AI 모델 데이터 호스팅이 협상되는 경우, A2(수집) 및 A4(AI 모델 데이터 전달)에 대한 서비스 액세스 정보도 수신한다. 이 정보는 AI 미디어 클라 이언트가 서비스에 액세스하는 데 필요하다. 프로비저닝에 따라, 서비스 액세스 정보에 대한 참조만 제공될 수 도 있다. 2. AI 모델 데이터 호스팅이 제공되고 선택되는 경우, AI 미디어 AF와 AI AS 간에는, 예컨대, AI 모델 데이터 수집 및 배포 리소스를 할당하기 위한 상호작용이 있을 수 있다. AI AS는 할당된 리소스에 대한 리소스 식별자 를 AI 미디어 AF에 제공하고, AI 미디어 AF는 해당 정보를 AI 미디어 애플리케이션 공급자에게 제공한다. 3. AI 미디어 애플리케이션 공급자는 AI 모델 데이터를 수집함으로써 수집 세션을 시작한다. 동적 AI 모델 AI 미디어 서비스의 경우, AI 모델 데이터는 지속적으로 수집될 수 있거나 한 번 업로드된 후 추후 업데이트될 수 있다. 4. AI 미디어 애플리케이션 공급자는 AI 미디어 애플리케이션에 서비스 안내 정보를 제공한다. 서비스 안내는 전체 서비스 액세스 정보(즉, AI 모델 세션 처리(A5) 및 AI 모델 데이터 전달 액세스(A4)에 대한 세부 정보, 예 컨대, AI 설정 파일을 포함함) 또는 서비스 액세스 정보나 사전 설정된 정보에 대한 참조를 포함한다. 참조만 포함된 경우, AI 미디어 클라이언트는 필요 시 (단계 6에서) 서비스 액세스 정보(예컨대, AI 설정 파일을 포함함)를 페칭한다. 5. AI 미디어 애플리케이션이 AI 모델 데이터 수신을 시작할 것을 결정하는 경우, 서비스 액세스 정보(전체 또 는 참조)가 AI 미디어 클라이언트에 제공된다. AI 미디어 클라이언트는 유니캐스트 하향링크 전달 세션을 활성 화한다. 6. 선택 사항) AI 미디어 클라이언트가 서비스 액세스 정보에 대한 참조만을 수신한 경우, AI 미디어 AF로부터 서비스 액세스 정보를 획득한다. 7. AI 미디어 클라이언트는 A5에서 AI 미디어 AF에 의해 공개된 AI 모델 데이터 세션 처리 API를 사용한다. AI 모델 데이터 세션 처리 API는 소비 측정, 로깅, 수집 및 보고를 설정하는 데 사용되거나; QoE 메트릭 측정, 로 깅, 수집 및 보고를 설정하는 데 사용되거나; 다양한 정책 및 요금 청구 처리를 요청하는 데 사용되거나; 또는 AI 미디어 AF 기반 네트워크 지원에 사용된다. API 사용의 실제 시간은 미디어 콘텐츠 수신 동안 사용될 수 있 는 특징과 상호작용에 따라 달라진다. 8. AI 미디어 클라이언트는 AI 모델 데이터 수신을 활성화한다. 본 발명의 모든 실시예에 대해, 서비스 안내에는 다음 중 하나가 포함된다: 1) 전체 서비스 액세스 정보(즉, AI 모델 세션 처리(A5) 및/또는 미디어 세션 처리(M5)에 대한 세부 정보, 및 AI 모델 데이터 전달 액세스(A4) 및/또는 미디어 콘텐츠 데이터 액세스(M5)에 대한 세부 정보, AI 설정 파일을 포함함), 또는 2) 서비스 액세스 정보나 사전 설정된 정보에 대한 참조. 이 정보는 AI 미디어 클라이언트가 서비스에 액세스하는 데 필요하다. 도 13은 도 8의 시나리오에 대한 기본적인 작업 흐름 절차를 도시한 것이다. 단계: 1. 애플리케이션은 애플리케이션 공급자에게 연락하여 AI 미디어 서비스에 대한 진입점을 페칭한다. 진입점의 획득은 다양한 방식으로 수행될 수 있다. 진입점은 예를 들어 AI 설정 파일에 대한 URL이 될 수 있다. 2. 세션 셋업: 2a. 진입점이 AI 설정 파일의 URL인 경우, 애플리케이션은 획득한 진입점을 사용하여 AI 모델 관리자를 초기화 한다. 2b. AI 모델 관리자는 진입점 정보에 기반하여 AI 모델 공급자로부터 AI 설정 파일을 검색한다. AI 설정 파일은 다음을 포함한다: * AI 미디어 서비스에 대한 전반적인 설명 * (식별자를 통해 표시된) AI 미디어 서비스에 대한 선택에 이용 가능한 AI 모델의 리스트. * 해당 리스트 내의 각 AI 모델에 대해: - 실제 AI 모델 데이터의 위치를 가리키는 식별자/식별자들(예컨대, URL(들)) - 모델 신경망 유형(CNN, DNN 등), 토폴로지 정보, 계층 수, 모델이 전체 또는 부분 계층 데이터를 포함하고 있 는지 여부, 필터 수, 커널, 바이어스, 양자화된 가중치, 텐서 등과 같은 AI 모델에 대한 다양한 파라미터를 설 명하는 메타데이터를 포함한 AI 모델에 대한 전반적인 설명. - AI 설정 파일은 또한 이용 가능한 AI 모델의 전달과 관련된 정보를 포함할 수 있다. 특히, AI 모델 데이터가 전체 파일(또는 유사한 파일)로서 다운로드될 수 있는지 여부, AI 모델이 부분 모델로서 전달될 수 있는지 여부 (그리고 이들이 독립적으로 추론될 수 있는지 여부), AI 모델 데이터가 다양한 데이터 유형(예를 들어, 개별 토 폴로지 데이터, 개별 파라미터 데이터(가중치, 바이어스 등) 등)에 따라 전달될 수 있는지 여부. - AI 설정 파일은 또한 AI 미디어 서비스에 대해 가능한 추론 설정, 예를 들어, 선택된 AI 모델에 따라 달라질 수 있는 가능한 네트워크-UE 분할 추론 설정에 대한 정보를 포함할 수 있다. 본 발명의 일 실시예에서, AI 미디어 AF는 UE로부터 UE의 능력, 상태 및 요구 사항(예를 들어, 처리 능력, AI 모델 처리를 위한 미디어 요구 사항, 모델 추론 버퍼 용량 등)에 관한 정보를 수신할 수 있다. AI 미디어 AF는 또한 5GS로부터 UE/네트워크 상태에 관한 정보(예를 들어, 네트워크 상태(예컨대, 혼잡도, 대역폭, 지연 시간), UE 위치, UE 요금 청구 정책 등) 및 다른 관련 정보도 수신할 수 있다. 그 후 AI 미디어 AF는 (UE 및 5GS로부터 의) 이들 정보를 사용하여 AI 미디어 서비스를 위한 하나의 AI 모델을 선택하고, 관련 AI 모델 설정 정보(예컨 대, 모델 위치 URL, 모델 전반적 설명 등)를 UE에 제공한다. 다른 실시예에서, AI 미디어 AF는 이들 정보를 사용하여 AI 미디어 애플리케이션 공급자로부터 프로비저닝된 모 델 중에서 적합한 AI 모델 세트를 사전 선택한다. 그 후 AI 미디어 AF는 선택된 AI 모델과 관련된 설정 정보(예 컨대, AI 모델 데이터 위치 URL, AI 모델 전반적 설명 속성, 예를 들어, 모델 유형, 계층 수 등)를 포함하도록 AI 설정 파일을 업데이트하고, 업데이트된 AI 설정 파일을 UE로 전송한다. 이러한 업데이트된 설정 파일을 사용 하여, UE의 AI 모델 관리자는 서비스를 위해 적합한 하나의 AI 모델을 선택한다. 다른 실시예에서, AI 미디어 AF는 AI 모델을 사전 선택하지 않고, 대신 (5GS로부터 획득되는) 관련 네트워크 상 태/조건 정보를 UE로 전송한다. 그 후 UE는 AI 설정 파일과 네트워크 정보를 모두 수신하면, (UE로부터 내부적 으로 이용 가능한 것을 포함한) 이용 가능한 모든 정보를 사용하여 서비스를 위해 적합한 AI 모델을 결정하고 선택한다. 2c. AI 모델 관리자는 AI 설정 파일을 파싱하고 AI 설정 파일을 처리한다. AI 모델 관리자는 또한 AI 설정 파일 중에서 AI 미디어 서비스를 위해 적합한 AI 모델을 선택할 수 있다. 이는 또한 이러한 단계 동안 선택된 AI 모 델에 필요한 AI 모델 데이터 전달 파이프라인을 결정할 수 있다. 2d. AI 모델 관리자는 AI 엔진 런타임에서 AI 런타임 세션 생성을 요청한다. 2e. AI 엔진 런타임은 추론을 위한 AI 모델을 수집하도록 준비된 AI 런타임 세션을 초기화한다. 2f. AI 엔진 런타임은 AI 모델 관리자에게 준비 상태를 통지한다. 3. AI 모델 관리자는 AI 설정 파일 중에서 AI 미디어 서비스를 위해 적합한 AI 모델을 선택할 수 있다(이는 단 계 2c 동안 이 작업을 수행하지 않은 경우에 그러하다). AI 모델 관리자는 또한 이 단계 동안 AI 설정 파일의 정보를 사용하여 선택된 AI 모델에 필요한 AI 모델 데이터 전달 파이프라인(메타데이터를 포함함)을 결정한다 (이는 단계 2c 동안 이 작업을 수행하지 않은 경우에 그러하다). 4. AI 모델 전달 파이프라인: 이는 단계 3에서 결정된 바와 같이, AI 모델 데이터를 전달하기 위한 가능한 파이 프라인이다. 세부 사항은 도 14a와 도 14b에 제공되고 있다. 이들 AI 모델 전달 파이프라인은 일단 수립되면 A4 를 통해 AI AS에서 UE로 AI 모델 데이터를 전달할 수 있다. 5. UE는 AI 미디어 서비스를 위해 관련 미디어를 입력으로 사용하여 AI 모델을 추론한다. 6. UE는 AI 미디어 서비스 상태(예컨대, AI 추론 상태, 지연 시간, 리소스 상태, 능력 상태, 동적 미디어 속성 등)에 관한 상태 보고를 AI 미디어 AF로 전송할 수 있다. 이 단계는 3단계 또는 심지어는 단계 2c 전에(즉, AI 모델과 그 전달 파이프라인을 선택하기 전에) 발생할 수 있으므로, 이 정보는 공유되어 단계 3 및 단계 2c의 의 사 결정 프로세스에 사용될 수 있다. 7. AI 미디어 AF는 네트워크 관련 상태/조건 보고를 UE에 전송할 수 있다. 이 단계는 3단계 또는 심지어는 단계 2c 전에(즉, AI 모델과 그 전달 파이프라인을 선택하기 전에) 발생할 수 있으므로, 이 정보는 공유되어 단계 3 및 단계 2c의 의사 결정 프로세스에 사용될 수 있다. 단계 6 및 단계 7은 두 엔드포인트 간의 UE 및 네트워크 상태 정보의 공유를 활성화할 수 있다. 이러한 정보는 AI 설정 파일 중에서 AI 모델을 선택하는 것과 관련된 결정을 내리고, 필요한 여러 개의 전달 파이프라인을 선 택하는 것과 관련된 결정을 내리고, (필요한 경우) 필요한 임의의 분할 추론 설정과 관련된 결정을 내리고, 그 리고 AI 미디어 서비스 동안, AI 설정 파일 자체를 업데이트하는 것과 관련된 결정을 내리거나 또는 위에 나열 된 것과 같은 임의의 결정을 내리기 위해, UE 또는 네트워크에 의해 사용될 수 있다. 8. 단계 6 및/또는 단계 7로부터의 내부 기능, 조건, 및 정보에 따라, UE는 AI 미디어 서비스를 위한 AI 모델을 재선택할 수 있고/있거나 또한 AI 모델 데이터 전달을 위한 전달 파이프라인을 재선택/재결정/업데이트할 수 있 다. 도 14a 및 도 14b는 도 13의 단계 4로부터의 다양한 AI 모델 전달 파이프라인을 도시한 것이다. UE 또는 네트워크는 네트워크에서 UE로 AI 모델 데이터를 전달하기 위해 다양한 파이프라인을 셋업하고 사용하 기로 결정할 수 있다. 전체 AI 모델 다운로드: 전체 AI 모델은 다운로드 방식(예컨대, 파일의 다운로드)으로 UE에 전달될 수 있으며, 여기서 UE에 대한 추론은 전체 AI 모델에 대한 모든 데이터가 수신된 후에만 수행된다. 부분 AI 모델 루프: AI 모델은 부분 다운로드 방식으로 전달될 수 있다. 부분적인 방식의 전달의 경우, AI 모델은 네트워크에서 여 러 개의 부분 모델로 분할된다. 이러한 부분 모델은 구현예에 따라 독립적으로 추론 가능한 것일 수 있거나 그 렇지 않을 수도 있다. 부분 모델은 스트림 방식으로 UE에 전달될 수 있으며, 여기서 각 부분 모델은 연속적으로 전달된다. 독립적으로 추론 가능한 부분 모델의 경우, UE에 대한 추론은 전체 AI 모델 데이터가 수신되기 전에 발생할 수 있다(예컨대, 제1 부분 모델에 대한 UE 추론은 제2 부분 모델의 데이터를 수신하기 전, 제1 부분 모 델 데이터를 수신한 후에 발생할 수 있다). AI 토폴로지 루프: AI 모델의 AI 토폴로지 데이터는 AI 모델과 연관된 나머지 데이터와는 별도로 전달될 수 있다. AI 파라미터 루프: AI 파라미터(예컨대, 가중치, 바이어스 등과 같은 노드 파라미터)에 대한 데이터는 AI 모델과 연관된 다른 데이 터와는 별도로(즉, 토폴로지 데이터와는 별도로) 전달될 수 있다. 가능한 전달 파이프라인 중 하나 이상을 선택하여 AI 모델 데이터 전달을 위해 셋업할 수 있으며, 각 파이프라 인의 루프 빈도는 AI 설정 파일의 데이터에 의해 명시된 AI 모델 특성 및 속성에 따라 다를 수 있다(예컨대, 파 라미터 파이프라인은 AI 미디어 서비스 기간 동안 필요한 파라미터 업데이트에 해당하는 빈도로 루프될 수 있다). 도 15는 AL 모델 하향링크 전달 및 미디어 콘텐츠 스트리밍 전달을 위한 상위 레벨 절차를 도시한 것으로, 이는 도 9의 시나리오에 해당하며, 여기서 AI 미디어 서비스는 UE로의 AI 모델 전달과 미디어 스트리밍 전달을 모두 포함한다. 단계: 1. AI 미디어 애플리케이션 공급자는 AI 미디어 AF와 함께 프로비저닝 세션을 생성하고, AI4Media 시스템(뿐만 아니라 미디어 스트리밍을 위한 5GMS 시스템)의 사용에 대한 프로비저닝을 시작한다. 수립 단계 동안, 사용된 특징들은 협상되고 세부적인 설정들이 교환된다. AI 미디어 AF는 A5 및 M5(AI 모델 세션 처리 및 미디어 세션 처리)에 대한 서비스 액세스 정보를 수신하고, AI 모델 데이터 및 미디어 콘텐츠 호스팅이 협상되는 경우, A2/M2(수집) 및 A4/M4(AI 모델 데이터 전달 및 미디어 콘텐츠 전달)에 대한 서비스 액세스 정보도 수신한다. 이 정보는 AI 미디어 클라이언트가 서비스에 액세스하는 데 필요하다. 프로비저닝에 따라, 서비스 액세스 정보에 대한 참조만 제공될 수도 있다. 2. AI 모델 데이터 호스팅이 제공되고 선택되는 경우, AI 미디어 AF와 AI AS/미디어 AS 간에는, 예컨대, AI 모 델 데이터 및 미디어 콘텐츠 수집 및 배포 리소스를 할당하기 위한 상호작용이 있을 수 있다. AI AS 및 미디어 AS는 할당된 리소스에 대한 리소스 식별자를 AI 미디어 AF에 제공하고, AI 미디어 AF는 해당 정보를 AI 미디어 애플리케이션 공급자에게 제공한다. 3. AI 미디어 애플리케이션 공급자는 AI 모델 데이터를 수집함으로써 AI 모델 수집 세션을 시작한다. 동적 AI 모델 AI 미디어 서비스의 경우, AI 모델 데이터는 지속적으로 수집될 수 있거나 한 번 업로드된 후 추후 업데이 트될 수 있다. 4. AI 미디어 애플리케이션 공급자는 미디어 콘텐츠를 수집함으로써 미디어 수집 세션을 시작한다. 라이브 미디 어 서비스(live media services)의 경우, 미디어 콘텐츠는 지속적으로 수집될 수 있거나 한 번 업로드된 후 추 후 업데이트될 수 있다. 5. AI 미디어 애플리케이션 공급자는 AI 미디어 애플리케이션에 서비스 안내 정보를 제공한다. 서비스 안내는 전체 서비스 액세스 정보(즉, AI 모델 세션 처리(A5) 및 미디어 세션 처리(M5)에 대한 세부 사항 및 AI 모델 데이터 전달 액세스(A4) 및 미디어 콘텐츠 전달 액세스(M4)에 대한 세부 정보, 예컨대, AI 설정 파일을 포함함) 또는 서비스 액세스 정보나 사전 설정된 정보에 대한 참조를 포함한다. 참조만 포함된 경우, AI 미디어 클라이 언트는 필요 시 (단계 6에서) 서비스 액세스 정보(예컨대, AI 설정 파일을 포함함)를 페칭한다. 6. AI 미디어 애플리케이션이 AI 모델 데이터 및 미디어 콘텐츠 데이터 수신을 시작할 것을 결정하는 경우, 서 비스 액세스 정보(전체 또는 참조)가 AI 미디어 클라이언트에 제공된다. AI 미디어 클라이언트는 유니캐스트 하 향링크 전달 세션을 활성화한다. 7. 선택 사항) AI 미디어 클라이언트가 서비스 액세스 정보에 대한 참조만을 수신한 경우, AI 미디어 AF로부터 서비스 액세스 정보를 획득한다. 8. AI 미디어 클라이언트는 A5에서 AI 미디어 AF에 의해 공개된 AI 모델 데이터 세션 처리 API를 사용한다. AI 모델 데이터 세션 처리 API는 소비 측정, 로깅, 수집 및 보고를 설정하는 데 사용되거나; QoE 메트릭 측정, 로 깅, 수집 및 보고를 설정하는 데 사용되거나; 다양한 정책 및 요금 청구 처리를 요청하는 데 사용되거나; 또는 AI 미디어 AF 기반 네트워크 지원에 사용된다. API 사용의 실제 시간은 미디어 콘텐츠 수신 동안 사용될 수 있 는 특징과 상호작용에 따라 달라진다. 9. AI 미디어 클라이언트는 AI 모델 데이터 수신을 활성화한다. 10. AI 미디어 클라이언트는 M5에서 AI 미디어 AF에 의해 공개된 미디어 세션 처리 API를 사용한다. 미디어 세 션 처리 API는 소비 측정, 로깅, 수집 및 보고를 설정하는 데 사용되거나; QoE 메트릭 측정, 로깅, 수집 및 보 고를 설정하는 데 사용되거나; 다양한 정책 및 요금 청구 처리를 요청하는 데 사용되거나; 또는 AI 미디어 AF 기반 네트워크 지원에 사용된다. API 사용의 실제 시간은 미디어 콘텐츠 수신 동안 사용될 수 있는 특징과 상호 작용에 따라 달라진다. 11. AI 미디어 클라이언트는 콘텐츠 데이터 수신을 활성화한다. 12. 미디어 플레이어는 수신된 스트리밍된 미디어 콘텐츠를 AI 클라이언트에 전달한다. 13. AI 클라이언트는 스트리밍된 미디어 콘텐츠를 모델에 대한 입력으로 사용하여 수신된 AI 모델에 대한 AI 추 론을 수행한다. 도 16은 도 9의 시나리오에 대한 기본적인 작업 흐름 절차를 도시한 것으로, 이는 도 13에 설명된 기본적인 작 업 흐름 절차를 확장한 것이다. 도 16의 단계 1 내지 단계 3은 도 13의 단계 1 내지 단계 3에 해당하고, 도 16의 단계 7 내지 단계 9는 도 13의 단계 5 내지 단계 7에 해당한다. 도 16의 단계 11은 도 13의 단계 8에 해당한다. AI 설정 파일은 다음을 포함한다: * AI 미디어 서비스에 대한 전반적인 설명 * (식별자를 통해 표시된) AI 미디어 서비스에 대한 선택에 이용 가능한 AI 모델의 리스트. * 해당 리스트 내의 각 AI 모델에 대해: - 실제 AI 모델 데이터의 위치를 가리키는 식별자/식별자들(예컨대, URL(들)) - 모델 신경망 유형(CNN, DNN 등), 토폴로지 정보, 계층 수, 모델이 전체 또는 부분 계층 데이터를 포함하고 있 는지 여부, 필터 수, 커널, 바이어스, 양자화된 가중치, 텐서 등과 같은 AI 모델에 대한 다양한 파라미터를 설 명하는 메타데이터를 포함한 AI 모델에 대한 전반적인 설명. - AI 설정 파일은 또한 이용 가능한 AI 모델의 전달과 관련된 정보를 포함할 수 있다. 특히, AI 모델 데이터가 전체 파일(또는 유사한 파일)로서 다운로드될 수 있는지 여부, AI 모델이 부분 모델로서 전달될 수 있는지 여부 (그리고 이들이 독립적으로 추론될 수 있는지 여부), AI 모델 데이터가 다양한 데이터 유형(예를 들어, 개별 토 폴로지 데이터, 개별 파라미터 데이터(가중치, 바이어스 등) 등)에 따라 전달될 수 있는지 여부. - AI 설정 파일은 또한 AI 미디어 서비스에 대해 가능한 추론 설정, 예를 들어, 선택된 AI 모델에 따라 달라질 수 있는 가능한 네트워크-UE 분할 추론 설정에 대한 정보를 포함할 수 있다. 본 발명의 일 실시예에서, AI 미디어 AF는 UE로부터 UE의 능력, 상태 및 요구 사항(예를 들어, 처리 능력, AI 모델 처리를 위한 미디어 요구 사항, 모델 추론 버퍼 용량 등)에 관한 정보를 수신할 수 있다. AI 미디어 AF는또한 5GS로부터 UE/네트워크 상태에 관한 정보(예를 들어, 네트워크 상태(예컨대, 혼잡도, 대역폭, 지연 시간), UE 위치, UE 요금 청구 정책 등) 및 다른 관련 정보도 수신할 수 있다. 그 후 AI 미디어 AF는 (UE 및 5GS로부터 의) 이들 정보를 사용하여 AI 미디어 서비스를 위한 하나의 AI 모델을 선택하고, 관련 AI 모델 설정 정보(예컨 대, 모델 위치 URL, 모델 전반적 설명 등)를 UE에 제공한다. 다른 실시예에서, AI 미디어 AF는 이들 정보를 사용하여 AI 미디어 애플리케이션 공급자로부터 프로비저닝된 모 델 중에서 적합한 AI 모델 세트를 사전 선택한다. 그 후 AI 미디어 AF는 선택된 AI 모델과 관련된 설정 정보(예 컨대, AI 모델 데이터 위치 URL, AI 모델 전반적 설명 속성, 예를 들어, 모델 유형, 계층 수 등)를 포함하도록 AI 설정 파일을 업데이트하고, 업데이트된 AI 설정 파일을 UE로 전송한다. 이러한 업데이트된 설정 파일을 사용 하여, UE의 AI 모델 관리자는 서비스를 위해 적합한 하나의 AI 모델을 선택한다. 다른 실시예에서, AI 미디어 AF는 AI 모델을 사전 선택하지 않고, 대신 (5GS로부터 획득되는) 관련 네트워크 상 태/조건 정보를 UE로 전송한다. 그 후 UE는 AI 설정 파일과 네트워크 정보를 모두 수신하면, (UE로부터 내부적 으로 이용 가능한 것을 포함한) 이용 가능한 모든 정보를 사용하여 서비스를 위해 적합한 AI 모델을 결정하고 선택한다. 도 13에 설명된 모든 다양한 실시예는 또한 도 16의 세부 사항에도 적용 가능한다. 도 16은 AI 모델 전달 파이프라인을 통해 AI 모델 데이터를 전달하는 것 외에도, 5GMS(TS 26.501)에 정의된 미 디어 전달 파이프라인을 사용하여, 가장 기본적인 레벨에서 네트워크로부터 UE로 미디어 전달 파이프라인을 통 해 미디어 콘텐츠 데이터를 전달하는 것을 포함한다. 단계 3에서, AI 클라이언트는 또한 AI 미디어 세션에 필요한 미디어 전달 파이프라인을 결정할 수도 있다. 단계: 4. 도 14a 및 도 14b가 참조된다. 5. 미디어 전달 파이프라인: 이는 미디어 AS로부터 AI 미디어 클라이언트로 미디어 콘텐츠 데이터를 전달하기 위한 가능한 파이프라인이다. 전달은 미디어 스트리밍 전달이나 다운로드 전달의 형태를 통해 또는 AI 미디어 서비스에 필요한 다른 형태의 전달 메커니즘을 통해 이루어질 수 있다. 이러한 전형적인 서비스 중 하나는 5GMS(TS 26.501)에 의해 정의된다. 6. 미디어 플레이어는, 미디어 데이터를 수신하면, 해당 미디어 데이터를 AI 클라이언트로 전송하여 AI 추론을 위한 입력으로 사용한다. AI 모델 입력으로 사용되기 전에 필요한 모든 미디어 처리가 또한 이 단계에서 미디어 플레이어나 임의의 다른 관련 엔티티(예컨대, 미디어 디코딩, 다운스케일링/업스케일링 등)에서 수행된다. 10. AI 클라이언트는 네트워크로부터 (AI 미디어 세션 핸들러를 통해) 또는 미디어 플레이어로부터 내부적으로 미디어 상태 보고를 수신하여, AI 모델 선택 결정을 업데이트하고/하거나 또한 AI 모델 데이터와 미디어 콘텐츠 데이터를 위해 사용되는 모델 전달 파이프라인에 대한 결정을 업데이트하는 데 사용할 수 있다. 도 17은 분할 추론 AI 미디어 서비스를 위한 상위 레벨 절차를 도시한 것으로, 이는 도 10의 시나리오에 해당하 는 것이며, 여기서 AI 미디어 서비스는 네트워크 및 UE 모두에서의 AI 모델 추론을 포함한다(여기서 UE는 IE AI 모델을 수신하고, 또한 네트워크로부터의 인터미디어 데이터도 수신한다). 단계: 1. AI 미디어 애플리케이션 공급자는 AI 미디어 AF와 함께 프로비저닝 세션을 생성하고, AI4Media 시스템(뿐만 아니라 미디어 스트리밍을 위한 5GMS 시스템)의 사용에 대한 프로비저닝을 시작한다. 수립 단계 동안, 사용된 특징들은 협상되고 세부적인 설정들이 교환된다. AI 미디어 AF는 A5 및 M5(AI 모델 세션 처리 및 미디어 세션 처리)에 대한 서비스 액세스 정보를 수신하고, AI 모델 데이터 및 미디어 콘텐츠 호스팅이 협상되는 경우, A2/M2(수집) 및 A4/M4(AI 모델 데이터 전달 및 미디어 콘텐츠 전달)에 대한 서비스 액세스 정보도 수신한다. 이 정보는 AI 미디어 클라이언트가 서비스에 액세스하는 데 필요하다. 프로비저닝에 따라, 서비스 액세스 정보에 대한 참조만 제공될 수도 있다. 2. AI 모델 데이터 호스팅이 제공되고 선택되는 경우, AI 미디어 AF와 AI AS/미디어 AS 간에는, 예컨대, AI 모 델 데이터 및 미디어 콘텐츠 수집 및 배포 리소스를 할당하기 위한 상호작용이 있을 수 있다. AI AS 및 미디어 AS는 할당된 리소스에 대한 리소스 식별자를 AI 미디어 AF에 제공하고, AI 미디어 AF는 해당 정보를 AI 미디어 애플리케이션 공급자에게 제공한다.3. AI 미디어 애플리케이션 공급자는 AI 모델 데이터를 수집함으로써 AI 모델 수집 세션을 시작한다. 동적 AI 모델 AI 미디어 서비스의 경우, AI 모델 데이터는 지속적으로 수집될 수 있거나 한 번 업로드된 후 추후 업데이 트될 수 있다. 네트워크와 UE 간의 분할 추론의 경우, AI 미디어 서비스에 필요한 UE AI 모델(들)과 네트워크 AI 모델(들)이 모두 수집된다. 4. AI 미디어 애플리케이션 공급자는 미디어 콘텐츠를 수집함으로써 미디어 수집 세션을 시작한다. 라이브 미디 어 서비스의 경우, 미디어 콘텐츠는 지속적으로 수집될 수 있거나 한 번 업로드된 후 추후 업데이트될 수 있다. 5. AI 미디어 애플리케이션 공급자는 AI 미디어 애플리케이션에 서비스 안내 정보를 제공한다. 서비스 안내는 전체 서비스 액세스 정보(즉, AI 모델 세션 처리(A5) 및 미디어 세션 처리(M5)에 대한 세부 사항 및 AI 모델 데 이터 전달 액세스(A4) 및 미디어 콘텐츠 전달 액세스(M4)에 대한 세부 정보, 예컨대, AI 설정 파일을 포함함) 또는 서비스 액세스 정보나 사전 설정된 정보에 대한 참조를 포함한다. 참조만 포함된 경우, AI 미디어 클라이 언트는 필요 시 (단계 6에서) 서비스 액세스 정보(예컨대, AI 설정 파일을 포함함)를 페칭한다. 6. AI 미디어 애플리케이션이 AI 모델 데이터 및 미디어 콘텐츠 데이터 수신을 시작할 것을 결정하는 경우, 서 비스 액세스 정보(전체 또는 참조)가 AI 미디어 클라이언트에 제공된다. AI 미디어 클라이언트는 유니캐스트 하 향링크 전달 세션을 활성화한다. 7. 선택 사항) AI 미디어 클라이언트가 서비스 액세스 정보에 대한 참조만을 수신한 경우, AI 미디어 AF로부터 서비스 액세스 정보를 획득한다. 8. AI 미디어 클라이언트는 A5에서 AI 미디어 AF에 의해 공개된 AI 모델 데이터 세션 처리 API를 사용한다. AI 모델 데이터 세션 처리 API는 소비 측정, 로깅, 수집 및 보고를 설정하는 데 사용되거나; QoE 메트릭 측정, 로 깅, 수집 및 보고를 설정하는 데 사용되거나; 다양한 정책 및 요금 청구 처리를 요청하는 데 사용되거나; 또는 AI 미디어 AF 기반 네트워크 지원에 사용된다. API 사용의 실제 시간은 미디어 콘텐츠 수신 동안 사용될 수 있 는 특징과 상호작용에 따라 달라진다. 9. AI 미디어 클라이언트는 UE AI 모델 데이터 수신을 활성화한다. 10. AI 미디어 클라이언트는 M5에서 AI 미디어 AF에 의해 공개된 미디어 세션 처리 API를 사용하여 네트워크로 부터 UE로 인터미디어 데이터를 전송한다. 미디어 세션 처리 API는 소비 측정, 로깅, 수집 및 보고를 설정하는 데 사용되거나; QoE 메트릭 측정, 로깅, 수집 및 보고를 설정하는 데 사용되거나; 다양한 정책 및 요금 청구 처 리를 요청하는 데 사용되거나; 또는 AI 미디어 AF 기반 네트워크 지원에 사용된다. API 사용의 실제 시간은 미 디어 콘텐츠 수신 동안 사용될 수 있는 특징과 상호작용에 따라 달라진다. 11. 미디어 AS는 수집된 미디어 데이터를 네트워크의 AI 엔진에 전달하여 네트워크 AI 추론을 위한 입력으로 사 용할 수 있도록 준비한다. 네트워크 AI 모델이 (예컨대, 수집 동안) 이전에 AI 엔진에 전달되지 않은 경우, AI AS 또는 미디어 AS는 이 단계에서 네트워크 AI 모델을 네트워크 AI 엔진에 전달할 수도 있다. 12. 네트워크 AI 엔진은, 미디어 데이터를 수신하면, 단계 11의 미디어 데이터를 입력으로 사용하여 네트워크 AI 추론을 수행한다. 13. 단계 12의 네트워크 AI 모델 추론의 출력 데이터(중간 데이터)는 UE로 전달할 준비가 된 미디어 AS로 전송 된다. 14. AI 미디어 클라이언트 및/또는 미디어 AS는 AI 미디어 서비스의 특성에 따라 미디어 데이터가 될 수도 있는 중간 데이터의 전달을 활성화한다. 15. 미디어 플레이어는 중간 데이터/미디어 데이터를 AI 클라이언트에 전달한다. 16. UE AI 클라이언트는 단계 14로부터의 수신된 중간 데이터를 모델의 입력으로 사용하여 (단계 9에서 수신된) 수신된 UE AI 모델에 대한 UE 측 디바이스 AI 추론을 수행한다. 도 18은 도 9의 시나리오에 대한 기본적인 작업 흐름 절차를 도시한 것으로, 이는 도 16에 설명된 기본적인 작 업 흐름 절차를 확장한 것이다. 도 18의 단계 1 내지 단계 3은 도 16의 단계 1 내지 단계 3에 해당하고, 단계 5는 단계 4에, 단계 10은 단계 5 에, 단계 11은 단계 6에, 단계 12는 단계 6에 해당하는 식이다. AI 설정 파일은 다음을 포함한다: * AI 미디어 서비스에 대한 전반적인 설명 * (식별자를 통해 표시된) AI 미디어 서비스에 대한 선택에 이용 가능한 AI 모델의 리스트. * 해당 리스트 내의 각 AI 모델에 대해: - 실제 AI 모델 데이터의 위치를 가리키는 식별자/식별자들(예컨대, URL(들)) - 모델 신경망 유형(CNN, DNN 등), 토폴로지 정보, 계층 수, 모델이 전체 또는 부분 계층 데이터를 포함하고 있 는지 여부, 필터 수, 커널, 바이어스, 양자화된 가중치, 텐서 등과 같은 AI 모델에 대한 다양한 파라미터를 설 명하는 메타데이터를 포함한 AI 모델에 대한 전반적인 설명. - AI 설정 파일은 또한 이용 가능한 AI 모델의 전달과 관련된 정보를 포함할 수 있다. 특히, AI 모델 데이터가 전체 파일(또는 유사한 파일)로서 다운로드될 수 있는지 여부, AI 모델이 부분 모델로서 전달될 수 있는지 여부 (그리고 이들이 독립적으로 추론될 수 있는지 여부), AI 모델 데이터가 다양한 데이터 유형(예를 들어, 개별 토 폴로지 데이터, 개별 파라미터 데이터(가중치, 바이어스 등) 등)에 따라 전달될 수 있는지 여부. - AI 설정 파일은 또한 AI 미디어 서비스에 대해 가능한 추론 설정, 예를 들어, 선택된 AI 모델에 따라 달라질 수 있는 가능한 네트워크-UE 분할 추론 설정에 대한 정보를 포함할 수 있다. 본 발명의 일 실시예에서, AI 미디어 AF는 UE로부터 UE의 능력, 상태 및 요구 사항(예를 들어, 처리 능력, AI 모델 처리를 위한 미디어 요구 사항, 모델 추론 버퍼 용량 등)에 관한 정보를 수신할 수 있다. AI 미디어 AF는 또한 5GS로부터 UE/네트워크 상태에 관한 정보(예를 들어, 네트워크 상태(예컨대, 혼잡도, 대역폭, 지연 시간), UE 위치, UE 요금 청구 정책 등) 및 다른 관련 정보도 수신할 수 있다. 그 후 AI 미디어 AF는 (UE 및 5GS로부터 의) 이들 정보를 사용하여 AI 미디어 서비스를 위한 하나의 AI 모델을 선택하고, 관련 AI 모델 설정 정보(예컨 대, 모델 위치 URL, 모델 전반적 설명 등)를 UE에 제공한다. 다른 실시예에서, AI 미디어 AF는 이들 정보를 사용하여 AI 미디어 애플리케이션 공급자로부터 프로비저닝된 모 델 중에서 적합한 AI 모델 세트를 사전 선택한다. 그 후 AI 미디어 AF는 선택된 AI 모델과 관련된 설정 정보(예 컨대, AI 모델 데이터 위치 URL, AI 모델 전반적 설명 속성, 예를 들어, 모델 유형, 계층 수 등)를 포함하도록 AI 설정 파일을 업데이트하고, 업데이트된 AI 설정 파일을 UE로 전송한다. 이러한 업데이트된 설정 파일을 사용 하여, UE의 AI 모델 관리자는 서비스를 위해 적합한 하나의 AI 모델을 선택한다. 다른 실시예에서, AI 미디어 AF는 AI 모델을 사전 선택하지 않고, 대신 (5GS로부터 획득되는) 관련 네트워크 상 태/조건 정보를 UE로 전송한다. 그 후 UE는 AI 설정 파일과 네트워크 정보를 모두 수신하면, (UE로부터 내부적 으로 이용 가능한 것을 포함한) 이용 가능한 모든 정보를 사용하여 서비스를 위해 적합한 AI 모델을 결정하고 선택한다. 도 13에 설명된 모든 다양한 실시예는 또한 도 18의 세부 사항에도 적용 가능한다. 도 18은 AI 모델 전달 파이프라인을 통해 AI 모델 데이터를 전달하는 것 외에도, 5GMS(TS 26.501)에 정의된 미 디어 전달 파이프라인을 사용하여, 가장 기본적인 레벨에서 네트워크로부터 UE로 미디어 전달 파이프라인을 통 해 중간 데이터를 전달하는 것을 포함한다. 단계 3에서, AI 클라이언트는 또한 AI 미디어 세션에 필요한 미디어 전달 파이프라인을 결정할 수도 있다. 단계 4: AI 클라이언트는 단계 3에서 결정된 바와 같이, 요청된 필요한 분할 추론 설정을 네트워크에게 통지한 다. 단계 6 내지 단계 9: 필요한 네트워크 AI 모델 데이터(예컨대, 코어 모델)는 네트워크 AI 엔진으로 전송되고, 수집된 미디어 데이터도 또한 AI 엔진으로 전송된다. 그 후 네트워크 AI 엔진은 이들 데이터를 사용하여 AI 모 델 추론을 수행하고, 단계 10에서 중간 데이터 전달 파이프라인을 통해 출력 중간 데이터를 UE로 전송한다. 본 개시의 청구항 또는 명세서에 기재된 실시예의 방법은 하드웨어, 소프트웨어, 또는 하드웨어와 소프트웨어의 조합의 형태로 구현될 수 있다. 소프트웨어로 구현되는 경우, 하나 이상의 프로그램(소프트웨어 모듈)을 저장하는 컴퓨터 판독 가능한 저장 매 체가 제공될 수 있다. 컴퓨터 판독 가능한 저장 매체에 저장된 하나 이상의 프로그램은 전자 디바이스 내의 하 나 이상의 프로세서에 의해 실행되도록 구성된다. 하나 이상의 프로그램은 전자 디바이스가 본 개시의 청구항 또는 명세서에 설명된 실시예의 방법을 실행하게 하는 인스트럭션을 포함한다.그러한 프로그램(소프트웨어 모듈, 소프트웨어)은 랜덤 액세스 메모리, 플래시 메모리를 포함하는 비휘발성 메 모리, 판독 전용 메모리(ROM), 전기적 소거 가능 프로그래머블 ROM(EEPROM), 자기 디스크 저장 디바이스, 컴팩 트 디스크 ROM(CD-ROM), DVD(digital versatile disc) 또는 다른 광학 저장 디바이스, 자기 카세트에 저장될 수 있다. 또는, 프로그램은 이들 모두의 조합 또는 그 일부의 조합으로 구성된 메모리에 저장될 수 있다. 또 한, 구성된 각 메모리는 여러 개의 숫자로 포함될 수 있다. 또한, 프로그램은 통신 네트워크, 예를 들어, 인터넷, 인트라넷, LAN(local area network), WAN(wide area network), 또는 SAN(storage area network), 또는 이들의 조합으로 구성된 통신 네트워크를 통해 액세스될 수 있는 부착 가능한 저장 디바이스에 저장될 수 있다. 그러한 저장 디바이스는 외부 포트를 통해 본 개시의 실시 예를 수행하는 디바이스에 접속될 수 있다. 또한, 통신 네트워크 상의 별도의 저장 디바이스는 본 개시의 실시 예를 수행하는 디바이스에 접속될 수 있다. 전술한 본 개시의 특정 실시예에서, 본 개시에 포함된 컴포넌트는 제시된 특정 실시예에 따라 단수 또는 복수로 표현된다. 그러나, 단수 또는 복수의 표현은 설명의 편의를 위해 제시된 상황에 대해 적절하게 선택된 것일 뿐 이며, 본 개시는 단수 또는 복수의 컴포넌트에 국한되는 것은 아니며, 복수로 표현된 컴포넌트라도 단수로 구성 될 수 있거나, 단수로 표현된 컴포넌트라도 복수로 구성될 수 있다. 한편, 본 개시의 상세한 설명에서는 특정 실시예가 설명되었지만, 본 개시의 범위를 벗어나지 않는 범위 내에서 다양한 변형이 가능하다. 따라서, 본 개시의 범위는 설명된 실시예에 국한되어서는 안 되고 설명된 실시예에 의해 정의되어서는 안 되며, 후술되는 청구항의 범위 및 이들 청구항의 범위와 균등한 것에 의해 정의되어야 한 다."}
{"patent_id": "10-2024-7040208", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 개시의 다양한 실시예에 따른 무선 통신 시스템을 도시한 것이다. 도 2는 본 개시의 다양한 실시예에 따른 무선 통신 시스템에서 기지국의 구성을 도시한 것이다. 도 3은 본 개시의 다양한 실시예에 따른 무선 통신 시스템에서 단말의 구성을 도시한 것이다. 도 4는 본 개시의 다양한 실시예에 따른 TS 26.501의 전체 5G 미디어 스트리밍 아키텍처를 도시한 것이다. 도 5는 본 개시의 다양한 실시예에 따른 TS 26.501의 5G 미디어 스트리밍 일반 아키텍처를 도시한 것이다. 도 6은 본 개시의 다양한 실시예에 따른 TS 26.501에서 명시된 미디어 하향링크 스트리밍을 위한 절차의 예를 도시한 것이다. 도 7은 본 개시의 다양한 실시예에 따른 TS 26.501에서 정의된 유니캐스트 미디어 하향링크 스트리밍 세션의 수 립을 설명하는 기준 절차를 도시한 것이다. 도 8은 본 개시의 다양한 실시예에 따라 AI/ML 모델이 네트워크에서 UE(종단 디바이스)로 전달되어야 하는 AI/ML 미디어 서비스 시나리오의 예를 도시한 것이다. 도 9는 본 개시의 다양한 실시예에 따라 AI 모델이 UE에 전달되고 미디어(예컨대, 비디오)가 UE에 스트리밍되는 시나리오의 예를 도시한 것이다. 도 10은 본 개시의 다양한 실시예에 따라 AI 미디어 서비스에 필요한 추론이 네트워크와 UE 사이에서 분할되는 시나리오의 예를 도시한 것이다. 도 11은 본 개시의 다양한 실시예에 따른 무선 통신 시스템에서 미디어 서비스를 위한 AI 모델 전달을 가능하게 하는 다양한 기능 엔티티 및 인터페이스를 식별하는 미디어용 AI(AI4Media) 아키텍처의 예를 도시한 것이다. 도 12는 본 개시의 다양한 실시예에 따른 무선 통신 시스템에서 도 8의 시나리오에 대응하는 AL 모델 하향링크 전달을 위한 절차의 예를 도시한 것이다. 도 13은 본 개시의 다양한 실시예에 따른 무선 통신 시스템에서 도 8의 시나리오를 위한 기본 작업 흐름 절차를 도시한 것이다. 도 14a는 본 개시의 다양한 실시예에 따른 무선 통신 시스템에서 도 13의 단계 4에서 획득되는 다양한 AI 모델 전달 파이프라인의 예를 도시한 것이다. 도 14b는 본 개시의 다양한 실시예에 따른 무선 통신 시스템에서 도 13의 단계 4에서 획득되는 다양한 AI 모델 전달 파이프라인의 예를 도시한 것이다. 도 15는 본 개시의 다양한 실시예에 따른 무선 통신 시스템에서 도 9의 시나리오에 대응하는 AL 모델 하향링크 전달 및 미디어 콘텐츠 스트리밍 전달을 위한 절차의 예를 도시한 것이다. 도 16은 본 개시의 다양한 실시예에 따른 무선 통신 시스템에서 도 13에 기술된 기본 작업 흐름 절차를 확장한 도 9의 시나리오에 대한 기본 작업 흐름 절차를 도시한 것이다. 도 17은 본 개시의 다양한 실시예에 따른 무선 통신 시스템에서 도 10의 시나리오에 대응하는 분할 추론 AI 미 디어 서비스를 위한 절차의 예를 도시한 것이다. 도 18은 본 개시의 다양한 실시예에 따른 무선 통신 시스템에서 도 9의 시나리오를 위한 기본 작업 흐름 절차를 도시한 것이다."}
