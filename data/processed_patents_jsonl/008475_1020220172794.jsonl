{"patent_id": "10-2022-0172794", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0087261", "출원번호": "10-2022-0172794", "발명의 명칭": "모델 분할 전송에 기반한 연합학습 방법 및 장치", "출원인": "한국전자통신연구원", "발명자": "이창식"}}
{"patent_id": "10-2022-0172794", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "연합학습을 위한 방법에 있어서,단말이, 서버로부터 인공지능 모델 및 상기 인공지능 모델을 분할하기 위한 기준을 지시하는 체크포인트 리스트를 수신하는 과정;상기 단말이, 상기 체크포인트 리스트에 기초하여, 상기 인공지능 모델을 복수의 서브 모델들로 분할하는 과정;및 상기 단말이, 상기 복수의 서브 모델들을 먼저 갱신이 완료된 순으로 상기 서버에게 전송하는 과정을 포함하는, 방법."}
{"patent_id": "10-2022-0172794", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 체크포인트 리스트는, 하나 이상의 체크포인트들을 포함하고,상기 하나 이상의 체크포인트들 각각은, 상기 인공지능 모델의 레이어들 중에서 선택된 서로 다른 기준 레이어를 지시하는, 방법."}
{"patent_id": "10-2022-0172794", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,상기 전송하는 과정은,상기 기준 레이어에 대한 파라미터의 갱신이 완료된 것에 응답하여, 상기 갱신된 파라미터를 포함하는 서브 모델을 상기 서버에게 전송하는, 방법."}
{"patent_id": "10-2022-0172794", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,상기 전송하는 과정은,서로 다른 복수의 QoS 플로우들을 통해 상기 복수의 서브 모델들을 전송하는, 방법."}
{"patent_id": "10-2022-0172794", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서,상기 단말이, AMF(Access and Mobility Management Function)로부터 상기 복수의 서브 모델들을 전송하기 위한상기 복수의 QoS 플로우들에 적용되는 QoS 규칙을 획득하는 과정을 추가로 포함하는, 방법."}
{"patent_id": "10-2022-0172794", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제4항에 있어서,상기 전송하는 과정은, 갱신이 늦게 완료되는 서브 모델일수록, 높은 전송 속도를 갖는 QoS 플로우를 통해 전송되는, 방법."}
{"patent_id": "10-2022-0172794", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "공개특허 10-2024-0087261-3-제4항에 있어서,상기 전송하는 과정은, 파라미터의 수가 많은 서브 모델일수록, 높은 전송속도를 갖는 QoS 플로우를 통해 전송되는, 방법."}
{"patent_id": "10-2022-0172794", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "연합학습을 위한 방법에 있어서,서버가, 단말에게 인공지능 모델 및 상기 인공지능 모델을 복수의 서브 모델들로 분할하기 위한 기준을 지시하는 체크포인트 리스트를 전송하는 과정;상기 서버가, 먼저 갱신이 완료된 순으로 전송된 상기 복수의 서브 모델들을 상기 단말로부터 수신하는 과정;및상기 서버가, 상기 복수의 서브 모델들을 이용하여 상기 인공지능 모델을 갱신하는 과정을 포함하는, 방법."}
{"patent_id": "10-2022-0172794", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서,상기 체크포인트 리스트는, 하나 이상의 체크포인트들을 포함하고,상기 하나 이상의 체크포인트들 각각은, 상기 인공지능 모델의 레이어들 중에서 선택된 서로 다른 기준 레이어를 지시하는, 방법."}
{"patent_id": "10-2022-0172794", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제8항에 있어서,상기 서버가, 코어 네트워크의 기능 엔티티에게 상기 인공지능 모델 및 상기 인공지능 모델에 대한 연합학습 성능 요구사항을 전송하는 과정;상기 서버가, 상기 기능 엔티티로부터 상기 연합학습 성능 요구사항을 기준으로 결정된 상기 체크포인트 리스트를 수신하는 과정을 추가로 포함하는, 방법."}
{"patent_id": "10-2022-0172794", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제10항에 있어서,상기 기능 엔티티는, PCF(Policy Control Function)인, 방법."}
{"patent_id": "10-2022-0172794", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제10항에 있어서,상기 연합학습 성능 요구사항은,정확도(accuracy) 및 지연도(latency) 중 하나 이상에 대한 조건을 포함하는, 방법."}
{"patent_id": "10-2022-0172794", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제8항에 있어서,상기 수신하는 과정은,서로 다른 QoS 플로우들을 통해 전송된 상기 복수의 서브 모델들을 각각 수신하는, 방법."}
{"patent_id": "10-2022-0172794", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "연합학습을 위한 방법에 있어서,공개특허 10-2024-0087261-4-PCF가, AF(Application Function)로부터 인공지능 모델 및 상기 인공지능 모델에 대한 연합학습 성능 요구사항을 수신하는 과정; 및상기 PCF가, 상기 연합학습 성능 요구사항을 기초로, 상기 인공지능 모델을 복수의 서브 모델들로 분할하기 위한 기준을 지시하는 체크포인트 리스트를 결정하는 과정; 및상기 PCF가, 상기 AF에게 상기 결정된 체크포인트 리스트를 전송하는 과정을 포함하는, 방법."}
{"patent_id": "10-2022-0172794", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제14항에 있어서상기 체크포인트 리스트는, 하나 이상의 체크포인트들을 포함하고,상기 하나 이상의 체크포인트들 각각은, 상기 인공지능 모델의 레이어들 중에서 선택된 서로 다른 기준 레이어를 지시하는, 방법."}
{"patent_id": "10-2022-0172794", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제15항에 있어서,상기 PCF가 서로 다른 후보 체크포인트들의 조합을 포함하는 복수의 후보 체크포인트 리스트를 획득하는 과정을 추가로 포함하는, 방법."}
{"patent_id": "10-2022-0172794", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제16항에 있어서,상기 결정하는 과정은,상기 복수의 후보 체크포인트 리스트 중에서, 상기 연합학습 성능 요구사항을 만족할 수 있는 후보 체크포인트리스트를 상기 체크포인트 리스트로 결정하는 것인, 방법."}
{"patent_id": "10-2022-0172794", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제14항에 있어서,상기 PCF가, 상기 복수의 서브 모델들을 각각 전송하기 위한 복수의 QoS 플로우들에 적용할 QoS 정책(policy)을결정하는 과정추가로 포함하는 것을 특징으로 하는, 방법."}
{"patent_id": "10-2022-0172794", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제18항에 있어서,상기 QoS 정책은,갱신이 늦게 완료되는 서브 모델을 전송하기 위한 QoS 플로우의 전송 속도를 높게 설정하는 정책을 포함하는,방법."}
{"patent_id": "10-2022-0172794", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제18항에 있어서,상기 QoS 정책은,파라미터의 수가 많은 서브 모델을 전송하기 위한 QoS 플로우의 전송 속도를 높게 설정하는 정책을 포함하는,방법."}
{"patent_id": "10-2022-0172794", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "모델 분할 전송에 기반한 연합학습 방법 및 장치를 개시한다. 본 개시의 일 측면에 의하면, 연합학습을 위한 방법에 있어서, 단말이, 서버로부터 인공지능 모델 및 상기 인공 지능 모델을 분할하기 위한 기준을 지시하는 체크포인트 리스트를 수신하는 과정; 상기 단말이, 상기 체크포인트 리스트에 기초하여, 상기 인공지능 모델을 복수의 서브 모델들로 분할하는 과정; 및 상기 단말이, 상기 복수의 서브 모델들을, 먼저 갱신이 완료된 순으로 상기 서버에게 전송하는 과정을 포함하는, 방법을 제공한다."}
{"patent_id": "10-2022-0172794", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 모델 분할 전송에 기반한 연합학습 방법 및 장치에 관한 것이다."}
{"patent_id": "10-2022-0172794", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "이하에 기술되는 내용은 단순히 본 실시예와 관련되는 배경 정보만을 제공할 뿐 종래기술을 구성하는 것이 아니 다. 연합학습(Federated Learning) 방식은 각 단말에서 생성되는 데이터를 중앙 서버로 모아서 인공지능 모델을 학 습하는 대신, 단말에서 자체적으로 모델을 학습하고 학습된 모델의 가중치를 일정 주기마다 학습 서버로 전달함 으로써 집단 지성을 학습하는 방식이다. 연합학습은 단말과 학습 서버 간에 주기적으로 모델의 가중치를 주고받기 때문에, 학습에 사용되는 인공지능 모 델의 크기와 모델을 구성하는 파라미터의 개수가 커짐에 따라 단말과 학습 서버 간 네트워크에 많은 부하가 걸 리게 되고 이는 학습 속도를 저하시키는 주요 원인이 되기도 한다. 또한, 학습 서버에서 글로벌 모델을 만들기 위해서는 각 단말에서 보내는 모델 가중치를 모두 취합하여야 하기 때문에, 특정 단말의 네트워크 상태가 좋지 않아 모델 전송이 느릴 경우, 전체 학습 속도를 저하시키게 된다. 이러한 문제를 해결하고자, 연합학습에 참여하는 단말을 특정 기준에 따라 동적으로 선택하는 방법이 제시되고 있다. 일반적으로, 연합학습 속도는 단말의 프로세싱 속도와 모델 전송 속도에 영향을 받게 된다. 특히, 단말이 비슷한 프로세싱 능력을 가지고 있다는 전제하에, 단말의 모델 전송 속도가 연합학습 성능의 주요한 요인이 된 다. 따라서 연합학습에 참여하는 단말을 선택하는 데에 있어서 전송 속도가 높은, 즉 네트워크 상태가 좋은 단 말을 선택하게 되면 전체 연합학습 속도를 높일 수 있다. 하지만, 각 단말이 가지고 있는 데이터의 분포가 다르 므로, 단지 네트워크 상태가 좋은 단말만을 선택하게 되면 과적합(overfitting)으로 인해 모델의 범용성에 문제 가 생기게 된다."}
{"patent_id": "10-2022-0172794", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 개시는, 연합학습에 참여하는 단말이 학습한 모델의 가중치를 빠르게 전달할 수 있는 방법 및 장치를 제공하 는 데 일 목적이 있다. 본 발명이 해결하고자 하는 과제들은 이상에서 언급한 과제들로 제한되지 않으며, 언급되지 않은 또 다른 과제 들은 아래의 기재로부터 통상의 기술자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2022-0172794", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 개시의 일 측면에 의하면, 연합학습을 위한 방법에 있어서, 단말이, 서버로부터 인공지능 모델 및 상기 인공 지능 모델을 분할하기 위한 기준을 지시하는 체크포인트 리스트를 수신하는 과정; 상기 단말이, 상기 체크포인 트 리스트에 기초하여, 상기 인공지능 모델을 복수의 서브 모델들로 분할하는 과정; 및 상기 단말이, 상기 복수 의 서브 모델들을 먼저 갱신이 완료된 순으로 상기 서버에게 전송하는 과정을 포함하는, 방법을 제공한다. 본 개시의 다른 측면에 의하면, 연합학습을 위한 방법에 있어서, 서버가, 단말에게 인공지능 모델 및 상기 인공 지능 모델을 복수의 서브 모델들로 분할하기 위한 기준을 지시하는 체크포인트 리스트를 전송하는 과정; 상기 서버가, 먼저 갱신이 완료된 순으로 전송된 상기 복수의 서브 모델들을 상기 단말로부터 수신하는 과정; 및 상 기 서버가, 상기 복수의 서브 모델들을 연결하여 상기 인공지능 모델을 갱신하는 과정을 포함하는, 방법을 제공 한다. 본 개시의 다른 측면에 의하면, 연합학습을 위한 방법에 있어서, PCF가, AF(Application Function)로부터 인공 지능 모델 및 연합학습 성능 요구사항을 수신하는 과정; 및 상기 PCF가, 상기 연합학습 성능 요구사항을 기초로, 상기 인공지능 모델을 복수의 서브 모델로 분할하기 위한 기준을 지시하는 체크포인트 리스트를 결정하 는 과정; 및 상기 PCF가, 상기 AF에게 상기 결정된 체크포인트 리스트를 전송하는 과정을 포함하는, 방법을 제 공한다. 본 개시의 다른 측면에 의하면, 통신 인터페이스; 하나 이상의 명령어들을 저장하는 메모리; 상기 명령어들을 실행하는 프로세서를 포함하고, 상기 프로세서는 상기 명령어들을 실행함으로써, 인공지능 모델 및 상기 인공지능 모델을 분할하기 위한 기준을 지시하는 체크포인트 리스트를 수신하도록 상기 통신 인터페이스를 제어하고, 상기 체크포인트 리스트에 기초하여, 상기 인공지능 모델을 복수의 서브 모델들로 분할하고; 상기 복수의 서브 모델들을 먼저 갱신이 완료된 순으로 전송하도록 상기 통신 인터페이스를 제어하는, 단말을 제공한다. 본 개시의 다른 측면에 의하면, 통신 인터페이스; 하나 이상의 명령어들을 저장하는 메모리; 상기 명령어들을 실행하는 프로세서를 포함하고, 상기 프로세서는 상기 명령어들을 실행함으로써, 인공지능 모델 및 상기 인공지 능 모델을 복수의 서브 모델들로 분할하기 위한 기준을 지시하는 체크포인트 리스트를 전송하고 먼저 갱신이 완 료된 순으로 전송된 상기 복수의 서브 모델들을 수신하도록 상기 통신 인터페이스를 제어하고, 상기 복수의 서 브 모델들을 연결하여 상기 인공지능 모델을 갱신하는, 서버를 제공한다. 본 개시의 다른 측면에 의하면, 통신 인터페이스; 하나 이상의 명령어들을 저장하는 메모리; 상기 명령어들을 실행하는 프로세서를 포함하고, 상기 프로세서는 상기 명령어들을 실행함으로써, 인공지능 모델 및 연합학습 성 능 요구사항을 수신하도록 상기 통신 인터페이스를 제어하고, 상기 연합학습 성능 요구사항을 기초로, 상기 인 공지능 모델을 복수의 서브 모델로 분할하기 위한 기준을 지시하는 체크포인트 리스트를 결정하고, 상기 결정된 체크포인트 리스트를 전송하도록 상기 통신 인터페이스를 제어하는, 코어망의 제1 기능 엔티티를 제공한다."}
{"patent_id": "10-2022-0172794", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 개시의 실시예에 의하면, 인공지능 모델을 서브 모델 단위로 분할하고, 역전파(backward propagation)가 끝 난 서브 모델부터 먼저 전송함으로써, 전체 모델을 전송하는데 소요되는 시간을 줄일 수 있다. 본 개시의 실시예에 의하면, 서브 모델들, 다른 규칙이 적용된 QoS 플로우에 실어서 전송함으로써, 연합학습의 속도를 높일 수 있다. 본 개시의 효과들은 이상에서 언급한 효과들로 제한되지 않으며, 언급되지 않은 또 다른 효과들은 아래의 기재 로부터 통상의 기술자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2022-0172794", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 본 개시의 일부 실시예들을 예시적인 도면을 이용해 상세하게 설명한다. 각 도면의 구성 요소들에 참조 부호를 부가함에 있어서, 동일한 구성 요소들에 대해서는 비록 다른 도면 상에 표시되더라도 가능한 한 동일한 부호를 가지도록 하고 있음에 유의해야 한다. 또한, 본 개시를 설명함에 있어, 관련된 공지 구성 또는 기능에 대한 구체적인 설명이 본 개시의 요지를 흐릴 수 있다고 판단되는 경우에는 그 상세한 설명은 생략한다. 본 개시에 따른 실시예의 구성요소를 설명하는 데 있어서, 제1, 제2, i), ii), a), b) 등의 부호를 사용할 수 있다. 이러한 부호는 그 구성요소를 다른 구성 요소와 구별하기 위한 것일 뿐, 그 부호에 의해 해당 구성요소의 본질 또는 차례나 순서 등이 한정되지 않는다. 명세서에서 어떤 부분이 어떤 구성요소를 '포함' 또는 '구비'한 다고 할 때, 이는 명시적으로 반대되는 기재가 없는 한 다른 구성요소를 제외하는 것이 아니라 다른 구성요소를 더 포함할 수 있는 것을 의미한다. 첨부된 도면과 함께 이하에 개시될 상세한 설명은 본 개시의 예시적인 실시형태를 설명하고자 하는 것이며, 본 개시가 실시될 수 있는 유일한 실시형태를 나타내고자 하는 것이 아니다. 도 1은 본 개시의 일 실시예에 따른 연합학습을 위한 시스템을 예시한 도면이다. 도 1에 도시되듯이, 연합학습 시스템은, 연합학습 서버 및 복수의 단말을 포함할 수 있다. 도 1에서는, 세 개의 단말이 도시되었지만, 이는 설명의 편의를 위한 것일 뿐, 이에 제한되지 않는다. 또한, 도 1은 하 나의 연합학습 서버가 도시되었지만, 이는 설명의 편의를 위한 것일 뿐, 이에 제한되지 않는다. 예컨대, 연 합학습 시스템은, 클라우드 서비스를 제공하기 위한 복수개의 서버들을 포함할 수 있으며, 복수개의 서버들이 연합학습 서버로 통칭될 수 있다. 연합학습 서버는 연합학습이 필요한 인공지능 모델인 글로벌 모델(global model)을 단말로 배포할 수 있다. 각 단말은, 자체적으로 보유한 학습 데이터인, 로컬 데이터를 이용하여 학습을 수행한다. 학습 과정을 통해, 각각의 단말은 독립적으로 학습된 인공지능 모델인 로컬 모델(local model)을 보유하게 된다. 각 단말은 로컬 모델을 연합학습 서버로 전송할 수 있다. 본 개시의 일 실시예에 따른 단말은 로컬 모델을 소정의 단위로 분할하여 전송할 수 있다. 각 단말은, 로컬 모델의 학습이 완료된 이후에 로컬 모델 의 전체 가중치를 한번에 연합학습 서버에게 전송하지 않고, 학습이 완료되기 이전에 로컬 모델의 일부 가 중치를 먼저 전송할 수 있다. 연합학습 서버는 각 단말로부터 전달받은 가중치를 취합하여 글로벌 모델을 업데이트할 수 있다. 연합 학습 서버는 기설정된 시간 또는 기설정된 목표성능에 도달할 때 까지 연합학습을 반복적으로 수행할 수 있 다. 이하, 도 2 내지 도 5를 참조하여, 본 개시의 일 실시예에 따른 연합학습 서버 및/또는 단말에 의해 수 행되는 모델 분할 전송에 기반한 연합학습 방법을 구체적으로 설명하도록 한다. 도 2는 본 개시의 일 실시예에 따른 모델 분할을 설명하기 위한 예시도이다. 인공지능 모델은, 복수의 레이어를 포함하는 인공 신경망(Artificial Neural Network)일 수 있다. 예를 들 어, 인공지능 모델은, 도 2에 도시되듯이, 입력 레이어(input layer, 200), 복수의 히든 레이어(hidden layer, 201 내지 206), 및 출력 레이어(output layer, 206)를 포함하는 심층 신경망(Deep Neural Network, DNN)으로 구현될 수 있다. 각 레이어(200 내지 206)들은 하나 이상의 노드들을 포함할 수 있으며, 인접한 레이 어들에 포함된 노드들은 가중치를 가지는 연결선들을 통해 서로 연결될 수 있다. 이때, 인접한 레이어들에 포함 되는 노드들은 완전하게 혹은 부분적으로 연결될 수 있다. 한편, 본 개시에서는, 인공지능 모델이 통상적인 DNN의 구조를 갖는 경우를 가정하여 설명하나, 이는 설명 의 편의를 위한 것으로서, 본 개시가 이에 한정되는 것은 아니다. 본 개시의 기술적 사상은, 적어도 일부의 파 라미터(parameter)가 다른 파라미터보다 먼저 갱신될 수 있는 다른 구조의 인공지능 모델에 대해 연합학습을 수 행하는 경우에도 실질적인 기술적 사상의 변경 없이 적용될 수 있음에 유의하여 한다. 인공지능 모델은 체크포인트(Check Point; CP)를 기준으로 복수개의 서브 모델(sub model)로 구분될 수 있 다. 여기서, 체크포인트는 특정 레이어의 위치를 의미할 수 있다. 체크포인트는, 바람직하게는, 특정 히든 레이 어(201 내지 206)를 지시할 수 있다. 예를 들어, 도 2에 도시된 것과 같이, 제1 체크포인트(CP1)가 제2 히든 레이어를 지시하고, 제2 체크포인 트(CP2)가 제4 히든 레이어를 지시할 수 있다. 이때, 제1 서브 모델은 입력 레이어, 제1 히든 레이어 및 제2 히든 레이어를 포함할 수 있고, 제2 서브 모델은 제2 히든 레이어, 제3 히든 레이어 및 제4 히든 레이어를 포함할 수 있으며, 제3 서브 모델은 제4 히든 레이어, 제5 히든 레이어 , 및 출력 레이어를 포함할 수 있다. 각 서브 모델은, 체크포인트의 개수와 체크포인트가 지시하는 레이어의 위치에 따라, 다양하게 구성될 수 있다. 한편, 도 2에서는, 인공지능 모델이 7개의 레이어를 포함하며, 2개의 체크포인트를 기준으로 3개의 서브 모 델로 구분되는 예를 도시하고 있지만, 이는 설명의 편의를 위한 것일 뿐, 본 개시가 이에 제한되는 것은 아니다. 도 3은 본 개시의 일 실시예에 따른 모델 분할 전송을 설명하기 위한 예시도이다. 단말이 인공지능 모델을 훈련시키는 과정은, 크게 순전파(forward propagation) 과정과 역전파(backward propagation) 과정으로 구성될 수 있다. 순전파 과정에서, 단말은 주어진 로컬 데이터를 이용하여, 입력 레이어에서부터 출력 레이어까지 순차적으로, 각 레이어에 포함된 노드의 출력 값을 계산할 수 있다. 특정 레이어에 포함된 노드의 출력 값은, 해당 레이어의 이전(previous) 레이어에 포함된 노드들의 출력 값에 가중치가 적용된 값들 및 기설정된 활성화 함수에 기초하여 계산될 수 있다. 여기서, 이전 레이어는, 인접한 레이어들 중 입력 레이어 측에 가까운 레이어를 의미할 수 있다. 동일한 관점에서, 이후 레이어는 인접한 레이어들 중 출력 레이어 측에 가까운 레이어를 의미할 수 있다. 역전파 과정에서, 단말은 출력 레이어에 포함된 노드(들)의 출력 값을 기초로 손실(loss)을 산출하고, 산출된 손실을 기초로 노드들 간의 가중치를 갱신할 수 있다. 여기서, 가중치의 갱신은 출력 레이어로부터 입력 레이어의 방향으로 진행된다. 단말은, 역전파를 수행하는 과정에서 특정 체크포인트에 도달하면, 해당 체크포인트에 대응하는 서브 모델 의 가중치를 연합학습 서버에게 전송할 수 있다. 여기서, 체크포인트의 도달은, 해당 체크포인트가 지시하 는 기준 레이어와 이후 레이어 사이의 가중치의 갱신이 완료된 것을 의미할 수 있다. 단말은 체크포인트에 도달하면, 해당 체크포인트가 지시하는 기준 레이어와 그 이후 레이어를 포함하는 서브 모델을 연합학습 서버 에게 전송할 수 있다. 예를 들어, 단말은, 출력 레이어에서부터 역순으로 가중치를 갱신하다가, 제2 체크포인트(CP2)에 의해 지시되는 기준 레이어인 제4 히든 레이어와 그 이후 레이어인 제5 히든 레이어 사이의 가중치 갱신이 완료되면, 제4 히든 레이어, 제5 히든 레이어 및 출력 레이어를 포함하는 제3 서브 모델을 연합 학습 서버에게 전송할 수 있다. 단말은 계속해서 제4 히든 레이어에서부터 역순으로 가중치를 갱 신하다가, 제1 체크포인트(CP1)에 의해 지시되는 기준 레이어인 제2 히든 레이어와 그 이후 레이어인 제3 히든 레이어 사이의 가중치 갱신이 완료되면, 제2 히든 레이어, 제3 히든 레이어 및 제4 히든 레이어를 포함하는 제2 서브 모델을 연합학습 서버에게 전송할 수 있다. 마지막으로, 단말은 계속 해서 제2 히든 레이어에서부터 역순으로 가중치를 갱신하고, 입력 레이어에 도달, 즉, 입력 레이어 와 제1 히든 레이어 사이의 가중치 갱신이 완료되면, 입력 레이어), 제1 히든 레이어 및 제2 히든 레이어를 포함하는 제1 서브 모델을 연합학습 서버에게 전송할 수 있다. 이상과 같이, 단말은, 인공지능 모델의 갱신이 완료되기를 기다리지 않고, 특정 서브 모델의 갱신이 완료된 순간 해당 서브 모델을 먼저 전송할 수 있다. 도 4는 본 개시의 일 실시예에 따른 모델 분할 전송에 기반한 연합학습 방법을 나타내는 순서도이다. 연합학습 서버는 단말에게 연합학습을 수행할 글로벌 모델 및 체크포인트 리스트를 전송할 수 있다 (S300). 체크포인트 리스트는, 하나 이상의 체크포인트를 포함할 수 있다. 예컨대, 도 2의 예시에서, 체크포인 트 리스트는, 제1 체크포인트(CP1) 및 제2 체크포인트(CP2)를 포함할 수 있다. 단말은 로컬 데이터를 이용하여, 로컬 모델을 훈련시킬 수 있다(S320). 단말은 로컬 모델을 훈련하는 과정에서, 로컬 모델을 복수의 서브 모델로 분할하여 연합학습 서버로 전 송할 수 있다(S422 내지 S424). 복수의 서브 모델 중 적어도 일부는, 로컬 모델의 훈련이 완료되기 이전에 연합 학습 서버로 전송될 수 있다. 여기서, 서브 모델을 전송하는 것은, 서브 모델의 가중치를 전송하는 것을 포 함할 수 있다.연합학습 서버는 단말로부터 전달받은 복수의 서브 모델들을 연결하여 로컬 모델로 재구성할 수 있다 (S440). 연합학습 서버는 복수의 단말들에 의해 훈련된 복수의 로컬 모델의 가중치를 취합하여, 글로벌 모델을 갱신할 수 있다(S460). 복수의 로컬 모델의 가중치를 취합하여 글로벌 모델을 갱신하는 구체적인 방법은, 해당 분야에서 공지되어 있으므로, 자세한 내용은 생략한다. 본 개시에서는, 이에 대해 특별한 방식으로 한정하지 않 는다. 연합학습 서버는 갱신된 글로벌 모델을 다시 단말에게 전송함으로써, 연합학습을 반복적으로 수행할 수 있다(S480). 실시예들에 따라, 연합학습 서버는 새로운 체크포인트 리스트를 갱신된 글로벌 모델과 함께 단 말에게 전송할 수도 있다. 도 5는 본 개시의 일 실시예에 따른 연합학습 서버의 로컬 모델 재구성 과정을 설명하기 위한 예시도이다. 연합학습 서버와 단말 사이에는 서브 모델의 개수에 대한 정보가 사전에 공유되어 있을 수 있다(S500). 예컨대, 서브 모델의 개수는 체크포인트의 개수에 의해 정의될 수 있으며, 연합학습 서버가 단말에게 체크포인트들의 리스트를 전송함으로써, 서브 모델의 개수에 대한 정보가 공유될 수 있다. 단말은 복수개의 서브 모델을 갱신이 완료된 순서대로 연합학습 서버에게 전송할 수 있다(S520 내지 S560). 상술한 것과 같이, 단말은 특정 서브 모델의 가중치 갱신이 완료되면, 해당 서브 모델의 가중치를 연합학습 서버에게 전송할 수 있다. 이때, 단말은 서브 모델의 가중치와 함께 해당 서브 모델을 식별할 수 있는 식별자를 전송할 수 있다. 연합학습 서버는 서브 모델의 가중치와 함께 수신한 식별자를 참조하여, 로컬 모델을 재구성할 수 있다 (S580). 예를 들어, 연합학습 서버는, 식별자를 통해 각 서브 모델이 전체 로컬 모델의 몇 번째 서브 모델 인지를 식별하고, 해당 순서대로 서브 모델을 연결할 수 있다. 한편, 도 5에서는, 연합학습 서버가 모든 서브 모델을 수신한 이후에, 서브 모델들을 연결하여 로컬 모델을 재구성하는 것으로 도시하고 있으나, 본 개시가 이에 제한되는 것은 아니다. 구현예에 따라, 연합학습 서버(1 0)는 각 서브 모델을 수신한 것에 응답하여, 로컬 모델의 적어도 일부를 재구성할 수 있다. 예를 들어, 연합학 습 서버는 로컬 모델의 가중치를 저장할 수 있는 저장 공간을 사전에 마련해 둘 수 있다. 저장 공간은, 각 서브 모델의 가중치를 저장할 수 있는 영역으로 구분될 수 있다. 연합학습 서버는 특정 서브 모델의 가중치 및 식별자를 수신한 것에 응답하여, 수신한 식별자에 대응하는 영역에 수신한 가중치를 저장함으로써, 단말(1 2)에 의해 훈련된 로컬 모델의 적어도 일부를 재구성할 수 있다. 도 6은 본 개시가 적용될 수 있는 무선통신 시스템의 아키텍처를 예시한 도면이다. 코어 네트워크는 (무선) 액세스 네트워크((R)AN: (Radio) Access Network, 62)에 의해 상호접속되는 고객 들에게 많은 통신 서비스들을 제공할 수 있다. 코어 네트워크는 네트워크 기능(Network Function)을 수행하는 다수의 엔티티들을 포함할 수 있다. 본 개 시에서 '코어 네트워크 엔티티' 또는 '네트워크 기능'이라는 용어는 코어 네트워크의 하나 이상의 기능을 수행 하는 임의의 엔티티를 지칭할 수 있다. 코어 네트워크 엔티티들은, 무선 및/또는 네트워크 통신들을 위해 구성 된 장치 또는 컴퓨터 시스템의 메모리에 저장되고 그의 프로세서 상에서 실행되는 컴퓨터 실행가능 명령어들(소 프트웨어)의 형태로 구현되는 논리적 엔티티들일 수 있다 이동성 기능(AMF: Access and Mobility Management Function, 600)은 단말의 이동성 관리 기능을 담당할 수 있다. AMF는 액세스 기술에 독립적으로, 즉 단말 단위로 액세스 및 이동성 관리 기능을 제공할 수 있다. 따라서 각 단말은 기본적으로 하나의 AMF에 연결될 수 있다. 세션 관리 기능(SMF: Session Management Function, 601)은 단말까지의 세션을 관리하는 기능을 담당할 수 있다. 단말에 여러 개의 세션이 생성되어 있을 때, 각 세션 별로 다른 SMF가 할당될 수 있다. 사용자 평면 기능(UPF: User Plane Function, 602)은 데이터 네트워크(DN: Data Network, 64)로부터 수신한 하 향링크 PDU(Protocol Data Unit)를 (R)AN을 경유하여 단말에게 전달하며, (R)AN을 경유하여 단말 로부터 수신한 상향링크 PDU를 DN으로 전달할 수 있다. 정책 제어 기능(PCF: Policy Control Function, 603)은 서비스 품질(Quality of Service, QoS)을 보장하기 위 한, 패킷 흐름 정보를 바탕으로 세션 관리, 이동성 관리 등의 정책을 결정할 수 있다. PCF에서 결정된 정책은 AMF, SMF 등에 전달되고, 이후 각 네트워크 기능에서 이동성 관리, 세션 관리, QoS 관리 등이 수행될 수 있다. 통합 데이터 저장소(UDR: Unified Data Repository, 604)는 데이터를 저장 및 관리하는 네트워크 기능 내지 데 이터베이스(Database, DB)이다. UDR은 PCF가 정책을 결정하기 위해 필요한 정보를 저장하고 있을 수 있다. 애플리케이션 기능(AF: Application function, 605)은 코어 네트워크의 네트워크 기능들과 상호작용할 수 있다. AF와 네트워크 기능들 사이의 상호작용은 직접 인터페이스를 통할 수 있거나, 네트워크 노출 기능 (NEF: Network Exposure Function, 미도시)를 통해 발생할 수 있다. AF는 코어 네트워크의 일부로 간 주될 수 있거나, 코어 네트워크의 외부에 있고 모바일 네트워크 운영자와 비즈니스 관계를 갖는 기업들에 의해 배치될 수 있다. AF는, 특정 서비스를 지원하는 서버에서 제공되는 기능일 수 있다. 인공지능 모델을 기반으로 연합 학습을 수행하고자 하는 주체인 연합학습 서버에서 제공하는 기능(function)일 수 있다. 본 개시에서, 'AF' 및 '연합학습 서버'의 용어가 혼용되어 사용될 수 있다. 코어 네트워크는 5G 코어 네트워크(5GC)일 수 있으며, 5G 통신 시스템에서 사용되는 통신 기술, 네트워크 장치 구성 들의 개념이 본 개시의 실시예에서 참조될 수 있다. 도 7은 본 개시의 일 실시예에 따른 연합학습을 위한 초기 설정방법을 나타내는 순서도이다. AF는 연합학습을 수행할 인공지능 모델에 대한 정보를 UDR에 등록할 수 있다(S700). 여기서, 인공지 능 모델에 대한 정보는, 서로 다른 체크포인트들의 조합으로 구성된 복수의 후보 체크포인트 리스트를 포함할 수 있다. 예를 들어, 후보 체크포인트 리스트에 포함된 체크포인트들의 개수 및/또는 각 체크포인트가 지시하는 레이어의 위치가 상이할 수 있다. 인공지능 모델에 대한 정보는, 각 후보 체크포인트 리스트를 기준으로 인공지 능 모델을 분할할 경우에 구성되는 서브 모델의 파라미터 개수를 더 포함할 수도 있다. AF는 인공지능 모델과 연합학습의 성능에 대한 요구사항을 코어 네트워크으로 전달할 수 있다(S710). 여기서, 성능에 대한 요구사항은, 예컨대, 정확도(accuracy) 및/또는 지연도(latency)를 포함할 수 있다. AF가 전달한 인공지능 모델과 성능 요구사항은 코어 네트워크에 존재하는 PCF로 전달될 수 있다. PCF는 수신한 인공지능 모델에 대한 정보를 UDR에게 요청하고, UDR에 등록된 정보를 수신할 수 있다(S720). PCF는 UDR로부터 수신한 정보를 바탕으로, AF의 성능 요구사항을 만족시키기 위한 체크포인트 리스트 및 QoS 정책(policy)을 결정할 수 있다(S730). 여기서, QoS 정책은, 결정된 체크 포인트 리스트에 의해 구분되는 복수의 서브 모델을 전달하기 위해 사용될 QoS 플로우(flow)에 적용되는 정책을 의미할 수 있다. PCF는 결정된 체크포인트 리스트를 AF에게 반환할 수 있다(S740). PCF에 의해 결정된 QoS 정책은, SMF를 통해 UPF에 설정될 수 있다(S750). PCF에 의해 결정된 QoS 정책은, AMF를 통해 단말의 QoS 규칙(rule)으로 설정될 수 있다(S760). 정책 설정이 완료된 후, AF는 연합학습 과정을 개시할 수 있다(S770). 예를 들어, AF는 도 4에 도시 된 과정을 통해 단말과 연합학습을 수행할 수 있다. 한편, 도 7에서 과정 S700 및/또는 과정 S720은 구현예에 따라 생략될 수도 있다. 예를 들어, 과정 S710에서 AF가 인공지능 모델에 대한 정보를 인공지능 모델 및 성능 요구사항과 함께 PCF에게 전송하도록 구현 될 수도 있다. PCF는 AF로부터 인공지능 모델에 대한 정보를 전달받지 못한 경우에만, UDR로부 터 인공지능 모델에 대한 정보를 가져오도록 구현될 수도 있다. 도 8은 본 개시의 일 실시예에 따른 단말이 다중 QoS 플로우를 통해 복수의 서브 모델을 전달하는 과정을 설명 하기 위한 예시도이다. 도 8에 도시되듯이, 단말은 복수의 QoS 플로우를 이용하여, 복수의 서브 모델을 전송할 수 있다. 예컨대, 도 2의 예시와 같이 로컬 모델이 3개의 서브 모델로 구분되는 경우, 단말은 제3 서브 모델을 제3 QoS 플로 우에 실어서 전송하고, 제2 서브 모델을 제2 QoS 플로우에 실어서 전송하며, 제1 서브 모델을 제1 QoS 플로우에 실어서 전송할 수 있다. 따라서, 단말과 UPF간에 생성된 PDU 세션(session)에는 연합학습을 위해 총 3 개의 QoS 플로우가 존재할 수 있다. 각 QoS 플로우(flow)에 적용되는 QoS 규칙(rule)은, PCF가 결정한 QoS 정책(policy)에 따라 설정될 수 있 다. 일 예로, 특정 서브 모델의 파라미터가 매우 많은 경우, 해당 서브 모델이 실리는 QoS 플로우에 높은 비트 레이트(bit rate)를 적용할 수 있다. 다른 예로, 가장 나중에 전송되는 서브 모델, 즉 입력 레이어를 포함하는 서브 모델(예컨대, 도 2의 제1 서브 모델)의 가중치를 빠르게 보내기 위해, 해당 서브 모델이 실리는 QoS 플로 우의 비트 레이트를 높게 설정할 수도 있다. 한편, 도 8에서는, 하나의 QoS 플로우에 하나의 서브 모델이 할당되는 예를 도시하고 있으나, 본 개시가 이에 한정되는 것은 아니다. 예컨대, 다른 실시예에서 단말과 UPF 간에 생성된 PDU 세션에는, 연합학습을 위해 서브 모델의 개수보다 적은 개수의 QoS 플로우가 존재할 수 있으며, 적어도 하나의 QoS 플로우에 복수개의 서브 모델이 할당될 수 있다. 도 9는 본 개시의 일 실시예에 따른 단말이 서로 다른 전송 속도를 제공하는 QoS 플로우를 통해 복수의 서브 모 델을 전달하는 과정을 설명하기 위한 예시도이다. 이하 도 9를 설명함에 있어, 단말에서 훈련된 모델이 3개 의 서브 모델로 구성되며, 각 서브 모델은 비슷한 개수의 파라미터를 갖는다고 가정한다. 시점 T1에서, 단말은 역전파 과정이 먼저 끝난 제3 서브 모델을 낮은 전송속도를 가지는 QoS 플로우에 실어 서 전송할 수 있다. 시점 T2에서, 단말은 두번째로 역전파 과정이 끝난 제2 서브 모델을 중간의 전송속도를 가지는 QoS 플로우에 실어서 전송할 수 있다. 시점 T3에서, 단말은 마지막으로 역전파 과정이 끝난 제1 서 브 모델을 높은 전송속도를 갖는 QoS 플로우에 실어서 보낼 수 있다. 이와 같이, 복수의 서브 모델을, 갱신이 완료된 순서에 따라서 다른 전송 속도를 갖는 QoS 플로우를 통해 전송할 수 있다. 이에 따라, 연합학습 서버 측면에서는, 복수의 서브 모델을 비슷한 시점 T1', T2' 및 T3'에 수신할 수 있게 된다. 연합학습 서버(1 0)는 각 QoS 플로우를 통해 전달받은 서브 모델들을 연결하여, 전체 로컬 모델을 재구성할 수 있다. 도 10은 본 개시의 일 실시예에 따른 단말이 연합학습을 수행하는 방법을 나타내는 순서도이다. 도 10에 도시된 방법은, 전술한 단말의 하나 이상의 기능이 적어도 하나의 전자장치에 의해 수행됨으로써 구현될 수 있다. 따라서 이하의 설명은 전자장치가 수행하는 동작 측면으로도 이해될 수 있다. 단말은 인공지능 모델 및 체크포인트 리스트를 수신할 수 있다(S1000). 예를 들어, 단말은 연합학습 서 버로부터 인공지능 모델 및 체크포인트 리스트를 수신할 수 있다. 여기서, 체크포인트 리스트는, 인공지능 모델을 분할하기 위한 기준을 지시할 수 있다. 예를 들어, 체크포인트 리스트는 하나 이상의 체크포인트들을 포 함하고, 하나 이상의 체크포인트들 각각은, 인공지능 모델의 레이어들 중에서 선택된 서로 다른 기준 레이어를 지시할 수 있다. 단말은 체크포인트 리스트에 기초하여, 인공지능 모델을 복수의 서브 모델들로 분할할 수 있다(S1020). 단말은 복수의 서브 모델들을 먼저 갱신이 완료된 순으로 전송할 수 있다(S1040). 단말은 체크포인트가 지시하는 기준 레이어에 대한 파라미터의 갱신이 완료된 것에 응답하여, 갱신된 파라미터를 포함하는 서브 모델 을 연합학습 서버에게 전송할 수 있다. 예를 들어, 단말은 체크 포인트가 지시하는 기준 레이어와 이후 레 이어 사이의 가중치 갱신이 완료되면, 해당 기준 레이어 및 이후 레이어를 포함하는 서브 모델의 가중치를 연합 학습 서버에게 전송할 수 있다. 단말은 복수의 서브 모델들을 전송함에 있어서, 서로 다른 복수의 QoS 플로우들을 통해 복수의 서브 모델들 을 전송할 수 있다. 각 QoS 플로우에는 적어도 하나의 서브 모델이 할당될 수 있다. 일 예로, 갱신이 늦게 완료 되는 서브 모델일수록, 높은 전송 속도를 갖는 QoS 플로우를 통해 전송될 수 있다. 다른 예로, 파라미터의 수가 많은 서브 모델일수록, 높은 전송속도를 갖는 QoS 플로우를 통해 전송될 수 있다. 이를 위해, 과정 S1000 내지 과정 S1040 중 어느 하나의 과정이 수행되기에 앞서, 단말은 코어 네트워크 의 기능 엔티티로부터 복수의 서브 모델들을 각각 전송하기 위한 복수의 QoS 플로우들에 적용되는 QoS 규칙 을 획득할 수 있다. 일 예로, QoS 규칙은, 갱신이 늦게 완료되는 서브 모델을 전송하기 위한 QoS 플로우의 전송 속도를 높게 설정하는 규칙을 포함할 수 있다. 다른 예로, QoS 규칙은, 파라미터의 수가 많은 서브 모델을 전송 하기 위한 QoS 플로우의 전송 속도를 높게 설정하는 규칙을 포함할 수 있다. 여기서, 코어 네트워크의 기능 엔티티는, AMF일 수 있다. 도 11은 본 개시의 일 실시예에 따른 연합학습 서버가 연합학습을 수행하는 방법을 나타내는 순서도이다. 도 11 에 도시된 방법은, 전술한 연합학습 서버의 하나 이상의 기능이 적어도 하나의 전자장치에 의해 수행됨으로 써 구현될 수 있다. 따라서 이하의 설명은 전자장치가 수행하는 동작 측면으로도 이해될 수 있다. 연합학습 서버는 인공지능 모델 및 체크포인트 리스트를 전송할 수 있다(S1100). 예를 들어, 연합학습 서버 는 복수의 단말들 각각에게 인공지능 모델 및 체크포인트 리스트를 전송할 수 있다. 여기서, 체크포인 트 리스트는, 인공지능 모델을 분할하기 위한 기준을 지시할 수 있다. 예를 들어, 체크포인트 리스트는 하나 이 상의 체크포인트들을 포함하고, 하나 이상의 체크포인트들 각각은, 인공지능 모델의 레이어들 중에서 선택된 서 로 다른 기준 레이어를 지시할 수 있다. 연합학습 서버는 먼저 갱신이 완료된 순으로 전송된 복수의 서브 모델들을 수신할 수 있다(S1120). 연합학 습 서버는 복수의 단말들 각각으로부터, 서로 다른 QoS 플로우들을 통해 전송된 복수의 서브 모델들을 수신할 수 있다. 각 서브 모델을 수신하는 것은, 각 서브 모델의 파라미터 및 식별자를 수신하는 것을 포함할 수 있다. 연합학습 서버는 복수의 서브 모델들을 이용하여 인공지능 모델을 갱신할 수 있다(S1140). 연합학습 서버 는 각 서브 모델의 식별자를 이용하여, 로컬 모델 내에서 해당 서브 모델의 순서를 식별할 수 있다. 연합학 습 서버는 각 단말들이 전송한 복수의 서브 모델들을 연결하여, 각 단말에 의해 학습된 로컬 모델 을 재구성할 수 있다. 연합학습 서버는 각 단말에 의해 학습된 복수의 로컬 모델을 취합하여, 글로벌 모델 을 갱신할 수 있다. 일부 실시예에서, 과정 S1100을 수행하기에 앞서, 연합학습 서버는 코어 네트워크의 기능 엔티티로부터 체크포인트 리스트를 수신할 수 있다. 예를 들어, 연합학습 서버는 코어 네트워크의 기능 엔티티에게 인공지능 모델 및 인공지능 모델에 대한 연합학습 성능 요구사항을 전송하고, 해당 연합학습 성능 요구사항을 기준으로 결정된 체크포인트 리스트를 수신할 수 있다. 연합학습 성능 요구사항은, 예를 들어, 정확도 (accuracy) 및 지연도(latency) 중 하나 이상에 대한 조건을 포함할 수 있다. 여기서, 코어 네트워크의 기 능 엔티티는 PCF일 수 있다. 도 12는 본 개시의 일 실시예에 따른 코어 네트워크의 기능 엔티티가 연합학습을 지원하는 방법을 나타내는 순 서도이다. 도 12에 도시된 방법은, 전술한 코어 네트워크의 하나 이상의 네트워크 기능이 적어도 하나의 전 자장치에 의해 수행됨으로써 구현될 수 있다. 따라서 이하의 설명은 전자장치가 수행하는 동작 측면으로도 이해 될 수 있다. 이하에서는, 코어 네트워크의 제1 기능 엔티티가 도 12에 도시된 방법을 수행하는 것으로 가정 하여 설명한다. 제1 기능 엔티티는 연합학습의 대상이 되는 인공지능 모델 및 해당 인공지능 모델에 대한 연합학습 성능 요구사 항을 수신할 수 있다(S1200). 예를 들어, PCF는 코어 네트워크의 내부 또는 외부에 구현된 제2 기능 엔티티로부터 인공지능 모델 및 연합학습 성능 요구사항을 수신할 수 있다. 여기서, 제2 기능 엔티티는 예컨대, AF일 수 있다. 제1 기능 엔티티는 인공지능 모델에 관한 정보를 획득할 수 있다(S1220). 일 예로, 제1 기능 엔티티는 제3 기능 엔티티로부터 인공지능 모델에 관한 정보를 수신할 수 있다. 제3 기능 엔티티는 UDR 또는 AF일 수 있 다. 실시예들에 따라, 제1 기능 엔티티는 과정 S1200에서, 인공지능 모델과 인공지능 모델에 관한 정보를 함께 수신할 수 있다. 다른 예로, 제1 기능 엔티티는 과정 S1200에서 수신한 인공지능 모델을 기초로, 인공지능 모델 에 관한 정보를 파악할 수도 있다. 여기서, 인공지능 모델에 관한 정보는 예를 들어, 인공지능 모델을 복수의 서브 모델들로 분할할 수 있는 기준을 지시하는 복수의 후보 체크포인트 리스트를 포함할 수 있다. 여기서, 복 수의 후보 체크포인트 리스트는, 서로 다른 후보 체크포인트들의 조합을 포함할 수 있다. 하나의 체크포인트 리 스트에 포함되는 하나 이상의 후보 체크포인트는 인공지능 모델의 레이어들 중에서 선택된 서로 다른 기준 레이 어를 지시할 수 있다. 인공지능 모델에 관한 정보는, 각 후보 체크포인트 리스트를 기준으로 인공지능 모델을 분할할 경우에 구성되는 서브 모델의 파라미터 개수를 더 포함할 수도 있다. 제1 기능 엔티티는 연합학습 성능 요구사항을 기초로, 체크포인트 리스트를 결정할 수 있다(S1240). 예를 들어, 제1 기능 엔티티는 복수의 후보 체크포인트 리스트 중에서, 연합학습 성능 요구사항을 만족할 수 있는 후보 체 크포인트 리스트를 선택할 수 있다. 제1 기능 엔티티는 결정된 체크포인트 리스트를 제2 기능 엔티티에게 전송할 수 있다(S1260). 일부 실시예에서, 제1 기능 엔티티는 PCF일 수 있다. 제1 기능 엔티티는, 결정된 체크포인트 리스트에 따 라 구성되는 복수의 서브 모델들을 각각 전송하기 위한 복수의 QoS 플로우들에 적용할 QoS 정책(policy)을 결정 할 수 있다. 일 예로, QoS 정책은, 갱신이 늦게 완료되는 서브 모델을 전송하기 위한 QoS 플로우의 전송 속도를 높게 설정하는 정책을 포함할 수 있다. 다른 예로, QoS 정책은, 파라미터의 수가 많은 서브 모델을 전송하기 위한 QoS 플로우의 전송 속도를 높게 설정하는 정책을 포함할 수 있다. 도 13은 본 개시의 일 실시예에 따른 모델 분할 전송에 기반한 연합학습을 위한 기능을 포함하는 전자장치를 개 략적으로 나타낸 블록구성도이다. 일 실시 예에서, 전자장치는 모델 분할 전송에 기반한 연합학습을 수행하도록 동작하는 연합학습 서버(1 0)일 수 있다. 다른 실시예에서, 전자장치는 모델 분할 전송에 기반한 연합학습을 수행하도록 동작하는 단 말일 수 있다. 다른 실시예에서 전자장치는 모델 분할 전송에 기반한 연합학습을 지원하도록 동작하는 코어 네트워크의 기능 엔티티를 구현하는 장치일 수 있다. 전자장치는 통신 인터페이스, 메모리 및 프로세서를 전부 또는 일부 포함한다. 통신 인터페이스는 프로세서와 연결되어, 다른 전자장치와 각종 무선신호를 송수신할 수 있다. 통 신 인터페이스는 예컨대, 송신 필터, 수신 필터, 증폭기, 믹서(mixer), 오실레이터(oscillator), DAC(Digital to Analog Convertor) 및 ADC(Analog to Digital Convertor) 등을 전부 또는 일부 포함할 수 있다. 메모리는 프로세서와 연결되어, 프로세서를 구동하기 위한 다양한 정보를 저장할 수 있다. 메모리는 프로세서를 통해 실행가능한 적어도 하나의 명령어를 저장할 수 있다. 메모리는 휘 발성 메모리 및 비휘발성 메모리 중 적어도 하나를 포함할 수 있다. 휘발성 메모리는 SRAM(Static Random Access Memory) 또는 DRAM(Dynamic Random Access Memory) 등 중 어느 하나를 포함할 수 있고, 비휘발성 메모 리는 플래시 메모리(flash memory) 등 중 어느 하나를 포함할 수 있다. 프로세서는 통신 인터페이스가 각종 무선신호를 송수신하도록 제어할 수 있으며, 전송할 또는 수신 한 무선신호 등을 메모리에 저장하도록 제어할 수도 있다. 프로세서는 도 1 내지 도 12에서 제안된 기능, 과정 및/또는 방법을 구현하도록 구성될 수 있다. 전술한 실시예에서 연합학습 서버, 전자장치 및/또는 코어 네트워크의 기능 엔티티의 동작이 프로세서 에 의해 구현될 수 있다. 일 예로, 프로세서는, 메모리에 저장된 명령어들을 실행함으로써, 인공지능 모델 및 인공지능 모델 을 분할하기 위한 기준을 지시하는 체크포인트 리스트를 수신하도록 통신 인터페이스를 제어할 수 있다. 프로세서는 수신한 체크포인트 리스트에 기초하여, 인공지능 모델을 복수의 서브 모델들로 분할할 수 있 다. 프로세서는 복수의 서브 모델들이 먼저 갱신이 완료된 순으로 전송되도록 통신 인터페이스를 제어할 수 있다. 다른 예로, 프로세서는, 메모리에 저장된 명령어들을 실행함으로써, 인공지능 모델 및 인공지능 모 델을 복수의 서브 모델들로 분할하기 위한 기준을 지시하는 체크포인트 리스트를 전송하도록 통신 인터페이스 를 제어할 수 있다. 프로세서는 먼저 갱신이 완료된 순으로 전송된 복수의 서브 모델들을 수신하도 록 통신 인터페이스를 제어할 수 있다. 프로세서는 수신한 복수의 서브 모델들을 연결하여 인공지 능 모델을 갱신할 수 있다. 다른 예로, 프로세서는, 메모리에 저장된 명령어들을 실행함으로써, 인공지능 모델 및 연합학습 성 능 요구사항을 수신하도록 통신 인터페이스를 제어할 수 있다. 프로세서는 수신한 연합학습 성능 요구사항을 기초로, 인공지능 모델을 복수의 서브 모델로 분할하기 위한 기준을 지시하는 체크포인트 리스트를 결정할 수 있다. 프로세서는 결정된 체크포인트 리스트를 전송하도록 통신 인터페이스를 제어할 수 있다. 본 개시의 예시적인 실시예들에 기술된 적어도 일부의 구성요소들은 DSP(Digital Signal Processor), 프로세서, 컨트롤러, ASIC(Application-Specific IC), 프로그래머블 로직소자(FPGA 등), 기타 전자소자 중의 적어도 하나 또는 이들의 조합이 포함되는 하드웨어 요소로써 구현될 수 있다. 또한, 예시적인 실시예들에서 기술된 적어도 일부의 기능(function)들 또는 처리과정(process)들은 소프트웨어로 구현될 수 있으며, 소프트웨어는 기록매체 에 저장될 수 있다. 본 개시의 예시적인 실시예들에 기술된 적어도 일부의 구성요소들, 기능들, 그리고 처리과 정들은 하드웨어와 소프트웨어의 결합으로 구현될 수 있다. 본 개시의 예시적인 실시예들에 따른 방법은 컴퓨터에서 실행될 수 있는 프로그램으로 작성될 수 있고, 마그네 틱 저장매체, 광학적 판독매체, 디지털 저장매체 등 다양한 기록 매체로도 구현될 수 있다.본 명세서에 설명된 각종 기술들의 구현들은 디지털 전자 회로조직으로, 또는 컴퓨터 하드웨어, 펌웨어, 소프트 웨어로, 또는 그들의 조합들로 구현될 수 있다. 구현들은 데이터 처리 장치, 예를 들어 프로그램가능 프로세서, 컴퓨터, 또는 다수의 컴퓨터들의 동작에 의한 처리를 위해, 또는 이 동작을 제어하기 위해, 컴퓨터 프로그램 제 품, 즉 정보 캐리어, 예를 들어 기계 판독가능 저장 장치(컴퓨터 판독가능 매체) 또는 전파 신호에서 유형적으 로 구체화된 컴퓨터 프로그램으로서 구현될 수 있다. 상술한 컴퓨터 프로그램(들)과 같은 컴퓨터 프로그램은 컴 파일된 또는 인터프리트된 언어들을 포함하는 임의의 형태의 프로그래밍 언어로 기록될 수 있고, 독립형 프로그 램으로서 또는 모듈, 구성요소, 서브루틴, 또는 컴퓨팅 환경에서의 사용에 적절한 다른 유닛으로서 포함하는 임 의의 형태로 전개될 수 있다. 컴퓨터 프로그램은 하나의 사이트에서 하나의 컴퓨터 또는 다수의 컴퓨터들 상에 서 처리되도록 또는 다수의 사이트들에 걸쳐 분배되고 통신 네트워크에 의해 상호 연결되도록 전개될 수 있다. 컴퓨터 프로그램의 처리에 적절한 프로세서들은 예로서, 범용 및 특수 목적 마이크로프로세서들 둘 다, 및 임의 의 종류의 디지털 컴퓨터의 임의의 하나 이상의 프로세서들을 포함한다. 일반적으로, 프로세서는 판독 전용 메 모리 또는 랜덤 액세스 메모리 또는 둘 다로부터 명령어들 및 데이터를 수신할 것이다. 컴퓨터의 요소들은 명령 어들을 실행하는 적어도 하나의 프로세서 및 명령어들 및 데이터를 저장하는 하나 이상의 메모리 장치들을 포함 할 수 있다. 일반적으로, 컴퓨터는 데이터를 저장하는 하나 이상의 대량 저장 장치들, 예를 들어 자기, 자기-광 디스크들, 또는 광 디스크들을 포함할 수 있거나, 이것들로부터 데이터를 수신하거나 이것들에 데이터를 송신하 거나 또는 양쪽으로 되도록 결합될 수도 있다. 컴퓨터 프로그램 명령어들 및 데이터를 구체화하는데 적절한 정 보 캐리어들은 예로서 반도체 메모리 장치들, 예를 들어, 하드 디스크, 플로피 디스크 및 자기 테이프와 같은 자기 매체(Magnetic Media), CD-ROM(Compact Disk Read Only Memory), DVD(Digital Video Disk)와 같은 광 기 록 매체(Optical Media), 플롭티컬 디스크(Floptical Disk)와 같은 자기-광 매체(Magneto-Optical Media), 롬 (ROM, Read Only Memory), 램(RAM, Random Access Memory), 플래시 메모리, EPROM(Erasable Programmable ROM), EEPROM(Electrically Erasable Programmable ROM) 등을 포함한다. 프로세서 및 메모리는 특수 목적 논리 회로조직에 의해 보충되거나, 이에 포함될 수 있다. 프로세서는 운영 체제(Operating System) 및 상기 운영 체제 상에서 수행되는 소프트웨어 애플리케이션을 수행 할 수 있다. 또한, 프로세서 디바이스는 소프트웨어의 실행에 응답하여, 데이터를 접근, 저장, 조작, 처리 및 생성할 수도 있다. 이해의 편의를 위하여, 프로세서 디바이스는 하나가 사용되는 것으로 설명된 경우도 있지만,"}
{"patent_id": "10-2022-0172794", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "해당 기술분야에서 통상의 지식을 가진 자는, 프로세서 디바이스가 복수 개의 처리 요소(processing element) 및/또는 복수 유형의 처리 요소를 포함할 수 있음을 알 수 있다. 예를 들어, 프로세서 디바이스는 복수 개의 프 로세서 또는 하나의 프로세서 및 하나의 컨트롤러를 포함할 수 있다. 또한, 병렬 프로세서(parallel processo r)와 같은, 다른 처리 구성(processing configuration)도 가능하다. 또한, 비-일시적 컴퓨터 판독가능 매체(non-transitory computer-readable media)는 컴퓨터에 의해 액세스될 수 있는 임의의 가용매체일 수 있고, 컴퓨터 저장매체 및 전송매체를 모두 포함할 수 있다. 본 명세서는 다수의 특정한 구현물의 세부사항들을 포함하지만, 이들은 어떠한 발명이나 청구 가능한 것의 범위 에 대해서도 제한적인 것으로서 이해되어서는 안되며, 오히려 특정한 발명의 특정한 실시형태에 특유할 수 있는 특징들에 대한 설명으로서 이해되어야 한다. 개별적인 실시형태의 문맥에서 본 명세서에 기술된 특정한 특징들 은 단일 실시형태에서 조합하여 구현될 수도 있다. 반대로, 단일 실시형태의 문맥에서 기술한 다양한 특징들 역 시 개별적으로 혹은 어떠한 적절한 하위 조합으로도 복수의 실시형태에서 구현 가능하다. 나아가, 특징들이 특 정한 조합으로 동작하고 초기에 그와 같이 청구된 바와 같이 묘사될 수 있지만, 청구된 조합으로부터의 하나 이 상의 특징들은 일부 경우에 그 조합으로부터 배제될 수 있으며, 그 청구된 조합은 하위 조합이나 하위 조합의 변형물로 변경될 수 있다. 마찬가지로, 특정한 순서로 도면에서 동작들을 묘사하고 있지만, 이는 바람직한 결과를 얻기 위하여 도시된 그 특정한 순서나 순차적인 순서대로 그러한 동작들을 수행하여야 한다거나 모든 도시된 동작들이 수행되어야 하는 것으로 이해되어서는 안 된다. 특정한 경우, 멀티태스킹과 병렬 프로세싱이 유리할 수 있다. 또한, 상술한 실시 형태의 다양한 장치 컴포넌트의 분리는 그러한 분리를 모든 실시형태에서 요구하는 것으로 이해되어서는 안되며, 설명한 프로그램 컴포넌트와 장치들은 일반적으로 단일의 소프트웨어 제품으로 함께 통합되거나 다중 소프트웨어 제품에 패키징 될 수 있다는 점을 이해하여야 한다. 한편, 본 명세서와 도면에 개시된 본 발명의 실시 예들은 이해를 돕기 위해 특정 예를 제시한 것에 지나지 않으 며, 본 발명의 범위를 한정하고자 하는 것은 아니다. 여기에 개시된 실시 예들 이외에도 본 발명의 기술적 사상"}
{"patent_id": "10-2022-0172794", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "에 바탕을 둔 다른 변형 예들이 실시 가능하다는 것은, 본 발명이 속하는 기술분야에서 통상의 지식을 가진 자에게 자명한 것이다. 본 실시예의 보호 범위는 아래의 청구범위에 의하여 해석되어야 하며, 그와 동등한 범위 내에 있는 모든 기술 사상은 본 실시예의 권리범위에 포함되는 것으로 해석되어야 할 것이다."}
{"patent_id": "10-2022-0172794", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 개시의 일 실시예에 따른 연합학습을 위한 시스템을 예시한 도면이다. 도 2는 본 개시의 일 실시예에 따른 모델 분할을 설명하기 위한 예시도이다. 도 3은 본 개시의 일 실시예에 따른 모델 분할 전송을 설명하기 위한 예시도이다. 도 4는 본 개시의 일 실시예에 따른 모델 분할 전송에 기반한 연합학습 방법을 나타내는 순서도이다. 도 5는 본 개시의 일 실시예에 따른 연합학습 서버의 로컬 모델 재구성 과정을 설명하기 위한 예시도이다. 도 6은 본 개시가 적용될 수 있는 5G 시스템의 아키텍처를 예시한 도면이다. 도 7은 본 개시의 일 실시예에 따른 연합학습을 위한 초기 설정방법을 나타내는 순서도이다. 도 8은 본 개시의 일 실시예에 따른 단말이 다중 QoS 플로우를 통해 복수의 서브 모델을 전달하는 과정을 설명 하기 위한 예시도이다. 도 9는 본 개시의 일 실시예에 따른 단말이 서로 다른 전송 속도를 제공하는 QoS 플로우를 통해 복수의 서브 모 델을 전달하는 과정을 설명하기 위한 예시도이다. 도 10은 본 개시의 일 실시예에 따른 단말이 연합학습을 수행하는 방법을 나타내는 순서도이다. 도 11은 본 개시의 일 실시예에 따른 연합학습 서버가 연합학습을 수행하는 방법을 나타내는 순서도이다. 도 12는 본 개시의 일 실시예에 따른 코어 네트워크의 기능 엔티티가 연합학습을 지원하는 방법을 나타내는 순 서도이다. 도 13은 본 개시의 일 실시예에 따른 모델 분할 전송에 기반한 연합학습을 위한 기능을 포함하는 전자장치를 개 략적으로 나타낸 블록구성도이다."}
