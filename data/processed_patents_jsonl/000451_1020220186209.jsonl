{"patent_id": "10-2022-0186209", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0103754", "출원번호": "10-2022-0186209", "발명의 명칭": "인공지능 기반 동영상 품질 분석 시스템 및 그 방법", "출원인": "씨제이올리브네트웍스 주식회사", "발명자": "정혜린"}}
{"patent_id": "10-2022-0186209", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "사용자 단말로부터 오류 검증을 수행해야 할 동영상 정보를 수신받아 저장하고, 저장한 동영상 정보에 대한 추출 프레임 간격 정보를 생성하며, 상기 추출 프레임 간격 정보를 포함하는 오류 검증 요청 신호를 생성하여 전송하는 동영상 정보 제공부; 및 상기 동영상 정보 제공부로부터 상기 오류 검증 요청 신호를 수신받으며, 수신받은 상기 오류 검증 요청 신호에포함되어 있는 동영상 정보에 대한 오류의 종류를 판별하고, 판별한 오류의 종류에 따라 상기 동영상 정보의 오류를 검증하여 오류 검증 결과 정보를 생성하며, 생성한 상기 오류 검증 결과 정보를저장함과 동시에 상기 동영상 정보 제공부로 전송하는 동영상 품질 분석 서버;를 포함하는 것을 특징으로 하는 인공지능 기반 동영상 품질 분석 시스템."}
{"patent_id": "10-2022-0186209", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 동영상 정보 제공부는, 상기 사용자 단말로 추출 프레임 간격 요청 신호를 송신하는 경우, FPS 값을 기준으로 하여 추출 프레임 간격요청 신호를 생성하여 상기 동영상 품질 분석 서버로 전송하는 것을 특징으로 하는 인공지능 기반 동영상 품질분석 시스템."}
{"patent_id": "10-2022-0186209", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서, 동영상 정보 제공부(100)는 사용자 단말로부터 수신받은 동영상 정보를 저장할 수 있으며, 저장한 동영상 정보를 카테고리 별로 분류하여 각각 개별적으로 저장할 수 하는 인공지능 기반 동영상 품질 분석 시스템."}
{"patent_id": "10-2022-0186209", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서, 상기 동영상 품질 분석 서버는, 상기 추출 프레임 간격 정보에 포함된 동영상 정보의 오류 검증을 위하여 이미지 데이터로 변환하여 전송하는프레임 추출부; 상기 이미지 데이터를 프레임 및 샷별로 각각 그룹화하여 그룹화한 프레임별 그룹 데이터 및 샷(shot)별 그룹데이터를 생성하여 전송하는 그룹 데이터 생성부; 그룹 데이터들(프레임별 그룹 데이터, 샷별 그룹 데이터)를 딥러닝 기반 오류 검증 모델을 통해 분석하여 각각의 그룹 데이터들에 대한 오류를 검증하는 오류 검증부; 상기 동영상 정보 제공부로부터 상기 오류 검증 요청 신호를 수신받아 분석하여 동영상 정보와 추출 프레임 간격 정보를 분류하여 데이터베이스 및 상기 프레임 추출부로 전송하고, 상기 그룹 데이터 생성부로부터 생성이완료된 그룹 데이터들을 수신받아 분석하여 해당 동영상 정보에 오류가 존재하는지 여부를 확인하고, 오류가 존재하는 경우, 해당 오류가 프레임별 그룹 데이터, 또는 샷별 그룹 데이터 중 어느 하나, 또는 둘 모두에 존재하는지 여부를 판단하며, 상기 프레임 추출부 및 그룹 데이터 생성부에서 생성한 데이터들을 수신받아 데이터베이공개특허 10-2024-0103754-3-스로 전송하는 제어부; 상기 프레임 추출부, 그룹 데이터 생성부에서 생성한 데이터들을 상기 제어부로부터 수신받아 저장하고, 상기제어부의 제어에 따라 저장한 그룹 데이터들을 상기 오류 검증부로 전송하는 데이터베이스;를 포함하는 것을 특징으로 하는 인공지능 기반 동영상 품질 분석 시스템."}
{"patent_id": "10-2022-0186209", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서, 상기 그룹 데이터 생성부는, 상기 샷별 그룹 데이터를 생성할 때, 상기 프레임 추출부에서 수신받은 동영상 정보를 제공받아 딥러닝 모델을통해 샷별로 분리하여 샷별 그룹 데이터로 생성하는 것을 특징으로 하는 인공지능 기반 동영상 품질 분석 시스템."}
{"patent_id": "10-2022-0186209", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제4항에 있어서, 상기 오류 검증부는, 상기 샷별 그룹 데이터의 색상 공간이 훼손되었는지 여부, 프레임의 튐 현상 및 버벅임 현상이 존재하는지 여부에 대한 오류를 검증할 수 있도록 상기 샷별 그룹 데이터를 프레임별로 구분한 후, 딥러닝 기반 오류 검증 모델을 활용하여 검증하는 샷별 오류 검증 모듈과, 상기 프레임별 그룹 데이터의 오류를 검증할 수 있도록 상기 프레임별 그룹 데이터를 프레임별로 구분한 후, 딥러닝 기반 오류 검증 모델을 활용하여 검증하는 프레임별 오류 검증 모듈을 포함하는 것을 특징으로 하는 인공지능 기반 동영상 품질 분석 시스템."}
{"patent_id": "10-2022-0186209", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6항에 있어서, 상기 샷별 오류 검증 모듈은, 색상 공간 훼손에 대한 오류 검증시 프레임별로 구분된 샷별 그룹 데이터를 색상 공간 시스템의 색상별 채널을통해 각각 비교하여 비교 결과값을 생성하고, 생성한 비교 결과값으로부터 프레임별로 구분된 샷별 그룹 데이터에 대한 각 채널별 평균 색상 분포도를 산출한 후, 산출한 색상 분포도를 기준으로 프레임별로 구분된 샷별 그룹 데이터의 타겟 프레임 이전 프레임과 이후 프레임을 비교하여 색상 공간의 훼손에 대한 오류를 검증하는 것을 특징으로 하는 인공지능 기반 동영상 품질 분석 시스템."}
{"patent_id": "10-2022-0186209", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제6항에 있어서, 상기 샷별 오류 검증 모듈은, 샷별 그룹 데이터에서 프레임의 튐 현상에 대한 오류를 검증하는 경우, 딥러닝 기반 오류 검증 모델을 통해 프레임별로 구분된 샷별 그룹 데이터들을 시간순서대로 정렬하고, 정렬이 이루어진 프레임별로 구분된 샷별 그룹데이터들을 순회하면서 상기 프레임별로 구분된 샷별 그룹 데이터들에 대한 프레임 임계값을 설정하고, 설정한임계값을 기준으로 타겟 프레임, 타겟 프레임의 이전 프레임과 이후 프레임을 비교하여 각각의 임계값에 대한변화값을 산출하며, 타겟 프레임의 임계값이 이전 프레임, 또는 이후 프레임의 임계값과 일정 수치 이상 차이가나는 경우, 해당 타겟 프레임에 프레임의 튐 현상이 발생한 것으로 판단하는 것을 특징으로 하는 인공지능 기반공개특허 10-2024-0103754-4-동영상 품질 분석 시스템."}
{"patent_id": "10-2022-0186209", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8에 있어서, 상기 샷별 오류 검증 모듈은, 버벅임 현상이 존재하는지 여부에 대한 오류를 검증하는 경우, 상기 임계값에 대한 변화값이 타겟 프레임과 이전 프레임이 동일하거나, 상기 임계값의 값보다 작은 경우 해당 타겟 프레임은 영상 버벅임 현상이 발생하였다고 판단하는 것을 특징으로 하는 인공지능 기반 동영상 품질 분석 시스템."}
{"patent_id": "10-2022-0186209", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제6항에 있어서, 상기 프레임별 오류 검증 모듈은, 상기 레터 박스의 오류 존재 여부를 검증하는 경우, 프레임을 기준으로 그룹화된 이미지 데이터들 각각에 대하여 상, 하, 좌, 우 방향에서 발생한 레터 박스와 필러 박스에 대한 길이를 계산하고, 상기 이미지 데이터의 전체 프레임에 대한 레터 박스 및 필러 박스의 길이값과 비교하여 블랙바가 형성되었는지 여부를 확인하여 상기블랙바가 형성되어 있는 경우 레터 박스의 오류가 존재하는 것으로 판단하는 것을 특징으로 하는 인공지능 기반동영상 품질 분석 시스템."}
{"patent_id": "10-2022-0186209", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제6항에 있어서, 상기 프레임별 오류 검증 모듈은, 노이즈 훼손 여부에 대한 오류 존재 여부를 검증하는 경우, 딥러닝 모델을 활용하여 그룹화된 이미지 데이터들을 학습하고, 학습 결과를 분석하여 노이즈 포함 여부를 확인하는 것을 특징으로 하는 인공지능 기반 동영상 품질 분석 시스템."}
{"patent_id": "10-2022-0186209", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제6항에 있어서, 상기 프레임별 오류 검증 모듈은, 프레임의 픽셀 손상 및 누락 여부를 검증하는 경우, 딥러닝 모델을 활용하여 프레임을 기준으로 그룹화된 이미지 데이터들을 학습하고, 학습에 사용한 이미지 데이터들로부터 손상된 부분 픽셀 추출하여 패치정보를 생성한후, 생성된 패치 정보를 기반으로 손상 프레임의 데이터를 증강하여, 손상 프레임의 존재 유무를 탐지하는 것을특징으로 하는 인공지능 기반 동영상 품질 분석 시스템."}
{"patent_id": "10-2022-0186209", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제14항에 있어서, 상기 제어부는, 상기 동영상 정보 제공부로부터 수신받은 추출 프레임 간격 정보에 FPS 값이 존재하는지 여부를 확인하고, 상기FPS 값이 존재하는 경우, 상기 프레임 추출부를 통해 추출이 가능한 FPS 값인지 여부를 확인하고, 추출이 불가능한 FPS 값인 경우에는 상기 동영상 정보 제공부로 FPS 값의 조정 여부를 요청하는 것을 특징으로 하는 인공지공개특허 10-2024-0103754-5-능 기반 동영상 품질 분석 시스템."}
{"patent_id": "10-2022-0186209", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "동영상 제공부 및 동영상 품질 분석 서버를 포함하는 인공지능 기반 동영상 품질 분석 방법에 있어서, (a) 상기 동영상 정보 제공부에서 사용자 단말로부터 오류 검증을 수행하고자 하는 동영상 정보와 상기 동영상정보에 대한 추출 프레임 간격 정보를 수신받아 오류 검증 요청 신호를 생성 및 전송하는 단계; (b) 상기 동영상 품질 분석 서버에서 상기 오류 검증 요청 신호를 수신받으며, 수신받은 오류 검층 요청 신호를분석하여 동영상 정보와 추출 프레임 간격 정보를 분류하고, 분류한 정보들을 저장하는 단계; (c) 상기 동영상 품질 분석 서버에서 상기 추출 프레임 간격 정보를 기준으로 분류된 동영상 정보로부터 이미지데이터를 추출하는 단계; (d) 상기 동영상 품질 분석 서버에서 상기 이미지 데이터를 딥러닝 모델을 통해 그룹화하되, 프레임별 그룹 데이터 및 샷별 그룹 데이터를 생성하는 단계; (e) 상기 동영상 품질 분석 서버에서 생성된 상기 그룹 데이터들을 분석하여 해당 동영상 정보에 오류가 존재하는지 여부를 확인하여 오류 검증 정보를 생성하는 단계; (f) 상기 동영상 품질 분석 서버에서 상기 오류 검증 정보에 따라 상기 그룹 데이터들 중 샷 그룹 데이터에 대한 오류를 검증하는 단계; (g) 상기 동영상 품질 분석 서버에서 상기 오류 검증 정보에 따라 상기 그룹 데이터들 중 프레임 그룹 데이터에대한 오류를 검증하는 단계; 를 포함하는 것을 특징으로 하는 인공지능 기반 동영상 품질 분석 방법."}
{"patent_id": "10-2022-0186209", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제14항에 있어서, 상기 (c) 단계는, 상기 추출 프레임 간격 정보에 FPS 값이 존재하는지 여부를 확인하고, 상기 FPS 값이 존재하는 경우, 상기 FPS값이 이미지 데이터로 추출 가능한 FPS값인지 여부를 확인하고, 추출이 불가능한 FPS 값인 경우에는 상기 동영상 정보 제공부로 상기 FPS 값의 조정 여부를 요청하고, 조정이 이루어진 FPS 값을 재수신받아 이미지 데이터를추출하는 것을 특징으로 하는 인공지능 기반 동영상 품질 분석 방법."}
{"patent_id": "10-2022-0186209", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제14항에 있어서, 상기 (f) 단계는, 상기 샷별 그룹 데이터에서 색상 공간의 훼손 여부를 검증하는 단계;를 포함하는 것을 특징으로 하는 인공지능기반 동영상 품질 분석 방법."}
{"patent_id": "10-2022-0186209", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제14항에 있어서, 상기 (f) 단계는, 상기 샷별 그룹 데이터에서 프레임의 튐 현상 및 버벅임 현상 여부를 검증하는 단계;공개특허 10-2024-0103754-6-를 포함하는 것을 특징으로 하는 인공지능 기반 동영상 품질 분석 방법."}
{"patent_id": "10-2022-0186209", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제14항에 있어서, 상기 (g) 단계는, 상기 프레임별 그룹 데이터에서 레터 박스의 오류를 검증하는 단계;를 포함하는 것을 특징으로하는 인공지능 기반 동영상 품질 분석 방법."}
{"patent_id": "10-2022-0186209", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제14항에 있어서, 상기 (g) 단계는, 상기 프레임별 그룹 데이터에서 노이즈 훼손 여부에 대한 오류를 검증하는 단계;를 포함하는 것을 특징으로 하는 인공지능 기반 동영상 품질 분석 방법."}
{"patent_id": "10-2022-0186209", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제14항에 있어서, 상기 (g) 단계는, 상기 프레임별 그룹 데이터에서 프레임의 픽셀 손상 및 누락 여부에 대한 오류를 검증하는 단계;를 포함하는 것을 특징으로 하는 인공지능 기반 동영상 품질 분석 방법."}
{"patent_id": "10-2022-0186209", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 사용자 단말로부터 오류 검증을 수행해야 할 동영상 정보를 수신받아 저장하고, 저장한 동영상 정보에 대한 추출 프레임 간격 정보를 생성하며, 상기 추출 프레임 간격 정보를 포함하는 오류 검증 요청 신호를 생성하 여 전송하는 동영상 정보 제공부; 및 상기 동영상 정보 제공부로부터 상기 오류 검증 요청 신호를 수신받으며, 수신받은 상기 오류 검증 요청 신호에 포함되어 있는 동영상 정보에 대한 오류의 종류를 판별하고, 판별한 오류 의 종류에 따라 상기 동영상 정보의 오류를 검증하여 오류 검증 결과 정보를 생성하며, 생성한 상기 오류 검증 결과 정보를저장함과 동시에 상기 동영상 정보 제공부로 전송하는 동영상 품질 분석 서버;를 포함하는 인공지능 기반 동영상 품질 분석 시스템 및 이를 이용한 동영상 품질 분석 방법을 제공하는 것이다."}
{"patent_id": "10-2022-0186209", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 인공지능 기반 동영상 품질 분석 시스템 및 그 방법에 관한 것으로, 더욱 상세하게는 동영상 정보를 샷(shot) 별로 분리한 후, 분리한 샷 별 동영상 정보를 딥러닝 기반 오류 검증 모델로 색상 공간 훼손 여부, 프 레임의 튐 현상 여부 및 영상의 버벅임 현상 여부를 검증하여 긍정 오류(false positive)의 발생을 최소화할 수 있어 동영상 정보의 품질 분석 결과에 대한 신뢰성을 극대화시킬 수 있는 인공지능 기반 동영상 품질 분석 시스 템 및 그 방법에 관한 것이다."}
{"patent_id": "10-2022-0186209", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "일반적으로, 동영상 데이터를 효과적으로 관리하기 위해 동영상 데이터를 분할하여 구조화하기 위한 다양한 시 스템이나 방법들이 개발되고 있으며, 영화 등의 동영상에 대한 장면 분할을 위해 컬러 히스토그램 비교 방법, 화소 단위 비교 방법 등이 제시되고 있다. 그러나, 화소 단위 비교 방법은 동일한 장면 내에서는 화소값의 변화가 적다는 점에 착안하여, 연속하는 한 쌍 의 프레임에서 대응하는 화소값을 비교하여 얼마나 많은 변화가 발생하였는지 측정하는 방법으로, 이 방법은 구 현은 간단하나 카메라 움직임에 민감하여, 움직임이 많은 영상에 적용할 경우 장면을 정확히 분할할 수 없는 문 제점이 있었다. 또한, 컬러 히스토그램 비교 방법은 동일한 장면 내의 프레임들이 상호 유사한 색상 분포를 가진다는 특성을 이 용하여, 인접 프레임들의 히스토그램 차이를 임계값과 비교하여 장면을 분할하는 것으로서, 카메라의 이동에는 덜 민감하나, 빛의 영향에 민감한 문제점이 있다. 즉, 갑작스런 조명 변화가 있는 경우 동일한 장면을 다른장면으로 인식할 수 있고, 다른 장면임에도 불구하고 색상 분포가 유사하면 이를 검출하지 못하는 문제점이 있었다. 이와 같이, 현재는 동영상의 화소값이나 색상 분포 등 RGB값을 기초 정보로 이용하기 때문에, 카메라의 움직임 이나 시간/공간적 연속성을 정확히 판단할 수 없어 동영상을 효과적으로 구조화하기 어렵다. 이에 따라, 뜻하지 않은 위치에서 광고가 송출되는 문제가 발생할 수 있고, 이를 방지하기 위해 수작업을 통해 장면 분할의 오류를 수정하여야 하므로 작업이 번거롭고 시간이 증가하는 등의 문제점이 있었다. 이에, 대한민국 공개특허 제10-2011-0021014호에는, 분할 대상 동영상을 구성하는 프레임을 추출하는 프레임 추 출부; 상기 프레임 추출부에서 추출한 프레임의 이웃 프레임과의 에너지 차이에 따라 분할 예정 위치를 결정하 는 계수 필터링부; 상기 계수 필터링부에서 결정한 분할 예정 위치 전후 프레임 간의 연속성을 판단하는 움직임 분석부; 및 상기 움직임 분석부에서 판단한 연속성에 따라 상기 동영상의 장면 분할 위치를 결정하는 분할 위치 결정부;를 포함하는 동영상 장면 분할 시스템이 게재된 바 있다. 그러나, 전술한 선행기술문헌에 의하면, 단순히 동영상을 프레임별로 추출 및 분할한 후, 단순 비교가 이루어지 는 것에 불과한 것으로, 이와 같은 방법으로는 분석 결과에 대한 신뢰성이 현저하게 떨어질 수밖에 없고, 카메 라의 장면 전환이 많은 경우에는 추출된 프레임들이 같은 샷(shot)에 존재한다 하더라도 프레임별로 큰 차이를 발생시키게 되어 오히려 동영상의 품질이 저하되는 문제점이 있다 특히, 전술한 선행기술문헌의 경우, 추출 및 분할한 프레임들의 오류 여부를 검사하지 않기 때문에 분할된 동영 상의 품질을 안정적으로 유지 및 확보하기 어려운 문제점이 있었다."}
{"patent_id": "10-2022-0186209", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 2, "content": "여기서 전술한 배경기술 또는 종래기술은 본 발명의 기술적 의의를 이해하는데 도움이 되기 위한 것일 뿐, 본"}
{"patent_id": "10-2022-0186209", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 3, "content": "발명의 출원 전에 이 발명이 속하는 기술분야에서 널리 알려진 기술을 의미하는 것은 아니다. 선행기술문헌 특허문헌 (특허문헌 0001) 대한민국 공개특허 제10-2011-0021014호"}
{"patent_id": "10-2022-0186209", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명이 이루고자 하는 기술적 과제는 동영상 정보를 샷(shot) 별로 분리한 후, 분리한 샷 별 동영상 정보를 딥러닝 기반 오류 검증 모델로 색상 공간 훼손 여부, 프레임의 튐 현상 여부 및 영상의 버벅임 현상 여부를 검 증하여 긍정 오류(false positive)의 발생을 최소화할 수 있어 동영상 정보의 품질 분석 결과에 대한 신뢰성을 극대화시킬 수 있는 인공지능 기반 동영상 품질 분석 시스템 및 그 방법을 제공하는데 그 목적이 있다. 다만, 본 발명의 목적은 이에만 제한되는 것은 아니며, 명시적으로 언급하지 않더라도"}
{"patent_id": "10-2022-0186209", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "이나 실 시 형태로부터 파악될 수 있는 목적이나 효과도 이에 포함됨은 물론이다."}
{"patent_id": "10-2022-0186209", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 2, "content": "과제의 해결 수단 이러한 과제를 해결하기 위하여 본 발명에 따른 인공지능 기반 동영상 품질 분석 시스템은, 사용자 단말로부터 오류 검증을 수행해야 할 동영상 정보를 수신받아 저장하고, 저장한 동영상 정보에 대한 추출 프레임 간격 정보 를 생성하며, 상기 추출 프레임 간격 정보를 포함하는 오류 검증 요청 신호를 생성하여 전송하는 동영상 정보 제공부; 및 상기 동영상 정보 제공부로부터 상기 오류 검증 요청 신호를 수신받으며, 수신받은 상기 오류 검증 요청 신호에 포함되어 있는 동영상 정보에 대한 오류의 종류를 판별하고, 판별한 오류의 종류에 따라 상기 동영상 정보의 오류를 검증하여 오류 검증 결과 정보를 생성하며, 생성한 상기 오류 검증 결과 정보를저장함과 동시 에 상기 동영상 정보 제공부로 전송하는 동영상 품질 분석 서버;를 포함하는 것을 특징으로 한다. 일 실시예에 있어서, 상기 동영상 정보 제공부는, 상기 사용자 단말로 추출 프레임 간격 요청 신호를 송신하는 경우, FPS 값을 기준으로 하여 추출 프레임 간격 요청 신호를 생성하여 상기 동영상 품질 분석 서버로 전송하는 것을 특징으로 한다. 일 실시예에 있어서, 상기 동영상 정보 제공부는 사용자 단말로부터 수신받은 동영상 정보를 저장할 수 있으며, 저장한 동영상 정보를 카테고리 별로 분류하여 각각 개별적으로 저장할 수 있다. 일 실시예에 있어서, 상기 동영상 품질 분석 서버는, 상기 추출 프레임 간격 정보에 포함된 동영상 정보의 오류 검증을 위하여 이미지 데이터로 변환하여 전송하는 프레임 추출부; 상기 이미지 데이터를 프레임 및 샷별로 각 각 그룹화하여 그룹화한 프레임별 그룹 데이터 및 샷(shot)별 그룹 데이터를 생성하여 전송하는 그룹 데이터 생 성부; 그룹 데이터들(프레임별 그룹 데이터, 샷별 그룹 데이터)를 딥러닝 기반 오류 검증 모델을 통해 분석하여 각각의 그룹 데이터들에 대한 오류를 검증하는 오류 검증부; 상기 동영상 정보 제공부로부터 상기 오류 검증 요 청 신호를 수신받아 분석하여 동영상 정보와 추출 프레임 간격 정보를 분류하여 데이터베이스 및 상기 프레임 추출부로 전송하고, 상기 그룹 데이터 생성부로부터 생성이 완료된 그룹 데이터들을 수신받아 분석하여 해당 동 영상 정보에 오류가 존재하는지 여부를 확인하고, 오류가 존재하는 경우, 해당 오류가 프레임별 그룹 데이터, 또는 샷별 그룹 데이터 중 어느 하나, 또는 둘 모두에 존재하는지 여부를 판단하며, 상기 프레임 추출부 및 그 룹 데이터 생성부에서 생성한 데이터들을 수신받아 데이터베이스로 전송하는 제어부; 상기 프레임 추출부, 그룹 데이터 생성부에서 생성한 데이터들을 상기 제어부로부터 수신받아 저장하고, 상기 제어부의 제어에 따라 저장 한 그룹 데이터들을 상기 오류 검증부로 전송하는 데이터베이스;를 포함하는 것을 특징으로 한다. 일 실시예에 있어서, 상기 그룹 데이터 생성부는, 상기 샷별 그룹 데이터를 생성할 때, 상기 프레임 추출부에서 수신받은 동영상 정보를 제공받아 딥러닝 모델을 통해 샷별로 분리하여 샷별 그룹 데이터로 생성하는 것을 특징 으로 한다. 일 실시예에 있어서, 상기 오류 검증부는, 상기 샷별 그룹 데이터의 색상 공간이 훼손되었는지 여부, 프레임의 튐 현상 및 버벅임 현상이 존재하는지 여부에 대한 오류를 검증할 수 있도록 상기 샷별 그룹 데이터를 프레임별 로 구분한 후, 딥러닝 기반 오류 검증 모델을 활용하여 검증하는 샷별 오류 검증 모듈과, 상기 프레임별 그룹 데이터의 오류를 검증할 수 있도록 상기 프레임별 그룹 데이터를 프레임별로 구분한 후, 딥러닝 기반 오류 검증 모델을 활용하여 검증하는 프레임별 오류 검증 모듈을 포함하는 것을 특징으로 한다. 일 실시예에 있어서, 상기 샷별 오류 검증 모듈은, 색상 공간 훼손에 대한 오류 검증시 프레임별로 구분된 샷별 그룹 데이터를 색상 공간 시스템의 색상별 채널을 통해 각각 비교하여 비교 결과값을 생성하고, 생성한 비교 결 과값으로부터 프레임별로 구분된 샷별 그룹 데이터에 대한 각 채널별 평균 색상 분포도를 산출한 후, 산출한 색 상 분포도를 기준으로 프레임별로 구분된 샷별 그룹 데이터의 타겟 프레임 이전 프레임과 이후 프레임을 비교하 여 색상 공간의 훼손에 대한 오류를 검증하는 것을 특징으로 한다. 일 실시예에 있어서, 상기 샷별 오류 검증 모듈은, 샷별 그룹 데이터에서 프레임의 튐 현상에 대한 오류를 검증 하는 경우, 딥러닝 기반 오류 검증 모델을 통해 프레임별로 구분된 샷별 그룹 데이터들을 시간순서대로 정렬하 고, 정렬이 이루어진 프레임별로 구분된 샷별 그룹 데이터들을 순회하면서 상기 프레임별로 구분된 샷별 그룹 데이터들에 대한 프레임 임계값을 설정하고, 설정한 임계값을 기준으로 타겟 프레임, 타겟 프레임의 이전 프레 임과 이후 프레임을 비교하여 각각의 임계값에 대한 변화값을 산출하며, 타겟 프레임의 임계값이 이전 프레임, 또는 이후 프레임의 임계값과 일정 수치 이상 차이가 나는 경우, 해당 타겟 프레임에 프레임의 튐 현상이 발생 한 것으로 판단하는 것을 특징으로 한다. 일 실시예에 있어서, 상기 샷별 오류 검증 모듈은, 버벅임 현상이 존재하는지 여부에 대한 오류를 검증하는 경 우, 상기 임계값에 대한 변화값이 타겟 프레임과 이전 프레임이 동일하거나, 상기 임계값의 값보다 작은 경우 해당 타겟 프레임은 영상 버벅임 현상이 발생하였다고 판단하는 것을 특징으로 한다. 일 실시예에 있어서, 상기 프레임별 오류 검증 모듈은, 상기 레터 박스의 오류 존재 여부를 검증하는 경우, 프 레임을 기준으로 그룹화된 이미지 데이터들 각각에 대하여 상, 하, 좌, 우 방향에서 발생한 레터 박스와 필러 박스에 대한 길이를 계산하고, 상기 이미지 데이터의 전체 프레임에 대한 레터 박스 및 필러 박스의 길이값과 비교하여 블랙바가 형성되었는지 여부를 확인하여 상기 블랙바가 형성되어 있는 경우 레터 박스의 오류가 존재 하는 것으로 판단하는 것을 특징으로 한다.일 실시예에 있어서, 상기 프레임별 오류 검증 모듈은, 노이즈 훼손 여부에 대한 오류 존재 여부를 검증하는 경 우, 딥러닝 모델을 활용하여 그룹화된 이미지 데이터들을 학습하고, 학습 결과를 분석하여 노이즈 포함 여부를 확인하는 것을 특징으로 한다. 일 실시예에 있어서, 상기 프레임별 오류 검증 모듈은, 프레임의 픽셀 손상 및 누락 여부를 검증하는 경우, 딥 러닝 모델을 활용하여 프레임을 기준으로 그룹화된 이미지 데이터들을 학습하고, 학습에 사용한 이미지 데이터 들로부터 손상된 부분 픽셀 추출하여 패치정보를 생성한 후, 생성된 패치 정보를 기반으로 손상 프레임의 데이 터를 증강하여, 손상 프레임의 존재 유무를 탐지하는 것을 특징으로 한다. 일 실시예에 있어서, 상기 제어부는, 상기 동영상 정보 제공부로부터 수신받은 추출 프레임 간격 정보에 FPS 값 이 존재하는지 여부를 확인하고, 상기 FPS 값이 존재하는 경우, 상기 프레임 추출부를 통해 추출이 가능한 FPS 값인지 여부를 확인하고, 추출이 불가능한 FPS 값인 경우에는 상기 동영상 정보 제공부로 FPS 값의 조정 여부를 요청하는 것을 특징으로 한다. 본 발명의 다른 일 실시예에 있어서, 동영상 제공부 및 동영상 품질 분석 서버를 포함하는 인공지능 기반 동영 상 품질 분석 방법은, (a) 상기 동영상 정보 제공부에서 사용자 단말로부터 오류 검증을 수행하고자 하는 동영 상 정보와 상기 동영상 정보에 대한 추출 프레임 간격 정보를 수신받아 오류 검증 요청 신호를 생성 및 전송하 는 단계; (b) 상기 동영상 품질 분석 서버에서 상기 오류 검증 요청 신호를 수신받으며, 수신받은 오류 검층 요 청 신호를 분석하여 동영상 정보와 추출 프레임 간격 정보를 분류하고, 분류한 정보들을 저장하는 단계; (c) 상 기 동영상 품질 분석 서버에서 상기 추출 프레임 간격 정보를 기준으로 분류된 동영상 정보로부터 이미지 데이 터를 추출하는 단계; (d) 상기 동영상 품질 분석 서버에서 상기 이미지 데이터를 딥러닝 모델을 통해 그룹화하 되, 프레임별 그룹 데이터 및 샷별 그룹 데이터를 생성하는 단계; (e) 상기 동영상 품질 분석 서버에서 생성된 상기 그룹 데이터들을 분석하여 해당 동영상 정보에 오류가 존재하는지 여부를 확인하여 오류 검증 정보를 생성 하는 단계; (f) 상기 동영상 품질 분석 서버에서 상기 오류 검증 정보에 따라 상기 그룹 데이터들 중 샷 그룹 데이터에 대한 오류를 검증하는 단계; (g) 상기 동영상 품질 분석 서버에서 상기 오류 검증 정보에 따라 상기 그룹 데이터들 중 프레임 그룹 데이터에 대한 오류를 검증하는 단계; 를 포함하는 것을 특징으로 한다. 본 발명의 다른 일 실시예에 있어서, 상기 (c) 단계는, 상기 추출 프레임 간격 정보에 FPS 값이 존재하는지 여 부를 확인하고, 상기 FPS 값이 존재하는 경우, 상기 FPS 값이 이미지 데이터로 추출 가능한 FPS값인지 여부를 확인하고, 추출이 불가능한 FPS 값인 경우에는 상기 동영상 정보 제공부로 상기 FPS 값의 조정 여부를 요청하고, 조정이 이루어진 FPS 값을 재수신받아 이미지 데이터를 추출하는 것을 특징으로 한다. 본 발명의 다른 일 실시예에 있어서, 상기 (f) 단계는, 상기 샷별 그룹 데이터에서 색상 공간의 훼손 여부를 검 증하는 단계;를 포함하는 것을 특징으로 한다. 본 발명의 다른 일 실시예에 있어서, 상기 (f) 단계는, 상기 샷별 그룹 데이터에서 프레임의 튐 현상 및 버벅임 현상 여부를 검증하는 단계;를 포함하는 것을 특징으로 한다. 본 발명의 다른 일 실시예에 있어서, 상기 (g) 단계는, 상기 프레임별 그룹 데이터에서 레터 박스의 오류를 검 증하는 단계;를 포함하는 것을 특징으로 한다. 본 발명의 다른 일 실시예에 있어서, 상기 (g) 단계는, 상기 프레임별 그룹 데이터에서 노이즈 훼손 여부에 대 한 오류를 검증하는 단계;를 포함하는 것을 특징으로 한다. 본 발명의 다른 일 실시예에 있어서, 상기 (g) 단계는, 상기 프레임별 그룹 데이터에서 프레임의 픽셀 손상 및 누락 여부에 대한 오류를 검증하는 단계;를 포함하는 것을 특징으로 한다. 위에서 언급된 본 발명의 기술적 과제 외에도, 본 발명의 다른 특징 및 이점들이 이하에서 기술되거나, 그러한"}
{"patent_id": "10-2022-0186209", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 3, "content": "기술 및 설명으로부터 본 발명이 속하는 기술분야에서 통상의 지식을 가진 자에게 명확하게 이해될 수 있을 것 이다."}
{"patent_id": "10-2022-0186209", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "이상과 같은 본 발명에 따르면 다음과 같은 효과가 있다. 본 발명에 따른 인공지능 기반 동영상 품질 분석 시스템 및 그 방법은 동영상 정보를 샷(shot) 별로 분리한 후, 분리한 샷 별 동영상 정보를 딥러닝 기반 오류 검증 모델로 색상 공간 훼손 여부, 프레임의 튐 현상 여부 및 영 상의 버벅임 현상 여부를 검증하여 긍정 오류(false positive)의 발생을 최소화할 수 있어 동영상 정보의 품질 분석 결과에 대한 신뢰성을 극대화시킬 수 있는 효과가 있다. 더불어, 본 발명의 다양하면서도 유익한 장점과 효과는 상술한 내용에 한정되지 않으며, 본 발명의 구체적인 실 시 형태를 설명하는 과정에서 보다 쉽게 이해될 수 있을 것이다."}
{"patent_id": "10-2022-0186209", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 본 발명의 바람직한 실시예를 첨부된 도면들을 참조하여 상세히 설명한다. 우선 각 도면의 구성요소들에 참조 부호를 부가함에 있어서, 동일한 구성요소들에 대해서는 비록 다른 도면상에 표시되더라도 가능한 동일한 부호를 가지도록 하고 있음에 유의해야 한다. 또한, 본 발명을 설명함에 있어, 관련된 공지 구성 또는 기능에 대한 구체적인 설명이 본 발명의 요지를 흐릴 수 있다고 판단되는 경우에는 그 상세한 설명은 생략한다. 또한, 이하에서 기재된 \"포함하다\", \"구성하다\" 또는 \"가지다\" 등의 용어는, 특별히 반대되는 기재가 없는 한, 해당 구성 요소가 내재될 수 있음을 의미하는 것이므로, 다른 구성 요소를 제외하는 것이 아니라 다른 구성 요 소를 더 포함할 수 있는 것으로 해석되어야 하며, 기술적이거나 과학적인 용어를 포함한 모든 용어들은, 다르게 정의되지 않는 한, 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자에 의해 일반적으로 이해되는 것과 동일한 의미를 가진다. 또한, 본 발명의 구성 요소를 설명하는 데 있어서, 제 1, 제 2, A, B, (a), (b) 등의 식별부호를 사용할 수 있 다. 이러한 식별부호는 그 구성 요소를 다른 구성 요소와 구별하기 위한 것이고, 설명의 편의를 위하여 사용되 는 것일 뿐, 그 식별부호에 의해 해당 구성 요소의 본질이나 차례 또는 순서 등이 한정되지 않는다. 어떤 구성 요소가 다른 구성요소에 \"연결\", \"결합\" 또는 \"접속\" 된다고 기재된 경우, 그 구성 요소는 그 다른 구성요소에 직접적으로 연결되거나 또는 접속될 수 있지만, 각 구성 요소 사이에 또 다른 구성 요소가 \"연결\", \"결합\" 또는 \"접속\"될 수도 있다고 이해되어야 할 것이다. 또한, 본 발명에 있어서 단말, 장치 또는 디바이스가 수행하는 것으로 기술된 동작이나 기능 중 일부는 해당 단 말, 장치 또는 디바이스와 연결된 서버에서 대신 수행될 수 있다. 마찬가지로, 서버가 수행하는 것으로 기술된 동작이나 기능 중 일부도 해당 서버와 연결된 단말, 장치 또는 디바이스에서 수행될 수도 있다.또한, 본 발명의 각 실시예에 기재된 각각의 서버는, 단말, 장치 또는 디바이스와 네트워크를 통해 통신하여 명 령, 코드, 파일, 콘텐츠, 서비스 등을 제공하는 컴퓨터 장치 또는 복수의 컴퓨터 장치들로 구현되는 시스템일 수 있으며, 메모리, 프로세서, 통신 인터페이스, 입출력 인터페이스 및 데이터베이스를 포함할 수 있다. 특히, 본 발명의 각 실시예에 따른 시스템을 실행시키기 위한 수단으로는 어플리케이션(Application), 또는 웹 서버일 수 있으며, 이 어플리케이션, 또는 웹 서버를 기록한 기록매체를 읽을 수 있는 수단인 단말로는, 일반적 인 데스크 탑이나 노트북 등의 일반 PC 뿐만 아니라, 스마트 폰, 태블릿 PC, 등의 모바일 단말기를 포함할 수 있다. 이하, 첨부된 도면을 참고하여 본 발명의 실시예들을 상세히 설명하도록 한다. 도시된 바와 같이, 본 발명의 인공지능 기반 동영상 품질 분석 시스템은 오류 검증을 수행해야 할 동영상 정보 가 저장되며, 저장된 동영상 정보를 전송하는 동영상 정보 제공부와, 동영상 정보 제공부와 네트워크 로 연결되며, 동영상 정보를 수신받아 오류 검증을 수행하여 동영상 정보의 품질을 분석하는 동영상 품질 분석 서버를 포함하여 구성된다. 동영상 정보 제공부는 사용자 단말과 네트워크로 연결될 수 있으며, 이 사용자 단말에서 생성한 동영상 정 보를 수신받아 저장한다. 여기서, 사용자 단말에서 생성한 동영상 정보는, 영화, 뮤직 비디오 등의 영상 정보일 수 있으나, 이에 한정하 는 것은 아니고, 개인이 직접 촬영한 동영상 정보일 수도 있다. 동영상 정보 제공부는 사용자 단말로부터 동영상 정보를 수신받는 경우, 이 동영상 정보의 오류 검증을 위 해 프레임의 추출시 추출 프레임의 간격에 대한 정보를 상기 사용자 단말로 요청할 수 있다. 이때, 동영상 정보 제공부는 사용자 단말로 추출 프레임 간격 요청 신호를 송신하는 경우, FPS 값을 기준 으로 하여 추출 프레임 간격 요청 신호를 생성하여 전송할 수 있다. 한편, 사용자 단말은 동영상 정보 제공부로부터 추출 프레임 간격 요청 신호를 수신받아 표시하여, 사용자 가 원하는 추출 프레임 간격에 대한 정보의 입력이 이루어질 수 있도록 구성된다. 또한, 동영상 정보 제공부는 사용자 단말로부터 추출 프레임 간격 정보가 수신되는 경우, 후술할 동영상 품질 분석 서버의 제어부로 추출 프레임 간격 정보를 전송할 수 있다. 이때, 동영상 정보 제공부는 해당 동영상 정보에 대한 오류 검증 요청 신호를 생성하여 제어부로 전 송할 수 있으며, 상기 오류 검증 요청 신호의 생성시 추출 프레임 간격 정보를 포함하여 생성할 수 있다. 아울러, 동영상 정보 제공부는 사용자 단말로부터 수신받은 동영상 정보를 저장할 수 있으며, 저장한 동영 상 정보를 카테고리 별로 분류하여 각각 개별적으로 저장할 수 있다. 동영상 품질 분석 서버는 동영상 정보 제공부로부터 오류 검증 요청 신호가 수신되는 경우, 해당 오 류 검증 요청 신호에 포함되어 있는 동영상 정보에 대한 오류의 종류를 판별하고, 판별한 오류의 종류에 따라 동영상 정보의 오류를 검증하며, 검증이 이루어진 동영상 정보를 저장함과 동시에 동영상 정보 제공부로 전송하는 것으로, 프레임 추출부, 그룹 데이터 생성부, 오류 검증부, 제어부 및 데이터베 이스를 포함하여 구성된다. 프레임 추출부는 제어부로부터 추출 프레임 간격 정보를 수신받으며, 이 추출 프레임 간격 정보에 포 함된 동영상 정보의 오류 검증을 위하여 이미지 데이터로 변환하는 역할을 한다. 일 예로, 추출 프레임 간격 정보에 있어서 사용자가 사용자 단말을 통해 요청한 추출 프레임 간격이 10 FPS인 경우, 동영상 정보의 프레임 간격을 1초마다 10장씩 추출하며, 해당 동영상 정보가 1분짜리 동영상 정보인 경우 총 600장의 이미지 데이터로 추출하는 것이다. 이러한 프레임 추출부는 추출된 동영상 정보의 이미지 데이터를 그룹 데이터 생성부로 전송하여 해당 동영상 정보의 이미지 데이터들의 그룹화가 이루어지도록 구성된다. 그룹 데이터 생성부는 프레임 추출부로부터 수신받은 동영상 정보의 이미지 데이터를 프레임 별로 그 룹화하여 그룹화한 프레임별 그룹 데이터를 생성하고, 또한 상기 이미지 데이터를 동영상 정보의 샷(shot)별로 그룹화하여 그룹화한 샷별 그룹 데이터를 생성하여 제어부로 전송하여 데이터베이스에 저장이 이루어 지도록 구성될 수 있다. 이때, 그룹 데이터 생성부는 이미지 데이터를 기반으로 샷별 그룹 데이터를 생성하는 것으로 설명하였으나, 이에 한정하는 것은 아니며, 샷별 그룹 데이터를 생성할 때, 프레임 추출부에서 수신받은 동영상 정보를 제공받을 수 있으며, 이 동영상 정보를 딥러닝 모델을 통해 샷별로 분리하여 샷별 그룹 데이터로 생성이 이루어지도록 구성될 수도 있다. 아울러, 그룹 데이터 생성부는 생성된 그룹 데이터들을 데이터베이스로 전송하여 저장이 이루어지도 록 구성될 수 있다. 여기서, 그룹 데이터 생성부는 동영상 정보의 분리를 위해 활용되는 딥러닝 모델의 경우, TransNetV2 모델 을 활용할 수 있으나, 이에 한정하는 것은 아니다. 한편, 본 발명에서 언급되는 샷(shot)은 카메라가 원 테이크로 한번에 돌아가는 한 장면을 의미하는 것으로, 카 메라가 전환되기 전까지 이어지는 시간적 묶음에 대한 영상정보를 의미하는 것으로, 그룹 데이터 생성부는 동영상 정보를 딥러닝 모델을 통해 분석하여 진행되는 장면이 전환되는 시점을 파악하고, 파악이 이루어진 장면 전환 시점에 대한 분리 기준점을 생성하여 상기 분리 기준점을 기반으로 동영상 정보를 분할하여 샷별 그룹 데 이터를 생성할 수 있을 것이다. 오류 검증부은 제어부의 제어에 따라 데이터베이스에 저장된 그룹 데이터들(프레임별 그룹 데이 터, 샷별 그룹 데이터)를 제공받으며, 제공받은 그룹 데이터들을 딥러닝 기반 오류 검증 모델을 통해 분석하여 각각의 그룹 데이터들에 대한 오류를 검증하는 구성요소로서, 샷 오류 검증 모듈과, 프레임 오류 검증 모 듈로 구성된다. 이러한 오류 검증부는 제어부로부터 오류 정보를 수신받아 이 오류 정보에 대응하여 그룹 데이터들의 오류를 검증할 수 있으며, 상기 오류 정보에 샷 오류 정보가 포함되어 있는 경우, 샷 오류 검증 모듈로 샷 별 그룹 데이터를 전송하여 오류의 검증이 이루어지도록 구성되며, 오류 검증 결과에 대한 정보를 생성하여 제 어부로 전송한다. 샷별 오류 검증 모듈은 샷별 그룹 데이터에서 색상 공간이 훼손되었는지 여부, 프레임의 튐 현상 및 버벅 임 현상이 존재하는지 여부를 검증하는 것으로, 샷을 기준으로 그룹화된 이미지 데이터들을 프레임별로 구분한 후, 딥러닝 기반 오류 검증 모델을 활용하여 검증이 이루어지도록 구성된다. 이러한 샷별 오류 검증 모듈은 색상 공간 훼손에 대한 오류 검증시 프레임별로 구분된 샷별 그룹 데이터를 색상 공간 시스템(RGB, CMYK, L* a* b* 등)에 대입하고, 대입이 이루어진 샷별 그룹 데이터의 색상 값이 훼손 되었는지 확인한다. 즉, 샷별 오류 검증 모듈은 프레임별로 구분된 샷별 그룹 데이터를 색상 공간 시스템의 색상별 채널(RGB,, RGBA, CMYK, L* a* b* 채널)을 통해 각각 비교하여 비교 결과값을 생성하고, 생성한 비교 결과값으로부터 프레 임별로 구분된 샷별 그룹 데이터에 대한 각 채널별 평균 색상 분포도를 산출한다. 이후, 도 4에 도시된 바와 같이, 산출한 색상 분포도를 기준으로 프레임별로 구분된 샷별 그룹 데이터의 타겟 프레임 이전 프레임과 이후 프레임을 비교해서 평균 색상 분포도와 다르다고 판단되면, 해당 타겟 프레임은 색 상 공간의 훼손에 대한 오류가 있다고 판단하고, 이에 대한 오류 검증 결과 정보를 생성하여 제어부로 전 송하는 것이다. 여기서, 타겟 프레임은, 프레임별로 구분된 샷별 그룹 데이터들 중에서 색상 공간 훼손에 대한 오류를 판단하고 자 하는 이미지 데이터일 수 있다. 또한, 색상 공간은, 색상 정보를 x, y, z의 공간으로 구분한 나타낸 것이며, RGB, 또는 RGBA는 색상을 빨강, 초 록, 파랑으로 표기한 것이며, CMYK는 시안, 마젠타 등으로 표기한 것이고, L* a* b* 는 CIELAB에서 제시한 색상 공간 시스템이다.또한, 샷별 오류 검증 모듈은 샷별 그룹 데이터에서 프레임의 튐 현상 및 버벅임 현상이 존재하는지 여부 에 대한 오류를 검증하는 경우, 도 5에 도시된 바와 같이, 딥러닝 기반 오류 검증 모델을 통해 프레임별로 구분 된 샷별 그룹 데이터들을 시간순서대로 정렬하고, 정렬이 이루어진 프레임별로 구분된 샷별 그룹 데이터들을 순 회하면서 상기 프레임별로 구분된 샷별 그룹 데이터들에 대한 프레임 임계값을 설정하고, 설정한 임계값을 기준 으로 타겟 프레임, 타겟 프레임의 이전 프레임과 이후 프레임을 비교하여 각각의 임계값에 대한 변화값을 산출 한다. 이때, 타겟 프레임의 임계값이 이전 프레임, 또는 이후 프레임의 임계값과 일정 수치 이상 차이가 나는 경우, 해당 타겟 프레임에 프레임의 튐 현상이 발생한 것으로 판단하고, 이에 대한 오류 검증 결과 정보를 생성하여 제어부로 전송한다. 또한, 이전 프레임, 또는 이후 프레임의 임계값이 프레임 임계값과 일정 수치 이상 차이가 나는 경우, 해당 이 전 프레임, 또는 이후 프레임 역시 프레임 튐 현상이 발생한 것으로 판단한다. 일 예로, 1회 당 현재 타겟 프레임을 포함한 이전 프레임 및 이후 프레임을 총 5개의 프레임으로 설정하여 타겟 프레임을 중심으로 2개의 이전 프레임과 2개의 이후 프레임에 대한 임계값과 미리 설정된 프레임 임계값을 비교 하여 각각의 프레임들에 대한 프레임 튐 현상을 동시에 판단하게 되는 것이다. 즉, 본 발명의 샷별 오류 검증 모듈은 프레임 튐 현상에 대한 오류 검증시 하나의 프레임별로 구분된 샷별 그룹 데이터, 또는 둘 이상의 프레임별로 구분된 샷별 그룹 데이터에 대한 검증이 이루어지도록 구성되는 것이다. 이때, 프레임 튐 현상은 영상 중에 무관한 프레임이 섞여 들어가는 경우, 또는 영상을 encoding, export하는 렌 더링 과정에서 발생하는 현상을 의미한다. 또한, 샷별 오류 검증 모듈은 샷별 그룹 데이터에서 영상 버벅임 현상(또는 영상 버퍼링 현상)에 대한 오 류를 검증하는 경우, 딥러닝 기반 오류 검증 모델을 통해 프레임별로 구분된 샷별 그룹 데이터들을 시간순서대 로 정렬하고, 정렬이 이루어진 프레임별로 구분된 샷별 그룹 데이터들을 순회하면서 상기 프레임별로 구분된 샷 별 그룹 데이터들에 대한 프레임 임계값을 설정하고, 설정한 임계값을 기준으로 타겟 프레임, 타겟 프레임의 이 전 프레임을 비교하여 각각의 임계값에 대한 변화값을 산출한다. 이때, 임계값에 대한 변화값이 타겟 프레임과 이전 프레임이 동일하거나, 상기 임계값의 값보다 작은 경우 해당 타겟 프레임은 영상 버벅임 현상이 발생하였다고 판단하고, 이에 대한 오류 검증 결과 정보를 생성하여 제어부 로 전송한다. 오류라고 판단한다. 한편, 오류 검증부는 제어부로부터 오류 정보를 수신받아 이 오류 정보에 대응하여 그룹 데이터들의 오류를 검증할 수 있으며, 상기 오류 정보에 프레임 오류 정보가 포함되어 있는 경우, 프레임 오류 검증 모듈 로 프레임별 그룹 데이터를 전송하여 오류의 검증이 이루어지도록 구성되며, 오류 검증 결과에 대한 정보 를 생성하여 제어부로 전송한다. 여기서, 프레임 별 오류 검증 모듈은 프레임을 기준으로 그룹화된 이미지 데이터들을 딥러닝 기반 오류 검 증 모델을 활용하여 검증이 이루어지도록 구성된다. 이러한 프레임 별 오류 검증 모듈은 동영상 정보의 레터 박스의 오류 존재 여부를 검증하는 경우, 프레임 을 기준으로 그룹화된 이미지 데이터들 각각에 대하여 이미지 데이터의 상, 하, 좌, 우 방향에서 발생한 레터 박스와 필러 박스에 대한 길이를 계산하고, 이후 오류 검증이 이루어지는 이미지 데이터의 전체 프레임에 대한 레터 박스 및 필러 박스의 길이를 계산한 후, 이미지 데이터의 레터 박스 및 필러 박스와 상기 이미지 데이터 전체 프레임에 대한 길이값을 비교하여 기준 길이값과 차이가 나는 위치를 파악하고, 파악한 위치에 블랙바가 형성되었는지 여부를 확인하여 상기 블랙바가 형성되어 있는 경우 레터 박스의 오류가 존재하는 것으로 판단하 고, 이에 대한 오류 검증 결과 정보를 생성하여 제어부로 전송한다. 여기서, 레터 박스의 오류라 함은, 도 7에 도시된 바와 같이, 우측 부분에 공간이 비어있는 이미지 데이터를 의 미하는 것으로, 통상적으로 동영상 정보에 있어서 화면비를 맞추기 위해 동영상 정보의 상,하, 좌, 우 방향에 블랙바를 구성하게 되는데, 이 블랙바가 1px라도 어긋나면 안됨에도 불구하고, 각각의 방향들에 대해 차이가 발생할 수 있으며, 이때 발생하는 차이를 레터 박스(동영상 정보의 상, 하 방향), 또는 필러 박스(동영상 정보의 좌, 우 방향)의 오류라고 한다. 또한, 프레임 별 오류 검증 모듈은 동영상 정보의 노이즈 훼손 여부에 대한 오류 존재 여부를 검증하는 경 우, No-Reference Image Quality Assessment 계열의 딥러닝 모델을 활용하여 프레임을 기준으로 그룹화된 이미 지 데이터들 각각에 대하여 이미지 데이터를 학습하고, 학습 결과를 분석하여 노이즈 포함 여부를 확인하며, 이 에 대한 오류 검증 결과 정보를 생성하여 제어부로 전송한다. 또한, 프레임 별 오류 검증 모듈은 동영상 정보의 프레임의 픽셀 손상 및 누락 여부를 검증하는 경우, Yolov5 과 같은 object detection 모델과 같은 딥러닝 모델을 활용하여 픽셀이 손상된 이미지 데이터들을 학습 하고, 학습에 사용한 이미지 데이터들로부터 손상된 부분 픽셀 추출하여 패치정보를 생성한 후, 생성된 패치 정 보를 기반으로 손상 프레임의 데이터를 증강하여, 손상 프레임의 존재 유무를 탐지함으로써, 픽셀 손상 및 누락 여부를 검증하고, 이에 대한 오류 검증 결과 정보를 생성하여 제어부로 전송한다. 즉, 도 8에 도시된 바와 같이, 노란박스에 포함된 일부 픽셀에 손상이 있는 경우들을 추출하여 패치 정보를 생 성하고, 생성한 패치 정보와 유사한 패치 정보를 생성한 후, 딥러닝 모델에 의한 학습을 통해 데이터 증강이 이 루어지도록 한다. 이후 object detection 모델이 패치 정보들을 탐지하도록 학습하고, 인퍼런스 단계에서 딥러 닝 모델에 입력된 프레임을 기준으로 그룹화된 이미지 데이터에 대해 손상 프레임을 탐지하는 것이다. 제어부는 동영상 품질 분석 서버의 구동을 제어하며, 동영상 정보 제공부와 네트워크로 연결되 어 동영상 정보 및 추출 프레임 간격 정보를 포함하는 오류 검증 요청 신호를 수신받으며, 수신받은 오류 검증 요청 신호를 분석하여 동영상 정보와 추출 프레임 간격 정보를 분류하고, 분류한 동영상 정보와 추출 프레임 간 격 정보를 데이터베이스로 전송하여 저장이 이루어지도록 함과 동시에 프레임 추출부로 전송하여 해 당 동영상 정보로부터 이미지 데이터의 추출이 이루어지도록 구성된다. 이때, 제어부는 동영상 정보 제공부로부터 수신받은 추출 프레임 간격 정보에 FPS 값이 존재하는지 여부를 확인하고, 상기 FPS 값이 존재하는 경우, 프레임 추출부를 통해 추출이 가능한 FPS 값인지 여부를 확인하고, 추출이 불가능한 FPS 값인 경우에는 동영상 정보 제공부로 FPS 값의 조정 여부를 요청하고, 조 정이 이루어진 FPS 값을 재수신받아 프레임 추출부로 전송할 수 있다. 여기서, 동영상 정보 제공부는 제어부로부터 FPS 값의 조정 요청 신호가 수신되는 경우, 사용자 단말 로 전송하여 재조정이 이루어지도록 할 수 있으나, 이에 한정하는 것은 아니며, 자동으로 FPS 값을 조정하여 제 어부로 송신한 후, 사용자 단말로 조정이 이루어진 FPS 값을 전송하도록 구성될 수도 있다. 또한, 제어부는 그룹 데이터 생성부로부터 생성이 완료된 그룹 데이터들(프레임별 그룹 데이터, 샷별 그룹 데이터)를 수신받으며, 수신받은 그룹 데이터들을 데이터베이스로 전송하여 저장이 이루어지도록 함 과 동시에 상기 그룹 데이터를 분석하여 해당 동영상 정보에 오류가 존재하는지 여부를 확인하고, 오류가 존재 하는 경우, 해당 오류가 프레임별 그룹 데이터, 또는 샷별 그룹 데이터 중 어느 하나, 또는 둘 모두에 존재하는 지 여부를 판단한다. 또한 제어부는 판단한 결과에 대응하는 오류 검증 정보를 생성하여 오류 검증부로 전송하여 해당 동 영상 정보의 오류 검증이 이루어지도록 한다. 이때, 오류 검증 정보는, 프레임별 그룹 데이터의 오류에 대한 프레임 오류 정보와, 샷별 그룹 데이터의 오류에 대한 샷 오류 정보로 이루어질 수 있다. 이러한 제어부는 상기 동영상 정보에 존재하는 오류의 존재 확인시 동영상 정보의 색상 공간이 훼손되었는 지 여부, 프레임의 튐 현상 및 버벅임 현상이 존재하는지 여부를 확인하고, 상기 각각의 오류들 중 어느 하나, 또는 둘 이상이 존재하는 경우에는 샷 오류 정보를 생성하여 오류 검증부로 전송한다. 또한, 제어부는 상기 동영상 정보에 존재하는 오류의 존재 확인시 동영상 정보의 레터 박스의 오류 존재 여부, 노이즈의 훼손 여부, 프레임의 픽셀 손상 및 누락 여부 등을 확인하고, 상기 각각의 오류들 중 어느 하나, 또는 둘 이상이 존재하는 경우에는 프레임 오류 정보를 생성하여 오류 검증부로 전송한다. 데이터베이스는 오류 검증이 이루어질 동영상 정보의 프레임별 그룹 데이터와 샷별 그룹 데이터가 저장되 며, 오류 검증이 완료된 각각의 그룹 데이터들이 저장된다. 또한, 데이터베이스는 오류 검증이 완료된 동영상 정보가 저장되고, 제어부를 통해 동영상 정보 제공 부로 상기 오류 검증이 완료된 동영상 정보의 전송이 이루어지도록 구성될 수 있다. 이하에서는, 본 발명의 인공지능 기반 동영상 품질 분석 시스템을 이용한 동영상 품질 분석 방법에 대하여 도 9 를 참조하여 설명하도록 한다. 도시된 바와 같이, 본 발명의 동영상 품질 분석 방법은 동영상 정보 제공부에서 사용자 단말로부터 오류 검증을 수행하고자 하는 동영상 정보를 수신받아 저장하는 동영상 정보를 제공받는 단계(S310)를 수행한다. 이때, 상기 S310 단계는, 동영상 정보 제공부에서 사용자 단말로부터 동영상 정보를 수신받는 경우, 이 동 영상 정보의 오류 검증을 위해 프레임의 추출시 추출 프레임의 간격에 대한 정보를 요청하여, 상기 추출 프레임 간격 정보를 제공받는 단계를 더 수행한다. 또한, 상기 S310 단계는, 상기 동영상 정보에 대한 오류 검증 요청 신호를 생성하여 동영상 품질 분석 서버 로 전송하는 단계를 더 수행한다. 또한, 상기 S310 단계는, 상기 동영상 정보를 카테고리 별로 분류하여 각각 개별적으로 저장하는 단계를 더 수 행할 수 있다. 이후, 상기 동영상 정보 제공부에서 상기 동영상 품질 분석 서버로 상기 동영상 정보, 추출 프레임 간격 정보를 포함하는 오류 검증 요청 신호를 수신받아 분석하여 동영상 정보와 추출 프레임 간격 정보를 분류 하고, 분류한 정보들을 저장하는 단계를 수행한다.(S320) 이때, 상기 S320 단계는, 추출 프레임 간격 정보를 기준으로 분류된 동영상 정보로부터 이미지 데이터를 추출할 수 있다. 한편, 상기 S320 단계는, 상기 동영상 정보 제공부로부터 수신받은 추출 프레임 간격 정보에 FPS 값이 존 재하는지 여부를 확인하고, 상기 FPS 값이 존재하는 경우, 상기 FPS 값이 이미지 데이터로 추출 가능한 FPS값인 지 여부를 확인하고, 추출이 불가능한 FPS 값인 경우에는 동영상 정보 제공부로 FPS 값의 조정 여부를 요 청하고, 조정이 이루어진 FPS 값을 재수신받아 이미지 데이터를 추출할 수 있을 것이다. 다음으로, 동영상 품질 분석 서버에서는 추출된 이미지 데이터를 딥러닝 모델을 통해 그룹화하되, 프레임 별 그룹 데이터 및 샷별 그룹 데이터를 생성하는 단계를 수행한다.(S330) 상기 S330 단계는, 샷별 그룹 데이터를 생성할 때, 프레임 추출부에서 수신받은 동영상 정보를 제공받을 수 있으며, 이 동영상 정보를 딥러닝 모델을 통해 샷별로 분리하여 샷별 그룹 데이터로 생성할 수 있다. 이후, 동영상 품질 분석 서버는 그룹 데이터들(프레임별 그룹 데이터, 샷별 그룹 데이터)을 분석하여 해당 동영상 정보에 오류가 존재하는지 여부를 확인하는 단계를 수행한다(S340) 이때, S340 단계는, 오류의 존재하는 경우, 해당 오류가 프레임별 그룹 데이터, 또는 샷별 그룹 데이터 중 어느 하나, 또는 둘 모두에 존재하는지 여부를 판단하고, 판단한 결과에 대응하는 오류 검증 정보를 생성하여 상기 그룹 데이터들에 해당하는 동영상 정보의 오류 검증이 이루어지도록 한다. 바람직하게는, 동영상 품질 분석 서버는 상기 오류 검증 정보를 오류 검증부로 전송하여 오류 검증이 이루어지도록 할 수 있다. 다음으로, 상기 오류 검증 정보에 샷 오류 정보가 포함되어 있는 경우, 동영상 품질 분석 서버의 오류 검 증부에 구성된 샷 오류 검증 모듈로 샷별 그룹 데이터를 전송하여 오류를 검증하는 단계를 수행한 다.(S350) 상기 S350 단계는, 상기 샷별 그룹 데이터에서 색상 공간이 훼손되었는지 여부, 프레임의 튐 현상 및 버벅임 현 상이 존재하는지 여부를 검증하는 단계로, 샷을 기준으로 그룹화된 이미지 데이터들을 프레임별로 구분한 후, 딥러닝 기반 오류 검증 모델을 활용하여 검증한다. 먼저, 상기 S350 단계는, 샷별 오류 검증 모듈을 통해 색상 공간 훼손에 대한 오류 검증시 프레임별로 구 분된 샷별 그룹 데이터를 색상 공간 시스템(RGB, CMYK, L* a* b* 등)에 대입하고, 대입이 이루어진 샷별 그룹 데이터의 색상 값이 훼손되었는지 확인할 수 있을 것이다. 즉, 상기 S350단계는 프레임별로 구분된 샷별 그룹 데이터를 색상 공간 시스템의 색상별 채널(RGB,RGBA, CMYK, L* a* b* 채널)을 통해 각각 비교하여 비교 결과값을 생성하는 단계를 수행하고, 이후 생성한 비교 결과값으로 부터 프레임별로 구분된 샷별 그룹 데이터에 대한 각 채널별 평균 색상 분포도를 산출한 다음, 산출한 색상 분 포도를 기준으로 프레임별로 구분된 샷별 그룹 데이터의 타겟 프레임 이전 프레임과 이후 프레임을 비교 후, 평 균 색상 분포도와 다르다고 판단되면, 해당 타겟 프레임은 색상 공간의 훼손에 대한 오류가 있다고 판단하는 단 계로 이루어질 수 있을 것이다. 또한, 상기 S350 단계는, 상기 샷 오류 정보에 프레임의 튐 현상에 대한 오류 정보가 포함되어 있는 경우, 딥러 닝 기반 오류 검증 모델을 통해 프레임별로 구분된 샷별 그룹 데이터들을 시간순서대로 정렬하는 단계를 수행한 다. 이후, 정렬이 이루어진 프레임별로 구분된 샷별 그룹 데이터들을 순회하면서 상기 프레임별로 구분된 샷별 그룹 데이터들에 대한 프레임 임계값을 설정하고, 설정한 임계값을 기준으로 타겟 프레임, 타겟 프레임의 이전 프레 임과 이후 프레임을 비교하여 각각의 임계값에 대한 변화값을 산출하는 단계를 수행한다. 이후, 타겟 프레임의 임계값이 이전 프레임, 또는 이후 프레임의 임계값과 일정 수치 이상 차이가 나는 경우, 해당 타겟 프레임에 프레임의 튐 현상이 발생한 것으로 판단하는 단계를 수행한다. 이때, 이전 프레임, 또는 이후 프레임의 임계값이 프레임 임계값과 일정 수치 이상 차이가 나는 경우, 해당 이 전 프레임, 또는 이후 프레임 역시 프레임 튐 현상이 발생한 것으로 판단할 수 있다. 또한, 상기 S350 단계는, 샷별 그룹 데이터에서 영상 버벅임 현상에 대한 오류를 검증하는 단계를 수행한다. 이때, 상기 S350 단계에서 영상 버벅임 현상에 대한 오류를 검증하는 단계를 수행하는 경우, 상기 임계값에 대 한 변화값이 타겟 프레임과 이전 프레임이 동일하거나, 상기 임계값의 값보다 작은 경우 해당 타겟 프레임은 영 상 버벅임 현상이 발생하였다고 판단할 수 있다. 다음으로, 상기 오류 검증 정보에 프레임 오류 정보가 포함되어 있는 경우, 동영상 품질 분석 서버의 오류 검증부에 구성된 프레임 오류 검증 모듈로 프레임별 그룹 데이터를 전송하여 오류를 검증하는 단계를 수행한다.(S360) 상기 S360 단계는, 프레임별 그룹 데이터의 레터 박스의 오류 존재 여부, 노이즈의 훼손 여부, 프레임의 픽셀 손상 및 누락 여부에 대한 오류 검사를 수행하는 단계이다. 이러한 상기 S360 단계는, 레터 박스의 오류 존재 여부에 대한 오류 검사시 프레임을 기준으로 그룹화된 이미지 데이터들 각각에 대하여 이미지 데이터의 상, 하, 좌, 우 방향에서 발생한 레터 박스와 필러 박스에 대한 길이 를 계산하는 단계를 수행한다. 이후 오류 검증이 이루어지는 이미지 데이터의 전체 프레임에 대한 레터 박스 및 필러 박스의 길이를 계산한 후, 이미지 데이터의 레터 박스 및 필러 박스와 상기 이미지 데이터 전체 프레임에 대한 길이값을 비교하는 단 계를 수행한다. 이후, 기준 길이값과 차이가 나는 이미지 데이터의 위치를 파악하고, 파악한 위치에 블랙바가 형성되었는지 여 부를 확인하여 상기 블랙바가 형성되어 있는 경우 레터 박스의 오류가 존재하는 것으로 판단하는 단계를 수행한 다. 또한, 상기 S360 단계는, 노이즈 훼손 여부에 대한 오류 검사시 No-Reference Image Quality Assessment 계열 의 딥러닝 모델을 활용하여 픽셀이 손상된 이미지 데이터들 각각에 대하여 이미지 데이터를 학습하는 단계를 수 행한다.또한, 상기 S360 단계는, 프레임의 픽셀 손상 및 누락 여부에 대한 오류 검사시 Yolov5 과 같은 object detection 모델을 통해 딥러닝 모델을 활용하여 프레임을 기준으로 그룹화된 이미지 데이터들을 학습하는 단계 를 수행한다. 이후, 학습에 사용한 이미지 데이터들로부터 손상된 부분 픽셀 추출하여 패치정보를 생성하는 단계를 수행한다. 이후, 생성된 패치 정보를 기반으로 손상 프레임의 데이터를 증강하여, 손상 프레임의 존재 유무를 탐지함으로 써, 픽셀 손상 및 누락 여부를 검증하는 단계를 수행한다. 한편, 본 발명에 기재된 네트워크는 복수의 단말 및 서버들과 같은 각각의 노드 상호 간에 정보 교환이 가능한 연결 구조를 의미하는 것으로, 이러한 네트워크의 일 예에는 RF, 3GPP(3rd Generation Partnership Project) 네트워크, LTE(Long Term Evolution) 네트워크, 5GPP(5rd Generation Partnership Project) 네트워크, WIMAX(World Interoperability for Microwave Access) 네트워크, 인터넷(Internet), LAN(Local Area Network), Wireless LAN(Wireless Local Area Network), WAN(Wide Area Network), PAN(Personal Area Network), 블루투스(Bluetooth) 네트워크, NFC 네트워크, 위성 방송 네트워크, 아날로그 방송 네트워크, DMB(Digital Multimedia Broadcasting) 네트워크 등이 포함되나 이에 한정되지는 않는다. 이상의 설명은 본 발명의 기술 사상을 예시적으로 설명한 것에 불과한 것으로서, 본 발명이 속하는 기술 분야에 서 통상의 지식을 가진 자라면 본 발명의 본질적인 특성에서 벗어나지 않는 범위에서 다양한 수정 및 변형이 가 능할 것이다. 따라서, 본 발명에 개시된 실시예들은 본 발명의 기술 사상을 한정하기 위한 것이 아니라 설명하 기 위한 것이고, 이러한 실시예에 의하여 본 발명의 기술 사상의 범위가 한정되는 것은 아니다. 본 발명의 보호 범위는 아래의 청구범위에 의하여 해석되어야 하며, 그와 동등한 범위 내에 있는 모든 기술 사상은 본 발명의 권리범위에 포함되는 것으로 해석되어야 할 것이다."}
{"patent_id": "10-2022-0186209", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일 실시예에 따른 인공지능 기반 동영상 품질 분석 시스템을 개략적으로 나타낸 구성 블록도, 도 2는 본 발명의 일 실시예에 따른 인공지능 기반 동영상 품질 분석 시스템의 동영상 품질 분석 서버를 개략적 으로 나타낸 구성 블록도, 도 3은 본 발명의 일 실시예에 따른 동영상 품질 분석 시스템의 오류 검증부에서 샷별 오류 검증 모듈을 통해 검증이 이루어지는 오류의 종류를 나타낸 예시도, 도 4는 본 발명의 일 실시예에 따른 샷별 오류 검증 모듈을 통해 색상 공간의 훼손 여부에 대한 오류를 검증하 는 상태를 나타낸 예시도, 도 5는 본 발명의 일 실시예에 따른 샷별 오류 검증 모듈을 통해 프레임 튐 여부 및 동영상 정보의 버벅임 현상 에 대한 검증 알고리즘을 개략적으로 나타낸 도면, 도 6은 본 발명의 일 실시예에 따른 동영상 품질 분석 시스템의 오류 검증부에서 프레임별 오류 검증 모듈을 통 해 검증이 이루어지는 오류의 종류를 나타낸 예시도, 도 7은 본 발명의 일 실시예에 따른 프레임별 오류 검증 모듈을 통해 레터 박스 오류에 대한 오류 검증시 표시 되는 화면 정보를 나타낸 예시도, 도 8은 본 발명의 일 실시예에 따른 프레임별 오류 검증 모듈을 통해 프레임 픽셀 손상 여부에 대한 오류 검증 시 표시되는 화면 정보를 나타낸 예시도, 도 9는 본 발명의 일 실시예에 따른 인공지능 기반 동영상 품질 분석 시스템을 이용한 동영상 품질 분석 방법을 나타낸 순서도이다."}
