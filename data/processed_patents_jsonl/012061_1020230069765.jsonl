{"patent_id": "10-2023-0069765", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0171607", "출원번호": "10-2023-0069765", "발명의 명칭": "도메인 한정 생체 리딩 장치 및 도메인 한정 생체 리딩 방법", "출원인": "경북대학교 산학협력단", "발명자": "신호근"}}
{"patent_id": "10-2023-0069765", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "생체 외면에 형성된 1개 도메인 이상의 발광 물질의 이미지를 촬영하는 촬영부; 및상기 이미지로부터, 사전에 머신러닝 된 알고리즘에 기초하여, 상기 생체의 행위 또는 의사를 결정하는,분석부;를 포함하는,도메인 한정 생체 리딩 장치."}
{"patent_id": "10-2023-0069765", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 촬영부는 상기 발광 물질 중 적어도 일부가 미케노 발광 물질인 이미지를 촬영하는,도메인 한정 생체 리딩 장치."}
{"patent_id": "10-2023-0069765", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 촬영부는 상기 발광 물질 도메인 중 적어도 일부가 입 주변에 형성된 이미지를 촬영하는,도메인 한정 생체 리딩 장치."}
{"patent_id": "10-2023-0069765", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서,상기 분석부는 상기 생체의 입술을 리딩하는,도메인 한정 생체 리딩 장치."}
{"patent_id": "10-2023-0069765", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제3항에 있어서,상기 분석부는 상기 생체의 발화 내용을 결정하는,도메인 한정 생체 리딩 장치."}
{"patent_id": "10-2023-0069765", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서,상기 분석부는 인공신경망에 의해 머신러닝 된 알고리즘에 기초하는,도메인 한정 생체 리딩 장치."}
{"patent_id": "10-2023-0069765", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6항에 있어서,상기 분석부는 CNN(Convolution Neural Network)에 의해 머신러닝 된 알고리즘에 기초하는,도메인 한정 생체 리딩 장치."}
{"patent_id": "10-2023-0069765", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "생체 외면에 형성된 1개 도메인 이상의 발광 물질의 학습이미지를 촬영하고, 상기 학습이미지와 상기 생체의 행공개특허 10-2024-0171607-3-위 또는 의사를 대응하여 트레이닝 셋(training set)을 형성하는 제1-1 단계; 및 상기 트레이닝 셋을 머신러닝하여 알고리즘을 구성하는 제1-2 단계;를 포함하는 제1 단계; 및상기 제1-1 단계와 동일하게 형성된 1개 도메인 이상의 발광 물질의 분석이미지를 촬영하는 제2-1 단계; 및 상기 분석이미지로부터 상기 제1-2 단계의 알고리즘에 기초하여, 상기 생체의 행위 또는 의사를 결정하는 제2-2단계;를 포함하는 제2 단계;를 포함하는,도메인 한정 생체 리딩 방법."}
{"patent_id": "10-2023-0069765", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서,상기 발광 물질 중 적어도 일부는 미케노 발광 물질인 것으로 준비하는,도메인 한정 생체 리딩 방법."}
{"patent_id": "10-2023-0069765", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제8항에 있어서,상기 발광 물질 도메인 중 적어도 일부가 입 주변에 형성된 학습이미지 및 분석이미지를 이용하는,도메인 한정 생체 리딩 방법."}
{"patent_id": "10-2023-0069765", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제10항에 있어서,상기 제1-1 단계는 상기 학습이미지와 상기 생체의 입술의 거동을 대응하고,상기 제2-2 단계는 상기 생체의 입술의 거동을 결정하는,도메인 한정 생체 리딩 방법."}
{"patent_id": "10-2023-0069765", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제10항에 있어서,상기 제1-1 단계는 상기 학습이미지와 상기 생체의 발화 내용을 대응하고,상기 제2-2 단계는 상기 생체의 발화 내용을 결정하는,도메인 한정 생체 리딩 방법."}
{"patent_id": "10-2023-0069765", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제8항에 있어서,상기 제1-2 단계는, 상기 트레이닝 셋을 인공신경망을 통해 머신러닝 하여 알고리즘을 구성하는,도메인 한정 생체 리딩 방법."}
{"patent_id": "10-2023-0069765", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제13항에 있어서,상기 제1-2 단계는, 상기 트레이닝 셋을 CNN(Convolution Neural Network)을 통해 머신러닝 하여 알고리즘을구성하는,도메인 한정 생체 리딩 방법."}
{"patent_id": "10-2023-0069765", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "도메인 한정 생체 리딩 장치 및 도메인 한정 생체 리딩 방법이 개시된다. 상기 도메인 한정 생체 리딩 장치는 생 체 외면에 형성된 1개 도메인 이상의 발광 물질의 이미지를 촬영하는 촬영부; 및 상기 이미지로부터, 사전에 머 신러닝 된 알고리즘에 기초하여, 상기 생체의 행위 또는 의사를 결정하는, 분석부;를 포함할 수 있다."}
{"patent_id": "10-2023-0069765", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 도메인 한정 생체 리딩 장치 및 도메인 한정 생체 리딩 방법에 관한 것이다."}
{"patent_id": "10-2023-0069765", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "센서는 현대 산업에서 공장, 자동차, 기계 및 항공기에 이르기까지 다양한 분야에서 널리 사용되고 있다. 최근 에는 인공지능 신소재 등의 기술 혁명으로 불러일으킨 기술의 발전으로 인해 다양하고 고도화된 센서가 요구되 고 있다 이러한 새로운 환경에 다양한 물성을 지닌 재료들의 특성을 이용 해 현장에서 요구하는 환경을 감지를 위해 새로운 센서 및 활용 측면에서 많은 연구가 이루어지고 있다. 특히 신축성 멀티 접근 및 해석의 가능성 높 은 공간 분해능 생체 적합성은 센서에 요구하는 중요한 특성이 되었다. 또한 AI의 도입으로 기존의 저차원의 감 지 능력에서 고차원의 해석 및 감지 능력을 가진 발전된 형태의 센서들이 광범위 한 연구분야로 발전 되고 있다. 기계 발광(ML) 재료는 고체 물질에 인장 압축 전단 진동 등의 다양한 기계적 자극이 가해질 때 발광을 보인다. ML의 발광 정도는 물질에 가해진 응력 및 변형에 강한 상관관계를 나타내기 때문에 응력감지에 적합하다. ML 재 료의 응력 감지는 각각의 나노 마이크로 ML 입자들은 응력에서 광자로의 독특한 변환 원리를 기반이며 이는 향 상된 응력 감지를 위한 기반을 마련한다. 특히 ML 재료 기반 감지는 정보를 전달하는 과정에서 공간을 통한 광 자 전송의 이점을 가지고 있다. 이는 광자 정보 특성으로 인해 다양한 위치에서 감지가 가능하고 가해지는 응력 이나 광자 정보를 원격으로 감지할 수 있다. 또 일반적으로 사용되는 센서에서의 전자 전도가 필요 없기 때문에 응력 광자 변환에서 우수한 신축성 생체 적합성 그리고 자가 출력을 가능케 한다. 중요한 점은 ML 기반 센싱이 기존 감지 기술의 단점을 보완해줄 수 있다는 점이다. 그리고, 몇몇의 ML재료에는 지속발광도 나타나는 점을 유 의해야 한다. 지난 수십년 동안 ML 재료와 ML 재료의 활용에 대해 광범위하게 연구되어왔다. ML 특성인 기계적 자극에 의한 발광이 이루어지며 함께 24 시간 동안의 긴 녹색 인광(PL)을 방출한다. 이러한 ML 재료는 성능 개선 다양한 활 용 및 진보된 연구들을 촉발 하였다. 인공지능의 발전으로 의료 진단, 항공 우주 로봇 공학, 운송, 제조 산업 등의 다양한 업무를 기계가 맡을 수 있 게 되었다. 인간과 기계 사이의 다양한 협업 증가는 고도화된 인간 기계 간 통신 HMC 을 필요로 한다. 인간은 제스처와 같은 다른 의사소통 수단보다 주로 음성 신호를 통해 다른 인간과 의사소통을 하며, 가까운 미래에 인 간과 기계에 보편적이고 자연스러운 의사소통 방식이 될 수 있다. 최근 딥 러닝 방법의 개발 로 인한 음성 인식 의 발전은 이미 시리, 구글 어시스턴트 빅스비 를 포함한 많은 제품에서 음성 안내 인터페이스를 만들었다. 그 러나 음성 안내 인터페이스를 이용한 단일 통신은 언어 장애인들이 AI 음성 인식 기계 를 이용 에 어려움을 준 다. 더욱이, 음성을 통한 HMC 는 소음 에 의해 쉽게 영향을 받을 수 있으며, 이는 소음이 많은 환경에서 HMC 성 능 저하로 이어질 수 있다 따라서 모든 사람에게 적합하고 다양한 환경에서 작동하는 다중 접근 을 가진 HMC 가 필요하다. 최근 몇 년 동안, 언어장애를 가진 사람과의 소통에서 소음의 영향을 줄이기 위해, 컴퓨터 비전과 딥 러닝으로 입술 움직임에서 뜻 을 해독하는 데 사용되어 왔다. 일반적으로 시각 음성 인식이라고도 알려진 립 리 딩 기술은 소리 신호의 유무에 관계없이 HMC 의 보안을 보장하고, 소음이 없는 영향이 없으며, 생체 인증과 같 은 여러 장점을 가지고 있다 따라서 립 리딩 기술은 다중 HMC 의 가능한 후보로 고려된다. 하지만, 립 리딩 기술의 단점 중 하나로는 빛이 잘 들어오는 환경에서만 작동한다. 밝기 가 낮으면 특징 추출과 입술 움직임 이 딥 러닝에 영향을 줄 수 있으며, 결과적으로 모델의 정확도에 영향을 미친다. 따라서 HMC 를 위 한 립 리딩 기술의 적용은 어두운 환경에서는 효과적이지 않다. AI 기계와 인간은 심해, 깊은 우주, 터널 및 동 굴의 어둠을 속을 탐험 한다. 다중 접근 통신 시스템에 통합된 새로운 HMC 모델은 이러한 어두운 환경에서 인간 과 기계의 상호 작용을 촉진하는 데 유용할 수 있다. 따라서 어두운 환경에서 인간이 AI 기계와 통신할 수 있도 록 하기 위해, 본 발명는 누구나 사용할 수 있고 소음의 영향을 받지 않는 새로운 어둠 속 HMC 모델을 제시한다."}
{"patent_id": "10-2023-0069765", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명의 일 목적은 암전 상황 및/또는 자연 재해 상황 등 극한의 상황에서, 생체, 특히 인간, 특히 장비조작 자, 작전수행자 및/또는 인명구조자 등의 언어적의사표현, 비언어적의사표현 및/또는 행위를 분석하여 의사소통 및/또는 상황분석을 수행할 수 있는 도메인 한정 생체 리딩 장치 및/또는 도메인 한정 생체 리딩 방법을 제공하 는 것이다."}
{"patent_id": "10-2023-0069765", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "일 측면에서 본 발명은, 생체 외면에 형성된 1개 도메인 이상의 발광 물질의 이미지를 촬영하는 촬영부; 및 상 기 이미지로부터, 사전에 머신러닝 된 알고리즘에 기초하여, 상기 생체의 행위 또는 의사를 결정하는, 분석부; 를 포함하는, 도메인 한정 생체 리딩 장치를 제공한다. 일 실시예에 있어서, 상기 촬영부는 상기 발광 물질 중 적어도 일부가 미케노 발광 물질인 이미지를 촬영할 수 있다. 일 실시예에 있어서, 상기 촬영부는 상기 발광 물질 도메인 중 적어도 일부가 입 주변에 형성된 이미지를 촬영 할 수 있다. 일 실시예에 있어서, 상기 분석부는 상기 생체의 입술을 리딩할 수 있다. 일 실시예에 있어서, 상기 분석부는 상기 생체의 발화 내용을 결정할 수 있다. 일 실시예에 있어서, 상기 분석부는 인공신경망에 의해 머신러닝 된 알고리즘에 기초할 수 있다. 일 실시예에 있어서, 상기 분석부는 CNN(Convolution Neural Network)에 의해 머신러닝 된 알고리즘에 기초할 수 있다. 다른 측면에서 본 발명은, 생체 외면에 형성된 1개 도메인 이상의 발광 물질의 학습이미지를 촬영하고, 상기 학 습이미지와 상기 생체의 행위 또는 의사를 대응하여 트레이닝 셋(training set)을 형성하는 제1-1 단계; 및 상 기 트레이닝 셋을 머신러닝 하여 알고리즘을 구성하는 제1-2 단계;를 포함하는 제1 단계; 및 상기 제1-1 단계와 동일하게 형성된 1개 도메인 이상의 발광 물질의 분석이미지를 촬영하는 제2-1 단계; 및 상기 분석이미지로부터 상기 제1-2 단계의 알고리즘에 기초하여, 상기 생체의 행위 또는 의사를 결정하는 제2-2 단계;를 포함하는 제2 단계;를 포함하는, 도메인 한정 생체 리딩 방법을 제공한다. 일 실시예에 있어서, 상기 발광 물질 중 적어도 일부는 미케노 발광 물질인 것으로 준비할 수 있다. 일 실시예에 있어서, 상기 발광 물질 도메인 중 적어도 일부가 입 주변에 형성된 학습이미지 및 분석이미지를 이용할 수 있다. 일 실시예에 있어서, 상기 제1-1 단계는 상기 학습이미지와 상기 생체의 입술의 거동을 대응할 수 있다. 일 실시예에 있어서, 상기 제2-2 단계는 상기 생체의 입술의 거동을 결정할 수 있다. 일 실시예에 있어서, 상기 제1-1 단계는 상기 학습이미지와 상기 생체의 발화 내용을 대응할 수 있다. 일 실시예에 있어서, 상기 제2-2 단계는 상기 생체의 발화 내용을 결정할 수 있다. 일 실시예에 있어서, 상기 제1-2 단계는, 상기 트레이닝 셋을 인공신경망을 통해 머신러닝 하여 알고리즘을 구 성할 수 있다. 일 실시예에 있어서, 상기 제1-2 단계는, 상기 트레이닝 셋을 CNN(Convolution Neural Network)을 통해 머신러 닝 하여 알고리즘을 구성할 수 있다."}
{"patent_id": "10-2023-0069765", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명의 실시예에 따른 도메인 한정 생체 리딩 장치 및/또는 본 발명의 실시예에 따른 도메인 한정 생체 리딩 방법을 통해, 암전 상황 및/또는 자연 재해 상황 등 극한의 상황에서, 생체, 특히 인간, 특히 장비조작자, 작전 수행자 및/또는 인명구조자 등의 언어적의사표현, 비언어적의사표현 및/또는 행위를 분석하여 의사소통 및/또는 상황분석을 수행할 수 있다."}
{"patent_id": "10-2023-0069765", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 첨부한 도면을 참조하여 본 발명의 실시예에 대해 상세히 설명한다. 본 발명은 다양한 변경을 가할 수 있 고 여러 가지 형태를 가질 수 있는 바, 특정 실시 예들을 도면에 예시하고 본문에 상세하게 설명하고자 한다. 그러나 이는 본 발명을 특정한 개시 형태에 대해 한정하려는 것이 아니며, 본 발명의 사상 및 기술 범위에 포함 되는 모든 변경, 균등물 내지 대체물을 포함하는 것으로 이해되어야 한다. 각 도면을 설명하면서 유사한 참조부 호를 유사한 구성요소에 대해 사용하였다. 첨부된 도면에 있어서, 구조물들의 치수는 본 발명의 명확성을 기하 기 위하여 실제보다 확대하여 도시한 것이다. 본 출원에서 사용한 용어는 단지 특정한 실시 예를 설명하기 위해 사용된 것으로, 본 발명을 한정하려는 의도가 아니다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 출원에서, \"포함 하다\" 또는 \"가지다\" 등의 용어는 명세서 상에 기재된 특징, 숫자, 단계, 동작, 구성요소 또는 이들을 조합한 것이 존재함을 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성요소 또는 이 들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되어야 한다. 다르게 정의되지 않는 한, 기술적이거나 과학적인 용어를 포함해서 여기서 사용되는 모든 용어들은 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자에 의해 일반적으로 이해되는 것과 동일한 의미를 가지고 있다. 일 반적으로 사용되는 사전에 정의되어 있는 것과 같은 용어들은 관련 기술의 문맥 상 가지는 의미와 일치하는 의 미를 가지는 것으로 해석되어야 하며, 본 출원에서 명백하게 정의하지 않는 한, 이상적이거나 과도하게 형식적 인 의미로 해석되지 않는다. 도 1은 본 발명의 실시예에 따른 도메인 한정 생체 리딩 장치를 개략적으로 도시한 도면이다. 도 1을 참조하면, 본 발명의 실시예에 따른 도메인 한정 생체 리딩 장치는, 생체 외면에 형성된 1개 도메 인 이상의 발광 물질의 이미지를 촬영하는 촬영부; 및 상기 이미지로부터, 사전에 머신러닝 된 알고리즘에 기초하여, 상기 생체의 행위 또는 의사를 결정하는, 분석부;를 포함할 수 있다. 상기 촬영부는, 생체를 촬영하여, 생체 외면에 형성된 1개 도메인 이상의 발광 물질의 이미지를 획득하는 부재이다. 본 명세서의 문맥에서, 발광 물질의 ‘도메인’ 이라는 용어는, 생체 외면의 전부 또는 일부에, 특히 유의하게 작은 수준의 점-유사 도형 형상으로 형성된 발광 물질의 일 영역을 의미할 수 있다. 따라서 생체 외면 에 형성된 1개 도메인 이상이 발광 물질의 이미지를 촬영부가 획득할 때, 상기 촬영부는 상기 발광 물질의 도메인의 전부 또는 일부의 위치, 색상 또는 밝기 및 형상을 획득할 수 있다. 촬영부가 상기와 같은 기능을 수행하는 한, 상기 촬영부가 촬영할 수 있는 상기 발광 물질의 재료는 특별히 제한되지 않는다. 일 실시예에 있어서, 상기 촬영부는 상기 발광 물질 중 적어도 일부가 미케노 발 광 물질인 이미지를 촬영할 수 있다. 미케노 발광 물질을 사용함으로써, 상기 발광 물질의 위치 뿐만 아니라, 상기 생체의 외면에 형성된 각 도메인의 신장 및 수축에 관한 정보도 상기 발광 물질로부터 수득할 수 있다. 촬영부가 상기와 같은 기능을 수행하는 한, 상기 발광 물질이 형성되는 생체의 외면은 특별히 제한되지 않 는다. 일 실시예에 있어서, 상기 촬영부는 상기 발광 물질 도메인 중 적어도 일부가 입 주변에 형성된 이 미지를 촬영할 수 있다. 입 주변은 촬영 대상인 생체가 말을 하는 등 언어적 표현을 수행할 때, 위치가 변화하 며 근육에 의한 피부의 신장 및 수축이 발생하므로, 이로부터 이미지를 수득하는 경우 생체의 언어적 표현에 의 한 의사를 추정할 수 있다. 상기 촬영부는 반드시 별도의 이미지 처리를 하지 않는 부재로 한정되지 않는다. 일 실시예에 있어서, 상 기 촬영부는 상기 생체 외면에 형성된 1개 도메인 이상의 발광 물질의 이미지를 획득하는 과정에서, 예컨 대 흑백화와 같이 특정 채색 또는 색상에 한정하여 획득한 이미지를 변경할 수 있으며, 이는 후술될 분석부 에서 처리될 수 있도록 사전 결정된 규칙에 따를 수 있다. 상기 분석부는, 상기 촬영부로부터 획득한 이미지로부터, 사전에 머신러닝 된 알고리즘에 기초하여, 상기 생체의 행위 또는 의사를 결정할 수 있다. 분석부가 상기와 같은 기능을 수행하는 한, 분석부가 리딩하는 이미지 및/또는 분석부가 결정하 는 생체의 행위 또는 의사는 특별히 제한되지 않는다. 상술된 바와 같이, 상기 발광 물질은 입 주변에 형성될 수 있다. 이 경우, 일 실시예에 있어서, 상기 분석부는 상기 생체의 입술을 리딩할 수 있다. 일 실시예에 있어서, 상기 분석부는 상기 생체의 발화 내용을 결정할 수 있다.본 명세서의 문맥에서, ‘머신러닝’은 데이터를 기반으로 학습하는 시스템을 통칭할 수 있다. 일 실시예에 있 어서, 상기 분석부는 인공신경망에 의해 머신러닝 된 알고리즘에 기초할 수 있다. 일 실시예에 있어서, 상 기 분석부는 CNN(Convolution Neural Network)에 의해 머신러닝 된 알고리즘에 기초할 수 있다. 도 2는 본 발명의 실시예에 따른 도메인 한정 생체 리딩 방법을 도시한 흐름도이다. 도 2를 참조하면, 본 발명의 실시예에 따른 도메인 한정 생체 리딩 방법은, 생체 외면에 형성된 1개 도메 인 이상의 발광 물질의 학습이미지를 촬영하고, 상기 학습이미지와 상기 생체의 행위 또는 의사를 대응하여 트 레이닝 셋(training set)을 형성하는 제1-1 단계(S211); 및 상기 트레이닝 셋을 머신러닝 하여 알고리즘을 구성 하는 제1-2 단계(S212);를 포함하는 제1 단계; 및 상기 제1-1 단계(S211)와 동일하게 형성된 1개 도메인 이상의 발광 물질의 분석이미지를 촬영하는 제2-1 단계(S221); 및 상기 분석이미지로부터 상기 제1-2 단계(S212)의 알 고리즘에 기초하여, 상기 생체의 행위 또는 의사를 결정하는 제2-2 단계(S222);를 포함하는 제2 단계;를 포함할 수 있다. 상게 제1-1 단계(S211)는, 머신러닝에 적용할 수 있는 트레이닝 셋을 형성하는 단계이다. 본 명세서의 문맥에서, 트레이닝 셋은 머신러닝을 수행하는 시스템이 학습하는 입력값 및 대응되는 출력값의 셋을 의미할 수 있다. 상기 트레이닝 셋은 발광 물질을 포함하는 쵤영 결과 및 이에 대응하는 생체의 행위 또는 의사일 수 있다. 상기 제1-2 단계(S212)는, 머신러닝을 진행하는 단계이다. 상기 머신러닝을 통해 시스템에 알고리즘이 형성될 수 있으며, 상기 알고리즘은 생체 표면에 형성된 1개 도메인 이상의 발광 물질의 상을 포함하는 촬영 결과를 입 력받아, 이로부터 상기 생체의 행위 또는 의사를 결정할 수 있는 알고리즘일 수 있다. 상기 제1 단계는, 전체적으로 트레이닝 셋을 형성하여 머신러닝을 통해 알고리즘을 형성하는 단계로, 이를 통해 본 발명의 실시예에 따른 도메인 한정 생체 리딩 방법을 수행하는 시스템, 바람직하게는 본 발명의 일 측 면에 따른 도메인 한정 생체 리딩 장치는 기계 학습을 수행할 수 있다. 상기 제2-1 단계(S221)는, 상기 발광 물질의 1개 도메인 이상의 분석이미지를 촬영하는 단계이다. 상기 분석이 미지는 상기 트레이닝 셋을 구성하는 학습이미지와 달리, 대응하는 생체의 행위 또는 의사가 미지의 상태이다. 상기 제2-2 단계(S222)는, 상기 학습이미지로부터 생체의 행위 또는 의사를 결정하는 단계이다. 상술된 바와 같 이, 상기 분석이미지는 상기 트레이닝 셋을 구성하는 학습이미지와 달리, 대응하는 생체의 행위 또는 의사가 미 지의 상태인데, 상기 트레이닝 셋을 머신러닝하여 시스템이 구축한 알고리즘에 기초하여 생체의 행위 또는 의 사를 결정할 수 있다. 상기 제2 단계는, 전체적으로 트레이닝 셋을 형성하여 머신러닝 된 알고리즘으로부터 생체의 행위 또는 의사를 결정하는 단계로, 이를 통해 본 발명의 실시예에 따른 도메인 한정 생체 리딩 방법을 수행하는 시스템, 바 람직하게는 본 발명의 일 측면에 따른 도메인 한정 생체 리딩 장치는 기계 학습된 알고리즘으로부터 생체의 행 위 또는 의사를 결정할 수 있다. 상기 본 발명의 실시예에 따른 도메인 한정 생체 리딩 방법에 관한 설명은, 상술된 본 발명의 실시예에 따 른 도메인 한정 생체 리딩 장치에 관한 설명에서 동일하거나 유사한 용어 또는 구성에 대해 동일하거나 유사하 게 적용될 수 있다. 따라서, 일 실시예에 있어서, 상기 발광 물질 중 적어도 일부는 미케노 발광 물질인 것으로 준비할 수 있다. 일 실시예에 있어서, 상기 발광 물질 도메인 중 적어도 일부가 입 주변에 형성된 학습이미지 및 분석이미지를 이용할 수 있다. 일 실시예에 있어서, 상기 제1-1 단계(S211)는 상기 학습이미지와 상기 생체 의 입술의 거동을 대응할 수 있다. 일 실시예에 있어서, 상기 제2-2 단계(S222)는 상기 생체의 입술의 거동을 결정할 수 있다. 일 실시예에 있어서, 상기 제1-1 단계(S211)는 상기 학습이미지와 상기 생체의 발화 내용을 대 응할 수 있다. 일 실시예에 있어서, 상기 제2-2 단계(S222)는 상기 생체의 발화 내용을 결정할 수 있다. 일 실 시예에 있어서, 상기 제1-2 단계(S212)는, 상기 트레이닝 셋을 인공신경망을 통해 머신러닝 하여 알고리즘을 구 성할 수 있다. 일 실시예에 있어서, 상기 제1-2 단계(S212)는, 상기 트레이닝 셋을 CNN(Convolution Neural Network)을 통해 머신러닝 하여 알고리즘을 구성할 수 있다. 본 발명의 실시예에 따른 도메인 한정 생체 리딩 장치 및/또는 본 발명의 실시예에 따른 도메인 한정 생체 리딩 방법을 통해, 암전 상황 및/또는 자연 재해 상황 등 극한의 상황에서, 생체, 특히 인간, 특히 장비조작자, 작전 수행자 및/또는 인명구조자 등의 언어적의사표현, 비언어적의사표현 및/또는 행위를 분석하여 의사소통 및/또는 상황분석을 수행할 수 있다.이하 본 발명의 실시예에 대해 상술한다. 다만, 하기에 기재된 실시예는 본 발명의 일부 실시 형태에 불과한 것으로서, 본 발명의 범위가 하기 실시예에 한정되는 것은 아니다. 제조예 SAO 마이크로 입자와 Eco flex 를 20:80 중량비로 PL 고분자 복합 패치를 제조하였다. SAO 는 일본 Nemoto 에서, Eco flex 는 미국 Smooth On, Inc. 에서 구매하였다. Eco flex는 인체 와 친화적이기 때문에 SAO 마이크 로 입자를 혼합 하는 데 선택되었다. 혼합은 450 RPM 에서 약 2 분 동안 플래너터리 믹서를 사용하여 수행하였 다. 균질성을 향상시키고 응집을 방지하기 위해 혼합 전에 직경 10 mm 의 ZrO2 볼을 용기에 첨가하였다. 잘 혼 합된 혼합체를 5 분간 진공상태를 만들어 주어 갇힌 기포를 제거하였다. 그 후, 복합체를 직경 2 mm, 두께 0.25 m 의 3D 프린팅 플레이트의 원형 몰드 중앙 부분에 부었다. 원형 몰드가 있는 플레이트는 CARIMA IM 96 을 사용 하여 인쇄 하였다. 다음 스핀코터를 사용하여 1000 RPM 에서 20 초 동안 복합체를 퍼트렸다. 그리고 나서 표면 을 날카로운 칼로 긁어주어 몰드 안에만 복합체가 남게 하였다. 그 후, 오븐으로 판을 옮기고 60 ℃ 에서 1 시 간 동안 굳 혔 다. 마지막으로, 응고된 복합 패치를 추출 하였다. 전체 공정은 도 3 에 나와 있다. 패치에서 SAO 의 분포를 보여주는 광학 현미경 이미지(OM)는 도 4 에 나와 있다. 어두운 환경에서 입술 움직임 시각화 SAO 마이크로 입자가 혼합된 SAO Ecoflex 복합체는 유연성이 높고, 신축성이 뛰어나며, 초연성 PL 패치를 제작 하였다. SAO Ecoflex 복합체는 자외선, 형광조명 또는 햇빛과 같은 여기원으로 조사 후 어두운 곳에서 녹색 빛 을 방출 한다(도 4). PL 패치의 발광과 형광등 빛의 스펙트럼 이 함께 도 5에 도시되어 있다. 이는 Eu2+ 이온의 4f5d-4f 특성 전이에 의해 530nm 에서 넓은 발광 대역을 보여준다. 형광등 조명 아래에서 20분 동안 충전한 후 상온에서 PL 패치의 광전자 증폭관 (PMT)으로 측정한 잔광 수명은 도 5b 와 같이 12 시간이 넘는 것으로 나타났 다. PL 패치의 잔광은 어두운 조건하에서 육안으로 선명하게 관찰할 수 있었으며, 12 시간 동안의 SAO 잔광 사 진은 참조에 잘 나타나 있다. 잔광의 수명은 여기원, 충전기간 및 외부 온도에 의해 영향을 받을 수 있다. 예를 들어, 온도가 감소하면 갇힌 전자 정공의 방출 속도가 감소하여 잔광 시간이 길어진다. 다양한 변수에 대한 SAO 의 붕괴 곡선은 잘 보고되어 있다. SAO 의 잔광은 여기원으로 재조사 후 회복 가능하다는 점에 유의해야 한다. 처음 8 개의 SAO Ecoflex 복합 패치를 입술에 직접 부착하였다. 이를 어두운 환경 에서 구 두어를 통해 입술 움 직임을 시각화 했다. 그러나, 혀와 입술에 붙여진 PL 패치 사이에 빈번한 접촉이 있다는 것을 발견했다. 따라서 해당 문제를 고려하여 PL 패치 위치를 입 주변 근육 위의 피부를 선택했다. 해당 근육은 입술을 감싸고 말하는 동안 입술의 모양을 조절한다. 따라서 입 주변 근육 위의 피부는 PL 패치의 이동 패턴을 기반으로 음성을 해독 하기에 이상적인 위치일 수 있다. 이를 바탕으로, 8 개의 PL 패치를 도 6a와 같이 인체 친화적인 접착제로 피부 에 부착 하였다. 어두운 환경에서는 도 6a 에 모식도 로 나타난 것처럼 입술을 둘러싸고 있는 발광 PL 패치를 볼 수 있다. PL 패치는 형광 등 조명에서 자연스럽게 충전된다는 점에 주목 해야 한다. 따라서 PL 패치를 충전 하는 데 특별한 UV가 사용되지 않았다. 본 발명은 주로 어두운 환경에서 음성의 해독을 개선하는 데 중점을 두었기 때문에, 구별 가능한 클래스의 수는 10 개로 제한하였다. 또한, 짧은 단어, 긴 단어, 유사한 단어, 시각적으로 유사한 단어, 시각적으로 다른 단어 및 제스처를 포함하도록 주의를 기울여 클래스를 선택하였다(도 6a). 특정 클래스는 연속적인 영상으로 녹화되었고, 짧은 간격을 두고 단어들을 20 번 반복하여 말하였다. 해당 방법 으로, 4 명의 참가자와 10 개의 클래스(4×10)로 총 40 개의 영상을 얻었다. 각 반복마다 해당 프레임을 쉽게 추출할 수 있도록 A4 용지로 카메라를 막아 발음 간 시작점을 맞추어 주었다. 또한, 딥러닝용 추가 분석과 특징 추출을 위해 한 영상에서 프레임 10 개를 선정했다. 각 10 개의 프레임을 추출하기 위해, 영상은 먼저 210×210 크기의 이미지로 변환되었다. 그런 다음 도 6b와 같이 각 프레임의 최대 밝기를 획득하고 프레임 수를 분석했다. 도 6b는 최대 밝기 값이 연속적으로 감소하는 상태에서 강도가 갑자기 증가하고 감소하는 것을 보여 준다. 급격한 상승과 하강은 카메라 렌즈의 노출과 차단되어 발생하며, 전반적인 감쇠는 위에서 언급한 바와 같 이 SAO의 감소하는 잔광이다. 도 6b는 임계 값 을 정한 다음 이진수로 변환하여 처리했다. 이진 데이터를 기반 으로 각 사이클의 첫 번째 프레임과 마지막 프레임이 결정 되므로 시작과 끝을 알 수 있다. 노출의 시작과 종료 에 대한 프레임을 결정한 후 도 6c과 같이 동일한 샘플링 간격 으로 사이클마다 10 프레임을 추출하였다. 이 방 법 을 이용하여 각 클래스별로 800 프레임 선택한 프레임 번호×반복×참가자 을 추출하였고, 10 개의 클래스에 대해 8000 프레임을 생성하였다 각 발음에 대해 프레임 수가 충분한 이동 패턴을 가지는지 확인 했다. 프레임 수를 늘리면 정보가 증가하지만 딥 러닝 모델 훈련 에 더 많은 계산이 필요하다. 움직임 패턴을 시각화하기 위해 도 7a와 같이 10 개의 프레임 을 단일 이미지로 병합했다. Around 와 같은 일부 클래스에서는 패치 의 위치 이동을 명확하게 볼 수 있다. Strain 과 같은 클래스에서는 PL 패치의 작은 움직임으로 인해 이동 관측이 어렵다. 자세히 보기 위해 도 7b 에 표시된 것처럼 병합된 이미지에서 두 개의 서로 다른 관심 영역(ROI)으로 ROI 1 및 ROI 2 가 선택되었다. 두 ROI 모두 대부분의 클래스에서 패치 이동이 명확하게 나타나는 것을 알 수 있다. Around 과 Ground 와 같은 유 사한 단어라도 두 ROI 에서 서로 다른 패턴을 보여 준 다. 또한 한 패치에는 이동의 유사성이 있지만, 다른 패 치에는 입술 움직임이 나타나는 독특한 표현이 있다. 예를 들어, Smile 은 ROI 1 에서 변형은 유사한 이동 패턴 을 보여주지만 ROI 2 에서는 뚜렷한 패턴을 보인다. 이는 입술을 둘러싼 피부의 변형에 국소적인 변화가 있으며 이러한 변형은 말하는 단어와 높은 상관관계가 있음을 시사한다. PL 패치는 피부 변형에 대한 국소적인 변화를 보여주는데 도움이 되기 때문에 딥러닝 알고리즘이 이러한 패턴을 효과적으로 학습하고 음성 해독할 수 있을지 알 수 있다. PL 패치의 이동 패턴을 음성 단어로 변환 본 발명에서는 PL 패치의 모션 패턴과 구두어 사이의 연결을 학습하기 위해 CNN(Convolutional Neural Network) 을 사용하였다. CNN 은 이미지 데이터를 처리하기 위한 딥 러닝 모델의 일종으로, 저수준 특성 에서 고 수준 특성 까지 계층을 설계되었다. CNN 은 일반적으로 컨볼루션 레이어, 풀링 레이어 및 완전 연결 레이어 로 총 세 가지 레이어로 구성된다. 컨볼루션 레이어는 컨볼루션 필터 커널 를 사용하여 입력 데이터에 컨볼루션 연산을 적용하여 특성 맵을 생성한다. 컨볼루션 연산의 결과는 풀링 층과 비선형 활성화 ReLU 함수를 통해 전달 된다. 비선형 활성화 함수는 CNN 에 복잡한 특성을 학습할 수 있는 능력을 증가시킨다. 그리고, 풀링 레이어는 특성 맵의 차원을 감소시킨다. 이는 계산 요구 사항을 줄이고 네트워크를 훈련할 때 과적합 문제를 해결하는 데 도움이 된다. 마지막 컨볼루션 레이어 또는 풀링 레이어의 출력 특성 맵은 1 차원 벡터로 변환되어 완전 연결 레이어에 연결된다. 완전 연결 레이어의 각 뉴런의 출력은 ReLU 와 같은 비선형 활성화 함수를 통해 전달된다. 마지막으로 완전 연결 계층은 일반적으로 클래스 수와 동일한 수의 출력 노드를 가지며, 활성화 함수는 일반적 으로 다른 계층과 다르다. 멀티클래스 분류 작업에 적용되는 활성화 함수는 출력 값을 확률로 정규화하는 소프 트맥스 함수이며, 각 값은 0 과 1 사이이고 모두 더한 값은 1 이다. 이미지의 복잡도에 따라 CNN 구조 에서 컨볼루션 및 풀링 레이어의 수를 늘릴 수 있다. 심층 CNN 은 낮은 수준 의 세부 특징을 더 효과적으로 캡처할 수 있지만 높은 계산 비용이 발생한다. 최근 컴퓨팅 파워의 상당한 증가 로 인해 AlexNet, Google Net, DenseNet, VGGNet, ResNet 및 Mobilenet 과 같은 많은 심층 컨볼루션 신경망이 개발되었다. 본 발명에서는 VGGNet 에서 영감을 받아 CNN 모델 의 특징 추출 계층의 깊이를 다양하게 테스트했다. 완전 연결 레이어는 모든 CNN 모델에서 고정되었다. 최소 단위를 2 개의 컨볼루션 레이어와 최대 풀링 레이어로 구성 하여 특징 추출 레이어의 단순히 반복함으로써 특징 추출 레이어의 깊이를 증가시켰다. 완전히 연결된 레이어는 세 개의 다른 레이어로 구성 된다. 제1 및 제2 완전 연결 층은 각각 ReLU 활성화 함수를 가진 256 개 및 128 개의 뉴런과 50%의 드롭아웃 층을 포함하였다. 과적합을 최소화하기 위해 드롭아웃 레이어가 포함되었다. 최종 완전 연결 층은 10 개의 클래스를 위한 10 개의 뉴런을 포함하고 있으며 소프트맥스 활성화를 사용하였다. 각 컨볼루 션 레이어는 3 × 3 커널, 1 × 1 스트라이드, ReLu 활성화 함수로 구성되었지만, 도 8a와 같이 특징 추출 레이 어의 위치에 따라 필터의 수가 달라졌다. 모델은 범주형 교차 엔트로피 손실 함수의 전역 최소값을 결정하기 위 해 학습률이 0.0001 인 Adams 최적화를 사용하여 테스트되었다. 하나의 특징 추출 레이어로 구성된 모델을 VGG- 1 모델이라고 한다. 마찬가지로, 2 개, 3 개, 4 개 및 5 개의 특징 추출 층을 가진 모델을 각각 VGG-2, VGG-3, VGG-4 및 VGG-5 라고 부른다. 특징 추출 층은 2 개의 컨볼루션 층과 최대 풀링 층으로 구성되었다는 점에 주목 해야 한다. VGG-5 의 아키텍처는 도 8a에 나와 있다. 또한, VGGNet 기반 모델의 성능을 검증하기 위해 ResNet 34 아키텍처를 사용하여 심층 CNN 모델이 구현되었다. ResNet 34 의 아키텍처는 도 9 에 나와 있다 입술 움직임의 공간 및 시간 정보를 포함하는 대표적인 10 개의 프레임의 특징 추출을 용이하게 하기위해 도 8b 과 같이 흑백 이미지로 변환한 후 프레임을 중첩하여 채널 차원이 10 인 총 800 개의 데이터 포인트 클래스 × 참가자 × 반복 를 사용 하였다. 본 발명에서는 과 적합 문제를 줄이 고자 데이터 수를 인위적으로 5 배 증가시 키기 위해 증강 기법을 적용하였으며, 이로 인해 4000 개의 데이터가 생성되었다. 확대는 도 8b 와 같이 각 적 층 이미지에 대해 무작위 회전 (-20°~20°), 무작위 스케일링 (0.9~1.1), 대칭(수평) 및 무작위 이동 수평 =± 10°, 수직 =±10 픽셀)을 수행 하였다. 800 개의 원래 데이터는 검증 및 테스트 데이터 세트로 동일하게 분할 된 반면, 생성된 모든 데이터는 모델을 훈련하는 데 사용되었다. 클래스를 기반으로 분할되어 각 클래스가 검증및 테스트 데이터 세트에서 동일 하게 분리되었다. 5 가지 VGGNet 기반 모델과 ResNet 34 의 결과는 학습 정확도, 검증 정확도 및 테스트 정확도는 표 1 에 제시되 어 있다. 표 1 Method Train accuracy Validation accuracyTest accuracy VGG-1 89.9 % 72 % 74 % VGG-2 95.7 % 85.5 % 90 % VGG-3 96.68 % 96.25 % 94.25 % VGG-4 98.5 % 98.75 % 98.5 % VGG-5 99.02 % 99 % 98.5 % ResNet-34 100 % 99 % 98.75 % VGG-1 은 약 90% 의 훈련 정확도를 보였고, 검증과 테스트 정확도는 각각 72% 와 74% 였다. 훈련 정확도에 비해 검증 및 테스트의 정확도가 낮다는 것은 적은 계층에서 오는 과적합 문제를 명확하게 보여준다. 검증 및 테스트 데이터 세트에서 모델의 정확도가 각각 85.5% 와 90% 로 크게 증가한 VGG-2 에서 과적합 은 개선되었다. 또한 VGG-2 의 추가 특징 추출 계층은 VGG-1 모델 과 비교하여 훈련 정확도를 6% 향상시켰다. 추가 특징 추출 계층에 대응하여 훈련 정확도를 높이고 과적합 문제를 감소시키는 추세는 VGG-5 까지 관찰된다. 반면 ResNet 34 는 검 증 및 테스트 정확도가 각각 99%, 98.75% 로 100% 의 훈련 정확도를 보여 VGG-5 의 성능과 상당히 유사하다. 따 라서, 형상 추출 계층이 깊을수록 모델이 정확도를 높이고 과적합 문제 를 해결하 는 것으로 결론 내릴 수 있다. 도 10 에서 표시한 대로 시험 데이터 집합의 혼동 행렬 을 보여준다. 이를 이용하여 개별 클래스의 모델의 성능 을 관찰할 수 있다 VGG-1 모델 은 “Strain” 과 “Stress”, “t” 와 “b”를 혼동하는 것을 보인다. 마찬가 지로 이 모델은 “Around\"와 ”Ground\"를 구별하는 것에도 약간의 혼동 이 있다. 또한 2.5% 낮은 오류를 보이며 “Smile\" 을 예측했다. 반면 \"Fracture\" 예측은 27.5% 로 낮은 정확도를 나타난다. Fracture 에 대한 잘못된 예측은 다른 클래스 로 예측하였기 때문이다. VGG-2 는 VGG-1 에 비해 각 클래스의 예측 정확도를 크게 향상시 켰다. 예를 들어 “Strain” 과 “Stress”, “b” 와 “t”, “Around\"와 ”Ground\" 사이의 혼동을 크게 감소 하여 예측 정확성을 향상시켰다. VGG-2 에 Smile 을 예측하는 정확도는 100% 이다. Fracture 의 예측율도 72.5% 로 개선되었다. 도 10 와 같이 VGG-5 의 혼동 행렬은 우수하다. VGG-1 부터 VGG-5 까지의 클래스별 정확도 측면 에서 모델의 성능이 증가하였으며, VGG-5가 최고의 성능을 보여주었다. VGG-5 모델은 'Around', 'b', 'Ground', 'Mechanics', 'Smile', 'Stress', 't'를 100% 정확도로 예측할 수 있었고, 'Fracture'와 'Science' 은 각각 97.5%, 95% 정확도로 예측했다. VGG-5 는 주어진 실제 클래스 “Strain”을 “Stress”로 예측하여 정 확도 92.5%로 나타났다. 또한 VGG-5 는 100% 의 정밀도로 “Stress” 를 예측할 수 있었다. ResNet 34 모델의 혼동 행렬 또한 특정 클래스에서 유사한 혼동 경향을 보여준다. 예를 들어, “S tress” 와 “Strain” 사이의 혼동은 ResNet 34 에서도 관찰된다. 게다가, VGG-5 와 ResNet 34 모두 “Around”, \"b\", \"t\", “Ground”, “ Smile”, “Mechanics” 등급에 대해 100% 의 예측 정확도를 보였다. 따라서, 구조적으로 서로 다름에도 불구하 고 특정 클래스 의 대한 혼동 경향 측면에서 두 모델이 유사하다고 결론 내릴 수 있다 모든 모델은 “Smile\" 을 가장 높은 정확도로 분류했다. VGG-기반 모델에서는 VGG-2 직후 100% 정확도가 달성되 었다. 이는 입술의 움직임으로 인해 발생하는 다수의 패치의 특이한 이동 때문일 수 있다. 다른 클래스는 입술 의 이동을 포함하지 않으며, 이는 얕은 CNN 모델에 의해 구별될 수 있는 뚜렷한 패턴을 초래한다. 또한 혼동 행 렬은 모델이 발음 지속 시간보다 입술 변형에 기초하여 판별되었음을 보여준다. 예를 들어, ”Mechanics\" 는 \"b\" 와 \"t\" 에 비해 발음 시간이 가장 오래 걸리지만, VGG모델은 발음 지속 시간이 다름에도 불구하고 좋은 성 능을 보였다. 대조적으로, 도 7b의 \"Stress\" 와 \"Strain\" 에서 PL 패치의 움직임 패턴에서 어느 정도 유사함을 분명히 보여준다. 이 두 단어가 발음될 때 PL 패치 중 일부는 입술 움직임의 유사성을 보일 수 있다. 유사성의 결과, 심층 컨볼루션 신경망(DCNN) 조차 혼동하는 경향이 있었다. 클래스 간 특징의 판별성을 향상시키는 한 가 지 방법은 입술 주위에 PL 패치를 더 추가하여 피부 변형의 공간 분해능을 높이는 것일 수 있다. 피부 변형의 공간 분해능을 높이면 잠재적으로 구별할 수 있는 패턴의 수가 증가하여 CNN이 더 높은 정밀도로 클래스를 분류 할 수 있다. 성능을 향상시키는 또 다른 방법은 CNN 모델 자체를 개선하는 것이다. 따라서 VGGNet 및 ResNet 아 키텍처 외에도 AlexNet, GoogleNet, DenseNet 및 MobileNet 과 같은 다른 심층 CNN 모델을 사용하여 이 발명을위한 보완 모델을 결정할 수 있다. 고찰 본 발명은 딥 러닝 알고리즘을 사용하여 PL 패치의 동작 패턴을 분류함으로써 입술 근처 피부를 사용하여 음성 을 해독하는 것이 가능하다는 것을 성공적으로 입증했다. 기존의 립 리딩 기술은 딥 러닝이 음성을 해독하기 위 한 특징을 생성하기 위해 입술 변형 이미지를 잘 구해해야 한다. 이는 입술의 기하학적 특징을 고려하지 않는 본 발명과는 다르다. 대신 말하는 중 근육의 변형은 음성을 해독하기 위해 PL 패치로 전달된다. 더 중요한 것은, 음성이 어두운 환경에서 24 해독된다는 것이다. 그러므로, 제한된 손사용, 목소리 떨림, 그리고 좋지 않 은 시력을 가진 장애인을 포함한 많은 사람들에게 유용할 수 있다. 이 어둠 속 통신은 도 11와 같이 다양한 분 야에서 사용될 수 있다. 최근 자동차용 제어 시스템이 개발되고 있다. 그러나 이러한 시스템은 엔진 소음 때문 에 립 리딩 기술의 성능 향상을 요구해왔다. 그러나 실내등이 켜진 상태로 야간 주행 하며 립리딩 기술 적용은 안전하지 않기 때문에 낮 시간에만 적용되도록 제한하였다. 따라서, 본 발명이 이 문제를 해결하는 데 도움이 될 것이라고 믿는다. 어둠 속 통신은 구글 어시스턴트, 시리, 아마존 알렉사 등과 통합해 어둠 속에서 안전한 개인 상호작용 을 제공할 수 있으며, 언어장애인도 제한 없이 사용할 수 있다. 또한 어둠 속 통신은 지문, 손바 닥 지문, 홍채 모양 등과 같은 물리적 생체 인식과 결합하거나 입술 움직임을 암호 로 설정하여 물리적 액세스 제어 시스템에서 단독으로 사용할 수 있다. 빛이 들어오지 않는 깊은 바다, 우주, 터널에서의 인간과 로봇 사이 의 어둠 속 통신은 강력한 멀티 접근 통신 시스템을 구축하는 데 매우 유망할 수 있다. 어둠 속 통신을 위해 개 발된 휴대폰 애플리케이션은 화재 사고 시 목소리에 문제가 있거나 집에 누군가 침입 했을 때 등 야간 비상사태 에 사용할 수 있다. 실제로는, 사람들은 말할 때 머리를 움직인다. 그러나 본 발명에서는 카메라를 마주할 때 머리 위치를 최대한 고정했다. 본 발명의 딥 러닝 모델은 무작위 이미지 회전, 이미지 이동 및 스케일링을 고려하여 훈련되었기 때 문에 카메라를 마주할 때 머리 움직임에 어느 정도의 유연성을 제공하였다. 그러나 카메라에서 떨어진 회전을 적용하려면 이러한 머리 움직임을 고려하는 새로운 실험 데이터 세트를 사용하여 모델을 훈련시켜야 한다. 일부 발명은 모델을 훈련시키기 위해 말하는 동안 말하는 사람의 여러 면을 기록하기 위해 다수의 카메라를 고려했다. 본 발명 뼈대에서 멀티 촬영 데이터베이스를 적용하는 것은 화자의 얼굴 각도에서 발생하는 문제를 해결하는 데 큰 도움이 될 수 있다. 현재 입술 학습 기술 동향은 주로 일반적인 데이터베이스를 기반 을 사용하여 딥 러닝 모델의 성능을 조사하는 데 초점이 맞춰져 있다. 일반적인 데이터베이스는 통제된 실험실 환경이나 TV 프로그램과 같은 환경 에서 데이 터를 추출한다. 두 환경 모두에서 조도는 매우 중요하다. 어두운 환경에서 입술 리딩 시스템을 적용하는 것은 몇 가지 이점이 있지만, 이러한 환경에서 시스템을 구현하는 것을 제안한 연구는 거의 없다. 이러한 연구는 어 두운 환경에서 음성을 해독할 때 빛에 민감하지 않은 열적외선(IR) 기술이 고려되었다. 열화상을 이용한 시각 음성인식은 적외선 카메라의 낮은 해상도와 노이즈로 인해 저조한 성능을 보였다고 해당 연구는 결론지었다. 저 대비 열 이미지 처리에서 ROI 를 선택하는 것은 기술적으로 어렵고 시간이 많이 걸리는 과정 이다. 적외선 카메 라는 매년 개선되고 있지만 표준 카메라와 비교하면 비싸다. 이와 관련하여 입술 판독 시스템에서 음성을 해독 하기 위해 발광 재료를 사용하는 것은 새로운 접근 방식이며, 시각적 음성 인식 시스템을 발전시키는 데 여러 기능 재료를 활용할 수 있는 문을 열 수 있다. 또한, 본 발명은 입술을 둘러싼 피부가 음성을 해독하는 데 사용 될 수 있다는 것을 보여준다. 이는 입술에 직접 부착된 PL 패치로 인해 발생할 수 있는 불편함을 줄인다. 또한 본 발명에 사용된 PL 패치는 생체 적합성 및 초연성 으로 사용 편의성이 더욱 향상되었다. 본 발명에서 제안하 는 방법은 심해, 우주 등 가혹한 환경에서 유용하도록 설계되었다. PL 패치의 가시 범위 파장은 헬멧의 보호 유 리를 관통할 수 있어 IR 신호보다 측정하기에 더 좋은 신호가 될 수 있다. 본 발명에서는 PL 이 어둠 속 기계 인간 소통 의 개념을 확립하는 것을 고려하였으나, PL 재료는 정기적으로 충 전하기 위해서는 UV 나 일 반 광과 같은 외부 에너지원이 필요하다. 이러한 PL 재료의 단점을 극복하기 위해 ML 재료는 이상적인 대체재 이다. 다양한 연구에서 초연성 ML 복합체를 사용하여, 얼굴 피부의 약한 자극 하에서 발광이 보고되었다. 따라서 본 발명에서 추가로 피부 구동 ML을 사용하여 음성을 해독하는 것은 흥미로울 것이다. 피부 구동 ML 을 사용하여 음성을 해독하는 것은 향후 발명의 주제가 될 것이다. 또한, 향후 발명은 대규모 데이터베이스가 립 리딩 기술 개발에 큰 역할을 하기 때문에 더 많은 수의 구별 가능한 단어와 참여자를 고려할 것이다. 상기에서는 본 발명의 바람직한 실시예를 참조하여 설명하였지만, 해당 기술 분야의 숙련된 당업자는 하기의 특 허 청구 범위에 기재된 본 발명의 사상 및 영역으로부터 벗어나지 않는 범위 내에서 본 발명을 다양하게 수정 및 변경시킬 수 있음을 이해할 수 있을 것이다."}
{"patent_id": "10-2023-0069765", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 실시예에 따른 도메인 한정 생체 리딩 장치를 개략적으로 도시한 도면이다. 도 2는 본 발명의 실시예에 따른 도메인 한정 생체 리딩 방법을 도시한 흐름도이다. 도 3 내지 도 11은 본 발명의 실험예에 따른 도면이다."}
