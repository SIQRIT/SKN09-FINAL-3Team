{"patent_id": "10-2020-0189058", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2022-0096531", "출원번호": "10-2020-0189058", "발명의 명칭": "빅데이터 분석을 위한 인공지능 기반의 클라우드 최적화 장치 및 방법", "출원인": "국민대학교산학협력단", "발명자": "이경용"}}
{"patent_id": "10-2020-0189058", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "희소행렬의 특징과 클라우드 인스턴스의 특성을 기초로 성능예측 모델을 구축하는 성능예측 모델 구축부;사용자 단말로부터 입력 데이터 특성 및 기계학습 알고리즘에 관한 사용자 입력을 수신하는 사용자 입력수신부;상기 사용자 입력에 대응되는 입력 희소행렬 곱셈을 정의하는 희소행렬 곱셈 정의부; 및상기 성능예측 모델을 이용하여 상기 입력 희소행렬 곱셈을 실행하기 위한 최적 클라우드 인스턴스를 결정하는클라우드 인스턴스 결정부를 포함하는 빅데이터 분석을 위한 인공지능 기반의 클라우드 최적화 장치."}
{"patent_id": "10-2020-0189058", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 성능예측 모델 구축부는모델 데이터 모집단을 기초로 상기 희소행렬의 특징에 관한 특징 집합을 생성하고,상기 특징 집합은 행렬의 원소 개수, 0이 아닌 원소 개수, 0이 아닌 원소 개수의 합 및 전체 곱셈의 실행 수를포함하는 것을 특징으로 하는 빅데이터 분석을 위한 인공지능 기반의 클라우드 최적화 장치."}
{"patent_id": "10-2020-0189058", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서, 상기 성능예측 모델 구축부는모델 데이터 모집단을 기초로 상기 클라우드 인스턴스의 특성에 관한 특성 집합을 생성하고,상기 특성 집합은 CPU 코어수, CPU 클락 속도, 메모리 크기, 디스크 및 네트워크 대역폭을 포함하는 것을 특징으로 하는 빅데이터 분석을 위한 인공지능 기반의 클라우드 최적화 장치."}
{"patent_id": "10-2020-0189058", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서, 상기 성능예측 모델 구축부는상기 특징 집합과 상기 특성 집합을 기초로 복수의 제1 러너들(first learners)을 결합하여 제2 러너(secondlearner)를 생성하는 앙상블 러닝(ensemble learning)을 수행하는 것을 특징으로 하는 빅데이터 분석을 위한 인공지능 기반의 클라우드 최적화 장치."}
{"patent_id": "10-2020-0189058", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서, 상기 성능예측 모델 구축부는그라디언트 부스팅 리그레서(Gradient Boosting Regressor) 기반의 앙상블 러닝을 통해 상기 복수의 제1 러너들을 상기 제2 러너로 결합하는 것을 특징으로 하는 빅데이터 분석을 위한 인공지능 기반의 클라우드 최적화장치."}
{"patent_id": "10-2020-0189058", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "공개특허 10-2022-0096531-3-제4항에 있어서, 상기 성능예측 모델 구축부는상기 제2 러너에 관한 베이지안 최적화(Bayesian Optimization)를 통해 하이퍼 파라미터(Hyper Parameter) 검색을 수행하여 상기 성능예측 모델을 생성하는 것을 특징으로 하는 빅데이터 분석을 위한 인공지능 기반의 클라우드 최적화 장치."}
{"patent_id": "10-2020-0189058", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에 있어서, 상기 사용자 입력 수신부는상기 사용자 단말로부터 상기 사용자 입력으로서 상기 희소행렬의 특성을 직접 수신하는 것을 특징으로 하는 빅데이터 분석을 위한 인공지능 기반의 클라우드 최적화 장치."}
{"patent_id": "10-2020-0189058", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1항에 있어서, 상기 희소행렬 곱셈 정의부는상기 입력 데이터 특성에 기초한 상기 기계학습 알고리즘의 수행 과정에서 가장 빈번하게 발생하는 희소행렬 곱셈을 상기 입력 희소행렬 곱셈으로 결정하는 것을 빅데이터 분석을 위한 인공지능 기반의 클라우드 최적화장치."}
{"patent_id": "10-2020-0189058", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1항에 있어서, 상기 클라우드 인스턴스 결정부는상기 성능예측 모델에 복수의 클라우드 인스턴스들을 적용하여 상기 입력 희소행렬 곱셈에 대한 실행시간을 각각 예측하고 상기 복수의 클라우드 인스턴스들 각각의 실행시간과 비용에 관한 성능 리스트를 생성하는 것을 특징으로 하는 빅데이터 분석을 위한 인공지능 기반의 클라우드 최적화 장치."}
{"patent_id": "10-2020-0189058", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9항에 있어서, 상기 클라우드 인스턴스 결정부는각 클라우드 인스턴스 별로 상기 실행시간과 상기 비용 간의 가중합을 산출하고 상기 가중합에 따라 상기 복수의 클라우드 인스턴스들을 정렬한 다음 상기 최적 클라우드 인스턴스를 결정하는 것을 특징으로 하는 빅데이터분석을 위한 인공지능 기반의 클라우드 최적화 장치."}
{"patent_id": "10-2020-0189058", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제1항에 있어서,상기 성능예측 모델을 이용하여 상기 입력 희소행렬 곱셈을 실행하기 위한 최적 곱셈 방법을 결정하는 곱셈 방법 결정부를 더 포함하는 것을 특징으로 하는 빅데이터 분석을 위한 인공지능 기반의 클라우드 최적화 장치."}
{"patent_id": "10-2020-0189058", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "희소행렬의 특징과 클라우드 인스턴스의 특성을 기초로 성능예측 모델을 구축하는 단계;사용자 단말로부터 입력 데이터 특성 및 기계학습 알고리즘에 관한 사용자 입력을 수신하는 단계;상기 사용자 입력에 대응되는 입력 희소행렬 곱셈을 정의하는 단계; 및상기 성능예측 모델을 이용하여 상기 입력 희소행렬 곱셈을 실행하기 위한 최적 클라우드 인스턴스를 결정하는공개특허 10-2022-0096531-4-단계를 포함하는 빅데이터 분석을 위한 인공지능 기반의 클라우드 최적화 방법."}
{"patent_id": "10-2020-0189058", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제12항에 있어서, 상기 성능예측 모델을 구축하는 단계는상기 희소행렬의 특징에 관한 특징 집합과 상기 클라우드 인스턴스의 특성에 관한 특성 집합을 기초로 복수의제1 러너들(first learners)을 결합하여 제2 러너(second learner)를 생성하는 앙상블 러닝(ensemblelearning)을 수행하여 상기 성능예측 모델을 구축하는 단계를 포함하는 것을 특징으로 하는 빅데이터 분석을 위한 인공지능 기반의 클라우드 최적화 방법."}
{"patent_id": "10-2020-0189058", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제12항에 있어서,상기 성능예측 모델을 이용하여 상기 입력 희소행렬 곱셈을 실행하기 위한 최적 곱셈 방법을 결정하는 단계를더 포함하는 것을 특징으로 하는 빅데이터 분석을 위한 인공지능 기반의 클라우드 최적화 방법."}
{"patent_id": "10-2020-0189058", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제14항에 있어서, 상기 최적 곱셈 방법을 결정하는 단계는상기 최적 클라우드 인스턴스의 각 작업 노드 별로 상기 입력 희소행렬 곱셈을 실행하는 최적의 희소행렬 곱셈방법을 결정하는 단계를 포함하는 것을 특징으로 하는 빅데이터 분석을 위한 인공지능 기반의 클라우드 최적화방법."}
{"patent_id": "10-2020-0189058", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 빅데이터 분석을 위한 인공지능 기반의 클라우드 최적화 장치 및 방법에 관한 것으로, 상기 장치는 희 소행렬의 특징과 클라우드 인스턴스의 특성을 기초로 희소행렬 곱셈의 성능을 예측하는 성능예측 모델을 구축하 는 성능예측 모델 구축부; 사용자 단말로부터 입력 데이터 특성 및 기계학습 알고리즘에 관한 사용자 입력을 수 신하는 사용자 입력 수신부; 상기 사용자 입력에 대응되는 입력 희소행렬 곱셈을 정의하는 희소행렬 곱셈 정의부; 및 상기 성능예측 모델을 이용하여 상기 입력 희소행렬 곱셈을 실행하기 위한 최적 클라우드 인스턴스를 결정하는 클라우드 인스턴스 결정부를 포함한다."}
{"patent_id": "10-2020-0189058", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 클라우드 최적화 기술에 관한 것으로, 보다 상세하게는 기계학습 알고리즘에 널리 활용되는 희소행렬 연산을 클라우드 환경에서 최적화 해주는 빅데이터 분석을 위한 인공지능 기반의 클라우드 최적화 장치 및 방법 에 관한 것이다."}
{"patent_id": "10-2020-0189058", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "최근 하드웨어 및 소프트웨어 시스템 기술의 향상은 과거에 불가능했던 대규모 데이터 집합의 처리를 가능하게 만들었다. 시스템들은 증가하는 빅데이터 분석 어플리케이션들의 수를 수용하기 위하여 운영 작업들을 통해 오 버헤드를 줄임으로써 확장성과 내결함성을 제공하는 클라우드 컴퓨팅 환경을 점점 더 많이 적용하고 있다. 클라 우드 컴퓨팅 서비스는 다양한 인스턴스에 고유한 하드웨어 구성을 제공하고, 많은 빅데이터 처리 소프트웨어 플 랫폼은 이러한 리소스를 스케일 아웃 방식으로 사용할 수 있다. 희소행렬의 곱셈은 매우 많은 기계학습 알고리즘에서 활용되고 있는 기술이며, 대규모 빅데이터로부터 의미 있 는 정보를 추출해내는데 필수적인 단계이다. 희소행렬 곱셈은 왼쪽, 오른쪽 2개의 행렬을 곱하게 되며 각 행렬 의 표현법 (희소행렬 유지 혹은 dense 행렬로 변환), 이에 따른 곱셈 작업을 분배하는 방법 (Outer, Inner, IndexedRow, Block), 연산 작업이 발생하는 클라우드 인스턴스 타입에 따라서 큰 성능 차이를 보여주는 특징이 있다. 한편, 일반적인 사용자가 기계학습 알고리즘의 특징, 행렬 곱셈의 성능 특징, 클라우드 인스턴스의 특징 등을 이해하여 최적의 환경을 구축하는 것은 불가능에 가깝다.선행기술문헌 특허문헌 (특허문헌 0001) 한국 등록특허공보 제10-0909510(2009.07.20)호"}
{"patent_id": "10-2020-0189058", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명의 일 실시예는 기계학습 알고리즘에 널리 활용되는 희소행렬 연산을 클라우드 환경에서 최적화 해주는 빅데이터 분석을 위한 인공지능 기반의 클라우드 최적화 장치 및 방법을 제공하고자 한다. 본 발명의 일 실시예는 희소행렬의 특징과 클라우드 인스턴스의 특성을 기초로 시간 및 비용에 관한 최적의 클 라우드 인스턴스를 사용자에게 추천하여 빅데이터 분석 작업의 시간을 줄이고 비용을 절감할 수 있는 빅데이터 분석을 위한 인공지능 기반의 클라우드 최적화 장치 및 방법을 제공하고자 한다."}
{"patent_id": "10-2020-0189058", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "실시예들 중에서, 빅데이터 분석을 위한 인공지능 기반의 클라우드 최적화 장치는 희소행렬의 특징과 클라우드 인스턴스의 특성을 기초로 성능예측 모델을 구축하는 성능예측 모델 구축부; 사용자 단말로부터 입력 데이터 특 성 및 기계학습 알고리즘에 관한 사용자 입력을 수신하는 사용자 입력 수신부; 상기 사용자 입력에 대응되는 입 력 희소행렬 곱셈을 정의하는 희소행렬 곱셈 정의부; 및 상기 성능예측 모델을 이용하여 상기 입력 희소행렬 곱 셈을 실행하기 위한 최적 클라우드 인스턴스를 결정하는 클라우드 인스턴스 결정부를 포함한다. 상기 성능예측 모델 구축부는 모델 데이터 모집단을 기초로 상기 희소행렬의 특징에 관한 특징 집합을 생성하고, 상기 특징 집합은 행렬의 원소 개수, 0이 아닌 원소 개수, 0이 아닌 원소 개수의 합 및 전체 곱셈의 실행 수를 포함할 수 있다. 상기 성능예측 모델 구축부는 모델 데이터 모집단을 기초로 상기 클라우드 인스턴스의 특성에 관한 특성 집합을 생성하고, 상기 특성 집합은 CPU 코어수, CPU 클락 속도, 메모리 크기, 디스크 및 네트워크 대역폭을 포함할 수 있다. 상기 성능예측 모델 구축부는 상기 특징 집합과 상기 특성 집합을 기초로 복수의 제1 러너들(first learners)을 결합하여 제2 러너(second learner)를 생성하는 앙상블 러닝(ensemble learning)을 수행할 수 있다. 상기 성능예측 모델 구축부는 그라디언트 부스팅 리그레서(Gradient Boosting Regressor) 기반의 앙상블 러닝을 통해 상기 복수의 제1 러너들을 상기 제2 러너로 결합할 수 있다. 상기 성능예측 모델 구축부는 상기 제2 러너에 관한 베이지안 최적화(Bayesian Optimization)를 통해 하이퍼 파 라미터(Hyper Parameter) 검색을 수행하여 상기 성능예측 모델을 생성할 수 있다. 상기 사용자 입력 수신부는 상기 사용자 단말로부터 상기 사용자 입력으로서 상기 희소행렬의 특성을 직접 수신 할 수 있다. 상기 희소행렬 곱셈 정의부는 상기 입력 데이터 특성에 기초한 상기 기계학습 알고리즘의 수행 과정에서 가장 빈번하게 발생하는 희소행렬 곱셈을 상기 입력 희소행렬 곱셈으로 결정할 수 있다. 상기 클라우드 인스턴스 결정부는 상기 성능예측 모델에 복수의 클라우드 인스턴스들을 적용하여 상기 입력 희 소행렬 곱셈에 대한 실행시간을 각각 예측하고 상기 복수의 클라우드 인스턴스들 각각의 실행시간과 비용에 관 한 성능 리스트를 생성할 수 있다. 상기 클라우드 인스턴스 결정부는 각 클라우드 인스턴스 별로 상기 실행시간과 상기 비용 간의 가중합을 산출하 고 상기 가중합에 따라 상기 복수의 클라우드 인스턴스들을 정렬한 다음 상기 최적 클라우드 인스턴스를 결정할수 있다. 상기 장치는 상기 성능예측 모델을 이용하여 상기 입력 희소행렬 곱셈을 실행하기 위한 최적 곱셈 방법을 결정 하는 곱셈 방법 결정부를 더 포함할 수 있다. 실시예들 중에서, 빅데이터 분석을 위한 인공지능 기반의 클라우드 최적화 방법은 희소행렬의 특징과 클라우드 인스턴스의 특성을 기초로 희소행렬 곱셈의 성능을 예측하는 성능예측 모델을 구축하는 단계; 사용자 단말로부 터 입력 데이터 특성 및 기계학습 알고리즘에 관한 사용자 입력을 수신하는 단계; 상기 사용자 입력에 대응되는 입력 희소행렬 곱셈을 정의하는 단계; 및 상기 성능예측 모델을 이용하여 상기 입력 희소행렬 곱셈을 실행하기 위한 최적 클라우드 인스턴스를 결정하는 단계를 포함한다. 상기 성능예측 모델을 구축하는 단계는 상기 희소행렬의 특징에 관한 특징 집합과 상기 클라우드 인스턴스의 특 성에 관한 특성 집합을 기초로 복수의 제1 러너들(first learners)을 결합하여 제2 러너(second learner)를 생 성하는 앙상블 러닝(ensemble learning)을 수행하여 상기 성능예측 모델을 구축하는 단계를 포함할 수 있다. 상기 방법은 상기 성능예측 모델을 이용하여 상기 입력 희소행렬 곱셈을 실행하기 위한 최적 곱셈 방법을 결정 하는 단계를 더 포함할 수 있다. 상기 최적 곱셈 방법을 결정하는 단계는 상기 최적 클라우드 인스턴스의 각 작업 노드 별로 상기 입력 희소행렬 곱셈을 실행하는 최적의 희소행렬 곱셈 방법을 결정하는 단계를 포함할 수 있다."}
{"patent_id": "10-2020-0189058", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "개시된 기술은 다음의 효과를 가질 수 있다. 다만, 특정 실시예가 다음의 효과를 전부 포함하여야 한다거나 다 음의 효과만을 포함하여야 한다는 의미는 아니므로, 개시된 기술의 권리범위는 이에 의하여 제한되는 것으로 이 해되어서는 아니 될 것이다. 본 발명의 일 실시예에 따른 빅데이터 분석을 위한 인공지능 기반의 클라우드 최적화 장치 및 방법은 기계학습 알고리즘에 널리 활용되는 희소행렬 연산을 클라우드 환경에서 최적화할 수 있다. 본 발명의 일 실시예에 따른 빅데이터 분석을 위한 인공지능 기반의 클라우드 최적화 장치 및 방법은 희소행렬 의 특징과 클라우드 인스턴스의 특성을 기초로 시간 및 비용에 관한 최적의 클라우드 인스턴스를 사용자에게 추 천하여 빅데이터 분석 작업의 시간을 줄이고 비용을 절감할 수 있다."}
{"patent_id": "10-2020-0189058", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명에 관한 설명은 구조적 내지 기능적 설명을 위한 실시예에 불과하므로, 본 발명의 권리범위는 본문에 설 명된 실시예에 의하여 제한되는 것으로 해석되어서는 아니 된다. 즉, 실시예는 다양한 변경이 가능하고 여러 가 지 형태를 가질 수 있으므로 본 발명의 권리범위는 기술적 사상을 실현할 수 있는 균등물들을 포함하는 것으로이해되어야 한다. 또한, 본 발명에서 제시된 목적 또는 효과는 특정 실시예가 이를 전부 포함하여야 한다거나 그러한 효과만을 포함하여야 한다는 의미는 아니므로, 본 발명의 권리범위는 이에 의하여 제한되는 것으로 이해 되어서는 아니 될 것이다. 한편, 본 출원에서 서술되는 용어의 의미는 다음과 같이 이해되어야 할 것이다. \"제1\", \"제2\" 등의 용어는 하나의 구성요소를 다른 구성요소로부터 구별하기 위한 것으로, 이들 용어들에 의해 권리범위가 한정되어서는 아니 된다. 예를 들어, 제1 구성요소는 제2 구성요소로 명명될 수 있고, 유사하게 제2 구성요소도 제1 구성요소로 명명될 수 있다. 어떤 구성요소가 다른 구성요소에 \"연결되어\"있다고 언급된 때에는, 그 다른 구성요소에 직접적으로 연결될 수 도 있지만, 중간에 다른 구성요소가 존재할 수도 있다고 이해되어야 할 것이다. 반면에, 어떤 구성요소가 다른 구성요소에 \"직접 연결되어\"있다고 언급된 때에는 중간에 다른 구성요소가 존재하지 않는 것으로 이해되어야 할 것이다. 한편, 구성요소들 간의 관계를 설명하는 다른 표현들, 즉 \"~사이에\"와 \"바로 ~사이에\" 또는 \"~에 이웃 하는\"과 \"~에 직접 이웃하는\" 등도 마찬가지로 해석되어야 한다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한 복수의 표현을 포함하는 것으로 이해되어야 하고, \"포함 하다\"또는 \"가지다\" 등의 용어는 실시된 특징, 숫자, 단계, 동작, 구성요소, 부분품 또는 이들을 조합한 것이 존재함을 지정하려는 것이며, 하나 또는 그 이상의 다른 특징이나 숫자, 단계, 동작, 구성요소, 부분품 또는 이 들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되어야 한다. 각 단계들에 있어 식별부호(예를 들어, a, b, c 등)는 설명의 편의를 위하여 사용되는 것으로 식별부호는 각 단 계들의 순서를 설명하는 것이 아니며, 각 단계들은 문맥상 명백하게 특정 순서를 기재하지 않는 이상 명기된 순 서와 다르게 일어날 수 있다. 즉, 각 단계들은 명기된 순서와 동일하게 일어날 수도 있고 실질적으로 동시에 수 행될 수도 있으며 반대의 순서대로 수행될 수도 있다. 본 발명은 컴퓨터가 읽을 수 있는 기록매체에 컴퓨터가 읽을 수 있는 코드로서 구현될 수 있고, 컴퓨터가 읽을 수 있는 기록 매체는 컴퓨터 시스템에 의하여 읽혀질 수 있는 데이터가 저장되는 모든 종류의 기록 장치를 포함 한다. 컴퓨터가 읽을 수 있는 기록 매체의 예로는 ROM, RAM, CD-ROM, 자기 테이프, 플로피 디스크, 광 데이터 저장 장치 등이 있다. 또한, 컴퓨터가 읽을 수 있는 기록 매체는 네트워크로 연결된 컴퓨터 시스템에 분산되어, 분산 방식으로 컴퓨터가 읽을 수 있는 코드가 저장되고 실행될 수 있다. 여기서 사용되는 모든 용어들은 다르게 정의되지 않는 한, 본 발명이 속하는 분야에서 통상의 지식을 가진 자에 의해 일반적으로 이해되는 것과 동일한 의미를 가진다. 일반적으로 사용되는 사전에 정의되어 있는 용어들은 관 련 기술의 문맥상 가지는 의미와 일치하는 것으로 해석되어야 하며, 본 출원에서 명백하게 정의하지 않는 한 이 상적이거나 과도하게 형식적인 의미를 지니는 것으로 해석될 수 없다. 행렬 곱셈(Matrix Multiplication)에 대한 성능 예측은 클라우드 컴퓨팅 환경에서 행렬 곱셈에 소요되는 시간을 산출함으로써 수행될 수 있다. 즉, 임의의 행렬들 간의 곱셈에 대한 성능을 예측하는 방법은 성능 예측 모델을 생성하고 성능 예측 모델을 이용하여 행렬 곱셈에 대한 소요 시간을 예측하는 것에 해당할 수 있다. 성능 예측 모델은 행렬 곱셈의 연산 시간에 가장 큰 영향을 미치는 행렬 특성을 입력 데이터로 하고 해당 행렬 특성을 가 진 행렬들 간의 행렬 곱셈에 소요되는 예상 시간을 출력 데이터로 하는 학습 데이터들을 기계 학습하여 생성된 학습 결과에 해당할 수 있다. 행렬 곱셈 성능 예측은 핵심적인 구성이라고 할 수 있는 성능 예측 모델 구축을 통해 수행될 수 있고, 학습 데 이터 집합 생성 단계, 특징 추출 단계 및 모델링 작업 단계로 구성될 수 있으며, 각 단계별로 수행되는 동작은 다음과 같다. 1) 학습 데이터 집합 생성 단계 학습 데이터 집합 생성 단계에서 행렬 곱셈 성능 예측은 성능 예측 모델을 구축하기 위해 다양한 형상과 크기의 행렬 곱셈에 관한 프로파일링을 수행할 수 있다. 보다 구체적으로, 행렬 곱셈 성능 예측은 학습에 사용될 학습 데이터를 생성하기 위하여 행렬 곱셈의 다양한 유형들에 속하는 행렬 곱셈 작업을 생성할 수 있다. 행렬 곱셈 성능 예측은 모든 형상과 크기의 행렬들을 처리하기 위해 행렬 곱셈 작업에 대해 왼쪽 및 오른쪽 행렬들 간의 행렬 곱셈 연산에 소요되는 예상 연산시간을 포함하는 프로파일을 수집하여 학습 프로파일링을 수행할 수 있다. 행렬 곱셈 작업은 왼쪽 및 오른쪽 행렬의 형상과 크기에 따라 정사각형 행렬들 간의 곱셈(square X square), 길 고 얇은 직사각형 행렬과 짧고 넓은 직사각형 행렬 간의 곱셈(long-thin X short-wide) 및 짧고 넓은 직사각형 행렬과 길고 얇은 직사각형 행렬 간의 곱셈(short-wide X long-thin)으로 크게 분류될 수 있다. 또한, 행렬 곱 셈 성능 예측은 행렬 곱셈에 소요되는 연산시간 측정에 있어서 JSON 형식의 다양한 실행 지표들을 제공하는 Apache Spark web UI REST API를 사용할 수 있으며, 반드시 이에 한정되지 않고, 다양한 분산 인공지능 연산 프 로그램을 사용할 수 있다. 행렬 곱셈 성능 예측은 서로 다른 용량을 가진 다양한 클라우드 컴퓨팅 인스턴스(instance)들에 대해 최적의 성 능을 얻기 위해 GPU 장치를 사용하는 인스턴스에서는 행렬 곱셈을 수행할 때 NVBLAS 라이브러리(Library)를 사 용하고 CPU 장치를 사용하는 인스턴스의 경우 OpenBLAS를 사용할 수 있다. 또한, 행렬 곱셈 성능 예측은 Spark 가 하드웨어 최적화 선형 대수 라이브러리와 상호 작용할 수 있도록 netlib-java library를 사용할 수 있다. 행 렬 곱셈 성능 예측은 반드시 이에 한정되지 않고 다양한 분산 인공지능 연산 프로그램을 사용할 수 있다. 2) 특징 추출 단계 분산 컴퓨팅 환경에서의 행렬 곱셈의 오버헤드(overhead)는 다양한 자원들에 영향을 받을 수 있다. 행렬 곱셈 성능 측정은 다양한 오버헤드를 처리하기 위해 입력 행렬 블록들의 차원(dimension)과 곱셈(product)을 사용할 수 있고, 예를 들어, lr, lc, rc, lr*rc, lr*lc, lc*rc, lr*lc+lc*rc 및 lr*lc*rc 등을 행렬 곱셈 성능을 모델 링하기 위한 행렬 특성들로서 사용할 수 있다. 여기에서, lr*rc는 출력 행렬의 크기를 나타내고, lr*lr 및 lc*rc는 각각 네트워크 오버헤드 및 입출력 디스크 오버헤드에 영향을 미치는 왼쪽 및 오른쪽 행렬 블록의 크기 를 나타낼 수 있다. lr*lc*rc는 행렬 곱셈에서 수행되는 곱셈 연산의 총 수를 나타낼 수 있다. 3) 모델링 작업 단계 모델링 작업 단계에서, 행렬 곱셈 성능 예측은 다양한 행렬들을 곱하는 성능을 예측할 수 있는 성능 예측 모델 을 구축할 수 있다. 모델링 작업 단계는 모델 구축 단계 및 하이퍼 파라미터(hyper-parameter) 검색 단계로 구 성될 수 있다. 행렬 곱셈 성능 예측은 모델 구축 단계를 위해 GB(Gradient Boost) regressor를 사용할 수 있고, GB 방법(method)에 대한 최적의 파라미터들을 찾기 위해 베이지안 최적화(Bayesian Optimization)를 사용할 수 있다. GB 방법은 분류 및 회귀에 대한 유연한 비모수 통계적 학습 접근법이다. GB 방법의 주된 아이디어는 특징들 간 의 복잡하고 비선형적인 상호작용들을 모델링하기 위해 점진적으로 간단한 선형 관계에만 일반적으로 적용할 수 있는 여러 개의 약한 학습기를 결합하는 것이다. GB 모델은 정방향 단계별 패턴으로 되어 있고, 각 단계에서 새 로운 약한 학습기 모델이 현재 모델의 나머지 부분에 적용되며, GB 모델은 이전 반복에 대한 오류를 수정하는데 더 중점을 둘 수 있다. 성능 예측 모델을 구축할 때 모델 파라미터들을 적절하게 설정하는 것이 예측 품질을 향상시키는데 매우 중요할 수 있다. 랜덤워크(random walk), 그리드 기반 검색(grid based search) 및 통계적 추론 (statistical inference) 등의 많은 휴리스틱(heuristic) 방법들은 최상의 성능을 발휘하는 하이퍼 파라미터를 검색하기 위해 제안되고 있다. 행렬 곱셈 성능 예측은 베이지안 모델에 기반한 통계적 추론 방법을 사용할 수 있다. 베이지안 최적화 방법은 모델 품질을 향상시키거나 불확실성을 줄일 수 있는 다음 단계의 구성 값들에 관한 집합을 검색 할 수 있다. 한편, 희소행렬 곱셈(Sparse Matrix Multiplication, SPMM)도 다양한 기계학습 알고리즘에 널리 사용되고 있다. 대규모 데이터 세트를 사용하는 SPMM의 응용 프로그램이 보편화됨에 따라 최적화된 설정에서 SPMM 작업을 실행하는 것은 매우 중요할 수 있다. 클라우드 리소스에서 분산된 SPMM 작업의 실행 환경은 입력 희소 데이터 세트, 고유한 SPMM 구현 방법 및 클라우드 인스턴스 유형의 선택에 따라 다양한 방식으로 수행될 수 있다. 희소행렬 곱셈에 대한 성능 예측도 상기에서 설명하는 행렬 곱셈에 대한 성능 예측 과정을 활용하여 수행될 수 있다. 다만, 희소행렬의 특징과 다양한 클라우드 인스턴스의 특성을 반영하기 위하여 학습 데이터 집합 생성 단 계와 특징 추출 단계에서 소정의 변경이 필요하고 이에 기반하여 모델링 작업 단계를 수행할 필요가 있다. 본 발명에 따른 클라우드 최적화 방법은 임의의 SPMM 작업에 대한 지연시간(또는 실행시간)을 정확하게 예측하고 최적의 구현 방법을 추천할 수 있다. 또한, 본 발명에 따른 클라우드 최적화 방법은 기존의 Apache Spark의 기 본 SPMM 구현에 비해 SPMM 작업을 완료하는 데 44% 더 적은 대기 시간을 기대할 수 있다.이하, 첨부된 도면들을 참조하여 본 발명의 바람직한 실시예를 상세하게 설명한다. 도 1은 본 발명에 따른 클라우드 최적화 시스템을 설명하는 도면이다. 도 1을 참조하면, 클라우드 최적화 시스템은 사용자 단말, 클라우드 최적화 장치 및 데이터베이 스를 포함할 수 있다. 사용자 단말은 클라우드 최적화 장치에 희소행렬에 관한 곱셈 연산을 필수적으로 요구하는 기계학습 알고리즘의 실행을 요청할 수 있는 컴퓨팅 장치에 해당할 수 있다. 또한, 사용자는 사용자 단말을 통해 해 당 요청을 처리하기 위한 클라우드 서비스를 이용할 수 있으며, 이를 위한 구체적인 요청 사항을 입력할 수 있 다. 예를 들어, 사용자는 사용자 단말을 통해 입력 데이터 정보, 기계학습 알고리즘에 관한 구체적 정보를 입력할 수 있으며, 이를 처리하기 위한 클라우드 인스턴스를 선택할 수 있다. 한편, 사용자 단말은 스마트폰, 노트북 또는 컴퓨터로 구현될 수 있으며, 반드시 이에 한정되지 않고, 태 블릿 PC 등 다양한 디바이스로도 구현될 수 있다. 사용자 단말은 클라우드 최적화 장치와 네트워크를 통해 연결될 수 있고, 복수의 사용자 단말들은 클라우드 최적화 장치와 동시에 연결될 수 있다. 클라우드 최적화 장치는 사용자 단말로부터 기계학습에 관한 인공지능 연산 서비스 요청을 수신하고, 인공지능을 구현할 때 필수적인 희소행렬의 곱셈 연산에 소요되는 실행시간을 예측하여 최적의 클라우드 컴퓨팅 서비스를 제공할 수 있는 컴퓨터 또는 프로그램에 해당하는 서버로 구현될 수 있다. 즉, 클라우드 최적화 장치 는 사용자의 요청 사항을 최소의 시간과 최소의 비용으로 처리할 수 있는 최적의 클라우드 인스턴스를 추 천할 수 있고, 사용자의 선택에 따라 인공지능에 관한 학습과 서비스를 제공할 수 있다. 또한, 클라우드 최적화 장치는 분산 컴퓨팅 기반으로 동작되는 적어도 하나의 클라우드 서버로 구현될 수 있으며, 이를 통해 제공되는 클라우드 인스턴스는 적어도 하나의 클라우드 서버에 분산된 가용 자원을 기초로 구현되어 서비스 동작을 수행할 수 있다. 클라우드 최적화 장치는 사용자 단말과 유선 네트워크 또는 블루투스, WiFi 등과 같은 무선 네트워크로 연결될 수 있고, 유선 또는 무선 네트워크를 통해 사용자 단말(11 0)과 통신을 수행할 수 있다. 또한, 클라우드 최적화 장치는 데이터베이스와 연동하여 희소행렬 곱셈의 연산성능을 예측하고 최적 클라우드 인스턴스를 추천하는 과정에서 다양한 형태로 수집 또는 가공된 정보들을 저장할 수 있다. 한편, 클라 우드 최적화 장치는 도 1과 달리, 데이터베이스를 내부에 포함하여 구현될 수 있으며, 별도의 외부 시스템과 연결되어 동작할 수도 있다. 예를 들어, 외부 시스템은 성능예측 모델 구축을 위한 독립된 학습 서버 에 해당할 수 있고, 클라우드 최적화 장치는 외부 시스템과 연동하여 기 구축된 성능예측 모델을 이용하여 구체적인 동작을 수행할 수 있다. 도 2는 도 1의 클라우드 최적화 장치의 시스템 구성을 설명하는 도면이다. 도 2를 참조하면, 클라우드 최적화 장치는 프로세서, 메모리, 사용자 입출력부 및 네트워 크 입출력부를 포함하여 구현될 수 있다. 프로세서는 클라우드 최적화 장치가 동작하는 과정에서의 각 단계들을 처리하는 프로시저를 실행할 수 있고, 그 과정 전반에서 읽혀지거나 작성되는 메모리를 관리할 수 있으며, 메모리에 있는 휘발성 메모리와 비휘발성 메모리 간의 동기화 시간을 스케줄할 수 있다. 프로세서는 클라우드 최적화 장치 의 동작 전반을 제어할 수 있고, 메모리, 사용자 입출력부 및 네트워크 입출력부와 전기적으로 연결되어 이들 간의 데이터 흐름을 제어할 수 있다. 프로세서는 클라우드 최적화 장치의 CPU(Central Processing Unit)로 구현될 수 있다. 메모리는 SSD(Solid State Drive) 또는 HDD(Hard Disk Drive)와 같은 비휘발성 메모리로 구현되어 클라우 드 최적화 장치에 필요한 데이터 전반을 저장하는데 사용되는 보조기억장치를 포함할 수 있고, RAM(Random Access Memory)과 같은 휘발성 메모리로 구현된 주기억장치를 포함할 수 있다. 사용자 입출력부는 사용자 입력을 수신하기 위한 환경 및 사용자에게 특정 정보를 출력하기 위한 환경을 포함할 수 있다. 예를 들어, 사용자 입출력부는 터치 패드, 터치 스크린, 화상 키보드 또는 포인팅 장치와 같은 어댑터를 포함하는 입력장치 및 모니터 또는 터치스크린과 같은 어댑터를 포함하는 출력장치를 포함할 수있다. 일 실시예에서, 사용자 입출력부는 원격 접속을 통해 접속되는 컴퓨팅 장치에 해당할 수 있고, 그러 한 경우, 클라우드 최적화 장치는 독립적인 서버로서 수행될 수 있다. 네트워크 입출력부은 네트워크를 통해 외부 장치 또는 시스템과 연결하기 위한 환경을 포함하고, 예를 들 어, LAN(Local Area Network), MAN(Metropolitan Area Network), WAN(Wide Area Network) 및 VAN(Value Added Network) 등의 통신을 위한 어댑터를 포함할 수 있다. 도 3은 도 1의 클라우드 최적화 장치의 기능적 구성을 설명하는 도면이다. 도 3을 참조하면, 클라우드 최적화 장치는 성능예측 모델 구축부, 사용자 입력 수신부, 희소행 렬 곱셈 정의부, 클라우드 인스턴스 결정부, 곱셈 방법 결정부 및 제어부(도 3에 미도시함)를 포함할 수 있다. 성능예측 모델 구축부는 희소행렬의 특징과 클라우드 인스턴스의 특성을 기초로 희소행렬 곱셈의 성능을 예측하는 성능예측 모델을 구축할 수 있다. 성능예측 모델 구축부에 의해 구축된 성능예측 모델은 사용자 가 입력한 입력 데이터 특성, 기계학습 알고리즘 또는 입력 행렬 정보에 기초하여 희소행렬 곱셈(SPMM)의 구현 방법과 클라우드 인스턴스 유형(type)에 관한 다양한 환경에서의 지연시간(또는 실행시간)을 예측할 수 있다. 일 실시예에서, 성능예측 모델 구축부는 모델 데이터 모집단을 기초로 희소행렬의 특징에 관한 특징 집합 을 생성할 수 있다. 이때, 특징 집합은 행렬의 원소 개수, 0이 아닌 원소 개수, 0이 아닌 원소 개수의 합 및 전 체 곱셈의 실행 수를 포함할 수 있다. 희소행렬 곱셈의 성능 예측을 위해 성능에 영향을 줄 수 있는 다양한 특 징 정보를 고려할 필요가 있으며, 특징 집합은 이러한 특징 정보들로 구성될 수 있다. 보다 구체적으로, 특징 집합은 희소행렬의 곱셈에 참여하는 왼쪽 및 오른쪽 행렬의 차원(dimension)에 관한 lr, lc 및 rc를 포함할 수 있다. 여기에서, lr, lc 및 rc는 각각 왼쪽 행렬의 행과 열의 수, 오른쪽 행렬의 열의 수 에 해당할 수 있다. 또한, 성능예측 모델의 목표 워크로드(target workload)는 희소행렬이기 때문에 행렬의 밀 도도 고려해야 할 중요한 요소에 해당할 수 있다. 즉, 특징 집합은 l-density 및 r-density를 포함할 수 있다. 여기에서, l-density 및 r-density는 각각 왼쪽 행렬 및 오른쪽 행렬의 밀도에 해당할 수 있다. 또한, 특징 집합은 l-nnz(nonzero) 및 r-nnz를 포함할 수 있다. 여기에서, l-nnz 및 r-nnz는 각각 왼쪽 행렬 및 오른쪽 행렬의 0이 아닌 원소 수에 해당할 수 있다. 이때, 행렬의 nnz는 밀도(density) 특징에 이미 반영될 수 있다. 왜냐하면, 행렬의 밀도는 nnz를 행렬의 총 원소 수로 나누어 산출되기 때문이다. 예를 들어, 왼쪽 행 렬의 밀도(l-density)는 l-nnz를 총 원소 수(lr×lc)로 나누어 산출될 수 있다. 이러한 상관관계는 대규모 데이 터 세트에 대한 모델링 과정에서 반영될 수 있다. 또한, 특징 집합은 lr×rc를 포함할 수 있으며, lr×rc는 희소행렬 곱셈의 출력 행렬의 차원(dimension)에 해당 할 수 있다. 또한, 특징 집합은 l-nnz+r-nnz를 포함할 수 있으며, l-nnz+r-nnz는 계산 중 모든 노드에 대한 셔 플링(shuffling) 오버헤드에 해당할 수 있다. 또한, 특징 집합은 l-nnz×r-nnz를 포함할 수 있으며, l-nnz×r- nnz는 희소행렬 포맷(format)에서 곱(product) 연산의 실제 횟수에 해당할 수 있다. 또한, 특징 집합은 lr×lc 및 lr×lc +lc×rc를 포함할 수 있으며, lr×lc 및 lr×lc +lc×rc는 각각 곱 연산의 총 횟수와 셔플 오버헤드 에 해당할 수 있다. 일 실시예에서, 특징 집합은 서로 다른 희소행렬 곱셈 방법에 적용 가능한 통합된 모델을 구축하기 위하여 범주 화된 'method' 특징을 포함할 수 있다(도 5 참조). 일 실시예에서, 성능예측 모델 구축부는 모델 데이터 모집단을 기초로 클라우드 인스턴스의 특성에 관한 특성 집합을 생성할 수 있다. 이때, 특성 집합은 CPU 코어수, CPU 클락 속도, 메모리 크기, 디스크, 및 네트워 크 대역폭(bandwidth)을 포함할 수 있다. 즉, 특성 집합은 다양한 클라우드 인스턴스들의 특성(characteristi c)들을 표현하기 위하여 상기와 같은 하드웨어 특징들을 포함할 수 있다. 일 실시예에서, 성능예측 모델 구축부는 특징 집합과 특성 집합을 기초로 복수의 제1 러너들(first learners)을 결합하여 제2 러너(second learner)를 생성하는 앙상블 러닝(ensemble learning)을 수행할 수 있 다. 여기에서, 제1 러너들(first learners) 및 제2 러너(second learner)는 각각 위크 러너들(weak learners) 및 스트롱 러너(strong learner)에 해당할 수 있다. 위크 러너들(weak learners)은 스트롱 러너에 비해 낮은 예 측 정확도를 가지는 학습(예측)자들의 집합에 해당할 수 있고, 스트롱 러너(strong learner)는 상대적으로 높은예측 정확도를 가지는 학습자에 해당할 수 있다. 보다 구체적으로, 성능예측 모델 구축부는 각각 특징 집합 및 특성 집합의 특징 및 특성 데이터를 기초로 복수의 위크 러너들을 결정하고 앙상블 러닝을 수행하여 스트롱 러너를 생성할 수 있다. 여기에서, 앙상블 러닝 (ensemble learning)은 여러 기계학습 알고리즘들을 각각 사용하는 경우에 비해 더 좋은 예측 성능을 얻기 위해, 다수의 기계학습 알고리즘을 사용하고 그 결과들을 조합하는 머신러닝(machine learning) 기법에 해당할 수 있다. 보다 구체적으로, 앙상블 러닝은 배깅(bagging)과 부스팅(boosting)의 두가지 방법을 통해 수행될 수 있다. 배 깅(bagging)은 bootstrap aggregating의 약자로, 부트스트랩(bootstrap)을 통해 조금씩 다른 훈련 데이터에 대 해 훈련된 복수의 위크 러너들을 결합(aggregating)시키는 방법이다. 여기에서, 부트스트랩은 주어진 훈련 데이 터에서 중복을 허용하여 원래 데이터와 같은 크기의 데이터를 만드는 과정을 의미할 수 있다. 즉, 배깅은 데이 터 샘플링을 통해 여러 개의 메타 데이터를 생성하고, 각 메타 데이터를 이용해 여러 개의 위크 러너들을 만들 며 최종적으로 각 위크 러너의 예측 결과를 평균하여 스트롱 러너로 결정할 수 있다. 예를 들어, 배깅은 랜덤 포레스트(random forest) 기반의 앙상블 러닝에서 사용될 수 있다. 부스팅은 메타 데이터로 여러 개의 위크 러너들을 순차적으로 생성하는데, 두번째 위크 러너는 첫번째 위크 러 너가 잘못 예측한 데이터에 가중치를 좀 더 주어서(boosting) 학습을 하고 최종적으로 마지막에 생성된 위크 러 너를 스트롱 러너로 결정할 수 있다. 예를 들어, 부스팅은 그라디언트 부스팅 리그레서(gradient boosting regressor) 기반의 앙상블 러닝에서 사용될 수 있다. 결과적으로, 성능예측 모델 구축부는 배깅과 부스팅 을 포함하는 앙상블 러닝을 수행하여 제1 러너들을 결합하여 제2 러너를 생성할 수 있다. 일 실시예에서, 성능예측 모델 구축부는 그라디언트 부스팅 리그레서(Gradient Boosting Regressor) 기반 의 앙상블 러닝을 통해 복수의 제1 러너들을 상기 제2 러너로 결합할 수 있다. 여기에서, 그라디언트 부스팅 리 그레서(GB regressor)는 분류 및 회귀에 대한 유연한 통계 학습 접근법에 해당하고 여러 개의 결정 트리를 묶어 강력한 모델을 만드는 앙상블 러닝 기법의 하나에 해당할 수 있다. 그라디언트 부스팅 리그레서는 랜덤 포레스 트와 마찬가지로 예측 모델을 구성하는 기본 요소로 결정 트리를 사용할 수 있다. 보다 구체적으로, 그라디언트 부스팅 리그레서는 주로 행렬 특성 간의 복잡하고 비선형적인 상호 작용을 모델링 하기 위해 점진적으로 간단한 선형 관계에만 일반적으로 적용 가능한 여러 개의 위크 러너들을 결합할 수 있다. 그라디언트 부스팅 리그레서는 스테이지 방식의 패턴으로 만들어지는데 각 단계에서 새로운 위크 러너 모델이 이전 모델의 오류를 수정한다. 즉, 그라디언트 부스팅 리그레서는 이전 결정 트리의 오차를 보완하는 방식으로 순차적인 결정 트리를 만들 수 있다. 그라디언트 부스팅 리그레서는 다수의 위크 러너들을 통해 스트롱 러너를 생성하여 과적합(overfitting) 에 강하다는 장점이 있다. 결과적으로, 성능예측 모델 구축부는 희소행렬의 특성 및 클라우드 인스턴스의 특성에 관한 데이터를 가지고 그라디언트 부스팅 리그레서 기반의 앙상블 러닝을 사용하여 희소행렬 곱셈에 관 한 성능예측 모델을 생성할 수 있다. 일 실시예에서, 성능예측 모델 구축부는 제2 러너에 관한 베이지안 최적화(Bayesian Optimization)를 통해 하이퍼 파라미터(Hyper Parameter) 검색을 수행하여 성능예측 모델을 생성할 수 있다. 여기에서, 베이지안 최적 화(Bayesian Optimization)는 모델 품질을 향상하거나 불확실성을 감소시킬 가능성이 있는 파라미터들을 검색하 고 확률적 프로세스를 사용하여 완전한 성능 측정치를 추정하는 접근법에 해당할 수 있다. 예를 들어, 베이지안 최적화는 목적 함수를 예측할 때, 이전 실험에서 사용 가능한 모든 정보를 사용하고(prior) 새로운 실험이 수행 된 후 목적 함수 모델을 수렴치(convergence)까지 업데이트 (posterior)할 수 있다. 보다 구체적으로, 성능예측 모델 구축부는 희소행렬 곱셈에 관한 성능예측 모델에 대해 베이지안 최적화를 수행하여 연산성능의 예측 정확도를 높일 수 있다. 다른 일 실시예에서, 성능예측 모델 구축부는 랜덤 워 크(random walk), 그리드 기반 검색 또는 통계적 추론(statistical inference)를 통해 설정된 하이퍼 파라미터 를 사용하여 성능예측 모델의 예측 정확도를 높일 수 있다. 사용자 입력 수신부는 사용자 단말로부터 입력 데이터 특성 및 기계학습 알고리즘에 관한 사용자 입 력을 수신할 수 있다. 이를 위해, 사용자 입력 수신부는 사용자 단말을 통해 사용자 입력 가능한 인 터페이스를 제공할 수 있으며, 사용자는 이를 통해 자신이 실행하고자 하는 환경 및 학습 조건을 설정할 수 있 다. 일 실시예에서, 사용자 입력 수신부는 사용자 단말로부터 사용자 입력으로서 희소행렬의 특성을 직접 수신할 수 있다. 사용자는 사용하고자 하는 기계학습 알고리즘을 특정할 수 있고, 이때 사용되는 입력 데이터들 을 구체적으로 특정할 수 있다. 또한, 사용자는 이와 별도로 학습 과정에 사용되는 희소행렬 자체의 특성을 직 접 입력할 수도 있다. 예를 들어, 사용자는 왼쪽 및 오른쪽 행렬의 차원(dimension) 및 밀도(density)와 같은 SPMM 작업의 워크로드 특성을 직접 특정할 수 있고, 사용자 입력 수신부는 사용자 단말로부터 이를 수신하여 성능예측 모델에 대한 구축 과정에 적용할 수 있다. 희소행렬 곱셈 정의부는 사용자 입력에 대응되는 입력 희소행렬 곱셈을 정의할 수 있다. 사용자가 기계학 습 알고리즘의 특징, 행렬 곱셈의 성능 특징, 클라우드 인스턴스의 특징 등을 이해하여 최적의 환경을 구축하는 것은 불가능에 가깝기 때문에 사용자는 단순히 사용하고자 하는 기계학습 알고리즘을 선택하거나 사용하고자 하 는 입력 데이터들을 지정할 수 있으며, 희소행렬 곱셈 정의부는 사용자가 입력한 정보를 기초로 해당 입력 데이터를 이용하여 해당 기계학습 알고리즘을 실행시키는 과정에서 연산 성능에 영향을 미치는 희소행렬 곱셈의 특징들을 도출할 수 있다. 일 실시예에서, 희소행렬 곱셈 정의부는 입력 데이터 특성에 기초한 기계학습 알고리즘의 수행 과정에서 가장 빈번하게 발생하는 희소행렬 곱셈을 입력 희소행렬 곱셈으로 결정할 수 있다. 한편, 입력 희소행렬 곱셈은 희소행렬 곱셈들의 집합으로 표현될 수도 있다. 즉, 희소행렬 곱셈 정의부는 사용자 입력에 대응되는 적어 도 하나의 희소행렬 곱셈을 결정할 수 있고, 이들의 집합을 입력 희소행렬 곱셈으로 결정할 수 있다. 따라서, 희소행렬 곱셈 정의부에 의해 정의된 입력 희소행렬 곱셈은 사용자 입력에 대응되는 것으로 이에 대한 연 산 성능 예측 결과는 사용자 입력에 대응되는 예측 결과로서 사용될 수 있다. 클라우드 인스턴스 결정부는 성능예측 모델을 이용하여 입력 희소행렬 곱셈을 실행하기 위한 최적 클라우 드 인스턴스를 결정할 수 있다. 즉, 최적 클라우드 인스턴스는 사용자 입력에 대응되는 입력 희소행렬 곱셈을 최소의 실행시간 또는 최소의 비용으로 실행 가능한 클라우드 인스턴스에 해당할 수 있다. 한편, 최적 클라우드 인스턴스는 사용자의 요청 조건에 따라 실행시간 및 비용의 최적 조합을 통해 결정될 수도 있다. 일 실시예에서, 클라우드 인스턴스 결정부는 성능예측 모델에 복수의 클라우드 인스턴스들을 적용하여 입 력 희소행렬 곱셈에 대한 실행시간을 각각 예측하고 복수의 클라우드 인스턴스들 각각의 실행시간과 비용에 관 한 성능 리스트를 생성할 수 있다. 즉, 성능예측 모델은 다양한 클라우드 인스턴스들에 따른 희소행렬 곱셈의 실행시간을 예측할 수 있고, 클라우드 인스턴스 결정부는 다양하게 설정된 클라우드 인스턴스 유형 별로 입력 희소행렬 곱셈에 대한 실행시간을 예측할 수 있다. 또한, 클라우드 인스턴스 결정부는 성능 예측 결 과로서 다양한 클라우드 인스턴스의 유형 및 크기에 대해 예측된 실행시간 정보를 리스트 형태로 생성하여 사용 자에게 추천할 수 있다. 즉, 사용자는 다양한 조건에 따른 예측 결과를 기초로 자신에게 가장 적합한 클라우드 환경을 선택할 수 있다. 일 실시예에서, 클라우드 인스턴스 결정부는 각 클라우드 인스턴스 별로 실행시간과 비용 간의 가중합을 산출하고 가중합에 따라 복수의 클라우드 인스턴스들을 정렬한 다음 최적 클라우드 인스턴스를 결정할 수 있다. 이때, 사용자는 실행시간 또는 비용에 대한 가중치를 직접 설정할 수 있고, 클라우드 인스턴스 결정부는 사용자에 의해 설정된 가중치에 따라 예측된 결과를 정렬할 수 있으며, 최우선 순위에 해당하는 클라우드 인스 턴스를 최적 클라우드 인스턴스로 결정하여 사용자에게 추천할 수 있다. 일 실시예에서, 클라우드 인스턴스 결정부는 최적 클라우드 인스턴스의 각 작업 노드 별로 입력 희소행렬 곱셈을 실행하는 최적의 희소행렬 곱셈 방법을 결정할 수 있다. 클라우드 인스턴스 결정부는 사용자의 선 택에 따라 최적 클라우드 인스턴스를 구성하는 다양한 작업 노드들에서 희소행렬 곱셈을 실행시킬 수 있으며, 이때, 각 작업 컴퓨터는 예측된 성능을 바탕으로 최적의 희소행렬 곱셈 방법을 선택하여 작업을 처리할 수 있다. 결과적으로, 모든 작업 노드들이 똑같은 방식의 희소행렬 곱셈 구현을 사용하지 않고, 필요에 따라 가능 한 방법 중 최적으로 예상되는 방법을 시도함으로써 전체 실행시간을 효과적으로 줄일 수 있다. 곱셈 방법 결정부는 성능예측 모델을 이용하여 입력 희소행렬 곱셈을 실행하기 위한 최적 곱셈 방법을 결 정할 수 있다. 즉, 성능예측 모델은 희소행렬의 특징과 해당 작업이 수행되는 클라우드 인스턴스의 특성을 기초 로 동작 성능의 특징을 예측할 수 있다. 곱셈 방법 결정부는 성능예측 모델이 예측한 결과를 이용하여 해 당 작업을 수행하는 최적의 희소행렬 곱셈 방법을 추천할 수 있다. 예를 들어, 희소행렬 곱셈 작업을 수행하는 다수의 작업 컴퓨터에서는 성능예측 모델이 예측한 성능을 바탕으로 각각의 작업 컴퓨터마다 최적의 희소행렬 곱셈 방법을 독립적으로 결정할 수 있으며, 이에 따라 전체 실행시간 을 효과적으로 줄일 수 있다. 즉, 최적의 희소행렬 곱셈 방법을 채택한 경우라 하더라도 모든 작업 컴퓨터들이동일한 방법으로 실행되는 경우 각 작업 컴퓨터의 독립된 실행 환경이 상이하여 최적의 성능을 발휘하기 어려울 수 있다. 제어부(도 3에 미도시함)는 클라우드 최적화 장치의 전체적인 동작을 제어하고, 성능예측 모델 구축부 , 사용자 입력 수신부, 희소행렬 곱셈 정의부, 클라우드 인스턴스 결정부 및 곱셈 방법 결 정부 간의 제어 흐름 또는 데이터 흐름을 관리할 수 있다. 도 4는 본 발명에 따른 빅데이터 분석을 위한 인공지능 기반의 클라우드 최적화 방법을 설명하는 순서도이다. 도 4를 참조하면, 클라우드 최적화 장치는 성능예측 모델 구축부를 통해 희소행렬의 특징과 클라우드 인스턴스의 특성을 기초로 희소행렬 곱셈의 성능을 예측하는 성능예측 모델을 구축할 수 있다(단계 S410). 클라 우드 최적화 장치는 사용자 입력 수신부를 통해 사용자 단말로부터 입력 데이터 특성 및 기계학 습 알고리즘에 관한 사용자 입력을 수신할 수 있다(단계 S430). 또한, 클라우드 최적화 장치는 희소행렬 곱셈 정의부를 통해 사용자 입력에 대응되는 입력 희소행렬 곱셈을 정의할 수 있다(단계 S450). 클라우드 최적화 장치는 클라우드 인스턴스 결정부를 통해 성능 예측 모델을 이용하여 입력 희소행렬 곱셈을 실행하기 위한 최적 클라우드 인스턴스를 결정할 수 있다(단계 S470). 도 5는 본 발명에 따른 S-MPEC 아키텍처를 설명하는 개념도이다. 도 5를 참조하면, 본 발명에 따른 클라우드 최적화 장치는 S-MPEC 아키텍처를 통해 구현될 수 있다. 사용 자는 왼쪽 및 오른쪽 행렬의 차원 및 밀도와 같은 SPMM 작업의 워크로드 특성을 사용자 단말을 통해 입력 할 수 있다. 이때, 클라우드 최적화 장치는 다양한 클라우드 인스턴스 유형과 함께 다양한 SPMM 시나리오 를 사용하여 기 구축된 성능예측 모델을 활용할 수 있다. 이때, 성능예측 모델은 데이터베이스를 통해 관 리될 수 있다. 따라서, 클라우드 최적화 장치는 성능예측 모델을 사용하여 다양한 클라우드 인스턴스 유형 및 크기에 대 한 입력 워크로드 시나리오의 지연(latency)을 효과적으로 예측할 수 있다. 도 6은 본 발명에 따른 성능예측 모델의 예측 정확도를 설명하는 도면이다. 도 6a는 GB 리그레서를 이용한 성능 예측 모델에 관한 것이고, 도 6b는 NNLS를 이용한 성능예측 모델에 관한 것이다. 도 7은 베이지안 최적화를 이용한 성능 향상을 설명하는 도면이다. 도 8은 다양한 클라우드 인스턴스 유형들에 관한 예측 정확도를 설명하는 도면이다. 도 8a는 all methods, 도 8b는 Outer sparse, 도 8c는 Indexed-Row에 관한 실험 결과에 해당할 수 있다. 도 9는 본 발명에 따른 S-MPEC를 이용하여 성능 효과를 설명하는 도면이다. 이하, 도 6 내지 9를 참조하여 본 발명의 방법에 관한 평가 결과를 상세하게 설명한다. 다양한 희소행렬, 분산 구현 및 클라우드 인스턴스 유형을 사용하여 SPMM 작업의 성능 예측의 적용 가능성과 이 점을 확인하기 위해 다양한 시나리오를 통해 실험을 수행할 수 있다. 다양한 입력 데이터 세트를 위해 SNAP의 Orkut, DBLP 및 Youtube 그래프 데이터 세트를 사용할 수 있다. Orkut 데이터 세트에는 3,072,441개의 노드 (node), 117,185,083개의 에지(edge) 및 234,370,166개의 nnz가 포함될 수 있다. DBLP 데이터 세트에는 317,080개의 노드, 1,049,866개의 에지 및 2,099,732개의 nnz가 포함될 수 있다. Youtube 데이터 세트에는 1,134,890개의 노드, 2,987,624개의 에지, 5,975,248개의 nnz가 포함될 수 있다. 4개의 분산 SPMM 구현 (distributed SPMM implementations)을 입력 데이터 세트에 적용할 수 있다. 또한, 클라우드 인스턴스로 c5.xlarge, c5.2xlarge, c5.4xlarge, r5.xlarge, r5.2xlarge 및 r5.4xlarge의 6가 지 AWS EC2 인스턴스 유형이 사용될 수 있다. 입력 데이터 세트를 왼쪽 행렬로 사용하여 Apache Spark를 사용하 여 다중 반복들(multiple iterations)에서 다중 소스(multi-source) BFS 알고리즘을 수행할 수 있다. 실용적인 (practical) BFS 시나리오를 재현하기 위해 오른쪽 행렬의 희소성을 다른 각도로 변경할 수 있다. 실험은 하나 의 마스터와 4개의 워커(worker)들로 AWS Elastic MapReduce 버전 5.27.0에서 수행될 수 있다. 최적화된 예측모델을 구축할 때 Python 3.8.5와 xgboost 1.2 및 bayesian-optimization 1.2 라이브러리가 사용될 수 있다. 먼저 제안된 특징 집합을 사용하여 S-MPEC의 예측 모델링 알고리즘인 GB-회귀 모델(GB-regressor model)의 예측 정확도를 평가할 수 있다. 훈련 및 테스트 데이터 세트를 8:2 비율로 나누면서 K-폴드(K-fold) 교차 검증을 10 회 수행할 수 있다. R2와 MAPE(평균 절대 백분율 오차, mean absolute percentage error) 메트릭을 사용하여 예 측 정확도를 측정할 수 있다. R2 메트릭은 예측 값과 실제 값의 유사도를 측정할 수 있다. R2 값이 높을수록 최 대 값이 1.0 인 정확도 결과를 나타낼 수 있다. 도 6a는 최소 및 최대 지시자(indicator)가 있는 막대로 표현되는 값을 갖는 기본 수직축에 R2 값(높을수록 좋 음)이 표시된 것을 나타낼 수 있다. MAPE 값(낮을수록 좋음)은 보조 수직축에 표시되며, 여기서 해당 값은 별표 로 표시될 수 있다. 가로축은 분산된 SPMM 구현을 나타낼 수 있다. 첫 번째 가로축 값인 All은 모든 SPMM 구현 방법의 데이터 세트를 사용하여 예측 모델이 구축되고 All 모델에만 '메서드(method)' 특징이 포함된 경우를 나 타낼 수 있다. 후자의 4개 값은 희소행렬 곱셈 방법들 각각에서 생성되고 학습 데이터 세트를 통해 구축된 모델 들의 예측 정확도를 나타낼 수 있다. 여기에서, Outer sparse는 Outer-Sparse SPMM에 해당하고, Inner sparse 는 Inner-Sparse SPMM에 해당하며, IndexedRow는 IndexedRow Partitioning SPMM에 해당하고, Block은 Block Partitioning SPMM에 해당할 수 있다. SPMM 구현 방법과 관련된 독점 데이터 세트로 구축된 모델이 통합 모델보다 더 나은 예측 정확도를 나타낼 수 있다. 그러나, 가장 성능이 떨어지는 통합 All 방법에서도 R2가 0.95이고 MAPE가 약 7.6%인 정확도를 나타낼 수 있다. R2 메트릭에 대한 블록(Block) 구현을 사용하면 최상의 예측 정확도를 얻을 수 있다. GB-regressor 알고리즘을 사용하는 모델에 대한 뛰어난 예측 정확도를 제공하기 위해 NNLS(non-negative least square) 선형 회귀 알고리즘을 사용하는 또 다른 모델을 사용할 수 있다. 그 결과는 도 6b에서 확인할 수 있다. 전체적인 예측 정확도 패턴은 GB 회귀 알고리즘에서 제공하는 것과 매우 유사할 수 있다. 그러나, 정확도는 상 당히 낮을 수 있다. 예를 들어, All 방법의 R2 값은 0.5이고 MAPE는 10% 이상일 수 있다. 결과로부터, 선형 모 델은 이러한 특성을 효과적으로 반영할 수 없기 때문에 다양한 클라우드 인스턴스 유형을 사용하는 다양한 SPMM 구현에 대해 제안된 특징들 간에 비선형적인 상관관계가 있다는 결론을 내릴 수 있다. 모델링 단계에서 S-MPEC는 베이지안 최적화 알고리즘을 사용하여 GB 회귀 모델에 대한 최적의 파라미터 집합을 찾을 수 있다. 도 7은 GB-regressor 모델링 중에 사용자가 설정할 수 있는 파라미터와 xgboost 라이브러리의 기 본값을 보여주어 하이퍼 파라미터 검색 단계의 성능 향상을 나타낼 수 있다. 마지막 열에는 예측 모델에 대한 최적의 하이퍼 파라미터가 표시될 수 있다. 베이지안 최적화를 실행할 때 해당 단계에서 최소화되는 목표 메트 릭을 -1×(MAPE×10+RMSE)로 설정할 수 있다. RMSE의 절대 값 범위에 적합하도록 MAPE 값에 10을 곱할 수 있다. 하이퍼 파라미터 최적화를 통해 모든 평가 지표에서 예측 정확도가 크게 향상되고 S-MPEC의 예측 정확도 향상에 기여함을 알 수 있다. 다양한 클라우드 인스턴스 유형에 대한 S-MPEC의 예측 정확도를 평가하기 위해 특정 인스턴스 유형을 제외한 후 S-MPEC 모델을 구축할 수 있다. 그림 8은 다양한 SPMM 구현의 예측 정확도를 나타낼 수 있다. 가로축은 예측할 대상 인스턴스 유형을 나타내며, 모델링 단계에서 가로축에서 대상 인스턴스 유형을 제외한 후 모델을 구축할 수 있다. 구축된 모델을 사용하여 특징들에 대해 대상 인스턴스 유형을 적절하게 설정하여 다양한 SPMM 시나리 오의 지연 시간을 예측할 수 있다. 기본 수직축은 R2 값이 막대로 표시되고 보조 수직축은 MAPE 값이 별표로 표 시될 수 있다. 이 단계에서는 다른 SPMM 구현 방법이 유사한 패턴을 나타내므로 세 가지 SPMM 구현 방법을 나타 낼 수 있다. S-MPEC는 다양한 SPMM 작업이 MAPE가 11% 미만인 다양한 클라우드 컴퓨팅 인스턴스에서 실행될 때 다양한 SPMM 작업의 지연 시간을 예측한다는 것을 알 수 있다. 최적의 하이퍼 파라미터 선택을 위해 베이지안 최적화가 적용된 GB 회귀 모델을 사용하여 S-MPEC는 다양한 클라 우드 환경에서 Apache Spark를 사용하여 실행될 때 제안된 특징들에 관한 다양한 분산 SPMM 구현의 응답 시간을 정확하게 모델링할 수 있다. 모델링 중에 어떤 특징이 중요한 기여를 하는지를 이해하기 위해 모델을 구축하는 동안 특징의 중요도를 계산할 수 있다. 대부분의 방법은 (l-nnz+r-nnz)를 셔플링 오버헤드를 나타내는 중요한 특징으로 나타낼 수 있다. 컴퓨팅 오버헤 드 (l-nnz×r-nnz)도 지연 시간을 결정하는 중요한 요소에 해당할 수 있다. 사용자는 S-MPEC를 사용하여 곱셈 작업을 실행하기 위한 최적의 SPMM 구현 방법을 선택할 수 있다. 입력 데이터 세트가 Apache Spark 드라이버에 RDD 개체로 로드되었다고 가정하면 사용자는 입력 특성을 고려하여 실행할 SPMM 구현을 쉽게 결정할 수 있다. Indexed-Row 및 Block 구현은 Apache Spark MLLib에서 기본적으로 지원될 수 있다. 또한, 사용자가 필요할 때 선택할 수 있도록 Inner-Sparse 및 Outer-Sparse를 오픈 소스로 구현할 수 있다. S-MPEC 사용으로 인한 성능 향상을 보여주기 위해 서로 다른 입력 데이터 세트 크기로 다양한 SPMM 작업을 테스 트할 수 있다. 각 SPMM 시나리오는 최상의 성능을 위해 서로 다른 구현을 포함할 수 있으며, 그 결과는 도 9에 나타날 수 있다. 가로축은 서로 다른 SPMM 메커니즘을 나타낼 수 있다. 각 워크로드의 최고 성능 구현 방법을 Ground Truth(GT)로 지정하고 S-MPEC (Proposed)는 제안된 모델을 사용하여 예측된 최적 구현 방법을 추천할 수 있다. 후자의 4개의 메커니즘들은 단일 구현 방법을 정적으로 사용할 수 있다. 즉, 사용자는 입력 데이터 세트 를 기반으로 SPMM 구현을 변경하지 않고 하나의 구현을 유지할 수 있다. 후자의 4개의 정적 구현 선택 시나리오 는 일반 Spark 사용자에게 대부분의 경우에 적용될 수 있다. 본 발명에 따른 클라우드 최적화 방법을 기반으로 사용자는 빅데이터 분석 작업을 클라우드 환경에서 진행 시 최적의 환경을 손쉽게 구축할 수 있다. 또한, 이를 활용하여 클라우드 사용료를 절감할 수 있고 작업을 빠른 시 간에 끝낼 수 있다. 나아가, 기존의 빅데이터 분석 시스템들이 입력 데이터에 대해서 희소행렬 곱셈을 실행할 경우 분산 서버 환경에서 여러 대의 서버가 실행될 경우에도 모든 서버들이 똑같은 방식의 곱셈을 진행하는 반 면, 본 발명의 경우 성능예측 모델을 기초로 분산 서버에 분배된 작업 특성을 고려하여 최선의 방법으로 행렬 곱셈을 실행할 수 있다. 상기에서는 본 발명의 바람직한 실시예를 참조하여 설명하였지만, 해당 기술 분야의 숙련된 당업자는 하기의 특 허 청구의 범위에 기재된 본 발명의 사상 및 영역으로부터 벗어나지 않는 범위 내에서 본 발명을 다양하게 수정 및 변경시킬 수 있음을 이해할 수 있을 것이다."}
{"patent_id": "10-2020-0189058", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명에 따른 클라우드 최적화 시스템을 설명하는 도면이다. 도 2는 도 1의 클라우드 최적화 장치의 시스템 구성을 설명하는 도면이다. 도 3은 도 1의 클라우드 최적화 장치의 기능적 구성을 설명하는 도면이다. 도 4는 본 발명에 따른 빅데이터 분석을 위한 인공지능 기반의 클라우드 최적화 방법을 설명하는 순서도이다. 도 5는 본 발명에 따른 S-MPEC 아키텍처를 설명하는 개념도이다. 도 6은 본 발명에 따른 성능예측 모델의 예측 정확도를 설명하는 도면이다. 도 7은 베이지안 최적화를 이용한 성능 향상을 설명하는 도면이다. 도 8은 다양한 클라우드 인스턴스 유형들에 관한 예측 정확도를 설명하는 도면이다. 도 9는 본 발명에 따른 S-MPEC를 이용하여 성능 효과를 설명하는 도면이다."}
