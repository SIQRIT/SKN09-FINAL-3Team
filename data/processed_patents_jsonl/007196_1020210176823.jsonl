{"patent_id": "10-2021-0176823", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2022-0083628", "출원번호": "10-2021-0176823", "발명의 명칭": "깊이 이미지 생성 장치 및 그 동작 방법", "출원인": "재단법인대구경북과학기술원", "발명자": "권순"}}
{"patent_id": "10-2021-0176823", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "기준 이미지 센서, N(1이상 자연수)개의 수평 배열 이미지 센서 쌍(각 수평 배열 이미지 센서 쌍은 상기 기준이미지 센서를 기준으로 수평 방향으로 대칭되게 배열되는 두 개의 수평 배열 이미지를 포함) 및 M(1이상 자연수)개의 수직 배열 이미지 센서 쌍(각 수평 배열 이미지 센서 쌍은 상기 기준 이미지 센서를 기준으로 수평 방향으로 대칭되게 배열되는 두 개의 수평 배열 이미지를 포함)이미지 촬영부;제1 미리 학습된 모델을 기반으로 N개의 수평 배열 이미지 세트 각각에서 깊이 정보를 추출하여 N개의 제1 깊이정보를 생성하는 제1 깊이 정보 생성부;제2 미리 학습된 모델을 기반으로 M개의 수직 배열 이미지 세트 각각에서 깊이 정보를 추출하여 M개의 제2 깊이정보를 생성하는 제2 깊이 정보 생성부;상기 N개의 제1 깊이 정보에 앙상블 기법을 적용하고, 상기 M개의 제2 깊이 정보에 앙상블 기법을 적용하고, 상기 N개의 제1 깊이 정보에 앙상블 기법을 적용한 결과 및 상기 M개의 제2 깊이 정보에 앙상블 기법을 적용한 결과에 앙상블 기법을 적용하여 제3 깊이 정보를 생성하는 제3 깊이 정보를 생성부; 및상기 제3 깊이 정보를 기반으로 깊이 맵 이미지를 생성하는 깊이 이미지 생성부;를 포함하되,상기 수평 배열 이미지 세트는 하나의 수평 배열 이미지 센서 쌍 및 상기 기준 이미지 센서에 의해 촬영된 이미지로 구성되고,상기 수직 배열 이미지 세트는 하나의 수직 배열 이미지 센서 쌍 및 상기 기준 이미지 센서에 의해 촬영된 이미지로 구성되는, 깊이 이미지 생성 장치."}
{"patent_id": "10-2021-0176823", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 N개의 수평 배열 이미지 센서 쌍 각각은 서로 상이한 위치에 배열되는, 깊이 이미지 생성 장치."}
{"patent_id": "10-2021-0176823", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서, 상기 M개의 수직 배열 이미지 센서 쌍 각각은 서로 상이한 위치에 배열되는, 깊이 이미지 생성 장치."}
{"patent_id": "10-2021-0176823", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서, 상기 제1 미리 학습된 모델은수평 이미지 세트로부터 깊이 정보를 추출하도록 미리 학습된 CNN 기반의 인공지능 모델인, 깊이 이미지 생성장치."}
{"patent_id": "10-2021-0176823", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서, 공개특허 10-2022-0083628-4-상기 제2 미리 학습된 모델은수직 이미지 세트로부터 깊이 정보를 추출하도록 미리 학습된 CNN 기반의 인공지능 모델인, 깊이 이미지 생성장치."}
{"patent_id": "10-2021-0176823", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서, 상기 제3 깊이 정보 생성부는, 보팅(Voting), 배깅(Bagging) 및 부스팅(Boosting) 중 적어도 하나의 앙상블 기법을 기반으로 상기 제3 깊이 정보를 생성하는, 깊이 이미지 생성 장치."}
{"patent_id": "10-2021-0176823", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "기준 이미지 센서, N(1이상 자연수)개의 수평 배열 이미지 센서 쌍(각 수평 배열 이미지 센서 쌍은 상기 기준이미지 센서를 기준으로 수평 방향으로 대칭되게 배열되는 두 개의 수평 배열 이미지를 포함) 및 M(1이상 자연수)개의 수직 배열 이미지 센서 쌍(각 수평 배열 이미지 센서 쌍은 상기 기준 이미지 센서를 기준으로 수평 방향으로 대칭되게 배열되는 두 개의 수평 배열 이미지를 포함)에 의해 촬영된 이미지들을 수신하는 단계;제1 미리 학습된 모델을 기반으로 N개의 수평 배열 이미지 세트 각각에서 깊이 정보를 추출하여 N개의 제1 깊이정보를 생성하는 단계;제2 미리 학습된 모델을 기반으로 M개의 수직 배열 이미지 세트 각각에서 깊이 정보를 추출하여 M개의 제2 깊이정보를 생성하는 단계;상기 N개의 제1 깊이 정보에 앙상블 기법을 적용하고, 상기 M개의 제2 깊이 정보에 앙상블 기법을 적용하고, 상기 N개의 제1 깊이 정보에 앙상블 기법을 적용한 결과 및 상기 M개의 제2 깊이 정보에 앙상블 기법을 적용한 결과에 앙상블 기법을 적용하여 제3 깊이 정보를 생성하는 단계; 및상기 제3 깊이 정보를 기반으로 깊이 맵 이미지를 생성하는 단계;를 포함하되,상기 수평 배열 이미지 세트는 하나의 수평 배열 이미지 센서 쌍 및 상기 기준 이미지 센서에 의해 촬영된 이미지로 구성되고,상기 수직 배열 이미지 세트는 하나의 수직 배열 이미지 센서 쌍 및 상기 기준 이미지 센서에 의해 촬영된 이미지로 구성되는, 깊이 이미지 생성 방법."}
{"patent_id": "10-2021-0176823", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서, 상기 N개의 수평 배열 이미지 센서 쌍 각각은 서로 상이한 위치에 배열되는, 깊이 이미지 생성 방법."}
{"patent_id": "10-2021-0176823", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제7항에 있어서, 상기 M개의 수직 배열 이미지 센서 쌍 각각은 서로 상이한 위치에 배열되는, 깊이 이미지 생성 방법."}
{"patent_id": "10-2021-0176823", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제7항에 있어서, 공개특허 10-2022-0083628-5-상기 제1 미리 학습된 모델은수평 이미지 세트로부터 깊이 정보를 추출하도록 미리 학습된 CNN 기반의 인공지능 모델인, 깊이 이미지 생성방법."}
{"patent_id": "10-2021-0176823", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제7항에 있어서, 상기 제2 미리 학습된 모델은수직 이미지 세트로부터 깊이 정보를 추출하도록 미리 학습된 CNN 기반의 인공지능 모델인, 깊이 이미지 생성방법."}
{"patent_id": "10-2021-0176823", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제7항에 있어서, 상기 제3 깊이 정보를 생성하는 단계는, 보팅(Voting), 배깅(Bagging) 및 부스팅(Boosting) 중 적어도 하나의 앙상블 기법을 기반으로 상기 제3 깊이 정보를 생성하는, 깊이 이미지 생성 방법."}
{"patent_id": "10-2021-0176823", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 2차원 이미지로부터 3차원 깊이 이미지를 생성하는 기술에 관한 것이다. 본 발명의 측면에 따르면, 기 준 이미지 센서, 기준 이미지 센서를 기준으로 수평 방향으로 대칭되게 배열되는 수평 배열 이미지 센서 쌍을 N(1 이상의 자연수)개 포함하는 수평 이미지 촬영 모듈 및 기준 이미지 센서를 기준으로 수직 방향으로 대칭되게 (뒷면에 계속)"}
{"patent_id": "10-2021-0176823", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 2차원 이미지로부터 3차원 깊이 이미지를 생성하는 기술에 관한 것이다."}
{"patent_id": "10-2021-0176823", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "3D 정보를 센싱하는 기술은 크게 능동 센싱 방식과 수동 센싱 방식으로 구분될 수 있다. 능동 센싱 방식은 LIDAR센서, TOF, RADAR 등 전파나 빛 신호를 쏜 후 되돌아오는 신호의 시간을 계산하는 방식을 사용한다. 반면, 수동 센싱 방식은 주로 듀얼 카메라를 사용한 스테레오비전이나 단일카메라 기반 Depthmap image를 생성한다. 스테레오비전의 경우 두 개의 카메라 간의 시차를 삼각측량방식으로 계산하여 객체나 화소의 거리(Depth)정보를 구하지만, 단일 카메라 기반의 Depth추정 방식은 머신러닝이나 딥러닝기반의 학습기반의 알고리즘을 사용하여 Depth feature(깊이 특징)을 사전에 학습하여 추정하는 차이점이 있다. 선행기술문헌 공개 논문 1 : C. Godard, O. M. Aodha and G. J. Brostow, \"Unsupervised Monocular Depth Estimation with Left-Right Consistency,\" 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), Honolulu, HI, 2017, pp. 6602-6611"}
{"patent_id": "10-2021-0176823", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명의 목적은 향상된 깊이 맵 이미지를 생성하는 기술을 제공하는 것이다. 또한, 본 발명의 목적은 비지도 학습 기반으로 깊이 맵 이미지를 생성하는 기술을 제공하는 것이다. 또한, 본 발명의 목적은 수직 및 수평 방향으로 대칭되게 배열되는 이미지 센서에 의해 촬영된 이미지들을 이용 하여 깊이 맵 이미지를 생성하는 기술을 제공하는 것이다."}
{"patent_id": "10-2021-0176823", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 측면에 따르면, 기준 이미지 센서, N(1이상 자연수)개의 수평 배열 이미지 센서 쌍(각 수평 배열 이 미지 센서 쌍은 상기 기준 이미지 센서를 기준으로 수평 방향으로 대칭되게 배열되는 두 개의 수평 배열 이미지 를 포함) 및 M(1이상 자연수)개의 수직 배열 이미지 센서 쌍(각 수평 배열 이미지 센서 쌍은 상기 기준 이미지 센서를 기준으로 수평 방향으로 대칭되게 배열되는 두 개의 수평 배열 이미지를 포함)을 포함하는 이미지 촬영 부; 제1 미리 학습된 모델을 기반으로 N개의 수평 배열 이미지 세트 각각에서 깊이 정보를 추출하여 N개의 제1 깊이 정보를 생성하는 제1 깊이 정보 생성부; 제2 미리 학습된 모델을 기반으로 M개의 수직 배열 이미지 세트 각각에서 깊이 정보를 추출하여 M개의 제2 깊이 정보를 생성하는 제2 깊이 정보 생성부; N개의 제1 깊이 정보에 앙상블 기법을 적용하고, M개의 제2 깊이 정보에 앙상블 기법을 적용하고, N개의 제1 깊이 정보에 앙상블 기법 을 적용한 결과 및 M개의 제2 깊이 정보에 앙상블 기법을 적용한 결과에 앙상블 기법을 적용하여 제3 깊이 정보 를 생성하는 제3 깊이 정보를 생성부; 제3 깊이 정보를 기반으로 깊이 맵 이미지를 생성하는 깊이 이미지 생성 부;를 포함하는 깊이 이미지 생성 장치가 제공된다. 일 실시예에서, 수평 배열 이미지 세트는 하나의 수평 배열 이미지 센서 쌍 및 기준 이미지 센서에 의해 촬영된 이미지로 구성되고, 수직 배열 이미지 세트는 하나의 수직 배열 이미지 센서 쌍 및 기준 이미지 센서에 의해 촬 영된 이미지로 구성될 수 있다. 일 실시예에서, N개의 수평 배열 이미지 센서 쌍 각각은 서로 상이한 위치에 배열될 수 있다. 일 실시예에서, M개의 수직 배열 이미지 센서 쌍 각각은 서로 상이한 위치에 배열될 수 있다. 일 실시예에서, 제1 미리 학습된 모델은 수평 이미지 세트로부터 깊이 정보를 추출하도록 미리 학습된 CNN 기반 의 인공지능 모델일 수 있다. 일 실시예에서, 제2 미리 학습된 모델은 수직 이미지 세트로부터 깊이 정보를 추출하도록 미리 학습된 CNN 기반 의 인공지능 모델일 수 있다. 일 실시예에서, 제3 깊이 정보 생성부는 보팅(Voting), 배깅(Bagging) 및 부스팅(Boosting) 중 적어도 하나의 앙상블 기법을 기반으로 제3 깊이 정보를 생성할 수 있다. 본 발명의 측면에 따르면, 기준 이미지 센서, N(1이상 자연수)개의 수평 배열 이미지 센서 쌍(각 수평 배열 이 미지 센서 쌍은 상기 기준 이미지 센서를 기준으로 수평 방향으로 대칭되게 배열되는 두 개의 수평 배열 이미지 를 포함) 및 M(1이상 자연수)개의 수직 배열 이미지 센서 쌍(각 수평 배열 이미지 센서 쌍은 상기 기준 이미지 센서를 기준으로 수평 방향으로 대칭되게 배열되는 두 개의 수평 배열 이미지를 포함)에 의해 촬영된 이미지들 을 수신하는 단계; 제1 미리 학습된 모델을 기반으로 N개의 수평 배열 이미지 세트 각각에서 깊이 정보를 추출 하여 N개의 제1 깊이 정보를 생성하는 단계; 제2 미리 학습된 모델을 기반으로 M개의 수직 배열 이미지 세트 각 각에서 깊이 정보를 추출하여 M개의 제2 깊이 정보를 생성하는 단계; N개의 제1 깊이 정보에 앙상블 기법을 적 용하고, M개의 제2 깊이 정보에 앙상블 기법을 적용하고, N개의 제1 깊이 정보에 앙상블 기법을 적용한 결과 및 M개의 제2 깊이 정보에 앙상블 기법을 적용한 결과에 앙상블 기법을 적용하여 제3 깊이 정보를 생성하는 단계; 제3 깊이 정보를 기반으로 깊이 맵 이미지를 생성하는 단계;를 포함하는 깊이 이미지 생성 방법이 개시된다."}
{"patent_id": "10-2021-0176823", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명의 일 측면에 따르면, 향상된 깊이 맵 이미지를 생성하는 기술이 가능하게 된다. 또한, 본 발명의 다른 측면에 따르면 비지도 학습 기반으로 깊이 맵 이미지를 생성하는 것이 가능하게 된다. 또한, 본 발명의 또 다른 측면에 따르면, 수직 및 수평 방향으로 대칭되게 배열되는 이미지 센서에 의해 촬영된 이미지들을 이용하여 깊이 맵 이미지를 생성하는 것이 가능하게 된다."}
{"patent_id": "10-2021-0176823", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 본 문서의 다양한 실시 예들이 첨부된 도면을 참조하여 기재된다. 실시 예 및 이에 사용된 용어들은 본 문서에 기재된 기술을 특정한 실시 형태에 대해 한정하려는 것이 아니며, 해당 실시 예의 다양한 변경, 균등물, 및/또는 대체물을 포함하는 것으로 이해되어야 한다. 하기에서 다양한 실시 예들을 설명에 있어 관련된 공지 기능 또는 구성에 대한 구체적인 설명이 발명의 요지를 불필요하게 흐릴 수 있다고 판단되는 경우에는 그 상세한 설명을 생략할 것이다. 그리고 후술되는 용어들은 다양한 실시 예들에서의 기능을 고려하여 정의된 용어들로서 이는 사용자, 운용자의 의도 또는 관례 등에 따라 달라질 수 있다. 그러므로 그 정의는 본 명세서 전반에 걸친 내용을 토대로 내려져야 할 것이다. 도면의 설명과 관련하여, 유사한 구성요소에 대해서는 유사한 참조 부호가 사용될 수 있다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함할 수 있다. 본 문서에서, \"A 또는 B\" 또는 \"A 및/또는 B 중 적어도 하나\" 등의 표현은 함께 나열된 항목들의 모든 가능한 조합을 포함할 수 있다. \"제1,\" \"제2,\" \"첫째,\" 또는 \"둘째,\" 등의 표현들은 해당 구성요소들을, 순서 또는 중요도에 상관없이 수식할 수 있고, 한 구성요소를 다른 구성요소와 구분하기 위해 사용될 뿐 해당 구성요소들을 한정하지 않는다. 어떤(예: 제1) 구성요소가 다른(예: 제2) 구성요소에 \"(기능적으로 또는 통신적으로) 연결되어\" 있다거나 \"접속 되어\" 있다고 언급된 때에는, 어떤 구성요소가 다른 구성요소에 직접적으로 연결되거나, 다른 구성요소(예: 제3 구성요소)를 통하여 연결될 수 있다. 본 명세서에서, \"~하도록 구성된(또는 설정된)(configured to)\"은 상황에 따라, 예를 들면, 하드웨어적 또는 소 프트웨어적으로 \"~에 적합한,\" \"~하는 능력을 가지는,\" \"~하도록 변경된,\" \"~하도록 만들어진,\" \"~를 할 수 있 는,\" 또는 \"~하도록 설계된\"과 상호 호환적으로(interchangeably) 사용될 수 있다. 어떤 상황에서는, \"~하도록 구성된 장치\"라는 표현은, 그 장치가 다른 장치 또는 부품들과 함께 \"~할 수 있는\" 것을 의미할 수 있다. 예를 들면, 문구 \"A, B, 및 C를 수행하도록 구성된(또는 설정된) 프로세서\"는 해당 동작을 수행하기 위한 전용 프로세서(예: 임베디드 프로세서), 또는 메모리 장치에 저장된 하나 이상의 소프트웨어 프로그램들을 실행함으 로써, 해당 동작들을 수행할 수 있는 범용 프로세서(예: CPU 또는 application processor)를 의미할 수 있다. 또한, '또는' 이라는 용어는 배타적 논리합 'exclusive or' 이기보다는 포함적인 논리합 'inclusive or' 를 의 미한다. 즉, 달리 언급되지 않는 한 또는 문맥으로부터 명확하지 않는 한, 'x가 a 또는 b를 이용한다' 라는 표현은 포함 적인 자연 순열들(natural inclusive permutations) 중 어느 하나를 의미한다. 상술한 구체적인 실시예들에서, 발명에 포함되는 구성 요소는 제시된 구체적인 실시 예에 따라 단수 또는 복수 로 표현되었다. 그러나, 단수 또는 복수의 표현은 설명의 편의를 위해 제시한 상황에 적합하게 선택된 것으로서, 상술한 실시 예들이 단수 또는 복수의 구성 요소에 제한되는 것은 아니며, 복수로 표현된 구성 요소라 하더라도 단수로 구성 되거나, 단수로 표현된 구성 요소라 하더라도 복수로 구성될 수 있다. 한편 발명의 설명에서는 구체적인 실시 예에 관해 설명하였으나, 다양한 실시 예들이 내포하는 기술적 사상의 범위에서 벗어나지 않는 한도 내에서 여러 가지 변형이 가능함은 물론이다. 그러므로 본 발명의 범위는 설명된 실시 예에 국한되어 정해져서는 아니되며 후술하는 청구범위 뿐만 아니라 이 청구범위와 균등한 것들에 의해 정해져야 한다. 도 1 내지 도 4는 본 발명의 일 실시예에 따른 깊이 이미지 생성 장치를 설명하기 위한 도면이다. 도 1을 참조하면, 본 발명의 일 실시예에 따른 깊이 이미지 생성 장치는 이미지 촬영부, 제1 깊이 정보 생성부, 제2 깊이 정보 생성부, 제3 깊이 정보 생성부 및 깊이 이미지 생성부를포함할 수 있다. 이미지 촬영부는 깊이 이미지를 생성하고자 하는 공간을 복수의 이미지 센서를 이용하여 촬영하여 2차원 이미지를 생성할 수 있다. 일 실시예에서, 이미지 촬영부는 도 2와 같이 배열된 복수의 이미지 센서를 포함할 수 있다. 도 2를 참조하면, 본 발명의 일 실시예에 따른 복수의 이미지 센서들을 포함하는 이미지 촬영부가 도시되 어 있다. 복수의 이미지 센서는 기준 이미지 센서, 기준 이미지 센서를 중심으로 수직 방향으로 대 칭되게 배열되는 수직 배열 이미지 센서들(2210 ~ 2260), 기준 이미지 센서를 중심으로 수평 방향으로 대 칭되게 배열되는 수평 배열 이미지 센서들(2310 ~ 2360)을 포함할 수 있다. 이때, 수직 방향으로 대칭되게 배열되는 수직 배열 이미지 센서들(2210 ~ 2260) 및 수평 방향으로 대칭되게 배 열되는 수평 배열 이미지 센서들(2310 ~ 2360)의 개수 및 위치는 미리 설정되거나 가변적으로 설정될 수 있다. 또한, 수직 방향으로 대칭되게 배열되는 수직 배열 이미지 센서들(2210 ~ 2260) 중에서, 기준 이미지 센서 에 대해 상호 대칭되는 위치에 배열된 두 개의 수직 배열 이미지 센서들은 하나의 수직 배열 이미지 센서 쌍을 형성할 수 있다. 예를 들어, 도 3에서 수직 배열 이미지 센서와 수직 배열 이미지 센서는 제1 수직 배열 이미지 센 서 쌍을 형성하고, 수직 배열 이미지 센서와 수직 배열 이미지 센서는 제2 수직 배열 이미지 센서 쌍을 형성하고, 수직 배열 이미지 센서와 수직 배열 이미지 센서는 제3 수직 배열 이미지 센서 쌍 을 형성할 수 있다. 또한, 수평 방향으로 대칭되게 배열되는 수평 배열 이미지 센서들(2310 ~ 2360) 중에서, 기준 이미지 센서 에 대해 상호 대칭되는 위치에 배열된 두 개의 수평 배열 이미지 센서들은 하나의 수평 배열 이미지 센서 쌍을 형성할 수 있다. 예를 들어, 도 3에서는 수평 배열 이미지 센서와 수평 배열 이미지 센서는 제1 수평 배열 이미지 쌍을 형성하고, 수평 배열 이미지 센서와 수평 배열 이미지 센서는 제2 수평 배열 이미지 쌍을 형 성하고, 수평 배열 이미지 센서와 수평 배열 이미지 센서는 제3 수평 배열 이미지 쌍을 형성할 수 있다. 제1 깊이 정보 생성부는 제1 미리 학습된 모델을 기반으로 수평 배열 이미지 세트로부터 제1 깊이 정보를 생성할 수 있다. 여기서, 수평 배열 이미지 세트는 수평 배열 이미지 센서 쌍을 구성하는 두 개의 수평 배열 이 미지 센서 각각에 의해 촬영된 이미지와 기준 이미지 센서에 의해 촬영된 이미지를 포함할 수 있다. 일 실시예에서, 제1 깊이 정보 생성부는 N(1 이상의 자연수)개의 수평 배열 이미지 센서 쌍이 존재하는 경우, N개의 수평 배열 이미지 센서 쌍으로부터 촬영된 이미지를 포함하는 N개의 수평 배열 이미지 세트 각각에 대해 제1 미리 학습된 모델을 기반으로 N개의 제1 깊이 정보를 생성할 수 있다. 또한, 실시예에 따라 도 3에 도시된 바와 같이, N개의 수평 배열 이미지 세트 각각에 대한 제1 미리 학습된 모 델들이 서로 상이할 수 있다. 일 실시예에서, 제1 미리 학습된 모델은 CNN(Convolutional Neural Networks) 기반으로 인공지능 모델을 이용 하여 2차원 이미지로부터 깊이 정보를 추출하도록 학습된 모델일 수 있다. 일 실시예에서, 제1 미리 학습된 모델은 도 4에 도시된 바와 같이, 3개의 2차원 이미지로부터 깊이 정보를 생성 하는 비지도 학습 기반의 깊이 맵 추정 모델일 수 있다. 도 4에 도시된 깊이 맵 추정 모델은 두 개의 이미지를 이용하여 깊이 맵을 추정할 경우 발생할 수 있는 가림 영 역(occlusion)으로 인한 오차를 줄이기 위해 3 개의 이미지 즉, 기준 이미지, 좌측 이미지 및 우측 이미지를 이 용하여 깊이 정보를 생성하는 모델이다. 도 4의 깊이 맵 추정 모델은 좌측 이미지(Il)와 기준 이미지(Ic)로부터 깊이 정보 dcl을 생성 및 우측 이미지(I r)와 기준 이미지(Ic)로부터 깊이 정보 dcr을 생하고, 다시 깊이 정보 dcl 와 깊이 정보 dcr을 이용하여 최종적으 로 깊이 정보 dc를 생성할 수 있다. 도 4의 깊이 맵 추정 모델을 본 발명의 수평 배열 이미지 쌍에 적용하는 경우, Ic 는 기준 이미지 센서에 의해 촬영된 영상, Il 및 Ir 는 수평 배열 이미지 센서 쌍을 구성하는 각각의 수평 배열 이미지 센서에 의해 촬영된 영상을 의미하고, 깊이 정보 dc는 제1 깊이 정보를 의미한다. 제2 깊이 정보 생성부는 제2 미리 학습된 모델을 기반으로 수직 배열 이미지 세트로부터 제2 깊이 정보를 생성할 수 있다. 여기서, 수직 배열 이미지 세트는 수직 배열 이미지 센서 쌍을 구성하는 두 개의 수직 배열 이 미지 센서 각각에 의해 촬영된 이미지와 기준 이미지 센서에 의해 촬영된 이미지를 포함할 수 있다. 일 실시예에서, 제2 깊이 정보 생성부는 M(1 이상의 자연수)개의 수직 배열 이미지 센서 쌍이 존재하는 경우, M개의 수직 배열 이미지 센서 쌍으로부터 촬영된 이미지를 포함하는 M개의 수직 배열 이미지 세트 각각에 대해 제2 미리 학습된 모델을 기반으로 제2 깊이 정보를 생성할 수 있다. 또한, 실시예에 따라 도 3에 도시된 바와 같이, M개의 수직 배열 이미지 세트 각각에 대한 제2 미리 학습된 모 델들은 서로 상이할 수 있다. 일 실시예에서, 제2 미리 학습된 모델은 CNN(Convolutional Neural Networks) 기반으로 인공지능 모델을 이용 하여 2차원 이미지로부터 깊이 정보를 추출하도록 학습된 모델일 수 있다. 일 실시예에서, 제2 미리 학습된 모델은 도 4에 도시된 바와 같이, 3개의 2차원 이미지로부터 깊이 정보를 생성 하는 비지도 학습 기반의 깊이 맵 추정 모델일 수 있다. 도 4에 도시된 깊이 맵 추정 모델은 두 개의 이미지를 이용하여 깊이 맵을 추정할 경우 발생할 수 있는 가림 영역(occlusion)으로 인한 오차를 줄이기 위해 3 개의 이 미지 즉, 기준 이미지, 좌측 이미지 및 우측 이미지를 이용하여 깊이 정보를 생성하는 모델이다. 도 4의 깊이 맵 추정 모델은 좌측 이미지(Il)와 기준 이미지(Ic)로부터 깊이 정보 dcl을 생성 및 우측 이미지(I r)와 기준 이미지(Ic)로부터 깊이 정보 dcr을 생하고, 다시 깊이 정보 dcl 와 깊이 정보 dcr을 이용하여 최종적으 로 깊이 정보 dc를 생성할 수 있다. 도 4의 깊이 맵 추정 모델을 본 발명의 수직 배열 이미지 쌍에 적용하는 경우, Ic 는 기준 이미지 센서에 의해 촬영된 영상, Il 및 Ir 는 수직 배열 이미지 센서 쌍을 구성하는 각각의 수직 배열 이미지 센서에 의해 촬영된 영상을 의미하고, 깊이 정보 dc는 제2 깊이 정보를 의미한다. 제3 깊이 정보 생성부는 제1 깊이 정보 및 제2 깊이 정보를 기반으로 최종 깊이 정보인 제3 깊이 정보를 생성할 수 있다. 일 실시예에서, 제3 깊이 정보 생성부는 도 3에 도시된 바와 같이, 제1 깊이 정보들에 대해 앙상블 기법 을 적용하여 하나의 깊이 정보를 생성하고, 제2 깊이 정보들에 대해 앙상블 기법을 적용하여 하나의 깊이 정보 를 생성하여, 제1 깊이 정보들에 대해 앙상블 기법을 적용하여 생성한 깊이 정보와 제2 깊이 정보들에 대해 앙 상블 기법을 적용하여 생성한 깊이 정보에 대해 다시 앙상블 기법을 적용하여 최종 깊이 정보인 제3 깊이 정보 를 생성할 수 있다. 일 실시예에서, 제3 깊이 정보 생성부는 보팅(Voting), 배깅(Bagging) 및 부스팅(Boosting) 등의 앙상블 기법을 이용하여 최종 깊이 정보를 생성할 수 있다. 깊이 이미지 생성부는 최종 깊이 정보인 제3 깊이 정보를 기반으로 3차원 공간 정보를 포함하는 깊이 맵 이미지를 생성할 수 있다. 도 5는 본 발명의 일 실시예에 따른 깊이 이미지 생성 방법의 흐름도이다. 이하, 도 1에 도시된 깊이 이미지 생성 장치에 의해 도 5의 방법이 수행되는 것을 예시로 설명한다. 단계 S5100에서, 3차원 이미지를 생성하고자 하는 공간에 대한 2차원 이미지가 촬영된다. 구체적으로, 깊이 이 미지 생성 장치는 깊이 이미지를 생성하고자 하는 공간을 복수의 이미지 센서를 이용하여 촬영하여 2차원 이미지를 생성할 수 있다. 일 실시예에서, 깊이 이미지 생성 장치는 도 2와 같이 배열된 복수의 이미지 센서를 포함할 수 있다. 도 2를 참조하면, 복수의 이미지 센서는 기준 이미지 센서, 기준 이미지 센서를 중심으로 수직 방향으로 대칭되게 배열되는 수직 배열 이미지 센서들(2210 ~ 2260), 기준 이미지 센서를 중심으로 수평 방향으 로 대칭되게 배열되는 수평 배열 이미지 센서들(2310 ~ 2360)을 포함할 수 있다. 또한, 수직 방향으로 대칭되게 배열되는 수직 배열 이미지 센서들(2210 ~ 2260) 중에서, 기준 이미지 센서 에 대해 상호 대칭되는 위치에 배열된 두 개의 수직 배열 이미지 센서들은 하나의 수직 배열 이미지 센서 쌍을 형성할 수 있다. 예를 들어, 도 3에서는 수직 배열 이미지 센서와 수직 배열 이미지 센서는 제1 수직 배열 이미지 쌍을 형성하고, 수직 배열 이미지 센서와 수직 배열 이미지 센서는 제2 수직 배열 이미지 쌍을 형성하고, 수직 배열 이미지 센서와 수직 배열 이미지 센서는 제3 수직 배열 이 미지 쌍을 형성할 수 있다. 또한, 수평 방향으로 대칭되게 배열되는 수평 배열 이미지 센서들(2310 ~ 2360) 중에서, 기준 이미지 센서 에 대해 상호 대칭되는 위치에 배열된 두 개의 수평 배열 이미지 센서들은 하나의 수평 배열 이미지 센서 쌍을 형성할 수 있다. 예를 들어, 도 3에서는 수평 배열 이미지 센서와 수직 배열 이미지 센서는 제1 수평 배열 이미지 쌍을 형성하고, 수평 배열 이미지 센서와 수평 배열 이미지 센서는 제2 수평 배열 이미지 쌍을 형 성하고, 수평 배열 이미지 센서와 수평 배열 이미지 센서는 제3 수평 배열 이미지 쌍을 형성할 수 있다. 단계 S5200에서, 제1 깊이 정보 및 제2 깊이 정보가 생성된다. 구체적으로, 깊이 이미지 생성 장치는 제1 미리 학습된 모델을 기반으로 수평 배열 이미지 세트로부터 제1 깊이 정보를 생성할 수 있다. 여기서, 수평 배열 이미지 세트는 수평 배열 이미지 센서 쌍을 구성하는 두 개의 수평 배열 이미지 센서 각각에 의해 촬영된 이미지와 기준 이미지 센서에 의해 촬영된 이미지를 포함할 수 있다. 일 실시예에서, 깊이 이미지 생성 장치는 N개의 수평 배열 이미지 센서 쌍이 존재하는 경우, N개의 수평 배열 이미지 센서 쌍으로부터 촬영된 이미지를 포함하는 N개의 수평 배열 이미지 세트 각각에 대해 제1 미리 학 습된 모델을 기반으로 제1 깊이 정보를 생성할 수 있다. 또한, 실시예에 따라 도 3에 도시된 바와 같이, N개의 수평 배열 이미지 세트 각각에 대한 제1 미리 학습된 모 델들이 서로 상이할 수 있다. 일 실시예에서, 제1 미리 학습된 모델은 CNN(Convolutional Neural Networks) 기반으로 인공지능 모델을 이용 하여 2차원 이미지로부터 깊이 정보를 추출하도록 학습된 모델일 수 있다. 일 실시예에서, 제1 미리 학습된 모델은 도 4에 도시된 바와 같이, 3개의 2차원 이미지로부터 깊이 정보를 생성 하는 비지도 학습 기반의 깊이 맵 추정 모델일 수 있다. 도 4에 도시된 깊이 맵 추정 모델은 두 개의 이미지를 이용하여 깊이 맵을 추정할 경우 발생할 수 있는 가림 영 역(occlusion)으로 인한 오차를 줄이기 위해 3 개의 이미지 즉, 기준 이미지, 좌측 이미지 및 우측 이미지를 이 용하여 깊이 정보를 생성하는 모델이다. 도 4의 깊이 맵 추정 모델은 좌측 이미지(Il)와 기준 이미지(Ic)로부터 깊이 정보 dcl을 생성 및 우측 이미지(I r)와 기준 이미지(Ic)로부터 깊이 정보 dcr을 생하고, 다시 깊이 정보 dcl 와 깊이 정보 dcr을 이용하여 최종적으 로 깊이 정보 dc를 생성할 수 있다. 도 4의 깊이 맵 추정 모델을 본 발명의 수평 배열 이미지 쌍에 적용하는 경우, Ic 는 기준 이미지 센서에 의해 촬영된 영상, Il 및 Ir 는 수평 배열 이미지 센서 쌍을 구성하는 각각의 수평 배열 이미지 센서에 의해 촬영된 영상을 의미하고, 깊이 정보 dc는 제1 깊이 정보를 의미한다. 또한, 깊이 이미지 생성 장치는 제2 미리 학습된 모델을 기반으로 수직 배열 이미지 세트로부터 제2 깊이 정보를 생성할 수 있다. 여기서, 수직 배열 이미지 세트는 수직 배열 이미지 센서 쌍을 구성하는 두 개의 수직 배열 이미지 센서 각각에 의해 촬영된 이미지와 기준 이미지 센서에 의해 촬영된 이미지를 포함할 수 있다. 일 실시예에서, 깊이 이미지 생성 장치는 M개의 수직 배열 이미지 센서 쌍이 존재하는 경우, M개의 수직 배열 이미지 센서 쌍으로부터 촬영된 이미지를 포함하는 M개의 수직 배열 이미지 세트 각각에 대해 제2 미리 학습된 모델을 기반으로 제2 깊이 정보를 생성할 수 있다. 또한, 실시예에 따라 도 3에 도시된 바와 같이, M개의 수직 배열 이미지 세트 각각에 대한 제2 미리 학습된 모 델들은 서로 상이할 수 있다. 일 실시예에서, 제2 미리 학습된 모델은 CNN(Convolutional Neural Networks) 기반으로 인공지능 모델을 이용 하여 2차원 이미지로부터 깊이 정보를 추출하도록 학습된 모델일 수 있다. 일 실시예에서, 제2 미리 학습된 모델은 도 4에 도시된 바와 같이, 3개의 2차원 이미지로부터 깊이 정보를 생성 하는 비지도 학습 기반의 깊이 맵 추정 모델일 수 있다. 도 4에 도시된 깊이 맵 추정 모델은 두 개의 이미지를 이용하여 깊이 맵을 추정할 경우 발생할 수 있는 가림 영역(occlusion)으로 인한 오차를 줄이기 위해 3 개의 이 미지 즉, 기준 이미지, 좌측 이미지 및 우측 이미지를 이용하여 깊이 정보를 생성하는 모델이다. 도 4의 깊이 맵 추정 모델은 좌측 이미지(Il)와 기준 이미지(Ic)로부터 깊이 정보 dcl을 생성 및 우측 이미지(I r)와 기준 이미지(Ic)로부터 깊이 정보 dcr을 생하고, 다시 깊이 정보 dcl 와 깊이 정보 dcr을 이용하여 최종적으 로 깊이 정보 dc를 생성할 수 있다. 도 4의 깊이 맵 추정 모델을 본 발명의 수직 배열 이미지 쌍에 적용하는 경우, Ic 는 기준 이미지 센서에 의해 촬영된 영상, Il 및 Ir 는 수직 배열 이미지 센서 쌍을 구성하는 각각의 수직 배열 이미지 센서에 의해 촬영된 영상을 의미하고, 깊이 정보 dc는 제2 깊이 정보를 의미한다. 단계 S5300에서, 제3 깊이 정보가 생성된다. 구체적으로 깊이 이미지 생성 장치는 제1 깊이 정보 및 제2 깊이 정보를 기반으로 최종 깊이 정보인 제3 깊이 정보를 생성할 수 있다. 일 실시예에서, 깊이 이미지 생성 장치는 도 3에 도시된 바와 같이, 제1 깊이 정보들에 대해 앙상블 기법 을 적용하여 하나의 깊이 정보를 생성하고, 제2 깊이 정보들에 대해 앙상블 기법을 적용하여 하나의 깊이 정보 를 생성하여, 제1 깊이 정보들에 대해 앙상블 기법을 적용하여 생성한 깊이 정보와 제2 깊이 정보들에 대해 앙 상블 기법을 적용하여 생성한 깊이 정보에 대해 다시 앙상블 기법을 적용하여 최종 깊이 정보인 제3 깊이 정보 를 생성할 수 있다. 일 실시예에서, 깊이 이미지 생성 장치는 보팅(Voting), 배깅(Bagging) 및 부스팅(Boosting) 등의 앙상 블 기법을 이용하여 최종 깊이 정보를 생성할 수 있다. 단계 S5400에서, 깊이 이미지가 생성된다. 구체적으로, 깊이 이미지 생성 장치는 최종 깊이 정보인 제3 깊이 정보를 기반으로 3차원 공간 정보를 포함하는 깊이 맵 이미지를 생성할 수 있다. 도 6은 본 발명의 다른 실시예에 따른 깊이 이미지 생성 장치의 블록도이다. 도 6에 도시된 바와 같이, 깊이 이미지 생성 장치는 프로세서, 메모리, 저장부, 사용 자 인터페이스 입력부 및 사용자 인터페이스 출력부 중 적어도 하나 이상의 요소를 포함할 수 있으 며, 이들은 버스를 통해 서로 통신할 수 있다. 또한, 깊이 이미지 생성 장치는 네트워크에 접속하 기 위한 네트워크 인터페이스를 또한 포함할 수 있다. 프로세서는 메모리 및/또는 저장소 에 저장된 처리 명령어를 실행시키는 CPU 또는 반도체 소자일 수 있다. 메모리 및 저장부는 다양한 유형의 휘발성/비휘발성 기억 매체를 포함할 수 있다. 예를 들어, 메모리는 ROM 및 RAM을 포함할 수 있다. 이상에서 설명된 장치는 하드웨어 구성요소, 소프트웨어 구성요소, 및/또는 하드웨어 구성요소 및 소프트웨어 구성요소의 조합으로 구현될 수 있다. 예를 들어, 실시예들에서 설명된 장치 및 구성요소는, 예를 들어, 프로세 서, 콘트롤러, ALU(arithmetic logic unit), 디지털 신호 프로세서(digital signal processor), 마이크로컴퓨 터, FPA(field programmable array), PLU(programmable logic unit), 마이크로프로세서, 또는 명령 (instruction)을 실행하고 응답할 수 있는 다른 어떠한 장치와 같이, 하나 이상의 범용 컴퓨터 또는 특수 목적 컴퓨터를 이용하여 구현될 수 있다. 처리 장치는 운영 체제(OS) 및 상기 운영 체제 상에서 수행되는 하나 이상의 소프트웨어 애플리케이션을 수행할 수 있다. 또한, 처리 장치는 소프트웨어의 실행에 응답하여, 데이터를 접근, 저장, 조작, 처리 및 생성할 수도 있다. 이"}
{"patent_id": "10-2021-0176823", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "해의 편의를 위하여, 처리 장치는 하나가 사용되는 것으로 설명된 경우도 있지만, 해당 기술분야에서 통상의 지 식을 가진 자는, 처리 장치가 복수 개의 처리 요소(processing element) 및/또는 복수 유형의 처리 요소를 포함 할 수 있음을 알 수 있다. 예를 들어, 처리 장치는 복수 개의 프로세서 또는 하나의 프로세서 및 하나의 콘트롤 러를 포함할 수 있다. 또한, 병렬 프로세서(parallel processor)와 같은, 다른 처리 구성(processing configuration)도 가능하다. 소프트웨어는 컴퓨터 프로그램(computer program), 코드(code), 명령(instruction), 또는 이들 중 하나 이상의 조합을 포함할 수 있으며, 원하는 대로 동작하도록 처리 장치를 구성하거나 독립적으로 또는 결합적으로 (collectively) 처리 장치를 명령할 수 있다. 소프트웨어 및/또는 데이터는, 처리 장치에 의하여 해석되거나 처 리 장치에 명령 또는 데이터를 제공하기 위하여, 어떤 유형의 기계, 구성요소(component), 물리적 장치, 가상 장치(virtual equipment), 컴퓨터 저장 매체 또는 장치, 또는 전송되는 신호 파(signal wave)에 영구적으로, 또는 일시적으로 구체화(embody)될 수 있다. 소프트웨어는 네트워크로 연결된 컴퓨터 시스템 상에 분산되어서, 분산된 방법으로 저장되거나 실행될 수도 있다. 소프트웨어 및 데이터는 하나 이상의 컴퓨터 판독 가능 기록 매 체에 저장될 수 있다."}
{"patent_id": "10-2021-0176823", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "이상과 같이 실시예들이 비록 한정된 도면에 의해 설명되었으나, 해당 기술분야에서 통상의 지식을 가진 자라면 상기의 기재로부터 다양한 수정 및 변형이 가능하다. 예를 들어, 설명된 기술들이 설명된 방법과 다른 순서로 수행되거나, 및/또는 설명된 시스템, 구조, 장치, 회로 등의 구성요소들이 설명된 방법과 다른 형태로 결합 또 는 조합되거나, 다른 구성요소 또는 균등물에 의하여 대치되거나 치환되더라도 적절한 결과가 달성될 수 있다. 그러므로, 다른 구현들, 다른 실시예들 및 특허청구범위와 균등한 것들도 후술하는 특허청구범위의 범위에 속한 다."}
{"patent_id": "10-2021-0176823", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1 내지 도 4는 본 발명의 일 실시예에 따른 깊이 이미지 생성 장치를 설명하기 위한 도면이다. 도 5는 본 발명의 일 실시예에 따른 깊이 이미지 생성 방법의 흐름도이다. 도 6은 본 발명의 다른 실시예에 따른 깊이 이미지 생성 장치의 블록도이다."}
