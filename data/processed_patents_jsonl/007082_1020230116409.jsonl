{"patent_id": "10-2023-0116409", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2025-0033814", "출원번호": "10-2023-0116409", "발명의 명칭": "깊이 정보를 이용한 딥러닝 기반 버추얼 휴먼 생성 방법 및 그 장치", "출원인": "이지원", "발명자": "이지원"}}
{"patent_id": "10-2023-0116409", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "컴퓨터 장치에 의해 실행되는 버추얼 휴먼 생성 방법에 있어서,실제 사람을 촬영하여 획득되는 촬영 정보를 수집하는 단계;상기 촬영 정보로부터 입력 이미지를 획득하는 단계;상기 입력 이미지를, 버추얼 휴먼 생성을 위해 딥러닝 기반으로 사전 학습된 이미지 변형 학습 모델에입력하여, 버추얼 휴먼 생성용 변형 이미지를 획득하는 단계;상기 변형 이미지에 대응하는 깊이 추정을 수행하여, 변형 깊이 정보를 획득하는 단계;상기 변형 이미지와 상기 변형 깊이 정보를 이용한 3차원 모델을 구성하는 단계; 및상기 구성된 3차원 모델을 이용하여, 상기 촬영 정보에 대응하는 버추얼 휴먼 모델을 생성하는 단계를 포함하는버추얼 휴먼 생성 방법."}
{"patent_id": "10-2023-0116409", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 버추얼 휴먼 모델을 이용하여 생성되는 버추얼 휴먼 콘텐츠를, 하나 이상의 사용자 디바이스로 제공하는단계를 더 포함하는버추얼 휴먼 생성 방법."}
{"patent_id": "10-2023-0116409", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 변형 깊이 정보를 획득하는 단계는,깊이 정보와 단안(monocular) 이미지가 사전 학습된 깊이 추정 학습 모델을 이용하여, 상기 변형 이미지를 단안이미지로 입력받아 이미지 내 상대적 깊이를 역추정하는 단계를 포함하는버추얼 휴먼 생성 방법."}
{"patent_id": "10-2023-0116409", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,상기 촬영 정보는 사용자의 휴대용 디바이스의 전면 카메라로부터 촬영된 이미지 정보를 포함하는버추얼 휴먼 생성 방법."}
{"patent_id": "10-2023-0116409", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서,상기 사전 학습된 이미지 변형 학습 모델은,상기 촬영 정보에 사용자의 손 이미지가 일측만 포함된 경우, 상기 버추얼 휴먼 생성용 변형 이미지 및 변형 깊이 정보는, 상기 손 이미지에 대응하는 가상의 타측 손 이미지가 더 포함되도록 학습 구성되는버추얼 휴먼 생성 방법."}
{"patent_id": "10-2023-0116409", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "공개특허 10-2025-0033814-3-제1항에 있어서,상기 변형 이미지와 변형 깊이 정보를 이용한 3차원 모델을 구성하는 단계는,상기 촬영 정보의 영상 프레임에 대응하여, 상기 버추얼 휴먼 생성용 변형 이미지 및 변형 깊이 정보를 이용한영상 프레임 이미지 시퀀스를 생성하는 단계를 포함하는버추얼 휴먼 생성 방법."}
{"patent_id": "10-2023-0116409", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에 있어서,상기 사전 학습된 이미지 변형 학습 모델은,상기 촬영 정보에 대응하여 개별적으로 입력되는 프롬프트의 텍스트 정보를 획득하고, 상기 텍스트 정보에 기초하여 상기 입력 이미지에 대응하는 변형 이미지를 생성함에 따라, 상기 버추얼 휴먼 모델의 캐릭터, 표정 또는동작 중 적어도 하나를 가변시키는 모델인버추얼 휴먼 생성 방법."}
{"patent_id": "10-2023-0116409", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서,상기 사전 학습된 이미지 변형 학습 모델은,스테이블 디퓨전(stable diffusion) 알고리즘 기반의 이미지 합성 학습 모델을 이용하여 상기 변형 이미지를 생성하는버추얼 휴먼 생성 방법."}
{"patent_id": "10-2023-0116409", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1항 내지 제8항 중 어느 한 항에 기재된 방법을 컴퓨터에서 실행시키기 위해 컴퓨터 판독 가능한 매체에 저장되는 컴퓨터프로그램."}
{"patent_id": "10-2023-0116409", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "컴퓨터 장치를 포함하는 서버에 있어서,실제 사람을 촬영하여 획득되는 촬영 정보를 수집하는 촬영 정보 수집부;상기 촬영 정보로부터 입력 이미지를 획득하고, 상기 입력 이미지를 버추얼 휴먼 생성을 위해 딥러닝 기반으로사전 학습된 이미지 변형 학습 모델에 입력하여, 버추얼 휴먼 생성용 변형 이미지를 획득하는 이미지 변형부;상기 변형 이미지에 대응하는 깊이 추정을 수행하여 변형 깊이 정보를 획득하며, 상기 변형 이미지와 상기 변형깊이 정보를 이용한 3차원 모델을 구성하는 3차원 모델 구성부; 및상기 구성된 3차원 모델을 이용하여, 상기 촬영 정보에 대응하는 버추얼 휴먼 모델을 생성하는 버추얼 휴먼 생성부를 포함하는서버."}
{"patent_id": "10-2023-0116409", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명의 실시 예에 따른 방법은, 컴퓨터 장치에 의해 실행되는 버추얼 휴먼 생성 방법에 있어서, 실제 사람을 촬영하여 획득되는 촬영 정보를 수집하는 단계; 상기 촬영 정보로부터 입력 이미지를 획득하는 단계; 상기 입력 이미지를, 버추얼 휴먼 생성을 위해 딥러닝 기반으로 사전 학습된 이미지 변형 학습 모델에 입력하여, 버추얼 휴 먼 생성용 변형 이미지를 획득하는 단계; 상기 변형 이미지에 대응하는 깊이 추정을 수행하여, 변형 깊이 정보를 획득하는 단계; 상기 변형 이미지와 상기 변형 깊이 정보를 이용한 3차원 모델을 구성하는 단계; 및 상기 구성된 3차원 모델을 이용하여, 상기 촬영 정보에 대응하는 버추얼 휴먼 모델을 생성하는 단계를 포함한다."}
{"patent_id": "10-2023-0116409", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 버추얼 휴먼 생성 방법 및 그 장치에 관한 것이다. 보다 구체적으로, 본 발명은 깊이 정보를 이용한 딥러닝 기반 버추얼 휴먼 생성 방법 및 그 장치에 관한 것이다."}
{"patent_id": "10-2023-0116409", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "최근 버추얼 휴먼을 이용하여 콘텐츠를 제공하는 컴퓨팅 기술에 대한 인공지능 알고리즘 기반의 다양한 관심과 발전이 이루어지고 있다. 특히, 현재 알려진 로지 등과 같은 버추얼 휴먼들은 인플루언서 활동 또는 광고에서 다양하게 이용되고 있다. 이러한 버추얼 휴먼 생성 기술은, 실제 사람의 촬영 정보를 기반으로 각 촬영 정보 내 얼굴과 신체 부분들을 3 차원 모델로 변형하는 이미지 처리를 수행하는 것이 일반적이며, 현재까지 대부분의 콘텐츠 생성에는 이러한 이 미지 변형 처리 기술들이 이용되고 있다. 그러나, 현재의 기술들은 실제 사람의 촬영 정보를 3차원 모델 이미지로 처리하기 위하여, 통상적으로 한명의 가상인간에 대해 그 가상인간 역할을 하는 실제 사람 3~5명정도가 준비되어 있어야 하며, 이들의 얼굴을 목적하 는 가상인간의 얼굴로 변형하기 위한 연산과정이 각각 개별적으로 요구되고 있는 실정이다. 따라서, 실제 사람의 표정이나 행동 등을 버추얼 휴먼의 표정과 몸짓으로 변형하기 위하여는 상당한 전문인력과 비용 및 시간이 소요되고 있으며, 실시간 처리나 일반 사용자들의 콘텐츠 제작 편의성 등은 고려되지 못하고 있 다."}
{"patent_id": "10-2023-0116409", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 상기한 바와 같은 과제를 해결하고자 안출된 것으로, 실제 사람의 촬영 정보에 대응하여, 깊이 정보 를 추출하여 이미지를 변형하는 딥러닝 학습 모델을 기반으로, 3차원 모델로 구성된 버추얼 휴먼들을 다양한 형 태로 생성하고, 그 표정이나 몸짓 변형을 3차원 모델 기반으로 실시간으로 처리함에 따라, 별도의 추가적인 인 력 동원 없이도 신속하고 편리하게 버추얼 휴먼을 생성하여 다양한 콘텐츠를 제공할 수 있는 버추얼 휴먼 생성 방법 및 그 장치를 제공하는 데 그 목적이 있다. 본 명세서의 해결하고자 하는 과제는 상술한 바에 한정되지 아니하고, 하기에서 설명하는 발명의 실시예들에 의 해 도출될 수 있는 다양한 사항들로 확장될 수 있다."}
{"patent_id": "10-2023-0116409", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기한 바와 같은 과제를 해결하기 위한 본 발명의 실시 예에 따른 방법은, 컴퓨터 장치에 의해 실행되는 버추 얼 휴먼 생성 방법에 있어서, 실제 사람을 촬영하여 획득되는 촬영 정보를 수집하는 단계; 상기 촬영 정보로부 터 입력 이미지를 획득하는 단계; 상기 입력 이미지를, 버추얼 휴먼 생성을 위해 딥러닝 기반으로 사전 학습된 이미지 변형 학습 모델에 입력하여, 버추얼 휴먼 생성용 변형 이미지를 획득하는 단계; 상기 변형 이미지에 대 응하는 깊이 추정을 수행하여, 변형 깊이 정보를 획득하는 단계; 상기 변형 이미지와 상기 변형 깊이 정보를 이 용한 3차원 모델을 구성하는 단계; 및 상기 구성된 3차원 모델을 이용하여, 상기 촬영 정보에 대응하는 버추얼 휴먼 모델을 생성하는 단계를 포함한다. 또한 상기한 바와 같은 과제를 해결하기 위한 본 발명의 실시 예에 따른 방법은, 상기 방법을 컴퓨터에서 실행 시키기 위해 컴퓨터 판독 가능한 매체에 저장되는 컴퓨터프로그램으로 구현될 수 있다. 또한, 상기한 바와 같은 과제를 해결하기 위한 본 발명의 실시 예에 따른 장치는, 컴퓨터 장치를 포함하는 서버 에 있어서, 실제 사람을 촬영하여 획득되는 촬영 정보를 수집하는 촬영 정보 수집부; 상기 촬영 정보로부터 입 력 이미지를 획득하고, 상기 입력 이미지를 버추얼 휴먼 생성을 위해 딥러닝 기반으로 사전 학습된 이미지 변형 학습 모델에 입력하여, 버추얼 휴먼 생성용 변형 이미지를 획득하는 이미지 변형부; 상기 변형 이미지에 대응하 는 깊이 추정을 수행하여 변형 깊이 정보를 획득하며, 상기 변형 이미지와 상기 변형 깊이 정보를 이용한 3차원 모델을 구성하는 3차원 모델 구성부; 및 상기 구성된 3차원 모델을 이용하여, 상기 촬영 정보에 대응하는 버추 얼 휴먼 모델을 생성하는 버추얼 휴먼 생성부를 포함한다."}
{"patent_id": "10-2023-0116409", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명의 실시 예에 따르면, 실제 사람을 촬영하여 획득되는 촬영 정보로부터, 버추얼 휴먼 생성용 변형 이미 지를 획득하며, 상기 변형 이미지에 대응하는 깊이 추정을 수행하여 상기 변형 이미지와 상기 변형 깊이 정보를 이용한 3차원 모델을 구성함에 따라, 효율적으로 버추얼 휴먼 모델을 생성할 수 있다. 이에 따라, 본 발명은 딥러닝 학습 모델을 기반으로, 이미지를 변형하고 깊이 정보를 추출함에 따라, 3차원 모 델로 구성된 버추얼 휴먼들을 다양한 형태로 생성하고, 그 표정이나 몸짓 변형을 3차원 모델 기반으로 실시간으로 처리할 수 있다. 따라서, 본 발명의 실시 예에 따르면 별도의 추가적인 인력 동원 없이도 신속하고 편리하게 버추얼 휴먼을 생성 하여 다양한 콘텐츠를 제공할 수 있는 버추얼 휴먼 생성 방법 및 그 장치를 제공할 수 있다. 나아가, 본 발명의 실시 예는 스마트폰과 같이 간단한 촬영 디바이스만으로도 손쉽게 버추얼 휴먼 생성이 가능 하게 하며, 이를 위한 모델 생성의 신속성 및 편의성을 제공할 수 있다."}
{"patent_id": "10-2023-0116409", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 명세서의 실시예를 설명함에 있어서 공지 구성 또는 기능에 대한 구체적인 설명이 본 명세서의 실시예의 요 지를 흐릴 수 있다고 판단되는 경우에는 그에 대한 상세한 설명은 생략한다. 그리고, 도면에서 본 명세서의 실 시예에 대한 설명과 관계없는 부분은 생략하였으며, 유사한 부분에 대해서는 유사한 도면 부호를 붙였다. 본 명세서의 실시예에 있어서, 어떤 구성요소가 다른 구성요소와 \"연결\", \"결합\" 또는 \"접속\"되어 있다고 할 때, 이는 직접적인 연결관계뿐만 아니라, 그 중간에 또 다른 구성요소가 존재하는 간접적인 연결관계도 포함할 수 있다. 또한 어떤 구성요소가 다른 구성요소를 \"포함한다\" 또는 \"가진다\"고 할 때, 이는 특별히 반대되는 기 재가 없는 한 다른 구성요소를 배제하는 것이 아니라 또 다른 구성요소를 더 포함할 수 있는 것을 의미한다. 본 명세서의 실시예에 있어서, 제1, 제2 등의 용어는 하나의 구성요소를 다른 구성요소로부터 구별하는 목적으 로만 사용되며, 특별히 언급되지 않는 한 구성요소들간의 순서 또는 중요도 등을 한정하지 않는다. 따라서, 본 명세서의 실시예의 범위 내에서 실시예에서의 제1 구성요소는 다른 실시예에서 제2 구성요소라고 칭할 수도 있 고, 마찬가지로 실시예에서의 제2 구성요소를 다른 실시예에서 제1 구성요소라고 칭할 수도 있다. 본 명세서의 실시예에 있어서, 서로 구별되는 구성요소들은 각각의 특징을 명확하게 설명하기 위함이며, 구성요 소들이 반드시 분리되는 것을 의미하지는 않는다. 즉, 복수의 구성요소가 통합되어 하나의 하드웨어 또는 소프 트웨어 단위로 이루어질 수도 있고, 하나의 구성요소가 분산되어 복수의 하드웨어 또는 소프트웨어 단위로 이루 어질 수도 있다. 따라서, 별도로 언급하지 않더라도 이와 같이 통합된 또는 분산된 실시예도 본 명세서의 실시 예의 범위에 포함된다. 본 명세서에서 네트워크는 유무선 네트워크를 모두 포함하는 개념일 수 있다. 이때, 네트워크는 디바이스와 시 스템 및 디바이스 상호 간의 데이터 교환이 수행될 수 있는 통신망을 의미할 수 있으며, 특정 네트워크로 한정 되는 것은 아니다. 본 명세서에 기술된 실시예는 전적으로 하드웨어이거나, 부분적으로 하드웨어이고 부분적으로 소프트웨어이거나, 또는 전적으로 소프트웨어인 측면을 가질 수 있다. 본 명세서에서 \"부(unit)\", \"장치\" 또는 \"시스템\" 등은 하드웨어, 하드웨어와 소프트웨어의 조합, 또는 소프트웨어 등 컴퓨터 관련 엔티티(entity)를 지 칭한다. 예를 들어, 본 명세서에서 부, 모듈, 장치 또는 시스템 등은 실행중인 프로세스, 프로세서, 객체 (object), 실행 파일(executable), 실행 스레드(thread of execution), 프로그램(program), 및/또는 컴퓨터 (computer)일 수 있으나, 이에 제한되는 것은 아니다. 예를 들어, 컴퓨터에서 실행중인 애플리케이션 (application) 및 컴퓨터의 양쪽이 모두 본 명세서의 부, 모듈, 장치 또는 시스템 등에 해당할 수 있다. 또한, 본 명세서에서 디바이스는 스마트폰, 태블릿 PC, 웨어러블 디바이스 및 HMD(Head Mounted Display)와 같 이 모바일 디바이스뿐만 아니라, PC나 디스플레이 기능을 구비한 가전처럼 고정된 디바이스일 수 있다. 또한,일 예로, 디바이스는 차량 내 클러스터 또는 IoT (Internet of Things) 디바이스일 수 있다. 즉, 본 명세서에서 디바이스는 어플리케이션 동작이 가능한 기기들을 지칭할 수 있으며, 특정 타입으로 한정되지 않는다. 하기에서 는 설명의 편의를 위해 어플리케이션이 동작하는 기기를 디바이스로 지칭한다. 본 명세서에 있어서 네트워크의 통신 방식은 제한되지 않으며, 각 구성요소간 연결이 동일한 네트워크 방식으로 연결되지 않을 수도 있다. 네트워크는, 통신망(일례로, 이동통신망, 유선 인터넷, 무선 인터넷, 방송망, 위성망 등)을 활용하는 통신 방식뿐만 아니라 기기들간의 근거리 무선 통신 역시 포함될 수 있다. 예를 들어, 네트워 크는, 객체와 객체가 네트워킹 할 수 있는 모든 통신 방법을 포함할 수 있으며, 유선 통신, 무선 통신, 3G, 4G, 5G, 혹은 그 이외의 방법으로 제한되지 않는다. 예를 들어, 유선 및/또는 네트워크는 LAN(Local Area Network), MAN(Metropolitan Area Network), GSM(Global System for Mobile Network), EDGE(Enhanced Data GSM Environment), HSDPA(High Speed Downlink Packet Access), W-CDMA(Wideband Code Division Multiple Access), CDMA(Code Division Multiple Access), TDMA(Time Division Multiple Access), 블루투스 (Bluetooth), 지그비(Zigbee), 와이-파이(Wi-Fi), VoIP(Voice over Internet Protocol), LTE Advanced, IEEE802.16m, WirelessMAN-Advanced, HSPA+, 3GPP Long Term Evolution (LTE), Mobile WiMAX (IEEE 802.16e), UMB (formerly EV-DO Rev. C), Flash-OFDM, iBurst and MBWA (IEEE 802.20) systems, HIPERMAN, Beam- Division Multiple Access (BDMA), Wi-MAX(World Interoperability for Microwave Access) 및 초음파 활용 통 신으로 이루어진 군으로부터 선택되는 하나 이상의 통신 방법에 의한 통신 네트워크를 지칭할 수 있으나, 이에 한정되는 것은 아니다. 다양한 실시예에서 설명하는 구성요소들이 반드시 필수적인 구성요소들은 의미하는 것은 아니며, 일부는 선택적 인 구성요소일 수 있다. 따라서, 실시예에서 설명하는 구성요소들의 부분집합으로 구성되는 실시예도 본 명세서 의 실시예의 범위에 포함된다. 또한, 다양한 실시예에서 설명하는 구성요소들에 추가적으로 다른 구성요소를 포 함하는 실시예도 본 명세서의 실시예의 범위에 포함된다. 이하에서, 도면을 참조하여 본 명세서의 실시예들에 대하여 상세히 살펴본다. 도 1은 본 명세서의 일실시예에 따른 시스템의 동작 환경의 예를 도시한 도면이다. 도 1을 참조하면 사용자 디 바이스, 하나 이상의 서버(120, 130, 140)가 네트워크를 통해 연결되어 있다. 이러한 도 1은 발명의 설명을 위한 일례로 사용자 디바이스의 수나 서버의 수가 도 1과 같이 한정되는 것은 아니다. 사용자 디바이스는 컴퓨터 시스템으로 구현되는 고정형 단말이거나 이동형 단말일 수 있다. 사용자 디바이 스는 예를 들면, 스마트폰(smart phone), 휴대폰, 내비게이션, 컴퓨터, 노트북, 디지털방송용 단말, PDA(Personal Digital Assistants), PMP(Portable Multimedia Player), 태블릿 PC, 게임 콘솔(game console), 웨어러블 디바이스(wearable device), IoT(internet of things) 디바이스, VR(virtual reality) 디바이스, AR(augmented reality) 디바이스 등이 있다. 일례로 실시예들에서 사용자 디바이스는 실질적으로 무선 또 는 유선 통신 방식을 이용하여 네트워크를 통해 다른 서버들(120 - 140)과 통신할 수 있는 다양한 물리적인 컴퓨터 시스템들 중 하나를 의미할 수 있다. 각 서버는 사용자 디바이스와 네트워크를 통해 통신하여 명령, 코드, 파일, 콘텐츠, 서비스 등을 제공 하는 컴퓨터 장치 또는 복수의 컴퓨터 장치들로 구현될 수 있다. 예를 들어, 서버는 네트워크를 통해 접속 한 사용자 디바이스로 각각의 서비스를 제공하는 시스템일 수 있다. 보다 구체적인 예로, 서버는 사용자 디바이스에 설치되어 구동되는 컴퓨터 프로그램으로서의 어플리케이션을 통해, 해당 어플리케이션이 목적 하는 서비스(일례로, 정보 제공 등)를 사용자 디바이스로 제공할 수 있다. 다른 예로, 서버는 상술한 어 플리케이션의 설치 및 구동을 위한 파일을 사용자 디바이스로 배포하고 사용자 입력 정보를 수신해 대응하 는 서비스를 제공할 수 있다. 도 2는 본 명세서의 일실시예에 있어서 컴퓨팅 장치의 내부 구성을 설명하기 위한 블록도이다. 이러한 컴 퓨팅 장치는 도1을 참조하여 상술한 사용자 디바이스 또는 서버(120-140)에 적용될 수 있으며, 각 장 치와 서버들은 일부 구성요소를 더 하거나 제외하여 구성됨으로써 동일하거나 유사한 내부 구성을 가질 수 있다. 도 2를 참조하면 컴퓨팅 장치는 메모리, 프로세서, 통신 모듈 그리고 송수신부를 포 함할 수 있다. 메모리는 비-일시적인 컴퓨터 판독 가능한 기록매체로서, RAM(random access memory), ROM(read only memory), 디스크 드라이브, SSD(solid state drive), 플래시 메모리(flash memory) 등과 같은 비소멸성 대용량 저장 장치(permanent mass storage device)를 포함할 수 있다. 여기서 ROM, SSD, 플래시 메모리, 디스크 드라이브 등과 같은 비소멸성 대용량 저장 장치는 메모리와는 구분되는 별도의 영구 저장 장 치로서 상술한 장치나 서버에 포함될 수도 있다. 또한, 메모리에는 운영체제와 적어도 하나의 프로그램 코드(일례로 사용자 디바이스 등에 설치되어 구동되는 브라우저나 특정 서비스의 제공을 위해 사용자 디바 이스 등에 설치된 어플리케이션 등을 위한 코드)가 저장될 수 있다. 이러한 소프트웨어 구성요소들은 메 모리와는 별도의 컴퓨터에서 판독 가능한 기록매체로부터 로딩될 수 있다. 이러한 별도의 컴퓨터에서 판 독 가능한 기록매체는 플로피 드라이브, 디스크, 테이프, DVD/CD-ROM 드라이브, 메모리 카드 등의 컴퓨터에서 판독 가능한 기록매체를 포함할 수 있다. 다른 실시예에서 소프트웨어 구성요소들은 컴퓨터에서 판독 가능한 기록매체가 아닌 통신 모듈을 통해 메 모리에 로딩될 수도 있다. 예를 들어, 적어도 하나의 프로그램은 개발자들 또는 어플리케이션의 설치 파 일을 배포하는 파일 배포 시스템(일례로, 상술한 서버)이 네트워크를 통해 제공하는 파일들에 의해 설치되는 컴퓨터 프로그램(일례로 상술한 어플리케이션)에 기반하여 메모리에 로딩될 수 있다. 프로세서는 기본적인 산술, 로직 및 입출력 연산을 수행함으로써, 컴퓨터 프로그램의 명령을 처리하도록 구성될 수 있다. 명령은 메모리 또는 통신 모듈에 의해 프로세서로 제공될 수 있다. 예를 들어 프로세서는 메모리와 같은 기록 장치에 저장된 프로그램 코드에 따라 수신되는 명령을 실행하도록 구 성될 수 있다. 통신 모듈은 네트워크를 통해 사용자 기기와 서버(120 -140)가 서로 통신하기 위한 기능을 제공할 수 있으며, 장치 및/또는 서버(120 - 140) 각각이 다른 전자 기기와 통신하기 위한 기능을 제공할 수 있다. 송수신부는 외부 입력/출력장치(미도시)와의 인터페이스를 위한 수단일 수 있다. 예를 들어, 외부 입력장 치는 키보드, 마우스, 마이크로폰, 카메라 등의 장치를, 그리고 외부 출력 장치는 디스플레이, 스피커, 햅틱 피 드백 디바이스(haptic feedback device) 등과 같은 장치를 포함할 수 있다. 다른 예로 송수신부는 터치스크린과 같이 입력과 출력을 위한 기능이 하나로 통합된 장치와의 인터페이스 를 위한 수단일 수도 있다. 또한, 다른 실시예들에서 컴퓨팅 장치는 적용되는 장치의 성질에 따라서 도 2의 구성요소들보다 더 많은 구성요소들을 포함할 수도 있다. 예를 들어, 컴퓨팅 장치가 사용자 디바이스에 적용되는 경우 상술한 입출력 장치 중 적어도 일부를 포함하도록 구현되거나 또는 트랜시버(transceiver), GPS(Global Positioning System) 모듈, 카메라, 각종 센서, 데이터베이스 등과 같은 다른 구성요소들을 더 포함할 수도 있다. 보다 구 체적인 예로, 사용자 디바이스가 스마트폰인 경우, 일반적으로 스마트폰이 포함하고 있는 가속도 센서나 자이로 센서, 카메라 모듈, 각종 물리적인 버튼, 터치패널을 이용한 버튼, 입출력 포트, 진동을 위한 진동기 등의 다양 한 구성요소들이 더 포함되도록 구현될 수 있다. 도 3은 본 발명의 실시 예에 따른 서비스 처리부 및 그 구성을 설명하기 위한 블록도이다. 도 3을 참조하면, 본 발명의 실시 예에 따른 컴퓨팅 장치는, 버추얼 휴먼 서비스 처리부를 더 포함할 수 있다. 버추얼 휴먼 서비스 처리부는, 프로세서에서 처리되는 로직 및 입출력 연산 중 본 발명의 실시 예에 따른 데이터 처리를 위한 다양한 서비스 프로세스를 수행하는 프로세서 모듈로 구성될 수 있다. 컴퓨 팅 장치는, 프로세서 내부에 버추얼 휴먼 서비스 처리부를 구성하거나, 버추얼 휴먼 서비스 처 리부가 외부 프로세서로 구비된 장치로부터 처리된 데이터를 이용하여 버추얼 휴먼 서비스 처리를 수행함 으로써, 생성된 버추얼 휴먼 콘텐츠 정보를 사용자 디바이스 또는 하나 이상의 서버(120, 130, 140)로 제 공할 수 있다. 이러한 처리에 따라, 사용자 디바이스 또는 하나 이상의 서버(120, 130, 140)는 본 발명의 실시 예에 따른 버추얼 휴먼 서비스 처리부 동작에 의해 구성된 버추얼 휴먼 콘텐츠를 제공받아 디스플레이 장치를 통해 출력하거나, 외부 네트워크를 통해 데이터를 송수신하는 데 이용할 수 있다. 보다 구체적으로, 도 3을 참조하면, 버추얼 휴먼 서비스 처리부는 촬영 정보 수집부, 학습 모델 기반 이미지 변형부, 3차원 모델 구성부, 버추얼 휴먼 생성부 및 콘텐츠 제공부를 포함할 수 있 으며, 이러한 각 처리부의 연계 동작을 통해 버추얼 휴먼 콘텐츠 생성 및 제공 프로세스를 수행할 수 있다. 특히, 버추얼 휴먼 서비스 처리부는, 버추얼 휴먼 콘텐츠 생성을 위한 촬영 정보를 수집하여, 버추얼 휴먼 생성을 위해 사전 딥러닝 학습된 학습 모델 기반의 이미지 변형을 처리하며, 변형 이미지에 대응하는 깊이 추정 을 통해 획득된 변형 깊이 정보와 변형 이미지를 이용한 3차원 모델을 구성하고, 구성된 3차원 모델 기반의 버 추얼 휴먼을 생성하며, 생성된 버추얼 휴먼을 이용한 버추얼 휴먼 콘텐츠 데이터를 구성하여, 프로세서 또 는 외부 장치, 네트워크 등으로 출력할 수 있다. 여기서, 앞서 설명한 바와 같은 종래기술의 문제점에 따르면, 실제 사람의 형태 및 동작을 반영하는 경우 하나 의 모델 구성을 위해 여러 사람의 촬영 데이터가 요구되는 한계가 있는 바, 본 발명의 실시 예에 따른 버추얼 휴먼 서비스 처리부는 스마트폰과 같은 사용자 디바이스에서 촬영된 촬영 정보만 입력되면, 다양한 프롬프트 설정에 따른 버추얼 휴먼의 3차원 모델 데이터가 구성되어 버추얼 휴먼 콘텐츠를 생성할 수 있게 되며, 이는 콘텐츠 생성 속도를 현저히 향상시키며 콘텐츠 생산 편의성 또한 크게 향상시킬 수 있게 한다. 이를 위해 먼저 촬영 정보 수집부는, 버추얼 휴먼 콘텐츠 구성을 위한 실제 사람의 촬영 정보를 수집한다. 여기서, 상기 촬영 정보는, 실제 사람의 이미지를 여러 각도에서 촬영한 영상 또는 프레임 이미지를 포함할 수 있으며, 사용자 디바이스 등에서의 비전 센서를 통해 센싱된 이미지 데이터를 포함할 수 있다. 또한, 사용 자 디바이스에 라이다 센서 등이 구비된 경우에는 상기 촬영 정보에 상기 라이다 센서 정보가 더 포함될 수도 있다. 그리고, 학습 모델 기반 이미지 변형부는, 상기 촬영 정보로부터 입력 이미지를 획득하며, 상기 입력 이미 지를, 버추얼 휴먼 생성을 위해 딥러닝 기반으로 사전 학습된 이미지 변형 학습 모델에 입력하여, 버추얼 휴먼 생성용 변형 이미지를 획득한다. 여기서, 상기 학습 모델 기반 이미지 변형부는, 상기 촬영 정보의 입력 이미지와 함께, 상기 촬영 정보에 대응하여 개별적으로 입력되는 프롬프트의 텍스트 정보를 획득하고, 상기 텍스트 정보에 기초하여 상기 입력 이 미지에 대응하는 변형 이미지를 생성함에 따라, 상기 버추얼 휴먼 모델의 캐릭터, 표정 또는 동작 중 적어도 하 나를 가변시키는 모델로 구성될 수 있다. 또한, 예를 들어 학습 모델 기반 이미지 변형부는, 스테이블 디퓨전(stable diffusion) 알고리즘 기반의 이미지 합성 학습 모델을 이용하여 상기 변형 이미지를 생성하는 모델일 수 있다. 여기서, 스테이블 디퓨전은 사전 학습된 학습 모델을 이용하여, 텍스트 프롬프트에서 사실적인 이미지를 생성할 수 있는 텍스트-이미지 모델로서, 스테이블 디퓨전 모델은 실제 이미지에 추가된 노이즈를 제거하는 방법을 딥 러닝 방식으로 학습할 수 있다. 이러한 노이즈 제거 프로세스는 사실적인 이미지를 생성하게 한다. 예를 들어 스테이블 디퓨전 모델은, 순수한 노이즈 이미지에서 모양을 인식하는 방법을 학습하고, 모양이 입력 텍스트의 단어와 일치하는 경우 점차 이러한 모양에 초점을 맞추는 잠재 확산(latent diffusion) 처리를 수행할 수 있으 며, 이를 위해 언어 모델을 사용한 잠재 공간상에 텍스트가 매핑될 수 있다. 그리고, 스테이블 디퓨전 모델은, 상기 재 공간에서 일련의 노이즈 추가 및 노이즈 제거 작업을 수행하며, 마지막으로 노이즈가 제거된 출력이 픽 셀 공간으로 디코딩되도록 처리할 수 있다. 또한, 이러한 스테이블 디퓨전 알고리즘을 통해, 학습 모델 기반 이미지 변형부는, 입력 이미지가 변형 이 미지로 전이되도록 하는 전이(Transfer) 학습을 미리 수행할 수 있다. 따라서, 본 발명의 실시 예에 따르면, 학습 모델 기반 이미지 변형부는, 촬영 정보 수집부에서 수집 된 촬영 정보와, 버추얼 휴먼 생성을 위해 미리 설정된 프롬프트에 기초하여, 입력 이미지상에 사전 설정된 버 추얼 휴먼의 캐릭터, 동작, 표정 등이 전이된 변형 이미지를 생성할 수 있다. 그리고, 3차원 모델 구성부는, 상기 변형 이미지에 대응하는 깊이 추정을 수행하여, 변형 깊이 정보를 획 득하며, 상기 변형 이미지와 상기 변형 깊이 정보를 이용한 3차원 모델을 구성한다. 이에 대하여 도 4를 참조하여 보다 구체적으로 설명하도록 한다. 도 4는 본 발명의 실시 예에 따른 3차원 모델 구성부를 보다 구체적으로 도시한 블록도로서, 도 4를 참조 하면, 3차원 모델 구성부는 깊이 추정부, 3차원 이미지 변환부 및 모델 데이터 구성부 를 포함한다. 먼저, 깊이 추정부는, 변형 이미지에 대응하는 변형 깊이 정보를 추정한다. 여기서, 깊이 추정부는, 깊이 정보와 단안(monocular) 이미지가 사전 학습된 깊이 추정 학습 모델을 이용 하여, 상기 변형 이미지를 단안 이미지로 입력받아 이미지 내 상대적 깊이를 역추정함에 따라, 상기 변형 깊이정보를 추정할 수 있다. 이러한 깊이 추정부의 추정 방식은 예를 들어, 알려진 MiDaS 기술을 이용한 depth2image 변환 방식으로 구현될 수 있다. 이러한 깊이 추정 학습 방식은, 변형 이미지로 구성된 버추얼 휴먼의 이미지 내 상대적 깊이 정보를 추정할 수 있게 한다. 그리고, 3차원 이미지 변환부는, 추정된 깊이 정보와 변형 이미지를 이용하여 버추얼 휴먼의 3차원 이미 지 변환 처리를 수행한다. 여기서, 3차원 이미지 변환 처리는 상기 촬영 정보의 영상 프레임에 대응하여, 상기 버추얼 휴먼 생성용 변형 이미지 및 변형 깊이 정보를 이용한 영상 프레임 이미지 시퀀스를 생성하는 처리를 포 함할 수 있다. 이를 위해, 3차원 이미지 변환부는, 상기 촬영 정보의 입력 이미지와 상기 변형 이미지의 버추얼 휴먼 영 역을 합성할 수 있으며, 합성된 영역에 대응하는 변형 깊이 정보를 삽입함에 따라, 3차원 모델 생성이나 그래픽 인터페이스 제공을 용이하게 할 수 있다. 이에 따라, 모델 데이터 구성부는, 버추얼 휴먼 콘텐츠 제공을 위한 그래픽 모델 데이터를 구성한다. 그 래픽 모델 데이터 구성을 위해, 모델 데이터 구성부는 변환된 3차원 이미지를 이용한 버추얼 휴먼의 그래 픽 모델 객체 데이터를 생성할 수 있다. 한편, 다시 도 3을 참조하면, 버추얼 휴먼 생성부는, 구성된 3차원 모델을 이용하여, 상기 촬영 정보에 대 응하는 버추얼 휴먼 모델을 생성한다. 이에 따라, 콘텐츠 제공부에서는 상기 생성된 버추얼 휴먼 모델을 이용한 버추얼 휴먼 콘텐츠를 가공하여, 하나 이상의 사용자 디바이스 또는 하나 이상의 서버(120, 130, 140)로 제공할 수 있다. 도 5 및 도 6은 본 발명의 실시 예에 따라 생성되는 버추얼 휴먼을 예시하기 위한 도면들이다. 먼저 도 5를 참조하면, 상기 촬영 정보는 사용자 디바이스의 전면 카메라로부터 촬영된 이미지 정보를 포 함할 수 있으며, 이러한 촬영 정보의 수집에 따라 버추얼 휴먼 서비스 처리부는, 촬영 정보로부터 추출된 입력 이미지의 버추얼 휴먼 변형을 수행하여 변형 이미지를 획득하고, 변환 이미지의 변형 깊이 정보와, 상기 변형 이미지를 이용하여 상기 입력 이미지에 수정 반영함에 따라, 버추얼 휴먼 모델을 이용한 버추얼 휴먼 콘텐 츠를 생성할 수 있다. 한편, 도 6을 참조하면, 본 발명의 실시 예에 따른 촬영 정보는 사용자가 직접 셀프 촬영한 경우가 존재하는 바, 버추얼 휴먼에는 한쪽 손만이 나타날 수 있다. 그러나, 필요에 따라서는 좌우측 손이 모두 나타나는 것이 자연스러울 수 있는 바, 본 발명의 실시 예에 따른 버추얼 휴먼 서비스 처리부의 상기 사전 학습된 이미지 변형 학습 모델은, 상기 촬영 정보에 사용자의 손 이미지가 일측만 포함된 경우, 상기 버추얼 휴먼 생성용 변형 이미지 및 변형 깊이 정보는, 상기 손 이미지에 대응하는 가상의 타측 손 이미지가 더 포함되도록 학습 구성될 수 있다. 즉, 버추얼 휴먼 콘텐츠를 제작하고자 하는 사용자가 통상 한 손으로 사용자 디바이스를 잡고, 그 전면 카 메라를 이용해서 얼굴을 촬영하는 경우, 사용자의 한 손이 사용자 디바이스 파지로 인해서 다른 동작을 할 수 없는 문제가 있는데, 본 발명은 사용자 디바이스를 들고있는 사용자의 손에 대응되는 버추얼 휴먼의 손 동작을 자연스럽게 발생시킬 수 있게 되는 것이다. 보다 구체적으로, 이러한 동작 구현을 자연스럽게 처리하기 위해, 학습 모델 기반 이미지 변형부에 입력되 는 프롬프트는, 사용자 디바이스의 마이크를 통해서 입력되는 대화내용 및 버츄얼 휴먼이 위치한 가상공간 의 특징 정보에 따라 조정될 수 있다. 이에 따라, 사용자 디바이스를 잡고 있지 않은 손의 동작 또한 변형 이미지에 등장할 수 있으며, 이를 통해 버츄얼 휴먼의 양손 동작을 자연스럽게 구현할 수 있게 된다. 예컨대, 밥을 먹는 상황의 경우, 학습 모델 기반 이미지 변형부에는 이에 적합한 프롬프트가 입력될 수 있 으며, 이에 따라 버추얼 휴먼 이미지에는 실제 사람의 일측 손에 따른 손 이미지 뿐만 아니라, 다른 한 손 이미 지도 식사하는 자세에 맞게 적절히 표현될 수 있다. 또한, 길을 걸어가는 상황의 경우에도, 학습 모델 기반 이미지 변형부에는 이에 적합한 프롬프트가 입력될 수 있으며, 이에 따라 버추얼 휴먼 이미지에는 실제 사람의 일측 손에 따른 손 이미지 뿐만 아니라, 다른 한 손이미지도 보행하는 동작에 맞게 적절히 표현될 수 있다. 도 7은 본 발명의 실시 예에 따른 컴퓨팅 장치의 동작을 설명하기 위한 흐름도이다. 도 7을 참조하면, 먼저 서비스 처리부는 실제 사람을 촬영하여 획득되는 촬영 정보를 수집한다(S101). 그리고, 서비스 처리부는, 상기 촬영 정보로부터 입력 이미지를 획득한다(S103). 이후, 서비스 처리부는, 상기 입력 이미지를, 버추얼 휴먼 생성을 위해 딥러닝 기반으로 사전 학습된 이미 지 변형 학습 모델에 입력하여, 버추얼 휴먼 생성용 변형 이미지를 획득한다(S105). 그리고, 서비스 처리부는, 상기 변형 이미지에 대응하는 깊이 추정을 수행하여, 변형 깊이 정보를 획득한 다(S107). 이후, 서비스 처리부는, 상기 변형 이미지와 상기 변형 깊이 정보를 이용한 3차원 모델을 구성한다(S109). 그리고, 서비스 처리부는, 상기 구성된 3차원 모델을 이용하여, 상기 촬영 정보에 대응하는 버추얼 휴먼 모델을 생성한다(S111). 도 8은 본 발명의 실시 예에 따른 3차원 모델 생성 프로세스를 보다 구체적으로 설명한 흐름도이다. 도 8을 참조하면, 본 발명의 실시 예에 따른 3차원 모델 구성부는, 변형 이미지를 단안 이미지로 입력받아 이미지 내 상대적 깊이 정보 역추정을 수행한다(S201). 그리고, 3차원 모델 구성부는, 상기 역추정된 깊이 정보를 이용한 3차원 이미지 변환을 수행한다(S203). 전술한 바와 같이, 본 발명의 실시 예에 따른 3차원 모델 구성부는, 촬영 영상의 각 프레임 이미지에서, 단안 이미지로부터 깊이 값을 추정하는 알고리즘 수행에 따라, 이미지 내 상대적 깊이 정보 역추정을 수행할 수 있으며, 이는 3차원 모델 변형에 이용됨에 따라, 버추얼 휴먼의 자연스럽고 입체적인 동작 구현과 3차원 그래픽 객체 생성에 이용할 수 있는 것이다. 이상에서 설명한 실시예들은 적어도 부분적으로 컴퓨터 프로그램으로 구현되고 컴퓨터로 읽을 수 있는 기록매체 에 기록될 수 있다. 실시예들을 구현하기 위한 프로그램이 기록되고 컴퓨터가 읽을 수 있는 기록매체는 컴퓨터 에 의하여 읽혀질 수 있는 데이터가 저장되는 모든 종류의 기록장치를 포함한다. 컴퓨터가 읽을 수 있는 기록매 체의 예로는 ROM, RAM, CD-ROM, 자기 테이프, 광 데이터 저장장치 등이 있다. 또한 컴퓨터가 읽을 수 있는 기록 매체는 네트워크로 연결된 컴퓨터 시스템에 분산되어, 분산 방식으로 컴퓨터가 읽을 수 있는 코드가 저장되고 실행될 수도 있다. 또한, 본 실시예를 구현하기 위한 기능적인 프로그램, 코드 및 코드 세그먼트(segment)들은 본 실시예가 속하는 기술 분야의 통상의 기술자에 의해 용이하게 이해될 수 있을 것이다. 이상에서 살펴본 본 명세서는 도면에 도시된 실시예들을 참고로 하여 설명하였으나 이는 예시적인 것에 불과하 며 당해 분야에서 통상의 지식을 가진 자라면 이로부터 다양한 변형 및 실시예의 변형이 가능하다는 점을 이해 할 것이다. 그러나, 이와 같은 변형은 본 명세서의 기술적 보호범위 내에 있다고 보아야 한다. 따라서, 본 명세 서의 진정한 기술적 보호범위는 첨부된 청구범위의 기술적 사상에 의해서 다른 구현들, 다른 실시예들 및 특허 청구범위와 균등한 것들도 포함하도록 정해져야 할 것이다.도면 도면1 도면2 도면3 도면4 도면5 도면6 도면7 도면8"}
{"patent_id": "10-2023-0116409", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 명세서의 일 실시 예에 따른 시스템의 동작 환경의 예를 도시한 도면이다. 도 2는 본 명세서의 일 실시 예에 있어서 컴퓨팅 장치의 내부 구성을 설명하기 위한 블록도이다. 도 3은 본 발명의 실시 예에 따른 버추얼 휴먼 서비스 처리부 및 그 구성을 설명하기 위한 블록도이다. 도 4는 본 발명의 실시 예에 따른 3차원 모델 구성부를 보다 구체적으로 도시한 블록도이다. 도 5 및 도 6은 본 발명의 실시 예에 따라 생성되는 버추얼 휴먼을 예시하기 위한 도면들이다. 도 7은 본 발명의 실시 예에 따른 컴퓨팅 장치의 동작을 설명하기 위한 흐름도이다. 도 8은 본 발명의 실시 예에 따른 3차원 모델 생성 프로세스를 보다 구체적으로 설명한 흐름도이다."}
