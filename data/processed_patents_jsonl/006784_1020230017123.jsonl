{"patent_id": "10-2023-0017123", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0124521", "출원번호": "10-2023-0017123", "발명의 명칭": "연합 학습을 기반으로 한 의료 영상 학습 시스템 및 그 방법", "출원인": "프로메디우스 주식회사", "발명자": "김민준"}}
{"patent_id": "10-2023-0017123", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "서버 및 복수의 단말기를 포함하는 의료 영상 학습 시스템에 있어서,상기 서버는,상기 복수의 단말기와 데이터를 송수신하도록 이루어지는 통신부;인공지능 모델 관련 정보를 저장하는 저장부; 및상기 통신부 및 상기 저장부를 제어하도록 이루어지는 프로세서를 포함하고, 상기 프로세서는,상기 복수의 단말기가 인공지능 모델을 학습하도록, 인공지능 모델 관련 정보를 상기 복수의 단말기 각각으로전송하고, 상기 복수의 단말기 중 어느 하나로부터 상기 인공지능 모델에 대한 학습 결과를 수신하도록 이루어지는 클라이언트 관리 모듈;상기 학습 결과에 기반하여 상기 인공지능 모델의 가중치 정보를 업데이트 하도록 이루어지는 인공지능 모듈;및상기 업데이트된 가중치 정보에 포함된 서로 다른 종류의 신경망 각각에 대한 가중치 정보를 병합하도록 이루어지는 가중치 관리 모듈을 포함하고,상기 클라이언트 관리 모듈은,상기 가중치 정보가 업데이트될 때마다 서로 다른 종류의 신경망 각각에 대한 가중치 정보가 병합된 데이터를상기 복수의 단말기 각각으로 전송하는 것을 특징으로 하는 의료 영상 학습 시스템."}
{"patent_id": "10-2023-0017123", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 인공지능 모델은 적대적 생성 신경망 인공지능 모델이고,상기 적대적 생성 신경망 인공지능 모델은 생성자 신경망 및 판별자 신경망을 포함하고,상기 서로 다른 종류의 신경망 각각에 대한 가중치 정보가 병합된 데이터는,상기 생성자 신경망 및 상기 판별자 신경망 각각과 관련된 가중치 데이터를 포함하는 것을 특징으로 하는 의료영상 학습 시스템."}
{"patent_id": "10-2023-0017123", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,상기 가중치 관리 모듈은,상기 학습 결과를 상기 생성자 신경망 및 상기 판별자 신경망 각각과 관련된 가중치 데이터로 분할하고,상기 인공지능 모듈은,상기 분할된 데이터를 기반으로 상기 생성자 신경망 및 상기 판별자 신경망 각각을 업데이트하는 것을 특징으로하는 의료 영상 학습 시스템."}
{"patent_id": "10-2023-0017123", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서,공개특허 10-2024-0124521-3-상기 학습 결과는,상기 어느 하나의 단말기가 기저장된 학습데이터를 기반으로 상기 생성자 신경망 및 상기 판별자 신경망 중 적어도 하나의 가중치를 수정하고, 수정된 생성자 신경망 관련 가중치 및 판별자 신경망 관련 가중치를 병합하여생성하는 것을 특징으로 하는 의료 영상 학습 시스템."}
{"patent_id": "10-2023-0017123", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서,상기 서버와 상기 복수의 단말기간 또는 상기 복수의 단말기간에는 상기 학습데이터가 송수신되지 않는 것을 특징으로 하는 의료 영상 학습 시스템."}
{"patent_id": "10-2023-0017123", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "복수의 단말기와 클라이언트 관리모듈, 인공지능 모듈 및 가중치 관리 모듈을 포함하는 서버를 포함하는 의료영상 학습 방법에 있어서,상기 클라이언트 관리모듈이 상기 복수의 단말기가 인공지능 모델을 학습하도록, 인공지능 모델 관련 정보를 상기 복수의 단말기 각각으로 전송하는 단계;상기 클라이언트 관리 모듈이 상기 복수의 단말기 중 어느 하나로부터 상기 인공지능 모델에 대한 학습 결과를수신하는 단계;상기 인공지능 모듈이 상기 학습 결과에 기반하여 상기 인공지능 모델의 가중치 정보를 업데이트 하는 단계;상기 가중치 관리모듈이 상기 업데이트된 가중치 정보에 포함된 서로 다른 종류의 신경망 각각에 대한 가중치정보를 병합하는 단계; 및상기 클라이언트 관리모듈이 서로 다른 종류의 신경망 각각에 대한 가중치 정보가 병합된 데이터를 상기 복수의단말기 각각으로 전송하는 것을 특징으로 하는 의료 영상 학습 방법."}
{"patent_id": "10-2023-0017123", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6항에 있어서,상기 인공지능 모델은 적대적 생성 신경망 인공지능 모델이고,상기 적대적 생성 신경망 인공지능 모델은 생성자 신경망 및 판별자 신경망을 포함하고,서로 다른 종류의 신경망 각각에 대한 가중치 정보가 병합된 데이터는,상기 생성자 신경망 및 상기 판별자 신경망 각각과 관련된 가중치 데이터를 포함하는 것을 특징으로 하는 의료영상 학습 방법."}
{"patent_id": "10-2023-0017123", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서,상기 가중치 관리 모듈이 상기 학습 결과를 상기 생성자 신경망 및 상기 판별자 신경망 각각과 관련된 가중치데이터로 분할하는 단계를 더 포함하고,상기 인공지능 모듈이 상기 학습 결과에 기반하여 상기 인공지능 모델의 가중치 정보를 업데이트 하는 단계는,상기 인공지능 모듈이 상기 분할된 데이터를 기반으로 상기 생성자 신경망 및 상기 판별자 신경망 각각을 업데이트하는 것임을 특징으로 하는 의료 영상 학습 방법."}
{"patent_id": "10-2023-0017123", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서,상기 학습 결과는,상기 어느 하나의 단말기가 기저장된 학습데이터를 기반으로 상기 생성자 신경망 및 상기 판별자 신경망 중 적공개특허 10-2024-0124521-4-어도 하나의 가중치를 수정하는 단계; 및상기 어느 하나의 단말기가 상기 수정된 생성자 신경망 관련 가중치 및 판별자 신경망 관련 가중치를 병합하여생성하는 단계를 통해 생성되는 것을 특징으로 하는 의료 영상 학습 방법."}
{"patent_id": "10-2023-0017123", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "컴퓨터와 결합되어, 제6항 내지 제9항 중 어느 한 항의 질병 예측 방법을 실행시키기 위하여 컴퓨터 판독 가능한 기록매체에 저장된 프로그램."}
{"patent_id": "10-2023-0017123", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 개시는 의료 영상 학습 시스템 및 그 방법에 관한 것이다. 본 개시에 일 측면에 따른 장치는, 서버 및 복수의 단말기를 포함하고, 상기 서버는 상기 복수의 단말기와 데이터를 송수신하도록 이루어지는 통신부, 인공지능 모 델 관련 정보를 저장하는 저장부, 상기 통신부 및 상기 저장부를 제어하도록 이루어지는 프로세서를 포함하고, (뒷면에 계속)"}
{"patent_id": "10-2023-0017123", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 의료 영상 학습 시스템 및 그 방법에 관한 것이다. 보다 상세하게는, 본 개시는 연합 학습을 통해 의 료영상 생성을 목표로하는 인공지능 모델의 영상 학습 시스템 및 그 방법에 관한 것이다."}
{"patent_id": "10-2023-0017123", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "최신 의료 인공지능 기술에서 대두되고 있는 연합학습은, 환자 개인의 프라이버시를 보장하면서 실질적 데이터 의 양을 증강시킬 수 있는 기술로 설명되고 있다. 구체적으로, 단일 병원에서 생성되는 데이터의 양 및 다양성 이 한정되어 있기 때문에, 영상 생성을 위한 인공지능 모델을 학습하는데 필요한 데이터를 충분히 확보하기 어 려운 실정이다. 연합학습 방법을 활용하면 병원 외부로 환자의 의료 데이터가 반출되지 않기 때문에, 다른 기관 환자 데이터를 활용할 수 있다. 한편, StyleGAN2-ADA, StyleGAN3은 성능 면에서 최상위권에 존재하는 적대적 생성 신경망이다. 이미지의 품질이 중요한 의료 데이터를 생성하는데 적합한 기술이므로, 원천 데이터의 양만 충분하다면 좋은 품질의 의료 데이터 를 생성할 수 있다. 인공지능 모델의 학습을 위한 데이터 확보를 위해, 비특허문헌 0001은 연합학습을 위한 오픈소스 프레임워크인 Flower와 StyleGAN2-ADA을 결합한 방식을 개시하고 있다. 하지만, 선행문헌은 연합 학습에 필수 구성요소인 서 버-클라이언트간 데이터 통신에 관한 내용이 개시되어 있지 않다. 선행기술문헌 특허문헌 (특허문헌 0001) (비특허문헌 0001) Sandra Carrasco Limeros, Sylwia Majchrowska, Mohamad Khir Zoubi, Anna Rosen, Juulia Suvilehto, Lisa Sjoblom, Magnus Kjellberg, \"GAN-based generative modelling for dermatological applications\", 24 Aug 2022"}
{"patent_id": "10-2023-0017123", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 개시에 개시된 실시예는 여러 기관의 데이터를 한 곳에 모으지 않고도 인공지능 모델 학습이 가능한 시스템 및 방법을 제공하는데 그 목적이 있다. 나아가, 본 개시에 개시된 실시예는 연합 학습 시스템 및 방법을 적대적 생성 신경망 모델에 적용할 수 있는 시 스템 및 방법을 제공하는데 그 목적이 있다. 본 개시가 해결하고자 하는 과제들은 이상에서 언급된 과제로 제한되지 않으며, 언급되지 않은 또 다른 과제들 은 아래의 기재로부터 통상의 기술자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2023-0017123", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상술한 기술적 과제를 달성하기 위한 본 개시에 일 측면에 따른 장치는, 서버 및 복수의 단말기를 포함하고, 상 기 서버는 상기 복수의 단말기와 데이터를 송수신하도록 이루어지는 통신부, 인공지능 모델 관련 정보를 저장하는 저장부, 상기 통신부 및 상기 저장부를 제어하도록 이루어지는 프로세서를 포함하고, 상기 프로세서는, 상기 복수의 단말기가 인공지능 모델을 학습하도록, 인공지능 모델 관련 정보를 상기 복수의 단말기 각각으로 전송하 고, 상기 복수의 단말기 중 어느 하나로부터 상기 인공지능 모델에 대한 학습 결과를 수신하도록 이루어지는 클 라이언트 관리 모듈, 상기 학습 결과에 기반하여 상기 인공지능 모델의 가중치 정보를 업데이트 하도록 이루어 지는 인공지능 모듈 및 상기 업데이트된 가중치 정보에 포함된 서로 다른 종류의 신경망 각각에 대한 가중치 정 보를 병합하도록 이루어지는 가중치 관리 모듈을 포함하고, 상기 클라이언트 관리 모듈은, 상기 가중치 정보가 업데이트될 때마다 서로 다른 종류의 신경망 각각에 대한 가중치 정보가 병합된 데이터를 상기 복수의 단말기 각각으로 전송하는 것을 특징으로 하는 의료 영상 학습 시스템을 제공할 수 있다. 또한, 본 개시에 다른 측면에 따른 방법은 복수의 단말기와 클라이언트 관리모듈, 인공지능 모듈 및 가중치 관 리 모듈을 포함하는 서버를 포함하는 의료 영상 학습 방법을 제공할 수 있다. 본 개시에 따른 방법은 상기 클라 이언트 관리모듈이 상기 복수의 단말기가 인공지능 모델을 학습하도록, 인공지능 모델 관련 정보를 상기 복수의 단말기 각각으로 전송하는 단계, 상기 클라이언트 관리 모듈이 상기 복수의 단말기 중 어느 하나로부터 상기 인 공지능 모델에 대한 학습 결과를 수신하는 단계, 상기 인공지능 모듈이 상기 학습 결과에 기반하여 상기 인공지 능 모델의 가중치 정보를 업데이트 하는 단계, 상기 가중치 관리모듈이 상기 업데이트된 가중치 정보에 포함된 서로 다른 종류의 신경망 각각에 대한 가중치 정보를 병합하는 단계 및 상기 클라이언트 관리모듈이 서로 다른 종류의 신경망 각각에 대한 가중치 정보가 병합된 데이터를 상기 복수의 단말기 각각으로 전송하는 것을 특징으 로 하는 의료 영상 학습 방법을 제공할 수 있다. 이 외에도, 본 개시를 구현하기 위한 실행하기 위한 컴퓨터 판독 가능한 기록 매체에 저장된 컴퓨터 프로그램이 더 제공될 수 있다. 이 외에도, 본 개시를 구현하기 위한 방법을 실행하기 위한 컴퓨터 프로그램을 기록하는 컴퓨터 판독 가능한 기 록 매체가 더 제공될 수 있다."}
{"patent_id": "10-2023-0017123", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 개시의 전술한 과제 해결 수단에 의하면, 연합학습을 위한 서버 및 단말기간 데이터 송수신 시, 서로 다른 신경망에 적용되는 가중치가 통합된 형태로 데이터를 송수신 함으로써, 연합학습을 적대적 생성 신경망에도 적 용할 수 있도록 한다. 이를 통해, 본 개시는 여러 기관의 데이터를 한 곳에 모으지 않고도, 적대적 생성 신경망 을 좋은 품질로 학습할 수 있게 한다. 본 개시의 효과들은 이상에서 언급된 효과로 제한되지 않으며, 언급되지 않은 또 다른 효과들은 아래의 기재로 부터 통상의 기술자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2023-0017123", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 개시 전체에 걸쳐 동일 참조 부호는 동일 구성요소를 지칭한다. 본 개시가 실시예들의 모든 요소들을 설명 하는 것은 아니며, 본 개시가 속하는 기술분야에서 일반적인 내용 또는 실시예들 간에 중복되는 내용은 생략한 다. 명세서에서 사용되는 '부, 모듈, 부재, 블록'이라는 용어는 소프트웨어 또는 하드웨어로 구현될 수 있으며, 실시예들에 따라 복수의 '부, 모듈, 부재, 블록'이 하나의 구성요소로 구현되거나, 하나의 '부, 모듈, 부재, 블 록'이 복수의 구성요소들을 포함하는 것도 가능하다. 명세서 전체에서, 어떤 부분이 다른 부분과 \"연결\"되어 있다고 할 때, 이는 직접적으로 연결되어 있는 경우뿐 아니라, 간접적으로 연결되어 있는 경우를 포함하고, 간접적인 연결은 무선 통신망을 통해 연결되는 것을 포함 한다. 또한 어떤 부분이 어떤 구성요소를 \"포함\"한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다른 구성요소를 제외하는 것이 아니라 다른 구성요소를 더 포함할 수 있는 것을 의미한다. 명세서 전체에서, 어떤 부재가 다른 부재 \"상에\" 위치하고 있다고 할 때, 이는 어떤 부재가 다른 부재에 접해 있는 경우뿐 아니라 두 부재 사이에 또 다른 부재가 존재하는 경우도 포함한다. 제 1, 제 2 등의 용어는 하나의 구성요소를 다른 구성요소로부터 구별하기 위해 사용되는 것으로, 구성요소가 전술된 용어들에 의해 제한되는 것은 아니다. 단수의 표현은 문맥상 명백하게 예외가 있지 않는 한, 복수의 표현을 포함한다. 각 단계들에 있어 식별부호는 설명의 편의를 위하여 사용되는 것으로 식별부호는 각 단계들의 순서를 설명하는 것이 아니며, 각 단계들은 문맥상 명백하게 특정 순서를 기재하지 않는 이상 명기된 순서와 다르게 실시될 수 있다. 이하 첨부된 도면들을 참고하여 본 개시의 작용 원리 및 실시예들에 대해 설명한다. 본 명세서에서 '본 개시에 따른 시스템'은 연산처리를 수행하여 사용자에게 결과를 제공할 수 있는 다양한 장치 들이 모두 포함된다. 예를 들어, 본 개시에 따른 장치는, 컴퓨터, 서버 장치 및 휴대용 단말기를 모두 포함하거 나, 또는 어느 하나의 형태가 될 수 있다. 여기에서, 상기 컴퓨터는 예를 들어, 웹 브라우저(WEB Browser)가 탑재된 노트북, 데스크톱(desktop), 랩톱 (laptop), 태블릿 PC, 슬레이트 PC 등을 포함할 수 있다. 상기 서버 장치는 외부 장치와 통신을 수행하여 정보를 처리하는 서버로써, 애플리케이션 서버, 컴퓨팅 서버, 데이터베이스 서버, 파일 서버, 게임 서버, 메일 서버, 프록시 서버 및 웹 서버 등을 포함할 수 있다. 상기 휴대용 단말기는 예를 들어, 휴대성과 이동성이 보장되는 무선 통신 장치로서, PCS(Personal Communication System), GSM(Global System for Mobile communications), PDC(Personal Digital Cellular), PHS(Personal Handyphone System), PDA(Personal Digital Assistant), IMT(International Mobile Telecommunication)-2000, CDMA(Code Division Multiple Access)-2000, W-CDMA(W-Code Division Multiple Access), WiBro(Wireless Broadband Internet) 단말, 스마트 폰(Smart Phone) 등과 같은 모든 종류의 핸드헬드 (Handheld) 기반의 무선 통신 장치와 시계, 반지, 팔찌, 발찌, 목걸이, 안경, 콘택트 렌즈, 또는 머리 착용형 장치(head-mounted-device(HMD) 등과 같은 웨어러블 장치를 포함할 수 있다. 이하에서는, 본 개시에 따른 의료 영상 학습 시스템에 대하여 설명한다. 도 1을 참고하면, 본 개시에 따른 의료 영상 학습 시스템은 서버 및 단말기를 포함할 수 있다. 서버는 단말기와 네트워크로 연결되며, 복수의 단말기 각각에 정보를 전송하고, 단말기 각각으로부 터 수신된 정보에 기반하여 의료 영상 학습에 필요한 데이터를 생성한다. 한편, 상기 단말기는 상술한 휴대용 단말기에 한정되지 않고, 프로세서가 탑재된 노트북, 데스크톱 (desktop), 랩톱(laptop), 태블릿 PC, 슬레이트 PC 등을 포함할 수 있는 것은 통상의 기술자에게 자명하다. 상술한 바와 같이, 본 개시에 따른 의료 영상 학습 시스템은 서버 및 단말기 간 데이터 송수신을 통해 구현될 수 있다. 이하에서는, 본 개시에 따른 의료 영상 학습 시스템을 구현하기 위한 서버 및 단말기 각각에 대하여 설 명한다. 도 2는 본 개시의 의료 영상 학습 시스템에 포함된 서버의 블록도이다. 본 개시에 따른 서버는 통신부, 저장부 및 프로세서 중 적어도 하나를 포함할 수 있다. 통신부는 단말기, 외부 저장소(예를 들어, 데이터베이스(database, 140)), 외부 서버 및 클라우드 서버 중 적어도 하나와 통신을 수행할 수 있다. 한편, 외부 서버 또는 클라우드 서버에서는, 프로세서의 적어도 일부의 역할을 수행하도록 구성될 수 있다. 즉, 데이터 처리 또는 데이터 연산 등의 수행은 외부 서버 또는 클라우드 서버에서 이루어지는 것이 가능 하며, 본 발명에서는 이러한 방식에 대한 특별한 제한을 두지 않는다. 한편, 통신부는 통신하는 대상(예를 들어, 전자기기, 외부 서버, 디바이스 등)의 통신 규격에 따라 다양한 통신 방식을 지원할 수 있다. 예를 들어, 통신부는, WLAN(Wireless LAN), Wi-Fi(Wireless-Fidelity), Wi-Fi(Wireless Fidelity) Direct, DLNA(Digital Living Network Alliance), WiBro(Wireless Broadband), WiMAX(World Interoperability for Microwave Access), HSDPA(High Speed Downlink Packet Access), HSUPA(High Speed Uplink Packet Access), LTE(Long Term Evolution), LTE-A(Long Term Evolution-Advanced), 5G(5th Generation Mobile Telecommunication ), 블루투스(Bluetooth™), RFID(Radio Frequency Identification), 적외선 통신(Infrared Data Association; IrDA), UWB(Ultra-Wideband), ZigBee, NFC(Near Field Communication), Wi-Fi Direct, Wireless USB(Wireless Universal Serial Bus) 기술 중 적어도 하나를 이용하여, 통신 대상과 통신하도록 이루 어질 수 있다. 다음으로 저장부는, 본 발명과 관련된 다양한 정보를 저장하도록 이루어질 수 있다. 본 발명에서 저장부 는 본 발명에 따른 장치 자체에 구비될 수 있다. 이와 다르게, 저장부의 적어도 일부는, 데이터베이 스(database: DB, 140) 클라우드 저장소(또는 클라우드 서버) 중 적어도 하나를 의미할 수 있다. 즉, 저장부 는 본 발명에 따른 장치 및 방법을 위하여 필요한 정보가 저장되는 공간이면 충분하며, 물리적인 공간에 대한 제약은 없는 것으로 이해될 수 있다. 이에, 이하에서는, 저장부, 데이터베이스, 외부 저장소, 클라우드 저장소(또는 클라우드 서버)를 별도로 구분하지 않고, 모두 저장부라고 표현하도록 한다. 다음으로, 프로세서는 본 발명과 관련된 장치의 전반적인 동작을 제어하도록 이루어질 수 있다. 프로세서 는 위에서 살펴본 구성요소들을 통해 입력 또는 출력되는 신호, 데이터, 정보 등을 처리하거나 사용자에게 적절한 정보 또는 기능을 제공 또는 처리할 수 있다. 프로세서는 적어도 하나의 CPU(Central Processing Unit, 중앙처리장치)를 포함하여, 본 발명에 따른 기능 을 수행할 수 있다. 한편, 프로세서는 본 개시에 따른 의료 영상 학습 시스템을 구현하기 위한 복수의 모듈을 포함할 수 있다. 구체적으로, 프로세서는 클라이언트 관리 모듈, 인공지능 모듈, 가중치 관리 모듈을 포함 할 수 있다. 각 모듈에 대하여는 후술한다. 도 2에 도시된 구성 요소들의 성능에 대응하여 적어도 하나의 구성요소가 추가되거나 삭제될 수 있다. 또한, 구 성 요소들의 상호 위치는 장치의 성능 또는 구조에 대응하여 변경될 수 있다는 것은 당해 기술 분야에서 통상의 지식을 가진 자에게 용이하게 이해될 것이다. 이하, 본 개시의 의료 영상 학습 시스템에 포함된 단말기에 대하여 구체적으로 설명한다. 도 3은 본 개시의 의료 영상 학습 시스템에 포함된 단말기의 블록도이다. 도 3을 참고하면, 본 개시에 따른 단말기는 통신부, 입력부, 표시부 및 프로세서 등 을 포함할 수 있다. 도 3에 도시된 구성요소들은 본 개시에 따른 의료 영상 학습 시스템을 구현하는데 있어서 필수적인 것은 아니어서, 본 명세서 상에서 설명되는 단말기는 위에서 열거된 구성요소들 보다 많거나, 또는 적 은 구성요소들을 가질 수 있다. 상기 구성요소들 중 통신부는 외부 장치와 통신을 가능하게 하는 하나 이상의 구성 요소를 포함할 수 있으 며, 예를 들어, 방송 수신 모듈, 유선통신 모듈, 무선통신 모듈, 근거리 통신 모듈, 위치정보 모듈 중 적어도 하나를 포함할 수 있다. 유선 통신 모듈은, 지역 통신(Local Area Network; LAN) 모듈, 광역 통신(Wide Area Network; WAN) 모듈 또는 부가가치 통신(Value Added Network; VAN) 모듈 등 다양한 유선 통신 모듈뿐만 아니라, USB(Universal Serial Bus), HDMI(High Definition Multimedia Interface), DVI(Digital Visual Interface), RS-1302(recommendedstandard1302), 전력선 통신, 또는 POTS(plain old telephone service) 등 다양한 케이블 통신 모듈을 포함할 수 있다. 무선 통신 모듈은 와이파이(Wifi) 모듈, 와이브로(Wireless broadband) 모듈 외에도, GSM(global System for Mobile Communication), CDMA(Code Division Multiple Access), WCDMA(Wideband Code Division Multiple Access), UMTS(universal mobile telecommunications system), TDMA(Time Division Multiple Access), LTE(Long Term Evolution), 4G, 5G, 6G 등 다양한 무선 통신 방식을 지원하는 무선 통신 모듈을 포함할 수 있 다. 입력부는 영상 정보(또는 신호), 오디오 정보(또는 신호), 데이터, 또는 사용자로부터 입력되는 정보의 입 력을 위한 것으로서, 적어도 하나의 카메라, 적어도 하나의 마이크로폰 및 사용자 입력부 중 적어도 하나를 포 함할 수 있다. 입력부에서 수집한 음성 데이터나 이미지 데이터는 분석되어 사용자의 제어명령으로 처리될 수 있다. 표시부는 시각, 청각 또는 촉각 등과 관련된 출력을 발생시키기 위한 것으로, 디스플레이부, 음향 출력부, 햅팁 모듈 및 광 출력부 중 적어도 하나를 포함할 수 있다. 디스플레이부는 터치 센서와 상호 레이어 구조를 이 루거나 일체형으로 형성됨으로써, 터치 스크린을 구현할 수 있다. 이러한 터치 스크린은, 본 장치와 사용자 사 이의 입력 인터페이스를 제공하는 사용자 입력부로써 기능함과 동시에, 본 장치와 사용자 간에 출력 인터페이스 를 제공할 수 있다. 디스플레이부는 본 장치에서 처리되는 정보를 표시(출력)한다. 예를 들어, 디스플레이부는 본 장치에서 구동되 는 응용 프로그램(일 예로, 어플리케이션)의 실행화면 정보, 또는 이러한 실행화면 정보에 따른 UI(User Interface), GUI(Graphic User Interface) 정보를 표시할 수 있다. 상술한 구성요소 외에, 상술한 단말기는 인터페이스부 및 메모리를 더 포함할 수 있다. 인터페이스부는 본 장치에 연결되는 다양한 종류의 외부 기기와의 통로 역할을 수행한다. 이러한 인터페이스부 는 유/무선 헤드셋 포트(port), 외부 충전기 포트(port), 유/무선 데이터 포트(port), 메모리 카드(memory card) 포트, 식별 모듈(SIM)이 구비된 장치를 연결하는 포트(port), 오디오 I/O(Input/Output) 포트(port), 비 디오 I/O(Input/Output) 포트(port), 이어폰 포트(port) 중 적어도 하나를 포함할 수 있다. 본 장치에서는, 상 기 인터페이스부에 연결된 외부 기기와 관련된 적절한 제어를 수행할 수 있다. 메모리는 본 장치의 다양한 기능을 지원하는 데이터와, 프로세서의 동작을 위한 프로그램을 저장할 수 있고, 입 /출력되는 데이터들(예를 들어, 음악 파일, 정지영상, 동영상 등)을 저장할 있고, 본 장치에서 구동되는 다수의 응용 프로그램(application program 또는 애플리케이션(application)), 본 장치의 동작을 위한 데이터들, 명령 어들을 저장할 수 있다. 이러한 응용 프로그램 중 적어도 일부는, 무선 통신을 통해 외부 서버로부터 다운로드 될 수 있다. 이러한, 메모리는 플래시 메모리 타입(flash memory type), 하드디스크 타입(hard disk type), SSD 타입(Solid State Disk type), SDD 타입(Silicon Disk Drive type), 멀티미디어 카드 마이크로 타입(multimedia card micro type), 카드 타입의 메모리(예를 들어 SD 또는 XD 메모리 등), 램(random access memory; RAM), SRAM(static random access memory), 롬(read-only memory; ROM), EEPROM(electrically erasable programmable read-only memory), PROM(programmable read-only memory), 자기 메모리, 자기 디스크 및 광디스 크 중 적어도 하나의 타입의 저장매체를 포함할 수 있다. 또한, 메모리는 본 장치와는 분리되어 있으나, 유선 또는 무선으로 연결된 데이터베이스가 될 수도 있다. 한편, 상술한 단말기는 프로세서를 포함한다. 프로세서는 본 장치 내의 구성요소들의 동작을 제어하기 위 한 알고리즘 또는 알고리즘을 재현한 프로그램에 대한 데이터를 저장하는 메모리, 및 메모리에 저장된 데이터를 이용하여 전술한 동작을 수행하는 적어도 하나의 프로세서(미도시)로 구현될 수 있다. 이때, 메모리와 프로세서 는 각각 별개의 칩으로 구현될 수 있다. 또는, 메모리와 프로세서는 단일 칩으로 구현될 수도 있다. 한편, 프로세서는 본 개시에 따른 의료 영상 학습 시스템을 구현하기 위한 복수의 모듈을 포함할 수 있다. 구체적으로, 프로세서는 인공지능 모듈, 가중치 관리 모듈을 포함할 수 있다. 각 모듈에 대하여 는 후술한다. 또한, 프로세서는 이하의 도면에서 설명되는 본 개시에 따른 다양한 실시 예들을 본 장치 상에서 구현하기 위하 여, 위에서 살펴본 구성요소들을 중 어느 하나 또는 복수를 조합하여 제어할 수 있다. 한편, 도 1 내지 3에 도시된 구성 요소들의 성능에 대응하여 적어도 하나의 구성요소가 추가되거나 삭제될 수 있다. 또한, 구성 요소들의 상호 위치는 장치의 성능 또는 구조에 대응하여 변경될 수 있다는 것은 당해 기술 분야에서 통상의 지식을 가진 자에게 용이하게 이해될 것이다. 이하에서는, 본 발명에서 서술되는 인공지능에 대하여 구체적으로 설명한다. 본 개시에 따른 인공지능과 관련된 기능은 상술한 서버 및 단말기에 탑재된 프로세서와 메모리를 통해 동작된다. 프로세서는 하나 또는 복수의 프로세서로 구성될 수 있다. 이때, 하나 또는 복수의 프로세서는 CPU, AP, DSP(Digital Signal Processor) 등과 같은 범용 프로세서, GPU, VPU(Vision Processing Unit)와 같은 그래 픽 전용 프로세서 또는 NPU와 같은 인공지능 전용 프로세서일 수 있다. 하나 또는 복수의 프로세서는, 메모리에 저장된 기 정의된 동작 규칙 또는 인공지능 모델에 따라, 입력 데이터를 처리하도록 제어한다. 또는, 하나 또는 복수의 프로세서가 인공지능 전용 프로세서인 경우, 인공지능 전용 프로세서는, 특정 인공지능 모델의 처리에 특화된 하드웨어 구조로 설계될 수 있다. 기 정의된 동작 규칙 또는 인공지능 모델은 학습을 통해 만들어진 것을 특징으로 한다. 여기서, 학습을 통해 만 들어진다는 것은, 기본 인공지능 모델이 학습 알고리즘에 의하여 다수의 학습 데이터들을 이용하여 학습됨으로 써, 원하는 특성(또는, 목적)을 수행하도록 설정된 기 정의된 동작 규칙 또는 인공지능 모델이 만들어짐을 의미 한다. 이러한 학습은 본 개시에 따른 인공지능이 수행되는 기기 자체에서 이루어질 수도 있고, 별도의 서버 및/ 또는 시스템을 통해 이루어 질 수도 있다. 학습 알고리즘의 예로는, 지도형 학습(supervised learning), 비지도 형 학습(unsupervised learning), 준지도형 학습(semi-supervised learning) 또는 강화 학습(reinforcement learning)이 있으나, 전술한 예에 한정되지 않는다. 인공지능 모델은, 복수의 신경망 레이어들로 구성될 수 있다. 복수의 신경망 레이어들 각각은 복수의 가중치들 (weight values)을 갖고 있으며, 이전(previous) 레이어의 연산 결과와 복수의 가중치들 간의 연산을 통해 신경 망 연산을 수행한다. 복수의 신경망 레이어들이 갖고 있는 복수의 가중치들은 인공지능 모델의 학습 결과에 의 해 최적화될 수 있다. 예를 들어, 학습 과정 동안 인공지능 모델에서 획득한 로스(loss) 값 또는 코스트(cost) 값이 감소 또는 최소화되도록 복수의 가중치들이 갱신될 수 있다. 인공 신경망은 심층 신경망(DNN:Deep Neural Network)를 포함할 수 있으며, 예를 들어, CNN (Convolutional Neural Network), DNN (Deep Neural Network), RNN (Recurrent Neural Network), RBM (Restricted Boltzmann Machine), DBN (Deep Belief Network), BRDNN(Bidirectional Recurrent Deep Neural Network) 또는 심층 Q-네트워크 (Deep Q-Networks) 등이 있으나, 전술한 예에 한정되지 않는다. 본 개시의 예시적인 실시예에 따르면, 프로세서는 인공지능을 구현할 수 있다. 인공지능이란 사람의 신경세포 (biological neuron)를 모사하여 기계가 학습하도록 하는 인공신경망(Artificial Neural Network) 기반의 기계 학습법을 의미한다. 인공지능의 방법론에는 학습 방식에 따라 훈련데이터로서 입력데이터와 출력데이터가 같이 제공됨으로써 문제(입력데이터)의 해답(출력데이터)이 정해져 있는 지도학습(supervised learning), 및 출력데 이터 없이 입력데이터만 제공되어 문제(입력데이터)의 해답(출력데이터)이 정해지지 않는 비지도학습 (unsupervised learning), 및 현재의 상태(State)에서 어떤 행동(Action)을 취할 때마다 외부 환경에서 보상 (Reward)이 주어지는데, 이러한 보상을 최대화하는 방향으로 학습을 진행하는 강화학습(reinforcement learning)으로 구분될 수 있다. 또한, 인공지능의 방법론은 학습 모델의 구조인 아키텍처에 따라 구분될 수도 있는데, 널리 이용되는 딥러닝 기술의 아키텍처는, 합성곱신경망(CNN; Convolutional Neural Network), 순환신 경망(RNN; Recurrent Neural Network), 트랜스포머(Transformer), 생성적 대립 신경망(GAN; generative adversarial networks) 등으로 구분될 수 있다. 본 장치와 시스템은 인공지능 모델을 포함할 수 있다. 인공지능 모델은 하나의 인공지능 모델일 수 있고, 복수 의 인공지능 모델로 구현될 수도 있다. 인공지능 모델은 뉴럴 네트워크(또는 인공 신경망)로 구성될 수 있으며, 기계학습과 인지과학에서 생물학의 신경을 모방한 통계학적 학습 알고리즘을 포함할 수 있다. 뉴럴 네트워크는 시냅스의 결합으로 네트워크를 형성한 인공 뉴런(노드)이 학습을 통해 시냅스의 결합 세기를 변화시켜, 문제 해 결 능력을 가지는 모델 전반을 의미할 수 있다. 뉴럴 네트워크의 뉴런은 가중치 또는 바이어스의 조합을 포함할 수 있다. 뉴럴 네트워크는 하나 이상의 뉴런 또는 노드로 구성된 하나 이상의 레이어(layer)를 포함할 수 있다. 예시적으로, 장치는 input layer, hidden layer, output layer를 포함할 수 있다. 장치를 구성하는 뉴 럴 네트워크는 뉴런의 가중치를 학습을 통해 변화시킴으로써 임의의 입력(input)으로부터 예측하고자 하는 결과 (output)를 추론할 수 있다. 프로세서는 뉴럴 네트워크를 생성하거나, 뉴럴 네트워크를 훈련(train, 또는 학습(learn)하거나, 수신되는 입력 데이터를 기초로 연산을 수행하고, 수행 결과를 기초로 정보 신호(information signal)를 생성하거나, 뉴럴 네 트워크를 재훈련(retrain)할 수 있다. 뉴럴 네트워크의 모델들은 GoogleNet, AlexNet, VGG Network 등과 같은 CNN(Convolution Neural Network), R-CNN(Region with Convolution Neural Network), RPN(Region Proposal Network), RNN(Recurrent Neural Network), S-DNN(Stacking-based deep Neural Network), S-SDNN(State-Space Dynamic Neural Network), Deconvolution Network, DBN(Deep Belief Network), RBM(Restrcted Boltzman Machine), Fully Convolutional Network, LSTM(Long Short-Term Memory) Network, Classification Network 등 다양한 종류의 모델들을 포함할 수 있으나 이에 제한되지는 않는다. 프로세서는 뉴럴 네트워크의 모델들에 따른 연산을 수행하기 위한 하나 이상의 프로세서를 포함할 수 있다. 예를 들어 뉴럴 네트워크는 심층 뉴럴 네트워크 (Deep Neural Network)를 포함할 수 있다. 뉴럴 네트워크는 CNN(Convolutional Neural Network), RNN(Recurrent Neural Network), 퍼셉트론(perceptron), 다층 퍼셉트론(multilayer perceptron), FF(Feed Forward), RBF(Radial Basis Network), DFF(Deep Feed Forward), LSTM(Long Short Term Memory), GRU(Gated Recurrent Unit), AE(Auto Encoder), VAE(Variational Auto Encoder), DAE(Denoising Auto Encoder), SAE(Sparse Auto Encoder), MC(Markov Chain), HN(Hopfield Network), BM(Boltzmann Machine), RBM(Restricted Boltzmann Machine), DBN(Depp Belief Network), DCN(Deep Convolutional Network), DN(Deconvolutional Network), DCIGN(Deep Convolutional Inverse Graphics Network), GAN(Generative Adversarial Network), LSM(Liquid State Machine), ELM(Extreme Learning Machine), ESN(Echo State Network), DRN(Deep Residual Network), DNC(Differentiable Neural Computer), NTM(Neural Turning Machine), CN(Capsule Network), KN(Kohonen Network) 및 AN(Attention Network)를 포함 할 수 있으나 이에 한정되는 것이 아닌 임의의 뉴럴 네트워크를 포함할 수 있음은 통상의 기술자가 이해할 것이다. 본 개시의 예시적인 실시예에 따르면, 프로세서는 GoogleNet, AlexNet, VGG Network 등과 같은 CNN(Convolution Neural Network), R-CNN(Region with Convolution Neural Network), RPN(Region Proposal Network), RNN(Recurrent Neural Network), S-DNN(Stacking-based deep Neural Network), S-SDNN(State-Space Dynamic Neural Network), Deconvolution Network, DBN(Deep Belief Network), RBM(Restrcted Boltzman Machine), Fully Convolutional Network, LSTM(Long Short-Term Memory) Network, Classification Network, Generative Modeling, eXplainable AI, Continual AI, Representation Learning, AI for Material Design, 자 연어 처리를 위한 BERT, SP-BERT, MRC/QA, Text Analysis, Dialog System, GPT-3, GPT-4, 비전 처리를 위한 Visual Analytics, Visual Understanding, Video Synthesis, ResNet 데이터 지능을 위한 Anomaly Detection, Prediction, Time-Series Forecasting, Optimization, Recommendation, Data Creation 등 다양한 인공지능 구 조 및 알고리즘을 이용할 수 있으며, 이에 제한되지 않는다. 이하, 첨부된 도면을 참조하여 본 개시의 실시예를 상세하게 설명한다. 이하에서는, 상술한 시스템을 활용한 의료 영상 학습 방법에 대해 구체적으로 설명한다. 후술하는 의료 영상 학 습 방법은 상술한 서버 및 단말기 간 데이터 송수신을 통해 구현되며, 상기 방법의 일부 단계는 서버 및 단말기 중 어느 하나에서 수행될 수 있다. 도 4는 본 개시에 따른 의료 영상 학습 방법의 흐름도이다. 도 4를 참조하면, 서버에 포함된 클라이언트 관리모듈이 복수의 단말기로 인공지능 모델 관련 정보를 전송 하는 단계가 진행된다(S110). 인공지능 모델의 연합 학습 방법은 인공지능 모델의 학습을 복수의 단말기에서 수행하는 방식으로, 서버는 복수 의 단말기에서의 학습을 관리하는 역할을 수행할 수 있다. 이를 위해, 클라이언트 관리모듈은 복수의 단말기가 인공지능 모델의 학습을 수행할 수 있도록 인공지능 모델관련 정보를 복수의 단말기 각각으로 전송한다. 학습 초기에 서버는 복수의 단말기로 인공지능 모델 학습을 위한 기본 데이터를 전송할 수 있다. 예를 들어, 서버는 연합 학습을 위해 복수의 단말기로 인공지능 모델의 프레임, 인공지능 모델의 가중치 (Weight) 정보 및 학습 규칙 등을 전송할 수 있다. 이를 위해, 인공지능 모델 관련 정보는 인공지능 모델의 프레임워크, 인공지능 모델 입력 데이터의 종류, 학습 데이터의 라벨링 방식, 인공지능 모델의 출력 데이터의 종류, 인공지능 모델의 가중치 정보 등을 포함할 수 있 다. 다만, 이에 한정되지 않고, 상기 인공지능 모델 관련 정보는 인공지능 모델 학습에 필요한 모든 데이터를포함할 수 있다. 단, 상기 인공지능 모델 관련 정보는 인공지능 모델 학습에 사용되는 학습데이터는 포함하지 않을 수 있다. 즉, 서버와 복수의 단말기간 또는 복수의 단말기간에는 인공지능 모델 학습을 위한 학습데이터가 송수신되지 않 을 수 있다. 다음으로, 복수의 단말기 중 어느 하나의 단말기에 기 저장된 학습데이터를 기반으로 인공지능 모델을 학습하는 단계가 진행된다(S120). 연합 학습에 참여한 복수의 단말기 각각은 서버로부터 인공지능 모델 관련 정보를 수신한 후 인공지능 모델의 학습을 진행할 수 있다. 복수의 단말기 각각의 프로세서는 인공지능 모듈이 구비될 수 있다. 인공지능 모 듈은 서버로부터 수신된 인공지능 모델 관련 정보를 활용하여, 단말기 내에서 인공지능 모델의 학습을 수 행한다. 여기서, 각 단말기에 포함된 인공지능 모듈은 단말기에 저장된 학습데이터를 활용하여 인공지능 모델에 대 한 학습을 수행할 수 있다. 각 단말기는 다른 기관에 속한 단말기 또는 서버로부터 학습데이터를 전송받지 않고, 단말기가 속한 기관 내에 저장된 학습데이터만으로 인공지능 모델에 대한 학습을 수행한다. 즉, 단말기 및 서버간 또는 단말기간에는 학습데이터 송수신은 이루어지지 않는다. 일 실시 예에 있어서, 상기 학습데이터는 의료 영상일 수 있다. 예를 들어, 상기 학습데이터는 CT촬영 영상일 수 있다. 한편, 본 발명은 적대적 생성 신경망 모델에 대한 연합 학습 방법을 제공한다. 이에, 복수의 단말기에서 학습을 진행하는 인공지능 모델의 종류는 적대적 생성 신경망 모델일 수 있다. 본 발명의 이해를 돕기 위해, 적대적 생성 신경망 모델에 대하여 설명한다. 후술하는 적대적 생성 신경망 모델 에 대한 설명은 본 발명의 이해를 돕기 위한 것일 뿐, 본 발명이 후술하는 인공지능 모델에만 적용될 수 있는 것이 아님은 통상의 기술자에게 자명하다. 도 5를 참조하면, 적대적 생성 신경망 모델은 생성자 신경망과 판별자 신경망을 포함할 수 있다. 적 대적 생성 신경망 모델의 학습은 생성자 신경망과 판별자 신경망의 학습 결과를 서로 주고받으면서 각 신경망에 대한 학습을 반복한다. 구체적으로, 판별자 신경망의 학습은 크게 두 가지 과정으로 이루어져 있다. 첫번째로, 진짜 데이터를 입 력해서 네트워크가 해당 데이터를 진짜로 분류하도록 학습시키는 과정이고 두 번째는 첫 번째와 반대로 생성자 신경망에서 생성한 가짜 데이터를 입력해서 해당 데이터를 가짜로 분류하도록 학습하는 과정이다. 이 과정 을 통해 판별자 신경망은 진짜 데이터를 진짜로, 가짜 데이터를 가짜로 분류할 수 있게 된다. 한편, 생성자 신경망은 생성자 신경망에서 생성된 가짜 데이터를 판별자 신경망에 입력하고, 가 짜 데이터를 진짜라고 분류할 만큼 진짜 데이터와 유사한 데이터를 만들어 내도록 학습된다. 상술한 학습과정을 반복하면 생성자 신경망과 판별자 신경망이 서로를 적대적인 경쟁자로 인식하여 모두 발전하게 된다. 결과적으로, 생성자 신경망은 진짜 데이터와 완벽히 유사한 가짜 데이터를 만들 수 있게 되고 이에 따라 분류 모델은 진짜 데이터와 가짜 데이터를 구분할 수 없게 된다. 상술한 바와 같이, 적대적 생성 신경망 모델은 생성자 신경망과 판별자 신경망을 모두 포함하며, 인 공지능 모델 학습시 각 모델에 대한 학습이 이루어져야 한다. 상술한 적대적 생성 신경망 모델의 일 예로, StyleGAN2-ada이 있을 수 있다. StyleGAN2-ada의 프레임은 도 6과 같다. 도 6에서 G는 생성자 신경망을 의미하며, D는 판별자 신경망을 의미한다. 한편, Aug는 증강부를 의미한다. 증강부는 메인 변환 영상에 대한 원본 이미지의 레이블 지도 기반 데이터 랜덤 분할 증강을 통해 무작위적으로 특정 영역이 강조된 도메인 변환 영상을 출력한다. 상기 증강부 는 적대적 생성 신경망 모델 학습에 활용되는 데이터셋의 양이 적을 때, 인공지능 모델의 학습 효율을 높 이기 위해 활용될 수 있다. 다만, 상기 증강부의 역할은 이에 한정되지 않으며, 본 발명에 적용되는 증강 부는 기 공지된 기술을 활용할 수 있다. 일 실시 예로, 복수의 단말기 각각에서 도 6에 도시된 인공지능 모델에 대한 학습이 이루어질 수 있다. 이때, 상기 인공지능 모델 관련 정보는 서로 다른 종류의 신경망 각각에 대한 가중치 정보가 병합된 데이터를 포함할 수 있다. 구체적으로, 상기 인공지능 모델은 적대적 생성 신경망 인공지능 모델이고, 상기 적대적 생성 신경망 인공지능 모델은 생성자 신경망 및 판별자 신경망을 포함하고, 서로 다른 종류의 신경망 각각에 대한 가 중치 정보가 병합된 데이터(이하, 통합 가중치 데이터)는, 상기 생성자 신경망 및 상기 판별자 신경망 각각과 관련된 가중치 데이터를 포함할 수 있다. 복수의 단말기 각각에 포함된 가중치 관리 모듈은 상기 통합 가중치 데이터를 수신하면, 생성자 신경망 과 관련된 가중치값(G)과 판별자 신경망과 관련된 가중치값(D)을 분할하여, 인공지능 모듈로 전 달한다. 이후, 각 단말기의 인공지능 모듈은 전달받은 가중치값(D)을 인공지능 모델에 적용한 후 학습을 진행한다. 다음으로, 상기 어느 하나의 단말기가 학습 결과를 서버로 전송할 수 있다(S130). 연합 학습에 참가한 복수의 단말기 각각은 1회의 학습이 종료될 때마다, 학습 결과를 서버로 전송할 수 있다. 여기서, 1회의 학습의 종료된다함은, 인공지능 모델에 학습데이터를 입력하여, 생성자 신경망 및 판별자 신경망의 출력 결과를 확인한 후, 생성자 신경망 및 판별자 신경망 중 적어도 하나의 가중치를 수정하는 일련의 과정 1회 완료되었음을 의미한다. 즉, 1회 학습이 종료될 때마다, 신경망 및 판별자 신경 망 중 적어도 하나의 가중치가 수정된다. 상기 학습 결과는 수정된 가중치값을 의미할 수 있다. 즉, 복수의 단말기 중 어느 하나에서 1회의 학습이 종료 될 때마다, 수정된 가중치값이 서버로 전송된다. 한편, 상기 학습 결과는 서로 다른 종류의 신경망 각각에 대한 가중치 정보가 병합된 데이터, 즉, 통합 가중치 데이터를 포함할 수 있다. 1회 학습이 완료된 단말기는 수정된 가중치 값을 활용하여 통합 가중치 데이터를 생성하고, 이를 서버로 전송한 다. 구체적으로, 각 단말기에 포함된 가중치 관리 모듈은 수정된 생성자 신경망 관련 가중치 및 판별자 신 경망 관련 가중치를 병합하여 학습 결과를 생성하고, 통신부는 상기 학습 결과를 서버로 전송한다. 다음으로, 서버에 포함된 인공지능 모듈이 수신된 학습 결과를 기반으로 인공지능 모델을 업데이트하는 단 계가 진행된다(S140). 서버가 단말기로부터 학습 결과를 수신할 때마다, 서버에 포함된 인공지능 모듈은 단말기로부터 수신된 수 정된 가중치값을 서버에 저장된 인공지능 모델에 적용한다. 이에 따라, 서버에 저장된 인공지능 모델에는 가장 최신의 가중치값이 저장될 수 있다. 서버는 복수의 단말기 각각으로부터 수정된 가중치값을 수신할 때마다, 서버에 저장된 인공지능 모델에 반영하 여, 서버에 저장된 인공지능 모델의 가중치값을 최신의 상태로 유지할 수 있다. 구체적으로, 클라이언트 관리 모듈이 단말기로부터 수정된 가중치값이 반영된 통합 가중치 데이터를 수신 하면, 이를 가중치 관리 모듈로 전달한다. 가중치 관리 모듈은 수신된 통합 가중치 데이터에서 생성 자 신경망과 관련된 가중치값(G)과 판별자 신경망과 관련된 가중치값(D)을 분할하여, 인공지능 모듈 로 전달한다. 인공지능 모듈은 서버에 저장된 인공지능 모델에 적용한다. 마지막으로, 서버가 업데이트된 인공지능 모델 관련 정보를 복수의 단말기로 전송하는 단계가 진행된다(S150). 서버는 최신 가중치값을 연합학습에 참가한 모든 단말기로 전송한다. 복수의 단말기는 서버로부터 최신 가중치 값을 전송받아 단말기 각각에 저장된 인공지능 모델에 적용하고, 최신 가중치 값이 적용된 인공지능 모델에 학 습데이터를 입력하여 학습을 진행한다. 단말기로부터 수정된 가중치값이 반영된 통합 가중치 데이터를 수신하면, 클라이언트 관리 모듈은 수신된 통합 가중치 데이터를 복수의 단말기로 전송한다. 복수의 단말기 각각에 포함된 가중치 관리 모듈은 수정된 가중치값이 반영된 통합 가중치 데이터를 수신하 면, 생성자 신경망과 관련된 가중치값(G)과 판별자 신경망과 관련된 가중치값(D)을 분할하여, 복수의 단말기 각각에 포함된 인공지능 모듈에 전달한다. 단말기 각각에 포함된 인공지능 모듈은 각 단말기 에 저장된 인공지능 모델에 적용한 후 학습을 진행한다. 상술한 방식으로, 복수의 단말기에서 단일 인공지능 모델에 대한 학습이 이루어질 수 있다. 도 7에 도시된 바와 같은 연합학습을 위한 프레임워크는 그 지원방식이 제한적이다. 구체적으로, 종래 연합학습 프레임워크는 classification, segmentation 및 detection 관련 태스크만 지원하고 있다. 즉, 종래 연합학습 프레임워크는 한 종류의 신경망을 학습할 수 있도록, 한 종류의 신경망에 대한 가중치 송수신만 지원한다. 이 때문에, 종래 연합학습 프레임워크는 두 종류의 신경망을 함께 학습시켜야하는 적대적 생성 신경망 모델에는 적 용되기 어렵다. 즉, 종래 연합학습 방법에서는 서버와 단말기간에는 한 종류의 신경망에 대한 가중치 정보만 송수신된다. 본 발명은 서버가 인공지능 모델 관련 정보를 복수의 단말기로 전송하거나, 1회 학습을 종료한 단말기가 서버로 학습 결과를 전송할 때, 생성자 신경망 및 판별자 신경망 각각에 대한 가중치값이 병합된 데이터를 활용함으로써, 적대적 생성 신경망에 대한 연합 학습이 가능하도록 한다. 도 8을 참조하면, 서버에 포함된 가중치 관리 모듈은 인공지능 모델 관련 정보를 단말기로 전송할 때, 생 성자 신경망과 관련된 가중치값(G)과 판별자 신경망과 관련된 가중치값(D)을 합친 통합 가중치 데이 터를 생성하고, 클라이언트 관리 모듈은 통합 가중치 데이터를 복수의 단말기로 전송하고, 단말기 각각에 포함된 가중치 관리 모듈는 수신된 통합 가중치 데이터를 분할하고, 단말기 각가에 포함된 인공지능 모듈 은 분할된 데이터를 단말기 각각에 저장된 인공지능 모델에 반영한다. 이를 위해서는, 통합 가중치 데이터에서 생성자 신경망과 관련된 가중치값의 위치 및 수, 판별자 신경망 과 관련된 가중치값의 위치 및 수가 서버 및 단말기에 동일하게 알려져 있어야 한다. 이를 위해, 서버는 최초로 복수의 단말기에 인공지능 모델 관련 정보를 전송할 때, 통합 가중치 데이터의 구조 관련 정보를 전송할 수 있다. 여기서, 통합 가중치 데이터의 구조 관련 정보는 통합 가중치 데이터에서 생성자 신경망과 관련된 가중치 값의 위치 및 수, 판별자 신경망과 관련된 가중치값의 위치 및 수와 관련된 정보를 포함할 수 있다. 예를 들어, 도 7에서 설명한 StyleGAN2-ada의 network 파라미터(가중치)는 512×512 image 기준 Condition을 적용했을 때, 165개의 신경자 생성망 파라미터와 91개의 판별자 생성망 파라미터가 존재한다. 따라서, 통합 가 중치 데이터는 256개의 가중치 통합된 형태이며, 165개의 신경자 생성망 관련 가중치와 91개의 판별자 생성망 관련 가중치를 포함할 수 있다. 다만, 상술한 가중치의 수는 영상의 크기에 따라 달라질 수 있다. 상술한 바와 같이, 본 개시는 연합학습을 위한 서버 및 단말기간 데이터 송수신 시, 서로 다른 신경망에 적용되 는 가중치가 통합된 형태로 데이터를 송수신 함으로써, 연합학습을 적대적 생성 신경망에도 적용할 수 있도록 한다. 이를 통해, 본 개시는 여러 기관의 데이터를 한 곳에 모으지 않고도, 적대적 생성 신경망을 좋은 품질로 학습할 수 있게 한다. 도 9은 단일 기관에 구비된 AbdomenCT를 StyleGAN2-ADA 네트워크를 사용하여 1000회 학습한 결과이고, 도 10은 본 개시에 따른 연합 학습으로 복수의 기관에 구비된 AbdomenCT를 StyleGAN2-ADA 네트워크를 사용하여 400회 학 습한 결과를 나타낸다. 도 9에 따른 학습 결과 FID score가 29로 도출되었고, 도 10에 따른 학습 결과 FID score가 30으로 도출되었다. 이러한 결과를 바탕으로, 본 개시에 따른 연합 학습을 적용하면, 단일 기관에 구비된 학습 데이터를 활용한 학 습 대비 적은 학습으로도 좋은 품질의 인공지능 모델을 구현할 수 있는 것을 알 수 있었다. 한편, 개시된 실시예들은 컴퓨터에 의해 실행 가능한 명령어를 저장하는 기록매체의 형태로 구현될 수 있다. 명 령어는 프로그램 코드의 형태로 저장될 수 있으며, 프로세서에 의해 실행되었을 때, 프로그램 모듈을 생성하여 개시된 실시예들의 동작을 수행할 수 있다. 기록매체는 컴퓨터로 읽을 수 있는 기록매체로 구현될 수 있다. 컴퓨터가 읽을 수 있는 기록매체로는 컴퓨터에 의하여 해독될 수 있는 명령어가 저장된 모든 종류의 기록 매체 를 포함한다. 예를 들어, ROM(Read Only Memory), RAM(Random Access Memory), 자기 테이프, 자기 디스크, 플 래쉬 메모리, 광 데이터 저장장치 등이 있을 수 있다."}
{"patent_id": "10-2023-0017123", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "이상에서와 같이 첨부된 도면을 참조하여 개시된 실시예들을 설명하였다. 본 개시가 속하는 기술분야에서 통상 의 지식을 가진 자는 본 개시의 기술적 사상이나 필수적인 특징을 변경하지 않고도, 개시된 실시예들과 다른 형 태로 본 개시가 실시될 수 있음을 이해할 것이다. 개시된 실시예들은 예시적인 것이며, 한정적으로 해석되어서 는 안 된다.도면 도면1 도면2 도면3 도면4 도면5 도면6 도면7 도면8 도면9 도면10"}
{"patent_id": "10-2023-0017123", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 개시의 전반적 시스템 도면이다. 도 2는 본 개시의 의료 영상 학습 시스템에 포함된 서버의 블록도이다. 도 3은 본 개시의 의료 영상 학습 시스템에 포함된 단말기의 블록도이다. 도 4는 본 개시에 따른 의료 영상 학습 방법의 흐름도이다. 도 5는 적대적 생성 신경망 모델을 나타내는 개념도이다. 도 6은 StyleGAN2-ADA을 나타내는 개념도이다. 도 7은 연합 학습 프레임워크를 나타내는 개념도이다. 도 8은 본 개시의 일 측면에 따른 통합 가중치 데이터의 송수신 및 처리를 나타내는 개념도이다. 도 9은 단일 기관에 구비된 AbdomenCT를 StyleGAN2-ADA 네트워크를 사용하여 1000회 학습한 결과이다. 도 10은 본 개시에 따른 연합 학습으로 복수의 기관에 구비된 AbdomenCT를 StyleGAN2-ADA 네트워크를 사용하여 400회 학습한 결과이다."}
