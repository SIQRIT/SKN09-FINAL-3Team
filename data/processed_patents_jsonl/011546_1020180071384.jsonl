{"patent_id": "10-2018-0071384", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2019-0133579", "출원번호": "10-2018-0071384", "발명의 명칭": "사용자와 대화하며 내면 상태를 이해하고 긴밀한 관계를 맺을 수 있는 감성지능형 개인비서", "출원인": "한국과학기술원", "발명자": "이수영"}}
{"patent_id": "10-2018-0071384", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "개인비서 시스템에 의해 수행되는 개인비서 방법에 있어서, 사용자의 음성, 표정 또는 감정이 유발되는 라이프로그를 파악하는 단계;상기 파악된 라이프로그에 대한 기계학습을 통하여 사용자의 내면 상태를 추론하는 단계; 및 상기 추론된 사용자의 내면 상태에 대응하여 생성된 대화 데이터를 TTS(Text To Speech)를 통해 출력하는 단계 를 포함하는 방법."}
{"patent_id": "10-2018-0071384", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 추론된 사용자의 내면 상태에 대응하여 생성된 대화 데이터를 TTS(Text To Speech)를 통해 출력하는 단계는,상기 추론된 사용자의 내면 상태에 대응하여 생성된 대화 내용의 텍스트 데이터를 음성 데이터로 변환하고, 상기 변환된 음성 데이터를 출력하여 상기 사용자와 대화하는 단계 를 포함하는 인지 방법."}
{"patent_id": "10-2018-0071384", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,상기 추론된 사용자의 내면 상태에 대응하여 생성된 대화 데이터를 TTS(Text To Speech)를 통해 출력하는 단계는,상기 변환된 음성 데이터를 상기 사용자의 내면 상태에 기초하여 감정, 나이 또는 성별 중 어느 하나 이상의 음성 출력 정보를 변경시키는 단계 를 포함하는 인지 방법."}
{"patent_id": "10-2018-0071384", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,상기 추론된 사용자의 내면 상태에 대응하여 생성된 대화 데이터를 TTS(Text To Speech)를 통해 출력하는 단계는,1)성별, 2)상기 성별에 따른 나이대 및 3)기쁨, 슬픔 또는 분노를 포함하는 감정 표현 중 적어도 하나 이상의구분 가능한 TTS를 생성하는 단계 를 포함하는 인지 방법."}
{"patent_id": "10-2018-0071384", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서,상기 파악된 라이프로그를 기계학습을 통하여 사용자의 내면 상태를 추론하는 단계는,상기 사용자의 얼굴, 상기 사용자의 표정, 상기 사용자와 대화하는 문장의 구문 분석을 통하여 감정, 연령 또는성별을 포함하는 내면 상태를 인식하는 단계 를 포함하는 인지 방법.공개특허 10-2019-0133579-3-청구항 6 제5항에 있어서,상기 파악된 라이프로그를 기계학습을 통하여 사용자의 내면 상태를 추론하는 단계는,상기 사용자의 대화 내용, 상기 사용자의 대화 억양 및 상기 사용자의 표정 변화 중 어느 하나 이상의 라이프로그를 융합하여 상기 사용자의 내면 상태를 인식하고, 상기 인식된 사용자의 내면 상태를 학습시키는 단계를 포함하는 인지 방법."}
{"patent_id": "10-2018-0071384", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제5항에 있어서,상기 파악된 라이프로그를 기계학습을 통하여 사용자의 내면 상태를 추론하는 단계는,상기 사용자의 정서적 불안, 상기 사용자의 스트레스 정도 또는 상기 사용자의 정신상태 중 어느 하나 이상의포함하는 라이프로그를 학습시키는 단계 를 포함하는 인지 방법."}
{"patent_id": "10-2018-0071384", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "개인비서 시스템에 있어서, 사용자의 음성, 표정 또는 감정이 유발되는 라이프로그를 파악하는 인식부;상기 파악된 라이프로그에 대한 기계학습을 통하여 사용자의 내면 상태를 추론하는 분석부; 및 상기 추론된 사용자의 내면 상태에 대응하여 생성된 대화 데이터를 TTS(Text To Speech)를 통해 출력하는 TTS대화부를 포함하는 시스템."}
{"patent_id": "10-2018-0071384", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서,상기 TTS(Text To Speech) 대화부는,상기 추론된 사용자의 내면 상태에 대응하여 생성된 대화 내용의 텍스트 데이터를 음성 데이터로 변환하고, 상기 변환된 음성 데이터를 출력하여 상기 사용자와 대화하는 것을 특징으로 하는 시스템."}
{"patent_id": "10-2018-0071384", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9항에 있어서,상기 TTS(Text To Speech) 대화부는,상기 변환된 음성 데이터를 상기 사용자의 내면 상태에 기초하여 감정, 나이 또는 성별 중 어느 하나 이상의 음성 출력 정보를 변경시키는 것을 특징으로 하는 시스템."}
{"patent_id": "10-2018-0071384", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제8항에 있어서,상기 TTS(Text To Speech) 대화부는,1)성별, 2)상기 성별에 따른 나이대 및 3)기쁨, 슬픔 또는 분노를 포함하는 감정 표현 중 적어도 하나 이상의구분 가능한 TTS를 생성하는 공개특허 10-2019-0133579-4-것을 특징으로 하는 시스템."}
{"patent_id": "10-2018-0071384", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제8항에 있어서,상기 분석부는, 상기 사용자의 얼굴, 상기 사용자의 표정, 상기 사용자와 대화하는 문장의 구문 분석을 통하여 감정, 연령 또는성별을 포함하는 내면 상태를 인식하는 것을 특징으로 하는 시스템."}
{"patent_id": "10-2018-0071384", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제12항에 있어서,상기 분석부는, 상기 사용자의 대화 내용, 상기 사용자의 대화 억양 및 상기 사용자의 표정 변화 중 어느 하나 이상의 라이프로그를 융합하여 상기 사용자의 내면 상태를 인식하고, 상기 인식된 사용자의 내면 상태를 학습시키는 것을 특징으로 하는 시스템."}
{"patent_id": "10-2018-0071384", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제13항에 있어서,상기 분석부는, 상기 사용자의 정서적 불안, 상기 사용자의 스트레스 정도 또는 상기 사용자의 정신상태 중 어느 하나 이상의포함하는 라이프로그를 학습시키는 것을 특징으로 하는 시스템."}
{"patent_id": "10-2018-0071384", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "사용자와 대화하며 내면 상태를 이해하고 긴밀한 관계를 맺을 수 있는 감성지능형 개인비서 시스템이 개시된다. 일 실시예에 따른 개인비서 시스템에 의해 수행되는 개인비서 방법은, 사용자의 음성, 표정 또는 감정이 유발되 는 라이프로그를 파악하는 단계; 상기 파악된 라이프로그에 대한 기계학습을 통하여 사용자의 내면 상태를 추론 하는 단계; 및 상기 추론된 사용자의 내면 상태에 대응하여 생성된 대화 데이터를 TTS(Text To Speech)를 통해 출력하는 단계를 포함할 수 있다."}
{"patent_id": "10-2018-0071384", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "아래의 설명은 인공지능 기술에 관한 것으로, 사용자와 대화하며 내면 상태를 이해하고 긴밀한 관계를 맺을 수 있는 감성지능형 개인비서 시스템에 관한 것이다."}
{"patent_id": "10-2018-0071384", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "앞으로의 인공지능은 인간을 얼마나 잘 이해하고 도울 수 있는지가 중요한 문제로 대두될 것이나, 현재의 인공 지능은 디바이스는 스피커로서 대표된다. 기능 중심적인 디바이스로서 단순한 지식 전달의 역할 혹은 질문-응 답(Q&A)을 잘하나 인간의 감성과 정서를 이해하지 못하여 실용화에 한계로 작용한다. 현재 출시된 인공지능 스피커 디바이스 경우 사용자가 어떤 감정으로 대하든 음성 인식 후 사용자의 질문 및 요 구에 대해 대응한다. 하지만 인간은 현재 처한 상황과 감정, 심리상태 및 발화자가 누군지에 따라 같은 말이라 도 다르게 느낄 수 있다. 그러므로 인간의 상황에 상관없이 항상 똑같이 대하는 인공지능은 인간의 비서로서 욕구를 충족시키기에는 어려운 상황이다. 알고리즘 설계 시 사용자가 원하는 대답을 지정하여 인공지능 디바이스가 들려줄 수 있도록 할 수 있으나, 반려 동물과는 다르게 감정 교류와 공감 능력이 없는 인공지능 디바이스는 정해진 상황에 대하여 똑같은 행동을 취하"}
{"patent_id": "10-2018-0071384", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 2, "content": "고 주인을 남들과 같이 대하므로 쉽게 인간의 흥미를 잃을 수 있다. 발명의 내용"}
{"patent_id": "10-2018-0071384", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "사용자의 라이프로그에 대한 기계학습을 통하여 사용자의 말과 감정을 포함하는 내면 상태를 추론 및 예측하여 대화에 대응하는 시스템 및 방법을 제공할 수 있다."}
{"patent_id": "10-2018-0071384", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "개인비서 시스템에 의해 수행되는 개인비서 방법은, 사용자의 음성, 표정 또는 감정이 유발되는 라이프로그를 파악하는 단계; 상기 파악된 라이프로그에 대한 기계학습을 통하여 사용자의 내면 상태를 추론하는 단계; 및 상 기 추론된 사용자의 내면 상태에 대응하여 생성된 대화 데이터를 TTS(Text To Speech)를 통해 출력하는 단계를 포함할 수 있다. 상기 추론된 사용자의 내면 상태에 대응하여 생성된 대화 데이터를 TTS(Text To Speech)를 통해 출력하는 단계 는, 상기 추론된 사용자의 내면 상태에 대응하여 생성된 대화 내용의 텍스트 데이터를 음성 데이터로 변환하고, 상기 변환된 음성 데이터를 출력하여 상기 사용자와 대화하는 단계를 포함할 수 있다. 상기 추론된 사용자의 내면 상태에 대응하여 생성된 대화 데이터를 TTS(Text To Speech)를 통해 출력하는 단계 는, 상기 변환된 음성 데이터를 상기 사용자의 내면 상태에 기초하여 감정, 나이 또는 성별 중 어느 하나 이상 의 음성 출력 정보를 변경시키는 단계를 포함할 수 있다. 상기 추론된 사용자의 내면 상태에 대응하여 생성된 대화 데이터를 TTS(Text To Speech)를 통해 출력하는 단계 는, 1)성별, 2)상기 성별에 따른 나이대 및 3)기쁨, 슬픔 또는 분노를 포함하는 감정 표현 중 적어도 하나 이상 의 구분 가능한 TTS를 생성하는 단계를 포함할 수 있다. 상기 파악된 라이프로그를 기계학습을 통하여 사용자의 내면 상태를 추론하는 단계는, 상기 사용자의 얼굴, 상 기 사용자의 표정, 상기 사용자와 대화하는 문장의 구문 분석을 통하여 감정, 연령 또는 성별을 포함하는 내면 상태를 인식하는 단계를 포함할 수 있다. 상기 파악된 라이프로그를 기계학습을 통하여 사용자의 내면 상태를 추론하는 단계는, 상기 사용자의 대화 내용, 상기 사용자의 대화 억양 및 상기 사용자의 표정 변화 중 어느 하나 이상의 라이프로그를 융합하여 상기 사용자의 내면 상태를 인식하고, 상기 인식된 사용자의 내면 상태를 학습시키는 단계를 포함할 수 있다. 상기 파악된 라이프로그를 기계학습을 통하여 사용자의 내면 상태를 추론하는 단계는, 상기 사용자의 정서적 불 안, 상기 사용자의 스트레스 정도 또는 상기 사용자의 정신상태 중 어느 하나 이상의 포함하는 라이프로그를 학 습시키는 단계를 포함할 수 있다. 개인비서 시스템은, 사용자의 음성, 표정 또는 감정이 유발되는 라이프로그를 파악하는 인식부; 상기 파악된 라 이프로그에 대한 기계학습을 통하여 사용자의 내면 상태를 추론하는 분석부; 및 상기 추론된 사용자의 내면 상 태에 대응하여 생성된 대화 데이터를 TTS(Text To Speech)를 통해 출력하는 TTS 대화부를 포함할 수 있다."}
{"patent_id": "10-2018-0071384", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "인공지능이 사용자의 내면 상태인 친밀성, 성격, 감정을 이해하는 감성지능 기술을 바탕으로 사용자와 대화하며 도우미의 역할을 수행할 뿐 아니라, 마치 반려동물처럼 인공지능이 사용자를 주인 혹은 가족으로 알아보고 남들 과 다르게 대할 수 있는 긴밀한 관계를 맺을 수 있도록 감정적 교류가 가능하고 공감을 할 수 있는 인공지능 개 인비서 시스템 및 방법을 제공할 수 있다."}
{"patent_id": "10-2018-0071384", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 실시예를 첨부한 도면을 참조하여 상세히 설명한다. 도 1은 일 실시예에 따른 네트워크 환경의 예를 설명하기 위한 도면이다. 도 1의 네트워크 환경은 전자 기기, 개인비서 시스템 및 네트워크를 포함하는 예를 나타내고 있 다. 이러한 도 1은 발명의 설명을 위한 일례로 전자 기기의 수나 시스템의 수가 도 1과 같이 한정되는 것은 아 니다. 전자 기기는 컴퓨터 장치로 구현되는 고정형 단말이거나 이동형 단말일 수 있다. 전자 기기의 예를 들면, 스마트폰(smart phone), 휴대폰, 네비게이션, 컴퓨터, 노트북, 디지털방송용 단말, PDA(Personal Digital Assistants), PMP(Portable Multimedia Player), 태블릿 PC 등이 있다. 일례로 전자 기기는 무 선 또는 유선 통신 방식을 이용하여 네트워크를 통해 다른 전자 기기 및/또는 개인비서 시스템과 통 신할 수 있다. 통신 방식은 제한되지 않으며, 네트워크가 포함할 수 있는 통신망(일례로, 이동통신망, 유선 인터넷, 무선 인터넷, 방송망)을 활용하는 통신 방식뿐만 아니라 기기들간의 근거리 무선 통신 역시 포함될 수 있다. 예를 들어, 네트워크는, PAN(personal area network), LAN(local area network), CAN(campus area network), MAN(metropolitan area network), WAN(wide area network), BBN(broadband network), 인터넷 등의 네트워크 중 하나 이상의 임의의 네트워크를 포함할 수 있다. 또한, 네트워크는 버스 네트워크, 스타 네트워크, 링 네트워크, 메쉬 네트워크, 스타-버스 네트워크, 트리 또는 계층적(hierarchical) 네트워크 등을 포함하는 네트 워크 토폴로지 중 임의의 하나 이상을 포함할 수 있으나, 이에 제한되지 않는다. 개인비서 시스템은 전자 기기와 네트워크를 통해 통신하여 명령, 코드, 파일, 컨텐츠, 서비스 등을 제공하는 컴퓨터 장치 또는 복수의 컴퓨터 장치들로 구현될 수 있다. 일례로, 개인비서 시스템은 네 트워크를 통해 접속한 전자 기기로 어플리케이션의 설치를 위한 파일을 제공할 수 있다. 이 경우 전 자 기기는 개인비서 시스템으로부터 제공된 파일을 이용하여 어플리케이션을 설치할 수 있다. 또한 전자 기기가 포함하는 운영체제(Operating System, OS) 및 적어도 하나의 프로그램(일례로 브라우저나 상 기 설치된 어플리케이션)의 제어에 따라 개인비서 시스템에 접속하여 개인비서 시스템이 제공하는 서 비스나 컨텐츠를 제공받을 수 있다. 예를 들어, 전자 기기가 어플리케이션의 제어에 따라 네트워크 를 통해 서비스 요청 메시지를 개인비서 시스템으로 전송하면, 개인비서 시스템은 서비스 요청 메시 지에 대응하는 코드를 전자 기기로 전송할 수 있고, 전자 기기는 어플리케이션의 제어에 따라 코드에 따른 화면을 구성하여 표시함으로써 사용자에게 컨텐츠를 제공할 수 있다. 또한, 개인비서 시스템은 서버 일 수 있으며, 사용자와 대화하며 내면 상태를 이해하고 긴밀한 관계를 맺을 수 있는 감성지능형 개인비서 서비 스를 제공할 수 있다. 아래의 실시예에서는 개인비서 시스템은 인공지능에 기반하여 사용자로부터 파악된 라이프로그와 관련된 다양한 응대를 제공하고, 사용자의 감정 및 내면 상태에 맞춘 다양한 응대를 제공하고, 반려동물처럼 사용자를 주인으 로 알아보고 남들과 다르게 대할 수 있는 긴밀한 관계를 유지할 수 있다. 개인비서 시스템은 감정 데이터를 수 집, 사용자(화자) 또는 사용자의 감정을 인식, 사용자의 감정에 대응하는 표현을 제공, 사용자의 감성에 대한 학습에 기반한 지능 서비스 및 사회윤리 학습을 포함하는 핵심 기술을 구성할 수 있다. 구체적으로, 개인비서 시스템은 방대한 텍스트 데이터 기반의 감정 데이터 수집 및 DB 기술, 대화 문장의 구문 분석에 기반한 감정 인 식, 학습, 추론 방법 기술, 실세계 잡음(음성 및 영상) 제거 및 대규모 학습 기술, 딥러닝 기반 사용자의 음성/ 얼굴 표정 기반 감정/연령/성별 인식 기술 및 대화 상대의 남/녀/노/소 등 나이, 성별에 따른 성별과 나이가 구 분되는 TTS(Text to Speech)생성 기술, 인공비서 목소리에 사용자의 내면 상태에 따라 감정과 나이, 성별을 변 화시킬 수 있는 TTS 생성 기술, 대화억양 생성 시, 감정 상태에 따라 기쁨, 슬픔, 분노 등을 포함하는 6가지 이 상의 감정 표현이 가능한 TTS 생성 기술, 대화 내용, 대화 억양 및 표정변화 등을 융합하여 사용자의 감정을 종합적으로 인식, 학습 및 추론 기술, 얼굴 인식/화자 인식에 기반한 대화 상대의 지속적 인식 기술, 대화 상대의 지속적인 라이프로그 정보 획득 및 유지관리 기술, 대화 상대의 정서적 불안, 스트레스 정도, 정신상태 감정 등 을 인식하고 학습 및 추론 기술, 적은 학습 데이터로부터 사람들이 사용할 수 있는 임계 성능을 넘겨서 베타 서 비스로 방대한 데이터를 수집할 수 있게 하는 기술을 제공할 수 있다. 도 2는 일 실시예에 따른 개인비서 시스템의 구성을 설명하기 위한 블록도이고, 도 3은 일 실시예에 따른 개인 비서 시스템의 사용자와 대화하여 사용자의 내면 상태를 이해하고 긴밀한 관계를 맺을 수 있는 감성지능형 개인 비서 방법을 설명하기 위한 흐름도이다. 개인비서 시스템의 프로세서는 인식부, 분석부 및 TTS 대화부를 포함할 수 있다. 이러한 프로세서의 구성요소들은 개인비서 시스템에 저장된 프로그램 코드가 제공하는 제어 명령에 따라 프로세서에 의 해 수행되는 서로 다른 기능들(different functions)의 표현들일 수 있다. 프로세서 및 프로세서의 구성요소들 은 도 3의 사용자와 대화하여 사용자의 내면 상태를 이해하고 긴밀한 관계를 맺을 수 있는 감성지능형 개인비서 방법이 포함하는 단계들(310 내지 330)을 수행하도록 개인비서 시스템을 제어할 수 있다. 이때, 프로세서 및 프로세서의 구성요소들은 메모리가 포함하는 운영체제의 코드와 적어도 하나의 프로그램의 코드에 따른 명령 (instruction)을 실행하도록 구현될 수 있다. 프로세서는 사용자와 대화하여 사용자의 내면 상태를 이해하고 긴밀한 관계를 맺을 수 있는 감성지능형 개인비 서 방법을 위한 프로그램의 파일에 저장된 프로그램 코드를 메모리에 로딩할 수 있다. 예를 들면, 개인비서 시 스템에서 프로그램이 실행되면, 프로세서는 운영체제의 제어에 따라 프로그램의 파일로부터 프로그램 코드를 메 모리에 로딩하도록 개인비서 시스템을 제어할 수 있다. 이때, 프로세서 및 프로세서가 포함하는 인식부, 분석부 및 TTS 대화부 각각은 메모리에 로딩된 프로그램 코드 중 대응하는 부분의 명령을 실행하여 이후 단계들(310 내지 330)을 실행하기 위한 프로세서의 서로 다른 기능적 표현들일 수 있다. 단계에서 인식부는 사용자의 음성, 표정 또는 감정이 유발되는 라이프로그를 파악할 수 있다. 단계에서 분석부는 파악된 라이프로그에 대한 기계학습을 통하여 사용자의 내면 상태를 추론할 수 있 다. 분석부는 사용자의 얼굴, 사용자의 표정, 사용자와 대화하는 문장의 구문 분석을 통하여 감정, 연령 또는 성별을 포함하는 내면 상태를 인식할 수 있다. 분석부는 사용자의 대화 내용, 사용자의 대화 억양 및 사용자의 표정 변화 중 어느 하나 이상의 라이프로그를 융합하여 사용자의 내면 상태를 인식하고, 인식된 사 용자의 내면 상태를 학습시킬 수 있다. 분석부는 사용자의 정서적 불안, 사용자의 스트레스 정도 또는 사 용자의 정신상태 중 어느 하나 이상의 포함하는 라이프로그를 학습시킬 수 있다. 단계에서 TTS 대화부는 추론된 사용자의 내면 상태에 대응하여 생성된 대화 데이터를 TTS를 통해 출 력할 수 있다. TTS 대화부는 추론된 사용자의 내면 상태에 대응하여 생성된 대화 내용의 텍스트 데이터를 음성 데이터로 변환하고, 변환된 음성 데이터를 출력하여 사용자와 대화할 수 있다. TTS 대화부는 변환된 음성 데이터를 사용자의 내면 상태에 기초하여 감정, 나이 또는 성별 중 어느 하나 이상의 음성 출력 정보를 변 경시킬 수 있다. TTS 대화부는 성별, 성별에 따른 나이대 및 기쁨, 슬픔 또는 분노를 포함하는 감정 표현 중 적어도 하나 이상의 구분 가능한 TTS를 생성할 수 있다. 도 4는 일 실시예에 따른 개인비서 시스템에서 사용자와 대화하여 사용자의 내면 상태를 이해하고 긴밀한 관계 를 맺을 수 있는 감성지능형 개인비서 서비스 동작을 설명하기 위한 도면이다. 도 4에서는 사용자가 전자 기기을 통하여 개인비서 서비스 동작을 설명하기로 한다. 이때, 전자 기 기에 플랫폼 또는 애플리케이션 형태로 개인비서 시스템에서 제공하는 서비스가 실행되어 동작될 수 있고, 또는, 서버와의 통신을 통하여 서비스가 실행되어 동작될 수 있다. 예를 들면, 전자 기기에 상기 서비스 를 위한 기능이 셋팅될 수 있다. 전자 기기에 사용자의 얼굴, 표정 등의 화상 데이터를 인식할 수 있는 센서 및 카메라가 장착되어 있을 수 있고, 사용자의 음성 데이터를 인식할 수 있는 마이크, 스피커 등이 장착되어 있을 수 있다. 개인비서 시스템은 전자 기기를 통하여 사용자의 음성, 표정 또는 감정이 유발되는 라이프로그를 파악할 수 있다. 이때, 라이프로그란 사용자로부터 유발되는 사용자와 관련된 모든 데이터를 의미할 수 있다. 개인비 서 시스템은 전자 기기를 통하여 사용자와 대화를 수행함에 따라 대화 구문에 포함된 감정, 억양, 대화 중 에 나타나는 표정 등을 지속적으로 수집할 수 있다. 이때, 개인비서 시스템은 사용자와 대화를 수행할 수 있으 며, 사용자와의 대화를 통하여 사용자의 라이프로그를 파악할 뿐만 아니라 사용자의 내면 상태를 추론할 수 있 다. 일례로, 개인비서 시스템은 처음 사용자와 대화를 수행할 경우, 사용자와 관련된 정보가 존재하지 않기 때문에 기본적으로 설정된 질의-응답으로 대화를 시작할 수 있다. 개인비서 시스템은 사용자와 대화를 수행함에 따라 사용자와 관련된 정보(예를 들면, 사용자의 식별 정보, 사용자의 선호 정보 등)이 수집됨에 따라 사용자가 흥미를 가질만한 질문을 포함하는 대화를 진행할 수 있다. 또한, 개인비서 시스템은 사용자와 대화를 수행한 적이 있을 경우, 기 저장된 사용자의 정보에 기초하여 사용자와 대화를 진행할 수 있다. 개인비서 시스템은 사 용자와 대화를 진행하면서 사용자와 관련된 라이프로그를 인식 및 파악할 수 있다. 개인비서 시스템은 대화 내 용, 대화 억양 및 표정 변화 등을 융합하여 사용자의 감정을 종합적으로 인식할 수 있다. 또한, 개인비서 시스 템은 사용자의 라이프로그를 지속적으로 수집하여 데이터베이스에 저장해놓을 수 있다. 개인비서 시스템은 라이프로그에 대한 기계학습을 통하여 사용자의 내면 상태를 추론할 수 있다. 일례로, 기계 학습은 인공지능의 한 분야로 새로운 정보를 학습하고, 학습을 수행함에 따라 습득된 정보를 효율적으로 사용할 수 있는 능력과 결부시키는 지식을 습득할 수 있고, 작업을 반복적으로 수행함으로써 결과를 획득하는 기술의 개선 과정이다. 예를 들면, 개인비서 시스템은 컴퓨터가 여러 데이터를 이용하여 마치 사람처럼 스스로 학습할 수 있게 하기 위하여 인공 신경망을 기반으로 구축한 기계 학습 기술인 딥 러닝을 통하여 사용자의 내면 상태를 추론할 수 있다. 이러한 딥 러닝은 인간의 두뇌가 수많은 데이터 속에서 패턴을 발견한 뒤 사물을 구분하는 정 보처리 방식을 모방하여 컴퓨터가 사물을 분별할 수 있도록 기계 학습시킨다. 딥 러닝 기술을 적용하여 사람이 모든 판단 기준을 정해주지 않아도 컴퓨터가 스스로 인지, 추론 및 판단할 수 있게 된다. 이에, 개인비서 시스 템은 딥러닝의 예로 CNN, RNN, DNN 등의 인공 신경망을 이용하여 사용자의 내면 상태를 추론할 수 있다. 구체적으로, 개인비서 시스템은 사용자의 얼굴, 사용자의 표정, 사용자와 대화하는 문장의 구문 분석을 통하여 감정, 연령 또는 성별을 포함하는 내면 상태를 인식할 수 있다. 개인비서 시스템은 사용자의 대화 내용, 사용 자의 대화 억양 및 사용자의 표정 변화 중 어느 하나 이상의 라이프로그를 융합하여 사용자의 내면 상태를 인식 하고, 인식된 사용자의 내면 상태를 학습시킬 수 있다. 예를 들면, 개인비서 시스템은 사용자의 대화 내용, 대 화 억양, 표정 변화 등 복합적인 데이터에 기반하여 사용자로부터 겉으로 드러나는 상태뿐만 아니라 사용자로부 터 겉으로 드러나지 않는 내면 상태를 판단할 수 있다. 개인비서 시스템은 사용자의 정서적 불안, 사용자의 스 트레스 정도 또는 사용자의 정신상태 중 어느 하나 이상의 포함하는 라이프로그를 학습시킬 수 있다. 또한, 개 인비서 시스템은 사용자의 얼굴 또는 사용자의 얼굴의 표정을 인식함에 따라 전처리 과정을 수행하여 노이즈를 제거한 후, 학습시킴으로써 보다 정확하게 사용자의 얼굴, 표정을 인식할 수 있다. 예를 들면, 개인비서 시스 템은 얼굴, 얼굴의 표정을 통하여 사용자를 식별할 수 있다. 개인비서 시스템은 사용자로부터 추출된 얼굴의 특징점을 이용하여 기 저장된 데이터와 매칭하여 사용자를 식별할 수 있고, 사용자의 감정을 판단할 수도 있다. 또는, 개인비서 시스템은 사용자로부터 수집된 라이프로그를 각각의 카테고리에 기초하여 학습시킬 수 있다. 예를 들면, 개인비서 시스템은 사용자로부터 수집된 라이프로그에서 얼굴 표정, 음성 데이터를 포함하는 카테고 리 각각을 분류하여 학습시킬 수 있다. 또한, 사용자로부터 수집된 라이프로그를 한번에 또는 동시에 학습시킬 수 있고, 또는, 라이프로그의 카테고리 각각에 해당하는 데이터를 시간차를 두고 학습시킬 수 있다. 개인비서 시스템은 라이프로그를 학습시킴에 따라 추론 및 분석된 사용자의 내면 상태에 대응하여 대화 데이터 를 생성할 수 있다. 개인비서 시스템은 대화 데이터를 텍스트 데이터로 생성할 수 있고, 생성된 텍스트 데이터 를 TTS를 통하여 음성 데이터로 변환할 수 있다. 예를 들면, 개인비서 시스템은 사용자의 내면 상태에 대응하 는 대화 데이터를 데이터 베이스에서 추출하거나, 사용자의 내면 상태와 관련된 인터넷 서비스의 검색을 통하여 컨텐츠/데이터들을 수집할 수 있다. 이와 같이 수집 또는 추출된 데이터에 기반하여 대화 데이터를 생성할 수 있다. 개인비서 시스템은 성별, 성별에 따른 연령대(나이대) 및 기쁨, 슬픔 또는 분노를 포함하는 복수 개(예 를 들면, 6가지 이상)의 감정 표현 중 적어도 하나 이상의 구분 가능한 TTS를 생성할 수 있다. 이러한 음성 데 이터를 출력하여 사용자와 대화가 수행될 수 있다. 이때, 개인비서 시스템은 변환된 음성 데이터를 사용자의 내면 상태에 기초하여 감정, 나이 또는 성별 중 어느 하나 이상의 음성 출력 정보를 변경시킬 수 있다. 예를 들면, 개인비서 시스템은 전자 기기에 음성 출력 정보를 변경하는 유저 인터페이스를 제공할 수 있고, 사 용자로부터 유저 인터페이스를 통하여 입력 또는 선택된 음성 출력 정보로 변경될 수 있다. 또는, 개인비서 시 스템은 사용자의 내면 상태에 대응하는 아바타를 통하여 사용자의 감정에 공감할 수 있는 음성 데이터, 표정을 반영시킬 수 있다. 또한, 개인비서 시스템은 마치 반려동물처럼 인공지능이 사용자를 주인 혹은 가족으로 알아 보고 긴밀한 관계를 맺을 수 있도록 감정적 교류가 가능하다. 또한, 개인비서 시스템은 사용자의 성별, 나이 등에 대응하는 TTS를 생성할 수 있다. 일례로, 개인비서 시스템은 사용자의 내면 상태와 동일한 또는 유사한 나이, 성별 감정을 가지고 있는 음성 출력 정보를 통하여 사용자와 대화를 수행할 수 있다. 개인비서 시스템은 TTS를 통하여 사용자와 대화를 수행함에 따라 다음 대화의 내용을 예측하여 사용자의 대화에 대응하는 대화 데이터를 생성할 수 있다. 이에 따라, 개인비서 시스템은 대화 데이터가 음성으로 출력됨에 따라 사용자와 연속적으로 대화를 수행할 수 있게 된다. 개인비서 시스템은 사용자로부터 발화되는 대화 내용과 감정 상태 등을 수집함에 따라 텍스트 데이터로 변환하여 저장할 수 있다. 개인비서 시스템은 대화 데이터 및 사용자와의 대화 내용을 학습시킴으로써 다음 대화를 예측 및 대응할 수 있다. 예를 들면, 개인비서 시스템은 사용자와 대화를 수행함에 따라 획득된 사용자의 라이프로그 또는 내면 상태를 학습시킴에 따라 계속적으로 다 음의 대화 데이터를 업데이트/변경할 수 있다. 다시 말해서, 개인비서 시스템은 사용자의 말, 억양, 얼굴 표정 등을 분석하여 사용자의 감정을 인식하고 지속 적으로 대응 가능한 대화 데이터를 생성하여 TTS로 출력할 수 있다. 이에 따라, 개인비서 시스템은 사용자로부 터 획득된 라이프로그에 기반하여 학습된 학습 데이터로부터 사용자들이 사용할 수 있는 임계 성능을 통과시킴 에 따라 베타 서비스로 방대한 데이터를 수집할 수 있도록 한다. 이상에서 설명된 장치는 하드웨어 구성요소, 소프트웨어 구성요소, 및/또는 하드웨어 구성요소 및 소프트웨어 구성요소의 조합으로 구현될 수 있다. 예를 들어, 실시예들에서 설명된 장치 및 구성요소는, 예를 들어, 프로 세서, 콘트롤러, ALU(arithmetic logic unit), 디지털 신호 프로세서(digital signal processor), 마이크로컴 퓨터, FPGA(field programmable gate array), PLU(programmable logic unit), 마이크로프로세서, 또는 명령 (instruction)을 실행하고 응답할 수 있는 다른 어떠한 장치와 같이, 하나 이상의 범용 컴퓨터 또는 특수 목적 컴퓨터를 이용하여 구현될 수 있다. 처리 장치는 운영 체제(OS) 및 상기 운영 체제 상에서 수행되는 하나 이상 의 소프트웨어 애플리케이션을 수행할 수 있다. 또한, 처리 장치는 소프트웨어의 실행에 응답하여, 데이터를 접근, 저장, 조작, 처리 및 생성할 수도 있다. 이해의 편의를 위하여, 처리 장치는 하나가 사용되는 것으로 설"}
{"patent_id": "10-2018-0071384", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "명된 경우도 있지만, 해당 기술분야에서 통상의 지식을 가진 자는, 처리 장치가 복수 개의 처리 요소 (processing element) 및/또는 복수 유형의 처리 요소를 포함할 수 있음을 알 수 있다. 예를 들어, 처리 장치 는 복수 개의 프로세서 또는 하나의 프로세서 및 하나의 콘트롤러를 포함할 수 있다. 또한, 병렬 프로세서 (parallel processor)와 같은, 다른 처리 구성(processing configuration)도 가능하다. 소프트웨어는 컴퓨터 프로그램(computer program), 코드(code), 명령(instruction), 또는 이들 중 하나 이상의 조합을 포함할 수 있으며, 원하는 대로 동작하도록 처리 장치를 구성하거나 독립적으로 또는 결합적으로 (collectively) 처리 장치를 명령할 수 있다. 소프트웨어 및/또는 데이터는, 처리 장치에 의하여 해석되거나 처리 장치에 명령 또는 데이터를 제공하기 위하여, 어떤 유형의 기계, 구성요소(component), 물리적 장치, 가상 장치(virtual equipment), 컴퓨터 저장 매체 또는 장치에 구체화(embody)될 수 있다. 소프트웨어는 네트워크로 연결된 컴퓨터 시스템 상에 분산되어서, 분산된 방법으로 저장되거나 실행될 수도 있다. 소프트웨어 및 데이터 는 하나 이상의 컴퓨터 판독 가능 기록 매체에 저장될 수 있다. 실시예에 따른 방법은 다양한 컴퓨터 수단을 통하여 수행될 수 있는 프로그램 명령 형태로 구현되어 컴퓨터 판 독 가능 매체에 기록될 수 있다. 상기 컴퓨터 판독 가능 매체는 프로그램 명령, 데이터 파일, 데이터 구조 등 을 단독으로 또는 조합하여 포함할 수 있다. 상기 매체에 기록되는 프로그램 명령은 실시예를 위하여 특별히 설계되고 구성된 것들이거나 컴퓨터 소프트웨어 당업자에게 공지되어 사용 가능한 것일 수도 있다. 컴퓨터 판 독 가능 기록 매체의 예에는 하드 디스크, 플로피 디스크 및 자기 테이프와 같은 자기 매체(magnetic media), CD-ROM, DVD와 같은 광기록 매체(optical media), 플롭티컬 디스크(floptical disk)와 같은 자기-광 매체 (magneto-optical media), 및 롬(ROM), 램(RAM), 플래시 메모리 등과 같은 프로그램 명령을 저장하고 수행하도 록 특별히 구성된 하드웨어 장치가 포함된다. 프로그램 명령의 예에는 컴파일러에 의해 만들어지는 것과 같은 기계어 코드뿐만 아니라 인터프리터 등을 사용해서 컴퓨터에 의해서 실행될 수 있는 고급 언어 코드를 포함한다."}
{"patent_id": "10-2018-0071384", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "이상과 같이 실시예들이 비록 한정된 실시예와 도면에 의해 설명되었으나, 해당 기술분야에서 통상의 지식을 가 진 자라면 상기의 기재로부터 다양한 수정 및 변형이 가능하다. 예를 들어, 설명된 기술들이 설명된 방법과 다 른 순서로 수행되거나, 및/또는 설명된 시스템, 구조, 장치, 회로 등의 구성요소들이 설명된 방법과 다른 형태 로 결합 또는 조합되거나, 다른 구성요소 또는 균등물에 의하여 대치되거나 치환되더라도 적절한 결과가 달성될 수 있다. 그러므로, 다른 구현들, 다른 실시예들 및 특허청구범위와 균등한 것들도 후술하는 특허청구범위의 범위에 속한 다.도면 도면1 도면2 도면3 도면4"}
{"patent_id": "10-2018-0071384", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 일 실시예에 따른 네트워크 환경의 예를 설명하기 위한 도면이다. 도 2는 일 실시예에 따른 개인비서 시스템의 구성을 설명하기 위한 블록도이다.도 3은 일 실시예에 따른 개인비서 시스템의 따른 사용자와 대화하여 사용자의 내면 상태를 이해하고 긴밀한 관 계를 맺을 수 있는 감성지능형 개인비서 방법을 설명하기 위한 흐름도이다. 도 4는 일 실시예에 따른 개인비서 시스템에서 사용자와 대화하여 사용자의 내면 상태를 이해하고 긴밀한 관계 를 맺을 수 있는 감성지능형 개인비서 서비스 동작을 설명하기 위한 도면이다."}
