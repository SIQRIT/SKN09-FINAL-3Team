{"patent_id": "10-2020-7025393", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2020-0108364", "출원번호": "10-2020-7025393", "발명의 명칭": "다중 계층 메모리 시스템에서의 원격 다이렉트 메모리 액세스", "출원인": "마이크론 테크놀로지, 인크.", "발명자": "마하라나, 파라그 알."}}
{"patent_id": "10-2020-7025393", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "컴퓨터 시스템에 있어서,복수의 메모리 컴포넌트들 및 원격 다이렉트 메모리 액세스 네트워크 인터페이스 카드에 동작 가능하게 결합된호스트 시스템으로서, 적어도,상기 호스트 시스템에서 실행되는 어플리케이션에 가상 메모리의 페이지를 할당하고;상기 가상 메모리의 페이지를 상기 복수의 메모리 컴포넌트들의 물리적 메모리의 페이지에 맵핑시키고;상기 호스트 시스템에 의해, 원격 다이렉트 메모리 액세스 동작을 수행하도록 상기 원격 다이렉트 메모리 액세스 네트워크 인터페이스 카드에 지시하고;상기 원격 다이렉트 메모리 액세스 동작 동안, 상기 원격 다이렉트 메모리 액세스 네트워크 인터페이스 카드는상기 복수의 메모리 컴포넌트들의 상기 물리적 메모리의 페이지와 상기 원격 다이렉트 메모리 액세스 네트워크인터페이스 카드에 컴퓨터 네트워크를 통해 연결되는 원격 장치 사이에서 데이터 전송을 수행하고;적어도 상기 데이터 전송 기간 동안, 상기 가상 메모리의 페이지와 상기 복수의 메모리 컴포넌트들의 상기 물리적 메모리의 페이지 사이의 맵핑을 잠그도록 하는, 상기 호스트 시스템을 포함하는, 컴퓨터 시스템."}
{"patent_id": "10-2020-7025393", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 호스트 시스템은 상기 원격 다이렉트 메모리 액세스 동작 후 상기 가상 메모리의 페이지와 상기 복수의 메모리 컴포넌트들 사이의 상기 맵핑을 잠금 해제하도록 더 구성되는, 컴퓨터 시스템."}
{"patent_id": "10-2020-7025393", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서, 상기 호스트 시스템은 상기 데이터 전송 후 상기 가상 메모리의 페이지와 상기 복수의 메모리컴포넌트들 사이의 상기 맵핑을 잠금 해제하도록 더 구성되는, 컴퓨터 시스템."}
{"patent_id": "10-2020-7025393", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서, 상기 호스트 시스템은,상기 어플리케이션에 결합된 통지 에이전트;상기 어플리케이션이 실행되는 운영 체제에 결합된 통지 에이전트; 및상기 운영 체제에서 실행되는 원격 다이렉트 메모리 액세스 드라이버로서, 상기 원격 장치는 상기 운영 체제에서 원격 볼륨(remote volume)으로서 장착되는, 상기 원격 다이렉트 메모리 액세스 드라이버 중 하나를 통해 상기 데이터 전송의 완료를 검출하도록 더 구성되는, 컴퓨터 시스템."}
{"patent_id": "10-2020-7025393", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제3항에 있어서, 상기 호스트 시스템은 하이퍼바이저(hypervisor)를 통해 상기 데이터 전달의 완료를 검출하도록 더 구성되는, 컴퓨터 시스템."}
{"patent_id": "10-2020-7025393", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5항에 있어서, 상기 호스트 시스템은 상기 하이퍼바이저에서 실행되는 원격 다이렉트 메모리 액세스 드라이버를 통해 상기 데이터 전송의 상기 완료를 검출하도록 더 구성되는, 컴퓨터 시스템."}
{"patent_id": "10-2020-7025393", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6항에 있어서, 상기 원격 다이렉트 메모리 액세스 네트워크 인터페이스 카드는 물리적 기능 및 복수의 가상공개특허 10-2020-0108364-3-기능들을 포함하여, 단일 루트 입/출력 가상화를 구현하고; 상기 하이퍼바이저에서 실행되는 상기 원격 다이렉트 메모리 액세스 드라이버는 상기 원격 다이렉트 메모리 액세스 네트워크 인터페이스 카드의 상기 물리적 기능을 제어하는, 컴퓨터 시스템."}
{"patent_id": "10-2020-7025393", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서, 상기 하이퍼바이저는 상기 데이터 전송 동안 상기 맵핑을 잠그는 메모리 장치 드라이버를 가지며; 상기 메모리 컴포넌트들은 제1 메모리 및 상기 제1 메모리보다 더 느린 제2 메모리를 포함하며; 상기 물리적 페모리의 페이지는 상기 제2 메모리에 있는, 컴퓨터 시스템."}
{"patent_id": "10-2020-7025393", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서, 상기 제1 메모리는 휘발성 동적 랜덤 액세스 메모리이고, 상기 제2 메모리는 비휘발성 교차점메모리인, 컴퓨터 시스템."}
{"patent_id": "10-2020-7025393", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제8항에 있어서, 상기 호스트 시스템은 상기 원격 다이렉트 메모리 액세스 동작에 응답하여 상기 가상 메모리의페이지와 상기 제2 메모리의 페이지 사이의 상기 맵핑을 잠그는, 컴퓨터 시스템."}
{"patent_id": "10-2020-7025393", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제10항에 있어서, 상기 호스트 시스템은 중앙 처리 유닛(CPU) 및 메모리 관리 유닛을 포함하며; 상기 CPU는PCIe(peripheral component interconnect express) 버스를 통해 상기 원격 다이렉트 메모리 액세스 네트워크인터페이스 카드에 결합되는, 컴퓨터 시스템."}
{"patent_id": "10-2020-7025393", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제1항에 있어서,상기 복수의 메모리 컴포넌트들 내에서 예측 데이터 이동을 수행하도록 구성된 컨트롤러를 더 포함하는, 컴퓨터시스템."}
{"patent_id": "10-2020-7025393", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제10항에 있어서, 상기 컨트롤러는 인공 신경망을 사용하여 상기 데이터 이동을 예측하는 상기 인공 신경망을구현하기 위해 FPGA(field programmable gate array) 또는 ASIC(application specific integrated circuit)를사용하여 구현된 데이터 오케스트레이터(data orchestrator)를 포함하는, 컴퓨터 시스템."}
{"patent_id": "10-2020-7025393", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "방법에 있어서,어플리케이션에 가상 메모리의 페이지를 할당하는 단계;상기 가상 메모리의 페이지를 복수의 메모리 컴포넌트들의 물리적 메모리의 페이지에 맵핑시키는 단계;상기 어플리케이션에 의해, 원격 다이렉트 메모리 액세스 동작을 수행하도록 원격 다이렉트 메모리 액세스 네트워크 인터페이스 카드에 지시하는 단계로서, 상기 원격 다이렉트 메모리 액세스 동작 동안, 상기 원격 다이렉트메모리 액세스 네트워크 인터페이스 카드는 상기 복수의 메모리 컴포넌트들의 상기 물리적 메모리의 페이지와상기 원격 다이렉트 메모리 액세스 네트워크 인터페이스 카드에 컴퓨터 네트워크를 통해 연결되는 원격 장치 사이에서 데이터 전송을 수행하는, 상기 지시하는 단계; 및적어도 상기 데이터 전송 기간 동안, 상기 가상 메모리의 페이지와 상기 복수의 메모리 컴포넌트들의 상기 물리적 메모리의 페이지 사이의 맵핑을 잠그는 단계를 포함하는, 방법."}
{"patent_id": "10-2020-7025393", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제14항에 있어서, 상기 데이터 전송 후,상기 맵핑을 잠금 해제하는 단계; 및공개특허 10-2020-0108364-4-워크로드 예측에 기초하여, 상기 가상 메모리의 페이지를 상기 복수의 메모리 컴포넌트들의 제1 메모리로부터상기 복수의 메모리 컴포넌트들의 제2 메모리로 스와핑하는 단계로서, 상기 제2 메모리는 상기 제1 메모리에 대해 더 빠른, 상기 스와핑하는 단계를 더 포함하는, 방법."}
{"patent_id": "10-2020-7025393", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "메모리 시스템은 메모리 컴포넌트들, 원격 다이렉트 메모리 액세스(RDMA) 네트워크 인터페이스 카드(RNIC) 및 호 스트 시스템을 가지며, 어플리케이션에 가상 메모리의 페이지를 할당하고; 가상 메모리의 페이지를 메모리 컴포 넌트들의 물리적 메모리의 페이지에 맵핑시키고; RDMA 동작을 수행하도록 RNIC에 지시하고; RDMA 동작 동안, 복 수의 메모리 컴포넌트들의 물리적 메모리의 페이지와 원격 다이렉트 메모리 액세스 네트워크 인터페이스 카드에 컴퓨터 네트워크를 통해 연결되는 원격 장치 사이에서 데이터 전송을 수행하고; 적어도 데이터 전송 기간 동안, 가상 메모리의 페이지와 복수의 메모리 컴포넌트들의 물리적 메모리의 페이지 사이의 맵핑을 잠그도록 구성된다."}
{"patent_id": "10-2020-7025393", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "관련 출원들 본 출원은 2018년 8월 21일자로 출원된, \"Remote Direct Memory Access in Multi-Tier Memory Systems\" 명칭의 미국 출원 일련 번호 제16/107,624호, 및 2018년 2월 5일자로 출원된, \"Remote Direct Memory Access (RDMA) in Two Tier Memory Systems\" 명칭의 미국 임시 특허 출원 일련 번호 제62/626,523호의 출원일에 대한 혜택을 주장하며, 이들 전체 내용들은 본원에 참조로서 통합된다. 본 출원은 2018년 7월 11일자로 출원된, \"Predictive Paging to Accelerate Memory Access\" 명칭의 미국 특허 출원 일련 번호 제16/032,331호, 2018년 7월 13일자로 출원된, \"Isolated Performance Domains in a Memory System\" 명칭의 미국 특허 출원 일련 번호 제16/035,469호, 2018년 8월 3일자로 출원된, \"Memory Virtualization for Accessing Heterogeneous Memory Components\" 명칭의 미국 특허 출원 일련 번호 제 16/054,719호, 2018년 8월 3일자로 출원된, \"Predictive Data Orchestration in Multi-Tier Memory Systems\" 명칭의 미국 특허 출원 일련 번호 제16/054,819호, 및 2018년 8월 3일자로 출원된, \"Memory Access Communications through Message Passing Interface Implemented in Memory Systems\" 명칭의 미국 특허 출원 일련 번호 제16/054,890호에 관하나 것이며, 이들 출원들의 전체 내용들은 본원에 참조로서 통합된다. 기술 분야 본원에 개시된 적어도 일부 실시예들은 일반적으로 메모리 시스템에 관한 것으로, 보다 구체적으로는, 이에 제 한되는 것으 아니나 다중 계층 메모리 시스템들에서의 원격 다이렉트 메모리 액세스(RDMA)에 관한 것이다."}
{"patent_id": "10-2020-7025393", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "메모리 서브 시스템은 DIMM(dual in-line memory Module), SO-DIMM(small outline DIMM), 또는 NVDIMM(non- volatile dual in-line memory module)과 같은 메모리 모듈일 수 있다. 메모리 서브 시스템은 솔리드 스테이트 드라이브(SSD) 또는 하드 디스크 드라이브(HDD)와 같은 저장 시스템일 수 있다. 메모리 서브 시스템은 데이터를 저장하는 하나 이상의 메모리 컴포넌트들을 포함할 수 있다. 메모리 컴포넌트들은, 예를 들어, 비휘발성 메모리 컴포넌트들 및 휘발성 메모리 컴포넌트들일 수 있다. 메모리 컴포넌트들의 예들은 메모리 집적 회로들을 포함한 다. 일부 메모리 집적 회로들은 휘발성이며 저장된 데이터를 유지하기 위해 전력을 필요로 한다. 일부 메모리 집적 회로들은 비휘발성이며 전력이 공급되지 않을 때에도 저장된 데이터를 유지할 수 있다. 비휘발성 메모리의 예들은 플래시 메모리, 읽기 전용 메모리(ROM), 프로그램 가능 읽기 전용 메모리(PROM), 소거 가능한 프로그램 가능 읽기 전용 메모리(EPROM) 및 전기적으로 소거 가능한 프로그램 가능 읽기 전용 메모리(EEPROM) 메모리 등 을 포함한다. 휘발성 메모리의 예들은 동적 랜덤 액세스 메모리(DRAM) 및 정적 랜덤 액세스 메모리(SRAM)를 포 함한다. 일반적으로, 호스트 시스템은 메모리 서브 시스템을 사용하여 메모리 컴포넌트들에 데이터를 저장하고 메모리 컴포넌트들로부터 데이터를 검색할 수 있다. 예를 들어, 컴퓨터는 호스트 시스템 및 호스트 시스템에 부착된 하나 이상의 메모리 서브 시스템들을 포함할 수 있다. 호스트 시스템은 데이터 및 인스트럭션들을 저장 및/또는 검색하기 위해 하나 이상의 메모리 서브 시스템 들과 통신하는 중앙 처리 유닛(CPU)을 가질 수 있다. 컴퓨터에 대한 인스트럭션들은 운영 체제들, 장치 드라이 버들 및 어플리케이션 프로그램들을 포함할 수 있다. 운영 체제는 컴퓨터의 리소스들을 관리하고, 그 리소스들 의 메모리 할당 및 시간 공유와 같은 어플리케이션 프로그램들에 공통적인 서비스들을 제공한다. 장치 드라이버 는 컴퓨터 내의 특정 유형의 장치들을 동작시키거나 제어하며; 운영 체제는 장치 드라이버를 사용하여 장치들의 유형에 의해 제공되는 리소스들 및/또는 서비스들을 제공한다. 컴퓨터 시스템의 중앙 처리 유닛(CPU)은 운영 체 제와 장치 드라이버들을 실행하여 어플리케이션 프로그램들에 서비스들 및/또는 리소스들을 제공할 수 있다. 중 앙 처리 유닛(CPU)은 서비스들 및/또는 리소스들을 사용하는 어플리케이션 프로그램을 실행할 수 있다. 예를 들 어, 컴퓨터 시스템들의 어플리케이션들의 유형을 구현하는 어플리케이션 프로그램은 데이터를 메모리 서브 시스 템의 메모리 컴포넌트들에 저장하고 메모리 컴포넌트들로부터 데이터를 검색하도록 중앙 처리 유닛(CPU)에 지시할 수 있다. 컴퓨터 시스템의 운영 체제는 어플리케이션 프로그램이 가상 메모리 어드레스를 사용하여 컴퓨터 시스템의 하나 이상의 메모리 서브 시스템들의 메모리 컴포넌트들에 데이터를 저장하거나 이로부터 데이터를 검색하게 할 수 있다. 운영 체제는 가상 어드레스들을 컴퓨터 시스템의 중앙 처리 유닛(CPU)에 연결된 하나 이상의 메모리 서브 시스템들의 물리적 어드레스들에 매핑한다. 운영 체제는 메모리 서브 시스템의 물리적 어드레스를 사용하여 가 상 어드레스들에 지정된 메모리 액세스들을 구현한다. 가상 어드레스 공간은 페이지들로 분할될 수 있다. 가상 메모리 페이지는 메모리 서브 시스템의 물리적 메모리 페이지에 맵핑될 수 있다. 운영 체제는 페이징 기술을 사용하여 메모리 모듈의 메모리의 페이지를 통해 저장 장 치의 메모리의 페이지에 액세스할 수 있다. 서로 다른 시기에, 메모리 모듈의 동일한 메모리 페이지는 저장 장 치 또는 컴퓨터 시스템의 다른 저장 장치의 다른 메모리 페이지에 액세스하기 위해 프록시로 사용될 수 있다. 컴퓨터 시스템은 가상 머신들을 생성하거나 프로비저닝하는 하이퍼바이저(또는 가상 머신 모니터)를 포함할 수 있다. 가상 머신은 컴퓨터 시스템에서 사용할 수 있는 리소스들과 서비스들을 사용하여 가상으로 구현되는 컴퓨 팅 장치이다. 하이퍼바이저는 마치 가상 머신의 컴포넌트들이 전용 물리적 컴포넌트들인 것처럼 운영 체제에 대 한 가상 머신을 나타낸다. 게스트 운영 체제는 컴퓨터 시스템에서 실행되는 호스트 운영 체제와 유사한 방식으 로, 가상 머신에서 사용할 수 있는 리소스들과 서비스들을 관리하기 위해 가상 머신에서 실행된다. 하이퍼바이 저는 다수의 가상 머신들이 컴퓨터 시스템의 리소스들을 공유할 수 있도록 하며, 가상 머신들이 실질적으로 서 로 독립적으로 컴퓨터에서 동작할 수 있도록 한다. 원격 다이렉트 메모리 액세스(remote direct memory access; RDMA)는 컴퓨터들의 운영 체제들을 포함하지 않고 컴퓨터 네트워크를 통해 한 컴퓨터의 메모리에서 다른 컴퓨터의 메모리로의 다이렉트 메모리 액세스를 위한 기 술이다. 네트워크 어댑터는 컴퓨터의 운영 체제에서 어플리케이션 메모리와 데이터 버퍼들 사이에 데이터를 복 사할 필요 없이 어플리케이션으로 또는 어플리케이션으로부터 직접 데이터를 전송하는 데 사용된다. 따라서, RDMA 동작들은 컴퓨터들의 중앙 처리 유닛(CPU)들을 포함하지 않고도 다른 시스템 동작들과 병행하여 수행될 수 있다."}
{"patent_id": "10-2020-7025393", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 개시의 적어도 일부 측면들은 지능형 데이터 오케스트레이터를 갖는 멀티-계층 메모리 서브 시스템에서의 원 격 다이렉트 메모리 액세스 기술들에 관한 것이다. 메모리 서브 시스템은 이하에서 \"메모리 디바이스\"로도 지칭된다. 메모리 서브 시스템의 예로는 메모리 버스를 통해 중앙 처리 유닛(CPU)에 연결되는 메모리 모듈이 있다. 메모리 모듈들의 예들은 DIMM(Dual In-line Memory Module), SO-DIMM(Small Outline DIMM), NVDIMM(Non- Volatile Dual In-line Memory Module) 등을 포함한다. 메모리 서브 시스템의 다른 예로는 주변 인터커넥트(예 를 들어, 입력/출력 버스, 저장 영역 네트워크)를 통해 중앙 처리 유닛(CPU)에 연결되는 저장 장치가 있다. 저 장 장치들의 예들은 솔리드 스테이트 드라이브(SSD), 플래시 드라이브, 범용 직렬 버스(USB) 플래시 드라이브 및 하드 디스크 드라이브(HDD)를 포함한다. 일부 실시예들에서, 메모리 서브 시스템은 메모리 기능들 및 저장 기능들 둘 다를 제공하는 하이브리드 메모리/저장 서브 시스템이다. 일반적으로, 호스트 시스템은 하나 이상의 메모리 컴포넌트들을 포함하는 메모리 서브 시스템을 이용할 수 있다. 호스트 시스템은 메모리 서브 시스템에 저장될 데이터를 제공할 수 있으며 메모리 서브 시스템에 검색될 데이터를 요청할 수 있다. 종래 시스템은 더 빠른 메모리들을 통해 더 느린 메모리들이 액세스되는 캐시 구조를 가질 수 있다. 프로세서가 현재 더 느린 메모리에 있는 데이터에 액세스하는 경우, 데이터는 더 느린 메모리에 있는 데이터의 프록시로서 더 빠른 메모리에 로딩된다. 이후, 프로세서는 성능 향상을 위해 더 빠른 메모리에 있는 데이터의 프록시/캐시 에서 동작한다. 더 빠른 메모리는 일반적으로 더 느린 메모리보다 더 작은 용량을 갖는다. 따라서, 더 느린 메 모리에 있는 데이터의 일부만이 더 빠른 메모리에 동시에 캐싱될 수 있다. 프로세서에 의해 액세스된 아이템이 현재 더 빠른 메모리에 없을 때 캐시 미스(cache miss)가 발생된다. 프로세서에 의해 액세스된 아이템이 현재 더 빠른 메모리에 있을 때 캐시 히트(cache hit)가 발생된다. 캐시 히트를 초래하는 액세스 백분율이 캐시 히트 율이다. 캐시 히트율을 개선하면 컴퓨팅 시스템의 운영 성능을 향상시킬 수 있다. 그러나, 캐시 히트율을 향상 시키기 위해 캐시 정책을 설계하는 것은 어려운 일이다. 본 개시의 적어도 일부 양상은 기계 학습 기술을 사용하여 상이한 계층들의 메모리들에 걸쳐 예측 데이터 이동 을 수행함으로써 상기 및 다른 결함들을 해결한다. 다른 계층들의 메모리들은 상이한 데이터 액세스 비용을 가 질 수 있다. 예를 들어, 컴퓨팅 시스템의 동작 성능을 향상시키기 위해, 자주 사용되는 데이터는 더 빠른 메모 리에 배치될 수 있으며; 덜 자주 사용되는 데이터는 더 느린 메모리에 배치될 수 있다. 더 빠른 메모리는 더 느 린 메모리를 위한 캐시 메모리로서 선택적으로 구성될 수 있다. 일부 경우, 더 느린 메모리의 적어도 일부는 캐 시로서 더 빠른 메모리를 거치지 않고 직접 액세스될 수 있다. 데이터 사용 정보는 워크로드 계획 및 이에 따른 상이한 계층들의 메모리들에 걸친 데이터 이동을 예측하기 위해, 기계 학습 기술을 사용하여 트레이닝된 예측 모델에 적용될 수 있다. 예를 들어, 데이터 사용 정보는 데이터를 사용하는 어플리케이션들 또는 프로그램들, 데이터 평가들이 이루어지는 사용자 계정들, 데이터에 액세스하는 가상 머신들, 데이터가 속하는 오브젝트들, 어플리케이션들에 구성된 데이터 블록들 대 오브젝트들 간 맵핑, 오브젝트들 간의 관계들 등과 같은, 데이터 액 세스들 및 데이터 액세스들과 관련된 속성들의 이력을 포함할 수 있다. 데이터 사용 정보에 따라 예측된 데이터 이동은 컴퓨팅 시스템의 동작 성능을 향상시키기 위해 선제적으로 수행될 수 있다. 예측 모델은 데이터 사용 정 보와 연관된 데이터 액세스들에 의해 발생된 이력 데이터 사용 정보 및 이력 데이터 이동을 사용하여 초기에 오 프라인으로 학습될 수 있다. 트레이닝은 이력 데이터 사용 정보를 예측 모델에 적용함으로써 생성된 이력 데이 터 이동과 예측 사이의 차이를 최소화한다. 이후, 예측 모델은 실시간 데이터 사용 정보를 사용하여 실시간 예 측에 사용될 수 있다. 예측된 데이터 이동을 수행하는 것은 데이터 액세스 요청들에 응답하여 데이터를 이동할 필요성을 감소시킬 수 있다. 실시간 데이터 액세스 요청들에 의해 발생된 데이터 이동 및/또는 예측된 데이터 이동이 계층들에 걸쳐 데이터를 이동할 필요성을 감소시키는지 여부의 표시들은 원하는 실시간 예측 결과들을 식별하는 데 사용될 수 있다. 원하는 결과들은 예측 모델의 지속적인 개선 및 적응을 위해 강화 기계 학습 기술 을 사용하여 예측 모델을 더 트레이닝시킬 수 있다. 예측 모델은 컴퓨팅 시스템의 실시간 사용 시 현재 워크로 드에 동적으로 적응될 수 있다. 예측 데이터 이동은 원격 다이렉트 메모리 액세스 동작들을 방해할 수 있다. 예를 들어, 원격 직접 메모리 액세 스 조작이 운영 체제와 무관한 방식으로 메모리의 페이지에서 수행되는 경우, 메모리의 페이지를 포함하는 예측 데이터 이동으로 인해 잘못된 결과들이 발생할 수 있다. 잘못된 결과들을 피하기 위해, 운영 체제는 원격 다이 렉트 메모리 액세스 동작 동안, 예측 데이터 이동이 원격 다이렉트 메모리 액세스 동작에 포함되는 메모리의 페 이지에서 수행되지 않도록 예측 데이터 이동과 조정되도록 구성될 수 있다. 예를 들어, 원격 다이렉트 메모리 액세스 동작의 개시(onset) 전에, 원격 다이렉트 메모리 액세스 동작을 포함하는 가상 메모리의 페이지는 물리 적 메모리에 고정되거나 요청시 페이징되도록 구성될 수 있으며; 원격 다이렉트 메모리 액세스 동작의 완료 후, 가상 메모리의 페이지는 예측 데이터 이동을 허용하도록 재구성될 수 있다. 도 1은 본 개시의 일부 실시예들에 따른 메모리 서브 시스템을 갖는 예시적인 컴퓨팅 시스템을 예시 한다. 메모리 서브 시스템은 메모리 컴포넌트들(109A 내지 109N)과 같은 매체를 포함할 수 있다. 메모리컴포넌트들(109A 내지 109N)은 휘발성 메모리 컴포넌트들, 비휘발성 메모리 컴포넌트들 또는 이들의 조합일 수 있다. 일부 실시예들에서, 메모리 서브 시스템은 메모리 모듈이다. 메모리 모듈의 예들로는 DIMM, NVDIMM 및 NVDIMM-P을 포함한다. 일부 실시예들에서, 메모리 서브 시스템은 저장 시스템이다. 저장 시스템의 예로는 SSD가 있다. 일부 실시예들에서, 메모리 서브 시스템은 하이브리드 메모리/저장 서브 시스템이다. 일반적 으로, 컴퓨팅 환경은 메모리 서브 시스템을 사용하는 호스트 시스템을 포함할 수 있다. 예를 들어, 호스트 시스템은 데이터를 메모리 서브 시스템에 기록하고 메모리 서브 시스템으로부터 데이터 를 판독할 수 있다. 호스트 장치는 데스크탑 컴퓨터, 랩탑 컴퓨터, 네트워크 서버, 모바일 장치 또는 메모리와 프로세싱 장치 를 포함하는 이러한 컴퓨팅 장치와 같은 컴퓨팅 장치일 수 있다. 호스트 시스템은 호스트 시스템이 메모리 서브 시스템로부터 데이터를 판독하거나 이에 데이터를 기록할 수 있도록 메모리 서브 시스템(11 0)을 포함하거나 이에 결합될 수 있다. 호스트 시스템은 물리적 호스트 인터페이스를 통해 메모리 서브 시 스템에 결합될 수 있다. 본원에 사용된 바와 같이, \"~에 결합된(coupled to)\"은 일반적으로 전기적, 광학 적, 자기적 등과 같은 연결들을 포함하여 유선이든 또는 무선이든, 간접 통신 연결 또는 (예를 들어, 중간 컴포 넌트들이 없는) 직접 통신 연결일 수 있는, 컴포넌트들 사이의 연결을 지칭한다. 물리적 호스트 인터페이스의 예들은, 이에 제한되는 것은 아니나, SATA(serial advanced technology attachment) 인터페이스, PCIe(peripheral component interconnect express) 인터페이스, USB(universal serial bus) 인터페이스, 광섬 유 채널, SAS(Serial Attached SCSI), DDR(double data rate) 메모리 버스 등을 포함한다. 물리적 호스트 인터 페이스는 호스트 시스템과 메모리 서브 시스템 사이에서 데이터를 전송하는 데 사용될 수 있다. 호스 트 시스템은 메모리 서브 시스템이 PCIe 인터페이스에 의해 호스트 시스템과 결합되는 경우 NVMe(NVM Express) 인터페이스를 추가로 이용하여 메모리 컴포넌트들(109A 내지 109N)에 액세스할 수 있다. 물 리적 호스트 인터페이스는 메모리 서브 시스템과 호스트 시스템 사이에서 제어, 어드레스, 데이터 및 다른 신호들을 전달하기 위한 인터페이스를 제공할 수 있다. 도 1은 예로서 메모리 서브 시스템을 예시한 다. 일반적으로, 호스트 시스템은 동일한 통신 연결, 다수의 개별 통신 연결들 및/또는 통신 연결들의 조 합을 통해 다수의 메모리 서브 시스템들에 액세스할 수 있다. 호스트 시스템은 프로세싱 장치 및 컨트롤러를 포함한다. 호스트 시스템의 프로세싱 장치 는 예를 들어, 마이크로프로세서, 중앙 처리 유닛(CPU), 프로세서의 프로세싱 코어, 실행 유닛 등일 수 있 다. 일부 경우, 컨트롤러는 메모리 컨트롤러, 메모리 관리 유닛 및/또는 이니시에이터(initiator)로 지칭 될 수 있다. 일 예에서, 컨트롤러는 호스트 시스템과 메모리 서브 시스템 사이에 결합된 버스를 통한 통신들을 제어한다. 일반적으로 컨트롤러는 메모리 컴포넌트들(109A 내지 109N)에 대한 원하는 액세스를 위해 명령들 또는 요 청들을 메모리 서브 시스템에 전송할 수 있다. 컨트롤러는 메모리 서브 시스템과 통신하기 위한 인터페이스 회로부를 더 포함할 수 있다. 인터페이스 회로부는 메모리 서브 시스템으로부터 수신된 응답들 을 호스트 시스템에 대한 정보로 변환할 수 있다. 호스트 시스템의 컨트롤러는 메모리 서브 시스템의 컨트롤러와 통신하여 메모리 컴포넌트 들(109A 내지 109N)에서의 데이터 판독, 데이터 기록 또는 소거와 같은 동작들 및 다른 이러한 동작들을 수행할 수 있다. 일부 경우, 컨트롤러는 프로세싱 장치의 동일한 페이지 내에 통합된다. 다른 경우, 컨트롤 러는 프로세싱 장치의 패키지로부터 분리된다. 컨트롤러 및/또는 프로세싱 장치는 하나 이 상의 집적 회로들 및/또는 개별 컴포넌트들, 버퍼 메모리, 캐시 메모리 또는 이들의 조합과 같은 하드웨어를 포 함할 수 있다. 컨트롤러 및/또는 프로세싱 장치는 마이크로컨트롤러, 특수 목적 논리 회로부(예를 들 어, FPGA(field programmable gate array), ASIC(application specific integrated circuit) 등), 또는 다른 적절한 프로세서일 수 있다. 메모리 컴포넌트들(109A 내지 109N)은 상이한 유형의 비휘발성 메모리 컴포넌트들 및/또는 휘발성 메모리 컴포 넌트들의 임의의 조합을 포함할 수 있다. 비휘발성 메모리 컴포넌트들의 예는 NAND(negative-and)형 플래시 메 모리를 포함한다. 메모리 컴포넌트들(109A 내지 109N) 각각은 단일 레벨 셀(SLC)들 또는 다중 레벨 셀(MLC)들 (예를 들어, 트리플 레벨 셀(TLC)들 또는 쿼드 레벨 셀(QLC)들)과 같은 하나 이상의 메모리 셀 어레이들을 포함 할 수 있다. 일부 실시예들에서, 특정 메모리 컴포넌트는 메모리 셀의 SLC 부분 및 MLC 부분 둘 다를 포함할 수 있다. 메모리 셀 각각은 호스트 시스템에 의해 사용된 하나 이상의 데이터 비트들(예를 들어, 데이터 블록 들)을 저장할 수 있다. NAND형 플래시 메모리와 같은 비휘발성 메모리 컴포넌트들이 설명되어 있지만, 메모리 컴포넌트들(109A 내지 109N)은 휘발성 메모리와 같은 임의의 다른 유형의 메모리에 기초할 수 있다. 일부 실시예들에서, 메모리 컴포넌트들(109A 내지 109N)은, 이에 제한되는 것은 아니나, 랜덤 액세스 메모리(RAM), 읽기 전용 메모리(ROM), 동적 랜덤 액세스 메모리(DRAM), 동기식 동적 랜덤 액세스 메모리(SDRAM), 위상 변화 메모리 (PCM), 자기 랜덤 액세스 메모리(MRAM), 스핀 전송 토크(STT)-MRAM, 강유전성 랜덤 액세스 메모리(FeTRAM), 강 유전성 RAM (FeRAM), 전도성 브리징 RAM(CBRAM), 저항성 랜덤 액세스 메모리(RRAM), OxRAM(Oxide-based RRAM), NOR(Negative-or) 플래시 메모리, 전기적으로 소거 가능한 프로그램 가능 읽기 전용 메모리(EEPROM), 나노 와이 어 기반 비휘발성 메모리, 멤리스터 기술을 통합한 메모리 및 비휘발성 메모리 셀들의 교차점 어레이일 수 있다. 비휘발성 메모리의 교차점 어레이는 스택 가능한 크로스 그리드 데이터 액세스 어레이(stackable cross- gridded data access array)와 함께 벌크 저항의 변화에 기초하여 비트 스토리지(bit storage)를 수행할 수 있 다. 추가로, 많은 플래시 기반 메모리들과 달리, 교차점 비휘발성 메모리는 쓰기 인플레이스(write in-place) 동작을 수행할 수 있으며, 여기서 비휘발성 메모리 셀은 비휘발성 메모리 셀이 미리 소거되지 않고 프로그래밍 될 수 있다. 게다가, 메모리 컴포넌트들(109A 내지 109N)의 메모리 셀들은 데이터를 저장하는데 사용되는 메모 리 컴포넌트의 단위를 지칭할 수 있는 메모리 페이지들 또는 데이터 블록들로서 그룹화될 수 있다. 메모리 서브 시스템의 컨트롤러는 메모리 컴포넌트들(109A 내지 109N)과 통신하여 데이터 판독, 데이 터 기록, 또는 메모리 컴포넌트들(109A 내지 109N)에서의 데이터 소거와 같은 동작들 및 다른 이러한 동작들(예 를 들어, 컨트롤러에 의해 명령 버스 상에서 스케줄링된 명령들에 응답하는)을 수행할 수 있다. 컨트롤러 는 하나 이상의 집적 회로들 및/또는 개별 컴포넌트들, 버퍼 메모리 또는 이들의 조합과 같은 하드웨어를 포함할 수 있다. 컨트롤러는, 마이크로컨트롤러, 특수 목적 논리 회로부(예를 들어, FPGA(field programmable gate array), ASIC(application specific integrated circuit) 등), 또는 다른 적절한 프로세서 일 수 있다. 컨트롤러는 로컬 메모리에 저장된 인스트럭션들을 실행하도록 구성된 프로세싱 장치 (프로세서)를 포함할 수 있다. 예시된 예에서, 컨트롤러의 로컬 메모리는 메모리 서브 시스템 과 호스트 시스템 간의 통신들을 처리하는 것을 포함하여, 메모리 서브 시스템의 동작을 제어하 는 다양한 프로세스들, 동작들, 논리 흐름들 및 루틴들을 수행하기 위한 인스트럭션들을 저장하도록 구성된 임 베디드된 메모리를 포함한다. 일부 실시예들에서, 로컬 메모리는 메모리 포인터, 페치 데이터(fetched data) 등을 저장하는 메모리 레지스터들을 포함할 수 있다. 로컬 메모리는 또한 마이크로-코드를 저장하기 위한 읽기 전용 메모리(ROM)를 포함할 수 있다. 도 1의 예시적인 메모리 서브 시스템은 컨트롤러를 포함하는 것으로 예시되어 있지만, 본 개시의 다른 실시예에서, 메모리 서브 시스템은 컨트롤러를 포 함하지 않을 수 있으며, 대신 (예를 들어, 외부 호스트에 의해 또는 메모리 서브 시스템으로부터 분리된 프로세 서나 컨트롤러에 의해 제공된) 외부 제어에 의존할 수 있다. 일반적으로, 컨트롤러는 호스트 시스템으로부터 명령들 또는 동작들을 수신할 수 있으며, 메모리 컴 포넌트들(109A 내지 109N)에 대한 원하는 액세스를 달성하기 위해 명령들 또는 동작들을 인스트럭션들 또는 적 절한 명령들로 변환할 수 있다. 컨트롤러는 웨어 레벨링(wear leveling) 동작들, 가비지 수집 동작들, 에 러 검출 및 에러 정정 코드(error-correcting code; ECC) 동작들, 암호화 동작들, 캐싱 동작들 및 메모리 컴포 넌트들(109A 내지 109N)과 관련되는 논리 블록 어드레스와 물리 블록 어드레스 간의 어드레스 변환들과 같은 다 른 동작들을 담당할 수 있다. 컨트롤러는 물리적 호스트 인터페이스를 통해 호스트 시스템과 통신하 기 위한 호스트 인터페이스 회로부를 더 포함할 수 있다. 호스트 인터페이스 회로부는 메모리 컴포넌트들(109A 내지 109N)과 연관된 응답들을 호스트 시스템에 대한 정보로 변환할 뿐만 아니라, 호스트 시스템으로부터 수신된 명령들을 메모리 컴포넌트들(109A 내지 109N)에 액세스하기 위한 명령 인스트럭션들로 변환할 수 있다. 메모리 서브 시스템은 또한 예시되지 않은 추가 회로부 또는 컴포넌트들을 포함할 수 있다. 일부 실시예들 에서, 메모리 서브 시스템은 컨트롤러로부터 어드레스를 수신하고 메모리 컴포넌트들(109A 내지 109N)에 액세스하기 위해 어드레스를 디코딩할 수 있는 캐시나 버퍼(예를 들어, DRAM) 및 어드레스 회로부(예를 들어, 행 디코더 또는 열 디코더)를 포함할 수 있다. 컴퓨팅 시스템은 메모리 서브 시스템의 더 빠른 메모리(예를 들어, 109A)와 더 느린 메모리(예를 들 어, 109N) 사이의 예측 데이터 이동을 수행할 수 있는 메모리 서브 시스템의 데이터 오케스트레이터 를 포함한다. 컴퓨팅 시스템은 적어도 원격 다이렉트 메모리 액세스 동작들을 용이하게 하기 위해 메모리 서브 시스템의 데이터 오케스트레이터와 협력하는 호스트 시스템의 데이터 오케스트레이터(11 3)를 더 포함한다. 일부 실시예들에서, 메모리 서브 시스템의 컨트롤러는 적어도 메모리 서브 시스템 의 데이터 오케스트레이터의 일부를 포함한다. 다른 실시예들에서, 또는 조합에서, 호스트 시스템 의 컨트롤러 및/또는 프로세싱 장치는 호스트 시스템의 데이터 오케스트레이터의 적 어도 일부를 포함한다. 예를 들어, 컨트롤러, 컨트롤러 및/또는 프로세싱 장치는 데이터 오케스트레이터를 구현하는 논리 회로부를 포함할 수 있다. 예를 들어, 호스트 시스템의 컨트롤러 또 는 프로세싱 장치(프로세서)는 본원에 설명된 호스트 시스템에서 데이터 오케스트레이터의 동작 을 수행하기 위해 메모리에 저장된 인스트럭션들을 실행하도록 구성될 수 있다. 일부 실시예들에서, 메모리 서 브 시스템의 데이터 오케스트레이터는 메모리 서브 시스템에 배치된 집적 회로에서 구현된다. 다른 실시예들에서, 호스트 시스템의 데이터 오케스트레이터는 호스트 시스템의 운영 체제, 장 치 드라이버 또는 어플리케이션의 일부이다. 메모리 서브 시스템의 데이터 오케스트레이터는 메모리 서브 시스템 내의 데이터 이동을 포함하 여 컴퓨팅 시스템에서의 데이터 사용 및 데이터 이동을 예측할 수 있다. 원격 다이렉트 액세스 동작 기간 동안, 호스트 시스템의 데이터 오케스트레이터는 메모리 서브 시스템의 데이터 오케스트레이터 가 원격 다이렉트 액세스 동작에 사용되는 메모리의 페이지를 스와핑(swapping)교환되는 것을 방지한다. 원격 다이렉트 액세스 동작이 시작된 후, 원격 다이렉트 액세스 동작에서 이루어진 데이터 전송은 프로세싱 장 치의 개입 없이 및/또는 호스트 시스템의 개입 없이 수행될 수 있으며; 데이터 오케스트레이터들 사이의 조정(coordination)은 원격 다이렉트 메모리 액세스의 데이터 전송이 메모리 서브 시스템에 서 데이터 오케스트레이터에 의해 수행되는 동시 예측 데이터 이동 및/또는 호스트 시스템에서의 동 작들에 의해 영향을 받지 않도록 보장한다. 데이터 오케스트레이터의 동작들에 관한 추가 세부 사항이 아 래에 설명된다. 도 2는 본원에 개시된 적어도 일부 실시예들에 따른 원격 다이렉트 메모리 액세스를 용이하게 하기 위한 데이터 오케스트레이터를 갖는 컴퓨팅 시스템을 도시한다. 도 2의 컴퓨팅 시스템은 호스트 시스템, 메모리 버스를 통해 호스트 시스템에 연결된 메모리 모 듈 및 컴퓨터 네트워크를 통해 원격 다이렉트 메모리 액세스(remote direct memory access; RDMA) 네트워크 인터페이스 카드(RNIC)에 연결된 원격 장치를 포함한다. RNIC는 메모리 버스를 통해 메모리 모듈에 연결되고 주변 장치 인터커넥트를 통해 호스트 시스템에 연결된다. 연결들 은 RNIC가 호스트 시스템으로부터 원격 다이렉트 메모리 액세스(RDMA) 명령을 수신하게 한다. 명령에 응답하여, RNIC는 RDMA 동작 동안, 호스트 시스템이 다른 동작들을 병행하여 수행할 수 있도록 호스 트 시스템과 관계없이 원격 장치와 메모리 모듈 사이에서 데이터 전송을 수행할 수 있다. 메모리 모듈은 도 1에 예시된 메모리 서브 시스템의 예이다. 원격 장치는 도 1에 예시된 것과 유사한 컴퓨터 시스템일 수 있다. 원격 장치는 네트워크, 별도의 호스트 시스템(예를 들어, 도 2의 호스트 시스템과 유사) 및 별도의 메모리 모듈(예를 들어, 도 2의 메모리 모듈과 유사)에 연결된 RNIC를 가질 수 있다. 호스트 시스템은 하나 이상의 프로세싱 코어들을 갖는 중앙 처리 유닛 또는 마이크로프로세서일 수 있는 프로세싱 장치를 갖는다. 호스트 시스템은 메모리 관리 유닛 및 캐시 메모리를 가질 수 있 다. 메모리 관리 유닛 및/또는 캐시 메모리의 적어도 일부는 프로세싱 장치의 동일한 집적 회로 패키지 내에 선택적으로 통합될 수 있다. 도 2에 예시된 메모리 모듈는 여러 유형의 메모리들(예: 221 및 223)을 갖는다. 예를 들어, 타입 A 메모리 는 타입 B 메모리보다 더 빠르다. 예를 들어, 메모리 버스는 이중 데이터 레이트 버스일 수 있으며; 주변 장치 인터커넥트는 PCIe(peripheral component interconnect express) 버스, SATA(serial advanced technology attachment) 버스, USB(universal serial bus) 버스 및/또는 저장 영역 네트워크 일 수 있다. 메모리 모듈의 타입 B 메모리는 저장 장치의 타입 B 메모리에 액세스하는 것보다 빠른 속도로 액세스될 수 있다. 일반적으로, 다수의 메모리 모듈들(예: 205)은 메모리 버스에 결합될 수 있으며; 다수의 저장 장치들(예를 들어, 도 6 및 7에 예시된 209)이 주변 장치 인터커넥트에 결합될 수 있다. 일부 경우, 주변 장치 인터커 넥트 및 저장 장치들(예: 209)은 선택적이며 컴퓨팅 시스템에는 없을 수 있다. 다른 경우, 메모리 버스 및 메모리 모듈들(예: 205)은 선택적이며 컴퓨팅 시스템에는 없을 수 있다. 다수의 메모리 모듈들(예: 205)이 메모리 버스에 결합 시 가능한 구성에서, 메모리 모듈들(예: 205) 중 하 나는 타입 A 메모리를 가지며; 다른 메모리 모듈들은 별도의 메모리 모듈(예: 205)의 타입 A 메모리 보다 낮은 속도로 액세스 가능한 타입 B 메모리를 갖는다. 프로세싱 장치 및/또는 MMU는 페이징 기술 및/또는 메모리 맵 인터페이스를 사용하여 컴퓨터 시스템 의 메모리의 다른 부분을 통해 컴퓨터 시스템의 메모리의 일부에 액세스하기 위한 인스트럭션들(예를 들어, 운 영 체제 및/또는 하나 이상의 장치 드라이버들)을 통해 구성된다. 예를 들어, 메모리 모듈의 타입 B 메모리는 메모리 모듈(또는 다른 메모리 모듈)의 타입 A 메모 리에 액세스될 수 있다. 예를 들어, 저장 장치(예: 209)의 메모리는 메모리 모듈의 타입 A 메모리 및/또는 메모리 모듈 의 타입 B 메모리를 통해 액세스될 수 있다. 예를 들어, 일부 경우, 동일한 메모리 모듈(또는 다른 메모리 모듈들)의 타입 A 메모리 및 타입 B 메 모리는 프로세싱 장치의 메모리 관리 유닛에 의해 메모리 버스를 통해 직접적으로 그리고 개별적으로 액세스할 수 있다. 그러나, 타입 B 메모리는 타입 A 메모리보다 느리기 때문에, 타입 A 메모리를 통해 타입 B 메모리에 액세스하는 것이 바람직하다. 다른 경우, 메모리 모듈의 타입 B 메모리는 (예를 들어, 메모리 버스의 어드레스 부분에서의 크 기 제한으로 인해) 메모리 모듈의 타입 A 메모리를 어드레싱하는 것을 통해서만 액세스 가능하다. 데이터 오케스트레이터는 컴퓨팅 시스템의 동작 성능을 최적화하기 위해 상이한 메모리들(예를 들어, 221, …, 223)에 걸쳐 데이터의 저장 위치들을 동적으로 조정할 수 있다. 예를 들어, 자주 액세스되는 데이터는 더 빠른 메모리(예: 221)에 스와핑될 수 있으며; 일정 시간 동안 사용되지 않은 데이터는 더 느린 메모리(예: 22 3)에 스와핑될 수 있다. 예를 들어, 데이터 오케스트레이터는 도 6 내지 9와 관련하여 아래에 논의된 바와 같이, 인공 신경망을 사용하여 데이터 이동을 예측할 수 있으며, 후속 시간 기간에 자주 액세스되는 데이터가 데이터가 액세스되기(또는 자주 액세스되기) 전에 이미 더 빠른 메모리(예: 221)에 있도록 메모리들의 계층들에 걸친 데이터 이동을 수행할 수 있다. 예측 데이터 향상의 일부 예들 및 세부사항들은 2018년 8월 3일자로 출원 된, \"Predictive Data Orchestration in Multi-Tier Memory Systems\"라는 명칭의 미국 특허 출원 일련 번호 제 16/054,819호에서 찾아볼 수 있다. 도 2에서, 메모리 모듈의 데이터 오케스트레이터와 호스트 시스템의 데이터 오케스트레이터 는 RNIC의 동작들을 방해하지 않도록 서로 조정된다. 예를 들어, 가상 메모리의 페이지가 원격 다이 렉트 메모리 액세스(RDMA) 동작을 위해 할당될 때, 데이터 오케스트레이터는 RDMA 동작이 완료될 때까지 페이지가 더 빠른 메모리(또는 더 느린 메모리)에 고정되게 할 수 있다. 대안으로, 가상 메모리의 페 이지가 원격 다이렉트 메모리 액세스(RDMA) 동작을 위해 할당될 때, 데이터 오케스트레이터는 RDMA 동작이 완료될 때까지 요청 시 더 빠른 메모리(또는 더 느린 메모리)로부터 페이지의 페이징이 수행되도록 구성될 수 있다. RDMA 동작이 완료된 후, 가상 메모리의 페이지 구성은 인공 신경망을 사용하여 이루어진 워크 로드 예측들에 기초하여 페이지가 더 빠른 메모리에서 더 느린 메모리로 (또는 더 느린 메모리 에서 더 빠른 메모리로) 이동될 수 있는 예측 데이터 이동을 허용하도록 조정될 수 있다. 가상 메모리의 페이지가 고정되는 것으로 구성될 때, 가상 메모리의 페이지에 대응하는 메모리 모듈에서의 물리적 메모리의 페이지 할당은 호스트 시스템에서 실행되는 운영 체제에 의해 및/또는 메모리 모듈 의 데이터 오케스트레이터에 의해 변경되도록 허용되지 않는다. 가상 메모리의 고정된 페이지와 메모리 모 듈의 대응되는 페이지 사이의 맵핑은 페이지가 고정되는 것으로 구성되는 동안 변경될 수 없기 때문에, RNIC는 운영 체제 및/또는 호스트 시스템의 개입 없이 메모리 모듈의 대응되는 페이지에서 RDMA 동작을 수행할 수 있다. 마찬가지로, 가상 메모리의 페이지가 요청 시 페이징을 위해 구성될 때, 메모리 모듈에서의 물리적 메모리 의 페이지 할당은 호스트 시스템에서 실행되는 운영 체제로부터 명시적인 요청없이 변경되도록 허용되지 않는다. 따라서, 페이지가 주문 시 페이징을 위해 구성되는 동안, 가상 메모리의 페이징 온 디맨드(paging-on- demand) 페이지와 메모리 모듈의 대응되는 페이지 사이의 매핑은 운영 시스템의 명시적 요청 없이 데이터 오케스트레이터에 의해 변경될 수 없다. 따라서, 운영 체제가 RDMA 동작의 보류 동안 페이지에 대한 페이 징 요청의 발행을 피하도록 프로그래밍되는 경우, RNIC는 운영 체제 및/또는 호스트 시스템의 개입 없이 메모리 모듈의 대응되는 페이지에서 RDMA 동작을 수행할 수 있다. 데이터 오케스트레이터는 RDMA 동작의 완료의 표시를 모니터링하도록 구성될 수 있다. RDMA 동작의 완료 시, 데이터 오케스트레이터는 메모리 모듈의 데이터 오케스트레이터가 (예를 들어, 워크로드 예 측들에 기초하여) 가상 메모리의 페이지에 대해 지능적 페이징(intelligent paging)을 수행할 수 있도록 가상 메모리의 페이지 설정을 조정할 수 있다.데이터 오케스트레이터는 호스트 시스템에 할당된 가상 메모리의 페이지에 대해 메모리 모듈 내 의 타입 A 메모리와 타입 B 메모리 사이에서 데이터 전송/이동을 수행하도록 메모리 모듈의 컨 트롤러 X에 지시할 수 있다. RNIC에 의해 수행되는 RDMA 동작의 동작 동안, 동작중인 페이지는 이러 한 데이터 이동을 방지하기 위해 잠금된다 (예를 들어, 요청 시 페이징을 고정하거나 요구하는 것을 통해 잠금 된다). RNIC에 의해 수행된 RDMA 데이터 전송의 동작 후, RDMA 데이터 전송을 완료한 페이지는 타입 A 메 모리와 타입 B 메모리 사이에서 데이터 이동을 허용하도록 잠금 해제된다. 일부 경우, 타입 A 메모리 및 타입 B 메모리 둘 다는 메모리 버스를 통해 RNIC에 액세스 가능하고; 데이터 오케스트레이터는 RDMA 데이터 전송의 성능 레벨과 일치하도록 선택된 타입 A 메모리 또는 타입 B 메모리 내의 페이지에 가상 메모리 페이지의 매핑을 잠그도록 구성된다. 예를 들어, 타입 B의 더 느린 메모리의 속도가 RDMA 데이터 전송을 수용하기에 충분할 때, 데이터 오케스 트레이터는 RDMA 데이터 전송을 위해 동작중인 가상 메모리의 페이지를 타입 A의 더 빠른 메모리에 고정하는 대신, 이를 타입 B의 더 느린 메모리에 잠글 수 있다. 또한, RDMA 동작의 완료 시, 데이터 오케 스트레이터는 가상 메모리 페이지의 페이징을 잠금 해제하고 이를 타입 A의 더 빠른 메모리로 이동시 킬 수 있다. 도 2의 컴퓨팅 시스템은 데스크탑 컴퓨터, 랩탑 컴퓨터, 네트워크 서버, 모바일 장치 또는 메모리와 프로세싱 장치를 포함하는 이러한 컴퓨팅 장치를 구현하는 데 사용될 수 있다. 프로세싱 장치는 메모리 서브 시스템 들(예: 205)로부터 데이터를 판독하고 이에 데이터를 기록할 수 있다. 프로세싱 장치는 하나 이상의 물리적 인터페이스(예: 203, 207)를 통해 메모리 서브 시스템(예: 205)에 결 합될 수 있다. 본원에 사용된 바와 같이, \"~에 결합된(coupled to)\"은 일반적으로 전기적, 광학적, 자기적 등과 같은 연결들을 포함하여 유선이든 또는 무선이든, 간접 통신 연결 또는 (예를 들어, 중간 컴포넌트들이 없는) 직접 통신 연결 일 수 있는, 컴포넌트들 사이의 연결을 지칭한다. 물리적 호스트 인터페이스의 예들은, 이에 제한되는 것은 아니나, SATA(serial advanced technology attachment) 인터페이스, PCIe(peripheral component interconnect express) 인터페이스, USB(universal serial bus) 인터페이스, 광섬유 채널, SCSI(Fibre Channel, Small Computer System Interface), SAS(Serial Attached SCSI) 등을 포함한다. 물리적 호스트 인터페이스는 프로세싱 장치와 메모리 서브 시스템(예: 209) 사이에서 데이터를 전송하는 데 사용될 수 있다. 컴퓨터 시스템은 메모리 서브 시스템이 PCIe 인터페이스를 통해 주변 장치 인터커넥트 와 결합될 때 메모리(예를 들어, 223, …, 225)에 액세스하기 위해 NVMe(NVM Express) 인터페이스를 더 이용할 수 있다. 물리적 호스트 인터페이스는 메모리 서브 시스템(예: 209)과 프로세싱 장치 사이에서 제 어, 어드레스, 데이터 및 다른 신호들을 전달하기 위한 인터페이스를 제공할 수 있다. 일반적으로, 메모리 서브 시스템(예를 들어, 205)은 메모리(예를 들어, 221, …, 223)를 제공하는 메모리 집적 회로들과 같은, 메모리 장치 세트를 연결하는 인쇄 회로 기판을 포함한다. 메모리 서브 시스템(예를 들어, 205) 상의 메모리(예를 들어, 221, …, 223)는 상이한 유형의 비휘발성 메모리 장치들 및/또는 휘발성 메모리 장치들 의 임의의 조합을 포함할 수 있다. 비휘발성 메모리 장치들의 예는 NAND(negative-and)형 플래시 메모리 또는 NOR(negative-or)형 플래시 메모리를 포함한다. 메모리 집적 회로는 단일 레벨 셀(SLC)들, 다중 레벨 셀(MLC)들, 트리플 레벨 셀(TLC)들, 쿼드 레벨 셀(QLC)들과 같은 하나 이상의 메모리 셀 어레이들을 포함할 수 있다. 일부 구현예들에서, 특정 메모리 장치는 메모리 셀들의 SLC 부분 및 MLC(또는 TLC 또는 QLC) 부분을 포함할 수 있다. 메모리 셀 각각은 호스트 시스템 에 의해 사용된 하나 이상의 데이터 비트들을 저장할 수 있다. NAND형 플래시 메모리와 같은 비휘발성 메 모리 장치들이 설명되어 있지만, 메모리 집적 회로들은 휘발성 메모리와 같은 임의의 다른 유형의 메모리에 기 초할 수 있다. 일부 구현예들에서, 메모리(예를 들어, 221, …, 223, …, 225)는 이에 제한되는 것은 아니나, 랜덤 액세스 메모리(RAM), 읽기 전용 메모리(ROM), 동적 랜덤 액세스 메모리(DRAM), 정적 랜덤 액세스 메모리 (SRAM), 동기식 동적 랜덤 액세스 메모리(SDRAM), 위상 변화 메모리(PCM), 자기 랜덤 액세스 메모리(MRAM), NOR(negative-or) 플래시 메모리, 전기적으로 소거 가능한 프로그램 가능 읽기 전용 메모리(EEPROM) 및 또는 비 휘발성 메모리 셀들의 교차점 어레이를 포함한다. 비휘발성 메모리의 교차점 어레이는 스택 가능한 크로스 그리 드 데이터 액세스 어레이와 함께 벌크 저항의 변화에 기초하여 비트 스토리지를 수행할 수 있다. 추가로, 많은플래시 기반 메모리들과 달리, 교차점 비휘발성 메모리는 쓰기 인플레이스(write in-place) 동작을 수행할 수 있으며, 여기서 비휘발성 메모리 셀은 비휘발성 메모리 셀이 미리 소거되지 않고 프로그래밍될 수 있다. 게다가, 메모리 장치들의 메모리 셀들은 데이터를 저장하는데 사용되는 메모리 장치의 단위를 지칭할 수 있는 메모리 페이지들 또는 데이터 블록들로서 그룹화될 수 있다. 메모리 서브 시스템(예를 들어, 205)은 프로세싱 장치 및/또는 메모리 관리 유닛(MMU)으로부터의 요 청들, 명령들 또는 인스트럭션들에 응답하여, 메모리(예를 들어, 221, …, 223)와 통신하여 메모리(예를 들어, 221, …, 223)에서의 데이터 판독, 데이터 기록 또는 데이터 소거와 같은 동작들 및 다른 이러한 동작들을 수행 하는 컨트롤러(예를 들어, 227)를 가질 수 있다. 컨트롤러(예를 들어, 227 또는 229)는 하나 이상의 집적 회로 들 및/또는 개별 컴포넌트들, 버퍼 메모리 또는 이들의 조합과 같은 하드웨어를 포함할 수 있다. 컨트롤러(예를 들어, 227)는, 마이크로컨트롤러, 특수 목적 논리 회로부(예를 들어, FPGA(field programmable gate array), ASIC(application specific integrated circuit) 등), 또는 다른 적절한 프로세서일 수 있다. 컨트롤러(예를 들어, 227)는 로컬 메모리에 저장된 인스트럭션들을 실행하도록 구성된 하나 이상의 프로세서들(프로세싱 장치 들)을 포함할 수 있다. 컨트롤러(예를 들어, 227)의 로컬 메모리는 메모리 서브 시스템(예를 들어, 205)과 프로세싱 장치 /MMU 사이의 통신 및 아래에서 더 상세히 설명되는 다른 기능들의 처리를 포함하여, 메모리 서브 시 스템(예를 들어, 205 209)의 동작을 제어하는 다양한 프로세스들, 동작들, 논리 흐름들 및 루틴들을 수행하기 위한 인스트럭션들을 저장하도록 구성된 임베디드된 메모리를 포함할 수 있다. 컨트롤러(예를 들어, 227)의 로 컬 메모리는 마이크로 코드를 저장하기위한 읽기 전용 메모리(ROM) 및/또는 메모리 포인터들, 페치된 데이 터 등을 저장하는 메모리 레지스터들을 포함할 수 있다. 도 2의 예시적인 메모리 서브 시스템들(예: 205)은 컨트롤러들(예를 들어, 227)을 포함하는 것으로 예시되어 있 지만, 본 개시의 다른 실시예에서, 메모리 서브 시스템(예를 들어, 205 또는 209)은 컨트롤러(예를 들어, 227) 를 포함하지 않을 수 있으며, 대신 외부 제어(예를 들어, MMU에 의해 제공되거나, 또는 메모리 서브 시스 템(예를 들어, 205 또는 209)으로부터 분리된 프로세서나 컨트롤러에 의해 제공됨)에 의존할 수 있다. 일반적으로, 컨트롤러(예를 들어, 227)는 통신 채널(예를 들어, 203 또는 207)에 대한 표준 통신 프로토콜에 따 라 프로세싱 장치 또는 MMU로부터 명령들, 요청들 또는 인스트럭션들을 수신할 수 있고, 표준 프로토 콜에 따른 명령들, 요청들 또는 인스트럭션들을 메모리 서브 시스템(예를 들어, 205) 내의 상세한 인스트럭션들 또는 적절한 명령들로 변환하여 메모리(예를 들어, 221, …, 223)에 대한 원하는 액세스를 달성할 수 있다. 예 를 들어, 컨트롤러(예를 들어, 227)는 웨어 레벨링 동작들, 가비지 수집 동작들, 에러 검출 및 에러 정정 코드 (ECC) 동작들, 암호화 동작들, 캐싱 동작들 및 메모리(예를 들어, 221, …, 223)와 관련되는 논리 블록 어드레 스와 물리 블록 어드레스 간의 어드레스 변환들과 같은 동작들을 담당할 수 있다. 컨트롤러(예를 들어, 227)는 물리적 호스트 인터페이스를 통해 프로세싱 장치와 통신하기 위한 호스트 인터페이스 회로부를 더 포함할 수 있다. 호스트 인터페이스 회로부는 메모리 장치들(예를 들어, 221, …, 223)과 연관된 응답들을 프로세싱 장 치에 대한 정보로 변환할 뿐만 아니라 프로세싱 장치로부터 수신된 명령들을 메모리 장치들(예를 들 어, 221, …, 223)에 액세스하기 위한 명령 인스트럭션들로 변환할 수 있다. 메모리 서브 시스템(예를 들어, 205)은 또한 예시되지 않은 추가 회로부 또는 컴포넌트들을 포함할 수 있다. 일 부 구현예들에서, 메모리 서브 시스템(예를 들어, 205)은 컨트롤러(예를 들어, 227) 또는 MMU로부터 어드 레스를 수신하고 어드레스를 디코딩하여 메모리(예를 들어, 221, …, 223)에 액세스할 수 있는 캐시 또는 버퍼 (예를 들어, DRAM) 및 어드레스 회로부(예를 들어, 행 디코더 및 열 디코더)를 포함할 수 있다. 일 예에서, 인터커텍트 또는 메모리 버스는 메모리 서브 시스템(예를 들어, 205)에 전력을 제공하고 /거나 미리 결정된 프로토콜을 통해 메모리 서브 시스템(예를 들어, 205)과 통신하기 위한 하나 이상의 커넥터 들을 가지며; 메모리 서브 시스템(예를 들어, 205)은 프로세싱 장치로부터 전력, 데이터 및 명령들을 수신 하기 위한 하나 이상의 커넥터들을 갖는다. 예를 들어, 인터커넥트 상의 커넥터와 메모리 서브 시스템(예 를 들어, 205) 상의 커넥터 사이의 연결은 PCIe 버스 또는 SATA 버스를 이용할 수 있다. 일부 경우, 주변 장치 인터커넥트는 메모리 모듈 및/또는 메모리 버스(예를 들어, 도 6에 예시 됨)를 통해 호스트 시스템에 연결될 수 있다. 이러한 상황에서, 데이터 오케스트레이터은 도 6에 예 시된 바와 같이, 메모리 모듈 상에서 구현될 수 있다. 일반적으로, 프로세싱 장치, 컨트롤러 및/또는 데이터 오케스트레이터는 아래에서 더 논의되는 바와 같이, 페이징 기술 및/또는 메모리 맵 인터페이스를 사용하여 컴퓨터 시스템의 메모리의 일부가 컴퓨터 시 스템의 메모리의 다른 부분을 통해 액세스되는 메모리 액세스의 가속을 포함하는, 서비스들을 제공하기 위해 하 나 이상의 운영 체제들을 실행할 수 있다. 도 3은 일 실시예에 따른 원격 다이렉트 메모리 액세스를 수행하는 컴퓨팅 시스템을 도시한다. 예를 들어, 도 3 의 시스템은 도 1 또는 2의 컴퓨팅 시스템을 사용하여 구현될 수 있다. 도 3에서, RNIC는 호스트 운영 체제로부터 명령을 수신하여 원격 다이렉트 메모리 액세스(RDMA) 동작 을 수행할 수 있다. RDMA 동작은 네트워크를 통해 메모리 모듈과 제거 장치 사이의 메모리 데이 터의 페이지를 전송한다. 예를 들어, 네트워크는 스위칭된 네트워크 섬유 및/또는 다른 유형의 컴퓨터 네 트워크들을 포함할 수 있다. 호스트 시스템에서 실행되는 호스트 운영 체제는 가상 머신의 가상 컴퓨터 컴포넌트들로서 메모 리 리소스들 및 RNIC를 제공하는 하이퍼바이저를 포함할 수 있다. 하이퍼바이저는 복수의 가상 머신들(예를 들어, 249)이 메모리 모듈 및 RNIC와 같은 물리적 리소스 세트를 공유하게 할 수 있다. 예를 들어, RNIC는 단일 루트 입/출력 가상화(virtualization)를 지원할 수 있다. 호스트 운영 체제(24 1)는 RNIC의 물리적 기능을 위한 장치 드라이브를 구현할 수 있으며; 가상 머신의 장치 드라이브는 RNIC의 물리적 기능에 대응되는 RNIC의 가상 기능에 액세스하기 위한 장치 드라이브를 가질 수 있다. 따라서, RNIC의 서로 다른 가상 기능들은 마치 RNIC의 다수의 사본들이 가상 머신들(예를 들어, 24 9)을 지원하기 위해 컴퓨터 시스템에 사실상 존재하는 것처럼 다른 가상 머신들에 할당될 수 있다. 어플리 케이션 세트(251, …, 253)는 가상 머신의 게스트 운영 체제 위에서 실행될 수 있다. 도 3에서, 호스트 시스템의 데이터 오케스트레이터는 메모리 장치 드라이브 및/또는 통지 에이 전트를 포함할 수 있다. 어플리케이션(251 또는 253)이 RDMA 동작을 위해 가상 메모리의 페이지를 할당할 때, 통지 에이전트 및/또는 메모리 장치 드라이버는 페이지에 대한 페이징 동작들을 잠글 수 있다. 따라서, 가상 메모리의 페이지와 메모리 모듈의 메모리(221 또는 223)의 페이지 사이의 맵핑은 RDMA 동작 동안 변경되지 않는다. 메모리 모듈과 원격 장치 사이의 RDMA 데이터 전송의 완료를 검출 시, 통지 에이전트 및/또는 메모리 장치 드라이버는 데이터 오케스트레이터가 워크로드에 기초하여 예측 데이터 이동을 수행하도록 페이지에 대한 페이징 동작들을 잠금 해제할 수 있다. 도 4는 도 4의 가상 머신에서 실행되는 어플리케이션에서 원격 다이렉트 메모리 액세스를 사용하는 예를 예시한다. 가상 머신은 호스트 시스템에서 하이퍼바이저에 이용 가능한 모듈의 메모리들(221, …, 223)을 나타내는 메모리 리소스들로부터 하이퍼바이저에 의해 할당되는 메모리 리소스들을 갖는 다. 가상 머신은 컴퓨터 시스템의 로컬 저장 장치를 로컬 볼륨으로, 원격 저장 장치를 원격 볼 륨으로 장착할 수 있다. 어플리케이션은 가상 볼륨의 일부가 가상 메모리들의 페이지로서 액세스되는 원격 다이렉트 메모리 액세스(RDMA) 동작을 수행하도록 가상 머신의 게스트 운영 체제를 요청하도록 프로그래밍될 수 있다. RDMA 요청에 응답하여, 게스트 운영 체제의 RDMA 드라이브는 하이퍼바이저의 RDMA 드라이브 또는 호스트 운영 체제와 통신하여 명령을 RNIC로 전송할 수 있으며, 이는 원격 장치로부 터 메모리 모듈의 페이지(또는 293)로 또는 메모리 모듈의 페이지(또는 293)로부터 페이지 의 데이터를 복사한다. 선택적으로, 어플리케이션은 RDMA 동작을 위해 할당된 가상 페이지를 (예를 들어, 요구 시 고정 또는 페이징의 요건을 통해) 메모리 모듈의 페이지(또는 293)에 잠그도록 명시적으로 요청한다. 대안으로, 통지 에이전트는 RDMA 동작 요청을 검출하기 위해 어플리케이션 및/또는 게스트 운영 체제에 연 결되고, 이에 응답하여 가상 페이지를 메모리 모듈의 페이지(또는 293)에 잠근다. 일부 경우, 메모리 모듈의 메모리 장치 드라이버는 RDMA 동작 요청을 통보받고, 이에 따라 응답으로서 가상 페이 지를 메모리 모듈의 페이지(또는 293)에 잠근다. 선택적으로, RDMA 데이터 전송 동작의 완료 후, 어플리케이션 및/또는 RDMA 드라이버(예: 286 또는 287)는 메모리 모듈의 페이지(또는 293)로부터 가상 메모리 페이지의 잠금 해제를 요청할 수 있다. 예 를 들어, 통지 에이전트는 RDMA 동작 요청의 완료를 검출하기 위해 어플리케이션 및/또는 게스트 운 영 체제에 연결되고, 이에 응답하여 가상 페이지를 메모리 모듈의 페이지(또는 293)로부터잠금 해제한다. 일부 경우, 메모리 모듈의 메모리 장치 드라이버는 RDMA 동작 요청의 완료를 통보받 고 응답으로서 가상 페이지를 메모리 모듈의 페이지(또는 293)로부터 잠금 해제한다. 일부 경우, 어플리케이션은 가상 볼륨의 일부가 가상 메모리의 페이지로서 액세스되는 다이렉트 메모리 액세스(DMA) 동작을 수행하도록 가상 머신의 게스트 운영 체제를 요청하도록 프로그래밍될 수 있다. 예를 들어, DMA 컨트롤러는 메모리 버스 및 주변 장치 인터커넥트에 연결되어 메모리 모듈 의 메모리의 페이지(또는 293)와 주변 장치 인터커넥트에 결합된 저장 장치 사이에서 데이터를 전송하며; 데이터 전송은 RDMA 동작에서와 같이 호스트 시스템의 개입 없이 수행될 수 있다. 이러한 상황 에서, DMA 동작에 포함된 가상 메모리 페이지는 RDMA 동작을 위한 페이지의 잠금/잠금 해제와 유사한 방식으로 잠금/잠금 해제될 수 있다. 도 5는 원격 다이렉트 메모리 액세스의 방법을 도시한다. 도 5의 방법은 하드웨어(예: 프로세싱 장치, 회로부, 전용 로직, 프로그램 가능 로직, 마이크로코드, 장치의 하드웨어, 집적 회로 등), 소프트웨어(예: 프로세싱 장 치에서 실행되거나 수행된 인스트럭션들) 또는 이들의 조합을 포함할 수 있는 프로세싱 로직에 의해 수행될 수 있다. 일부 실시예들에서, 도 5의 방법은 도 1 내지 4의 데이터 오케스트레이터에 의해 적어도 부분적으로 수행된다. 특정 시퀀스 또는 순서로 도시되어 있지만, 달리 명시되지 않는 한, 프로세스들의 순서는 수정될 수 있다. 따라서, 예시된 실시예들은 단지 예들로서 이해되어야 하고, 예시된 프로세스들은 상이한 순서로 수행될 수 있으며, 일부 프로세스들은 병행하여 수행될 수 있다. 추가로, 하나 이상의 프로세스들은 다양한 실시예들에 서 생략될 수 있다. 따라서, 모든 프로세스들이 모든 실시예에서 필요한 것은 아니다. 다른 프로세스 흐름들이 가능하다. 예를 들어, 도 5의 방법은 도 1의 메모리 서브 시스템, 도 2의 RNIC 및 데이터 오케스트레이터, 도 3의 하이퍼바이저 및/또는 도 4의 가상 머신을 사용하여 지능적 데이터 이동과 관련하여 원격 다 이렉트 메모리 액세스를 위한 도 1, 2, 3 또는 4의 컴퓨팅 시스템에서 구현될 수 있다. 예를 들어, 데이터 오케 스트레이터는 도 2의 메모리 모듈의 컨트롤러 및 도 1의 호스트 시스템의 프로세싱 장치 및 컨트롤러와 같은, 메모리 서브 시스템의 컨트롤러를 통해 적어도 부분적으로 구현될 수 있다. 선택적으로, 데이터 오케스트레이터는 도 6 내지 9와 관련하여 아래에 더 논의된 예측 데이터 이 동 기술들을 포함할 수 있다. 블록에서, 컴퓨터 시스템은 컴퓨터 시스템에서 실행되는 어플리케이션에 가상 메모리의 페이지 를 할당한다. 예를 들어, 어플리케이션은 도 3 및 4에 예시된 바와 같이, 컴퓨터 시스템에서 호스팅되고 게스트 운영 체 제에 의해 제어되는 가상 머신에서 실행될 수 있다. 대안으로, 어플리케이션은 하이퍼바이저 또는 가상 머신 없이 운영 체제에서 실행될 수 있다. 블록에서, 컴퓨터 시스템은 가상 메모리의 페이지를 물리적 메모리의 페이지(또는 293)에 맵핑 한다. 예를 들어, 컴퓨터 시스템은 메모리 모듈을 갖는다. 메모리 모듈은 상이한 성능 레벨들(예를 들어, 상이한 메모리 액세스 속도)을 갖는 상이한 계층의 메모리들(예를 들어, 221, …, 223)을 갖는다. 컴퓨터 시스 템이 가상 메모리의 페이지를 물리적 메모리의 페이지(또는 293)에 매핑할 때, 어플리케이션에 할당된 가상 메모리의 페이지에 액세스하면 메모리 모듈의 물리적 메모리의 페이지(또는 293)에 메모 리가 액세스하게 된다. 블록에서, 컴퓨터 시스템은 원격 다이렉트 메모리 액세스 동작을 수행하도록 원격 다이렉트 메모리 액세스 네트워크 인터페이스 카드에 지시한다. RDMA 네트워크 인터페이스 카드(RNIC)는 RDMA 동작 전후에 호 스트 시스템과 통신하기 위해 (예를 들어, 주변 장치 인터커넥트를 통해) 호스트 시스템에 대한 연결을 갖는다. RNIC는 RDMA 동작 동안 RDMA 데이터 전송을 위해 호스트 시스템과 통신하지 않는다. RNIC는 호스트 시스템을 거치지 않는 메모리 모듈(예를 들어, 메모리 버스를 통해)에 대한 연결을 가지며; RNIC는 또한 호스트 시스템을 거치지 않는 원격 장치에 대한 네트워크 연결을 갖는다. 따라서, RNIC는 일단 RDMA 동작에 대한 요청이 수신되면 호스트 시스템과 관계없이 RDMA 데 이터 전송을 수행할 수 있다. 예를 들어, 어플리케이션은 운영 체제(243 및/또는 241)가 어플리케이션에 할당된 가상 메모리의 페 이지를 통해 원격 볼륨의 일부에 액세스하도록 요청할 수 있다. 요청은 원격 다이렉트 메모리 액세스(RDMA) 드라이버들(286 및 287)을 사용하여 수행될 수 있다. 블록에서, 원격 다이렉트 메모리 액세스 네트워크 인터페이스 카드는 물리적 메모리의 페이지 (또는 293)과 네트워크 인터페이스 카드에 컴퓨터 네트워크를 통해 연결되는 원격 장치 사이에 서 원격 다이렉트 메모리 액세스 데이터 전송을 수행한다. 원격 다이렉트 메모리 액세스 데이터 전송은 호스트 시스템 및/또는 호스트 시스템에서 실행되는 운영 체제(241/243)의 동작들과 관계없이 RDMA 네트워크 인터페이스 카드에 의해 수행될 수 있다. 호스트 시스템 및/또는 호스트 시스템에서 실행되는 운영 체제(241/243)는 RNIC에 의해 제어되는 데이터 전송과 병행하여 동작들을 수행할 수 있다. 예를 들어, RNIC는 호스트 시스템 및/또는 운영 체제(241/243)의 개입 없이 원격 장치의 페이지 의 데이터를 메모리 모듈의 페이지(또는 293)로 전송한다. 블록에서, 컴퓨터 시스템의 데이터 오케스트레이터은 적어도 RDMA 데이터 전송 기간 동안, 가상 메모 리의 페이지와 컴퓨터 시스템의 메모리 컴포넌트들의 물리적 메모리의 페이지(또는 293) 사이의 맵핑 을 잠근다. 맵핑의 잠금은 메모리 모듈의 다른 어플리케이션들, 컴퓨팅 프로세스들, 운영 체제들 및/또는 데이터 오케 스트레이터가 가상 메모리의 페이지의 콘텍스트 외부에서 물리적 메모리의 페이지(또는 293)를 사용하는 것을 방지한다. 예를 들어, 맵핑이 잠기면, 가상 메모리의 페이지는 물리적 메모리의 페이지 (또는 293)에서 스와핑될 수 없으며; 가상 메모리의 다른 페이지는 물리적 메모리의 페이지(또는 293)으로 스와핑될 수 없다. 잠금은 가상 메모리의 페이지를 물리적 메모리의 페이지(또는 293)에 고정되도록 구성하거나, 가상 메모리의 페이지의 스와핑을 온-디맨드 기준으로 제한함으로써 구현될 수 있다. 맵핑의 잠금은 어플리케이 션에 대한 페이지의 할당에 응답하여, RDMA 동작에서 가상 메모리의 페이지의 사용에 응답하여, RDMA 데이터 전송을 시작하기 위한 RNIC에 대한 명령에 응답하여, 및/또는 RDMA 데이터 전송의 개시의 표 시에 응답하여 수행될 수 있다. 선택적으로, 컴퓨터 시스템의 호스트 시스템의 데이터 오케스트레이터는 원격 다이렉트 메모리 액세 스 동작 및/또는 RDMA 데이터 전송 후 가상 메모리의 페이지와 복수의 메모리 컴포넌트들 사이의 매핑을 자동으 로 잠금 해제할 수 있다. 잠금 해제는 가상 메모리의 페이지의 고정 속성 또는 온-디맨드 페이징 속성을 제거함으로써 구현될 수 있다. 예를 들어, 호스트 시스템의 데이터 오케스트레이터는 메모리 모듈을 위한 통지 에이전트 및/또는 메모리 장치 드라이버를 포함할 수 있다. 호스트 시스템의 데이터 오케스트레이터는 어플리 케이션에 결합된 통지 에이전트 및/또는 어플리케이션이 실행되고 있는 운영 체제(243/241)를 통해 RDMA 데이터 전송의 완료를 검출할 수 있다. 일부 경우, 데이터 오케스트레이터는 RDMA 데이터 전송 의 완료를 검출하기 위해 원격 다이렉트 메모리 액세스 드라이버(예를 들어, 286 또는 287)와 통신한다. 일부 경우, 호스트 시스템의 데이터 오케스트레이터는 어플리케이션이 실행되고 있는 가상 머신 을 호스팅하는 하이퍼바이저를 통해 데이터 전송의 완료를 검출한다. 예를 들어, 검출은 하이퍼바이 저에서 실행되는 원격 다이렉트 메모리 액세스 드라이버 및/또는 메모리 모듈을 위한 장치 드라 이버와의 통신과 관련하여 이루어질 수 있다. 선택적으로, 원격 다이렉트 메모리 액세스 네트워크 인터페이스 카드(RNIC)는 단일 루트 입/출력 가상화를 구현하여 물리적 기능 및 복수의 가상 기능들을 제공할 수 있다. 가상 머신의 RDMA 드라이버는 RNIC의 가상 기능에 액세스하는데 사용되며; 하이퍼바이저의 RDMA 드라이버는 RNIC의 물리 적 기능에 대한 액세스를 제어한다. 하이퍼바이저는 RDMA 데이터 전송 동안 가상 메모리의 페이지의 매핑을 잠그는 장치 드라이버를 포함할 수 있다. 메모리 모듈은 상이한 계층들의 메모리들을 가질 수 있다. 예를 들어, 메모리는 메모리보다 더 빠를 수 있고; 더 빠른 메모리는 휘발성 동적 랜덤 액세스 메모리일 수 있으며; 더 느린 메모리는 비 휘발성 교차점 메모리일 수 있다. 더 느린 메모리가 RDMA 데이터 전송을 지원하기에 충분히 빠를 경우, 컴 퓨팅 시스템은 페이지를 더 빠른 메모리의 페이지에 잠그는 대신, RDMA 데이터 전송 기간 동안 가상 메모리의 페이지를 더 느린 메모리의 페이지에 자동으로 잠글 수 있다. 예를 들어, RDMA 데이터 전송 직전에, 데이터 오케스트레이터는 가상 메모리의 페이지를 더 빠른 메 모리의 페이지로부터 더 느린 메모리의 페이지로 스와핑할 수 있고; 더 느린 메모리의 페이지을 사용하여 RDMA 데이터 전송이 이루어지며; RDMA 데이터 전송 후, 데이터 오케스트레이터(11 3)는 가상 메모리의 페이지를 (예를 들어, 워크로드 예측에 기초하여) 더 느린 메모리의 페이지(29 3)로부터 더 빠른 메모리의 페이지로 스와핑할 수 있다. 선택적으로, 메모리 모듈은 상이한 계층들의 메모리들(221, …, 223)에 걸친 예측 데이터 이동을 수행하도 록 구성된 컨트롤러를 가질 수 있다. 컨트롤러는 하기에 더 논의된 바와 같이, 인공 신경망을 사용하여 데이터 이동을 예측하는 필드 프로그램 가능 게이트 어레이(FPGA) 또는 어플리케이션별 집적 회로(ASIC)를 사용하여 데 이터 오케스트레이터를 구현할 수 있다. 데이터 오케스트레이터는 상이한 계층들의 메모리들, 더 빠른 메모리(예: 109A) 및 느린 메모리(예: 109 N)에 걸쳐 데이터 사용 및 이동을 예측할 수 있다. 어플리케이션들은 시퀀스들의 특정 데이터에 액세스할 수 있 으며; 특정 오브젝트들이 함께 사용될 수 있다. 따라서, 사용자 계정, 어플리케이션, 가상 시스템에서의 데이터 아이템의 사용은, 오브젝트의 일부로서, 다른 관련 데이터 아이템의 후속 사용의 표시일 수 있다. 관련 데이터 아이템이 액세스되기 전에, 메모리 서브 시스템의 데이터 아이템들의 물리적 저장 위치들을 재정렬하도록 컨트롤러에 지시할 수 있어, 데이터 오케스트레이터는 호스트 시스템의 프로세싱 장치가 관련 데이터 아이템에 액세스하는 시점에, 데이터 아이템이 이미 더 빠른 메모리(예: 109A)에 있도록 한다. 따 라서, 컴퓨팅 시스템의 동작 성능이 향상된다. 데이터 오케스트레이터의 예측 모델은 초기에는 이력 데이 터 액세스 기록들을 사용하여 오프라인으로 트레이닝된 다음 실시간 데이터 액세스 기록들을 사용하여 실시간 사용으로 지속적으로 트레이닝될 수 있는 인공 신경망을 통해 구현될 수 있다. 일 예에서, 중앙 처리 유닛(CPU)은 CPU에 연결된 하나 이상의 메모리 시스템들에 제공된 두 메모리 세트들에 액 세스될 수 있다. 예를 들어, 한 메모리 세트는 다른 메모리 세트보다 더 느릴 수 있으며; 중앙 처리 유닛(CPU) 는 페이징 기술을 사용하여 더 빠른 메모리 세트를 통해 더 느린 메모리 세트에 액세스하도록 구성될 수 있다. 더 빠른 메모리 세트는 더 느린 메모리 세트의 캐시 메모리로 사용될 수 있다. 예를 들어, 한 메모리 세트는 CPU에 의해 직접 어드레스할 수 없고, CPU에 의해 직접 어드레스할 수 있는 다른 메모리 세트에 결합되며; 중앙 처리 유닛(CPU)은 페이징 기술의 사용과 유사한 방식으로 직접 어드레스할 수 있는 메모리 세트를 통해 직접 어 드레스할 수 없는 메모리 세트에 액세스하도록 구성될 수 있다. 직접 액세스될 수 없는 메모리 세트는 직접 평 가될 수 없는 메모리 세트의 캐시 메모리로 사용될 수 있다. 더 빠른 메모리는 더 느린 메모리의 캐시로 사용될 대, 더 빠른 메모리에 저장된 데이터는 더 느린 메모리에 대 응되는 사본을 갖는다. 더 빠른 메모리가 변경되면, 더 느린 메모리에 대응되는 사본은 쓸모 없게 된다. 더 빠 른 메모리의 변경된 콘텐트는 업데이트를 위해 더 느린 메모리로 플러시(flushed)되어야 한다. 대안으로, 더 느린 메모리의 콘텐트는 일부 경우 더 빠른 메모리를 거치지 않고 액세스도리 수 있으며; 더 빠른 메모리의 콘텐트는 더 느린 메모리에 대응되는 사본을 가질 수 없다. 더 느린 메모리와 더 빠른 메모리의 콘텐 츠 분포는 현재 워크로드의 동작 성능을 최적화하기 위해 동적으로 변경될 수 있다. 이러한 상황에서, 더 빠른 메모리는 여전히 캐시 히트율을 추적하기 위한 캐시로 간주될 수 있다. 예를 들어, 액세스 중인 데이터 아이템 이 더 빠른 메모리에서 서비스되는 경우, 캐시 히트가 카운팅되며; 액세스 중인 데이터 아이템이 더 느린 메모 리에서 서비스되는 경우, 캐스 미스가 카운팅된다. 일부 경우, 메모리 가상화는 서로 다른 계층들의 메모리들에 대한 메모리 액세스를 가상화하여 어플리케이션들 및/또는 가상 머신들로부터 메모리 컴포넌트들(109A 내지 109N)의 차이를 쉴드(shield)하기 위해 메모리 컴포넌 트의 장치 드라이버에서 구현될 수 있다. 메모리 가상 장치는 컴퓨팅 시스템의 성능을 최적화하기 위해 서로 다 른 계층들의 메모리들에 걸쳐 데이터 저장 위치들을 자동으로 조정한다. 메모리 가상 장치들의 일부 세부사항들 및 예들은 2018년 8월 3일자로 출원된, \"Memory Virtualization for Accessing Heterogeneous Memory Components\" 명칭의 미국 특허 출원 일련 번호 제16/054,719호에서 찾아볼 수 있다. 액세스 중인 데이터 아이템이 더 느린 메모리 세트에 있지만 더 빠른 메모리 세트에 있지 않은 경우, 데이터 아 이템은 더 느린 메모리 세트에서 직접 액세스되거나, 더 빠른 메모리 세트에 액세스하기 위해 더 빠른 메모리 세트로 스와핑되거나, 더 빠른 메모리 세트에 캐시될 수 있다. 데이터 아이템에 액세스하는 워크로드가 데이터 오케스트레이터에 의해 예측되는 경우, 데이터 오케스트레이터는 데이터 액세스 전에 데이터 아이템 을 더 빠른 메모리 세트로 스와핑하거나 데이터 아이템을 더 빠른 메모리 세트에 캐시하도록 컨트롤러에 지시한다. 데이터 이동이 워크로드 예측에 따라 수행된 후, 데이터 아이템이 액세스될 때 데이터 액세스는 더 빠른 메모리 세트로부터 서비스될 수 있다. 데이터 액세스가 더 빠른 메모리 세트로부터 서비스되기 때문에, 데 이터 액세스를 완료하는 시간은 더 느린 메모리 세트로부터 서비스되거나, 서비스를 위해 더 빠른 메모리 세트로 스와핑되거나, 캐싱한 다음 서비스하기 위해 더 느린 메모리 세트로부터 더 빠른 메모리 세트로 데이터를 로 딩하는 것보다 더 짧다. 예를 들어, 액세스 중인 가상 메모리의 페이지가 현재 더 느린 메모리 세트에는 있지만 더 빠른 메모리 세트에 는 없는 경우, 페이지는 더 느린 메모리 세트에서 페이지를 서비스하기 위해 더 빠른 메모리 세트로부터 할당될 수 있으며; 페이지의 데이터는 더 느린 메모리 세트로부터 페치되고 더 빠른 메모리 세트의 할당된 페이지에 저 장되어, 가상 메모리의 페이지의 데이터 액세스가 후속 동작들에서 더 빠른 메모리 세트의 할당된 페이지에 액 세스하는 것을 통해 이루어질 수 있도록 한다. 일부 경우, 페이지 스와핑은 더 느린 메모리에서 단순히 요청된 데이터 요소에 액세스하는 것보다 더 오랜 시간 이 걸린다. 따라서, 요청된 데이터 요소는 요청자에게 먼저 서비스되며, 페이지 스와핑은 핫 페이지의 데이터 요소들에 대한 후속 액세스 속도를 높이기 위해 수행된다. 따라서, 전반적인 성능은 페이지 스왑이 완료될 때까 지 데이터 요소에 대한 요청을 홀딩하는 것보다 더 낫다. 또한, 더 느린 메모리 세트의 페이지들의 사용과 관련된 정보는 페이지들의 사용을 예측하는 자가 학습(self- learning) 예측 엔진을 트레이닝시키는 데 사용될 수 있다. 예를 들어, 감독된 기계 학습 기법은 상기 정보를 사용하여, 예측들과 페이지들의 실제 사용 사이의 에러들을 줄임으로써 더 느린 메모리 세트에서 페이지들의 사 용을 예측하기 위한 인공 신경망을 트레이닝시키는데 사용될 수 있다. 인공 신경망의 트레이닝 이후, 예측 엔진 은 현재 정보를 사용하여 사용될 다음 페이지들을 예측할 수 있다. 또한, 추가 트레이닝을 위한 예측에 따른 실 제 사용으로부터의 트레이닝, 예측 및 피드백은 인공 신경망의 예측 모델을 가장 최근의 메모리 페이지 사용 패 턴들에 적응시키기 위해 지속적인 방식으로 수행될 수 있다. 더 느린 메모리 세트의 페이지를 곧 사용할 것이라는 메모리 사용 예측에 응답하여, 데이터 오케스트레이터 는 더 느린 메모리 세트에서 더 빠른 메모리 세트로 데이터 페이지를 선제적으로 스왑하거나 캐시하도록 컨트롤러에 지시하여, 처리에 필요한 경우, 데이터의 페이지가 이미 더 빠른 메모리 세트에 있도록 하며, 이 배치는 데이터 페이지의 데이터 액세스 속도를 향상시킨다. 예측의 정확도는 이후의 실제 페이지 사용에 대해 측정될 수 있으며; 예측 및 이후의 실제 페이지 사용은 메모 리 페이지들의 가장 최근의 사용 패턴들을 추적하기 위해 인공 신경망을 더 트레이닝시키거나 조정하는 데 사용 될 수 있다. 대안으로 또는 조합하여, 기계 학습 기반 예측은 정책 기반 예측 규칙들로 대체되거나 강화될 수 있다. 예를 들 어, 주민 코드들을 저장하는 페이지들(예: 낮은 어드레스들)은 자주 사용되는 페이지들의 스와핑을 줄이기 위해 가능한 한 더 빠른 메모리 세트에 유지될 수 있다. 예를 들어, 거대한 페이지는 거대한 페이지의 일부인 페이지 가 액세스되고 있을 때 더 빠른 메모리 세트에 로딩될 수 있다. 예를 들어, 예측들은 페이지들이 순차적으로 또 는 랜덤으로 액세스되는지 여부, 데이터 액세스가 안정적인 상태 모드인지 또는 버스트 모드인지 여부, 및/또는 페이지들(및 크기가 다른 페이지들) 간의 논리적 관계와 같은 표시들에 기초하는, 휴리스틱 규칙들을 적어도 부 분적으로 사용하여 이루어질 수 있다. 예측 기술들에 대한 일부 세부사항들 및 예들은 2018년 7월 11일자로 출원된, \"Predictive Paging to Accelerate Memory Access\" 명칭의 미국 특허 출원 일련 번호 제16/032,331호에서 찾아볼 수 있다. 도 6은 본원에 개시된 적어도 일부 실시예들에 따른 데이터 위치들을 최적화하기 위해 상이한 계층의 메모리 및 데이터 오케스트레이터를 갖는 컴퓨팅 시스템을 도시한다. 도 6의 컴퓨팅 시스템은 호스트 시스템, 메모리 버스를 통해 호스트 시스템에 연결된 메모리 모 듈 및 인터커넥트를 통해 메모리 모듈에 연결된 저장 장치를 포함한다. 저장 장치 및 /또는 메모리 모듈은 도 1에 예시된 메모리 서브 시스템의 예들이다. 호스트 시스템은 하나 이상의 프로세싱 코어들을 갖는 중앙 처리 유닛 또는 마이크로프로세서일 수 있는 프로세싱 장치를 갖는다. 호스트 시스템은 메모리 관리 유닛 및 캐시 메모리를 가질 수 있 다. 메모리 관리 유닛 및/또는 캐시 메모리의 적어도 일부는 프로세싱 장치의 동일한 집적 회로 패키지 내에 선택적으로 통합될 수 있다. 도 6에 예시된 메모리 모듈는 여러 유형의 메모리들(예: 221 및 223)을 갖는다. 예를 들어, 타입 A 메모리 는 타입 B 메모리보다 더 빠르다. 예를 들어, 메모리 버스는 이중 데이터 레이트 버스일 수 있으며; 인터커넥트는 PCIe(peripheral component interconnect express) 버스, SATA(serial advanced technology attachment) 버스, USB(universal serial bus) 버스 및/또는 저장 영역 네트워크 일 수 있다. 메모리 모듈의 타입 B 메모리는 저장 장 치의 타입 B 메모리에 액세스하는 것보다 빠른 속도로 액세스될 수 있다. 도 6에 예시된 저장 장치는 여러 유형의 메모리(예: 223 및 225)를 갖는다. 예를 들어, 메모리 타입 B는 메모리 타입 C보다 빠르다. 일반적으로, 다수의 메모리 모듈들(예: 205)은 메모리 버스에 결합될 수 있으며; 다수의 저장 장치들(예: 209)은 주변 장치 인터커넥트에 결합될 수 있다. 일부 경우, 주변 장치 인터커넥트 및 저장 장치들 (예: 209)은 선택적이며 컴퓨팅 시스템에는 없을 수 있다. 다른 경우, 메모리 버스 및 메모리 모듈들(예: 205)은 선택적이며 컴퓨팅 시스템에는 없을 수 있다. 다수의 메모리 모듈들(예: 205)이 메모리 버스에 결합 시 가능한 구성에서, 메모리 모듈들(예: 205) 중 하 나는 타입 A 메모리를 가지며; 다른 메모리 모듈들은 별도의 메모리 모듈(예: 205)의 타입 A 메모리 보다 낮은 속도로 액세스 가능한 타입 B 메모리를 갖는다. 마찬가지로, 인터커넥트에 다수의 저장 장치들(예: 205)이 결합되었을 때 가능한 구성에서, 저장 장치(예: 209) 중 하나는 타입 B 메모리를 가지며, 다른 저장 장치는 개별 저장 장치(예: 209)의 타입 B 메모리 보다 낮은 속도로 액세스할 수 있는 타입 C 메모리를 갖는다. 프로세싱 장치 및/또는 MMU는 페이징 기술 및/또는 메모리 맵 인터페이스를 사용하여 컴퓨터 시스템 의 메모리의 다른 부분을 통해 컴퓨터 시스템의 메모리의 일부에 액세스하기 위한 인스트럭션들(예를 들어, 운 영 체제 및/또는 하나 이상의 장치 드라이버들)을 통해 구성된다. 예를 들어, 메모리 모듈의 타입 B 메모리는 메모리 모듈(또는 다른 메모리 모듈)의 타입 A 메모 리에 액세스될 수 있다. 예를 들어, 저장 장치(예: 209)의 타입 B 메모리는 메모리 모듈의 타입 A 메모리 및/또는 메모 리 모듈의 타입 B 메모리를 통해 액세스될 수 있다. 예를 들어, 저장 장치의 타입 C 메모리는 메모리 모듈의 타입 A 메모리를 통해, 메모리 모 듈의 타입 B 메모리를 통해 및/또는 저장 장치(또는 다른 저장 장치)의 타입 B 메모리를 통해 액세스될 수 있다. 예를 들어, 일부 경우, 동일한 메모리 모듈(또는 다른 메모리 모듈들)의 타입 A 메모리 및 타입 B 메 모리는 프로세싱 장치의 메모리 관리 유닛에 의해 메모리 버스를 통해 직접적으로 그리고 개별적으로 액세스할 수 있다. 그러나, 타입 B 메모리는 타입 A 메모리보다 느리기 때문에, 타입 A 메모리를 통해 타입 B 메모리에 액세스하는 것이 바람직하다. 다른 경우, 메모리 모듈의 타입 B 메모리는 (예를 들어, 메모리 버스의 어드레스 부분에서의 크 기 제한으로 인해) 메모리 모듈의 타입 A 메모리를 어드레싱하는 것을 통해서만 액세스 가능하다. 데이터 오케스트레이터는 특히, 메모리 모듈의 타입 B 메모리가 메모리 버스를 사용하여 직접 어드레스할 수 없을 경우, 메모리 모듈 내의 타입 A 메모리와 타입 B 메모리 사이에서 데 이터 전송/이동을 수행하도록 메모리 모듈의 컨트롤러 X에 지시할 수 있다. 또한, 데이터 오케스트레이터는 저장 장치의 컨트롤러 Y와 통신하여 저장 장치의 메모리들 (223 내지 225) 사이 및/또는 저장 장치와 메모리 모듈 사이의 데이터 전송/이동을 수행하도록 메모 리 모듈의 컨트롤러 X에 지시할 수 있다. 일 변형예에서, 메모리 모듈의 메모리(예: 221 및 223)는 메모리 모듈 내에 개별적으로 동일한 성은 을 가질 수 잇다. 그러나, 메모리 관리 유닛 및/또는 프로세싱 장치는 메모리를 통해 메모리 를 통한 액세스하는 것이 (예를 들어, 메모리 버스의 어드레스 부분의 크기 제한으로 인해) 제한된다. 따라서, 메모리는 프로세싱 장치에 대한 메모리보다 느린 것으로 보인다. 일반적으로, 메모리 서브 시스템들(예: 205 및 209)은 메모리(예를 들어, 221, …, 223, …, 225)와 같은 매체 를 포함할 수 있다. 메모리(예를 들어, 221, …, 223, …, 225)는 휘발성 메모리, 비휘발성 메모리(NVM) 및/또 는 이들의 조합을 포함할 수 있다. 일부 실시예들에서, 컴퓨터 시스템은 저장 장치인 적어도 하나의 메모 리 서브 시스템을 포함한다. 저장 장치의 예는 솔리드 스테이트 드라이브(SSD)이다. 일부 실시예들에서,컴퓨터 시스템은 메모리 모듈로서 구성된 하이브리드 메모리/저장 시스템인 적어도 하나의 메모리 서브 시 스템을 포함한다. 프로세싱 장치는 메모리 서브 시스템들(예: 205 및 209) 각각에 데이터를 기록하고, 메 모리 서브 시스템들(예: 205 및 209)로부터 직접 또는 간접적으로 데이터를 판독할 수 있다. 도 6의 컴퓨팅 시스템은 데스크탑 컴퓨터, 랩탑 컴퓨터, 네트워크 서버, 모바일 장치 또는 메모리와 프로세싱 장치를 포함하는 이러한 컴퓨팅 장치를 구현하는 데 사용될 수 있다. 프로세싱 장치는 메모리 서브 시스템 들(예: 205 및 209)로부터 데이터를 판독하고 이에 데이터를 기록할 수 있다. 일부 경우, 인터커넥트는 메모리 모듈 및/또는 메모리 버스를 거치지 않고 호스트 시스템 에 연결된다. 저장 장치가 메모리 모듈을 거치지 않고 호스트 시스템에 결합될 경우(예를 들어, 도 2에 예시된 바와 같이), 데이터 오케스트레이터는 메모리 모듈의 데이터 오케스트레이터와 유사한 방식으로 저장 장치에 구현될 수 있다. 일부 경우, 데이터 오케스트레이터는 호스트 시스템에 적어도 부분적으로 구현될 수 있다. 도 7은 데이터 오케스트레이터를 갖는 시스템을 도시한다. 예를 들어, 도 7의 시스템은 도 1, 2, 3, 4 또 는 6의 컴퓨터 시스템에 구현될 수 있다. 도 7의 시스템은 도 1, 2, 3, 4 또는 6의 컴퓨터 시스템의 프로세싱 장치에서 실행될 수 있는 호스트 운영 체제를 포함한다. 호스트 운영 체제는 메모리 모듈 및/또는 저장 장치와 같은 메모리 서브 시스템들의 메모리(예를 들어, 221, …, 223, …, 225)를 사용하여 메모리 서비스들을 제공하는 하나 이상의 장 치 드라이브들을 포함한다. 호스트 운영 체제는 가상 머신를 프로비저닝하는 하이퍼바이저를 포함한다. 가상 머신는 도 1, 2, 3, 4 또는 6의 컴퓨팅 시스템의 하드웨어를 사용하여 호스트 운영 체제에 의해 제공되는 리소스 들 및 서비스들을 통해 구현되는 가상 하드웨어를 갖는다. 예를 들어, 하이퍼바이저는 메모리 모듈 및/또는 저장 장치와 같은, 메모리 서브 시스템들의 메모리(예를 들어, 221, …, 223, …, 225)의 일부를 사용하여 가상 머신의 일부로서 가상 메모리를 프로비저닝할 수 있다. 가상 머신은 게스트 운영 체제가 가상 머신에서의 프로비저닝과 동일하거나 유사한 하드웨어 세트를 갖는 물리적 컴퓨팅 시스템에서 실행되는 운영 체제와 같은 방식으로, 게스트 운영 체제에서 실행되 는 어플리케이션들(예를 들어, 251, …, 253)에 리소스들 및/또는 서비스들을 제공하도록 한다. 하이퍼바이저 는 가상 머신에서 프로비저닝된 가상 하드웨어와 호스트 운영 체제에 의해 관리되는 컴퓨팅 시스템의 하드웨어의 서비스들 사이의 매핑을 관리한다. 도 7은 가상 머신이 하이퍼바이저에 의해 프로비저닝되는 경우를 예시한다. 일반적으로, 하이퍼바이 저는 동일한 게스트 운영 체제 또는 다른 게스트 운영 체제(예: 243)를 실행할 수 있는 복수의 가상 머신들(예: 249)을 프로비저닝할 수 있다. 다른 사용자 세트들 및/또는 어플리케이션 프로그램들은 다른 가상 머신들을 사용하도록 할당될 수 있다. 일부 경우, 호스트 운영 체제는 가상 머신들을 프로비저닝하기 위한 서비스들을 제공하도록 특화되며, 다 른 어플리케이션 프로그램들을 실행하지 않는다. 대안으로, 호스트 운영 체제는 어플리케이션들(예를 들어, 251, …, 253)과 같은 다른 어플리케이션 프로그램들을 지원하기 위한 추가 서비스들을 제공할 수 있다. 도 7에서, 하이퍼바이저는 단일 루트 I/O 가상화를 사용하여 서로 다른 특성들/속성들의 데이터 스트림을 구성하도록 구성된다. 예를 들어, 메모리 모듈은 다수의 가상 기능들(예: 247)을 구현할 수 있는 물리적 기능을 갖는다. 가상 기능은 물리적 기능을 통해 메모리 모듈의 서비스를 제공한다. 하이 퍼바이저는 특정 가상 머신, 특정 어플리케이션(예를 들어, 251 또는 253), 특정 사용자 계정 등에 의한 메모리 액세스를 위해 가상 기능을 할당하고 예약한다. 따라서, 메모리 모듈에 액세스하는 데 사용되는 가상 기능의 식별정보는 가상 머신, 어플리케이션 및/또는 가상 기능을 사용하여 이루어진 데이터 액세스와 관련되거나 담당하는 사용자 계정의 식별정보들과 같은, 데이터 액세스에 대한 데이 터 사용 정보를 추론하는 데 사용될 수 있다. 이러한 정보는 기계 학습의 데이터 오케스트레이터에서 사용 되어 데이터 워크로드 및/또는 이동을 예측하고 실시간 예측을 할 수 있다. 예를 들어, 데이터 오케스트레이터는 데이터 아이템이 가상 머신, 가상 시스템에서 실행되는 어플리 케이션 및/또는 어플리케이션을 운영하는 사용자 계정에 의한 사용을 위해 실제로 요청되기 전에 더 느린 메모리에서 데이터 아이템의 사용을 예측하고 데이터 아이템을 더 빠른 메모리로 로드하도록 트레이닝될수 있다. 예측은 아이템을 사용하려는 요청이 메모리 모듈에 도달하기 전에 데이터 아이템을 사용하기 위 한 요청과 아이템을 더 빠른 메모리로 로딩, 전송 및/또는 캐싱함으로써 더 빠른 메모리에 있는 아이템의 이용 가능성 사이의 시간을 줄이며, 이는 페이지의 데이터 액세스를 가속화한다. 예를 들어, 더 느린 메모리는 메모리 모듈의 메모리일 수 있고, 더 빠른 메모리는 동일한 메모리 모 듈(또는 메모리 모듈과 동일한 메모리 버스에 연결된 다른 메모리 모듈)의 메모리일 수 있 다. 예를 들어, 더 느린 메모리는 저장 장치의 메모리일 수 있으며; 더 빠른 메모리는 메모리 모듈 의 동일한 타입의 메모리이거나, 메모리 모듈의 메모리일 수 있다. 예를 들어, 더 느린 메모리는 저장 장치의 메모리일 수 있으며; 더 빠른 메모리는 동일한 저장 장치 의 메모리이거나, 인터커넥트에 연결된 다른 저장 장치이거나, 메모리 모듈의 메모리(예를 들어, 223 또는 221)일 수 있다. 바람직하게는, 예측 데이터 이동은 메모리 버스 및/또는 인터커넥트와 같은 프로세싱 장치에 연 결된 통신 채널의 정체를 피하거나 감소시키기 위해, 동일한 메모리 모듈, 동일한 저장 장치 또는 메 모리 모듈과 저장 장치의 동일한 조합과 같은, 동일한 메모리 서브 시스템 내에서 수행된다. 예를 들 어, 예측 데이터 이동은 데이터 오케스트레이터로부터의 하나 이상의 명령, 요청 또는 인스트럭션에 응답 하여 메모리 모듈의 컨트롤러의 제어 하에서, 데이터를 메모리 모듈의 더 느린 메모리로부 터 메모리 모듈의 더 빠른 메모리로 복사하도록 수행될 수 있다. 예를 들어, 예측 데이터 이동은 데 이터 오케스트레이터로부터의 하나 이상의 명령, 요청 또는 인스트럭션에 응답하여 저장 장치의 컨트 롤러의 제어 하에서, 데이터를 저장 장치의 더 느린 메모리로부터 저장 장치의 더 빠른 메 모리로 복사하도록 수행될 수 있다. 예를 들어, 예측 데이터 이동은 데이터 오케스트레이터로부터의 하나 이상의 명령, 요청 또는 인스트럭션에 응답하여, 컨트롤러 및 저장 장치의 컨트롤러의 제 어 하에서, 데이터를 저장 장치로부터 메모리 모듈로 복사하도록 수행될 수 있다. 일 실시예에서, 하이퍼바이저는 장치 드라이버에게 메모리 서브 시스템(예: 메모리 모듈 또는 저장 장치)의 메모리(예: 221, …, 223, … 또는 225)에 액세스할 것을 요청할 뿐만 아니라, 장치 드라이버에게 메모리(예: 221, …, 223 또는 225) 내의 어느 데이터 아이템들이 후속 기간에 사용될 가능성이 높은 지 그리고 메모리(예: 메모리(예를 들어, 221, …, 223, … 또는 225)) 내의 어느 데이터 아이템들이 후속 시간 기간에 사 용되지 않을 가능성이 높은 지의 예측들을 수행하는 데 사용될 수 있는 정보를 제공한다. 정보는 가상 머신 , 어플리케이션, 사용자 계정 등과 같은 특정 데이터 사용 속성들과 사전 연관된 가상 기능들(예: 247)의 사용을 통해 적어도 부분적으로 제공될 수 있다. 예를 들어, 사용될 가능성이 높은 페이지는 핫(hot) 페이지로 지칭될 수 있으며; 사용되지 않을 가능성이 높은 페이지는 콜드(cold) 페이지로 지칭될 수 있다. 후속 시간 기간에 페이지가 사용될 가능성은 페이지의 온도로 지칭될 수 있다. 데이터 오케스트레이터는 하이퍼바이저에 의해 제공/식별된 정보를 사용하여 페이지 들의 온도들을 예측하고, 콜드 페이지들을 더 빠른 메모리에서 더 느린 메모리로 이동시키고, 핫 페이지들을 더 느린 메모리에서 더 빠른 메모리로 이동시켜 메모리(예를 들어, 221, …, 223, … 또는 225)의 페이지들의 분포 를 최적화하고 데이터 액세스를 가속화시킨다. 예측들을 하기 위해 하이퍼바이저에 의해 제공되고 데이터 오케스트레이터에 의해 사용된 정보의 예 들은, 이전 기간에 사용되는 페이지들의 시퀀스들, 더 느린 메모리에서 더 빠른 메모리로 페이지들을 로드하기 위한 요청들의 인스턴스들, 페이지들의 콘텐트 속성들, 페이지들의 소유권 속성들, 페이지들의 사용자들 또는 어플리케이션들의 식별정보들, 페이지들이 가상 머신 및/또는 사용자 계정에서 순차적 모드로 액세스되는지 여 부의 표시, 페이지 액세스들이 안정 상태에 있는지 여부의 표시, 사용된 페이지가 거대한 페이지와 연관되는지 의 표시, 데이터 블록들과 오브젝트들 사이의 맵핑 등을 포함한다. 도 8은 데이터 오케스트레이터의 구현예를 예시한다. 도 8에서, 데이터 오케스트레이터는 캐시 컨트롤러 및 워크로드 인식기를 포함한다. 워크로드 인식기는 인공 신경망을 사용하여 구현될 수 있는 예측 모델을 포함한다. 캐시 컨트롤러는 호스트 시스템으로부터의 데이터 액세스 요청들을 처리한다. 캐시 컨트롤러 는 낮은 성능의 메모리에 대해 캐시로 사용되는 고성능 메모리를 모니터링하고, 캐시의 사용량을 분석하고, 캐시 사용량을 최적화하고, 캐시의 사용을 관리한다. 종래 캐시 기술들은 캐시 컨트롤러에서 구현될 수 있다. 데이터 액세스 요청들에 응답하여, 캐시 컨트롤러는 요청들에 의해 대상이 되는 데이터가 요청 들의 시점에 고성능 메모리에 있는지를 결정한다. 그렇다면, 캐시 컨트롤러는 대응되는 데이터 액세 스 요청들을 캐시 히트로 카운팅한다. 그렇지 않은 경우, 캐시 컨트롤러는 대응되는 데이터 액세스 요청들을 캐시 미스로 카운팅한다. 따라서, 캐시 컨트롤러는 데이터 액세스 요청들의 시점에 데 이터 분포에 대한 캐시 히트율의 측정을 생성할 수 있다. 선택적으로, 캐시 컨트롤러은 대응되는 데이터를 더 높은 성능의 메모리에 캐싱/로딩하지 않고 더 낮은 성 능의 메모리로부터 직접 데이터 액세스 요청들의 일부를 서비스할 수 있다. 캐시 컨트롤러에 사용된 캐시 정책은 캐시 컨트롤러에 의해 구현되는 데이터 이동(data movements)을 식별하는 데 사용될 수 있다. 데이터 액세스 요청들에 대응되는 데이터 사용 정보는 예측 모델의 트레이닝을 위한 컴퓨팅 시 스템 운용의 초기 기간 동안 수집된다. 예를 들어, 감독된 기계 학습 기술은 데이터 액세스 요청들에 응답 하여 캐시 컨트롤러에 의해 구현되는 데이터 이동과 데이터 액세스 요청들에 대응되는 데이터 사용 정보를 사용한 예측 모델을 사용하여 예측된 데이터 이동 사이의 차이를 최소화하기 위해 예측 모델의 인공 신경망을 트레이닝시키는 데 사용될 수 있다. 기계 학습은 초기 예측 모델을 확립 하기 위해 다른 컴퓨팅 장치 상에서 오프라인으로 수행될 수 있다. 이후, 예측 모듈은 실시간 데이터 사용 정보 및 실시간 데이터 액세스 요청들에 기초하여 데이 터 이동의 실시간 예측을 하기 위한 워크로드 인식기에 사용될 수 있다. 워크로드 인식기는 캐 쉬 히트율에 변화를 일으킬 수 있는 예측 데이터 측정을 수행하도록 캐시 컨트롤러에 지시한다. 예측 모델는 캐시 히트율을 지속적으로 상승시키기 위해 하이브리드 강화 기계 학습 기술을 사용하여 실시 간으로 조정 및/또는 트레이닝된다. 따라서, 예측 모델은 캐시 컨트롤러만을 통해 달성될 수 있는 것 보다 더 높은 캐시 히트율을 달성하기 위해 컴퓨팅 시스템의 현재 워크로드에 자동으로 적응하고 예측 데 이터 이동을 구현할 수 있다. 바람직하게는, 워크로드 인식기에 의해 이루어진 예측들은 블록 대 오브젝트 맵에 적어도 부분적으로 기초한다. 데이터 사용 정보의 통계적 분석을 위해, 데이터 오케스트레이터는 데이터 블록들 간의 기 본 관계들을 식별할 수 있다. 예를 들어, 일부 데이터 블록들은 어플리케이션에서 동일한 데이터 오브젝트의 부 분들을 나타낸다; 데이터 객체들의 부분들이 함께 액세스된다; 일부 데이터 오브젝트들은 특정 순서로 액세스되 는 패턴을 갖는다; 가상 머신에서 어플리케이션을 실행하는 사용자 계정에서의 하나의 데이터 오브젝트에 대한 액세스는 다른 데이터 오브젝트에 대한 액세스로 이어질 가능성이 높을 수 있다. 블록 대 오브젝트 맵은 워크로드 인식기의 예측 정확도를 향상시키는 관계들을 식별한다. 도 9는 예측 데이터 오케스트레이션의 방법을 도시한다. 도 9의 방법은 하드웨어(예: 프로세싱 장치, 회로부, 전용 로직, 프로그램 가능 로직, 마이크로코드, 장치의 하드웨어, 집적 회로 등), 소프트웨어(예: 프로세싱 장 치에서 실행되거나 수행된 인스트럭션들) 또는 이들의 조합을 포함할 수 있는 프로세싱 로직에 의해 수행될 수 있다. 일부 실시예들에서, 도 9의 방법은 도 1 내지 8의 데이터 오케스트레이터에 의해 적어도 부분적으로 수행된다. 특정 시퀀스 또는 순서로 도시되어 있지만, 달리 명시되지 않는 한, 프로세스들의 순서는 수정될 수 있다. 따라서, 예시된 실시예들은 단지 예들로서 이해되어야 하고, 예시된 프로세스들은 상이한 순서로 수행될 수 있으며, 일부 프로세스들은 병행하여 수행될 수 있다. 추가로, 하나 이상의 프로세스들은 다양한 실시예들에 서 생략될 수 있다. 따라서, 모든 프로세스들이 모든 실시예에서 필요한 것은 아니다. 다른 프로세스 흐름들이 가능하다. 예를 들어, 도 9의 방법은 도 7의 호스트 운연 체제 및 도 8의 예측 모델과 함께 도 1, 2, 3, 4 또는 6의 컴퓨팅 시스템에서 구현될 수 있다. 예를 들어, 데이터 오케스트레이터는 캐시 컨트롤러 및 도 8 의 워크로드 인식기 및/또는 도 7의 가상 기능을 통해 적어도 부분적으로 구현될 수 있다. 블록에서, 데이터 오케스트레이터은 프로세싱 장치로부터, 계층들에 걸쳐 제1 데이터 이동을 야 기하는 제1 데이터 액세스 요청들을 수신한다. 예를 들어, 상이한 계층들의 메모리 컴포넌트들(예를 들어, 도 1의 109A 내지 109N, 도 7의 221 내지 223 및/또 는 내지 225)은 제1 메모리 및 제2 메모리를 가질 수 있으며, 여기서 제1 메모리는 제2 메모리의 캐시로 기능한 다. 예들 들어, 제1 메모리는 휘발성 동적 랜덤 액세스 메모리일 수 있으며; 제2 메모리는 비휘발성 교차점 메모리일 수 있다. 일부 경우, 제1 메모리 및 제2 메모리는 메모리 모듈 또는 저장 장치와 동일한 메모 리 서브 시스템에 하우징된다. 다른 경우, 제1 메모리 및 제2 메모리는 호스트 시스템 및/또는 메모리 버 스를 포함하지 않고 서로 통신할 수 있는 별도의 동일한 메모리 서브 시스템에 하우징될 수 있다. 프로세싱 장치이 제2 메모리에 액세스될 때, 액세스 요청들은, 제1 메모리에서, 액세스중인 제2 메모리의 일부의 캐싱을 발생시킨다. 다른 경우, 제1 메모리는 제2 메모리의 캐시로 기능하지 않으며; 제2 메모리에 있는 데이터 아이템에 액세스하기 위한 요청에 응답하여, 데이터 오케스트레이터는 정책 또는 규칙 세트에 기초 하여, 데이터 아이템의 저장 위치를 제2 메모리에서 제1 메모리로 변경할 것인지를 결정하며; 만약 그렇다면, 데이터 오케스트레이터는 데이터 아이템을 제2 메모리에서 제1 메모리로 스와핑할 수 있다. 블록에서, 데이터 오케스트레이터는 제1 데이터 액세스 요청들에 응답하여 제1 데이터 이동을 수행한 다. 예를 들어, 제1 데이터 액세스 요청들에 응답하여 수행/구현된 제1 데이터 이동은 제1 데이터 액세스 요청들과 관련된 데이터 사용 정보와 관련하여 기록될 수 있다. 예를 들어, 데이터 사용 정보는 일정 기간에 사용중인 데 이터 블록의 시퀀스, 제2 메모리에서 제1 메모리로 데이터를 로딩하기 위한 요청들의 인스턴스들, 제2 메모리에 서 제1 메모리로 로딩된 데이터 블록들의 콘텐트 속성들, 제2 메모리에서 제1 메모리로 로딩된 데이터 블록들의 소유권 속성들, 제2 메모리에서 제1 메모리로 로딩된 데이터 블록들의 사용자들의 식별정보들, 제2 메모리에서 제1 메모리로 로딩중인 데이터 블록들을 야기하는 어플리케이션들의 식별정보들, 가상 머신에서 순차적 모드로 액세스되는 데이터 블록들의 식별정보, 사용자 계정의 순차적 모드로 액세스되는 데이터 블록들의 식별정보, 및 /또는 안정 상태에 있는 데이터 액세스들의 식별정보를 식별할 수 있다. 제1 데이터 이동은 제1 데이터 액세스 요청들과 관련된 데이터 사용 정보를 사용하여 예측들을 수행하는 예측 모델의 원하는 예측 결과들로 사용될 수 있다. 예를 들어, 예측 모델은 제1 데이터 이동과 제1 데이 터 액세스 요청들과 관련된 데이터 사용 정보를 사용하여 이루어진 예측들 사이의 차이를 줄이기 위해 감독된 기계 학습 기술을 사용하여 트레이닝될 수 있는 인공 신경망을 갖는다. 인공신경망의 초기 트레이닝은 별도의 컴퓨터 및 제1 데이터 액세스 요청들에 대한 기록된 정보, 제1 데이터 액세스 요청들에 의해 야기된 제1 데이터 이동, 및 제1 데이터 액세스 요청들 전 데이터 사용 정보를 사용하여 오프라인에서 선택적으로 수행될 수 있다. 예를 들어, 데이터 오케스트레이터는 데이터 오케스트레이터에 의해 제어되는 메모리의 일부에 기록 된 정보를 저장할 수 있으며; 다른 프로세싱 장치는 데이터 오케스트레이터에 대한 추기 트레이닝을 수행하기 위해 메모리의 일부에 액세스할 수 있다. 대안으로, 인공 신경망의 초기 트레이닝은 예측 모델의 예측 정확도가 임계 레벨에 도달할 때까지 데이터 오케스트레이터에서 수행될 수 있다. 블록에서, 메모리 서브 시스템(예를 들어, 메모리 모듈 및/또는 저장 장치)은 제1 데이터 이동 후 제1 데이터 액세스 요청들을 서비스한다. 컴퓨팅 시스템의 성능은 데이터 이동을 예측하고 대응되는 데 이터 액세스 요청들 전에 예측된 데이터 이동을 수행함으로써 개선될 수 있다. 블록에서, 데이터 오케스트레이터는 프로세싱 장치로부터 데이터 사용 정보를 수신한다. 블록에서, 데이터 오케스트레이터는 데이터 사용 정보 및 기계 학습을 통해 트레이닝된 예측 모 델에 기초하여, 메모리 컴포넌트들에서의 계층들에 걸쳐 제2 데이터 이동을 예측한다. 블록에서, 데이터 오케스트레이터는 제2 데이터 액세스 요청들을 수신하기 전에 제2 데이터 이 동을 수행한다. 제2 데이터 이동은 제2 데이터 액세스 요청들에 의해 야기되는 계층들에 걸친 데이터 이동을 감소시킨다. 데이터 오케스트레이터는 프로세싱 장치로부터 제2 데이터 액세스 요청들 및/또는 제2 데이터 액세스 요청들에 의해 야기된 데이터 이동을 서비스하는 데 있어 다수의 메모리 컴포넌트들의 성능 측정에 기초하여 예 측 모델을 선택적으로 더 트레이닝시킬 수 있다. 예를 들어, 성능 측정은 데이터 오케스트레이터에 의해 측정된 제2 데이터 액세스 요청들의 캐시 히트율일 수 있다. 예를 들어, 제2 메모리의 데이터에 대한 프로세싱 장치의 요청들은 제2 메모리에서 제1 메모리로 의 요청된 데이터의 이동을 야기할 수 있다. 이러한 이동은 캐시 미스로 카운팅될 수 있으며; 이러한 이동을 야 기하지 않는 데이터 액세스 요청들은 캐시 히트로 카운팅될 수 있다. 데이터 오케스트레이터는 하이브리드 강화 학습 기술을 사용하여 예측 모델을 트레이닝시켜 캐시 히트율을 높이고, 캐시 미스의 수를 줄이고/줄 이거나 데이터 액세스 요청들로부터 식별된 원하는 데이터 이동과 예측을 일치시킬 수 있다.예를 들어, 데이터 오케스트레이터는 필드 프로그램 가능 게이트 어레이(FPGA) 또는 어플리케이션별 집적 회로(ASIC)의 형태로, 메모리 모듈 또는 저장 장치에 배치된 집적 회로 칩의 컨트롤러로 구현될 수 있다. 데이 터 오케스트레이터는 데이터 액세스 요청들이 사용되는 가상 기능들(예: 247)의 아이덴터티들에 적어도 부 분적으로 기초하여 데이터 사용 정보를 획득한다. 예를 들어, 상이한 가상 기능들(예: 247)은 가상 머신들, 어플리케이션들, 사용자 계정들, 데이터 액세스 모드들 등과 같은 일정 기간 동안 데이터 사용 정보의 상이한 조합들을 나타내는 데 사용될 수 있다. 선택적으로, 데이터 오케스트레이터는 데이터 액세스 요청들과 데이터 사용 정보의 통계 분석을 더 수행하여 프로세싱 장치에서 실행되는 어플리케이션들에서 구성된 바와 같은 다수의 메모리 컴포넌트들 및 데이터 오브젝트들의 데이터 블록들 사이의 매핑을 식별한다. 예측 모델과의 매핑을 사용하면 데이터 오케 스트레이터의 예측 정확도를 향상시킬 수 있다. 바람직하게는, 예측 데이터 이동은 호스트 시스템과 통신하기 위해 데이터 오케스트레이터에 의 해 사용되는 버스(예: 203)를 거치지 않고 수행된다. 일부 구현예들에서, 프로세싱 장치 및 메모리 서브 시스템 사이의 통신 채널은 근거리 통신망, 무선 근거 리 무선 통신망, 무선 사설 통신망, 이동 통신망, 광대역 고속 상시 연결 무선 통신 연결(예를 들어, 현재 또는 차세대 모바일 통신 링크)과 같은, 컴퓨터 네트워크를 포함하며; 프로세싱 장치 및 메모리 서브 시스템은 NVMe 프로토콜과 유사한 데이터 저장 관리 및 사용 명령들을 사용하여 서로 통신하도록 구성될 수 있다. 일반적으로 메모리 서브 시스템은 비휘발성 저장 매체를 가질 수 있다. 비휘발성 저장 매체의 예들은 집적 회로 에서 형성된 메모리 셀들 및 강체 디스크들에 코팅된 자성 물질을 포함한다. 비휘발성 저장 매체는 전력을 소모 하지 않고 이에 저장된 데이터/정보를 유지할 수 있다. 메모리 셀은 NAND 로직 게이트, NOR 로직 게이트, 위상 변화 메모리(PCM), 자기 메모리(MRAM), 저항성 랜덤 액세스 메모리, 교차점 저장 장치 및 메모리 장치들(예를 들어, 3D X점 메모리) 과 같은, 다양한 메모리/저장 기술들을 사용하여 구현될 수 있다. 교차점 메모리 장치는 트랜지스터가 없는 메모리 소자들을 사용하며, 그 각각은 열(column)로 함께 적층되는 메모리 셀 및 선택기를 갖는다. 메모리 소자 열(column)은 두 개의 수직으로 배치된 와이어들을 통해 연결되며, 여기서 하나는 메모리 소자 열 위에 있고 다른 하나는 메모리 소자 열 아래에 있다. 각 메모리 소자는 두 레이어들 각각에 하나의 와 이어의 교차점에서 개별적으로 선택될 수 있다. 교차점 메모리 장치들은 빠르고 비휘발성이며, 처리 및 저장을 위한 통합 메모리 풀(pool)로 사용될 수 있다. 메모리 서브 시스템(예: 205 또는 209)의 컨트롤러(예: 227 또는 229)는 펌웨어를 실행하여 프로세싱 장치(11 8)로부터의 통신에 응답하여 동작들을 수행할 수 있다. 일반적으로 펌웨어는 공학적 컴퓨팅 장치들의 제어, 모 니터링 및 데이터 조작을 제공하는 컴퓨터 프로그램의 일종이다. 컨트롤러의 동작을 포함하는 일부 실시예들은 컨트롤러의 펌웨어와 같은, 컨트롤러에 의해 실행 된 컴퓨터 인스트럭션들을 사용하여 구현될 수 있다. 일부 경우, 하드웨어 회로들은 기능들 중 적어도 일부를 구현하는 데 사용될 수 있다. 펌웨어는 초기에 비휘발성 저장 매체 또는 다른 비휘발성 장치에 저장될 수 있으 며, 컨트롤러에 의한 실행을 위해 휘발성 DRAM 및/또는 프로세서 내 캐시 메모리에 로딩될 수 있다. 비일시적(non-transitory) 컴퓨터 저장 매체는 일반적으로 메모리 서브 시스템(예: 209 또는 205)의 펌웨어의 인스트럭션들 및/또는 운영 체제(예: 241, 243)의 인스트럭션들, 특히 장치 드라이버 및 하이퍼바이저를 저장하는 데 사용될 수 있다. 인스트럭션들이 컨트롤러 및/또는 프로세싱 장치에 의해 실행될 때, 인 스트럭션들은 컨트롤러 및/또는 프로세싱 장치가 위에서 논의된 방법을 수행하게 한다. 도 10은 기계가 본원에 논의된 방법론들 중 임의의 하나 이상을 수행하게 하는 인스트럭션 세트가 실행될 수 있 는 컴퓨터 시스템의 예시적인 상기 기계를 예시한다. 일부 실시예들에서, 컴퓨터 시스템은 메모리 서 브 시스템(예를 들어, 도 1의 메모리 서브 시스템)을 포함하거나, 이에 결합되거나 이를 이용하는 호스트 시스템(예를 들어, 도 1의 호스트 시스템)에 대응되거나, 데이터 오케스트레이터의 동작들을 수행(예 를 들어, 도 1 내지 9를 참조하여 설명된 데이터 오케스트레이터에 대응되는 동작들을 수행하기 위한 인스 트럭션들을 실행)하는 데 사용될 수 있다. 대안적인 실시예들에서, 기계는 LAN, 인트라넷, 엑스트라넷 및/또는 인터넷의 다른 기계들에 연결(예를 들어, 네트워킹)될 수 있다. 기계는 클라이언트-서버 네트워크 환경에서 서 버 또는 클라이언트 기계의 용량으로, 피어 투 피어(또는 분산) 네트워크 환경에서의 피어 기계로, 또는 클라우 드 컴퓨팅 인프라스트럭처 또는 환경에서의 서버 또는 클라이언트 기계로 동작할 수 있다. 기계는 개인용 컴퓨터(PC), 태블릿 PC, 셋톱박스(STB), 개인용 디지털 보조 장치(PDA), 셀룰러 텔레폰, 웹 기기, 서버, 네트워크 라우터, 스위치 또는 브릿지, 또는 해당 기계에 의해 수행될 조치들을 명시하는 인스트럭 션 세트(순차적 또는 다른 방식)을 실행할 수 있는 임의의 기계일 수 있다. 또한, 단일 기계가 예시되어 있지만, \"기계\"라는 용어는 또한 본원에서 논의된 방법론들 중 임의의 하나 이상을 수행하기 위해 인스트럭션 세트(또는 복수 세트)를 개별적으로 또는 공통으로 실행하는 임의의 기계 컬렉션을 포함하는 것으로 간주해야 한다. 예시적인 컴퓨터 시스템은 버스(다수의 버스들을 포함할 수 있음)를 통해 서로 통신하는, 프로세싱 장치, 메인 메모리(예: 읽기 전용 메모리(ROM), 플래시 메모리, 동기식 DRAM(SDRAM) 또는 램버스 DRAM(RDRAM)과 같은 동적 랜덤 액세스 메모리(DRAM), 정적 랜덤 액세스 메모리(SRAM) 등), 및 데이터 저장 시스 템를 포함한다. 프로세싱 장치는 마이크로프로세서, 중앙 처리 유닛 등과 같은 하나 이상의 범용 프로세싱 장치들을 나타 낸다. 보다 구체적으로, 프로세싱 장치는 CISC(complex instruction set computing) 마이크로프로세서, RISC(reduced instruction set computing) 마이크로프로세서, VLIW(very long instruction word) 마이크로프로 세서, 또는 인스트럭션 세트들을 구현하는 프로세서, 또는 인스트럭션 세트들의 조합을 구현하는 프로세서들일 수 있다. 프로세싱 장치는 또한 ASIC(application specific integrated circuit), FPGA(field programmable gate array), DSP(digital signal processor), 네트워크 프로세서 등과 같은 하나 이상의 특수 목적 프로세싱 장치들일 수 있다. 프로세싱 장치는 본원에 논의된 동작들 및 단계들을 수행하기 위한 인스 트럭션들을 수행하도록 구성된다. 컴퓨터 시스템은 네트워크를 통해 통신하기 위한 네트워크 인 터페이스 장치를 더 포함할 수 있다. 데이터 저장 시스템는 본원에 설명된 방법들 또는 기능들 중 임의의 하나 이상을 구현하는 하나 이상의 인스트력션 세트 또는 소프트웨어가 저장되는 기계 판독 가능 저장 매체(컴퓨터 판독 가능 매체라고 도 함)를 포함할 수 있다. 인스트럭션들은 또한 기계 판독 가능 저장 매체를 구성하는 컴퓨터 시스템 , 메인 메모리 및 프로세싱 장치에 의한 실행 동안 메인 메모리 내에 및/또는 프로세싱 장 치 내에 완전히 또는 적어도 부분적으로 상주할 수 있다. 기계 판독 가능 저장 매체, 데이터 저장 시 스템 및/또는 메인 메모리는 도 1의 메모리 서브 시스템에 대응될 수 있다. 일 실시예에서, 인스트럭션들은 데이터 오케스트레이터(예를 들어, 도 1 내지 9를 참조하여 설명된 데이터 오케스트레이터)에 대응되는 기능을 구현하기 위한 인스트럭션들을 포함한다. 기계 판독 가능 저장 매체가 예시적인 실시에서 단일 매체인 것으로 도시되어 있지만, \"기계 판독 가능 저장 매체\"라는 용어는 하나 이상의 인스트럭션 세트들을 저장하는 단일 매체 또는 다중 매체를 포함하는 것으로 간주되어야 한다. \"기 계 판독 가능 저장 매체\"라는 용어는 또한 기계에 의해 실행되는 인스트럭션 세트를 저장 또는 인코딩할 수 있 고 기계가 본 개시의 방법들 중 임의의 하나 이상을 수행하게 하는 임의의 매체를 포함하는 것으로 간주되어야 한다. 따라서, \"기계 판독 가능 저장 매체\"라는 용어는, 이에 제한되는 것은 아니나, 솔리드 스테이트 메모리들, 광학 매체 및 자기 매체를 포함하는 것으로 간주되어야 한다. 전술한 상세한 설명의 일부 부분들은 컴퓨터 메모리 내의 데이터 비트들에 대한 연산의 알고리즘 및 상징적 표 현들과 관련하여 제시되었다. 이러한 알고리즘적 설명들 및 표현들은 데이터 처리 분야의 당업자가 그들 작업의 실체를 다른 당업자에게 가장 효과적으로 전달하기 위해 사용되는 방식들이다. 여기서, 알고리즘은 일반적으로 원하는 결과를 도출하는 자기 모순 없는(self-consistent) 동작 시퀀스인 것으로 생각된다. 동작들은 이러한 물 리적 수량의 물리적 조작을 필요로 한다. 일반적으로, 반드시 그런 것은 아니지만, 이러한 양은 저장되고, 결합 되고, 비교되고 아니면 조작될 수 있는 전기 또는 자기 신호들의 형태를 취한다. 이러한 신호들을 비트, 값, 요 소, 심볼, 문자, 용어, 숫자 등으로 지칭하는 것이, 주로 일반적인 사용의 이유로, 때때로 편리한 것으로 입증 되었다. 그러나, 이러한 및 유사한 용어들 모두는 적절한 물리적 양과 관련이 있으며 이러한 양에 적용되는 편리한 라벨 들일 뿐이라는 점을 명심해야 한다. 본 개시는 컴퓨터 시스템의 레지스터들과 메모리들 내에서 물리적(전자적) 양으로 표현되는 데이터를 컴퓨터 시스템 메모리들 또는 레지스터들 또는 다른 이러한 정보 저장 시스템들 내의 물리적 양으로 표현되는 다른 데이터로 조작하고 변환하는 컴퓨터 시스템 또는 이와 유사한 전자 컴퓨팅 장치의 동작 및 프로세스들을 인용할 수 있다. 본 개시는 또한 본원에서 동작들을 수행하기 위한 장치에 관한 것이다. 이 장치는 의도된 목적들을 위해 특별히 구성될 수 있거나, 이는 컴퓨터에 저장된 컴퓨터 프로그램에 의해 선택적으로 활성화되거나 재구성된 범용 컴퓨 터를 포함할 수 있다. 이러한 컴퓨터 프로그램은, 이에 제한되는 것은 아니나, 플로피 디스크, 광 디스크, CD-ROM, 및 자기-광학 디스크, 읽기 전용 메모리(ROM), 랜덤 액세스 메모리(RAM), EPROM, EEPROM, 자기 또는 광학 카드, 또는 각각 컴퓨터 시스템 버스에 연결된 전자 인스트럭션들을 저장하기에 적합한 임의의 유형의 매체를 포함하는 임의 유형의 디스크와 같은 컴퓨터 판독 가능 저장 매체에 저장될 수 있다. 본원에 제시된 알고리즘들 및 디스플레이들은 본질적으로 임의의 특정 컴퓨터 또는 다른 장치와 관련되지 않는 다. 다양한 범용 시스템들은 본원의 교시에 따른 프로그램들과 함께 사용될 수 있거나, 방법을 수행하기 위해 다 특화된 장치를 구성하는 것이 편리하다는 것을 입증할 수 있다. 다양한 이들 시스템들의 구조는 아래의 설명 에서 제시되는 것으로 나타날 것이다. 또한, 본 개시는 임의의 특정 프로그래밍 언어를 참조하여 설명되지 않는 다. 다양한 프로그래밍 언어들이 본원에 기술된 바와 같이 본 개시의 교시를 구현하는 데 사용될 수 있음이 이 해될 것이다. 본 개시는 본 개시에 따른 프로세스를 수행하기 위해 컴퓨터 시스템(또는 다른 전자 장치)를 프로그래밍하는 데 사용될 수는, 인스트럭션들을 저장한 기계 판독 가능 매체를 포함할 수 있는 컴퓨터 프로그램 제품 또는 소프트 웨어로서 제공될 수 있다. 기계 판독 가능 매체는 기계(예: 컴퓨터)에 의해 판독 가능한 형태로 정보를 저장하 기 위한 임의의 메커니즘을 포함한다. 일부 실시예들에서, 기계 판독 가능(예: 컴퓨터 판독 가능) 매체는 읽기 전용 메모리( \"ROM\"), 랜덤 액세스 메모리( \"RAM\"), 자기 디스크 저장 매체, 광 저장 매체, 플래시 메모리 컴포 넌트들 등과 같은 기계(예: 컴퓨터) 판독 가능 저장 매체를 포함한다. 이 설명에서, 다양한 기능들 및 동작들은 설명을 단순화하기 위해 컴퓨터 명령에 의해 수행되거나 컴퓨터 명령 에 의해 야기되는 것으로 설명된다. 그러나, 당업자는 이러한 표현이 의미하는 것이 마이크로프로세서와 같은 하나 이상의 컨트롤러들 또는 프로세서들에 의한 컴퓨터 인스트럭션들의 실행으로 인한 기능들이라는 것을 인식 할 것이다. 대안으로, 또는 조합하여, 기능들 및 동작들은 어플리케이션별 집적 회로(ASIC) 또는 필드 프로그램 가능 게이터 어레이(FPGA)를 사용하는 것과 같은, 소프트웨어 인스트력션들이 있든 없든 특수 목적 회로부를 사 용하여 구현될 수 있다. 실시예들은 소프트웨어 인스트럭션들 없이 하드와이어링된 회로부를 사용하거나, 소프 트웨어 인스트럭션들과 조합하여 구현될 수 있다. 따라서, 기술들은 하드웨어 회로부와 소프트웨어의 임의의 특 정 조합이나, 데이터 프로세싱 시스템에 의해 실행된 인스트럭션들에 대한 임의의 특정 출처에 제한되지 않는다. 전술한 명세서에서, 본 개시의 실시예들은 그 특정 예시적인 실시예들을 참조하여 설명되었다. 다음의 청구 범 위에 명시된 본 개시의 실시예들의 넓은 사상 및 범위를 벗어나지 않고 다양한 변형들이 이루어질 수 있음이 명 백할 것이다. 따라서, 명세서 및 도면들은 제한적인 의미보다는 예시적인 의미로 간주되어야 한다.도면 도면1 도면2 도면3 도면4 도면5 도면6 도면7 도면8 도면9 도면10"}
{"patent_id": "10-2020-7025393", "section": "도면", "subsection": "도면설명", "item": 1, "content": "실시예들은 예로서 도시되며, 유사한 참조 번호들이 유사한 요소들을 나타내는 첨부 도면들의 도면들에 제한되 지 않는다. 도 1은 본 개시의 일부 실시예들에 따른 메모리 서브 시스템을 갖는 예시적인 컴퓨팅 시스템을 예시한다. 도 2는 본원에 개시된 적어도 일부 실시예들에 따른 원격 다이렉트 메모리 액세스를 용이하게 하기 위한 데이터 오케스트레이터(data orchestrator)를 갖는 컴퓨팅 시스템을 도시한다. 도 3은 일 실시예에 따른 원격 다이렉트 메모리 액세스를 수행하는 컴퓨팅 시스템을 도시한다. 도 4는 가상 머신에서 실행되는 어플리케이션에서 원격 다이렉트 메모리 액세스를 사용하는 예를 예시한다. 도 5는 원격 다이렉트 메모리 액세스의 방법을 도시한다. 도 6은 본원에 개시된 적어도 일부 실시예들에 따른 데이터 위치들을 최적화하기 위해 상이한 계층의 메모리 및 데이터 오케스트레이터를 갖는 컴퓨팅 시스템을 도시한다. 도 7은 데이터 오케스트레이터를 갖는 시스템을 도시한다. 도 8은 데이터 오케스트레이터의 구현예를 예시한다. 도 9는 예측 데이터 오케스트레이션의 방법을 도시한다. 도 10은 본 개시의 실시예들이 동작할 수 있는 예시적인 컴퓨터 시스템의 블록도이다."}
