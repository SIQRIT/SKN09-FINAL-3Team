{"patent_id": "10-2023-0033824", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0135003", "출원번호": "10-2023-0033824", "발명의 명칭": "인공지능 모델학습 고속화를 위한 분산 딥러닝 플랫폼과 연계 가능한 분산 딥러닝 인퍼런싱", "출원인": "주식회사 딥인스펙션", "발명자": "이철희"}}
{"patent_id": "10-2023-0033824", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "하이브리드 방식의 분산 딥러닝 플랫폼 모듈; 분산 인퍼런싱 모듈; 상기 하이브리드 방식의 분산 딥러닝 플랫폼 모듈 및 분산 인퍼런싱 모듈을 연결하는 API; 상기 하이브리드 방식의 분산 딥러닝 플랫폼 모듈 및 분산 인퍼런싱 모듈을 제어하는 컨트롤러; 및상기 하이브리드 방식의 분산 딥러닝 플랫폼 모듈 및 분산 인퍼런싱 모듈을 통합하는 웹 서비스 기반의 UI(UserInterface)를 포함하고, 상기 분산 인퍼런싱 모듈은 영상 데이터를 분석하여 시설물 표면, 항공기 동체의 표면 및 제트 엔진 중 적어도어느 하나의 손상을 검출하고, 검출된 손상 정보에 대한 정량화 및 시각화를 수행하는 인공지능 모델을 분산 기술 기반으로 구동시키는 것인 인공지능 모델학습 고속화를 위한 분산 딥러닝 플랫폼과 연계 가능한 분산 딥러닝 인퍼런싱 시스템."}
{"patent_id": "10-2023-0033824", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 분산 딥러닝 플랫폼 모듈은 인피니밴드 스위치, 소프트 메모리박스, GPU로 구성된 하드웨어 시스템을 이용해 연산하고, 텐서플로우 프레임워크를 기반으로 작동되는 것 인 인공지능 모델학습 고속화를 위한 분산 딥러닝 플랫폼과 연계 가능한 분산 딥러닝 인퍼런싱 시스템."}
{"patent_id": "10-2023-0033824", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서, 상기 분산 인퍼런싱 모듈은 상기 영상 데이터로부터 실시간으로 상기 시설물 표면, 항공기 동체의 표면 및 제트엔진 중 적어도 어느 하나의 손상의 손상을 검출하는 클래시피케이션(Classification) 기능, 오브젝트디텍션(Object Detection) 기능, 세그멘테이션(Segmentation) 기능을 수행하되, 피라미드식 4단계 특징 추출 네트워크를 포함하는 RPN 기반의 인공지능 모델로 구성되는 것인 인공지능 모델학습 고속화를 위한 분산 딥러닝 플랫폼과 연계 가능한 분산 딥러닝 인퍼런싱 시스템."}
{"patent_id": "10-2023-0033824", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서, 상기 분산 인퍼런싱 모듈은 인피니밴드 스위치, 광케이블, 어댑터, GPU로 구성된 하드웨어 시스템을 이용해 연산하고, 텐서플로우 프레임워크 또는 파이토치 프레임워크를 기반으로 작동되는 것인 인공지능 모델학습 고속화를 위한 분산 딥러닝 플랫폼과 연계 가능한 분산 딥러닝 인퍼런싱 시스템."}
{"patent_id": "10-2023-0033824", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "공개특허 10-2023-0135003-3-제1항에 있어서, 상기 분산 인퍼런싱 모듈은 동시 접속자수 증가 및 태스크 증가에 따라 스케일업이 가능하도록 태스크와 연산자원을 매칭하고 관리하는 잡스케줄러(Job Scheduler) API와 백엔드(Backend)를 포함하며 웹 브라우저 또는 모바일기기를 통해 실행되는 것인 인공지능 모델학습 고속화를 위한 분산 딥러닝 플랫폼과 연계 가능한 분산 딥러닝 인퍼런싱 시스템."}
{"patent_id": "10-2023-0033824", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서, 상기 웹 서비스 기반의 UI는 상기 UI 상에서 AI 모델 학습에 필요한 하이퍼파라미터를 입력하는 서브윈도우, 학습 과정과 결과를 모니터링하고 출력하는 서브윈도우, AI 모델 인퍼런싱의 파라미터를 입력하는 서브윈도우로구성되는 것인 인공지능 모델학습 고속화를 위한 분산 딥러닝 플랫폼과 연계 가능한 분산 딥러닝 인퍼런싱 시스템."}
{"patent_id": "10-2023-0033824", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6항에 있어서, 상기 웹 서비스 기반의 UI는 Learning Rate, Mini Batch Size, Drop Out, Activation Function, OptimizationFunction, Layer Number 중 적어도 어느 하나를 포함하는 상기 하이퍼파라미터를 입력하는 서브윈도우를 포함하는 것인 인공지능 모델학습 고속화를 위한 분산 딥러닝 플랫폼과 연계 가능한 분산 딥러닝 인퍼런싱 시스템."}
{"patent_id": "10-2023-0033824", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1항에 있어서, 상기 분산 인퍼런싱 모듈을 구성하는 인공지능 모델은 대량의 학습데이터 없이 검출성능을 빠르게 향상시킬 수있는 클래시피케이션(classification) 기반 메타러닝 학습 기법을 적용하여 손상을 검출 및 분류하는 것인 인공지능 모델학습 고속화를 위한 분산 딥러닝 플랫폼과 연계 가능한 분산 딥러닝 인퍼런싱 시스템."}
{"patent_id": "10-2023-0033824", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 인공지능 모델학습 고속화를 위한 분산 딥러닝 플랫폼과 연계 가능한 분산 딥러닝 인퍼런싱 시스템 및 그 방법에 관한 것으로, 보다 상세하게는 성능 향상을 위해 필수적인 큰 규모의 인공지능 모델을 빠르게 학습시 키기 위한 분산 딥러닝 플랫폼 기술과 연계 가능하고, 다수의 서버 및 GPU(Graphic Processing Unit)를 클러스 (뒷면에 계속)"}
{"patent_id": "10-2023-0033824", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 인공지능 모델학습 고속화를 위한 분산 딥러닝 플랫폼과 연계 가능한 분산 딥러닝 인퍼런싱 시스템 및 그 방법에 관한 것으로, 보다 상세하게는 성능 향상을 위해 필수적인 큰 규모의 인공지능 모델을 빠르게 학 습시키기 위한 분산 딥러닝 플랫폼 기술과 연계 가능하고, 다수의 서버 및 GPU(Graphic Processing Unit)를 클 러스터링 하여 서비스 단계에서 추론 속도를 향상시키는 것이 가능한 분산 딥러닝 인퍼런싱 시스템 및 그 방법 에 관한 것이다. 본 발명은 한국전자통신연구원 R&D 성과활용 및 신사업 촉진 지원사업의 일환으로 수행한 연구(파이썬기반 딥러 닝 모델 지원 분산 학습 및 인퍼런싱 플랫폼 기술 개발)로부터 도출된 것이다."}
{"patent_id": "10-2023-0033824", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "인공지능 모델을 더욱 지능적으로 개선하고, 인간처럼 복잡하고 다양한 데이터를 높은 성능으로 처리하기 위해 인공지능 모델의 크기는 향후 지속적으로 커질 것으로 전망되며, 규모가 큰 인공지능 모델을 빠르게 학습시키는기술은 필수불가결하게 될 것으로 예상된다. 종래 기술에 따르면, 인공지능 모델을 빠르게 학습시키기 위해 클럭(clock) 속도(GHz 단위)가 높은 고사양의 서 버를 활용하거나, 코어수가 많은 GPU(Graphic Processing Unit)를 사용하였으나, 속도 향상에 기술적인 한계가 있고 구축 비용이 기하급수적으로 증가된다는 문제가 있다. 또한, 전문적인 IDC(Internet Data Center)가 아닌 기업내에 구축된 인하우스(In House) 서버 시스템을 구성하 는 핵심 구성요소(GPU 등)의 구입 시기와 모델이 모두 다른 경우가 많은데, 이종 서버 및 이종 GPU를 조합할 경 우 분산 학습 및 분산 인퍼런싱 과정에서 성능 저하가 발생하는 문제가 있다. 또한, AI 모델 개발을 위한 텐서 플로우 프레임워크(Tensorflow Framework)와 같은 분산처리를 지원하는 오픈소 스를 활용할 경우, 분산 효율이 매우 낮아 8대 이상의 GPU로 분산 처리하는 것이 현실적으로 불가능하고, 분산 딥러닝 플랫폼 모듈의 하드웨어 파트를 구성하는 인피니밴드 스위치와 소프트 메모리박스의 활용이 불가능하여 AI 모델 학습을 단계별로 진행하는 과정에서 학습 가중치 행렬(Weight)을 실시간으로 업데이트하고 공유할 때 병목 현상이 발생되는 문제가 있다."}
{"patent_id": "10-2023-0033824", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 전술한 문제점을 해결하기 위해 제안된 것으로, 성능 향상을 위해 필수적인 큰 규모의 인공지능 모델 을 빠르게 학습시키기 위한 분산 딥러닝 플랫폼 기술과 연계가 가능하고, 다수의 서버 및 GPU(Graphic Processing Unit)를 클러스터링하되 이종 서버 및 이종 GPU를 조합하더라도 급격한 성능 저하를 방지하며, 최대 64대까지 일정 수준 이상의 분산 효율을 유지하여 서비스 단계에서 추론 속도를 향상시키고, AI 모델 학습과 AI 모델 인퍼런싱 단계에서 사용자에게 다양하고 직관적인 정보를 제공하여, 작업 효율을 높이는 것이 가능한 분산 딥러닝 인퍼런싱 시스템 및 그 방법을 제공하는데 그 목적이 있다."}
{"patent_id": "10-2023-0033824", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명에 따른 분산 딥러닝 인퍼런싱 시스템은 하이브리드 방식의 분산 딥러닝 플랫폼 모듈; 분산 인퍼런싱 모 듈; 상기 하이브리드 방식의 분산 딥러닝 플랫폼 모듈 및 분산 인퍼런싱 모듈을 연결하는 API; 상기 하이브리드 방식의 분산 딥러닝 플랫폼 모듈 및 분산 인퍼런싱 모듈을 제어하는 컨트롤러; 및 상기 하이브리드 방식의 분산 딥러닝 플랫폼 모듈 및 분산 인퍼런싱 모듈을 통합하는 웹 서비스 기반의 UI(User Interface)를 포함하고, 상기 분산 인퍼런싱 모듈은 영상 데이터를 분석하여 시설물 표면, 항공기 동체의 표면 및 제트 엔진 중 적어도 어느 하나의 손상을 검출하고, 검출된 손상 정보에 대한 정량화 및 시각화를 수행하는 인공지능 모델을 분산 기술 기 반으로 구동시킨다. 상기 분산 딥러닝 플랫폼 모듈은 인피니밴드 스위치, 소프트 메모리박스, GPU로 구성된 하드웨어 시스템을 이용 해 연산하고, 텐서플로우 프레임워크를 기반으로 작동된다. 상기 분산 인퍼런싱 모듈은 상기 영상 데이터로부터 실시간으로 상기 시설물 표면, 항공기 동체의 표면 및 제트 엔진 중 적어도 어느 하나의 손상의 손상을 검출하는 클래시피케이션(Classification) 기능, 오브젝트디텍션 (Object Detection) 기능, 세그멘테이션(Segmentation) 기능을 수행하되, 피라미드식 4단계 특징 추출 네트워크 를 포함하는 RPN 기반의 인공지능 모델로 구성된다. 상기 분산 인퍼런싱 모듈은 인피니밴드 스위치, 광케이블, 어댑터, GPU로 구성된 하드웨어 시스템을 이용해 연 산하고, 텐서플로우 프레임워크 또는 파이토치 프레임워크를 기반으로 작동된다. 상기 분산 인퍼런싱 모듈은 동시 접속자수 증가 및 태스크 증가에 따라 스케일업이 가능하도록 태스크와 연산자 원을 매칭하고 관리하는 잡스케줄러(Job Scheduler) API와 백엔드(Backend)를 포함하며 웹 브라우저 또는 모바 일기기를 통해 실행된다. 상기 웹 서비스 기반의 UI는 상기 UI 상에서 AI 모델 학습에 필요한 하이퍼파라미터를 입력하는 서브윈도우, 학 습 과정과 결과를 모니터링하고 출력하는 서브윈도우, AI 모델 인퍼런싱의 파라미터를 입력하는 서브윈도우로구성된다. 상기 웹 서비스 기반의 UI는 Learning Rate, Mini Batch Size, Drop Out, Activation Function, Optimization Function, Layer Number 중 적어도 어느 하나를 포함하는 상기 하이퍼파라미터를 입력하는 서브윈도우를 포함한 다. 상기 분산 인퍼런싱 모듈을 구성하는 인공지능 모델은 대량의 학습데이터 없이 검출성능을 빠르게 향상시킬 수 있는 클래시피케이션(classification) 기반 메타러닝 학습 기법을 적용하여 손상을 검출 및 분류한다."}
{"patent_id": "10-2023-0033824", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명에 따르면, 인공지능 모델을 빠르게 학습시키기 위한 분산 딥러닝 플랫폼 기술과 연계가 가능하고 다수 의 서버 및 GPU(Graphic Processing Unit)를 클러스터링하여 분산 인퍼런싱하고, 인공지능 모델을 이용한 학습 및 서비스 구축의 기간을 단축하고 효율을 높이는 효과가 있다. 전문적인 IDC가 아닌 기업의 인하우스 서버 시스템을 구성하는 이종의 서버 및 구성요소(GPU 등)을 조합하여 최 대 64대까지 분산 효율을 유지시키고, 서비스 단계에서 추론 속도를 향상시키는 효과가 있다. 분산 딥러닝 플랫폼 모듈의 하드웨어 파트를 구성하는 인피니밴드 스위치와 소프트메모리박스는 AI 모델학습을 단계별로 진행하는 과정에서 학습 가중치 행렬(Weight)을 실시간으로 업데이트하고 공유함에 있어서 병목 현상 이 발생되지 않도록 하는 장점이 있다. UI 상에서 AI 모델학습에 필요한 하이퍼파라미터 입력, 학습 과정 및 결과에 대한 모니터링 및 출력, AI 모델 인퍼런싱의 파라미터 입력을 위한 서브 윈도우를 포함하여, AI 모델 학습과 AI 모델 인퍼런싱 단계에서 사용자 에게 다양하고 직관적인 정보를 제공하여 작업 효율을 높이는 것이 가능하다."}
{"patent_id": "10-2023-0033824", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 2, "content": "본 발명의 효과는 이상에서 언급한 것들에 한정되지 않으며, 언급되지 아니한 다른 효과들은 아래의 기재로부터 당업자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2023-0033824", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명의 전술한 목적 및 그 이외의 목적과 이점 및 특징, 그리고 그것들을 달성하는 방법은 첨부되는 도면과 함께 상세하게 후술되어 있는 실시예들을 참조하면 명확해질 것이다. 그러나 본 발명은 이하에서 개시되는 실시예들에 한정되는 것이 아니라 서로 다른 다양한 형태로 구현될 수 있"}
{"patent_id": "10-2023-0033824", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "으며, 단지 이하의 실시예들은 본 발명이 속하는 기술분야에서 통상의 지식을 가진 자에게 발명의 목적, 구성 및 효과를 용이하게 알려주기 위해 제공되는 것일 뿐으로서, 본 발명의 권리범위는 청구항의 기재에 의해 정의 된다. 한편, 본 명세서에서 사용된 용어는 실시예들을 설명하기 위한 것이며 본 발명을 제한하고자 하는 것은 아니다. 본 명세서에서, 단수형은 문구에서 특별히 언급하지 않는 한 복수형도 포함한다. 명세서에서 사용되는 \"포함한 다(comprises)\" 및/또는 \"포함하는(comprising)\"은 언급된 구성소자, 단계, 동작 및/또는 소자가 하나 이상의 다른 구성소자, 단계, 동작 및/또는 소자의 존재 또는 추가됨을 배제하지 않는다. 본 발명의 실시예에 따른 분산 딥러닝 인퍼런싱 시스템은 하이브리드 방식의 분산 딥러닝 플랫폼 모듈; 분산 인 퍼런싱 모듈; 상기 하이브리드 방식의 분산 딥러닝 플랫폼 모듈 및 분산 인퍼런싱 모듈을 연결하는 API; 상기 하이브리드 방식의 분산 딥러닝 플랫폼 모듈 및 분산 인퍼런싱 모듈을 제어하는 컨트롤러; 및 상기 하이브리드 방식의 분산 딥러닝 플랫폼 모듈 및 분산 인퍼런싱 모듈을 통합하는 웹 서비스 기반의 UI(User Interface)를 포 함하고, 상기 분산 인퍼런싱 모듈은 영상 데이터를 분석하여 시설물 표면, 항공기 동체의 표면 및 제트 엔진 중 적어도 어느 하나의 손상을 검출하고, 검출된 손상 정보에 대한 정량화 및 시각화를 수행하는 인공지능 모델을 분산 기술 기반으로 구동시킨다. 상기 분산 딥러닝 플랫폼 모듈은 인피니밴드 스위치, 소프트 메모리박스, GPU로 구성된 하드웨어 시스템을 이용 해 연산하고, 텐서플로우 프레임워크를 기반으로 작동된다. 상기 분산 인퍼런싱 모듈은 상기 영상 데이터로부터 실시간으로 상기 시설물 표면, 항공기 동체의 표면 및 제트 엔진 중 적어도 어느 하나의 손상의 손상을 검출하는 클래시피케이션(Classification) 기능, 오브젝트디텍션 (Object Detection) 기능, 세그멘테이션(Segmentation) 기능을 수행하되, 피라미드식 4단계 특징 추출 네트워크 를 포함하는 RPN 기반의 인공지능 모델로 구성된다. 상기 분산 인퍼런싱 모듈은 인피니밴드 스위치, 광케이블, 어댑터, GPU로 구성된 하드웨어 시스템을 이용해 연 산하고, 텐서플로우 프레임워크 또는 파이토치 프레임워크를 기반으로 작동된다. 상기 분산 인퍼런싱 모듈은 동시 접속자수 증가 및 태스크 증가에 따라 스케일업이 가능하도록 태스크와 연산자 원을 매칭하고 관리하는 잡스케줄러(Job Scheduler) API와 백엔드(Backend)를 포함하며 웹 브라우저 또는 모바 일기기를 통해 실행된다. 상기 웹 서비스 기반의 UI는 상기 UI 상에서 AI 모델 학습에 필요한 하이퍼파라미터를 입력하는 서브윈도우, 학 습 과정과 결과를 모니터링하고 출력하는 서브윈도우, AI 모델 인퍼런싱의 파라미터를 입력하는 서브윈도우로 구성된다. 상기 웹 서비스 기반의 UI는 Learning Rate, Mini Batch Size, Drop Out, Activation Function, Optimization Function, Layer Number 중 적어도 어느 하나를 포함하는 상기 하이퍼파라미터를 입력하는 서브윈도우를 포함한 다. 상기 분산 인퍼런싱 모듈을 구성하는 인공지능 모델은 대량의 학습데이터 없이 검출성능을 빠르게 향상시킬 수 있는 클래시피케이션(classification) 기반 메타러닝 학습 기법을 적용하여 손상을 검출 및 분류한다. 분산 딥러닝 플랫폼 기술 분산 딥러닝 플랫폼 기술은 HPC(High-Performance Computing, 고성능 컴퓨팅) 시스템 상에서 다수의 서버들을 이용하여 고속으로 대규모 딥러닝 모델의 트레이닝(학습)이 가능하도록 지원하는 솔루션으로 대표적인 인공지능 프레임웍인 TensorFlow와 같은 기존 딥러닝 라이브러리를 확장하여 빠른 심층 학습속도를 달성하는 분산 학습 솔루션이다. 파라미터 서버인 SMB(Soft Memory Box) 도입을 통해 파라미터를 해당 원격 메모리로 직접 전송하고 SMB를 활용하여 기존의 TCP/IP를 제거하고 이를 통해 속도를 향상시킨다. 분산 인퍼런싱 기술 분산 인퍼런싱 기술은 분산 딥러닝 플랫폼 기술을 통해 AI 모델을 학습시킨 후 새로운 데이터에 대해 추론(인퍼 런싱)하는 단계에서 분산 기술, 복수의 CPU, 복수의 GPU, 인피니밴드스위치 기반으로 데이터 처리속도를 향상시 키는 기술이다. 텐서플로우 지원 분산 딥러닝 기술 구글의 텐서플로우 팀은 모델 병렬성과 분산 딥러닝을 위한 언어를 제공하는 메시(Mesh) 텐서플로우를 발표했 다. 메시 텐서플로우는 네트워크로 연결된 프로세서의 n차원 배열이 사용되는 다양한 시나리오에 맞는 폭넓은 분산 텐서 계산 클래스를 지정한다. 이러한 시나리오에는 모델 매개변수가 너무 많아서 하나의 장치에 다 들어 가지 않는 경우, 너무 커서 활성화 시 하나의 장치에 들어가지 않는 3D 이미지 모델이나 기타 데이터 예제, 또 는 저지연 병렬 추론이 필요한 경우 등이 포함된다. Horovod 지원 분산 딥러닝 기술 Horovod 지원 분산 딥러닝 기술은 Uber사에서 개발한 분산 딥러닝 솔루션이며 오픈소스이다. 자율 주행 연구에 서 여행 예측 및 사기 방지에 이르기까지 딥 러닝을 통해 엔지니어와 데이터 과학자는 사용자를 위해 더 나은 경험을 만들 수 있다. TensorFlow는 다양한 이유로 Uber에서 선호하는 딥 러닝 라이브러리가 되었다. 먼저 프레임워크는 딥 러닝을 위 해 가장 널리 사용되는 오픈 소스 프레임워크 중 하나이므로 신규 사용자를 쉽게 온보딩할 수 있다. 또한 낮은 수준의 모델 세부 정보를 수정할 수 있는 기능과 고성능을 결합한다. 예를 들어 Keras와 같은 높은 수준의 API 를 모두 사용하고 NVIDIA의 CUDA 툴킷을 사용하여 자체 사용자 지정 연산자를 구현할 수 있다. 또한 TensorFlow 는 탐색적 연구를 수행하는 것부터 클라우드 서버, 모바일 앱, 심지어 자율 주행 차량에 프로덕션 환경에 모델 을 배포하는 것에 이르기까지 다양한 딥 러닝 사용 사례에 대한 종단 간 지원을 제공한다. 인피니밴드 스위치 인피니밴드스위치(InfiniBand Switch)는 고성능 컴퓨팅과 기업용 데이터 센터에서 사용되는 스위치 방식의 통신 연결 방식이다. 주요 특징으로는 높은 스루풋과 낮은 레이턴시 그리고 높은 안정성과 확장성을 들 수 있다. 컴퓨팅 노드와 스토리지 장비와 같은 고성능 I/O 장비간의 연결에 사용되며 인피니밴드는 가상 인터페 이스 아키텍처(VIA)의 확대 개념이다. 소프트 메모리박스 대규모의 데이터를 처리하기 위해서는 여러 대의 컴퓨터로 나눠 '분산 학습'을 시행하게 되는데, 이때 통신 병 목 현상이 발생해 특정 지점에서 성능이나 용량이 저하되는 현상이 나타나는 게 문제이다. 이를 위해 CPU나 GPU 의 성능을 개선하는 방법도 있으나 이는 장비 교체라는 부담이 따른다. `소프트메모리 박스(Soft Memory Box)' 라고 불리는 공유기억장치는 분산 학습 시의 통신 병목현상을 해소함으로써 학습 시간을 단축시키고 소프트 메 모리 박스는 컴퓨터 사이에 위치해 각 컴퓨터들이 학습한 데이터를 서로 공유하도록 도움으로써 통신량을 줄여 주는 일종의 가상 공유 메모리 역할을 수행하는 것이다. RPN 기반 인공지능 알고리즘 RPN은 영역제안네트워크(Region Proposal Network)를 이용하여 이미지에 포함된 객체의 특징을 추출하고 그 특 징을 기반으로 후보 Bounding Box를 복수로 추천한 후 확률기반으로 추천 Bounding Box의 수를 단계적으로 줄여 최종적인 검출결과를 추론하는 알고리즘이다. 과정을 보다 상세히 설명하면, 우선 각 관심 영역(RoI; Region of Interest)에 대한 피쳐 추출의 계산을 공유하 고 딥러닝 기반의 RPN을 도입해 구현할 수 있다. 많은 CNN 레이어를 사용해 피쳐 맵을 추출하고 나면 RPN을 통해 개체를 포함하고 있을 가능성이 높은 윈도우가 다량으로 생성된다. 그런 다음 알고리즘은 각 윈도우에 있는 피쳐 맵을 검색하고, 고정 크기로 조정한 뒤(RoI 풀링) 클래스 확률과 해당 객체에 대한 더욱 정확한 경계박스를 예측한다. 여기서 고려해야 할 점은 RPN이 윈도우를 생성하는 방법인데, RPN은 앵커 박스를 사용합니다. 하지만 앵커 박스 가 데이터로부터 생성되는 것이 아니라 고정된 크기와 형태로 생성된다는 것이고 이 점이 다른 유사 알고리즘과 의 차이점이다. 이 앵커 박스는 이미지를 보다 조밀하게 커버할 수 있으며, RPN은 여러 객체 카테고리에 대한 분류 대신 윈도우의 객체 포함 유무에 대한 이진 분류(Binary Classification)만 수행한다. Attention 메카니즘 기반의 딥러닝 알고리즘 및 SVM Attention(자연어처리 분야)의 기본 아이디어는 decoder에서 출력 단어를 예측하는 매 시점(time step)마다, encoder에서의 전체 입력 문장을 다시 한번 참고한다는 점이다 단, 전체 입력 문장을 전부 다 동일한 비율로 참고하는 것이 아니라, 해당 시점에서 예측해야할 단어와 연관이 있는 입력 단어 부분을 좀 더 집중(attention)해서 보게 된다. Attention 메카니즘의 프로세스는 다음과 같다. 1) 어텐션 스코어(Attention Score)를 구한다. 2) 소프트맥스(softmax) 함수를 통해 어텐션 분포(Attention Distribution)를 구한다. 3) 각 인코더의 어텐션 가중치와 은닉 상태를 가중합하여 어텐션 값(Attention Value)을 구한다. 4) 어텐션 값과 디코더의 t 시점의 은닉 상태를 연결한다.(Concatenate) 영상처리 분야에서 어텐션(Attention)의 기본 아이디어는 공간적 어텐션(spatial attention)을 적절히 잘 사용 하면 해당 모듈의 수용층(receptive field)를 늘릴 수 있다는 것이다. 즉 spatial attention을 적절히 사용하 여 Receptive field를 증가키시는 동시에 아주 적은 연산의 추가로 기존의 network보다 더 좋은 성능을 내는 network를 개발하는 것이 가능하다. Attention은 최근 network들이 성능향상에 매우 중요한 역활을 해왔다. 실제로 Residual attention network(RAN)은 attention 모듈을 여러번 쌓아서 기존 Residual Network보다 더 좋은 성능을 내었다. 어텐션모듈(attention module)을 이용하여 다단계 수용층(receptive field)을 만들면 그로 인해 translation과 scale로부터 불변하는 특성을 얻을수 있다. SVM은 2개의 범주를 분류하는 이진 분류기이다. 주요 목적은 두 클래스 사이의 Margin을 최대화하는 '최적의 분리 결정경계 (decision boundary)인 Hyper- plane'을 찾는 것이다. Hyperplane을 지지하는 관측치들을 support vector라고 부르고 마진(margin)은 결정 경계와 support vector사 이의 거리를 의미한다. SVM은 데이터 포인트들을 올바르게 분리하면서 마진의 크기를 최대화해야 하는데, 결국 이상치(outlier)를 잘 다루는 게 중요하다. 개별적인 학습 데이터들을 다 놓치지 않으려고 아웃라이어를 허용하지 않는 기준으로 결정 경계를 정해버리면 오버피팅(overfitting) 문제가 발생할 수 있다. SVM에서는 결정 경계를 정의하는 게 결국 서포트 벡터이기 때문에 데이터 포인트 중에서 서포트 벡터만 잘 골라 내면 나머지 쓸 데 없는 수많은 데이터 포인트들을 무시할 수 있으며, 이러한 특성이 SVM을 매우 빠르게 구동시 키는 이유이다. 메타러닝 알고리즘 모델에게 학습하는 법을 학습시키는 기법으로 metric 기반, model 기반, optimization 기반 방법 등이 있다. 기 존의 딥러닝 알고리즘에서 많이 사용하는 지도학습은 데이터의 수가 일정하지 않을 경우 모델 성능에서 클래스 간 불균형을 초래하여 검출성능이 일정수준 이상 향상되지 않는 문제가 발생하였고 이와 같은 문제를 해결하는 방법으로 model 기반 메타 러닝 방법이 제시되었다. 메타러닝은 데이터가 부족한 클래스에서 모델의 성능을 향상시키고, 학습을 빠르게 수행하는 장점이 있으며 모 델은 1단계로 데이터가 풍부한 클래스로 잘 분류하는 방법을 학습 후 데이터가 적은 클래스를 포함하여 전체 클 래스의 특징을 2단계로 학습한다. 메타러닝은 구체적으로 Attention 기법을 사용하여 각 클래스에 해당하는 attentive vectors 추출 후, feature map과 channel-wise product 하여 생성한 meta feature를 통해 객체의 위치와 클래스를 판별한다. Web Browser로 실행할 수 있는 플랫폼 플랫폼은 실행장소의 영향을 받지 않고 별도의 소프트웨어 설치 없이 웹브라우저에서 실행 가능한 형태이며, UAV 제어, 영상 모니터링(관제), 영상처리 등 전 과정에 필요한 기능리스트를 가지고 있다. Sync Mode Synchronous Mode는 모든 노드의 모든 분산 프로세스(또는 GPU)들 간에 그래디언트(gradient)가 계산되면, 이 그래디언트를 통합(Averaging)하여 각 노드의 분산학습 프로세스들이 각자 자신의 로컬 모델을 학습하는 방식이 다. 비교적 분산학습의 하이퍼파라미터 튜닝이 쉽지만 이종 GPU 노드의 수가 증가할수록 낙오자(staraggler) 문 제로 인해 학습 시간이 오래 걸리는 단점이 있다. 보유한 GPU 서버가 동종이고, GPUDirect RDMA P2P를 지원하는 Tesla GPU에서 잘 사용되는 방식이다. Async Mode Asynchronous Mode는 모든 노드의 모든 분산 프로세스(또는 GPU)들 간에 asynchronous SGD를 사용하는 파라미 터 업데이트 방식이다. 이 방식은 동일 노드에 이종의 GPU들이 설치되어 있는 경우에 이용하기에 적당한 방식이 다. 그러나 비동기로 학습하는 프로세스(또는 GPU)들의 숫자가 늘어날 수 록 학습 효율이 떨어지는 단점 또한가지고 있다. Hybrid Mode Hybrid Mode는 intra-node synchronous stochastic gradient descent (SSGD) and inter-node asynchronous stochastic gradient descent (ASGD)를 사용하는 파라미터 업데이트 방식이다. 이 모드는 한 머신의 GPU들이 같은 종류인 경우에, 동일 머신의 GPU들간에 synchronous SGD 기법으로 파라미터를 업데이트하고, 다른 머신간 의 파라미터 업데이트에는 asynchronous SGD 기법(엄밀하게는 Elastic Averaging ASGD를 사용함)을 이용한다. 도 22는 본 발명의 실시예에 따른 방법을 구현하기 위한 컴퓨터 시스템을 나타낸 블록도이다. 도 22를 참조하면, 컴퓨터 시스템은, 버스를 통해 통신하는 프로세서, 메모리, 입력 인터페이스 장치, 출력 인터페이스 장치, 및 저장 장치 중 적어도 하나를 포함할 수 있다. 컴퓨터 시스템은 또한 네트워크에 결합된 통신 장치를 포함할 수 있다. 프로세서는 중앙 처 리 장치(central processing unit, CPU)이거나, 또는 메모리 또는 저장 장치에 저장된 명령을 실 행하는 반도체 장치일 수 있다. 메모리 및 저장 장치는 다양한 형태의 휘발성 또는 비휘발성 저장 매체를 포함할 수 있다. 예를 들어, 메모리는 ROM(read only memory) 및 RAM(random access memory)를 포함할 수 있다. 본 기재의 실시예에서 메모리는 프로세서의 내부 또는 외부에 위치할 수 있고, 메모리는 이미 알려진 다양한 수단을 통해 프로세서와 연결될 수 있다. 메모리는 다양한 형태의 휘발성 또는 비휘발성 저장 매체이며, 예를 들어, 메모리는 읽기 전용 메모리(read-only memory, ROM) 또는 랜덤 액세스 메모리(random access memory, RAM)를 포함할 수 있다. 따라서, 본 발명의 실시예는 컴퓨터에 구현된 방법으로서 구현되거나, 컴퓨터 실행 가능 명령이 저장된 비일시 적 컴퓨터 판독 가능 매체로서 구현될 수 있다. 한 실시예에서, 프로세서에 의해 실행될 때, 컴퓨터 판독 가능 명령은 본 기재의 적어도 하나의 양상에 따른 방법을 수행할 수 있다. 통신 장치는 유선 신호 또는 무선 신호를 송신 또는 수신할 수 있다. 또한, 본 발명의 실시예에 따른 방법은 다양한 컴퓨터 수단을 통해 수행될 수 있는 프로그램 명령 형태로 구현 되어, 컴퓨터 판독 가능 매체에 기록될 수 있다. 상기 컴퓨터 판독 가능 매체는 프로그램 명령, 데이터 파일, 데이터 구조 등을 단독으로 또는 조합하여 포함할 수 있다. 상기 컴퓨터 판독 가능 매체에 기록되는 프로그램 명령은, 본 발명의 실시예를 위해 특별히 설계되어 구성된 것이거나, 컴퓨터 소프트웨어 분야의 통상의 기술자에게 공지되어 사용 가능한 것일 수도 있다. 컴퓨터 판독 가능 기록 매체는 프로그램 명령을 저장하고 수행하도록 구성된 하드웨어 장치를 포함할 수 있다. 예를 들 어, 컴퓨터 판독 가능 기록 매체는 하드 디스크, 플로피 디스크 및 자기 테이프와 같은 자기 매체(magnetic media), CD-ROM, DVD와 같은 광 기록 매체(optical media), 플롭티컬 디스크(floptical disk)와 같은 자기-광 매체(magneto-optical media), 롬(ROM), 램(RAM), 플래시 메모리 등일 수 있다. 프로그램 명령은 컴파일러에 의해 만들어지는 것과 같은 기계어 코드뿐만 아니라, 인터프리터 등을 통해 컴퓨터에 의해 실행될 수 있는 고급 언어 코드를 포함할 수 있다. 이상에서 본 발명의 실시예에 대하여 상세하게 설명하였지만 본 발명의 권리범위는 이에 한정되는 것은 아니고 다음의 청구범위에서 정의하고 있는 본 발명의 기본 개념을 이용한 당업자의 여러 변형 및 개량 형태 또한 본 발명의 권리범위에 속하는 것이다.도면 도면1 도면2 도면3 도면4 도면5 도면6 도면7 도면8 도면9 도면10 도면11 도면12 도면13 도면14 도면15 도면16 도면17 도면18 도면19 도면20 도면21 도면22"}
{"patent_id": "10-2023-0033824", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 실시예에 따른 하이브리드 방식의 분산 딥러닝 플랫폼 기술의 분산 컴퓨팅 하드웨어 및 분산 솔루션 배치도를 도시한다. 도 2는 본 발명의 실시예에 따른 하이브리드 방식의 분산 딥러닝 플랫폼 기술의 분산 컴퓨팅 하드웨어 및 분산 솔루션 구성도를 도시한다. 도 3은 본 발명의 실시예에 따른 인공지능기반 항공기동체 및 엔진 안전검사 플랫폼을 도시한다. 도 4는 본 발명의 실시예에 따른 하이브리드 방식의 분산 딥러닝 플랫폼 기술의 분산 컴퓨팅 성능평가를 위한 소요시간 실험결과 도시한다. 도 5는 본 발명의 실시예에 따른 하이브리드 방식의 분산 딥러닝 플랫폼 기술의 분산 컴퓨팅 성능평가를 위한 정확도 실험결과 도시한다. 도 6은 본 발명의 실시예에 따른 인공지능 및 RPN 기반 항공기동체 손상검출 알고리즘 및 설명가능인공지능 모 듈의 아키텍처를 도시한다. 도 7은 본 발명의 실시예에 따른 학습데이터 라벨링 및 AI 모델의 트레이닝 프로세스를 도시한다. 도 8는 본 발명의 실시예에 따른 인공지능 및 RPN 기반 항공기동체 손상검출 알고리즘의 플로우차트를 도시한다. 도 9는 본 발명의 실시예에 따른 인공지능 및 RPN 기반 항공기동체 손상검출 알고리즘 학습을 위한 데이터 수집 및 라벨링 플로우차트를 도시한다. 도 10은 본 발명의 실시예에 따른 항공기동체 손상 데이터셋의 예시이다. 도 11은 본 발명의 실시예에 따른 항공기엔진 및 블레이드 손상 데이터셋의 예시이다. 도 12는 본 발명의 실시예에 따른 항공기동체 및 엔진 손상데이터의 클래스를 도시한다. 도 13은 본 발명의 실시예에 따른 인공지능기반 항공기동체 안전검사 플랫폼 요구사항 수집서를 도시한다. 도 14은 본 발명의 실시예에 따른 인공지능기반 항공기동체 안전검사 플랫폼 요구사항 기능리스트를 도시한다. 도 15은 본 발명의 실시예에 따른 인공지능기반 항공기엔진 및 블레이드 안전검사 플랫폼 요구사항 수집서를 도 시한다. 도 16은 본 발명의 실시예에 따른 인공지능기반 항공기엔진 및 블레이드 안전검사 플랫폼 요구사항 기능리스트 를 도시한다. 도 17은 본 발명의 실시예에 따른 결함검출 목적의 AI 안전검사를 위한 메타러닝 아키텍처의 구성도이다. 도 18은 본 발명의 실시예에 따른 결함검출 목적의 AI 안전검사를 위한 메타러닝 개념도이다. 도 19는 본 발명의 실시예에 따른 하이브리드 방식의 분산 딥러닝 플랫폼 모듈의 동작 컴포넌트를 도시한다. 도 20은 본 발명의 실시예에 따른 하이브리드 방식의 분산 딥러닝 플랫폼 모듈의 옵티마이저 동작 개요를 도시 한다. 도 21은 본 발명의 실시예에 따른 하이브리드 방식의 분산 딥러닝 플랫폼 모듈의 GPU Node 간 파라미터 공유 및 업데이트 메커니즘을 도시한다. 도 22는 본 발명의 실시예에 따른 방법을 구현하기 위한 컴퓨터 시스템을 나타낸 블록도이다."}
