{"patent_id": "10-2023-0015459", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0123025", "출원번호": "10-2023-0015459", "발명의 명칭": "공황 장애 위험도 분석 방법 및 장치", "출원인": "포항공과대학교 산학협력단", "발명자": "이근배"}}
{"patent_id": "10-2023-0015459", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "분석장치가 대상자로부터 t시점의 질문 및 상기 t시점의 질문에 대한 대상자의 응답을 입력 받는 단계; 상기 분석장치가 상기 질문 및 상기 응답을 제1 모델에 입력하는 단계;상기 분석장치가 상기 질문 및 상기 응답을 처리한 제1 모델의 제1 은닉 벡터를 제2 모델에 입력하는 단계; 상기 분석장치가 t시점 이전의 질문 및 상기 t시점 이전의 질문에 대한 대상자의 응답을 처리한 제1 모델의 제2은닉 벡터를 제2 모델에 입력하는 단계; 및상기 분석장치가 상기 제1 은닉 벡터 및 상기 제2 모델의 출력 값을 기초로 상기 대상자를 정상 또는 위험으로분류하는 단계; 를 포함하되상기 제1 모델은 대화 상태를 추적하는 모델로서, 대화로부터 사전에 설정된 슬롯(Slot)의 값(Value)을 추출하는 모델이고, 상기 제2 모델은 상기 제1 은닉 벡터 값과 상기 제2 은닉 벡터 값 상호 간의 연관관계를 특징으로 사용하여 상기 t시점 이전의 질문 및 응답에 대한 문맥 벡터(Context Vector)을 계산하는 모델인, 공황 장애 위험도 분석 방법."}
{"patent_id": "10-2023-0015459", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서 상기 대상자를 정상 또는 위험으로 분류하는 것은 상기 제1 은닉 벡터 및 상기 제2 모델의 출력 값을 분류기에 넣어 상기 대상자의 위험 확률을 획득하고, 상기위험확률이 사전에 설정된 임계값 이상이라면 상기 대상자를 위험으로 분류하고, 상기 위험확률이 상기 임계값미만이라면 상기 대상자를 정상으로 분류하는 것인공황 장애 위험도 분석 방법."}
{"patent_id": "10-2023-0015459", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서상기 제2 은닉 벡터는 사전에 상기 t시점 이전의 질문 및 t시점 이전의 질문에 대한 응답을 제1 모델로 처리하여 데이터베이스에 저장된 것인 공황 장애 위험도 분석 방법."}
{"patent_id": "10-2023-0015459", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서 상기 제1 모델은 사전 학습(Pre-Training) 된 언어모델을 이용한 모델인 공황 장애 위험도 분석 방법."}
{"patent_id": "10-2023-0015459", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서 상기 사전 학습된 언어모델은 GPT(Generative Pre-trained Transformer)기반 모델인 공황 장애위험도 분석 방법."}
{"patent_id": "10-2023-0015459", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서 상기 제2 모델은 메모리 인코딩 레이어(Memory Encoding Layer) 및 어텐션 레이어(Attention Layer)을 포함하되공개특허 10-2024-0123025-3-상기 메모리 인코딩 레이어는 상기 제2 은닉 벡터에서 미리 설정된 과거 기간에 대응되는 값을 선택하여 인코딩하고, 상기 어텐션 레이어는 상기 메모리 인코딩 레이어의 출력 값과 상기 제1 은닉 벡터와의 연관관계를 기초로 어텐션 점수(Attention Score)를 계산한 뒤, 상기 메모리 인코딩 레이어의 출력 값에 반영하는공황 장애 위험도 분석 방법."}
{"patent_id": "10-2023-0015459", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6항에 있어서 상기 메모리 인코딩 레이어는 Bi-GRU(Bi-Directional Gated Recurrent Unit)을 포함하는 공황 장애 위험도 분석 방법."}
{"patent_id": "10-2023-0015459", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제6항에 있어서상기 어텐션 레이어는 Attention-GRU(Attention Gated Recurrent Unit)을 포함하는 공황 장애 위험도 분석 방법."}
{"patent_id": "10-2023-0015459", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "t시점의 질문 및 상기 t시점의 질문에 대한 대상자의 응답을 입력 받는 입력장치; 상기 질문 및 상기 응답을 제1 모델에 입력하고, 상기 질문 및 상기 응답을 처리한 제1 모델의 제1 은닉 벡터를제2 모델에 입력하고, 상기 t시점 이전의 질문 및 상기 t시점 이전의 질문에 대한 대상자의 응답을 처리한 제1모델의 제2 은닉 벡터를 제2 모델에 입력하고, 상기 제1 은닉 벡터 및 상기 제2 모델의 출력 값을 기초로 상기대상자를 정상 또는 위험으로 분류하는 연산장치; 및 상기 제1 모델 및 상기 제2 모델을 저장하는 저장장치; 를 포함하되상기 제1 모델은 대화 상태를 추적하는 모델로서, 대화로부터 사전에 설정된 슬롯(Slot)의 값(Value)을 추출하는 모델이고, 상기 제2 모델은 상기 제1 은닉 벡터 값과 상기 제2 은닉 벡터 값 상호 간의 연관관계를 특징으로 사용하여 상기 t시점 이전의 질문 및 응답에 대한 문맥 벡터(Context Vector)을 계산하는 모델인, 공황 장애 위험도 분석 장치."}
{"patent_id": "10-2023-0015459", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9항에 있어서 상기 대상자를 정상 또는 위험으로 분류하는 것은 상기 제1 은닉 벡터 및 상기 제2 모델의 출력 값을 분류기에 넣어 상기 대상자의 위험확률을 획득하고, 상기 위험확률이 사전에 설정된 임계값 이상이라면 상기 대상자를 위험으로 분류하고, 상기 위험확률이 상기 임계값 미만이라면 상기 대상자를 정상으로 분류하는 것인공황 장애 위험도 분석 장치."}
{"patent_id": "10-2023-0015459", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제9항에 있어서 상기 제1 모델은 사전 학습(Pre-Training) 된 언어모델을 이용한 모델인 공황 장애 위험도 분석 장치."}
{"patent_id": "10-2023-0015459", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제10항에 있어서 상기 사전 학습된 언어모델은 GPT(Generative Pre-trained Transformer)기반 모델인 공황 장애 위험도 분석 장치.공개특허 10-2024-0123025-4-청구항 13 제9항에 있어서 상기 제2 모델은 메모리 인코딩 레이어(Memory Encoding Layer) 및 어텐션 레이어(Attention Layer)를 포함하되,상기 메모리 인코딩 레이어는 상기 제2 은닉 벡터에서 미리 설정된 과거 기간에 대응되는 값을 선택하여 인코딩하고, 상기 어텐션 레이어는 상기 메모리 인코딩 레이어의 출력 값과 상기 제1 은닉 벡터와의 연관관계를 기초로 어텐션 점수(Attention Score)를 계산한 뒤, 상기 메모리 인코딩 레이어의 출력 값에 반영하는,공황 장애 위험도 분석 장치."}
{"patent_id": "10-2023-0015459", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제13항에 있어서 상기 메모리 인코딩 레이어는 Bi-GRU(Bi-Directional Gated Recurrent Unit)을 포함하는 공황 장애 위험도 분석 장치."}
{"patent_id": "10-2023-0015459", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제13항에 있어서상기 어텐션 레이어는 Attention-GRU(Attention Gated Recurrent Unit)을 포함하는 공황 장애 위험도 분석 장치."}
{"patent_id": "10-2023-0015459", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "공황 장애 위험도 분석 방법은 분석장치가 대상자로부터 t시점의 질문 및 상기 t시점의 질문에 대한 대상자의 응 답을 입력 받는 단계; 상기 분석장치가 상기 질문 및 상기 응답을 제1 모델에 입력하는 단계; 상기 분석장치가 상기 질문 및 상기 응답을 처리한 제1 모델의 제1 은닉 벡터를 제2 모델에 입력하는 단계; 상기 분석장치가 t시 점 이전의 질문 및 상기 t시점 이전의 질문에 대한 대상자의 응답을 처리한 제1 모델의 제2 은닉 벡터를 제2 모 델에 입력하는 단계; 및 상기 분석장치가 상기 제1 은닉 벡터 및 상기 제2 모델의 출력 값을 기초로 공황장애 위 험도를 계산하는 단계; 를 포함한다."}
{"patent_id": "10-2023-0015459", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "이하 설명하는 기술은 공황 장애의 위험도를 분석하는 방법 및 장치에 대한 것이다."}
{"patent_id": "10-2023-0015459", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "공황 장애(Panic disorder)는 예기치 않게 극심한 공포를 느끼는 증상이다. 공황 장애 환자는 가슴이 뛰거나 호 흡곤란 등의 증세를 가지고 있다. 공황 장애의 원인은 생물학적, 외부적, 개인적 경험 등이 있다고 알려져 있다. 공황 장애는 정신과 의사가 병력, 정신상태 등을 기준으로 진단한다. 정신과 의사는 필요시 심리 검사를 진행할 수 있다. 최근에는 IT기술의 발달로 메신저나 앱 등을 통해 공황 장애의 위험도를 분석하는 방법들이 개발되고 있다. 선행기술문헌 특허문헌 (특허문헌 0001) 한국 공개특허공보 10-2021-0009617"}
{"patent_id": "10-2023-0015459", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "챗봇(Chatbot)은 공황 장애 위험도를 분석하기 위해 이용되어 왔다. 종래 챗봇은 사용자가 질문에 맞는 선택지 를 고르는 방식으로 대화가 이루어졌다. 이러한 방식은 완전한 대화 형식으로 진행되었다고 보기 힘들다. 또한 이미 공황장애를 겪고 있는 사람을 상대로는 공황 장애 여부를 검출하는 하는 것은 어려웠다. 이하 설명하는 기술은 딥러닝을 이용한 인공지능 모델을 통해 실시간으로 공황 장애 위험도를 검출하는 방법을 제안한다."}
{"patent_id": "10-2023-0015459", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "공황 장애 위험도 분석 방법은 분석장치가 대상자로부터 t시점의 질문 및 상기 t시점의 질문에 대한 대상자의 응답을 입력 받는 단계; 상기 분석장치가 상기 질문 및 상기 응답을 제1 모델에 입력하는 단계; 상기 분석장치 가 상기 질문 및 상기 응답을 처리한 제1 모델의 제1 은닉 벡터를 제2 모델에 입력하는 단계; 상기 분석장치가 t시점 이전의 질문 및 상기 t시점 이전의 질문에 대한 대상자의 응답을 처리한 제1 모델의 제2 은닉 벡터를 제2 모델에 입력하는 단계; 및 상기 분석장치가 상기 제1 은닉 벡터 및 상기 제2 모델의 출력 값을 기초로 공황장애 위험도를 계산하는 단계; 를 포함한다."}
{"patent_id": "10-2023-0015459", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "이하 설명하는 기술을 이용하면 메신저 앱 등을 통해서도 실시간으로 공황장애를 진단할 수 있다. 이하 설명하는 기술을 이용하면 종래 심리상담센터에서 진행된 심리상담을 대체할 수 있다. 이하 설명하는 기술을 이용하면 대화 상태 추적 모델의 이용해 공황장애 위험도를 분석할 수 있다. 이하 설명하는 기술을 이용하면 빠르면서도 정확하게 공황장애 위험도를 분석할 수 있다."}
{"patent_id": "10-2023-0015459", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하 설명하는 기술은 다양한 변경을 가할 수 있고 여러 가지 실시예를 가질 수 있다. 명세서의 도면에 이하 설 명하는 기술의 특정 실시 형태가 기재될 수 있다. 그러나, 이는 이하 설명하는 기술의 설명을 위한 것이며 이하 설명하는 기술을 특정한 실시 형태에 대해 한정하려는 것이 아니다. 따라서 이하 설명하는 기술의 사상 및 기술 범위에 포함되는 모든 변경 물, 균등 물 내지 대체 물이 이하 설명하는 기술에 포함하는 것으로 이해되어야 한 다. 다양한 구성요소들을 설명하기 위해서 제1, 제2, A, B 등의 용어가 사용될 수 있다. 하지만 상기 용어는 단지 하나의 구성요소를 다른 구성요소들과 구별하기 위해서 사용될 뿐, 상기 용어로 해당 구성요소들을 한정하려고 하는 것이 아니다. 예를 들어, 이하 설명하는 기술의 권리 범위를 벗어나지 않으면서 제1 구성요소는 제2 구성 요소로 명명될 수 있고, 유사하게 제2 구성요소도 제1 구성요소로 명명될 수 있다. “및/또는” 이라는 용어는 복수의 관련된 기재된 항목들의 조합 또는 복수의 관련된 기재된 항목들 중의 어느 항목을 포함한다. 이하 사용되는 용어에서 단수의 표현은 문맥상 명백하게 다르게 해석되지 않는 한 복수의 표현을 포함하는 것으 로 이해되어야 하고, \"포함한다\" 등의 용어는 기재된 특징, 개수, 단계, 동작, 구성요소, 부분품 또는 이들을 조합한 것이 존재함을 의미하는 것이지, 하나 또는 그 이상의 다른 특징들이나 개수, 단계 동작 구성요소, 부분 품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 배제하지 않는 것으로 이해되어야 한다. 도면에 대한 상세한 설명을 하기에 앞서, 본 명세서에서의 구성부들에 대한 구분은 각 구성부가 담당하는 주기 능 별로 구분한 것에 불과함을 명확히 하고자 한다. 즉, 이하에서 설명할 2개 이상의 구성부가 하나의 구성부로 합쳐지거나 또는 하나의 구성부가 보다 세분화된 기능별로 2개 이상으로 분화되어 구비될 수도 있다. 그리고 이 하에서 설명할 구성 부 각각은 자신이 담당하는 주기능 이외에도 다른 구성부가 담당하는 기능 중 일부 또는 전 부의 기능을 추가적으로 수행할 수도 있으며, 구성 부 각각이 담당하는 주기능 중 일부 기능이 다른 구성부에의 해 전담되어 수행될 수도 있음은 물론이다. 또, 방법 또는 동작 방법을 수행함에 있어서, 상기 방법을 이루는 각 과정들은 문맥상 명백하게 특정 순서를 기 재하지 않은 이상 명기된 순서와 다르게 일어날 수 있다. 즉, 각 과정들은 명기된 순서와 동일하게 일어날 수도있고 실질적으로 동시에 수행될 수도 있으며 반대의 순서대로 수행될 수도 있다. 이하 설명하는 기술에서 대화 상태 추적(Dialogue State Tracking) 시스템은 목적 지향 대화 시스템의 핵심 부 분이다. 대화 상태 추적은 특정 목적을 달성하기 위한 시스템일 수 있다. 대화 상태 추적은 대화에서 표현된 사 용자의 목적을 추출할 수 있다. 이하 설명하는 기술에서 조기 위험 검출(Early Risk Detection) 시스템은 대화를 분석해 위험도를 검출하는 시 스템이다. 조기 위험 검출 시스템은 연속적으로 들어오는 입력을 바탕으로 위험도를 검출할 수 있다. 조기 위험 검출 시스템은 온라인 그루밍, 보이스 피싱, 정신 질환 위험군을 검출하는데 이용될 수 있다. 이하 공황 장애 위험도 분석장치(이하 분석장치)가 공황 장애의 위험도를 분석하는 전체적인 과정을 살펴본다. 도1은 분석장치가 공황장애 위험도를 분석하는 전체적인 과정을 보여준다. 분석장치는 대상자와 대화할 수 있다. 분석장치와 대상자가 대화한 정보를 대화 정보라고 할 수 있다. 대화 정보는 질문과 그에 대한 답변이 포함되어 있을 수 있다. 예를 들어 대화 정보는 분석장치가 대상자에게 질문한 내용을 포함할 수 있다. 또는 대화 정보는 대상자가 질문 내용에 답한 내용을 포함할 수 있다. 대화 정보는 대상자의 공황 장애 위험도를 분석하는데 필요한 정보를 포함할 수 있다. 분석장치는 과거에 대상자와 분석장치가 대화한 대화 정보를 입력 받을 수 있다. 과거는 t시점 이전의 시점일 수 있다. 예를 들어 t-1, t-2, …t-N시점일 수 있다. 분석장치는 현재 대상자와 분석장치가 대화한 대화 정보를 입력 받을 수 있다. 현재는 t시점의 시점일 수 있다. 분석장치는 입력 받은 대화 정보를 기초로 대상자의 공황 장애 위험도를 분석할 수 있다. 대화 정보는 과거에 대화한 대화 내용을 포함할 수 있다. 과거 대화 정보는 현재 시점을 기준으로 가장 최근에 이루어진 대화를 제외한 대화 내용을 포함할 수 있다. 일 실시예로 대화 정보는 과거 t-1, t-2, …t-N 시점의 대화 내용을 포함할 수 있다. 대화 정보는 현재 대화한 대화 내용을 포함할 수 있다. 현재 대화 정보는 현재 시점을 기준으로 가장 최근에 이 루어진 대화 내용을 포함할 수 있다. 일 실시예로 대화 정보는 현재 t시점의 대화 내용을 포함할 수 있다. 일 실시예로 대화 정보는 분석장치와 대상자가 턴(turn)을 주고받으며 대화한 내용을 포함할 수 있다. 예를 들 어 대화 정보는 첫번째 턴에 분석장치가 대상자에게 질문하고, 두번째 턴에 대상자가 질문에 답하고, 세번째 턴 에 분석장치가 대상자에게 질문하고, 네번째 턴에 대상자가 질문에 답하는 내용을 포함할 수 있다. 이 경우 첫 번째 턴의 질문과 두번째 턴의 답변은 현재 시점의 대화 정보라고 할 수 있다. 세번째 턴의 질문과 네번째 턴의 답변을 과거 시점의 대화 정보라고 할 수 있다. 과거 대화 정보는 데이터 베이스에 저장될 수 있다. 데이터 베이스에 저장된 과거 대화 정보는 분석장치에 입력 될 수 있다. 분석장치는 제1 모델 및 제2 모델을 이용해서 공황 장애 위험도를 분석할 수 있다. 제1 모델 및 제2 모델은 인공신경망으로 구축된 모델일 수 있다. 제1 모델은 대화 정보를 입력 받을 수 있다. 제1 모델은 현재 대화 정보로부터 제1 은닉 상태(Hidden state) 값을 생성할 수 있다. 제1 은닉 상태 값은 벡터 (vector)일 수 있다. 제1 모델은 과거 대화정보로부터 제2 은닉 상태 값을 생성할 수 있다. 제2 은닉 상태 값은 벡터일 수 있다. 제2 모델은 제1 모델이 생성한 제1 은닉 상태 값 및 제2 은닉 상태 값을 입력 받을 수 있다. 제2 모델은 입력 받은 정보를 기초로 대상자의 공황 장애 위험도에 대한 정보를 출력할 수 있다. 제1 모델 및 제2 모델에 대한 구체적인 내용은 아래에서 설명한다. 분석장치는 대상자의 공황장애 위험도를 확률로 출력할 수 있다. 또는 분석장치는 대상자의 공황장애 위험도를 기초로 대상자를 공황장애 환자로 분류할 수 있다. 이하 제1 모델 및 제2 모델에 대하여 설명한다. 도2은 몇몇 실시예에 따른 제1 모델 및 제2 모델의 예이다. 먼저 제1 모델에 대해서 살펴본다. 제1 모델은 목적 지향 대화 모델(Goal-oriented dialog, Task-oriented dialog)일 수 있다. 제1 모델은 목적을 달성하기 위해 대화 상태를 추적(Dialogue State Tracking)할 수 있다. 제1 모델은 대화정보에서 슬롯(Slot)에 해당하는 값(Value)을 추출할 수 있다. 슬롯은 목적 달성을 위해 대화 정보에서 어떠한 정보를 추적해야 하는지를 의미할 수 있다. 값은 대화(발화)에서 담고 있는 각 슬롯에 대응되 는 상세 정보일 수 있다. 제1 모델은 대화 정보를 입력 받을 수 있다. 대화 정보는 시스템의 행동(Previous System Action, At)을 포함할 수 있다. 시스템의 행동은 분석장치가 대상 자에게 질문한 내용일 수 있다. 시스템의 행동 At는 [ACTION][REQUEST]At[/ACTIOIN]일 수 있다. 대화 정보는 대상자의 발화(Current User Utterance, Ut)를 포함할 수 있다. 대상자의 발화는 대상자가 질문에 답한 내용일 수 있다. 대화 정보는 시스템의 행동(At)과 대상자의 발화(Ut)을 결합(Concatenate)한 정보를 것일 수 있다. 즉 대화 정보 는 At Ut [SEP] 일 수 있다. [SEP]는 GPT-2에서 입력을 구분하기 위한 특수 토큰 일 수 있다. 과거 대화 정보는 At-N Ut-N [SEP] 일 수 있다. 현재 대화 정보는 At Ut [SEP] 일 수 있다. 제1 모델은 사전 학습(Pre-training)된 모델을 이용할 수 있다. 제1 모델은 사전 학습된 모델을 전이학습(transfer learning)한 모델일 수 있다. 제1 모델은 종래 알려진 GTP(Generative Pre-trained Transformer)모델을 이용할 수 있다. 또는 제1 모델은 종 래 알려진 Ko-GTP(Korean GPT)모델을 이용할 수 있다. 제1 모델은 입력된 대화 정보를 기초로 은닉 상태(Hidden state) 값을 계산할 수 있다. 제1 모델의 은닉 상태 값은 제2 모델에 입력될 수 있다. 은닉 상태 값은 Belief state(Bt 를 포함할 수 있다. Belief state는 시간 t에서 슬롯 및 값에 대한 정보를 포 함할 수 있다. 즉 은닉 상태 값은 제1 모델이 추적한 대화 상태 정보를 포함할 수 있다. 예를 들어 슬롯이 K개라면 Belief state(Bt)는 {(Sk, VtK)｜1 ≤ k ≤ K}일 수 있다. 이때 서로 다른 K개의 액션 A = A1, …, Ak를 가질 수 있다. 과거 대화 정보에 대한 제1 모델의 은닉 상태 값은 제2 은닉 상태 값이라고 할 수 있다. 다시 말하면 과거 대화 정보가 제1 모델에 입력되면 제2 은닉 상태 값이 계산될 수 있다. 예를 들어 현재 시간이 t라고 한다면 제2 은닉 상태 값은 t-1, t-2, ..., t-N 일 때의 대화 정보에 대한 은닉 상태 값(Ht-1, Ht-2, ..., Ht-N)을 포함할 수 있다 (N은 1이상의 자연수). 현재 대화 정보에 대한 제1 모델의 은닉 상태 값은 제1 은닉 상태 값이라고 할 수 있다. 다시 말하면 현재 대화 정보가 제1 모델에 입력되면 제1 은닉 상태 값이 계산될 수 있다. 예를 들어 현재 시간이 t라고 한다면 제1 은닉 상태 값은 t일때의 대화 정보에 대한 은닉 상태 값(Ht)을 포함할 수 있다. 제2 은닉 상태 값은 데이터 베이스에 저장될 수 있다. 제2 은닉 상태 값은 현재 대화 정보가 입력되면 제2 모델 에 입력될 수 있다. 제2 은닉 상태 값은 현재 대화 정보가 입력되기 전에 사전에 계산될 수 있다. 이를 통해 분 석장치가 한 번에 계산하여야 하는 양을 줄일 수 있다. 이하 제2 모델에 대하여 살펴본다. 제2 모델은 조기 위험 검출(Early Risk Detection) 모델일 수 있다. 제2 모델은 연속적으로 들어오는 정보를 바 탕으로 공황 장애 위험을 검출하는 모델일 수 있다. 제2 모델은 빠르고 정확하게 공황 장애 위험을 검출할 수 있다. 제2모델은 모든 문장을 보고 문서를 분류하는 문서 분류모델과는 다를 수 있다. 제2 모델은 제1 모델의 은닉 상태 값을 입력 받을 수 있다. 다시 말해 제2 모델은 대화 정보 및 대화 정보에 대 한 슬롯-값에 대한 정보를 입력 받을 수 있다. 제2 모델은 메모리 인코더 레이어(Memory Encoder Layer), 어텐션 레이어(Attention layer), 분류기 (Classifier) 및 결정 모듈(Decision Module)를 포함할 수 있다. 또는 제2 모델은 메모리 인코더 레이어 및 어 텐션 레이어만 포함하고 분류기와 결정 모듈은 별도의 모델로 볼 수도 있다. 메모리 인코더 레이어는 입력 받은 정보를 임베딩 하는 레이어 일 수 있다. 메모리 인코더 레이어는 Bi-GRU(Bi-Directional Gated Recurrent Unit)을 이용해서 입력 받은 정보를 임베딩 하는 레이어 일 수 있다. 메모리 인코더는 제2 은닉 상태 값을 받을 수 있다. 메모리 인코더는 제2 은닉 상태 값을 입력 받아 임베딩 하 는 레이어 일 수 있다. 메모리 인코더는 과거 대화 정보 중 얼마나 가져갈 것인지 결정하는 레이어 일 수 있다. 다시 말해 메모리 인코 더는 제2 은닉 상태 값에서 몇 개를 가져갈 것인지 결정하는 레이어일 수 있다. 예를 들어 메모리 인코더는 t-1, t-2, …t-N에 대한 제2 은닉 상태 값 중에서 t-1, t-2, t-3 만을 선택하여 임 베딩 할 수 있다. 다시 말해 메모리 인코더는 Ht-1, Ht-2, Ht-3만을 이용해 임베딩 할 수 있다． 메모리 인코더는 제2 은닉 상태 값을 보존할 수 있게 임베딩 결과에 입력 받은 제2 은닉 상태 값을 더할 수 있다． 수학식1은 메모리 인코더에서 출력되는 값(Mt)에 대한 식이다. 수학식 1"}
{"patent_id": "10-2023-0015459", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "Ht-window-1+k 은 제2 은닉 상태 값을 일 수 있다. Windows는 몇 개의 제2 은닉상태 값을 가져갈 것인지 결정하는 변수일 수 있다. 어텐션 레이어는 현재 시점의 대화 정보와 과거 시점의 대화 정보와의 연관관계를 계산할 수 있다. 어텐션 레이 어는 계산된 연관관계를 특징으로 사용하여 과거 시점의 대화정보에 대한 문맥 벡터(context vector)을 만드는 레이어 일 수 있다. 어텐션 레이어는 제1 은닉 상태 값과 메모리 인코더가 출력하는 값과의 연관관계를 계산할 수 있다. 어텐션 레 이어는 계산된 연관관계를 메모리 인코더의 출력 값에 반영할 수 있다. 이를 통해 현재 시점의 대화 정보와 과 거 시점의 대화정보 각각에 대한 중요도를 계산할 수 있다. 어텐션 레이어는 메모리 인코더가 출력하는 값(Mt)을 입력 받을 수 있다. 어텐션 레이어는 GRU(Gated Recurrent Unit)기반의 모델일 수 있다. 수학식2는 어텐션 레이어가 연관관계를 반영할 때 이용되는 식이다. 수학식 2"}
{"patent_id": "10-2023-0015459", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "ak는 제1 은닉 상태 값(Ht)과 메모리 인코더에 출력된 값(Mk)과 연관관계를 계산한 것에 소프트 맥스(SoftMax)를 한 것일 수 있다. hk는 GRU의 각 단계마다 출력되는 값을 의미할 수 있다. Ct는 어텐션 레이어가 출력하는 최종 값일 수 있다. 분류기는 제1 은닉 상태 값(Ht)와 어텐션 레이어의 출력 값(Ct)을 입력 받을 수 있다. 분류기는 입력 받은 정보를 선형 레이어(Linear Layer)과 SoftMax함수를 거쳐 위험확률을 계산할 수 있다. 분류기는 위험확률을 기초로 대상자를 공황 장애 위험자로 분류할 수도 있다. 결정 모듈은 더 대화를 진행할지 아니면 위험하다고 판단하고 대화를 중단할 것인지 결정하는 모듈일 수 있다. 결정 모듈은 분류기의 출력 값을 입력 받을 수 있다. 결정 모듈은 다음 대화 정보를 추가적으로 받을지 결정할 수 있다. 결정 모듈은 위험 확률이 미리 설정된 기준보다 높을 경우 대상자의 상태가 위험하다고 판단할 수 있다. 이 경 우 결정 모듈은 정지 결정을 할 수 있다. 정지 결정이 내려지면 분석 장치는 더 이상 새로운 대화 정보를 입력 받지 않을 수 있다. 결정 모듈은 분석장치와 대상자의 대화가 사전에 설정된 일정 횟수 이상 되어야 대화를 중단할 수 있다. 이는 너무 빠른 결정을 내리는 것을 방지하기 위함이다. 이를 위해서 종래 사용되던 손실함수를 변형해서 사용할 수 있다. 구체적인 내용은 아래에서 설명한다. 결정 모듈은 위험 확률이 미리 설정된 기준보다 낮을 경우 다음 대화 정보를 입력 받을 수 있다. 다시 말해 위 험이 없다고 판단하고 대화를 더 진행해 나갈 수 있다. 이하 모델을 학습시키는데 사용된 손실함수에 대해 살펴본다. 일반적으로 사용되는 (NLL)Negative Log Likelihood을 손실함수로 이용하면 모델이 너무 빠르게 결정을 할 수도 있다. 너무 빠른 결정을 하게 되면 모델은 잘못된 예측을 할 수 있다. 예를 들어 분석장치가 공황 장애를 판단하는데 3번의 대화를 진행하는 경우가 있을 수 있다. 3번의 대화만으로 대상자가 공황 장애 위험성이 있는지 판단하는 것은 쉽지 않다. 따라서 몇 개의 대화만으로 분석장치가 대상자 에게 공황 장애 위험도가 있는지 판단하는 것을 방지할 필요가 있다. 또는 NLL을 손실함수로 이용하면 모델이 너무 느리게 결정을 할 수 있다. 모델이 너무 느린 결정을 하게 되면 신속함을 떨어질 수 있다. 예를 들어 분석장치가 공황 장애를 판단하는데 100번의 대화를 진행하는 경우가 있을 수 있다. 이 경우 공황 장 애 위험도를 판단하는 정확도는 높을 수 있다. 하지만 빠르게 공황 장애를 판단해야 하지 못하는 문제점이 있을 수 있다. 따라서 이러한 문제점을 해결할 수 있는 손실함수가 필요하다. 수학식 3은 대화 상태 추적(Dialogue State Tracking, DST)을 학습시키는데 이용되는 손실함수(LossDST)이다. 다 시 말하면 수학식 3는 제1 모델을 학습시키는데 이용되는 손실함수 일 수 있다. 수학식 3"}
{"patent_id": "10-2023-0015459", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "Bt는 Belief State을 의미할 수 있다. At는 시스템의 액션을 의미할 수 있다. 수학식4는 조기 위험 검출(Early Risk Detection, ERD)을 학습시키는데 이용되는 손실함수(LossERD)이다. 다시 말하면 수학식 4는 제2 모델을 학습시키는데 이용되는 손실함수 일 수 있다. 수학식 4"}
{"patent_id": "10-2023-0015459", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "수학식4에서 d는 위험 결정까지 확인한 문장의 개수를 의미할 수 있다. 예를 들어 한 문장만 참조할 경우(d=1) 패널티는 0이 될 수 있다. 또는 전체 문장의 50%만 참조할 경우 패널티 는 0.5가 될 수 있다. 이를 위해서 p값을 조절할 수 잇다. 정확도의 저하를 막기 위해, 손실함수는 빠른 예측의 오답에 대해서는 패널티를 더 크게 부여할 수 있다. 이를 통해 분석장치가 너무 빠른 결정을 내리는 것을 방지할 수 있다. 수학식5는 대화 상태 추적 모델과 조기 위험 검출 모델의 결합한 모델의 손실함수(Losstotal)일 수 있다. 다시 말 해 제1 모델 과 제2 모델을 결합한 모델의 손실함수 일 수 있다. 수학식 5"}
{"patent_id": "10-2023-0015459", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "수학식5에서 는 0과 1사이 값을 갖는 하이퍼파라미터 일 수 있다. α는 조기 위험 검출 시스템의 과적합을 방 지할 수 있다. 왜냐하면 이진 분류를 하는 제2 모델과 비교할 때 제1 모델은 슬롯과 값을 추출해야 하기 때문에 학습이 더 까 다로울 수 있기 때문이다. 이하 모델의 성능을 평가한 결과를 살펴본다. 도3는 몇몇 실시예에 제1 모델이 출력한 값을 보여 준다. 제1 모델은 대화 정보를 입력 받을 수 있다. 도3의 대화정보는 분석장치가 대상자에게 질문한 내용 및 대상자의 답변 내용을 포함한다. 도3 (A)에서 분석장치가 질문한 내용은 “안녕하세요, 무슨 일이 있으셨나요?”일 수 있다. 도3 (A)에서 대상자 가 답변한 내용은 “엘리베이터를 타는 것이 힘들어요”일 수 있다. 도3(A)에서 제1 모델은 대화 정보에서 “사건” 슬롯에 대한 값인 “엘리베이터를 타는 것”을 추출하였다. 도3 (B)에서 분석장치가 질문한 내용은 “엘리베이터 타는 것이 어떻게 힘드시죠?”일 수 있다. 도3 (B)에서 대 상자가 답변한 내용은 “엘리베이터를 타면 무서워요”일 수 있다. 도3(B)에서 제1 모델은 대화 정보에서 “감정” 슬롯에 대한 값인 “무서워요”를 추출하였다. 표1은 몇몇 실시예에 따른 분석장치의 성능을 평가한 예이다. 표1은 분석장치가 대화 상태를 얼마나 잘 추적하는지, 조기 위험을 얼마나 잘 검출하는지를 평가한 예일 수 있 다. 표 1 JGA(%) Micro F1(%) Latency F1(%) Model 1 87.4 94.0 81.1 Model 2 84.3 52.9 3.3 표1에서 Model 1은 [Previous System Action][Current User Utterance][Belief state]에 해당하는 은닉층을 제 2 모델에 넣은 결과 일 수 있다. 다시 말해 Model1은 제1 모델이 계산한 슬롯 및 값에 대한 정보를 제2 모델에 입력한 것일 수 있다. Model 2는 [Previous System Action][Current User Utterance]을 입력한 결과일 수 있다. 다시 말해 Model2는 제2 모델이 계산한 슬롯 및 값에 대한 정보를 제2 모델에 입력하지 않는 것일 수 있다. JGA(Joint Goal Accuracy)는 대화 상태 추적을 평가하는 지표일 수 있다. 다시 말해 JGA는 제1 모델의 성능을 평가하는 지표일 수 있다. JGA는 각 턴에 대하여 모델이 예측한 모든 슬롯과 값이 정확한지 평가하는 지표일 수 있다. JGA는 모델이 예측 한 모든 슬롯과 값이 실제 슬롯과 값 쌍에 일치한 수를 전체 대화 수로 나누어 계산될 수 있다. Micro F1 및 Latency F1은 조기 위험 검출의 정확성을 측정하기 위한 지표일 수 있다. 다시 말해 Micro F1 및 Latency F1은 제2 모델의 성능을 평가하는 지표일 수 있다. Micro F1은 결정 모듈이 정지 판단을 내릴 때 까지의 턴 만을 사용하여 검출의 정확성을 측정한 것일 수 있다. Latency F1은 검출의 신속성을 측정하기 위한 지표일 수 있다. 수학식 6은 Latency F1을 계산하는 식일 수 있다. 수학식 6"}
{"patent_id": "10-2023-0015459", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 7, "content": "수학식 6에서 Penalty는 [0,1)의 범위에 해당하는 값일 수 있다. Penalty는 참조하는 문장의 수가 많은 수록 커 질 수 있다. 수학식 6에서 Speed는 Penalty의 중앙값일 수 있다. 수학식6에서 Latency F1은 micro F1과 Speed 의 곱으로 정의될 수 있다. JGA는 Model 1 및 Model 2가 많은 차이가 나지 아니하였다. 즉 대화 상태 추적의 성능은 양 모델이 비슷한 것을 확인할 수 있다. Micro F1 및 Latency F1은 Model 1이 Model 2 보다 높았다. 즉 조기 위험 검출의 성능은 Model 1이 더 좋은 것 을 확인할 수 있다. 따라서 Belief state는 공황 장애 조기 위험을 검출할 수 있는 유의미한 정보를 포함하고 있음을 확인할 수 있 다. 다시 말해 제2 모델에 제1 모델의 은닉 상태 값을 입력하면 제2 모델의 성능이 향상되는 것을 확인할 수 있 다. 이하 분석장치의 구성에 대하여 설명한다. 도4은 몇몇 실시예에 따른 분석장치의 예이다. 분석장치은 도1에서 설명한 분석장치에 해당할 수 있다. 분석장치은 PC, 노트북, 스마트기기, 서버 또는 데이터처리 전용 칩셋 등과 같이 물리적으로 다양한 형태 로 구현될 수도 있다. 분석장치은 입력장치, 저장장치, 연산장치, 출력장치, 인터페 이스 장치 및 통신장치를 포함할 수 있다. 분석장치는 대화장치를 포함할 수 있다. 대화 장치는 대상자와 대화를 하는 장치일 수 있다. 대화장치는 대상자에게 질문할 질문 정보를 생성할 수 있다. 입력장치는 일정한 명령 또는 데이터를 입력 받는 인터페이스 장치(키보드, 마우스, 터치스크린 등)를 포 함할 수도 있다. 입력장치는 별도의 저장장치(USB, CD, 하드디스크 등)을 통하여 정보를 입력 받는 구성을 포함할 수도 있다. 입력장치는 입력 받는 데이터를 별도의 측정장치를 통하여 입력 받거나, 별도의 DB을 통하여 입력 받을 수도 있다. 입력장치는 유선 또는 무선 통신을 통해 데이터를 입력 받을 수 있다. 입력 장치는 대화 정보를 입력 받을 수 있다. 입력장치는 t시점의 질문 및 t시점의 응답을 입력받을 수 있다. 입력장치는 t시점 이전의 질문 및 t시점 이전의 응답을 입력받을 수 있다. 저장장치는 입력장치을 통해 입력 받은 정보를 저장할 수 있다. 저장장치는 연산장치가 연 산하는 과정에서 생성되는 정보를 저장할 수 있다. 즉 저장장치는 메모리를 포함할 수 있다. 저장장치 는 연산장치가 계산한 결과를 저장할 수 있다. 저장장치는 제1 모델 및 제2 모델을 저장할 수 있다. 제1 모델 및 제2 모델은 전술한 모델일 수 있다. 저장장치는 입력 받은 대화 정보를 저장할 수 있다. 저장장치는 제1 모델이 계산한 결과를 저장할 수 있다. 저장장치는 대화 정보에 대한 제2 히든 상태 값을 저장할 수 있다. 저장장치는 제2 히든 상태 값을 저장한 데이터베이스를 저장할 수 있다. 연산장치는 대화 정보를 제1 모델에 입력할 수 있다. 대화 정보는 현재 또는 과거의 대화 정보를 포함할 수 있다. 제1 모델은 전술한 제1 모델일 수 있다. 제1 모델은 대화 상태를 추적하는 모델일 수 있다. 연산장치(430는 현재 대화 정보를 처리한 제1 모델의 제1 은닉 벡터를 제2 모델에 입력할 수 있다. 연산장치는 과거 대화 정보를 처리한 제1 모델의 제2 은닉 벡터를 제2 모델에 입력할 수 있다. 연산장치는 제1 은닉 벡터 및 제2 모델의 출력 값을 기초로 대상자를 정상 또는 위험으로 분류할 수 있다. 연산장치는 제1 은닉 벡터 및 제2 모델의 출력값을 기초로 대상자의 위험확률을 계산할 수 있다. 연산장치 는 위험확률이 임계값 이상인지 미만인지를 기준으로 대상자를 정상 또는 위험으로 분류할 수 있다. 연산장치는 제1 모델을 이용해서 대화정보로부터 사전에 설정된 슬롯의 값을 추출할 수 있다. 연산장치 는 제2 모델을 이용해서 제1 은닉 상태 값과 제2 은닉 상태 값 상호간의 연관관계를 특징으로 사용하여 문 맥벡터(context vector)을 만들 수 있다. 출력장치는 일정한 정보를 출력하는 장치가 될 수도 있다. 출력장치은 데이터 과정에 필요한 인터페 이스, 입력된 데이터, 분석결과 등을 출력할 수도 있다. 출력장치은 디스플레이, 문서를 출력하는 장치, 등과 같이 물리적으로 다양한 형태로 구현될 수도 있다. 인터페이스 장치는 외부로부터 일정한 명령 및 데이터를 입력 받는 장치일 수 있다. 인터페이스 장치(45 0)는 물리적으로 연결된 입력 장치 또는 외부 저장장치로부터 대화 정보를 입력 받을 수 있다. 인터페이스 장치 는 분석장치를 제어하기 위한 제어신호를 입력 받을 수 있다. 인터페이스 장치는 연산장치(43 0)가 연산한 결과를 출력할 수 있다. 통신장치는 유선 또는 무선 네트워크를 통해 일정한 정보를 수신하고 전송하는 구성을 의미할 수 있다. 통 신장치는 대화 정보 정보를 수신할 수 있다. 통신장치는 분석장치를 제어하는데 필요한 제어 신호를 수신할 수 있다. 통신장치는 분석장치가 분석한 결과를 전송할 수 있다. 전술한 공황 장애 위험도 분석 방법은 컴퓨터에서 실행될 수 있는 실행가능한 알고리즘을 포함하는 프로그램(또 는 어플리케이션)으로 구현될 수 있다. 상기 프로그램은 일시적 또는 비일시적 판독 가능 매체(non-transitory computer readable medium)에 저장되어 제공될 수 있다. 비일시적 판독 가능 매체란 레지스터, 캐쉬, 메모리 등과 같이 짧은 순간 동안 데이터를 저장하는 매체가 아니 라 반영구적으로 데이터를 저장하며, 기기에 의해 판독(reading)이 가능한 매체를 의미한다. 구체적으로는, 상 술한 다양한 어플리케이션 또는 프로그램들은 CD, DVD, 하드 디스크, 블루레이 디스크, USB, 메모리카드, ROM (read-only memory), PROM (programmable read only memory), EPROM(Erasable PROM, EPROM) 또는 EEPROM(Electrically EPROM) 또는 플래시 메모리 등과 같은 비일시적 판독 가능 매체에 저장되어 제공될 수 있 다. 일시적 판독 가능 매체는 스태틱 램(Static RAM，SRAM), 다이내믹 램(Dynamic RAM，DRAM), 싱크로너스 디램 (Synchronous DRAM，SDRAM), 2배속 SDRAM(Double Data Rate SDRAM，DDR SDRAM), 증강형 SDRAM(Enhanced SDRAM ，ESDRAM), 동기화 DRAM(Synclink DRAM，SLDRAM) 및 직접 램버스 램(Direct Rambus RAM，DRRAM) 과 같은 다양 한 RAM을 의미한다. 본 실시례 및 본 명세서에 첨부된 도면은 전술한 기술에 포함되는 기술적 사상의 일부를 명확하게 나타내고 있 는 것에 불과하며, 전술한 기술의 명세서 및 도면에 포함된 기술적 사상의 범위 내에서 당업자가 용이하게 유추할 수 있는 변형 예와 구체적인 실시례는 모두 전술한 기술의 권리범위에 포함되는 것이 자명하다고 할 것이다."}
{"patent_id": "10-2023-0015459", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도1은 분석장치가 대화를 분석하는 전체적인 과정을 보여준다. 도2는 몇몇 실시예에 따른 제1 모델 및 제2모델의 예이다. 도3은 몇몇 실시예에 따른 제1 모델 출력 값의 예이다. 도4는 몇몇 실시예에 따른 분석장치 구성의 예이다."}
