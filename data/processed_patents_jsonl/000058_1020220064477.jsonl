{"patent_id": "10-2022-0064477", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0164837", "출원번호": "10-2022-0064477", "발명의 명칭": "AI 기반의 스피커 시스템", "출원인": "조홍석", "발명자": "조홍석"}}
{"patent_id": "10-2022-0064477", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "주변 소음 인식 시, 소음 방향으로 영상촬영 동작을 수행하고, AI 객체인식기법을 통해 촬영영상 내 소음근원대상을 인식하고, 상기 촬영영상에 대한 비전 컴퓨팅을 통해 상기 소음근원대상으로부터 시선을 받는 아이컨택 및상기 소음근원대상의 특정 행동 중 적어도 하나를 인식하면, 상기 소음근원대상으로 대화를 시도하여 AI 음성챗봇을 수행하는 AI 대화 로봇; 및상기 AI 대화 로봇으로부터 상기 촬영영상을 통한 상기 소음근원대상의 인식결과 및 상기 AI 음성 챗봇의 대화내용을 수신하여 온라인 강화학습을 통해 상기 소음근원대상의 인식 및 상기 AI 음성 챗봇의 각 기능을 업그레이드하기 위한 AI 서비스 서버를 포함하는 것을 특징으로 하는 AI 기반의 스피커 시스템."}
{"patent_id": "10-2022-0064477", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1 항에 있어서,상기 AI 대화 로봇은,다수의 지향성 마이크를 통해 외부로부터 입력되는 소음발생여부와 소음발생방향을 각각 인식하고, 사용자의 음성을 입력 받는 마이크부;상기 AI 음성 챗봇을 위한 음성을 출력하는 스피커부;상기 마이크부를 통한 소음 인식 시 작동되어 주변 촬영을 통해 상기 촬영영상을 생성하는 카메라부;AI 객체인식기법을 통해 상기 촬영영상 내 사용자를 인식하되, 미리 저장된 사용자와 저장되어 있지 않은 새로운 사용자를 구분하여 인식하는 객체 인식부;상기 객체 인식부를 통해 인식된 사용자와의 거리가 미리 설정된 기준거리 이상인 경우 비전 컴퓨팅의 페이스메시 탐지(face mesh detection) 기능을 이용하여 사용자 얼굴의 방향 및 각도를 검출하여 사용자의 시선을 인식하고, 사용자와의 거리가 상기 기준거리 미만인 경우 비전 컴퓨팅의 홍채인식을 통해 사용자의 홍채방향을 검출하여 사용자의 시선을 인식하는 사용자 시선 인식부;상기 촬영영상을 대상으로 비전 컴퓨팅의 포즈 탐지(pose detection) 기능 또는 개체 탐지(Object Detection)기능을 수행하여 사용자의 특정행동을 인식하는 사용자 행동 분석부; 및상기 사용자 시선 인식부를 통해 사용자의 시선 또는 상기 사용자 행동 인식부를 통해 사용자의 특정행동이 인식되는 경우, 미리 설정된 음성 멘트를 상기 스피커부로 전달하여 사용자와의 대화를 시도한 후 사용자의 음성응답이 있는 경우 상기 AI 음성 챗봇을 수행하는 AI 음성 챗봇부를 포함하는 것을 특징으로 하는 AI 기반의 스피커 시스템."}
{"patent_id": "10-2022-0064477", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2 항에 있어서,상기 AI 대화 로봇은,상기 객체 인식부를 통해 사용자가 인식되지 않으면, 상기 마이크부를 통해 인식된 소음발생방향에 따른 상기카메라부의 회전 및 상기 AI 대화 로봇의 위치이동 중 적어도 하나의 동작을 제어하는 로봇 동작 제어부를 더포함하는 것을 특징으로 하는 AI 기반의 스피커 시스템.공개특허 10-2023-0164837-3-청구항 4 제3 항에 있어서,상기 AI 음성 챗봇부는,상기 사용자 시선 인식부를 통한 사용자의 시선 또는 상기 사용자 행동 인식부를 통한 특정행동 인식 여부에 따라, 미리 설정된 음성 멘트를 상기 스피커부로 전달하여 사용자와의 대화를 시도하여 상기 AI 음성 챗봇을 실행하거나, 주변 소음을 인식하는 초기 상태로 복귀하도록 제어하는 AI 음성 챗봇 활성화 제어부;상기 마이크부를 통해 입력된 음성데이터를 텍스트데이터로 변환하는 STT(Speech To Text) 변환부;상기 텍스트데이터를 분석하되, 사용자의 음성이 입력된 시점에서 사용자를 촬영한 영상이 있는 경우 미리 정의된 딥러닝 모델을 이용하여 해당 영상 내 사용자의 감정 및 상황을 각각 분류하고, 그 분류 결과를 상기 텍스트데이터와 함께 파싱 및 자연어 처리를 통해 해석하고, 그 해석 결과에 따른 응답데이터를 도출하여 제공하는 응답데이터 제공부; 및상기 응답데이터를 음성데이터로 변환하여 상기 스피커부로 전달하는 TTS(Text To Speech) 변환부를 포함하는것을 특징으로 하는 AI 기반의 스피커 시스템."}
{"patent_id": "10-2022-0064477", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4 항에 있어서,상기 AI 음성 챗봇 활성화 제어부는,상기 사용자 시선 인식부를 통한 사용자의 시선 인식이 미리 설정된 시간 이상으로 유지되면, 미리 설정된 음성멘트를 상기 스피커부로 전달하여 사용자와의 대화를 시도하고,상기 사용자 시선 인식부를 통한 사용자의 시선 인식이 미리 설정된 시간 미만으로 유지되면, 상기 AI 음성 챗봇부를 동작을 종료하고, 상기 마이크부를 통한 주변 소음 인식 준비 상태로 전환되도록 하는 것을 특징으로 하는 AI 기반의 스피커 시스템."}
{"patent_id": "10-2022-0064477", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제4 항에 있어서,상기 사용자 시선 인식부는,상기 스피커부를 통한 상기 음성데이터의 출력종료시점마다 사용자의 시선 인식을 수행하고,상기 AI 음성 챗봇부는,AI 음성 챗봇을 수행하는 중에 상기 사용자의 시선 인식부를 통해 사용자의 시선이 인식되면 상기 AI 음성 챗봇을 유지하고, 사용자의 시선이 인식되지 않으면 상기 음성 AI 챗봇을 종료하는 것을 특징으로 하는 AI 기반의스피커 시스템."}
{"patent_id": "10-2022-0064477", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 AI 기반의 스피커 시스템에 관한 것으로, 해결하고자 하는 과제는 사용자의 대화 의도를 먼저 파악하 여 사용자에게 보다 사람친화적인 선재 대응이 가능하며, 이에 따른 대화 로봇에 대한 친밀감을 향상시키는데 있 다. (뒷면에 계속)"}
{"patent_id": "10-2022-0064477", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명의 실시예는 AI 기반의 스피커 시스템에 관한 것이다."}
{"patent_id": "10-2022-0064477", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "일반적으로 AI 스피커는, 자연언어 처리 등 인공지능을 이용하여 사용자의 명령을 이해하고, 빅데이터 등을 이 용하여 데이터 처리를 하여 사용자의 명령에 대한 응답을 소리로 출력하는 인공지능 시스템이다.이러한 인공지능 스피커(혹은 인공지능 비서)는 음성인식, 클라우드, 인공지능 기술을 활용하여 사용자의 음성 을 인식하고 의사소통을 하는 장치이다. 이 의사 소통을 통해 인공지능 스피커는 사물인터넷(IoT) 기능이 있는 주변 기기(조명, 온도조절, 가스밸브 등)를 제어할 수 있고 사용자가 희망하는 음악을 재생할 수도 있으며 각종 정보를 사용자에게 제공할 수도 있다. 인공지능 스피커를 활용하려면 먼저 호출어(wake-up-word)를 들려주어 인공지능 스피커를 리퀘스트 대기모드로 만들어야 한다. 그리고 나서 음성으로 명령을 내리거나 질문을 하면 인공지능 스피커는 광대역 네트워크를 통해 음성을 서버로 전달하고, 서버는 자연어를 컴퓨터가 인식할 수 있는 언어로 해석하여 인공지능 스피커가 제공할 서비스를 알려준다. 그러나, 종래 인공지능 스피커는 사용자가 해당 스피커와의 대화를 시도하기 위한 별도의 음성 명령 또는 버튼 이나 터치를 통해 먼저 입력해주어야 함에 따라 최근 인공지능 스피커를 탑재하여 구현된 반려 로봇의 경우 사 람 친화적인 대응이 미흡하다는 단점이 있다. 선행기술문헌 특허문헌 (특허문헌 0001) 공개특허공보 제10-2020-0117712호(공개일자: 2020년10월14일) (특허문헌 0002) 등록특허공보 제10-2346158호(등록일자: 2021년12월28일)"}
{"patent_id": "10-2022-0064477", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명의 실시예는, 사용자의 대화 의도를 먼저 파악하여 사용자에게 보다 사람친화적인 선재 대응이 가능하며, 이에 따른 대화 로봇에 대한 친밀감을 향상시킨 AI 기반의 스피커 시스템을 제공한다."}
{"patent_id": "10-2022-0064477", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 실시예에 따른 AI 기반의 스피커 시스템은, 주변 소음 인식 시, 소음 방향으로 영상촬영 동작을 수행 하고, AI 객체인식기법을 통해 촬영영상 내 소음근원대상을 인식하고, 상기 촬영영상에 대한 비전 컴퓨팅을 통 해 상기 소음근원대상으로부터 시선을 받는 아이컨택 및 상기 소음근원대상의 특정 행동 중 적어도 하나를 인식 하면, 상기 소음근원대상으로 대화를 시도하여 AI 음성 챗봇을 수행하는 AI 대화 로봇; 및 상기 AI 대화 로봇으 로부터 상기 촬영영상을 통한 상기 소음근원대상의 인식결과 및 상기 AI 음성 챗봇의 대화내용을 수신하여 온라 인 강화학습을 통해 상기 소음근원대상의 인식 및 상기 AI 음성 챗봇의 각 기능을 업그레이드하기 위한 AI 서비 스 서버를 포함한다. 또한, 상기 AI 대화 로봇은, 다수의 지향성 마이크를 통해 외부로부터 입력되는 소음발생여부와 소음발생방향을 각각 인식하고, 사용자의 음성을 입력 받는 마이크부; 상기 AI 음성 챗봇을 위한 음성을 출력하는 스피커부; 상 기 마이크부를 통한 소음 인식 시 작동되어 주변 촬영을 통해 상기 촬영영상을 생성하는 카메라부; AI 객체인식 기법을 통해 상기 촬영영상 내 사용자를 인식하되, 미리 저장된 사용자와 저장되어 있지 않은 새로운 사용자를 구분하여 인식하는 객체 인식부; 상기 객체 인식부를 통해 인식된 사용자와의 거리가 미리 설정된 기준거리 이 상인 경우 비전 컴퓨팅의 페이스 메시 탐지(face mesh detection) 기능을 이용하여 사용자 얼굴의 방향 및 각도 를 검출하여 사용자의 시선을 인식하고, 사용자와의 거리가 상기 기준거리 미만인 경우 비전 컴퓨팅의 홍채인식 을 통해 사용자의 홍채방향을 검출하여 사용자의 시선을 인식하는 사용자 시선 인식부; 상기 촬영영상을 대상으 로 비전 컴퓨팅의 포즈 탐지(pose detection) 기능 또는 개체 탐지(Object Detection) 기능을 수행하여 사용자 의 특정행동을 인식하는 사용자 행동 분석부; 및 상기 사용자 시선 인식부를 통해 사용자의 시선 또는 상기 사 용자 행동 인식부를 통해 사용자의 특정행동이 인식되는 경우, 미리 설정된 음성 멘트를 상기 스피커부로 전달 하여 사용자와의 대화를 시도한 후 사용자의 음성응답이 있는 경우 상기 AI 음성 챗봇을 수행하는 AI 음성 챗봇 부를 포함할 수 있다. 또한, 상기 AI 대화 로봇은, 상기 객체 인식부를 통해 사용자가 인식되지 않으면, 상기 마이크부를 통해 인식된 소음발생방향에 따른 상기 카메라부의 회전 및 상기 AI 대화 로봇의 위치이동 중 적어도 하나의 동작을 제어하는 로봇 동작 제어부를 더 포함할 수 있다. 또한, 상기 AI 음성 챗봇부는, 상기 사용자 시선 인식부를 통한 사용자의 시선 또는 상기 사용자 행동 인식부를 통한 특정행동 인식 여부에 따라, 미리 설정된 음성 멘트를 상기 스피커부로 전달하여 사용자와의 대화를 시도 하여 상기 AI 음성 챗봇을 실행하거나, 주변 소음을 인식하는 초기 상태로 복귀하도록 제어하는 AI 음성 챗봇 활성화 제어부; 상기 마이크부를 통해 입력된 음성데이터를 텍스트데이터로 변환하는 STT(Speech To Text) 변환 부; 상기 텍스트데이터를 분석하되, 사용자의 음성이 입력된 시점에서 사용자를 촬영한 영상이 있는 경우 미리 정의된 딥러닝 모델을 이용하여 해당 영상 내 사용자의 감정 및 상황을 각각 분류하고, 그 분류 결과를 상기 텍 스트데이터와 함께 파싱 및 자연어 처리를 통해 해석하고, 그 해석 결과에 따른 응답데이터를 도출하여 제공하 는 응답데이터 제공부; 및 상기 응답데이터를 음성데이터로 변환하여 상기 스피커부로 전달하는 TTS(Text To Speech) 변환부를 포함할 수 있다. 또한, 상기 AI 음성 챗봇 활성화 제어부는, 상기 사용자 시선 인식부를 통한 사용자의 시선 인식이 미리 설정된 시간 이상으로 유지되면, 미리 설정된 음성 멘트를 상기 스피커부로 전달하여 사용자와의 대화를 시도하고, 상 기 사용자 시선 인식부를 통한 사용자의 시선 인식이 미리 설정된 시간 미만으로 유지되면, 상기 AI 음성 챗봇 부를 동작을 종료하고, 상기 마이크부를 통한 주변 소음 인식 준비 상태로 전환되도록 할 수 있다. 또한, 상기 사용자 시선 인식부는, 상기 스피커부를 통한 상기 음성데이터의 출력종료시점마다 사용자의 시선 인식을 수행하고, 상기 AI 음성 챗봇부는, AI 음성 챗봇을 수행하는 중에 상기 사용자의 시선 인식부를 통해 사 용자의 시선이 인식되면 상기 AI 음성 챗봇을 유지하고, 사용자의 시선이 인식되지 않으면 상기 음성 AI 챗봇을 종료할 수 있다."}
{"patent_id": "10-2022-0064477", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명에 따르면, 사용자의 대화 의도를 먼저 파악하여 사용자에게 보다 사람친화적인 선재 대응이 가능하며, 이에 따른 대화 로봇에 대한 친밀감을 향상시킨 AI 기반의 스피커 시스템을 제공할 수 있다."}
{"patent_id": "10-2022-0064477", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 명세서에서 사용되는 용어에 대해 간략히 설명하고, 본 발명에 대해 구체적으로 설명하기로 한다. 본 발명에서 사용되는 용어는 본 발명에서의 기능을 고려하면서 가능한 현재 널리 사용되는 일반적인 용어들을 선택하였으나, 이는 당 분야에 종사하는 기술자의 의도 또는 판례, 새로운 기술의 출현 등에 따라 달라질 수 있 다. 또한, 특정한 경우는 출원인이 임의로 선정한 용어도 있으며, 이 경우 해당되는 발명의 설명 부분에서 상세 히 그 의미를 기재할 것이다. 따라서 본 발명에서 사용되는 용어는 단순한 용어의 명칭이 아닌, 그 용어가 가지 는 의미와 본 발명의 전반에 걸친 내용을 토대로 정의되어야 한다. 명세서 전체에서 어떤 부분이 어떤 구성요소를 \"포함\"한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다른 구성요소를 제외하는 것이 아니라 다른 구성요소를 더 포함할 수 있음을 의미한다. 또한, 명세서에 기재된 \"...부\", \"모듈\" 등의 용어는 적어도 하나 이상의 기능이나 동작을 처리하는 단위를 의미하며, 이는 하드웨어 또는 소프트웨어로 구현되거나 하드웨어와 소프트웨어의 결합으로 구현될 수 있다. 아래에서는 첨부한 도면을 참고하여 본 발명의 실시예에 대하여 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자가 용이하게 실시할 수 있도록 상세히 설명한다. 그러나 본 발명은 여러 가지 상이한 형태로 구현될 수 있으며 여기에서 설명하는 실시예에 한정되지 않는다. 그리고 도면에서 본 발명을 명확하게 설명하기 위해서 설명과 관계없는 부분은 생략하였으며, 명세서 전체를 통하여 유사한 부분에 대해서는 유사한 도면 부호를 붙였다. 도 1은 본 발명의 실시예에 따른 AI 기반의 스피커 시스템의 전체 구성을 설명하기 위해 나타낸 개요도이고, 도 2는 본 발명의 실시예에 따른 AI 대화 로봇의 전체 구성을 나타낸 블록도이고, 도 3은 본 발명의 실시예에 따른 AI 음성 챗봇부의 구성을 나타낸 블록도이며, 도 4는 본 발명의 실시예에 따른 AI 서비스 서버의 전체 구성을 나타낸 블록도이다. 도 1을 참조하면, 본 발명의 실시예에 따른 AI 기반의 스피커 시스템은 AI 대화 로봇 및 AI 서비스 서버 중 적어도 하나를 포함할 수 있다. 상기 AI 대화 로봇은, 소위 반려로봇이라 불리는 장치로 사용자의 얼굴, 시선, 행동, 음성 등을 인식하고 그에 따른 대화를 먼저 시도하여 보다 사람친화적인 동작을 행할 수 있는 스마트 기기로, 고정형과 이동형으로 나누어 구현 가능하다. 여기서, 고정형은 테이블이나 선반 등 위치를 고정시킨 상태에서 이동하지 않고 사용하 기 위한 형태로 구현된 것을 의미하고, 이동형은 실내를 이동하며 동작할 수 있도록 이동수단(바퀴, 궤도, 다리 등)이 추가 구성된 형태의 로봇을 의미할 수 있다. 이러한 AI 대화 로봇의 외관은 사람들에게 친숙한 꼬마 로봇 모양이나 로봇 이미지가 아닌 강아지, 고양이 등 반려동물의 형태로 구현 가능하며, 본 실시예에서는 AI 대화 로봇의 외형에 대하여 한정하는 것은 아니다. 상기 AI 대화 로봇은, 주변 소음 인식 시, 소음 방향으로 영상촬영 동작을 수행하고, AI 객체인식기법을 통해 촬영영상 내 소음근원대상을 인식하고, 해당 촬영영상에 대한 비전 컴퓨팅(Vision Computing)을 통해 소음 근원대상으로부터 시선을 받는 아이컨택 및 소음근원대상의 특정 행동 중 적어도 하나를 인식하면, 해당 소음근 원대상으로 대화를 먼저 시도하여 AI 음성 챗봇을 수행할 수 있다. 이를 위해 AI 대화 로봇은 도 2에 도시된 바와 같이, 로봇 구동부, 마이크부, 스피커부, 카메라부, 객체 인식부, 사용자 시선 인식부, 사용자 행동 인식부, AI 음성 챗봇부 및 로봇 동작 제어부 중 적어도 하나를 포함할 수 있다. 상기 로봇 구동부는, 고정형과 이동형 AI 대화 로봇 모두 공통적으로 카메라부의 촬영각도를 변 경 또는 조절하기 위한 부분과, 이동형의 경우 AI 대화 로봇을 특정 위치로 이동하기 위한 부분으로 구분 될 수 있으며, 고정형은 이러한 부분이 구비되지 않는다. 로봇 구동부에서 카메라부의 촬영각도를 변 경 또는 조절하기 위해 세로축 서보모터와 가로축 서보모터를 구비할 수 있으며, 로봇 동작 제어부의 제어 신호에 따라 구동될 수 있다. 이러한 서보모터들은 AI 대화 로봇의 목 부분에 설치되어 카메라부의 촬영각도를 자유롭게 조절할 수 있으며, 이는 고정형과 이동형에 모두 적용될 수 있다. 이동형 AI 대화 로봇 의 경우 로봇 구동부는 바퀴, 궤도, 다리 등으로 구현될 수 있으며, 로봇 동작 제어부의 제어신 호에 따라 구동될 수 있다 상기 마이크부는, 다수의 지향성 마이크를 통해 외부로부터 입력되는 소음발생여부와 소음발생방향을 각각 인식하고, 사용자의 음성을 입력 받을 수 있다. 다수의 지향성 마이크는 AI 대화 로봇의 전, 후, 좌, 후 방향에 대하여 각각 설치되어, 미리 설정된 데시벨 이상의 소음이 발생하였는지 여부와, 소음 발생 시 어느 방 향에서 소음이 발행하였는지를 인식하여 로봇 동작 제어부로 전달할 수 있으며, 이에 로봇 동작 제어부 는 마이크부에서 전달 받은 소음발생방향(또는 각도)에 대한 데이터를 기반으로 이동형 로봇의 경우 주행방향과 경로를 생성하여 그에 따른 로봇 구동부의 이동수단(바퀴, 궤도, 다리)의 동작을 제어할 수 있 다. 상기 마이크부는 상술한 바와 같이 다수의 지향성 마이크를 이용해 소음발생방향(또는 각도)을 인지할 수 있으나, 빔 포밍(beam forming)기술을 이용해 다방향(multi-direction)으로부터 소음 또는 음성(또는 음원)신호 를 입력 받아 소음 또는 음성(또는 음원)의 발생 방향을 추적할 수 있도록 구현이 가능하다. 상기 스피커부는, AI 음성 챗봇부와 연결되어 AI 음성 챗봇을 위한 음성데이터를 입력 받아 외부로 출력할 수 있다. 상기 카메라부는, 마이크부를 통한 소음(또는 음성, 음원) 인식 시 작동되어 주변 촬영을 통해 촬영 영상을 생성할 수 있다. 즉, 카메라부는 마이크부를 통한 소음(또는 음성, 음원) 인식 이전에는 작동 되지 않으며, 마이크부에서 소음을 인식하는 경우 작동되어 촬영동작을 수행할 수 있다. 또한, 카메라부 는 로봇 구동부의 서버모터에 의해 촬영각도가 조절되어 주변에 객체(소음근원대상)에 대한 영상을촬영할 수 있다. 상기 객체 인식부는, AI 객체인식기법을 통해 카메라부에서 생성되는 촬영영상 내 사용자를 인식하되, 미리 저장된 사용자와 저장되어 있지 않은 새로운 사용자를 구분하여 인식할 수 있다. 즉, 본 실시예 에 따른 스피커 시스템을 처음 사용하는 사용자는 사용자 얼굴과 이름을 등록을 우선으로 한 후 사용할 수 있으며, 사용 간에 새로운 사람의 얼굴이 인식되면, 미리 등록되어 있지 않으므로 해당 사용자에 대해서는 3 회 이상의 인식 과정을 거치고, '사람'이라는 이름으로 저장된 후에 AI 대화 로봇이 반응하도록 구현될 수 있다. 상기 사용자 시선 인식부는, 객체 인식부를 통해 인식된 사용자와의 거리가 미리 설정된 기준거리 이 상인 경우 비전 컴퓨팅의 페이스 메시 탐지(face mesh detection) 기능을 이용하여 사용자 얼굴의 방향 및 각도 를 검출하여 사용자의 시선을 인식하고, 사용자와의 거리가 상기 기준거리 미만인 경우 비전 컴퓨팅의 홍채인식 을 통해 사용자의 홍채방향을 검출하여 사용자의 시선을 인식할 수 있다. 예를 들어, 2m 이상의 거리에서 사용자가 인식되면, 비전 컴퓨팅의 페이스 메시 탐지(face mesh detection) 기 능을 이용하여 사용자 얼굴의 방향 및 각도를 검출할 수 있다. 페이스 메시 탐지 기능은 개체 탐지(Object Detection) 기술 중 하나로, 실시간으로 대략 468개의 3D 얼굴 랜드마크를 추정하는 얼굴 형상 솔루션이다. 머 신러닝 기술을 사용하여 사용자 얼굴의 3D 표면 형상을 유추할 수 있어 별도의 센서 없이도 일반 카메라의 영상 만으로도 실행이 가능하다. 이러한 비전 컴퓨팅의 페이스 메시 탐지(face mesh detection) 기능을 활용해 원거 리에서 인식된 사용자의 얼굴 각도, 방향 등을 검출하고, 사용자가 AI 대화 로봇을 바라보고 있는지 여부 를 판단할 수 있다. 또한, 2m 미만의 거리에서 사용자가 인식되면, 홍채인식 기능을 이용해 사용자 홍채의 각도 를 검출함으로써 사용자가 AI 대화 로봇을 바라보고 있는지 여부를 판단할 수 있다. 한편, 사용자 시선 인식부는, 스피커부를 통한 AI 대화 로봇의 음성데이터의 출력종료시점마다 사용자의 시선 인식을 수행하고, 시선 인식 결과를 AI 음성 챗봇부로 반환하여 AI 음성 챗봇 서비스의 지 속 여부가 결정될 수 있도록 하며, 이에 대한 보다 상세한 설명은 후술한다. 상기 사용자 행동 인식부는, 촬영영상을 대상으로 비전 컴퓨팅의 포즈 탐지(pose detection) 기능 또는 개 체 탐지(Object Detection) 기능을 수행하여 사용자의 특정행동을 인식할 수 있다. 사용자의 특정행동은 미리 정해진 제스쳐나 모션일 수 있으나, 이 보다는 사람이 괴로워하거나 정신적으로 힘들어 할 때 나타나는 행동들, 또는 곤란에 빠졌거나 어떠한 행위에 문제가 있을 때 나타나는 행동들로 정의할 수 있다. 이와 같은 특정행동은 AI 대화 로봇이 해당 사용자에게 도움을 주기 위한 조건이나 상황, 또는 감정적 교류가 필요한 상황으로 판단하기 위함이다. 상기 AI 음성 챗봇부는, 사용자 시선 인식부를 통해 사용자의 시선 또는 사용자 행동 인식부를 통해 사용자의 특정행동이 인식되는 경우, 미리 설정된 음성 멘트를 스피커부로 전달하여 사용자와의 대화 를 먼저 시도한 후 사용자의 음성응답이 있는 경우 AI 음성 챗봇을 수행할 수 있다. 이를 위해 AI 음성 챗봇부는 도 3에 도시된 바와 같이, AI 음성 챗봇 활성화 제어부, STT 변환부 , 응답데이터 제공부 및 TTS 변환부 중 적어도 하나를 포함할 수 있다. 상기 AI 음성 챗봇 활성화 제어부는, 사용자 시선 인식부를 통한 사용자의 시선 또는 사용자 행동 인 식부를 통해 사용자의 특정행동 인식 여부에 따라, 미리 설정된 음성 멘트를 스피커부로 전달하여 사 용자와의 대화를 먼저 시도할 수 있으며, 이후 사용자와의 AI 음성 챗봇을 실행하거나, AI 음성 챗봇부의 동작을 종료할 수도 있다. 예를 들어, AI 음성 챗봇 활성화 제어부는 사용자 시선 인식부를 통해 사용자의 시선을 인식하는 경 우 사용자에게 \"날씨가 참 좋죠?\" 등의 인사말을 먼저 건 내며 말을 걸 수 있고, 사용자 행동 인식부를 통 해 사용자의 특정행동이 인식되는 경우 \"제가 도와드릴 것이 있을 까요?\" 등 사용자의 상황에 맞는 말을 먼저 건 내며 물어볼 수 있다. 이와 같이, AI 음성 챗봇 활성화 제어부는 사용자의 시선을 인식하거나 사용자의 특정행동을 인식하는 경우, AI 음성 챗봇 실행의 기본 조건으로서 인지하여 사용자보다 먼저 그 상황에 맞는 준 비된 음성 멘트를 건 내며 대화를 시작할 수 있다. 상기 AI 음성 챗봇 활성화 제어부는, 사용자 시선 인식부를 통해 사용자의 시선을 인식할 때, 미리 설정된 시간 이상으로 시선 인식 상태가 유지되면, 미리 설정된 음성 멘트를 스피커부로 전달하여 사용자 와의 대화를 시도할 수 있다. 즉, 사용자가 AI 대화 로봇을 잠깐 바라보는 것이 아니라, 대략 5초 이상 바 라봤을 때 사용자에게 \"날씨가 참 좋죠?\" 등의 인사말을 먼저 건 내며 말을 걸 수 있다. 이는, 사용자가 의도없이 AI 대화 로봇를 바라 볼 수 있는 상황을 구분하기 위한 것으로, 사용자가 일정 시간 이상 AI 대화 로 봇을 바라 볼 때 사용자가 AI 대화 로봇과의 대화가 필요한 상황으로 판단하여 먼저 대화를 시도할 수 있다. 또한, 대략 5초 미만으로 사용자의 시선을 인식할 수 없는 경우 AI 음성 챗봇으로 이어지지 않고, 마 이크부를 통한 주변 소음 인식 준비 상태로 전환되어 초기 상태로 복귀되도록 제어할 수 있다. 또한, AI 음성 챗봇 활성화 제어부는, 사용자 시선 인식부를 통한 사용자의 시선 인식이 미리 설정된 시간 미만으로 유지(예를 들어 5초 미만으로 시선이 유지되는 경우)되면, 마이크부를 통한 주변 소음 인식 준비 상태 즉 초기 상태로 전환되도록 제어할 수 있다. 상기 STT 변환부는, AI 음성 챗봇 활성화 제어부에 의해 AI 음성 챗봇 기능이 활성화되면, 마이크부 를 통해 입력된 음성데이터를 STT(Speech To Text) 기술을 이용해 텍스트데이터로 변환할 수 있다. 상기 응답데이터 제공부는, STT 변환부를 통해 변환된 텍스트데이터를 분석하되, 사용자의 음성이 입 력된 시점에서 사용자를 촬영한 영상이 있는 경우 미리 정의된 딥러닝 모델을 이용하여 해당 영상 내 사용자의 감정 및 상황을 각각 분류하고, 그 분류 결과를 텍스트데이터와 함께 파싱 및 자연어 처리를 통해 해석하고, 그 해석 결과에 따른 응답데이터를 도출하여 제공할 수 있다. 즉, 사용자 음성과 함께 사용자를 촬영한 영상이 있 는 경우, 해당 촬영영상에 대하여 딥러닝 모델을 통해 사용자의 감정이나 상황이 가령, 기쁜 상태인지, 흥분된 상태인지, 우울한 상태인지 등으로 사용자 감정이나 상황을 분류하고, 그 분류 결과와 함께 사용자가 말한 내용 즉 텍스트데이터의 내용을 해석하여 그에 맞는 응답데이터를 도출할 수 있다. 예를 들어, 사용자를 촬영한 영상 을 분석한 결과 우울한 감정이나 상황으로 분류되면서, 사용자가 말한 내용을 분석한 결과 친구와 다툰 내용 등 을 말하고 있을 때, 미리 학습된 알고리즘에 따라 친구와 화해하는 방법에 대한 응답데이터를 도출하거나, 기분 을 전환할 수 있는 정보나 콘텐츠를 제공하기 위한 응답데이터를 도출할 수 있다. 상기 TTS 변환부는, 응답데이터 제공부를 통해 제공되는 응답데이터를 TTS(Text To Speech) 기술을 이용해 음성데이터로 변환하여 스피커부로 전달할 수 있다. 한편, AI 음성 챗봇부는, AI 음성 챗봇을 수행하는 중에 사용자의 시선 인식부를 통해 사용자의 시선 이 인식되면 AI 음성 챗봇을 유지하고, 사용자의 시선이 인식되지 않으면 음성 AI 챗봇을 종료할 수 있다. 예를 들어, AI 음성 챗봇부의 대화 내용이 끝나는 시점으로부터 미리 설정된 시간 이전에 사용자가 AI 대 화 로봇을 바라보고 있는 경우 AI 음성 챗봇 동작을 계속해서 수행하고, 사용자가 다른 곳을 바라보고 있 는 경우 AI 음성 챗봇 동작을 종료하고, 마이크부를 통한 주변 소음 인식 준비 상태로 전환되어 초기 상태 로 복귀될 수 있다. 상기 로봇 동작 제어부는, 객체 인식부를 통해 사용자가 인식되지 않으면, 마이크부를 통해 인 식된 소음발생방향에 따른 카메라부의 회전 및 AI 대화 로봇의 위치이동 중 적어도 하나의 동작을 제 어할 수 있다. 상기 AI 서비스 서버는, AI 대화 로봇으로부터 촬영영상을 통한 소음근원대상의 인식결과 및 AI 음성 챗봇의 대화내용 등을 수신하여 온라인 강화학습을 통해 소음근원대상의 인식 및 AI 음성 챗봇의 각 기능을 업 그레이드할 수 있다. 이를 위해 AI 서비스 서버는 도 4에 도시된 바와 같이, AI 검색/실행 서비스 처리부와 온라인 강화학 습 실행부 중 적어도 하나를 포함할 수 있다. 상기 AI 검색/실행 서비스 처리부는, 사용자로부터 입력되는 호출어, 질의어, 명령어 등에 따른 정보나 데 이터를 검색 또는 탐색하여 사용자에게 제공하기 위한 서비스를 제공하며, 이는 일반적인 인공지능 스피커의 기 능에 해당되므로 보다 구체적인 설명은 생략한다. 상기 온라인 강화학습 실행부는 AI 대화 로봇의 실시간 강화학습(Online Machine Learning)을 위한 구성요소로, 온라인 학습이라고도 하며, 이러한 온라인 학습은, 학습이 끝나 제품화가 된 로봇모델에 대하여 미 니 배치(Mini-batch)라 부르는 작은 묶음 단위의 데이터를 주입하여 모델을 학습시키는 방법이다. 미니 배치의 크기가 작기 때문에 학습 단계가 빠르고, 비용이 적게 들기 때문에 해당 모델은 데이터가 도착하는 대로 즉시 학습할 수 있다. 또한, 온라인 학습은 점진적으로 학습이 일어나기 때문에 점진적 학습이라고 불리며, 온라인 학습 모델은 새로운 데이터 샘플을 학습하면 해당 학습이 끝난 데이터가 더 이상 필요하지 않기 때문에 보관하 지 않아도 되므로 저장공간을 절약할 수 있는 이점이 있다. 상기 AI 서비스 서버는 AI 대화 로봇으로부터 받은 학습데이터(대화내용, 학습용 사진, 학습용 동영 상 등)를 로컬 또는 클라우드에 사용자 별로 독립 공간에 저장하고, 사용자 별로 학습된 정보를 AI 대화 로봇 으로 전달하여 사용자 별로 강화된 인공지능을 갖도록 한다. 도 5는 본 발명의 실시예에 따른 AI 기반의 스피커 시스템의 전체 동작 프로세스를 설명하기 위해 나타낸 순서 도이고, 도 6은 본 발명의 실시예에 따른 AI 챗봇 대화 실행 단계의 상세 프로세스를 나타낸 순서도이다. 도 5를 참조하면, 사용자 등록 단계(S1)를 우선적으로 수행하며, 해당 단계에서 사용자의 이름과 얼굴(특징데이 터) 등록할 수 있다. 이후, AI 대화 로봇은 마이크를 통해 주변 소음을 인식(S2)하게 되면, 카메라 영상으 로 소음근원대상을 인식하거나, 사람이라는 객체 자체를 인식할 수 있다(S3). 이때, 소음근원대상이나 사람 객 체를 인식할 수 없으면, 고정형 로봇은 소음발생방향으로 카메라를 회전하여 소음근원대상을 다시 한번 찾게 되 고, 이동형 로봇은 소음발생방향으로 이동하며 카메라를 회전해 소음근원대상을 찾을 수 있다(S4). 이러한 루틴 을 최소 3회 반복하여 소음근원대상을 인식할 수 있다. 소음근원대상(기 등록 사용자 또는 미 등록 사용자)이 인식(S5)된 후, 해당 사용자의 특정행동이 인식(S6)되는지, 사용자가 AI 대화 로봇에 대한 시선이 인식 (S7)되는지를 확인하고, 사용자의 특정행동을 인식하면 사용자의 상황에 맞는 미리 준비된 질문을 먼저 건 내고 (S8), 사용자의 시선을 5초 이상 인식하면 미리 준비된 인사말을 사용자에게 먼저 건 내어(S9) AI 챗봇 대화를 실행(S10)할 수 있다. 도 6을 참조하면, AI 음성 챗봇이 시작되면 마이크를 통해 입력된 음성데이터를 STT 기술을 이용해 텍스트데이 터로 변환한 후 해당 내용을 분석(S10a)할 수 있으며, 이때 사용자를 촬영한 영상이 있는 경우 해당 영상을 인 공지능 모델을 이용해 사용자의 감정과 상황을 분류하고, 그 분류 결과를 텍스트데이터와 함께 분석할 수 있다 (S10b). 이후, 사용자의 음성분석결과에 따라 응답데이터를 도출하고, 도출된 응답데이터를 TTS 기술을 이용해 음성데이터로 변환하여 스피커로 전달할 수 있다(S10c). 이때, AI 대화 로봇이 대답을 할 때 해당 대화의 종료시점에 사용자의 시선을 추적하여 사용자의 시선이 AI 대화 로봇을 바라보는 것으로 인식되면 계속해 서 AI 음성 챗봇 동작을 수행하며, 사용자의 시선이 인식되지 않으면 AI 음성 챗봇 동작을 종료하고 마이크를 통한 주변 소음 인식 준비 상태로 전환되어 초기 상태로 복귀될 수 있다. 이상에서 설명한 것은 본 발명에 의한 AI 기반의 스피커 시스템을 실시하기 위한 하나의 실시예에 불과한 것으 로서, 본 발명은 상기 실시예에 한정되지 않고, 이하의 특허청구범위에서 청구하는 바와 같이 본 발명의 요지를 벗어남이 없이 당해 발명이 속하는 분야에서 통상의 지식을 가진 자라면 누구든지 다양한 변경 실시가 가능한 범위까지 본 발명의 기술적 정신이 있다고 할 것이다."}
{"patent_id": "10-2022-0064477", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 실시예에 따른 AI 기반의 스피커 시스템의 전체 구성을 설명하기 위해 나타낸 개요도이다. 도 2는 본 발명의 실시예에 따른 AI 대화 로봇의 전체 구성을 나타낸 블록도이다. 도 3은 본 발명의 실시예에 따른 AI 음성 챗봇부의 구성을 나타낸 블록도이다. 도 4는 본 발명의 실시예에 따른 AI 서비스 서버의 전체 구성을 나타낸 블록도이다. 도 5는 본 발명의 실시예에 따른 AI 기반의 스피커 시스템의 전체 동작 프로세스를 설명하기 위해 나타낸 순서 도이다. 도 6은 본 발명의 실시예에 따른 AI 챗봇 대화 실행 단계의 상세 프로세스를 나타낸 순서도이다."}
