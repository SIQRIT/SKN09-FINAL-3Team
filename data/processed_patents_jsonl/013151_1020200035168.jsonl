{"patent_id": "10-2020-0035168", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2020-0132672", "출원번호": "10-2020-0035168", "발명의 명칭": "전자 장치 및 그 제어 방법", "출원인": "삼성전자주식회사", "발명자": "류성한"}}
{"patent_id": "10-2020-0035168", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "전자 장치의 제어 방법에 있어서,음성 신호를 획득하는 단계;상기 음성 신호를 바탕으로 제1 문장을 획득하고, 상기 제1 문장을 자연어 이해 모듈에 입력하여 상기 제1 문장에 대한 제1 특징값을 획득하는 단계;상기 제1 문장에 대응되는 제1 의미 정보를 획득하고, 상기 제1 의미 정보를 자연어 생성 모듈에 입력하여 상기제1 의미 정보에 대한 제2 특징값을 획득하는 단계; 및상기 제1 특징값 및 상기 제2 특징값이 벡터 공간 상에서 기설정된 거리 이내에 존재하도록 상기 자연어 이해모듈 및 상기 자연어 생성 모듈을 학습시키는 단계;를 포함하는제어 방법."}
{"patent_id": "10-2020-0035168", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1 항에 있어서,상기 학습시키는 단계는,상기 제1 특징값 및 상기 제2 특징값 중 하나의 특징값을 획득하고,특징값을 입력받아 상기 입력된 특징값을 생성한 모듈을 예측하도록 학습된 판별 모듈에 상기 획득된 특징값을입력하여 제1 모듈을 획득하고,상기 제1 모듈과 상기 획득된 특징값을 실제로 생성한 제2 모듈이 상이하도록 상기 자연어 이해 모듈 및 상기자연어 생성 모듈을 학습시키는제어 방법."}
{"patent_id": "10-2020-0035168", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1 항에 있어서,상기 학습시키는 단계는,복수의 특징값을 입력 받아 상기 복수의 특징값의 관련 정도에 대한 점수를 획득하도록 학습된 관련성 산출 모듈에 상기 제1 특징값 및 상기 제2 특징값을 입력하여 제1 점수를 획득하고,상기 제1 점수가 기설정된 점수보다 크도록 상기 자연어 이해 모듈 및 상기 자연어 생성 모듈을 학습시키는제어 방법."}
{"patent_id": "10-2020-0035168", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3 항에 있어서,상기 관련성 산출 모듈을 학습시키는 단계;를 더 포함하고,상기 관련성 산출 모듈을 학습시키는 단계는,상기 제1 문장 및 상기 제1 의미 정보의 관련 정도에 대한 제2 점수를 획득하고,상기 제1 점수 및 상기 제2 점수의 차이가 기설정된 점수보다 작도록 상기 관련성 산출 모듈을 학습시키는제어 방법.공개특허 10-2020-0132672-3-청구항 5 제1 항에 있어서,상기 제1 특징값을 획득하는 단계는,상기 제1 문장을 상기 자연어 이해 모듈에 입력하여 제2 의미 정보를 획득하는 단계를 포함하고,상기 학습시키는 단계는,상기 제1 의미 정보 및 상기 제2 의미 정보의 차이가 최소화되도록 상기 자연어 이해 모듈을 학습시키는 단계를포함하는제어 방법."}
{"patent_id": "10-2020-0035168", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5 항에 있어서,상기 자연어 이해 모듈은 제1 인코더 및 제1 디코더를 포함하고,상기 제1 특징값을 획득하는 단계는,상기 제1 문장을 상기 제1 인코더에 입력하여 상기 제1 특징값을 획득하는 단계 및상기 제1 특징값을 상기 제1 디코더에 입력하여 상기 제2 의미 정보를 획득하는 단계를 포함하는제어 방법."}
{"patent_id": "10-2020-0035168", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6 항에 있어서,상기 제1 디코더는,상기 제2 의미 정보에 포함된 복수의 의미 항목마다 대응되는 복수의 디코더들을 포함하고,상기 제1 특징값을 획득하는 단계는,상기 복수의 디코더로부터 각각 출력되는 제1 중간 특징값을 바탕으로 상기 제1 특징값을 획득하는제어 방법."}
{"patent_id": "10-2020-0035168", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1 항에 있어서,상기 제2 특징값을 획득하는 단계는,상기 제1 의미 정보를 상기 자연어 생성 모듈에 입력하여 제2 문장을 획득하는 단계를 포함하고,상기 학습시키는 단계는,상기 제1 문장 및 상기 제2 문장의 의미 차이가 최소화되도록 상기 자연어 생성 모듈을 학습시키는 단계를 포함하는제어 방법."}
{"patent_id": "10-2020-0035168", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8 항에 있어서,상기 자연어 생성 모듈은 제2 인코더 및 제2 디코더를 포함하고,상기 제2 특징값을 획득하는 단계는,상기 제1 의미 정보를 상기 제2 인코더에 입력하여 상기 제2 특징값을 획득하는 단계 및 공개특허 10-2020-0132672-4-상기 제2 특징값을 상기 제2 디코더에 입력하여 상기 제2 문장을 획득하는 단계를 포함하는제어 방법."}
{"patent_id": "10-2020-0035168", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9 항에 있어서,상기 제2 인코더는,상기 제1 의미 정보에 포함된 복수의 의미 항목마다 대응되는 복수의 인코더들을 포함하고,상기 제2 특징값을 획득하는 단계는,상기 복수의 인코더로부터 각각 출력되는 제2 중간 특징값을 바탕으로 상기 제2 특징값을 획득하는제어 방법."}
{"patent_id": "10-2020-0035168", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "전자 장치에 있어서,적어도 하나의 인스트럭션을 포함하는 메모리; 및상기 메모리와 연결되어 상기 전자 장치를 제어하는 프로세서;를 포함하며,상기 프로세서는, 상기 적어도 하나의 인스트럭션을 실행함으로써,음성 신호를 획득하고,상기 음성 신호를 바탕으로 제1 문장을 획득하고 상기 제1 문장을 자연어 이해 모듈에 입력하여 상기 제1 문장에 대한 제1 특징값을 획득하고,상기 제1 문장에 대응되는 제1 의미 정보를 획득하고 상기 제1 의미 정보를 자연어 생성 모듈에 입력하여 상기제1 의미 정보에 대한 제2 특징값을 획득하고,상기 제1 특징값 및 상기 제2 특징값이 벡터 공간 상에서 기설정된 거리 이내에 존재하도록 상기 자연어 이해모듈 및 상기 자연어 생성 모듈을 학습시키는전자 장치."}
{"patent_id": "10-2020-0035168", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11 항에 있어서,상기 프로세서는, 상기 제1 특징값 및 상기 제2 특징값 중 하나의 특징값을 획득하고,특징값을 입력받아 상기 입력된 특징값을 생성한 모듈을 예측하도록 학습된 판별 모듈에 상기 획득된 특징값을입력하여 제1 모듈을 획득하고,상기 제1 모듈과 상기 획득된 특징값을 실제로 생성한 제2 모듈이 상이하도록 상기 자연어 이해 모듈 및 상기자연어 생성 모듈을 학습시키는전자 장치."}
{"patent_id": "10-2020-0035168", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제11 항에 있어서,상기 프로세서는,복수의 특징값을 입력 받아 상기 복수의 특징값의 관련 정도에 대한 점수를 획득하도록 학습된 관련성 산출 모듈에 상기 제1 특징값 및 상기 제2 특징값을 입력하여 제1 점수를 획득하고,상기 제1 점수가 기설정된 점수보다 크도록 상기 자연어 이해 모듈 및 상기 자연어 생성 모듈을 학습시키는공개특허 10-2020-0132672-5-전자 장치."}
{"patent_id": "10-2020-0035168", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제13 항에 있어서,상기 프로세서는,상기 제1 문장 및 상기 제1 의미 정보의 관련 정도에 대한 제2 점수를 획득하고,상기 제1 점수 및 상기 제2 점수의 차이가 기설정된 점수보다 작도록 상기 관련성 산출 모듈을 학습시키는전자 장치."}
{"patent_id": "10-2020-0035168", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제11 항에 있어서,상기 프로세서는,상기 제1 문장을 상기 자연어 이해 모듈에 입력하여 제2 의미 정보를 획득하고,상기 제1 의미 정보 및 상기 제2 의미 정보의 차이가 최소화되도록 상기 자연어 이해 모듈을 학습시키는전자 장치."}
{"patent_id": "10-2020-0035168", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제15 항에 있어서,상기 자연어 이해 모듈은 제1 인코더 및 제1 디코더를 포함하고,상기 프로세서는,상기 제1 문장을 상기 제1 인코더에 입력하여 상기 제1 특징값을 획득하고,상기 제1 특징값을 상기 제1 디코더에 입력하여 상기 제2 의미 정보를 획득하는전자 장치."}
{"patent_id": "10-2020-0035168", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제16 항에 있어서,상기 제1 디코더는,상기 제2 의미 정보에 포함된 복수의 의미 항목마다 대응되는 복수의 디코더들을 포함하고,상기 프로세서는,상기 복수의 디코더로부터 각각 출력되는 제1 중간 특징값을 바탕으로 상기 제1 특징값을 획득하는전자 장치."}
{"patent_id": "10-2020-0035168", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제11 항에 있어서,상기 프로세서는,상기 제1 의미 정보를 상기 자연어 생성 모듈에 입력하여 제2 문장을 획득하고,상기 제1 문장 및 상기 제2 문장의 의미 차이가 최소화되도록 상기 자연어 생성 모듈을 학습시키는전자 장치."}
{"patent_id": "10-2020-0035168", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "공개특허 10-2020-0132672-6-제18 항에 있어서,상기 자연어 생성 모듈은 제2 인코더 및 제2 디코더를 포함하고,상기 프로세서는,상기 제1 의미 정보를 상기 제2 인코더에 입력하여 상기 제2 특징값을 획득하고,상기 제2 특징값을 상기 제2 디코더에 입력하여 상기 제2 문장을 획득하는전자 장치."}
{"patent_id": "10-2020-0035168", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제19 항에 있어서,상기 제2 인코더는,상기 제1 의미 정보에 포함된 복수의 의미 항목마다 대응되는 복수의 인코더들을 포함하고,상기 프로세서는,상기 복수의 인코더로부터 각각 출력되는 제2 중간 특징값을 바탕으로 상기 제2 특징값을 획득하는전자 장치."}
{"patent_id": "10-2020-0035168", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "전자 장치의 제어 방법이 개시된다. 본 개시에 따른 제어 방법은 음성 신호를 획득하는 단계, 음성 신호를 바탕 으로 제1 문장을 획득하고 제1 문장을 자연어 이해 모듈(NLU)에 입력하여 제1 문장에 대한 제1 특징값을 획득하 는 단계, 제1 문장에 대응되는 제1 의미 정보를 획득하고, 제1 의미 정보를 자연어 생성 모듈(NLG)에 입력하여 제1 의미 정보에 대한 제2 특징값을 획득하는 단계, 및 제1 특징값 및 제2 특징값이 벡터 공간 상에서 기설정된 거리 이내에 존재하도록 자연어 이해 모듈 및 자연어 생성 모듈을 학습시키는 단계를 포함한다."}
{"patent_id": "10-2020-0035168", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 전자 장치 및 그 제어 방법으로, 보다 상세하게는, 대화 시스템에서 사용자 입력에 대한 응답을 자연 어로 제공할 수 있는 전자 장치 및 그 제어 방법에 관한 것이다."}
{"patent_id": "10-2020-0035168", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "근래에는 인공 지능 시스템이 다양한 분야에서 이용되고 있다. 인공 지능 시스템은 기존의 룰(rule) 기반 스마 트 시스템과 달리 기계가 스스로 학습시키고 판단하며 똑똑해지는 시스템이다. 인공 지능 시스템은 사용할수록 인식률이 향상되고 사용자 취향을 보다 정확하게 이해할 수 있게 되어, 기존 룰 기반 스마트 시스템은 점차 딥 러닝 기반 인공 지능 시스템으로 대체되고 있다. 인공 지능 기술은 기계학습(예로, 딥러닝) 및 기계학습을 활용한 요소 기술들로 구성된다. 기계학습은 입력 데이터들의 특징을 스스로 분류/학습시키는 알고리즘 기술이며, 요소기술은 딥러닝 등의 기계 학습 알고리즘을 활용하여 인간 두뇌의 인지, 판단 등의 기능을 수행하기 위한 기술로서, 언어적 이해, 시각적 이해, 추론/예측, 지식 표현, 동작 제어 등의 기술 분야로 구성된다. 특히, 언어적 이해는 인간의 언어/문자를 인식하고 응용/처리하는 기술로서, 자연어 처리, 기계 번역, 대화시스템, 질의 응답, 음성 인식/합성 등을 포함 한다. 한편, 최근에는 다양한 기업이 인공지능 모델을 이용하여 사용자 입력(특히, 사용자 음성)에 대한 응답을 제공 할 수 있는 대화 시스템(Dialogue System)을 제공되고 있다. 이러한 대화 시스템은 보통 자동 음성 인식 (Automatic Speech Recognition (ASR)) 모듈, 자연어 이해(Natural Language Understanding (NLU)) 모듈, 대화 관리(Dialogue Management (DM)) 모듈, 자연어 생성(Natural Language Generation) 모듈 및 TTS(Text-To- Speech) 모듈을 포함한다. 전자 장치가 대화 시스템을 이용하여 사용자에게 최적의 응답을 제공하기 위해서는 상술한 모듈들 각각의 처리 결과가 정확하여야 한다. 특히, 사람과 전자 장치 사이의 자연스러운 대화를 위하여, 자연어 생성 모듈은 사용 자 음성에 응답한 최적의 자연어를 생성해야 한다. 만약, 자연어 생성 모듈이 이상하거나 어색한 응답을 제공할 경우, 대화 시스템의 사용성이 낮아지는 문제가 발생될 수 있다. 따라서, 자연어 생성 모듈이 정확한 응답을 포 함하는 자연어를 생성하는 것이 대화 시스템에서 매우 중요한 과제이며, 이러한 과제를 해결하기 위해서는 대화"}
{"patent_id": "10-2020-0035168", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 2, "content": "시스템에 대한 효율적인 학습 방법이 필요하다.발명의 내용"}
{"patent_id": "10-2020-0035168", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명이 해결하고자 하는 일 기술적 과제는, 대화 시스템의 성능 향상을 위한 효율적인 학습 방법을 제공하는 것이다. 본 발명의 기술적 과제들은 이상에서 언급한 기술적 과제들로 제한되지 않으며, 언급되지 않은 또 다른 기술적"}
{"patent_id": "10-2020-0035168", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 2, "content": "과제들은 아래의 기재로부터 본 발명의 기술분야에서의 통상의 기술자에게 명확하게 이해 될 수 있을 것이다."}
{"patent_id": "10-2020-0035168", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상술한 기술적 과제를 해결하기 위한 본 개시의 예시적인 일 실시 예에 따르면, 전자 장치에 있어서, 적어도 하 나의 인스트럭션을 포함하는 메모리; 및 상기 메모리와 연결되어 상기 전자 장치를 제어하는 프로세서;를 포함 하며, 상기 프로세서는, 상기 적어도 하나의 인스트럭션을 실행함으로써, 음성 신호를 획득하고, 상기 음성 신 호를 바탕으로 제1 문장을 획득하고, 상기 제1 문장을 자연어 이해 모듈에 입력하여 상기 제1 문장에 대한 제1 특징값을 획득하고, 상기 제1 문장에 대응되는 제1 의미 정보를 획득하고, 상기 제1 의미 정보를 자연어 생성 모듈에 입력하여 상기 제1 의미 정보에 대한 제2 특징값을 획득하고, 상기 제1 특징값 및 상기 제2 특징값이 벡 터 공간 상에서 기설정된 거리 이내에 존재하도록 상기 자연어 이해 모듈 및 상기 자연어 생성 모듈을 학습시키 는 전자 장치가 제공될 수 있다. 상술한 기술적 과제를 해결하기 위한 본 개시의 예시적인 다른 일 실시 예에 따르면, 전자 장치의 제어 방법에 있어서, 음성 신호를 획득하는 단계; 상기 음성 신호를 바탕으로 제1 문장을 획득하고, 상기 제1 문장을 자연어 이해 모듈에 입력하여 상기 제1 문장에 대한 제1 특징값을 획득하는 단계; 상기 제1 문장에 대응되는 제1 의미 정보를 획득하고, 상기 제1 의미 정보를 자연어 생성 모듈에 입력하여 상기 제1 의미 정보에 대한 제2 특징값을 획득하는 단계; 및 상기 제1 특징값 및 상기 제2 특징값이 벡터 공간 상에서 기설정된 거리 이내에 존재하도록 상기 자연어 이해 모듈 및 상기 자연어 생성 모듈을 학습시키는 단계;를 포함하는 제어 방법이 제공될 수 있다."}
{"patent_id": "10-2020-0035168", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 2, "content": "본 개시의 과제의 해결 수단이 상술한 해결 수단들로 제한되는 것은 아니며, 언급되지 아니한 해결 수단들은 본"}
{"patent_id": "10-2020-0035168", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 3, "content": "명세서 및 첨부된 도면으로부터 본 개시가 속하는 기술분야에서 통상의 지식을 가진 자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2020-0035168", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "이상과 같은 본 개시의 다양한 실시 예에 따르면, 효율적인 학습 방법을 통해 대화 시스템의 성능을 향상시킬 수 있다. 이에 따라, 대화 시스템의 사용성이 증가될 수 있다. 그 외에 본 개시의 실시 예로 인하여 얻을 수 있거나 예측되는 효과에 대해서는 본 개시의 실시 예에 대한 상세 한 설명에서 직접적 또는 암시적으로 개시하도록 한다. 예컨대, 본 개시의 실시 예에 따라 예측되는 다양한 효 과에 대해서는 후술될 상세한 설명 내에서 개시될 것이다."}
{"patent_id": "10-2020-0035168", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 명세서에서 사용되는 용어에 대해 간략히 설명하고, 본 개시에 대해 구체적으로 설명하기로 한다. 본 개시의 실시 예에서 사용되는 용어는 본 개시에서의 기능을 고려하면서 가능한 현재 널리 사용되는 일반적인 용어들을 선택하였으나, 이는 당 분야에 종사하는 기술자의 의도 또는 판례, 새로운 기술의 출현 등에 따라 달 라질 수 있다. 또한, 특정한 경우는 출원인이 임의로 선정한 용어도 있으며, 이 경우 해당되는 개시의 설명 부 분에서 상세히 그 의미를 기재할 것이다. 따라서 본 개시에서 사용되는 용어는 단순한 용어의 명칭이 아닌, 그 용어가 가지는 의미와 본 개시의 전반에 걸친 내용을 토대로 정의되어야 한다. 본 개시의 실시 예들은 다양한 변환을 가할 수 있고 여러 가지 실시 예를 가질 수 있는바, 특정 실시 예들을 도 면에 예시하고 상세한 설명에 상세하게 설명하고자 한다. 그러나 이는 특정한 실시 형태에 대해 범위를 한정하 려는 것이 아니며, 개시된 사상 및 기술 범위에 포함되는 모든 변환, 균등물 내지 대체물을 포함하는 것으로 이 해되어야 한다. 실시 예들을 설명함에 있어서 관련된 공지 기술에 대한 구체적인 설명이 요지를 흐릴 수 있다고 판단되는 경우 그 상세한 설명을 생략한다. 제1, 제2 등의 용어는 다양한 구성요소들을 설명하는데 사용될 수 있지만, 구성요소들은 용어들에 의해 한정되 어서는 안 된다. 용어들은 하나의 구성요소를 다른 구성요소로부터 구별하는 목적으로만 사용된다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 출원에서, \"포함하다\" 또 는 \"구성되다\" 등의 용어는 명세서 상에 기재된 특징, 숫자, 단계, 동작, 구성요소, 부품 또는 이들을 조합한 것이 존재함을 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성요소, 부품 또 는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되어야 한다. 아래에서는 첨부한 도면을 참고하여 본 개시의 실시 예에 대하여 본 개시가 속하는 기술 분야에서 통상의 지식 을 가진 자가 용이하게 실시할 수 있도록 상세히 설명한다. 그러나 본 개시는 여러 가지 상이한 형태로 구현될 수 있으며 여기에서 설명하는 실시 예에 한정되지 않는다. 그리고 도면에서 본 개시를 명확하게 설명하기 위해 서 설명과 관계없는 부분은 생략하였으며, 명세서 전체를 통하여 유사한 부분에 대해서는 유사한 도면 부호를 붙였다. 도 1은 본 개시의 일 실시 예에 따른 전자 장치의 동작을 설명하기 위한 흐름도이다. 도 1을 참조하면, 전자 장치(또는 대화 시스템)는 음성 인식 모듈, 자연어 이해 모듈, 대화 관 리 모듈, 자연어 생성 모듈 및 TTS 모듈을 포함할 수 있다. 전자 장치는 스마트폰, 태블릿 PC, 데스크톱 PC, 랩탑 PC, 스마트 TV, 스마트 스피커 중 적어도 하나를 포함할 수 있다. 전자 장치는 음성 인식 모듈에 음성 신호(예로, 사용자 음성)를 입력하여 제1 문장(S1)을 획득할 수 있다. 그리고, 전자 장치는 자연어 이해 모듈에 제1 문장(S1)을 입력하여 제1 문장(S1)에 대한 제1 의미 정보(SF1)를 획득할 수 있다. 여기서, 의미 정보란 문장의 의미를 나타내는 정보로서, 시맨틱 프레임 (semantic frame)을 의미한다. 의미 정보는 복수의 의미 항목을 포함하며, 예로는 도메인(domain), 의도 (intention) 및 슬롯(slot)을 포함할 수 있다.전자 장치는 제1 의미 정보(SF1)를 대화 관리 모듈에 입력하여 제2 의미 정보(SF2)를 획득할 수 있다. 제2 의미 정보(SF2)는 제1 문장(S1)에 대한 응답인 제2 문장(S2)에 대응되는 의미 정보를 의미한다. 전자 장치는 제2 의미 정보(SF2)를 자연어 생성 모듈에 입력하여 제2 문장(S2)을 획득할 수 있다. 그리고, 전자 장치는 제2 문장(S2)을 TTS 모듈(Text-To-Speech module, 150)에 입력하여 음성 신호를 생성 및 출 력할 수 있다. 한편, 전자 장치가 사용자에게 최적의 응답을 제공하기 위해서는 상술한 모듈들의 성능을 높이는게 중요하 며, 이를 위해 각 모듈들에 대한 효율적인 학습 방법이 필요하다. 이하에서는 전자 장치를 구성하는 각 모 듈들의 학습 방법에 대해 설명하도록 한다. 도 2는 본 개시의 일 실시 예에 따른 자연어 이해 모듈 및 자연어 생성 모듈의 학습 방법을 설명하기 위한 흐름 도이다. 자연어 이해 모듈은 문장 인코더 및 의미 정보 디코더를 포함할 수 있다. 문장 인코더는 자연어 문장을 입력 받아 입력된 자연어 문장에 대한 특징값을 출력하는 모듈이다. 또한, 의미 정보 디코더 는 특징값을 입력 받아 입력된 특징값에 대한 자연어 문장을 출력하는 모듈이다. 전자 장치는 제3 문장(S3)을 자연어 이해 모듈에 입력하여 제3 문장(S3)에 대한 제1 특징값(F1) 및 제3 의미 정보(SF3)를 획득할 수 있다. 구체적으로, 전자 장치는 제3 문장(S3)을 문장 인코더에 입력 하여 제1 특징값(F1)을 획득하고, 제1 특징값(F1)을 의미 정보 디코더에 입력하여 제3 의미 정보(SF3)를 획득할 수 있다. 여기서, 제1 특징값(F1)은 제3 문장(S3)에 대한 특징(feature)을 나타내기 위한 벡터값을 의미 한다. 그리고, 본 명세서에서 특징값은 중간 표현(intermediate representation)으로 지칭될 수 있다. 자연어 생성 모듈은 의미 정보 인코더 및 문장 디코더를 포함할 수 있다. 의미 정보 인코더 는 의미 정보(또는 의미 프레임)를 입력 받아 입력된 의미 정보에 대한 특징값을 출력한다. 문장 디코더 는 특징값을 입력 받아 입력된 특징값에 대한 의미 정보를 출력한다. 전자 장치는 제4 의미 정보(SF4)를 자연어 생성 모듈에 입력하여 제4 의미 정보(SF4)에 대한 제2 특 징값(F2) 및 제4 문장(S4)을 획득할 수 있다. 구체적으로, 전자 장치는 제4 의미 정보(SF4)를 의미 정보 인코더에 입력하여 제2 특징값(F2)을 획득하고, 제2 특징값(F2)을 문장 디코더에 입력하여 제4 문장 (S4)을 획득할 수 있다. 여기서, 제2 특징값(F2)은 제4 의미 정보(SF4)에 대한 특징(feature)을 나타내기 위한 벡터값을 의미한다. 또한, 제4 의미 정보(SF4)는 제3 문장(S3)에 매칭되는 학습 데이터로서, 라벨링 된 데이터 (labeled data)를 의미할 수 있다. 한편, 전자 장치는 제1 특징값(F1) 및 제2 특징값(F2)이 동일한 벡터 공간 내에서 기 설정된 거리 이내에 존재하도록 자연어 이해 모듈 및 자연어 생성 모듈을 학습시킬 수 있다. 즉, 전자 장치는 서로 대응되는 학습 데이터인 제3 문장(S3) 및 제4 의미 정보(SF4)로부터 각각 획득된 제1 특징값(F1) 및 제2 특징값 (F2)이 유사한 값을 갖도록 문장 인코더 및 의미 정보 인코더를 각각 학습시킬 수 있다. 구체적으로, 전자 장치는 제1 특징값(F1) 및 제2 특징값(F2)이 벡터 공간 내에서 기 설정된 거리 이내에 존재하도록 문 장 인코더 및 의미 정보 인코더에 포함된 특징값을 산출하기 위한 함수식에 포함된 가중치(weight) 값을 조절할 수 있다. 여기서, 가중치값들은 벡터값일 수 있다. 또한, 전자 장치는 복수의 특징값을 입력 받아 복수의 특징값의 관련 정도에 대한 점수(score)를 획득하도 록 학습된 관련성 산출 모듈(relevance measurer module, 160)을 이용하여 자연어 이해 모듈 및 자연어 생성 모듈을 학습시킬 수 있다. 특히, 전자 장치는 자연어 이해 모듈 및 자연어 생성 모듈(14 0)에 포함된 문장 인코더, 의미 정보 디코더, 의미 정보 인코더 및 문장 디코더를 학습시 킬 수 있다. 구체적으로, 전자 장치는 제1 특징값(F1) 및 제2 특징값(F2)을 관련성 산출 모듈에 입력하여 제1 특 징값(F1) 및 제2 특징값(F2)의 관련성에 대한 제1 점수를 획득할 수 있다. 이 때, 전자 장치는 제1 점수가 기설정된 점수보다 크도록 자연어 이해 모듈 및 자연어 생성 모듈을 학습시킬 수 있다. 여기서, 기설 정된 점수는 확률값을 의미하며, 예로는 0.9의 값을 가질 수 있다. 한편, 전자 장치는 관련성 산출 모듈을 학습시킬 수 있다. 구체적으로, 전자 장치는 제3 문장 (S3) 및 제4 의미 정보(SF4)간의 관련성에 제2 점수를 획득하고, 제1 점수 및 제2 점수의 차이가 기설정된 점수 (예로, 0.02)보다 작도록 관련성 산출 모듈을 학습시킬 수 있다.전자 장치는 판별 모듈(discriminator module, 170)을 이용하여 자연어 이해 모듈 및 자연어 생성 모듈을 학습시킬 수 있다. 여기서, 판별 모듈이란 특징값을 입력 받아 입력된 특징값을 생성한 소스 모듈을 예측하도록 학습된 모듈을 의미한다. 전자 장치는 제1 특징값(F1) 및 제2 특징값(F2) 중 적어도 하 나를 판별 모듈에 입력하여 예측된 모듈을 획득할 수 있다. 예를 들어, 전자 장치가 제1 특징값(F1) 을 판별 모듈에 입력할 때, 판별 모듈은 자연어 이해 모듈을 출력할 수 있다. 이 때, 전자 장치 는 예측된 모듈로 자연어 이해 모듈을 식별할 수 있다. 전자 장치는 판별 모듈을 통해 획득되는 예측된 모듈과 제1 특징값(F1) 및 제2 특징값(F2)을 실제로 생성한 모듈이 상이하도록 자연어 이해 모듈 및 자연어 생성 모듈을 학습시킬 수 있다. 특히, 전자 장치는 자연어 이해 모듈의 문장 인코더 및 자연어 생성 모듈의 의미 정보 인코더를 학습시킬 수 있다. 즉, 전자 장치는 판별 모듈이 제1 특징값(F1) 및 제2 특징값(F2)을 실제로 생성한 문장 인코더 및 의미 정보 인코더를 정확히 예측하지 못하도록 문장 인코더 및 의미 정보 인코 더를 학습시킬 수 있다. 달리 말해, 전자 장치는 판별 모듈이 제1 특징값(F1) 및 제2 특징값 (F2)을 정확히 구별하지 못하도록 문장 인코더 및 의미 정보 인코더를 학습시킬 수 있다. 예를 들어, 전자 장치는 제1 특징값(F1)을 판별 모듈에 입력할 수 있다. 이 때, 판별 모듈을 통 해 자연어 이해 모듈이 획득되면, 판별 모듈이 정확한 예측에 성공한 것이므로 문장 인코더의 학습 정도가 부족하다고 판단될 수 있다. 반면에, 판별 모듈을 통해 자연어 생성 모듈이 획득되면, 정확한 예측에 실패한 것이므로 문장 인코더의 학습 정도가 충분하다고 판단될 수 있다. 이상과 같이 전자 장치는 관련성 산출 모듈 및 판별 모듈을 이용함으로써 제1 특징값(F1) 및 제 2 특징값(F2)이 벡터 공간 상에서 기설정된 거리 이내에 존재하도록 자연어 이해 모듈 및 자연어 생성 모 듈을 학습시킬 수 있다. 이하에서는 보다 구체적인 학습 데이터의 예시를 통해 자연어 이해 모듈 및 자연어 생성 모듈의 학습 방법에 대하여 설명하도록 한다. 도 3은 본 개시의 일 실시 예에 따른 자연어 이해 모듈 및 자연어 생성 모듈의 학습 방법을 설명하기 위한 흐름 도이다. 한편, 도 2에서 상술한 설명과 중복되는 사항은 설명의 편의상 생략하도록 한다. 전자 장치는 제3 문장(S3, \"KBS 틀어줘\")을 문장 인코더에 입력하여 제1 특징값(F1)을 획득할 수 있 다. 또한, 전자 장치는 제3 문장(S3)에 대응되는 제4 의미 정보(SF4, [tv_가이드, 프로그램 실행, 채널 명])를 의미 정보 인코더에 입력하여 제2 특징값(F2)을 획득할 수 있다. 그리고, 전자 장치는 제1 특 징값(F1) 및 제2 특징값(F2)의 벡터 공간 상에서 기설정된 거리 이내에 존재하도록 자연어 이해 모듈 및 자연어 생성 모듈을 학습시킬 수 있다. 한편, 의미 정보 인코더는 복수의 의미 항목마다 대응되는 복수의 인코더를 포함할 수 있다. 예를 들어, 의미 정보 인코더는 도메인 인코더(141-1), 의도 인코더(141-2), 슬롯 인코더(141-3) 및 통합 의미 정보 인코더(141-4)를 포함할 수 있다. 이 때, 전자 장치는 도메인 인코더(141-1), 의도 인코더(141-2), 슬롯 인코더(141-3) 각각에 제4 의미 정보(SF4)에 포함된 의미 항목('tv_가이드', '프로그램 실행', '채널명')을 입 력하여 제2-1 특징값(F2-1), 제2-2 특징값(F2-2) 및 제2-3 특징값(F2-3)을 획득할 수 있다. 그리고, 전자 장치 는 제2-1 특징값(F2-1), 제2-2 특징값(F2-2) 및 제2-3 특징값(F2-3)을 통합 의미 정보 인코더(141-4)에 입력하여 제2 특징값(F2)을 획득할 수 있다. 또한, 의미 정보 디코더는 복수의 의미 항목마다 대응되는 복수의 인코더를 포함할 수 있다. 예를 들어, 의미 정보 디코더는 도메인 디코더(122-1), 의도 디코더(122-2), 슬롯 디코더(122-3) 및 통합 의미 정보 디코더(122-4)를 포함할 수 있다. 이 때, 전자 장치는 제1 특징값(F1)을 통합 의미 정보 디코더(122-4)에 입력하여 제1-1 특징값(F1-1), 제1-2 특징값(F1-2) 및 제1-3 특징값(F2-3)을 획득할 수 있다. 그리고, 전자 장 치는 제1-1 특징값(F1-1), 제1-2 특징값(F1-2) 및 제1-3 특징값(F2-3)을 각각 도메인 디코더(122-1), 의 도 디코더(122-2), 슬롯 디코더(122-3)에 입력하여 제3 의미 정보(SF3, 'tv_가이드', '프로그램 실행', '채널 명')를 획득할 수 있다. 도 3에서는 의미 정보에 포함된 의미 항목이 도메인, 의도, 슬롯으로 구성되는 것을 예로 들었으나 이는 일 실 시 예에 불과하며, 일부 항목이 생략되거나 다른 항목이 부가되어 의미 정보를 구성할 수 있음은 물론이다. 한편, 전자 장치는 제3 의미 정보(SF3) 및 제4 의미 정보(SF4)를 바탕으로 자연어 이해 모듈을 학습 시킬 수 있다. 구체적으로, 전자 장치는 제3 의미 정보(SF3) 및 제4 의미 정보(SF4)를 비교하여 에러값을 산출하고, 산출된 에러값이 기설정된 값보다 작아지도록 자연어 이해 모듈을 학습시킬 수 있다. 또한, 전 자 장치는 제4 의미 정보(SF4)에 대응되는 참조 문장을 획득하고, 참조 문장과 제4 문장(S4)을 바탕으로 자연어 생성 모듈을 학습시킬 수 있다. 구체적으로, 전자 장치는 참조 문장과 제4 문장(S4)을 비교하 여 에러값을 산출하고, 산출된 에러값이 기설정된 값보다 작아지도록 자연어 생성 모듈을 학습시킬 수 있 다. 도 4는 대화 관리 모듈의 동작을 설명하기 위한 흐름도이다. 전자 장치는 자연어 이해 모듈로부터 획득된 제1 문장(S1)에 대한 제1 의미 정보(SF1)를 대화 관리 모듈에 입력하여 제2 의미 정보(SF2)를 획득할 수 있다. 그리고, 전자 장치는 제2 의미 정보(SF2)를 자연어 생성 모듈에 입력하여 제2 문장(S2)을 획득할 수 있다. 전자 장치는 의미 정보 인코더, 문장 예측 모듈 및 의미 정보 디코더를 포함할 수 있다. 이 때, 전자 장치는 제1 의미 정보(SF1)를 의미 정보 인코더에 입력하여 제3 특징값(F3)을 획득할 수 있다. 그리고, 전자 장치는 제3 특징값(F3)을 문장 예측 모듈에 입력하여 제4 특징값(F4)을 획득할 수 있다. 또한, 전자 장치는 제4 특징값(F4)을 의미 정보 디코더에 입력하여 제2 의미 정보(SF2)를 획득할 수 있다. 전자 장치는 제1 문장(S1)에 대한 다음 문장인 참조 문장을 획득하고, 참조 문장과 제2 문장(S2)을 바탕으 로 대화 관리 모듈을 학습시킬 수 있다. 구체적으로, 전자 장치는 참조 문장과 제2 문장(S2)을 비교 하여 에러값을 산출하고, 산출된 에러값이 기설정된 값보다 작아지도록 대화 관리 모듈을 학습시킬 수 있 다. 한편, 전자 장치는 획득되는 음성 신호가 전자 장치에서 지원 가능한 기설정된 문장에 대응되는지 여 부를 고려하여 사용자에게 응답을 제공할 수 있다. 구체적으로, 전자 장치는 획득된 음성 신호가 기설정된 문장에 대응되면, 음성 신호를 바탕으로 획득된 문장을 자연어 이해 모듈, 대화 관리 모듈, 자연어 생성 모듈 및 TTS 모듈에 순차적으로 입력하여 문장을 획득하고 획득된 문장에 대응되는 응답을 사용자에게 제공할 수 있 다. 반면에, 획득된 음성 신호가 기설정된 문장에 대응되지 않으면, 전자 장치는 획득된 문장을 자연어 생 성 모듈에 입력하지 않고 기설정된 문장에 대응되는 응답을 사용자에게 제공할 수 있다. 이하에서는, 획득된 음 성 신호가 기설정된 문장에 대응되는지 여부를 바탕으로 응답을 제공하는 전자 장치의 동작에 대하여 설명 하도록 한다. 도 5는 본 개시의 일 실시 예에 따른 전자 장치의 제어 방법을 도시한 순서도이다. 전자 장치는 음성 신호를 획득할 수 있다(S510). 이 때, 전자 장치는 음성 신호를 획득하기 위한 마 이크를 포함할 수 있으며, 마이크를 통해 사용자로부터 음성 신호를 획득할 수 있다. 전자 장치는 획득된 음성 신호를 바탕으로 제1 문장을 획득할 수 있다(S520). 이 때, 전자 장치는 음 성 인식 모듈에 획득된 음성 신호를 입력하여 제1 문장을 획득할 수 있다. 전자 장치는 제1 문장을 바탕으로 제1 특징값 및 제1 의미 정보를 획득할 수 있다(S530). 이 때, 전자 장 치는 제1 문장을 자연어 이해 모듈에 입력하여 제1 특징값 및 제1 의미 정보를 획득할 수 있다 (S530). 구체적으로, 전자 장치는 자연어 이해 모듈에 포함된 문장 인코더에 제1 문장을 입력하 여 제1 특징값을 획득하고, 제1 특징값을 의미 정보 디코더에 입력하여 제1 의미 정보를 획득할 수 있다. 전자 장치는 제1 의미 정보에 대한 제2 특징값과 제1 특징값을 바탕으로 제1 문장 및 제1 의미 정보 간의 관련성에 대한 점수를 획득할 수 있다(S540). 구체적으로, 전자 장치는 제1 의미 정보를 의미 정보 인코더 에 입력하여 제2 특징값을 획득하고, 제2 특징값 및 제1 특징값을 관련성 산출 모듈에 입력하여 제1 문장 및 제1 의미 정보 간의 관련성에 대한 점수를 획득할 수 있다. 전자 장치는 획득된 점수가 기설정된 점수보다 높은지 판단할 수 있다(S550). 획득된 점수가 기설정된 점 수보다 높다고 판단되면, 전자 장치는 제1 의미 정보를 대화 관리 모듈에 입력하여 제2 의미 정보를 획득할 수 있다(S560). 그리고, 전자 장치는 제2 의미 정보를 자연어 생성 모듈에 입력하여 제2 문장 을 획득하고(S570), 제2 문장에 대응되는 음성 신호를 출력할 수 있다(S580). 이 때, 전자 장치는 스피커 를 통해 제2 문장에 대응되는 음성 신호를 출력하거나, 디스플레이를 통해 제2 문장을 디스플레이할 수 있다. 반면에, 획득된 점수가 기설정된 점수보다 높지 않다고 판단되면, 전자 장치는 기설정된 문장에 대응되는음성 신호를 출력할 수 있다(S590). 여기서, 기설정된 문장은 전자 장치에서 획득된 음성 신호에 대한 서 비스를 지원할 수 없음을 나타내는 거절 응답에 대응되는 문장(예로, \"이해하지 못하겠습니다\")일 수 있다. 이 와 같이, 전자 장치는 관련성 산출 모듈을 이용하여 획득된 음성 신호가 지원 가능한 서비스에 해당 하는 지 여부를 판단할 수 있다. 구체적으로, 전자 장치는 제1 특징값 및 제2 특징값을 관련성 산출 모듈 에 입력하여 획득한 점수와 기설정된 점수를 비교하여 획득된 음성 신호에 대한 서비스 지원 가능 여부를 판단할 수 있다. 이하에서는, 보다 구체적인 예시를 통해 도 5에 따른 전자 장치의 제어 방법에 대해 설명하도록 한다. 도 6은 지원 가능한 서비스에 대응되는 음성 신호를 획득하였을 때 전자 장치의 동작을 설명하기 위한 흐름도이다. 도 6을 참조하면, 전자 장치는 음성 신호(\"Is London cold now?\")를 획득하고, 획득된 음성 신호를 음성 인식 모듈에 입력하여 제1 문장(S1)을 획득할 수 있다. 즉, 전자 장치는 현재 런던의 날씨에 대해 질 문하는 음성 신호를 획득하여 제1 문장(S1)을 획득할 수 있다. 그리고, 전자 장치는 제1 문장(S1)을 문장 인코더에 입력하여 제1 특징값(F1)을 획득하고, 제1 특징 값(F1)을 의미 정보 디코더에 입력하여 제1 의미 정보(SF1)를 획득할 수 있다. 이 때, 제1 의미 정보(SF 1)는 도메인('날씨'), 의도('온도 확인') 및 슬롯('장소/시간/온도')에 대한 정보를 포함하는 슬롯을 포함할 수 있다. 전자 장치는 제1 의미 정보(SF1)를 의미 정보 인코더에 입력하여 제2 특징값(F2)을 획득할 수 있다. 전자 장치는 제1 특징값(F1) 및 제2 특징값(F2)을 관련성 산출 모듈에 입력하여 제1 문장(S1) 및 제1 의미 정보(SF1)에 대한 관련성에 대한 점수를 획득할 수 있다. 획득된 점수가 기설정된 점수보다 크면, 전자 장치는 제1 의미 정보(SF1)를 대화 관리 모듈에 입력하 여 제2 의미 정보(SF2)를 획득할 수 있다. 이 때, 제2 의미 정보(SF2)는 도메인('날씨'), 의도('날씨 물음') 및 슬롯('장소/시간/온도')에 대한 정보를 포함하는 슬롯을 포함할 수 있다. 전자 장치는 제2 의미 정보(SF 2)를 자연어 생성 모듈에 입력하여 제2 문장(S2)을 획득할 수 있다. 이 때, 전자 장치는 제2 의미 정 보(SF2)를 의미 정보 인코더에 입력하여 제3 특징값(F3)을 획득하고, 제3 특징값(F3)을 문장 디코더 에 입력하여 제2 문장(S2)을 획득할 수 있다. 그리고, 전자 장치는 제2 문장(S2)을 TTS 모듈에 입력 하여 음성 신호(\"Now London is 4.5°C\")를 획득하고, 획득된 음성 신호를 출력할 수 있다. 도 7은 지원 불가능한 서비스에 대응되는 음성 신호를 획득하였을 때 전자 장치의 동작을 설명하기 위한 흐름도 이다. 한편, 도 5 및 도 6과 중복되는 사항들에 대한 설명은 편의상 생략하도록 한다. 도 7을 참조하면, 전자 장치는 음성 신호(“I want to drink a cup of cold coffee now\")를 획득할 수 있 다. 그리고, 전자 장치는 획득한 음성 신호를 음성 인식 모듈 및 자연어 이해 모듈에 순차적으 로 입력하여 제1 의미 정보(SF1)를 획득할 수 있다. 이 때, 제1 의미 정보(SF1)는 도메인('날씨') 및 의도('날 씨 확인')를 포함할 수 있다. 즉, 제1 의미 정보(SF1)는 획득된 음성 신호에 대응되지 않는 정보를 포함할 수 있다. 전자 장치는 제1 의미 정보(SF1)를 의미 정보 인코더에 입력하여 제2 특징값(F2)을 획득하고, 제1 특 징값(F1) 및 제2 특징값(F2)을 관련성 산출 모듈에 입력하여 제1 문장(S1) 및 제1 의미 정보(SF1) 간의 관 련성에 대한 점수를 획득할 수 있다. 획득된 점수가 기설정된 점수보다 작으면, 전자 장치는 기설정된 문장(예로, \"이해하지 못하겠습니다\")을 획득할 수 있다. 이 때, 기설정된 문장은 전자 장치에 포함된 메모리 상에 미리 저장되어있을 수 있다. 전 자 장치는 기설정된 문장을 TTS 모듈에 입력하여 기설정된 문장에 대응되는 음성 신호(“Sorry, I don't understand\")를 획득하고, 획득된 음성 신호를 출력할 수 있다. 한편, 이상에서는 설명의 편의상 전자 장치가 하나의 문장을 자연어 이해 모듈에 입력하여 하나의 의 미 정보를 획득하는 것으로 설명하였으나, 이에 한정되는 것은 아니며, 전자 장치는 하나의 문장을 자연어 이해 모듈에 입력하여 복수의 의미 정보를 획득할 수 있다. 도 8은 하나의 입력 문장에 대응되는 복수의 의미 정보가 획득된 경우 전자 장치의 동작 방법을 설명하기 위한 도면이다. 도 8을 참조하면, 전자 장치는 제1 문장(S1)을 자연어 이해 모듈에 입력하여 제1 의미 정보(SF1) 및 제2 의미 정보(SF2)를 획득할 수 있다. 이 때, 제1 의미 정보(SF1) 및 제2 의미 정보(SF2)는 각각 제1 문장(S1)에 대응될 수 있다. 예를 들어, 제1 문장(S1)이 \"KBS 틀어줘\"일 때, 제1 의미 정보(SF1)의 도메인은 tv이며 제2 의미 정보(SF2)의 도메인은 라디오일 수 있다. 전자 장치는 제1 의미 정보(SF1)를 의미 정보 인코더(161-1)에 입력하여 제2-1 특징값(F2-1)을 획득하고, 제2-1 특징값(F2-1) 및 제1 특징값(F1)을 관련성 산출 모듈(160-1)에 입력하여 제1 점수(score 1)를 획득할 수 있다. 또한, 전자 장치는 제2 의미 정보(SF2)를 의미 정보 인코더(161-2)에 입력하여 제2-2 특징값(F2- 2)을 획득하고, 제2-2 특징값(F2-2) 및 제1 특징값(F1)을 관련성 산출 모듈(160-2)에 입력하여 제2 점수(score 2)를 획득할 수 있다. 전자 장치는 획득된 제1 점수 및 제2 점수를 각각 기설정된 기준 점수와 비교하여 제1 점수 및 제2 점수 중 기설정된 기준 점수보다 큰 점수에 대응되는 의미 정보를 획득할 수 있다. 일 예로, 제1 점수가 기설정된 기 준 점수보다 크다면, 전자 장치는 제1 점수에 대응되는 제1 의미 정보(SF1)를 획득할 수 있다. 다른 일 예 로, 제1 점수 및 제2 점수가 기설정된 기준 점수보다 크다면, 전자 장치는 제1 점수 및 제2 점수에 각각 대응되는 제1 의미 정보(SF1) 및 제2 의미 정보(SF2)를 획득할 수 있다. 이상과 같이 기설정된 기준 점수보다 큰 점수에 대응되는 의미 정보를 바탕으로 전자 장치는 사용자에게 응답을 제공할 수 있다. 구체적으로, 전자 장치는 제1 의미 정보(SF1) 및 제2 의미 정보(SF2) 중 기설정된 기준 점수보다 큰 점수에 대응되는 의미 정보를 대화 관리 모듈에 입력하여 사용자 응답을 위한 의미 정보 를 획득하고, 사용자 응답을 위한 의미 정보를 자연어 생성 모듈에 입력하여 응답 문장을 획득할 수 있다. 그리고, 전자 장치는 응답 문장을 TTS 모듈에 입력하여 음성 신호를 획득하고, 획득된 음성 신호를 출력할 수 있다. 한편, 전자 장치는 기설정된 기준 점수보다 큰 점수에 대응되는 의미 정보가 여러 개인 경우, 여러 개의 의미 정보를 바탕으로 사용자에게 응답을 제공할 수 있다. 예를 들어, 전자 장치가 제1 문장(\"KBS 틀어 줘\")(S1)을 획득한 경우, 전자 장치는 'tv'를 도메인 정보로 갖는 제1 의미 정보(SF1) 및 '라디오'를 도메 인 정보로 갖는 제2 의미 정보(SF2)를 획득할 수 있다. 또한, 전자 장치는 제1 의미 정보(SF1) 및 제2 의 미 정보(SF2) 각각에 대한 제1 점수 및 제2 점수가 모두 기설정된 기준 점수보다 클 수 있다. 이 때, 전자 장치 는 제1 의미 정보(SF1) 및 제2 의미 정보(SF2)를 바탕으로, 응답 문장(\"tv로 켤까요? 아니면 라디오로 켤 까요?\")을 획득할 수 있다. 또는, 전자 장치는 여러 개의 의미 정보 중 일부를 바탕으로 사용자에 응답을 제공할 수 있다. 구체적으로, 전자 장치는 가장 큰 점수에 대응되는 의미 정보를 선택하고, 선택된 의미 정보를 바탕으로 응답을 제공할 수 있다. 예를 들어, 제1 점수(score 1)가 0.9이고, 제2 점수(score 2)가 0.8인 경우, 전자 장치 는 제1 점수(score 1)에 대응되며 'tv'를 도메인 정보로 갖는 제1 의미 정보(SF1)를 선택할 수 있다. 그리 고, 전자 장치는 제1 의미 정보(SF1)를 바탕으로 응답 문장(\"KBS로 채널을 변경했습니다\")을 획득할 수 있 다. 한편, 이상에서는 전자 장치가 자연어 이해 모듈을 통해 의미 정보를 획득하고, 획득된 의미 정보를 바탕 으로 사용자에게 제공될 응답 문장을 생성하는 것으로 설명하였으나, 전자 장치는 의미 정보를 획득하지 않고 응답 문장을 생성할 수 있다. 전자 장치는, 이른바 종단간 대화 시스템(end-to-end dialog system)으 로 구현될 수 있다. 이하에서는 도 9를 참조하여 종단간 대화 시스템으로 구현되는 전자 장치의 일 실시 예에 대하여 설명하도록 한다. 도 9는 본 개시의 일 실시 예에 따른 전자 장치의 구현 예를 설명하기 위한 도면이다. 전자 장치는 음성 인식 모듈, 문장 인코더, 문장 예측 모듈, 문장 디코더 및 TTS 모 듈을 포함할 수 있다. 전자 장치는 사용자로부터 음성 신호(“Is London cold now?\")를 획득하고, 획득된 음성 신호를 음성 인식 모듈에 입력하여 입력 문장을 획득할 수 있다. 그리고, 전자 장치는 입력 문장을 문장 인코더에 입력하여 제1 특징값(F1)을 획득하고, 제1 특징값(F1)을 문장 예측 모듈에 입력하여 제2 특징값(F2)을 획 득할 수 있다. 또한, 전자 장치는 제2 특징값(F2)을 문장 디코더에 입력하여 응답 문장을 획득할 수 있다. 이와 같이 전자 장치는 종단간 대화 시스템(end-to-end dialog system)으로 구현될 수 있다. 즉, 전자 장치는 제1 특징값(F1) 및 제2 특징값(F2)을 바탕으로 의미 정보를 생성하는 것이 아니라, 곧바로 응 답 문장을 획득할 수 있다. 그리고, 전자 장치는 응답 문장을 TTS 모듈에 입력하여 응답 신호(“Now London is 4.5°C\")를 획득 하고, 획득된 응답 신호를 출력하여 사용자에게 응답을 제공할 수 있다.한편, 기존의 대화 시스템은 미리 학습된 문장에 대해서만 응답을 제공할 수 있었다. 예를 들어, 도 10에 도시 된 바와 같이 미학습된 문장(\"뉴스 녹화해줘\")이 획득되면, 전자 장치는 미학습된 문장을 이해할 수 없어 그에 대한 적절한 응답을 제공할 수 없었다. 그러나, 본 개시에 따른 전자 장치는 미리 학습되지 않은 문 장에 대한 음성 신호를 획득한 경우에도 사용자에게 최적의 응답을 제공할 수 있다. 이러한 전자 장치는 제로 샷 러닝(zero-shot learning)을 통해 구현될 수 있다. 도 10은 본 개시의 일 실시 예에 따른 전자 장치의 동작을 설명하기 위한 도면이다. 전자 장치는 제1 문장(“뉴스 녹화해줘\")(S1)을 문장 인코더에 입력하여 제1 특징값(F1)을 획득하고, 제1 의미 정보(SF1)를 의미 정보 인코더에 입력하여 제2 특징값(F2)을 획득할 수 있다. 이 때, 전자 장치는 제1 의미 정보(SF1)에 포함된 데이터(도메인, 의도, 슬롯)를 심볼 단위(예로, 0, 1, 2 등)가 아닌 텍스트 단위('tv_guide', 'recond_program', 'genre')로 입력할 수 있다. 전자 장치는 제1 특징값(F1) 및 제2 특징값(F2)을 관련성 산출 모듈에 입력하여 제1 문장(S1) 및 제 1 의미 정보(SF1) 간의 관련성에 대한 점수를 획득하고, 획득된 점수가 기설정된값보다 크도록 문장 인코더 및 의미 정보 인코더를 학습시킬 수 있다. 전술한 바와 같이, 전자 장치가 텍스트 단위로 제 1 의미 정보(SF1)를 의미 정보 인코더에 입력함에 따라, 학습된 전자 장치는 입력되는 문장 또는 의 미 정보를 이해할 수 있게 된다. 따라서, 전자 장치는 학습되지 않은 문장에 대응되는 음성 신호를 획득하 더라도, 획득된 음성 신호에 대한 문장의 의미를 이해하여 적절한 응답을 제공할 수 있다. 도 11은 본 개시의 일 실시 예에 따른 전자 장치의 구성을 도시한 블록도이다. 도 11에 도시된 바와 같이, 전자 장치는 메모리, 프로세서, 통신 인터페이스, 마이크, 디스플레이 및 스 피커를 포함할 수 있다. 한편, 도 11에 도시된 전자 장치의 구성은 전자 장치의 유형에 따라 일부 구성이 추가되거나 생략될 수 있음은 물론이다. 메모리는 전자 장치의 적어도 하나의 다른 구성요소에 관계된 명령 또는 데이터를 저장할 수 있다. 특히, 메모리는 비휘발성 메모리 및 휘발성 메모리를 포함할 수 있으며, 예로, 플래시메모리(flash- memory), 하드디스크 드라이브(HDD) 또는 솔리드 스테이트 드라이브(SSD) 등으로 구현될 수 있다. 메모리(111 0)는 프로세서에 의해 액세스되며, 프로세서에 의한 데이터의 독취/기록/수정/삭제/갱신 등이 수행 될 수 있다. 또한, 메모리는 대화 시스템을 동작하기 위한 인공지능 에이전트를 저장할 수 있다. 구체적 으로, 전자 장치는 사용자 발화에 대한 응답으로 자연어를 생성하거나 제어 명령을 획득하기 위하여 인공 지능 에이전트(Artificial intelligence agent)를 이용할 수 있다. 이때, 인공지능 에이전트는 AI(Artificial Intelligence) 기반의 서비스(예를 들어, 음성 인식 서비스, 비서 서비스, 번역 서비스, 검색 서비스 등)를 제 공하기 위한 전용 프로그램이다. 특히, 인공지능 에이전트는 기존의 범용 프로세서(예를 들어, CPU) 또는 별도 의 AI 전용 프로세서(예를 들어, GPU, NPU 등)에 의해 실행될 수 있다. 또한, 메모리는 도 12에 도시된 바 와 같은 대화 시스템을 구성하는 복수의 구성(또는 모듈)을 포함할 수 있다. 통신 인터페이스는 다양한 유형의 통신방식에 따라 다양한 유형의 외부 장치와 통신을 수행하는 구성이다. 통신 인터페이스는 와이파이 모듈, 블루투스 모듈, 적외선 통신 모듈 및 무선 통신 모듈 등을 포함할 수 있다. 특히, 프로세서는 통신 인터페이스를 이용하여 각종 외부 장치와 통신을 수행할 수 있다. 마이크는 사용자의 음성을 입력받기 위한 구성으로서, 전자 장치 내에 구비될 수 있으나, 이는 일 실시예에 불과할 뿐, 전자 장치의 외부에 전자 장치와 유선 또는 무선으로 연결될 수 있다. 특히, 마이크는 전자 장치 또는 전자 장치 주위의 외부 기기를 제어하기 위한 사용자 음성을 입력 받을 수 있다. 디스플레이는 외부로부터 수신된 영상 또는 UI를 디스플레이할 수 있다. 특히, 디스플레이는 LCD(Liquid Crystal Display), OLED(Organic Light Emitting Diodes) 디스플레이, PDP(Plasma Display Panel) 등과 같은 다양한 형태의 디스플레이로 구현될 수 있다. 디스플레이 내에는 a-si TFT, LTPS(low temperature poly silicon) TFT, OTFT(organic TFT) 등과 같은 형태로 구현될 수 있는 구동 회로, 백라이트 유 닛 등도 함께 포함될 수 있다. 한편, 디스플레이는 터치 센서와 결합된 터치 스크린, 플렉시블 디스플레 이(flexible display), 3차원 디스플레이(3D display) 등으로 구현될 수 있다. 또한, 본 발명의 일 실시 예에 따른, 디스플레이는 영상을 출력하는 디스플레이 패널뿐만 아니라, 디스플레이 패널을 하우징하는 베젤을 포함할 수 있다. 특히, 본 발명의 일 실시예에 따른, 베젤은 사용자 인터렉션을 감지하기 위한 터치 센서(미도시)를 포함할 수 있다. 특히, 디스플레이는 사용자 음성에 대한 응답 결과를 텍스트 또는 이미지 형태로 제공할 수 있다. 스피커는 외부로 수신된 각종 오디오 데이터뿐만 아니라 각종 알림 음이나 음성 메시지 등을 출력하는 구 성요소일 수 있다. 이때, 전자 장치는 스피커와 같은 오디오 출력 장치를 포함할 수 있으나, 오디 오 출력 단자와 같은 출력 장치를 포함할 수 있다. 특히, 스피커는 사용자 음성에 대한 응답 결과 및 동 작 결과 등을 음성 형태로 제공할 수 있다. 그 밖에 전자 장치는 전자 장치를 제어하기 위한 사용자 명령을 입력받는 입력 인터페이스를 포함 할 수 있다. 이때, 입력 인터페이스는 버튼, 터치 패드, 마우스 및 키보드와 같은 장치로 구현되거나, 상술한 디스플레이 기능 및 조작 입력 기능도 함께 수행 가능한 터치 스크린으로도 구현될 수 있다. 여기서, 버튼은 전 자 장치의 본체 외관의 전면부나 측면부, 배면부 등의 임의의 영역에 형성된 기계적 버튼, 터치 패드, 휠 등과 같은 다양한 유형의 버튼이 될 수 있다. 프로세서는 메모리와 전기적으로 연결되어 전자 장치의 전반적인 동작을 제어할 수 있다. 특 히, 프로세서는 메모리에 저장된 적어도 하나의 인스트럭션을 실행함으로써, 음성 신호를 획득하고, 음성 신호를 바탕으로 제1 문장을 획득할 수 있다. 그리고, 프로세서는 제1 문장을 자연어 이 해 모듈에 입력하여 제1 문장에 대한 제1 특징값을 획득할 수 있다. 그리고, 프로세서는 제1 문장에 대응 되는 제1 의미 정보를 획득하고, 제1 의미 정보를 자연어 생성 모듈에 입력하여 상기 제1 의미 정보에 대한 제2 특징값을 획득할 수 있다. 그리고, 프로세서는 제1 특징값 및 제2 특징값이 벡터 공간 상에서 기설정된 거리 이내에 존재하도록 자연어 이해 모듈 및 자연어 생성 모듈을 학습시킬 수 있다. 특히, 프로세서는 제1 특징값 및 제2 특징값 중 하나의 특징값을 획득하고, 특징값을 입력받아 입력된 특 징값을 생성한 모듈을 예측하도록 학습된 판별 모듈에 획득된 특징값을 입력하여 제1 모듈을 획득하고, 제1 모 듈과 상기 획득된 특징값을 실제로 생성한 제2 모듈이 상이하도록 자연어 이해 모듈 및 자연어 생성 모듈을 학 습시킬 수 있다. 또한, 프로세서는 복수의 특징값을 입력 받아 복수의 특징값의 관련 정도에 대한 점수를 획득하도록 학습 된 관련성 산출 모듈에 제1 특징값 및 제2 특징값을 입력하여 제1 점수를 획득하고, 제1 점수가 기설정된 점수 보다 크도록 자연어 이해 모듈 및 자연어 생성 모듈을 학습시킬 수 있다. 이 때, 프로세서는 제1 문장 및 제1 의미 정보의 관련 정도에 대한 제2 점수를 획득하고, 제1 점수 및 제2 점수의 차이가 기설정된 점수보다 작 도록 관련성 산출 모듈을 학습시킬 수 있다. 한편, 프로세서는 제1 문장을 자연어 이해 모듈에 입력하여 제2 의미 정보를 획득하고, 제1 의미 정보 및 제2 의미 정보의 차이가 최소화되도록 자연어 이해 모듈을 학습시킬 수 있다. 이 때, 자연어 이해 모듈은 제1 인코더 및 제1 디코더를 포함하고, 프로세서는 제1 문장을 제1 인코더에 입력하여 제1 특징값을 획득하고, 제1 특징값을 제1 디코더에 입력하여 제2 의미 정보를 획득할 수 있다. 그리고, 제1 디코더는, 제2 의미 정보에 포함된 복수의 의미 항목마다 대응되는 복수의 디코더들을 포함할 수 있다. 이 때, 프로세서(112 0)는 복수의 디코더로부터 각각 출력되는 제1 중간 특징값을 바탕으로 제1 특징값을 획득할 수 있다. 또한, 프로세서는 제1 의미 정보를 자연어 생성 모듈에 입력하여 제2 문장을 획득하고, 제1 문장 및 제2 문장의 의미 차이가 최소화되도록 자연어 생성 모듈을 학습시킬 수 있다. 이 때, 자연어 생성 모듈은 제2 인코 더 및 제2 디코더를 포함하고, 프로세서는 제1 의미 정보를 제2 인코더에 입력하여 제2 특징값을 획득할 수 있다. 그리고, 프로세서는 제2 특징값을 제2 디코더에 입력하여 제2 문장을 획득할 수 있다. 여기서, 제2 인코더는 제1 의미 정보에 포함된 복수의 의미 항목마다 대응되는 복수의 인코더들을 포함할 수 있고, 프로 세서는, 복수의 인코더로부터 각각 출력되는 제2 중간 특징값을 바탕으로 제2 특징값을 획득할 수 있다. 특히, 본 개시에 따른 인공지능과 관련된 기능은 프로세서와 메모리를 통해 동작된다. 프로세서 는 하나 또는 복수의 프로세서로 구성될 수 있다. 이때, 하나 또는 복수의 프로세서는 CPU, AP, DSP(Digital Signal Processor) 등과 같은 범용 프로세서, GPU, VPU(Vision Processing Unit)와 같은 그래픽 전용 프로세서 또는 NPU와 같은 인공지능 전용 프로세서일 수 있다. 하나 또는 복수의 프로세서는, 메모리 에 저장된 기 정의된 동작 규칙 또는 인공지능 모델에 따라, 입력 데이터를 처리하도록 제어한다. 또는, 하나 또는 복수의 프로세서가 인공지능 전용 프로세서인 경우, 인공지능 전용 프로세서는, 특정 인공지능 모델 의 처리에 특화된 하드웨어 구조로 설계될 수 있다. 기 정의된 동작 규칙 또는 인공지능 모델은 학습을 통해 만들어진 것을 특징으로 한다. 여기서, 학습을 통해 만 들어진다는 것은, 기본 인공지능 모델이 학습 알고리즘에 의하여 다수의 학습 데이터들을 이용하여 학습됨으로 써, 원하는 특성(또는, 목적)을 수행하도록 설정된 기 정의된 동작 규칙 또는 인공지능 모델이 만들어짐을 의미 한다. 이러한 학습은 본 개시에 따른 인공지능이 수행되는 기기 자체에서 이루어질 수도 있고, 별도의 서버 및/ 또는 시스템을 통해 이루어 질 수도 있다. 학습 알고리즘의 예로는, 지도형 학습(supervised learning), 비지도 형 학습(unsupervised learning), 준지도형 학습(semi-supervised learning), 생성적 적대 신경망(Generative Adversarial Network) 또는 강화 학습(reinforcement learning)이 있으나, 전술한 예에 한정되지 않는다. 인공지능 모델은, 복수의 신경망 레이어들로 구성될 수 있다. 복수의 신경망 레이어들 각각은 복수의 가중치들 (weight values)을 갖고 있으며, 이전(previous) 레이어의 연산 결과와 복수의 가중치들 간의 연산을 통해 신경 망 연산을 수행한다. 복수의 신경망 레이어들이 갖고 있는 복수의 가중치들은 인공지능 모델의 학습 결과에 의 해 최적화될 수 있다. 예를 들어, 학습 과정 동안 인공지능 모델에서 획득한 로스(loss) 값 또는 코스트(cost) 값이 감소 또는 최소화되도록 복수의 가중치들이 갱신될 수 있다. 인공 신경망은 심층 신경망(DNN:Deep Neural Network)를 포함할 수 있으며, 예를 들어, CNN (Convolutional Neural Network), DNN (Deep Neural Network), RNN (Recurrent Neural Network), RBM (Restricted Boltzmann Machine), DBN (Deep Belief Network), BRDNN(Bidirectional Recurrent Deep Neural Network) 또는 심층 Q-네트워크 (Deep Q-Networks) 등이 있으나, 전술한 예에 한정되지 않는다. 도 12는 본 개시의 일 실시예에 따른, 대화 시스템을 도시한 블록도이다. 도 12에 도시된 대화 시스템은 가상의 인공지능 에이전트와 자연어를 통해 대화를 수행하거나 전자 장치를 제어하기 위한 구성으로서, 본 개시의 일 실시예 따르면, 대화 시스템에 포함된 모듈은 전자 장치의 메모리 내에 저장될 수 있으나, 이는 일 실시예에 불과할 뿐, 하드웨어와 소프트웨어의 결합된 형태로 구현될 수 있다. 또한, 대화 시스템에 포함된 적어도 하나의 모듈은 외부의 적어도 하나의 서버에 포함될 수 있다. 대화 시스템은 도 12에 도시된 바와 같이, 음성 입력(speech input) 모듈, 음성 인식(speech recognition)(SR) 모듈, 자연어 이해(natural language understanding)(NLU) 모듈, 대화 관리 (dialogue manager)(DM) 모듈, 자연어 생성(natural language generator)(NLG) 모듈, 텍스트 음성 변환(text to speech)(TTS) 모듈 및 출력(output) 모듈을 포함할 수 있다. 음성 입력 모듈은 음성 데이터 형태의 사용자 음성을 입력받을 수 있다. 이때, 음성 입력 모듈은 마이크를 포함할 수 있으며, 마이크를 통해 사용자 음성을 포함하는 아날로그 형태의 오디오 신호를 수신할 수 있으며, 아날로그 신호를 디지털 신호로 변환할 수 있다. 일 실시예로, 음성 입력 모듈은 디지털 신호로 부터 노이즈 성분을 제거하여 사용자 음성에 대응되는 음성 데이터를 획득할 수 있다. 다만, 다른 실시예에 따 르면, 음성 입력 모듈이 별도의 노이즈 성분을 제거하지 않고, 이후 음성 인식 모델을 통해 디지털 신호 에 포함된 노이즈가 제거될 수 있다. 특히, 음성 입력 모듈을 통해 수신되는 사용자 음성은 적어도 하나 의 텍스트를 포함하는 문장 또는 구 형태일 수 있으나, 이는 일 실시예에 불과할 뿐, 복수의 문장 또는 구를 포 함할 수 있다. 한편, 음성 입력 모듈에 포함된 마이크는 전자 장치 내부에 구비될 수 있으나, 이는 일 실시예에 불과할 뿐, 외부에 구비되어 전자 장치와 유선 또는 무선으로 연결될 수 있다. 또한, 음성 입력 모듈 은 외부 장치로부터 사용자 음성을 수신하는 통신 모듈을 포함할 수 있음은 물론이다. 음성 인식 모듈은 음성 입력 모듈로부터 수신된 음성 데이터 형태의 사용자 음성을 텍스트 데이터 로 변환할 수 있다. 이때, 텍스트 데이터는 문자 코드로 이루어진 데이터이며, 음성 데이터는 사용자 음성에 대 한 주파수 정보를 포함하는 데이터일 수 있다. 음성 인식 모듈은 음향(acoustic) 모델 및 언어(language) 모델을 포함할 수 있다. 이때, 음향 모델은 발성에 관련된 정보를 포함할 수 있고, 언어 모델은 단위 음소 정보 및 단위 음소 정보의 조합에 대한 정보를 포함할 수 있다. 음성 인식 모듈은 발성에 관련된 정보 및 단위 음소 정보에 대한 정보를 이용하여 사용자 음성을 텍스트 데이터로 변환할 수 있다. 자연어 이해 모듈은 음성 인식 모듈을 통해 획득된 문장에 대한 의미적 분석(semantic analyze)을 수행하여 사용자 음성에 대한 도메인 및 사용자 의도를 파악할 수 있다. 이 때, 자연어 이해 모듈은 의 미(semantic) 매칭을 이용하여 의미적 분석을 수행할 수 있다. 대화 관리 모듈은 자연어 이해 모듈을 통해 획득된 도메인, 사용자 의도 및 슬롯 중 적어도 하나를 바탕으로 사용자 음성에 대한 응답을 제공할 수 있다. 이때, 대화 매니저 모듈은 지식 베이스를 기반으로 사용자 음성에 대한 응답을 제공할 수 있다. 이때, 지식 베이스는 전자 장치 내에 포함될 수 있으나, 이는 일 실시예에 불과할 뿐, 외부 서버에 포함될 수 있다. 자연어 생성 모듈은 지정된 정보를 텍스트 형태로 변경할 수 있다. 텍스트 형태로 변경된 정보는 자연어 의 형태일 수 있다. 지정된 정보는, 예를 들어, 질문에 대한 응답 정보 또는 사용자의 추가 입력을 안내하는 정 보(예: 사용자 입력에 대한 피드백 정보)일 수 있다. 텍스트 형태로 변경된 정보는 전자 장치의 디스플레 이에 표시되거나, 텍스트 음성 변환 모듈에 의해 음성 형태로 변경될 수 있다. 텍스트 음성 변환 모듈은 텍스트 형태의 정보를 음성 형태의 정보로 변경할 수 있다. 텍스트 음성 변환 모듈은 자연어 생성 모듈로부터 수신한 문장(또는 텍스트 데이터)을 음성 데이터 형태의 정보로 변 경할 수 있다. 출력 모듈은 텍스트 음성 변환 모듈로부터 수신된 음성 데이터 형태의 정보를 출력할 수 있다. 이 때, 출력 모듈은 스피커 또는 음성 출력 단자를 통해 음성 데이터 형태의 정보를 출력할 수 있다. 또는 출력 모듈은 자연어 생성 모듈을 통해 획득된 텍스트 데이터 형태의 정보를 디스플레이 또는 영상 출력 단자를 통해 출력할 수 있다. 한편, 상술한 실시예에서는 전자 장치 내부에 음성 인식 모듈, 자연어 이해 모듈이 포함된 것으로 설명하 였으나, 이는 일 실시예에 불과할 뿐, 음성 인식 모듈, 자연어 이해 모듈 중 적어도 하나는 외부 서버에 존재할 수 있다. 일 예로, 음성 인식 모듈은 전자 장치에 구비될 수 있으며, 자연어 이해 모듈은 서버에 존재할 수 있다. 도 13은 본 개시의 일 실시 예에 따른 전자 장치의 제어 방법을 설명하기 위한 순서도이다. 도 13을 참조하면, 전자 장치는 음성 신호를 획득할 수 있다(S1310). 전자 장치는 음성 신호를 바탕 으로 제1 문장을 획득하고, 제1 문장을 자연어 이해 모듈에 입력하여 제1 문장에 대한 제1 특징값을 획득할 수 있다(S1320). 이 때, 전자 장치는 음성 신호를 음성 인식 모듈에 입력하여 제1 문장을 획득할 수 있 다. 그 외 본 단계에 대한 상세한 설명은 도 5를 참조하도록 한다. 전자 장치는 제1 문장에 대응되는 제1 의미 정보를 획득하고, 제1 의미 정보를 자연어 생성 모듈에 입력하 여 제1 의미 정보에 대한 제2 특징값을 획득할 수 있다(S1330). 이 때, 제1 의미 정보는 라벨링된 학습 데이터 일 수 있다. 본 단계는 도 2에서 이미 설명 되었으므로 그 상세한 설명은 생략하도록 한다. 전자 장치는 제1 특징값 및 제2 특징값이 벡터 공간 상에서 기 설정된 거리 이내에 존재하도록 자연어 이 해 모듈 및 자연어 생성 모듈을 학습시킬 수 있다(S1340). 이 때, 전자 장치는 관련성 산출 모듈을 이용하 여 자연어 이해 모듈 및 자연어 생성 모듈을 학습시킬 수 있다. 또한, 전자 장치는 판별 모듈을 이용하여 자연어 이해 모듈 및 자연어 생성 모듈을 학습시킬 수 있다. 한편, 이에 대한 상세한 설명은 도 2 및 도 3을 참 조하도록 한다. 한편, 이상에서 설명된 다양한 실시 예들은 소프트웨어(software), 하드웨어(hardware) 또는 이들의 조합을 이 용하여 컴퓨터(computer) 또는 이와 유사한 장치로 읽을 수 있는 기록 매체 내에서 구현될 수 있다. 일부 경우 에 있어 본 명세서에서 설명되는 실시 예들이 프로세서 자체로 구현될 수 있다. 소프트웨어적인 구현에 의하면, 본 명세서에서 설명되는 절차 및 기능과 같은 실시 예들은 별도의 소프트웨어 모듈들로 구현될 수 있다. 소프트 웨어 모듈들 각각은 본 명세서에서 설명되는 하나 이상의 기능 및 작동을 수행할 수 있다. 한편, 상술한 본 개시의 다양한 실시 예들에 따른 처리 동작을 수행하기 위한 컴퓨터 명령어(computer instructions)는 비일시적 컴퓨터 판독 가능 매체(non-transitory computer-readable medium) 에 저장될 수 있 다. 이러한 비일시적 컴퓨터 판독 가능 매체에 저장된 컴퓨터 명령어는 프로세서에 의해 실행되었을 때 상술한 다양한 실시 예에 따른 처리 동작을 특정 기기가 수행하도록 할 수 있다. 비일시적 컴퓨터 판독 가능 매체란 레지스터, 캐쉬, 메모리 등과 같이 짧은 순간 동안 데이터를 저장하는 매체 가 아니라 반영구적으로 데이터를 저장하며, 기기에 의해 판독(reading)이 가능한 매체를 의미한다. 비일시적 컴퓨터 판독 가능 매체의 구체적인 예로는, CD, DVD, 하드 디스크, 블루레이 디스크, USB, 메모리카드, ROM 등 이 있을 수 있다. 한편, 기기로 읽을 수 있는 저장매체는, 비일시적(non-transitory) 저장매체의 형태로 제공될 수 있다. 여기서, ‘비일시적 저장매체'는 실재(tangible)하는 장치이고, 신호(signal)(예: 전자기파)를 포함하지 않는다는 것을 의미할 뿐이며, 이 용어는 데이터가 저장매체에 반영구적으로 저장되는 경우와 임시적으로 저장되는 경우를 구분하지 않는다. 예로, '비일시적 저장매체'는 데이터가 임시적으로 저장되는 버퍼를 포함할 수 있다. 일 실시예에 따르면, 본 문서에 개시된 다양한 실시예들에 따른 방법은 컴퓨터 프로그램 제품(computer program product)에 포함되어 제공될 수 있다. 컴퓨터 프로그램 제품은 상품으로서 판매자 및 구매자 간에 거래될 수 있 다. 컴퓨터 프로그램 제품은 기기로 읽을 수 있는 저장 매체(예: compact disc read only memory (CD-ROM))의 형태로 배포되거나, 또는 어플리케이션 스토어(예: 플레이 스토어TM)를 통해 또는 두개의 사용자 장치들(예: 스 마트폰들) 간에 직접, 온라인으로 배포(예: 다운로드 또는 업로드)될 수 있다. 온라인 배포의 경우에, 컴퓨터 프로그램 제품(예: 다운로더블 앱(downloadable app))의 적어도 일부는 제조사의 서버, 어플리케이션 스토어의 서버, 또는 중계 서버의 메모리와 같은 기기로 읽을 수 있는 저장 매체에 적어도 일시 저장되거나, 임시적으로 생성될 수 있다. 이상에서는 본 개시의 바람직한 실시 예에 대하여 도시하고 설명하였지만, 본 개시는 상술한 특정의 실시 예에"}
{"patent_id": "10-2020-0035168", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "한정되지 아니하며, 청구범위에서 청구하는 본 개시의 요지를 벗어남이 없이 당해 개시에 속하는 기술분야에서 통상의 지식을 가진자에 의해 다양한 변형실시가 가능한 것은 물론이고, 이러한 변형실시들은 본 개시의 기술적 사상이나 전망으로부터 개별적으로 이해되어져서는 안될 것이다."}
{"patent_id": "10-2020-0035168", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 개시의 일 실시 예에 따른 전자 장치의 동작을 설명하기 위한 흐름도이다. 도 2는 본 개시의 일 실시 예에 따른 자연어 이해 모듈 및 자연어 생성 모듈의 학습 방법을 설명하기 위한 흐름 도이다. 도 3은 본 개시의 일 실시 예에 따른 자연어 이해 모듈 및 자연어 생성 모듈의 학습 방법을 설명하기 위한 흐름 도이다. 도 4는 대화 관리 모듈의 동작을 설명하기 위한 흐름도이다. 도 5는 본 개시의 일 실시 예에 따른 전자 장치의 제어 방법을 도시한 순서도이다. 도 6은 지원 가능한 서비스에 대응되는 음성 신호를 획득하였을 때 전자 장치의 동작을 설명하기 위한 흐름도이 다. 도 7은 지원 불가능한 서비스에 대응되는 음성 신호를 획득하였을 때 전자 장치의 동작을 설명하기 위한 흐름도이다. 도 8은 하나의 입력 문장에 대응되는 복수의 의미 정보가 획득된 경우 전자 장치의 동작 방법을 설명하기 위한 도면이다. 도 9는 본 개시의 일 실시 예에 따른 전자 장치의 구현 예를 설명하기 위한 도면이다. 도 10은 본 개시의 일 실시 예에 따른 전자 장치의 동작을 설명하기 위한 도면이다. 도 11은 본 개시의 일 실시 예에 따른 전자 장치의 구성을 도시한 블록도이다. 도 11은 본 개시의 일 실시 예에 따른 출력 이미지를 나타내는 도면이다. 도 12는 본 개시의 일 실시예에 따른, 대화 시스템을 도시한 블록도이다. 도 13은 본 개시의 일 실시 예에 따른 전자 장치의 제어 방법을 설명하기 위한 순서도이다."}
