{"patent_id": "10-2021-0142151", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2021-0134528", "출원번호": "10-2021-0142151", "발명의 명칭": "비디오 처리 방법, 장치, 전자 기기, 저장 매체 및 컴퓨터 프로그램", "출원인": "베이징 바이두 넷컴 사이언스 테크놀로지 컴퍼니", "발명자": "왕 치"}}
{"patent_id": "10-2021-0142151", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "비디오 처리 방법으로서,복수의 제1 비디오 프레임을 획득하고, 상기 복수의 제1 비디오 프레임을 미세입도(fine granularity) 분할하여복수의 제2 비디오 프레임을 획득하는 단계; 상기 복수의 제2 비디오 프레임과 관련된 멀티 모달 정보(multimodal information)에 따라 상기 복수의 제2 비디오 프레임에 대해 특징 코딩을 진행하여, 상기 멀티 모달 정보 융합을 나타내는 특징 융합 정보를 획득하는단계; 및상기 특징 융합 정보에 의해 상기 복수의 제2 비디오 프레임에 대해 유사도 매칭을 진행하고, 유사도 매칭 결과에 의해 타겟 비디오를 획득하는 단계를 포함하는, 비디오 처리 방법."}
{"patent_id": "10-2021-0142151", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 복수의 제1 비디오 프레임을 획득하고 상기 복수의 제1 비디오 프레임을 미세입도 분할하여 복수의 제2 비디오 프레임을 획득하는 단계는, 숏 및 색상 변환을 나타내는 매개변수에 따라 상기 복수의 제1 비디오 프레임을 미세입도 분할하여 상기 복수의제2 비디오 프레임을 획득하는 단계를 포함하는, 비디오 처리 방법."}
{"patent_id": "10-2021-0142151", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서, 상기 복수의 제2 비디오 프레임과 관련된 멀티 모달 정보에 의해 상기 복수의 제2 비디오 프레임에 대해 특징코딩을 진행하여 상기 멀티 모달 정보 융합을 나타내는 특징 융합 정보를 획득하는 단계는, 상기 멀티 모달 정보에 의해 상기 복수의 제2 비디오 프레임에 대해 특징 추출 및 특징 융합 처리하여 상기 특징 융합 정보를 획득하는 단계를 포함하는, 비디오 처리 방법."}
{"patent_id": "10-2021-0142151", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서, 상기 특징 융합 정보에 의해 상기 복수의 제2 비디오 프레임에 대해 유사도 매칭을 진행하고 유사도 매칭 결과에 의해 타겟 비디오를 획득하는 단계는,상기 특징 융합 정보에 의해 상기 복수의 제2 비디오 프레임의 유사도에 대해 채점하여 채점 결과를 상기 유사도 매칭 결과로 사용하고, 상기 유사도 매칭 결과가 동일 이벤트 콘텐츠에 대한 인접 비디오 프레임이 유사한 경우, 상기 인접 비디오 프레임에 의해 상기 복수의 제2 비디오 프레임을 각각 머지하는 작업이 종료될 때까지 상기 인접 비디오 프레임에대해 비디오 머지를 진행하고, 비디오 머지 결과에 따라 상기 타겟 비디오를 획득하는 단계를 포함하는, 비디오 처리 방법."}
{"patent_id": "10-2021-0142151", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제2항 내지 제4항 중 어느 한 항에 있어서, 사전 훈련된 제1 신경망 모델에 따라 상기 복수의 제2 비디오 프레임에서 상기 멀티 모달 정보를 식별하는 단계공개특허 10-2021-0134528-3-를 더 포함하는, 비디오 처리 방법."}
{"patent_id": "10-2021-0142151", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5항에 있어서, 사전 훈련된 제1 신경망 모델에 따라 상기 복수의 제2 비디오 프레임에서 상기 멀티 모달 정보를 식별하는 상기단계는, 상기 제1 신경망 모델 중의 지식 그래프(Knowledge Grap) 추출기에 의해 지식 그래프 정보를 식별하는 단계; 상기 제1 신경망 모델 중의 텍스트 추출기에 의해 텍스트 정보를 식별하는 단계; 상기 제1 신경망 모델 중의 오디오 추출기에 의해 오디오 정보를 식별하는 단계; 상기 제1 신경망 모델 중의 색조 추출기에 의해 색조 정보를 식별하는 단계; 상기 제1 신경망 모델 중의 물체 추출기에 의해 물체 정보를 식별하는 단계;상기 제1 신경망 모델 중의 동작 추출기에 의해 동작 정보를 식별하는 단계를 포함하되, 상기 멀티 모달 정보는 상기 지식 그래프 정보, 상기 텍스트 정보, 상기 오디오 정보, 상기 색조정보, 상기 물체 정보, 상기 동작 정보 중 적어도 하나 이상을 포함하는, 비디오 처리 방법."}
{"patent_id": "10-2021-0142151", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6항에 있어서, 제2 신경망 모델에 따라 상기 멀티 모달 정보 중 각 유형의 정보를 구분하는 단계;제3 신경망 모델에 따라 상기 멀티 모달 정보와 관련된 타이밍 정보를 식별하는 단계;상기 제1 신경망 모델, 제2 신경망 모델, 상기 제3 신경망 모델의 출력 결과를 융합하여 상기 특징 융합 정보를획득하는 단계를 더 포함하는, 비디오 처리 방법."}
{"patent_id": "10-2021-0142151", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "비디오 처리 장치로서,복수의 제1 비디오 프레임을 획득하고 상기 복수의 제1 비디오 프레임을 미세입도 분할하여 복수의 제2 비디오프레임을 획득하는 분할 모듈;상기 복수의 제2 비디오 프레임과 관련된 멀티 모달 정보에 의해 상기 복수의 제2 비디오 프레임에 대해 특징코딩을 진행하여 상기 멀티 모달 정보 융합을 나타내는 특징 융합 정보를 획득하는 코딩 모듈; 및상기 특징 융합 정보에 의해 상기 복수의 제2 비디오 프레임에 대해 유사도 매칭을 진행하고, 유사도 매칭 결과에 의해 타겟 비디오를 획득하는 비디오 처리 모듈을 포함하는 비디오 처리 장치."}
{"patent_id": "10-2021-0142151", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서, 상기 분할 모듈은, 숏 및 색상 변환을 나타내는 매개변수에 따라 상기 복수의 제1 비디오 프레임을 미세입도 분할하여 상기 복수의제2 비디오 프레임을 획득하는 비디오 처리 장치."}
{"patent_id": "10-2021-0142151", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제8항에 있어서, 상기 코딩 모듈은, 공개특허 10-2021-0134528-4-상기 멀티 모달 정보에 의해 상기 복수의 제2 비디오 프레임에 대해 특징 추출 및 특징 융합 처리하여 상기 특징 융합 정보를 획득하는 비디오 처리 장치."}
{"patent_id": "10-2021-0142151", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제8항에 있어서, 상기 비디오 처리 모듈은,상기 특징 융합 정보에 의해 상기 복수의 제2 비디오 프레임의 유사도에 대해 채점하고 채점 결과를 상기 유사도 매칭 결과로 사용하고, 상기 유사도 매칭 결과가 동일 이벤트 콘텐츠에 대한 인접 비디오 프레임이 유사한 경우, 상기 인접 비디오 프레임에 의해 상기 복수의 제2 비디오 프레임을 각각 머지하는 작업이 종료될 때까지 상기 인접 비디오 프레임에대해 비디오 머지를 진행하고, 비디오 머지 결과에 따라 상기 타겟 비디오를 획득하는 비디오 처리 장치."}
{"patent_id": "10-2021-0142151", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제9항 내지 제11항 중 어느 한 항에 있어서,사전 훈련된 제1 신경망 모델에 따라 상기 복수의 제2 비디오 프레임에서 상기 멀티 모달 정보를 식별하는 식별모듈을 더 포함하는 비디오 처리 장치."}
{"patent_id": "10-2021-0142151", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제12항에 있어서, 상기 식별 모듈은, 상기 제1 신경망 모델 중의 지식 그래프(Knowledge Grap) 추출기에 의해 지식 그래프 정보를 식별하고; 상기 제1 신경망 모델 중의 텍스트 추출기에 의해 텍스트 정보를 식별하고; 상기 제1 신경망 모델 중의 오디오 추출기에 의해 오디오 정보를 식별하고; 상기 제1 신경망 모델 중의 색조 추출기에 의해 색조 정보를 식별하고; 상기 제1 신경망 모델 중의 물체 추출기에 의해 물체 정보를 식별하고;상기 제1 신경망 모델 중의 동작 추출기에 의해 동작 정보를 식별하고,상기 멀티 모달 정보는 상기 지식 그래프 정보, 상기 텍스트 정보, 상기 오디오 정보, 상기 색조 정보, 상기 물체 정보, 상기 동작 정보 중 적어도 하나 이상을 포함하는 비디오 처리 장치."}
{"patent_id": "10-2021-0142151", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제13항에 있어서, 제2 신경망 모델에 따라 상기 멀티 모달 정보 중 각 유형의 정보를 구분하고, 제3 신경망 모델에 따라 상기 멀티 모달 정보와 관련된 타이밍 정보를 식별하고, 상기 제1 신경망 모델, 제2 신경망 모델, 상기 제3 신경망 모델의 출력 결과를 융합하여 상기 특징 융합 정보를획득하는 융합 모듈을 더 포함하는 비디오 처리 장치."}
{"patent_id": "10-2021-0142151", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "전자 기기로서,적어도 하나 이상의 프로세서; 및 상기 적어도 하나 이상의 프로세서에 통신 연결되는 메모리를 포함하되, 상기 메모리에는 상기 적어도 하나 이상의 프로세서에 의해 실행 가능한 명령이 저장되고, 상기명령은 상기 적어도 하나 이상의 프로세서에 의해 실행되어 상기 적어도 하나 이상의 프로세서가 제1 항 내지공개특허 10-2021-0134528-5-제4항 중 어느 한 항에 따른 상기 방법을 수행하도록 하는, 전자 기기."}
{"patent_id": "10-2021-0142151", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "컴퓨터 명령이 저장된 비일시적 컴퓨터 판독 가능 저장 매체로서, 상기 컴퓨터 명령은 컴퓨터가 제1항 내지 제4항 중 어느 한 항에 따른 상기 방법을 실행하도록 하는, 저장매체."}
{"patent_id": "10-2021-0142151", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "컴퓨터 판독가능 저장 매체에 저장된 컴퓨터 프로그램으로서,상기 컴퓨터 프로그램 중의 명령이 프로세서에 의해 실행될 경우, 제1항 내지 제4항 중 어느 한 항의 방법을 구현하는 것을 특징으로 하는 컴퓨터 판독가능 저장 매체에 저장된 컴퓨터 프로그램."}
{"patent_id": "10-2021-0142151", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 출원은 비디오 처리 방법, 장치, 전자 기기, 저장 매체 및 컴퓨터 프로그램을 개시하였는 바, 인공 지능 분야 에 관한 것으로, 특히 딥 러닝, 모델 훈련, 지식 그래프, 비디오 처리 등 분야에 관한 것이다. 구체적으로 다음 기술적 해결수단에 의해 구현된다. 복수의 제1 비디오 프레임을 획득하고, 상기 복수의 제1 비디오 프레임을 미 세입도(fine granularity) 분할하여 복수의 제2 비디오 프레임을 획득하고; 상기 복수의 제2 비디오 프레임과 관 련된 멀티 모달 정보(multimodal information)에 따라 상기 복수의 제2 비디오 프레임에 대해 특징 코딩을 진행 하여, 상기 멀티 모달 정보 융합을 나타내는 특징 융합 정보를 획득하고; 상기 특징 융합 정보에 의해 상기 복수 의 제2 비디오 프레임에 대해 유사도 매칭을 진행하고, 유사도 매칭 결과에 의해 타겟 비디오를 획득한다. 본 출 원은 비디오 분할의 정확도를 향상시킬 수 있다."}
{"patent_id": "10-2021-0142151", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 출원은 인공지능 기술분야에 관한 것으로, 특히 딥 러닝, 모델 훈련, 지식 그래프, 비디오 처리 등 분야에 관한 것이다."}
{"patent_id": "10-2021-0142151", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "휴대용 기기, 휴대폰 단말기 등 전자 기기가 이전보다 더 지능화되고, 칩의 분석 능력이 더 강력함에 따라 특히 비디오 정보에 대한 분석, 화면 렌더링 등이 이전보다 더 빠르고, 더 선명해져 사용자가 비디오 품질에 대한 요 구가 높아지고 있다. 특히 시효성(timeliness)이 높은 장면(예를 들면 퍼레이드 장면, 스포츠 경기, 실시간 라 이브 영상 등)인 경우, 사용자는 비디오의 순간 하이라이트 장면을 모두 캡처하기 원하므로 더 정확하고 선명한 비디오 화면이 필요한 실정이다. 비디오 처리에서, 비디오 분할을 예로 들면, 비디오 분할을 수동 방식으로 구현할 수 있는데, 이는 많은 인건비 를 낭비할 뿐만 아니라 상기 시효성이 높은 장면의 요구 사항을 충족할 수 없다. 비-수동 방식의 일부 비디오 분할 방식은, 비디오 프레임의 콘텐츠 정보(예를 들면, 텍스트, 영상 내 물체, 동작 등)를 충분히 이해할 수 없 고, 비디오 이벤트의 연관성(예를 들면 숏 변환으로 인한 장면 전환 등)에 대해서도 제대로 파악할 수 없으므로 비디오 화면을 해석하는 정확도를 크게 저하시켜 타겟 비디오가 최종적으로 제공하는 비디오 품질에 영향을 미 치게 된다."}
{"patent_id": "10-2021-0142151", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 출원은 비디오 처리 방법, 장치, 전자 기기, 저장 매체 및 컴퓨터 프로그램을 제공한다."}
{"patent_id": "10-2021-0142151", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 출원의 일 측면에 따르면, 비디오 처리 방법을 제공한다. 상기 방법은, 복수의 제1 비디오 프레임을 획득하고, 상기 복수의 제1 비디오 프레임을 미세입도(fine granularity) 분할하여 복수의 제2 비디오 프레임을 획득하는 단계; 상기 복수의 제2 비디오 프레임과 관련된 멀티 모달 정보(multimodal information)에 따라 상기 복수의 제2 비 디오 프레임에 대해 특징 코딩을 진행하여, 상기 멀티 모달 정보 융합을 나타내는 특징 융합 정보를 획득하는 단계; 상기 특징 융합 정보에 의해 상기 복수의 제2 비디오 프레임에 대해 유사도 매칭을 진행하고, 유사도 매칭 결과 에 의해 타겟 비디오를 획득하는 단계를 포함한다. 본 출원의 다른 일 측면에 따르면, 비디오 처리 장치를 제공한다. 상기 장치는, 복수의 제1 비디오 프레임을 획득하고 상기 복수의 제1 비디오 프레임을 미세입도 분할하여 복수의 제2 비디오 프레임을 획득하는 분할 모듈; 상기 복수의 제2 비디오 프레임과 관련된 멀티 모달 정보에 의해 상기 복수의 제2 비디오 프레임에 대해 특징 코딩을 진행하여 상기 멀티 모달 정보 융합을 나타내는 특징 융합 정보를 획득하는 코딩 모듈; 상기 특징 융합 정보에 의해 상기 복수의 제2 비디오 프레임에 대해 유사도 매칭을 진행하고, 유사도 매칭 결과 에 의해 타겟 비디오를 획득하는 비디오 처리 모듈을 포함한다. 본 출원의 다른 일 측면에 따르면, 전자 기기를 제공한다. 상기 전자 기기는, 적어도 하나 이상의 프로세서; 및 상기 적어도 하나 이상의 프로세서에 통신 연결되는 메모리를 포함하고 상기 메모리에는 상기 적어도 하나 이상의 프로세서에 의해 실행 가능한 명령이 저장되고, 상기 명령은 상기 적 어도 하나 이상의 프로세서에 의해 실행되어 상기 적어도 하나 이상의 프로세서가 본 출원의 어느 일 실시예에 따른 상기 방법을 수행하도록 한다. 본 출원의 다른 일 측면에 따르면, 컴퓨터 명령이 저장된 비일시적 컴퓨터 판독 가능 저장 매체를 제공한다. 상 기 컴퓨터 명령은 컴퓨터가 본 출원의 어느 일 실시예에 따른 상기 방법을 실행하도록 한다. 본 출원의 다른 일 측면에 따르면, 컴퓨터 판독 가능 저장 매체에 저장된 컴퓨터 프로그램을 제공하며, 해당 컴 퓨터 프로그램 중의 명령이 프로세서에 의해 실행될 경우, 본 출원의 임의의 하나의 실시예 중의 방법을 실현한 다."}
{"patent_id": "10-2021-0142151", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 출원에 사용하여 복수의 제1 비디오 프레임을 획득하고, 상기 복수의 제1 비디오 프레임을 미세입도 분할하 여 복수의 제2 비디오 프레임을 획득할 수 있다. 상기 복수의 제2 비디오 프레임과 관련된 멀티 모달 정보에 의 해 상기 복수의 제2 비디오 프레임에 대해 특징 코딩을 진행하여 상기 멀티 모달 정보 융합을 나타내는 특징 융 합 정보를 획득할 수 있다. 상기 특징 융합 정보에 의해 상기 복수의 제2 비디오 프레임에 대해 유사도 매칭을 진행하여 유사도 매칭 결과에 의해 타겟 비디오를 획득할 수 있다. 상기 멀티 모달 정보를 기반으로 특징 코딩 을 진행하여 더 많은 비디오 콘텐츠 세부사항이 포함된 정보를 획득할 수 있으므로 유사도 매칭 후 얻은 타겟 비디오가 더욱 정확하여 비디오 분할의 정확도를 향상시켰다. 본 명세서에 기재된 내용은 본 출원의 실시예의 핵심 또는 중요한 특징을 표시하기 위한 것이 아니며, 또한 본 출원의 범위를 제한하기 위해 사용되는 것이 않음을 이해해야 한다. 본 출원의 기타 특징은 아래의 명세서를 통 해 쉽게 이해할 수 있을 것이다."}
{"patent_id": "10-2021-0142151", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하 도면을 결합하여 본 출원의 실시예의 다양한 세부사항이 포함된 본 출원의 예시적 실시예를 설명하며, 이 들은 예시적 실시예로만 간주되어야 한다. 따라서 당업자는 여기서 설명하는 실시예에 대해 본 출원의 범위 및사상을 벗어나지 않으면서 다양한 변경 및 수정을 진행할 수 있음을 알 수 있을 것이다. 마찬가지로, 명확성과 간결함을 위하여, 이하 설명에서는 공지된 기능 및 구조에 대한 설명을 생략한다. 본 명세서에서 \"및/또는\"이라는 표현은 연관된 대상의 연관 관계에 대해서만 설명하고 3가지 관계가 존재할 수 있음을 나타내고, 예를 들어, A 및/또는 B는 A만 존재하는 경우, A와 B가 동시에 존재하는 경우, B만 존재하는 경우의 3가지 경우를 나타낼 수 있다. 본문에서 \"적어도 하나 이상\"라는 용어는 여러 가지 중 임의의 하나 또는 여러 가지 중 적어도 두 개의 임의의 조합을 의미하고, 예를 들어, A, B, C중의 적어도 하나 이상을 포함하는 것은, A, B 및 C로 이루어진 집합 중에서 선택된 임의의 하나 또는 복수의 요소를 포함하는 것을 의미할 수 있 다. 본문에서 \"제1\", \"제2\"라는 용어는 복수의 유사한 기술 용어를 가리키고 또한 이를 구분하는 것을 의미하며, 순서를 한정하거나, 2개만을 한정하는 의미가 아니며, 예를 들어, 제1 특징 및 제2 특징은 두 종류/ 두 개 특징이 있음을 가리키며, 제1 특징은 하나 또는 복수일 수 있고, 제2 특징도 하나 또는 복수일 수 있다. 또한, 본 출원을 더 잘 설명하기 위해, 이하 구체적인 실시예에서는 많은 구체적인 세부사항을 제공한다. 당업 자라면, 본 출원은 일부 구체적인 세부사항이 없이도 동일하게 실시될 수 있음을 이해할 것이다. 일부 실시예에 서, 당업자에게 잘 알려진 방법, 수단, 요소 및 회로에 대해서는 본 출원의 요지를 강조하기 위해 상세하게 설 명하지 않는다. 비디오 분할은 인터넷 비디오 및 뉴미디어 쇼트 비디오 콘텐츠 플랫폼의 수요에 따라 기존의 TV미디어 프로그램 에 대해 2차 가공하는 것으로, 즉 종래의 전체 프로그램 콘텐츠를 일부 논리적 사고 또는 특정 필요에 따라 여 러 비디오로 분할하는 것이다. 인터넷 비디오 콘텐츠의 주요 소스는 종래의 TV미디어 프로그램, 다양한 기관의 비디오 제품, 영화 제작사의 영화 작품을 포함하고, 이러한 비디오의 분할을 통해 가치 있는 정보를 심층 발굴 하여 다시 편집한 후 인터랙티브 인터넷 TV(IPTV), OTT, 모바일 TV 및 뉴미디어 쇼트 비디오 플랫폼에 사용할 수 있어 뉴미디어 시청각 프로그램의 단편화 요구 사항을 충족시킬 수 있다. 이는, 영상 음성 편집 업계의 새로 운 시도이자 탐구이다. 종래의 수동 방식의 비디오 분할 기술은, 인적 자원을 이용하여 비디오를 편집하고 비디오 분할을 진행하는데, 이는 처리 시간이 길고 비디오가 많은 경우에 생선성이 서서히 증가하므로 시효성이 높은 케이스에 활용될 수 없어 많은 시간 및 경험을 허비할 뿐만 아니라 원가 및 시효성에 대한 요구를 만족할 수 없다. 비-수동 방식의 비디오 분할 기술의 경우, 예를 들면, 머신 러닝이 아닌 종래의 비디오 분할 알고리즘은, 비록 색조 및 블록 매 칭(block-matching)을 기반으로 비디오 분할을 진행할 수 있으나 사진, 숏 사이의 시각적 정보만 고려하므로 비 디오 프레임의 콘텐츠 정보를 이해할 수 없다. 또 예를 들면, 머신 러닝에 기반한 비디오 분할 기술은, 비록 클 러스터링 기법에 의해 비디오 분할(키 프레임의 추출, 이미지 특징의 묘사, 클러스터링 등을 포함함)을 진행할 수 있으나 비디오 이벤트의 연속성을 고려하지 않고, 숏 전환이 빈번한 일부 장면(도 1에 도시된 스포츠 경기 중 복수의 비디오 프레임으로 구성된 하이라이트 순간 등) 또는 복잡한 이벤트 장면에 여러 숏이 연속적으로 변 환하는 비디오가 존재하므로 비디오 분할의 효과가 좋지 않고 비디오 분할의 정확도가 낮은 편이다. 본 출원의 실시예에 따르면, 비디오 처리 방법을 제공한다. 도 2는 본 출원의 실시예에 따른 비디오 처리 방법 의 개략적인 흐름도이고, 상기 방법은 비디오 처리 장치에 적용될 수 있다. 예를 들면, 상기 장치는 실행 상태 중인 단말 또는 서버 또는 기타 처리 기기에 배치되어 비디오 프레임의 분할, 비디오 프레임의 특징 코딩, 비디 오 프레임의 유사도 매칭을 실행하여 최종 타겟 비디오 등을 획득할 수 있다. 여기서 단말은 유저 기기(UE, User Equipment), 모바일 기기, 셀룰러 폰, 무선 전화, 개인 휴대 정보 단말기 (PDA, Personal Digital Assistant), 휴대용 기기, 컴퓨팅 기기, 차량 탑재 기기, 웨어러블 기기 등일 수 있다. 일부 가능한 구현 방식 에서, 상기 방법은 또한 프로세서를 통해 메모리에 저장된 컴퓨터 판독 가능 명령을 호출하는 방식으로 구현될 수 있다. 도 2에 도시된 바와 같이, 상기 방법은, 복수의 제1 비디오 프레임을 획득하고 상기 복수의 제1 비디오 프레임을 미세입도 분할하여 복수의 제2 비디오 프레임을 획득하는 단계 S101; 상기 복수의 제2 비디오 프레임과 관련된 멀티 모달 정보에 의해 상기 복수의 제2 비디오 프레임에 대해 특징 코딩을 진행하여 상기 멀티 모달 정보 융합을 나타내는 특징 융합 정보를 획득하는 단계 S102; 상기 특징 융합 정보에 의해 상기 복수의 제2 비디오 프레임에 대해 유사도 매칭을 진행하고 유사도 매칭 결과 에 의해 타겟 비디오를 획득하는 단계 S103를 포함한다. 상기 단계 S101에서, 숏 및 색상 변환을 나타내는 매개변수에 따라 상기 복수의 제1 비디오 프레임을 미세입도 분할하여 상기 복수의 제2 비디오 프레임을 획득할 수 있다. 숏 및 색상 변환을 나타내는 매개변수는, 숏의 관점에서 볼 때 비디오 에지에 대한 분할, 비디오 내의 블록 매칭에 기반한 비디오 분할, 통계적 결정에 기반한 비디오 분할, 두 임계값의 비교에 기반한(두 임계값의 비교를 설정하여 급진적(abrupt) 숏 변화인지 점진적 (gradual) 숏 변화인지 구분) 비디오 분할 등을 포함할 수 있다. 색상 변환 관점에서 볼 때 색조에 기반한 비 디오 분할을 포함할 수 있다. 상기 단계 S102에서, 상기 멀티 모달 정보에 의해 상기 복수의 제2 비디오 프레임에 대해 특징 추출 및 특징 융 합처리하여 상기 특징 융합 정보를 획득할 수 있다. 그 중, 융합 처리는 복수의 신경망 모델을 사용하거나 또는 다기능 추출로 통합된 하나의 신경망 모델을 전문가 모델로 사용하여, 제2 비디오 프레임과 관련된 멀티 모달 정보에 대해 각각 특징 추출을 진행할 수 있다. 여기서, 멀티 모달 정보는, 지식 그래프 정보, 상기 텍스트 정 보, 상기 오디오 정보, 상기 색조 정보, 상기 물체 정보, 상기 동작 정보 중 적어도 하나 이상을 포함한다. 상기 단계 S103에서, 상기 특징 융합 정보에 의해 상기 복수의 제2 비디오 프레임의 유사도를 채점하고, 채점 결과를 상기 유사도 매칭 결과로 사용할 수 있다. 상기 유사도 매칭 결과가 동일 이벤트 콘텐츠에 대한 인접 비 디오 프레임이 유사한 경우, 상기 인접 비디오 프레임에 의해 상기 복수의 제2 비디오 프레임을 각각 머지하는 작업이 종료될 때까지 상기 인접 비디오 프레임에 대해 비디오 머지를 진행하고, 비디오 머지 결과에 따라 상기 타겟 비디오를 획득한다. 본 출원을 사용하여 복수의 제1 비디오 프레임을 획득하고 상기 복수의 제1 비디오 프레임을 미세입도 분할하여 복수의 제2 비디오 프레임을 획득할 수 있다. 상기 복수의 제2 비디오 프레임과 관련된 멀티 모달 정보에 의해, 상기 복수의 제2 비디오 프레임에 대해 특징 코딩을 진행하여 상기 멀티 모달 정보 융합을 나타내는 특징 융합 정보를 획득할 수 있다. 상기 특징 융합 정보에 의해, 상기 복수의 제2 비디오 프레임에 대해 유사도 매칭을 진 행하여 유사도 매칭 결과에 의해 타겟 비디오를 획득할 수 있다. 상기 멀티 모달 정보를 기반으로 특징 코딩을 진행할 수 있으므로 더 많은 비디오 콘텐츠 세부사항이 포함된 정보를 획득할 수 있고, 유사도에 따라 매칭한 후 얻은 타겟 비디오가 더 정확하여 비디오 분할의 정확도를 향상시켰다. 일 예시에서, 상기 단계 S101 내지 S103는 비디오 분할 모듈, 멀티 모달 특징 코딩 모듈, 유사도 매칭 모듈(주 로 인접된 비디오 세그먼트에 대한 유사도 매칭), 비디오 프레임 스플라이싱 모듈(video frame splicing module)을 통해 구현될 수 있다. 구체적으로, 상기 비디오 분할 모듈에 입력된 복수의 제1 비디오 프레임을 획 득한 후, 숏 및 색상 변환에 따라, 획득된 복수의 제1 비디오 프레임을 미세입도 분할하여 복수의 제2 비디오 프레임을 획득할 수 있다. 상기 멀티 모달 특징 코딩 모듈에 입력된 상기 복수의 제2 비디오 프레임에 대해, 멀 티 모달 정보에 의해 특징 코딩(예를 들어 멀티 모달 정보의 특징 추출 및 특징 융합)을 진행하여 멀티 모달 정 보가 융합된 특징 정보를 획득한다. 상기 특징 정보를 상기 유사도 매칭 모듈에 입력하고 비디오 유사도 매칭을 수행하여 유사도 매칭 결과(예를 들어 유사도의 채점 결과)를 획득한다. 유사도 매칭 결과가 동일 이벤트 콘텐 츠에 대한 2개의 인접 비디오 프레임이 유사한 경우, 동일한 이벤트 내의 비디오 세그먼트를 복원하는 전략에 따라 상기 비디오 세그먼트 스플라이싱 모듈을 통해 동일 이벤트 콘텐츠에 대한 두 인접 비디오 프레임을 각각 비디오 머지하여 비디오 처리의 최종 비디오 분할 결과를 얻는다. 동일 이벤트 콘텐츠에 대한 유사도 머지이므 로 비디오 콘텐츠 세부사항의 유사도에 더 집중하게 되고 이로 인해 비디오 분할이 더 정확하여 최종 비디오 분 할 결과의 정확도를 크게 향상시켰다. 일 실시방식에서, 사전 훈련된 제1 신경망 모델에 의해 상기 복수의 제2 비디오 프레임에서 상기 멀티 모달 정 보를 식별하는 단계를 더 포함한다. 일 예시에서, 제1 신경망 모델은 복수의 전문가 모델로 구성될 수 있고, 복수의 전문가 모델 각각의 기능을 하 나의 신경망에 통합시킬 수도 있다. 복수의 전문가 모델 각각의 기능을 하나의 신경망에 통합시킨 제1 신경망 모델을 예로 들면, 상기 제1 신경망 모델은 지식 그래프 추출기, 텍스트 추출기, 오디오 추출기, 색조 추출기, 물체 추출기 및 동작 추출기를 포함할 수 있다. 여기서, 제1 신경망 모델 중의 지식 그래프 추출기(또는 지식 그래프에 기반한 구조화 태그 벡터 추출기라고 칭함)에 의해 지식 그래프 정보(예를 들면 knowledge특징)를 식 별할 수 있고, 제1 신경망 모델 중의 텍스트 추출기(또는 텍스트에 기반한 텍스트 벡터 추출기라고 칭함)에 의 해 텍스트 정보(예를 들어 text특징)를 식별할 수 있고, 상기 제1 신경망 모델 중의 오디오 추출기(또는 오디오 에 기반한 오디오 벡터 추출기라고 칭함)에 의해 오디오 정보(예를 들어audio특징)를 식별할 수 있고, 상기 제1 신경망 모델 중의 색조 추출기(또는 이미지에 기반한 RGB추출기라고 칭함)에 의해 색조 정보(예를 들어RGB특 징)를 식별할 수 있고, 상기 제1 신경망 모델 중의 물체 추출기(또는 목표 검출에 기반한 물체 특징 추출기라고 칭함)에 의해 물체 정보(예를 들어object특징)를 식별할 수 있고, 상기 제1 신경망 모델 중의 동작 추출기(동작 식별에 기반한 동작 벡터 추출기)에 의해 동작 정보(예를 들어action특징)를 식별할 수 있다. 여기서, 상기 멀티 모달 정보는, 상기 지식 그래프 정보, 상기 텍스트 정보, 상기 오디오 정보, 상기 색조 정보, 상기 물체 정 보, 상기 동작 정보 중 적어도 하나 이상을 포함한다. 본 실시방식에 따라, 본 출원의 스마트 비디오 분할 기술과 머신 러닝에 기반한 복수의 전문가 모델을 결합하여 멀티 모달 정보의 특징 식별, 특징 추출 및 특징 융합을 구현한다. 더 나아가, 융합된 특징 정보(특징 융합 정 보라고 칭함)에 대해 유사도를 비교하여 보다 충분한 비디오 콘텐츠 세부사항 정보를 획득하여 비디오 콘텐츠 및 이벤트 지식을 깊이 이해하므로 가장 정밀한 비디오 분할 결과를 얻을 수 있어 최종 비디오 분할 결과의 정 확도를 대폭 향상시킬 수 있다. 일 실시방식에서, 비디오 특징 추출 모델 과 같은 사전 훈련된 제1 신경망 모델에 의해 상기 복수의 제2 비디 오 프레임에서 상기 멀티 모달 정보를 식별 및 추출할 수 있다. 비디오 특징 식별 모델 과 같은 제2 신경망 모델에 의해 상기 멀티 모달 정보 중 각 유형의 정보를 구분할 수 있다. 비디오에 대응하는 타이밍 정보의 추출 모델 과 같은 제3 신경망 모델에 의해 상기 멀티 모달 정보와 관련된 타이밍 정보를 식별 및 추출하고, 상기 비디오 특징 추출의 시간 오프셋 표현을 기록하고, 상기 제1 신경망 모델, 제2 신경망 모델, 상기 제3 신경망 모델의 출력 결과를 융합하여, 상기 특징 융합 정보를 획득한다. 특징 융합 정보는 더 많은 비디오 콘텐츠의 세 부사항을 묘사할 수 있으므로 후속 유사도 비교 시 매칭 속도 및 정확도를 향상시키는데 도움이 될 수 있다. 그 러므로, 동일 이벤트 콘텐츠에 대한 2개의 인접 비디오 프레임을 유사도 매칭한 후 얻은 비디오 처리의 최종 비 디오 분할 결과가 더 정밀하고 비디오 분할이 더 정확하여 최종 비디오 분할 결과의 정확도를 대폭 향상시킬 수 있다. 적용 예시: 본 출원의 실시예 1의 처리 절차는 다음 내용을 포함한다. 도 3은 본 출원의 실시예에 따른 비디오 처리 방법을 구현하는 시스템 모듈의 구성도이고, 비디오 분할 모듈(주 로 숏 및 색상 변환에 따라 비디오를 미세입도 분할함), 멀티 모달 특징 코딩 모듈(주로 멀티 모달 정보를 이용 하여 비디오에 대해 특징 코딩을 진행함), 유사도 매칭 모듈(주로 인접 비디오 세그먼트에 대해 유사도 매칭을 진행한 다음 비디오 세그먼트에 대해 동일 이벤트 콘텐츠에 따라 비디오 머지를 진행하여 최종 비디오 분할 결 과를 얻을 수 있음)로 구성된 시스템에 의해 본 출원의 스마트 비디오 분할 절차를 구현할 수 있다. 멀티 모달 정보의 융합을 통해 비디오 콘텐츠 및 이벤트 지식을 깊이 이해하고, 딥 러닝을 결합하여 비디오를 분할한다. 도 3에 도시된 바와 같이, 다음 구성을 포함한다. 1. 비디오 분할 모듈 비디오 분할 모듈을 통해 비디오 세그먼트의 미세입도 분할을 구현할 수 있고, 미세입도 분할의 원칙은 주로 색 조에 기반한 분할, 에지에 기반한 분할, 블록 매칭에 기반한 분할, 통계적 결정에 기반한 분할, 두 임계값 비교 에 기반한 분할을 포함한다. 여기서, 1)색조에 기반한 분할인 경우, 2개 프레임의 그레이 스케일 차이를 직접 계산할 수 있고, 전체 프레임 차이가 특정 설정된 임계값보다 크면, 급진적 숏 변화가 존재하고, 2)에지에 기반 한 분할인 경우, 에지 특성은 숏 분할에 사용되며, 먼저 프레임 간의 전체 변위를 계산하고 이에 따라 정합을 진행한 다음 에지의 개수 및 위치를 계산하고, 3)블록 매칭에 기반한 분할인 경우, 비-압축 비디오에 사용하는 블록 매칭 숏을 예로 들면, 모션 평활도 측정을 통해 숏의 변화를 검출할 수 있고, 4)통계적 결정에 기반한 분 할인 경우, 모션 보상 특징 및 적응 임계값(Adaptive Thresholding), 그리고 비디오 시퀀스의 시계열 급진적 숏 변화 모드 및 숏 길이 분포 정보를 이용하여 하나의 통계적 결정 모델을 형성하고, 상기 통계적 결정 모델을 통 해 유추한 기준은 숏 검출 오류율을 최소화할 수 있고, 5)이중 임계값 비교에 기반한 분할인 경우, 2개의 임계 값(예를 들면Tb, Ts)을 설정할 수 있다. 프레임 차이가 Tb보다 클 경우, 급진적 숏 변화가 존재하고, 프레임 차 이가 Tb보다 작고 Ts보다 클 경우 점진적 숏 변화가 존재한다. 후속 프레임의 프레임 차이가 Ts를 초과하기 시 작할 때, 해당 프레임을 점진적 숏 변화의 시작 프레임이라고 칭하되, 이하 마찬가지이다. 2. 멀티 모달 특징 코딩 모듈 도 4는 본 출원의 실시예에 따른 멀티 모달 정보를 기반으로 특징 코딩을 구현하는 개략도이고, 멀티 모달 특징 코딩은 주로 복수의 전문가 모델을 통해 여러 전문가 벡터(experts embedding)를 획득하고, 이러한 experts embedding을 통해 전체 비디오의 멀티 모달 정보에 대한 부각 및 특징 추출을 완성한다. 도 4에 도시된 바와 같 이, 다음과 같은 내용을 포함한다. 비디오 레벨 벡터(embedding) 표현은, 멀티 모달 변환기(MMT, Multi-modual Transformer)와 같은 멀티 모달 특 징 코딩 모듈의 일 예시에 의해 획득된다. MMT는 Transformer인코더의 아키텍처를 준수할 수 있고, Transformer 인코더는 스택된 셀프 어텐션 메커니즘(Self-Attention)층 및 완전연결층으로 구성된다. MMT의 입력Ω( )은 하 나의 embedding 표현 세트이고, 모든 차원이 동일하고, 차원으로 규정하되, 이들 중 각 embedding은 모두 하나의 특징 표현 세트를 나타내고, 해당 입력은 식에 표시된 바와 같다."}
{"patent_id": "10-2021-0142151", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "여기서, 식의 각 매개변수의 의미는 다음과 같다. Ω()는 비디오 프레임을 특징 코딩한 후의 벡터 출력이고, F()는 비디오 특징 추출 모델을 나타내고, 비디오 중의 멀티 모달 정보를 추출한다. 여기서, 는 지식 그래프 정보(예를 들면 knowledge특징)의 추출하는 것을 나타내고, \"kno\"는 knowledge특징의 약어이고, \"k\"는 벡터의 차원을 나타내고, \"agg\"는 평균 벡터를 나타내고, 이런 식으로, 텍스 트 정보(예를 들면 text특징), 오디오 정보(예를 들면 audio특징), 색조 정보(예를 들면 RGB특징), 물체 정보 (예를 들면 object특징) 및 동작 정보(예를 들면 action특징)를 각각 추출할 수 있고; M()은 비디오 특징 식별 모델을 나타내고, 멀티 모달 정보 중 다양한 유형의 정보를 구분하고, T()는 비디오에 대응하는 타이밍 정보의 추출 모델을 나타내고, 타이밍 정보(즉 시계열 벡터)를 추출 및 기록 하여 특징 추출의 시간 오프셋 표현을 기록하고, 여기서, 는 추출된 타이밍 정보를 나타내고, \"D\"는 몇 초인지 나타낸다. F()를 통해 추출된 상기 멀티 모달 정보의 경우, 비디오 데이터 고유의 다양한 형식에서 유효한 표현을 학습 하기 위해, 다양한 전문가 모델을 비디오 특징 추출기로 사용하여 상기 멀티 모달 정보를 추출할 수 있고, 다양 한 전문가 모델은 주로 지식 그래프에 기반한 구조화 태그embedding추출기, 텍스트에 기반한 text embedding추 출기, 오디오에 기반한 audio embedding추출기, 이미지에 기반한 RGB추출기, 및 목표 검출에 기반한 object특징 추출기 및 동작 식별에 기반한 action embedding추출기를 포함하고, 다양한 전문가 모델에서 각각 추출된 상기 멀티 모달 정보의 특징 융합을 통해, 다양한 콘텐츠 차원에서 비디오 정보를 다각도로 표현할 수 있다. 특징 융 합을 통해, 학습하여 얻은, 상이한 전문가 모델에서 추출한 상기 멀티 모달 정보 간의 관계를 기반으로, 또한 크로스 모드와 긴 시퀀스 시간 관계를 이용하여 연합 표현할 수 있으므로 사전 훈련된 상이한 전문가 모델 을 이용하여 더 정확한 비디오 콘텐츠 세부사항을 얻을 수 있다. 각 전문가 모델은 모두 특정 훈련을 받은 후 얻은 것으로서, 멀티 모달 정보의 특징 추출에 사용된다. 하나의 비디오 에 대해, 각 전문가 모델은 K개의 특징(features)이 포함된 하나의 시퀀스를 추출할 수 있는데, 로 표기한다. 다양한 전문가 모델을 통해 비디오의 feature표현을 추출하는 경우, 상이한 전문가 모델을 사용하여 특징 추출 을 진행하므로 추출된 상이한 전문가 벡터의 특징(또는 특징 벡터라고 칭함)을 공통 차원에 매핑하기 위해, N개의 linear layer를 사용하여(전문가당 1개 추출) 모든 특징을 에 투영할 수 있다. Transformer 인코더는 각 특징 입력에 대해 하나의 embedding을 형성하여 복수의 특징에 대해 복수의 embedding"}
{"patent_id": "10-2021-0142151", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "표현을 제공한다. 각 특징의 유일한 embedding 표현을 얻기 위해, 하나의 요약 embedding 을 정의할 수 있 고, 상기 embedding은 수집된 특징을 맥락화(contextualization)하고(현재 표현을 집합), 맥스 풀링을 통해 해 당 임베딩을 초기화하므로( ), 전체 입력되는 Feature시퀀스의 형식은 식에 나타낸 바와 같다."}
{"patent_id": "10-2021-0142151", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "식에서, N은 전문가 모델의 수를 나타내고(N은 1보다 큰 양의 정수임), K는 벡터 차원을 나타낸다(K는 1보다 큰 양의 정수임). M()을 통한 멀티 모달 정보 중 상이한 유형 정보를 구분함에 있어서, 멀티 모달 정보를 더 잘 처리하고 구분 하기 위해, MMT는 현재 처리하는 embedding임베딩이 어느 전문가 모델로부터의 입력인지 구분해야 하고, N개의 차원의 embeddings임베딩 을 학습하여 상이한 전문가의 embedding 표현을 구분할 수 있다. 전문가 모델의 embeddings에서 비디오 인코더까지의 시퀀스는 다음 식에 표시된 형식을 사용한다."}
{"patent_id": "10-2021-0142151", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "식에서, N은 전문가 모델의 수를 나타낸다(N은 1보다 큰 양의 정수임). T()를 통한 타이밍 정보의 기록은, 비디오 중 각 특징이 MMT로부터 추출되는 시간 정보를 제공한다. 하나의 비디오의 최장 길이는 초일 수 있고, \"초\"를 메트릭 파라미터로 사용하되, 초마다 하나의 차원의 D=| |를 학습하고, 형식은 와 같다. 시간 범위 [t, t+1)에서 추출된 각 전문가 모드 feature는 로 표시된다. 예를 들면, 비디오에서 2.2초에 추출된 특징은 시간 임베딩 을 통해 시간 코딩을 진행한다. 2개의 부가 시간 임베딩 및 을 학습하고, 집계 특징 및 알 수 없는 시간 정보 특징을 각각 코딩한다. 마지막으 로, Temporal embeddings T시퀀스는 다음 식에 표시된 형식을 사용한다."}
{"patent_id": "10-2021-0142151", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "식에서, 는 시간 정보의 평균 벡터를 나타내고, 는 제D초(D는 1초보다 큰 수치임)의 시간 정보를 나타 낸다. MMT의 구현 방식은 다음 식에 표시된 바와 같다."}
{"patent_id": "10-2021-0142151", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 7, "content": "식에서, N은 전문가 모델의 수를 나타내고, 동시에, _agg ()로 비디오 요약 정보를 나타낸다. 는 MMT의 입력이다. 3. 유사도 매칭 모듈: 도 5는 본 출원의 실시예에 따른 유사도 매칭 개략도이고, 유사도 매칭 모듈에 의해 주로 인접한 2개의 비디오 세그먼트의 유사도 계산을 완성하고, 유사도 매칭은 상하 대칭되는 모듈 설계를 사용한다. 복수의 전문가 모델 embeding에 대한 유사도 계산을 통해, 가중치 연산(가중치는 어텐션 메커니즘을 통해 자동으로 학습할 수 있 음)을 이용하여 유사도 점수를 얻음으로써 유사도 매칭 결과를 얻는다. 손실 함수는 양방향 최대 경계 손실 함 수(bi-directional max-margin ranking loss)를 사용할 수 있고, 식에 표시된 바와 같다."}
{"patent_id": "10-2021-0142151", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 8, "content": "식에서, 는 상기 손실 함수를 나타내고, B는 샘플 배치 처리를 위한 초매개변수(batch size)를 나타내고, 이고, 는 2개의 비디오 세그먼트의 유사도를 나타내고, m은 margin이고, 값은 (0, 1)이 될 수 있다. 4. 유사도 매칭 모듈은 상기 도 3을 토대로 유사도 매칭 모듈 뒤에 하나의 비디오 프레임 스플라이싱 모듈을 추 가하여 비디오 스플라이싱 처리에 전문적으로 사용된다. 도 6은 본 출원의 실시예에 따른 비디오 머지 개략도이고, 상기 비디오 스플라이싱 처리를 통합한 유사도 매칭 모듈을 예로 들면, 도 6에 도시된 바와 같이, 유사도 매칭 모듈을 통해 인접 비디오 세그먼트의 머지 스플라이 싱을 구현할 수 있고, 주로 동일한 이벤트 내의 비디오 세부 세그먼트를 복원하되, 인접한 2개의 비디오 세그먼 트가 유사한 것으로 판단되면, 2개의 비디오를 머지하는 바, 순차적으로 비교하여 최종 비디오 분할 결과를 얻 는다. 본 적용 예시를 사용하면, 멀티 모달 정보를 추출하기 위한 복수의 전문가 모델의 정보를 융합할 수 있고, 멀티 모달 정보를 캡처 및 융합함으로써 다각도 비디오 콘텐츠를 전반적으로 부각시켜 비디오 화면의 디스플레이 효 과를 개선하고, 딥 러닝 방식을 통해 대규모 대량의 비디오 분할을 진행할 수 있고, 또한 전체 프로세스가 보다 효율적이고 원가가 저렴하여 시효성이 높은 비디오 요구 조건을 충족할 수 있다. 그리고, KG기반의 구조화 태그 기술(예를 들어 엔티티, 토픽 등), 텍스트 기반의 표현 기술, 시각(RGB, Object, Action)기반의 기술 등을 결합 하여, 비디오 콘텐츠 관점에서 비디오를 분할할 수 있어 여러 숏의 빈번한 전환으로 인해 분할 효과가 저하되는 문제를 해결할 수 있다. 그리고 확장성이 강하고, 사용되는 시나리오가 비디오 기술에만 국한되지 않고, 비디오 지문 인식, 짧은 비디오에 기인한 긴 비디오, 동일한 비디오 매칭과 같은 모든 비디오의 유사도 매칭 시나리오 에 적용될 수 있다. 본 출원의 실시예에 따르면, 비디오 처리 장치를 제공한다. 도 7은 본 출원의 실시예에 따른 비디오 처리 장치 의 구성을 나타낸 개략도이고, 도 7에 도시된 바와 같이, 상기 장치는, 복수의 제1 비디오 프레임을 획득하고, 상기 복수의 제1 비디오 프레임을 미세입도 분할하여 복수의 제2 비디오 프레임을 획득하는 분할 모듈; 상 기 복수의 제2 비디오 프레임과 관련된 멀티 모달 정보에 의해, 상기 복수의 제2 비디오 프레임에 대해 특징 코 딩을 진행하여 상기 멀티 모달 정보 융합을 나타내는 특징 융합 정보를 획득하는 코딩 모듈; 상기 특징 융 합 정보에 의해 상기 복수의 제2 비디오 프레임에 대해 유사도 매칭을 진행하고 유사도 매칭 결과에 의해 타겟 비디오를 획득하는 비디오 처리 모듈을 포함한다. 일 실시방식에서, 상기 분할 모듈은, 숏 및 색상 변환을 나타내는 매개변수에 따라 상기 복수의 제1 비디오 프 레임을 미세입도 분할하여 상기 복수의 제2 비디오 프레임을 획득한다. 일 실시방식에서, 상기 코딩 모듈은, 상기 멀티 모달 정보에 의해 상기 복수의 제2 비디오 프레임에 대해 특징 추출 및 특징 융합처리하여 상기 특징 융합 정보를 획득한다. 일 실시방식에서, 상기 비디오 처리 모듈은, 상기 특징 융합 정보에 의해 상기 복수의 제2 비디오 프레임의 유 사도에 대해 채점하고, 채점 결과를 상기 유사도 매칭 결과로 사용하고, 상기 유사도 매칭 결과가 동일 이벤트 콘텐츠에 대한 인접 비디오 프레임이 유사한 경우, 상기 인접 비디오 프레임에 의해 상기 복수의 제2 비디오 프 레임을 각각 머지하는 작업이 종료될 때까지 상기 인접 비디오 프레임에 대해 비디오 머지를 진행하고, 비디오 머지 결과에 따라 상기 타겟 비디오를 획득한다. 일 실시방식에서, 사전 훈련된 제1 신경망 모델에 의해 상기 복수의 제2 비디오 프레임에서 상기 멀티 모달 정 보를 식별하는 식별 모듈을 더 포함한다. 일 실시방식에서, 상기 식별 모듈은, 상기 제1 신경망 모델 중의 지식 그래프 추출기에 의해 지식 그래프 정보 를 식별하고, 상기 제1 신경망 모델 중의 텍스트 추출기에 의해 텍스트 정보를 식별하고, 상기 제1 신경망 모델 중의 오디오 추출기에 의해 오디오 정보를 식별하고, 상기 제1 신경망 모델 중의 색조 추출기에 의해 색조 정보 를 식별하고, 상기 제1 신경망 모델 중의 물체 추출기에 의해 물체 정보를 식별하고, 상기 제1 신경망 모델 중 의 동작 추출기에 의해 동작 정보를 식별한다. 상기 멀티 모달 정보는 상기 지식 그래프 정보, 상기 텍스트 정 보, 상기 오디오 정보, 상기 색조 정보, 상기 물체 정보, 상기 동작 정보 중 적어도 하나 이상을 포함한다. 일 실시방식에서, 제2 신경망 모델에 의해 상기 멀티 모달 정보 중 각 유형의 정보를 구분하고, 제3 신경망 모 델에 의해 상기 멀티 모달 정보와 관련된 타이밍 정보를 식별하고, 상기 제1 신경망 모델, 제2 신경망 모델, 상 기 제3 신경망 모델의 출력 결과를 융합하여 상기 특징 융합 정보를 획득하는 융합 모듈을 더 포함한다. 본 출원 실시예에서 각 장치 중의 각 모듈의 기능은 상술한 방법의 해당 설명 부분을 참조할 수 있으므로 중복 설명하지 않는다. 본 출원의 실시예에 따르면, 본 출원은 전자 기기 및 판독 가능 저장 매체를 더 제공한다. 도 8에 도시된 바와 같이, 이는 본 출원의 실시예에 따른 비디오 처리 방법을 구현하는 전자 기기의 블록도이다. 상기 전자 기기는 전술한 설치 디바이스 또는 프록시 디바이스일 수 있다. 전자 기기는 랩 컴퓨터, 데스크탑 컴퓨터, 워크스테이션, PDA, 서버, 블레이드 서버(blade server), 대형 컴퓨터 및 기타 적절한 컴퓨터 와 같은 여러 종류의 디지털 컴퓨터를 지칭한다. 전자 기기는 PDA(Personal Digital Assistant), 이동전화 (Cellular phone), 스마트폰(smartphone), 웨어러블 디바이스(wearable device) 및 기타 유사한 컴퓨팅 장치와 같은 다양한 이동식 장치를 지칭할 수도 있다. 본 명세서에 언급된 부재, 이들의 연결 및 관계, 그리고 이들의 기능은 예시에 불과하고, 기재 및/또는 청구한 본 출원의 구현을 한정하는데 있는 것이 아니다. 도 8에 도시된 바와 같이, 상기 전자 기기는 하나 또는 복수의 프로세서, 메모리, 및 각 부재를 연결 하고 고속 인터페이스 및 저속 인터페이스를 포함하는 인터페이스를 포함한다. 각 부재는 서로 다른 버스를 이 용하여 상호 연결되며, 공동 메인 보드에 장착될 수 있으며 필요에 따라 다른 방식으로도 장착될 수 있다. 프로 세서는 전자 기기 내에서 실행되는 명령을 처리할 수 있으며, 메모리 또는 메모리 상에 저장되어 외부 입력/출 력 장치(예컨대, 인터페이스에 커플링되는 디스플레이 장치) 상에 GUI 이미지 정보를 출력하는 명령을 포함한다. 기타 실시방식에서, 필요하다면 복수의 프로세서 및/또는 복수의 버스를 복수의 메모리와 함께 사용 할 수 있다. 마찬가지로, 복수의 전자 기기를 연결할 수 있으며, 각 기기는 일부 필요한 동작(예를 들어, 서버 어레이, 한 세트의 블레이드 서버 또는 멀티 프로세서 시스템으로서)을 제공한다. 도 8은 하나의 프로세서(80 1)를 예로 한다. 메모리는 본 출원에서 제공되는 비일시적 컴퓨터 판독 가능 저장 매체이다. 여기서, 하나 이상의 프로세서 가 본 출원에 따른 비디오 처리 방법을 구현하도록 상기 메모리에 하나 이상의 프로세서에 의해 실행되는 명령 이 저장되어 있다. 본 출원의 비일시적 컴퓨터 판독 가능 저장 매체는 컴퓨터 명령을 저장한다. 상기 컴퓨터 명 령은 컴퓨터가 본 출원에 따른 비디오 처리 방법을 구현하도록 한다. 메모리는 비일시적 컴퓨터 판독 가능 저장 매체로서, 비일시적 소프트웨어 프로그램, 비일시적 컴퓨터 실 행가능 프로그램 및 모듈, 예를 들어 본 출원의 실시예에 따른 비디오 처리 방법에 대응되는 프로그램 명령/모 듈(예를 들어, 도7에 도시된 분할 모듈, 코딩 모듈, 비디오 처리 모듈 등 모듈)을 저장하는데 사용된다. 프로세 서는 메모리에 저장된 비일시적 소프트웨어 프로그램, 명령 및 모듈을 실행함으로써 서버의 다양한 기능 활용 및 데이터 처리를 수행하여 상기 실시예의 비디오 처리 방법을 구현한다. 메모리는 프로그램 저장 영역 및 데이터 저장 영역을 포함할 수 있다. 여기서, 프로그램 저장 영역은 운영 체제, 하나 이상의 기능에 필요한 응용 프로그램을 저장할 수 있다. 데이터 저장 영역은 전자 기기의 사용으로 생성된 데이터 등을 저장할 수 있다. 또한, 메모리는 고속 랜덤 액세스 메모리(high speed random access memory)을 포함하고, 비일시적 메모리, 예를 들어 하나 이상의 디스크 메모리, 플래시 메모리 또는 기타 비일시 적 고체 메모리를 포함할 수도 있다. 일부 실시예에서, 메모리는 프로세서에 대해 원격 설치되는 메 모리를 선택할 수 있으며, 이러한 원격 메모리(remote memory)는 네트워크를 통해 전자 기기에 연결될 수 있다. 상기 네트워크의 실제 예로는 인터넷, 기업 내부 네트워크, LAN, 이동통신망 및 그 조합을 포함할 수 있으나 이 에 한정되지 않는다. 비디오 처리 방법의 전자 기기는 입력장치 및 출력장치를 더 포함할 수 있다. 프로세서, 메모리 , 입력장치 및 출력장치는 버스 또는 기타 방식을 통해 연결될 수 있으며, 도 8에는 버스를 통 해 연결되는 것을 일 예로 한다. 입력장치는 입력된 숫자 또는 문자 정보를 수신하고, 전자 기기의 사용자 설정 및 기능 제어에 관한 키 입 력 신호를 생성할 수 있으며, 예를 들어 터치스크린, 키보드, 마우스, 트랙패드, 터치패드, 지시스틱, 하나 또 는 복수의 마우스 버턴, 트랙볼, 조이스틱 등 입력장치이다. 출력장치는 디스플레이 장치, 보조 조명 장치 (예를 들어, LED) 및 촉각 피드백 장치(예를 들어, 진동 모터)등을 포함할 수 있다. 상기 디스플레이 장치는 액 정 디스플레이(LCD), 발광다이오드(LED) 디스플레이 및 플라스마 디스플레이를 포함하나 이에 한정되지 않는다. 일부 실시방식에서, 디스플레이 장치는 터치스크린일 수 있다. 여기서 설명된 시스템 및 기술의 다양한 실시양태는 디지털 회로 시스템, 집적회로 시스템, 전용 ASIC(전용 접 적회로), 컴퓨터 하드웨어, 펌웨어, 소프트웨어, 및 /또는 이들의 조합에서 구현될 수 있다. 상기 다양한 실시 양태는 하나 또는 복수의 컴퓨터 프로그램에서 실시되고, 상기 하나 또는 복수의 컴퓨터 프로그램은 하나 이상 의 프로그램 가능 프로세서를 포함하는 프로그램 가능 시스템 상에서 실행 및/또는 해석된다. 상기 프로그램 가 능 프로세서는 전용 또는 범용 프로그램 가능 프로세서일 수 있으며, 저장 시스템, 하나 이상의 입력장치 및 하 나 이상의 출력장치로부터 데이터 및 명령을 수신하고, 데이터 및 명령을 상기 저장 시스템, 상기 하나 이상의 입력장치 및 상기 하나 이상의 출력장치로 전송할 수 있다. 이들 컴퓨터 프로그램(프로그램, 소프트웨어, 소프트웨어 애플리케이션 또는 코드로도 알려짐)은 프로그램 가능 프로세서를 위한 기계 명령어를 포함하고, 높은 레벨 프로세스 및/또는 객체 지향 프로그래밍 언어 및/또는 어 셈블리/기계 언어로 구현될 수 있다. 본 명세서에서 \"기계 판독 가능 매체\", \"컴퓨터 판독 가능 매체\"라는 용어 는, 기계 판독 가능 신호인 기계 명령을 수신하는 기계 판독 가능 매체를 포함하는, 프로그램 가능 프로세서로 기계 명령어 및/또는 데이터를 제공하기 위해 사용되는 임의의 컴퓨터 프로그램 제품, 장치 및/또는 디바이스 (예컨대, 자기 디스크, 광 디스크, 메모리, 프로그램 가능 논리 장치(PLD))을 지칭한다. \"기계 판독 가능 신 호\"라는 용어는 프로그램 가능 프로세서로 기계 명령어 및/또는 데이터를 제공하기 위해 사용되는 임의의 신호를 지칭한다. 사용자와의 상호 작용을 제공하기 위해, 본 명세서에 기술된 시스템 및 기술은 사용자에게 정보를 디스플레이하 기 위한 디스플레이 디바이스(예컨대, CRT(cathode ray tube) 또는 LCD(liquid crystal display) 모니터) 및 사용자가 컴퓨터에 입력하는 키보드 및 포인팅 디바이스(예컨대, 마우스 또는 트랙볼)를 갖는 컴퓨터상에서 구 현될 수 있다. 다른 종류의 디바이스도 사용자와의 상호 작용을 제공하기 위해 사용될 수 있는데, 예를 들어, 사용자에게 제공된 피드백은 임의의 형태의 감각 피드백(예컨대, 시각적 피드백, 청각 피드백 또는 촉각적 피드 백)일 수 있으며, 사용자로부터의 입력은 임의의 형태(음향, 음성 또는 촉각 입력을 포함)로 수신될 수 있다. 본 명세서에서 설명된 시스템 및 기술은 백 엔드(back end) 컴포넌트(예컨대, 데이터 서버)를 포함하거나 미들 웨어 컴포넌트(예컨대, 애플리케이션 서버)를 포함하거나, 또는 프론트 엔드 컴포넌트(예컨대, 그래픽 사용자 인터페이스 또는 웹 브라우저를 갖는 사용자 컴퓨터이며 사용자는 상기 그래픽 사용자 인터페이스 또는 웹 브라 우저를 통해 본 명세서에서 기술된 시스템 및 기술의 실시양태와 연동할 수 있다.)를 포함하거나, 또는 백 엔드, 미들웨어 또는 프런트 엔드 컴포넌트의 임의의 조합을 포함하는 컴퓨팅 시스템에서 구현될 수 있다. 시스 템의 컴포넌트는 임의의 형태 또는 매체의 디지털 데이터 통신(예컨대, 통신 네트워크)에 의해 상호 접속될 수 있다. 통신 네트워크의 예로는 근거리 통신망(LAN), 광역 통신망(WAN), 및 인터넷을 포함한다. 컴퓨터 시스템은 클라이언트단 및 서버를 포함할 수 있다. 클라이언트단과 서버는 서로 멀리 떨어져 있으며 일 반적으로 통신 네트워크를 통해 연동된다. 상응한 컴퓨터 상에서 실행되고 각각 클라이언트단-서버 관계를 갖는 컴퓨터 프로그램을 통해 클라이언트단과 서버의 관계를 생성한다. 서버는 클라우드 서버일 수 있으며, 클라우드 컴퓨팅 서버 또는 클라우드 호스트로도 불리며, 클라우드 컴퓨팅 서비스 체계 중의 호스트 제품 중 하나로서, 전통 물리적 호스트와 가상 전용 서버(VPS) 서비스에 존재하는, 관리가 어렵고 서비스 확장성이 취약한 단점을 해결한다. 서버는 분산식 시스템의 서버 또는 블록체인이 결합된 서버일 수 있다. 본 출원을 사용하여 복수의 제1 비디오 프레임을 획득하고, 상기 복수의 제1 비디오 프레임을 미세입도 분할하 여 복수의 제2 비디오 프레임을 획득할 수 있다. 상기 복수의 제2 비디오 프레임과 관련된 멀티 모달 정보에 의 해 상기 복수의 제2 비디오 프레임에 대해 특징 코딩을 진행하여 상기 멀티 모달 정보 융합을 나타내는 특징 융 합 정보를 획득할 수 있다. 상기 특징 융합 정보에 의해 상기 복수의 제2 비디오 프레임에 대해 유사도 매칭을 진행하여 유사도 매칭 결과에 의해 타겟 비디오를 획득할 수 있다. 상기 멀티 모달 정보를 기반으로 특징 코딩 을 진행하여 더 많은 비디오 콘텐츠 세부사항이 포함된 정보를 획득할 수 있으므로 유사도 매칭 후 얻은 타겟 비디오가 더욱 정확하여 비디오 분할의 정확도를 향상시켰다. 위에 기술된 다양한 형식의 프로세스, 재배열, 추가 또는 삭제의 단계가 적용될 수 있음을 이해해야 한다. 예를 들어, 본 출원에 기재된 각 단계는 병렬로 진행할 수도, 순차적으로 진행할 수도, 다른 순서로 진행될 수도 있 는 바, 본 출원에 개시된 기술적 수단이 목표한 결과를 구현할 수만 있다면 특별히 한정하지 않는다."}
{"patent_id": "10-2021-0142151", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 9, "content": "상기 구체적 실시방식은 본 출원의 보호범위를 한정하지 않는다. 본 기술분야의 일반 기술자는 설계 요구 및 기 타 요소에 따라 다양한 수정, 조합, 서브 조합 및 대체가 가능하다는 것을 알 수 있다. 본 출원의 사상 및 원칙 내에서 진행한 그 어떠한 수정, 균등한 치환 및 개선 등은 모두 본 출원의 보호 범위에 속한다."}
{"patent_id": "10-2021-0142151", "section": "도면", "subsection": "도면설명", "item": 1, "content": "아래 첨부 도면들은 본 기술적 해결수단을 보다 쉽게 이해하는데 사용되며, 본 출원에 대한 한정이 아니다. 도 1은 본 출원의 실시예에 따른 비디오 처리에서 시효성이 높은 장면의 복수의 비디오 프레임의 개략도이다. 도 2는 본 출원의 실시예에 따른 비디오 처리 방법의 개략적인 흐름도이다. 도 3은 본 출원의 실시예에 따른, 비디오 처리 방법을 구현하는 시스템 모듈의 아키텍쳐 도면이다. 도 4는 본 출원의 실시예에 따른 멀티 모달 정보를 기반으로 특징 코딩을 구현하는 개략도이다. 도 5는 본 출원의 실시예에 따른 유사도 매칭의 개략도이다. 도 6은 본 출원의 실시예에 따른 비디오 머지(video merge)의 개략도이다. 도 7은 본 출원의 실시예에 따른 비디오 처리 장치의 구성을 나타낸 개략도이다. 도 8은 본 출원의 실시예에 따른 비디오 처리 방법을 구현하는 전자 기기의 블록도이다."}
