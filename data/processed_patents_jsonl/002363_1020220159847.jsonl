{"patent_id": "10-2022-0159847", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0077679", "출원번호": "10-2022-0159847", "발명의 명칭": "소리인식 감독관 기술을 활용한 유러닝 학습 플랫폼에서 학습 주의 집중 시스템 및 방법", "출원인": "(주)엔에스데블", "발명자": "이언주"}}
{"patent_id": "10-2022-0159847", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "온라인 학습 또는 유비쿼터스 기반 학습(UBL) 시에, 학습자의 출석을 기록하고 학습 콘텐츠를 제공하며, 사용자단말의 학습자가 바른 자세로 주의 집중학습되도록 학습자 단말의 음성 인식 모듈에 의해 학습자의 말소리를 인식하여 경고 메시지를 발생하는 LRS 서버; 상기 LRS 서버와 유무선 통신망을 통해 연결되고, 상기 학습 콘텐츠를 제공받고 학습자의 말소리를 인식하며,상기 LRS 서버로부터 학습 패턴과 통계 데이터를 제공받으며, 음성 인식 모듈을 구비한 학습자 단말들; 및 상기 LRS 서버와 유무선 통신망을 통해 연결되는 감독관 단말; 을 포함하는 소리인식 감독관 기술을 활용한 유러닝 학습 플랫폼에서의 학습 주의 집중 시스템."}
{"patent_id": "10-2022-0159847", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 학습자 단말들과 감독관 단말은 PC, 노트북, 스마트폰 또는 태블릿 PC를 사용하는 소리인식 감독관 기술을활용한 유러닝 학습 플랫폼에서의 학습 주의 집중 시스템."}
{"patent_id": "10-2022-0159847", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서, 상기 학습자 단말은 음성 인식 모듈이 구비되고, 상기 음성 인식 모듈은 주변 잡음을 필터링하고 학습자의 말소리를 샘플링(8k, 16k, 또는 48k 샘플링)하여 음성을 인식하기 위해 SileroVAD 및 SpeechBrain 알고리즘을 사용하는, 소리인식 감독관 기술을 활용한 유러닝 학습 플랫폼에서의 학습 주의 집중 시스템."}
{"patent_id": "10-2022-0159847", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서, 상기 LRS 서버는 학습자 단말과 감독관 단말과 유무선 통신을 통해 연결되는 WWW 서버; 유무선 통신망을 통해 태블릿 학습자 단말과 감독관 단말로 온라인 또는 유비쿼터스 기반 학습(UBL)과 유비쿼터스 기반 시험(UBT)의 응용 서비스를 제공하도록 제어하는 제어부; 상기 제어부에 연결되며, 온라인 학습과 시험 또는 유비쿼터스 기반 온라인 학습(UBL)과 시험(UBT)의 출석을 관리하는 출석관리부; 상기 제어부에 연결되며, 온라인 학습 또는 유비쿼터스 기반 온라인 학습(UBL) 콘텐츠를 제공하는 학습 콘텐츠제공부; 상기 제어부에 연결되며, 학습자별로 학급자의 음성인식 데이터를 수신받아 학습자의 소리 패턴을 분석하는 음성인식 분석부; 상기 제어부에 연결되며, 실시간으로 수신되는 학습자의 안면 인식 데이터 및/또는 학습자의 말소리 데이터를수신받아 학습자별 학습 관련 빅 데이터를 수신받아 학습 패턴 통계 데이터를 시각화하여 학습 패턴 차트, 막대그래프, 산점도를 표시하는 빅 데이터 분석/통계 제공부; 및 학습자DB, 학습 콘텐츠DB, 및 얼굴 사진 DB를 포함하는 소리인식 감독관 기술을 활용한 유러닝 학습 플랫폼에서의 학습 주의 집중 시스템."}
{"patent_id": "10-2022-0159847", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "공개특허 10-2024-0077679-3-제1항에 있어서, 온라인 학습 또는 UBT 학습/또는 시험 시에, 상기 감독관 단말은 상기 LRS 서버를 통해 다수의 학습자 단말의학습자의 출석을 확인하고, 주변 화이트 노이즈를 필터링한 학습자의 말소리의 음성 인식 데이터를 모니터링하다가, 학습자의 말소리가 들리면, 해당 사용자 단말로 UBL 주의집중 학습되도록 경고 메시지 또는 알람을 전송하는, 소리인식 감독관 기술을 활용한 유러닝 학습 플랫폼에서의 학습 주의 집중 시스템."}
{"patent_id": "10-2022-0159847", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서, 상기 LRS 서버에 연동된 상기 학습자 단말에서, 학습 시간 동안, 녹음/녹화 데이터(소리 파일과 이미지 파일이통합된 영상 파일)을 상기 LRS 서버로 전송하여 저장되는 상기 학습자 단말에 구비된 녹음 및 녹화 프로그램을구비하는, 소리인식 감독관 기술을 활용한 유러닝 학습 플랫폼에서의 학습 주의 집중 시스템."}
{"patent_id": "10-2022-0159847", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "(a) 온라인 학습 또는 유비쿼터스 기반 학습(UBL) 시에, 안면인식 모듈과 음성 인식 모듈을 구비한 학습자 단말로부터 LRS 서버에 로그인 후 학습자의 출석을 등록하여 상기 LRS 서버로부터 학습자 단말로 학습 콘텐츠를 제공받는 단계; 및 (b) 상기 LRS 서버가 학습자의 출석을 기록하고 학습 콘텐츠를 제공하며, 사용자 단말의 정면 카메라를 주시하며 학습자가 바른 자세로 주의 집중학습되도록 학습자 단말의 음성 모듈에 의해 학습자의 말소리를 인식하여 말소리가 들리면 해당 학습자 단말로 알람 또는 경고 메시지가 출력되도록 하는 단계; 를 포함하는 소리인식 감독관 기술을 활용한 유러닝 학습 플랫폼에서의 학습 주의 집중 서비스 방법."}
{"patent_id": "10-2022-0159847", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서, 상기 학습자 단말들과 감독관 단말은 PC, 노트북, 스마트폰 또는 태블릿 PC를 사용하는 소리인식 감독관 기술을활용한 유러닝 학습 플랫폼에서의 학습 주의 집중 서비스 방법."}
{"patent_id": "10-2022-0159847", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제7항에 있어서, 상기 학습자 단말은 음성 인식 모듈이 구비되고, 상기 음성 인식 모듈은 주변 잡음을 필터링하고 학습자의 말소리를 샘플링(8k, 16k, 또는 48k 샘플링)하여 음성을 인식하기 위해 SileroVAD 및 SpeechBrain 알고리즘을 사용하는, 소리인식 감독관 기술을 활용한 유러닝 학습 플랫폼에서의 학습 주의 집중 서비스 방법."}
{"patent_id": "10-2022-0159847", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제7항에 있어서, 온라인 학습 또는 UBT 학습/또는 시험 시에, 상기 LRS 서버에 접속된 감독관 단말은 다수의 학습자 단말의 학습자의 출석을 확인하고, 학습자별 학습 패턴을 모니터링하며, 주변 화이트 노이즈를 필터링한 학습자의 말소리의음성 인식 데이터를 모니터링하다가, 학습자의 말소리가 들리면, 해당 사용자 단말로 UBL 주의집중 학습되도록경고 메시지 또는 알람을 전송하는 단계를 더 포함하는 소리인식 감독관 기술을 활용한 유러닝 학습 플랫폼에서의 학습 주의 집중 서비스 방법."}
{"patent_id": "10-2022-0159847", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제7항에 있어서, 상기 LRS 서버는 실시간으로 학습자의 3D 학습 얼굴을 얼굴의 윤곽선과 사용자 단말의 카메라를 주시하는 얼굴모습이 표현되는 머리와 이마/눈/코/귀/입을 포함하여 3D 모델링하여 렌더링하는 3D 렌더러를 더 포함하며, 상기 3D 렌더러에 의해 실시간으로 학습자의 3D 학습 얼굴을 얼굴의 윤곽선과 사용자 단말의 카메라를 주시하는얼굴 모습이 표현되는 머리와 이마/눈/코/귀/입을 포함하여 3D 모델링하여 렌더링하는 단계를 더 포함하는 소리공개특허 10-2024-0077679-4-인식 감독관 기술을 활용한 유러닝 학습 플랫폼에서의 학습 주의 집중 서비스 방법."}
{"patent_id": "10-2022-0159847", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제7항에 있어서, 학습 시간 동안, 상기 학습자 단말에 구비된 녹음 및 녹화 프로그램의 녹음/녹화 데이터(소리 파일과 이미지 파일이 통합된 영상 파일)을 상기 LRS 서버로 전송하여 저장되는 단계를 더 포함하는 소리인식 감독관 기술을 활용한 유러닝 학습 플랫폼에서의 학습 주의 집중 서비스 방법."}
{"patent_id": "10-2022-0159847", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "소리인식 감독관 기술을 활용한 유러닝 학습 플랫폼에서의 학습 주의 집중 시스템 및 방법이 개시된다. 상기 시 스템은 온라인 학습 또는 유비쿼터스 기반 학습(UBL) 시에, 학습자의 출석을 기록하고 학습 콘텐츠를 제공하며, 사용자 단말의 학습자가 바른 자세로 주의 집중학습되도록 학습자 단말의 음성 인식 모듈에 의해 학습자의 말소 (뒷면에 계속)"}
{"patent_id": "10-2022-0159847", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 AI 기반의 블렌디드 러닝(blended learning) 시스템에 관한 것으로, 보다 상세하게는 비대면 온라인 학습과 유비쿼터스 기반 학습(UBL, Ubiquitous based learning)에서 LRS 서버와 연동하여 사용자 단말은 미디어 재생부와 안면인식 모듈과 음성 모듈을 구비하고, 학습 콘텐츠를 제공하고 학습 패턴을 모니터링하는 LRS 서버 에 연동된 사용자 단말의 정면 카메라에 포커싱된 학습 콘텐츠에 시선을 바로보고 주의집중 학습되도록 안면 인 식 이외에 사용자 단말의 음석 인식 모듈에 의해 학습자의 말소리가 들리는 경우 주의 집중 학습하도록 해당 사 용자 단말로 알람/경고 메시지를 발생하는, 소리인식 감독관 기술을 활용한 유러닝 학습 플랫폼에서의 학습 주 의 집중 시스템 및 방법에 관한 것이다."}
{"patent_id": "10-2022-0159847", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "음성인식(Speech Recognition)은 man-machine 인터페이스 기술로써, 마이크로 입력된 음향 신호(Acoustic speech signal)에 대하여 잡음을 제거하고 음성 신호의 특징을 추출하여 단어의 집합 또는 문장의 텍스트로 변 환하는(mapping) 과정이며, 마이크-> AMP -> LPF -> ADC -> 음성 데이터베이스에 저장된다. 음성 인식은 크게 전처리부와 인식부로 구성되며, 전처리부는 사용자가 발성한 음성 신호로부터 잡음을 제거하고 인식 과정을 위 한 특징을 추출하며, 인식부는 입력된 음성을 음성 데이터베이스와의 비교를 통해 가장 가능성 있는 단어를 인 식결과로 출력하거나 비교 단어를 제한하여 문장을 인식한다. 음성 인식 기술은 미리 저장된 음성 패턴과 사용자의 음성 패턴을 비교하여, 매칭되는 패턴의 음성을 인식한다. 음성인식 시스템은 벡터 양자화(Vector Quantization)를 이용하는 방법, 동적 시간 정합(Dynamic Time Warping, DTW)을 이용하는 방법, 신경회로망(Neural Network)을 이용하는 방법, HMM(Hidden Markov Model, 은 닉 마코프 모델)을 이용하는 방법이 사용되고 있다. MSVQ(Multi-Section Vector Quantization)는 음성의 대 음성의 대표 패턴을 생성할 때 음성의 시간적인 관계를 고려하여 벡터양자화(Vector Quantization)를 적용한 방법이다. 음성 신호는 동일한 발음에 대해서도 시간 길이 가 다르므로 음성을 일정한 몇 개의 구간으로 분할하고 분할된 음성 구간에서 특징 벡터를 구함으로써 음성 구 간의 수를 일정하게 정규화하며, 이를 위하여 발성 시간이 짧은 음성은 구간 길이를 짧게 하고, 발성 시간이 긴 음성은 각 구간의 길이를 길게 하여 시간 길이가 다른 음성이라도 동일한 구간 수를 갖도록 한다. MVSQ는 음성 을 몇 개의 구간(section)으로 나누고 구간 별로 독립된 VQ를 수행하여 각 구간 별로 대표 벡터를 생성하고 음 성의 구간 수를 정규화 한다. 길이가 다른 음성을 MSVQ을 이용하여 음성 구간 수를 정규화 하며, 각 구간에서의 대표 벡터 생성은 LBG(Linde-Buzo-Gray) 알고리즘을 사용한다. 은닉마르코프모델(HMM)을 사용한 음성인식 알고리즘은 통계적 언어모델이 사용될 경우 음성처리 및 언어처리를 계층적인 단일구조로 처리할 수 있다. 음성 인식 기술은 미리 저장된 음성 패턴과 사용자의 음성 패턴을 비교하여, 매칭되는 패턴의 음성을 인식한다. 이와 관련된 선행기술1로써, 특허등록번호 10-1770817에서는 \"온라인 학습자를 위한 주의집중 판단 시스템 및 그 방법\"이 등록되어 있다. 도 1d를 참조하면, 상기 온라인 학습자를 위한 주의집중 판단 시스템은 콘텐츠를 입력받아 등록하는 입력부; 상기 등록된 콘텐츠에서 콘텐츠 정보를 생성하여 카테고리별로 저장하는 데이터베이스; 상기 등록된 콘텐츠 중 사용자가 선택한 콘텐츠를 디스플레이하는 디스플레이부; 상기 사용자가 선택한 콘텐츠에서 단어를 추출하고 상기 추출된 단어와 상기 카테고리별로 저장된 콘텐츠 정보 를 이용하여 콘텐츠 단어 및 노이즈 단어를 생성하는 단어 생성부; 및 상기 콘텐츠 단어 및 상기 노이즈 단어로 구성된 질의응답을 이용하여 상기 사용자의 주의집중 여부를 판단하는 주의집중 판단부;를 포함하며, 상기 단어 생성부는 기 콘텐츠가 등록되면 자동적으로 상기 콘텐츠로부터 자막 및 명사를 추출하여 단어를 생성 하고, 상기 저장된 콘텐츠 정보와 상기 생성된 단어에 대해서 각각 가중치를 계산하며, 상기 계산된 가중치에 따라 상기 콘텐츠 단어를 생성함으로써, 상기 가중치에 따라 상기 콘텐츠 단어를 포함하는 상기 질의응답을 사 용자에게 제공하고, 상기 단어 생성부는 상기 콘텐츠 단어 및 노이즈 단어를 학습자가 이전에 시청했던 콘텐츠를 기반으로 생성함으 로써, 동일한 콘텐츠에 대해서도 학습자마다 서로 다른 콘텐츠 단어 및 노이즈 단어를 생성한다. 이와 관련된 선행기술2로써, 특허 등록번호 10-1690546에서는 단말기의 음성인식을 통한 어학학습 방법 및 시스 템이 등록되어 있다. 도 1a는 종래의 단말기의 음성인식을 통한 어학학습 시스템 구성도이다. 도 1a를 참조하면, 단말기는 어학 어플리케이션 실행에 따른 화면을 제공하는 표시부; 개인의 발음 차이를 고려 하여 설정되는 다수의 패턴데이터를 저장하는 단말저장부; 및 상기 어학 어플리케이션을 실행하여 적어도 하나 의 어학문제를 제시하고, 상기 어학문제에 대응하는 음성데이터를 사용자로부터 수집하고, 상기 수집된 음성데 이터와 상기 다수의 패턴데이터를 비교하고, 매칭도가 기 설정값 보다 높은 패턴데이터를 선택하여 음성 인식을 위한 범위를 설정하고, 상기 선택된 패턴 데이터와 상기 수집된 음성데이터를 비교하여 음성 인식을 수행한 후 어학문제에 대한 평가 결과를 생성하는 단말제어부 포함한다. 이와 관련된 선행기술3으로써, 특허등록번호 10-2041618 (등록일자 2019년 10월 31일), \"인공지능 음성인식을 위한 기계학습 기반 자연어 말뭉치 구축 서비스 제공 시스템 및 방법\"이 등록되어 있다. 그러나, 기존의 이러닝 또는 유러닝 시스템은 단지 온라인 학습 콘텐츠를 제공하였으며, 음성 인식 기술을 사용 하여 학습자의 부주의하게 말소리가 들리면 주변 잡을을 필터링하고 AI 음성 인식에 의해 해당 사용자 단말로 알람 또는 경고 메시지를 발생하고 주의집중 학습이 되도록 하는 블렌디드 러닝 시스템을 제공하지 않았다. 선행기술문헌 특허문헌 (특허문헌 0001) 특허등록번호 10-1770817 (등록일자 2017년 08월 17일), \"온라인 학습자를 위한 주의집중 판단 시스템 및 그 방법\", 고려대학교 산학협력단 (특허문헌 0002) 특허등록번호 10-1690546 (등록일자 2016년 12월 22일), \"단말기의 음성인식을 통한 어학학습 방법 및 시스템\", 에스케이텔레콤 주식회사 (특허문헌 0003) 특허등록번호 10-2041618 (등록일자 2019년 10월 31일), \"인공지능 음성인식을 위한 기계학습 기반 자연어 말뭉치 구축 서비스 제공 시스템 및 방법\", (주)미디어코퍼스"}
{"patent_id": "10-2022-0159847", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "상기 문제점을 해결하기 위한 본 발명의 목적은 비대면 온라인 학습과 유비쿼터스 기반 학습(UBL)에서 LRS 서버 와 연동하여 사용자 단말은 미디어 재생부와 안면인식 모듈과 음성 모듈을 구비하고, 학습 콘텐츠를 제공하고 학습 패턴을 모니터링하는 LRS 서버에 연동된 사용자 단말의 정면 카메라에 포커싱된 학습 콘텐츠에 시선을 바 로보고 주의집중 학습되도록 안면 인식 이외에 사용자 단말의 음석 인식 모듈에 의해 학습자의 말소리가 들리는 경우 주의 집중 학습하도록 해당 사용자 단말로 알람/경고 메시지를 발생하는, 소리인식 감독관 기술을 활용한유러닝 학습 플랫폼에서의 학습 주의 집중 시스템을 제공한다. 본 발명의 다른 목적은 소리인식 감독관 기술을 활용한 유러닝 학습 플랫폼에서의 학습 주의 집중 서비스 방법 을 제공한다."}
{"patent_id": "10-2022-0159847", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 목적을 달성하기 위해, 소리인식 감독관 기술을 활용한 유러닝 학습 플랫폼에서의 학습 주의 집중 시 스템은, 온라인 학습 또는 유비쿼터스 기반 학습(UBL) 시에, 학습자의 출석을 기록하고 학습 콘텐츠를 제공하며, 사용자 단말의 학습자가 바른 자세로 주의 집중학습되도록 학습자 단말의 음성 인식 모듈에 의해 학 습자의 말소리를 인식하여 경고 메시지를 발생하는 LRS 서버; 상기 LRS 서버와 유무선 통신망을 통해 연결되고, 상기 학습 콘텐츠를 제공받고 학습자의 말소리를 인식하며, 상기 LRS 서버로부터 학습 패턴과 통계 데이터를 제 공받으며, 음성 인식 모듈을 구비한 학습자 단말들; 및 상기 LRS 서버와 유무선 통신망을 통해 연결되는 감독관 단말을 포함한다. 본 발명의 다른 목적을 달성하기 위해, 소리인식 감독관 기술을 활용한 유러닝 학습 플랫폼에서의 학습 주의 집 중 서비스 방법은 (a) 음성 인식 모듈을 구비한 학습자 단말로부터 LRS 서버에 로그인 후 학습자의 출석을 등록 하여 상기 LRS 서버로부터 학습자 단말로 학습 콘텐츠를 제공받는 단계; 및 (b) 상기 LRS 서버가 학습자의 출석 을 기록하고 학습 콘텐츠를 제공하며, 사용자 단말의 정면 카메라를 주시하며 학습자가 바른 자세로 주의 집중 학습되도록 학습자 단말의 음성 모듈에 의해 학습자의 말소리를 인식하여 말소리가 들리면 해당 학습자 단말로 알람 또는 경고 메시지가 출력되도록 하는 단계를 포함한다."}
{"patent_id": "10-2022-0159847", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명의 소리인식 감독관 기술을 활용한 유러닝 학습 플랫폼에서의 학습 주의 집중 시스템 및 방법은 비대면 온라인 학습과 유비쿼터스 기반 학습(UBL)에서 LRS 서버와 연동하여 사용자 단말은 미디어 재생부와 안면인식 모듈과 음성 모듈을 구비하고, 학습 콘텐츠를 제공하고 학습 패턴을 모니터링하는 LRS 서버에 연동된 사용자 단 말의 정면 카메라에 포커싱된 학습 콘텐츠에 시선을 바로보고 주의집중 학습되도록 안면 인식 이외에 사용자 단 말의 음석 인식 모듈에 의해 학습자의 말소리가 들리는 경우 해당 사용자 단말로 알람/경고 메시지를 발생하여 주의 집중 학습하도록 하는 효과가 있다."}
{"patent_id": "10-2022-0159847", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 본 발명의 바람직한 실시예를 첨부된 도면을 참조하여 발명의 구성 및 동작을 상세하게 설명한다."}
{"patent_id": "10-2022-0159847", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "본 발명은 개시되는 실시예들에 한정되는 것이 아니라 해당 기술분야에서 통상의 지식을 가진 자가 서로 다른 다양한 형태로 구현될 수 있다. 본 발명의 설명에 있어서 관련된 공지의 기술 또는 공지의 구성에 대한 구체적 인 설명이 본 발명의 요지를 불필요하게 흐릴 수 있다고 판단되는 경우 그 자세한 설명을 생략한다. 또한, 첨부 된 도면 번호는 동일한 구성을 표기할 때에 다른 도면에서 동일한 도면번호를 부여한다. 본 연구개발을 통한 특정한 실시 형태에 대해 한정하지 않으며, 본 발명의 사상 및 기술 범위에 포함되는 모든 변환, 균등물 내지 대체물을 포함하는 것으로 이해되어야 한다. 본 발명의 소리인식 감독관 기술을 활용한 유러닝 학습 플랫폼에서의 학습 주의 집중 시스템 및 방법은 비대면 온라인 학습과 유비쿼터스 기반 학습(UBL, Ubiquitous based learning)에서 LRS 서버와 연동하여 사용자 단말 (태블릿 PC, 스마트폰, PC)은 3D 렌더러와 미디어 재생부와 안면 인식 모듈과 음성 인식 모듈을 구비하며, 사용 자 단말은 LRS 서버로부터 학습 콘텐츠를 제공받고, 학습 콘텐츠를 제공하고 3D 학습 얼굴과 학습 패턴을 모니 터링하여 학습 패턴 통계 데이터를 제공하는 LRS 서버에 연동된 사용자 단말의 정면 카메라에 포커싱된 학습 콘 텐츠에 시선을 바로보고 주의집중 학습되도록 얼굴의 윤곽선과 눈2/코/귀2의 얼굴의 특징점들을 안면 인식을 하 며, 학습자의 학습 패턴을 모니터링하고 일정 각도로 시선이 빗나갈 경우 또는 눈과 귀의 거리, 코와 귀의 거리, 눈과 눈 사이 거리, 귀와 귀의 거리, 목과 어깨의 거리, 어깨와 어깨의 거리의 해당 방향의 거리가 일정 기준치를 넘는 경우, 또는 학습자의 말소리가 들리는 경우 소리와 메시징 기술을 사용하여 해당 사용자 단말로 알람/경고 메시지를 발생하여 학습자가 주의 집중 학습되도록 한다. 도 2a, 2b는 비대면 온라인 학습에서 웹 브라우저 기반 ubcloud 인공지능을 사용한 주의 집중 학습 시스템의 구 현 예이다. UBL(Ubiquitous-Based Learning) 기술을 적용하여 학습 서버에 유무선 통신망을 통해 접속된 스마트 기기(태블 릿 PC)를 활용한 시험 방식인 UBT(Ubiquitous-Based Test) 기술을 활용한 문제중심학습(PBL; Problem Based Learning) 및 실습, 이러닝/유러닝 온라인 학습 시에 학습자의 행동 데이터를 인식하여 주의집중 학습을 제공하 는 블렌디드 러닝 시스템을 제공한다. 본 발명의 소리인식 감독관 기술을 활용한 유러닝 학습 플랫폼에서의 학습 주의 집중 시스템 및 방법은 비대면 온라인 이러닝/유러닝 학습 시에, 사용자 단말(태블릿 PC, 스마트폰, PC)은 학습 콘텐츠를 제공하고 합습자의 학습 패턴을 기록하는 LRS 서버와 연동되는 교육 콘텐츠 viewer가 설치되고, AI 안면인식/동작인식/음성 인식, 소리와 메시징 기술을 사용하여 사용자 단말의 정면 카메라를 사용한 AI 기반 안면 인식(posenet 알고리즘, real-time face pose estimation) 기술을 사용하는 얼굴의 윤곽선과 눈2/코/귀2의 얼굴의 특징점들을 인식하는 안면인식 모듈이 탑재되며, 얼굴 인식 시에 응시자 단말의 정면 카메라(C)를 사용하여 촬영된 얼굴 사진을 학습 콘텐츠 서버의 얼굴 사진 DB의 학습자 얼굴 사진의 특징점들과 비교하여 학습자의 출석 여부를 검출하고, 비대 면 온라인 학습에서, 사용자 단말의 정면 카메라 영상 데이터를 사용하여 실시간으로 AI 기반 안면을 인식하여 학습자의 영상의 얼굴의 행동 패턴을 검출하여 학습 콘텐츠 서버(ubcloud 서버)에 연동된 사용자 단말의 정면 카메라에 포커싱 된 비대면 강의 학습 콘텐츠에 시선을 바로보고 주의 집중 학습되도록 얼굴의 윤곽선과 눈2/코 /귀2 얼굴의 특징점 5점 척도 안면 인식을 통해 일정 각도로 시선이 빗나갈 경우 또는 눈과 귀의 거리, 코와 귀의 거리의 해당 방향의 거리가 일정 기준치를 넘는 경우, 또는 학습자의 말소리가 들리는 경우 해당 사용자 단 말로 알람/경고 메시지를 발생하며, 소리와 메시징 기술을 사용하여 학습자가 주의 집중학습 되도록 한다. 도 3은 UBL 학습 시에, 태블릿 PC, 스마트폰, PC 기반 학습 콘텐츠를 제공하고 Bledded Learning을 위한 학습자 의 학습 패턴을 기록하는 LRS 서버를 구비하는 안면인식 감독관 기술을 활용한 유러닝 학습 플랫폼에서의 학습 주의 집중 시스템 구성도이다. 안면인식 감독관 기술을 활용한 유러닝 학습 플랫폼에서의 학습 주의 집중 시스템은 UBL 클라우드 서버로써 온 라인 학습과 UBL 학습 콘텐츠를 제공하는 LRS 서버, 학습자 단말 및 감독관 단말(300,310,311)을 포함한다. 사용자 단말(310,311)은 학습 콘텐츠를 제공하고 학습자의 안면인식/음성 인식을 통해 학습 패턴을 기록하고 통 계 데이터를 시각화하여 출력하는 LRS 서버로부터 유무선 통신망을 통해 온라인 학습 콘텐츠를 제공받는 스마트폰, 태블릿 PC 뿐만 아니라, 유무선 통신망(이더넷, Wi-Fi, LTE 4G/5G)을 통해 인터넷 접속이 가능한 노 트북을 포함한다. 사용자 단말은 안면 인식 모듈과, 음성 인식 모듈과 3D 학습 얼굴과 학습 패턴 통계 데이터를 데이터 시각화하 여 표시하는 3D 뷰어가 구비된다. 사용자 단말(310,311)은 유러닝 학습 플랫폼에서 UBL 주의집중 합습이 되도록 학습 콘텐츠를 제공하고 학습 패 턴을 기록하는 LRS 서버와 연동되는 교육 콘텐츠 viewer가 설치되며, AI 안면인식/동작인식/음성인식과 메시징 기술을 사용하여 학습자 얼굴의 윤곽선과 눈2/코/귀2의 얼굴의 특징점 5점 척도 특징점들을 인식하고 학급자의 얼굴의 행동 패턴 데이터를 인식하는 안면인식 모듈과, 주변 잡음을 필터링하고 학습자의 말소리를 샘플링(8k, 16k, 또는 48k 샘플링)하여 음성을 인식하는 음성 인식 모듈을 구비한다. 학습자 단말로써, 사용자 단말(310,311)의 안면 인식 모듈은 얼굴의 윤곽선과 눈2/코/귀2 얼굴이 특징점들을 인 식하기 위해 posenet 알고리즘을 사용한다. 사용자 단말(310,311)의 음성 인식 모듈은 주변 잡음을 필터링하고 학습자의 말소리를 샘플링(8k, 16k, 또는 48k 샘플링)하여 음성을 인식하기 위해 SileroVAD 및 SpeechBrain 알고리즘을 사용하였다. 감독관 단말과 사용자 단말은 LRS 서버에 접속되며 각각 \"교사 모드\" 및 \"학습자 모드\"로 동작된다. 본 발명의 소리인식 감독관 기술을 활용한 유러닝 학습 플랫폼에서의 학습 주의 집중 시스템은 온라인 학습 또는 유비쿼터스 기반 학습(UBL) 시에, 학습자의 출석을 기록하고 학습 콘텐츠를 제공하며, 마이크 와 스피커와 카메라를 구비한 사용자 단말의 정면 카메라를 주시하며 학습자가 바른 자세로 주의 집중학습되도 록 학습자 단말의 음성 인식 모듈에 의해 학습자의 말소리를 인식하여 경고 메시지를 발생하며, 학습자의 안면 인식 학습 패턴을 기록하고, 학습자의 학습 자세를 3D 렌더링하여 표시하며, 학습 패턴에 등급/점수를 기록하고 이에 따른 통과/탈락 예측과 개인별 학습 분석 차트의 통계 데이터를 시각화(막대 그래프, scatter diagram)하 여 출력하는 LRS 서버; 상기 LRS 서버와 유무선 통신망을 통해 연결되고, 카메라와 안면인식 모듈과 음성 인식 모듈 및 서버 연동 녹음 프로그램(UBL 학습 시간 동안 녹음)을 구비하며, 얼굴의 윤곽선과 눈2/코/귀2 얼굴의 특징점들을 인식하고 말소리를 인식하며, 3D 학습 얼굴과 학습자의 학습 패턴과 통계 데이터를 제공받으며, 안면인식 모듈과 음성 인 식 모듈을 구비한 학습자 단말들; 및 상기 LRS 서버와 유무선 통신망(이더넷, Wi-Fi, LTE 4G/5G)을 통해 연결되고, 학습자의 자세가 비딱하면 해당 사용자 단말로 UBL 주의집중 학습되도록 알람 또는 경고 메시지를 전송하는 감독관 단말을 포함하며, 상기 학습자 단말은 음성 인식 모듈이 구비되고, 상기 음성 인식 모듈은 주변 잡음을 필터링하고 학습자의 말소 리를 샘플링(8k, 16k, 또는 48k 샘플링)하여 음성을 인식하기 위해 SileroVAD 및 SpeechBrain 알고리즘을 사용 한다. 학습 시간 동안, 사용자 단말은 학습자의 영상과 말소리가 레코딩되는 녹음 및 녹화 프로그램, 학습자의 학습 얼굴이 3D 모델링되고 렌더링되는 학습 패턴 3D viewer가 설치되며, 사용자 단말로부터 학습자의 학습 영상과 소리 데이터를 LRS 서버로 전송한다. 블렌디드 러닝 시스템의 온라인 학습 또는 UBT 학습 시에, 얼굴의 윤곽선과 눈2/코/귀2를 감지하는 안면인식 모 듈은 응시자 단말의 카메라로 실시간으로 촬영된 정면 얼굴 영상의 ROI를 검출하여 코의 정점을 기준으로 center alignment를 통해 표준 크기로 크기 보정/회전/각도 보정된 표준 크기의 정면 얼굴 사진에 대하여 AI 안 면 인식 알고리즘을 사용하여 얼굴 객체를 추출하고, 얼굴 행동 패턴을 인식하며, 학습자의 얼굴의 윤곽선과 눈 2/코/귀2의 얼굴 특징점들을 추출하며, 얼굴 특징 추출과 분류를 통해 눈2/코/귀2의 얼굴의 특징점들의 각각 좌 측/우측 귀와 좌측/우측 눈의 중심점(동공)과의 유클리디안 거리(d)와 유사도(similarity)를 계산하고, 온라인 학습 또는 UBT 학습을 제공하는 LRS 서버의 얼굴사진 DB의 사진과 데이터와 비교하여 출석을 확인하며, 온라인 학습/시험 또는 UBL 학습/UBL 시험시에 눈/코 3점이 양 끝 귀 2점에 가까워지는 지에 따라 오른쪽/왼쪽으로 머 리 이동을 감지하고 부정행위와 관련된 얼굴의 이상행동 패턴을 검출하고, 얼굴 인식 시에 안면윤곽선 인식이 안되는 경우, 화면으로부터 일정 각도 이상으로 벗어난 경우(눈/코 3점이 양 끝 귀 2점에 가까워지는 지에 따라 눈과 귀의 거리, 코와 귀의 거리, 눈과 눈 사이 거리, 귀와 귀의 거리, 목과 어깨의 거리, 어깨와 어깨의 거리 의 해당 방향의 거리가 일정 기준치를 넘는 경우) 학습자 단말의 카메라로 촬영되는 얼굴 행동 패턴을 인식하여 전면 얼굴이 좌우로 돌아간 각도에 따라 우측 눈과 우측 귀의 거리와 좌측 눈과 좌측 귀의 거리가 달라지므로, 또는 학습자의 말소리가 들리는 경우 주의집중 학습되도록 관련 이미지 또는 영상 데이터를 LRS 서버로 전 송하고, LRS 서버에 연동된 감독관 단말이 확인 후, 감독관 단말로부터 LRS 서버를 통해 해당 학습자 단말로 주의집중학습되도록 경고 메시지를 전송하거나 또는 알람을 발생한다. 사용자 단말(310,311)에서 정면 자세로 학습자가 온라인 학습 또는 UBL 학습이 되도록, 학습자의 안면인식 시에 비딱한 자세가 검출되거나 또는 음성 인식시에 학습자의 말소리 들리는 경우 해당 사용자 단말로 알람 또는 경 고 메시지를 출력하여 주의집중 학습되도록 한다. 온라인 학습 또는 UBT 학습/또는 시험 시에, 감독관 단말은 LRS 서버를 통해 다수의 학습자 단말의 학습자 의 출석을 확인하고, 안면인식과 음성인식 기술을 활용한 AI 감독관으로써, 학습자별 학습 패턴 또는 시험 패턴 을 모니터링하며, 학습자의 두 눈의 아이트랙킹, 눈/코/귀의 안면 인식 데이터 및 주변 화이트 노이즈를 필터링 한 학습자의 말소리의 음성 인식 데이터를 모니터링하다가, 학습자의 학습 자세가 비딱하면(학습자의 비딱한 자 세, 고개 돌림, 말소리) 학습 자세가 삐탁하거나 고개를 상하 방향/좌우 방향으로 돌리거나, 말소리가 들리면, 해당 사용자 단말로 UBL 주의집중 학습되도록 경고 메시지 또는 알람을 전송한다. 이때, 학습자 단말은 주의집중 학습되도록 경고 메시지 또는 알람이 출력된다. LRS 서버는 WWW 서버, 제어부, 회원 등록부, 사용자 인증부, 출석 관리부, 학 습 콘텐츠 제공부, 안면인식 분석부, 음성인식 분석부, 빅 데이터 분석/통계제공부, 3D 렌 더러, 학습자DB, 학습 콘텐츠DB, 및 얼굴사진 DB를 포함한다. 상기 LRS 서버는 학습자 단말과 감독관 단말과 유무선 통신을 통해 연결되는 WWW 서버; 유무선 통신망을 통해 태블릿 PC, 스마트폰, PC의 학습자 단말과 감독관 단말로 온라인 또는 유비쿼터스 기반 학습(UBL)과 유비쿼터스 기반 시험(UBT)의 응용 서비스를 제공하도록 제어하는 제어부; 상기 제어부에 연결되며, 학습자의 회원 정보를 등록받아 ID/Passwd를 저장하여 관리하는 회원 등록부 ; 상기 제어부에 연결되며, QR 코드/Passwd 또는 ID/Passwd 또는 온라인 인증서를 사용하여 사용자를 인증하 는 사용자 인증부; 상기 제어부에 연결되며, 태블릿 PC, 스마트폰, PC 기반 온라인 학습(Learning)과 시험(Test) 또는 유비쿼 터스 기반 온라인 학습(UBL)과 시험(UBT)의 출석을 관리하는 출석관리부; 상기 제어부에 연결되며, 온라인 학습 또는 유비쿼터스 기반 온라인 학습(UBL, Ubiquitous based Learning) 콘텐츠를 제공하는 학습 콘텐츠 제공부; 상기 제어부에 연결되며, 학습자별로 학급자의 안면인식 데이터를 수신받아 얼굴의 윤곽선과 눈2/코/귀2 얼굴의 특징점들을 추출하여 UBL 주의집중 학습되도록 학습자의 얼굴의 학습 패턴을 분석하는 안면인식 분석부 ; 상기 제어부에 연결되며, 학습자별로 학급자의 음성인식 데이터를 수신받아 학습자의 소리 패턴을 분석하 는 음성인식 분석부; 상기 제어부에 연결되며, 실시간으로 수신되는 학습자의 안면 인식 데이터 및또는 학습자의 말소리 데이터 를 수신받아 학습자별 학습 관련 빅 데이터를 수신받아 학습 패턴 통계 데이터를 시각화하여 학습 패턴 차트, 막대그래프, 산점도를 표시하는 빅 데이터 분석/통계 제공부; 및 학습자DB, 학습 콘텐츠DB, 및 얼굴사진 DB를 포함한다. 상기 LRS 서버는 학습자 단말들과 감독관 단말과 연결되고 실시간으로 학습자의 얼굴 영상과 음성 데이터 를 저장하고 스트리밍 서비스를 제공하는 NVR 서버를 더 포함한다. 상기 LRS 서버는 3D 학습 콘텐츠를 제공하며, 실시간으로 학습자의 3D 학습 얼굴을 얼굴의 윤곽선과 머리 와 이마/눈/코/귀/입을 3D 모델링하여 렌더링하는 3D 렌더러를 더 포함한다. 상기 LRS 서버에 연동된 상기 학습자 단말은 학습 시간 동안, 녹음/녹화 데이터(소리 파일과 이미지 파일 이 통합된 영상 파일)을 상기 LRS 서버로 전송하여 저장되는 상기 학습자 단말에 구비된 녹음 및 녹화 프로그램 을 구비한다. 상기 제어부에 연결되며, 학습자 단말에서 안면인식 모듈과 얼굴의 특징점들을 인식하는 안면 인식 모듈에 의해 정면 카메라의 영상에 대하여 안면인식 기술(posenet 알고리즘)을 사용하여 눈/코 3점이 양 끝 귀 2점에 가까워지는 지에 따라 오른쪽/왼쪽으로 머리 이동을 감지하고 온라인 학습과 UBL 학습시 얼굴의 학습 패턴을 검 출하며, 안면윤곽선 인식이 안되는 경우, 학습 화면 또는 시험 화면으로부터 얼굴이 일정 각도 이상으로 벗어난 경우(눈/코 3점이 양 끝 귀 2점에 가까워지는 지에 따라 눈과 귀의 거리, 코와 귀의 거리, 눈과 눈 사이 거리, 귀와 귀의 거리, 목과 어깨의 거리, 어깨와 어깨의 거리의 해당 방향의 거리가 일정 기준치를 넘는 경우) 감독 관 단말에 표시되고, 감독관 단말로부터 LRS 서버를 통해 해당 학습자 단말로 부정행위 관련 경고 메시지 또는 알람을 해당 학습자 단말로 전송한다. 모집단(population)의 n개의 표본(sample)을 추출하고, 모집단의 평균/표준편차/분산을 계산하여 학습 패턴 빅 데이터 분석을 통해 통계 분석(학습 패턴 평균, 개인별 표준편차)을 실시하여 막대 그래프, 시간 경과에 따른 학습 패턴(학습 자세, 고개의 좌우 방향, 상하 방향)이 표시된 산점도(scatter diagram)로 데이터 시각화하여 표시된다. n명의 학습자들의 학습 패턴[n개의 표본(sample)]의 모평균 E(x) E(x)= m = (X1+X2+X3+...+Xn)/n 모평균(mean) m, 표준편차(standard deviation)가 σ 일때, 모집단(population)에서 샘플링된 크기가 n개의 표 본(sample)을 추출하여 생성된 표본 평균 m과 표본 분산 을 갖는 모평균과 모분산을 갖는 정규 분포 N(m, )를 이루며, 이에 따라 표본 평균 m을 갖는 표준 정규 분포를 이룬다. 표준 정규 분포는 학습 패턴 n개의 표본 평균 m 및 표준편차를 계산하며, 표본 오차는 ±2P (신뢰도 95% 신뢰구 간)을 갖는다. 도 4 내지 도 6은 UBL 클라우드 서버(LRS 서버, Learning Record Server)에 접속된 사용자 단말의 주의집중 UBL 학습 테스트 화면이다. 도 7은 학습자의 센터 얼라이먼트(centre alignment)를 기준으로 학습자의 자세 인식 얼굴의 윤곽선과 눈2/코/ 귀2 안면인식 초기화 화면이다. 1) 안면인식과 음성 인식를 실행하는 AI 감독관 프로그램이 사용자 단말의 카메라를 주시하는 학습자의 센터 얼 라인먼트(centre alignment)를 기준으로 성공적으로 학습자의 얼굴의 안면 인식을 했다면 눈2/코/귀2에 빨간 점 이 찍힌 캡춰가 출력된다[Close 버튼을 클릭한다]. 2) 학습자가 머리를 오른쪽으로 움직이면, 우측 상단에 경고 메시지가 팝업된다. [메시지, Please docus on screen]. 메시지를 확인한 뒤 고개를 왼쪽으로 돌려서 메시지를 한번 더 확인한다. 3) 사용자 단말의 카메라를 가리거나 얼굴을 숨긴 뒤 메시지 팝업을 확인한다. [메시지, Face not available] 온라인 학습 또는 UBL 학습/또는 UBT 시험 시에, 수업 진행중 집중하지 않았을때 화면 메시지 우측 상단에 화면 에 경고 메시지를 출력하고, 동시에 소리로 경고음을 출력한다. 실시예에서는, 서울대-NSD 공동보고서에서, 서울대학교 사범대학 AI 기반 교육연구센터에서 교육에서의 AI 활용 사례 및 온라인 학습 시스템에 대하여, UBL 클라우드 서버(LRS 서버) 상에서 태블릿 PC 기반의 유비쿼터스 기반 학습(UBL) 및 유비쿼터스 기반 시험(UBT)에 얼굴의 윤곽선과 눈2/코/귀2 안면 인식과 음성 인식이 사용된 AI 감 독관 기술을 실시하였으며, 영어를 외국어로 학습하는 상황에서 영어 독해 및 쓰기 과업에서 학습자의 인지적 처리 과정을 통해 특정 회사의 뇌파도 검출과 함께 고려하여 \"학습집중도\"를 평가한 결과 긍정적인 결과가 있었 다. 학습 콘텐츠를 제공하는 LMS와 AI 감독관 기술은 학습자의 행동 데이터를 기록하고 제공하기 때문에, AI 감독 관은 일반적인 LMS가 제공하던 서버 접속 시간, 접속 횟수, 학습 시간, 과제 등의 로그 데이터를 넘어, 수업 참 여에 대한 직접적인 데이터를 제공할 수 있다. AI 감독관을 사용한 학습자의 시선 추적(Eye-Tracking) 또는 안구 이동(Eye-Movement)에 관련된 로그 데이터를 저장하여 실험을 실시하였다. 도 8은 Posenet 알고리즘을 사용한 학습자의 학습 얼굴 눈2/코/귀2 얼굴 영상과, 3D 학습 얼굴 렌더링(3D view), 및 학습 패턴과 관련된 통계 데이터를 시각화하여 학습 분석 차트로 표시된 막대 그래프와 산점도(좌우 방향, 상하 방향)를 나타낸다. 안면인식 시에, 양쪽 귀/눈/코 5점 사이 거리 비율을 계산한 각도/비율 정보, 얼굴의 좌우 방향, 얼굴의 상하 방향을 테스트하였다. 도 9는 출석, 온라인 학습/UBL 학습 콘텐츠를 제공하고 AI 모듈을 구동하여 학습자의 얼굴 안면 인식에 의해 학 습 패턴(등급, 접수), 학습과 과제수행(assignment), 학습자별 학습 패턴을 제공하며 통과/탈락 예측을 제공하 는 UBL 클라우드 서버(LRS 서버)의 지식 트랙킹 모듈(activities), activities의 그룹핑, 학습 패턴 일반화, 학습 패턴 통계 데이터 시각화 및 통과/탈락 예측(prediction)을 제공하는 UBL 클라우드 서버(LRS 서버)의 구성 도이다. 도 10a 내지 도 10d는 출석, 학습 콘텐츠를 제공하고 AI 모듈을 구동하여 학습자의 얼굴 안면 인식에 의해 학습 패턴(등급, 접수), 학습과 과제수행(assignment), 학습자별 학습 패턴을 제공하며 통과/탈락 예측을 제공하는 UBL 클라우드 서버(LRS 서버)의 지식 트랙킹 액티비티들(activities)과 애트리뷰션, 학습 진단을 나타낸 도면이 다. 액티비티들(activities)은 Log in time, Log out time, Stay time in UBL, Number of dairy visit, Study time in viewer, Video watching time, Video call stay time, Video cal stay time, 출석(attentance)들이 특정 애트리뷰트(사이트 방문, 뷰어, 퀴즈, 토론, 과제 수행, 팀 프로젝트, MSG)에 그룹핑되어 연결되며, 각각 의 애트리뷰트는 진단 목록의 학습 역량, 학습 패턴, 콘텐츠 이용, 관심, 집중도, initiative, 관계 (Relationship)과 연결된다. 온라인 학습 또는 UBL 학습 시에, 학습자의 학습 패턴이 지속적으로 불량한 학습자가 감지된 경우, LRS 서버 에 연동된 감독관 단말은 해당 학습자는 주의력 결핍증(attention deficit disorder)을 가진 학습자로 판 단하여 해당 학습자를 주의집중 학습 모니터링 관리 대상자로 선정하여 카메라 안면 인식/음성 인식을 하여 주 의집중 바른 학습 태도가 되도록 항시 모니터링한다. 도 11은 UBL 학습 시에, UI/UX 화면의 음성 검출 화면이다. 도 12는 음성 인식 시에, 주변 잡음을 필터링하고 학습자의 말소리를 샘플링(8k, 16k, 또는 48k 샘플링)하여 음 성 인식된 SileroVAD 및 SpeechBrain 알고리즘 실행 결과이다. 사용자 단말의 음성 인식 모듈은 SileroVAD 및 SpeechBrain 알고리즘을 사용하였으며, 음성 인식 시에, 마이크 로 입력 된 음성 신호에 대하여 미리 저장된 생활상의 특정 소리(TV 소리, 전화 소리, 탁자 소리, 집 문여는 소 리)를 필터링하고 주변 잡음(가우시안 노이즈)을 필터링하며, 순수한 학습자의 말소리를 샘플링(8k, 16k, 또는 48k 샘플링)하여 학습자의 말소리를 음성 인식한다. 또한, 본 발명의 인공지능 기반의 블렌디드 러닝 서비스 방법은 (a) 온라인 학습 또는 유비쿼터스 기반 학습(UBL) 시에, 안면인식 모듈과 음성 인식 모듈을 구비한 학습자 단말 로부터 LRS 서버에 접속하여 ID/Passwd 로그인 후 학습자의 출석을 등록하여 상기 LRS 서버로부터 학습 콘텐츠를 제공받는 단계; 및 (b) 상기 LRS 서버가 학습자의 출석을 기록하고 학습 콘텐츠를 제공하며, 사용자 단말의 정면 카메라를 주시하 며 학습자가 바른 자세로 주의 집중학습되도록 학습자의 학습 패턴을 기록하고, 학습자의 얼굴 부분의 학습 자 세를 윤곽선과 눈/코/귀/입을 포함하여 3D 렌더링하여 표시하며, 학습자의 학습 패턴에 등급/점수를 기록하며 통과/탈락 예측과 학습 분석 차트의 통계 데이터를 시각화하여 출력하는 단계를 포함한다. 소리인식 감독관 기술을 활용한 유러닝 학습 플랫폼에서의 학습 주의 집중 서비스 방법은 (a) 음성 인식 모듈을 구비한 학습자 단말로부터 LRS 서버에 로그인 후 학습자의 출석을 등록하여 상기 LRS 서버로부터 학습자 단말로 학습 콘텐츠를 제공받는 단계; 및 (b) 상기 LRS 서버가 학습자의 출석을 기록하고 학습 콘텐츠를 제공하며, 사 용자 단말의 정면 카메라를 주시하며 학습자가 바른 자세로 주의 집중학습되도록 학습자 단말의 음성 모듈에 의 해 학습자의 말소리를 인식하여 말소리가 들리면 해당 학습자 단말로 알람 또는 경고 메시지가 출력되도록 하는 단계를 포함한다. 상기 방법에서, 상기 학습자 단말은 얼굴의 윤곽선과 눈2/코/귀2 안면인식 모듈과 음성인식 모듈이 구비되며, 상기 LRS 서버와 유무선 통신망을 통해 연결되고, 상기 학습 콘텐츠를 제공받고 카메라와 안면인식 모듈을 구비 하며 학습자의 얼굴의 윤곽선과 눈2/코/귀2 얼굴의 특징점들을 인식하며, 학습자의 학습 자세가 비딱하면(학습 자의 비딱한 자세, 고개 돌림, 말소리) 학습 자세가 삐탁하거나 고개를 상하 방향/좌우 방향으로 돌리거나, 음 성 인식에 의해 학습자의 말소리가 들리면, 해당 사용자 단말로 UBL 주의집중 학습되도록 자체적으로 경고 메시 지 또는 알람을 출력한다. 상기 방법은, 온라인 학습 또는 UBT 학습/또는 시험 시에, 상기 LRS 서버에 접속된 감독관 단말은 다수의 학습 자 단말의 학습자의 출석을 확인하고, 안면인식과 음성인식 기술을 활용한 AI 감독관으로써, 학습자별 학습 패 턴을 모니터링하며, 학습자의 두 눈의 아이트랙킹, 눈/코/귀의 안면 인식 데이터 및 주변 화이트 노이즈를 필터 링한 학습자의 말소리의 음성 인식 데이터를 모니터링하다가, 학습자의 학습 자세가 비딱하면(학습자의 비딱한 자세, 고개 돌림, 말소리) 학습 자세가 삐탁하거나 고개를 상하 방향/좌우 방향으로 돌리거나, 말소리가 들리면, 해당 사용자 단말로 UBL 주의집중 학습되도록 경고 메시지 또는 알람을 전송하는 단계를 더 포함한다. 상기 학습자 단말은 얼굴의 윤곽선과 눈2/코/귀2 안면인식 모듈과 음성인식 모듈이 구비되며, 상기 안면 인식 모듈은 얼굴의 윤곽선과 눈2/코/귀2 얼굴의 특징점을 인식하기 위해 posenet 알고리즘을 사용한 다. 상기 LRS 서버는 실시간으로 학습자의 3D 학습 얼굴을 얼굴의 윤곽선과 사용자 단말의 카메라를 주시하는 얼굴 모습이 표현되는 머리와 이마/눈/코/귀/입을 포함하여 3D 모델링하여 렌더링하는 3D 렌더러를 더 포함하며, 상기 방법은 상기 3D 렌더러에 의해 실시간으로 학습자의 3D 학습 얼굴을 얼굴의 윤곽선과 사용자 단말의 카메 라를 주시하는 얼굴 모습이 표현되는 머리와 이마/눈/코/귀/입을 포함하여 3D 모델링하여 렌더링하는 단계를 더 포함한다. 상기 방법은 학습 시간 동안, 상기 학습자 단말에 구비된 녹음 및 녹화 프로그램의 녹음/녹화 데이터(소리 파일 과 이미지 파일이 통합된 영상 파일)을 상기 LRS 서버로 전송하여 저장되는 단계를 더 포함한다. 도 13은 온라인 학습/UBL 학습 또는 시험 시에, LRS 서버와 연동된 사용자 단말의 녹음/녹화 프로그램을 보인 화면이다. 앱 실행 및 시험데이터 요청, QR 코드 인식(또는 바코드 인식), 안면 인식 -> 데이터 확인 -> 레코딩 대기 -> 레코딩 시작(시험 데이터 기반 자동 오프라인 레코딩) -> 레코딩 중 앱 강제종료 등 예외 처리(재시작, 계속 레코딩 기능) -> 레코딩 종료 대기 -> 레코딩 종료 -> 레코딩 종료 후 처리(이미지 취합 및 영상파일, 녹음파일) -> 응시자 단말로부터 LRS 서버로 전송(학습 또는 시험 부정행위 관련 이미지, 영상 파일, 녹음 파일) -> 전송실패 예외 처리(자동 재시도, 수동 업로드) -> 처리 종료 메시지를 LRS 서버로부터 수신받고 종료 된다. 또한, 온라인 학습 및 UBL 학습 과정 후에, 온라인 시험 및 UBT 시험이 실시된다. 추가적으로, LMS와 UBL,UBT 클라우드 서버로 사용되는 LRS 서버는 온라인 시험 또는 UBT 시험을 위해, 응시자의 얼굴의 윤곽선과 눈2/코/귀2의 시각적인 부정행위를 감지하는 안 면인식 분석부와 말소리를 분석하는 음성인식 분석부를 기본적으로 구비하며, 상기 제어부에 연결되며, 상기 응시자 단말과 상기 감독관 단말로 시험 프로그램(App)과 시험지를 제공하 며, 응시자 정보들과 응시자의 현장 얼굴 사진, 감독관 정보를 관리하며, 온라인 시험 또는 UBT 시험 시에 일정 시험 시간 이내에 각각의 응시자 단말에 시험지 작성 답안을 저장 후 시험 종료시 시험 서버로 전송되며, 응시 자들의 시험지 작성 답안, 채점 결과, 감독관 정보와 응시자 현황 정보를 저장하여 관리하는 시험 관리부; 응시자들의 시험지와 작성 답안, 채점 결과를 저장하는 시험 정보DB; 응시자 정보와 표준 크기의 정면 얼굴 사 진을 저장하는 응시자DB와 얼굴 DB, 시험 DB를 더 포함한다. 온라인 시험 또는 UBT 시험을 관리하는 시험 관리부는 의과대학/치과대학/약학 대학/공과 대학 등의 대학 시험, TOEIC/TOEFL 시험, 어학 시험, 공무원 시험, 자격증 시험, 어학 교육, 보건의료교육 등의 학습과 온라인 시험지 를 제공하는 문제 은행의 각종 공인 인증 시험 또는 비공인 시험을 시험 일정과 장소를 공지하고, 시험 서버의 데이터베이스의 시험 프로그램을 사용하여 유무선 통신망을 통해 응시자 단말들에게 온라인 시험 또는 오프라인 상에서 저장된 시험 문제를 활용하여 시험을 치를 수 있는 모든 형태의 PC/스마트 기기를 활용하는 UBT 시험을 제공한다. LRS 서버의 제어부는 시험일정과 장소가 확정되면, 감독관을 선임하여 감독관에게 감독관선임정보를 제공 하고, 응시자들에게 문자 메시지/웹페이지를 통해 시험 일정과 장소를 공지하며, 시험 당일 시험장소의 감독관 단말로 시험 정보와 시험지 정보를 송수신하여 시험을 진행 관리하고, 자동채점결과부 및 검수관리부의 결과로 부터 채점 결과를 해당 응시자 단말들로 제공한다. 시험정보 데이터베이스에 저장되는 시험정보는 시험 제목, 시험 일정과 장소, 시험 시간, 시험 장소의 위치 정 보, 할당된 시험실별 감독관 정보와 응시자들 명단, 시험실별 좌석수, 감독관 정보, A/B 문제 유형별 시험지의 문제 정보, 답안 정보, 채점 정보, 감독관 정보를 포함한다. 그리고, 응시자 데이터베이스는 이름, 주민등록번호, 집주소, 이동전화번호, 이메일 등을 포함하는 응시자 정보, 응시자 사진(표준 크기의 얼굴 정면 사진) 및 QR 코드/passwd, ID/passwd 식별 정보와 시험 관련 정보, 응시자 신청 현황이 저장된다. 또한, 상기 LRS 서버는 UBL 학습 후에, 정해진 일정과 시간과 장소에서 UBT 시험을 실시하는 시험관리부와 채점부를 추가적으로 더 구비하며, 온라인 시험 또는 UBT 시험 시에, 정해진 일정과 시간과 장소에서 학습자의 응시표에 부착되는 인식 코드로써 바코드 또는 QR 코드를 사용하며, 실시예에서는 응시자들에게 QR 코드가 부착된 응시표가 제공된다. 상기 시험 프로그램의 시험지 문항은 주관식 및/또는 객관식 시험 문항을 포함하며, 각 문항마다 텍스트 및 이 미지 뿐만 아니라 텍스트, 이미지, VR/AR 콘텐츠, 음성과 동영상 중 적어도 하나 이상이 포함된 멀티미디어 시 험 문항이 출제되어 응시자 단말(300,310,311)로 디스플레이된다. 상기 응시자 단말(300,310,311)은 획일적으로 정면 카메라(C)를 구비하는 태블릿 PC, 스마트폰, PC, 노트북 중 어느 하나 단말을 사용하며, 온라인 시험 또는 UBT 시험 서버로부터 다운로드된 시험 프로그램(App)이 설 치되고, 온라인 시험 또는 UBT 시험 서버와 연동되는 영상과 소리가 레코딩되는 녹음 및 녹화 프로그램이 설치 된다. 시험시에는 , 상기 응시자 단말(300,310,311)은 응시자 단말의 정면 카메라 영상의 얼굴의 특징점들을 인식하는 인공지능 안면인식 모듈; 온라인 시험 또는 UBT 시험 중에, 시각적인 부정행위를 방지하도록 응시자 단말의 정면 카메라 영상의 얼굴의 행동 패턴을 인식하여 얼굴의 특징점들을 구성하는 얼굴의 윤곽선과 눈2, 코, 귀2의 얼굴의 특징점 5점 척도 부 정행위 방지 모듈; 및 온라인 시험 또는 UBT 시험 중에, 청각적인 부정행위를 방지하도록 응시자의 말소리를 인식하는 음성 인식 모듈 을 포함한다. 추가적으로, 응시자 단말은 주관식 시험 문항을 위해 스타일러스 펜의 필기체를 인식하여 문자로 변환하여 필기 체 문자를 인식하는 터치 센서와 디스플레이를 구비하는 응시자 단말의 필기체 인식부를 더 포함한다. 추가적으로, 온라인 시험 또는 UBT 시험은 2지/3지/4지/5지선다 객관식 시험 뿐만아니라 주관식 시험을 제공하 며. 주관식 시험 문항은 터치센서와 디스플레이를 구비하는 응시자 단말의 필기체 인식부를 사용하여 스타일러스 펜의 필기체를 인식하여 문자로 변환하여 필기체 문자를 인식하는 주관식 시험을 포함한다. 마찬가지로, 상기 안면인식 모듈에 사용된 상기 안면윤곽선 인식 기술은 posenet 알고리즘을 사용한다. 안면인식과 얼굴의 윤곽선과 눈2/코/귀2 얼굴의 특징점 5점 척도 부정행위를 방지하는 안면인식 모듈은 얼굴의 특징점 눈/코 3점이 양 끝 귀 2점에 가까워지는 지에 따라 오른쪽/왼쪽으로 머리 이동을 감지하고 추적하여 얼 굴의 행동 패턴을 검출하며, FACE RECOGNITION/FACE MOTION RECOGNITION/RESULT ANLAYSIS를 통해 얼굴 인식시 에 안면윤곽선 인식이 안되는 경우, 태블릿 PC의 카메라 영상이 촬영되는 시험 화면으로부터 일정 각도 이상으 로 벗어난 경우(눈/코 3점이 양 끝 귀 2점에 가까워지는 지에 따라 눈과 귀의 거리, 코와 귀의 거리, 눈과 눈 사이 거리, 귀와 귀의 거리, 목과 어깨의 거리, 어깨와 어깨의 거리의 해당 방향의 거리가 일정 수치를 넘는 경 우), 말소리가 들리는 경우 해당 응시자 단말로 경고 메시지 또는 알람을 출력하거나 또는 해당 응시자 단말에 저장한 후 이를 시험 종료시 서버로 전송하며, 서버는 응시자들에게 채점 결과를 제공한다. 마찬가지로, 응시자 단말은 온라인 또는 UBT 시험 서버와 연동되는 녹음/녹화 프로그램이 설치되며, AI 안면인 식/동작인식/소리인식 기술을 사용하여 인공지능 안면인식 모듈과 얼굴의 윤곽선과 눈2/코/귀2 얼굴의 특징점 5 점 척도 부정행위 방지 모듈, 및 음성인식 모듈을 구비하며, 온라인 시험 또는 UBT 시험 서버와 연동하여 온라 인 시험 또는 UBT 시험의 대리시험 방지 및 시청각적인 부정행위를 방지하게 된다. 본 발명에 따른 실시예들은 다양한 컴퓨터 수단을 통해 수행될 수 있는 프로그램 명령 형태로 구현되고, 컴퓨터 판독 가능 기록 매체에 기록될 수 있다. 상기 컴퓨터 판독 가능 기록 매체는 프로그램 명령, 데이터 파일, 데이 터 구조를 단독으로 또는 조합하여 포함할 수 있다. 컴퓨터 판독 가능 기록 매체는 스토리지, 하드 디스크, 플 로피 디스크 및 자기 테이프와 같은 자기 매체(magnetic media), CD-ROM, DVD와 같은 광기록 매체(optical media), 플롭티컬 디스크(floptical disk)와 같은 자기-광 매체(magneto-optical media), 및 롬(ROM), 램 (RAM), 플래시 메모리, 스토리지 등과 같은 저장 매체에 프로그램 명령을 저장하고 수행하도록 구성된 하드웨어 장치가 포함될 수 있다. 프로그램 명령의 예는 컴파일러에 의해 만들어지는 것과, 기계어 코드 뿐만 아니라 인 터프리터를 사용하여 컴퓨터에 의해 실행될 수 있는 고급 언어 코드를 포함할 수 있다. 상기 하드웨어 장치는 본 발명의 동작을 수행하기 위해 하나 이상의 소프트웨어 모듈로써 작동하도록 구성될 수 있다. 이상에서 설명한 바와 같이, 본 발명의 방법은 프로그램으로 구현되어 컴퓨터의 소프트웨어를 이용하여 읽을 수 있는 형태로 기록매체(CD-ROM, RAM, ROM, 메모리 카드, 하드 디스크, 광자기 디스크, 스토리지 디바이스 등)에 저장될 수 있다. 본 발명의 구체적인 실시예를 참조하여 설명하였지만, 본 발명은 상기와 같이 기술적 사상을 예시하기 위해 구 체적인 실시 예와 동일한 구성 및 작용에만 한정되지 않고, 본 발명의 기술적 사상과 범위를 벗어나지 않는 한 도 내에서 다양하게 변형하여 실시될 수 있으며, 본 발명의 범위는 후술하는 특허청구범위에 의해 결정되어야 한다."}
{"patent_id": "10-2022-0159847", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1a는 종래의 단말기의 음성인식을 통한 어학학습 시스템 구성도이다. 도 1b는 온라인 학습자를 위한 주의집중 판단 시스템의 판단 방법를 나타낸 순서도이다. 도 2a, 2b는 비대면 온라인 학습에서 웹 브라우저 기반 ubcloud 인공지능을 사용한 주의 집중 학습 시스템의 구 현 예이다. 도 3은 UBL 학습 시에, 태블릿 PC, 스마트폰, PC 기반 학습 콘텐츠를 제공하고 Blended Learning을 위한 학습자 의 학습 패턴을 기록하는 LRS 서버를 구비하는 안면인식 감독관 기술을 활용한 유러닝 학습 플랫폼에서의 학습 주의 집중 시스템 구성도이다. 도 4 내지 도 6은 UBL 클라우드 서버(LRS 서버, Learning Record Server)에 접속된 사용자 단말의 주의집중 UBL 학습 테스트 화면이다. 도 7은 학습자의 센터 얼라이먼트(centre alignment)를 기준으로 학습자의 자세 인식 얼굴의 윤곽선과 눈2/코/ 귀2 안면인식 초기화 화면이다. 도 8은 Posenet 알고리즘을 사용한 학습자의 학습 얼굴 눈2/코/귀2 얼굴 영상과, 3D 학습 얼굴 렌더링(3D view), 및 학습 패턴과 관련된 통계 데이터를 시각화하여 학습 분석 차트로 표시된 막대 그래프와 산점도를 나 타낸다. 도 9는 출석, 온라인 학습/UBL 학습 콘텐츠를 제공하고 AI 모듈을 구동하여 학습자의 얼굴 안면 인식에 의해 학 습 패턴(등급, 접수), 학습과 과제수행(assignment), 학습자별 학습 패턴을 제공하며 통과/탈락 예측을 제공하 는 UBL 클라우드 서버(LRS 서버)의 지식 트랙킹 모듈(activities), activities의 그룹핑, 학습 패턴 일반화, 학습 패턴 통계 데이터 시각화 및 통과/탈락 예측(prediction)을 제공하는 UBL 클라우드 서버(LRS 서버)의 구성도이다. 도 10a 내지 도 10d는 출석, 온라인 학습/UBL 학습 콘텐츠를 제공하고 AI 모듈을 구동하여 학습자의 얼굴 안면 인식에 의해 학습 패턴(등급, 접수), 학습과 과제수행(assignment), 학습자별 학습 패턴을 제공하며 통과/탈락 예측을 제공하는 UBL 클라우드 서버(LRS 서버)의 지식 트랙킹 액티비티들과 애트리뷰션, 학습 진단을 나타낸 도 면이다. 도 11은 UBL 학습 시에, UI/UX 화면의 음성 검출 화면이다. 도 12는 음성 인식 시에, 주변 잡음을 필터링하고 학습자의 말소리를 샘플링(8k, 16k, 또는 48k 샘플링)하여 음 성 인식된 SileroVAD 및 SpeechBrain 알고리즘 실행 결과이다. 도 13은 온라인 학습/UBL 학습 또는 시험 시에, LRS 서버와 연동된 사용자 단말의 녹음/녹화 프로그램을 보인 화면이다."}
