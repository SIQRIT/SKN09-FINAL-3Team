{"patent_id": "10-2023-0000451", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0108758", "출원번호": "10-2023-0000451", "발명의 명칭": "고빈도 증권 거래를 위한 작업 스케줄링 방법 및 시스템", "출원인": "리벨리온 주식회사", "발명자": "유성엽"}}
{"patent_id": "10-2023-0000451", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "적어도 하나의 프로세서에 의해서 수행되는, 고빈도 거래(High Frequency Trading)를 위한 작업 스케줄링 방법에 있어서,고빈도 거래를 위한 복수의 입력 데이터를 획득하는 단계;작업 완료까지의 허용 시간 및 하드웨어의 가용 리소스에 기초하여, 기계학습 모델의 추론 연산에 대한 작업부하(workload)를 결정하는 단계; 상기 결정된 작업부하에 기초하여, 상기 복수의 입력 데이터 중에서 적어도 하나의 입력 데이터를 선택하는 단계; 및상기 선택된 적어도 하나의 입력 데이터를 상기 기계학습 모델에 적용하는 단계를 포함하는, 고빈도 거래 작업 스케줄링 방법."}
{"patent_id": "10-2023-0000451", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 작업부하를 결정하는 단계는,상기 허용 시간 및 상기 하드웨어의 가용 리소스에 기초하여, 상기 작업부하를 처리하기 위한 상기 하드웨어의리소스를 결정하는 단계; 및상기 결정된 리소스를 상기 하드웨어로 공급하는 단계를 포함하는, 고빈도 거래 작업 스케줄링 방법."}
{"patent_id": "10-2023-0000451", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,상기 결정된 리소스를 상기 하드웨어로 공급하는 단계는,상기 결정된 리소스에 기초하여, 상기 하드웨어로 공급되는 클럭의 속도 또는 전압 중 적어도 하나를 조절하는단계를 포함하는, 고빈도 거래 작업 스케줄링 방법."}
{"patent_id": "10-2023-0000451", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서,상기 하드웨어는 상기 기계학습 모델의 연산을 위한 복수의 전용 가속기를 포함하고,상기 클럭의 속도 또는 전압 중 적어도 하나를 조절하는 단계는, 상기 복수의 전용 가속기 중에서, 상기 작업부하가 할당되는 적어도 하나의 전용 가속기를 식별하는 단계; 및상기 식별된 적어도 하나의 전용 가속기로 공급되는 클럭의 속도 또는 전압 중 적어도 하나를 조절하는 단계공개특허 10-2024-0108758-3-를 포함하는, 고빈도 거래 작업 스케줄링 방법."}
{"patent_id": "10-2023-0000451", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서,상기 기계학습 모델의 추론 연산에 대한 작업부하를 결정하는 단계는,상기 허용 시간 이내에 작업 완료가 가능한 하나 이상의 후보 작업부하를 후보 목록에 등록하는 단계; 및상기 후보 목록 중에서, 하나의 후보 작업부하를 상기 추론 연산에 대한 작업부하로 결정하는 단계를 포함하고, 상기 결정된 작업부하에 포함된 배치 사이즈를 가진 적어도 하나의 입력 데이터가 상기 기계학습 모델에 입력되는, 고빈도 거래 작업 스케줄링 방법."}
{"patent_id": "10-2023-0000451", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5항에 있어서,상기 후보 목록에 등록된 후보 작업부하 각각의 지연 시간은 상기 허용 시간 이내이고, 상기 후보 목록에 등록된 후보 작업부하 각각의 필요 전력량은 가용 전력량 이내이고,상기 후보 작업부하의 각각과 관련된 할당 리소스 및 배치 사이즈에 기초하여 상기 지연 시간과 상기 필요 전력량이 산출되는, 고빈도 거래 작업 스케줄링 방법."}
{"patent_id": "10-2023-0000451", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제5항에 있어서,상기 후보 목록 중에서, 하나의 후보 작업부하를 상기 추론 연산에 대한 작업부하로 결정하는 단계는,상기 하나 이상의 후보 작업부하의 각각과 관련된 할당 리소스와 배치 사이즈에 기초하여, 상기 하나 이상의 후보 작업부하의 각각에 대한 성능지표를 산출하는 단계; 및상기 산출된 성능지표가 가장 높은 후보 작업부하를 상기 추론 연산에 대한 작업부하로 결정하는 단계를 포함하는, 고빈도 거래 작업 스케줄링 방법."}
{"patent_id": "10-2023-0000451", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제5항에 있어서,상기 후보 목록 중에서, 하나의 후보 작업부하를 상기 추론 연산에 대한 작업부하로 결정하는 단계는,상기 하나 이상의 후보 작업부하의 각각과 관련된 할당 리소스에 기초하여, 가장 적은 할당 리소스를 가지는 후보 작업부하를 상기 추론 연산에 대한 작업부하로 결정하는 단계를 포함하는, 고빈도 거래 작업 스케줄링 방법."}
{"patent_id": "10-2023-0000451", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제5항에 있어서,상기 후보 목록 중에서, 하나의 후보 작업부하를 상기 추론 연산에 대한 작업부하로 결정하는 단계는,공개특허 10-2024-0108758-4-상기 하나 이상의 후보 작업부하의 각각과 관련된 할당 리소스와 배치 사이즈에 기초하여, 상기 하나 이상의 후보 작업부하의 각각의 지연 시간을 산출하는 단계; 및상기 산출된 지연 시간이 가장 짧은 후보 작업부하를 상기 추론 연산에 대한 작업부하로 결정하는 단계를 포함하는, 고빈도 거래 작업 스케줄링 방법."}
{"patent_id": "10-2023-0000451", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제5항에 있어서,상기 후보 목록 중에서, 하나의 후보 작업부하를 상기 추론 연산에 대한 작업부하로 결정하는 단계는,상기 하나 이상의 후보 작업부하의 각각과 관련된 배치 사이즈에 기초하여, 가장 큰 배치 사이즈를 가지는 후보작업부하를 상기 추론 연산에 대한 작업부하로 결정하는 단계를 포함하는, 고빈도 거래 작업 스케줄링 방법."}
{"patent_id": "10-2023-0000451", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제5항에 있어서,상기 후보 목록에 후보 작업부하가 등록되지 않았다는 판정에 응답하여, 상기 복수의 입력 데이터 중에서 가장오래된 입력 데이터를 추출하는 단계; 및상기 추출된 입력 데이터를 규칙 기반으로 주문 데이터를 생성하는 규칙 기반 주문 모델에 적용하는 단계를 더 포함하는, 고빈도 거래 작업 스케줄링 방법."}
{"patent_id": "10-2023-0000451", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제1항에 있어서,상기 복수의 입력 데이터를 획득하는 단계 이전에,하나 이상의 타겟 종목에 대한 마켓 데이터의 트래픽을 획득하는 단계; 및상기 획득된 트래픽에 기초하여, 상기 작업 완료까지의 허용 시간을 결정하는 단계를 더 포함하는, 고빈도 거래 작업 스케줄링 방법."}
{"patent_id": "10-2023-0000451", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제1항에 있어서,상기 하드웨어는 상기 기계학습 모델의 연산을 위한 전용 가속기를 포함하고, 상기 방법은,상기 추론 연산에 대한 작업부하를 결정하는 단계 이전에, 상기 전용 가속기에 할당되는 최소 리소스를 결정하는 단계; 및상기 결정된 최소 리소스가 상기 전용 가속기에 공급되도록 상기 하드웨어로 공급되는 리소스를 조절하는 단계를 더 포함하는, 고빈도 거래 작업 스케줄링 방법.공개특허 10-2024-0108758-5-청구항 14 제13항에 있어서,상기 전용 가속기에 할당되는 최소 리소스를 결정하는 단계는, 상기 전용 가속기로 입력되는 적어도 하나의 입력 데이터에 대한 배치 사이즈를 식별하는 단계;상기 전용 가속기로 공급되는 리소스보다 적은 복수의 후보 리소스를 선택하는 단계;상기 식별된 배치 사이즈 및 상기 선택된 복수의 후보 리소스에 기초하여, 상기 복수의 후보 리소스의 각각에대한 작업 지연 시간을 산출하는 단계; 및상기 산출된 작업 지연 시간이 상기 작업 완료까지의 허용 시간보다 미만이 되는 적어도 하나의 후보 리소스 중에서, 가장 적은 후보 리소스를 상기 전용 가속기로 할당되는 최소 리소스로 결정하는 단계를 포함하는, 고빈도 거래 작업 스케줄링 방법."}
{"patent_id": "10-2023-0000451", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제1항에 있어서,상기 하드웨어는 상기 기계학습 모델의 연산을 위한 복수의 전용 가속기를 포함하고, 상기 선택된 적어도 하나의 입력 데이터를 상기 기계학습 모델에 적용하는 단계는, 상기 작업부하를 담당하는 타겟 전용 가속기를 결정하는 단계; 및상기 선택된 적어도 하나의 입력 데이터를 상기 타겟 전용 가속기로 제공하는 단계를 포함하고,상기 타겟 전용 가속기는 상기 적어도 하나의 입력 데이터를 상기 기계학습 모델에 입력하여, 고빈도 거래를 위한 추론 연산을 수행하도록 구성된, 고빈도 거래 작업 스케줄링 방법."}
{"patent_id": "10-2023-0000451", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제1항에 있어서,상기 하드웨어는 상기 기계학습 모델의 연산을 위한 복수의 전용 가속기를 포함하고, 상기 복수의 전용 가속기 각각에는 리소스가 공급되고, 상기 방법은, 상기 선택된 적어도 하나의 입력 데이터를 상기 기계학습 모델에 입력하는 단계 이후에, 상기 복수의 전용 가속기 각각으로 공급되고 남은 잔여 가용 리소스를 측정하는 단계;상기 복수의 전용 가속기 중에서, 상기 측정된 잔여 가용 리소스를 제공하기 위한 타겟 전용 가속기를 결정하는단계; 및상기 결정된 타겟 전용 가속기로, 상기 잔여 가용 리소스의 일부 또는 전부를 공급하는 단계를 더 포함하는, 고빈도 거래 작업 스케줄링 방법."}
{"patent_id": "10-2023-0000451", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제16항에 있어서,상기 타겟 전용 가속기를 결정하는 단계는,하나 이상의 전용 가속기의 각각에 대한 후보 리소스를 후보 목록에 등록하는 단계 - 상기 후보 리소스는 전용공개특허 10-2024-0108758-6-가속기로 공급되는 리소스보다 증가된 리소스를 가짐 - ; 및상기 후보 목록에 등록된 하나 이상의 후보 리소스 중, 하나의 후보 리소스와 연관된 전용 가속기를 상기 타겟전용 가속기로 결정하는 단계를 포함하고,상기 잔여 가용 리소스의 일부 또는 전부를 공급하는 단계는, 상기 타겟 전용 가속기와 연관된 하나의 후보 리소스에 기초하여, 상기 가용 리소스의 일부 또는 전부를 상기타겟 전용 가속기로 공급하는 단계를 포함하는, 고빈도 거래 작업 스케줄링 방법."}
{"patent_id": "10-2023-0000451", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제17항에 있어서, 상기 후보 리소스를 후보 목록에 등록하는 단계는, 상기 복수의 전용 가속기 각각으로 공급되고 남은 잔여 전력량을 측정하는 단계;상기 하나 이상의 전용 가속기 각각에 후보 리소스를 공급하는 경우, 상기 하나 이상의 전용 가속기 각각에서요구되는 제1 전력량을 산출하는 단계;상기 하나 이상의 전용 가속기 각각에 대해, 상기 산출된 제1 전력량에서 상기 하나 이상의 전용 가속기 각각으로 공급 중인 제2 전력량을 차감한 제3 전력량을 산출하는 단계; 상기 산출된 제3 전력량이 상기 잔여 전력량을 초과하는 전용 가속기를 식별하는 단계; 및 상기 식별된 전용 가속기와 연관된 후보 리소스를 상기 후보 목록에서 제거하는 단계를 포함하는, 고빈도 거래 작업 스케줄링 방법."}
{"patent_id": "10-2023-0000451", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제17항에 있어서,상기 하나의 후보 리소스와 연관된 전용 가속기를 상기 타겟 전용 가속기로 결정하는 단계는,상기 하나 이상의 전용 가속기의 각각에 입력되는 적어도 하나의 입력 데이터에 대한 배치 사이즈 및 상기 후보목록에 포함된 후보 리소스에 기초하여, 상기 하나 이상의 전용 가속기의 각각에 대한 추가 성능지표를 산출하는 단계; 및상기 산출된 추가 성능지표가 가장 높은 전용 가속기를 상기 타겟 전용 가속기로 결정하는 단계를 포함하는, 고빈도 거래 작업 스케줄링 방법."}
{"patent_id": "10-2023-0000451", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제17항에 있어서,상기 하나의 후보 리소스와 연관된 전용 가속기를 상기 타겟 전용 가속기로 결정하는 단계는,상기 후보 목록에 포함된 후보 리소스에 기초하여, 상기 하나 이상의 전용 가속기의 각각으로 추가되는 전력량을 산출하는 단계; 및상기 산출된 전력량 중에서 최소의 전력량을 가지는 전용 가속기를 상기 타겟 전용 가속기로 결정하는 단계공개특허 10-2024-0108758-7-를 포함하는, 고빈도 거래 작업 스케줄링 방법."}
{"patent_id": "10-2023-0000451", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_21", "content": "제17항에 있어서,상기 하나의 후보 리소스와 연관된 전용 가속기를 상기 타겟 전용 가속기로 결정하는 단계는,하나 이상의 전용 가속기의 각각에 입력되는 적어도 하나의 입력 데이터에 대한 배치 사이즈에 기초하여, 상기후보 목록에 등록된 전용 가속기들 중에서 최대의 배치 사이즈를 가지는 전용 가속기를 상기 타겟 전용 가속기로 결정하는 단계를 포함하는, 고빈도 거래 작업 스케줄링 방법."}
{"patent_id": "10-2023-0000451", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_22", "content": "제1항 내지 제21항 중 어느 한 항에 따른 방법을 컴퓨터에서 실행하기 위해 컴퓨터 판독 가능한 기록 매체에 저장된 컴퓨터 프로그램."}
{"patent_id": "10-2023-0000451", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_23", "content": "정보 처리 시스템으로서, 하나 이상의 인스트럭션을 저장하는 메모리; 및상기 메모리의 하나 이상의 인스트럭션을 실행함으로써, 고빈도 거래를 위한 복수의 입력 데이터를 획득하고,작업 완료까지의 허용 시간 및 하드웨어의 가용 리소스에 기초하여, 기계학습 모델의 추론 연산에 대한 작업부하를 결정하고, 상기 결정된 작업부하에 기초하여, 상기 복수의 입력 데이터 중에서 적어도 하나의 입력 데이터를 선택하고, 상기 선택된 적어도 하나의 입력 데이터를 상기 기계학습 모델에 적용하도록 구성된 프로세서를 포함하는, 정보 처리 시스템."}
{"patent_id": "10-2023-0000451", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 개시는 적어도 하나의 프로세서에 의해 수행되는 고빈도 거래를 위한 작업 스케줄링 방법이 제공된다. 이 방 법은 고빈도 거래를 위한 복수의 입력 데이터를 획득하는 단계, 작업 완료까지의 허용 시간 및 하드웨어의 가용 리소스에 기초하여, 기계학습 모델의 추론 연산에 대한 작업부하(workload)를 결정하는 단계 및 결정된 작업부하 에 기초하여, 복수의 입력 데이터 중에서 적어도 하나의 입력 데이터를 선택하는 단계 및 선택된 적어도 하나의 입력 데이터를 기계학습 모델에 적용하는 단계를 포함할 수 있다."}
{"patent_id": "10-2023-0000451", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 고빈도 증권 거래를 위한 작업 스케줄링 방법 및 시스템에 관한 것으로서, 구체적으로, 하드웨어의 가용 리소스에 기초하여 고빈도 증권 거래를 위한 작업을 스케줄링하는 방법 및 시스템에 관한 것이다."}
{"patent_id": "10-2023-0000451", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "온라인을 통해서, 주식, 채권, 파생상품 등 유가 증권을 활발하게 거래되고 있다. 유가 증권은 수시로 가격이 변동될 수 있어, 거래자는 가격 변동 사항을 모니티링하여, 목표가 또는 손절가에 도달한 유가 증권을 매수 또 는 매도하기도 한다. 이러한 유가 증권의 매매는 알고리즘을 통해서 자동적으로 수행되기도 한다. 또한, 미세한 가격 변동을 예측하여, 짧은 시간 안에 높은 빈도로 거래를 수행하는 고빈도 증권 거래(high frequency trading)가 유권 증권 시장에서 발생하고 있다. 고빈도 증권 거래는 주식, 채권, 파생상품 등 유가 증권의 미세한 가격 변동을 이용하여, 짧은 시간 안에 높은 빈도(예를 들어, 1초에 수백 번에서 수천 번)로 거 래하는 거래 방식이다. 고빈도 증권 거래에 있어서 빠른 처리 속도는 매우 중요하다. 일반적으로, 입력된 정 보를 기초로 트레이딩 알고리즘을 처리하여 출력을 내보내기까지의 시간이 단축될수록 거래에서의 우위가 선점 될 수 있다. 한편, 고빈도 증권 거래에 기계학습 모델이 이용되고 있다. 기계학습 모델을 이용한 고빈도 증권 거래 기법은 마켓으로부터 획득되는 대량의 데이터를 분석하기 때문에, 특정 종족의 시세를 예측할 때, 고전적인 알고리즘에 비교하여 더 많은 인자들을 고려할 뿐만 아니라 시세 예측의 정확성도 우수할 수 있다. 다만, 기계학습 모델을이용하여 다량의 데이터를 분석하기 위해서는, 기계학습 모델의 연산에 많은 저장 공간과 처리 자원이 요구될 수 있다. 또한, 기계학습 모델에서, 대량의 데이터에 대한 복잡한 연산이 요구되기 때문에, 기계학습 모델을 이용하는 데 이터양, 연산 복잡도 등에 따라 증권 주문을 위한 연산 속도가 달라질 수 있다. 예컨대, 데이터양이 적으면 기 계학습 모델의 연산 속도가 빨라질 수 있고, 연산 복잡도가 높으면 기계학습 모델의 연산 속도가 느려질 수 있 다. 즉, 데이터양 및/또는 연산 복잡도에 따라 기계학습 모델을 포함하는 시스템의 스루풋(throughput) 및/또 는 지연 시간(latency)이 달라질 수 있다. 데이터양이 많아지거나 연산 복잡도가 높아져서 주문 데이터를 위한 지연 시간(latency)이 길어지는 경우, 고빈도 증권 거래에서의 주문 데이터 생성이 늦어질 수 있다. 이에 따라, 지연 시간 및/또는 하드웨어의 가용 리소스를 고려하여, 기계학습 모델의 추론 연산에 대한 적절한 작업 스케줄링이 필요하다."}
{"patent_id": "10-2023-0000451", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 개시는 상술된 문제점을 해결하기 위한 고빈도 증권 거래를 위한 작업 스케줄링 방법, 기록매체에 저장된 컴 퓨터 프로그램 및 장치(시스템)를 제공한다."}
{"patent_id": "10-2023-0000451", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 개시는 방법, 장치(시스템) 및/또는 컴퓨터 판독 가능 저장 매체에 저장된 컴퓨터 프로그램, 컴퓨터 프로그 램이 저장된 컴퓨터 판독 가능 저장 매체를 포함한 다양한 방식으로 구현될 수 있다. 본 개시의 일 실시예에 따르면, 적어도 하나의 프로세서에 의해서 수행되는 고빈도 거래를 위한 작업 스케줄링 방법은, 고빈도 거래를 위한 복수의 입력 데이터를 획득하는 단계, 작업 완료까지의 허용 시간 및 하드웨어의 가용 리소스에 기초하여, 기계학습 모델의 추론 연산에 대한 작업부하(workload)를 결정하는 단계 및 결정된 작 업부하에 기초하여, 복수의 입력 데이터 중에서 적어도 하나의 입력 데이터를 선택하는 단계 및 선택된 적어도 하나의 입력 데이터를 기계학습 모델에 적용하는 단계를 포함할 수 있다. 또한, 작업부하를 결정하는 단계는, 허용 시간 및 하드웨어의 가용 리소스에 기초하여, 작업부하를 처리하기 위 한 하드웨어의 리소스를 결정하는 단계 및 결정된 리소스를 하드웨어로 공급하는 단계를 포함할 수 있다. 또한, 결정된 리소스를 하드웨어로 공급하는 단계는, 결정된 리소스에 기초하여, 하드웨어로 공급되는 클럭의 속도 또는 전압 중 적어도 하나를 조절하는 단계를 포함할 수 있다. 또한, 하드웨어는 기계학습 모델의 연산을 위한 복수의 전용 가속기를 포함하고, 클럭의 속도 또는 전압 중 적 어도 하나를 조절하는 단계는, 복수의 전용 가속기 중에서, 작업부하가 할당되는 적어도 하나의 전용 가속기를 식별하는 단계 및 식별된 적어도 하나의 전용 가속기로 공급되는 클럭의 속도 또는 전압 중 적어도 하나를 조절 하는 단계를 포함할 수 있다. 또한, 기계학습 모델의 추론 연산에 대한 작업부하를 결정하는 단계는, 허용 시간 이내에 작업 완료가 가능한 하나 이상의 후보 작업부하를 후보 목록에 등록하는 단계 및 후보 목록 중에서, 하나의 후보 작업부하를 추론 연산에 대한 작업부하로 결정하는 단계를 포함하고, 결정된 작업부하에 포함된 배치 사이즈를 가진 적어도 하나 의 입력 데이터가 기계학습 모델에 입력될 수 있다. 또한, 후보 목록에 등록된 후보 작업부하 각각의 지연 시간은 허용 시간 이내이고, 후보 목록에 등록된 후보 작 업부하 각각의 필요 전력량은 가용 전력량 이내이고, 후보 작업부하의 각각과 관련된 할당 리소스 및 배치 사이 즈에 기초하여 지연 시간과 필요 전력량이 산출될 수 있다. 또한, 후보 목록 중에서, 하나의 후보 작업부하를 추론 연산에 대한 작업부하로 결정하는 단계는, 하나 이상의 후보 작업부하의 각각과 관련된 할당 리소스와 배치 사이즈에 기초하여, 하나 이상의 후보 작업부하의 각각에 대한 성능지표를 산출하는 단계 및 산출된 성능지표가 가장 높은 후보 작업부하를 추론 연산에 대한 작업부하로 결정하는 단계를 포함할 수 있다. 또한, 후보 목록 중에서, 하나의 후보 작업부하를 추론 연산에 대한 작업부하로 결정하는 단계는, 하나 이상의 후보 작업부하의 각각과 관련된 할당 리소스에 기초하여, 가장 적은 할당 리소스를 가지는 후보 작업부하를 추론 연산에 대한 작업부하로 결정하는 단계를 포함할 수 있다. 또한, 후보 목록 중에서, 하나의 후보 작업부하를 추론 연산에 대한 작업부하로 결정하는 단계는, 하나 이상의 후보 작업부하의 각각과 관련된 할당 리소스와 배치 사이즈에 기초하여, 하나 이상의 후보 작업부하의 각각의 지연 시간을 산출하는 단계 및 산출된 지연 시간이 가장 짧은 후보 작업부하를 추론 연산에 대한 작업부하로 결 정하는 단계를 포함할 수 있다. 또한, 후보 목록 중에서, 하나의 후보 작업부하를 추론 연산에 대한 작업부하로 결정하는 단계는, 하나 이상의 후보 작업부하의 각각과 관련된 배치 사이즈에 기초하여, 가장 큰 배치 사이즈를 가지는 후보 작업부하를 추론 연산에 대한 작업부하로 결정하는 단계를 포함할 수 있다. 또한, 작업 스케줄링 방법은, 후보 목록에 후보 작업부하가 등록되지 않았다는 판정에 응답하여, 복수의 입력 데이터 중에서 가장 오래된 입력 데이터를 추출하는 단계 및 추출된 입력 데이터를 규칙 기반으로 주문 데이터 를 생성하는 규칙 기반 주문 모델에 적용하는 단계를 더 포함할 수 있다. 또한, 작업 스케줄링 방법은, 복수의 입력 데이터를 획득하는 단계 이전에, 하나 이상의 타겟 종목에 대한 마켓 데이터의 트래픽을 획득하는 단계 및 획득된 트래픽에 기초하여, 작업 완료까지의 허용 시간을 결정하는 단계를 더 포함할 수 있다. 또한, 하드웨어는 기계학습 모델의 연산을 위한 전용 가속기를 포함하고, 작업 스케줄링 방법은 추론 연산에 대 한 작업부하를 결정하는 단계 이전에, 전용 가속기에 할당되는 최소 리소스를 결정하는 단계 및 결정된 최소 리 소스가 전용 가속기에 공급되도록 하드웨어로 공급되는 리소스를 조절하는 단계를 더 포함할 수 있다. 또한, 전용 가속기에 할당되는 최소 리소스를 결정하는 단계는, 전용 가속기로 입력되는 적어도 하나의 입력 데 이터에 대한 배치 사이즈를 식별하는 단계, 전용 가속기로 공급되는 리소스보다 적은 복수의 후보 리소스를 선 택하는 단계, 식별된 배치 사이즈 및 선택된 복수의 후보 리소스에 기초하여, 복수의 후보 리소스의 각각에 대 한 작업 지연 시간을 산출하는 단계 및 산출된 작업 지연 시간이 작업 완료까지의 허용 시간보다 미만이 되는 적어도 하나의 후보 리소스 중에서, 가장 적은 후보 리소스를 전용 가속기로 할당되는 최소 리소스로 결정하는 단계를 포함할 수 있다. 또한, 하드웨어는 기계학습 모델의 연산을 위한 복수의 전용 가속기를 포함하고, 선택된 적어도 하나의 입력 데 이터를 기계학습 모델에 적용하는 단계는, 작업부하를 담당하는 타겟 전용 가속기를 결정하는 단계 및 선택된 적어도 하나의 입력 데이터를 타겟 전용 가속기로 제공하는 단계를 포함하고, 타겟 전용 가속기는 적어도 하나 의 입력 데이터를 기계학습 모델에 입력하여, 고빈도 거래를 위한 추론 연산을 수행하도록 구성될 수 있다. 또한, 하드웨어는 기계학습 모델의 연산을 위한 복수의 전용 가속기를 포함하고, 복수의 전용 가속기 각각에는 리소스가 공급되고, 작업 스케줄링 방법은, 선택된 적어도 하나의 입력 데이터를 기계학습 모델에 입력하는 단 계 이후에, 복수의 전용 가속기 각각으로 공급되고 남은 잔여 가용 리소스를 측정하는 단계, 복수의 전용 가속 기 중에서, 측정된 잔여 가용 리소스를 제공하기 위한 타겟 전용 가속기를 결정하는 단계 및 결정된 타겟 전용 가속기로, 잔여 가용 리소스의 일부 또는 전부를 공급하는 단계를 더 포함할 수 있다. 또한, 타겟 전용 가속기를 결정하는 단계는, 하나 이상의 전용 가속기의 각각에 대한 후보 리소스를 후보 목록 에 등록하는 단계 - 후보 리소스는 전용 가속기로 공급되는 리소스보다 증가된 리소스를 가짐 -, 및 후보 목록 에 등록된 하나 이상의 후보 리소스 중, 하나의 후보 리소스와 연관된 전용 가속기를 타겟 전용 가속기로 결정 하는 단계를 포함하고, 잔여 가용 리소스의 일부 또는 전부를 공급하는 단계는, 타겟 전용 가속기와 연관된 하 나의 후보 리소스에 기초하여, 가용 리소스의 일부 또는 전부를 타겟 전용 가속기로 공급하는 단계를 포함할 수 있다. 또한, 후보 리소스를 후보 목록에 등록하는 단계는, 복수의 전용 가속기 각각으로 공급되고 남은 잔여 전력량을 측정하는 단계, 하나 이상의 전용 가속기 각각에 후보 리소스를 공급하는 경우, 하나 이상의 전용 가속기 각각 에서 요구되는 제1 전력량을 산출하는 단계, 하나 이상의 전용 가속기 각각에 대해, 산출된 제1 전력량에서 하 나 이상의 전용 가속기 각각으로 공급 중인 제2 전력량을 차감한 제3 전력량을 산출하는 단계, 산출된 제3 전력 량이 잔여 전력량을 초과하는 전용 가속기를 식별하는 단계 및 식별된 전용 가속기와 연관된 후보 리소스를 후 보 목록에서 제거하는 단계를 포함할 수 있다. 또한, 하나의 후보 리소스와 연관된 전용 가속기를 타겟 전용 가속기로 결정하는 단계는, 하나 이상의 전용 가 속기의 각각에 입력되는 적어도 하나의 입력 데이터에 대한 배치 사이즈 및 후보 목록에 포함된 후보 리소스에기초하여, 하나 이상의 전용 가속기의 각각에 대한 추가 성능지표를 산출하는 단계 및 산출된 추가 성능지표가 가장 높은 전용 가속기를 타겟 전용 가속기로 결정하는 단계를 포함할 수 있다. 또한, 하나의 후보 리소스와 연관된 전용 가속기를 타겟 전용 가속기로 결정하는 단계는, 후보 목록에 포함된 후보 리소스에 기초하여, 하나 이상의 전용 가속기의 각각으로 추가되는 전력량을 산출하는 단계 및 산출된 전 력량 중에서 최소의 전력량을 가지는 전용 가속기를 타겟 전용 가속기로 결정하는 단계를 포함할 수 있다. 또한, 하나의 후보 리소스와 연관된 전용 가속기를 타겟 전용 가속기로 결정하는 단계는, 하나 이상의 전용 가 속기의 각각에 입력되는 적어도 하나의 입력 데이터에 대한 배치 사이즈에 기초하여, 후보 목록에 등록된 전용 가속기들 중에서 최대의 배치 사이즈를 가지는 전용 가속기를 타겟 전용 가속기로 결정하는 단계를 포함할 수 있다. 상술한 작업 스케줄링 방법을 컴퓨터에서 실행하기 위해 컴퓨터 판독 가능한 기록 매체에 저장된 컴퓨터 프로그 램이 제공될 수 있다. 본 개시의 일 실시예에 따른 정보 처리 시스템은, 하나 이상의 인스트럭션을 저장하는 메모리 및 메모리의 하나 이상의 인스트럭션을 실행함으로써, 고빈도 거래를 위한 복수의 입력 데이터를 획득하고, 작업 완료까지의 허용 시간 및 하드웨어의 가용 리소스에 기초하여, 기계학습 모델의 추론 연산에 대한 작업부하를 결정하고, 결정된 작업부하에 기초하여, 복수의 입력 데이터 중에서 적어도 하나의 입력 데이터를 선택하고, 선택된 적어도 하나 의 입력 데이터를 기계학습 모델에 적용하도록 구성된 프로세서를 포함할 수 있다."}
{"patent_id": "10-2023-0000451", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 개시의 일부 실시예에 따르면, 기계학습 모델의 추론 연산에 대한 최적의 작업부하(workload)가 결정되고, 결정된 작업부하에 기초한 배치 사이즈(batch size)를 가지는 적어도 하나의 입력 데이터가 기계학습 모델에 적 용될 수 있다. 이에 따라, 허용 시간 이내의 고빈도 거래를 위한 최대 개수 또는 최대량의 주문 데이터가 생성 될 수 있다. 본 개시의 일부 실시예에 따르면, 하나 이상의 전용 가속기로 리소스가 공급되고 나서 남은 잔여 가용 리소스가 있으면, 최대의 성능을 발휘할 수 있는 전용 가속기로 잔여 가용 리소스가 공급될 수 있다. 이에 따라, 잔여 가용 리소스가 낭비되지 않을 뿐만 아니라, 고빈도 거래를 수행하는 시스템의 성능이 더 효과적으로 발휘될 수 있다. 본 개시의 일부 실시예에 따르면, 높은 성능이 요구되는 시기에 하드웨어에 많은 양의 리소스가 공급될 수 있다. 이에 따라, 하드웨어의 스루풋이 향상되어 주문 데이터 생성을 위한 연산이 지연되지 않고 신속하게 수 행될 수 있다. 본 개시의 일부 실시예에 따르면, 작업 스케줄링을 수행하기 전에, 허용되는 범위 내에서 최소 리소스가 전용 가속기로 공급할 수 있다. 이에 따라, 작업 스케줄링 전에 하드웨어의 가용 리소스가 최대로 모이게 되고, 최 대로 모인 가용 리소스가 이용되어 더욱 효율적으로 고빈도 주문을 위한 작업 스케줄링이 수행될 수 있다. 본 개시의 효과는 이상에서 언급한 효과로 제한되지 않으며, 언급되지 않은 다른 효과들은 청구범위의 기재로부"}
{"patent_id": "10-2023-0000451", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 2, "content": "터 본 개시가 속하는 기술분야에서 통상의 지식을 가진 자('통상의 기술자'라 함)에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2023-0000451", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 본 개시의 실시를 위한 구체적인 내용을 첨부된 도면을 참조하여 상세히 설명한다. 다만, 이하의 설명에 서는 본 개시의 요지를 불필요하게 흐릴 우려가 있는 경우, 널리 알려진 기능이나 구성에 관한 구체적 설명은 생략하기로 한다. 첨부된 도면에서, 동일하거나 대응하는 구성요소에는 동일한 참조부호가 부여되어 있다. 또한, 이하의 실시예 들의 설명에 있어서, 동일하거나 대응되는 구성요소를 중복하여 기술하는 것이 생략될 수 있다. 그러나, 구성 요소에 관한 기술이 생략되어도, 그러한 구성요소가 어떤 실시예에 포함되지 않는 것으로 의도되지는 않는다. 개시된 실시예의 이점 및 특징, 그리고 그것들을 달성하는 방법은 첨부되는 도면과 함께 후술되어 있는 실시예 들을 참조하면 명확해질 것이다. 그러나, 본 개시는 이하에서 개시되는 실시예들에 한정되는 것이 아니라 서로 다른 다양한 형태로 구현될 수 있으며, 단지 본 실시예들은 본 개시가 완전하도록 하고, 본 개시가 통상의 기술 자에게 발명의 범주를 완전하게 알려주기 위해 제공되는 것일 뿐이다. 본 명세서에서 사용되는 용어에 대해 간략히 설명하고, 개시된 실시예에 대해 구체적으로 설명하기로 한다. 본 명세서에서 사용되는 용어는 본 개시에서의 기능을 고려하면서 가능한 현재 널리 사용되는 일반적인 용어들을 선택하였으나, 이는 관련 분야에 종사하는 기술자의 의도 또는 판례, 새로운 기술의 출현 등에 따라 달라질 수 있다. 또한, 특정한 경우는 출원인이 임의로 선정한 용어도 있으며, 이 경우 해당되는 발명의 설명 부분에서 상세히 그 의미를 기재할 것이다. 따라서, 본 개시에서 사용되는 용어는 단순한 용어의 명칭이 아닌, 그 용어 가 가지는 의미와 본 개시의 전반에 걸친 내용을 토대로 정의되어야 한다. 본 명세서에서의 단수의 표현은 문맥상 명백하게 단수인 것으로 특정하지 않는 한, 복수의 표현을 포함한다. 또한, 복수의 표현은 문맥상 명백하게 복수인 것으로 특정하지 않는 한, 단수의 표현을 포함한다. 명세서 전체 에서 어떤 부분이 어떤 구성요소를 포함한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다른 구성요소를 제외하는 것이 아니라 다른 구성요소를 더 포함할 수 있음을 의미한다. 또한, 명세서에서 사용되는 '모듈' 또는 '부'라는 용어는 소프트웨어 또는 하드웨어 구성요소를 의미하며, '모 듈' 또는 '부'는 어떤 역할들을 수행한다. 그렇지만, '모듈' 또는 '부'는 소프트웨어 또는 하드웨어에 한정되 는 의미는 아니다. '모듈' 또는 '부'는 어드레싱할 수 있는 저장 매체에 있도록 구성될 수도 있고 하나 또는 그 이상의 프로세서들을 재생시키도록 구성될 수도 있다. 따라서, 일 예로서, '모듈' 또는 '부'는 소프트웨어 구성요소들, 객체지향 소프트웨어 구성요소들, 클래스 구성요소들 및 태스크 구성요소들과 같은 구성요소들과, 프로세스들, 함수들, 속성들, 프로시저들, 서브루틴들, 프로그램 코드의 세그먼트들, 드라이버들, 펌웨어, 마이 크로 코드, 회로, 데이터, 데이터베이스, 데이터 구조들, 테이블들, 어레이들 또는 변수들 중 적어도 하나를 포 함할 수 있다. 구성요소들과 '모듈' 또는 '부'들은 안에서 제공되는 기능은 더 작은 수의 구성요소들 및 '모듈' 또는 '부'들로 결합되거나 추가적인 구성요소들과 '모듈' 또는 '부'들로 더 분리될 수 있다. 본 개시의 일 실시예에 따르면, '모듈' 또는 '부'는 프로세서 및 메모리로 구현될 수 있다. '프로세서'는 범용 프로세서, 중앙 처리 장치(CPU), 마이크로프로세서, 디지털 신호 프로세서(DSP), 제어기, 마이크로제어기, 상태 머신 등을 포함하도록 넓게 해석되어야 한다. 몇몇 환경에서, '프로세서'는 주문형 반도체(ASIC), 프로그램가 능 로직 디바이스(PLD), 필드 프로그램가능 게이트 어레이(FPGA) 등을 지칭할 수도 있다. 예를 들어, 주문형 반도체는 신경망 처리 장치(NPU) 등을 포함할 수 있다. '프로세서'는, 예를 들어, CPU, NPU 및 FPGA의 조합,DSP와 마이크로프로세서의 조합, 복수의 마이크로프로세서들의 조합, DSP 코어와 결합한 하나 이상의 마이크로 프로세서들의 조합, 또는 임의의 다른 그러한 구성들의 조합과 같은 처리 디바이스들의 조합을 지칭할 수도 있 다. 또한, '메모리'는 전자 정보를 저장 가능한 임의의 전자 컴포넌트를 포함하도록 넓게 해석되어야 한다. '메모리'는 임의 액세스 메모리(RAM), 판독-전용 메모리(ROM), 비-휘발성 임의 액세스 메모리(NVRAM), 프로그 램가능 판독-전용 메모리(PROM), 소거-프로그램가능 판독 전용 메모리(EPROM), 전기적으로 소거가능 PROM(EEPROM), 플래쉬 메모리, 자기 또는 광학 데이터 저장장치, 레지스터들 등과 같은 프로세서-판독가능 매체 의 다양한 유형들을 지칭할 수도 있다. 프로세서가 메모리로부터 정보를 판독하고/하거나 메모리에 정보를 기 록할 수 있다면 메모리는 프로세서와 전자 통신 상태에 있다고 불린다. 프로세서에 집적된 메모리는 프로세서 와 전자 통신 상태에 있다. 본 개시에서, '시스템'은 서버 장치와 클라우드 장치 중 적어도 하나의 장치를 포함할 수 있으나, 이에 한정되 는 것은 아니다. 예를 들어, 시스템은 하나 이상의 서버 장치로 구성될 수 있다. 다른 예로서, 시스템은 하나 이상의 클라우드 장치로 구성될 수 있다. 또 다른 예로서, 시스템은 서버 장치와 클라우드 장치가 함께 구성되 어 동작될 수 있다. 또 다른 예로서, 시스템은 고빈도 증권 주문을 위한 클라이언트 장치일 수 있다. 또한, 이하의 실시예들에서 사용되는 제1, 제2, A, B, (a), (b) 등의 용어는 어떤 구성요소를 다른 구성요소와 구별하기 위해 사용되는 것일 뿐, 그 용어에 의해 해당 구성요소의 본질이나 차례 또는 순서 등이 한정되지는 않는다. 또한, 이하의 실시예들에서, 어떤 구성요소가 다른 구성요소에 '연결', '결합' 또는 '접속'된다고 기재된 경우, 그 구성요소는 그 다른 구성요소에 직접적으로 연결되거나 또는 접속될 수 있지만, 각 구성요소 사이에 또 다른 구성요소가 '연결', '결합' 또는 '접속'될 수도 있다고 이해되어야 한다. 또한, 이하의 실시예들에서 사용되는 '포함한다(comprises)' 및/또는 '포함하는(comprising)'은 언급된 구성요 소, 단계, 동작 및/또는 소자는 하나 이상의 다른 구성요소, 단계, 동작 및/또는 소자의 존재 또는 추가를 배제 하지 않는다. 본 개시에서, '복수의 A 각각' 은 복수의 A에 포함된 모든 구성 요소의 각각을 지칭하거나, 복수의 A에 포함된 일부 구성 요소의 각각을 지칭할 수 있다. 본 개시에서, '하드웨어'란 고빈도 거래 방법을 실시하기 위해 사용되는 임의의 장치를 지칭하며, 예를 들어, 중앙 처리 장치(예를 들어, CPU 등), 재프로그래밍 또는 재설계가 가능한 프로세서(예를 들어, FPGA), 가속기 (예를 들어, NPU, GPU 등), 메모리 등을 포함할 수 있으나, 이에 한정되지 않는다. 이러한 하드웨어는 정보 처 리 시스템에 포함되거나 정보 처리 시스템에 의해 접근될 수 있다. 본 개시에서, '리소스(resource)'는 하드웨어를 동작시키기 위해서 하드웨어로 공급되는 임의의 자원을 지칭할 수 있으며, 예를 들어, 전압, 클럭 주파수 등을 포함할 수 있다. 예를 들어, 리소스는 전압 값, 주파수 값 등 을 포함할 수 있다. 본 개시에서, '종목'이란, 증권 시장에서 매매 거래의 대상이 되는 주식, 채권, 파생상품(옵션, 선물 등)과 같 은 유가 증권을 내용과 형식에 따라 분류한 것을 지칭할 수 있다. 종목은 개별 종목 이외에 지수 관련 종목, 산업 섹터와 관련된 종목, 특정 상품(예를 들어, 원유, 농산물, 금 등)에 대한 종목, 환율 관련 종목 등도 포함 할 수 있다. 본 개시에서, '증권 거래소'란, 적어도 하나의 국가에서 유통되는 유가 증권을 유통하는 곳으로서, 각 기업이나 정보 등이 발행한 유가 증권을 상장하여 거래할 수 있도록 중개하는 곳을 지칭할 수 있다. 일 실시예에서, 증 권 거래소는 증권 거래소의 시스템을 포함할 수 있다. 본 개시에서, '오더북(Order Book; OB)'은 증권 시장에 존재하는 매수 희망자와 매도 희망자의 매수 주문 또는 매도 주문(호가, 수량, 매수 희망자 또는 매도 희망자 정보 등)에 대한 정보를 기록한 목록을 포함할 수 있다. 본 개시에서, '오더북의 상단(Top of the Book; ToB)'은 가장 높은 매수가와 가장 낮은 매도가에 대한 정보를 포함할 수 있다. 본 개시에서, '마켓 데이터'는 증권 거래소에서 거래되는 종목들에 대한 데이터를 포함할 수 있다. 예를 들어, 마켓 데이터는 증권 거래소에서 거래되는 종목들(중 적어도 일부)의 오더북, 공시, 뉴스 등을 포함할 수 있다.본 개시에서, '기계학습 모델'은 주어진 입력에 대한 해답(answer)을 추론하는데 사용하는 임의의 모델을 포함 할 수 있다. 일 실시예에 따르면, 기계학습 모델은 입력 레이어(층), 복수 개의 은닉 레이어 및 출력 레이어를 포함한 인공신경망 모델을 포함할 수 있다. 여기서, 각 레이어는 복수의 노드를 포함할 수 있다. 또한, 본 개 시에서, 기계학습 모델은 인공신경망 모델을 지칭할 수 있으며, 인공신경망 모델은 기계학습 모델을 지칭할 수 있다. 본 개시에서, '인스트럭션(instruction)'은 기능을 기준으로 묶인 일련의 컴퓨터 판독가능 명령어들로서 컴퓨터 프로그램의 구성요소이자 프로세서에 의해 실행되는 것을 지칭할 수 있다. 이하, 본 개시의 다양한 실시예들에 대하여 첨부된 도면에 따라 상세하게 설명한다. 도 1은 본 개시의 일 실시예에 따른 정보 처리 시스템의 작동 예시를 나타내는 개요도이다. 일 실시예에 따르면, 정보 처리 시스템은 마켓 데이터를 기초로 하나 이상의 미래 시점(가까운 미래 시점, 예를 들어, 미리 정해진 시간 후)의 시장 상황을 예측할 수 있으며, 이를 기초로 타겟 종목에 대한 주문을 생성하여 타겟 증권 거래소(제2 증권 거래소)에 전송할 수 있다. 고빈도 증권 거래에 있어서, 마켓 데이터를 기초로 빠른 속 도로 주문을 생성하여 전송하는 것이 매우 중요하다. 이 때문에, 고빈도 증권 거래에서는 마이크로초 (microsecond) 단위의 지연 시간(latency)까지 고려되어야 하며, 지연 시간을 감소시키기 위해 정보 처리 시스 템은 타겟 증권 거래소(제2 증권 거래소)의 서버와 가까운 곳에 위치(colocation)할 수 있다. 일 실시예에 따르면, 정보 처리 시스템은 제1 증권 거래소로부터 마켓 데이터를 수신할 수 있다. 추가적 으로 또는 이와 달리, 정보 처리 시스템은 제1 증권 거래소 이외에 웹 사이트 또는 애플리케이션으로부터 마켓 데이터를 수신할 수 있다. 여기서, 웹 사이트 또는 애플리케이션은 하나 이상의 거래소에서 발생하는 마 켓 데이터를 취합하는 사이트 또는 애플리케이션일 수 있고, 또는 사설 회사가 독자적으로 운영하는 사이트 또 는 애플리케이션일 수 있다. 마켓 데이터는 복수의 종목들에 대한 오더북, 공시, 뉴스 등이 포함될 수 있다. 일 실시예에서, 마켓 데이터는 타겟 종목에 대한 데이터를 포함할 수 있다. 예를 들어, 마켓 데이터는 타겟 종 목의 오더북의 상단, 타겟 종목에 대한 (유효한) 주문 목록, 타겟 종목에 관한 이전 주문에 대한 제1 증권 거래 소의 응답 등을 포함할 수 있다. 마켓 데이터는 일정 간격 동안에 동적으로 수신될 수 있다. 즉, 증권 시장 환경에 따라, 단위 시간 동안에 정 보 처리 시스템에서 수신되는 마켓 데이터의 크기 또는 개수가 상이할 수 있다. 예컨대, 증권 시장의 변 동이 큰 경우에는 단위 시간 동안에 수신되는 마켓 데이터의 크기가 크거나 또는 데이터의 개수가 많을 수 있다. 즉, 증권 시장의 변동성이 커지는 경우에 오더북의 변동 크기 또는 횟수도 증가하여, 이에 따라 단위 시 간당 정보 처리 시스템에서 수신되는 마켓 데이터의 크기 또는 개수도 많아질 수 있다. 도 1에서 제1 증권 거래소는 하나의 증권 거래소인 것처럼 도시되었으나, 이는 설명의 편의를 위한 것일 뿐이며, 제1 증권 거래소는 하나 이상의 증권 거래소를 포함할 수 있다. 또한, 도 1에서 제1 증권 거래소 는 제2 증권 거래소와 다른 별개의 거래소인 것처럼 도시되었으나, 이 역시 설명의 편의를 위한 것일 뿐이며, 제1 증권 거래소는 제2 증권 거래소를 포함하거나, 제2 증권 거래소는 제1 증권 거래소 를 포함할 수도 있다. 일 실시예에 따르면, 정보 처리 시스템은 마켓 데이터를 분석하여 주문을 생성할 수 있다. 예를 들어, 정 보 처리 시스템은 마켓 데이터를 기초로 생성된 데이터 및/또는 마켓 데이터를 분석하여, 하나 이상의 미 래 시점(예를 들어, n초 후, 여기서 n은 양의 실수임)에서의 시장 상황(예를 들어, 타겟 종목의 가격)을 예측하 고, 이를 기초로 주문을 생성할 수 있다. 여기서, 마켓 데이터에 기초하여 생성된 데이터 및/또는 마켓 데이터 를 분석하는 과정은 기계학습 모델(예를 들어, DNN 등)에 의해 수행될 수 있다. 한편, 고빈도 증권 거래에 있어서 마켓 데이터를 빠르게 분석하여 주문을 생성하는 것이 매우 중요한데, 일반적 인 프로세서의 경우 기계학습 모델의 복잡하고 대량의 연산을 지원하기 위한 저장 공간과 연산 자원을 보유하고 있지 않아 일반적인 프로세서를 이용하여 기계학습 모델을 구동하는 경우, 처리 속도 및/또는 효율이 떨어질 수 있다. 이러한 점을 감안하여, 본 개시의 일 실시예에 따른 정보 처리 시스템은, 기계학습 모델을 위한 전 용 가속기(예를 들어, 뉴럴 처리 유닛(Neural Processing Unit; NPU))를 포함할 수 있으며, 전용 가속기는 뉴럴 처리 유닛을 위한 집적회로(예를 들어, Application-Specific Integrated Circuit; ASIC)로 구현될 수 있다. 한편, 기계학습 모델을 이용하는 경우, 적절한 전/후 처리 과정이 필요할 수 있다. 예를 들어, 마켓 데이터로 부터 기계학습 모델의 입력 데이터를 생성하거나, 기계학습 모델로부터 출력된 데이터를 기초로 주문 데이터를 생성하는 과정이 필요할 수 있다. 이러한 전/후 처리 과정은 시장 상황, 규율, 마켓 메이커에 대한 보상 규정등의 변화에 따라 지속적으로 변경될 수 있다. 이러한 전/후 처리 과정을 처리하는 프로세서를 특정 용도로 맞 춤 제작된 주문형 반도체(예를 들어, ASIC)로 구현하는 경우, 재설계가 불가능하여 전/후 처리 과정이 변경되는 경우 변경된 전/후 처리 과정을 수행하기 위한 프로세서를 다시 제작해야 할 수 있다. 이에 따라, 기계학습 모 델의 구동을 제외한 과정은 재프로그래밍 및/또는 설계 변경이 가능한 프로세서(예를 들어, 필드 프로그래머블 게이트 어레이(Field Programmable Gate Array; FPGA)로 구현된 프로세서)에 의해 수행될 수 있다. 상술한 바와 같이, 기계학습 모델을 구동하는 프로세서가 전용 가속기(예를 들어, ASIC으로 구현된 전용 가속기)로 구성됨으로써 빠르고 효율적으로 기계학습 모델의 연산을 처리할 수 있다. 또한, 전/후 처리 과정은 재프로그래밍 또는 재설계가 가능한 프로세서(예를 들어, FPGA)를 이용하여 처리함으로써, 계속적으로 변화하는 시장 상황에 맞춰 유연하게 전/후 처리 과정이 변경될 수 있다. 이와 같이, 고빈도 증권 거래를 처리하기 위해 적합한 상이한 2 이상의 프로세서를 사용함으로써, 유연한 전/후 처리 과정의 구현 및 효율적이고 신속한 기계 학습 모델의 연산 처리가 동시에 실현될 수 있다. 도 2는 본 개시의 일 실시예에 따른 정보 처리 시스템의 내부 구성을 나타내는 블록도이다. 정보 처리 시 스템은 메모리, 프로세서, 통신 모듈 및 입출력 인터페이스를 포함할 수 있다. 도 2 에 도시된 바와 같이, 정보 처리 시스템은 통신 모듈을 이용하여 네트워크를 통해 정보 및/또는 데이 터를 통신할 수 있도록 구성될 수 있다. 메모리는 비-일시적인 임의의 컴퓨터 판독 가능한 기록매체를 포함할 수 있다. 일 실시예에 따르면, 메모 리는 ROM(read only memory), 디스크 드라이브, SSD(solid state drive), 플래시 메모리(flash memory) 등과 같은 비소멸성 대용량 저장 장치(permanent mass storage device)를 포함할 수 있다. 다른 예로서, ROM, SSD, 플래시 메모리, 디스크 드라이브 등과 같은 비소멸성 대용량 저장 장치는 메모리와는 구분되는 별도의 영 구 저장 장치로서 정보 처리 시스템에 포함될 수 있다. 또한, 메모리에는 운영체제와 적어도 하나의 프로그램 코드(예를 들어, 정보 처리 시스템에 설치되어 구동되는 기계학습 모델의 연산 처리, 전/후 처리, 증권 주문 전송 등을 위한 코드)가 저장될 수 있다. 도 2에서, 메모리는 단일 메모리인 것으로 도 시되었지만, 이는 설명의 편의를 위한 것일 뿐이며, 메모리는 복수의 메모리를 포함할 수 있다. 예를 들 어, 프로세서가 복수의 프로세서를 포함하는 경우, 메모리는 복수의 프로세서의 각각과 연결되어 처 리되는 하나 이상의 메모리를 포함할 수 있다. 다른 예로서, 프로세서가 복수의 프로세서를 포함하는 경 우, 복수의 프로세서와 연결되어 처리되는 복수의 메모리를 포함할 수 있다. 이러한 소프트웨어 구성요소들은 메모리와는 별도의 컴퓨터에서 판독 가능한 기록매체로부터 로딩될 수 있 다. 이러한 별도의 컴퓨터에서 판독 가능한 기록매체는 이러한 정보 처리 시스템에 직접 연결가능한 기록 매체를 포함할 수 있는데, 예를 들어, 플로피 드라이브, 디스크, 테이프, DVD/CD-ROM 드라이브, 메모리 카드 등 의 컴퓨터에서 판독 가능한 기록매체를 포함할 수 있다. 다른 예로서, 소프트웨어 구성요소들은 컴퓨터에서 판 독 가능한 기록매체가 아닌 통신 모듈을 통해 메모리에 로딩될 수도 있다. 예를 들어, 적어도 하나 의 프로그램은 개발자들 또는 어플리케이션의 설치 파일을 배포하는 파일 배포 시스템이 통신 모듈을 통해 제공하는 파일들에 의해 설치되는 컴퓨터 프로그램(예를 들어, 마켓 데이터 분석, 미래 시장 예측, 증권 주문 생성 및 전송 등을 위한 프로그램 등)에 기반하여 메모리에 로딩될 수 있다. 프로세서는 기본적인 산술, 로직 및 입출력 연산을 수행함으로써, 컴퓨터 프로그램의 명령을 처리하도록 구성될 수 있다. 명령은 메모리 또는 통신 모듈에 의해 사용자 단말(미도시) 또는 다른 외부 시스템 으로 제공될 수 있다. 예를 들어, 프로세서는 작업 완료까지의 허용 시간 및 하드웨어의 가용 리소스에 기초하여, 기계학습 모델의 추론 연산에 대한 작업부하(workload)를 결정하고, 결정된 작업부하에 기초하여 복 수의 입력 데이터 중에서 적어도 하나의 입력 데이터를 추출할 수 있다. 여기서, 하드웨어의 가용 리소스는 전 체 리소스 중에서, 작업부하를 처리하는데 사용할 수 있는 리소스일 수 있다. 가령, 가용 리소스는 전체 리소 스 중에서 하드웨어로 공급하고 남아 있는 리소스일 수 있다. 또한, 프로세서는 추출된 적어도 하나의 입 력 데이터를 기계학습 모델에 적용할 수 있다. 나아가, 프로세서는 허용 시간 및 하드웨어의 가용 리소스 에 기초하여, 작업부하를 처리하기 위한 하드웨어의 리소스를 결정하고, 결정된 리소스를 하드웨어로 공급할 수 있다. 통신 모듈은 네트워크를 통해 사용자 단말(미도시)과 정보 처리 시스템이 서로 통신하기 위한 구성 또는 기능을 제공할 수 있으며, 정보 처리 시스템이 외부 시스템(일례로 별도의 클라우드 시스템 등)과 통 신하기 위한 구성 또는 기능을 제공할 수 있다. 일례로, 정보 처리 시스템의 프로세서의 제어에 따 라 제공되는 제어 신호, 명령, 데이터 등이 통신 모듈과 네트워크를 거쳐 사용자 단말 및/또는 외부 시스템의 통신 모듈을 통해 사용자 단말 및/또는 외부 시스템으로 전송될 수 있다. 예를 들어, 외부 시스템(예컨대, 증권 거래소 시스템)은 정보 처리 시스템으로부터 주문 데이터 등을 전달받을 수 있다. 또한, 정보 처리 시스템의 입출력 인터페이스는 정보 처리 시스템과 연결되거나 정보 처리 시스 템이 포함할 수 있는 입력 또는 출력을 위한 장치(미도시)와의 인터페이스를 위한 수단일 수 있다. 예를 들면, 입출력 인터페이스는 PCI express 인터페이스, 이더넷(ethernet) 인터페이스 중 적어도 하나를 포함 할 수 있다. 도 2에서는 입출력 인터페이스가 프로세서와 별도로 구성된 요소로서 도시되었으나, 이 에 한정되지 않으며, 입출력 인터페이스가 프로세서에 포함되도록 구성될 수 있다. 정보 처리 시스 템은 도 2의 구성요소들보다 더 많은 구성요소들을 포함할 수 있다. 정보 처리 시스템의 프로세서는 복수의 사용자 단말 및/또는 복수의 외부 시스템으로부터 수신된 정 보 및/또는 데이터를 관리, 처리 및/또는 저장하도록 구성될 수 있다. 여기서, 프로세서는 중앙 처리 장 치(Central Processing Unit)을 포함할 수 있다. 또한, 하드웨어는 정보 처리 시스템에 포함된 프로세서 및/또는 메모리를 포함할 수 있는데, 예를 들어, 프로세서는 전처리 및 후처리를 위한 FPGA로 구현된 적어도 하나의 프로세서 및 기계학습 모델을 위한 ASIC으로 구현된 하나 이상의 전용 가속기 및 리소스 제어를 위한 프로세서를 더 포함할 수 있다. 이 경우, 메모리는 중앙 처리 장치, FPGA 및 전용 가속기의 각각에 의해 접근 가능한 하나 이상의 메모리를 포함할 수 있다. 도 2에서는 정보 처리 시스템에 메모리 , 프로세서 및 통신 모듈이 별도로 구현된 것으로 도시되어 있으나, 이에 한정되지 않고, 메모 리의 적어도 일부 및/또는 통신 모듈의 적어도 일부가 프로세서에 포함되도록 구현될 수 있다. 도 3은 본 개시의 일 실시예에 따른 프로세서의 내부 구성을 나타내는 도면이다. 도 3에서는 프로세서 가 보드(board) 형태로 구현된 것으로 예시하고 있다. 예를 들어, 정보 처리 시스템의 프로세서 는 도 3의 프로세서를 포함할 수 있다. 또한, 중앙 처리 장치(CPU)가 정보 처리 시스템의 프로 세서에 더 포함될 수 있다. 일 실시예에 따르면, 프로세서는 데이터 전/후 처리를 위한 적어도 하나의 프로세서, 기계학습 모델 을 위한 전용 가속기(예를 들어, ASIC으로 구현된 전용 가속기) 및 적어도 하나의 메모리를 포함할 수 있다. 설명의 편의를 위해, 도 3에서는 데이터 전/후 처리를 위한 적어도 하나의 프로세서는 FPGA이고, 기계학습 모델을 위한 전용 가속기는 NPU인 것으로 지칭하여 설명한다. FPGA는 데이터 수신부, 데이터 전처리부 및 주문 생성부를 포함할 수 있다. 또한, NPU는 로딩 모듈, 연산 모듈 및 전송 모듈을 포함할 수 있다. 도 3에서 프로세서의 내부 구성을 기능별로 구분하여 설명하지만, 이는 반드시 물리적으로 구분되는 것을 의미하지 않는다는 것을 밝혀 둔 다. 또한, 도 3에서 도시한 FPGA 및 NPU의 내부 구성은 예시일 뿐이며, 필수 구성만을 도시한 것은 아니다. 일 실시예에 따르면, FPGA의 데이터 수신부는 하나 이상의 타겟 종목에 대하여 하나 이상의 증권 거 래소(예를 들어, 제1 증권 거래소, 제2 증권 거래소 등), 웹 사이트, 애플리케이션 등으로부터 마켓 데이터를 수신할 수 있다. 일 실시예에서, 하나 이상의 증권 거래소는 타겟 증권 거래소를 포함할 수 있다. 여기서, 타 겟 증권 거래소는 주문 데이터를 전송하는 목적지로서, 주문 데이터에 기초하여 증권 매도 또는 매수를 진행할 수 있다. 마켓 데이터는 하나 이상의 증권 거래소에서 거래되는 종목들에 대한 데이터를 포함할 수 있다. 예를 들어, 마 켓 데이터는 증권 거래소에서 거래되는 종목들(중 적어도 일부)의 오더북을 포함할 수 있으며, 추가적으로 마켓 데이터는 타겟 종목에 대한 데이터를 포함할 수 있다. 예를 들어, 마켓 데이터는 타겟 종목의 오더북의 상단, 타겟 종목에 대한 (유효한) 주문 목록, 타겟 종목에 관한 이전 주문에 대한 타겟 증권 거래소의 응답 등을 포함 할 수 있다. 데이터 수신부는 증권 거래소 또는 웹 사이트로부터 마켓 데이터를 수신할 수 있다. 한편, 증권 시장 및/ 또는 타겟 증권의 변동폭이 크면, 마켓 데이터의 수신 횟수가 많아지거나 마켓 데이터의 크기가 커질 수 있고, 증권 시장 및/또는 타겟 증권의 변동폭이 작으면 마켓 데이터의 수신 횟수가 적어지거나 마켓 데이터의 크기가 작아질 수 있다. 예를 들어, 타겟 종목의 가격 변동폭이 큰 경우, 데이터 수신부는 타겟 종목의 오더북을 포함하는 마켓 데이터를 단위 시간 동안에 더욱 많은 횟수로 수신할 수 있다. 반대로, 타겟 종목의 가격 변동 폭이 작은 경우, 데이터 수신부는 타겟 종목의 오더북을 포함하는 마켓 데이터를 단위 시간 동안에 적은 횟수로 수신할 수 있다. 즉, 타겟 종목에 대한 가격 변동폭이 크면, 타겟 종목에 대한 마켓 데이터의 수신 트래픽이 증가될 수 있다. 고빈도 증권 거래에서는 빠른 속도로 데이터를 처리하는 것이 중요하기 때문에, 마켓 데이터는 데이터 전송 속 도가 빠른 사용자 데이터그램 프로토콜(User Datagram Protocol; UDP)을 통해 수신될 수 있다. 다만, 일부 실 시예에서, 필요에 따라(예를 들어, 데이터의 신뢰도를 확보하기 위해) 마켓 데이터 수신에 다른 통신 프로토콜 (예를 들어, TCP/IP)이 사용될 수 있다. 데이터 전처리부는 수신된 하나 이상의 마켓 데이터를 기초로 기계학습 모델에 대한 입력 데이터를 생성할 수 있다. 일 실시예에 따르면, 데이터 전처리부는 마켓 데이터 중 하나 이상의 종목에 대한 하나 이상의 입력 특징을 선별하여 입력 데이터를 구성할 수 있다. 즉, 데이터 전처리부에 의해서 하나 이상의 마켓 데이터가 전처리되고, 전처리된 마켓 데이터에 기초하여 입력 데이터가 구성될 수 있다. 예를 들어, 데이터 전 처리부는 입력 데이터에 포함되는 입력 특징을 추출하거나 선별하기 위한 특징 추출부를 포함할 수 있다. 데이터 전처리부에 의해서 생성된 복수의 입력 데이터는 큐에 저장될 수 있다. 일 실시예에서, 입력 데이터에 포함되는 하나 이상의 종목은 타겟 종목의 시장 상황 변동의 선행 지표가 될 수 있는 종목을 포함할 수 있다. 예를 들어, 주문의 대상이 되는 타겟 종목이 A사 주식(현물) 종목인 경우, A사 주식과 관련된 선물 종목, A사 주식과 관련된 옵션 종목, 다른 거래소에 포함된 A사 관련 종목, A사와 연관된 상품(예: 원유 등)에 대한 선물 종목 등에 대한 데이터가 입력 데이터에 포함될 수 있다. 또한, 일 실시예에서, 입력 데이터에 포함되는 하나 이상의 입력 특징은 타겟 종목의 시장 상황 예측에 의미 있는 정보를 포함할 수 있다. 예를 들어, 입력 특징은 시장 가격(거래 가격), 매수 측 오더북 상단의 가격, 수량, 매도 측 오더북 상단의 가격, 수량, 매수 희망자 수, 매도 희망자 수, 오더북 상단 다음 단계의 매수 호가, 오더북 상단 다음 단계의 매도 호가, 오더북에 포함된 호가의 분산 등 하나 이상의 종목의 오더북으로부터 추출할 수 있는 여러 정보, 이를 가공한 정보 및/또는 정보의 신뢰도 등을 포함할 수 있다. 입력 데이터의 구성은 도 5를 참조 하여 보다 상세히 후술하기로 한다. 데이터 전처리부에서 의해 생성된 입력 데이터는 기계학습 모델을 위한 전용 가속기인 NPU로 전달되 어, 기계학습 모델(예를 들어, DNN)로 입력될 수 있다. 일 실시예에 따르면, NPU는 기계학습 모델의 구동 을 위해 특화된 주문형 반도체(ASIC)로서 구현될 수 있다. NPU는 기계학습 모델에 입력 데이터를 입력하 는 것에 응답으로, 타겟 종목에 대한 예측 데이터를 획득할 수 있다. 예를 들어, NPU는 기계학습 모델에 입력 데이터를 입력하여, 하나 이상의 미래 시점의 타겟 종목의 가격(예를 들어, 시장 가격)을 예측한 출력 데 이터를 도출할 수 있다. 타겟 종목에 대한 주문과 연관된 출력 데이터를 도출하는 기계학습 모델과 관련하여서 는, 도 4 내지 도 6을 참조하여 상세히 후술된다. 도 3에서는, 기계학습 모델을 위한 가속기가 전용 가속기 (NPU)로 도시되어 있으나, 이에 한정되지 않으며, 기계학습 모델을 위한 임의의 가속기(예: GPU 등)가 사용될 수 있다. 주문 생성부는 기계학습 모델로부터 출력된 예측 데이터를 제공받을 수 있고, 예측 데이터를 기초로 타겟 증권 거래소에서의 주문 데이터를 생성할 수 있다. 예를 들어, 주문 생성부는 기계학습 모델로부터 추론 된 미래 시점에서의 타겟 종목의 가격 변동 예측 및/또는 예측 가격을 기초로, 미리 결정된 정책에 따라 타겟 종목에 대한 주문 데이터를 생성할 수 있다. 구체적인 예로, 타겟 종목의 가격이 상승할 것으로 예측된 경우, 주문 생성부는 즉시 새로운 매수 요청 주문을 생성하거나, 기존의 매도 요청 주문의 호가를 정정할 수 있 다. 일 실시예에 따르면, 주문 데이터는 타겟 종목에 대한 주문 종류(신규 주문, 주문 취소, 주문 정정), 매수 또는 매도 여부, 가격(호가), 수량 등에 대한 정보를 포함할 수 있다. 메모리는 복수의 프로세서에 의해서 공유되는 메모리일 수 있다. 예컨대, 메모리는 복수의 NPU(34 0)에 의해 공유되는 메모리일 수 있다. 추가적으로 또는 이와 달리, 메모리는 FPGA와 NPU에 의 해서 공유될 수도 있다. DMA(Direct Memory Access)가 이용되어 복수의 프로세서에 의해서 메모리가 공유 될 수 있다. DMA 기반으로 메모리를 공유하기 위하여, DMA 컨트롤러(미도시)가 보드에 탑재될 수 있다. 일 실시예에 따르면, 미리 결정된 개수의 NPU가 하나의 메모리를 공유할 수 있으며, NPU 개수가 증가하는 경우 증가된 개수에 비례하는 개수의 메모리가 탑재될 수 있다. 메모리는 입력 데이터의 일부 또는 전부를 저장(로딩)할 수 있다. 또한, 메모리는 기계학습 모델의 연산에 이용되는 복수의 파라 미터를 로딩할 수 있다. 복수의 파라미터는 기계학습 모델의 연산 과정에서 교체되거나 갱신될 수 있다. 도 3 에서는 메모리가 NPU 외부에 있는 것으로 예시되어 있으나, 메모리는 NPU와 하나의 칩 형 태로 구현될 수 있다. NPU의 로딩 모듈은 FPGA의 데이터 전처리부로부터 수신한 입력 데이터의 일부 또는 전부를 메모리로 로딩할 수 있다. 예컨대, 로딩 모듈은 기계학습 모델의 연산에 필요한 데이터를 입력 데이 터로부터 획득하고, 획득된 데이터를 메모리에 로딩할 수 있다. 일 실시예에 따르면, 큐에 저장된 입력 데이터의 일부 또는 전부를 메모리로 로딩할 수 있다. 로딩 모듈은 NPU로 할당된 배치 사이즈 (batch size)에 상응하는, 적어도 하나의 입력 데이터를 큐로부터 추출하여 메모리로 로딩할 수 있다. 연산 모듈은 메모리에 로딩된 데이터를 기계학습 모델에 입력함으로써, 타겟 종목에 대한 예측 데이 터를 생성하기 위한 기계학습 모델의 연산을 수행할 수 있다. NPU가 복수인 경우, 각각의 NPU는 기계학습 모델에 포함된 복수의 레이어와 연관된 복수의 처리 영역 으로 구획될 수 있다. 이러한 경우, 연산 모듈은 기계학습 모델의 전체 연산 중에서 일부 연산을 수행할 수 있다. 예를 들어, 기계학습 모델이 복수의 레이어에 가지는 인공신경망 모델을 포함하는 경우, 제1 NPU에 포함된 제1 연산 모듈은 제1 레이어에 대한 연산을 수행하고, 제2 NPU에 포함된 제2 연산 모듈은 제2 레이어에 대한 연산을 수행할 수 있다. 연산 모듈은 NPU에 포함된 연산기를 포함할 수 있다. NPU의 전송 모듈은 연산 모듈로부터 출력된 연산 결과(예컨대, 타겟 종목에 대한 예측 데이터) 를 FPGA의 주문 생성부로 제공할 수 있다. FPGA와 NPU 간에는 소정의 입출력 대역폭을 가지는 통신 선로가 형성되어 있으며, 통신 선로를 이용하여 FPGA에서 NPU로 입력 데이터가 제공되고, NPU에서 FPGA로 예측 데이터가 제공될 수 있다. 이러한 구조의 프로세서에 있어서, 마켓 데이터에 기초하여 주문 데이터를 생성하기까지 지연 시간이 발생 할 수 있다. 마켓 데이터의 수신 트래픽이 증가하거나 기계학습 모델의 연산량이 많아지거나 기계학습 모델에 입력되는 입력 데이터의 배치 사이즈(batch size)가 클수록, 주문 데이터를 생성하기까지의 지연 시간이 증가할 수 있다. 고빈도 증권 거래에 있어서 지연 시간은 치명적인 단점으로 작용할 수 있다. 이에 따라, 고빈도 증 권 거래에 있어서, 지연 시간이 감소하여 빠르게 주문 데이터를 생성되게 하는 것이 중요하다고 할 수 있다. 본 개시에서는 후술하는 바와 같이, 하드웨어에 대한 성능 향상이 필요한 것으로 예측되는 경우, 평소보다 많은 리소스를 하드웨어로 할당하여 하드웨어의 성능을 일시적으로 상승시켜, 보다 빠르게 데이터에 대한 로딩/연산/ 전송이 수행되도록 제어할 수 있다. 여기서, 리소스는 하드웨어에 제공될 수 있는 임의의 자원을 지칭할 수 있 으며, 예를 들어, 전압 또는 클럭 소스 중 적어도 하나를 포함할 수 있으나, 이에 한정되지 않는다. 하드웨어 의 성능을 동적으로 조절하는 방법에 대해서는 도 7를 참조하여 자세하게 후술하기로 한다. 이하, 도 4 내지 도 6을 참조하여, 기계학습 모델의 학습 방법과 기계학습 모델로부터 획득되는 출력 데이터에 대해서 설명한다. 도 4는 본 개시의 일 실시예에 따른 기계학습 모델이 입력 데이터를 기초로 출력 데이터를 출력하는 예시를 나타내는 도면이다. 일 실시예에 따르면, 기계학습 모델은 입력 데이터를 기초로, 타겟 종목 의 주문과 연관된 출력 데이터를 출력할 수 있다. 일 실시예에 따르면, 기계학습 모델은 입력 데이터 를 기초로 미래 특정 시점에서의 타겟 종목의 예측 가격(예를 들어, 시장 가격 또는 중간 가격 등)을 출력 할 수 있다. 다른 실시예에 따르면, 입력 데이터를 기초로 복수의 미래 시점에서의 타겟 종목의 예측 가 격이 출력될 수 있다. 이때, 기계학습 모델을 이용하여 다중 전망 예측(multi horizon forecasting)에 기반하여, 복수의 미래 시점 각각에서의 타겟 종목의 가격이 예측될 수 있다. 일 실시예에 따르면, 기계학습 모델에 입력되는 입력 데이터는 하나 이상의 시점에서의 하나 이상의 종목에 대한 하나 이상의 입력 특징을 포함하는 입력 특징 맵(input feature map)을 포함할 수 있다. 기계학습 모델의 입력 데이터에 관하여는 도 5를 참조하여 상세히 후술된다. 일 실시예에 따르면, 기계학습 모델은 하나 이상의 증권 거래소의 참조 마켓 데이터를 기초로 생성된 참조 입력 데이터를 이용하여 타겟 증권 거래소에서의 증권 주문과 연관된 참조 출력 데이터를 추론하도록 학습될 수 있다. 예를 들어, 기계학습 모델은 제1 증권 거래소의 제1 참조 마켓 데이터 및 제2 증권 거래소의 제2 참조 마켓 데이터를 기초로 생성된 시점 t부터 시점 t+M-1까지의 참조 입력 데이터, 시점 t+1에서의 타겟 종목 의 중간 가격 데이터를 이용하여, 총 M개의 연속된 시점을 포함하는 시간 구간에서의 입력 데이터를 기초로 다 음 시점에서의 타겟 종목의 중간 가격을 추론하도록 지도 학습될 수 있다. 여기서, t와 M은 자연수일 수 있다. 일 실시예에 따르면, 기계학습 모델은 특정 시점의 특정 종목에 대한 마켓 데이터와 정답 데이터(ground truth data)를 포함하는 트레이닝셋을 기초로, 특정 시점보다 미래인 복수의 시점에서의 특정 종목에 대한 예측 데이터를 추론하도록 학습될 수 있다. 여기서, 정답 데이터는 미래인 복수의 시점 각각에서의 특정 종목에 가 격일 수 있다. 기계학습 모델로부터 출력된 특정 미래 시점에서의 특정 종목에 대한 추론 가격과, 정답데이터에 포함된 특정 미래 시점에서의 특정 종목에 대한 가격의 차이(loss)가 산출되고, 산출된 차이가 기계학 습 모델로 반영(피드백)되어, 인공신경망에 포함된 각 노드의 가중치가 조정될 수 있다. 기계학습 모델에 의해 출력된 출력 데이터는 타겟 증권 거래소에서의 증권 주문과 연관된 정보를 포 함할 수 있으며, 프로세서(예컨대, 정보 처리 시스템의 프로세서)는 출력 데이터 및 미리 정해진 정책에 기초하여, 타겟 종목에 대한 주문 데이터를 생성할 수 있다. 여기서, 미리 정해진 정책에는 출력 데이터 에 포함된 예측 결과에 따라, 주식을 매도, 매수, 거래 수량 등이 정의될 수 있다. 일 실시예에 따르면, 본 개 시의 기계학습 모델은 인공신경망 모델(예를 들어, DNN 등)일 수 있다. 인공신경망 모델에 관하여는, 도 6을 참조하여 상세히 후술된다. 도 5는 본 개시의 일 실시예에 따른 기계학습 모델의 입력 데이터의 구성의 예시를 나타내는 도면이다. 정보 처리 시스템은 하나 이상의 거래소로부터 수신된 마켓 데이터를 기초로, 입력 데이터를 생성할 수 있 다. 일 실시예에 따르면, 입력 데이터는 하나 이상의 시점에서의 하나 이상의 종목에 대한 하나 이상의 입력 특징을 포함하는 입력 특징 맵(input feature map)을 포함할 수 있다. 예를 들어, 입력 특징 맵은, 도 5에 도시된 바와 같이 M개(여기서, M은 자연수임)의 시점에서의 K개(여기서, K 는 자연수임)의 종목에 대한 N개(여기서, N은 자연수임)의 입력 특징을 포함할 수 있다. 도시된 예에서, 입력 데이터에 포함된 입력 특징 맵 중 특정 시점(도 5에서, 시점 m)에서의 데이터는, 특정 시점에서의 하나 이 상의 종목(도 5에서, 제1 종목, 제2 종목, 제3 종목 등)에 대한 하나 이상의 입력 특징(도 5에서, 매수 측 오더 북 상단의 가격, 수량, 매도 측 오더북 상단의 가격, 수량 등)을 포함할 수 있다. 또한, 입력 데이터에 포함된 입력 특징 맵 중 특정 입력 특징(도 5에서, n번째 입력 특징)에 대한 데이터는 하나 이상의 시점(도 5에서, 시점 t-M+1부터 시점 t까지)에서의 하나 이상의 종목에 대한 특정 입력 특징을 포함할 수 있다. 일 실 시예에서, 입력 특징 맵은 서로 다른 종목에 대한 하나 이상의 입력 특징이 서로 교차되도록 생성될 수 있다. 일 실시예에 따르면, 입력 데이터에 포함되는 하나 이상의 종목은 주문 대상이 되는 타겟 종목의 시장 상 황의 선행 지표가 되는 종목일 수 있다. 예를 들어, 주문의 대상이 되는 타겟 종목이 A사 주식(현물) 종목인 경우, A사 주식과 관련된 선물 종목, A사 주식과 관련된 옵션 종목, 다른 거래소에 포함된 A사 관련 종목, A사 관련 상품에 대한 선물 종목 중 적어도 하나가 선행이 되는 지표가 되는 종목일 수 있다. 일 실시예에서, 하나 이상의 종목은 타겟 종목을 포함할 수 있다. 즉, 정보 처리 시스템은 타겟 종목에 대한 데이터를 포함한 입력 데이터를 기반으로, 타겟 종목의 미래 시장 상황을 예측할 수 있다. 또한, 일 실시예에서, 각 입력 종목에 대 한 정보는 각 입력 종목과 연관된 코드(symbol)로서 포함될 수 있다. 일 실시예에 따르면, 입력 데이터에 포함되는 하나 이상의 입력 특징은 타겟 종목의 시장 상황 예측에 의 미 있는 정보를 포함할 수 있다. 예를 들어, 입력 특징은 시장 가격(거래 가격), 매수 측 오더북 상단의 가격, 수량, 매도 측 오더북 상단의 가격, 수량, 매수 희망자 수, 매도 희망자 수, 오더북 상단 다음 단계의 매수 호 가, 오더북 상단 다음 단계의 매도 호가, 오더북에 포함된 호가의 분산 등 하나 이상의 종목의 오더북으로부터 추출할 수 있는 여러 정보, 이를 가공한 정보 및/또는 정보의 신뢰도 등을 포함할 수 있다. 일 실시예에서, 이 러한 하나 이상의 입력 특징은 하나 이상의 종목 각각으로부터 추출될 수 있다. 상술한 바와 같이 구성된 입력 데이터는 프로세서(예를 들어, FPGA 등)에 의해 기계학습 모델을 위한 전용 가속기로 전달되어, 기계학습 모델에 입력될 수 있다. 도 6은 본 개시의 일 실시예에 따른 인공신경망 모델을 나타내는 예시도이다. 인공신경망 모델은, 기계학습 모델의 일 예로서, 기계학습(Machine Learning) 기술과 인지과학에서, 생물학적 신경망의 구조에 기초 하여 구현된 통계학적 학습 알고리즘 또는 그 알고리즘을 실행하는 구조이다. 일 실시예에 따르면, 인공신경망 모델은, 생물학적 신경망에서와 같이 시냅스의 결합으로 네트워크를 형성 한 인공 뉴런인 노드(Node)들이 시냅스의 가중치를 반복적으로 조정하여, 특정 입력에 대응한 올바른 출력과 추 론된 출력 사이의 오차가 감소되도록 학습함으로써, 문제 해결 능력을 가지는 기계학습 모델을 나타낼 수 있다. 예를 들어, 인공신경망 모델은 기계학습, 딥러닝 등의 인공지능 학습법에 사용되는 임의의 확률 모델, 뉴 럴 네트워크 모델 등을 포함할 수 있다. 일 실시예에 따르면, 인공신경망 모델은 하나 이상의 증권 거래소의 마켓 데이터를 기초로 생성된 입력 데 이터를 이용하여 미래의 한 시점에서 타겟 증권 거래소에서의 증권 주문과 연관된 데이터(예를 들어, 가격, 가 격 변동 등에 대한 데이터)를 추론하도록 구성된 인공신경망 모델을 포함할 수 있다. 다른 실시예에서 따르면, 인공신경망 모델은 다중 전망 예측(multi horizon forecasting) 모델을 포함하여, 복수의 미래 시점에서타겟 증권 거래소에서의 증권 주문과 연관된 데이터(예: 가격, 가격 변동 등에 대한 데이터)을 예측할 수도 있 다. 인공신경망 모델은 다층의 노드들과 이들 사이의 연결로 구성된 다층 퍼셉트론(MLP: multilayer perceptron)으로 구현된다. 본 실시예에 따른 인공신경망 모델은 MLP를 포함하는 다양한 인공신경망 모델 구조들 중의 하나를 이용하여 구현될 수 있다. 도 6에 도시된 바와 같이, 인공신경망 모델은, 외부로부터 입력 신호 또는 데이터를 수신하는 입력층, 입력 데이터에 대응한 출력 신호 또는 데이터를 출 력하는 출력층, 입력층과 출력층 사이에 위치하며 입력층으로부터 신호를 받아 특성을 추 출하여 출력층으로 전달하는 n개(여기서, n은 양의 정수)의 은닉층(630_1 내지 630_n)으로 구성된다. 여 기서, 출력층은 은닉층(630_1 내지 630_n)으로부터 신호를 받아 외부로 출력한다. 인공신경망 모델의 학습 방법에는, 교사 신호(정답)의 입력에 의해서 문제의 해결에 최적화되도록 학습하 는 지도 학습(Supervised Learning) 방법과, 교사 신호를 필요로 하지 않는 비지도 학습(Unsupervised Learning) 방법이 있다. 일 실시예에서, 인공신경망 모델은 타겟 증권 거래소에서의 증권 주문과 연관된 데이터를 추론하도록 지도 학습 및/또는 비지도 학습될 수 있다. 예를 들어, 인공신경망 모델은 참조 입 력 데이터로부터 하나 이상의 미래 시점에서의 타겟 종목의 참조 가격을 추론하도록 지도 학습될 수 있다. 이렇게 학습된 인공신경망 모델은 정보 처리 시스템의 메모리(미도시)에 저장될 수 있으며, 통신 모듈 및/ 또는 메모리로부터 수신된 데이터의 입력에 응답하여 타겟 증권 거래소에서의 증권 주문과 연관된 데이터를 추 론할 수 있다. 일 실시예에 따르면, 타겟 증권 거래소에서의 증권 주문과 연관된 데이터를 추론하기 위한 인공신경망 모델의 입력 데이터는, 하나 이상의 시점에서의 하나 이상의 종목에 대한 하나 이상의 입력 특징을 포함할 수 있다. 예를 들어, 인공신경망 모델의 입력층에 입력되는 입력 데이터는, 하나 이상의 시점에서의 하나 이상 의 종목에 대한 하나 이상의 입력 특징에 대한 정보를 포함하는 데이터를 하나의 벡터 데이터 요소로 구성한, 벡터가 될 수 있다. 데이터의 입력에 응답하여, 인공신경망 모델의 출력층에서 출력되는 출력 데이 터는 타겟 증권 거래소에서의 증권 주문과 연관된 데이터를 나타내거나 특징화하는 벡터가 될 수 있다. 즉, 인 공신경망 모델의 출력층은 하나 이상의 미래 시점에서 타겟 증권 거래소에서의 증권 주문과 연관된 데이터를 나타내거나 특징화하는 벡터를 출력하도록 구성될 수 있다. 본 개시에 있어서, 인공신경망 모델(60 0)의 출력 데이터는, 이상에서 설명된 유형에 한정되지 않으며, 하나 이상의 미래 시점에서 타겟 증권 거래소에 서의 증권 주문과 연관된 데이터를 나타내는 임의의 정보/데이터를 포함할 수 있다. 이와 같이, 인공신경망 모델의 입력층과 출력층에 복수의 입력 데이터와 대응되는 복수의 출력 데이터가 각각 매칭되고, 입력층, 은닉층(630_1 내지 630_n) 및 출력층에 포함된 노드들 사이의 시냅 스 값이 조정됨으로써, 특정 입력에 대응한 올바른 출력이 추출될 수 있도록 학습될 수 있다. 이러한 학습 과 정을 통해, 인공신경망 모델의 입력 데이터에 숨겨져 있는 특성이 파악될 수 있고, 입력 데이터에 기초하 여 계산된 출력 데이터와 목표 출력 간의 오차가 줄어들도록 인공신경망 모델의 노드들 사이의 시냅스 값 (또는 가중치)이 조정될 수 있다. 이렇게 학습된 인공신경망 모델은 입력된 데이터에 응답하여, 타겟 증 권 거래소에서의 증권 주문과 연관된 데이터를 출력할 수 있다. 도 7을 참조하여, 본 개시의 일 실시예에 따른, 동적으로 하드웨어 성능이 조절되는 정보 처리 시스템의 내부 구성을 설명한다. 설명의 편의를 위해, 도 7을 참조한 설명에서는 데이터 전처리 및 후처리를 수행하는 프로세 서가 FPGA인 것으로 지칭하여 설명한다. 또한, 후술하는 실시예들에서는 기계학습 모델을 위한 전용 가속기가 NPU인 것으로 지칭하여 설명한다. 도 7은 본 개시의 일 실시예에 따른 정보 처리 시스템의 내부 구성을 예시하는 도면이다. 도 7에 예시된 바와 같이, 정보 처리 시스템에는 복수의 리소스(710, 720), 프로세서, NPU 클러스터 및 FPGA를 포함할 수 있다. 예를 들어, 프로세서는 중앙 처리 장치일 수 있다. 또한, 도면에 도시되지 않았으나, 정보 처리 시스템은 메모리를 더 포함할 수 있다. 도 7에서 실선은 리소스가 공급되는 라인을 나타낼 수 있고, 점선은 통신 경로를 나타낼 수 있다. 정보 처리 시스템은 도 2의 정보 처리 시스템(11 0)의 적어도 일부에 포함될 수 있다. 제1 리소스는 복수의 클럭 소스(712-1 내지 712-n, n은 자연수임)를 포함할 수 있다. 복수의 클럭 소스의 각각의 주파수가 서로 상이할 수 있다. 이와 달리, 복수의 클럭 소스의 적어도 일부의 주파수는 서로 동일할 수 있다. 예컨대, 제1 클럭 소스(712-1)는 200MHz일 수 있고, 제2 클럭 소스(712-2)는 1GHz일 수 있다. 다른예로서, 제1 클럭 소스(712-1)와 제2 클럭 소스(712-2) 모두 2GHz일 수 있다. 복수의 클럭 소스(712-1 내지 712-n) 중에서 적어도 하나가 활성화되어 정보 처리 시스템의 하드웨어로 목표 속도의 클럭 신호가 공급될 수 있다. 여기서, 하드웨어는 FPGA, NPU 클러스터, 프로세서, 메모리(미도시) 등을 포함할 수 있다. 도 7에 예시된 바와 같이, 제1 리소스와 하드웨어 간에 복수의 클럭 신호 공급 라인이 형성되어 있 으며, 각각의 클럭 신호 공급 라인을 통해서 목표 속도를 가지는 클럭 신호가 하드웨어로 공급될 수 있다. 복 수의 클럭 소스(712-1 내지 712-n) 중에서 활성화되는 클럭 소스는 프로세서에 의해서 결정될 수 있다. 제2 리소스는 복수의 전압 소스(722-1 내지 722-n, 여기서, n은 자연수임)을 포함할 수 있다. 복수의 전 압 소스의 각각의 전압이 서로 상이할 수 있다. 이와 달리, 복수의 전압 소스의 적어도 일부의 주파수는 서로 동일할 수 있다. 예컨대, 제1 전압 소스(722-1)는 0.7V일 수 있고, 제2 전압 소스(722-2)는 1V일 수 있다. 다 른 예로서, 제1 전압 소스(722-1)와 제2 전압 소스(722-2)는 모두 5V일 수 있다. 적어도 하나의 전압 소스가 활성화되어 정보 처리 시스템의 하드웨어로 목표가 되는 세기의 목표 전압이 공급될 수 있다. 도 7에 예 시된 바와 같이, 제2 리소스와 하드웨어 간에 복수의 전압 공급 라인이 형성되어 있으며, 각각의 전압 공 급 라인을 통해서 목표 전압이 하드웨어로 공급될 수 있다. 하드웨어로 공급되는 전압의 세기는 프로세서(74 0)에 의해서 결정될 수 있다. NPU 클러스터는 복수의 NPU(762-1 내지 762-n)를 포함할 수 있다. 복수의 NPU(762-1 내지 762-n) 중 적 어도 하나는, FPGA에 의해 전처리된 입력 데이터에 기초하여 기계학습 모델의 연산을 수행하고, 기계학습 모델의 출력 데이터를 FPGA로 전달할 수 있다. 복수의 NPU(762-1 내지 762-n) 중 적어도 하나는, 큐에서 입력 데이터를 추출할 수 있다. 예컨대, FPGA는 마켓 데이터를 전처리한 적어도 하나의 입력 데이터를 큐 에 저장하고, 복수의 NPU(762-1 내지 762-n) 중 적어도 하나는 입력 데이터를 큐에서 추출할 수 있다. 일 실시예에 따르면, NPU(762-1 내지 762-n)의 각각은 서로 독립적으로 동작하는 기계학습 모델과 연관될 수 있 다. 예를 들어, NPU_1(762-1)은 제1 기계학습 모델과 연관될 수 있고, NPU_2(762-2)는 제2 기계학습 모델과 연 관될 수 있으며, NPU_3(762-3)은 제3 기계학습 모델과 연관될 수 있다. 일부 실시예에서, NPU(762-1 내지 762-n)는 기계학습 모델에 포함된 복수의 레이어와 연관된 복수의 처리 영역 으로 구획될 수 있다. 예를 들어, 기계학습 모델이 복수의 레이어에 가지는 인공신경망 형태로 구현된 경우, NPU_1(762-1)은 인공신경망의 제1 레이어와 관련된 처리 영역에 대한 연산을 수행하고, NPU_2(762-2)는 인공신 경망의 제2 레이어와 관련된 처리 영역에 대한 연산을 수행할 수 있다. 다른 예로서, 복수의 NPU가 하나의 레 이어와 연관될 수 있다. 예컨대, NPU_1(762-1)과 NPU_2(762-2)가 인공신경망의 제1 레이어와 관련된 처리 영역 에 대한 연산을 수행할 수 있다. 또 다른 예로서, 하나의 NPU가 복수의 레이어와 연관될 수 있다. 미리 결정된 개수의 NPU는 하나의 메모리(미도시)에 공유할 수 있으며, 메모리가 미리 결정된 개수의 NPU에 의 해서 공유될 수 있다. 이때, 메모리에는 기계학습 모델의 연산을 위한 파라미터가 로딩될 수 있다. 예컨대, NPU_1(762-1)에 의해 연산된 인공신경망의 제1 레이어에 대한 출력 결과와 관련된 제1 파라미터가 메모리에 저 장될 수 있고, 메모리에 저장된 제1 파라미터를 기초하여 제2 레이어의 연산이 NPU_2(762-2)에 의해서 수행된 후 연산 결과와 관련된 제2 파라미터가 메모리에 저장될 수 있다. FPGA는 마켓 데이터를 전처리하여 기계학습 모델에 입력되는 적어도 하나의 입력 데이터를 생성한 후, 생 성된 입력 데이터를 NPU 클러스터로 제공할 수 있다. 이때, 생성된 적어도 하나의 입력 데이터는 메모리 에 저장되고, 메모리에 저장된 적어도 하나의 입력 데이터가 NPU 클러스터로 제공될 수 있다. 예컨대, 메 모리는 큐를 포함하고, 적어도 하나의 입력 데이터는 큐에 저장되고, 큐에 저장된 입력 데이터의 우선순위에 기 초하여 적어도 하나의 입력 데이터가 NPU 클러스터로 제공될 수 있다. 일 실시예에 따르면, 프로세서에 의해서 결정된 배치 사이즈(batch size)에 기초하여, 메모리에 저장된 적 어도 하나의 입력 데이터가 추출되고, 추출된 입력 데이터가 NPU(762-1 내지 762-n)로 제공될 수 있다. 또한, FPGA는 NPU 클러스터로부터 수신한 기계학습 모델의 예측 데이터(출력 데이터)에 기초하여, 타겟 종 목에 대한 증권을 매수 또는 매도하는 주문 데이터를 생성하여 타겟 증권 거래소로 전송할 수 있다. NPU 클러스터에 포함된 복수의 NPU(762-1 내지 762-n) 각각은 제1 리소스로부터 클럭 신호를 공급받 고, 제2 리소스로부터 전압을 공급받을 수 있다. NPU 클러스터에 포함된 복수의 NPU(762-1 내지 762-n) 각각은 서로 상이하거나 동일한 세기의 전압 및/또는 동일한 속도의 클럭 신호를 공급받을 수 있다. 더 욱 빠른 클럭 신호를 공급받을수록 NPU(762-1 내지 762-n)의 연산 속도가 빨라질 수 있다. 추가적으로 또는 이 와 달리, 더욱 큰 세기의 전압을 공급받을수록 NPU(762-1 내지 762-n)의 연산 속도가 빨라질 수 있다. 또한,도면에 도시되지 않았으나, 메모리도 제1 리소스로부터 클럭 신호를 공급받고, 제2 리소스로부터 전 압을 공급받을 수 있다. 프로세서는 NPU 클러스터에 포함된 NPU(762-1 내지 762-n) 중에서 적어도 하나의 NPU를 타겟 NPU로 결정하고, 타겟 NPU로 할당되는 작업부하(workload)를 결정할 수 있다. 또한, 프로세서는 작업부하에 기 초한 배치 사이즈를 가지는 적어도 하나의 입력 데이터를 타겟 NPU로 제공하여, 타겟 NPU를 통해서 적어도 하나 의 입력 데이터가 기계학습 모델에 적용되게 제어할 수 있다. 또한, 프로세서는 타겟 NPU로 공급되는 리 소스를 제어할 수 있다. 이러한 제어를 위하여, 프로세서는 스케줄러와 리소스 제어부를 포함 할 수 있다. 스케줄러는 하나 이상의 타겟 종목에 대한 마켓 데이터의 트래픽을 FPGA로부터 수신하고, 수신된 마 켓 데이터의 트래픽에 기초하여, 허용 시간을 동적으로 결정할 수 있다. 일 실시예에 따르면, 마켓 데이터의 트래픽은 단위 시간 동안에 FPGA에 의해서 수신되는 마켓 데이터의 크기 또는 마켓 데이터의 수신 횟수에 기초하여 측정될 수 있다. 또한, 허용 시간은 주문 데이터가 생성되기까지 허용되는 시간이거나, 기계학습 모 델에서 추론 결과가 획득되기까지의 허용 시간일 수 있다. 일 실시예에 따르면, 스케줄러는 마켓 데이터 의 트래픽이 높아지면 허용 시간을 상대적으로 짧게 설정할 수 있고, 마켓 데이터의 트래픽이 낮아지면 허용 시 간을 상대적으로 길게 설정할 수 있다. 즉, 허용 시간은 마켓 트래픽과 반비례할 수 있다. 스케줄러는 각 NPU(762-1 내지 762-N)에 할당된 작업부하를 결정할 수 있다. 일 실시예에 따르면, 스케줄 러는 작업 완료까지의 허용 시간 및 하드웨어의 가용 리소스에 기초하여, 작업 수행 대상이 되는 타겟 NPU 를 결정하고, 타겟 NPU를 통해서 수행되는 기계학습 모델의 추론 연산에 대한 작업부하를 결정할 수 있다. 스 케줄러는 결정된 작업부하에 기초하여, 복수의 입력 데이터 중에서 적어도 하나의 입력 데이터를 선택하고, 선택된 적어도 하나의 입력 데이터와 연관된 정보를 타겟 NPU로 제공할 수 있다. 예컨대, 스케줄러 는 선택된 적어도 하나의 입력 데이터 각각에 대한 인덱스(index)를 타겟 NPU로 전달하고, 타겟 NPU는 인 덱스에 기초하여 메모리로부터 적어도 하나의 입력 데이터를 추출할 수 있다. 여기서, 인덱스는 메모리의 큐에 저장된 입력 데이터의 우선순위와 연관된 식별정보일 수 있다. 다른 예로서, 스케줄러는 선택된 적어도 하나의 입력 데이터를 메모리로부터 추출하고, 추출된 적어도 하나의 입력 데이터를 타겟 NPU로 전송할 수 있다. 이에 따라, 타겟 NPU는 작업부하에 기초로 선택된 적어도 하나의 입력 데이터를 기계학습 모델에 적용 하여, 기계학습 모델을 통한 추론 연산을 수행할 수 있다. 스케줄러에 의해서 작업부하가 할당되는 다양 한 방법은, 도 10 및 도 11을 참조하여 후술하기로 한다. 리소스 제어부는 하드웨어로 공급되는 리소스를 제어하여, 하드웨어의 성능을 동적으로 조절할 수 있다. 리소스 제어부는 허용 시간 및 하드웨어의 가용 리소스에 기초하여, 작업부하를 처리하기 위한 하드웨어의 리소스를 결정하고, 결정된 리소스를 하드웨어로 공급할 수 있다. 이때, 리소스 제어부는 작업부하가 할 당된 타겟 NPU로 결정된 리소스를 공급할 수 있다. 또한, 리소스 제어부는 제1 리소스에 포함된 클럭 소스(712-1 내지 712-n) 중에서 하나 이상이 활성 화되도록 제어할 수 있고, 제2 리소스에 포함된 전압 소스(722-1 내지 722-n) 중에서 하나 이상이 활성화 되도록 제어할 수 있다. 활성화된 하나 이상의 클럭 소스는 하드웨어로 목표 속도의 클럭 신호를 공급할 수 있 고, 활성화된 하나 이상의 전압 소스는 하드웨어로 목표 전압을 공급할 수 있다. 본 개시에서, 클럭 소스의 개 수, 전압 소스의 개수 및 NPU 클러스터의 개수를 나타나기 위하여 모두 n으로 표현하였으나, 각각의 n은 서로 상이하거나 적어도 일부가 동일할 수 있다. 리소스 제어부에 의해서 하드웨어의 리소스가 제어되는 다양 한 방법은 도 9 및 도 12를 참조하여 더욱 자세하게 설명하기로 한다. 도 8은 본 발명의 일 실시예에 따른, 하드웨어 리소스 제어에 이용되는 다양한 참조 테이블(810, 820)을 예시하 는 도면이다. 도 8에 예시된 바와 같이, 복수의 참조 테이블(810, 820)이 정보 처리 시스템의 메모리에 저장될 수 있다. 도 8에 테이블에 기록된 리소스는 클럭 주파수와 전압과 연관될 수 있다. 가령 제1 리소스(RES_#1) 는 제1 클럭 주파수와 제1 전압을 포함할 수 있고, 제2 리소스(RES_#2)는 제1 클럭 주파수와 제2 전압을 포함할 수 있고, 제3 리소스(RES_#3)는 제2 클럭 주파수와 제1 전압을 포함할 수 있다. 여기서, 주파수는 도 7의 클럭 소스(712-1 내지 712-n)에서 공급하는 주파수와 연관되고, 전압은 도 7의 전압 소스(722-1 내지 722-n)에서 공 급하는 전압과 연관될 수 있다. 제1 참조 테이블에는 소비 전력(consumed power), 배치 사이즈(batch size) 및 리소스(resource)가 매핑 된 데이터가 포함될 수 있다. 제1 참조 테이블에 기록된 소비 전력은 배치 사이즈와 리소스에 비례하여 증가할 수 있다. 즉, 배치 사이즈가 클수록, 클럭 주파수가 빠를수록 및/또는 전압이 클수록 소비 전력이 증가할 수 있다. 여기서, 소비 전력은 후술하는 작업부하에 필요한 필요 전력으로 이해될 수 있다. 제2 참조 테이블에는 추론 시간(inference time), 배치 사이즈(batch size) 및 리소스(resource)가 매핑 된 데이터가 포함될 수 있다. 여기서, 추론 시간은 후술하는 작업부하를 처리하는데 발생되는 지연시간으로 이 해될 수 있다. 제2 참조 테이블에 포함된 추론 시간은, 배치 사이즈와 반비례하고 및/또는 리소스 양과 비례할 수 있다. 즉, 배치 사이즈가 작을수록 추론 시간은 짧아지고, 리소스 양이 클수록 추론 시간이 짧아질 수 있다. 도 8에 예시된 적어도 하나의 테이블은, NPU로 작업부하를 할당될 때 이용되며, 더불어 하드웨어로 공급되는 리 소스를 조절할 때 이용될 수 있다. 이하, 도 9 내지 도 12를 참조하여, 고빈도 거래를 위한 작업 스케줄링 방법 및/또는 리소스 조절 방법에 대해 서 설명한다. 도 9 내지 도 12에 도시된 방법은, 본 개시의 목적을 달성하기 위한 일 실시예일 뿐이며, 필요에 따라 일부 단계가 추가되거나 삭제될 수 있음은 물론이다. 또한, 도 9 내지 도 12에 도시된 방법은, 정보 처리 시스템에 포함된 적어도 하나의 프로세서에 의해서 수행될 수 있다. 예컨대, 도 9 내지 도 12에 도시된 방법은, 도 7의 프로세서에 포함된 스케줄러 및/또는 리소스 제어부에 의해서 수행될 수 있다. 설명의 편의를 위해서 도 7의 정보 처리 시스템에 포함된 프로세서에 의해서, 도 9 내지 도 12에 도시된 각 단 계가 수행되는 것으로 설명하기로 한다. 도 9는 본 개시의 일 실시예에 따른, 하드웨어로 최소 리소스가 공급되는 방법을 설명하기 위한 흐름도이 다. 도 9에 도시된 방법은 도 7의 프로세서에 포함된 리소스 제어부에 의해서 수행될 수 있다. 또 한, 도 9와 연관된 방법은 작업 스케줄링이 개시되기 전에 수행될 수 있다. 가령, 작업 스케줄링과 연관 된 준비 트리거 또는 준비 명령이 발생하면, 도 9에 따른 프로세스가 수행될 수 있다. 프로세서는 하나 이상의 NPU의 각각으로 공급중인 리소스를 식별할 수 있다(S910). 여기서, NPU는 기계학습 모 델을 위한 전용 가속기에 대한 하나의 예시일 수 있다. 또한, 리소스는 전압 또는 클럭 신호 중 적어도 하나를 포함할 수 있으며, 프로세서는 각 NPU로 공급되는 전압 세기 또는 클럭 주파수 중 적어도 하나를 포함하는 리소 스를 식별할 수 있다. 그 후, 프로세서는 하나 이상의 NPU의 각각으로 공급 가능한 최소 리소스를 결정할 수 있다(S920). 일 실시예 에 따르면, 프로세서는 각 NPU로 입력되는 적어도 하나의 입력 데이터에 대한 배치 사이즈를 식별하고, 각 NPU 로 공급하고자 하는 복수의 후보 리소스 선택하여 후보 리소스 목록에 등록할 수 있다. 여기서, 후보 리소스는 현재 NPU로 공급되고 있는 리소스보다 적고, 미리 정해진 하한값보다 큰 범위에서 복수 개가 선택될 수 있다. 가령, NPU_1로 공급되는 리소스가 RA_#1인 경우, NPU_1을 대상으로 하는 복수의 후보 리소스는, RA_#1 보다 적 고 하한값보다 많을 수 있다. 또한, 하나 이상의 NPU 각각에 대한 후보 리소스 목록은 서로 상이하거나 동일할 수 있다. 예컨대, NPU_1과 NPU_2에 동일한 리소스가 현재 공급되는 경우, NPU_1을 대상으로 하는 제1 후보 리 소스 목록은 NPU_2를 대상으로 하는 제2 후보 리소스 목록과 동일할 수 있다. 다른 예로서, NPU_1과 NPU_3에 상이한 리소스가 현재 공급되는 경우, NPU_1을 대상으로 하는 제1 후보 리소스 목록은 NPU_3을 대상으로 하는 제3 후보 리소스 목록과 상이할 수 있다. 프로세서는 복수의 NPU 각각으로 입력되는 입력 데이터에 대한 배치 사이즈 및 NPU 각각에 대한 후보 리소스 목 록에 포함된 후보 리소스에 기초하여, 복수의 후보 리소스의 각각에 대한 작업 지연 시간을 산출할 수 있다. 여기서, 작업 지연 시간은 기계학습 모델의 추론 시간일 수 있으며, 도 8의 제2 참조 테이블이 이용되어 산출될 수 있다. 예컨대, 배치 사이즈가 BZ_#1이고 리소스가 RA_#1인 경우, 프로세서는 도 8의 제2 참조 테이 블을 참조하여, 작업 지연 시간이 INT_#1인 것으로 산출할 수 있다. 그 후, 프로세서는 산출된 작업 지연 시간이 허용 시간 미만이 되는 적어도 하나의 후보 리소스 중에서, 가장 적은 리소스를 가지는 후보 리소스를 NPU별로 식별하고, 식별된 NPU별 후보 리소스를 NPU 각각으로 공급되는 최 소 리소스로 결정할 수 있다. 한편, 리소스에는 전압과 클럭 주파수가 포함될 수 있으며, 이 경우 전압에 제1 가중치를 적용하고, 클럭 주파수에 제2 가중치를 적용하여 가중 합산된 값이 가장 적은 후보 리소스를 최소 리 소스로 결정할 수 있다. 그 후, 프로세서는 결정된 NPU별 최소 리소스를 NPU 각각으로 공급되도록, 리소스를 조절할 수 있다(S930). 프 로세서는 도 7에 예시된 제1 리소스 및/또는 제2 리소스를 제어함으로써, 최소 리소스에 해당하는 클 럭 및/또는 전압을 NPU로 공급할 수 있다. 도 10은 본 개시의 일 실시예 따른, 고빈도 거래를 위한 작업 스케줄링 방법을 설명하기 위한 흐름도이다. 도 10에 도시된 각 방법은 도 7의 정보 처리 시스템의 프로세서에 포함된 스케줄러 에 의해서 수행될 수 있다. 프로세서는 고빈도 거래를 위한 복수의 입력 데이터를 획득할 수 있다(S1010). 복수의 입력 데이터는 마켓 데 이터가 전처리된 데이터일 수 있다. 그 후, 프로세서는 작업 완료까지의 허용 시간 및 하드웨어의 가용 리소스에 기초하여, 기계학습 모델의 추론 연산에 대한 작업부하(workload)를 결정할 수 있다(S1020). 여기서, 허용 시간은 주문 데이터가 생성되기까지 의 허용되는 시간으로 동적으로 결정될 수 있다. 일 실시예에 따르면, 프로세서는 하나 이상의 타겟 종목에 대 한 마켓 데이터의 트래픽을 획득하고, 획득된 트래픽에 기초하여 작업 완료까지의 허용 시간을 결정할 수 있다. 허용 시간의 길이 및 가용 리소스의 양에 기초하여, 작업부하의 크기가 결정될 수 있다. 허용 시간 및 하드웨 어의 가용 리소스에 기초하여, 작업부하가 결정되는 방법은 도 11을 참조하여 자세하게 설명하기로 한다. 일 실시예에 따르면, 프로세서는 작업부하를 처리하기 위한 하드웨어의 리소스를 결정하고, 결정된 리소스를 하 드웨어로 공급할 수 있다. 여기서, 하드웨어는 적어도 하나의 NPU, 메모리, FPGA 등을 포함할 수 있다. 프로 세서는 결정된 리소스에 기초하여, 하드웨어로 공급되는 클럭의 주파수 또는 전압 중 적어도 하나를 조절할 수 있다. 일 실시예에 따르면, 하드웨어는 복수의 NPU가 포함될 수 있고, 프로세서는 복수의 NPU 중에서 적어도 하나의 NPU에 결정된 작업부하를 할당할 수 있다. 이 경우, 프로세서는 작업부하가 할당된 적어도 하나의 NPU 를 식별하고, 결정된 리소스에 기초하여 식별된 적어도 하나의 NPU로 공급되는 클럭의 속도 또는 전압 중 적어 도 하나를 조절할 수 있다. 이어서, 프로세서는 결정된 작업부하에 기초하여, 복수의 입력 데이터 중에서 적어도 하나의 입력 데이터를 선 택할 수 있다(S1030). 그 후, 프로세서는 선택된 적어도 하나의 입력 데이터를 기계학습 모델에 적용할 수 있다(S1040). 일 실시예에 따르면, 하드웨어는 기계학습 모델의 연산을 위한 복수의 NPU를 포함할 수 있다. 이 경우, 프로세서는 작업부 하를 담당하는 타겟 NPU를 결정하고, 선택된 적어도 하나의 입력 데이터를 타겟 NPU로 제공할 수 있다. 타겟 NPU는 선택된 적어도 하나의 입력 데이터를 기계학습 모델에 입력하여, 고빈도 거래를 위한 추론 연산을 수행할 수 있다. 도 11은 도 10의 단계 S1020를 더욱 자세하게 설명하기 위한 흐름도이다. 프로세서는 리소스 목록에서 검증 대 상이 되는 타겟 리소스를 선택할 수 있다(S1102). 여기서, 타겟 리소스는 NPU로 할당되는 후보 리소스일 수 있 다. 리소스 목록은 서로 상이한 복수의 리소스를 포함하여 미리 생성될 수 있다. 리소스는 전압 및/또는 클럭 주파수를 포함하고, 리소스 목록에 포함된 복수의 리소스는 서로 상이한 전압 및/또는 클럭 주파수를 포함할 수 있다. 그 후, 프로세서는 배치 사이즈 목록에서 검증 대상이 되는 타겟 배치 사이즈를 선택할 수 있다(S1104). 여기 서, 타겟 배치 사이즈는 NPU로 할당되는 후보 배치 사이즈일 수 있다. 배치 사이즈 목록은 서로 상이한 복수의 배치 사이즈를 포함하여 미리 생성될 수 있다. 리소스 목록과 배치 사이즈 목록은 관리자에 의해서 생성하여 정보 처리 시스템에 저장될 수 있고, 또한 관리자에 의해서 갱신될 수 있다. 후술하는 바와 같이, 검증에 통과 한 리소스와 배치 사이즈를 포함하는 후보 작업부하가 제1 후보 작업 목록에 등록될 수 있다. 이어서, 프로세서는 타겟 리소스와 타겟 배치 사이즈에 기초하여, 필요 전력량과 지연 시간을 산출할 수 있다 (S1106). 일 실시예에 따르면, 프로세서는 도 8의 제1 테이블을 이용하여 필요 전력량(consumed power)을 산출할 수 있고, 도 8의 제2 테이블을 이용하여, 지연 시간(inference time)을 산출할 수 있다. 예컨대, 프로세서는 타겟 리소스와 타겟 배치 사이즈에 상응하는 필요 전력량을 도 8의 제1 테이블에서 획득할 수 있고, 타겟 리소스와 타겟 배치 사이즈에 상응하는 지연 시간을 도 8의 제2 테이블에서 획득할 수 있다. 그 후, 프로세서는 산출된 지연 시간이 허용 시간 미만인지 여부를 판정할 수 있다(S1108). 지연 시간이 허용 시간 이상이라는 판정에 응답하여, 프로세서는 배치 사이즈 목록에서 타겟 배치 사이즈를 재선택하거나, 리소스 목록에서 타겟 리소스를 재선택할 수 있다(S1120). 즉, 프로세서는 타겟 배치 사이즈와 타겟 리소스의 조합에 대한 검증에 실패한 것으로 판정하여, 타겟 배치 사이즈와 타겟 리소스에 대한 새로운 조합이 생성되도록, 배치 사이즈 목록에서 타겟 배치 사이즈를 재선택하거나, 리소스 목록에서 타겟 리소스를 재선택할 수 있다. 타겟 배치 사이즈가 재선택하거나 타겟 리소스가 재선택되면, 단계 S1106 부터의 프로세스가 다시 진행될 수 있다. 반면에, 단계 S1108의 판정 결과, 지연 시간이 허용 시간 미만이면, 프로세서는 산출된 필요 전력량이 가용 전 력량 이하인지 여부를 판정할 수 있다(S1110). 여기서, 가용 전력량은 전체 전력량에서 현재 공급중인 전력량(즉, 이미 사용된 전력량)을 감산하여 측정될 수 있다. 필요 전력량이 가용 전력량을 초과한다는 판정에 응답 하여, 프로세서는 배치 사이즈 목록에서 타겟 배치 사이즈를 재선택하거나, 리소스 목록에서 타겟 리소스를 재 선택할 수 있다(S1120). 즉, 프로세서는 타겟 배치 사이즈와 타겟 리소스의 조합에 대한 검증에 실패한 것으로 판정하여, 타겟 배치 사이즈와 타겟 리소스에 대한 새로운 조합이 생성되도록, 배치 사이즈 목록에서 타겟 배치 사이즈를 재선택하거나, 리소스 목록에서 타겟 리소스를 재선택할 수 있다. 반면에, 단계 S1110의 판정 결과, 필요 전력량이 가용 전력량 이하이면, 프로세서는 타겟 리소스와 타겟 배치 사이즈를 포함하는 후보 작업부하를 생성하고, 생성된 후보 작업부하를 제1 후보 목록에 등록할 수 있다 (S1112). 즉, 검증에 성공한 타겟 리소스와 타겟 배치 사이즈에 조합을 가지는 후보 작업부하가 제1 후보 목록 에 등록될 수 있다. 그 후, 프로세서는 리소스 목록에 포함된 리소스와 배치 사이즈 목록에 포함된 리소스가, 경우의 수에 따라 모 두 조합되어 검증되었는지 여부를 판정할 수 있다(S1114). 즉, 프로세서는 리소스 목록에 포함된 리소스의 개 수와 배치 사이즈 목록에 포함된 배치 사이즈의 개수를 기초로, 조합되는 경우의 수만큼에 해당하는 횟수로 검 증 프로세스가 모두 진행되었는지 여부를 판정할 수 있다. 가령, 리소스 목록에 3개의 리소스가 등록되고, 배 치 사이즈 목록에 3개의 배치 사이즈가 등록된 경우, 프로세서는 총 9개로 조합된 타겟 리소스와 타겟 배치 사 이즈의 각각에 대한 검증 프로세스가 진행되었는지 여부를 판정할 수 있다. 리소스 목록에 포함된 리소스와 배치 사이즈 목록에 포함된 리소스가 경우의 수에 따라 모두 조합되어 검증되지 않았다는 판정에 응답하여, 프로세서는 조합되지 않은 리소스와 배치 사이즈가 조합되도록, 타겟 리소스 또는 타겟 배치 사이즈를 다시 선택할 수 있다(S1120). 그 후, 새롭게 조합된 타겟 리소스와 타겟 배치 사이즈에 기 초하여 단계 S1106 부터의 프로세스가 진행될 수 있다. 상술한 프로세스에 따라, 검증에 통과한 리소스와 배치 사이즈의 조합이 제1 후보 목록에 등록될 수 있다. 검 증이 수행됨에 따라, 제1 후보 목록에 등록된 후보 작업부하의 각각의 지연 시간은 허용 시간 이내이고, 제1 후 보 목록에 등록된 후보 작업부하의 각각의 필요 전력량은 가용 전력량 이내일 수 있다. 한편, 리소스 목록에 포함된 리소스와 배치 사이즈 목록에 포함된 리소스가 경우의 수에 따라 모두 조합되었다 는 판정에 응답하여, 프로세서는 제1 후보 목록에 포함된 후보 작업부하들 중에서, 기계학습 모델의 추론 연산 에 대한 작업부하를 결정할 수 있다(S1116). 결정된 작업부하에 포함된 타겟 리소스는 추론 연산을 위한 하드 웨어(예컨대, NPU)로 할당되는 리소스일 수 있다. 프로세서는 결정된 작업부하에 포함된 타겟 리소스(할당 리 소스)에 기초하여, 작업부하를 담당하는 NPU로 리소스를 공급할 수 있다. 이에 따라, 기계학습 모델의 추론 연 산을 수행하는 NPU는 타겟 리소스만큼의 리소스를 공급받을 수 있다. 일 실시예에 따르면, 프로세서는 성능지표, 리소스 크기, 지연 시간 또는 배치 사이즈 중 적어도 하나에 기초하 여, 기계학습 모델의 추론 연산에 대한 작업부하를 결정할 수 있다. 성능지표의 일 예시로서, PPW(Performance Per Watt)가 이용될 수 있다. 본 개시는 이에 한정되지 않고, PPW 이외에 다양한 지표가 성능지표로서 이용될 수 있다. PPW가 성능지표로서 이용되는 경우, 프로세서는 배치 사이즈, 지연 시간 및 필요 전력량을 기초하여, PPW를 산 출할 수 있다. 아래의 수학식 1이 PPW를 산출하는데 이용될 수 있다. 수학식 1"}
{"patent_id": "10-2023-0000451", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "여기서, 'PPW'는 성능지표의 일 예시이고, 'latency'는 지연 시간이고, 'consumed_power'은 필요 전력량이고, 'batch_size'는 배치 사이즈를 지칭할 수 있다. 프로세서는 후보 작업부하에 포함된 배치 사이즈와 리소스에 기초하여, 지연 시간과 필요 전력량을 산출할 수 있다. 이때, 프로세서는 도 8의 제1 참조 테이블을 이용하여 필요 전력량을 산출하고, 도 2의 제2 참조 테이블을 이용하여 지연 시간을 산출할 수 있다. 또한, 프로세서는 산출된 필요 전력량과 지연 시간 및 배치 사이즈를 수학식 1에 대입하여, 후보 작업부하의 PPW를 성능지표로서 산출할 수 있다. 프로세서는 제1 후보 목록에 포함된 각각의 후보 작업부하의 성능지표가 산출되면 성능지표가 가장 높은 후보 작업부하를 기계학습 모델의 추론 연산에 대한 작업부하로 결정할 수 있다. 다른 예로서, 프로세서는 제1 후보 목록에 등록된 하나 이상의 후보 작업부하의 각각에 포함된 타겟 리소스에 기초하여, 가장 적은 타겟 리소스를 가지는 후보 작업부하를 기계학습 모델의 추론 연산에 대한 작업부하로 결 정할 수 있다. 즉, 프로세서는 가장 적은 리소스를 요구하는 후보 작업부하를 기계학습 모델의 추론 연산에 대 한 작업부하로 결정할 수 있다. 또 다른 예로서, 프로세서는 제1 후보 목록에 등록된 하나 이상의 후보 작업부하의 각각과 관련된 할당 리소스 와 배치 사이즈에 기초하여, 하나 이상의 후보 작업부하의 각각의 지연 시간을 산출한 후, 산출된 지연 시간이 가장 짧은 후보 작업부하를 추론 연산에 대한 작업부하로 결정할 수 있다. 즉, 프로세서는 가장 빨리 추론할 수 있는 후보 작업부하를 추론 연산에 대한 작업부하로 결정할 수 있다. 또 다른 예로서, 프로세서는 제1 후보 목록에 등록된 하나 이상의 후보 작업부하의 각각과 관련된 배치 사이즈 에 기초하여, 가장 큰 배치 사이즈를 가지는 후보 작업부하를 추론 연산에 대한 작업부하로 결정할 수 있다. 즉, 프로세서는 가장 큰 배치 사이즈에 해당하는 입력 데이터를 처리할 수 있는 후보 작업부하를 추론 연산에 대한 작업부하로 결정할 수 있다. 한편, 제1 후보 목록에는 타겟 리소스와 배치 사이즈가 등록되지 않을 수 있다. 즉, 타겟 리소스와 배치 사이 즈의 모든 조합이 검증 프로세스를 통과하지 못하여, 제1 후보 목록에는 어떠한 후보 작업부하가 등록되지 않을 수 있다. 이 경우, 프로세서는 복수의 입력 데이터 중에서 가장 오래된 입력 데이터를 추출하고, 추출된 입력 데이터를 규칙 기반으로 주문 데이터를 생성하는 규칙 기반 주문 모델에 적용할 수 있다. 규칙 기반 주문 모델 에서 적용된 입력 데이터를 메모리의 큐에서 삭제될 수 있다. 여기서, 규칙 기반 주문 모델은 기계학습 모델을 이용하지 않고, 사전에 정의된 규칙(rule)에 기초하여 자동적 으로 주문 데이터를 생성하는 모델일 수 있다. 예를 들어, 규칙 기반 주문 모델은 입력 규칙과 출력 규칙이 일 대일 대응된 규칙 정보(예를 들어, 수식, 모델링 등)를 포함하는 모델일 수 있다. 규칙 기반 주문 모델은 입력 데이터로부터 입력 규칙을 획득하고, 입력 규칙에 상응하는 출력 규칙에 기초하여 주문 데이터를 생성할 수 있 다. 여기서, 입력 규칙은 종목, 호가, 종합주가 지수, 거래량 등을 포함할 수 있고, 출력 규칙은 매도 또는 매 수, 주문량, 가격 등을 포함할 수 있다. 복수의 입력 규칙과 출력 규칙의 쌍은 관리자의 의해서 미리 정의될 수 있다. 한편, 작업부하에 연관된 적어도 하나의 입력 데이터를 입력받아, 추론 연산을 수행중인 복수의 NPU 중에서, 적 어도 하나의 NPU로 잔여 가용 리소스가 추가적으로 공급될 수 있다. 도 12는 본 개시의 일 실시예에 따른, 가용 리소스가 NPU로 추가적으로 공급하는 방법을 설명하는 흐름도 이다. 도 12에 도시된 각 방법은 도 7의 정보 처리 시스템의 프로세서에 포함된 리소스 제어부(74 4)에 의해서 수행될 수 있다. 또한, 도 12에 따른 방법은 도 10에 따른 방법 이후에 진행될 수 있 다. 프로세서는 적어도 하나의 NPU로 공급하고 남은 잔여 가용 리소스를 측정할 수 있다(S1210). 여기서, 잔여 가 용 리소스는 적어도 하나의 NPU로 공급하고 남은 전압 및/또는 클럭 신호를 포함할 수 있다. 이어서, 프로세서는 적어도 하나의 NPU로 공급하고 남은 잔여 가용 전력량을 측정할 수 있다(S1220). 예컨대, 프로세서는 공급할 수 있는 최대 전력량에서 제공중인 전력량을 차감함으로써, 잔여 가용 전력량을 측정할 수 있다. 다음으로, 프로세서는 하나 이상의 NPU의 각각에 대한 후보 리소스를 제2 후보 목록에 등록할 수 있다(S1230). 이때, 프로세서는 추론 연산을 수행중인 NPU를 식별하고, 식별된 적어도 하나의 NPU 각각에 대한 후보 리소스를 제2 후보 목록에 등록할 수 있다. 여기서, 후보 리소스는 NPU로 공급되는 리소스보다 증가된 리소스를 가질 수 있다. 즉, 추론 연산을 더욱 빠르게 처리하기 위하여, 추가적인 리소스가 공급되는 NPU가 선정되어야 하므로, 후보 리소스는 NPU로 공급되고 있는 리소스보다 증가된 리소스를 가질 수 있다. 여기서, 리소스의 증가폭은 미 리 결정될 수 있다. 그 후, 프로세서는 제2 후보 목록에 등록된 적어도 하나의 NPU를 식별하고, NPU 각각에 입력되는 입력 데이터에 대한 배치 사이즈를 식별할 수 있다. 또한, 프로세서는 제2 후보 목록에 포함된 NPU별 후보 리소스 및 NPU별 배치 사이즈에 기초하여, 필요 전력량인 제1 전력량을 NPU별로 산출할 수 있다(S1240). 프로세서는 도 8의 제1참조 테이블을 이용하여 제1 전력량을 산출할 수 있다. 이어서, 프로세서는 NPU별로 공급중인 제2 전력량을 산출할 수 있다(S1250). 예컨대, 프로세서는 도 8의 제1 참조 테이블을 이용하여 제2 전력량을 산출할 수 있다. 다른 예로서, 프로세서는 전압 센서 및/또는 전류 센서를 이용하여 각 NPU로 공급중인 제2 전력량을 측정할 수 있다. 그 후, 프로세서는 제1 전력량에서 제2 전력량을 차감한 제3 전력량을 NPU별로 산출할 수 있다(S1260). 여기서, 제3 전력량은 추가적으로 공급되는 전력량으로 이해될 수 있다. 이어서, 프로세서는 제3 전력량이 잔여 가용 전력량을 초과하는지 여부를 판정하여, 잔여 가용 전력량을 초과하 는 제3 전력량을 가지는 후보 리소스를 제2 후보 목록에서 제거함으로써, 제2 후보 목록을 필터링할 수 있다 (S1270). 그 후, 프로세서는 제2 후보 목록에 포함된 적어도 하나의 후보 리소스와 연관된 NPU 중에서, 잔여 가용 리소스 가 공급되는 타겟 NPU를 결정할 수 있다. 일 실시예에 따르면, 프로세서는 성능지표, 제3 전력량 또는 배치 사 이즈 중 적어도 하나에 기초하여, 제2 후보 목록에 포함된 적어도 하나의 후보 리소스와 연관된 NPU 중에서 하 나의 타겟 NPU를 결정할 수 있다. 예컨대, 프로세서는 제2 후보 목록에 등록된 NPU 각각에 입력되는 적어도 하나의 입력 데이터에 대한 배치 사이 즈를 식별하고, 식별된 NPU별 배치 사이즈 및 제2 후보 목록에 포함된 후보 리소스에 기초하여, NPU별 추가 성 능지표를 산출할 수 있다. 이때, 프로세서는 수학식 1을 이용하여, NPU별 추가 성능지표를 산출할 수 있다. 구체적으로, 프로세서는 각 NPU별로 기 할당된 작업부하에 포함된 배치 사이즈와 리소스에 기초하여, 지연 시간 과 필요 전력량을 산출하고, 산출된 지연 시간과 필요 전력량을 수학식 1에 대입하여 NPU 각각에 대한 현재의 제1 성능지표를 산출할 수 있다. 또한, 프로세서는 식별된 NPU별 배치 사이즈와 제2 후보 목록에 포함된 후보 리소스를 기초하여 지연 시간과 필요 전력량을 산출하고, 산출된 지연 시간과 필요 전력량을 수학식 1에 대입하 여, 잔여 리소스를 공급할 경우에 예상되는 제2 성능지표를 NPU별로 산출할 수 있다. 이어서, 프로세서는 제2 성능지표에서 제1 성능지표를 감산한 추가 성능지표를 NPU별로 산출할 수 있다. 프로세서는 추가 성능지표가 가장 높은 NPU를 잔여 가용 리소스가 공급되는 타겟 NPU로 결정할 수 있다. 다른 예로서, 프로세서는 제2 후보 목록에 포함된 후보 리소스에 기초하여, 제2 후보 목록에 등록된 하나 이상 의 NPU의 각각으로 추가되는 전력량을 산출할 수 있다. 프로세서는 도 8의 제1 참조 테이블을 참조하여, NPU별로 추가되는 전력량을 산출할 수 있다. 구체적으로, 프로세서는 각 NPU별로 기 할당된 작업부하에 포함된 배치 사이즈와 리소스에 기초하여, 제4 전력량을 산출할 수 있다. 여기서, 제4 전력량은 현재 NPU로 공급되는 전력량일 수 있다. 또한, 프로세서는 식별된 NPU별 배치 사이즈와 제2 후보 목록에 포함된 후보 리소스에 기초 하여, 제5 전력량을 NPU별로 산출할 수 있다. 여기서, 제5 전력량은 후보 리소스를 공급하는 경우에 필요한 전 력량일 수 있다. 이어서, 프로세서는 제5 전력량에서 제4 전력량을 감산한 추가 전력량을 NPU별로 산출할 수 있다. 프로세서는 추가 전력량이 가장 적은 NPU를 잔여 가용 리소스가 공급되는 타겟 NPU로 결정할 수 있다. 또 다른 예로서, 프로세서는 제2 후보 목록에 등록된 NPU 각각에 입력되는 적어도 하나의 입력 데이터에 대한 배치 사이즈를 식별하고, 식별된 배치 사이즈 중에서 최대 크기의 배치 사이즈를 가지는 NPU를 잔여 가용 리소 스가 공급되는 타겟 NPU로 결정할 수 있다. 타겟 NPU가 결정된 것에 응답하여, 프로세서는 타겟 NPU로 잔여 가용 리소스의 일부 또는 전부를 공급할 수 있 다(S1290). 일 실시예에서, 프로세서는 타겟 NPU와 연관된 후보 리소스에 기초하여, 타겟 NPU로 공급하는 리소 스의 양을 결정하고, 결정된 리소스의 양만큼의 잔여 가용 리소스를 타겟 NPU로 공급할 수 있다. 예컨대, 프로 세서는 도 7의 제1 리소스 및/또는 제2 리소스를 제어하여 타겟 NPU로 클럭 신호 및/또는 전압을 공 급할 수 있다. 도 13은 본 개시의 일 실시예에 따른 증권 거래 생성과 연관된 임의의 컴퓨팅 장치의 구성도이다. 예를 들어, 컴퓨팅 장치는 정보 처리 시스템 및/또는 사용자 단말(미도시)과 관련될 수 있다. 도시된 바와 같 이, 컴퓨팅 장치는 하나 이상의 프로세서, 버스, 통신 인터페이스, 프로세서에 의해 수행되는 컴퓨터 프로그램을 로드(load)하는 메모리 및 컴퓨터 프로그램을 저장하는 스 토리지를 포함할 수 있다. 다만, 도 13에는 본 개시의 실시예와 관련 있는 구성요소들만이 도시되어 있"}
{"patent_id": "10-2023-0000451", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "다. 따라서, 본 개시가 속한 기술분야의 통상의 기술자라면 도 13에 도시된 구성요소들 외에 다른 범용적인 구 성 요소들이 더 포함될 수 있음을 알 수 있다.프로세서는 컴퓨팅 장치의 각 구성의 전반적인 동작을 제어한다. 프로세서는 CPU(Central Processing Unit), MPU(Micro Processor Unit), MCU(Micro Controller Unit), GPU(Graphic Processing Unit), NPU(Neural Processing Unit) 또는 본 개시의 기술 분야에 잘 알려진 임의의 형태의 프로세서를 포함하여 구성 될 수 있다. 또한, 프로세서는 본 개시의 실시예들에 따른 방법을 실행하기 위한 적어도 하나의 애플리 케이션 또는 프로그램에 대한 연산을 수행할 수 있다. 컴퓨팅 장치는 하나 이상의 프로세서를 구비할 수 있다. 예를 들어, 컴퓨팅 장치는 FPGA로 구현된 프로세서, ASIC으로 구현된 기계학습 모델을 위한 전용 가속기(NPU)를 포함할 수 있다. 메모리는 각종 데이터, 명령 및/또는 정보를 저장할 수 있다. 메모리는 본 개시의 다양한 실시예 들에 따른 방법/동작을 실행하기 위하여 스토리지로부터 하나 이상의 컴퓨터 프로그램을 로드할 수 있다. 메모리는 RAM과 같은 휘발성 메모리로 구현될 수 있으나, 본 개시의 기술적 범위는 이에 한정되지 아니한다. 버스는 컴퓨팅 장치의 구성 요소 간 통신 기능을 제공할 수 있다. 버스는 주소 버스 (Address Bus), 데이터 버스(Data Bus) 및 제어 버스(Control Bus) 등 다양한 형태의 버스로 구현될 수 있다. 통신 인터페이스는 컴퓨팅 장치의 유무선 인터넷 통신을 지원할 수 있다. 또한, 통신 인터페이스 는 인터넷 통신 외의 다양한 통신 방식을 지원할 수도 있다. 이를 위해, 통신 인터페이스는 본 개 시의 기술 분야에 잘 알려진 통신 모듈을 포함하여 구성될 수 있다. 스토리지는 하나 이상의 컴퓨터 프로그램을 비임시적으로 저장할 수 있다. 스토리지는 ROM(Read Only Memory), EPROM(Erasable Programmable ROM), EEPROM(Electrically Erasable Programmable ROM), 플래시 메모리 등과 같은 비휘발성 메모리, 하드 디스크, 착탈형 디스크, 또는 본 개시가 속하는 기술 분 야에서 잘 알려진 임의의 형태의 컴퓨터로 읽을 수 있는 기록 매체를 포함하여 구성될 수 있다. 컴퓨터 프로그램은 메모리에 로드될 때 프로세서로 하여금 본 개시의 다양한 실시예들에 따 른 동작/방법을 수행하도록 하는 하나 이상의 인스트럭션들(instructions)을 포함할 수 있다. 즉, 프로세서 는 하나 이상의 인스트럭션들을 실행함으로써, 본 개시의 다양한 실시예들에 따른 동작/방법들을 수행할 수 있다. 예를 들어, 프로세서는 메모리의 하나 이상의 인스트럭션을 실행함으로써, 고빈도 거래 를 위한 복수의 입력 데이터를 획득하고, 작업 완료까지의 허용 시간 및 하드웨어의 가용 리소스에 기초하여, 기계학습 모델의 추론 연산에 대한 작업부하(workload)를 결정하고, 결정된 작업부하에 기초하여, 복수의 입력 데이터 중에서 적어도 하나의 입력 데이터를 선택하고, 선택된 적어도 하나의 입력 데이터를 기계학습 모델에 적용하도록 구성될 수 있다. 상술한 흐름도 및 상술한 설명은 일 예시일 뿐이며, 일부 실시예에서는 다르게 구현될 수 있다. 예를 들어, 일 부 실시예에서는 각 단계의 순서가 바뀌거나, 일부 단계가 반복 수행되거나, 일부 단계가 생략되거나, 일부 단 계가 추가될 수 있다. 상술한 방법은 컴퓨터에서 실행하기 위해 컴퓨터 판독 가능한 기록 매체에 저장된 컴퓨터 프로그램으로 제공될 수 있다. 매체는 컴퓨터로 실행 가능한 프로그램을 계속 저장하거나, 실행 또는 다운로드를 위해 임시 저장하 는 것일수도 있다. 또한, 매체는 단일 또는 수개 하드웨어가 결합된 형태의 다양한 기록 수단 또는 저장수단일 수 있는데, 어떤 컴퓨터 시스템에 직접 접속되는 매체에 한정되지 않고, 네트워크 상에 분산 존재하는 것일 수 도 있다. 매체의 예시로는, 하드 디스크, 플로피 디스크 및 자기 테이프와 같은 자기 매체, CD-ROM 및 DVD 와 같은 광기록 매체, 플롭티컬 디스크(floptical disk)와 같은 자기-광 매체(magneto optical medium), 및 ROM, RAM, 플래시 메모리 등을 포함하여 프로그램 명령어가 저장되도록 구성된 것이 있을 수 있다. 또한, 다른 매체 의 예시로, 애플리케이션을 유통하는 앱 스토어나 기타 다양한 소프트웨어를 공급 내지 유통하는 사이트, 서버 등에서 관리하는 기록매체 내지 저장매체도 들 수 있다. 본 개시의 방법, 동작 또는 기법들은 다양한 수단에 의해 구현될 수도 있다. 예를 들어, 이러한 기법들은 하드 웨어, 펌웨어, 소프트웨어, 또는 이들의 조합으로 구현될 수도 있다. 본원의 개시와 연계하여 설명된 다양한 예시적인 논리적 블록들, 모듈들, 회로들, 및 알고리즘 단계들은 전자 하드웨어, 컴퓨터 소프트웨어, 또는 양자 의 조합들로 구현될 수도 있음을 통상의 기술자들은 이해할 것이다. 하드웨어 및 소프트웨어의 이러한 상호 대 체를 명확하게 설명하기 위해, 다양한 예시적인 구성요소들, 블록들, 모듈들, 회로들, 및 단계들이 그들의 기능 적 관점에서 일반적으로 위에서 설명되었다. 그러한 기능이 하드웨어로서 구현되는지 또는 소프트웨어로서 구 현되는 지의 여부는, 특정 애플리케이션 및 전체 시스템에 부과되는 설계 요구사항들에 따라 달라진다. 통상의기술자들은 각각의 특정 애플리케이션을 위해 다양한 방식들로 설명된 기능을 구현할 수도 있으나, 그러한 구현 들은 본 개시의 범위로부터 벗어나게 하는 것으로 해석되어서는 안된다. 하드웨어 구현에서, 기법들을 수행하는 데 이용되는 프로세싱 유닛들은, 하나 이상의 ASIC들, DSP들, 디지털 신 호 프로세싱 디바이스들(digital signal processing devices; DSPD들), 프로그램가능 논리 디바이스들 (programmable logic devices; PLD들), 필드 프로그램가능 게이트 어레이들(field programmable gate arrays; FPGA들), 프로세서들, 제어기들, 마이크로제어기들, 마이크로프로세서들, 전자 디바이스들, 본 개시에 설명된 기능들을 수행하도록 설계된 다른 전자 유닛들, 컴퓨터, 또는 이들의 조합 내에서 구현될 수도 있다. 따라서, 본 개시와 연계하여 설명된 다양한 예시적인 논리 블록들, 모듈들, 및 회로들은 범용 프로세서, DSP, ASIC, FPGA나 다른 프로그램 가능 논리 디바이스, 이산 게이트나 트랜지스터 로직, 이산 하드웨어 컴포넌트들, 또는 본원에 설명된 기능들을 수행하도록 설계된 것들의 임의의 조합으로 구현되거나 수행될 수도 있다. 범용 프로세서는 마이크로프로세서일 수도 있지만, 대안으로, 프로세서는 임의의 종래의 프로세서, 제어기, 마이크로 제어기, 또는 상태 머신일 수도 있다. 프로세서는 또한, 컴퓨팅 디바이스들의 조합, 예를 들면, DSP와 마이크 로프로세서, 복수의 마이크로프로세서들, DSP 코어와 연계한 하나 이상의 마이크로프로세서들, 또는 임의의 다 른 구성의 조합으로서 구현될 수도 있다. 펌웨어 및/또는 소프트웨어 구현에 있어서, 기법들은 랜덤 액세스 메모리(random access memory; RAM), 판독 전 용 메모리(read-only memory; ROM), 비휘발성 RAM(non-volatile random access memory; NVRAM), PROM(programmable read-only memory), EPROM(erasable programmable read-only memory), EEPROM(electrically erasable PROM), 플래시 메모리, 컴팩트 디스크(compact disc; CD), 자기 또는 광학 데이 터 스토리지 디바이스 등과 같은 컴퓨터 판독가능 매체 상에 저장된 명령들로서 구현될 수도 있다. 명령들은 하나 이상의 프로세서들에 의해 실행 가능할 수도 있고, 프로세서(들)로 하여금 본 개시에 설명된 기능의 특정 양태들을 수행하게 할 수도 있다. 소프트웨어로 구현되는 경우, 상술된 기법들은 하나 이상의 명령들 또는 코드로서 컴퓨터 판독 가능한 매체 상 에 저장되거나 또는 컴퓨터 판독 가능한 매체를 통해 전송될 수도 있다. 컴퓨터 판독가능 매체들은 한 장소에 서 다른 장소로 컴퓨터 프로그램의 전송을 용이하게 하는 임의의 매체를 포함하여 컴퓨터 저장 매체들 및 통신 매체들 양자를 포함한다. 저장 매체들은 컴퓨터에 의해 액세스될 수 있는 임의의 이용 가능한 매체들일 수도 있다. 비제한적인 예로서, 이러한 컴퓨터 판독가능 매체는 RAM, ROM, EEPROM, CD-ROM 또는 다른 광학 디스크 스토리지, 자기 디스크 스토리지 또는 다른 자기 스토리지 디바이스들, 또는 소망의 프로그램 코드를 명령들 또 는 데이터 구조들의 형태로 이송 또는 저장하기 위해 사용될 수 있으며 컴퓨터에 의해 액세스될 수 있는 임의의 다른 매체를 포함할 수 있다. 또한, 임의의 접속이 컴퓨터 판독가능 매체로 적절히 칭해진다. 예를 들어, 소프트웨어가 동축 케이블, 광섬유 케이블, 연선, 디지털 가입자 회선 (DSL), 또는 적외선, 무선, 및 마이크로파와 같은 무선 기술들을 사용하여 웹사이트, 서버, 또는 다른 원격 소스로부터 전송되면, 동축 케 이블, 광섬유 케이블, 연선, 디지털 가입자 회선, 또는 적외선, 무선, 및 마이크로파와 같은 무선 기술들은 매 체의 정의 내에 포함된다. 본원에서 사용된 디스크(disk) 와 디스크(disc)는, CD, 레이저 디스크, 광 디스크, DVD(digital versatile disc), 플로피디스크, 및 블루레이 디스크를 포함하며, 여기서 디스크들(disks)은 보통 자기적으로 데이터를 재생하고, 반면 디스크들(discs) 은 레이저를 이용하여 광학적으로 데이터를 재생한다. 위의 조합들도 컴퓨터 판독가능 매체들의 범위 내에 포함되어야 한다. 소프트웨어 모듈은, RAM 메모리, 플래시 메모리, ROM 메모리, EPROM 메모리, EEPROM 메모리, 레지스터들, 하드 디스크, 이동식 디스크, CD-ROM, 또는 공지된 임의의 다른 형태의 저장 매체 내에 상주할 수도 있다. 예시적인 저장 매체는, 프로세가 저장 매체로부터 정보를 판독하거나 저장 매체에 정보를 기록할 수 있도록, 프로세서에 연결될 수 있다. 대안으로, 저장 매체는 프로세서에 통합될 수도 있다. 프로세서와 저장 매체는 ASIC 내에 존 재할 수도 있다. ASIC은 유저 단말 내에 존재할 수도 있다. 대안으로, 프로세서와 저장 매체는 유저 단말에서 개별 구성요소들로서 존재할 수도 있다. 이상 설명된 실시예들이 하나 이상의 독립형 컴퓨터 시스템에서 현재 개시된 주제의 양태들을 활용하는 것으로 기술되었으나, 본 개시는 이에 한정되지 않고, 네트워크나 분산 컴퓨팅 환경과 같은 임의의 컴퓨팅 환경과 연계 하여 구현될 수도 있다. 또 나아가, 본 개시에서 주제의 양상들은 복수의 프로세싱 칩들이나 장치들에서 구현 될 수도 있고, 스토리지는 복수의 장치들에 걸쳐 유사하게 영향을 받게 될 수도 있다. 이러한 장치들은 PC들,"}
{"patent_id": "10-2023-0000451", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "네트워크 서버들, 및 휴대용 장치들을 포함할 수도 있다.본 명세서에서는 본 개시가 일부 실시예들과 관련하여 설명되었지만, 본 개시의 발명이 속하는 기술분야의 통상 의 기술자가 이해할 수 있는 본 개시의 범위를 벗어나지 않는 범위에서 다양한 변형 및 변경이 이루어질 수 있 다. 또한, 그러한 변형 및 변경은 본 명세서에 첨부된 특허청구의 범위 내에 속하는 것으로 생각되어야 한다."}
{"patent_id": "10-2023-0000451", "section": "도면", "subsection": "도면설명", "item": 1, "content": "본 개시의 실시예들은, 이하 설명하는 첨부 도면들을 참조하여 설명될 것이며, 여기서 유사한 참조 번호는 유사 한 요소들을 나타내지만, 이에 한정되지는 않는다. 도 1은 본 개시의 일 실시예에 따른 정보 처리 시스템의 작동 예시를 나타내는 개요도이다. 도 2는 본 개시의 일 실시예에 따른 정보 처리 시스템의 내부 구성을 나타내는 블록도이다. 도 3은 본 개시의 일 실시예에 따른 프로세서의 내부 구성을 나타내는 도면이다. 도 4는 본 개시의 일 실시예에 따른 기계학습 모델이 입력 데이터를 기초로 출력 데이터를 출력하는 예시를 나 타내는 도면이다. 도 5는 본 개시의 일 실시예에 따른 기계학습 모델의 입력 데이터의 구성의 예시를 나타내는 도면이다.도 6은 본 개시의 일 실시예에 따른 인공신경망 모델을 나타내는 예시도이다. 도 7은 본 개시의 일 실시예에 따른 정보 처리 시스템의 내부 구성을 예시하는 도면이다. 도 8은 본 발명의 일 실시예에 따른, 하드웨어 리소스 제어에 이용되는 다양한 참조 테이블을 예시하는 도면이 다. 도 9는 본 개시의 일 실시예에 따른, 하드웨어로 최소 리소스가 공급되는 방법을 설명하기 위한 흐름도이다. 도 10은 본 개시의 일 실시예 따른, 고빈도 거래를 위한 작업 스케줄링 방법을 설명하기 위한 흐름도이다. 도 11은 도 10의 단계 S1020를 더욱 자세하게 설명하기 위한 흐름도이다. 도 12는 본 개시의 일 실시예에 따른, 가용 리소스가 NPU로 추가적으로 공급하는 방법을 설명하는 흐름도이다. 도 13은 본 개시의 일 실시예에 따른, 증권 거래 생성과 연관된 임의의 컴퓨팅 장치의 구성도이다."}
