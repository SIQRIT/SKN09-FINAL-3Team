{"patent_id": "10-2022-0073493", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0173251", "출원번호": "10-2022-0073493", "발명의 명칭": "최소 위험 조작을 수행하기 위한 차량 및 상기 차량의 작동 방법", "출원인": "현대자동차주식회사", "발명자": "장찬종"}}
{"patent_id": "10-2022-0073493", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "차량의 작동 방법에 있어서,차량의 상태를 모니터링하는 동작;상기 차량의 상태를 기초로 긴급 정차 유형을 결정하는 동작;상기 결정된 긴급 정차 유형을 실행하는 동작을 포함하는, 차량의 작동 방법."}
{"patent_id": "10-2022-0073493", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,최소 위험 조작 기능의 실행 요청을 획득하는 동작을 더 포함하고,상기 요청을 획득하는 경우에만 상기 모니터링 동작, 상기 긴급 정차 유형을 결정하고 그에 따라 긴급 정차 유형을 실행하는 동작을 수행하는, 차량의 작동 방법."}
{"patent_id": "10-2022-0073493", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 차량이 긴급 정차 유형의 실행을 완료하고 최소 위험 상태에 도달하였는 지를 판단하는 동작; 및상기 차량이 최소 위험 상태에 도달한 경우 자율주행 시스템을 오프(off)하는 동작을 더 포함하는, 차량의 작동 방법."}
{"patent_id": "10-2022-0073493", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,상기 차량의 상태를 모니터링하는 동작은,상기 차량의 구성요소들의 상태 정보를 획득하는 동작; 및상기 차량의 주변환경 정보를 획득하는 동작을 포함하는, 차량의 작동 방법."}
{"patent_id": "10-2022-0073493", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서,상기 긴급 정차 유형은, 직진 주행만 하면서 정차하는 직진 정차;공개특허 10-2023-0173251-3- 차선을 따라 주행하면서 정차하는 차선내 정차; 갓길을 인식하고 갓길에 걸쳐서 정차하는 반갓길 정차; 및 갓길을 인식하고 완전히 갓길로 들어가서 정차하는 완전 갓길 정차를 포함하는, 차량의 작동 방법."}
{"patent_id": "10-2022-0073493", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5항에 있어서,상기 차량의 상태를 기초로 긴급 정차 유형을 결정하는 동작은,상기 차량의 브레이크 제어만 가능한 경우에는 상기 직진 정차로 결정하는 동작;상기 차량의 브레이크 제어 및 조향 제어가 가능한 경우에는 상기 차선내 정차로 결정하는 동작; 및상기 차량의 브레이크 제어 및 조향 제어가 가능하고, 차선 변경 및 갓길 검출이 가능한 경우에는 상기 반갓길정차 또는 상기 완전 갓길 정차 중의 하나로 결정하는 동작을 포함하는, 차량의 작동 방법."}
{"patent_id": "10-2022-0073493", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제5항에 있어서,상기 차량의 상태를 기초로 긴급 정차 유형을 결정하는 동작은,상기 차량의 구성요소들의 상태 정보 및 상기 차량의 주변환경 정보의 적어도 일부가 포함된 이미지를 생성하는동작; 및생성된 상기 이미지를 입력으로 하는 인공지능을 사용하여 긴급 정차 유형을 결정하는 동작을 포함하는, 차량의 작동 방법."}
{"patent_id": "10-2022-0073493", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서,상기 이미지를 생성하는 동작은,상기 차량의 주행 기능 정보를 포함하는 제1 이미지를 생성하는 동작;상기 차량의 검출 기능 정보를 포함하는 제2 이미지를 생성하는 동작;상기 차량의 주변 환경 정보를 포함하는 제3 이미지를 생성하는 동작; 및생성된 상기 제1 이미지 내지 제3 이미지를 합성하여 단순 조감도 이미지를 생성하는 동작을 포함하는, 차량의 작동 방법."}
{"patent_id": "10-2022-0073493", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서,상기 차량의 주행 기능 정보를 포함하는 제1 이미지를 생성하는 동작은,상기 차량의 조향각 제어가 불가능한 경우, 상기 차량의 현재의 조향각에 기초하여 운전가능 영역과 운전 불가능 영역을 서로 상이한 색깔로 표시하는 상기 제1 이미지를 생성하는 동작을 포함하는, 공개특허 10-2023-0173251-4-차량의 작동 방법."}
{"patent_id": "10-2022-0073493", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제8항에 있어서,상기 차량의 검출 기능 정보를 포함하는 제2 이미지를 생성하는 동작은,차선과 갓길을 서로 상이한 색깔로 표시하는 상기 제2 이미지를 생성하는 동작을 포함하는, 차량의 작동 방법."}
{"patent_id": "10-2022-0073493", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제8항에 있어서,상기 차량의 검출 기능 정보를 포함하는 제2 이미지를 생성하는 동작은,차선 검출이 실패한 경우, 정상적으로 인식되던 과거의 차선 정보에 기초하여 현재의 차선 정보를 예측하고, 정상적으로 검출된 차선 정보와 예측한 차선 정보를 서로 구분할 수 있는 방법으로 표시하는 상기 제1 이미지를생성하는 동작을 포함하는, 차량의 작동 방법."}
{"patent_id": "10-2022-0073493", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제8항에 있어서,상기 이미지를 생성하는 동작은,주변 차량과의 충돌 위험도를 계산하는 동작; 및상기 충돌 위험도를 내포하도록 상기 단순 조감도 이미지에 포함된 상기 주변 차량의 명도를 상기 충돌 위험도에 따라 변경하여 표시하는 동작을 더 포함하는, 차량의 작동 방법."}
{"patent_id": "10-2022-0073493", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "차량에 있어서,상기 차량의 구성 요소의 상태 정보 및 상기 차량의 주변 환경 정보를 검출하는 센서;상기 센서로부터 오는 정보에 기초하여 상기 차량의 자율주행을 제어하는 프로세서; 및상기 프로세서의 제어에 따라 상기 차량의 작동을 제어하는 컨트롤러를 포함하고,상기 프로세서는, 상기 센서로부터 오는 정보에 기초하여 상기 차량의 상태를 모니터링하고, 상기 차량의 상태를 기초로 긴급 정차 유형을 결정하고, 상기 컨트롤러를 제어하여 상기 결정된 긴급 정차 유형을 실행하는, 차량.공개특허 10-2023-0173251-5-청구항 14 제13항에 있어서,상기 프로세서는, 추가적으로 최소 위험 조작 기능의 실행 요청을 획득하고, 상기 요청을 획득하는 경우에만 상기 긴급 정차 유형을 결정하고 그에 따라 긴급 정차 유형을 실행하는, 차량."}
{"patent_id": "10-2022-0073493", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제13항에 있어서,상기 프로세서는, 추가적으로 상기 차량이 최소 위험 상태에 도달하면 상기 실행된 긴급 정차 유형을 완료하고, 자율주행 시스템을 오프(off)시키는, 차량."}
{"patent_id": "10-2022-0073493", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제13항에 있어서,상기 프로세서는, 상기 차량의 상태를 모니터링하여 상기 차량의 주행 기능 관련 고장 정보를 획득하고, 상기 차량의 검출 기능 관련 고장 정보를 획득하고, 상기 차량의 주변환경 정보를 획득하는, 차량."}
{"patent_id": "10-2022-0073493", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제16항에 있어서,상기 긴급 정차 유형은, 직진 주행만 하면서 정차하는 직진 정차; 차선을 따라 주행하면서 정차하는 차선내 정차; 갓길을 인식하고 갓길에 걸쳐서 정차하는 반갓길 정차; 갓길을 인식하고 완전히 갓길로 들어가서 정차하는 완전 갓길 정차를 포함하는, 차량."}
{"patent_id": "10-2022-0073493", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제17항에 있어서,상기 프로세서는, 상기 긴급 정차 유형으로, 상기 차량의 브레이크 제어만 가능한 경우에는 상기 직진 정차를 결정하고,공개특허 10-2023-0173251-6- 상기 차량의 브레이크 제어 및 조향 제어가 가능한 경우에는 상기 차선내 정차를 결정하고, 상기 차량의 브레이크 제어 및 조향 제어가 가능하고, 차선 변경 및 갓길 검출이 가능한 경우에는 상기 반갓길 정차 또는 상기 완전 갓길 정차 중의 하나를 결정하는, 차량."}
{"patent_id": "10-2022-0073493", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제15항에 있어서,상기 프로세서는, 상기 차량의 구성요소들의 상태 정보 및 상기 차량의 주변환경 정보의 적어도 일부가 포함된 이미지를 생성하고, 생성된 상기 이미지를 입력으로 하는 인공지능을 사용하여 긴급 정차 유형을 결정하는, 차량."}
{"patent_id": "10-2022-0073493", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제19항에 있어서,상기 프로세서는, 상기 차량의 주행 기능 정보를 포함하는 제1 이미지를 생성하고, 상기 차량의 검출 기능 정보를 포함하는 제2 이미지를 생성하고, 상기 차량의 주변 환경 정보를 포함하는 제3 이미지를 생성하고, 생성된 상기 제1 이미지 내지 제3 이미지를 합성하여 단순 조감도 이미지를 생성하는, 차량."}
{"patent_id": "10-2022-0073493", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_21", "content": "제20항에 있어서,상기 프로세서는, 상기 제1 이미지 생성 시에, 상기 차량의 조향각 제어가 불가능한 경우, 상기 차량의 현재의 조향각에 기초하여 운전가능 영역과 운전 불가능 영역을 서로 상이한 색깔로 표시하는, 차량."}
{"patent_id": "10-2022-0073493", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_22", "content": "제20항에 있어서,상기 프로세서는, 상기 제2 이미지 생성 시에, 차선과 갓길을 서로 상이한 색깔로 표시하는, 차량.공개특허 10-2023-0173251-7-청구항 23 제20항에 있어서,상기 프로세서는, 상기 제2 이미지 생성 시에, 차선 검출이 실패한 경우, 정상적으로 인식되던 과거의 차선 정보에 기초하여현재의 차선 정보를 예측하고, 정상적으로 검출된 차선 정보와 예측한 차선 정보를 서로 구분할 수 있는 방법으로 표시하는 상기 제1 이미지를 생성하는 동작을 포함하는, 차량."}
{"patent_id": "10-2022-0073493", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_24", "content": "제20항에 있어서,상기 프로세서는, 주변 차량과의 충돌 위험도를 계산하고, 상기 충돌 위험도를 내포하도록 상기 단순 조감도 이미지에 포함된 상기 주변 차량의 명도를 상기 충돌 위험도에 따라 변경하여 표시하는, 차량."}
{"patent_id": "10-2022-0073493", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 개시는 예측하지 못한 사고 또는 이벤트가 발생한 경우 주변 차량과의 충돌 위험을 최소화하기 위한 긴급 정 차 유형을 판단하고, 그에 따라 최소 위험 조작을 수행하기 위한 차량 및 상기 차량의 작동 방법에 관한 것으로, 차량의 작동 방법은 차량의 상태를 모니터링하는 동작, 상기 차량의 상태를 기초로 긴급 정차 유형을 결정하는 동작, 상기 결정된 긴급 정차 유형을 실행하는 동작을 포함할 수 있다."}
{"patent_id": "10-2022-0073493", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "다양한 실시 예는 고속도로에서 주행 시 예측하지 못한 사고 또는 이벤트가 발생한 경우 주변 차량과의 충돌 위 험을 최소화하기 위한 긴급 정차 유형을 판단하고, 그에 따라 최소 위험 조작을 수행하기 위한 차량 및 상기 차 량의 작동 방법에 관한 것이다."}
{"patent_id": "10-2022-0073493", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "최근 운전자의 운전을 돕기 위하여 첨단 운전자 보조 시스템(Advanced Driver Assistance Systems; ADAS)이 개 발되고 있다. ADAS는 복수의 하부 기술 분류를 갖고 있으며, 운전자에게 상당한 편의를 제공할 수 있다. 이러한 ADAS는 자율 주행이라고 불리기도 하고, ADS(Automated Driving System)이라고 불리기도 한다. 한편, 차량이 자율 주행을 수행하는 경우, 예측하지 못한 사고 또는 이벤트가 발생할 수 있고, 이러한 이벤트에 대해서는 주변 차량과의 충돌 위험을 최소화하는 적절한 대처가 수행되지 않는 경우 차량은 위험한 상태에 놓일 수 있다."}
{"patent_id": "10-2022-0073493", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 개시의 다양한 실시 예는 차량이 자율 주행 중에 발생하는 이벤트에 대해 주변 차량과의 충돌 위험을 최소화 하기 위한 긴급 정차 유형을 판단하는 방법을 제공할 수 있다. 본 문서에서 이루고자 하는 기술적 과제는 이상에서 언급한 기술적 과제로 제한되지 않으며, 언급되지 않은 또"}
{"patent_id": "10-2022-0073493", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 2, "content": "다른 기술적 과제들은 아래의 기재로부터 본 발명이 속하는 기술분야에서 통상의 지식을 가진 자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2022-0073493", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 다양한 실시 예들에 따르면, 차량의 작동 방법은 차량의 상태를 모니터링하는 동작, 상기 차량의 상 태를 기초로 긴급 정차 유형을 결정하는 동작, 상기 결정된 긴급 정차 유형을 실행하는 동작을 포함할 수 있다. 본 발명의 다양한 실시 예들에 따르면, 차량은 상기 차량의 구성 요소의 상태 정보 및 상기 차량의 주변 환경 정보를 검출하는 센서, 상기 센서로부터 오는 정보에 기초하여 상기 차량의 자율주행을 제어하는 프로세서 및 상기 프로세서의 제어에 따라 상기 차량의 작동을 제어하는 컨트롤러를 포함할 수 있다. 상기 프로세서는 상기 센서로부터 오는 정보에 기초하여 상기 차량의 상태를 모니터링하고, 상기 차량의 상태를 기초로 긴급 정차 유형을 결정하고, 상기 컨트롤러를 제어하여 상기 결정된 긴급 정차 유형을 실행하는 포함할 수 있다. 본 발명의 다양한 실시 예들에 따르면, 차량의 작동 방법은 최소 위험 조작 기능의 실행 요청을 획득하는 동작 을 더 포함하고, 상기 요청을 획득하는 경우에만 상기 모니터링 동작, 상기 긴급 정차 유형을 결정하고 그에 따 라 긴급 정차 유형을 실행하는 동작을 수행할 수 있다. 본 발명의 다양한 실시 예들에 따르면, 차량의 작동 방법은 상기 차량이 긴급 정차 유형의 실행을 완료하고 최 소 위험 상태에 도달하였는 지를 판단하는 동작 및 상기 차량이 최소 위험 상태에 도달한 경우 자율주행 시스템 을 오프(off)하는 동작을 더 포함할 수 있다. 본 발명의 다양한 실시 예들에 따르면, 상기 차량의 상태를 모니터링하는 동작은 상기 차량의 구성요소들의 상 태 정보를 획득하는 동작 및 상기 차량의 주변환경 정보를 획득하는 동작을 포함할 수 있다. 본 발명의 다양한 실시 예들에 따르면, 상기 긴급 정차 유형은 직진 주행만 하면서 정차하는 직진 정차, 차선을 따라 주행하면서 정차하는 차선내 정차, 갓길을 인식하고 갓길에 걸쳐서 정차하는 반갓길 정차, 및 갓길 을 인식하고 완전히 갓길로 들어가서 정차하는 완전 갓길 정차를 포함할 수 있다. 본 발명의 다양한 실시 예들에 따르면, 상기 차량의 상태를 기초로 긴급 정차 유형을 결정하는 동작은 상기 차 량의 브레이크 제어만 가능한 경우에는 상기 직진 정차로 결정하는 동작, 상기 차량의 브레이크 제어 및 조향 제어가 가능한 경우에는 상기 차선내 정차로 결정하는 동작 및 상기 차량의 브레이크 제어 및 조향 제어가 가능 하고, 차선 변경 및 갓길 검출이 가능한 경우에는 상기 반갓길 정차 또는 상기 완전 갓길 정차 중의 하나로 결 정하는 동작을 포함할 수 있다. 본 발명의 다양한 실시 예들에 따르면, 상기 차량의 상태를 기초로 긴급 정차 유형을 결정하는 동작은 상기 차 량의 구성요소들의 상태 정보 및 상기 차량의 주변환경 정보의 적어도 일부가 포함된 이미지를 생성하는 동작 및 생성된 상기 이미지를 입력으로 하는 인공지능을 사용하여 긴급 정차 유형을 결정하는 동작을 포함할 수 있 다. 본 발명의 다양한 실시 예들에 따르면, 상기 이미지를 생성하는 동작은 상기 차량의 주행 기능 정보를 포함하는 제1 이미지를 생성하는 동작, 상기 차량의 검출 기능 정보를 포함하는 제2 이미지를 생성하는 동작, 상기 차량 의 주변 환경 정보를 포함하는 제3 이미지를 생성하는 동작 및 생성된 상기 제1 이미지 내지 제3 이미지를 합성 하여 단순 조감도 이미지를 생성하는 동작을 포함할 수 있다. 본 발명의 다양한 실시 예들에 따르면, 상기 차량의 주행 기능 정보를 포함하는 제1 이미지를 생성하는 동작은 상기 차량의 조향각 제어가 불가능한 경우, 상기 차량의 현재의 조향각에 기초하여 운전가능 영역과 운전 불가 능 영역을 서로 상이한 색깔로 표시하는 상기 제1 이미지를 생성하는 동작을 포함할 수 있다. 본 발명의 다양한 실시 예들에 따르면, 상기 차량의 검출 기능 정보를 포함하는 제2 이미지를 생성하는 동작은 차선과 갓길을 서로 상이한 색깔로 표시하는 상기 제2 이미지를 생성하는 동작을 포함할 수 있다. 본 발명의 다양한 실시 예들에 따르면, 상기 차량의 검출 기능 정보를 포함하는 제2 이미지를 생성하는 동작은 차선 검출이 실패한 경우, 정상적으로 인식되던 과거의 차선 정보에 기초하여 현재의 차선 정보를 예측하고, 정 상적으로 검출된 차선 정보와 예측한 차선 정보를 서로 구분할 수 있는 방법으로 표시하는 상기 제1 이미지를 생성하는 동작을 포함할 수 있다.본 발명의 다양한 실시 예들에 따르면, 상기 이미지를 생성하는 동작은 주변 차량과의 충돌 위험도를 계산하는 동작 및 상기 충돌 위험도를 내포하도록 상기 단순 조감도 이미지에 포함된 상기 주변 차량의 명도를 상기 충돌 위험도에 따라 변경하여 표시하는 동작을 더 포함할 수 있다."}
{"patent_id": "10-2022-0073493", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 개시의 다양한 실시 예들에 따라, 차량이 자율 주행 중 발생한 이벤트에 의해 위험에 처하더라도, 상기 위험 을 제거할 수 있는 최소 위험 조작을 수행할 수 있다. 이에 따라, 상기 차량은 위험으로부터 벗어나 최소 위험 상태로 전환될 수 있고 차량의 주행 안정성이 더욱 증대되는 효과가 있다. 본 개시에서 얻을 수 있는 효과는 이상에서 언급한 효과들로 제한되지 않으며, 언급하지 않은 또 다른 효과들은 아래의 기재로부터 본 개시가 속하는 기술 분야에서 통상의 지식을 가진 자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2022-0073493", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하 다양한 실시 예들이 첨부된 도면을 참고하여 상세히 설명된다. 본 개시에서 다수개의 실시예들이 설명되는 경우, 각각의 실시예는 독립적인 실시예일 수도 있으나, 서로 충돌 이 되지 않는 경우, 두 개 이상의 실시예가 혼합되어 실시될 수도 있다. 도 1은 본 개시의 다양한 실시예들에 따른, 차량의 개념적인 구조를 도시한 도면이다. 도 1을 참조하면, 차량은 자율 주행(automated drive)을 지원할 수 있다. 실시 예들에 따라, 차량은 운전자의 조작 없이 조향, 가속, 브레이크, 변속 또는 주차를 수행할 수 있으며, 운전자의 개입 시 운전자의 제 어에 따라 주행할 수 있다. 예컨대, 차량은 SAE(Society of Automation Engineers)에 따른 레벨 3 이상의 수준에 따라 자율 주행을 수행할 수 있는 차량을 의미할 수 있으나, 본 개시가 이에 한정되는 것은 아니다. 예컨대, 본 명세서에서 설명되는 자율 주행은 PDCMS(Pedestrian Detection and Collision Mitigation System), LCDAS(Lane Change Decision Aid System), LDWS(Land Departure Warning System), ACC(Adaptive Cruise Control), LKAS(Lane Keeping Assistance System), RBDPS(Road Boundary Departure Prevention System), CSWS(Curve Speed Warning System), FVCWS(Forward Vehicle Collision Warning System), LSF(Low SpeedFollowing) 등의 ADS 기능들 중 적어도 하나를 포함할 수 있다. 차량은 센서, 컨트롤러, 프로세서, 디스플레이, 통신장치 및 저장장치를 포함할 수 있다. 센서는 차량의 주변의 환경을 감지하고, 차량의 주변에 관련된 데이터를 생성할 수 있다. 실시 예들에 따라, 센서는 카메라, 라이다(light detection and ranging (LIDAR)) 센서, 레이다(radio detection and ranging (RADAR) 센서 및 위치 센서 중 적어도 하나를 포함할 수 있다. 카메라는 차량 주변을 촬영하고, 촬영 결과에 따라 차량 주변에 대한 이미지를 생성할 수 있다. 카메 라는 차량의 전방, 후방 및/또는 측방을 감지하고, 감지 결과에 따라 이미지 데이터를 생성할 수 있다. 예 컨대, 카메라는 차량의 전방, 후방 및/또는 측방에 위치한 다른 물체들(예컨대, 다른 차량, 사람, 물체, 차선, 장애물)에 대한 이미지 데이터를 생성할 수 있다. 실시 예들에 따라, 카메라는 이미지 센서, 이미지 프로세서 및 카메라 MCU를 포함할 수 있다. 예컨대, 렌즈를 통해 촬영된 피사체의 이미지를 이미지 센서가 센싱하고, 이미지 프로세서가 이미지 센서로부터 그 데이터를 수 신하여 프로세싱하며, 카메라 MCU는 이미지 프로세서로부터 그 데이터를 수신할 수 있다. 라이다 센서는 빛 또는 레이저를 이용하여 차량의 전방, 후방 및/또는 측방을 감지하고, 감지 결과에 따라 감지 데이터를 생성할 수 있다. 예컨대, 라이다 센서는 차량의 전방, 후방 및/또는 측방에 위치한 다른 물 체들(예컨대, 다른 차량, 사람, 물체, 차선, 장애물)을 감지 또는 인식할 수 있다. 실시 예들에 따라, 라이다 센서는 레이저 송신 모듈, 레이저 검출 모듈, 신호 수집 및 처리 모듈, 데이터 송수 신 모듈로 구성될 수 있고, 레이저의 광원은 250 nm 내지 11 μm의 파장 영역 내의 파장을 가지거나 파장 가변 이 가능한 레이저 광원들이 사용될 수 있다. 또한 라이다 센서는 신호의 변조 방식에 따라서, TOF(time of flight) 방식과 위상 변위(phase shift) 방식으로 구분될 수 있다. 레이다 센서는 전자기파(또는 전파)를 이용하여 차량의 전방, 후방 및/또는 측방을 감지하고, 감지 결과에 따라 감지 데이터를 생성할 수 있다. 예컨대, 레이더 센서는 차량의 전방, 후방 및/또는 측방에 위치한 다 른 물체들(예컨대, 다른 차량, 사람, 물체, 차선, 장애물)을 감지 또는 인식할 수 있다. 레이더 센서는 주파수 변조 반송파(FMCW, Frequency Modulation Carrier Wave) 또는 펄스 반송파(Pulse Carrier) 방식을 이용하여 수평각도 30도 범위에서 150m 전방까지의 물체를 감지할 수 있다. 레이더 센서는 감 지 결과에 따라 생성된 데이터를 프로세싱할 수 있고, 이러한 프로세싱은 센싱한 전방의 물체를 확대하거나 전 체 시야 영역 중에서 물체의 영역에 포커스를 맞추는 것을 포함할 수 있다. 위치 센서는 차량의 현재 위치를 측정할 수 있다. 실시 예들에 따라, 위치 센서는 GPS 센서를 포함할 수 있고, GPS 센서는 위성과의 통신을 이용해 차량의 위치, 속도 및 현재 시간을 측정할 수 있다. 실시 예들 에 따라, 상기 GPS 센서는 위성으로부터 발사되는 전파의 지연시간을 계측하고 궤도로부터의 거리에서 차량 의 위치를 구할 수 있다. 컨트롤러는 프로세서의 제어에 따라 차량의 작동을 제어할 수 있다. 실시 예들에 따라, 컨트롤 러는 차량의 조향, 구동, 브레이크 및 변속을 제어할 수 있다. 예컨대, 컨트롤러는 차량의 조향, 구동, 브레이크 및 변속을 수행하기 위한 각 구성요소들을 제어할 수 있다. 컨트롤러는 프로세서의 제어에 따라 차량의 조향을 제어할 수 있다. 실시 예들에 따라, 컨트롤 러는 스티어링 휠을 구동시키는 전동식 파워스티어링 시스템(MPDS)에 대한 제어를 수행할 수 있다. 예컨대, 컨트롤러는 차량의 충돌이 예상되는 경우에 충돌을 회피하거나 피해를 최소화할 수 있는 방향으로 자동차의 조향을 제어할 수 있다. 컨트롤러는 프로세서의 제어에 따라 차량의 구동을 제어할 수 있다. 실시 예들에 따라, 컨트롤 러는 차량의 감속, 가속 또는 엔진의 온/오프(on/off)를 수행할 수 있다. 예컨대, 컨트롤러는 프로세서의 제어에 따라 가속 또는 감속을 수행할 수 있고, 차량의 운행의 시작 또는 종료 시에 엔진 의 온/오프를 수행할 수 있다. 또한, 컨트롤러는 운전자의 제어 없이, 차량의 주행을 제어할 수 있다. 예컨대, 컨트롤러는 프 로세서의 제어에 따라 차량의 자율 주행을 수행할 수 있다. 컨트롤러는 프로세서의 제어에 따라 차량의 브레이크를 제어할 수 있다. 실시 예들에 따라, 컨 트롤러는 차량의 브레이크의 동작 여부를 제어하고 브레이크의 답력을 제어할 수 있다. 예컨대, 컨트 롤러는 충돌이 예상되는 경우 등에 자동적으로 긴급 브레이크를 작동시키도록 제어할 수 있다. 프로세서는 차량의 전반적인 작동을 제어할 수 있다. 프로세서는 차량 내의 구성요소들을 통합적으로 제어할 수 있는 ECU(electrical control unit)일 수 있다. 예컨대, 프로세서는 연산 처리를 수행할 수 있는 CPU(central processing unit) 또는 MCU(micro processing unit)을 포함할 수 있다. 또한, 프 로세서는 적어도 하나 이상일 수 있으며, 이때, 각각의 프로세서는 서로 상이한 기능을 독립적으로 동작하여 차량 내의 구성요소를 제어하거나, 다른 실시예에 따르면, 서로 연관되어 데이터를 주고 받으면 서 함께 차량 내의 구성요소들을 통합적으로 제어할 수 있다. 프로세서는 차량의 제어와 관련된 판단을 수행하고, 판단 결과에 따라 컨트롤러를 제어할 수 있 다. 실시 예들에 따라, 프로세서는 센서로부터 데이터를 수신하고, 수신된 데이터에 기초하여 컨트롤 러를 제어하기 위한 제어 명령을 생성할 수 있다. 프로세서는 제어 명령을 컨트롤러에 전송할 수 있다. 또한, 프로세서는 운전자의 입력 또는 제어를 수신하고, 운전자의 입력에 따라 컨트롤러를 제어할 수 있다. 한편, 이상에서는 컨트롤러와 프로세서가 분리된 구성요소인 것을 가정하고 설명하였으나, 실시 예들 에 따라 컨트롤러와 프로세서는 하나의 구성요소로서 통합될 수 있다. 예컨대, 컨트롤러와 프로 세서는 하나의 장치로서 통합되어 서로 연동될 수 있다. 디스플레이는 차량과 관련된 정보를 시각적으로 표시할 수 있다. 실시 예들에 따라, 디스플레이(14 0)는 프로세서의 제어에 따라, 차량의 운전자에게 차량과 관련된 다양한 정보를 제공할 수 있다. 예컨대, 디스플레이는 프로세서의 제어에 따라 차량의 현 상태를 시각적으로 표시할 수 있다. 통신장치는 차량의 외부와 통신할 수 있다. 실시 예들에 따라, 통신장치는 프로세서의 제 어에 따라 차량의 외부로부터 데이터를 수신하거나, 또는 차량의 외부로 데이터를 전송할 수 있다. 예컨대, 통신장치는 무선 통신 프로토콜 또는 유선 통신 프로토콜을 이용하여 통신을 수행할 수 있다. 예컨대, 차량은 통신장치를 이용하여 다른 차량과 통신하거나 (vehicle to vehicle) 또는 인프라와 통신(vehicle to infra)할 수 있다. 저장장치는 프로세서가 동작하는 데 필요한 프로그래밍된 소프트웨어 및 각종 설정 정보를 저장하고 있을 수 있다. 프로세서는 차량의 시동이 켜지거나 전원이 온(ON)되는 경우 저장장치로부터 소프트웨 어 코드를 읽어들여 동작할 수 있다. 또한 프로세서는 동작 중 생성하는 입, 출력 데이터를 저장장치(16 0)에 임시적으로 저장할 수도 있다. 도 1과 같은 차량의 개념적인 구조를 가진 차량이 자율 주행을 수행하고 있는 동안, 예측하지 못한 사고 등과 같은 이벤트가 발생하였을 때 차량의 자율 주행 기능은 주변 차량과의 충돌 위험을 최소화하기 위하여 긴급하게 정차를 시도할 필요가 있다. 본 개시에서는 자율 주행 차량이 시도할 수 있는 긴급 정차 유형을 제안하고 어떤 유형을 사용하여야 하는 지에 대한 판단하는 장치 및 방법을 제공하고자 한다. 도 2는 차량의 긴급 정차 유형을 판단하기 위한 기능 블록들을 도시한 도면이다. 일 실시 예에 따라, 도 2의 기능 블록들은 도 1의 프로세서에 의하여 수행될 수 있으나, 각 기능 블록들은 서로 다른 프로세서에 의해서 수행될 수도 있다. 도 2를 참조하면, 차량의 긴급 정차 유형을 판단하기 위한 기능 블록들은 고장정보 수집부, 주변환경정보 수집부, 주변환경 예측부, 위험도 판단부 및 긴급 정차 유형 판단부를 포함할 수 있다. 이 중에서 위험도 판단부는 부가적인 기능으로 해당 기능은 포함하지 않을 수도 있다. 고장정보 수집부는 차량의 자율주행 기능의 성능을 판단하는 기능을 담당하며, 센서 등을 이용하여 수집한 정보를 기초로 차량의 주요 부품의 성능 상태를 수집하고 차량이 정상 상태인지 고장 상태인 지를 판단할 수 있다. 일 실시 예에 따라, 고장정보 수집부는 변속기, 엔진, 조향 장치 등을 포함하는 차 량 주행기능과 관련된 장치의 고장 정보를 수집하는 부분과, 카메라, 레이더, 라이다 센서 등과 같은 차량 디텍 션 기능과 관련된 장치의 고장 정보를 수집하는 부분으로 나눌 수 있다.주변환경정보 수집부는 카메라와 레이더 또는 라이더 센서와 같은 차량에 부착된 센서, 내비게이션 또는 통신장치를 통해 획득한 정보를 융합하여 차량의 주변에서 검출되는 주변 차량 정보, 차선 정보, 갓 길 정보를 획득할 수 있다. 주변환경 예측부는 주변환경정보 수집부로부터 획득한 정보와 고장정보 수집부로부터 획득한 차 량 상태 정보에 기초하여 차량 주변의 환경 변화를 예측할 수 있다. 위험도 판단부는 주변환경정보 수집부로부터 획득한 주변 차량의 상태 정보에 기초하여 자차량과 주 변 차량 간의 충돌 위험도를 계산할 수 있다. 긴급 정차 유형 판단부는 고장정보 수집부, 주변환경 예측부, 위험도 판단부로부터 획득한 정보들을 종합적으로 이용하여 차량을 위험 최소화 상태(minimal risk condition)에 도달하도록 하기 위한 적절한 유형을 선택할 수 있다. 도 3은 다양한 실시예들에 따른 긴급 정차 유형 판단부에서 판단하는 최종 긴급 정차의 유형을 도시한 도 면이다. 도 3을 참조하면, 긴급 정차 유형 판단부는 직진 정차(유형 1), 차선내 정차(유형 2), 반갓길 정차(유형 3) 및 완전 갓길 정차(유형 4)의 4가지 유형 중에 하나를 최소 위험 조작(minimum risk maneuver) 유형으로 선 택하고, 해당 유형에 따라 차량이 정차되도록 제어할 수 있다. 직진 정차(유형 1)는 구브러진 차선이라도 차선에 따라 주행하지 못하고 직진하여 바로 정차하는 유형으로 브레 이크 제어만 가능하면 실현가능한 유형일 수 있다. 즉, 차량이 고장 등에 의하여 차선 변경이나 조향이 불 가하고 브레이크만 제어 가능한 경우에, 긴급 정차 유형 판단부는 직진 정차(유형 1)만 선택 가능할 수 있 다. 차선내 정차(유형 2)는 차량을 차선 내에서 차선을 따라 주행하다가 긴급 정차를 수행하는 유형으로, 차량 은 최소한 브레이크 제어와 조향 제어가 가능하여야만 사용할 수 있는 유형일 수 있다. 반갓길 정차(유형 3) 및 완전 갓길 정차(유형 4)는 차량이 차선을 변경하여 갓길에 정차시키는 유형으로 완전히 갓길로 빠져나가 정차하는 완전 갓길 정차(유형 4)와 갓길에 차량의 일부가 걸치도록 정차하는 반 갓길 정차(유형 3)가 있을 수 있다. 차량은 브레이크 제어와 조향 제어가 가능하여야 하고, 자율 주행 기 능 중에서는 차선 변경 기능과 갓길 검출 기능이 가능하여야 사용할 수 있는 유형일 수 있다. 본 개시의 다양한 실시예들에 따르면, 긴급 정차 유형 판단부는 인공지능에 기반하여 긴급 정차 유형을 판 단할 수 있다. 도 4는 긴급 정차 유형 판단부가 사용할 수 있는 인공지능의 일 예를 도시한 도면이다. 도 4의 인공지능은 프로그램으로 구현되어 프로세서에 의해 실행될 수 있다. 또한, 도 4의 인공지능 구현 예는 일 실시예인 것으로 본 개시의 내용이 이에 한정되지 아니하며 다른 구조 또는 다른 알고리즘의 인공지능 이 사용될 수도 있다. 도 4의 인공지능은 심층 신경망의 일종인 합성곱 신경망(convolution neural network, CNN) 구조의 인공지능의 일 예를 도시한 것이다. 합성곱 신경망 기반의 인공지능은 이미지, 동영상, 문자열과 같은 구조적 공간 데이터 를 식별하는 데 있어 효과적일 수 있다. 합성곱 신경망은 이미지의 공간 정보를 유지하면서 인접 이미지와의 특 징을 효과적으로 인식할 수 있다. 도 4를 참조하면, 합성곱 신경망 기반의 인공지능은 특징 추출 층과 분류 층을 포함할 수 있다. 특 징 추출 층은 합성곱(convolution)을 이용하여 이미지에서 공간적으로 가까이에 위치한 것들을 합성하여 이미지의 특징을 추출할 수 있다. 특징 추출 층은 합성곱 층(421, 425)과 풀링 층(523, 427)을 복수 개 쌓은 형태로 구성될 수 있다. 합성 곱 층(421, 425)은 입력 데이터에 필터를 적용한 후 활성화 함수를 적용한 것일 수 있다. 합성곱 층(421, 42 5)은 복수의 채널을 포함할 수 있으며, 각각의 채널은 서로 상이한 필터 및/또는 서로 상이한 활성화 함수를 적 용한 것일 수 있다. 합성곱 층(421, 425)의 결과는 특징 지도(feature map)일 수 있다. 특징 지도는 2차원 행 렬 형태의 데이터일 수 있다. 풀링 층(423, 427)은 합성곱 층(421, 425)의 출력 데이터, 즉 특징 지도를 입력 으로 받아서 출력 데이터의 크기를 줄이거나, 특정 데이터를 강조하는 용도로 사용될 수 있다. 풀링 층(423, 427)은 합성곱 층(421, 425)의 출력 데이터의 일부 데이터 중에서 가장 큰 값을 선택하는 맥스 풀링(maxpooling), 평균값을 선택하는 평균 풀링(average pooling), 최소 값을 선택하는 민 풀링(min pooling)의 함수 를 적용하여 출력 데이터를 생성할 수 있다. 일련의 합성곱 층과 풀링 층을 거치면서 생성되는 특징 지도는 그 크기가 점점 작아질 수 있다. 마지막 합성곱 층과 풀링 층을 거쳐 생성된 최종 특징 지도는 1차원 형태로 변환되어 분류 층으로 입력될 수 있다. 분류 층은 완전 연결된 인공 신경망 구조일 수 있다. 분류 층의 입력 노드의 개수는 최종 특징 지도의 행 렬의 원소 수에 채널의 수를 곱한 것과 동일할 수 있다. 분류 층에서 사용하는 완전 연결된 인공 신경망은 입력 층(Input Layer), 출력 층(Output Layer), 그리고 선택적으로 하나 이상의 은닉 층(Hidden Layer)을 포함할 수 있다. 각 층은 신경망의 뉴런에 대응되는 하나 이 상의 노드를 포함하고, 인공 신경망은 한 층의 노드와 다른 층의 노드 간을 연결하는 시냅스를 포함할 수 있다. 인공 신경망에서 노드는 시냅스를 통해 입력되는 입력 신호들을 받고, 각 입력 신호들에 대한 가중치 및 편향에 대한 활성 함수에 기초하여 출력 값을 생성할 수 있다. 각 노드의 출력 값은 시냅스를 통해 다음 층의 입력 신 호로 작용할 수 있다. 한 층의 모든 노드와 다음 층의 모든 노드가 시냅스를 통해 모두 연결된 경우의 인공 신 경망을 완전 연결된 인공 신경망이라 칭할 수 있다. 인공 신경망 모델의 파라미터는 학습을 통해 결정되는 파라미터를 의미하며, 분류 층 인공 신경망의 시냅 스 연결의 가중치와 뉴런의 편향 등이 포함될 수 있고, 특징 추출 층의 각 합성곱 층(421, 425)에서 적용 되는 필터의 크기와 종류 등을 포함할 수 있다. 그리고, 하이퍼 파라미터는 특징 추출 층의 합성곱 층의 개수, 분류 층의 은닉 층의 개수와 같은 인공지능의 구조 자체를 기술하는 파라미터를 의미할 수 있다. 또한, 하이퍼 파라미터는 기계 학습 알고리즘에서 학습 전에 설정되어야 하는 파라미터를 의미하며, 학습률 (Learning Rate), 반복 횟수, 미니 배치 크기, 초기화 함수 등이 포함될 수 있다. 심층 신경망 구조로 상술한 합성곱 신경망 외에도 순환신경망(recurrent neural network, RNN), LSTM(long short term memory network), GRU(gated recurrent units)등이 사용될 수도 있다. 순환신경망은 순차적인 데 이터를 학습하여 분류 또는 예측을 수행할 수 있는 것으로 내부에 순환 구조가 들어 있어 과거 시간의 학습이 가중치와 곱해져 현재 학습에 반영될 수 있은 구조이다. 따라서 현재의 출력 결과는 과거 시간에서의 출력 결 과에 영향을 받으며, 은닉 층은 일종의 메모리 기능을 수행한다. 순환신경망은 음성 파형을 분석하여 기계 번 역을 수행하거나, 텍스트의 문장 앞 뒤 성분을 파악하여 텍스트를 생성하거나, 음성 인식을 위해 사용될 수 있 다. 인공 신경망 학습의 목적은 손실 함수를 최소화하는 모델 파라미터를 결정하는 것으로 볼 수 있다. 손실 함수 는 인공 신경망의 학습 과정에서 최적의 모델 파라미터를 결정하기 위한 지표로 이용될 수 있다. 완전 연결된 인공 신경망의 경우, 학습에 의하여 각 시냅스의 가중치가 결정될 수 있으며, 합성곱 신경망의 경우, 학습에 의 하여 특징 지도를 추출하기 위한 합성곱 층의 필터가 결정될 수 있다. 기계 학습은 학습 방식에 따라 지도 학습(Supervised Learning), 비지도 학습(Unsupervised Learning), 강화 학습(Reinforcement Learning)으로 분류할 수 있다. 지도 학습은 학습 데이터에 대한 레이블(label)이 주어진 상태에서 인공 신경망을 학습시키는 방법을 의미하며, 레이블이란 학습 데이터가 인공 신경망에 입력되는 경우 인공 신경망이 추론해 내야 하는 정답(또는 결과 값)을 의미할 수 있다. 비지도 학습은 학습 데이터에 대한 레이블이 주어지지 않는 상태에서 인공 신경망을 학습시키 는 방법을 의미할 수 있다. 강화 학습은 어떤 환경 안에서 정의된 에이전트가 각 상태에서 누적 보상을 최대화 하는 행동 혹은 행동 순서를 선택하도록 학습시키는 학습 방법을 의미할 수 있다. 도 4에 도시한 인공지능은 주변환경 예측부에서 생성한 이미지를 입력으로 사용하고, 도 3에 도시된 최소 위험 조작 유형 중의 하나를 선택한 유형으로 출력할 수 있다. 인공지능은 추가적으로 최소 위험 조 작을 수행하여도 되지 않는 상황으로 판단한 경우에는 정상 상태임을 나타내는 것을 출력할 수 있다. 즉, 인공 지능이 결정하는 출력은 도 3에 도시된 유형 유형과 정상 상태를 나타내는 정보일 수 있다. 도 4에 도시된 인공지능에 입력되는 이미지는 단순히 카메라 또는 이미지 센서로 촬상한 이미지가 아니고, 주변환경 예측부가 주변환경정보 수집부로부터 획득한 주변 차량 정보, 차선 검출 정보와 고장정보 수집부로부터 획득한 차량의 고장 정보를 포함하는 차량 상태 정보에 기초하여 생성한 단순화된 조감도 (simplified bird's eye view, SBEV) 형태의 이미지일 수 있다. 도 5 내지 8은 주변환경 예측부에서 생성한 이미지의 예들을 도시한 도면이다. 도 5에서, 왼쪽의 도면(510, 530)은 실제 주행 상황을 모사한 도면이고, 오른쪽의 이미지(520, 540)는 각 실제 주행상황에 대응하여 주변환경 예측부가 생성한 이미지일 수 있다. 도 5를 참조하면, 주변환경 예측부는 자차량을 포함하여 주어진 관심 영역(region of interest) 내 존재하는 차량(511, 513)은 검정색 사각형(521, 523)으로 표시하고, 검출된 차선은 얇은 실선(녹색 실선) 또는 얇은 실선으로 표시할 수 있다. 그리고 갓길이 있는 경우에는 갓길을 구분하는 차선을 굵은 실선(검정색 실선) 또는 굵은 실선으로 표시할 수 있다. 즉, 주변환경 예측부는 갓길이 존재하는 경우, 얇은 실선 (얇은 실선(녹색 실선))과 굵은 실선(굵은 실선(검정색 실선))을 이용하여 갓길을 구분할 수 있는 이 미지를 생성할 수 있다. 도 6은 주변 인식 장치의 고장 또는 비정상 동작 시에 주변환경 예측부가 생성하는 이미지의 일 예를 도시 한다. 도 6에서, 왼쪽의 도면은 실제 주행 상황을 모사한 도면이고, 오른쪽의 이미지들(610, 620, 630)은 실제 주행상황에 대응하여 주변 인식 장치의 고장 또는 비정상 동작 시에 주변환경 예측부가 생성한 이미지일 수 있다. 일 실시 예에 따라 주변의 차량 또는 차선을 검출하는 센서 또는 프로세서가 일시적으로 또는 영구적으로 고장 이거나 비정상적인 경우, 주변 차량 정보 및 차선 검출에 실패할 수 있다. 이 경우 도 5에 도시한 바와 같이 얇 은 실선(녹색 실선), 굵은 실선(검정색 실선)으로 표시하는 차선, 그리고 검정색 사각형으로 표 시하는 주변 차량에 대한 정보를 획득할 수 없을 수 있다. 그러면 주변환경 예측부는 정상적으로 인식되던 과거의 차선 정보 또는 주변 차량 정보를 이용하여 현재의 주변 환경을 예측하고, 그 결과를 이미지들(610, 620, 630)에 포함시킬 수 있다. 일 실시 예에 따라, 도 6의 이미지를 참조하면, 주변환경 예측부가 차선 정보를 획득하지 못한 경우 에, 주변환경 예측부는 얇은 실선(녹색 실선)으로 표시된 과거의 차선 정보에 기초하여 현재의 차선 정보를 예측하고 이를 녹색 점선 또는 얇은 점선으로 이미지에 표시할 수 있다. 다른 일 실시 예에 따라, 도 6의 이미지를 참조하면, 주변환경 예측부가 차선 정보를 획득하지 못한 경우에, 주변환경 예측부는 굵은 실선(검은색 실선)으로 표시된 과거의 갓길 차선 정보에 기초하여 현재의 갓길 차선 정보를 예측하고 이를 검은색 점선 또는 굵은 점선으로 이미지에 표시할 수 있다. 다른 일 실시 예에 따라, 도 6의 이미지를 참조하면, 주변 차량 인식 성능이 비정상이어서 주변환경 예측 부가 주변 차량을 인식하지 못하는 경우에는 해당 차량의 과거의 위치 정보 및 상태 정보를 기반으로 현재 의 위치 정보를 예측하여 회색 사각형으로 이미지에 포함시킬 수 있다. 도 7은 차량의 횡방향 제어가 불가능한 경우에 주변환경 예측부가 생성한 이미지의 일 예를 도시한다. 도 7에서, 왼쪽의 도면은 실제 주행 상황을 모사한 도면이고, 오른쪽의 이미지는 차량의 횡방향 제어 가 불가능한 경우에 주변환경 예측부가 생성한 이미지일 수 있다. 일 실시 예에 따라 차량의 횡방향 제어를 담당하는 프로세서나 엑추에이터가 비정상적인 상태인 경우, 차량은 현재의 조향각을 유지하면서 긴급하게 정지를 하여야 할 필요가 있다. 이를 반영하여 주변환경 예측부는 차량의 조향각 변경이 불가한 경우, 긴급 정지를 위한 운전가능영역(drivable area)을 보여주는 이미지를 생성할 수 있다. 일 실시 예에 따라, 차량의 횡방향 제어기가 작동되지 않는다고 판단한 경우, 주변환경 예측부 는 현재시점의 조향각을 유지하며 차량이 진행할 수 있는 운전가능영역은 제1 색(예: 하얀색) 또는 제1 패턴(예: 무 패턴)으로 표시하고, 차량이 진행할 수 없는 운전불가능영역은 제2 색(진한 회색) 또는 제2 패턴(예: 점 패턴)으로 표시한 이미지를 생성할 수 있다. 이에 따라, 주변환경 예측부는 차량의 고장으로 인하여 야기된 축소된 운전가능영역을 이미지에 표시할 수 있다. 상술 실시 예에서 운전가 능영역과 운전불가능영역을 색 또는 패턴을 이용하여 구분하여 이미지에 표시하도록 하였으나, 이에 한정하는 것은 아니며, 이미지 내에서 운전가능영역과 운전불가능영역을 구분하도록 할 수 있는 어떠 한 방법도 사용 가능할 수 있다. 도 8은 자차량의 상태가 주행이 불가한 경우에 주변환경 예측부가 생성한 이미지의 일 예를 도시한다. 도 8을 참조하면, 자차량이 차선 정보 감지, 주변 차량 인식 등에는 문제가 없으나 엔진 과열이 발생하는 등과 같은 주행이 불가한 상태인 경우 주변환경 예측부는 자차량을 표시하는 검은색 사각형 외각을 자차량을 표 시하는 색과 다른 색(예: 빨간색) 또는 다른 패턴(예: 점 패턴)으로 둘러쌓도록 표시한 이미지를 생성할 수 있다. 도 9는 위험도 정보가 부가된 주변환경 예측부가 생성한 위험도 정보가 부가된 이미지의 일 예를 도시한다. 주변환경 예측부는 부가적으로 주변의 차량과 자차량의 운행 상태를 기초로 자차량과 주변 차량 간의 충돌 위험도를 판단할 수 있다. 그리고 도 9에 도시된 바처럼, 판단된 충돌 위험도가 미리 설정된 값을 초과하면 주 변환경 예측부는 생성하는 이미지(920, 930)에서 해당 주변 차량의 색깔을 상이한 색으로 변경할 수 있다. 즉 도 9의 이미지에 도시된 것처럼, 충돌 위험도가 미리 설정된 값보다 작으면 주변 차량을 검은 색으로 표시하는 반면에 도 9의 이미지(920, 930)에 도시된 것처럼, 충돌 위험도가 미리 설정된 값보다 크다면 주변 차 량을 빨간색 또는 회색으로 표시할 수 있다. 또한, 주변환경 예측부는 판단된 충돌 위험도의 정도에 기초 하여 생성하는 이미지(920, 930)에서 해당 주변 차량의 명도를 다르게 할 수 있다. 일 실시 예에 따라, 주변환 경 예측부는 충돌 위험도가 높을수록 명도 값을 크게 할 수 있다. 도 10은 주변환경 예측부가 충돌 위험도를 계산하는 예를 설명하기 위한 도면이다. 일 실시 예에 따라, 주변환경 예측부를 충돌 위험도를 계산하기 위한 위험도 판단부를 구비하거나, 별도의 위험도 판단부가 구비되고, 주변환경 예측부는 위험도 판단부로부터 결과값을 획득하여 이용할 수도 있다. 도 10을 참고하면, 전방 차량과 후방 차량 사이의 충돌 위험도가 계산될 수 있다. 여기서, 자차량 은 전방 차량이 될 수도 있고, 후방 차량이 될 수도 있다. 먼저 다음 수학식 1을 이용하여 충돌 예상 시간(time to collision, TTC)을 계산할 수 있다. 수학식 1"}
{"patent_id": "10-2022-0073493", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "여기서, Plong은 도 10에 도시된 것처럼 후방 차량과 전방 차량 간의 종방향 거리를 나타내고,vrel은 후방 차량과 전방 차량 간의 종방향 상대 속도를 나타낼 수 있다. 충돌 위험도 계산은 자차량에서 수행되므로, vrel은 자차량에 대한 주변 차량의 종방향 상대속도를 나타내는 것일 수 있다. 또한, 수학식 2를 이용하여 경고 지수(warning index, xp)를 계산할 수 있다. 수학식 2"}
{"patent_id": "10-2022-0073493", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "item": 3, "content": "도 10에 도시된 바와 같이, Plong은 후방 차량과 전방 차량 간의 종방향 거리를 나타내고, dbr은 차 량이 최대 감속도로 등가속도 운동할 경우 정지할 때까지의 거리(breaking-critical distance)이고, dw는 dbr에 운전자가 브레이크를 밟을 때까지의 반응 시간을 고려한 정지거리(warning-critical distance)이다. dbr은 다음 수학식 3을 이용하여 계산할 수 있고, dw는 다음 수학식 4를 이용하여 계산할 수 있다. 수학식 3"}
{"patent_id": "10-2022-0073493", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "수학식 4"}
{"patent_id": "10-2022-0073493", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "여기서, vrel은 후방 차량과 전방 차량 간의 종방향 상대 속도를 나타내고, tbreak는 제동 시스템 하 드웨어의 시스템 지연시간, tthinking은 운전자가 브레이크를 밟을 때까지의 반응 시간, ax,max는 차량의 종방향 최 대 감속도를 나타낸다. 후방 차량의 운전자가 브레이크를 밟고 후방 차량이 최대로 감속하는 경우 후방 차량은 dw만 큼 갈 수 있고, dw가 Plong보다 작다면, 경고지수(xp)는 양의 값을 가지고 현재 상황이 안전하다고 판단할 수 있 다. 반대로 dw가 Plong보다 크다면 경고지수(xp)는 음의 값을 가지고 충돌 가능성이 있음을 판단할 수 있다. 주변환경 예측부는 종방향 충돌 위험 지수(longitudinal collision risk index, Ilong)를 다음 수학식 5에 기초하여 계산할 수 있다. 수학식 5"}
{"patent_id": "10-2022-0073493", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "여기서, xmax는 경고지수의 최대값, xth는 경고지수의 임계값이며, 는 TTC-1의 임계값이다. 만약 자차량이 차로 변경을 하는 경우 차로 변경 시간(time to lane crossing, TLC)은 다음 수학식 6을 이용하 여 계산할 수 있다. 수학식 6"}
{"patent_id": "10-2022-0073493", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 7, "content": "여기서, y는 주변 차량의 횡방향 상대 위치를 나타내고, vy는 후방 차량과 전방 차량 간의 횡방향 상대 속도를 나타낸다.그리고, 주변환경 예측부는 수학식 7을 이용하여 횡방향 충돌 위험 지수(lateral collision risk index, Ilat)를 계산할 수 있다. 수학식 7"}
{"patent_id": "10-2022-0073493", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 8, "content": "여기서, TLCth는 미리 설정된 차로 변경 시간의 임계값일 수 있다. 횡방향 충돌 위험 지수는 0~1 사이의 값을 가지며, 1에 가까울수록 현재 상황이 위험함을 의미할 수 있다. 일 실시 예에 따라, 위의 수학식들에 포함된 임계값들은 충돌 사고 데이터를 기반으로 설정할 수도 있고, 모의 시험을 통해 생성한 가상 사고 데이터 결과를 기반으로 설정할 수도 있다. 일 실시 예에 따라, 와 TLCth 는 0.5일 수 있다. 주변환경 예측부는 상술한 수학식에 기초하여 획득한 종방향 충돌 위험 지수 및/또는 횡방향 충돌 위험 지 수를 반영하여 도 9에 도시된 바와 같이 충돌 위험 지수에 따라 명도를 다르게 한 이미지를 생성할 수 있다. 본 개시에서 제안하는 차량은 자율 주행을 지원할 수 있다. 실시 예들에 따라, 차량은 운전자의 조작 없이 조향, 가속, 브레이크, 변속 또는 주차를 수행할 수 있으며, 운전자의 개입 시 운전자의 제어에 따라 주행 할 수 있다. 차량은 자율 주행을 지원하기 위하여 다양한 자율 주행 관련 기능들을 수행할 수 있으며, 특 히, 상술한 기능들에 기반하여 차량은 최소 위험 조작(minimal risk maneuver, MRM)을 수행할 수 있다. 도 11은 다양한 실시 예들에 따른 차량의 최소 위험 조작을 수행하기 위한 작동 동작을 도시한 흐름도이다. 도 11을 참조하면, 동작 S10에서, 차량은 최소 위험 조작(MRM)이 시작되도록 하는 요청을 획득할 수 있다. 실시 예들에 따라, 프로세서는 차량의 시동이 켜지고, 차량이 일정 속도 이상으로 이동하기 시 작한 경우 최소 위험 조작 기능이 시작되도록 하는 요청을 생성할 수 있다. 또는, 프로세서는 차량 및 차량 주변의 상태 정보를 획득하고, 획득한 상태 정보에 기초하여 최소 위험 조작 요청을 생성할 수 있 다. 또는 프로세서는 통신장치 또는 센서를 통해 수신한 외부로부터의 최소 위험 조작 요청을 획득할 수 있다. 최소 위험 조작 요청은 차량으로 하여금 최소 위험 조작을 수행하도록 하는 임의의 명령 을 의미할 수 있다. 동작 S20에서, 차량은 최소 위험 조작 요청이 있는 경우, 최소 위험 조작 기능을 실행할 수 있다. 최소 위험 조작 기능은 차량의 상태를 모니터링하는 동작, 긴급 정차 유형을 결정하는 동작 및 결정된 긴급 정 차 유형을 실행하는 동작을 포함할 수 있다. 동작 S21에서 차량은 차량의 상태를 모니터링할 수 있다. 실시 예들에 따라, 차량은 고장정보 수집부 및 주변환경정보 수집부를 이용하여 차량의 구성요소들의 상태와 차량 주변환경 정 보를 모니터링할 수 있다. 차량은 차량의 구성요소들 각각의 상태 및 차량이 진행하고 있는 주 변 환경 정보, 예를 들어 차선, 주변 차량 정보 등을 실시간으로 모니터링 할 수 있다. 차량은 센서 중에서 현재 사용 가능한(또는 동작 가능한) 센서 또는 구성요소가 무엇인지 판단할 수 있다. 동작 S23에서, 차량은 수집된 정보에 기초하여 차량의 긴급 정차 유형을 결정할 수 있다. 다양한 실시 예 들에 따르면 차량의 긴급 정차 유형은 직진 정차, 차선내 정차, 반갓길 정차 및 완전 갓길 정차를 포함할 수 있 다. 다만 이에 한정되는 것은 아니고, 다른 실시 예에서는 추가적인 긴급 정차 유형이 포함될 수도 있다. 차량은 고장 상태의 판단 결과에 기초하여, 현재 고장 상태에 적합한 긴급 정차 유형을 결정할 수 있다. 일 실시 예에 따라, 차량의 브레이크 제어만 가능한 경우에는 직진 정차만이 실현 가능한 유형으로 선택될 수 있다. 다른 일 실시 예에 따라, 차량의 조향 제어와 브레이크 제어가 가능한 경우에는 직진 정차 외에도 차선내 정차 유형이 선택될 수 있다. 다른 일 실시 예에 따라, 차량의 조향 제어와 브레이크 제어가 가능할 뿐만 아니 라 자율 주행 기능 중에서 차선 변경 기능과 갓길 검출 기능이 가능한 경우에는 반갓길 정차 유형 및 완전 갓길정차 유형도 선택될 수 있다. 본 개시의 다양한 실시 예들에 따르면, 차량은 인공지능에 기반하여 긴급 정차 유형을 결정할 수 있다. 도 12는 차량이 인공지능에 기반하여 긴급 정차 유형을 결정하는 것을 도시한 흐름도이다. 도 12를 참조하면, 동작 S110에서, 수집한 차량 상태 정보 또는 고장 정보 및 주변 환경 정보를 포함하는 이미 지를 생성할 수 있다. 동작 S120에서는, 동작 S110에서 생성한 이미지에 충돌 위험도 정보를 추가적으로 삽입할 수 있으나, 이는 보조 적인 동작으로써 동작 S120은 실행하지 않을 수 있다. 동작 S130에서, 생성된 이미지를 입력으로 하는 인공지능에 기반하여 긴급 정차 유형을 결정할 수 있다. 여기서 인공지능은 동작 S110 또는 S120에서 생성한 이미지를 기반으로 지도 학습 방식에 따라 학습된 인공 지능일 수 있다. 즉, 차량에 구비된 인공지능은 차량에 탑재되기 전 제조사에서 학습시킨 인공지능일 수 있다. 따라서, 차 량은 미리 학습된 인공지능을 이용하여 입력된 이미지를 기초로 긴급 정차 유형을 결정할 수 있다. 도 13은 수집한 차량 상태 또는 고장 정보 및 주변 환경 정보를 기초로 인공지능에 입력되는 단순화된 조감도 이미지를 생성하는 예를 도시한 흐름도이다. 도 13의 흐름도는 도 12의 동작 S110의 상세 동작을 나타내는 것일 수 있다. 도 13에 따라 단순 조감도(SBEV) 이미지를 생성하기 전에 단순 조감도 이미지의 크기가 설정되어 있을 수 있다. 설정되는 이미지의 크기는 인공지능을 학습시키기 위한 이미지 및 학습된 인공지능이 판단을 위하여 입력받는 이미지에서 모두 동일하게 사용될 수 있는 것일 수 있다. 일 실시 예에 따라, 단순 조감도 이미지의 크기는 3HW 로 설정될 수 있다. 여기서 H는 이미지의 높이를 나타내고 W는 이미지의 폭이고 3은 R, G, B의 3개의 이미지임 을 나타내는 것일 수 있다. 그리고 높이와 폭의 단위는 픽셀(pixel)일 수 있다. 또한, 실제 물리적인 의미와 매 핑하기 위하여 픽셀 간 거리를 X(m)로 설정할 수 있다. 도 13을 참조하면, 동작 S210에서 차량은 변속기, 엔진, 조향장치 등의 차량 구성요소의 고장 정보에 기초 하여 차량 주행 기능 정보와 관련된 이미지를 생성할 수 있다. 예를 들면, 차량 조향의 고장을 반영하여 현재의 조향각에서 차량이 진행할 수 있는 주행 가능 영역을 결정하고, 설정된 이미지 크기와 픽셀 간 거 리에 기초하여 단순 조감도 이미지에 표현할 수 있다. 동작 S220에서, 차량은 카메라, 레이더, 라이다 센서 등과 같은 차량의 검출 기능을 가진 구성 요소에 의 하여 수집된 정보에 기초하여 차량 검출 기능 정보와 관련된 이미지를 생성할 수 있다. 예를 들면 차량은 과거 차량의 궤적, 위치를 단순 조감도 이미지에 표현할 수 있다. 동작 S230에서 차량은 주변환경정보 수집부 및 주변환경 예측부로부터 획득한 정보에 기초하여 현재의 주변 환경정보에 대한 이미지를 생성할 수 있다. 예를 들면, 차량은 교통 정보, 갓길정보, 안전지 대 표시 등을 이미지에 표현할 수 있다. 또한, 차량은 주변환경정보 수집부에서 인식한 차선에 대하 여는 실선으로 표시하고, 차선 미인식으로 인하여 주변환경 예측부에서 예측한 차선에 대하여는 점선으로 표시할 수 있다. 동작 S240에서 차량은 단순 조감도 이미지를 생성할 수 있다. 차량은 동작 S210 내지 S230에서 생성 한 이미지들을 합성하여 단순 조감도 이미지를 생성할 수 있다. 이때 단순 조감도 이미지는 자차량 및 검출된 주변차량을 사각형 형태로 표시하고, 차선은 실선 또는 점선으로 표시하는 것과 같이 단순한 형태로 가능한한 많은 정보를 포함할 수 있도록 되었다. 일 실시 예에 따라, 차량이 동작 S240을 별도로 수행하지 않고, 동 작 S210 내지 S230을 순차적으로 또는 병렬적으로 실행하면서 설정된 이미지 크기에 각 동작에서 그려진 단순 이미지를 부가함으로써 단순 조감도 이미지를 획득할 수도 있다. 동작 S250에서 차량은 필요한 경우 기타 이미지 전처리 작업을 수행하여 인공지능에 입력시키는 최종 이미 지를 생성할 수 있다. 도 13의 실시 예에서, 동작 S210 내지 S230은 어떤 순서에 따라 수행되는 것이 아니고, 도 13에 예시된 순서와 다른 순서로 수행될 수 있을 뿐만 아니라, 다른 실시 예에 따르면, 동시에 해당 동작들이 수행될 수도 있다. 동작 S110에 따라 생성된 최종 이미지는 도 5 내지 8의 이미지일 수 있다. 동작 S120이 추가적으로 진행하여 생성된 최종 이미지는 도 9의 이미지일 수 있다. 다시 도 11을 참조하면, 동작 S25에서, 결정된 긴급 정차 유형을 실행할 수 있다. 차량은 결정된 긴급 정차 유형을 실행하기 위하여 차량의 정지, 차량의 조향 제어, 차선 유지, 시각적, 청 각적 및 촉각적 알림 제공, 차량의 감속, 차량의 가속, 자율 주행의 개시/종료, 차량의 시동 OFF, 긴급 신호 전 송, 비상등 제어, 속도 감소 경고, 브레이크등 제어, 다른 탑승객으로의 제어 권한 이양 및 원격 제어 중 적어 도 하나를 실행할 수 있다. 예컨대, 차량의 프로세서는 결정된 긴급 정차 유형에 대응하는 제어 명령 을 컨트롤러로 전송하고, 컨트롤러는 제어 명령에 따라 차량을 제어할 수 있다. 동작 S25에서 결정된 긴급 정차 유형이 실행된 이후 차량은 정차하게 되고 최소 위험 상태에 있을 수 있다. 차량이 최소 위험 상태에 도달한 경우에는 자율주행 시스템을 오프(off)하거나 또는 차량의 시동 을 끌 수 있다. 그리고 동작 S20 중에 차량은 사용자의 조작을 무시하거나 중단시킬 수 있고, 사용자의 조작을 간섭하 고, 최소 위험 조작에 의한 동작에 우선순위를 줄 수 있다."}
{"patent_id": "10-2022-0073493", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 개시의 다양한 실시예들에 따른, 차량의 개념적인 구조를 도시한 도면이다. 도 2는 차량의 긴급 정차 유형을 판단하기 위한 기능 블록들을 도시한 도면이다. 도 3은 다양한 실시예들에 따른 긴급 정차 유형 판단부에서 판단하는 최종 긴급 정차의 유형을 도시한 도면이다. 도 4는 긴급 정차 유형 판단부가 사용할 수 있는 인공지능의 일 예를 도시한 도면이다. 도 5 내지 8은 주변환경 예측부에서 생성한 이미지의 예들을 도시한 도면이다. 도 9는 위험도 정보가 부가된 주변환경 예측부가 생성한 위험도 정보가 부가된 이미지의 일 예를 도시한다. 도 10은 주변환경 예측부가 충돌 위험도를 계산하는 예를 설명하기 위한 도면이다. 도 11은 다양한 실시 예들에 따른 차량의 최소 위험 조작을 수행하기 위한 작동 동작을 도시한 흐름도이다. 도 12는 차량이 인공지능에 기반하여 긴급 정차 유형을 결정하는 것을 도시한 흐름도이다. 도 13은 수집한 차량 상태 또는 고장 정보 및 주변 환경 정보를 포함하는 이미지를 생성하는 일 예를 도시한 흐 름도이다. 도면의 설명과 관련하여, 동일 또는 유사한 구성요소에 대해서는 동일 또는 유사한 참조 부호가 사용될 수 있다."}
