{"patent_id": "10-2023-0118700", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2025-0036337", "출원번호": "10-2023-0118700", "발명의 명칭": "음성과 음향 인식을 위한 인공 신경망 모델 학습 장치 및 추론 시스템", "출원인": "감바랩스", "발명자": "하유빈"}}
{"patent_id": "10-2023-0118700", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "추론 단말로부터 로컬 네트워크를 통해 수집되는 오디오 데이터를 이용하여 추론 단말로 배포되는 인공 신경망모델을 학습시키는 장치로서,제1 추론 단말로부터 수집되는 복수의 오디오 데이터 중 제1 오디오 데이터들을 이용하여 추론용 제1 인공 신경망 모델을 학습시키는 제1 학습 에이전트; 및 상기 제1 추론 단말로부터 수집되는 복수의 오디오 데이터 중 제2 오디오 데이터들을 이용하여 상기 제1 학습에이전트에서 학습된 제1 인공 신경망 모델을 평가하고 평가 결과에 따라 상기 제1 추론 단말로 상기 학습된 제1 인공 신경망 모델을 상기 로컬 네트워크를 통해 배포하는 제1 평가 에이전트;를 포함하는, 인공 신경망 모델 학습 장치."}
{"patent_id": "10-2023-0118700", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 제1 학습 에이전트는 상기 제1 추론 단말과 다른 제2 추론 단말에서 상기 로컬 네트워크를 통해 수집되는복수의 오디오 데이터 중 제1 오디오 데이터들을 이용하여 상기 제2 추론 단말에서의 추론용 제1 인공 신경망모델을 학습시키고,상기 제1 평가 에이전트는 상기 제2 추론 단말로부터 수집되는 복수의 오디오 데이터 중 제2 오디오 데이터들을이용하여 상기 제1 학습 에이전트에서 상기 제2 추론 단말에 대해 학습된 제1 인공 신경망 모델을 평가하고 평가 결과에 따라 상기 제2 추론 단말로 상기 제2 추론 단말에 대해 상기 학습된 제1 인공 신경망 모델을 상기 로컬 네트워크를 통해 배포하고,상기 로컬 네트워크는 사설망인, 인공 신경망 모델 학습 장치."}
{"patent_id": "10-2023-0118700", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서, 상기 제1 추론 단말로부터 수집되는 복수의 오디오 데이터 중 제3 오디오 데이터들을 이용하여 상기 제1 추론단말 주변에서 발생하는 환경음 제거를 위한 제2 인공 신경망 모델을 학습시키는 제2 학습 에이전트; 및 상기 제1 추론 단말로부터 수집되는 복수의 오디오 데이터 중 제4 오디오 데이터를 이용하여 상기 제2 학습 에이전트에서 학습된 제2 인공 신경망 모델을 평가하고 평가 결과에 따라 상기 제1 추론 단말로 상기 학습된 제2인공 신경망 모델을 상기 로컬 네트워크를 통해 배포하는 제2 평가 에이전트;를 더 포함하고, 학습된 상기 제1 인공 신경망 모델과 상기 제2 인공 신경망 모델은 상기 제1 추론 단말에서 수행되어 상기 제1추론 단말에서 수집되는 오디오 데이터에서 주변 환경음을 제거하고 제거된 오디오 데이터에서 목표 음원을 인식하는,인공 신경망 모델 학습 장치."}
{"patent_id": "10-2023-0118700", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제2항에 있어서, 상기 인공 신경망 모델 학습 장치는, 상기 제1 추론 단말에서 학습 주기 동안 수집되는 복수의 오디오 데이터를이용하여 기존 제1 인공 신경망 모델로부터 파인 튜닝되는 상기 제1 추론 단말을 위한 제1 인공 신경망 모델을학습하고, 상기 제2 추론 단말에서 학습 주기 동안 수집되는 복수의 오디오 데이터를 이용하여 기존 제1 인공공개특허 10-2025-0036337-3-신경망 모델로부터 파인 튜닝되는 상기 제2 추론 단말을 위한 제1 인공 신경 모델을 학습하는,인공 신경망 모델 학습 장치."}
{"patent_id": "10-2023-0118700", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제3항에 있어서,상기 제1 학습 에이전트는 상기 제1 오디오 데이터들과 미리 저장되어 있는 목표 음원 데이터들로 합성되는 오디오 데이터들을 추론 학습용 오디오 데이터로 수신하고, 상기 제1 평가 에이전트는 상기 제2 오디오 데이터들과 상기 미리 저장되어 있는 목표 음원 데이터들로 합성된오디오 데이터들을 추론 평가용 오디오 데이터로 수신하며, 상기 제2 학습 에이전트는 상기 제3 오디오 데이터들과 미리 저장되어 있는 목표 음원 데이터들로 합성된 오디오 데이터들을 환경음 제거 학습용 오디오 데이터로 수신하고, 상기 제2 평가 에이전트는 상기 제4 오디오 데이터들과 상기 미리 저장되어 있는 목표 음원 데이터들로 합성된오디오 데이터들을 환경음 제거 평가용 오디오 데이터로 수신하는, 인공 신경망 모델 학습 장치."}
{"patent_id": "10-2023-0118700", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "오디오 신호를 수신하는 마이크;로컬 네트워크를 통해 통신 패킷을 송수신하는 통신 인터페이스; 상기 마이크로부터의 오디오 데이터들과 제1 인공 신경망 모델의 프로그램을 저장하는 메모리;대응 신호를 출력하는 출력부; 및 상기 메모리의 프로그램의 코드를 수행하는 마이크로 컨트롤러;로서, 상기 마이크를 통해 수집되는 오디오 데이터들을 포함하는 통신 패킷을 상기 통신 인터페이스를 통해 로컬 네트워크에 연결된 인공 신경망 모델 학습 장치로 전송하고 상기 로컬 네트워크를 통해 상기 인공 신경망 모델 학습 장치로부터 상기 수집되는 오디오 데이터들에 대한 학습과 평가에 따른 추론용 제1 인공 신경망 모델을 수신하여 상기 메모리에 저장하고 상기 제1 인공 신경망 모델의 수행에 따라 목표 음원의 인식시에 대응 신호를 상기 출력부로 출력하는, 마이크로 컨트롤러;를 포함하는,인공 신경망 추론 단말."}
{"patent_id": "10-2023-0118700", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6항에 있어서, 상기 메모리는 상기 인공 신경망 모델 학습 장치로부터 수신되고 상기 마이크를 통해 수집되는 오디오 데이터들에 대해 학습되는 제2 인공 신경망 모델을 더 저장하고, 상기 제2 인공 신경망 모델의 프로그램과 상기 제1 인공 신경망 모델의 프로그램을 수행하는 상기 마이크로 컨트롤러는 마이크를 통해 수집되는 오디오 데이터들을 상기 제2 인공 신경망 모델에 입력하여 환경음이 제거된오디오 데이터들을 생성하고 상기 환경음이 제거된 오디오 데이터들을 상기 제1 인경 신경망 모델에 입력하여목표 음원의 인식 여부를 나타내는 추론 결과를 생성하고 상기 목표 음원의 인식을 나타내는 추론 결과에 따라상기 대응 신호를 생성하여 상기 출력부로 출력하는, 인공 신경망 추론 단말."}
{"patent_id": "10-2023-0118700", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서,상기 제1 인공 신경망 모델은 경량 합성곱 신경망 모델이고,상기 마이크로 컨트롤러는 상기 제1 인공 신경망 모델과 상기 제2 인공 신경망 모델의 프로그램을 직접 수행하공개특허 10-2025-0036337-4-는 RISC(reduced instruction set computer) 아키텍처 기반의 컨트롤러이고,상기 인공 신경망 추론 단말은 임베디드 시스템(embedded system)으로 구현되는, 인공 신경망 추론 단말."}
{"patent_id": "10-2023-0118700", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1항의 인공 신경망 모델 학습 장치; 상기 학습 장치와 로컬 네트워크를 통해 통신 패킷을 송수신하는 제6항의 제1 추론 단말; 및상기 학습 장치와 상기 로컬 네트워크를 통해 통신 패킷을 송수신하는 제6항의 제2 추론 단말;을 포함하고, 상기 학습 장치는 상기 제1 추론 단말로부터 수집되는 오디오 데이터를 이용하여 상기 제1 추론 단말에서 수행되는 제1 인공 신경망 모델을 학습시키고, 상기 제2 추론 단말로부터 수집되는 오디오 데이터를 이용하여 상기제2 추론 단말에서 수행되는 제1 인공 신경망 모델을 학습시키는,인공 신경망 추론 시스템."}
{"patent_id": "10-2023-0118700", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은, 제1 추론 단말로부터 수집되는 복수의 오디오 데이터 중 제1 오디오 데이터들을 이용하여 추론용 제1 인공 신경망 모델을 학습시키는 제1 학습 에이전트 및 제1 추론 단말로부터 수집되는 복수의 오디오 데이터 중 제2 오디오 데이터들을 이용하여 제1 학습 에이전트에서 학습된 제1 인공 신경망 모델을 평가하고 평가 결과에 따라 제1 추론 단말로 학습된 제1 인공 신경망 모델을 로컬 네트워크를 통해 배포하는 제1 평가 에이전트를 포함 하는, 음성과 음향 인식을 위한 인공 신경망 모델 학습 장치 및 추론 시스템에 관한 것이다."}
{"patent_id": "10-2023-0118700", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 음성과 음향 인식을 위한 인공 신경망 모델 학습 장치 및 추론 시스템에 관한 것으로서, 구체적으로 는 인공 신경망 모델이 수행되는 개별 환경에서의 소음과 음향을 반영하여 개별 환경별로 인공 신경망 모델을 적응시키고 개별 환경에서 직접 적응된 추론의 수행이 가능한 음성과 음향 인식을 위한 인공 신경망 모델 학습 장치 및 추론 시스템에 관한 것이다."}
{"patent_id": "10-2023-0118700", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "사람이 상황을 인지하기 위한 대표적인 감각으로는 시각과 청각이 있으며, 인공지능을 사용하여 사람의 감각 을 모사한 시스템의 개발이 이루어지고 있다. 영상 정보와 함께 음성 및 음향(이하, '음성' 및 '음향'을 통칭하 여 청각을 통해 인지 가능한 대역폭의 신호인 '오디오'로 지칭할 수 있음) 정보는 상황을 인지하고 상호 작용하 기 위한 효과적인 수단 중 하나이다. 일반적으로 사람이 기계와의 상호 작용을 위해 버튼, 레버 등 물리적 접촉 수단을 주로 사용하였으나, 인공지 능 및 음성 인식 기술의 발전과 함께 음성을 통한 사용자 인터페이스 (Voice User Interface, VUI)는 스마트폰 및 사물인터넷(IoT, Internet of Things) 장치를 위한 주요 인터페이스 기술로서 사용된다. 인공지능 기술의 발전과 고속 네트워크 기술(예: 5G 셀룰러)의 발전으로 스마트폰이나 사물인터넷 장치에서도 음성인식 인터페이스를 제공할 수 있게 되었다. 일반적으로, 장치의 마이크에서 수집한 음성 정보를 클라우드 서버로 전송하고, 서버는 음성 정보를 분석하여, 그 결과를 장치로 응답한다. 장치는 서버의 분석 결과를 바탕 으로 동작하지만, 이러한 절차가 고속의 네트워크 기술을 통해 제공되므로 사용자는 매끄럽게 장치와 상호작용 할 수 있다. 음성 인식 기술은 사용자 인터페이스 및 지능형 서비스를 위해 유망한 기술이지만, 사용 환경에 따라 소음에 의 해 간섭받기 쉽다. 또한, 다양한 환경에 따라 발생하는 소음 및 주변 음향의 패턴과 강도가 상이하므로 장치가 정의된 음성 또는 음향을 정확히 인식하지 못하는 문제가 발생한다. 음성 인식 인터페이스 및 서비스를 위해 사용되는 대표적인 기술은 음성 정보를 분석하여 자동으로 문장으로 변 환해주는 자동 음성 인식(ASR, Automatic Speech Recognition)이다. 최근의 고성능 자동 음성 인식 기술들은 Transformer 모델에 기반하고 있으며, 이는 매우 큰 연산 자원과 메모리 공간을 요구한다. 때문에, 스마트폰이 나 사물인터넷 장치에서 단독으로 동작하기는 어려우며, 고속 네트워크를 통한 클라우드 서버의 연결이 필수적 이다. Transformer 기반의 고성능 자동 음성 인식 기술은 높은 정확도를 제공하며, 대부분의 음성을 판독할 수 있지만, 많은 연산 처리량이 요구된다. 때문에, 마이크로 컨트롤러(MCU, Microcontroller) 또는 어플리케이션 프로세서 (AP, Application Processor)와 같이 고성능 신경망 연산이 어려운 장치는 미리 정의된 특정 단어(키 워드)만을 인식하는 키워드 인식(KWS, Keyword Spotting) 기술을 적용하고 있다. 이러한 키워드 인식 기술은 일반적으로 스마트폰 또는 사물인터넷 장치에서 호출어 또는 기동어 (Wake word)를 인식하기 위한 방법으로 사용 되고 있으나, 장치 제어 명령을 위해서도 사용될 수 있다. 기존의 음성 인식 기술은 다양한 분야에서 적용 가능하지만 해결해야 하는 여러 문제점이 존재한다. 먼저, 음성 인식을 위한 자동 음성 추론 시스템은 수집된 음성 정보를 클라우드 서버로 전송하고 서버에서 분석 과 그 처리 및 추론 결과를 원격의 단말로 전송하여 응답하게 된다. 여기서, 단말로부터 수집된 음성 정보는 사 용자가 전송을 의도치 않은 정보를 포함할 수 있어 프라이버시 또는 비밀 정보가 클라우드 서버에 노출될 수 있 는 문제가 발생한다. 또한, 기존 자동 음성 추론 시스템은 단말이 음성 정보를 수집하고 인터넷을 통해 클라우드 서버로 전송하며 클 라우드 서버가 음성 정보에 대한 추론이 이루어져 네트워크가 단절되는 경우 음성 서비스가 불가능하다. 그에 따라 신뢰도나 안정성이 중요한 어플리케이션에서 문제가 발생한다. 자동 음성 추론 시스템은 클라우드 서버의 동일한 음성 인식 모델을 이용하여 추론을 수행하는 데, 클라우드 서 버는, 음성 외의 소음이나 주변 음향을 가지는 음성 정보에서 음성 인식을 수행하는 경우, 소음이나 주변 음향 의 강도나 패턴에 따라 음성 인식을 위한 인공 신경망 모델의 성능이 매우 달라지는 영향이 발생한다. 더욱이, 음성 정보를 전달하는 단말의 사용 환경에 따라 소음과 주변 음향의 강도, 패턴, 형태는 서로 달라 소 음이나 주변 음향을 반영한 음성 인식 모델의 학습과 그 개선이 용이치 않다. 이와 같이, 기존 알려진 자동 음성 인식 기술이 가지고 있는 다양한 문제점을 개선할 수 있는 음성과 음향 인식 을 위한 인공 신경망 모델 학습 장치 및 추론 시스템이 필용하다."}
{"patent_id": "10-2023-0118700", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은, 상술한 문제점을 해결하기 위해서 안출한 것으로서, 인공 신경망을 이용한 오디오 인식에 있어 수반 되는 프라이버시 또는 비밀 정보의 노출을 없애거나 줄일 수 있는 인공 신경망 모델 학습 장치 및 추론 시스템 을 제공하는 데 목적이 있다. 또한, 본 발명은 네트워크 단절에도 인공 신경망을 이용한 오디오 인식과 그에 따른 필요 조치가 내장형 시스 템을 가지는 개별 환경에서 저비용으로 수행 가능한 인공 신경망 모델 학습 장치 및 추론 시스템을 제공하는 데 목적이 있다. 또한, 본 발명은 주변 소음이나 잡음을 가지는 오디오 데이터를 수집하고 수집된 오디오 데이터를 활용하여 현 장에서 이용 가능한 음성 인식 모델을 학습시켜 실시 환경의 소음에 적응하여 오디오 인식이 가능한 인공 신경 망 모델 학습 장치 및 추론 시스템을 제공하는 데 목적이 있다. 또한, 본 발명은 개별 환경별로 수집되는 오디오 데이터를 이용하여 음성 인식 모델을 학습시키고 개별 환경별 로 학습된 음성 인식 모델을 제공 및 수행하여 소음과 잡음이 서로 다른 다양한 환경에서 적응적으로 강건한 오 디오 인식 효율을 높이고 현장에서의 필요한 조치를 수행할 수 있는 인공 신경망 모델 학습 장치 및 추론 시스 템을 제공하는 데 목적이 있다. 본 발명에서 이루고자 하는 기술적 과제들은 이상에서 언급한 기술적 과제들로 제한되지 않으며, 언급하지 않은"}
{"patent_id": "10-2023-0118700", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 2, "content": "또 다른 기술적 과제들은 아래의 기재로부터 본 발명이 속하는 기술분야에서 통상의 지식을 가진 자에게 명확하 게 이해될 수 있을 것이다."}
{"patent_id": "10-2023-0118700", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 일 양상에 따른 인공 신경망 모델 학습 장치는 추론 단말로부터 로컬 네트워크를 통해 수집되는 오디 오 데이터를 이용하여 추론 단말로 배포되는 인공 신경망 모델을 학습시키고, 제1 추론 단말로부터 수집되는 복 수의 오디오 데이터 중 제1 오디오 데이터들을 이용하여 추론용 제1 인공 신경망 모델을 학습시키는 제1 학습 에이전트 및 제1 추론 단말로부터 수집되는 복수의 오디오 데이터 중 제2 오디오 데이터들을 이용하여 제1 학습 에이전트에서 학습된 제1 인공 신경망 모델을 평가하고 평가 결과에 따라 제1 추론 단말로 학습된 제1 인공 신 경망 모델을 로컬 네트워크를 통해 배포하는 제1 평가 에이전트를 포함한다. 상기한 인공 신경망 모델 학습 장치에 있어서, 제1 학습 에이전트는 제1 추론 단말과 다른 제2 추론 단말에서 로컬 네트워크를 통해 수집되는 복수의 오디오 데이터 중 제1 오디오 데이터들을 이용하여 제2 추론 단말에서의 추론용 제1 인공 신경망 모델을 학습시키고, 제1 평가 에이전트는 제2 추론 단말로부터 수집되는 복수의 오디오 데이터 중 제2 오디오 데이터들을 이용하여 제1 학습 에이전트에서 제2 추론 단말에 대해 학습된 제1 인공 신경 망 모델을 평가하고 평가 결과에 따라 제2 추론 단말로 제2 추론 단말에 대해 학습된 제1 인공 신경망 모델을 로컬 네트워크를 통해 배포하고, 로컬 네트워크는 사설망이다. 상기한 인공 신경망 모델 학습 장치에 있어서, 제1 추론 단말로부터 수집되는 복수의 오디오 데이터 중 제3 오 디오 데이터들을 이용하여 제1 추론 단말 주변에서 발생하는 환경음 제거를 위한 제2 인공 신경망 모델을 학습 시키는 제2 학습 에이전트 및 제1 추론 단말로부터 수집되는 복수의 오디오 데이터 중 제4 오디오 데이터를 이 용하여 제2 학습 에이전트에서 학습된 제2 인공 신경망 모델을 평가하고 평가 결과에 따라 제1 추론 단말로 학 습된 제2 인공 신경망 모델을 로컬 네트워크를 통해 배포하는 제2 평가 에이전트를 더 포함하고, 학습된 제1 인 공 신경망 모델과 제2 인공 신경망 모델은 제1 추론 단말에서 수행되어 제1 추론 단말에서 수집되는 오디오 데 이터에서 주변 환경음을 제거하고 제거된 오디오 데이터에서 목표 음원을 인식한다. 상기한 인공 신경망 모델 학습 장치에 있어서, 인공 신경망 모델 학습 장치는, 제1 추론 단말에서 학습 주기 동 안 수집되는 복수의 오디오 데이터를 이용하여 기존 제1 인공 신경망 모델로부터 파인 튜닝되는 제1 추론 단말 을 위한 제1 인공 신경망 모델을 학습하고, 제2 추론 단말에서 학습 주기 동안 수집되는 복수의 오디오 데이터 를 이용하여 기존 제1 인공 신경망 모델로부터 파인 튜닝되는 제2 추론 단말을 위한 제1 인공 신경 모델을 학습 한다. 상기한 인공 신경망 모델 학습 장치에 있어서, 제1 학습 에이전트는 제1 오디오 데이터들과 미리 저장되어 있는 목표 음원 데이터들로 합성되는 오디오 데이터들을 추론 학습용 오디오 데이터로 수신하고, 제1 평가 에이전트 는 제2 오디오 데이터들과 미리 저장되어 있는 목표 음원 데이터들로 합성된 오디오 데이터들을 추론 평가용 오 디오 데이터로 수신하며, 제2 학습 에이전트는 제3 오디오 데이터들과 미리 저장되어 있는 목표 음원 데이터들 로 합성된 오디오 데이터들을 환경음 제거 학습용 오디오 데이터로 수신하고, 제2 평가 에이전트는 제4 오디오 데이터들과 미리 저장되어 있는 목표 음원 데이터들로 합성된 오디오 데이터들을 환경음 제거 평가용 오디오 데 이터로 수신한다. 또한, 본 발명의 일 양상에 따른 인공 신경망 추론 단말은 오디오 신호를 수신하는 마이크, 로컬 네트워크를 통 해 통신 패킷을 송수신하는 통신 인터페이스, 마이크로부터의 오디오 데이터들과 제1 인공 신경망 모델의 프로 그램을 저장하는 메모리, 대응 신호를 출력하는 출력부 및 메모리의 프로그램의 코드를 수행하는 마이크로 컨트 롤러로서, 마이크를 통해 수집되는 오디오 데이터들을 포함하는 통신 패킷을 통신 인터페이스를 통해 로컬 네트 워크에 연결된 인공 신경망 모델 학습 장치로 전송하고 로컬 네트워크를 통해 인공 신경망 모델 학습 장치로부 터 수집되는 오디오 데이터들에 대한 학습과 평가에 따른 추론용 제1 인공 신경망 모델을 수신하여 메모리에 저 장하고 제1 인공 신경망 모델의 수행에 따라 목표 음원의 인식시에 대응 신호를 출력부로 출력하는, 마이크로 컨트롤러를 포함한다. 상기한 인공 신경망 추론 단말에 있어서, 메모리는 인공 신경망 모델 학습 장치로부터 수신되고 마이크를 통해 수집되는 오디오 데이터들에 대해 학습되는 제2 인공 신경망 모델을 더 저장하고, 제2 인공 신경망 모델의 프로 그램과 제1 인공 신경망 모델의 프로그램을 수행하는 마이크로 컨트롤러는 마이크를 통해 수집되는 오디오 데이 터들을 제2 인공 신경망 모델에 입력하여 환경음이 제거된 오디오 데이터들을 생성하고 환경음이 제거된 오디오 데이터들을 제1 인경 신경망 모델에 입력하여 목표 음원의 인식 여부를 나타내는 추론 결과를 생성하고 목표 음 원의 인식을 나타내는 추론 결과에 따라 대응 신호를 생성하여 출력부로 출력한다. 상기한 인공 신경망 추론 단말에 있어서, 제1 인공 신경망 모델은 경량 합성곱 신경망 모델이고, 마이크로 컨트 롤러는 제1 인공 신경망 모델과 제2 인공 신경망 모델의 프로그램을 직접 수행하는 RISC(reduced instruction set computer) 아키텍처 기반의 컨트롤러이고, 인공 신경망 추론 단말은 임베디드 시스템(embedded system)으로 구현된다. 또한, 본 발명의 일 양상에 따른 인공 신경망 추론 시스템은 상기의 인공 신경망 모델 학습 장치, 학습 장치와 로컬 네트워크를 통해 통신 패킷을 송수신하는 상기의 제1 추론 단말 및 학습 장치와 로컬 네트워크를 통해 통 신 패킷을 송수신하는 상기의 제2 추론 단말을 포함하고, 학습 장치는 제1 추론 단말로부터 수집되는 오디오 데 이터를 이용하여 제1 추론 단말에서 수행되는 제1 인공 신경망 모델을 학습시키고, 제2 추론 단말로부터 수집되 는 오디오 데이터를 이용하여 제2 추론 단말에서 수행되는 제1 인공 신경망 모델을 학습시킨다."}
{"patent_id": "10-2023-0118700", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "상기와 같은 본 발명에 따른 인공 신경망 모델 학습 장치 및 추론 시스템은 인공 신경망을 이용한 오디오 인식 에 있어 수반되는 프라이버시 또는 비밀 정보의 노출을 없애거나 줄일 수 있는 효과가 있다. 또한, 상기와 같은 본 발명에 따른 인공 신경망 모델 학습 장치 및 추론 시스템은 네트워크 단절에도 인공 신경 망을 이용한 오디오 인식과 그에 따른 필요 조치가 내장형 시스템을 가지는 개별 환경에서 저비용으로 수행 가 능한 효과가 있다. 또한, 상기와 같은 본 발명에 따른 인공 신경망 모델 학습 장치 및 추론 시스템은 주변 소음이나 잡음을 가지는 오디오 데이터를 수집하고 수집된 오디오 데이터를 활용하여 현장에서 이용 가능한 음성 인식 모델을 학습시켜 실시 환경의 소음에 적응하여 오디오 인식이 가능한 효과가 있다. 또한, 상기와 같은 본 발명에 따른 인공 신경망 모델 학습 장치 및 추론 시스템은 개별 환경별로 수집되는 오디 오 데이터를 이용하여 음성 인식 모델을 학습시키고 개별 환경별로 학습된 음성 인식 모델을 제공 및 수행하여 소음과 잡음이 서로 다른 다양한 환경에서 적응적으로 강건한 오디오 인식 효율을 높이고 현장에서의 필요한 조 치를 수행할 수 있는 효과가 있다. 본 발명에서 얻을 수 있는 효과는 이상에서 언급한 효과들로 제한되지 않으며, 언급하지 않은 또 다른 효과들은"}
{"patent_id": "10-2023-0118700", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 2, "content": "아래의 기재로부터 본 발명이 속하는 기술분야에서 통상의 지식을 가진 자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2023-0118700", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "상술한 목적, 특징 및 장점은 첨부된 도면을 참조하여 상세하게 후술 되어 있는 상세한 설명을 통하여 더욱 명"}
{"patent_id": "10-2023-0118700", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "확해 질 것이며, 그에 따라 본 발명이 속하는 기술분야에서 통상의 지식을 가진 자가 본 발명의 기술적 사상을 용이하게 실시할 수 있을 것이다. 또한, 본 발명을 설명함에 있어서 본 발명과 관련된 공지 기술에 대한 구체적 인 설명이 본 발명의 요지를 불필요하게 흐릴 수 있다고 판단되는 경우에 그 상세한 설명을 생략하기로 한다. 이하, 첨부된 도면을 참조하여 본 발명에 따른 바람직한 실시 예를 상세히 설명하기로 한다. 도 1은 본 발명에 따른 인공 신경망 추론 시스템의 예를 도시한 도면이다. 도 1의 예와 같이, 인공 신경망 추론 시스템은 학습 장치, 하나 이상의 추론 단말과 학습 장치 와 추론 단말을 연결하는 로컬 네트워크를 포함하여 구성된다. 본 발명에 따른, 인공 신경망 추론 시스템은 학습 장치와 추론 단말이 로컬 네트워크를 통해 서 로 연결되고 로컬 네트워크는 인터넷과 같은 공중망과 분리된(예를 들어, 게이트웨이나 방화벽을 통해 분 리된) 사설망(private network)으로 구현된다. 로컬 네트워크는 이더넷, 지그비, 와이파이, 블루투스 등의 통신 프로토콜을 이용하여 구성되는 사설망이다. 본 발명의 인공 신경망 추론 시스템은 추론 단말이 학습 장치로부터 배포된 인공 신경망 모델을 직접 수행하여 수집되는 오디오 데이터로부터 목표 음원(target audio source)을 인식하고 목표 음원의 인식에 따라 필요한 대응 조치를 취할 수 있도록 구성된다. 추론 단말은 바람직하게는 임베디드 시스템(embeddedsystem)(내장형 시스템)으로 구현된다. 추론 단말은 학습 장치에 의해서 배포되고 이 추론 단말의 주변 환경음을 반영하여 학습되는 인 공 신경망 모델의 프로그램을 수행하고 특정 목표 음원( 데이터)을 인식하고 목표 음원의 인식에 따라 설정된 특정 대응 조치(예를 들어, 경고음 출력, 액츄에이터 동작 정지, 도어 오픈 등)를 수행할 수 있다. 추론 단말 은 임베디드 시스템의 형태로 구현되어 특정 장소나 위치에 설치된다. 다수의 추론 단말 각각은 학습 장치와 로컬 네트워크를 통해 통신 패킷을 송수신할 수 있도록 구성된다. 본 발명의 인공 신경망 추론 시스템은 다양한 현장과 장소에서 적용될 수 있다. 예를 들어, 인공 신경망 추론 시스템은 지하철 역사에 설치될 수 있다. 추론 단말은 지하철의 스크린도어에 설치되어 미리 정해진 특정 목표 음원(예를 들어, \"열어줘\" 등)의 인식에 따라 연결된 액츄에이터를 구동하여 설치된 스크린도어를 오픈할 수 있다. 예를 들어, 인공 신경망 추론 시스템은 (자동화) 공장에 설치될 수 있다. 추론 단말은 공장 상의 각종 자 동화 라인에 설치되고 자동화 라인의 긴급 정지를 위한 미리 정해진 특정 목표 음원(예를 들어, \"정지\" 등)의 인식에 따라 자동화 라인의 정지를 위한 액츄에이터를 구동하거나 비상 신호를 발생시킬 수 있다. 예를 들어, 인공 신경망 추론 시스템은 가정 내 침입 감지와 보안 서비스를 위해 설치될 수 있다. 가정 내 특정 위치에 설치되는 추론 단말은 유리창 깨지는 소리, 걸쇠 부서지는 소리, 목재 부러지는 소리 등의 특정 목 표 음원의 인식에 따라 비상음을 발생시키고 외부 침입의 발생을 나타내는 신호를 유무선 네트워크를 통해 출력 할 수 있다. 본 발명의 인공 신경망 추론 시스템은 예로 든 적용 사례 외에 다양한 형태와 환경에서 이용 가능 하다. 본 발명의 인공 신경망 추론 시스템의 추론 단말들 각각은 학습에 이용되는 주변 환경음을 나타내거나 포 함하는 오디오 데이터를 수집하고 수집된 오디오 데이터들을 로컬 네트워크를 통해 학습 장치로 전달 하고 이러한 오디오 데이터로 학습된 인공 신경망 모델을 이 추론 단말이 수신하여 주변 환경의 소음에 적 응적으로 특정 목표 음원을 인식할 수 있도록 구성된다. 시끄러운 환경의 추론 단말은 시끄러운 소음에 적응적으로 동작하여 목표 음원의 인식이 필요하다. 추론 단말이 설치되는 환경에 따라 이러한 주변음(소음)은 서로 달라질 수밖에 없어 추론 단말별로 주변 환경음에 적응적으로 동작하는 인공 지능 모델의 사용이 필수적이다. 추론 단말에 대해서는 도 4 이하에서 상세히 살펴보도록 한다. 학습 장치는 추론 단말에서 수행되는 인공 신경망 모델을 학습시키고 학습된 인공 신경망 모델을 로 컬 네트워크를 통해 추론 단말로 배포한다. 학습 장치는 추론 단말에서 수집되는 주변 소 음(환경음)을 학습 데이터로 이용하여 설정된 목표 음원을 인식할 수 있도록 인공 신경망 모델을 파인 튜닝 (fine tunning)(또는 미세 조정)하고 파인 튜닝된 인공 신경망 모델을 추론 단말로 로컬 네트워크를 통해 전송할 수 있다. 전송되는 인공 신경망 모델은 바람직하게는 추론 단말에 의해 직접 수행된다. 학습 장치는 개별 추론 단말로부터 수집되는 오디오 데이터를 이용하여 개별 추론 단말에서 수행되는 인공 신경망 모델을 학습시키도록 바람직하게 구성된다. 학습 장치는 개인용 컴퓨터로 구현되거나 워크 스테이션 등으로 구현될 수 있다. 학습 장치는 개별 또는 그룹별 추론 단말에서 수집된 오디오 데이터들을 학습 데이터로 이용하여 개별 또는 그룹별 추론 단 말에서 수행되는 인공 신경망 모델을 학습시키고 학습 모델의 평가에 따라 개별 또는 그룹별 추론 단말 로 배포할 수 있도록 구성된다. 설계 변형에 따라, 학습 장치가 추론 단말 내에 내장될 수도 있 다. 학습 장치에 대해서는 도 2 및 도 3과 도 6을 통해 좀 더 상세히 살펴보도록 한다. 도 2는 인공 신경망 모델 학습 장치의 블록도를 도시한 도면이다. 도 2의 학습 장치의 블록도는 개념적인 HW 블록도를 나타내고 학습 장치는 도 2에 도시되지 않은 다 른 HW 블록을 더 가질 수 있다. 예를 들어, 학습 장치는 입출력 블록을 더 포함하여 구성될 수 있다. 도 2의 학습 장치는 로컬 네트워크에 연결되어 추론 단말에서 이용되는 인공 신경망 모델의 학 습에 이용되며 고성능 클라우드 서버 대신에 개인용 컴퓨터나 중/저 사양의 워크스테이션으로 구현될 수 있다.학습 장치는 로컬 네트워크를 통해 수집되는 추론 단말로부터의 오디오 데이터를 이용하여 해당 추론 단말로 배포되는 인공 신경망 모델을 학습시키도록 구성된다. 도 2의 학습 장치는 통신 모듈과 저장 모듈과 제어 모듈을 포함하여 구성되고 각각의 모듈 들은 보드 상에 구현되거나 칩셋 및/또는 전자 회로로 구현될 수 있다. 통신 모듈은 로컬 네트워크와 통신을 수행하기 위한 칩셋, 회로 및/또는 보드를 포함하여 구성된다. 예를 들어, 통신 모듈은 로컬 네트워크의 설정된 통신 프로토콜을 수행하기 위한 물리 계층 및/또는 링크 계층의 인터페이스, 칩셋, 회로, 안테나 등을 포함하여 구성될 수 있다. 통신 모듈은 적어도 추론 단 말과 통신이 가능하도록 구성되고 나아가 인터넷 등의 공중망과 통신이 더 가능하도록 구성될 수 있다. 통 신 모듈은 이더넷, 지그비, 와이파이, 블루투스 등의 통신 프로토콜에 따른 통신 패킷을 적어도 송수신할 수 있도록 구성된다. 저장 모듈은 휘발성 메모리, 비휘발성 메모리 및/또는 HDD 등의 대용량 저장매체를 포함하여 각종 데이터 와 프로그램을 저장한다. 저장 모듈은 제어 모듈에서 수행되는 각종 프로그램, 추론 단말로 전 달되는 각종 인공 신경망 모델(의 프로그램)들, 추론 단말로부터 수신되는 각종 오디오 데이터들을 저장한 다. 저장 모듈은 각종 데이터, 인공 신경망 모델, 추론 단말로부터 수집되는 오디오 데이터를 관리하 기 위한 데이터베이스를 포함(저장) 할 수 있다. 제어 모듈은 하나 이상의 CPU, 그래픽 카드를 포함한다. 제어 모듈은 CPU나 그래픽 카드에서 수행되 는 프로그램을 저장 모듈에서 로딩하고 프로그램의 수행에 따라 학습 장치를 제어하고 관리한다. 제 어 모듈은 적어도 추론 단말을 위한 하나 이상의 인공 신경망 모델을 학습시키고 평가하며 평가 결과 에 따라 추론 단말로 학습된 인공 신경망 모델을 로컬 네트워크(에 연결되는 통신 모듈)를 통해 배포할 수 있도록 구성된다. 제어 모듈은 저장 모듈의 프로그램(들)을 CPU나 그래픽 카드에서 수행하 여 서로 연계된 하나 이상의 인공 신경망 모델을 학습시키고 학습된 하나 이상의 인공 신경망 모델을 개별 또는 그룹별 추론 단말로 전달할 수 있다. 도 3은 본 발명에 따른 인공 신경망 모델 학습 장치의 예시적인 기능 블록도를 도시한 도면이다. 도 3은 기능 블록도는 저장 모듈에 저장되어 있는 프로그램(들)의 제어 모듈에 의한 수행으로 바람직 하게 이루어진다. 기능 블록들은 개별 프로그램으로 구성되거나 일부 기능 블록들은 하나의 통합 프로그램으로 구성될 수도 있다. 프로그램은 다양한 형태로 구현될 수 있고 예를 들어, 라이브러리, 링크 가능한 프로그램 모 듈, 실행 파일 등 다양한 형태로 구현될 수 있다. 도 3에 따르면, 학습 장치는 시스템 관리 에이전트, 하나 이상의 학습 에이전트, 하나 이상의 평가 에이전트, 학습 데이터 관리 에이전트, 통신 에이전트 등을 포함하여 구성된다. 학습 장치는 바 람직하게는 적어도 두 개의 학습 에이전트(157, 161)와 적어도 두 개의 평가 에이전트(159, 163)를 가진다. 이하, 두 개의 학습 에이전트 중 특정 하나의 학습 에이전트를 '제1 학습 에이전트'라 지칭하고 다른 특정 하나 의 학습 에이전트를 '제2 학습 에이전트'라 지칭한다. 또한, 두 개의 평가 에이전트 중 제1 학습 에이전트(15 7)의 인공 신경망 모델을 평가하는 특정 하나의 평가 에이전트를 '제1 평가 에이전트'라 지칭하고 제2 학습 에 이전트의 인공 신경망 모델을 평가하는 특정 다른 하나의 평가 에이전트를 '제2 평가 에이전트'라 지칭한 다. 시스템 관리 에이전트는 학습 장치와 나아가 인공 신경망 추론 시스템을 제어하고 관리한다. 시스템 관리 에이전트는 로컬 네트워크로 연결되는 추론 단말들의 제어 정책을 통신 에이전트를 통해 배포한다. 예를 들어, 시스템 관리 에이전트는 오디오 데이터의 학습 주기, 수집 주기, 전송 주기 등 의 수집 관련 제어 정책을 각 추론 단말로 전송할 수 있다. 또한, 시스템 관리 에이전트는 다양한 발화자의 특성을 반영한 목표 음원 데이터들로 사전에 학습되고 목 표 음원의 인식을 위한 기본(base) 인공 신경망 모델(이하 '제1 인공 신경망 모델'이라 함)과, 추론 단말 에서 수신되는 일련의 오디오 데이터들에서 추론 단말 주변의 환경음(소음)을 제거하기 위한 기본(base) 인공 신경망 모델(이하 '제2 인공 신경망 모델'이라 함)을 구성하고 기본 제1 인공 신경망 모델을 제1 학습 에 이전트에 제공하고 소음 제거용 기본 제2 인공 신경망 모델을 제2 학습 에이전트에 제공한다. (기본) 제1 인공 신경망 모델은 바람직하게는 경량 합성곱 신경망(LightWeighted Convolutional Neural Network) 모델이고, 기본 제1 인공 신경망 모델과 기본 제2 인공 신경망 모델은 시스템 관리자 등에 의해 사전 에 미리 준비된다. (기본) 제2 인공 신경망 모델은 경량 합성곱 신경망 모델이거나 알려져 있거나 알려질 다른 유형의 인공 신경망 모델일 수 있다. 추론 단말에서의 인식 대상인 목표 음원(target audio source)은 추론 시스템의 적용 환경 예에 따라 미리 결정되고 특정 단어(음성 키워드)의 음성을 나타내거나 특정 소리를 나타낼 수 있다. 목표 음원은 예를 들어, '열어줘', '정지' 등의 단어를 나타내거나 유리창 깨지는 소리, 걸쇠 부서지는 소리, 목재 부러지는 소리 등을 나타낼 수 있다. 목표 음원 데이터는 목표 음원을 오디오 데이터로 나타내는 데이터이다. 시스템 관리 에이전트는 다양한 발화자와 다양한 환경에서 발생하고 동일한 목표 음원을 나타내는 목표 음원 데이터들을 다수 개 미리 가지고 학습 에이전트(157, 161)로 제공할 수 있다. 통신 에이전트는 로컬 네트워크를 통해 추론 단말과 각종 데이터와 제어 정책 등을 송수신한다. 예를 들어, 통신 에이전트는 시스템 관리 에이전트로부터 수신되는 특정 추론 단말의 수집 관련 제어 정책을 로컬 네트워크를 통해 특정 추론 단말로 전송하고 추론 단말로부터의 수집된 오디 오 데이터를 수신하고 수신된 수집 오디오 데이터를 학습 데이터 관리 에이전트로 전달할 수 있다. 학습 데이터 관리 에이전트는 제1 인공 신경망 모델과 제2 인공 신경망 모델의 학습에 이용되는 데이터를 관리한다. 학습 데이터 관리 에이전트는 저장 모듈의 데이터베이스에 추론 단말에서 수집된 오 디오 데이터를 추론 단말(예를 들어, 추론 단말의 ID)별로 저장한다. 설계 변형예에 따라, 추론 단말 그룹별로 추론 단말 그룹 내의 추론 단말에서 수집된 오디오 데이터를 해당 추론 단말 그룹(의 그룹 ID)에 매칭시켜 저장한다. 추론 단말은 설치 위치에 따라 그룹핑 될 수 있다. 예를 들어, 설정된 거리(예 를 들어, 10 m) 이내의 추론 단말은 하나의 그룹으로 그룹핑되고 추론 단말 그룹별로 학습 및 평가와 배포 가 이루어질 수도 있다. 시스템 관리 에이전트에 의해 설정되는 (특정) 추론 단말(의 그룹)에 대한 학습 주기가 도래함에 따 라, 학습 데이터 관리 에이전트는 학습 주기가 도래한 추론 단말(의 그룹)에서 수집된 오디오 데이터 들을 학습용 오디오 데이터(들)와 평가용 오디오 데이터(들)로 분류한다. 분류 비율(예를 들어, 1:1 등)이나 데 이터베이스의 오디오 데이터의 저장기간과 연계되는 학습 주기 등은 시스템 관리 에이전트에 의해 설정될 수 있다. 학습 데이터 관리 에이전트는 분류된 학습용 오디오 데이터(들)와 인식 대상인 목표 음원 데이터(들)를 제 1 학습 에이전트와 제2 학습 에이전트로 제공하고 분류된 평가용 오디오 데이터(들)와 인식 대상 목 표 음원 데이터(들)를 제1 평가 에이전트와 제2 평가 에이전트로 제공한다. 분류된 학습용 오디오 데이터(들)와 인식 대상이자 저장 모듈에 미리 저장되어 있는 목표 음원 데이터 (들)는 학습 데이터 관리 에이전트에 의해 또는 제1 학습 에이전트와 제2 학습 에이전트에 의해 오디오 합성된다. 예를 들어, 제1 학습 에이전트와 제2 학습 에이전트는 학습 데이터 관리 에이전트 에 의해 합성된 오디오 데이터들을 추론 학습용 오디오 데이터와 환경음 제거 학습용 오디오 데이터로 학 습 데이터 관리 에이전트로부터 수신할 수 있다. 분류된 평가용 오디오 데이터(들)와 인식 대상 목표 음원 데이터(들)는 학습 데이터 관리 에이전트에 의해 또는 제1 평가 에이전트와 제2 평가 에이전트에 의해 오디오 합성된다. 예를 들어, 제1 평가 에이전 트와 제2 평가 에이전트는 학습 데이터 관리 에이전트에 의해 합성된 오디오 데이터들을 추론 평가용 오디오 데이터와 환경음 제거 평가용 오디오 데이터로 학습 데이터 관리 에이전트로부터 수신할 수 있다. 다양한 설계 예에 따라, 제1 학습 에이전트와 제2 학습 에이전트에 제공되는 분류된 학습용 오디오 데이터(들)는 동일하거나 다를 수 있다. 또한, 제1 평가 에이전트와 제2 평가 에이전트에서 제공되는 분류된 평가용 오디오 데이터(들)는 동일하거나 다를 수 있다. 제1 학습 에이전트는 추론 단말(의 그룹)별로 수집되는 오디오 데이터들 중에서 분류된 학습용 오디 오 데이터들(이하 '제1 오디오 데이터'라고도 함)을 이용하여 상기 추론 단말(의 그룹)의 제1 인공 신경망 모델을 학습시킨다. 제1 학습 에이전트는 학습 데이터 관리 에이전트로부터 제1 오디오 데이터들과 인식 대상인 목표 음원의 목표 음원 데이터(들)를 수신하고 합성되는 제1 오디오 데이터들과 목표 음원 데이터 들을 제1 인공 신경망 모델에 입력하고 제1 인공 신경망 모델의 파라미터(예를 들어, 픽쳐맵)의 (파인) 튜닝을통해 상기 추론 단말(의 그룹)의 제1 인공 신경망 모델을 학습시킨다. 제1 학습 에이전트는 상기 추 론 단말의 학습 주기의 도래에 따라 수집된 오디오 데이터(들)를 이용하여 제1 인공 신경망 모델을 학습시 킬 수 있다. 또한, 제1 학습 에이전트는 다른 특정 추론 단말(의 그룹)별로 수집되는 오디오 데이터들 중에서 분 류된 제1 오디오 데이터를 이용하여 상기 다른 특정 추론 단말(의 그룹)의 제1 인공 신경망 모델을 학습시 킨다. 제1 학습 에이전트는 학습 데이터 관리 에이전트로부터 제1 오디오 데이터들과 인식 대상인 목 표 음원의 목표 음원 데이터들을 수신하고 합성된 제1 오디오 데이터들과 목표 음원 데이터들을 다른 특정 추론 단말(의 그룹)의 제1 인공 신경망 모델에 입력하고 제1 인공 신경망 모델의 파라미터(예를 들어, 픽쳐맵) 의 (파인) 튜닝을 통해 상기 다른 특정 추론 단말(의 그룹)의 제1 인공 신경망 모델을 학습시킨다. 제1 학 습 에이전트는 상기 다른 특정 추론 단말의 학습 주기의 도래에 따라 수집된 오디오 데이터(들)를 이 용하여 상기 다른 특정 추론 단말의 제1 인공 신경망 모델을 학습시킬 수 있다. 이와 같이, 제1 학습 에이전트는 개별 추론 단말(의 그룹)별로 수집되는 오디오 데이터들을 이용하여 개별 추론 단말(의 그룹)에서 수행되는 제1 인공 신경망 모델을 학습시킨다. 학습된 제1 인공 신경망 모델 을 수행하는 개별 추론 단말(의 그룹)은 주변 환경음(소음 등)에 동적으로 적응되고 개별 추론 단말 (의 그룹)에서 발생하는 여러 유형의 다른 주변 환경음에도 불구하고 목표 음원 데이터를 용이하게 인식 가능하 다. 제1 평가 에이전트는 추론 단말(의 그룹)별로 수집되는 오디오 데이터들 중에서 분류된 평가용 오디 오 데이터들(이하 '제2 오디오 데이터'라고도 함)을 이용하여 추론 단말(의 그룹)의 학습이 이루어진 제1 인공 신경망 모델을 평가한다. 제1 평가 에이전트는 평가 결과에 따라 상기 추론 단말(의 그룹)로 학 습된 제1 인공 신경망 모델을 (통신 에이전트를 경유해서) 로컬 네트워크를 통해 배포한다. 제1 평가 에이전트는 학습 데이터 관리 에이전트로부터 제2 오디오 데이터들과 목표 음원 데이터들을 수신하고 합성된 제2 오디오 데이터들과 목표 음원 데이터들을 학습된 제1 인공 신경망 모델에 입력하고 인식 결과를 제1 인공 신경망 모델로부터 수신한다. 제1 평가 에이전트는 다수의 합성된 오디오 데이터를 제1 인공 신경망 모델에 입력하고 인식 확률을 나타내는 인식 결과를 수신할 수 있다. 제1 평가 에이전트는 (다수의) 인식 확률이 설정된 임계 확률을 초과하는 경우 학습된 제1 인공 신경망 모델이 개선된 것으로 판단하 여 오디오 수집에 이용된 추론 단말(의 그룹)으로 배포할 수 있다. 또한, 제1 평가 에이전트는 다른 특정 추론 단말(의 그룹)별로 수집되는 오디오 데이터들 중에서 제2 오디오 데이터들을 이용하여 다른 특정 추론 단말(의 그룹)에 대해 학습이 이루어진 제1 인공 신경망 모델 을 평가한다. 제1 평가 에이전트는 평가 결과에 따라 상기 다른 특정 추론 단말(의 그룹)로 학습된 제1 인공 신경망 모델을 (통신 에이전트를 경유해서) 로컬 네트워크를 통해 배포한다. 제1 평가 에이전트는 학습 데이터 관리 에이전트로부터 다른 특정 추론 단말(의 그룹)에서 수집 된 제2 오디오 데이터들과 인식 대상인 목표 음원의 목표 음원 데이터들을 수신하고 합성된 제2 오디오 데이터 들과 목표 음원 데이터들을 학습된 제1 인공 신경망 모델에 입력하고 인식 결과를 제1 인공 신경망 모델로부터 수신한다. 제1 평가 에이전트는 다수의 합성된 오디오 데이터를 제1 인공 신경망 모델에 입력하고 인식 확 률을 나타내는 인식 결과를 수신할 수 있다. 제1 평가 에이전트는 (다수의) 인식 확률이 설정된 임계 확률 을 초과하는 경우 학습된 제1 인공 신경망 모델이 개선된 것으로 판단하여 오디오 수집에 이용된 다른 특정 추 론 단말(의 그룹)으로 배포할 수 있다. 여기서, 수집된 오디오 데이터들의 오디오 합성시 합성에 입력되는 수집된 오디오 데이터들(제1 오디오 데이터 및 제2 오디오 데이터)의 신호 강도는 변경될 수 있다. 원래의 수집된 오디오 데이터의 신호 강도보다 낮은(줄 인, 예를 들어, 1/2, 1/3 등) 신호 강도로 수집된 오디오 데이터(제1 오디오 데이터 및 제2 오디오 데이터)와 목표 음원 데이터를 합성하고 합성된 오디오 데이터로 제1 학습 에이전트와 제1 평가 에이전트가 학 습하고 평가할 수 있다. 이와 같이, 제1 평가 에이전트는 각각의 추론 단말별로 해당 추론 단말을 위한 제1 인공 신경망 모델을 해당 추론 단말에서 수집되고 주변 환경음을 가지는 오디오 데이터로 평가하여 추론 단말의 인식 성능의 개선이 가능하다. 또한, 주변 환경음의 변화가 발생하는 경우에도 동적인 인식 성능의 개선이 가능 하다. 제2 학습 에이전트는 추론 단말(의 그룹)별로 수집되는 오디오 데이터들 중에서 분류된 학습용 오디 오 데이터들(이하 '제3 오디오 데이터'라고도 함) 이용하여 상기 추론 단말(의 그룹)의 주변에서 발생하는 환경음 제거를 위한 제2 인공 신경망 모델을 학습시킨다. 제3 오디오 데이터들은 제1 오디오 데이터들과 동일하 거나 다를 수 있다. 제2 학습 에이전트는 제3 오디오 데이터와 목표 음원 데이터로 합성된 오디오 데이터를 상기 추론 단말 (의 그룹)의 제2 인공 신경망 모델에 입력하고 제2 인공 신경망 모델의 파라미터(예를 들어, 픽쳐맵)의 (파인) 튜닝을 통해 상기 추론 단말(의 그룹)의 제2 인공 신경망 모델을 학습시킨다. 제2 학습 에이전트 는 상기 추론 단말의 학습 주기의 도래에 따라 수집된 오디오 데이터(들)를 이용하여 제2 인공 신경 망 모델을 학습시킬 수 있다. 제2 학습 에이전트는 다른 특정 추론 단말(의 그룹)에 대해서도 목표 음원 데이터들과 상기 다른 특 정 추론 단말(의 그룹)에서 수집된 제3 오디오 데이터들과 합성된 오디오 데이터를 이용하여 상기 다른 특 정 추론 단말(의 그룹)의 제2 인공 신경망 모델을 상기 다른 특정 추론 단말(의 그룹)의 학습 주기의 도래에 따라 학습시킬 수 있다. 제2 평가 에이전트는 추론 단말(의 그룹)별로 수집되는 오디오 데이터들 중에서 분류된 평가용 오디 오 데이터들(이하 '제4 오디오 데이터'라고도 함)을 이용하여 추론 단말(의 그룹)의 학습이 이루어진 제2 인공 신경망 모델을 평가한다. 제2 평가 에이전트는 평가 결과에 따라 상기 추론 단말(의 그룹)로 학 습된 제2 인공 신경망 모델을 (통신 에이전트를 경유해서) 로컬 네트워크를 통해 배포한다. 제4 오디 오 데이터들은 제2 오디오 데이터들과 동일하거나 상이할 수 있다. 제2 평가 에이전트는 학습 데이터 관리 에이전트로부터 제4 오디오 데이터들과 목표 음원 데이터들을 수신하고 합성된 제4 오디오 데이터들과 목표 음원 데이터들을 제2 학습 에이전트에 의해 학습된 제2 인공 신경망 모델에 입력하고 인식 결과를 제2 인공 신경망 모델로부터 수신한다. 제2 평가 에이전트는 다수의 합성된 오디오 데이터를 제2 인공 신경망 모델에 입력하고 인식 확률을 나타내는 인식 결과를 수신할 수 있다. 제2 평가 에이전트는 (다수의) 인식 확률이 설정된 임계 확률을 초과하는 경우 학습된 제2 인공 신경망 모 델이 개선된 것으로 판단하여 오디오 수집에 이용된 추론 단말(의 그룹)로 배포할 수 있다. 또한, 제2 평가 에이전트는 다른 특정 추론 단말(의 그룹)별로 수집되는 오디오 데이터들 중에서 제4 오디오 데이터들을 이용하여 다른 특정 추론 단말(의 그룹)에 대해 학습이 이루어진 제2 인공 신경망 모델 을 인식 결과에 따라 평가하고 로컬 네트워크를 통해 배포한다. 제1 학습 에이전트, 제2 학습 에이전트, 제1 평가 에이전트 및 제2 평가 에이전트와 제1 인공 신경망 모델과 제2 인공 신경망 모델은 인공 신경망 개발이 가능한 소프트웨어 플랫폼을 이용하여 개발 및 구현된다. 예를 들어, 학습 장치는 텐서 플로 플랫폼, 딥 러닝 라이브러인 PYTORCH, SPeechBrain 등을 이 용하여 제1 학습 에이전트, 제2 학습 에이전트, 제1 평가 에이전트 및 제2 평가 에이전트 를 구현하고 제1 인공 신경망 모델과 제2 인공 신경망 모델을 구현하고 학습시킬 수 있다. 도 3의 기능 블록들을 통해, 학습되는 제1 인공 신경망 모델과 제2 인공 신경망 모델은 해당 추론 단말에 배포되고 해당 추론 단말에서 수행된다. 제1 인공 신경망 모델과 제2 인공 신경망 모델을 배포 받고 수행 하는 추론 단말은 마이크를 통해 수집되는 오디오 데이터에서 주변 환경음을 제거하고 제거된 오디오 데이터에서 목표 음원을 인식할 수 있다. 도 3과 같이, 학습 장치는 목표 음원 인식을 위한 제1 인공 신경망 모델과 잡음 등을 제거하기 위한 제2 인공 신경망 모델을 학습시키고 추론 단말로 배포한다. 제1 인공 신경망 모델과 제2 인공 신경망 모델을 분리시킴으로써 예를 들어, 목표 음원이 달라지는 경우, 성능이 이미 개선된 제2 인공 신경망 모델을 기존에 적 용하면서 제1 인공 신경망 모델에 대해서만 집중 학습시켜 목표 음원 인식을 위한 성능 유지와 빠른 개선을 가 져올 수 있다. 이와 같이, 학습 장치는 하나의 추론 단말에서 학습 주기 동안 수집되는 오디오 데이터들을 이용하여 기존에 수행되는 제1 인공 신경망 모델 파인 튜닝을 통해 상기 하나의 추론 단말을 위한 제1 인공 신경망 모델을 학습하고 상기 하나의 추론 단말로 배포한다. 또한, 학습 장치는 다른 추론 단말에서 학 습 주기 동안 수집되는 오디오 데이터들을 이용하여 기존에 수행되는 제1 인공 신경망 모델의 파인 튜닝을 통해 상기 다른 추론 단말을 위한 제1 인공 신경망 모델을 학습하고 상기 다른 추론 단말로 배포한다. 이 에 따라, 학습 장치는 추론 단말의 설치 환경에 따라 야기되거나 발생하는 각종 유형의 소음을 제거 하거나 적응하여 음성 인식이 가능하다.도 4는 추론 단말의 예시적인 하드웨어 블록도를 도시한 도면이다. 도 4의 예와 같이, 추론 단말은 마이크, 통신 인터페이스, 출력부, 메모리 및 마이크 로 컨트롤러를 포함하여 구성된다. 추론 단말은 도 4에 도시되지 않은 다른 블록을 더 포함할 수 있 다. 추론 단말은 (소형의) 내장형 시스템으로 구현되고 인공 신경망 추론 시스템이 운영되는 특정 위치나 장소에 설치될 수 있다. 도 4의 하드웨어 블록을 간단히 살펴보면, 마이크는 오디오 신호를 수신한다. 마이크는 진동 신호를 전기 신호로 변환하고 변환된 전기 신호를 아날로그 오디오 신호로 출력할 수 있다. 통신 인터페이스는 로컬 네트워크를 통해 통신 패킷을 송수신한다. 통신 인터페이스는 이더넷, 지그비, 와이파이 및/또는 블루투스 등의 통신 프로토콜의 구현에 필요한 통신칩셋(예를 들어, 파이칩)과 회로, 안테나, 커넥터 등을 포함하여 로컬 네트워크를 통해 통신 패킷을 송수신할 수 있다. 메모리는 비휘발성 메모리와 휘발성 메모리를 더 포함하여 각종 데이터와 프로그램을 저장한다. 예를 들어, 메모리는 마이크를 통해 수신되는 오디오 데이터들과 마이크로 컨트롤러에서 수행되는 제 1 인공 신경망 모델의 프로그램과 제2 인공 신경망 모델의 프로그램을 저장하고 그 외 관리(제어) 프로그램을 더 저장할 수 있다. 본 추론 단말의 마이크를 통해 수집되고 학습 장치로 전송되는 오디오 데이터로 학습된 제1 인 공 신경망 모델의 프로그램과 제2 인공 신경망 모델의 프로그램은 학습 장치로부터 수신되어 메모리 에 저장되고 마이크로 컨트롤러가 수행한다. 학습된 제1 인공 신경망 모델의 프로그램과 제2 인공 신경망 모델의 프로그램을 수행하는 마이크로 컨트롤러는 마이크로부터 수신되는 오디오 데이터들에서 목표 음원을 인식할 수 있도록 구성된다. 출력부는 마이크로 컨트롤러에 연결되어 마이크로 컨트롤러로부터 수신되는 대응 신호를 출력한 다. 출력부는 스피커, 액츄에이터를 동작시키기 위한 회로 및/또는 도어를 오픈하기 위한 회로 등을 가지 고 해당 기기를 제어하기 위한 제어 신호를 마이크로 컨트롤러로부터 수신하고 해당 기기를 제어하기 위한 대응 신호를 출력한다. 출력부는 예를 들어, 경고음을 출력하거나 구동중이 모터 등의 액츄에이터의 동작을 정지하기 위한 신호를 출력하거나 닫혀 있는 도어를 오픈하기 위한 신호를 출력할 수 있다. 설계 예와 다양한 응용 예에 따라, 출력부 는 다양한 형태로 구현될 수 있다. 마이크로 컨트롤러는 추론 단말을 제어한다. 마이크로 컨트롤러는 메모리의 프로그램 코드 를 수행하도록 구성된다. 마이크로 컨트롤러는 인공 신경망의 수행에 특화된 GPU(Graphics Processing Unit)나 NPU(Neural Processing Unit)나 스마트폰에 탑재되는 AP(Application Processor) 대신에 저사양의 컨 트롤러로 구현된다. 마이크로 컨트롤러는 RISC(reduced instruction set computer) 아키텍처 기반의 컨트롤러로서 로드/스토 어 명령어에 기반하여 프로그램의 코드를 ALU(Arithmetic Logic Unit)에서 수행할 수 있도록 구현된다. 마이크 로 컨트롤러는 메모리의 제1 인공 신경망 모델과 제2 인공 신경망 모델의 프로그램을 로드/스토어 명 령어 기반으로 (ALU 에서) 직접 수행하는 ARM 프로세서 IP를 내장(포함)하거나 Xtensa 아키텍처 IP를 내장할 수 있다. 예를 들어, 마이크로 컨트롤러는 저사양의 32비트 ARM 프로세서나 Xtensa 프로세서를 내장하고 RTOS(Real- Time Operating System) 환경하에서 제1 인공 신경망 모델과 제2 인공 신경망 모델의 프로그램을 ARM 프로세서 나 Xtensa 프로세서에서 수행하여 마이크에서의 오디오 데이터에서 잡음(주변 환경음)을 제거하고 목표 음 원을 인식할 수 있도록 구성된다. 이러한 추론 단말의 구성에 따라, 추론 단말은 저렴하게 구현 가능 하고 클라우드 서버나 원격의 서버를 이용하지 않고서도 경제적인 비용과 효율적으로 음성 인식이 가능하다. 도 5 및 도 6에서, 추론 단말(의 마이크로 컨트롤러)에서 이루어지는 목표 음원 인식 관련 구체적인 제어를 좀 더 살펴보도록 한다. 도 5는 추론 단말의 예시적인 기능 블록도를 도시한 도면이다. 도 5에 따르면, 추론 단말은 오디오 수신 에이전트, 오디오데이터 수집 에이전트, 통신 에이전 트, 제1 인공신경망모델 수행 에이전트, 제2 인공신경망모델 수행 에이전트 및 출력 관리 에이 전트를 포함하여 구성된다. 오디오 수신 에이전트, 오디오데이터 수집 에이전트, 통신 에이전트, 제1 인공신경망모델 수행 에이전트, 제2 인공신경망모델 수행 에이전트 및 출력 관리 에이전트는 개별 프로그램으로 구성 되거나 일부 기능 블록들은 하나의 통합 프로그램으로 구성될 수도 있다. 프로그램은 다양한 형태로 구현될 수 있고 예를 들어, 라이브러리, 링크 가능한 프로그램 모듈, 실행 파일 등 다양한 형태로 구현될 수 있다. 오디오 수신 에이전트, 오디오데이터 수집 에이전트, 통신 에이전트, 제1 인공신경망모델 수행 에이전트, 제2 인공신경망모델 수행 에이전트 및 출력 관리 에이전트들과 나아가 제1 인공 신경 망 모델의 프로그램과 제2 인공 신경망 모델의 프로그램은 추론 단말의 마이크로 컨트롤러에( 의해) 서 수행된다. 오디오 수신 에이전트는 마이크를 통해 오디오 데이터를 수신한다. 오디오 수신 에이전트는 제2 인공신경망모델 수행 에이전트로 샘플링 주기에 따른 일련의 오디오 데이터들을 제공하고 오디오데이터 수 집 에이전트로 샘플링 주기에 따른 일련의 오디오 데이터들을 제공한다. 통신 에이전트는 로컬 네트워크를 액세스하는 통신 인터페이스를 통해 학습 장치와 통신 패킷을 송수신한다. 통신 에이전트(의 마이크로 컨트롤러)는 학습 장치로부터 수집 주기, 전송 주기 등의 수집 관련 제어 정책을 수신하고 수신된 수집 관련 제어 정책을 오디오데이터 수집 에이전트로 전달하고 학습된 제1 인공 신경망 모델의 프로그램을 제1 인공신경망모델 수행 에이전트로 전달하고 학습 된 제2 인공 신경망 모델의 프로그램을 제2 인공신경망모델 수행 에이전트로 전달할 수 있다. 추론 단말에서 수집되는 오디오 데이터에 대한 학습과 평가에 따른 추론용 제1 인공 신경망 모델의 프로그 램은 메모리에 저장되고 주변 환경음 제거를 위해 수집되는 오디오 데이터를 이용하여 학습과 평가가 이루 어진 환경음 제거용 제2 인공 신경망 모델의 프로그램도 메모리에 저장된다. 오디오데이터 수집 에이전트는 수집 관련 제어 정책에 따른 수집 주기의 도래에 따라 오디오 수신 에이전 트로부터의 일정한 시간 동안의 오디오 데이터(주변 환경음을 인식 가능한 오디오 데이터)를 메모리 에 저장한다. 오디오데이터 수집 에이전트는 전송 주기(수집 주기보다 긴)의 도래에 따라, 수집 주기에 따 라 수집된 다수의 오디오 데이터들을 통신 에이전트를 통해 학습 장치로 전송할 수 있다. 설계 응용 에 따라, 오디오데이터 수집 에이전트는 대응 신호가 발생하지 않는 유휴 시간에 오디오 데이터를 수집하 고 전송 주기의 도래에 따라 수집된 오디오 데이터들을 전송할 수 있다. 이와 같이, 오디오데이터 수집 에이전트(를 수행하는 마이크로 컨트롤러)는 마이크를 통해 수집 되는 오디오 데이터들을 포함하는 통신 패킷을 통신 인터페이스를 통해 로컬 네트워크에 연결된 인공 신경망 모델 학습 장치로 전송한다. 제2 인공신경망모델 수행 에이전트는 로컬 네트워크를 통해 통신 에이전트로부터 수신되는 학습 된 제2 인공 신경망 모델의 프로그램을 수행한다. 제2 인공신경망모델 수행 에이전트(의 마이크로 컨트롤 러)는 마이크를 통해 수집되는 일련의 오디오 데이터들을 학습된 제2 인공 신경망 모델의 프로그램에 입력하여 주변의 환경음이 제거된 오디오 데이터들을 생성한다. 제2 인공 신경망 모델의 프로그램은 본 추론 단 말에서 수집되고 주변의 환경음을 가지는 오디오 데이터로 학습되어 높은 정확도로 환경음이 제거된 오디 오 데이터를 생성할 수 있다. 또한, 주변 환경음의 변화에도 동적으로 적응하여 환경음 제거가 가능하다. 제1 인공신경망모델 수행 에이전트는 로컬 네트워크를 통해 통신 에이전트로부터 수신되는 학습 된 제1 인공 신경망 모델의 프로그램을 수행한다. 제1 인공신경망모델 수행 에이전트(의 마이크로 컨트롤 러)는 제2 인공 신경망 모델의 프로그램에서 출력되는 오디오 데이터들(제2 인공 신경망 모델에 의해 주변 환경음이 주로 제거된 오디오 데이터들)을 입력받고 입력받은 오디오 데이터들로부터 목표 음원을 인식한다. 제 1 인공신경망모델 수행 에이전트는 목표 음원의 인식 여부를 나타내는 추론 결과를 출력할 수 있다. 제1 인공신경망모델 수행 에이전트는 제2 인공 신경망 모델의 프로그램에 의해 주변 환경음이 (주로) 제 거된 오디오 데이터들을 제1 인공 신경망 모델에 입력하고 제1 인공 신경망 모델에서 출력되는 인식 확률이 임 계 확률 이상인 경우 목표 음원의 인식을 나타내는 추론 결과를 출력할 수 있다. 이와 같이, 제1 인공신경망모델 수행 에이전트는 추론 단말에서 발생하는 주변 환경음에 대한 동적인 학습으로 주변 환경음이 제거된 오디오 데이터에서 목표 음원 인식이 가능하다. 설계 변형 예에 따라, 제2 인공 신경망모델 수행 에이전트(와 제2 인공 신경망 모델 프로그램)의 수행과 적용은 생략될 수 있어 오디오 수 신 에이전트로부터의 오디오 데이터가 직접 제1 인공신경망모델 수행 에이전트로 공급될 수도 있다. 출력 관리 에이전트(의 마이크로 컨트롤러)는 제1 인공신경망모델 수행 에이전트로부터의 추론 결과에 따라 대응 신호를 출력부로 출력한다. 출력 관리 에이전트는 목표 음원의 인식을 나타내는 추 론 결과의 수신에 따라 대응 신호를 생성하여 출력부로 출력할 수 있다. 이상으로 살펴본 바와 같이, 추론 단말은 추론 단말 주변에서 발생하는 주변 환경음으로 학습된 인공 신경망 모델을 학습 장치로부터 학습 주기에 따라 수신하고 수신된 인공 신경망 모델을 RISC 기반의 마이 크로 컨트롤러에서 수행한다. 추론 단말이 직접 인공 신경망 모델을 수행할 수 있다. 더욱이, 인공 신경망 모델이 주변 환경음에 개별 튜닝되어 마이크로 컨트롤러에서 수행 가능한 정도로 경량화 가능하다. 도 6은 본 발명에 따른 인공 신경망 추론 시스템에서의 추론 단말과 학습 장치의 개략적인 동작과 그 사이의 제어 흐름을 도시한 도면이다. 인공 신경망 추론 시스템은 다수의 추론 단말들을 가질 수 있고 도 6의 제어 흐름은 개별 추론 단말 별로 이루어질 수 있다. 이미, 도 1 내지 도 5를 통해 추론 단말과 학습 장치의 구성 및 제어를 상세 히 살펴보았으므로 여기서는 제어 순서를 위주로 간단히 살펴보도록 한다. 먼저, 추론 단말과 학습 장치는 목표 음원 인식을 위한 환경을 설정(① 참조)한다. 학습 장치는 추론 단말로 최초의(또는 기본) 제1 인공 신경망 모델의 프로그램과 최초의(또는 기본) 제2 인공 신경망 모델의 프로그램을 로컬 네트워크를 통해 추론 단말로 전송한다. 또한, 학습 장치는 수집 주기, 전송 주기 등의 수집 관련 제어 정책을 로컬 네트워크를 통해 추론 단말로 전송한다. 추론 단말은 수집 주기에 따라 마이크를 통해 오디오 데이터를 수집하고 저장(② 참조)한다. 추론 단 말은 전송 주기의 도래에 따라 수집된 다수의 오디오 데이터들을 학습 장치로 전송(③ 참조)한다. 학습 장치는 수신되는 오디오 데이터들을 추론 단말(의 그룹)에 매칭시켜 저장 모듈(의 데이터 베이스)에 저장하고 추론 단말의 학습 주기의 도래에 따라, 수집된 오디오 데이터들을 학습용 오디오 데이 터(들)와 평가용 오디오 데이터(들)로 분류(④ 참조)한다. 학습 장치는 분류된 오디오 데이터를 사용하여 본 추론 단말의 인공 신경망 모델을 학습하고 평가(⑤ 참조)한다. 학습 장치는 평가 결과에 따라 인공 신경망 모델을 추론 단말로 로컬 네트워크를 통해 전송(⑥ 참조)하고 추론 단말에서 사용중인 현재 인공 신경망 모델(의 ID)을 데이터베이스에 업데이트한다. 추론 단말은 인공 신경망 모델을 수신 및 적용한다. 이후, 추론 단말은 마이크를 통해 오디오 데이터를 수신하고 수신된 오디오 데이터를 적용된 인공 신경망 모델에 입력하여 목표 음원의 인식을 시도하고 목표 음원의 인식시에 대응 신호를 출력(⑦ 참조)한다. 추론 단말과 학습 장치는 학습 주기(는 전송 주기와 수집 주기보다 통상 김)에 따라 반복적으로 ② 내지 ⑦의 과정을 수행한다. 여기서, 도 6의 ② 내지 ⑦의 과정은 순차적으로 수행되는 것으로 설명하였으나, ② 내지 ⑦의 과정은 독립적으로 또는 병렬적으로 수행될 수도 있다. 이상 살펴본 바와 같이, 본 발명에 따른 인공 신경망 추론 시스템은 음성 인식에 수반되는 프라이버시 또는 비 밀 정보의 노출을 없애거나 줄일 수 있다. 또한, 인공 신경망 추론 시스템은 네트워크의 단절에도 저렴한 비용 으로 주변 환경에 적응된 목표 음원(오디오)의 인식이 가능하다. 이상에서 설명한 본 발명은, 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자에게 있어 본 발명의 기술 적 사상을 벗어나지 않는 범위 내에서 여러 가지 치환, 변형 및 변경이 가능하므로 전술한 실시 예 및 첨부된 도면에 의해 한정되는 것이 아니다. 부호의 설명100 : 학습 장치 101 : 통신 모듈 105 : 저장 모듈 109 : 제어 모듈 151 : 통신 에이전트 153 : 시스템 관리 에이전트 155 : 학습 데이터 관리 에이전트 157 : 제1 학습 에이전트 159 : 제1 평가 에이전트 161 : 제2 학습 에이전트 163 : 제2 평가 에이전트 500 : 추론 단말 501 : 마이크 503 : 통신 인터페이스 505 : 출력부 507 : 메모리 509 : 마이크로 컨트롤러 551 : 오디오 수신 에이전트 553 : 오디오데이터 수집 에이전트 555 : 통신 에이전트 557 : 제1 인공신경망모델 수행 에이전트 559 : 제2 인공신경망모델 수행 에이전트 561 : 출력 관리 에이전트 900 : 로컬 네트워크도면 도면1 도면2 도면3 도면4 도면5 도면6"}
{"patent_id": "10-2023-0118700", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명에 따른 인공 신경망 추론 시스템의 예를 도시한 도면이다. 도 2는 인공 신경망 모델 학습 장치의 블록도를 도시한 도면이다. 도 3은 본 발명에 따른 인공 신경망 모델 학습 장치의 예시적인 기능 블록도를 도시한 도면이다. 도 4는 추론 단말의 예시적인 하드웨어 블록도를 도시한 도면이다. 도 5는 추론 단말의 예시적인 기능 블록도를 도시한 도면이다. 도 6은 본 발명에 따른 인공 신경망 추론 시스템에서의 추론 단말과 학습 장치의 개략적인 동작과 그 사이의 제 어 흐름을 도시한 도면이다."}
