{"patent_id": "10-2024-0062599", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2025-0046142", "출원번호": "10-2024-0062599", "발명의 명칭": "잠재 확산을 통한 역양자화 기반 오디오 신호를 부/복호화하는 방법 및 장치", "출원인": "한국전자통신연구원", "발명자": "장인선"}}
{"patent_id": "10-2024-0062599", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "음성 신호(speech signal)를 처리(processing)하는 방법에 있어서,상기 음성 신호가 양자화(quantization)된 이산 잠재 벡터(discrete latent vector)를 획득하는 동작; 및상기 이산 잠재 벡터에 기초하여, 상기 이산 잠재 벡터가 역-양자화(de-quantization)된 연속 잠재 벡터(continuous latent vector)를 출력하는 동작을 포함하는, 방법."}
{"patent_id": "10-2024-0062599", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 연속 잠재 벡터를 출력하는 동작은,상기 이산 잠재 벡터를 뉴럴 네트워크(neural network)를 구성하는 복수의 레이어(layer)들에 따라 점진적으로업 샘플링(up-sampling)하는 동작을 포함하는, 방법."}
{"patent_id": "10-2024-0062599", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,상기 업 샘플링하는 동작은,상기 이산 잠재 벡터 및 상기 복수의 레이어들 중 제1 레이어에 대응하는 제1 연속 잠재 벡터에 기초하여, 상기복수의 레벨 중 제2 레이어에 대응하는 제2 연속 잠재 벡터를 추정하는 동작을 포함하는, 방법."}
{"patent_id": "10-2024-0062599", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서,상기 제2 연속 잠재 벡터를 추정하는 동작은,상기 이산 잠재 벡터 및 상기 제1 연속 잠재 벡터에 기초하여, 상기 제1 연속 잠재 벡터에 포함된 노이즈를 추정하는 동작; 및상기 제1 연속 잠재 벡터에서 상기 노이즈를 제거하여, 상기 제2 연속 잠재 벡터를 계산하는 동작을 포함하는, 방법."}
{"patent_id": "10-2024-0062599", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제2항에 있어서,상기 복수의 레이어들 중 가장 높은 레벨의 레이어를 통해 출력된 연속 잠재 벡터에 기초하여, 복원 음성 신호를 생성하는 동작공개특허 10-2025-0046142-3-을 더 포함하는, 방법."}
{"patent_id": "10-2024-0062599", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "음성 신호(speech signal)를 처리(processing)하는 전자 장치에 있어서,프로세서 및인스트럭션들을 저장하는 메모리를 포함하고,상기 인스트럭션들은, 상기 프로세서에 의해 실행될 때 상기 전자 장치로 하여금,상기 음성 신호가 양자화(quantization)된 이산 잠재 벡터(discrete latent vector)를 획득하도록 하고,상기 이산 잠재 벡터에 기초하여, 상기 이산 잠재 벡터가 역-양자화(de-quantization)된 연속 잠재 벡터(continuous latent vector)를 출력하도록 하는, 전자 장치."}
{"patent_id": "10-2024-0062599", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6항에 있어서,상기 인스트럭션들은, 상기 프로세서에 의해 실행될 때 상기 전자 장치로 하여금,상기 이산 잠재 벡터를 뉴럴 네트워크(neural network)를 구성하는 복수의 레이어(layer)에 따라 점진적으로 업샘플링(up-sampling)하도록 하는, 전자 장치."}
{"patent_id": "10-2024-0062599", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서,상기 인스트럭션들은, 상기 프로세서에 의해 실행될 때 상기 전자 장치로 하여금,상기 이산 잠재 벡터 및 상기 복수의 레벨 중 제1 레벨에 대응하는 제1 이산 잠재 벡터에 기초하여, 상기 복수의 레벨 중 제2 레벨에 대응하는 제2 연속 잠재 벡터를 추정하도록 하는, 전자 장치."}
{"patent_id": "10-2024-0062599", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서,상기 인스트럭션들은, 상기 프로세서에 의해 실행될 때 상기 전자 장치로 하여금,상기 이산 잠재 벡터 및 상기 제1 연속 잠재 벡터에 기초하여, 상기 제1 연속 잠재 벡터에 포함된 노이즈를 추정하도록 하고,상기 제1 연속 잠재 벡터에서 상기 노이즈를 제거하여, 상기 제2 연속 잠재 벡터를 계산하도록 하는, 전자장치."}
{"patent_id": "10-2024-0062599", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제7항에 있어서,상기 인스트럭션들은, 상기 프로세서에 의해 실행될 때 상기 전자 장치로 하여금,상기 복수의 레이어들 중 가장 높은 레벨의 레이어를 통해 출력된 연속 잠재 벡터에 기초하여, 복원 음성 신호공개특허 10-2025-0046142-4-를 생성하도록 하는, 전자 장치."}
{"patent_id": "10-2024-0062599", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "잠재 확산을 통한 역양자화 기반 오디오 신호를 부/복호화하는 방법 및 장치가 개시된다. 일 실시예에 따른 복 호화 방법은, 음성 신호가 양자화(quantization)된 이산 잠재 벡터(discrete latent vector)를 획득하는 동작과, 상기 이산 잠재 벡터에 기초하여, 상기 이산 잠재 벡터가 역-양자화(de-quantization)된 연속 잠재 벡터 (continuous latent vector)를 출력하는 동작을 포함할 수 있다."}
{"patent_id": "10-2024-0062599", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "아래 개시는 잠재 확산을 통한 역양자화 기반 오디오 신호를 부/복호화하는 방법 및 장치에 관한 것이다."}
{"patent_id": "10-2024-0062599", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "신경 음성 코덱(neural speech codec, NSC)은 음성 신호의 복잡한 패턴을 더 효과적으로 포착하기 위해 발전되 어왔다. 신경 음성 코덱은 크게 두가지 종류로 분류될 수 있는데, 그 예로 엔드-투-엔드 코덱(end-to-end codec) 및 뉴럴 보코더(neural vocoder)가 있을 수 있다. 생성형 모델(generative model)은 인공지능 분야에서 데이터를 생성하는 모델일 수 있다. 생성형 모델은 기존 에 주어진 데이터를 바탕으로 새로운 데이터를 생성하거나, 주어진 데이터의 분포를 학습하여 새로운 샘플을 생 성할 수 있다. 생성형 모델은 다양한 분야에서 활용되며, 이미지 생성, 자연어 생성, 음성 생성 등 다양한 응용 이 가능할 수 있다. 생성형 모델의 일 예인 확산 모델(diffusion model)은 최근에 등장한 생성형 모델 중 하나로서, 데이터의 분포 를 근사화하기 위해 확산 과정을 사용할 수 있다. 확산 모델은 주어진 초기 데이터를 점진적으로 변형시켜 원 하는 데이터를 생성할 수 있다."}
{"patent_id": "10-2024-0062599", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 2, "content": "위에서 설명한 배경기술은 발명자가 본원의 개시 내용을 도출하는 과정에서 보유하거나 습득한 것으로서, 반드 시 본 출원 전에 일반 공중에 공개된 공지기술이라고 할 수는 없다."}
{"patent_id": "10-2024-0062599", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "일 실시예는 압축된 음성 신호(speech signal)를 복호화하기 위해, 생성형 모델(generative model)을 이용하여 저 비트율의 이산 잠재 벡터(discrete latent vector)로부터 고 비트 율의 연속 잠재 벡터(continuous latent vector)를 추정하는 기술을 제공할 수 있다. 다만, 기술적 과제는 상술한 기술적 과제들로 한정되는 것은 아니며, 또 다른 기술적 과제들이 존재할 수 있다."}
{"patent_id": "10-2024-0062599", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "일 실시예에 따른 음성 신호(speech signal)를 처리(processing)하는 방법은, 상기 음성 신호가 양자화 (quantization)된 이산 잠재 벡터(discrete latent vector)를 획득하는 동작과, 상기 이산 잠재 벡터에 기초하 여, 상기 이산 잠재 벡터가 역-양자화(de-quantization)된 연속 잠재 벡터(continuous latent vector)를 출력 하는 동작을 포함할 수 있다. 상기 연속 잠재 벡터를 출력하는 동작은, 상기 이산 잠재 벡터를 뉴럴 네트워크(neural network)를 구성하는 복 수의 레이어(layer)들에 따라 점진적으로 업 샘플링(up-sampling)하는 동작을 포함할 수 있다. 상기 업 샘플링하는 동작은, 상기 이산 잠재 벡터 및 상기 복수의 레이어들 중 제1 레이어에 대응하는 제1 연속 잠재 벡터에 기초하여, 상기 복수의 레벨 중 제2 레이어에 대응하는 제2 연속 잠재 벡터를 추정하는 동작을 포 함할 수 있다. 상기 제2 연속 잠재 벡터를 추정하는 동작은, 상기 이산 잠재 벡터 및 상기 제1 연속 잠재 벡터에 기초하여, 상 기 제1 연속 잠재 벡터에 포함된 노이즈를 추정하는 동작과, 상기 제1 연속 잠재 벡터에서 상기 노이즈를 제거하여, 상기 제2 연속 잠재 벡터를 계산하는 동작을 포함할 수 있다. 상기 방법은, 상기 복수의 레이어들 중 가장 높은 레벨의 레이어를 통해 출력된 연속 잠재 벡터에 기초하여, 복 원 음성 신호를 생성하는 동작을 더 포함할 수 있다. 일 실시예에 따른 음성 신호(speech signal)를 처리(processing)하는 전자 장치는 프로세서와, 인스트럭션들을 저장하는 메모리를 포함할 수 있다. 상기 인스트럭션들은, 상기 프로세서에 의해 실행될 때 상기 전자 장치로 하여금, 상기 음성 신호가 양자화(quantization)된 이산 잠재 벡터(discrete latent vector)를 획득하도록 할 수 있다. 상기 인스트럭션들은, 상기 프로세서에 의해 실행될 때 상기 전자 장치로 하여금, 상기 이산 잠재 벡 터에 기초하여, 상기 이산 잠재 벡터가 역-양자화(de-quantization)된 연속 잠재 벡터(continuous latent vector)를 출력하도록 할 수 있다. 상기 인스트럭션들은, 상기 프로세서에 의해 실행될 때 상기 전자 장치로 하여금, 상기 이산 잠재 벡터를 뉴럴 네트워크(neural network)를 구성하는 복수의 레이어(layer)에 따라 점진적으로 업 샘플링(up-sampling)하도록 할 수 있다. 상기 인스트럭션들은, 상기 프로세서에 의해 실행될 때 상기 전자 장치로 하여금, 상기 이산 잠재 벡터 및 상기 복수의 레벨 중 제1 레벨에 대응하는 제1 이산 잠재 벡터에 기초하여, 상기 복수의 레벨 중 제2 레벨에 대응하 는 제2 연속 잠재 벡터를 추정하도록 할 수 있다. 상기 인스트럭션들은, 상기 프로세서에 의해 실행될 때 상기 전자 장치로 하여금, 상기 이산 잠재 벡터 및 상기 제1 연속 잠재 벡터에 기초하여, 상기 제1 연속 잠재 벡터에 포함된 노이즈를 추정하도록 할 수 있다. 상기 인 스트럭션들은, 상기 프로세서에 의해 실행될 때 상기 전자 장치로 하여금, 상기 제1 연속 잠재 벡터에서 상기 노이즈를 제거하여, 상기 제2 연속 잠재 벡터를 계산하도록 할 수 있다. 상기 인스트럭션들은, 상기 프로세서에 의해 실행될 때 상기 전자 장치로 하여금, 상기 복수의 레이어들 중 가 장 높은 레벨의 레이어를 통해 출력된 연속 잠재 벡터에 기초하여, 복원 음성 신호를 생성하도록 할 수 있다."}
{"patent_id": "10-2024-0062599", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "실시예들에 대한 특정한 구조적 또는 기능적 설명들은 단지 예시를 위한 목적으로 개시된 것으로서, 다양한 형 태로 변경되어 구현될 수 있다. 따라서, 실제 구현되는 형태는 개시된 특정 실시예로만 한정되는 것이 아니며, 본 명세서의 범위는 실시예들로 설명한 기술적 사상에 포함되는 변경, 균등물, 또는 대체물을 포함한다. 제1 또는 제2 등의 용어를 다양한 구성요소들을 설명하는데 사용될 수 있지만, 이런 용어들은 하나의 구성요소 를 다른 구성요소로부터 구별하는 목적으로만 해석되어야 한다. 예를 들어, 제1 구성요소는 제2 구성요소로 명 명될 수 있고, 유사하게 제2 구성요소는 제1 구성요소로도 명명될 수 있다. 어떤 구성요소가 다른 구성요소에 \"연결되어\" 있다고 언급된 때에는, 그 다른 구성요소에 직접적으로 연결되어 있거나 또는 접속되어 있을 수도 있지만, 중간에 다른 구성요소가 존재할 수도 있다고 이해되어야 할 것이다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 명세서에서, \"포함하다\" 또는 \"가지다\" 등의 용어는 설명된 특징, 숫자, 단계, 동작, 구성요소, 부분품 또는 이들을 조합한 것이 존재함 으로 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성요소, 부분품 또는 이들 을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되어야 한다. 다르게 정의되지 않는 한, 기술적이거나 과학적인 용어를 포함해서 여기서 사용되는 모든 용어들은 해당 기술 분야에서 통상의 지식을 가진 자에 의해 일반적으로 이해되는 것과 동일한 의미를 가진다. 일반적으로 사용되 는 사전에 정의되어 있는 것과 같은 용어들은 관련 기술의 문맥상 가지는 의미와 일치하는 의미를 갖는 것으로 해석되어야 하며, 본 명세서에서 명백하게 정의하지 않는 한, 이상적이거나 과도하게 형식적인 의미로 해석되지 않는다. 이하, 실시예들을 첨부된 도면들을 참조하여 상세하게 설명한다. 첨부 도면을 참조하여 설명함에 있어, 도면 부호에 관계없이 동일한 구성 요소는 동일한 참조 부호를 부여하고, 이에 대한 중복되는 설명은 생략하기로 한 다. 도 1은 일 실시예에 따른 음성 신호 처리 시스템의 일 예를 나타낸다. 도 1을 참조하면, 음성 신호 처리 장치(speech signal processing device)는 부호화기(encoder) 및 복호화기(decoder)을 포함할 수 있다. 다만, 도 1은 본 발명을 설명하기 위한 일 예이고, 본 발명의 권리 범위가 이에 한정되는 것으로 해석되어서는 안 된다. 예를 들어, 음성 신호 처리 장치는 부호화기 및 복호화기 중 어느 하나만을 포함할 수 있다. 음성 신호를 처리한다는 것은 음성 신호를 압축하는 것 및/또는 압축된 음성 신호를 압축되기 전의 신호로 복원 하는 것을 포함할 수 있다. 부호화기는 입력 음성 신호를 부호화 하여 비트 스트림을 생성하고, 비트 스트림을 복호화기로 전송 (또는 출력)할 수 있다. 복호화기는 부호화기로부터 획득(예: 수신)한 비트 스트림을 복호화 하여 복원 음성 신호를 생성할 수 있다. 부호화기 및 복호화기의 구체적인 구성 및 동작에 대해서는 도 2를 참조하여 이하에서 상세히 설명하 도록 한다. 도 2는 도 1에 도시된 부호화기 및 복호화기를 설명하기 위한 도면이다. 도 2를 참조하면, 부호화기는 이산적 부호화기(discrete encoder)를 포함할 수 있다. 복호화기는 연속적 복호화기(continuous decoder), 및 생성형 모델(generative model)을 포함 할 수 있다. 부호화기는 음성 신호(예: 도 1의 입력 음성 신호)가 암호화된 비트 스트림을 생성할 수 있다. 이산적 부 호화기는 음성 신호에 기초하여, 이산 잠재 벡터(discrete latent vector)를 출력할 수 있다. 이산 잠재 벡터는 음성 신호가 양자화(quantization)된 벡터로, 저 비트율을 가질 수 있다. 이산적 부호화기는 이산 잠재 공간(discrete latent space) 을 학습하는 자동 부호화기(auto encoder)일 수 있다. 이산적 부호화기 는 시간 영역의 음성 신호를 이산 잠재 공간 으로 축소시켜 이산 잠재 벡터를 생성할 수 있다. 위에서 설명한 이산 잠재 벡터는 신경 음성 코덱(neural speech codec, NSC) 기술 분야에서 엔드-투-엔드 학습 (end-to-end training)을 통해 구성한 이산적 부호화기 및/또는 이산적 복호화기(예: 도 3a의 이산적 복호 화기)의 잠재 벡터를 포함할 수 있다. 복호화기는 부호화기로부터 비트 스트림(예: 이산 잠재 벡터)를 획득(예: 수신)할 수 있다. 복호화기는 저 비트율의 이산 잠재 벡터를 이용하여, 고품질의 복원 음성 신호를 생성할 수 있다. 예를 들어, 복호화기는 이산 잠재 벡터로부터 생성형 모델을 통해 연속 잠재 벡터를 생성하고, 연속 잠재 벡터를 연속적 복호화기에 의해 복원하여, 고품질의 복원 음성 신호를 생성할 수 있다. 이하에서는, 부호화기 및/또는 복호화기의 학습방법에 대해서 도 3a 및 도3 b를 참조하여 상세히 설 명하도록 한다.도 3a 및 도 3b는 도 2에 도시된 부호화기 및 복호화기의 학습 방법을 설명하기 위한 도면이다. 도 3a를 참조하면, 연속적 부호화기 및 연속적 복호화기의 학습, 이산적 부호화기 및 연속적 복 호화기의 학습, 및 생성형 모델의 학습은 독립적으로 수행될 수 있다. 이산적 부호화기는 음성 신호(예: 도 1의 입력 음성 신호)에 기초하여, 이산 잠재 벡터(discrete latent vector)를 출력하도록 학습될 수 있다. 이산 잠재 벡터에 대한 설명은 도 2를 참조하여 상세히 설명한바, 이하 에서는 설명을 생략하도록 한다. 이산적 복호화기는 이산 잠재 벡터에 기초하여, 제1 복원 음성 신호를 생성하도록 학습될 수 있다. 제1 복원 음성 신호는 저 비트율의 이산 잠재 벡터에 기초하여 생성된 것으로, 저 품질(low quality)일 수 있다. 연속적 부호화기는 음성 신호(예: 도 1의 입력 음성 신호)에 기초하여, 연속 잠재 벡터(continuous latent vector)를 출력하도록 학습될 수 있다. 연속 잠재 벡터는 이산 잠재 벡터가 역-양자화된 잠재 벡터일 수 있다. 또한, 연속 잠재 벡터는 음성 신호가 암호화는 되었으나 양자화 되지 않은 벡터로, 고 비트율을 가질 수 있다. 연속적 부호화기는 연속 잠재 공간(continuous latent space) 을 학습하는 자동 부호화기(auto encoder)일 수 있다. 연속적 부호화기는 시간 영역의 음성 신호를 연속 잠재 공간 으로 축소시켜 연속 잠재 벡터를 생성할 수 있다연속적 복호화기는 연속적 부호화기로부터 연속 잠재 벡터를 획득할 수 있다. 연속적 복호화기는 연속 잠재 벡터에 기초하여, 제2 복원 음성 신호를 생성하도록 학습될 수 있다. 제2 복원 음성 신호는 고 비트율의 연속 잠재 벡터에 기초하여 생성된 것으로, 고 품질(high quality)일 수 있다. 제1 복원 음성 신호와 제2 복원 음성 신호 간의 품질의 차이가 나는 이유는, 이산 잠재 벡터는 암호화된 음성 신호가 양자화된 것으로 가지고 있는 정보(예: 도 1의 입력 음성 신호의 음성 특징에 관한 정보를 포함)의 양이 연속 잠재 벡터 보다 적기 때문일 수 있다. 위에서 설명한 연속 잠재 벡터는 신경 음성 코덱(neural speech codec, NSC) 기술 분야에서 엔드-투-엔드 학습 (end-to-end training)을 통해 구성한 연속적 부호화기 및/또는 연속적 복호화기의 잠재 벡터를 포함 할 수 있다. 연속적 부호화기 및 연속적 복호화기의 학습, 이산적 부호화기 및 연속적 복호화기의 학습 이 완료된 경우, 도 2에 도시된 바와 같이, 부호화기에는 연속적 복호화기가 탑재되고, 복호화기 에는 이산적 부호화기가 탑재될 수 있다. 다만, 이에 한정되는 것은 아니다. 이하에서는, 생성형 모델의 학습 방법에 대해 설명하도록 한다. 도 3b를 참조하면, 복호화기는 생성형 모델의 학습을 위해 이산 잠재 벡터 및 연속 잠재 벡터를 이용 할 수 있다. 생성형 모델의 학습이 완료된 경우, 생성형 모델은 이산 잠재 벡터에 기초하여, 연속 잠재 벡터를 생성할 수 있다. 생성형 모델은 입력 컨디션(input condition)(예: 이산 잠재 벡터)에 기초하여, 특정 출력(예: 연속 잠재 벡터)을 만들어내는 뉴럴 네트워크를 의미할 수 있다. 뉴럴 네트워크는 복수의 레이어(layer)(예: 레이어(255- 1) 내지 레이어(255-N))들을 포함할 수 있다. 뉴럴 네트워크(또는 인공 신경망)는 기계학습과 인지과학에서 생물학의 신경을 모방한 통계학적 학습 알고리즘 을 포함할 수 있다. 뉴럴 네트워크는 시냅스의 결합으로 네트워크를 형성한 인공 뉴런(노드)이 학습을 통해 시 냅스의 결합 세기를 변화시켜, 문제 해결 능력을 가지는 모델 전반을 의미할 수 있다. 뉴럴 네트워크의 뉴런은 가중치 또는 바이어스의 조합을 포함할 수 있다. 뉴럴 네트워크는 하나 이상의 뉴런 또는 노드로 구성된 하나 이상의 레이어(layer)를 포함할 수 있다. 뉴럴 네트워크는 뉴런의 가중치를 학습을 통해 변화시킴으로써 임의의 입력으로부터 예측하고자 하는 결과를 추론할 수 있다. 뉴럴 네트워크는 심층 뉴럴 네트워크 (Deep Neural Network)를 포함할 수 있다. 뉴럴 네트워크는 CNN(Convolutional Neural Network), RNN(Recurrent Neural Network), 퍼셉트론(perceptron), 다층 퍼셉트론 (multilayer perceptron), FF(Feed Forward), RBF(Radial Basis Network), DFF(Deep Feed Forward), LSTM(Long Short Term Memory), GRU(Gated Recurrent Unit), AE(Auto Encoder), VAE(Variational Auto Encoder), DAE(Denoising Auto Encoder), SAE(Sparse Auto Encoder), MC(Markov Chain), HN(HopfieldNetwork), BM(Boltzmann Machine), RBM(Restricted Boltzmann Machine), DBN(Depp Belief Network), DCN(Deep Convolutional Network), DN(Deconvolutional Network), DCIGN(Deep Convolutional Inverse Graphics Network), GAN(Generative Adversarial Network), LSM(Liquid State Machine), ELM(Extreme Learning Machine), ESN(Echo State Network), DRN(Deep Residual Network), DNC(Differentiable Neural Computer), NTM(Neural Turning Machine), CN(Capsule Network), KN(Kohonen Network), VGG(Visual Geometry Group) 네트 워크 및 AN(Attention Network)를 포함할 수 있다. 이하에서는, 생성형 모델을 학습시키는 방법에 대해 구체적으로 설명하도록 한다. 생성형 모델은 이산 잠재 벡터에 기초하여, 연속 잠재 벡터를 생성할 수 있도록 학습될 수 있다. 예를 들 어, 생성형 모델은 연속 잠재 벡터를 생성하기 위해, 확산 모델(diffusion model)로 구현될 수 있다. 확 산 모델은 마르코프 프로세스(markov process)를 통해 입력 컨디션에 따른 출력을 생성하도록 학습된 모델일 수 있다. 마르코프 프로세스는 포워드 프로세스(forward process)와 리버스 프로세스(reverse process)를 포함할 수 있다. 이하에서는, 포워드 프로세스 및 리버스 프로세스를 통해 생성형 모델이 학습되는 방법을 설명 하도록 한다. 설명의 편의를 위해 다음과 같이 용어를 정의하도록 한다. 레이어(255-1)는 가장 낮은 레벨의 레이어이고, 다 음 단계로 갈수록 레벨은 높아지는 것으로 가정하여 설명하도록 한다. 예를 들어, 레이어(255-2)는 레이어 (255-1)보다 한 단계 높은 레벨의 레이어일 수 있다. 또한, 레이어(255-1 내지 255-N 중 어느 하나)에 대응되 는 연속 잠재 벡터는 리버스 프로세스를 기준으로 레이어에 입력된 연속 잠재 벡터로 가정하도록 한다. 이는, 포워드 프로세스에서 레이어를 통해 출력된 연속 잠재 벡터와 동일할 수 있다. 예를 들어, 연속 잠재 벡터 는 레이어(255-1)에 대응될 수 있다. 포워드 프로세스에서, 연속 잠재 벡터 z0는 뉴럴 네트워크(예: 생성형 모델)를 구성하는 복수의 레이어(예: 레이어(255-1) 내지 레이어(255-N))들에 따라 점진적으로 다운 샘플링(down sampling)될 수 있다. 예를 들어, 연속 잠재 벡터 z0는 레이어(255-N)에 입력되어 노이즈 (예: 가우시안 노이즈(gaussian noise)) 가 더해져 연속 잠재 벡터 z1이 될 수 있다. 연속 잠재 벡터 z1 또한 다음 레이어(예: 레이어(255-N)보다 한 단계 낮은 레벨의 레이어를 포함)에 입력되어 제1 연속 잠재 벡터가 다운 샘플링된 방법과 실질적으로 동일한 방법에 의해 제3 연속 잠재 벡터 z2가 될 수 있다. 이와 같은 방법을 반복적으로 수행할 경우, 제N 연속 잠재 벡터 가 생성될 수 있다. 제N 연속 잠재 벡터 는 제1 연속 잠재 벡터 z0로부터 노이즈가 N번(예: 레이어 (예: 255-1 내지 255-N 중 하나 이상)에 입력된 횟수)만큼 더해져서 노이즈로 변환된 잠재 벡터일 수 있다. 즉 포워드 프로세스에서, 연속 잠재 벡터가 다음 단계로 진행될 경우 노이즈가 단계 별로 더해질 수 있다. 리버스 프로세스에서, 이산 잠재 벡터 h는 뉴럴 네트워크(예: 생성형 모델)를 구성하는 복수의 레이어(예: 레이어(255-1) 내지 레이어(255-N))들에 따라 점진적으로 업 샘플링(up sampling)될 수 있다. 이산 잠재 벡터 h는 복수의 레이어에 따라 업 샘플링 되어 연속 잠재 벡터 z0가 될 수 있다. 예를 들어, 레이어(255-1)는 이산 잠재 벡터 h 및 연속 잠재 벡터 를 입력 받아 연속 잠재 벡터 에 포함된(또는 더해진) 노이즈 (예: 가우시안 노이즈(gaussian noise))를 추정할 수 있다. 레이어(255-1)는 연속 잠재 벡터 에서 추정된 노이즈 를 제거하여, 연속 잠재 벡터 를 생성할 수 있다. 레이어(255-1)에 대응되는 연속 잠재 벡터는 연속 잠재 벡터 이와 같은 방법을 레이어의 레벨이 높아짐에 따라 반복적으로 수행할 경우, 가장 높은 레벨의 레 이어(255-N)에 대응되는 연속 잠재 벡터 z0가 계산(또는 추정)될 수 있다. 즉, 리버스 프로세스에서 이산 잠재 벡터가 다음 단계로 진행될 경우 노이즈가 단계 별로 제거될 수 있다. 포워드 프로세스 및/또는 리버스 프로세스를 통해 생성형 모델을 구성하는 파라미터(예: )가 학 습될 수 있다. 파라미터는 레이어 별로 입력되는 연속 잠재 벡터에 포함된 노이즈를 추정하기 위한 것일 수 있 다. 예를 들어, 파라미터들은 포워드 프로세스에서 레이어(255-1)에 입력된 연속 잠재 벡터 에 더해진 노 이즈 와, 리버스 프로세스에서 레이어(255-1)에서 추정된 노이즈 의 차이가 최소화되기 위해 학습될 수있다. 파라미터들은 하기의 수학식 1을 통해 학습될 수 있다. [수학식 1]"}
{"patent_id": "10-2024-0062599", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "수학식 1에서, 는 노이즈에 관한 손실함수를 나타내고, 는 포워드 프로세스에서 t번째 레이어에 입력된 t-1 번째 연속 잠재 벡터에 더해진 노이즈를 나타내고, 는 리버스 프로세스에서 t번째 레 이어에 입력된 t 번째 연속 잠재 벡터에 포함된 노이즈를 추정하기 위한 파라미터를 나타낸다. 생성형 모델의 학습이 완료된 경우, 생성형 모델은 이산 잠재 벡터 h에 기초하여, 연속 잠재 벡터 z0 를 생성할 수 있다. 이하에서는, 이에 대해서 설명하도록 한다. 생성형 모델은 이산 잠재 벡터를 뉴럴 네트워크(neural network)를 구성하는 복수의 레이어(layer)들에 따 라 점진적으로 업 샘플링(up-sampling)할 수 있다. 생성형 모델은 이산 잠재 벡터 및 복수의 레이어들 (255-1 내지 255-N) 중 제1 레이어에 대응하는 제1 연속 잠재 벡터에 기초하여, 복수의 레이어들(255-1 내지 255-N) 중 제2 레이어에 대응하는 제2 연속 잠재 벡터를 추정할 수 있다. 제1 레이어는 제2 레이어 보다 낮은 단계의 레이어일 수 있다. 다만, 제1 레이어는 반드시 레이어(255-1)인 것은 아니고 복수의 레이어들(255-1 내 지 255-N) 중 어느 하나의 레이어일 수 있다. 예를 들어, 제1 레이어는 레이어(255-n)일 수 있다. 이때, n은 1과 N 사이의 정수일 수 있다. 생성형 모델은 이산 잠재 벡터 및 제1 연속 잠재 벡터에 기초하여, 제1 연속 잠재 벡터에 포함된 노이즈를 추정할 수 있다. 생성형 모델은 제1 연속 잠재 벡터에서 노이즈를 제거하여, 제2 연속 잠재 벡터를 계산 할 수 있다. 이에 대해서는 위의 리버스 프로세스에서 상세히 설명한바, 이하에서는 설명을 생략하도록 한다. 생성형 모델은 최종 생성된 연속 잠재 벡터(예: 복수의 레이어들(255-1 내지 255-N) 중 가장 높은 레벨의 레이어를 통해 출력된 연속 잠재 벡터)를 연속적 부호화기로 출력할 수 있다. 연속적 부호화기는 최 종 생성된 연속 잠재 벡터에 기초하여, 복원 음성 신호를 생성할 수 있다. 이산적 부호화기, 연속적 복호화기, 및 생성형 모델은 학습이 완료된 경우 부호화기(예: 도 2의 부호화기) 및/또는 복호화기(예: 도 2의 복호화기)에 탑재될 수 있다. 이에 대해서는 도 2에 도시된 바와 동일하므로, 구체적인 설명은 생략하도록 한다. 도 4은 일 실시예에 따른 음성 신호를 처리하는 방법의 흐름도의 일 예를 나타낸다. 도 4을 참조하면, 동작 410 및 동작 430은 순차적으로 수행될 수 있지만, 이에 한정되는 것은 아니다. 예를 들 어, 둘 이상의 동작들이 병렬적으로 수행될 수 있다. 동작 410 및 동작 430은 도 1 및 도 3b를 참조하여 설명 한 음성 신호 처리 장치(예: 도 1의 음성 신호 처리 장치)의 동작과 실질적으로 동일할 수 있다. 이에, 상세한 설명은 생략하도록 한다 동작 410에서, 음성 신호 처리 장치는 음성 신호가 양자화된 이산 잠재 벡터를 획득(예: 수신)할 수 있다. 동작 430에서, 음성 신호 처리 장치는 이산 잠재 벡터에 기초하여, 이산 잠재 벡터가 역-양자화된 연속 잠 재 벡터를 출력할 수 있다. 도 5는 일 실시예에 따른 전자 장치의 일 예를 나타낸다. 도 5를 참조하면, 전자 장치는 메모리 및 프로세서를 포함할 수 있다. 전자 장치는 도 1 의 음성 신호 처리 장치를 포함할 수 있다. 예를 들어, 전자 장치는 도 1의 복호화기를 포함한 장치일 수 있다.메모리는 프로세서에 의해 실행가능한 인스트럭션들(예: 프로그램)을 저장할 수 있다. 예를 들어, 인스트럭션들은 프로세서의 동작 및/또는 프로세서의 각 구성의 동작을 실행하기 위한 인스트럭션들 을 포함할 수 있다. 메모리는 휘발성 메모리 장치 또는 비휘발성 메모리 장치로 구현될 수 있다. 휘발성 메모리 장치는 DRAM(dynamic random access memory), SRAM(static random access memory), T- RAM(thyristor RAM), Z-RAM(zero capacitor RAM), 또는 TTRAM(Twin Transistor RAM)으로 구현될 수 있다. 비휘발성 메모리 장치는 EEPROM(Electrically Erasable Programmable Read-Only Memory), 플래시(flash) 메모 리, MRAM(Magnetic RAM), 스핀전달토크 MRAM(Spin-Transfer Torque(STT)-MRAM), Conductive Bridging RAM(CBRAM), FeRAM(Ferroelectric RAM), PRAM(Phase change RAM), 저항 메모리(Resistive RAM(RRAM)), 나노 튜브 RRAM(Nanotube RRAM), 폴리머 RAM(Polymer RAM(PoRAM)), 나노 부유 게이트 메모리(Nano Floating Gate Memory(NFGM)), 홀로그래픽 메모리(holographic memory), 분자 전자 메모리 소자(Molecular Electronic Memory Device), 또는 절연 저항 변화 메모리(Insulator Resistance Change Memory)로 구현될 수 있다. 프로세서는 메모리에 저장된 데이터를 처리할 수 있다. 프로세서는 메모리에 저장된 컴퓨 터로 읽을 수 있는 코드(예를 들어, 소프트웨어) 및 프로세서에 의해 유발된 인스트럭션(instruction)들을 실행할 수 있다. 프로세서는 목적하는 동작들(desired operations)을 실행시키기 위한 물리적인 구조를 갖는 회로를 가지는 하드웨어로 구현된 데이터 처리 장치일 수 있다. 예를 들어, 목적하는 동작들은 프로그램에 포함된 코드(code) 또는 인스트럭션들(instructions)을 포함할 수 있다. 예를 들어, 하드웨어로 구현된 데이터 처리 장치는 마이크로프로세서(microprocessor), 중앙 처리 장치(central processing unit), 프로세서 코어(processor core), 멀티-코어 프로세서(multi-core processor), 멀티프로세서 (multiprocessor), ASIC(Application-Specific Integrated Circuit), FPGA(Field Programmable Gate Array)를 포함할 수 있다. 프로세서는 메모리에 저장된 코드 및/또는 인스트럭션들을 실행함으로써, 전자 장치으로 하여금 하나 이상의 동작들을 수행하도록 할 수 있다. 전자 장치에 의해 수행되는 동작들은 도 1 내지 도 3를 참 조하여 설명한 음성 신호 처리 장치에 의해 수행되는 동작들(예: 음성 신호 처리 장치에 의해 수행되 는 음성 신호 처리 방법 및/또는 음성 신호 처리 장치에 의해 수행되는 뉴럴 네트워크(예: 도 2의 생성형 모델)의 학습 방법을 포함)과 실질적으로 동일할 수 있다. 이에 중복되는 설명은 생략하도록 한다. 이상에서 설명된 실시예들은 하드웨어 구성요소, 소프트웨어 구성요소, 및/또는 하드웨어 구성요소 및 소프트웨 어 구성요소의 조합으로 구현될 수 있다. 예를 들어, 실시예들에서 설명된 장치, 방법 및 구성요소는, 예를 들 어, 프로세서, 콘트롤러, ALU(arithmetic logic unit), 디지털 신호 프로세서(digital signal processor), 마 이크로컴퓨터, FPGA(field programmable gate array), PLU(programmable logic unit), 마이크로프로세서, 또는 명령(instruction)을 실행하고 응답할 수 있는 다른 어떠한 장치와 같이, 범용 컴퓨터 또는 특수 목적 컴퓨터를 이용하여 구현될 수 있다. 처리 장치는 운영 체제(OS) 및 상기 운영 체제 상에서 수행되는 소프트웨어 애플리 케이션을 수행할 수 있다. 또한, 처리 장치는 소프트웨어의 실행에 응답하여, 데이터를 접근, 저장, 조작, 처 리 및 생성할 수도 있다. 이해의 편의를 위하여, 처리 장치는 하나가 사용되는 것으로 설명된 경우도 있지만,"}
{"patent_id": "10-2024-0062599", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "해당 기술분야에서 통상의 지식을 가진 자는, 처리 장치가 복수 개의 처리 요소(processing element) 및/또는 복수 유형의 처리 요소를 포함할 수 있음을 알 수 있다. 예를 들어, 처리 장치는 복수 개의 프로세서 또는 하 나의 프로세서 및 하나의 컨트롤러를 포함할 수 있다. 또한, 병렬 프로세서(parallel processor)와 같은, 다른 처리 구성(processing configuration)도 가능하다. 소프트웨어는 컴퓨터 프로그램(computer program), 코드(code), 명령(instruction), 또는 이들 중 하나 이상의 조합을 포함할 수 있으며, 원하는 대로 동작하도록 처리 장치를 구성하거나 독립적으로 또는 결합적으로 (collectively) 처리 장치를 명령할 수 있다. 소프트웨어 및/또는 데이터는, 처리 장치에 의하여 해석되거나 처리 장치에 명령 또는 데이터를 제공하기 위하여, 어떤 유형의 기계, 구성요소(component), 물리적 장치, 가상 장치(virtual equipment), 컴퓨터 저장 매체 또는 장치, 또는 전송되는 신호 파(signal wave)에 영구적으로, 또는 일시적으로 구체화(embody)될 수 있다. 소프트웨어는 네트워크로 연결된 컴퓨터 시스템 상에 분산되어서, 분산된 방법으로 저장되거나 실행될 수도 있다. 소프트웨어 및 데이터는 컴퓨터 판독 가능 기록 매체에 저장될 수 있다.실시예에 따른 방법은 다양한 컴퓨터 수단을 통하여 수행될 수 있는 프로그램 명령 형태로 구현되어 컴퓨터 판 독 가능 매체에 기록될 수 있다. 컴퓨터 판독 가능 매체는 프로그램 명령, 데이터 파일, 데이터 구조 등을 단 독으로 또는 조합하여 저장할 수 있으며 매체에 기록되는 프로그램 명령은 실시예를 위하여 특별히 설계되고 구 성된 것들이거나 컴퓨터 소프트웨어 당업자에게 공지되어 사용 가능한 것일 수도 있다. 컴퓨터 판독 가능 기록 매체의 예에는 하드 디스크, 플로피 디스크 및 자기 테이프와 같은 자기 매체(magnetic media), CD-ROM, DVD와 같은 광기록 매체(optical media), 플롭티컬 디스크(floptical disk)와 같은 자기-광 매체(magneto-optical media), 및 롬(ROM), 램(RAM), 플래시 메모리 등과 같은 프로그램 명령을 저장하고 수행하도록 특별히 구성된 하드웨어 장치가 포함된다. 프로그램 명령의 예에는 컴파일러에 의해 만들어지는 것과 같은 기계어 코드뿐만 아니라 인터프리터 등을 사용해서 컴퓨터에 의해서 실행될 수 있는 고급 언어 코드를 포함한다. 위에서 설명한 하드웨어 장치는 실시예의 동작을 수행하기 위해 하나 또는 복수의 소프트웨어 모듈로서 작동하 도록 구성될 수 있으며, 그 역도 마찬가지이다."}
{"patent_id": "10-2024-0062599", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "이상과 같이 실시예들이 비록 한정된 도면에 의해 설명되었으나, 해당 기술분야에서 통상의 지식을 가진 자라면 이를 기초로 다양한 기술적 수정 및 변형을 적용할 수 있다. 예를 들어, 설명된 기술들이 설명된 방법과 다른 순서로 수행되거나, 및/또는 설명된 시스템, 구조, 장치, 회로 등의 구성요소들이 설명된 방법과 다른 형태로 결합 또는 조합되거나, 다른 구성요소 또는 균등물에 의하여 대치되거나 치환되더라도 적절한 결과가 달성될 수 있다. 그러므로, 다른 구현들, 다른 실시예들 및 특허청구범위와 균등한 것들도 후술하는 특허청구범위의 범위에 속한 다."}
{"patent_id": "10-2024-0062599", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 일 실시예에 따른 음성 신호 처리 시스템의 일 예를 나타낸다. 도 2는 도 1에 도시된 부호화기 및 복호화기를 설명하기 위한 도면이다. 도 3a 및 도 3b는 도 2에 도시된 부호화기 및 복호화기의 학습 방법을 설명하기 위한 도면이다. 도 4은 일 실시예에 따른 음성 신호를 처리하는 방법의 흐름도의 일 예를 나타낸다. 도 5는 일 실시예에 따른 전자 장치의 일 예를 나타낸다."}
