{"patent_id": "10-2023-7025704", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0137335", "출원번호": "10-2023-7025704", "발명의 명칭": "컴퓨터 구현 방법, 웨어러블 장치, 비일시적 컴퓨터판독 가능 저장 매체, 시각 장애 사용자의", "출원인": "도틀루먼 스에를르", "발명자": "아마리에이, 코르넬-마리안"}}
{"patent_id": "10-2023-7025704", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "이하의 단계를 포함하는 웨어러블 장치(1)에 의해 시각 장애 사용자의 이동을 보조하도록 구성된 컴퓨터 구현방법으로서, S1 웨어러블 장치(1)의 감각 유닛(2)에 의해 시각 장애 사용자의 환경으로부터 데이터를 획득하고, 시야(20)로부터감지하고, 상기 획득된 데이터를 웨어러블 장치(1)의 처리 및 제어 유닛(3)의 감각 융합 하위 유닛(30)에 전송하는 단계, S2 a) 획득한 데이터를 감각 융합 하위 유닛(30)에 의해 융합하고, 융합된 데이터를 처리 및 제어 유닛(3)의 라이브 맵 하위 유닛(31)에 전송하고, 이하를 포함하는 라이브 맵(310)을 라이브 맵 하위 유닛(31)에 의해 생성하고, 반복적으로 업데이트하고 저장하는 단계 - a) 하기를 포함하는, 상기 처리 및 제어 유닛(3)으로부터 수신한 융합 데이터를 기반으로 생성되는 라이브 맵결정: - 감각 유닛(2)의 위치 및 방향, - 복수의 물체(On) 및 - 복수의 생명체(Ln),상기 라이브 맵 결정은 감각 유닛(2)으로부터 수신한 데이터와 라이브 맵(310)으로부터 수신한 데이터에 적용된로컬라이제이션 알고리즘을 사용하여 라이브 맵(310)의 복수의 물체(On) 및 복수의 생명체(Ln)에 대한 감각 유닛(2)의 위치와 방향을 로컬라이제이션 모듈(301)에 의해 반복적으로 로컬라이징하는 것과, 감각 유닛(2)의 위치와 방향에 대한 상기 로컬라이제이션 데이터를 감각 융합 하위 유닛(30)의 보행 가능 영역 검출 모듈(302)에반복적으로 전송하는 것을 포함함 -,b) 복수의 물체(On) 및 복수의 생명체(Ln)가 점유하지 않는 지면 상의 영역의 앙상블로서 정의되는 자유 영역(A)에 기초하여 생성되는 라이브 맵 결정 - 상기 자유 영역(A)은영구적으로 사전 결정된 보행 가능 영역 요건 세트를 충족하는 보행 가능 영역(WA)을 포함하고, 상기 자유 영역(A)의 결정은, - 감각 유닛(2)로부터 수신된 데이터, - 로컬라이제이션 모듈(301)로부터 수신된 데이터, - 영구적인 사전 결정된 보행 가능 영역 요건 세트에 기초하고, 상기 업데이트된 자유 영역(A)은 라이브 맵(310)에 반복적으로 전송되고,상기 업데이트된 라이브 맵(310)은 메모리(M)에 반복적으로 저장됨 - S3 자동으로 또는 처리 및 제어 유닛의 네비게이션 매니저 하위 유닛에 의해 결정하는 시각 장애 사용자로부터의제1 요청에 응답하여, 시각 장애 사용자가 감각 유닛(2)의 현재 위치로부터 복수의 물체(On) 및/또는 복수의 생명체(Ln) 중에서 선택된 관심 포인트(PI)로 네비게이션하는 적어도 하나의 네비게이션 경로(Pn) 및 관련 네비게이션 안내 지시를 반복적으로 업데이트하고 저장하는 단계 - 시각 장애 사용자로부터의 임의의 요청은 사용자명령 인터페이스(5)의 햅틱 수단(51) 및 오디오 수단(52)을 이용하여 이루어지며, 상기 요청은 처리 및 제어 유공개특허 10-2023-0137335-3-닛(3)의 사용자 명령 인터페이스 매니저 하위 유닛(34)을 통해 내비게이션 매니저 하위 유닛(33)에 의해 수신됨- 와, 네비게이션 매니저 하위 유닛(33)에 의해 처리 및 제어 유닛(3)의 피드백 매니저 하위 유닛(35)에 관련네비게이션 안내 지시를 전송하는 단계, S4피드백 매니저 하위 유닛(35)에 의해, 각각의 관련 네비게이션 안내 지시를 송신하기 위한 안내 모드를 사용하여 시각 장애 사용자에 대한 안내를 제공하는 단계 - 각각의 네비게이션 지시는 피드백 매니저 하위 유닛(35)에의해 처리 및 제어 유닛(3)의 피드백 유닛(4)에 전송된 햅틱 및/또는 오디오 큐를 포함하고, 상기 피드백 유닛(4)은,- 시각 장애 사용자의 머리에 배치하도록 구성된 햅틱 피드백 액추에이터(41), 및/또는 - 시각 장애 사용자의 귀의 한쪽 또는 양쪽에 배치하도록 구성된 오디오 피드백 액추에이터(42)를 포함하고, 각각의 관련 네비게이션 안내 지시에 대한 상기 안내 모드는 사용자 명령 인터페이스(4)에 의해 그리고 사용자명령 인터페이스 매니저 하위 유닛(34)을 통해 피드백 매니저 하위 유닛(35)에 의해 수신되는 사용자 명령을 통해 시각 장애 사용자에 의해 선택됨 - 를 포함하며, S2의 상기 라이브 맵 결정은 하기를 더 포함하며,c) 처리 및 제어 유닛(3)의 관계 매니저 하위 유닛(32)으로부터 수신되는 복수의 물체(On) 및/또는 복수의 생명체(Ln) 사이의 복수의 관계(Rn)에 기초하여 생성되는 라이브 맵 결정 - 상기 복수의 관계(Rn)는 사전 결정된 관계 요건 세트를 적용하는 것을 포함하는 라이브 맵(310)으로부터 획득된 데이터에 기초하여 관계 매니저 하위유닛(32)에 의해 반복적으로 생성되고 업데이트되며, 상기 업데이트된 복수의 관계(Rn)는 라이브 맵(310)에 반복적으로 전송되고,상기 로컬라이제이션 알고리즘은 복수의 관계(Rn)에 추가로 적용됨 , S2에서, b) 자유 영역(A)에 기초하여 생성되는 상기 라이브 맵 결정은, 상기 영구적인 사전 결정된 보행 가능 영역 요건 세트 및 적어도 하나의 예측 가능한 조건부 보행 가능 영역 요건을 충족시키는 조건부 보행 가능 영역(CWA)을 더 포함하고, 또한, 보행 가능 영역(A)의 결정과 동시에, 계산되어 메모리(M)에 저장된 적어도 하나의 예측 가능한 조건부 보행 가능 영역 요건에 기초하여 조건부 보행 가능 영역(CWA)을 보행 가능 영역 검출 모듈(302)에 의해 반복적으로 결정하는 것을 더 포함하고, S3은 적어도 하나의 네비게이션 경로(Pn)의 결정 후에 a) 자동으로 또는 시각 장애 사용자의 제2 요청에 응답하여, i) 보행 가능 구역(WA) 및/또는 조건부 보행 가능 구역(CWA)을 통과하고, ii) 비충돌 요건 및 비공격성 요건을 포함하는 안전 요건 세트를 충족하는 적어도 하나의 네비게이션 경로(Pn)로부터 선호 네비게이션 경로(SP)를 반복적으로 선택하는 것 - 네비게이션 매니저 하위 유닛(33)은 처리 및 제어 유닛(3)의 피드백 매니저 하위 유닛(35)에 선호 네비게이션경로(SP)를 추가로 전송하고, 선호 네비게이션 경로(SP)가 조건부 보행 가능 영역(CWA)을 통과할 때, 네비게이션 매니저 하위 유닛(33)은 피드백 매니저 하위 유닛에 상기 적어도 하나의 예측 가능한 조건부 보행 가능 영역 요건에 대응하는 관련 네비게이션 안내 지시를 전송함 - 과,b) 선호 네비게이션 경로(SP)를 따라 피드백 매니저 하위 유닛(35)에 의해 S4의 안내를 제공하는 것을 더 포함하는 것을 특징으로 하는, 컴퓨터 구현 방법."}
{"patent_id": "10-2023-7025704", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 라이브 맵(310)은 동시적 로컬라이제이션 및 매핑(Simultaneous Localization And Mapping, SLAM) 알고리즘을공개특허 10-2023-0137335-4-사용하여 감각 융합 하위 유닛에 의해 업데이트되는, 컴퓨터 구현 방법."}
{"patent_id": "10-2023-7025704", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항 또는 제2항에 있어서, S3에서, 관심 포인트(PI)가 시각 장애 사용자에게 알려져 있지 않고 적어도 하나의 네비게이션 경로(Pn)를결정, 반복 업데이트 및 저장하기 전에, 하위 단계 3-0:S. 3-0.1. 복수의 물체(On) 중에서 선택된 적어도 하나의 물체(On) 또는 복수의 생명체(Ln) 중에서 선택된 적어도 하나의생명체에 관한 시각 장애 사용자에 의한 정보 요청을 처리 및 제어 유닛(3)의 사운드 표현 서브 유닛(36)에 전송하는 단계, S. 3-0.2. 선택된 적어도 하나의 특정 물체(On) 또는 적어도 하나의 특정 생명체(Ln)에 관한 정보를 라이브 맵(310)으로부터 처리 및 제어 유닛(3)의 사운드 표현 하위 유닛(36)에 의해 추출하고, 추출된 정보를 대응하는 공간 사운드로 표현하고, 공간 사운드를 피드백 유닛(4)에 의해 시각 장애 사용자에게 전송하는 단계,S. 3-0.3. 시각 장애 사용자가 상기 복수의 물체(On) 또는 상기 복수의 생명체(Ln) 중에서 관심 포인트(PI)을 선택하고,대응하는 선택 요청을 네비게이션 매니저 하위 유닛(33)에 전송하는 단계를 포함하는, 컴퓨터 구현 방법."}
{"patent_id": "10-2023-7025704", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항 내지 제3항 중 어느 한 항에 있어서, S3에서, 적어도 하나의 네비게이션 경로(Pn)를 결정, 반복적으로 업데이트 및 저장하기 전에, 예비 하위 단계: S. 3-1.시각 장애 사용자를 위해 관련 네비게이션 안내 지시와 함께 방황 경로(WP)를 네비게이션 매니저(33)에 의해 결정하고, 방황 경로(WP) 및 관련 네비게이션 안내 지시를 피드백 매니저 하위 유닛(35)에 전송하는 단계를 포함하는, 컴퓨터 구현 방법."}
{"patent_id": "10-2023-7025704", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항 내지 제4항 중 어느 한 항에 있어서, 햅틱 큐는 사전 결정된 선호 네비게이션 경로(SP) 복잡성 기준에 따라 진동의 지속 시간, 주기성, 강도 또는 빈도수가 변하고, 오디오 큐는 사전 결정된 선호 네비게이션 경로 복잡성 기준에 따라 주파수, 지속 시간, 반복 강도 또는 3D 공간 가상화가 변하는, 컴퓨터 구현 방법."}
{"patent_id": "10-2023-7025704", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항 내지 제5항 중 어느 한 항에 있어서, 3차원의 보행 가능 터널(T)은 수평 종축으로 선호 네비게이션 경로(SP)를 갖는 사전 결정된 단면의 가상 터널로서 정의되며, 안내 모드는 시각 장애 사용자가 보행 가능 터널(T)의 가상 벽에 접근하고 있을 때 시각 장애 사용자에게 전송되는 특정 햅틱 큐를 더 포함하는, 공개특허 10-2023-0137335-5-컴퓨터 구현 방법."}
{"patent_id": "10-2023-7025704", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항 내지 제5항 중 어느 한 항에 있어서, 선호 네비게이션 경로(SP)는 복수의 이정표(93)로 구분되는 사전 결정된 세그먼트로 분할되고, 안내 모드는 현재 이정표(93)로부터 후속 이정표(93)까지 시각 장애 사용자에게 연관된 네비게이션 안내 지시를제공하는, 다음 적어도 하나의 이정표(93)의 위치를 시그널링하는 햅틱 큐 및/또는 오디오 큐를 포함하고, 사전 결정된 세그먼트의 길이는 선호 네비게이션 경로(SP)의 복잡성과 길이에 따라 변하는, 컴퓨터 구현 방법."}
{"patent_id": "10-2023-7025704", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1항 내지 제5항 중 어느 한 항에 있어서, S4의 안내 모드는 선호 네비게이션 경로(SP) 상의 방향을 시그널링하는 햅틱 큐 및/또는 오디오 큐를 포함하고, 선호 네비게이션 경로(SP) 상의 방향은 감각 유닛(2)의 위치를 원점으로 하고 사전 결정된 길이의 반지름을 갖는 원과 선호 네비게이션 경로의 교차점과 감각 유닛의 원점에 의해 정의되는 선에 의해 결정되며, 선호 네비게이션 경로(SP) 상의 방향을 시그널링하는 오디오 큐는 감각 유닛(2)에 대해 공간화된 음원(S)의 사전 결정된 제1 거리(d1)에 배치된 공간화된 음원(S)으로부터 발생하는, 컴퓨터 구현 방법."}
{"patent_id": "10-2023-7025704", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1항 내지 제5항 중 어느 한 항에 있어서, 오디오 큐는 공간화된 음원(S)이 사전 결정된 제2 거리(d2)의 끝에 도달하고 다시 감각 유닛(2)의 위치로 돌아올 때까지 감각 유닛(2)의 위치로부터 선호 네비게이션 경로(SP) 상의 사전 결정된 제2 거리(d2)를 따라 가상으로 이동하는 공간화된 음원으로부터 발생하는 공간 사운드인, 컴퓨터 구현 방법."}
{"patent_id": "10-2023-7025704", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "하기를 포함하는 시각 장애 사용자의 이동을 보조하기 위한 웨어러블 장치(1)로서, - 하기를 포함하는, 시각 장애 사용자의 머리에 위치하도록 구성된 감각 유닛(2):- 카메라(21), - 깊이 센서(22), - 관성 측정 유닛(23), 및 - 사운드 로컬라이제이션 센서(24),- 하기를 포함하는 처리 및 제어 유닛(3):-하기를 포함하는 감각 융합 서브 유닛(30):- 로컬라이제이션 모듈(301), - 보행 가능 영역 검출 모듈(302), - 방향 계산 모듈(303), -사운드 방향 로컬라이제이션 모듈(304), - 사운드 분류 모듈(305), 공개특허 10-2023-0137335-6-- 물체 2D 특성 추출 모듈(306), - 물체 3D 특성 융합 모듈(307), - 물체 3D 특성 융합 모듈(308), - 라이브 맵 하위 유닛(31), - 관계 매니저 하위 유닛(32), - 네비게이션 매니저 하위 유닛(33), - 사용자 명령 인터페이스 매니저 하위 유닛(34), - 피드백 매니저 하위 유닛(35), - 사운드 표현 하위 유닛(36),- 하기를 포함하는, 시각 장애 사용자의 머리에 위치하도록 구성된 피드백 유닛(4):- 하기를 포함하는 복수의 햅틱 피드백 액추에이터(41):- 좌측 햅틱 피드백 액추에이터(411), - 우측 햅틱 피드백 액추에이터(412) 및 - 중앙 햅틱 피드백 액추에이터(413),- 하기를 포함하는 복수의 오디오 피드백 액추에이터(42): - 좌측 오디오 피드백 액추에이터(421) 및 - 우측 오디오 피드백 액추에이터(422),- 하기를 포함하는, 시각 장애 사용자의 머리에 배치되도록 구성된 사용자 명령 인터페이스(5):- 복수의 사용자 명령 햅틱 수단(51) 및-복수의 사용자 명령 오디오 수단(52),- 전력 저장 유닛(6)과, - 메모리(M)와,- 통신 프로토콜에 의한 감각 유닛(2), 처리 및 제어 유닛(3), 피드백 유닛(4), 사용자 명령 인터페이스(5), 전력 저장 유닛(6) 및 메모리(M) 사이의 전자 통신 수단을 포함하며,상기 웨어러블 장치(1)는 청구항 1 내지 청구항 9 중 어느 한 항에 따른 시각 장애 사용자의 이동을 보조하도록구성된 방법의 단계를 적용하도록 구성되는, 웨어러블 장치."}
{"patent_id": "10-2023-7025704", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제10항에 있어서, 감각 유닛은 감각 유닛(2)의 절대 위치를 결정하도록 구성된 글로벌 포지셔닝 센서(25)와 물체(On) 및 생명체(Ln)의 온도를 결정하도록 구성된 온도 센서(26) 중 적어도 하나의 추가 센서를 더 포함하고, 감각 융합 하위 유닛(30)은 물체 사운드 특성 융합 모듈(308)로부터의 데이터를 감각 유닛(2)의 절대 위치에 관한 데이터와 융합하도록 구성된 상대-절대 변환 모듈(309-1)과, 물체 사운드 특성 융합 모듈(308)로부터의 데이터를 물체(On) 및 생명체(Ln)의 온도에 관한 데이터와 융합하여 융합된 데이터를 라이브 맵 서브 유닛(31)에 전송하도록 구성된 물체 온도 특성 융합 모듈(309-2)을 더 포함하는, 웨어러블 장치."}
{"patent_id": "10-2023-7025704", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "의 저장 매체를 포함하는 비일시적 컴퓨터 판독 가능 저장 장치는 청구항 1 내지 청구항 9 중 어느 한항에 따른 시각 장애 사용자의 이동을 보조하도록 구성된 컴퓨터 구현 방법의 동작을 수행하는, 하나 이상의 프로세서에 의해 실행 가능한 명령어를 포함하는, 시스템."}
{"patent_id": "10-2023-7025704", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "프로그램이 청구항 10 또는 청구항 11에 따른 웨어러블 장치(1)에 의해 실행될 때 웨어러블 장치(1)가 청구항 1내지 청구항 9 중 어느 한 항에 따른 시각 장애 사용자의 이동을 보조하도록 구성된 컴퓨터 구현 방법의 단계를실행하게 하는 명령어를 포함하는 컴퓨터 프로그램."}
{"patent_id": "10-2023-7025704", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "하나 이상의 프로세서 및 하나 이상의 비일시적 컴퓨터 판독 가능 저장 장치를 포함하는 시스템으로서,"}
{"patent_id": "10-2023-7025704", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명의 제1 양태에서, 웨어러블 장치에 의해 시각 장애 사용자의 이동을 보조하기 위한 컴퓨터 구현 방법이 청구되며, S1- 시각 장애 사용자 환경으로부터 데이터를 획득하는 단계, (뒷면에 계속)"}
{"patent_id": "10-2023-7025704", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 시각 장애 사용자의 이동 보조 분야에 관한 것이다. 특히, 본 발명은 시각 장애인(본 발명 전체에서 시각 장애 사용자라고 함)의 이동을 보조하는 방법 및 웨어러블 장치에 관한 것이다. \"시각 장애\"라는 용어는 본 발명 전반에 걸쳐 중등도 장애 및 중증 장애(실명)를 포함한다."}
{"patent_id": "10-2023-7025704", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "연구에 따르면 2015년에 3,600만 명이 중증 장애를 겪었고 2억 1,660만 명이 중증의 시각 장애를 가졌다. 이 숫 자가 증가하는 동안, 사람들은 자신의 요건을 더 많이 인식하게 되었고 시각 장애 지원을 목표로 하는 해결책이 등장했다. 예를 들어, 지팡이나 안내견과 같은 고전적인 네비게이션 방법을 사용하여 시각 장애 사용자가 도시 에 더 쉽게 접근할 수 있게 되었다. 기술적인 해결책도 등장하여 맹인 및 시각 장애 사용자 커뮤니티에 의해 수 용되기 시작한다. OrCam Inc. 또는 Microsoft Inc.에서 제안한 해결책은 다양한 수준에서 채택되었다. 그러나, 기술의 발전에도 불구하고 시각 장애 사용자에게 가장 많이 사용되는 해결책은 여전히 지팡이다. 시각 장애 사용자를 보조하기 위한 기술적인 해결책은 새롭지 않다. 초기 노력은 Paul Bach-Y-Ritta 외 다수의 발명의 US 3,594,823A[1]에 있다고 생각된다. 이 특허에서 시각 신호는 맹인의 등에 대한 햅틱 피드백으로 변환 되었다. 일반적으로 시각 장애 사용자를 보조하기 위한 기술적인 해결책은 다음 카테고리 중 하나 이상에서 나타났다. - 감각적 대체 - 사용 가능한 감각을 사용하여 해당 감각을 통해 일반적으로 수신되지 않는 정보를 표현하는 것. 촉각과 같은 다른 감각 또는 사운드를 사용하여 시각 정보를 대체하기 위해 다음 몇 년 동안 여러 다른 노 력이 이루어졌다. - 감각적 대체를 사용하여 시각 장애 사용자를 위한 경로를 생성하고 해당 경로를 그들에게 전달하는 방법, - 주변 환경에서 시각 장애 사용자의 위치를 로컬라이징하는 방법 및/또는 장애물 및/또는 목표 목적지로 간주 될 수 있는 다양한 물체를 로컬라이징하는 방법, - 시각 장애 사용자에게 환경, 경로, 장애물에 대한 정보를 전달하고 그들로부터 피드백을 수신하는 방법. 다양한 해결책은 위에서 언급한 카테고리 중 하나 이상에 중점을 둔다. 2015년 7월 26일에 공개된 US 9,915,545[2]는 스마트 기기를 사용하여 맹인에게 방향을 제공하는 방법을 개시한 다. 본 방법은 적어도 2개의 센서에 의해 그리고 스마트 기기의 찾기 모드의 선택에 응답하여 스마트 기기의 주 변 환경에 대응하는 이미지 데이터 및 스마트 기기의 포지셔닝에 대응하는 포지셔닝 데이터를 검출하는 단계와,원하는 물체 또는 원하는 위치를 입력 장치에 의해 수신하는 단계와, 스마트 기기의 메모리에 저장된 이미지 데 이터, 포지셔닝 데이터 및 맵 데이터에 기초하여 프로세서에 의해 스마트 기기의 초기 위치를 결정하는 단계와, 스마트 기기의 초기 위치 및 맵 데이터에 기초하여 원하는 물체에 대한 방향을 출력 장치에 의해 제공하는 단계 를 포함한다. 2015년 7월 16일에 공개된 US 9,629,774[3]에는 적어도 하나의 캐비티를 정의하고 목 부분과 제1 및 제2 측면 부분을 갖는 본체를 포함하는 스마트 목걸이가 개시되어 있다. 목걸이는 스마트 목걸이의 주변 환경에 대응하는 깊이 정보를 포함하는 이미지 데이터를 검출하도록 구성된 한 쌍의 스테레오 카메라를 포함한다. 목걸이는 스마 트 목걸이의 포지셔닝에 대응하는 포지셔닝 데이터를 검출하도록 구성된 포지셔닝 센서를 더 포함한다. 목걸이 는 적어도 하나의 캐비티에 배치되고 맵 데이터 및 물체 데이터를 저장하도록 구성된 비일시적 메모리를 포함한 다. 스마트 목걸이는 한 쌍의 스테레오 카메라, 포지셔닝 센서 및 비일시적 메모리에 연결된, 적어도 하나의 캐 비티에 위치한 프로세서를 또한 포함한다. 프로세서는 이미지 데이터, 포지셔닝 데이터, 맵 데이터 및 물체 데 이터에 기초하여 출력 데이터를 결정하도록 구성된다. 2016년 11월 15일에 발표된 학술 논문[4], \"시각 장애 사용자를 위한 상황 기반 의사 결정 기능을 갖춘 웨어러 블 실내 네비게이션 시스템\"[4]에서, Xiaochen Zhang 외 다수 저자는 시각 장애 사용자를 위한 웨어러블 실내 네비게이션 시스템을 제공한다. 이 시스템은 RGB-D 카메라, 관성 측정 유닛(Inertial Measurement Unit, IMU) 및 웹 카메라와 같은 피드백 유닛와 여러 센서를 내장한, 로컬라이제이션 및 네비게이션을 위한 동시적 로컬라 이제이션 및 매핑(Simultaneous Localization And Mapping, SLAM) 및 시맨틱 경로 플래닝을 사용한다. 이 시스 템은 사용자의 위치와 방향을 추정하기 위해 RGB-D 기반 시각적 오도메트리 알고리즘을 적용하고 방향 오류를 개선하기 위해 관성 측정 유닛(IMU)를 적용한다. 사용자의 위치를 로컬라이징하기 위해 방 번호, 복도 코너 등 주요 랜드마크가 웹 카메라와 RGB-D 카메라에 의해 검출되어, 디지털화된 층별도와 매칭된다. 경로 및 모션 안 내가 생성되어 사용자를 원하는 목적지로 안내한다. 이 논문은 잘못된 관찰로 인한 사용자의 혼란을 해결하기 위해 경로 플래닝에 대한 컨텍스트 기반 의사 결정 메커니즘에서 엄격한 명령과 인간을 위한 최적의 기계 결정 사이의 적합성을 개선하는 방법을 제안한다. US 2016/0033280 A1[5]은 지능형 이어피스에 결합된 관성 측정 유닛(IMU), 글로벌 포지셔닝 시스템(Global Positioning System, GPS) 유닛 및 적어도 하나의 카메라에 연결된 프로세서를 포함하는, 사용자의 귀에 착용되 는 지능형 이어피스를 개시한다. IMU는 지능형 이어피스의 위치, 속도 또는 가속도에 대응하는 관성 측정 데이 터를 검출하도록 구성되고, 글로벌 포지셔닝 시스템(GPS) 유닛은 지능형 이어피스의 위치에 대응하는 위치 데이 터를 검출하도록 구성되며, 적어도 하나의 카메라는 지능형 이어피스에 연결되고 지능형 안내 장치의 주변 환경 에 대응하는 이미지 데이터를 검출하도록 구성된다. 이어피스는 IMU, GPS 유닛 및 적어도 하나의 카메라에 연결 된 프로세서를 또한 포함한다. 프로세서는 주변 환경에서 물체를 인식하도록 구성된다. 이는 저장된 물체 데이 터 및 관성 측정 데이터 또는 위치 데이터 중 적어도 하나에 기초하여 이미지 데이터를 분석함으로써 행해진다. 프로세서는 결정된 바람직한 이벤트 또는 행동에 기초하여 목적지를 결정할 수 있다. 프로세서는 결정된 목적지, 이미지 데이터, 관성 측정 데이터 또는 위치 데이터에 기초하여 목적지까지 지능형 안내 장치를 네비게 이션하기 위한 네비게이션 경로를 결정할 수 있다. 프로세서는 결정된 네비게이션 경로에 데이터베이스화된 출 력을 결정할 수 있다. US 2016/0033280 A1[5]에는 시각 장애 사용자를 위한 장치의 특정 개조가 개시되어 있지 않다. 당업자는 시각 장애 사용자의 이동을 보조하는 모든 장치가 시각 장애 사용자가 볼 수 없거나 간신히 볼 수 있 기 때문에 시각 장애 사용자가 시각을 이용하여 얻을 수 없는 환경으로부터의 정보를 주로 사용자에게 제공해야 함을 알고 있다. 즉, 시각 장애 사용자의 네비게이션을 보조하는 장치에 사용되는 모든 센서 중에서, 비디오 카 메라가 가장 중요하다. 이 중요한 측면을 염두에 두고 US 2016/0033280 A1은 도 8b 및 도 9b에 도시된 바와 같이 사용자의 귀 중 하나 에 뒤에 착용되는 단일 이어피스를 개시하고 있다. US 2016/0033280 A1의 이어피스를 시각 장애 사용자가 사용하는 경우, 이어피스의 위치가 귀 뒤에 있기 때문에, 카메라의 시야가 시각 장애 사용자의 머리에 의해 부분적으로 가려지고, 따라서 이어피스는 환경을 완전히 커버 하는 이미지를 제공할 수 없다. 예를 들어, 이어피스가 좌측 귀 뒤에 있으면, 우측 시야의 일부가 사용자의 머 리에 의해 가려진다. US 2016/0033280 A1은 당업자가 일반적인 일반 지식을 사용하여 추가 카메라의 대체 위치의 주제를 재현할 수 있도록 각각의 구현을 자세히 설명하지 않고, 추가 카메라의 대체 위치를 불완전하게 개시하고 있다. 선행 기술의 단점 감각적 대체에 관하여, 알려진 해결책은 일반적으로 청각 및/또는 햅틱에 내장된 것보다 훨씬 더 큰 것으로 알 려진 시력의 대역폭을 부적절하게 대체하여 너무 부족한 정보 또는 너무 많은 비필수 정보를 제공하여 사용자를 혼란스럽게 하거나 성가시게 한다. 맵을 생성하는 방법 및/또는 시각 장애 사용자를 위한 경로를 생성하여 그들에게 상기 경로를 전달하는 방법에 관하여, 종래 기술의 네비게이션/GPS 기반 방법은 일반적인 경로를 제공하지만 장애물이나 생명체를 피하기 위 해 아무것도 하지 않는다. 환경 내에서 시각 장애 사용자의 위치를 로컬라이징하는 방법 및/또는 장애물 및/또는 목표 목적지로 볼 수 있 는 다양한 물체를 로컬라이징하는 방법에 관하여, Microsoft Seeing AI 또는 OrCam과 같은 방법은 시각 장애 사 용자의 제한된 시야에 존재하는 물체만 인식하지만 목표 목적지에 도달하는 방법에 대한 충분한 정보를 제공하 지 않는다. 일반적으로, 알려진 해결책은 센서에 의해 검출된 물체의 위치를 저장할 가능성이 없거나 감소되어 있으며, 결과적으로 과거에 검출된 물체를 인식할 가능성이 없거나 감소했다. 알려진 해결책은 물체에 대한 완 전한 정보, 예를 들어 의자가 다른 사람에 의해 점유된 경우 시각 장애 사용자가 매우 위생적이지 않고, 위험할 수 있고 너무 많은 시간이 걸릴 수 있는 해당 물리적, 화학적 특성을 인식하기 위해 해당 물체를 만질 필요가 있는 물체의 크기 및 기타 물리적, 화학적 특성과 같은, 시각 장애 사용자에게 유용할 수 있는 정보를 제공할 가능성이 없다. 시각 장애 사용자에게 환경, 경로 또는 장애물에 관한 정보를 전달하고 그들로부터 피드백을 수신하는 방법과 관련하여, 대부분의 현재 해결책은 시각 장애 사용자에게 정보를 너무 느리게 전달하고 및/또는 피드백을 너무 느리게 수신하여 초기 경로의 수정을 어렵게 하게 지연시킨다. 예를 들어 US 9,629,774[3]의 실시예에서, 스마트 목걸이가 계단, 화장실 출구 또는 빈 좌석을 인식할 수 있지 만, 상기 목걸이는 물체의 특성: 걸쇠나 문손잡이를 만지거나 빈 좌석이 더러운 경우, 방향과 같은 보다 심층적 인 정보를 제공하도록 구성되지 않는다. US 9,629,774[3]는 스마트 목걸이가 45도 회전, 90도 회전, 좌회전, 우회전과 같은 다양한 각도의 회전으로 시 각 장애 사용자에게 전송할 수 있는 제한된 수의 명령 유형을 교시한다. 이러한 정보 전달 방법을 사용하면, US 9,629 774[3]는 시각 장애가 없는 사람의 자연 경로 생성과 비교할 때 엄격하다. US 9,629,774[3]는 다른 특성 없이 다양한 물체의 위치만 포함하는 맵에 대해 교시한다. US 9,915,545[2]는 전자 장치의 시각 장애 사용자에게 전자 장치의 현재 위치에서 원하는 물체의 위치까지의 방 향을 제공하는 방법을 교시한다. 이 방법에서는 경로가 생성되는 영역의 유형 간에 구분이 없으며, 다양한 물체 간에 구축된 관계가 없으며 생명체의 감정 상태의 검출 또는 표면의 청결도와 같은 물체와 생명체의 일부 중요 한 특성이 생략되고 맵의 콘텐츠가 센서의 시야 정보로 축소된다."}
{"patent_id": "10-2023-7025704", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명이 해결하고자 하는 과제는 사용자가 비시각 장애 사용자의 네비게이션에 더 가까운 방식으로 실내 및 실외를 네비게이션할 수 있게 하는 시각 장애 사용자의 이동을 보조하도록 구성된 방법을 제공하는 것이다. 특 히, 본 발명이 해결하고자 하는 과제는 다음과 같다. - 시각 장애 사용자의 보다 안전한 네비게이션 및 보다 구체적인 네비게이션 목표를 목적으로 물체와 생명체 사 이의 보다 정확하고 보다 상세한 관계를 제공하는 것을 포함하여 사용자의 환경에 대한 보다 정확하고 보다 상 세한 표현을 제공하는 것. - 보다 정확하고 상세한 네비게이션 경로 생성을 제공하는 것. - 정확성과 보안 측면에서 네비게이션 경로를 따라 시각 장애 사용자에게 더 나은 안내를 제공하는 것. - 네비게이션 경로를 따라 시각 장애 사용자에게 더 나은 안내를 제공하여 더 편안하고 비시각 장애 사용자와 유사한 결정을 내릴 수 있는 가능성을 제공하는 것."}
{"patent_id": "10-2023-7025704", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 제1 양태에서, 웨어러블 장치를 통해 시각 장애 사용자의 이동을 보조하도록 구성된 방법이 제공되며, 이 방법은 다음 단계를 포함한다. S1 웨어러블 장치의 감각 유닛에 의해 시각 장애 사용자의 환경으로부터 데이터를 획득하고, 시야로부터 감지하 고, 상기 획득된 데이터를 웨어러블 장치의 처리 및 제어 유닛의 감각 융합 하위 유닛에 전송하는 단계, S2 획득한 데이터를 감각 융합 하위 유닛에 의해 융합하고, 융합된 데이터를 처리 및 제어 유닛의 라이브 맵 하위 유닛에 전송하고, 라이브 맵을 라이브 맵 하위 유닛에 의해 생성하고, 반복적으로 업데이트하고 저장하는 단계 - 라이브 맵은 다음의 데이터를 포함함 - 1. 이하를 포함하여 감각 융합 하위 유닛으로부터 수신한 융합 데이터를 기반으로 하는 라이브 맵 결정 데이터 - 감각 유닛의 위치 및 방향 - 복수의 물체 - 복수의 생명체 2. 처리 및 제어 유닛의 관계 매니저 하위 유닛으로부터 수신된 복수의 물체 및/또는 복수의 생명체 사이의 복 수의 관계에 기초하여 생성되는 라이브 맵 결정 데이터 3. 복수의 물체 및 복수의 생명체(Ln)가 점유하지 않는 지면 상의 영역의 앙상블로서 정의되는 자유 영역에 기 초하여 생성되는 라이브 맵 결정 데이터로서, 상기 자유 영역(A)은, 영구적으로 사전 결정된 보행 가능 영역 요건 세트를 충족하는 보행 가능 영역, 상기 영구적인 사전 결정된 보행 가능 영역 요건 세트 및 적어도 하나의 예측 가능한 조건부 보행 가능 영역 요 건을 충족하는 조건부 보행 가능 영역을 포함하며, S3 자동으로 또는 처리 및 제어 유닛의 네비게이션 매니저 하위 유닛에 의해 결정하는 시각 장애 사용자로부터의 요청에 응답하여, 시각 장애 사용자가 감각 유닛의 현재 위치로부터 복수의 물체 및/또는 복수의 생명체 중에서 선택된 관심 포인트로 네비게이션하는 적어도 하나의 네비게이션 경로 및 관련 네비게이션 안내 지시를 반복적 으로 업데이트하고 저장하는 단계, 자동으로 또는 시각 장애 사용자로부터의 요청에 응답하여, i) 보행 가능 영역 및/또는 조건부 보행 가능 영역 을 통과하는 요건 및 ii) 비충돌 요건 및 비공격성 요건을 포함하는 안전 요건 세트를 충족하는 요건 중 적어도 2개의 네비게이션 경로 요건을 충족하는 적어도 하나의 네비게이션 경로에서 선호 네비게이션 경로를 반복적으 로 선택하는 단계 - 여기서, 시각 장애 사용자로부터의 임의의 요청은 사용자 명령 인터페이스의 햅틱 수단 또 는 오디오 수단을 사용하여 이루어지며, 상기 요청은 처리 및 제어 유닛의 사용자 명령 인터페이스 매니저 하위 유닛을 통해 네비게이션 매니저 하위 유닛에 의해 수신됨 - 네비게이션 매니저 하위 유닛에 의해 처리 및 제어 유닛의 피드백 매니저 하위 유닛에 i) 선호 네비게이션 경로 및 ii) 관련 네비게이션 안내 지시를 송신하는 단계 - 여기서, 선호 네비게이션 경로(SP)가 조건부 보행 가능 영역을 통과할 때, 네비게이션 매니저 서브 유닛은 상기 적어도 하나의 예측 가능한 조건부 보행 가능 영역 요 건에 대응하는 관련 네비게이션 안내 지시를 피드백 매니저 하위 유닛에 전송함 - S4 피드백 매니저 하위 유닛에 의해, 선호 네비게이션 경로를 따라, 각각의 관련 네비게이션 안내 지시(각각의 네 비게이션 지시는 피드백 매니저 하위 유닛에 의해 처리 및 제어 유닛의 피드백 유닛에 전송된 햅틱 및/또는 오 디오 큐를 포함함)를 송신하기 위한 안내 모드를 사용함으로써, 시각 장애 사용자에 대한 안내를 제공하는 단계, - 상기 피드백 유닛은 시각 장애 사용자의 머리에 배치하도록 구성된 햅틱 피드백 액추에이터 및/또는 시각 장애 사용자의 귀의 한쪽 또는 양쪽에 배치하도록 구성된 오디오 피드백 액추에이터를 포함하고, 여기서 각각의 관련 네비게이션 안내 지시에 대한 안내 모드는 사용자 명령 인터페이스에 의해 그리고 사용자 명령 인터페이스 매니저 하위 유닛을 통해 피드백 매니저 하위 유닛에 의해 수신되는 사용자 명령을 통해 시각 장애 사용자에 의해 선택됨 - 를 포함한다. 본 발명의 제2 양태에서, 하기를 포함하는, 시각 장애 사용자의 이동을 보조하기 위한 웨어러블 장치가 제공 되며: - 하기 기본 센서를 포함하는, 시각 장애 사용자의 머리에 위치하도록 구성된 감각 유닛: - 카메라, - 깊이 센서, - 관성 측정 유닛, - 사운드 로컬라이제이션 센서, -하기를 포함하는 처리 및 제어 유닛: - 하기를 포함하는 감각 융합 서브 유닛: - 로컬라이제이션 모듈, - 보행 가능 영역 검출 모듈, - 방향 계산 모듈, - 사운드 방향 로컬라이제이션 모듈, - 사운드 분류 모듈, - 물체 2D 특성 추출 모듈, - 물체 3D 특성 융합 모듈, - 물체 사운드 특성 융합 모듈, -라이브 맵 하위 유닛, - 관계 매니저 하위 유닛, - 네비게이션 매니저 하위 유닛, - 사용자 명령 인터페이스 매니저 하위 유닛, - 피드백 매니저 하위 유닛, - 사운드 표현 하위 유닛, - 하기를 포함하는 시각 장애 사용자의 머리에 위치하도록 구성된 피드백 유닛: - 하기를 포함하는 복수의 햅틱 피드백 액추에이터: - 좌측 햅틱 피드백 액추에이터, - 우측 햅틱 피드백 액추에이터, - 중앙 햅틱 피드백 액추에이터, - 하기를 포함하는 복수의 햅틱 피드백 액추에이터: - 좌측 오디오 피드백 액추에이터, - 우측 오디오 피드백 액추에이터, - 하기를 포함하는, 시각 장애 사용자의 머리에 배치되도록 구성된 사용자 명령 인터페이스: - 복수의 사용자 명령 햅틱 수단, - 복수의 사용자 명령 오디오 수단, - 전력 저장 유닛, - 메모리, 및 - 통신 프로토콜에 의한 감각 유닛, 처리 및 제어 유닛, 피드백 유닛, 사용자 명령 인터페이스, 전력 저장 유닛 및 메모리 사이의 전자 통신 수단, 여기서 웨어러블 장치는 이들의 조합을 포함하여 본 발명의 임의의 실시예에 따른 방법의 단계를 적용하도록 구 성된다. 본 발명의 제3 양태에서, 컴퓨터 프로그램으로 인코딩된 비일시적 컴퓨터 판독 가능 저장 매체가 제공되며, 컴 퓨터 프로그램은 이들의 조합을 포함하여 임의의 바람직한 실시예에서 이러한 실행 시 하나 이상의 프로세서로 하여금 시각 장애 사용자의 이동을 보조하도록 구성된 컴퓨터 구현 방법의 동작을 수행하게 하는, 하나 이상의 프로세서에 의해 실행 가능한 명령어를 포함한다. 본 발명의 제4 양태에서, 프로그램이 웨어러블 장치에 의해 실행될 때 본 발명의 임의의 구현에 따라 웨어러블 장치가 이들의 조합을 포함하는 임의의 바람직한 실시예에서, 시각 장애 사용자의 이동을 보조하도록 구성된 컴 퓨터 구현 방법의 단계를 수행하게 하는 명령어를 포함하는 컴퓨터 프로그램이 제공된다. 본 발명의 제5 양태에서, 하나 이상의 프로세서와 하나 이상의 비일시적 컴퓨터 판독 가능 저장 장치를 포함하 는 시스템이 제공되고, 비일시적 컴퓨터 판독 가능 저장 장치는 이들의 조합을 포함하여 임의의 바람직한 실시 예에서 시각 장애 사용자의 이동을 보조하도록 구성된 컴퓨터 구현 방법의 동작을 수행하기 위해 하나 이상의 프로세서에 의해 실행 가능한 명령어를 포함한다. 하나의 예시적인 구현예에 따르면, 컴퓨터 구현 방법은 시야로부터 감지하는 웨어러블 장치의 감각 유닛을 포함 하는 시각 장애 사용자의 환경으로부터 데이터를 획득하는 단계와, 획득된 데이터를 웨어러블 디바이스의 처리 및 제어 유닛의 감각 융합 하위 유닛에 전송하는 단계와, 획득한 데이터를 감각 융합 하위 유닛에 의해 융합하 는 단계와, 융합된 데이터를 처리 및 제어 유닛의 라이브 맵 하위 유닛에 전송하는 단계와, 라이브 맵을 라이브 맵 하위 유닛에 의해 생성, 반복 업데이트 및 저장하는 단계를 포함한다. 라이브 맵은 감각 유닛, 복수의 물체, 및 복수의 생명체의 위치 및 방향을 포함한, 감각 융합 하위 유닛으로부터 처리 및 제어 유닛에서 수신된 융합 된 데이터에 기초하여 생성되는 하나 이상의 라이브 맵 결정과, 처리 및 제어 유닛의 관계 매니저 하위 유닛으 로부터 수신되는, 복수의 물체 또는 복수의 생명체 사이 또는 복수의 물체 또는 복수의 생명체 사이의 복수의 관계에 기초하여 생성되는 하나 이상의 라이브 맵 결정과, 복수의 물체 및 복수의 생명체가 점유하지 않는 지면 상의 영역의 앙상블로 정의되는 자유 영역(자유 구역은 영구적인 사전 결정된 보행 가능 영역 요건 세트를 충족 하는 보행 가능 영역과, 영구적인 사전 결정된 보행 가능 영역 요건 세트 및 적어도 하나의 예측 가능한 조건부 보행 가능 영역 요건을 충족하는 조건부 보행 가능 영역을 포함함)에 기초하여 생성되는 하나 이상의 라이브 맵 결정을 포함한다. 이 방법은 자동으로 또는 시각 장애 사용자로부터의 제1 요청에 응답하여, 시각 장애 사용자 가 감각 유닛의 현재 위치로부터 복수의 물체 또는 복수의 생명체 또는 복수의 물체와 복수의 생명체 중에서 선 택된 관심 포인트로 네비게이션하는 적어도 하나의 네비게이션 경로 및 관련 네비게이션 안내 지시를 처리 및 제어 유닛의 네비게이션 매니저 하위 유닛에 의해 결정하고 반복적으로 업데이트하고 저장하는 단계와, 자동으 로 또는 시각 장애 사용자로부터의 제2 요청에 응답하여, (i) 보행 가능 영역 또는 조건부 보행 가능 영역 또는 보행 가능 영역과 조건부 보행 가능 영역을 통과하고 (ii) 비충돌 요건 및 비공격성 요건을 포함하는 안전 요건 세트를 충족하는 적어도 하나의 네비게이션 경로 중에서 선호 네비게이션 경로를 반복적으로 선택하는 단계 - 여기서, 시각 장애 사용자로부터의 임의의 요청은 사용자 명령 인터페이스의 햅틱 수단 또는 오디오 수단을 사 용하여 이루어지며, 상기 요청은 처리 및 제어 유닛의 사용자 명령 인터페이스 매니저 하위 유닛을 통해 네비게 이션 매니저 하위 유닛에 의해 수신됨 - 와, 네비게이션 매니저 하위 유닛에 의해 처리 및 제어 유닛의 피드백 매니저 하위 유닛에 선호 네비게이션 경로 및 관련 네비게이션 안내 지시를 송신하는 단계 - 여기서, 선호 네비 게이션 경로가 조건부 보행 가능 영역을 통과할 때, 네비게이션 매니저 서브 유닛은 상기 적어도 하나의 예측 가능한 조건부 보행 가능 영역 요건에 대응하는 관련 네비게이션 안내 지시를 피드백 매니저 하위 유닛에 전송 함 - 와, 피드백 매니저 하위 유닛에 의해, 선호 네비게이션 경로를 따라, 각각의 관련 네비게이션 안내 지시(각각의 네비게이션 지시는 피드백 매니저 하위 유닛에 의해 처리 및 제어 유닛의 피드백 유닛에 전송된 햅틱 및/또는 오디오 큐를 포함함)를 송신하기 위한 안내 모드를 사용함으로써, 시각 장애 사용자에 대한 안내를 제 공하는 단계 - 피드백 유닛은 시각 장애 사용자의 머리에 배치하도록 구성된 햅틱 피드백 액추에이터 및/또는 시각 장애 사용자의 귀의 한쪽 또는 양쪽에 배치하도록 구성된 오디오 피드백 액추에이터를 포함하고, 여기서 각각의 관련 네비게이션 안내 지시에 대한 안내 모드는 사용자 명령 인터페이스에 의해 그리고 사용자 명령 인 터페이스 매니저 하위 유닛을 통해 피드백 매니저 하위 유닛에 의해 수신되는 사용자 명령을 통해 시각 장애 사 용자에 의해 선택됨 - 를 포함한다. 일부 구현예는 다음의 특징 중 하나 이상을 포함한다. 예를 들어, 이 방법은 감각 융합 하위 유닛으로부터 수신 된 융합 데이터에 기초하여 감각 유닛의 위치 및 방향, 복수의 물체 및 복수의 생명체의 위치, 방향 및 특성을 반복적으로 결정하는 것을 포함하여 라이브 맵을 생성 및 업데이트하는 단계와, 생성 및 업데이트된 라이브 맵 을 감각 융합 서브 유닛의 로컬라이제이션 모듈에 반복적으로 전송하는 단계와, 사전 결정된 관계 요건 세트를 적용하는 것을 포함하여 라이브 맵으로부터 획득된 데이터에 기초하여 복수의 물체 또는 복수의 생명체 또는 복 수의 물체와 복수의 생명체 사이의 복수의 관계를 관계 매니저 서브 유닛에 의해 반복적으로 생성 및 업데이트 하는 단계와, 업데이트된 복수의 관계를 라이브 맵에 반복적으로 전송하는 단계와, 감각 유닛으로부터 수신한 데이터와 라이브 맵으로부터의 데이터에 적용된 로컬라이제이션 알고리즘을 이용하여 라이브 맵의 복수의 물체 및 복수의 생명체에 대한 감각 유닛의 위치 및 방향을 로컬라이제이션 모듈에 의해 반복적으로 로컬라이징하는 단계와, 감각 유닛의 위치 및 방향의 로컬라이제이션 데이터를 감각 융합 서브 유닛의 보행 가능 영역 검출 모 듈에 반복적으로 전송하는 단계와, 감각 유닛으로부터 수신된 데이터, 로컬라이제이션 모듈로부터 수신된 데이 터, 영구적인 사전 결정된 보행 가능 영역 요건 세트, 및 계산되어 메모리에 저장된 적어도 하나의 예측 가능한 조건부 보행 가능 영역 요건에 기초하는 자유 영역을 보행 가능 영역 검출 모듈에 의해 반복적으로 결정하는 단 계와, 업데이트된 자유 영역을 라이브 맵에 반복적으로 전송하는 단계와, 업데이트된 라이브 맵을 메모리에 저 장하는 단계를 포함한다. 라이브 맵은 SLAM(Simultaneous Localization and Mapping) 알고리즘을 사용하여 감 각 융합 하위 유닛에 의해 업데이트된다. 이 방법은 복수의 물체 중에서 선택된 적어도 하나의 물체 또는 복수 의 생명체 중에서 선택된 적어도 하나의 생명체에 관한 시각 장애 사용자에 의한 정보 요청을 처리 및 제어 유 닛의 사운드 표현 하위 유닛에 전송하는 단계와, 선택된 적어도 하나의 특정 물체 또는 적어도 하나의 특정 생 명체에 관한 정보를 처리 및 제어 유닛의 사운드 표현 하위 유닛에 의해 라이브 맵으로부터 추출하는 단계와, 추출된 정보를 대응하는 공간 사운드로서 표현하는 단계와, 공간 사운드를 피드백 유닛에 의해 시각 장애 사용 자에게 송신하는 단계와, 상기 복수의 물체 또는 상기 복수의 생명체 중 관심 포인트를 시각 장애 사용자에 의 해 선택하는 단계와, 대응하는 선택 요청을 네비게이션 매니저 하위 유닛에 송신하는 단계를 포함한다. 이 방법 은 네비게이션 매니저에 의해 시각 장애 사용자를 위한 관련 네비게이션 안내 지시와 함께 방황 경로를 결정하 는 단계와, 방황 경로 및 관련 네비게이션 안내 지시를 피드백 매니저 하위 유닛에 전송하는 단계를 포함한다. 햅틱 큐는 사전 결정된 선호 네비게이션 경로 복잡성 기준에 따라 진동의 지속 시간, 주기성, 강도 또는 빈도수 가 변하고, 오디오 큐는 사전 결정된 선호 네비게이션 경로 복잡도 기준에 따라 빈도수, 지속 기간, 반복 강도 또는 3D 공간 가상화가 변한다. 3차원의 보행 가능 터널은 수평 종축으로 선호 네비게이션 경로를 갖는 사전 결 정된 단면의 가상 터널로서 정의되며, 안내 모드는 시각 장애 사용자가 보행 가능 터널의 가상 벽에 접근하고 있을 때 시각 장애 사용자에게 전송되는 특정 햅틱 큐를 더 포함한다. 선호 네비게이션 경로는 복수의 이정표로 구분되는 사전 결정된 세그먼트로 분할되고, 안내 모드는 현재 이정표로부터 후속 이정표까지 시각 장애 사용자 에게 연관된 네비게이션 안내 지시를 제공하는, 다음 적어도 하나의 이정표의 위치를 시그널링하는 햅틱 큐 또 는 오디오 큐를 포함하고, 사전 결정된 세그먼트의 길이는 선호 네비게이션 경로의 복잡성과 길이에 따라 변한 다. 안내 모드는 선호 네비게이션 경로 상의 방향을 시그널링하는 햅틱 큐 또는 오디오 큐 또는 햅틱 및 오디오 큐를 포함한다. 선호 네비게이션 경로 상의 방향은 감각 유닛의 위치를 원점으로 하고 사전 결정된 길이의 반지 름을 갖는 원과 선호 네비게이션 경로의 교차점과 감각 유닛의 원점에 의해 정의되는 선에 의해 결정되며, 선호 네비게이션 경로 상의 방향을 시그널링하는 오디오 큐는 감각 유닛에 대해 공간화된 음원(s)의 사전 결정된 제1 거리에 배치된 공간화된 음원으로부터 발생한다. 오디오 큐는 공간화된 음원이 사전 결정된 제2 거리의 끝에 도 달하고 다시 감각 유닛의 위치로 돌아올 때까지 감각 유닛의 위치로부터 선호 네비게이션 경로 상의 사전 결정 된 제2 거리를 따라 가상으로 이동하는 공간화된 음원으로부터 발생하는 공간 사운드이다. 다른 일반적인 구현예에서, 시각 장애 사용자의 이동을 보조하는 웨어러블 장치는 카메라, 깊이 센서, 관성 측 정 유닛 및 사운드 로컬라이제이션 센서를 포함하는, 시각 장애 사용자의 머리에 배치되도록 구성된 감각 유닛 을 포함한다. 이 장치는 로컬라이제이션 모듈, 보행 가능 영역 검출 모듈, 방향 계산 모듈, 사운드 방향 로컬라 이제이션 모듈, 사운드 분류 모듈, 물체 2d 특성 추출 모듈, 물체 3d 특성 융합 모듈 및 물체 사운드 특성 융합모듈을 포함하는 감각 융합 하위 유닛을 포함하는 처리 및 제어 유닛을 포함한다. 이 장치는 라이브 맵 하위 유 닛, 관계 매니저 하위 유닛, 네비게이션 매니저 하위 유닛, 사용자 명령 인터페이스 매니저 하위 유닛, 피드백 매니저 하위 유닛 및 사운드 표현 하위 유닛을 포함한다. 이 장치는 좌측 햅틱 피드백 액추에이터, 우측 햅틱 피드백 액추에이터, 중앙 햅틱 피드백 액추에이터를 포함하는 복수의 햅틱 피드백 액추에이터와, 좌측 오디오 피드백 액추에이터 및 우측 오디오 피드백 액추에이터를 포함하는 복수의 오디오 피드백 액추에이터를 포함하는, 시각 장애 사용자의 머리에 배치되도록 구성된 피드백 유닛을 포함한다. 이 장치는 복수의 사용자 명 령 햅틱 수단 및 복수의 사용자 명령 오디오 수단을 포함하는, 시각 장애 사용자의 머리에 배치하도록 구성된 사용자 명령 인터페이스를 포함한다. 이 장치는 전력 저장 유닛, 메모리, 감각 유닛, 처리 및 제어 유닛, 피드 백 유닛, 사용자 명령 인터페이스, 전력 저장 유닛 및 메모리 사이의 전자 통신 구성 요소를 포함한다. 예시적인 구현예는 다음 특징 중 하나 이상을 포함한다. 감각 유닛은 감각 유닛의 절대 위치를 결정하도록 구성 된 글로벌 포지셔닝 센서 또는 물체 및 생명체의 온도를 결정하도록 구성된 온도 센서 중 적어도 하나의 추가 센서를 포함한다. 감각 융합 하위 유닛은 물체 사운드 특성 융합 모듈로부터의 데이터를 감각 유닛의 절대 위치 에 관한 데이터와 융합하도록 구성된 상대-절대 변환 모듈과, 물체 사운드 특성 융합 모듈로부터의 데이터를 물 체 및 생명체의 온도에 관한 데이터와 융합하여 융합된 데이터를 라이브 맵 서브 유닛에 전송하도록 구성된 물 체 온도 특성 융합 모듈을 포함한다. 다른 예시적인 구현예는 하나 이상의 프로세서, 및 개시된 방법에 대응하는 동작을 수행하기 위해 하나 이상의 프로세서에 의해 실행 가능한 명령어를 저장하는 하나 이상의 비일시적 기계 판독 가능 저장 장치를 포함하는 시스템, 또는 컴퓨터 프로그램 - 컴퓨터 프로그램은 하나 이상의 프로세서에 의해 실행될 때 하나 이상의 프로 세서로 하여금 개시된 방법에 대응하는 동작을 수행하게 하는 명령어를 포함함 - 으로 인코딩된 비일시적 컴퓨 터 저장 매체를 포함한다. 본 발명의 하나의 양태의 임의의 특징은 임의의 적절한 조합으로 본 발명의 다른 양태에 적용될 수 있다. 특히, 방법 특징은 장치 특징에 적용될 수 있으며 그 반대도 가능하다. 적용 가능한 경우, 수단 + 기능 특징은 적절하게 프로그래밍된 프로세서 및 관련 메모리와 같은 그들의 대응하 는 구조로 대안적으로 표현될 수 있다. 본 발명의 다양한 특징의 특정 조합은 독립적으로 구현 및/또는 공급 및/또는 사용될 수 있다."}
{"patent_id": "10-2023-7025704", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명의 주요 이점은 다음과 같다. - 사용자 환경에 대한 보다 정확하고 상세한 표현, 네비게이션 경로의 보다 정확하고 상세한 생성, 및 네비게이 션 경로를 따르는 사용자의 보다 정확하고 안전한 안내로 인해, 시각 장애 사용자가 보다 안전하게 네비게이션 하고 일상 생활의 물체와 생명체에 보다 정확하게 접근할 수 있도록 한다. - 편안함과 의사 결정 가능성 측면에서 시각 장애가 없는 사용자의 경험에 더 가까운 네비게이션 경험을 제공한 다."}
{"patent_id": "10-2023-7025704", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "참조 리스트 이 리스트에는 설명 및/또는 도면에 있는 구성 요소, 파라미터 또는 기준에 대한 참조가 포함된다. 이것은 발명 을 용이하게 읽게 하기 위해 만들어졌다. 1 : 웨어러블 기기 11 : 헤드셋 구성 요소 12 : 벨트 착용 구성 요소 12 : 손목 구성 요소 - 그래픽으로 표시되지 않음 13 : 휴대용 구성 요소 - 그래픽으로 표시되지 않음 2 : 감각 유닛 21, 22, 23, 24 : 기본 센서 20 : 기본 센서의 시야 21 : 카메라 22 : 깊이 센서 21-22 : 카메라 및 깊이 센서 - 그래픽으로 표시되지 않음 23 : 관성 측정 유닛 24 : 사운드 로컬라이제이션 센서 21-22 : 카메라 및 깊이 센서 - 그래픽으로 표시되지 않음 25, 26 : 추가 센서 25 : 글로벌 포지셔닝 센서 26 : 온도 센서 3 : 처리 및 제어 유닛 30 : 감각 융합 하위 유닛 301 : 로컬라이제이션 모듈 302 : 보행 가능 영역 검출 모듈 303 : 방향 계산 모듈 304 : 사운드 방향 로컬라이제이션 모듈 305 : 사운드 분류 모듈 306 : 물체 2D 특성 추출 모듈 307 : 물체 3D 특성 융합 모듈 308 : 물체 사운드 특성 융합 모듈 309-1 : 상대-절대 변환 모듈 309-2 : 물체 온도 특성 융합 모듈 31 : 라이브 맵 하위 유닛 310 : 라이브 맵 32 : 관계 매니저 하위 유닛 33 : 네비게이션 매니저 하위 유닛 34 : 사용자 명령 인터페이스 매니저 하위 유닛 35 : 피드백 매니저 하위 유닛 36 : 사운드 표현 하위 유닛 4 : 피드백 유닛 41 : 햅틱 피드백 액추에이터 411 : 좌측 피드백 액추에이터 412 : 우측 피드백 액추에이터 413 : 중앙 피드백 액추에이터 42 : 오디오 피드백 액추에이터 421 : 좌측 오디오 피드백 액추에이터 422 : 우측 오디오 피드백 액추에이터 5 : 사용자 명령 인터페이스 51 : 사용자 명령 햅틱 수단 52 : 사용자 명령 오디오 수단 6 : 전력 저장 유닛 - 그래픽으로 표시되지 않음 M : 메모리 - 그래픽으로 표시되지 않음 7 : 통신 유닛 - 그래픽으로 표시되지 않음 라이브 맵의 콘텐츠 감각 융합 하위 유닛으로부터 수신된 융합 데이터에 기초한 라이브 맵 결정 - 감각 유닛의 위치 및 방향 - On : 복수의 물체 - Ln : 복수의 생명체 - 그래픽으로 나타내지 않음 관계 매니저 하위 유닛으로부터 수신된 데이터에 기초한 라이브 맵 결정 - 복수의 물체(On) 및/또는 복수의 생명체(Ln) 사이의 복수의 관계(Rn) = 관계 - 그래픽으로 나타내지 않음 A : 자유 영역 - WA : 보행 가능 영역 - CWA : 조건부 보행 가능 영역 - NA : 도보 불가 영역 최소 요건 - 영역에 있어서 - 영구적으로 사전 결정된 보행 가능 영역 요건 세트 - 하나 이상의 예측 가능한 조건부 보행 가능 영역 요건 - 관계에 있어서 - 이하를 포함하는 사전 결정된 관계 요건의 카테고리 - 사전 결정된 부모 자식 관계와 - 사전 결정된 조건부 관계 - 네비게이션 경로(Pn)의 경우 - 2개의 네비게이션 경로 요건 - 안전 요건 - 비충돌 요건 - 비공격성 요건 - WA 또는 CWA에 있음 선택 기준 - 경로 선택 기준 세트 - 비용 기준 - 목적지까지의 비용-시간 기준 - 편안함 기준 - 사전 결정된 선호 네비게이션 경로 복잡성 기준 공간 사운드에 대한 기준 - 사전 결정된 공간 사운드 기준 시각 장애 사용자에 의한 요청 및 선택 - 시작 요청 - 선택 요청 - 정보 요청 네비게이션 매니저 하위 유닛에 의해 결정된 경로 - Pn : 적어도 하나 네비게이션 경로 - 그래픽으로 표현하지 않음 - SP : 선호 네비게이션 경로 - WP : 방황 경로 - 그래픽으로 표시되지 않음 - PI : 관심 포인트 - PI-OLD : 오래된 관심 포인트 - PPI : 잠재적 관심 포인트 - 그래픽으로 표현되지 않음 해당 네비게이션 안내 지시를 송신하기 위한 안내 모드 T : 보행 가능 터널 93 : 이정표 93 r : 감각 유닛의 위치가 원점이 되는 원의 사전 결정된 길이를 갖는 반지름 94 : 선호 네비게이션 경로(SP)와 반경(d1)을 갖는 원의 교차점 S : 공간화된 음원 d1 : 감각 유닛에 대한 공간화된 음원(S)의 사전 결정된 제1 거리 d2 : 사전 결정된 제2 거리 예 1 도 14 내지 도 17 84 : 초기 관심 포인트 = 관심 포인트(PI)로서 선택된 복수의 물체(On) 중 특정의 예시적인 복수의 물체(On)로 서의 입구 문 84-01 및 84-02 : 관심 포인트로서 선택되는 복수의 물체 중에서 예시적인 물체(On)로서 그래픽으로 표현되 지 않은 2개의 입구 문 841 : 추가 관심 포인트 = 관심 포인트(PI)의 다른 특정 예로서의 초인종 841 83 : 복수의 생명체(Ln) 중 특정 예시적인 생명체(Ln)로서의 개 831 : 신호등 832 : 횡단보도 942 : 보행 가능 영역(WA)의 특정 예로서의 보행 가능 영역 941 : 보행 불가 구역(NA)의 특정 예로서의 보행 불가 영역 943 : 조건부 보행 가능 영역(CWA)의 특정 예로서의 조건부 보행 가능 영역 911 : 선호 네비게이션 경로(SP)의 특정 예로서의 초기 네비게이션 경로 912 : 선호 네비게이션 경로(SP)의 다른 특정 예로서의 보조 네비게이션 경로 922 : 보행 가능 터널(T)의 특정 예로서의 보행 가능 터널 예 2 그룹 - 도 18 내지 도 28 85 : 잠재적인 관심 포인트(PPI) 지점인 복수의 물체(On) 중 특정 예로서 그리고 물체(On)의 특정 예로서 및 물 체(On)의 카테고리의 예로서의 창 85-1 : 제1 창 85-2 : 제2 창 85-3 : 제3 창 - 그래픽으로 표시되지 않음 85-4 : 제4 창 - 그래픽으로 표시되지 않음 85-E1 및 85-E2 : 임의의 창의 선택된 말단 S86 : 창의 해당 공간 사운드 S86-1 : 제1 창(85-1)에 대응 - 그래픽으로 표현되지 않음 S86-2 : 제2 창(85-2)에 대응 - 그래픽으로 표현되지 않음 S86-3 : 제3 창(85-3)에 대응 - 그래픽으로 표현되지 않음 S86-4 : 제4 창(85-4)에 대응 - 그래픽으로 표현되지 않음 공간 사운드의 특정 예 S86f : 특정 주파수를 갖는 공간 사운드 - 그래픽으로 표시되지 않음 S86f-1 창(85-1)에 대응하는 특정 주파수를 갖는 공간 사운드 S86f-2 창(85-2)에 대응하는 특정 주파수를 갖는 공간 사운드 S86f1, S86f2 : 창의 윤곽선을 따라 가상으로 이동하는 서로 다른 주파수로 인코딩되는 공간화된 음원 S86p : 특정 펄스를 갖는 공간 사운드 - 그래픽으로 표현되지 않음 S86t : 특정 시간 특성을 갖는 공간 사운드 - 그래픽으로 표시되지 않음 S86t-1, S86t-2 : 2개의 창(85-1, 85-2)의 프레임의 형태를 표현하기 위해 서로 다른 시간 특성을 갖는 공간 사 운드S86t11-1, S86t12-1 : 창(85-1)의 외부 프레임 형상을 표현하기 위해 창(85-1)의 윤곽선을 가상으로 이동하는 시간 특성이 서로 다른 공간 사운드 S86t21-1, S86t22-1 : 창(85-1)의 내부 프레임의 형상을 표현하기 위해 창(85-1)의 윤곽선을 따라 가상으로 이 동하는 시간 특성이 서로 다른 공간 사운드 S86P : 점형 사운드 S86P1 및 S86P2 : 창의 윤곽을 따라 가상으로 이동하는 공간화된 점형 사운드 S86P-E1 및 S86P-E2 : 창(85-E1 및 85-E2)의 말단에 대응하는 2개의 공간화된 점형 사운드 S86L : 선형 사운드 S861, S862 : 창의 내부 프레임의 윤곽과 외부 윤곽 사이의 공간 내에서 각진 패턴으로 가상으로 이동하는 공간 사운드 t0 : 창의 윤곽을 따라 가상으로 이동하는 공간화된 음원의 시간적인 시작 포인트 및 tfinal : 종료 포인트 자세한 설명 및 구현 예 도 1을 참조하면, 웨어러블 장치는 감각 유닛, 처리 및 제어 유닛, 피드백 유닛, 사용자 명령 인터 페이스를 포함한다. 웨어러블 장치는 그래픽으로 표현되지 않은 2개의 하드웨어 유닛, 즉 전력 저장 유닛 및 메모리(M)를 포 함한다. 본 발명 전체에 걸쳐, 시각 장애 사용자가 웨어러블 장치를 착용하고 있고 웨어러블 장치의 스위치가 켜 져 있음을 이해해야 한다. 따라서, 웨어러블 장치 또는 감각 유닛에 대한 설명, 청구범위 및 도면에서의 모든 참조는 시각 장애 사용자의 위치에 대한 참조를 포함하는 것으로 이해되어야 한다. 단순화를 위해, 본 발 명 전체에 걸쳐 시각 장애 사용자는 모든 성별 상황을 포함하는 \"그\"로 지칭될 것이다. 하드웨어 유닛의 구성 및 위치에 대한 세부 사항은 웨어러블 장치의 구성과 관련된 설명 부분에서 제공될 것 이다. 방법의 더 나은 이해를 위해, 하드웨어 유닛의 기본 구성 요소는 방법의 공개와 함께 간략하게 설명된다. 감각 유닛은 시각 장애 사용자의 머리에 배치되며 다음의 기본 센서를 포함한다. - 카메라 - 깊이 센서 - 관성 측정 유닛 - 사운드 로컬라이제이션 센서 처리 및 제어 유닛은 이하를 포함한다. - 감각 융합 하위 유닛 - 라이브 맵 하위 유닛 - 관계 매니저 하위 유닛 - 네비게이션 매니저 하위 유닛 - 사용자 명령 인터페이스 매니저 하위 유닛 - 피드백 매니저 하위 유닛 - 사운드 표현 하위 유닛 감각 융합 하위 유닛은 이하를 포함한다: - 로컬라이제이션 모듈 - 보행 가능 영역 검출 모듈 - 방향 계산 모듈 - 사운드 방향 로컬라이제이션 모듈 - 사운드 분류 모듈 - 물체 2D 특성 추출 모듈 - 물체 3D 특성 융합 모듈 - 물체 사운드 특성 융합 모듈 도 2는 시각 장애 사용자의 이마에서의 감각 유닛의 바람직한 위치를 도시한다. 상세한 설명 및 도면 전반에 걸쳐, 사용자의 이마에서의 선호하는 위치가 예시되었다. 당업자는 본 발명이 감각 유닛을 이마에 배치하는 것으로 제한되지 않음을 이해할 것이다. 본 발명에 따른 방법은 4개의 단계를 포함한다. 4개의 단계는 먼저 연속적으로 간략하게 설명된다. 그런 다음 단계 2, 3, 4에 대해 자세히 설명될 것이다. S1 시각 장애 사용자의 머리에 착용한 웨어러블 기기의 감각 유닛은 시각 장애 사용자의 환경으로부터 데 이터를 획득한다. 이를 위해 감각 유닛은 감각 유닛의 위치를 원점으로 하는 시야로부터 감지한다. S2 감각 유닛에 의해 감지된 데이터는 감각 융합 하위 유닛에 전송된다. 감각 융합 하위 유닛은 필터링, 스무딩, 인공지능 기반 알고리즘을 포함한 데이터 처리 알고리즘에 의해 감 각 유닛으로부터 획득한 데이터를 융합하고, 그 융합한 데이터를 처리 및 제어 유닛의 라이브 맵 하위 유 닛에 전송한다. 또한, 라이브 맵 하위 유닛은 라이브 맵을 생성하고 반복적으로 업데이트하고 저장한다. 라이브 맵 은 다음의 3개의 데이터 카테고리를 포함한다. 1. 감각 융합 하위 유닛으로부터 수신된 융합 데이터를 기반으로 생성되는 라이브 맵 결정 2. 복수의 물체(On) 및/또는 복수의 생명체(Ln) 사이의 복수의 관계(Rn)에 기초하여 생성되는 라이브 맵 결정 3. 자유 영역(A)을 기반으로 한 라이브 맵 결정 라이브 맵은 메모리(M)에 저장된 데이터베이스이다. 본 발명 전반에 걸쳐, 라이브 맵에 데이터를 업 데이트하고 저장하는 것은 메모리(M)에 라이브 맵을 업데이트하고 저장하는 것을 포함할 것이다. 라이브 맵이 저장되는 방식은 본 발명의 범위를 벗어난다. 도 3은 감각 유닛의 위치를 원점으로 하는 시야를 개략적으로 도시하는 반면, 도 4는 실제 환경과 비교 하여 시야 및 라이브 맵의 내용을 개략적으로 도시한다. 본 발명의 실시예에서, 라이브 맵은 메모리(M)에 이미 존재한다. 이 경우에, 라이브 맵의 영역 범위 는 라이브 맵에 과거에 저장된 콘텐츠에 의해 결정된다. 도 4로부터 알 수 있는 바와 같이, 라이브 맵 은 더 이상 시야에 없지만, 과거에는 시야에 있었던 물체를 포함한다. 도 4의 라이브 맵은 과거의 관전 포인트인 오래된 관심 포인트(PI-OLD)를 포함한다. 1. 감각 융합 하위 유닛으로부터 수신된 융합 데이터에 기초한 라이브 맵 결정은 이하의 결정을 포함한다. - 감각 유닛의 위치 및 방향 - 복수의 물체(On). 각 물체(On)에 대해 결정은 이하를 참조한다. - 자신의 위치 - 물리적, 음향적, 화학적 특성 - 자신의 방향 - 사전 결정된 시간 단위로 미래 위치의 예측 - 복수의 생명체(Ln). 각 생명체(Ln)에 대해 결정은 이하를 참조한다. - 자신의 위치 - 생물학적 및 음향적 특성 - 방향, 현재 활동 및 기분 상태 - 사전 결정된 시간 단위로 미래 위치의 예측 2. 복수의 물체(On) 및/또는 복수의 생명체(Ln) 사이의 복수의 관계(Rn)에 기초한 라이브 맵 결정은 처리 및 제 어 유닛의 관계 매니저 하위 유닛으로부터 수신된다. 관계 관리자 하위 유닛은 라이브 맵의 업데이트에 대해 라이브 맵 하위 유닛에 질의함으로써 라이 브 맵으로부터 가장 최근 업데이트를 가져온다. 계산은 적어도 이하를 포함하는 사전 결정된 관계 요건을 기초로 한다. - 사전 결정된 부모 자식 관계, 및 - 사전 결정된 조건부 관계 단순화를 위해, 본 발명 전체에 걸쳐, - \"관계\"라는 용어는 복수의 관계(Rn)에 대한 등가 표현으로 사용되며, - 대안적으로 관계라고 불리는 복수의 관계(Rn)는 정적 관계와 동적 관계 모두를 지칭한다. 계산을 수행한 후, 관계 매니저 하위 유닛은 계산 결과로서 업데이트된 관계를 라이브 맵 하위 유닛에 전송하여 라이브 맵에 저장한다. 복수의 관계(Rn)의 생성에 관한 세부 사항은 아래의 S.2.2와 관련된 섹션에서 제공된다. 3. 자유 영역(A)을 기반으로 한 라이브 맵 결정 자유 영역(A)은 복수의 물체(On) 및 복수의 생명체(Ln)가 점유하지 않는 지면 상의 영역의 앙상블로 정의된다. 상기 자유 영역(A)는 3개의 카테고리로 구분된다. - 보행 가능 영역(WA)을 시각 장애 사용자가 다치지 않고 보행할 수 있는 영역으로 정의하는 영구적인 사전 결 정된 보행 가능 영역 요건 세트를 충족하는 보행 가능 영역(WA) - 상기 영구적인 사전 결정된 보행 가능 영역 요건 세트를 충족하고 적어도 하나의 예측 가능한 조건부 보행 가 능 영역 요건을 충족하는 조건부 보행 가능 영역(CWA) 및 - 영구적인 사전 결정된 보행 가능 영역 요건 세트도 적어도 하나의 예측 가능한 조건부 보행 가능 영역 요건도 충족하지 않는 비 보행 가능 영역(NA) S3에서, 자동으로 또는 시각 장애 사용자의 제1 요청에 응답하여, 처리 및 제어 유닛의 네비게이션 매니저 하위 유닛은 시각 장애 사용자가 감각 유닛의 현재 위치로부터 복수의 물체(On) 및/또는 복수의 생명체 (Ln) 중에서 선택된 관심 포인트(PI)까지 네비게이션하는 하나 이상의 네비게이션 경로(Pn)를 결정하고 반복적 으로 업데이트하고 메모리(M)에 저장한다. \"네비게이션\"이라는 용어는 본 발명에서 다음을 포함하는 것으로 이해되어야 한다. - 물체(On) 또는 생명체(Ln)를 향해 시각 장애 사용자가 걷는 것 - 시각 장애 사용자가 칫솔, 문손잡이 등과 같은 다양한 물체를 찾고 접근하기 위해 한 손 또는 두 손이나 팔다 리로 하는 일상적인 몸짓과 행동 네비게이션 경로(Pn)의 비제한적인 예는 다음을 포함한다. - 실외 보행을 위한 네비게이션 경로(Pn) - 실내 보행을 위한 네비게이션 경로(Pn) - 빗과 같은 작은 물체에서 평면과 같은 큰 물체에 이르기까지 다양한 목적을 위해 매우 다양한 물체에 도달하 기 위한 네비게이션 경로(Pn) 네비게이션 매니저 하위 유닛은 자동으로 또는 시각 장애 사용자의 제2 요청에 대한 응답으로 하나의 선호 네비게이션 경로(SP)를 반복적으로 선택한다. G하나의 네비게이션 경로(Pn)만이 결정되면, 선호 네비게이션 경 로(SP)는 네비게이션 경로(Pn)이다. 2개 이상의 네비게이션 경로(Pn)가 결정되면, 네비게이션 매니저 서브 유닛 은 그 중 하나를 선호 네비게이션 경로(SP)로서 반복해서 선택한다. 선호 네비게이션 경로(SP)는 관련 네비게이션 안내 지시와 함께 네비게이션 매니저 하위 유닛에 의해 처리 및 제어 유닛의 피드백 매니저 하위 유닛으로 반복적으로 전송된다. 하나 이상의 네비게이션 경로(Pn)를 결정하기 위해, 네비게이션 매니저 하위 유닛은 적어도 2개의 네비게이 션 경로 요건이 충족되는지를 체크하기 위해 라이브 맵에 질의한다. 제1 네비게이션 경로 요건은 따라서 선호 네비게이션 경로(SP)를 포함하는 모든 네비게이션 경로(Pn)가 보행 가 능 영역(WA) 및/또는 조건부 보행 가능 영역(CWA)을 통과해야 한다는 것이다. 제2 네비게이션 경로 요건은 사전 결정된 시간 단위로 적어도 하나의 네비게이션 경로(Pn) 부근에 위치하거나 위치할 것으로 예상되는 복수의 물체(On) 및/또는 복수의 생명체(Ln)에 대해 안전 요건 세트를 충족하는 것이다. 근접성은 예를 들어 웨어러블 장치의 위치로부터 0.3m로 사전 결정된다. 안전 요건 세트는 적어도 하나의 비충돌 요건과 적어도 하나의 비공격성 요건을 포함한다. 다른 안전 요건은 시 각 장애 사용자(예를 들어, 노인)의 요구 또는 시각 장애 사용자가 일반적으로 거주하는 환경의 특성(예를 들어, 인구 밀도가 높은 도시 지역) 또는 둘 모두로부터 발생하는 다양한 특정 요구에 대해 정의될 수 있다. 비충돌 요건은 복수의 물체(On) 및/또는 복수의 생명체(Ln)의 개별 경로가 적어도 하나의 네비게이션 경로(Pn) 와 충돌하지 않아야 함을 의미한다. 비공격성 요건은 복수의 생명체(Ln)의 기분이 시각 장애 사용자에 대한 공격적인 행동을 예상하지 않아야 함을 의미한다. 밀집 지역을 피하거나 사전 결정된 값보다 높은 경사가 있는 구역을 통과하지 않도록 하는 요건과 같은 제한되 지 않은 다른 네비게이션 경로 요건은 사용자에 의해 정의될 수 있다. 네비게이션 경로 요건은 사전 결정되어 메모리(M)에 저장된다. 네비게이션 경로 요건은 네비게이션 매니저 하위 유닛에 의해 적용된다. 시각 장애 사용자는 사용자 명령 인터페이스 매니저 하위 유닛을 통해 다른 사 전 결정된 네비게이션 경로 요건을 설정할 수 있다. 선택된 네비게이션 경로(SP)가 조건부 보행 가능 영역(CWA)을 통과할 때, 네비게이션 매니저 하위 유닛은 피드백 매니저 하위 유닛에 상기 적어도 하나의 예측 가능한 조건부 보행 가능 영역 요건과 관련된 네비게 이션 안내 지시를 전송한다. 적어도 하나의 네비게이션 경로(Pn)의 결정은 네비게이션 매니저 하위 유닛에 의해 자동으로 또는 시각 장 애 사용자로부터 시작 요청을 수신하여 시작된다. 네비게이션 매니저 하위 유닛이 2개 이상의 네비게이션 경로(Pn)를 결정하는 경우, 선호 네비게이션 경로 (SP)의 선택은 네비게이션 매니저 하위 유닛에 의해 자동으로 또는 상기 네비게이션 매니저 하위 유닛 에 의해 시각 장애 사용자로부터의 선택 요청을 수신함으로써 수행된다. 네비게이션 매니저 하위 유닛은 기본적으로 선호 네비게이션 경로(SP)의 선택이 네비게이션 매니저 하위 유 닛에 의해 자동으로 수행되거나 시각 장애 사용자로부터의 선택 요청에 따라 수행되도록 구성될 수 있다. 네비게이션 매니저 하위 유닛에 의해 자동으로 수행될 때, 선호 네비게이션 경로(SP)의 선택은 비용 기준, 목적지까지의 비용 시간 기준, 편안함 기준을 포함하는 사전 결정된 경로 선택 기준 세트를 적용하는 것에 기초 한다. 경로 선택 기준의 적용은 종래 기술에 따라 수행된다. 시각 장애 사용자에 의한 요청은 사용자 명령 인터페이스의 햅틱 수단 또는 오디오 수단을 사용하여 이루어진다. 이들 요청은 처리 및 제어 유닛의 사용자 명령 인터페이스 매니저 하위 유닛을 통해 네비게 이션 매니저 하위 유닛에 의해 수신된다. S4에서 피드백 매니저 하위 유닛은 네비게이션 매니저 하위 유닛으로부터 수신된 각각의 관련된 네비게 이션 안내 지시를 전송하기 위한 안내 모드를 사용하여 선호 네비게이션 경로(SP)를 따라 시각 장애 사용자를 안내한다. 안내 모드는 피드백 매니저 하위 유닛에 의해 처리 및 제어 유닛의 피드백 유닛에 전송된다. 각 네비 게이션 안내 지시는 햅틱 및/또는 오디오 큐를 포함한다. 안내 모드는 이하에 의해 이루어진다. - 시각 장애 사용자의 이마에 배치하도록 구성된 피드백 유닛의 햅틱 피드백 액추에이터를 사용하여 햅 틱 큐에 의해, 또는 - 시각 장애 사용자의 한쪽 또는 양쪽 귀에 인접하게 배치하도록 구성된 피드백 유닛의 청각 액추에이터(4 2)를 사용하여 오디오 큐에 의해, 또는 - 오디오 큐와 햅틱 큐를 결합하여 각각의 관련된 네비게이션 안내 지시에 대한 안내 모드는 시각 장애 사용자에 의해 사용자 명령 인터페이스 에 의해 선택되고 또한 사용자 명령 인터페이스 매니저 하위 유닛을 통해 피드백 매니저 하위 유닛에 의해 수신된 사용자 명령을 통해 선택된다. 도 5를 참조한 S2-에 대한 세부 사항 라이브 맵은 후술하는 바와 같이 제1 하위 단계부터 마지막 하위 단계까지 여러 레이어의 정보가 추가되기 때문에 다층 케이크와 비교될 수 있다. 각 레이어에서 라이브 맵은 더 높은 레벨의 세부 정보와 정확도를 얻는다. 생성은 계속되며 결과적으로 라이브 맵의 지속적인 업데이트 및 지속적인 저장이 이루어진다. 라이브 맵에서 다중 정보 레이어를 생성하는 이점은 데이터 이해 및 액세스의 사용 용이성과 관련된다. 각 각의 개별 레이어에는 시스템의 특정 다른 구성 요소와 관련된 특정 정보가 포함되어 있으므로 정보에 더 빠르 게 액세스할 수 있다. S 2.1. 라이브 맵 서브 유닛은 감각 융합 하위 유닛으로부터 수신된 융합 데이터에 기초하여 감각 유닛 의 위치 및 방향, 복수의 물체(On)의 위치와 방향 및 특성, 복수의 생명체(Ln)의 위치와 방향 및 특성을 반 복적으로 결정하여 라이브 맵을 생성하고 업데이트하고, 생성 및 업데이트된 라이브 맵을 감각 융합 서브 유닛의 로컬라이제이션 모듈에 반복 전송한다. S 2.2. 관계 매니저 하위 유닛은 사전 결정된 관계 요건 세트를 적용하는 것을 포함하여 라이브 맵으 로부터 획득된 데이터에 기초하여 복수의 물체(On) 및/또는 복수의 생명체(Ln) 사이의 복수의 관계(Rn)를 반복 적으로 생성 및 업데이트한다. 반복적으로 업데이트된 복수의 관계(Rn)는 라이브 맵에 반복적으로 전송되 어 복수의 관계(Rn)의 콘텐츠를 참조하는 레이어로 S 2.1에서 출력된 라이브 맵을 업데이트한다. S 2.3. 로컬라이제이션 모듈은 감각 유닛으로부터 수신된 데이터 및 라이브 맵의 데이터에 적용되 는 로컬라이제이션 알고리즘을 사용하여 라이브 맵의 복수의 물체(On) 및 복수의 생물(Ln) 각각에 대해 감 각 유닛의 위치 및 방향을 반복적으로 로컬라이징한다. 감각 유닛의 위치 및 방향의 로컬라이제이션은 감 각 융합 하위 유닛의 보행 가능 영역 검출 모듈에 반복적으로 전송되고, 따라서 복수의 물체(On) 및 복수의 생명체(Ln)에 대한 감각 유닛의 위치 및 방향의 로컬라이제이션 데이터를 참조하는 레이어로 S 2.2로 부터 출력된 라이브 맵 콘텐츠를 업데이트한다. S 2.4. 보행 가능 영역 검출 모듈은 이하에 기초하여 자유 영역(A)을 반복적으로 결정한다. i) 감각 유닛으로부터 수신된 데이터 ii) 로컬라이제이션 모듈로부터 수신된 데이터 iii) 영구적으로 사전 결정된 보행 가능 영역 요건 세트, 및 iv) 계산되어 보행 가능 영역 검출 모듈의 메모리(M)에 저장된 적어도 하나 예측 가능한 조건부 보행 가능 영역 요건 반복적으로 업데이트되는 자유 영역(A)의 구성 요소는 라이브 맵에 반복적으로 전송되어, 자유 영역(A)의 구성 요소를 참조하는 레이어로 S 2.3에서 출력되는 라이브 맵 콘텐츠를 업데이트한다.S.2.5. 업데이트된 라이브 맵은 메모리(M)에 반복적으로 저장된다. S.2.1. 융합 데이터에 기초한 라이브 맵 결정에 관한 세부 사항 방향 계산 모듈은 관성 측정 유닛에 의해 제공된 관성 이동 데이터에 기초하여 감각 유닛에 대한 복수의 물체(On) 및 복수의 생명체(Ln) 중 웨어러블 디바이스의 감각 유닛의 현재 위치 및 방향을 결정한 다. 이를 위해, 방향 계산 모듈은 카메라와 깊이 센서가 카메라와 관련하여 검출된 물체(On) 가 어디에 있는지를 보여주지만 지면과 관련하여 어떻게 방향을 잡는지는 보여주지 않기 때문에 물체의 3D 포지 셔닝을 위해 3축(피치, 롤, 요)에서의 시스템의 방향을 계산하는 방향 계산 알고리즘을 적용한다. 물체 2D 특성 추출 모듈은 카메라로부터 획득된 2D 이미지의 픽셀 단위 분할을 제공하고, 시야에 배치된 복수의 물체(On) 중 각각의 물체(On) 및 복수의 생명체(Ln) 중 각각의 생명체(Ln)을 픽셀 단위로 분할된 2D 이미지에서 검출하고, 2D 좌표에서의 그들 각각의 위치 및 그들 각각의 물리적 특성을 결정한다. 물체 2D 특성 추출 모듈은 이하의 몇 가지 동작을 결합하는 물체 2D 특성 추출 알고리즘을 사용한다. - 여러 후속 이미지 사이의 데이터를 비교하여 카메라에 대한 물체(On) 또는 생명체(Ln)의 유형, 2D 위치 및 상대적인 2D 크기 및 2D 중심, 2D 모션 벡터를 결정하는 물체 검출 - 2D 좌표에서의 물체의 방향을 결정하는 물체 포즈 검출 - 달리기, 앉기, 기침 등과 같은 생명체(Ln)의 활동과 잠자기, 깨어 있음 등과 같은 상태를 이해하는 데 사용되 는 골격 방향에 의해 생명체(Ln)의 자세를 결정하는 골격 포즈 검출 - 미소, 웃음, 울음 등과 같은 공감 상태와, 수면, 깨어 있음, 피곤함 등과 같은 활동 상태를 결정하는 얼굴 특 징 검출 - 이하와 같은 다양한 양태에 대한 알고리즘을 포함하는 물체 특성 결정 - 예를 들어 얼마나 많이 보이는지와 관습적인 이미지에 따라 어떻게 되어야 하는지를 비교함으로써 의자, 핸들 바, 냉장고 또는 방의 점유 정도 - 예를 들어 투명한 용기의 경우 용기의 2D 충전 정도 - 예를 들어, 카메라에 의해 포착된 물체(On)를 깨끗한 유사 물체(On)의 알려진 이미지와 비교하고 차이를 계산함으로써 제품의 더러운 정도 또한 물체 3D 특성 융합 모듈은 물체 2D 특성 추출 모듈, 방향 계산 모듈 및 깊이 센서로부 터 데이터를 수신하고, 복수의 물체(On) 및 복수의 생명체(Ln)에 관해 물체 2D 특성 추출 모듈로부터 수신 된 2D 정보에 대한 추가 세부 정보를 결정한다. 따라서 물체 3D 특성 융합 모듈은 3D 좌표에서의 감각 유닛에 대한 각 물체(On)의 위치, 크기, 구성, 구조, 색상, 형상, 습도, 온도, 점유도, 청결도, 사용도, 마모도, 안정성도, 충만도, 위험도와 같은 물리적 특 성, 감각 유닛에 대한 방향, 및 움직임의 벡터에 기초한 3D 좌표 기반의 사전 결정된 순간에서의 미래 위치 를 각각 결정한다. 또한 물체 3D 특성 융합 모듈은 3D 좌표에서의 각 생명체(Ln)의 위치, 키와 같은 물리 적 특성, 골격 자세 방향 및 사전 결정된 시간 단위에서의 미래 위치 예측에 관한 데이터를 각각 결정한다. 골 격 포즈 방향, 얼굴 표정 및 그들의 물리적 특성에 기초하여, 물체 3D 특성 융합 모듈은 각각의 생명체 (Ln)의 현재 활동 및 기분 상태를 결정한다. 사운드 방향 로컬라이제이션 모듈은 사운드 로컬라이제이션 센서로부터 수신된 데이터에 기초하여 복 수의 물체(On) 및 복수의 생명체(Ln) 각각에 의해 방사되는 3차원 좌표로 표현되는 복수의 사운드 스트림의 방 향을 결정한다. 방법의 일 실시예에서, 복수의 사운드 스트림의 방향은 마이크의 위치를 알면서 사운드 로컬라이제이션 센서 의 마이크 사이의 사운드 스트림의 차이를 비교함으로써 결정된다. 사운드 방향 로컬라이제이션 모듈 은 사운드 스트림이 나오는 방향을 감지하여 나오는 사운드 스트림의 소스를 삼각 측량한다. 사운드 방향 로컬라이제이션 모듈에 의해 방향이 결정된 복수의 사운드 스트림 각각은 사운드 분류 모듈 에 의해 사운드 유형으로 분류된다. 물체 사운드 특성 융합 모듈은 사운드 분류 모듈에서 결정된 분류된 사운드 유형에 기초하여 3차원 좌표가 결정된 복수의 물체(On) 및 생물(Ln) 각각에 음향 특성을 부가한다. 그런 다음, 물체 사운드 특성 융합 모듈은 모든 융합된 데이터를 라이브 맵에 저장하기 위해 라이브 맵 서브 유닛에 전송한다. S.2.2. 복수의 관계(Rn)의 생성에 관한 세부사항 관계 매니저 하위 유닛으로부터 수신된 데이터에 기초한 라이브 맵 결정은 시각 장애 사용자의 환경을 정의 하는 추가의 상세한 정보를 제공한다. 이러한 방식으로 관계 매니저 하위 유닛은 시각 장애 사용자의 보다 안전한 네비게이션 및 보다 구체적인 네비게이션 목표라는 본 발명의 목적을 충족하는 물체(On) 및 생명체(Ln) 에 대한 보다 정확하고 상세한 정보를 제공하며, 후자는 본 발명에서 관심 포인트(PI)로서 정의된다. 처리 및 제어 유닛에 의해 사용되는 알고리즘은 물체 검출, 물체 포즈 검출, 물체 특성 결정을 포함하지만 이에 국한되지는 않는다. 처리 및 제어 유닛에 의해 사용되는 알고리즘은 이하의 항목으로 정의된다. - 복수의 물체(On) 중 각각의 물체(On) - 복수의 생명체(Ln) 중 각각의 생명체(Ln) - 각 물체(On)의 각 구성 요소 부분, 예를 들어: 의자의 다리 - 각 생명체(Ln)의 각 부분 예를 들어, 물체(On)가 다리가 4개인 의자인 경우, 의자는 4개의 다리 각각과 별개의 항목으로 정의된다. 본 발명의 범위를 벗어나는 항목화의 정도는 사전 결정된다. 처리 및 제어 유닛는 그들의 물리적 관계에 기초하여 물체 클러스터를 생성한다. 따라서, 소정의 부모-자식 관계는 개별 아이템을 연결하여 물체(On), 생명체(Ln) 또는 둘 이상의 물체(On), 둘 이상의 생명체(Ln), 또는 물체(On)와 생명체(Ln) 사이의 앙상블을 형성할 수 있다. 예를 들어: 문 손잡이는 문 에 속한다. 문 손잡이와 문 모두는 아이템이다. 한편으로는 아이템 사이, 다른 한편으로는 물체(On)와 생명체 (Ln) 사이의 주요 차이점은 물체(On) 및 생명체(Ln)가 물체 및 생명체가 무엇인지에 대한 사람들의 일반적인 기 대에 부합하고, 알고리즘에 대해서는 모든 물체(On) 및 생명체(Ln)와 해당 구성 요소가 아이템으로 취급된다는 점이다. 사전 결정된 조건부 관계는 조건, 예를 들어 횡단보도는 신호등 색상에 따라 조건부 보행 가능 영역이다는 조건 이 충족되는 경우에만 개별 아이템을 연결하는 것을 의미한다. 관계 매니저 하위 유닛은 특정 알고리즘을 사용하여 가능한 관계를 계산하기 위해 라이브 맵으로부터 의 데이터를 사용한다. 부모-자식 관계의 경우, 알고리즘의 비제한적 예는 이하와 같다. - 물리적 근접성: 물체(On) 또는 생명체(Ln)에 대응하는 아이템이 물리적으로 근접한 경우, 부모-자식 관계를 형성한다. - 모자와 열린 수통이 가까이 있으면, 수통은 자식인 모자의 부모가 되고, - 키보드나 마우스가 컴퓨터와 가까이 있으면, 키보드나 마우스는 부모가 되는 컴퓨터를 향해 자식이 되고, - 개나 고양이와 같은 반려 동물이 생명체와 근접하여 검출되면, 반려 동물은 부모가 되는 인간의 자식이 되며, - 문 손잡이가 문에 가까우면, 문 손잡이는 문의 자식이 된다. 마찬가지로 차량의 문은 차량의 자식이다. - 수용과의 물리적 근접성: 물체(On) 또는 생명체(Ln)에 대응하는 아이템이 물리적으로 근접하고 하나의 물체 또는 생명체가 다른 물체에 수용되어 있으면, 다른 부모-자식 관계를 형성한다. - 물고기가 어항에 근접한 것으로 검출되고 어항에 담기면, 그 물고기는 부모가 되는 어항의 자식이 되고, - 투명한 용기에서 액체가 검출되면, 용기는 부모가 되고 액체는 자식이 되며, - 버스 근처에서 좌석이 검출되고 좌석이 버스 내부에 포함된 경우, 좌석은 버스의 자식이 된다. - 교차와의 물리적 근접성: 물체(On)가 물리적으로 근접하고 하나 이상의 평면이 교차하는 경우, 다른 부모-자 식 관계를 형성한다. - 문과 벽이 근접한 것으로 검출되고 그들의 평면이 일치하면, 문은 벽에 대해 자식이 된다. 검출된 관계에 기초한 새로운 아이템의 생성: - 교차와의 물리적 근접성: 물체(On)에 대응하는 아이템이 가까이 있으면, 아이템은 교차하여 새로운 아이템 유 형을 생성하고 해당 아이템의 자식으로서 할당된다. - 바닥, 지붕 및 다수의 벽이 근접 및 교차하는 아이템으로 검출되면, 이들은 다른 아이템인 방을 형성하고, 방 의 자식이 되고, - 다수의 방이 생성되면, 근접 및 교차하여 층을 만들고 층에 대해 자식이 되며, - 하나 이상의 층이 생성되면, 건물을 생성하고 건물에 대해 자식이 된다. 조건부 관계의 경우 알고리즘의 비제한적 예는 이하와 같다. - 물리적 근접성: 물체(On)에 대응하는 아이템이 매우 근접한 경우, 조건부 관계를 형성한다. - 문 근처에서 초인종이 검출되면, 그들은 조건부 관계를 형성한다. 문에 들어가기 전에 초인종을 눌러야 한다. - 문 손잡이 근처에서 열쇠 구멍이 검출되면, 그들은 조건부 관계를 형성한다. 문 손잡이를 작동하기 전에, 문 을 잠금 해제해야 한다. - 오리엔테이션을 통한 물리적 근접성: 물체(On)에 대응하는 아이템이 가까이에 있고 특정 방식으로 방향 설정 된 경우, 다른 조건부 관계를 형성한다. - 횡단보도와 같은 조건부 보행 가능 영역(CA)이 검출되고 횡단보도를 향하는 보행자 신호등이 검출되면, 검출 된 신호등의 색상에 의해 조건부 보행 가능 영역(CA)이 조정된다. 물체(On) 또는 생명체(Ln)의 유형에 따라 특정 속성이 예를 들어, 이하의 경우에 부모에서 자식으로 전달될 수 있다. - 문 손잡이가 자동차의 자식인 문의 자식인 경우, 자동차가 움직일 때 문 손잡이나 문이 더 이상 웨어러블 장 치의 시야에 있지 않더라도, 그 사이에 자동차 위치가 변경된 경우에도 마찬가지로 그들의 위치가 업데 이트될 것이다. 복수의 관계(Rn)를 설정하기 위한 알고리즘에 사용되는 모든 파라미터는 사전 결정되며, 예를 들어, 물리적 근 접성을 결정하기 위해 사전 결정된 범위의 거리가 사용된다. S.2.3. 감각 유닛의 위치 및 방향의 로컬라이제이션에 관한 세부 사항 로컬라이제이션 모듈은 감각 유닛의 카메라, 깊이 센서, 관성 측정 유닛으로부터 획득된 데이터에 적용되는 위치 파악 알고리즘에 의해 재 라이브 맵에서 3D 좌표로 웨어러블 장치의 감각 유닛 과 감각 유닛에 대한 복수의 물체(On) 및 생명체(Ln)의 현재 위치 및 방향을 반복적으로 결정한다. 위치 파악의 결과는 자유 영역(A)의 구성 요소를 결정하는 보행 가능 영역 검출 모듈에 전송된다. S.2.4. 자유 영역(A)의 구성 요소 결정에 관한 세부 사항. 영구적으로 사전 결정된 보행 가능 영역 요건 세트는 다양한 일반 안전 및 편의 요건을 고려하여 각각의 시각 장애 사용자에 대해 사전 결정된 카테고리를 포함한다. 이 세트는 적어도 이하의 2개의 카테고리를 포함한다. - 기하학적으로 사전 결정된 보행 가능 영역 요건은 시각 장애 사용자가 사실상 차지하는 공간의 기하학적 구조 를 나타낸다. 따라서, 가상 직육면체는 시각 장애 사용자의 치수에 맞게 조정된 3차원을 갖는 것으로 이미징된 다. 가상 직육면체는 시각 장애 사용자가 가만히 서 있거나 움직일 때 시각 장애 사용자를 부상으로부터 보호한 다. 이 카테고리의 요건에 대한 비제한적 예는 이하와 같다. 지면의 진동은 사전 결정된 높이를 초과해서는 안 되고, 지면에서 특정 거리에 배치된 빔은 거리가 사전 결정된 임계값 미만인 경우 등에는 위험한 것으로 간주된 다. - 표면 사전 결정된 보행 가능 영역 요건: 5cm와 같이 사전 결정된 너비를 초과하는 수막; 얼음; 진흙; 거리와 도로(이들로 한정되지 않음)와 같은 특정 지면 유형은 제외된다. 조건부 보행 가능 영역(CWA)은 영구적인 사전 결정된 보행 가능 영역 요건 세트를 충족하고 추가로 적어도 하나 의 예측 가능한 조건부 보행 가능 영역 요건을 충족해야 한다. 영구적인 보행 가능 영역 요건 세트 및 적어도 하나의 예측 가능한 조건부 보행 가능 영역 요건은 각각의 시각 장애 사용자에 대해 사전 결정되고 메모리(M)에 저장된다. 보행 가능 영역 결정 모듈은 한편으로는 카메라 및 깊이 센서로부터 수신하는 데이터에 다른 한편으로는 로컬라이제이션 모듈로부터 수신하는 데이터 에 상기 요건을 적용하고, 로컬라이제이션 모듈로부터 수신된 상기 데이터는 관계 매니저 하위 유닛으 로부터 수신되고 라이브 맵에 저장되는 관계의 업데이트를 포함한다. 다른 바람직한 실시예에서, 라이브 맵의 일부는 인터넷의 지리적 맵 사이트에서 다운로드할 수 있으며, 상 기 일부는 S 2.1 내지 S.2.4에 설명된 레이어를 참조하고 맵이 다운로드되는 지리적 맵 사이트에 따라 각 레이 어의 정보가 부분적이거나 완전할 수 있다는 점을 고려한다. 인터넷으로부터의 다운로드는 그래픽으로 표현되지 않은, 인터넷에 연결된 통신 유닛을 사용하여 수행된다. 이 경우, 로컬라이제이션 모듈은 다운로드된 라이브 맵에서 감각 유닛의 위치 및 방향을 로컬라이징한다. 라이브 맵 서브 유닛의 메모리에 미리 저장된 라이브 맵이 있는 경우, 미리 저장된 라이브 맵의 라이브 맵 결정에 기초하여 라이브 맵이 생성된다. 미리 저장된 라이브 맵이 웨어러블 장치의 메모리(M)에 존재하는 경우, 라이브 맵 서브 유닛에 의 해 이전에 결정되었기 때문에, 인터넷에서 다운로드되었기 때문에, 둘 다이기 때문에, 감각 유닛으로부터 수 신된 데이터에 기초한 결정은 로컬라이제이션 모듈에 의한 감각 유닛의 현재 위치 및 방향의 이전에 저 장된 라이브 맵 내의 식별 및 감각 유닛으로부터 수신된 데이터에 적용되는 로컬라이제이션 알고리즘에 의해 보행 가능 영역 검출 모듈에 의해 보행 가능 영역(WA) 및 조건부 보행 가능 영역(CWA)을 포함하는 자 유 영역(A)의 식별에 의해 단계 2.3으로 시작한다. 또한, 라이브 맵은 S 2.1 내지 S.2.2에 기술된 추가 정보로 반복적으로 업데이트되고 단계 2.3 및 단계 2.4 및 단계 2.5의 나머지 부분은 위에서 설명한 대로 수행된다. 바람직한 실시예에서, 라이브 맵은 동시 로컬라이제이션 및 매핑 SLAM 알고리즘을 사용하여 감각 융합 하 위 유닛에 의해 업데이트된다. SLAM 알고리즘은 새로운 위치 정보로 추정된 위치를 개선하기 위해 반복 프로세스를 사용하기 때문에 특히 유리 하다. 반복 프로세스가 높을수록 위치 정확도가 높아진다. 이것은 처리 장치의 병렬 처리 기능을 갖춘 계산 및 고 구성 하드웨어에 더 많은 시간이 걸린다. 다른 바람직한 실시예에서 사용되는 SLAM 알고리즘은 광대한 정보를 제공하는 이점을 갖는 시각적 SLAM 알고리 즘이며, 매우 작은 크기, 무게 및 전력 SWaP 풋프린트를 갖는 수동 센서 및 구성 요소를 사용할 수 있기 때문에 저렴하고 구현하기 쉽다. 본 발명은 지금까지 개시된 바와 같이 시작 요청을 보내기 전에 시각 장애 사용자에게 관심 포인트(PI)가 알려 진 경우를 말한다. 다른 경우에는, 시각 장애 사용자는 시작 요청을 보내기 전에 관심 포인트(PI)에 대한 충분한 정보를 가지고 있 지 않다. 전형적인 예는 그가 새로운 환경에 도착했을 때, 또는 일반적인 좌석 위치와 같이 알려진 환경에서 무 언가 변경된 경우이다. 한 가지 예는 시각 장애 사용자가 4개의 창이 있는 새 방에 들어가는 경우이다. 그는 창을 열고 싶어한다. 하지 만 4개의 창 중 관심 포인트(PI)로 선택할 창은 무엇일까? 또는 시각 장애 사용자가 예를 들어 30석의 점유된 좌석과 10개의 빈 좌석이 있는 회의실에 입장한다. 10개의 빈 좌석 중 관심 포인트(PI)로 선택할 수 있는 좌석 은 무엇일까? 시각 장애 사용자가 시작 요청을 전송하기 전에 관심 포인트(PI)를 선택하기 위해 자신의 환경으로부터 추가 정 보를 필요로 하는 이러한 경우를 포함하기 위해, 다른 바람직한 실시예에서, 관심 포인트(PI)가 시각 장애 사용 자에 의해 알려지지 않은 경우, 하위 단계 3-0은 단계 3의 다른 모든 하위 단계 전에 수행된다. S.3-0.1에서. 시각 장애 사용자는 처리 및 제어 유닛의 사운드 표현 하위 유닛에 복수의 물체(On)로부터 선택된 적어도 하나의 물체(On) 또는 복수의 생명체(Ln)로부터 선택된 적어도 하나의 생명체(Ln)에 관한 정보요청을 전송한다. 상기 적어도 하나의 물체(On) 또는 적어도 하나의 생명체(Ln)는 시각 장애 사용자를 위한 잠 재적 관심 포인트(PPI)이다. 복수의 물체(On) 중에서 선택된 적어도 하나의 물체(On)의 예는 선택된 방으로부터 의 창의 그룹이고, 이는 \"창\"이라고 명명될 수 있다. \"잠재적\"이라는 용어는 물체(On) 그룹 중 임의의 물체(On)가 초기 관심 포인트(PI)로서 선택될 수 있음을 의미 한다. 사운드 표현 하위 유닛은 이하의 유닛이다. - 라이브 맵 하위 유닛, 피드백 매니저 하위 유닛 및 사용자 명령 인터페이스 하위 유닛에 연결된 독립형 하위 유닛, 또는 - 네비게이션 매니저 하위 유닛의 하위 유닛(도 1에 간략화하기 위해 표시됨), 또는 - 피드백 매니저 하위 유닛의 모듈. 4개의 창이 있는 방을 예로 들면, 시각 장애 사용자는 그가 방에 얼마나 많은 창이 있는지, 방에서의 위치, 창 의 크기 또는 형상, 손잡이의 위치를 알아보고자 하는 \"창\"이라는 이름의 정보 요청을 사용자 명령 인터페이스 를 통해 사운드 표현 하위 유닛에 전송한다. 이 예에서 창은 잠재적 관심 포인트(PPI)이다. 정보 요청은 시각 장애 사용자가 정보 요청을 보내는 순간에 서 있는 장소 근처에 있는 사전 결정된 관심 영역, 이 경우 방 을 지칭한다. 정보 요청은 시작 요청 및 선택 요청과 마찬가지로 사용자 명령 인터페이스에 의해 사용자 명령 인터페이스 매니저 하위 유닛을 통해 사운드 표현 하위 유닛에 전송된다. S.3-0.2에서. 사운드 표현 하위 유닛은 선택된 적어도 하나의 특정 물체(On) 또는 적어도 하나의 특정 생명 체(Ln)에 관한 정보를 라이브 맵으로부터 추출하고 상기 적어도 하나의 특정 물체(On) 또는 적어도 하나의 특정 생명체(Ln)를 대응하는 공간 사운드로서 각각 표현하고, 사운드 표현 하위 유닛이 피드백 유닛의 일부 가 아닌 경우 피드백 매니저 하위 유닛을 통해 공간 사운드를 피드백 유닛에 전송한다. 공간 사운드의 표현은 사전 결정된 공간 사운드 기준에 기초하여 선택된 물체(On) 또는 선택된 생명체(Ln)의 분 류된 사운드 유형을 인코딩함으로써 사운드 표현 하위 유닛에 의해 생성된다. 사전 결정된 공간 사운드 기준의 비제한적이고 포괄적이지 않은 예는 이하와 같다. - 상기 특정 카테고리의 물체(Ln) 중의 물체(Ln)의 특정 특징 또는 상기 특정 카테고리의 생명체(Ln) 중의 생명 체(Ln)의 특정 특징에 따른 사운드의 바이노럴 가상화(binaural virtualization), - 시각 장애 사용자에 대한 상기 물체(On) 및 생명체(Ln)의 거리에 따른 공간 사운드의 주파수, 진폭, 주기, 주 파수 성분, 필 팩터, 지속 시간 및 반복의 변화. 사전 결정된 공간 사운드 기준에 기초한 선택된 물체 또는 선택된 생명체(Ln)의 분류된 사운드 유형의 인코딩 유형은 사운드의 다양한 기술적 특징을 구별하는 사용자의 능력을 결정하는 테스트 절차에 기초하여 선택된다. 시각 장애 사용자는 인간의 자연스러운 능력을 사용하여 각각의 공간 사운드의 위치를 로컬라이징하여 음원에서 나와서 웨어러블 장치로 적절한 트레이닝을 받은 사운드를 처리할 수 있다. 공간 사운드의 로컬라이제이션은 3개의 공간 차원에서 수행된다. - 수평: 시각 장애 사용자의 이마의 방위각에 본질적으로 대응하는 웨어러블 장치의 방위, - 수직: 지면으로부터 시각 장애 사용자의 이마의 고도에 본질적으로 대응하는 웨어러블 장치까지 측정된 고 도, - 감각 유닛의 서 있는 포인트에서 측정한 거리 범위 또는 근거리 차원. S.3-0.3에서, 시각 장애 사용자는 상기 특정 복수의 물체(On)로부터 또는 상기 복수의 생명체(Ln)로부터 각각 관심 포인트(PI)를 선택하고 대응하는 선택을 네비게이션 매니저 하위 유닛에 전송한다. 예 2 그룹은 사운드 표현의 문제를 자세히 설명한다. 일부 상황에서, 예를 들어 시각 장애 사용자가 새로운 목적지에 도착할 때 관심 포인트(PI)는 라이브 맵에 없다.이 경우, 라이브 맵 유닛은 네비게이션 매니저 하위 유닛 및 사용자 명령 인터페이스 매니저 하위 유닛 에 관심 포인트(PI)가 라이브 맵에 없다는 확인을 전송한다. 이 방법은 적어도 하나의 네비게이션 경 로(Pn)를 결정, 반복 업데이트 및 저장하기 전에 S3에서 추가 하위 단계를 가진다. S 3-1 네비게이션 매니저 하위 유닛은 그래픽으로 표현되지 않은 방황 경로(WP)를 결정하는 반면, 방법의 S1 및 S2는 관심 포인트(PI)가 발견되고 라이브 맵에 저장될 때까지 반복되며, 상기 방황 경로(WP)는 적어 도 2개의 네비게이션 경로 요건을 충족한다. 네비게이션 매니저 하위 유닛이 물체(On)의 특정 카테고리 또는 상기 생명체(Ln)의 특정 카테고리를 대응하 는 공간 사운드로서 나타내는 동안 방황 경로(WP)를 결정하는 것이 가능하다. 관심 포인트(PI)의 선택에 대한 결정이 내려지면, 방법의 단계 3 및 단계 4의 나머지가 개시된 바와 같이 수행된다. S4에 대한 세부 사항 모든 안내 모드는 네비게이션할 때 시각 장애 사용자를 선호 네비게이션 경로(SP)에 유지하는 목적을 가지고 있 다. 각각의 선호 네비게이션 경로(SP)는 실생활에서 발생하는 다양한 네비게이션 상황에 대응하는 고유한 복잡 도를 가지고 있다. 발명자들은 객관적인 기준과 주관적인 기준을 모두 포함하는 소정의 선호 네비게이션 경로 (SP) 복잡성 기준에 대응하는 스코어를 사용함으로써 선호 네비게이션 경로(SP)의 복잡도를 정량화할 것으로 생 각했으며, 주관적인 기준은 객관적인 기준에 대한 시각 장애 사용자의 자체 해석으로서, 예를 들어, 특정 시각 장애 사용자에게 먼 거리로 인식되는 것은 다른 시각 장애 사용자에게는 먼 것으로 인식되지 않는 것이며, 주변 환경의 소음이나 온도와 동일하다는 것이다. 이하는 사전 결정된 선호 네비게이션 경로 복잡성 기준의 일부 비제한적 및 비포괄적인 예이다. - 보행 가능 영역(WA) 및 조건부 보행 가능 영역(CWA)의 폭: 3m 폭의 보행 가능 영역(WA)와 10cm 폭의 보행 가 능 영역(WA)만 네비게이션하는 것이다르다. - 관심 포인트(PI)까지 남은 거리, - 회전 수 및 각각의 회전 정도 예: 30°, 75°, - 경사 및/또는 계단 수, - 오디오 큐의 사용을 제한할 수 있기 때문에 환경의 소음. 햅틱 큐는 사전 결정된 선호 네비게이션 경로 복잡성 기준에 따라 진동의 지속 시간, 주기성, 강도 또는 빈도수 가 다르다. 오디오 큐는 사전 결정된 선호 네비게이션 경로 복잡성 기준에 따라 빈도수, 지속 시간, 반복, 강도 또는 3D 공 간 가상화가 다르다. 햅틱 큐 및 오디오 큐 각각의 변형은 시각 장애 사용자의 안내를 사전 결정된 선호 네비게이션 경로(SP) 복잡도 기준에 의해 정량화된 각각의 선호 네비게이션 경로의 복잡도에 적응시키는 이점이 있다. 햅틱 큐와 오디오 큐의 특성의 변화와 햅틱 큐와 오디오 큐의 결합 가능성의 장점은 이하와 같다. - 정확성과 보안 측면에서 네비게이션 경로를 따라 시각 장애 사용자에게 더 나은 안내를 제공한다. - 사전 결정된 기본 네비게이션 경로 복잡성 기준에 따라 안내를 사용자 정의할 수 있는 가능성을 제공한다. - 시각 장애 사용자가 필요에 따라 지속적으로 신호를 조정하여 더 많은 결정을 내릴 수 있는 가능성을 제공하 는 보다 편안한 네비게이션을 제공한다. 햅틱 큐 햅틱 큐는 햅틱 피드백 액추에이터를 통해 수신된다. 시각 장애 사용자는 각각의 유형의 햅틱 큐를 특정 안 내 지시와 연관시키기 위해 웨어러블 장치를 사용하기 전에 트레이닝을 받는다. 도 6을 참조하면, 안내의 최소 3개 방향(전진, 좌회전, 우회전)을 보장하기 위해 모두 이마의 방위(동일한 수평 에 있음)에 배치된 최소 개수의 3개의 햅틱 피드백 액추에이터가 필요하다. - 좌측 이마 부분에 장착된 좌측 햅틱 피드백 액추에이터, - 우측 이마 부분에 장착된 우측 햅틱 피드백 액추에이터, - 이마 중앙에 장착된 중앙 햅틱 피드백 액추에이터. 상기 햅틱 피드백 액추에이터는 진동 액추에이터 및 초음파 햅틱 피드백 액추에이터와 같은 근거리 원격 햅 틱을 포함한다. 진동 액추에이터는 피드백 매니저로부터 수신된 전기 신호를 시각 장애 사용자의 이마에서 느껴지는 강제 진동으로 변환하는 복수의 공진 액추에이터를 포함하며, 상기 진동은 특정 안내 지시와 관련된다. 본 발명에 사용된 진동 액추에이터의 비제한적인 예는 선형 공진 액추에이터이다. 좌측 햅틱 피드백 액추에이터 , 우측 햅틱 피드백 액추에이터 및 중앙 햅틱 피드백 액추에이터 각각은 하나 이상의 선형 공진 액추에이터를 포함할 수 있다. 선형 공진 액추에이터를 사용하는 것은 3개 이상의 안내 방향이 예상되는 경우, 그들의 공지된 우수한 햅틱 성 능, 다른 진동 액추에이터와 비교하여 공진시 개선된 효율성, 전력 소비를 최적화하는 용량 및 예를 들어 매트 릭스의 형태로 구성할 수 있는 작은 크기로 인해 본 발명에 유리하다. 2개 유형의 햅틱 큐가 있다. - 시간적 햅틱 큐는 햅틱 피드백 액추에이터를 사용함으로써 동일하거나 동일하지 않은 시간 간격으로 수신 되는 큐이며, - 대안적으로 햅틱 패턴 큐라고 불리는 시공간 햅틱 큐는 공간 구성 요소, 즉 시각 장애 사용자가 방향을 재지 정해야 하는 방향(예를 들어, 아래에서 위로 또는 위에서 아래로, 또는 우측으로 또는 좌측으로 등)을 나타내는 패턴과 결합된 시간적 구성 요소를 갖는다. 방향의 촉각 느낌은 그들의 개선된 공진 효율이 햅틱 큐 진동의 지 속 시간, 주기성, 강도 또는 빈도수의 변화를 향상시키기 때문에 예를 들어 선형 공진 액추에이터를 사용하여 얻을 수 있다. 복수의 선형 공진 액추에이터는 사전 결정된 빠른 연속 진동을 출력하고, 하나의 선형 공진 액추 에이터는 시각 장애 사용자가 방향을 바꿔야 하는 방향으로 차례로 진동하여 시각 장애인 사용자가 방향을 바꿔 야 하는 방향으로 이마를 끌고 가는 촉각을 제공한다. 사전 결정된 선호 네비게이션 경로 복잡도 기준을 적용하 는 비제한적 예는 이하와 같이 주어진다. - 햅틱 큐는 이하와 정비례하여 더 강렬하고/하거나 더 빈번하고/하거나 더 높은 진동 빈도수를 갖는다. - 선호 네비게이션 경로(SP)로부터의 편차도, - 시각 장애 사용자가 90°회전과 30°회전 또는 10 계단 오르기와 2 계단 오르기를 구별하기 위해 필요한 움직 임의 양. - 햅틱 큐는 시각 장애 사용자가 많은 햅틱 큐를 수신하는 피로를 피하기 위해 관심 포인트(PI)로의 네비게이션 의 추정 시간이 사전 결정된 시간 임계값을 초과하는 경우 더 작은 지속 시간 및/또는 더 적은 강도 및/또는 더 적은 진동 속도를 갖는다. 햅틱 큐의 유형은 시각 장애 사용자의 요구에 따라 각각의 경우에 사전 결정된다. 햅틱 큐의 사전 결정의 예는 본 발명의 교시의 더 나은 이해를 위해 아래에 제시되며, 이를 제한하기 위한 것이 아니다. - 감각 유닛의 현재 위치에서 네비게이션을 시작하기 위한 제1 햅틱 큐, - 시각 장애 사용자가 선호 네비게이션 경로(SP)에서 좌측으로 벗어났음을 알리는 제2 햅틱 큐, - 시각 장애 사용자가 선호 네비게이션 경로(SP)에서 우측으로 벗어났음을 알리는 제3 햅틱 큐, - 전진하기 위한 제4 햅틱 큐, - 좌회전 또는 우회전을 위한 제5 햅틱 큐, - 올라가거나 내려가는 제6 햅틱 큐, - 네비게이션 매니저 하위 유닛이 적어도 하나의 네비게이션 경로 요건이 충족되지 않음을 검출하는 경우 또는 적어도 하나의 예측 가능한 조건부 보행 가능 영역 요건이 충족될 때까지 중지하라는 네비게이션 지시를 전송해야 하는 조건부 보행 가능 영역(CA)을 검출하는 경우, 네비게이션이 종료되지 않았을 때의 일시적인 중지 를 위한 제7 햅틱 큐, - 관심 포인트(PI)에 도달함에 따라 네비게이션의 종료를 알리는 제8 햅틱 큐. 시각 장애 사용자의 다른 네비게이션 상황이나 요건을 수용하기 위해 추가 햅틱 큐가 정의될 수 있다. 보다 정확한 안내를 보장하기 위해 또한 동시에 시각 장애 사용자에게 햅틱 큐로 인한 불필요한 과부하를 방지 하기 위해 예를 들어, 이하의 햅틱 큐 유형을 결합할 수 있다. - 시작/중지와 같은 간단한 네비게이션 지시의 경우, 위의 예에서의 제1, 제7, 제8 큐는 시간적 큐만 사용될 수 있고, 반면에, - 복잡한 네비게이션 안내의 경우, 시간적 햅틱 큐만 사용할 때보다 햅틱 패턴 큐에 진동 기준을 적용할 때 좌/ 우 회전 또는 위/아래 안내가 더 정확하기 때문에 시공간 큐가 사용될 수 있다. 사용된 피드백 액추에이터로부터의 하나 이상에 대한 각각의 유형의 햅틱 큐의 할당은 사전 결정된다. 오디오 큐 오디오 큐는 시각 장애 사용자의 귀에서 오디오 피드백 액추에이터를 통해 수신된 사람 인지 가능 사운드이 다. 오디오 피드백 액추에이터는 피드백 매니저 서브 유닛으로부터 수신된 전기 신호를 사운드로 변환하는 스피커, 헤드폰 또는 골전도 스피커이다. 오디오 피드백 액추에이터를 통해 수신된 연관된 네비게이션 안내 지시는 관련된 각 네비게이션 안내 지시에 특정 사운드를 할당하는 원리에 기초한다. 도 6을 참조하면, 이하의 최소 개수의 2개의 오디오 피드백 액추에이터가 사용된다. - 좌측 귀에 또는 그 주위에 장착된 좌측 오디오 피드백 액추에이터, - 우측 귀에 또는 그 주위에 장착된 우측 오디오 피드백 액추에이터. 좌측 오디오 피드백 액추에이터 및 우측 오디오 피드백 액추에이터 각각은 동일한 방위 상에 배치된 복수의 스피커, 헤드폰 또는 골전도 스피커를 포함할 수 있다. 오디오 큐의 유형은 시각 장애 사용자의 필요에 따라 각각의 경우에 대해 사전 결정된다. 오디오 큐의 사전 결 정의 예는 본 발명의 교시를 제한하기 위한 것이 아니라 더 잘 이해하기 위해 아래에 제공된다. - 감각 유닛의 현재 위치에서 네비게이션을 시작하기 위한 제1 오디오 큐, - 시각 장애 사용자가 선호 네비게이션 경로(SP)에서 좌측으로 이탈했음을 알리는 제2 오디오 큐, - 시각 장애 사용자가 선호 네비게이션 경로(SP)에서 우측으로 벗어났음을 알리는 제3 오디오 큐, - 전진하기 위한 제4 오디오 큐, - 좌회전 또는 우회전을 위한 제5 오디오 큐, - 올라가거나 내려가는 제6 오디오 큐, - 네비게이션이 종료되지 않았을 때 일시적인 중지를 위한 제7 오디오 큐, - 관심 포인트(PI)에 도달함에 따라 네비게이션의 종료를 시그널링하기 위한 제8 오디오 큐. 시각 장애 사용자의 네비게이션 상황이나 요건을 수용하기 위해 추가 유형의 오디오 큐가 정의될 수 있다. 오디오 피드백 액추에이터로부터의 하나 이상에 대한 각각의 유형의 오디오 큐의 할당은 사전 결정된다. 사운드의 기원을 고려하면 2가지 유형의 사운드가 있다. - 시작 및 중지와 같은 간단한 관련 네비게이션 안내 지시에 사용되는, 오디오 피드백 액추에이터에서 발생 하는 간단한 사운드, - 시작 및 중지를 제외한 모든 관련 네비게이션 안내 지시에 사용되는, 하나 이상의 공간 사운드 소스(S)에서 발생하는 공간 사운드. 도 8a 및 도 8b에 도시된 하나의 바람직한 실시예에서, 안내 모드는 선호 네비게이션 경로(SP)를 수평 종축으로 서 갖는, 사전 결정된 단면의 가상 터널로서 정의된 3차원 보행 가능 터널(T)을 포함한다. S4의 안내 모드는 시각 장애 사용자가 보행 가능 터널(T)의 가상 벽에 접근하고 있을 때 시각 장애 사용자에게 전송된 특정 햅틱 큐 를 포함한다. 3차원 보행 가능 터널(T)은 선호 네비게이션 경로(SP)와 동시에 네비게이션 매니저 하위 유닛에 의해 결정 되고, 그 다음에 햅틱 큐와 함께 피드백 매니저 하위 유닛에 전송된다. 보행 가능 터널(T)의 장점은 보행 가능 터널(T)의 가상 벽에 의해 정의된 좌우로의 자유도가 더 높아 시각 장애 사용자가 보다 편안하게 네비게이션할 수 있다는 점이다. 안내 큐는 시각 장애 사용자가 보행 가능 터널(T)의 가상 벽에 도달하여 보행 가능 터널(T)의 가상 벽에 정의된 공간 내로 돌아올 때 전송된다. 일부 실시예에서, 보행 가능 터널(T)의 가상 벽을 시그널링하는 안내 큐와는 별 도로, 시각 장애 사용자가 보행 가능 터널(T)의 가상 벽 내에서 안전하게 네비게이션하고 있음을 확인하기 위해 다른 안내 큐가 전송된다. 보행 가능 터널(T)의 단면은 선호 네비게이션 경로(SP)를 따르는 복수의 가능한 단면에 따라 그리고 시각 장애 사용자의 선호도에 따라 사전 결정된다. 예 1은 보행 가능 터널(T)을 사용하는 안내 모드를 자세히 설명한다. 다른 바람직한 실시예에서, 도 9를 참조하면, 선호 네비게이션 경로(SP)는 복수의 이정표에 의해 구분되는 사전 결정된 세그먼트로 나누어진다. 각각의 세그먼트의 한쪽 끝에는 현재 이정표가 있고 다른 끝에는 후속 이정표가 있다. \"다음\"과 \"후속\"이라는 단어는 같은 의미다. S4의 안내 모드는 시각 장애 사용자에게 현재 이정표에서 다음 이정표까지 관련된 네비게이션 안내 지 시를 제공하는 다음 이정표의 위치를 시그널링하는 햅틱 큐 및/또는 오디오 큐를 포함한다. 시각 장애 사용 자가 이미 후속 이정표를 통과한 경우, 상기 후속 이정표는 현재 이정표가 되는 식이다. 사전 결정된 세그먼트의 길이는 선호 네비게이션 경로(SP)의 복잡성과 길이에 따라 다르다. 2개의 연속적인 이정표 사이의 각각의 세그먼트의 길이는 사전 결정된 우선 네비게이션 경로 복잡도 기준에 반비례하며, 우선 네비게이션 경로(SP)가 복잡할수록 각각의 세그먼트는 더 짧아진다. 이정표는 직진하는 부분보다 수평면 또는 수직면의 방향 전환을 포함하는 부분에서 더 빈번하다. 2개의 연속적인 이정표 사이의 각각의 세그먼트의 길이는 도 9에 도시된 바와 같이 선호 네비게이션 경로 (SP)를 따르는 세그먼트의 길이가 반드시 동일할 필요는 없다는 것을 의미하는 사전 결정된 선호 네비게이션 경 로(SP) 복잡도 기준을 적용함으로써 결정된다. 각각의 세그먼트의 길이는 사전 결정된 선호 네비게이션 경로 복잡성 기준에 대응하는 스코어를 사용하여 계산 될 수 있거나 인공 지능 기반 러닝 방법을 사용하기 위해 동적으로 적응될 수 있다. 예를 들어, 시각 장애 사용 자가 반복적인 일부 선호 네비게이션 경로(SP)를 가지고 있고 그가 이정표를 즐겨찾기로 사용하여 안내 방법을 선택하는 경우, 상기 학습 방법을 사용하여 이정표의 길이를 동적으로 적응시키는 것이 편리하다. 현재 이정표에서 다음 이정표까지 안내 모드에서 사용되는 큐는 이하와 같다. - 햅틱 큐, - 오디오 큐 또는 - 햅틱 및 오디오 큐. 햅틱 큐를 사용하는 비제한적 예는 이하와 같다. - 제1, 제7, 제8 큐는 시간적이다. - 제2 및 제3 큐는 시각 장애 사용자가 선호 네비게이션 경로(SP)에서 떨어져 있는 경우의 시공간 시그널링이다. - 제4 큐는 전진할 때 다음 이정표를 알리는 시공간적 시그널링이다. - 제5 및 제6 큐는 시각 장애 사용자가 각각 수평 또는 수직 평면에서 자신의 이동 방향을 재설정해야 하는 장 소로서 정의된 다음 이정표를 나타내는 시공간 시그널링이다. 햅틱 패턴 큐의 진동의 지속 시간, 주기성, 강도 또는 빈도수의 변화는 사전 결정된 선호 네비게이션 경로 복잡 성 기준에 정비례하고 동시에 후속 이정표까지 남은 거리에 반비례하여 변화한다. 오디오 큐를 사용하는 비제한적 예는 이하와 같다. - 제1, 제7, 제8 큐는 단순한 사운드이다. - 다른 모든 큐는 공간 사운드이다. 오디오 피드백 액추에이터는 시각 장애 사용자가 상기 후속 이정표(9 3)에 도달할 때까지 상기 후속 이정표의 위치로부터 들리는 공간 사운드를 사용하여 상기 후속 이정표 의 공간 내 위치를 반복적으로 출력한다. 각각의 이정표에 도달하면, 그 공간 사운드는 더 이상 들리지 않 고 현재 이정표가 되고 후속 이정표에 대응하는 공간 사운드가 들리기 시작하는 식이다. 공간 사운드는 사전 결정된 선호 네비게이션 경로 복잡성 기준에 따라 주파수, 지속 시간, 반복, 강도 및 3D 공 간 가상화에 정비례하고 동시에 후속 이정표까지 남은 거리에 반비례하여 변경된다. 관심 포인트(PI)와 일치하는 하나의 후속 이정표만 있는 상황에서 오디오 큐만을 사용하는 것이 유리하다. 예를 들어, 시각 장애 사용자가 소파에서 부엌까지 갈 필요가 있으면, 이 경우 부엌은 유일한 후속 이정표 이다. 공간화된 오디오 큐는 이 경우 부엌에 대응한다. 오디오 큐를 사용하는 것은 시각 장애 사용자가 다음 이 정표까지 네비게이션해야 할 남은 거리를 상기 후속 이정표의 위치에서 들리는 해당 오디오 큐와 연관 시킬 수 있는 가능성을 제공하기 때문에 단순성과 예측 가능성의 이점이 있으며, 이는 네비게이션할 때 방향의 정도과 안전감을 개선한다. 예를 들어 집 안의 네비게이션 경로의 경우 관심 포인트(PI)가 시각 장애 사용자에 게 알려져 있고 관심 포인트(PI)까지 이동할 거리가 짧을 때 오디오 큐만 사용하는 것이 유리하다. 현재 이정표에서 다음 이정표까지의 안내 모드가 햅틱 및 오디오 큐에 의한 것일 때, 상기 햅틱 큐와 오디오 큐 중 하나를 주된 큐로 정의하고 다른 하나를 보조 큐로 정의할 수 있으며, 보조는 예를 들어 중지 및 재개를 지시하는 제7 큐와 같이 특정의 사전 결정된 상황에서만 큐를 출력한다. 다른 바람직한 실시예에서, 도 10을 참조하면, 보행 가능 터널(T)을 사용하는 안내 모드의 햅틱 큐를 현재 이정 표로부터 다음 이정표까지의 안내 모드의 오디오 큐와 결합하는 것이 가능하다. 햅틱 큐에 의해 전송된 관련 네비게이션 안내 지시는 시각 장애 사용자가 선호 네비게이션 경로(SP) 및 보행 가능 터널(T)의 한계 내에 서 유지하는 것을 목표로 하는 반면, 오디오 큐는 시각 장애 사용자가 다음 이정표까지 네비게이션하고 남 은 거리를 추정할 수 있게 한다. 2개의 안내 모드를 결합하면 각각의 안내 모드의 장점, 즉 현재 이정표에서 다음 이정표까지 안내 모드 의 단순성과 예측 가능성과 터널 보행의 편안함과 안전성을 결합하는 이점이 있다. 다른 바람직한 실시예에서, S4의 안내 모드는 선호 네비게이션 경로(SP)의 방향을 시그널링하는 햅틱 큐 또는 오디오 큐 또는 햅틱 및 오디오 큐로 구성된다. 햅틱 큐를 사용하는 비제한적 예는 이하와 같다. - 제1, 제7, 제8 큐는 시간적이다. - 제2 및 제3 큐는 시각 장애 사용자가 선호 네비게이션 경로(SP)에서 떨어져 있는 경우 시공간 큐이고, - 제4 큐는 앞으로 나아가는 방향을 시그널링하는 시공간적이고, - 제5 및 제6 큐는 시각 장애 사용자가 수평 또는 수직 평면에서 자신의 이동 방향을 재설정해야 하는 방향을 나타내는 시공간적 큐이다. 촉각 패턴 큐는 시각 장애 사용자가 앞에 서 있는 사람에 의해 움직이는 방향으로 그의 이마에 의해 계속해서 끌려가는 인상을 주도록 사전 결정된다. 오디오 큐를 사용하는 비제한적 예는 이하와 같다. - 제1, 제7, 제8 큐는 단순한 사운드이다. 다른 모든 큐는 공간 사운드이다. 공간 사운드는 사전 결정된 선호 네비게이션 경로 복잡도 기준에 따라 주파수, 지속 시간, 반복, 강도 또는 3D 공간 가상화에 정비례한다. 시각 장애 사용자는 네비게이션을 할 때 공간화된 음원(s)의 방향을 따라간다. 선호 네비게이션 경로(SP) 상의 방향 시그널링에 기초한 안내 모드와 현재 이정표에서 후속 이정표까지 의 안내 모드 사이의 주요 차이점은 햅틱 패턴 큐의 특징의 변형 및 공간 사운드 각각을 나타낸다. - 둘 모두의 안내 모드에서 햅틱 패턴 신호 및 공간 사운드 각각은 사전 결정된 선호 네비게이션 경로 복잡성 기준에 따라 정비례하여 변한다. - 현재 이정표에서 후속 이정표까지의 안내 모드의 경우, 후속 이정표까지의 거리에 따라 선호 네 비게이션 경로(SP) 상의 방향을 시그널링하는 것에 기초한 안내 모드에 존재하지 않는 후속 이정표까지의 거리와 관련된 추가 변형이 있다. 선호 네비게이션 경로(SP)의 복잡도가 현재 이정표에서 후속 이정표까지의 안내 모드 또는 도보 터널 (T)의 안내 모드를 사용하는 경우보다 낮은 상황에서 선호 네비게이션 경로(SP)의 방향을 시그널링하는 햅틱 큐 또는 오디오 큐를 사용하는 것이 유리하다. 이러한 하나의 예는 동일한 선호 네비게이션 경로(SP)가 자주 사용 되는 경우이다. 선호 네비게이션 경로(SP) 상의 방향을 시그널링하는 햅틱 큐 또는 오디오 큐를 사용하는 이점 은 시각 장애 사용자에게 피로를 덜 준다는 것이다. 선호 네비게이션 경로(SP) 상의 방향을 시그널링하는 햅틱 큐를 사용하는 하나의 비제한적인 예가 도 11a에 주 어진다. 이 예에서 먼저 선호 네비게이션 경로(SP)를 감각 유닛의 위치를 원점으로 하고 사전 결정된 길이를 갖는 반지름(r)을 갖는 원과 교차하여 교차점을 획득함으로써 선호 네비게이션 경로(SP) 상의 방향을 시그 널링하는 방법을 먼저 결정한다. 감각 유닛의 원점과 교차점을 연결하는 가상 라인은 시각 장애 사용자 가 따라야 할 방향을 제공하며, 상기 방향은 상기 햅틱 큐 또는 오디오 큐에 의해 그에게 전달된다. 소정의 반 지름(r)의 길이는 선호 네비게이션 경로(SP)의 복잡도에 따라 설정된다. 선호 네비게이션 경로(SP) 상의 방향을 시그널링하는 오디오 큐를 사용하는 다른 비제한적 예가 도 11b에 주어 진다. 이 예에서, 따라야 할 방향은 도 11a의 예에서와 같은 방식으로 설정된다. 공간화된 음원(S)은 감각 유닛에 대한 공간화된 음원(s)의 소정의 제1 거리(d1)에 위치한다. 안내 모드에서 유연성을 얻고 선호 네비게이션 경로(SP)의 복잡도에 상기 안내 모드를 적응시키기 위해, 감각 유닛에 대한 공간화된 음원(S)의 사전 결정된 제1 거리(d1)는 도 11b에 도시된 반지름(r)의 사전 결정된 길 이보다 작거나 그보다 크거나 같을 수 있다. 햅틱 큐를 오디오 큐와 결합하는 것이 가능하며, 이 결합은 그래픽으로 표현되지 않는다. 다른 바람직한 실시예에서, 도 12를 참조하면, 오디오 큐는 공간화 음원(S)이 사전 결정된 제2 거리(d2)의 끝에 도달할 때까지 감각 유닛의 위치로부터 다시 감각 유닛의 위치로 선호 네비게이션 경로(SP) 상의 사전 결 정된 제2 거리(d2)를 따라 가상으로 이동하는 공간화 음원(S)으로부터 발생하는 공간 사운드이다. 오디오 큐를 사용하는 비제한적 예는 이하와 같다. - 제1, 제7, 제8 큐는 단순한 사운드이다. - 다른 모든 신호는 공간 사운드이다. 오디오 피드백 액추에이터는 사전 결정된 선호 경로 복잡성 기준에 정비례하는 주파수, 지속 시간, 반복, 강도의 변화, 및 3차원 공간 가상화를 통해 공간화된 음원(S)을 반복적으로 출력한다. 사전 결정된 제2 거리(d2)는 선호 네비게이션 경로(SP)가 더 복잡할수록 사전 결정된 제2 거리(d2)가 더 작아지 는 사전 결정된 선호 네비게이션 경로(SP) 복잡도 기준에 반비례한다. 사전 결정된 제2 거리(d2)는 일반적으로 0.2m와 5m 사이에서 변한다. 선호 네비게이션 경로(SP)가 매우 복잡한 경우, 사전 결정된 제2 거리(d2)는 일반적으로 0.2와 1m 사이에서 변한다. 사전 결정된 제2 거리(d2)에 대한 값 의 예는 예시 목적으로만 제공되며 제한하는 것으로 간주되지 않아야 한다. 예: 소정의 제2 거리(d2)는 1.2m이다. 이는 공간화된 음원(s)이 감각 유닛의 위치에서 가상으로 0.2m를 이동 하고 있음을 의미한다. 공간 사운드는 감각 유닛의 위치에서 네비게이션 방향으로 1.2m에 도달할 때까지 앞 뒤로 이동한 다음 다시 감각 유닛의 위치로 돌아온다. 사운드의 속도가 사람의 보행 속도보다 상당히 빠르기 때문에, 시각 장애 사용자는 공간 사운드의 가상 이동을 이용하는 안내 모드에서 사운드는 시각 장애 사용자와 는 독립적으로 이동하기 때문에 본 발명에서 개시한 그 어떤 안내 모드보다 네비게이션 안내 지시를 더 자세하 게 받게 된다. 사운드의 특징, 즉 주파수, 지속 시간, 반복, 강도 및 3D 공간 가상화 또는 이들의 조합 사이의 임의의 특징은 사전 결정된 제2 거리(d2)까지 남은 거리에 반비례하여 변한다. 예를 들어, 공간화된 음원(S)이 0.2m에 있을 때 보다 공간화된 음원(S)이 0.1m에 있을 때 오디오 큐가 더 빈번하고/하거나 더 강렬하고/하거나 더 3D 공간적으 로 가상화되거나 더 오래 지속된다. 이 안내 모드의 장점은 보행 가능 영역(WA)이 매우 좁은 환경에서 유리하게 되는 네비게이션의 미세 조정을 가 능하게 하고, 결과적으로 선호 네비게이션 경로(SP)가 물체(On)와 생명체(Ln) 사이에서 슬라롬처럼 보인다는 것 이다. 본 발명의 제2 양태에서, 웨어러블 장치는 감각 유닛, 처리 및 제어 유닛, 피드백 유닛, 사용자 명 령 인터페이스를 포함한다. 웨어러블 장치는 그래픽으로 표현되지 않은 2개의 하드웨어 유닛, 즉 전력 저장 유닛 및 메모리(M)를 포 함한다. \"메모리(M)\"이라는 용어는 단일의 구별되는 하드웨어 유닛에서 함께 그룹화되거나 다른 하드웨어 유닛 각각에 퍼져 있는 복수의 비휘발성 메모리를 지칭하는 것으로 이해되어야 한다. 메모리(M)는 적어도 라이브 맵, 모든 알고리즘, 모든 기준 및 요건 및 예를 들어 안내 지시를 수신하기 위 해 사용자가 선호하는 큐 유형(이에 제한되지 않음)과 같은 시각 장애 사용자의 선호도를 저장하도록 구성된다. 저장은 종래 기술에 따라 수행된다. 웨어러블 장치는 바람직한 실시예에서 단일 구성 요소 장치인 반면, 다른 바람직한 실시예에서는 다중 구성 요소 장치이다. 단일 구성 요소 장치의 경우, 모든 하드웨어 유닛은 도 2b에 도시된 웨어러블 장치에 포함된다. 웨어러블 디바이스는 그래픽으로 표현되지 않고 머리에 장착된다. 시각 장애 사용자의 머리에 하드웨어 유닛을 배치하 는 것은 예를 들어 모든 하드웨어 유닛에 대해 우수한 지지 및 앵커를 제공하는 이점을 갖는 헤드밴드의 형태일 수 있다. 다중 구성 요소 장치의 바람직한 실시예의 경우, 도 2a, 도 6 및 도 7을 참조하면, 구성 요소 중 하나는 감 각 유닛 및 피드백 유닛을 포함하는 헤드셋 구성 요소이다. 헤드셋 구성 요소는 예를 들어 도 2a 및 도 2b에 도시된 헤드밴드 형태일 수 있다. 다중 구성 요소 장치의 바람직한 실시예의 2개의 비제한적인 예는 이하의 2개의 구성 요소를 도시한다: - 헤드셋 구성 요소, 및 - 벨트 착용 구성 요소 또는 각각 손목 구성 요소. 손목 구성 요소는 그래픽으로 표현되지 않는다. 이 경우, 벨트 착용 구성 요소 또는 각각 손목 구성 요소는 처리 및 제어 유닛, 사용자 명령 인터페 이스 및 전력 저장 유닛을 포함한다. 메모리(M)는 2개의 구성 요소 중 하나로 구성되거나 분산될 수 있다. 도 2a는 헤드셋 구성 요소와 벨트 착용 구성 요소를 갖는 2-구성 요소 장치의 바람직한 실시예를 도 시한다. 헤드셋 구성 요소과 벨트 착용 구성 요소 또는 각각 손목 구성 요소 간의 구성 요소 구분은 주로 유닛의 크기와 무게에 기초한다. 단일 구성 요소 장치를 사용하는 이점은 머리 위의 바람직한 위치가 오디오 큐를 들을 수 있는 귀의 위치에 근접하게 되어 비시각 장애 사용자의 감각적 경험에 매우 근접한, 웨어러블 장치의 시각 장애 사용자를 위한 감각적 경험을 생성한다는 것이다. 그러나, 일부 경우에는 처리 및 제어 유닛 및/또는 전력 저장 유닛과같은 일부 하드웨어 장치가 무겁고 부피가 클 수 있다. 이러한 경우에, 다중 구성 요소 장치는 무겁고 부피가 큰 하드웨어 유닛을 벨트나 손목 (이것으로 제한되지 않음)과 같은 신체의 다른 위치에 배치하는 이점을 갖는다. 일반적으로 하드웨어 유닛의 소형화를 향해 기술이 발전함에 따라, 이것은 시각 장애 사용자의 머리에 너무 많 은 부담을 주지 않으면서 단일 구성 요소 장치를 사용할 가능성을 증가시킬 것이다. 그래픽으로 표현되지 않은 다른 바람직한 실시예에서, 이하의 3개의 구성 요소가 있다. - 감각 유닛, 피드백 유닛을 포함하는 헤드셋 구성 요소, - 벨트 착용 구성 요소, 또는 각각 손목 구성 요소는 처리 및 제어 유닛, 전력 저장 유닛을 포함 하고, - 사용자 명령 인터페이스를 포함하는 휴대용 구성 요소 - 그래픽으로 표현되지 않음. 메모리(M)는 헤드셋 구성 요소 또는 벨트 착용 구성 요소 또는 각각 손목 구성 요소 중 임의의 것 에 포함되거나 둘 사이에 퍼질 수 있다. 본 발명을 수행하기 위해 웨어러블 장치를 구성하는 다양한 유닛의 구성은 인체의 다양한 부위에 단일 또는 다중 구성 요소 장치의 상기 하드웨어 유닛을 배치하는 것에 의해 영향을 받지 않는다. 하드웨어 유닛은 유선 통신 프로토콜 또는 무선 통신 프로토콜 또는 유선 및 무선 프로토콜의 조합에 의해 그들 사이에서 통신하며, 상기 통신은 종래 기술에 따라 발생한다. 감각 유닛 감각 유닛은 시각 장애 사용자의 환경에 관한 데이터를 수집하도록 구성된 수단을 갖는다. 감각 유닛에 의해 수집된 데이터는 좋은 시력을 포함하여 좋은 감각 능력을 가진 인간에 의해 일반적으로 식 별되는 물체(On) 및 생명체(Ln)의 다중 특성을 지칭한다. 감각 유닛에 의해 수집된 데이터는 최신 기술보다 더 정확한 환경의 복잡성을 반영한다. 보다 정확한 데이터 수집이라는 목표를 달성하기 위해 감각 유닛에는 여러 유형의 센서 조합이 필요하며 이 에 대해 자세히 설명한다. 센서의 모든 예는 본 발명의 교시를 더 잘 이해하기 위한 것이며 본 발명을 제한하지 않는다는 것을 이해해야 한다. 감각 유닛은 4개의 기본 센서, 즉 카메라, 깊이 센서, 관성 측정 유닛 및 사운드 로컬라이제이 션 센서를 포함한다. 카메라, 깊이 센서 및 관성 측정 유닛의 최상의 위치는 웨어러블 장치가 단일 구성 요소인지 또 는 다중 구성 요소 장치인지에 관계없이 도 2a 및 도 2b에 도시된 바와 같이 이마에 있다. 감각 유닛을 이마 에 위치시키는 것이 선호되는 이유는 i) 인간은 시각 장애가 있든 없든 장치가 없을 때 사운드나 햅틱 큐와 같 은 큐를 받을 때 머리를 움직이는 데 익숙하기 때문이며, ii) 이마가 현재 다른 장치나 작업에 사용되지 않기 때문이며, iii) 카메라 및 깊이 센서에 대한 최상의 시야가 이마에 있기 때문이다. 시각 장애 사용자의 이마에 감각 유닛을 배치하는 구성은 시야가 이하를 포함하도록 보장해야 한다. - 시각 장애 사용자의 발, - 발에 바로 근접한 자유 영역(A)의 구성 요소, - 시각 장애 사용자의 즉각적인 스텝. 제1 센서는 카메라이다. \"카메라\"라는 용어는 본 발명 전체에 걸쳐 하나 또는 여러 개의 디지털 비디오 카메라를 가리킨다. 본 발명은 적어도 디지털 비디오 카메라를 가질 것을 요구한다. 카메라는 카메라 시야로부터 2D 이미지를 획득하고, 획득한 2D 이미지를 로컬라이제이션 모듈, 보행 가능 영역 검출 모듈 및 물체 2D 특성 추출 모듈에 전송하도록 구성된다. \"이미지\"라는 용어는 카메라의 이미지 획득 프레임 속도에 따라 비디오뿐만 아니라 정적 이미지를 포함한다. 카메라에 의해 획득된 이미지는 양태; 카테고리 -예: 나무 자동차; 색상, 형상, 치수 및 자유 영역(A)의 구 성 요소와 같은 복수의 물체(On) 및 복수의 생명체(Ln)의 시각적 특성을 참조한다. 카메라의 비제한적인 예는 최소 비디오 해상도가 1280픽셀×720픽셀인 HD 카메라, 최소 비디오 해상도가 320픽셀×240픽셀인 VGA 카메라를 포함한다. 카메라의 최소 요건은 이하와 같다. - 최소 50°에서 최대 180°사이의 수평 시야, 클수록 더 넓은 영역의 정보를 제공하므로 더 좋다. - 최소 60°에서 최대 180°사이의 수직 시야각, 클수록 더 넓은 영역의 정보를 제공하므로 더 좋다. 카메라는 RGB 카메라일 수도 있고 아닐 수도 있다. RGB 특징은 카메라 시야에서 보다 정확한 정보를 제공하 는 데 도움이 된다. 카메라가 복잡할수록 카메라가 획득한 2D 이미지에 더 많은 정보가 포함될 것이다. 제2 센서는 깊이 센서이다. \"깊이 센서\"라는 용어는 본 발명 전반에 걸쳐, 하나 또는 여러 깊이 센서. 본 발명은 적어도 하나의 깊이 센서를 가질 것을 요구한다. 깊이 센서는 연속적인 포인트 클라우드로서 깊이 센서 시야에 배치된 각각의 물체(On)와 각각의 생명체(L n)에 대한 3차원 거리 위치 및 치수에 대응하는 3D 포인트 클라우드 데이터를 획득하여, 로컬라이제이션 모듈 , 보행 가능 영역 검출 모듈, 및 물체 3D 특성 융합 모듈에 전송하도록 구성된다. 깊이 센서가 획득한 3D 포인트 클라우드 데이터는 물체(On)와 생명체(Ln)의 밀도, 부피 등의 3D 물리적 특 성을 의미한다. 깊이 센서의 비제한적 예는 입체 카메라, 레이더, Lidar, 초음파 센서, mmWave 레이더 센서이다. mmWave 레 이더 센서를 사용하면 생명체(Ln)가 움직이는 경우에도 생명체(Ln)의 맥박이나 호흡을 감지할 수 있어 시각 장 애 사용자에게 추가적인 정보를 제공할 수 있다는 장점이 있다. 단일 센서 카메라 및 깊이 센서(21-22)에 카메라와 깊이 센서를 결합하는 것이 가능하다. 이점은 2개의 센서의 작업을 수행하도록 구성된 하나의 센서만 사용하여 앞서 언급한 2개의 센서의 크기와 무게를 줄이는 것 이다. 카메라 및 깊이 센서(21-22)의 비제한적인 일례는 비행 시간(TOF) 카메라일 것이다. 제3 센서는 관성 측정 유닛이다. \"관성 측정 유닛\"이라는 용어는 본 발명 전체에 걸쳐 적어도 하나의 가속도계와 적어도 하나의 자이로스코프로 구성되고 개별 센서 또는 결합 센서로 구성된 앙상블을 나타낸다. 더 나은 정확도를 위해 별도의 센서로서 또는 적어도 가속도계 및/또는 적어도 자이로스코프와 결합하여 적어도 하 나의 자력계를 추가하는 것이 바람직하다. 앙상블의 크기와 무게를 줄여야 하기 때문에 결합 센서를 사용하는 것이 좋다. 본 발명은 적어도 하나의 관성 측정 유닛을 가질 것을 요구한다. 관성 측정 유닛은 감각 유닛의 방향을 결정하고 결정된 방향을 방향 계산 모듈을 통해 로컬라이제 이션 모듈과 특성 융합 모듈에 전송하도록 구성된다. 감각 유닛은 시각 장애 사용자의 이마에 위치하므로, 관성 측정 유닛에 의해 획득된 정보는 지면에 대한 시각 장애 사용자의 머리 방향을 암시적으로 의미한다. 제4 센서는 사운드 로컬라이제이션 센서이다. \"사운드 로컬라이제이션 센서\"라는 용어는 일반적으로 들어오는 음파의 방향 및 소스와 센서 사이의 거리에 의해 3차원 공간에서 다양한 사운드의 소스를 결정하는 데 사용되는 하나 또는 여러 센서의 앙상블을 본 발명 전반에 걸쳐 지칭한다. 사운드 로컬라이제이션 센서는 물체(On) 및 생명체(Ln)가 방출하는 3차원 공간 내의 복수의 사운드 스트림 을 획득하여 사운드 방향 로컬라이제이션 모듈에 전송하도록 구성된다. 사운드 로컬라이제이션 센서에 의해 획득된 정보는 상기 사운드의 방향성을 포함하여 물체(On)와 생명체 (Ln)가 발산하는 사운드를 지칭한다. 사운드 로컬라이제이션 센서에 의한 환경의 커버리지는 자신의 빔패턴에 의해 정의된다. 사운드 로컬라이제이션 센서의 비제한적 예는 마이크 어레이다. 사운드 로컬라이제이션 센서에 사용되는 마 이크 어레이의 최소 수는 빔 패턴의 합이 시야의 각도와 동일해야 한다. 사운드 로컬라이제이션 센서에 사용되는 최대 마이크 어레이 수는 360°를 포괄한다. 마이크 어레이는 빔 패턴의 합이 시야의 각도와 360 °사이에 포함되도록 헤드셋 내에 배치된다. 기본 센서는 카메라, 깊이 센서의 각각의 시야와 관성 측정 유닛의 측정 범위 및 사운드 로컬라이 제이션 센서의 빔 패턴의 상관 관계를 포함하여 특정 구성을 처리 및 제어 유닛의 감각 융합 하위 유닛 으로부터 수신한다. 상기 상관 관계는 결과적으로 도 3에 개략적으로 도시된 기본 센서의 시야를 갖는다. 기본 센서의 시야 의 개념은 모든 기본 센서가 정확히 동일한 범위를 갖는다는 것을 의미하지는 않는다. 수학의 공통 분모 개념과 마찬가지로 모든 기본 센서가 지각하는 영역으로 이해해야 한다. 일반적으로, 기본 센서의 시야는 전방을 향한다. 그러나, 사운드 로컬라이제이션 센서는 예를 들어 마이크 어레이의 수가 빔 패턴의 합이 360°와 같게 될 때 기본 센서의 시야보다 더 넓은 범위를 가질 수 있다. 이는 시각 장애 사용자의 등에서 나오는 사운드 정 보를 수집할 수 있다는 장점이 있다. 도 13에 도시된 다른 바람직한 실시예에서, 글로벌 포지셔닝 센서 및 온도 센서 중 하나 또는 둘 모두 의 추가 센서를 추가함으로써 시각 장애 사용자의 환경에 대한 더 많은 정보를 제공하는 것이 가능하다. 각각의 추가 센서와 기본 센서 그룹의 모든 조합은 처리 및 제어 유닛에 추가 정보를 제공하여 보다 정확하 고 상세한 라이브 맵을 제공하는 이점이 있다. 2개의 추가 센서 각각은 이하와 같이 감각 융합 하위 유닛에 대응하는 모듈을 갖는다. 글로벌 포지셔닝 센서는 감각 유닛의 절대 위치를 결정하고 그 결정을, 감각 유닛의 상대 위치를 절 대 위치로 변환하는 상대 대 절대-상대 변환 모듈(309-1)에 전송하고, 따라서 물체(On)의 위치 및 생명체(Ln)의 위치가 절대 위치로 표현되도록 구성된다. 글로벌 포지셔닝 센서의 최적의 위치는 다중 구성 요소 장치의 경우 웨어러블 장치의 헤드셋 구성 요소 의 최상부에 있고, 단일 구성 요소 장치의 경우에는 웨어러블 장치의 최상부에 각각 있다. 글로벌 포지셔닝 센서가 없는 경우, 감각 융합 하위 유닛은 각각의 물체(On) 및 각각의 생명체(Ln)에 대한 웨어러블 장치의 상대 위치를 결정한다. 온도 센서는 물체(On)와 생명체(Ln)의 온도를 결정하고, 결정된 온도를 물체 온도 특성 융합 모듈(309-2)에 전송하도록 구성된다. 추가 센서 중 어느 하나를 사용하는 경우, 물체 사운드 특성 융합 모듈에 의해 출력된 데이터는 절대-상대 변환 모듈(309-1) 또는 물체 온도 특성 융합 모듈(309-2)에 각각 전송되어, 각각의 센서에 의해 전송된 데이터 와 융합되거나 결과는 라이브 맵 하위 유닛에 전송된다. 2개의 추가 센서를 모두 사용하는 경우, 도 13에 도시된 바와 같이, 물체 사운드 특성 융합 모듈에 의해 출력된 데이터는 절대-상대 변환 모듈(309-1)에 전송되고, 글로벌 포지셔닝 센서로부터의 데이터와 융합되 고, 결과는 물체 온도 특성 융합 모듈(309-2)에 전송되고 온도 센서에 의해 전송된 데이터와 융합되고 결과 는 라이브 맵 하위 유닛에 전송된다. 처리 및 제어 유닛 처리 및 제어 유닛은 마이크로컨트롤러, 컴퓨터, 슈퍼컴퓨터(이에 제한되지 않음)와 같은 적어도 하나의 프 로세서 및 적어도 하나의 비휘발성 메모리를 포함하는 컴퓨팅 유닛이다. \"컴퓨팅 유닛\"이라는 용어는 컴퓨터 통 신 시스템 내에서 원격으로 배치되어 서로 통신하는 단일 컴퓨팅 유닛 또는 복수의 컴퓨팅 유닛을 포함한다. 처리 및 제어 유닛은 감각 융합 하위 유닛, 라이브 맵 하위 유닛, 관계 매니저 하위 유닛, 네비 게이션 매니저 하위 유닛, 사용자 명령 인터페이스 매니저 하위 유닛, 피드백 매니저 하위 유닛 및 사운드 표현 하위 유닛을 포함한다. 도 5를 참조하면, 감각 융합 하위 유닛은 감각 유닛의 4개의 기본 센서로부터 수신된 결정을 융합하고 상관시키도록 구성된 수단을 포함한다. 도 13을 참조하면, 감각 융합 하위 유닛은 감각 유닛의 4개의 기본 센서로부터 또한 추가 센서 중 하나 또는 둘 다로부터 수신된 결정을 융합하고 상관시키도록 구성된 수단을 포함한다. 로컬라이제이션 모듈은 감각 유닛의 카메라, 깊이 센서, 관성 측정 유닛로부터 획득한 데 이터에 적용되는 위치 파악 알고리즘을 통해 웨어러블 장치의 감각 유닛의 현재 위치 및 방향과 감각 유 닛에 대한 복수의 물체(Ln) 및 생명체(Ln)의 현재 위치 및 방향을 현재 라이브 맵 상의 3D 좌표로 로컬 라이징하도록 구성된 수단을 포함한다. 로컬라이제이션 모듈은 감각 유닛의 위치 및 방향의 로컬라이제이션을 보행 가능 영역 검출 모듈 에 전송하여, S2.2로부터 출력된 라이브 맵 콘텐츠를 복수의 물체(On) 및 복수의 생명체(Ln)에 대한 감각유닛의 위치 및 방향의 로컬라이제이션 정보를 참조하여 레이어로 업데이트하도록 구성된 수단을 더 포함한 다. 보행 가능 영역 검출 모듈은 카메라 및 깊이 센서로부터 획득된 데이터를 수신하도록 구성된 수단, 및 로컬라이제이션 모듈로부터 데이터를 수신하도록 구성된 수단, 및 2개의 데이터 소스에 기초하여 보행 가능 영역(WA) 및 조건부 보행 가능 영역(CWA)을 정의하고 이들을 메모리(M)에 저장된 영구적인 사전 결정 된 보행 가능 영역 요건 및 예측 가능한 조건부 보행 가능 영역 요건 세트를 적용하여 라이브 맵 하위 유닛(3 1)에 전송하도록 구성된 수단을 포함한다. 방향 계산 모듈은 관성 측정 유닛에 의해 제공된 관성 데이터에 기초하여 웨어러블 장치의 방향을 결정하고 그 결정을 물체 3D 특성 융합 모듈에 전송하도록 구성된 수단을 포함한다. 사운드 방향 로컬라이제이션 모듈은 사운드 로컬라이제이션 센서로부터 수신된 데이터에 기초하여 복 수의 물체(On) 및 복수의 생명체(Ln) 각각에 의해 방출되는 3D 좌표로 표현되는 복수의 사운드 스트림의 방향을 결정하도록 구성된 수단 및 결정된 방향을 사운드 분류 모듈에 전송하도록 구성된 수단을 포함한다. 사운드 분류 모듈은 사운드 방향 로컬라이제이션 모듈로부터 수신된 복수의 사운드 스트림을 사운드 유형으로 분류하고 분류된 사운드 유형을 물체 사운드 특성 융합 모듈에 전송하도록 구성된 수단을 포함한 다. 복수의 사운드 스트림을 사운드 유형으로 분류하도록 구성된 수단은 일반적으로 인공 지능 알고리즘을 사용 한다. 개체 2D 특성 추출 모듈은 카메라로부터 획득된 2D 이미지를 픽셀별로 분할하고, 픽셀별 분할된 2D 이 미지에서 시야에 배치된 복수의 물체(On) 중 각각의 물체(On) 및 복수의 생명체(Ln) 중 각각의 생명체(Ln) 를 검출하고, 2D 좌표에서의 각각의 위치 및 각각의 물리적 특성을 결정하고, 그 결정을 물체 3D 특성 융합 모 듈에 전송하도록 구성된 수단을 포함한다., 객체 3D 특성 융합 모듈은 물체 2D 특성 추출 모듈, 방향 계산 모듈 및 깊이 센서로부터 데 이터를 수신하고 이하를 결정하도록 구성된 수단을 포함한다. - 감각 유닛에 대한 각각의 물체(On)의 3D 좌표에서의 위치, 감각 유닛에 대한 그들의 방향, 및 움직임의 벡터 각각에 기초한 사전 결정된 순간에서의 미래 위치. - 치수, 구성, 구조, 색상, 형상, 습도, 온도, 점유도, 청결도, 사용도, 마모도, 안정도, 충만도, 위험도와 같 은 복수의 물체(On)의 물리적 특성. - 3D 좌표에서의 각 생명체(Ln)의 위치, 키와 같은 물리적 특성, 골격 자세 방향, 이동 벡터에 기초한 사전 결 정된 시간 단위의 미래 위치 예측, - 골격 자세 방향 및 물리적 특성에 기초한 각 생명체(Ln)의 현재 활동 및 기분 상태. 개체 사운드 특성 융합 모듈은 검출된 물체(On) 및 생명체(Ln)와 연관시킴으로써 사운드 분류 모듈에 의해 결정된 분류된 사운드 스트림 유형에 기초하여 3D 좌표가 결정한 음향 특성을 생명체(Ln) 및 복수의 물체 (On) 각각에 추가하고 모든 데이터를 라이브 맵 하위 유닛에 전송하도록 구성된 수단을 포함한다. 본 발명의 일 실시예에서, 감각 융합 하위 유닛은 상대-절대 변환 모듈(309-1)을 더 포함한다. 이 모듈은 감각 유닛의 상대 위치를 절대 위치로 변환하고 물체 사운드 특성 융합 모듈로부터의 데이터를 감각 유 닛의 절대 위치에 관한 데이터와 융합하고 결정을 직접 또는 물체 온도 특성 융합 모듈(309-2)을 사용하여 라이브 맵 하위 유닛에 전송하도록 구성된 수단을 포함한다. 본 발명의 다른 실시예에서, 감각 융합 하위 유닛은 물체 온도 특성 융합 모듈(309-2)을 더 포함한다. 이 모듈은 검출된 물체(On) 및 생명체(Ln)의 온도를 결정하고, 물체 사운드 특성 융합 모듈로부터의 데이터를 물체(On) 및 생명체(Ln)의 온도에 관한 데이터와 융합하고 융합된 데이터를 라이브 맵 하위 유닛에 전송하 도록 구성된 수단을 포함한다. 상대-절대 변환 모듈(309-1)이 사용되면, 해당 데이터를 물체 온도 특성 융합 모 듈(309-2)에 전송하고 최종적으로 그 데이터를 물체(On)와 생명체(Ln)의 온도에 관한 데이터와 융합한다. 본 발명에 따르면, 라이브 맵 하위 유닛은 라이브 맵을 생성, 반복 업데이트 및 저장하도록 구성된 수 단 및 자유 영역(A)의 구성 요소를 참조하는 데이터를 수신하고 S 2.2로부터 출력된 라이브 맵 콘텐츠를 보행 가능 영역 검출 모듈로부터 감각 유닛의 위치 및 방향의 로컬라이제이션 및 물체 사운드 특성 융 합 모듈로부터 음향 특성을 포함하는 3D 좌표의 복수의 물체(On) 및 생명체(Ln) 각각에 관한 데이터를 참조하는 레이어로 업데이트하고, 모든 라이브 맵 결정을 로컬라이제이션 모듈에 전송하도록 구성되는 수단 을 포함한다. 라이브 맵 하위 유닛은 이하를 수신하도록 구성된 수단을 포함한다. - 관계 매니저 하위 유닛에 의한 라이브 맵의 질의, - 관심 포인트(PI)가 라이브 맵에 이미 있는 경우 네비게이션 매니저 하위 유닛으로의 사용자 명령 인 터페이스 매니저 하위 유닛의 질의를 포함하는, 네비게이션 매니저 하위 유닛에 의한 라이브 맵의 질의, - 관계 매니저 하위 유닛에 의해 수행되는 업데이트된 관계(Rn), - 네비게이션 매니저 하위 유닛에 의해 수행되는 자유 영역(A)의 업데이트된 구성 요소, - 물체(On)에 관한 특정 정보에 관한 사운드 표현 모듈의 질의. 라이브 맵 하위 유닛은 이하를 전송하도록 구성된 수단을 포함한다. - 관계 매니저 하위 유닛에 의한 라이브 맵의 질의에 응답하여 복수의 관계(Rn), - 네비게이션 매니저 하위 유닛의 질의에 응답하여 자유 영역(A)의 구성 요소, - 질의에 응답하여 네비게이션 매니저 하위 유닛에 대한 모든 라이브 맵 결정. 관계 매니저 하위 유닛은 라이브 맵에 질의하고 질의 결과로서 라이브 맵으로부터 가장 최근에 업데이트된 데이터를 가져오도록 구성된 수단을 포함한다. 가장 최근에 업데이트된 데이터는 이하를 참조한다. - 복수의 물체(On), - 복수의 생명체(Ln), - 조건부 보행 가능 영역(CWA), 일부 물체(On) 및/또는 일부 생명체(Ln)가 상기 조건부 보행 가능 영역(CWA), 예를 들어 신호등 또는 개와 관련되기 때문에, - 질의 이전의 기존 관계(Rn). 또한, 관계 매니저 하위 유닛은 복수의 물체(On) 및/또는 복수의 생명체(Ln) 사이의 관계를 결정 및 업데이 트하기 위한 계산을 수행하고 계산 결과로서의 업데이트된 관계를 라이브 맵 하위 유닛에 전송하여 라이브 맵에 저장하도록 구성되는 수단을 포함한다. 네비게이션 매니저 하위 유닛은 이하를 수행하도록 구성되는 수단을 포함한다. - 적어도 하나의 네비게이션 경로(Pn)를 결정하고 반복적으로 업데이트하여 메모리(M)에 저장하고, - 적어도 하나의 네비게이션 경로(Pn) 중에서 선호 네비게이션 경로(SP)를 반복적으로 선택하고, - 관련 네비게이션 안내 지시와 함께 선호 네비게이션 경로(SP)를 피드백 매니저 하위 유닛에 반복적으로 전송하고. - 사용자 명령 인터페이스 매니저 하위 유닛으로부터 시작 요청, 선택 요청 및 정보 요청을 수신하고, - 감각 융합 하위 유닛으로부터 수신된 융합된 데이터 및 자유 영역(A)의 구성 요소: 보행 가능 영역(WA), 조건부 보행 가능 영역(CWA) 및 보행 불가 영역(NA)에 기초한 라이브 맵 결정을 라이브 맵에 질의하고 라 이브 맵 서브 유닛으로부터 각각의 질의에 대응하는 응답을 수신하고, - 관심 포인트(PI)가 라이브 맵에 이미 있는 경우 사용자 명령 인터페이스 매니저 하위 유닛의 질의를 수신하고, - 적어도 2개의 네비게이션 경로 요건이 충족되는지 여부를 확인하고, - 피드백 매니저 하위 유닛에 상기 적어도 하나의 예측 가능한 조건부 보행 가능 영역 요건과 관련된 네비 게이션 안내 지시를 전송한다. 사용자 명령 인터페이스 매니저 하위 유닛은 시각 장애 사용자가 사용자 명령 인터페이스를 통해 행하는 요청 및 선택을 수신하여 네비게이션 매니저 하위 유닛에 전송하도록 구성된 수단과 선택된 안내 모드를 피드백 매니저 하위 유닛에 전송하도록 구성된 수단을 포함한다. 사용자 명령 인터페이스 매니저 하위 유닛은 라이브 맵으로부터 특정 카테고리의 물체(On) 또는 특정 카테고리의 생명체(Ln)의 사운드 표현에 대한 시각 장애 사용자로부터의 요청을 수신하기 위한 수단을 더 포함 한다. 피드백 매니저 하위 유닛은 사용자 명령 인터페이스 매니저 하위 유닛으로부터의 선택된 안내 모드와 함께 네비게이션 매니저 하위 유닛으로부터의 안내 지시를 수신함으로써 선호 네비게이션 경로(SP)를 따라 시각 장애 사용자를 안내하도록 구성된 수단 및 대응하는 관련 안내 지시를 피드백 유닛에 전송하도록 구성 된 수단을 포함하고, 특정 카테고리의 물체(On) 또는 특정 카테고리의 생명체(Ln)에 관한 사운드 표현을 전송하 기 위한 수단을 더 포함한다. 사운드 표현 하위 유닛이 독립적인 하위 유닛이고 네비게이션 매니저 하위 유닛의 하위 유닛인 실시예 에서, 피드백 매니저 하위 유닛은 사운드 표현 하위 유닛으로부터 특정 카테고리의 물체(On) 또는 특정 카테고리의 생명체(Ln)의 사운드 표현을 수신하기 위한 수단을 더 포함한다. 사운드 표현 하위 유닛은 시각 장애인으로부터 요청을 수신하고 라이브 맵으로부터 특정 카테고리의 물체(On) 또는 특정 카테고리의 생명체(Ln)에 대한 해당 정보를 추출하도록 구성된 수단과, 추출된 정보를 해당 공간 사운드로서 표현하여 피드백 유닛에 전송하는 수단을 포함한다. 시각 장애 사용자의 머리에 배치되도록 구성된 피드백 유닛은 피드백 매니저 서브 유닛으로부터 관련 안 내 지시를 수신함으로써 그리고 방법의 단계 4의 세부 사항에 관한 섹션에서 상세히 기술된 바와 같이 시각 장 애 사용자에게 햅틱 및/또는 오디오 큐를 전송함으로써 선호 네비게이션 경로(SP)를 따라 시각 장애 사용자를 안내하도록 구성된 수단을 포함하고, 시각 장애 사용자에게 특정 카테고리의 물체(On) 또는 특정 카테고리의 생 명체(Ln)에 대한 사운드 표현을 전송하기 위한 수단을 포함한다. 시각 장애 사용자의 머리에 배치되도록 구성된 사용자 명령 인터페이스는 시각 장애 사용자로부터 요청, 즉 시작 요청, 선택 요청 및 정보 요청 및 안내 모드의 선택을 수신하여 이들 요청을 사용자 명령 인터페이스 매니 저 하위 유닛에 전송하도록 구성된 수단을 포함한다. 사용자 명령 인터페이스의 비제한적 예는 이하와 같다. - 사용자 명령 햅틱 수단, 예를 들어 빈번한 사전 결정된 관심 포인트(PI)에 대응하는 간단한 요청에 사용 되는 버튼. 예를 들어, 제1 버튼은 시각 장애 사용자가 살고 있는 집의 현관문에 대응하는 '집'을, 제2 버튼은 '화장실'을, 제3 버튼은 '주방'을 명명하는 식이다. 버튼은 아날로그 또는 디지털일 수 있다. - 사용자 명령 오디오 수단, 예를 들어 자주 사용하지 않는 관심 포인트(PI)에 대한 마이크. 사용자 명령 오디오 수단은 음성 인식 수단과 시각 장애 사용자의 단어를 사용자 명령 인터페이스 매니저 하위 유닛에 전송되는 명령으로 변환하기 위한 수단을 포함한다. 4개의 창이 있는 방과 동일한 예를 들면, 시각 장애 사용자 는 마이크에 \"창\"이라고 말하고 방의 4개 창 모두는 사운드로 표현된다. 사용자 명령 인터페이스와 시각 장애 사용자 및 사용자 명령 인터페이스 매니저 하위 유닛의 통신은 종 래 기술에 따른다. 전력 저장 유닛 \"전력 저장 유닛\"이라는 용어는 웨어러블 장치의 다른 하드웨어 장치에 전력을 공급하도록 구성된 하나 또는 여러 개의 배터리를 지칭하는 것으로 이해되어야 한다. 전력 저장 유닛이 웨어러블 장치의 상기 다 른 하드웨어 유닛에 전력을 공급하는 방식은 종래 기술에 따라 수행된다. 통신 유닛은 다운로드 가능한 맵(그러나 이에 제한되지 않음)과 같은 맵을 인터넷으로부터 다운로드하도록 구성된 수단을 포함한다. 본 발명의 제3 양태에서, 컴퓨터 프로그램으로 인코딩된 비일시적 컴퓨터 판독 가능 저장 매체가 제공되며, 컴 퓨터 프로그램은 이들의 조합을 포함하여 임의의 바람직한 실시예에서 실행 시 하나 이상의 프로세서가 시각 장 애 사용자의 이동을 보조하도록 구성된 컴퓨터 구현 방법의 동작을 수행하게 하는, 하나 이상의 프로세서에 의 해 실행 가능한 명령을 포함한다. 본 발명의 제4 양태에서, 프로그램이 웨어러블 장치에 의해 실행될 때 본 발명의 임의의 구현예에 따라 이들의 조합을 포함하여 임의의 바람직한 실시예에서, 시각 장애 사용자의 이동을 보조하도록 구성된 컴퓨터 구현 방법 의 단계를 웨어러블 장치가 수행하게 하는 명령어를 포함하는 컴퓨터 프로그램이 제공된다. 본 발명의 제5 양태에서, 하나 이상의 프로세서 및 하나 이상의 비일시적 컴퓨터 판독 가능 저장 장치를 포함하 는 시스템이 제공되며, 비일시적 컴퓨터 판독 가능 저장 장치는 이들의 조합을 포함하여 임의의 바람직한 실시 예에서, 시각 장애 사용자의 이동을 보조하도록 구성된 컴퓨터 구현 방법의 동작을 수행하도록 하나 이상의 프 로세서에 의해 실행 가능한 명령어를 포함한다. \"컴퓨터\"라는 용어는 마이크로컨트롤러, 컴퓨터, 슈퍼컴퓨터(이에 제한되지 않음)와 같은 적어도 하나의 프로세 서 및 적어도 하나의 비휘발성 메모리를 포함하는 컴퓨팅 유닛을 의미한다. \"컴퓨팅 유닛\"이라는 용어는 컴퓨터 통신 시스템 내에서 원격으로 배치되어 서로 통신하는 단일 컴퓨팅 유닛 또는 복수의 컴퓨팅 유닛을 포함한다. 예 1 방법의 상세한 설명은 도 14, 도 15, 도 16 및 도 17을 참조하여 실생활 시나리오에서 예시된다. 당업자는 본 발명의 교시가 이 예에 제한되지 않음을 이해할 것이다. 실생활 시나리오에서 시각 장애 사용자는 건물 입구에 가까운 거리의 인도에 있다. 그는 건물 안으로 들어가 고자 하므로 자신의 서있는 포인트에서 건물의 현관문까지 길을 찾아야 하고 현관문의 초인종도 찾아야 한다. 이것은 시각 장애 사용자가 건물의 입구 문으로 안내받기 위해 시작 요청을 보내는 경우의 비제한적인 예이다. 도 14 및 도 15에는 다음을 포함하는 라이브 맵의 일부가 도시되어 있다. - 일부분을 갖는 건물: 각 계단, 울타리, 2개의 난간 각각, 초기 관심 포인트로 간주되고 도어 잠금 장치, 문 손잡이 및 초인종과 같은 구성 부분을 갖는 입구 문, 초인종은 추가 관심 포인트로 간주된다. - 생명체(Ln)로서 인식된 개, - 보도와 건물 입구 계단을 포함하는 보행 가능 영역(WA), - 거리를 포함하는 보행 불가 영역(NA), - 조건부 보행 가능 영역: 각각은 해당 신호등이 제공된 2개 횡단보도. 기하학적으로 사전 결정된 보행 가능 영역 요건의 예는 보도의 높이는 7cm를 초과해서는 안 되는 요건, 울타리 까지의 거리는 0.5m를 초과해서는 안 되는 요건, 보도 가장자리까지의 거리는 0.5m를 초과해서는 안 되는 요건, 가상 직육면체의 높이는 시각 장애 사용자의 키 1.80m보다 40cm 더 큰 2.20m인 요건을 포함한다. 정적 및 동적 물리적 관계(Rn)의 예는 신호등의 색상을 조건부 보행 가능 영역의 조건부 상태와 연관 시키는 것(색상이 녹색인 경우 영역은 보행 가능한 반면 색상이 적색인 경우 영역은 보행 불가능한 영역임)과 관련하여 처리 및 제어 유닛의 관계 매니저 하위 유닛에 의해 라이브 맵에서 생성된 관 계이다. 조건부 보행 가능 영역(CWA)에 대한 비제한적 예는 보행자 신호등이 설치된 2개의 횡단보도에 의해 표현된다. 거리는 영구적으로 사전 결정된 보행 가능 영역 요건에서 보행 불가 영역(NA)으로 정의된다. 횡단보 도에 도달할 때, 신호등이 없는 경우에는 보행 가능 영역으로 미리 정의되어 있고, 신호등이 있는 경 우에는 신호등의 색상이 녹색일 때만 보행이 가능한 조건부 보행 가능 영역으로 사전 정의된다. 이는 신호등의 색상이 적색에서 녹색으로, 녹색에서 적색으로 예측 가능하게 변경되므로 하나 이상의 예측 가능한 조 건부 보행 가능 영역 요건의 예이다. 시각 장애 사용자는 시작 요청을 보낼 때 건물의 보도에 있다. 본 발명의 여러 실시예에서, 입구 문은 과거에 방법의 단계 2에서 추가되었기 때문에 이미 라이브 맵 에 있다. 시각 장애 사용자가 택시에서 완전히 새로운 장소에 막 내렸고 입구 문이 이전에 라이브 맵에 추가된 적이 없기 때문에 상기 입구 문은 시작 요청을 전송하는 순간에 라이브 맵에 아직 존재하지 않는 본 발명의 실시예에서, 네비게이션 매니저 하위 유닛은 반복적으로 시야의 초점을 다시 맞추기 위해 방황 경로(WP)를 결정하는 반면, 방법의 S1 및 S2는 상기 입구 문이 발견되어 라이브 맵에 저장될 때까지 반복된다.시각 장애 사용자가 택시에서 서로 근접하는 2개의 입구 문(84-01 및 84-02)이 있는 완전히 새로운 장소에 막 내렸기 때문에 시각 장애 사용자가 입구 문을 알지 못하는 본 발명의 실시예에서, 시각 장애 사용자는 \"입 구 문\"을 찾기 위해 네비게이션 매니저 하위 유닛에 정보 요청을 전송한다. 그런 다음, 네비게이션 매니저 하위 유닛은 시각 장애 사용자의 근접성으로부터 관심 영역의 입구 문에 대한 라이브 맵을 질의하고 2 개의 입구 문(84-01 및 84-02)이 각각 존재하는 것을 발견한다. 2개의 입구 문(84-01 및 84-02)이 라이브 맵에 아직 저장되지 않은 경우, 네비게이션 매니저 하위 유닛 은 상기 입구 문(84-01 및 84-02)이 발견되어 라이브 맵에 저장될 때까지 방황 경로(WP)를 결정한다. 2개의 입구 문(84-01 및 84-02)이 발견되고 라이브 맵에 저장되면 네비게이션 매니저 하위 유닛은 이 들 각각을 대응하는 공간 사운드로서 표현하고 피드백 매니저 하위 유닛을 통해 피드백 유닛에 전송한다. 그러면 시각 장애 사용자는 입구 문(84-01 및 84-02) 중 하나를 자신의 초기 관심 포인트를 구성하는 입구 문으로서 선택한다. 네비게이션 매니저 하위 유닛은 S3에서 단일 네비게이션 경로(Pn) 즉, 시각 장애 사용자가 자신이 서 있는 포인트에서 입구 문까지 네비게이션하기 위한 초기 네비게이션 경로를 결정한다. 따라서 선호 네비게 이션 경로(SP)는 초기 네비게이션 경로이다. 시각 장애 사용자가 초기 네비게이션 경로를 따라 네비게이션할 때, 개가 감각 유닛에 의해 감 지된다. 개의 공격성은 이하와 같이 감지된다. - 개가 짖는 경우, 이는 물체 사운드 특성 융합 모듈에 의해 감지되고, - 개가 공격적인 표정을 지으면, 물체 2D 특성 추출 모듈에 의해 감지되고, - 개가 화가 나서 움직이거나 떨고 있다면, 이는 물체 3D 특성 융합 모듈에 의해 감지된다. 데이터는 기본 센서에 의해 감지되고 적용 가능한 경우 추가 센서에 의해 융합된 후 라이브 맵에 포함되도 록 라이브 맵 서브 유닛에 전송되기 때문에, 네비게이션 매니저 서브 유닛은 라이브 맵을 질의할 때, 적어도 2개의 네비게이션 경로 요건을 확인하고 비공격성 요건이 충족되지 않았음을 검출한다. 이러한 이유 로, 네비게이션 매니저 하위 유닛은 동일한 초기 관심 포인트(PI)를 향하는 2차 네비게이션 경로 를 결정한다. 이제 선호 네비게이션 경로(SP)는 역반응을 갖는 개를 피하는 2차 네비게이션 경로이다. 도 14, 도 15 및 도 16을 참조하면, 2차 경로는 조건부 보행 영역(CWA)의 예인 2개의 횡단보도(83 2)를 이용하여 보행 불가 영역(NA)의 예인 도로를 건너야 한다. 시각 장애 사용자가 제1 횡단보도에 접근할 때, 관계 매니저 하위 유닛은 조건부 영역이 제1 신호등의 색상에 의해 조정된다고 결정한다. 따라서, 제1 신호등의 색상을 제1 횡단보도의 조건부 상태와 관련시키는 조건부 관계가 관계 매니저 하위 유닛에 의해 라이브 맵에 구축된다. 신호등이 녹색으로 바뀌면, 조건부 보행 가능 영역은 보행 가능한 것으로 간주되고 시각 장애 사용자 는 2차 경로에서 네비게이션을 계속하라는 관련 네비게이션 안내 지시를 수신한다. 제2 횡단보도에서도 마찬가지다. 도 16은 제2 신호등의 색상이 녹색으로 바뀔 때까지 제2 횡단보도에서 기다리는, 2차 경로를 네 비게이션하는 시각 장애 사용자를 도시한다. 도 17을 참조하면, 시각 장애 사용자는 이미 2개의 횡단보도를 모두 건넜으며 초기 관심 포인트, 즉 입구 문에 접근하고 있다. 관계 매니저 하위 유닛은 초기 관심 포인트, 즉 입구 문과 추가 관심 포인트, 즉 초인종 사이의 새로운 부모-자식 관계를 결정한다. 따라서, 초인종에 대응하는 새로운 아이템 이 라이브 맵에 생성되고, 입구 문과 초인종 사이의 새로운 부모-자식 관계가 관계 매니저 하위 유닛에 의해 생성되어 라이브 맵에 업데이트된다. 초인종은 관심 포인트(PI)로서 입구 문 을 대체했다. 도 15 및 도 16에는 약 1m의 횡단면, 즉 2차 네비게이션 경로의 좌측으로 약 0.5m 및 우측으로 약 0.5m인 보행 가능 터널이 도시되어 있으며, 후자는 선으로 표현된다. 선호 네비게이션 경로(SP)가 아파트와 같은 실내 공간을 통과하는 경우, 횡단면은 일반적으로 더 작으며, 예를 들어 우선 네비게이션 경로(SP)의 좌측으로 약 0.25m이고 우측으로 약 0.25m인 약 0.5m이다. 시각 장애 사용자가 보행 가능 터널을 지나가게 하는 안내의 세부 사항은 도 15 및 도 16과 관련하여 이하 에 예시된다. 이 예에서, 웨어러블 장치는 좌측 햅틱 피드백 액추에이터, 우측 햅틱 피드백 액추에이터 및 중앙 햅틱 피드백 액추에이터를 구비하고, 이들 각각은 하나 이상의 선형 공진 액추에이터를 포 함한다. 이 예에서, 관련된 네비게이션 안내 지시를 수신하기 위해 3차원 보행 가능 터널(T)이 선택된다. 시각 장애 사용자는 일시적인 제1 햅틱 큐로 시작 명령을 받고 시각 장애 사용자는 네비게이션을 시작한다. 피드백 매니저 하위 유닛은 방향성 햅틱 큐를 제공함으로써 시각 장애 사용자를 선호 네비게이션 경로(SP) 상에서 그리고 보행 가능 터널의 한계 내에서 유지하도록 시도할 것이다. 시각 장애 사용자가 네비게이션할 때 보행 가능 터널의 좌측에 너무 가까이 있으면, 시공간적인 제2 햅틱 큐가 좌측 피드백 액추에이터에 의해 수신된다. 좌측 피드백 액추에이터의 선형 공진 액추에이터는 시각 장애 사용자가 방향을 변경해야 하는 방향, 즉 시각 장애 사용자에게 이마를 우측으로 끌리는 촉각을 제공 하는 우측으로, 다른 선형 공진 액추에이터가 진동한 후 하나의 선형 공진 액추에이터가 진동하는 빠르고 연속 적인 진동을 출력한다. 제2 햅틱 큐의 진동의 지속 시간, 주기성, 강도 또는 빈도수의 변화는 보행 가능 터널 의 좌측에 대한 근접 정도에 비례한다. 시각 장애 사용자가 네비게이션할 때 보행 가능 터널의 우측에 너무 가까이 있으면, 시공간적이고 우측 대 신 좌측을 방향 재지정 방향으로 표시한다는 점만 제외하고 제2 햅틱 큐 중 하나와 동일한 구성을 갖는 제3 햅 틱 큐가 우측 피드백 액추에이터에 의해 수신된다. 제3 햅틱 큐의 진동의 지속 시간, 주기성, 강도 또는 빈도수의 변화는 보행 가능 터널의 우측에 대한 근접 정도에 비례한다. 사용자를 진행으로 안내하는 것은 시공간적인 제4 햅틱 큐이다. 제4 햅틱 큐는 중앙 피드백 액추에이터에 의해 수신된다. 제4 햅틱 큐의 진동의 지속 시간, 주기성, 강도 또는 빈도수의 변화는 시각 장애 사용자가 네비 게이션할 때 가져야 하는 속도에 비례한다. 시각 장애 사용자가 네비게이션할 때 수평면에서 이동 방향을 다시 설정해야 하는 경우, 예를 들어 도 16에 도 시된 보행자 교차로에 도달했을 때 우회전해야 하면, 중앙 피드백 액추에이터에 의해 시공간적인 제5 햅틱 패턴 큐가 수신된다. 제5 햅틱 큐의 진동의 지속 시간, 주기성, 강도 또는 빈도수의 변화는 회전 정도에 비례한다. 시각 장애 사용자가 네비게이션할 때 수직면에서 이동 방향을 다시 설정해야 하는 경우, 예를 들어 시각 장애 사용자가 이미 보행자 도로를 건너 건물의 계단에 접근하고 일부 계단을 올라야 하는 경우에, 시공간적인 제6 햅틱 큐가 중앙 피드백 액추에이터에 의해 수신된다. 제6 햅틱 큐의 진동의 지속 시간, 주기성, 강도 또는 빈도수의 변화는 시각 장애 사용자에게 필요한 움직임의 양에 비례한다. 시각 장애 사용자가 도 15 및 도 16에 도시된 보행자 교차로에 도달할 때, 신호등의 색이 적색이면, 시간적이고 중앙 피드백 액추에이터에 의해 일시적으로 중지하라는 관련 네비게이션 안내 지시에 대응하는 제7 햅틱 큐가 수신된다. 그런 다음 신호등이 녹색으로 바뀌면, 이번에는 네비게이션 재개에 대응하는 제7 햅틱 큐가 다시 수신된다. 시간적이고 관심 포인트(PI)에 도달함에 따라 네비게이션의 종료를 시그널링하는 제8 햅틱 패턴 큐가 중심 피드 백 액추에이터로부터 수신된다. 네비게이션 상황 또는 사용자 요건을 수용하도록 추가 유형의 햅틱 패턴 큐가 정의될 수 있다. 예를 들어, 시각 장애 사용자가 네비게이션할 때 2차 네비게이션 경로의 보행 가능 터널 내의 중심에 있으면, 우측 피 드백 햅틱 액추에이터 및 좌측 피드백 햅틱 액추에이터는 어떤 유형의 햅틱 패턴 큐도 제시하지 않을 수 있거나, 이마 양쪽에 제9 유형의 햅틱 패턴 큐를 제공하여 시각 장애 사용자에게 그가 보행 가능 터널 내 중심에서 네비게이션하고 있음을 시그널링한다. 예 2 그룹 시각 장애 사용자가 4개의 창, 즉 제1 창(85-1), 제2 창(85-2), 제3 창(85-3), 제4 창(85-4)이 있는 새로 운 방에 들어가고 4개의 창 중 하나를 열기를 원할 때를 예로 들면, 잠재적인 관심 포인트(PPI)는 복수의 물체(On) 중에서 선택된 적어도 하나의 물체(On)로서 4개의 창의 그룹이다. \"잠재적인\"이라는 용어는 방의 임의의 창이 초기 관심 포인트(PI)로서 선택될 수 있음을 의미한다. 도 18 내지 도 28을 참조하면, 시각 장애 사용자는 초기 관심 포인트(PI)를 선택하기 위해 그가 방으로부터 창 에 관한 더 많은 세부 사항을 찾는 데 관심이 있기 때문에 하위 단계 S.3-0.1에서 \"창\"이라는 이름의 정보 요청 을 잠재적 관심 포인트(PPI)로서 전송한다. 당업자는 설명된 예가 모든 종류의 물체(On)에 적용되고 생명체(Ln)의 카테고리에 준용된다는 것을 이해해야 한 다. 하위 단계 S.3.-0.2에서 사운드 표현 하위 유닛은 4개의 창 각각을 대응하는 공간 사운드로서 표현한다. 제1 공간 사운드(S86-1), 제2 공간 사운드(S86-2), 제3 공간 사운드(S86-3), 제4 공간 사운드(S86- 4)는 사운드 표현 하위 유닛이 상기 피드백 매니저 하위 유닛의 일부가 아닐 때, 피드백 매니저 하위 유닛을 통해 4개의 공간 사운드를 피드백 유닛에 전송한다. 하위 단계 S.3-0.3에서 시각 장애 사용자는 4개의 창(85-1, 85-2, 85-3, 85-4)으로부터 초기 관심 포인트(PI) 로서 선택하고 다른 선택 요청과 마찬가지로 대응하는 선택 요청을 송신한다. 하위 단계 S.3-0.2의 사운드 표현은 4개의 창(85-1, 85-2, 85-3, 85-4)의 그룹에서 하나의 창 또는 2개의 창에 대해 도 18 내지 도 28을 참조하여 이하에 예시된다. 당업자는 본 발명의 교시가 이러한 예 그룹에 제한되지 않 는다는 것과 창에 대한 참조번호는 4개의 창(85-1, 85-2, 85-3, 및 85-4)을 나타낸다는 것을 이해해야 한다. 마찬가지로, 공간 사운드에 대한 참조번호(S86)는 대응하는 각각의 공간 사운드(S86-1, S86-2, S86-3 및 S86-4)를 나타낸다. 예 2-1에서, 도 18을 참조하면, 바람직한 실시예에서, 사운드 표현 모듈은 라이브 맵으로부터 잠재적 관심 포인트(PPI)인 창에 관한 특정 정보를 추출하고, 이들을 창의 위치로부터 방출되는 시각 장애 사 용자에 의해 인지되는 공간 사운드(S86)로 인코딩하고, 오디오 피드백 액추에이터에 의해 시각 장애 사용자 에게 공간 사운드(S86)를 전송한다. 상기 잠재적 관심 포인트(PPI)를 나타내는 창의 추가적인 특징, 예를 들어 그것의 치수 또는 재질의 밀도를 예시하기 위해, 네비게이션 매니저 하위 유닛은 공간 사운드(S86)를 그래픽으로 표시되지 않은 특정 주파수 (S86f), 특정 시간 주기(S86t) 및/또는 특정 펄스(S86p)를 갖는 공간 사운드로서 추가로 인코딩할 수 있으며, 상기 주파수(S86f), 특정 시간 주기(S86t) 및/또는 펄스(S86p)는 상기 추가적인 특징에 대응한다. 도 19a 및 도 19b 각각에서, 예 2-2 및 예 2-3를 참조하면, 다른 바람직한 실시예에서, 사운드 표현 하위 유닛 은 선택된 창에 관한 특정 정보를 잠재적인 관심 포인트의 위치에 대해 과장되거나 \"확대된\" 표현 을 갖는 공간 사운드(S86)로서 인코딩한다. 예를 들어, 잠재적 관심 포인트가 10m 범위에 있다면, 예를 들 어 1m 범위에서 공간 사운드(S861)로 표현될 것이다. 이 확대 또는 과장 효과는 도 19a에 도시된 고도와 도 19b 에 도시된 방위 모두에서 시각 장애 사용자에게 제공된다. 예 2-4에서, 도 20을 참조하면, 다른 바람직한 실시예에서, 시각 장애 사용자는 시각 장애 사용자로부터 동일하 지 않은 거리에 배치된 2개의 창(85-1, 85-2)의 사운드 표현에 대한 요청을 전송한다. 사운드 표현 서브 유닛은 라이브 맵으로부터의 선택된 창(85-1, 85-2)의 특정 정보를 시각 장애 사용 자까지의 창(85-1, 85-2)의 거리에 따라 서로 다른 주파수 특성을 갖는 공간 사운드(S86f-1, S86f-2)로 인코딩 하고, 인코딩된 공간 사운드(S86f-1, S86f-2)를 시각 장애 사용자에게 전송한다. 따라서 예를 들어 시각 장애 사용자에게 전송된 창의 추가 기능에 대응하는 공간 사운드(S86f-1, S86f-2)의 대응하는 오디오 큐는 주파수에 따라 변하고, 시각 장애 사용자에게 더 가까운 것(85-1)보다 창(85-2)에 대해 큐는 더 오래 지속되고/되거나 반복 정도는 더 높다. 예 2-5에서, 도 21을 참조하면, 다른 바람직한 실시예에서, 시각 장애 사용자는 창의 여백을 사운드로 표현 하라는 요청을 전송한다. 간략화를 위해, 각각 2개의 말단(85-E1 및 85-E2)만을 나타내도록 선택되었으며, 당업 자는 동일한 표현이 창의 형상에 따라 창의 모든 말단에 적용됨을 이해한다. 사운드 표현 하위 유닛은 라이브 맵으로부터 선택된 창의 특정 정보를 추출하고, 그것을 창 말단 (85-1E 및 85-E2)에 대응하는 공간 사운드(S86P-E1 및 S86P-E2)로 인코딩하고, 공간 사운드(S86P-E1 및 S86P- E2)는 시각 장애 사용자에 대한 2개의 선택된 말단의 거리에 따라 서로 다른 인코딩 특성을 갖는다. 거리는 창 의 방위, 고도 또는 범위에서 또는 전술한 것의 임의의 조합에서 측정될 수 있다. 예 2-6에서, 도 22를 참조하면, 다른 바람직한 실시예에서, 시각 장애 사용자는 잠재적인 관심 포인트(PPI)로서 창의 치수를 표현하기 위해 사용자 명령 인터페이스에 의한 요청을 사용자 명령 인터페이스 하위 유닛 을 통해 사운드 표현 하위 유닛에 전송한다. 사운드 표현 서브 유닛은 라이브 맵으로부터 추출된 선택된 창의 치수의 특정 정보를 창의 선 택된 말단 사이의 3개의 공간적 치수 중 하나를 따라 점형 사운드를 표현하는 시간 공간 사운드(S86P) 또는 말 단(85-E1)에서 말단(85-E2)까지의 직선 경로로 이동하는 선형 사운드(S86L)로 인코딩하고, 이들을 오디오 피드 백 액추에이터를 통해 시각 장애 사용자에게 전송한다. 창이 직사각형인 경우(그래픽으로 표시되지 않 음) 창의 다른 말단, 특히 85-E3 및 85-E4에 대해 동일한 작업이 수행된다. 창의 치수는 종래 기술로부터 공지된 수단에 의해 대응하는 공간 치수를 따라 창의 말단(85-E1, 85-E2, 85-E3 및 85-E4) 사이에서 측정된다. 예 2-7 내지 예 2-10에서, 도 23 내지 도 26을 참조하면, 다른 바람직한 실시예에서, 시각 장애 사용자는 창 또는 창 일부의 형상을 표현하기 위한 요청을 전송한다. 예 2-7 내지 예 2-10에서, 창은 직사각형이 아닌 장식용 창, 또는 거울 또는 문의 장식 부분일 수 있다. 단순화를 위해 창으로 지칭될 수 있다. 사운드 표현 하위 유닛은 라이브 맵으로부터 특정 정보를 추출하고, 이것을 창의 형상을 나타내는 시간 공간 사운드(S86)로 인코딩한다. 예 2-7에서, 도 23을 참조하면, 창의 형상은 2개의 공간화된 점형 사운드(S86P1 및 S86P2)로 표현되고, 그 들 각각은 창의 수직 대칭 축에 배치된 시작 포인트(tO)에서 종료 포인트(tfinal)로 창 윤곽의 절반에서 동시에 가상으로 이동한다. 예 2-8에서, 도 24를 참조하면, 창의 형상은 시작 포인트(tO)에서 종료 포인트(tfinal)로 창의 윤곽에서 가상 으로 이동하는 2개의 공간 사운드(S86f1 및 S86f2)로 표현되고, 공간 사운드(S86f1, S86f2)는 공간 사운드가 이 동한 창 부분의 윤곽의 사용자에 대한 거리에 따라 서로 다른 주파수로 인코딩된다. 예 2-9에서, 도 25를 참조하면, 창의 형상은 시작 포인트(tO)에 다시 도달할 때까지 창 부분의 윤곽에 서 시작 포인트(tO)로부터 가상으로 이동하는 단일 공간 사운드(S86)로 표현된다. 예 2-10에서, 도 26을 참조하면, 창의 형상은 창의 내부 윤곽과 외부 윤곽 사이의 공간 내에서 각진 패 턴으로 가상으로 이동하는 단일 공간 사운드(S86)로 표현된다. 예 2.11 및 예 2.12에서, 도 27 및 도 28을 참조하면, 다른 바람직한 실시예에서, 선택된 창은 창 또는 문을 나 타낼 수 있다. 이들 2개의 예에서, 창은 장식 용도 또는 기술적 기능을 갖는 적어도 하나의 내부 프레임을 갖는 다. 이러한 바람직한 실시예에서 내부 프레임의 윤곽은 예를 들어 부상의 위험 때문에 또는 문 또는 창의 손잡 이가 내부 프레임 상에 있기 때문에 중요하다. 예 2.11에서, 도 27을 참조하면, 잠재적인 관심 포인트로서 함께 서 있는 2개의 창(85-1, 85-2)이 시각 장애 사 용자에 대해 서로 다른 거리에 배치되어 있다. 이들은 창이나 문이 될 수 있다. 시각 장애 사용자가 취해야 하 는 행동은 둘 모두에 관련되기 때문에 잠재적인 관심 포인트로 함께 서 있다. 예를 들어, 둘 다 열려 있어야 하 는 2개의 분리된 창이 있거나 시각 장애 사용자가 통과해야 하는 2개의 문이 있는 복도가 있다. 2개의 창(85-1, 85-2)은 다양한 치수의 열린 공간(예를 들어, 창의 경우 5-10cm, 문의 경우 1-2m)만큼 분리되어 있다. 시각 장애 사용자는 창에 더 가깝게 배치된다. 시각 장애 사용자는 2개의 창(85-1, 85-2) 사이의 열린 공간 거리의 사운드 표현과 2개의 창(85-1, 85-2)의 내 부 프레임 형상에 대한 요청을 전송한다. 사운드 표현 서브 유닛은 2개의 창(85-1, 85-2)의 라이브 맵으로부터 특정 정보를 추출하고, 2개의 창 (85-1, 85-2)의 내부 프레임의 형상을 표현하기 위한 서로 다른 시간 특성을 갖는 공간 사운드(S86t-1, S86t- 2)로 인코딩한다. 도 27에 도시된 바와 같이 시각 장애 사용자에게 더 가까이 위치한 창(85-1)은 2개의 공간 사운드(S86t1-1, S86t2-1)로 표현되고, 하나의 공간 사운드(S86t1-1)는 창(85-1)의 외부 윤곽을 나타내고 다른 공간 사운드 (S86t2-1)는 창(85-1)의 내부 윤곽을 나타낸다. 각각의 공간 사운드(S86t1-1 및 S86t2-1)는 동시에 시작하는 2 개의 다른 공간 사운드, 즉 창(85-1)의 외부 윤곽을 나타내는 S86t11-1 및 S86t12-1과 창-1의 내부 윤곽을 나타내는 S86t21-1과 S86t22-1을 포함한다. 2개의 창(85-1, 85-2) 사이의 열린 공간으로 인해, 시각 장애 사용자에게 더 가까이 위치한 창(85-1)은 제2 창 (85-2)에 관한 자세한 정보를 검출하는 장벽 역할을 하고, 결과적으로 사운드 표현 하위 유닛은 창(85-2)의 3차원 위치 및 수직 치수에 대응하는 단순화된 공간 사운드(S86t-2)만을 출력할 수 있다. 예 2-12에서, 도 28을 참조하면, 다른 바람직한 실시예에서, 시각 장애 사용자는 창의 내부 프레임의 형상 의 세부 사항의 사운드 표현에 대한 요청을 전송한다. 단순화를 위해 도 28은 직사각형 형상을 예시하지만 어떤 기하학적 형상도 될 수 있다. 사운드 표현 서브 유닛은 라이브 맵으로부터 특정 정보를 추출하고, 동시에 시작하여 창의 내부 프레임의 윤곽과 외부 윤곽 사이의 공간 내에서 각진 패턴으로 가상으로 이동하는 2개의 공간 사운드(S861, S862)로 인코딩한다. 방법 및 시스템의 설명이 바람직한 실시예와 관련하여 상세하게 개시되었지만, 당업자는 본 발명의 교시에 대한 본질적인 범위를 벗어나지 않고 특정 상황에 적응하도록 수정이 이루어질 수 있음을 이해할 것이다. 청구범위에 나타나는 참조 번호는 단지 예시를 위한 것이며 청구범위에 제한적인 영향을 미치지 않는다. 레퍼런스 목록"}
{"patent_id": "10-2023-7025704", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "[1] - US 3,594,823"}
{"patent_id": "10-2023-7025704", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "[2] - US 9,915,545"}
{"patent_id": "10-2023-7025704", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "[3] - US 9,629,774"}
{"patent_id": "10-2023-7025704", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "[4], 장 샤오첸 외 다수 발명. \"Wearable Indoor Navigation System with Context Based Decision Making for Visually Impaired\" [4] 국제 첨단 로봇 및 자동화 저널"}
{"patent_id": "10-2023-7025704", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "[5] US 2016/0033280 A1 도면 도면1 도면2a 도면2b 도면3 도면4 도면5 도면6 도면7 도면8a 도면8b 도면9 도면10 도면11 도면12 도면13 도면14 도면15 도면16 도면17 도면18 도면19a 도면19b 도면20 도면21 도면22 도면23 도면24 도면25 도면26 도면27 도면28"}
{"patent_id": "10-2023-7025704", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명에 따른 방법 및 웨어러블 장치의 개략도이다. 도 2는 2개의 바람직한 실시예에서 웨어러블 장치의 구성 요소의 개략적인 포지셔닝을 보여주는 트라이메트 릭 뷰로서, 도 2a는 2개의 구성 요소의 웨어러블 장치를 예시하고, 도 2b는 단일 구성 요소의 웨어러블 장치를 예시한다. 도 3은 기본 센서의 시야에 대한 개략도이다. 도 4는 현실 및 라이브 맵 콘텐츠의 개략도이다. 도 5는 웨어러블 디바이스가 기본 센서만을 사용할 때의 라이브 맵의 생성의 개략도이다. 도 6은 시각 장애 사용자의 뒤통수에서 본 헤드셋 구성 요소를 보여주고 피드백 유닛의 구성 요소 및 사 용자 명령 인터페이스의 구성 요소의 포지셔닝을 상세히 나타내는 바람직한 실시예 중 하나의 트라이메트릭 뷰이다. 도 7은 시각 장애 사용자의 이마에서 본 헤드셋 구성 요소를 보여주고 4개의 기본 센서의 포지셔닝과 사용 자 명령 인터페이스의 구성 요소의 포지셔닝을 상세히 나타내는 도 6의 바람직한 실시예의 세부 정면도이다. 도 8a는 보행 가능 터널(T)을 사용하여 안내 모드를 보여주는 개략도이다. 도 8b은 보행 가능 터널(T)을 사용하여 안내 모드를 보여주는 실시예의 트라이메트릭 뷰이다. 도 9는 이정표를 사용하여 안내 모드를 보여주는 실시예의 트라이메트릭 뷰이다. 도 10은 보행 가능 터널(T) 및 이정표를 사용하여 안내 모드를 보여주는 실시예의 개략도이다. 도 11은 도 11a의 햅틱 큐 및 도 11b의 오디오 큐를 사용하여 안내 모드를 보여주는 실시예의 개략도이다. 도 12는 선호 네비게이션 경로(SP)를 따라 가상으로 이동하는 공간화된 음원(S)으로부터 발생하는 공간 사운드 를 사용함으로써 안내 모드를 보여주는 실시예의 개략도이다. 도 13은 2개의 추가 센서(25, 26)를 포함하는 웨어러블 장치에 대응하는 실시예의 개략도이다. 도 14 내지 도 17은 예 1의 방법을 예시한다. 도 14는 실제 시나리오 장면의 평면도이다. 도 15는 실제 시나리오 장면의 트라이메트릭 뷰이다. 도 16은 2차 경로의 세부 사항을 예시한다. 도 17은 초인종이 관심 포인트(PI)로서 입구 문을 대체하는 세부 사항을 예시한다. 도 18 내지 도 28은 예 2로서, 창를 상징적으로 표현하는 방법을 예시한다. 도 18은 예 2-1로서, 공간 사운드(S86)가 창의 동일한 위치에서 인지되는 방법의 단계 S.3-0.2의 개략도이 다. 도 19a는 예 2-2로서, 공간 사운드(S86)가 입면 공간 차원에서 창에 대해 과장되거나 \"확대\"된 방법의 단계 S.3-0.2의 개략도이다. 도 19b는 예 2-3로서, 공간 사운드(S86)가 방위각 공간 차원에서 창에 대해 과장되거나 \"확대\"된 방법의 단 계 S.3-0.2의 개략도이다. 도 20은 예 2-4로서, 시각 장애 사용자로부터 동일하지 않은 거리에 배치된 2개의 창(85-1 및 85-2)가 시각 장 애 사용자로부터의 창(85-1, 85-2)의 거리에 따라 가상 사운드(S86f-1, S86f-2)의 주파수 특성이 서로 다른 사 운드로 표현되는 방법의 단계 S.3-0.2의 개략도이다. 도 21은 예 2-5로서, 창의 여백이 시각 장애 사용자에 대한 각 말단의 거리에 따라 상이한 인코딩 특성을 갖는 2개의 공간 사운드(S86P-E1 및 S86P-E2)에 의해 표현되는 사운드인 방법의 단계 S.3-0.2의 개략도이다. 도 22는 예 2-6로서, 창의 치수(S86P 및 S86L)의 표현을 보여주는 방법의 단계 S.3-0.2의 개략도이다. 도 23은 예 2-7로서, 창의 형상이 2개의 공간화된 점형 음원(S86P1 및 S86P2)에 의해 표현되는 방법의 단계 S.3-0.2의 개략도이다. 도 24는 예 2-8로서, 창의 형상이 방위에서 상이한 주파수를 갖는 2개의 공간화된 음원(S86f1, S86f2)에 의 해 표현되는 방법의 단계 S.3-0.2의 개략도이다. 도 25는 예 2-9로서, 창의 형상이 시작 포인트(t0)에 다시 도달할 때까지 창의 윤곽 상에서 시작 포인 트(t0)로부터 가상으로 이동하는 단일 공간화된 음원(S86)으로 표현되는 방법의 단계 S.3-0.2의 개략도이다. 도 26은 예 2-10로서, 창의 형상이 각진 패턴으로 가상으로 이동하는 단일 공간화된 음원(S86)에 의해 표현 되는 방법의 단계 S.3-0.2의 개략도이다. 도 27은 예 2-11로서, 시각 장애 사용자에 대해 서로 다른 거리에 배치된 2개의 창(85-1, 85-2)의 표현을 나타 내는 방법의 단계 S.3-0.2의 개략도이다. 도 28은 예 2-12로서, 동시에 시작하고 창의 내부 프레임 안쪽에서 각진 패턴으로 이동하는 2개의 공간 사운드(S861, S862)에 의한 창의 사운드 표현을 나타내는 방법의 단계 S.3-0.2의 개략도이다."}
