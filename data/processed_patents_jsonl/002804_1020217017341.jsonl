{"patent_id": "10-2021-7017341", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2021-0096619", "출원번호": "10-2021-7017341", "발명의 명칭": "분산 컴퓨팅 및 스토리지에 대한 지능형 비중앙집중식 자율 마켓플레이스", "출원인": "이아곤 에즈", "발명자": "리마 클라우디오"}}
{"patent_id": "10-2021-7017341", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "피어-투-피어 네트웤에 있어서,하나의 티어 내에 있는 복수의 컴퓨트 노드들 리스트를 생성하는 매니징 노드;다른 노드들이 활용할 컴퓨트 리소스들을 제공하며, 적어도 부분적으로 상기 컴퓨트 리소스들에 기초해서 자신이 상기 티어 내에 있음을 결정하고, 상기 매니징 노드에게 상기 결정에 따라 상기 리스트에 자신을 추가하도록통지하는, 제1 컴퓨트 노드; 및자신과 관련된 하나 또는 그 이상의 태스크들을 실행하도록 활용될 것으로 예측된 컴퓨트 용량에 기초하여 상기티어의 확인을 수행하고, 그 확인에 입각해서 상기 매니징 노드를 확인하며, 상기 매니징 노드로부터 상기 리스트를 요청하는, 클라이언트 노드를 포함하는 피어-투-피어 네트웤."}
{"patent_id": "10-2021-7017341", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 컴퓨트 리소스들은 하나 또는 그 이상의 활용 가능한 중앙 처리 장치들 및 활용 가능한 메모리를포함하는, 네트웤."}
{"patent_id": "10-2021-7017341", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 매니징 노드는 상기 리스트를 상기 클라이언트 노드로 전달하는, 네트웤."}
{"patent_id": "10-2021-7017341", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,상기 클라이언트 노드는 상기 복수의 컴퓨트 노드들로부터 최저가 노드를 확인하는, 네트웤."}
{"patent_id": "10-2021-7017341", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서,상기 클라이언트 노드는 상기 클라이언트 노드와 상기 최저가 노드 사이의 레이턴시를 결정하기 위해 레이턴시테스트를 실행하는, 네트웤."}
{"patent_id": "10-2021-7017341", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5항에 있어서,상기 클라이언트 노드는:상기 레이턴시가 기준치보다 큰지 결정하고;상기 레이턴시가 상기 기준치 보다 큼에 따라, 상기 하나 또는 그 이상의 태스크들이 실행을 위해 상기 제1 컴퓨트 노드로 오프로드되어야 한다고 결정하는,네트웤."}
{"patent_id": "10-2021-7017341", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에 있어서, 공개특허 10-2021-0096619-3-상기 제1 컴퓨트 노드는 적어도 전기 비용 및 사용자 입력에 기초해서 상기 컴퓨트 리소스들을 활용하는데 드는비용을 결정하는, 네트웤."}
{"patent_id": "10-2021-7017341", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1항에 있어서, 상기 제1 컴퓨트 노드는 상기 컴퓨트 리소스들의 아이덴티피케이션(identification)을 상기 매니징 노드로 전달하는, 네트웤."}
{"patent_id": "10-2021-7017341", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "한 세트의 명령을 포함하는 적어도 하나의 컴퓨터 판독 가능한 저장 매체에 있어서, 상기 명령들은, 복수의 컴퓨팅 디바이스들에 의해 실행될 때, 상기 복수의 컴퓨팅 디바이스들로 하여금:매니징 노드를 가지고, 한 티어 내에 있는 복수의 컴퓨트 노드들의 리스트를 생성하고;제1 컴퓨트 노드를 가지고, 다른 노드들이 활용할 컴퓨트 리소스들을 제공하며;상기 제1 컴퓨트 노드를 가지고, 적어도 부분적으로 상기 컴퓨트 리소스들에 기초하여 상기 컴퓨트 노드가 상기티어 내에 있다는 결정을 수행하고;상기 제1 컴퓨트 노드를 가지고, 상기 결정에 입각해 상기 제1 컴퓨트 노드를 상기 리스트에 추가하도록 상기매니징 노드에게 통지를 전송하며;클라이언트 노드를 가지고, 상기 클라이언트 노드와 관련된 하나 또는 그 이상의 태스크들을 실행하도록 활용될것으로 예측된 컴퓨트 용량에 기초해서 상기 티어의 확인을 수행하고;상기 클라이언트 노드를 가지고, 상기 확인에 기초해서 상기 매니징 노드를 확인하며;상기 클라이언트 노드를 가지고, 상기 매니징 노드로부터 상기 리스트를 요청하게 하는,적어도 하나의 컴퓨터 판독 가능한 저장 매체."}
{"patent_id": "10-2021-7017341", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9항에 있어서, 상기 컴퓨트 리소스들은 하나 또는 그 이상의 활용 가능한 중앙 처리 장치 및 활용 가능한 메모리를 포함하는,적어도 하나의 컴퓨터 판독 가능한 저장 매체."}
{"patent_id": "10-2021-7017341", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제9항에 있어서, 상기 명령들은, 실행되어, 상기 복수의 컴퓨팅 디바이스들로 하여금, 상기 매니징 노드를 가지고, 상기 리스트를 상기 클라이언트 노드로 전송하게 하는, 적어도 하나의 컴퓨터 판독 가능한 저장 매체."}
{"patent_id": "10-2021-7017341", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제9항에 있어서, 상기 명령들은, 실행되어, 상기 복수의 컴퓨팅 디바이스들로 하여금, 상기 클라이언트 노드를 가지고, 상기 복수의 컴퓨트 노드들로부터 최저가 노드를 확인하게 하는, 적어도 하나의 컴퓨터 판독 가능한 저장 매체."}
{"patent_id": "10-2021-7017341", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제12항에 있어서, 상기 명령들은, 실행되어, 상기 복수의 컴퓨팅 디바이스들로 하여금, 상기 클라이언트 노드를 가지고, 상기 클라이언트 노드와 상기 최저가 노드 사이의 레이턴시를 결정하도록 레이턴시 테스트를 실행하게 하는, 적어도 하나의 컴퓨터 판독 가능한 저장 매체.공개특허 10-2021-0096619-4-청구항 14 제13항에 있어서, 상기 명령들은, 실행되어, 상기 복수의 컴퓨팅 디바이스들로 하여금:상기 클라이언트 노드를 가지고, 상기 레이턴시가 기준치보다 크다고 결정하고;상기 레이턴시가 상기 기준치보다 큼에 따라, 상기 클라이언트 노드를 가지고, 상기 하나 또는 그 이상의 태스크들이 실행을 위해 상기 제1 컴퓨트 노드로 오프로드되어야 한다고 결정하는,적어도 하나의 컴퓨터 판독 가능한 저장 매체."}
{"patent_id": "10-2021-7017341", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제9항에 있어서, 상기 명령들은, 실행되어, 상기 복수의 컴퓨팅 디바이스들로 하여금:상기 제1 컴퓨트 노드를 가지고, 적어도 전기 비용과 사용자 입력에 기초해서 상기 컴퓨트 리소스들을 활용하는데 드는 비용을 결정하게 하는,적어도 하나의 컴퓨터 판독 가능한 저장 매체."}
{"patent_id": "10-2021-7017341", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제9항에 있어서, 상기 명령들은, 실행되어, 상기 컴퓨팅 디바이스들로 하여금, 상기 제1 컴퓨트 노드를 가지고, 상기 컴퓨트 리소스들의 아이덴티피케이션(identification)을 상기 매니징 노드로 전송하게 하는, 적어도 하나의 컴퓨터 판독가능한 저장 매체."}
{"patent_id": "10-2021-7017341", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "매니징 노드를 가지고, 하나의 티어 내에 있는 복수의 컴퓨트 노드들의 리스트를 생성하는 것;제1 컴퓨트 노드를 가지고, 다른 노드들이 활용할 컴퓨트 리소스들을 제공하는 것;상기 제1 컴퓨트 노드를 가지고, 적어도 부분적으로 상기 컴퓨트 리소스들에 기초해서 상기 제1 컴퓨트 노드가상기 티어 내에 있다는 결정을 수행하는 것;상기 제1 컴퓨트 노드를 가지고, 상기 결정에 기초해서 상기 제1 컴퓨트 노드를 상기 리스트에 추가하도록 상기매니징 노드에게 통지를 전송하는 것;클라이언트 노드를 가지고, 상기 클라이언트 노드와 관련된 하나 또는 그 이상의 태스크들을 실행하도록 활용될것으로 예측된 컴퓨트 용량에 기초하여 상기 티어의 확인을 수행하는 것;상기 클라이언트 노드를 가지고, 상기 확인에 기초하여 상기 매니징 노드를 확인하는 것; 및상기 클라이언트 노드를 가지고, 상기 매니징 노드로부터 상기 리스트를 요청하는 것을 포함하는 방법."}
{"patent_id": "10-2021-7017341", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제17항에 있어서, 상기 컴퓨트 리소스들은 하나 또는 그 이상의 활용 가능한 중앙 처리 장치 및 활용 가능한 메모리를 포함하는,방법."}
{"patent_id": "10-2021-7017341", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제17항에 있어서, 상기 매니징 노드를 가지고, 상기 리스트를 상기 클라이언트 노드로 전송하는 것을 추가로 포함하는, 방법."}
{"patent_id": "10-2021-7017341", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "공개특허 10-2021-0096619-5-제17항에 있어서, 상기 클라이언트 노드를 가지고, 상기 복수의 컴퓨트 노드들로부터 최저가 노드를 확인하는 것을 추가로 포함하는, 방법."}
{"patent_id": "10-2021-7017341", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_21", "content": "제20항에 있어서, 상기 클라이언트 노드를 가지고, 상기 클라이언트 노드와 상기 최저가 노드 사이에서 레이턴시를 결정하는 레이턴시 테스트를 실행하는 것을 추가로 포함하는, 방법."}
{"patent_id": "10-2021-7017341", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_22", "content": "제21항에 있어서,상기 클라이언트 노드를 가지고, 상기 레이턴시가 기준치보다 크다고 결정하는 것;상기 레이턴시가 상기 기준치보다 큼에 따라, 상기 클라이언트 노드를 가지고, 상기 하나 또는 그 이상의 태스크들이 실행을 위해 상기 제1 컴퓨트 노드로 오프로드되어야 한다고 결정하는 것을 추가로 포함하는, 방법."}
{"patent_id": "10-2021-7017341", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_23", "content": "제17항에 있어서,상기 제1 컴퓨트 노드를 가지고, 적어도 전기 비용과 사용자 입력에 기초하여 상기 컴퓨트 리소스들을 활용하는데 드는 비용을 결정하는 것을 추가로 포함하는, 방법."}
{"patent_id": "10-2021-7017341", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_24", "content": "제17항에 있어서,상기 제1 컴퓨트 노드를 가지고, 상기 컴퓨트 리소스들의 아이덴티피케이션(identification)을 상기 매니징 노드로 전송하는 것을 추가로 포함하는, 방법."}
{"patent_id": "10-2021-7017341", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "방법, 시스템 및 장치들이 비중앙집중식 네트웤을 제공하는 기술을 가능하게 할 수 있다. 상기 기술은 한 티어 내의 복수의 컴퓨트 노드들을 담은 리스트를 생성하는 하나의 매니징 노드를 포함할 수 있다. 상기 기술은 다른 노드들이 활용할 컴퓨트 리소스들을 제공하는 제1 컴퓨트 노드를 더 포함할 수 있다. 상기 제1 컴퓨트 노드는 적 어도 부분적으로 상기 컴퓨트 리소스들에 기초하여 상기 제1 컴퓨트 노드가 상기 티어 내에 존재한다는 결정을 수행하고, 상기 결정에 기초해서 상기 리스트에 상기 제1 컴퓨트 노드를 추가하도록 상기 매니징 노드에 통지를 전송한다. 상기 기술은 또한 하나 또는 그 이상의 관련 태스크를 실행하기 위해 활용될 것으로 예측되는 컴퓨트 용량에 기초해서 상기 티어의 확인을 수행하는 하나의 클라이언트 노드를 포함할 수 있다. 상기 클라이언트 노드 는 상기 확인에 기초하여 상기 매니징 노드를 확인하고 상기 매니징 노드로부터 상기 리스트를 요청한다."}
{"patent_id": "10-2021-7017341", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "관련 출원들의 크로스-레퍼런스 본 출원은 2018. 11. 8에 출원된 미국의 임시 특허 출원(Provisional Patent Application) 제62/757,327호에 대한 우선권의 이익을 주장한다. 실시예들은 일반적으로 비중앙집중식 클라우드 컴퓨팅 마켓플레이스와 관련된다. 자세하게는, 몇몇 실시예들은 비중앙집중 방식으로 컴퓨트 리소스들에 억세스하는 마켓플레이스로 구현될 수 있다."}
{"patent_id": "10-2021-7017341", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "몇몇 사용자들과 기업들의 컴퓨트 리소스들에 대한 수요는 변동할 수 있다. 예컨대, 넷플릭(NETFLIX)나 훌루 (HULU)와 같은 비디오 스트리밍 서비스는, 사용자들이 업무에 매달려 있지 않을, 오후 5시 이후에 컴퓨트 리소 스들을 더 많은 양으로 필요로 할지 모른다. 동일한 비디오 스트리밍 서비스는 사람들이 바빠서 비디오 스트리 밍 서비스를 이용할 수 없는 오후 5시 이전에는 그 수요가 줄어 있을지도 모른다. 그러한 수요 변동은, 비디오 스트리밍 서비스를 위해 그 리소스들을 소유하는 것은 현명한 것이 아닐 수도 있다는 점에서, 문제가 있을 수 있다. 오히려, 변동 수요에 기초해서 리소스들을 빌리는 것이 비디오 스트리밍 서비스를 위해 더 나을지 모른다. 또한, 데이터 센터 운영자들이나 데스크탑 또는 심지어 모바일폰 소유자들과 같은 컴퓨트 리소스 소유 자들은 이용해서 무료 보상 또는 수입을 발생시킬 수 있는 여분의 컴퓨트 리소스들을 통상 가지고 있다."}
{"patent_id": "10-2021-7017341", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "item": 1, "content": "도 1은 CPU/GPU 프로세싱 및 데이터 스토리지와 같은 컴퓨팅 리소스들에 대한 거래를 가능하게 하는 완전 비중 앙집중식 지능형 자율 마켓플레이스를 만들기 위한 아키텍처를 나타낸다. 게임이론적인 미시경제 이론들과 인공지능(AI)이 마켓플레이스에 대한 관리, 리소스 할당, 평판 관리 및 전체 퍼포먼스 최적화를 위해 이용된다. 몇몇 실시예들은 거래 참가자들에 대한 인증, 거래 회계 감사, 데이터 보안 및 전체 안전 보증을 위해 블록체인 또는 분산원장기술(DLT)을 포함한다. 클라이언트들은 클라이언트 노드들(102a-102n)로 표현될 수 있다. 클라이언트 노드들(102a-102n)은 티어 1 내지 티어 N 마이너(miner)들(122a-122n)로 표현될 수 있는 적절한(예컨대, 믿을 수 있고 저렴한 가격의) 분산 컴퓨 팅 리소스들(예컨대, 컴퓨테이셔널 프로세싱 및 스토리지)과의 매칭을 위해 네트웤에 연결할 수 있다. 즉, 클라 이언트 노드들(102a-102n)은 (후술하는) 비중앙집중식 자율 컴퓨테이셔널 마켓플레이스에서 공표될 주문을 넣기 위해 네트웤에 억세스할 수 있다. 클라이언트 노드들(102a-102n)의 수는 티어 1 내지 티어 N 마이너들(122a- 122n)의 수와 다를 수 있음이 이해될 것이다. 즉, 클라이언트 노드(102n)에 대한 그 'n'은 티어 N 마이너(122 n)의 그 'n' 및 'N'과 다른 숫자일 수 있다. 비중앙집중식 마켓플레이스는 아키텍처의 전체 기능을 유지하기 위해 어떠한 중앙집중식 구성도 필요하지 않다는 것을 의미할 수 있다. 예들 들어, 비중앙집중식 아키텍처는 중앙집중식 구성이 하나도 없다거나 또는 어 떠한 중앙집중식 구성도 아키텍처의 전체 기능 수행에 있어서 중요하지 않을 수 있음을 의미할 수 있다. (때때로 유틸리타리안이라 불리는) 컴퓨테이셔널 리소스 공급자들은 티어 1 내지 티어 N 컴퓨트 노드들(122a- 122n)로 나타낼 수 있다. 티어 1 내지 티어 N 컴퓨트 노드들(122a-122n)은 컴퓨팅 리소스들을 제공할 수 있다. 티어 1 내지 티어 N 컴퓨트 노드들은 자신들이 제공하는 리소스들의 양을 할당 및/또는 결정할 수 있다. 몇몇 실시예들에서, 티어 1 내지 티어 N 컴퓨트 노드들(122a-122n)은 인공지능(AI) 레이어가, 토큰 및/또는 가 격 인센티브와 사용양 및 다른 파라미터에 기초해서, 컴퓨팅 리소스 또는 양을 결정하도록 허용할 수 있다. 몇몇 실시예들에서, AI 레이어는 KwH(시간당 킬로 와트) 당 전기 요금을 입력하도록 티어 1 내지 N 컴퓨트 노드들(122a-122n)에 온라인 계산기를 제공할 수 있으며, 그리고 AI 레이어는 예상 전기 비용을 계산할 수 있다. AI 레이어는 통계적으로 클라이언트 노드들(102a-102n)이 사용할 수 없다고 인식하기 1/3 시간 전에 티어 1 내지 N 컴퓨트 노드들(122a-122n)은 사용할 수 있는 상태에 있어야 할 지 모른다고 추정한다. AI 레이어 는 통계적으로 티어 1 내지 N 컴퓨트 노드들(122a-122n)은 클라이언트 노드들(102a-102n)이 그들에 대해 활용 가능하지 않다고 인지하기 1/3 시간 전에 활용 가능해야할 필요가 있을 수 있다고 추정한다. 스토리지에 대해, AI 레이어는 마이너들에게 스토리지(예컨대, 하드 디스크) 구입 날짜를 입력하도록 요청 할 수 있으며, 그런 다음 AI 레이어는 스토리지에 대한 전형적인 소매 단가를 고려해서 GB당 비용을 분할 상환할 수 있다. 전기 비용은 스토리지 비용과 함께 옥션에서 입찰하는 동안 사용될지도 모르는 티어 1 내지 N컴퓨트 노드들(122a-122n)에 대한 실제 비용을 형성할 수 있다. 유사한 프로세스가 (예컨대, 그 프로세서의) 다 른 하드웨어 컴포넌트에 대해 가격 산정을 위해 진행될 수 있다. 이러한 리소드들은 P2P 비중앙집중식 마켓플레이스에서 공표될 수 있으며, 그 중 몇몇은 다른 종류의 리소 스들을 위해 그리고 내결함성(fault-tolerance) 목적을 위해 역동적으로 만들어질 수 있다. 클라이언트 노드들 (102a-102n)이 찾는 리소스들과 티어 1 내지 N 컴퓨트 노드들(122a-122n)이 제공하는 리소스들 사이에 매칭되는 것이 있을 때, 스마트 계약 거래가 블록체인 및/또는 DLT 기술을 이용해서 완결될 수 있다. 몇몇 실시예들에서, 그 계약 로직은 거래 완결을 자동화한다. 몇몇 서비스 티어들(예컨대, 서비스들의 N개 티어들)이 티어 1 내지 티어 N 컴퓨트 노드들(122a-122n)에 의해 제공될 수 있다. 마찬가지로, 클라이어언트 노드들(102a-102n)은 특정 서비스 티어들을 원할 수 있다. 티어들은 가동시간(uptime), 활용가능도(availability), 및/또는 신뢰도(trustability) 레벨에 따라 컴퓨팅 및 스토리지 퍼포먼스의 레벨을 명시할 수 있다. 예컨대, 티어 1은 하이 퍼포먼스 분산 컴퓨팅을 위한 것일 수 있다. 티어 2는 소기업, 중기업 및 소비자 등급의 컴퓨팅을 위한 것일 수 있다. 티어 3은 모바일기기 컴퓨팅 등등을 위한 것일 수 있다. 비록 3개의 티어들에 대 해 기술했지만, 3개 이상 또는 이하의 티어들이 제공될 수도 있기 때문에, 제공되는 티어들의 수는 제한이 없다. 마켓플레이스 생성을 가능하게 하는 기본 메커니즘은 피어-투-피어(P2P) 네트웤 프로토콜에 기초한다. 본 실시 예에서는, Kademila P2P DHT 프로토콜 및/또는 AI 레이어는 모든 피어 노드들의 검색, 메세징, 동기 화 및 리소스 할당을 다룰 수 있다. 또한, 평판 관리 시스템은 하이 퍼포먼스의 티어 1 컴퓨트 노드들 내지 티어 N 컴퓨트 노드들(122a-122n) (예컨대, 컴퓨팅 리소스 공급자들)에 대해 랭킹을 부여하고, 리소스 할당을 향상시키며, 아키텍처의 악성 (malicious and rogue) 노드들을 분리시킬 수 있다. 예컨대, 평판 관리 시스템은 머신러닝에 기초한 예측 분석(predictive analysis)을 수행하고 모든 티어 1 내지 N 컴퓨트 노드들(122a-122n)에 대해 (예컨대, 1이 최 악이고 5가 최상인 경우에 1에서 5까지의) 등급을 부여할 평판 관리 서비스를 또한 구축할 수 있다. 이 서비스 로부터 나온 결과들은 블록체인 레이어일 수 있는 수단을 통해서 모든 사용자들에 의해 억세스 가능하게 만드어 질 것이며, 이는 전술한 분산형 버전에 의해 담보되듯이 티어 1 내지 N 컴퓨트 노드들(122a-122n) 및 클라이언 트 노드들(102a-102n)에 대한 스토리지 또는 프로세싱과 관련한 어떠한 추가 조건도 필요로 하지 않도록 도와줄 것이다. 평판 관리 시스템은 하이 퍼포먼스를 내는 티어 1 컴퓨트 노드 내지 티어 N 컴퓨트 노드들(122a-122n)에게 재정적 인센티브 및/또는 더 많은 일거리를 통해 보상하기 위해 그 랭킹을 AI 레이에 제공할 수 있다. 즉, AI 레이어110)는 그 하이 퍼포먼스의 티어 1 컴퓨트 노드 내지 티어 N 컴퓨트 노드들(122a-122n)에게 특혜를 줄 수 있다. 그래서, 몇몇 실시예들은 고품질 저가의 컴퓨팅 파워 및 스토리지를 찾는 고객들에 대해 컴퓨팅 리소스를 상품 화하는 거래 기반의 마켓플레이스를 생성하기 위해, 블록체인 및/또는 DLT를 이용한 피어-투-피어 분산 네트웤 분산 컴퓨팅 리소스(컴퓨팅 파워 및 스토리지)의 할당, 인증, 관리, 및 검색 방법과 아키텍처에 관련된다. 예를 들어, 리소스들 중 적어도 두 개는 P2P 비중앙집중식 컴퓨터 프로세싱 및 P2P 비중앙집중식 스토리지 을 포함한다. AI 레이어는 자율 비중앙집중식 지능형 클라우드 컴퓨팅 플랫폼을 형성하기 위해 상기 오퍼레이션들 중 적 어도 몇몇을 관리하고 향상시킬 수 있다. 도시된 것처럼, API들은 유저 인터페이스와 블록체인 사이의 호출을 가능하게 할 수 있다. 블록체인은 거래, 랭킹, 서비스 요청, 리소스 제공, 평판 스코어 등 등의 원장 또는 기록으로서의 역할을 할 수 있다. 티어 1 컴퓨트 노드 내지 티어 N 컴퓨트 노드들(122a-122n)에 걸쳐 완전 비중앙집중식 클라우드 컴퓨팅 및 스토 리지에 대한 AI 주도의 마켓플레이스를 구축하는 것에 대한 여러 측면들이 아래에서 더 자세히 제공된다. 대조 적으로, 몇몇 다른 시스템들은 시스템 전체 기능에 있어 꼭 필요하고 중대하여 매우 중요한 중앙집중식 컴포넌 트를 가질 수 있다. 본 출원의 실시예들은 스토리지 및 컴퓨트 리소스 거래를 위한 융통성 있고 안전한 마켓플 레이스를 포함하는 완전 개방적이고, 비중앙집중식이며, 무한 확장 가능한 클라우드 컴퓨팅 솔루션을 구축할 분 산 컴퓨팅 및 스토리지에 관련될 수 있다. 블록체인, DLT 및 암호화폐 기술의 출현이 인터넷 스케일 솔루션들을 가능하게 했을지 모른다. 진정한 비중앙집 중식 인터넷 스케일 클라우드 컴퓨팅 및 스토리지 솔루션들을 확장 리소스들로 구축하는데 블록체인, DLT 및/또 는 P2P 네트웤이 활용될 수 있다. 몇몇 실시예들에서, 컨테이너(예컨대, 라이브러리들과 다른 종속 항목들을 포 함할 필요가 있을 수 있다 모든 그 파트들을 갖는 애플리케이션, 도커 컨테이너, 등등)로 캡슐화될 수 있는 어 떠한 작업도 제출될 수 있으며, 클라이언트 노드들(102a-102n)은 그 작업의 실행 기간에 대해 지불하기만 하면 될 수도 있다. 그래서, 유저들은 거의 제한 없는 매우 높게 활용 가능한 컴퓨트 용량에 절감된 비용과 고효율로 억세스할 수 있을지도 모른다. 도 1에 도시된 것처럼, 아키텍처는 클라이언트 노드(102a-102n)에 대한 클라이언트 인터페이스를 포 함한다. 클라이언트 인터페이스 및/또는 클라이언트 노드(102a-102n)는 다양한 플랫폼(예컨대, 윈도우, 맥 OS 및 리눅스)으로 될 수 있다. 클라이언트 인터페이스는 클라이언트 노드(102a-102n) 상에서 작동되거나, 또는 클라이언트 노드(102a-102n)로부터 떨어져 있을 수 있다. 클라이언트 인터페이스 및 클라이언트 노드 (102a-102n)는 지능형 P2P 비중앙집중식 마켓플레이스를 통해 분산 컴퓨팅 및 스토리지 리소스 네트웤 인 프라스트럭처에 연결되어 있을 수 있다. \"Alexandria Protocol\"로 불리는, 인공지능 레이어는 몇몇 실시예들에 있어서, 분산 컴퓨트 리소스 할당 및 성능 최적화를 가능하게 할 수도 있다. 인공지능 레이어는 P2P 비중앙집중식 마켓플레이스에서의 상호작용들로부터 지속적으로 학습하며, P2P 비중앙집중식 마켓플레이스에의 참가자들을 위한 전략을 최적 화 한다. 예컨대, 인공지능 레이어는 다음을 실행할 수도 있다: 1. P2P 비중앙집중식 컴퓨터 프로세싱과 P2P 비중앙집중식 스토리지의 분산 P2P 리소스 할당 및 퍼포 먼스를 계획하고 최적화 하는 일; 2. 클라이언트 노드들(102a-102n)(예컨대, 유틸리타리안들), 티어 1 내지 N 마이너들(122a-122n)(예컨대, 클라 이언트들) 및/또는 (후술하는) 매니징 노드들과 같은 시스템 노드들에 대해서 평판을 축적하는 일; 3. 클라이언트 노드(102a-102n)의 가동 시간 및 활용가능도를 예측하는 일; 4. 태스크 특성에 따라 티어 1 내지 티어 N 마이너(122a-122n)에 대한 대략적인 태스크 완료 시간을 예측하는 일; 5. 잠재 이익뿐만 아니라 국소적인 리소스 활용도 최대화하기 위해 클라이언트 노드(102a-102n)에 대한 최상의 가격 전략을 추천하는 일. 아키텍처는 더 많은 태스크와 참가자로 그 크기가 조정되기 때문에, 인공지능 레이어의 머신 및/또는 딥 러닝 모델은 추가 데이터들로부터 학습할 수 있으며, 참가자 관점에서 점점 더 효율성 있고 유용하게 될 수 있다. 몇몇 실시예에서, 인공지능 레이어는 아키텍처에 대한 위협을 평가하는 위협 매니저를 포함할 수도 있다. 몇몇 실시예에서, 위협 매니저는 그러한 리스크들을 완화시키기 위해 인공지능 레이어의 그 거동 및/또는 파라미터를 수정할 수도 있다. 예를 들면, 몇몇 실시예에서, 위협 매니저는 그러한 리스 크들을 완화시키기 위해, 예컨대, 아키텍처에 잠재적 리스크를 가하는 것으로 확인된 컴퓨트 노드들(122a- 122n) 중 몇몇을 제외시키는 것처럼, 인공지능 레이어의 그 거동 및/또는 파라미터를 수정할 수 있다. 몇몇 실시예에서, 인공지능 레이어는 컨센서스 메카니즘(consensus mechanism)을 구현할 수 있다. 그 명칭 이 의미하듯이, 컨센서스 메커니즘은 컴퓨트 태스크를 티어 1 내지 n 컴퓨트 노드(122a-122n) 중 복수의(예컨대, 3 또는 다른 홀수의) 컴퓨트 노드에 분배한 다음, 대다수의 티어 1 내지 n 컴퓨트 노드(122a- 122n)에 의해 제공되는 결과를 선택하는 것을 수반한다. 선택된 결과와 매칭되지 않는 결과를 갖는 티어 1 내지 n 컴퓨트 노드(122a-122n)는 어떠한 보상도 받지 못하며, 또한 평판 스코어에 대해 벌점을 받는다. 몇몇 실시예들은 비중앙집중식 분산 컴퓨팅 및 저장 마켓플레이스를 구축하는 것과 관련된다. 상기 아키텍처 에 있어서, 분산 컴퓨팅 리소스(스토리지 및 컴퓨팅)에 대한 P2P 비중앙집중식 블록체인 (및/또는 DLT)과 P2P 비중앙집중식 마켓플레이스, 티어 1 내지 N 컴퓨트 노드(122a-122n), 클라이언트 노드(102a- 102n), 및 AI 레이어와 같은 면들은 도 2의 아키텍처에서 더 자세히 보여진다. 상기 아키텍처는 중첩 구성들이 서로 그 안에 포함됨으로써 상기 아키텍처의 일부로서 쉽게 구현될 수 있다. 상기 아키텍처은 1) 비중앙집중식 애플리케이션(Dapps)과 웹-클라이언트 인터페이스 레이어; 2) 블록 체인 및/또는 DLT 레이어 (예컨대, 이더리움, IOTA, 코다, EOS, 하이퍼레저 등등의 레이어), 그리고 3)P2P 네트웤 레이어를 포함한 적어도 3개의 레이어로 형성될 수 있다. 기저에 있는 P2P 네트웤 레이어는 어떠한 새로운 노드들도 거기서 P2P 네트웤에 합류해 다른 피어 (peer)들에 끼워져 그들과 동기화될 수 있는 네트웤 프로토콜을 포함할 수 있다. 새로운 노드들이 추가되면, 컴 퓨팅 리소스 공급자들(새로운 노드들의 컴퓨트 노드들)은 바로 그 컴퓨트 노드들의 컴퓨팅 리소스들이 마켓플레 이스에서 활용가능하게 되는 방식과 그 서비스에 대해 그들이 선택한 보상들을 설정할 수 있다. 그 서비스들은 또한 블록체인 및/또는 DLT에 추가되고, 서비스들의 다른 티어 1 내지 N(204a-204n)으로 분류되며, 상기 노드들(206a-206n, 208a-208n, 210a-210n)의 컴퓨트 노드들은 자동 등록해서 암호화된 해시 포인터들을 이용해 리소스들의 활용가능도를 공표할 수 있다. 서비스들의 각 티어 1 내지 N(204a-204n)은, 클라이언트 및 컴퓨팅 노드 공급자들이 상호 작용해 비중앙집중 방 식으로 컴퓨팅 리소스들을 상품화할 수 있는 특정 파라미터 범위 내에서 유일한 세트의 컴퓨팅 리소스들(예컨대, 특정 한계치들 사이의 컴퓨팅 파워 및 스토리지)을 공표한다. 서비스 매칭이 확인되면, 그리 고 스마트 계약 또는 어떠한 것이든 스마트 코드 로직 거래가 블로체인 및/또는 DLT 레이어에서 발생하면, 그 서비스에 대한 지불을 위해 바로 토큰들이 컴퓨트 및 클라이언트 노드들 사이에서 교환될 수 있다. 예를 들어, 티어 1 (204a)은 기업 레벨의 프로세싱 파워 및 스토리지에 해당할 수 있다. 노드(210a)는 티어 1(204a) 카테고리에서 서비스들을 제공하는 컴퓨트 노드일 수 있다. 즉, 상기 노드(210a)는 기업 레벨의 프로세 싱 파워 및 스토리지를 제공할 수 있다. 상기 노드(210a)는 티어 1(204a)에서 상기 노드(210a)에 대한 프로세싱 파워 및 스토리지의 정확한 레벨, 가격 조건들, 서비스 협의 사항들, 시간 제한들 (예컨대, 2시간 이하 내에서 또는 오전 2시에서 오전 6시 사이에서 실행할 수 있는 작업이어야 한다는) 등등을 공표할 수도 있다. 상기 노드 (210n)은 클라이언트 노드일 수 있다. 상기 노드(210n)은 티어 1(204a)에 서비스 레벨들을 요구할 수 있으며, 그래서 티어 1(204a)에서의 모든 공표된 노드 정보 리스트를 받을 수 있다. 상기 노드(210n)는 상기 노드(210 a)의 상기 공표 내용이 수용할 수 있다고 결정해, 상기 노드(210a)를 선택할 수 있다. 상기 노드(210n)은 하이- 레이턴시 통신 가능성을 완화시키기 위해 상기 노드(210a)를 선택하기 전에 레이턴시(latency) 테스트들을 실행 할 수 있다. 그런 다음, 상기 노드(210n)는 상기 노드(210a)의 워크로드를 오프로드할 수 있다. 상기 노드 (210a)가 워크로드를 완료한 후에, 상기 노드(210n)은 그 워크로드가 만족스럽게 실행되었음을 검증하고, 만족 스러운 실행이었다면 상기 노드(210a)에 토큰을 제공할 수 있다. 몇몇 실시예들에서, 상기 노드(210n)은 특정 지역의 컴퓨트 노드들 및/또는 특정 레이턴시 특성들을 가지는 컴 퓨트 노드들을 선택할 옵션을 가질 수 있다. 지역에 특화된 복수의 P2P 네트웤들이 지원된다. 예를 들어, 미국 서부, 미국 동부, 유럽 서부, 유럽 동부, 인도, 동남아시아 등등에 대한 P2P 네트웤. 이는 지정학적으로 가까운 컴퓨트 노드들에 대한 선택을 단순화시킬 뿐만 아니라, 유럽연합의 개인정보 보호규정(GDPR)과 같은 지역 특유 의 데이터 취급 요건들을 충족시키는 것도 가능하게 한다. 서비스 티어들(204a-204n)은 다음과 같이 결정될 수 있다. 예컨대, 네트웤의 유틸리타리안들은 대부분 랩탑과 데스크탑 장비들을 가진 홈 유저들일 수 있다. 몇몇 예들에서, 이러한 유틸리타리안들은 티어 2 (204b) 유틸리 타리안들로 정의될 수 있다. 기업 등급의 하드웨어, 소프트웨어 제공자들과 데이터 센터 운영자들은 또한 컴퓨 트 파워 및 스토리지를 판매하기 위해 아키텍처에 합류할 수 있다. 기업 유틸리타리안들은 티어 1 (204a) 유틸리타리안들로 정의될 수 있다. 끝으로, 상기 티어 N(204n) 유틸리타리안들은 모바일 및 사물인터넷(IoT) 장 비들의 카테고리와 관련되는 것으로 정의될 수 있는데, 이들은 낮은 컴퓨팅 및 저장 용량을 가지지만 이러한 리 소스들을 상기 아키텍처의 피어-투-피어 네트웤에 여전히 제공할 수 있다. 상기 티어 2(204b) 레벨은 아래에 보이는 것처럼 다른 레인지의 컴퓨팅 파워를 나타내는 몇 개의 서브-카테코리 들로 더 나뉘어질 수 있다. 예를 들어, T2.small은 어떠한 것이건 2개까지의 CPU와 2GB와 4GB 사이의 RAM과 2 GHz까지의 CPU 속도를 가지는 장비를 나타낼 수 있다. 상기 계층화(tiering) 및 서브-카테고리화(sub- categorization) 전략은 향후 티어-1 공급자들의 추가를 고려한다. 이 서비스 티어 1 및 2 (204a, 204b)가 아 래 테이블 I에 리스트되어 있다. 몇몇 실시예들에서, 테이블 I은 티어 N (204n) 서비스 공급자들을 포함할 수 있다. 표 1 티어 레벨 OS CPU의 최대 수최대 메모리 (RAM in GB)최대 스피드 (GHz)이름 2 WINDOWS/LINUX 2 2 2 T2.nano 2 WINDOWS/LINUX 2 4 2 T2.small2 WINDOWS/LINUX 2 8 2 T2.medium 2 WINDOWS/LINUX 2 16 2 T2.large 2 WINDOWS/LINUX 2 32 2 T2.xlarge 2 WINDOWS/LINUX 2 2 4 T2.nano.fast 2 WINDOWS/LINUX 2 4 4 T2.small.fast 2 WINDOWS/LINUX 2 8 4 T2.medium.fast 2 WINDOWS/LINUX 2 16 4 T2.large.fast 2 WINDOWS/LINUX 2 32 4 T2.xlarge.fast 1 WINDOWS/LINUXMore than 2 T1.default 테이블 I - 유틸리타리안 컴퓨팅 리소스들에 기초한 서비스 티어들 카테고리화 에이전트 (예컨대, 소프트웨어 에이전트, 애플리케이션, 및/또는 다른 소프트웨어)는 그 컴퓨트 노드에 대한 CPU 개수와 RAM을 결정할 수 있으며, 자동적으로 그 컴퓨트 노드의 리소스들이 속하는 티어를 결정한다. 그 다 음 상기 에이전트는 또한 그 티어에 대한 매니징 노드를 찾고, 그 컴퓨트 리소스들을 판매하기 위해 상기 매니 징 노드와 함께 그 컴퓨트 노드를 리스트화할 수 있다. 상기 컴퓨트 노드의 유저들은 그 컴퓨트 리소스들이 다 른이들에 의해 사용되어서는 안되는 시간 기간을 리스트화 할 옵션을 갖는다(또는 그 컴퓨트 노드들은 자동적으 로 그 옵션을 가질 수 있다). 또한, 상기 컴퓨트 노드는 그들의 컴퓨터 리소스들을 공유하는 1 시간(또는 다른 시간 길이) 당 가격(예컨대, USD)을 제공할 수 있다. 상기 클라이언트 노드들은 유틸리타리안 리소스들의 사용 에 대하여 N 분(예컨대 15분) 간격으로 변경될 수 있다. 컴퓨트 노드가 컴퓨트 서비스들을 제공하는 것으로 마 켓플레이스에 리스트되고 나면, 하나의 유틸리타리안으로 불릴 수 있다. 도 3은 P2P 네트웤에서 P2P 티어들을 포함하는 비중앙집중식 컴퓨팅 아키텍처를 나타낸다. 상기 P2P 비중앙집중식 블록체인(및/또는 DLT) 마켓플레이스, 티어 1 내지 티어 N 컴퓨트 노드들(122a-122n), 클라 이언트 노드들(102n-102n), 그리고 분산 컴퓨팅 리소스들(스토리지 및 컴퓨테이션)를 위한 AI 레이어, 노 드들(206a-206n, 208a-208n, 210a-210n), 블록체인, 비중앙집중식 컴퓨팅 리소스들 마켓플레이스 및 비중 앙집중식 애플리케이션 및 웹 클라이언트 인터페이스 레이어와 같은, 상기 아키텍처 (도 1) 및 상기 아키텍처 (도 2)의 면들은 도 3의 상기 아키텍처에서 더 자세히 나타나 있다. 상기 아키텍처은 중첩 구성들이 서로 그 안에 포함됨으로써 상기 아키텍처 (도 1) 및 아키텍처 (도 2)의 일부로서 쉽 게 구현될 수 있다. 상기 P2P 네트웤에서, 컴퓨터 리소스들과 관련된 거래들에 대한 관리를 위해 컴퓨팅 리소스들은 블록체인 및/또는 DLT(예컨대, 이더리움, IOTA, 코다, EOS, 하이퍼레저 등등)를 사용해서 공유될 수 있다. P2P 티어들은 여기서 기술되는 것처럼 컴퓨테이션 리소스 마켓에 기초해 결정될 수 있다. 몇몇 실시예들에서, 상기 P2P 네트웤의 구성요소들은 다음을 포함한다: 1. 클라이언트들: 그들의 태스크들을 실행하기 위한 컴퓨트 리소스들을 찾고 그 리소스들에 대한 대가를 기꺼이 지불하고자 하는 클라이언트 노드들(312, 316) 2. 유틸리타리안: 보상을 받고 여분의 컴퓨테이션 리소스들 및 저장 리소스들을 판매하고 자하는 컴퓨트 노드들 (308a, 308b, 310a-310c); 및 3. 마켓플레이스 소유자들 또는 거래소들: 클라이언트들에 의한 유틸리타리안들의 검색을 가능하게 하는 역동적 으로 선택된 매니징 노드들(304, 306). 상기 네트웤에는 유틸리타리안들이 판매하고 검증 및 시행 계획에 유리 하게 참가할 컴퓨트 및 저장 리소스들의 그 레인지에 따라 복수의 마켓플레이스 소유자들이 있을 수 있다. 상기 노드들(304, 306, 308a, 308b, 310a-310c, 312)은 하나 이상의 모드를 가질 수 있음을 주목할 필요가 있 다. 예컨대, 상기 노드들(304, 306, 308a, 308b, 310a-310c, 312) 중 어떤 노드도 듀얼 모드를 가질 수 있으며, 듀얼 모드에서 그 노드는 클라이언트, 유틸리타리안 P2P 노드(예컨대, 리소스 공급자) 및 마켓플레이스 소유자 중 둘 또는 그 이상으로서 기능할 수 있다. 도 3에 보이는 것처럼, 서비스 티어에 대한 특정 예시를 위해, 컴퓨트 리소스들에 대해 그리고 매니징 노드 (예컨대, T2nano) 및 매니징 노드 (예컨대, T2large)를 통해 확인되는 두 개의 마켓플레이스가 있을 수 있다. 컴퓨트 리소스들을 판매하는 상기 컴퓨트 노드들(310a-310c, 308a, 308b)은 상기 적절한 매니징 노드 (304, 306)를 통해 그 두 마켓플레이스들 중 하나에 자신들을 리스트할 수 있다. 예컨대, 상기 컴퓨트 노드들(310a-310c, 308a, 308b)은 그 매니징 노드들(304, 306)을 통해 그들 리소스의 활용가능성을 알릴 수 있다. 유사하게, 컴퓨트 리소스 룩업을 찾는 상기 클라이언트 노드들(312, 316)은 원하는 서비스 레벨에 대한 상기 매 니징 노드들(306, 304)의 적절한 마켓플레이스 소유자를 확인하고 그 서비스를 제공할 수 있는 그 매니징 노드 들(304, 306)로부터 유틸리타리안 리스트를 얻는다. 예컨대, 특정 티어(예컨대, 티어 2) 내에서 컴퓨테이셔널 리소스들의 세 서브-카테고리들이 있을 수 있다: 1) nano, 2) medium, 및 3) large. \"nano\"는 유틸리타리안이 마켓플레이스에 제공할 수 있는 작은 리소스(예컨대, 컴퓨터 스토리지 및 프로세싱)를 의미할 수 있으며, \"medium\"은 유틸리타리안이 제공할 수 있는 중간 리소스(예 컨대, 컴퓨터 스토리지 및 프로세싱)를 의미할 수 있고, \"large\"는 유틸리타리안이 제공할 수 있는 큰 리소스들 (예컨대, 컴퓨터 스토리지 및 프로세싱)을 의미할 수 있다. 상기 노드들(304, 306, 308a, 308b, 310a-310c, 312)은 퍼블릭 블록체인 및/또는 DLT 어드레스들을 가질 수 있 다. 상기 노드들(304, 306, 308a, 308b, 310a-310c, 312)은 그들이 상기 P2P 네트웤로부터 만들어낼 수 있는 가치를 최대화하기 위해 참가하는 합리적인 실체들로 여겨질 수 있다. 몇몇 실시예들에서, 게임 이론 원리 들이 적용될 수 있다. 다른 한편, 상기 네트웤에 악성 노드들이 몇몇 있을 수 있으며, 그들이 네트웤 오퍼레이 션들에 주는 영향을 최소화하기 위한 바람직한 방법에 관한 논의가 아래에서 제시된다. 몇몇 실시예들에서, 제어기(control plane)는 위협 모델 시나리오들 및 솔루션들을 확인하기 위해, 상기 위협 매니저와 유사할 수 있는, 하나의 위협 매니저를 포함할 수 있다. 즉, 몇몇 실시예들은 어떠한 중대한 중앙집중식 지배 없이 완전하거나 또는 실질적으로 비중앙집중식인 시스템을 포함할 수 있기에, 다른 참 가자들이 이기적인 이득을 위해 상기 아키텍터을 다루려고 시도할지도 모르는 여러 시나리오들이 있을 수 있다. 상기 위협 매니저는 그러한 주요 시나리오들을 확인하고 전체 시스템이 계속해서 높은 퍼포먼스와 충실도로 기능하는 것을 보장하기 위해 기술적인 솔루션들을 실행할 수 있다. 예를 들어, 이클립스 공격(Eclipse attack)에서, 상대방은 개별 노드의 P2P 네트웤 참가를 방해할 수 있다. 그 러한 공격은, 예컨대, 50% 이상의 네트웤 노드들이 상대방에 의해 지배되면, 가능할 수 있다. 바람직한 실시예 에 의하면, 다음과 같이, 블록체인 (예컨대, 이더리움) 퍼블릭 어드레스와 함께 IP 어드레스를 추가하는 것이 노드들에 대한 그 P2P 네트웤 id를 생성하는데 이용될 수 있다: Kad P2P 네트웤 emlia id = hash (이더리움 퍼블릭 어드레스, IP 어드레스, 지역 코드) 그 결과, 이클립스 공격과 관련된 리스크는 전술한 것처럼 ID들을 할당함으로서 완화될 수 있다. 시빌 공격(Sybil attack)은, 상대방이 P2P 네트웤의 기능 및 전체 평판을 떨어뜨리기 위해 그 P2P 네트웤 에서 대부분의 노드들(304, 306, 308a, 308b, 310a-310c, 312, 316)을 제어할 수 있게 되는 이클립스 공 격의 확장판일 수 있다. 사실, 이 공격은 이클립스 공격이 성공하는데 대한 전제조건이다. 아키텍처에서의 시빌 공격의 출현 징후 중 하나는 공격자가 상기 마켓플레이스 및 컴퓨트 노드들(310a- 310c, 308a, 308b) (예컨대, 유틸리타리안들)을 제어하고 클라이언트 컴퓨테이션들을 제어해서, 어떠한 실제 작 업도 수행하지 않고 상기 컴퓨트 노드들(310a-310c, 308a, 308b) 작업에 대해 대가를 지불 받는 것이다. 그들을 위한 그 작업 수행에 대해 상기 컴퓨트 노드들(310a-310c, 308a, 308b) 중 단일 컴퓨트 노드 또는 한 세트의 컴 퓨트 노드들(310a-310c, 308a, 308b)에 의존하는 상기 클라이언트 노드들(312, 316) 중 하나의 클라이언트 노드 는 그 받은 결과가 맞는지 허위인지 알 수 있는 방법이 없을 것이다. 이클립스 공격에 대한 전술한 기술적 솔루션 및 완화 전략은 유용할 수 있다. 또한 상기 P2P 네트웤에서 상기 매니징, 컴퓨트 및 클라이언트 노드들(304, 306, 308a, 308b, 310a-310c, 312, 316)이 시빌 공격의 영향 을 최소화할 수 있도록 도와줄 몇 가지 다른 기술들이 있다. 이러한 기술들은 평판 관리 및 컴퓨테이션 결과들 을 크로스-체킹하는 것을 다룬다. 그래서, 몇몇 실시예들은 시빌 공격들로부터 보호하기 위해 관리 내역들을 관 리하고 컴퓨테이션 결과들을 크로스-체킹 할 수 있다. 몇몇 공격들에서, 탐욕스런 유틸리타리안들이 태스크들에 대해 저가 입찰서를 제출하고, 이후에 클라이언트 노 드들(312, 316)에 대해 열악한 퀄리티로 서비스를 제공하는 것이 가능할 수 있다. 클라이언트 노드들(312, 31 6)은 그 탐욕스런 유틸리타리안들이 그 태스크들에 관해 낮은 퀄리티 또는 맞지 않는 컴퓨테이션을 제공했다는 것을 즉시 알지 못할 수도 있다. 태스크를 실제 완료하지 않으면서 태스크에 대해 보상 받고자 하는 탐욕스런 유틸리타리안들이 존재하는 것으로서, 작은 규모이기는 하지만, 이는 시빌 공격의 한 유형일 수 있다. 시빌 공 격을 처리하는 것으로 제안된 기술들은 또한 이러한 탐욕스런 유틸리타리안들이 옥션에서 낙찰되지 못하도록 하는 것과 탐욕스런 유틸리타리안들이 그 필요 컴퓨테이션을 수행하지 않고 나온 결과를 또한 감지하는 것으로부 터 둘 다에 유용할 것이다. 몇몇 실시예들에서, 악성 마켓플레이스 소유자들(예컨대, 매니징 노드들)은 존재할 수 있다. 이 공격 시나리오 에서, 상기 P2P 네트웤에 악성 마켓플레이스 소유자들을 갖는 것이 미치는 영향이 논의된다. 이 시나리오에서, 가능한 공격 유형은 a) 악성 컴퓨트 노드들(예컨대, 유틸리타리안들)과 공모하고 정상 노드들이 옥션 프로세스 에 참가하는 것을 억제하는 것; 그리고 b) 전체 시스템 유틸리티를 약화시킬 노력으로 클라이언트 노드들(312, 316)과 정보를 공유 및/또는 저장하는 것을 포함한다. 다음 문제들이 그 솔수션의 일부로서 후술하는 방식으로 해결될 수 있으며, 위협 매니저를 통해 시행 및/또는 전파될 수 있다: 1) (여기 기술된 바와 같이) 상기 컴퓨터 노드들(308a, 308b, 310a-310c)에 대한 평판을 축적하는 방식과 유사 하게 상기 마켓플레이스 소유자들에 대한 평판을 축적하는 것; 2) 서비스의 특정 티어에 대해 상기 마켓플레이스 소유자들을 각각 순회시키는 것. 후술하게 되는 바와 같이, 상기 아키텍처은, 그 입력값들에 대한 티어 1의 해시(hash)를 계산하기 위해, 그 년도의 위크 넘버(week number of the year)를 이용한다. 그래서, 매주 상기 컴퓨트 노드들(308a, 308b, 310a-310c)은, 심지어 동일 티어에 대해, 상기 P2P 네트웤으로부터 선택될 수 있는 새로운 매니징 노드와 함께 자신들의 리스트를 다 시 생성한다. 상기 클라이언트 노드들(312, 316)은 또한 룩업 수행을 위해 사용하는 해시를 계속 업데이트하기 때문에, 그 새로운 매니징 노드들을 찾아내는 것이 가능할 수 있다. 몇몇 실시예들에서, 그 인스턴트 아키텍처 에서 항상 협정세계시(UTC)에 입각할 수 있음을 주목할 필요가 있다. 그 때문에, P2P 네트웤의 클럭 들을 글로벌하게 동기화시킬 필요가 없을 수 있다. 만약 상기 클라이언트 노드들(312, 316) 중 한 클라이언트 노드가 한 티어에 대해 상기 매니징 노드들(304, 306)로부터 하나의 매니징 노드에 대한 룩업을 수행하고, 어떠 한 컴퓨트 노드 정보도 받지 못한다면, 상기 아키텍처는 자동적으로 그 위크 넘버를 1 더 올려 새로운 매 니징 노드에 대해 다시 시도할 수 있다. 즉, 네트웤의 높은 신뢰도를 보장하기 위해, 몇몇 실시예들은 액티브- 액티브 모드나 또는 액티브-패시브 모드에서 마켓플레이스의 공동 소유자들로서 작용하는 복수의 네트웤 노드들 을 가지는 것을 지원할 수 있다. 마켓플레이스 소유자들서 역할 하기로 동의한 노드들은 Chord 또는 Kademlia 같은 프로토콜을 이용해 피어-투-피어 네트웤을 형성하며, 한 컴퓨트 리소스 값의 그 정확한 마켓플레이스 소유 자는 해시를 생성하고 그 해시 값에 대한 룩업을 수행함으로써 결정된다. 3) 매 티어 당 여용의(redundent) 마켓플레이스 소유자들(매니징 노드들)이 있을 수 있다. 그 여용의 매니징 노 드들은 그 지정된 매니징 노드의 바로 후속한 이웃들(immediate successor neighbors of the designated managing node)일 수 있다. 그래서, 예컨대, 상기 매니징 노드가 '티어-1'에 대한 마켓플레이스 소유자라 고 하면, 상기 컴퓨트 노드들(310a-310c)은 또한 그 바로 후속한 '노드 2'에서 그들을 리스트 할 수 있다. 상기 클라이언트 노드은, 매니징 노드로부터 컴퓨트 노드들(310a-310c) 리스트를 확보할 때, '노드 2'를 또한 컨택해서 컴퓨트 노드들(310a-310c)의 그 리스트를 얻을 수 있다. 만약, 상기 컴퓨트 노드들(310a-310c)을 컨택한 후에도 두 세트의 데이터가 매우 다르다면, 상기 클라이언트 노드는 매니징 노드에 대한 지불 을 생략하고, 또한 상기 매니징 노드에 대한 낮은 평판을 공표할 수 있다. 몇몇 실시예들에서, 프리-로딩 클라이언트는 상기 아키텍처를 첨부할 수 있다. 즉, 상기 클라이언트 노드 들(312, 316)은 또한, 그들을 위한 태스크가 컴퓨트 노드들(308a, 308b, 310a-310c)에 의해 실행되게 하지만, 상기 컴퓨트 노드들(308a, 308b, 310a-310c)과 매니징 노드들(304, 306)에 대한 지불을 마킹(marking)하지 않 음으로써, 상기 P2P 네트웤에서 리소스들을 남용할지도 모르는 일이 있을 수 있다. 이는 블록체인 및/또는 DLT 를 에스크로(escrow)로 이용하고 스마트 계약을 통해 거래시킴으로써 해결된다. 몇몇 실시예들에서, 결과 검증 기술 중 하나가 채용되어 컴퓨트 노드들이 클라이언트 노드들에게 쓰레기 결과들 을 되돌려 주지 않도록 확실히 할 것이다(예컨대, 트로이목마 악성코드의 주입). 이를 완화시키기 위해, 몇몇 실시예들은 미리 알고 있는 아웃풋 값과 검증 가능한 값을 가진 클라이언트 컴퓨테이션에 단계 하나를 자동 삽 입하는 것을 포함할 수 있다. 태스크가 완료되면, 그 컴퓨트 노드들로부터 나온 아웃풋 결과들에는 그 아웃풋 결과들에 포함된 미리 알고 있는 그 값이 포함되어 있을 것이다. 웹 호스팅과 관련된 도커 태스크들은 또한 그 컴퓨트 노드가 호스팅할 것으로 예상되는 웹 사이트(또는 웹 서비스)를 확실히 호스팅하도록 하기 위해 지속적 으로 대조되어 체크될 수 있는 \"healthcheck URL\"을 수용할 수 있다. 만약, 미리 알고 있는 그 값이 포함되어 있지 않다면, 상기 아키텍처는 컴퓨트 노드가 그 클라이언트 노드의 요구 사양에 따라 태스크를 프로세싱 하지 않았으며 따라서 대가가 지불되서는 안된다고 결정할 수 있다. 도 4는 노드 결합 오퍼레이션을 실행하는 방법을 나타낸다. 상기 방법은 일반적으로 컴퓨팅 장비에 의해 시행될 수 있으며, 예컨대 앞서 논의된 상기 아키텍처(도 1), 상기 아키텍처(도 2) 및 상기 아 키텍처(도 3)와 같이, 여기 기술된 실시예들 중 하나와 함께 오퍼레이팅될 수 있다. 하나의 실시예에서, 상기 방법은 랜덤 억세스 메모리(RAM), 리드-온리-메모리(ROM), 프로그래머블 ROM(PROM), 펌웨어, 플래쉬 메모리, 등등과 같이 기계 또는 컴퓨터로 판독 가능한 스토리지 매체에 저장된 한 세트의 논리명령들로서 하나 또는 그 이상의 모듈로, 예컨대, 프로그래머블 로직 어레이(PLAs), 필드 프로그래머블 게이트 어레이(FPGAs), 콤플렉스 프로그래머블 로직 디바이스(CPLDs)와 같은 컨피규러블 로직(configurable logic)으로, 예컨대, 에이 식(ASIC; application specific integrated circuit), 시모스(CMOS; complementary metal oxide semiconductor) 또는 트랜지스터-트랜지스터 로직(TTL) 기술과 같은 회로 기술을 이용한 고정-기능 로직 하드웨 어로, 또는 그들의 어느 한 조합으로 구현된다. 예컨대, 그 방법에서 보여지는 오퍼레이션들을 수행할 컴퓨터 프로그램 코드는, JAVA, SMALLTALK, C++ 또 는 그 유사 언어와 같은 객체 지향 프로그래밍 언어(object oriented programming language)와 \"C\" 프로그래밍 언어 또는 유사 프로그래밍 언어와 같은 전통적인 절차적 프로그래밍 언어(conventional procedural programming language)를 포함해서, 하나 또는 그 이상의 프로그래밍 언어의 조합으로 작성될 수 있다. 또한, 논리명령들은 어셈블러 명령들, 명령어 집합 구조(ISA; instruction set architecture) 명령들, 기계 명령들 (machine instructions), 기계 종속 명령들(machine dependent instructions), 마이크로코드(microcode), 상태 설정 데이터(state setting data), 집적 회로에 대한 환경 설정 데이터(configuration data), 하드웨어(예컨대, 호스트 프로세서, 중앙 처리 장치/CPU, 마이크로콘트롤러, 등등)에 고유한 전기 회로 및/또는 다른 구조의 구성품들을 개인 맞춤화 하는 상태 정보들을 포함할 수 있다. 도시된 프로세싱 블록은 컴퓨트 노드를 네트웤(예컨대, P2P 네트웤)에 연결시킨다. 프로세싱 블록은 다음과 같이 생성되는 P2P 네트웤 아이디(ID) 생성 단계를 포함할 수 있다: P2P 네트웤 id = hash (블록체인 및 /또는 DLP 퍼블릭 어드레스, IP 어드레스, 지역 코드). 몇몇 실시예들에서, 프로세싱 블록은 새로운 노드 들을 도와 네트웤에 연결시키는 공개 노드들 리스트를 결정할 수 있다. 그와는 달리 또는 그와 함께, 이미 상기 P2P 네트웤의 일부인 검증된 노드들의 무작위한 리스트를 내놓는 블록체인으로부터 하나의 노드들 리스트를 내 놓는 API가 제공될 수 있다. 몇몇 실시예들에서, 신규 사용자들이 상기 P2P 네트웤에 연결할 수 있도록 하기 위해 네트웤이 제공할 수 있는 디렉토리 서비스를 통해서 상기 P2P 네트웤 ID를 생성할 데이터가 제공될 수 있다. 그와 달리, 이러한 데이터들 은 신규 사용자들로 하여금 블록체인을 조회해 상기 P2P 네트웤의 잠재 부분인 사용자들 리스트를 직접 불러들 이도록 함으로써 배포될 수 있다. 이 특정 예에서, 상기 네트웤에 연결된 상기 노드는 컴퓨트 노드이다. 따라서, 상기 컴퓨트 노드(예컨대, 작업 자 및/또는 유틸리타리인)는 상기 컴퓨트 노드가 제공할 수 있는 서비스의 그 티어를 선택한다. 이는 프로 세싱 파워(예컨대, CPU 수, CPU 타입, GPU 수, GPU 타입) 및 활용 가능한 스토리지(예컨대, RAM, SSD(solid- state drive) 및/또는 하드드라이브 등등과 같은 롱-텀 스토리지)에 근거할 수 있다. 도시된 프로세싱 블록은 그 티어에 대한 그 선택된 리소스 조건이 그 컴퓨트 노드에 대한 그 역사적 기록 (historical record)을 충족시키는지 결정한다. 예컨대, 상기 컴퓨트 노드가 컴퓨팅 리소스들을 팔 수 있기 위 해서는 그 마지막 1 시간 이내에 50% 이하의 CPU 및/또는 GPU 사용 점유량(CPU and/or GPU utilization)을 가 져야만 할 수 있다. 즉, 상기 컴퓨트 노드의 역사적 리소스 사용량(예컨대, 리소스들의 활용 가능한 양)은 그 티어에 대한 최소 요구 조건(예컨대, 팔려고 하는 리소스의 최소양)을 충족시켜야 한다. 그 애플리케이션, 타이 밍, 등등에 따라 다른 기준들이 적용될 수 있다. 또한, 다른 클래스들의 컴퓨트 노드들에 대해 다른 다른 티어 가 있을 수 있다. 만약, 리소스 요구 조건들이 충족되지 않으면, 도시된 프로세싱 블록은 다른 서비스 티 어를 선택하도록 실행한다. 만약, 리소스 조건들이 충족되면, 도시된 프로세싱 블록은 그 서비스 티어에 기반해서 매니징 노드 네트웤 ID를 생성한다. 예컨대, 상기 컴퓨트 노드가 제공할 그 서비스 티어의 그 매니징 노드에 대해 상기 컴퓨트 노드 는 매니징 노드 P2P 네트웤 ID를 생성할 수 있다. 상기 매니징 노드 네트웤 ID는 상기 티어에 대한 마켓플레이 스 소유자를 확인할 수 있다. 몇몇 실시예들에서, 단 하나의 마켓플레이스 소유자가 주어진 서비스 티어를 독점 하지 않는 것(그래서, 악성코드의 공격 및/또는 중앙집중식 제어의 가능성을 감소시키는 것)을 보장하기 위해, 무작위 숫자(예컨대, 위크 넘버)가 또한 해시 함수에 추가될 수 있다. 마켓플레이스 소유자의 그 P2P 네트웤 ID 는 \"hash(vCPUs, RAM, 위크 넘버)\"로 확인될 수 있다. 도시된 프로세싱 블록은 상기 매니징 노드에 상기 컴퓨트 노드의 추가 및 어떠한 것이건 상기 컴퓨트 노드 에 관련 사항들(예컨대, 활용 가능한 리소스들, 가격 조건들, 등등)에 대해 고지한다. 예컨대, 상기 컴퓨트 노 드는 자신을 상기 매니징 노드와 함께 등록할 수 있다. 그 등록 정보는 튜플(tuple)(예컨대, IP 어드레스, 활용 가능한 시간 간격, 활용 가능한 리소스들, 등등) 형태일 수 있다. 또한, 그 등록 복사본이 회계감사 프로세스를 위해 블록체인 및/또는 DLT에 저장될 수 있다. 도 5는 클라이언트 노드를 네트웤에 추가하는 방법을 나타낸다. 상기 방법은 일반적으로, 예컨대, 예 컨대, 아키텍처 (도 1), 아키텍처 (도 2), 아키텍처 (도 3)와 전술한 방법 (도 4)과 같이 여기서 기술된 실시예들 중 어떠한 것과도 함께 구현될 수 있다. 특히, 상기 방법은 RAM, ROM, PROM, 펌웨 어, 플래쉬 메모리, 등등과 같이 기계 또는 컴퓨터로 판독 가능한 스토리지 매체에 저장된 한 세트의 논리명령 들로서 하나 또는 그 이상의 모듈로, 예컨대, PLAs, FPGAs, CPLDs와 같은 컨피규러블 로직(configurable logic)으로, 예컨대, ASIC, CMOS 또는 TTL 기술과 같은 회로 기술을 이용한 고정-기능 로직 하드웨어로, 또는 그들의 어느 한 조합으로 구현될 수 있다. 도시된 프로세싱 블록는 클라이언트 노드를 네트웤에 연결하고 원하는 티어 서비스에 대한 매니징 노드를 확인한다. 예컨대, 클라이언트 노드의 사용자는 도커 이미지로 명시된 태스크를 위해 필요로 하는 그 서비스 티 어를 명시할 수 있다. 그 선택된 티어에 입각해서, 상기 클라이언트 노드들은 그 상응하는 마켓플레이스 소유자 (예컨대, 상기 매니징 노드)를 조회(lookup) 할 있다. 그 룩업 프로세스는 방법에서 전술한 컴퓨트 노드 룩업으로 위에서 기술했던 프로세스와 유사하거나 동일할 수 있다. 도시된 프로세싱 블록에서, 상기 클라이언트 노드는 상기 매니징 노드에 컨택해서 모든 컴퓨트 노드들의 리스트를 받을 수 있다. 도시된 프로세싱 블록에서, 상기 클라이언트 노드는 옥션을 진행할 수 있다. 이 옥션이 진행되는 동안, 상기 클라이언트 노드는 가격 정보를 위해 모든 컴퓨트 노드들에 컨택할 수 있다. 그 실 행 가격을 명시한 회신들을 받기 위해 소정의 단위(예컨대, 15 분)가 이용될 수 있다(옥션이 열리는 시간 주 기). 그 회신들은 또한 상기 컴퓨트 노드들이 여전히 그들의 컴퓨팅 리소스들을 할애할 수 있다는 검증 역할로 서 작용할 수 있다. 도시된 프로세싱 블록에서, 상기 클라이언트 노드는 회신한 모든 컴퓨트 노드들의 레이턴시를 측정한다. 소정의 기준치(예컨대, 디폴트 5초) 이상의 레이턴시를 가지는 컴퓨트 노드들은 모두 거절될 수 있다. 몇몇 실 시예들에서, 상기 레이턴시는 상기 클라이언트 노드를 향해 상기 컴퓨트 노드로부터 나온 메시지가 상기 클라이 언트 노드에 도달하는데 걸리는 시간으로 측정된다. 도시된 프로세싱 블록에서, 그 유틸리타리안 노드들로부터의 가격 입찰 접수 및/또는 그 레이턴시 분석이 있으면, 상기 클라이언트 노드는 상기 컴퓨트 노드들 중에서 레이턴시 기준치를 충족시키는 최저 입찰가의 컴퓨 트 노드들을 하나 또는 그 이상 선택할 수 있다. 몇몇 실시예들에서, 상기 클라이언트 노드가 더 바람직함을 나 타내는 스피드 기준치보다 상기 레이턴시가 밑에 있으면, 상기 클라이언트 노드는 저가의 컴퓨터 노드들보다 더 비싼 컴퓨트 노드를 선택할 수 있다. 도시된 프로세싱 블록는 그 선택된 하나 또는 그 이상의 컴퓨트 노드들로 하나의 실행될 이미지를 보낸다. 즉, 상기 클라이언트 노드는 하나 또는 그 이상의 컴퓨트 노드들과 통신하고 실행될 도커 이미지를 보낼 수 있 다. 도시된 프로세싱 블록에서, 상기 클라이언트 노드는 그 하나 또는 그 이상의 컴퓨트 노드들에 의한 컴 퓨테이션들 결과를 받는다. 예컨대, 하나 또는 그 이상의 컴퓨트 노드들로부터 나온 컴퓨테이션 결과들은 상기 클라이언트 노드로 다시 보내져 미리 결정된 디렉토리에 또는 회신콜의 통합 자원 식별자(URI; uniform resource indicator)를 통해 저장된다. 도시된 프로세싱 블록은 대가들을 지불한다. 몇몇 실시예들에서, 상기 클라이언트 노드에 의해 지불되는 가격은 Vickrey 옥션에서 기술되는 것처럼 상기 컴퓨트 노드들의 모든 입찰가들로부터 두 번째로 낮은 가격일 수 있다. 이러한 형태의 옥션 메커니즘을 통해 컴퓨팅 리소스들에 대한 그 공급 비용을 충실하게 공유하는 것이 컴퓨트 노드의 최상의 입찰 전략임을 보장할 수 있다. 옥션의 세부 사항들은 또한 블록체인에 기록될 수 있다. 몇몇 실시예들에서, 상기 매니징 노드 또한 상기 클라이언트 노드에 의해 지불될 수 있다. 상기 매니징 노드에 지불할 그 대가는 최저 입찰가(하나 또는 그 이상의 컴퓨트 노드들에 의해 제공된 입찰가)에 대한 것과 두 번째 최저 입찰가에 대한 것이다르다. 예컨대, Vickrey 옥션에서, 컴퓨트 리소스들의 공급 비용을 제시함에 있어서 진실을 말하는 것이 최상의 전략이 다. 상기 컴퓨트 노드들은 최저가에 기초해서 선택될 수 있지만, 보상을 받는 것은 동일 마켓플레이스에서 리스 트된 두 번째 최저가이다. 몇몇 실시예들은, 파일이 청크(chunk) 되어 복제되고 나서 복수 마이너들에 저장되어야 하기 때문에, 옥션 끝에서 복수의 낙찰자들이 선탤될 수 있음을 고려하기 위해 Vickrey 옥션 프로토콜을 더 확장할 수 있다. 또한, 몇몇 실시예들은 옥션의 모든 참가자들이 온라인이며 서로 알지 못한다는 사실때문에 복 수의 유찰 시나리오를 고려할 수 있다. 상기 방법은 모두 스마트 계약에 따른 것일 수 있다. 도 6은 한 애플리케이션(또는 다른 소프트웨어)에서, 유틸리타리안들이 그들 리소스들을 판매하기 위해 설정 값 들을 설정할 수 있도록 하는 프로세싱 셋팅 섹션을 나타낸다. 도시되는 바와 같이, 사용자 및/또는 컴퓨트 노드는 파라미터들을 설정할 수 있다. 상기 파라미터들은 클라이언트 노드들에 의해 활용될 수 있는 디스크 공간 크기, 및 그 애플리케이션이 사용자 입력 및 컴퓨트 노드의 설정들에 기초해서 자동으로 정할 수 있는 티어 셋팅을 포함할 수 있다. 도 7은 사용자 및/또는 클라이언트로 하여금 태스크의 분산 실행을 위해 상기 네트웤에서 컴퓨트 노드들로부터 컴퓨트 리소스들을 구매할 수 있도록 하기 위한 그래픽 유저 인터페이스를 나타낸다. 상기 그래픽 유저 인 터페이스는 어떻게 클라이언트들이 그들의 태스크를 실행하는데 필요한 컴퓨트 용량의 티어에 대해 요구 사항들을 설정할 수 있는지를 나타낸다. 예컨대, 상기 클라이언트 노드가 태스크 요구 사항들을 명시하고 실행될 도커 이미지를 명시한 한 후에, 소프트웨어 에이전트는 그 티어에 대한 매니징 노드에 연락해 활용 가능한 유틸리타리안들(컴퓨트 노드들) 리스트를 얻을 수 있다. 상기 클라이언트 노드의 사용자는 도 8에 보이 는 바와 같이 하나를 선택할 옵션과 함께 그 유틸리타리안들에 대한 상세 정보를 제공받을 수 있다. 예컨대, 그래픽 유저 인터페이스은 상기 마켓플레이스에 제공된 유틸리타리안들을 리스트화한다. 만 약 한 사용자가 유틸리타리안 리소스들 중 하나를 선택하지 않으면, 그 에이전트는 또한 레이턴시 테스트 로부터 나온 레이턴시가 미리 설정된 양 아래이기만 하면 유티릴타리인들로부터 가장 낮게 가능한 비용의 유틸리타리안 리소스를 자동 선택하도록 설정될 수 있다. 몇몇 실시예들에서, 상기 클라이언트 노드는 그 테스트 결과들이 저장되는 디렉토리를 설정할 수 있다. 컴퓨테 이션으로부터 나온 결과들이 활용 가능하기만 하면, 사용자는 작업이 완료되었음을 확인해 주는 이메일을 받을 옵션을 갖는다. 또한, 상기 애플리케이션은 동일 액션들에 대한 통지를 제공할 수 있다. 도 9는 클라이언트 설정 및 레스트 API들(rest APIs)를 사용한 오픈 개발자 인터페이스를 나타낸다. 마켓 플레이스는 사용자들로 하여금 스토리지 용량을 사고 팔수 있도록 하는 애플리케이션에 통합될 수 있다. 같은 성능이 컴퓨트 리소스들의 판매, 구매, 그리고 관리를 위해 레스트풀 APIs(RESTful APIs)를 통해 제공될 수 있다. 그러한 오픈 플랫폼 덕분에 개발자들은 크고 저렴하며 억세스 용이한 컴퓨트 노드들을 고취시킬 새로 운 혁신적인 앱들을 구축할 수 있을 것이다. 도시된 바와 같이, 인터페이스는 일렉톤 애플리케이션 (electorn applications), 웹-유저 인터페이스, 노드 웹 서비스들 및 도커 엔진을 포함할 수 있다. 아래는 레스트 APIs를 구현할 슈도코드(pseudo-code)이다: Create a compute resource to sell POST /compute { \"tier name\": \"string\", \"kademlia_id\" : \"string\", \"public_address : \"string\", \"ip_address\" : \"string\", \"country_code\": \"string\", \"price_per_15_mins\": \"double\", \"availability_window\": \"string\", \"cpu_count\" : \"int\", \"speed_in_ghz\": \"int\", \"memory_in_gb\" : \"int\" } Get a list of utilitarians providing a particular tier of compute resource GET /compute/{tier_name} [ {\"kademlia_id\" : \"string\", \"public_address \": \"string\", \"ip_address\": \"string\", \"country_code\": \"string\", \"latency_in_msecs\": \"int\", \"price_per_15_mins\": \"double\", \"cpu_count\" : \"int\", \"speed_in_ghz\": \"int\", \"memory_in_gb\" : \"int\"}, {},... ] Submit a Docker instance for execution on the selected utilitarian POST /compute { \"client_kademlia_id\" : \"string\", \"client_public_address\": \"string\", \"client_ip_address\" : \"string\", \"docker_image\" : \"blob\", \"return_uri : \"string\" } 도커 엔진에서 단일 도커 컨테이너로 패키징된 클라이언트에 대한 태스크는 관리될 수 있다. 몇몇 중간 병 렬 오퍼레이션으로 연속해서 실행될 필요가 있는 한 세트의 상호의존적 태스크를 요하는 다양한 워크로드들이 있다. 제너럴 워크플로우 매니지먼트 시스템이 제공되며, 클라이언트들은 태스크에 대한 워크플로우를 정의하고 제출하는데 이를 이용할 수 있다. 결국, 워크플로우 매니지먼트 시스템은 모든 필요한 태스크들을 완료하는데 최상의 신뢰, 퍼포먼스 및 비용 이익을 제공하기 위해 자동적으로 모든 태스크들의 실행을 스케쥴링하고 관리 및 최적화할 수 있다. 도 10은 평판을 관리하는 방법을 나타낸다. 상기 방법(1000')은 일반적으로, 예컨대 예컨대 아키텍처 (도 1), 아키텍처 (도 2), 아키텍처 (도 3), 전술한 상기 방법 (도 4)과 상기 방법 (도 5)과 같이 여기 기술된 실시예들 중 어떠한 것과도 함께 구현될 수 있다. 특히, 상기 방법은 RAM, ROM, PROM, 펌웨어, 플래쉬 메모리, 등등과 같이 기계 또는 컴퓨터로 판독 가능한 스토리지 매체에 저장된 한 세트의 논리명령들로서 하나 또는 그 이상의 모듈로, 예컨대, PLAs, FPGAs, CPLDs와 같은 컨피규러블 로직 (configurable logic)으로, 예컨대, ASIC, CMOS 또는 TTL 기술과 같은 회로 기술을 이용한 고정-기능 로직 하 드웨어로, 또는 그들의 어느 한 조합으로 구현될 수 있다. 몇몇 실시예에 의하면, 혁신적인 평판 관리 및 인센티브 엔지니어링이 이용되어 그 시스템 스스로 지속가능하게 할 수 있다. 앞에서 기술된 것처럼, 악성 또는 부실 컴퓨트 노드들, 매니징 노드들 및 클라이언트 노드들은 낮 은 평판 스코어들에 기초해서 아키텍처들로부터 제거될 수 있다. 상기 네트웤의 모든 노드는 다른 모든 노드의 평판에 대한 복사본을 가지고 있을 수 있다. 상기 평판은 상기 노 드의 다른 노드들과 협업한 직접 경험의 총계적 표현일 수 있으며, 또한 상기 평판은 상기 노드가 접수했던 메 시지들을 공표한다. 이 평판은 유틸리타리안이든 마켓플레이스 소유자이든 클라이언트이든 모든 다른 노드에 대 해 계산될 수 있다. 바람직한 실시예에 의하면, 평판 관리는 다음과 같이 수행될 수 있다. 도시된 프로세싱 블록에서, 컴퓨트 노드는 거래를 완료할 수 있다. 도시된 프로세싱 블록에서, 그 거래를 성공적으로 완료한 후에, 상기 컴 퓨트 노드는 완료 인증을 생성할 수 있다. 도시된 프로세싱 블록은 상기 완료 인증을 상기 컴퓨트 노드가 그 네트웤에서 인지하고 있는 다른 모든 노드들에게 공표한다. 상기 완료 인증은 클라이언트 노드에서 컴퓨트 노드에 행해진 지불 거래를 기록한 블록체인 블록에 대한 해시 포인터를 포함할 수 있다. 다른 노드들은 상기 완료 인증을 수신한 후 다음과 같이 상기 컴퓨트 노드의 평판을 계산한다: utilitarian reputation new = f(utilitarian reputation old * client reputation) 또는 두 값 중 어느 하나 라도 0인 경우 1 식 1 동일 쌍의 컴퓨트 및 클라이언트 노드들에 대해 많아봐야 일주일에 한 번씩 평판이 올라간다. 상기 평판은 노드의 그 P2P 네트웤 id와 관련될 수 있으며, 이는 결국 블록체인 퍼블릭 어드레스와 관련된다는 것을 의미한다. 또한, 평판은 단조적으로 증가하는 정수일 수 있다. 그 값이 크면 클수록 평판이 높고, 제로는 최악임을 의미한다. 제로 값은 또한 노드의 평판이 미지상태임을 의미한다. 악성 코드는 항상 그 P2P 네트웤 id 를 생성하고 모르는 노드로 그 네트웤에 다시 연결할 수 있기 때문에, 최악과 미지상태는 호환적으로 다뤄질 수 있다. 도 11은 평판을 업데이팅하는 방법을 나타낸다. 도시된 프로세싱 블록는 완료 인증을 수신한다. 도시된 프로세싱 블록는 그 완료 인증과 관련된 노드의 평판 스코어를 계산한다. 도시된 프로세싱 블록은 한 노드에 대한 신규의 완료 인증이 소정의 제한 시간 내에 접수되는지 여부를 결정한다. 예컨대, 한 노드에 대 한 평판은 시간 감소 함수(decaying function of time)일 수 있다. 그래서, 만약 한 유틸리타리안이 서비스를 제공하지 않으면, 평판은 시간 경과에 따라 점점 떨어진다. 만약 새로운 인증이 수신되지 않으면, 도시된 프로 세싱 브록은 다음과 같이 평판을 떨어뜨릴 수 있다: New Reputation = Ratings in last 30 days * α + Previous ratings * (1 - α), 식 2 위 식에서, α는 신규 평가에 할당된 웨이트를 조절한다. 기술된 바와 같이, 노드들에 대한 평판은 노드들이 언 제 서비스를 제공 및/또는 수신하기로 결정하는지에 대한 그 결정의 일부일 수 있다. 실시예들은 모든 유형의 반도체 집적 회로(\"IC\") 칩들과 사용하는데 적용될 수 있다. 이러한 IC 칩들의 예는 프 로세서들, 콘트롤러들, 칩셋 컴포넌트들, 프로그래머블 로직 어레이들(OLAs), 메모리 칩들, 네트웤 칩들, 시스 템 온 칩(SoCs), SSD/NAND 콘트롤러 ASICs, 및 그 유사한 것들을 포함하지만 그에 한정되지는 않는다. 덧붙여, 몇몇 도면들에서, 신호 연결선들은 라인들로 표현된다. 몇몇은 더 많은 구성 신호 경로들을 나타내기 위해 다를 수 있으며, 많은 구성 신호 경로들을 나타내기 위해 번호 라벨을 포함할 수 있고, 주된 정보 흐름 방향을 나타 내기 위해 하나 또는 그 이상의 끝에 화살표들을 포함할 수 있다. 그러나, 이는 한정하는 것으로 해석되어서는 안된다. 오히려, 그러한 추가된 세부사항들은 회로에 대해 더 쉽게 이해할 수 있도록 하나 또는 그 이상의 바람 직한 실시예들과 함께 사용될 수 있다. 사실 어떠한 표시된 신호선들도, 추가 정보를 포함하던 포함하지 않던, 복수 방향으로 통할 수 있는 하나 또는 그 이상의 신호들을 포함할 수 있으며, 어떠한 적합한 유형의 신호 체계, 예컨대 다른 쌍들, 광섬유 라인들(optical fiber lines), 및/또는 싱글-엔디드 라인들로 구현되는 디지털 또는 아날로그 라인들로도 구현될 수 있다. 비록 실시예들이 그에 한정되는 것이 아니지만, 예시적인 사이즈들/모델들/값들/레인지들이 주어졌을 수 있다. 제조 기술들(예컨대, 포토리소그래피)이 점점 더 발전함에 따라, 더 작은 사이즈의 장비들이 제조될 수 있을 것으로 기대된다. 또한, IC 칩들 및 다른 컴포넌트들에 대한 잘 알려진 파워/그라운드 연결은, 표현 및 설명의 단 순화를 위해, 그리고 실시예들의 특정 면들을 모호하게 하지 않도록 하기 위해, 도면에 나타날 수도 또는 나타나지 않을 수도 있다. 또한, 블록 다이어그램 형태로 배열되어 나타날 수 있는데, 이는 모호한 실시예들을 피하 기 위해, 그리고 또 그러한 블록 다아어그램 배열들의 구현에 관한 세부사항들이 그 실시예가 구현되는 그 컴퓨"}
{"patent_id": "10-2021-7017341", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "팅 시스템에 매우 종속적이라는 점, 즉, 그러한 세부사항들은 해당 기술분야의 숙력된 자의 범주 내에 있을 것 이라는 사실 관점 때문이다. 특정 세부사항들(예컨대, 회로들)이 바람직한 실시예들을 기술하기 위해 제시된 경"}
{"patent_id": "10-2021-7017341", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "우에, 실시예들은 그러한 특정 세부사항들 없이 또는 그 변형과 함께 구현될 수 있다는 것은 해당 기술분야의 기술자에게 자명할 것이다. 따라서, 그러한 묘사는 한정하는 요소 대신에 설명적인 것으로 간주되어야 한다. 용어 \"커플된(coupled)\"은 여기서 문제의 그 컴포넌트들 사이에, 직접 또는 간접의, 어떠한 유형의 관계를 의미 하는 것으로 사용될 수 있으며, 전기적, 기계적, 유체적, 광학적, 전자기학적, 전자기계적 또는 다른 연결에 사 용될 수 있다. 또한, 용어들 \"제1\", \"제2\", 등등은 여기서 단지 설명을 용이하게 하기 위해 사용될 뿐이며, 달 리 지시되지 않는 한, 어떠한 특정의 시간적 또는 발생 순서적 의미를 지니지 않는다. 본 출원 명셍서 및 청구항들에서 사용되듯이, 용어 \"중 하나 또는 그 이상\"이 결부된 아이템들 리스트는 그 리 스트된 아이템들의 어떠한 조합도 의미할 수 있다. 예컨대, 문구 \"A, B, 또는 C 중 하나 또는 그 이상\"은 A; B; C; A 및 B; A 및 C; B 및 C; 또는 A, B 및 C를 의미할 수 있다."}
{"patent_id": "10-2021-7017341", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "해당 기술분야의 기술자들은 전술한 내용으로부터 상기 실시예들의 폭넓은 기술들은 다양한 형태로 구현될 수 있음을 알 것이다. 따라서, 상기 실시예들이 특정 예시들과 연결되어 기술되었지만, 도면, 명세서, 그리고 청구 항들을 알면 다른 변형들이 기술자에게 자명할 것이기 때문에, 그 실시예들의 진정한 범주는 그렇게 한정되서는 안된다. 도면 도면1 도면2 도면3 도면4 도면5 도면6 도면7 도면8 도면9 도면10 도면11"}
{"patent_id": "10-2021-7017341", "section": "도면", "subsection": "도면설명", "item": 1, "content": "실시예들의 여러가지 장점들은, 후술하는 상세한 설명 및 첨부된 청구항들과 아래의 도면들을 참조하면, 해당 분야의 기술자에게 자명할 것이다: 도 1은 하나의 실시예에 의한 지능, 비중앙집중식 자율 아키텍처의 일 예를 나타낸다; 도 2는 하나의 실시예에 따라 컴퓨트 리소스들 분배하는 아키텍처이다; 도 3은 하나의 실시예에 의한 비중앙집중식 컴퓨팅 아키텍처이다; 도 4는 하나의 실시예에 의한 노드 연결 오퍼레이션의 실행 방법에 대한 일 예의 플로우차트이다; 도 5는 하나의 실시예에 따라 클라이이언트 노드를 네트웤에 추가하는 방법에 대한 일 예의 플로우차트이다; 도 6은 하나의 실시예에 의한 프로세싱 셋팅 섹션에 대한 일 예이다; 도 7은 하나의 실시예에 의한 그래픽 유저 인터페이스의 일 예이다; 도 8은 하나의 실시예에 의한 그래픽 유저 인터페이스의 일 예이다; 도 9는 하나의 실시예에 의한 클라이언트 환경 설정 및 오픈 개발자 인터페이스에 대한 일 예이다; 도 10은 하나의 실시예에 의한 평판 관리 방법에 대한 일 예의 플로우차트이다; 도 11은 하나의 실시예에 의한 평판 업데이트 방법에 대한 일 예의 플로우차트이다."}
