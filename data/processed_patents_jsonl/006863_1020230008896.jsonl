{"patent_id": "10-2023-0008896", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0116228", "출원번호": "10-2023-0008896", "발명의 명칭": "감정 인식 기반 로봇 동작 제어 방법 및 이를 이용한 로봇 장치", "출원인": "주식회사 에듀로봇", "발명자": "형현준"}}
{"patent_id": "10-2023-0008896", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "각 단계가 카메라를 포함하는 로봇의 프로세서에 의해 수행되는 방법으로서, a) 상기 카메라로부터 사용자의 얼굴이 포함된 이미지를 획득하는 단계; b) 상기 이미지로부터 상기 사용자의 얼굴을 인식하고, 인식된 얼굴의 표정을 분석하여 상기 사용자의 감정 정보를 생성하는 단계; 및 c) 상기 감정 정보를 기초로 상기 로봇의 동작 속도 및 동작 가속도 중 적어도 하나 이상을 제어하는 단계를 포함하는, 감정 인식 기반 로봇 동작 제어 방법."}
{"patent_id": "10-2023-0008896", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 감정 정보는,복수의 감정 상태들 및 상기 감정 상태들 각각에 대한 강도(Intensity)를 포함하는 것인, 감정 인식 기반 로봇동작 제어 방법."}
{"patent_id": "10-2023-0008896", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서, 상기 감정 상태는, 기쁨, 슬픔, 놀람, 화남, 두려움 및 혐오 중 적어도 하나 이상을 포함하는 것인, 감정 인식 기반 로봇 동작 제어 방법."}
{"patent_id": "10-2023-0008896", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제2항에 있어서, 상기 b) 단계는, 상기 이미지를 기설정된 크기로 편집하는 과정 및 상기 이미지에 그레이스케일을 적용하는 과정 중 적어도 하나이상의 과정을 포함하는 전처리를 수행하는 단계; 및 전처리된 상기 이미지로부터 상기 사용자의 얼굴을 인식하고, 감정 인식 모델을 이용하여, 인식된 얼굴의 표정을 토대로 상기 감정 정보를 생성하는 단계를 포함하는, 감정 인식 기반 로봇 동작 제어 방법."}
{"patent_id": "10-2023-0008896", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서, 상기 감정 인식 모델은, 학습용 얼굴 표정 이미지와 상기 학습용 얼굴 표정 이미지에 대한 감정 정보를 포함하는 학습 데이터를 기초로,특정 얼굴 이미지로부터 얼굴 표정을 분석하여 상기 특정 얼굴 이미지에 대한 감정 정보를 출력하도록 훈련된인공지능 모델인, 감정 인식 기반 로봇 동작 제어 방법."}
{"patent_id": "10-2023-0008896", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제2항에 있어서, 상기 c) 단계는, 공개특허 10-2024-0116228-3-상기 감정 상태들 각각의 강도를 고려하여 상기 감정 상태들 중 주요 감정 상태를 선정하는 단계;상기 주요 감정 상태에 대응되는 상기 로봇의 최대 동작 속도 및 최대 동작 가속도를 포함하는 감정 동작 프로파일, 기설정된 상기 로봇의 중립 속도 및 중립 가속도를 포함하는 중립 동작 프로파일 및 상기 주요 감정 상태의 강도를 토대로 상기 로봇의 최종 동작 프로파일을 설정하는 단계; 및 상기 최종 동작 프로파일에 따라, 상기 로봇의 상기 동작 속도 및 상기 동작 가속도를 제어하는 단계를 포함하는, 감정 인식 기반 로봇 동작 제어 방법."}
{"patent_id": "10-2023-0008896", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제2항에 있어서,d) 상기 a) 내지 c) 단계를 반복하여 상기 사용자의 감정 상태 및 강도가 실시간으로 변경되는 경우, 변경된 감정 상태 및 강도에 기초하여 상기 로봇의 동작 속도 및 가속도 중 적어도 하나 이상을 재설정하는 단계를 더 포함하는 것인, 감정 인식 기반 로봇 동작 제어 방법."}
{"patent_id": "10-2023-0008896", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "카메라;적어도 하나의 프로세서 및 상기 프로세서와 전기적으로 연결되고, 상기 프로세서에서 수행되는 적어도 하나의 코드가 저장되는 메모리를포함하고, 상기 메모리는, 상기 프로세서를 통해 실행될 때, 상기 프로세서가,상기 카메라로부터 사용자의 얼굴이 포함된 이미지를 획득하고, 상기 이미지로부터 사용자의 얼굴을 인식하고, 인식된 얼굴의 표정을 분석하여 상기 사용자의 감정 정보를 생성하고, 그리고, 상기 감정 정보를 기초로 로봇 장치의 동작 속도 및 동작 가속도 중 적어도 하나 이상을 제어하도록 야기하는코드를 저장하는, 감정 인식 로봇 장치."}
{"patent_id": "10-2023-0008896", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서, 상기 감정 정보는, 복수의 감정 상태들 및 상기 감정 상태들 각각에 대한 강도(Intensity)를 포함하는 것인, 감정 인식 로봇 장치."}
{"patent_id": "10-2023-0008896", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9항에 있어서, 상기 감정상태는, 기쁨, 슬픔, 놀람, 화남, 두려움 및 혐오 중 적어도 하나 이상을 포함하는 것인, 감정 인식 로봇 장치."}
{"patent_id": "10-2023-0008896", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제9항에 있어서, 상기 메모리는 상기 프로세서로 하여금, 상기 이미지를 기설정된 크기로 편집하는 과정 및 이미지에 그레이스케일을 적용하는 과정 중 적어도 하나 이상의 과정을 포함하는 전처리를 수행하고, 그리고, 전처리된 상기 이미지로부터 상기 사용자의 얼굴을 인식하고, 감정 인식 모델을 이용하여, 인식된 얼굴의 표정을 토대로 상기 감정 정보를 생성하도록 야기하는 코드를 저장하는, 감정 인식 로봇 장치.공개특허 10-2024-0116228-4-청구항 12 제11항에 있어서, 상기 감정 인식 모델은, 학습용 얼굴 표정 이미지, 상기 학습용 얼굴 표정 이미지에 대한 감정 정보를 포함하는 학습 데이터를 기초로,특정 얼굴 이미지로부터 얼굴 표정을 분석하여 상기 특정 얼굴 이미지에 대한 감정 정보를 출력하도록 훈련된인공지능 모델인, 감정 인식 로봇 장치."}
{"patent_id": "10-2023-0008896", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제9항에 있어서, 상기 메모리는 상기 프로세서로 하여금, 상기 감정 상태들 각각의 강도를 고려하여 상기 감정 상태들 중 주요 감정 상태를 선정하고, 상기 주요 감정 상태에 대응되는 상기 로봇의 최대 동작 속도 및 최대 동작 가속도를 포함하는 감정 동작 프로파일, 기설정된 상기 로봇의 중립 속도 및 중립 가속도를 포함하는 중립 동작 프로파일 및 상기 주요 감정 상태의 강도를 토대로 상기 로봇의 최종 동작 프로파일을 설정하고, 그리고, 상기 최종 동작 프로파일에 따라, 상기 로봇의 상기 동작 속도 및 상기 동작 가속도를 제어하도록 야기하는 코드를 저장하는, 감정 인식 로봇 장치."}
{"patent_id": "10-2023-0008896", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명의 일 실시예는, 사용자 감정 인식을 기반으로 로봇 장치의 동작 제어 방법을 제공한다. 본 방법은, 상기 카메라로부터 사용자의 얼굴이 포함된 이미지를 획득하는 단계, 상기 이미지로부터 상기 사용자의 얼굴을 인식하 고, 인식된 얼굴의 표정을 분석하여 상기 사용자의 감정 정보를 생성하는 단계 및 상기 감정 정보를 기초로 상기 로봇의 동작 속도 및 동작 가속도 중 적어도 하나 이상을 제어하는 단계를 포함한다."}
{"patent_id": "10-2023-0008896", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 감정 인식 기반 로봇 동작 제어 방법 및 이를 이용한 로봇 장치에 관한 것으로, 보다 상세하게는, 로 봇의 카메라로부터 사용자의 이미지를 획득하고, 해당 이미지로부터 사용자의 얼굴 표정을 분석하여 사용자의 감정 정보를 도출하고, 도출된 감정 정보를 기초로 로봇의 동작 속도 및 동작 가속도 중 적어도 하나 이상을 제 어하는 감정 인식 기반 로봇 동작 제어 방법 및 이를 이용한 로봇 장치에 관한 것이다."}
{"patent_id": "10-2023-0008896", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "4차 산업혁명 기술로 불리는 사물인터넷, 클라우드 컴퓨팅, 인공지능, 5G 등의 정보통신 기술이 발전함에 따라, 다양한 센서를 통해 사람의 감정을 감지하고 사람과 상호작용하는 소셜 로봇이 개발되고 있다. 종래의 소셜 로 봇은 다양한 센서를 통해 사람에 대한 기쁨, 슬픔, 놀람, 화남, 두려움, 혐오 등의 감정 상태를 파악하고, 해당 감정 상태에 따라 특정 동작을 수행하도록 작동하고 있다. 사람의 감정은 기쁨, 슬픔, 놀람, 화남, 두려움, 혐오 등의 사람이 경험하는 전반적인 감정이나 분위기를 나타 내는 감정 상태와 각 감정 상태와 관련된 힘이나 활력의 정도를 나타내는 감정 강도로 나타낼 수 있다. 그러나, 종래의 소셜 로봇은 감정 상태만을 파악하고, 파악된 감정 상태에 따라 설정된 특정 동작만을 수행하므로, 감정 상태에 대한 감정 강도를 고려하여 사람과 더욱 효과적으로 상호작용하는 소셜 로봇을 제공하고 있지 못하는 실 정이다."}
{"patent_id": "10-2023-0008896", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 전술한 종래 기술의 문제점을 해결하기 위한 것으로서, 로봇의 카메라로부터 사용자의 이미지를 획득 하고, 해당 이미지로부터 사용자의 얼굴 표정을 분석하여 사용자의 감정 정보를 도출하고, 도출된 감정 정보를 기초로 로봇의 동작 속도 및 동작 가속도 중 적어도 하나 이상을 제어하는 감정 인식 기반 로봇 동작 제어 방법 및 이를 이용한 로봇 장치를 제공하는 것을 일 기술적 과제로 한다. 또한, 본 발명은 사용자의 감정 상태와 감정 상태에 대한 강도를 고려하여 동작하는 로봇을 제공하는 것을 본 발명의 또 다른 기술적 과제로 한다. 본 발명이 이루고자 하는 기술적 과제들은 상기한 기술적 과제로 제한되지 않으며, 이하의 설명으로부터 본 발 명의 또 다른 기술적 과제들이 도출될 수 있다."}
{"patent_id": "10-2023-0008896", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상술한 기술적 과제를 해결하기 위한 기술적 수단으로서, 본 발명의 일 측면에 따라, 사용자 감정 인식을 기반 으로 로봇 장치의 동작 제어 방법을 제공한다. 본 방법은, 상기 카메라로부터 사용자의 얼굴이 포함된 이미지를 획득하는 단계, 상기 이미지로부터 상기 사용자의 얼굴을 인식하고, 인식된 얼굴의 표정을 분석하여 상기 사용 자의 감정 정보를 생성하는 단계 및 상기 감정 정보를 기초로 상기 로봇의 동작 속도 및 동작 가속도 중 적어도 하나 이상을 제어하는 단계를 포함한다. 또한, 상술한 기술적 과제를 해결하기 위한 기술적 수단으로서, 본 발명의 다른 일 측면에 따라, 감정 인식 로 봇 장치가 제공된다. 본 장치는, 카메라, 적어도 하나의 프로세서 및 상기 프로세서와 전기적으로 연결되고, 상 기 프로세서에서 수행되는 적어도 하나의 코드가 저장되는 메모리를 포함하고, 상기 메모리는, 상기 프로세서를 통해 실행될 때 상기 프로세서가, 상기 카메라로부터 사용자의 얼굴이 포함된 이미지를 획득하고, 상기 이미지 로부터 상기 사용자의 얼굴을 인식하고, 인식된 얼굴의 표정을 분석하여 상기 사용자의 감정 정보를 생성하고, 그리고, 상기 감정 정보를 기초로 상기 로봇의 동작 속도 및 동작 가속도 중 적어도 하나 이상을 제어하도록 야 기하는 코드를 저장한다."}
{"patent_id": "10-2023-0008896", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "전술한 본 발명의 과제 해결 수단에 따르면, 본 발명은 사람의 감정 상태와 감정 상태에 대한 강도를 고려하여 종래의 소셜 로봇보다 더욱 효과적으로 사람과 감정적인 상호작용을 할 수 있다. 또한, 전술한 본 발명의 과제 해결 수단에 따르면, 본 발명은 사람의 감정을 고려하여 작업자의 감정을 해하지 않으면서, 사람이 수행하는 작업을 보조하거나, 사람의 감정을 공감하는 등의 역할을 수행할 수 있다."}
{"patent_id": "10-2023-0008896", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하에서는 첨부한 도면을 참조하여 본 발명을 상세히 설명하기로 한다. 다만, 본 발명은 여러 가지 상이한 형 태로 구현될 수 있으며, 여기에서 설명하는 실시예들로 한정되는 것은 아니다. 또한, 첨부된 도면은 본 명세서 에 개시된 실시예를 쉽게 이해할 수 있도록 하기 위한 것일 뿐, 첨부된 도면에 의해 본 명세서에 개시된 기술적 사상이 제한되지 않는다. 여기에 사용되는 기술용어 및 과학용어를 포함하는 모든 용어들은 본 발명이 속하는"}
{"patent_id": "10-2023-0008896", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "기술분야에서 통상의 지식을 가진 자가 일반적으로 이해하는 의미로 해석되어야 한다. 사전에 정의된 용어들은 관련기술문헌과 현재 개시된 내용에 부합하는 의미를 추가적으로 갖는 것으로 해석되어야 하며, 별도로 정의되 지 않는 한 매우 이상적이거나 제한적인 의미로 해석되지 않는다. 도면에서 본 발명을 명확하게 설명하기 위해서 설명과 관계없는 부분은 생략하였으며, 도면에 나타난 각 구성요 소의 크기, 형태, 형상은 다양하게 변형될 수 있다. 명세서 전체에 대하여 동일/유사한 부분에 대해서는 동일/ 유사한 도면 부호를 붙였다. 이하의 설명에서 사용되는 구성요소에 대한 접미사 \"모듈\" 및 “부” 등은 명세서 작성의 용이함만이 고려되어 부여되거나 혼용되는 것으로서, 그 자체로 서로 구별되는 의미 또는 역할을 갖는 것은 아니다. 또한, 본 명세서 에 개시된 실시예를 설명함에 있어서 관련된 공지 기술에 대한 구체적인 설명이 본 명세서에 개시된 실시 예의요지를 흐릴 수 있다고 판단되는 경우 그 상세한 설명을 생략하였다. 명세서 전체에서, 어떤 부분이 다른 부분과 \"연결(접속, 접촉 또는 결합)\"되어 있다고 할 때, 이는 \"직접적으로 연결(접속, 접촉 또는 결합)\"되어 있는 경우뿐만 아니라, 그 중간에 다른 부재를 사이에 두고 \"간접적으로 연결 (접속, 접촉 또는 결합)\"되어 있는 경우도 포함한다. 또한 어떤 부분이 어떤 구성요소를 \"포함(구비 또는 마 련)\"한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다른 구성요소를 제외하는 것이 아니라 다른 구성요소 를 더 \"포함(구비 또는 마련)\"할 수 있다는 것을 의미한다. 본 명세서에서 사용되는 제1, 제2 등과 같이 서수를 나타내는 용어들은 하나의 구성 요소를 다른 구성요소로부 터 구별하는 목적으로만 사용되며, 구성 요소들의 순서나 관계를 제한하지 않는다. 예를 들어, 본 발명의 제1구 성요소는 제2구성요소로 명명될 수 있고, 유사하게 제2구성요소도 제1구성 요소로 명명될 수 있다. 본 명세서에 서 사용되는 단수 표현의 형태들은 명백히 반대의 의미를 나타내지 않는 한 복수 표현의 형태들도 포함하는 것으로 해석되어야 한다. 이하에서 설명되는 통신 모듈은 다른 네트워크 장치와 유무선 연결을 통해 제어 신호 또는 데이터 신호와 같은 신호를 송수신하기 위해 필요한 하드웨어 및 소프트웨어를 포함하는 장치를 포함할 수 있다. 또한, 메모리는 통 신 모듈로 입력되는 정보 및 데이터, 프로세서에 의해 수행되는 기능에 필요한 정보 및 데이터, 프로세서의 실 행에 따라 생성된 데이터 중 적어도 어느 하나 이상을 저장할 수 있다. 메모리는 전원이 공급되지 않아도 저장 된 정보를 계속 유지하는 비휘발성 저장장치 및 저장된 정보를 유지하기 위하여 전력을 필요로 하는 휘발성 저 장장치를 통칭하는 것으로 해석되어야 한다. 메모리는 저장된 정보를 유지하기 위하여 전력이 필요한 휘발성 저 장장치 외에 자기 저장 매체(magnetic storage media) 또는 플래시 저장 매체(flash storage media)를 포함할 수 있으나, 본 발명의 범위가 이에 한정되는 것은 아니다. 프로세서는 데이터를 제어 및 처리하는 다양한 종류 의 장치들을 포함할 수 있다. 프로세서는 프로그램 내에 포함된 코드 또는 명령으로 표현된 기능을 수행하기 위 해 물리적으로 구조화된 회로를 갖는, 하드웨어에 내장된 데이터 처리 장치를 의미할 수 있다. 일 예에서, 프로 세서는 마이크로프로세서(microprocessor), 중앙처리장치(central processing unit: CPU), 프로세서 코어 (processor core), 멀티프로세서(multiprocessor), ASIC(application-specific integrated circuit), FPGA(field programmable gate array) 등의 형태로 구현될 수 있으나, 본 발명의 범위가 이에 한정되는 것은 아니다. 도 1은 본 발명의 일 실시예에 따른 감정 인식 로봇 장치(이하, “로봇 장치”이라 함)의 구성을 도시한 블록도이고, 도 2는 로봇 장치가 사용자의 감정을 인식하고, 인식된 감정에 따라 동작을 제어하는 것에 대 한 일례를 나타낸 도면이다. 도 2 및 도 3을 함께 참조하면, 로봇 장치는 카메라, 적어도 하나의 프로세서 및 메모리를 포함하고, 통신 모듈, 데이터베이스 및 로봇 장치의 동작을 수행하는 구성들을 더 포함할 수 있 다. 통신 모듈은 외부 장치 또는 서버와 정보 송수신을 수행하여 사용자 감정 정보를 인식하기 위해 필요한 데 이터와 인식한 감정 정보를 송수신할 수 있다. 데이터베이스는 카메라를 통해 획득한 이미지에서 사용자 감정 정보를 도출하고, 감정 정보를 기초로 로봇 장치의 동작 속도 및 동작 가속도를 제어하기 위해 필요한 데이터가 저장되는 곳일 수 있다. 데이터 베이스는 메모리의 일부 영역에 구축되거나 별도의 하드웨어로 구현될 수 있다. 카메라는 로봇 장치 주변의 사람을 촬영한다. 카메라는 사람에 대해 연속적으로 이미지를 획득 할 수 있다. 프로세서는 메모리에 저장된 코드에 따라 동작을 수행한다. 메모리는 프로세서와 전기적으로 연결되고, 프로세서에서 수행되는 적어도 하나의 코드가 저장 된다. 메모리는 프로세서를 통해 실행될 때 프로세서가 다음과 같은 기능 및 절차들을 수행하도 록 야기하는 코드가 저장된다. 메모리에는 카메라로부터 사용자의 얼굴이 포함된 이미지를 획득하도록 야기하는 코드가 저장된 다. 메모리에는 획득한 이미지로부터 사용자의 얼굴을 인식하고, 인식된 얼굴의 표정을 분석하 여 사용자의 감정 정보를 생성하도록 야기하는 코드가 저장된다. 보다 상세하게는, 메모리에는 이미 지을 기설정된 크기로 편집하는 과정 및 이미지에 그레이 스케일(grayscale)을 수행하는 과정 중 적어도 하나 이상을 포함하는 전처리를 수행하도록 야기하는 코드가 저장된다. 메모리에는 전처리된 이미지 로부터 사용자의 얼굴을 인식하고, 감정 인식 모델을 이용하여 사용자의 인식된 얼굴의 표정을 토대로 감 정 정보를 생성하도록 야기하는 코드가 저장된다. 감정 정보는 복수의 감정 상태들 및 감정 상태들 각각에 대한 강도(Intensity)를 포함한다. 예를 들면, 감정 상태들은 기쁨, 슬픔, 놀람, 화남, 두려움, 혐오 등이 있을 수 있다. 하나 이상의 감정 상태 각각에 대한 강도(Intensity)는 감정 상태와 관련된 힘이나 활력의 정도를 나타내 는 것으로서, 값, 퍼센트, 단계 등 다양하게 표현될 수 있다. 강도에 대한 값, 퍼센트 또는 단계가 높을수록 해 당 감정 상태의 정도가 높다고 판단할 수 있다. 감정 인식 모델은 학습용 얼굴 표정 이미지, 학습용 얼굴 표정 이미지에 대한 감정 정보를 포함하는 학습 데이터를 기초로, 특정 얼굴 이미지로부터 얼굴 표정을 분석하여 특 정 얼굴 이미지에 대한 감정 정보를 출력하도록 훈련된 인공지능 모델이다. 메모리에는 감정 정보를 기초로 로봇 장치의 동작 속도 및 동작 가속도 중 적어도 하나 이상을 제어하도록 야기하는 코드가 저장된다. 보다 상세하게는, 메모리에는 감정 상태들 각각의 강도를 고려하여 감정 상태들 중 주요 감정 상태를 선정하도록 야기하는 코드가 저장된다. 예를 들면, 복수의 감정 상태 각 각에 대한 강도 값들 중 가장 큰 값과 대응되는 감정 상태를 주요 감정 상태로 선정한다. 메모리에는 주요 감정 상태에 대응되는 로봇 장치의 최대 동작 속도 및 최대 동작 가속도를 포함하는 감정 동작 프로파일, 로봇 장치의 중립 속도 및 중립 가속도를 포함하는 중립 동작 프로파일 및 주요 감정 상태의 강도를 토대로 로봇 장치의 최종 동작 프로파일을 설정하도록 야기하는 코드가 저장된다. 최 종 동작 프로파일의 동작 속도 및 동작 가속도는 아래와 같이 나타낼 수 있다. 최종 동작 프로파일의 동작 속도 = 중립 속도 + (주요 감정 상태에 따른 감정 동작 프로파일의 최대 동작 속도 - 중립 속도) x 주요 감정 상태의 강도 최종 동작 프로파일의 동작 가속도 = 중립 가속도 + (주요 감정 상태에 따른 감정 동작 프로파일의 최대 동작 가속도 - 중립 가속도) x 주요 감정 상태의 강도 최종 동작 프로파일의 동작 속도 및 동작 가속도 도출 예시는 도 3에서 후술하고자 한다. 메모리는 최종 동작 프로파일에 따라, 로봇 장치의 동작 속도 및 동작 가속도를 제어하도록 야기하는 코드가 저장된다. 도 3은 사용자의 감정 상태에 따라 기설정된 동작 프로파일에 대한 일례를 나타낸 도면이다. 도 2 및 도 3을 함께 참조하면, 로봇 장치에는 사용자의 감정 상태별 동작 프로파일과 중립 동작 프로파일 이 기설정되어 저장되어 있다. 중립 동작 프로파일은 로봇 장치에 대한 기준 속도 및 기준 가속 도를 나타내는 동작 프로파일이다. 예를 들면, 사용자의 감정 상태별 동작 프로파일은 기쁨 상태 동작 프로파일 , 화남 상태 동작 프로파일, 두려움 상태 동작 프로파일, 혐오 상태 동작 프로파일, 슬픔 상태 동작 프로파일 및 놀람 상태 동작 프로파일을 포함할 수 있다. 최종 동작 프로파일의 동작 속도 및 동작 가속도를 도출하는 것에 대한 예를 들면, 로봇 장치가 주요 감정 상태로 기쁨 상태를 선정하 고, 기쁨 상태에 대한 강도는 98%이고, 기설정된 중립 동작 프로파일의 중립 속도는 50%이고, 중립 가속도는 50%이고, 로봇 장치에 기설정된 기쁨 상태 동작 프로파일의 최대 동작 속도가 70%, 최대 동작 가속도 가 75%이면, 최종 동작 프로파일의 동작 속도는 69.6%, 동작 가속도는 75.5%로 아래와 같이 도출된다. 50%중립 속도 + (70%기쁨 상태의 최대 동작 속도 - 50%중립 속도)*0.98기쁨 상태에 대한 강도 = 69.6%최종 동작 프로파일의 동작 속도 50%중립 가속도 + (75%기쁨 상태의 최대 동작 가속도 - 50%중립 가속도)*0.98기쁨 상태에 대한 강도 = 75.5%최종 동작 프로파일의 동작 가속도 도 4는 감정 인식 로봇 장치의 다양한 구현 예시를 나타낸 도면이고, 도 4의 (a)는 로봇 장치가 강아 지 로봇일 경우에 대한 일례를 나타낸 도면이고, 도 4의 (b)는 로봇 장치가 공장 등에 활용되는 다관절 로 봇 장치일 경우에 대한 일례를 나타낸 도면이다. 도 1 및 도 4의 (a)를 함께 참조하면, 로봇 장치가 강아지 로봇일 경우, 로봇 장치는 몸체부, 몸체부와 연결된 헤드부, 몸체부와 연결된 하나 이상의 다리부를 포함한다. 헤드부는 카메라, 회전 가능한 회전축 및 헤드부 동작을 위한 엑츄에이터를 포함하고, 입출력 모듈을 더 포함할 수 있다. 다리부는 복수의 관절부 및 관절부를 동작시키기 위한 엑츄에이터를 포함한다. 강아지 로봇인 로봇 장치는 카메라를 통해 이미지를 획득하고, 획득된 이미지로부터 인식된 사용자의 얼굴 영역을 토대로 사용자의 감정 정보를 도출하고, 감정 정보를 기초로 로봇 장치의 동작 속도 및 동작 가속도를 제어한다. 사용자의 감정 정보가 기쁨으로 도출되면, 로봇 장치는 사용자에게 달려가는 동작, 로 봇 장치의 헤드부의 동작에 대한 속도 및 가속도를 사용자의 감정 정보를 기초로 도출된 최종 동작 프로파 일에 따라 헤드부의 엑츄에이터와 다리부의 엑츄에이터를 제어한다. 예를 들면, 사용자의 감정이 기 쁨이면, 강아지 로봇인 로봇 장치는 모든 동작을 평소보다 빠르게 수행하고, 사용자의 감정이 슬픔이면, 모든 동작을 평소보다 느리게 수행하여 사용자의 감정에 깊이 공감하는 동작을 수행할 수 있다. 도 1 및 도 4의 (a)를 함께 참조하면, 로봇 장치가 공장 등에 활용되는 다관절 로봇 장치일 경우, 로봇 장 치는 물건을 파지하는 그립부, 복수의 관절 구조 및 관절 구조가 회전 가능하도록 하는 회전 가이드를 포 함하는 몸체부 더 포함할 수 있다. 로봇 장치는 카메라를 통해 작업자의 이미지를 획득하고, 이미지에서 인식된 작업자의 얼굴 영역을 토대로 작업자의 감정 정보를 도출한다. 로봇 장치는 작업자의 감정 정보를 기초로 로봇 장치의 동작 속도 및 동작 가속도를 제어한다. 예를 들면, 로봇 장치가 도출한 작업자의 감정 상태가 슬픔 상태일 경우, 로봇 장치는 물건을 작업자에게 전달하는 동작 등에 대한 동작 속도 및 동작 가속도를 줄임으로써, 작업자의 감정 상태에 따라 작업자와 협업하도록 할 수 있다. 이를 통해, 로봇 장치는 작업자의 감정을 고 려하여 작업자의 감정을 해하지 않으면서, 작업을 보조하는 역할을 수행할 수 있다. 도 5는 본 발명의 다른 실시예에 따른 감정 인식 기반 로봇 동작 제어 방법을 설명하는 동작 흐름도이고, 도 6 및 도 7은 감정 인식 기반 로봇 동작 제어 방법의 단계들이 포함하는 세부 단계들을 나타낸 흐름도이다. 이하에 서 도 5 내지 도 7을 참조하여, 감정 인식 기반 로봇 동작 제어 방법을 설명하도록 한다. 이하에서 설명될 감정 인식 기반 로봇 동작 제어 방법의 각 단계들은 앞서 도 1 내지 도 4를 참조하여 설명한 로봇 장치에 의해 수행될 수 있다. 따라서, 앞서 도 1 내지 도 4를 참조하여 설명한 본 발명의 실시예에 대한 내용은 이하에서 설 명될 실시예에도 동일하게 적용될 수 있으며, 이하에서 상술한 설명과 중복되는 내용은 생략하도록 한다. 이하 에서 설명되는 단계들은 반드시 순서대로 수행되어야 하는 것은 아니고, 단계들의 순서는 다양하게 설정될 수 있으며, 단계들은 거의 동시에 수행될 수도 있다. 도 5를 참조하면, 감정 인식 기반 로봇 동작 제어 방법은 각 단계가 카메라를 포함하는 로봇의 프로세서에 의해 수행되는 방법으로서, 이미지 획득 단계(S1100), 감정 정보 도출 단계(S1200) 및 로봇 동작 제어 단계(S1300)를 포함하고, 로봇 동작 재설정 단계(S1400)를 더 포함할 수 있다. 이미지 획득 단계(S1100)는 로봇의 카메라로부터 사용자의 얼굴이 포함된 이미지를 획득하는 단계이다. 감정 정 보 도출 단계(S1200)는 이미지로부터 사용자의 얼굴을 인식하고, 인식된 얼굴의 표정을 분석하여 사용자의 감정 정보를 생성하는 단계이다. 감정 정보는 복수의 감정 상태들 및 감정 상태들 각각에 대한 강도를 포함한다. 감 정 상태는 기쁨, 슬픔, 놀람, 화남, 두려움 및 혐오 중 적어도 하나 이상을 포함한다. 로봇 동작 제어 단계 (S1300)는 감정 정보를 기초로 로봇의 동작 속도 및 동작 가속도 중 적어도 하나 이상을 제어하는 단계이다. 로 봇 동작 재설정 단계(S1400)는 이미지 획득 단계(S1100) 내지 로봇 동작 제어 단계(S1300)를 반복하여 사용자의 감정 상태 및 강도가 실시간으로 변경되는 경우, 변경된 감정 상태 및 강도에 기초하여 로봇의 동작 속도 및 가 속도 중 적어도 하나 이상을 재설정하는 단계이다. 도 6을 참조하면, 감정 정보 도출 단계(S1200)는 이미지 전처리 단계(S1210) 및 얼굴 인식 기반 감정 정보 도출 단계(S1220)를 포함한다. 이미지 전처리 단계(S1210)는 이미지를 기설정된 크기로 편집하는 과정 및 이미지에 그레이스케일을 적용하는 과정 중 적어도 하나 이상을 포함하는 전처리를 수행하는 단계이다. 얼굴 인식 기반 감정 정보 도출 단계(S1220)는 전처리된 이미지로부터 사용자의 얼굴을 인식하고, 감정 인식 모 델을 이용하여 인식된 얼굴의 표정을 토대로 감정 정보를 도출하는 단계이다. 감정 인식 모델은 학습용 얼굴 표 정 이미지, 상기 학습용 얼굴 표정 이미지에 대한 감정 정보를 포함하는 학습 데이터를 기초로, 특정 얼굴 이미 지로부터 얼굴 표정을 분석하여 상기 특정 얼굴 이미지에 대한 감정 정보를 출력하도록 훈련된 인공지능 모델이 다. 도 7을 참조하면, 로봇 동작 제어 단계(S1300)는 주요 감정 상태 선정 단계(S1310), 최종 동작 프로파일 설정 단계(S1320) 및 로봇 동작 속도 및 가속도 제어 단계(S1330)를 포함한다. 주요 감정 상태 선정 단계(S1310)는 감정 상태들 각각의 강도를 고려하여 감정 상태들 중 주요 감정 상태를 선 정하는 단계이다. 최종 동작 프로파일 설정 단계(S1320)는 주요 감정 상태에 따른 로봇의 최대 동작 속도 및 최대 동작 가속도를 포함하는 감정 동작 프로파일, 로봇의 중립 속도 및 중립 가속도를 포함하는 중립 동작 프로 파일 및 주요 감정 상태의 강도를 토대로 최종 동작 프로파일을 설정하는 단계이다. 로봇 동작 속도 및 가속도 제어 단계(S1330)는 최종 동작 프로파일에 따라, 로봇의 동작 속도 및 동작 가속도를 제어하는 단계이다. 이상 지금까지 설명한 본 발명의 실시예들에 따른 사용자 감정 인식을 기반으로 로봇 장치의 동작 제어 방법은, 컴퓨터에 의해 실행되는 프로그램 모듈과 같은 컴퓨터에 의해 실행가능한 명령어를 포함하는 기록 매체의 형태 로도 구현될 수 있다. 컴퓨터 판독 가능 매체는 컴퓨터에 의해 액세스될 수 있는 임의의 가용 매체일 수 있고, 휘발성 및 비휘발성 매체, 분리형 및 비분리형 매체를 모두 포함한다. 또한, 컴퓨터 판독가능 매체는 컴퓨터 저 장 매체를 포함할 수 있다. 컴퓨터 저장 매체는 컴퓨터 판독가능 명령어, 데이터 구조, 프로그램 모듈 또는 기 타 데이터와 같은 정보의 저장을 위한 임의의 방법 또는 기술로 구현된 휘발성 및 비휘발성, 분리형 및 비분리 형 매체를 모두 포함한다."}
{"patent_id": "10-2023-0008896", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "본 발명이 속하는 기술분야의 통상의 지식을 가진 자는 상술한 설명을 기초로 본 발명의 기술적 사상이나 필수 적인 특징을 변경하지 않고서 다른 구체적인 형태로 쉽게 변형이 가능하다는 것을 이해할 수 있을 것이다. 그러 므로 이상에서 기술한 실시예들은 모든 면에서 예시적인 것이며 한정적이 아닌 것으로 이해되어야만 한다. 본 발명의 범위는 후술하는 특허청구범위에 의하여 나타내어지며, 특허청구범위의 의미 및 범위 그리고 그 균등 개 념으로부터 도출되는 모든 변경 또는 변형된 형태가 본 발명의 범위에 포함되는 것으로 해석되어야 한다. 본원 의 범위는 상기 상세한 설명보다는 후술하는 특허청구범위에 의하여 나타내어지며, 특허청구범위의 의미 및 범 위 그리고 그 균등 개념으로부터 도출되는 모든 변경 또는 변형된 형태가 본원의 범위에 포함되는 것으로 해석 되어야 한다."}
{"patent_id": "10-2023-0008896", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일 실시예에 따른 감정 인식 로봇 장치의 구성을 도시한 블록도이다. 도 2는 도 1에 도시된 감정 인식 로봇 장치가 사용자의 감정을 인식하고, 인식된 감정에 따라 동작을 제어하는 것에 대한 일례를 나타낸 도면이다. 도 3은 사용자의 감정 상태에 따라 기설정된 동작 프로파일에 대한 일례를 나타낸 도면이다. 도 4는 도 1에 도시된 감정 인식 로봇 장치의 다양한 구현 예시를 나타낸 도면이다. 도 5는 본 발명의 다른 실시예에 따른 감정 인식 기반 로봇 동작 제어 방법을 설명하는 동작 흐름도이다. 도 6 및 도 7은 도 5에 도시된 감정 인식 기반 로봇 동작 제어 방법의 단계들이 포함하는 세부 단계들을 나타낸 흐름도이다."}
