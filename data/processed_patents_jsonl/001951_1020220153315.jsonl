{"patent_id": "10-2022-0153315", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0073115", "출원번호": "10-2022-0153315", "발명의 명칭": "사용자 입력에 기반하여 사운드를 제공하는 전자 장치 및 그 동작 방법", "출원인": "주식회사 버시스", "발명자": "이성욱"}}
{"patent_id": "10-2022-0153315", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "전자 장치의 동작 방법으로서,음원 파일과 연관된 복수의 오디오 소스들을 획득하는 동작;상기 복수의 오디오 소스들 중 적어도 일부를 제어하기 위한 복수의 오브젝트들을 표시하는 동작;상기 복수의 오디오 소스들 중 적어도 일부에 기반하여 제1 사운드를 제공하는 동작;상기 사운드를 제공하는 동안, 복수의 시간들 별로 상기 복수의 오브젝트들 중 적어도 일부를 제어하기 위한 사용자의 인터랙션을 획득하는 동작; 및상기 복수의 시간들 별 상기 사용자의 인터랙션에 대한 정보를 포함하는 파일을 획득하는 동작;을, 포함하는,동작 방법."}
{"patent_id": "10-2022-0153315", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1 항에 있어서,서버로 상기 음원 파일을 전송한 것에 기반하여, 상기 서버로부터 상기 복수의 오디오 소스들을 주기적으로 획득하는 동작;을, 더 포함하는,동작 장법."}
{"patent_id": "10-2022-0153315", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1 항에 있어서,상기 복수의 오브젝트들 중 적어도 일부의 위치의 이동에 기반하여, 상기 복수의 오디오 소스들 중 적어도 일부의 속성을 제어함에 기반하여, 제2 사운드를 제공하는 동작;을, 더 포함하는,동작 방법."}
{"patent_id": "10-2022-0153315", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1 항에 있어서,상기 파일은, 상기 복수의 시간들 별 상기 사용자의 인터랙션에 대한 정보, 및 상기 복수의 오디오 소소들 중적어도 일부를 포함하는,동작 방법."}
{"patent_id": "10-2022-0153315", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4 항에 있어서,상기 복수의 시간들 별 상기 사용자의 인터랙션에 대한 정보는, 상기 복수의 오디오 소스들 중 적어도 일부를재생하는 동안, 상기 복수의 오브젝트들 중 적어도 일부를 제어함에 기반하여 복수의 오디오 소스들 중 적어도일부의 속성을 제어하도록 설정되는,공개특허 10-2023-0073115-3-동작 방법."}
{"patent_id": "10-2022-0153315", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5 항에 있어서, 상기 파일은 상기 복수의 오브젝트들과 연관된 화면을 식별하기 위한 식별 정보를 더 포함하고,상기 파일에 기반하여, 상기 식별 정보에 대응하는 상기 복수의 오브젝트들을 표시하는 동작;을 더 포함하는,동작 방법."}
{"patent_id": "10-2022-0153315", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "서버의 동작 방법으로서,전자 장치로부터 음원 파일을 수신하는 동작;상기 음원 파일과 연관된 복수의 오디오 소스들을 획득하는 동작;상기 전자 장치로, 상기 복수의 오디오 소스들 중 적어도 일부를 제어하기 위한 복수의 오브젝트들을 포함하는화면과 함께 상기 복수의 오디오 소스들 중 적어도 일부를 제공하는 동작;상기 전자 장치로부터, 복수의 시간들 별로 상기 복수의 오브젝트들 중 적어도 일부를 제어하기 위한 사용자의인터랙션을 획득하는 동작; 및상기 복수의 시간들 별 상기 사용자의 인터랙션에 대한 정보를 포함하는 파일을 획득하고, 상기 파일을 저장하는 동작;을, 포함하는,동작 방법."}
{"patent_id": "10-2022-0153315", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7 항에 있어서,상기 파일은, 상기 복수의 시간들 별 상기 사용자의 인터랙션에 대한 정보, 및 상기 복수의 오디오 소소들 중적어도 일부를 포함하는,동작 방법."}
{"patent_id": "10-2022-0153315", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8 항에 있어서,상기 복수의 시간들 별 상기 사용자의 인터랙션에 대한 정보는, 상기 복수의 오디오 소스들 중 적어도 일부를재생하는 동안, 상기 복수의 오브젝트들 중 적어도 일부를 제어함에 기반하여 복수의 오디오 소스들 중 적어도일부의 속성을 제어하도록 설정되는,동작 방법."}
{"patent_id": "10-2022-0153315", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제7 항에 있어서,상기 전자 장치로부터 다른 외부 전자 장치로 상기 파일을 공유하기 위한 요청을 수신하는 동작; 및상기 외부 전자 장치로, 상기 파일에 접근하기 위한 링크 정보를 송신하는 동작;을 더 포함하는,공개특허 10-2023-0073115-4-동작 방법."}
{"patent_id": "10-2022-0153315", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "다양한 실시예들에 따르면, 전자 장치의 동작 방법으로서, 복수의 오디오 소스들에 대응하는 음악 파일을 획득하 는 동작; 적어도 하나의 오브젝트를 포함하는 제1 화면을 표시하면서, 상기 음악 파일과 연관된 제1 재생 시간에 대응하는 제1 주파수 스펙트럼을 갖는 제1 사운드를 출력하는 동작; 상기 제1 사운드를 출력하는 동안, 상기 적 (뒷면에 계속)"}
{"patent_id": "10-2022-0153315", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는, 사용자 입력에 기반하여 사운드를 제공하는 전자 장치 및 그 동작 방법에 관한 것이다."}
{"patent_id": "10-2022-0153315", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "저장매체를 이용하여 음악을 기록하고 감상하기 시작한 이래로 음악은 수동적/피동적 감상의 대상이 되었으며, 능동적이고, 주도적으로 음악에 참여하는 것은 음악적 전문가의 영역으로 치부되어왔다. 또한, 초창기 저장매체로 이용되었던 레코드 판의 물리적 한계로 인해 통념적인 음악의 길이가 정해졌으며, 레 코드 판의 물리적 한계를 벗어난 디지털 음악의 시대에서도 통념적인 음악의 길이는 대중적인 음악의 길이로 자 리매김하게 되었다. 결국, 현대 사회를 살아가는 대다수 음악의 수요자들은 한정된 시간적 길이 내에서 주어진 음악의 수동적/피동 적 감상이라는 한정된 역할에 머무를 수밖에 없게 되어 원하는 시간만큼 능동적이고 주도적으로 음악에 참여하 는 음악 본연의 즐거움 중 하나를 잃게 되었다. 따라서, 음악의 수요자들에게 음악 본연의 즐거움을 되돌려 놓기 위해서는 음악에 대한 참여의 장벽을 낮추고, 한정된 오디오 소스를 이용하되 통념적인 음악의 길이를 탈피하도록 치밀하게 설계된 오디오 소스 재생 방법과 이를 이용한 음악 어플리케이션이 필요할 수 있다."}
{"patent_id": "10-2022-0153315", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "다양한 실시예들에 따른, 일 과제는 사용자에게 자연스러운 음악적 생동감을 부여하기 위한 실감형 오디오 소스 재생 방법을 제공하는 것이다. 다양한 실시예들에 따른, 일 과제는 사용자와의 인터랙션을 기초로 음악에 생동감을 부여하기 위한 실감형 오디 오 소스 재생 방법을 제공하는 것이다. 다양한 실시예들에 따른, 일 과제는 사용자에게 다양한 음악적 경험을 제공하기 위한 실감형 오디오 소스 재생 방법을 제공하는 것이다. 다양한 실시예들에 따른, 일 과제는 사용자에게 주도적이고 다양한 음악적 경험을 제공하기 위한 실감형 오디오 소스 재생 방법을 제공하는 것이다. 다양한 실시예들에 따른, 일 과제는 오디오 소스 세트를 비선형적으로 재생하기 위한 오디오 소스 재생 방법을 제공하는 것이다. 본 발명의 해결하고자 하는 과제들이 상술한 해결 과제들로 제한되는 것은 아니며, 언급되지 아니한 해결 과제"}
{"patent_id": "10-2022-0153315", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 2, "content": "들은 본 명세서 및 첨부된 도면으로부터 본 발명이 속하는 기술분야에서 통상의 지식을 가진 자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2022-0153315", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "다양한 실시예들에 따르면, 전자 장치의 동작 방법으로서, 복수의 오디오 소스들에 대응하는 음악 파일을 획득 하는 동작; 적어도 하나의 오브젝트를 포함하는 제1 화면을 표시하면서, 상기 음악 파일과 연관된 제1 재생 시 간에 대응하는 제1 주파수 스펙트럼을 갖는 제1 사운드를 출력하는 동작; 상기 제1 사운드를 출력하는 동안, 상 기 적어도 하나의 오브젝트에 대한 사용자의 입력을 식별하는 동작; 상기 식별된 입력에 의한 제1 조건이 만족 되는 경우: 상기 식별된 입력이 제1 입력인 경우, 제1 시각적 이펙트가 적용된 제2 화면을 표시하면서 제2 주파 수 스펙트럼을 갖는 제2 사운드를 출력하는 동작; 및 상기 식별된 입력이 제2 입력인 경우, 제2 시각적 이펙트 가 적용된 제3 화면을 표시하면서 제3 주파수 스펙트럼을 갖는 제3 사운드를 출력하는 동작;을 포함하고, 상기 식별된 입력에 의한 제2 조건이 만족되는 경우: 상기 음악 파일과 연관된 제2 재생 시간에 대응하는 제2 주파수 스펙트럼을 갖는 제2 사운드를 출력하는 동작;을 포함하는, 동작 방법이 제공될 수 있다.다양한 실시예들에 따르면, 전자 장치의 동작 방법으로서, 복수의 오디오 소스들에 대응하는 음악 파일을 획득 하는 동작; 적어도 하나의 제1 오브젝트를 포함하는 제1 화면을 표시하면서, 상기 음악 파일에 기반하여 제1 주 파수 스펙트럼을 갖는 제1 사운드를 출력하는 동작; 상기 제1 사운드를 출력하면서 상기 적어도 하나의 오브젝 트에 대한 사용자 입력이 수신되지 않는 동안, 특정 종류의 이벤트를 식별하는 동작; 상기 식별된 이벤트의 종 류가 사운드를 제어하기 위한 제1 종류인 경우, 상기 제1 사운드의 제1 청각적 속성을 변경하고, 상기 제1 청각 적 속성의 변경에 기반하여 상기 제1 오브젝트의 제1 시각적 속성을 변경하는 동작; 및 상기 식별된 이벤트의 종류가 화면을 제어하기 위한 제2 종류인 경우, 상기 적어도 하나의 제1 오브젝트의 제2 시각적 속성을 변경하 고, 상기 제2 시각적 속성의 변경에 기반하여 상기 제1 사운드의 제2 청각적 속성을 변경하는 동작;을 포함하는, 동작 방법이 제공될 수 있다. 상기 적어도 하나의 제1 오브젝트에 대한 사용자 입력과 연관된 특정 모드 전환 조건의 만족 여부를 식별하는 동작; 상기 모드 전환 조건이 만족되는 경우: 상기 사용자 입력에 의해 제1 조건이 만족되는 경우: 상기 사용자 입력이 제1 입력인 경우, 제1 시각적 이펙트가 적용된 제2 화면을 표시하면서 제2 주파수 스펙트럼을 갖는 제2 사운드를 출력하는 동작; 및 상기 사용자 입력이 제2 입력인 경우, 제2 시각적 이펙트가 적용된 제3 화면을 표 시하면서 제3 주파수 스펙트럼을 갖는 제3 사운드를 출력하는 동작; 및 상기 사용자 입력에 의한 제2 조건이 만 족되는 경우: 상기 음악 파일과 연관된 제2 시간 구간에 대응하는 제2 주파수 스펙트럼을 갖는 제2 사운드를 출 력하는 동작;를 포함하는, 상기 사용자 입력이 식별되지 않는 경우: 이벤트를 식별하는 동작; 상기 식별된 이벤 트의 종류가 화면을 제어하기 위한 제 1 종류인 경우, 상기 적어도 하나의 제1 오브젝트의 제1 시각적 속성을 변경하고, 상기 시각적 속성의 변경에 기반하여 상기 제1 사운드의 제1 청각적 속성을 변경하는 동작; 및 상기 식별된 이벤트의 종류가 사운드를 제어하기 위한 제 2 종류인 경우, 상기 제1 사운드의 제2 청각적 속성을 변경 하고, 상기 청각적 속성의 변경에 기반하여 상기 제1 오브젝트의 제2 시각적 속성을 변경하는 동작;을 포함하는, 동작 방법이 제공될 수 있다."}
{"patent_id": "10-2022-0153315", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 2, "content": "다양한 실시예들에 따른, 과제의 해결 수단이 상술한 해결 수단들로 제한되는 것은 아니며, 언급되지 아니한 해"}
{"patent_id": "10-2022-0153315", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 3, "content": "결 수단들은 본 명세서 및 첨부된 도면으로부터 본 발명이 속하는 기술분야에서 통상의 지식을 가진 자에게 명 확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2022-0153315", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "다양한 실시예들에 따르면, 사용자와의 인터랙션을 기초로 사용자에게 한정된 시공간 내에서 자연스러운 음악적 변화를 유도하고, 자유로운 음악적 변화를 허용하여 생동감을 부여하기 위한 실감형 오디오 소스 재생 방법이 제공될 수 있다. 다양한 실시예들에 따르면, 사용자와의 인터랙션을 기초로 오디오 소스에 대한 선택적 변화를 부여하여 사용자 에게 주도적 음악적 경험을 만들어 주되, 오디오 소스에 대한 비선택적 변화를 부여하여 사용자에게 다양한 음 악적 경험을 제공하기 위한 실감형 오디오 소스 재생 방법이 제공될 수 있다. 다양한 실시예들에 따르면, 사용자와의 인터랙션을 기초로 오디오 소스에 대한 지속적 변화 가능성을 부여하여 사용자에게 주도적 음악적 경험을 만들어주되, 오디오 소스에 대한 임의적 변화 가능성을 부여하여 사용자에게 다양한 음악적 경험을 만들어주기 위한 실감형 오디오 소스 재생 방법이 제공될 수 있다. 다양한 실시예들에 따르면, 사용자와의 인터랙션을 기초로 적어도 하나의 오디오 소스 세트를 비선형적으로 재 생하기 위한 오디오 소스 재생 방법이 제공될 수 있다."}
{"patent_id": "10-2022-0153315", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 2, "content": "본 발명의 효과들이 상술한 효과들로 제한되는 것은 아니며, 언급되지 아니한 효과들은 본 명세서 및 첨부된 도"}
{"patent_id": "10-2022-0153315", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 3, "content": "면으로부터 본 발명이 속하는 기술분야에서 통상의 지식을 가진 자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2022-0153315", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 문서에 개시된 다양한 실시예들에 따른 전자 장치는 다양한 형태의 장치가 될 수 있다. 전자 장치는, 예를 들면, 휴대용 통신 장치(예: 스마트폰), 컴퓨터 장치, 휴대용 멀티미디어 장치, 휴대용 의료 기기, 카메라, 웨 어러블 장치, 또는 가전 장치를 포함할 수 있다. 본 문서의 실시예에 따른 전자 장치는 전술한 기기들에 한정되 지 않는다. 본 문서의 다양한 실시예들 및 이에 사용된 용어들은 본 문서에 기재된 기술적 특징들을 특정한 실시예들로 한 정하려는 것이 아니며, 해당 실시예의 다양한 변경, 균등물, 또는 대체물을 포함하는 것으로 이해되어야 한다. 도면의 설명과 관련하여, 유사한 또는 관련된 구성요소에 대해서는 유사한 참조 부호가 사용될 수 있다. 아이템 에 대응하는 명사의 단수 형은 관련된 문맥상 명백하게 다르게 지시하지 않는 한, 상기 아이템 한 개 또는 복수 개를 포함할 수 있다. 본 문서에서, \"A 또는 B\", \"A 및 B 중 적어도 하나\", \"A 또는 B 중 적어도 하나\", \"A, B 또는 C\", \"A, B 및 C 중 적어도 하나\", 및 \"A, B, 또는 C 중 적어도 하나\"와 같은 문구들 각각은 그 문구들 중 해당하는 문구에 함께 나열된 항목들 중 어느 하나, 또는 그들의 모든 가능한 조합을 포함할 수 있다. \"제1\", \"제2\", 또는 \"첫째\" 또는 \"둘째\"와 같은 용어들은 단순히 해당 구성요소를 다른 해당 구성요소와 구분하기 위 해 사용될 수 있으며, 해당 구성요소들을 다른 측면(예: 중요성 또는 순서)에서 한정하지 않는다. 어떤(예: 제 1) 구성요소가 다른(예: 제2) 구성요소에, \"기능적으로\" 또는 \"통신적으로\"라는 용어와 함께 또는 이런 용어 없 이, \"커플드\" 또는 \"커넥티드\"라고 언급된 경우, 그것은 상기 어떤 구성요소가 상기 다른 구성요소에 직접적으 로(예: 유선으로), 무선으로, 또는 제3 구성요소를 통하여 연결될 수 있다는 것을 의미한다. 본 문서의 다양한 실시예들에서 사용된 용어 \"모듈\"은 하드웨어, 소프트웨어 또는 펌웨어로 구현된 유닛을 포함 할 수 있으며, 예를 들면, 로직, 논리 블록, 부품, 또는 회로와 같은 용어와 상호 호환적으로 사용될 수 있다. 모듈은, 일체로 구성된 부품 또는 하나 또는 그 이상의 기능을 수행하는, 상기 부품의 최소 단위 또는 그 일부 가 될 수 있다. 예를 들면, 일 실시예에 따르면, 모듈은 ASIC(application-specific integrated circuit)의 형 태로 구현될 수 있다. 본 문서의 다양한 실시예들은 기기(machine)(예: 전자 장치) 의해 읽을 수 있는 저장 매체(storage medium)(예: 내장 메모리) 또는 외장 메모리)에 저장된 하나 이상의 명령어들을 포함하는 소프트웨어(예: 프로그램))로서 구 현될 수 있다. 예를 들면, 기기(예: 전자 장치)의 프로세서(예: 프로세서)는, 저장 매체로부터 저장된 하나 이 상의 명령어들 중 적어도 하나의 명령을 호출하고, 그것을 실행할 수 있다. 이것은 기기가 상기 호출된 적어도 하나의 명령어에 따라 적어도 하나의 기능을 수행하도록 운영되는 것을 가능하게 한다. 상기 하나 이상의 명령 어들은 컴파일러에 의해 생성된 코드 또는 인터프리터에 의해 실행될 수 있는 코드를 포함할 수 있다. 기기로 읽을 수 있는 저장 매체는, 비일시적(non-transitory) 저장 매체의 형태로 제공될 수 있다. 여기서, ‘비일시적 ’은 저장 매체가 실재(tangible)하는 장치이고, 신호(signal)(예: 전자기파)를 포함하지 않는다는 것을 의미할 뿐이며, 이 용어는 데이터가 저장 매체에 반영구적으로 저장되는 경우와 임시적으로 저장되는 경우를 구분하지 않는다. 일 실시예에 따르면, 본 문서에 개시된 다양한 실시예들에 따른 방법은 컴퓨터 프로그램 제품(computer program product)에 포함되어 제공될 수 있다. 컴퓨터 프로그램 제품은 상품으로서 판매자 및 구매자 간에 거래될 수 있 다. 컴퓨터 프로그램 제품은 기기로 읽을 수 있는 저장 매체(예: compact disc read only memory(CD-ROM))의형태로 배포되거나, 또는 어플리케이션 스토어(예: 플레이 스토어TM)를 통해 또는 두 개의 사용자 장치들(예: 스 마트 폰들) 간에 직접, 온라인으로 배포(예: 다운로드 또는 업로드)될 수 있다. 온라인 배포의 경우에, 컴퓨터 프로그램 제품의 적어도 일부는 제조사의 서버, 어플리케이션 스토어의 서버, 또는 중계 서버의 메모리와 같은 기기로 읽을 수 있는 저장 매체에 적어도 일시 저장되거나, 임시적으로 생성될 수 있다. 다양한 실시예들에 따르면, 상기 기술한 구성요소들의 각각의 구성요소(예: 모듈 또는 프로그램)는 단수 또는 복수의 개체를 포함할 수 있으며, 복수의 개체 중 일부는 다른 구성요소에 분리 배치될 수도 있다. 다양한 실시 예들에 따르면, 전술한 해당 구성요소들 중 하나 이상의 구성요소들 또는 동작들이 생략되거나, 또는 하나 이상 의 다른 구성요소들 또는 동작들이 추가될 수 있다. 대체적으로 또는 추가적으로, 복수의 구성요소들(예: 모듈 또는 프로그램)은 하나의 구성요소로 통합될 수 있다. 이런 경우, 통합된 구성요소는 상기 복수의 구성요소들 각각의 구성요소의 하나 이상의 기능들을 상기 통합 이전에 상기 복수의 구성요소들 중 해당 구성요소에 의해 수행되는 것과 동일 또는 유사하게 수행할 수 있다. 다양한 실시예들에 따르면, 모듈, 프로그램 또는 다른 구성 요소에 의해 수행되는 동작들은 순차적으로, 병렬적으로, 반복적으로, 또는 휴리스틱하게 실행되거나, 상기 동 작들 중 하나 이상이 다른 순서로 실행되거나, 생략되거나, 또는 하나 이상의 다른 동작들이 추가될 수 있다. 다양한 실시예들에 따르면, 전자 장치의 동작 방법으로서, 복수의 오디오 소스들에 대응하는 음악 파일을 획득 하는 동작; 적어도 하나의 오브젝트를 포함하는 제1 화면을 표시하면서, 상기 음악 파일과 연관된 제1 재생 시 간에 대응하는 제1 주파수 스펙트럼을 갖는 제1 사운드를 출력하는 동작; 상기 제1 사운드를 출력하는 동안, 상 기 적어도 하나의 오브젝트에 대한 사용자의 입력을 식별하는 동작; 상기 식별된 입력에 의한 제1 조건이 만족 되는 경우: 상기 식별된 입력이 제1 입력인 경우, 제1 시각적 이펙트가 적용된 제2 화면을 표시하면서 제2 주파 수 스펙트럼을 갖는 제2 사운드를 출력하는 동작; 및 상기 식별된 입력이 제2 입력인 경우, 제2 시각적 이펙트 가 적용된 제3 화면을 표시하면서 제3 주파수 스펙트럼을 갖는 제3 사운드를 출력하는 동작;을 포함하고, 상기 식별된 입력에 의한 제2 조건이 만족되는 경우: 상기 음악 파일과 연관된 제2 재생 시간에 대응하는 제2 주파수 스펙트럼을 갖는 제2 사운드를 출력하는 동작;을 포함하는, 동작 방법이 제공될 수 있다. 다양한 실시예들에 따르면, 상기 음악 파일에 기반하여 상기 복수의 오디오 소스들을 획득하는 동작;을 포함하 고, 상기 복수의 오디오 소스들은 상기 음악 파일과 연관된 제1 재생 시간에 대응하는 제1 오디오 소스 셋, 및 상기 음악 파일과 연관된 제2 재생 시간에 대응하는 제2 오디오 소스 셋을 포함하는, 상기 제1 오디오 소스 셋 에 기반하여, 상기 제1 주파수 스펙트럼을 갖는 사익 제1 사운드를 출력하는 동작; 및 상기 제2 오디오 소스 셋 에 기반하여, 상기 제2 주파수 스펙트럼을 갖는 상기 제2 사운드를 출력하는 동작;을 포함하는, 동작 방법이 제 공될 수 있다. 다양한 실시예들에 따르면, 상기 식별된 입력에 의한 제1 조건이 만족되는 경우: 특정 오디오 소스를 출력하거 나, 및/또는 특정 오디오 효과를 적용함에 기반하여, 상기 제1 주파수 스펙트럼을 갖는 사익 제1 사운드를 출력 하는 동작; 상기 식별된 입력에 의한 제2 조건이 만족되는 경우: 재생 중인 오디오 소스 셋을 상기 제1 오디오 소스 셋에서 상기 제2 오디오 소스 셋으로 변경함에 기반하여, 상기 제2 주파수 스펙트럼을 갖는 상기 제2 사운 드를 출력하는 동작;을 포함하는, 동작 방법이 제공될 수 있다. 다양한 실시예들에 따르면, 상기 식별된 입력에 의한 상기 제1 조건 또는 상기 제2 조건의 만족 여부를 판단하 는 동작은: 상기 적어도 하나의 오브젝트에 대한 상기 식별된 입력의 횟수를 식별하는 동작; 상기 식별된 입력 의 횟수가 기-설정된 임계 횟수와 비교하는 동작; 및 상기 비교 결과에 기반하여, 상기 식별된 입력에 의한 상 기 제1 조건 또는 상기 제2 조건의 만족 여부를 판단하는 동작;을 포함하는, 동작 방법이 제공될 수 있다. 다양한 실시예들에 따르면, 상기 식별된 입력의 횟수가 상기 기-설정된 임계 횟수 보다 작은 경우, 상기 제1 조 건이 만족된 것으로 판단하는 동작; 및 상기 식별된 입력의 횟수가 상기 기-설정된 임계 횟수 보다 큰 경우, 상 기 제2 조건이 만족된 것으로 판단하는 동작;을 포함하는, 동작 방법이 제공될 수 있다. 다양한 실시예들에 따르면, 전자 장치의 동작 방법으로서, 복수의 오디오 소스들에 대응하는 음악 파일을 획득 하는 동작; 적어도 하나의 제1 오브젝트를 포함하는 제1 화면을 표시하면서, 상기 음악 파일에 기반하여 제1 주 파수 스펙트럼을 갖는 제1 사운드를 출력하는 동작; 상기 제1 사운드를 출력하면서 상기 적어도 하나의 오브젝 트에 대한 사용자 입력이 수신되지 않는 동안, 특정 종류의 이벤트를 식별하는 동작; 상기 식별된 이벤트의 종 류가 사운드를 제어하기 위한 제1 종류인 경우, 상기 제1 사운드의 제1 청각적 속성을 변경하고, 상기 제1 청각 적 속성의 변경에 기반하여 상기 제1 오브젝트의 제1 시각적 속성을 변경하는 동작; 및 상기 식별된 이벤트의 종류가 화면을 제어하기 위한 제2 종류인 경우, 상기 적어도 하나의 제1 오브젝트의 제2 시각적 속성을 변경하 고, 상기 제2 시각적 속성의 변경에 기반하여 상기 제1 사운드의 제2 청각적 속성을 변경하는 동작;을포함하는, 동작 방법이 제공될 수 있다. 다양한 실시예들에 따르면, 상기 음악 파일에 기반하여 상기 복수의 오디오 소스들을 획득하는 동작;을 포함하 고, 상기 복수의 오디오 소스들은 상기 음악 파일과 연관된 제1 재생 시간에 대응하는 제1 오디오 소스 셋, 및 상기 음악 파일과 연관된 제2 재생 시간에 대응하는 제2 오디오 소스 셋을 포함하고, 상기 제1 사운드를 출력하 는 중에 상기 제1 재생 시간에서 상기 제2 재생 시간으로 변경되는 경우, 상기 특정 종류의 이벤트를 식별하는 동작;을 포함하는, 동작 방법이 제공될 수 있다. 다양한 실시예들에 따르면, 상기 제1 사운드를 출력하는 중에, 상기 제1 사운드를 출력하는 시간과 연관된 정보 를 식별하는 동작; 및 상기 시간과 연관된 정보가 특정 조건을 만족하는 경우, 상기 특정 종류의 이벤트를 식별 하는 동작;을 포함하는, 동작 방법이 제공될 수 있다. 다양한 실시예들에 따르면, 상기 제1 사운드를 출력하는 중에, 상기 적어도 하나의 오브젝트의 이동이 식별되는 경우, 상기 특정 종류의 이벤트를 식별하는 동작;을 포함하는, 동작 방법이 제공될 수 있다. 다양한 실시예들에 따르면, 전자 장치의 동작 방법으로서, 복수의 오디오 소스들에 대응하는 음악 파일을 획득 하는 동작; 적어도 하나의 제1 오브젝트를 포함하는 제1 화면을 표시하면서, 상기 음악 파일과 연관된 제1 재생 시간에 대응하는 제1 주파수 스펙트럼을 갖는 제1 사운드를 출력하는 동작; 상기 적어도 하나의 제1 오브젝트에 대한 사용자 입력과 연관된 특정 모드 전환 조건의 만족 여부를 식별하는 동작; 상기 모드 전환 조건이 만족되는 경우: 상기 사용자 입력에 의해 제1 조건이 만족되는 경우: 상기 사용자 입력이 제1 입력인 경우, 제1 시각적 이펙트가 적용된 제2 화면을 표시하면서 제2 주파수 스펙트럼을 갖는 제2 사운드를 출력하는 동작; 및 상기 사용자 입력이 제2 입력인 경우, 제2 시각적 이펙트가 적용된 제3 화면을 표 시하면서 제3 주파수 스펙트럼을 갖는 제3 사운드를 출력하는 동작; 및 상기 사용자 입력에 의한 제2 조건이 만 족되는 경우: 상기 음악 파일과 연관된 제2 시간 구간에 대응하는 제2 주파수 스펙트럼을 갖는 제2 사운드를 출 력하는 동작;를 포함하는, 상기 사용자 입력이 식별되지 않는 경우: 이벤트를 식별하는 동작; 상기 식별된 이벤 트의 종류가 화면을 제어하기 위한 제 1 종류인 경우, 상기 적어도 하나의 제1 오브젝트의 제1 시각적 속성을 변경하고, 상기 시각적 속성의 변경에 기반하여 상기 제1 사운드의 제1 청각적 속성을 변경하는 동작; 및 상기 식별된 이벤트의 종류가 사운드를 제어하기 위한 제 2 종류인 경우, 상기 제1 사운드의 제2 청각적 속성을 변경 하고, 상기 청각적 속성의 변경에 기반하여 상기 제1 오브젝트의 제2 시각적 속성을 변경하는 동작;을 포함하는, 동작 방법이 제공될 수 있다. 이하에서는 다양한 실시예들에 따른 인터랙티브(interactive) 음악 감상 시스템의 일 예에 대해서 설명한다. 1. 인터랙티브 음악 감상 시스템 다양한 실시예들에 따르면, 인터랙티브 음악 감상 시스템은, 사용자 주도(user-led) 하에 음악을 감상하기 위한 기능들(또는 서비스들)을 제공(또는 수행)하도록, 구현된 시스템으로 정의될 수 있다. 단순히 오디오 소스 를 시계열적으로 재생하여 사운드를 출력하는 기능을 제공하도록 구현된 종래의 음악 감상 시스템과 비교하여, 인터랙티브 음악 감상 시스템을 이용하는 사용자는 인터랙티브 음악 감상 시스템에 의해 제공되는 음악을 주도적으로 재구성함으로써 다이나믹하게 음악을 감상할 수 있게 된다. 이에 따라 사용자는 인터랙티브 음악 감 상 시스템을 통해 단순히 수동적으로 음악을 감상하는 종래의 음악 감상 행태에서 벗어나, 보다 더 능동적으 로 음악을 감상하게 될 수 있으며, 음악 감상에 대한 몰입감이 더 증대될 수 있다. 인터랙티브 음악 감상 시스 템에 의해 제공(또는 수행)되는 기능들의 예에 대해서는, 이하의 다양한 실시예들을 참조하여 설명한다. 도 1은, 다양한 실시예들에 따른, 인터랙티브 음악 감상 시스템의 일 예를 설명하기 위한 도면이다. 도 1을 참조하면, 다양한 실시예들에 따르면 상기 인터랙티브 음악 감상 시스템은 전자 장치 및/또는 서버를 포함할 수 있다. 다양한 실시예들에 따르면, 전자 장치는 소정의 컨텐트를 제공하도록 구현되는 전자 장치일 수 있다. 예를 들어, 전자 장치는 시각적 컨텐트(100a)(예: 그래픽 유저 인터페이스(graphic user interface, GUI))를 제공하기 위한 적어도 하나의 전자 부품(또는 하드웨어)(예: 디스플레이), 및 청각적 컨텐트(100b)(예: 음악)를 제공하기 위한 적어도 하나의 전자 부품(또는 하드웨어)(예: 스피커)을 포함하도록 구현되는 장치일 수 있다. 예를 들어, 전자 장치는 스마트폰, 텔레비전(television, TV), 웨어러블 장치, HMD(head mounted display) 장치 등을 포함할 수 있으나, 기재된 예에 제한되지 않고 사용자에게 시각적 컨텐트(100a) 및 청각적 컨텐트(100b)를 제공 가능한 다양한 종류의 전자 장치를 포함할 수 있다. 이때, 전자 장치에 의해 제공되는 시각적 컨텐트(100a)와 청각적 컨텐트(100b)는 소정의 시간 정보(100c)(예: 특정 스테이지 진입 후의 시간) 와 연관된 형태로 제공될 수 있는데, 시간 정보(100c)의 예에 대해서는 더 구체적으로 후술한다. 다양한 실시예들에 따르면, 전자 장치에 의해 제공되는 컨텐트는 사용자에 의해 다이나믹(dynamic)하 게 제어될 수 있다. 다시 말해, 전자 장치는, 컨텐트(예: 시각적 컨텐트(100a), 청각적 컨텐트 (100b), 시간 정보(100c))의 적어도 일부의 속성이 제어되거나 및/또는 변경됨에 기반하여, 컨텐트의 나머 지 일부의 속성을 제어하거나 및/또는 변경할 수 있다. 예를 들어, 전자 장치는, 청각적 컨텐트(100b)를 제공하는 동안 사용자로부터 수신되는 시각적 컨텐트(100a)의 적어도 일부의 속성을 제어하기 위한 입력에 기반 하여, 상기 청각적 컨텐트(100b)의 적어도 일부의 속성(또는 특성)을 제어할 수 있다. 즉, 전자 장치는, 사용자에게 청각적 컨텐트(100b)를 감상하는 중에 시인하고 제어할 수 있는 대상으로 기능을 수행할 수 있는 시 각적 컨텐트(100a)를 제공함으로써, 사용자가 다이나믹하게 청각적 컨텐트(100b)를 제어하며 감상하도록 할 수 있다. 다양한 실시예들에 따르면, 서버는 전자 장치의 외부에 구현되는 다양한 종류의 외부 전자 장치일 수 있다. 상기 서버는 상기 전자 장치로 인터랙티브한 음악 감상 기능을 제공하도록 구현된 어플리케이 션(또는 프로그램)을 제공하기 위한 배포 서버, 또는 상기 전자 장치와 다른 외부 전자 장치 간의 정보(또 는 데이터, 또는 파일)의 공유를 위한 플랫폼 서버 중 적어도 하나를 포함할 수 있다. 한편 도시 및/또는 기재된 예에 제한되지 않고, 인터랙티브 음악 감상 시스템은 더 많은 장치들을 포함하거 나, 및/또는 더 적은 장치들을 포함하도록 구현될 수 있다. 예를 들어, 상기 인터랙티브 음악 감상 시스템은 전자 장치에 동작적으로 연결되어(또는 통신 연결되어) 외부 환경에 대한 정보(예: 이미지, 다양한 종류의 센서 정보)를 제공하도록 구현되는 외부 전자 장치를 더 포함할 수 있다. 또 예를 들어, 상기 인터랙티브 음악 감상 시스템은 전자 장치만을 포함할 수도 있다. 한편 특별한 언급이 없다면, 이하에서 기술되는 다양한 실시예들에 따른 전자 장치의 적어도 일부 동작은 서버에 의해 수행될 수도 있고, 또 다양한 실시예들에 따른 서버의 적어도 일부 동작은 전자 장치 에 의해 수행될 수도 있는 것으로, 당업자에 의해 이해될 수 있다. 다시 말해, 전자 장치에 의해 모 든 동작이 수행되는 온-디바이스(on-device) 타입, 서버에 의해 모든 동작이 수행되는 서버 타입, 또는 전 자 장치와 서버 각각에 의해 동작이 수행되는 하이브리드 타입의 인터랙티브 음악 감상 시스템이 구현될 수 있다. 2. 인터랙티브 음악 감상 시스템의 구성 2.1 전자 장치의 구성 이하에서는 다양한 실시예들에 따른 전자 장치의 구성의 예에 대해서 설명한다. 도 2a는 다양한 실시예들에 따른 전자 장치의 구성의 일 예를 설명하기 위한 도면이다. 이하에서는 도 2b 를 참조하여 도 2a에 대해서 더 설명한다. 도 2b는 다양한 실시예들에 따른 어플리케이션의 실행에 따른 전자 장치의 동작의 예를 설명하기 위 한 도면이다. 도 2b의 어플리케이션의 실행에 따라서 제공되는 스테이지 별 컨텐트의 예에 대해서는 도 3을 참조하여 설명한다. 도 3은 다양한 실시예들에 따른 오디오 소스 셋(또는 오디오 소스) 및 스테이지 별 컨텐트의 예를 설명하 기 위한 도면이다. 도 2a를 참조하면, 전자 장치는 프로세서, 통신 회로, 출력 장치, 입력 장치, 및 메 모리를 포함할 수 있다. 도 2a에 도시된 및/또는 기재된 바에 제한되지 않고, 전자 장치는 더 많은 구성들을 포함하거나, 또는 더 적은 구성들을 포함하도록 구현될 수도 있다. 한편, 전술한 바와 같이 전자 장치 의 구성들의 적어도 일부가 다른 외부 전자 장치(예: 서버)에 구현됨으로써, 이하에서 기술되는 다양 한 실시예들에 따른 동작들 중 적어도 일부가 외부 전자 장치에 의해 수행될 수 있음은 당업자에게 자명하다. 다양한 실시예들에 따르면, 프로세서는 적어도 일부가 서로 다른 기능을 제공하도록 구현되는 적어도 하나 의 프로세서를 포함할 수 있다. 예를 들면, 소프트웨어(예: 프로그램)를 실행하여 프로세서에 연결된 전자 장치의 적어도 하나의 다른 구성요소(예: 하드웨어 또는 소프트웨어 구성요소)를 제어할 수 있고, 다양한 데이터 처리 또는 연산을 수행할 수 있다. 일 실시예에 따르면, 데이터 처리 또는 연산의 적어도 일부로서, 프 로세서는 다른 구성요소(예: 통신 회로, 출력 장치, 입력 장치)로부터 수신된 명령 또는데이터를 메모리(예: 휘발성 메모리)에 저장하고, 휘발성 메모리에 저장된 명령 또는 데이터를 처리하고, 결과 데이터를 비휘발성 메모리에 저장할 수 있다. 일 실시예에 따르면, 프로세서는 메인 프로세서(예: 중 앙 처리 장치 또는 어플리케이션 프로세서) 또는 이와는 독립적으로 또는 함께 운영 가능한 보조 프로세서(예: 그래픽 처리 장치, 신경망 처리 장치(NPU: neural processing unit), 이미지 시그널 프로세서, 센서 허브 프로 세서, 또는 커뮤니케이션 프로세서)를 포함할 수 있다. 예를 들어, 전자 장치가 메인 프로세서 및 보조 프 로세서를 포함하는 경우, 보조 프로세서는 메인 프로세서보다 저전력을 사용하거나, 지정된 기능에 특화되도록 설정될 수 있다. 보조 프로세서는 메인 프로세서와 별개로, 또는 그 일부로서 구현될 수 있다. 보조 프로세서 는, 예를 들면, 메인 프로세서가 인액티브(예: 슬립) 상태에 있는 동안 메인 프로세서를 대신하여, 또는 메인 프로세서가 액티브(예: 어플리케이션 실행) 상태에 있는 동안 메인 프로세서와 함께, 전자 장치의 구성요 소들 중 적어도 하나의 구성요소(예: 통신 회로, 출력 장치, 입력 장치)와 관련된 기능 또는 상 태들의 적어도 일부를 제어할 수 있다. 일 실시예에 따르면, 보조 프로세서(예: 이미지 시그널 프로세서 또는 커뮤니케이션 프로세서)는 기능적으로 관련 있는 다른 구성요소(예: 통신 회로, 출력 장치, 입력 장 치)의 일부로서 구현될 수 있다. 일 실시예에 따르면, 보조 프로세서(예: 신경망 처리 장치)는 인공지능 모델의 처리에 특화된 하드웨어 구조를 포함할 수 있다. 인공지능 모델은 기계 학습을 통해 생성될 수 있다. 이 러한 학습은, 예를 들어, 인공지능 모델이 수행되는 전자 장치 자체에서 수행될 수 있고, 별도의 서버(예: 서버)를 통해 수행될 수도 있다. 학습 알고리즘은, 예를 들어, 지도형 학습(supervised learning), 비지도 형 학습(unsupervised learning), 준지도형 학습(semi-supervised learning) 또는 강화 학습(reinforcement learning)을 포함할 수 있으나, 전술한 예에 한정되지 않는다. 인공지능 모델은, 복수의 인공 신경망 레이어들 을 포함할 수 있다. 인공 신경망은 심층 신경망(DNN: deep neural network), CNN(convolutional neural network), RNN(recurrent neural network), RBM(restricted boltzmann machine), DBN(deep belief network), BRDNN(bidirectional recurrent deep neural network), 심층 Q-네트워크(deep Q-아니오etworks) 또는 상기 중 둘 이상의 조합 중 하나일 수 있으나, 전술한 예에 한정되지 않는다. 인공지능 모델은 하드웨어 구조 이외에, 추가적으로 또는 대체적으로, 소프트웨어 구조를 포함할 수 있다. 다양한 실시예들에 따르면, 통신 회로는 전자 장치와 외부 전자 장치(예: 도 1의 서버) 간의 직 접(예: 유선) 통신 채널 또는 무선 통신 채널의 수립, 및 수립된 통신 채널을 통한 통신 수행을 지원할 수 있다. 통신 회로은 프로세서(예: 어플리케이션 프로세서)와 독립적으로 운영되고, 직접(예: 유선) 통 신 또는 무선 통신을 지원하는 하나 이상의 커뮤니케이션 프로세서를 포함할 수 있다. 일 실시예에 따르면, 통 신 회로는 무선 통신 모듈(예: 셀룰러 통신 모듈, 근거리 무선 통신 모듈, 또는 GNSS(global navigation satellite system) 통신 모듈) 또는 유선 통신 모듈(예: LAN(local area network) 통신 모듈, 또는 전력선 통 신 모듈)을 포함할 수 있다. 이들 통신 모듈 중 해당하는 통신 모듈은 제1 네트워크(예: 블루투스, WiFi(wireless fidelity) direct 또는 IrDA(infrared data association)와 같은 근거리 통신 네트워크) 또는 제2 네트워크(예: 레거시 셀룰러 네트워크, 5G 네트워크, 차세대 통신 네트워크, 인터넷, 또는 컴퓨터 네트워크 (예: LAN 또는 WAN)와 같은 원거리 통신 네트워크)를 통하여 외부의 전자 장치(예: 서버)와 통신할 수 있 다. 이런 여러 종류의 통신 모듈들은 하나의 구성요소(예: 단일 칩)로 통합되거나, 또는 서로 별도의 복수의 구 성요소들(예: 복수 칩들)로 구현될 수 있다. 무선 통신 모듈은 가입자 식별 모듈에 저장된 가입자 정보(예: 국 제 모바일 가입자 식별자(IMSI))를 이용하여 제1 네트워크 또는 제2 네트워크와 같은 통신 네트워크 내에서 전 자 장치를 확인 또는 인증할 수 있다. 무선 통신 모듈은 4G 네트워크 이후의 5G 네트워크 및 차세대 통신 기술, 예를 들어, NR 접속 기술(new radio access technology)을 지원할 수 있다. NR 접속 기술은 고용량 데이 터의 고속 전송(eMBB(enhanced mobile broadband)), 단말 전력 최소화와 다수 단말의 접속(mMTC(massive machine type communications)), 또는 고신뢰도와 저지연(URLLC(ultra-reliable and low-latency communications))을 지원할 수 있다. 무선 통신 모듈은, 예를 들어, 높은 데이터 전송률 달성을 위해, 고주파 대역(예: mmWave 대역)을 지원할 수 있다. 무선 통신 모듈은 고주파 대역에서의 성능 확보를 위한 다양한 기술 들, 예를 들어, 빔포밍(beamforming), 거대 배열 다중 입출력(massive MIMO(multiple-input and multiple- output)), 전차원 다중입출력(FD-MIMO: full dimensional MIMO), 어레이 안테나(array antenna), 아날로그 빔 형성(analog beam-forming), 또는 대규모 안테나(large scale antenna)와 같은 기술들을 지원할 수 있다. 무선 통신 모듈은 전자 장치, 외부 전자 장치(예: 서버) 또는 네트워크 시스템에 규정되는 다양한 요구사 항을 지원할 수 있다. 일 실시예에 따르면, 무선 통신 모듈은 eMBB 실현을 위한 Peak data rate(예: 20Gbps 이 상), mMTC 실현을 위한 손실 Coverage(예: 164dB 이하), 또는 URLLC 실현을 위한 U-plane latency(예: 다운링 크(DL) 및 업링크(UL) 각각 0.5ms 이하, 또는 라운드 트립 1ms 이하)를 지원할 수 있다. 다양한 실시예들에 따르면 출력 장치는 시각적 컨텐트(100a), 및/또는 청각적 컨텐트(100b)를 전자 장치 의 외부로 제공하도록 구현되는 전자 부품(또는 하드웨어)을 포함할 수 있다. 예를 들어, 출력 장치 는 디스플레이, 스피커, 햅틱 장치와 같은 촉감을 제공하도록 구현되는 전자 부품을 포함할 수 있으나, 기재된 예에 제한되지 않고 다양한 종류의 전자 부품을 더 포함할 수 있다. 출력 장치의 예로서 기재된 전자 부품들은 당업자에게 자명하므로, 더 구체적인 설명은 생략한다. 다양한 실시예들에 따르면 입력 장치는 전자 장치의 외부로부터 정보를 획득하도록 구현되는 전자 부 품(또는 하드웨어)을 포함할 수 있다. 예를 들어, 입력 장치는 카메라, 마이크, 및 센서를 포함할 수 있으나, 기재된 예에 제한되지 않고 다양한 종류의 전자 부품을 더 포함할 수 있다. 입력 장치 의 예로서 기재된 전자 부품들은 당업자에게 자명하므로, 더 구체적인 설명은 생략한다. 다양한 실시예들에 따르면 메모리는 어플리케이션, 및 데이터베이스를 저장하도록 구현될 수 있 다. 상기 어플리케이션(또는 프로그램)은 인터랙티브한 음악 감상을 위해 기능을 제공하도록 구현될 수 있 다. 상기 데이터베이스는 상기 어플리케이션의 실행에 의해 시각적 컨텐트(100a) 및/또는 청각적 컨 텐트(100b)를 제공하기 위한 다양한 종류의 파일들(예: 그래픽 엘리먼트 셋(set)(211a)(또는 그래픽 엘리먼트), 오디오 소스 셋(231a)(또는 오디오 소스), 데이터베이스(또는 룰 정보))을 포함할 수 있다. 상기 데 이터베이스(또는 룰 정보)는 어플리케이션과 별도로 구현되는 것으로 도시되었으나, 도시된 예 에 제한되지 않고 적어도 일부가 어플리케이션 내에 구현될 수 있다. 상기 시각적 컨텐트(100a)와 상기 청 각적 컨텐트(100b)의 제공의 기반이 된다는 점에서, 상기 데이터베이스는 소스 풀(source pool)로 정의될 수도 있다. 상기 어플리케이션(또는 프로그램) 및/또는 상기 데이터베이스는 서버(예: 배포 서 버)로부터 전자 장치로 수신(또는 다운로드)될 수 있으나, 기재된 예에 제한되지 않고 전자 장치에 미리 저장되어 있을 수도 있다. 다양한 실시예들에 따르면, 상기 어플리케이션은 어플리케이션 뿐만 아니라, 파일(예: 음악 파일)뿐만 아 니라, 프로그램, 및/또는 컴퓨터 코드(computer code)와 같이 전자 장치에 의해 실행 가능하며 저장 가능한 형 태로 구현될 수 있다. 다양한 실시예들에 따르면, 상기 어플리케이션이 실행되는 경우, 프로세서는 시각적 컨텐트(100a) 및 /또는 청각적 컨텐트(100b)를 소정의 시간 정보(100c)(예: 스테이지(200a, ?, 200n), 및/또는 타임라인(dt))에 따라서 제공하도록 전자 부품들(또는 하드웨어들)(예: 출력 장치)을 제어하는 동작을 수행할 수 있다. 이 하의 전자 장치(예: 프로세서)의 동작들은 어플리케이션의 실행에 기반하여 수행되는 동작들로 이해될 수 있다. 도 2b를 참조하면, 전자 장치는 어플리케이션의 실행에 기반하여 데이터베이스로부터 그래픽 정 보/오디오 정보를 획득함에 기반하여, 시각적 컨텐트(100a)를 출력 장치(예: 디스플레이)를 통해 출 력(또는 표시)하거나, 및/또는 청각적 컨텐트(100b)를 출력 장치(예: 스피커)를 통해 출력할 수 있다. 예를 들어, 상기 시각적 컨텐트(100a)는 그래픽 엘리먼트 셋(211a)을 포함할 수 있다. 상기 그래픽 엘리먼트 셋 (211a)은 복수의 그래픽 엘리먼트들을 포함할 수 있다. 상기 그래픽 엘리먼트는 디스플레이 상에 표시 가 능한 그래픽 오브젝트, 이미지, 및 텍스트를 의미할 수 있으며, 기재된 예에 제한되지 않고 디스플레이 상 에 표시 가능한 전자적인 정보(예: 시각적 효과(비쥬얼 이펙트)를 더 포함할 수 있다. 또, 상기 시각적 컨텐트 (100a)는 후술되는 소스 풀의 비쥬얼 셋에 대응하는 개념일 수 있다. 또 예를 들어, 상기 청각적 컨텐트(100b)는 오디오 소스 셋(231a)을 포함할 수 있다. 도 3을 참조하면, 상기 오 디오 소스 셋(231a)은 복수의 오디오 소스들을 포함할 수 있다. 또, 상기 청각적 컨텐트(100b)는 후술되는 소스 풀의 오디오 셋에 대응하는 개념일 수 있다. 다양한 실시예들에 따르면, 어플리케이션는 복수의 스테이지들(301a, 301n) 별로 오디오 소스 셋(231a), 그래픽 엘리먼트 셋(211a), 및 룰 정보을 포함할 수 있다. 상기 복수의 스테이지들(301a, 301n) 별로 포함 된 오디오 소스 셋(231a), 그래픽 엘리먼트 셋(211a), 또는 룰 정보 중 적어도 하나는 서로 다를 수 있다. 이에 따라 예를 들어, 어플리케이션이 실행되는 경우, 전술한 바와 같이 복수의 스테이지들(301a, 301n) 별로 서로 다른 오디오 소스 셋(231a)에 기반하여 음악의 서로 다른 부분(예: 벌스(verse) 등과 같음 음악 구성)에 대응하는 청각적 컨텐트(100b)가 제공될 수 있다. 또 예를 들어, 어플리케이션이 실행되는 경우, 서로 다른 그래픽 엘리먼트 셋(211a)을 포함하는 시각적 컨텐트(100a)가 표시될 수 있다. 또 예를 들어, 어플리 케이션이 실행되는 경우, 복수의 스테이지들(301a, 301n) 별로 서로 다른 룰 정보에 기반하여, 복수의 스테이지들(301a, 301n) 별로 동일한 사용자 인터랙션이 입력되는 경우 서로 다른 제어 동작이 수행될 수 있 으며, 또는 복수의 스테이지들(301a, 301n) 별로 서로 다른 사용자 인터랙션이 입력되는 경우 서로 대응하는 제 어 동작이 수행될 수도 있다. 다양한 실시예들에 따르면, 상기 복수의 스테이지들(300a, 300b)은 음원 파일의 서로 다른 부분에 대응할 수 있다. 예를 들어, 도 3에 도시된 바와 같이, 복수의 오디오 소스 셋들(300a, 300b, 300c) 각각은 음원 파일 의 서로 다른 부분으로부터 획득될 수 있다. 이때, 복수의 스테이지들(301a, 301n) 각각은 서로 다른 오디 오 소스 셋들(301a, 301n)을 제공(또는 포함)하도록 구현될 수 있다. 이에 따라, 전자 장치는 상기 복수의 스테이지들(301a, 301n) 별로 음원 파일의 서로 다른 부분을 제공할 수 있게 될 수 있다. 다시 말해, 복수 의 스테이지들(300a, 300b)은 음원 파일의 특정 시간에 대응하는 의미에서, 타임 라인(dt)으로 이해될 수 있다. 상기 복수의 스테이지들(300a, 300b) 간의 전환은 사용자의 입력과 연관된 조건이 만족되는 경우, 수행될 수 있는데, 이에 대해서는 각각의 실시예를 참조하여 후술한다. 다양한 실시예들에 따르면, 특정 스테이지에 진입된 상태에서, 유지되는 시간(dt1, dt2)이 타임라인으로 이해될 수도 있다. 전자 장치는 상기 유지되는 시간(dt1, dt2)에 대응하는 룰 정보를 저장하고, 저장된 룰 정보에 기반하여 시각적 컨텐트(100a) 및 청각적 컨텐트(100b)를 변형하여 제공할 수 있다. 이하에서는, 다양한 실시예들에 따른, 그래픽 엘리먼트 셋(201a), 오디오 소스 셋(203a), 및 룰 정보의 예 에 대해서 설명한다. 2.2 오디오 소스 셋의 생성 예 이하에서는, 다양한 실시예들에 따른 오디오 소스 셋(231a) 및 오디오 소스 셋(231a)에 포함되는 복수의 오디오 소스들의 예에 대해서 설명한다. 도 3은 다양한 실시예들에 따른, 오디오 소스의 예를 설명하기 위한 도면이다. 다양한 실시예들에 따르면, 오디오 소스(audio source)(또는, 사운드 소스(sound source))는 사운드를 발생시키 는 전자적 데이터(또는 파일, 또는 정보)를 의미할 수 있다. 즉, 상기 오디오 소스의 재생에 따라 특정 종류의 사운드가 출력될 수 있다. 예를 들어, 오디오 소스는 턴테이블을 이용하여 사운드를 출력할 수 있도록 저장된 음반, 컴퓨팅 장치와 이와 연결된 스피커를 이용하여 사운드를 출력할 수 있도록 저장된 CD 음반, 사운드 웨이 브(sound wave)형식으로 저장되거나 생성된 오디오 데이터, 아날로그 신호(analog-signal) 형식으로 저장되거나 생성된 오디오 데이터, 디지털 신호(digital-signal) 형식으로 저장되거나 생성된 오디오 데이터 등에 대응될 수 있으나, 이에 한정되지 않는다. 또 예를 들어, 오디오 소스는 MP3, FLAC 등처럼 오디오 압축 기술(audio compression techniques)이 적용된 데이터 형식으로 저장된 오디오 데이터에 대응될 수 있으나, 이에 한정되지 않는다. 다양한 실시예들에 따르면, 오디오 소스는 적어도 1개 이상의 사운드 데이터를 포함할 수 있다. 일 실시예에서, 오디오 소스는 어플리케이션이 실행되는 경우 재생되는 적어도 1 개 이상의 제1 사운드 데 이터를 포함할 수 있다. 상기 오디오 소스가 복수 개인 경우에는, 복수의 오디오 소스들을 포함한다는 의미에서 \"오디오 소스 셋\"로 명명될 수 있다. 이하에서는 설명의 편의를 위하여, 오디오 소스로 기재하며, 상기 오디오 소스는 하나의 오디오 소스를 포함하는 개념 뿐만 아니라, 복수의 오디오 소스들을 포함하는 오디오 소스 셋 개 념으로 이해될 수 있다. 상기 적어도 1개 이상의 제1 사운드 데이터는 사용자의 인터랙션과는 무관하게 재생되 는 사운드 데이터일 수 있다. 예를 들어, 상기 오디오 소스는 서로 대응하는(또는 유사한) 시간 길이(또는 재생 길이)를 갖는 적어도 1 개 이상의 특정 스템(stem) 파일(또는 스템)을 포함할 수 있다. 상기 스템은 보컬, 악기 (예: 기타, 드럼, 피아노, 심벌(cymbal), 플럭(pluck), 턴-테이블, 킥), 신스, 등과 같이 곡을 구성하는 시계열 적인 음원들을 포함할 수 있다. 이에 따라, 어플리케이션이 실행되는 경우 동일한 재생 시간 동안 각각의 스템 파일에 기반한 사운드가 출력됨에 따라, 혼합 사운드가 제공될 수 있다. 또 일 실시예에서, 오디오 소스는 사용자 인터랙션에 기반하여 출력 되도록 설정되는 적어도 1 개 이상의 제2 사운드 데이터를 포함할 수 있다. 상기 적어도 1 개 이상의 제2 사운드 데이터의 재생 길이는 전술한 스템 파일 의 재생 길이 보다 짧을 수 있다. 상기 적어도 1개 이상의 제2 사운드 데이터는 특정 종류의 사운드(예: 효과음, 특정 단어(예: \"what\")의 목소리, 특정 악기(예: 피아노, 드럼, 심벌 등)에 대응하는 사운드)를 출력하 도록 구현된 데이터일 수 있다. 상기 제2 사운드 데이터는 오디오 소스와는 별도로 구현되는 사운드 데이터일 수도 있다.다양한 실시예들에 따르면, 오디오 소스에 기반하여 다양한 종류의 음악적 단위들이 설정(또는 식별)될 수 있다. 예를 들어, 음악적 단위(musical meter)는 음악을 구분하여 설명하기 위한 단위를 의미할 수 있으며, 비 트(beat), 마디(bar), 동기(Motive), 작은 악절(Phrase), 큰악절(Period) 등을 포함할 수 있다. 상기, 비트 (beat)는 시간의 기본적 단위로 기준 박자의 한 박자를 의미할 수 있으며, 통상의 기술자가 이해할 수 있는 비 트(beat)로 이해될 수 있다. 상기, 마디(bar)는 오디오 소스의 기준 박자수를 포함하는 음악적 단위를 의미할 수 있으며, 악보에서 세로줄로 구분되는 악곡의 최소 단위를 의미할 수 있으며, 통상의 기술자가 이해할 수 있 는 마디(bar)로 이해될 수 있다. 즉, 서로 다른 오디오 소스는 서로 다른 음악적 단위를 가질 수 있다. 이 때, 상기 적어도 하나 이상의 악기는 피아노, 기타, 드럼, 베이스 등을 포함할 수 있으나, 이에 한정되지 않 으며, 사운드를 발생시키기 위한 기계 및 기구를 모두 포함할 수 있다. 또한 이 때, 녹음 데이터는 피아노, 기타, 드럼, 베이스가 합주되어 녹음된 녹음데이터 일 수 있으며, 피아노, 기타, 드럼 베이스의 연주가 녹음되어 스피커 등 출력 장치를 통해 재출력된 소리가 녹음된 녹음 데이터일 수도 있으나, 이에 한정되지 않는다. 또한, 일 실시예에 따라 오디오 소스를 획득하기 위해 소스 분리(Source separation) 기법이 이용될 수 있다. 예를 들어, 상술한 합주 등을 통하여 녹음된 오디오 소스를 소스 분리 모델을 이용하여 각각의 악기에 대응되는 오디오 소스들로 분리하여 오디오 소스를 획득할 수 있으나, 이에 한정되지 않는다. 이 때, 분리된 오디오 소스들은 물리적으로 각각의 악기에 대응될 수 있으나, 이에 한정되지 않으며 의미론적으 로 각각의 악기에 대응되는 것으로 보는 경우도 포함할 수 있다. 또한, 일 실시예에 따른 상기 소스 분리 모델은 머신 러닝(Machine learning) 방법으로 구현될 수 있다. 예를 들어, 상기 소스 분리 모델은 지도 학습을 통해 구현된 모델일 수 있으나, 이에 한정되지 않으며, 비지도 학습, 준지도 학습, 강화 학습 등을 통해 구현된 모델일 수 있다. 또한, 일 실시예에 따른 상기 소스 분리 모델은 인공 신경망(artificial neural network, ANN)으로 구현될 수 있다. 예를 들어, 상기 소스 분리 모델은 전방 전달 신경망(Feedforward neural network), 방사 신경망(radial basis function network) 또는 코헨 자기조직 신경망(kohonen self-organizing network) 등으로 구현될 수 있 으나, 이에 한정되지 않는다. 또한, 일 실시예에 따른 상기 소스 분리 모델은 심층 신경망(Deep neural network, DNN)으로 구현될 수 있다. 예를 들어, 상기 소스 분리 모델은 합성곱신경망(Convolutional neural network, CNN), 순환 인공 신경망 (Recurrent neural network, RNN), LSTM(Long Short Term Memory Network) 또는 GRUs(Gated Recurrent Units) 등으로 구현될 수 있으나, 이에 한정되지 않는다. 또한, 상기 소스 분리 모델에 입력되는 데이터는 녹음하여 획득된 오디오 소스 자체일 수 있으며, 전처리 된 오 디오 소스 데이터일 수 있다. 또한, 일 실시예에 따라 오디오 소스를 획득하기 위해 구조 분리 기법이 이용될 수 있다. 예를 들어, 상술한 합주 등을 통하여 녹음된 오디오 소스를 구조 분리 모델을 이용하여 적어도 둘 이상의 음악 구간으로 분리하여 오디오 소스를 획득할 수 있으나, 이에 한정되지 않는다. 이 때, 일 실시예에 따른 상기 구조 분리 모델은 머신 러닝(Machine learning) 방법으로 구현될 수 있다. 예를 들어, 상기 구조 분리 모델은 지도 학습을 통해 구현된 모델일 수 있으나, 이에 한정되지 않으며, 비지도 학습, 준지도 학습, 강화 학습 등을 통해 구현된 모델일 수 있다. 또한, 일 실시예에 따른 상기 구조 분리 모델은 인공 신경망(artificial neural network, ANN)으로 구현될 수 있다. 예를 들어, 상기 구조 분리 모델은 전방 전달 신경망(Feedforward neural network), 방사 신경망(radial basis function network) 또는 코헨 자기조직 신경망(kohonen self-organizing network) 등으로 구현될 수 있 으나, 이에 한정되지 않는다. 또한, 일 실시예에 따른 상기 구조 분리 모델은 심층 신경망(Deep neural network, DNN)으로 구현될 수 있다. 예를 들어, 상기 구조 분리 모델은 합성곱신경망(Convolutional neural network, CNN), 순환 인공 신경망 (Recurrent neural network, RNN), LSTM(Long Short Term Memory Network) 또는 GRUs(Gated Recurrent Units) 등으로 구현될 수 있으나, 이에 한정되지 않는다.또한, 상기 구조 분리 모델에 입력되는 데이터는 녹음하여 획득된 오디오 소스 자체일 수 있으며, 전처리 된 오 디오 소스 데이터일 수 있다. 또한, 일 실시예에 따라 오디오 소스를 획득하기 위해 적어도 하나 이상의 악기 및 보컬 각각의 연주가 녹음된 녹음 데이터가 이용될 수 있으나, 이에 한정되지 않는다. 이 때, 상기 적어도 하나 이상의 악기는 피아노, 기타, 드럼, 베이스 등을 포함할 수 있으나, 이에 한정되지 않 으며, 사운드를 발생시키기 위한 기계 및 기구를 모두 포함할 수 있다. 또한 이 때, 녹음 데이터는 피아노, 기타, 드럼, 베이스 각각이 연주되어 녹음된 녹음데이터 일 수 있으며, 피 아노, 기타, 드럼, 베이스 각각의 연주가 녹음되어 스피커 등 출력 장치를 통해 재출력된 소리가 녹음된 녹음 데이터일 수도 있으나, 이에 한정되지 않는다. 또한, 일 실시예에 따라 오디오 소스를 획득하기 위해 적어도 하나의 오디오 소스를 생성할 수 있다. 예를 들어, 일 실시예에 따라 오디오 소스를 획득하기 위해 사운드 타입, 멜로디, 장르, 보컬 등을 기초로 적어 도 하나의 오디오 소스를 생성할 수 있으나, 이에 한정되지 않는다. 또한, 일 실시예에 따라 오디오 소스를 획득하기 위해 오디오 소스 생성 모델이 이용될 수 있다. 이 때, 일 실시예에 따른 상기 오디오 소스 생성 모델은 머신 러닝(Machine learning) 방법으로 구현될 수 있다. 예를 들어, 상기 사운드 생성 모델은 지도 학습을 통해 구현된 모델일 수 있으나, 이에 한정되지 않으며, 비지도 학습, 준지도 학습, 강화 학습 등을 통해 구현된 모델일 수 있다. 또한, 일 실시예에 따른 상기 오디오 소스 생성 모델은 인공 신경망(artificial neural network, ANN)으로 구현 될 수 있다. 예를 들어, 상기 사운드 생성 모델은 전방 전달 신경망(Feedforward neural network), 방사 신경망 (radial basis function network) 또는 코헨 자기조직 신경망(kohonen self-organizing network) 등으로 구현 될 수 있으나, 이에 한정되지 않는다. 또한, 일 실시예에 따른 상기 오디오 소스 생성 모델은 심층 신경망(Deep neural network, DNN)으로 구현될 수 있다. 예를 들어, 상기 사운드 생성 모델은 합성곱신경망(Convolutional neural network, CNN), 순환 인공 신 경망(Recurrent neural network, RNN), LSTM(Long Short Term Memory Network) 또는 GRUs(Gated Recurrent Units) 등으로 구현될 수 있으나, 이에 한정되지 않는다. 또한, 일 실시예에 따라 오디오 소스를 획득하기 위해 획득된 오디오 소스에 오디오 소스 생성 모델을 적용할 수 있다. 예를 들어, 한국어로 녹음된 오디오 소스에 오디오 소스 생성 모델을 적용하여 영어로 번역된 오디오 소스를 획 득할 수 있으나, 이에 한정되지 않는다. 또한, 예를 들어, 남성의 목소리로 녹음된 오디오 소스에 오디오 소스 생성 모델을 적용하여 여성의 목소리로 판단될 수 있는 오디오 소스를 획득할 수 있으나, 이에 한정되지 않는다. 다만, 상술한 예시들은 오디오 소스를 획득하기 위한 간단한 예시들일 뿐, 발명의 실시예들은 이에 한정되지 않으며, 다양한 방법으로 오디오 소스를 획득하는 예시들을 포함할 수 있다. 2.2.1 오디오 소스의 속성 다양한 실시예들에 따르면, 오디오 소스는 제어(또는 조절, 또는 변경) 가능한 다양한 종류의 속성을 가질 수 있다.(또는 포함할 수 있다.) 예를 들어, 상기 오디오 소스의 속성은 출력 여부, 음 높이, 종류, 크기, 재생 속 도와 같이 청각적인 속성을 포함할 수 있으며, 기재된 예에 제한되지 않고 다양한 종류의 청각과 관련된 속성들 을 더 포함할 수 있다. 예를 들어, 출력 여부는 오디오 소스에 포함된 사운드 데이터(예: 제1 사운드 데이터, 및/또는 제2 사운드 데이터)의 출력 여부를 나타낼 수 있다. 또 예를 들어, 상기 음 높이는 오디오 소스에 포함 된 사운드 데이터(예: 제1 사운드 데이터, 및/또는 제2 사운드 데이터)의 음 높이를 나타내고, 크기는 사운드 데이터의 크기를 나타내고, 재생 속도는 사운드 데이터의 재생 속도를 나타낼 수 있다. 또 예를 들어, 상기 종 류는 오디오 소스에 포함된 사운드 데이터(예: 제1 사운드 데이터, 및/또는 제2 사운드 데이터)의 종류(예: 목 소리, 기계음)를 나타낼 수 있다. 상기 오디오 소스의 속성은 사용자의 인터랙션에 의해 변경될 수 있는데, 이 에 대해서는 구체적으로 후술한다. 다양한 실시예들에 따르면, 상기 오디오 소스의 속성에 따라서, 오디오 소스에 기반하여 출력되는 사운드의 주 파수 스펙트럼이 결정될 수 있다. 즉 상기 오디오 소스의 속성이 변경되는 경우, 출력되는 사운드의 주파수 스 펙트럼이 변경될 수 있다. 상기 주파수 스펙트럼은 사운드의 주파수 별 세기(또는 에너지)를 의미할 수 있다. 2.3. 그래픽 엘리먼트 셋 다양한 실시예들에 따르면, 그래픽 엘리먼트 셋(201a)은 전자 장치의 디스플레이에 표시 가능한 전자적인 데이 터를 의미할 수 있다. 예를 들어 뉴 디지털 싱글 파일이 실행되는 경우, 상기 그래픽 엘리먼트 셋(201a)은 실행 화면에 표시되는 그래픽 오브젝트들을 의미할 수 있다. 다양한 실시예들에 따르면, 그래픽 엘리먼트 셋(201a)의 속성은 사용자의 입력(예: 터치, 드래그)에 의해 변경 될 수 있다. 상기 그래픽 엘리먼트 셋(201a)의 속성이 변경됨에 기반하여, 대응하는 오디오 소스의 속성이 변경 될 수 있는데, 이에 대해서는 룰 정보에 대한 목차에서 설명한다. 2.3.1 그래픽 엘리먼트 셋의 종류 다양한 실시예들에 따르면, 도 2를 참조하면, 그래픽 엘리먼트 셋(201a)은 디스플레이에 출력 가능한 그래 픽 오브젝트들을 포함할 수 있다. 상기 그래픽 오브젝트들은 다양한 형상의 그래픽 오브젝트를 포함할 수 있으 므로, 각각의 실시예들을 참조하여 기술한다. 또, 예를 들어, 상기 그래픽 엘리먼트 셋(201a)는 텍스트(미도 시)를 포함할 수 있다. 또 예를 들어, 상기 그래픽 엘리먼트 셋(201a)은 사용자의 인터랙션에 기반하여 표시되 도록 설정되는 종류의 그래픽 오브젝트(미도시)(또는 비쥬얼 이펙트)를 포함할 수 있다. 2.3.2 그래픽 엘리먼트 셋의 속성 다양한 실시예들에 따르면, 그래픽 엘리먼트 셋(201a)는 제어(또는 조절, 또는 변경) 가능한 다양한 종류의 속 성을 가질 수 있다.(또는 포함할 수 있다.) 예를 들어, 상기 그래픽 엘리먼트 셋(201a)의 속성은 색상, 형상, 크기, 개수와 같은 시각적인 속성을 포함할 수 있으며, 기재된 예에 제한되지 않고 다양한 종류의 시각과 관련 된 속성들을 더 포함할 수 있다. 상기 그래픽 엘리먼트 셋(201a)의 속성은 사용자의 인터랙션에 의해 변경될 수 있는데, 이에 대해서는 구체적으로 후술한다. 2.4 룰 정보 다양한 실시예들에 따르면 룰 정보(또는 인터랙션 룰(interaction rule))는 사용자의 인터랙션(예: 터치 입력, 드래그 입력)에 대한 응답으로, 오디오 소스 셋(203a)의 속성, 그래픽 오브젝트의 속성, 및/또는 타임라 인을 변경하기 위한 제어 동작을 수행하도록 설정된 정보를 의미할 수 있다. 예를 들어, 룰 정보은, 특정 그래픽 오브젝트에 대한 사용자의 터치 입력이 획득되는 경우, 특정 제어 동작(예: 제1 오디오 이펙트를 적용) 을 수행하도록 함으로써, 재생되는 오디오 소스의 속성을 변경하도록 하는 정보일 수 있으나, 이에 한정되지 않 는다. 예를 들어, 상기 제어 동작은 오디오 소스의 속성을 제어하기 위한 동작들을 포함할 수 있다. 예를 들어, 상기 제어 동작은 오디오 소스에 오디오 이펙트를 적용하는 동작, 재생되는 오디오 소스를 치환, 변경하는 동작, 재 생되는 오디오 소스와 상이한 오디오 소스를 추가하는 동작, 재생되는 오디오 소스 중 적어도 일부를 재생하지 않는 동작 등을 포함할 수 있으나, 이에 한정되지 않는다. 상기 오디오 이펙트는 오디오 소스에 대한 템포 (Tempo) 조절, Low pass filter, High pass filter, 피치(Pitch) 조절, 보컬 오디오 출력, 연주 악기 변경, 음 원 멈춤, 악기 사운드 출력, 음원 소스의 성부 재구성, 비트 리피터(beat repeater), 특정 성부의 소리만 출력, 성부의 출력 레벨 조절, 에코(echo), 음원의 구간 이동, 사이키델릭 모드(Psychedelic mode), 패닝 조절, 플랜 저 코러스, 잔향 효과(리버브), 딜레이 등을 포함할 수 있으나, 이에 한정되지 않는다. 또 예를 들어, 상기 제어 동작은 그래픽 엘리먼트 셋(201a)의 속성을 제어하기 위한 동작들을 포함할 수 있다. 예를 들어, 상기 제어 동작은 디스플레이 되는 화면에 비쥬얼 이펙트를 적용하는 동작을 포함할 수 있다. 일 예 로, 상기 제어 동작은 배경 컬러의 변경, 적어도 하나의 그래픽 오브젝트 오브젝트의 형상, 크기, 컬러 등의 변 경, 오디오 소스 중 보컬에 대한 가사를 디스플레이하는 동작 등을 포함할 수 있으나, 이에 한정되지 않는다. 다양한 실시예들에 따르면, 상기 룰 정보는 제어되는 그래픽 오브젝트의 종류(또는 속성)(이하, 인터랙션 대상), 또는 사용자 인터랙션의 종류(이하, 입력 타입) 중 적어도 하나에 대응하는 적어도 하나의 제어 동작을 수행하도록 구현될 수 있다. 예를 들어, 제1 사용자 인터랙션에 의해 제1 그래픽 오브젝트가 제어되는 경우 적 어도 하나의 제1 제어 동작이 수행될 수 있고, 제2 사용자 인터랙션에 의해 제2 그래픽 오브젝트가 제어되는 경 우 적어도 하나의 제2 제어 동작이 수행될 수 있다. 이에 따라, 사용자는 뉴 디지털 싱글 파일에 인터랙션을 다 양하게 함(예: 인터랙션의 종류를 다양하게 함, 및/또는 인터랙션되는 그래픽 오브젝트의 종류(또는 속성)을 다양하게 함)으로써, 결과적으로 출력되는 청각적 내용들, 및/또는 시각적 내용들을 다양한 형태로 제어하면서 경 험할 수 있게 된다. 상기 제어 동작은 스킴(또는 방식, 또는 방법)으로 표현될 수 있으며, 서로 다른 제어 동작을 수행한다는 기재 는 서로 다른 스킴으로 오디오 소스의 속성, 및/또는 그래픽 엘리먼트 셋(201a)의 속성을 제어하는 것으로 이해 될 수 있다. 2.4.1 룰 정보의 예시 다양한 실시예들에 따르면, 룰 정보는 사용자의 인터랙션에 기반하여, 전술한 시각적 컨텐트(100a)(예: 그 래픽 엘리먼트 셋(201a))의 속성, 청각적 컨텐트(100b)(예: 오디오 소스 셋(203a))의 속성, 및/또는 시간 정보 (100c)(예: 스테이지, 및/또는 타임라인(dt, dt1, dt2))의 적어도 일부를 제어(또는 설정, 또는 변경)을 위한 정보일 수 있다. 예를 들어, 전자 장치는 복수의 룰 정보들 중 특정 시간 정보(예: 스테이지(200a), 및/또는 타임라인(dt, dt1, dt2)) 및 사용자 인터랙션의 종류에 대응하는 룰 정보를 식별하고, 상기 식별된 룰 정보에 기반하여 데이터베이스에 저장된 그래픽 엘리먼트 중 특정 정보와 오디오 소스 중 특정 정보를 획 득함에 기반하여, 시각적 컨텐트(100a) 및 청각적 컨텐트(100b)를 제공하도록 구현될 수 있다. 상기 사용자의 인터랙션에 기반하는 정보라는 점에서, 인터랙션 룰(interaction rule)로 정의될 수도 있다. 이 때, 사용자의 인터랙션은 인터랙션의 대상, 입력 타입 등에 따라 특정될 수 있다. 상기 인터랙션의 대상은 사용자로부터 획득되는 입력의 대상을 의미할 수 있다. 예를 들어, 사용자로부터 물리적으로 입력을 획득하는 대상일 수 있으며, 사용자로부터 입력을 획득하도록 사용자의 단말을 통해 디스플레이 되는 오브젝트일 수 있고, 사용자로부터 입력을 획득하기 위해 특정된 영역을 의미할 수 있으며, 사용자로부터 입력을 획득하기 위 한 특정 영역을 가이드 하기 위해 사용자의 단말을 통해 디스플레이 되는 오브젝트일 수 있으나, 이에 한정되지 않으며, 사용자로부터 직접적으로 및/또는 간접적으로 입력을 획득하거나, 획득된 입력을 특정하기 위한 것들을 의미할 수 있다. 또한, 상기 인터랙션의 대상은 사용자의 단말을 통해 디스플레이 되는 적어도 하나의 오브젝트를 포함할 수 있 다. 예를 들어, 상기 인터랙션의 대상은 제1 오브젝트 및 제2 오브젝트를 포함할 수 있으나, 이에 한정되지 않는다. 또한, 상기 인터랙션의 대상은 사용자의 단말을 통해 디스플레이 되는 배경 오브젝트를 포함할 수 있다. 예를 들어, 상기 인터랙션의 대상이 배경 오브젝트가 되는 경우 사용자로부터 상기 배경 오브젝트에 대한 인터 랙션을 획득하는 경우 적어도 하나의 동작을 수행하도록 설계될 수 있으나, 이에 한정되지 않는다. 또한, 상기 인터랙션의 대상은 적어도 하나의 하드웨어 장치를 포함할 수 있다. 예를 들어, 상기 인터랙션의 대상은 스마트폰을 포함할 수 있으며, 상기 스마트폰에 대한 사용자의 위치 변경 인터랙션을 획득하는 경우 적어도 하나의 동작을 수행하도록 설계될 수 있으나, 이에 한정되지 않는다. 이 때, 상기 적어도 하나의 하드웨어 장치는 스마트폰, 이어폰, 헤드폰, 조이콘 등 하드웨어 장치 및 주변 기기 를 모두 포함할 수 있으나, 이에 한정되지 않는다. 상기 입력 타입은 사용자로부터 획득되는 입력의 종류를 의미할 수 있다. 예를 들어, 상기 입력 타입은 터치 패 널을 이용한 터치 입력, 드래그 입력, 배쉬 입력, 스왑 입력, 특정 패턴 입력 등을 포함할 수 있으며, 적어도 하나의 입력 장치를 이용한 다양한 입력을 포함할 수 있고, 적어도 하나의 하드웨어 장치에 대한 쉐이크 입력, 스윙 입력 등 다양한 입력을 포함할 수 있으며, 카메라 등 센서를 이용한 모션 입력 사용자의 위치를 추적하여 가상의 공간에서 사용자의 위치와 오브젝트의 위치가 매칭되는 허공 터치 입력 등 다양한 입력을 포함할 수 있 으나, 이에 한정되지 않으며, 특정 동작을 수행하기 위해서 알고리즘으로 규정된 다양한 입력들을 포함할 수 있 다. 한편 기재된 예시 이외에도, 사용자의 입력이 아닌, 날씨 정보나 위치 정보와 같은 외부 정보들에 기반하여 음 악 테마가 변경되는 룰 정보이 구현될 수도 있다. 다양한 실시예들에 따르면, 스테이지 별로 룰 정보가 제공될 수 있다. 예를 들어 아래의 [표 1]을 참조하 면, 스테이지 별로 제공되는 룰 정보에 기반하여, 특정 사용자 인터랙션이 수신되는 경우 전자 장치에 의 해 그래픽 엘리먼트, 및 오디오 소스의 제어가 수행될 수 있다.표 1 스테이지 종류 오디오 소스 그래픽 오브젝트 룰 정보 인트로에 대응하 는 스테이지인트로에 대응하는 오 디오 소스- 원 형상의 유체 메인 오 브젝트- 구름 형상의 복수의 서브 오브젝트들- 메인 오브젝트 터치 시 제1 악기(예: 심벌)의 오디오 소스 재생 및 비주얼 이 펙트 적용 - 서브 오브젝트 터치 시 제2 악기(예: 플럭)의 오디오 소스 재생 및 비주얼 이 펙트 적용 후렴에 대응하는 스테이지후렴에 대응하는 오디 오 소스- 원 형상의 유체 메인 오 브젝트- 구름 형상의 복수의 서브 오브젝트들- 메인 오브젝트 터치 시 제3 악기(예: 턴테이블)의 오디오 소스 재생, 음악 테 마 랜덤 변경, 및 비주얼 테마 랜덤 변경 - 서브 오브젝트 터치 시 현재 재생 시점 에 대응하는 보컬 오디오 소스를 랜덤 음 높이로 재생, 및 비주얼 이펙트 적용 벌스-pre에 대응 하는 스테이지벌스-pre에 대응하는 오디오 소스- 원 형상의 유체 메인 오 브젝트- 굴곡진 긴 형상의 서로 다른 크기 또는 색상의 서브 오브젝트- 메인 오브젝트 터치 시, \"what\"이라는 보컬 오디오 소스 재생 - 각기 다른 서브 오브젝트 터치 시 랜덤 한 효과음 오디오 소스 재생 및 비주얼 이펙트 적용 벌스에 대응하는 스테이지벌스에 대응하는 오디 오 소스- 원 형상의 유체 메인 오 브젝트- 굴곡진 긴 형상의 서브 오브젝트- 메인 오브젝트 터치 시 제3 악기(예: 심벌)의 오디오 소스 재생, 곡 테마 랜덤 변경, 및 비주얼 테마 랜덤 변경 - 각기 다른 서브 오브젝트 터치 시 랜덤 한 효과음 오디오 소스 재생 및 비주얼 이펙트 적용 브릿지에 대응하 는 스테이지브릿지에 대응하는 오 디오 소스- 원 형상의 유체 메인 오 브젝트- 소용돌이 형상의 서 브 오브젝트- 메인 오브젝트 터치 시 현재 재생 시점 에 대응하는 오디오 소스 재생 및 비주얼 효과 적용 - 서브 오브젝트 터치 시 제4 악기(예: 심벌)의 오디오 소스 재생 및 비주얼 이 펙트 적용 한편 [표 1]에 기재된 예에 제한되지 않고, 다양한 음악의 부분들(예: 코러스, 송폼) 별로 대응하는 스테이지 별 룰 정보가 구현될 수 있다. 또 예를 들어, 아래의 [표 2]에 기재된 바와 같이 다양한 종류의 사용자 입 력에 대응하는 룰 정보 또한 구현될 수 있다. 표 2 사용자 입력 인터랙션 룰 줌-인 오디오 소스의 재생 속도를 느리게 제어 줌-아웃 오디오 소스의 재생 속도를 빠르게 제어 전자 장치를 흔듦킥 오디오 소스 재생소정 구간(예: 한 마디) 오디오 소스 재생 반복 3. 인터랙티브 음악 감상 파일의 배포 다양한 실시예들에 따르면, 어플리케이션의 실행에 기반하여, 저장되는 인터랙티브 음악 감상 파일(이하, 파일)(또는, 플랫폼 파일)은 저장 및/또는 배포될 수 있다. 예를 들어, 상기 음악 감상 파일은 사용자에 의해 입력된 인터랙션 정보와 함께 저장되어 배포될 수 있다. 상기 배포는 서버를 통해 수행될 수도 있으 나, 전자 장치들 간에 직접 수행될 수도 있다. 도 4는, 다양한 실시예들에 따른, 인터랙티브 음악 감상 파일의 배포의 예를 설명하기 위한 도면이다. 도 4를 참조하면, 배포 횟수(n)에 따라서 파일(A',A'', A''')은 동일한 음원 소스(A)와 룰 정보(R)을 포함하되 배포 횟수(n) 별로 사용자의 인터랙션에 의해 생성되는 인터랙션 정보(I1, I2, I3, I4)를 포함할 수 있다. 예를 들어, 뉴 디지털 싱글 파일이 최초 배포되기 이전에(n=1), 서버는 오디오 소스(A) 및 룰 정보 (R)을 포함하는 뉴 디지털 싱글 파일(A)을 구현할 수 있다. 상기 뉴 디지털 싱글 파일이이 제1 전자 장치로 최초 배포되는 경우(n=2), 제1 전자 장치는 뉴 디지털 싱 글 파일(A)을 재생하는 동안 제1 사용자로부터 제1 사용자 인터랙션을 수신함에 기반하여 제1 사용자 인터랙션 에 대한 제1 정보(I1)을 별도로 저장할 수 있다. 상기 사용자 인터랙션에 대한 제1 정보(I1)을 더 포함하는 일 은 A'로 정의될 수 있다. 이때 파일(A')은 다른 전자 장치(예: 제2 전자 장치)로 배포될 수 있고, 상기 제2 전자 장치는 사용자 인터랙션 에 대한 제1 정보(I1)에 기반하여 파일(A')을 재생하는 동안 제2 전자 장치의 제2 사용자로부터 제2 사용자 인 터랙션을 수신함에 기반하여 제2 사용자 인터랙션에 대한 제2 정보(I2)를 별도로 더 저장할 수 있다. 상기 사용 자 인터랙션에 대한 제1 정보(I1) 및 제2 정보(I2)를 더 포함하는 파일은 A''로 정의될 수 있다. 연속적으로 도 4에 도시된 바와 같이, 뉴 디지털 싱글 파일이 배포됨에 따라서 사용자 인터랙션에 대한 정보들 (I3, I4)이 추가되며, 사용자 인터랙션에 대한 정보들(I3, I4)이 추가된 뉴 디지털 싱글 파일들(A''', A'''')이 생성될 수 있다. 또한, 이 경우, 오디오 소스 A는 변형 없이 저장될 수 있어, 원 음원 소스를 추적하기 용이할 수 있으며, 각각 의 인터랙션들의 추가 삭제 변경 등이 자유로이 가능할 수 있다. 또한, 각각의 인터랙션은 하나의 음원 소스에 대해 시계열 적으로 저장될 수 있으며, 복수개의 음원 소스 각각 에 대해 시계열 적으로 저장될 수 있고, 복수개의 음원 소스의 시계열적 저장과 함께 시계열 적으로 저장될 수 있으나, 이에 한정되지 않는다. 또한, 각각의 사용자들은 변형된 음악에 대해 공유하기 위해 인터랙션 만을 공유할 수 있으나, 이에 한정되지 않는다. 또한, 각각의 사용자들은 변형된 음악에 대해 공유하기 위해 음원 소스와 음원 소스에 대응되는 인터랙션을 공 유할 수 있으나, 이에 한정되지 않는다. 또한, 각각의 사용자들은 변형된 음악에 대해 공유하기 위해 음원 소스에 대한 소정의 정보와 해당 음원 소스에 대응되는 인터랙션을 공유할 수 있으나, 이에 한정되지 않는다. 또한, 일 실시예에 따르면, 아래와 같은 저장 및 재생 기술이 적용될 수 있으나, 이에 한정되지 않는다. 이하에서는 다양한 실시예들에 따른, 전자 장치, 및 서버의 동작의 예에 대해서 설명한다. 4. 최상위 컨셉 도 5는, 다양한 실시예들에 따른, 전자 장치의 동작의 일 예를 설명하기 위한 도면이다. 도 5를 참조하면, 다양한 실시예들에 따르면, 전자 장치(예: 프로세서)는 제어 이벤트를 수신한 것에 기반하여 전자 장치에 의해 제공되는 시각적 컨텐트(100a)(예: 그래픽 엘리먼트 셋(500a)), 청각적 컨텐트(100b)(예: 오디오 소스 셋(500b)), 또는 시간 정보(100c)(예: 타임라인 및/또는 스테이지(500c)) 중 적 어도 하나를 제어하고, 상기 제어된 대상(예: 그래픽 엘리먼트 셋(500a))에 대응하는 다른 대상(예: 오디오 소 스 셋(500b))을 제어할 수 있다. 상기 전자 장치의 제어는 룰 정보에 기반할 수 있으므로, 중복되는 설명은 생략한다. 상기 제어 이벤트는 사용자의 입력에 의한 이벤트, 및 사용자의 입력이 없는 경우에 발생되는 이벤트를 포 함할 수 있으며, 이에 대해서는 이하의 도면들을 참조하여 설명한다. 4.1 사용자 인터랙션 시나리오(사용자 인터랙션 모드) 다양한 실시예들에 따르면, 전자 장치는 제어 이벤트를 식별하는 동작의 적어도 일부로 사용자의 입 력이 식별되는 경우, 시각적 컨텐트(100a)를 제어 및/또는 시간 정보(100c))(예: 타임라인)을 제어함으로써, 이 에 대응하는 청각적 컨텐트(100b)를 변형하여 제공할 수 있다. 도 6a는 다양한 실시예들에 따른, 전자 장치의 동작의 일 예를 설명하기 위한 흐름도이다. 다양한 실시예 들에 따르면, 도 6a에 도시되는 동작들은 도시되는 순서에 국한되지 않고 다양한 순서로 수행될 수 있다. 또한, 다양한 실시예들에 따르면, 도 6a에 도시되는 동작들 보다 더 많은 동작들이 수행되거나, 더 적은 적어도 하나 의 동작이 수행될 수도 있다. 이하에서는 도 6b를 참조하여 도 6a에 대해서 더 설명한다. 도 6b는 다양한 실시예들에 따른, 전자 장치의 사용자의 입력이 수신되는 경우 컨텐트들을 제어하는 동작 의 예를 설명하기 위한 도면이다.다양한 실시예들에 따르면, 전자 장치(예: 프로세서)는, 동작 601에서, 복수의 오디오 소스들에 대응 하는 음악 파일을 획득하고, 동작 603에서, 적어도 하나의 오브젝트를 포함하는 제1 화면을 표시하면서, 상기 음악 파일과 연관된 제1 시간 구간에 대응하는 제1 주파수 스펙트럼을 갖는 제1 사운드를 출력할 수 있다. 예를 들어 도 6b에 도시된 바와 같이, 전자 장치는 디스플레이 상에 제1 그래픽 오브젝트 셋(601a)을 포함하는 시각적 컨텐트(100a)를 표시하면서, 오디오 소스 셋(601b)을 재생함에 기반하여 청각적 컨텐트(100b)를 제공할 수 있다. 이때, 제공되는 청각적 컨텐트(100b)의 주파수 별 세기(주파수 스펙트럼)는 제1 주파수 스펙트럼일 수 있다. 다양한 실시예들에 따르면, 전자 장치(예: 프로세서)는, 동작 605에서, 제1 오브젝트에 대한 사용자 의 입력을 식별하고, 사용자의 입력이 식별되는 경우(605-예) 동작 607에서, 제1 조건이 만족되는지 여부를 판 단하고, 제1 조건이 만족되지 않는 것으로 판단된 경우(607-아니오) 동작 613에서 제2 조건이 만족되는지 여부 를 판단할 수 있다. 예를 들어 도 6b에 도시된 바와 같이, 전자 장치는 특정 오브젝트(예: 601a)에 대한 사용자의 입력(예: 인터랙션(A))가 수신되는 것으로 판단된 경우, 사용자의 입력과 연관된 조건들의 만족 여부 를 판단할 수 있다. 예를 들어, 사용자의 입력과 연관된 제1 조건은, 특정 종류의 사용자의 입력이 지정된 시간 동안 임계 횟수 미만으로 수신되는 경우, 만족될 수 있다. 일 예로, 지정된 시간 동안 단일의 터치 입력이나, 또는 드래그 입력이 수신되는 경우 제1 조건이 만족될 수 있다. 또 예를 들어, 사용자의 입력과 연관된 제2 조 건은, 특정 종류의 사용자의 입력이 지정된 시간 동안 임계 횟수 이상 수신되는 경우, 만족될 수 있다. 일 예로, 지정된 시간 동안 터치 입력이 임계 횟수 이상 수신되는 경우, 상기 제2 조건이 만족될 수 있다. 다양한 실시예들에 따르면, 사용자의 입력과 연관된 조건들 별로 룰 정보(또는 스킴)이 미리 지정되며, 전자 장 치는 만족된 조건에 대응하는 특정 룰 정보(또는 특정 스킴)에 기반하여 컨텐트(예: 시각적 컨텐트(100a), 청각적 컨텐트(100b), 및 시각 정보(100c))를 제어할 수 있다. 이에 따라, 아래의 전자 장치의 동작 609, 동작 611, 및 동작 615가 수행될 수 있다. 다양한 실시예들에 따르면, 전자 장치(예: 프로세서)는, 제1 조건이 만족된 경우(607-예) 동작 609에 서, 제1 입력인 경우 제1 시각적 이펙트가 적용된 제2 화면을 표시하면서 제2 주파수 스펙트럼을 갖는 제2 사운 드를 출력하고, 동작 611에서, 제2 입력인 경우 제1 시각적 이펙트가 적용된 제3 화면을 표시하면서 제3 주파수 스펙트럼을 갖는 제3 사운드를 출력할 수 있다. 예를 들어 전술한 제1 조건이 만족되는 경우, 전자 장치는 수신된 입력의 종류를 식별하고, 식별된 종류에 대응하는 방식(또는 스킴, 또는 룰)에 기반하여 시각적 컨텐트 (100a)의 속성을 및/또는 청각적 컨텐트(100b)의 속성을 제어할 수 있다. 일 예로 도 6b에 도시된 바와 같이, 상기 전자 장치는 터치 입력이 수신된 경우, 그래픽 엘리먼트(601a)의 적어도 일부의 형상을 변형하여 표 시하고, 제1 오디오 소스 셋(601b)의 적어도 일부의 속성(예: 출력 여부, 음 높이, 종류, 크기, 재생 속도)을 변형하여 재생함으로써 변형된 주파수 스펙트럼(예: 주파수 별 세기(또는 에너지))의 청각적 컨텐트(100b)(또는 사운드)를 출력할 수 있다. 이에 따라, 사용자는 사운드를 감상하면서, 그래픽 엘리먼트(601a)를 제어함으로써 다른 분위기(예: 다른 주파수 스펙트럼)의 사운드를 감상할 수 있게 된다. 또 일 예로 도시되지 않았으나, 상기 전자 장치는 드래그 입력이 수신된 경우, 그래픽 엘리먼트(601a)의 적어도 일부의 위치를 이동시켜 표시하 고, 제1 오디오 소스 셋(601b)의 적어도 일부의 속성(예: 출력 여부, 음 높이, 종류, 크기, 재생 속도)을 변형 하여 재생함으로써 변형된 주파수 스펙트럼(예: 주파수 별 세기(또는 에너지))의 청각적 컨텐트(100b)(또는 사 운드)를 출력할 수도 있다. 이때, 제공되는 청각적 컨텐트(100b)의 주파수 별 세기(주파수 스펙트럼)는 제2 주 파수 스펙트럼일 수 있다. 도 6b에 도시된 바와 같이, 음원 속성의 변경에 따라서 높은 주파수 대역의 사운드의 세기가 커져, 더 고조된 청각적 컨텐트(100b)가 제공될 수 있다. 다양한 실시예들에 따르면, 전자 장치(예: 프로세서)는, 제2 조건이 만족된 경우(613-예) 동작 615에 서, 상기 음악 파일과 연관된 제2 시간 구간(예: 다른 스테이지)에 대응하는 제2 주파수 스펙트럼을 갖는 제2 사운드를 출력할 수 있다. 예를 들어 전술한 제2 조건이 만족되는 경우, 전자 장치는 현재 스테이지(예: 제1 스테이지(601c))를 다른 스테이지(예: 제2 스테이지(미도시))로 변경하고, 다른 스테이지(예: 제2 스테이지 (미도시))에 대응하는 그래픽 엘리먼트 셋(예: 제2 그래픽 엘리먼트 셋(미도시))을 포함하는 시각적 컨텐트 (100a)를 표시하고, 오디오 소스 셋(예: 제2 오디오 소스 셋(미도시))을 재생함으로써, 다른 주파수 스펙트럼의 청각적 컨텐트(100b)를 제공할 수 있다. 4.2 사용자 논-인터랙션 시나리오(사용자 논-인터랙션 모드) 다양한 실시예들에 따르면, 전자 장치는 제어 이벤트를 식별하는 동작의 적어도 일부로 사용자의 입 력 이외의 다른 요소가 식별되는 경우, 시각적 컨텐트(100a) 및/또는 시간 정보(100c)(예: 타임라인)의 적어도일부를 제어하고, 상기 제어에 기반하여 청각적 컨텐트(100b)를 변형하여 제공할 수 있다. 도 7a는 다양한 실시예들에 따른, 전자 장치의 동작의 일 예를 설명하기 위한 흐름도이다. 다양한 실시예 들에 따르면, 도 7a에 도시되는 동작들은 도시되는 순서에 국한되지 않고 다양한 순서로 수행될 수 있다. 또한, 다양한 실시예들에 따르면, 도 7a에 도시되는 동작들 보다 더 많은 동작들이 수행되거나, 더 적은 적어도 하나 의 동작이 수행될 수도 있다. 이하에서는 도 7b를 참조하여 도 7a에 대해서 더 설명한다. 도 7b는 다양한 실시예들에 따른, 전자 장치의 사용자의 입력 이외의 다른 정보가 수신되는 경우, 컨텐트 들을 제어하는 동작의 예를 설명하기 위한 도면이다. 다양한 실시예들에 따르면, 전자 장치(예: 프로세서)는, 동작 701에서, 복수의 오디오 소스들에 대응 하는 음악 파일을 획득하고, 동작 703에서, 적어도 하나의 오브젝트를 포함하는 제1 화면을 표시하면서, 상기 음악 파일과 연관된 제1 시간에 대응하는 제1 주파수 스펙트럼을 갖는 제1 사운드를 출력할 수 있다. 예를 들어 도 7b에 도시된 바와 같이, 전자 장치는 디스플레이 상에 제1 그래픽 오브젝트 셋(701a)을 포함하는 시각 적 컨텐트(100a)를 표시하면서, 오디오 소스 셋(701b)을 재생함에 기반하여 청각적 컨텐트(100b)를 제공할 수 있다. 이때, 제공되는 청각적 컨텐트(100b)의 주파수 별 세기(주파수 스펙트럼)는 제1 주파수 스펙트럼일 수 있 다. 다양한 실시예들에 따르면, 전자 장치(예: 프로세서)는, 동작 705에서, 이벤트(예: 제어 이벤트 )의 발생 여부를 판단하고, 이벤트(예: 제어 이벤트)가 발생된 경우(705-예) 동작 707에서, 발생된 이벤트(예: 제어 이벤트)의 종류가 화면 제어를 위한 제1 종류인지 여부를 판단하고, 제1 종류가 아닌 경 우(707-아니오) 동작 711에서, 발생된 이벤트(예: 제어 이벤트)의 종류가 사운드 제어를 위한 제2 종류인 지 여부를 판단할 수 있다. 예를 들어 전자 장치는, 사용자의 입력이 수신되지 않는 동안(예: 전자 장치 의 모드가 사용자 논-인터랙션 모드로 설정되는 동안), 다양한 종류의 제어 이벤트를 식별하는 동작 을 수행할 수 있다. 전자 장치는 상기 제어 이벤트를 식별하는 동작의 적어도 일부로, 타임라인(dt) 의 변경(예: 제1 타임라인(701c)에서 제2 타임라인(703c)로 변경)에 따라 자동으로(automatically) 변경되는 시 각적 컨텐트(100a)(예: 그래픽 엘리먼트 셋(701a))의 속성(예: 캐릭터의 위치)의 변경을 식별할 수 있다. 전자 장치의 디스플레이 상에 표시되는 시각적 컨텐트(100a)의 속성은 시간에 따라 랜덤하게 변경되도록 미리 기-설정되어 있을 수 있다. 일 예로, 디스플레이 상에 표시되는 캐릭터가 자동으로 이동되도록 기-설정될 수 있 으며, 기재된 예에 제한되지 않고 다양한 종류의 그래픽 엘리먼트의 다양한 종류의 속성이 변경되도록 기-설정 될 수 있다. 또 예를 들어 도시되지 않았으나, 전자 장치는 제어 이벤트를 식별하는 동작의 적어도 일부로, 시간의 흐름에 따라 자동으로 변경되는 스테이지를 식별할 수 있다. 다양한 실시예들에 따르면, 전자 장치는 전술한 타임라인(dt)의 변경 및/또는 스테이지의 변경이 식 별된 이후, 경과된 시간이 임계 값을 초과하는지 여부를 판단하고, 상기 임계 값을 초과하는 경우에 상기 제어 이벤트가 발생된 것으로 결정할 수 있으나, 기재된 예에 제한되지는 않는다. 다양한 실시예들에 따르면, 전자 장치는 식별된 제어 이벤트의 종류를 식별할 수 있다. 상기 종류는 시각적 컨텐트(100a)의 속성, 및 청각적 컨텐트(100b)의 속성을 제어하기 위한 종류를 포함할 수 있다. 일 예를 들어, 도 7b에 도시된 바와 같이, 전자 장치는 타임라인의 변경(예: 제1 타임라인(701c)에서 제2 타 임라인(703c)로 변경)을 식별하는 경우 시각적 컨텐트(100a)의 속성을 변경하기 위한 제1 종류의 이벤트가 발생 된 것으로 식별할 수 있다. 다양한 실시예들에 따르면, 전자 장치(예: 프로세서)는, 발생된 이벤트가 화면 제어를 위한 제1 종류 인 경우(707-예) 동작 709에서, 상기 적어도 하나의 제1 오브젝트의 제1 시각적 속성을 변경하고 상기 시각적 속성의 변경에 기반하여 상기 제1 사운드의 제1 청각적 속성을 변경하고, 발생된 이벤트가 사운드 제어를 위한 제2 종류인 경우(711-예) 동작 713에서, 상기 제1 사운드의 제2 청각적 속성을 변경하고 상기 청각적 속성의 변 경에 기반하여 상기 제1 오브젝트의 제2 시각적 속성을 변경할 수 있다. 예를 들어 전자 장치는 특정 종류 의 컨텐트(예: 시각적 컨텐트(100a), 또는 청각적 컨텐트(100b))를 제어하기 위한 특정 종류의 이벤트가 발생되 는 경우, 특정 종류의 이벤트에 대응하는 특정 종류의 컨텐트의 속성을 변경하고, 상기 특정 종류의 컨텐트의 속성의 변경 및 이에 대응하는 룰 정보에 기반하여, 연쇄적으로 다른 종류의 컨텐트의 속성을 변경할 수 있다. 일 예를 들어, 룰 정보는 특정 시각적 컨텐트(100a)(예: 그래픽 엘리먼트 셋)가 제어되는 것에 대한 응답으로, 청각적 컨텐트(100b)를 제어하도록 구현될 수 있다. 이 경우, 전자 장치는 사용자의 인터랙션과 는 관계없이, 이벤트의 발생(예: 타임라인(dt)의 변경)에 기반하여 특정 시각적 컨텐트(100a)의 속성이 제어되 는 경우(예: 그래픽 제1 엘리먼트 셋(701a)가 제2 그래픽 엘리먼트 셋(703a)으로 변경), 룰 정보에 기반하여 연쇄적으로 청각적 컨텐트(100b)의 속성을 제어(예: 제1 오디오 소스 셋(701b)을 제2 오디오 소스 셋(703b)로 변 경)할 수 있다. 반대로, 룰 정보는 특정 청각적 컨텐트(100b)(예: 오디오 소스 셋)가 제어되는 것에 대한 응답으로, 시각적 컨텐트(100a)를 제어하도록 구현될 수도 있다. 4.3 모드 전환 시나리오 다양한 실시예들에 따르면, 전자 장치는 제어 이벤트를 식별하기 위한 모드를 전환할 수 있다. 상기 모드는 전술한 사용자 인터랙션 모드 및 사용자 논-인터랙션 모드를 포함할 수 있다. 도 8a는 다양한 실시예들에 따른, 전자 장치의 동작의 일 예를 설명하기 위한 흐름도이다. 다양한 실시예 들에 따르면, 도 8a에 도시되는 동작들은 도시되는 순서에 국한되지 않고 다양한 순서로 수행될 수 있다. 또한, 다양한 실시예들에 따르면, 도 8a에 도시되는 동작들 보다 더 많은 동작들이 수행되거나, 더 적은 적어도 하나 의 동작이 수행될 수도 있다. 이하에서는 도 8b를 참조하여 도 8a에 대해서 더 설명한다. 도 8b는 다양한 실시예들에 따른, 전자 장치의 모드 전환 동작의 예를 설명하기 위한 도면이다. 다양한 실시예들에 따르면, 전자 장치(예: 프로세서)는, 동작 801에서, 복수의 오디오 소스들에 대응 하는 음악 파일을 획득하고, 동작 803에서, 적어도 하나의 오브젝트를 포함하는 제1 화면을 표시하면서, 상기 음악 파일과 연관된 제1 시간에 대응하는 제1 주파수 스펙트럼을 갖는 제1 사운드를 출력할 수 있다. 다양한 실시예들에 따르면, 전자 장치(예: 프로세서)는, 동작 805에서, 모드를 결정하기 위한 이벤트 를 식별할 수 있다. 동작 807에서, 식별된 이벤트가 제1 이벤트인지 여부를 판단하고, 상기 제1 이벤트가 아닌 경우(807-아니오), 동작 809에서, 식별된 이벤트가 제2 이벤트인지 여부를 판단할 수 있다. 다양한 실시예들에 따르면, 전자 장치(예: 프로세서)는, 전자 장치는 식별된 이벤트가 제1 이벤 트인 경우(807-예), 전자 장치의 모드를 사용자 인터랙션 모드로 설정하고, 도 6a 내지 도 6b에서의 전술 한 적어도 하나의 동작을 수행할 수 있다. 전자 장치는 식별된 이벤트가 제2 이벤트인 경우(809-예), 전자 장치의 모드를 사용자 논-인터랙션 모드로 설정하고, 전술한 도 7a 내지 도 7b에서 전술한 적어도 하나의 동작을 수행할 수 있다. 예를 들어, 전자 장치는 모드를 결정하기 위한 이벤트를 식별하는 동작의 적어도 일부로, 시간과 연관된 정보(예: 도 8b의 (a))를 식별하는 동작 및/또는 거리와 연관된 조건(예: 도 8b의 (b))을 식별하는 동작을 수행 할 수 있다. 일 예로 도 8b의 (a)에 도시된 바와 같이, 전자 장치는 특정 스테이지에 진입 후 및/또는 어 플리케이션 실행 후 경과된 시간이 기-설정된 값 미만인 경우 제1 이벤트로 판단하고 전자 장치의 모드를 사용자 인터랙션 모드로 설정하고, 기-설정된 값을 초과하는 경우 제2 이벤트로 판단하고 전자 장치의 모 드를 사용자 논-인터랙션 모드로 설정할 수 있다. 또 일 예로 도 8b의 (b)에 도시된 바와 같이, 전자 장치(11 0)는 사용자(U)와의 거리가 기-설정된 값 미만인 경우 제1 이벤트로 판단하고 전자 장치의 모드를 사용자 인터랙션 모드로 설정하고, 기-설정된 값 이상인 경우 제2 이벤트로 판단하고 전자 장치의 모드를 사용자 논-인터랙션 모드로 설정할 수 있다. 5. 세계관 UI 도 9는, 다양한 실시예들에 따른, 전자 장치의 동작의 예를 설명하기 위한 도면이다. 도 9를 참조하면, 다양한 실시예들에 따르면, 전자 장치(예: 프로세서)는 제어 이벤트의 발생에 기반하여, 시각적 컨텐트(100a)(예: 그래픽 엘리먼트 셋(900a))의 적어도 일부, 청각적 컨텐트(100b)(예: 오디 오 소스 셋(901b))의 적어도 일부, 또는 시간 정보(100c)(예: 타임라인 및/또는 스테이지(900c)) 중 적어도 하 나를 제어할 수 있다. 이때, 상기 그래픽 엘리먼트 셋(900a)는 메인 오브젝트(900a), 서브 오브젝트(903a), 및 부가 오브젝트(905a)를 포함하도록 구현되며, 메인 오브젝트(900a)는 상기 오디오 소스 셋(901b)의 복수의 오디 오 소스들(901b, 903b)의 적어도 일부의 속성을 제어하도록 구현될 수 있다. 5.1 세계관 UI의 구성 요소 도 10은, 다양한 실시예들에 따른, 전자 장치의 동작의 예를 설명하기 위한 흐름도이다. 다양한 실 시예들에 따르면, 도 10에 도시되는 동작들은 도시되는 순서에 국한되지 않고 다양한 순서로 수행될 수 있다. 또한, 다양한 실시예들에 따르면, 도 10에 도시되는 동작들 보다 더 많은 동작들이 수행되거나, 더 적은 적어도 하나의 동작이 수행될 수도 있다. 이하에서는 도 11을 참조하여 도 10에 대해서 더 설명한다. 도 11a는, 다양한 실시예들에 따른, 전자 장치에 의해 제공되는 시각적 컨텐트의 일 예를 설명하기 위한 도면이다. 도 11b는, 다양한 실시예들에 따른, 전자 장치에 의해 제공되는 시각적 컨텐트의 다른 예를 설 명하기 위한 도면이다. 도 11c는, 다양한 실시예들에 따른, 전자 장치에 의해 제공되는 시각적 컨텐트의 또 다른 예를 설명하기 위한 도면이다. 다양한 실시예들에 따르면, 전자 장치(예: 프로세서)는, 동작 1001에서, 복수의 오디오 소스들을 획 득하고, 동작 1003에서, 복수의 오디오 소스들의 적어도 일부의 속성을 제어하도록 구현되는 복수의 메인 그래 픽 오브젝트들(예: 도 11a의 그래픽 오브젝트(901a)) 및 상기 복수의 메인 그래픽 오브젝트들을 연결하는 복수 의 서브 그래픽 오브젝트들(예: 도 11a의 그래픽 오브젝트(903a))을 표시할 수 있다. 상기 메인 그래픽 오브젝 트(901a) 별로, 오디오 소스의 음 높이, 재생 속도, 재생 여부와 같은 서로 다른 속성을 제어하도록 구현될 수 있으며, 상기 속성의 예에 대해서는 “목차. 2.2.1”에서 전술하였으므로, 중복되는 설명은 생략한다. 상기 메 인 그래픽 오브젝트(901a) 별로 제어 가능한 속성은 랜덤하게 부여되거나 및/또는 위치 별로 기-설정된 속성이 부여될 수도 있다. 다양한 실시예들에 따르면, 상기 메인 오브젝트(901a)의 형상은 도 11a의 (a)의 원형, 그리고 (b)의 삼각형으로 구현될 수 있으나, 기재된 및/또는 도시된 예에 제한되지 않고 다양한 종류의 형상으로 구현될 수 있다. 다양한 실시예들에 따르면, 상기 메인 그래픽 오브젝트(901a)는 제1 종류의 메인 그래픽 오브젝트(1101a) 및 제 2 종류의 메인 그래픽 오브젝트(1103a)를 포함할 수 있다. 상기 제1 종류의 메인 그래픽 오브젝트(1101a)는 관 절 오브젝트로 명명되며, 제2 종류의 메인 그래픽 오브젝트(1103a)는 머리 오브젝트로 명명될 수 있다. 일 실시 예에서, 상기 관절 오브젝트(1101a)의 위치와 상기 머리 오브젝트(1103a)의 위치는 서로 다른 지점에 표시되도 록 설정될 수 있다. 예를 들어, 상기 관절 오브젝트(1101a)는 서브 오브젝트(903a)가 연결되는 지점 및/또는 서 브 오브젝트(903a)의 일 단부에 위치될 수 있으나, 상기 머리 오브젝트(1103a)는 서브 오브젝트(903a)의 단부에 만 위치되도록 구현될 수 있으나, 기재된 예와 반대로 구현될 수도 있다. 또 일 실시예에서, 상기 관절 오브젝 트(1101a)의 크기와 상기 머리 오브젝트(1103a)의 크기는 서로 다르도록 설정될 수 있다. 예를 들어, 상기 관절 오브젝트(1101a)의 크기가 상기 머리 오브젝트(1103a)의 크기보다 작도록 구현될 수 있으나, 기재된 예와 반대 로 구현될 수도 있다. 또 일 실시예에서, 상기 관절 오브젝트(1101a)와 상기 머리 오브젝트(1103a)는 서로 다른 방식으로 오디오 소스의 속성을 제어하도록 구현될 수 있다. 다양한 실시예들에 따르면, 상기 메인 그래픽 오브젝트(901a)와 상기 서브 그래픽 오브젝트(903a)의 속성(예: 위치, 형상)은 제어될 수 있다. 예를 들어, 특정 메인 그래픽 오브젝트(901a)의 위치는 이동(예: 좌/우로 이 동)될 수 있다. 이때, 특정 메인 그래픽 오브젝트(901a)가 이동됨에 따라, 특정 메인 그래픽 오브젝트(901a)와 다른 그래픽 오브젝트(901a)를 연결하는 서브 그래픽 오브젝트(903a)의 형상(예: 길이)이 변경될 수 있다. 상기 메인 그래픽 오브젝트(901a)의 이동은, 사용자의 입력에 의한 이동, 및 자동으로 수행되는 랜덤 이동을 포함할 수 있다. 상기 메인 그래픽 오브젝트(901a)가 자동으로 랜덤하게 이동되는 경우, 상기 메인 그래픽 오브젝트 (901a)는 상기 복수의 오디오 소스들에 기반하여 식별되는 음악적 단위(예: 박자)에 대응하는 주기로 이동될 수 있다. 이에 따라, 전체적인 오브젝트(예: 메인 그래픽 오브젝트(901a)와 서브 그래픽 오브젝트(903a))의 형상이 마치 음악에 맞추어 움직이는(또는 춤을 추는) 생물로 사용자에게 인식되어, 음악의 더 생동감 있는 감상이 가 능해질 수 있다. 다양한 실시예들에 따르면, 도 11c를 참조하면, 상기 메인 그래픽 오브젝트(1301c, 1303c, 1305c)가 이동됨에 따라서 서로 중첩되는 경우에는, 소정의 형상(예: 삼각형, 사각형과 같은 다각형)을 형성하도록 메인 그래픽 오 브젝트(1301c, 1303c, 1305c)의 위치와 이를 연결하는 서브 오브젝트(903a)의 위치가 설정될 수 있다. 다양한 실시예들에 따르면, 도 11a를 참조하면, 전자 장치는 적어도 하나의 부가 오브젝트(905a)를 더 표 시할 수 있다. 부가 오브젝트(905a)는 도시된 바와 같이 십자 형태로 구현될 수 있으나, 다양한 형상으로 구현 될 수 있음은 당업자에 의해 자명하다. 상기 부가 오브젝트(905a)는 상기 메인 오브젝트(901a)와 상기 서브 오 브젝트(903a)의 위치 이외의 배경 영역에서 생성되어, 임의의 한 방향(예: 아래 방향)으로 이동될 수 있다. 상 기 부가 오브젝트의 생성 시기는 상기 복수의 오디오 소스들의 음악적 단위(예: 박자, 마디)에 기초하여 결정될 수 있다. 상기 부가 오브젝트(905a)는 선택되는 경우, 기-설정된 및/또는 랜덤하게 설정되는 오디오 효 과 및/또는 시각적 효과를 제공할 수 있다. 다양한 실시예들에 따르면, 도 11b의 (a) 내지 (d)를 참조하면, 리듬 노트(1100b)는 복수의 오디오 소스들에 기 반한 음악적 단위(예: 박자, 마디)를 시인하도록 제공될 수 있다. 예를 들어, 상기 리듬 노트(1100b)는 머리 오 브젝트(1103a)와 가장 먼 메인 오브젝트(901a)(이하, 꼬리 오브젝트)에서 생성되어, 상기 부가 오브젝트(905a) 의 이동 방향과는 다르게(또는 반대로) 머리 오브젝트(1103a) 방향으로 서브 오브젝트(903a)를 따라서 이동될수 있다. 이때, 리듬 노트(1100b)가 머리 오브젝트(1103a)에 도달되는 경우, 소멸되며 시각적 이펙트가 제공되 거나 및/또는 오디오 소스의 속성이 제어될 수 있다. 한편, 기재된 예와 반대로 리듬 노트(1100b)가 이동되어 소멸될 수 있다. 이때, 상기 리듬 노트(1100b)가 이동하면서 상기 메인 오브젝트들(901a)과 중첩되는 시점은, 상기 복수의 오디오 소스들의 음악적 단위(예: 박자, 마디)에 기초하여 결정될 수 있으며, 이에 따라 사용자는 상기 리듬 노트(1100b)의 위치를 통해서 음악의 음악적 단위를 인지할 수 있게 된다. 5.2 메인 오브젝트 개수 설정 및 메인 오브젝트 기반 제어 동작 도 12a는, 다양한 실시예들에 따른, 전자 장치의 동작의 예를 설명하기 위한 흐름도이다. 다양한 실 시예들에 따르면, 도 12a에 도시되는 동작들은 도시되는 순서에 국한되지 않고 다양한 순서로 수행될 수 있다. 또한, 다양한 실시예들에 따르면, 도 12a에 도시되는 동작들 보다 더 많은 동작들이 수행되거나, 더 적은 적어 도 하나의 동작이 수행될 수도 있다. 이하에서는 도 12b 및 도 12c를 참조하여 도 12a에 대해서 더 설명한다. 도 12b는, 다양한 실시예들에 따른, 전자 장치의 메인 오브젝트(901a)의 개수를 설정하는 동작의 예를 설 명하기 위한 도면이다. 도 12c는, 다양한 실시예들에 따른, 전자 장치의 메인 오브젝트(901a)의 이동에 따 라서 오디오 소스의 속성을 제어하는 동작의 예를 설명하기 위한 도면이다. 다양한 실시예들에 따르면, 전자 장치(예: 프로세서)는, 동작 1201에서, 복수의 오디오 소스들(예: 도 12b의 제1 내지 제4 오디오 소스(1200a, 12200b, 1200c, 1200d))에 기반한 음악적 단위(예: 박자, 마디)를 식별하고, 동작 1203에서, 식별된 음악적 단위에 대응하는 개수의 복수의 메인 그래픽 오브젝트들을 포함하는 실행 화면을 표시하면서 상기 복수의 오디오 소스들에 기반하여 제1 사운드(예: 음악)를 출력할 수 있다. 예를 들어 도 12c에 도시된 바와 같이, 전자 장치는 식별된 음악적 단위가 4/4박자인 경우, 4개의 메인 그래픽 오브젝트들(901a)을 표시하고, 상기 메인 그래픽 오브젝트들(901a)을 연결하는 3개의 서브 오브젝트들(903a)을 표시할 수 있다. 음악을 청취하는 사용자로 하여금 상기 박자를 나타내는 메인 그래픽 오브젝트(901a)의 개수를 기반으로 음악의 박자를 더 용이하게 인지하도록 하며, 결과적으로 사용자가 박자에 맞추어 오디오의 속성을 제 어하도록 가이드하여 인터랙티브한 음악 감상의 질이 향상되도록 할 수 있다. 다양한 실시예들에 다르면, 전자 장치는 시간의 흐름에 따라 식별된 음악적 단위에 기반하여 메인 오브젝 트(903a)에 시각적 효과를 제공할 수 있다. 예를 들어, 전자 장치는 전술한 바와 같이 리듬 노트를 상기 박자에 따라서 메인 오브젝트(901a) 상에 위치할 수 있다. 또 예를 들어, 전자 장치는 박자 별로 메인 오 브젝트(901a)의 속성(예: 크기, 색상)을 제어할 수도 있다. 이에 따라, 음악적 단위에 대한 사용자의 인식률이 향상될 수 있다. 다양한 실시예들에 따르면, 전자 장치(예: 프로세서)는, 동작 1205에서, 복수의 메인 그래픽 오브젝 트들 중 특정 메인 그래픽 오브젝트를 제어하기 위한 사용자 입력(예: 터치 입력, 드래그 입력)을 식별할 수 있 다. 다양한 실시예들에 따르면, 전자 장치(예: 프로세서)는, 동작 1207에서, 이동 방향이 제1 방향인지 여부를 판단하고, 제1 방향인 경우(1207-예) 동작 1209에서, 상기 복수의 오디오 소스들 중 적어도 일부의 속성 을 제1 방식(예: 제1 크기로 오디오 효과 적용)에 기반하여 제어함으로써 제2 사운드를 출력하고, 제1 방향이 아닌 경우(1207-아니오), 동작 1211에서, 이동 방향이 제2 방향인지 여부를 판단하고, 제2 방향인 경우(1211-예) 동작 1213에서, 상기 복수의 오디오 소스들 중 적어도 일부의 속성을 제2 방식(예: 제2 크기로 오디오 효과 적용)에 기반하여 제어함으로써 제3 사운드를 출력할 수 있다. 예를 들어 도 12c에 도시된 바와 같 이, 전자 장치는 메인 오브젝트(901a)에 대한 드래그 입력이 수신되는 경우, 이동 방향 및 이동 거리에 따 라서 결정되는 메인 오브젝트(901a)의 위치에 따라서 서로 다른 오디오 효과(1210a, 1210b)를 적용할 수 있다. 예를 들어, 서로 다른 오디오 효과를 적용하는 동작은 속성을 제어하는 정도를 다르게 적용하는 동작을 포함할 수 있으나, 기재된 예에 제한되지 않을 수 있다. 다양한 실시예들에 따르면, 메인 오브젝트(901a) 별로 이동 방향(또는, 위치의 변경 방향)은 제1 방향과 제1 방 향의 반대 방향인 제2 방향으로 설정될 수 있다. 예를 들어 도 12c에 도시된 바와 같이 좌측과 우측일 수 있으 나, 기재된 예에 제한되지 않고 상측과 하측, 대각 우측과 대각 좌측 등으로 구현될 수도 있다. 이에 따라, 사 용자는 직관적으로 메인 오브젝트(901a)를 제어하여, 감상하는 음악을 제어할 수 있게 된다. 다양한 실시예들에 따르면, 전자 장치(예: 프로세서)는, 제1 방향 및 제2 방향이 아닌 경우(1211-아 니오) 동작 1215에서, 배경에 대한 시각적 효과를 제공(예: 색상 변경, 특정 색상의 컨텐트를 제공)하면서 오디 오 효과를 제공할 수 있다. 예를 들어, 전자 장치는 메인 오브젝트(901a)에 대한 터치 입력이 수신되는 경우, 드래그 입력을 수신한 경우와는 다른 오디오 효과(예: 제3 오디오 효과)를 적용할 수 있다. 다양한 실시예들에 따르면, 전자 장치(예: 프로세서)는 터치의 속성(예: 강도)에 따라서 서로 다른 시각적 효과(예: 색상을 다르게 함) 및/또는 오디오 효과를 제공할 수 있다. 다양한 실시예들에 따르면, 전자 장치(예: 프로세서)는 복수의 오디오 소스들에 대응하는 음원 파일 의 종류에 따라 동일한 터치 입력이더라도, 서로 다른 시각적 효과(예: 색상을 다르게 함) 및/또는 오디오 효과 를 제공할 수 있다. 5.3. 신규 메인 오브젝트 생성 동작 도 13a는, 다양한 실시예들에 따른, 전자 장치의 동작의 예를 설명하기 위한 흐름도이다. 다양한 실 시예들에 따르면, 도 12a에 도시되는 동작들은 도시되는 순서에 국한되지 않고 다양한 순서로 수행될 수 있다. 또한, 다양한 실시예들에 따르면, 도 13a에 도시되는 동작들 보다 더 많은 동작들이 수행되거나, 더 적은 적어 도 하나의 동작이 수행될 수도 있다. 이하에서는 도 13b를 참조하여 도 13a에 대해서 더 설명한다. 도 13b는, 다양한 실시예들에 따른, 전자 장치의 신규 오브젝트를 생성하는 동작의 예를 설명하기 위한 도 면이다. 도 13c는, 다양한 실시예들에 따른, 전자 장치의 신규 오브젝트를 생성하는 동작의 예를 설명하기 위한 도면이다. 다양한 실시예들에 따르면, 전자 장치(예: 프로세서)는 전술한 동작 1201 내지 동작 1203을 수행한 이후, 동작 1301에서 사용자의 입력을 식별할 수 있다. 다양한 실시예들에 따르면, 전자 장치(예: 프로세서)는, 동작 1303에서, 식별된 사용자의 입력이 오 브젝트의 생성을 위한 입력인지 여부를 판단하고, 오브젝트의 생성을 위한 입력인 경우(1303-예) 동작 1305에서, 복수의 오디오 소스들의 특정 속성을 제어하기 위한 오브젝트를 더 표시할 수 있다. 예를 들어 도 13b에 도시된 바와 같이, 전자 장치는 복수의 서브 오브젝트들(903a) 중 일부에 대한 사용자 입력을 수신 하는 경우, 사용자 입력이 수신된 위치에 새로 생성된 메인 오브젝트를 표시할 수 있다. 이때, 전자 장치 는 새로 생성된 메인 오브젝트와 기존의 메인 오브젝트(901a)를 연결하는 새로운 서브 오브젝트 (1310, 1320)를 표시할 수 있다. 또 예를 들어 도시되지 않았으나, 전자 장치는 메인 오브젝트(901a)에 대 해서 특정 종류의 사용자 입력이 수신되는 경우, 새로운 메인 오브젝트(901a)를 표시할 수도 있다. 다양한 실시예들에 따르면, 전자 장치(예: 프로세서)는 메인 오브젝트(901a)의 개수가 변경되는 경우, 스테이지를 변경하거나, 및/또는 오디오 소스 셋을 변경할 수 있다. 또 다양한 실시예들에 따르면, 전자 장치(예: 프로세서)는 메인 오브젝트(901a)의 개수가 변경되는 경우, 신규 생성된 메인 오브젝트에 대한 사용자의 입력의 종류에 기반하여 적어도 하나의 동작을 수행할 수 있 다. 예를 들어, 전자 장치(예: 프로세서)는 신규 생성된 메인 오브젝트의 생성 후 확대 및 축소 동작 이 식별되는 경우, 특정 오디오 효과를 적용하거나, 및/또는 재생되는 오디오 소스의 출력 레벨 조절(예: 확대 시 출력 레벨이 높아지고, 축소 시 출력 레벨이 낮아짐)할 수 있다. 또, 전자 장치(예: 프로세서)는 신규 생성된 메인 오브젝트에 대한 사용자 입력(ex. 터치)이 식별되는 경우, 오디오 효과를 적용할 수 있다. 또, 전자 장치(예: 프로세서)는 신규 생성된 메인 오브젝트의 내부가 터치되는 경우, 다른 스테이지 로 이동할 수 있다. 또, 전자 장치(예: 프로세서)는 스핀 입력이 식별되는 경우, 오디오 및/또는 시 각적 효과를 제공할 수 있다. 또 다양한 실시예들에 따르면, 전자 장치(예: 프로세서)는 메인 오브젝트(901a)의 개수가 변경되는 경우, 복수의 오디오 소스들의 음악적 단위(예: 박자)를 변경할 수 있다. 예를 들어, 전자 장치는 메인 오 브젝트(901a)의 개수가 4개에서 8개로 증가되는 경우, 박자를 4/4박자에서 8/8박자로 변경할 수 있다. 전자 장 치는 박자를 변경하는 동작의 적어도 일부로, 메인 오브젝트(901a)의 개수가 임계 개수에 도달되는지 여부 를 판단할 수 있다. 전자 장치는 상기 메인 오브젝트(901a)의 개수가 4개에서 증가하여 임계 개수(예: 8개)에 도달되기 전까지는 박자 변경 동작을 삼가하고, 메인 오브젝트(901a)의 개수 가 임계 개수에 도달되는 경우 박자 변경 동작을 수행할 수 있다. 상기 임계 개수는 최초의 음악적 단위(예: 박자)에 기반하여 결정될 수 있다. 5.4. 메인 오브젝트에 대한 입력 기반 효과 제공 동작 도 14a는, 다양한 실시예들에 따른, 전자 장치의 동작의 예를 설명하기 위한 흐름도이다. 다양한 실 시예들에 따르면, 도 14a에 도시되는 동작들은 도시되는 순서에 국한되지 않고 다양한 순서로 수행될 수 있다.또한, 다양한 실시예들에 따르면, 도 14a에 도시되는 동작들 보다 더 많은 동작들이 수행되거나, 더 적은 적어 도 하나의 동작이 수행될 수도 있다. 이하에서는 도 14b를 참조하여 도 14a에 대해서 더 설명한다. 도 14b는, 다양한 실시예들에 따른, 전자 장치의 사용자의 입력이 배경 화면 상에 수신되는 경우, 오브젝 트의 위치를 제어하는 동작의 예를 설명하기 위한 도면이다. 다양한 실시예들에 따르면, 전자 장치(예: 프로세서)는, 동작 1401에서, 사용자 입력을 식별할 수 있 다. 다양한 실시예들에 따르면, 전자 장치(예: 프로세서)는, 동작 1403에서, 사용자 입력이 오브젝트(예: 메인 그래픽 오브젝트(901a))에 대한 입력인지 여부를 판단하고, 오브젝트에 대한 입력인 경우(1403-예), 동작 1405에서, 제1 그래픽 오브젝트의 이동 방향에 대응하는 제1 방식에 기반하여, 복수의 오디오 소스들 중 적어도 일부의 속성을 제어함으로써 제2 사운드를 출력할 수 있다. 예를 들어, 전자 장치의 1403 동작 내지 1405 동작은, 전술한 전자 장치의 동작 1205 내지 동작 1215와 같이 수행될 수 있으므로 중복되는 설명은 생략 한다. 다양한 실시예들에 따르면, 전자 장치(예: 프로세서)는, 오브젝트에 대한 입력이 아닌 경우(1403-아 니오), 동작 1407에서, 사용자 입력이 배경에 대한 입력인지 여부를 판단하고, 배경에 대한 입력인 경우(1407- 예), 동작 1409에서, 사용자의 입력의 위치에 기반하여 적어도 하나의 제2 그래픽 오브젝트가 이동되도록 제어 하고, 동작 1411에서, 적어도 하나의 제2 그래픽 오브젝트의 이동 방향에 대응하는 제2 방식에 기반하여, 복수 의 오디오 소스들 중 적어도 일부의 속성을 제어함으로써 제3 사운드를 출력할 수 있다. 예를 들어 도 14b에 도 시된 바와 같이, 전자 장치는, 그래픽 오브젝트(예: 메인 그래픽 오브젝트(901a) 및 서브 그래픽 오브젝트 (903a))의 위치 이외의 영역에 대한 사용자 입력(예: 터치)를 수신할 수 있다. 전자 장치는, 사용자 입력 (예: 터치)의 위치(예: (x1, y1))와 복수의 메인 그래픽 오브젝트(901a)의 위치(예: (x2, y2))를 비교한 것에 기반하여, 가장 거리가 짧은 것으로 식별되는 메인 그래픽 오브젝트(901a)의 위치를 이동시킬 수 있다. 전자 장 치는 상기 메인 그래픽 오브젝트(901a)의 위치를 이동시키는 동작의 적어도 일부로, 상기 사용자 입력(예: 터치)의 위치(예: (x1, y1))로부터 상기 식별된 메인 그래픽 오브젝트(901a)의 위치(예: (x2, y2))의 방향으로 상기 식별된 메인 그래픽 오브젝트(901a)를 이동시킬 수 있다. 이에 따라 식별된 메인 그래픽 오브젝트(901a)가 사용자 입력의 위치로부터 멀어질 수 있다. 다만 기재된 예에 제한되지 않고, 반대 방향으로 이동되어 사용자 입력의 위치에 가까워질 수도 있다. 이때, 전자 장치는 메인 그래픽 오브젝트(901a)의 이동에 따라서, 이 동되는 메인 그래픽 오브젝트(901a)에 연결되는 서브 그래픽 오브젝트(903a)의 길이도 조절할 수 있다. 5.5. 메인 오브젝트의 종류에 기반한 음악적 효과 제공 도 15는 다양한 실시예들에 따른, 전자 장치의 동작의 예를 설명하기 위한 흐름도이다. 다양한 실시 예들에 따르면, 도 15에 도시되는 동작들은 도시되는 순서에 국한되지 않고 다양한 순서로 수행될 수 있다. 또 한, 다양한 실시예들에 따르면, 도 15에 도시되는 동작들 보다 더 많은 동작들이 수행되거나, 더 적은 적어도 하나의 동작이 수행될 수도 있다. 다양한 실시예들에 따르면, 전자 장치(예: 프로세서)는, 동작 1501에서, 복수의 오디오 소스들에 기 반한 음악적 단위를 식별하고, 동작 1503에서, 제1 종류의 메인 오브젝트(예: 도 11의 관절 오브젝트(1101a)) 및 제2 종류의 메인 오브젝트(예: 도 11의 머리 오브젝트(1103a))를 포함하는 복수의 메인 오브젝트들(901a)을 표시할 수 있다. 다양한 실시예들에 따르면, 전자 장치(예: 프로세서)는, 동작 1505에서, 복수의 메인 그래픽 오브젝 트들(901a) 중 특정 메인 그래픽 오브젝트를 제어하기 위한 사용자 입력을 식별할 수 있다. 다양한 실시예들에 따르면, 전자 장치(예: 프로세서)는, 동작 1507에서, 제어된 메인 그래픽 오브젝 트의 종류가 제1 종류(예: 도 11의 관절 오브젝트(1101a))인지 여부를 판단하고, 제1 종류(예: 도 11의 관절 오 브젝트(1101a))인 경우(1507-예), 동작 1509에서, 그래픽 오브젝트의 이동 방향에 대응하는 제1 방식(예: 관절 오브젝트(1101a)에 할당된 오디오 효과)에 기반하여, 복수의 오디오 소스들 중 적어도 일부의 속성을 제어함으 로써 제2 사운드를 출력할 수 있다. 전자 장치의 동작 1507 내지 동작 1509는, 전술한 전자 장치의 동작 1205 내지 동작 1215와 같이 수행될 수 있으므로 중복되는 설명은 생략한다. 다양한 실시예들에 따르면, 전자 장치(예: 프로세서)는, 동작 1511에서, 제어된 메인 그래픽 오브젝 트의 종류가 제2 종류(예: 도 11의 머리 오브젝트(1103a))인지 여부를 판단하고, 제2 종류(예: 도 11의 머리 오 브젝트(1103a))인 경우(1511-예), 동작 1513에서, 제2 방식에 기반하여, 복수의 오디오 소스들 중 적어도 일부의 속성을 제어함으로써 제3 사운드를 출력할 수 있다. 예를 들어, 전자 장치는, 머리 오브젝트(1103a)가 선택되는 경우, 현재 스테이지에서 다른 스테이지로 이동하여 이동된 스테이지에 대응하는 오디오 소스 셋을 재 생함으로써 기존과는 다른 사운드를 제공할 수 있다. 또 예를 들어, 전자 장치는, 머리 오브젝트(1103a)가 선택되는 경우, 스테이지를 유지하면서, 현재 오디오 소스 셋의 적어도 일부를 다른 종류 및/또는 다른 속성의 오디오 소스로 변경하는 동작을 수행할 수 있다. 5.6. 부가 오브젝트(십자가 오브젝트) 제공 동작 도 16은 다양한 실시예들에 따른, 전자 장치의 동작의 예를 설명하기 위한 흐름도이다. 다양한 실시 예들에 따르면, 도 16에 도시되는 동작들은 도시되는 순서에 국한되지 않고 다양한 순서로 수행될 수 있다. 또 한, 다양한 실시예들에 따르면, 도 16에 도시되는 동작들 보다 더 많은 동작들이 수행되거나, 더 적은 적어도 하나의 동작이 수행될 수도 있다. 다양한 실시예들에 따르면, 전자 장치(예: 프로세서)는, 동작 1601에서, 복수의 오디오 소스들에 기 반한 음악적 단위를 식별하고, 동작 1603에서, 식별된 음악적 단위에 대응하는 개수의 복수의 메인 그래픽 오브 젝트들(901a)을 포함하는 실행 화면을 표시하면서 상기 복수의 오디오 소스들에 기반하여 제1 사운드를 출력할 수 있다. 다양한 실시예들에 따르면, 전자 장치(예: 프로세서)는, 동작 1605에서, 특정 시간이 경과되는 경우, 적어도 하나의 부가 오브젝트(예: 도 11의 부가 오브젝트(905a))를 표시하고, 동작 1607에서, 적어도 하나의 부 가 오브젝트(예: 도 11의 부가 오브젝트(905a))가 선택되는 경우, 특정 시각적 효과를 제공함에 기반하여 제2 실행 화면을 표시하면서, 특정 오디오 효과를 제공함에 기반하여 제2 사운드를 출력할 수 있다. 예를 들어, 전 자 장치는 음악적 단위(예: 박자, 마디)에 기초하여 설정되는 주기로, 실행 화면의 상단 부분의 배경 영역 에서 부가 오브젝트(905a)를 생성하여 하단 방향으로 이동시킬 수 있다. 5.7. 메인 오브젝트의 이동 범위 가이드 동작 도 17은 다양한 실시예들에 따른, 전자 장치의 동작의 예를 설명하기 위한 흐름도이다. 다양한 실시 예들에 따르면, 도 17에 도시되는 동작들은 도시되는 순서에 국한되지 않고 다양한 순서로 수행될 수 있다. 또 한, 다양한 실시예들에 따르면, 도 17에 도시되는 동작들 보다 더 많은 동작들이 수행되거나, 더 적은 적어도 하나의 동작이 수행될 수도 있다. 이하에서는, 도 18을 참조하여, 도 17에 대해서 더 설명한다. 도 18은 다양한 실시예들에 따른, 전자 장치의 메인 그래픽 오브젝트(901a) 별로 오디오 속성을 부여하는 동작의 예를 설명하기 위한 도면이다. 다양한 실시예들에 따르면, 전자 장치(예: 프로세서)는, 동작 1701에서, 복수의 오디오 소스들에 기 반한 음악적 단위를 식별하고, 동작 1703에서, 식별된 음악적 단위에 대응하는 개수의 복수의 메인 그래픽 오브 젝트들(901a)을 포함하는 실행 화면을 표시하면서 상기 복수의 오디오 소스들에 기반하여 제1 사운드를 출력할 수 있다. 전자 장치는 복수의 메인 그래픽 오브젝트들(901a)을 포함하는 실행 화면을 표시하는 동작의 적 어도 일부로, 복수의 메인 그래픽 오브젝트들(901a) 별로 부여되는 오디오 효과 간의 연관도에 기반하여, 메인 그래픽 오브젝트(901a)의 순서 및/또는 위치를 결정할 수 있다. 상기 연관도는 일 오디오 효과가 다른 오디오 효과에 청각적으로 영향을 주는 정도로 정의될 수 있으며, 전자 장치는 오디오 효과 별로 연관도에 대한 정보가 미리 저장하여, 미리 저장된 정보에 기반하여 오디오 효과들 간의 연관도를 식별할 수 있으나, 기재된 구현 예에 제한되지는 않는다. 예를 들어 도 18을 참조하면, 전자 장치는 제1 메인 오브젝트(1800a)에 부 여된 제1 오디오 효과와 제2 메인 오브젝트(1800b)에 부여된 제2 오디오 효과 간의 연관도가 높은 경우(예: 임 계 값 보다 높은 경우), 제1 메인 오브젝트(1800a)와 제2 메인 오브젝트(1800b)를 인접한 위치에 위치시킬 수 있다. 일 예로, 전자 장치는 제1 메인 오브젝트(1800a)와 제2 메인 오브젝트(1800b)를 일 서브 오브젝트 (1800c)로 연결되도록 설정할 수 있다. 다양한 실시예들에 따르면, 전자 장치(예: 프로세서)는, 동작 1705에서, 복수의 메인 그래픽 오브젝 트들(901a) 중 특정 메인 그래픽 오브젝트를 제어하기 위한 사용자 입력을 식별할 수 있다. 다양한 실시예들에 따르면, 전자 장치(예: 프로세서)는, 동작 1707에서, 특정 메인 그래픽 오브젝트 (901a)와 연관된 이동 범위 내에서 상기 특정 메인 그래픽 오브젝트가 이동되도록 제어하고, 동작 1709에서, 그 래픽 오브젝트의 이동 방향에 대응하는 방식에 기반하여, 복수의 오디오 소스들 중 적어도 일부의 속성을 제어 함으로써 제2 사운드를 출력할 수 있다. 예를 들어, 서로 인접한 위치의 메인 오브젝트들(1800a, 1800b) 중 일 메인 오브젝트(예: 제2 메인 오브젝트(1800b))의 위치에 기반하여, 다른 메인 오브젝트(예: 제1 메인 오브젝트(1800a))의 위치의 이동 범위(MD)가 설정(또는 결정, 또는 제한)될 수 있다. 이에 따라, 서브 오브젝트(1800c) 의 길이 또한 제한될 수 있다. 이에 따라, 연관도가 높은 음악적 효과들이 존재하는 경우, 특정 오디오 효과가 지나치게 제어되는 것이 방지됨으로써, 음악 감상의 질이 향상될 수 있다. 6. TV app 도 19는, 다양한 실시예들에 따른, 전자 장치의 동작의 예를 설명하기 위한 도면이다. 도 19를 참조하면, 다양한 실시예들에 따르면, 전자 장치(예: 프로세서)는 입력 장치(예: 카메 라, 마이크, 센서)를 통해서 제어 이벤트의 발생을 식별하고, 그래픽 엘리먼트 셋(1900a) 의 적어도 일부, 오디오 소스 셋(1900b)의 적어도 일부, 또는 타임라인 및/또는 스테이지(1900c) 중 적어도 하 나를 제어할 수 있다. 예를 들어, 전자 장치는 상기 입력 장치를 이용하여 사용자의 제스쳐, 및/또는 모션을 인식한 것에 기반하여, 제어 이벤트의 발생을 식별할 수 있다. 6.1. TV app의 구성 요소 도 20은, 다양한 실시예들에 따른, 전자 장치의 동작의 예를 설명하기 위한 흐름도이다. 다양한 실 시예들에 따르면, 도 20에 도시되는 동작들은 도시되는 순서에 국한되지 않고 다양한 순서로 수행될 수 있다. 또한, 다양한 실시예들에 따르면, 도 20에 도시되는 동작들 보다 더 많은 동작들이 수행되거나, 더 적은 적어도 하나의 동작이 수행될 수도 있다. 이하에서는, 도 21a 및 도 21b를 참조하여, 도 20에 대해서 더 설명한다. 도 21a는, 다양한 실시예들에 따른, 전자 장치의 시각적 컨텐트(101a)를 제공하는 동작의 일 예를 설명하 기 위한 도면이다. 도 21b는, 다양한 실시예들에 따른, 전자 장치의 체인 인터랙션의 예를 설명하기 위한 도면이다. 다양한 실시예들에 따르면, 전자 장치(예: 프로세서)는, 2001 동작에서, 프로그램을 실행한 것에 기 반하여, 복수의 오브젝트들(예: 도 21a의 복수의 오브젝트들(2101, 2103, 2105))을 포함하는 실행 화면을 표시 하면서 복수의 오디오 소스들에 기반하여 제1 사운드를 출력할 수 있다. 예를 들어 도 21a를 참조하면, 전자 장 치는 어플리케이션이 실행되는 경우, 어플리케이션의 실행 화면 상에 복수의 오브젝트들(2101, 2103, 2105))을 표시하면서, 복수의 오디오 소스들을 재생함으로써 제1 사운드를 출력할 수 있다. 다양한 실시예들에 따르면, 상기 복수의 오브젝트들(2101, 2103, 2105) 별로 적어도 하나의 오디오 효과 및/또 는 제어 가능한 적어도 하나의 오디오 속성이 설정될 수 있다. 도 21a에 도시된 바와 같이, 오브젝트(2101, 2103, 2105)는 제1 축 방향(예: 가로 방향(X)) 및/또는 제2 축 방향(예: 세로 방향(Y))으로 이동되도록 설정될 수 있다. 이때, 오브젝트(2101, 2103, 2105)와 이동 축 방향 별로 제어 가능한 오디오 소스의 종류 및/또는 오 디오 소스의 속성, 그리고 적용되는 오디오 효과의 종류가 달라질 수 있다. 예를 들어, 아래의 [표 1]을 참조하 면, 오브젝트들(2101, 2103, 2105) 별로 제어되는 오디오 소스의 종류가 설정될 수 있으며, 이에 따라 이동되는 방향(예: 가로 방향(X), 및 세로 방향(Y)) 별로 적용되는 효과와 기준(예: 이동 거리에 따라 정도가 변경되는지, 또는 위치 기준에 따라 적용되는지)이 달라질 수 있다. 표 3 오디오 소스 종류 이동 방향 Y X 악기 하이패스필터 음높낮이 드럼 어깨선기준 드럼 트랙 변경 음높낮이 종합컨트롤 스피드/높낮이 선형 조절 비트리피터 보컬 어깨선기준 보컬 변경 높낮이 베이스 디스토션효과 높낮이 [표 3]의 기재는, 예시일 뿐, 오브젝트(2101, 2103, 2105)와 각 축 방향 별로 다양한 종류의 다른 오디오 효과 및/또는 오디오 속성이 제어되도록 설정될 수 있음은, 당업자에게 자명하다.다양한 실시예들에 따르면, 전자 장 치(예: 프로세서)는, 2003 동작에서, 복수의 오브젝트들 중 사용자의 모션에 의해 선택된 특정 오브 젝트를 식별할 수 있다. 예를 들어, 전자 장치는 입력 장치를 이용하여 전자 장치의 전방에 위 치하는 사용자의 모션을 식별할 수 있다. 상기 사용자의 모션은 주먹을 쥐는 그랩 모션, 손을 흔드는 스윙 모션, 펀치 모션 등과 같은 사용자의 손에 의해 수행 가능한 다양한 종류의 모션을 포함할 수 있으며, 기재된 예에 제한되지 않고 다른 신체 일부(예: 팔, 발, 다리, 얼굴)을 이용한 다양한 종류의 모션을 포함할 수도있다. 일 예로, 전자 장치는 카메라를 이용하여 식별되는 사용자의 신체 일부(예: 손)의 형상의 변화를 검 출하고, 검출된 변화에 대응하는 모션을 식별할 수 있다. 또 일 예로, 전자 장치는 카메라 이외의 센싱 장 치(예: 자기장 센서)를 이용하여, 사용자의 신체 일부(예: 손)의 형상의 변화를 검출하고, 검출된 변화에 대응 하는 모션을 식별할 수 있다. 기재된 예들 이외의 다양한 구현 예는 당업자에게 자명하므로, 더 구체적인 설명 은 생략한다. 이때, 도 21a에 도시된 바와 같이, 입력 장치는, 전자 장치와 별도로 구비되어 전자 장 치로 센싱된 정보(예: 신체 일부의 변화)를 전달할 수 있으나, 기재된 및/또는 도시된 예에 제한되지 않고, 전자 장치는 입력 장치를 포함하도록 구현될 수도 있다. 다양한 실시예들에 따르면, 전자 장치(예: 프로세서)는, 2005 동작에서, 상기 특정 오브젝트의 이동 에 기반하여 상기 복수의 오디오 소스들 중 특정 오디오 소스의 속성을 제어한 것에 기반하여, 제2 사운드를 출 력할 수 있다. 예를 들어 도 21a에 도시된 바와 같이, 전자 장치는 식별된 사용자의 모션(GM)(예: 그랩)에 기반하여 그래픽 오브젝트를 선택할 수 있다. 전자 장치는 모션(GM)의 위치(예: 좌표)와 그래픽 오 브젝트의 위치(예: 좌표)를 비교한 것에 기반하여, 모션(GM)에 대응하는 위치의 그래픽 오브젝트를 선택할 수 있다. 예를 들어, 전자 장치는 상기 모션(GM)이 이동되는 경우, 상기 모션(GM)의 이동 방향에 대응하는 방향으로 상기 선택된 그래픽 오브젝트를 이동시키고, 상기 그래픽 오브젝트의 이동 방향 에 대응하는 오디오 소스의 속성을, 이동 거리에 대응하는 정도로 조절할 수 있다. 도 21b를 참조하면, 다양한 실시예들에 따르면, 전자 장치(예: 프로세서)는 그래픽 오브젝트(2101, 2013, 2105)의 이동에 기반한 연쇄적인 효과를 제공할 수도 있다. 예를 들어, 전자 장치는 제1 그래픽 오 브젝트의 이동에 따라서 연쇄적으로 제2 그래픽 오브젝트의 속성(예: 위치, 개수)이 변경됨에 기반 하여, 오디오 소스의 속성을 연쇄적으로 제어할 수 있다. 6.2. 제어 조건 만족 시 아바타 표시 동작 도 22는, 다양한 실시예들에 따른, 전자 장치의 동작의 예를 설명하기 위한 흐름도이다. 다양한 실 시예들에 따르면, 도 22에 도시되는 동작들은 도시되는 순서에 국한되지 않고 다양한 순서로 수행될 수 있다. 또한, 다양한 실시예들에 따르면, 도 22에 도시되는 동작들 보다 더 많은 동작들이 수행되거나, 더 적은 적어도 하나의 동작이 수행될 수도 있다. 이하에서는, 도 23a 및 도 23b를 참조하여, 도 22에 대해서 더 설명한다. 도 23a는, 다양한 실시예들에 따른, 전자 장치의 사용자 간의 거리에 기반하여 제어를 위한 아바타를 제공 하는 동작의 일 예를 설명하기 위한 도면이다. 도 23b는, 다양한 실시예들에 따른, 전자 장치의 사용자 간 의 거리에 기반하여 제어를 위한 아바타를 제공하는 동작의 다른 예를 설명하기 위한 도면이다. 다양한 실시예들에 따르면, 전자 장치(예: 프로세서)는, 동작 2201에서, 프로그램을 실행한 것에 기 반하여, 복수의 오브젝트들(1900a)을 포하는 실행 화면을 표시하면서 복수의 오디오 소스들에 기반하여 제1 사 운드를 출력할 수 있다. 다양한 실시예들에 따르면, 전자 장치(예: 프로세서)는, 동작 2203에서, 사용자(U)의 복수의 신체 부 분들에 대한 정보를 획득하고, 동작 2205에서, 상기 복수의 신체 부분들 중 제1 부분(예: 몸통(B), 손바닥(P)) 에 대한 제1 정보에 기반하여, 특정 조건이 만족되는지 여부를 판단할 수 있다. 예를 들어, 도 23a에 도시된 바 와 같이, 전자 장치는 입력 장치를 통해서 획득되는 사용자의 특정 부분과 연관된 정보(예: 크기에 대한 정보, 형상에 대한 정보, 등)에 기반하여 사용자(U)와 전자 장치 사이의 거리(D1, D2)를 식별할 수 있다. 예를 들어, 사용자의 특정 부분은 도 23a에 도시된 바와 같이 상기 사용자의 신체 부분들 중 가장 큰 부 분인 몸통(B), 또는 도 23b에 도시된 바와 같이 손바닥(P)을 포함할 수 있으며, 이에 제한되지 않는다. 전자 장 치는 신체 일부(예: 몸통(B), 손바닥(P))의 크기 별로 대응하는 거리에 대한 정보를 미리 저장하고, 미리 저장된 정보로부터 현재 카메라를 이용하여 획득된 이미지로부터 검출되는 신체 일부(예: 몸통(B), 손바닥 (P))의 크기에 대응하는 거리(D1, D2)를 식별할 수 있다. 다양한 실시예들에 따르면, 전자 장치(예: 프로세서)는 특정 부분(예: 몸통(B), 손바닥(P)) 이외의 다른 신체 부분에 기반하여 임계 거리내로 인식되는 경우에는, 상기 아바타를 표시하는 동작을 삼가 할 수 있다. 다양한 실시예들에 따르면, 전자 장치(예: 프로세서)는 상기 거리를 식별하는 동작의 적어도 일부로, 사용자의 개인 정보에 더 기반하여 상기 거리를 식별할 수 있다. 예를 들어 신체 일부(예: 몸통(B), 손바닥 (P))의 크기는 전자 장치로부터 같은 거리더라도, 다르게 촬영될 수 있다. 따라서, 전자 장치는 신체 일부(예: 몸통(B), 손바닥(P))의 크기에 영향을 주는 개인 정보(예: 성별, 나이, 전체 신장)를 기반하여 상기신체 일부(예: 몸통(B), 손바닥(P)의 크기에 대응하는 거리를 조절할 수 있다. 일 예로, 전자 장치는 남성 과 비교하여, 여성의 경우 동일한 신체 일부(예: 몸통(B), 손바닥(P)의 크기에 기반하여 식별된 거리를 더 크게 인식할 수 있다. 상기 개인 정보는 전자 장치로 입력될 수 있으나, 또는 전자 장치가 자체적으로 분 석(예: 카메라를 통해 촬영된 이미지로부터 식별되는 특징에 대응하는 개인 정보를 식별)할 수도 있다. 다양한 실시예들에 따르면, 전자 장치(예: 프로세서)는, 동작 2207에서 조건이 만족되는 것으로 판단 되는 경우(2207-예), 동작 2209에서 제1 정보에 기반한 아바타를 표시할 수 있다. 예를 들어 도 23a 및 도 23b 에 도시된 바와 같이, 전자 장치는 식별된 거리(D2, D)가 복수의 그래픽 오브젝트들(1900a)의 제어를 위한 임계 거리(예: 2.5m, 그러나 제한되지 않음) 내로 식별되는 경우, 디스플레이 상에 아바타(2300a, 2300b)를 표 시하고, 상기 사용자에게 제어 권한을 부여할 수 있다. 상기 제어 권한은 상기 사용자가 그래픽 오브젝트들 (1900a)을 제어 가능하도록 하는 권한일 수 있다. 이에 따라, 사용자는 상기 아바타(2300a, 2300b)를 인지함으 로써, 그래픽 오브젝트들(1900a)에 대한 제어 권한이 사용자에게 부여됨을 인식할 수 있다. 상기 아바타(2300a, 2300b)는 기-구현된 아바타, 및/또는 전자 장치에 의해 촬영된 사용자의 신체 부분들에 기반하여 구현되는 아바타일 수 있다. 다양한 실시예들에 따르면, 전자 장치(예: 프로세서)는, 동작 2211에서, 상기 복수의 신체 부분들 중 상기 제1 부분(예: 몸통(B), 손바닥(P))과는 다른 제2 부분(예: 손(H), 손가락(F))과 연관된 정보에 기반하여 상기 복수의 오브젝트들 중 제1 오브젝트(예: 오브젝트)에 대한 정보를 식별하고, 동작 2213에서, 상기 제1 오브젝트(예: 오브젝트)의 속성(예: 밝기)을 제어하면서, 상기 제1 오브젝트(예: 오브젝트)에 대응하는 상기 복수의 오디오 소스들 중 특정 오디오 소스의 속성을 제어한 것에 기반하여 제2 사운드를 출력할 수 있다. 예를 들어, 전자 장치는 상기 거리를 식별하기 위한 신체 부분(예: 몸통(B), 손바닥(P))과는 다 른 신체 부분(예: 손(H), 손가락(F))에 기반하여, 사용자의 모션 및/또는 제스쳐를 인식하는 동작을 수행할 수 있다. 다시 말해, 전자 장치는 사용자의 거리가 임계 거리내로 인식된 이후에는, 상기 사용자(U)의 다른 신체 부분(예: 손(H), 손가락(F))을 인식하는 동작을 개시(또는 수행)할 수 있다. 다양한 실시예들에 따르면, 전자 장치(예: 프로세서)는 임계 거리 내에 복수의 사용자가 존재하는 것으로 인식되는 경우, 거리가 가장 가까운 것으로 인식되는 사용자에게 제어 권한을 부여할 수 있다. 6.3. 화면 전환 동작 도 24는, 다양한 실시예들에 따른, 전자 장치의 동작의 예를 설명하기 위한 흐름도이다. 다양한 실 시예들에 따르면, 도 24에 도시되는 동작들은 도시되는 순서에 국한되지 않고 다양한 순서로 수행될 수 있다. 또한, 다양한 실시예들에 따르면, 도 24에 도시되는 동작들 보다 더 많은 동작들이 수행되거나, 더 적은 적어도 하나의 동작이 수행될 수도 있다. 이하에서는, 도 25를 참조하여, 도 24에 대해서 더 설명한다. 도 25는, 다양한 실시예들에 따른, 전자 장치의 화면 전환 동작의 일 예를 설명하기 위한 도면이다. 다양한 실시예들에 따르면, 전자 장치(예: 프로세서)는, 동작 2401에서, 프로그램을 실행한 것에 기 반하여, 복수의 오브젝트들(예: 도 25의 복수의 오브젝트들)을 포함하는 실행 화면을 표시하면서 제1 사운드를 출력하고, 동작 2403에서, 사용자(U)의 복수의 신체 부분들에 대한 정보를 획득하고, 동작 2405에 서, 상기 복수의 신체 부분들 중 제1 부분(예: 몸통(B))에 대한 제1 정보에 기반하여, 제1 조건이 만족(예: 제1 임계 거리 내로 진입)되는지 여부를 판단할 수 있다. 예를 들어, 전자 장치는, 사용자(U)와의 거리가 제1 임계 거리(예: 4.5m, 그러나 제한되지 않음) 바깥인 경우, 대기 화면을 표시할 수 있다. 상기 대기 화면 은 다양한 형상의 오브젝트들을 포함할 수 있다. 전자 장치는 상기 대기 화면을 표시하 면서, 다른 화면(2520, 2530) 보다 상대적으로 작은 에너지를 갖는(즉, 주파수 별 에너지가 낮은) 사운드를 출 력할 수 있다. 다양한 실시예들에 따르면, 전자 장치(예: 프로세서)는, 동작 2407에서, 제1 조건이 만족되는 경우 (2407-예), 동작 2409에서, 사용자(U)에 대응하는 제1 그래픽 오브젝트(예: 도 25의 그래픽 오브젝트)를 표시하면서 제2 사운드를 출력하고, 동작 2411에서, 상기 복수의 신체 부분들 중 제1 부분에 대한 제1 정보에 기반하여, 제2 조건이 만족(예: 제2 임계 거리 내로 진입)되는지 여부를 판단할 수 있다. 예를 들어, 전자 장치 는, 상기 사용자(U)와의 거리가 제1 임계 거리 내로 판단되는 경우, 사용자(U)의 특정 신체 부분(예: 목) 의 위치에 대응하는 대기 화면 상의 위치에 오브젝트를 표시할 수 있다. 이때, 상기 오브젝트(251 2)의 표시에 따라서, 다른 나머지 복수의 오브젝트들이 멀리 퍼지도록 이동됨으로써, 고조되는 시각적 연 출 효과가 제공될 수 있다. 전자 장치는 상기 시각적 연출 효과를 제공하면서, 전술하 제1 사운드와는 다른 속성을 갖는 제2 사운드를 제공할 수 있다. 상기 제2 사운드는 제1 사운드 보다 상대적으로 큰 에너지를 갖 는(즉, 적어도 일부 주파수 별 에너지가 높은) 사운드로 설정되어, 고조되는 분위기가 연출될 수 있다. 다양한 실시예들에 따르면, 대기 화면을 제공하는 동안의 전자 장치(예: 프로세서)의 전력 소 모는 메뉴 화면을 제공하는 동안의 전자 장치의 전력 소모와 비교하여 낮을 수 있다. 다시 말해, 전 자 장치(예: 프로세서)는 대기 화면을 제공하는 동안, 메뉴 화면을 제공하는 동안과 비 교하여 더 적은 개수의 전자 부품을 제어(예: 나머지 전자 부품을 슬립 상태로 제어)할 수 있다. 이에 따라 전 자 장치는, 소정의 기능을 제공하도록 구현되는 메뉴 화면이 제공되기 이전에 대기 화면을 표 시하는 동안의 운용 부담이 경감되되, 대기 화면 상의 시각적 효과 및 사운드의 청각적 효과를 통해 사용 자(U)가 제어 가능한 상태로 돌입할 수 있음을 인식하도록 할 수 있다. 다양한 실시예들에 따르면, 전자 장치(예: 프로세서)는, 동작 2413에서, 제2 조건이 만족되는 경우 (2413-예), 동작 2415에서, 제3 사운드를 출력하면서 상기 제1 화면을 제어하기 위한 적어도 하나의 제3 그래픽 오브젝트를 표시할 수 있다. 예를 들어, 전자 장치는 상기 사용자(U)와의 거리가 제2 임계 거리내로 판단 되는 경우, 대기 화면 대신에 메뉴 화면을 표시할 수 있다. 상기 메뉴 화면은 다양한 종류의 정보(예: 날씨 정보, 뉴스 정보) 및 음악을 선택하기 위한 메뉴를 포함할 수 있다. 전자 장치는 사용자에 의해 특정 음악이 선택되는 경우, 특정 음악에 대응하는 복수의 오디오 소스들을 재생하며, 복수의 오브젝트들 (1900a)를 포함하는 실행 화면을 제공할 수 있다. 상기 복수의 오브젝트들(1900a)의 제어에 따른, 전자 장치의 중복되는 동작에 대해서는 생략한다. 6.4. 인터랙션 종류의 확장 예 다양한 실시예들에 따르면, 전술한 사용자의 그랩 이외에도, 전자 장치는 다양한 종류의 인터랙션에 기반 하여, 시각적 컨텐트(100a)(예: 그래픽 오브젝트)의 속성을 제어하고, 청각적 컨텐트(100b)의 속성을 제어할 수 있다. 도 26은, 다양한 실시예들에 따른, 전자 장치의 동작의 예를 설명하기 위한 흐름도이다. 다양한 실 시예들에 따르면, 도 26에 도시되는 동작들은 도시되는 순서에 국한되지 않고 다양한 순서로 수행될 수 있다. 또한, 다양한 실시예들에 따르면, 도 26에 도시되는 동작들 보다 더 많은 동작들이 수행되거나, 더 적은 적어도 하나의 동작이 수행될 수도 있다. 이하에서는, 도 27을 참조하여, 도 26에 대해서 더 설명한다. 도 27은, 다양한 실시예들에 따른, 사용자의 인터랙션의 종류들의 예를 설명하기 위한 도면이다. 다양한 실시예들에 따르면, 전자 장치(예: 프로세서)는, 동작 2601에서, 인터랙션에 대한 정보를 획 득하고, 동작 2603에서, 제1 오브젝트 이벤트의 발생 여부를 판단할 수 있다. 예를 들어 아래의 [표 4] 및 도 27의 (a) 내지 (d)를 참조하면, 사용자의 인터랙션의 종류는 모션뿐만 아니라, 목소리 등과 같은 인터랙션을 포 함하며, 기재된 예에 제한되지 않고 시각적으로 사용자로부터 식별될 수 있는 인터랙션(예: 표정 등) 및 청각적 으로 사용자로부터 식별될 수 있는 인터랙션(예: 손뼉 등)을 더 포함할 수 있다. 표 4 사용자 인터랙션 종류 오브젝트 속성 모션 그랩 위치 펀치 개수, 위치 핀치 크기 목소리 \"후~\" 부는 음성 위치 “특정 단어”를 포함하는 음성 단어에 기반한 속성 제어 이에 따라, 전자 장치는 입력 장치를 통해서 다양한 종류의 인터랙션을 식별하고, 인터랙션에 의해 선택되는 오브젝트를 식별할 수 있다. 상기 전자 장치의 상기 오브젝트의 선택을 식별하는 동작은, 오브젝 트 이벤트의 발생을 식별하는 동작으로 정의될 수 있다. 다양한 실시예들에 따르면, 전자 장치(예: 프로세 서)는 동작 2605에서, 이벤트와 연관된 신체 부분이 제1 부분(예: 그랩, 목소리 등과 같은 인터랙션의 종 류)인지 여부를 판단하고, 제1 부분인 경우(2605-예), 동작 2607에서, 제1 부분에 대응하는 제1 정보에 기반하 여, 제1 부분에 의한 제1 특성을 식별하고, 동작 2609에서, 상기 제1 오브젝트와 제1 특성에 대응하는 제1 스킴 에 기반하여, 출력 중인 오디오 소스 셋을 제어하면서 제1 오브젝트의 시각적 속성을 제1 속성으로 제어할 수 있다.다양한 실시예들에 따르면, 전자 장치(예: 프로세서)는, 이벤트와 연관된 신체 부분이 제1 부분이 아 닌 경우(2605-아니오), 동작 2611에서, 이벤트와 연관된 신체 부분이 제2 부분(예: 그랩, 목소리 등과 같은 인 터랙션의 종류)인지 여부를 판단하고, 제2 부분인 경우(2611-예), 동작 2613에서, 제2 부분과 연관된 제2 정보 에 기반하여, 제2 부분에 의한 제2 특성을 식별하고, 동작 2615에서, 상기 제1 오브젝트와 제2 특성에 대응하는 제2 스킴에 기반하여, 출력 중인 수의 오디오 소스 셋을 제어하면서 제1 오브젝트의 시각적 속성을 제2 속성으 로 제어할 수 있다. 다시 [표 2]를 참조하면, 인터랙션의 종류 별로 제어될 수 있는 오브젝트의 속성이 달라질 수 있다. 전자 장치 는 상기 [표 2]에 대한 정보를 미리 저장하고, 이벤트가 발생되는 경우 현재 식별된 인터랙션의 종류(또는 신체 부분의 종류)와 상기 미리 저장된 정보를 비교하여, 식별된 인터랙션의 종류에 대응하는 상기 오브젝트의 속성을 제어할 수 있다. 예를 들어, 전자 장치는 도 27의 (a)에 도시된 바와 같이 그랩이 식별되는 경우 오브젝트의 위치를 제어하고, 도 27의 (b)에 도시된 바와 같이 펀치가 식별되는 경우 오부젝트의 수를 제어하고, 도 27의 (c) 내지 (d)에 도시된 바와 같이 특정 단어(예: “이동”, “크게”)를 포함하는 발화를 수 신하는 경우에는 특정 단어에 대응하는 속성(예: 위치, 크기)을 제어할 수 있다. 이때 아래의 [표 5]를 참조하면, 선택된 그래픽 오브젝트에 할당된 오디오 소스의 종류 및 제어되는 그래픽 오 브젝트의 속성에 따라서, 특정 오디오 효과가 적용될 수 있다. 일 예로, 그랩에 의해 “악기”에 대응하는 오브 젝트의 위치가 Y로 이동되는 경우, 하이패스 필터가 적용될 수 있다. 또 일 예로, 목소리에 의해 “악기”에 대 응하는 오브젝트의 크기가 커지는 경우, 악기의 출력 레벨이 커질 수 있다. 이에 따라, 전자 장치에 의해 제공되는 청각적 컨텐트(100b)(예: 음악)의 에너지(예: 주파수 별 세기)가 달라질 수 있다. 표 5 오디오 소스 종류 오브젝트의 속성 위치 크기 Y X 커짐 작아짐 악기 하이패스필터 음높낮이 레벨이 커짐 레벨이 작아짐 드럼 어깨선기준 드럼 트랙 변경음높낮이 드럼템포증가 드럼템포감소 종합컨트롤 스피드/높낮이 선 형 조절비트리피터 보컬 어깨선기준 보컬 변경높낮이 베이스 디스토션효과 높낮이 [표 5]에 기재된 사항은 예시일 뿐, 더 다양한 종류의 오브젝트의 속성(예: 오브젝트의 개수)과 오디오 소스의 종류에 따라서, 특정 오디오 효과가 적용될 수 있다. 6.5. 물체에 기반한 인터랙션의 예 도 28은, 다양한 실시예들에 따른, 전자 장치의 동작의 예를 설명하기 위한 흐름도이다. 다양한 실 시예들에 따르면, 도 28에 도시되는 동작들은 도시되는 순서에 국한되지 않고 다양한 순서로 수행될 수 있다. 또한, 다양한 실시예들에 따르면, 도 28에 도시되는 동작들 보다 더 많은 동작들이 수행되거나, 더 적은 적어도 하나의 동작이 수행될 수도 있다. 이하에서는, 도 29를 참조하여, 도 28에 대해서 더 설명한다. 도 29는, 다양한 실시예들에 따른, 전자 장치의 식별되는 물체의 종류에 기반하여 시각적 컨텐트(100a) 및 청각적 컨텐트(100b)를 제어하는 동작의 예를 설명하기 위한 도면이다. 다양한 실시예들에 따르면, 전자 장치(예: 프로세서)는, 동작 2801에서, 사용자의 신체 일부와 연관 된 물체(예: 도 29의 스틱)의 종류를 식별하고, 동작 2803에서, 식별된 물체에 의한 모션의 종류(예: 도 29의 타격)를 식별할 수 있다. 예를 들어, 전자 장치는 입력 장치(예: 카메라)를 이용하여 식별되는 특정 오브젝트의 형상에 대응하는 물체를 식별할 수 있다. 이때 예를 들어, 전자 장치에는, 아래의 [표 4]에 기 재된 바와 같이 물체의 종류 별로 제어 가능한 오브젝트의 속성에 대한 정보가 미리 저장될 수 있다. 전자 장치 는 상기 미리 저장된 정보에 기반하여, 물체에 의한 모션에 의해 선택되는 그래픽 오브젝트의 속성을 변경 할 수 있다. 상기 오브젝트의 속성의 변경에 따라, 변경된 시각적 컨텐트(100a)가 제공될 수 있다.표 6 물체 종류 모션 종류 오브젝트 속성 스틱 찌르기 숫자 타격 위치 기타 기타 액션 [표 6]에 기재된 사항은 예시일 뿐, 기재된 바에 제한되지 않는다.다양한 실시예들에 따르면, 전자 장치 (예: 프로세서)는, 동작 2805에서, 물체의 종류 및 모션의 종류에 대응하는, 시각적 컨텐트의 속성 및/또 는 청각적 컨텐트의 속성을 제어할 수 있다. 예를 들어, 전자 장치는 전술한 [표 3]의 그래픽 오브젝트에 할당된 오디오 소스의 종류 및 제어되는 그래픽 오브젝트의 속성에 대한 정보를 미리 저장하고, 해당 정보에 기 반하여 오디오 효과를 적용함에 기반하여, 전자 장치에 의해 제공되는 청각적 컨텐트(100b)(예: 음악)의 에너지(예: 주파수 별 세기)가 달라질 수 있다. 6.6. 논-오브젝트 컨텐트 시나리오 도 30은, 다양한 실시예들에 따른, 전자 장치의 동작의 예를 설명하기 위한 흐름도이다. 다양한 실 시예들에 따르면, 도 30에 도시되는 동작들은 도시되는 순서에 국한되지 않고 다양한 순서로 수행될 수 있다. 또한, 다양한 실시예들에 따르면, 도 30에 도시되는 동작들 보다 더 많은 동작들이 수행되거나, 더 적은 적어도 하나의 동작이 수행될 수도 있다. 이하에서는, 도 31을 참조하여, 도 30에 대해서 더 설명한다. 도 31은, 다양한 실시예들에 따른, 전자 장치의 식별되는 물체의 종류에 기반하여 시각적 컨텐트(100a) 및 청각적 컨텐트(100b)를 제어하는 동작의 예를 설명하기 위한 도면이다. 다양한 실시예들에 따르면, 전자 장치(예: 프로세서)는, 동작 3001에서, 적어도 하나의 정보에 기반 하여 이펙트 이벤트의 발생을 식별할 수 있다. 예를 들어 도 31에 도시된 바와 같이, 전자 장치는 디스플 레이 상에 화면을 표시한 상태에서, 입력 장치를 이용하여, [표 2] 및 [표 4]를 참조하여 기술한, 다양한 종류의 인터랙션을 식별할 수 있다. 상기 화면은 복수의 오디오 소스들 중 적어도 일부를 제어하기 위한 그래픽 오브젝트를 미포함 할 수 있다. 다양한 실시예들에 따르면, 전자 장치(예: 프로세서)는, 동작 3003에서, 발생된 이펙트 이벤트가 제1 이벤트인지 여부를 판단하고, 제1 이벤트인 경우(3003-예), 동작 3005에서, 제1 이벤트에 기반하여 제1 이펙트 효과를 상기 화면에 출력하고, 동작 3007에서, 오디오 소스 셋의 제1 이펙트 효과에 대응하는 제1 속성을 제어 할 수 있다. 다양한 실시예들에 따르면, 전자 장치(예: 프로세서)는, 발생된 이펙트 이벤트가 제1 이 벤트가 아닌 경우(3003-아니오), 동작 3009에서, 발생된 이펙트 이벤트가 제2 이벤트인지 여부를 판단하고, 제2 이벤트인 경우(3009-예), 동작 3011에서, 제2 이벤트에 기반하여 제2 이펙트 효과를 상기 화면에 출력하고, 동 작 3013에서, 오디오 소스 셋의 제2 이펙트 효과에 대응하는 제2 속성을 제어할 수 있다. 예를 들어, 전자 장치 는, 도 31의 (a)에 도시된 바와 같이, 사용자의 스윙을 식별한 것에 기반하여 제1 비쥬얼 효과(예: 물결 효과)를 표시하고, 도 31의 (c)에 도시된 바와 같이, 사용자의 펀치를 식별한 것에 기반하여 제2 비쥬얼 효과 (예: 물 동심원 효과)를 표시할 수 있다. 이때, 전자 장치는 도 31의 (a)에 도시된 바와 같이, 검출되는 인터랙션의 정도에 따라서 비쥬얼 효과(예: 물결 효과)의 레벨을 조정할 수 있다. 전자 장치는 상기 비쥬 얼 효과를 제공하면서, 룰 정보에 기반하여 비쥬얼 효과 제공 시 적용되도록 설정된 오디오 효과를 적용할 수 있다. 6.7. 모드 전환 시나리오 도 32는, 다양한 실시예들에 따른, 전자 장치의 동작의 예를 설명하기 위한 흐름도이다. 다양한 실 시예들에 따르면, 도 32에 도시되는 동작들은 도시되는 순서에 국한되지 않고 다양한 순서로 수행될 수 있다. 또한, 다양한 실시예들에 따르면, 도 32에 도시되는 동작들 보다 더 많은 동작들이 수행되거나, 더 적은 적어도 하나의 동작이 수행될 수도 있다. 이하에서는, 도 33을 참조하여, 도 32에 대해서 더 설명한다. 도 33은, 다양한 실시예들에 따른, 전자 장치의 사용자 인터랙션 모드와 사용자 논-인터랙션 모드 간의 전 환 동작의 예를 설명하기 위한 도면이다. 다양한 실시예들에 따르면, 전자 장치(예: 프로세서)는, 동작 3201에서, 프로그램을 실행한 것에 기 반하여 실행 화면을 표시하면서 복수의 오디오 소스들에 기반하여 제1 사운드를 출력하고, 동작 3203에서, 사용자의 복수의 신체 부분들에 대한 정보를 획득하고, 동작 3205에서, 상기 복수의 신체 부분들 중 제1 부분(예: 몸통(B))에 대한 제1 정보에 기반하여, 특정 조건이 만족(예: 사용자(U)와의 거리가 임계 거리 내임)되는지 여 부를 판단할 수 있다. 다양한 실시예들에 따르면, 전자 장치(예: 프로세서)는, 동작 3207에서, 조건의 만족 여부를 판단하 고, 조건이 만족되는 경우(3207-예), 동작 3209에서 전자 장치의 모드를 제1 모드(예: 사용자 인터랙션 모 드)로 설정할 수 있다. 예를 들어 도 33의 (a)를 참조하면, 전자 장치는 사용자(U)와의 거리가 임계 거리 내인 경우, 사용자의 인터랙션에 기반하여 그래픽 오브젝트(1900a)를 제어하도록 함으로써 청각적 컨텐트를 다 이나믹하게 제어하도록 할 수 있다. 전자 장치의 모드가 사용자 인터랙션 모드인 상태에서 수행되는 전자 장치의 동작은, 전술한 “6.1 목차 내지 6.5 목차”와 같이 수행될 수 있으므로, 중복되는 설명은 생략한 다. 다양한 실시예들에 따르면, 전자 장치(예: 프로세서)는, 조건이 만족되지 않는 경우(3207-아니오), 동작 3211에서, 전자 장치의 모드를 제2 모드(예: 사용자 논-인터랙션 모드)로 설정하고, 동작 3213에서, 문맥 정보를 획득하고, 동작 3215에서, 문맥 정보에 기반하여 오디오 소스의 속성을 제어하거나 및/또는 화면을 제어할 수 있다. 예를 들어 도 33의 (b)를 참조하면, 전자 장치는 사용자(U)와의 거리가 임계 거리 바깥인 경우, 사용자의 인터랙션 이외의 다른 문맥 정보에 기반하여 그래픽 오브젝트(1900a)를 제어하도록 함으로써 주 변 환경에 적합하게 청각적 컨텐트를 제어하도록 할 수 있다. 예를 들어, 상기 문맥 정보는 마이크를 통해 수신 되는 주변 사운드, 카메라를 이용하여 획득되는 이미지내 오브젝트들에 대한 정보, 서버 등을 통해서 수신되는 날씨/온도 정보 등을 포함할 수 있으며, 기재된 예에 제한되지 않고, 전자 장치의 주변으로부터 획득될 수 있는 다양한 정보를 포함할 수 있다. 다양한 실시예들에 따르면, 전자 장치(예: 프로세서)는 아래의 [표 7]에 기재된 바와 같이, 획득되는 문맥 정보의 정도에 따라서 그래픽 오브젝트의 속성을 제어할 수 있다. 이에 따라, 전자 장치는 룰 정보에 기반하여 제어된 그래픽 오브젝트의 속성에 대응하는 비쥬얼 이펙트를 제공하거나, 및/또는 오디오 소스의 속성 을 제어할 수 있다. 표 7 문맥 정보 오브젝트 속성 제어 주변 사운드 노이즈 제 1 값 미만 위치 위치 변화량 감소 주변 사운드 노이즈 제 1 값 초과 위치 위치 변화량 증가 다양한 실시예들에 따르면, 전자 장치(예: 프로세서)는 전자 장치의 모드를 설정하는 동작의 적 어도 일부로, 시간 정보를 더 이용할 수 있다. 예를 들어, 전자 장치는 임계 거리 내로 또는 바깥으로 식 별된 사용자의 거리가 임계 시간 이상으로 유지되는지 여부를 판단하고, 임계 시간 이상 유지되는 경우 모드를 설정하는 동작을 수행할 수 있다. 7. 메타버스 UI 도 34는, 다양한 실시예들에 따른, 전자 장치의 동작의 예를 설명하기 위한 도면이다. 이하에서는 도 35를 참조하여, 도 34에 대해서 더 설명한다. 도 35는, 다양한 실시예들에 따른, 전자 장치에 의해 제공되는 컨텐트의 예를 설명하기 위한 도면이다. 도 34를 참조하면, 다양한 실시예들에 따르면, 전자 장치(예: 프로세서)는 제어 이벤트의 발생 에 기반하여, 그래픽 엘리먼트 셋(3400a)의 적어도 일부, 오디오 소스 셋(3400b)의 적어도 일부, 또는 타임라인 및/또는 스테이지(3400c) 중 적어도 하나를 제어할 수 있다. 예를 들어 도 35를 참조하면, 상기 그래픽 엘리먼트 셋(3400a)는 그래픽 공간(예: 맵(3410a)), 상기 그래픽 공 간 상에 배치 가능한 메인 캐릭터(3420a), 및 서브 오브젝트(3430a)를 포함할 수 있다. 상기 메인 캐릭터 (3420a)는 사용자의 입력에 기반하여 그래픽 공간(예: 맵(3410a)) 상에서 이동되도록 구현될 수 있다. 상기 서 브 오브젝트(3430a)는 그래픽 공간(예: 맵(3410a)) 상에 기-배치되는 그래픽 오브젝트일 수 있다. 예를 들어, 상기 복수의 그래픽 오브젝트들(예: 메인 캐릭터(3420a), 및 서브 오브젝트(3430a))는 특정 오디오 소스를 제공하거나, 및/또는 오디오 효과를 적용하도록 설정될 수 있다. 예를 들어, 메인 캐릭터(3420a)는 이동 되거나 및/또는 선택되어 특정 모션을 수행하는 경우, 특정 오디오 소스를 제공하거나 및/또는 오디오 효과를적용하도록 미리 구현될 수 있다. 또 예를 들어, 상기 서브 오브젝트(3430a)는 상태에 따라서, 특정 오디오 소 스를 제공하거나 및/또는 오디오 효과를 적용하도록 미리 구현될 수 있다. 일 예로, 상기 서브 오브젝트(3430 a)는 활성화 상태에서 특정 오디오 소스를 제공하거나 및/또는 오디오 효과를 적용하는 기능을 수행하나, 비활 성화 상태에서는 상기 기능의 수행을 삼가할 수 있다. 예를 들어 도 35를 참조하면, 상기 그래픽 공간(예: 맵(3410a))은 복수의 지역들(예: 제1 지역 내지 제9 지역) 을 포함할 수 있다. 상기 복수의 지역들 별로 오디오 소스 셋(3400b)가 할당될 수 있다. 일 예로, 상기 복수의 지역들 별로 서로 다른 구성(또는 테마)(예: 인트로(intro), 벌스(verse))의 음원이 설정될 수 있다. 이에 따라, 전자 장치는 메인 캐릭터(3420a)가 위치되는 지역에 대응하는 오디오 소스 셋을 재생함으로써, 청각 적 컨텐트(100b)(예: 음악)를 제공할 수 있다. 7.1. 메인 캐릭터에 대한 입력에 기반한 컨텐트 제어 다양한 실시예들에 따르면, 전자 장치(예: 프로세서)는 메인 캐릭터(3420a)와 연관된 사용자 입력이 수신되는 경우, 시각적 컨텐트(100a)의 속성 및/또는 청각적 컨텐트(100b)의 속성을 제어할 수 있다. 7.1.1. 사용자 입력의 타이밍 기반 제어 동작 도 36은, 다양한 실시예들에 따른, 전자 장치의 동작의 예를 설명하기 위한 흐름도이다. 다양한 실 시예들에 따르면, 도 36에 도시되는 동작들은 도시되는 순서에 국한되지 않고 다양한 순서로 수행될 수 있다. 또한, 다양한 실시예들에 따르면, 도 36에 도시되는 동작들 보다 더 많은 동작들이 수행되거나, 더 적은 적어도 하나의 동작이 수행될 수도 있다. 이하에서는, 도 37 및 도 38을 참조하여, 도 36에 대해서 더 설명한다. 도 37은, 다양한 실시예들에 따른, 전자 장치의 음악적 단위에 기반하여 식별되는 이벤트 발생 시점 및 시 간 구간의 예를 설명하기 위한 도면이다. 도 38a는, 다양한 실시예들에 따른, 전자 장치의 시간 구간을 가 이드하기 위해 시각적 효과를 제공하는 동작의 예를 설명하기 위한 도면이다. 도 38b는, 다양한 실시예들에 따 른, 전자 장치의 시간 구간을 가이드하기 위해 시각적 효과를 제공하는 동작의 예를 설명하기 위한 도면이 다. 도 38c는 다양한 실시예들에 따른, 전자 장치의 메인 캐릭터(3420a)에 대한 시간 구간 별 사용자의 입 력에 기반하여, 효과를 제공하는 동작의 예를 설명하기 위한 도면이다. 다양한 실시예들에 따르면, 전자 장치(예: 프로세서)는, 동작 3601에서, 메인 오브젝트(예: 도 34 및 도 35의 메인 그래픽 오브젝트(3420a))를 포함하는 실행 화면을 표시하면서, 복수의 오디오 소스들(예: 도 34 및 도 35의 오디오 소스 셋(3400b))에 기반하여 사운드를 출력할 수 있다. 다양한 실시예들에 따르면, 전자 장치(예: 프로세서)는, 동작 3603에서, 복수의 오디오 소스들에 기 반하여 음악적 단위(예: 박자, 마디)를 식별하고, 동작 3605에서, 식별된 음악적 단위(예: 박자, 마디)에 기초 하여 복수의 시각적 이벤트 발생 시점들을 식별하고, 동작 3607에서, 상기 복수의 시각적 이벤트 발생 시점들에 기초하여 복수의 시간 구간들을 결정할 수 있다. 예를 들어 도 37을 참조하면, 전자 장치는, 음악적 단위 로서 6 마디를 식별하는 경우, 기-설정된 마디(예: 2/6 마디, 4/6 마디, 6/6 마디)를 이벤트 발생 시점으로 식 별할 수 있다. 상기 이벤트 발생 시점은, 특정 음악적 효과가 적용되거나, 및/또는 특정 오디오 소스가 출력되 는 것이, 자연스러운 음악적 시점으로 이해될 수 있다. 전자 장치는, 식별된 이벤트 발생 시점에 기반하여, 복수의 종류의 시간 구간들을 설정할 수 있다. 예를 들어, 도 37에 도시된 바와 같이, 전자 장치 는 이벤트 발생 시점을 포함하는 제1 시간 구간 및 상기 제1 시간 구간 이외의 나머지 시간 구간인 제2 시 간 구간을 설정할 수 있다. 상기 제1 시간 구간은 상기 이벤트 발생 시점을 기준으로 소정의 시간 간격이 형성 되도록 설정될 수 있다. 후술하겠으나, 전자 장치는, 사용자가 음악을 청취하면서, 상기 제1 시간 구간에 음악적 효과를 적용하도록 유도함으로써, 음악 감상의 질을 향상시킬 수 있다. 다양한 실시예들에 따르면, 전자 장치(예: 프로세서)는, 메인 캐릭터(3420a) 상에 시각적 효과를 제 공함으로써, 제1 시간 구간과 제2 시간 구간을 가이드할 수 있다. 예를 들어. 또한, 상기 제1 시간 구간 및 상 기 제2 시간 구간을 가이드하기 위해 메인 캐릭터(3420a)의 연관된 위치에 적어도 하나의 오브젝트가 표시될 수 있다. 예를 들어 도 38a에 도시된 바와 같이, 상기 제1 시간 구간을 가이드하기 위해 메인 캐릭터(3420a)의 연 관된 위치에 흰색 원이 제공될 수 있으며, 흰색 원이 가장 커지는 순간이 상기 제1 타입 시간 구간과 대응되도 록 설정될 수 있으나, 이에 한정되지 않는다. 보다 구체적으로 도 38a에 도시된 바를 참조하면, 도 38a의 (a)에 도시된 바와 같이 흰색 원이 작게 시작해서, 도 38a의 (b)에 도시된 바와 같이 흰색 원이 크게 디스플레이 될 수 있으며, 상기 흰색 원이 가장 커지는 시점이 상기 제1 시간 구간에 대응되도록 설정될 수 있으나, 이에 한정 되지 않는다. 또한 예를 들어 도 38b에 도시된 바와 같이, 상기 제2 시간 구간을 가이드 하기 위해 붉은색 원이제공될 수 있으며, 붉은색 원이 가장 커지는 순간이 상기 제2 시간 구간과 대응되도록 설정될 수 있으나, 이에 한정되지 않는다. 이 때, 상술한 예시의 경우 도 30에 도시된 바와 같을 수 있다. 보다 구체적으로, 도 38b에 도시된 바를 참조하면, 도 38b의 (a)에 도시된 바와 같이 붉은색 원이 작게 시작해서, 도 38b의 (b)에 도시된 바와 같이 붉은색 원이 크게 디스플레이 될 수 있으며, 상기 붉은색 원이 가장 커지는 시점이 상기 제2 시간 구 간에 대응되도록 설정될 수 있으나, 이에 한정되지 않는다. 또한, 예를 들어, 상기 제1 시간 구간 및 상기 제2 시간 구간을 가이드하기 위한 캐릭터의 모션이 제공될 수 있다. 보다 구체적으로 상기 제1 시간 구간 및 상기 제2 시간 구간은 상기 캐릭터의 동작에 의해 가이드될 수 있으며, 예를 들어, 상기 제1 시간 구간은 캐릭터가 오른발을 구르는 타이밍에 의해 가이드될 수 있으며, 상기 제2 시간 구간은 캐릭터의 손동작의 타이밍에 의해 가이드될 수 있으나, 이에 한정되지 않으며, 캐릭터의 동작에 의해 상기 제1 시간 구간 및 상기 제2 시간 구간 이 가이드 되는 다양한 실시예들을 포함할 수 있다. 다양한 실시예들에 따르면, 전자 장치(예: 프로세서)는, 동작 3609에서, 메인 오브젝트에 대한 사용 자 입력을 획득하고, 동작 3611에서, 사용자 입력의 획득 시점에 제1 시간 구간인지 여부를 판단하고, 제1 시간 구간인 경우(3611-예), 동작 3613에서, 메인 오브젝트(예: 도 34 및 도 35의 메인 그래픽 오브젝트(3420a))의 동작을 제1 동작으로 제어하면서 제1 오디오 효과를 출력하고, 제1 시간 구간이 아닌 경우(3611-아니오), 동작 3615에서, 사용자 입력의 획득 시점이 제2 시간 구간인지 여부를 판단하고, 제2 시간 구간인 경우(3615-예), 동 작 3617에서, 메인 오브젝트(예: 도 34 및 도 35의 메인 그래픽 오브젝트(3420a))의 동작을 제2 동작으로 제어 하면서, 제2 오디오 효과를 출력할 수 있다. 도 38c의 (a)를 참조하면, 전자 장치(예: 프로세서)는 메인 캐릭터(3420a)가 기-설정된 모션(예: 발 구름 동작)을 수행하도록 제어할 수 있으며, 상기 발구름 동작은 상술한 오디오 소스의 음악적 단위(예: 박자, 마디)에 대응되도록 디스플레이될 수 있으나, 이에 한정되지 않는다. 도 38c의 (b)를 참조하면, 전자 장치 (예: 프로세서)는 상기 제1 시간 구간에 사용자로부터 상기 제1 입력이 획득되는 경우 비쥬얼 이펙트 를 출력할 수 있다. 예를 들어, 도 38c의 (b)에 도시된 바와 같이 캐릭터 주변에 비쥬얼 이펙트를 출력할 수 있 으며, 재생 중인 오디오 소스에 포함되는 적어도 하나의 문자를 표시하며, 메인 캐릭터(3420a)가 기-설정된 특 정 동작(예: 랩 모션)을 수행하도록 제어할 수 있다. 상기 적어도 하나의 문자는 랜덤하게 생성될 수 있으며, 또는 NLP, TTS, 음성인식 등의 기술을 적용하여 오디오 소스로부터 식별되는 문자를 포함하거나, 및/또는 사용 자로부터 오디오 녹음을 획득하여 생성될 수 있다. 또한, 상기 오디오 소스가 재생됨에 따라 표시된 문자가 순 차적으로 사라질 수 있다. 또한, 도 38c의 (a) 및 (b)를 참조하면, 사용자로부터 상기 제1 시간 구간 또는 상기 제2 시간 구간에 상기 제1 입력 또는 상기 제2 입력이 획득된 경우 사용자에게 배경 공간을 디스플레이 할 수 있다. 예를 들어, 사용자로부터 인터랙션을 획득한 보상으로 시야가 확보되는 것을 표시하기 위하여 사용자로부 터 인터랙션이 획득된 경우 배경 공간을 디스플레이 할 수 있으나, 이에 한정되지 않는다. 전자 장치(예: 프로세서)는 상기 제2 시간 구간에 사용자로부터 상기 제2 입력이 획득되는 경우 전술한 동작을 삼가할 수 있다. 즉, 전자 장치는 기-설정된 모션(예: 발구름 동작)을 유지하도록 제어하며, 텍스트를 표시하지 않도 록 제어할 수 있으나, 기재된 예에 제한되지 않는다. 한편, 상기 메인 캐릭터(3420a)의 모션은 다양하게 설정될 수 있는데, 이를 위한 모션의 생성의 예에 대해서는 “7.1.2 목차”를 참조하여 설명한다. 7.1.2. 메인 오브젝트 및 모션 생성 시나리오 도 39는, 다양한 실시예들에 따른, 전자 장치의 동작의 예를 설명하기 위한 흐름도이다. 다양한 실 시예들에 따르면, 도 39에 도시되는 동작들은 도시되는 순서에 국한되지 않고 다양한 순서로 수행될 수 있다. 또한, 다양한 실시예들에 따르면, 도 39에 도시되는 동작들 보다 더 많은 동작들이 수행되거나, 더 적은 적어도 하나의 동작이 수행될 수도 있다. 이하에서는, 도 40, 도 41a, 및 도 41b를 참조하여, 도 39에 대해서 더 설명 한다. 도 40은, 다양한 실시예들에 따른, 전자 장치의 메인 그래픽 오브젝트의 생성 동작의 예를 설명하기 위한 도면이다. 도 41a는, 다양한 실시예들에 따른, 전자 장치의 모션 생성 동작의 예를 설명하기 위한 도면이 다. 도 41b는, 다양한 실시예들에 따른, 전자 장치의 모션 제어 동작의 예를 설명하기 위한 도면이다. 다양한 실시예들에 따르면, 전자 장치(예: 프로세서)는, 동작 3901에서, 메인 오브젝트(예: 도 40의 메인 캐릭터(3420a))를 획득하고, 동작 3903에서, 메인 오브젝트(예: 도 40의 메인 캐릭터(3420a))와 연관된 적 어도 하나의 모션을 획득할 수 있다. 다양한 실시예들에 따르면, 전자 장치(예: 프로세서)는, 사용자 고유의 캐릭터를 생성할 수 있다. 일 실시예에서, 도 40의 4010에 도시된 바와 같이, 전자 장치는 기-구현된 캐릭터를 제공하고, 캐릭터의 시각 적 속성(예: 부분 별 형상, 분분 별 색상 등)을 편집하기 위한 인터페이스를 제공할 수 있다. 전자 장치 는 상기 인터페이스를 통해서 선택되는 시각적 속성에 다라서, 캐릭터를 구성하여 메인 캐릭터 (3420a)를 생성할 수 있다. 또 일 실시예에서, 전자 장치는 카메라를 이용하여 촬영된 사용자(U)에 대한 정보(예: 얼굴 특징)에 기반하여, 3D 모델링과 같은 알고리즘을 이용하여 사용자(U)에 대응하는 3D 캐릭터를 생 성할 수도 있다. 즉, 인터랙티브 음악 감상 시스템은 나만의 고유의 캐릭터를 생성함으로써, 마치 내가 가상 현실 공간을 탐험하면서 음악을 감상하는 듯한 분위기를 연출함으로써, 음악 감상에 대한 몰입도를 향상시킬 수 있다. 다양한 실시예들에 따르면, 전자 장치(예: 프로세서)는, 기-구현된 캐릭터 모션을 생성할 수 있다. 예를 들어, 도 41a의 4110을 참조하면, 전자 장치는 사용자의 입력에 기반하여 제공되는 기-구현된 모션을 제공할 수 있다. 상기 기-구현된 모션은, 획득된 복수의 움직임들 중 적어도 일부를 이어 붙이는 형태로 제작될 수 있으나, 기재된 예에 제한되지는 않는다. 상기 기-구현된 모션은, 메인 캐릭터(3420a)가 선택된 경우 제공되 는 제1 종류의 모션 및 메인 캐릭터(3420a)의 주위가 선택된 경우 제공되는 제2 종류의 모션을 포함할 수 있다. 이에 따라, 전자 장치는 상기 메인 캐릭터(3420a)가 선택된 경우, 다양한 실시예들에 따르면, 전자 장치(예: 프로세서)는, 사용자 고유의 캐릭터 모션과 함께 모션에 대응하는 음악적 효과를 생성할 수 있다. 예를 들어, 도 41a의 4120을 참조하면, 전자 장치는 캐릭터 모션 을 생성하는 동작의 적어도 일부로, 메인 캐릭터(3420a)를 구성하는 복수의 관절들을 표시하고, 관절들 중 선택된 관절(예: 특정 관절)을 이동시키기 위한 사용자의 입력에 기반하여, 메인 캐릭터 (3420a)의 캐릭터 모션을 생성할 수 있다. 예를 들어, 전자 장치는 지정된 시간 동안, 사용자의 입력에 기 반하여 선택된 관절의 이동을 식별하고, 지정된 시간 동안의 관절의 이동에 대응하는 캐릭터 모션을 생성할 수 있다. 이때, 전자 장치는 오디오 효과를 선택하기 위한 인터페이스를 제공함으로써, 생성된 캐릭터 모션에 대응하는 오디요 효과를 선택하도록 하고, 생성된 모션과 선택된 오디오 효과를 서로 연관된 형태로 저 장할 수 있다. 이후, 해당 모션이 수행되는 경우, 전자 장치는 모션과 연관된 오디오 효과를 청각적 컨텐 트(100b)(예: 오디오 소스)에 적용할 수 있다. 한편, 전자 장치는 관절 별로 모션을 생성할 수 있으며, 이 후 사용자에 의해 선택된 관절에 기반하여 그에 대응하는 모션을 메인 캐릭터(3420a)를 통해 제공할 수 있다. 다양한 실시예들에 따르면, 도 41b를 참조하면, 전자 장치(예: 프로세서)는 메인 캐릭터(3420a)의 모 션을 제어하기 위한 별도의 그래픽 오브젝트(4100b)를 제공할 수 있다. 상기 그래픽 오브젝트(4100b)는 메인 캐 릭터(3420a)의 모션의 종류를 선택하기 위한 기능을 제공하도록 구현될 수 있다. 예를 들어, 도 41b에 도시된 바와 같이, 상기 그래픽 오브젝트(4100b)는 사용자에 의해 선택(예: 터치)되는 경우, 메인 캐릭터(3420a)가 수 행할 모션의 종류(예: 춤 동작의 종류)를 선택하기 위한 적어도 하나의 메인 영역(4111b, 4112b, 4113b, 4114b) 및 선택된 종류의 모션과 연관된 서브 모션(예: 메인 캐릭터(3420a)의 일 부분의 움직임 및/또는 춤 동작)을 선 택하기 위한 적어도 하나의 서브 영역(4120b)을 제공하도록 구현될 수 있다. 상기 서브 모션에 대응하는 메인 캐릭터(3420a)의 일 부분은 메인 캐릭터(3420a) 상체 부분, 하체 부분, 팔, 다리 등 다양한 종류의 부분을 포함 할 수 있다. 도 41b를 참조하면, 전자 장치는 상기 그래픽 오브젝트(4100b)에 대한 터치가 유지된 상태에 서 이동되어 특정 메인 영역(4114b)이 선택된 경우 선택된 메인 영역(4114b)에 대응하는 모션(예: 춤 동작)을 수행하도록 메인 캐릭터(3420a)를 제어할 수 있다. 전자 장치는 특정 메인 영역(4114b)이 선택된 경우 상 기 터치가 유지된 상태에서 다른 서브 영역(4120b)로 이동되는 경우, 메인 캐릭터(3420a)의 모션을 선택된 모션 으로 유지한 상태에서 서브 영역(4120b)에 대응하는 메인 캐릭터(3420a)의 일 부분(예: 상체 부분)의 모션만을 특정 모션으로 제어할 수 있다. 전자 장치는 상기 터치가 해제되는 경우 설정된 모션을 계속하여 유지하여 메인 캐릭터(3420a)를 제어할 수 있으나, 기재된 예에 제한되지 않고 모션의 제공을 중단할 수도 있다. 전술한 바와 같이, 그래픽 오브젝트(4100b)의 터치를 유지한 상태에서 드래그함으로써 연속적으로 메인 캐릭터(3420a) 의 모션을 제어함에 따라, 사용자가 메인 캐릭터(3420a)의 움직임을 제어하는 연속적인 경험을 할 수 있게 된다. 한편, 기재된 예에 제한되지 않고, 상기 그래픽 오브젝트(4100b)가 메인 캐릭터(3420a)의 움직임을 제어 하는 기능을 제공하는 것으로 기술하였으나, 이와 유사하게 메인 영역(4111b, 4112b, 4113b, 4114b)에 기반하여 오디오 소스의 종류를 선택하고, 서브 영역(4120b)에 기반하여 선택된 종류의 오디오 소스의 속성을 제어하는 기능을 제공하도록 구현될 수도 있다. 다양한 실시예들에 따르면, 전자 장치(예: 프로세서)는 사용자 맞춤 형의 캐릭터 모션 및/또는 오디 오 효과를 제공할 수 있다. 예를 들어, 전자 장치는 소정의 캘리브레이션(calibration)을 위한 기간 동안수집되는 사용자가 그래픽 오브젝트를 제어(예: 터치)하는 정보를 기반으로, 사용자의 고유의 음악적 정보(예: 음악적 패턴, 음악적 취향)를 획득하고, 이에 대응하는 모션 및/또는 오디오 효과를 제공할 수 있다. 전자 장치 는 음악적 정보를 획득하는 동작의 적어도 일부로, 미리-저장된 사용자의 그래픽 오브젝트를 제어하는 정 보 별로 대응하는 음악적 정보에 대한 정보를 이용하거나, 및/또는 그래픽 오브젝트를 제어하는 정보를 입력 받 은 것에 대한 응답으로 음악적 정보를 출력하도록 구현되는 인공 지능 모델을 이용할 수 있다. 일 예로, 전자 장치는 소정의 그래픽 오브젝트를 제공하면서 음악을 재생하면서 사용자가 그래픽 오브젝트를 터치하도록 가이드하고, 사용자의 터치가 수신되는 시간과 미리-저장된 정보를 이용하여 사용자의 음악적 취향을 식별할 수 있다. 일 예로, 전자 장치는 사용자가 특정 박자로 그래픽 오브젝트를 터치를 수행하는 경우, 박자감을 좋 아하는 사용자의 음악적 취향을 식별할 수 있다. 전자 장치는 상기 식별된 음악적 취향에 기반하여, 메인 캐릭터(3420a)의 선택 시 특정 모션(예: 랩 모션)과 함께, 음악적 효과로서 박자감을 고양시키는 소리(예: 드럼 소리, 비트 소리)를 제공할 수 있다. 다양한 실시예들에 따르면, 전자 장치(예: 프로세서)는, 동작 3905에서, 메인 오브젝트(예: 도 41의 메인 캐릭터(3420a))를 포함하는 실행 화면을 표시하면서, 복수의 오디오 소스들에 기반하여 사운드를 출력하고, 동작 3907에서, 메인 오브젝트(예: 도 41의 메인 캐릭터(3420a))에 대한 사용자 입력을 획득하고, 동 작 3909에서, 메인 오브젝트(예: 도 41의 메인 캐릭터(3420a))의 동작을 적어도 하나의 동작 중 특정 동작으로 제어하면서, 특정 오디오 효과를 출력할 수 있다. 일 실시예에서, 전자 장치는 메인 캐릭터(3420a)에 대한 사용자 입력을 수신하는 경우, 미리-설정된 모션을 적용하거나 및/또는 생성된 모션으로 메인 캐릭터가 동작을 수행하도록 제어하며, 이에 대응하는 오디오 효과를 출력하도록 제어할 수 있다. 또 일 실시예에서, 전자 장치 는 메인 캐릭터(3420a)의 주변 영역(예: 메인 캐릭터(3420a)로부터 기-설정된 거리 떨어진 영역)에 사용자 입력을 수신하는 경우, 기-설정된 모션으로 메인 캐릭터가 동작을 수행하도록 제어하며, 이에 대응하는 오디오 효과를 출력하도록 제어할 수 있다. 해당 모션은, 사용자의 입력이 수신된 위치로부터 메인 캐릭터(3420a)의 신 체 부분이 멀어지는 듯한 모션이 수 있다. 또 예를 들어, 전자 장치는 모션을 제공하는 동작의 적어도 일 부로, 상기 사용자의 입력이 수신된 위치와 가장 가까운 위치의 관절을 선택하고, 선택된 관절과 연관된 모션을 제공할 수 있다. 7.1.3. 청각적 컨텐트의 음악적 단위에 기반한 모션 제공 도 42는, 다양한 실시예들에 따른, 전자 장치의 동작의 예를 설명하기 위한 흐름도이다. 다양한 실 시예들에 따르면, 도 42에 도시되는 동작들은 도시되는 순서에 국한되지 않고 다양한 순서로 수행될 수 있다. 또한, 다양한 실시예들에 따르면, 도 42에 도시되는 동작들 보다 더 많은 동작들이 수행되거나, 더 적은 적어도 하나의 동작이 수행될 수도 있다. 이하에서는, 도 43을 참조하여, 도 42에 대해서 더 설명한다. 도 43은, 다양한 실시예들에 따른, 전자 장치의 청각적 컨텐트의 음악적 단위에 기초하여 모션을 제공하는 동작의 예를 설명하기 위한 도면이다. 다양한 실시예들에 따르면, 전자 장치(예: 프로세서)는, 동작 4201에서, 복수의 오디오 소스들에 기 반한 음악적 단위(예: 박자, 마디)를 식별하고, 동작 4203에서, 음악적 단위(예: 박자, 마디)에 대응하는 개수 의 적어도 하나의 관절(예: 도 43의 관절(4310, 4320))을 포함하는 메인 오브젝트(예: 메인 캐릭터(3420a))를 제공할 수 있다. 예를 들어 도 43을 참조하면, 전자 장치는 현재 제공되는 오디오 소스 셋(또는 복수의 오 디오 소스들)의 음악적 단위(예: 박자, 마디)에 기반하여, 메인 캐릭터(3420a)의 관절의 개수를 설정할 수 있다. 예를 들어, 전자 장치는 1/2 박자인 경우 메인 캐릭터(3420a)의 관절의 개수를 1개로 설정하고, 8/8 박자인 경우 메인 캐릭터(3420a)의 관절의 개수를 8개로 설정할 수 있으나, 기재된 예는 예시일 뿐 박자 별로 서로 다른 관절의 개수가 설정될 수 있다. 도 43을 참조하면, 상기 관절의 개수에 따라서, 메인 캐릭터(4320a) 에 형성되는 관절의 위치가 상이해질 수 있다. 전술한 바와 같이, 전자 장치는, 지역 별로 서로 다른 구성 (예: 인트로(intro), 벌스(verse))의 오디오 소스 셋을 할당할 수 있는데, 메인 캐릭터(3420a)가 위치되는 지역에 따라서 상기 음악적 단위가 변경될 수 있으나, 기재된 예에 제한되지 않고, 타임라인의 경과에 따라서 음악적 단위(예: 박자, 단위)가 변경될 수도 있다. 다양한 실시예들에 따르면, 전자 장치(예: 프로세서)는, 동작 4205에서, 특정 관절에 대한 사용자 입 력을 획득하고, 동작 4207에서, 사용자 입력에 기반하여 메인 오브젝트의 동작을 특정 동작으로 제어하면서, 특 정 오디오 효과를 출력할 수 있다. 예를 들어, 전자 장치는 메인 오브젝트의 동작을 특정 동작으로 제어하 는 동작의 적어도 일부로, 메인 캐릭터(3420a)에 대한 사용자 입력을 수신하는 경우, 특정 관절을 선택하고, 선 택된 특정 관절에 대응하는 모션으로 메인 캐릭터(3420a)의 동작을 제어할 수 있다. 도 43을 참조하면, 사용자의 입력(예: 터치)이 수신되는 위치가 동일하더라도, 메인 캐릭터(3420a)에 구현되는 관절의 개수에 따라서, 선 택되는 관절이 상이해질 수 있다. 이에 따라, 메인 캐릭터(3420a)에 적용되는 모션이 상이해질 수 있으며, 결과 적으로 음악적 단위 별로 서로 다른 캐릭터 모션이 제공되며, 서로 다른 모션에 대응하는 오디오 효과가 적용 및/또는 오디오 소스가 출력될 수 있다. 7.2. 서브 오브젝트에 기반한 컨텐트 제어 7.2.1. 서브 오브젝트의 활성화 도 44는, 다양한 실시예들에 따른, 전자 장치의 동작의 예를 설명하기 위한 흐름도이다. 다양한 실 시예들에 따르면, 도 44에 도시되는 동작들은 도시되는 순서에 국한되지 않고 다양한 순서로 수행될 수 있다. 또한, 다양한 실시예들에 따르면, 도 44에 도시되는 동작들 보다 더 많은 동작들이 수행되거나, 더 적은 적어도 하나의 동작이 수행될 수도 있다. 이하에서는, 도 45를 참조하여, 도 44에 대해서 더 설명한다. 도 45는, 다양한 실시예들에 따른, 전자 장치의, 메인 캐릭터(3420a)의 위치에 기반한 서브 오브젝트 (3430a)의 활성화의 예를 설명하기 위한 도면이다. 다양한 실시예들에 따르면, 전자 장치(예: 프로세서)는, 동작 4401에서, 복수의 오디오 소스에 기반 하여 제1 사운드를 출력하면서, 제1 오브젝트(예: 메인 캐릭터(3420a))를 그래픽 공간에 제공하고, 동작 4403에 서, 제1 오브젝트(예: 메인 캐릭터(3420a))를 이동하기 위한 사용자의 입력을 수신할 수 있다. 다양한 실시예들에 따르면, 전자 장치(예: 프로세서)는, 동작 4405에서, 거리 조건이 만족되는 제1 서브 오브젝트(예: 도 45의 구조물(3430a))를 식별되는지 여부를 판단하고, 제1 서브 오브젝트(예: 도 45의 구 조물(3430a))가 식별되는 경우(4405-예), 동작 4407에서, 제1 스킴에 기반하여 제1 사운드와는 다른 제2 사운드 를 출력하고, 제1 서브 오브젝트(예: 도 45의 구조물(3430a))가 식별되지 않는 경우(4405-아니오), 동작 4409에 서, 제2 스킴에 기반하여 제1 사운드와는 다른 제3 사운드를 출력할 수 있다. 예를 들어 도 45에 도시된 바와 같이, 전자 장치는 메인 캐릭터(3420a)의 위치(예: 그래픽 공간 상의 좌표)와 서브 오브젝트(3430a)의 위 치(예: 그래픽 공간 상의 좌표)를 비교한 것에 기반하여, 메인 캐릭터(3420a)와 서브 오브젝트(3430a) 사이의 거리를 식별할 수 있다. 전자 장치는 상기 거리가 임계 값 보다 큰 경우 상기 서브 오브젝트(3430a)의 상 태를 비활성화 상태로 제어하고, 상기 거리가 임계 값 미만인 경우 상기 서브 오브젝트(3430a)의 상태를 활성화 상태로 제어할 수 있다. 이 경우 전술한 바와 같이, 전자 장치는 서브 오브젝트(3430a)가 제공하도록 설정 된 오디오 효과의 적용 및/또는 오디오 소스의 재생을 수행할 수 있다. 7.2.2. 서브 오브젝트의 획득에 기반한 오디오 소스 활성화 도 46은, 다양한 실시예들에 따른, 전자 장치의 동작의 예를 설명하기 위한 흐름도이다. 다양한 실 시예들에 따르면, 도 46에 도시되는 동작들은 도시되는 순서에 국한되지 않고 다양한 순서로 수행될 수 있다. 또한, 다양한 실시예들에 따르면, 도 46에 도시되는 동작들 보다 더 많은 동작들이 수행되거나, 더 적은 적어도 하나의 동작이 수행될 수도 있다. 이하에서는, 도 47을 참조하여, 도 46에 대해서 더 설명한다. 도 47은, 다양한 실시예들에 따른, 전자 장치의, 서브 오브젝트의 획득에 따른 오디오 소스 재생의 활성화 의 예를 설명하기 위한 도면이다. 다양한 실시예들에 따르면, 전자 장치(예: 프로세서)는, 동작 4601에서, 복수의 오디오 소스에 기반 하여 제1 사운드를 출력하면서, 제1 오브젝트(예: 도 47의 메인 캐릭터(3420a))를 그래픽 공간에 제공하고, 동 작 4603에서, 제1 오브젝트(예: 도 47의 메인 캐릭터(3420a))를 이동하기 위한 사용자의 입력을 수신할 수 있다. 다양한 실시예들에 따르면, 전자 장치(예: 프로세서)는, 동작 4605에서, 제1 오브젝트의 이동에 기반 하여, 상기 복수의 서브 오브젝트들 중 일부 서브 오브젝트들(예: 도 47의 서브 오브젝트)을 획득하고, 동작 4607에서, 상기 복수의 오디오 소스들 중 선택된 적어도 하나의 오디오 소스를 출력함에 기반하여, 제2 사 운드를 출력하고, 동작 4609에서, 상기 제2 사운드를 출력하는 동안 상기 제1 오브젝트(예: 도 47의 메인 캐릭 터(3420a))에 대한 사용자 입력이 수신되는 경우, 상기 선택된 적어도 하나의 오디오 소스 중 적어도 일부의 속 성을 변경함으로써 제3 사운드를 출력할 수 있다. 예를 들어 도 47을 참조하면, 전자 장치는 그래픽 공간 상에, 메인 캐릭터(3420a)에 의해 획득 가능한 서브 오브젝트들을 제공할 수 있다. 상기 서브 오브젝트들 각각에 할당된 오디오 효과 및/또는 오디오 소스는, 메인 캐릭터(3420a)에 의해 획득되는 경우, 적용되거나 및/ 또는 재생될 수 있다. 전자 장치는 메인 캐릭터(3420a)의 이동 시 메인 캐릭터(3420a)의 위치와 서브 오브젝트의 위치를 비교한 것에 기반하여, 메인 캐릭터(3420a)의 위치에 대응하는 위치의 서브 오브젝트 를 선택하는 동작을 수행할 수 있다. 전자 장치는 실행 화면 상에 획득된 서브 오브젝트에 대 응하는 오디오 소스들의 재생을 제어하기 위한 인터페이스(4711, 4721)를 제공하고, 상기 인터페이스에 기반하 여 사용자의 입력에 기반하여 재생되는 것으로 선택되는 오디오 소스들을 재생할 수 있다. 7.3 메인 캐릭터의 이동에 따른 컨텐트 제어 7.3.1 메인 캐릭터 이동 시 오디오 재생 시나리오 도 48은, 다양한 실시예들에 따른, 전자 장치의 동작의 예를 설명하기 위한 흐름도이다. 다양한 실 시예들에 따르면, 도 48에 도시되는 동작들은 도시되는 순서에 국한되지 않고 다양한 순서로 수행될 수 있다. 또한, 다양한 실시예들에 따르면, 도 48에 도시되는 동작들 보다 더 많은 동작들이 수행되거나, 더 적은 적어도 하나의 동작이 수행될 수도 있다. 이하에서는, 도 49를 참조하여, 도 48에 대해서 더 설명한다. 도 49는, 다양한 실시예들에 따른, 전자 장치의, 메인 캐릭터의 이동에 따라서 청각적 컨텐트의 재생, 그 리고 청각적 컨텐트의 역재생에 따른 메인 캐릭터의 이동의 예를 설명하기 위한 도면이다. 다양한 실시예들에 따르면, 전자 장치(예: 프로세서)는, 동작 4801에서, 제1 오브젝트(예: 메인 캐릭 터(3420a))를 그래픽 공간에 제공하고, 동작 4803에서, 복수의 사운드 소스들 중 적어도 제1 일부만을 재생함으 로써 제1 사운드를 출력할 수 있다. 예를 들어, 전자 장치는 복수의 오디오 소스들 중, 현재 메인 캐릭터 (3420a)가 위치되는 지역(예: 제1 테마 아레아)에 대응하는 오디오 소스만을 재생하여, 특정 테마의 사운드(예: 제1 테마 사운드)를 제공할 수 있다. 상기 특정 테마의 사운드를 제공하기 위한 오디오 소스는(즉, 영역에 할당 된 오디오 소스는), 멜로디와 같은 긴 시간 유지되는 오디오 소스일 수 있다. 다양한 실시예들에 따르면, 전자 장치(예: 프로세서)는, 동작 4805에서, 이동을 위한 사용자 입력의 수신 여부를 판단하고, 사용자 입력이 수신되는 경우(4805-예), 동작 4807에서, 상기 복수의 사운드 소스들 중 상기 적어도 제1 일부(예: 제1 테마 사운드)와 함께 상기 복수의 사운드 소스들 중 적어도 제2 일부(예: 메인 캐릭터(3420a) 이동 시 출력되도록 설정된 오디오 소스)를 재생함으로써, 제2 사운드를 출력하고, 사용자 입력 이 수신되지 않는 경우(4805-아니오), 동작 4809에서, 제1 테마의 제1 사운드(예: 제1 테마 사운드)의 출력을 유지할 수 있다. 예를 들어 도 49의 (a)를 참조하면, 전자 장치는 메인 캐릭터(3420a)가 위치되는 지역(예: 제1 테마 아레아)에 대응하는 오디오 소스를 재생하는 동안, 메인 캐릭터(4320a)가 이동되는 경우 특 정 오디오 소스의 재생을 수행하고, 메인 캐릭터(4320a)가 이동되지 않는 경우 특정 오디오 소스의 재생을 삼가 하면서, 메인 캐릭터(3420a)가 위치되는 지역(예: 제1 테마 아레아)에 대응하는 오디오 소스의 재생만을 유지할 수 있다. 상기 메인 캐릭터(4320a)가 이동됨에 따라 제공되는 특정 오디오 소스는 상기 메인 캐릭터(4320a)가 위치되는 지역에 대응하는 오디오 소스와는 상이할 수 있다. 예를 들어, 메인 캐릭터(4320a)가 이동되는 경우 특정 오디오 소스는 드럼에 대응하는 오디오 소스일 수 있다. 전자 장치는 특정 오디오 소스를 제공하는 중에 메인 캐릭터(4320a)의 이동이 중단되는 경우, 특정 오디오 소스의 재생을 중단할 수 있다. 전자 장치(11 0)는 메인 캐릭터(4320a)의 이동이 재개되는 경우, 다른 종류의 오디오 소스로 변경하여 재생을 수행할 수 있다. 한편, 메인 캐릭터(3420a)가 위치되는 지역(예: 제1 테마 아레아)에 대응하는 오디오 소스가 멜로디, 그리고 메 인 캐릭터(3420a)가 이동되는 경우 제공되는 오디오 소스가 드럼인 것으로 기술하였으나, 이와는 반대로 구현될 수도 있다. 다양한 실시예들에 따르면, 메인 캐릭터(3420a)는 사용자의 입력이 수신되지 않는 상태에서, 자동으로 랜덤한 위치로 이동될 수도 있다. 이 경우, 전자 장치는 사용자의 입력에 의해 메인 캐릭터(3420a)가 이동되는 경 우와는 다른 오디오 소스를 재생하거나 및/또는 동일한 오디오 소스이되 특정 오디오 효과를 적용하여 재생할 수 있다. 다양한 실시예들에 따르면, 도 49에 도시된 바와 같이, 전자 장치는 메인 캐릭터(3420a)의 이동에 따라서 메인 캐릭터(3420a)의 그래픽 공간에서의 위치에 대응하는 특정 오디오 소스의 재생 시점을 식별할 수 있다. 다 시 말해, 상기 메인 캐릭터(3420a)의 그래픽 공간에서의 위치와 특정 오디오 소스의 재생 시점은 서로 맵핑 (mapping)될 수 있다. 이에 따라, 도 49의 (b)를 참조하면, 전자 장치는, 특정 오디오 소스가 역재생되어 특정 오디오 소스의 재생 시점이 역으로 이동되는 경우, 메인 캐릭터(3420a)의 위치가 역으로 이동될 수 있다. 예를 들어, 전자 장치는, 메인 캐릭터(3420a)의 그래픽 공간에서의 위치와 특정 오디오 소스의 재생 시점 은 서로 맵핑(mapping)된 정보를 미리 저장하고, 미리 저장된 정보에 기반하여 메인 캐릭터(3420a)의 위치가 역으로 이동되는 경우 상기 이동된 위치에 대응하는 특정 오디오 소스의 재생 시점으로 설정할 수 있다. 7.3.2 메인 캐릭터 이동 시 오디오 효과 선택 시나리오 도 50은, 다양한 실시예들에 따른, 전자 장치의 동작의 예를 설명하기 위한 흐름도이다. 다양한 실 시예들에 따르면, 도 50에 도시되는 동작들은 도시되는 순서에 국한되지 않고 다양한 순서로 수행될 수 있다. 또한, 다양한 실시예들에 따르면, 도 50에 도시되는 동작들 보다 더 많은 동작들이 수행되거나, 더 적은 적어도 하나의 동작이 수행될 수도 있다. 다양한 실시예들에 따르면, 전자 장치(예: 프로세서)는, 동작 5001에서, 복수의 오디오 효과들 중 특 정 오디오 효과를 선택하고, 동작 5003에서, 상기 복수의 사운드 소스들 중 상기 적어도 제1 일부와 함께 상기 복수의 사운드 소스들 중 적어도 제2 일부만을 재생함으로써, 제2 사운드를 출력할 수 있다. 예를 들어, 전자 장치는, 메인 캐릭터(3420a)의 이동 시 특정 오디오 소스를 재생하는 동작의 적어도 일부로, 메인 캐릭터 (3420a)가 이동될 때마다 특정 오디오 효과를 선택하여 적용할 수 있다. 전자 장치는 복수의 오디오 효과 들 중 메인 캐릭터(3420a)의 이동시 마다 특정 오디오 효과를 선택하여, 선택된 오디오 효과를 오디오 소스의 재생 시 적용할 수 있다. 7.3.3 메인 캐릭터 이동 시 오디오 재생 및 오디오 효과 선택 전체 시나리오 도 51은, 다양한 실시예들에 따른, 전자 장치의 동작의 예를 설명하기 위한 흐름도이다. 다양한 실 시예들에 따르면, 도 51에 도시되는 동작들은 도시되는 순서에 국한되지 않고 다양한 순서로 수행될 수 있다. 또한, 다양한 실시예들에 따르면, 도 51에 도시되는 동작들 보다 더 많은 동작들이 수행되거나, 더 적은 적어도 하나의 동작이 수행될 수도 있다. 다양한 실시예들에 따르면, 전자 장치(예: 프로세서)는, 동작 5101에서, 제1 오브젝트(예: 메인 캐릭 터(3420a))를 그래픽 공간에 제공하고, 동작 5103에서, 복수의 영역들 중 상기 제1 오브젝트(예: 메인 캐릭터 (3420a))가 위치되는 제1 영역에 대응하는 제1 테마의 제1 사운드를 출력할 수 있다. 다양한 실시예들에 따르면, 전자 장치(예: 프로세서)는, 동작 5105에서, 이동을 위한 사용자 입력이 수신되는지 여부를 판단하고, 사용자 입력이 수신되는 경우(5105-예), 동작 5107에서, 특정 종류의 복수의 사운 드 소스들 중에서 제1 사운드 소스를 선택하고, 동작 5109에서, 제1 테마의 상기 제1 사운드를 출력하면서, 상 기 특정 종류의 상기 제1 사운드 소스를 더 출력함으로써, 제2 사운드를 출력하고, 사용자 입력이 수신되지 않 는 경우(5105-아니오), 동작 5111에서, 제1 테마의 제1 사운드의 출력을 유지할 수 있다. 7.4 멀티 플레이 시나리오 도 52는, 다양한 실시예들에 따른, 전자 장치 및 서버의 동작의 예를 설명하기 위한 흐름도이 다. 다양한 실시예들에 따르면, 도 52에 도시되는 동작들은 도시되는 순서에 국한되지 않고 다양한 순서로 수행 될 수 있다. 또한, 다양한 실시예들에 따르면, 도 52에 도시되는 동작들 보다 더 많은 동작들이 수행되거나, 더 적은 적어도 하나의 동작이 수행될 수도 있다. 이하에서는, 도 53을 참조하여 도 52에 대해서 더 설명한다. 도 53은, 다양한 실시예들에 따른, 전자 장치의 멀티 플레이 시나리오의 예를 설명하기 위한 도면이다. 다양한 실시예들에 따르면, 서버는, 동작 5201 및 동작 5230에서, 복수의 전자 장치들(예: 제1 전자 장치 (5200a)와 제2 전자 장치(5200b))의 접속을 식별할 수 있다. 다양한 실시예들에 따르면, 서버는, 동작 5205에서, 복수의 전자 장치들(예: 제1 전자 장치(5200a)와 제2 전자 장치(5200b)) 별 메인 그래픽 오브젝트(예: 도 53의 메인 캐릭터들(5311, 5312))를 생성하여 그래픽 공간 에 제공할 수 있다. 다양한 실시예들에 따르면, 서버는, 동작 5207 및 동작 5209에서, 복수의 전자 장치들(예: 제1 전자 장치 (5200a)와 제2 전자 장치(5200b))의 정보를 수신할 수 있다. 예를 들어, 상기 수신되는 정보는, 메인 캐릭터 (5311, 5312)의 위치를 제어하기 위한 정보(예: 사용자 입력에 대한 정보)를 포함할 수 있다. 이 경우, 서버 는 상기 메인 캐릭터(5311, 5312)의 위치를 이동시켜, 이동시킨 위치에 대한 정보를 저장할 수 있다. 또 예를 들어, 상기 수신되는 정보는, 메인 캐릭터(5311, 5312)의 위치에 대한 정보를 직접적으로 포함할 수도 있 다. 다양한 실시예들에 따르면, 서버는, 동작 5211에서, 수신된 정보들에 기반하여, 복수의 메인 그래픽 오브 젝트들(예: 도 53의 메인 캐릭터들(5311, 5312))과 연관된 조건의 만족을 판단하고, 동작 5213 및 동작 5215에서, 복수의 전자 장치들(예: 제1 전자 장치(5200a)와 제2 전자 장치(5200b))로 제1 사운드를 제공하는 동작을 수행할 수 있다. 일 실시예에서, 도 53의 (a)에 도시된 바와 같이, 서버는 메인 캐릭터들(5311, 5312)이 서로 인접한 위치 (예: 기-설정된 거리 내의 위치)에 위치되는 경우, 메인 캐릭터들(5311, 5312)과 연관된 조건이 만족된 것으로 판단하고, 복수의 전자 장치들(예: 제1 전자 장치(5200a)와 제2 전자 장치(5200b))로 다른 전자 장치의 청각적 컨텐트를 제공하는 기능을 수행할 수 있다. 예를 들어, 서버는 일 캐릭터(예: 제1 메인 캐릭터)에 대응하는 일 전자 장치(예: 제1 전자 장치(5200a))로, 다른 캐릭터(예: 제2 메인 캐릭터) 상에 다른 전자 장치(예: 제2 전자 장치(5200b))로 제공되는 청각적 컨텐트를 감상하기 위한 인터페이스를 제공할 수 있 다. 해당 인터페이스가 선택되는 경우, 서버는 제1 전자 장치(5200a)로 청각적 컨텐트를 제공하며, 청각적 컨텐트의 재생 시점을 조절하도록 할 수 있다. 일 실시예에서, 도 53의 (b)에 도시된 바와 같이, 서버는 메인 캐릭터들(5311, 5312)과 연관된 조건이 만 족된 것으로 판단하는 경우, 서로 합주하는 기능을 제공할 수 있다. 서버는 메인 캐릭터들(5311, 5312)과 연관된 조건이 만족된 것으로 판단하는 동작의 적어도 일부로, 메인 캐릭터들(5311, 5312)이 서로 인접한 위치 (예: 기-설정된 거리 내의 위치)에 위치되는지 판단할 수 있다. 또, 서버는, 서로 인접한 위치인 것으로 판단된 메인 캐릭터들(5311, 5312) 별 그래픽 공간 상에서의 이동 경로의 유사도를 판단하고, 유사도가 기설정 된 값 이상인 경우에 상기 조건이 만족된 것으로 판단할 수 있으나, 기재된 예에 제한되지 않는다. 서버는 상기 조건이 만족된 경우, 메인 캐릭터들(5311, 5312)에 대응하는 복수의 전자 장치들(예: 제1 전자 장치 (5200a)와 제2 전자 장치(5200b))의 합주를 위한 파티(party)를 생성할 수 있다. 서버는 복수의 전자 장치 들(예: 제1 전자 장치(5200a)와 제2 전자 장치(5200b))로 동일한 오디오 소스를 제공하면서, 복수의 전자 장치 들(예: 제1 전자 장치(5200a)와 제2 전자 장치(5200b)) 별로 획득된 서브 오브젝트에 대응하는 오디오 소스 (5321, 322)를 재생하도록 할 수 있다. 파티에 포함된, 복수의 전자 장치들(예: 제1 전자 장치(5200a)와 제2 전 자 장치(5200b))은 사용자의 입력이 수신되는 경우, 동일한 오디오 소스를 재생하면서, 전술한 서브 오브젝트에 대응하는 오디오 소스(5321, 322)를 재생할 수 있다. 8. 트랜스포트를 포함하는 어플리케이션(또는 플레이어)의 구현 예 도 54는, 다양한 실시예들에 따른, 전자 장치의 소스풀, 입력풀, 및 복수의 트랜스 포트들을 포함하는 플 레이어(또는 어플리케이션)의 예를 설명하기 위한 도면이다. 이하에서는, 도 55a 및 도 55b를 참조하여, 도 54 에 대해서 더 설명한다. 도 55a는, 다양한 실시예들에 따른, 일 트랜스 포트의 동작의 예를 설명하기 위한 도면이다. 도 55b는, 다양한 실시예들에 따른, 일 트랜스 포트의 동작의 예를 설명하기 위한 도면이다. 다양한 실시예들에 따르면, 도 54를 참조하면, 인터랙티브 음악 감상 시스템은 플레이어, 소스 풀 (source pool), 및 입력 풀(input pool)을 포함할 수 있다. 상기 플레이어는 도 2에서 기술 한 어플리케이션를 의미하고, 소스 풀 및 입력 풀은 도 2에서 기술한 데이터베이스 내에 저장된 정보들일 수 있다. 다양한 실시예들에 따르면, 소스 풀은 아래의 [표 8]과 같은 종류의 데이터를 포함하도록 구현될 수 있다. 아래의 [표 8]에 기재된 바와 같이, 소스 풀은 비쥬얼 셋과 오디오 셋 분류 별로 정보를 포함하도 록 구현됨에 따라, 플레이어가 트랜스포트에 기반하여 비쥬얼 셋 정보 중 적어도 일부와 오디오 셋 정보 중 적어도 일부를 획득하게 될 수 있다. 표 8 종류 포함 정보비쥬얼 셋 (그래픽 데이터)인터랙션 리소스캐릭터 위치 데이터 리듬 이벤트 데이터 UI 이미지/텍스트 폰트 비쥬얼 이펙트 입자 효과 배경 및 하늘 맵 공간의 조명 정보 맵 효과 안개 맵 공간 맵 공간 정보 카메라 오브젝트 메인 캐릭터 서브 오브젝트 부가 오브젝트 오디오 셋 (오디오 데이터)오디오 파일 ogg, wav, mp3 오디오 샘플 오디오 인포 BPM Key Major Minor Genre House Rock Hiphop 종류 루프(긴 시간 길이의 종류) 원-샷(짧은 시간 길이의 종류) 다양한 실시예들에 따르면, 입력 풀은 사용자의 인터랙션, 문맥 정보, 서버로부터 수신되는 정보 등 제어 이벤트를 유발하는 다양한 종류의 정보를 의미할 수 있다.다양한 실시예들에 따르면, 복수의 트랜스 포트들은 시각적 컨텐트(100a)와 청각적 컨텐트(100b)를 제공하기 위하여 정보를 재생하는 일종의 재생 모듈로서, 실행되는 경우 소정의 기능을 제공하도록 설정되는 소정의 프로그램, 컴퓨터 코드, API, 및/또는 함 수의 형태로 구현될 수 있다. 플레이어가 실행되는 경우, 복수의 트랜스 포트들 중 적어도 하나가 실행됨에 기반하여, 프로세서가 적어도 하나의 동작을 수행하도록 하여 시각적 컨텐트 및/또는 청각적 컨 텐트를 제공하도록 할 수 있다. 따라서, 이하에서 기술되는 다양한 실시예들에 다른, 트랜스 포트의 동작 은, 트랜스 포트가 실행되는 경우 프로세서가 수행하는 동작으로 이해될 수 있다. 다양한 실시예들에 따르면, 복수의 트랜스포트들 간에는 서로 전환될 수 있다. 예를 들어, 일 트랜스포트 가 실행됨에 기반하여 기능이 제공되는 중에 특정 조건이 만족되는 경우(예: 후술되는 제어 오브젝트가 선택됨), 다른 트랜스포트로 진입하고, 특정 조건이 불만족되는 경우((예: 제어 오브젝트의 선택이 해제 됨), 일 트랜스포트로 복귀될 수 있으나, 기재된 예에 제한되지 않는다. 트랜스포트 간의 전환이 수행됨에 따라, 전자 장치에 의해 제공되는 시각적 컨텐트 및 청각적 컨텐트 또한 변경될 수 있다. 상기 복수의 트 랜스 포트들은 베이직 트랜스포트와 이벤트 트랜스포트를 포함할 수 있는데, 이에 대해서는 구체적으로 후술한다. 이때, 트랜스포트는 연쇄적으로 연결될 수 있다. 예를 들어, 도 54에 도시된 바와 같이, 베이직 트랜 스포트에서 이벤트 트랜스포트로 진입(enter)된 이후, 이벤트 트랜스포트에서 다른 서브 이벤트 트랜스포트로 또 진입(enter)될 수 있다. 이때, 각각의 트랜스포트에서 다른 트랜스포트로 진입되는 조건은 동일하거나, 및/ 또는 상이하게 설정될 수 있다. 도 55a 및 도 55b를 참조하면, 일 트랜스포트는 싱크 모듈, 인터랙션 모듈, 및 출력 모듈 를 포함할 수 있다. 예를 들어, 상기 싱크 모듈은 오디오 정보와 그래픽 정보에 기반하여 시각적 컨텐트(100a)와 청각적 컨텐 트(100b)를 생성하는 모듈일 수 있다. 상기 싱크 모듈은 소스 풀로부터 오디오 셋 중 적어도 일부를 획득하기 위한 오디오 셋 획득 모듈(5521a), 비쥬얼 셋 중 적어도 일부를 획득하기 위한 비쥬얼 셋 획득 모듈(5521b), 및 획득된 오디오 셋 중 적어도 일부를 기반으로 시각적 컨텐트(100a)를 생성하고 비쥬얼 셋 중 적어도 일부에 기반하여 청각적 컨텐트(100b)를 생성하고, 생성된 컨텐트들을 합쳐 출력 모듈를 통해 출 력하는 오디오 셋-비쥬얼 셋 싱크 모듈(5521c)을 포함할 수 있다. 예를 들어, 상기 인터랙션 모듈은 싱크 모듈이 소스 풀로부터 획득하는 정보를 제어하기 위한 모듈 일 수 있다. 상기 인터랙션 모듈은 인터랙션에 대한 정보를 획득하기 위한 입력 식별 모듈(5523a), 및 인터랙션에 대한 정보에 대응하는 룰 정보를 기반으로 싱크 모듈이 특정 그래픽 정보와 제어하는 인터랙션 시스템 이용 모듈(5523b)(즉, 룰 정보를 참조함)를 포함할 수 있다. 한편, 기재된 예에 제한되지 않고, 단순히 인터랙션 모듈은 룰 정보로 대체될 수 있으며, 이 경우, 각각의 트랜스포트는 특정 룰 정보에 기반하여 특정 그래픽 정보와 특정 오디오 정보를 획득하도록 구현될 수 있다. 예를 들어, 상기 출력 모듈는 각각의 컨텐트를 출력 장치로 전달하여 사용자에게 제공되도록 하는 모듈일 수 있다. 예시적으로, 도 55a 및 도 55b를 참조하면, 입력이 수신되지 않는 동안(T=0), 일 트랜스 포트(예: 제1 트랜스포 트)는 싱크 모듈을 이용하여 소스 풀로부터 제1 오디오 정보 및 제1 그래픽 정보를 획득하고, 이에 기반하여 시각적 컨텐트(100a) 및 청각적 컨텐트(100b)를 생성하여 출력 모듈를 통해 출력할 수 있다. 특 정 조건이 만족되는 경우(예: 입력이 수신되는 경우)(T=1)에는, 다른 트랜스포트(예: 제2 트랜스포트)로 전환될 수 있다. 상기 제2 트랜스포트는 인터랙션 모듈에 기반하여 식별되는 인터랙션에 대한 정보에 기반하여, 싱크 모듈이 제1 트랜스포트와는 다른 오디오 정보와 그래픽 정보를 획득하도록 제어하고, 이에 기반하여 시각적 컨텐트(100a) 및 청각적 컨텐트(100b)를 생성하여 출력 모듈를 통해 출력할 수 있다. 각각의 트랜스포트에 기반하여 출력되는 시각적 컨텐트(100a) 및 청각적 컨텐트(100b)의 예에 대해서는 이하에 서 기술한다. 8.1. 베이직 트랜스포트와 이벤트 트랜스포트 다양한 실시예들에 따르면, 전자 장치는 베이직 트랜스포트에 기반한 음악 감상 동작을 수행하는 중에, 사 용자의 인터랙션의 여부에 따라서 이벤트 트랜스포트에 기반한 음악 감상 동작을 개시하여, 급격한 시각적 컨텐 트(100a)의 전환과 함께 청각적 컨텐트(100b)를 제어하기 위한 기능을 제공할 수 있다. 상기 급격한 전환에 따 라, 인터랙티브한 음악 감상에 대한 몰입도가 고취될 수 있다. 도 56은, 다양한 실시예들에 따른, 전자 장치 및 서버의 동작의 예를 설명하기 위한 흐름도이 다. 다양한 실시예들에 따르면, 도 56에 도시되는 동작들은 도시되는 순서에 국한되지 않고 다양한 순서로 수행 될 수 있다. 또한, 다양한 실시예들에 따르면, 도 56에 도시되는 동작들 보다 더 많은 동작들이 수행되거나, 더 적은 적어도 하나의 동작이 수행될 수도 있다. 이하에서는, 도 57a 및 도 57b를 참조하여 도 55에 대해서 더 설 명한다. 도 57a는, 다양한 실시예들에 따른, 전자 장치의 베이직 트랜스포트와 이벤트 트랜스포트 간의 전환 동작 의 예를 설명하기 위한 도면이다. 도 57b는, 다양한 실시예들에 따른, 전자 장치의 이벤트 트랜스포트에 기반하여 제공되는 시각적 컨텐트 상에서의 메인 캐릭터의 이동에 따른 동작의 예를 설명하기 위한 도면이다. 도 57c는, 다양한 실시예들에 따른, 전자 장치의 베이직 트랜스포트와 이벤트 트랜스포트 간의 전환 동작 의 다른 예를 설명하기 위한 도면이다. 다양한 실시예들에 따르면, 전자 장치(예: 프로세서)는, 동작 5601에서, 프로그램을 실행하고, 동작 5603에서, 인터랙션의 수신 여부를 판단할 수 있다. 전술한 복수의 트랜스포트들은 베이직 트랜스포트 및 이벤트 트랜스포트를 포함할 수 있다. 예를 들어, 전자 장치는 인터랙션이 수신되지 않는 경우에는 베이직 트랜스포트에 기반하여 시각적 컨텐트와 청각적 컨텐트를 제공하고, 인터랙션이 수신되는 동안에는 이벤트 트랜 스포트에 기반하여 시각적 컨텐트와 청각적 컨텐트를 제공할 수 있다. 다양한 실시예들에 따르면, 도 57a 및 도 57c를 참조하면, 베이직 트랜스포트에 기반하여 제공되는 시각적 컨텐 트(예: 제1 실행 화면)는 메인 캐릭터, 제어 오브젝트, 및 그 외의 부가 오브젝트를 포함할 수 있다. 전자 장치는 상기 베이직 트랜스포트에 기반하여, 상기 시각적 컨텐트를 제공하면 서, 적어도 하나의 오디오 소스(예: 메인 오디오 소스 셋)를 재생함에 기반하여 사운드(예: 음악)를 사용자에게 제공할 수 있다. 이때 도 57a를 참조하면, 전자 장치는 메인 캐릭터가 부가 오브젝트를 따라 달리는 모션을 수행하도록 제어함으로써, 음악 감상의 몰임감을 향상시킬 수 있다. 도 57c를 참조하면, 전자 장 치는 메인 캐릭터가 행성 형태의 그래픽 오브젝트의 상에서 춤 동작을 수행하는 것으로 제어 할 수도 있다. 이 경우, 도 41b를 참조하여 기술한 바와 같이, 그래픽 오브젝트는 메인 캐릭터의 모션을 제어하는 기능을 제공하도록 구현될 수 있다. 다양한 실시예들에 따르면, 도 57a 및 도 57c를 참조하면, 이벤트 트랜스포트에 기반하여 제공되는 시각적 컨텐 트(예: 제2 실행 화면)은 메인 캐릭터, 제어 오브젝트, 및 그 외의 부가 오브젝트를 포함할 수 있다. 전자 장치는 상기 이벤트 트랜스포트에 기반하여, 상기 시각적 컨텐트를 제공하면서, 적어도 하나의 오디오 소스(예: 서브 오디오 소스 셋)를 재생함에 기반하여 사운드(예: 음악)를 사용자에게 제공할 수 있다. 상기 시각적 컨텐트는 상기 시각적 컨텐트와는 상이한 분위기의 시각적 컨텐트들 을 포함하며, 메인 캐릭터가 이동 가능한 그래픽 공간이 제공될 수 있다. 상기 그래픽 공간은, 상기 부가 오브젝트에 의해 제공될 수 있다. 이때, 제공되는 사운드는 베이직 트랜스포트에 기반하여 제공되는 사운 드와는 상이할 수 있다. 다양한 실시예들에 따르면, 전자 장치(예: 프로세서)는, 인터랙션이 수신되는 것으로 판단되지 않는 경우(5603-아니오), 동작 5605에서, 메인 오브젝트 및 제어 오브젝트를 포함하는 제1 실행 화면(예: 도 57a의 제1 실행 화면)을 표시하면서 제1 오디오를 재생하고, 동작 5607에서, 상기 제어 오브젝트(예: 제어 오브 젝트)의 상태를 상기 메인 오브젝트(예: 메인 캐릭터)의 제어가 불가능한 제1 상태(예: 비활성화 상태)로 제어할 수 있다. 다양한 실시예들에 따르면, 전자 장치(예: 프로세서)는, 인터랙션(예: 제어 오브젝트)이 수신 되는 것으로 판단되는 경우(5603-예), 동작 5609에서, 상기 제어 오브젝트(예: 제어 오브젝트)의 상기 상 태를 상기 메인 오브젝트(예: 메인 캐릭터)의 제어가 가능한 제2 상태(예: 활성화 상태)로 제어하고, 동 작 5611에서, 상기 메인 오브젝트(예: 메인 캐릭터) 및 상기 제어 오브젝트(예: 제어 오브젝트)를 포함하는 제2 실행 화면(예: 도 57a의 제2 실행 화면)을 표시하면서 제2 오디오를 재생하고, 동작 5613에 서, 상기 제어 오브젝트(예: 제어 오브젝트)에 기반한 상기 메인 오브젝트(예: 메인 캐릭터) 의 위 치의 이동 및 상기 제2 실행 화면(예: 도 57a의 제2 실행 화면)에 진입한 시점과 연관된 시간에 기반하여 상기 제2 오디오의 속성을 제어할 수 있다. 예를 들어, 전자 장치는 베이직 트랜스포트에 기반하여 제1 실 행 화면이 제공되는 동안 제어 오브젝트에 대한 입력이 수신되는 경우, 베이직 트랜스포트를 이벤 트 트랜스 포트로 변경하고 베이직 트랜스포트에 기반하여, 제2 실행 화면을 제공하면서, 오디오 소스(예: 서브 오디오 소스 셋)에 기반하여 사운드를 출력할 수 있다. 전자 장치는 제1 실행 화면에 서 제어 오브젝트가 터치된 순간 제2 실행 화면으로 전환함으로써, 음악 감상에 대한 몰입도를 향 상시킬 수 있다. 다양한 실시예들에 따르면, 도 57b를 참조하면, 상기 이벤트 트랜스포트에 기반하여 제공되는 제2 실행 화면 이 표시되는 동안에는, 오디오 소스(예: 서브 오디오 소스 셋)의 속성의 제어가 가능하다. 예를 들어, 전 자 장치는 메인 캐릭터의 위치에 기반하여 오디오 소스(예: 서브 오디오 소스 셋)의 속성을 제어할 수 있다. 전자 장치는 사용자의 입력에 의한 제어 오브젝트의 이동에 따라서, 메인 캐릭터을 부가 오브젝트 상에서 이동시키고, 상기 메인 캐릭터의 위치(예: x좌표, y좌표)에 기반하여, 특정 오디오 소스를 추가 출력하거나, 오디오 소스(예: 서브 오디오 소스 셋)의 속성을 제어하거나, 및/또는 오 디오 소스(예: 서브 오디오 소스 셋)에 오디오 효과를 적용할 수 있다. 일 예로, 전자 장치는 그래픽 공간 상에서의 상기 메인 캐릭터의 위치(예: x좌표, y좌표)가 특정 조건을 만족하는 경우, 특정 오디오 소스를 추가 출력하거나, 오디오 소스(예: 서브 오디오 소스 셋)의 속성을 제어하거나, 및/또는 오디오 소스(예: 서브 오디오 소스 셋)에 오디오 효과를 적용할 수 있다. 상기 특정 조건은, 예를 들면, 상기 그래픽 공간 상에 배치되는 특정 서브 오브젝트의 위치에 도달되어 특정 서브 오브젝트를 획득하거나, 또 는 특정 영역의 위치에 도달되는 것을 포함할 수 있다. 예를 들어, 전자 장치는 제어 오브젝트에 대 한 사용자의 터치가 유지되는 시간(dt)에 기반하여, 오디오 소스(예: 서브 오디오 소스 셋)의 속성을 제어하거 나 및/또는 오디오 소스(예: 서브 오디오 소스 셋)에 오디오 효과를 적용할 수 있다. 일 예로, 전자 장치 는, 터치가 유지되는 시간(dt)이 임계 시간을 넘는 경우, 출력되는 사운드의 에너지를 감소(예: 볼륨을 감소)시 킬 수 있다. 다양한 실시예들에 따르면, 전자 장치(예: 프로세서)는, 동작 5615에서, 인터랙션이 유지되는지 여부 를 판단하고, 인터랙션이 유지되는 경우, 5609 동작 내지 5614 동작(즉, 이벤트 트랜스포트에 기반한 동작)을 수행하고, 인터랙션이 유지되지 않는 경우 5605 동작(즉, 베이직 트랜스포트로 복귀하여, 베이직 트랜스포트에 기반한 동작)을 수행할 수 있다. 한편 도시되지 않았으나, 메인 캐릭터가 그래픽 공간 상에서 떨어지는 경우(예: 부가 오브젝트로부터 벗어나는 경우), 전자 장치는 베이직 트랜스포트로 복귀하는 동작을 수행할 수 있다.(또는 기재된 예에 제한되지 않고, 다른 서브 이벤트 트랜스포트로 변경할 수도 있다.) 다양한 실시예들에 따르면, 전자 장치(예: 프로세서)는, 이벤트 트랜스포트에 기반하여 동작을 수행 하는 동안, 특정 조건이 만족되는 경우 다른 이벤트 트랜스포트(예: 도 54의 서브 이벤트 트랜스포트)로 전환하 고, 전환된 다른 이벤트 트랜스포트에 기반한 동작을 수행할 수 있다. 예를 들어, 전자 장치는 이벤트 트 랜스포트에 대응하는 그래픽 공간에 제공되는 특정 서브 오브젝트를 상기 메인 캐릭터가 획득하는경우, 다른 이벤트 트랜스포트로 또 전환할 수 있다. 8.2. 트랜스 포트 간의 전환 동작 8.2.1 컨텐트 전환 동작 도 58은, 다양한 실시예들에 따른, 전자 장치 및 서버의 동작의 예를 설명하기 위한 흐름도이 다. 다양한 실시예들에 따르면, 도 58에 도시되는 동작들은 도시되는 순서에 국한되지 않고 다양한 순서로 수행 될 수 있다. 또한, 다양한 실시예들에 따르면, 도 58에 도시되는 동작들 보다 더 많은 동작들이 수행되거나, 더 적은 적어도 하나의 동작이 수행될 수도 있다. 이하에서는, 도 59a 및 도 59b를 참조하여 도 58에 대해서 더 설 명한다. 도 59a는, 다양한 실시예들에 따른, 전자 장치의 베이직 트랜스포트와 이벤트 트랜스포트 간의 전환 동작 의 예를 설명하기 위한 도면이다. 도 59b는, 다양한 실시예들에 따른, 전자 장치의 이벤트 트랜스포트에 기반하여 제공되는 시각적 컨텐트 상에서의 메인 캐릭터의 이동에 따른 동작의 예를 설명하기 위한 도면이다. 다양한 실시예들에 따르면, 전자 장치(예: 프로세서)는, 동작 5801에서, 복수의 실행 화면들(예: 제1 화면(5910a) 및 제2 화면(5910b)) 중에서 선택된 제1 실행 화면(예: 제1 화면(5910a))과 함께 상기 제1 실행 화 면(예: 제1 화면(5910a))에 대응하는 제1 오디오 중 제1 부분을 제공하고, 동작 5803에서 제2 실행 화면(예: 제 2 화면(5910b))으로 변경하기 위한 이벤트가 식별되는지 여부를 판단할 수 있다. 예를 들어, 전자 장치는 베이직 트랜스포트(5900a)에 기반하여 획득되는 그래픽 정보에 기반하여 제1 화면(5910a)를 제공하면서, 베이직 트랜스포트(5900a)에 기반하여 획득되는 오디오 정보(예: 도 59b의 오디오 소스 셋(5920a))를 재생함에 기반하 여 사운드를 출력할 수 있다. 상기 출력되는 사운드의 에너지(예: 맵 에너지)는 기-설정될 수 있다. 전자 장치 는 제1 화면(5910a)의 제어 오브젝트(예: 도 57a 또는 도 57c의 제어 오브젝트)에 대한 사용자 입력 여부를 판단할 수 있다. 다양한 실시예들에 따르면, 전자 장치(예: 프로세서)는, 제2 실행 화면(예: 제2 화면(5910b))으로 변 경하기 위한 이벤트가 식별되는 경우(5803-예), 동작 5805에서, 상기 제2 실행 화면(예: 제2 화면(5910b))과 함 께 상기 제2 실행 화면(예: 제2 화면(5910b))에 대응하는 제2 오디오 중 일부분을 제공하고, 동작 5807에서, 제 1 실행 화면(예: 제1 화면(5910a))으로 복귀하기 위한 이벤트가 식별되는지 여부를 판단할 수 있다. 예를 들어, 전자 장치는 1 화면(5910a)의 제어 오브젝트(예: 도 57a또는 도 57c의 제어 오브젝트)에 대한 사용 자 입력이 수신되는 경우, 베이직 트랜스포트(5900a)에 기반한 오디오 소스(5920a)의 재생을 중단하고, 이벤트 트랜스포트(5900b)로 전환할 수 있다. 전자 장치는 이벤트 트랜스포트(5900b)로 전환된 이후, 이벤트 트랜 스포트(5900b)에 기반하여 획득되는 그래픽 정보에 기반하여 상기 제2 화면(5910b)을 제공하면서, 이벤트 트랜 스포트(5900b)에 기반하여 획득되는 오디오 정보(예: 오디오 소스(5920b))를 재생함에 기반하여 사운드를 출력 할 수 있다. 상기 제2 화면(5910b)을 제공하는 동안 출력되는 사운드의 에너지는, 제1 화면(5910a)를 제공하는 동안 출력되는 사운드의 에너지와 상이할 수 있다. 전술한 바와 같이, 전자 장치는 전술한 바와 같이 제2 화면(5910b)를 제공하는 동안에는, 적어도 하나의 오디오 소스의 속성이 제어 가능하도록 할 수 있다. 예를 들 어, 도 59a의 5900에 도시된 바와 같이, 상기 제어는 메인 캐릭터의 위치의 변화, 및/또는 제어 오브젝트 에 대한 사용자 입력이 유지되는 시간의 길이에 기반하여 수행될 수 있다. 이에 따라, 상기 제2 화면 (5910b)을 제공하는 동안 출력되는 사운드의 에너지(예: 맵 에너지(5921b), 위치 별 에너지(5923b), 타임라인 에너지(5925b))는 다이나믹하게 제어될 수 있다. 다양한 실시예들에 따르면, 전자 장치(예: 프로세서)는, 제1 실행 화면(예: 제1 화면(5910a))으로 복 귀하기 위한 이벤트가 식별되는 경우(5807-예), 동작 5809에서, 상기 제1 실행 화면(예: 제1 화면(5910a))과 함 께 상기 제1 오디오 중 상기 제1 부분의 종료 시점 이후의 다른 나머지 제2 부분을 제공할 수 있다. 예를 들어, 전자 장치는 제어 오브젝트에 대한 사용자 입력이 해제되는 경우, 이벤트 트랜스포트(5900b)에 기반 한 오디오 소스(5920b)의 재생을 중단하고, 베이직 트랜스포트(5900a)에 기반한 오디오 소스(5920a)의 재생을 재개할 수 있다. 예를 들어, 전자 장치는 오디오 소스(5920a)의 재생이 중단된 시점부터, 다시 재생을 수 행할 수 있다. 이에 따라, 사용자의 인터랙션이 해제되는 경우, 사용자는 기존의 음악으로 복귀하여 음악 감상 이 일시 중단된 부분부터 다시 감상을 재개할 수 있게 된다. 8.2.2. 재생 축 전환 동작 도 60은, 다양한 실시예들에 따른, 전자 장치 및 서버의 동작의 예를 설명하기 위한 흐름도이 다. 다양한 실시예들에 따르면, 도 60에 도시되는 동작들은 도시되는 순서에 국한되지 않고 다양한 순서로 수행될 수 있다. 또한, 다양한 실시예들에 따르면, 도 60에 도시되는 동작들 보다 더 많은 동작들이 수행되거나, 더 적은 적어도 하나의 동작이 수행될 수도 있다. 다양한 실시예들에 따르면, 전자 장치(예: 프로세서)는, 동작 6001에서, 복수의 재생 모듈들 중 제1 재생 모듈(예: 베이직 트랜스포트)에 대응하는 적어도 하나의 제1 오디오 파일을 재생하고, 동작 6003에서 제2 재생 모듈(예: 이벤트 트랜스포트)로 변경하기 위한 이벤트가 식별되는지 여부를 판단할 수 있다. 다양한 실시예들에 따르면, 전자 장치(예: 프로세서)는, 제2 재생 모듈(예: 이벤트 트랜스포트)로 변 경하기 위한 이벤트가 식별되는 경우(6003-예), 동작 6005에서, 상기 제1 재생 모듈(예: 베이직 트랜스포트)에 대응하는 상기 적어도 하나의 제1 오디오 파일의 재생을 중지하고 상기 제2 재생 모듈(예: 이벤트 트랜스포트) 에 대응하는 적어도 하나의 제2 오디오 파일을 재생하고, 동작 6007에서, 제1 재생 모듈(예: 베이직 트랜스포트)로 복귀하기 위한 이벤트가 식별되는지 여부를 판단할 수 있다. 다양한 실시예들에 따르면, 전자 장치(예: 프로세서)는, 제1 재생 모듈로 복귀하기 위한 이벤트가 식 별되는 경우(6007-예), 동작 6009에서, 상기 제2 재생 모듈(예: 이벤트 트랜스포트)에 대응하는 상기 적어도 하 나의 제2 오디오 파일의 재생을 중지하고 상기 제1 재생 모듈(예: 베이직 트랜스포트)에 대응하는 상기 적어도 하나의 제1 오디오 파일을 상기 제1 시점부터 다시 재생할 수 있다. 9. 그래픽-뮤직 싱크 알고리즘 도 61은, 다양한 실시예들에 따른, 전자 장치 및 서버의 동작의 예를 설명하기 위한 흐름도이 다. 다양한 실시예들에 따르면, 도 61에 도시되는 동작들은 도시되는 순서에 국한되지 않고 다양한 순서로 수행 될 수 있다. 또한, 다양한 실시예들에 따르면, 도 61에 도시되는 동작들 보다 더 많은 동작들이 수행되거나, 더 적은 적어도 하나의 동작이 수행될 수도 있다. 이하에서는 도 62a 및 도 62b를 참조하여, 도 61에 대해서 더 설 명한다. 도 62a는, 다양한 실시예들에 따른, 그래픽 데이터가 제공되는 시점과 오디오 소스가 재생되는 시점의 예를 설 명하기 위한 도면이다. 도 62b는, 다양한 실시예들에 따른, 활성화 구간의 예를 설명하기 위한 도면이다. 다양한 실시예들에 따르면, 전자 장치(예: 프로세서)는, 동작 6101에서, 복수의 오디오 소스들(예: 제1 내지 제5 오디오 소스(audio source #1 내지 #5))을 획득하고, 동작 6103에서, 복수의 오디오 소스들(예: 제1 내지 제5 오디오 소스(audio source #1 내지 #5))에 기반하여 음악적 단위(예: 박자, 마디)를 식별하고, 동 작 6105에서, 식별된 음악적 단위(예: 박자, 마디)에 기반하여 이벤트 시점을 식별하고, 이벤트 발생 시점에 기 반하여 사용자 입력을 획득하기 위한 활성화 구간을 설정할 수 있다. 예를 들어, 전자 장치는 프로그램이 실행되는 동안 제공될 복수의 오디오 소스들(예: 제1 내지 제5 오디오 소스(audio source #1 내지 #5))을 획득 하고, 복수의 오디오 소스들(예: 제1 내지 제5 오디오 소스(audio source #1 내지 #5)) 중 적어도 일부에 기반 하여 음악적 단위(예: 박자, 마디)를 식별할 수 있다. 일 예로, 전자 장치는 복수의 오디오 소스들(예: 제 1 내지 제5 오디오 소스(audio source #1 내지 #5)) 중 프로그램이 실행되는 동안 전 시간 구간에 걸쳐 재생되 는 오디오 소스(예: 제1 오디오 소스(audio source#1))를 식별하고, 식별된 오디오 소스에 기반하여 음악적 단 위(예: 박자, 마디)를 식별할 수 있다. 전자 장치는 상기 음악적 단위(예: 박자, 마디)에 기반하여 이벤트 발생 시점을 식별할 수 있다. 상기 이벤트 발생 시점은, 특정 음악적 효과가 적용되거나, 및/또는 특정 오디오 소스가 출력되기에 적절한 시점으로 이해될 수 있다. 다양한 실시예들에 따르면, 도 62b를 참조하면, 전자 장치(예: 프로세서)는, 상기 이벤트 발생 시점 을 기준으로 활성화 구간을 설정할 수 있다. 상기 활성화 구간은 상기 이벤트 발생 시점을 기준으로 소정의 시 간 이전인 제1 시간 구간과 상기 이벤트 발생 시점을 기준으로 소정의 시간 이후인 제2 시간 구간을 포함할 수 있다. 상기 제1 시간 구간은 상기 제2 시간 구간 보다 길도록 설정될 수 있다. 다양한 실시예들에 따르면, 전자 장치(예: 프로세서)는, 동작 6107에서, 복수의 오디오 소스들(예: 제1 내지 제5 오디오 소스(audio source #1 내지 #5)) 중 적어도 일부를 재생하면서, 적어도 하나의 그래픽 오 브젝트(예: “목차. 2 내지 목차. 5”의 그래픽 오브젝트들)를 포함하는 실행 화면을 표시하고, 동작 6109에서, 적어도 하나의 그래픽 오브젝트에 대한 사용자 입력을 획득함에 기반하여, 사용자 입력이 획득된 시점을 획득할 수 있다. 다양한 실시예들에 따르면, 전자 장치(예: 프로세서)는, 동작 6111에서, 획득된 시점이 제1 시구간 (예: 활성화 구간 중 제1 시간 구간)에 해당하는지 여부를 판단하고, 제1 시구간(예: 활성화 구간 중 제1 시간 구간)에 해당하는 경우(6111-예), 동작 6113에서, 이벤트 시점에 특정 오디오 소스(예: 제4 오디오 소스(audiosource#4))를 출력하거나 및/또는 특정 오디오 소스의 속성을 제어하면서, 시각적 효과(visual effect)를 제공 할 수 있다. 예를 들어, 상기 출력되는 제4 오디오 소스(audio source#4)는 “목차. 2 내지 목차. 5”에서 기술 한 사용자의 인터랙션에 기반하여 제공되는 다양한 종류의 오디오 소스를 포함할 수 있다. 상기 특정 이벤트 시 점으로, 특정 오디오 소스(예: 제4 오디오 소스(audio source#4))를 출력하거나 및/또는 특정 오디오 소스의 속 성을 제어하면서, 시각적 효과(visual effect)를 제공의 시점이 제어됨에 따라서, 시각적 컨텐트(100a)와 청각 적 컨텐트(100b)가 시간적으로 동기화될 수 있다. 다양한 실시예들에 따르면, 전자 장치(예: 프로세서)는, 1 시구간(예: 활성화 구간 중 제1 시간 구간)에 해당하지 않는 경우(6111-아니오), 동작 6115에서, 획득된 시점이 제2 시구간(예: 활성화 구간 중 제2 시간 구간)에 해당하는지 여부를 판단하고, 제2 시구간(예: 활성화 구간 중 제2 시간 구간)에 해당하는 경우 (6115-예), 동작 6117에서, 사용자 입력을 무시할 수 있다. 10. 인터랙티브 음악 감상 플랫폼 이하에서 기술되는 다양한 실시예들에 따른 서버의 동작들 중 적어도 일부는, 특별한 언급이 없다면 소정 의 어플리케이션(또는 프로그램)에 의해 제공 가능한 동작으로 구현될 수도 있다. 즉, 이하의 서버의 동작 들 중 적어도 일부는 전자 장치에 저장된 어플리케이션(또는 프로그램)이 실행되는 경우, 전자 장치 에 의해 수행될 수 있다. 10.1 교환을 위한 전자 장치와 서버의 동작 도 63은, 다양한 실시예들에 따른, 전자 장치 및 서버의 동작의 예를 설명하기 위한 흐름도이 다. 다양한 실시예들에 따르면, 도 63에 도시되는 동작들은 도시되는 순서에 국한되지 않고 다양한 순서로 수행 될 수 있다. 또한, 다양한 실시예들에 따르면, 도 63에 도시되는 동작들 보다 더 많은 동작들이 수행되거나, 더 적은 적어도 하나의 동작이 수행될 수도 있다. 이하에서는, 도 64, 도 65a, 및 도 65b를 참조하여, 도 63에 대 해서 더 설명한다. 도 64는, 다양한 실시예들에 따른, 서버에 의해 교환되는 플랫폼 파일의 일 예를 설명하기 위한 도면이다. 도 65a는, 다양한 실시예들에 따른, 서버에 의해 제공되는 인터페이스의 일 예를 설명하기 위한 도면이다. 도 65b는, 다양한 실시예들에 따른, 서버에 의해 획득되는 어레이 별 정보의 예를 설명하기 위한 도면이다. 다양한 실시예들에 따르면, 서버는, 동작 6301에서, 음원 파일을 수신하고, 동작 6303에서, 업로드된 음원 파일에 대한 정보를 식별하고, 동작 6305에서, 음원 파일에 기반하여 복수의 오디오 소스들을 획득하고, 동작 6307에서, 복수의 오디오 소스들 중 적어도 일부를 제어하기 위한 실행 화면을 구성하고, 동작 6309에서, 실행 화면 및 복수의 오디오 소스들을 제공할 수 있다. 예를 들어, 도 65a를 참조하면, 서버는 전자 장치 의 접속이 식별되는 경우, 전자 장치로, 소정의 그래픽 유저 인터페이스를 제공할 수 있다. 상기 그 래픽 유저 인터페이스는 오디오 소스의 제어 및/또는 오디오 효과를 적용하기 위한 시각적 컨텐트(100a) (예: 복수의 그래픽 오브젝트들)를 포함하는 제1 영역, 선택된 음원 파일을 재생하기 위한 기능을 제공하는 제2 영역, 오디오 소스 및/또는 오디오 효과를 선택하기 위한 제3 영역, 음원 파일 업로 드 기능 및 업로드된 음원 파일에 대한 정보를 제공하기 위한 제4 영역을 포함할 수 있으며, 기재된 및/ 또는 도시된 예에 제한되지 않고, 다양한 종류의 그래픽 적 요소를 더 포함하도록 구현될 수도 있다. 서버(12 0)는, 전자 장치에 의해 상기 제4 영역에 포함된 음원 파일 업로드를 위한 메뉴가 선택되는 경우, 음원 파일 업로드 기능을 제공할 수 있으며, 이에 따라 전자 장치로부터 음원 파일을 수신할 수 있 다. 전자 장치는 수신된 음원 파일을, 전술한 오디오 소스 분리 기술에 기반하여, 복수의 오디오 소스들로 분리하여, 전자 장치로 제공할 수 있다. 전자 장치는 제1 영역을 통해 상기 분리된 복수의 오 디오 소스들 중 적어도 일부를 재생함으로써, 사운드를 사용자에게 제공할 수 있다. 한편, 도시된 예에 제한되지 않고, 상기 제1 영역에 제공되는 시각적 컨텐트(100a)는 “목차. 2 내지 목 차. 5”에서 기술한 다양한 종류의 시각적 컨텐트(100a)를 포함할 수 있다. 도시되지 않았으나, 서버는 상 기 다양한 종류의 시각적 컨텐트(100a)를 선택하기 위한 메뉴 화면을 제공하고, 상기 메뉴 화면으로부터 선택된 시각적 컨텐트(100a)를 제1 영역에 배치하여 전자 장치로 제공할 수 있다. 다양한 실시예들에 따르면, 서버는 전자 장치로 주기적으로 음원 파일과 연관된 복수의 오디오 소스 들을 전송하는 동작을 수행할 수 있다. 예를 들어, 상기 서버는 주기적으로 음원 파일의 일부분을 복수의 오디오 소스들로 변환하여 전자 장치로 전송하는 동작을 수행할 수 있다. 상기, 서버의 전송 주기를중계할 수 있는 중계 장치(및/또는 중계 프로그램)이 더 구현될 수 있다. 상기 복수의 오디오 소스들을 실시간 으로 생성하여 주기적으로 전송하는 동작을 통해, 오디오 소스의 분리가 원활해지는 이점이 있다. 다양한 실시예들에 따르면, 전자 장치는, 동작 6311에서, 실행 화면에 포함된 오브젝트(예: 복수의 그래픽 오브젝트들)를 제어함에 기반하여, 복수의 오디오 소스들의 적어도 일부의 속성을 제어함에 기반하여 사 운드를 제공하고, 동작 6313에서, 제공된 사운드와 연관된 적어도 하나의 파일을 저장하고, 동작 6315에서, 적 어도 하나의 파일 전송할 수 있다. 도 65b를 참조하면, 전자 장치는 복수의 오디오 소스들 중 적어도 일부 를 재생함에 기반하여 사운드를 출력하는 중에 사용자의 입력에 기반하여 복수의 그래픽 오브젝트들(6511a, 6511b, 6511c)의 위치를 제어하고, 상기 위치 제어에 기반하여 특정 오디오 소스를 출력하거나 및/또는 특정 오 디오 효과를 적용할 수 있다. 이때, 전자 장치는 시간을 복수의 시점들로 분할하고, 분할된 복수의 시점들 (시간 어레이) 별 사용자의 인터랙션에 대한 정보(6500a)를 획득할 수 있다. 상기 사용자의 인터랙션에 대한 정 보는, 복수의 그래픽 오브젝트들(6511a, 6511b, 6511c)의 위치에 대한 정보를 포함할 수 있다. 일 예로서, 상기 복수의 시점들 사이의 시간 간격은 0.2초일 수 있은가, 기재된 예에 제한되지 않고 다양한 시간 간격으로 구현 될 수 있다. 다양한 실시예들에 따르면, 서버는, 동작 6317에서, 수신된 적어도 하나의 파일을 저장할 수 있다. 서버 는 전자 장치로부터 전술한 복수의 시점들(시간 어레이) 별 사용자의 인터랙션에 대한 정보를 수신할 수 있다. 서버는 도 64에 도시된 바와 같이, 음원 파일에 대한 정보(예: 오디오 소스 셋), 시각적 컨텐트에 대한 정보(예: UI 식별 정보), 또는 상기 사용자의 인터랙션에 대한 정보(예: 어레이별 그래픽 오브젝트의 위치 정보) 중 적어도 하나를 연관된 형태(예: 하나의 데이터 셋트)로 저장할 수 있다. 상기 연관되도록 저장된 형태의 파일은 플랫폼 파일로 정의될 수 있다. 이에 따라, 사용자 고유의 인터랙티브 한 음악 경험이 재활용(예: 다시 재생, 및/또는 다른 사용자와 공유)될 수 있다. 예를 들어, 상기 서버는 상기 저장된 플랫폼 파일에 기반하여, 오디오 소스 셋을 재생하는 경우, 상기 사용자의 인터랙션에 대한 정보(예: 어레이별 그래픽 오브젝트의 위치 정보)를 기반으로 특정 오디오 소스를 재생하거나 및/또 는 특정 오디오 효과를 반영함으로써, 사용자가 이전에 감상한 사운드를 다시 재현하여 제공할 수 있다. 10.2 전자 장치의 동작 도 66은, 다양한 실시예들에 따른, 전자 장치의 동작의 예를 설명하기 위한 흐름도이다. 다양한 실 시예들에 따르면, 도 66에 도시되는 동작들은 도시되는 순서에 국한되지 않고 다양한 순서로 수행될 수 있다. 또한, 다양한 실시예들에 따르면, 도 66에 도시되는 동작들 보다 더 많은 동작들이 수행되거나, 더 적은 적어도 하나의 동작이 수행될 수도 있다. 다양한 실시예들에 따르면, 전자 장치(예: 프로세서)는, 동작 6601에서, 복수의 오디오 소스들을 포 함하는 음원 파일을 획득하고, 동작 6603에서, 복수의 오디오 소스들 중 적어도 일부의 제1 속성을 제어하기 위 한 적어도 하나의 오브젝트를 포함하는 실행 화면(예: 도 65a의 인터페이스)을 표시할 수 있다. 다양한 실시예들에 따르면, 전자 장치(예: 프로세서)는, 동작 6605에서, 상기 복수의 오디오 소스들 중 적어도 일부를 재생하면서 복수의 시간 별로 적어도 하나의 오브젝트(예: 도 65a의 그래픽 오브젝트) 에 대한 사용자의 입력을 획득하고, 상기 사용자의 입력에 기반하여 상기 복수의 오디오 소스들 중 적어도 일부 의 속성을 제어하고, 동작 6607에서, 상기 복수의 시간 별 획득된 사용자의 입력과 연관된 정보(예: 6500a)를 획득하고, 동작 6609에서, 상기 복수의 시간 별 획득된 사용자의 입력과 연관된 정보를 포함하는 데이터 셋을 전송할 수 있다. 10.3 공유 동작 도 67은, 다양한 실시예들에 따른, 복수의 전자 장치들(예: 전자 장치(6700a), 외부 전자 장치(6700b)) 및 서버 의 동작의 예를 설명하기 위한 흐름도이다. 다양한 실시예들에 따르면, 도 67에 도시되는 동작들은 도시되는 순서에 국한되지 않고 다양한 순서로 수행될 수 있다. 또한, 다양한 실시예들에 따르면, 도 67에 도시 되는 동작들 보다 더 많은 동작들이 수행되거나, 더 적은 적어도 하나의 동작이 수행될 수도 있다. 다양한 실시예들에 따르면, 전자 장치(6700a)(예: 프로세서)는, 동작 6701에서, 외부 전자 장치(6700b)로 제공된 사운드와 연관된 적어도 하나의 파일에 접근하기 위한 접근 정보를 전송할 수 있다. 예를 들어, 전자 장 치(6700a)는 서버를 통해 인터랙티브 음악 감상 플랫폼을 이용하는 동안, 특정 플랫폼 파일을 다른 사용자와 공유하는 기능을 실행할 수 있다. 전자 장치(6700a)는 플랫폼 파일이 공유될 다른 사용자가 선 택되는 경우, 다른 사용자의 외부 전자 장치(6700b)로 링크 정보를 제공할 수 있다. 상기 링크 정보는, 상기 특정 플랫폼 파일을 식별하기 위한 식별 정보, 및 서버로 접속하기 위한 링크(URI, URL)를 포함할 수 있다. 상기 링크 정보는, 종래의 메신저 어플리케이션을 통해 공유될 수 있으나, 기재된 예에 제한되지 않고, 서버에서 운용되는 메신져 기능을 이용하여 공유될 수도 있다. 다양한 실시예들에 따르면, 외부 전자 장치(6700b)는, 동작 6703에서, 서버로 접속할 수 있다. 예를 들어, 외부 전자 장치(6700b)는 상기 링크 정보를 선택한 것에 기반하여, 서버로 접속할 수 있다. 다양한 실시예들에 따르면, 서버는, 동작 6705에서, 제공된 사운드와 연관된 적어도 하나의 파일(예: 도 64의 플랫폼 파일 중 적어도 일부)을 획득하고, 동작 6707에서, 적어도 하나의 파일(예: 도 64의 플랫폼 파일 중 적어도 일부)에 기반하여 복수의 오디오 소스들을 획득하고, 동작 6709에서, 적어도 하나의 파일 (예: 도 64의 플랫폼 파일 중 적어도 일부)에 기반하여 복수의 오디오 소스들의 적어도 일부의 속성을 제 어함에 기반하여 사운드를 재생할 수 있다. 예를 들어, 서버는 외부 전자 장치(6700b)가 접속되는 경우, 외부 전자 장치(6700b)로부터 플랫폼 파일을 식별하기 위한 식별 정보를 획득하고, 식별 정보에 대응하는 플랫폼 파일을 식별할 수 있다. 서버는 상기 플랫폼 파일로부터 식별되는 UI 식별 정보(642 0)에 대응하는 시각적 컨텐트(100a)를 제1 영역에 포함하는 인터페이스를 제공하면서, 상기 플랫폼 파일로부터 식별되는 오디오 소스 셋을 외부 전자 장치(6700b)로 제공하여 재생하도록 할 수 있다. 이때, 서버 및/또는 외부 전자 장치(6700b)는 어레이 별 오브젝트 위치 정보에 기반하여 시각적 컨 텐트(100a) 내의 복수의 오브젝트들(예: 도 65a의 오브젝트)의 위치를 제어함에 기반하여, 특정 오디오 소스를 재생하거나 및/또는 특정 오디오 효과를 적용할 수 있다. 다양한 실시예들에 따르면, 외부 전자 장치(6700b)는 상기 플랫폼 파일에 기반하여 시각적 컨텐트(100a) 및 청각적 컨텐트(100b)를 제공하는 동안, 수신되는 사용자의 입력에 기반하여 어레이 별 복수의 오브젝트들(예: 도 65a의 오브젝트)의 위치를 제어하는 입력을 수신할 수 있다. 이에 따라, 서버는 상기 외부 전자 장치(6700b)로부터 기반하여 어레이 별 복수의 오브젝트들(예: 도 65a의 오브젝트)의 위 치를 제어하는 정보를, 기존의 플랫폼 파일 내에 추가할 수 있다. 10.4 확장 실시예 다양한 실시예들에 따르면, 전자 장치 및/또는 서버는, 전술한 그래픽 오브젝트에 대한 사용자의 인 터랙션 이외에도, 다양한 종류의 인터랙션을 획득하기 위한 시각적 컨텐트(100a)를 제공할 수 있다. 이하에서는, 전자 장치의 사용자의 모션을 획득하는 동작이 기술되나, 기재된 예에 제한되지 않고, 본 명 세서에서 기술된 다양한 종류의 인터랙션(예: 목소리, 물체 등)을 획득하기 위한 시각적 컨텐트(100a)가 제공될 수 있음은, 당업자에게 자명하다. 도 68은, 다양한 실시예들에 따른, 전자 장치의 동작의 예를 설명하기 위한 흐름도이다. 다양한 실 시예들에 따르면, 도 68에 도시되는 동작들은 도시되는 순서에 국한되지 않고 다양한 순서로 수행될 수 있다. 또한, 다양한 실시예들에 따르면, 도 68에 도시되는 동작들 보다 더 많은 동작들이 수행되거나, 더 적은 적어도 하나의 동작이 수행될 수도 있다. 이하에서는 도 69, 도 70a, 도 70b, 및 도 71을 참조하여, 도 68에 대해서 더 설명한다. 도 69는, 다양한 실시예들에 따른, 플랫폼 파일의 다른 예를 설명하기 위한 도면이다. 도 70a는, 다양한 실시예들에 따른, 서버에 의해 제공되는 시각적 컨텐트(100a)의 예를 설명하기 위한 도면이다. 도 70b는, 다양한 실시예들에 따른, 서버에 의해 제공되는 시각적 컨텐트(100a)의 예를 설명하기 위한 도면이다. 도 71은, 다양한 실시예들에 따른, 서버에 의해 제공되는 메신저 기능의 예를 설명하기 위한 도면이다. 다양한 실시예들에 따르면, 전자 장치는, 동작 6801에서, 복수의 오디오 소스들을 포함하는 음원 파일을 획득하고, 동작 6803에서, 카메라에 의해 촬영된 사용자를 포함하는 실행 화면을 표시할 수 있다. 예를 들어, 서버는, 도 70a 및 도 70b에 도시된 바와 같이, 전자 장치로 카메라에 의해 촬영된 영상 중 적어도 일부(예: 사용자(7010a, 7010b))를 포함하는 시각적 컨텐트(7020a, 7020b)를 인터페이스를 제공하면서, 전자 장치에 의해 선택된 음원 파일에 대응하는 복수의 오디오 소스들 중 적어도 일부를 재생함에 기반하 여 청각적 컨텐트(100b)를 제공할 수 있다. 상기 시각적 컨텐트(7020a, 7020b)의 배경은 기-설정된 배경이거나, 및/또는 전자 장치의 카메라에 의해 촬영된 사용자(U)가 위치하는 배경일 수 있다. 다양한 실시예들에 따르면, 상기 전자 장치는, 상기 시각적 컨텐트(7020a) 상에 적어도 하나의 그래픽 오 브젝트를 더 표시할 수 있다. 예를 들어, 도 70b에 도시된 바와 같이, 상기 시각적 컨텐트(7020a)는 가상의 캐 릭터(7001b, 7003b)를 포함할 수 있다. 상기 가상의 캐릭터(7001b, 7003b)는 선택된 음악 파일에 대응하는 아티스트들에 대응할 수 있으나, 기재된 예에 제한되지 않고 음악 파일과는 별개로 선택되는 가상의 캐릭터가 제공 될 수도 있다. 상기 가상의 캐릭터(7001b, 7003b)는 복수의 오디오 소스들 중 적어도 일부가 재생되는 동안, 소 정의 모션을 취하도록 설정될 수 있다. 일 예로, 음악적 단위에 기반하여, 상기 가상의 캐릭터(7001b, 7003b)가 춤 동작을 수행하도록 구현될 수 있다. 또 예를 들어, 도시되지 않았으나, 그래픽적 건축물 등 가상의 그래픽 오브젝트가 시각적 컨텐트(7020a) 상에 제공될 수 있다. 다양한 실시예들에 따르면, 전자 장치는, 동작 6805에서, 상기 복수의 오디오 소스들 중 적어도 일부를 재 생하면서 복수의 시간(예: 전술한 시간 어레이) 별로 사용자의 모션을 획득하고, 상기 획득된 모션에 기반하여 상기 복수의 오디오 소스들 중 적어도 일부의 속성을 제어하고, 동작 6807에서, 상기 복수의 시간 별 획득된 사 용자의 모션과 연관된 정보를 획득할 수 있다. 즉, 전자 장치는 복수의 시간들(시간 어레이) 별로 그래픽 오브젝트의 위치 대신에 카메라에 의해 촬영되는 사용자의 모션에 대한 정보를 획득할 수 있다. 다양한 실시예들에 따르면, 전자 장치는 복수의 오디오 소스들 중 적어도 일부를 재생함에 기반하여 청각 적 컨텐트(100b)를 제공하면서, 상기 사용자의 모션에 대응하는 특정 오디오 소스를 재생하거나 및/또는 특정 오디오 효과를 적용할 수 있다. 예를 들어 도 70a 및 도 70b에 도시된 바와 같이, 전자 장치는 사용자의 모션(7010a, 7030a, 7010b, 7030b) 별로 특정 오디오 소스를 재생할 수 있다. 다양한 실시예들에 따르면, 전자 장치는 상기 사용자의 모션에 대응하는 시각적 효과를 시각적 컨텐트 (110a)에 반영할 수 있다. 예를 들어, 도 70b에 도시된 바와 같이, 전자 장치는 상기 사용자의 모션에 기 반하여, 시각적 컨텐트(7020b)에 포함된 가상의 캐릭터(7001b, 7003b)의 동작을 제어할 수 있다. 예를 들어, 전 자 장치는 사용자의 모션이 제1 모션인 경우 가상의 캐릭터(7001b, 7003b)의 동작을 제1 동작으로 제어할 수 있으나, 사용자의 모션이 제2 모션인 경우 가상의 캐릭터(7001b, 7003b)의 동작을 제2 동작으로 제어할 수 있다. 다양한 실시예들에 따르면, 전자 장치는, 동작 6809에서, 상기 복수의 시간 별 획득된 사용자의 모션과 연 관된 정보를 포함하는 데이터 셋을 전송할 수 있다. 이에 따라, 도 69에 도시된 바와 같이, 서버는 오디오 소스 셋, 촬영된 비디오, 또는 어레이별 유저 모션 중 적어도 하나를 포함하는 플랫폼 파일 을 저장 및/또는 관리할 수 있다. 11. 확장 UI 도 72는, 다양한 실시예들에 따른, 인터랙티브 음악 감상 시스템에 의해 제공 가능한, 시각적 컨텐트(100a) 의 예를 설명하기 위한 도면이다. 도 72를 참조하면, 인터랙티브 음악 감상 시스템은, 메타버스(metaverse) 시각적 컨텐트를 제공하도록 구현 될 수 있다. 즉, 인터랙티브 음악 감상 시스템은, 가상 현실(virtual reality, VR), 혼합 현실(mixed reality, MR) 등과 같은 확장 현실(extended reality, XR) 용 전자 장치에 의해 제공 가능한 확장 현실 컨텐트를 제공하도록 구현될 수 있다. 다양한 실시예들에 따르면, 인터랙티브 음악 감상 시스템은, 전술한 시각적 컨텐트(100a)들과 유사하게, 복 수의 스테이지들 별로 구현되는 시각적 컨텐트(7210a, 7210b, 7210c) 내에 복수의 3D 그래픽 오브젝트들(7211a, 7211b)을 구현하고, 각각의 시각적 컨텐트(7210a, 7210b, 7210c)가 제공되는 동안 이에 대응하는 적어도 하나의 오디오 소스를 재생함에 기반하여 청각적 컨텐트(100b)(예: 제1 사운드, 제2 사운드)를 제공할 수 있다. 다양한 실시예들에 따르면, 인터랙티브 음악 감상 시스템은, 전술한 그래픽 오브젝트의 제어에 따른 시각적 컨텐트(100a) 및/또는 청각적 컨텐트(100b)를 제어하는 동작, 스테이지를 전환하는 동작 등을 수행할 수 있는 바, 더 중복되는 설명은 생략한다.도면 도면1 도면2a 도면2b 도면3 도면4 도면5 도면6a 도면6b 도면7a 도면7b 도면8a 도면8b 도면9 도면10 도면11a 도면11b 도면11c 도면12a 도면12b 도면12c 도면13a 도면13b 도면14a 도면14b 도면15 도면16 도면17 도면18 도면19 도면20 도면21a 도면21b 도면22 도면23a 도면23b 도면24 도면25 도면26 도면27 도면28 도면29 도면30 도면31 도면32 도면33 도면34 도면35 도면36 도면37 도면38a 도면38b 도면38c 도면39 도면40 도면41a 도면41b 도면42 도면43 도면44 도면45 도면46 도면47 도면48 도면49 도면50 도면51 도면52 도면53 도면54 도면55a 도면55b 도면56 도면57a 도면57b 도면57c 도면58 도면59a 도면59b 도면60 도면61 도면62a 도면62b 도면63 도면64 도면65a 도면65b 도면66 도면67 도면68 도면69 도면70a 도면70b 도면71 도면72"}
{"patent_id": "10-2022-0153315", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은, 다양한 실시예들에 따른 인터랙티브 음악 감상 시스템의 일 예를 설명하기 위한 도면이다. 도 2a는, 다양한 실시예들에 따른 전자 장치의 구성의 일 예를 설명하기 위한 도면이다. 도 2b는, 다양한 실시예들에 따른 어플리케이션의 실행에 따른 전자 장치의 동작의 예를 설명하기 위한 도면이 다. 도 3은, 다양한 실시예들에 따른 오디오 소스 셋(또는 오디오 소스) 및 스테이지 별 컨텐트의 예를 설명하기 위한 도면이다. 도 4는, 다양한 실시예들에 따른, 인터랙티브 음악 감상 파일의 배포의 예를 설명하기 위한 도면이다. 도 5는, 다양한 실시예들에 따른, 전자 장치의 동작의 일 예를 설명하기 위한 도면이다. 도 6a는, 다양한 실시예들에 따른, 전자 장치의 동작의 일 예를 설명하기 위한 흐름도이다. 도 6b는, 다양한 실시예들에 따른, 전자 장치의 사용자의 입력이 수신되는 경우 컨텐트들을 제어하는 동작의 예 를 설명하기 위한 도면이다. 도 7a는, 다양한 실시예들에 따른, 전자 장치의 동작의 일 예를 설명하기 위한 흐름도이다. 도 7b는, 다양한 실시예들에 따른, 전자 장치의 사용자의 입력 이외의 다른 정보가 수신되는 경우, 컨텐트들을 제어하는 동작의 예를 설명하기 위한 도면이다. 도 8a는, 다양한 실시예들에 따른, 전자 장치의 동작의 일 예를 설명하기 위한 흐름도이다. 도 8b는, 다양한 실시예들에 따른, 전자 장치의 모드 전환 동작의 예를 설명하기 위한 도면이다. 도 9는, 다양한 실시예들에 따른, 전자 장치의 동작의 예를 설명하기 위한 도면이다. 도 10은, 다양한 실시예들에 따른, 전자 장치의 동작의 예를 설명하기 위한 흐름도이다. 도 11a는, 다양한 실시예들에 따른, 전자 장치에 의해 제공되는 시각적 컨텐트의 일 예를 설명하기 위한 도면이 다. 도 11b는, 다양한 실시예들에 따른, 전자 장치에 의해 제공되는 시각적 컨텐트의 다른 예를 설명하기 위한 도면 이다. 도 11c는, 다양한 실시예들에 따른, 전자 장치에 의해 제공되는 시각적 컨텐트의 또 다른 예를 설명하기 위한 도면이다. 도 12a는, 다양한 실시예들에 따른, 전자 장치의 동작의 예를 설명하기 위한 흐름도이다. 도 12b는, 다양한 실시예들에 따른, 전자 장치의 메인 오브젝트의 개수를 설정하는 동작의 예를 설명하기 위한 도면이다. 도 12c는, 다양한 실시예들에 따른, 전자 장치의 메인 오브젝트의 이동에 따라서 오디오 소스의 속성을 제어하 는 동작의 예를 설명하기 위한 도면이다. 도 13a는, 다양한 실시예들에 따른, 전자 장치의 동작의 예를 설명하기 위한 흐름도이다. 도 13b는, 다양한 실시예들에 따른, 전자 장치의 신규 오브젝트를 생성하는 동작의 예를 설명하기 위한 도면이 다. 도 13c는, 다양한 실시예들에 따른, 전자 장치의 신규 오브젝트를 생성하는 동작의 예를 설명하기 위한 도면이 다. 도 14a는, 다양한 실시예들에 따른, 전자 장치의 동작의 예를 설명하기 위한 흐름도이다. 도 14b는, 다양한 실시예들에 따른, 전자 장치의 사용자의 입력이 배경 화면 상에 수신되는 경우, 오브젝트의 위치를 제어하는 동작의 예를 설명하기 위한 도면이다. 도 15는, 다양한 실시예들에 따른, 전자 장치의 동작의 예를 설명하기 위한 흐름도이다. 도 16은, 다양한 실시예들에 따른, 전자 장치의 동작의 예를 설명하기 위한 흐름도이다. 도 17은, 다양한 실시예들에 따른, 전자 장치의 동작의 예를 설명하기 위한 흐름도이다. 도 18은, 다양한 실시예들에 따른, 전자 장치의 메인 그래픽 오브젝트 별로 오디오 속성을 부여하는 동작의 예 를 설명하기 위한 도면이다. 도 19는, 다양한 실시예들에 따른, 전자 장치의 동작의 예를 설명하기 위한 도면이다. 도 20은, 다양한 실시예들에 따른, 전자 장치의 동작의 예를 설명하기 위한 흐름도이다.도 21a는, 다양한 실시예들에 따른, 전자 장치의 시각적 컨텐트를 제공하는 동작의 일 예를 설명하기 위한 도면 이다. 도 21b는, 다양한 실시예들에 따른, 전자 장치의 체인 인터랙션의 예를 설명하기 위한 도면이다. 도 22는, 다양한 실시예들에 따른, 전자 장치의 동작의 예를 설명하기 위한 흐름도이다. 도 23a는, 다양한 실시예들에 따른, 전자 장치의 사용자 간의 거리에 기반하여 제어를 위한 아바타를 제공하는 동작의 일 예를 설명하기 위한 도면이다. 도 23b는, 다양한 실시예들에 따른, 전자 장치의 사용자 간의 거리에 기반하여 제어를 위한 아바타를 제공하는 동작의 다른 예를 설명하기 위한 도면이다. 도 24는, 다양한 실시예들에 따른, 전자 장치의 동작의 예를 설명하기 위한 흐름도이다. 도 25는, 다양한 실시예들에 따른, 전자 장치의 화면 전환 동작의 일 예를 설명하기 위한 도면이다. 도 26은, 다양한 실시예들에 따른, 전자 장치의 동작의 예를 설명하기 위한 흐름도이다. 도 27은, 다양한 실시예들에 따른, 사용자의 인터랙션의 종류들의 예를 설명하기 위한 도면이다. 도 28은, 다양한 실시예들에 따른, 전자 장치의 동작의 예를 설명하기 위한 흐름도이다. 도 29는, 다양한 실시예들에 따른, 전자 장치의 식별되는 물체의 종류에 기반하여 시각적 컨텐트 및 청각적 컨 텐트를 제어하는 동작의 예를 설명하기 위한 도면이다. 도 30은, 다양한 실시예들에 따른, 전자 장치의 동작의 예를 설명하기 위한 흐름도이다. 도 31은, 다양한 실시예들에 따른, 전자 장치의 식별되는 물체의 종류에 기반하여 시각적 컨텐트 및 청각적 컨 텐트를 제어하는 동작의 예를 설명하기 위한 도면이다. 도 32는, 다양한 실시예들에 따른, 전자 장치의 동작의 예를 설명하기 위한 흐름도이다. 도 33은, 다양한 실시예들에 따른, 전자 장치의 사용자 인터랙션 모드와 사용자 논-인터랙션 모드 간의 전환 동 작의 예를 설명하기 위한 도면이다. 도 34는, 다양한 실시예들에 따른, 전자 장치의 동작의 예를 설명하기 위한 도면이다. 도 35는, 다양한 실시예들에 따른, 전자 장치에 의해 제공되는 컨텐트의 예를 설명하기 위한 도면이다. 도 36은, 다양한 실시예들에 따른, 전자 장치의 동작의 예를 설명하기 위한 흐름도이다. 도 37은, 다양한 실시예들에 따른, 전자 장치의 음악적 단위에 기반하여 식별되는 이벤트 발생 시점 및 시간 구 간의 예를 설명하기 위한 도면이다. 도 38a는, 다양한 실시예들에 따른, 전자 장치의 시간 구간을 가이드하기 위해 시각적 효과를 제공하는 동작의 예를 설명하기 위한 도면이다. 도 38b는, 다양한 실시예들에 따른, 전자 장치의 시간 구간을 가이드하기 위해 시각적 효과를 제공하는 동작의 예를 설명하기 위한 도면이다. 도 38c는, 다양한 실시예들에 따른, 전자 장치의 메인 캐릭터에 대한 시간 구간 별 사용자의 입력에 기반하여, 효과를 제공하는 동작의 예를 설명하기 위한 도면이다. 도 39는, 다양한 실시예들에 따른, 전자 장치의 동작의 예를 설명하기 위한 흐름도이다. 도 40은, 다양한 실시예들에 따른, 전자 장치의 메인 그래픽 오브젝트의 생성 동작의 예를 설명하기 위한 도면 이다. 도 41a는, 다양한 실시예들에 따른, 전자 장치의 모션 생성 동작의 예를 설명하기 위한 도면이다. 도 41b는, 다양한 실시예들에 따른, 전자 장치의 모션 제어 동작의 예를 설명하기 위한 도면이다. 도 42는, 다양한 실시예들에 따른, 전자 장치의 동작의 예를 설명하기 위한 흐름도이다. 도 43은, 다양한 실시예들에 따른, 전자 장치의 청각적 컨텐트의 음악적 단위에 기초하여 모션을 제공하는 동작의 예를 설명하기 위한 도면이다. 도 44는, 다양한 실시예들에 따른, 전자 장치의 동작의 예를 설명하기 위한 흐름도이다. 도 45는, 다양한 실시예들에 따른, 전자 장치의, 메인 캐릭터의 위치에 기반한 서브 오브젝트의 활성화의 예를 설명하기 위한 도면이다. 도 46은, 다양한 실시예들에 따른, 전자 장치의 동작의 예를 설명하기 위한 흐름도이다. 도 47은, 다양한 실시예들에 따른, 전자 장치의, 서브 오브젝트의 획득에 따른 오디오 소스 재생의 활성화의 예 를 설명하기 위한 도면이다. 도 48은, 다양한 실시예들에 따른, 전자 장치의 동작의 예를 설명하기 위한 흐름도이다. 도 49는, 다양한 실시예들에 따른, 전자 장치의, 메인 캐릭터의 이동에 따라서 청각적 컨텐트의 재생, 그리고 청각적 컨텐트의 역재생에 따른 메인 캐릭터의 이동의 예를 설명하기 위한 도면이다. 도 50은, 다양한 실시예들에 따른, 전자 장치의 동작의 예를 설명하기 위한 흐름도이다. 도 51은, 다양한 실시예들에 따른, 전자 장치의 동작의 예를 설명하기 위한 흐름도이다. 도 52는, 다양한 실시예들에 따른, 전자 장치 및 서버의 동작의 예를 설명하기 위한 흐름도이다. 도 53은, 다양한 실시예들에 따른, 전자 장치의 멀티 플레이 시나리오의 예를 설명하기 위한 도면이다. 도 54는, 다양한 실시예들에 따른, 전자 장의 소스풀, 입력풀, 및 복수의 트랜스 포트들을 포함하는 플레이어 (또는 어플리케이션)의 예를 설명하기 위한 도면이다. 도 55a는, 다양한 실시예들에 따른, 일 트랜스 포트의 동작의 예를 설명하기 위한 도면이다. 도 55b는, 다양한 실시예들에 따른, 일 트랜스 포트의 동작의 예를 설명하기 위한 도면이다. 도 56은, 다양한 실시예들에 따른, 전자 장치 및 서버의 동작의 예를 설명하기 위한 흐름도이다. 도 57a는, 다양한 실시예들에 따른, 전자 장치의 베이직 트랜스포트와 이벤트 트랜스포트 간의 전환 동작의 예 를 설명하기 위한 도면이다. 도 57b는, 다양한 실시예들에 따른, 전자 장치의 이벤트 트랜스포트에 기반하여 제공되는 시각적 컨텐트 상에서 의 메인 캐릭터의 이동에 따른 동작의 예를 설명하기 위한 도면이다. 도 57c는, 다양한 실시예들에 따른, 전자 장치의 베이직 트랜스포트와 이벤트 트랜스포트 간의 전환 동작의 다 른 예를 설명하기 위한 도면이다. 도 58은, 다양한 실시예들에 따른, 전자 장치 및 서버의 동작의 예를 설명하기 위한 흐름도이다. 도 59a는, 다양한 실시예들에 따른, 전자 장치의 베이직 트랜스포트와 이벤트 트랜스포트 간의 전환 동작의 예 를 설명하기 위한 도면이다. 도 59b는, 다양한 실시예들에 따른, 전자 장치의 이벤트 트랜스포트에 기반하여 제공되는 시각적 컨텐트 상에서 의 메인 캐릭터의 이동에 따른 동작의 예를 설명하기 위한 도면이다. 도 60은, 다양한 실시예들에 따른, 전자 장치 및 서버의 동작의 예를 설명하기 위한 흐름도이다. 도 61은, 다양한 실시예들에 따른, 전자 장치 및 서버의 동작의 예를 설명하기 위한 흐름도이다. 도 62a는, 다양한 실시예들에 따른, 그래픽 데이터가 제공되는 시점과 오디오 소스가 재생되는 시점의 예를 설 명하기 위한 도면이다. 도 62b는, 다양한 실시예들에 따른, 활성화 구간의 예를 설명하기 위한 도면이다. 도 63은, 다양한 실시예들에 따른, 전자 장치 및 서버의 동작의 예를 설명하기 위한 흐름도이다. 도 64는, 다양한 실시예들에 따른, 서버에 의해 교환되는 플랫폼 파일의 일 예를 설명하기 위한 도면이다. 도 65a는, 다양한 실시예들에 따른, 서버에 의해 제공되는 인터페이스의 일 예를 설명하기 위한 도면이다. 도 65b는, 다양한 실시예들에 따른, 서버에 의해 획득되는 어레이 별 정보의 예를 설명하기 위한 도면이다.도 66은, 다양한 실시예들에 따른, 전자 장치의 동작의 예를 설명하기 위한 흐름도이다. 도 67은, 다양한 실시예들에 따른, 복수의 전자 장치들(예: 전자 장치, 외부 전자 장치) 및 서버의 동작의 예를 설명하기 위한 흐름도이다. 도 68은, 다양한 실시예들에 따른, 전자 장치의 동작의 예를 설명하기 위한 흐름도이다. 도 69는, 다양한 실시예들에 따른, 플랫폼 파일의 다른 예를 설명하기 위한 도면이다. 도 70a는, 다양한 실시예들에 따른, 서버에 의해 제공되는 시각적 컨텐트의 예를 설명하기 위한 도면이다. 도 70b는, 다양한 실시예들에 따른, 서버에 의해 제공되는 시각적 컨텐트의 예를 설명하기 위한 도면이다. 도 71은, 다양한 실시예들에 따른, 서버에 의해 제공되는 메신저 기능의 예를 설명하기 위한 도면이다. 도 72는, 다양한 실시예들에 따른, 인터랙티브 음악 감상 시스템에 의해 제공 가능한, 시각적 컨텐트의 예를 설 명하기 위한 도면이다."}
