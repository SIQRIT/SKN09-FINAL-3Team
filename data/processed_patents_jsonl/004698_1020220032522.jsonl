{"patent_id": "10-2022-0032522", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0135271", "출원번호": "10-2022-0032522", "발명의 명칭": "인공지능을 이용한 단말 화면 기반 행위 상태 분석 방법", "출원인": "주식회사 비즈모델라인", "발명자": "김재형"}}
{"patent_id": "10-2022-0032522", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "적어도 하나의 단말과 통신하는 운영서버를 통해 실행되는 방법에 있어서, 캡쳐 가능한 f(f≥1)개의 화면을 구비한 g(g≥1)개의 단말을 이용하면서 주어진 행위를 행하는 대상자가 상기행위를 행하는 행위 시간 동안 기 설정된 시간 단위 별로 상기 대상자가 이용하는 적어도 하나의 화면을 기 설정된 이미지 획득 규칙에 따라 캡쳐하여 획득된 P(P≥1)개의 이미지 중 지정된 P'(P'≤P)개의 이미지와 상기P'개의 이미지를 설명하는 P'개의 메타정보의 조합을 포함하는 대상자의 행위 확인 정보를 지정된 관리자의 단말로 제공하여 상기 관리자에 의해 상기 대상자의 행위 상태를 설정한 p(1≤p≤P)개의 이미지와 p개의 메타정보및 p개의 행위 상태 정보를 포함하는 학습데이터를 지정된 인공지능모듈에 적용하여 학습시키는 제1 단계; 캡쳐 가능한 s(s≥1)개의 화면을 구비한 m(m≥1)개의 단말을 이용하여 S(S= )개의 화면을 주시 가능한 상태에서 주어진 행위를 행하는 사용자의 행위 상태를 분석하기 위해 설정된 t(t≥1)개의 행위 시간을 포함하는 전체 행위 시간을 기 설정된 시간 단위로 분할한 N(N≥2)개의 분할 시간 구간 중 현재 시점의 제n(1≤n≤N)차 분할 시간 구간에 활성화된 상태에 대응하는 적어도 하나의 화면을 기 설정된 이미지 획득 규칙에 따라 캡쳐하여 획득된 적어도 하나의 이미지를 근거로 상기 제n차 분할 시간 구간의 행위 상태 분석과 관련된 일의적이미지에 해당하는 in(1≤n≤N)(in≥1)개의 제n차 이미지와 상기 in개의 제n차 이미지를 설명하는 in개의 메타정보를확인하는 제2 단계; 및상기 확인된 in개의 제n차 이미지와 in개의 메타정보의 조합을 포함하는 사용자의 행위 확인 정보를 상기 인공지능모듈에 대입하여 상기 사용자의 행위 상태 정보를 분석하는 제3 단계;를 포함하는 인공지능을 이용한 단말 화면 기반 행위 상태 분석 방법."}
{"patent_id": "10-2022-0032522", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1항에 있어서, 대상자가 이용하는 단말이나 지정된 관리자가 이용하는 단말과 연동하여 상기 대상자가 g개의 단말을 이용하면서 행하는 주어진 행위의 범주에 대응하는 대상자의 행위 범주 정보를 등록 또는 설정받아 지정된 운영DB에 저장하는 단계를 더 포함하는 것을 특징으로 하는 인공지능을 이용한 단말 화면 기반 행위 상태 분석 방법."}
{"patent_id": "10-2022-0032522", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 2항에 있어서, 상기 행위 범주 정보는, 상기 대상자가 단말을 이용하여 업무를 수행하는 경우 상기 대상자의 업무 범주나 직무에 대응하는 정보를 포함하는 것을 특징으로 하는 인공지능을 이용한 단말 화면 기반 행위 상태 분석 방법."}
{"patent_id": "10-2022-0032522", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 2항에 있어서, 상기 행위 범주 정보는, 상기 대상자가 단말을 이용하여 비대면 수업에 참가는 경우 상기 대상자가 참가하는 수업 범주나 과목에 대응하는 정보를 포함하는 것을 특징으로 하는 인공지능을 이용한 단말 화면 기반 행위 상태 분석 방법."}
{"patent_id": "10-2022-0032522", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "공개특허 10-2023-0135271-3-제 2항에 있어서, 상기 행위 범주 정보는, 상기 대상자가 단말을 이용하여 학습을 행하는 경우 상기 대상자가 학습할 학습 범주나 과목에 대응하는 정보를포함하는 것을 특징으로 하는 인공지능을 이용한 단말 화면 기반 행위 상태 분석 방법."}
{"patent_id": "10-2022-0032522", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제 1항에 있어서, 상기 행위는,대상자가 적어도 하나의 단말을 이용하여 업무를 행하는 것, 대상자가 적어도 하나의 단말을 이용하여 비대면 수업에 참가하는 것, 대상자가 적어도 하나의 단말을 이용하여 비대면 학습을 행하는 것 중 적어도 하나를 포함하는 것을 특징으로하는 인공지능을 이용한 단말 화면 기반 행위 상태 분석 방법."}
{"patent_id": "10-2022-0032522", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제 1항에 있어서, 상기 이미지 획득 규칙은, 화면을 캡쳐할 시간 구간에 활성화된 상태를 포함하는 e(1≤e≤S)개의 화면으로부터 상기 시간 구간의 지정된캡쳐 시점에 e개의 대표 이미지를 캡쳐하여 획득하는 규칙을 포함하는 것을 특징으로 하는 인공지능을 이용한단말 화면 기반 행위 상태 분석 방법."}
{"patent_id": "10-2022-0032522", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제 1항에 있어서, 상기 이미지 획득 규칙은, 화면을 캡쳐할 시간 구간에 활성화된 상태를 포함하는 e(1≤e≤S)개의 화면 중 적어도 하나의 지정된 액션이 인식된 k(1≤k≤e)개의 화면을 통해 기 설정된 R(R≥1)개의 액션 중 지정된 r(1≤r≤R)개의 액션이 인식되는 경우에 상기 k개의 화면으로부터 지정된 액션이 인식된 액션 인식 시점 별로 r개의 특징 이미지를 캡쳐하여 획득하는 규칙을 포함하는 것을 특징으로 하는 인공지능을 이용한 단말 화면 기반 행위 상태 분석 방법."}
{"patent_id": "10-2022-0032522", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제 1항에 있어서, 상기 이미지 획득 규칙은, 화면을 캡쳐할 시간 구간에 활성화된 상태를 포함하는 e(1≤e≤S)개의 화면으로부터 상기 시간 구간의 지정된캡쳐 시점에 e개의 대표 이미지를 캡쳐하여 획득하는 규칙과,상기 활성하된 e개의 화면 중 적어도 하나의 지정된 액션이 인식된 k(1≤k≤e)개의 화면을 통해 기 설정된 R(R≥1)개의 액션 중 지정된 r(1≤r≤R)개의 액션이 인식되는 경우에 상기 k개의 화면으로부터 지정된 액션이 인식된 액션 인식 시점 별로 r개의 특징 이미지를 캡쳐하여 획득하는 규칙의 조합을 포함하는 것을 특징으로 하는인공지능을 이용한 단말 화면 기반 행위 상태 분석 방법."}
{"patent_id": "10-2022-0032522", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제 1항에 있어서, 상기 P'개의 이미지는,상기 P개의 이미지 중 대상자의 행위 상태 분석과 관련된 일의적 이미지를 포함하는 것을 특징으로 하는 인공지능을 이용한 단말 화면 기반 행위 상태 분석 방법.공개특허 10-2023-0135271-4-청구항 11 제 1항에 있어서, 상기 P'개의 메타정보는, 상기 대상자가 이용하는 적어도 하나의 화면을 기 설정된 이미지 획득 규칙에 따라 캡쳐하여 획득하는 과정과연동하여 생성된 화면 메타정보를 포함하는 것을 특징으로 하는 인공지능을 이용한 단말 화면 기반 행위 상태분석 방법."}
{"patent_id": "10-2022-0032522", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제 1항에 있어서, 상기 제1 단계는, 캡쳐 가능한 f(f≥1)개의 화면을 구비한 g(g≥1)개의 단말을 이용하면서 주어진 행위를 행하는 대상자가 상기행위를 행하도록 설정된 b(b≥1)개의 행위 시간을 포함하는 전체 행위 시간을 기 설정된 시간 단위로 분할한D(D≥2)개의 분할 시간 구간 중 적어도 하나의 화면이 활성화된 상태를 포함하는 적어도 하나의 분할 시간 구간별로 상기 활성화된 상태에 대응하는 적어도 하나의 화면을 기 설정된 이미지 획득 규칙에 따라 캡쳐하여 획득된 P(P≥1)개의 이미지 중 지정된 P'(P'≤P)개의 이미지와 상기 P'개의 이미지를 설명하는 P'개의 메타정보를저장하는 제1-1 단계; 상기 저장된 P'개의 이미지와 P'개의 메타정보의 조합을 포함하는 대상자의 행위 확인 정보를 지정된 관리자의단말로 제공하여 상기 관리자에 의해 상기 대상자의 행위 확인 정보를 근거로 상기 대상자의 행위 상태를 판단하여 설정한 p(1≤p≤P)개의 행위 상태 정보를 수신하고 상기 p개의 행위 상태 정보에 대응하는 p개의 이미지와p개의 메타정보를 확인하는 제1-2 단계; 및상기 확인된 p개의 이미지와 p개의 메타정보 및 p개의 행위 상태 정보를 포함하여 구성된 학습데이터를 지정된인공지능모듈에 적용하여 학습시키는 제1-3 단계;를 포함하는 것을 특징으로 하는 인공지능을 이용한 단말 화면기반 행위 상태 분석 방법."}
{"patent_id": "10-2022-0032522", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제 12항에 있어서, 상기 대상자의 행위 확인 정보는, 상기 대상자가 g개의 단말을 이용하면서 행하는 주어진 행위의 범주에 대응하는 대상자의 행위 범주 정보를 더포함하는 것을 특징으로 하는 인공지능을 이용한 단말 화면 기반 행위 상태 분석 방법."}
{"patent_id": "10-2022-0032522", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제 12항에 있어서, 상기 학습데이터는. 상기 대상자가 g개의 단말을 이용하면서 행하는 주어진 행위의 범주에 대응하는 대상자의 행위 범주 정보를 더포함하는 것을 특징으로 하는 인공지능을 이용한 단말 화면 기반 행위 상태 분석 방법."}
{"patent_id": "10-2022-0032522", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제 1항에 있어서, 사용자가 이용하는 단말이나 지정된 관리자가 이용하는 단말과 연동하여 상기 사용자가 m개의 단말을 이용하면서 행하는 주어진 행위의 범주에 대응하는 사용자의 행위 범주 정보를 등록 또는 설정받아 지정된 운영DB에 저장하는 단계를 더 포함하는 것을 특징으로 하는 인공지능을 이용한 단말 화면 기반 행위 상태 분석 방법."}
{"patent_id": "10-2022-0032522", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "공개특허 10-2023-0135271-5-제 1항에 있어서, 상기 S개의 화면은, 사용자가 주어진 행위를 행하기 위해 이용하도록 설정된 단말의 화면을 포함하는 것을 특징으로 하는 인공지능을 이용한 단말 화면 기반 행위 상태 분석 방법."}
{"patent_id": "10-2022-0032522", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제 16항에 있어서, 상기 S개의 화면은, 사용자가 주어진 행위를 행하기 위해 이용하도록 설정된 단말의 화면 외에 사용자의 행위 시간 동안 사용자가이용 가능한 단말이나 사용자가 휴대하거나 소지한 단말의 화면을 더 포함하는 것을 특징으로 하는 인공지능을이용한 단말 화면 기반 행위 상태 분석 방법."}
{"patent_id": "10-2022-0032522", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제 1항에 있어서, 상기 일의적 이미지는, 제(n-1)((n-1)≥1)차 분할 시간 구간에 대응하는 이미지와 다른 이미지, 화면의 맨위 표시된 애플리케이션이 사용자의 지정된 행위 범주와 관련된 특정 애플리케이션을 포함하는이미지, 화면의 맨위 표시된 인터페이스 화면이 사용자의 지정된 행위 범주와 관련된 인터페이스 화면을 포함하는 이미지, 지정된 액션을 근거로 획득된 이미지,사용자의 지정된 행위 범주와 관련된 워크플로(workflow)에 대응하는 이미지 중 적어도 하나의 이미지를 포함하는 것을 특징으로 하는 인공지능을 이용한 단말 화면 기반 행위 상태 분석 방법."}
{"patent_id": "10-2022-0032522", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제 1항에 있어서, 상기 in개의 메타정보는, 상기 제n차 분할 시간 구간에 활성화된 상태에 대응하는 적어도 하나의 화면을 캡쳐하여 이미지를 획득하는 과정과 연동하여 생성된 화면 메타정보를 근거로 생성되는 것을 특징으로 하는 인공지능을 이용한 단말 화면 기반행위 상태 분석 방법."}
{"patent_id": "10-2022-0032522", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제 19항에 있어서, 상기 화면 메타정보는, 상기 이미지를 캡쳐한 시점을 식별 가능한 시점 식별 정보, 상기 이미지를 캡쳐한 화면을 식별 가능한 화면 식별 정보, 상기 이미지를 캡쳐한 단말을 식별 가능한 단말 식별 정보, 지정된 액션을 근거로 이미지를 캡쳐한 경우 상기 이미지에 대응하는 액션을 분류하는 액션 분류 정보, 지정된 액션을 근거로 캡쳐된 이미지에 대응하는 액션을 확인 가능한 액션 확인 정보, 상기 화면의 맨위 표시된 애플리케이션을 식별하는 애플리케이션 식별 정보, 상기 화면의 맨위 표시된 애플리케이션의 인터페이스 화면을 식별하는 인터페이스 식별 정보, 상기 화면의 맨위 표시된 애플리케이션을 통해 표시된 컨텐츠를 식별하는 컨텐츠 식별 정보, 공개특허 10-2023-0135271-6-상기 화면의 맨위 표시된 애플리케이션을 통해 수행되는 적어도 하나의 워크플로를 설명하는 워크플로 정보, 상기 화면의 맨위 표시된 브라우져에 로딩된 페이지를 식별하는 애플리케이션 식별 정보, 상기 화면의 맨위 표시된 브라우져에 로딩된 페이지의 인터페이스 화면을 식별하는 인터페이스 식별 정보, 상기 화면의 맨위 표시된 브라우져에 로딩된 페이지를 통해 표시된 컨텐츠를 식별하는 컨텐츠 식별 정보, 상기 화면의 맨위 표시된 브라우져에 로딩된 페이지를 통해 수행되는 적어도 하나의 워크플로를 설명하는 워크플로 정보 중 적어도 하나의 정보를 포함하는 것을 특징으로 하는 인공지능을 이용한 단말 화면 기반 행위 상태분석 방법."}
{"patent_id": "10-2022-0032522", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_21", "content": "제 20항에 있어서, 상기 화면 메타정보는, 상기 화면의 맨위 아래 표시되거나 감춤된 적어도 하나의 애플리케이션을 식별하는 애플리케이션 식별 정보, 상기 화면의 맨위 아래 표시되거나 감춤된 적어도 하나의 애플리케이션의 인터페이스 화면을 식별하는 인터페이스 식별 정보, 상기 화면의 맨위 아래 표시되거나 감춤된 적어도 하나의 애플리케이션을 통해 표시된 컨텐츠를 식별하는 컨텐츠 식별 정보, 상기 화면의 맨위 아래 표시되거나 감춤된 적어도 하나의 애플리케이션을 통해 수행되는 적어도 하나의 워크플로를 설명하는 워크플로 정보, 상기 화면의 맨위 아래 표시되거나 감춤된 적어도 하나의 브라우져에 로딩된 적어도 하나의 페이지를 식별하는애플리케이션 식별 정보, 상기 화면의 맨위 아래 표시되거나 감춤된 적어도 하나의 브라우져에 적어도 하나의 로딩된 페이지의 인터페이스 화면을 식별하는 인터페이스 식별 정보, 상기 화면의 맨위 아래 표시되거나 감춤된 적어도 하나의 브라우져에 로딩된 적어도 하나의 페이지를 통해 표시된 컨텐츠를 식별하는 컨텐츠 식별 정보, 상기 화면의 맨위 아래 표시되거나 감춤된 적어도 하나의 브라우져에 로딩된 적어도 하나의 페이지를 통해 수행되는 적어도 하나의 워크플로를 설명하는 워크플로 중 적어도 하나의 정보를 더 포함하는 것을 특징으로 하는인공지능을 이용한 단말 화면 기반 행위 상태 분석 방법."}
{"patent_id": "10-2022-0032522", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_22", "content": "제 1항에 있어서, 상기 제2 단계는, 사용자가 이용하는 m개의 단말 중 제n차 분할 시간 구간에 활성화된 상태를 대응하는 화면을 구비한 m'(1≤m'≤m)개의 단말의 프로그램으로부터 상기 제n차 분할 시간 구간의 지정된 캡쳐 시점에 상기 활성화된 상태를 대응하는 en(1≤n≤N)(1≤en≤S)개의 화면을 캡쳐하여 획득된 en개의 대표 이미지를 수신하는 절차를 수행하는 수신단계;및상기 수신된 en개의 대표 이미지를 근거로 상기 제n차 분할 시간 구간의 행위 상태 분석과 관련된 일의적 이미지에 해당하는 in(1≤in≤en)개의 제n차 이미지를 확인하는 확인단계;를 포함하는 것을 특징으로 하는 인공지능을이용한 단말 화면 기반 행위 상태 분석 방법."}
{"patent_id": "10-2022-0032522", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_23", "content": "제 22항에 있어서, 공개특허 10-2023-0135271-7-상기 수신단계는, 상기 en개의 대표 이미지를 설명하는 en개의 화면 메타정보를 수신하는 단계를 더 포함하며,상기 in개의 메타정보는, 상기 en개의 화면 메타정보를 근거로 확인되는 것을 특징으로 하는 인공지능을 이용한단말 화면 기반 행위 상태 분석 방법."}
{"patent_id": "10-2022-0032522", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_24", "content": "제 1항에 있어서, 상기 제2 단계는, 사용자가 이용하는 m개의 단말 중 제n차 분할 시간 구간에 활성화된 상태를 대응하는 화면을 구비한 m'(1≤m'≤m)개의 단말의 프로그램으로부터 상기 제n차 분할 시간 구간에 활성화된 상태를 대응하는 en(1≤n≤N)(1≤en≤S)개의 화면 별로 기 설정된 R(R≥1)개의 액션 중 지정된 액션에 대응하는 화면을 인식하는 절차를 수행하여 적어도하나의 지정된 액션이 인식된 kn(1≤n≤N)(1≤kn≤en)개의 화면을 지정된 액션 인식 시점 별로 캡쳐하여 획득된 rn(1≤n≤N)(1≤rn≤R, rn≥kn)개의 특징 이미지를 수신하는 절차를 수행하는 수신단계; 및상기 수신된 rn개의 특징 이미지를 근거로 상기 제n차 분할 시간 구간의 행위 상태 분석과 관련된 일의적 이미지에 해당하는 in(1≤in≤rn)개의 제n차 이미지를 확인하는 확인단계;를 포함하는 것을 특징으로 하는 인공지능을이용한 단말 화면 기반 행위 상태 분석 방법."}
{"patent_id": "10-2022-0032522", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_25", "content": "제 24항에 있어서, 상기 R개의 액션은, 사용자의 지정된 행위 범주와 관련된 특정 애플리케이션을 구동하는 액션, 사용자의 지정된 행위 범주와 관련된 특정 애플리케이션의 지정된 인터페이스 화면을 호출하거나 조작하는액션, 페이지를 로딩 가능한 브라우져를 구동하는 액션, 브라우져를 통해 사용자의 지정된 행위 범주와 관련된 페이지를 로딩하거나 조작하는 액션, 특정 애플리케이션이나 브라우져를 통해 사용자의 지정된 행위 범주와 관련된 컨텐츠를 로딩하거나 조작하는 액션, 특정 애플리케이션을 통해 사용자의 지정된 행위 범주와 관련된 워크플로(workflow)에 대응하는 인터페이스 화면을 호출하거나 조작하는 액션, 브라우져를 통해 사용자의 지정된 행위 범주와 관련된 워크플로에 대응하는 페이지를 로딩하거나 조작하는 액션중 적어도 하나의 액션을 포함하는 것을 특징으로 하는 인공지능을 이용한 단말 화면 기반 행위 상태 분석방법."}
{"patent_id": "10-2022-0032522", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_26", "content": "제 25항에 있어서, 상기 R개의 액션은, 사용자의 지정된 행위 범주와 무관한 애플리케이션을 구동하는 액션, 사용자의 지정된 행위 범주와 무관한 애플리케이션을 조작하는 액션, 브라우져를 통해 사용자의 지정된 행위 범주와 무관한 페이지를 로딩하거나 조작하는 액션, 애플리케이션이나 브라우져를 통해 사용자의 지정된 행위 범주와 무관한 컨텐츠를 로딩하거나 조작하는 액션, 애플리케이션이나 브라우져를 통해 사용자의 지정된 행위 범주나 워크플로와 무관한 서버에 접속하거나 상기 사용자의 지정된 행위 범주나 워크플로와 무관한 서버로부터 파일이나 데이터를 다운로드하거나 상기 사용자의 지공개특허 10-2023-0135271-8-정된 행위 범주나 워크플로와 무관한 서버로 파일이나 데이터를 전송하는 액션, 단말의 외부 저장장치에 파일이나 데이터를 저장하는 액션 중 적어도 하나의 액션을 더 포함하는 것을 특징으로하는 인공지능을 이용한 단말 화면 기반 행위 상태 분석 방법."}
{"patent_id": "10-2022-0032522", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_27", "content": "제 24항에 있어서, 상기 수신단계는, 상기 rn개의 특징 이미지를 설명하는 rn개의 화면 메타정보를 수신하는 단계를 더 포함하며,상기 in개의 메타정보는, 상기 rn개의 화면 메타정보를 근거로 확인되는 것을 특징으로 하는 인공지능을 이용한단말 화면 기반 행위 상태 분석 방법."}
{"patent_id": "10-2022-0032522", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_28", "content": "제 1항에 있어서, 상기 제2 단계는, 사용자가 이용하는 m개의 단말 중 제n차 분할 시간 구간에 활성화된 상태를 대응하는 화면을 구비한 m'(1≤m'≤m)개의 단말의 프로그램으로부터 상기 제n차 분할 시간 구간의 지정된 캡쳐 시점에 상기 활성화된 상태를 대응하는 en(1≤n≤N)(1≤en≤S)개의 화면을 캡쳐하여 획득된 en개의 대표 이미지를 수신하는 절차를 수행하고, 상기 제n차 분할 시간 구간에 활성화된 상태를 대응하는 en개의 화면 별로 기 설정된 R(R≥1)개의 액션 중 지정된 액션에 대응하는 화면을 인식하는 절차를 수행하여 적어도 하나의 지정된 액션이 인식된 kn(1≤n≤N)(1≤kn≤en)개의 화면을 지정된 액션 인식 시점 별로 캡쳐하여 획득된 rn(1≤n≤N)(1≤rn≤R, rn≥kn)개의 특징 이미지를 수신하는 절차를 수행하는 수신단계; 및상기 수신된 en개의 대표 이미지와 rn개의 특징 이미지를 근거로 상기 제n차 분할 시간 구간의 행위 상태 분석과관련된 일의적 이미지에 해당하는 in(1≤in≤(en+rn))개의 제n차 이미지를 확인하는 확인단계;를 포함하는 것을특징으로 하는 인공지능을 이용한 단말 화면 기반 행위 상태 분석 방법."}
{"patent_id": "10-2022-0032522", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_29", "content": "제 28항에 있어서, 상기 수신단계는, 상기 en개의 대표 이미지를 설명하는 en개의 화면 메타정보와 상기 rn개의 특징 이미지를 설명하는 개의 rn개의 화면 메타정보를 수신하는 단계를 더 포함하며,상기 in개의 메타정보는, 상기 en개의 화면 메타정보와 rn개의 화면 메타정보 중 적어도 하나의 화면 메타정보를근거로 확인되는 것을 특징으로 하는 인공지능을 이용한 단말 화면 기반 행위 상태 분석 방법."}
{"patent_id": "10-2022-0032522", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_30", "content": "제 1항에 있어서, 상기 사용자의 행위 확인 정보는, 상기 사용자가 m개의 단말을 이용하면서 행하는 주어진 행위의 범주에 대응하는 사용자의 행위 범주 정보를 더포함하는 것을 특징으로 하는 인공지능을 이용한 단말 화면 기반 행위 상태 분석 방법."}
{"patent_id": "10-2022-0032522", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_31", "content": "공개특허 10-2023-0135271-9-제 30항에 있어서, 상기 제3 단계는, 상기 in개의 제n차 이미지와 in개의 메타정보 및 상기 사용자의 행위 범주 정보를 포함하는 사용자의 행위 확인정보를 상기 인공지능모듈에 대입하여 상기 사용자의 행위 상태 정보를 분석하는 단계를 포함하는 것을 특징으로 하는 인공지능을 이용한 단말 화면 기반 행위 상태 분석 방법."}
{"patent_id": "10-2022-0032522", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_32", "content": "제 1항에 있어서, 상기 사용자의 행위 확인 정보와 상기 인공지능모듈을 통해 분석된 사용자의 행위 상태 정보를 상기 사용자가이용하는 단말이나 지정된 관리자가 이용하는 단말로 제공하여 상기 사용자나 관리자에 의해 수정된 적어도 하나의 행위 상태 정보를 수신하는 단계; 및적어도 하나의 행위 상태 정보가 수정된 경우, 상기 수정된 사용자의 행위 확인 정보와 행위 상태 정보를 포함하는 학습데이터를 상기 인공지능모듈에 적용하여 학습시키는 단계;를 더 포함하는 것을 특징으로 하는 인공지능을 이용한 단말 화면 기반 행위 상태 분석 방법."}
{"patent_id": "10-2022-0032522", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 인공지능을 이용한 단말 화면 기반 행위 상태 분석 방법에 관한 것으로서, 본 발명에 따른 적어도 하 나의 단말과 통신하는 운영서버를 통해 실행되는 인공지능을 이용한 단말 화면 기반 행위 상태 분석 방법은, 캡 쳐 가능한 f(f≥1)개의 화면을 구비한 g(g≥1)개의 단말을 이용하면서 주어진 행위를 행하는 대상자가 상기 행위 (뒷면에 계속)"}
{"patent_id": "10-2022-0032522", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 인공지능을 이용한 단말 화면 기반 행위 상태 분석 방법에 관한 것으로, 캡쳐 가능한 화면을 구비한 단말을 이용하면서 주어진 행위를 행하는 대상자가 상기 행위를 행하는 행위 시간 동안 기 설정된 시간 단위 별 로 상기 대상자가 이용하는 적어도 하나의 화면을 기 설정된 이미지 획득 규칙에 따라 캡쳐하여 획득된 이미지 와 상기 이미지를 설명하는 메타정보의 조합을 포함하는 대상자의 행위 확인 정보를 지정된 관리자의 단말로 제 공하여 상기 관리자에 의해 상기 대상자의 행위 상태를 설정한 이미지와 메타정보 및 행위 상태 정보를 포함하 는 학습데이터를 지정된 인공지능모듈에 적용하여 학습시킨 이후, 캡쳐 가능한 화면을 구비한 단말을 이용하여 화면을 주시 가능한 상태에서 주어진 행위를 행하는 사용자의 행위 상태를 분석하기 위해 설정된 행위 시간을 포함하는 전체 행위 시간을 기 설정된 시간 단위로 분할한 분할 시간 구간 중 현재 시점의 분할 시간 구간에 활 성화된 상태에 대응하는 적어도 하나의 화면을 기 설정된 이미지 획득 규칙에 따라 캡쳐하여 획득된 적어도 하 나의 이미지를 근거로 상기 분할 시간 구간의 행위 상태 분석과 관련된 일의적 이미지에 해당하는 이미지와 상 기 이미지를 설명하는 메타정보를 확인하고, 상기 확인된 이미지와 메타정보의 조합을 포함하는 사용자의 행위 확인 정보를 상기 인공지능모듈에 대입하여 상기 사용자의 행위 상태 정보를 분석하는 방법에 관한 것이다."}
{"patent_id": "10-2022-0032522", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "컴퓨터 기술의 발달로 다양한 직종에서 컴퓨터(PC나 모바일 등)로 업무를 보는 경우가 많아졌다. 하지만 컴퓨터 업무라는 것이 보통 개인이 사용하는 경우가 대다수 이기 때문에 실제 업무를 하고 있는지 아님 업무 외 다른 일을 하고 있는지 확인하기가 쉽지 않았다. 대한민국 특허공개공보 제10-2015-0000012호는 화면 캡쳐 기능을 이용한 직원 관리 시스템에 관한 것으로, 직원 단말의 모니터 화면을 캡쳐하고, 이를 기반으로 직원이 어떠한 작업을 하고 있는 지를 보다 손쉽고 정확하게 파 악할 수 있도록 하는 기술이 기재되어 있다. 그러나, 캡쳐한 화면을 기반으로 어떤 직원이 어떤 작업을 하는지를 관리자가 직접 모니터링 해야 하는 번거로 움이 있었고, 관리자가 부족하거나 부재중인 경우, 또는 모니터링 할 화면이 많은 경우 직원의 작업을 정확하게"}
{"patent_id": "10-2022-0032522", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 2, "content": "파악하기 어려운 문제점이 있었다.발명의 내용"}
{"patent_id": "10-2022-0032522", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명의 목적은, 캡쳐 가능한 화면을 구비한 단말을 이용하면서 주어진 행위를 행하는 대상자가 상기 행위를 행하는 행위 시간 동안 기 설정된 시간 단위 별로 상기 대상자가 이용하는 적어도 하나의 화면을 기 설정된 이 미지 획득 규칙에 따라 캡쳐하여 획득된 이미지와 상기 이미지를 설명하는 메타정보의 조합을 포함하는 대상자 의 행위 확인 정보를 지정된 관리자의 단말로 제공하여 상기 관리자에 의해 상기 대상자의 행위 상태를 설정한 이미지와 메타정보 및 행위 상태 정보를 포함하는 학습데이터를 지정된 인공지능모듈에 적용하여 학습시킨 이후, 캡쳐 가능한 화면을 구비한 단말을 이용하여 화면을 주시 가능한 상태에서 주어진 행위를 행하는 사용자 의 행위 상태를 분석하기 위해 설정된 행위 시간을 포함하는 전체 행위 시간을 기 설정된 시간 단위로 분할한 분할 시간 구간 중 현재 시점의 분할 시간 구간에 활성화된 상태에 대응하는 적어도 하나의 화면을 기 설정된 이미지 획득 규칙에 따라 캡쳐하여 획득된 적어도 하나의 이미지를 근거로 상기 분할 시간 구간의 행위 상태 분 석과 관련된 일의적 이미지에 해당하는 이미지와 상기 이미지를 설명하는 메타정보를 확인하고, 상기 확인된 이 미지와 메타정보의 조합을 포함하는 사용자의 행위 확인 정보를 상기 인공지능모듈에 대입하여 상기 사용자의 행위 상태 정보를 분석하는 인공지능을 이용한 단말 화면 기반 행위 상태 분석 방법을 제공함에 있다."}
{"patent_id": "10-2022-0032522", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명에 따른 적어도 하나의 단말과 통신하는 운영서버를 통해 실행되는 인공지능을 이용한 단말 화면 기반 행위 상태 분석 방법은, 캡쳐 가능한 f(f≥1)개의 화면을 구비한 g(g≥1)개의 단말을 이용하면서 주어진 행위를 행하는 대상자가 상기 행위를 행하는 행위 시간 동안 기 설정된 시간 단위 별로 상기 대상자가 이용하는 적어도 하나의 화면을 기 설정된 이미지 획득 규칙에 따라 캡쳐하여 획득된 P(P≥1)개의 이미지 중 지정된 P'(P'≤P)개 의 이미지와 상기 P'개의 이미지를 설명하는 P'개의 메타정보의 조합을 포함하는 대상자의 행위 확인 정보를 지 정된 관리자의 단말로 제공하여 상기 관리자에 의해 상기 대상자의 행위 상태를 설정한 p(1≤p≤P)개의 이미지 와 p개의 메타정보 및 p개의 행위 상태 정보를 포함하는 학습데이터를 지정된 인공지능모듈에 적용하여 학습시 키는 제1 단계와, 캡쳐 가능한 s(s≥1)개의 화면을 구비한 m(m≥1)개의 단말을 이용하여 S(S= ) 개의 화면을 주시 가능한 상태에서 주어진 행위를 행하는 사용자의 행위 상태를 분석하기 위해 설정된 t(t≥1)개의 행위 시간을 포함하는 전체 행위 시간을 기 설정된 시간 단위로 분할한 N(N≥2)개의 분할 시간 구간 중 현재 시 점의 제n(1≤n≤N)차 분할 시간 구간에 활성화된 상태에 대응하는 적어도 하나의 화면을 기 설정된 이미지 획득 규칙에 따라 캡쳐하여 획득된 적어도 하나의 이미지를 근거로 상기 제n차 분할 시간 구간의 행위 상태 분석과 관련된 일의적 이미지에 해당하는 in(1≤n≤N)(in≥1)개의 제n차 이미지와 상기 in개의 제n차 이미지를 설명하는 in 개의 메타정보를 확인하는 제2 단계와, 상기 확인된 in개의 제n차 이미지와 in개의 메타정보의 조합을 포함하는 사용자의 행위 확인 정보를 상기 인공지능모듈에 대입하여 상기 사용자의 행위 상태 정보를 분석하는 제3 단계 를 포함할 수 있다. 본 발명에 따르면, 대상자가 이용하는 단말이나 지정된 관리자가 이용하는 단말과 연동하여 상기 대상자가 g개 의 단말을 이용하면서 행하는 주어진 행위의 범주에 대응하는 대상자의 행위 범주 정보를 등록 또는 설정받아 지정된 운영DB에 저장하는 단계를 더 포함할 수 있다. 본 발명에 따르면, 상기 행위 범주 정보는, 상기 대상자가 단말을 이용하여 업무를 수행하는 경우 상기 대상자 의 업무 범주나 직무에 대응하는 정보를 포함할 수 있다. 본 발명에 따르면, 상기 행위 범주 정보는, 상기 대상자가 단말을 이용하여 비대면 수업에 참가는 경우 상기 대 상자가 참가하는 수업 범주나 과목에 대응하는 정보를 포함할 수 있다.본 발명에 따르면, 상기 행위 범주 정보는, 상기 대상자가 단말을 이용하여 학습을 행하는 경우 상기 대상자가 학습할 학습 범주나 과목에 대응하는 정보를 포함할 수 있다. 본 발명에 따르면, 상기 행위는, 대상자가 적어도 하나의 단말을 이용하여 업무를 행하는 것, 대상자가 적어도 하나의 단말을 이용하여 비대면 수업에 참가하는 것, 대상자가 적어도 하나의 단말을 이용하여 비대면 학습을 행하는 것 중 적어도 하나를 포함할 수 있다. 본 발명에 따르면, 상기 이미지 획득 규칙은, 화면을 캡쳐할 시간 구간에 활성화된 상태를 포함하는 e(1≤e≤ S)개의 화면으로부터 상기 시간 구간의 지정된 캡쳐 시점에 e개의 대표 이미지를 캡쳐하여 획득하는 규칙을 포 함할 수 있다. 본 발명에 따르면, 상기 이미지 획득 규칙은, 화면을 캡쳐할 시간 구간에 활성화된 상태를 포함하는 e(1≤e≤ S)개의 화면 중 적어도 하나의 지정된 액션이 인식된 k(1≤k≤e)개의 화면을 통해 기 설정된 R(R≥1)개의 액션 중 지정된 r(1≤r≤R)개의 액션이 인식되는 경우에 상기 k개의 화면으로부터 지정된 액션이 인식된 액션 인식 시점 별로 r개의 특징 이미지를 캡쳐하여 획득하는 규칙을 포함할 수 있다. 본 발명에 따르면, 상기 이미지 획득 규칙은, 화면을 캡쳐할 시간 구간에 활성화된 상태를 포함하는 e(1≤e≤ S)개의 화면으로부터 상기 시간 구간의 지정된 캡쳐 시점에 e개의 대표 이미지를 캡쳐하여 획득하는 규칙과, 상 기 활성하된 e개의 화면 중 적어도 하나의 지정된 액션이 인식된 k(1≤k≤e)개의 화면을 통해 기 설정된 R(R≥ 1)개의 액션 중 지정된 r(1≤r≤R)개의 액션이 인식되는 경우에 상기 k개의 화면으로부터 지정된 액션이 인식된 액션 인식 시점 별로 r개의 특징 이미지를 캡쳐하여 획득하는 규칙의 조합을 포함할 수 있다. 본 발명에 따르면, 상기 P'개의 이미지는, 상기 P개의 이미지 중 대상자의 행위 상태 분석과 관련된 일의적 이 미지를 포함할 수 있다. 본 발명에 따르면, 상기 P'개의 메타정보는, 상기 대상자가 이용하는 적어도 하나의 화면을 기 설정된 이미지 획득 규칙에 따라 캡쳐하여 획득하는 과정과 연동하여 생성된 화면 메타정보를 포함할 수 있다. 본 발명에 따르면, 상기 제1 단계는, 캡쳐 가능한 f(f≥1)개의 화면을 구비한 g(g≥1)개의 단말을 이용하면서 주어진 행위를 행하는 대상자가 상기 행위를 행하도록 설정된 b(b≥1)개의 행위 시간을 포함하는 전체 행위 시 간을 기 설정된 시간 단위로 분할한 D(D≥2)개의 분할 시간 구간 중 적어도 하나의 화면이 활성화된 상태를 포 함하는 적어도 하나의 분할 시간 구간 별로 상기 활성화된 상태에 대응하는 적어도 하나의 화면을 기 설정된 이 미지 획득 규칙에 따라 캡쳐하여 획득된 P(P≥1)개의 이미지 중 지정된 P'(P'≤P)개의 이미지와 상기 P'개의 이 미지를 설명하는 P'개의 메타정보를 저장하는 제1-1 단계와, 상기 저장된 P'개의 이미지와 P'개의 메타정보의 조합을 포함하는 대상자의 행위 확인 정보를 지정된 관리자의 단말로 제공하여 상기 관리자에 의해 상기 대상자 의 행위 확인 정보를 근거로 상기 대상자의 행위 상태를 판단하여 설정한 p(1≤p≤P)개의 행위 상태 정보를 수 신하고 상기 p개의 행위 상태 정보에 대응하는 p개의 이미지와 p개의 메타정보를 확인하는 제1-2 단계와, 상기 확인된 p개의 이미지와 p개의 메타정보 및 p개의 행위 상태 정보를 포함하여 구성된 학습데이터를 지정된 인공 지능모듈에 적용하여 학습시키는 제1-3 단계를 포함할 수 있다. 본 발명에 따르면, 상기 대상자의 행위 확인 정보는, 상기 대상자가 g개의 단말을 이용하면서 행하는 주어진 행 위의 범주에 대응하는 대상자의 행위 범주 정보를 더 포함할 수 있다.본 발명에 따르면, 상기 학습데이터는. 상기 대상자가 g개의 단말을 이용하면서 행하는 주어진 행위의 범주에 대응하는 대상자의 행위 범주 정보를 더 포함할 수 있다. 본 발명에 따르면, 사용자가 이용하는 단말이나 지정된 관리자가 이용하는 단말과 연동하여 상기 사용자가 m개 의 단말을 이용하면서 행하는 주어진 행위의 범주에 대응하는 사용자의 행위 범주 정보를 등록 또는 설정받아 지정된 운영DB에 저장하는 단계를 더 포함할 수 있다. 본 발명에 따르면, 상기 S개의 화면은, 사용자가 주어진 행위를 행하기 위해 이용하도록 설정된 단말의 화면을 포함할 수 있다. 본 발명에 따르면, 상기 S개의 화면은, 사용자가 주어진 행위를 행하기 위해 이용하도록 설정된 단말의 화면 외 에 사용자의 행위 시간 동안 사용자가 이용 가능한 단말이나 사용자가 휴대하거나 소지한 단말의 화면을 더 포 함할 수 있다. 본 발명에 따르면, 상기 일의적 이미지는, 제(n-1)((n-1)≥1)차 분할 시간 구간에 대응하는 이미지와 다른 이미 지, 화면의 맨위 표시된 애플리케이션이 사용자의 지정된 행위 범주와 관련된 특정 애플리케이션을 포함하는 이 미지, 화면의 맨위 표시된 인터페이스 화면이 사용자의 지정된 행위 범주와 관련된 인터페이스 화면을 포함하는 이미지, 지정된 액션을 근거로 획득된 이미지, 사용자의 지정된 행위 범주와 관련된 워크플로(workflow)에 대응 하는 이미지 중 적어도 하나의 이미지를 포함할 수 있다. 본 발명에 따르면, 상기 in개의 메타정보는, 상기 제n차 분할 시간 구간에 활성화된 상태에 대응하는 적어도 하 나의 화면을 캡쳐하여 이미지를 획득하는 과정과 연동하여 생성된 화면 메타정보를 근거로 생성될 수 있다. 본 발명에 따르면, 상기 화면 메타정보는, 상기 이미지를 캡쳐한 시점을 식별 가능한 시점 식별 정보, 상기 이 미지를 캡쳐한 화면을 식별 가능한 화면 식별 정보, 상기 이미지를 캡쳐한 단말을 식별 가능한 단말 식별 정보, 지정된 액션을 근거로 이미지를 캡쳐한 경우 상기 이미지에 대응하는 액션을 분류하는 액션 분류 정보, 지정된 액션을 근거로 캡쳐된 이미지에 대응하는 액션을 확인 가능한 액션 확인 정보, 상기 화면의 맨위 표시된 애플리 케이션을 식별하는 애플리케이션 식별 정보, 상기 화면의 맨위 표시된 애플리케이션의 인터페이스 화면을 식별 하는 인터페이스 식별 정보, 상기 화면의 맨위 표시된 애플리케이션을 통해 표시된 컨텐츠를 식별하는 컨텐츠 식별 정보, 상기 화면의 맨위 표시된 애플리케이션을 통해 수행되는 적어도 하나의 워크플로를 설명하는 워크플 로 정보, 상기 화면의 맨위 표시된 브라우져에 로딩된 페이지를 식별하는 애플리케이션 식별 정보, 상기 화면의 맨위 표시된 브라우져에 로딩된 페이지의 인터페이스 화면을 식별하는 인터페이스 식별 정보, 상기 화면의 맨위 표시된 브라우져에 로딩된 페이지를 통해 표시된 컨텐츠를 식별하는 컨텐츠 식별 정보, 상기 화면의 맨위 표시 된 브라우져에 로딩된 페이지를 통해 수행되는 적어도 하나의 워크플로를 설명하는 워크플로 정보 중 적어도 하 나의 정보를 포함할 수 있다. 본 발명에 따르면, 상기 화면 메타정보는, 상기 화면의 맨위 아래 표시되거나 감춤된 적어도 하나의 애플리케이 션을 식별하는 애플리케이션 식별 정보, 상기 화면의 맨위 아래 표시되거나 감춤된 적어도 하나의 애플리케이션 의 인터페이스 화면을 식별하는 인터페이스 식별 정보, 상기 화면의 맨위 아래 표시되거나 감춤된 적어도 하나 의 애플리케이션을 통해 표시된 컨텐츠를 식별하는 컨텐츠 식별 정보, 상기 화면의 맨위 아래 표시되거나 감춤 된 적어도 하나의 애플리케이션을 통해 수행되는 적어도 하나의 워크플로를 설명하는 워크플로 정보, 상기 화면 의 맨위 아래 표시되거나 감춤된 적어도 하나의 브라우져에 로딩된 적어도 하나의 페이지를 식별하는 애플리케 이션 식별 정보, 상기 화면의 맨위 아래 표시되거나 감춤된 적어도 하나의 브라우져에 적어도 하나의 로딩된 페 이지의 인터페이스 화면을 식별하는 인터페이스 식별 정보, 상기 화면의 맨위 아래 표시되거나 감춤된 적어도하나의 브라우져에 로딩된 적어도 하나의 페이지를 통해 표시된 컨텐츠를 식별하는 컨텐츠 식별 정보, 상기 화 면의 맨위 아래 표시되거나 감춤된 적어도 하나의 브라우져에 로딩된 적어도 하나의 페이지를 통해 수행되는 적 어도 하나의 워크플로를 설명하는 워크플로 중 적어도 하나의 정보를 더 포함할 수 있다. 본 발명에 따르면, 상기 제2 단계는, 사용자가 이용하는 m개의 단말 중 제n차 분할 시간 구간에 활성화된 상태 를 대응하는 화면을 구비한 m'(1≤m'≤m)개의 단말의 프로그램으로부터 상기 제n차 분할 시간 구간의 지정된 캡 쳐 시점에 상기 활성화된 상태를 대응하는 en(1≤n≤N)(1≤en≤S)개의 화면을 캡쳐하여 획득된 en개의 대표 이미지를 수신하는 절차를 수행하는 수신단계와, 상기 수신된 en개의 대표 이미지를 근거로 상기 제n차 분할 시간 구간의 행위 상태 분석과 관련된 일의적 이미지에 해당하는 in(1≤in≤en)개의 제n차 이미지를 확인하는 확인단계를 포 함할 수 있다. 본 발명에 따르면, 상기 수신단계는, 상기 en개의 대표 이미지를 설명하는 en개의 화면 메타정보를 수신하는 단 계를 더 포함할 수 있으며, 상기 in개의 메타정보는, 상기 en개의 화면 메타정보를 근거로 확인될 수 있다. 본 발명에 따르면, 상기 제2 단계는, 사용자가 이용하는 m개의 단말 중 제n차 분할 시간 구간에 활성화된 상태 를 대응하는 화면을 구비한 m'(1≤m'≤m)개의 단말의 프로그램으로부터 상기 제n차 분할 시간 구간에 활성화된 상태를 대응하는 en(1≤n≤N)(1≤en≤S)개의 화면 별로 기 설정된 R(R≥1)개의 액션 중 지정된 액션에 대응하는 화 면을 인식하는 절차를 수행하여 적어도 하나의 지정된 액션이 인식된 kn(1≤n≤N)(1≤kn≤en)개의 화면을 지정된 액 션 인식 시점 별로 캡쳐하여 획득된 rn(1≤n≤N)(1≤rn≤R, rn≥kn)개의 특징 이미지를 수신하는 절차를 수행하는 수 신단계와, 상기 수신된 rn개의 특징 이미지를 근거로 상기 제n차 분할 시간 구간의 행위 상태 분석과 관련된 일 의적 이미지에 해당하는 in(1≤in≤rn)개의 제n차 이미지를 확인하는 확인단계를 포함할 수 있다. 본 발명에 따르면, 상기 R개의 액션은, 사용자의 지정된 행위 범주와 관련된 특정 애플리케이션을 구동하는 액 션, 사용자의 지정된 행위 범주와 관련된 특정 애플리케이션의 지정된 인터페이스 화면을 호출하거나 조작하는 액션, 페이지를 로딩 가능한 브라우져를 구동하는 액션, 브라우져를 통해 사용자의 지정된 행위 범주와 관련된 페이지를 로딩하거나 조작하는 액션, 특정 애플리케이션이나 브라우져를 통해 사용자의 지정된 행위 범주와 관 련된 컨텐츠를 로딩하거나 조작하는 액션, 특정 애플리케이션을 통해 사용자의 지정된 행위 범주와 관련된 워크 플로(workflow)에 대응하는 인터페이스 화면을 호출하거나 조작하는 액션, 브라우져를 통해 사용자의 지정된 행 위 범주와 관련된 워크플로에 대응하는 페이지를 로딩하거나 조작하는 액션 중 적어도 하나의 액션을 포함할 수 있다. 본 발명에 따르면, 상기 R개의 액션은, 사용자의 지정된 행위 범주와 무관한 애플리케이션을 구동하는 액션, 사 용자의 지정된 행위 범주와 무관한 애플리케이션을 조작하는 액션, 브라우져를 통해 사용자의 지정된 행위 범주 와 무관한 페이지를 로딩하거나 조작하는 액션, 애플리케이션이나 브라우져를 통해 사용자의 지정된 행위 범주 와 무관한 컨텐츠를 로딩하거나 조작하는 액션, 애플리케이션이나 브라우져를 통해 사용자의 지정된 행위 범주 나 워크플로와 무관한 서버에 접속하거나 상기 사용자의 지정된 행위 범주나 워크플로와 무관한 서버로부터 파 일이나 데이터를 다운로드하거나 상기 사용자의 지정된 행위 범주나 워크플로와 무관한 서버로 파일이나 데이터 를 전송하는 액션, 단말의 외부 저장장치에 파일이나 데이터를 저장하는 액션 중 적어도 하나의 액션을 더 포함 할 수 있다. 본 발명에 따르면, 상기 수신단계는, 상기 rn개의 특징 이미지를 설명하는 rn개의 화면 메타정보를 수신하는 단 계를 더 포함할 수 있으며, 상기 in개의 메타정보는, 상기 rn개의 화면 메타정보를 근거로 확인될 수 있다.본 발명에 따르면, 상기 제2 단계는, 사용자가 이용하는 m개의 단말 중 제n차 분할 시간 구간에 활성화된 상태 를 대응하는 화면을 구비한 m'(1≤m'≤m)개의 단말의 프로그램으로부터 상기 제n차 분할 시간 구간의 지정된 캡 쳐 시점에 상기 활성화된 상태를 대응하는 en(1≤n≤N)(1≤en≤S)개의 화면을 캡쳐하여 획득된 en개의 대표 이미지를 수신하는 절차를 수행하고, 상기 제n차 분할 시간 구간에 활성화된 상태를 대응하는 en개의 화면 별로 기 설정된 R(R≥1)개의 액션 중 지정된 액션에 대응하는 화면을 인식하는 절차를 수행하여 적어도 하나의 지정된 액션이 인식된 kn(1≤n≤N)(1≤kn≤en)개의 화면을 지정된 액션 인식 시점 별로 캡쳐하여 획득된 rn(1≤n≤N)(1≤rn≤R, rn≥k n)개의 특징 이미지를 수신하는 절차를 수행하는 수신단계와, 상기 수신된 en개의 대표 이미지와 rn개의 특징 이 미지를 근거로 상기 제n차 분할 시간 구간의 행위 상태 분석과 관련된 일의적 이미지에 해당하는 in(1≤in≤ (en+rn))개의 제n차 이미지를 확인하는 확인단계를 포함할 수 있다. 본 발명에 따르면, 상기 수신단계는, 상기 en개의 대표 이미지를 설명하는 en개의 화면 메타정보와 상기 rn개의 특징 이미지를 설명하는 개의 rn개의 화면 메타정보를 수신하는 단계를 더 포함할 수 있으며, 상기 in개의 메타 정보는, 상기 en개의 화면 메타정보와 rn개의 화면 메타정보 중 적어도 하나의 화면 메타정보를 근거로 확인될 수 있다. 본 발명에 따르면, 상기 사용자의 행위 확인 정보는, 상기 사용자가 m개의 단말을 이용하면서 행하는 주어진 행 위의 범주에 대응하는 사용자의 행위 범주 정보를 더 포함할 수 있다. 본 발명에 따르면, 상기 제3 단계는, 상기 in개의 제n차 이미지와 in개의 메타정보 및 상기 사용자의 행위 범주 정보를 포함하는 사용자의 행위 확인 정보를 상기 인공지능모듈에 대입하여 상기 사용자의 행위 상태 정보를 분 석하는 단계를 포함할 수 있다. 본 발명에 따르면, 상기 사용자의 행위 확인 정보와 상기 인공지능모듈을 통해 분석된 사용자의 행위 상태 정보 를 상기 사용자가 이용하는 단말이나 지정된 관리자가 이용하는 단말로 제공하여 상기 사용자나 관리자에 의해 수정된 적어도 하나의 행위 상태 정보를 수신하는 단계와, 적어도 하나의 행위 상태 정보가 수정된 경우, 상기 수정된 사용자의 행위 확인 정보와 행위 상태 정보를 포함하는 학습데이터를 상기 인공지능모듈에 적용하여 학 습시키는 단계를 더 포함할 수 있다."}
{"patent_id": "10-2022-0032522", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명에 따르면, 관리자에 의해 관측된 이미지와 메타 정보 및 사용자의 행위 목적이나 범주를 식별하는 행위 범주 정보를 확인하고 관리자에 의해 설정된 행위 상태 정보를 수신하여 인공지능모듈을 학습시킴으로써, 이후 사용자의 행위 시간 동안 사용자가 주시 가능한 적어도 하나의 단말 화면을 캡쳐한 이미지와 메타 정보 및 사용 자의 행위 범주 정보를 인공지능모듈에 대입하여 사용자의 행위 목적이나 범주에 대응하는 사용자의 행위 상태 를 자동 분석할 수 있는 이점이 있다."}
{"patent_id": "10-2022-0032522", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하 첨부된 도면과 설명을 참조하여 본 발명의 바람직한 실시예에 대한 동작 원리를 상세히 설명한다. 다만, 하기에 도시되는 도면과 후술되는 설명은 본 발명의 특징을 효과적으로 설명하기 위한 여러 가지 방법 중에서 바람직한 실시 방법에 대한 것이며, 본 발명이 하기의 도면과 설명만으로 한정되는 것은 아니다. 즉, 하기의 실시예는 본 발명의 수 많은 실시예 중에 바람직한 합집합 형태의 실시예에 해당하며, 하기의 실시 예에서 특정 구성(또는 단계)을 생략하는 실시예, 또는 특정 구성(또는 단계)에 구현된 기능을 특정 구성(또는 단계)으로 분할하는 실시예, 또는 둘 이상의 구성(또는 단계)에 구현된 기능을 어느 하나의 구성(또는 단계)에 통합하는 실시예, 특정 구성(또는 단계)의 동작 순서를 교체하는 실시예 등은, 하기의 실시예에서 별도로 언급 하지 않더라도 모두 본 발명의 권리범위에 속함을 명백하게 밝혀두는 바이다. 따라서 하기의 실시예를 기준으로 부분집합 또는 여집합에 해당하는 다양한 실시예들이 본 발명의 출원일을 소급받아 분할될 수 있음을 분명하게 명기하는 바이다. 또한, 하기에서 본 발명을 설명함에 있어 관련된 공지 기능 또는 구성에 대한 구체적인 설명이 본 발명의 요지 를 불필요하게 흐릴 수 있다고 판단되는 경우에는 그 상세한 설명을 생략할 것이다. 그리고 후술되는 용어들은 본 발명에서의 기능을 고려하여 정의된 용어들로서, 이는 사용자, 운용자의 의도 또는 관례 등에 따라 달라질 수 있다. 그러므로 그 정의는 본 발명에서 전반에 걸친 내용을 토대로 내려져야 할 것이다. 결과적으로, 본 발명의 기술적 사상은 청구범위에 의해 결정되며, 이하 실시예는 진보적인 본 발명의 기술적 사"}
{"patent_id": "10-2022-0032522", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "상을 본 발명이 속하는 기술분야에서 통상의 지식을 가진 자에게 효율적으로 설명하기 위한 일 수단일 뿐이다. 도면1는 본 발명의 실시 방법에 따른 인공지능을 이용하여 단말 화면 기반 행위 상태를 분석하는 시스템의 구성 을 도시한 도면이다. 보다 상세하게 본 도면1는 캡쳐 가능한 화면을 구비한 단말을 이용하면서 주어진 행위를 행하는 대상자가 상기 행위를 행하는 행위 시간 동안 기 설정된 시간 단위 별로 상기 대상자가 이용하는 적어도 하나의 화면을 기 설 정된 이미지 획득 규칙에 따라 캡쳐하여 획득된 이미지와 상기 이미지를 설명하는 메타정보의 조합을 포함하는 대상자의 행위 확인 정보를 지정된 관리자의 단말로 제공하여 상기 관리자에 의해 상기 대상자의 행위 상태를 설정한 이미지와 메타정보 및 행위 상태 정보를 포함하는 학습데이터를 지정된 인공지능모듈에 적용하여 학습시 킨 이후, 캡쳐 가능한 화면을 구비한 단말을 이용하여 화면을 주시 가능한 상태에서 주어진 행위를 행하는 사용 자의 행위 상태를 분석하기 위해 설정된 행위 시간을 포함하는 전체 행위 시간을 기 설정된 시간 단위로 분할한 분할 시간 구간 중 현재 시점의 분할 시간 구간에 활성화된 상태에 대응하는 적어도 하나의 화면을 기 설정된 이미지 획득 규칙에 따라 캡쳐하여 획득된 적어도 하나의 이미지를 근거로 상기 분할 시간 구간의 행위 상태 분 석과 관련된 일의적 이미지에 해당하는 이미지와 상기 이미지를 설명하는 메타정보를 확인하고, 상기 확인된 이 미지와 메타정보의 조합을 포함하는 사용자의 행위 확인 정보를 상기 인공지능모듈에 대입하여 상기 사용자의"}
{"patent_id": "10-2022-0032522", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "행위 상태 정보를 분석하는 시스템 구성을 도시한 것으로서, 본 발명이 속한 기술분야에서 통상의 지식을 가진 자라면, 본 도면1를 참조 및/또는 변형하여 상기 시스템에 대한 다양한 실시 방법(예컨대, 일부 구성부가 생략 되거나, 또는 세분화되거나, 또는 합쳐진 실시 방법)을 유추할 수 있을 것이나, 본 발명은 상기 유추되는 모든실시 방법을 포함하여 이루어지며, 본 도면1에 도시된 실시 방법만으로 그 기술적 특징이 한정되지 아니한다. 본 발명의 시스템은, 운영서버와 통신하며 캡쳐 가능한 하나 이상의 화면을 구비한 하나 이상의 단말을 이 용하면서 주어진 행위를 행하는 대상자(또는 샤용자)의 단말와, 상기 대상자가 이용하는 적어도 하나의 화 면을 기 설정된 이미지 획득 규칙에 따라 캡쳐하여 획득된 이미지와 상기 이미지를 설명하는 메타정보의 조합을 포함하는 대상자의 행위 확인 정보를 제공받아 상기 대상자의 행위 상태에 대한 이미지와 메타정보 및 행위 상 태 정보를 설정하는 관리자의 단말과, 상기 대상자의 단말 및 관리자의 단말과 통신하며 인공지 능을 이용한 단말 화면 기반 행위 상태를 분석하는 운영서버를 포함한다. 한편, 상기 운영서버는 독 립된 서버 형태, 둘 이상의 서버 조합 형태, 기 구비된 서버에 설치 구동되는 서버 프로그램 형태 중 적어도 하 나 또는 둘 이상의 조합 형태로 구현될 수 있으며, 상기 운영서버를 구현하는 방식에 의해 본 발명이 한정 되지 아니한다. 또한, 상기 운영서버는 인공지능모듈을 구비한다. 상기 인공지능모듈은 상기 대상자의 행위 상 태를 설정한 p(1≤p≤P)개의 이미지와 p개의 메타정보 및 p개의 행위 상태 정보를 포함하는 학습데이터를 지정 된 인공지능 알고리즘을 통해 학습한다. 또한, 상기 인공지믕모듈은 사용자의 행위 상태 분석을 위해 확인된 in개의 제n차 이미지와 in개의 메타정 보의 조합을 포함하는 사용자의 행위 확인 정보를 이용하여 상기 사용자의 행위 상태 정보를 지정된 인공지능 알고리즘을 통해 분석할 수 있다. 또한, 상기 인공지믕모듈은 대상자의 p개의 행위 상태 정보에 대응하는 p개의 이미지와 p개의 메타정보가 확인되면, 상기 확인된 p개의 이미지와 p개의 메타정보 및 p개의 행위 상태 정보를 포함하여 구성된 학습데이터 를 지정된 인공지능 알고리즘을 통해 학습할 수 있다. 또한, 상기 인공지믕모듈은 대상자가 이용하는 단말의 화면을 캡쳐하여 상기 대상자의 단말 이용을 관측한 특징에 대응하는 상기 p개의 이미지와 p개의 메타정보를 포함하는 입력정보(Feature Vectors)와 상기 대 상자의 단말 기반 행위의 관측된 결과에 대응하는 p개의 행위 상태 정보를 포함하는 출력정보(Label)를 포함하 는 학습데이터를 지정된 인공지능 알고리즘을 통해 학습할 수 있다. 또한, 상기 인공지믕모듈은 대상자가 이용하는 단말의 화면을 캡쳐하여 상기 대상자의 단말 이용을 관측한 특징에 대응하는 상기 p개의 이미지와 p개의 메타정보 및 대상자의 행위 범주 정보를 포함하는 입력정보 와 상기 대상자의 단말 기반 행위의 관측된 결과에 대응하는 p개의 행위 상태 정보를 포함하는 출력정보를 포함 하는 학습데이터를 지정된 인공지능 알고리즘을 통해 학습할 수 있다. 또한, 상기 인공지믕모듈은 사용자가 이용하는 단말의 화면을 캡쳐하여 상기 사용자의 단말 이용을 관측한 특징에 대응하는 상기 in개의 제n차 이미지와 in개의 메타정보를 포함하는 사용자의 행위 확인 정보를 지정된 인 공지능 알고리즘을 통해 분석하도록 할 수 있다. 또한, 상기 인공지믕모듈은 상기 in개의 제n차 이미지와 in개의 메타정보 및 상기 사용자의 행위 범주 정보 를 포함하는 사용자의 행위 확인 정보를 지정된 인공지능 알고리즘을 통해 분석하도록 할 수 있다. 또한, 상기 인공지믕모듈은 사용자가 이용하는 단말의 화면을 캡쳐하여 상기 사용자의 단말 이용을 관측한 특징에 대응하는 상기 in개의 제n차 이미지와 in개의 메타정보 및 상기 사용자의 행위 범주 정보를 포함하는 사 용자의 행위 확인 정보를 지정된 인공지능 알고리즘을 통해 분석하도록 할 수 있다. 또한, 상기 인공지믕모듈은 적어도 하나의 행위 상태 정보가 수정된 경우, 상기 수정된 사용자의 행위 확 인 정보와 행위 상태 정보를 포함하는 학습데이터를 지정된 인공지능 알고리즘을 통해 학습할 수 있다. 상기 대상자(또는 사용자)의 단말은 캡쳐 가능한 하나 이상의 화면을 구비한 하나 이상의 단말을 이용하면 서 주어진 행위를 행하는 대상자(또는 샤용자)가 이용하는 컴퓨터 장치의 총칭으로서, 적어도 하나의 화면을 구 비한 컴퓨터, 태블릿PC, 휴대폰(Cell Phone), 스마트폰(Smart Phone), TV(Television), AR(Argmented Realit y)장치, VR(Virtual Reality)장치, MR(Mixed Reality)글라스 중 적어도 하나의 단말을 포함할 수 있다. 한편 본 발명의 대상자(또는 사용자)의 단말은 상기 서술된 경우로 한정되지 아니하며, 캡쳐 가능한 적어 도 하나의 화면을 구비한 현존하는 모든 단말을 포함할 뿐만 아니라, 캡쳐 가능한 적어도 하나의 화면을 구비하여 미래에 출시되는 모든 단말도 본 발명의 단말 범주에 포함되는 것으로 정의한다. 바람직하게, 상기 대상자(또는 사용자)의 단말은 지정된 이미지 획득 규칙에 따라 지정된 화면을 캡쳐하여 이미지를 획득하는 기능과, 지정된 식별 정보를 상기 운영서버로 전송하는 기능과, 현재 시점에 대응하는 제n차 분할 시간 구간에 활성화된 상태에 대응하는 적어도 하나의 화면을 확인하는 기능과, 상기 제n차 분할 시 간 구간에 활성화된 상태에 대응하는 적어도 하나의 화면을 확인한 경우, 상기 제n차 분할 시간 구간의 지정된 캡쳐 시점에 상기 활성화된 상태에 대응하는 적어도 하나의 화면을 캡쳐한 적어도 하나의 대표 이미지를 획득하 는 기능과, 상기 획득된 적어도 하나의 대표 이미지를 상기 운영서버로 전송하는 기능과, 상기 제n차 분할 시간 구간에 활성화된 상태에 대응하는 적어도 하나의 화면을 확인한 경우, 상기 활성화된 상태에 대응하는 적 어도 하나의 화면을 판독하여 기 설정된 R(R≥1)개의 액션 중 지정된 액션에 대응하는 화면을 인식하는 기능과, 지정된 액션이 인식된 화면을 캡쳐한 적어도 하나의 특징 이미지를 획득하는 기능과, 상기 획득된 적어도 하나 의 특징 이미지를 상기 운영서버로 전송하는 기능과, 상기 제n차 분할 시간 구간에 활성화된 상태에 대응 하는 적어도 하나의 화면을 확인한 경우, 상기 제n차 분할 시간 구간의 지정된 캡쳐 시점에 상기 활성화된 상태 에 대응하는 적어도 하나의 화면을 캡쳐한 적어도 하나의 대표 이미지를 획득하는 절차를 수행하고, 상기 활성 화된 상태에 대응하는 적어도 하나의 화면을 판독하여 기 설정된 R(R≥1)개의 액션 중 지정된 액션에 대응하는 화면을 인식하는 절차를 수행하여 지정된 액션이 인식된 화면을 캡쳐한 적어도 하나의 특징 이미지를 획득하는 기능과, 적어도 하나의 대표 이미지를 획득한 경우 상기 획득된 적어도 하나의 대표 이미지를 상기 운영서버 로 전송하고, 적어도 하나의 특징 이미지를 획득한 경우 상기 획득된 적어도 하나의 특징 이미지를 상기 운영서버로 전송하는 기능을 위해 지정된 적어도 하나 이상의 절차를 수행하는 프로그램이나 앱 (Application)이 설치되어 구동되는 것이 바람직하다. 상기 관리자의 단말은 상기 대상자(또는 사용자)를 관리하거나 사용자의 주어진 행위를 관리하는 관리자가 이용하는 컴퓨터 장치의 총칭으로서, 적어도 하나의 화면을 구비한 컴퓨터, 태블릿PC, 휴대폰(Cell Phone), 스 마트폰(Smart Phone), TV(Television), AR(Argmented Reality)장치, VR(Virtual Reality)장치, MR(Mixed Reality)글라스 중 적어도 하나의 단말을 포함할 수 있다. 한편 본 발명의 관리자의 단말은 상기 서술된 경우로 한정되지 아니하며, 캡쳐 가능한 적어도 하나의 화면을 구비한 현존하는 모든 단말을 포함할 뿐만 아니라, 캡쳐 가능한 적어도 하나의 화면을 구비하여 미래에 출시되는 모든 단말도 본 발명의 단말 범주에 포함 되는 것으로 정의한다. 또한, 상기 관리자의 단말은 상기 대상자(또는 사용자)를 관리하거나 사용자의 주어진 행위를 관리하는 기 능을 위해 지정된 적어도 하나 이상의 절차를 수행하는 프로그램이나 앱(Application)이 설치되어 구동되는 것 이 바람직하다.한편, 도면1를 참조하면, 상기 운영서버는, 단말에 지정된 이미지 획득 규칙에 따라 화면을 캡쳐하여 이미지를 획득하는 기능을 포함하는 프로그램을 설치하는 프로그램 설치부와, 단말과 연동하여 상기 대상자를 고유 식별하는 대상자 식별 정보를 등록받아 저장하는 정보 저장부와, 적어도 하나의 단말 에 설치된 프로그램을 구동하여 연동하기 위한 절차를 수행하는 프로그램 연동부를 포함하여 구성될 수 있 다. 도면1에 따르면, 상기 프로그램 설치부는 대상자가 이용하는 g개의 단말에 지정된 이미지 획득 규칙 에 따라 화면을 캡쳐하여 이미지를 획득하는 기능을 포함하는 프로그램을 설치하기 위한 절차를 수행한다. 여기 서, 상기 프로그램은 단독 실행 가능한 애플리케이션을 포함할 수 있고, 대상자의 지정된 행위 범주와 관련된 특정 애플리케이션(예: 업무용 애플리케이션, 비대면 수업용 애플리케이션 등)과 연동하여 실행 가능한 애플리 케이션을 포함할 수 있고, 웹 브라우져와 연동하여 실행 가능한 애플리케이션을 포함할 수 있다. 또한, 상기 프 로그램은 실행된 후 백그라운드 동작 가능하며, 백그라운드 동작 상태에서 이미지를 획득하는 기능을 수행할 수 있다. 상기 g개의 단말은, 지정된 이미지 획득 규칙에 따라 지정된 화면을 캡쳐하여 이미지를 획득하는 기능을 포함하는 프로그램을 설치한 단말을 포함하거나, 또는 대상자가 주어진 행위를 행하기 위해 이용하도록 설정된 적어도 하나의 단말을 포함할 수 있다. 또한, 상기 g개의 단말은 대상자가 주어진 행위를 행하는 행위 시간 동안 대상자가 이용 가능한 단말이나 대상자가 휴대하거나 소지 가능한 단말을 포함할 수 있다. 예컨대, 대상자의 행위에 직접 이용되지 않더라도 대 상자가 행위 시간 동안 행위와 무관하게 이용 가능하거나 개인적으로 휴대하거나 소지 가능한 단말(예: 휴대폰, 스마트폰, 태블릿PC 등)을 포함할 수 있다. 한편, 상기 프로그램 설치부는 사용자가 이용하는 m개의 단말에 지정된 이미지 획득 규칙에 따라 화 면을 캡쳐하여 이미지를 획득하는 기능을 포함하는 프로그램을 설치하기 위한 절차를 수행할 수 있다. 여기서, 상기 m개의 단말은, 지정된 이미지 획득 규칙에 따라 지정된 화면을 캡쳐하여 이미지를 획득하는 기능을 포함하는 프로그램을 설치한 단말을 포함하거나, 또는 사용자가 주어진 행위를 행하기 위해 이용하도록 설정된 적어도 하나의 단말을 포함할 수 있다. 또한, 상기 m개의 단말은, 사용자가 주어진 행위를 행하는 행위 시간 동안 사용자가 이용 가능한 단말이나 사용자가 휴대하거나 소지 가능한 단말을 더 포함할 수 있다. 도면1에 따르면, 상기 정보 저장부는 대상자가 이용하는 단말과 연동하여 상기 대상자를 고유 식별하 는 대상자 식별 정보를 등록받아 지정된 운영DB에 저장한다. 예컨대, 상기 대상자가 이용하는 단말에 프로 그램이 설치되지 않은 상태에서도 웹을 통해 대상자 식별 정보를 등록할 수 있는데, 대상자 식별 정보를 등록한 후 프로그램을 설치하는 과정을 수행할 수 있다. 또한, 상기 정보 저장부는 대상자가 이용하는 단말이나 지정된 관리자가 이용하는 단말과 연동 하여 상기 대상자가 g개의 단말을 이용하면서 행하는 주어진 행위의 범주에 대응하는 대상자의 행위 범주 정보를 등록 또는 설정받아 지정된 운영DB에 저장할 수 있다. 여기서 상기 관리자는 상기 대상자를 관리하거나 대상자의 주어진 행위를 관리하는 관리자를 포함하거나, 또는 단순히 본 발명의 시스템을 관리하는 관리자를 포함할 수 있으며, 상기 행위 범주 정보는, 대상자를 고유 식별 하는 대상자 식별 정보와 매핑되어 운영DB에 저장될 수 있다. 상기 행위 범주 정보는, 상기 대상자가 단말을 이용하여 업무를 수행하는 경우 상기 대상자의 업무 범주나 직무에 대응하는 정보를 포함하거나, 또는 상기 대상자가 단말을 이용하여 비대면 수업에 참가는 경우 상 기 대상자가 참가하는 수업 범주나 과목에 대응하는 정보를 포함하거나, 또는 상기 대상자가 단말을 이용 하여 학습을 행하는 경우 상기 대상자가 학습할 학습 범주나 과목에 대응하는 정보를 포함할 수 있다. 한편, 상기 정보 저장부는 지정된 이미지 획득 규칙에 따라 지정된 화면을 캡쳐하여 이미지를 획득하는 기 능을 포함하는 프로그램을 대상자가 이용하는 단말에 설치 구동한 경우 상기 단말의 프로그램과 통신 하여 상기 단말의 대상자를 고유 식별하는 대상자 식별 정보와 상기 프로그램을 설치한 단말을 고유 식별하는 단말 식별 정보와 상기 단말에서 구동된 프로그램을 고유 식별하는 프로그램 식별 정보와 상기 단말의 프로그램과 통신하기 위한 통신 식별 정보 중 적어도 하나의 식별 정보를 확인하여 지정된 운영DB 에 등록 또는 매핑 저장할 수 있다. 한편, 상기 정보 저장부는 사용자가 이용하는 단말과 연동하여 상기 사용자를 고유 식별하는 사용자 식별 정보를 등록받아 지정된 운영DB에 저장할 수 있다. 또한, 상기 정보 저장부는 사용자가 이용하는 단말이나 지정된 관리자가 이용하는 단말과 연동 하여 상기 사용자가 m개의 단말을 이용하면서 행하는 주어진 행위의 범주에 대응하는 사용자의 행위 범주 정보를 등록 또는 설정받아 지정된 운영DB에 저장할 수 있다. 여기서, 상기 행위 범주 정보는, 상기 사용자가 단말을 이용하여 업무를 수행하는 경우 상기 사용자의 업무 범주나 직무에 대응하는 정보를 포함하거나, 또는 상기 사용자가 단말을 이용하여 비대면 수업에 참가는 경우 상기 사용자가 참가하는 수업 범주나 과 목에 대응하는 정보를 포함하거나, 또는 상기 사용자가 단말을 이용하여 학습을 행하는 경우 상기 사용자 가 학습할 학습 범주나 과목에 대응하는 정보를 포함할 수 있다. 여기서, 상기 관리자는 상기 사용자를 관리하거나 상기 사용자의 행위를 관리하거나 감독 가능한 관리자를 포함 할 수 있다. 한편, 상기 정보 저장부는 지정된 이미지 획득 규칙에 따라 지정된 화면을 캡쳐하여 이미지를 획득하는 기 능을 포함하는 프로그램을 사용자가 이용하는 단말에 설치 구동한 경우 상기 단말의 프로그램과 통신 하여 상기 단말의 사용자를 고유 식별하는 사용자 식별 정보와 상기 프로그램을 설치한 단말을 고유 식별하는 단말 식별 정보와 상기 단말에서 구동된 프로그램을 고유 식별하는 프로그램 식별 정보와 상기 단말의 프로그램과 통신하기 위한 통신 식별 정보 중 적어도 하나의 식별 정보를 확인하여 지정된 운영DB 에 등록 또는 매핑 저장할 수 있다. 도면1에 따르면, 상기 프로그램 연동부는 단말에서 접속하여 대상자 식별 정보를 확인한 경우 상기 대상자 식별 정보와 매핑된 적어도 하나의 식별 정보를 이용하여 대상자가 이용하는 적어도 하나의 단말에 설치된 프로그램을 구동하여 연동하기 위한 절차 또는 대상자가 이용하는 적어도 하나의 단말에서 기 구동 된 프로그램과 연동하기 위한 절차를 수행한다. 여기서, 상기 대상자 식별 정보와 매핑된 적어도 하나의 식별 정보는 단말 식별 정보, 프로그램 식별 정보, 통 신 식별 정보 중 어느 하나 또는 둘 이상 조합에 대응하는 식별 정보를 포함할 수 있다.또한, 프로그램을 구동하여 연동하는 것은 단말에 프로그램이 설치되어 있으나 아직 구동되지 않은 경우 푸시 등을 통지하여 프로그램을 구동한 후 연동하는 것을 포함하며, 기 구동된 프로그램과 연동하는 것은 단말 에서 대상자가 수동으로 프로그램을 구동하거나 또는 단말에서 대상자의 지정된 행위 범주와 관련된 특정 애플리케이션이나 웹 브라우져를 구동하면서 이와 연계된 프로그램이 구동되거나 또는 단말의 시작프 로그램에 해당 프로그램이 등록되어 있어 단말의 부팅 과정에서 자동으로 구동된 경우 상기 단말에서 기 구동된 구동된 프로그램과 연동하는 것을 포함할 수 있으며, 적어도 하나의 단말의 프로그램과 연동하 는 과정을 1회 이상 수행하여 g개의 단말의 프로그램과 연동하게 될 수 있다. 또한, 상기 프로그램 연동부는 단말의 프로그램이 구동되어 상기 단말의 프로그램으로부터 지정 된 식별 정보(예컨대, 대상자 식별 정보, 단말 식별 정보, 프로그램 식별 정보 등)를 수신한 경우, 상기 단말 의 프로그램과 연동하는 절차를 수행할 수 있다. 여기서 대상자가 이용하는 특정한 단말에서 프로그 램이 구동되어 지정된 식별 정보를 통해 접속할 수 있다. 또한, 상기 프로그램 연동부는 상기 수신된 식별 정보를 근거로 적어도 하나의 다른 단말과 관련된 적어도 하나의 식별 정보(예컨대, 다른 단말의 단말 식별 정보, 프로그램 식별 정보, 통신 식별 정보 중 어느 하나 또는 둘 이상 조합에 대응하는 식별 정보 등)를 확인한 경우 상기 확인된 식별 정보를 이용하여 대상자가 이용하는 적어도 하나의 다른 단말에 설치된 프로그램을 구동하여 연동하기 위한 절차 또는 대상자가 이용 하는 적어도 하나의 다른 단말에서 기 구동된 프로그램과 연동하기 위한 절차를 수행할 수 있다. 또한, 상기 g개의 단말은, 상기 프로그램을 설치한 단말을 고유 식별하는 단말 식별 정보와 상기 단 말에서 구동된 프로그램을 고유 식별하는 프로그램 식별 정보와 상기 단말의 프로그램와 통신하기 위 한 통신 식별 정보 중 적어도 하나의 식별 정보에 대응하는 단말을 포함하거나, 또는 상기 프로그램이 구동된 단말을 포함하거나, 또는 상기 프로그램이 구동되어 연동된 단말을 포함할 수 있다. 한편, 상기 프로그램 연동부는 단말에서 접속하여 사용자 식별 정보를 확인한 경우 상기 사용자 식별 정보와 매핑된 적어도 하나의 식별 정보를 이용하여 사용자가 이용하는 적어도 하나의 단말에 설치된 프로 그램을 구동하여 연동하기 위한 절차 또는 사용자가 이용하는 적어도 하나의 단말에서 기 구동된 프로그램 과 연동하기 위한 절차를 수행한다. 여기서, 상기 사용자 식별 정보와 매핑된 적어도 하나의 식별 정보는 단말 식별 정보, 프로그램 식별 정보, 통 신 식별 정보 중 어느 하나 또는 둘 이상 조합에 대응하는 식별 정보를 포함할 수 있다. 또한, 프로그램을 구동하여 연동하는 것은 단말에 프로그램이 설치되어 있으나 아직 구동되지 않은 경우 푸시 등을 통지하여 프로그램을 구동한 후 연동하는 것을 포함하며, 기 구동된 프로그램과 연동하는 것은 단말 에서 사용자가 수동으로 프로그램을 구동하거나 또는 단말에서 사용자의 지정된 행위 범주와 관련된 특정 애플리케이션이나 웹 브라우져를 구동하면서 이와 연계된 프로그램이 구동되거나 또는 단말의 시작프 로그램에 해당 프로그램이 등록되어 있어 단말의 부팅 과정에서 자동으로 구동된 경우 상기 단말에서 기 구동된 구동된 프로그램과 연동하는 것을 포함할 수 있으며, 적어도 하나의 단말의 프로그램과 연동하 는 과정을 1회 이상 수행하여 g개의 단말의 프로그램과 연동하게 될 수 있다. 또한, 상기 프로그램 연동부는 단말의 프로그램이 구동되어 상기 단말의 프로그램으로부터 지정 된 식별 정보(예컨대, 사용자 식별 정보, 단말 식별 정보, 프로그램 식별 정보 등)를 수신한 경우, 상기 단말 의 프로그램과 연동하는 절차를 수행할 수 있다. 여기서 사용자가 이용하는 특정한 단말에서 프로그램이 구동되어 지정된 식별 정보를 통해 접속할 수 있다. 또한, 상기 프로그램 연동부는 상기 수신된 식별 정보를 근거로 적어도 하나의 다른 단말과 관련된 적어도 하나의 식별 정보(예컨대, 다른 단말의 단말 식별 정보, 프로그램 식별 정보, 통신 식별 정보 중 어느 하나 또는 둘 이상 조합에 대응하는 식별 정보 등)를 확인한 경우 상기 확인된 식별 정보를 이용하여 사용자가 이용하는 적어도 하나의 다른 단말에 설치된 프로그램을 구동하여 연동하기 위한 절차 또는 대상자가 이용 하는 적어도 하나의 다른 단말에서 기 구동된 프로그램과 연동하기 위한 절차를 수행할 수 있다. 또한, 상기 m개의 단말은, 상기 프로그램을 설치한 단말을 고유 식별하는 단말 식별 정보와 상기 단 말에서 구동된 프로그램을 고유 식별하는 프로그램 식별 정보와 상기 단말의 프로그램와 통신하기 위 한 통신 식별 정보 중 적어도 하나의 식별 정보에 대응하는 단말을 포함하거나, 또는 상기 프로그램이 구동된 단말을 포함하거나, 또는 상기 프로그램이 구동되어 연동된 단말을 포함할 수 있다. 한편, 도면1을 참조하면, 상기 운영서버는, 캡쳐 가능한 f(f≥1)개의 화면을 구비한 g(g≥1)개의 단말을 통해 화면을 캡쳐하여 획득된 이미지와 상기 이미지를 설명하는 메타정보를 저장하는 이미지 획득부와, 상 기 대상자의 행위 확인 정보를 근거로 상기 대상자의 행위 상태를 판단하여 설정한 행위 상태 정보를 수신하고 상기 행위 상태 정보에 대응하는 이미지와 메타정보를 확인하는 행위상태정보 수신부와, 상기 확인된 이미 지와 메타정보 및 행위 상태 정보를 포함하여 구성된 학습데이터를 지정된 인공지능모듈에 적용하여 학습시키는 인공지능 학습부를 포함하여 구성될 수 있다. 도면1에 따르면, 상기 이미지 획득부는 캡쳐 가능한 f(f≥1)개의 화면을 구비한 g(g≥1)개의 단말을 이용 하면서 주어진 행위를 행하는 대상자가 상기 행위를 행하도록 설정된 b(b≥1)개의 행위 시간을 포함하는 전체 행위 시간을 기 설정된 시간 단위로 분할한 D(D≥2)개의 분할 시간 구간 중 적어도 하나의 화면이 활성화된 상 태를 포함하는 적어도 하나의 분할 시간 구간 별로 상기 활성화된 상태에 대응하는 적어도 하나의 화면을 기 설 정된 이미지 획득 규칙에 따라 캡쳐하여 획득된 P(P≥1)개의 이미지 중 지정된 P'(P'≤P)개의 이미지와 상기 P'개의 이미지를 설명하는 P'개의 메타정보를 저장한다. 여기서, 상기 행위는, 대상자가 단말을 이용하여 지정된 목적을 달성하기 위해 의지를 가지고 행하는 것을 포함할 수 있다. 또한, 상기 행위는, 대상자가 적어도 하나의 단말을 이용하여 업무를 행하는 것, 대상자가 적어도 하나의 단말을 이용하여 비대면 수업에 참가하는 것, 대상자가 적어도 하나의 단말을 이용하여 비대면 학습 을 행하는 것 중 적어도 하나를 포함할 수 있다. 한편, 상기 시간 단위는, 단말 화면 기반 행위 상태 분석을 위해 주기적으로 화면을 캡쳐하여 이미지를 획득하 도록 설정된 특정 시간 단위를 포함하거나, 또는 1분 단위를 포함할 수 있다. 예컨대, 1분 단위가 기본일 수 있 으나, 당업자의 선택이나 대상자가 행하는 행위의 종류에 따라 2분 단위, 3분 단위, …, 10분 단위 등, 다양하 게 설정 가능하다. 한편, 상기 캡쳐를 위한 이미지 획득 규칙은, 화면을 캡쳐할 시간 구간에 활성화된 상태를 포함하는 e(1≤e≤ S)개의 화면으로부터 상기 시간 구간의 지정된 캡쳐 시점에 e개의 대표 이미지를 캡쳐하여 획득하는 규칙을 포 함하거나, 또는 화면을 캡쳐할 시간 구간에 활성화된 상태를 포함하는 화면이 부재한 경우 상기 대표 이미지의 캡쳐를 생략하는 규칙을 더 포함하거나, 또는 화면을 캡쳐할 시간 구간에 활성화된 상태를 포함하는 e(1≤e≤ S)개의 화면 중 적어도 하나의 지정된 액션이 인식된 k(1≤k≤e)개의 화면을 통해 기 설정된 R(R≥1)개의 액션중 지정된 r(1≤r≤R)개의 액션이 인식되는 경우에 상기 k개의 화면으로부터 지정된 액션이 인식된 액션 인식 시점 별로 r개의 특징 이미지를 캡쳐하여 획득하는 규칙을 포함하거나, 또는 화면을 캡쳐할 시간 구간에 활성화 된 상태를 포함하는 화면이 부재하거나 지정된 액션이 인식된 화면이 부재한 경우 상기 특징 이미지의 캡쳐를 생략하는 규칙을 포함할 수 있다. 또한, 상기 이미지 획득 규칙은, 화면을 캡쳐할 시간 구간에 활성화된 상태를 포함하는 e(1≤e≤S)개의 화면으 로부터 상기 시간 구간의 지정된 캡쳐 시점에 e개의 대표 이미지를 캡쳐하여 획득하는 규칙과, 상기 활성하된 e 개의 화면 중 적어도 하나의 지정된 액션이 인식된 k(1≤k≤e)개의 화면을 통해 기 설정된 R(R≥1)개의 액션 중 지정된 r(1≤r≤R)개의 액션이 인식되는 경우에 상기 k개의 화면으로부터 지정된 액션이 인식된 액션 인식 시점 별로 r개의 특징 이미지를 캡쳐하여 획득하는 규칙의 조합을 포함할 수 있다. 또한, 상기 이미지 획득 규칙은, 화면을 캡쳐할 시간 구간에 활성화된 상태를 포함하는 화면이 부재한 경우 상 기 대표 이미지의 캡쳐를 생략하는 규칙을 더 포함하거나, 또는 화면을 캡쳐할 시간 구간에 활성화된 상태를 포 함하는 화면이 부재하거나 지정된 액션이 인식된 화면이 부재한 경우 상기 특징 이미지의 캡쳐를 생략하는 규칙 을 더 포함할 수 있다. 한편, 상기 P'개의 이미지는, 상기 P개의 이미지 중 대상자의 행위 상태 분석과 관련된 일의적 이미지를 포함할 수 있으며, 상기 일의적 이미지는, 화면의 맨위 표시된 애플리케이션이 대상자의 지정된 행위 범주와 관련된 특 정 애플리케이션을 포함하는 이미지, 화면의 맨위 표시된 인터페이스 화면이 대상자의 지정된 행위 범주와 관련 된 인터페이스 화면을 포함하는 이미지, 지정된 액션을 근거로 획득된 이미지, 대상자의 지정된 행위 범주와 관 련된 워크플로(workflow)에 대응하는 이미지 중 적어도 하나의 이미지를 포함할 수 있다. 한편, 상기 P'개의 메타정보는, 상기 대상자가 이용하는 적어도 하나의 화면을 기 설정된 이미지 획득 규칙에 따라 캡쳐하여 획득하는 과정과 연동하여 생성된 화면 메타정보를 포함할 수 있다. 여기서, 상기 화면 메타정보는, 상기 이미지를 캡쳐한 시점을 식별 가능한 시점 식별 정보, 상기 이미지를 캡쳐 한 화면을 식별 가능한 화면 식별 정보, 상기 이미지를 캡쳐한 단말을 식별 가능한 단말 식별 정보, 지정된 액 션을 근거로 이미지를 캡쳐한 경우 상기 이미지에 대응하는 액션을 분류하는 액션 분류 정보, 지정된 액션을 근 거로 캡쳐된 이미지에 대응하는 액션을 확인 가능한 액션 확인 정보, 상기 화면의 맨위 표시된 애플리케이션을 식별하는 애플리케이션 식별 정보, 상기 화면의 맨위 표시된 애플리케이션의 인터페이스 화면을 식별하는 인터 페이스 식별 정보, 상기 화면의 맨위 표시된 애플리케이션을 통해 표시된 컨텐츠를 식별하는 컨텐츠 식별 정보, 상기 화면의 맨위 표시된 애플리케이션을 통해 수행되는 적어도 하나의 워크플로를 설명하는 워크플로 정보, 상 기 화면의 맨위 표시된 브라우져에 로딩된 페이지를 식별하는 애플리케이션 식별 정보, 상기 화면의 맨위 표시 된 브라우져에 로딩된 페이지의 인터페이스 화면을 식별하는 인터페이스 식별 정보, 상기 화면의 맨위 표시된 브라우져에 로딩된 페이지를 통해 표시된 컨텐츠를 식별하는 컨텐츠 식별 정보, 상기 화면의 맨위 표시된 브라 우져에 로딩된 페이지를 통해 수행되는 적어도 하나의 워크플로를 설명하는 워크플로 정보 중 적어도 하나의 정 보를 포함할 수 있다. 또한, 상기 화면 메타정보는, 상기 화면의 맨위 아래 표시되거나 감춤된 적어도 하나의 애플리케이션을 식별하 는 애플리케이션 식별 정보, 상기 화면의 맨위 아래 표시되거나 감춤된 적어도 하나의 애플리케이션의 인터페이 스 화면을 식별하는 인터페이스 식별 정보, 상기 화면의 맨위 아래 표시되거나 감춤된 적어도 하나의 애플리케 이션을 통해 표시된 컨텐츠를 식별하는 컨텐츠 식별 정보, 상기 화면의 맨위 아래 표시되거나 감춤된 적어도 하 나의 애플리케이션을 통해 수행되는 적어도 하나의 워크플로를 설명하는 워크플로 정보, 상기 화면의 맨위 아래 표시되거나 감춤된 적어도 하나의 브라우져에 로딩된 적어도 하나의 페이지를 식별하는 애플리케이션 식별 정보, 상기 화면의 맨위 아래 표시되거나 감춤된 적어도 하나의 브라우져에 적어도 하나의 로딩된 페이지의 인 터페이스 화면을 식별하는 인터페이스 식별 정보, 상기 화면의 맨위 아래 표시되거나 감춤된 적어도 하나의 브라우져에 로딩된 적어도 하나의 페이지를 통해 표시된 컨텐츠를 식별하는 컨텐츠 식별 정보, 상기 화면의 맨위 아래 표시되거나 감춤된 적어도 하나의 브라우져에 로딩된 적어도 하나의 페이지를 통해 수행되는 적어도 하나 의 워크플로를 설명하는 워크플로 중 적어도 하나의 정보를 더 포함할 수 있다. 한편, 본 발명의 대상자가 이용하는 단말로부터 상기 이미지를 획득하는 제1 실시예에 따르면, 대상자가 이용하는 단말의 프로그램은 화면을 캡쳐할 분할 시간 구간에 활성화된 상태에 대응하는 적어도 하나의 화 면을 확인하고, 상기 분할 시간 구간에 활성화된 상태에 대응하는 적어도 하나의 화면을 확인한 경우, 상기 분 할 시간 구간의 지정된 캡쳐 시점에 상기 활성화된 상태에 대응하는 적어도 하나의 화면을 캡쳐한 적어도 하나 의 대표 이미지를 획득한 후, 상기 획득된 적어도 하나의 대표 이미지를 상기 운영서버(또는 상기 이미지 획득부)로 전송하는 절차를 수행할 수 있다. 여기서, 상기 단말의 프로그램은, 상기 획득된 대표 이미지를 설명하는 화면 메타정보를 생성할 수 있다. 또한, 상기 단말의 프로그램은, 상기 획득된 대표 이미지에 상기 생성된 화면 메타정보를 첨부하여 상기 운영서버로 전송할 수 있다. 상기 이미지 획득부는 대상자가 이용하는 g개의 단말 중 지정된 분할 시간 구간에 활성화된 상태를 대응하는 화면을 구비한 g'(1≤g'≤g)개의 단말의 프로그램으로부터 상기 분할 시간 구간의 지정된 캡쳐 시점에 상기 활성화된 상태를 대응하는 적어도 하나의 대표 이미지를 수신하고, 상기 대표 이미지를 포함하는 P'개의 이미지를 저장할 수 있다. 여기서, 상기 이미지 획득부는 상기 대표 이미지를 설명하는 화면 메타정보를 수신하고, 상기 저장단계는, 상기 P'개의 이미지를 설명하는 P'개의 화면 메타정보를 포함하는 P'개의 메타정보를 저장할 수 있다. 그리고, 상기 화면 메타정보는, 상기 대표 이미지를 캡쳐한 시점을 식별 가능한 시점 식별 정보, 상기 대표 이 미지를 캡쳐한 화면을 식별 가능한 화면 식별 정보, 상기 대표 이미지를 캡쳐한 단말을 식별 가능한 단말 식별 정보, 상기 화면의 맨위 표시된 애플리케이션을 식별하는 애플리케이션 식별 정보, 상기 화면의 맨위 표시된 애 플리케이션의 인터페이스 화면을 식별하는 인터페이스 식별 정보, 상기 화면의 맨위 표시된 애플리케이션을 통 해 표시된 컨텐츠를 식별하는 컨텐츠 식별 정보, 상기 화면의 맨위 표시된 애플리케이션을 통해 수행되는 적어 도 하나의 워크플로를 설명하는 워크플로 정보, 상기 화면의 맨위 표시된 브라우져에 로딩된 페이지를 식별하는 애플리케이션 식별 정보, 상기 화면의 맨위 표시된 브라우져에 로딩된 페이지의 인터페이스 화면을 식별하는 인 터페이스 식별 정보, 상기 화면의 맨위 표시된 브라우져에 로딩된 페이지를 통해 표시된 컨텐츠를 식별하는 컨 텐츠 식별 정보, 상기 화면의 맨위 표시된 브라우져에 로딩된 페이지를 통해 수행되는 적어도 하나의 워크플로 를 설명하는 워크플로 정보 중 적어도 하나의 정보를 포함할 수 있다. 또한, 상기 화면 메타정보는, 상기 화면의 맨위 아래 표시되거나 감춤된 적어도 하나의 애플리케이션을 식별하 는 애플리케이션 식별 정보, 상기 화면의 맨위 아래 표시되거나 감춤된 적어도 하나의 애플리케이션의 인터페이 스 화면을 식별하는 인터페이스 식별 정보, 상기 화면의 맨위 아래 표시되거나 감춤된 적어도 하나의 애플리케 이션을 통해 표시된 컨텐츠를 식별하는 컨텐츠 식별 정보, 상기 화면의 맨위 아래 표시되거나 감춤된 적어도 하 나의 애플리케이션을 통해 수행되는 적어도 하나의 워크플로를 설명하는 워크플로 정보, 상기 화면의 맨위 아래 표시되거나 감춤된 적어도 하나의 브라우져에 로딩된 적어도 하나의 페이지를 식별하는 애플리케이션 식별 정보, 상기 화면의 맨위 아래 표시되거나 감춤된 적어도 하나의 브라우져에 적어도 하나의 로딩된 페이지의 인 터페이스 화면을 식별하는 인터페이스 식별 정보, 상기 화면의 맨위 아래 표시되거나 감춤된 적어도 하나의 브 라우져에 로딩된 적어도 하나의 페이지를 통해 표시된 컨텐츠를 식별하는 컨텐츠 식별 정보, 상기 화면의 맨위 아래 표시되거나 감춤된 적어도 하나의 브라우져에 로딩된 적어도 하나의 페이지를 통해 수행되는 적어도 하나의 워크플로를 설명하는 워크플로 중 적어도 하나의 정보를 더 포함할 수 있다. 한편, 본 발명의 대상자가 이용하는 단말로부터 상기 이미지를 획득하는 제2 실시예에 따르면, 대상자가 이용하는 단말의 프로그램은 화면을 캡쳐할 분할 시간 구간에 활성화된 상태에 대응하는 적어도 하나의 화 면을 확인하고, 상기 분할 시간 구간에 활성화된 상태에 대응하는 적어도 하나의 화면을 확인한 경우, 상기 활 성화된 상태에 대응하는 적어도 하나의 화면을 판독하여 기 설정된 R(R≥1)개의 액션 중 지정된 액션에 대응하 는 화면을 인식하고, 지정된 액션이 인식된 화면을 캡쳐한 적어도 하나의 특징 이미지를 획득하면, 상기 획득된 적어도 하나의 특징 이미지를 상기 운영서버로 전송할 수 있다. 여기서, 상기 단말의 프로그램은 상기 분할 시간 구간 중에 상기 활성화된 상태에 대응하는 적어도 하나의 화면을 지정된 주기로 판독하거나 지정된 액션에 대응하는 이벤트 발생을 검출하여 기 설정된 R개의 액션 중 지 정된 액션을 인식할 수 있다. 또한, 상기 단말의 프로그램은 상기 획득된 특징 이미지를 설명하는 화면 메타정보를 생성할 수 있다. 또한, 상기 단말의 프로그램은 상기 획득된 특징 이미지에 상기 생성된 화면 메타정보를 첨부하여 상기 운 영서버(이미지 획득부)로 전송할 수 있다. 상기 이미지 획득부는 대상자가 이용하는 g개의 단말 중 지정된 분할 시간 구간에 활성화된 상태를 대응하는 화면을 구비한 g'(1≤g'≤g)개의 단말의 프로그램으로부터 상기 분할 시간 구간에 활성화된 상태 를 대응하는 적어도 하나의 화면 별로 기 설정된 R(R≥1)개의 액션 중 지정된 액션에 대응하는 화면을 인식하는 절차를 수행하여 적어도 하나의 지정된 액션이 인식된 적어도 하나의 화면을 지정된 액션 인식 시점 별로 캡쳐 하여 획득된 적어도 하나의 특징 이미지를 수신하고, 상기 특징 이미지를 포함하는 P'개의 이미지를 저장할 수 있다. 여기서, 상기 R개의 액션은, 대상자의 지정된 행위 범주와 관련된 특정 애플리케이션을 구동하는 액션, 대상자 의 지정된 행위 범주와 관련된 특정 애플리케이션의 지정된 인터페이스 화면을 호출하거나 조작하는 액션, 페이 지를 로딩 가능한 브라우져를 구동하는 액션, 브라우져를 통해 대상자의 지정된 행위 범주와 관련된 페이지를 로딩하거나 조작하는 액션, 특정 애플리케이션이나 브라우져를 통해 대상자의 지정된 행위 범주와 관련된 컨텐 츠(예컨대, 문자, 이미지, 사운드, 동영상, 3D객체 등)를 로딩하거나 조작하는 액션, 특정 애플리케이션을 통해 대상자의 지정된 행위 범주와 관련된 워크플로(workflow)에 대응하는 인터페이스 화면을 호출하거나 조작하는 액션, 브라우져를 통해 대상자의 지정된 행위 범주와 관련된 워크플로에 대응하는 페이지를 로딩하거나 조작하 는 액션 중 적어도 하나의 액션을 포함할 수 있다. 또한, 상기 R개의 액션은, 대상자의 지정된 행위 범주와 무관한 애플리케이션을 구동하는 액션, 대상자의 지정 된 행위 범주와 무관한 애플리케이션을 조작하는 액션, 브라우져를 통해 대상자의 지정된 행위 범주와 무관한 페이지를 로딩하거나 조작하는 액션, 애플리케이션이나 브라우져를 통해 대상자의 지정된 행위 범주와 무관한 컨텐츠를 로딩하거나 조작하는 액션, 애플리케이션이나 브라우져를 통해 대상자의 지정된 행위 범주나 워크플로 와 무관한 서버에 접속하거나 상기 대상자의 지정된 행위 범주나 워크플로와 무관한 서버로부터 파일이나 데이 터를 다운로드하거나 상기 대상자의 지정된 행위 범주나 워크플로와 무관한 서버로 파일이나 데이터를 전송하는 액션, 단말의 외부 저장장치에 파일이나 데이터를 저장하는 액션 중 적어도 하나의 액션을 더 포함할 수 있다. 여기서, 상기 이미지 획득부는 상기 특징 이미지를 설명하는 화면 메타정보를 수신하고, 상기 P'개의 이미 지를 설명하는 P'개의 화면 메타정보를 포함하는 P'개의 메타정보를 저장할 수 있다.상기 화면 메타정보는, 상기 특징 이미지를 캡쳐한 시점을 식별 가능한 시점 식별 정보, 상기 특징 이미지를 캡 쳐한 화면을 식별 가능한 화면 식별 정보, 상기 특징 이미지를 캡쳐한 단말을 식별 가능한 단말 식별 정보, 상 기 특징 이미지에 대응하는 액션을 분류하는 액션 분류 정보, 상기 특징 이미지에 대응하는 액션을 확인 가능한 액션 확인 정보, 상기 화면의 맨위 표시된 애플리케이션을 식별하는 애플리케이션 식별 정보, 상기 화면의 맨위 표시된 애플리케이션의 인터페이스 화면을 식별하는 인터페이스 식별 정보, 상기 화면의 맨위 표시된 애플리케 이션을 통해 표시된 컨텐츠를 식별하는 컨텐츠 식별 정보, 상기 화면의 맨위 표시된 애플리케이션을 통해 수행 되는 적어도 하나의 워크플로를 설명하는 워크플로 정보, 상기 화면의 맨위 표시된 브라우져에 로딩된 페이지를 식별하는 애플리케이션 식별 정보, 상기 화면의 맨위 표시된 브라우져에 로딩된 페이지의 인터페이스 화면을 식 별하는 인터페이스 식별 정보, 상기 화면의 맨위 표시된 브라우져에 로딩된 페이지를 통해 표시된 컨텐츠를 식 별하는 컨텐츠 식별 정보, 상기 화면의 맨위 표시된 브라우져에 로딩된 페이지를 통해 수행되는 적어도 하나의 워크플로를 설명하는 워크플로 정보 중 적어도 하나의 정보를 포함할 수 있다. 여기서, 상기 화면 메타정보는, 상기 화면의 맨위 아래 표시되거나 감춤된 적어도 하나의 애플리케이션을 식별 하는 애플리케이션 식별 정보, 상기 화면의 맨위 아래 표시되거나 감춤된 적어도 하나의 애플리케이션의 인터페 이스 화면을 식별하는 인터페이스 식별 정보, 상기 화면의 맨위 아래 표시되거나 감춤된 적어도 하나의 애플리 케이션을 통해 표시된 컨텐츠를 식별하는 컨텐츠 식별 정보, 상기 화면의 맨위 아래 표시되거나 감춤된 적어도 하나의 애플리케이션을 통해 수행되는 적어도 하나의 워크플로를 설명하는 워크플로 정보, 상기 화면의 맨위 아 래 표시되거나 감춤된 적어도 하나의 브라우져에 로딩된 적어도 하나의 페이지를 식별하는 애플리케이션 식별 정보, 상기 화면의 맨위 아래 표시되거나 감춤된 적어도 하나의 브라우져에 적어도 하나의 로딩된 페이지의 인 터페이스 화면을 식별하는 인터페이스 식별 정보, 상기 화면의 맨위 아래 표시되거나 감춤된 적어도 하나의 브 라우져에 로딩된 적어도 하나의 페이지를 통해 표시된 컨텐츠를 식별하는 컨텐츠 식별 정보, 상기 화면의 맨위 아래 표시되거나 감춤된 적어도 하나의 브라우져에 로딩된 적어도 하나의 페이지를 통해 수행되는 적어도 하나 의 워크플로를 설명하는 워크플로 중 적어도 하나의 정보를 더 포함할 수 있다. 한편, 본 발명의 대상자가 이용하는 단말로부터 상기 이미지를 획득하는 제3 실시예에 따르면, 대상자가 이용하는 단말의 프로그램은 화면을 캡쳐할 분할 시간 구간에 활성화된 상태에 대응하는 적어도 하나의 화 면을 확인하고, 상기 분할 시간 구간에 활성화된 상태에 대응하는 적어도 하나의 화면을 확인한 경우, 상기 분 할 시간 구간의 지정된 캡쳐 시점에 상기 활성화된 상태에 대응하는 적어도 하나의 화면을 캡쳐한 적어도 하나 의 대표 이미지를 획득하는 절차를 수행하고, 상기 활성화된 상태에 대응하는 적어도 하나의 화면을 판독하여 기 설정된 R(R≥1)개의 액션 중 지정된 액션에 대응하는 화면을 인식하는 절차를 수행하여 지정된 액션이 인식 된 화면을 캡쳐한 적어도 하나의 특징 이미지를 획득한 후, 적어도 하나의 대표 이미지를 획득한 경우 상기 획 득된 적어도 하나의 대표 이미지를 상기 운영서버(또는 이미지 획득부)로 전송하고, 적어도 하나의 특징 이미지를 획득한 경우 상기 획득된 적어도 하나의 특징 이미지를 상기 운영서버(또는 이미지 획득부)로 전 송할 수 있다. 여기서, 상기 단말의 프로그램은 상기 획득된 대표 이미지를 설명하는 화면 메타정보를 생성할 수 있다. 또한, 상기 단말의 프로그램은 상기 획득된 대표 이미지에 상기 생성된 화면 메타정보를 첨부하여 상기 운 영서버(또는 이미지 획득부)로 전송할 수 있다. 또한, 상기 단말의 프로그램은 상기 획득된 특징 이미지를 설명하는 화면 메타정보를 생성할 수 있다. 또한, 상기 단말의 프로그램은 상기 획득된 특징 이미지에 상기 생성된 화면 메타정보를 첨부하여 상기 운 영서버(또는 이미지 획득부)로 전송할 수 있다.한편, 상기 이미지 획득부는 대상자가 이용하는 g개의 단말 중 지정된 분할 시간 구간에 활성화된 상 태를 대응하는 화면을 구비한 g'(1≤g'≤g)개의 단말의 프로그램으로부터 상기 분할 시간 구간의 지정된 캡쳐 시점에 상기 활성화된 상태를 대응하는 적어도 하나의 대표 이미지를 수신하고, 상기 분할 시간 구간에 활 성화된 상태를 대응하는 적어도 하나의 화면 별로 기 설정된 R(R≥1)개의 액션 중 지정된 액션에 대응하는 화면 을 인식하여 적어도 하나의 지정된 액션이 인식된 적어도 하나의 화면을 지정된 액션 인식 시점 별로 캡쳐하여 획득된 적어도 하나의 특징 이미지를 수신한 후, 상기 대표 이미지와 특징 이미지 중 적어도 하나의 이미지를 포함하는 P'개의 이미지를 저장할 수 있다. 여기서, 상기 R개의 액션은, 대상자의 지정된 행위 범주와 관련된 특정 애플리케이션을 구동하는 액션, 대상자 의 지정된 행위 범주와 관련된 특정 애플리케이션의 지정된 인터페이스 화면을 호출하거나 조작하는 액션, 페이 지를 로딩 가능한 브라우져를 구동하는 액션, 브라우져를 통해 대상자의 지정된 행위 범주와 관련된 페이지를 로딩하거나 조작하는 액션, 특정 애플리케이션이나 브라우져를 통해 대상자의 지정된 행위 범주와 관련된 컨텐 츠(예컨대, 문자, 이미지, 사운드, 동영상, 3D객체 등)를 로딩하거나 조작하는 액션, 특정 애플리케이션을 통해 대상자의 지정된 행위 범주와 관련된 워크플로(workflow)에 대응하는 인터페이스 화면을 호출하거나 조작하는 액션, 브라우져를 통해 대상자의 지정된 행위 범주와 관련된 워크플로에 대응하는 페이지를 로딩하거나 조작하 는 액션 중 적어도 하나의 액션을 포함할 수 있다. 또한, 상기 R개의 액션은, 대상자의 지정된 행위 범주와 무관한 애플리케이션을 구동하는 액션, 대상자의 지정 된 행위 범주와 무관한 애플리케이션을 조작하는 액션, 브라우져를 통해 대상자의 지정된 행위 범주와 무관한 페이지를 로딩하거나 조작하는 액션, 애플리케이션이나 브라우져를 통해 대상자의 지정된 행위 범주와 무관한 컨텐츠를 로딩하거나 조작하는 액션, 애플리케이션이나 브라우져를 통해 대상자의 지정된 행위 범주나 워크플로 와 무관한 서버에 접속하거나 상기 대상자의 지정된 행위 범주나 워크플로와 무관한 서버로부터 파일이나 데이 터를 다운로드하거나 상기 대상자의 지정된 행위 범주나 워크플로와 무관한 서버로 파일이나 데이터를 전송하는 액션, 단말의 외부 저장장치에 파일이나 데이터를 저장하는 액션 중 적어도 하나의 액션을 더 포함할 수 있다. 또한, 상기 이미지 획득부는 상기 대표 이미지를 설명하는 화면 메타정보와 상기 특징 이미지를 설명하는 화면 메타정보를 수신하고, 상기 P'개의 이미지를 설명하는 P'개의 화면 메타정보를 포함하는 P'개의 메타정보 를 저장할 수 있다. 여기서, 상기 화면 메타정보는, 상기 대표 이미지 또는 특징 이미지를 캡쳐한 시점을 식별 가능한 시점 식별 정 보, 상기 대표 이미지 또는 특징 이미지를 캡쳐한 화면을 식별 가능한 화면 식별 정보, 상기 대표 이미지 또는 특징 이미지를 캡쳐한 단말을 식별 가능한 단말 식별 정보, 상기 특징 이미지에 대응하는 액션을 분류하는 액션 분류 정보, 상기 특징 이미지에 대응하는 액션을 확인 가능한 액션 확인 정보, 상기 화면의 맨위 표시된 애플리 케이션을 식별하는 애플리케이션 식별 정보, 상기 화면의 맨위 표시된 애플리케이션의 인터페이스 화면을 식별 하는 인터페이스 식별 정보, 상기 화면의 맨위 표시된 애플리케이션을 통해 표시된 컨텐츠를 식별하는 컨텐츠 식별 정보, 상기 화면의 맨위 표시된 애플리케이션을 통해 수행되는 적어도 하나의 워크플로를 설명하는 워크플 로 정보, 상기 화면의 맨위 표시된 브라우져에 로딩된 페이지를 식별하는 애플리케이션 식별 정보, 상기 화면의 맨위 표시된 브라우져에 로딩된 페이지의 인터페이스 화면을 식별하는 인터페이스 식별 정보, 상기 화면의 맨위 표시된 브라우져에 로딩된 페이지를 통해 표시된 컨텐츠를 식별하는 컨텐츠 식별 정보, 상기 화면의 맨위 표시 된 브라우져에 로딩된 페이지를 통해 수행되는 적어도 하나의 워크플로를 설명하는 워크플로 정보 중 적어도 하 나의 정보를 포함할 수 있다. 또한, 상기 화면 메타정보는, 상기 화면의 맨위 아래 표시되거나 감춤된 적어도 하나의 애플리케이션을 식별하 는 애플리케이션 식별 정보, 상기 화면의 맨위 아래 표시되거나 감춤된 적어도 하나의 애플리케이션의 인터페이 스 화면을 식별하는 인터페이스 식별 정보, 상기 화면의 맨위 아래 표시되거나 감춤된 적어도 하나의 애플리케이션을 통해 표시된 컨텐츠를 식별하는 컨텐츠 식별 정보, 상기 화면의 맨위 아래 표시되거나 감춤된 적어도 하 나의 애플리케이션을 통해 수행되는 적어도 하나의 워크플로를 설명하는 워크플로 정보, 상기 화면의 맨위 아래 표시되거나 감춤된 적어도 하나의 브라우져에 로딩된 적어도 하나의 페이지를 식별하는 애플리케이션 식별 정보, 상기 화면의 맨위 아래 표시되거나 감춤된 적어도 하나의 브라우져에 적어도 하나의 로딩된 페이지의 인 터페이스 화면을 식별하는 인터페이스 식별 정보, 상기 화면의 맨위 아래 표시되거나 감춤된 적어도 하나의 브 라우져에 로딩된 적어도 하나의 페이지를 통해 표시된 컨텐츠를 식별하는 컨텐츠 식별 정보, 상기 화면의 맨위 아래 표시되거나 감춤된 적어도 하나의 브라우져에 로딩된 적어도 하나의 페이지를 통해 수행되는 적어도 하나 의 워크플로를 설명하는 워크플로 중 적어도 하나의 정보를 더 포함할 수 있다. 도면1에 따르면, 상기 행위상태정보 수신부는 상기 저장된 P'개의 이미지와 P'개의 메타정보의 조합을 포 함하는 대상자의 행위 확인 정보를 지정된 관리자의 단말로 제공하여 상기 관리자에 의해 상기 대상자의 행위 확인 정보를 근거로 상기 대상자의 행위 상태를 판단하여 설정한 p(1≤p≤P)개의 행위 상태 정보를 수신하고 상 기 p개의 행위 상태 정보에 대응하는 p개의 이미지와 p개의 메타정보를 확인한다. 여기서, 상기 대상자의 행위 확인 정보는, 상기 대상자가 g개의 단말을 이용하면서 행하는 주어진 행위의 범주에 대응하는 대상자의 행위 범주 정보를 더 포함할 수 있다. 여기서, 관리자의 단말로 P'개의 이미지 와 P'개의 메타정보의 조합 외에 대상자의 행위 범주 정보를 더 제공 가능하며, 이 경우 관리자는 P'개의 메타 정보 외에 대상자의 행위 범주 정보를 더 이용하여 대상자의 행위 상태를 판단할 수 있다. 본 발명의 실시 방법에 따르면, 상기 행위상태정보 수신부는 상기 관리자의 단말로부터 p개의 행위 상태 정보를 수신하고, 상기 저장된 P'개의 이미지와 P'개의 메타정보 중 상기 p개의 행위 상태 정보에 대응하 는 p개의 이미지와 p개의 메타정보를 확인할 수 있다. 또한 상기 행위상태정보 수신부는 상기 관리자의 단말로부터 p개의 이미지와 p개의 메타정보 및 p개 의 행위 상태 정보를 수신할 수 있다. 도면1에 따르면, 인공지능 학습부는 상기 확인된 p개의 이미지와 p개의 메타정보 및 p개의 행위 상태 정보 를 포함하여 구성된 학습데이터를 지정된 인공지능모듈에 적용하여 학습시킨다. 본 발명의 실시 방법에 따르면, 상기 인공지능 학습부는 대상자가 이용하는 단말의 화면을 캡쳐하여 상기 대상자의 단말 이용을 관측한 특징에 대응하는 상기 p개의 이미지와 p개의 메타정보를 포함하는 입력정보 (Feature Vectors)와 상기 대상자의 단말 기반 행위의 관측된 결과에 대응하는 p개의 행위 상태 정보를 포함하 는 출력정보(Label)를 포함하는 학습데이터를 지정된 인공지능모듈에 적용하여 학습시킬 수 있다. 여기서, 상기 학습데이터는. 상기 대상자가 g개의 단말을 이용하면서 행하는 주어진 행위의 범주에 대응하 는 대상자의 행위 범주 정보를 더 포함할 수 있다. 또한, 본 발명의 실시 방법에 따르면, 상기 인공지능 학습부는 대상자가 이용하는 단말의 화면을 캡 쳐하여 상기 대상자의 단말 이용을 관측한 특징에 대응하는 상기 p개의 이미지와 p개의 메타정보 및 대상자의 행위 범주 정보를 포함하는 입력정보와 상기 대상자의 단말 기반 행위의 관측된 결과에 대응하는 p개의 행위 상 태 정보를 포함하는 출력정보를 포함하는 학습데이터를 지정된 인공지능모듈에 적용하여 학습시킬 수 있다. 한편, 도면1을 참조하면, 분할 시간 구간의 행위 상태 분석과 관련된 일의적 이미지에 해당하는 이미지와 상기 이미지를 설명하는 메타정보를 확인하는 이미지 확인부와, 상기 확인된 이미지와 메타정보의 조합을 포함 하는 사용자의 행위 확인 정보를 상기 인공지능모듈에 대입하여 상기 사용자의 행위 상태 정보를 분석하는 정보 분석부를 포함하여 구성될 수 있다. 도면1에 따르면, 상기 이미지 확인부는, 캡쳐 가능한 s(s≥1)개의 화면을 구비한 m(m≥1)개의 단말을 이용 하여 S(S= )개의 화면을 주시 가능한 상태에서 주어진 행위를 행하는 사용자의 행위 상태를 분석하기 위해 설정된 t(t≥1)개의 행위 시간을 포함하는 전체 행위 시간을 기 설정된 시간 단위로 분할한 N(N≥2)개의 분할 시간 구간 중 현재 시점의 제n(1≤n≤N)차 분할 시간 구간에 활성화된 상태에 대응하는 적어도 하나의 화 면을 기 설정된 이미지 획득 규칙에 따라 캡쳐하여 획득된 적어도 하나의 이미지를 근거로 상기 제n차 분할 시 간 구간의 행위 상태 분석과 관련된 일의적 이미지에 해당하는 in(1≤n≤N)(in≥1)개의 제n차 이미지와 상기 in개의 제n차 이미지를 설명하는 in개의 메타정보를 확인한다. 여기서, 상기 행위는, 사용자가 단말을 이용하여 지정된 목적을 달성하기 위해 의지를 가지고 행하는 것을 포함할 수 있다. 또한, 상기 행위는, 사용자가 적어도 하나의 단말을 이용하여 업무를 행하는 것, 사용자 가 적어도 하나의 단말을 이용하여 비대면 수업에 참가하는 것, 사용자가 적어도 하나의 단말을 이용 하여 비대면 학습을 행하는 것 중 적어도 하나를 포함할 수 있다. 한편, 상기 주어진 행위를 행하는 사용자의 행위 상태를 분석하기 위해 설정된 t개의 행위 시간은, 사용자의 행 위 가능 시간 중 지정된 행위를 행하도록 설정된 시간, 사용자의 행위 가능 시간 중 지정된 비행위 시간을 제외 한 시간 중 적어도 하나의 시간을 포함할 수 있다. 여기서 상기 비행위 시간은, 휴식 시간, 식사 시간, 적어도 하나의 단말을 이용하지 않도록 설정되거나 단말을 이용 불가한 행위 시간 중 적어도 하나의 시간을 포함 할 수 있다. 한편, 상기 전체 행위 시간은, 상기 t개의 행위 시간의 합을 포함할 수 있다. 또한, 상기 시간 단위는, 단말 화면 기반 행위 상태 분석을 위해 주기적으로 화면을 캡쳐하여 이미지를 획득하 도록 설정된 특정 시간 단위를 포함할 수 있다. 예컨대, 상기 시간 단위는 1분 단위를 기본으로 할 수 있지만, 당업자의 선택이나 사용자가 행하는 행위의 종류에 따라 2분 단위, 3분 단위, …, 10분 단위 등, 다양하게 설정 가능하다. 한편, 상기 S개의 화면은, 사용자가 주어진 행위를 행하기 위해 이용하도록 설정된 단말의 화면 외에 사용 자의 행위 시간 동안 사용자가 이용 가능한 단말이나 사용자가 휴대하거나 소지한 단말의 화면을 더 포함할 수 있다. 한편, 상기 이미지 획득 규칙은, 지정된 분할 시간 구간에 활성화된 상태를 포함하는 e(1≤e≤S)개의 화면으로 부터 상기 분할 시간 구간의 지정된 캡쳐 시점에 e개의 대표 이미지를 캡쳐하여 획득하는 규칙을 포함할 수 있 으며, 지정된 분할 시간 구간에 활성화된 상태를 포함하는 화면이 부재한 경우 상기 대표 이미지의 캡쳐를 생략 하는 규칙을 더 포함할 수 있다. 또한, 상기 이미지 획득 규칙은, 지정된 분할 시간 구간에 활성화된 상태를 포함하는 e(1≤e≤S)개의 화면 중 적어도 하나의 지정된 액션이 인식된 k(1≤k≤e)개의 화면을 통해 기 설정된 R(R≥1)개의 액션 중 지정된 r(1≤ r≤R)개의 액션이 인식되는 경우에 상기 k개의 화면으로부터 지정된 액션이 인식된 액션 인식 시점 별로 r개의 특징 이미지를 캡쳐하여 획득하는 규칙을 포함할 수 있으며, 지정된 분할 시간 구간에 활성화된 상태를 포함하는 화면이 부재하거나 지정된 액션이 인식된 화면이 부재한 경우 상기 특징 이미지의 캡쳐를 생략하는 규칙을 더 포함할 수 있다. 또한, 상기 이미지 획득 규칙은, 지정된 분할 시간 구간에 활성화된 상태를 포함하는 e(1≤e≤S)개의 화면으로 부터 상기 분할 시간 구간의 지정된 캡쳐 시점에 e개의 대표 이미지를 캡쳐하여 획득하는 규칙과, 상기 활성하 된 e개의 화면 중 적어도 하나의 지정된 액션이 인식된 k(1≤k≤e)개의 화면을 통해 기 설정된 R(R≥1)개의 액 션 중 지정된 r(1≤r≤R)개의 액션이 인식되는 경우에 상기 k개의 화면으로부터 지정된 액션이 인식된 액션 인 식 시점 별로 r개의 특징 이미지를 캡쳐하여 획득하는 규칙의 조합을 포함할 수 있다. 여기서, 상기 이미지 획득 규칙은, 지정된 분할 시간 구간에 활성화된 상태를 포함하는 화면이 부재한 경우 상 기 대표 이미지의 캡쳐를 생략하는 규칙, 또는 지정된 분할 시간 구간에 활성화된 상태를 포함하는 화면이 부재 하거나 지정된 액션이 인식된 화면이 부재한 경우 상기 특징 이미지의 캡쳐를 생략하는 규칙을 더 포함할 수 있 다. 한편, 상기 분할 시간 구간의 행위 상태 분석과 관련된 일의적 이미지는, 제(n-1)((n-1)≥1)차 분할 시간 구간 에 대응하는 이미지와 다른 이미지, 화면의 맨위 표시된 애플리케이션이 사용자의 지정된 행위 범주와 관련된 특정 애플리케이션을 포함하는 이미지, 화면의 맨위 표시된 인터페이스 화면이 사용자의 지정된 행위 범주와 관 련된 인터페이스 화면을 포함하는 이미지, 지정된 액션을 근거로 획득된 이미지, 사용자의 지정된 행위 범주와 관련된 워크플로(workflow)에 대응하는 이미지 중 적어도 하나의 이미지를 포함할 수 있다. 한편, 상기 in개의 제n차 이미지를 설명하는 in개의 메타정보는, 상기 제n차 분할 시간 구간에 활성화된 상태에 대응하는 적어도 하나의 화면을 캡쳐하여 이미지를 획득하는 과정과 연동하여 생성된 화면 메타정보를 근거로 생성될 수 있다. 여기서 상기 화면 메타정보는, 상기 이미지를 캡쳐한 시점을 식별 가능한 시점 식별 정보, 상기 이미지를 캡쳐 한 화면을 식별 가능한 화면 식별 정보, 상기 이미지를 캡쳐한 단말을 식별 가능한 단말 식별 정보, 지정된 액 션을 근거로 이미지를 캡쳐한 경우 상기 이미지에 대응하는 액션을 분류하는 액션 분류 정보, 지정된 액션을 근 거로 캡쳐된 이미지에 대응하는 액션을 확인 가능한 액션 확인 정보, 상기 화면의 맨위 표시된 애플리케이션을 식별하는 애플리케이션 식별 정보, 상기 화면의 맨위 표시된 애플리케이션의 인터페이스 화면을 식별하는 인터 페이스 식별 정보, 상기 화면의 맨위 표시된 애플리케이션을 통해 표시된 컨텐츠를 식별하는 컨텐츠 식별 정보, 상기 화면의 맨위 표시된 애플리케이션을 통해 수행되는 적어도 하나의 워크플로를 설명하는 워크플로 정보, 상 기 화면의 맨위 표시된 브라우져에 로딩된 페이지를 식별하는 애플리케이션 식별 정보, 상기 화면의 맨위 표시 된 브라우져에 로딩된 페이지의 인터페이스 화면을 식별하는 인터페이스 식별 정보, 상기 화면의 맨위 표시된 브라우져에 로딩된 페이지를 통해 표시된 컨텐츠를 식별하는 컨텐츠 식별 정보, 상기 화면의 맨위 표시된 브라 우져에 로딩된 페이지를 통해 수행되는 적어도 하나의 워크플로를 설명하는 워크플로 정보 중 적어도 하나의 정 보를 포함할 수 있다. 또한, 상기 화면 메타정보는, 상기 화면의 맨위 아래 표시되거나 감춤된 적어도 하나의 애플리케이션을 식별하 는 애플리케이션 식별 정보, 상기 화면의 맨위 아래 표시되거나 감춤된 적어도 하나의 애플리케이션의 인터페이 스 화면을 식별하는 인터페이스 식별 정보, 상기 화면의 맨위 아래 표시되거나 감춤된 적어도 하나의 애플리케 이션을 통해 표시된 컨텐츠를 식별하는 컨텐츠 식별 정보, 상기 화면의 맨위 아래 표시되거나 감춤된 적어도 하 나의 애플리케이션을 통해 수행되는 적어도 하나의 워크플로를 설명하는 워크플로 정보, 상기 화면의 맨위 아래 표시되거나 감춤된 적어도 하나의 브라우져에 로딩된 적어도 하나의 페이지를 식별하는 애플리케이션 식별 정보, 상기 화면의 맨위 아래 표시되거나 감춤된 적어도 하나의 브라우져에 적어도 하나의 로딩된 페이지의 인 터페이스 화면을 식별하는 인터페이스 식별 정보, 상기 화면의 맨위 아래 표시되거나 감춤된 적어도 하나의 브 라우져에 로딩된 적어도 하나의 페이지를 통해 표시된 컨텐츠를 식별하는 컨텐츠 식별 정보, 상기 화면의 맨위 아래 표시되거나 감춤된 적어도 하나의 브라우져에 로딩된 적어도 하나의 페이지를 통해 수행되는 적어도 하나의 워크플로를 설명하는 워크플로 중 적어도 하나의 정보를 더 포함할 수 있다. 한편, 본 발명의 상기 사용자의 단말로부터 이미지를 획득하는 제1 실시예에 따르면, 사용자가 이용하는 단말의 프로그램은 현재 시점에 대응하는 제n차 분할 시간 구간에 활성화된 상태에 대응하는 적어도 하나 의 화면을 확인하고, 상기 제n차 분할 시간 구간에 활성화된 상태에 대응하는 적어도 하나의 화면을 확인한 경 우, 상기 제n차 분할 시간 구간의 지정된 캡쳐 시점에 상기 활성화된 상태에 대응하는 적어도 하나의 화면을 캡 쳐한 적어도 하나의 대표 이미지를 획득한 후, 상기 획득된 적어도 하나의 대표 이미지를 상기 운영서버 (이미지 확인부)로 전송할 수 있다. 여기서, 상기 단말의 프로그램은, N개의 분할 시간 구간 중 현재 시점에 대응하는 제n차 분할 시간 구간을 확인할 수 있다. 또한, 상기 단말의 프로그램은, 상기 제n차 분할 시간 구간 중에 대표 이미지를 획득하도록 설정된 지정된 캡쳐 시점이 도래하는지 확인할 수 있다. 또한, 상기 단말의 프로그램은, 상기 획득된 대표 이미지를 설명하는 화면 메타정보를 생성할 수 있다. 또한, 상기 단말의 프로그램은, 상기 획득된 대표 이미지에 상기 생성된 화면 메타정보를 첨부하여 상기 운영서버(이미지 확인부)로 전송할 수 있다. 상기 이미지 확인부는, 사용자가 이용하는 m개의 단말 중 제n차 분할 시간 구간에 활성화된 상태를 대응하는 화면을 구비한 m'(1≤m'≤m)개의 단말의 프로그램으로부터 상기 제n차 분할 시간 구간의 지정된 캡쳐 시점에 상기 활성화된 상태를 대응하는 en(1≤n≤N)(1≤en≤S)개의 화면을 캡쳐하여 획득된 en개의 대표 이미지 를 수신하고, 상기 수신된 en개의 대표 이미지를 근거로 상기 제n차 분할 시간 구간의 행위 상태 분석과 관련된 일의적 이미지에 해당하는 in(1≤in≤en)개의 제n차 이미지를 확인할 수 있다. 여기서, 상기 in개의 제n차 이미지는, 상기 en개의 대표 이미지를 그대로 포함하거나, 또는 상기 en개의 대표 이 미지 중에서 일부 선택된 이미지를 포함할 수 있다. 또한, 상기 이미지 확인부는, 상기 en개의 대표 이미지를 설명하는 en개의 화면 메타정보를 수신할 수 있으 며, 여기서 상기 in개의 메타정보는, 상기 en개의 화면 메타정보를 근거로 확인되는 것이 바람직하다. 상기 화면 메타정보는, 상기 대표 이미지를 캡쳐한 시점을 식별 가능한 시점 식별 정보, 상기 대표 이미지를 캡 쳐한 화면을 식별 가능한 화면 식별 정보, 상기 대표 이미지를 캡쳐한 단말을 식별 가능한 단말 식별 정보, 상 기 화면의 맨위 표시된 애플리케이션을 식별하는 애플리케이션 식별 정보, 상기 화면의 맨위 표시된 애플리케이 션의 인터페이스 화면을 식별하는 인터페이스 식별 정보, 상기 화면의 맨위 표시된 애플리케이션을 통해 표시된 컨텐츠를 식별하는 컨텐츠 식별 정보, 상기 화면의 맨위 표시된 애플리케이션을 통해 수행되는 적어도 하나의 워크플로를 설명하는 워크플로 정보, 상기 화면의 맨위 표시된 브라우져에 로딩된 페이지를 식별하는 애플리케 이션 식별 정보, 상기 화면의 맨위 표시된 브라우져에 로딩된 페이지의 인터페이스 화면을 식별하는 인터페이스 식별 정보, 상기 화면의 맨위 표시된 브라우져에 로딩된 페이지를 통해 표시된 컨텐츠를 식별하는 컨텐츠 식별 정보, 상기 화면의 맨위 표시된 브라우져에 로딩된 페이지를 통해 수행되는 적어도 하나의 워크플로를 설명하는워크플로 정보 중 적어도 하나의 정보를 포함할 수 있다. 또한, 상기 화면 메타정보는, 상기 화면의 맨위 아래 표시되거나 감춤된 적어도 하나의 애플리케이션을 식별하 는 애플리케이션 식별 정보, 상기 화면의 맨위 아래 표시되거나 감춤된 적어도 하나의 애플리케이션의 인터페이 스 화면을 식별하는 인터페이스 식별 정보, 상기 화면의 맨위 아래 표시되거나 감춤된 적어도 하나의 애플리케 이션을 통해 표시된 컨텐츠를 식별하는 컨텐츠 식별 정보, 상기 화면의 맨위 아래 표시되거나 감춤된 적어도 하 나의 애플리케이션을 통해 수행되는 적어도 하나의 워크플로를 설명하는 워크플로 정보, 상기 화면의 맨위 아래 표시되거나 감춤된 적어도 하나의 브라우져에 로딩된 적어도 하나의 페이지를 식별하는 애플리케이션 식별 정보, 상기 화면의 맨위 아래 표시되거나 감춤된 적어도 하나의 브라우져에 적어도 하나의 로딩된 페이지의 인 터페이스 화면을 식별하는 인터페이스 식별 정보, 상기 화면의 맨위 아래 표시되거나 감춤된 적어도 하나의 브 라우져에 로딩된 적어도 하나의 페이지를 통해 표시된 컨텐츠를 식별하는 컨텐츠 식별 정보, 상기 화면의 맨위 아래 표시되거나 감춤된 적어도 하나의 브라우져에 로딩된 적어도 하나의 페이지를 통해 수행되는 적어도 하나 의 워크플로를 설명하는 워크플로 중 적어도 하나의 정보를 더 포함할 수 있다. 또한, 상기 이미지 확인부는, 상기 en개의 화면 메타정보를 근거로 상기 in개의 제n차 이미지를 설명하는 in개의 메타정보를 확인할 수 있다. 한편, 본 발명의 상기 사용자의 단말로부터 이미지를 획득하는 제2 실시예에 따르면, 사용자가 이용하는 단말의 프로그램은 현재 시점에 대응하는 제n차 분할 시간 구간에 활성화된 상태에 대응하는 적어도 하나 의 화면을 확인하고, 상기 제n차 분할 시간 구간에 활성화된 상태에 대응하는 적어도 하나의 화면을 확인한 경 우, 상기 활성화된 상태에 대응하는 적어도 하나의 화면을 판독하여 기 설정된 R(R≥1)개의 액션 중 지정된 액 션에 대응하는 화면을 인식하고, 지정된 액션이 인식된 화면을 캡쳐한 적어도 하나의 특징 이미지를 획득한 후, 상기 획득된 적어도 하나의 특징 이미지를 상기 운영서버(이미지 확인부)로 전송할 수 있다. 여기서, 상기 사용자가 이용하는 단말의 프로그램은, N개의 분할 시간 구간 중 현재 시점에 대응하는 제n 차 분할 시간 구간을 확인할 수 있다. 또한, 상기 사용자가 이용하는 단말의 프로그램은, 상기 제n차 분할 시간 구간 중에 상기 활성화된 상태에 대응하는 적어도 하나의 화면을 지정된 주기로 판독하거나 지정된 액션에 대응하는 이벤트 발생을 검출하여 기 설정된 R개의 액션 중 지정된 액션을 인식할 수 있다. 또한, 상기 사용자가 이용하는 단말의 프로그램은, 상기 획득된 특징 이미지를 설명하는 화면 메타정보를 생성할 수 있다. 또한, 상기 사용자가 이용하는 단말의 프로그램은, 상기 획득된 특징 이미지에 상기 생성된 화면 메타정보 를 첨부하여 상기 운영서버(이미지 확인부)로 전송할 수 있다. 상기 이미지 확인부는, 사용자가 이용하는 m개의 단말 중 제n차 분할 시간 구간에 활성화된 상태를 대응하는 화면을 구비한 m'(1≤m'≤m)개의 단말의 프로그램으로부터 상기 제n차 분할 시간 구간에 활성화 된 상태를 대응하는 en(1≤n≤N)(1≤en≤S)개의 화면 별로 기 설정된 R(R≥1)개의 액션 중 지정된 액션에 대응하는 화면을 인식하여 적어도 하나의 지정된 액션이 인식된 kn(1≤n≤N)(1≤kn≤en)개의 화면을 지정된 액션 인식 시점 별 로 캡쳐하여 획득된 rn(1≤n≤N)(1≤rn≤R, rn≥kn)개의 특징 이미지를 수신하고, 상기 수신된 rn개의 특징 이미지를근거로 상기 제n차 분할 시간 구간의 행위 상태 분석과 관련된 일의적 이미지에 해당하는 in(1≤in≤rn)개의 제n 차 이미지를 확인할 수 있다. 여기서, 상기 R개의 액션은, 사용자의 지정된 행위 범주와 관련된 특정 애플리케이션을 구동하는 액션, 사용자 의 지정된 행위 범주와 관련된 특정 애플리케이션의 지정된 인터페이스 화면을 호출하거나 조작하는 액션, 페이 지를 로딩 가능한 브라우져를 구동하는 액션, 브라우져를 통해 사용자의 지정된 행위 범주와 관련된 페이지를 로딩하거나 조작하는 액션, 특정 애플리케이션이나 브라우져를 통해 사용자의 지정된 행위 범주와 관련된 컨텐 츠(예컨대, 문자, 이미지, 사운드, 동영상, 3D객체 등)를 로딩하거나 조작하는 액션, 특정 애플리케이션을 통해 사용자의 지정된 행위 범주와 관련된 워크플로(workflow)에 대응하는 인터페이스 화면을 호출하거나 조작하는 액션, 브라우져를 통해 사용자의 지정된 행위 범주와 관련된 워크플로에 대응하는 페이지를 로딩하거나 조작하 는 액션 중 적어도 하나의 액션을 포함할 수 있다. 또한, 상기 R개의 액션은, 사용자의 지정된 행위 범주와 무관한 애플리케이션을 구동하는 액션, 사용자의 지정 된 행위 범주와 무관한 애플리케이션을 조작하는 액션, 브라우져를 통해 사용자의 지정된 행위 범주와 무관한 페이지를 로딩하거나 조작하는 액션, 애플리케이션이나 브라우져를 통해 사용자의 지정된 행위 범주와 무관한 컨텐츠를 로딩하거나 조작하는 액션, 애플리케이션이나 브라우져를 통해 사용자의 지정된 행위 범주나 워크플로 와 무관한 서버에 접속하거나 상기 사용자의 지정된 행위 범주나 워크플로와 무관한 서버로부터 파일이나 데이 터를 다운로드하거나 상기 사용자의 지정된 행위 범주나 워크플로와 무관한 서버로 파일이나 데이터를 전송하는 액션, 단말의 외부 저장장치에 파일이나 데이터를 저장하는 액션 중 적어도 하나의 액션을 더 포함할 수 있다. 한편, 상기 분할 시간 구간의 행위 상태 분석과 관련된 일의적 이미지에 해당하는 in개의 제n차 이미지는, 상기 rn개의 특징 이미지를 그대로 포함하거나, 또는 상기 rn개의 특징 이미지 중에서 일부 선택된 이미지를 포함할 수 있다. 또한, 상기 이미지 확인부는, 상기 rn개의 특징 이미지를 설명하는 rn개의 화면 메타정보를 수신할 수 있으 며, 상기 in개의 메타정보는, 상기 rn개의 화면 메타정보를 근거로 확인되는 것이 바람직하다. 여기서, 상기 화면 메타정보는, 상기 특징 이미지를 캡쳐한 시점을 식별 가능한 시점 식별 정보, 상기 특징 이 미지를 캡쳐한 화면을 식별 가능한 화면 식별 정보, 상기 특징 이미지를 캡쳐한 단말을 식별 가능한 단말 식별 정보, 상기 특징 이미지에 대응하는 액션을 분류하는 액션 분류 정보, 상기 특징 이미지에 대응하는 액션을 확 인 가능한 액션 확인 정보, 상기 화면의 맨위 표시된 애플리케이션을 식별하는 애플리케이션 식별 정보, 상기 화면의 맨위 표시된 애플리케이션의 인터페이스 화면을 식별하는 인터페이스 식별 정보, 상기 화면의 맨위 표시 된 애플리케이션을 통해 표시된 컨텐츠를 식별하는 컨텐츠 식별 정보, 상기 화면의 맨위 표시된 애플리케이션을 통해 수행되는 적어도 하나의 워크플로를 설명하는 워크플로 정보, 상기 화면의 맨위 표시된 브라우져에 로딩된 페이지를 식별하는 애플리케이션 식별 정보, 상기 화면의 맨위 표시된 브라우져에 로딩된 페이지의 인터페이스 화면을 식별하는 인터페이스 식별 정보, 상기 화면의 맨위 표시된 브라우져에 로딩된 페이지를 통해 표시된 컨 텐츠를 식별하는 컨텐츠 식별 정보, 상기 화면의 맨위 표시된 브라우져에 로딩된 페이지를 통해 수행되는 적어 도 하나의 워크플로를 설명하는 워크플로 정보 중 적어도 하나의 정보를 포함할 수 있다. 또한, 상기 화면 메타정보는, 상기 화면의 맨위 아래 표시되거나 감춤된 적어도 하나의 애플리케이션을 식별하 는 애플리케이션 식별 정보, 상기 화면의 맨위 아래 표시되거나 감춤된 적어도 하나의 애플리케이션의 인터페이 스 화면을 식별하는 인터페이스 식별 정보, 상기 화면의 맨위 아래 표시되거나 감춤된 적어도 하나의 애플리케 이션을 통해 표시된 컨텐츠를 식별하는 컨텐츠 식별 정보, 상기 화면의 맨위 아래 표시되거나 감춤된 적어도 하 나의 애플리케이션을 통해 수행되는 적어도 하나의 워크플로를 설명하는 워크플로 정보, 상기 화면의 맨위 아래표시되거나 감춤된 적어도 하나의 브라우져에 로딩된 적어도 하나의 페이지를 식별하는 애플리케이션 식별 정보, 상기 화면의 맨위 아래 표시되거나 감춤된 적어도 하나의 브라우져에 적어도 하나의 로딩된 페이지의 인 터페이스 화면을 식별하는 인터페이스 식별 정보, 상기 화면의 맨위 아래 표시되거나 감춤된 적어도 하나의 브 라우져에 로딩된 적어도 하나의 페이지를 통해 표시된 컨텐츠를 식별하는 컨텐츠 식별 정보, 상기 화면의 맨위 아래 표시되거나 감춤된 적어도 하나의 브라우져에 로딩된 적어도 하나의 페이지를 통해 수행되는 적어도 하나 의 워크플로를 설명하는 워크플로 중 적어도 하나의 정보를 더 포함할 수 있다. 또한, 상기 이미지 확인부는, 상기 rn개의 화면 메타정보를 근거로 상기 in개의 제n차 이미지를 설명하는 in개의 메타정보를 확인할 수 있다. 한편, 본 발명의 상기 사용자의 단말로부터 이미지를 획득하는 제3 실시예에 따르면, 사용자가 이용하는 단말의 프로그램은, 현재 시점에 대응하는 제n차 분할 시간 구간에 활성화된 상태에 대응하는 적어도 하나 의 화면을 확인하고, 상기 제n차 분할 시간 구간에 활성화된 상태에 대응하는 적어도 하나의 화면을 확인한 경 우, 상기 제n차 분할 시간 구간의 지정된 캡쳐 시점에 상기 활성화된 상태에 대응하는 적어도 하나의 화면을 캡 쳐한 적어도 하나의 대표 이미지를 획득하는 절차를 수행하고, 상기 활성화된 상태에 대응하는 적어도 하나의 화면을 판독하여 기 설정된 R(R≥1)개의 액션 중 지정된 액션에 대응하는 화면을 인식하는 절차를 수행하여 지 정된 액션이 인식된 화면을 캡쳐한 적어도 하나의 특징 이미지를 획득한 후, 적어도 하나의 대표 이미지를 획득 한 경우 상기 획득된 적어도 하나의 대표 이미지를 상기 운영서버(이미지 확인부)로 전송하고, 적어 도 하나의 특징 이미지를 획득한 경우 상기 획득된 적어도 하나의 특징 이미지를 상기 운영서버(이미지 확 인부)로 전송할 수 있다. 여기서, 상기 사용자가 이용하는 단말의 프로그램은, N개의 분할 시간 구간 중 현재 시점에 대응하는 제n 차 분할 시간 구간을 확인할 수 있다. 또한, 상기 사용자가 이용하는 단말의 프로그램은, 상기 제n차 분할 시간 구간 중에 대표 이미지를 획득하 도록 설정된 지정된 캡쳐 시점이 도래하는지 확인할 수 있다. 또한, 상기 사용자가 이용하는 단말의 프로그램은, 상기 획득된 대표 이미지를 설명하는 화면 메타정보를 생성할 수 있으며, 상기 획득된 대표 이미지에 상기 생성된 화면 메타정보를 첨부하여 상기 운영서버(이미 지 확인부)로 전송할 수 있다. 또한, 상기 사용자가 이용하는 단말의 프로그램은, 상기 획득된 특징 이미지를 설명하는 화면 메타정보를 생성할 수 있으며, 상기 획득된 특징 이미지에 상기 생성된 화면 메타정보를 첨부하여 상기 운영서버(이미 지 확인부)로 전송할 수 있다. 한편, 상기 이미지 확인부는, 사용자가 이용하는 m개의 단말 중 제n차 분할 시간 구간에 활성화된 상 태를 대응하는 화면을 구비한 m'(1≤m'≤m)개의 단말의 프로그램으로부터 상기 제n차 분할 시간 구간의 지 정된 캡쳐 시점에 상기 활성화된 상태를 대응하는 en(1≤n≤N)(1≤en≤S)개의 화면을 캡쳐하여 획득된 en개의 대표 이미지를 수신하고, 상기 제n차 분할 시간 구간에 활성화된 상태를 대응하는 en개의 화면 별로 기 설정된 R(R≥ 1)개의 액션 중 지정된 액션에 대응하는 화면을 인식하는 절차를 수행하여 적어도 하나의 지정된 액션이 인식된 kn(1≤n≤N)(1≤kn≤en)개의 화면을 지정된 액션 인식 시점 별로 캡쳐하여 획득된 rn(1≤n≤N)(1≤rn≤R, rn≥kn)개의 특 징 이미지를 수신하고, 상기 수신된 en개의 대표 이미지와 rn개의 특징 이미지를 근거로 상기 제n차 분할 시간 구간의 행위 상태 분석과 관련된 일의적 이미지에 해당하는 in(1≤in≤(en+rn))개의 제n차 이미지를 확인할 수있다. 여기서, 상기 R개의 액션은, 사용자의 지정된 행위 범주와 관련된 특정 애플리케이션을 구동하는 액션, 사용자 의 지정된 행위 범주와 관련된 특정 애플리케이션의 지정된 인터페이스 화면을 호출하거나 조작하는 액션, 페이 지를 로딩 가능한 브라우져를 구동하는 액션, 브라우져를 통해 사용자의 지정된 행위 범주와 관련된 페이지를 로딩하거나 조작하는 액션, 특정 애플리케이션이나 브라우져를 통해 사용자의 지정된 행위 범주와 관련된 컨텐 츠(예컨대, 문자, 이미지, 사운드, 동영상, 3D객체 등)를 로딩하거나 조작하는 액션, 특정 애플리케이션을 통해 사용자의 지정된 행위 범주와 관련된 워크플로(workflow)에 대응하는 인터페이스 화면을 호출하거나 조작하는 액션, 브라우져를 통해 사용자의 지정된 행위 범주와 관련된 워크플로에 대응하는 페이지를 로딩하거나 조작하 는 액션 중 적어도 하나의 액션을 포함할 수 있다. 또한, 상기 R개의 액션은, 사용자의 지정된 행위 범주와 무관한 애플리케이션을 구동하는 액션, 사용자의 지정 된 행위 범주와 무관한 애플리케이션을 조작하는 액션, 브라우져를 통해 사용자의 지정된 행위 범주와 무관한 페이지를 로딩하거나 조작하는 액션, 애플리케이션이나 브라우져를 통해 사용자의 지정된 행위 범주와 무관한 컨텐츠를 로딩하거나 조작하는 액션, 애플리케이션이나 브라우져를 통해 사용자의 지정된 행위 범주나 워크플로 와 무관한 서버에 접속하거나 상기 사용자의 지정된 행위 범주나 워크플로와 무관한 서버로부터 파일이나 데이 터를 다운로드하거나 상기 사용자의 지정된 행위 범주나 워크플로와 무관한 서버로 파일이나 데이터를 전송하는 액션, 단말의 외부 저장장치에 파일이나 데이터를 저장하는 액션 중 적어도 하나의 액션을 더 포함할 수 있다. 또한, 상기 제n차 분할 시간 구간의 행위 상태 분석과 관련된 일의적 이미지에 해당하는 in개의 제n차 이미지는, 상기 en개의 대표 이미지와 rn개의 특징 이미지를 그대로 포함하거나, 또는 상기 en개의 대표 이미지와 rn개의 특 징 이미지 중에서 일부 선택된 이미지를 포함할 수 있다. 또한, 상기 이미지 확인부는, 상기 en개의 대표 이미지를 설명하는 en개의 화면 메타정보와 상기 rn개의 특 징 이미지를 설명하는 개의 rn개의 화면 메타정보를 수신할 수 있으며, 상기 in개의 메타정보는, 상기 en개의 화 면 메타정보와 rn개의 화면 메타정보 중 적어도 하나의 화면 메타정보를 근거로 확인되는 것이 바람직하다. 여기서, 상기 화면 메타정보는, 상기 대표 이미지 또는 특징 이미지를 캡쳐한 시점을 식별 가능한 시점 식별 정 보, 상기 대표 이미지 또는 특징 이미지를 캡쳐한 화면을 식별 가능한 화면 식별 정보, 상기 대표 이미지 또는 특징 이미지를 캡쳐한 단말을 식별 가능한 단말 식별 정보, 상기 특징 이미지에 대응하는 액션을 분류하는 액션 분류 정보, 상기 특징 이미지에 대응하는 액션을 확인 가능한 액션 확인 정보, 상기 화면의 맨위 표시된 애플리 케이션을 식별하는 애플리케이션 식별 정보, 상기 화면의 맨위 표시된 애플리케이션의 인터페이스 화면을 식별 하는 인터페이스 식별 정보, 상기 화면의 맨위 표시된 애플리케이션을 통해 표시된 컨텐츠를 식별하는 컨텐츠 식별 정보, 상기 화면의 맨위 표시된 애플리케이션을 통해 수행되는 적어도 하나의 워크플로를 설명하는 워크플 로 정보, 상기 화면의 맨위 표시된 브라우져에 로딩된 페이지를 식별하는 애플리케이션 식별 정보, 상기 화면의 맨위 표시된 브라우져에 로딩된 페이지의 인터페이스 화면을 식별하는 인터페이스 식별 정보, 상기 화면의 맨위 표시된 브라우져에 로딩된 페이지를 통해 표시된 컨텐츠를 식별하는 컨텐츠 식별 정보, 상기 화면의 맨위 표시 된 브라우져에 로딩된 페이지를 통해 수행되는 적어도 하나의 워크플로를 설명하는 워크플로 정보 중 적어도 하 나의 정보를 포함할 수 있다. 또한, 상기 화면 메타정보는, 상기 화면의 맨위 아래 표시되거나 감춤된 적어도 하나의 애플리케이션을 식별하 는 애플리케이션 식별 정보, 상기 화면의 맨위 아래 표시되거나 감춤된 적어도 하나의 애플리케이션의 인터페이 스 화면을 식별하는 인터페이스 식별 정보, 상기 화면의 맨위 아래 표시되거나 감춤된 적어도 하나의 애플리케 이션을 통해 표시된 컨텐츠를 식별하는 컨텐츠 식별 정보, 상기 화면의 맨위 아래 표시되거나 감춤된 적어도 하나의 애플리케이션을 통해 수행되는 적어도 하나의 워크플로를 설명하는 워크플로 정보, 상기 화면의 맨위 아래 표시되거나 감춤된 적어도 하나의 브라우져에 로딩된 적어도 하나의 페이지를 식별하는 애플리케이션 식별 정보, 상기 화면의 맨위 아래 표시되거나 감춤된 적어도 하나의 브라우져에 적어도 하나의 로딩된 페이지의 인 터페이스 화면을 식별하는 인터페이스 식별 정보, 상기 화면의 맨위 아래 표시되거나 감춤된 적어도 하나의 브 라우져에 로딩된 적어도 하나의 페이지를 통해 표시된 컨텐츠를 식별하는 컨텐츠 식별 정보, 상기 화면의 맨위 아래 표시되거나 감춤된 적어도 하나의 브라우져에 로딩된 적어도 하나의 페이지를 통해 수행되는 적어도 하나 의 워크플로를 설명하는 워크플로 중 적어도 하나의 정보를 더 포함할 수 있다. 또한, 상기 이미지 확인부는, 상기 en개의 화면 메타정보와 rn개의 화면 메타정보를 근거로 상기 in개의 제 n차 이미지를 설명하는 in개의 메타정보를 확인할 수 있다. 여기서, 상기 이미지 확인부는, 상기 in개의 제 n차 이미지와 in개의 메타정보를 저장할 수 있다. 한편, 상기 이미지 확인부는, 상기 in개의 제n차 이미지에 대응하는 in개의 제n차 이미지 파일을 저장할 수 있다. 여기서 상기 in개의 메타정보는 상기 이미지 파일에 설정된 메타정보 영역에 저장되거나, 상기 이미지 파 일과 연계된 별도 데이터 파일에 저장될 수 있다. 또한, 상기 이미지 확인부는, 지정된 C(C=(N*S))개의 셀 영역을 포함하는 이미지 구조의 셀 영역 중 상기 제n차 분할 시간 구간에 대응하는 in(in<C)개의 셀 영역에 상기 in개의 제n차 이미지를 삽입하거나 또는 삽입하 여 저장할 수 있다. 여기서, 상기 이미지 구조는, 상기 C개의 셀 영역을 포함하는 통합 이미지 파일을 포함하거나, 또는 상기 분할 시간 개수에 대응하는 N개의 셀 영역을 포함하는 S개의 이미지 파일을 포함할 수 있다. 상기 S개의 이미지 파일은, 상기 S개의 화면에 일대일 매칭되는 이미지 파일을 포함할 수 있으며, 상기 이미지 구조는, 이미지를 저장 가능한 C개의 셀 영역을 포함하는 지정된 저장 구조의 저장매체를 포함할 수 있다. 여기서, 상기 저장매체는, 상기 C개의 셀 영역을 포함하는 파일을 포함할 수 있다. 예컨대, 이미지 파일(예: *.JPG, *.PNG 등)이 아니라 별도 정의된 데이터 파일에 저장할 수 있다. 또한, 상기 저장매체는, 상기 C개의 셀 영역을 포함하는 데이터베이스를 포함할 수 있다. 예컨대, 이미지 파일 (예: *.JPG, *.PNG 등)에 저장하지 않고, 데이터베이스의 셀에 저장할 수 있다. 상기 C개의 셀 영역은, 상기 분할 시간 개수와 분할 시간 개수의 곱에 일대일 매칭된 개수의 셀 영역인 것이거 나, 또는 상기 분할 시간 개수와 분할 시간 개수의 곱에 일대일 매칭된 개수의 셀 영역을 포함하되, 각 분할 시 간 구간 별 이미지를 삽입하는 과정에서 부족 시 확장 가능한 것이거나, 또는 상기 분할 시간 개수와 분할 시간 개수의 곱에 일대일 매칭된 개수의 셀 영역을 포함하되, N개의 분할 시간 구간 별 이미지를 삽입한 후 미사용 셀 영역 존재시 상기 미사용 셀 영역을 소거하에 축소 가능한 것을 포함할 수 있다. 또한, 상기 이미지 확인부는, 상기 이미지 구조에 설정된 C개의 셀 영역 중 상기 제n차 분할 시간 구간에 대응하는 in개의 제n차 이미지를 삽입할 in개의 셀 영역을 확인할 수 있다. 여기서, 상기 in개의 셀 영역은, 상기 이미지 구조에 설정된 C개의 셀 영역 중 상기 제n차 분할 시간 구간에 대 응하는 이미지를 삽입하도록 설정된 셀 영역을 포함할 수 있다. 예컨대, C개의 셀 영역 중 제n차 분할 시간의 이미지를 셀 영역이 미리 고정하여 설정될 수 있으며, 이 경우 제n차 분할 시간 구간의 이미지 개수가 특정 개 수(예: 화면 개수에 대응하는 S개)로 고정된 경우에 적용 가능하다. 또한, 상기 in개의 셀 영역은, 상기 이미지 구조에 설정된 C개의 셀 영역 중 제1차 내지 제(n-1)((n-1)≥1)차 분할 시간 구간에 대응하는 이미지를 유효 저장한 셀 영역을 제외한 빈 셀 영역 중에서 선택되는 셀 영역을 포 함할 수 있다. 예컨대, C개의 셀 영역 중 제n차 분할 시간의 이미지를 셀 영역이 미리 설정되지 않고 앞선 분할 시간 구간에 이미지를 기 저장한 셀 영역 다음(또는 지정된 규칙에 따라 동적 결정되는) 빈 셀 영역에 제n차 분 할 시간의 이미지를 저장하도록 동적 선택될 수 있으며, 이 경우, 제n차 분할 시간 구간의 이미지 개수가 총 화 면 개수 S개보다 작을 수도 있고, 같을 수도 있고, 클 수도 있는 동적인 경우에 적용 가능하다. 즉 액션 기반으 로 이미지를 캡쳐할 경우 제n차 분할 시간 구간에 액션이 발생하지 않은 경우 제n차 분할 시간 구간의 이미지 개수는 총 화면 개수 S개보다 작을 수 있고, 제n차 분할 시간 구간에 복수의 액션이 발생한 경우 제n차 분할 시 간 구간의 이미지 개수는 총 화면 개수 S개보다 클 수도 있다. 또한, 상기 in개의 메타정보는, 상기 이미지 구조에 설정된 C개의 셀 영역 중 in개의 제n차 이미지를 삽입할 in 개의 셀 영역을 식별하거나 in개의 셀 영역에 랜덤 접근(Random Access)하기 위한 in개의 셀 영역 정보를 포함할 수 있다. 또한, 상기 in개의 메타정보는, 상기 이미지 구조에 설정된 메타정보 영역에 저장될 수 있으며, 상기 메타정보 영역은, 상기 이미지 구조에 설정된 저장영역을 포함할 수 있다. 또한, 상기 in개의 메타정보는, 상기 이미지 구조가 C개의 셀 영역을 포함하는 통합 이미지 파일을 포함하는 경 우, 상기 통합 이미지 파일에 설정된 메타정보 영역에 저장되거나, 또는 상기 이미지 구조가 N개의 셀 영역을 포함하는 S개의 이미지 파일을 포함하는 경우, 상기 S개의 이미지 파일에 설정된 메타정보 영역에 저장되거나, 또는 상기 이미지 구조가 C개의 셀 영역을 포함하는 지정된 저장 구조의 저장매체를 포함하는 경우, 상기 저장 매체에 설정된 메타정보 영역에 저장될 수 있다. 또한, 상기 in개의 메타정보는, 상기 이미지 구조에 설정된 C개의 셀 영역과 매칭된 C개의 메타정보 영역에 저장 될 수 있으며, 상기 C개의 메타정보 영역은, 상기 이미지 구조에 설정된 C개의 저장영역을 포함할 수 있다. 한편, 상기 in개의 메타정보는, 상기 이미지 구조가 C개의 셀 영역을 포함하는 통합 이미지 파일을 포함하는 경 우, 상기 통합 이미지 파일에 설정된 C개의 메타정보 영역에 저장되거나, 또는 상기 이미지 구조가 N개의 셀 영 역을 포함하는 S개의 이미지 파일을 포함하는 경우, 상기 S개의 이미지 파일에 설정된 N개의 메타정보 영역에 저장되거나, 또는 상기 이미지 구조가 C개의 셀 영역을 포함하는 지정된 저장 구조의 저장매체를 포함하는 경우, 상기 저장매체에 설정된 C개의 메타정보 영역에 저장될 수 있다. 또한, 상기 in개의 메타정보는, 상기 이미지 구조와 연계된 별도 데이터 구조에 설정된 메타정보 영역에 저장되 거나, 상기 이미지 구조에 설정된 C개의 셀 영역과 연계된 별도 데이터 구조에 설정된 C개의 메타정보 영역에 저장될 수 있으며, 상기 데이터 구조는, 메타정보를 저장 가능한 별도의 데이터 파일을 포함할 수 있다. 또한, 상기 in개의 메타정보는, 상기 이미지 구조가 C개의 셀 영역을 포함하는 통합 이미지 파일을 포함하는 경 우, 상기 통합 이미지 파일과 연계된 별도 통합 데이터 파일에 설정된 메타정보 영역 또는 C개의 메타정보 영역에 저장되거나, 또는 상기 이미지 구조가 N개의 셀 영역을 포함하는 S개의 이미지 파일을 포함하는 경우, 상기 S개의 이미지 파일과 연계된 별도 통합 데이터 파일에 설정된 메타정보 영역 또는 C개의 메타정보 영역에 저장 되거나, 또는 상기 이미지 구조가 N개의 셀 영역을 포함하는 S개의 이미지 파일을 포함하는 경우, 상기 S개의 이미지 파일과 연계된 S개의 별도 데이터 파일에 설정된 메타정보 영역 또는 C개의 메타정보 영역에 저장되거나, 또는 상기 이미지 구조가 C개의 셀 영역을 포함하는 지정된 저장 구조의 저장매체를 포함하는 경우, 상기 저장매체와 연계된 별도 저장매체에 설정된 메타정보 영역 또는 C개의 메타정보 영역에 저장될 수 있다. 한편, 도면1에 따르면, 상기 정보 분석부는, 상기 확인된 in개의 제n차 이미지와 in개의 메타정보의 조합을 포함하는 사용자의 행위 확인 정보를 상기 인공지능모듈에 대입하여 상기 사용자의 행위 상태 정보를 분석한다. 상기 정보 분석부는, 사용자가 이용하는 단말의 화면을 캡쳐하여 상기 사용자의 단말 이용을 관측한 특징 에 대응하는 상기 in개의 제n차 이미지와 in개의 메타정보를 포함하는 사용자의 행위 확인 정보를 상기 인공지능 모듈의 입력정보로 대입하여 상기 인공지능모듈을 통해 분석된 상기 사용자의 행위 상태 정보를 확인할 수 있다. 여기서, 상기 사용자의 행위 확인 정보는, 상기 사용자가 m개의 단말을 이용하면서 행하는 주어진 행위의 범주에 대응하는 사용자의 행위 범주 정보를 더 포함할 수 있다. 또한, 상기 정보 분석부는, 상기 in개의 제n차 이미지와 in개의 메타정보 및 상기 사용자의 행위 범주 정보 를 포함하는 사용자의 행위 확인 정보를 상기 인공지능모듈에 대입하여 상기 사용자의 행위 상태 정보를 분석할 수 있다. 또한, 상기 정보 분석부는, 사용자가 이용하는 단말의 화면을 캡쳐하여 상기 사용자의 단말 이용을 관측한 특징에 대응하는 상기 in개의 제n차 이미지와 in개의 메타정보 및 상기 사용자의 행위 범주 정보를 포함 하는 사용자의 행위 확인 정보를 상기 인공지능모듈의 입력정보로 대입하여 상기 인공지능모듈을 통해 분석된 상기 사용자의 행위 상태 정보를 확인할 수 있다. 한편, 상기 정보 분석부는, 상기 사용자의 행위 확인 정보와 상기 인공지능모듈을 통해 분석된 사용자의 행위 상태 정보를 상기 사용자가 이용하는 단말이나 지정된 관리자가 이용하는 단말로 제공하여 상기 사용자나 관리자에 의해 수정된 적어도 하나의 행위 상태 정보가 수신되면, 적어도 하나의 행위 상태 정보가 수 정된 경우, 상기 수정된 사용자의 행위 확인 정보와 행위 상태 정보를 포함하는 학습데이터를 상기 인공지능모 듈에 적용하여 학습시킬 수 있다. 도면2는 본 발명의 실시 방법에 따라 대상자의 행위 상태를 설정한 이미지와 메타정보 및 행위 상태 정보를 포 함하는 학습데이터를 지정된 인공지능모듈에 적용하여 학습시키는 과정을 도시한 흐름도이다. 보다 상세하게 본 도면2는 운영서버에서 캡쳐 가능한 f(f≥1)개의 화면을 구비한 g(g≥1)개의 단말을 이용하면서 주어진 행위를 행하는 대상자가 상기 행위를 행하는 행위 시간 동안 기 설정된 시간 단위 별로 상기 대상자가 이용하는 적어도 하나의 화면을 기 설정된 이미지 획득 규칙에 따라 캡쳐하여 획득된 P(P≥1)개의 이 미지 중 지정된 P'(P'≤P)개의 이미지와 상기 P'개의 이미지를 설명하는 P'개의 메타정보의 조합을 포함하는 대 상자의 행위 확인 정보를 지정된 관리자의 단말로 제공하여 상기 관리자에 의해 상기 대상자의 행위 상태"}
{"patent_id": "10-2022-0032522", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "를 설정한 p(1≤p≤P)개의 이미지와 p개의 메타정보 및 p개의 행위 상태 정보를 포함하는 학습데이터를 지정된인공지능모듈에 적용하여 학습시키는 과정을 도시한 것으로서, 본 발명이 속한 기술분야에서 통상의 지식 을 가진 자라면, 본 도면2를 참조 및/또는 변형하여 상기 과정에 대한 다양한 실시 방법(예컨대, 일부 단계가 생략되거나, 또는 순서가 변경된 실시 방법)을 유추할 수 있을 것이나, 본 발명은 상기 유추되는 모든 실시 방 법을 포함하여 이루어지며, 본 도면2에 도시된 실시 방법만으로 그 기술적 특징이 한정되지 아니한다. 도면2를 참조하면, 운영서버는 대상자가 이용하는 g개의 단말에 지정된 이미지 획득 규칙에 따라 화 면을 캡쳐하여 이미지를 획득하는 기능을 포함하는 프로그램을 설치한다. 그리고, 상기 운영서버는 대상자가 이용하는 단말과 연동하여 상기 대상자를 고유 식별하는 대상자 식별 정보를 등록받아 지정된 운영DB에 저장한다. 그리고, 상기 운영서버는 대상자가 이용하는 단말이나 지정된 관리자가 이용하는 단말과 연동하 여 상기 대상자가 g개의 단말을 이용하면서 행하는 주어진 행위의 범주에 대응하는 대상자의 행위 범주 정 보를 등록 또는 설정받아 지정된 운영DB에 저장한다. 여기서, 상기 행위 범주 정보는, 상기 대상자가 단말을 이용하여 업무를 수행하는 경우 상기 대상자의 업 무 범주나 직무에 대응하는 정보를 포함하거나, 또는 상기 대상자가 단말을 이용하여 비대면 수업에 참가 는 경우 상기 대상자가 참가하는 수업 범주나 과목에 대응하는 정보를 포함하거나, 또는 상기 대상자가 단말을 이용하여 학습을 행하는 경우 상기 대상자가 학습할 학습 범주나 과목에 대응하는 정보를 포함할 수 있다. 이후, 상기 운영서버는 캡쳐 가능한 f개의 화면을 구비한 g개의 단말을 이용하면서 주어진 행위를 행하는 대상자가 상기 행위를 행하도록 설정된 b개의 행위 시간을 포함하는 전체 행위 시간을 기 설정된 시간 단위로 분할한 D개의 분할 시간 구간 중 적어도 하나의 화면이 활성화된 상태를 포함하는 적어도 하나의 분할 시간 구 간 별로 상기 활성화된 상태에 대응하는 적어도 하나의 화면을 기 설정된 이미지 획득 규칙에 따라 캡쳐하여 P(P≥1)개의 이미지를 획득하고, 상기 획득된 P(P≥1)개의 이미지 중 지정된 P'(P'≤P)개의 이미지와 상기 P'개의 이미지를 설명하는 P'개의 메타정보를 저장한다. 여기서, 상기 대상자가 이용하는 단말의 프로그램을 통해 상기 P개의 이미지를 획득하는 제1 실시예에 따 르면, 상기 대상자가 이용하는 단말의 프로그램은, 화면을 캡쳐할 분할 시간 구간에 활성화된 상태에 대응 하는 적어도 하나의 화면을 확인하고, 상기 분할 시간 구간에 활성화된 상태에 대응하는 적어도 하나의 화면을 확인한 경우, 상기 분할 시간 구간의 지정된 캡쳐 시점에 상기 활성화된 상태에 대응하는 적어도 하나의 화면을 캡쳐한 적어도 하나의 대표 이미지를 획득하고, 상기 획득된 적어도 하나의 대표 이미지를 상기 운영서버 로 전송할 수 있으며, 상기 운영서버는 대상자가 이용하는 g개의 단말 중 지정된 분할 시간 구간에 활성화 된 상태를 대응하는 화면을 구비한 g'(1≤g'≤g)개의 단말의 프로그램으로부터 상기 분할 시간 구간에 활 성화된 상태를 대응하는 적어도 하나의 화면 별로 기 설정된 R(R≥1)개의 액션 중 지정된 액션에 대응하는 화면 을 인식하고, 적어도 하나의 지정된 액션이 인식된 적어도 하나의 화면을 지정된 액션 인식 시점 별로 캡쳐하여 획득된 적어도 하나의 특징 이미지를 수신하여, 상기 특징 이미지를 포함하는 P'개의 이미지를 저장할 수 있다. 상기 대상자가 이용하는 단말의 프로그램을 통해 상기 P개의 이미지를 획득하는 제2 실시예에 따르면, 상 기 대상자가 이용하는 단말의 프로그램은 화면을 캡쳐할 분할 시간 구간에 활성화된 상태에 대응하는 적어 도 하나의 화면을 확인하고, 상기 분할 시간 구간에 활성화된 상태에 대응하는 적어도 하나의 화면을 확인한 경 우, 상기 활성화된 상태에 대응하는 적어도 하나의 화면을 판독하여 기 설정된 R(R≥1)개의 액션 중 지정된 액 션에 대응하는 화면을 인식하고, 지정된 액션이 인식된 화면을 캡쳐한 적어도 하나의 특징 이미지를 획득하여, 상기 획득된 적어도 하나의 특징 이미지를 상기 운영서버로 전송할 수 있으며, 이 때 상기 운영서버 는 대상자가 이용하는 g개의 단말 중 지정된 분할 시간 구간에 활성화된 상태를 대응하는 화면을 구비한 g'(1≤g'≤g)개의 단말의 프로그램으로부터 상기 분할 시간 구간에 활성화된 상태를 대응하는 적어도 하나의 화 면 별로 기 설정된 R(R≥1)개의 액션 중 지정된 액션에 대응하는 화면을 인식하고 적어도 하나의 지정된 액션이 인식된 적어도 하나의 화면을 지정된 액션 인식 시점 별로 캡쳐하여 획득된 적어도 하나의 특징 이미지를 수신 하고, 상기 특징 이미지를 포함하는 P'개의 이미지를 저장할 수 있다. 상기 대상자가 이용하는 단말의 프로그램을 통해 상기 P개의 이미지를 획득하는 제3 실시예에 따르면, 상 기 대상자가 이용하는 단말의 프로그램은 화면을 캡쳐할 분할 시간 구간에 활성화된 상태에 대응하는 적어 도 하나의 화면을 확인하고, 상기 분할 시간 구간에 활성화된 상태에 대응하는 적어도 하나의 화면을 확인한 경 우, 상기 분할 시간 구간의 지정된 캡쳐 시점에 상기 활성화된 상태에 대응하는 적어도 하나의 화면을 캡쳐한 적어도 하나의 대표 이미지를 획득하는 절차를 수행하고, 상기 활성화된 상태에 대응하는 적어도 하나의 화면을 판독하여 기 설정된 R(R≥1)개의 액션 중 지정된 액션에 대응하는 화면을 인식하는 절차를 수행하여 지정된 액 션이 인식된 화면을 캡쳐한 적어도 하나의 특징 이미지를 획득하는 절차를 수행하고, 적어도 하나의 대표 이미 지를 획득한 경우 상기 획득된 적어도 하나의 대표 이미지를 상기 운영서버로 전송하는 절차를 수행하고, 적어도 하나의 특징 이미지를 획득한 경우 상기 획득된 적어도 하나의 특징 이미지를 상기 운영서버로 전 송할 수 있으며, 이 때 상기 운영서버는 상기 대상자가 이용하는 g개의 단말 중 지정된 분할 시간 구간에 활성화된 상태를 대응하는 화면을 구비한 g'(1≤g'≤g)개의 단말의 프로그램으로부터 상기 분할 시간 구간 의 지정된 캡쳐 시점에 상기 활성화된 상태를 대응하는 적어도 하나의 대표 이미지를 수신하고, 상기 분할 시간 구간에 활성화된 상태를 대응하는 적어도 하나의 화면 별로 기 설정된 R(R≥1)개의 액션 중 지정된 액션에 대응 하는 화면을 인식하여 적어도 하나의 지정된 액션이 인식된 적어도 하나의 화면을 지정된 액션 인식 시점 별로 캡쳐하여 획득된 적어도 하나의 특징 이미지를 수신하고, 상기 대표 이미지와 특징 이미지 중 적어도 하나의 이 미지를 포함하는 P'개의 이미지를 저장할 수 있다. 상기 P'개의 이미지와 상기 P'개의 이미지를 설명하는 P'개의 메타정보가 저장되면, 상기 운영서버는 상기 저장된 P'개의 이미지와 P'개의 메타정보의 조합을 포함하는 대상자의 행위 확인 정보를 지정된 관리자의 단말 로 제공한다. 여기서, 상기 대상자의 행위 확인 정보는, 상기 대상자가 g개의 단말을 이용하면 서 행하는 주어진 행위의 범주에 대응하는 대상자의 행위 범주 정보를 더 포함할 수 있다. 그리고, 상기 운영서버는 상기 관리자에 의해 상기 대상자의 행위 확인 정보를 근거로 상기 대상자의 행위 상태를 판단하여 설정한 p(1≤p≤P)개의 행위 상태 정보를 수신하고, 상기 p개의 행위 상태 정보에 대응하 는 p개의 이미지와 p개의 메타정보를 확인한다. 본 발명의 실시 방법에 따르면, 상기 운영서버는 상기 관리자의 단말로부터 p개의 행위 상태 정보를 수신하고, 상기 저장된 P'개의 이미지와 P'개의 메타정보 중 상기 p개의 행위 상태 정보에 대응하는 p개의 이미 지와 p개의 메타정보를 확인할 수 있다. 또한, 본 발명의 실시 방법에 따르면, 상기 운영서버는 상기 관리자의 단말로부터 p개의 이미지와 p 개의 메타정보 및 p개의 행위 상태 정보를 수신할 수 있다. 상기 p개의 행위 상태 정보에 대응하는 p개의 이미지와 p개의 메타정보가 확인되면, 상기 운영서버는 상기 확인된 p개의 이미지와 p개의 메타정보 및 p개의 행위 상태 정보를 포함하여 구성된 학습데이터를 지정된 인공 지능모듈에 적용하여 학습시킨다. 본 발명의 실시 방법에 따르면, 상기 운영서버는 대상자가 이용하는 단말의 화면을 캡쳐하여 상기 대 상자의 단말 이용을 관측한 특징에 대응하는 상기 p개의 이미지와 p개의 메타정보를 포함하는 입력정보(Feature Vectors)와 상기 대상자의 단말 기반 행위의 관측된 결과에 대응하는 p개의 행위 상태 정보를 포함하는 출력정보(Label)를 포함하는 학습데이터를 지정된 인공지능모듈에 적용하여 학습시킬 수 있다. 또한, 본 발명의 실시 방법에 따르면, 상기 운영서버는 대상자가 이용하는 단말의 화면을 캡쳐하여 상기 대상자의 단말 이용을 관측한 특징에 대응하는 상기 p개의 이미지와 p개의 메타정보 및 대상자의 행위 범 주 정보를 포함하는 입력정보와 상기 대상자의 단말 기반 행위의 관측된 결과에 대응하는 p개의 행위 상태 정보 를 포함하는 출력정보를 포함하는 학습데이터를 지정된 인공지능모듈에 적용하여 학습시킬 수 있다. 도면3은 본 발명의 실시 방법에 따라 분할 시간 구간의 행위 상태 분석과 관련된 일의적 이미지에 해당하는 이 미지와 메타정보를 확인하는 과정을 도시한 흐름도이다. 보다 상세하게 본 도면3은 상기 도면2의 과정을 통해 운영서버9100)에서 대상자의 행위 상태를 설정한 이미지와 메타정보 및 행위 상태 정보를 포함하는 학습데이터를 지정된 인공지능모듈에 적용하여 학습시킨 후, 캡쳐 가능 한 s(s≥1)개의 화면을 구비한 m(m≥1)개의 단말을 이용하여 S(S= )개의 화면을 주시 가능한 상 태에서 주어진 행위를 행하는 사용자의 행위 상태를 분석하기 위해 설정된 t(t≥1)개의 행위 시간을 포함하는 전체 행위 시간을 기 설정된 시간 단위로 분할한 N(N≥2)개의 분할 시간 구간 중 현재 시점의 제n(1≤n≤N)차 분할 시간 구간에 활성화된 상태에 대응하는 적어도 하나의 화면을 기 설정된 이미지 획득 규칙에 따라 캡쳐하 여 획득된 적어도 하나의 이미지를 근거로 상기 제n차 분할 시간 구간의 행위 상태 분석과 관련된 일의적 이미 지에 해당하는 in(1≤n≤N)(in≥1)개의 제n차 이미지와 상기 in개의 제n차 이미지를 설명하는 in개의 메타정보를 확"}
{"patent_id": "10-2022-0032522", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "인하는 과정을 도시한 것으로서, 본 발명이 속한 기술분야에서 통상의 지식을 가진 자라면, 본 도면3을 참조 및 /또는 변형하여 상기 과정에 대한 다양한 실시 방법(예컨대, 일부 단계가 생략되거나, 또는 순서가 변경된 실시 방법)을 유추할 수 있을 것이나, 본 발명은 상기 유추되는 모든 실시 방법을 포함하여 이루어지며, 본 도면3에 도시된 실시 방법만으로 그 기술적 특징이 한정되지 아니한다. 도면3을 참조하면, 운영서버는 사용자가 이용하는 m개의 단말에 지정된 이미지 획득 규칙에 따라 화 면을 캡쳐하여 이미지를 획득하는 기능을 포함하는 프로그램을 설치한다. 그리고, 상기 운영서버는 사용자가 이용하는 단말이나 지정된 관리자가 이용하는 단말과 연동하 여 상기 사용자가 m개의 단말을 이용하면서 행하는 주어진 행위의 범주에 대응하는 사용자의 행위 범주 정 보를 등록 또는 설정받아 지정된 운영DB에 저장한다. 이후, 상기 운영서버는 캡쳐 가능한 s개의 화면을 구비한 m개의 단말을 이용하여 S개의 화면을 주시 가능한 상태에서 주어진 행위를 행하는 사용자의 행위 상태를 분석하기 위해 설정된 t개의 행위 시간을 포함하 는 전체 행위 시간을 기 설정된 시간 단위로 분할한 N개의 분할 시간 구간 중 현재 시점의 제n차 분할 시간 구 간에 활성화된 상태에 대응하는 적어도 하나의 화면을 기 설정된 이미지 획득 규칙에 따라 캡쳐하여 적어도 하 나의 이미지를 획득한다. 여기서, 상기 일의적 이미지는, 제(n-1)((n-1)≥1)차 분할 시간 구간에 대응하는 이미지와 다른 이미지, 화면의 맨위 표시된 애플리케이션이 사용자의 지정된 행위 범주와 관련된 특정 애플리케이션을 포함하는 이미지, 화면 의 맨위 표시된 인터페이스 화면이 사용자의 지정된 행위 범주와 관련된 인터페이스 화면을 포함하는 이미지, 지정된 액션을 근거로 획득된 이미지, 사용자의 지정된 행위 범주와 관련된 워크플로(workflow)에 대응하는 이 미지 중 적어도 하나의 이미지를 포함할 수 있다. 그리고, 상기 운영서버는 상기 획득된 적어도 하나의 이미지를 근거로 상기 제n차 분할 시간 구간의 행위 상태 분석과 관련된 일의적 이미지에 해당하는 in(1≤n≤N)(in≥1)개의 제n차 이미지와 상기 in개의 제n차 이미지를 설명하는 in개의 메타정보를 확인한다. 여기서, 상기 in개의 메타정보는, 상기 제n차 분할 시간 구간에 활성화된 상태에 대응하는 적어도 하나의 화면을 캡쳐하여 이미지를 획득하는 과정과 연동하여 생성된 화면 메타정보를 근거로 생성될 수 있다. 상기 화면 메타정보는, 상기 이미지를 캡쳐한 시점을 식별 가능한 시점 식별 정보, 상기 이미지를 캡쳐한 화면 을 식별 가능한 화면 식별 정보, 상기 이미지를 캡쳐한 단말을 식별 가능한 단말 식별 정보, 지정된 액션을 근 거로 이미지를 캡쳐한 경우 상기 이미지에 대응하는 액션을 분류하는 액션 분류 정보, 지정된 액션을 근거로 캡 쳐된 이미지에 대응하는 액션을 확인 가능한 액션 확인 정보, 상기 화면의 맨위 표시된 애플리케이션을 식별하 는 애플리케이션 식별 정보, 상기 화면의 맨위 표시된 애플리케이션의 인터페이스 화면을 식별하는 인터페이스 식별 정보, 상기 화면의 맨위 표시된 애플리케이션을 통해 표시된 컨텐츠를 식별하는 컨텐츠 식별 정보, 상기 화면의 맨위 표시된 애플리케이션을 통해 수행되는 적어도 하나의 워크플로를 설명하는 워크플로 정보, 상기 화 면의 맨위 표시된 브라우져에 로딩된 페이지를 식별하는 애플리케이션 식별 정보, 상기 화면의 맨위 표시된 브 라우져에 로딩된 페이지의 인터페이스 화면을 식별하는 인터페이스 식별 정보, 상기 화면의 맨위 표시된 브라우 져에 로딩된 페이지를 통해 표시된 컨텐츠를 식별하는 컨텐츠 식별 정보, 상기 화면의 맨위 표시된 브라우져에 로딩된 페이지를 통해 수행되는 적어도 하나의 워크플로를 설명하는 워크플로 정보 중 적어도 하나의 정보를 포 함할 수 있다. 또한, 상기 화면 메타정보는, 상기 화면의 맨위 아래 표시되거나 감춤된 적어도 하나의 애플리케이션을 식별하 는 애플리케이션 식별 정보, 상기 화면의 맨위 아래 표시되거나 감춤된 적어도 하나의 애플리케이션의 인터페이 스 화면을 식별하는 인터페이스 식별 정보, 상기 화면의 맨위 아래 표시되거나 감춤된 적어도 하나의 애플리케 이션을 통해 표시된 컨텐츠를 식별하는 컨텐츠 식별 정보, 상기 화면의 맨위 아래 표시되거나 감춤된 적어도 하 나의 애플리케이션을 통해 수행되는 적어도 하나의 워크플로를 설명하는 워크플로 정보, 상기 화면의 맨위 아래 표시되거나 감춤된 적어도 하나의 브라우져에 로딩된 적어도 하나의 페이지를 식별하는 애플리케이션 식별 정보, 상기 화면의 맨위 아래 표시되거나 감춤된 적어도 하나의 브라우져에 적어도 하나의 로딩된 페이지의 인 터페이스 화면을 식별하는 인터페이스 식별 정보, 상기 화면의 맨위 아래 표시되거나 감춤된 적어도 하나의 브 라우져에 로딩된 적어도 하나의 페이지를 통해 표시된 컨텐츠를 식별하는 컨텐츠 식별 정보, 상기 화면의 맨위 아래 표시되거나 감춤된 적어도 하나의 브라우져에 로딩된 적어도 하나의 페이지를 통해 수행되는 적어도 하나 의 워크플로를 설명하는 워크플로 중 적어도 하나의 정보를 더 포함할 수 있다. 도면4a와 도면4b는 본 발명의 실시 방법에 따라 사용자의 행위 상태 분석과 관련된 이미지와 메타정보를 확인하 는 과정을 도시한 흐름도이다. 보다 상세하게 본 도면4a와 도면4b는 상기 도면3의 과정 중, 사용자의 행위 상태를 분석하기 위해 현재 시점의 제n차 분할 시간 구간에 활성화된 상태에 대응하는 적어도 하나의 화면을 기 설정된 이미지 획득 규칙에 따라 캡쳐하여 획득된 적어도 하나의 이미지를 근거로 상기 제n차 분할 시간 구간의 행위 상태 분석과 관련된 일의적 이미지에 해당하는 in개의 제n차 이미지와 상기 in개의 제n차 이미지를 설명하는 in개의 메타정보를 확인하는 과"}
{"patent_id": "10-2022-0032522", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "정을 보다 상세하게 다양한 실시예 별로 도시한 것으로서, 본 발명이 속한 기술분야에서 통상의 지식을 가진 자 라면, 본 도면4a와 도면4b를 참조 및/또는 변형하여 상기 과정에 대한 다양한 실시 방법(예컨대, 일부 단계가 생략되거나, 또는 순서가 변경된 실시 방법)을 유추할 수 있을 것이나, 본 발명은 상기 유추되는 모든 실시 방 법을 포함하여 이루어지며, 본 도면4a와 도면4b 도시된 실시 방법만으로 그 기술적 특징이 한정되지 아니한다. 도면4a를 참조하면, 사용자가 이용하는 단말의 프로그램은 N개의 분할 시간 구간 중 현재 시점에 대응하는 제n차 분할 시간 구간을 확인하고(400a), 현재 시점에 대응하는 제n차 분할 시간 구간에 활성화된 상태에 대응하는 적어도 하나의 화면을 확인한다(405a). 상기 제n차 분할 시간 구간에 활성화된 상태에 대응하는 적어도 하나의 화면이 확인되면, 상기 사용자가 이용하 는 단말의 프로그램은 상기 제n차 분할 시간 구간 중에 대표 이미지를 획득하도록 설정된 지정된 캡쳐 시 점이 도래하는지 확인한다(410a). 그리고, 상기 단말의 프로그램은 상기 제n차 분할 시간 구간의 지정된 캡쳐 시점에 상기 활성화된 상태에 대응하는 적어도 하나의 화면을 캡쳐한 적어도 하나의 대표 이미지를 획득하고(415a), 상기 획득된 대표 이미지 를 설명하는 화면 메타정보를 생성한 후(420a), 상기 획득된 대표 이미지에 상기 생성된 화면 메타정보를 첨부 하여 상기 운영서버로 전송한다(425a). 그러면, 상기 운영서버는 사용자가 이용하는 m개의 단말 중 제n차 분할 시간 구간에 활성화된 상태를 대응 하는 화면을 구비한 m'(1≤m'≤m)개의 단말의 프로그램으로부터 상기 제n차 분할 시간 구간의 지정된 캡쳐 시점에 상기 활성화된 상태에 대응하는 en(1≤n≤N)(1≤en≤S)개의 화면을 캡쳐하여 획득된 en개의 대표 이미지와 상 기 en개의 대표 이미지를 설명하는 en개의 화면 메타정보를 수신한다(430a). 여기서, 상기 in개의 메타정보는, 상기 en개의 화면 메타정보를 근거로 확인될 수 있다. 그리고, 상기 운영서버는 상기 수신된 en개의 대표 이미지를 근거로 상기 제n차 분할 시간 구간의 행위 상 태 분석과 관련된 일의적 이미지에 해당하는 in(1≤in≤en)개의 제n차 이미지를 확인하고, 상기 en개의 화면 메타 정보를 근거로 상기 in개의 제n차 이미지를 설명하는 in개의 메타정보를 확인한다(435a). 도면4b를 참조하면, 사용자가 이용하는 단말의 프로그램은 N개의 분할 시간 구간 중 현재 시점에 대응하는 제n차 분할 시간 구간을 확인하고(400b), 현재 시점에 대응하는 제n차 분할 시간 구간에 활성화된 상태에 대응 하는 적어도 하나의 화면을 확인한다(405b). 상기 제n차 분할 시간 구간에 활성화된 상태에 대응하는 적어도 하나의 화면이 확인되면, 상기 단말의 프 로그램은 상기 활성화된 상태에 대응하는 적어도 하나의 화면을 판독하여 기 설정된 R(R≥1)개의 액션 중 지정 된 액션에 대응하는 화면을 인식한다(410b). 여기서 상기 제n차 분할 시간 구간 중에 상기 활성화된 상태에 대 응하는 적어도 하나의 화면을 지정된 주기로 판독하거나 지정된 액션에 대응하는 이벤트 발생을 검출하여 기 설 정된 R개의 액션 중 지정된 액션을 인식할 수 있다. 그리고, 상기 단말의 프로그램은 지정된 액션이 인식된 화면을 캡쳐한 적어도 하나의 특징 이미지를 획득 하고(415b), 상기 획득된 특징 이미지를 설명하는 화면 메타정보를 생성한 후(420b), 상기 획득된 특징 이미지 에 상기 생성된 화면 메타정보를 첨부하여 상기 운영서버로 전송한다(425b). 그러면, 상기 운영서버는 사용자가 이용하는 m개의 단말 중 제n차 분할 시간 구간에 활성화된 상태를 대응 하는 화면을 구비한 m'(1≤m'≤m)개의 단말의 프로그램으로부터 상기 제n차 분할 시간 구간에 활성화된 상 태를 대응하는 en(1≤n≤N)(1≤en≤S)개의 화면 별로 기 설정된 R(R≥1)개의 액션 중 지정된 액션에 대응하는 화면 을 인식한다(430b). 그리고, 상기 운영서버는 적어도 하나의 지정된 액션이 인식된 kn(1≤n≤N)(1≤kn≤en)개의 화면을 지정된 액 션 인식 시점 별로 캡쳐하여 획득된 rn(1≤n≤N)(1≤rn≤R, rn≥kn)개의 특징 이미지와 상기 rn개의 특징 이미지를 설명하는 rn개의 화면 메타정보를 수신한다(435b). 여기서 상기 in개의 메타정보는, 상기 rn개의 화면 메타정보 를 근거로 확인될 수 있다. 그리고, 상기 운영서버는 상기 수신된 rn개의 특징 이미지를 근거로 상기 제n차 분할 시간 구간의 행위 상 태 분석과 관련된 일의적 이미지에 해당하는 in(1≤in≤rn)개의 제n차 이미지를 확인하고, 상기 rn개의 화면 메타 정보를 근거로 상기 in개의 제n차 이미지를 설명하는 in개의 메타정보를 확인한다(440b). 도면5는 본 발명의 실시 방법에 따라 사용자의 행위 확인 정보를 인공지능모듈에 대입하여 사용자의 행위 상태 정보를 분석하는 과정을 도시한 흐름도이다. 보다 상세하게 본 도면5는 상기 도면3의 과정을 통해 분할 시간 구간의 행위 상태 분석과 관련된 일의적 이미지 에 해당하는 in개의 제n차 이미지와 in개의 메타정보가 확인된 후, 운영서버에서 상기 확인된 in개의 제n차 이미지와 in개의 메타정보의 조합을 포함하는 사용자의 행위 확인 정보를 인공지능모듈에 대입하여 상기 사"}
{"patent_id": "10-2022-0032522", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 7, "content": "용자의 행위 상태 정보를 분석하는 과정을 도시한 것으로서, 본 발명이 속한 기술분야에서 통상의 지식을 가진 자라면, 본 도면5를 참조 및/또는 변형하여 상기 과정에 대한 다양한 실시 방법(예컨대, 일부 단계가 생략되거 나, 또는 순서가 변경된 실시 방법)을 유추할 수 있을 것이나, 본 발명은 상기 유추되는 모든 실시 방법을 포함 하여 이루어지며, 본 도면5에 도시된 실시 방법만으로 그 기술적 특징이 한정되지 아니한다. 도면5를 참조하면, 운영서버는 사용자가 이용하는 단말의 화면을 캡쳐하여 상기 사용자의 단말 이용 에 대한 특징을 관측한다. 그리고, 상기 운영서버는 상기 사용자의 단말 이용을 관측한 특징에 대응하는 상기 in개의 제n차 이미지와 in개의 메타정보 및 상기 사용자의 행위 범주 정보를 포함하는 사용자의 행위 확인 정보를 상기 인공지능모듈 의 입력정보로 대입하여, 상기 인공지능모듈을 통해 분석된 상기 사용자의 행위 상태 정보를 확 인한다. 이후, 상기 운영서버(1000는 상기 사용자의 행위 확인 정보와 상기 인공지능모듈을 통해 분석된 사용자의 행위 상태 정보를 상기 사용자가 이용하는 단말이나 지정된 관리자가 이용하는 단말로 제공한다 . 그리고, 상기 운영서버는 상기 사용자나 관리자에 의해 수정된 적어도 하나의 행위 상태 정보가 수신되는 지 확인하고, 적어도 하나의 행위 상태 정보가 수정된 경우, 상기 수정된 사용자의 행위 확인 정보와 행위 상태 정보를 포함하는 학습데이터를 상기 인공지능모듈에 적용하여 학습시킨다."}
{"patent_id": "10-2022-0032522", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 실시 방법에 따른 인공지능을 이용하여 단말 화면 기반 행위 상태를 분석하는 시스템의 구성 을 도시한 도면이다. 도 2는 본 발명의 실시 방법에 따라 대상자의 행위 상태를 설정한 이미지와 메타정보 및 행위 상태 정보를 포함 하는 학습데이터를 지정된 인공지능모듈에 적용하여 학습시키는 과정을 도시한 흐름도이다.도 3은 본 발명의 실시 방법에 따라 분할 시간 구간의 행위 상태 분석과 관련된 일의적 이미지에 해당하는 이미 지와 메타정보를 확인하는 과정을 도시한 흐름도이다. 도 4a, 도4b는 본 발명의 실시 방법에 따라 사용자의 행위 상태 분석과 관련된 이미지와 메타정보를 확인하는 과정을 도시한 흐름도이다. 도 5는 본 발명의 실시 방법에 따라 사용자의 행위 확인 정보를 인공지능모듈에 대입하여 사용자의 행위 상태 정보를 분석하는 과정을 도시한 흐름도이다."}
