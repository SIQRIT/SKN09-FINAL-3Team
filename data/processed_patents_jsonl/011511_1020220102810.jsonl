{"patent_id": "10-2022-0102810", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0024611", "출원번호": "10-2022-0102810", "발명의 명칭": "안전 기능을 수행하는 전자 장치 및 그 제어 방법", "출원인": "삼성전자주식회사", "발명자": "최현미"}}
{"patent_id": "10-2022-0102810", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "전자 장치에 있어서, 통신 인터페이스; 및상이한 타입의 복수의 컨텍스트 정보, 상기 복수의 컨텍스트 정보 각각에 맵핑된 위험 상황 정보 및 상기 위험상황 각각에 맵핑된 제어 정보를 포함하는 안전 템플릿 정보를 획득하고, 상기 통신 인터페이스를 통해 적어도 하나의 사용자 디바이스로부터 적어도 하나의 센싱 데이터가 수신되면, 상기 적어도 하나의 센싱 데이터에 대응되는 컨텍스트 정보를 식별하고, 상기 안전 템플릿 정보 및 상기 컨텍스트 정보의 타입에 기초하여 위험 상황 정보를 식별하고, 상기 적어도 하나의 센싱 데이터에 기초하여 착용형 로봇의 주변 환경이 상기 식별된 위험 상황 정보에 대응되는 위험 상황에 해당하는지 여부를 식별하고, 상기 위험 상황에 해당되는 것으로 식별되면, 상기 안전 템플릿에 기초하여 상기 위험 상황에 맵핑된 적어도 하나의 제어 정보를 획득하고, 상기 획득된 적어도 하나의 제어 정보에 기초하여 상기 착용형 로봇 또는 상기 사용자 디바이스 중 적어도 하나를 제어하는 하나 이상의 프로세서;를 포함하는 전자 장치."}
{"patent_id": "10-2022-0102810", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 하나 이상의 프로세서는, 상기 적어도 하나의 사용자 디바이스로부터 수신된 복수의 센싱 데이터에 기초하여 제1 및 제2 컨텍스트 정보가식별되면, 상기 제1 및 상기 제2 컨텍스트 정보의 타입 각각에 대응되는 제1 및 제2 위험 상황 정보를식별하고, 상기 제1 컨텍스트 정보에 대응되는 적어도 하나의 센싱 데이터에 기초하여 상기 착용형 로봇의 주변 환경이 제1 위험 상황에 해당하는지 여부를 식별하고, 상기 제2 컨텍스트 정보에 대응되는 적어도 하나의 센싱 데이터에 기초하여 상기 착용형 로봇의 주변 환경이 제2 위험 상황에 해당하는지 여부를 식별하고, 상기 제1 위험 상황 및 상기 제2 위험 상황이 식별되면, 상기 안전 템플릿에 기초하여 상기 제1 위험 상황에 맵핑된 적어도 하나의 제1 제어 정보 및 상기 제2 위험 상황에 맵핑된 적어도 하나의 제2 제어 정보를 획득하는,전자 장치."}
{"patent_id": "10-2022-0102810", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 전자 장치는, 상기 착용형 로봇으로 구현되며, 상기 착용형 로봇은, 구동부;를 더 포함하며, 상기 하나 이상의 프로세서는, 상기 적어도 하나의 사용자 디바이스로부터 수신된 복수의 센싱 데이터에 기초하여 동일한 타입의 컨텍스트 정보가 식별되면, 상기 식별된 컨텍스트 정보의 타입에 기초하여 위험 상황 정보를 식별하고, 공개특허 10-2024-0024611-3-상기 복수의 센싱 데이터에 기초하여 상기 착용형 로봇의 주변 환경이 상기 위험 상황 정보에 대응되는 위험 상황에 해당되는 것으로 식별되면, 상기 안전 템플릿에 기초하여 상기 식별된 위험 상황에 맵핑된 제어 신호를 획득하고, 상기 제어 신호에 기초하여 상기 구동부를 제어하는, 전자 장치."}
{"patent_id": "10-2022-0102810", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서,상기 복수의 센싱 데이터는 제1 센싱 데이터 및 제2 센싱 데이터를 포함하며, 상기 하나 이상의 프로세서는, 상기 제1 센싱 데이터에 기초하여 상기 위험 상황이 식별되고 상기 제2 센싱 데이터에 기초하여 상기 위험 상황이 식별되면, 상기 안전 템플릿에 기초하여 상기 위험 상황에 맵핑된 제어 신호를 획득하는, 전자 장치."}
{"patent_id": "10-2022-0102810", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서,상기 하나 이상의 프로세서는, 상기 적어도 하나의 사용자 디바이스로부터 수신된 특정 타입의 컨텍스트 정보에 대응되는 센싱 데이터가 임계개수 미만이면, 상기 안전 템플릿에 기초하여 상기 위험 상황에 맵핑된 알림(Notification) 정보를 획득하고, 상기 획득된 알림 정보를 상기 통신 인터페이스를 통해 상기 적어도 하나의 사용자 디바이스로 전송하는, 전자장치."}
{"patent_id": "10-2022-0102810", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서,상기 하나 이상의 프로세서는,상기 위험 상황 정보가 식별되면, 상기 적어도 하나의 센싱 데이터 및 상기 위험 상황 정보를 학습된 인공 지능모델에 입력하여 상기 착용형 로봇의 주변 환경이 상기 위험 상황에 해당하는지 여부를 식별하는, 전자 장치."}
{"patent_id": "10-2022-0102810", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에 있어서,상기 상이한 타입의 복수의 컨텍스트 정보는, 주변 사물 인식 정보, 주변 지형 인식 정보, 고도 인식 정보, 온도/습도 인식 정보, 시간대 인식 정보 또는 과운동 인식 정보 중 적어도 하나를 포함하며, 상기 위험 상황 정보는, 충돌 회피 상황 정보, 사용 불가 상황 정보, 사용 주의 상황 정보, 사용 제한 상황 정보 또는 오동작 상황 정보중 적어도 하나를 포함하며, 상기 제어 정보는, 소리 알림 정보, 상기 착용형 로봇의 운동 강도 정보, 전원 제어 정보, 주변음 청취 제어 정보 또는 플래쉬 제어 정보 중 적어도 하나를 포함하는, 전자 장치."}
{"patent_id": "10-2022-0102810", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1항에 있어서, 상기 전자 장치는, 상기 착용형 로봇 또는 서버로 구현되며, 상기 서버는, 공개특허 10-2024-0024611-4-상기 획득된 적어도 하나의 제어 정보에 기초하여 상기 통신 인터페이스를 통해 상기 착용형 로봇 또는 상기 사용자 디바이스 중 적어도 하나로 제어 신호를 전송하는, 전자 장치."}
{"patent_id": "10-2022-0102810", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서,상기 하나 이상의 프로세서는,상기 위험 상황 정보가 식별되면, 상기 적어도 하나의 센싱 데이터 및 상기 위험 상황 정보를 학습된 인공 지능모델에 입력하여 상기 착용형 로봇의 주변 환경이 상기 위험 상황에 해당하는지 여부를 식별하는, 전자 장치."}
{"patent_id": "10-2022-0102810", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제1항에 있어서,상기 적어도 하나의 사용자 디바이스는, 스마트 폰, 스마트 워치(Watch) 또는 블루투스 이어폰(Bluetooth earphone) 중 적어도 하나를 포함하는, 전자장치."}
{"patent_id": "10-2022-0102810", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "전자 장치의 제어 방법에 있어서,상이한 타입의 복수의 컨텍스트 정보, 상기 복수의 컨텍스트 정보 각각에 맵핑된 위험 상황 정보 및 상기 위험상황 각각에 맵핑된 제어 정보를 포함하는 안전 템플릿 정보를 획득하는 단계;적어도 하나의 사용자 디바이스로부터 적어도 하나의 센싱 데이터가 수신되면, 상기 적어도 하나의 센싱 데이터에 대응되는 컨텍스트 정보를 식별하는 단계;상기 안전 템플릿 정보 및 상기 컨텍스트 정보의 타입에 기초하여 위험 상황 정보를 식별하는 단계;상기 적어도 하나의 센싱 데이터에 기초하여 착용형 로봇의 주변 환경이 상기 식별된 위험 상황 정보에 대응되는 위험 상황에 해당하는지 여부를 식별하는 단계;상기 위험 상황에 해당되는 것으로 식별되면, 상기 안전 템플릿에 기초하여 상기 위험 상황에 맵핑된 적어도 하나의 제어 정보를 획득하는 단계; 및상기 획득된 적어도 하나의 제어 정보에 기초하여 상기 착용형 로봇 또는 상기 사용자 디바이스 중 적어도 하나를 제어하는 단계;를 포함하는, 제어 방법."}
{"patent_id": "10-2022-0102810", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항에 있어서,상기 위험 상황 정보를 식별하는 단계는,상기 적어도 하나의 사용자 디바이스로부터 수신된 복수의 센싱 데이터에 기초하여 제1 및 제2 컨텍스트 정보가식별되면, 상기 제1 및 상기 제2 컨텍스트 정보의 타입 각각에 대응되는 제1 및 제2 위험 상황 정보를 식별하는단계;를 포함하고,상기 위험 상황에 해당하는지 여부를 식별하는 단계는,상기 제1 컨텍스트 정보에 대응되는 적어도 하나의 센싱 데이터에 기초하여 상기 착용형 로봇의 주변 환경이 제1 위험 상황에 해당하는지 여부를 식별하는 단계; 및 상기 제2 컨텍스트 정보에 대응되는 적어도 하나의 센싱 데이터에 기초하여 상기 착용형 로봇의 주변 환경이 제2 위험 상황에 해당하는지 여부를 식별하는 단계;를 포함하고,상기 제어 정보를 획득하는 단계는,상기 제1 위험 상황 및 상기 제2 위험 상황이 식별되면, 상기 안전 템플릿에 기초하여 상기 제1 위험 상황에 맵핑된 적어도 하나의 제1 제어 정보 및 상기 제2 위험 상황에 맵핑된 적어도 하나의 제2 제어 정보를 획득하는,공개특허 10-2024-0024611-5-제어 방법."}
{"patent_id": "10-2022-0102810", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제11항에 있어서,상기 전자 장치는, 상기 착용형 로봇으로 구현되며, 상기 위험 상황 정보를 식별하는 단계는,상기 적어도 하나의 사용자 디바이스로부터 수신된 복수의 센싱 데이터에 기초하여 동일한 타입의 컨텍스트 정보가 식별되면, 상기 식별된 컨텍스트 정보의 타입에 기초하여 위험 상황 정보를 식별하고, 상기 제어 정보를 획득하는 단계는,상기 복수의 센싱 데이터에 기초하여 상기 착용형 로봇의 주변 환경이 상기 위험 상황 정보에 대응되는 위험 상황에 해당되는 것으로 식별되면, 상기 안전 템플릿에 기초하여 상기 식별된 위험 상황에 맵핑된 제어 신호를 획득하고,상기 제어하는 단계는,상기 제어 신호에 기초하여 구동부를 제어하는, 제어 방법."}
{"patent_id": "10-2022-0102810", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제13항에 있어서,상기 복수의 센싱 데이터는 제1 센싱 데이터 및 제2 센싱 데이터를 포함하며, 상기 제어 신호를 획득하는 단계는,상기 제1 센싱 데이터에 기초하여 상기 위험 상황이 식별되고 상기 제2 센싱 데이터에 기초하여 상기 위험 상황이 식별되면, 상기 안전 템플릿에 기초하여 상기 위험 상황에 맵핑된 제어 신호를 획득하는, 제어 방법."}
{"patent_id": "10-2022-0102810", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제11항에 있어서,상기 제어 정보를 획득하는 단계는,상기 적어도 하나의 사용자 디바이스로부터 수신된 특정 타입의 컨텍스트 정보에 대응되는 센싱 데이터가 임계개수 미만이면, 상기 안전 템플릿에 기초하여 상기 위험 상황에 맵핑된 알림(Notification) 정보를 획득하는 단계;를 포함하고,상기 제어하는 단계는,상기 획득된 알림 정보를 상기 적어도 하나의 사용자 디바이스로 전송하는, 제어 방법."}
{"patent_id": "10-2022-0102810", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제11항에 있어서,상기 위험 상황에 해당하는지 여부를 식별하는 단계는,상기 위험 상황 정보가 식별되면, 상기 적어도 하나의 센싱 데이터 및 상기 위험 상황 정보를 학습된 인공 지능모델에 입력하여 상기 착용형 로봇의 주변 환경이 상기 위험 상황에 해당하는지 여부를 식별하는, 제어 방법."}
{"patent_id": "10-2022-0102810", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제11항에 있어서,상기 상이한 타입의 복수의 컨텍스트 정보는, 주변 사물 인식 정보, 주변 지형 인식 정보, 고도 인식 정보, 온도/습도 인식 정보, 시간대 인식 정보 또는 과운동 인식 정보 중 적어도 하나를 포함하며, 공개특허 10-2024-0024611-6-상기 위험 상황 정보는, 충돌 회피 상황 정보, 사용 불가 상황 정보, 사용 주의 상황 정보, 사용 제한 상황 정보 또는 오동작 상황 정보중 적어도 하나를 포함하며, 상기 제어 정보는, 소리 알림 정보, 상기 착용형 로봇의 운동 강도 정보, 전원 제어 정보, 주변음 청취 제어 정보 또는 플래쉬 제어 정보 중 적어도 하나를 포함하는, 제어 방법."}
{"patent_id": "10-2022-0102810", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제11항에 있어서, 상기 전자 장치는, 서버로 구현되며, 상기 제어하는 단계는,상기 획득된 적어도 하나의 제어 정보에 기초하여 상기 착용형 로봇 또는 상기 사용자 디바이스 중 적어도 하나로 제어 신호를 전송하는, 제어 방법."}
{"patent_id": "10-2022-0102810", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제18항에 있어서,상기 위험 상황에 해당하는지 여부를 식별하는 단계는,상기 위험 상황 정보가 식별되면, 상기 적어도 하나의 센싱 데이터 및 상기 위험 상황 정보를 학습된 인공 지능모델에 입력하여 상기 착용형 로봇의 주변 환경이 상기 위험 상황에 해당하는지 여부를 식별하는, 제어 방법."}
{"patent_id": "10-2022-0102810", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제11항에 있어서,상기 적어도 하나의 사용자 디바이스는, 스마트 폰, 스마트 워치(Watch) 또는 블루투스 이어폰(Bluetooth earphone) 중 적어도 하나를 포함하는, 제어방법."}
{"patent_id": "10-2022-0102810", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "전자 장치가 개시된다. 전자 장치는, 통신 인터페이스 및 상이한 타입의 복수의 컨텍스트 정보, 복수의 컨텍스트 정보 각각에 맵핑된 위험 상황 정보 및 위험 상황 각각에 맵핑된 제어 정보를 포함하는 안전 템플릿 정보를 획득 하고, 통신 인터페이스를 통해 적어도 하나의 사용자 디바이스로부터 적어도 하나의 센싱 데이터가 수신되면, 적 (뒷면에 계속)"}
{"patent_id": "10-2022-0102810", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 안전 기능을 수행하는 전자 장치 및 그 제어 방법에 관한 것으로, 더욱 상세하게는 사용자 디바이스 에 포함된 센서를 이용하여 안전 기능을 수행하는 전자 장치 및 그 제어 방법에 관한 것이다."}
{"patent_id": "10-2022-0102810", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "전자 기술의 발달에 힘입어 다양한 유형의 전자 기기가 개발 및 보급되고 있으며, 최근에는 사용자 등에게 서비 스를 제공하는 전자 장치에 대한 기술 개발이 활발해지고 있다. 특히, 사용자의 보행과 운동 기능을 증진시켜 사용자가 효율적이고 안정적으로 걸을 수 있도록 도와주는 착용형 로봇(예를 들어, GEMS(Gait Enhancing and Motivating System))과 같은 전자 장치에 대한 기술 개발이 활발해지고 있다. 한편, GEMS와 같은 착용형 로봇의 경우 사용자의 신체에 직접적으로 결합하는 경우가 많으며, 로봇을 착용한 사 용자가 안전하게 로봇을 사용하기 위하여는 안전 기능이 담보되어야 한다. 특히, 사용자가 보행하는 공간 등 사 용자의 주변 환경에서 발생할 수 있는 위험한 상황을 예측하거나 위험한 상황으로부터 신속하게 반응하여 사용 자의 안전성이 확보되어야 한다."}
{"patent_id": "10-2022-0102810", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 2, "content": "발명의 내용"}
{"patent_id": "10-2022-0102810", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "이상과 같은 목적을 달성하기 위한 일 실시 예에 따른 안전 기능을 수행하는 전자 장치는, 통신 인터페이스 및 상이한 타입의 복수의 컨텍스트 정보, 상기 복수의 컨텍스트 정보 각각에 맵핑된 위험 상황 정보 및 상기 위험 상황 각각에 맵핑된 제어 정보를 포함하는 안전 템플릿 정보를 획득하는 하나 이상의 프로세서(또는, 프로세 서)를 포함할 수 있다. 프로세서는, 상기 통신 인터페이스를 통해 적어도 하나의 사용자 디바이스로부터 적어도 하나의 센싱 데이터가 수신되면, 상기 적어도 하나의 센싱 데이터에 대응되는 컨텍스트 정보를 식별할 수 있다. 프로세서는, 상기 안전 템플릿 정보 및 상기 컨텍스트 정보의 타입에 기초하여 위험 상황 정보를 식별할 수 있 다. 프로세서는, 상기 적어도 하나의 센싱 데이터에 기초하여 착용형 로봇의 주변 환경이 상기 식별된 위험 상 황 정보에 대응되는 위험 상황에 해당하는지 여부를 식별할 수 있다. 프로세서는, 상기 위험 상황에 해당되는 것으로 식별되면, 상기 안전 템플릿에 기초하여 상기 위험 상황에 맵핑된 적어도 하나의 제어 정보를 획득할 수 있다. 프로세서는, 상기 획득된 적어도 하나의 제어 정보에 기초하여 상기 착용형 로봇 또는 상기 사용자 디바 이스 중 적어도 하나를 제어할 수 있다. 여기서, 상기 하나 이상의 프로세서는, 상기 적어도 하나의 사용자 디바이스로부터 수신된 복수의 센싱 데이터 에 기초하여 제1 및 제2 컨텍스트 정보가 식별되면, 상기 제1 및 상기 제2 컨텍스트 정보의 타입 각각에 대응되 는 제1 및 제2 위험 상황 정보를 식별하고, 상기 제1 컨텍스트 정보에 대응되는 적어도 하나의 센싱 데이터에 기초하여 상기 착용형 로봇의 주변 환경이 제1 위험 상황에 해당하는지 여부를 식별하고, 상기 제2 컨텍스트 정 보에 대응되는 적어도 하나의 센싱 데이터에 기초하여 상기 착용형 로봇의 주변 환경이 제2 위험 상황에 해당하 는지 여부를 식별하고, 상기 제1 위험 상황 및 상기 제2 위험 상황이 식별되면, 상기 안전 템플릿에 기초하여 상기 제1 위험 상황에 맵핑된 적어도 하나의 제1 제어 정보 및 상기 제2 위험 상황에 맵핑된 적어도 하나의 제2 제어 정보를 획득할 수 있다. 또한, 상기 전자 장치는, 상기 착용형 로봇으로 구현되며, 상기 착용형 로봇은, 구동부,를 더 포함하며, 상기 하나 이상의 프로세서는, 상기 적어도 하나의 사용자 디바이스로부터 수신된 복수의 센싱 데이터에 기초하여 동 일한 타입의 컨텍스트 정보가 식별되면, 상기 식별된 컨텍스트 정보의 타입에 기초하여 위험 상황 정보를 식별 하고, 상기 복수의 센싱 데이터에 기초하여 상기 착용형 로봇의 주변 환경이 상기 위험 상황 정보에 대응되는 위험 상황에 해당되는 것으로 식별되면, 상기 안전 템플릿에 기초하여 상기 식별된 위험 상황에 맵핑된 제어 신 호를 획득하고, 상기 제어 신호에 기초하여 상기 구동부를 제어할 수 있다. 여기서, 상기 복수의 센싱 데이터는 제1 센싱 데이터 및 제2 센싱 데이터를 포함하며, 상기 하나 이상의 프로세 서는, 상기 제1 센싱 데이터에 기초하여 상기 위험 상황이 식별되고 상기 제2 센싱 데이터에 기초하여 상기 위 험 상황이 식별되면, 상기 안전 템플릿에 기초하여 상기 위험 상황에 맵핑된 제어 신호를 획득할 수 있다. 여기서, 상기 하나 이상의 프로세서는, 상기 적어도 하나의 사용자 디바이스로부터 수신된 특정 타입의 컨텍스 트 정보에 대응되는 센싱 데이터가 임계 개수 미만이면, 상기 안전 템플릿에 기초하여 상기 위험 상황에 맵핑된 알림(Notification) 정보를 획득하고, 상기 획득된 알림 정보를 상기 통신 인터페이스를 통해 상기 적어도 하나 의 사용자 디바이스로 전송할 수 있다. 또한, 상기 하나 이상의 프로세서는, 상기 위험 상황 정보가 식별되면, 상기 적어도 하나의 센싱 데이터 및 상 기 위험 상황 정보를 학습된 인공 지능 모델에 입력하여 상기 착용형 로봇의 주변 환경이 상기 위험 상황에 해 당하는지 여부를 식별할 수 있다. 여기서, 상기 상이한 타입의 복수의 컨텍스트 정보는, 주변 사물 인식 정보, 주변 지형 인식 정보, 고도 인식 정보, 온도/습도 인식 정보, 시간대 인식 정보 또는 과운동 인식 정보 중 적어도 하나를 포함하며, 상기 위험 상황 정보는, 충돌 회피 상황 정보, 사용 불가 상황 정보, 사용 주의 상황 정보, 사용 제한 상황 정보 또는 오 동작 상황 정보 중 적어도 하나를 포함하며, 상기 제어 정보는, 소리 알림 정보, 상기 착용형 로봇의 운동 강도 정보, 전원 제어 정보, 주변음 청취 제어 정보 또는 플래쉬 제어 정보 중 적어도 하나를 포함할 수 있다. 또한, 상기 전자 장치는, 상기 착용형 로봇 또는 서버로 구현되며, 상기 서버는, 상기 획득된 적어도 하나의 제 어 정보에 기초하여 상기 통신 인터페이스를 통해 상기 착용형 로봇 또는 상기 사용자 디바이스 중 적어도 하나로 제어 신호를 전송할 수 있다. 여기서, 상기 하나 이상의 프로세서는, 상기 위험 상황 정보가 식별되면, 상기 적어도 하나의 센싱 데이터 및 상기 위험 상황 정보를 학습된 인공 지능 모델에 입력하여 상기 착용형 로봇의 주변 환경이 상기 위험 상황에 해당하는지 여부를 식별할 수 있다. 여기서, 상기 적어도 하나의 사용자 디바이스는, 스마트 폰, 스마트 워치(Watch) 또는 블루투스 이어폰 (Bluetooth earphone) 중 적어도 하나를 포함할 수 있다. 이상과 같은 목적을 달성하기 위한 일 실시 예에 따른 안전 기능을 수행하는 전자 장치의 제어 방법은, 상이한 타입의 복수의 컨텍스트 정보, 상기 복수의 컨텍스트 정보 각각에 맵핑된 위험 상황 정보 및 상기 위험 상황 각 각에 맵핑된 제어 정보를 포함하는 안전 템플릿 정보를 획득하는 단계를 포함할 수 있다. 제어 방법은, 적어도 하나의 사용자 디바이스로부터 적어도 하나의 센싱 데이터가 수신되면, 상기 적어도 하나의 센싱 데이터에 대응 되는 컨텍스트 정보를 식별하는 단계를 포함할 수 있다. 제어 방법은, 상기 안전 템플릿 정보 및 상기 컨텍스트 정보의 타입에 기초하여 위험 상황 정보를 식별하는 단계를 포함할 수 있다. 제어 방법은, 상기 적어도 하나의 센싱 데이터에 기초하여 착용형 로봇의 주변 환경이 상기 식별된 위험 상황 정보에 대응되는 위험 상황에 해당 하는지 여부를 식별하는 단계를 포함할 수 있다. 제어 방법은, 상기 위험 상황에 해당되는 것으로 식별되면, 상 기 안전 템플릿에 기초하여 상기 위험 상황에 맵핑된 적어도 하나의 제어 정보를 획득하는 단계를 포함할 수 있 다. 제어 방법은, 상기 획득된 적어도 하나의 제어 정보에 기초하여 상기 착용형 로봇 또는 상기 사용자 디바이 스 중 적어도 하나를 제어하는 단계를 포함할 수 있다. 여기서, 상기 위험 상황 정보를 식별하는 단계는, 상기 적어도 하나의 사용자 디바이스로부터 수신된 복수의 센 싱 데이터에 기초하여 제1 및 제2 컨텍스트 정보가 식별되면, 상기 제1 및 상기 제2 컨텍스트 정보의 타입 각각 에 대응되는 제1 및 제2 위험 상황 정보를 식별하는 단계를 포함하고, 상기 위험 상황에 해당하는지 여부를 식 별하는 단계는, 상기 제1 컨텍스트 정보에 대응되는 적어도 하나의 센싱 데이터에 기초하여 상기 착용형 로봇의 주변 환경이 제1 위험 상황에 해당하는지 여부를 식별하는 단계 및 상기 제2 컨텍스트 정보에 대응되는 적어도 하나의 센싱 데이터에 기초하여 상기 착용형 로봇의 주변 환경이 제2 위험 상황에 해당하는지 여부를 식별하는 단계를 포함하고, 상기 제어 정보를 획득하는 단계는, 상기 제1 위험 상황 및 상기 제2 위험 상황이 식별되면, 상기 안전 템플릿에 기초하여 상기 제1 위험 상황에 맵핑된 적어도 하나의 제1 제어 정보 및 상기 제2 위험 상 황에 맵핑된 적어도 하나의 제2 제어 정보를 획득할 수 있다. 여기서, 상기 전자 장치는, 상기 착용형 로봇으로 구현되며, 상기 위험 상황 정보를 식별하는 단계는, 상기 적 어도 하나의 사용자 디바이스로부터 수신된 복수의 센싱 데이터에 기초하여 동일한 타입의 컨텍스트 정보가 식 별되면, 상기 식별된 컨텍스트 정보의 타입에 기초하여 위험 상황 정보를 식별하고, 상기 제어 정보를 획득하는 단계는, 상기 복수의 센싱 데이터에 기초하여 상기 착용형 로봇의 주변 환경이 상기 위험 상황 정보에 대응되는 위험 상황에 해당되는 것으로 식별되면, 상기 안전 템플릿에 기초하여 상기 식별된 위험 상황에 맵핑된 제어 신 호를 획득하고, 상기 제어하는 단계는, 상기 제어 신호에 기초하여 구동부를 제어할 수 있다. 여기서, 상기 복수의 센싱 데이터는 제1 센싱 데이터 및 제2 센싱 데이터를 포함하며, 상기 제어 신호를 획득하 는 단계는, 상기 제1 센싱 데이터에 기초하여 상기 위험 상황이 식별되고 상기 제2 센싱 데이터에 기초하여 상 기 위험 상황이 식별되면, 상기 안전 템플릿에 기초하여 상기 위험 상황에 맵핑된 제어 신호를 획득할 수 있다. 여기서, 상기 제어 정보를 획득하는 단계는, 상기 적어도 하나의 사용자 디바이스로부터 수신된 특정 타입의 컨 텍스트 정보에 대응되는 센싱 데이터가 임계 개수 미만이면, 상기 안전 템플릿에 기초하여 상기 위험 상황에 맵 핑된 알림(Notification) 정보를 획득하는 단계를 포함하고, 상기 제어하는 단계는, 상기 획득된 알림 정보를 상기 적어도 하나의 사용자 디바이스로 전송할 수 있다. 또한, 상기 위험 상황에 해당하는지 여부를 식별하는 단계는, 상기 위험 상황 정보가 식별되면, 상기 적어도 하 나의 센싱 데이터 및 상기 위험 상황 정보를 학습된 인공 지능 모델에 입력하여 상기 착용형 로봇의 주변 환경 이 상기 위험 상황에 해당하는지 여부를 식별할 수 있다. 여기서, 상기 상이한 타입의 복수의 컨텍스트 정보는, 주변 사물 인식 정보, 주변 지형 인식 정보, 고도 인식 정보, 온도/습도 인식 정보, 시간대 인식 정보 또는 과운동 인식 정보 중 적어도 하나를 포함하며, 상기 위험 상황 정보는, 충돌 회피 상황 정보, 사용 불가 상황 정보, 사용 주의 상황 정보, 사용 제한 상황 정보 또는 오 동작 상황 정보 중 적어도 하나를 포함하며, 상기 제어 정보는, 소리 알림 정보, 상기 착용형 로봇의 운동 강도 정보, 전원 제어 정보, 주변음 청취 제어 정보 또는 플래쉬 제어 정보 중 적어도 하나를 포함할 수 있다.여기서, 상기 전자 장치는, 서버로 구현되며, 상기 제어하는 단계는, 상기 획득된 적어도 하나의 제어 정보에 기초하여 상기 착용형 로봇 또는 상기 사용자 디바이스 중 적어도 하나로 제어 신호를 전송할 수 있다. 여기서, 상기 위험 상황에 해당하는지 여부를 식별하는 단계는, 상기 위험 상황 정보가 식별되면, 상기 적어도 하나의 센싱 데이터 및 상기 위험 상황 정보를 학습된 인공 지능 모델에 입력하여 상기 착용형 로봇의 주변 환 경이 상기 위험 상황에 해당하는지 여부를 식별할 수 있다. 여기서, 상기 적어도 하나의 사용자 디바이스는, 스마트 폰, 스마트 워치(Watch) 또는 블루투스 이어폰 (Bluetooth earphone) 중 적어도 하나를 포함할 수 있다. 한편, 전자 장치의 프로세서에 의해 실행되는 경우 상기 전자 장치가 동작을 수행하도록 하는 컴퓨터 명령을 저 장하는 비일시적 컴퓨터 판독 가능 기록 매체에 있어서, 상기 동작은, 상이한 타입의 복수의 컨텍스트 정보, 상 기 복수의 컨텍스트 정보 각각에 맵핑된 위험 상황 정보 및 상기 위험 상황 각각에 맵핑된 제어 정보를 포함하 는 안전 템플릿 정보를 획득하는 단계를 포함할 수 있다. 상기 동작은, 적어도 하나의 사용자 디바이스로부터 적어도 하나의 센싱 데이터가 수신되면, 상기 적어도 하나의 센싱 데이터에 대응되는 컨텍스트 정보를 식별하는 단계를 포함할 수 있다. 상기 동작은, 상기 안전 템플릿 정보 및 상기 컨텍스트 정보의 타입에 기초하여 위험 상황 정보를 식별하는 단계를 포함할 수 있다. 상기 동작은, 상기 적어도 하나의 센싱 데이터에 기초하여 착용 형 로봇의 주변 환경이 상기 식별된 위험 상황 정보에 대응되는 위험 상황에 해당하는지 여부를 식별하는 단계 를 포함할 수 있다. 상기 동작은, 상기 위험 상황에 해당되는 것으로 식별되면, 상기 안전 템플릿에 기초하여 상기 위험 상황에 맵핑된 적어도 하나의 제어 정보를 획득하는 단계를 포함할 수 있다. 상기 동작은, 상기 획득 된 적어도 하나의 제어 정보에 기초하여 상기 착용형 로봇 또는 상기 사용자 디바이스 중 적어도 하나를 제어하 는 단계를 포함할 수 있다."}
{"patent_id": "10-2022-0102810", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하에서는 첨부 도면을 참조하여 본 개시를 상세히 설명한다. 본 명세서에서 사용되는 용어에 대해 간략히 설명하고, 본 개시에 대해 구체적으로 설명하기로 한다. 본 개시의 실시 예에서 사용되는 용어는 본 개시에서의 기능을 고려하면서 가능한 현재 널리 사용되는 일반적인 용어들을 선택하였으나, 이는 당 분야에 종사하는 기술자의 의도 또는 판례, 새로운 기술의 출현 등에 따라 달 라질 수 있다. 또한, 특정한 경우는 출원인이 임의로 선정한 용어도 있으며, 이 경우 해당되는 개시의 설명 부 분에서 상세히 그 의미를 기재할 것이다. 따라서 본 개시에서 사용되는 용어는 단순한 용어의 명칭이 아닌, 그 용어가 가지는 의미와 본 개시의 전반에 걸친 내용을 토대로 정의되어야 한다. 본 명세서에서, \"가진다,\" \"가질 수 있다,\" \"포함한다,\" 또는 \"포함할 수 있다\" 등의 표현은 해당 특징(예: 수 치, 기능, 동작, 또는 부품 등의 구성요소)의 존재를 가리키며, 추가적인 특징의 존재를 배제하지 않는다.A 또는/및 B 중 적어도 하나라는 표현은 \"A\" 또는 \"B\" 또는 \"A 및 B\" 중 어느 하나를 나타내는 것으로 이해되어 야 한다. 본 명세서에서 사용된 \"제1,\" \"제2,\" \"첫째,\" 또는 \"둘째,\"등의 표현들은 다양한 구성요소들을, 순서 및/또는 중요도에 상관없이 수식할 수 있고, 한 구성요소를 다른 구성요소와 구분하기 위해 사용될 뿐 해당 구성요소들 을 한정하지 않는다. 어떤 구성요소(예: 제1 구성요소)가 다른 구성요소(예: 제2 구성요소)에 \"(기능적으로 또는 통신적으로) 연결되 어((operatively or communicatively) coupled with/to)\" 있다거나 \"접속되어(connected to)\" 있다고 언급된 때에는, 어떤 구성요소가 다른 구성요소에 직접적으로 연결되거나, 다른 구성요소(예: 제3 구성요소)를 통하여 연결될 수 있다고 이해되어야 할 것이다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 출원에서, \"포함하다\" 또 는 \"구성되다\" 등의 용어는 명세서상에 기재된 특징, 숫자, 단계, 동작, 구성요소, 부품 또는 이들을 조합한 것 이 존재함을 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성요소, 부품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되어야 한다. 본 개시에서 \"모듈\" 혹은 \"부\"는 적어도 하나의 기능이나 동작을 수행하며, 하드웨어 또는 소프트웨어로 구현되 거나 하드웨어와 소프트웨어의 결합으로 구현될 수 있다. 또한, 복수의 \"모듈\" 혹은 복수의 \"부\"는 특정한 하드 웨어로 구현될 필요가 있는 \"모듈\" 혹은 \"부\"를 제외하고는 적어도 하나의 모듈로 일체화되어 적어도 하나의 프 로세서(미도시)로 구현될 수 있다. 도 1a 및 1b는 일 실시 예에 따른 전자 장치의 제어 방법을 개략적으로 설명하기 위한 도면이다. 도 1a 및 1b에 따르면, 전자 장치는 적어도 하나의 사용자 디바이스로부터 센싱 데이터를 수신하고, 수신된 센싱 데이터를 이용하여 로봇의 주변 환경이 위험 상황에 해당하는지 여부를 식별할 수 있다. 사용 자 디바이스는 사용자가 현재 착용 중인 사용자 디바이스이며, 예를 들어 스마트 폰, 스마트 워치(Watch) 또는 블루투스 이어폰(Bluetooth earphone) 중 적어도 하나를 포함할 수 있으나 이에 한정되지 않는다. 적어도 하나의 사용자 디바이스는 전자 장치와 통신을 수행할 수 있는 다양한 타입의 디바이스를 포함할 수 있다. 여기서, 도 1a에 도시된 바와 같이 전자 장치는 서버로 구현될 수 있으며, 로봇은 예를 들어 착용 형 로봇(Wearable Robot)일 수 있다. 일 예에 따라, 서버는 적어도 하나의 사용자 디바이스 각각에 포 함된 센서로부터 획득된 센싱 데이터, 예를 들어 카메라를 통해 획득된 영상 데이터를 수신할 수 있다. 일 예에 따라, 서버는 적어도 하나의 디바이스로부터 영상 데이터가 수신되면, 영상 데이터를 분석하여 로봇 의 주변 환경이 위험 상황에 해당하는지 여부를 식별할 수 있다. 예를 들어, 서버는 수신된 영상 데이 터를 분석하여 로봇의 정면에 장애물이 존재하는 것으로 식별할 수 있다. 일 예에 따라, 전자 장치는 로봇이 위험 상황에 해당되는 것으로 식별되면, 로봇 또는 적어도 하 나의 사용자 디바이스를 제어하여 위험 상황에 대응되는 동작을 수행할 수 있다. 예를 들어, 서버는 로 봇의 정면에 장애물이 존재하는 것으로 식별된 경우, 로봇의 전원이 OFF되도록 하는 제어 신호를 로봇 에 전송하거나, 주의 알림음(Warning sound)이 출력되도록 하는 제어 신호를 사용자 디바이스로 전송할 수 있다. 다만, 전자 장치는 도 1b에 도시된 바와 같이 로봇으로 구현될 수도 있다. 일 예에 따라, 로봇은 적어 도 하나의 디바이스로부터 영상 데이터가 수신되면, 영상 데이터를 분석하여 로봇의 주변 환경이 위험 상황에 해당하는지 여부를 식별할 수 있다. 예를 들어, 로봇은 수신된 영상 데이터를 분석하여 로봇의 정면에 장애물이 존재하는 것으로 식별할 수 있다. 일 예에 따라, 로봇은 로봇의 정면에 장애물이 존 재하는 것으로 식별된 경우, 로봇에 포함된 구동부(미도시)를 제어하여 로봇의 동작이 정지되도록 제어 할 수 있다. 또는, 로봇은 주의 알림음(Warning sound)이 출력되도록 하는 제어 신호를 사용자 디바이스 로 전송할 수도 있다. 이하에서는, 사용자 디바이스로부터 획득된 센싱 정보를 이용하여 착용형 로봇 주변 환경을 감시(또는, 모니터 링)하고, 이에 기초하여 안전 기능을 수행하는 다양한 실시 예에 대해 설명하도록 한다. 도 2는 일 실시 예에 따른 전자 장치의 구성을 나타내는 블록도이다. 도 2에 따르면, 전자 장치는 통신 인터페이스 및 프로세서를 포함할 수 있다. 전자 장치는 로봇 또는 서버 중 하나일 수 있다. 일 예에 따라, 로봇은 GEMS(Gait Enhancing and Motivating System)와 같은 착용형 로봇(Wearable Robot)일 수 있다. GEMS는 로보틱스(robotics) 기술을 기반으로 보행과 운동 기능을 보조하여, 사용자가 안정적으로 걸을 수 있도록 도와주는 웨어러블 보행 보조 로 봇이다. GEMS는 사용자 필요에 따라 고관절, 무릎, 발목 등에 착용해 보행에 관여하는 주요 근육의 부하를 덜어 준다. 다만, 이에 한정되지 않으며 로봇은 보조용 로봇, 재활용 로봇 및 증강용 로봇 중 어느 하나일 수 있 다. 전자 장치가 로봇으로 구현될 경우, 도 1b에 도시된 바와 같이 전자 장치는 적어도 하나의 사용자 디바이스와 통신을 수행할 수 있다. 전자 장치는 서버, 예를 들어, 컨텐츠 제공 서버, PC 등 컨텐츠를 제공할 수 있는 다양한 타입의 장치 로 구현될 수 있다. 또는 전자 장치는 클라우딩 컴퓨팅 환경이 구축된 시스템 자체일 수도 있다. 전자 장 치가 서버로 구현될 경우, 도 1a에 도시된 바와 같이 전자 장치는 로봇 및 적어도 하나의 사 용자 디바이스 각각에 대한 통신을 수행할 수 있다. 통신 인터페이스는 다양한 타입의 컨텐츠를 입력받는다. 예를 들어 통신 인터페이스는 AP 기반의 Wi- Fi(와이파이, Wireless LAN 네트워크), 블루투스(Bluetooth), 지그비(Zigbee), 유/무선 LAN(Local Area Network), WAN(Wide Area Network), 이더넷(Ethernet), IEEE 1394, HDMI(High-Definition Multimedia Interface), USB(Universal Serial Bus), MHL(Mobile High-Definition Link), AES/EBU(Audio Engineering Society/ European Broadcasting Union), 옵티컬(Optical), 코액셜(Coaxial 등과 같은 통신 방식을 통해 외부 장치(예를 들어, 소스 장치), 외부 저장 매체(예를 들어, USB 메모리), 외부 서버(예를 들어 웹 하드) 등으로부 터 스트리밍 또는 다운로드 방식으로 신호를 입력받을 수 있다. 일 실시 예에 따라, 프로세서는 통신 인터페이스를 통하여 적어도 하나의 디바이스로부터 센싱 데이 터를 획득할 수 있다. 하나 이상의 프로세서(이하, 프로세서)는 통신 인터페이스와 전기적으로 연결되어 전자 장치의 전반적인 동작을 제어한다. 프로세서는 하나 또는 복수의 프로세서로 구성될 수 있다. 구체적으로, 프로세 서는 메모리(미도시)에 저장된 적어도 하나의 인스트럭션을 실행함으로써, 본 개시의 다양한 실시 예에 따 른 전자 장치의 동작을 수행할 수 있다. 일 실시 예에 따라 프로세서는 디지털 영상 신호를 처리하는 디지털 시그널 프로세서(digital signal processor(DSP), 마이크로 프로세서(microprocessor), GPU(Graphics Processing Unit), AI(Artificial Intelligence) 프로세서, NPU (Neural Processing Unit), TCON(Time controller)으로 구현될 수 있다. 다만, 이에 한정되는 것은 아니며, 중앙처리장치(central processing unit(CPU)), MCU(Micro Controller Unit), MPU(micro processing unit), 컨트롤러(controller), 어플리케이션 프로세서(application processor(AP)), 또 는 커뮤니케이션 프로세서(communication processor(CP)), ARM 프로세서 중 하나 또는 그 이상을 포함하거나, 해당 용어로 정의될 수 있다. 또한, 프로세서는 프로세싱 알고리즘이 내장된 SoC(System on Chip), LSI(large scale integration)로 구현될 수도 있고, ASIC(application specific integrated circuit), FPGA(Field Programmable gate array) 형태로 구현될 수도 있다. 일 실시 예에 따라 프로세서는 디지털 시그널 프로세서(digital signal processor(DSP), 마이크로 프로세 서(microprocessor), TCON(Time controller)으로 구현될 수 있다. 다만, 이에 한정되는 것은 아니며, 중앙처리 장치(central processing unit(CPU)), MCU(Micro Controller Unit), MPU(micro processing unit), 컨트롤러 (controller), 어플리케이션 프로세서(application processor(AP)), 또는 커뮤니케이션 프로세서 (communication processor(CP)), ARM 프로세서 중 하나 또는 그 이상을 포함하거나, 해당 용어로 정의될 수 있 다. 또한, 프로세서는 프로세싱 알고리즘이 내장된 SoC(System on Chip), LSI(large scale integration) 로 구현될 수도 있고, FPGA(Field Programmable gate array) 형태로 구현될 수도 있다. 일 실시 예에 따라, 프로세서는 전자 장치에 포함된 적어도 하나의 하드웨어(Hardware)의 성능(또는 수행 능력)을 모니터링(Monitoring)하여, 적어도 하나의 하드웨어의 성능이 기 설정된 값 이하인지 여부를 식별 할 수 있다. 프로세서는 전자 장치에 포함된 적어도 하나의 하드웨어의 성능이 기 설정된 값 이하인 것으로 식별되면, 식별된 하드웨어를 통해 수행되는 특정 서비스를 식별할 수 있다. 이 후, 프로세서는 전 자 장치가 더 이상 식별된 특정 서비스를 수행할 수 없는 것으로 식별할 수 있다. 일 실시 예에 따라, 프로세서는 위험 상황에 대응되는 제어 정보를 포함하는 안전 템플릿 정보를 획득할 수 있다. 여기서, 안전 템플릿 정보는 식별된 위험 상황의 타입에 대응되는 제어 정보가 맵핑된 정보이다. 일 예에 따라, 프로세서는 메모리에 저장된 상이한 타입의 복수의 컨텍스트 정보, 상기 복수의 컨텍스트 정보 각각에 맵핑된 위험 상황 정보 및 상기 위험 상황 각각에 맵핑된 제어 정보를 포함하는 안전 템플릿 정보 를 획득할 수 있다. 여기서, 컨텍스트 정보는 예를 들어 주변 사물 인식 정보 또는 현재 로봇 주변 온도 정보와 같은 로봇 의 주변 환경에 대한 정보일 수 있다. 위험 상황 정보는 로봇의 주변 환경의 위험 수준 또는 상황 타입에 대한 정보로서, 예를 들어 로봇의 충돌 회피 상황 또는 로봇 사용 불가 상황 정보일 수 있다. 한편, 제 어 정보는 식별된 위험 상황에 대한 피드백 정보로서 예를 들어 로봇의 전원 OFF에 대응되는 제어 신호 또 는 사용자 디바이스의 플래쉬(Flash) ON에 대응되는 제어 신호일 수 있다. 안전 템플릿 정보에 대하여는 도 4a 및 4b를 통해 자세히 설명하도록 한다. 한편, 일 예에 따라, 안전 템플릿 정보는 메모리에 기 저장되어 있을 수 있다. 일 실시 예에 따라, 프로세서는 센싱 데이터에 기초하여 컨텍스트 정보를 식별할 수 있다. 일 예에 따라, 프로세서는 통신 인터페이스를 통해 적어도 하나의 사용자 디바이스로부터 적어도 하나의 센싱 데이 터가 수신되면, 수신된 적어도 하나의 센싱 데이터에 대응되는 컨텍스트 정보를 식별할 수 있다. 여기서, 센싱 데이터는 적어도 하나의 사용자 디바이스에 포함된 적어도 하나의 센서를 통해 획득된 데이터이며, 사용자 디바이스 중 하나인 스마트폰에 포함된 카메라를 통해 획득된 영상 정보일 수 있다. 센싱 데이터에 대하여는 도 4a를 통해 자세히 설명하도록 한다. 이 경우, 일 예에 따라, 센싱 데이터에 대응되는 컨텍스트 정보는 센싱 데이터 획득에 이용된 센서의 타입에 기 초하여 식별될 수 있다. 예를 들어, 메모리(미도시)에는 센서의 타입 정보에 대응되는 컨텍스트 정보가 저장되 어 있을 수 있으며, 프로세서는 수신된 센싱 데이터의 센서 타입 정보를 식별하고, 이에 대응되는 컨텍스 트 정보를 식별할 수 있다. 예를 들어, 프로세서는 사용자 디바이스에 포함된 카메라를 통해 영상 정보가 획득된 경우, 센서의 타입이 카메라인 것으로 식별하고, 이에 대응되는 컨텍스트 정보로서 주변 사물 인식 정보, 주변 지형 인식 정보 또는 고도 인식 정보 중 적어도 하나를 식별할 수 있다. 일 실시 예에 따라, 프로세서는 위험 상황 정보를 식별할 수 있다. 일 예에 따라, 프로세서는 안전 템플릿 정보 및 식별된 컨텍스트 정보의 타입에 기초하여 위험 상황 정보를 식별할 수 있다. 예를 들어, 프로세 서는 식별된 컨텍스트 정보의 타입이 주변 사물 인식 정보인 경우, 획득된 안전 템플릿 정보에 기초하여 주변 사물 인식 정보에 대응되는 충돌 회피 상황 정보를 위험 상황 정보로 식별할 수 있다. 일 실시 예에 따라, 프로세서는 착용형 로봇의 주변 환경이 위험 상황에 해당하는지 여부를 식별할 수 있 다. 일 예에 따라, 프로세서는 수신된 적어도 하나의 센싱 데이터 및 식별된 위험 상황 정보에 기초하여, 착용형 로봇의 주변 환경이 식별된 위험 상황 정보에 대응되는 위험 상황에 해당하는지 여부를 식별할 수 있다. 예를 들어, 로봇을 착용한 사용자의 정면에 대한 영상 정보가 센싱 데이터로 수신되고, 이에 대응되는 충돌 회피 상황 정보가 획득된 경우, 프로세서는 학습된 인공 지능 모델을 이용하여 로봇의 주변 환경이 현 재 충돌 회피 상황인지 여부를 식별할 수 있다. 이에 대하여는 도 7a 및 7b를 통해 자세히 설명하도록 한다. 이어서, 일 실시 예에 따라 프로세서는 식별된 위험 상황에 맵핑된 제어 정보를 획득할 수 있다. 일 예에 따라, 프로세서는 착용형 로봇의 주변 환경이 위험 상황에 해당되는 것으로 식별되면, 안전 템플릿에 기초 하여 식별된 위험 상황에 맵핑된 적어도 하나의 제어 정보를 획득할 수 있다. 예를 들어, 프로세서는 착용 형 로봇의 주변 환경이 충돌 회피 상황에 해당되는 것으로 식별되면, 안전 템플릿에 기초하여 충돌 회피 상황에 맵핑된 소리 알림 정보 또는 운동 강도 정보 중 적어도 하나를 획득할 수 있다. 이어서, 일 실시 예에 따라, 프로세서는 획득된 적어도 하나의 제어 정보에 기초하여 착용형 로봇 또는 사 용자 디바이스 중 적어도 하나를 제어할 수 있다. 제어 정보에는 로봇 또는 적어도 하나의 사용자 디바이스 에 대한 동작 정보(예를 들어, 로봇의 전원이 OFF되도록 제어하는 신호에 대한 정보 또는 사용자 디바 이스가 플래쉬(Flash) 모드를 작동하도록 제어하는 신호에 대한 정보)가 포함되어 있을 수 있으며, 이는 도 4b를 통해 자세히 설명하도록 한다. 일 예에 따라, 프로세서는 획득된 소리 알림 정보 및 운동 강도 정보가 획득된 경우, 소리 알림(예를 들 어, “전방에 장애물이 감지되었습니다. 조심하세요”)에 대응되는 제어 신호를 통신 인터페이스를 통해 사용자 디바이스인 스마트 폰으로 전송할 수 있다. 또는, 일 예에 따라, 전자 장치가 서버로 구현된 경우, 프로세서는 획득된 운동 강도 정보에 기 초하여 로봇의 운동 강도가 기 설정된 값 미만이 되도록 하는 제어 신호를 통신 인터페이스를 통해 로 봇으로 전송할 수 있다. 여기서 기 설정된 값은 초기 설정시 메모리(미도시)에 저장된 값일 수 있으나 이에 한정되지 않으며, 사용자 설정에 따라 이후 기 설정된 값은 변경될 수 있음은 물론이다. 한편, 일 예에 따라, 전자 장치가 로봇으로 구현된 경우, 프로세서는 획득된 운동 강도 정보에 기초하여 운동 강도가 기 설정된 값 미만이 되도록 구동부(미도시)를 제어할 수 있다. 이에 따라, 전자 장치는 사용자가 착용한 적어도 하나의 사용자 디바이스로부터 수신된 센싱 데이터를 이용하여 로봇을 착용한 사용자의 주변 환경의 위험 상황을 식별할 수 있게 되며, 이에 따라 사용자의 안전성이 확보될 수 있다. 도 3은 일 실시 예에 따른 전자 장치의 제어 방법을 설명하기 위한 흐름도이다. 일 실시 예에 따라, 제어 방법은 컨텍스트 정보, 컨텍스트 정보 각각에 맵핑된 위험 상황 정보 및 위험 상황 각 각에 맵핑된 제어 정보를 포함하는 안전 템플릿 정보를 획득할 수 있다(S310). 이어서, 일 실시 예에 따라, 제어 방법은 적어도 하나의 사용자 디바이스로부터 적어도 하나의 센싱 데이터가 수신되는지 여부를 식별할 수 있다(S320). 일 예에 따라, 제어 방법은 사용자의 스마트폰에 포함된 카메라를 통 해 획득된 영상 정보가 통신 인터페이스를 통해 수신되면, 이를 통해 사용자 디바이스로부터 센싱 데이터 가 수신된 것으로 식별할 수 있다. 일 예에 따라, 제어 방법은 사용자의 스마트 워치에 포함된 심박 센서를 통 해 획득된 사용자의 심박 정보를 수신할 수도 있다. 이어서, 일 실시 예에 따라, 제어 방법은 적어도 하나의 사용자 디바이스로부터 적어도 하나의 센싱 데이터가 수신되면(Y), 적어도 하나의 센싱 데이터에 대응되는 컨텍스트 정보를 식별할 수 있다(S330). 일 예에 따라, 사 용자가 착용한 스마트 워치로부터 사용자의 심박 정보가 수신되면, 제어 방법은 수신된 심박 정보의 센서 타입 인 심박 센서를 식별하고, 메모리에 저장된 정보에 기초하여 식별된 센서 타입에 대응되는 컨텍스트 정보 인 과운동 인식 정보를 식별할 수 있다. 이어서, 일 실시 예에 따라, 제어 방법은 안전 템플릿 정보 및 컨텍스트 정보의 타입에 기초하여 위험 상황 정 보를 식별할 수 있다(S340). 일 예에 따라, 제어 방법은 식별된 심박 센서에 대응되는 컨텍스트 정보로 과운동 인식 정보가 식별되면, 획득된 안전 템플릿 정보에 기초하여 과운동 인식 정보에 맵핑된 위험 상황 정보인 사용 제한 상황 정보를 식별할 수 있다. 일 실시 예에 따라, 제어 방법은 착용형 로봇의 주변 환경이 식별된 위험 상황 정보에 대응되는 위험 상황에 해 당되는지 여부를 식별할 수 있다(S350). 일 예에 따라, 제어 방법은 수신된 사용자의 심박 정보에 기초하여 로 봇의 사용 제한 상황에 해당하는지 여부를 식별할 수 있다. 예를 들어, 제어 방법은 학습된 인공 지능 모델 에 수신된 사용자의 심박 정보 및 식별된 위험 상황 정보인 사용 제한 상황 정보를 입력하여, 로봇이 사용 제한 상황에 해당하는지 여부를 식별할 수 있다. 또는, 예를 들어, 제어 방법은, 수신된 사용자의 심박수가 임 계 값 이상인 것으로 식별되면, 로봇이 사용 제한 상황에 해당하는 것으로 식별할 수도 있다. 일 실시 예에 따라, 제어 방법은 착용형 로봇의 주변 환경이 식별된 위험 상황 정보에 대응되는 위험 상황에 해 당되는 것으로 식별되면(Y), 안전 템플릿 정보에 기초하여 위험 상황에 맵핑된 적어도 하나의 제어 정보를 획득 할 수 있다(S360). 일 예에 따라, 제어 방법은 사용자의 심박수가 임계 값 이상임에 따라 로봇이 사용 제한 상황에 해당하는 것으로 식별되면, 사용 제한 상황 정보에 맵핑된 운동 강도 정보(또는, 운동 강도 제어 정보) 를 획득할 수 있다. 일 실시 예에 따라, 제어 방법은 획득된 적어도 하나의 제어 정보에 기초하여 착용형 로봇 또는 사용자 디바이 스 중 적어도 하나를 제어할 수 있다(S370). 일 예에 따라, 전자 장치가 로봇으로 구현된 경우, 제어 방법은 사용 제한 상황 정보에 맵핑된 운동 강도 정보에 기초하여 로봇의 운동 강도가 기 설정된 값 미만이 되도록 구동부(미도시)를 제어할 수 있다. 도 4a 내지 4b는 일 실시 예에 따른 센싱 데이터 및 안전 템플릿 정보를 설명하기 위한 도면이다. 일 실시 예에 따라 프로세서는 획득된 센싱 데이터 및 안전 템플릿 정보에 기초하여 로봇 또는 적어도 하나의 사용자 디바이스를 제어할 수 있다. 먼저, 일 실시 예에 따라, 도 4a에 따르면, 프로세서는 적어도 하나의 사용자 디바이스(31 내지 33)로부터 획득된 센싱 데이터에 대응되는 적어도 하나의 컨텍스트 정보를 식별할 수 있다. 한편, 일 예에 따라 상이 한 타입의 복수의 컨텍스트 정보는 주변 사물 인식 정보, 주변 지형 인식 정보, 고도 인식 정보, 온도/습도 인식 정보, 시간대 인식 정보 또는 과운동 인식 정보 중 적어도 하나를 포함 할 수 있으나 이에 한정되는 것은 아니며, 상이한 타입의 컨텍스트 정보를 더 포함할 수 있다. 일 예에 따라 센싱 데이터에 대응되는 컨텍스트 정보는 센싱 데이터 획득에 이용된 적어도 하나의 센서 의 타입에 기초하여 식별될 수 있다. 여기서, 메모리(미도시)에는 센서의 타입에 대한 정보(또는, 센 싱 데이터의 타입 정보, 401 내지 409) 및 각각의 타입 정보(401 내지 409)에 맵핑된 컨텍스트 정보가 저 장되어 있을 수 있다. 일 예에 따라, 센서의 타입에 대한 정보(또는, 센서 타입 정보, 또는, 센싱 데이터 의 타입 정보)는 카메라 타입 정보, 기압계 센서 타입 정보, 조도 센서 타입 정보, 온도/습도 센서 타입 정보, 가속도 센서 타입 정보, 심박 센서 타입 정보, 근접 센서 타입 정보, 마 이크 타입 정보 및 스피커 타입 정보를 포함할 수 있으나, 이에 한정되는 것은 아니며 상이한 타입의 센서 타입 정보를 포함할 수 있음은 물론이다. 일 예에 따라, 프로세서는 수신된 센싱 데이터의 센서 타입 정보를 식별하고, 메모리(미도시)에 저장된 정 보에 기초하여 식별된 센서 타입 정보에 대응되는 컨텍스트 정보를 식별할 수 있다. 예를 들어, 프로세서 는 스마트폰에 포함된 카메라를 통해 영상 정보가 획득된 경우, 카메라에 대응되는 센서 타입 정보를 식별하고, 이에 대응되는 컨텍스트 정보로서 주변 사물 인식 정보, 주변 지형 인식 정보 또는 고도 인식 정보 중 적어도 하나를 식별할 수 있다. 또는, 예를 들어, 프로세서는 스마트 워치에 포함된 조도 센서를 통해 조도 정보가 획득된 경우, 조도 센서의 타입 정보를 식별하고, 이에 대응되는 컨텍스트 정보로서 시간대 인식 정보를 식별할 수 있다. 이 후, 프로세서는 컨텍스트 정보가 식별되면, 컨텍스트 정보의 타입에 기초하여 위험 상황 정보를 식별할 수 있다. 일 실시 예에 따라, 도 4b에 따르면 프로세서는 안전 템플릿 정보에 기초하여 식별된 컨텍스트 정보 에 대응되는 위험 상황 정보를 식별할 수 있다. 일 예에 따라, 안전 템플릿 정보는 상이한 타입 의 컨텍스트 정보, 위험 상황 정보 및 제어 정보를 포함할 수 있다. 일 예에 따라, 위험 상황 정보는, 충돌 회피 상황 정보, 사용 불가 상황 정보, 사용 주의 상황 정보, 사용 제한 상 황 정보 또는 오동작 상황 정보 중 적어도 하나를 포함할 수 있으나, 이에 한정되는 것은 아니며 상 이한 타입의 상황 정보를 더 포함할 수도 있음은 물론이다. 일 예에 따라, 프로세서는 안전 템플릿 정보 및 컨텍스트 정보의 타입에 기초하여 위험 상황 정보를 식별 할 수 있다. 예를 들어, 조도 센서의 타입 정보가 식별되고, 이에 대응되는 컨텍스트 정보로서 시간대 인 식 정보가 식별된 경우를 상정한다. 이 경우, 프로세서는 컨텍스트 정보로서 시간대 인식 정보 가 식별되면, 시간대 인식 정보의 타입에 기초하여 이에 대응되는 위험 상황 정보로서 사용 주의 상황 정 보를 식별할 수 있다. 이 후, 일 실시 예에 따라, 프로세서는 적어도 하나의 센싱 데이터에 기초하여 착용형 로봇의 주변 환 경이 식별된 위험 상황에 해당되는 것으로 식별되면, 안전 템플릿 정보에 기초하여 위험 상황에 맵핑된 적 어도 하나의 제어 정보를 획득할 수 있다. 일 예에 따라, 제어 정보는, 소리 알림 정보, 착용형 로봇의 운동 강도 정보, 전원 제어 정보, 주변음 청취 제어 정보 또는 플래쉬 제어 정보 중 적어도 하나를 포함할 수 있으나 이에 한정되지 않으며 상이한 타입의 제어 정보를 더 포함할 수 있음 은 물론이다. 일 예에 따라, 프로세서는 수신된 조도 정보에 기초하여 주변 환경의 조도가 기 설정된 값 미만인 것으로 식별되면, 주변 환경이 사용 주의 상황인 것으로 식별할 수 있다. 이어서, 프로세서는 안전 템플릿 정보를 이용하여 사용 주의 상황에 맵핑된 제어 정보로 주변음 청취 정보 또는 플래쉬 제어 정 보 중 적어도 하나를 획득할 수 있다. 일 실시 예에 따라, 프로세서는 획득된 주변음 청취 정보 및 플래쉬 제어 정보가 획득된 경우, 이에 대응되는 제어 신호를 통신 인터페이스를 통해 사용자 디바이스로 전송할 수 있다. 또는 프로세 서는 상술한 제어 정보에 기초하여 구동부(미도시)를 제어할 수 있다. 일 예에 따라, 전자 장치가 서버로 구현된 경우, 프로세서는 획득된 주변음 청취 정보에 기초하 여 사용자의 블루투스 이어폰이 주변음 청취 기능을 수행하도록 제어하는 신호를 통신 인터페이스를 통해 블루투스 이어폰에 전송할 수 있다. 또는, 프로세서는 사용자의 스마트 폰이 플래쉬 ON 기능 을 수행하도록 제어하는 신호를 통신 인터페이스를 통해 스마트 폰에 전송할 수도 있다.한편, 도 2로 돌아와서, 일 실시 예에 따라 프로세서는 적어도 하나의 사용자 디바이스로부터 복수의 센싱 데이터가 수신되면, 복수의 센싱 데이터 각각에 대응되는 제어 정보를 획득할 수 있다. 먼저, 일 예에 따라 적어도 하나의 사용자 디바이스로부터 수신된 복수의 센싱 데이터에 기초하여 제1 및 제2 컨텍스트 정보가 식별되면, 프로세서는 제1 및 제2 컨텍스트 정보의 타입 각각에 대응되는 제1 및 제2 위험 상황 정보를 식별할 수 있다. 예를 들어, 스마트 폰에 포함된 카메라 센서를 통해 영상 정보가 수신되 고, 스마트 워치에 포함된 심박 센서를 통해 사용자의 심박 정보가 수신된 경우를 상정한다. 프로세서(12 0)는 안전 템플릿 정보에 기초하여 수신된 영상 정보에 대응되는 주변 사물 인식 정보를 식별하고, 수신된 심박 정보에 대응되는 과운동 인식 정보를 식별할 수 있다. 이어서, 프로세서는 식별된 각각 의 컨텍스트 정보에 대응되는 위험 상황 정보로서 충돌 회피 상황 정보 및 사용 제한 상황 정보를 식 별할 수 있다. 이어서, 일 예에 따라, 프로세서는 제1 컨텍스트 정보에 대응되는 적어도 하나의 센싱 데이터에 기초하여 착용형 로봇의 주변 환경이 제1 위험 상황에 해당하는지 여부를 식별할 수 있다. 예를 들어, 프로세서(12 0)는 주변 사물 인식 정보에 대응되는 영상 정보에 기초하여 착용형 로봇 정면에 장애물이 존재하는 것으로 식별되면, 착용형 로봇의 주변 환경이 충돌 회피 상황에 해당하는 것으로 식별할 수 있다. 일 예에 따라, 프로세서는 제2 컨텍스트 정보에 대응되는 적어도 하나의 센싱 데이터에 기초하여 착용형 로봇의 주변 환경이 제2 위험 상황에 해당하는지 여부를 식별할 수 있다. 예를 들어, 프로세서는 과운 동 인식 정보에 대응되는 사용자의 심박 정보에 기초하여 로봇을 착용한 사용자의 심박수가 임계 값 이상인 것으로 식별되면, 착용형 로봇의 주변 환경이 사용 제한 상황에 해당되는 것으로 식별할 수 있다. 이어서, 일 예에 따라 프로세서는 제1 위험 상황 및 제2 위험 상황이 식별되면, 안전 템플릿에 기초하여 제1 위험 상황에 맵핑된 적어도 하나의 제1 제어 정보 및 제2 위험 상황에 맵핑된 적어도 하나의 제2 제어 정보 를 각각 획득할 수 있다. 예를 들어, 프로세서는 충돌 회피 상황이 식별됨에 따라, 충돌 회피 상황 정보 에 대응되는 제어 정보로서 소리 알림 정보, 운동 강도 정보를 획득할 수 있다. 또한, 프로세서 는 사용 제한 상황이 식별됨에 따라, 사용 제한 상황 정보에 대응되는 제어 정보로서 운동 강도 정보 를 획득할 수 있다. 한편, 일 실시 예에 따라 프로세서는 복수의 센싱 데이터에 기초하여 동일한 타입의 컨텍스트 정보가 식별 되면, 복수의 센싱 데이터 각각에 기초하여 로봇이 위험 상황에 해당하는지 여부를 식별할 수 있다. 일 예에 따라, 전자 장치가 착용형 로봇으로 구현되는 경우를 상정한다. 일 예에 따라, 프로세서(12 0)는 적어도 하나의 사용자 디바이스로부터 수신된 복수의 센싱 데이터에 기초하여 동일한 타입의 컨텍스트 정보가 식별되면, 식별된 컨텍스트 정보의 타입에 기초하여 위험 상황 정보를 식별할 수 있다. 예를 들어, 카메 라를 통해 획득된 센싱 정보(또는, 센싱 데이터) 및 및 마이크를 통해 획득된 센싱 정보(또는, 센싱 데이터)가 수신된 경우, 프로세서는 먼저 수신된 복수의 센싱 데이터가 동일한 타입의 컨텍스트 정보(41 0)인 주변 사물 인식 정보인 것으로 식별할 수 있다. 이어서, 프로세서는 주변 사물 인식 정보 에 대응되는 위험 상황 정보인 충돌 회피 상황 정보를 식별할 수 있다. 이어서, 일 예에 따라 프로세서는 복수의 센싱 데이터에 기초하여 착용형 로봇의 주변 환경이 위험 상 황 정보에 대응되는 위험 상황에 해당되는 것으로 식별되면, 안전 템플릿에 기초하여 식별된 위험 상황에 맵핑 된 제어 신호를 획득할 수 있다. 이 경우, 일 예에 따라 프로세서는 복수의 센싱 데이터 각각에 기초하여 위험 상황에 해당하는지 여부를 식별할 수 있다. 예를 들어, 프로세서는 카메라를 통해 획득된 센싱 정보(또는, 센싱 데이터) 및 및 마이크를 통 해 획득된 센싱 정보 각각에 기초하여 로봇의 주변 환경이 충돌 회피 상황에 해당하는지 여부를 각각 식별 하고, 수신된 복수의 센싱 데이터 중 적어도 하나의 센싱 데이터에 따라 로봇 충돌 회피 상황에 해당하는 것으로 식별되면, 안전 템플릿에 기초하여 식별된 충돌 회피 상황에 맵핑된 제어 정보인 소리 알림 정보 또는 운동 강도 정보 중 적어도 하나를 획득할 수 있다. 일 예에 따라, 카메라를 통해 획득된 센싱 데이터에 기초하여 로봇의 주변 환경이 충돌 회피 상황에 해당하지 않는 것으로 식별되는 경우에도, 마이크를 통해 획득된 센싱 정보에 기초하여 주변 환경이 충돌 회피 상황에 해당하는 것으로 식별되면, 프 로세서는 안전 템플릿에 기초하여 제어 정보를 획득할 수 있게 된다. 이어서, 일 예에 따라 프로세서는 획득된 제어 정보에 기초하여 구동부(미도시)를 제어할 수 있다. 예를 들어, 프로세서는 획득된 제어 정보인 소리 알림 정보 또는 운동 강도 정보 중 적어도 하나에기초하여 이에 대응되는 제어 신호를 통신 인터페이스를 통하여 사용자 디바이스로 전송하거나, 획득 된 제어 정보에 기초하여 구동부(미도시)를 제어할 수 있다. 이 경우, 사용자 디바이스로 전송할지 또는 구 동부(미도시)를 제어할지 여부는 제어 정보의 타입에 기초하여 식별될 수 있다. 또는, 일 예에 따라 수신된 센 싱 데이터의 타입의 개수에 기초하여 식별될 수도 있다. 이는 도 6을 통해 자세히 설명하도록 한다. 한편, 일 실시 예에 따라, 프로세서는 제1 센싱 데이터에 기초하여 위험 상황이 식별되고 제2 센싱 데이터 에 기초하여 위험 상황이 식별되면, 안전 템플릿에 기초하여 위험 상황에 맵핑된 제어 신호를 획득할 수 있다. 여기서, 복수의 센싱 데이터는 제1 및 제2 센싱 데이터를 포함할 수 있다. 일 예에 따라, 프로세서는 카메라를 통해 획득된 센싱 정보(또는, 센싱 데이터) 및 및 마이크를 통해 획득된 센싱 정보 각각에 기초하여 로봇의 주변 환경이 충돌 회피 상황에 해당하는지 여부를 각각 식 별할 수 있다. 예를 들어, 프로세서는 카메라를 통해 획득된 센싱 데이터에 기초하여 충돌 회피 상황 에 해당되는 것으로 식별되고, 마이크를 통해 획득된 센싱 데이터에 기초하여 충돌 회피 상황에 해당되는 것으로 식별되면, 안전 템플릿에 기초하여 충돌 회피 상황에 대응되는 제어 정보를 획득할 수 있다. 다만, 이에 한정되는 것은 아니며, 일 예에 따라 프로세서는 제1 센싱 데이터에 기초하여 위험 상황이 식 별되지 않더라도, 제2 센싱 데이터에 기초하여 위험 상황이 식별되면, 안전 템플릿에 기초하여 위험 상황에 맵 핑된 제어 신호를 획득할 수 있음은 물론이다. 도 5는 일 실시 예에 따른 복수의 센싱 데이터가 수신된 경우의 전자 장치의 제어 방법을 설명하기 위한 도면이 다. 도 5에 따르면, 먼저 일 실시 예에 따라, 제어 방법은 수신된 센싱 데이터의 타입 별 개수를 식별할 수 있다 (S510). 일 예에 따라, 복수의 센싱 데이터가 수신된 경우, 프로세서는 수신된 복수의 센싱 데이터의 타입 (401 내지 409)을 식별할 수 있다. 예를 들어, 스마트 워치에 포함된 마이크를 통해 획득된 센싱 데이터 및 스마트 폰에 포함된 마이 크를 통해 획득된 센싱 데이터 각각이 수신된 경우, 프로세서는 마이크를 통해 획득된 센싱 데 이터가 2개인 것으로 식별할 수 있다. 이어서, 일 실시 예에 따라, 제어 방법은 수신된 센싱 데이터에 기초하여 로봇이 위험 상황에 해당하는지 여부를 식별할 수 있다(S520). 일 예에 따라, 프로세서는 스마트 폰에 포함된 마이크를 통해 획 득된 센싱 데이터 에 기초하여 로봇의 주변 환경이 충돌 회피 상황에 해당되는 것으로 식별되고, 스마트 워 치에 포함된 마이크를 통해 획득된 센싱 데이터에 기초하여 로봇의 주변 환경이 충돌 회피 상황에 해당되는 것으로 식별되면, 안전 템플릿에 기초하여 충돌 회피 상황에 대응되는 제어 정보를 획득할 수 있 다. 이 경우, 학습된 인공 지능 모델을 이용하여 로봇의 주변 환경이 충돌 회피 상황에 해당되는 것으로 식 별할 수 있다. 한편, 다른 예에 따라, 프로세서는 스마트 폰에 포함된 마이크를 통해 획득된 센싱 데이터에 기 초하여 로봇의 주변 환경이 충돌 회피 상황에 해당되는 것으로 식별되나, 스마트 워치에 포함된 마이크 를 통해 획득된 센싱 데이터에 기초하여서는 로봇의 주변 환경이 충돌 회피 상황에 해당되지 않는 것으로 식별되면, 제어 정보를 획득하지 않을 수 있다. 즉, 복수의 센싱 데이터 각각이 동일한 타입의 위험 상황 정보에 대응되는 경우, 프로세서는 복수의 센싱 데이터가 각각 위험 상황에 해당되는 것으로 식별되는 경우에만 제어 정보(또는, 제어 신호)를 획득하고, 획득 된 제어 정보에 기초하여 구동부를 제어할 수도 있다. 이에 따라, 로봇은 위험 상황에 해당 여부에 대한 판단의 정확도가 향상되며, 사용자는 안전 기능을 수행하는 로봇에 대한 신뢰도가 향상된다. 이어서, 일 실시 예에 따라 제어 방법은 사용자 디바이스와의 통신 상태를 식별할 수 있다(S530). 일 예에 따라, 로봇의 주변 환경이 충돌 회피 상황에 해당되는 것으로 식별된 경우, 프로세서는 소리 알림 정 보 또는 운동 강도 정보 중 적어도 하나를 획득할 수 있다. 이 경우, 일 예에 따라 전자 장치가 서버로 구현되는 경우, 프로세서는 통신 인터페이스를 통해 운동 강도 정보에 대응되는 제어 신호를 통신 인터페이스를 통해 로봇에 전송할 수 있다. 일 예에 따라, 제어 방법은 로봇과 사용자 디바이스와의 통신 상태를 식별하여, Hand Shaking이 원활하 게 수행되는 것으로 식별된 경우에만 통신 인터페이스를 통해 로봇에 전송할 수 있다. 또는, 일 예에 따라 전자 장치가 로봇으로 구현되는 경우, 프로세서는 로봇과 사용자 디바이스와의 통신 상태를 식별하여, Hand Shaking이 원활하게 수행되는 것으로 식별된 경우에만 구동부(미도시)를 제어할 수 있다. 도 2로 돌아와서, 일 실시 예에 따라 프로세서는 획득된 센싱 데이터 타입 별 개수에 기초하여 상이한 타 입의 제어 신호를 로봇 또는 적어도 하나의 사용자 디바이스에 전송할 수 있다. 이는 하기의 도 6을 통 해 자세히 설명하도록 한다. 도 6은 일 실시 예에 따른 상이한 타입의 제어 신호를 전송하는 방법을 설명하기 위한 도면이다. 도 6에 따르면, 일 실시 예에 따라, 프로세서는 제어 정보의 타입에 기초하여 제어 신호의 타입을 식별할 수 있다. 여기서, 제어 신호의 타입은 알림(Notification) 정보 또는 로봇의 구동부(미도시) 제어 신호 중 하나일 수 있다. 일 예에 따라, 프로세서는 식별된 제어 정보가 소리 알림 정보, 주변음 청취 정보 또는 플래쉬 제어 정보인 경우, 제어 신호의 타입이 알림 정보인 것으로 식별하고, 식별된 제어 신호의 타입에 기초하 여 통신 인터페이스를 통해 적어도 하나의 사용자 디바이스로 식별된 제어 정보에 대응되는 제어 신호 를 전송할 수 있다. 한편, 일 예에 따라, 프로세서는 식별된 제어 정보가 운동 강도 정보 또는 전원 제어 정보인 경 우, 로봇의 구동부(미도시) 제어 신호인 것으로 식별할 수 있다. 이어서, 프로세서는 식별된 제어 정 보가 구동부 제어 신호인 것으로 식별됨에 따라, 통신 인터페이스를 통해 로봇에 식별된 제어 신호를 전송할 수 있다. 또는, 프로세서는 식별된 제어 신호에 기초하여 구동부(미도시)를 제어할 수도 있다. 한편, 일 실시 예에 따라, 프로세서는 센싱 데이터의 타입 별 개수에 기초하여 제어 신호의 타입을 식별할 수 있다. 일 예에 따라, 프로세서는 센싱 데이터의 타입 별 개수가 임계 개수(예를 들어, 2개) 미만이면, 안전 템플릿에 기초하여 식별된 위험 상황에 맵핑된 제어 정보를 획득할 수 있다. 이 경우, 제어 정보의 타입은 알림 정보일 수 있다. 예를 들어, 프로세서는 스마트 워치에 포함된 마이크를 통해 획득된 센싱 데이터 및 스마트 폰 에 포함된 마이크를 통해 획득된 센싱 데이터 각각이 수신된 경우, 프로세서는 마이크를 통 해 획득된 센싱 데이터가 2개인 것으로 식별할 수 있다. 이어서, 프로세서는 수신된 복수의 센싱 데이터에 기초하여 로봇의 주변 환경이 충돌 회피 상황에 해당되는 것으로 판단되면, 안전 템플릿에 기초하여 운동 강도 정보를 획득할 수 있다. 이 경우, 수신된 센싱 데이터의 타입 별 개수가 2개 이상임에 따라, 프 로세서는 안전 템플릿에 기초하여 식별된 충돌 회피 상황에 맵핑된 운동 강도 정보를 획득할 수 있다. 이 경우, 운동 강도 정보는 구동부(미도시) 제어 신호일 수 있다. 또는, 예를 들어 프로세서는 스마트 폰에 포함된 마이크를 통해 획득된 센싱 데이터만이 수신된 경우, 마이크를 통해 획득된 센싱 데이터가 1개인 것으로 식별할 수 있다. 이어서, 프로세서는 수신 된 센싱 데이터에 기초하여 로봇의 주변 환경이 충돌 회피 상황에 해당되는 것으로 판단되면, 안전 템플릿 에 기초하여 운동 강도 정보를 획득할 수 있다. 이 경우, 수신된 센싱 데이터의 타입 별 개수가 임계 개수인 2개 미만인 것으로 식별됨에 따라, 프로세서는 안전 템플릿에 기초하여 식별된 충돌 회피 상 황에 맵핑된 알림 정보를 획득할 수 있다. 이 경우, 알림 정보는 운동 강도를 제어하도록 사용자에게 알림 정보 를 제공하기 위한 신호로서, 예를 들어 “전방에 장애물이 감지되었습니다. 운동 강도를 낮추세요”와 같은 알 림을 제공하기 위한 신호일 수 있다. 프로세서는 획득된 알림 정보를 통신 인터페이스를 통해 적어도 하나의 사용자 디바이스로 전송할 수 있다. 전자 장치는 센싱 데이터의 타입 별 개수가 임계 개수 이상인 경우에만 구동부를 직접 제어하고, 센싱 데 이터의 타입 별 개수가 임계 개수 미만인 경우에는 알림 정보를 전송함으로써, 센싱 정확도가 향상될 수 있으며 사용자의 만족도가 향상될 수 있다. 한편, 일 실시 예에 따라 프로세서는 특정 타입의 컨텍스트 정보에 대응되는 센싱 데이터의 개수에 기초하여 제어 신호의 타입을 식별할 수도 있다. 일 예에 따라, 프로세서는 적어도 하나의 사용자 디바이 스로부터 수신된 특정 타입의 컨텍스트 정보에 대응되는 센싱 데이터가가 임계 개수 미만이면, 안전 템플릿 에 기초하여 위험 상황에 맵핑된 알림 정보를 획득할 수 있다. 예를 들어, 카메라를 통해 획득된 센싱 정보(또는, 센싱 데이터) 및 마이크를 통해 획득된 센싱 정보 가 수신된 경우를 상정한다. 프로세서는 이에 대응되는 컨텍스트 정보인 충돌 회피 상황 정보에 대응되는 센싱 데이터의 개수가 임계 개수인 2개 이상인 것으로 식별됨에 따라, 안전 템플릿에 기초하여 충돌 회피 상황에 맵핑되는 운동 강도 정보를 획득할 수 있다. 이 경우, 프로세서는 운동 강도 정보에 기초하여 구동부(미도시)를 제어할 수 있다. 또는 전자 장치가 서버로 구현된 경우 프로세서는 운동 강도 정보에 대응되는 구동부(미도시) 제어 신호를 통신 인터페이스를 통해 로봇에 전송할 수 있다. 또는, 예를 들어, 마이크를 통해 획득된 센싱 정보만 수신된 경우를 상정한다. 프로세서는 이에 대응 되는 컨텍스트 정보인 충돌 회피 상황 정보에 대응되는 센싱 데이터의 개수가 임계 개수인 2개 미만인 것으로 식별됨에 따라, 안전 템플릿에 기초하여 충돌 회피 상황에 맵핑된 운동 강도 정보를 획득할 수 있다. 이 경우, 획득된 운동 강도 정보는 알림 정보 타입일 수 있다. 프로세서는 획득된 알림 정보를 통신 인터 페이스를 통해 적어도 하나의 사용자 디바이스로 전송할 수 있다. 도 7a 및 7b는 일 실시 예에 따른 학습된 인공 지능 모델을 이용하여 위험 상황을 식별하는 방법을 설명하기 위 한 도면이다. 본 개시의 일 실시 예에 따른 전자 장치는 적어도 하나의 신경망 레이어로 구성되는 복수의 인공 지능 모 델(또는 인공 신경망 모델 또는 학습 네트워크 모델)을 포함할 수 있다. 인공 신경망은 심층 신경망(DNN:Deep Neural Network)를 포함할 수 있으며, 예를 들어, CNN (Convolutional Neural Network), RNN (Recurrent Neural Network), RBM (Restricted Boltzmann Machine), DBN (Deep Belief Network), BRDNN(Bidirectional Recurrent Deep Neural Network) 또는 심층 Q-네트워크 (Deep Q-Networks) 등이 있으나, 전술한 예에 한정되지 않는다. 일 예에 따라, 메모리(미도시)는 복수의 신경망(또는, 인공 지능) 모델에 관한 정보를 저장할 수 있다. 여기서, 신경망 모델에 관한 정보를 저장한다는 것은 신경망 모델의 동작과 관련된 다양한 정보, 예를 들어 신경망 모델 에 포함된 적어도 하나의 레이어에 대한 정보, 적어도 하나의 레이어 각각에서 이용되는 파라미터, 바이어스 등 에 대한 정보 등을 저장한다는 것을 의미할 수 있다. 다만, 프로세서의 구현 형태에 따라 신경망 모델에 관한 정보가 프로세서의 내부 메모리에 저장될 수 있음은 물론이다. 예를 들어, 프로세서가 전용 하 드웨어로 구현되는 경우, 신경망 모델에 관한 정보는 프로세서 내부 메모리에 저장될 수도 있다. 도 7a 및 7b에 따르면, 일 실시 예에 따라 프로세서는 학습된 인공 지능 모델(또는, 신경망 모델)을 이용 하여 로봇의 주변 환경이 위험 상황에 해당하는지 여부를 식별할 수 있다. 일 예에 따라, 도 7a에 따르면, 프로세서는 위험 상황 정보가 식별되면, 적어도 하나의 센싱 데이터 및 위험 상황 정보를 학습된 인공 지능 모델에 입력하여 착용형 로봇의 주변 환경이 위험 상황 에 해당하는지 여부를 식별할 수 있다. 예를 들어, 프로세서는 카메라를 통해 획득된 센싱 데이터 가 수신됨에 따라 충돌 회피 상황 정보가 식별된 경우, 수신된 센싱 데이터와 위험 상황 정보 를 학습된 인공 지능 모델에 입력하여 위험 상황 식별 정보를 획득할 수 있다. 이 경우, 위험 상황 식별 정보는 로봇의 주변 환경이 충돌 회피 상황에 해당하는지 여부에 대한 판단 정보일 수 있다. 이 어서, 프로세서는 획득된 위험 상황 식별 정보 및 안전 템플릿에 기초하여 제어 정보를 획득하 고, 획득된 제어 정보에 기초하여 로봇 또는 사용자 디바이스 중 적어도 하나를 제어할 수 있게 된다. 일 예에 따라, 도 7b에 따르면, 전자 장치는 센싱 데이터의 타입 각각에 대응되는 복수의 신경망 모델을 포함할 수 있다. 프로세서는 일 예에 따라 제1 센싱 데이터가 수신되면, 제1 센싱 데이터에 대 응되는 신경망 모델을 식별하고, 식별된 신경망 모델에 제1 센싱 데이터를 입력하여 제1 센싱 데이터에 대응되는 제1 위험 상황 식별 정보를 획득할 수 있다. 또는, 프로세서는 일 예에 따라 제2 센싱 데이터가 수신되면, 제2 센싱 데이터에 대응되는 신경망 모델을 식별하고, 식별된 신경망 모델에 제2 센싱 데이터를 입력하여 제2 센싱 데이터에 대응되는 제2 위험 상황 식별 정보를 획 득할 수 있다. 한편, 일 실시 예에 따라 학습된 신경망 모델은 센싱 데이터, 위험 상황 정보 및 센싱 데이터에 대응되는 위험 상황 식별 정보(또는, 위험 상황 해당 여부에 대한 판단 정보)에 기초하여 학습될 수 있다. 또는, 일 실시 예에 따라 학습된 신경망 모델은 센싱 데이터 및 이에 대응되는 위험 상황 식별 정보에 기초하여 학습될 수 있다. 이 경우, 전자 장치는 센싱 데이터의 타입의 개수에 대응되는 개수의 적어도 하나의 신경망 모델을 포함할 수 있다. 도 8은 일 실시 예에 따른 전자 장치의 제어 방법을 설명하기 위한 도면이다. 일 실시 예에 따라, 로봇을 착용한 사용자가 흐린 주말 저녁에 고양이가 자주 출몰하는 공원에서 운동 하는 경우를 상정한다. 일 실시 예에 따라, 도 8에 따르면, 프로세서는 먼저 통신 인터페이스를 통해 사용자가 현재 사용중 인 스마트폰에 포함된 카메라를 통해 획득된 제1 센싱 데이터, 조도 센서를 통해 획득된 제2 센 싱 데이터, 스피커를 통해 획득된 제3 센싱 데이터를 수신할 수 있다. 또한, 프로세서는 통신 인터페 이스를 통해 사용자가 현재 사용중인 블루투스 이어폰에 포함된 마이크를 통해 획득된 제4 센싱 데이터를 수신할 수 있다. 일 실시 예에 따라, 프로세서는 수신된 복수의 센싱 데이터 각각에 대응되는 컨텍스트 정보를 식별할 수 있다. 이 경우, 프로세서는 제1 센싱 데이터에 대응되는 주변 사물 인식 정보, 제2 센싱 데이터에 대 응되는 시간대 인식 정보, 제4 센싱 데이터에 대응되는 주변 사물 인식 정보를 식별할 수 있다. 이어서, 일 실시 예에 따라 프로세서는 식별된 컨텍스트 정보의 타입에 대응되는 위험 상황 정보로서 충돌 회피 상황 정보, 사용 주의 상황 정보를 식별할 수 있다. 이어서, 일 실시 예에 따라 프로세서는 수신된 적어도 하나의 센싱 데이터 및 식별된 위험 상황 정보에 기 초하여 사용자가 위험 상황에 해당하는지 여부를 식별할 수 있다. 이 경우, 학습된 인공 지능 모델에 센싱 데이 터 및 위험 상황 정보를 입력하여 사용자가 위험 상황에 해당하는지 여부를 식별할 수 있다. 일 예에 따라, 프로세서는 조도가 임계 값 미만인 것으로 식별됨에 따라 주변 환경이 매우 어두운 상황이 지속되는 것으로 식별되면, 사용 주의 상황 정보에 대응되는 주변음 청취 정보 및 플래쉬 제어 정보를 획득할 수 있다. 일 예에 따라, 프로세서는 길고양이의 울음 소리에 대응되는 센싱 데이터 또는 길고양이의 실루 엣에 대응되는 센싱 데이터가 수신됨에 따라 로봇의 주변에 길고양이가 존재하는 것으로 식별되면, 충돌 회 피 상황에 맵핑된 소리 알림 정보 및 운동 강도 제어 정보를 획득할 수 있다. 이어서, 일 실시 예에 따라 프로세서는 획득된 제어 정보에 기초하여 로봇 또는 사용자 디바이스 를 제어할 수 있다. 일 예에 따라, 프로세서는 주변음 청취 기능을 ON하는 제어 신호를 통신 인터페이스 를 통해 블루투스 이어폰으로 전송할 수 있다. 일 예에 따라, 프로세서는 플래쉬를 ON하는 제어 신호를 통신 인터페이스를 통해 스마트폰으로 전송할 수 있다. 일 예에 따라, 전자 장치가 서버 로 구현된 경우, 프로세서는 운동 강도를 기 설정된 값 미만으로 감소시키는 제어 신호를 통신 인터페 이스를 통해 로봇으로 전송할 수 있다. 또는, 전자 장치가 로봇로 구현된 경우, 프로세서는 운동 강도가 기 설정된 값 미만으로 감소하도록 구동부(미도시)를 제어할 수 있다. 상술한 예에 따르면, 사용자는 착용형 로봇뿐만 아니라 사용자가 사용중인 적어도 하나의 사용자 디바이스에 기 초하여 안전하게 보행 또는 운동이 가능하다. 전자 장치는 사용자 디바이스로부터 획득된 센싱 데이터를 이용하 여 안전 기능을 수행할 수 있게 되며, 이에 따라 사용자의 안전성이 확보될 수 있게 된다. 도 9는 일 실시 예에 따른 전자 장치의 제어 방법을 설명하기 위한 도면이다. 일 실시 예에 따라, 늦은 밤 사용자가 로봇을 착용하고 스마트폰 및 스마트 워치를 사용하는 상태로 시내를 걷고 있는 경우를 상정한다. 도 9에 따르면, 일 실시 예에 따라 프로세서는 먼저 통신 인터페이스를 통해 사용자가 현재 사용중인 스마트폰에 포함된 카메라를 통해 획득된 제1 센싱 데이터, 조도 센서를 통해 획득된 제2 센싱 데이터, 스피커를 통해 획득된 제3 센싱 데이터 및 근접 센서를 통해 획득된 제4 센싱 데이터를 수신 할 수 있다. 또한, 프로세서는 통신 인터페이스를 통해 사용자가 현재 사용중인 스마트 워치에 포함된 심박 센서를 통해 획득된 제5 센싱 데이터 및 스피커를 통해 획득된 제6 센싱 데이터를 수신 할 수 있다. 일 실시 예에 따라, 프로세서는 수신된 복수의 센싱 데이터 각각에 대응되는 컨텍스트 정보를 식별할 수 있다. 이 경우, 프로세서는 제1 센싱 데이터에 대응되는 주변 사물 인식 정보, 제2 센싱 데이터에 대 응되는 시간대 인식 정보, 제5 센싱 데이터에 대응되는 과운동 인식 정보를 식별할 수 있다. 이어서, 일 실시 예에 따라 프로세서는 식별된 컨텍스트 정보의 타입에 대응되는 위험 상황 정보로서 충돌 회피 상황 정보, 사용 주의 상황 정보 및 사용 제한 상황 정보를 획득할 수 있다. 이어서, 일 실시 예에 따라 프로세서는 수신된 적어도 하나의 센싱 데이터 및 식별된 위험 상황 정보에 기 초하여 사용자가 위험 상황에 해당하는지 여부를 식별할 수 있다. 이 경우, 학습된 인공 지능 모델에 센싱 데이터 및 위험 상황 정보를 입력하여 사용자가 위험 상황에 해당하는지 여부를 식별할 수 있다. 일 예에 따라, 프로세서는 사용자 전방에 가로등이 존재하는 것으로 식별되는 경우, 사용자가 충돌 회피 상황에 해당하는 것으로 식별할 수 있다. 일 예에 따라, 프로세서는 사용자가 저항 모드로 보행 중에 횡단 보도를 건너고 있는 경우, 사용 제한 상황 또는 충돌 회피 상황에 해당하는 것으로 식별할 수 있다. 여기서, 저 항 모드란 보행에 저항을 줌으로써 운동용으로 사용하는 기능을 의미한다. 이어서, 일 실시 예에 따라 프로세서는 획득된 제어 정보에 기초하여 로봇 또는 사용자 디바이스 를 제어할 수 있다. 일 예에 따라, 프로세서는 전방에 장애물이 존재함을 알리는 제어 신호를 통신 인터페 이스를 통해 스마트폰 또는 스마트 워치로 전송할 수 있다. 또는, 일 예에 따라 프로세서는 “횡단보도 보행이 끝나기 전 신호가 바뀔 수 있으니 주의하세요”에 대응되는 알림 신호를 통신 인터페이스 를 통해 스마트 워치로 전송할 수 있다. 일 예에 따라, 전자 장치가 서버로 구현된 경우, 프 로세서는 운동 강도를 기 설정된 값 미만으로 감소시키는 제어 신호를 통신 인터페이스를 통해 로봇 으로 전송할 수 있다. 또는, 전자 장치가 로봇로 구현된 경우, 프로세서는 운동 강도가 기 설정된 값 미만으로 감소하도록 구동부(미도시)를 제어할 수 있다. 한편, 일 실시 예에 따라, 프로세서는 사용자 데이터에 기초하여 로봇 또는 적어도 하나의 사용자 디 바이스를 제어할 수 있다. 일 예에 따라, 메모리(미도시)에는 사용자의 운동 지속 시간, 사용자 설정 값, 과거 사용자 운동시의 보조/저항 토크 패턴 정보가 기 저장되어 있을 수 있으며, 프로세서는 상술한 정보 를 이용하여 제어 정보를 획득할 수 있다. 예를 들어, 사용자가 설정한 운동 강도에 대한 정보가 있는 경우, 프 로세서는 사용자가 설정한 운동 강도에 대한 정보에 기초하여 로봇을 제어할 수 있다. 또는, 일 실시 예에 따라 프로세서는 센싱 데이터 및 사용자 데이터에 기초하여 위험 상황을 식별할 수 있다. 한편, 일 실시 예에 따라 안전 템플릿 정보에 포함된 제어 정보는 사용자 설정에 기초하여 달라질 수 있다. 예를 들어, 사용자가 로봇을 착용하고 30분 이상 운동을 지속하지 않은 경우, 프로세서는 이를 고려하여 30분 미만의 운동 지속 시간을 갖도록 하는 제어 정보를 획득할 수도 있다. 이에 따라, 전자 장치는 로봇 및 적어도 하나의 사용자 디바이스로부터 획득된 센싱 데이터에 기초하여 안 전 기능을 수행할 수 있게 된다. 도 10은 일 실시 예에 따른 전자 장치의 세부 구성을 나타내는 블록도이다. 도 10에 따르면, 전자 장치(100')는 통신 인터페이스, 프로세서, 메모리, 사용자 인터페이스 , 마이크, 구동부, 센서, 스피커 및 디스플레이를 포함할 수 있다. 도 9에 도 시된 구성 중 도 2에 도시된 구성과 중복되는 구성에 대해서는 자세한 설명을 생략하도록 한다. 메모리는 다양한 실시 예를 위해 필요한 데이터를 저장할 수 있다. 메모리는 데이터 저장 용도에 따 라 전자 장치(100')에 임베디드된 메모리 형태로 구현되거나, 전자 장치(100')에 탈부착이 가능한 메모리 형태 로 구현될 수도 있다. 예를 들어, 전자 장치(100')의 구동을 위한 데이터의 경우 전자 장치(100')에 임베디드된 메모리에 저장되고, 전자 장치(100')의 확장 기능을 위한 데이터의 경우 전자 장치(100')에 탈부착이 가능한 메 모리에 저장될 수 있다. 한편, 전자 장치(100')에 임베디드된 메모리의 경우 휘발성 메모리(예: DRAM(dynamic RAM), SRAM(static RAM), 또는 SDRAM(synchronous dynamic RAM) 등), 비휘발성 메모리(non-volatile Memory) (예: OTPROM(one time programmable ROM), PROM(programmable ROM), EPROM(erasable and programmable ROM), EEPROM(electrically erasable and programmable ROM), mask ROM, flash ROM, 플래시 메모리(예: NAND flash 또는 NOR flash 등), 하드 드라이브, 또는 솔리드 스테이트 드라이브(solid state drive(SSD)) 중 적어도 하나 로 구현될 수 있다. 또한, 전자 장치(100')에 탈부착이 가능한 메모리의 경우 메모리 카드(예를 들어, CF(compact flash), SD(secure digital), Micro-SD(micro secure digital), Mini-SD(mini secure digital), xD(extreme digital), MMC(multi-media card) 등), USB 포트에 연결가능한 외부 메모리(예를 들어, USB 메모리) 등과 같은 형태로 구현될 수 있다. 일 예에 따라, 메모리는 복수의 신경망(또는, 인공 지능) 모델에 관한 정보를 저장할 수 있다. 여기서, 신 경망 모델에 관한 정보를 저장한다는 것은 신경망 모델의 동작과 관련된 다양한 정보, 예를 들어 신경망 모델에 포함된 적어도 하나의 레이어에 대한 정보, 적어도 하나의 레이어 각각에서 이용되는 파라미터, 바이어스 등에 대한 정보 등을 저장한다는 것을 의미할 수 있다. 다만, 프로세서의 구현 형태에 따라 신경망 모델에 관한 정보가 프로세서의 내부 메모리에 저장될 수 있음은 물론이다. 예를 들어, 프로세서가 전용 하드웨어 로 구현되는 경우, 신경망 모델에 관한 정보는 프로세서 내부 메모리에 저장될 수도 있다.사용자 인터페이스는 버튼, 터치 패드, 마우스 및 키보드와 같은 장치로 구현되거나, 상술한 디스플레이 기능 및 조작 입력 기능도 함께 수행 가능한 터치 스크린, 리모콘 송수신부 등으로 구현될 수 있다. 리모콘 송 수신부는 적외선 통신, 블루투스 통신 또는 와이파이 통신 중 적어도 하나의 통신 방식을 통해 외부 원격 제어 장치로부터 리모콘 신호를 수신하거나, 리모콘 신호를 송신할 수 있다. 마이크는 소리를 획득하여 전기 신호로 변환하는 모듈을 의미할 수 있으며, 콘덴서 마이크, 리본 마이크, 무빙코일 마이크, 압전소자 마이크, 카본 마이크, MEMS(Micro Electro Mechanical System) 마이크일 수 있다. 또한, 무지향성, 양지향성, 단일지향성, 서브 카디오이드(Sub Cardioid), 슈퍼 카디오이드(Super Cardioid), 하 이퍼 카디오이드(Hyper Cardioid)의 방식으로 구현될 수 있다. 구동부는 전자 장치(100')를 주행시킬 수 있는 장치이다. 구동부는 프로세서의 제어에 따라 주 행 방향 및 주행 속도를 조절할 수 있으며, 일 예에 따른 구동부는 전자 장치(100')가 주행하기 위한 동력 을 발생시키는 동력발생장치(예: 사용 연료(또는 에너지원)에 따라 가솔린 엔진(engine), 디젤 엔진, LPG(liquefied petroleum gas) 엔진, 전기 모터 등), 주행 방향을 조절하기 위한 조향 장치(예: 기계식 스티어 링(manual steering), 유압식 스티어링(hydraulics steering), 전자식 스티어링(electronic control power steering; EPS) 등), 동력에 따라 전자 장치(100')를 주행시키는 주행 장치(예: 바퀴, 프로펠러 등) 등을 포함 할 수 있다. 여기서, 구동부는 전자 장치(100')의 주행 타입(예: 휠 타입, 보행 타입, 비행 타입 등)에 따 라 변형 실시될 수 있다. 적어도 하나의 센서(160, 이하 센서)는 다양한 타입의 복수의 센서를 포함할 수 있다. 센서는 물리량을 계 측하거나 전자 장치(100')의 작동 상태를 감지하여, 계측 또는 감지된 정보를 전기 신호로 변환할 수 있다. 센 서는 카메라를 포함할 수 있으며, 카메라는 오브젝트에 의해 반사되어 수신되는 가시광 기타 광학 신호를 이미지 센서로 포커싱하는 렌즈 및 가시광 기타 광학 신호를 감지할 수 있는 이미지 센서를 포함할 수 있다. 여 기서, 이미지 센서는 복수의 픽셀로 구분되는 2D의 픽셀 어레이를 포함할 수 있으며, 일 예에 따른 카메라는 뎁 스 카메라로 구현될 수 있다. 또한, 센서는 라이더(LIDAR, Light Detection And Ranging) 센서 및 TOF(Time of flight) 센서와 같은 거리 센서를 포함할 수 있다. 그 밖에 적어도 하나의 센서는 제스처 센서, 자이로 센서, 기압 센서, 마그네틱 센서, 가속도 센서, 그립 센서, 근접 센서, 컬러(color) 센서(예: RGB(red, green, blue) 센서), 생체 센서, 온/습도 센서, 조도 센서 또는 UV(ultra violet) 센서 중의 적어도 하나를 포함할 수도 있다. 스피커는, 고음역대 소리 재생을 위한 트위터, 중음역대 소리 재생을 위한 미드레인지, 저음역대 소리 재 생을 위한 우퍼, 극저음역대 소리 재생을 위한 서브우퍼, 공진을 제어하기 위한 인클로저, 스피커에 입력되는 전기 신호 주파수를 대역 별로 나누는 크로스오버 네트워크 등으로 이루어질 수 있다. 스피커는, 음향 신호를 전자 장치(100')의 외부로 출력할 수 있다. 스피커는 멀티미디어 재생, 녹음 재생, 각종 알림음, 음성 메시지 등을 출력할 수 있다. 전자 장치(100')는 스피커와 같은 오디오 출력 장 치를 포함할 수 있으나, 오디오 출력 단자와 같은 출력 장치를 포함할 수 있다. 특히, 스피커는 획득한 정 보, 획득한 정보에 기초하여 가공·생산한 정보, 사용자 음성에 대한 응답 결과 또는 동작 결과 등을 음성 형태 로 제공할 수 있다. 디스플레이는 자발광 소자를 포함하는 디스플레이 또는, 비자발광 소자 및 백라이트를 포함하는 디스플레 이로 구현될 수 있다. 예를 들어, LCD(Liquid Crystal Display), OLED(Organic Light Emitting Diodes) 디스플 레이, LED(Light Emitting Diodes), 마이크로 LED(micro LED), Mini LED, PDP(Plasma Display Panel), QD(Quantum dot) 디스플레이, QLED(Quantum dot light-emitting diodes) 등과 같은 다양한 형태의 디스플레이 로 구현될 수 있다. 디스플레이 내에는 a-si TFT, LTPS(low temperature poly silicon) TFT, OTFT(organic TFT) 등과 같은 형태로 구현될 수 있는 구동 회로, 백라이트 유닛 등도 함께 포함될 수 있다. 한 편, 디스플레이는 터치 센서와 결합된 터치 스크린, 플렉시블 디스플레이(flexible display), 롤러블 디스 플레이(rollable display), 3차원 디스플레이(3D display), 복수의 디스플레이 모듈이 물리적으로 연결된 디스 플레이 등으로 구현될 수 있다. 프로세서는 상술한 다양한 실시 예에 따라 획득된 출력 영상을 출력하도록 디스플레이를 제어할 수 있다. 여기서, 출력 영상은, 4K 또는 8K 이상의 고해상도 영상일 수 있다. 상술한 다양한 실시 예에 따르면, 사용자 디바이스로부터 획득된 센싱 정보를 이용하여 착용형 로봇 주변 환경 을 감시(또는, 모니터링)하고, 이에 기초하여 안전 기능을 수행할 수 있다. 이에 따라, 사용자의 안전성이 확보 될 수 있다.한편, 상술한 본 개시의 다양한 실시 예들에 따른 방법들은, 기존 전자 장치에 설치 가능한 어플리케이션 형태 로 구현될 수 있다. 또는 상술한 본 개시의 다양한 실시 예들에 따른 방법들은 딥 러닝 기반의 학습된 신경망 (또는 심층 학습된 신경망) 즉, 학습 네트워크 모델을 이용하여 수행될 수 있다. 또한, 상술한 본 개시의 다양 한 실시 예들에 따른 방법들은, 기존 전자 장치에 대한 소프트웨어 업그레이드, 또는 하드웨어 업그레이드 만으 로도 구현될 수 있다. 또한, 상술한 본 개시의 다양한 실시 예들은 전자 장치에 구비된 임베디드 서버, 또는 전 자 장치의 외부 서버를 통해 수행되는 것도 가능하다. 한편, 본 개시의 일시 예에 따르면, 이상에서 설명된 다양한 실시 예들은 기기(machine)(예: 컴퓨터)로 읽을 수 있는 저장 매체(machine-readable storage media)에 저장된 명령어를 포함하는 소프트웨어로 구현될 수 있다. 기기는, 저장 매체로부터 저장된 명령어를 호출하고, 호출된 명령어에 따라 동작이 가능한 장치로서, 개시된 실 시 예들에 따른 디스플레이 장치(예: 디스플레이 장치(A))를 포함할 수 있다. 명령이 프로세서에 의해 실행될 경우, 프로세서가 직접, 또는 프로세서의 제어 하에 다른 구성요소들을 이용하여 명령에 해당하는 기능을 수행 할 수 있다. 명령은 컴파일러 또는 인터프리터에 의해 생성 또는 실행되는 코드를 포함할 수 있다. 기기로 읽을 수 있는 저장 매체는, 비일시적(non-transitory) 저장매체의 형태로 제공될 수 있다. 여기서, '비일시적'은 저 장매체가 신호(signal)를 포함하지 않으며 실재(tangible)한다는 것을 의미할 뿐 데이터가 저장매체에 반영구적 또는 임시적으로 저장됨을 구분하지 않는다. 또한, 일 실시 예에 따르면, 이상에서 설명된 다양한 실시 예들에 따른 방법은 컴퓨터 프로그램 제품(computer program product)에 포함되어 제공될 수 있다. 컴퓨터 프로그램 제품은 상품으로서 판매자 및 구매자 간에 거래 될 수 있다. 컴퓨터 프로그램 제품은 기기로 읽을 수 있는 저장 매체(예: compact disc read only memory (CD- ROM))의 형태로, 또는 어플리케이션 스토어(예: 플레이 스토어TM)를 통해 온라인으로 배포될 수 있다. 온라인 배포의 경우에, 컴퓨터 프로그램 제품의 적어도 일부는 제조사의 서버, 어플리케이션 스토어의 서버, 또는 중계 서버의 메모리와 같은 저장 매체에 적어도 일시 저장되거나, 임시적으로 생성될 수 있다. 또한, 상술한 다양한 실시 예들에 따른 구성 요소(예: 모듈 또는 프로그램) 각각은 단수 또는 복수의 개체로 구 성될 수 있으며, 전술한 해당 서브 구성 요소들 중 일부 서브 구성 요소가 생략되거나, 또는 다른 서브 구성 요 소가 다양한 실시 예에 더 포함될 수 있다. 대체적으로 또는 추가적으로, 일부 구성 요소들(예: 모듈 또는 프로 그램)은 하나의 개체로 통합되어, 통합되기 이전의 각각의 해당 구성 요소에 의해 수행되는 기능을 동일 또는 유사하게 수행할 수 있다. 다양한 실시 예들에 따른, 모듈, 프로그램 또는 다른 구성 요소에 의해 수행되는 동 작들은 순차적, 병렬적, 반복적 또는 휴리스틱하게 실행되거나, 적어도 일부 동작이 다른 순서로 실행되거나, 생략되거나, 또는 다른 동작이 추가될 수 있다. 이상에서는 본 개시의 바람직한 실시 예에 대하여 도시하고 설명하였지만, 본 개시는 상술한 특정의 실시 예에"}
{"patent_id": "10-2022-0102810", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "한정되지 아니하며, 청구범위에서 청구하는 본 개시의 요지를 벗어남이 없이 당해 개시에 속하는 기술분야에서 통상의 지식을 가진 자에 의해 다양한 변형실시가 가능한 것은 물론이고, 이러한 변형실시들은 본 개시의 기술 적 사상이나 전망으로부터 개별적으로 이해되어서는 안될 것이다."}
{"patent_id": "10-2022-0102810", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1a 및 1b는 일 실시 예에 따른 전자 장치의 제어 방법을 개략적으로 설명하기 위한 도면이다. 도 2는 일 실시 예에 따른 전자 장치의 구성을 나타내는 블록도이다. 도 3은 일 실시 예에 따른 전자 장치의 제어 방법을 설명하기 위한 흐름도이다. 도 4a 내지 4b는 일 실시 예에 따른 센싱 데이터 및 안전 템플릿 정보를 설명하기 위한 도면이다. 도 5는 일 실시 예에 따른 복수의 센싱 데이터가 수신된 경우의 전자 장치의 제어 방법을 설명하기 위한 도면이 다. 도 6은 일 실시 예에 따른 상이한 타입의 제어 신호를 전송하는 방법을 설명하기 위한 도면이다. 도 7a 및 7b는 일 실시 예에 따른 학습된 인공 지능 모델을 이용하여 위험 상황을 식별하는 방법을 설명하기 위 한 도면이다. 도 8은 일 실시 예에 따른 전자 장치의 제어 방법을 설명하기 위한 도면이다. 도 9는 일 실시 예에 따른 전자 장치의 제어 방법을 설명하기 위한 도면이다. 도 10은 일 실시 예에 따른 전자 장치의 세부 구성을 나타내는 블록도이다."}
