{"patent_id": "10-2023-0138648", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2025-0055645", "출원번호": "10-2023-0138648", "발명의 명칭": "영상 기반 행동 인식 장치 및 방법", "출원인": "한국전자통신연구원", "발명자": "배강민"}}
{"patent_id": "10-2023-0138648", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "행동 인식 장치에 있어서,복수의 기준 행동 데이터를 저장하는 메모리; 입력 영상으로부터 행동 시작 시점을 검출하는 동기화 모듈;상기 행동 시작 시점부터 상기 입력 영상으로부터 신체 영역을 추출하고, 상기 신체 영역에 포함된 관절 정보를인식하는 인식 모듈; 및상기 신체 영역 및 상기 관절 정보를 포함하는 사용자 데이터와 상기 복수의 기준 행동 데이터 간의 유사도를산출하는 유사도 비교 모듈을 포함하는 행동 인식 장치."}
{"patent_id": "10-2023-0138648", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "청구항 1에 있어서, 상기 동기화 모듈은,상기 입력 영상과 관련된 멀티 모달 정보에 기반하여 상기 행동 시작 시점을 검출하는 것인 행동 인식 장치."}
{"patent_id": "10-2023-0138648", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "청구항 2에 있어서, 상기 멀티 모달 정보는,지정된 음성 입력, 지정된 음악 시작, 지정된 버튼 조작, 지정된 제스처 입력, 지정된 화면 출력 또는 지정된음악 재생 중 적어도 하나의 멀티 모달 정보를 포함하는 것인 행동 인식 장치."}
{"patent_id": "10-2023-0138648", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "청구항 1에 있어서, 상기 유사도 비교 모듈은,상기 유사도의 산출에 따라 상기 입력 영상에 대응하는 기준 행동을 결정하는 것인 행동 인식 장치."}
{"patent_id": "10-2023-0138648", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "청구항 1에 있어서, 상기 각 기준 행동 데이터는,각 기준 행동에 각기 관련된 기준 신체 영역 영상 및 각 기준 신체 영역 영상과 관련된 복수의 기준 관절 정보를 포함하는 것인 행동 인식 장치."}
{"patent_id": "10-2023-0138648", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "청구항 5에 있어서, 상기 유사도 비교 모듈은, 상기 신체 영역을 적어도 상기 기준 신체 영역의 크기에 대응하도록 정규화하고 상기 정규화된 신체 영역과 상기 기준 신체 영역 영상 간의 유사도를 산출하는 것인 행동 인식 장치."}
{"patent_id": "10-2023-0138648", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "청구항 1에 있어서, 상기 유사도 비교 모듈은,IoU(intersection of union), 코사인 유사도 및 이미지 분류에 관련된 심층 신경망 중 복수의 기법들에 기반하여 상기 사용자 데이터와 상기 기준 행동 데이터 간의 유사도를 종합적으로 산출하는 것인 행동 인식 장치."}
{"patent_id": "10-2023-0138648", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "공개특허 10-2025-0055645-3-청구항 1에 있어서, 상기 유사도 비교 모듈은,상기 입력 영상에서 상기 신체 영역을 추출함에 따라 입력 신체 영역 영상을 획득하고, 상기 복수의 기준 행동데이터에 따른 복수의 신체 영역 영상들과 상기 획득된 신체 영역 영상 간의 유사도를 산출하는 것인 행동 인식장치."}
{"patent_id": "10-2023-0138648", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "청구항 1에 있어서, 상기 관절 정보는, 각 관절들의 위치 좌표를 포함하고,상기 유사도 비교 모듈은, 상기 각 관절들의 위치 좌표에 기반하여 상기 각 관절들의 자세 벡터들을 산출하고,상기 산출된 자세 벡터들과 상기 기준 행동 데이터에 따른 자세 벡터들 간의 유사도를 산출하는 것인 행동 인식장치."}
{"patent_id": "10-2023-0138648", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "청구항 9에 있어서, 상기 자세 벡터들에 기반하여 사용자의 행동을 상기 기준 행동에 맞추도록 하는 자세 교정 정보를 생성하는 안내 모듈을 더 포함하는 행동 인식 장치."}
{"patent_id": "10-2023-0138648", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "청구항 1에 있어서, 상기 유사도 비교 모듈은,상기 복수의 기준 행동 데이터와 상기 신체 영역 간의 유사도가 기정된 기준치 이하이면, 상기 동기화 모듈로하여금 상기 행동 시작 시점의 검출을 중단하도록 하는 것인 행동 인식 장치."}
{"patent_id": "10-2023-0138648", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "행동 인식 장치에 있어서,사용자를 촬영하는 카메라; 적어도 하나의 명령어를 저장하는 메모리; 및프로세서를 포함하고, 상기 프로세서는, 상기 적어도 하나의 명령어를 실행함에 따라,상기 카메라를 통해 촬영된 영상으로부터 행동 시작 시점을 검출하고, 상기 행동 시작 시점부터 상기 촬영된 영상으로부터 추출된 신체 영역에 포함된 관절 정보를 인식하고, 상기 신체 영역 및 상기 관절 정보를 포함하는 사용자 데이터와 복수의 기준 행동 데이터 간의 유사도를 산출함에 따라 상기 촬영된 영상과 비교할 기준 행동을 결정하는 것인 행동 인식 장치."}
{"patent_id": "10-2023-0138648", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "청구항 12에 있어서, 통신 모듈을 더 포함하고, 상기 프로세서는,통신 모듈을 통해 외부 전자 장치와 통신하여 상기 행동 시작 시점의 검출, 상기 관절 정보의 인식 및 상기 기준 행동의 결정을 수행하는 것인 행동 인식 장치."}
{"patent_id": "10-2023-0138648", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "청구항 12에 있어서, 디스플레이를 더 포함하고, 상기 프로세서는,상기 기준 행동과 상기 촬영된 영상 간의 자세 벡터를 포함하는 유사도를 산출하고,상기 산출된 유사도에 기반하여 사용자의 행동을 상기 결정된 기준 행동에 맞추는 안내 데이터를 상기 디스플레공개특허 10-2025-0055645-4-이를 통해 출력하는 것인 행동 인식 장치."}
{"patent_id": "10-2023-0138648", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "청구항 12에 있어서, 상기 프로세서는,지정된 음성 입력, 지정된 음악 시작, 지정된 버튼 조작, 지정된 제스처 입력, 지정된 화면 출력 또는 지정된음악 재생 중 적어도 하나의 멀티 모달 정보를 확인하면, 상기 행동 시작 시점인 것으로 결정하는 것인 행동 인식 장치."}
{"patent_id": "10-2023-0138648", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "청구항 12에 있어서, 상기 프로세서는,IoU(intersection of union), 코사인 유사도 및 이미지 관련된 심층 경망 중 복수의 기법들에 기반하여 상기 사용자 데이터와 상기 기준 행동 데이터 간의 유사도를 산출하는 것인 행동 인식 장치."}
{"patent_id": "10-2023-0138648", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "청구항 12에 있어서, 상기 프로세서는,상기 복수의 기준 행동 데이터와 상기 신체 영역과 간의 유사도가 기정된 기준치 이하이면, 상기 행동 시작 시점의 검출 중단하는 것인 행동 인식 장치."}
{"patent_id": "10-2023-0138648", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "적어도 하나의 프로세서에 의한 행동 인식 방법에 있어서,입력 영상으로부터 행동 시작 시점을 검출하는 동작;상기 행동 시작 시점부터 상기 입력 영상으로부터 신체 영역을 추출하고, 상기 신체 영역으로부터 관절 정보를인식하는 동작; 및상기 신체 영역 및 상기 관절 정보를 포함하는 사용자 데이터와 상기 복수의 기준 행동 데이터 간의 유사도에기반하여 상기 입력 영상과 비교할 기준 행동을 결정하는 동작을 포함하는 행동 인식 방법."}
{"patent_id": "10-2023-0138648", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "청구항 18에 있어서, 상기 검출하는 동작은,상기 입력 영상과 관련된 소리 발생, 음악 재생, 버튼 조작 또는 화면 출력에 기반하여 상기 행동 시작 시점을검출하는 동작을 포함하는 것인 행동 인식 방법."}
{"patent_id": "10-2023-0138648", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "청구항 18에 있어서, 상기 결정하는 동작은,IoU(intersection of union), 코사인 유사도 및 이미지 관련된 심층 신경망 중 복수의 기법들에 기반하여 상기사용자 데이터와 상기 기준 행동 데이터 간의 유사도를 산출하는 동작을 포함하는 행동 인식 방법."}
{"patent_id": "10-2023-0138648", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 문서에 개시되는 일 실시 예에 따른 행동 인식 장치는, 복수의 기준 행동 데이터를 저장하는 메모리; 입력 영 상으로부터 행동 시작 시점을 검출하는 동기화 모듈; 상기 행동 시작 시점부터 상기 입력 영상으로부터 신체 영 역을 추출하고, 상기 신체 영역에 포함된 관절 정보를 인식하는 인식 모듈; 및 상기 신체 영역 및 상기 관절 정 보를 포함하는 사용자 데이터와 상기 복수의 기준 행동 데이터 간의 유사도를 산출하는 유사도 비교 모듈을 포함 할 수 있다."}
{"patent_id": "10-2023-0138648", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 문서에서 개시되는 다양한 실시 예들은, 행동 인식 기술과 관련된다."}
{"patent_id": "10-2023-0138648", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "요즘, 사람에 대한 촬영 영상에 기반하여 사람의 상태(행동 정보)을 인식하는 기술이 널리 연구되고 있다. 예를 들어, 영상 감시(visual surveillance), 사람-컴퓨터 상호작용(human-computer interaction) 및 지능로봇 (intelligent robot)과 같은 다양한 적용 분야에서 사람의 상태 인식이 연구되고 있다.그 중 하나로, 사람의 상태 정보 또는 관절 정보를 인식하는 연구가 있다. 예를 들면, 센서 또는 카메라를 이용 하여 사람의 이동 궤적을 분석하여 사용자의 행동 및 제스처를 인식하는 기술이 구현되고 있다."}
{"patent_id": "10-2023-0138648", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "종래의 사람 상태 인식 방법은 개별 사람의 행동을 보다 정확하게 인식하기 위하여 행동 인식을 위한 학습 과정 에 많은 데이터 셋을 필요로 하는 딥러닝 기반의 무거운 모델들(예: LSTM, 3D CNN 등)을 활용한다. 이 같이, 다 량의 학습 데이터셋 수집을 필요로 하기 때문에, 새로운 행동을 추가하는 경우에도 많은 작업량을 수반하였다. 본 문서에 개시되는 다양한 실시 예들은 사람 영상 간의 유사도 비교를 통해 사용자 행동을 인식할 수 있는 영 상 기반 행동 인식 장치 및 방법을 제공할 수 있다."}
{"patent_id": "10-2023-0138648", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 문서에 개시되는 일 실시 예에 따른 행동 인식 장치는, 복수의 기준 행동 데이터를 저장하는 메모리; 입력 영상으로부터 행동 시작 시점을 검출하는 동기화 모듈; 상기 행동 시작 시점부터 상기 입력 영상으로부터 신체 영역을 추출하고, 상기 신체 영역에 포함된 관절 정보를 인식하는 인식 모듈; 및 상기 신체 영역 및 상기 관절 정보를 포함하는 사용자 데이터와 상기 복수의 기준 행동 데이터 간의 유사도를 산출하는 유사도 비교 모듈을 포함할 수 있다. 또한, 본 문서에 개시되는 일 실시 예에 따른 행동 인식 장치는, 사용자를 촬영하는 카메라; 적어도 하나의 명 령어를 저장하는 메모리; 및 프로세서를 포함하고, 상기 프로세서는, 상기 적어도 하나의 명령어를 실행함에 따 라 상기 카메라를 통해 촬영된 영상으로부터 행동 시작 시점을 검출하고, 상기 행동 시작 시점부터 상기 촬영된 영상으로부터 추출된 신체 영역에 포함된 관절 정보를 인식하고, 상기 신체 영역 및 상기 관절 정보를 포함하는 사용자 데이터와 복수의 기준 행동 데이터 간의 유사도를 산출함에 따라 상기 촬영된 영상과 비교할 기준 행동 을 결정할 수 있다. 또한, 본 문서에 개시되는 일 실시 예에 따른 행동 인식 방법은, 입력 영상으로부터 행동 시작 시점을 검출하는 동작; 상기 행동 시작 시점부터 상기 입력 영상으로부터 신체 영역을 추출하고, 상기 신체 영역으로부터 관절 정보를 인식하는 동작; 및 상기 신체 영역 및 상기 관절 정보를 포함하는 사용자 데이터와 상기 복수의 기준 행 동 데이터 간의 유사도에 기반하여 상기 입력 영상과 비교할 기준 행동을 결정하는 동작을 포함할 수 있다."}
{"patent_id": "10-2023-0138648", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 문서에 개시되는 다양한 실시 예들에 따르면, 사람 영상들 간의 유사도 비교를 통해 사용자의 행동을 인식할 수 있다. 이 외에, 본 문서를 통해 직접적 또는 간접적으로 파악되는 다양한 효과들이 제공될 수 있다."}
{"patent_id": "10-2023-0138648", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "item": 1, "content": "도 1은 일 실시예에 따른 행동 인식 장치의 구성도를 나타내고, 도 2는 일 실시예에 따른 행동 자세 벡터를 설 명하기 위한 도면이다.도 1을 참조하면, 일 실시예에 따른 행동 인식 장치는 메모리, 동기화 모듈, 인식 모듈, 유사도 비교 모듈 및 안내 모듈을 포함할 수 있다. 일 실시예에서, 동기화 모듈, 인식 모듈 , 유사도 비교 모듈 및 안내 모듈은 적어도 하나의 프로세서에 포함된 소프트웨어 모듈일 수 있 다. 일 실시 예에서, 행동 인식 장치는 일부 구성요소가 생략되거나, 추가적인 구성요소를 더 포함할 수 있다. 또한, 행동 인식 장치의 구성요소들 중 일부가 결합되어 하나의 개체로 구성되되, 결합 이전의 해당 구성요소들의 기능을 동일하게 수행할 수 있다. 일 실시예에 따르면, 메모리는 복수의 기준 행동들에 각기 관련된 복수의 기준 행동 데이터를 저장할 수 있다. 상기 복수의 기준 행동 데이터는 각 기준 신체 영역 영상(예: 기준 행동을 취하는 사람의 신체 영역 영상) 및 기준 신체 영역 영상에 따른 관절 정보(예: 기준 행동을 취하는 사람의 관절 위치 좌표값)를 포함할 수 있다. 상기 기준 행동은 예를 들면, 운동 동작, 안무 동작 또는 춤 동작 중 적어도 하나의 움직임에 따른 동 작을 포함할 수 있다. 상기 운동 동작은 예를 들면, 요가, 필라테스, 헬스나 체조와 같은 다양한 운동의 동작일 수 있다. 상기 안무 동작은 특정 음악에 맞추어진 안무 동작들을 포함할 수 있다. 상기 춤 동작은 음악과 관련 되지 않은 춤 동작일 수 있다. 일 실시예에 따르면, 동기화 모듈은 입력 영상과 관련된 멀티 모달 정보에 기반하여 사용자의 행동 시작 시점을 인식할 수 있다. 상기 입력 영상은 예를 들면, 사용자의 신체를 촬영한 영상일 수 있다. 상기 멀티 모달 정보는 예를 들면, 지정된 음성 입력, 지정된 음악 시작, 지정된 버튼 조작, 지정된 제스처 입력, 지정된 가이 드 영상 출력 또는 지정된 음악 재생 중 적어도 하나의 멀티 모달 정보를 포함할 수 있다. 예를 들어, 동기화 모듈은 입력 영상으로부터 프레임의 변화 정보를 확인하고 입력 영상과 녹화된 소리의 변화를 확인할 수 있다. 동기화 모듈은 안무 동작과 같이 음악과 관련된 동작의 경우, 입력된 사용자 영상에 포함된 소리 변화로부 터 음악의 재생 시점을 확인하고, 확인된 재생 시점에 기반하여 행동 시작 시점을 검출할 수 있다. 동기화 모듈은 운동 동작의 경우, 사용자 영상의 프레임 변화, 사용자 영상과 관련된 소리의 변화 또는 다 른 입력 정보에 기반하여 행동 시작 시점을 검출할 수 있다. 예를 들어, 동기화 모듈은 입력 영상(사용자 영상)의 프레임 변화로부터 사용자의 지정된 움직임(예:: 제스처)을 인식하고, 인식된 움직임에 대응하는 시점 을 행동 시작 시점으로 검출할 수 있다. 다른 예를 들어, 동기화 모듈은 동영상과 함께 녹화된 소리로부터 지정된 소리(예: 시작)를 검출하고, 검출된 소리에 대응하는 시점을 행동 시작 시점으로 검출할 수 있다. 또 다 른 예로, 동기화 모듈은 입력 모듈(예: 버튼)을 지정된 사용자 입력(예: 특정 키 조작)을 검출하고, 사용 자 입력의 시점을 행동 시작 시점으로 결정할 수 있다. 또는, 동기화 모듈은 입력 영상과 관련되어 디스플 레이에 표시되는 가이드 영상의 표시 시점을 행동 시작 시점으로 결정할 수 있다. 일 실시예에 따르면, 인식 모듈은 검출된 행동 시작 시점부터 입력 영상에서 사용자의 행동을 인식함에 따 라 신체 영역 및 관절 정보를 포함하는 사용자 데이터를 생성할 수 있다. 예를 들어, 인식 모듈은 행동 시 작 시점부터 입력 영상에서 사용자의 신체 영역을 추출하고, 추출된 신체 영역에서 관절 위치 좌표값에 관련된 관절 정보를 인식할 수 있다. 상기 신체 영역은 예를 들면, 입력 영상의 각 프레임에서 사람 신체로 인식된 영 역 영상으로, 도 1의 패턴 표시된 영역일 수 있다. 상기 관절 정보는 각 관절의 위치 좌표로서, 예를 들면, 도 1의 예측 결과에 포함된 직선들에 관련된 정보(예: 좌표 정보)일 수 있다. 한 실시예에 따르면, 인식 모듈은 신체 영역 및 관절 정보를 인식하도록 마련된 제1 인공지능 모델일 수 있다. 인식 모듈은 제1 인공지능 모델을 이용하여 입력 영상 각 프레임에 따른 특징점에 기반하여 사용자 의 신체 영역을 추출할 수 있다. 인식 모듈은 제1 인공지능 모델을 이용하여 추출된 신체 영역으로부터 지 정된 관절 위치 좌표를 추출할 수 있다. 상기 인식 모듈에 의해 인식되는 관절은 예를 들면, 얼굴, 목, 어 깨, 팔꿈치, 손목, 골반, 무릎, 발목 중 적어도 하나의 유형에 속하는 관절을 포함할 수 있다. 상기 나열된 관 절들은 인체에서 용이하게 식별될 수 있는 위치에 존재하면서 사람의 행동에서 뚜렷한 움직임을 보이는 관절일 수 있다. 일 실시예에 따르면, 유사도 비교 모듈은 입력 영상으로부터 검출된 신체 영역을 정규화(normalize)하여 지정된 크기(기준 행동 데이터에 대응하는 크기)로 변환할 수 있다. 입력 영상의 신체 영역 영상은 사용자의 키, 몸무게 또는 촬영 위치에 따라서 그 크기가 상이할 수 있다. 유사도 비교 모듈은 정규화를 통해 입력 신체 영역을 기준 규격(예: 기준 사이즈)으로 변환함에 따라 사용자들의 신체 사이즈 편차로 인한 유사도 검출 의 오류를 방지할 수 있다. 여기서, 유사도 비교 모듈은 관절 정보에 대해서도 정규화할 수 있다. 일 실시예에 따르면, 유사도 비교 모듈은 IoU(intersection of union), 코사인 유사도 및 영상 분류에 관 련된 심층 신경망 중 복수의 기법들에 기반하여 사용자 데이터와 상기 기준 행동 데이터 간의 유사도를 산출할 수 있다. 일 실시예에 따르면, 유사도 비교 모듈은 IoU(intersection of union)를 활용하여 변환된 사용자 신체 영 역과 기준 행동 영역 영상들 간의 유사도를 산출할 수 있다. 상기 IoU 값은 예를 들면, 2개의 영역들이 얼마나 겹쳐 있는지를 나타내는 지표로서, 변환된 신체 영역(입력 영상)과 기준 행동 간의 IoU 값이 클수록 입력과 기 준 행동 간의 유사도는 높을 수 있다. 하기 수학식 1과 같이, 유사도 비교 모듈은 예측된 신체 영역의 binary mask 와 메모리의 기준 신 체 영상의 ground truth binary mask 간의 IoU를 계산하여 두 행동들(간의 제1 유사도 를 산출할 수 있다. 상기 두 행동들은 입력 신체 영역에 따른 사용자 행동과 기준 신체 영역에 따른 기준 행동일 수 있다. 수학식 1"}
{"patent_id": "10-2023-0138648", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "일 실시예에 따르면, 유사도 비교 모듈은 입력된 사용자 관절 정보와 기준 행동들에 따른 기준 관절 정보 간의 제2 유사도(예: 코사인 유사도)를 산출할 수 있다. 도 2를 참조하면, 유사도 비교 모듈은 관절 정보에 따른 관절의 위치 좌표값에 기반하여 사용자의 자세 벡 터를 결정할 수 있다. 예를 들어, 유사도 비교 모듈은 도 2와 같이, 사용자의 관절 위치 좌표값들을 연결 함에 따라 자세 벡터( )와 기준 행동(gt 자세)의 자세 벡터 ( )를 각각 산출할 수 있다. 유사도 비교 모듈은 자세 벡터들의 코사인 유사도(cosine similarity)를 활용하여 각 관절 요소들의 정확 도를 산출할 수 있다. 예를 들어, 유사도 비교 모듈은 관절별로 사용자 행동과 기준 행동((또는 입력된 자 세 벡터와 기준 행동의 자세 벡터) 간의 코사인 유사도( )를 하기 수학식2와 같이 산출할 수 있다. 수학식 2"}
{"patent_id": "10-2023-0138648", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "유사도 비교 모듈은 사용자의 전체 신체 영역에서 각 관절 자세의 정확도( ) 즉, 각 관절의 코사인 유 사도를 종합한 제2 유사도를 하기 수학식 3과 같이 산출할 수 있다. 수학식 3"}
{"patent_id": "10-2023-0138648", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "일 실시예에 따르면, 유사도 비교 모듈은 심층 신경망(DNN; deep neural network)을 이용하여 사용자 신체 영역 영역과 신체 영역 영상 간의 제3 유사도(Limg)를 산출할 수 있다. 예를 들어, 유사도 비교 모듈은 입 력된 신체 영역 영상(input)과 메모리에 저장된 기준 신체 영역 영상(gt)을 심층 신경망(DNN)을 통해 특징 공간으로 투영할 수 있다. 상기 심층 신경망은 예를 들면, 이미지를 분류하는 심층 신경망 모델로서, 일 실시예 에 따른 행동 인식을 위한 별도의 학습 과정 없이 적용될 수 있다. 이에, 일 실시예에 따르면, 심층 신경망 모델의 학습을 위한 컴퓨팅 자원 사용을 줄일 수 있다. 수학식 4"}
{"patent_id": "10-2023-0138648", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "일 실시예에 따르면, 유사도 비교 모듈은 상술된 3가지 방식으로 입력 영상에 따른 사용자 데이터와 복수 의 기준 행동 데이터 간을 비교한 결과인 제1 유사도(LIOU), 제2 유사도(Lpose) 및 제3 유사도(Limg)를 종합하여 입력 영상과 각 기준 행동들 간의 최종 유사도(Lt)를 결정할 수 있다. 수학식 5에서, λ1, λ2, λ3은 각기 제1 내지 3 유사도의 가중치로서 실험적으로 결정될 수 있다. 수학식 5"}
{"patent_id": "10-2023-0138648", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "일 실시예에 따르면, 유사도 비교 모듈은 복수의 기준 행동 데이터 중 사용자 데이터와 최종 유사도가 가 장 높은 기준 행동 데이터(C)를 결정(또는, 반환)할 수 있다. 수학식 6"}
{"patent_id": "10-2023-0138648", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 7, "content": "일 실시예에 따르면, 유사도 비교 모듈은 결정된 기준 행동 데이터와 사용자 데이터를 비교하고 비교 결과 를 출력할 수 있다. 일 실시예에 따르면, 안내 모듈은 유사도 비교 모듈의 출력값에 기반하여 입력 행동을 결정된 기준 행동에 맞추도록 하는 자세 교정 정보를 생성할 수 있다. 예를 들어, 안내 모듈은 수학식 2와 같이 사용자 데이터와 결정된 기준 행동 데이터 간의 자세 벡터를 비교함에 따라 사용자 행동이 결정된 기준 행동과 더 유사 해지도록 하는 자세 교정 정보를 생성할 수 있다. 다른 예를 들어, 사용자의 팔 자세가 기준 행동의 팔 자세보 다 낮게 들린 경우, 안내 모듈은 사용자의 팔을 더 올리도록 하는 메시지 '팔을 올리세요'또는 '팔을 올리 는 방향'의 화살표를 포함하는 자세 교정 정보를 생성할 수 있다. 안내 모듈은 생성된 자세 교정 정보를 사용자에게 제공(예: 디스플레이 또는 소리로 출력)할 수 있다. 한편, 일 실시예에 따르면, 유사도 비교 모듈은 복수의 기준 행동 데이터 중 사용자 데이터와 유사도가 지 정된 값 이상인 데이터가 없거나, 결정된 기준 행동 데이터와 사용자 데이터 간의 유사도가 지정된 값 미만이면, 더 이상의 유사도 비교를 중단할 수 있다. 이 경우, 유사도 비교 모듈은 동기화 모듈로 하 여금 행동 시작 시점의 검출을 중단하도록 하는 안내를 전달할 수 있다. 그러면, 동기화 모듈은 유사도 비 교 모듈의 안내에 따라 행동 시작 시점의 검출을 중단할 수 있다. 만약, 기준 행동과 입력 행동 간의 동기화하지 않고 행동을 인식하는 경우에는 행동 인식 장치가 행동을 아예 인식하지 못하거나 사용자의 행동 인식을 제대로 수행하지 못할 수 있다. 하지만, 일 실시예에 따른 행동 인식 장치는 동기화 모듈을 통해 등장 인물이 행동을 시작하는 시점을 명확히 파악할 수 있어, 영상 기반의 사용자 행동의 인식률을 높이고 사용자의 의도와 일치하는 행동을 인식할 수 있다. 또한, 일 실시예에 따른 행동 인식 장치는 사용자의 신체 영상을 정규화하여 기준 행동 데이터와 비교함에 따라 적은 량의 학습 데이터셋(예: 한두 명의 행동 영상)를 사람의 행동을 학습할 수 있고, 새로운 행동에 대한 학습 및 인식의 확장에 유리할 수 있어, 다양한 행동 인식에 응용될 수 있다. 뿐만 아니라, 일 실시예에 따른 행동 인식 장치는 음원 재생, 사용자 음성, 버튼 입력 또는 가이드 영상 출력과 같은 멀티 모달 정보에 기반하여 행동 시작 시점을 정확히 판단함에 따라 행동 인식의 정확도는 높이고 행동 인식을 위한 불필요한 데이터 송수신을 방지함에 따라 에너지 소비를 줄일 수 있다. 더 나아가, 일 실시예에 따른 행동 인식 장치는 사용자의 행동과 가장 유사한 기준 행동을 반환하고 사용 자 행동이 기준 행동과 유사해지도록 자세 교정 정보를 제공함에 따라 사용자의 트레이닝이나 춤 연습을 지원할 수 있다. 도 3은 제1 실시예에 따른 행동 인식 장치의 구성도를 나타낸다. 도 3을 참조하면, 제1 실시예에 따른 행동 인식 장치(100')는 하나의 장치로 구성될 수 있고, 센서 모듈, 출력 모듈, 메모리 및 프로세서를 포함할 수 있다. 일 실시 예에서, 행동 인식 장치(100')는 일 부 구성요소가 생략되거나, 추가적인 구성요소를 더 포함할 수 있다. 또한, 행동 인식 장치(100')의 구성요소들 중 일부가 결합되어 하나의 개체로 구성되되, 결합 이전의 해당 구성요소들의 기능을 동일하게 수행할 수 있다. 예를 들어, 기준 행동 데이터를 저장하는 메모리는 외부 전자 장치에 마련될 수 있다. 도 3에서는 설명의 편의성과 이해를 돕기 위하여 도 1 및 2와 중복되는 설명은 대부분 생략하고, 새로운 구성을 중심으로 설명한다. 하지만, 이에 한정되지 않는다. 일 실시예에 따르면, 센서 모듈은 사용자를 촬영하는 카메라 모듈 및 소리를 감지하는 마이크를 포함할 수 있다. 카메라 모듈은 프로세서의 제어에 따라 행동하는 사용자의 신체를 촬영할 수 있다. 마이크는 입력된 소리를 전기적인 신호에 변환함에 따라 음성 신호를 생성할 수 있다. 센서 모듈은 버튼 조작, 또는 터치 입력 중 적어도 하나의 입력 신호를 더 감지할 수 있다. 센서 모듈은 촬영된 입력 영상, 음성 신호 또는 입력 신호 중 적어도 하나의 정보를 프로세서로 전달할 수 있다. 출력 모듈은 프로세서의 제어에 따라 기호, 숫자 또는 문자 중 적어도 하나의 데이터를 시각, 청각 또는 촉각적으로 출력할 수 있다. 출력 모듈은 예를 들면, 액정 디스플레이, OLED, 터치스크린 디스플레이, 스피커 중 적어도 하나의 출력 장치를 포함할 수 있다. 출력 모듈은 프로세서의 제어에 따라 자세 교정 정보를 출력할 수 있다. 메모리는 행동 인식 장치(100')의 적어도 하나의 구성요소(예: 프로세서)에 의해 사용되는 다양한 데 이터를 저장할 수 있다. 데이터는 예를 들어, 소프트웨어 및 이와 관련된 명령에 대한 입력 데이터 또는 출력 데이터를 포함할 수 있다. 예를 들어, 메모리는 영상 기반 행동 인식을 위한 적어도 하나의 인스트럭션을 저장할 수 있다. 메모리는 다양한 형태의 휘발성 메모리 또는 비휘발성 메모리를 포함할 수 있다. 예를 들 어, 메모리는 ROM(read only memory) 및 RAM(random access memory)를 포함할 수 있다. 본 기재의 실시예에서 메모리는 프로세서의 내부 또는 외부에 위치할 수 있고, 메모리는 이미 알려진 다양한 수단을 통해 프로세 서와 연결될 수 있다. 일 실시예에 따르면, 메모리는 복수의 기준 행동에 관련된 기준 행동 데이터를 저장할 수 있다. 상기 각 기준 행동 데이터는 각 기준 행동에 각기 관련된 기준 신체 영역 영상 및 각 기준 신체 영역 영상과 관련된 복 수의 기준 관절 정보를 포함할 수 있다. 상기 기준 행동 데이터는 행동 시작 시점으로 인식될 멀티 모달 정보와 관련하여 저장될 수 있다. 예를 들어, 안무 동작의 행동 시작 시점으로 인식될 멀티 모달 정보는 안무 음악의 시작 시점일 수 있다. 프로세서는 행동 인식 장치(100')의 적어도 하나의 다른 구성요소(예: 하드웨어 또는 소프트웨어 구성요소)를 제어할 수 있고, 다양한 데이터 처리 또는 연산을 수행할 수 있다. 프로세서는 예를 들어, 중 앙처리장치(CPU), 그래픽처리장치(GPU), 마이크로프로세서, 애플리케이션 프로세서(application processor), 주 문형 반도체(ASIC(application specific integrated circuit), FPGA(field programmable gate arrays)) 중 적 어도 하나를 포함할 수 있으며, 복수의 코어를 가질 수 있다. 프로세서는 동기화 모듈, 인식 모듈, 유사도 비교 모듈 및 안내 모듈을 포함할 수 있 다. 동기화 모듈, 인식 모듈, 유사도 비교 모듈 및 안내 모듈은 프로세서에 의해 실 행되는 소프트웨어 모듈일 수 있다. 프로세서는 센서 모듈을 통해 사용자 영상을 촬영하고, 동기화 모듈을 통해 촬영 영상에서 행동 시작 시점을 검출할 수 있다. 프로세서는 인식 모듈을 통해 행동 시작 시점부터 상기 입력 영상으로 부터 신체 영역을 추출하고, 상기 신체 영역에 포함된 관절 정보를 인식할 수 있다. 프로세서는 유사도 비 교 모듈을 통해 신체 영역 영상 및 관절 정보 중 적어도 하나에 기반하여 복수의 기준 행동 데이터와 입력 영상 간의 적어도 하나의 유사도(예: 제1 내지 제3 유사도)를 산출할 수 있다. 프로세서는 유사도 비교 모 듈을 통해 입력 영상에 대응하는 기준 행동 데이터를 결정하고, 안내 모듈을 통해 사용자 행동을 기 준 행동 데이터에 따른 기준 행동에 맞추도록 하는 자세 교정 정보를 생성할 수 있다. 프로세서는 자세 교정 정보를 - 예컨대, 사용자 정보와 함께 - 출력 모듈(예: 디스플레이)을 통해 출 력할 수 있다. 이 경우, 사용자는 자신의 행동과 자세 교정 정보를 함께 확인하고, 자신의 운동/안무/춤 자세를 교정할 수 있다. 이와 같이, 제1 실시예에 따른 행동 인식 장치(100')는 하나의 장치로 구성되어, 사용자와 직접 인터페이스하면 서 사용자 행동을 추적하여 사용자 행동을 교정하도록 지원할 수 있다. 이 경우, 행동 인식 장치(100')는 오프 라인 게임기 등으로 구현되어 사용자의 춤, 운동과 같은 행동을 인식 및 교정하도록 지원할 수 있다. 도 4는 제2 실시예에 따른 행동 인식 장치의 구성도를 나타낸다. 도 4를 참조하면, 제2 실시예에 따른 행동 인식 장치(100\")는 사용자 단말(400A) 및 서버 장치(400B)를 포함할 수 있다. 일 실시예에서, 행동 인식 장치(100\")는 일부 구성요소가 생략되거나, 추가적인 구성요소를 더 포함할 수 있다. 또한, 행동 인식 장치(100\")의 구성요소들 중 일부가 결합되어 하나의 개체로 구성되되, 결합 이전의 해당 구성 요소들의 기능을 동일하게 수행할 수 있다. 도 4에서는 설명의 편의성과 이해를 돕기 위하여 도 1 내지 3와 중 복되는 설명을 가급적 생략하고 새로운 구성을 중심으로 설명한다. 하지만, 이에 한정되지 않는다. 일 실시예에 따르면, 사용자 단말(400A)은 사용자에 의해 소지되는 컴퓨팅 장치로서, 스마트폰, 스마트 패드, TV, 노트북, 랩탑과 같은 다양한 단말일 수 있다. 일 실시예에 따르면, 서버 장치(400B)는 지정된 서비스(예: 춤 배우기)과 관련된 행동 인식 방법을 제공하는 서 버일 수 있다. 일 실시예에 따르면, 행동 인식 장치(100\")는 요가나 스포츠와 같이 지정된 동작을 따라하는 사람의 행동을 지 정된 행동과 현재 사람의 행동 간의 유사도를 수치적으로 산출하고 이를 통해 사용자가 행동을 보정하도록 유도 할 수 있다. 일 실시예에 따르면, 사용자는 사용자 단말(400A)의 센서 모듈(또는, 입력 모듈(미도시))을 통해 '제1 뮤 직의 안무 배우기' 서비스를 선택할 수 있다. 그러면, 사용자 단말(400A)은 서버 장치(400B)에 요청하여 제1 뮤 직의 안무 동영상을 스트리밍 받고, 제1 뮤직의 안무를 재생하면서, 사용자의 신체를 촬영함에 따라 생성된 사 용자 영상을 제1 뮤직의 재생 시점과 관련하여 서버 장치(400B)로 송신할 수 있다. 서버 장치(400B)는 사용자 영상으로부터 제1 뮤직의 재생 시점을 확인하고, 확인된 시점을 행동 시작 시점으로 결정할 수 있다. 서버 장치 (400B)는 사용자 영상으로부터 신체 영역 및 신체 영역에 관련된 관절 정보를 추출하고, 추출된 신체 영역 및 관절 정보와 제1 뮤직의 안무에 대응하는 기준 행동 데이터와 비교함에 따라 사용자의 춤 동작을 교정하기 위한 행동 교정 정보를 생성 및 사용자 단말(400A)에 제공할 수 있다. 그러면, 사용자 단말(400A)은 제1 뮤직의 안무 와 더불어 사용자에 대한 행동 교정 정보를 출력함에 따라 사용자의 행동을 교정할 수 있다. 상기 행동 교정 정 보는 예를 들면, 더 정확한 춤 동작을 위하여 관절의 위치를 교정하도록 안내하는 화살표, 문구, 이미지(예: 관 절 위치 표시 이미지) 또는 음성 안내 중 적어도 하나의 안내를 포함할 수 있다. 일 실시예에 따르면, 사용자가 사용자 단말(400A)의 센서 모듈(또는, 입력 모듈(미도시))을 통해 '요가 배 우기' 서비스를 선택하면, 사용자 단말(400A)은 서버 장치(400B)에 요청하여 요가 동영상을 스트리밍 받을 수 있다. 사용자 단말(400A)은 요가 동작 동영상을 재생하면서 사용자 신체를 촬영함에 따라 사용자 영상을 생성하 고 생성된 사용자 영상을 요가 동영상의 재생 시점과 관련하여 서버 장치(400B)에 송신할 수 있다. 서버 장치 (400B)는 사용자 영상으로부터 요가 동영상의 재생 시점을 검출하여 요가 동작의 재생 시작 시점으로 검출할 수 있다. 서버 장치(400B)는 사용자 영상으로부터 신체 영역 및 관절 정보를 추출한 후 요가 동영상에 대응하는 기 준 행동 데이터와 비교함에 따라 사용자의 요가 동작을 교정하기 위한 행동 교정 정보를 생성 및 사용자 단말 (400A)에 제공할 수 있다. 그러면, 사용자 단말(400A)은 요가 동영상과 더불어 사용자에 대한 행동 교정 정보를 출력함에 따라 사용자의 행동을 교정할 수 있다. 상술한 실시예에서는 서버 장치(400B)(또는, 행동 인식 장치(100”))가 재생중인 동영상의 재생 시점에 기반하 여 행동 시작 시점을 확인하는 경우를 예로 들어 설명하였다. 하지만, 이와 달리, 서버 장치(400B)는 재생 동영 상 없이 사용자 영상으로부터 확인된 음성에 기반하여 행동 시작 시점을 확인할 수 있다. 예를 들어, 사용자는 사용자 단말(400A)을 통해 '요가 운동 서비스'를 선택하면, 사용자 단말(400A)은 사용자의 신체에 대한 동영상 (사용자 영상)을 촬영하면서 사용자 음성을 녹음할 수 있다. 사용자 단말(400A)은 사용자 영상과 음성을 상호 관련하여 서버 장치(400B)로 송신할 수 있다. 그러면, 서버 장치(400B)는 사용자 음성으로부터 '시작' 또는 '브짓지'와 같은 지정된 음성을 획득하고, 음성 검출 시점을 행동 시작 시점으로 확인할 수 있다. 서버 장치(400 B)는 행동 시점 시작부터 사용자 영상으로부터 추출된 신체 영역 및 관절 정보를 기준 행동 데이터와 비교함에 따라 행동 교정 정보를 생성 및 사용자 단말(400A)에 송신할 수 있다. 사용자 단말(400A)은 행동 교정 정보를 수신하여 행동 교정 정보에 따라 사용자의 행동을 기준 행동에 맞추도록 하는 촬영 영상, 신체 영역 영상, 가이 드 영상 또는 행동 교정 정보 중 적어도 하나의 정보를 사용자에게 안내할 수 있다. 이하, 도 4를 참조하여 사용자 단말(400A)과 서버 장치(400B)의 각 구성요소에 대하여 설명한다. 도 4를 참조하면, 사용자 단말(400A)은 제1 통신 모듈, 센서 모듈, 출력 모듈, 제1 메모리 및 제1 프로세서를 포함할 수 있다. 사용자 단말(400A)은 사용자 입력을 수신하는 입력 모듈(미도시)을 더 포함할 수 있다. 제1 통신 모듈은 예를 들면, LAN, FTTH, xDSL, WiFi, Wibro, 3G, 4G 또는 5G 중 적어도 하나의 통신 채널 을 수립 및 통신 채널을 통해 데이터를 송수신할 수 있다. 제1 통신 모듈은 서버 장치(400B)와의 통신 채 널을 수립 또는 형성할 수 있다. 센서 모듈은 사용자 영상을 촬영 가능한 카메라 및 주변 소리를 감지하는 마이크를 포함할 수 있다. 출력 모듈은 액정 디스플레이, OLED, 터치스크린 디스플레이, 스피커 중 적어도 하나의 출력 장치를 포함 할 수 있다. 제1 메모리는 사용자 단말(400A)에 의한 영상 촬영 및 행동 교정 안내를 위한 적어도 하나의 인스트럭션을 저장할 수 있다. 제2 메모리는 예를 들면, 서버 장치(400B)와 데이터를 송수신하여 입력 영상에서 행동 시 작 시점 검출, 신체 영역과 관절 정보 인식, 신체 영역과 관절 정보에 기반하여 기준 행동을 확인하고, 기준 행 동과 입력 행동 간을 비교하여 사용자의 행동 교정 정보를 생성하기 위한 적어도 하나의 인스트럭션을 포함할 수 있다. 제1 프로세서는 행동 인식 장치(100\")의 적어도 하나의 다른 구성요소(예: 하드웨어 또는 소프트웨어 구성 요소)를 제어할 수 있고, 다양한 데이터 처리 또는 연산을 수행할 수 있다. 일 실시예에 따르면, 제1 프로세서는 서버 장치(400B)로부터 가이드 영상을 제공받아 출력 모듈을 통 해 출력할 수 있다. 예를 들어, 사용자가 센서 모듈을 통해 행동 형태(예: 춤, 운동)를 선택하면, 제1 프 로세서는 서버 장치(400B)에 요청하고 선택된 행동 형태에 대응하는 가이드 영상을 수신하고 출력 모듈 을 통해 출력할 수 있다. 상기 가이드 영상은 예를 들면, 사용자가 따라할 기준 행동(춤, 운동) 영상)을 포함할 수 있다. 일 실시예에 따르면, 제1 프로세서는 센서 모듈(예: 카메라)를 통해 시간적으로 연속하는 사용자 영 상(예: 동영상)을 획득할 수 있다. 제1 프로세서는 사용자 영상을 실시간으로 제1 통신 모듈을 통해 서버 장치(400B)로 송신할 수 있다. 여기서, 제1 프로세서는 소리(예: 사용자 음성, 재생 음악) 및 조작 버튼 정보와 같은 멀티 모달 정보를 사용자 영상과 더 관련하여 서버 장치(400B)로 송신할 수 있다. 일 실시예에 따르면, 제1 프로세서는 서버 장치(400B)로부터 사용자의 행동 교정과 관련된 행동 교정 정보 를 획득하고, 행동 교정 정보를 출력 모듈을 통해 출력할 수 있다. 예를 들어, 제1 프로세서는 제1 통신 모듈을 통해 서버 장치(400B)로부터 행동 교정 정보를 수신하고, 입력된 신체 영역 영상, 가이드 영 상 및 행동 교정 정보를 종합하여 출력 모듈을 통해 출력할 수 있다. 상기 행동 교정 정보는 예를 들면, 교정할 행동을 안내하는 화살표, 문구, 또는 소리 중 적어도 하나의 정보를 포함할 수 있다. 일 실시예에 따르면, 서버 장치(400B)는 제2 통신 모듈, 제2 메모리 및 제2 프로세서를 포함할 수 있다. 제2 통신 모듈은 예를 들면, LAN, FTTH, xDSL, WiFi, Wibro, 3G, 4G 또는 5G 중 적어도 하나의 통신 채널 을 수립 및 통신 채널을 통해 데이터를 송수신할 수 있다. 제2 통신 모듈은 사용자 단말(400A)과의 통신 채널을 수립 또는 형성할 수 있다. 제2 메모리는 서버 장치(400B)에 의한 사용자 영상으로부터 행동 시작 시점 검출, 신체 영역 및 관절 정보 인식, 사용자 영상에 따른 입력 행동과 대응되는 기준 행동 결정 및 입력 행동의 결정 행동으로의 행동 교정 정 보 생성을 위한 적어도 하나의 인스트럭션을 저장할 수 있다. 제2 프로세서는 행동 인식 장치(100\")의 적어도 하나의 다른 구성요소(예: 하드웨어 또는 소프트웨어 구성 요소)를 제어할 수 있고, 다양한 데이터 처리 또는 연산을 수행할 수 있다. 제2 프로세서는 동기화 모듈, 인식 모듈, 유사도 비교 모듈 및 안내 모듈을 포함할 수 있다. 동기화 모듈, 인식 모듈, 유사도 비교 모듈 및 안내 모듈은 제2 프로세서에 의해 실행되는 소프트웨어 모듈일 수 있다. 일 실시예에 따르면, 제2 프로세서는 제2 통신 모듈을 통해 사용자 단말(400A)로부터 사용자 영상을 획득할 수 있다. 제2 프로세서는 동기화 모듈을 통해 촬영 영상에서 행동 시작 시점을 검출하고, 인 식 모듈을 통해 행동 시작 시점부터 상기 입력 영상으로부터 신체 영역 추출 및 신체 영역에 포함된 관절 정보를 인식할 수 있다. 제2 프로세서는 유사도 비교 모듈을 통해 복수의 기준 행동 데이터와 입력 신체 영역/관절 정보 간의 적어도 하나의 유사도(예: 제1 내지 제3 유사도)를 산출함에 따라 사용자 영상에 대 응하는 기준 행동을 결정할 수 있다. 제2 프로세서는 안내 모듈을 통해 사용자 행동을 기준 행동에 맞추도록 하는 자세 교정 정보를 생성할 수 있다. 일 실시예에 따르면, 제2 프로세서는 사용자의 행동 교정과 관련된 출력 영상을 생성하고, 제2 통신 모듈 을 통해 사용자 단말(400A)에 송신할 수 있다. 상기 출력 영상은 예를 들면, 촬영 영상, 입력된 신체 영역 영상, 가이드 영상(예: 사용자가 따라할 기준 행동(춤, 운동) 영상), 행동 교정 정보(예: 교정할 행동을 안내하 는 화살표, 문구, 음성 안내) 중 적어도 하나의 정보를 포함할 수 있다. 예를 들어, 제2 프로세서는 제2 통신 모듈을 통해 사용자 단말(400A)에 가이드 영상 및 행동 교정 정보를 송신함에 따라 사용자 단말 (400A)이 입력된 신체 영역 영상, 가이드 영상 및 행동 교정 정보를 출력하도록 지원할 수 있다. 이와 같이, 일 실시예에 따른 행동 인식 장치(100\")는 기준 행동(동작)과 사용자 행동 간 유사도를 비교함에 따 라 게임, 춤 학습 등과 같이 여러 분야에서 다양하게 활용될 수 있다. 도 5는 일 실시예에 따른 행동 인식 방법의 흐름도를 나타낸다. 도 5를 참조하면, 동작 510에서, 행동 인식 장치는 입력 영상으로부터 행동 시작 시점을 검출할 수 있다. 예를 들어, 행동 인식 장치는 멀티 모달 정보에 기반하여 행동 시작 시점을 검출할 수 있다. 상기 멀티 모 달 정보는 지정된 음성 입력, 지정된 음악 시작, 지정된 버튼 조작, 지정된 제스처 입력, 지정된 화면 출력 또 는 지정된 음악 재생 중 적어도 하나의 정보를 포함할 수 있다. 동작 520에서, 행동 인식 장치는 행동 시작 시점부터 상기 입력 영상으로부터 신체 영역을 추출하고 신체 영역에서 관절 정보를 인식할 수 잇다. 예를 들어, 행동 인식 장치는 사용자 신체 영역을 학습한 제1 인공 지능 모델에 기반하여 행동 시작 시점의 각 프레임으로부터 신체 영역을 추출할 수 있다. 행동 인식 장치 는 제1 인공지능 모델을 이용하여 추출된 신체 영역의 특징점에 기반하여 신체 영역으로부터 지정된 관절 위치 좌표를 예측할 수 있다. 상기 신체 영역은 예를 들면, 입력 영상의 각 프레임에서 사람으로 인식된 영역 영상일 수 있다. 상기 관절 정보는 각 관절의 위치 좌표일 수 있다. 동작 530에서, 행동 인식 장치는 신체 영역 및 상기 관절 정보를 포함하는 사용자 데이터와 상기 복수의 기준 행동 데이터 간의 유사도를 산출할 수 있다. 동작 530에서, 행동 인식 장치는 유사도 산출에 기반하 여 상기 입력 영상과 비교할 기준 행동을 결정할 수 있다. 도 6은 일 실시예에 따른 행동 인식 방법의 세부 흐름도를 나타낸다. 도 6을 참조하면, 동작 610에서, 행동 인식 장치는 사용자 영상이 입력될 때까지 대기할 수 잇다. 행동 인식 장치는 동작 610에서 사용자 영상이 입력되는 것을 확인하면, 동작 620에서, 기제공된 가이드 영상이 있는지를 확인할 수 있다. 상기 가이드 영상은 예를 들면, 사용자가 따라할 기준 행동(춤, 운동) 영상) 을 포함할 수 있다. 행동 인식 장치는 동작 620에서, 가제공된 가이드 영상이 있는 것을 확인하면, 동작 630에서, 가이드 영상 의 재생 시점에 기반하여 행동 시작 시점을 검출할 수 있다. 동작 640에서, 행동 인식 장치는 행동 시작 시점부터 사용자 영상에서 신체 영역 및 관절 정보를 포함하는 사용자 데이터를 추출할 수 있다. 예를 들어, 행동 인식 장치는 사용자 영상에서 신체 영역을 추출하고, 신체 영역에서 관절 위치 좌표에 관련된 관절 정보를 검출할 수 있다. 동작 650에서, 행동 인식 장치는 사용자 데이터를 기준 행동 데이터에 대응하도록 정규화할 수 있다. 예를 들어, 행동 인식 장치는 신체 영역 및 관절 정보를 기준 행동 데이터에 따른 신체 영역의 크기에 대응하도록 정규화할 수 있다. 행동 인식 장치는 정규화된 신체 영역에 기반하여 관절 정보 또한 정규화할 수 있다. 동작 660에서, 행동 인식 장치는 정규화된 사용자 데이터와 기준 행동 데이터에 기반하여 사용자 영상에 대응하는 기준 행동을 결정할 수 있다. 동작 670에서, 행동 인식 장치는 사용자 영상에 따른 사용자 행동과 결정된 기준 행동의 유사도에 기반하 여 행동 교정 정보를 생성할 수 있다. 동작 670에서, 행동 인식 장치는 생성된 행동 교정 정보를 사용자에 게 제공할 수 있다. 동작 680에서, 행동 인식 장치는 사용자 행동과 결정된 기준 행동 간의 유사도가 지정된 값 미만인지를 확 인할 수 있다. 사용자 행동과 기준 행동 간의 유사도가 지정된 값 미만이면, 행동 인식 장치는 사용자 행 동에 대한 유사도 비교를 종료할 수 있다. 한편, 동작 620에서, 기 제공된 가이드 영상이 없는 것을 확인하면, 행동 인식 장치는 사용자 영상과 관련 된 지정된 소리 또는 입력이 있는지를 확인하고, 지정된 소리 또는 입력에 기반하여 행동 시작 시점을 검출할 수 있다. 본 문서의 다양한 실시예들 및 이에 사용된 용어들은 본 문서에 기재된 기술적 특징들을 특정한 실시예들로 한 정하려는 것이 아니며, 해당 실시예의 다양한 변경, 균등물, 또는 대체물을 포함하는 것으로 이해되어야 한다. 도면의 설명과 관련하여, 유사한 또는 관련된 구성요소에 대해서는 유사한 참조 부호가 사용될 수 있다. 아이템 에 대응하는 명사의 단수 형은 관련된 문맥상 명백하게 다르게 지시하지 않는 한, 상기 아이템 한 개 또는 복수 개를 포함할 수 있다. 본 문서에서, \"A 또는 B\", \"A 및 B 중 적어도 하나\",“A 또는 B 중 적어도 하나”, \"A, B 또는 C\", \"A, B 및 C 중 적어도 하나” 및 “A, B, 또는 C 중 적어도 하나\"와 같은 문구들 각각은 그 문구들 중 해당하는 문구에 함께 나열된 항목들 중 어느 하나, 또는 그들의 모든 가능한 조합을 포함할 수 있다. \"제1\", \"제2\", 또는 \"첫째\" 또는 \"둘째\"와 같은 용어들은 단순히 해당 구성요소를 다른 해당 구성요소와 구분하기 위 해 사용될 수 있으며, 해당 구성요소들을 다른 측면(예: 중요성 또는 순서)에서 한정하지 않는다. 어떤(예: 제 1) 구성요소가 다른(예: 제2) 구성요소에, “기능적으로” 또는 “통신적으로”라는 용어와 함께 또는 이런 용 어 없이, “커플드” 또는 “커넥티드”라고 언급된 경우, 그것은 상기 어떤 구성요소가 상기 다른 구성요소에 직접적으로(예: 유선으로), 무선으로, 또는 제3 구성요소를 통하여 연결될 수 있다는 것을 의미한다. 본 문서에서 사용된 용어 \"모듈\"은 하드웨어, 소프트웨어 또는 펌웨어로 구현된 유닛을 포함할 수 있으며, 예를 들면, 로직, 논리 블록, 부품, 또는 회로와 같은 용어와 상호 호환적으로 사용될 수 있다. 모듈은, 일체로 구성 된 부품 또는 하나 또는 그 이상의 기능을 수행하는, 상기 부품의 최소 단위 또는 그 일부가 될 수 있다. 예를 들면, 일실시예에 따르면, 모듈은 ASIC(application-specific integrated circuit)의 형태로 구현될 수 있다. 본 문서의 다양한 실시예들은 기기(machine)(예: 전자 장치) 의해 읽을 수 있는 저장 매체(storage medium)() (예: 내장 메모리 또는 외장 메모리)에 저장된 하나 이상의 명령어들을 포함하는 소프트웨어(예: 프로그램)로서 구현될 수 있다. 예를 들면, 기기(예: 행동 인식 장치)의 프로세서(예: 프로세서는, 저장 매체로부터 저장된 하나 이상의 명령어들 중 적어도 하나의 명령을 호출하고, 그것을 실행할 수 있다. 이것은 기기가 상기 호출된 적어도 하나의 명령어에 따라 적어도 하나의 기능을 수행하도록 운영되는 것을 가능하게 한다. 상기 하 나 이상의 명령어들은 컴파일러에 의해 생성된 코드 또는 인터프리터에 의해 실행될 수 있는 코드를 포함할 수 있다. 기기로 읽을 수 있는 저장매체는, 비일시적(non-transitory) 저장매체의 형태로 제공될 수 있다. 여기서, ‘비일시적’은 저장매체가 실재(tangible)하는 장치이고, 신호(signal)(예: 전자기파)를 포함하지 않는다는 것 을 의미할 뿐이며, 이 용어는 데이터가 저장매체에 반영구적으로 저장되는 경우와 임시적으로 저장되는 경우를 구분하지 않는다. 일실시예에 따르면, 본 문서에 개시된 다양한 실시예들에 따른 방법은 컴퓨터 프로그램 제품(computer program product)에 포함되어 제공될 수 있다. 컴퓨터 프로그램 제품은 상품으로서 판매자 및 구매자 간에 거래될 수 있 다. 컴퓨터 프로그램 제품은 기기로 읽을 수 있는 저장 매체(예: compact disc read only memory (CD-ROM))의 형태로 배포되거나, 또는 어플리케이션 스토어(예: 플레이 스토어TM)를 통해 또는 두개의 사용자 장치들(예: 스 마트폰들) 간에 직접, 온라인으로 배포(예: 다운로드 또는 업로드)될 수 있다. 온라인 배포의 경우에, 컴퓨터 프로그램 제품의 적어도 일부는 제조사의 서버, 어플리케이션 스토어의 서버, 또는 중계 서버의 메모리와 같은 기기로 읽을 수 있는 저장 매체에 적어도 일시 저장되거나, 임시적으로 생성될 수 있다. 본 문서의 다양한 실시예에 따른 구성 요소들은 소프트웨어 또는 DSP(digital signal processor), FPGA(Field Programmable Gate Array) 또는 ASIC(Application Specific Integrated Circuit)와 같은 하드웨어 형태로 구현 될 수 있으며, 소정의 역할들을 수행할 수 있다. '구성 요소들'은 소프트웨어 또는 하드웨어에 한정되는 의미는 아니며, 각 구성 요소는 어드레싱할 수 있는 저장 매체에 있도록 구성될 수도 있고 하나 또는 그 이상의 프로세 서들을 재생시키도록 구성될 수도 있다. 일 예로서 구성 요소는 소프트웨어 구성 요소들, 객체지향 소프트웨어 구성 요소들, 클래스 구성 요소들 및 태스크 구성 요소들과 같은 구성 요소들과, 프로세스들, 함수들, 속성들, 프로시저들, 서브루틴들, 프로그램 코드의 세그먼트들, 드라이버들, 펌웨어, 마이크로 코드, 회로, 데이터, 데 이터베이스, 데이터 구조들, 테이블들, 어레이들 및 변수들을 포함할 수 있다. 다양한 실시예들에 따르면, 상기 기술한 구성요소들의 각각의 구성요소(예: 모듈 또는 프로그램)는 단수 또는 복수의 개체를 포함할 수 있다. 다양한 실시예들에 따르면, 전술한 해당 구성요소들 중 하나 이상의 구성요소들 또는 동작들이 생략되거나, 또는 하나 이상의 다른 구성요소들 또는 동작들이 추가될 수 있다. 대체적으로 또는 추가적으로, 복수의 구성요소들(예: 모듈 또는 프로그램)은 하나의 구성요소로 통합될 수 있다. 이런 경우, 통 합된 구성요소는 상기 복수의 구성요소들 각각의 구성요소의 하나 이상의 기능들을 상기 통합 이전에 상기 복수 의 구성요소들 중 해당 구성요소에 의해 수행되는 것과 동일 또는 유사하게 수행할 수 있다. 다양한 실시예들에 따르면, 모듈, 프로그램 또는 다른 구성요소에 의해 수행되는 동작들은 순차적으로, 병렬적으로, 반복적으로, 또는 휴리스틱하게 실행되거나, 상기 동작들 중 하나 이상이 다른 순서로 실행되거나, 생략되거나, 또는 하나 이상의 다른 동작들이 추가될 수 있다."}
{"patent_id": "10-2023-0138648", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 일 실시예에 따른 행동 인식 장치의 구성도를 나타낸다. 도 2는 일 실시예에 따른 행동 자세 벡터를 설명하기 위한 도면이다. 도 3은 제1 실시예에 따른 행동 인식 장치의 구성도를 나타낸다. 도 4는 제2 실시예에 따른 행동 인식 장치의 구성도를 나타낸다. 도 5는 일 실시예에 따른 행동 인식 방법의 흐름도를 나타낸다. 도 6은 일 실시예에 따른 행동 인식 방법의 세부 흐름도를 나타낸다. 도면의 설명과 관련하여, 동일 또는 유사한 구성요소에 대해서는 동일 또는 유사한 참조 부호가 사용될 수 있다."}
