{"patent_id": "10-2024-0078218", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2025-0012512", "출원번호": "10-2024-0078218", "발명의 명칭": "인공지능 모델의 운영을 위한 단말 환경에서의 인공지능 모델의 관리를 위한 방법 및 시스템", "출원인": "주식회사 피아몬드", "발명자": "황두건"}}
{"patent_id": "10-2024-0078218", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "적어도 하나의 프로세서를 포함하는 컴퓨터 장치의 인공지능 모델 관리 방법에 있어서,상기 적어도 하나의 프로세서에 의해, 인공지능 모델 스토어에 등록된 복수의 인공지능 모델들 중에서 인공지능모델을 선택하는 단계;상기 적어도 하나의 프로세서에 의해, 상기 선택된 인공지능 모델의 특징 및 기능에 대한 정보를 상기 인공지능모델 스토어를 통해 획득하여 사용자에게 제공하는 단계;상기 적어도 하나의 프로세서에 의해, 상기 사용자의 요청에 따라 상기 인공지능 모델 스토어를 통해 상기 선택된 인공지능 모델을 다운로드하여 검증하는 단계; 및상기 적어도 하나의 프로세서에 의해, 상기 검증된 인공지능 모델의 데이터 접근 범위, 실시간 입력 연동 범위,외부 통신 범위, 및 동작 주기 중 적어도 둘 이상을 상기 사용자를 통해 설정받기 위한 기능을 제공하는 단계를 포함하는 인공지능 모델 관리 방법."}
{"patent_id": "10-2024-0078218", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 데이터 접근 범위를 설정받기 위한 기능은, (1) 상기 검증된 인공지능 모델이 접근 가능한 데이터의 형식,(2) 상기 컴퓨터 장치에 설치된 외부 어플리케이션 중 상기 검증된 인공지능 모델이 호출 가능한 어플리케이션,및 (3) 상기 컴퓨터 장치에 저장된 데이터 중 상기 인공지능 모델이 접근 가능한 데이터, 중 적어도 하나를 설정받기 위한 기능을 포함하는 것을 특징으로 하는 인공지능 모델 관리 방법."}
{"patent_id": "10-2024-0078218", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 실시간 입력 연동 범위를 설정받기 위한 기능은, 기설정된 복수의 호출 가능 형태 중에서 상기 검증된 인공지능 모델과 관련하여 활성화 가능한 호출 가능 형태를 설정받기 위한 기능을 포함하는 것을 특징으로 하는인공지능 모델 관리 방법."}
{"patent_id": "10-2024-0078218", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서,상기 복수의 호출 가능 형태는, (1) 상기 컴퓨터 장치가 제공하는 사용자 인터페이스를 통해 상기 검증된 인공지능 모델이 호출되는 형태, (2) 상기 검증된 인공지능 모델이 상기 사용자의 명령어를 대기하는 형태, 및 (3)상기 컴퓨터 장치에 설치된 다른 인공지능 모델 또는 어플리케이션을 통해 상기 검증된 인공지능 모델이 호출되는 형태, 중 둘 이상을 포함하는 것을 특징으로 하는 인공지능 모델 관리 방법."}
{"patent_id": "10-2024-0078218", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서,상기 외부 통신 범위를 설정받기 위한 기능은, 상기 검증된 인공지능 모델의 외부 통신 가능 여부를 설정받기위한 기능을 포함하는 것을 특징으로 하는 인공지능 모델 관리 방법."}
{"patent_id": "10-2024-0078218", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서,상기 동작 주기를 설정받기 위한 기능은, 상기 검증된 인공지능 모델이 상기 사용자의 입력에 반응하여 동작하공개특허 10-2025-0012512-3-는 주기 또는 방식을 설정받기 위한 기능을 포함하는 것을 특징으로 하는 인공지능 모델 관리 방법."}
{"patent_id": "10-2024-0078218", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6항에 있어서,상기 검증된 인공지능 모델이 상기 사용자의 입력에 반응하여 동작하는 방식은 상기 검증된 인공지능 모델이 자체적으로 트리거링되는 방식을 적어도 포함하는 것을 특징으로 하는 인공지능 모델 관리 방법."}
{"patent_id": "10-2024-0078218", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1항에 있어서,상기 적어도 하나의 프로세서는, 암호화 기능을 제공하는 하드웨어 또는 펌웨어로 구현된 암호화 프로세서를 포함하고,상기 다운로드하여 검증하는 단계는,상기 암호화 프로세서와 상기 컴퓨터 장치가 더 포함하는 보안 메모리간에 설정된 암호화된 채널을 통해 상기선택된 인공지능 모델의 적어도 일부를 암호화하여 상기 보안 메모리의 저장 공간으로 전달하는 것을 특징으로 하는 인공지능 모델 관리 방법."}
{"patent_id": "10-2024-0078218", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서,상기 보안 메모리는, 인공지능 모델 및 인공지능 모델과 관련된 메타데이터를 저장하기 위한 인공지능 모델 스토리지, 및 상기 컴퓨터 장치에 설치된 인공지능 모델을 통해 수집 및 생성되는 데이터를 저장하기 위한 인공지능 데이터 스토리지를 포함하는 것을 특징으로 하는 인공지능 모델 관리 방법."}
{"patent_id": "10-2024-0078218", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9항에 있어서,상기 인공지능 데이터 스토리지는 인공지능 모델을 통해 임베딩된 벡터 데이터를 저장하기 위한 벡터 저장 기능을 포함하는 것을 특징으로 하는 인공지능 모델 관리 방법."}
{"patent_id": "10-2024-0078218", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제1항 내지 제10항 중 어느 한 항의 방법을 상기 컴퓨터 장치에 실행시키기 위해 컴퓨터 판독 가능한 기록매체에 저장되는 컴퓨터 프로그램."}
{"patent_id": "10-2024-0078218", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제1항 내지 제10항 중 어느 한 항의 방법을 컴퓨터 장치에 실행시키기 위한 컴퓨터 프로그램이 기록되어 있는컴퓨터 판독 가능한 기록매체."}
{"patent_id": "10-2024-0078218", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "컴퓨터 장치에 있어서,상기 컴퓨터 장치에서 판독 가능한 명령을 실행하도록 구현되는 적어도 하나의 프로세서를 포함하고,상기 적어도 하나의 프로세서에 의해, 인공지능 모델 스토어에 등록된 복수의 인공지능 모델들 중에서 인공지능 모델을 선택하고, 상기 선택된 인공지능 모델의 특징 및 기능에 대한 정보를 상기 인공지능 모델 스토어를 통해 획득하여 사용자에게 제공하고, 상기 사용자의 요청에 따라 상기 인공지능 모델 스토어를 통해 상기 선택된 인공지능 모델을 다운로드하여 검증공개특허 10-2025-0012512-4-하고,상기 검증된 인공지능 모델의 데이터 접근 범위, 실시간 입력 연동 범위, 외부 통신 범위, 및 동작 주기 중 적어도 둘 이상을 상기 사용자를 통해 설정받기 위한 기능을 제공하는 것을 특징으로 하는 컴퓨터 장치."}
{"patent_id": "10-2024-0078218", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제13항에 있어서,상기 데이터 접근 범위를 설정받기 위한 기능은, (1) 상기 검증된 인공지능 모델이 접근 가능한 데이터의 형식,(2) 상기 컴퓨터 장치에 설치된 외부 어플리케이션 중 상기 검증된 인공지능 모델이 호출 가능한 어플리케이션,및 (3) 상기 컴퓨터 장치에 저장된 데이터 중 상기 인공지능 모델이 접근 가능한 데이터, 중 적어도 하나를 설정받기 위한 기능을 포함하는 것을 특징으로 하는 컴퓨터 장치."}
{"patent_id": "10-2024-0078218", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제13항에 있어서,상기 실시간 입력 연동 범위를 설정받기 위한 기능은, 기설정된 복수의 호출 가능 형태 중에서 상기 검증된 인공지능 모델과 관련하여 활성화 가능한 호출 가능 형태를 설정받기 위한 기능을 포함하는 것을 특징으로 하는 컴퓨터 장치."}
{"patent_id": "10-2024-0078218", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제13항에 있어서,상기 외부 통신 범위를 설정받기 위한 기능은, 상기 검증된 인공지능 모델의 외부 통신 가능 여부를 설정받기위한 기능을 포함하는 것을 특징으로 하는 컴퓨터 장치."}
{"patent_id": "10-2024-0078218", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제13항에 있어서,상기 동작 주기를 설정받기 위한 기능은, 상기 검증된 인공지능 모델이 상기 사용자의 입력에 반응하여 동작하는 주기 또는 방식을 설정받기 위한 기능을 포함하는 것을 특징으로 하는 컴퓨터 장치."}
{"patent_id": "10-2024-0078218", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제13항에 있어서,상기 적어도 하나의 프로세서는, 암호화 기능을 제공하는 하드웨어 또는 펌웨어로 구현된 암호화 프로세서를 포함하고,상기 선택된 인공지능 모델을 다운로드하여 검증하기 위해, 상기 암호화 프로세서는,상기 암호화 프로세서와 상기 컴퓨터 장치가 더 포함하는 보안 메모리간에 설정된 암호화된 채널을 통해 상기선택된 인공지능 모델의 적어도 일부를 암호화하여 상기 보안 메모리의 저장 공간으로 전달하는 것을 특징으로 하는 컴퓨터 장치."}
{"patent_id": "10-2024-0078218", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "인공지능 모델의 운영을 위한 단말 환경에서의 인공지능 모델의 관리를 위한 방법 및 시스템을 개시한다. 일실 시예에 따른 인공지능 모델 관리 방법은 인공지능 모델 스토어에 등록된 복수의 인공지능 모델들 중에서 인공지 능 모델을 선택하는 단계, 상기 선택된 인공지능 모델의 특징 및 기능에 대한 정보를 상기 인공지능 모델 스토어 를 통해 획득하여 사용자에게 제공하는 단계, 상기 사용자의 요청에 따라 상기 인공지능 모델 스토어를 통해 상 기 선택된 인공지능 모델을 다운로드하여 검증하는 단계, 및 상기 검증된 인공지능 모델의 데이터 접근 범위, 실 시간 입력 연동 범위, 외부 통신 범위, 및 동작 주기 중 적어도 둘 이상을 상기 사용자를 통해 설정받기 위한 기 능을 제공하는 단계를 포함할 수 있다."}
{"patent_id": "10-2024-0078218", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "아래의 설명은 인공지능 모델의 운영을 위한 단말 환경에서의 인공지능 모델의 관리를 위한 방법 및 시스템에 관한 것이다."}
{"patent_id": "10-2024-0078218", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "인공지능(Artificial Intelligence, AI) 모델은 급속도로 발전하고 있으며, LLM(Large Language Model)에 대한 정교한 트레이닝을 통해 보다 작은 하이퍼파라미터(Hyperparameter)를 이용함에도 고성능을 가진 새로운 전문가 모델들이 등장할 것으로 기대되고 있다. 또한, 기존 사용자 단말 환경은 LLM을 탑재할 수 없으나, 향후 단말의 메모리 및 추론 전용 칩 등의 탑재로 인해 보다 큰 AI 모델의 단말 구동이 가능할 것으로 기대되고 있다. 또한, MOE(Mixture of Expert)와 같이 특정 도메인에 특화되어 학습된 AI 모델을 활용하여, 우수한 추론 성능을 제공하는 소형 모델을 필요에 따라 로딩 후 활용하는 형태 등의 접근들이 이루어질 수 있다. 한편, 사용자와 사이버 세계가 만나는 접점인 휴대 단말 또는 AR(Augmented Reality), VR(Virtual Reality), XR(eXtended Reality) 장치 등이 사용자의 정보를 가장 손쉽게 취득할 수 있는 포인트가 될 수 있다. 향후 단 말상에서의 사용자의 행위를 학습하고 이러한 사용자의 행위를 대신해서 처리할 수 있는 온-디바이스(On- device) AI 에이전트가 사용자의 단말에 탑재될 것으로 기대되고 있다. 이 경우, 모바일 환경에서 이용하는 다 양한 서비스 응답 및 양방향 상호작용을 AI 모델이 대신할 것으로 예상된다. 일례로, AI 모델을 통해 단말은"}
{"patent_id": "10-2024-0078218", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 2, "content": "사용자의 기상 여부를 판단하여 알람의 울림 여부 및 소리 등을 제어하고, 전날의 주식시장 정보를 요약해서 제"}
{"patent_id": "10-2024-0078218", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 3, "content": "공하고, 이메일의 주요 내용을 요약하고, 할 일(to do list) 또는 스케쥴 상의 주요 일정을 리마인드하고, 구입 상품들의 배송 현황 또는 금일 수령할 상품들에 대한 정보를 알려 주는 것 등, 사용자와 단말간의 상호작용을 통해 수행되던 일들에서 사용자의 행위를 AI 모델이 대신할 수 있다. 이러한 단말 구동용 AI 모델은 외부 네트워크 상의 AI 모델과의 차별성을 갖는다. 외부 네트워크 상에서 동작 하는 AI 모델이 경우 사용자 데이터의 외부 반출이 이루어지는 점 등의 이슈로 개인의 활용성의 한계가 존재한 다. 특히 프라이버시의 노출에 대해 자유롭지 않고, 매번 외부 네트워크 자원을 이용하는 점, 응답에 네트워크 지연 등이 발생할 수 있다. 이와 대비해, 단말상에서 구동 가능한 경량 AI 모델의 경우 시스템의 성능에 따른 모델 크기에 비례해 원하는 AI 기능을 단말 상에서 직접 구동할 수 있는 특징을 갖는다. [선행문헌번호] 한국공개특허 제10-2024-0068980호"}
{"patent_id": "10-2024-0078218", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "인공지능 모델의 운영을 위한 단말 환경에서의 인공지능 모델의 관리를 위한 방법 및 시스템을 제공한다."}
{"patent_id": "10-2024-0078218", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "적어도 하나의 프로세서를 포함하는 컴퓨터 장치의 인공지능 모델 관리 방법에 있어서, 상기 적어도 하나의 프 로세서에 의해, 인공지능 모델 스토어에 등록된 복수의 인공지능 모델들 중에서 인공지능 모델을 선택하는 단계; 상기 적어도 하나의 프로세서에 의해, 상기 선택된 인공지능 모델의 특징 및 기능에 대한 정보를 상기 인 공지능 모델 스토어를 통해 획득하여 사용자에게 제공하는 단계; 상기 적어도 하나의 프로세서에 의해, 상기 사 용자의 요청에 따라 상기 인공지능 모델 스토어를 통해 상기 선택된 인공지능 모델을 다운로드하여 검증하는 단 계; 및 상기 적어도 하나의 프로세서에 의해, 상기 검증된 인공지능 모델의 데이터 접근 범위, 실시간 입력 연 동 범위, 외부 통신 범위, 및 동작 주기 중 적어도 둘 이상을 상기 사용자를 통해 설정받기 위한 기능을 제공하 는 단계를 포함하는 인공지능 모델 관리 방법을 제공한다. 일측에 따르면, 상기 데이터 접근 범위를 설정받기 위한 기능은, 상기 검증된 인공지능 모델이 접근 가능한 데이터의 형식, 상기 컴퓨터 장치에 설치된 외부 어플리케이션 중 상기 검증된 인공지능 모델이 호출 가능 한 어플리케이션, 및 상기 컴퓨터 장치에 저장된 데이터 중 상기 인공지능 모델이 접근 가능한 데이터, 중 적어도 하나를 설정받기 위한 기능을 포함하는 것을 특징으로 할 수 있다. 다른 측면에 따르면, 상기 실시간 입력 연동 범위를 설정받기 위한 기능은, 기설정된 복수의 호출 가능 형태 중 에서 상기 검증된 인공지능 모델과 관련하여 활성화 가능한 호출 가능 형태를 설정받기 위한 기능을 포함하는 것을 특징으로 할 수 있다.또 다른 측면에 따르면, 상기 복수의 호출 가능 형태는, 상기 컴퓨터 장치가 제공하는 사용자 인터페이스를 통해 상기 검증된 인공지능 모델이 호출되는 형태, 상기 검증된 인공지능 모델이 상기 사용자의 명령어를 대기하는 형태, 및 상기 컴퓨터 장치에 설치된 다른 인공지능 모델 또는 어플리케이션을 통해 상기 검증된 인공지능 모델이 호출되는 형태, 중 둘 이상을 포함하는 것을 특징으로 할 수 있다. 또 다른 측면에 따르면, 상기 외부 통신 범위를 설정받기 위한 기능은, 상기 검증된 인공지능 모델의 외부 통신 가능 여부를 설정받기 위한 기능을 포함하는 것을 특징으로 할 수 있다. 또 다른 측면에 따르면, 상기 동작 주기를 설정받기 위한 기능은, 상기 검증된 인공지능 모델이 상기 사용자의 입력에 반응하여 동작하는 주기 또는 방식을 설정받기 위한 기능을 포함하는 것을 특징으로 할 수 있다. 또 다른 측면에 따르면, 상기 검증된 인공지능 모델이 상기 사용자의 입력에 반응하여 동작하는 방식은 상기 검 증된 인공지능 모델이 자체적으로 트리거링되는 방식을 적어도 포함하는 것을 특징으로 할 수 있다. 또 다른 측면에 따르면, 상기 적어도 하나의 프로세서는, 암호화 기능을 제공하는 하드웨어 또는 펌웨어로 구현 된 암호화 프로세서를 포함하고, 상기 다운로드하여 검증하는 단계는, 상기 암호화 프로세서와 상기 컴퓨터 장 치가 더 포함하는 보안 메모리간에 설정된 암호화된 채널을 통해 상기 선택된 인공지능 모델의 적어도 일부를 암호화하여 상기 보안 메모리의 저장 공간으로 전달하는 것을 특징으로 할 수 있다. 또 다른 측면에 따르면, 상기 보안 메모리는, 인공지능 모델 및 인공지능 모델과 관련된 메타데이터를 저장하기 위한 인공지능 모델 스토리지, 및 상기 컴퓨터 장치에 설치된 인공지능 모델을 통해 수집 및 생성되는 데이터를 저장하기 위한 인공지능 데이터 스토리지를 포함하는 것을 특징으로 할 수 있다. 또 다른 측면에 따르면, 상기 인공지능 데이터 스토리지는 인공지능 모델을 통해 임베딩된 벡터 데이터를 저장 하기 위한 벡터 저장 기능을 포함하는 것을 특징으로 할 수 있다. 컴퓨터 장치와 결합되어 상기 방법을 컴퓨터 장치에 실행시키기 위해 컴퓨터 판독 가능한 기록매체에 저장된 컴 퓨터 프로그램을 제공한다. 상기 방법을 컴퓨터 장치에 실행시키기 위한 프로그램이 기록되어 있는 컴퓨터 판독 가능한 기록매체를 제공한 다. 컴퓨터 장치에 있어서, 상기 컴퓨터 장치에서 판독 가능한 명령을 실행하도록 구현되는 적어도 하나의 프로세서 를 포함하고, 상기 적어도 하나의 프로세서에 의해, 인공지능 모델 스토어에 등록된 복수의 인공지능 모델들 중 에서 인공지능 모델을 선택하고, 상기 선택된 인공지능 모델의 특징 및 기능에 대한 정보를 상기 인공지능 모델 스토어를 통해 획득하여 사용자에게 제공하고, 상기 사용자의 요청에 따라 상기 인공지능 모델 스토어를 통해 상기 선택된 인공지능 모델을 다운로드하여 검증하고, 상기 검증된 인공지능 모델의 데이터 접근 범위, 실시간 입력 연동 범위, 외부 통신 범위, 및 동작 주기 중 적어도 둘 이상을 상기 사용자를 통해 설정받기 위한 기능을 제공하는 것을 특징으로 하는 컴퓨터 장치를 제공한다."}
{"patent_id": "10-2024-0078218", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "인공지능 모델의 운영을 위한 단말 환경에서의 인공지능 모델의 관리를 위한 방법 및 시스템을 제공할 수 있다."}
{"patent_id": "10-2024-0078218", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 실시예를 첨부한 도면을 참조하여 상세히 설명한다. 본 발명의 실시예들에 따른 인공지능 모델 관리 시스템은 적어도 하나의 컴퓨터 장치에 의해 구현될 수 있다. 이때, 컴퓨터 장치에는 본 발명의 일실시예에 따른 컴퓨터 프로그램이 설치 및 구동될 수 있고, 컴퓨터 장치는 구동된 컴퓨터 프로그램의 제어에 따라 본 발명의 실시예들에 따른 사용자 인공지능 모델 관리 방법을 수행할 수 있다. 상술한 컴퓨터 프로그램은 컴퓨터 장치와 결합되어 인공지능 모델 관리 방법을 컴퓨터에 실행시키기 위해 컴퓨터 판독 가능한 기록매체에 저장될 수 있다. 도 1은 본 발명의 일실시예에 따른 네트워크 환경의 예를 도시한 도면이다. 도 1의 네트워크 환경은 복수의 전 자 기기들(110, 120, 130, 140), 복수의 서버들(150, 160) 및 네트워크를 포함하는 예를 나타내고 있다. 이러한 도 1은 발명의 설명을 위한 일례로 전자 기기의 수나 서버의 수가 도 1과 같이 한정되는 것은 아니다. 복수의 전자 기기들(110, 120, 130, 140)은 컴퓨터 시스템으로 구현되는 고정형 단말이거나 이동형 단말일 수 있다. 복수의 전자 기기들(110, 120, 130, 140)의 예를 들면, 스마트폰(smart phone), 휴대폰, 내비게이션, 컴퓨터, 노트북, 디지털방송용 단말, PDA(Personal Digital Assistants), PMP(Portable Multimedia Player), 태블릿 PC, 게임 콘솔(game console), 웨어러블 디바이스(wearable device), IoT(internet of things) 디바이 스, VR(virtual reality) 디바이스, AR(augmented reality) 디바이스 등이 있다. 일례로 도 1에서는 전자 기 기의 예로 스마트폰의 형상을 나타내고 있으나, 본 발명의 실시예들에서 전자 기기는 실질적으로 무 선 또는 유선 통신 방식을 이용하여 네트워크를 통해 다른 전자 기기들(120, 130, 140) 및/또는 서버(150, 160)와 통신할 수 있는 다양한 물리적인 컴퓨터 시스템들 중 하나를 의미할 수 있다. 통신 방식은 제한되지 않으며, 네트워크가 포함할 수 있는 통신망(일례로, 이동통신망, 유선 인터넷, 무선 인터넷, 방송망, 위성망 등)을 활용하는 통신 방식뿐만 아니라 기기들간의 근거리 무선 통신 역시 포함될 수 있 다. 예를 들어, 네트워크는, PAN(personal area network), LAN(local area network), CAN(campus area network), MAN(metropolitan area network), WAN(wide area network), BBN(broadband network), 인터넷 등의 네트워크 중 하나 이상의 임의의 네트워크를 포함할 수 있다. 또한, 네트워크는 버스 네트워크, 스타 네 트워크, 링 네트워크, 메쉬 네트워크, 스타-버스 네트워크, 트리 또는 계층적(hierarchical) 네트워크 등을 포 함하는 네트워크 토폴로지 중 임의의 하나 이상을 포함할 수 있으나, 이에 제한되지 않는다. 서버(150, 160) 각각은 복수의 전자 기기들(110, 120, 130, 140)과 네트워크를 통해 통신하여 명령, 코드, 파일, 콘텐츠, 서비스 등을 제공하는 컴퓨터 장치 또는 복수의 컴퓨터 장치들로 구현될 수 있다. 예를 들어, 서버는 네트워크를 통해 접속한 복수의 전자 기기들(110, 120, 130, 140)로 제1 서비스를 제공 하는 시스템일 수 있으며, 서버 역시 네트워크를 통해 접속한 복수의 전자 기기들(110, 120, 130, 140)로 제2 서비스를 제공하는 시스템일 수 있다. 보다 구체적인 예로, 서버는 복수의 전자 기기들(110, 120, 130, 140)에 설치되어 구동되는 컴퓨터 프로그램으로서의 어플리케이션을 통해, 해당 어플리케이션이 목적 하는 서비스(일례로, 검색 서비스 등)를 제1 서비스로서 복수의 전자 기기들(110, 120, 130, 140)로 제공할 수 있다. 다른 예로, 서버는 상술한 어플리케이션의 설치 및 구동을 위한 파일을 복수의 전자 기기들(110, 120, 130, 140)로 배포하는 서비스를 제2 서비스로서 제공할 수 있다. 도 2는 본 발명의 일실시예에 따른 컴퓨터 장치의 예를 도시한 블록도이다. 앞서 설명한 복수의 전자 기기들 (110, 120, 130, 140) 각각이나 서버들(150, 160) 각각은 도 2를 통해 도시된 컴퓨터 장치에 의해 구현될 수 있다.이러한 컴퓨터 장치는 도 2에 도시된 바와 같이, 메모리, 프로세서, 통신 인터페이스 그리 고 입출력 인터페이스를 포함할 수 있다. 메모리는 컴퓨터에서 판독 가능한 기록매체로서, RAM(random access memory), ROM(read only memory) 및 디스크 드라이브와 같은 비소멸성 대용량 기록장치 (permanent mass storage device)를 포함할 수 있다. 여기서 ROM과 디스크 드라이브와 같은 비소멸성 대용량 기록장치는 메모리와는 구분되는 별도의 영구 저장 장치로서 컴퓨터 장치에 포함될 수도 있다. 또한, 메모리에는 운영체제와 적어도 하나의 프로그램 코드가 저장될 수 있다. 이러한 소프트웨어 구성요 소들은 메모리와는 별도의 컴퓨터에서 판독 가능한 기록매체로부터 메모리로 로딩될 수 있다. 이러 한 별도의 컴퓨터에서 판독 가능한 기록매체는 플로피 드라이브, 디스크, 테이프, DVD/CD-ROM 드라이브, 메모리 카드 등의 컴퓨터에서 판독 가능한 기록매체를 포함할 수 있다. 다른 실시예에서 소프트웨어 구성요소들은 컴 퓨터에서 판독 가능한 기록매체가 아닌 통신 인터페이스를 통해 메모리에 로딩될 수도 있다. 예를 들어, 소프트웨어 구성요소들은 네트워크를 통해 수신되는 파일들에 의해 설치되는 컴퓨터 프로그램에 기 반하여 컴퓨터 장치의 메모리에 로딩될 수 있다. 프로세서는 기본적인 산술, 로직 및 입출력 연산을 수행함으로써, 컴퓨터 프로그램의 명령을 처리하도록 구성될 수 있다. 명령은 메모리 또는 통신 인터페이스에 의해 프로세서로 제공될 수 있다. 예 를 들어 프로세서는 메모리와 같은 기록 장치에 저장된 프로그램 코드에 따라 수신되는 명령을 실행 하도록 구성될 수 있다. 통신 인터페이스는 네트워크를 통해 컴퓨터 장치가 다른 장치(일례로, 앞서 설명한 저장 장치들)와 서로 통신하기 위한 기능을 제공할 수 있다. 일례로, 컴퓨터 장치의 프로세서가 메모리 와 같은 기록 장치에 저장된 프로그램 코드에 따라 생성한 요청이나 명령, 데이터, 파일 등이 통신 인터페 이스의 제어에 따라 네트워크를 통해 다른 장치들로 전달될 수 있다. 역으로, 다른 장치로부터의 신 호나 명령, 데이터, 파일 등이 네트워크를 거쳐 컴퓨터 장치의 통신 인터페이스를 통해 컴퓨터 장치로 수신될 수 있다. 통신 인터페이스를 통해 수신된 신호나 명령, 데이터 등은 프로세서나 메모리로 전달될 수 있고, 파일 등은 컴퓨터 장치가 더 포함할 수 있는 저장 매체(상술한 영구 저장 장치)로 저장될 수 있다. 입출력 인터페이스는 입출력 장치와의 인터페이스를 위한 수단일 수 있다. 예를 들어, 입력 장치는 마이크, 키보드 또는 마우스 등의 장치를, 그리고 출력 장치는 디스플레이, 스피커와 같은 장치를 포함할 수 있 다. 다른 예로 입출력 인터페이스는 터치스크린과 같이 입력과 출력을 위한 기능이 하나로 통합된 장치와 의 인터페이스를 위한 수단일 수도 있다. 입출력 장치는 컴퓨터 장치와 하나의 장치로 구성될 수도 있다. 또한, 다른 실시예들에서 컴퓨터 장치는 도 2의 구성요소들보다 더 적은 혹은 더 많은 구성요소들을 포함 할 수도 있다. 그러나, 대부분의 종래기술적 구성요소들을 명확하게 도시할 필요성은 없다. 예를 들어, 컴퓨 터 장치는 상술한 입출력 장치 중 적어도 일부를 포함하도록 구현되거나 또는 트랜시버 (transceiver), 데이터베이스 등과 같은 다른 구성요소들을 더 포함할 수도 있다. 단말 환경에서 동작하는 인공지능(Artificial Intelligence, AI) 모델의 경우 사용자의 데이터에 직접 액세스할 수 있기 때문에 별도의 안전한 데이터 접근 및 활용 관리 모델이 제시되어야 한다. 일례로, 사용자가 안전하게 사용할 수 있는 AI 모델들을 공급하는 별도의 AI 모델 스토어가 요구될 수 있다. 이러한 AI 모델 스토어는 개 별 AI 모델에 대한 안정성 및/또는 기능 등을 평가 및 관리할 수 있어야 한다. 사용자는 안정성이 검증된 AI 모델을 자신의 선택에 따라 단말에 설치 및 사용자가 원하는 정보에 대한 접근 권한을 부여할 수 있다. 도 3은 본 발명의 일실시예에 따른 AI 모델 관리 시스템의 개략적인 모습의 예를 도시한 도면이다. 도 3의 실 시예에 따른 AI 모델 관리 시스템은 사용자 단말, AI 모델 스토어, AI 모델 등록 서비스 서버 및 AI 모델 서비스 공급자를 나타내고 있다. 본 실시예에서 사용자 단말에 공급하고자 하는 AI 모델에 대해서, AI 모델 스토어는 AI 모델 서비스 공급자가 제공하는 AI 모델에 대한 사전 검증 절차를 거쳐 AI 모델을 등록할 수 있으며, 사용자 단말의 요청에 따라 AI 모델을 사용자 단말에 배포 할 수 있다. 이러한 AI 모델 스토어는 사전에 등록될 AI 모델을 검증 및 심사하는 기능, AI 모델의 외부 데이터 연동 정보를 관리하는 기능, AI 모델의 버전 및 무결성 관리하는 기능 등을 제공할 수 있다. 이때, AI 모델 등록 서비스 서버는 사용자 단말에서 운영 가능한 AI 모델 관련 정보를 별도로 관리할 수 있다. 사용자 단말, AI 모델 스토어, AI 모델 등록 서비스 서버 및 AI 모델 서비스 공급자 각각 은 앞서 설명한 컴퓨터 장치를 통해 구현될 수 있으며, 네트워크를 통해 서로 통신할 수 있다. 또한, 도 3의 실시예에서는 하나의 사용자 단말과 하나의 AI 모델 서비스 공급자를 나타내고 있으나, 복수의 사용자 단말들과 복수의 AI 모델 서비스 공급자들이 존재할 수 있음을 쉽게 이해할 수 있을 것이다. 도 4는 본 발명의 일실시예에 따른 AI 모델 관리 과정의 예를 도시한 도면이다. 사용자는 사용자 단말 을 이용하여 AI 모델 스토어에 접근하여 사용자가 원하는 AI 모델을 선택할 수 있으며, 사용자 단말은 AI 모델 스토어로부터 사용자에 의해 선택된 AI 모델을 다운로드받아 AI 모델을 사용자 단말에 설치(또는 로딩)할 수 있으며, 설치된 AI 모델을 실행시킬 수 있다. 한편, 기존의 서비스 사업자, 플랫폼 공급사 및/또는 AI 전문 기업들은 각각이 가진 개별 기능 및 서비스에 특 화된 AI 모델을 개발하고, 이를 사용자 단말에 탑재하고자 할 수 있으며, AI 모델을 사용자 단말에 설치 함으로써 자신의 플랫폼, 서비스 및/또는 어플리케이션의 사용을 극대화 하고자 할 수 있다. 이러한 서비 스 사업자, 플랫폼 공급사 및/또는 AI 전문 기업들 각각은 AI 모델 서비스 공급자로서 동작할 수 있으며, 자신의 AI 모델을 AI 모델 스토어에 등록할 수 있다. 또한, AI 모델 서비스 공급자는 AI 모델 스토어를 통해 AI 모델을 설치한 사용자 단말로 해당 AI 모델이 특화된 서비스를 제공할 수 있다. 일례로, 사용자의 사용자 질의에 따라 사용자 단말은 개별 AI 모델을 호출하고, 호출된 AI 모델과 연계하여 AI 모델 서비스 공급자가 제공하는 서비스를 제공받 을 수 있다. 이러한, AI 모델은 사용자의 권한 설정에 따라 각기 동작을 달리할 수 있으며 사용자가 직접 실행하지 않 고도 특정 상황에서 트리거링될 수 있고, 설정된 권한의 특성에 따라 직접 외부 서비스와의 연동(메시징, 이-커 머스 등을 위한 연동)을 진행할 수 있다. 또한, AI 모델은 기존의 디바이스 공급자(사용자 단말의 공급자)가 신뢰하는 음성 인식 서비스 형태의 AI 서비스와 연계해 사용자의 입력을 해당 AI 서비스를 이용 하여 처리하는 형태로 동작할 수 있다. 사용자 단말은 사용자 단말에 탑재된 센서, 어플리케이션, 및/또는 데이터를 이용하여 AI 모델을 동 작시킬 수 있다. 일례로, 사용자 단말은 사용자 단말에서 수집 가능한 센싱 정보, 사용자 단말(31 0)에서 구동된 어플리케이션을 통해 입출력 및 생성되는 데이터, 및/또는 사용자 단말의 제작사 및/또는 공급사에 저장된 데이터를 이용하여 AI 모델을 동작시킬 수 있다. AI 모델이 이용 가능한 데이터에는 사용자의 개인 정보가 포함될 수 있다. 일례로, 사용자의 개인 정보는 사용자의 신상과 관련된 정보뿐만 아니라, HCI(Human Computer Interaction)에 대한 정보 또는 HCI에 의해 생성되는 정보, 사용자의 음성, 동작, 이동, 위치, 기타 센싱 데이터 등 다양한 정보가 포함될 수 있다. AI 모델 스토어는 다수의 공급자들(AI 모델 서비스 공급자)에 의해 제공되는 AI에 대한 검증 및 관리 를 처리할 수 있다. 도 5는 본 발명의 일실시예에 있어서, 단말 환경에서 동작하는 AI 모델 공급 및 설치를 위한 구조의 예를 도시 한 도면이다. 도 5에서는 사용자 단말, AI 모델 스토어, 및 AI 모델 등록 서비스 서버를 나타 내고 있다. 사용자 단말은 사용자의 선호에 따라 AI 모델을 로컬에서 구동할 수 있다. 이러한 사용자 단말(31 0)은 기존의 단말 컴퓨팅 자원과 분리된 형태의 안전한 AI 모델 구동을 지원할 수 있으며, 사용자의 선택 에 기반해 AI 모델을 설치 및 운용할 수 있다. 사용자 단말은 사용자의 선택에 대한 정보를 관리할 수 있으며, 사용자 단말에 설치된 AI 모델의 버전 및 무결성을 관리할 수 있다. 또한, 사용자 단말 은 AI 모델의 이용 정보(일례로, AI 모델 호출에 대한 정보)를 관리할 수 있다. AI 모델 스토어는 AI 모델 서비스 공급자와 사용자를 연결해주는 서비스를 제공할 수 있다. 사 용자들은 AI 모델 사용 시의 안정성을 담보하기 위해 AI 모델 서비스 공급자에 의해 인증된 AI 모델 스토 어를 이용하여 AI 모델을 제공받을 수 있다. 또한, AI 모델 서비스 공급자는 다수의 사용자들에게 단일화된 접근을 위하여 AI 모델 스토어를 이용할 수 있다. 이러한 AI 모델 스토어는 AI 모델 서비 스 공급자에 의해 등록되는 AI 모델을 검증할 수 있으며, 등록된 AI 모델의 버전과 무결성을 관리할 수 있 다. 또한, AI 모델 스토어는 사용자 단말로 AI 모델을 추천하기 위한 기능 및/또는 서비스를 제공할 수 있다.AI 모델 등록 서비스 서버는 사용자 단말에서 운영 가능한 AI 모델 관련 정보를 별도로 관리할 수 있 다. 이러한 정보는 AI 모델의 버전, AI 모델의 단말 장치 연동 범위(일례로, 연동 가능한 각종 센서류에 대한 정보), AI 모델의 외부 서비스 연동 범위(가능한 API 호출에 대한 정보), AI 모델의 이용 가능한 메모리 또는 저장공간의 크기, 및/또는 AI 모델의 업데이트 주기 등에 대한 정보를 포함할 수 있다. 또한, AI 모델 등록 서 비스 서버는 사용자 단말에 대한 정보를 관리할 수 있으며, 사용자 단말상에 설치된 AI 모델에 대한 정보를 관리할 수 있고, 단말별로 AI 모델의 운영에 대한 정보를 관리할 수 있다. 도 6은 본 발명의 일실시예에 있어서, AI 모델 등록 서비스 서버의 내부 구성의 예를 도시한 도면이다. 본 실 시예에 따른 AI 모델 등록 서비스 서버는 사용자 단말 정보 관리부, 설치 모델 버전 관리부, 및 모델 운영 관리부를 포함할 수 있다. AI 모델 등록 서비스 서버는 AI 모델 등록 서비스 서버와 연동된 AI 모델 스토어와 사용자 단말 의 환경에 설치된 AI 모델의 정보를 관리하기 위한 기능을 제공할 수 있다. 또한, AI 모델 등록 서비스 서버는 사용자의 인증된 사용자 단말에 대한 정보로서 AI 모델 스토어의 인증된 AI 모델에 대한 다운로드 및 업데이트 등의 기능을 관리할 수 있다. 사용자 단말 정보 관리부는 사용자 단말의 AI 모델의 운영과 관련된 장치 정보를 관리할 수 있다. 일례로, 사용자 단말 정보 관리부는 사용자 단말 상의 운영체제의 버전, AI 모델과 관련된 보안 프레 임워크(security framework)의 정보, 사용자 단말의 하드웨어 정보 등을 장치 정보로서 저장 및 관리할 수 있으며, 이를 기반으로 향후 사용자가 특정 AI 모델의 설치를 요청하는 경우 해당 AI 모델의 사용자 단말 에서의 설치 가능 여부를 결정할 수 있다. 여기서, 보안 프레임워크는 사용자 단말에 설치되어 해당 AI 모델을 호출하는 어플리케이션의 보안 프레임워크를 포함할 수 있다. 이때, 사용자의 특정 AI 모델의 설치에 대한 요청은 사용자 단말을 통해 AI 모델 스토어로 전달될 수 있으며, AI 모델 스토어와 연동된 AI 모델 등록 서비스 서버가 이러한 설치 요청을 전달받아 해당 AI 모델의 사용자 단말에서의 설치 가능 여부를 저장된 정보에 기반하여 결정할 수 있다. 이후, AI 모델 등록 서비스 서버는 설치 가능 여부에 대한 정보를 사용자 단말 및/또는 AI 모델 스토어로 전달할 수 있다. 또한, 사용자 단말 정 보 관리부는 AI 모델의 장치 연동 범위에 대한 정보(일례로, 각종 센서 중 연동 가능한 센서에 대한 정 보)를 저장 및 관리할 수 있다. 일례로, 사용자 단말 정보 관리부는 사용자 단말의 하드웨어 정보를 이용하여 특정 AI 모델이 사용자 단말에서 액세스할 수 있는 기능 범위에 대해 정의하고 제어할 수 있다. 만약 특정 AI 모델이 N개의 기능을 가지고 있고, 사용자 단말이 N-1개의 기능을 가지는 경우, AI 모델 등 록 서비스 서버는 사용자 단말 정보 관리부에서 관리되는 정보를 통해 사용자 단말에서 수행할 수 없는 기능을 제외한 다른 AI 모델을 선택하여 다운로드하도록 사용자 단말로 서비스를 제공함으로써, 사용자 단말에서의 모델의 운영 공간을 감소시킬 수 있다. 이를 위해, 사용자 단말 정보 관리부는 AI 모델의 이용 가능한 메모리 및/또는 저장공간의 크기, 사용자 단말의 하드웨어 정보 및/또는 AI 모델의 업데이트 주기 등에 대한 정보를 더 저장하여 관리할 수 있다. 한편, 사용자 단말 정보 관리부는 AI 모델 스토어 측의 AI 모델에 대한 업데이트 요청이 있는 경우, 이를 사용자 단말에 대한 정보와 매칭해 업 데이트 스케쥴을 관리할 수도 있다. 설치 모델 버전 관리부는 AI 모델 등록 서비스 서버 측에서 사용자 단말 상에 설치된 AI 모델의 버전을 관리하는 기능을 제공할 수 있다. 여기서, AI 모델의 버전을 관리하는 것은 사용자 단말 상에 설 치된 AI 모델들 각각의 버전을 저장하고 업데이트하는 것을 의미할 수 있다. 일례로, 설치 모델 버전 관리부 는 AI 모델 등록 서비스 서버 측에서 사용자 단말 상에 설치된 AI 모델들 각각의 버전 정보를 이용하여, 특정 AI 모델의 업데이트가 이루어지는 경우, 사용자에게 AI 모델의 업데이트 등에 대한 알림을 제공할 수 있다. 사용자 단말 상에 설치된 AI 모델의 경우 단일 AI 모델의 형태로 동작하거나 별도의 추 가 학습된 레이어를 사용하는 방식(일례로, 로라(Low-Rank Adaption, LoRA), PEFT(Parameter Efficient Fine- Tuning) 또는 파인-튜닝(Fine-Turning(제로-샷(zero-shot), 원-샷(one-shot), 퓨-샷(few-shot)) 등)으로 제공 될 수 있어, 그 특징에 맞춰 AI 모델의 업데이트가 이루어질 수 있어야 한다. 따라서 사용자 단말 및 AI 모델 스토어의 공급자 측면에서 AI 모델의 설치 정보를 관리하는 기능의 경우, 설치 모델 버전 관리부 는 AI 모델의 기본 메타 정보 이외에 사용자 단말 상에서 추가 학습된(사용자 단말 또는 특정 서비스와 연계하여 추가 학습된) 정보에 대한 내용을 별도로 관리할 수 있어야 한다. 이때, 사용자가 해 당 정보를 관리 주체와 공유하고자 하는 경우에만, 설치 모델 버전 관리부가 해당 정보를 관리할 수 있다. 모델 운영 관리부는 사용자 단말에서 설치 및 동작되는 AI 모델의 운영 관련 정보를 관리할 수 있다. 이러한 운영 관련 정보는, 사용자 단말에 설치 및 동작되는 AI 모델이 사용자 단말의 외부 서비스와통신하였는지 여부에 대한 정보, 사용자 단말에서의 AI 모델의 자체 업데이트 여부 등에 대한 정보를 포함 할 수 있다. 모델 운영 관리부는 추가적으로 사용자 단말의 운영체제 버전 및 특징에 따라 AI 모델 과의 호환성 등을 관리하기 위한 기능을 제공할 수 있다. 도 7은 본 발명의 일실시예에 있어서, AI 모델 스토어의 내부 구성의 예를 도시한 도면이다. 본 실시예에 따른 AI 모델 스토어는 모델 검증부, 모델 버전 관리부, 및 모델 추천부를 포함할 수 있다. 모델 검증부는 AI 모델 스토어와 사용자 단말의 환경에 설치된 AI 모델의 정보를 관리하기 위한 기능을 제공할 수 있다. 사용자의 인증된 단말 정보와 AI 모델 스토어에서 인증된 AI 모델에 대한 다운로드 및 업데이트 등의 기능을 관리할 수 있다. 모델 버전 관리부는 사용자 단말에서의 AI 모델의 운영과 관련된 정보를 관리할 수 있다. 일례로, 모델 버전 관리부는 사용자 단말 상의 운영체제의 버전, AI 모델과 관련 보안 프레임워크의 정보 등 을 관리할 수 있으며, 이를 기반으로 향후 사용자가 특정 AI 모델의 설치를 요청하는 경우 해당 AI 모델의 사용자 단말에서의 설치 가능 여부를 판단할 수 있다. 또한, 모델 버전 관리부는 AI 모델의 장치 연 동 범위에 대한 정보(일례로, 각종 센서 중 연동 가능한 센서에 대한 정보)를 관리할 수 있다. 일례로, 모델 버전 관리부는 사용자 단말의 하드웨어 정보를 이용하여 특정 AI 모델이 사용자 단말에서 액세 스할 수 있는 기능 범위에 대해 정의하고 제어할 수 있다. 만약 특정 AI 모델이 N개의 기능을 가지고 있고, 사 용자 단말이 N-1개의 기능을 가지는 경우, 모델 버전 관리부는 사용자 단말에서 수행할 수 없는 기능을 제외한 다른 AI 모델을 선택하여 다운로드하도록 사용자 단말로 서비스를 제공함으로써, 사용자 단 말에서의 모델의 운영 공간을 감소시킬 수 있다. 이를 위해, 사용자 단말 정보 관리부는 AI 모델의 이용 가능한 메모리 및/또는 저장공간의 크기, 사용자 단말의 하드웨어 정보 및/또는 AI 모델의 업데이트 주기 등에 대한 정보를 저장하여 관리할 수 있다. 한편, 모델 버전 관리부는 AI 모델 스토어 측의 AI 모델에 대한 업데이트 요청이 있는 경우, 이를 사용자 단말에 대한 정보와 매칭해 업데이트 스케쥴을 관리할 수도 있다. 이러한 모델 버전 관리부는 앞서 설명한 AI 모델 등록 서비스 서버의 사용자 단말 정보 관리부 와 유사한 기능을 제공하기 때문에 실시예에 따라 생략될 수도 있다. 일례로, AI 모델 스토어는 AI 모델 등록 서비스 서버와 연동하여 사용자 단말 정보 관리부를 통해 모델 버전 관리부의 기능을 제공 할 수 있다. 모델 추천부는 사용자 단말로 AI 모델을 추천하기 위한 기능을 제공할 수 있다. 일례로, 모델 추천 부는 AI 모델 서비스 공급자에 의해 등록한 다수의 AI 모델들을 분류하고, 기능별로 정렬하여 사용자 맞춤형으로 AI 모델을 추천하는 기능을 제공할 수 있다. 이를 통해 사용자에게 다수의 AI 모델들을 노출 하여 설치하는 유도 형태뿐 아니라, 특정 AI 모델이 연결 가능한 AI 모델의 정보(AI 모델들간의 연동을 통한 서 비스 향상 측면)를 바탕으로 상호 활용 가능한 AI 모델의 정보에 기반하여 AI 모델을 추천할 수 있게 된다. 이 러한 AI 모델들간의 상호 호출 정보는 AI 모델의 검증(또는 심사) 시에 AI 모델 서비스 공급자에서 제공하 는 AI 모델의 외부 호출 정보 등을 기반으로 생성될 수 있다. 또는 직접 AI 모델 서비스 공급자가 연동 가능한 외부 모델 정보를 별도로 제공할 수 있으며, 모델 추천부는 AI 모델 서비스 공급자가 제공하 는 정보를 이용하여 상호 호출 정보를 생성할 수 있다. 일례로, 검색을 위한 제1 AI 모델이 이미지 검색을 통 해, 특정 정보를 획득하면 이 정보를 기반으로 이커머스 서비스를 위한 제2 AI 모델을 호출할 수 있으며, 이 경 우 모델 추천부는 제1 AI 모델을 사용하는 사용자 단말로 제2 AI 모델을 추천할 수 있다. 도 8은 본 발명의 일실시예에 있어서, 사용자 단말의 내부 구성의 예를 도시한 도면이다. 본 실시예에 따른 사 용자 단말는 사용자 선택 정보 관리부, 설치 모델 버전 관리부, 및 모델 운영 관리부를 포 함할 수 있다. 일례로, 사용자 선택 정보 관리부, 설치 모델 버전 관리부, 및 모델 운영 관리부 는 AI 모델 관리 서비스와 관련하여, 사용자 단말에 설치 및 구동되는 어플리케이션의 소프트웨어 모 듈의 형태로 구현될 수 있다. 사용자 선택 정보 관리부는 사용자 단말에 설치된 AI 모델별로 사용자가 공유한 또는 접근 가능 한 정보를 관리하는 기능을 제공할 수 있다. 사용자 단말 자체의 플랫폼에서 AI 에이전트(일례로, 시리 (siri), 헤이 구글(hey google) 등)와 연동하여 사용자 단말의 운영체제의 음성인식 처리 기능 등과 같은 다양한 기능을 수행하는 기능이 설정될 수 있다. 또한, 사용자 선택 정보 관리부는 사용자 단말 자 체에서 생성 및 관리되는 정보로의 접근을 위한 액세스 허용 여부(일례로, 사용자 단말에 설치된 앱이나 다른 컴퓨터 프로그램으로의 액세스 허용 여부) 등을 관리할 수 있다.설치 모델 버전 관리부는 사용자 단말 상에 설치된 AI 모델의 버전을 관리하는 기능을 제공할 수 있 다. 설치 모델 버전 관리부는 사용자 단말 상에 설치된 AI 모델 들의 버전 정보를 주기적으로 서버 측(AI 모델 스토어 및/또는 AI 모델 등록 서비스 서버)과 확인하여 특정 AI 모델의 업데이트 여부를 확인할 수 있다. 또한, 설치 모델 버전 관리부는 특정 AI 모델의 업데이트가 이루어진 경우, 사용자(41 0)에게 해당 AI 모델의 업데이트에 대한 알림을 제공할 수 있다. 사용자 단말 상에 설치된 AI 모델의 경 우 단일 모델 형태로 동작하거나 별도의 추가 학습된 레이어를 사용하는 방식(일례로, 로라, PEFT 또는 파인튜 닝 등)으로 제공될 수 있어, 그 특징에 맞춰 AI 모델에 대한 업데이트가 이루어질 수 있어야 한다. 따라서 사 용자 단말 및 AI 모델 스토어의 공급자 측면에서 AI 모델의 설치 정보를 관리하는 기능의 경우, 설치 모델 버전 관리부는 AI 모델의 기본 메타 정보 이외에 사용자 단말 상에서 추가 학습된(사용자 단말 또는 특정 서비스와 연계하여 추가 학습된) 정보에 대한 내용을 별도로 관리할 수 있어야 한다. 이때, 사용자가 해당 정보를 관리 주체와 공유하고자 하는 경우에만, 설치 모델 버전 관리부가 해당 정보를 관리할 수 있다. 이러한 설치 모델 버전 관리부는 앞서 설명한 AI 모델 등록 서비스 서버의 설치 모 델 버전 관리부와 연동하여 AI 모델의 버전을 관리할 수도 있다. 모델 운영 관리부는 사용자 단말에 설치된 AI 모델의 운영 형태를 관리하는 기능을 제공할 수 있다. 모델 운영 관리부는 AI 모델의 자체적인 동작 및/또는 AI 모델의 외부 서비스와의 연계 동작 등과 같은 AI 모델의 동작을 관리할 수 있다. 추가적으로 모델 운영 관리부는 데이터 학습을 통한 모델 크기의 변경 및 변경된 파라미터 정보들을 관리할 수 있다. 또한, 모델 운영 관리부는 사용자 단말에서 AI 모델이 동작하는 경우에 해당 AI 모델의 성능 정보를 수집 및 관리할 수 있다. 일례로, 모델 운영 관리부는 AI 모델의 동작에 따른 응답시간 지연, AI 모델의 사용자 단말의 자원 사용량 등을 파악해 서버 측(AI 모델 스토어 및/또는 AI 모델 등록 서비스 서버)으로 제공할 수 있다. 또한, 모델 운영 관리부는 특 정 AI 모델의 과다 자원 사용 또는 지연 등의 이슈를 사용자 또는 서버 측으로 리포팅함으로써 최적의 모 델 사용 환경 등을 제시할 수 있다. 일례로, 모델 운영 관리부는 AI 모델의 동작 시 기존 동작 정보의 특 성을 파악하여 메모리 요구사항 등을 동적으로 설정함으로써 사용자의 AI 모델 이용 시의 응답성을 향상시 킬 수 있다. 도 9는 본 발명의 일실시예에 있어서, AI 모델 운영을 위한 사용자 단말의 하드웨어 구조의 예를 도시한 도면이 다. 본 실시예에 따른 사용자 단말은 NAND(Not AND) 스토리지, DRAM(Dynamic Random Access Memory, 920), 컨트롤러(controllers, 930), 어플리케이션 프로세서(application processor, 940), 보안 입출 력(secured input/output, 950), 암호화 프로세서(cryptographic processor, 960), 및 보안 메모리(secured memory, 970)를 포함할 수 있다. NAND 스토리지와 DRAM는 사용자 단말에 포함되어 연결 가능한 저장소일 수 있다. 컨트롤러(controllers, 930)는 사용자 단말의 저장소(NAND 스토리지와 DRAM) 및 외부 인터페이 스 등을 연결하는 버스 컨트롤러(bus controller)를 포함할 수 있다. 어플리케이션 프로세서는 사용자 단말의 명령어를 처리하는 구성요소일 수 있다. 보안 입출력은 사용자 단말 상에서 생성되는 주요 인증 정보 및 개인 정보, 그리고 AI 모델에 대한 정보들을 안전하게 관리하기 위해 암호화 프로세서 및 보안 메모리 등과의 통신 시에 암호화된 채널 을 제공할 수 있다. 이때 보안 입출력이 제공하는 암호화된 채널로의 연결이 가능한 모듈로는 암호화 프 로세서, 코프로세서(coprocessor), HMAC(Hash-based Message Authentication Code) 엔진, SHA(Secure Hash Algorithm) 엔진, 키 생성 모듈, 난수 생성 모듈, 실행 엔진, 휘발성 메모리 및/또는 비휘발성 메모리 등 이 포함될 수 있다. AI 모델에서 처리하기 위한 데이터 또는 처리된 데이터(일례로, 임베딩된 벡터 데이터) 등 이 해당 보안 입출력을 통해 안전하게 관리될 수 있다. 암호화 프로세서는 암호화 관련된 기능을 제공하는 하드웨어 또는 펌웨어로서, 사용자 단말의 공급자 에 의해 제공될 수 있으며, 하드웨어 수준에서의 안전성을 제공할 수 있다. 이러한 암호화 프로세서는 자 격 증명 키 관리(Credential Key Management)를 위한 기능과 연결되어 디바이스 키, 그룹 키, 자격 증명 정보 등을 별도로 관리하는 기능을 제공할 수 있다. 보안 메모리는 AI 모델 스토리지 및 AI 데이터 스토리지를 포함할 수 있다. AI 모델 스토리지는 AI 모델 자체, 그리고 AI 모델과 관련된 메타데이터를 저장하기 위한 모델 스토리지를 포함할 수 있다. 이러한 모델 스토리지는 가중치가 변경된 하이퍼파라미터 등을 별도로 저장 및 관리할 수 있다. 또한, AI 모델 스토리지는 AI 모델의 동작 및 사용 이력을 저장하기 위한 모델 로그 스토리지를 포함 할 수 있다. 이러한 AI 모델 스토리지에 저장된 데이터는 향후 AI 모델의 오작동 및 이상 여부를 검증할 수 있는 기능을 제공하기 위해 사용될 수 있다. AI 데이터 스토리지는 사용자 데이터 중 AI 모델을 통해 수집 및 생성되는 데이터를 저장할 수 있다. 특"}
{"patent_id": "10-2024-0078218", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "정 AI 모델의 사용을 통해 자동 응답 또는 데이터의 요약 등과 같이 새로운 데이터가 생성된 경우 해당 데이터 는 AI 모델의 향후 성능 향상 및 사용자 경험의 통일성 제공을 위해 재활용될 수 있다. 이러한 AI 모델의 실행 결과로 생성된 데이터는 AI 데이터 스토리지를 통해 별도 저장될 수 있으며, 생성형 AI 모델에 의해 접근 될 수 있다. AI 데이터 스토리지에 저장된 데이터는 사용자의 선택에 의해 접근 가능하며, AI 모델 의 공급자(AI 모델 서비스 공급자)라 하더라도 외부에서 해당 데이터를 직접 액세스 할 수 없도록 AI 데이 터 스토리지가 구현될 수 있다. 또한, AI 데이터 스토리지는 임베딩된 벡터를 저장할 수 있는 벡터 저장 기능을 포함할 수 있으며, AI 모델의 동작에 필요한 정보를 벡터 형태로 저장 및 제공할 수 있는 기능을 포함할 수 있다. 도 10는 본 발명의 일실시예에 있어서, AI 모델 운영을 위한 사용자 단말의 소프트웨어 구조의 예를 도시한 도 면이다. 본 실시예에 따른 사용자 단말은 어플리케이션, 운영체제, 보안 입출력, 암호 화 엔진, 및 보안 메모리를 포함할 수 있다. 어플리케이션은 사용자 단말에 인증되어 설치 및 구동된 어플리케이션들을 의미할 수 있다. 이러한 어플리케이션은 보안 프레임워크를 이용하여 AI 모델들과 통신할 수 있다. 일례로, AI 에이전트 어플리케이션 및 이와 연결 가능한 어플리케이션들 각각은 별도의 보안 프레임워크를 활용하여 AI 에이전 트와 상호작용할 수 있다. 다시 말해, 기존 어플리케이션들과는 달리 AI 에이전트는 자체-트리거링(self triggering) 형태로 동작이 가능함으로 이를 제어할 수 있도록 어플리케이션은 별도의 보안 프레임워크 의 제약을 가질 수 있다 또한, 어플리케이션은 API 컨트롤러를 포함할 수 있다. 온-디바이스 AI 모델의 동작에 있어, 사용 자 단말에 설치된 어플리케이션과 AI 에이전트간 상호 커뮤니케이션을 진행하는 경우, AI 에이전트 는 개별 어플리케이션을 연결할 수 있는 API 기능을 제공할 수 있다. 해당 API는 AI 에이전트에 의해 호 출 및 응답됨으로 그 개별 동작에 대한 사용자의 인지, 허가, 그리고 안정성 여부를 사전 및 사후적으로 판단할 수 있어야 한다. 어플리케이션은 API 컨트롤러를 통해, AI 에이전트가 활용 가능한 API 정 보들을 관리하고 제어하는 기능을 제공할 수 있다. 운영체제는 사용자 단말의 사용자 인증, 어플리케이션 인증 등을 자체적으로 처리할 수 있는 로컬 인증 기능을 제공할 수 있다. 또한 AI 모델의 동작을 위한 AI 모델 동작 환경(AI Model Running Environment, 1021)을 기존의 기능들과의 안정성 및 독립된 성능 등을 제공하기 위해 샌드박스(sandbox, 1022) 구조로 제공할 수 있다. AI 모델 동작 환경은 AI 모델이 안전하게 동작 가능한 별도의 관리 환경으로서, 사용자 단말의 자원 상황에 따라 로딩하고자 하는 AI 모델들의 우선순위 관리, 동작시간, 응답 대기 시간 등을 관리하기 위해 사용될 수 있다. 또한, 운영체제는 AI 모델 동작 환경을 통해 해당 AI 모델이 사용하는 별도의 AI 모델 스토리지 및 AI 데이터 스토리지 등으로의 접근 관리 및 용량 관리 등의 기능을 더 제공할 수 있다. 보안 입출력은 앞서 설명한 도 9의 보안 입출력에 대응할 수 있으며, 암호화된 채널을 제공할 수 있 다. 암호화 엔진은 사용자 단말 내부의 암호화 관련 처리를 위해 별도의 하드웨어 프로세서를 이용하거 나 또는 소프트웨어적으로 구현된 엔진일 수 있다. 강건한 보안 제공을 위해 사용자 단말 자체에서 암호 화 엔진을 통해 하드웨어 기반의 암호화 처리 기능을 제공할 수 있다. AES (Advanced Encryption Standard) 엔진 등의 다양한 암호화 모듈을 자체적으로 탑재해, 암호화 처리를 제공 및 가속할 수 있다. 보안 메모리는 앞서 설명한 도 9의 보안 메모리에 대응할 수 있다. 보안 메모리는 기존의 일 반 NAND 플래시, DRAM 등의 스토리지(일례로, 도 9의 NAND 스토리지와 DRAM)와는 달리 AI 모델의 동 작과 관련된 주요 및/또는 민감 정보들이 저장 및 관리되는 공간을 의미할 수 있다. 이러한 보안 메모리(105 0)는 별도의 물리적인 구조를 가지거나, 논리적으로 분할될 수 있다. 다만 이러한 보안 메모리의 사용을 위해 보안 입출력에서 제공되는 암호화된 채널이 사용될 수 있다. AI 모델의 특성상 대규모 행렬 연산 등이 이루어져 함으로 보안 메모리는 메모리와 같이 고속의 버스 인터페이스를 지원할 수 있다. AI 모델스토리지의 경우 파일 스토리지 형태의 구성을 가질 수 있으며, AI 데이터 스토리지의 경우 AI 모 델의 동작 과정에서 입출력으로 생성된 데이터들을 임시 저장하는 공간의 역할을 수행할 수 있으며, 벡터 데이 터베이스를 자체적으로 포함할 수 있다. 도 11은 본 발명의 일실시예에 있어서, AI 모델을 다운로드 및 설치하는 과정의 예를 도시한 흐름도이다. 본 실시예에 따른 AI 모델의 다운로드 및 설치는 사용자 단말에 의해 수행될 수 있다. 단계에서 사용자 단말은 AI 모델을 선택할 수 있다. 사용자는 AI 모델 스토어 또는 사용 자가 사용하고 있는 서비스 앱 등을 통해서, 설치하고자 하는 AI 모델을 확인할 수 있다. 일례로, 사용자 단말은 AI 모델 스토어에 등록된 복수의 인공지능 모델들 중에서 특정 인공지능 모델을 선택할 수 있 다. 이때, 선택된 인공지능 모델은 사용자에 의해 선택된 모델일 수 있다. 일례로, 사용자의 판단에 의 해 설치하고자 하는 AI 모델이 있는 경우, 사용자 단말은 사용자의 입력에 따라 해당 AI 모델을 선택 하고, AI 모델 스토어로 연결되어 AI 모델에 대한 상세 정보를 획득하여 사용자에게 제공할 수 있다. 단계에서 사용자 단말은 AI 모델의 특징 및 기능을 확인할 수 있다. 일례로, 사용자 단말은 단계에서 선택된 인공지능 모델의 특징 및 기능에 대한 정보를 AI 모델 스토어를 통해 획득하여 사 용자에게 제공할 수 있다. 이처럼, 사용자 단말은 AI 모델 스토어와 같이 사용자 단말의 운영체제 및 안전한 데이터 저장 공간, 모델 실행 공간 등을 관리하는 공급자의 서비스를 통해, 검증된 AI 모델 의 정보를 획득하여 사용자에게 제공할 수 있다. 이 경우 사용자는 모델의 크기 및 특성, 서비스 연 계형태 및 개인정보 접근 범위 등 모델 활용에 필요한 기본 정보를 확인할 수 있고, 이를 통해 얻을 수 있는 혜 택, 타 사용자의 후기, 모델 설치 및 활용에 따른 비용 등의 정보를 확인할 수 있다. 또한 사용자 단말은 사용자의 개인 정보 제공 시, 해당 AI 모델을 설치 후 받을 수 있는 예상 혜택에 대한 정보(일례로, 혜택 에 대한 추정치)를 AI 모델 스토어를 통해 획득하여 사용자에게 제공할 수 있다. 단 이를 위해서는 사용자 단말 상에서 해당 AI 모델의 공급자, 인증된 어플리케이션 또는 온라인 서비스와 연계해 사용자 정 보가 확인될 수 있어야 한다. 여기서, 혜택에 대한 정보는 단순한 비용 절감 형태뿐 아니라 사용자가 사"}
{"patent_id": "10-2024-0078218", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "용자 단말과의 인터렉션 횟수를 줄이거나(일례로, 요약 정보 제공, 자동 주문 등), 특정 서비스에 대한 대 응(일례로, 예약, 이벤트 등)을 효과적으로 진행하는 등의 다양한 사용자와 단말간의 인터렉션 케이스를 포함할 수 있다. 이후, 사용자는 설치하고자 하는 AI 모델의 정보를 확인 후 사용자 단말을 통해 해당 AI 모델의 설치 를 요청할 수 있다. 단계에서 사용자 단말은 AI 모델을 다운로드 및 검증할 수 있다. 사용자가 특정 AI 모델의 설 치를 요청한 경우, 사용자 단말은 AI 모델 스토어를 통해 사용자에 의해 요청된 AI 모델을 다운 로드하여 검증할 수 있다. 이때, 사용자 단말에서 충분한 모델 동작 환경(저장 공간 및 컴퓨팅 능력)이 제공되지 않는 경우, 해당 AI 모델의 다운로드가 이루어지지 않거나, 사용자 단말은 AI 모델 스토어 를 통해 사용자에게 보다 작은 크기 또는 보다 작은 컴퓨팅 능력을 요구하는 AI 모델을 추천할 수 있다. 또한 사용자 단말에 너무 많은 AI 모델이 다운로드 및 동작되는 경우, 사용자 단말은 사용자 단말 에 설치된 AI 모델들에 대한 정보를 사용자에게 제공할 수 있다. AI 모델의 다운로드 시 AI 모델이 보안 메모리(910 또는 1050)의 저장 공간으로 저장되는 과정에서 별도의 암호 화 기법이 활용될 수 있다. 일례로, 사용자 단말은 일회성 암호화 방식을 이용해 AI 모델의 일부 또는 전 체 값을 암호화 후 이를 복호화하는 형식의 적용을 통해 다운로드 과정에서의 AI 모델의 외부 오염에 따른 취약 성을 개선할 수 있다. 보다 구체적인 예로, 사용자 단말은 컴퓨터 장치에 의해 구현될 수 있으며, 컴퓨터 장치의 프로세서는 메모리가 포함하는 운영체제의 코드나 적어도 하나의 컴퓨터 프로그 램의 코드에 따른 제어 명령(instruction)을 실행하도록 구현될 수 있다. 여기서, 프로세서는 컴퓨터 장 치에 저장된 코드가 제공하는 제어 명령에 따라 컴퓨터 장치가 도 11의 방법이 포함하는 단계들(1110 내지 1170)을 수행하도록 컴퓨터 장치를 제어할 수 있다. 이때, 프로세서로서 암호화 기능을 제공하 는 하드웨어 또는 펌웨어로 구현된 암호화 프로세서가 더 포함될 수 있다. 이 경우, 컴퓨터 장치는 암호 화 프로세서와 컴퓨터 장치가 더 포함할 수 있는 보안 메모리간에 설정된 암호화된 채널을 통해 선택된 AI 모델의 적어도 일부를 암호화하여 보안 메모리의 저장 공간으로 전달할 수 있다. 보안 메모리는 앞서 설명한 보안 메모리(970 또는 1050)에 대응될 수 있다. 이러한 보안 메모리에 대해서는 앞서 자세히 설명한 바 있다. 단계에서 사용자 단말은 AI 모델의 데이터의 접근 범위를 설정할 수 있다. 일례로, 사용자 단말 은 사용자 단말에 설치된 AI 모델의 데이터에 대한 접근 범위를 사용자가 설정할 수 있는 기능 을 사용자에게 제공할 수 있다. 데이터 접근 범위를 설정받기 위한 기능은, 검증된 AI 모델이 접근 가능한 데이터의 형식, 사용자 단말에 설치된 외부 어플리케이션 중 검증된 AI 모델이 호출 가능한 어플리 케이션, 및/또는 사용자 단말에 저장된 데이터 중 검증된 AI 모델이 접근 가능한 데이터를 설정받기 위한 기능을 포함할 수 있다. 일례로, 사용자는 사용자 단말에서 제공하는 기능을 이용하여 자신의 모델 활용 형태에 따라 해당 AI 모델이 접근할 수 있는 기존 데이터의 접근(연결) 범위를 결정할 수 있다. 앞 서 설명한 바와 같이, 이러한 데이터의 접근 범위는 AI 모델이 접근 가능한 데이터의 형식(파일, 이미지, 비디 오 등)뿐 아니라, 기존에 설치된 외부 어플리케이션을 호출 가능한 범위 및/또는 기존 데이터에 접근 가능한 범 위를 포함할 수 있다. 단계에서 사용자 단말은 AI 모델의 실시간 입력 연동 범위를 설정할 수 있다. 이때, 사용자 단말 은 AI 모델의 동작 시 실시간으로 사용자 단말에 입력되는 사용자 명령어를 연동할 수 있는 범위를 설정할 수 있다. 일례로, AI 모델은 다음 1) 내지 3)과 같은 형태의 호출 단계를 가질 수 있다. 1) 사용자 단말이 제공하는 사용자 AI 인터페이스를 통해 AI 모델이 호출되는 경우 2) AI 모델이 직접 사용자의 명령어를 대기하는 경우(MIC(microphone), 프롬프트 등을 통해 사용자로 부터 사용자 단말로 입력되는 직접 명령을 처리하는 경우) 3) 사용자 단말 내에 설치된 다른 AI 모델 또는 어플리케이션을 통해 호출되는 경우 사용자 단말은 상술한 1) 내지 3) 각각의 형태를 활성화할 것인지 여부를 설정할 수 있는 기능을 사용자 에게 제공할 수 있다. AI 모델이 직접 사용자의 명령어를 대기하는 경우, 사용자 단말은 별도 의 AI 에이전트가 사용자 정보를 모니터링 하고 있음에 대한 알림을 별도의 수단(일례로, 인디케이터 라이트 (Indicator Light), 백그라운드 음성 안내, 앱 상단을 통한 알림 메시지 등)을 통해 사용자에게 제공할 수 있다. 단계에서 사용자 단말은 AI 모델의 외부 통신 범위를 설정할 수 있다. AI 모델이 외부 통신을 필요 로 하는지 여부는 AI 모델 스토어이 해당 AI 모델을 검증하는 과정에서 확인될 수 있다. 이 경우, 사용자 단말은 외부 통신을 필요로 하는 AI 모델에 대해 사용자에게 해당 AI 모델의 외부 통신에 대한 사용 자 동의를 받기 위한 기능을 사용자에게 제공할 수 있다. 이후, 사용자가 제공된 기능을 통해 해당 AI 모델의 외부 통신에 동의하는지 여부에 따라 사용자 단말이 해당 AI 모델의 외부 통신 범위를 설정할 수 있다. 단계에서 사용자 단말은 AI 모델의 동작 주기를 설정할 수 있다. 사용자 단말은 AI 모델이 사 용자 입력에 반응해 동작하는 주기 및 방식 등을 설정할 수 있다. 설정되는 방식에는 AI 모델이 자체 트리거링 되는 방식을 포함할 수 있다. 사용자 단말에서 AI 모델에 대한 설정이 완료되면, 해당 설정 정보는 AI 모델 등록 서비스 서버로 전 달되어 보관될 수 있다. 또한 사용자 단말에 해당 AI 모델의 설정 정보에 대한 매니페스트 정보들이 별도 로 저장 및 관리되어서 추후 AI 모델의 발견 등에 활용될 수 있다. 사용자 단말에 AI 모델에 대한 설정이 완료되면, 안전한 운영을 위해서 사용자 단말, AI 모델 스토어, 및/또는 AI 모델 등록 서비스 서버 는 해당 사용자 단말에 설치된 AI 모델에 대한 정보를 기록함으로써, 추후 AI 모델의 변경 여부 등을 모니터링하는데 활용할 수 있다. AI 모델에 대한 정보는 일례로 스냅 샷(snap shot) 등의 형태로, 사용자 단말 , AI 모델 스토어, 및/또는 AI 모델 등록 서비스 서버에 저장될 수 있다. AI 모델의 관리를 위한 메타데이터 중 AI 모델에 대한 일반 정보의 예는 아래 표 1과 같다. 표 1 · Metadata · On Device Model Information // 사용자 단말 상에서 동작하는 AI 모델의 관리를 위한 정보 · General // AI 모델 관련한 일반 정보 · Name // AI 모델의 명 (사용자에게 제공되는) · Code // AI 모델의 내부 코드 · Hash // AI 모델의 해쉬값 · Size // AI 모델의 크기 · Latest updated // 마지막 업데이트 정보 (일자) · Certification Code // 인증 획득 코드 · Certification Date // 인증 유효기간 · Core Model // AI 모델의 코어 정보, 사용자 단말에서 파인튜닝되는 형태로 동작하는 AI 모델의 경우, 초기 다운로드 및 설치되는 코어 모델의 정보를 의미함. · Version // 버전 정보 · Size // 코어 모델의 사이즈 · Hash // 코어 모델의 해쉬값 · Local Model // 사용자 단말에서 사용자의 이용에 따라 AI 모델의 정보가 업데이트 되는 AI 모 델의 경우, 관련된 모델 값의 변화를 기록 · Latest updated // 마지막 업데이트 정보(일자) · Size // 로컬 AI 모델의 사이즈 · Hash // 로컬 AI 모델의 해쉬값 · Backup Methods// AI 모델의 외부 백업여부(클라우드(Cloud), 데이터 금고(Data Vaults), 서비스 제공자(Service Provider)의 AI 모델 관리용 서비스) · Backup Date // AI 모델의 외부 백업 일자(로컬 AI 모델의 마지막 정보 업데이트 일자와는 다를 수 있음) AI 모델의 관리를 위한 메타데이터 중 AI 모델의 외부 접근 제어 관련 정보의 예는 아래 표 2와 같다. 표 2 · Metadata · Data Access Control Information // AI 모델의 외부 정보 접근을 위한 제어 정보 일체 · Channel // 채널 관련 정보 · Communication // 커뮤니케이션 정보 (외부 또는 실시간 데이터 I/O에 접근이 필요한 경 우) · URL (APIs) // 외부 커뮤니케이션을 위한 URL · Local Channel // AI 모델이 설치된 사용자 단말의 입출력 인터페이스를 이용해 실시 간 접근이 필요한 포인트 · Local data Access // 내부 데이터 접근을 위한 정보 · Access ID // 사용자 단말 내의 스토리지 액세스 정보(물리적인 주소 보다는 포토 앨 범(photo album), 보이스 리코딩(voice recording) 등의 논리적인 주소 정보(운영체제 나 보안 프레임 워크 상에서 접근을 허용하는) 대상) · Access Code // 정보 액세스를 위한 별도의 코드 · Accessible data list // 접근 가능한 데이터 리스트 (사용자가 허가한 또는 단말의 모델 설치 시 기본 획득하게 되는) · Data type // 데이터의 타입 · App. // 연결 가능한 고유의 어플리케이션 정보 (사용자 단말에 설치된) · Device // 스마트 워치(Smart Watch), 스마트 링(Smart Ring), 스마트 글래스(Smart Glass), 블루투스 디바이스(Bluetooth Devices) 등 사용자 단말과 연계 가능한 장치 · PermissionRequest // 사용자의 퍼미션 형태 · Access type · ByPass // 상시 접근 가능 · Ask // 사용자 응답 결과에 따른 접근 · User Allowance Information · Permission Allow List · ID // 사용자 단말의 어플리케이션 또는 디바이스 정보에 접근시 사용할 공유 ID · PermissionItems // 사용자의 Permission 허가 정보 · Permitted Date // 퍼미션 부여 시점(날짜) AI 모델의 관리를 위한 메타데이터 중 AI 모델의 동작과 관련된 응답 성능에 대한 정보의 예는 아래 표 3와 같 다.표 3 · Metadata · Service Performance Information // AI 모델의 응답 성능 관련 정보 · Model response time // 응답 시간 · Input token length //입력 토큰 길이 · Output token length // 응답 토큰 길이 · API model response time // 외부 모델 호출 응답 시간 · Request token length // 요청 토큰 길이 · Response token length // 응답 토큰 길이 · Operation Performance Information // AI 모델의 동작에 관련된 사용자 단말의 하드웨어 사용 량 정보 · Processor // Process 관련 정보 · Type // Processor Type {AP, NPU, GPU, TPU, Inference, etc} · Usage // 커뮤니케이션 정보(외부 또는 실시간 데이터 I/O에 접근이 필요한 경우) · Temperature // 외부 커뮤니케이션을 위한 URL · Memory // 사용자 단말의 메모리 관련 정보 · General Usage // 메모리 할당량 · Dedicated Usage// NPU(Neural Processing Unit), TPU(Tensor Processing Unit) 등 특정 프로세서를 위해 할당된 HBM(High Bandwidth Memory) 형태의 전용 메모리 사용량 · Storage // 사용자 단말의 스토리지 관련 정보 · Usage // 스토리지 사용량 · Battery Usage // 해당 시점에서의 배터리 사용량 도 12는 본 발명의 일실시예에 있어서, AI 모델 스토어의 모델 검증 절차의 예를 도시한 흐름도이다. 본 실시 예에 따른 AI 모델에 대한 모델 검증 절차는 AI 모델 스토어에 의해 수행될 수 있다.단계에서 AI 모 델 스토어는 모델 공급자의 AI 모델에 대한 등록 요청을 수신할 수 있다. 여기서, 모델 공급자는 AI 모델 서비스 공급자에 대응할 수 있다. AI 모델의 공급자는 자신의 AI 모델을 제공하기 위해 AI 모델 스토어 상에 AI 모델의 등록을 위한 심사를 요청할 수 있으며, AI 모델 스토어는 이러한 요청을 수신할 수 있다. 단계에서 AI 모델 스토어는 AI 모델의 인터페이스에 대한 정보 확인할 수 있다. AI 모델 스토어 는 AI 모델이 갖는 인터페이스 기능에 대해 모델 공급자가 제공한 내용을 바탕으로 해당 AI 모델에 대한 심사를 진행할 수 있으며, 이를 위해, 모델 공급자가 제공하는 AI 모델의 인터페이스에 대한 정보를 확인할 수 있다. 사용자 단말에서 동작하는 AI 모델의 경우 보안 및 프라이버시 등의 이슈로 완벽히 격리 (isolation) 환경에서 구동되어야 하며, 특정 기능에 대해서만 사용자의 동의 하에 외부 연동 기능이 제공 될 수 있다. 단계에서 AI 모델 스토어는 검증용 모델을 이용하여 검토 대상이 되는 AI 모델에 대한 검증을 진행 할 수 있다. AI 모델 스토어는 AI 모델을 심사하기 위해서 안전성이 검증된 소규모 모델(검증용 모델)을 이용해 해당 AI 모델에 대한 검증을 진행할 수 있다. 이때 검증용 모델은 안정성이 보장된 데이터를 활용해 특 정 분야 또는 데이터 영역에 대한 검증이 완료된 모델을 의미할 수 있다. 전체 AI 모델에 대한 검증이 아닌 개 별 AI 모델이 가진 영역의 검증을 진행하는 형태로 진행될 수 있다. 단계에서 AI 모델 스토어는 검토 대상이 되는 AI 모델의 특성에 맞춘 검증 시나리오를 생성할 수 있 다. 소규모의 검증용 모델에 의해 검증이 완료된 검토 대상이 되는 AI 모델에 대해서는 해당 AI 모델의 특성에 맞춘 시나리오 검증이 이루어질 수 있다. AI 모델의 특성상 다양한 이벤트에 대해 능동적으로 반응할 수 있기 때문에, 기본적인 안정성 검증 이외에 해당 AI 모델의 특성에 따른 검증 시나리오가 요구된다. 이때, AI 모델 스토어는 모델 공급자가 제공한 검증 시나리오, 인터페이스 정보, 및 AI 모델의 가중치 정보를 기반으로 해당 AI 모델을 위한 맞춤형 검증 시나리오를 생성할 수 있다. 단계에서 AI 모델 스토어는 맞춤형 검증 시나리오에 기반하여 검토 대상이 되는 AI 모델에 대한 검 증을 진행할 수 있다. AI 모델 스토어는 앞서 설명한 맞춤형 검증 시나리오에 대해서 AI 모델에 대한 별 도의 테스트 과정을 거칠 수 있다.단계에서 AI 모델 스토어는 AI 모델의 운영 특성을 테스트할 수 있다. AI 모델 스토어는 AI 모 델의 단말 환경에서의 동작 시 특성에 대해 테스트를 진행할 수 있다. 단말 별 AI 모델의 운영 환경에 맞춰 AI 모델의 동작 속도, 컴퓨팅 자원 활용, 전력 등 기본적인 동작 운영 환경에 대한 테스트를 진행할 수 있으며, 실 시예에 따라 사용자 데이터 접근 여부, 외부 네트워크 연동 여부 등에 대한 정보도 테스트 대상이 될 수 있다. 또한 실시간성을 요구하는 특성을 가진 경우, 해당 AI 모델의 용량(사용자 단말에서의 실시간 AI 모델의 동작 가능 여부)에 기반해 AI 모델의 운영성을 판단할 수 있다. 단계에서 AI 모델 스토어는 AI 모델에 대한 인증을 발행하고, 정보를 업데이트할 수 있다. AI 모델 스토어는 검증 과정을 통과한 AI 모델에 대해서는 인증(인증서)을 발행할 수 있다. 이때 인증 정보에는 AI 모델의 특성 정보(AI 모델의 크기, 해쉬값, 테스트 내용, 유효기간 등)가 포함될 수 있다 인증이 발행된(인 증서가 발급된) AI 모델의 경우, AI 모델 스토어 및/또는 AI 모델 등록 서비스 서버에 인증된 AI 모 델에 대한 정보가 업데이트될 수 있으며, 사용자 단말의 환경에서 동작 가능한 상황이 될 수 있다. AI 모델의 경우 독립적으로 동작할 수 있어야 하며, 해당 AI 모델의 동작 시 메모리 사용에 따른 컨텍스트 스위 칭(context switching) 비용이 높게 발생하는 특성이 존재한다. 이에 AI 모델의 크기에 따라 단말 환경에서 동 작할 수 있는 AI 모델은 한정적이며, 특히 크기가 큰 AI 모델의 경우 단말에서 실시간으로는 단일 모델만 동작 하도록 제한될 수 있다. 사용자 데이터에 대해 별도 임베딩하거나 비 실시간 형태로 동작이 가능한 모델의 경우, AI 모델은 사용자 단말 의 컴퓨팅 특성에 기반해 운영 정보가 자동으로 스케쥴링될 수 있으며, 외부 승인된 서비스의 요청에 의해 그 우선순위가 높아질 수 있다. 또한, 실시간으로 동작하는 AI 모델(일례로, 통신, 통화, SMS/MMS/채팅 등을 위한 AI 모델) 등은 상시 단말의 AI 추론 엔진 상에 상시 로딩될 수 있어야 한다. 또한, AI 모델의 동작에 따라 LLM(Large Language Model) 등의 경우 별도의 데이터를 자체적으로 임베딩한 경우 이에 대한 별도의 벡터 저장 공간이 요구될 수 있다. 이때 AI 모델 별로 임베딩 시, 벡터 저장 공간의 효율성 이 저하되기 때문에 사용자 단말 또는 AI 모델 스토어의 공급사가 제공하는 임베딩 모델의 사용을 사 용자에게 제안할 수 있다. 이 경우 개별 AI 모델은 공급되는 임베딩 모델을 활용하여 데이터를 벡터화시 키며, 향후 데이터 활용시에도 해당 임베딩 모델의 특성에 따라 동작할 수 있다. 도 13은 본 발명의 일실시예에 따른 인공지능 모델 관리 방법의 예를 도시한 흐름도이다. 본 실시예에 따른 인 공지능 모델 관리 방법은 AI 모델 등록 서비스 서버를 구현하는 컴퓨터 장치에 의해 수행될 수 있다. 이때, 컴퓨터 장치의 프로세서는 메모리가 포함하는 운영체제의 코드나 적어도 하나의 컴퓨터 프로그램의 코드에 따른 제어 명령(instruction)을 실행하도록 구현될 수 있다. 여기서, 프로세서는 컴퓨 터 장치에 저장된 코드가 제공하는 제어 명령에 따라 컴퓨터 장치가 도 13의 방법이 포함하는 단계들 (1310 내지 1340)을 수행하도록 컴퓨터 장치를 제어할 수 있다. 단계에서 컴퓨터 장치는 인공지능 모델 스토어로부터 인공지능 모델을 다운로드 받아 설치하는 복수 의 사용자 단말들 각각의 장치 정보를 저장 및 업데이트할 수 있다. 복수의 사용자 단말들 각각은 앞서 설명한 사용자 단말에 대응할 수 있다. 또한, 인공지능 모델 스토어는 앞서 설명한 AI 모델 스토어에 대응 할 수 있다. 여기서, 장치 정보는, 사용자 단말 상의 운영체제의 버전, 및 인공지능 모델을 호출하는 어플리케 이션의 보안 프레임워크에 대한 정보 중 적어도 하나를 포함할 수 있다. 단계에서 컴퓨터 장치는 인공지능 모델 스토어에 등록된 인공지능 모델의 장치 연동 범위에 대한 정 보를 더 저장 및 업데이트할 수 있다. 여기서, 장치 연동 범위에 대한 정보는, 기 정의된 센서들 중 인공지능 모델이 연동 가능한 센서에 대한 정보, 인공지능 모델이 이용 가능한 메모리 또는 저장공간의 크기, 및 인공지 능 모델의 업데이트 주기 중 적어도 하나를 포함할 수 있다. 단계에서 컴퓨터 장치는 복수의 사용자 단말들 중 제1 사용자 단말의 제1 인공지능 모델에 대한 설 치 요청에 따라, 제1 사용자 단말의 장치 정보에 기반하여 제1 사용자 단말에서의 제1 인공지능 모델의 설치 가 능 여부를 결정할 수 있다. 단계에서 컴퓨터 장치는 복수의 사용자 단말들 중 제2 사용자 단말의 하드웨어 정보 및 제2 인공지 능 모델의 장치 연동 범위를 이용하여 제2 인공지능 모델이 제2 사용자 단말에서 액세스 가능한 기능 범위를 설 정할 수 있다. 여기서, 제2 사용자 단말은 제1 사용자 단말과 동일한 사용자 단말이거나 상이한 사용자 단말일수 있다. 기능 범위는 인공지능 모델이 제2 사용자 단말에서 접근 가능한 어플리케이션에 대한 정보, 접근 가 능한 센서에 대한 정보, 및/또는 접근 가능한 데이터에 대한 정보를 포함할 수 있다. 단계에서 컴퓨터 장치는 기능 범위에 따라 제2 인공지능 모델이 포함하는 기능들 중 적어도 하나의 기능이 제외된 제3 인공지능 모델을 결정할 수 있다. 여기서, 제2 인공지능 모델은 제2 사용자 단말에서 설치 를 요청한 인공지능 모델을 포함할 수 있다. 이 경우, 제2 인공지능 모델 대신 제3 인공지능 모델이 제2 사용 자 단말로 추천될 수 있다. 앞서, 특정 AI 모델이 N개의 기능을 가지고 있고, 사용자 단말이 N-1개의 기 능을 가지는 경우, AI 모델 등록 서비스 서버는 사용자 단말 정보 관리부에서 관리되는 정보를 통해 사용자 단말에서 수행할 수 없는 기능을 제외한 다른 AI 모델을 선택하여 다운로드하도록 사용자 단말 로 서비스를 제공함으로써, 사용자 단말에서의 모델의 운영 공간을 감소시킬 수 있음에 대해 설명한 바 있다. 사용자 단말이 해당 AI 모델을 통해 수행할 수 없는 기능이 둘 이상이라면, 둘 이상의 기능이 제외된 또 다른 AI 모델이 선택될 수도 있음을 쉽게 이해할 수 있을 것이다. 실시예에 따라 컴퓨터 장치는 장치 연동 범위에 대한 정보를 이용하여 복수의 사용자 단말들 각각에 설치 된 인공지능 모델에 대한 업데이트 스케쥴을 관리할 수 있다. 일례로, 컴퓨터 장치는 장치 연동 범위에 대한 정보가 포함하는 각 사용자 단말들에서의 인공지능 모델의 업데이트 주기를 활용하여 복수의 사용자 단말 들 각각에 설치된 인공지능 모델에 대한 업데이트 스케쥴을 관리할 수 있다. 또한 실시예에 따라, 복수의 사용자 단말들 각각에 설치된 인공지능 모델의 버전 정보를 더 저장 및 업데이트할 수 있다. 일례로, 컴퓨터 장치는 특정 인공지능 모델의 버전이 업데이트되었음을 확인하는 경우, 해당 인 공지능 모델이 설치된 사용자 단말들로 해당 인공지능 모델의 버전 업데이트에 대한 알림을 제공할 수 있다. 또한 실시예에 따라, 컴퓨터 장치는 복수의 사용자 단말들 각각에 설치 및 구동되는 인공지능 모델의 운영 정보를 더 저장 및 업데이트할 수 있다. 여기서, 운영 정보는 사용자 단말에 설치 및 구동된 인공지능 모델이 사용자 단말의 외부 서비스와 통신하였는지 여부에 대한 정보, 및 사용자 단말에 설치 및 구동된 인공지능 모델 이 해당 사용자 단말에서 자체적으로 업데이트되었는지 여부에 대한 정보 중 적어도 하나를 포함할 수 있다. 일례로, 사용자 단말에서 자체적으로 업데이트된 인공지능 모델은 해당 인공지능 모델 스토어에 등록된 인공지 능 모델과 서로 다른 버전의 인공지능 모델로서 관리될 필요가 있다. 컴퓨터 장치는 이러한 자체적 업데 이트 여부에 대한 정보를 통해 인공지능 모델의 버전을 추가로 관리할 수 있다. 이와 같이, 본 발명의 실시예들에 따르면, 단말 환경에 설치되어 동작하는 인공지능 모델의 관리를 위한 방법 및 시스템을 제공할 수 있다. 이상에서 설명된 시스템 또는 장치는 하드웨어 구성요소, 또는 하드웨어 구성요소 및 소프트웨어 구성요소의 조 합으로 구현될 수 있다. 예를 들어, 실시예들에서 설명된 장치 및 구성요소는, 예를 들어, 프로세서, 콘트롤러, ALU(arithmetic logic unit), 디지털 신호 프로세서(digital signal processor), 마이크로컴퓨터, FPGA(field programmable gate array), PLU(programmable logic unit), 마이크로프로세서, 또는 명령 (instruction)을 실행하고 응답할 수 있는 다른 어떠한 장치와 같이, 하나 이상의 범용 컴퓨터 또는 특수 목적 컴퓨터를 이용하여 구현될 수 있다. 처리 장치는 운영 체제(OS) 및 상기 운영 체제 상에서 수행되는 하나 이상 의 소프트웨어 어플리케이션을 수행할 수 있다. 또한, 처리 장치는 소프트웨어의 실행에 응답하여, 데이터를 접근, 저장, 조작, 처리 및 생성할 수도 있다. 이해의 편의를 위하여, 처리 장치는 하나가 사용되는 것으로 설"}
{"patent_id": "10-2024-0078218", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "명된 경우도 있지만, 해당 기술분야에서 통상의 지식을 가진 자는, 처리 장치가 복수 개의 처리 요소 (processing element) 및/또는 복수 유형의 처리 요소를 포함할 수 있음을 알 수 있다. 예를 들어, 처리 장치 는 복수 개의 프로세서 또는 하나의 프로세서 및 하나의 콘트롤러를 포함할 수 있다. 또한, 병렬 프로세서 (parallel processor)와 같은, 다른 처리 구성(processing configuration)도 가능하다. 소프트웨어는 컴퓨터 프로그램(computer program), 코드(code), 명령(instruction), 또는 이들 중 하나 이상의 조합을 포함할 수 있으며, 원하는 대로 동작하도록 처리 장치를 구성하거나 독립적으로 또는 결합적으로 (collectively) 처리 장치를 명령할 수 있다. 소프트웨어 및/또는 데이터는, 처리 장치에 의하여 해석되거나 처리 장치에 명령 또는 데이터를 제공하기 위하여, 어떤 유형의 기계, 구성요소(component), 물리적 장치, 가상 장치(virtual equipment), 컴퓨터 저장 매체 또는 장치에 구체화(embody)될 수 있다. 소프트웨어는 네트워크로 연결된 컴퓨터 시스템 상에 분산되어서, 분산된 방법으로 저장되거나 실행될 수도 있다. 소프트웨어 및 데이터 는 하나 이상의 컴퓨터 판독 가능 기록매체에 저장될 수 있다. 실시예에 따른 방법은 다양한 컴퓨터 수단을 통하여 수행될 수 있는 프로그램 명령 형태로 구현되어 컴퓨터 판 독 가능 매체에 기록될 수 있다. 상기 컴퓨터 판독 가능 매체는 프로그램 명령, 데이터 파일, 데이터 구조 등 을 단독으로 또는 조합하여 포함할 수 있다. 매체는 컴퓨터로 실행 가능한 프로그램을 계속 저장하거나, 실행 또는 다운로드를 위해 임시 저장하는 것일 수도 있다. 또한, 매체는 단일 또는 수개 하드웨어가 결합된 형태의 다양한 기록수단 또는 저장수단일 수 있는데, 어떤 컴퓨터 시스템에 직접 접속되는 매체에 한정되지 않고, 네트 워크 상에 분산 존재하는 것일 수도 있다. 매체의 예시로는, 하드 디스크, 플로피 디스크 및 자기 테이프와 같 은 자기 매체, CD-ROM 및 DVD와 같은 광기록 매체, 플롭티컬 디스크(floptical disk)와 같은 자기-광 매체 (magneto-optical medium), 및 ROM, RAM, 플래시 메모리 등을 포함하여 프로그램 명령어가 저장되도록 구성된 것이 있을 수 있다. 또한, 다른 매체의 예시로, 애플리케이션을 유통하는 앱 스토어나 기타 다양한 소프트웨어 를 공급 내지 유통하는 사이트, 서버 등에서 관리하는 기록매체 내지 저장매체도 들 수 있다. 프로그램 명령의 예에는 컴파일러에 의해 만들어지는 것과 같은 기계어 코드뿐만 아니라 인터프리터 등을 사용해서 컴퓨터에 의 해서 실행될 수 있는 고급 언어 코드를 포함한다."}
{"patent_id": "10-2024-0078218", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "이상과 같이 실시예들이 비록 한정된 실시예와 도면에 의해 설명되었으나, 해당 기술분야에서 통상의 지식을 가 진 자라면 상기의 기재로부터 다양한 수정 및 변형이 가능하다. 예를 들어, 설명된 기술들이 설명된 방법과 다 른 순서로 수행되거나, 및/또는 설명된 시스템, 구조, 장치, 회로 등의 구성요소들이 설명된 방법과 다른 형태 로 결합 또는 조합되거나, 다른 구성요소 또는 균등물에 의하여 대치되거나 치환되더라도 적절한 결과가 달성될 수 있다. 그러므로, 다른 구현들, 다른 실시예들 및 청구범위와 균등한 것들도 후술하는 청구범위의 범위에 속한다."}
{"patent_id": "10-2024-0078218", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일실시예에 따른 네트워크 환경의 예를 도시한 도면이다. 도 2는 본 발명의 일실시예에 따른 컴퓨터 장치의 예를 도시한 블록도이다. 도 3은 본 발명의 일실시예에 따른 AI 모델 관리 시스템의 개략적인 모습의 예를 도시한 도면이다. 도 4는 본 발명의 일실시예에 따른 AI 모델 관리 과정의 예를 도시한 도면이다. 도 5는 본 발명의 일실시예에 있어서, 단말 환경에서 동작하는 AI 모델 공급 및 설치를 위한 구조의 예를 도시 한 도면이다. 도 6은 본 발명의 일실시예에 있어서, AI 모델 등록 서비스 서버의 내부 구성의 예를 도시한 도면이다. 도 7은 본 발명의 일실시예에 있어서, AI 모델 스토어의 내부 구성의 예를 도시한 도면이다.도 8은 본 발명의 일실시예에 있어서, 사용자 단말의 내부 구성의 예를 도시한 도면이다. 도 9는 본 발명의 일실시예에 있어서, AI 모델 운영을 위한 사용자 단말의 하드웨어 구조의 예를 도시한 도면이 다. 도 10는 본 발명의 일실시예에 있어서, AI 모델 운영을 위한 사용자 단말의 소프트웨어 구조의 예를 도시한 도 면이다. 도 11은 본 발명의 일실시예에 있어서, AI 모델을 다운로드 및 설치하는 과정의 예를 도시한 흐름도이다. 도 12는 본 발명의 일실시예에 있어서, AI 모델 스토어의 모델 검증 절차의 예를 도시한 흐름도이다. 도 13은 본 발명의 일실시예에 따른 인공지능 모델 관리 방법의 예를 도시한 흐름도이다."}
