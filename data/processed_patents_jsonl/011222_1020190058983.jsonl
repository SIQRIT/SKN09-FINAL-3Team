{"patent_id": "10-2019-0058983", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2020-0132613", "출원번호": "10-2019-0058983", "발명의 명칭": "웨이크 언 보이스", "출원인": "삼성전자주식회사", "발명자": "한창우"}}
{"patent_id": "10-2019-0058983", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "제1 멀티 채널 오디오 신호를 수신하는 단계;상기 제1 멀티 채널 오디오 신호에 포함되는 각 채널 오디오 신호로부터 주파수 대역별 음성 신호 특성 및 노이즈 신호 특성을 획득하는 단계;상기 음성 신호 특성, 소정 시간 전에 획득된 음성 신호 특성 및 상기 노이즈 신호 특성에 기초하여 상기 제1멀티 채널 오디오 신호에 대해 빔포밍을 수행함으로써, 음성 성분이 강화된 신호를 생성하는 단계;상기 음성 성분이 강화된 신호에 기초하여 음성 인식 동작을 활성화 하는 단계; 및제2 멀티 채널 오디오 신호에 대해 음성 인식을 수행하고 음성 인식 결과를 출력하는 단계를 포함하는, 음성 인식 방법."}
{"patent_id": "10-2019-0058983", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1 항에 있어서,상기 음성 성분이 강화된 신호를 생성하는 단계는,상기 음성 신호 특성 및 상기 노이즈 신호 특성에 기초하여 상기 제1 멀티 채널 오디오 신호에 대해 제1 빔포밍을 수행함으로써, 제1 강화 신호를 생성하는 단계; 및상기 음성 신호 특성 및 M 프레임 이 전에 획득된 음성 신호 특성에 기초하여 상기 제1 멀티 채널 오디오 신호에 대해 제2 빔포밍을 수행함으로써, 제2 강화 신호를 생성하는 단계를 포함하는, 음성 인식 방법."}
{"patent_id": "10-2019-0058983", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2 항에 있어서,상기 음성 인식 동작을 활성화 하는 단계는,상기 제1 강화 신호 또는 상기 제2 강화 신호 내에 기 설정된 단어가 포함된다는 판단에 기초하여, 음성 인식동작을 활성화 하는 단계를 포함하고,상기 제2 멀티 채널 오디오 신호는, 사용자가 상기 기 설정된 단어를 발화한 이후에 발화한 음성 신호를 포함하는 것을 특징으로 하는, 음성 인식 방법."}
{"patent_id": "10-2019-0058983", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제2 항에 있어서,상기 제2 강화 신호는, 상기 음성 신호 특성으로부터 상기 M 프레임 이 전에 획득된 음성 신호 특성이 제거된신호인 것을 특징으로 하는, 음성 인식 방법."}
{"patent_id": "10-2019-0058983", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1 항에 있어서,상기 음성 신호 특성 및 노이즈 신호 특성을 획득하는 단계는,상기 각 채널 오디오 신호에 대해 주파수 변환을 수행함으로써 주파수 빈 값들을 획득하는 단계;마스크를 적용함으로써, 상기 획득된 주파수 빈 값들로부터 주파수 대역별 음성 교차 파워 스펙트럴 밀도(speech cross-PSD(Power Spectral Density)) 및 노이즈 교차 파워 스펙트럴 밀도(noise crss-PSD)를 각각 획득하는 단계를 포함하는, 음성 인식 방법.공개특허 10-2020-0132613-3-청구항 6 제5 항에 있어서,상기 제1 멀티 채널 오디오 신호가 M개의 채널들을 통해 수신한 M개의 오디오 신호들을 포함하는 경우, 상기 음성 교차 파워 스펙트럴 밀도 및 상기 노이즈 교차 파워 스펙트럴 밀도는 MxM 매트릭스의 형태인 것을 특징으로하는, 음성 인식 방법."}
{"patent_id": "10-2019-0058983", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1 항에 있어서,상기 음성 신호 특성 및 상기 노이즈 신호 특성을 획득하기 위해 이용되는 마스크를 추정하는 단계를 더 포함하고,상기 마스크를 추정하는 단계는, 상기 제1 멀티 채널 오디오 신호에 대해 중간값 필터를 적용함으로써, 단일 채널 오디오 신호로 변환하는 단계;및상기 단일 채널 오디오 신호에 대한 신경망 분석을 통해 주파수 대역별 마스크 값을 추정하는 단계를 포함하는,음성 인식 방법."}
{"patent_id": "10-2019-0058983", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제3 항에 있어서,상기 음성 인식을 수행하고 음성 인식 결과를 출력하는 단계는,상기 제1 강화 신호 내에 상기 기 설정된 단어가 포함된다는 판단에 기초하여 음성 인식 동작이 활성화 된경우, 상기 제2 멀티 채널 오디오 신호에 대해 어댑티브 빔포밍(adaptive beamforming)을 수행하는 단계; 및상기 제1 강화 신호 내에는 상기 기 설정된 단어가 포함되지 않고 상기 제2 강화 신호 내에 상기 기 설정된 단어가 포함된다는 판단에 기초하여 음성 인식 동작이 활성화 된 경우, 상기 제2 멀티 채널 오디오 신호에 대해픽스드 빔포밍(fixed beamforming)을 수행하는 단계를 포함하는, 음성 인식 방법."}
{"patent_id": "10-2019-0058983", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8 항에 있어서,상기 어댑티브 빔포밍을 수행하는 단계는, 상기 제2 멀티 채널 오디오 신호의 매 프레임마다 파라미터들을 업데이트함으로써, 업데이트된 파라미터들에 기초하여 빔포밍을 수행하는 단계를 포함하고,상기 픽스드 빔포밍을 수행하는 단계는,상기 제2 강화 신호 생성 시에 이용되었던 파라미터들에 기초하여, 상기 제2 멀티 채널 오디오 신호에 대해서빔포밍을 수행하는 단계를 포함하는, 음성 인식 방법."}
{"patent_id": "10-2019-0058983", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제1 항에 있어서,상기 제1 멀티 채널 오디오 신호 및 상기 제2 멀티 채널 오디오 신호는,음성 인식 장치에 구비된 복수의 마이크들로부터 수신되는 것을 특징으로 하는, 음성 인식 방법."}
{"patent_id": "10-2019-0058983", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제1 멀티 채널 오디오 신호를 수신하는 수신부;상기 제1 멀티 채널 오디오 신호에 포함되는 각 채널 오디오 신호로부터 주파수 대역별 음성 신호 특성 및 노이즈 신호 특성을 획득하고,공개특허 10-2020-0132613-4-상기 음성 신호 특성, 소정 시간 전에 획득된 음성 신호 특성 및 상기 노이즈 신호 특성에 기초하여 상기 제1멀티 채널 오디오 신호에 대해 빔포밍을 수행함으로써, 음성 성분이 강화된 신호를 생성하고, 상기 음성 성분이 강화된 신호에 기초하여 음성 인식 동작을 활성화 하고,제2 멀티 채널 오디오 신호에 대해 음성 인식을 수행하는, 적어도 하나의 프로세서; 및음성 인식 결과를 출력하는 출력부를 포함하는, 음성 인식 장치."}
{"patent_id": "10-2019-0058983", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11 항에 있어서,상기 적어도 하나의 프로세서는, 상기 음성 신호 특성 및 상기 노이즈 신호 특성에 기초하여 상기 제1 멀티 채널 오디오 신호에 대해 제1 빔포밍을 수행함으로써, 제1 강화 신호를 생성하고,상기 음성 신호 특성 및 M 프레임 이 전에 획득된 음성 신호 특성에 기초하여 상기 제1 멀티 채널 오디오 신호에 대해 제2 빔포밍을 수행함으로써, 제2 강화 신호를 생성하고,상기 제1 강화 신호 및 상기 제2 강화 신호에 기초하여 음성 인식 동작을 활성화하는 것을 특징으로 하는, 음성인식 장치."}
{"patent_id": "10-2019-0058983", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제12 항에 있어서,상기 적어도 하나의 프로세서는,상기 제1 강화 신호 또는 상기 제2 강화 신호 내에 기 설정된 단어가 포함된다는 판단에 기초하여, 음성 인식동작을 활성화 하고,상기 제2 멀티 채널 오디오 신호는, 사용자가 상기 기 설정된 단어를 발화한 이후에 발화한 음성 신호를 포함하는 것을 특징으로 하는, 음성 인식 장치."}
{"patent_id": "10-2019-0058983", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제12 항에 있어서,상기 제2 강화 신호는, 상기 음성 신호 특성으로부터 상기 M 프레임 이전에 획득된 음성 신호 특성이 제거된 신호인 것을 특징으로 하는, 음성 인식 장치."}
{"patent_id": "10-2019-0058983", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제11 항에 있어서,상기 적어도 하나의 프로세서는,상기 각 채널 오디오 신호에 대해 주파수 변환을 수행함으로써 주파수 빈 값들을 획득하고,마스크를 적용함으로써, 상기 획득된 주파수 빈 값들로부터 주파수 대역별 음성 교차 파워 스펙트럴 밀도 및 노이즈 교차 파워 스펙트럴 밀도를 각각 획득하는 것을 특징으로 하는, 음성 인식 장치."}
{"patent_id": "10-2019-0058983", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제15 항에 있어서,상기 제1 멀티 채널 오디오 신호가 M개의 채널들을 통해 수신한 M개의 오디오 신호들을 포함하는 경우, 상기 음성 교차 파워 스펙트럴 밀도 및 상기 노이즈 교차 파워 스펙트럴 밀도는 MxM 매트릭스의 형태인 것을 특징으로하는, 음성 인식 장치."}
{"patent_id": "10-2019-0058983", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "공개특허 10-2020-0132613-5-제11 항에 있어서,상기 적어도 하나의 프로세서는,상기 음성 신호 특성 및 상기 노이즈 신호 특성을 획득하기 위해 이용되는 마스크를 추정하도록 구성되고,상기 적어도 하나의 프로세서는, 상기 마스크를 추정하기 위하여, 상기 제1 멀티 채널 오디오 신호에 대해 중간값 필터를 적용함으로써, 단일 채널 오디오 신호로 변환하고,상기 단일 채널 오디오 신호에 대한 신경망 분석을 통해 주파수 대역별 마스크 값을 추정하는 것을 특징으로 하는, 음성 인식 장치."}
{"patent_id": "10-2019-0058983", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제13 항에 있어서,상기 적어도 하나의 프로세서는,상기 제1 강화 신호 내에 상기 기 설정된 단어가 포함된다는 판단에 기초하여 음성 인식 동작이 활성화 된경우, 상기 제2 멀티 채널 오디오 신호에 대해 어댑티브 빔포밍을 수행하고,상기 제1 강화 신호 내에는 상기 기 설정된 단어가 포함되지 않고 상기 제2 강화 신호 내에 상기 기 설정된 단어가 포함된다는 판단에 기초하여 음성 인식 동작이 활성화 된 경우, 상기 제2 멀티 채널 오디오 신호에 대해픽스드 빔포밍을 수행하는 것을 특징으로 하는, 음성 인식 장치."}
{"patent_id": "10-2019-0058983", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제18 항에 있어서,상기 적어도 하나의 프로세서는,상기 제2 멀티 채널 오디오 신호의 매 프레임마다 파라미터들을 업데이트함으로써, 업데이트된 파라미터들에 기초하여 상기 어댑티브 빔포밍을 수행하고,상기 제2 강화 신호 생성 시에 이용되었던 파라미터들에 기초하여, 상기 제2 멀티 채널 오디오 신호에 대해서상기 픽스드 빔포밍을 수행하는 것을 특징으로 하는, 음성 인식 장치."}
{"patent_id": "10-2019-0058983", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제11 항에 있어서,상기 수신부는 복수의 마이크들을 포함하고,상기 제1 멀티 채널 오디오 신호 및 상기 제2 멀티 채널 오디오 신호는,상기 복수의 마이크들로부터 수신되는 것을 특징으로 하는, 음성 인식 장치."}
{"patent_id": "10-2019-0058983", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_21", "content": "제1 항의 방법을 수행하도록 하는 프로그램이 저장된 하나 이상의 컴퓨터로 읽을 수 있는 기록매체를 포함하는컴퓨터 프로그램 제품."}
{"patent_id": "10-2019-0058983", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "제1 멀티 채널 오디오 신호를 수신하는 단계, 제1 멀티 채널 오디오 신호에 포함되는 각 채널 오디오 신호로부터 주파수 대역별 음성 신호 특성 및 노이즈 신호 특성을 획득하는 단계, 음성 신호 특성, 소정 시간 전에 획득된 음성 신호 특성 및 노이즈 신호 특성에 기초하여 제1 멀티 채널 오디오 신호에 대해 빔포밍을 수행함으로써, 음 성 성분이 강화된 신호를 생성하는 단계, 음성 성분이 강화된 신호에 기초하여 음성 인식 동작을 활성화 하는 단 계, 및 제2 멀티 채널 오디오 신호에 대해 음성 인식을 수행하고 음성 인식 결과를 출력하는 단계를 포함하는, 음성 인식 방법이 개시된다."}
{"patent_id": "10-2019-0058983", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 음성 인식 수행 방법 및 장치에 관한 것으로서, 보다 상세하게는 음성 간섭에 강인한 웨이크 언 보이 스를 위하여 전처리를 수행하는 음성 인식 동작 방법 및 장치에 관한 것이다."}
{"patent_id": "10-2019-0058983", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "다양한 기능을 복합적으로 수행하는 전자 장치들이 개발됨에 따라, 조작성을 향상시키기 위하여 음성 인식 기능 이 탑재된 전자 장치들이 출시되고 있다. 음성 인식 기능은, 별도의 버튼 조작 또는 터치 모듈의 접촉에 의하지않고 사용자의 음성을 인식함으로써 장치를 손쉽게 제어할 수 있는 장점을 가진다. 이러한 음성 인식 기능에 의하면, 예를 들어 스마트폰과 같은 휴대용 단말기 및 TV, 냉장고 등과 같은 가전 제 품에서 별도의 버튼을 누르는 조작 없이 통화 기능을 수행하거나 문자 메시지를 작성할 수 있으며, 길찾기, 인 터넷 검색, 알람 설정 등 다양한 기능을 손쉽게 설정할 수 있다. 음성 인식 장치로부터 상당히 떨어진 거리에 위치한 사용자의 음성에 의해 제어되기 위해서, 음성 인식 장치는 시끄러운 환경에서도 안정적인 성능을 보장할 수 있어야 한다. 안정적인 성능을 보장하기 위하여, 음성 인식 동 작을 시작할 시기를 사용자가 음성 인식 장치에게 알려주는 WoV(Wake On Voice) 기술이 이용될 수 있다. 음성 인식 장치를 웨이크 업 하기 위하여, 사용자는 주 명령어 앞에 미리 결정된 웨이크 워드를 추가하여 발화한다. WoV 기술은 음성 제어의 첫 번째 단계가 되므로, 높은 정확성이 요구된다. 한편, 인공 지능(Artificial Intelligence, AI) 시스템은 인간 수준의 지능을 구현하는 컴퓨터 시스템이며, 기 존의 룰(Rule) 기반 스마트 시스템과 달리 기계가 스스로 학습하고 판단하며 똑똑해지는 시스템이다. 인공지능 시스템은 사용할수록 인식률이 향상되고 사용자 취향을 보다 정확하게 이해할 수 있게 되어, 기존의 룰 기반 스 마트 시스템은 점차 딥러닝 기반 인공지능 시스템으로 대체되고 있다. 인공 지능 기술은 기계학습(딥러닝) 및 기계 학습을 활용한 요소 기술들로 구성된다. 기계 학습은 입력 데이터들의 특징을 스스로 분류/학습하는 알고리즘 기술이며, 요소 기술은 딥 러닝 등의 기계 학습 알고리즘을 활용하는 기술로서, 언어적 이해, 시각적 이해, 추론/예측, 지식 표현, 동작 제어 등의 기술 분야로 구성된다. 인공 지능 기술이 응용되는 다양한 분야는 다음과 같다. 언어적 이해는 인간의 언어/문자를 인식하고 응용/처리 하는 기술로서, 자연어 처리, 기계 번역, 대화 시스템, 질의 응답, 음성 인식/합성 등을 포함한다. 추론 예측은 정보를 판단하여 논리적으로 추론하고 예측하는 기술로서, 지식/확률 기반 추론, 최적화 예측, 선호 기반 계획, 추천 등을 포함한다. 지식 표현은 인간의 경험정보를 지식데이터로 자동화 처리하는 기술로서, 지식 구축(데이 터 생성/분류), 지식 관리(데이터 활용) 등을 포함한다."}
{"patent_id": "10-2019-0058983", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "TV 시청 환경과 같이 음성이 포함된 노이즈가 존재하는 환경에서 음성 인식 장치가 동작하는 경우, 기존의 전처 리 기법이 제대로 동작하지 않아 음성 인식 장치의 웨이크 업(wake up) 성공률이 현저히 떨어진다는 문제점이 있다."}
{"patent_id": "10-2019-0058983", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상술한 기술적 과제를 달성하기 위한 기술적 수단으로서, 본 개시의 일 실시 예에 따른 음성 인식 방법은, 제1 멀티 채널 오디오 신호를 수신하는 단계; 상기 제1 멀티 채널 오디오 신호에 포함되는 각 채널 오디오 신호로부 터 주파수 대역별 음성 신호 특성 및 노이즈 신호 특성을 획득하는 단계; 상기 음성 신호 특성, 소정 시간 전에 획득된 음성 신호 특성 및 상기 노이즈 신호 특성에 기초하여 상기 제1 멀티 채널 오디오 신호에 대해 빔포밍을 수행함으로써, 음성 성분이 강화된 신호를 생성하는 단계; 상기 음성 성분이 강화된 신호에 기초하여 음성 인식 동작을 활성화 하는 단계; 및 제2 멀티 채널 오디오 신호에 대해 음성 인식을 수행하고 음성 인식 결과를 출력 하는 단계를 포함할 수 있다. 또한, 본 개시의 일 실시 예에 따른 음성 인식 장치는, 제1 멀티 채널 오디오 신호를 수신하는 수신부; 상기 제 1 멀티 채널 오디오 신호에 포함되는 각 채널 오디오 신호로부터 주파수 대역별 음성 신호 특성 및 노이즈 신호 특성을 획득하고, 상기 음성 신호 특성, 소정 시간 전에 획득된 음성 신호 특성 및 상기 노이즈 신호 특성에 기 초하여 상기 제1 멀티 채널 오디오 신호에 대해 빔포밍을 수행함으로써, 음성 성분이 강화된 신호를 생성하고, 상기 음성 성분이 강화된 신호에 기초하여 음성 인식 동작을 활성화 하고, 제2 멀티 채널 오디오 신호에 대해 음성 인식을 수행하는, 적어도 하나의 프로세서; 및 음성 인식 결과를 출력하는 출력부를 포함할 수 있다. 또한, 본 개시의 일 실시 예에 따른 컴퓨터 프로그램 제품은, 제1 멀티 채널 오디오 신호를 수신하는 단계; 상 기 제1 멀티 채널 오디오 신호에 포함되는 각 채널 오디오 신호로부터 주파수 대역별 음성 신호 특성 및 노이즈 신호 특성을 획득하는 단계; 상기 음성 신호 특성, 소정 시간 전에 획득된 음성 신호 특성 및 상기 노이즈 신호특성에 기초하여 상기 제1 멀티 채널 오디오 신호에 대해 빔포밍을 수행함으로써, 음성 성분이 강화된 신호를 생성하는 단계; 상기 음성 성분이 강화된 신호에 기초하여 음성 인식 동작을 활성화 하는 단계; 및 제2 멀티 채 널 오디오 신호에 대해 음성 인식을 수행하고 음성 인식 결과를 출력하는 단계를 포함하는 음성 인식 방법을 수 행하도록 하는 프로그램이 저장된 하나 이상의 컴퓨터로 읽을 수 있는 기록매체를 포함할 수 있다."}
{"patent_id": "10-2019-0058983", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "음성 간섭에 강인한 웨이크 워드 검출(speech-interference robust wake word detection)을 위한 신호 전처리 방법이 제공될 수 있다."}
{"patent_id": "10-2019-0058983", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "아래에서는 첨부한 도면을 참조하여 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자가 용이하게 실시할 수 있도록 본 발명의 실시 예를 상세히 설명한다. 그러나 본 발명은 여러 가지 상이한 형태로 구현될 수 있으며 여기에서 설명하는 실시 예에 한정되지 않는다. 그리고 도면에서 본 발명을 명확하게 설명하기 위해서 설명과 관계없는 부분은 생략하였으며, 명세서 전체를 통하여 유사한 부분에 대해서는 유사한 도면 부호를 붙였다. 명세서 전체에서, 어떤 부분이 다른 부분과 \"연결\"되어 있다고 할 때, 이는 \"직접적으로 연결\"되어 있는 경우뿐 아니라, 그 중간에 다른 소자를 사이에 두고 \"전기적으로 연결\"되어 있는 경우도 포함한다. 또한 어떤 부분이 어떤 구성요소를 \"포함\"한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다른 구성요소를 제외하는 것이 아 니라 다른 구성요소를 더 포함할 수 있는 것을 의미한다. 본 명세서에서 다양한 곳에 등장하는 \"일부 실시 예에서\" 또는 \"일 실시 예에서\" 등의 어구는 반드시 모두 동일 한 실시 예를 가리키는 것은 아니다. 일부 실시 예는 기능적인 블록 구성들 및 다양한 처리 단계들로 나타내어질 수 있다. 이러한 기능 블록들의 일 부 또는 전부는, 특정 기능들을 실행하는 다양한 개수의 하드웨어 및/또는 소프트웨어 구성들로 구현될 수 있다. 예를 들어, 본 개시의 기능 블록들은 하나 이상의 마이크로프로세서들에 의해 구현되거나, 소정의 기능을 위한 회로 구성들에 의해 구현될 수 있다. 또한, 예를 들어, 본 개시의 기능 블록들은 다양한 프로그래밍 또는 스크립팅 언어로 구현될 수 있다. 기능 블록들은 하나 이상의 프로세서들에서 실행되는 알고리즘으로 구현될 수 있다. 또한, 본 개시는 전자적인 환경 설정, 신호 처리, 및/또는 데이터 처리 등을 위하여 종래 기술을 채용할 수 있다. \"모듈\" 및 \"구성\" 등과 같은 용어는 넓게 사용될 수 있으며, 기계적이고 물리적인 구성들로서 한정되 는 것은 아니다.또한, 도면에 도시된 구성 요소들 간의 연결 선 또는 연결 부재들은 기능적인 연결 및/또는 물리적 또는 회로적 연결들을 예시적으로 나타낸 것일 뿐이다. 실제 장치에서는 대체 가능하거나 추가된 다양한 기능적인 연결, 물 리적인 연결, 또는 회로 연결들에 의해 구성 요소들 간의 연결이 나타내어질 수 있다. 이하 첨부된 도면을 참고하여 본 개시를 상세히 설명하기로 한다. 음성 인식 인터페이스는 최근 스마트 장치를 제어하기 위한 대표적인 요소가 되었다. 음성 인식 장치로부터 상 당히 떨어진 거리에 위치한 사용자의 음성에 의해 제어되기 위해서, 음성 인식 장치는 시끄러운 환경에서도 안 정적인 성능을 보장할 수 있어야 한다. 안정적인 성능을 보장하기 위하여, 사용자가 음성 인식 장치에게 음성 인식 동작을 시작할 시기를 알려주는 WoV(Wake On Voice) 기술이 이용될 수 있다. 음성 인식 장치를 웨이크 업 하기 위하여, 사용자는 주 명령어 앞에 미리 결정된 웨이크 워드를 추가하여 발화한다. WoV 기술은 음성 제어의 첫 번째 단계가 되므로, 높은 정확성이 요구된다. 음성 인식 장치로부터 먼 거리에 위치한 사용자가 발화한 음성 신호는, 음성 인식 장치에게 전달되는 도중에 노 이즈(noise)와 잔향(reverberation)으로 인해 품질이 심각하게 저하될 수 있다. 특히, 도 1에 도시된 바와 같이, TV로부터 음성이 포함된 노이즈가 출력되는 환경에서 음성 인식 장치가 동작하는 경우, 사용자 의 웨이크 워드에 의해 음성 인식 장치가 웨이크 업 되는 성공률이 현저히 떨어지는 문제점이 있다. TV로부터 음성 노이즈가 출력되는 환경 뿐만 아니라, 가사가 있는 노래가 출력되는 환경 또는 많은 사람들이 모 여있는 환경과 같이 음성 노이즈가 존재하는 환경에서 음성 인식 정확도를 높이기 위하여, 본 개시의 일 실시 예에 따르면 다 채널 음성 강화 방법이 이용될 수 있다. 일반적인 다채널 음성 강화 방법에 따르면, 음성 노이즈가 존재하는 환경에서, 멀티 채널을 통해 수신되는 오디 오 신호들 중에서 타겟 음성 신호가 포함되는 오디오 신호와 음성 노이즈가 포함되는 오디오 신호가 구분되어 처리되기 어렵다. 그러나, 본 개시의 일 실시 예에 따르면 멀티 채널을 통해 수신되는 오디오 신호들 중에서 웨 이크 워드가 포함되는 오디오 신호를 결정하여 웨이크 업 모듈에 전달함으로써 웨이크 업을 위한 음성 인식 성 능을 향상 시킬 수 있다. 본 개시의 일 실시 예에 따르면 멀티 채널 오디오 신호에 대한 빔포밍을 수행함으로써 타겟 음성 성분이 강화된 신호를 웨이크 업 모듈에 전달함으로써 웨이크 업을 위한 음성 인식 성능을 향상 시킬 수 있다., 본 개시의 실 시 예들에 따르면, 음성 간섭 환경에서도 강인한 웨이크 워드 검출을 가능하게 하는 전처리(front-end) 방법이 제공된다. 도 2a, 2b 및 2c는 일 실시 예에 따른 음성 인식 시스템을 설명하기 위한 도면이다. 도 2a에 도시된 바와 같이, 일 실시 예에 따른 음성 인식 시스템은 음성 인식 장치를 포함할 수 있다. 예를 들어, 도 2a에 도시된 바와 같이, 음성 인식 장치는, 인공 지능 기술을 기반으로 하는 디지털 음성 보조 디바이스(Digital Voice Assistant Device)일 수 있다. 그러나 실시 예는 도 2a에 도시된 예에 제한되지 않으며, 음성 인식 장치는, TV, 냉장고, 세탁기 등의 가전 제품, 스마트폰, PC, 웨어러블 디바이스, PDA(personal digital assistant), 미디어 플레이어, 마이크로 서버, GPS(global positioning system) 장치, 전자책 단말기, 디지털방송용 단말기, 네비게이션, 키오스크, MP3 플레이어, 디지털 카메라 및 기타 모바일 또 는 비모바일 컴퓨팅 장치일 수 있으나, 이에 제한되지 않는다. 일 실시 예에 따른 음성 인식 장치는, 다양한 방향에서 수신되는 오디오 신호들을 수신하기 위한 복수의 마이크로폰들을 포함할 수 있다. 예를 들어, 음성 인식 장치가 구 형 또는 원통형인 경우, 음성 인식 장치 의 표면에 일정한 간격으로 배치된 복수의 마이크로폰들을 포함할 수 있다. 예를 들어, 음성 인식 장치 는, 음성 인식 장치의 측면에 45도 간격으로 배치되는 8 개의 마이크로폰들을 포함함으로써, 360도 모든 방향으로부터 수신되는 8 채널 오디오 신호를 수신할 수 있다. 그러나 실시 예는 이에 제한되지 않으며, 음성 인식 장치는, 2 채널, 4 채널, 6 채널 등 다양한 개수의 채널들을 통해 오디오 신호들을 수신할 수 있다. 일 실시 예에 따른 음성 인식 장치는, 음성 인식의 정확도를 높이기 위하여 수신되는 오디오 신호에 대해 전처리를 수행할 수 있다. 예를 들어, 음성 인식 장치는, 수신되는 멀티 채널 오디오 신호에 대한 빔포밍 을 수행함으로써, 타겟 음성 신호가 강화된 신호를 생성하고, 강화된 신호에 기초하여 음성 인식을 수행할 수 있다. 일 실시 예에 따른 음성 인식 장치는, 멀티 채널 오디오 신호에 대한 빔포밍을 수행함에 있어서, 결정된 빔의 방향을 나타낼 수 있다. 예를 들어, 음성 인식 장치가 복수의 마이크로폰들을 포함하는 경우, 음성 인식 장치는, 각 마이크로폰이 배치된 위치에 대응하는 위치에 LED를 배치함으로써, 적어도 하나의 LED를 이용하여 빔포밍의 방향을 나타낼 수 있다. 또는, 음성 인식 장치의 주변에 복수의 LED들 또는 원형 LED를 배치함으로써, 복수의 마이크로폰들을 통해 수신되는 오디오 신호들 중에서 타겟 음성을 포함하는 것으로 결정 되는 마이크로폰의 방향을 나타낼 수 있다. 일 예로서, 음성 인식 장치가 어댑티브 빔포밍(adaptive beamforming)을 수행하는 경우, 음성 인식 장치 는, 음성 명령을 발화하는 사용자가 이동함에 따라, 사용자가 이동하는 위치(또는, 업데이트된 빔의 방 향)를 LED를 통해 나타낼 수 있다. 다른 예로서, 음성 인식 장치가 픽스드 빔포밍을 수행하는 경우, 음성 인식 장치는, 고정된 빔의 방향을 LED를 통해 나타낼 수 있다. 또한, 일 실시 예에 따른 음성 인식 장치는, WoV 기능을 이용하여 음성 인식 기능을 활성화 할 수 있다. 일 실시 예에 따른 음성 인식 장치는, 미리 결정된 웨이크 워드에 대한 신호를 계속적으로 모니터링함으로 써, 사용자가 웨이크 워드를 발화하는 경우, 전체 음성 인식 기능을 활성화할 수 있다. 음성 인식 장치 가 웨이크 업 되면, 음성 인식 장치는, 웨이크 워드 이후에 사용자가 발화하는 명령에 대해서 음성 인식을 수행하고, 음성 인식 결과를 출력하거나 음성 인식 결과에 대응하는 소정 동작을 수행할 수 있다. 또한, 도 2b에 도시된 바와 같이, 일 실시 예에 따른 음성 인식 시스템은 제1 음성 인식 장치(200a) 및 제2 음 성 인식 장치(200b)을 포함할 수 있다. 제1 음성 인식 장치(200a) 와 제2 음성 인식 장치(200b)는 유선 또는 무 선으로 연결 될 수 있다. 제1 음성 인식 장치(200a) 및 제2 음성 인식 장치(200b)를 총칭하여 음성 인식 장치 라고 할 수 있다. 예를 들어, 제1 음성 인식 장치(200a)는, 음성 신호를 수신하고 음성 인식 결과를 출력하는 디지털 음성 보조 디바이스일 수 있다. 그러나 실시 예는 이에 제한되지 않고, 제1 음성 인식 장치(200a)는, 웨어러블 디바이스, 스마트폰, 태블릿 PC, PC, 또는 스마트 TV 와 같은 모바일 컴퓨팅 장치이거나 비모바일 컴퓨팅 장치일 수 있다. 제2 음성 인식 장치(200b)는, 스마트폰, 태블릿 PC, PC, 스마트 TV 와 같은 모바일 컴퓨팅 장치이거나 비모바일 컴퓨팅 장치일 수 있다. 제1 음성 인식 장치(200a)는 제2 음성 인식 장치(200b)와 연동할 수 있다. 일 실시예에 따른 제1 음성 인식 장치(200a)와 제2 음성 인식 장치(200b)는, 제어 신호를 송수신 하거나 데이터 를 공유할 수 있다. 일 실시예에 따른 제1 음성 인식 장치(200a)는, 사용자가 발화한 음성 신호를 포함하는 오디오 신호를 입력 받고, 입력된 오디오 신호 또는 압축된 신호를 제2 음성 인식 장치(200b)에게 송신 할 수 있다. 제2 음성 인식 장치(200b)는, 제1 음성 인식 장치(200a)로부터 수신된 신호에 기초하여 음성 인식을 수행할 수 있다. 또는, 제 1 음성 인식 장치(200a)는, 사용자가 발화한 음성 신호를 포함하는 오디오 신호를 입력 받고, 입력된 오디 오 신호로부터 검출된 음성 신호를 제2 음성 인식 장치(200b)에게 송신 할 수 있다. 또는, 제1 음성 인식 장치 (200a)는, 사용자가 발화한 음성 신호를 포함하는 오디오 신호를 입력 받고, 입력된 오디오 신호로부터 검 출된 음성 신호의 특징을 제2 음성 인식 장치(200b)에게 송신 할 수 있다. 또한, 일 실시 예에 따른 음성 인식 장치는, 음성 인식의 정확도를 높이기 위하여 수신되는 오디오 신호에 대해 전처리를 수행할 수 있다. 전처리는 제1 음성 인식 장치(200a)에서 수행되거나, 제2 음성 인식 장치(200 b)에서 수행될 수 있다. 또는, 제1 음성 인식 장치(200a) 및 제2 음성 인식 장치(200b) 각각에서 전처리가 부분 적으로 수행될 수 있다. 일 예로서, 제1 음성 인식 장치(200a)는, 수신된 오디오 신호 또는 압축된 신호를 제2 음성 인식 장치(200b)에 게 송신하고, 제2 음성 인식 장치(200b)는, 수신되는 신호에 대한 전처리를 수행하고 음성 인식을 수행할 수 있 다. 예를 들어, 제1 음성 인식 장치(200a)는, 사용자가 발화한 음성 신호를 포함하는 멀티 채널 오디오 신 호를 입력 받고, 입력된 멀티 채널 오디오 신호를 제2 음성 인식 장치(200b)에게 송신 할 수 있다. 제2 음성 인 식 장치(200b)는, 수신되는 멀티 채널 오디오 신호에 대한 빔포밍을 수행함으로써, 타겟 음성 신호가 강화된 신 호를 생성하고, 강화된 신호에 기초하여 음성 인식을 수행할 수 있다. 다른 예로서, 제1 음성 인식 장치(200a)는, 수신된 오디오 신호에 대한 전처리를 수행하고, 전처리가 수행된 신 호를 제2 음성 인식 장치(200b)에게 송신할 수 있다. 제2 음성 인식 장치(200b)는, 전처리가 수행된 신호에 대 해서 음성 인식을 수행할 수 있다. 예를 들어, 제1 음성 인식 장치(200a)는, 사용자가 발화한 음성 신호를 포함하는 멀티 채널 오디오 신호를 입력 받고, 입력된 멀티 채널 오디오 신호에 대한 빔포밍을 수행함으로써, 타겟 음성 신호가 강화된 신호를 생성할 수 있다. 제1 음성 인식 장치(200a)는, 강화된 신호를 제2 음성 인식장치(200b)에게 송신하고, 제2 음성 인식 장치(200b)는 수신된 강화된 신호에 기초하여 음성 인식을 수행할 수 있다. 또한, 일 실시 예에 따른 음성 인식 장치는, WoV 기능을 이용하여 음성 인식 기능을 활성화 할 수 있다. WoV 동작은 제1 음성 인식 장치(200a)에서 수행되거나, 제2 음성 인식 장치(200b)에서 수행될 수 있다. 또는, 제1 음성 인식 장치(200a) 및 제2 음성 인식 장치(200b) 각각에서 WoV 동작이 부분적으로 수행될 수 있다. 일 예로서, 제2 음성 인식 장치(200b)는 제1 음성 인식 장치(200a)를 통해 수신된 오디오 신호에 웨이크 워드가 포함되는지 여부를 계속적으로 모니터링할 수 있다. 사용자가 웨이크 워드를 발화하는 경우, 제2 음성 인식 장치(200b)는 전체 음성 인식 기능을 활성화할 수 있다. 제2 음성 인식 장치(200b)는, 웨이크 워드 이후에 사용 자가 발화하는 명령에 대해서 음성 인식을 수행하고, 제1 음성 인식 장치(200a)를 통해 음성 인식 결과를 출력 하거나 음성 인식 결과에 대응하는 소정 동작을 수행할 수 있다. 다른 예로서, 제1 음성 인식 장치(200a)는 입력된 오디오 신호에 웨이크 워드가 포함되는지 여부를 계속적으로 모니터링할 수 있다. 사용자가 웨이크 워드를 발화하는 경우, 제1 음성 인식 장치(200a)는 웨이크 워드가 발화되었다는 정보를 제2 음성 인식 장치(200b)에게 알림으로써 제2 음성 인식 장치(200b)의 음성 인식 기능을 웨이크 업 할 수 있다. 제2 음성 인식 장치(200b)는, 웨이크 워드 이후에 사용자가 발화하는 명령에 대해서 음 성 인식을 수행하고, 제1 음성 인식 장치(200a)를 통해 음성 인식 결과를 출력하거나 음성 인식 결과에 대응하 는 소정 동작을 수행할 수 있다. 또한, 도 2c에 도시된 바와 같이, 일 실시예에 따른 음성 인식 시스템은 음성 인식 장치 및 음성 인식 서 버를 포함할 수 있다. 음성 인식 장치 와 음성 인식 서버는 유선 또는 무선으로 연결 될 수 있 다. 일 실시예에 따른 음성 인식 서버는, 음성 인식 장치와 데이터를 공유할 수 있다. 예를 들어, 음성 인식 장치는, 음성 신호를 수신하고 음성 인식 결과를 출력하는 디지털 음성 보조 디바이 스일 수 있다. 그러나 실시 예는 이에 제한되지 않고, 음성 인식 장치는, 웨어러블 디바이스, 스마트폰, 태블릿 PC, PC, 또는 스마트 TV 와 같은 모바일 컴퓨팅 장치이거나 비모바일 컴퓨팅 장치일 수 있다. 일 실시예에 따른 음성 인식 장치는, 사용자가 발화한 음성 신호를 포함하는 오디오 신호를 입력 받고, 입력된 오디오 신호 또는 압축된 신호를 음성 인식 버에게 송신 할 수 있다. 음성 인식 서버는, 음성 인식 장치로부터 수신된 신호에 기초하여 음성 인식을 수행할 수 있다. 또는, 음성 인 식 장치는, 사용자가 발화한 음성 신호를 포함하는 오디오 신호를 입력 받고, 입력된 오디오 신호로부 터 검출된 음성 신호를 음성 인식 서버에게 송신 할 수 있다. 또는, 음성 인식 장치는, 사용자가 발화한 음성 신호를 포함하는 오디오 신호를 입력 받고, 입력된 오디오 신호로부터 검출된 음성 신호의 특징을 음성 인식 서버에게 송신 할 수 있다. 또한, 일 실시 예에 따른 음성 인식 장치는, 음성 인식의 정확도를 높이기 위하여 수신되는 오디오 신호에 대해 전처리를 수행할 수 있다. 전처리는 음성 인식 장치에서 수행되거나, 음성 인식 서버에서 수행 될 수 있다. 또는, 음성 인식 장치 및 음성 인식 서버 각각에서 전처리가 부분적으로 수행될 수 있다. 일 예로서, 음성 인식 장치는, 수신된 오디오 신호 또는 압축된 신호를 음성 인식 서버에게 송신하고, 음성 인식 서버는, 수신되는 신호에 대한 전처리를 수행하고 음성 인식을 수행할 수 있다. 예를 들어, 음성 인식 장치는, 사용자가 발화한 음성 신호를 포함하는 멀티 채널 오디오 신호를 입력 받고, 입력된 멀티 채널 오디오 신호를 음성 인식 서버에게 송신 할 수 있다. 음성 인식 서버는, 수신되는 멀티 채널 오디오 신호에 대한 빔포밍을 수행함으로써, 타겟 음성 신호가 강화된 신호를 생성하고, 강화된 신호 에 기초하여 음성 인식을 수행할 수 있다. 다른 예로서, 음성 인식 장치는, 수신된 오디오 신호에 대한 전처리를 수행하고, 전처리가 수행된 신호를 음성 인식 서버에게 송신할 수 있다. 음성 인식 서버는, 전처리가 수행된 신호에 대해서 음성 인식을 수행할 수 있다. 예를 들어, 음성 인식 장치는, 사용자가 발화한 음성 신호를 포함하는 멀티 채널 오 디오 신호를 입력 받고, 입력된 멀티 채널 오디오 신호에 대한 빔포밍을 수행함으로써, 타겟 음성 신호가 강화 된 신호를 생성할 수 있다. 음성 인식 장치는, 강화된 신호를 음성 인식 서버에게 송신하고, 음성 인 식 서버는 수신된 강화된 신호에 기초하여 음성 인식을 수행할 수 있다. 또한, 일 실시 예에 따른 음성 인식 장치는, WoV 기능을 이용하여 음성 인식 기능을 활성화 할 수 있다. WoV 동작은 음성 인식 장치에서 수행되거나, 음성 인식 서버에서 수행될 수 있다. 또는, 음성 인식장치 및 음성 인식 서버 각각에서 WoV 동작이 부분적으로 수행될 수 있다. 일 예로서, 음성 인식 서버는 음성 인식 장치를 통해 수신된 오디오 신호에 웨이크 워드가 포함되는 지 여부를 계속적으로 모니터링할 수 있다. 사용자가 웨이크 워드를 발화하는 경우, 음성 인식 서버는 전체 음성 인식 기능을 활성화할 수 있다. 음성 인식 서버는, 웨이크 워드 이후에 사용자가 발화하는 명령 에 대해서 음성 인식을 수행하고, 음성 인식 장치를 통해 음성 인식 결과를 출력하거나 음성 인식 결과에 대응하는 소정 동작을 수행할 수 있다. 다른 예로서, 음성 인식 장치는 입력된 오디오 신호에 웨이크 워드가 포함되는지 여부를 계속적으로 모니 터링할 수 있다. 사용자가 웨이크 워드를 발화하는 경우, 음성 인식 장치는 웨이크 워드가 발화되었다 는 정보를 음성 인식 서버에게 알림으로써 음성 인식 서버의 음성 인식 기능을 웨이크 업 할 수 있다. 음성 인식 서버는, 웨이크 워드 이후에 사용자가 발화하는 명령에 대해서 음성 인식을 수행하고, 음 성 인식 장치를 통해 음성 인식 결과를 출력하거나 음성 인식 결과에 대응하는 소정 동작을 수행할 수 있 다. 도 2a, 2b 및 2c에 도시된 바와 같이, 일 실시 예에 따른 음성 인식 시스템은 적어도 하나의 음성 인식 장치를 포함하고, 디바이스 및/또는 음성 인식 서버를 더 포함할 수 있다. 이하에서는, 설명의 편의를 위해 \"음성 인식 장치\" 에서 수행되는 음성 인식 방법에 대해 서술하도록 하겠다. 다만, 이하에서 기술되는 음성 인식 장치의 동 작의 일부 또는 전부는 음성 인식 장치에 연결되는 디바이스 및 음성 인식 서버에서도 수행될 수 있으며, 복수 의 음성 인식 장치들에 의해 부분적으로 수행될 수 있다. 도 3a, 3b 및 3c는 일 실시 예에 따른 음성 인식 장치의 블록도의 예를 도시한다. 도 3a에 도시된 바와 같이, 일 실시 예에 따른 음성 인식 장치는, 수신부, 프로세서, 및 출력부 를 포함할 수 있다. 그러나, 도 3a에 도시된 구성 요소 모두보다 많은 구성 요소에 의해 음성 인식 장치 가 구현될 수도 있다. 예를 들어, 도 3b에 도시된 바와 같이, 일 실시 예에 따른 음성 인식 장치는, 통신부 및 메모리를 더 포함할 수 있다. 또한, 도 3a, 3b 및 3c에서는 편의상 음성 인식 장치가 하나의 프로세서를 포함하는 것으로 도시하였으나, 실시 예는 이에 제한되지 않으며 음성 인식 장치는 복수의 프로세서들을 포함할 수 있다. 음성 인식 장치가 복수의 프로세서들을 포함하는 경우 이하에서 서술하는 프로세서의 동작은 복수의 프로세서들에 의해 나누어 수행될 수 있다. 수신부는, 오디오 신호를 수신할 수 있다. 예를 들어, 수신부는, 마이크로폰(Microphone)에 의해 외 부의 소리를 전기적인 음향 데이터로 변환함으로써 오디오 신호를 직접 수신할 수 있다. 수신부는, 복수의 채널들(예를 들어, 복수의 마이크로폰들)을 통해 멀티 채널 오디오 신호를 수신할 수 있다. 또는, 수신부는, 외부 장치에서 송신된 오디오 신호를 수신할 수 있다. 도 3a 및 3b에는, 수신부가, 음성 인식 장치의 내부에 포함되는 것으로 도시되었으나, 다른 일 실시 예에 따른 수신부는 별도의 장치 내에 포함되고 음성 인식 장치와는 유,무선으로 연결되는 형태로 구현될 수 있다. 수신부는, 멀티 채널 오디오 신호를 수신할 수 있다. 멀티 채널 오디오 신호는 복수의 채널들 각각으로부 터 수신되는 복수의 오디오 신호들을 포함할 수 있다. 본 개시의 일 실시 예에 따른 프로세서는, 수신부를 통해 수신되는 오디오 신호에 대해 음성 인식을 수행할 수 있다. 또한, 프로세서는, 음성 인식의 정확도를 높이기 위하여 수신되는 오디오 신호에 대해 전 처리를 수행할 수 있다. 예를 들어, 프로세서는, 수신되는 멀티 채널 오디오 신호에 대한 빔포밍을 수행함 으로써, 타겟 음성 신호가 강화된 신호를 생성하고, 강화된 신호에 기초하여 음성 인식을 수행할 수 있다. 또한, 프로세서는, WoV 기능을 이용하여 음성 인식 기능을 활성화 할 수 있다. 이하에서는, 일 실시 예에 따른 프로세서에 의해 수행되는 전처리 방법을 구체적으로 설명한다. 프로세서는, 제1 멀티 채널 오디오 신호에 포함되는 각 채널 오디오 신호로부터 주파수 대역별 음성 신호 특성 및 노이즈 신호 특성을 획득할 수 있다. 프로세서는, 각 채널 오디오 신호에 대해 주파수 변환을 수행함으로써 주파수 빈 값들을 획득할 수 있다. 프로세서는, 획득된 주파수 빈 값들에 대해 마스크를 적용함으로써, 획득된 주파수 빈 값들을 음성에 해당 하는 값들과 노이즈에 해당하는 값들로 구분할 수 있다. 프로세서는, 음성에 해당하는 값들과 노이즈에 해당하는 값들에 기초하여, 주파수 대역별 음성 교차 파워 스펙트럴 밀도(cross-PSD(Power Spectral Density)) 및 노이즈 교차 파워 스펙트럴 밀도를 각각 획득할 수 있다. 예를 들어, 제1 멀티 채널 오디오 신호가 M개의 채널들을 통해 수신된 M개의 오디오 신호들을 포함하는 경우, 음성 교차 파워 스펙트럴 밀도 및 노이즈 교차 파워 스펙트럴 밀도는 MxM 매트릭스의 형태일 수 있다. 프로세서는, 음성 신호 특성 및 노이즈 신호 특성을 획득하기 위해 이용되는 마스크를 추정할 수 있다. 프 로세서는, 마스크를 추정하기 위하여, 제1 멀티 채널 오디오 신호에 대해 중간값 필터를 적용함으로써, 단 일 채널 오디오 신호로 변환할 수 있다. 프로세서는, 단일 채널 오디오 신호에 대한 신경망 분석을 통해 주파수 대역별 마스크 값을 추정할 수 있다. 프로세서는, 음성 신호 특성, 소정 시간 전에 획득된 음성 신호 특성 및 노이즈 신호 특성에 기초하여 멀 티 채널 오디오 신호에 대해 빔포밍을 수행할 수 있다. 프로세서는, 빔포밍의 결과로서 음성 성분이 강화 된 신호를 생성할 수 있다. 소정 시간은 예를 들어, 미리 결정된 웨이크 워드의 길이 및 프레임 단위를 고려하 여 미리 결정된 시간일 수 있다. 프로세서는, 음성 신호 특성 및 노이즈 신호 특성에 기초하여 제1 멀티 채널 오디오 신호에 대해 제1 빔포 밍을 수행함으로써, 제1 강화 신호를 생성할 수 있다. 프로세서는, 음성 신호 특성 및 M 프레임 이 전에 획득된 음성 신호 특성에 기초하여 제1 멀티 채널 오디오 신호에 대해 제2 빔포밍을 수행함으로써, 제2 강화 신 호를 생성할 수 있다. 제2 강화 신호는, 현재 프레임에 대해 획득된 음성 신호 특성으로부터 M 프레임 이전에 획득된 음성 신호 특성이 제거된 신호일 수 있다. 프로세서는, 음성 성분이 강화된 신호에 기초하여 음성 인식 동작을 활성화 할 수 있다. 프로세서는, 제1 빔포밍에 기초하여 생성된 제1 강화 신호 및 제2 빔포밍에 기초하여 생성된 제2 강화 신 호에 기초하여 음성 인식 동작을 활성화 할 수 있다. 프로세서는, 제1 강화 신호 또는 제1 강화 신호 내에 기 설정된 단어가 포함된다는 판단에 기초하여, 음성 인식 동작을 활성화할 수 있다. 프로세서는, 새롭게 수신되는 제2 멀티 채널 오디오 신호에 대해 음성 인식을 수행할 수 있다. 프로세서 는, 사용자가 기 설정된 단어(예를 들어, 웨이크 워드)를 발화한 이 후에 발화하는 음성 신호를 포함하는 제2 멀티 채널 오디오 신호에 대해 음성 인식을 수행할 수 있다. 예를 들어, 제1 멀티 채널 오디오 신호가 웨이 크 워드를 포함하는 신호라면, 제2 멀티 채널 오디오 신호는 웨이크 워드 이후에 발화되는 사용자 명령을 포함 하는 신호일 수 있다. 프로세서는, 제1 강화 신호 내에 기 설정된 단어가 포함된다는 판단에 기초하여 음성 인식 동작이 활성화 된 경우, 새롭게 수신되는 제2 멀티 채널 오디오 신호에 대해 어댑티브 빔포밍을 수행할 수 있다. 프로세서 는, 제1 멀티 채널 오디오 신호 이후에 수신되는 제2 멀티 채널 오디오 신호에 대한 파라미터들을 업데이 트함으로써, 업데이트된 파라미터들에 기초하여 어댑티브 빔포밍을 수행할 수 있다. 예를 들어, 프로세서 는, 제2 멀티 채널 오디오 신호의 매 프레임마다 파라미터들을 업데이트함으로써, 업데이트된 파라미터들에 기 초하여 어댑티브 빔포밍을 수행할 수 있다. 또는, 프로세서는, 소정 프레임 간격으로 빔포밍 파라미터들을 업데이트함으로써, 업데이트된 파라미터들에 기초하여 어댑티브 빔포밍을 수행할 수 있다. 반면에, 프로세서는, 제1 강화 신호 내에는 기 설정된 단어가 포함되지 않고 제2 강화 신호 내에 기 설정 된 단어가 포함된다는 판단에 기초하여 음성 인식 동작이 활성화 된 경우, 제2 멀티 채널 오디오 신호에 대해 픽스드 빔포밍을 수행할 수 있다. 프로세서는, 제2 강화 신호 생성 시에 이용되었던 파라미터들에 기초하 여, 제1 멀티 채널 오디오 신호 이후에 수신되는 제2 멀티 채널 오디오 신호에 대해서 픽스드 빔포밍을 수행할 수 있다. 일 실시 예에 따른 프로세서는 입력 오디오 신호로부터 음성 신호의 주파수 특성을 추출하고, 음향 모델과 언어 모델을 이용하여 음성 인식을 수행 할 수 있다. 주파수 특성은, 음향 입력의 주파수 스펙트럼을 분석하여 추출되는, 음향 입력의 주파수 성분들의 분포를 의미할 수 있다. 따라서, 도 3b에 도시된 바와 같이, 음성 인식 장치는, 음향 모델과 언어 모델을 저장하는 메모리를 더 포함할 수 있다. 출력부는, 음성 신호에 대해서 음성 인식이 수행된 결과를 출력 할 수 있다. 출력부는, 음성 인식이 수행된 결과를 사용자에게 알리거나, 외부 디바이스(예를 들어, 스마트 폰, 가전 제품, 웨어러블 디바이스, 엣 지 디바이스, 서버 등)에게 전송할 수 있다. 예를 들어, 출력부는, 오디오 신호로 출력할 수 있는 스피커 또는 비디오 신호를 출력 할 수 있는 디스플레이를 포함할 수 있다.또는, 출력부는, 음성 인식이 수행된 결과에 대응하는 동작을 수행할 수 있다. 예를 들어, 음성 인식 장치 는, 음성 인식이 수행된 결과에 대응하는 음성 인식 장치의 기능을 결정하고, 해당 기능을 수행하는 화면을 출력부를 통해 출력할 수 있다. 또는, 음성 인식 장치는, 음성 인식이 수행된 결과에 대응하 는 키워드를 외부 서버로 전송하고, 전송된 키워드에 관련된 정보를 서버로부터 수신하여 출력부를 통해 화면 상에 출력할 수 있다. 도 3b의 통신부는 유선 통신 또는 무선 통신을 통해 외부 디바이스, 장치 또는 서버와 통신할 수 있다. 통 신부는, 외부 장치로부터 오디오 신호, 음성 신호, 음성 신호의 특징, 음성 인식 수행 결과, 웨이크 워드 와 관련된 정보, 전처리를 위한 파라미터 등을 수신할 수 있다. 또는, 통신부는, 외부 장치에게 오디오 신 호, 음성 신호, 음성 신호의 특징, 음성 인식 수행 결과, 웨이크 워드와 관련된 정보, 전처리를 위한 파라미터 등을 송신할 수 있다. 일 실시 예에 따른 통신부는, 근거리 통신 모듈, 유선 통신 모듈, 이동 통신 모듈, 방송 수신 모듈 등을 포함할 수 있다. 도 3b의 메모리는, 음성 인식을 수행하기 위한 음향 모델, 언어 모델, 화자 인식을 수행하기 위한 등록된 화자의 음성 신호에 대한 등록 화자 모델, 음성 인식 히스토리, 웨이크 워드와 관련된 정보, 이 전 프레임으로 부터 획득된 신호 특성 등을 저장할 수 있다. 한편, 도 3c에 도시된 바와 같이, 일 실시 예에 따른 음성 인식 서버는, 통신부 및 프로세서를 포함할 수 있다. 도 3c의 통신부 및 프로세서는 도 3a 및 3b의 통신부 및 프로세서에 대응 되므로 중복되는 설명은 생략한다. 일 실시 예에 따른 음성 인식 서버는, 통신부를 통해 음성 인식 장치로부터 오디오 신호 또는 압축된 신호를 수신할 수 있다. 또는, 음성 인식 서버는, 통신부를 통해 음성 인식 장치에서 전 처리가 수행된 신호를 수신할 수 있다. 프로세서는, 수신된 신호에 대한 음성 인식을 수행할 수 있다. 일 예로서, 프로세서는, 이 전 프레임으로부터 획득된 음성 신호 특성에 기초하여, 제1 멀티 채널 오디오 신호의 현재 프레임에 대한 빔포밍을 수행함으로써, 음성 성분이 강화된 신호를 생성할 수 있다. 또는, 프로세 서는, 음성 인식 장치로부터 음성 성분이 강화된 신호를 수신할 수 있다. 프로세서는, 음성 성 분이 강화된 신호에 기초하여 음성 인식 동작을 활성화 하고, 새롭게 수신되는 제2 멀티 채널 오디오 신호에 대 해 음성 인식을 수행할 수 있다. 다른 예로서, 프로세서는, 음성 인식 장치로부터 수신되는 웨이크 업 여부를 알리는 신호에 기초하여 음성 인식 동작을 활성화 하고, 새롭게 수신되는 제2 멀티 채널 오디오 신호에 대해 음성 인식을 수행할 수 있 다. 프로세서는, 음성 인식 장치에게 음성 인식 결과를 출력하도록 통신부를 제어할 수 있다. 이하에서는, 일 실시 예에 따른 음성 인식 장치 또는 음성 인식 서버의 구체적인 동작 방법을 설명한 다. 이하에서 서술하는 방법의 각 단계는, 상술한 음성 인식 장치의 각 구성들에 의해 수행될 수 있다. 설 명의 편의상 음성 인식 장치가 동작의 주체인 경우만을 예로 들어 설명하였지만, 이하의 설명은 복수의 음 성 인식 장치들을 연결하는 디바이스 또는 음성 인식 서버가 동작의 주체인 경우에도 적용될 수 있다. 도 4는 일반적으로 이용되는 웨이크 업 방식을 도시한다. WoV 기술을 이용하는 음성 인식 장치를 사용함에 있어서, 먼 거리에 위치한 사용자가 발화한 음성 신호는, 음성 인식 장치에게 전달되는 도중에 노이즈와 잔향으로 인해 품질이 심각하게 저하될 수 있다. 따라서, 음성 인식 장치에 수신되는 오디오 신호 내에 웨이크 워드가 포함되어 있는지 여부를 판단하기에 앞서, 오디오 신호에 포 함되는 노이즈와 잔향을 제거하기 위한 전처리가 요구된다. 특히, 음성 인식 장치로부터 먼 거리에 위치한 사용자의 음성에 의한 웨이크 업 정확도를 높이기 위하여, 다 채 널 음성 강조(multi-channel speech enhancement)가 이용될 수 있다. 예를 들어, 다 채널 음성 강조 방법으로 서 빔포밍이 이용될 수 있다. 빔 포밍이란 타겟 신호를 강화하기 위해 시공간 필터를 설계하는 것을 의미한다. 일반적으로 이용되는 전처리 기법은, 멀티 채널 오디오 신호에 대해 빔포밍을 수행함으로써 음성 강화 신호를 생성하는 단계 및 음성 강화 신호에 기초하여 웨이크 업 여부를 결정하는 단계를 포함할 수 있다. 일반적인 전처리 기법에 따르면, GEV(Generalized Eigenvalue) 빔포머가 이용될 수 있다. 아래의 [수학식 1]에 따라서, GEV 빔포머는 멀티 채널 오디오 신호를 주파수 변환함으로써 획득된 시간-주파수 빈 값들 각각에 대해서 SNR(Signal Noise Ratio)을 최대로 하는 파라미터들을 획득할 수 있다. 예를 들어, GEV 빔포머는, 타겟 음성 신호를 강화하기 위한 필터를 구성하기 위해 이용되는 필터 계수들을 획득할 수 있다. [수학식 1]"}
{"patent_id": "10-2019-0058983", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "[수학식 1]에서 P{A}는 A의 제1 주성분(1st Principle Component)을 나타낸다. Rs(f, n)은 각 시간-주파수 빈의 음성 신호 특성이고, Rn(f, n)은 각 시간-주파수 빈의 노이즈 신호 특성일 수 있다. 예를 들어, Rs(f, n)은 깨끗 한 음성(clean speech)의 교차 파워 스펙트럴 밀도이고, Rn(f, n)은 노이즈의 교차 파워 스펙트럴 밀도일 수 있 다. f는 주파수 빈을 나타내는 주파수 인덱스(frequency index)를 나타내고, n은 빔포밍 대상이 되는 멀티 채널 오디오 신호의 프레임의 인덱스(frame index)를 나타낸다. 예를 들어, 멀티 채널 오디오 신호가 M채널 입력 신 호인 경우, Rs(f, n) 및 Rn(f, n)는 MxM 매트릭스로 표현될 수 있다. 도 4의 웨이크 업 단계에서 음성 인식 장치는, 빔포밍에 의해 타겟 음성 성분이 강화된 신호를 분석 하고, 신호 내에 미리 결정된 웨이크 워드가 포함되어 있는지 여부를 결정할 수 있다. 음성 인식 장치는, 신호 내에 미리 결정된 웨이크 워드가 포함되는 경우, 음성 인식 기능을 웨이크 업 할 수 있다. 다만, 도 4에 도시된 일반적인 전처리 기술은, 타겟 음성 신호와 노이즈 신호의 스펙트럼 분포가 서로 구별될 수 있다는 가정에 기초한 것이다. 따라서, 앞에서 도 1을 참조하여 설명한 것과 같이 노이즈 신호에 음성 노이 즈가 포함되는 경우, 웨이크 업 정확도가 떨어질 수 있다. 음성 노이즈가 존재하는 환경에서 웨이크 업 정확도가 떨어지는 이유를 구체적으로 설명하면, 전처리 단계에서, 각 시간- 주파수 빈 내에 음성 성분이 우세한 지 노이즈 성분이 우세한 지를 판단하기 위한 스펙트럼 마스크가 추정될 수 있다. 추정되는 마스크는, 각 시간-주파수 빈 내에서 음성 성분의 비율을 가리키는 음성 마스크와 노 이즈 성분의 비율을 가리키는 노이즈 마스크를 포함할 수 있다. 음성 간섭 환경에서는, 음성 노이즈가 우세한 시간-주파수 빈의 음성 마스크가 크게 추정될 수 있다. 따라서, 빔포밍 단계에서 음성 노이즈가 포함된 음성 성 분이 강화됨으로써, 품질이 저하된 신호가 출력될 수 있다. 이러한 문제점을 해결하기 위해, 본 개시에서는 음성 간섭에 강인한 WoV를 위한 새로운 전처리 방법을 제안한다. 음성 간섭에 강인하게 동작하기 위하여, 본 개시의 일 실시예에 따른 음성 인식 장치는 음성 간 섭에 강인한 빔포머(Speech-Interference Robust Beamformer)를 추가로 포함할 수 있다. 본 개시의 일 실시 예에 따른 음성 간섭에 강인한 빔포머는, 현재 프레임의 음성 특성으로부터 소정 시간 전의 프레임의 음성 특성을 제거하도록 동작할 수 있다. 소정 시간은, 웨이크 워드의 길이, 사용자의 발화 특성, 사 용자가 웨이크 워드를 발화하는 데 소요되는 시간 등에 따라서 변경될 수 있다. 예를 들어, 웨이크 워드는 매우 짧은 시간(예를 들어, 1초 미만) 내에 발화된다는 특징에 기초하여, 음성 간섭 에 강인한 빔포머는, 소정 시간(예를 들어, 1초) 전의 음성 입력 특성과 현재 음성 입력 특성의 차이를 이용하 여 빔포밍을 수행할 수 있다. 도 5에 도시된 바와 같이, 본 개시의 일 실시예에 따른 음성 인식 장치는, 전처리를 위하여 일반적인 빔포 밍 방식을 수행하는 제1 빔포밍부와 새롭게 제안되는 빔포밍 방식을 수행하는 제2 빔포밍부를 포함하 고, 제1 빔포밍부 및 제2 빔포밍부에 의해 음성 성분이 강화된 신호들에 기초하여 웨이크 업 여부를 결정하는 듀얼 웨이크 업(Dual Wake up) 모듈을 포함할 수 있다. 한편, 본 개시의 일 실시 예에 따르면, 도 5에 도시된 빔포밍 이외에도 다양한 전처리 동작이 수행될 수 있다. 예를 들어, 빔포밍을 수행하기 이전에 자동 에코 삭제(Automatic Echo Cancelation, AEC), 레지듀얼 에코 저하 (Residual Echo Suppression) 등이 수행될 수 있다. 또한, 멀티 채널 오디오 신호들에 대해 빔포밍을 수행함으 로써 출력된 단일 채널 신호에 대해 노이즈 저하(Noise Suppression)가 추가로 수행될 수 있다. 도 5의 제1 빔포밍부가 수행하는 일반적인 빔포밍 방식은, 도 4의 빔포밍부에서 수행되는 방식과 동 일하므로 중복되는 설명은 생략한다. 제2 빔포밍부에 포함되는 새롭게 제안되는 GEVprop 빔포머에는, [수학식 2]와 같이, 변형된 노이즈 신호 특 성 이 적용될 수 있다. [수학식 2]"}
{"patent_id": "10-2019-0058983", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "[수학식 2]에서 는 M 프레임 이 전의 음성 신호 특성을 나타낸다. 예를 들어, 는 M 프레임 이 전 프레임으로부터 획득된 음성 교차 파워 스펙트럴 밀도일 수 있다. 제안되는 GEVprop 빔포머는 현재 프레임의 입력으로부터 M 프레임 이전 프레임의 음성 신호 특성 에 해당 하는 성분을 제거하도록 동작할 수 있다. 예를 들어, 1 프레임은 16ms이고 M이 60인 경우, 제안되는 GEVprop 빔포머는, 현재 음성의 특성으로부터 0.96초 전에 음성으로 추정된 특성을 제거하도록 동작할 수 있다. 따라서, 본 개시에서 제안되는 GEVprop 빔포머는, 음성 간섭 환경에서도, 음성 노이즈를 제거함으로써 타겟 음성이 강화된 신호를 출력함으로써, 웨이크 업 성능을 개 선할 수 있다. 다만, 본 개시에서 제안되는 GEVprop 빔포머는 [수학식 2]에 제한되지 않으며, 음성 신호 특성 Rs(f, n) 대신에 전체 입력 신호 특성 R(f, n)이 사용될 수 있다. 도 5에 도시된 바와 같이, 본 개시의 일 실시 예에 따른 음성 간섭에 강인한 듀얼 웨이크 업 방식에 의하면, 일 반적인 전처리 방법에 의한 출력과 음성 간섭에 강인한 전처리 방법에 의한 출력이 동시에 생성될 수 있다. 일반적인 빔포밍 방식을 수행하는 제1 빔포밍부와 새롭게 제안되는 빔포밍 방식을 수행하는 제2 빔포밍부 는 상호 보완적이다. 따라서 본 개시의 일 실시 예에 따른 음성 인식 장치는, 제1 빔포밍부와 제2 빔 포밍부를 병렬로 사용하여 음성 강화를 수행함으로써, 두 개의 별도의 강화 된 음성 신호들을 생성할 수 있다. 강화된 음성 신호들 각각은 듀얼 웨이크 업 모듈에 공급되고, 듀얼 웨이크 업 모듈 은 강화된 음성 신호들에 기초하여 웨이크 업 여부를 결정할 수 있다. 일 예로서, 듀얼 웨이크 업 모듈 은, 제1 빔포밍부로부터 출력되는 제1 강화 신호 또는 제2 빔포밍부 로부터 출력되는 제2 강화 신호에 미리 결정된 웨이크 워드가 포함되는 것으로 판단되면, 음성 인식 기능 을 웨이크 업 할 것을 결정할 수 있다. 다른 예로서, 듀얼 웨이크 업 모듈 은, 제1 강화 신호에 미리 결정된 웨이크 워드가 포함되는 확률 (confidence score) 및 제2 강화 신호에 미리 결정된 웨이크 워드가 포함되는 확률의 가중치 합(weighted su m)에 기초하여, 음성 인식 기능을 웨이크 업 여부를 결정할 수 있다. 한편, 본 개시의 일 실시 예에 따른 음성 인식 장치는, 음성 간섭 환경에서 웨이크 업 된 경우, 웨이크 업 에 성공한 전처리에 대응하는 빔으로 고정하여 음성 인식을 수행할 수 있다. 본 개시의 일 실시 예에 따른 음성 인식 장치는, 일반적인 환경에서는 어댑티브 빔포밍을 수행함으로써, 이동하는 음원의 위치를 따라가면서 적응적으로 빔포밍을 수행할 수 있다. 반면에, 음성 인식 장치는, 음 성 간섭 환경에서는, 화자가 웨이크 워드를 발화한 위치와 동일한 위치에서 이어지는 명령을 발화한다고 가정하 고, 픽스드 빔포밍을 수행함으로써 음성 노이즈의 간섭을 최소화 하여 음성 인식 정확도를 높일 수 있다. 웨이크 업 후 ASR 단계에서 어댑티브 빔포밍과 픽스드 빔포밍을 선택적으로 수행하는 구체적인 방법과 관련하여 서는, 후에 도 9를 참조하여 보다 구체적으로 설명한다. 이하에서는, 도 6을 참조하여, 도 5에 도시된 본 개시의 일 실시 예에 따른 듀얼 빔포머의 구체적인 동작을 설 명한다. 본 개시의 일 실시 예에 따른 음성 인식 장치는, 멀티 채널 오디오 신호에 대해 윈도윙 및 주파수 변환을 수행할 수 있다. 예를 들어, 본 개시의 일 실시 예에 따른 음성 인식 장치는, 윈도윙 및 STFT(Short- time Fourier Transform)을 수행할 수 있다. 도 7에 도시된 바와 같이, 일 실시 예에 따른 음성 인식 장치는 수신된 오디오를 소정 시간 간격으로 샘플 링함으로써 획득된 오디오 신호에 대해 윈도윙을 수행하여 소정 시간 영역의 프레임들을 획득할 수 있다. 음성 인식 장치는, 프레임들을 시간-주파수 변환함으로써 주파수 대역별 주파수 빈 값들 을 획득할 수 있다. M 개의 마이크들을 통해 입력된 M-채널 오디오 신호에 대해 K차 STFT를 적용하는 경우를 예로 들어 설명한다. 각 채널의 오디오 신호에 대해 매 프레임마다 컴플렉스 고속 푸리에 트랜스폼(Complex Fast Fourier Transfor m)을 수행한 뒤, 절반을 취하면 (K/2+1)차 주파수 빈 값들이 획득된다. 본 개시의 일 실시 예에 따른 음성 인식 장치는, 획득된 주파수 빈 값들에 대해서 마스크를 추정할 수 있다. 음성 인식 장치는, 각 주파수 빈 상의 음성 성분(speech component) 또는 노이즈 성분(noise component) 의 존재를 나타내는 스펙트럼 마스크를 추정할 수 있다. 추정된 마스크는, 시공간 필터(spatio-temporal filter)의 계수, 즉 빔 포머의 파라미터를 구성하는데 필요한 음성 신호 통계 및 노이즈 신호 통계를 계산하는 데 사용될 수 있다. 본 개시의 일 실시 예에 따른 음성 인식 장치는, 2 개의 마스크들을 추정할 수 있다. 추정되는 마스크들 중 하나는, 어떠한 시간-주파수 빈들이 음성이 우세한 것으로 짐작되는 지(which time-frequency bins are presumably dominated by speech)를 나타낼 수 있다. 다른 하나는 어떠한 시간-주파수 빈들이 노이즈가 우세한 것으로 짐작되는 지(which time-frequency bins are presumably dominated by noise)를 나타낼 수 있다. 추정된 마스크들은, 각 주파수 대역의 노이즈 신호 특성 및 음성 신호 특성을 추정하는 데 사용될 수 있다. 음성 인식 장치는, 추정 된 마스크 값을 각 주파수 빈에 대해서 적용함으로써, 오디오 신호 중 음성(Clean Speech)에 해당하는 부분과 노이즈에 해당하는 부분을 구분할 수 있다. 음성 인식 장치는, 음성 신호 특성 및 노이즈 신호 특성으로서 각각 음성 교차 파워 스펙트럴 밀도와 노이즈 교차 파워 스펙트럴 밀도를 계산할 수 있다. M-채널 오디오 신호가 수신되는 경우를 예로 들어 설명하면, 음성 인식 장치는, 각 시간-주파수 빈에 대한 M-채널 입력 특성을 M x M 교차 파워 스펙트럴 밀도(Cross-PSD)로 나타낼 수 있다. M x M 교차 파워 스펙트럴 밀도에서 대각선(Diagonal) 값은 각 채널 오디오 신호의 파워를 의미할 수 있다. M x M 교차 파워 스펙트럴 밀 도에서 대각선 이외의(Off-diagonal) 값은 두 채널 오디오 신호들 간의 상관 관계를 의미하고, 위상(Phase) 값 은 두 채널 오디오 신호들 간의 시간 딜레이(Time-delay) 정도를 의미할 수 있다. 본 개시의 일 실시 예에 따르면, 빔 포밍 기반의 음성 인식 성능을 향상시키기 위하여, 신경망을 이용한 GEV(Neural Network Supported Generalized Eigenvector, NN-GEV) 빔포머가 이용될 수 있다. NN-GEV 빔포밍은, 딥 러닝 기반의 시간-주파수 마스크 추정과 GEV 빔포밍을 결합한 방식이다. NN 기반 분류기를 이용하여 마스크 를 추정하는 구체적인 방법과 관련하여서는, 후에 도 10 및 도 11을 참조하여 보다 구체적으로 설명한다. 음성 인식 장치는, 이 전 프레임에 대해 획득되었던 노이즈 신호 특성을 현재 프레임에 대해 추정된 마스 크에 기초하여 업데이트함으로써, 노이즈 신호 특성을 새롭게 획득할 수 있다. 음성 인식 장치는, 이 전 프레임에 대해 획득되었던 음성 신호 특성을 현재 프레임에 대해 추정된 마스크에 기초하여 업데이트함으로 써, 음성 신호 특성을 새롭게 획득할 수 있다. 음성 인식 장치는 현재 프레임에 대해서 획득된 노이즈 신호 특성 및 음성 신호 특성에 기초하여 빔포밍 을 수행할 수 있다. 빔포밍 방식은, 도 4의 빔포밍부에서 수행되는 방식과 동일하므로 중복되는 설명은 생략한다. 음성 인식 장치는, 빔포밍이 수행된 결과에 대해 역 고속 푸리에 변환(Inverse Fourier Transform) 및 오 버랩 애드(Overlap Add)를 수행함으로써 음성 성분이 강화된 출력 신호를 생성할 수 있다. 한편, 음성 인식 장치는, 현재 프레임으로부터 획득된 음성 신호 특성 및 M 프레임 이 전에 획득되었던 음 성 신호 특성에 기초하여, 본 개시에서 새롭게 제안되는 음성 간섭에 강인한 빔포밍을 수행할 수 있 다. 본 개시에서 새롭게 제안되는 빔포밍 방식은 도 5의 제2 빔포밍부에서 수행되는 방식과 동일하므 로 중복되는 설명은 생략한다. 다음으로, 음성 인식 장치는, 빔포밍이 수행된 결과에 대해 역 고속 푸리에 변환 및 오버랩 애드를 수행함 으로써 음성 성분이 강화된 출력 신호를 생성할 수 있다. 상술한 바와 같이, 본 개시의 일 실시 예에 따라 빔포밍 방식을 이용하는 전처리 기술에 의하면, 멀티 채널을 통해 수신되는 오디오 신호들 중에서 웨이크 워드가 포함되는 오디오 신호를 결정하여 웨이크 업 모듈에 전달함 으로써 웨이크 업을 위한 음성 인식 성능을 향상 시킬 수 있다. 따라서, 본 개시의 일 실시 예에 따라 빔포밍 방식을 이용하는 전처리 기술에 의하면, 음성 인식 장치로부터 먼 거리에 위치한 사용자의 발화에 대해서 도 음성 인식 성능을 향상 시킬 수 있다. 또한, 종래의 단일 채널에 기반한(또는 하나의 기준 채널 및 하나의 보조 채널을 포함하는 두 채널에 기반한) 적응적 노이즈 삭제(Adaptive Noise Cancellation, ANC) 방식에 의하면, 음성 간섭이 없는 일반적인 환경에서도 왜곡된 음성 신호를 출력하므로 ASR에서 높은 성능을 기대할 수 없다는 단점이 있었다. 그러나, 본 개시의 일 실시 예에 따르면, 도 6에 도시된 빔포밍(651, 652)이 수행된 이후에 다양한 후처리 동작 이 수행될 수 있다. 예를 들어, 빔포밍을 수행한 결과에 추가적인 포스트 필터링(post filter)을 적용함으로써 왜곡을 더욱 감소시킬 수 있다. 본 개시의 일 실시 예에 따른 전처리 방법은, 포스트 필터링의 예로서, BAN(Blind Analytic Normalization) 필터링을 수행함으로써 왜곡 없는 MVDR(Minimum Variance Distortionless Response)빔포밍을 수행할 수 있다. 본 개시의 일 실시 예에 따른 전처리 방법은 GEV 빔포빙 결과물에 BAN 필터 를 추가로 이용하는 MVDR 빔포밍 방식을 이용함으로써 음성 간섭 환경 뿐만 아니라 일반적인 환경에서도 왜곡 없는 음성 강화 신호를 출력할 수 있다. 본 개시의 일 실시 예에 따르면, 이 전에 수신되었던 프레임으로부터 획득되었던 필터 계수를 현재 프레임에 그 대로 적용하는 것이 아니라, 과거에 추정했던 음성 성분에 대한 통계(예를 들어, 음성 교차 파워 스펙트럴 밀도)와 현재 추정한 음성 성분에 대한 통계를 이용하여 현재 프레임에 대한 필터 계수를 결정하는 것이므로, 보다 왜곡 없는 음성 강화 신호를 출력할 수 있다. 또한, 본 개시의 일 실시 예에 따라 획득되는 교차 파워 스펙트럴 밀도는, 빔포밍 뿐만 아니라, 노이즈 저하 (Noise Suppression), 사운드 소스 로컬리제이션(Sound Source Localization) 등의 다양한 전처리 기술에 이용 될 수 있다. 이하에서는, 도 8을 참조하여, 상술한 실시 예들에 따른 음성 인식 장치가 듀얼 빔포밍 방식을 이용하여 웨이크 업 되고 음성 인식을 수행하는 전체적인 동작 방법을 설명한다. 도 8에 도시된 음성 인식 방법은, 도 3a, 도 3b 또는 도 3c에 도시된 음성 인식 장치 및 음성 인식 서버 에서 처리되는 단계들로 구성된다. 따라서, 이하에 생략된 내용이라 하더라도 음성 인식 장치 및 음 성 인식 서버 에 관하여 상술된 내용은 도 8 의 음성 인식 방법에도 적용될 수 있다. 중복되는 설명은 생 략한다. 단계 S810에서 일 실시 예에 따른 음성 인식 장치는, 제1 멀티 채널 오디오 신호를 수신할 수 있다. 멀티 채널 오디오 신호는, 음성 인식 장치에 구비된 복수의 마이크들 각각으로부터 수신되는 오디오 신호 들을 포함할 수 있다. 단계 S820에서 일 실시 예에 따른 음성 인식 장치는, 제1 멀티 채널 오디오 신호에 포함되는 각 채널 오디 오 신호로부터 주파수 대역별 음성 신호 특성 및 노이즈 신호 특성을 획득할 수 있다. 음성 인식 장치는, 각 채널 오디오 신호에 대해 주파수 변환을 수행함으로써 주파수 빈 값들을 획득할 수 있다. 음성 인식 장치는, 마스크를 추정하고, 추정된 마스크를 획득된 주파수 빈 값들에게 적용함으로써, 획득된 주파수 빈 값들을 음성에 해당하는 값들과 노이즈에 해당하는 값들로 구분할 수 있다. 음성 인식 장치 는, 음성에 해당하는 값들과 노이즈에 해당하는 값들에 기초하여, 주파수 대역별 음성 교차 파워 스펙트럴 밀도 및 노이즈 교차-파워 스펙트럴 밀도를 각각 획득할 수 있다. 예를 들어, 제1 멀티 채널 오디오 신호가 M개의 채널들을 통해 수신한 M개의 오디오 신호들을 포함하는 경우, 음성 인식 장치는, 각 주파수 빈에 대해서 M 채널 오디오 신호들에 대한 MxM 음성 교차-파워 스펙트럴 밀 도 및 MxM 노이즈 교차-파워 스펙트럴 밀도를 획득할 수 있다. 음성 인식 장치는, 신경망을 이용하여, 음성 신호 특성 및 노이즈 신호 특성을 획득하기 위해 이용되는 마 스크를 추정할 수 있다. 음성 인식 장치는, 제1 멀티 채널 오디오 신호에 대해 중간값 필터를 적용함으로 써, 단일 채널 오디오 신호로 변환하고, 단일 채널 오디오 신호에 대한 신경망 분석을 통해 주파수 대역별 마스크 값을 추정할 수 있다. 단계 S830에서 일 실시 예에 따른 음성 인식 장치는 음성 신호 특성, 소정 시간 전에 획득된 음성 신호 특 성 및 노이즈 신호 특성에 기초하여 제1 멀티 채널 오디오 신호에 대해 빔포밍을 수행함으로써, 음성 성분이 강 화된 신호를 생성할 수 있다. 음성 인식 장치는, 단계 S820에서 획득된 현재 프레임에 대한 음성 신호 특성 및 노이즈 신호 특성에 기초 하여, 제1 멀티 채널 오디오 신호에 대해 제1 빔포밍을 수행함으로써, 제1 강화 신호를 생성할 수 있다. 제1 강 화 신호는 오디오 신호로부터 노이즈 신호 특성이 제거된 신호일 수 있다. 또한, 음성 인식 장치는, 현재 프레임에 대한 음성 신호 특성 및 M 프레임 이 전의 프레임에 대해 획득된 음성 신호 특성에 기초하여, 제1 멀티 채널 오디오 신호에 대해 제2 빔포밍을 수행함으로써, 제2 강화 신호를 생성할 수 있다. 제2 강화 신호는, 음성 신호 특성으로부터 M 프레임 이전에 획득된 음성 신호 특성이 제거된 신호일 수 있다. 단계 S840에서 일 실시 예에 따른 음성 인식 장치는 음성 성분이 강화된 신호에 기초하여 음성 인식 동작 을 활성화 할 수 있다. 음성 인식 장치는, 제1 강화 신호 또는 제2 강화 신호 내에 기 설정된 단어가 포함된다는 판단에 기초하여, 음성 인식 동작을 활성화 할 수 있다. 단계 S850에서 일 실시 예에 따른 음성 인식 장치는 새롭게 수신되는 제2 멀티 채널 오디오 신호에 대해 음성 인식을 수행하고 음성 인식 결과를 출력할 수 있다. 제2 멀티 채널 오디오 신호는, 사용자가 기 설정된 단 어(예를 들어, 웨이크 워드)를 발화한 이후에 발화한 음성 신호를 포함할 수 있다. 예를 들어, 제1 멀티 채널 오디오 신호가 웨이크 워드를 포함하는 신호라면, 제2 멀티 채널 오디오 신호는 웨이크 워드 이후에 발화되는 사용자의 음성 명령을 포함하는 신호일 수 있다. 일 실시 예에 따른 음성 인식 장치는, 웨이크 업 시 이용된 빔포밍 방식에 따라 어댑티브 빔포밍과 픽스드 빔포밍을 선택적으로 사용할 수 있다. 음성 인식 장치는, 단계 S840에서 제1 강화 신호 내에 기 설정된 단어가 포함된다는 판단에 기초하여 음성 인식 동작이 활성화 된 경우, 제2 멀티 채널 오디오 신호에 대해 어댑티브 빔포밍을 수행할 수 있다. 음성 인식 장치는, 제2 멀티 채널 오디오 신호에 대한 파라미터들을 업데이트함으로써, 업데이트된 파라미터들에 기 초하여 어댑티브 빔포밍을 수행할 수 있다. 음성 인식 장치는, 제2 멀티 채널 오디오 신호의 적어도 하나 의 프레임에 대해서 음성 신호 특성 및 노이즈 신호 특성을 계산하고, 계산된 결과에 기초하여 빔포머의 파라미 터들을 업데이트 할 수 있다. 예를 들어, 음성 인식 장치는, 제2 멀티 채널 오디오 신호의 매 프레임마다 파라미터들을 업데이트함으로 써, 업데이트된 파라미터들에 기초하여 어댑티브 빔포밍을 수행할 수 있다. 또는, 음성 인식 장치는, 소정 프레임 간격으로 빔포밍 파라미터들을 업데이트함으로써, 업데이트된 파라미터들에 기초하여 어댑티브 빔포밍을 수행할 수 있다. 어댑티브 빔포밍에 따르면, 새롭게 수신되는 멀티 채널 오디오 신호의 적어도 하나의 프레임의 타겟 신호 성분 과 노이즈 신호 성분을 분석하고, 분석 결과에 기초하여 타겟 신호를 강화하기 위한 필터 계수를 업데이트 할 수 있다. 따라서, 어댑티브 빔포밍에 의하면, 적응적으로 변경 가능한 빔을 이용하여 빔포밍을 수행할 수 있다. 반면에, 음성 인식 장치는, 단계 S840에서 제1 강화 신호 내에는 기 설정된 단어가 포함되지 않고 제2 강 화 신호 내에 기 설정된 단어가 포함된다는 판단에 기초하여 음성 인식 동작이 활성화 된 경우, 제2 멀티 채널 오디오 신호에 대해 픽스드 빔포밍을 수행할 수 있다. 음성 인식 장치는, 제2 강화 신호 생성 시에 이용되 었던 파라미터들에 기초하여, 제2 멀티 채널 오디오 신호에 대해서 픽스드 빔포밍을 수행할 수 있다. 음성 인식 장치는, 새롭게 수신되는 멀티 채널 오디오 신호에 대해서 웨이크 업 시 이용되었던 빔포머의 파라미터들 을 이용하여 빔포밍을 수행할 수 있다. 도 9에 도시된 바와 같이, 일 실시 예에 따른 음성 인식 장치는, 음성 간섭 환경에서도 웨이크 업 성공률 을 높게 유지하기 위하여, 웨이크 업 단계에서, 이중 전처리 프로세스(S910) 및 듀얼 웨이크업 프로세스(S920) 를 수행할 수 있다. 단계 S910에서 음성 인식 장치는, 이중 전처리를 위하여, 일반 전처리와 음성 간섭에 강인한 전처리를 병 렬적으로 수행할 수 있다. 구체적으로, 음성 인식 장치는, 일반적인 빔포밍과 음성 간섭에 강인하도록 새 롭게 제안되는 빔포밍을 병렬적으로 수행하는, 듀얼 빔포밍을 수행할 수 있다. 병렬적으로 수행되는 듀얼 빔포 밍과 관련하여서는, 도 5 및 도 6에 대한 설명이 적용될 수 있다. 중복되는 설명은 생략한다. 단계 S920에서 음성 인식 장치는, 일반적인 빔포밍을 통해 음성 성분이 강화된 신호 또는 음성 간섭에 강 인한 빔포밍을 통해 음성 성분이 강화된 신호에 기초하여 웨이크 업 여부를 결정할 수 있다. 단계 S920에서 음성 인식 기능을 웨이크 업 하도록 결정된 경우, 단계 S930에서 음성 인식 장치는, 웨이크 워드 뒤에 발화되는 주 명령어에 대한 음성 인식을 수행하고 음성 인식 결과를 출력할 수 있다. 단계 S920에서 음성 인식 기능을 웨이크 업 하도록 결정된 경우, 단계 S931에서 음성 인식 장치는, 일반적 인 빔포밍에 의해 강화된 신호에 기초하여 웨이크 업이 결정되었는지 여부를 판단할 수 있다. 일반적인 빔포밍에 의해 강화된 신호에 기초하여 웨이크 업이 결정된 경우, 단계 S933에서 음성 인식 장치(20 0)는, 새롭게 수신되는 멀티 채널 오디오 신호에 대해서 어댑티브 빔포밍을 수행할 수 있다. 새롭게 수신되는 멀티 채널 오디오 신호는, 사용자에 의해 웨이크 워드 뒤에 발화되는 주 명령어를 포함할 수 있다. 일반적인 빔포밍에 의해 강화된 신호에 기초하여 웨이크 업이 결정되지 않은 경우, 단계 S935에서 음성 인식 장 치는, 빔을 고정할 수 있다. 음성 인식 장치는, 새롭게 수신되는 멀티 채널 오디오 신호에 대해서 픽 스드 빔포밍을 수행할 수 있다. 상대적으로 짧은 길이(예를 들어, 1초 미만)의 웨이크 워드를 인식하는 웨이크 업 단계에서는, 음성 간섭에 강 인한 빔포밍을 이용함으로써 음성 간섭 환경에서의 웨이크 업 성능을 높일 수 있다. 다만, 상대적으로 긴 길이 (예를 들어, 1초 이상)의 발화에 대한 음성 인식을 수행하는 ASR(Automatic Speech Recognition) 단계에서는, 음성 간섭에 강인한 빔포밍을 이용할 경우 음성 인식 성능이 보장되지 않는다. 따라서, 음성 간섭에 강인한 빔포밍에 의해 웨이크 업 된 이후에, 음성 인식 장치는, ASR을 위해 오디오 신호를 전처리 함에 있어서 일반적인 빔포밍 방식을 이용할 수 있다. 음성 인식 장치가 웨이크 업 되었다 는 것은, 음성 간섭에 강인한 빔포밍이 화자의 발화를 제대로 타겟팅하도록 동작했다는 것을 의미할 수 있다. 그러므로, 음성 인식 장치는, 웨이크 업 시점의 빔을 유지함으로써 음성 간섭 환경에서도 음성 인식 성능 을 향상시킬 수 있다. 음성 간섭에 강인한 빔포밍에 의해 강화된 신호에 기초하여 음성 인식 장치가 웨이크 업 된 경우 빔 고정 이 필요하지만, 일반적인 빔포밍에 기초하여 웨이크 업 된 경우 어댑티브 빔이 이용될 수 있다. 한편, 본 개시의 일 실시 예에 따른 음성 인식 장치는, 빔 포밍 기반의 음성 인식 성능을 향상시키기 위하 여, 신경망을 이용한 GEV 빔 포머를 이용할 수 있다. 도 10은 일 실시 예에 따른 신경망에 기반한 마스크 계산 방식을 도시한다. 도 10에 도시된 바와 같이, 음성 인 식 장치는 멀티 채널 오디오 신호에 대해서 각 채널 별 오디오 신호에 대한 신경망 분석을 통해 음 성 성분과 노이즈 성분을 구분할 수 있다. 음성 인식 장치는, 음성 성분 및 노이즈 성분 각각에 대 해서 중간값 필터를 적용할 수 있다(1031, 1032). 음성 인식 장치는, 중간값 필터가 적용된 음성 성분 및 중간값 필터가 적용된 노이즈 성분에 기초하여 마스크를 추정할 수 있다. 음성 인식 장치는, 추정된 마스크에 기초하여 음성 교차 파워 스펙트럴 밀도를 획득하고, 노이즈 교차 파워 스펙트럴 밀도를 획득 할 수 있다. 음성 인식 장치는, 음성 교차 파워 스펙트럴 밀도 및 노이즈 교차 파워 스펙트럴 밀도 에 기초하여 GEV 빔포밍을 수행할 수 있다. 한편, 본 개시의 다른 일 실시 예에 따르면, 도 11에 도시된 신경망 기반 마스크 계산 방식이 이용될 수 있다. 전처리 시 소요되는 계산 부담(computational overload)를 줄이기 위하여, 멀티 채널 오디오 신호에 대해 신경 망 분석을 수행하기 전에 중간값 필터를 적용할 수 있다. 도 11에 도시된 바와 같이, 음성 인식 장치는 멀티 채널 오디오 신호에 대해서 중간값 필터를 적용 함으로써 단일 채널 오디오 신호로 변환할 수 있다. 음성 인식 장치는, 단일 채널 오디오 신호에 대 해서 최적화된 신경망 분석을 수행할 수 있다. 음성 인식 장치는, 신경망 분석을 통해 소스 스펙트 럼을 추정할 수 있다. 음성 인식 장치는, 신경망 분석을 통해 추정된 소스 스펙트럼에 기초하여 마스크를 추정할 수 있다. 음성 인식 장치는, 추정된 마스크에 기초하여 음성 교차 파워 스펙트럴 밀도를 획 득하고, 노이즈 교차 파워 스펙트럴 밀도를 획득할 수 있다. 음성 인식 장치는, 음성 교차 파 워 스펙트럴 밀도 및 노이즈 교차 파워 스펙트럴 밀도에 기초하여 듀얼 빔포밍을 수행할 수 있다. 듀얼빔포밍은, 현재 프레임에 대한 음성 신호 특성 및 노이즈 신호 특성에 기초한 일반적인 빔포밍과 현재 프레임에 대한 음성 신호 특성 및 M 프레임 이전 음성 신호 특성에 기초한 음성 간섭에 강인한 빔포밍을 병렬적으로 수행 하는 것을 의미할 수 있다. 도 3a 내지 도 9를 참조하여 상술한 바와 같이, 본 개시의 일 실시 예에 따른 음성 인식 장치는, 일반적인 빔포머와 음성 간섭에 강인한 빔포머를 병렬로 사용하여 멀티 채널 오디오 신호에 대한 음성 강화를 수행할 수 있다. 일 실시 예에 따른 음성 인식 장치는, 두 개의 빔포머들에 의해 생성된 두 개의 음성 신호들에 기초 하여 웨이크 업 여부를 결정할 수 있다. 그러나 본 개시는 상술한 실시 예에 제한되지 않는다. 예를 들어, 하드웨어의 제약 등으로 두 개의 빔포머들을 병렬적으로 동작하는 것이 불가능 한 경우, 일반적인 빔포머와 음성 간섭에 강인한 빔포머가 선택적으로 이용될 수 있다. 도 12에 도시된 바와 같이, 다른 일 실시 예에 따른 음성 인식 장치는, 멀티 채널 오디오 신호에 대해서, VAD(Voice Activity Detection) 모듈에 의해 보이스 동작을 검출할 수 있다(S1210). 음성 인식 장치는, 멀티 채널 오디오 신호에 보이스 노이즈가 포함되는 경우, M 프레임 이상 보이스가 지속되었는지 여부를 판단할 수 있다(S1220). 음성 인식 장치는, M 프레임 이상 보이스가 지속되는 경우, 음성 간섭 환경이라고 판단하고, 음성 간섭에 강인한 빔포머만을 온(on) 하여 빔포밍을 수행할 수 있다(S1231). 음성 인식 장치는, M 프레임 이상 보이 스가 지속되지 않는 경우, 음성 간섭이 없는 일반적인 환경이라고 판단하고, 일반적인 빔포머만을 온 하여 빔포 밍을 수행할 수 있다(S1232). 따라서, 도 12에 도시된 다른 일 실시 예에 따른 음성 인식 장치는, 일반적인 빔포밍이 수행된 결과 및 음 성 간섭에 강인한 빔포밍이 수행된 결과 중 하나에 기초하여 웨이크 업 여부를 결정하는 싱글 웨이크 업을 수행 함으로써, 소비되는 전력 및 계산 로드를 줄일 수 있다. 개시된 실시 예들은 컴퓨터로 읽을 수 있는 저장 매체(computer-readable storage media)에 저장된 명령어를 포 함하는 S/W 프로그램으로 구현될 수 있다. 컴퓨터는, 저장 매체로부터 저장된 명령어를 호출하고, 호출된 명령어에 따라 개시된 실시 예에 따른 동작이 가 능한 장치로서, 개시된 실시 예들에 따른 영상 전송 장치 및 영상 수신 장치를 포함할 수 있다. 컴퓨터로 읽을 수 있는 저장매체는, 비일시적(non-transitory) 저장매체의 형태로 제공될 수 있다. 여기서, '비 일시적' 은 저장매체가 신호(signal)를 포함하지 않으며 실재(tangible)한다는 것을 의미할 뿐 데이터가 저장매 체에 반영구적 또는 임시적으로 저장됨을 구분하지 않는다. 또한, 개시된 실시 예들에 따른 전자 장치 또는 방법은 컴퓨터 프로그램 제품(computer program product)에 포 함되어 제공될 수 있다. 컴퓨터 프로그램 제품은 상품으로서 판매자 및 구매자 간에 거래될 수 있다. 컴퓨터 프로그램 제품은 S/W 프로그램, S/W 프로그램이 저장된 컴퓨터로 읽을 수 있는 저장 매체를 포함할 수 있다. 예를 들어, 컴퓨터 프로그램 제품은 전자 장치의 제조사 또는 전자 마켓(예, 구글 플레이 스토어, 앱 스 토어)을 통해 전자적으로 배포되는 S/W 프로그램 형태의 상품(예, 다운로더블 앱)을 포함할 수 있다. 전자적 배 포를 위하여, S/W 프로그램의 적어도 일부는 저장 매체에 저장되거나, 임시적으로 생성될 수 있다. 이 경우, 저 장 매체는 제조사의 서버, 전자 마켓의 서버, 또는 SW 프로그램을 임시적으로 저장하는 중계 서버의 저장매체가 될 수 있다. 컴퓨터 프로그램 제품은, 서버 및 단말(예로, 음성 인식 장치 또는 음성 인식 서버)로 구성되는 시스템에서, 서 버의 저장매체 또는 단말의 저장매체를 포함할 수 있다. 또는, 서버 또는 단말과 통신 연결되는 제3 장치(예, 스마트폰)가 존재하는 경우, 컴퓨터 프로그램 제품은 제3 장치의 저장매체를 포함할 수 있다. 또는, 컴퓨터 프 로그램 제품은 서버로부터 단말 또는 제3 장치로 전송되거나, 제3 장치로부터 단말로 전송되는 S/W 프로그램 자 체를 포함할 수 있다. 이 경우, 서버, 단말 및 제3 장치 중 하나가 컴퓨터 프로그램 제품을 실행하여 개시된 실시 예들에 따른 방법을 수행할 수 있다. 또는, 서버, 단말 및 제3 장치 중 둘 이상이 컴퓨터 프로그램 제품을 실행하여 개시된 실시 예 들에 따른 방법을 분산하여 실시할 수 있다. 예를 들면, 서버(예로, 클라우드 서버 또는 인공 지능 서버 등)가 서버에 저장된 컴퓨터 프로그램 제품을 실행 하여, 서버와 통신 연결된 단말이 개시된 실시 예들에 따른 방법을 수행하도록 제어할 수 있다. 또 다른 예로, 제3 장치가 컴퓨터 프로그램 제품을 실행하여, 제3 장치와 통신 연결된 단말이 개시된 실시 예에 따른 방법을 수행하도록 제어할 수 있다. 구체적인 예로, 제3 장치는 영상 전송 장치 또는 영상 수신 장치를 원 격 제어하여, 패킹 영상을 전송 하거나 수신하도록 제어할 수 있다. 제3 장치가 컴퓨터 프로그램 제품을 실행하는 경우, 제3 장치는 서버로부터 컴퓨터 프로그램 제품을 다운로드하 고, 다운로드된 컴퓨터 프로그램 제품을 실행할 수 있다. 또는, 제3 장치는 프리로드된 상태로 제공된 컴퓨터 프로그램 제품을 실행하여 개시된 실시 예들에 따른 방법을 수행할 수도 있다."}
{"patent_id": "10-2019-0058983", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 음성 간섭이 존재하는 환경에서 음성 인식 동작의 웨이크 업 성공률이 떨어지는 문제점을 설명하기 위한 도면이다. 도 2a, 2b 및 2c는 일 실시 예에 따른 음성 인식 시스템을 설명하기 위한 도면이다. 도 3a 및 3b는 일 실시 예에 따른 음성 인식 장치의 블록도의 예를 도시한다. 도 3c는 일 실시 예에 따른 음성 인식 서버의 블록도의 예를 도시한다. 도 4는 일반적으로 이용되는 웨이크 업 방식을 도시한다. 도 5는 일 실시 예에 따른 듀얼 웨이크 업 방식을 도시한다. 도 6은 일 실시 예에 따른 병렬적으로 수행되는 듀얼 빔포밍 방식을 설명하는 도면이다. 도 7은 일 실시 예에 따라 이용되는 STFT(Short-time Fourier Transform)를 설명하기 위한 도면이다. 도 8은 일 실시 예에 따른 음성 인식 방법의 흐름도이다. 도 9는 일 실시 예에 따른 음성 인식 방법의 구체적인 흐름도이다. 도 10은 일 실시 예에 따른 신경망(Neural Network)에 기반한 마스크 계산 방식을 도시한다. 도 11은 다른 일 실시 예에 따른 신경망 기반 마스크 계산 방식을 도시한다. 도 12는 다른 일 실시 예에 따라 선택적으로 수행되는 듀얼 빔포밍 방식을 설명하는 도면이다."}
