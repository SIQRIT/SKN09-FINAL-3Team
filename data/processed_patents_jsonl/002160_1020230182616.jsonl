{"patent_id": "10-2023-0182616", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0126804", "출원번호": "10-2023-0182616", "발명의 명칭": "인공지능 모델을 이용한 블랙박스 영상 기반의 교통사고 과실비율 판정 서버 및 방법", "출원인": "주식회사 씨피식스", "발명자": "박준일"}}
{"patent_id": "10-2023-0182616", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "사전 학습된 인공지능 모델을 이용하여 판정 대상 차량의 사고 전 시점, 사고 시점 및 사고 후 시점 각각에 대한 분석 대상 영상으로부터 교통사고 관련 객체를 파악하는 영상 분석부;상기 교통사고 관련 객체를 기초로 상기 사고 전 시점, 사고 시점 및 사고 후 시점 각각에 대한 제1 점수 분류테이블(score classification table)을 생성하고, 상기 제1 점수 분류 테이블과 사전 설정된 케이스 유사도 판정 기준을 비교하여 과실 비율을 파악하는 분석 결과 평가부; 및파악된 상기 과실 비율을 반영한 교통사고 분석 정보를 제공하는 분석 결과 제공부를 포함하고,상기 분석 결과 평가부는, 상기 사고 시점에 대한 제1 점수 분류 테이블과 상기 케이스 유사도 판정 기준을 비교하여 제1 유사도를 계산하고, 상기 제1 유사도가 기준치 이상인 경우 상기 제1 유사도에 기반하여 상기 교통사고 분석 정보를 결정하고,상기 제1 유사도가 상기 기준치 미만인 경우, 상기 사고 전 시점에 대한 제1 점수 분류 테이블과 상기 케이스유사도 판정 기준을 비교하여 제2 유사도를 계산하고, 상기 제2 유사도에 기반하여 상기 교통사고 분석 정보를결정하는, 교통사고 과실비율 판정 서버."}
{"patent_id": "10-2023-0182616", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "청구항 1에 있어서,상기 분석 결과 평가부는, 상기 제2 유사도가 상기 기준치 미만인 경우, 상기 사고 후 시점에 대한 제1 점수 분류 테이블과 상기 케이스유사도 판정 기준을 비교하여 제3 유사도를 계산하고, 상기 제3 유사도에 기반하여 상기 교통사고 분석 정보를결정하는, 교통사고 과실비율 판정 서버."}
{"patent_id": "10-2023-0182616", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "청구항 2에 있어서,상기 분석 결과 평가부는, 상기 제1 유사도, 상기 제2 유사도 및 상기 제3 유사도가 모두 기준치 미만인 경우, 판정 절차를 종료하는, 교통사고 과실비율 판정 서버."}
{"patent_id": "10-2023-0182616", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "청구항 2에 있어서,상기 제1 유사도, 상기 제2 유사도 및 상기 제3 유사도는 각각,상기 사고 시점, 사고 전 시점 및 사고 후 시점의 상기 제1 점수 분류 테이블 내 교통사고 관련 객체 항목 및상기 케이스 유사도 판정 기준의 제2 점수 분류 테이블 내 GIA 아이템 항목의 항목 중복률 및 항목 결과값의 중복률을 포함하는, 교통사고 과실비율 판정 서버."}
{"patent_id": "10-2023-0182616", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "공개특허 10-2024-0126804-3-청구항 1에 있어서,상기 분석 결과 평가부는, 상기 교통사고 관련 객체 별로 고유 식별값을 지정하고, 상기 사고 전 시점, 사고 시점 및 사고 후 시점 각각의상기 분석 대상 영상에서 파악된 상기 교통사고 관련 객체의 상기 고유 식별값을 기초로 상기 제1 점수 분류 테이블을 생성하고, 생성된 상기 제1 점수 분류 테이블을 상기 케이스 유사도 판정 기준과 비교하여 상기 판정 대상 차량이 가해 차량인지 또는 피해 차량인지 여부를 결정하는, 교통사고 과실비율 판정 서버."}
{"patent_id": "10-2023-0182616", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "청구항 5에 있어서,상기 분석 결과 평가부는, 상기 제1 점수 분류 테이블을 상기 케이스 유사도 판정 기준과 비교하여 상기 판정대상 차량 및 타 차량의 과실비율을 계산하는, 교통사고 과실비율 판정 서버."}
{"patent_id": "10-2023-0182616", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "교통사고 과실비율 판정 서버에 의해 수행되는 방법에 있어서,사전 학습된 인공지능 모델을 이용하여 판정 대상 차량의 사고 전 시점, 사고 시점 및 사고 후 시점 각각에 대한 분석 대상 영상으로부터 교통사고 관련 객체를 파악하는 단계;상기 교통사고 관련 객체를 기초로 상기 사고 전 시점, 사고 시점 및 사고 후 시점 각각에 대한 제1 점수 분류테이블(score classification table)을 생성하는 단계;상기 제1 점수 분류 테이블과 사전 설정된 케이스 유사도 판정 기준을 비교하여 과실 비율을 파악하는 단계; 및파악된 상기 과실 비율을 반영한 교통사고 분석 정보를 제공하는 단계를 포함하고,상기 과실 비율을 파악하는 단계는, 상기 사고 시점에 대한 제1 점수 분류 테이블과 상기 케이스 유사도 판정 기준을 비교하여 제1 유사도를 계산하고, 상기 제1 유사도가 기준치 이상인 경우 상기 제1 유사도에 기반하여 상기 교통사고 분석 정보를 결정하는단계;상기 제1 유사도가 상기 기준치 미만인 경우, 상기 사고 전 시점에 대한 제1 점수 분류 테이블과 상기 케이스유사도 판정 기준을 비교하여 제2 유사도를 계산하고, 상기 제2 유사도에 기반하여 상기 교통사고 분석 정보를결정하는 단계를 포함하는, 교통사고 과실비율 판정 방법."}
{"patent_id": "10-2023-0182616", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "인공지능 모델을 이용한 블랙박스 영상 기반의 교통사고 과실비율 판정 서버 및 방법이 개시된다. 본 발명의 일 실시예에 따른 교통사고 과실비율 판정 서버는, 사전 학습된 인공지능 모델을 이용하여 사고 전 시점, 사고 시점 및 사고 후 시점 각각에 대한 분석 대상 영상으로부터 교통사고 관련 객체를 파악하고, 교통사고 관련 객체를 추 가한 분석 대상 영상의 사본을 생성 및 저장하는 영상 분석부; 교통사고 관련 객체를 기초로 사고 전 시점, 사고 시점 및 사고 후 시점 각각에 대한 사본 분석 대상 영상에 대한 제1 점수 분류 테이블(score classification table)을 생성하고, 제1 점수 분류 테이블과 사전 설정된 케이스 유사도 판정 기준을 비교하여 과실 비율을 파악 하는 분석 결과 평가부; 및 파악된 상기 과실 비율을 반영한 교통사고 분석 정보 및 상기 교통사고 분석 정보에 대응되는 증거자료를 포함하는 분석 결과를 생성하여 제공하는 분석 결과 제공부를 포함한다."}
{"patent_id": "10-2023-0182616", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "개시되는 실시예들은 인공지능 모델을 이용한 블랙박스 영상 기반의 교통사고 과실비율 판정 서버 및 방법과 관 련된다."}
{"patent_id": "10-2023-0182616", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "보험사는 교통사고 발생에 대한 보험처리를 보다 체계적으로 수행하기 위해 교통사고 현장에 대한 영상을 수집 하고 있는 실정이다. 차량용 블랙박스는 차량에 장착된 카메라 및 각종 센서를 통해 교통사고 발생 당시의 영상 데이터 및 센싱 데이 터를 획득하고, 이를 보험사 서버로 제공할 수 있다. 한편, 보험사 서버는 차량, 보험사 직원 또는 보험 가입자를 통해 교통사고 영상을 수집하지만, 이를 실제 보험 처리에 이용하기 위해 교통사고 영상 각각을 육안으로 확인하여 교통사고 관련 부분을 수작업으로 체크하고 있 는 실정이다."}
{"patent_id": "10-2023-0182616", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "개시된 실시예들은 블랙박스 영상을 기초로 교통사고 과실비율을 자동으로 판정하기 위한 인공지능 모델을 이용 한 블랙박스 영상 기반의 교통사고 과실비율 판정 서버 및 방법을 제공하고자 한다."}
{"patent_id": "10-2023-0182616", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "일 실시예에 따른 교통사고 과실비율 판정 서버는, 사전 학습된 인공지능 모델을 이용하여 사고 전 시점, 사고 시점 및 사고 후 시점 각각에 대한 분석 대상 영상으로부터 교통사고 관련 객체를 파악하고, 상기 교통사고 관 련 객체를 추가한 분석 대상 영상의 사본을 생성 및 저장하는 영상 분석부; 상기 교통사고 관련 객체를 기초로 상기 사고 전 시점, 사고 시점 및 사고 후 시점 각각에 대한 사본 분석 대상 영상에 대한 제1 점수 분류 테이블 (score classification table)을 생성하고, 상기 제1 점수 분류 테이블과 사전 설정된 케이스 유사도 판정 기준 을 비교하여 과실 비율을 파악하는 분석 결과 평가부; 및 파악된 상기 과실 비율을 반영한 교통사고 분석 정보 및 상기 교통사고 분석 정보에 대응되는 증거자료를 포함하는 분석 결과를 생성하여 제공하는 분석 결과 제공부 를 포함하고, 상기 분석 대상 영상은 원본 사고영상으로부터 상기 사고 전 시점, 사고 시점 및 사고 후 시점과 관련된 부분만을 추출한 영상일 수 있다. 상기 영상 분석부는, 상기 교통사고 관련 객체를 추가하여 상기 분석 대상 영상의 사본을 저장할 때, 상기 원본 사고영상, 상기 사본 분석 대상 영상 및 원본 증명을 위한 해시값을 서로 매칭하여 함께 저장할 수 있다. 상기 영상 분석부는, 상기 사본 분석 대상 영상을 저장할 때, 상기 교통사고 관련 객체와 관련된 레이블링 정보 를 포함하는 추가 메타 데이터 생성하고, 이를 상기 사본 분석 대상 영상과 매칭하여 함께 저장할 수 있다. 상기 교통사고 관련 객체는, 차량 객체, 환경 객체 및 인간 행동 객체 중 적어도 하나 이상을 포함할 수 있다. 상기 차량 객체는, 차량의 브레이크등 점등 상태, 차량의 방향지시등 점등 상태, 차량의 파손 상태, 가해 차량 및 피해 차량 중 적어도 하나 이상을 포함하고, 상기 환경 객체는, 신호등 점등 상태, 교차로 및 차선 인식 상 태, 가로등 점등 상태 및 도로 시설물 상태 중 적어도 하나 이상을 포함할 수 있다. 상기 분석 결과 평가부는, 상기 교통사고 관련 객체 별로 고유 식별값을 지정하고, 상기 사고 전 시점, 사고 시 점 및 사고 후 시점 각각의 상기 사본 분석 대상 영상에서 파악된 상기 교통사고 관련 객체의 상기 고유 식별값 을 기초로 제1 점수 분류 테이블(score classification table)을 생성하고, 생성된 상기 제1 점수 분류 테이블 을 상기 케이스 유사도 판정 기준과 비교하여 판정대상 차량이 가해 차량인지 또는 피해 차량인지 여부를 최종 결정하고, 상기 케이스 유사도 판정 기준은 제2 점수 분류 테이블 형태일 수 있다. 상기 분석 결과 평가부는, 상기 제1 점수 분류 테이블을 사전 설정된 상기 케이스 유사도 판정 기준의 상기 제2 점수 분류 테이블과 비교하여 판정대상 차량 및 타 차량의 과실비율을 파악할 수 있다. 상기 분석 결과 평가부는, 상기 판정대상 차량이 제1 피해 차량, 제2 피해 차량, 제1 가해 차량 및 제2 가해 차 량 중 어느 하나의 차량인지 여부를 파악할 수 있다. 상기 분석 결과 평가부는, 상기 사고 전 시점, 사고 시점 및 사고 후 시점 중 상기 사고 시점에 대한 제1 점수 분류 테이블과 상기 케이스 유사도 판정 기준을 최우선적으로 비교하고, 비교 결과 서로 간의 유사도가 기준치 이상인 경우, 해당 비교 결과를 상기 교통사고 분석 정보로 결정하고, 상기 유사도가 상기 기준치 미만인 경우, 상기 사고 전 시점에 대한 제1 점수 분류 테이블과 상기 케이스 유사도 판정 기준을 비교하고, 비교 결과 서로 간의 유사도가 상기 기준치 이상인 경우, 해당 비교 결과를 상기 교통사고 분석 정보로 결정하며, 상기 유사도 가 상기 기준치 미만인 경우, 상기 사고 후 시점에 대한 제1 점수 분류 테이블과 상기 케이스 유사도 판정 기준 을 비교하고, 비교 결과 서로 간의 유사도가 상기 기준치 이상인 경우, 해당 비교 결과를 상기 교통사고 분석정보를 결정하고, 및 상기 사고 시점, 사고 전 시점 및 사고 후 시점 모두에 대한 제1 점수 분류 테이블과 상기 케이스 유사도 판정 기준의 유사도가 기준치 미만인 경우, 판정 절차를 종료할 수 있다. 다른 실시예에 따른 교통사고 과실비율 판정 방법은, 교통사고 과실비율 판정 서버에 의해 수행되는 방법에 있 어서, 사전 학습된 인공지능 모델을 이용하여 사고 전 시점, 사고 시점 및 사고 후 시점 각각에 대한 분석 대상 영상으로부터 교통사고 관련 객체를 파악하는 단계; 상기 교통사고 관련 객체를 추가한 분석 대상 영상의 사본 을 생성 및 저장하는 단계; 상기 교통사고 관련 객체를 기초로 상기 사고 전 시점, 사고 시점 및 사고 후 시점 각각에 대한 사본 분석 대상 영상에 대한 제1 점수 분류 테이블(score classification table)을 생성하는 단계; 상기 제1 점수 분류 테이블과 사전 설정된 케이스 유사도 판정 기준을 비교하여 과실 비율을 파악하는 단계; 및 파악된 상기 과실 비율을 반영한 교통사고 분석 정보 및 상기 교통사고 분석 정보에 대응되는 증거자료를 포함 하는 분석 결과를 생성하여 제공하는 단계를 포함하고, 상기 분석 대상 영상은 원본 사고영상으로부터 상기 사 고 시점과 관련된 부분만을 추출한 영상일 수 있다."}
{"patent_id": "10-2023-0182616", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "개시되는 실시예들에 따르면, 인공지능 모델을 이용하여 블랙박스 영상으로부터 손해 보험 협회의 기준에 따른 교통사고 관련 객체를 자동으로 파악하고, 이를 기초로 객관적인 기준을 통해 과실비율을 판정할 수 있다는 효 과를 기대할 수 있다. 또한, 개시되는 실시예들에 따르면, 블랙박스 영상인 원본 사고영상을 기초로 사고보험 처리를 위한 추가 정보 를 생성하되, 원본 사고영상을 유지하는 형태로 정보를 추가하기 때문에, 사고보험 처리를 보다 효율적으로 처 리할 수 있고 원본 사고영상을 비롯한 추가 정보를 법적 증거자료로 활용할 수 있다."}
{"patent_id": "10-2023-0182616", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 도면을 참조하여 본 발명의 구체적인 실시형태를 설명하기로 한다. 이하의 상세한 설명은 본 명세서에서 기술된 방법, 장치 및/또는 시스템에 대한 포괄적인 이해를 돕기 위해 제공된다. 그러나 이는 예시에 불과하며 본 발명은 이에 제한되지 않는다. 본 발명의 실시예들을 설명함에 있어서, 본 발명과 관련된 공지기술에 대한 구체적인 설명이 본 발명의 요지를 불필요하게 흐릴 수 있다고 판단되는 경우에는 그 상세한 설명을 생략하기로 한다. 그리고, 후술되는 용어들은 본 발명에서의 기능을 고려하여 정의된 용어들로서 이는 사용자, 운용자의 의도 또는 관례 등에 따라 달라질 수 있다. 그러므로 그 정의는 본 명세서 전반에 걸친 내용을 토대로 내려져야 할 것이다. 상세한 설명에서 사용되 는 용어는 단지 본 발명의 실시예들을 기술하기 위한 것이며, 결코 제한적이어서는 안 된다. 명확하게 달리 사 용되지 않는 한, 단수 형태의 표현은 복수 형태의 의미를 포함한다. 본 설명에서, \"포함\" 또는 \"구비\"와 같은 표현은 어떤 특성들, 숫자들, 단계들, 동작들, 요소들, 이들의 일부 또는 조합을 가리키기 위한 것이며, 기술된 것 이외에 하나 또는 그 이상의 다른 특성, 숫자, 단계, 동작, 요소, 이들의 일부 또는 조합의 존재 또는 가능 성을 배제하도록 해석되어서는 안 된다. 도 1은 일 실시예에 따른 교통사고 과실비율 판정 서버와 타 구성들 간의 연결 관계를 설명하기 위한 블록도이 다.이하에서는, 일 실시예에 따른 교통사고 과실비율 판정 방법을 대략적으로 설명하기 위한 예시도인 도 2 및 일 실시예에 따른 교통사고 과실비율 판정 방법을 설명하기 위한 예시도인 도 3 내지 도 12를 참고하여 설명하기로 한다. 도 1을 참고하면, 교통사고 과실비율 판정 서버는 원본 사고영상을 전달하는 사용자 단말, 교통사고 관련 보험 처리를 수행하는 보험사 서버 및 교통사고 영상 처리 서버와 통신 연결되어, 서로 간에 정 보 송수신을 수행할 수 있다. 이때, 원본 사고영상은 블랙박스 영상으로, 전방 사고영상 및 후방 사고영상을 포 함할 수 있다. 이에 한정되지 않고, 원본 사고영상은 차량에 장착된 영상 촬영장치(미도시)의 위치에 따라 좌측 또는 우측에 대한 사이드 사고영상을 추가로 포함할 수 있다. 즉, 원본 사고영상은 차량에 장착된 영상 촬영장 치의 위치에 따라 해당 방향에 대한 사고영상을 추가로 포함할 수 있는 것이다. 도 2를 참고하면, 교통사고 과실비율 판정 서버는 교통사고 영상 처리 서버로부터 사용자(예를 들어, 보험 가입자)에 의해서 사용자 단말을 통해 제공되는 원본 사고영상을 기초로 획득된 분석 대상 영상을 수 신할 수 있다. 본 실시예에서는 교통사고 과실비율 판정 서버와 교통사고 영상 처리 서버를 별도로 도시하였지만, 하나의 구성으로 함께 구현될 수도 있다. 상술한 분석 대상 영상은 원본 사고영상 중 사고보험 처리 시 참조되는 영상으로, 원본 사고영상에 분석 시 참 조되기 위한 각종 정보가 추가된 전방 사고영상 또는 후방 사고영상의 사본일 수 있다. 또한, 분석 대상 영상은 교통사고 영상 처리 서버를 통해 원본 사고영상 중 중점적으로 검토되어야 할 상황(예를 들어, 충돌시점) 을 포함하는 영상으로 선별된 영상일 수 있다. 이때, 교통사고 과실비율 판정 서버는 교통사고 영상 처리 서버로부터 분석 대상 영상뿐만 아니라 분 석 대상 영상과 관련된 각종 정보(원본 사고영상, 사고영상의 사본, 원본 파일 정보 및 추가되는 정보 등)도 함 께 수신할 수 있다. 교통사고 영상 처리 서버로부터 전달된 정보(분석 대상 영상, 원본 사고영상, 사고영 상의 사본, 원본 파일 정보 및 추가 정보)는 원본 사고영상을 기초로 추가되는 사고영상의 사본(분석 대상 영상 포함) 및 추가 정보(메타 데이터 등)을 포함하여 원본 증명을 위해 해시값이 영상 처리 시마다 추가 생성되어 서로 매칭하여 저장될 수 있다. 상기 원본 파일 정보는 원본 사고영상 파일에 기록된 원본 메타 데이터를 의미 할 수 있다. 상기 추가 정보는 원본 사고 영상을 처리할 때마다 추가되는 정보를 의미할 수 있다. 이때, 사고영상의 사본들은 원본 사고영상과의 연관성을 위해 원본 파일명으로 파일명을 생성한 상태일 수 있다. 이러한 원리는 본 실시예에서도 동일하게 적용될 수 있다. 본 실시예에서, 사본 사고영상의 파일명을 원 본 사고영상의 원본 파일명으로 설정하는 것은 원본 파일명과 동일하게 설정하거나, 또는 원본 파일명을 포함하 도록 설정하거나, 또는 원본 파일명을 파악할 수 있는 형태로 설정하는 것을 의미할 수 있다. 즉, 본 실시예에서는 사고보험 처리를 위한 원본 사고영상을 분석할 때, 원본 사고영상은 원본 상태로 유지하면 서, 추가되는 정보를 포함시켜 원본 사고영상의 사본을 생성하여 저장 및 관리하는 것이다. 도 2를 참고하면, 교통사고 과실비율 판정 서버는 분석 대상 영상을 분석 및 평가하여 과실비율 판정 결과 를 포함하는 정보를 획득할 수 있으며, 이에 대한 상세 설명은 후술하기로 한다. 이하에서는, 교통사고 과실비율 판정 서버의 상세 구성을 설명하기로 한다. 도 1을 참고하면, 교통사고 과실비율 판정 서버는 영상 분석부, 분석 결과 평가부 및 분석 결과 제공부를 포함할 수 있다. 도 3 및 도 4를 참고하면, 영상 분석부는 사전 학습된 인공지능 모델을 이용하여 사고 전 시점, 사고 시점 및 사고 후 시점 각각에 대한 분석 대상 영상으로부터 교통사고 관련 객체를 파악하고, 교통사고 관련 객체를 추가한 분석 대상 영상의 사본을 생성 및 저장할 수 있다. 상기 교통사고 관련 객체는 분석 대상 영상으로부터 사고보험 처리를 위해 고려해야 할 대상을 의미하는 것으로, 손해 보험 협회(General Insurance Associations, GIA)에서 고려하는 아이템을 기준으로 결정될 수 있다. 상기 분석 대상 영상은 사고 시점(time of car accident, TCA), 사고 시점(TCA)을 기준으로 한 사고 전 시점 (before a car accident, BCA) 및 사고 후 시점(after a car accident, ACA)을 포함할 수 있다. 이하에서는, 설명의 편의를 위해, 사고 전 시점, 사고 시점, 사고 후 시점과 각각에 대한 BCA, TCA, ACA를 혼용하여 사용하 기로 한다. 도 5 및 도 6에서 도시하는 바와 같이, 상기 분석 대상 영상은 원본 사고영상으로부터 상기 사고 전 시점(BCA), 사고 시점(TCA) 및 사고 후 시점(ACA)과 관련된 부분만(Record S. ~ Record E.)을 추출한 영상(Trim Videofile)일 수 있다. 이때, 분석 대상 영상은 사고 시점(TCA)을 기준으로 사고 전 시점(BCA) 및 사고 후 시점(ACA) 각각에 레이블링 된 레이블링 정보(label inf.)를 포함할 수 있다. 이때, 레이블링 정보는 인식된 교통사고 관 련 객체 정보 및 해당 영상의 식별 정보(예를 들어, 사고 전 시점, 사고 시점 및 사고 후 시점 중 해당 시점정 보 및 해당 분석 대상 영상 식별정보)를 포함할 수 있다. 상기 교통사고 관련 객체는, 차량 객체, 환경 객체 및 인간 행동 객체 중 적어도 하나 이상을 포함할 수 있다. 구체적으로, 상기 차량 객체는, 차량의 브레이크등 점등 상태, 차량의 방향지시등 점등 상태, 차량의 파손 상태, 가해 차량 및 피해 차량 중 적어도 하나 이상을 포함할 수 있으며, 이에 한정되지 않고, 차량과 관련된 사고보험 처리 시 요구되는 항목을 추가로 포함할 수 있다. 상기 환경 객체는, 신호등 점등 상태, 교차로 및 차선 인식 상태, 가로등 점등 상태 및 도로 시설물 상태 중 적 어도 하나 이상을 포함할 수 있다. 상기 신호등은 보행자 신호등 및 차량 신호등을 비롯하여 도로 상에 존재하 는 각종 신호를 포함할 수 있다. 즉, 환경 객체는 교통환경 및 지역환경과 관련된 각종 객체를 포함할 수 있는 것이다. 일 예로, 도 3을 참고하면, 영상 분석부는 과거 교통사고 정보를 입력값으로 교통사고 관련 객체를 인식하 도록 사전 학습된 인공지능 모델을 이용하여 분석 대상 영상으로부터 차량 객체, 환경 객체 및 인간 행동 객체 를 인식하여 분석 대상 영상에 Object N으로 표시할 수 있다. 다른 예로, 도 4를 참고하면, 영상 분석부는 사전 학습된 인공지능 모델을 이용하여 분석 대상 영상으로부 터 차량 객체, 환경 객체 및 인간 행동 객체를 인식(Object N)하되, 인식된 교통사고 관련 객체에 대한 객체명 도 함께 표시할 수 있다. 예를 들어, 영상 분석부는 차량 객체에 대해서는 Object V, Object DV, Object BL 등과 같이 표시하고, 환경 객체에 대해서는 Object SL(streetlight), Object SF(street furniture), Object Lane 등으로 표시하며, 인간 행동 객체에 대해서는 Object H(humen) 등으로 표시할 수 있다. 이를 위해, 인공지 능 모델은 GIA 아이템 기반 교통사고 관련 객체를 파악하고, 해당 교통사고 관련 객체의 대상(차량 객체, 환경 객체 및 인간 행동 객체의 세부 대상(예를 들어, 차량, 신호등, 가로등, 사람, 도로 시설물 등))을 파악하기 위 해 사전 학습된 상태일 수 있다. 상기 교통사고 관련 객체는 손해 보험 협회(General Insurance Associations, GIA)(이하, GIA라고 하기로 함) 아이템을 기준으로 결정될 수 있다. 즉, 교통사고 관련 객체는 후술하는 GIA 아이템을 객체로 반영할 수 있다는 것이다. 예를 들어, GIA 아이템은 GIA_TL(Traffic Light), GIA_IS(Intersection), GIA_Lane, GIA_Object BL(Brake Light), GIA_Object TS(Turn Signal), GIA_Object DV(Damaged Vehicle), GIA_Object OV(offending vehicle) 및 GIA_Humen_Item을 포함할 수 있다. 상기 GIA_TL은 BCA 시점의 신호등 점등 상태를 식별하기 위한 아이템, GIA_IS는 BCA 시점의 교차로 식별을 위한 아이템, GIA_Lane은 BCA 시점 영상에서 차선의 상태를 식별하기 위한 아이템, GIA_Object BL은 BCA 시점 영상에서 앞차(또는 영상에서 식별되는 모든 차량)의 브레이크등 점등 상태 를 식별하기 위한 아이템, GIA_Object TS는 BCA 시점 영상에서 앞차(또는 영상에서 식별되는 모든 차량)의 방향 지시등 점등 상태를 식별하기 위한 아이템, GIA_Object DV는 BCA 시점 영상에서 파손되는 차량을 식별하기 위한 아이템, GIA_Object OV는 BCA 시점 영상에서 가해 차량을 식별하기 위한 아이템 및 GIA_Humen_Item은 NTU_RGB+D(또는 NTU_RGB+D 120) 데이터셋에서 식별 가능한 아이템을 의미하는 것일 수 있다. 상기 NTU RGB+D 데이터셋(Nanyang Technological University's Red Blue Green and Depth information dataset)은 인간의 일상 행동을 인식하는 연구를 위해 구축된 국제 표준 데이터셋으로 114,480개의 3차원 영상 데이터셋을 포함한다. 세계 최대 규모의 데이터셋으로 딥러닝 기반의 다양한 행동 인식 연구에 활용되고 있다. 예를 들어, 인사하기, 토닥이기, 밀치기 등의 인간들 간의 상호작용을 촬영한 8천여 개의 행동 데이터들은 로봇 이 인간의 행동 습성을 이해하고 학습하는 용도로 활용될 수 있다. 상기 NTU RGB+D 데이터셋은 NTU RGB+D 120 데이터셋으로도 명명 가능할 수 있다. 도 6을 참고하면, 영상 분석부는 분석 대상 영상으로부터 사고 전, 사고 시점 및 사고 후 시점 각각에 대 해 레이블링된 레이블링 정보를 포함하는 추가 메타 데이터를 추가 생성하여 분석 대상 영상의 사본과 함께 저 장할 수 있다. 도 6을 참고하면, 영상 분석부는 교통사고 관련 객체를 추가하여 분석 대상 영상의 사본을 저장할 때, 원 본 사고영상, 사본 분석 대상 영상 및 원본 증명을 위한 해시값을 서로 매칭하여 함께 저장할 수 있다. 추가로, 영상 분석부는 사본 분석 대상 영상 및 원본 사고영상, 해시값 이외에, 최초 원본 사고영상을 기초로 사고보험 처리를 위해 추가로 생성된 정보(영상, 메타 데이터 및 해시값 등)를 서로 매칭하여 저장할 수 있다. 도시하지 않았지만, 영상 분석부는 별도의 메모리에 분석 대상 영상의 사본을 저장할 수 있다. 이 외에도, 메모리(미도시)는 교통사고 과실비율 판정 서버와 관련된 각종 정보가 저장될 수 있다. 영상 분석부는 사본 분석 대상 영상을 저장할 때, 교통사고 관련 객체와 관련된 레이블링 정보를 포함하는 추가 메타 데이터 생성하고, 이를 사본 분석 대상 영상과 매칭하여 함께 저장할 수 있다. 이때, 레이블링 정보 는 인식된 교통사고 관련 객체 정보뿐만 아니라 해당 영상의 식별 정보(예를 들어, 사고 전 시점, 사고 시점 및 사고 후 시점 중 해당 시점정보 및 해당 분석 대상 영상 식별정보)를 포함할 수 있다. 영상 분석부는 사본 분석 대상 영상의 파일명을 원본 사고영상의 원본 파일명으로 설정할 수 있다. 본 실 시예에서, 사본 분석 대상 영상의 파일명을 원본 사고영상의 원본 파일명으로 설정하는 것은 원본 파일명과 동 일하게 설정하거나, 또는 원본 파일명을 포함하도록 설정하거나, 또는 원본 파일명을 파악할 수 있는 형태로 설 정하는 것을 의미할 수 있다. 예를 들어, 원본 사고영상의 파일명은 202301311423, 분석 대상 영상의 파일명은 TV_202301311423, 사본 분석 대상 영상의 파일명은 L_TV_202301311423 일 수 있다. 즉, 영상 분석부는 원본 사고영상 및 분석 대상 영 상과 연관성이 증명될 수 있도록 파일명을 생성하는 것이다. 분석 결과 평가부는 교통사고 관련 객체를 기초로 사고 전 시점, 사고 시점 및 사고 후 시점 각각에 대한 사본 분석 대상 영상에 대한 제1 점수 분류 테이블(score classification table)을 생성하고, 제1 점수 분류 테 이블과 사전 설정된 케이스 유사도 판정 기준을 비교하여 과실 비율을 파악할 수 있다. 분석 결과 평가부는 교통사고 관련 객체 별로 고유 식별값을 지정하고, 사고 전 시점, 사고 시점 및 사고 후 시점 각각의 사본 분석 대상 영상에서 파악된 교통사고 관련 객체의 고유 식별값을 기초로 제1 점수 분류 테 이블을 생성할 수 있다. 도 7과 같이, 분석 결과 평가부는 GIA 아이템 기준 교통사고 관련 객체 별로 제1 점수 분류 테이블을 생성 한 것이다. 구체적으로, 분석 결과 평가부는 GIA_TL 교통사고 관련 객체 중 R(red)는 1, Y(yellow)는 2, G(green)는 3, Arrow는 4로 고유 식별값을 각각 지정하고, 사본 분석 대상 영상의 BCA, TCA 및 ACA 각각에 대해 인식된 항 목에 해당 고유 식별값을 제1 점수 분류 테이블에 기록할 수 있다. 또한, 분석 결과 평가부는 GIA_Lane 교통사고 관련 객체에 대해서는 인식되면(보이면) 1, 인식되지 않으면 (보이지 않으면) 0으로 고유 식별값을 각각 지정하고, 사본 분석 대상 영상의 BCA, TCA 및 ACA 각각에 대해 인 식된 항목에 0 또는 1의 고유 식별값을 제1 점수 분류 테이블에 기록할 수 있다. 이때, GIA_Lane 교통사고 관련 객체는 우측(Right)과 좌측(Left)을 포함할 수 있다. 또한, 분석 결과 평가부는 GIA_Object BL 교통사고 관련 객체에 대해서는 브레이크등이 점등 상태로 인식 되면 1, 점등 상태가 인식되지 않으면 0으로 고유 식별값을 각각 지정하고, 사본 분석 대상 영상의 BCA, TCA 및 ACA 각각에 대해 인식된 항목에 0 또는 1의 고유 식별값을 제1 점수 분류 테이블에 기록할 수 있다. 이때, GIA_ Object BL 교통사고 관련 객체는 우측(Right)과 좌측(Left)을 포함할 수 있다. 분석 결과 평가부는 GIA_Humen_Item 교통사고 관련 객체에 대해서는 NTU RGB+D 데이터셋을 기초로 파악된 인간 행동(예를 들어, A8 : sit dowm)에 대해 인식되면 1, 인식되지 않으면 0으로 각각 고유 식별값으로 지정하 고, 사본 분석 대상 영상의 BCA, TCA 및 ACA 각각에 대해 인식된 항목에 0 또는 1의 고유 식별값을 제1 점수 분 류 테이블에 기록할 수 있다. 즉, GIA_Humen_Item 교통사고 관련 객체에 대한 고유 식별값은 인간 행동의 고유 식별값과 해당 인간 행동의 행위 여부에 대한 고유 식별값을 포함할 수 있다. 도 7은 사본 분석 대상 영상에서 사람이 주저앉은 경우(sit down)에 대해서만 개시한 것으로, 인식된 다른 인간 행동(A9 : standing up (from sitting position), A27: jump up, A52: pushing other person 등)에 대해서도 고유 식별값인 0 또는 1로 기록할 수 있음은 당연하다 할 것이다. 분석 결과 평가부는 생성된 제1 점수 분류 테이블을 케이스 유사도 판정 기준과 비교하여 판정대상 차량이 가해 차량인지 또는 피해 차량인지 여부를 최종 결정할 수 있다. 영상 분석부에서 교통사고 관련 객체(예를 들어, GIA_Object DV, GIA_Object OV)가 인식되었다면, 분석 결과 평가부는 제1 점수 분류 테이블과 케이스 유사도 판정 기준과의 비교를 통해 판정대상 차량이 가해차량인지 또는 피해 차량인지 여부를 결정할 수 있는 것이다. 본 실시예에서의 케이스 유사도 판정 기준은 손해보험협회가 발간한 자동차 사고 과실비율분쟁 심의 사례를 기 준으로 생성된 것일 수 있다. 예를 들어, 도 8을 참고하면, 분석 결과 평가부는 자동차 사고 과실비율분쟁 심의 사례를 본 실시예에 적 용될 수 있는 형태로 가공하여 케이스 유사도 판정 기준으로 생성하되, 각각의 케이스 유사도 판정 기준은 사례 의 도표는 케이스, 도표 번호는 숫자, (가) 등과 같은 세부분류는 A~Z로 변경할 수 있다. 이때, 케이스 유사도 판정 기준은 피해 차량(GIA_Object_DV) 및 가해 차량((GIA_Object_OV) 사례에 대해 모두 생성될 수 있다. 또한, 도 9 및 도 10에서 도시하는 바와 같이, 케이스 유사도 판정 기준은 피해 차량(GIA_Object_DV)에 대한 사 고 전 시점(BCA), 사고 시점(TCA) 및 사고 후 시점(ACA)에 대한 케이스 아이템을 포함할 수 있다. 추가로, 케이 스 유사도 판정 기준은 가해 차량(GIA_Object_OV)에 대한 사고 전 시점(BCA), 사고 시점(TCA) 및 사고 후 시점 (ACA)에 대한 케이스 아이템도 포함할 수 있다. 도 8 내지 도 10은 케이스 유사도 판정 기준의 일 예시를 나타내는 것으로서, 해당 케이스 유사도 판정 기준의 사례명은 Case_202_A일 수 있다. 즉, 케이스 유사도 판정 기준은 자동차 사고 과실비율분쟁 사례 정보 및 사례 정보와 매칭되는 케이스 아이템을 포함할 수 있다. 이때, 케이스 아이템은 피해 차량의 BCA, TCA 및 ACA 시점의 케이스 아이템과 가해 차량의 BCA, TCA 및 ACA 시점의 케이스 아이템을 포함할 수 있다. 이때, 케이스 아이템의 항목은 교통사고 관련 객체와 대응될 수 있다. 이하에서는, 도 8의 A 차량((가)녹색진입) 및 B 차량에 대해 케이스 아이템을 기초로 판정하는 경우를 예로 들 어 설명하기로 한다. 일 예로, 피해 차량의 BCA 시점의 케이스 아이템(GIA_Object_DV BCA Status의 케이스 아이템)은 GIA_TL, GIA_IS, GIA_Lane_R, GIA_Lane_L, GIA_Object_BL_R, GIA_Object_BL_L 및 GIA_Humen_Item 항목을 포함할 수 있 으며, 이에 한정되지 않고 운용자의 필요에 따라 추가 또는 삭제 될 수 있다. 도 9를 참고하면, 분석 결과 평가부는 도 8의 A 차량((가)녹색진입)에 대해 GIA_Object_DV BCA Status를 판단할 때, GIA_TL은 노란색 신호등의 점등 상태인 2(Y), GIA_IS는 교차로가 인식되어 교차로 진입 상태인 1(In), GIA_Lane_R은 우측 차선이 인식되어 차선 미 침범 상태인 1(In), GIA_Lane_L은 좌측 차선이 인식되어 차선 미 침범 상태인 1(In), GIA_Object_BL_R은 우측 브레이크등이 미 점등 상태인 0(Off), GIA_Object_BL_L은 좌측 브레이크등이 미 점등 상태인 0(Off) 및 GIA_Humen_Item은 사람이 인식되지 않은 상태인 0(not exist)일 수 있다. 다른 예로, 가해 차량의 BCA 시점의 케이스 아이템(GIA_Object_OV BCA Status의 케이스 아이템)은 GIA_TL, GIA_IS, GIA_Lane_R, GIA_Lane_L, GIA_Object_BL_R, GIA_Object_BL_L 및 GIA_Humen_Item 항목을 포함할 수 있 으며, 이에 한정되지 않고 운용자의 필요에 따라 추가 또는 삭제 될 수 있다. 도 9를 참고하면, 분석 결과 평가부는 도 8의 B 차량에 대해 GIA_Object_OV BCA Status를 판단할 때, GIA_TL은 초록색 신호등의 점등 상태인 3(G), GIA_IS은 교차로가 인식되어 교차로 진입 상태인 1(In), GIA_Lane_R은 우측 차선이 인식되어 차선 미 침범 상태인 1(In), GIA_Lane_L은 좌측 차선이 인식되어 차선 미 침범 상태인 1(In), GIA_Object_BL_R은 우측 브레이크등이 점등 상태인 1(On), GIA_Object_BL_L은 좌측 브레이 크등이 점등 상태인 1(On) 및 GIA_Humen_Item은 사람이 인식되지 않은 상태인 0(not exist)일 수 있다. 다른 예로, 피해 차량의 TCA 시점의 케이스 아이템(GIA_Object_DV TCA Status의 케이스 아이템)은 GIA_TL, GIA_IS, GIA_Lane_R, GIA_Lane_L, GIA_Object_BL_R, GIA_Object_BL_L 및 GIA_Humen_Item 항목을 포함할 수 있 으며, 이에 한정되지 않고 운용자의 필요에 따라 추가 또는 삭제 될 수 있다. 도 10을 참고하면, 분석 결과 평가부는 도 8의 A 차량에 대해 GIA_Object_DV TCA Status를 판단할 때, GIA_TL은 빨간색 신호등의 점등 상태인 1(R), GIA_IS는 교차로가 인식되어 교차로 진입 상태인 1(In), GIA_Lane_R은 우측 차선이 인식되어 차선 미 침범 상태인 1(In), GIA_Lane_L은 좌측 차선이 인식되어 차선 미 침범 상태인 1(In), GIA_Object_BL_R은 우측 브레이크등이 미 점등 상태인 0(Off), GIA_Object_BL_L은 좌측 브 레이크등이 미 점등 상태인 0(Off) 및 GIA_Humen_Item은 사람이 인식되지 않은 상태인 0(not exist)일 수 있다.다른 예로, 가해 차량의 TCA 시점의 케이스 아이템(GIA_Object_OV TCA Status의 케이스 아이템)은 GIA_TL, GIA_IS, GIA_Lane_R, GIA_Lane_L, GIA_Object_BL_R, GIA_Object_BL_L 및 GIA_Humen_Item 항목을 포함할 수 있 으며, 이에 한정되지 않고 운용자의 필요에 따라 추가 또는 삭제 될 수 있다. 도 10을 참고하면, 도 8의 B 차량에 대해 GIA_Object_OV TCA Status를 판단할 때, GIA_TL은 초록색 신호등의 점등 상태인 3(G), GIA_IS는 교차로가 인식되어 교차로 진입 상태인 1(In), GIA_Lane_R은 우측 차선이 인식되어 차선 미 침범 상태인 1(In), GIA_Lane_L은 좌측 차선이 인식되어 차선 미 침범 상태인 1(In), GIA_Object_BL_R 은 우측 브레이크등이 점등 상태인 1(On), GIA_Object_BL_L은 좌측 브레이크등이 점등 상태인 1(On) 및 GIA_Humen_Item은 사람이 인식되지 않은 상태인 0(not exist)일 수 있다. 본 실시예에서는 피해 차량 및 가해 차량의 BCA 및 TCA에 대해서만 개시하였지만, ACA에 대해서도 케이스 유사 도 판정 기준을 설정함은 당연하다 할 것이다. 분석 결과 평가부는 사전에 케이스 유사도 판정 기준을 도 11과 같은 제2 점수 분류 테이블(score classification table) 형태로 생성(예를 들어, Case_202_A : GIA_Object_DV status, GIA_Object_OV status) 하여, 사본 분석 대상 영상에 대한 제1 점수 분류 테이블과 비교가 용이할 수 있도록 할 수 있다. 즉, 분석 결과 평가부는 도 8 내지 도 10과 같은 과정을 통해 케이스 유사도 판정 기준을 제2 점수 분류 테이블 형태로 생성할 수 있는 것이다. 분석 결과 평가부는 제1 점수 분류 테이블을 사전 설정된 케이스 유사도 판정 기준의 제2 점수 분류 테이 블과 비교하여 판정대상 차량 및 타 차량의 과실비율을 파악할 수 있다. 이때, 판정대상 차량은 보험 가입자의 차량을 의미할 수 있다. 일 예로, 분석 결과 평가부는 사고 전 시점, 사고 시점 및 사고 후 시점 중 사고 시점에 대한 판정대상 차 량의 제1 점수 분류 테이블과 케이스 유사도 판정 기준을 최우선적으로 비교하고, 비교 결과 서로 간의 유사도 가 기준치 이상인 경우, 해당 비교 결과를 교통사고 분석 정보로 결정할 수 있다. 상기 서로 간의 유사도는 사 고 시점(TCA)의 판정대상 차량의 제1 점수 분류 테이블 내 교통사고 관련 객체 항목과 케이스 유사도 판정 기준 의 제2 점수 분류 테이블 내 GIA 아이템 항목의 항목 중복률 및 항목 결과값의 중복률을 포함할 수 있다. 이때, 항목 중복률은 교통사고 관련 객체 항목과 GIA 아이템 항목의 일치하는 확률을 의미할 수 있다. 상기 항목 결과 값의 중복률은 서로 대응되는 교통사고 관련 객체 항목과 GIA 아이템 항목의 결과값이 일치하는 확률을 의미할 수 있다. 도 11을 참고하면, 분석 결과 평가부는 판정대상 차량에 대한 제1 점수 분류 테이블 내 교통사고 관련 객 체 항목과 케이스 유사도 판정 기준의 제2 점수 분류 테이블 내 GIA 아이템의 항목을 서로 비교하여 과실비율을 파악할 수 있다. 예를 들어, 분석 결과 평가부는 TCA 시점에서의 교통사고 관련 객체 항목과 GIA 아이템 항목의 항목 중복 률이 기 설정된 제1 중복률(예를 들어, 60%) 이상(예를 들어, 80%)이고, 항목 결과값의 중복률이 기 설정된 제2 중복률(예를 들어, 80%) 이상인 경우, 해당 케이스가 사전에 설정한 과실비율(도 8의 결정비율)로 결정할 수 있 다. 도 11의 경우, 판정대상 차량의 제1 점수 분류 테이블인 Case_L_TV_202301311423은 TCA 시점을 기준으로 케이스 유사도 판정 기준의 제2 점수 분류 테이블 중 GIA_Object_DV Status 제2 점수 분류 테이블 중 TCA 시점과의 중 복률이 기 설정된 제1 및 제2 중복률 이상임이 파악되어서, Case_202_A에 대해 사전 설정된 과실비율(도 8의 결 정비율) 20 : 80으로 결정될 수 있다. 즉, 판정대상 차량의 과실비율은 20인 것이다. 다른 예로, 분석 결과 평가부는 사고 시점에 대한 제1 점수 분류 테이블과 케이스 유사도 판정 기준 간의 비교 결과, 유사도가 기준치 미만인 경우, 사고 전 시점에 대한 제1 점수 분류 테이블과 케이스 유사도 판정 기 준을 비교하고, 비교 결과 서로 간의 유사도가 기준치 이상인 경우, 해당 비교 결과를 상기 교통사고 분석 정보 로 결정할 수 있다. 예를 들어, TCA 시점에서의 교통사고 관련 객체 항목과 GIA 아이템 항목의 항목 중복률이 기 설정된 제1 중복률 (예를 들어, 60%) 미만(예를 들어, 59%)인 경우, 분석 결과 평가부는 BCA 시점을 기준으로 유사도를 비교 하여 과실비율을 판정할 수 있다. 즉, BCA 시점 기준의 항목 중복률 및 항목 결과값의 중복률이 2차적으로 보정 값으로 적용될 수 있는 것이다. 다른 예로, 분석 결과 평가부는 사고 전 시점(BCA)에 대한 제1 점수 분류 테이블과 케이스 유사도 판정 기 준 간의 비교 결과, 유사도가 기준치 미만인 경우, 사고 후 시점에 대한 제1 점수 분류 테이블과 케이스 유사도 판정 기준을 비교하고, 비교 결과 서로 간의 유사도가 기준치 이상인 경우, 해당 비교 결과를 상기 교통사고 분 석 정보로 결정할 수 있다. 예를 들어, 분석 결과 평가부는 BCA 시점 기준의 중복률(예를 들어, 항목 중복률)이 제1 중복률(예를 들어, 60%) 미만인 경우, ACA 시점을 기준으로 유사도록 비교하여 과실비율을 판정할 수 있다. 즉, 분석 결과 평가부는 TCA 시점 -> BCA 시점 -> ACA 시점을 우선 순위로 하여 과실비율 판정을 진행할 수 있다. 다른 예로, 분석 결과 평가부는 사고 시점, 사고 전 시점 및 사고 후 시점 모두에 대한 제1 점수 분류 테 이블과 케이스 유사도 판정 기준의 유사도가 기준치 미만인 경우, 판정 절차를 종료할 수 있다. 예를 들어, 분석 결과 평가부는 TCA, BCA 및 ACA 시점 모두의 중복률이 사전 설정된 제1 중복률(예를 들어, 항목 중복률이 60%) 미만인 경우, 과실비율 판정을 중단할 수 있다. 이는, 과실비율 판정 결과에 대한 신 뢰성 확보를 위한 것일 수 있다. 한편, 분석 결과 평가부는 판정대상 차량이 제1 피해 차량, 제2 피해 차량, 제1 가해 차량 및 제2 가해 차 량 중 어느 하나의 차량인지 여부를 파악할 수 있다. 상기 제1 피해 차량은 최초 피해 차량, 제2 피해 차량은 다중 피해 차량, 제1 가해 차량은 최초 가해 차량 및 제2 가해 차량은 다중 가해 차량을 의미할 수 있다. 구체적으로, 분석 대상 영상이 전방 사고영상 및 후방 사고영상을 포함하는 경우, 분석 결과 평가부는 전 후방 사고영상에 대해 상술한 과실비율 판정 절차를 수행하여 전후방 사고영상 각각에 대한 사고 시점, 사고 전 시점 및 사고 후 시점 모두에 대한 제1 점수 분류 테이블을 생성하고, 이를 케이스 유사도 판정 기준과 비교할 수 있는 것이다. 이때, 전방 사고영상 뿐만 아니라 후방 사고영상에서도 충돌 상황을 인식한 경우, 분석 결과 평가부는 판정 대상 차량이 제2 피해 차량 또는 제2 가해 차량임을 파악할 수 있는 것이다. 분석 결과 제공부는 파악된 상기 과실 비율을 반영한 교통사고 분석 정보 및 상기 교통사고 분석 정보에 대응되는 증거자료를 포함하는 분석 결과를 생성하여 제공할 수 있다. 이때, 교통사고 분석 정보는 원본 사고영 상으로부터 파악된 과실 비율 판단 정보 뿐만 아니라, 변호사 및 보험사측 협의 내용을 포함할 수 있다. 또한, 교통사고 분석 정보는 필요에 따라 판단 기준 자료 인용에 대한 내용 및 기계적인 판단으로 실제 판단과 다를 수 있다는 면책 공고를 포함할 수 있다. 예를 들어, 분석 결과 제공부는 도 12와 같은 분석 보고서와 같은 교통사고 분석 정보와 도 11과 같은 교 통사고 분석 정보를 입증할 수 있는 증거자료를 포함하여 분석 결과를 생성할 수 있는 것이다. 한편, 본 실시예의 영상 분석부, 분석 결과 평가부 및 분석 결과 제공부를 포함하는 교통사고 과실비율 판정 서버는 하나 이상의 코어로 구성될 수 있으며, 컴퓨팅 장치의 중앙 처리 장치(central processing unit), 범용 그래픽 처리 장치 (general purpose graphics processing unit), 텐서 처리 장치 (tensor processing unit) 등의 데이터 분석, 딥러닝을 위한 프로세서를 포함할 수 있다. 교통사고 과실비율 판 정 서버 내 각 구성은 메모리(미도시)에 저장된 컴퓨터 프로그램을 판독하여 본 실시예에 따른 기계 학습 을 위한 데이터 처리를 수행할 수 있다. 본 실시예에 따라 교통사고 과실비율 판정 서버 내 각 구성은 신 경망의 학습을 위한 연산을 수행할 수 있다. 교통사고 과실비율 판정 서버 내 각 구성은 딥러닝(deep learning)에서 학습을 위한 입력 데이터의 처리, 입력 데이터에서의 피처 추출, 오차 계산, 역전파 (backpropagation)를 이용한 신경망의 가중치 업데이트 등의 신경망의 학습을 위한 계산을 수행할 수 있다. 상기 뉴럴 네트워크 모델은 딥 뉴럴 네트워크일 수 있다. 본 개시에서, 신경망, 네트워크 함수, 뉴럴 네트워크 (neural network)는 동일 한 의미로 사용될 수 있다. 딥 뉴럴 네트워크(DNN: deep neural network, 심층신경 망)는 입력 레이어와 출력 레이어 외에 복수의 히든 레이어를 포함하는 신경망을 의미할 수 있다. 딥 뉴럴 네트 워크를 이용하면 데이터의 잠재적인 구조(latent structures)를 파악할 수 있다. 즉, 사진, 글, 비디오, 음성, 음악의 잠재적인 구조(예를 들어, 어떤 물체가 사진에 있는지, 글의 내용과 감정이 무엇인지, 음성의 내용과 감 정이 무엇인지 등)를 파악할 수 있다. 딥 뉴럴 네트워크는 컨벌루셔널 뉴럴 네트워크(CNN: convolutional neural network), 리커런트 뉴럴 네트워크(RNN: recurrent neural network), 제한 볼츠만 머신(RBM: restricted boltzmann machine), 심층 신뢰 네트워크(DBN: deep belief network), Q 네트워크, U 네트워크, 샴 네트워크 등을 포함할 수 있다.컨벌루셔널 뉴럴 네트워크는 딥 뉴럴 네트워크의 일종으로서, 컨벌루셔널 레이어를 포함하는 신경망을 포함한다. 컨벌루셔널 뉴럴 네트워크는, 최소 한의 전처리(preprocess)를 사용하도록 설계된 다계층 퍼셉트론 (multilayer perceptrons)의 한 종류이다. CNN은 하나 또는 여러 개의 컨벌루셔널 레이어와 이와 결합된 인공 신경망 계층들로 구성될 수 있다. CNN은 가중치와 풀링 레이어(pooling layer)들을 추가로 활용할 수 있다. 이 러한 구조 덕분에 CNN은 2차원 구 조의 입력 데이터를 충분히 활용할 수 있다. 컨벌루셔널 뉴럴 네트워크는 이 미지에서 오브젝트를 인식하기 위하여 사용될 수 있다. 컨벌루셔널 뉴럴 네트워크는, 이미지 데이터를 차원을 가진 행렬로 나타내어 처리할 수 있다. 예를 들어 RGB(red-green-blue)로 인코딩 된 이미지 데이터의 경우, R, G, B 색상별로 각각 2 차원(예를 들어, 2 차원 이미지 인 경우) 행렬로 나타내 질 수 있다. 즉, 이미지 데이터 의 각 픽셀의 색상 값이 행렬의 성분이 될 수 있으며 행렬의 크기는 이미지의 크기와 같을 수 있다. 따라서, 이 미지 데이터는 3개의 2차원 행렬로(3차원의 데이터 어레이)로 나타내질 수 있다. 컨벌루셔널 뉴럴 네트워크에서, 컨벌루셔널 필터를 이동해가며 컨벌루셔널 필터와 이미지의 각 위치에서의 행렬 성분끼리 곱하는 것으로 컨벌루셔널 과정(컨벌루셔널 레이어의 입출력)을 수행할 수 있다. 컨벌루셔널 필터는 n*n 형태의 행렬로 구성될 수 있다. 컨벌루셔널 필터는, 일반적으로 이미지의 전체 픽셀의 수보다 작은 고정된 형태의 필터로 구성될 수 있다. 즉, m*m 이미지를 컨벌루셔널 레이어(예를 들어, 컨벌루셔널 필터의 사이즈가 n*n인 컨벌루셔널 레이어)입력시키는 경우, 이미지의 각 픽셀을 포함하는 n*n 픽셀을 나타내는 행렬이 컨벌루셔 널 필터와 성분 곱 (즉, 행렬의 각 성분끼리의 곱) 될 수 있다. 컨벌루셔널 필터와의 곱에 의하여 이 미지에서 컨벌루셔널 필터와 매칭되는 성분이 추출될 수 있다. 예를 들어, 이미지에서 상하 직선 성분을 추출하기 위한 3*3 컨벌루셔널 필터는 [[0,1,0], [0,1,0], [0,1,0]] 와 같이 구성될 수 있다. 이미지에서 상하 직선 성분을 추 출하기 위한 3*3 컨벌루셔널 필터가 입력 이미지에 적용되면 이미지에서 컨벌 루셔널 필터와 매칭되는 상하 직 선 성분이 추출되어 출력될 수 있다. 컨벌루셔널 레이어는 이미지를 나타낸 각각의 채널에 대한 각각의 행렬(즉, R, G, B 코딩 이미 지의 경우, R, G, B 색상)에 컨벌루셔널 필터를 적용할 수 있다. 컨벌루셔널 레이 어는 입력 이미지에 컨벌루셔널 필터를 적용하여 입력 이미지에서 컨벌루셔널 필터 와 매칭되는 피쳐를 추출할 수 있다. 컨벌루셔널 필터의 필터 값(즉, 행렬의 각 성 분의 값)은 컨벌루셔널 뉴럴 네트워크의 학습 과정에서 역전파에 의하여 업데이트 될 수 있다. 컨벌루셔널 레이어의 출력에는, 서브샘플링 레이어가 연결되어 컨벌 루셔널 레이어의 출력을 단순화하여 메모리 사용량과 연산량을 줄일 수 있다. 예를 들어, 2*2 맥스 풀링 필터를 가지는 풀링 레이어에 컨벌루셔널 레이어의 출력을 입 력시키는 경우, 이미지의 각 픽셀에서 2*2 패치마다 각 패치에 포함되는 최대값을 출력하여 이미지를 압축할 수 있다. 전술한 풀링은 패치에서 최소값을 출력하거나, 패치의 평균값을 출력하는 방식일 수도 있으며 임의의 풀링 방식이 본 개시에 포함될 수 있다. 컨벌루셔널 뉴럴 네트워크는, 하나 이상의 컨벌루셔널 레이어, 서브 샘플링 레이어를 포함할 수 있다. 컨벌루셔 널 뉴럴 네트워크는 컨벌루셔널 과정과 서브샘플링 과정(예를 들어, 전술한 맥스 풀링 등)을 반복적으로 수행하 여 이미지에서 피쳐를 추출할 수 있다. 반복적인 컨벌루션널 과정과 서브샘플링 과정을 통해 뉴럴 네트워크는 이미지의 글로벌 피쳐를 추출할 수 있다. 컨벌루셔널 레이어 또는 서브샘플링 레이어의 출력은 풀 커넥티드 레이어(fully connected layer)에 입력될 수 있다. 풀 커넥티드 레이어는 하나의 레이어에 있는 모든 뉴런과 이웃한 레이어에 있는 모든 뉴런이 연결되는 레 이어이 다. 풀 커넥티드 레이어는 뉴럴 네트워크에서 각 레이어의 모든 노드가 다른 레이 어의 모든 노드에 연 결된 구조를 의미할 수 있다. 사용자 단말은 차량에 정착된 유무선 통신이 가능한 블랙박스이거나, 또는 휴대폰과 같은 이동통신 단말이 거나, 또는 데스크톱 PC와 같은 유선 단말일 수 있다. 이때, 사용자는 운전자를 비롯한 보험 가입자를 의미할 수 있으나, 이에 한정되지 않는다. 본 실시예에서는 원본 사고영상을 교통사고 과실비율 판정 서버 또는 교통사고 영상 처리 서버로 전달하는 대상을 사용자라 할 수 있다. 보험사 서버는 교통사고 과실비율 판정 서버와 통신 연결되어 정보를 송수신할 수 있다. 예를 들어, 보험사 서버는 교통사고 분석 정보 및 상기 교통사고 분석 정보에 대응되는 증거자료를 포함하 는 분석 결과를 비롯하여 보험 처리를 위한 각종 정보를 사전 협의에 따라 교통사고 과실비율 판정 서버로 부터 수신할 수 있다. 보험사 서버는 교통사고 과실비율 판정 서버와 원활한 정보 공유를 위해 정보의 형식, 파일명, 정보 가 포함하고 있는 용어 등을 사전에 통일 또는 공유할 수 있다.도 13은 일 실시예에 따른 교통사고 과실비율 판정 방법을 설명하기 위한 흐름도이다. 도 13에 도시된 방법은 예를 들어, 전술한 교통사고 과실 비율 판정 서버에 의해 수행될 수 있다. 도시된 흐름도에서는 상기 방법 을 복수 개의 단계로 나누어 기재하였으나, 적어도 일부의 단계들은 순서를 바꾸어 수행되거나, 다른 단계와 결 합되어 함께 수행되거나, 생략되거나, 세부 단계들로 나뉘어 수행되거나, 또는 도시되지 않은 하나 이상의 단계 가 부가되어 수행될 수 있다. 도 13에서의 교통사고 영상 처리 방법은 상술한 도 1 내지 도 12에 개시된 동일 구성에서 수행되는 것으로, 설 명의 편의를 위해 중복되는 상세 설명은 생략하기로 한다. 1100 단계에서, 교통사고 과실비율 판정 서버는 영상 분석부를 통해 사전 학습된 인공지능 모델을 이 용하여 사고 전 시점, 사고 시점 및 사고 후 시점 각각에 대한 분석 대상 영상으로부터 교통사고 관련 객체를 파악할 수 있다. 상기 분석 대상 영상은 원본 사고영상으로부터 사고 전 시점, 사고 시점 및 사고 후 시점과 관 련된 부분만을 추출한 영상일 수 있다. 1200 단계에서, 교통사고 과실비율 판정 서버는 영상 분석부를 통해 교통사고 관련 객체를 추가한 분 석 대상 영상의 사본을 생성 및 저장할 수 있다. 1300 단계에서, 교통사고 과실비율 판정 서버는 분석 결과 평가부를 통해 교통사고 관련 객체를 기초 로 상기 사고 전 시점, 사고 시점 및 사고 후 시점 각각에 대한 사본 분석 대상 영상에 대한 제1 점수 분류 테 이블(score classification table)을 생성할 수 있다. 1400 단계에서, 교통사고 과실비율 판정 서버는 분석 결과 평가부를 통해 제1 점수 분류 테이블과 사 전 설정된 케이스 유사도 판정 기준을 비교하여 과실 비율을 파악할 수 있다. 1500 단계에서, 교통사고 과실비율 판정 서버는 분석 결과 제공부를 통해 파악된 과실 비율을 반영한 교통사고 분석 정보 및 교통사고 분석 정보에 대응되는 증거자료를 포함하는 분석 결과를 생성하여 제공할 수 있다. 도 14는 일 실시예에 따른 컴퓨팅 장치를 포함하는 컴퓨팅 환경을 예시하여 설명하기 위한 블록도이다. 도시된 실시예에 서, 각 컴포넌트들은 이하에 기술된 것 이외에 상이한 기능 및 능력을 가질 수 있고, 이하에 기술된 것 이외에도 추가적인 컴포넌트를 포함할 수 있다. 도시된 컴퓨팅 환경은 컴퓨팅 장치를 포함한다. 컴퓨팅 장치는 일 실시예에 따른 교통사고 과실비 율 판정 서버에 포함된 하나 이상의 컴포넌트일 수 있다. 컴퓨팅 장치는 적어도 하나의 프로세서, 컴퓨터 판독 가능 저장 매체 및 통신 버스를 포함한다. 프로세서는 컴퓨팅 장치로 하여금 앞서 언급된 예시적인 실시예에 따라 동작하도록 할 수 있 다. 예컨대, 프로세서는 컴퓨터 판독 가능 저장 매체에 저장된 하나 이상의 프로그램들을 실행할 수 있 다. 상기 하나 이상의 프로그램들은 하나 이상의 컴퓨터 실행 가능 명령어를 포함할 수 있으며, 상기 컴퓨터 실 행 가능 명령어는 프로세서에 의해 실행되는 경우 컴퓨팅 장치로 하여금 예시적인 실시예에 따른 동작 들을 수행하도록 구성될 수 있다. 컴퓨터 판독 가능 저장 매체는 컴퓨터 실행 가능 명령어 내지 프로그램 코드, 프로그램 데이터 및/또는 다 른 적합한 형태의 정보를 저장하도록 구성된다. 컴퓨터 판독 가능 저장 매체에 저장된 프로그램은 프로 세서에 의해 실행 가능한 명령어의 집합을 포함한다. 일 실시예에서, 컴퓨터 판독 가능 저장 매체는 메 모리(랜덤 액세스 메모리와 같은 휘발성 메모리, 비휘발성 메모리, 또는 이들의 적절한 조합), 하나 이상의 자 기 디스크 저장 디바이스들, 광학 디스크 저장 디바이스들, 플래시 메모리 디바이스들, 그 밖에 컴퓨팅 장치 에 의해 액세스되고 원하는 정보를 저장할 수 있는 다른 형태의 저장 매체, 또는 이들의 적합한 조합일 수 있다. 통신 버스는 프로세서, 컴퓨터 판독 가능 저장 매체를 포함하여 컴퓨팅 장치의 다른 다양한 컴 포넌트들을 상호 연결한다. 컴퓨팅 장치는 또한 하나 이상의 입출력 장치를 위한 인터페이스를 제공하는 하나 이상의 입출력 인터 페이스 및 하나 이상의 네트워크 통신 인터페이스를 포함할 수 있다. 입출력 인터페이스 및 네트워크 통신 인터페이스는 통신 버스에 연결된다. 입출력 장치는 입출력 인터페이스를 통해 컴퓨팅 장치의 다른 컴포넌트들에 연결될 수 있다. 예시적인 입출력 장치는 포인팅 장치(마우스 또는 트랙패드 등), 키보드, 터치 입력 장치(터치패드 또는 터치스크린 등), 음성 또는 소리 입력 장치, 다양한 종류의 센서 장치 및/또는 촬영 장치와 같은 입력 장치, 및/또는 디스플레이 장치, 프린터, 스피커 및/또는 네트워크 카드와 같은 출력 장치를 포함할 수 있다. 예시적인 입출력 장치는 컴퓨팅 장치를 구성하는 일 컴포넌트로서 컴퓨팅 장치의 내부에 포함될 수도 있고, 컴퓨팅 장치와는 구별되는 별개의 장치로 컴퓨팅 장치와 연결될 수도 있다."}
{"patent_id": "10-2023-0182616", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "이상에서 본 발명의 대표적인 실시예들을 상세하게 설명하였으나, 본 발명이 속하는 기술분야에서 통상의 지식 을 가진 자는 상술한 실시예에 대하여 본 발명의 범주에서 벗어나지 않는 한도 내에서 다양한 변형이 가능함을 이해할 것이다. 그러므로 본 발명의 권리범위는 설명된 실시예에 국한되어 정해져서는 안 되며, 후술하는 청구 범위뿐만 아니라 이 청구범위와 균등한 것들에 의해 정해져야 한다."}
{"patent_id": "10-2023-0182616", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 일 실시예에 따른 교통사고 과실비율 판정 서버와 타 구성들 간의 연결 관계를 설명하기 위한 블록도 도 2는 일 실시예에 따른 교통사고 과실비율 판정 방법을 대략적으로 설명하기 위한 예시도 도 3 내지 도 12는 일 실시예에 따른 교통사고 과실비율 판정 방법을 설명하기 위한 예시도 도 13은 일 실시예에 따른 교통사고 과실비율 판정 방법을 설명하기 위한 흐름도 도 14는 일 실시예에 따른 컴퓨팅 장치를 포함하는 컴퓨팅 환경을 예시하여 설명하기 위한 블록도"}
