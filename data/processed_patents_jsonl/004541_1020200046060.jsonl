{"patent_id": "10-2020-0046060", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2021-0128183", "출원번호": "10-2020-0046060", "발명의 명칭": "인공지능용 영상을 제공하는 영상처리방법 및 장치와 인공지능 기기를 위한 정보제공시스템", "출원인": "장종환", "발명자": "장종환"}}
{"patent_id": "10-2020-0046060", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "디스플레이;디스플레이에서 출력할 기본 영상 데이터 및 인공지능용 영상 데이터를 저장하는 메모리;메모리에 저장된 제어 프로그램을 실행하며, 기본 영상이 출력되는 중에 설정 조건에 따라 인공지능용 영상이출력되도록 디스플레이를 제어하는 프로세서를 포함하는 영상 처리 장치."}
{"patent_id": "10-2020-0046060", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 프로세서는, 인접한 기본 영상 프레임의 사이에 기본 영상 프레임이 하나 이상 삽입되도록 상기 디스플레이를 제어하는 것을 특징으로 하는 영상 처리 장치."}
{"patent_id": "10-2020-0046060", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,상기 인공지능용 영상 프레임은 상기 기본 영상 프레임에 비하여 지속시간이 짧은 것을 특징으로 하는 영상 처리 장치."}
{"patent_id": "10-2020-0046060", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,상기 프로세서는, 기본 영상 프레임에 적어도 하나의 인공지능용 영상 프레임이 오버랩 되도록 상기 디스플레이를 제어하는 것을 특징으로 하는 영상 처리 장치."}
{"patent_id": "10-2020-0046060", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서,상기 프로세서는, 인공지능용 영상 프레임을 다수 개로 분할하여 설정된 주기마다 다수의 분할된 인공지능용 영상이 기본 영상 프레임에 순차적으로 오버랩 되도록 상기 디스플레이를 제어하는 것을 특징으로 하는 영상 처리장치."}
{"patent_id": "10-2020-0046060", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항 내지 제5항 중 어느 한 항에 있어서,상기 인공지능용 영상은 상기 디스플레이의 일부 영역에만 표시되는 것을 특징으로 하는 영상 처리 장치."}
{"patent_id": "10-2020-0046060", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항 내지 제5항 중 어느 한 항에 있어서,이동체 접근을 감지하는 접근감지부를 포함하고, 상기 프로세서는 이동체 접근이 감지된 경우에 한하여 인공지능용 영상을 출력하도록 제어하는 것을 특징으로 하는 영상 처리 장치."}
{"patent_id": "10-2020-0046060", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서,상기 프로세서는 접근하는 이동체가 자율주행 기기인지 여부를 확인하고, 자율주행 기기로 확인된 경우에 한하공개특허 10-2021-0128183-3-여 인공지능용 영상을 출력하도록 제어하는 것을 특징으로 하는 영상 처리 장치."}
{"patent_id": "10-2020-0046060", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1항에 있어서,기본 영상만을 출력하는 제1 동작모드, 인공지능용 영상만을 출력하는 제2 동작모드, 기본 영상이 출력되는 중에 인공지능용 영상을 출력하는 제3 동작모드 중에서 하나의 동작모드를 결정하는 동작모드결정수단을 포함하는것을 특징으로 하는 영상 처리 장치."}
{"patent_id": "10-2020-0046060", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "디스플레이에서 기본 영상을 출력하는 단계;기본 영상이 출력되는 중에 설정 조건에 따라 인공지능용 영상을 출력하되, 인접한 기본 영상 프레임의 사이에인공지능용 영상 프레임을 하나 이상 삽입하여 출력하는 인공지능용 영상 출력단계를 포함하는 영상 처리 방법."}
{"patent_id": "10-2020-0046060", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제10항에 있어서,상기 인공지능용 영상 프레임은 상기 기본 영상 프레임에 비하여 지속시간이 짧은 것을 특징으로 하는 영상 처리 방법."}
{"patent_id": "10-2020-0046060", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제10항에 있어서,상기 인공지능용 영상은 상기 디스플레이의 일부 영역에만 표시되는 것을 특징으로 하는 영상 처리 방법."}
{"patent_id": "10-2020-0046060", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제10 항에 있어서,상기 인공지능용 영상 출력단계에서는, 이동체 접근이 감지된 경우에 한하여 인공지능용 영상을 출력하는 것을특징으로 하는 영상 처리 방법."}
{"patent_id": "10-2020-0046060", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "카메라;카메라 촬영 영상의 각 프레임을 분석하여 등록된 인공지능용 영상이 포함된 프레임이 있는지 확인하고, 인공지능용 영상으로부터 정보를 획득하는 인공지능용 영상 확인부;카메라 촬영 영상을 분석하여 주변 객체를 분류하고 제어 지령을 생성하는 인공지능부;메모리에 저장된 제어 프로그램을 실행하며, 인공지능용 영상 확인부에서 획득한 정보를 처리하는 프로세서를 포함하는 인공지능 기기."}
{"patent_id": "10-2020-0046060", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제14항에 있어서,상기 인공지능용 영상은 충돌 경고 영상이고, 상기 인공지능용 영상 확인부에서 충돌 경고 영상을 확인하면, 상기 인공지능부는 카메라의 촬영 영상에서 충돌경고 영상이 표시된 영역을 고정 장애물로 간주하고 영상 분석을 수행하는 것을 특징으로 하는 인공지능 기기."}
{"patent_id": "10-2020-0046060", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제14항에 있어서,공개특허 10-2021-0128183-4-주변 객체와의 거리를 감지하는 거리감지센서를 더 포함하고,상기 인공지능부는, 입력노드에 카메라 촬영 영상, 거리감지센서의 측정값 및 인공지능용 영상 확인부에서 확인한 인공지능용 영상 정보가 입력되는 딥러닝 알고리즘을 포함하는 것을 특징으로 하는 인공지능 기기."}
{"patent_id": "10-2020-0046060", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제14항에 있어서,인공지능용 영상을 출력하는 영상 처리 장치로 기기 식별정보를 무선으로 전송하는 통신부를 포함하는 것을 특징으로 하는 인공지능 기기."}
{"patent_id": "10-2020-0046060", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 사람을 위한 영상과 인공지능용 영상을 함께 출력할 수 있는 영상 처리 장치를 개시한다. 본 발명에 따른 영상 처리 장치는, 디스플레이; 디스플레이에서 출력할 기본 영상 데이터 및 인공지능용 영상 데이터를 저 장하는 메모리; 메모리에 저장된 제어 프로그램을 실행하며, 기본 영상이 출력되는 중에 설정 조건에 따라 인공 (뒷면에 계속)"}
{"patent_id": "10-2020-0046060", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 영상처리기술에 관한 것으로서, 구체적으로는 하나의 디스플레이에서 사람을 위한 영상과 인공지능 기기만이 인식할 수 있는 영상을 함께 제공할 수 있는 영상처리 방법 및 장치에 관한 것이다."}
{"patent_id": "10-2020-0046060", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "최근 대부분의 공공장소나 유동인구가 많은 장소에는 사람들에게 뉴스, 정보, 광고 등을 제공하기 위한 디지털 정보 디스플레이(DID)가 설치되어 있으며, DID를 기반으로 네트워크 서비스, 인터랙티브 서비스 등을 제공하는 디지털 사이니지(Digital Signage)가 새로운 커뮤니케이션 플랫폼 산업으로 주목을 받고 있다. 그런데 기존의 디스플레이는 인간에게 시각 정보를 제공하는 것으로서 그 용도가 제한적이라는 한계가 있다. 예를 들어 4차 산업 혁명의 핵심 기술로 주목받고 있는 인공지능 기반의 자율주행 기기(자동차, 드론, 로봇 등)가 상용화되면 인공지능도 사람과 마찬가지로 디스플레이 영상을 통해 정보를 획득해야 할 필요가 있다. 그러나 현재의 디스플레이는 사람을 기준으로 영상을 출력하므로 인공지능을 위한 영상을 기존 방식대로 출력하 면 사람들이 영상을 시청하는데 불편을 겪을 수밖에 없다. 이러한 경우를 대비하여 동일한 디스플레이를 통해 사람에게 필요한 정보와 인공지능 기기에게 필요한 정보를 함께 제공하되, 사람이 시청하는데 아무런 불편이나 문제가 없도록 영상을 제공하는 방법을 개발할 필요가 있다. 한편 인공지능 기기가 이동하는 경로 주변에 디스플레이가 많이 설치되면, 인공지능 기기가 카메라 영상을 분석 하여 주변환경을 인식할 때 디스플레이 속의 이미지를 실제인 것으로 판단하는 인지 착오가 발생할 수 있으므로 이를 방지할 수 있는 방안을 마련할 필요도 있다. 예를 들어 최근 대부분의 자율주행 차량에서는 주변의 객체를 인지하고 분류하는 수단으로서 인공지능을 사용하 고 있으며, 인공지능은 도 1에 예시한 바와 같이 카메라 영상으로부터 차량, 차선, 간판, 신호등, 보행자 등의 다양한 객체를 분류하고 객체의 속도, 방향 등을 확인한 후 주행전략을 결정하고 차량의 속도와 방향을 제어한 다. 그런데 인공지능으로 영상분석을 하는 경우에는 카메라 영상에 포함된 디스플레이의 영상을 실제인 것으로 오인 할 가능성이 있다. 일 예로서, 도 2에 예시한 바와 같이, 자율주행 드론의 주행경로 주변에 설치된 대형 디스플레이가 예 를 들어 건물 이미지와 하늘 이미지를 포함하는 영상을 출력한다고 가정하면, 인공지능 영상분석 모델 은 카메라 영상에서 디스플레이 전체를 고정 장애물로 인식하고 이를 우회하는 경로를 설정해야만 한다. 그런데 만일 인공지능 영상분석 모델이 영상 속의 건물 이미지를 고정 장애물로 인식하고 건물 이미지 와 건물 이미지 사이의 하늘 이미지를 주행가능한 자유공간으로 인식하면, 하늘 이미지의 중앙 부 분을 향하는 주행경로(화살표 방향)를 설정함으로써 드론이 디스플레이에 충돌하는 사고가 발생할 수 있다. 다른 예로서, 도 3에 예시한 바와 같이, 자율주행 자동차의 주행 도로 주변에 설치된 대형 디스플레이 가 예를 들어 도로 이미지를 출력한다고 가정하면, 인공지능 영상분석 모델은 카메라 영상에서 디스플레이 전체를 고정 장애물로 인식하고 이를 우회하는 경로를 설정해야만 한다. 그런데 만일 인공지능 영상분석 모델이 화면 속의 도로 이미지를 진짜 도로로 인식하면, 도로 이미지를 향하는 주행경로(화살표 방향)를 설정함으로써 자동차가 정상 도로를 벗어나거나 디스플레이에 충돌하 는 사고가 발생할 수 있다. 따라서 카메라 영상을 분석하여 주변 환경을 인지하는 인공지능 기반 자율주행 기기의 안전한 주행을 위해서는 주행 경로 주변에 설치된 디스플레이로 인해 발생할 수 있는 인지 착오를 방지할 수 있는 방안을 반드시 마련할 필요가 있다. 선행기술문헌 특허문헌 (특허문헌 0001) 한국공개특허 제10-2019-0001668호(2019.01.07 공개)"}
{"patent_id": "10-2020-0046060", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 이러한 배경에서 고안된 것으로서, 하나의 디스플레이에서 사람을 위한 영상과 인공지능 기기만이 인 식할 수 있는 영상을 함께 제공할 수 있는 영상처리방법을 제공하는데 그 목적이 있다. 또한 본 발명은 인공지능 기기가 디스플레이의 영상에 포함된 객체를 실제인 것으로 오인하는 것을 방지하는데 그 목적이 있다. 또한 본 발명은 인공지능 기반의 자율주행 기기가 디스플레이의 영상에 포함된 객체를 실제로 오인하여 디스플 레이에 충돌하거나 정상 경로에서 이탈하는 사고를 방지하는데 그 목적이 있다."}
{"patent_id": "10-2020-0046060", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "이러한 목적을 달성하기 위하여, 본 발명의 제1 양상은, 디스플레이; 디스플레이에서 출력할 기본 영상 데이터 및 인공지능용 영상 데이터를 저장하는 메모리; 메모리에 저장된 제어 프로그램을 실행하며, 기본 영상이 출력 되는 중에 설정 조건에 따라 인공지능용 영상이 출력되도록 디스플레이를 제어하는 프로세서를 포함하는 영상 처리 장치를 제공한다. 본 발명의 제1 양상에 따른 영상 처리 장치에서, 상기 프로세서는, 인접한 기본 영상 프레임의 사이에 기본 영 상 프레임이 하나 이상 삽입되도록 상기 디스플레이를 제어할 수 있다. 이 경우, 상기 인공지능용 영상 프레임 은 상기 기본 영상 프레임에 비하여 지속시간이 짧을 수 있다. 또한 본 발명의 제1 양상에 따른 영상 처리 장치에서, 상기 프로세서는, 기본 영상 프레임에 적어도 하나의 인 공지능용 영상 프레임이 오버랩 되도록 상기 디스플레이를 제어할 수 있다. 이 경우 상기 프로세서는, 인공지능 용 영상 프레임을 다수 개로 분할하여 설정된 주기마다 다수의 분할된 인공지능용 영상이 기본 영상 프레임에 순차적으로 오버랩 되도록 상기 디스플레이를 제어할 수 있다. 또한 본 발명의 제1 양상에 따른 영상 처리 장치에서, 상기 인공지능용 영상은 상기 디스플레이의 일부 영역에 만 표시될 수 있다. 또한 본 발명의 제1 양상에 따른 영상 처리 장치는, 이동체 접근을 감지하는 접근감지부를 포함하고, 상기 프로 세서는 이동체 접근이 감지된 경우에 한하여 인공지능용 영상을 출력하도록 제어할 수 있다. 이때, 상기 프로세 서는 접근하는 이동체가 자율주행 기기인지 여부를 확인하고, 자율주행 기기로 확인된 경우에 한하여 인공지능 용 영상을 출력하도록 제어할 수 있다. 또한 본 발명의 제1 양상에 따른 영상 처리 장치는, 기본 영상만을 출력하는 제1 동작모드, 인공지능용 영상만 을 출력하는 제2 동작모드, 기본 영상이 출력되는 중에 인공지능용 영상을 출력하는 제3 동작모드 중에서 하나 의 동작모드를 결정하는 동작모드결정수단을 포함할 수 있다. 본 발명의 제2 양상은, 디스플레이에서 기본 영상을 출력하는 단계; 기본 영상이 출력되는 중에 설정 조건에 따 라 인공지능용 영상을 출력하되, 인접한 기본 영상 프레임의 사이에 인공지능용 영상 프레임을 하나 이상 삽입 하여 출력하는 인공지능용 영상 출력단계를 포함하는 영상 처리 방법을 제공한다. 본 발명의 제2 양상에 따른 영상 처리 방법에서, 상기 인공지능용 영상 프레임은 상기 기본 영상 프레임에 비하 여 지속시간이 짧을 수 있다. 또한 본 발명의 제2 양상에 따른 영상 처리 방법에서, 상기 인공지능용 영상은 상기 디스플레이의 일부 영역에 만 표시될 수 있다. 또한 본 발명의 제2 양상에 따른 영상 처리 방법에서, 상기 인공지능용 영상 출력단계에서는 이동체 접근이 감 지된 경우에 한하여 인공지능용 영상을 출력할 수 있다. 본 발명의 제3 양상은, 카메라; 카메라 촬영 영상의 각 프레임을 분석하여 등록된 인공지능용 영상이 포함된 프 레임이 있는지 확인하고, 인공지능용 영상으로부터 정보를 획득하는 인공지능용 영상 확인부; 카메라 촬영 영상 을 분석하여 주변 객체를 분류하고 제어 지령을 생성하는 인공지능부; 메모리에 저장된 제어 프로그램을 실행하 며, 인공지능용 영상 확인부에서 획득한 정보를 처리하는 프로세서를 포함하는 인공지능 기기를 제공한다. 본 발명의 제3 양상에 따른 인공지능 기기에서, 상기 인공지능용 영상은 충돌 경고 영상이고, 상기 인공지능용 영상 확인부에서 충돌 경고 영상을 확인하면, 상기 인공지능부는 카메라의 촬영 영상에서 충돌 경고 영상이 표 시된 영역을 고정 장애물로 간주하고 영상 분석을 수행할 수 있다. 또한 본 발명의 제3 양상에 따른 인공지능 기기는, 주변 객체와의 거리를 감지하는 거리감지센서를 더 포함하고, 상기 인공지능부는, 입력노드에 카메라 촬영 영상, 거리감지센서의 측정값 및 인공지능용 영상 확인 부에서 확인한 인공지능용 영상 정보가 입력되는 딥러닝 알고리즘을 포함할 수 있다. 또한 본 발명의 제3 양상에 따른 인공지능 기기는, 인공지능용 영상을 출력하는 영상 처리 장치로 기기 식별정 보를 무선으로 전송하는 통신부를 포함할 수 있다."}
{"patent_id": "10-2020-0046060", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명에 따르면, 하나의 디스플레이에서 사람을 위한 영상과 인공지능이 인식할 수 있는 영상을 함께 제공할 수 있으므로 디스플레이가 사람은 물론이고 인공지능과의 커뮤니케이션 플랫폼으로 활용될 수 있다. 또한 본 발명에 따르면, 영상분석용 인공지능이 디스플레이의 영상에 포함된 객체를 실제인 것으로 오인하는 인 지 착오를 방지할 수 있고, 이를 통해 자율주행 기기 등이 디스플레이에 충돌하거나 정상 경로에서 이탈하는 사 고를 예방할 수 있다. 또한 본 발명에 따르면, 영상분석용 인공지능이 영상분석을 수행할 때 카메라 영상에서 사전 등록된 패턴이 확 인되면 디스플레이 전체를 고정 장애물로 간주하고 분석 대상에서 제외하는 것이 가능하므로 카메라 영상 중에 서 인공지능이 분석할 객체의 수를 줄일 수 있고 이를 통해 인공지능의 연산속도 및 판단속도를 크게 향상시킬 수 있다."}
{"patent_id": "10-2020-0046060", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하에서는 도면을 참조하여 본 발명의 바람직한 실시예를 상세히 설명한다. 참고로 본 명세서에서 어떤 부분이 어떤 구성요소를 포함 또는 구비하는 것은, 특별히 반대되는 기재가 없는 한 다른 구성요소를 제외하는 것이 아니라 다른 구성요소를 더 포함하거나 구비할 수 있는 것을 의미한다. 또한 하 나의 구성요소(element)가 다른 구성요소와 연결, 결합, 또는 통신하는 경우는, 다른 구성요소와 직접적으로 연 결, 결합, 또는 통신하는 경우만 아니라 중간에 다른 요소를 사이에 두고 간접적으로 연결, 결합, 또는 통신하 는 경우도 포함한다. 또한 하나의 구성요소가 다른 구성요소와 직접 연결 또는 직접 결합되는 경우는 중간에 다 른 요소가 개재되지 않는 것을 의미한다. 또한 본 명세서에 첨부된 도면은 발명의 요지를 이해하기 쉽도록 예시 한 것에 불과하므로 이로 인해 본 발명의 권리범위가 제한되어서는 아니 됨을 미리 밝혀 둔다. 본 발명은, 사람이 인식할 수 있는 기본 영상과 인공지능만이 인식할 수 있는 인공지능용 영상을 모두 출력할 수 있는 영상 처리 장치와 이를 이용하는 인공지능 기기에 관한 것이다. 먼저 본 발명의 일 실시예에 따른 영상 처리 장치는, 도 4의 블록도에 나타낸 바와 같이, 프로세서, 메모리, 디스플레이, 입력부, 통신부, 접근감지부, 버스 등을 포함할 수 있다. 프로세서는 메모리에 저장된 컴퓨터 프로그램을 실행하여 소정의 연산이나 데이터 처리를 실행한다. 프로세서는 CPU(Central Processing Unit)와 GPU(Graphics Processing Unit) 중에서 적어도 하나를 포함 할 수 있다. 메모리는 비휘발성 메모리(예: 플래시 메모리 등)와 휘발성 메모리(예: RAM(random access memory)를 포함 할 수 있다. 또한 메모리는 HDD, SSD, CD-ROM 등의 대용량 스토리지를 포함할 수 있다. 메모리는 영상 처리 장치의 동작을 위한 컴퓨터 프로그램, 디스플레이를 통해 출력할 기본 영 상 데이터 및 인공지능용 영상데이터를 저장할 수 있다. 컴퓨터 프로그램 및/또는 영상데이터는 비휘발성 메모 리에 저장되고 휘발성 메모리로 로드되어 실행될 수 있다. 메모리에 저장된 컴퓨터 프로그램은, 도 5의 블록도에 예시한 바와 같이, 디스플레이의 출력을 제어 하는 제어 프로그램을 포함하며, 제어 프로그램에는 영상출력제어부가 포함될 수 있다. 영상출력제어부는 사전 설정된 방법에 따라 디스플레이를 제어하여 인공지능용 영상을 출력한다. 구 체적인 인공지능용 영상 출력 방법에 대해서는 후술하기로 한다. 도면에는 영상출력제어부가 메모리에 저장된 프로그램 형태의 소프트웨어인 것으로 나타나 있으나, 이에 한정되는 것은 아니다. 예를 들어 영상출력 제어 기능 중에서 적어도 일부의 기능은 하드웨어로 구현될 수 도 있고, 소프트웨어와 하드웨어의 조합으로 구현될 수도 있다. 이때 하드웨어는 주문형 반도체(ASIC, Application Specific Integrated Circuit) 일 수도 있다. 디스플레이는 영상이 표시되는 패널과 패널의 각 화소에 전기적 신호를 인가하는 드라이버 IC를 포함할 수 있다. 패널의 종류는 특별히 한정되지 않으며 LCD, LED, OLED, PDP 등의 평판패널일 수도 있고, LED전광판일 수 도 있고, 기타 다른 방식으로 영상을 표현하는 장치일 수도 있다. 또한 디스플레이는 홀로그램을 표현하는 디스플레이일 수도 있다. 입력부는 영상 처리 장치의 관리자 또는 사용자를 위한 입력수단으로서, 키보드, 버튼, 터치패드, 터 치스크린, 마우스, 조이스틱 중에서 적어도 하나를 포함할 수 있다. 통신부에서 수신한 제어신호를 프로세 서로 전달하는 통신 인터페이스가 입력부의 역할을 할 수도 있다.통신부는 유선 및/또는 무선 통신 모듈을 포함하며, 그 종류는 특별히 한정되지 않는다. 무선 통신 모듈은, 예를 들어, Wi-Fi, 블루투스(Bluetooth), 지웨이브(Z-wave), 지그비(Zigbee), BLE(Bluetooth Low Energy), UWB(Ultra-Wideband) 등의 근거리 무선 통신 모듈 중에서 적어도 하나를 포함할 수도 있고, LTE-M, NB-Iot(NarrowBand-Internet of Things), LoRa(Long Range Wide Area Network) 등의 저전력 광역(Low Power Wide-Area: LPWA) 통신 모듈 중에서 적어도 하나를 포함할 수도 있고, 이동통신망 접속을 위한 이동통신 모듈을 포함할 수도 있다. 또한 통신부는 V2X 통신 인터페이스 중에서 적어도 하나를 포함할 수도 있다. V2X(Vehicle to Everything)는 예를 들어 차량 간의 통신(V2V), 차량과 인프라 간의 통신(V2I), 차량과 보행자 간의 통신(V2P), 차량과 네트워크 간의 통신(V2N) 등을 포함할 수 있다. 접근감지부는 이동체 접근을 감지하기 위한 것으로서, 레이더센서, 적외선센서, 초음파 센서, 레이저센서 중에서 적어도 하나를 포함할 수 있다. 또한 접근감지부는 카메라 영상을 분석하여 이동체의 접근여부를 판단하는 영상분석장치 또는 영상분석 소프트웨어일 수도 있다. 접근감지부는 이동체가 접근할 때만 인공지능용 영상 및/또는 기본 영상을 출력하도록 제어하기 위한 것으 로서, 자율주행 기기의 운행이 빈번하지 않은 지역에서 영상 출력으로 인한 전력 소비를 줄이는 용도로 활용될 수 있다. 접근감지부는 생략될 수도 있다. 버스는 영상 처리 장치의 각 구성요소(110,120,130,140,150,160) 간에 전기적 신호를 전송하는 것으 로서, 케이블, 회로패턴 등일 수 있다. 이하에서는 도 6을 참조하여 본 발명의 실시예에 따른 영상 처리 장치가 인공지능용 영상을 출력하는 방법 을 설명한다. 먼저, 영상 처리 장치에서 출력할 기본 영상과 인공지능용 영상을 메모리에 저장하는 한편, 경고출력 제어부에서 인공지능용 영상을 출력할 때 참조할 파라미터(예, 인공지능용 영상의 출력조건, 지속시간, 출 력주기, 출력방법 등)를 설정해야 한다. 인공지능용 영상의 출력조건은, 예를 들어, 항상 출력, 주기적 출력, 이동체 접근 시 출력 등으로 구분될 수 있 다. 또한 인공지능용 영상의 출력 방법은, 기본 영상의 프레임 사이에 인공지능용 영상의 프레임을 삽입하는 방법, 기본 영상의 프레임에 인공지능용 영상의 프레임을 오버랩 시키는 방법, 기본 영상의 프레임에 분할된 인공지능 용 영상의 프레임을 오버랩 시키는 방법 등으로 구분될 수 있다. (ST11) 영상 처리 장치가 동작을 시작하면, 프로세서는 설정된 조건에 따라 기본 영상을 디스플레이를 통해 출력한다. 프로세서는 인공지능용 영상의 출력조건을 확인하고, 출력조건이 '항상 출력' 또는 '주기 적 출력'인 경우에는 설정된 방식에 따라 인공지능용 영상을 함께 출력할 수도 있다. (ST12) 만일 출력조건이 '이동체 접근 시 출력'인 경우에는, 프로세서는 접근감지부의 감지결과를 이용하여 이동체의 접근 여부를 판단한다. (ST13) 프로세서는, 이동체가 접근하는 것으로 판단되면, 설정된 방식에 따라 디스플레이를 통해 인공지능용 영상을 출력할 수도 있고, 도면에 나타낸 바와 같이 이동체가 인공지능 기기인지 여부를 다시 한번 확인할 수도 있다. 예를 들어 운전자가 직접 운전하는 차량이 접근하는 경우에는 굳이 인공지능용 영상을 출력하지 않아도 되기 때 문이다. 접근하는 이동체가 인공지능 기기인지 여부는 인공지능 기기와의 무선 통신을 통해 획득한 기기 식별정보를 통 해 확인할 수 있다. 예를 들어 자율주행 통신규격인 V2X 통신을 통해 자율주행 기기의 식별정보를 획득하고 이 를 통해 자율주행 기기의 접근 여부를 확인할 수 있다. (ST14) 만일 접근하는 이동체가 인공지능 기기인 것으로 확인되면, 프로세서는 설정된 방법에 따라 디스플레이 를 통해 인공지능용 영상을 출력한다. (ST15) 한편 접근했던 이동체가 지나갔거나 다른 이동체가 접근하지 않는 경우에는 인공지능용 영상의 출력을 중단할 수 있다. 이를 위해 프로세서는 이동체의 접근 여부를 계속 감시하여 이동체가 접근하지 않는 경우에는 인 공지능용 영상의 출력을 종료하고 기본 영상만을 출력할 수 있다. (ST16, ST17) 이하에서는 도 7을 참조하여 본 발명의 실시예에 따른 인공지능용 영상의 출력 방법을 설명한다. 일반적으로 디스플레이가 기본 영상을 출력할 때는, 도 7(a)에 나타낸 바와 같이, 다수의 기본 영상의 프 레임(fo)을 일정한 휴지기간(△t)을 두고 주기적으로 출력한다. 본 발명의 일 실시예에 따른 인공지능용 영상 출력 방법은 이러한 휴지기간(△t)을 활용하는 것으로서, 도 7 (b)의 프레임 구성도에 나타낸 바와 같이, 기본 영상의 프레임(fo) 사이의 각 휴지기간(△t)에 인공지능용 영상 프레임(fa)을 삽입하는 방법이다. 이때 삽입되는 인공지능용 영상 프레임(fa)의 지속시간은 기본 영상 프레임 (fo)의 지속시간에 비해 짧은 것이 바람직하지만 반드시 이에 한정되는 것은 아니다. 한편, 고속 카메라의 경우 보급형 수준이라도 최소 1,000fps(frame per second) 정도의 성능을 발휘하고, 인간 의 시력은 대략 60Hz 정도까지 구분할 수 있으므로 인공지능 기기에 고속 카메라를 탑재하면 사람이 전혀 인식 할 수 없을 정도로 빠르게 지나가는 영상이라도 인공지능 기기는 고속카메라를 통해 쉽게 확인할 수 있다. 따라서 도 7(b)에 나타낸 바와 같이, 기본 영상 프레임(fo) 사이의 짧은 휴지기간(△t)에 인공지능용 영상 프레 임(fa)을 삽입하면 사람이 기본 영상을 시청하는데 아무런 방해를 주지 않으면서도 인공지능 기기를 대상으로 하는 다양한 영상을 제공할 수 있다. 한편 도 7(b)에는 기본 영상 프레임(fo) 사이의 휴지기간(△t)마다 각 3개씩의 인공지능용 영상 프레임(fa)이 삽입되는 것으로 나타나 있으나 이에 한정되는 것은 아니다. 예를 들어 도 7(c)에 나타낸 바와 같이, 기본 영상 프레임(fo) 사이의 휴지기간(△t)마다 삽입되는 인공지능용 영상 프레임(fa)의 개수가 일정하지 않을 수도 있고, 각 인공지능용 영상 프레임(fa)의 지속시간이 일정하지 않을 수도 있다. 또한 기본 영상 프레임(fo)을 통해서는 아무런 정보를 출력하지 않고, 인공지능용 영상 프레임(fa)을 통해서만 인공지능 기기를 위한 정보를 출력할 수도 있다. 또한 디스플레이를 인공지능 전용 모드로 설정하여, 인공지능용 영상 프레임(fa)만을 고속으로 출력하여 인공지능 기기를 대상으로 대량의 정보를 전송할 수도 있다. 이 경우, 사람의 입장에서는 단순히 깜박이는 정도 의 현상만을 인식할 수 있을 것이다. 도 8은 기본 영상의 사이에 인공지능용 영상이 삽입되어 디스플레이를 통해 출력되는 모습을 예 시한 것이다. 이때 인공지능용 영상에 표시되는 이미지의 종류는 특별히 한정되지 않으며, 도 8(a)에 나타 낸 바와 같이 줄무늬 형태의 인공지능용 패턴(135a)을 포함할 수도 있고, 도 8(b)에 나타낸 바와 같이 디스플레 이의 여러 위치에 사람이 인지할 수 없을 정도의 크기로 표시된 점 형태의 인공지능용 패턴(135a)을 포함 할 수도 있다. 이 밖에 인공지능용 영상을 구성하는 인공지능용 패턴(135a)은 매우 다양하게 구현될 수 있다. 일 예로서, 도 9a에 예시한 바와 같이, 인공지능용 패턴(135a)은 소정의 문자를 포함할 수도 있다. 다른 예로서, 도 9b에 예시한 바와 같이, 인공지능용 패턴(135a)은 도로표지판의 패턴일 수도 있다. 이 경우, 사람의 입장에서는 디스플레이가 정보 또는 광고를 출력하는 것으로 인식하고, 인공지능 기기의 입장 에서는 디스플레이가 도로표지판의 기능을 하는 것으로 인식할 수 있다. 또 다른 예로서, 도 9c에 나타낸 바와 같이, 디스플레이의 전체 영역이 아니라 일부 영역을 특정하여 인공 지능용 패턴(135a)을 표시할 수 있다. 한편 인공지능용 영상을 어떤 방법으로 출력하든 인공지능용 프레임(fa)의 프레임 레이트(fps)가 너무 높거나 프레임 지속시간이 너무 길면 사람의 눈에도 인공지능용 영상이 보여서 기본 영상을 시청하는데 방해가 될 수 있다. 따라서 사람의 눈에는 보이지 않을 정도로 인공지능용 프레임(fa)의 프레임 레이트 및/또는 지속시간을 적절히 선택하는 것이 바람직하다. 또한 인공지능용 프레임(fa)의 프레임 레이트가 너무 낮거나 지속시간이 너무 짧으면 인공지능 기기에서 카메라 영상분석으로 인공지능용 영상을 인식하지 못하는 경우가 발생할 수 있다. 따라서 인공지능 기기에 장착된 카메라의 fps 성능을 고려하여 인공지능용 프레임(fa)의 프레임 레이트 및/또는 지속시간을 적절히 선택 하는 것이 바람직하다.다음으로 본 발명의 일 실시예에 따른 인공지능 기기를 설명한다. 인공지능 기기는, 도 10의 블록도에 나타낸 바와 같이, 프로세서, 메모리, 카메라, 인공지 능용 영상 확인부, 인공지능부, 동작조절부, 거리감지센서, 통신부, 버스 등을 포함할 수 있다. 프로세서는 메모리에 저장된 컴퓨터 프로그램을 실행하여 소정의 연산이나 데이터 처리를 실행한다. 프로세서는 CPU와 GPU중에서 적어도 하나를 포함할 수 있다. 메모리는 비휘발성 메모리와 휘발성 메모리를 포함할 수 있다. 또한 메모리는 HDD, SSD, CD-ROM 등의 대용량 스토리지를 포함할 수 있다. 메모리는 인공지능 기기의 동작을 위한 컴퓨터 프로그램, 제어 파라미터, 데이터 등을 저장할 수 있다. 컴퓨터 프로그램, 제어 파라미터, 데이터 등은 비휘발성 메모리에 저장 되고 휘발성 메모리로 로드되어 실행될 수 있다. 카메라는 기기 주변의 영상을 획득하기 위한 것으로서, 구체적인 종류는 한정되지 않는다. 다만, 영상 처 리 장치의 디스플레이에서 짧은 시간 동안 출력되는 인공지능용 영상을 촬영하기 위해서는 카메 라의 영상 생성 프레임 레이트(fps)는 디스플레이의 영상 출력 프레임 레이트(fps)에 비해 충분히 큰 것이 바람직하다. 인공지능용 영상 확인부는 카메라에서 촬영한 영상에 인공지능용 영상이 포함되어 있는지 여부 를 판단한다. 구체적으로는, 카메라 촬영 영상에 포함된 디스플레이의 영상에 인공지능용 영상이 포 함되어 있는지 여부를 판단한다. 인공지능용 영상 확인부는 카메라 영상의 각 프레임을 모두 분석하여 사전에 등록된 인공지능용 영상 또는 인공지능용 패턴(135a)이 포함된 프레임이 존재하는지 여부를 판단하는 것이 바람직하다. 인공지능용 영상 확인부가 인공지능용 영상을 확인하면, 프로세서는 인공지능용 영상에서 획득한 정보를 기초로 인공지능 기기의 동작을 제어할 수 있다. 또한 인공지능용 영상 확인부는 인공지능용 영상을 확인한 후에 해당 정보를 인공지능부로 전달 할 수도 있다. 한편 디스플레이에서 출력되는 인공지능용 영상을 카메라로 촬영하는 경우에는, 촬영 각도, 거 리, 조도, 날씨 등에 따라 인공지능용 영상의 패턴이 다양하게 변형되어 촬영될 수도 있다. 따라서 인공지능용 영상 확인부는 인공지능용 영상의 다양한 변형 패턴을 사전에 모두 저장해 두거나 머신러닝을 통해 미리 학습해 두는 것이 바람직하다. 인공지능용 영상의 패턴에 대한 머신 러닝에는 지도 학습 방식의 알고리즘이 사용될 수도 있고, 딥러닝 영상 분석 알고리즘이 사용될 수도 있다. 인공지능부는 카메라에서 획득한 영상, 인공지능용 영상 확인부에서 획득한 인공지능용 영상 , 거리감지센서에서 획득한 거리 정보 등을 이용하여 인공지능 기기의 동작을 제어한다. 인공지능부에서 실행되는 인공지능 알고리즘의 종류는 특별히 한정되지 않는다. 예를 들어, DNN(Deep Neural Network), CNN(convolutional Neural Network), RNN(Recurrent Neural Network) 등의 인공신경망(ANN, Artificial Neural Network)을 기반으로 하는 딥러닝 알고리즘을 이용하여 인공지능 기기의 동작을 제어할 수 있다. 딥러닝 알고리즘의 인공신경망(ANN)은 도 11에 예시한 바와 같이 입력 레이어와 출력 레이어의 사이에 하나 이 상의 히든 레이어(hidden layer)를 가지며, 딥러닝 알고리즘을 통한 학습은 임의의 제1 레이어의 노드(뉴런)와 제2 레이어의 노드(뉴런) 사이에 부여된 가중치([W]1,,,,[W]n)를 최적화하는 과정이다. 딥러닝 알고리즘은 학습주기마다 또는 설정된 주기마다 출력 노드의 출력값과 목표값 사이의 오차를 기초로 경 사감소법(Gradient Descent Method) 등을 적용하여 각 가중치([W]1,,,,[W]n)를 갱신함으로써 출력값의 정확도 를 지속적으로 향상시킬 수 있다. 인공지능 기기가 자율주행 기기인 경우에는, 입력 레이어의 각 입력 노드에는 카메라에서 획득한 영 상과, 인공지능용 영상 확인부에서 확인한 인공지능용 영상 정보와, 거리감지센서의 측정값 등이 입 력될 수 있고, 출력 레이어의 출력 노드는 입력된 정보에 대응하여 자율주행 기기를 제어하기 위한 속도지령 및 /또는 방향지령을 출력할 수 있다. 속도지령은 가속, 감속, 정지 지령 등을 포함하고, 방향지령은 수평방향 이외에도 수직방향의 지령을 포함할 수 도 있다. 인공지능부는 별도의 프로세서, 메모리, 데이터 등을 구비하는 모듈 형태로 탑재될 수도 있고, 인공지능 기기의 프로세서와 메모리를 활용하여 연산을 수행하는 소프트웨어 형태로 설치될 수도 있다. 또한 인공지능부는 구성 요소 전부가 인공지능 기기에 탑재될 수도 있고, 일부 기능이 통신부와 통신이 가능한 원격에서 실행되는 분산형 시스템으로 구현될 수도 있다. 동작조절부는 인공지능부의 지령에 응하여 인공지능 기기의 동작을 제어한다. 인공지능 기기 가 자율주행 기기인 경우에는, 동작조절부는 속도지령에 응하여 엔진 속도, 모터 속도, 변속기어, 브 레이크 등을 제어하는 속도조절부와 방향지령에 응하여 주행방향을 제어하는 방향조절부를 포함할 수 있다. 거리감지센서는 인공지능 기기가 주변 객체와의 거리 등을 측정하기 위한 것으로서, 레이더센서, 초 음파센서, 적외선센서, 레이저센서, 라이다(LiDAR) 중에서 적어도 하나를 포함할 수 있다. 통신부는 유선 및/또는 무선 통신 모듈을 포함하며, 그 종류는 특별히 한정되지 않는다. 무선 통신 모듈은, 예를 들어, Wi-Fi, 블루투스, 지웨이브, 지그비, BLE, UWB 등의 근거리 무선 통신 모듈 중에서 적어도 하나를 포함할 수도 있고, LTE-M, NB-Iot, 저전력 광역(LPWA) 통신 모듈 중에서 적어도 하나를 포함할 수도 있 고, 이동통신망 접속을 위한 이동통신 모듈을 포함할 수도 있고, V2X 통신 인터페이스 중에서 적어도 하나를 포 함할 수도 있다. 버스는 인공지능 기기의 각 구성요소 간에 전기적 신호를 전송하는 것으로서, 케이블, 회로패턴 등일 수 있다. 이하에서는 도 12를 참조하여 본 발명의 실시예에 따른 인공지능 기기가 인공지능용 영상을 이용하여 기기 의 동작을 제어하는 방법을 설명한다. 먼저, 영상 처리 장치에서 출력되는 인공지능용 영상에 대한 정보를 사전에 인공지능 기기의 메 모리에 저장한다. (ST21) 이어서 인공지능 기기가 카메라를 이용하여 주변 환경을 촬영한다. (ST22) 카메라에서 촬영된 영상은 인공지능용 영상 확인부로 전달되며, 인공지능용 영상 확인부는 촬영 한 영상의 각 프레임을 분석하여 인공지능용 영상이 포함되어 있는지 여부를 확인한다. (ST23, ST24) 인공지능용 영상 확인부는 인공지능용 영상이 발견되면, 인공지능용 영상으로부터 소정의 정보 를 획득할 수 있다. 인공지능용 영상으로부터 획득할 수 있는 정보의 종류는 특별히 제한되지 않는다. 예 를 들어 인공지능 기기는 인공지능용 영상에서 단순히 데이터를 인식할 수도 있고, 소정의 명령을 인 식할 수도 있다. (ST25) 프로세서는 인공지능용 영상 확인부에서 획득한 정보를 사전 설정된 방법으로 처리할 수 있다. 예를 들어, 프로세서는 인공지능용 영상 확인부에서 획득한 정보를 가장 우선적으로 처리할 수도 있고, 별 도로 설정된 순서대로 처리할 수도 있다. (ST26) 한편, 인공지능용 영상 확인부가 카메라 촬영 영상에 인공지능용 영상이 포함되어 있는지 확인하는 중이거 나 카메라 촬영 영상에 인공지능용 영상이 포함되어 있지 않은 경우에도 인공지능부는 카메라 촬영 영상에 포함된 모든 객체를 대상으로 딥러닝 기반의 영상분석을 수행할 수 있다. (ST27) 따라서 본 발명의 실시예에 따른 인공지능 기기는, 인공지능용 영상에서 획득한 정보를 이용하여 기 기의 동작을 제어하거나 소정의 데이터를 생성할 수도 있고, 인공지능부의 딥러닝 영상 분석 결과를 이용 하여 기기의 동작을 제어하거나 소정의 데이터를 생성할 수도 있다. (ST28) 이하에서는, 인공지능 기기가 차량, 드론, 로봇 등의 자율주행 인공지능 기기이고 영상 처리 장치에 서 출력되는 인공지능용 영상이 충돌 경고 영상인 경우를 가정하여, 자율주행 인공지능 기기가 주행 제어하는 방법을 도 13의 흐름도를 참조하여 설명한다. 먼저, 영상 처리 장치에서 출력되는 인공지능용 충돌 경고 영상에 대한 정보를 자율주행 인공지능 기 기에 저장한다. (ST31)이어서 자율주행 인공지능 기기가 주행하면서 카메라를 이용하여 주변 환경을 촬영한다. (ST32) 카메라에서 촬영된 영상은 실시간으로 인공지능용 영상 확인부와 인공지능부로 전달되며, 인공 지능용 영상 확인부는 촬영한 영상의 각 프레임을 분석하여 인공지능용 충돌 경고 영상과 동일한 패 턴이 포함된 프레임이 있는지 여부를 확인하고, 인공지능부는 카메라 촬영 영상에 포함된 객체의 분류 작 업을 위하여 딥러닝 영상 분석을 시작한다. (ST33, ST34) 인공지능용 영상 확인부는 카메라 촬영 영상의 프레임 중에서 인공지능용 충돌 경고 영상이 발견되면 해당 정보를 인공지능부로 전달하며, 인공지능부는 인공지능용 충돌 경고 영상이 표시된 디스플 레이 전체를 고정 장애물로 간주한 후 딥러닝 영상 분석을 수행한다. 이렇게 하면 인공지능부는 디스플레이와 디스플레이에 표시된 이미지에 대해서는 딥러닝 분석을 수행할 필요가 없으므로 연산시간을 크게 단축시킬 수 있을 뿐만 아니라 디스플레이에 표시된 이미지로 인 한 인지 착오를 방지함으로써 주행 안전성을 개선할 수 있다. (ST35) 만일 카메라 촬영 영상의 프레임 중에서 인공지능용 충돌 경고 영상이 발견되지 않으면, 인공지능부 는 카메라 촬영 영상에 포함된 모든 객체를 대상으로 딥러닝 영상분석을 수행한다. (ST36) 이어서 인공지능부는 딥러닝 영상 분석 결과를 토대로 속도지령 및/또는 방향지령을 출력하여 주행 속도 및/또는 방향을 제어한다. (ST37) 한편 본 발명의 실시예에 따른 영상 처리 방법이나 인공지능 기기의 제어방법은 다양한 컴퓨터 수단을 통하여 수행될 수 있는 프로그램 명령 형태로 구현되어 컴퓨터로 판독 가능한 기록 매체에 기록될 수 있다. 이때, 컴퓨터로 판독 가능한 기록매체는 프로그램 명령, 데이터 파일, 데이터 구조 등을 단독으로 또는 조합하 여 포함할 수 있다. 기록매체에 기록되는 프로그램 명령은 본 발명을 위하여 특별히 설계되고 구성된 것들이거 나 컴퓨터 소프트웨어 관련 통상의 기술자에게 공지되어 사용 가능한 것일 수도 있다. 컴퓨터로 판독 가능한 기록매체는 하드 디스크, 플로피 디스크 및 자기 테이프와 같은 자기 매체(Magnetic Media), CD-ROM, DVD와 같은 광기록 매체(Optical Media), 플롭티컬 디스크(Floptical Disk)와 같은 자기-광 매체(Magneto-Optical Media), 롬(ROM), 램(RAM), 플래시 메모리 등에서 적어도 하나를 포함할 수 있다. 또한 프로그램 명령에는 컴파일러에 의해 만들어지는 것과 같은 기계어 코드뿐만 아니라 인터프리터 등을 사용 해서 컴퓨터에 의해서 실행될 수 있는 고급 언어 코드를 포함할 수 있다. 이상에서는 본 발명의 바람직한 실시예를 설명하였으나, 본 발명은 앞서 설명한 실시예에 한정되지 않고 구체적 인 적용 과정에서 다양하게 변형 또는 수정되어 실시될 수 있다. 첫째, 본 발명의 실시예에서는 영상 처리 장치의 디스플레이에서 사람을 위한 기본 영상과 인공 지능용 영상을 함께 출력하는 것으로 설명하였으나 동작 방식이 이에 한정되는 것은 아니다. 예를 들어, 영상 처리 장치의 동작모드를 기본 영상 만을 출력하는 제1 동작모드, 인공지능용 영상 만을 출력하는 제2 동작모드, 기본 영상과 인공지능용 영상을 앞서 설명한 방식으로 함께 출력 하는 제3 동작모드 등으로 구분하여 필요에 따라 동작모드를 선택할 수도 있다. 이때 영상 처리 장치의 프로세서는 설정된 조건의 충족 여부에 따라 특정 동작모드를 선택할 수도 있 고, 입력부 또는 통신부를 통해 입력된 관리자의 명령에 응하여 동작모드를 선택할 수도 있고, 통신 부를 통해 수신한 인공지능 기기의 요청에 응하여 동작모드를 선택할 수도 있다. 둘째, 이상에서는 영상 처리 장치의 디스플레이에서 인공지능용 영상을 출력할 때, 기본영상 프 레임(fo) 사이의 휴지기간(△t)에 인공지능용 프레임(fa)이 삽입되는 것으로 설명하였으나 반드시 이에 한정되 는 것은 아니다. 일 예로서, 도 14(a)의 프레임 구성도에 나타낸 바와 같이, 기본 영상의 프레임(fo)에 인공지능용 영상의 프레 임(fa)을 오버랩 시켜서 출력할 수도 있다. 이 방법은 기본영상 프레임(fo) 사이의 휴지기간(△t)이 매우 짧은 경우에 유용한 방법이다. 도 15는 기본 영상에 인공지능용 영상이 오버랩 되면서 디스플레이를 통해 인공지능용 패턴 (135a)이 주기적으로 출력되는 모습을 예시한 것이다.한편 도 14(a)에는 모든 기본 영상 프레임(fo)에 주기적으로 동일한 개수의 인공지능용 영상 프레임(fa)이 오버 랩되는 것으로 나타나 있으나 이는 예시에 불과하다. 따라서 각 기본 영상 프레임(fo)에 오버랩되는 인공지능용 영상 프레임(fa)의 개수 및/또는 지속시간은 서로 다를 수 있다. 또한 필요한 경우에는, 도 14(b)의 프레임 구성도에 나타낸 바와 같이, 기본영상 프레임(fo)에 인공지능용 영상 프레임(fa)을 오버랩시키는 한편 기본영상 프레임(fo) 사이의 휴지기간(△t)에도 인공지능용 영상 프레임(fa)을 삽입하여 출력할 수도 있다. 또한 기본영상 프레임(fo)의 주기 및 휴지기간(△t)을 전혀 고려하지 않고 인공지능용 영상 프레임(fa)을 설정 된 주기마다 기본 영상에 오버랩시켜서 출력하는 것도 가능하다. 다른 예로서, 도 16(a)의 프레임 구성도에 나타낸 바와 같이, 기본 영상의 프레임(fo)에 인공지능용 영상의 프 레임(fa)을 오버랩 시키되, 인공지능용 프레임(fa)을 fa1, fa2, fa3, fa4, fa5, fa6 등과 같이 다수 개로 분할 하여 기본 영상의 프레임(fo)에 순차적으로 오버랩 시켜서 출력하는 방법이다. 이렇게 하면 도 17에 나타낸 바와 같이, 인공지능용 패턴(135a)이 하나의 기본 영상에 모두 표시되는 것이 아니라 다수의 분할된 인공지능용 패턴(135a-1,,,,,135a-6)이 다수의 기본 영상에 하나씩 순차적으로 오버 랩되어 표시되므로 일종의 애니메이션 효과를 얻을 수 있다. 도 16(a)에는 다수의 분할된 인공지능용 프레임(fa1, fa2, fa3, fa4, fa5, fa6)을 기본 영상의 프레임(fo)에 연속적으로 오버랩 시키는 것으로 나타나 있으나 이에 한정되는 것은 아니다. 예를 들어 도 16(b)에 나타낸 바 와 같이, 기본 영상의 프레임(fo)을 하나씩 건너뛰면서 분할된 인공지능용 영상의 프레임(fa1, fa2, fa3, fa4, fa5, fa6)을 연속적으로 오버랩 시킬 수도 있고, 이와 다른 방식으로 오버랩 시킬 수도 있으며, 이를 통해 다양 한 방식으로 인공지능용 영상을 제공할 수 있다. 이와 같이 디스플레이를 통해 인공지능용 영상 프레임(fa)을 출력하는 구체적인 방법은 필요에 따라 다양 하게 변형 또는 수정될 수 있다. 다만, 어떠한 방식으로 출력하든 기본 영상을 시청하는 사람이 인식할 수 없을 정도로 인공지능용 영상 프레임(fa)의 출력주기 및/또는 지속시간을 적절히 조절해야 함은 물론이다. 셋째, 도 10의 블록도에는 인공지능용 영상 확인부가 인공지능부와 별도로 설치되는 것으로 나타나 있으나 이에 한정되는 것은 아니다. 즉, 인공지능용 영상 확인부는 인공지능 기반으로 구현될 수도 있으며, 이 경우 인공지능용 영상 확인부 는 인공지능부에 포함될 수도 있고, 별도의 인공지능 모델로 구현될 수도 있다. 이와 같이 본 발명은 다양한 형태로 변형 또는 수정되어 실시될 수 있으며, 변형 또는 수정된 실시예도 후술하 는 특허청구범위에 개시된 본 발명의 기술적 사상을 포함한다면 본 발명의 권리범위에 속함은 당연하다 할 것이다."}
{"patent_id": "10-2020-0046060", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 영상분석용 인공지능이 카메라 영상에서 객체를 분류하는 모습을 예시한 도면 도 2와 도 3은 자율주행 기기가 디스플레이에 충돌하는 여러 경우를 예시한 도면 도 4는 본 발명의 일 실시예에 따른 영상 처리 장치의 블록도 도 5는 제어 프로그램의 기능 블록도 도 6은 본 발명의 일 실시예에 따른 영상 처리 장치가 인공지능용 영상을 출력하는 과정을 예시한 흐름도 도 7은 본 발명의 일 실시예에 따른 인공지능용 영상 표시방법을 나타낸 프레임 구성도 도 8은 본 발명의 일 실시예의 방법에 따라 디스플레이에 출력되는 영상을 예시한 도면 도 9a 내지 도 9c는 다양한 인공지능용 영상을 예시한 도면 도 10은 본 발명의 일 실시예에 따른 인공지능 기기의 블록도 도 11은 딥러닝 모델 아키텍처를 예시한 도면도 12는 인공지능용 영상을 이용한 인공지능 기기의 제어방법을 예시한 흐름도 도 13은 충돌경고 영상을 이용한 자율주행 인공지능 기기의 주행제어방법을 예시한 흐름도 도 14는 인공지능용 영상 표시방법의 변형 예를 나타낸 프레임 구성도 도 15는 도 14의 프레임 구성을 적용한 출력 영상을 예시한 도면 도 16은 인공지능용 영상 표시방법의 다른 변형 예를 나타낸 프레임 구성도 도 17은 도 16의 프레임 구성을 적용한 출력 영상을 예시한 도면"}
