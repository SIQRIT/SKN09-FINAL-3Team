{"patent_id": "10-2023-0020187", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0127147", "출원번호": "10-2023-0020187", "발명의 명칭": "이기종 데이터 혼합을 통한 강건한 인공지능 모델 학습 장치 및 방법", "출원인": "서울시립대학교 산학협력단", "발명자": "오창대"}}
{"patent_id": "10-2023-0020187", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "단말로부터 서로 다른 도메인에 존재하는 복수의 학습 데이터를 포함하는 이기종 학습 데이터를 수신하는 데이터 수신 모듈; 및상기 수신된 이기종 학습 데이터에 대한 데이터 혼합을 수행하여 혼합 데이터를 생성하는 데이터 혼합 모듈을포함하되,상기 데이터 혼합 모듈은, 상기 이기종 학습 데이터의 소정 차원의 임베딩 공간(embedding space)에서의 측지 곡선(geodesic)에 기초하여상기 데이터 혼합을 수행하는 인공지능 모델 학습 장치."}
{"patent_id": "10-2023-0020187", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1 항에 있어서,상기 학습 데이터는, 텍스트 데이터, 이미지 데이터, 소리 데이터 또는 포인트 클라우드 데이터를 포함하는인공지능 모델 학습 장치."}
{"patent_id": "10-2023-0020187", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1 항에 있어서,상기 데이터 혼합 모듈은, 히든 단계(hidden representation)에서 상기 이기종 학습 데이터에 대한 혼합을 수행하는 인공지능 모델 학습 장치."}
{"patent_id": "10-2023-0020187", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1 항에 있어서,상기 데이터 혼합 모듈은, 상기 생성된 혼합 데이터가 상기 이기종 학습 데이터의 상기 측지 곡선에 기반한 초구(hypersphere)상에 존재하도록 상기 데이터 혼합을 수행하는 인공지능 모델 학습 장치."}
{"patent_id": "10-2023-0020187", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1 항에 있어서,상기 생성된 혼합 데이터를 기초로 학습을 수행하여 학습 모델을 생성하는 학습 수행 모듈을 더 포함하되,공개특허 10-2024-0127147-3-상기 학습 수행 모듈은,파지티브 페어(positive pair)간의 거리는 최소화하고, 네거티브 페어(negative pair)간의 거리는 최대화 하는대조 학습법(contrastive learning)을 이용하여 상기 학습을 수행하는인공지능 모델 학습 장치."}
{"patent_id": "10-2023-0020187", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5 항에 있어서,상기 학습 수행 모듈은,상기 혼합 데이터를 기초로 하드 네거티브 페어(hard negative pair)를 결정하고, 상기 결정된 하드 네거티브 페어를 상기 네거티브 페어로서 이용하여 대조 학습을 수행하는 인공지능 모델 학습 장치."}
{"patent_id": "10-2023-0020187", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6 항에 있어서,상기 이기종 학습 데이터는, 제1 텍스트 데이터와 제1 이미지 데이터를 포함하는 제1 데이터 셋과, 제2 텍스트데이터와 제2 이미지 데이터를 포함하는 제2 데이터 셋을 포함하고, 상기 혼합 데이터는, 상기 제1 데이터 셋에 대한 제1 혼합 데이터와, 상기 제2 데이터 셋에 대한 제2 혼합 데이터를 포함할 때,상기 학습 수행 모듈은, 상기 제1 데이터 셋의 상기 제1 텍스트 데이터와 상기 제1 이미지 데이터를 상기 파지티브 페어로 하고, 상기 제1 데이터 셋의 상기 제1 텍스트 데이터 및 상기 제1 이미지 데이터 중 어느 하나와, 상기 제2 혼합 데이터를 상기 하드 네거티브 페어로 하여 학습을 수행하는인공지능 모델 학습 장치."}
{"patent_id": "10-2023-0020187", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "단말로부터 서로 다른 도메인에 존재하는 이기종 학습 데이터를 수신하는 단계; 및 상기 수신된 이기종 학습 데이터에 대한 데이터 혼합을 수행하여 혼합 데이터를 생성하는 단계를 포함하되,상기 혼합 데이터를 생성하는 단계는,상기 이기종 학습 데이터의 소정 차원의 임베딩 공간(embedding space)에서의 측지 곡선(geodesic)에 기초하여상기 데이터 혼합을 수행하는 인공지능 모델 학습 방법."}
{"patent_id": "10-2023-0020187", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8 항에 있어서,상기 혼합 데이터를 생성하는 단계는,상기 생성된 혼합 데이터가 상기 이기종 학습 데이터의 상기 측지 곡선에 기반한 초구(hypersphere)상에 존재하도록 상기 데이터 혼합을 수행하는 공개특허 10-2024-0127147-4-인공지능 모델 학습 방법."}
{"patent_id": "10-2023-0020187", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제8 항에 있어서,상기 생성된 혼합 데이터를 기초로 학습을 수행하여 학습 모델을 생성하는 단계를 더 포함하되,상기 학습 모델을 생성하는 단계는,파지티브 페어(positive pair)간의 거리는 최소화하고, 네거티브 페어(negative pair)간의 거리는 최대화하는대조 학습법(contrastive learning)을 이용하여 상기 학습을 수행하는인공지능 모델 학습 방법."}
{"patent_id": "10-2023-0020187", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "인공지능 모델 학습 장치 및 방법이 제공된다. 상기 인공지능 모델 학습 장치는 단말로부터 서로 다른 도메인에 존재하는 복수의 학습 데이터를 포함하는 이기종 학습 데이터를 수신하는 데이터 수신 모듈 및 상기 수신된 이기 종 학습 데이터에 대한 데이터 혼합을 수행하여 혼합 데이터를 생성하는 데이터 혼합 모듈을 포함하되, 상기 데 이터 혼합 모듈은, 상기 이기종 학습 데이터의 소정 차원의 임베딩 공간(embedding space)에서의 측지 곡선 (geodesic)에 기초하여 상기 데이터 혼합을 수행할 수 있다."}
{"patent_id": "10-2023-0020187", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 인공지능 모델의 강건한 학습을 수행하는 인공지능 모델 학습 장치 및 방법에 관한 것이다. 보다 상 세하게, 본 발명은 이미지, 텍스트 등 상이한 종류의 데이터에 대한 데이터 혼합을 수행한 후, 생성된 혼합 데 이터에 기초하여 학습을 수행할 수 있는 강건한 인공지능 모델 학습 장치 및 방법에 관한 것이다."}
{"patent_id": "10-2023-0020187", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "이 부분에 기술된 내용은 단순히 본 실시예에 대한 배경 정보를 제공할뿐 종래기술을 구성하는 것은 아니다. 머신 러닝(machine learning)은 인공 지능의 한 분야로서 컴퓨터가 특정 문제에 대한 올바른 답을 도출할 수 있 도록 학습 데이터를 통해 문제와 답 사이의 연관 관계를 스스로 학습하게 하는 기술을 의미한다. 최근에는 하나의 기계 학습 알고리즘을 통해 생성된 인공지능 모델을 사용할 뿐만 아니라, 동일한 학습 데이터 에 여러 가지 기계 학습 알고리즘을 적용하여 생성한 다양한 인공지능 모델을 조합하여 결과를 도출하는 앙상블 알고리즘에 대한 연구가 활발히 진행되고 있다. 다만, 일반적인 데이터 혼합과 관련한 학습 데이터 생성 기술의 경우 단일 데이터에 기초한 데이터 혼합 기술에 그친다. 즉, 서로 다른 종류의 데이터의 혼합을 통한 학습 데이터 생성 및 학습 과정에 대하여는 기술 개발이 부족한 상태이고, 따라서 이러한 이기종 데이터간 혼합을 통해 학습을 수행하는 기술에 대한 니즈가 존재해왔다. 선행기술문헌 특허문헌 (특허문헌 0001) 공개특허공보 제10-2019-0179049호"}
{"patent_id": "10-2023-0020187", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명의 목적은, 이미지, 텍스트 등 상이한 종류의 데이터에 대한 데이터 혼합을 수행한 후, 생성된 혼합 데 이터에 기초하여 학습을 수행함으로써 더욱 강건한 인공지능 모델 학습이 가능한 인공지능 모델 학습 장치 및 방법을 제공하는 것이다. 본 발명의 다른 목적은, 측도(geodesic)를 기반으로 데이터 혼합을 수행함으로써 안정적으로 데이터 혼합이 가 능한 인공지능 모델 학습 장치 및 방법을 제공하는 것이다. 본 발명의 또 다른 목적은, 인풋(input) 단계가 아닌 히든 단계(hidden representation)에서 데이터 혼합을 수 행함으로써 보다 안정적인 멀티 모달 러닝이 가능한 인공지능 모델 학습 장치 및 방법을 제공하는 것이다. 본 발명의 목적들은 이상에서 언급한 목적으로 제한되지 않으며, 언급되지 않은 본 발명의 다른 목적 및 장점들 은 하기의 설명에 의해서 이해될 수 있고, 본 발명의 실시예에 의해 보다 분명하게 이해될 것이다. 또한, 본 발 명의 목적 및 장점들은 특허 청구 범위에 나타낸 수단 및 그 조합에 의해 실현될 수 있음을 쉽게 알 수 있을 것 이다."}
{"patent_id": "10-2023-0020187", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 몇몇 실시예에 따른 인공지능 모델 학습 장치는, 단말로부터 서로 다른 도메인에 존재하는 복수의 학 습 데이터를 포함하는 이기종 학습 데이터를 수신하는 데이터 수신 모듈 및 상기 수신된 이기종 학습 데이터에 대한 데이터 혼합을 수행하여 혼합 데이터를 생성하는 데이터 혼합 모듈을 포함하되, 상기 데이터 혼합 모듈은, 상기 이기종 학습 데이터의 소정 차원의 임베딩 공간(embedding space)에서의 측지 곡선(geodesic)에 기초하여 상기 데이터 혼합을 수행할 수 있다. 또한, 상기 학습 데이터는, 텍스트 데이터, 이미지 데이터, 소리 데이터 또는 포인트 클라우드 데이터를 포함할 수 있다. 또한, 상기 데이터 혼합 모듈은, 히든 단계(hidden representation)에서 상기 이기종 학습 데이터에 대한 혼합 을 수행할 수 있다. 또한, 상기 데이터 혼합 모듈은, 상기 생성된 혼합 데이터가 상기 이기종 학습 데이터의 상기 측지 곡선에 기반 한 초구(hypersphere)상에 존재하도록 상기 데이터 혼합을 수행할 수 있다. 또한, 상기 인공지능 모델 학습 장치는 상기 생성된 혼합 데이터를 기초로 학습을 수행하여 학습 모델을 생성하 는 학습 수행 모듈을 더 포함하되, 상기 학습 수행 모듈은, 파지티브 페어(positive pair)간의 거리는 최소화하 고, 네거티브 페어(negative pair)간의 거리는 최대화하는 대조 학습법(contrastive learning)을 이용하여 상 기 학습을 수행할 수 있다. 또한, 상기 학습 수행 모듈은, 상기 혼합 데이터를 기초로 하드 네거티브 페어(hard negative pair)를 결정하고, 상기 결정된 하드 네거티브 페어를 상기 네거티브 페어로서 이용하여 대조 학습을 수행할 수 있다. 또한, 상기 이기종 학습 데이터는, 제1 텍스트 데이터와 제1 이미지 데이터를 포함하는 제1 데이터 셋과, 제2 텍스트 데이터와 제2 이미지 데이터를 포함하는 제2 데이터 셋을 포함하고, 상기 혼합 데이터는, 상기 제1 데이 터 셋에 대한 제1 혼합 데이터와, 상기 제2 데이터 셋에 대한 제2 혼합 데이터를 포함할 때, 상기 학습 수행 모 듈은, 상기 제1 데이터 셋의 상기 제1 텍스트 데이터와 상기 제1 이미지 데이터를 상기 파지티브 페어로 하고, 상기 제1 데이터 셋의 상기 제1 텍스트 데이터 및 상기 제1 이미지 데이터 중 어느 하나와, 상기 제2 혼합 데이 터를 상기 하드 네거티브 페어로 하여 학습을 수행할 수 있다. 본 발명의 몇몇 실시예에 따른 인공지능 모델 학습 방법은, 단말로부터 서로 다른 도메인에 존재하는 이기종 학 습 데이터를 수신하는 단계 및 상기 수신된 이기종 학습 데이터에 대한 데이터 혼합을 수행하여 혼합 데이터를 생성하는 단계를 포함하되, 상기 혼합 데이터를 생성하는 단계는, 상기 이기종 학습 데이터의 소정 차원의 임베 딩 공간(embedding space)에서의 측지 곡선(geodesic)에 기초하여 상기 데이터 혼합을 수행할 수 있다. 또한, 상기 혼합 데이터를 생성하는 단계는, 상기 생성된 혼합 데이터가 상기 이기종 학습 데이터의 상기 측지 곡선에 기반한 초구(hypersphere)상에 존재하도록 상기 데이터 혼합을 수행할 수 있다. 또한, 상기 인공지능 모델 학습 방법은, 상기 생성된 혼합 데이터를 기초로 학습을 수행하여 학습 모델을 생성 하는 단계를 더 포함하되, 상기 학습 모델을 생성하는 단계는, 파지티브 페어(positive pair)간의 거리는 최소 화하고, 네거티브 페어(negative pair)간의 거리는 최대화하는 대조 학습법(contrastive learning)을 이용하여 상기 학습을 수행할 수 있다."}
{"patent_id": "10-2023-0020187", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명의 인공지능 모델 학습 장치 및 방법은, 이미지, 텍스트 등 상이한 종류의 데이터에 대한 데이터 혼합을 수행한 후, 생성된 혼합 데이터에 기초하여 학습을 수행할 수 있어, 이기종 데이터간의 혼합 데이터에 기초한 고도화된 학습을 수행할 수 있는 새로운 효과를 갖는다. 또한, 본 발명의 인공지능 모델 학습 장치 및 방법은 측도(geodesic)를 기반으로 데이터 혼합을 수행함으로써 혼합 전과 혼합 후에 각 데이터들이 균일한 임베딩 공간(embedding space)을 가짐으로써 더욱 안정적인 데이터 혼합이 가능하다. 또한, 본 발명의 인공지능 모델 학습 장치 및 방법은 인풋(input) 단계가 아닌 히든 단계(hidden representation)에서 데이터 혼합을 수행함으로써 보다 안정적인 멀티 모달 러닝이 가능하다. 상술한 내용과 더불어 본 발명의 구체적인 효과는 이하"}
{"patent_id": "10-2023-0020187", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명의 이점 및 특징, 그리고 그것들을 달성하는 방법은 첨부되는 도면과 함께 상세하게 후술되어 있는 실시 예들을 참조하면 명확해질 것이다. 그러나 본 발명은 이하에서 개시되는 실시예들에 한정되는 것이 아니라 서로 다른 다양한 형태로 구현될 것이며, 단지 본 실시예들은 본 발명의 개시가 완전하도록 하며, 본 발명이 속하는"}
{"patent_id": "10-2023-0020187", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "기술분야에서 통상의 지식을 가진 자에게 발명의 범주를 완전하게 알려주기 위해 제공되는 것이며, 본 발명은 청구항의 범주에 의해 정의될 뿐이다. 명세서 전체에 걸쳐 동일 참조 부호는 동일 구성 요소를 지칭한다. 다른 정의가 없다면, 본 명세서에서 사용되는 모든 용어(기술 및 과학적 용어를 포함)는 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자에게 공통적으로 이해될 수 있는 의미로 사용될 수 있을 것이다. 또한, 일반적 으로 사용되는 사전에 정의되어 있는 용어들은 명백하게 특별히 정의되어 있지 않는 한 이상적으로 또는 과도하 게 해석되지 않는다. 또한, 본 발명을 구현함에 있어서 설명의 편의를 위하여 구성요소를 세분화하여 설명할 수 있으나, 이들 구성요 소가 하나의 장치 또는 모듈 내에 구현될 수도 있고, 혹은 하나의 구성요소가 다수의 장치 또는 모듈들에 나뉘 어져서 구현될 수도 있다. 본 발명에서 인공지능, 머신 러닝(Machine Learning) 또는 딥러닝(Deep Learning)은 서로 혼용될 수 있다. 머 신 러닝 기술은 인공지능 기술의 일종이며, 딥러닝 기술은 머신러닝 기술의 일종이다. 딥러닝 기술은 데이터를 기반으로 다단계로 깊은 수준까지 내려가 학습하는 것이다. 딥러닝은, 단계를 높여가면서 복수의 데이터들로부터 핵심적인 데이터를 추출하는 머신 러닝(Machine Learning) 알고리즘의 집합을 나타낸다. 본 명세서에서 언급하는 인공지능 모델은 공지의 인공지능 모델을 의미할 수 있다. 예를 들어, 인공지능 모델은 CNN(Convolutional Neural Network), RNN(Recurrent Neural Network), DBN(Deep Belief Network), GNN(Graph Neural Network) 등의 구조를 이용할 수 있다. 다만, 본 발명에 따른 인공지능 모델 학습 장치 및 방법은 GNN에더욱 큰 효과를 갖는 것으로 입증되었다. 그러나, 본 발명의 실시예들이 이에 제한되는 것은 아니며, 본 발명의 인공지능 모델 학습 장치 및 방법은 상술한 구조 외에도 다양한 구조에 적용될 수 있는 포괄적인 기술이다. CNN은 사람이 물체를 인식할 때 물체의 기본적인 특징들을 추출한 다음 뇌 속에서 복잡한 계산을 거쳐 그 결과 를 기반으로 물체를 인식한다는 가정을 기반으로 만들어진 사람의 뇌 기능을 모사한 모델이다. RNN은 자연어 처리 등에 많이 이용되며, 시간의 흐름에 따라 변하는 시계열 데이터(Time-series data) 처리에 효과적인 구조로 매 순간마다 레이어를 쌓아올려 인공신경망 구조를 구성할 수 있다. DBN은 딥러닝 기법인 RBM(Restricted Boltzman Machine)을 다층으로 쌓아 구성되는 딥러닝 구조이다. RBM 학습 을 반복하여 일정 수의 레이어가 되면, 해당 개수의 레이어를 가지는 DBN이 구성될 수 있다. GNN(Graphic Neural Network)은 특정 파라미터 간 매핑된 데이터를 기초로 모델링된 모델링 데이터를 이용하여, 모델링 데이터 간의 유사도와 특징점을 도출하는 방식으로 구현된 인공신경망 구조를 나타낸다. 한편, 인공지능 모델의 학습은 주어진 입력에 대하여 원하는 출력이 나오도록 노드간 연결선의 웨이트(weight) 를 조정(필요한 경우 바이어스(bias) 값도 조정)함으로써 이루어질 수 있다. 또한, 인공지능 모델은 학습에 의 해 웨이트(weight) 값을 지속적으로 업데이트 시킬 수 있다. 또한, 인공지능 모델의 학습에는 역전파(Back Propagation) 등의 방법이 사용될 수 있다. 인공지능 모델의 학습 방법으로는 비지도학습(unsupervised learning)과 지도학습(supervised learning), 준지 도학습(self-supervised learning)이 모두 사용될 수 있다. 도 1은 본 발명의 몇몇 실시예에 따른 인공지능 모델 학습 시스템의 구성을 개략적으로 설명하기 위한 도면이다. 도 1을 참조하면, 인공지능 모델 학습 시스템은 단말, 인공지능 모델 학습 장치 및 통신망을 포함한다. 단말은 여러 종류의 학습 데이터를 보관하고 있는 장치를 의미한다. 도 1에는 단말의 몇몇 예로서 노트북 PC, 스마트폰 이 예시되어 있으나, 본 발명의 실시예가 이 에 제한되는 것은 아니다. 예컨대, 단말은 도 1에 예시된 노트북 PC, 스마트폰 이외에도, 태블 릿 PC, 데스크탑 컴퓨터, 학습 데이터를 보관하고 있는 데이터베이스 등을 포함할 수 있다. 몇몇 예로, 단말은 서로 다른 도메인에 존재하는 복수의 학습 데이터를 포함하는 이기종 학습 데이터를 저 장하고, 이를 인공지능 모델 학습 장치로 전송할 수 있다. 다시 말하면, 단말은 서로 다른 도메인을 갖는 학습 데이터들을 인공지능 모델 학습 장치로 제공할 수 있다. 이때, 학습 데이터는 텍스트 데이터, 이미지 데이터, 소리 데이터, 포인트 클라우드 데이터 등을 포함할 수 있 으나, 본 발명의 실시예가 이에 제한되는 것은 아니다. 예를 들어, 단말은 전술한 학습 데이터의 몇몇 예 들 중에서, 텍스트 데이터와 이미지 데이터를 이기종 학습 데이터로 하여 인공지능 모델 학습 장치로 제공 할 수 있으나, 본 발명의 실시예가 이에 제한되는 것은 아니다. 몇몇 예로, 이기종 학습 데이터는, 동일한 사실을 나타내는 복수의 학습 데이터 셋 들을 포함할 수 있다. 예를 들어 설명하면, 이기종 학습 데이터는 \"차가 도로위를 달리고 있다\" 또는 \"A Car is driving on the road\" 와 같은 텍스트 데이터와, 해당 텍스트 데이터와 동일한 사실을 나타내는(차가 도로위를 달리고 있는) 이미지 데이 터를 포함하는 학습 데이터 셋을 포함할 수 있다. 이때, 이기종 학습 데이터는 단말의 몇몇 예중 어느 하나(예: 101)에 저장된 데이터일 수도 있고, 여러 단 말(예: 101과 102)에 분산되어 저장된 데이터일 수도 있다. 인공지능 모델 학습 장치는 단말로부터 수신된 이기종 학습 데이터를 기초로 학습 모델을 생성할 수 있다. 몇몇 예로, 인공지능 모델 학습 장치는 수신된 이기종 학습 데이터에 대한 데이터 혼합을 수행하여 혼합 데이터를 생성한 후, 생성된 혼합 데이터를 기초로 학습을 수행할 수 있다. 예를 들어, 인공지능 모델 학습 장치는 서로 동일한 사실을 나타내며 서로 다른 도메인에 존재하는 데이터 를 혼합하는 과정을 통해 혼합 데이터를 생성할 수 있다. 다시 말하면, 혼합 데이터는, 서로 동일한 사실을 나 타내는 학습 데이터 셋의 각 학습 데이터 간의 데이터 혼합 결과일 수 있다. 예를 들어 설명하면, 혼합 데이터 는, \"A Car is driving on the road\"와 같은 텍스트 데이터와, 이와 동일한 사실을 나타내는(예: 차가 도로위를 달리고 있는) 이미지 데이터 간의 데이터 혼합 결과일 수 있다. 다만 본 발명의 실시예가 이에 제한되는 것은 아니다. 이때, 인공지능 모델 학습 장치는 인풋(input) 단계가 아닌, 히든 단계(hidden representation)에서 데이 터 혼합을 수행할 수 있다. 즉, 본 발명의 인공지능 모델 학습 장치는 인풋 단계가 아닌 히든 단계에서 데 이터 혼합을 수행함으로써 보다 안정적인 멀티 모달 러닝이 가능하다. 몇몇 예로, 인공지능 모델 학습 장치는 이기종 학습 데이터와, 이기종 학습 데이터의 혼합 결과인 혼합 데 이터가 동일한 임베딩 공간(embedding space)을 갖도록 데이터 혼합을 수행할 수 있다. 예컨대, 인공지능 모델 학습 장치는 이기종 학습 데이터의 임베딩 공간에서의 측지 곡선(geodesic)에 기반 한 보간법(interpolation)을 이용하여 데이터 혼합을 수행할 수 있다. 예를 들어, 인공지능 모델 학습 장치 는 생성된 혼합 데이터가 이기종 학습 데이터의 측지 곡선에 기반한 초구(hypersphere)상에 존재하도록 데 이터 혼합을 수행하고, 생성된 혼합 데이터를 피팅(fitting)할 수 있다. 이어서, 인공지능 모델 학습 장치는 생성된 혼합 데이터를 기초로, 파지티브 페어(positive pair)간의 거 리는 최소화하고, 네거티브 페어(negative pair)간의 거리는 최대화 하는 대조 학습법(contrastive learning) 을 이용하여 학습을 수행함으로써 학습 모델을 생성할 수 있다. 이때, 인공지능 모델 학습 장치는 생성된 혼합 데이터를 기초로 하드 네거티브 페어를 결정하고, 결정된 하드 네거티브 페어를 기초로 대조 학습을 수행할 수 있다. 이렇듯, 본 발명의 인공지능 모델 학습 장치는, 이미지, 텍스트 등 상이한 종류의 데이터에 대한 데이터 혼합을 수행한 후, 생성된 혼합 데이터에 기초하여 학습을 수행할 수 있어, 이기종 데이터간의 혼합 데이터에 기초한 고도화된 학습을 수행할 수 있는 새로운 효과를 갖는다. 또한, 본 발명의 인공지능 모델 학습 장치는, 측도를 기반으로 데이터 혼합을 수행함으로써 혼합 전과 혼 합 후에 각 데이터들이 균일한 임베딩 공간(embedding space)을 가짐으로써 더욱 안정적인 데이터 혼합이 가능 하다. 인공지능 모델 학습 장치의 구체적인 데이터 혼합 방법 및 학습 방법에 대하여는 도 2를 통해 상술하기로 한다. 한편, 통신망은 단말과 인공지능 모델 학습 장치를 연결하는 역할을 수행한다. 즉, 통신망(30 0)은 인공지능 모델 학습 장치가 단말로부터 데이터를 송수신할 수 있도록 접속 경로를 제공하는 통 신망을 의미한다. 통신망은 예컨대 LANs(Local Area Networks), WANs(Wide Area Networks), MANs(MetRoFolitan Area Networks), ISDNs(Integrated Service Digital Networks) 등의 유선 네트워크나, 무선 LANs, CDMA, 블루투스, 위성 통신 등의 무선 네트워크를 망라할 수 있으나, 본 발명의 범위가 이에 한정되는 것 은 아니다. 이하, 도 2 내지 도 8을 참조하여 인공지능 모델 학습 장치 및 이를 이용한 인공지능 모델 학습 방법에 대 하여 더 자세히 설명한다. 도 2는 본 발명의 몇몇 실시예에 따른 인공지능 모델 학습 장치의 블록도이다. 도 3은 인공지능 모델 학습 방법 의 흐름도이다. 도 2 및 도 3을 참조하면, 인공지능 모델 학습 장치는 수신된 이기종 학습 데이터(Heterogeneous network Learning Data, 이하 \"HLD\"라 한다)를 기초로 학습 모델(Learned Model, 이하 \"LM\"이라 한다)을 생성할 수 있 다. 몇몇 예로, 인공지능 모델 학습 장치는 데이터 수신 모듈, 데이터 혼합 모듈 및 학습 수행 모듈 을 포함할 수 있다. 우선, 데이터 수신 모듈은 단말로부터 서로 다른 도메인에 존재하는 이기종 학습 데이터(HLD)를 수신할 수 있다(S100). 이때, 이기종 학습 데이터(HLD)는 서로 다른 도메인에 존재하는 복수의 학습 데이터를 포함할 수 있다. 다시 말 하면, 이기종 학습 데이터(HLD)는 서로 다른 도메인을 갖는 학습 데이터들을 포함할 수 있다. 이때, 학습 데이 터는 텍스트 데이터, 이미지 데이터, 소리 데이터, 포인트 클라우드 데이터 등을 포함할 수 있으나, 본 발명의 실시예가 이에 제한되는 것은 아니다. 이하, 도 4를 참조하여 이기종 학습 데이터(HLD)에 대하여 더 자세히 설명한다. 도 4는 본 발명의 몇몇 실시예에 따른 이기종 학습 데이터를 설명하기 위한 예시적인 도면이다. 도 4를 참조하면, 학습 데이터(Learning Data, 이하 \"LD\"라 한다)는 텍스트 데이터(Text Data, 이하 \"TD\"라 한 다), 이미지 데이터(Image Data, 이하 \"ID\"라 한다), 소리 데이터(Sound Data, 이하 \"SD\"라 한다), 포인트 클 라우드 데이터(Point Cloud Data, 이하 \"PCD\"라 한다) 등을 포함할 수 있다. 텍스트 데이터(TD)는 국어, 영어, 일어, 중국어, 스페인어 등의 모든 언어를 망라할 수 있다. 이미지 데이터 (ID)는 동영상 및/또는 동영상의 일 프레임인 이미지를 포함할 수 있다. 소리 데이터(SD)는 인간을 포함하는 동 물 및/또는 사물의 소리를 녹음한 데이터를 의미할 수 있다. 이때, 소리 데이터(VD)가 인간의 음성을 녹음한 데 이터인 경우, 소리 데이터(VD)는 텍스트 데이터(TD)와 마찬가지로, 국어, 영어, 일어, 중국어, 스페인어 등의 모든 언어를 망라할 수 있다. 포인트 클라우드 데이터(PCD)는 3차원 공간상에 퍼져 있는 여러 포인트의 집합에 관한 데이터를 의미할 수 있고, 라이다(Lidar)센서, RGB 센서 등을 통해 수집될 수 있다. 이기종 학습 데이터(HLD)는 전술한 학습 데이터(LD) 중에서 적어도 두 종류의 학습 데이터(LD)를 포함할 수 있 다. 다시 말하면, 이기종 학습 데이터(HLD)는 서로 다른 도메인을 갖는 학습 데이터(LD)들의 집합을 포함할 수 있다. 도 4에는 이기종 학습 데이터(HLD)의 몇몇 예로서, 이기종 학습 데이터(HLD)가 텍스트 데이터(TD)와 이미지 데 이터(ID)만을 포함하는 것으로 도시되어 있으나, 본 발명의 실시예가 이에 제한되는 것은 아니다. 이하, 설명의 편의를 위해 이기종 학습 데이터(HLD)는 텍스트 데이터(TD)와 이미지 데이터(ID)를 포함하는 것으로 가정하여 설명하기로 한다. 이때, 이기종 학습 데이터(HLD)는, 동일한 사실을 나타내는 복수의 학습 데이터 셋(Learning Data Set, 이하 \"LDS\"라 한다) 들을 포함할 수 있다. 도 4를 예를 들어 설명하면, 이기종 학습 데이터(HLD)는 \"A Car is driving on the road\"와 같은 텍스트 데이 터와, 해당 텍스트 데이터와 동일한 사실을 나타내는(차가 도로위를 달리고 있는) 이미지 데이터를 포함하는 제 1 데이터 셋(LDS1)을 포함할 수 있다. 또한, 이와 유사하게 이기종 학습 데이터(HLD)는 \"A dog is sitting on the grass\"와 같은 텍스트 데이터와, 해당 텍스트 데이터와 동일한 사실을 나타내는(강아지가 잔디에 앉아있는) 이미지 데이터를 포함하는 제2 데이 터 셋(LDS2)을 포함할 수 있다. 이어서, 다시 도 2 및 도 3을 참조하면, 데이터 혼합 모듈은 수신된 이기종 학습 데이터(HLD)에 대한 데이 터 혼합을 수행할 수 있다(S200). 다시 말하면, 데이터 혼합 모듈은 수신된 이기종 학습 데이터(HLD)에 대 한 데이터 혼합을 수행하여 혼합 데이터(Blended Data, 이하 \"BD\"라 한다)를 생성할 수 있다. 예를 들어, 데이터 혼합 모듈은 서로 동일한 사실을 나타내며 서로 다른 도메인에 존재하는 데이터를 혼합 하는 과정을 통해 혼합 데이터를 생성할 수 있다. 다시 말하면, 혼합 데이터는, 서로 동일한 사실을 나타내는 학습 데이터 셋의 각 학습 데이터 간의 데이터 혼합 결과일 수 있다. 예를 들어 설명하면, 혼합 데이터는, \"A Car is driving on the road\"와 같은 텍스트 데이터와, 이와 동일한 사실을 나타내는(예: 차가 도로위를 달리고 있는) 이미지 데이터 간의 데이터 혼합 결과일 수 있다. 다만 본 발명의 실시예가 이에 제한되는 것은 아니다. 몇몇 예로, 데이터 혼합 모듈은 인풋(input) 단계가 아닌, 히든 단계(hidden representation)에서 데이터 혼합을 수행할 수 있다. 즉, 본 발명의 인공지능 모델 학습 장치는 인풋 단계가 아닌 히든 단계에서 데이 터 혼합을 수행함으로써 보다 안정적인 멀티 모달 러닝이 가능하다.몇몇 예로, 데이터 혼합 모듈은 이기종 학습 데이터(HLD)와, 이기종 학습 데이터의 혼합 결과인 혼합 데이 터(BD)가 동일한 임베딩 공간(embedding space)을 갖도록 데이터 혼합을 수행할 수 있다. 다시 말하면, 데이터 혼합 모듈은 이기종 학습 데이터(HLD)의 각 학습 데이터들과, 혼합 데이터(BD)가 동일한 임베딩 공간에 존 재하도록 데이터 혼합을 수행할 수 있다. 예컨대, 데이터 혼합 모듈은 이기종 학습 데이터(HLD)의 소정 차원(예: 512 차원)을 갖는 임베딩 공간에서 의 측지 곡선을 고려한 보간법(interpolation)을 이용하여 데이터 혼합을 수행할 수 있다. 예를 들어, 데이터 혼합 모듈은 생성된 혼합 데이터가 이기종 학습 데이터의 측지 곡선에 기반한 초구(hypersphere)상에 존재 하도록 데이터 혼합을 수행하고, 생성된 혼합 데이터를 피팅(fitting)할 수 있다. 이렇듯, 본 발명의 인공지능 모델 학습 장치는, 이미지, 텍스트 등 상이한 종류의 데이터에 대한 데이터 혼합을 수행한 후, 생성된 혼합 데이터에 기초하여 학습을 수행할 수 있어, 이기종 데이터간의 혼합 데이터에 기초한 고도화된 학습을 수행할 수 있는 새로운 효과를 갖는다. 또한, 본 발명의 인공지능 모델 학습 장치는, 측도를 기반으로 데이터 혼합을 수행함으로써 혼합 전과 혼 합 후에 각 데이터들이 균일한 임베딩 공간(embedding space)을 가짐으로써 더욱 안정적인 데이터 혼합이 가능 하다. 이어서, 학습 수행 모듈은 생성된 혼합 데이터(BD)를 기초로 학습을 수행하여 학습 모델(LM)을 생성할 수 있다(S300). 이때, 학습 모델(LM)은 이기종 학습 데이터에 포함된 각 학습 데이터 간의 연관성을 파악하는 딥러닝 모델일 수 있다. 다시 말하면, 학습 모델(LM)은 \"수행 단계\"(Interference Phase)에서, 전술한 학습 데이터 중 어느 하나 의 종류의 데이터(예: 텍스트 데이터(TD))가 입력되면, 해당 텍스트 데이터(TD)에 알맞은 이미지 데이터(ID)를 출력하는 방식의 머신 러닝 모델일 수 있으나, 본 발명의 실시예가 이에 제한되는 것은 아니다. 몇몇 예로, 학습 수행 모듈은 생성된 혼합 데이터(BD)를 기초로, 대조 학습법(contrastive learning)을 통 해 학습 모델(LM)을 생성할 수 있다. 대조 학습법이란, 비지도 표현 학습(unsupervied representation learning) 또는 다양한 도메인에 대한 프리- 트레이닝에서 활용되는 학습법이다. 대조 학습법은 데이터를 임베딩 공간에 매핑(mapping)하는 임베딩 기능을 학습하여, 의미적으로 유사한 데이터가 거리 메트릭(distance matric)에서 가까운 임베딩을 갖도록 하는 학습법 이다. 이때 거리 메트릭에는 일반적으로 연산의 편리함을 위해 코사인 유사도, 유클리디안 거리 등이 이용될 수 있다. 따라서, 본 발명의 학습 수행 모듈은 이기종 학습 데이터(HLD)와 혼합 데이터(BD)에서, 파지티브 페어 (positive pair)간의 거리는 최소화하고, 네거티브 페어(negative pair)간의 거리는 최대화 하는 방식의 대조 학습법을 통해 학습 모델(LM)을 생성할 수 있다. 이때, 학습 수행 모듈은 생성된 혼합 데이터(BD)를 기초로 하드 네거티브 페어(hard negative pair)를 결 정하고, 결정된 하드 네거티브 페어를 네거티브 페어로서 이용하여 대조 학습을 수행할 수 있다. 예를 들어 설명하면, 학습 수행 모듈은 이기종 학습 데이터(HLD) 중 제1 텍스트 데이터와, 이에 상응하는 제1 이미지 데이터를 파지티브 페어로 하여 그들간의 거리를 최소화 하고, 제1 텍스트 데이터와, 제1 텍스트 데 이터에 기초하지 않은 혼합 데이터(BD)를 하드 네거티브 페어로 하여 그들간의 거리를 최대화하는 방식으로 학 습을 수행할 수 있다. 이때, 하드 네거티브 페어에 포함된 제1 텍스트 데이터(예: A Car is driving on the road)와, 제1 텍스트 데 이터에 기초하지 않은 혼합 데이터(BD, 예: 강아지가 잔디에 앉아있음에 관한 텍스트 데이터와 이미지 데이터의 혼합 데이터)는 서로 다른 사실을 나타낼 수 있다. 데이터 혼합 모듈 및 학습 수행 모듈의 구체적인 동작 방식에 대하여 도 5 내지 도 8을 참조하여 자 세히 설명한다. 도 5 내지 도 8은 본 발명의 몇몇 실시예에 따른 혼합 데이터 생성 과정 및 생성된 혼합 데이터를 이용한 학습 과정을 설명하기 위한 개념도이다. 구체적으로, 도 5는 본 발명의 데이터 혼합 과정이 수행되기 전을 도시한 것 이고, 도 6은 측지 곡선(geodesic, 이하 \"gd\"라 한다)에 기초한 데이터 혼합 과정을 도시한 것이고, 도 7은 생 성된 혼합 데이터(BD)에 기초한 대조 학습법을 설명하기 위한 도면이고, 도 8은 혼합 데이터를 이용한 학습 과 정이 완료된 후를 도시한 것이다. 우선, 도 2 및 도 5를 참조하면, 도 5에는 데이터 혼합을 수행하기 전에 초구(hypersphere)상에 존재하는 텍스 트 데이터(TD)와 이미지 데이터(ID)가 도시되어 있다. 이때, 텍스트 데이터(TD)와 이미지 데이터(ID)는 미리 정의된 임베딩 공간(Embedding Space, 이하 \"ES\"라 한 다)을 가질 수 있다. 이때, 임베딩 공간은 예컨대 512차원을 가질 수 있으나, 본 발명의 실시예가 이에 제한되 는 것은 아니다. 이어서, 도 2 및 도 6을 참조하면, 데이터 혼합 모듈은 동일한 사실을 나타내는 학습 데이터 셋에 포함된 각 학습 데이터를 혼합하여 혼합 데이터(BD)를 생성할 수 있다. 이때, 데이터 혼합 모듈은 도 6에 도시된 바와 같이 인풋(input) 단계가 아닌, 임베딩 공간(ES)으로 표현 되는 히든 단계(hidden representation)에서 데이터 혼합을 수행할 수 있다. 즉, 본 발명의 인공지능 모델 학습 장치는 인풋 단계가 아닌 히든 단계에서 데이터 혼합을 수행함으로써 보다 안정적인 멀티 모달 러닝이 가 능하다. 몇몇 예로, 데이터 혼합 모듈은 이기종 학습 데이터(TD1과 ID1)와, 이기종 학습 데이터의 혼합 결과인 혼 합 데이터(D_H)가 동일한 임베딩 공간(ES)을 갖도록 데이터 혼합을 수행할 수 있다. 예컨대, 데이터 혼합 모듈은 이기종 학습 데이터(HLD)의 소정 차원(예: 512 차원)을 갖는 임베딩 공간(E S)에서의 측지 곡선(gd)을 고려한 보간법(interpolation)을 이용하여 데이터 혼합을 수행할 수 있다. 예를 들어, 데이터 혼합 모듈은 생성된 혼합 데이터(D_H)가 이기종 학습 데이터의 측지 곡선(gd)에 기반한 초구 (hypersphere)상에 존재하도록 데이터 혼합을 수행하고, 생성된 혼합 데이터를 피팅(fitting)할 수 있다. 도 6을 예를 들어 설명하면, 데이터 혼합 모듈은 제1 텍스트 데이터(TD1)와 제1 이미지 데이터(ID1)의 임 베딩 공간(ES)에서의 측지 곡선(gd) 상에 혼합 데이터(D_H)가 존재하도록 데이터 혼합을 수행할 수 있다. 이때, 데이터 혼합 모듈은 임베딩 공간(ES)상에서 혼합 데이터(D_H)와 데이터 혼합의 기초가 되는 각 학습 데이터(TD1, ID1)간의 각도(λθ와 (1- λ)θ)를 결정하고, 결정된 각도(λθ와 (1- λ)θ)에 기초하여 임베딩 공간(ES)상에서 혼합 데이터(D_H)의 최종 위치를 결정할 수 있다. 이때, λ값은 예컨대 0.5일 수 있으나, 본 발 명의 실시예가 이에 제한되는 것은 아니다. 만약, 데이터 혼합 모듈이 제1 텍스트 데이터(TD1)와 제1 이미지 데이터(ID1)의 임베딩 공간(ES)을 무시하 고 데이터 혼합을 수행하는 경우, 도 6에 도시된 바와 같이 초구와 측지 곡선(gd) 상이 아닌, 별개의 임베딩 공 간에 존재하는 혼합 데이터(D_I)가 생성된다. 이 경우, 혼합 전의 이기종 학습 데이터(HLD)의 임베딩 공간(ES) 과 균일하지 않고 얼라인(align)되지 않은 임베딩 공간에 혼합 데이터(D_I)가 생성됨으로써 학습 효과가 열등할 수 있다. 따라서, 본 발명의 데이터 혼합 모듈은 이기종 학습 데이터(TD1과 ID1)와, 이기종 학습 데이터의 혼합 결 과인 혼합 데이터(D_H)가 동일한 임베딩 공간(ES)을 갖도록 데이터 혼합을 수행함으로써 안정적인 인공지능 모 델 학습이 가능한 새로운 효과를 갖는다. 이어서, 도 2 및 도 7을 참조하면, 학습 수행 모듈은 혼합 데이터(BD)를 기초로 학습을 수행하여 학습 모 델(LM)을 생성할 수 있다. 몇몇 예로, 학습 수행 모듈은 생성된 혼합 데이터(BD)를 기초로 전술한 대조 학습법을 통해 학습 모델(L M)을 생성할 수 있다. 예를 들어, 학습 수행 모듈은 이기종 학습 데이터(HLD)와 혼합 데이터(BD)에서, 파지티브 페어 간의 거리 는 최소화하고, 네거티브 페어 간의 거리는 최대화 하는 방식의 대조 학습법을 통해 학습 모델(LM)을 생성할 수 있다. 이때, 학습 수행 모듈은 생성된 혼합 데이터(BD)를 기초로 하드 네거티브 페어(hard negative pair)를 결 정하고, 결정된 하드 네거티브 페어를 네거티브 페어로서 이용하여 대조 학습을 수행할 수 있다.도 7을 예를 들어 설명하면, 학습 수행 모듈은 이기종 학습 데이터(HLD) 중 n번째 텍스트 데이터인 제n 텍 스트 데이터(TDn)와, 이에 상응하는 제n 이미지 데이터(IDn)를 파지티브 페어로 결정할 수 있다. 또한, 학습 수행 모듈은 제n 텍스트 데이터(TDn)와, 각 혼합 데이터(BD1 내지 BD5) 중 적어도 하나를 하드 네거티브 페어로 결정할 수 있다. 예를 들어, 학습 수행 모듈은 제n 텍스트 데이터(TDn)와, 제1 혼합 데이터(BD1)를 하드 네거티브 페어로 결정하고, 제n 텍스트 데이터(TDn)와, 제2 혼합 데이터(BD2)를 하드 네거티브 페어로 결정하고, 제n 텍스트 데 이터(TDn)와, 제3 혼합 데이터(BD3)를 하드 네거티브 페어로 결정하고, 제n 텍스트 데이터(TDn)와, 제4 혼합 데 이터(BD4)를 하드 네거티브 페어로 결정하고, 제n 텍스트 데이터(TDn)와, 제5 혼합 데이터(BD5)를 하드 네거티 브 페어로 결정할 수 있다. 즉, 하드 네거티브 페어(예: TDn과 BD1)란, 서로 다른 사실을 나타내며, 데이터 혼합 유무가 서로 다른 데이터 들 간의 페어를 의미할 수 있다. 다시 말하면, 하드 네거티브 페어(예: TDn과 BD1)란, 서로 다른 사실을 나타내 는 단일 데이터(예: TDn)와 혼합 데이터(예: BD1)간의 쌍을 의미할 수 있다. 일반적으로, 하드 네거티브 페어가 아닌 네거티브 페어(예: TDn과 ID1)를 이용하여 학습을 수행하는 경우, 네거 티브 페어의 각 학습 데이터(예: TDn, ID1)간의 유사도가 낮은 바, 그에 따라 학습 난이도가 낮고 따라서 학습 결과의 성능이 다소 떨어질 수 있다. 따라서, 본 발명의 인공지능 모델 학습 장치는 일반적인 네거티브 페 어가 아닌, 혼합 데이터 형태의 하드 네거티브 페어를 이용함으로써 더 고도화된 학습이 가능한 것이다. 이어서, 학습 수행 모듈은 임베딩 공간(ES) 상에서 파지티브 페어(TDn과 IDn)간의 거리는 최소화하고, 하 드 네거티브 페어(TDn과 BD1, TDn과 BD2, TDn과 BD3, TDn과 BD4, TDn과 BD5)간의 거리는 최대화 하는 방식으로 학습을 수행할 수 있다. 전술한 학습 과정을 통해 생성된 학습 결과는 도 8에 도시되어 있다. 도 8을 참조하면, 전술한 학습 과정을 통 해, 각 학습 데이터는 균일한 임베딩 공간(ES)을 갖고, 얼라인(align) 상태가 우수하다. 도 9는 본 발명의 몇몇 실시예에 따른 인공지능 모델 학습 장치의 하드웨어 구현을 설명하기 위한 도면이다. 도 9을 참조하면, 본 발명의 몇몇 실시예들에 따른 인공지능 모델 학습 장치는 전자 장치로 구현될 수 있다. 전자 장치는 컨트롤러(1010, controller), 입출력 장치(1020, I/O), 메모리 장치(1030, memory device), 인터페이스(1040, interface) 및 버스(1050, bus)를 포함할 수 있다. 컨트롤러, 입출력 장치 , 메모리 장치 및/또는 인터페이스는 버스를 통하여 서로 결합될 수 있다. 이때, 버스 는 데이터들이 이동되는 통로(path)에 해당한다. 구체적으로, 컨트롤러는 CPU(Central Processing Unit), MPU(Micro Processor Unit), MCU(Micro Controller Unit), GPU(Graphic Processing Unit), NPU(Neural Processing Unit), 디지털 신호 프로세스, 마이 크로컨트롤러, 어플리케이션 프로세서(AP, application processor) 및 이들과 유사한 기능을 수행할 수 있는 논 리 소자들 중에서 적어도 하나를 포함할 수 있다. 입출력 장치는 키패드(keypad), 키보드, 터치스크린 및 디스플레이 장치 중 적어도 하나를 포함할 수 있 다. 메모리 장치는 데이터 및/또는 프로그램 등을 저장할 수 있다. 인터페이스는 통신 네트워크로 데이터를 전송하거나 통신 네트워크로부터 데이터를 수신하는 기능을 수행 할 수 있다. 인터페이스는 유선 또는 무선 형태일 수 있다. 예컨대, 인터페이스는 안테나 또는 유 무선 트랜시버 등을 포함할 수 있다. 도시하지 않았지만, 메모리 장치는 컨트롤러의 동작을 향상시 키기 위한 동작 메모리로서, 고속의 디램 및/또는 에스램 등을 더 포함할 수도 있다. 메모리 장치는 내부 에 프로그램 또는 어플리케이션을 저장할 수 있다. 본 발명의 실시예들에 따른 인공지능 모델 학습 장치는 각각 복수의 전자 장치가 네트워크를 통해서 서로 연결되어 형성된 시스템일 수 있다. 이러한 경우에는 각각의 모듈 또는 모듈의 조합들이 전자 장치 로 구현될 수 있다. 단, 본 실시예가 이에 제한되는 것은 아니다. 추가적으로, 인공지능 모델 학습 장치는 워크스테이션(workstation), 데이터 센터, 인터넷 데이터 센터 (internet data center(IDC)), DAS(direct attached storage) 시스템, SAN(storage area network) 시스템, NAS(network attached storage) 시스템, RAID(redundant array of inexpensive disks, or redundant array of independent disks) 시스템, 및 EDMS(Electronic Document Management) 시스템 중 적어도 하나로 구현될 수 있 으나, 본 실시예가 이에 제한되는 것은 아니다. 또한, 인공지능 모델 학습 장치에 포함된 적어도 일부 구성은 통신망(도 1의 300)을 통해서 데이터를 교환 할 수 있다. 통신망(도 1의 300)은 유선 인터넷 기술, 무선 인터넷 기술 및 근거리 통신 기술에 의한 네트워크 를 포함할 수 있다. 유선 인터넷 기술은 예를 들어, 근거리 통신망(LAN, Local area network) 및 광역 통신망 (WAN, wide area network) 중 적어도 하나를 포함할 수 있다. 무선 인터넷 기술은 예를 들어, 무선랜(Wireless LAN: WLAN), DMNA(Digital Living Network Alliance), 와이브 로(Wireless Broadband: Wibro), 와이맥스(World Interoperability for Microwave Access: Wimax), HSDPA(High Speed Downlink Packet Access), HSUPA(High Speed Uplink Packet Access), IEEE 802.16, 롱 텀 에볼루션(Long Term Evolution: LTE), LTE-A(Long Term Evolution-Advanced), 광대역 무선 이동 통신 서비스 (Wireless Mobile Broadband Service: WMBS) 및 5G NR(New Radio) 기술 중 적어도 하나를 포함할 수 있다. 단, 본 실시예가 이에 제한되는 것은 아니다. 근거리 통신 기술은 예를 들어, 블루투스(Bluetooth), RFID(Radio Frequency Identification), 적외선 통신 (Infrared Data Association: IrDA), UWB(Ultra-Wideband), 지그비(ZigBee), 인접 자장 통신(Near Field Communication: NFC), 초음파 통신(Ultra Sound Communication: USC), 가시광 통신(Visible Light Communication: VLC), 와이 파이(Wi-Fi), 와이 파이 다이렉트(Wi-Fi Direct), 5G NR (New Radio) 중 적어도 하 나를 포함할 수 있다. 단, 본 실시예가 이에 제한되는 것은 아니다. 통신망(도 1의 300)을 통해서 통신하는 인공지능 모델 학습 장치는 이동통신을 위한 기술표준 및 표준 통 신 방식을 준수할 수 있다. 예를 들어, 표준 통신 방식은 GSM(Global System for Mobile communication), CDMA(Code Division Multi Access), CDMA2000(Code Division Multi Access 2000), EV-DO(Enhanced Voice-Data Optimized or Enhanced Voice-Data Only), WCDMA(Wideband CDMA), HSDPA(High Speed Downlink Packet Access), HSUPA(High Speed Uplink Packet Access), LTE(Long Term Evolution), LTEA(Long Term Evolution- Advanced) 및 5G NR(New Radio) 중 적어도 하나를 포함할 수 있다. 단, 본 실시예가 이에 제한되는 것은 아니다. 이상의 설명은 본 실시예의 기술 사상을 예시적으로 설명한 것에 불과한 것으로서, 본 실시예가 속하는 기술 분 야에서 통상의 지식을 가진 자라면 본 실시예의 본질적인 특성에서 벗어나지 않는 범위에서 다양한 수정 및 변 형이 가능할 것이다. 따라서, 본 실시예들은 본 실시예의 기술 사상을 한정하기 위한 것이 아니라 설명하기 위 한 것이고, 이러한 실시예에 의하여 본 실시예의 기술 사상의 범위가 한정되는 것은 아니다. 본 실시예의 보호 범위는 아래의 청구범위에 의하여 해석되어야 하며, 그와 동등한 범위 내에 있는 모든 기술 사상은 본 실시예의 권리범위에 포함되는 것으로 해석되어야 할 것이다.도면 도면1 도면2 도면3 도면4 도면5 도면6 도면7 도면8 도면9"}
{"patent_id": "10-2023-0020187", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 몇몇 실시예에 따른 인공지능 모델 학습 시스템의 구성을 개략적으로 설명하기 위한 도면이다. 도 2는 본 발명의 몇몇 실시예에 따른 인공지능 모델 학습 장치의 블록도이다. 도 3은 인공지능 모델 학습 방법의 흐름도이다. 도 4는 본 발명의 몇몇 실시예에 따른 이기종 학습 데이터를 설명하기 위한 예시적인 도면이다. 도 5 내지 도 8은 본 발명의 몇몇 실시예에 따른 혼합 데이터 생성 과정 및 생성된 혼합 데이터를 이용한 학습 과정을 설명하기 위한 개념도이다. 도 9는 본 발명의 몇몇 실시예에 따른 인공지능 모델 학습 장치의 하드웨어 구현을 설명하기 위한 도면이다."}
