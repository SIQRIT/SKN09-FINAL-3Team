{"patent_id": "10-2022-0001723", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0106005", "출원번호": "10-2022-0001723", "발명의 명칭": "도메인특화 음성인식 모델 구성 방법 및 장치와 이를 이용한 종단형 음성인식기", "출원인": "한국전자통신연구원", "발명자": "윤승"}}
{"patent_id": "10-2022-0001723", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "기억장소 및 프로세서가 포함된 컴퓨터 시스템에서 실행되는 종단형 음성인식 모델 구성 방법에 있어서,상기 프로세서가, 특화를 원하는 도메인의 텍스트 데이터(이하, '도메인 텍스트 데이터')를 수집하고, 상기 수집된 도메인 텍스트 데이터를 상기 기억장소에 포함된 음성-전사문 텍스트 DB(이하, '기본 전사문 텍스트 DB')와 비교하여 이 기본 전사문 텍스트 DB에 포함되지 않아 추가 학습이 필요한 도메인 텍스트를 결정하여 상기 기억장소에 특화대상 도메인 텍스트 DB를 구축하고;상기 프로세서가, 상기 특화대상 도메인 텍스트 DB의 특화대상 도메인 텍스트로부터 특화대상 음성신호를 생성하고, 생성된 특화대상 음성신호로 음성인식 신경망을 학습시켜서 특화를 원하는 도메인에 특화된 종단형 음성인식 모델을 만드는 것을 포함하는 도메인특화 음성인식 모델 구성 방법."}
{"patent_id": "10-2022-0001723", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 추가 학습이 필요한 도메인 텍스트는 도메인 텍스트의 출현 빈도가 사전 설정된 임계값이하일 때 결정되는 것을 특징으로 하는 도메인특화 음성인식 모델 구성 방법."}
{"patent_id": "10-2022-0001723", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서, 상기 수집된 도메인 텍스트 데이터를 상기 기본 전사문 텍스트 DB와 비교하는 것은,상기 수집된 도메인 텍스트에서 비교 후보 텍스트를 추출하여, 이 추출된 비교 후보 텍스트를 상기 기본 전사문텍스트 DB와 비교하는 것을 포함하는 도메인특화 음성인식 모델 구성 방법."}
{"patent_id": "10-2022-0001723", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서, 상기 특화대상 음성신호의 생성은, 단일 화자 음성합성기 및 다화자 음성합성기 중 하나를 사용하여 이루어지는 것을 특징으로 하는 도메인특화 음성인식 모델 구성 방법."}
{"patent_id": "10-2022-0001723", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서, 상기 특화대상 음성신호로 음성인식 신경망을 학습시키는 것은 상기 생성된 특화 음성으로 처음부터 음성인식 신경망을 학습시키는 것을 특징으로 하는 도메인특화 음성인식모델 구성 방법."}
{"patent_id": "10-2022-0001723", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서, 상기 특화대상 음성신호로 음성인식 신경망을 학습시키는 것은 기존에 만들어져 있는 일반 음성인식 신경망을 연결학습 및 전이학습 중 하나를 이용하여 추가로 학습시키는 것을 특징으로 하는 도메인특화 음성인식 모델 구성 방법."}
{"patent_id": "10-2022-0001723", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에 있어서, 상기 특화대상 도메인 텍스트 DB의 특화대상 도메인 텍스트의 양을 변화시켜 특화대상 도메인텍스트의 가중치를 조절하는 특화 언어모델을 생성하는 것을 추가로 포함하는 도메인특화 음성인식 모델 구성방법."}
{"patent_id": "10-2022-0001723", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1항에 있어서, 상기 특화대상 도메인 텍스트 DB의 특화대상 도메인 텍스트의 양을 변화시켜 특화대상 도메인텍스트의 가중치를 조절하기 위하여 상기 특화대상 도메인 텍스트 DB로부터 특화 사용자 어휘를 추출하여 특화사용자어휘 DB를 구축하는 것을 추가로 포함하는 도메인특화 음성인식 모델 구성 방법.공개특허 10-2023-0106005-3-청구항 9 종단형 음성인식 모델 구성 장치에 있어서,특화를 원하는 도메인의 텍스트 데이터(이하, '도메인 텍스트 데이터')를 수집하고; 상기 수집된 도메인 텍스트 데이터를 음성-전사문 텍스트 DB(이하, '기본 전사문 텍스트 DB')와 비교하여 이 기본 전사문 텍스트 DB에 포함되지 않아 추가 학습이 필요한 도메인 텍스트를 결정하여 특화대상 도메인 텍스트DB를 생성하고;상기 특화대상 도메인 텍스트 DB의 특화대상 도메인 텍스트로부터 특화대상 음성신호를 생성하고;생성된 특화대상 음성신호로 음성인식 신경망을 학습시키는 프로세서를 포함하는 도메인특화 음성인식 모델 구성 장치."}
{"patent_id": "10-2022-0001723", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9항에 있어서, 상기 추가 학습이 필요한 도메인 텍스트는 도메인 텍스트의 출현 빈도가 사전 설정된 임계값이하일 때 결정되는 것을 특징으로 하는 도메인특화 음성인식 모델 구성 장치."}
{"patent_id": "10-2022-0001723", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제9항에 있어서, 상기 수집된 도메인 텍스트 데이터를 상기 기본 전사문 텍스트 DB와 비교하는 것은,상기 수집된 도메인 텍스트에서 비교 후보 텍스트를 추출하여, 이 추출된 비교 후보 텍스트를 상기 기본 전사문텍스트 DB와 비교하는 것을 포함하는 도메인특화 음성인식 모델 구성 장치."}
{"patent_id": "10-2022-0001723", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제9항에 있어서, 상기 특화대상 음성신호의 생성은, 단일 화자 음성합성기 및 다화자 음성합성기 중 하나를 사용하여 이루어지는 것을 특징으로 하는 도메인특화 음성인식 모델 구성 장치."}
{"patent_id": "10-2022-0001723", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제9항에 있어서, 상기 특화대상 음성신호로 음성인식 신경망을 학습시키는 것은 상기 생성된 특화 음성으로 처음부터 음성인식 신경망을 학습시키는 것을 특징으로 하는 도메인특화 음성인식모델 구성 장치."}
{"patent_id": "10-2022-0001723", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제9항에 있어서, 상기 특화대상 음성신호로 음성인식 신경망을 학습시키는 것은 기존에 만들어져 있는 일반 음성인식 신경망을 연결학습 및 전이학습 중 하나를 이용하여 추가로 학습시키는 것을 특징으로 하는 도메인특화 음성인식 모델 구성 장치."}
{"patent_id": "10-2022-0001723", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제9항에 있어서, 상기 특화대상 도메인 텍스트 DB의 특화대상 도메인 텍스트의 양을 변화시켜 특화대상 도메인텍스트의 가중치를 조절하는 특화 언어모델을 추가로 포함하는 도메인특화 음성인식 모델 구성 장치."}
{"patent_id": "10-2022-0001723", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제9항에 있어서, 상기 특화대상 도메인 텍스트 DB의 특화대상 도메인 텍스트의 양을 변화시켜 특화대상 도메인텍스트의 가중치를 조절하기 위하여 상기 특화대상 도메인 텍스트 DB로부터 특화 사용자 어휘를 추출하여 생성되는 특화 사용자어휘 DB를 추가로 포함하는 도메인특화 음성인식 모델 구성 장치."}
{"patent_id": "10-2022-0001723", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "청구항 9 내지 청구항 14 중 한 항에 기재된 도메인특화 음성인식 모델 구성 장치에 의해 구성된 도메인특화 음성인식 모델을 포함하는 도메인특화 종단형 음성인식기.공개특허 10-2023-0106005-4-청구항 18 제17항에 있어서, 상기 도메인특화 음성인식 모델은상기 학습된 음성인식 신경망을 이용하여, 입력된 음성신호의 프레임별 인코드 값을 출력하는 음성 입력인코더; 및 상기 음성인식 신경망을 이용하여, 상기 인코드 값에 대한 어텐션(attention)을 계산하여 최종 문자열을 출력하는 문자열 출력 디코더를 포함하는 도메인특화 종단형 음성인식기."}
{"patent_id": "10-2022-0001723", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제17항에 있어서, 상기 특화대상 도메인 텍스트 DB의 특화대상 도메인 텍스트의 양을 변화시켜 특화대상 도메인텍스트의 가중치를 조절하는 특화 언어모델을 추가로 포함하는 도메인특화 종단형 음성인식기."}
{"patent_id": "10-2022-0001723", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제17항에 있어서, 상기 특화대상 도메인 텍스트 DB의 특화대상 도메인 텍스트의 양을 변화시켜 특화대상 도메인텍스트의 가중치를 조절하기 위하여 상기 특화대상 도메인 텍스트 DB로부터 특화 사용자 어휘를 추출하여 생성되는 특화 사용자어휘 DB를 추가로 포함하는 도메인특화 종단형 음성인식기."}
{"patent_id": "10-2022-0001723", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "원하는 특정 도메인에서의 음성인식 성능을 높일 수 있는 종단형 음성인식 기술에 관한 것으로, 특화를 원하는 도메인의 텍스트 데이터(이하, '도메인 텍스트 데이터')를 수집하고, 상기 수집된 도메인 텍스트 데이터를 상기 기억장소에 포함된 음성-전사문 텍스트 DB(이하, '기본 전사문 텍스트 DB')와 비교하여 이 기본 전사문 텍스트 DB에 포함되지 않아 추가 학습이 필요한 도메인 텍스트를 결정하여 상기 기억장소에 특화 대상 도메인 텍스트 DB 를 구축한다. 또한, 상기 특화 대상 도메인 텍스트 DB의 도메인 텍스트로부터 음성신호를 생성하고, 생성된 음성 신호로 음성인식 신경망을 학습시켜서 특화를 원하는 도메인에 특화된 종단형 음성인식 모델을 만든다. 이 특화 된 음성인식 모델을 종단형 음성인식기에 적용하여 도메인 특화 종단형 음성인식을 수행할 수 있다."}
{"patent_id": "10-2022-0001723", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 음성인식(Speech Recognition), 특히, 종단형 음성인식(End-to-End Speech Recognition)과 음성인식 을 위한 신경망 기술에 관련된 것이다."}
{"patent_id": "10-2022-0001723", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "인공지능 기술의 발달에 따라 음성인식 기술이 널리 확산되고 있다. 특히 최근에는 음성신호를 입력으로 하고 텍스트 문자열을 출력으로 하여 신경망을 이용해 학습한 종단형 음성인식 기술이 개발됨에 따라 과거에 비해 음 성인식 성능이 대폭 향상되었다. 그러나 종단형 음성인식 기술은 학습을 위해, 음성신호를 녹음한 파일과 이를 기록한 전사문이 반드시 한 쌍(음 성-전사문 쌍)을 필요로 한다. 이 때문에 음향모델, 언어모델, 및 발음사전이 분리되어 있는 종래의 음성인식 기술에 비해 종단형 음성인식 기술은 사용된 텍스트의 양이 절대적으로 부족하여, 학습에 포함되지 않은 특정 도메인에서의 성능은 상대적으로 떨어지는 단점이 있다. 또한 원하는 도메인의 성능을 높이기 위해 도메인 특화를 하려고 할 때도 음성신호를 녹음한 파일과 이를 기록 한 전사문이 함께 필요함에 따라 특화용 데이터 수집이 어려워 특화가 용이치 않은 문제가 존재한다."}
{"patent_id": "10-2022-0001723", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "이에, 본 발명의 목적은 상술한 문제점을 해결하기 위하여 특정 도메인에서의 음성인식 성능을 높일 수 있는 종 단형 음성인식 기술을 제안하는 것이다."}
{"patent_id": "10-2022-0001723", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기 목적을 달성하기 위하여, 본 발명은 음성 신호를 녹음한 파일과 이를 기록한 전사문을 이용하지 않고, 수 집이 용이한 텍스트 데이터를 이용해 도메인을 특화하여 이 특화된 도메인에서의 음성인식 성능을 높인 음성인 식 모델 생성방법 및 장치와 이를 이용한 종단형 음성인식기를 제공한다. 본 발명의 일 측면에 따른 도메인 특화 종단형 음성인식 모델 생성방법 및 장치는, 기억장소 및 프로세서가 포 함된 컴퓨터 시스템으로 구현될 수 있다. 상기 프로세서는, 특화를 원하는 도메인의 텍스트 데이터(이하, '도메인 텍스트 데이터')를 수집하고, 상기 수 집된 도메인 텍스트 데이터를 상기 기억장소에 포함된 음성-전사문 텍스트 DB(이하, '기본 전사문 텍스트 DB')와 비교하여 이 기본 전사문 텍스트 DB에 포함되지 않아 추가 학습이 필요한 도메인 텍스트를 결정하여 상기 기 억장소에 특화 대상 도메인 텍스트 DB를 구축한다. 또한 상기 프로세서는, 음성합성기를 이용해 (또는 음성합성 프로그램을 실행하여) 상기 특화 대상 도메인 텍스트 DB의 도메인 텍스트로부터 음성신호를 생성하고, 생성된 음성신호로 음성인식 신경망을 학습시켜서 특화를 원하는 도메인에 특화된 종단형 음성인식 모델을 만든다. 이 특화된 음성인식 모델을 종단형 음성인식기에 적용하여 도메인 특화 종단형 음성인식을 수행할 수 있다. 추가로, 상기 프로세서는, 상기 특화 대상 도메인 텍스트 DB를 이용하여 도메인 특화 언어 모델 및/또는 도메인 특화 사용자 어휘를 만들 수 있고, 이들을 음성인식 과정에 반영하여 특화 가중치를 조절할 수 있다. 본 발명의 다른 측면에 따르면, 상기 도메인특화 음성인식 모델을 이용한 도메인특화 종단형 음성인식기가 제공 된다. 본 발명의 더 상세한 구성 및 작용은 이후에 도면과 함께 설명하는 구체적인 실시예를 통하여 더욱 명확해질 것 이다."}
{"patent_id": "10-2022-0001723", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명에 의하면, 음성이 녹음된 음성신호 파일 없이도 텍스트 DB만을 이용해 종단형 음성인식기의 도메인 특 화가 가능하다. 이때 음성 합성기를 이용해 생성된 음성은 실제 사람이 발성한 음성과는 차이가 있지만, 종단형 음성인식에서는 다른 그 무엇보다 학습시에 해당 텍스트와 음성이 포함되었는지(관측이 되었는지) 아닌지가 매 우 중요하기 때문에 음성 합성기로 생성된 음성 및 텍스트를 학습에 반영하는 것은 매우 중요하다. 학습에 반영 하지 않았을 경우 해당 텍스트의 확률값이 매우 낮게 학습됨에 따라 음성인식 과정에서 음성인식 대상 후보에 포함되는 것 자체가 거의 불가능하나, 음성 및 텍스트를 통해 학습을 하게 되면 해당 텍스트가 음성인식 대상 후보가 될 수 있는 수준의 확률값을 갖게 되어 음성인식이 가능한 길을 열어 주게 되는 것이다. 이러한 효과는 학습 과정에서 단순히 음성신호적인 정보 외에 언어적인 정보도 함께 학습되기 때문에 가능하다. 추가적으로, 학습시에 관측되지 않은 텍스트에 대해서는 음성인식 대상 후보가 될 확률이 매우 떨어지기 때문에 음성인식 성능이 저하될 뿐만 아니라 나중에 언어모델을 통해 또는 사용자 어휘 등록을 통해 특화를 하려고 해 도 텍스트만으로 특화하는 것은 거의 불가능하다. 이 언어모델을 통한 또는 사용자 어휘 등록을 통한 특화는 대 상 텍스트가 경쟁 후보들 중에 존재할 때에는 이에 대한 가중치를 높여 음성인식이 잘 되도록 하는 효과가 나타 날 수 있지만, 후보로서의 경쟁력이 매우 낮은 경우에는 가중치를 높여도 그 효과가 잘 나타나지 않는다. 이 때문에 음성 합성기를 써서 음성신호를 생성해 학습에 반영하는 것은 그 자체로도 음성인식 성능을 매우 향 상시킬 수 있을 뿐만 아니라, 학습에 반영된 텍스트에 대해서는 추후 언어모델을 활용해 또는 사용자 어휘 등록 을 활용해 해당 단어 또는 문장의 가중치를 높임으로써 경쟁 후보들보다 우위에 있도록 하여 더욱 용이하게 음 성인식 성능을 높일 수 있게 한다. 결론적으로, 본 발명에 따르면, 특화대상 도메인 데이터를 대규모로 수집하여 이를 대상으로 음성을 생성한 후 학습해 음성인식 성능 개선 효과 확보와 다화자 음성 합성을 통한 강건성 확보가 가능하고, 특히, 언어모델 및/ 또는 사용자 어휘의 결합을 통한 가중치 조절로 특정 도메인 전반에 대해 음성인식 성능을 더욱 향상시킬 수 있 다."}
{"patent_id": "10-2022-0001723", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명의 이점 및 특징, 그리고 이들을 달성하는 방법은 이하 첨부된 도면과 함께 상세하게 기술된 바람직한 실시예를 참조하면 명확해질 것이다. 그러나 본 발명은 이하에 기술된 실시예에 한정되는 것이 아니라 다양한"}
{"patent_id": "10-2022-0001723", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "다른 형태로 구현될 수 있다. 실시예는 단지 본 발명을 완전하게 개시하며 본 발명이 속하는 기술분야에서 통상 의 지식을 가진 자에게 발명의 범주를 완전하게 알려주기 위해 제공되는 것일 뿐, 본 발명은 청구항의 기재 내 용에 의해 정의되는 것이다. 또한, 본 명세서에서 사용된 용어는 실시예를 설명하기 위한 것이며 본 발명을 제 한하고자 하는 것이 아니다. 본 명세서에서, 단수형은 특별히 언급하지 않는 한 복수형도 포함한다. 또한 명세 서에 사용된 '포함한다(comprise, comprising 등)'라는 용어는 언급된 구성요소, 단계, 동작, 및/또는 소자 이 외의 하나 이상의 다른 구성요소, 단계, 동작, 및/또는 소자의 존재 또는 추가를 배제하지 않는 의미로 사용된 것이다. 이하, 본 발명의 바람직한 실시예를 첨부 도면을 참조하여 상세히 설명한다. 실시예의 설명에 있어, 관련된 공 지 구성 또는 기능에 대한 구체적인 설명이 본 발명의 요지를 흐릴 수 있는 경우에는 그 상세한 설명을 생략한 다. 도 1은 일반적인 종단형 음성인식기의 구성도이다. 음성신호가 종단형 음성인식기에 입력되면, 특징 추출부는 음성인식기가 처리하기에 적합한 구조로 예를 들 면 멜필터뱅크(Mel Filter Bank)와 같은 형태로 특징을 추출한다. 추출된 특징은 음성인식 모델의 음성 입 력 인코더가 수신한다. 음성 입력 인코더는 신경망으로 학습되어 있어서 음성신호의 매 프레임별 인코드 값을 출력한다. 문자열 출력 디코더는 인코드 값을 수신하여 상기 신경망을 이용해서 어떤 인코 드 출력에 어텐션(attention)을 할지 계산하여 최종 문자열을 출력한다. 여기에서는 어텐션 기반의 인코더-디코 더 구조의 음성인식 모델을 예로 들었지만 종단형 음성인식기가 이러한 구조에 국한되는 것은 아니다. 마지 막으로, 음성인식 결과 출력부는 상기 디코더에서 출력된 최종 문자열에 대해 텍스트 심볼 후처리 등의 과정을 수행하여 음성인식 결과 텍스트를 출력한다. 도 1에 나타낸 '일반형 또는 기본' 종단형 음성인식기는, 이후 설명할, 본 발명의 실시예에 따른 '도메인 특화 형' 종단형 음성인식기와 달리 도메인 특화가 이루어지지 않은 상태의 음성인식기이다. 이 기본 종단형 음성인 식기에서는 충분한 양의 음성-전사문 쌍으로 음성-전사문 텍스트 DB를 만들어야 하는데, 이 과정에서 중요한 것 은 기본 음성인식 유닛들의 설정이다. 비교적 고른 통계로 음성인식 유닛들이 분포되도록 이들을 설정하는 것이 도메인 특화에 유리하다. 음성인식 유닛은 인식시에 단어를 단위로 사용하게 되면 개수가 너무 많아지므로 통상 서브워드 단위로 분절하여 사용하는데, 최근에는 Byte Pair Encoding을 많이 사용한다. 이 때 Byte Pair Encoding의 결과물인 서브워드 음성인식 유닛들 간에 통계 분포 격차가 너무 크게 나타나지 않 도록 최종 음성인식 유닛들의 개수를 많이 늘리지 않는 것이 좋다. 왜냐하면 분포 격차가 너무 크게 나타날 경 우 데이터베이스에서 적게 출현한 유닛은, 이후 설명할 본 발명에 따른 도메인 특화시에 상대적으로 많은 양의 데이터를 포함해야 특화가 가능해지기 때문이다. 비교적 고른 분포로 음성인식 유닛들이 구성되면 상대적으로 적은 양의 데이터로도 도메인 특화가 가능해진다. 한국어의 경우에, Byte Pair Encoding을 통해 서브워드 음성 인식 유닛을 10,000개 정도 설정하는 것보다는 실제 사용되는 음절 수인 2300~2400여 음절로 서브워드 음성인식 유닛을 설정하는 것이 통계 분포상 비교적 고른 분포를 가지게 되어 유리하다. 도 2는 본 발명의 실시예에 따른 도메인특화 음성인식 모델을 생성하는 방법의 오퍼레이션 순서도이다. 비록 도 2가 방법적 측면에서의 단계별 태스크 처리 흐름을 나타내고 있지만, 이로부터 본 발명의 다른 측면에 따른 도 메인특화 음성인식 모델 생성 장치의 처리유닛을 도출하는 것은 당업자에게 용이하다. 본 발명의 실시예에 따른 도메인 특화 종단형 음성인식 모델 생성방법은, 기억장소 및 프로세서가 포함된 컴퓨 터 시스템에서 실행될 수 있다. 또한 본 발명의 다른 실시예에 따른 도메인 특화 종단형 음성인식 모델 생성장 치는, 기억장소 및 프로세서가 포함된 범용 컴퓨터 하드웨어 및 이와 결합되어 또는 독립적으로 사용되는 소프 트웨어로 구현될 수 있거나 상기 종단형 음성인식 모델 생성방법을 실행하는 소프트웨어가 임베드된 전용의 하 드웨어 및 소프트웨어의 조합(예를 들어, DSP(digital signal processor), 프로세서, 컨트롤러, ASIC(application-specific IC), 프로그래머블 로직소자(FPGA) 등)로 구현될 수 있다. 도 2를 참조하면 본 발명의 실시예에 따른 도메인 특화 종단형 음성인식 모델 생성 방법 및 장치는 먼저, 원시 도메인 데이터(구체적으로, 도메인 텍스트)를 수집하는 단계부터 시작한다. 특정 도메인에 음성인식기를 특화시키기로 결정되면, 먼저 특화를 원하는 응용 도메인에서 출현 가능한 텍스트가 충분히 포함된 원시 도메인 데이터를 수집한다. 대개 음성인식이 어려운 단어들은 기본 종단형 음성인식기(도 1 참조)의 학습시에 포함되지않은 전문용어, 고유명사, 외래어 등이므로 이들이 충분히 포함되도록 수집하며, 단어뿐만 아니라 해당 단어들 을 포함한 실제 발화되는 문장들도 함께 수집하도록 한다. 정교한 수집을 위해 사람이 직접 후보 문장을 작성할 수도 있고 기존에 구축되어 있는 사전, 예문 등을 도메인 텍스트로 활용할 수도 있다. 만일 사람의 개입을 최소 화하고 도메인 텍스트 수집부터 이후의 전 과정을 자동화하고 싶으면 수집 대상 키워드만 결정한 후 웹 크롤러 를 이용해 자동으로 홈페이지, SNS, 블로그 등의 데이터를 수집할 수도 있다. 물론 이 때 기존에 운영하는 서비 스가 있어 텍스트 로그 데이터의 활용이 가능하다면 로그 데이터를 이용하는 것도 가능하다. 원시 도메인 데이터가 수집되면, 해당 데이터에서 텍스트를 추출하고 추출된 텍스트에 포함된 심볼, 숫자, 외국 어 표기 등에 대한 정규화 과정을 거쳐 도메인 텍스트 데이터베이스를 구축(DB화)한다. 다음은, 구축된 도메인 텍스트 DB에서 비교 후보 텍스트(즉, 비교 대상)를 추출하는 단계이다. 이를 위해, 도메인 텍스트 DB에서 단어, 단어 연쇄(N-Gram), 또는 문장 단위의 비교 후보 텍스트를 비교 대상으 로서 추출한다. 다음 단계에서는 도 1의 기본 종단형 음성인식기를 만들 때 사용되었던 음성-전사문 텍스트 DB와 상기 도메인 텍스트 DB의 비교 후보 텍스트들을 비교하여, 사전에 정해진 임계값 이하의 후보들을 찾아낸다. 임계 값은 단순히 출현 빈도를 이용해 결정할 수도 있고 전체 텍스트의 규모 등을 고려해 상대적으로 결정할 수도 있 다. 상기 비교 과정에서 특화할 도메인 데이터로 결정된 특화 대상 비교 후보 텍스트를 특화대상 도메인 텍스 트 DB로 DB화한다. 이 과정은 상기 도메인 텍스트 DB에 비교 후보 텍스트가 남아있는지 판단하여 남아있지 않을 때까지 반복 수행된다. 도메인 텍스트 DB 전체에 대해 상기 비교 과정이 수행되어 비교가 완료되어 특화대상 도메인 텍스트 DB가 구축되면, 이 특화대상 도메인 텍스트 DB를 이용해 실제 음성, 즉, 특화대상 음성을 생성하여 특 화대상 음성 DB를 구축한다. 여기서 음성의 생성은, 기본 종단형 음성인식기(도 1 참조)의 음성인식 모델을 만들 때 사용한 음성과 같은 규격으로 생성한다. 또한 가능하면 음성인식 성능을 높이기 위해서 여 러 명의 목소리로 음성을 생성할 수 있다. 단일 화자 합성기를 여러 가지로 다양하게 사용할 수도 있고, 다양한 화자 임베딩을 입력받아 해당 화자의 음색으로 합성음을 생성해 낼 수 있는 다화자 음성합성기를 사용할 수도 있다(그럼에도 불구하고, 단일 화자 합성기만 존재한다면 단일 화자 합성기로 음성을 생성하는 것도 일부 성능 저하가 존재하지만, 도메인특화 관점에서는 도움이 된다). 특화대상 음성이 생성되면 이를 이용해 음성인식 신경망을 학습시킨다 - 이를 '특화 학습'이라 부르 기로 한다. 특화 학습의 방식으로서, 기본 음성 데이터와 새로 생성된 특화 음성을 함께 이용하여 처음부터 음 성인식 신경망을 학습시킬 수도 있고, 기존에 만들어져 있는 일반 음성인식 신경망을 연결학습 또는 전이학습 등을 이용하여 추가로 학습시킬 수도 있다. 후자의 추가 학습은 인코더와 디코더 전체를 대상으로 할 수도 있고 인코더 또는 디코더만을 대상으로 할 수도 있으며 경우에 따라서는 일부 레이어만을 대상으로 할 수도 있다. 음성인식 신경망의 특화 학습이 끝나면 이 특화 음성인식 신경망을 이용하여 도메인특화 음성인식 모델을 구성한다. 앞의 도 1의 설명에서 언급한 것과 같이 도메인특화 음성인식 모델은 어텐션 기반의 인코더-디 코더 구조로 구성할 수 있지만 이에 국한되는 것은 아니다. 도 3은 도메인특화 음성인식 모델을 이용한 도메인특화 종단형 음성인식기의 구성도이다. 도 2의 과정을 통해 생성된 도메인특화 음성인식 신경망으로 도메인특화 음성인식 모델을 구성하고 도 1에서 설명한 음성인식기의 음성인식 모델을 이 특화 음성인식 모델로 대체하면, 본 발명에 따른 특화 종단형 음성인식기가 구성된다. 음성신호가 특화 종단형 음성인식기에 입력되면, 특징 추출부는 음성인식기가 처리하기에 적합한 구조로 예 를 들면 멜필터뱅크(Mel Filter Bank)와 같은 형태로 특징을 추출한다. 추출된 특징은 특화 음성인식 모델 의 음성 입력 인코더가 수신한다. 음성 입력 인코더는 특화 신경망으로 학습되어 있어서 음성신호 의 매 프레임별 인코드 값을 출력한다. 문자열 출력 디코더는 인코드 값을 수신하여 상기 신경망을 이 용해서 어떤 인코드 출력에 어텐션(attention)을 할지 계산하여 최종 문자열을 출력한다. 여기에서는 어텐션 기 반의 인코더-디코더 구조의 특화 음성인식 모델을 예로 들었지만 본 발명의 특화 종단형 음성인식기가 이러 한 구조에 국한되는 것은 아니다. 마지막으로, 음성인식 결과 출력부는 상기 디코더에서 출력된 최종문자열에 대해 텍스트 심볼 후처리 등의 과정을 수행하여 음성인식 결과 텍스트를 출력한다. 도 3과 같이 특화 종단형 음성인식기를 구성할 수 있지만, 추가적으로 특화의 정도를 가중치를 써서 조절하고 싶을 때에는 특화 언어모델을 생성할 수 있다. 도 4는 이러한 특화 언어모델을 생성하는 방법을 나타내는 흐름 도이다. 도 2에서 나타낸 특화대상 도메인 텍스트 DB만을 이용하여 특화 언어모델을 생성할 수도 있고, 필 요에 따라서는 일반 종단형 음성인식기를 만들 때 사용된 음성-전사문 텍스트 DB와 병합하여 특화 언어모델 을 생성할 수도 있다. 이 때 필요한 경우 특화대상 도메인 텍스트 DB 안의 각 텍스트들의 양을 변 화시켜서(줄이거나 늘려) 특화대상 도메인 텍스트들의 상대적 가중치들을 조절할 수 있다. 언어모델은 N-Gram 기반의 통계적 언어모델, 또는 RNN, Transformer 등 신경망 기반의 언어모델로 최종 생성이 가능하다. 생성된 특화 언어모델을 이용하여 특화 가중치를 조절한다. 특화 언어모델 및 이를 이용한 가중치 조절 에 대해 좀더 구체적으로 설명하면 다음과 같다. 먼저 수집된 특화대상 도메인 텍스트 DB로부터 특화대상 도메인을 대표할 수 있는 Validation Set과 Test Set을 선정한다. 이후 해당 Validation Set의 각 문장들과 특화 대상 도메인 텍스트 DB 내의 각 문장들 사 이의 문장 임베딩 벡터 간 유사도를 측정한다. 다음으로 유사도가 높은 문장들에게는 유사도에 따라 높은 가중치를 부여하고, 유사도가 낮은 문장들에는 낮은 가중치를 부여하여 특화 언어모델을 1차로 생성한다. 생성된 특화 언어모델을 이용하여 Test Set을 대상으로 혼잡도(Perplexity)를 계산하여 적절한 기대 수준의 혼 잡도가 측정되었는지 확인한다. 혼잡도가 목표보다 높은 경우에는 Validation Set과 유사도가 높은 특화대상 도메인 텍스트 DB 내의 문장들에 이전보다 더 높은 가중치를 부여하고 유사도가 낮은 문장들에게는 이전보다 더 낮은 가중치를 부여하여 언어모 델을 재생성한다. 혼잡도가 목표보다 낮은 경우에는 Validation Set과 유사도가 높은 특화대상 도메인 텍스트 DB 내의 문장들에 이전보다 더 낮은 가중치를 부여하고 유사도가 낮은 문장들에게는 이전보다 더 높은 가중 치를 부여하여 언어모델을 재생성한다. 혼잡도가 목표한 기대 수치에 다다를 때까지 이러한 과정을 반복하여 최 종 특화 언어모델을 생성한다. 특화 언어모델이 만들어지면 실제 음성인식기에 이 언어모델을 결합하여 음성 인식 성능을 측정한다. 특화 Test Set에 대해 실제 음성이 존재하면 이를 이용하고 음성이 존재하지 않으면 음성합성기를 이용하여 Test Set 문장에 대해 음성신호를 생성한 후 음성 인식 성능을 측정한다. 이 때 언어모델 가중치를 다양하게 적용해 음성인식 성능을 측정하여, Test Set에 대해서는 음성 인식 결과가 기대 목표에 부합하게 나타나고, 동시에 기존의 음성인식 성능도 저하되지 않는 적절한 언어모델 가중치를 찾아 이를 적용하도록 한다. 한편, 특화 가중치 조절을 위하여 도 4와 같이 생성된 특화 언어모델을 이용할 수도 있지만 특화 사용자어 휘 DB를 이용할 수도 있다. 도 5는 특화 사용자어휘를 추출하여 특화 사용자어휘 DB를 생성하는 방법을 기 술한 흐름도이다. 특화대상 도메인 텍스트 DB로부터 특화 사용자 어휘를 추출하고 이를 특화 사용자어휘로 저장하여 특화 사용자어휘 DB를 만든다. 특화 사용자 어휘 DB가 만들어지면, 해당 어휘들을 포함한 평가용 문장을 다양한 조합으로 구성한다. (예를 들어, '학교'에 대해 \"오늘 나는 '학교'에 갑니다.\" \"너는 '학교'에 갔었니?\" 등.) 평가용 문장들에 대해 실제 사람의 음성으로 평가용 음성 신호 발화셋을 구축하거나 불가능할 경우에는 음성 합 성기를 통하여 음성 신호를 생성하여 평가용 음성 신호 발화셋을 구축한다. 이후 특화 사용자 어휘를 결합한 음성인식기를 이용하여 평가용 음성신호 발화셋에 대해 음성인식 평가를 수행 하여 음성 인식이 잘되는 특화 사용자 어휘에는 낮은 가중치를 부여하고 음성 인식이 안 되는 특화 사용자 어휘 에는 상대적으로 높은 가중치를 부여한다. 이러한 다양한 가중치 조합 실험을 통해 최종적으로 평가용 음성 신호 발화 전체에 대해 가장 좋은 결과 수치를 보일 수 있도록 특화 사용자 어휘별로 가중치를 조절한다. 상기 특화 언어모델은 별도로 생성된 후 음성인식 모델과 융합(Fusion)되어 동작하지만, 특화 사용자어 휘 DB는 융합되지 않은 채로 외부에서 구문 힌트(Phrase Hints)(또는 다른 이름으로, 음성 문맥(Speech Context))처럼 명시적으로 가중치를 조절하여 동작하게 할 수 있다. 도 6은 도 3에 나타낸 특화 종단형 음성인식기에 특화 언어 모델과 특화 사용자어휘 DB를 추가 반영한 실시예의 특화 종단형 음성인식기의 구성도이다. 도 3에서 기술한 특화 종단형 음성인식기에 도 4에서 기술한 특화 언어모델과 도 5에서 기술한 특화 사용자어휘 DB를 결합하면 도 6의 특화 종단형 음성인식기가 된 다. 특화 언어모델은 Shallow Fusion, Deep Fusion 등의 형태로 특화 음성인식 모델과 융합되어 활용되고, 특화 사용자어휘 DB는 외부에 존재한 채로 인식 대상 후보들의 경쟁 과정에서 가중치를 계산할 때만 활용된 다(만일 언어 모델을 Cold Fusion하려면 음성 DB 학습과 함께 학습이 이루어져야 한다). 양쪽 모두 특화 텍스트 의 가중치를 반영하는 데 활용될 수 있지만 그 성격상 대개 특화 언어모델은 좀 더 많은 양의 특화 텍스트 를 반영할 때 사용하고 특화 사용자어휘 DB는 상대적으로 적은 양의 특화 텍스트를 반영할 때 사용할 수 있 다."}
{"patent_id": "10-2022-0001723", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "지금까지 본 발명의 바람직한 실시예를 통하여 본 발명을 상세히 설명하였으나, 본 발명이 속하는 기술분야의 통상의 지식을 가진 자는 본 발명이 그 기술적 사상이나 필수적인 특징을 변경하지 않고서 본 명세서에 개시된 내용과는 다른 구체적인 형태로 실시될 수 있다는 것을 이해할 수 있을 것이다. 이상에서 기술한 실시예들은 모 든 면에서 예시적인 것이며 한정적이 아닌 것으로 이해해야 한다. 또한 본 발명의 보호범위는 상기 상세한 설명 보다는 후술한 특허청구범위에 의하여 정해지며, 특허청구의 범위 그리고 그 균등 개념으로부터 도출되는 모든 변경 또는 변형된 형태는 본 발명의 기술적 범위에 포함되는 것으로 해석되어야 한다.도면 도면1 도면2 도면3 도면4 도면5 도면6"}
{"patent_id": "10-2022-0001723", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 일반적인 종단형 음성인식기의 구성도이다. 도 2는 본 발명의 일실시예에 따른 도메인특화 음성인식 모델 생성 방법의 구성도이다. 도 3은 본 발명의 일실시예에 따른, 도메인특화 음성인식 모델을 이용한 종단형 음성인식기의 구성도이다. 도 4는 특화 언어모델을 생성하는 방법을 나타내는 흐름도이다. 도 5는 특화 사용자어휘를 추출하여 특화 사용자어휘 DB를 생성하는 방법을 기술한 흐름도이다. 도 6은 도 3에 나타낸 종단형 음성인식기에 특화 언어 모델과 특화 사용자어휘 DB를 추가 반영한 실시 예의 종단형 음성인식기의 구성도이다."}
