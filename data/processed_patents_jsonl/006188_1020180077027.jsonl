{"patent_id": "10-2018-0077027", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2020-0004054", "출원번호": "10-2018-0077027", "발명의 명칭": "대화 시스템 및 대화 처리 방법", "출원인": "현대자동차주식회사", "발명자": "박정미"}}
{"patent_id": "10-2018-0077027", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "운전자 및 적어도 하나의 동승자를 포함하는 차량 내 탑승자 간 대화 및 차량 조작 정보 중 적어도 하나를 입력받고, 상기 탑승자 간 대화 및 상기 차량 조작 정보 중 적어도 하나에 기초하여 상기 적어도 하나의 동승자를식별하고, 상기 탑승자 간 대화에 기초하여 경유지에서의 상기 적어도 하나의 동승자의 인원 변화를 예측하는동승자 인원 정보를 생성하고, 상기 동승자 인원 정보에 대응되는 선발화 메시지를 획득하는 입력 처리기; 및선발화를 출력하는 결과 처리기;를 포함하는 대화 시스템."}
{"patent_id": "10-2018-0077027", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1 항에 있어서,상기 선발화 메시지는 상기 경유지에서의 상기 적어도 하나의 동승자 각각의 하차 가능성, 상기 경유지에서의상기 적어도 하나의 동승자 각각의 하차 후 재탑승 가능성 및 상기 경유지에서의 탑승예정자의 탑승 가능성 중적어도 하나를 나타내는 대화 시스템."}
{"patent_id": "10-2018-0077027", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 1 항에 있어서,상기 입력 처리기는,상기 탑승자 간 대화에 포함된 적어도 하나의 동승자의 음성의 음성 특성 정보에 기초하여 상기 적어도 하나의동승자의 탑승을 판단하는 음성 입력 처리기; 및상기 차량 조작 정보에 기초하여 상기 적어도 하나의 동승자의 탑승을 판단하는 상황 정보 처리기;를 포함하는대화 시스템."}
{"patent_id": "10-2018-0077027", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 3 항에 있어서,상기 음성 특성 정보는 비언어적 음성학 특성 및 언어적 특성 중 적어도 하나를 포함하는 대화 시스템."}
{"patent_id": "10-2018-0077027", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제 3 항에 있어서,상기 차량 조작 정보는 조수석 및 후열 시트 각각에 대한 윈도우 조정 버튼 조작 정보, 시트 조정 버튼 조작 정보 및 공조 장치 조정 버튼 조작 정보 중 적어도 하나를 포함하는 대화 시스템."}
{"patent_id": "10-2018-0077027", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제 3 항에 있어서,상기 입력 처리기는,상기 적어도 하나의 동승자의 탑승을 판단한 경우, 상기 적어도 하나의 동승자의 탑승에 대응되는 선발화 메시지를 획득하고, 상기 선발화 메시지에 대한 적어도 하나의 동승자의 발화를 입력 받고, 상기 선발화 메시지에대한 상기 적어도 하나의 동승자의 발화에 자연어 이해 알고리즘을 적용하여 상기 적어도 하나의 동승자를 식별하는 대화 시스템."}
{"patent_id": "10-2018-0077027", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제 3 항에 있어서,공개특허 10-2020-0004054-3-상기 입력 처리기는,상기 적어도 하나의 동승자의 탑승을 판단하지 못한 경우, 상기 적어도 하나의 동승자의 비-탑승에 대응되는 선발화 메시지를 획득하고, 상기 선발화 메시지에 대한 운전자의 발화를 입력 받고, 상기 선발화 메시지에 대한운전자의 발화에 자연어 이해 알고리즘을 적용하여 동승자 존재 여부를 확인하는 대화 시스템."}
{"patent_id": "10-2018-0077027", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제 2항에 있어서,상기 입력 처리기는,상기 탑승자 간 대화에 자연어 이해 알고리즘을 적용하여 상기 경유지에서의 상기 적어도 하나의 동승자 각각의상기 하차 가능성 및 상기 경유지에서의 상기 적어도 하나의 동승자 각각의 상기 하차 후 재탑승 가능성을 판단하고, 상기 하차 가능성 및 상기 하차 후 재탑승 가능성에 기초하여, 상기 동승자 인원 정보를 생성하는 대화시스템."}
{"patent_id": "10-2018-0077027", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제 2항에 있어서,상기 입력 처리기는,차량 내 통화 내용을 입력 받고, 상기 차량 내 통화 내용에 자연어 이해 알고리즘을 적용하여 상기 경유지에서의 상기 탑승예정자의 탑승 가능성을 판단하고, 상기 탑승 가능성에 기초하여, 상기 동승자 인원 정보를 생성하는 대화 시스템."}
{"patent_id": "10-2018-0077027", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제 8 항에 있어서,상기 입력 처리기는,상기 경유지 출발 후, 상기 탑승자 간 대화 및 상기 차량 조작 정보에 기초하여 상기 경유지 출발 후 동승자 인원 변화 결과를 판단하고, 상기 동승자 인원 정보에 기초한 동승자 인원 변화 예측 결과와 상기 경유지 출발 후동승자 인원 변화 결과를 비교하고, 상기 비교의 결과에 대응되는 선발화 메시지를 획득하고,상기 결과 처리기는,상기 경유지 출발 후, 상기 선발화 메시지에 따라 선발화를 출력하는 대화 시스템."}
{"patent_id": "10-2018-0077027", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제 10항에 있어서,상기 입력 처리기는,상기 경유지 출발 후, 상기 경유지 출발 후 동승자 인원 변화 결과를 판단하기 위한 선발화 메시지를 획득하고,상기 선발화 메시지에 대한 탑승자의 발화를 입력 받고, 상기 선발화 메시지에 대한 탑승자의 발화에 자연어 이해 알고리즘을 적용하여 상기 경유지 출발 후 동승자 인원 변화 결과를 판단하는 대화 시스템."}
{"patent_id": "10-2018-0077027", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제 1 항에 있어서,차량의 주행이 종료되는 경우, 주행 관련 정보 및 상기 적어도 하나의 동승자 각각에 관한 동승자 정보가 저장되는 저장부;를 더 포함하는 대화 시스템."}
{"patent_id": "10-2018-0077027", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제 12 항에 있어서,상기 주행 관련 정보는 주행의 출발지, 경유지 및 도착지 중 적어도 하나를 포함하는 대화 시스템.공개특허 10-2020-0004054-4-청구항 14 제 12 항에 있어서,상기 동승자 정보는 동승자 식별 정보, 음성 특성 정보, 착석 위치 정보, 탑승 시각 정보, 탑승 장소 정보, 하차 시각 정보 및 하차 장소 정보 중 적어도 하나를 포함하는 대화 시스템."}
{"patent_id": "10-2018-0077027", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제 12 항에 있어서,상기 입력 처리기는,상기 탑승자 간 대화 및 상기 차량 조작 정보를 입력 받고, 상기 탑승자 간 대화 및 상기 차량 조작 정보에 기초하여 상기 적어도 하나의 동승자의 탑승을 판단하고, 상기 적어도 하나의 동승자 각각의 특성이 상기 동승자정보와 일치하는지 판단하고, 상기 특성이 상기 동승자 정보와 일치하는 제1 동승자의 이전 주행 참여 여부를확인하기 위한 선발화 메시지를 획득하고,상기 결과 처리기는,상기 선발화 메시지에 따라 선발화를 출력하는 대화 시스템."}
{"patent_id": "10-2018-0077027", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제 15 항에 있어서,상기 입력 처리기는,상기 선발화 메시지에 대한 동승자의 발화를 입력 받고, 상기 선발화 메시지에 대한 동승자의 발화에 자연어 이해 알고리즘을 적용하여 상기 제1 동승자의 상기 이전 주행 참여 여부를 확인하고, 상기 제1 동승자가 이전 주행에 참여한 경우, 상기 탑승자 간 대화 및 상기 동승자 정보에 기초하여 상기 동승자 인원 정보를 생성하는 대화 시스템."}
{"patent_id": "10-2018-0077027", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "운전자 및 적어도 하나의 동승자를 포함하는 차량 내 탑승자 간 대화 및 차량 조작 정보 중 적어도 하나를 입력받고;상기 탑승자 간 대화 및 상기 차량 조작 정보 중 적어도 하나에 기초하여 상기 적어도 하나의 동승자를 식별하고;상기 탑승자 간 대화에 기초하여 경유지에서의 상기 적어도 하나의 동승자의 인원 변화를 예측하는 동승자 인원정보를 생성하고;상기 동승자 인원 정보에 대응되는 선발화 메시지를 획득하고;선발화를 출력하는 것;을 포함하는 대화 처리 방법."}
{"patent_id": "10-2018-0077027", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제 17 항에 있어서,상기 선발화 메시지는 상기 경유지에서의 상기 적어도 하나의 동승자 각각의 하차 가능성, 상기 경유지에서의상기 적어도 하나의 동승자 각각의 하차 후 재탑승 가능성 및 상기 경유지에서의 탑승예정자의 탑승 가능성 중적어도 하나를 나타내는 대화 처리 방법."}
{"patent_id": "10-2018-0077027", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제 17 항에 있어서,상기 탑승자 간 대화에 포함된 적어도 하나의 동승자의 음성의 음성 특성 정보에 기초하여 상기 적어도 하나의동승자의 탑승을 판단하고;공개특허 10-2020-0004054-5-상기 차량 조작 정보에 기초하여 상기 적어도 하나의 동승자의 탑승을 판단하는 것;을 더 포함하는 대화 처리방법."}
{"patent_id": "10-2018-0077027", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제 19 항에 있어서,상기 음성 특성 정보는 비언어적 음성학 특성 및 언어적 특성 중 적어도 하나를 포함하는 대화 처리 방법."}
{"patent_id": "10-2018-0077027", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_21", "content": "제 19 항에 있어서,상기 차량 조작 정보는 조수석 및 후열 시트 각각에 대한 윈도우 조정 버튼 조작 정보, 시트 조정 버튼 조작 정보 및 공조 장치 조정 버튼 조작 정보 중 적어도 하나를 포함하는 대화 처리 방법."}
{"patent_id": "10-2018-0077027", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_22", "content": "제 19 항에 있어서,상기 적어도 하나의 동승자의 탑승을 판단한 경우, 상기 적어도 하나의 동승자의 탑승에 대응되는 선발화 메시지를 획득하고;상기 선발화 메시지에 대한 적어도 하나의 동승자의 발화를 입력 받고;상기 선발화 메시지에 대한 상기 적어도 하나의 동승자의 발화에 자연어 이해 알고리즘을 적용하여 상기 적어도하나의 동승자를 식별하는 것;을 더 포함하는 대화 처리 방법."}
{"patent_id": "10-2018-0077027", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_23", "content": "제 19 항에 있어서,상기 적어도 하나의 동승자의 탑승을 판단하지 못한 경우, 상기 적어도 하나의 동승자의 비-탑승에 대응되는 선발화 메시지를 획득하고;상기 선발화 메시지에 대한 운전자의 발화를 입력 받고;상기 선발화 메시지에 대한 운전자의 발화에 자연어 이해 알고리즘을 적용하여 동승자 존재 여부를 확인하는것;을 더 포함하는 대화 처리 방법."}
{"patent_id": "10-2018-0077027", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_24", "content": "제 18항에 있어서,상기 탑승자 간 대화에 자연어 이해 알고리즘을 적용하여 상기 경유지에서의 상기 적어도 하나의 동승자 각각의상기 하차 가능성 및 상기 경유지에서의 상기 적어도 하나의 동승자 각각의 상기 하차 후 재탑승 가능성을 판단하고;상기 하차 가능성 및 상기 하차 후 재탑승 가능성에 기초하여, 상기 동승자 인원 정보를 생성하는 것;을 더 포함하는 대화 처리 방법."}
{"patent_id": "10-2018-0077027", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_25", "content": "제 18항에 있어서,차량 내 통화 내용을 입력 받고;상기 차량 내 통화 내용에 자연어 이해 알고리즘을 적용하여 상기 경유지에서의 상기 탑승예정자의 탑승 가능성을 판단하고;상기 탑승 가능성에 기초하여, 상기 동승자 인원 정보를 생성하는 것;을 더 포함하는 대화 처리 방법."}
{"patent_id": "10-2018-0077027", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_26", "content": "공개특허 10-2020-0004054-6-제 24 항에 있어서,상기 경유지 출발 후, 상기 탑승자 간 대화 및 상기 차량 조작 정보에 기초하여 상기 경유지 출발 후 동승자 인원 변화 결과를 판단하고;상기 동승자 인원 정보에 기초한 동승자 인원 변화 예측 결과와 상기 경유지 출발 후 동승자 인원 변화 결과를비교하고;상기 비교의 결과에 대응되는 선발화 메시지를 획득하고;상기 경유지 출발 후, 상기 선발화 메시지에 따라 선발화를 출력하는 것;을 더 포함하는 대화 처리 방법."}
{"patent_id": "10-2018-0077027", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_27", "content": "제 26 항에 있어서,상기 경유지 출발 후, 상기 경유지 출발 후 동승자 인원 변화 결과를 판단하기 위한 선발화 메시지를 획득하고;상기 선발화 메시지에 대한 탑승자의 발화를 입력 받고;상기 선발화 메시지에 대한 탑승자의 발화에 자연어 이해 알고리즘을 적용하여 상기 경유지 출발 후 동승자 인원 변화 결과를 판단하는 것;을 더 포함하는 대화 처리 방법."}
{"patent_id": "10-2018-0077027", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_28", "content": "제 17 항에 있어서,차량의 주행이 종료되는 경우, 주행 관련 정보 및 상기 적어도 하나의 동승자 각각에 관한 동승자 정보가 저장되는 것;을 더 포함하는 대화 처리 방법."}
{"patent_id": "10-2018-0077027", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_29", "content": "제 28 항에 있어서,상기 주행 관련 정보는 주행의 출발지, 경유지 및 도착지 중 적어도 하나를 포함하는 대화 처리 방법."}
{"patent_id": "10-2018-0077027", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_30", "content": "제 28 항에 있어서,상기 동승자 정보는 동승자 식별 정보, 음성 특성 정보, 착석 위치 정보, 탑승 시각 정보, 탑승 장소 정보, 하차 시각 정보 및 하차 장소 정보 중 적어도 하나를 포함하는 대화 처리 방법."}
{"patent_id": "10-2018-0077027", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_31", "content": "제 28 항에 있어서,상기 탑승자 간 대화 및 상기 차량 조작 정보를 입력 받고;상기 탑승자 간 대화 및 상기 차량 조작 정보에 기초하여 상기 적어도 하나의 동승자의 탑승을 판단하고;상기 적어도 하나의 동승자 각각의 특성이 상기 동승자 정보와 일치하는지 판단하고;상기 특성이 상기 동승자 정보와 일치하는 제1 동승자의 이전 주행 참여 여부를 확인하기 위한 선발화 메시지를획득하고;상기 선발화 메시지에 따라 선발화를 출력하는 것;을 더 포함하는 대화 처리 방법."}
{"patent_id": "10-2018-0077027", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_32", "content": "제 31 항에 있어서,상기 선발화 메시지에 대한 동승자의 발화를 입력 받고;상기 선발화 메시지에 대한 동승자의 발화에 자연어 이해 알고리즘을 적용하여 상기 제1 동승자의 상기 이전 주공개특허 10-2020-0004054-7-행 참여 여부를 확인하고;상기 제1 동승자가 이전 주행에 참여한 경우, 상기 탑승자 간 대화 및 상기 동승자 정보에 기초하여 상기 동승자 인원 정보를 생성하는 것;을 더 포함하는 대화 처리 방법."}
{"patent_id": "10-2018-0077027", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "주행 중 차량 내 탑승자 간의 대화에 기초하여 동승자를 식별하는 서비스를 제공할 뿐만 아니라, 차량 내 동승자 인원 변화를 예측하여 안내하는 서비스 또한 제공할 수 있는 대화 시스템, 이를 포함하는 차량 및 대화 처리 방 법을 제공한다. 일 실시예에 따른 대화 시스템은, 운전자 및 적어도 하나의 동승자를 포함하는 차량 내 탑승자 간 대화 및 차량 조작 정보 중 적어도 하나를 입력 받고, 상기 탑승자 간 대화 및 상기 차량 조작 정보 중 적어도 하나에 기초하 여 상기 적어도 하나의 동승자를 식별하고, 상기 차량 내 탑승자 간 대화에 기초하여 경유지에서의 상기 적어도 하나의 동승자의 인원 변화를 예측하는 동승자 인원 정보를 생성하고, 상기 동승자 인원 정보에 대응되는 선발화 메시지를 획득하는 입력 처리기; 및 선발화를 출력하는 결과 처리기;를 포함한다."}
{"patent_id": "10-2018-0077027", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "개시된 발명은 사용자와의 대화를 통해 사용자의 의도를 파악하고 사용자에게 필요한 정보나 서비스를 제공하는 대화 시스템, 및 대화 처리 방법에 관한 것이다."}
{"patent_id": "10-2018-0077027", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "차량용 AVN이나 대부분의 모바일 기기는 작은 화면 및 작은 버튼으로 인해, 사용자에게 시각적인 정보를 제공하 거나 사용자의 입력을 수신함에 있어 불편함이 발생할 수 있다. 특히, 사용자가 운전 중 시각적인 정보를 확인하거나 기기를 조작하기 위해, 시선을 이동시키고 스티어링 휠에 서 손을 떼는 것은 안전 운전에 위협이 되는 요소로 작용한다. 따라서, 사용자와의 대화를 통해 사용자의 의도를 파악하고, 사용자에게 필요한 서비스를 제공하는 대화 시스템 이 차량에 적용될 경우 보다 안전하고 편리하게 서비스를 제공할 수 있을 것으로 기대된다."}
{"patent_id": "10-2018-0077027", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "개시된 발명의 일 측면은, 차량 주행 환경에서 사용자와의 대화 및 차량 상태 정보, 주행 환경 정보, 사용자 정 보 등의 다양한 정보를 바탕으로 사용자의 의도를 정확하게 파악함으로써, 사용자의 실제 의도에 부합되는 서비 스 또는 사용자에게 가장 필요한 서비스를 제공할 수 있는 대화 시스템, 이를 포함하는 차량 및 대화 처리 방법 을 제공한다. 개시된 발명의 다른 일 측면은, 주행 중 차량 내 탑승자 간의 대화에 기초하여 동승자를 식별하는 서비스를 제 공할 뿐만 아니라, 차량 내 동승자 인원 변화를 예측하여 안내하는 서비스 또한 제공할 수 있는 대화 시스템, 이를 포함하는 차량 및 대화 처리 방법을 제공한다."}
{"patent_id": "10-2018-0077027", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "일 실시예에 따른 대화 시스템은, 운전자 및 적어도 하나의 동승자를 포함하는 차량 내 탑승자 간 대화 및 차량 조작 정보 중 적어도 하나를 입력 받고, 상기 탑승자 간 대화 및 상기 차량 조작 정보 중 적어도 하나에 기초하 여 상기 적어도 하나의 동승자를 식별하고, 상기 탑승자 간 대화에 기초하여 경유지에서의 상기 적어도 하나의 동승자의 인원 변화를 예측하는 동승자 인원 정보를 생성하고, 상기 동승자 인원 정보에 대응되는 선발화 메시 지를 획득하는 입력 처리기; 및 선발화를 출력하는 결과 처리기;를 포함한다. 상기 선발화 메시지는 상기 경유지에서의 상기 적어도 하나의 동승자 각각의 하차 가능성, 상기 경유지에서의 상기 적어도 하나의 동승자 각각의 하차 후 재탑승 가능성 및 상기 경유지에서의 탑승예정자의 탑승 가능성 중 적어도 하나를 나타낼 수 있다. 상기 입력 처리기는, 상기 탑승자 간 대화에 포함된 적어도 하나의 동승자의 음성의 음성 특성 정보에 기초하여 상기 적어도 하나의 동승자의 탑승을 판단하는 음성 입력 처리기; 및 상기 차량 조작 정보에 기초하여 상기 적 어도 하나의 동승자의 탑승을 판단하는 상황 정보 처리기;를 포함한다. 상기 음성 특성 정보는 비언어적 음성학 특성 및 언어적 특성 중 적어도 하나를 포함할 수 있다. 상기 차량 조작 정보는 조수석 및 후열 시트 각각에 대한 윈도우 조정 버튼 조작 정보, 시트 조정 버튼 조작 정 보 및 공조 장치 조정 버튼 조작 정보 중 적어도 하나를 포함할 수 있다. 상기 입력 처리기는, 상기 적어도 하나의 동승자의 탑승을 판단한 경우, 상기 적어도 하나의 동승자의 탑승에 대응되는 선발화 메시지를 획득하고, 상기 선발화 메시지에 대한 적어도 하나의 동승자의 발화를 입력 받고, 상 기 선발화 메시지에 대한 상기 적어도 하나의 동승자의 발화에 자연어 이해 알고리즘을 적용하여 상기 적어도하나의 동승자를 식별할 수 있다. 상기 입력 처리기는, 상기 적어도 하나의 동승자의 탑승을 판단하지 못한 경우, 상기 적어도 하나의 동승자의 비-탑승에 대응되는 선발화 메시지를 획득하고, 상기 선발화 메시지에 대한 운전자의 발화를 입력 받고, 상기 선발화 메시지에 대한 운전자의 발화에 자연어 이해 알고리즘을 적용하여 동승자 존재 여부를 확인할 수 있다. 상기 입력 처리기는, 상기 탑승자 간 대화에 자연어 이해 알고리즘을 적용하여 상기 경유지에서의 상기 적어도 하나의 동승자 각각의 상기 하차 가능성 및 상기 경유지에서의 상기 적어도 하나의 동승자 각각의 상기 하차 후 재탑승 가능성을 판단하고, 상기 하차 가능성 및 상기 하차 후 재탑승 가능성에 기초하여, 상기 동승자 인원 정 보를 생성할 수 있다. 상기 입력 처리기는, 차량 내 통화 내용을 입력 받고, 상기 차량 내 통화 내용에 자연어 이해 알고리즘을 적용 하여 상기 경유지에서의 상기 탑승예정자의 탑승 가능성을 판단하고, 상기 탑승 가능성에 기초하여, 상기 동승 자 인원 정보를 생성할 수 있다. 상기 입력 처리기는, 상기 경유지 출발 후, 상기 탑승자 간 대화 및 상기 차량 조작 정보에 기초하여 상기 경유 지 출발 후 동승자 인원 변화 결과를 판단하고, 상기 동승자 인원 정보에 기초한 동승자 인원 변화 예측 결과와 상기 경유지 출발 후 동승자 인원 변화 결과를 비교하고, 상기 비교의 결과에 대응되는 선발화 메시지를 획득하 고, 상기 결과 처리기는, 상기 경유지 출발 후, 상기 선발화 메시지에 따라 선발화를 출력할 수 있다. 상기 입력 처리기는, 상기 경유지 출발 후, 상기 경유지 출발 후 동승자 인원 변화 결과를 판단하기 위한 선발 화 메시지를 획득하고, 상기 선발화 메시지에 대한 탑승자의 발화를 입력 받고, 상기 선발화 메시지에 대한 탑 승자의 발화에 자연어 이해 알고리즘을 적용하여 상기 경유지 출발 후 동승자 인원 변화 결과를 판단할 수 있다. 차량의 주행이 종료되는 경우, 주행 관련 정보 및 상기 적어도 하나의 동승자 각각에 관한 동승자 정보가 저장 되는 저장부;를 더 포함할 수 있다. 상기 주행 관련 정보는 주행의 출발지, 경유지 및 도착지 중 적어도 하나를 포함할 수 있다. 상기 동승자 정보는 동승자 식별 정보, 음성 특성 정보, 착석 위치 정보, 탑승 시각 정보, 탑승 장소 정보, 하 차 시각 정보 및 하차 장소 정보 중 적어도 하나를 포함할 수 있다. 상기 입력 처리기는, 상기 탑승자 간 대화 및 상기 차량 조작 정보를 입력 받고, 상기 탑승자 간 대화 및 상기 차량 조작 정보에 기초하여 상기 적어도 하나의 동승자의 탑승을 판단하고, 상기 적어도 하나의 동승자 각각의 특성이 상기 동승자 정보와 일치하는지 판단하고, 상기 특성이 상기 동승자 정보와 일치하는 제1 동승자의 이전 주행 참여 여부를 확인하기 위한 선발화 메시지를 획득하고, 상기 결과 처리기는, 상기 선발화 메시지에 따라 선발화를 출력할 수 있다. 상기 입력 처리기는, 상기 선발화 메시지에 대한 동승자의 발화를 입력 받고, 상기 선발화 메시지에 대한 동승 자의 발화에 자연어 이해 알고리즘을 적용하여 상기 제1 동승자의 상기 이전 주행 참여 여부를 확인하고, 상기 제1 동승자가 이전 주행에 참여한 경우, 상기 탑승자 간 대화 및 상기 동승자 정보에 기초하여 상기 동승자 인 원 정보를 생성할 수 있다. 일 실시예에 따른 대화 처리 방법은, 운전자 및 적어도 하나의 동승자를 포함하는 차량 내 탑승자 간 대화 및 차량 조작 정보 중 적어도 하나를 입력 받고; 상기 탑승자 간 대화 및 상기 차량 조작 정보 중 적어도 하나에 기초하여 상기 적어도 하나의 동승자를 식별하고; 상기 탑승자 간 대화에 기초하여 경유지에서의 상기 적어도 하나의 동승자의 인원 변화를 예측하는 동승자 인원 정보를 생성하고; 상기 동승자 인원 정보에 대응되는 선발 화 메시지를 획득하고; 선발화를 출력하는 것;을 포함할 수 있다. 상기 선발화 메시지는 상기 경유지에서의 상기 적어도 하나의 동승자 각각의 하차 가능성, 상기 경유지에서의 상기 적어도 하나의 동승자 각각의 하차 후 재탑승 가능성 및 상기 경유지에서의 탑승예정자의 탑승 가능성 중 적어도 하나를 나타낼 수 있다. 상기 대화 처리 방법은, 상기 탑승자 간 대화에 포함된 적어도 하나의 동승자의 음성의 음성 특성 정보에 기초 하여 상기 적어도 하나의 동승자의 탑승을 판단하고; 상기 차량 조작 정보에 기초하여 상기 적어도 하나의 동승 자의 탑승을 판단하는 것;을 더 포함할 수 있다. 상기 음성 특성 정보는 비언어적 음성학 특성 및 언어적 특성 중 적어도 하나를 포함할 수 있다. 상기 차량 조작 정보는 조수석 및 후열 시트 각각에 대한 윈도우 조정 버튼 조작 정보, 시트 조정 버튼 조작 정 보 및 공조 장치 조정 버튼 조작 정보 중 적어도 하나를 포함할 수 있다. 상기 대화 처리 방법은, 상기 적어도 하나의 동승자의 탑승을 판단한 경우, 상기 적어도 하나의 동승자의 탑승 에 대응되는 선발화 메시지를 획득하고; 상기 선발화 메시지에 대한 적어도 하나의 동승자의 발화를 입력 받고; 상기 선발화 메시지에 대한 상기 적어도 하나의 동승자의 발화에 자연어 이해 알고리즘을 적용하여 상기 적어도 하나의 동승자를 식별하는 것;을 더 포함할 수 있다. 상기 대화 처리 방법은, 상기 적어도 하나의 동승자의 탑승을 판단하지 못한 경우, 상기 적어도 하나의 동승자 의 비-탑승에 대응되는 선발화 메시지를 획득하고; 상기 선발화 메시지에 대한 운전자의 발화를 입력 받고; 상 기 선발화 메시지에 대한 운전자의 발화에 자연어 이해 알고리즘을 적용하여 동승자 존재 여부를 확인하는 것; 을 더 포함할 수 있다. 상기 대화 처리 방법은, 상기 탑승자 간 대화에 자연어 이해 알고리즘을 적용하여 상기 경유지에서의 상기 적어 도 하나의 동승자 각각의 상기 하차 가능성 및 상기 경유지에서의 상기 적어도 하나의 동승자 각각의 상기 하차 후 재탑승 가능성을 판단하고; 상기 하차 가능성 및 상기 하차 후 재탑승 가능성에 기초하여, 상기 동승자 인원 정보를 생성하는 것;을 더 포함할 수 있다. 상기 대화 처리 방법은, 차량 내 통화 내용을 입력 받고; 상기 차량 내 통화 내용에 자연어 이해 알고리즘을 적 용하여 상기 경유지에서의 상기 탑승예정자의 탑승 가능성을 판단하고; 상기 탑승 가능성에 기초하여, 상기 동 승자 인원 정보를 생성하는 것;을 더 포함할 수 있다. 상기 대화 처리 방법은, 상기 경유지 출발 후, 상기 탑승자 간 대화 및 상기 차량 조작 정보에 기초하여 상기 경유지 출발 후 동승자 인원 변화 결과를 판단하고; 상기 동승자 인원 정보에 기초한 동승자 인원 변화 예측 결 과와 상기 경유지 출발 후 동승자 인원 변화 결과를 비교하고; 상기 비교의 결과에 대응되는 선발화 메시지를 획득하고; 상기 경유지 출발 후, 상기 선발화 메시지에 따라 선발화를 출력하는 것;을 더 포함할 수 있다. 상기 대화 처리 방법은, 상기 경유지 출발 후, 상기 경유지 출발 후 동승자 인원 변화 결과를 판단하기 위한 선 발화 메시지를 획득하고; 상기 선발화 메시지에 대한 탑승자의 발화를 입력 받고; 상기 선발화 메시지에 대한 탑승자의 발화에 자연어 이해 알고리즘을 적용하여 상기 경유지 출발 후 동승자 인원 변화 결과를 판단하는 것;을 더 포함할 수 있다. 상기 대화 처리 방법은, 차량의 주행이 종료되는 경우, 주행 관련 정보 및 상기 적어도 하나의 동승자 각각에 관한 동승자 정보가 저장되는 것;을 더 포함할 수 있다. 상기 주행 관련 정보는 주행의 출발지, 경유지 및 도착지 중 적어도 하나를 포함할 수 있다. 상기 동승자 정보는 동승자 식별 정보, 음성 특성 정보, 착석 위치 정보, 탑승 시각 정보, 탑승 장소 정보, 하 차 시각 정보 및 하차 장소 정보 중 적어도 하나를 포함할 수 있다. 상기 대화 처리 방법은, 상기 탑승자 간 대화 및 상기 차량 조작 정보를 입력 받고; 상기 탑승자 간 대화 및 상 기 차량 조작 정보에 기초하여 상기 적어도 하나의 동승자의 탑승을 판단하고; 상기 적어도 하나의 동승자 각각 의 특성이 상기 동승자 정보와 일치하는지 판단하고; 상기 특성이 상기 동승자 정보와 일치하는 제1 동승자의 이전 주행 참여 여부를 확인하기 위한 선발화 메시지를 획득하고; 상기 선발화 메시지에 따라 선발화를 출력하 는 것;을 더 포함할 수 있다. 상기 대화 처리 방법은, 상기 선발화 메시지에 대한 동승자의 발화를 입력 받고; 상기 선발화 메시지에 대한 동 승자의 발화에 자연어 이해 알고리즘을 적용하여 상기 제1 동승자의 상기 이전 주행 참여 여부를 확인하고; 상 기 제1 동승자가 이전 주행에 참여한 경우, 상기 탑승자 간 대화 및 상기 동승자 정보에 기초하여 상기 동승자 인원 정보를 생성하는 것;을 더 포함할 수 있다."}
{"patent_id": "10-2018-0077027", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "일 측면에 따른 대화 시스템, 이를 포함하는 차량 및 대화 처리 방법에 의하면, 차량 주행 환경에서 사용자와의 대화 및 차량 상태 정보, 주행 환경 정보, 사용자 정보 등의 다양한 정보를 바탕으로 사용자의 의도를 정확하게 파악함으로써, 사용자의 실제 의도에 부합되는 서비스 또는 사용자에게 가장 필요한 서비스를 제공할 수 있다. 다른 측면에 따른 대화 시스템, 이를 포함하는 차량 및 대화 처리 방법에 의하면, 주행 중 차량 내 탑승자 간의 대화에 기초하여 동승자 각각의 하차 가능성 및 하차 후 재탑승 가능성을 예측함으로써, 개별 동승자가 원하는 지점에 하차할 수 있도록 안내할 뿐만 아니라, 주행 중인 운전자의 집중 분산을 방지할 수 있는 서비스를 제공 할 수 있다."}
{"patent_id": "10-2018-0077027", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "명세서 전체에 걸쳐 동일 참조 부호는 동일 구성요소를 지칭한다. 본 명세서가 실시예들의 모든 요소들을 설명"}
{"patent_id": "10-2018-0077027", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "하는 것은 아니며, 본 발명이 속하는 기술분야에서 일반적인 내용 또는 실시예들 간에 중복되는 내용은 생략한 다. 명세서에서 사용되는 ‘부, 모듈, 부재, 블록’이라는 용어는 소프트웨어 또는 하드웨어로 구현될 수 있으 며, 실시예들에 따라 복수의 '부, 모듈, 부재, 블록'이 하나의 구성요소로 구현되거나, 하나의 '부, 모듈, 부재, 블록'이 복수의 구성요소들을 포함하는 것도 가능하다. 명세서 전체에서, 어떤 부분이 다른 부분과 \"연결\"되어 있다고 할 때, 이는 직접적으로 연결되어 있는 경우뿐 아니라, 간접적으로 연결되어 있는 경우를 포함하고, 간접적인 연결은 무선 통신망을 통해 연결되는 것을 포함 한다. 또한 어떤 부분이 어떤 구성요소를 \"포함\"한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다른 구성요소를 제외하는 것이 아니라 다른 구성요소를 더 포함할 수 있는 것을 의미한다. 단수의 표현은 문맥상 명백하게 예외가 있지 않는 한, 복수의 표현을 포함한다. 각 단계들에 붙여지는 부호는 각 단계들을 식별하기 위해 사용되는 것으로 이들 부호는 각 단계들 상호 간의 순 서를 나타내는 것이 아니며, 각 단계들은 문맥상 명백하게 특정 순서를 기재하지 않는 이상 명기된 순서와 다르 게 실시될 수 있다. 이하 첨부된 도면들을 참고하여 대화 시스템, 이를 포함하는 차량 및 대화 처리 방법의 실시예를 상세하게 설명 한다. 일 실시예에 따른 대화 시스템은 사용자의 음성 및 음성 외 입력을 이용하여 사용자의 의도를 파악하고 사용자 의 의도에 적합한 서비스 또는 사용자에게 필요한 서비스를 제공하는 장치로서, 서비스 제공의 일 수단 또는 사 용자의 의도를 명확히 파악하기 위한 일 수단으로 시스템 발화를 출력함으로써 사용자와 대화를 수행할 수 있다. 구체적인 예로, 대화 시스템은 음성 인식을 이용함으로써, 차량 내 탑승자 간 대화 내용을 파악하고, 차량 내 탑승자 간 대화 내용에 기초하여 동승자를 식별하고, 동승자 각각의 하차 가능성 및 하차 후 재탑승 가능성을 판단할 수 있다. 대화 시스템은, 동승자의 하차 가능성 및 하차 후 재탑승 가능성을 운전자에게 알리기 위한 일 수단으로 시스템 발화를 출력함으로써 동승자와 대화를 수행할 수 있다. 이 때, 대화 시스템은 사용자의 요청에 대응하여 시스템 발화를 출력함으로써 사용자의 대화를 수행할 수도 있 고, 사용자의 요청이 없어도 선발화를 출력함으로써 사용자와 대화를 수행할 수도 있다. 이하에서 설명되는 선발화는 사용자가 요청하지 않았음에도 출력되는 발화로써, 동승자가 의도하는 경유지 또는 도착지에 도달하여 즉각적인 반응이 필요한 경우에 출력되는 발화를 포함할 수 있다. 또한, 선발화는 사용자 정보를 획득 및 분석하여 사용자가 요청하지 않았음에도 정보 전달이 필요한 경우에 출력되는 발화를 포함할 수 있다. 또한, 선발화는 대화 시스템이 외부 기기 예를 들어 차량, 사용자 단말, 외부 서버 등으로부터 각종 정보를 전 달 받아 정보 전달이 필요한 경우에 출력되는 발화를 포함할 수 있다. 한편, 선발화가 사용자가 요청하지 않았음에도 출력되는 시스템 발화로만 한정되는 것은 아니다. 사용자의 요청 이 즉각적이지 않아, 일정 시간 또는 특정 조건이 발생했을 때에 발화 출력이 요구되는 경우에는 선발화에 포함 될 수 있다. 예를 들어, 사용자가 일정 시간 이후에 출력을 요구하거나 또는 요청한 일정 시간이 도달했음에도 사용자가 통화 중이어서 발화 출력을 미루어야 하는 경우, 대화 시스템은 적절한 타이밍을 선정하고, 선정한 타 이밍에 선발화를 출력할 수 있다. 이하에서는 설명의 편의상 선발화 또는 사용자가 요청에 대응하여 출력하는 시스템 발화를 구분하여 설명할 필요가 없는 경우 발화로 통칭하기로 한다. 이하에서 설명되는 사용자 또는 차량 내 탑승자는 차량 내에 탑승한 모든 대상체를 포함한다. 예를 들어, 사용 자 또는 차량 내 탑승자는 운전자뿐만 아니라 동승자를 포함하며, 보다 구체적으로는 운전석 및 보조석 시트뿐 만 아니라 후열 시트에 탑승하는 동승자를 전부 통칭한다. 당해 실시예에서 사용자에게 제공되는 서비스는 정보의 제공, 차량의 제어, 오디오/비디오/내비게이션 기능의 실행, 외부 서버로부터 가져온 컨텐츠의 제공 등 사용자의 필요나 사용자의 의도에 부응하기 위해 수행되는 모 든 동작을 포함할 수 있다. 또한, 일 실시예에 따른 대화 시스템은 차량 환경에 특화된 대화 처리 기술을 제공함으로써, 차량이라는 특수한 환경에서 사용자의 의도를 정확히 파악할 수 있다. 이러한 대화 시스템과 사용자를 연결하는 게이트 웨이는 차량 또는 차량에 연결된 모바일 기기가 될 수 있다. 후술하는 바와 같이, 대화 시스템은 차량에 마련될 수도 있고, 차량 외부의 원격 서버에 마련되어 차량 또는 차 량에 연결된 모바일 기기와의 통신을 통해 데이터를 주고 받을 수도 있다. 또한, 대화 시스템의 구성 요소 중 일부는 차량에 마련되고 일부는 원격 서버에 마련되어 대화 시스템의 동작을 차량과 원격 서버에서 부분적으로 수행하는 것도 가능하다. 도 1은 일 실시예에 따른 대화 시스템의 제어 블록도이다. 도 1을 참조하면, 일 실시예에 따른 대화 시스템은 사용자의 음성 및 음성 외 입력을 포함하는 사용자 입 력이나 차량과 관련된 정보 또는 사용자와 관련된 정보를 포함하는 입력을 처리하는 입력 처리기, 입력 처 리기의 처리 결과를 이용하여 사용자의 의도 또는 차량의 상태를 파악하고, 사용자의 의도나 차량의 상태 에 대응되는 액션을 결정하는 대화 관리기, 대화 관리기의 출력 결과에 따라 특정 서비스를 제공하거 나 대화를 계속 이어 나가기 위한 시스템 발화를 출력하는 결과 처리기 및 대화 시스템이 후술하는 동작을 수행하기 위해 필요한 각종 정보를 저장하는 저장부를 포함한다. 입력 처리기는 사용자 음성과 음성 외 입력, 두 가지 종류의 입력을 수신할 수 있다. 음성 외 입력은 사용 자의 제스처 인식이나, 입력 장치의 조작을 통해 입력되는 사용자의 음성 외 입력, 차량의 상태를 나타내는 차 량 상태 정보, 차량의 주행 환경과 관련된 주행 환경 정보, 사용자의 상태를 나타내는 사용자 정보 등을 포함할 수 있다. 이러한 정보들 외에도 차량과 사용자와 관련된 정보로서, 사용자의 의도를 파악하거나 사용자 또는 차 량에 필요한 서비스를 제공하기 위해 사용될 수 있는 정보이면, 모두 입력 처리기의 입력이 될 수 있다. 사용자는 운전자와 동승자를 모두 포함할 수 있다. 입력 처리기는 입력된 사용자 음성을 인식하여 텍스트 형태의 발화문으로 변환하고, 사용자의 발화문에 자 연어 이해(Natural Language Understanding) 알고리즘을 적용하여 사용자의 의도를 파악한다. 또한, 입력 처리기는 입력된 차량 내 탑승자의 음성 및 음성 외 입력 장치의 조작을 통해 입력되는 사용자 의 음성 외 입력을 인식하여 차량 내에 동승자가 탑승하였음을 판단할 수 있다. 이후, 대화 시스템은 탑승 이 판단된 동승자 각각의 식별을 위해 동승자의 신원 정보를 요청하는 선발화를 출력할 수 있으며, 동승자 각각 의 발화를 수신하여 동승자 각각을 식별할 수 있다. 이 때, 동승자 각각을 식별하는 것은, 탑승이 판단된 동승 자 각각을 동승자 각각의 신원 정보에 기초하여 구분하는 것을 의미할 수 있다. 또한, 입력 처리기는 사용자 음성 외에 차량의 상태나 주행 환경과 관련된 정보를 수집하고, 수집된 정보 를 이용하여 상황을 이해한다. 입력 처리기는 자연어 이해를 통해 파악한 사용자의 의도와 상황에 관련된 정보 등을 대화 관리기로 전달한다. 대화 관리기는 입력 처리기로부터 전달된 사용자의 의도, 상황에 관련된 정보 등에 기초하여 사용자 의 의도나 현재 상황에 대응되는 액션을 결정하고, 해당 액션을 수행하기 위해 필요한 인자들을 관리한다. 당해 실시예에서 액션은 특정 서비스를 제공하기 위해 수행되는 모든 동작을 의미할 수 있으며, 액션의 종류는 미리 정의될 수 있다. 경우에 따라, 서비스의 제공과 액션의 수행은 동일한 의미일 수 있다. 예를 들어, 도메인/액션 추론 규칙 DB(141, 도 22a 참조)에 길 안내, 차량 상태 점검, 주유소 추천 등과 같은 액션이 미리 정의될 수 있고, 저장된 추론 규칙에 따라 사용자의 발화에 대응되는 액션, 즉 사용자가 의도하는 액션을 미리 정의된 액션 중에서 추출할 수 있다. 또한, 차량에 발생한 이벤트와 연관된 액션이 미리 정의되어 연관 액션 DB(146b, 도 24 참조)에 저장될 수 있다. 액션의 종류에 대해서는 제한을 두지 않으며, 대화 시스템이 차량 또는 모바일 기기를 통해 수 행 가능한 것으로서, 미리 정의되고, 그 추론 규칙이나 다른 액션/이벤트와의 관계 등이 저장되어 있으면 액션 이 될 수 있다. 대화 관리기는 결정된 액션에 관한 정보를 결과 처리기로 전달한다. 결과 처리기는 전달된 액션을 수행하기 위해 필요한 대화 응답 및 명령어를 생성하여 출력한다. 대화 응답 은 텍스트, 이미지 또는 오디오로 출력될 수 있고, 명령어가 출력되면 출력된 명령어에 대응되는 차량 제어, 외 부 컨텐츠 제공 등의 서비스가 수행될 수 있다. 예를 들어, 결과 처리기는 동승자를 식별하기 위한 대화 응답, 및 명령어 등을 생성하여 출력할 수 있다. 일 실시예로, 결과 처리기는 입력 처리기을 통해 탑승이 판단된 동승자를 식별하기 위해, 동승자의 신원 정보를 묻는 내용을 선발화로 출력할 수 있다. 또한, 결과 처리기는 동승자 인원 변화 예측 결과를 위한 대화 응답, 및 명령어 등을 생성하여 출력할 수 있다. 일 실시예로, 결과 처리기는 경유지에서 동승자 각각의 하차 가능성 및 하차 후 재탑승 가능성에 관 한 내용을 선발화로 출력할 수 있다. 저장부는 대화 처리 및 서비스 제공에 필요한 각종 정보를 저장한다. 예를 들어, 자연어 이해에 사용되는 도메인, 액션, 화행, 개체명과 관련된 정보를 미리 저장할 수 있고, 입력된 정보로부터 상황을 이해하기 위해 사용되는 상황 이해 테이블을 저장할 수도 있으며, 차량에 마련된 센서가 감지한 데이터, 사용자와 관련된 정보, 액션 수행을 위해 필요한 정보를 미리 저장할 수도 있다. 예를 들어, 저장부는 차량의 주행이 종료한 경우, 차량의 주행에 관한 주행 관련 정보 및 차량이 주행하는 동안 탑승한 동승자에 대한 동승자 정보를 저장할 수도 있다. 구체적으로, 저장부는 주행의 출발지, 경유 지 및 도착지와 같은 차량의 주행에 관한 주행 관련 정보를 저장하고, 개인 식별 정보, 음성 특성 정보, 착석 위치 정보, 탑승 시각 정보, 하차 시각 정보, 탑승 장소 정보 및 하차 장소 정보 등과 같은 동승자에 대한 동승 자 정보를 저장할 수도 있다. 저장부에 저장되는 정보들에 관한 더 자세한 설명은 후술하도록 한다. 전술한 바와 같이, 대화 시스템은 차량 환경에 특화된 대화 처리 기술을 제공한다. 대화 시스템의 구 성요소가 전부 차량에 포함될 수도 있고, 일부만 포함될 수도 있다. 대화 시스템은 원격 서버에 마련되고 차량은 대화 시스템과 사용자 사이의 게이트웨이의 역할만 할 수도 있다. 어느 경우이던지, 대화 시스템 은 차량 또는 차량과 연결된 모바일 기기를 통해 사용자와 연결될 수 있다. 도 2a는 차량 내부의 구성을 나타낸 도면이고, 도 2b는 도 2a와 다른 각도에서 바라본 차량 내부의 구성을 개략 적으로 나타낸 도면이다. 도 2a를 참조하면, 차량 내부의 대시보드의 중앙 영역인 센터페시아에는 오디오 기능, 비디오 기능, 내비게이션 기능 또는 전화 걸기 기능을 포함하는 차량의 제어를 수행하기 위해 필요한 화면을 표시하는 디스플레이와 사용자의 제어 명령을 입력 받기 위한 입력 버튼이 마련될 수 있다. 또한, 운전자의 조작 편의성을 위해 스티어링 휠에도 입력 버튼이 마련될 수 있고, 운전석(254a)과 조수석(254b) 사이의 센터 콘솔 영역에 입력 버튼의 역할을 수행하는 조그 셔틀이 마련될 수도 있다. 한편, 시트가 운전석(254a)과 조수석(254b)으로 한정되는 것은 아니다. 도 2b을 참조하면, 차량에는 경 우에 따라 후열 시트(254c, 254d)가 마련될 수도 있다. 이때, 대화 시스템은 조수석(245b) 및 후열 시트(254c, 254d)에 동승자가 탑승하고, 차량 내 탑승자 간 대화가 진행되는 경우, 음성 인식을 통해 동승자의 탑승을 판단하고, 음성이 발생하는 위치를 추정하여 차량 내 동승자 의 착석 위치를 판단할 수 있다. 또한, 대화 시스템은 조수석(245b) 및 후열 시트(254c, 254d) 측에 마련된 각 종 센서를 통해 해당 시트 측에 동승자가 있음을 판단할 수 있다. 실시예에 따른 대화 시스템은 탑승이 판단된 동승자 각각의 식별을 위해 동승자의 신원 정보를 요청하는 선발화 를 출력할 수 있으며, 동승자 각각의 발화를 수신하여 동승자 각각을 식별할 수 있다. 전술한 바와 같이, 동승 자 각각을 식별하는 것은, 탑승이 판단된 동승자 각각을 동승자 각각의 신원 정보에 기초하여 구분하는 것을 의 미할 수 있다. 또한, 실시예에 따른 대화 시스템은 차량 내 동승자의 착석 위치를 포함하는 동승자에 대한 동승자 정보를 저장 할 수도 있다. 이에 관한 구체적인 설명은 후술하도록 한다. 디스플레이, 입력 버튼 및 각종 기능을 전반적으로 제어하는 프로세서를 포함하는 모듈을 AVN(Audio Video Navigation) 단말이라 할 수도 있고, 헤드유닛(Head Unit)이라 할 수도 있다. 디스플레이는 LCD(Liquid Crystal Display), LED(Light Emitting Diode), PDP(Plasma Display Panel), OLED(Organic Light Emitting Diode), CRT(Cathode Ray Tube) 등의 다양한 디스플레이 장치 중 하나로 구현될 수 있다. 입력 버튼은 도 2a에 도시된 바와 같이 디스플레이와 인접한 영역에 하드 키 타입으로 마련될 수도 있고, 디스플레이가 터치 스크린 타입으로 구현되는 경우에는 디스플레이가 입력 버튼의 기능도 함께 수행할 수 있다. 차량은 사용자의 명령을 음성 입력 장치를 통해 음성으로 입력 받을 수 있다. 음성 입력 장치는 음향을 입력 받아 전기적인 신호로 변환하여 출력하는 마이크로폰을 포함할 수 있다. 효과적인 음성의 입력을 위하여 음성 입력 장치는 도 2에 도시된 바와 같이 헤드라이닝에 마련될 수 있으나, 차량의 실시예가 이에 한정되는 것은 아니며, 대시보드 위에 마련되거나 스티어링 휠에 마련되는 것도 가능하다. 또한, 음성 입력 장치는 조수석(245b) 및 후열 시트(254c, 254d)에 착석한 동승 자의 음성의 입력을 위하여 조수석(245b) 및 후열 시트(254c, 254d) 각각에 마련될 수 있다. 이 외에도 사용자 의 음성을 입력 받기에 적합한 위치이면 어디든 제한이 없다. 차량 내부에는 사용자와 대화를 수행하거나, 사용자가 원하는 서비스를 제공하기 위해 필요한 음향을 출력 하는 스피커가 마련될 수 있다. 일 예로, 스피커는 운전석 도어(253a) 및 조수석 도어(253b) 내측에 마련될 수 있다. 스피커는 내비게이션 경로 안내를 위한 음성, 오디오/비디오 컨텐츠에 포함되는 음향 또는 음성, 사용자가 원하는 정보나 서비스를 제공하기 위한 음성, 사용자의 발화에 대한 응답으로서 생성된 시스템 발화 등을 출력 할 수 있다. 일 실시예에 따른 대화 시스템은 차량 환경에 특화된 대화 처리 기술을 이용하여 사용자의 라이프스타일에 최적화된 서비스를 제공하고, 커넥티드카(Connected Car), 사물인터넷(IoT), 인공지능(AI) 등의 기술을 이용한 새로운 서비스를 구현할 수 있다. 일 실시예에 따른 대화 시스템과 같이 차량 환경에 특화된 대화 처리 기술을 적용할 경우, 운전자의 직접 주행 상황에서, 주요 상황(Context)에 대한 인지 및 대응이 용이하다. 유량 부족, 졸음 운전 등 주행에 영향을 미치는 요소에 가중치를 부여하여 서비스를 제공할 수 있고, 대부분의 경우 목적지로 이동 중인 조건을 기반으 로 주행 시간, 목적지 정보 등 서비스 제공을 위해 필요한 정보를 용이하게 획득할 수 있다. 또한, 운전자의 의도를 파악하고, 기능을 제안하는 지능적인 서비스를 용이하게 구현할 수 있다. 이는 운전자의 직접 주행 상황에 있어 실시간 정보와 액션을 우선적으로 고려하기 때문이다. 일 예로, 주행 중에 운전자가 주 유소를 검색하면, 이는 지금 주유소에 가겠다는 운전자의 의도로 해석될 수 있다. 그러나, 차량이 아닌 환경에 서 주유소를 검색할 경우 지금 주유소를 가겠다는 의도 외에 위치 정보 조회, 전화번호 조회, 가격 조회 등 다 른 다양한 의도로도 해석되는 것이 가능하다. 또한, 차량은 한정적인 공간이지만, 그 안에 다양한 상황이 존재할 수 있다. 예를 들어, 렌터카 등 생소한 인터 페이스의 운전 상황, 대리 운전을 맡긴 상황, 세차 등 차량 관리 상황, 유아를 탑승시키는 상황, 특정 목적지를 찾아가는 상황 등에서 대화 시스템을 활용할 수 있다. 또한, 차량 점검 단계, 출발 준비 단계, 주행 단계, 주차 단계 등 차량의 주행과 그 전후를 구성하는 각각의 단 계에서도 다양한 서비스의 기회와 대화 상황들이 발생한다. 특히, 차량 문제의 대처 방안을 모르는 상황, 차량 과 각종 외부 기기 연동 상황, 연비 등 주행 습관 확인 상황, 스마트 크루즈 컨트롤(Smart Cruise Control) 등 의 안전 지원 기능 활용 상황, 내비게이션 조작 상황, 졸음 운전 상황, 매일 동일한 경로를 반복해서 주행하는 상황, 주정차가 가능한 곳인지 확인해야 하는 상황 등에서 대화 시스템을 활용할 수 있다. 도 3 내지 도 6은 대화 시스템과 운전자 사이에 주고 받을 수 있는 대화의 예시를 나타낸 도면이다. 도 3을 참조하면, 운전자가 현재 잔유량을 묻거나 주유소 안내를 요청하는 발화를 입력하지 않더라도, 대화 시 스템은 스스로 현재 잔유량을 판단하고, 판단된 잔유량이 설정된 기준값 미만인 경우에는 현재 잔유량에 대한 정보를 제공하는 발화(S1: 현재 남은 기름으로 43km 주행 가능합니다)를 먼저 출력할 수 있다. 이에 대한 응답으로, 운전자는 주유소로 경로 안내를 받기 위해 근처 주유소를 묻는 발화(U1: 근처 주유소 알려 줘)를 입력할 수 있고, 대화 시스템은 현재 위치에서 가장 가까운 주유소에 대한 정보를 제공하는 발화 (S2: 현재 위치에서 가까운 주유소로 A 오일 성림 주유소, B 오일 장대 주유소, C 오일 태평양 주유소가 있습니 다)를 출력할 수 있다. 운전자는 추가적으로 기름 가격에 대한 정보를 요청하기 위한 발화(U2: 그 중 가장 싼 곳은 어디야?)를 입력할 수 있고, 대화 시스템은 유종 별 가격에 대한 정보 제공하는 발화(S3: 휘발유 가격이 가장 낮은 곳은 B 오 일 장대 주유소로 리터당 1,294원이고, 경유 가격이 가장 낮은 곳은 A 오일 성림 주유소로 리터당 985원입니 다)를 출력할 수 있다. 운전자는 B 오일 장대 주유소로 안내해 달라는 발화(U3)를 입력할 수 있고, 대화 시스템은 운전자가 선택 한 주유소로 안내를 시작한다는 발화 (S4: B 오일 장대 주유소로 안내를 시작합니다)를 출력할 수 있다. 즉, 대화 시스템이 입력 처리기를 통해 수신한 차량의 상태 정보에 기초하여 현재 필요한 서비스가 주유소 안내 서비스임을 판단하고, 이를 제공하기 위한 선발화를 출력할 수 있다. 또한, 운전자는 대화 시스템 과의 대화를 통하여 현재 차량의 유종을 가장 싼 가격에 판매하는 근처의 주유소로 경로 안내를 받을 수 있게 된다. 당해 실시예에서는 사용자가 발화하기 전에 대화 시스템이 먼저 출력하는 발화를 선발화라 하 기로 한다. 한편, 대화 시스템은 전술한 도 3의 예시에서 주유소를 선택함에 있어, 일부 질의를 생략하고 바로 정보를 제공함으로써 대화의 단계와 시간을 단축하는 것도 가능하다. 예를 들어, 대화 시스템은 현재 차량의 유종이 휘발유이고 운전자의 주유소 선택 기준이 가격이라는 정보 를 미리 알 수 있다. 차량의 유종에 대한 정보는 차량으로부터 획득할 수 있고, 운전자의 주유소 선택 기준은 운전자에게 미리 입력 받거나 운전자의 대화 이력 또는 주유소 선택 이력을 학습하여 획득할 수 있다. 이러한 정보는 대화 시스템의 저장부에 미리 저장될 수 있다. 이 경우, 도 4에 도시된 바와 같이, 운전자가 기름 가격에 대한 정보를 요청하기 위한 발화(U2)를 입력하지 않 더라도(U3 생략) 대화 시스템이 기름 가격에 대한 정보, 특히 현재 차량의 유종인 휘발유의 가격에 대한 정보를 제공하는 발화(S2+S3=S3’)을 선제적으로 출력할 수 있다. 운전자는 기름 가격에 대한 정보를 요청하기 위한 발화(U2)를 생략할 수 있고, 대화 시스템의 응답은 근처 주유소 안내를 위한 발화(S2)와 기름 가격 안내를 위한 발화(S3)가 하나로 합쳐짐으로써 대화 단계와 시간을 단 축할 수 있다. 또한, 대화 시스템은 운전자가 현재 잔유량을 물었다는 사실에 기초하여 운전자의 의도가 주유소 검색이라 는 점을 스스로 파악할 수도 있다. 이 경우, 도 5에 도시된 바와 같이, 운전자가 근처 주유소를 묻는 발화(U1)를 입력하지 않더라도(U1 생략), 대 화 시스템이 기름 가격에 대한 정보를 제공하는 발화(S2+S3=S3”)를 선제적으로 출력할 수 있다. 또한, 기름 가격에 대한 정보를 제공하는 발화(S3”)에 현재 위치에서 가장 가까우면서 기름 가격이 가장 싼 주 유소가 하나인 경우에는 해당 주유소로 안내할 지 여부까지 함께 질의할 수 있다. 따라서, 사용자는 어느 주유 소로 안내해달라는 구체적인 발화를 입력하지 않고, 단순히 대화 시스템의 질의에 동의하는 발화(U3’: 그래)를 입력함으로써 해당 주유소로의 길 안내를 요청할 수 있다. 이와 같이, 대화 시스템은 미리 획득한 정보를 이용하여 사용자가 발화하지 않은 내용까지 고려함으로써, 사용자의 실제 의도를 파악하고 그에 대응되는 정보를 선제적으로 제공할 수 있다. 이를 통해 사용자가 원하는 서비스를 제공하기까지의 대화 단계와 시간을 단축할 수 있다. 도 6을 참조하면, 대화 시스템은 차량 내 탑승자 간 대화 및 차량 조작 정보에 기초하여 동승자가 탑승한 것을 판단한 경우, 동승자의 신원 정보를 요청하는 발화(S11: 누구세요? 이름을 말씀해 주세요)를 먼저 출력할 수 있다. 이에 대한 응답으로, 동승자는 자신의 신원 정보를 포함하는 발화(U11: 나는 OO이야)를 입력할 수 있고, 대화 시스템은 동승자의 발화를 통해 동승자의 신원을 식별할 수 있다. 즉, 대화 시스템이 입력 처리기를 통해 수신한 차량 내 탑승자 간 대화 및 차량 조작 정보에 기초하 여 차량에 탑승한 동승자의 탑승을 판단하고, 동승자의 신원을 식별하기 위한 선발화를 출력할 수 있다. 또한, 동승자는 대화 시스템과의 대화를 통하여 신원 정보를 대화 시스템에 제공할 수 있다. 도 7 및 도 8은 동승자 인원 변화를 예측하고 선발화를 출력하는 대화 시스템의 예시를 나타낸 도면이다. 도 7을 참조하면, 차량 내 대화 시스템은 동승자의 신원을 식별한 이후에 차량 내 탑승자 간 대화에 기초하여 동승자 인원 변화를 예측하고, 동승자 인원 변화 예측 결과를 나타내는 선발화를 출력할 수 있다. 구체적으로, 차량 내 대화 시스템은 차량 내 탑승자 간 대화에 자연어 이해 알고리즘을 적용하여 동 승자 각각의 경유지에서의 하차 가능성 및 하차 후 재탑승 가능성을 판단할 수 있다. 또한, 차량 내 대화 시스템은 차량 내 통화 내용에 자연어 이해 알고리즘을 적용하여 탑승예정자의 경유지에서의 탑 승 가능성을 판단할 수 있다. 이에 관한 구체적인 설명은 후술하도록 한다. 차량 내 대화 시스템은 경유지 도착 전, 동승자 각각의 하차 가능성 및 하차 후 재탑승 가능성 및 탑승예정자의 탑승 가능성에 기초하여 \"A는 경유지에서 하차합니다. B는 경유지에서 하차 후 재탑승합니다. C는 경유지에서 하차하지 않습니다. D는 경유지에서 탑승합니다\"와 같이 동승자 인원 변화 예측 결과에 관한 선 발화를 출력할 수 있다. 도 8을 참조하면, 차량 내 대화 시스템은 경유지 출발 후, 경유지 도착 전 예측된 동승자 인원 변화 예측 결과와 경유지 출발 후 동승자 인원 변화 결과의 비교 결과에 관한 선발화를 출력할 수 있 다. 구체적으로, 차량 내 대화 시스템은 경유지 출발 후, 경유지 도착 전 획득된 동승자 인원 변화 예측 결과와 경유지 출발 후 동승자 인원 변화 결과를 비교할 수 있다. 경유지 도착 전 예측된 동승자 인원 변화 예측 결과와 경유지 출발 후 동승자 인원 변화 결과의 비교 는 경유지 출발 후, 차량 내 탑승자 간 대화 및 차량 조작 정보에 기초하여 경유지 출발 후 차량 내 동승자의 탑승 여부를 판단함으로써 수행될 수 있다. 또한, 차량 내 대화 시스템은 경유지 출발 후 동승자 인원 변화 결과를 확인하기 위해, 동승자 인원 변화 예측 결과가 맞는지 확인하는 내용의 선발화를 출력할 수 있다. 차량 내 대화 시스템은 동승자 인원 변화 예측 결과가 맞는지 확인하는 내용의 선발화에 대한 차량 내 탑승자의 발화를 통해 탑 경유지 도착 전 예측된 동승자 인원 변화 예측 결과와 경유지 출발 후 동승자 인원 변화 결과를 비교할 수 있다. 차량 내 대화 시스템은 경유지 출발 후, 경유지 도착 전 예측된 동승자 인원 변화 예측 결 과와 경유지 출발 후 동승자 인원 변화 결과의 비교에 기초하여, \"현재 동승자는 동승자 인원 변화 예측 결과와 상이합니다\"와 같이 비교 결과에 관한 선발화를 출력할 수 있다. 도 9 및 도 10은 대화 시스템과 차량의 구성 요소들 사이의 연결 관계를 간략하게 나타낸 제어 블록도이다. 도 9를 참조하면, 대화 시스템에 입력되는 사용자의 음성은 차량에 마련된 음성 입력 장치를 통 해 입력될 수 있다. 앞서 도 2에서 설명한 바와 같이, 음성 입력 장치는 차량 내부에 마련된 마이크 로폰을 포함할 수 있다. 사용자 입력 중 음성을 제외한 입력은 음성 외 입력 장치를 통해 입력될 수 있다. 음성 외 입력 장치(22 0)는 사용자의 조작을 통해 명령을 입력 받는 입력 버튼(221, 223)과 조그 셔틀을 포함할 수 있다. 또한, 음성 외 입력 장치는 사용자를 촬영하는 카메라를 포함하는 것도 가능하다. 카메라로 촬영한 영상을 통해, 명령 입력의 일 수단으로 사용되는 사용자의 제스처, 표정 또는 시선 방향을 인식할 수 있다. 또는, 카메 라로 촬영한 영상을 통해 사용자의 상태(졸음 상태 등)를 파악하는 것도 가능하다. 또한, 음성 외 입력 장치는 동승자의 차량 내 탑승 및 착석 위치를 판단하기 위해 조수석(245b) 및 후열 시트(254c, 254d) 측에 마련된 윈도우 조정 버튼, 시트 조정 버튼, 공조 장치 조정 버튼 등을 포함할 수 있다. 차량에 관한 정보는 차량 제어기를 통해 대화 시스템에 입력될 수 있다. 차량에 관한 정보는 차량 에 마련된 각종 센서를 통해 획득된 차량 상태 정보 또는 주변 상황 정보를 포함할 수 있고, 차량의 유종 과 같이 차량에 기본적으로 저장된 정보도 포함할 수 있다. 대화 시스템은 음성 입력 장치를 통해 입력된 사용자 음성, 음성 외 입력 장치를 통해 입력된 사용자의 음성 외 입력, 차량 제어기를 통해 입력된 각종 정보를 이용하여 사용자의 의도와 상황을 파악하 고, 사용자의 의도에 대응되는 액션을 수행하기 위한 응답을 출력한다. 대화자 출력 장치는 대화자에게 시각적, 청각적 또는 촉각적인 출력을 제공하는 장치로서, 차량에 마 련된 디스플레이 및 스피커를 포함할 수 있다. 디스플레이 및 스피커는 사용자의 발화에 대한 응답, 사용자에 대한 질의, 또는 사용자가 요청한 정보를 시각적 또는 청각적으로 출력할 수 있다. 또는, 스티어링 휠에 진동기를 장착하여 진동을 출력하는 것도 가능하다. 또한, 차량 제어기는 대화 시스템으로부터 출력되는 응답에 따라, 사용자의 의도나 현재 상황에 대응 되는 액션을 수행하기 위해 차량을 제어할 수 있다. 한편, 차량은 차량에 마련된 센서를 통해 획득된 데이터뿐만 아니라, 통신 장치를 통해 외부 컨 텐츠 서버 또는 외부 기기로부터 획득된 정보, 예를 들어 교통 상황, 날씨, 온도, 동승자 정보, 운전자 개 인 정보 등의 주행 환경 정보와 사용자 정보도 수집하여 대화 시스템에 전달할 수 있다. 도 10에 도시된 바와 같이, 잔유량, 강우량, 강우 속도, 주변 장애물 정보, 속도, 엔진 온도, 타이어 공기압, 현재 위치 등과 같이 차량에 마련된 센서로부터 획득되는 정보는 내부 신호 제어기를 통해 대화 시스템 에 입력될 수 있다. 이외에도, 윈도우 조정 버튼 조작 정보, 시트 조정 버튼 조작 정보, 공조 장치 조정 버튼 조작 정보 등과 같이 차량에 마련된 센서로부터 획득되는 정보 또한 내부 신호 제어기를 통해 대화 시스템에 입력될 수 있 는 등 제한은 없다. V2X(Vehicle to Everything)를 통해 외부에서 획득된 주행 환경 정보는 외부 신호 제어기를 통해 대화 시 스템에 입력될 수 있다. V2X는 차량이 주행하면서 도로 인프라 및 다른 차량과 상호 통신하면서 교통 상황 등 각종 유용한 정보를 교환 및 공유하는 것을 의미한다. V2X 통신은 차량과 인프라 간(V2I: Vehicle-to-Infrastructure, 이하 V2I) 통신, 차량 간(V2V: Vehicle to- Vehicle) 통신, 차량과 모바일 기기 간(V2N: Vehicle-to-Nomadic devices) 통신을 포함할 수 있다. 따라서, V2X 통신을 이용하면, 차량끼리 직접 통신하거나, 또는 거리에 설치되어 있는 인프라와 통신하여 전방의 교통 정보, 다른 차량의 접근 또는 추돌 가능성 등의 정보를 주고 받아 운전자에게 알려줄 수 있다. 따라서, 외부 신호 제어기를 통해 대화 시스템에 입력되는 주행 환경 정보는 전방의 교통 정보, 주변 차량의 접근 정보, 다른 차량과의 추돌 경고, 실시간 교통 상황, 돌방 상황, 교통흐름 제어 상태 등을 포함할 수 있다. 도면에 도시되어 있지는 않으나, V2X 를 통해 획득하는 신호 역시 통신 장치를 통해 차량에 입력될 수 있다. 차량 제어기는 전술한 동작과 후술하는 동작을 수행하기 위한 프로그램이 저장되는 메모리 및 저장된 프로 그램을 실행시키는 프로세서를 포함할 수 있다. 메모리와 프로세서는 각각 적어도 하나 마련될 수 있고, 복수 개 마련되는 경우에는 이들이 하나의 칩 상에 집적될 수도 있고 물리적으로 분리될 수도 있다. 또한, 내부 신호 제어기와 외부 신호 제어기는 동일한 프로세서 및 메모리에 의해 구현될 수도 있고, 별도의 프로세서 및 메모리에 의해 구현될 수도 있다. 도 11 및 도 12는 대화 시스템의 구성 요소와 차량의 구성 요소들 사이의 연결 관계를 간략하게 나타낸 제어 블 록도이다. 도 11을 참조하면, 음성 입력 장치로부터 전송된 사용자 음성은 입력 처리기 내의 음성 입력 처리기 로 입력되고, 음성 외 입력 장치로부터 전송된 사용자의 음성 외 입력은 입력 처리기 내의 상황 정보 처리기로 입력된다. 또한, 내부 신호 제어기를 통해 입력된 정보 및 외부 신호 제어기를 통해 입력된 정보는 입력 처리기 내의 상황 정보 처리기로 입력된다. 상황 정보 처리기에 입력되는 상황 정보는 음성 외 입력 장치 및 차량 제어기로부터 입력된 차 량 상태 정보, 주행 환경 정보, 사용자 정보 등을 포함한다. 상황 정보 처리기는 입력된 상황 정보에 기초 하여 상황을 이해한다. 대화 시스템은 이러한 상황 이해를 통해 사용자의 의도를 더 정확히 파악하거나 현 재 사용자에게 필요한 서비스를 효과적으로 찾을 수 있다. 예를 들어, 음성 입력 처리기는 음성입력장치를 통해 인식한 차량 내 탑승자 간의 대화에 기초하여 동승자의 탑승을 판단할 수 있다. 또한, 음성 입력 처리기는 음성입력장치를 통해 인식한 차량 내 탑 승자 간의 대화에 기초하여 경유지에서의 동승자 각각의 하차 가능성 및 하차 후 재탑승 가능성을 판단할 수 있 다. 또한, 음성 입력 처리기는 음성입력장치를 통해 인식한 차량 내 통화 내용에 기초하여 차량에 탑 승할 탑승예정자를 예측할 수 있다. 또한, 상황 정보 처리기는 음성 외 입력장치 조작을 인식하고, 인식된 결과에 기초하여 동승자의 탑승 여부를 판단할 수 있다. 결과 처리기로부터 출력되는 응답은 대화자 출력 장치 또는 차량 제어기에 입력되어 차량 으로 하여금 사용자에게 필요한 서비스를 제공할 수 있게 한다. 또는, 외부 컨텐츠 서버에 전송되어 필요 한 서비스를 요청할 수 있다. 차량 제어기로부터 전송되는 차량 상태 정보, 주행 환경 정보, 사용자 정보 등은 저장부에 저장된다. 도 12를 참조하면, 저장부는 장기 메모리와 단기 메모리를 포함할 수 있다. 저장부에 저장 되는 데이터는 데이터의 중요성과 영속성 및 설계자의 의도에 따라 단기, 장기 메모리로 구분되어 저장될 수 있 다. 단기 메모리는 이전에 수행한 대화를 저장할 수 있다. 이전에 수행한 대화는 현재 시점으로부터 기준 시간 이내에 수행한 대화일 수 있다. 또는, 사용자와 대화 시스템 사이의 발화 내용의 용량이 기준치가 될 때까 지 계속 대화가 저장될 수도 있다. 일 예로, 현재 시간이 식사 시간인 경우, 차량은 스피커를 통해 식당으로 안내할지 여부를 묻는 발화 를 출력할 수 있다. 식사 시간인지 여부는 현재 시간이 식사 시간으로 미리 설정된 시간 범위에 포함하는지 여 부에 기초하여 판단할 수 있다. 사용자가 “강남역 근처 식당 알려줘”라고 발화하거나, 사용자가 “식당 알려 줘”라고 발화하고 차량의 현재 위치가 강남역 근처인 경우, 대화 시스템은 외부 컨텐츠 서버를 통해 강남역 근처의 식당을 검색하고, 검색된 강남역 근처의 식당에 관한 정보를 사용자에게 제공한다. 정보 제 공의 일 예로, 디스플레이에 식당 목록을 표시할 수 있고, 사용자가 “첫 번째”라고 발화하면, 단기 메모 리에 식당에 대한 문의부터 선택까지의 대화 내용이 저장될 수 있다. 또는, 대화 내용 전체가 저장되는 것뿐만 아니라, 대화 내용에 포함된 특정 정보를 저장하는 것도 가능하다. 예 를 들어, 단기 메모리 또는 장기 메모리에 식당 목록 중 첫 번째의 식당을 사용자가 선택한 식당으로 저장하는 것도 가능하다. 강남역 근처의 식당에 대한 대화 뒤에 사용자가 대화 시스템에 “날씨는?”이라고 질문하면, 대화 시스템 은 단기 메모리에 저장된 대화로부터 사용자의 관심 위치가 강남역인 것을 추정하여 사용자에게 “강 남역에는 비가 오고 있습니다.”라는 응답을 출력할 수 있다. 이후에, 사용자가 “그 식당 메뉴 좀 추천해줘.”라고 발화하면, 대화 시스템은 단기 메모리에 저장된 대 화로부터 “그 식당”이 강남역 근처 식당인 것으로 추정하고, 외부 컨텐츠 서버로부터 제공되는 서비스를 통해 해당 식당의 추천 메뉴에 대한 정보를 획득하고, “그 식당은 칼국수가 맛있습니다.”와 같은 응답을 출력 할 수 있다. 장기 메모리는 데이터의 영속성 유무에 따라 데이터를 저장할 수 있다. 예를 들어, 가족이나 친구의 전화 번호, 집이나 회사와 같은 POI 정보, 특정 인자에 대한 사용자의 선호도 등은 데이터의 영속성이 보장되는 것으로 판단하고, 장기 메모리에 저장할 수 있다. 반면, 데이터의 영속성이 보장되지 않는 것으로 판단되는 데 이터는 단기 메모리에 저장될 수 있다. 일 예로, 장기 메모리는 차량의 주행이 종료한 경우, 차량의 주행에 관한 주행 관련 정보 및 차량이 주행 하는 동안 탑승한 동승자에 대한 동승자 정보를 저장할 수도 있다. 구체적으로, 장기 메모리는 주행의 출 발지, 경유지 및 도착지와 같은 차량의 주행에 관한 주행 관련 정보를 저장하고, 개인 식별 정보, 음성 특성 정 보, 착석 위치 정보, 탑승 시각 정보, 하차 시각 정보, 탑승 장소 정보 및 하차 장소 정보 등과 같은 동승자에 대한 동승자 정보를 저장할 수 있다. 일 예로, 사용자의 현재 위치는 일시적인 데이터이므로 단기 메모리에 저장될 수 있고, 식당에 대한 사용 자의 선호도는 이후에도 사용 가능한 영속적인 데이터로 볼 수 있으므로 장기 메모리에 저장될 수 있다. 사용자가 “근처에 식당 없나?”라고 발화하면, 대화 시스템은 단기 메모리로부터 사용자의 현재 위 치를 파악하고 장기 메모리로부터 사용자가 선호하는 식당이 중식당이라는 것을 파악할 수 있다. 따라서, 외부 컨텐츠를 이용하여 현재 위치 주변에서 사용자가 선호하는 중식당 목록을 추천해 줄 수 있다. 또한, 대화 시스템은 장기 메모리와 단기 메모리에 저장된 데이터를 이용하여 사용자에게 선제 적으로 서비스나 정보를 제공해줄 수 있다. 예를 들어, 장기 메모리에 사용자의 집에 대한 정보가 저장될 수 있다. 대화 시스템은 외부 컨텐츠 서버로부터 사용자의 집과 관련된 정보를 획득하여, 사용자에게 “이번 주 금요일 아파트 단지 청소로 단 수 예정입니다.”라는 정보를 제공해줄 수 있다. 또한, 대화 시스템은 차량의 다음 주행에서 이전 주행에 탑승한 동승자와 동일한 동승자가 탑승한 경우 저 장된 동승자 정보 및 차량 내 탑승자 간의 대화에 기초하여 동승자 각각의 하차 가능성 및 하차 후 재탑승 가능 성을 예측할 수 있다. 또는, 단기 메모리에 차량의 배터리 상태에 대한 정보가 저장될 수 있다. 대화 시스템은 단기 메모리 에 저장된 차량의 배터리 상태를 분석하여 “차량의 배터리 상태가 좋지 않습니다. 겨울이 되기 전에 수 리를 받으세요.”라는 정보를 제공해 줄 수 있다. 도 13은 대화 시스템이 차량에 마련되는 차량 단독 방식에 대한 제어 블록도이다. 차량 단독 방식에서는 도 13에 도시된 바와 같이, 입력 처리기, 대화 관리기, 결과 처리기 및 저장부를 포함하는 대화 시스템이 차량에 포함될 수 있다. 대화 시스템이 차량에 포함되면, 차량이 자체적으로 사용자와의 대화를 처리하고 사용자에게 필 요한 서비스를 제공해줄 수 있다. 다만, 대화 처리 및 서비스 제공을 위해 필요한 정보는 외부 컨텐츠 서버 로부터 가져올 수 있다. 차량 감지부가 감지한 잔유량, 강우량, 강우 속도, 주변 장애물 정보, 타이어 공기압, 현재 위치, 엔진 온 도, 차량 속도 등과 같은 차량 상태 정보 또는 주행 환경 정보는 차량 제어기를 통해 대화 시스템에 입력된다. 또한, 차량 제어기는 대화 시스템이 출력한 응답에 따라 차량에 마련된 공조 장치, 윈도우 , 도어, 시트 또는 AVN 등을 제어할 수 있다. 예를 들어, 대화 시스템이 사용자의 의도 또는 사용자에게 필요한 서비스가 차량 내부의 온도를 낮추 는 것이라고 판단하고, 이에 대응되는 명령어를 생성하여 출력하면, 차량 제어기가 공조 장치를 제어 하여 차량 내부의 온도를 낮출 수 있다. 다른 예로, 대화 시스템이 사용자의 의도 또는 사용자에게 필요한 서비스가 운전석 윈도우(252a)를 올리는 것이라고 판단하고, 이에 대응되는 명령어를 생성하여 출력하면, 차량 제어기가 윈도우를 제어하여 운전석 윈도우(252a)를 올릴 수 있다. 또 다른 예로, 대화 시스템이 사용자의 의도에 대응되는 서비스 또는 사용자에게 필요한 서비스가 특정 목 적지로의 경로 안내라고 판단하고, 이에 대응되는 명령어를 생성하여 출력하면, 차량 제어기가 AVN을 제어하여 경로 안내를 수행할 수 있다. 필요한 경우, 통신 장치가 외부 컨텐츠 서버로부터 지도 데이 터, POI 정보 등을 가져와 서비스 제공에 이용할 수 있다. 도 14 및 도 15는 대화 시스템이 원격 서버에 마련되고 차량이 사용자와 대화 시스템을 연결하는 게이트웨이의 역할만 하는 차량 게이트웨이 방식에 대한 제어 블록도이다. 차량 게이트웨이 방식에서는 도 14에 도시된 바와 같이, 차량 외부에 원격 대화 시스템 서버가 마련되 고, 차량에는 원격 대화 시스템 서버와 통신 장치를 통해 연결되는 대화 시스템 클라이언트 가 마련된다. 통신 장치가 차량과 원격 대화 시스템 서버를 연결하는 게이트웨이의 역할을 수행한 다. 대화 시스템 클라이언트는 입출력 장치와 연결된 인터페이스로써 기능하며, 데이터 수집과 송수신을 수행 할 수 있다. 차량에 마련된 음성 입력 장치와 음성 외 입력 장치가 사용자 입력을 수신하고 대화 시스템 클 라이언트에 전달하면, 대화 시스템 클라이언트가 통신 장치를 통해 원격 대화 시스템 서버로 입력 데이터를 전송할 수 있다. 차량 제어기 역시 차량 감지부에서 감지한 데이터를 대화 시스템 클라이언트에 전달할 수 있고, 대화 시스템 클라이언트가 통신 장치를 통해 원격 대화 시스템 서버로 차량 감지부에서 감지 한 데이터를 전송할 수 있다. 원격 대화 시스템 서버에는 전술한 대화 시스템이 마련되어 입력 데이터의 처리, 입력 데이터의 처리 결과를 바탕으로 한 대화 처리 및 대화 처리 결과에 기초한 결과 처리를 모두 수행할 수 있다. 또한, 원격 대화 시스템 서버는 입력 데이터의 처리, 대화 관리 또는 결과 처리에 있어 필요한 정보나 컨텐 츠를 외부 컨텐츠 서버로부터 가져올 수 있다. 차량 역시 원격 대화 시스템 서버로부터 전송되는 응답에 따라 사용자에게 필요한 서비스를 제공하기 위해 필요한 컨텐츠를 외부 컨텐츠 서버로부터 가져올 수 있다. 도 15를 참조하면, 통신 장치는 외부 장치와 통신을 가능하게 하는 하나 이상의 통신 모듈을 포함할 수 있 으며, 예를 들어 근거리 통신 모듈, 유선 통신 모듈 및 무선 통신 모듈를 포함할 수 있다. 근거리 통신 모듈은 블루투스 모듈, 적외선 통신 모듈, RFID(Radio Frequency Identification) 통신 모듈, WLAN(Wireless Local Access Network) 통신 모듈, NFC 통신 모듈, 직비(Zigbee) 통신 모듈 등 근거리에 서 무선 통신망을 이용하여 신호를 송수신하는 다양한 근거리 통신 모듈 중 적어도 하나를 포함할 수 있다. 유선 통신 모듈은 지역 통신(Local Area Network; LAN) 모듈, 광역 통신(Wide Area Network; WAN) 모듈 또는 부가가치 통신(Value Added Network; VAN) 모듈 등 다양한 유선 통신 모듈뿐만 아니라, USB(Universal Serial Bus), HDMI(High Definition Multimedia Interface), DVI(Digital Visual Interface), RS- 232(recommended standard232), 전력선 통신, 또는 POTS(plain old telephone service) 등 다양한 케이블 통신 모듈 중 적어도 하나를 포함할 수 있다. 무선 통신 모듈은 와이파이(Wifi) 모듈, 와이브로(Wireless broadband) 모듈 외에도, GSM(Global System for Mobile Communication), CDMA(Code Division Multiple Access), WCDMA(Wideband Code Division Multiple Access), UMTS(Universal Mobile Telecommunications System), TDMA(Time Division Multiple Access), LTE(Long Term Evolution), 4G, 5G 등 무선 통신 방식으로 인터넷망과 연결될 수 있는 다양한 무선 통신 모듈 중 적어도 하나를 포함할 수 있다. 한편, 통신 장치는 차량 내부의 전자 장치들 사이의 통신을 위한 내부 통신 모듈(미도시)을 더 포함 할 수도 있다. 차량의 내부 통신 프로토콜로는 CAN(Controller Area Network), LIN(Local Interconnection Network), 플렉스레이(FlexRay), 이더넷(Ethernet) 등을 사용할 수 있다. 대화 시스템은 무선 통신 모듈을 이용하여 외부 컨텐츠 서버 또는 원격 대화 시스템 서버와 데이터를 주고 받을 수 있다. 또한, 무선 통신 모듈을 이용하여V2X 통신을 수행할 수 있다. 또한, 근거리 통신 모듈 또는 유선 통신 모듈을 이용하여 차량에 연결되는 모바일 기기와 데이터를 주고 받을 수 있다. 도 16은 차량 게이트웨이 방식에서 차량이 입력 처리와 출력 처리를 일부 수행할 수 있는 경우에 대한 제어 블 록도이다.전술한 바와 같이, 차량의 대화 시스템 클라이언트가 데이터의 수집 및 송수신의 기능만 수행하는 것 도 가능하나, 도 16에 도시된 바와 같이, 대화 시스템 클라이언트에 입력 처리기, 결과 처리기 및 저장부가 포함되어, 사용자나 차량으로부터 입력되는 데이터의 처리나 사용자에게 필요한 것으로 판단 된 서비스 제공과 관련된 처리를 차량에서도 수행하는 것이 가능하다. 즉, 입력 처리기와 결과 처리 기의 동작을 원격 대화 시스템 서버뿐만 아니라 차량에서도 수행할 수 있다. 이 경우, 전술한 입력 처리기의 동작을 대화 시스템 클라이언트가 일부만 수행하는 것도 가능하고 전 부 수행하는 것도 가능하다. 또한, 전술한 결과 처리기의 동작을 대화 시스템 클라이언트가 일부만 수행하는 것도 가능하고 전부 수행하는 것도 가능하다. 처리해야 할 데이터의 용량 및 데이터 처리 속도 등을 고려하여 원격 대화 시스템 서버와 대화 시스템 클라 이언트 사이의 태스크 분담을 결정할 수 있다. 도 17은 원격 대화 시스템 서버와 차량이 모두 대화 처리를 수행할 수 있는 하이브리드 방식에 대한 제어 블록 도이다. 하이브리드 방식에서는 도 17에 도시된 바와 같이, 원격 대화 시스템 서버에도 입력 처리기, 대화 관리 기, 결과 처리기 및 저장부가 마련되어 대화 처리를 수행할 수 있고, 차량에도 입력 처리 기, 대화 관리기, 결과 처리기 및 저장부를 포함하는 단말 대화 시스템이 마련되어 대화 처리를 수행할 수 있다. 다만, 차량에 마련된 프로세서나 메모리는 원격 대화 시스템 서버에 마련된 프로세서나 메모리와 용량 이나 성능 측면에서 차이가 있을 수 있다. 따라서, 단말 대화 시스템에서 모든 입력 데이터를 처리하고 대 화를 관리하여 결과를 출력할 수 있는 경우에는 단말 대화 시스템에서 전 과정을 수행하고, 그렇지 않은 경우에는 원격 대화 시스템 서버에 처리를 요청할 수 있다. 단말 대화 시스템에서 대화 처리를 수행하기 전에, 입력 데이터의 종류에 기초하여 단말 대화 시스템(29 0)의 처리 가부를 판단하고, 판단 결과에 따라 직접 처리하거나 원격 대화 시스템 서버에 처리를 요청할 수 있다. 또는, 단말 대화 시스템이 대화 처리를 수행하다가 처리가 불가능한 상황이 발생하였을 때, 원격 대화 시 스템 서버에 처리를 요청하면서 자신이 처리한 결과를 함께 전송하는 것도 가능하다. 예를 들어, 고성능의 컴퓨팅 파워, 장기간 데이터의 처리가 필요한 경우는 원격 대화 시스템 서버에서 처리 하고, 실시간으로 처리해야 하는 것은 단말 대화 시스템에서 처리할 수 있다. 예를 들어, 즉시 처리가 필 요한 인스턴스가 발생하여 동기화 이전 데이터를 처리해야 하는 경우에는 단말 대화 시스템에서 우선적으 로 처리되도록 설정할 수 있다. 또한, 차량 내 미등록 발화자가 있어 사용자 확인이 필요한 경우에는 원격 대화 시스템 서버에서 대화를 처 리하도록 할 수 있다. 즉, 차량 내 신규 동승자가 있어 동승자 식별이 필요한 경우에는 원격 대화 시스템 서버 에서 대화를 처리하도록 할 수 있다. 또한, 통신 장치를 통해 원격 대화 시스템 서버와 연결이 불가능한 상황에서 단말 대화 시스템이 자체적으로 대화 처리를 완료할 수 없는 경우에는, 대화자 출력 장치를 통해 사용자에게 대화 처리가 수행 될 수 없음을 안내할 수 있다. 단말 대화 시스템에 저장되는 데이터와 원격 대화 시스템 서버에 저장되는 데이터는 데이터의 용량이나 데이터의 종류와 같은 기준에 따라 결정될 수 있다. 예를 들어, 개인 식별이 가능하여 프라이버시 침해 우려가 있는 데이터의 경우에는 단말 대화 시스템의 저장부에 저장할 수 있다. 또한, 대용량의 데이터는 원 격 대화 시스템 서버의 저장부에 저장하고, 소용량의 데이터는 단말 대화 시스템의 저장부에 저장할 수 있다. 또는, 소용량의 데이터가 원격 대화 시스템 서버의 저장부와 단말 대화 시스템의 저장부 양쪽에 모두 저장되는 것도 가능하다. 도 18및 도 19는 차량에 연결된 모바일 기기가 사용자와 원격 대화 시스템 서버를 연결하는 모바일 게이트웨이 방식에 대한 제어 블록도이다. 모바일 게이트웨이 방식에서는 도 18에 도시된 바와 같이, 모바일 기기가 차량으로부터 차량 상태 정 보, 주행 환경 정보 등을 수신하고, 사용자 입력과 차량 상태 정보를 원격 대화 시스템 서버로 전송한다.즉, 모바일 기기가 사용자와 원격 대화 시스템 서버 또는 차량와 원격 대화 시스템 서버를 연 결하는 게이트웨이의 역할을 수행한다. 모바일 기기는 스마트 폰, 스마트 워치, 스마트 글래스, PDA, 태플릿 PC 등과 같이 휴대가 가능하며 외부 서버 및 차량과 통신하여 데이터를 주고 받을 수 있는 전자 기기일 수 있다. 모바일 기기는 사용자 음성을 입력 받는 음성 입력 장치, 사용자의 음성 외 입력을 수신하는 음성 외 입력 장치, 시각적, 청각적 또는 촉각적으로 응답을 출력하는 출력 장치, 원격 대화 시스템 서버 및 차량과 통신하여 데이터를 송수신하는 통신 장치 및 차량과 사용자로부터 입력 데이터를 수 집하여 통신 장치를 통해 원격 대화 시스템 서버로 전송하는 대화 시스템 클라이언트를 포함한다. 음성 입력 장치는 음향을 입력 받아 전기적인 신호로 변환하여 출력하는 마이크로폰을 포함할 수 있다. 음성 외 입력 장치는 모바일 기기에 마련된 입력 버튼, 터치 스크린 또는 카메라를 포함할 수 있다. 출력 장치는 모바일 기기에 마련된 디스플레이, 스피커 또는 진동기를 포함할 수 있다. 사용자에 대한 입출력 인터페이스로 모바일 기기에 마련된 음성 입력 장치, 음성 외 입력 장치 및 출력 장치를 이용하는 것뿐만 아니라, 차량에 마련된 음성 입력 장치, 음성 외 입력 장치 및 대화자 출력 장치를 이용하는 것도 가능하다. 차량이 차량 감지부가 감지한 데이터와 사용자 입력을 모바일 기기에 전달하면, 모바일 기기 의 대화 시스템 클라이언트가 이를 원격 대화 시스템 서버로 전송한다. 또한, 대화 시스템 클라이언트는 원격 대화 시스템 서버로부터 전송되는 응답이나 명령어를 차량 에 전달할 수 있다. 사용자에 대한 입출력 인터페이스로 차량에 마련된 대화자 출력 장치를 이용하는 경우에는, 대화자 출력 장치를 통해 대화 시스템의 발화를 출력하거나, 사용자의 발화에 대한 응답을 출력할 수 있다. 모바일 기기에 마련된 출력 장치를 이용하는 경우에는, 모바일 기기의 출력 장 치를 통해 대화 시스템의 발화를 출력하거나, 사용자의 발화에 대한 응답을 출력할 수 있다. 차량 제어를 위한 명령어는 차량에 전달되고, 차량 제어기는 전달된 명령어에 대응되는 제어를 수행 하여 사용자에게 필요한 서비스를 제공할 수 있다. 한편, 대화 시스템 클라이언트는 입력 데이터를 수집하여 원격 대화 시스템 서버로 전달하는 것뿐만 아 니라, 대화 시스템의 입력 처리기 및 결과 처리기의 기능을 일부 또는 전부 수행하는 것도 가능 하다. 도 19를 참조하면, 모바일 기기의 통신 장치는 외부 장치와 통신을 가능하게 하는 하나 이상의 통신 모듈을 포함할 수 있으며, 예를 들어 근거리 통신 모듈, 유선 통신 모듈 및 무선 통신 모듈를 포함할 수 있다. 근거리 통신 모듈은 블루투스 모듈, 적외선 통신 모듈, RFID(Radio Frequency Identification) 통신 모듈, WLAN(Wireless Local Access Network) 통신 모듈, NFC 통신 모듈, 직비(Zigbee) 통신 모듈 등 근거리에 서 무선 통신망을 이용하여 신호를 송수신하는 다양한 근거리 통신 모듈 중 적어도 하나를 포함할 수 있다. 유선 통신 모듈은 지역 통신(Local Area Network; LAN) 모듈, 광역 통신(Wide Area Network; WAN) 모듈 또는 부가가치 통신(Value Added Network; VAN) 모듈 등 다양한 유선 통신 모듈뿐만 아니라, USB(Universal Serial Bus), HDMI(High Definition Multimedia Interface), DVI(Digital Visual Interface), RS- 232(recommended standard232), 전력선 통신, 또는 POTS(plain old telephone service) 등 다양한 케이블 통신 모듈 중 적어도 하나를 포함할 수 있다. 무선 통신 모듈은 와이파이(Wifi) 모듈, 와이브로(Wireless broadband) 모듈 외에도, GSM(Global System for Mobile Communication), CDMA(Code Division Multiple Access), WCDMA(Wideband Code Division Multiple Access), UMTS(Universal Mobile Telecommunications System), TDMA(Time Division Multiple Access), LTE(Long Term Evolution), 4G, 5G 등 무선 통신 방식으로 인터넷망과 연결될 수 있는 다양한 무선 통신 모듈 중 적어도 하나를 포함할 수 있다. 예를 들어, 모바일 기기는 근거리 통신 모듈 또는 유선 통신 모듈을 통해 차량과 연결될 수 있고, 무선 통신 모듈을 통해 원격 대화 시스템 서버 또는 외부 컨텐츠 서버와 연결될 수있다. 도 20은 모바일 기기에 대화 시스템이 탑재되는 모바일 단독 방식에 대한 제어 블록도이다. 모바일 단독 방식에서는, 도 20에 도시된 바와 같이, 대화 시스템이 모바일 기기에 마련된다. 따라서, 대화 처리를 수행하기 위해 원격 대화 시스템 서버와 연결될 필요가 없고, 모바일 기기가 자체 적으로 사용자와의 대화를 처리하고 사용자에게 필요한 서비스를 제공해줄 수 있다. 다만, 대화 처리 및 서비스 제공을 위해 필요한 정보 중 일부는 외부 컨텐츠 서버로부터 가져올 수 있다. 또한, 전술한 방식 중 어느 방식에서든, 대화 시스템을 구성하는 구성요소들이 물리적으로 분리되어 마련 되는 것도 가능하고, 구성요소 중 일부가 생략되는 것도 가능하다. 예를 들어, 대화 시스템이 원격 대화 시스템 서버에 마련되는 경우에도, 대화 시스템을 구성하는 구성요소들 중 일부가 별도의 서버나 차량 에 마련될 수 있다. 이 때, 별도의 서버는 운영 또는 관리 주체가 원격 대화 시스템 서버와 동일할 수도 있 고, 다를 수도 있다. 예를 들어, 후술하는 음성 인식기 또는 자연어 이해기는 별도의 서버에 마련될 수 있고, 대화 시스템은 별도의 서버로부터 사용자 발화에 대한 음성 인식 결과 또는 자연어 이해 결과를 제공받을 수 있다. 또는, 저장부가 별도의 서버에 마련되는 것도 가능하다. 이하, 대화 시스템의 세부적인 구성 및 각 구성요소 별 구체적인 동작을 상세하게 설명한다. 후술하는 실 시예에서는 설명의 편의를 위해, 대화 시스템이 차량에 마련된 경우를 가정하여 설명한다. 후술하는 대화 시스템의 세부적인 구성들은 수행하는 동작에 따라 구분한 것으로서, 이들이 동일한 프로세서와 메모 리에 의해 구현되는지 여부, 프로세서와 메모리의 물리적인 위치 등에 대해서는 제한을 두지 않는다. 도 21, 도 22a 및 도 22b는 대화 시스템의 구성 중 입력 처리기의 구성이 세분화된 제어 블록도이다. 도 21을 참조하면, 입력 처리기는 음성 입력을 처리하는 음성 입력 처리기 및 상황 정보를 처리하는 상황 정보 처리기를 포함할 수 있다. 음성 입력 장치를 통해 입력된 사용자 음성은 음성 입력 처리기로 전송되고, 음성 외 입력 장치(22 0)를 통해 입력된 음성 외 사용자 입력은 상황 정보 처리기로 전송된다. 차량 제어기는 차량 상태 정보, 주행 환경 정보 및 사용자 정보를 상황 정보 처리기로 전송한다. 주 행 환경 정보 및 사용자 정보는 외부 컨텐츠 서버 또는 차량에 연결된 모바일 기기로부터 제공 될 수도 있다. 음성 외 입력은 모두 상황 정보에 포함될 수 있다. 즉, 상황 정보는 차량 상태 정보, 주행 환경 정보, 사용자 정보, 동승자 탑승 정보 및 경유지 도착 정보 및 경유지 출발 정보를 포함할 수 있다. 동승자 탑승 정보는 차량 내 동승자가 탑승하였는지 여부를 나타내는 상황 정보일 수 있으며, 경유지 도착 정보는 차량의 경유지 도착을 나타내는 상황 정보일 수 있으며, 경유지 출발 정보는 차량의 경유지 도착 이후 출발을 나타내는 상황 정보일 수 있다. 대화 시스템은 음성인식장치를 통해 차량 내 탑승자 간의 대화를 인식하여 획득한 동승자에 관련된 정보 및 음성 외 입력장치를 통해 획득한 동승자에 관련된 정보에 기초하여 동승자 탑승 정보를 획득할 수 있다. 또한, 대화시스템은 차량 감지부가 감지한 현재 위치, 차량 속도 등과 같은 차량 상태 정보에 기초하 여 차량의 경유지 도착 또는 경유지 출발 여부를 판단할 수 있고, 이를 통해 경유지 도착 정보 및 경유지 출발 정보를 획득할 수 있다. 차량 상태 정보는 차량에 마련된 센서에 의해 획득된 정보로서 차량의 상태를 나타내는 정보를 포함할 수 도 있고, 차량의 유종과 같이 차량에 관련된 정보로서 차량에 저장되어 있는 정보 등을 포함할 수도 있다. 주행 환경 정보는 차량에 마련된 센서에 의해 획득된 정보로서 전방 카메라, 후방 카메라 또는 스테레오 카메라가 획득한 영상 정보, 레이더(radar), 라이다(Lidar), 초음파 센서 등의 센서가 획득한 장애물 정보, 강 우 센서가 획득한 강우량/강우속도 정보 등을 포함할 수 있다. 또한, 주행 환경 정보는 V2X를 통해 획득된 정보로서 교통 상황 정보, 신호등 정보, 주변 차량의 접근 또는 추 돌 가능성 정보 등을 더 포함할 수 있다. 사용자 정보는 차량에 마련된 카메라 또는 생체 신호 측정 장치를 통해 측정한 사용자의 상태와 관련된 정보, 사용자가 차량에 마련된 입력 장치를 이용하여 직접 입력한 사용자와 관련된 정보, 외부 컨텐츠 서버에 저 장된 사용자와 관련된 정보, 차량에 연결된 모바일 기기에 저장된 정보 등을 포함할 수 있다. 음성 입력 처리기는 입력된 사용자 음성을 인식하여 텍스트 형태의 발화문으로 출력하는 음성 인식기 (111a), 발화문에 대해 자연어 이해 기술(Natural Language Understanding)을 적용하여 발화문이 내포하는 사 용자의 의도를 파악하는 자연어 이해기(111b) 및 자연어 이해 결과와 상황 정보를 대화 관리기로 전달하는 대화 입력 관리기(111c)를 포함할 수 있다. 음성 인식기(111a)는 음성 인식 엔진(speech recognition engine)을 포함하고, 음성 인식 엔진은 입력된 음성에 음성 인식 알고리즘을 적용하여 사용자가 발화한 음성을 인식하고, 인식 결과를 생성할 수 있다. 이 때, 입력된 음성은 음성 인식을 위한 더 유용한 형태로 변환될 수 있는바, 음성 신호로부터 시작 지점과 끝 지점을 검출하여 입력된 음성에 포함된 실제 음성 구간을 검출한다. 이를 EPD(End Point Detection)이라 한다. 그리고, 검출된 구간 내에서 켑스트럼(Cepstrum), 선형 예측 코딩(Linear Predictive Coefficient: LPC), 멜프 리퀀시켑스트럼(Mel Frequency Cepstral Coefficient: MFCC) 또는 필터 뱅크 에너지(Filter Bank Energy) 등의 특징 벡터 추출 기술을 적용하여 입력된 음성의 특징 벡터를 추출할 수 있다. 그리고, 추출된 특징 벡터와 훈련된 기준 패턴과의 비교를 통하여 인식 결과를 얻을 수 있다. 이를 위해, 음성 의 신호적인 특성을 모델링하여 비교하는 음향 모델(Acoustic Model) 과 인식 어휘에 해당하는 단어나 음절 등 의 언어적인 순서 관계를 모델링하는 언어 모델(Language Model)이 사용될 수 있다. 이를 위해, 저장부에 는 음향 모델/언어 모델 DB가 저장될 수 있다. 음향 모델은 다시 인식 대상을 특징 벡터 모델로 설정하고 이를 음성 데이터의 특징 벡터와 비교하는 직접 비교 방법과 인식 대상의 특징 벡터를 통계적으로 처리하여 이용하는 통계 방법을 나뉠 수 있다. 직접 비교 방법은 인식 대상이 되는 단어, 음소 등의 단위를 특징 벡터 모델로 설정하고 입력 음성이 이와 얼마 나 유사한지를 비교하는 방법으로서, 대표적으로 벡터 양자화(Vector Quantization) 방법이 있다. 벡터 양자화 방법에 의하면 입력된 음성 데이터의 특징 벡터를 기준 모델인 코드북(codebook)과 매핑시켜 대표 값으로 부호 화함으로써 이 부호 값들을 서로 비교하는 방법이다. 통계적 모델 방법은 인식 대상에 대한 단위를 상태 열(State Sequence)로 구성하고 상태 열 간의 관계를 이용하 는 방법이다. 상태 열은 복수의 노드(node)로 구성될 수 있다. 상태 열 간의 관계를 이용하는 방법은 다시 동적 시간 와핑(Dynamic Time Warping: DTW), 히든 마르코프 모델(Hidden Markov Model: HMM), 신경 회로망을 이용 한 방식 등이 있다. 동적 시간 와핑은 같은 사람이 같은 발음을 해도 신호의 길이가 시간에 따라 달라지는 음성의 동적 특성을 고려 하여 기준 모델과 비교할 때 시간 축에서의 차이를 보상하는 방법이고, 히든 마르코프 모델은 음성을 상태 천이 확률 및 각 상태에서의 노드(출력 심볼)의 관찰 확률을 갖는 마르코프 프로세스로 가정한 후에 학습 데이터를 통해 상태 천이 확률 및 노드의 관찰 확률을 추정하고, 추정된 모델에서 입력된 음성이 발생할 확률을 계산하는 인식 기술이다. 한편, 단어나 음절 등의 언어적인 순서 관계를 모델링하는 언어 모델은 언어를 구성하는 단위들 간의 순서 관계 를 음성 인식에서 얻어진 단위들에 적용함으로써 음향적인 모호성을 줄이고 인식의 오류를 줄일 수 있다. 언어 모델에는 통계적 언어 모델과 유한 상태 네트워크(Finite State Automata: FSA)에 기반한 모델이 있고, 통계적 언어 모델에는 Unigram, Bigram, Trigram 등 단어의 연쇄 확률이 이용된다. 음성 인식기(111a)는 음성을 인식함에 있어 상술한 방식 중 어느 방식을 사용해도 무방하다. 예를 들어, 히든 마르코프 모델이 적용된 음향 모델을 사용할 수도 있고, 음향 모델과 음성 모델을 통합한 N-best 탐색법을 사용 할 수 있다. N-best 탐색법은 음향 모델과 언어 모델을 이용하여 N개까지의 인식 결과 후보를 선택한 후, 이들 후보의 순위를 재평가함으로써 인식 성능을 향상시킬 수 있다. 음성 인식기(111a)는 인식 결과의 신뢰성을 확보하기 위해 신뢰값(confidence value)을 계산할 수 있다. 신뢰값 은 음성 인식 결과에 대해서 그 결과를 얼마나 믿을 만한 것인가를 나타내는 척도이다. 일 예로, 인식된 결과인 음소나 단어에 대해서, 그 외의 다른 음소나 단어로부터 그 말이 발화되었을 확률에 대한 상대값으로 정의할 수 있다. 따라서, 신뢰값은 0 에서 1 사이의 값으로 표현할 수도 있고, 0 에서 100 사이의 값으로 표현할 수도 있 다. 신뢰값이 미리 설정된 임계값(threshold)을 초과하는 경우에는 인식 결과를 출력하여 인식 결과에 대응되는 동 작이 수행되도록 할 수 있고, 신뢰값이 임계값 이하인 경우에는 인식 결과를 거절(rejection)할 수 있다. 또한, 음성 인식기(111a)는 음성입력장치를 통해 입력된 탑승자 별 음성을 구분할 수 있다. 구체적으로, 음성 인식기(111a)는 음성입력장치를 통해 입력된 탑승자 음성의 비언어적 음성학 특성과 언어적 특성을 비교하여 탑승자 별 음성을 구분할 수 있다. 비언어적 음성학 특성은 탑승자 음성의 높낮이, 세기, 숨쉬기, 빠 르기 등을 포함할 수 있다. 언어적 특성은 탑승자 음성의 사투리, 은어, 억양 등을 포함할 수 있다. 또한, 음성 인식기(111a)는 음성입력장치를 통해 입력된 동승자 별 음성을 구분하여, 차량 내 새로운 동승 자가 탑승하였음을 판단할 수 있다. 음성 인식기(111a)의 인식 결과인 텍스트 형태의 발화문은 자연어 이해기(111b)로 입력된다. 자연어 이해기(111b)는 자연어 이해 기술을 적용하여 발화문에 내포된 사용자의 의도를 파악할 수 있다. 따라서, 사용자는 자연스러운 대화(Dialogue)를 통해 명령을 입력할 수 있고, 대화 시스템 역시 대화를 통 해 명령의 입력을 유도하거나 사용자가 필요로 하는 서비스를 제공할 수 있다. 먼저, 자연어 이해기(111b)는 텍스트 형태의 발화문에 대해 형태소 분석을 수행한다. 형태소는 의미의 최소 단 위로써, 더 이상 세분화할 수 없는 가장 작은 의미 요소를 나타낸다. 따라서, 형태소 분석은 자연어 이해의 첫 단계로서, 입력 문자열을 형태소열로 바꿔준다. 자연어 이해기(111b)는 형태소 분석 결과에 기초하여 발화문으로부터 도메인을 추출한다. 도메인은 사용자가 발 화한 언어의 주제를 식별할 수 있는 것으로서, 예를 들어, 경로 안내, 날씨 검색, 교통 검색, 일정 관리, 주유 안내, 공조 제어, 동승자 탑승, 동승자 인원 변화 등의 다양한 주제를 나타내는 도메인이 데이터베이스화 되어 있다. 자연어 이해기(111b)는 발화문으로부터 개체명을 인식할 수 있다. 개체명은 인명, 지명, 조직명, 시간, 날짜, 화폐 등의 고유 명사로서, 개체명 인식은 문장에서 개체명을 식별하고 식별된 개체명의 종류를 결정하는 작업이 다. 개체명 인식을 통해 문장에서 중요한 키워드를 추출하여 문장의 의미를 파악할 수 있다. 자연어 이해기(111b)는 발화문이 갖는 화행을 분석할 수 있다. 화행 분석은 사용자 발화에 대한 의도를 분석하 는 작업으로, 사용자가 질문을 하는 것인지, 요청을 하는 것인지, 응답을 하는 것인지, 단순한 감정 표현을 하 는 것인지 등에 관한 발화의 의도를 파악하는 것이다. 자연어 이해기(111b)는 사용자의 발화 의도에 대응하는 액션을 추출한다. 발화문에 대응되는 도메인, 개체명, 화행 등의 정보에 기초하여 사용자의 발화 의도를 파악하고, 발화 의도에 대응되는 액션을 추출할 수 있다. 액 션은 오브젝트(Object)와 오퍼레이터(Operator)에 의해 정의될 수 있다. 또한, 자연어 이해기(111b)는 액션 수행과 관련된 인자를 추출하는 것도 가능하다. 액션 수행과 관련된 인자는 액션을 수행하는데 직접적으로 필요한 유효 인자일 수도 있고, 이러한 유효 인자를 추출하기 위해 사용되는 비 유효 인자일 수도 있다. 예를 들어, 사용자의 발화문이 “서울역 가자”인 경우에, 자연어 이해기(111b)는 발화문에 대응되는 도메인으 로 “내비게이션”을 추출하고, 액션으로 “길안내”를 추출할 수 있다. 화행은 “요청”에 해당한다. 개체명인 “서울역”은 액션 수행과 관련된 [인자: 목적지]에 해당하나, 실제 내비게이션을 통한 길안내를 위해 서는 구체적인 출구 번호나 GPS 정보가 필요할 수 있다. 이 경우, 자연어 이해기(111b)가 추출한 [인자: 목적지: 서울역]은 다수의 서울역 POI 중 실제 사용자가 원하는 서울역을 검색하기 위한 후보 인자가 될 수 있 다. 또한, 자연어 이해기(111b)는 파스트리(Parse-tree)와 같이 단어와 단어, 문장과 문장의 수식 관계를 표현할 수 있는 수단도 추출할 수 있다. 자연어 이해기(111b)의 처리 결과인, 형태소 분석 결과, 도메인 정보, 액션 정보, 화행 정보, 추출된 인자 정보, 개체명 정보, 파스트리 등은 대화 입력 관리기(111c)로 전달된다. 또한, 자연어 이해기(111b)의 처리 결과인, 형태소 분석 결과, 도메인 정보, 액션 정보, 화행 정보, 추출된 인 자 정보, 개체명 정보, 파스트리 등은 동승자 판단기(111d)를 통하여 대화 입력 관리기(111c)로 전달될 수 있다.동승자 판단기(111d)는 자연어 이해기(111b)의 출력을 기반으로, 차량 내 동승자 인원 변화를 예측한다. 구체적 으로, 동승자 판단기(111d)는 차량 내 탑승자 간의 대화에 기초하여 동승자 각각의 하차 가능성 및 하차 후 재 탑승 가능성을 예측할 뿐만 아니라, 차량 내 통화 내용에 기초하여 탑승 예정 인원을 예측할 수 있다. 동승자 판단기(111d)는 동승자 인원 변화 예측 결과에 기초하여 동승자 인원 정보를 생성할 수 있다. 동승자 인원 정보는 경유지에서의 동승자 각각의 하차 가능성, 하차 후 재탑승 가능성 및 경유지에서의 탑승예 정자의 탑승 가능성을 포함할 수 있다. 상황 정보 처리기는 음성 외 입력 장치와 차량 제어기로부터 정보를 수집하는 상황 정보 수집기 (112a), 상황 정보의 수집을 관리하는 상황 정보 수집 관리기(112b) 및 자연어 이해 결과와 수집된 상황 정보에 기초하여 상황을 이해하는 상황 이해기(112c)를 포함할 수 있다. 입력 처리기는 전술 또는 후술하는 동작을 수행하기 위한 프로그램이 저장되는 메모리 및 저장된 프로그램 을 실행시키는 프로세서를 포함할 수 있다. 메모리와 프로세서는 각각 적어도 하나 마련될 수 있고, 복수 개 마 련되는 경우에는 이들이 하나의 칩 상에 집적될 수도 있고 물리적으로 분리될 수도 있다. 또한, 입력 처리기에 포함되는 음성 입력 처리기와 상황 정보 처리기는 동일한 프로세서 및 메 모리에 의해 구현되는 것도 가능하고, 별개의 프로세서 및 메모리에 의해 구현되는 것도 가능하다. 이하, 도 22a 및 도 22b를 참조하여 입력 처리기의 구성요소들이 저장부에 저장된 정보를 이용하여 어떻게 입력 데이터를 처리하는지 구체적으로 설명한다. 도 22a를 참조하면, 자연어 이해기(111b)는 도메인 추출, 개체명 인식, 화행 분석 및 액션 추출을 위해 도메인/ 액션 추론 규칙 DB를 이용할 수 있다. 도메인/액션 추론 규칙 DB에는 도메인 추출 규칙, 화행 분석 규칙, 개체명 변환 규칙, 액션 추출 규칙 등 이 저장될 수 있다. 음성 외 사용자 입력, 차량 상태 정보, 주행 환경 정보, 사용자 정보와 같은 기타 정보는 상황 정보 수집기 (112a)로 입력되고, 상황 정보 DB, 장기 메모리 또는 단기 메모리에 저장될 수 있다. 예를 들어, 상황 정보 DB에는 차량 감지부가 감지한 로우 데이터(raw data)가 센서 타입과 센서 값으 로 구분되어 저장될 수 있다. 단기 메모리와 장기 메모리에는 사용자의 현재 상태, 사용자의 선호도/성향 또는 이를 판단할 수 있 는 데이터와 같이 사용자에게 의미가 있는 데이터가 저장될 수 있다. 전술한 바와 같이, 장기 메모리에는 사용자의 전화번호부, 일정, 선호도, 학력, 성격, 직업, 가족 관련 정 보 등과 같이 영속성이 보장되어 장기적으로 사용 가능한 정보가 저장될 수 있다. 또한, 장기 메모리에는 주행에 관한 주행 관련 정보 및 차량이 주행하는 동안 탑승한 동승자에 대한 동승자 정보가 저장될 수 있다. 단기 메모리에는 현재/이전 위치, 오늘 일정, 이전 대화 내용, 대화 참여자, 주변 상황, 도메인, 운전자 상태 등과 같이 영속성이 보장되지 않거나 불확실하여 단기적으로 사용되는 정보가 저장될 수 있다. 데이터의 종류에 따라 상황 정보 DB, 단기 메모리 및 장기 메모리 중 두 개 이상의 저장소에 중복되어 저 장되는 데이터도 있을 수 있다. 또한, 단기 메모리에 저장된 정보 중 영속성이 보장되는 것으로 판단된 정보는 장기 메모리로 보내질 수 있다. 또한, 단기 메모리나 상황 정보 DB에 저장된 정보를 이용하여 장기 메모리에 저장될 정보를 획 득하는 것도 가능하다. 예를 들어, 일정 기간 축적된 목적지 정보 또는 대화 내용을 분석하여 사용자의 선호도 를 획득하고, 획득된 사용자의 선호도를 장기 메모리에 저장할 수 있다. 단기 메모리나 상황 정보 DB에 저장된 정보를 이용하여 장기 메모리에 저장될 정보를 획득하는 것은 대화 시스템 내부에서 수행되는 것도 가능하고, 별도의 외부 시스템에서 수행되는 것도 가능하다. 전자의 경우, 후술하는 결과 처리기의 메모리 관리기에서 수행 가능하다. 이 경우, 단기 메모리(14 4)나 상황 정보 DB에 저장된 데이터 중에서 사용자의 선호도나 성향과 같이 의미 있는 정보 또는 영속성 있는 정보를 획득하는데 사용되는 데이터는 장기 메모리에 로그 파일 형태로 저장될 수 있다. 메모리 관리기는 일정 기간 이상 축적된 데이터를 분석하여 영속성이 있는 데이터를 획득하고 장기 메모리 에 다시 저장한다. 장기 메모리 내에서 영속성 있는 데이터가 저장되는 위치와 로그 파일 형태로 저 장되는 데이터가 저장되는 위치를 서로 다를 수 있다. 또는, 메모리 관리기가 단기 메모리에 저장된 데이터 중에서 영속성 있는 데이터를 판단하고, 판단된 데이터를 장기 메모리로 옮겨 저장하는 것도 가능하다. 별도의 외부 시스템에서 수행하는 경우에는, 도 22b에 도시된 바와 같이 통신부, 저장부 및 제어부 를 포함하는 데이터 관리 시스템이 사용될 수 있다. 통신부가 상황 정보 DB 또는 단기 메모리에 저장된 데이터를 수신한다. 저장된 데이터 전부가 통신부에 전송될 수도 있고, 사용자의 선호도나 성향과 같이 의미 있는 정보 또는 영속성 있는 정보를 획 득하는데 사용되는 데이터만 선별되어 전송될 수도 있다. 수신된 데이터는 저장부에 저장된다. 제어부는 축적된 데이터를 분석하여 영속성이 있는 데이터를 획득하고, 획득된 데이터는 다시 통신부(81 0)를 통해 대화 시스템으로 전송한다. 전송된 데이터는 대화 시스템의 장기 메모리에 저장된다. 또한, 대화 입력 관리기(111c)가 자연어 이해기(111b)의 출력 결과를 상황 이해기(112c)에 전달하여 액션 수행 과 관련된 상황 정보를 얻을 수도 있다. 상황 이해기(112c)는 상황 이해 테이블에 저장된 액션 별 상황 정보를 참조하여, 사용자의 발화 의도에 대 응되는 액션 수행과 관련된 상황 정보가 무엇인지 판단할 수 있다. 도 23a 및 도 23b는 상황 이해 테이블에 저장되는 정보의 예시를 나타낸 도면이다. 도 23a 의 예시를 참조하면, 상황 이해 테이블에는 액션 수행과 관련된 상황 정보와 상황 정보 타입이 각 각의 액션 별로 저장될 수 있다. 예를 들어, 길 안내가 액션인 경우에는 상황 정보로 현재 위치가 필요하고, 상황 정보 타입은 GPS 정보일 수 있 다. 차량 상태 점검이 액션인 경우에는 상황 정보로 이동거리가 필요하고, 상황 정보 타입은 정수일 수 있다. 주유소 추천이 액션인 경우에는 상황 정보로 잔유량과 주행 가능 거리(DTE: Distance To Empty)이 필요하고, 상 황 정보 타입은 정수일 수 있다. 사용자 발화 의도에 대응되는 액션 수행과 관련된 상황 정보가 상황 정보 DB, 장기 메모리 또는 단기 메모리에 이미 저장되어 있는 경우, 상황 이해기(112c)는 상황 정보 DB, 장기 메모리 또는 단기 메모리로부터 해당 정보를 가져와 대화 입력 관리기(111c)에 전달한다. 사용자 발화 의도에 대응되는 액션 수행과 관련된 상황 정보가 상황 정보 DB, 장기 메모리 또는 단기 메모리에 저장되어 있지 않은 경우, 상황 이해기(112c)는 상황 정보 수집 관리기(112b)에 필요한 정보를 요청한다. 상황 정보 수집 관리기(112b)는 상황 정보 수집기(112a)가 필요한 정보를 수집하도록 한다. 상황 정보 수집기(112a)는 주기적으로 데이터를 수집할 수도 있고, 특정 이벤트 발생 시에 수집할 수도 있으며, 주기적으로 수집하다가 특정 이벤트 발생 시에 추가적으로 더 수집할 수도 있다. 또한, 상황 정보 수집 관리기 (112b)로부터 데이터 수집 요청이 입력되는 경우에 데이터를 수집할 수도 있다. 상황 정보 수집기(112a)는 필요한 정보를 수집하여 상황 정보 DB 또는 단기 메모리에 저장하고, 상황 정보 수집 관리기(112b)에 확인 신호를 전송한다. 상황 정보 수집 관리기(112b)도 상황 이해기(112c)에 확인 신호를 전송하고, 상황 이해기(112c)는 필요한 정보 를 상황 정보 DB, 장기 메모리 또는 단기 메모리로부터 가져와 대화 입력 관리기(111c)로 전달 한다. 구체적인 예로, 사용자 발화 의도에 대응되는 액션이 길안내인 경우, 상황 이해기(112c)는 상황 이해 테이블 을 검색하여 길안내와 관련된 상황 정보가 현재 위치임을 알 수 있다. 단기 메모리에 현재 위치가 이미 저장되어 있는 경우, 상황 이해기(112c)는 단기 메모리로부터 현재 위치를 가져와 대화 입력 관리기(111c)에 전달한다. 단기 메모리에 현재 위치가 저장되어 있지 않은 경우에는, 상황 정보 수집 관리기(112b)에 현재 위치를 요 청하고, 상황 정보 수집 관리기(112b)는 상황 정보 수집기(112a)로 하여금 차량 제어기로부터 현재 위치를획득하게 한다. 상황 정보 수집기(112a)가 현재 위치를 획득하여 단기 메모리에 저장하고, 상황 정보 수집 관리기(112b)에 확인 신호를 전송한다. 상황 정보 수집 관리기(112b)도 상황 이해기(112c)에 확인 신호를 전송하고, 상황 이해 기(112c)는 단기 메모리로부터 현재 위치 정보를 가져와 대화 입력 관리기(111c)로 전달한다. 대화 입력 관리기(111c)는 자연어 이해기(111b)의 출력과 상황 이해기(112c)의 출력을 대화 관리기로 전달 하고, 중복된 입력이 대화 관리기로 들어가지 않도록 관리할 수 있다. 이 때, 자연어 이해기(111b)의 출력 과 상황 이해기(112c)의 출력은 하나로 합쳐져서 대화 관리기에 전달될 수도 있고, 각각 독립적으로 전달 될 수도 있다. 한편, 상황 정보 수집 관리기(112b)는 상황 정보 수집기(112a)가 수집한 데이터가 미리 설정된 조건을 만족하여 특정 이벤트가 발생한 것으로 판단하면 상황 이해기(112c)에 액션 트리거 신호를 전송할 수 있다. 상황 이해기 (112c)는 상황 이해 테이블을 검색하여 해당 이벤트와 관련된 상황 정보를 검색하고, 검색된 상황 정보가 저장되어 있지 않으면 다시 상황 정보 수집 관리기(112b)에 상황 정보의 요청 신호를 전송한다. 예를 들어, 상황 정보 수집 관리기(112b)는 상황 정보 수집기(112a)가 수집한 차량 내 음성 외 입력 장치 에 대한 차량 조작 정보가 미리 설정된 조건을 만족하여, 차량 내 동승자가 탑승한 것으로 판단되면, 상황 이해 기(112c)에 액션 트리거 신호를 전송할 수 있다. 그러면, 상황 이해기(112c)는 상황 이해 테이블을 검색하 여 해당 이벤트와 관련된 상황 정보를 검색하고, 검색된 상황 정보가 저장되어 있지 않으면 다시 상황 정보 수 집 관리기(112b)에 상황 정보의 요청 신호를 전송한다. 도 23b의 예시와 같이, 상황 이해 테이블에는 이벤트와 관련된 상황 정보와 상황 정보의 타입이 각각의 이 벤트 별로 저장될 수 있다. 예를 들어, 발생된 이벤트가 엔진 온도 경고인 경우에는 관련된 상황 정보로 정수 타입의 엔진 온도가 저장될 수 있다. 발생된 이벤트가 운전자 졸음 감지인 경우에는 관련된 상황 정보로 정수 타입의 운전자 졸음 단계가 저장될 수 있다. 발생된 이벤트가 타이어 공기압 부족인 경우에는 관련된 상황 정보로 정수 타입의 타이어 공기 압력이 저장될 수 있다. 발생된 이벤트가 연료 경고인 경우에는 관련된 상황 정보로 정수 타입의 주행 가능 거 리가 저장될 수 있다. 발생된 이벤트가 센서 이상인 경우에는 관련된 상황 정보로 문자 타입의 센서 명칭이 저 장될 수 있다. 또한, 도 23c에 예시와 같이, 상황 이해 테이블에는 이벤트와 관련된 상황 정보와 상황 정보의 타입이 각 각의 이벤트 별로 저장될 수 있다. 발생된 이벤트가 윈도우 조정 버튼 조작인 경우에는 관련된 상황 정보로 문 자 타입의 윈도우 조정 정보가 저장될 수 있다. 발생된 이벤트가 시트 조정 버튼 조작인 경우에는 관련된 상황 정보로 문자 타입의 시트 조정 정보가 저장될 수 있다. 또한, 발생된 이벤트가 공조 장치 조정 버튼 조작인 경 우에는 관련된 상황 정보로 문자 타입의 공조 장치 조정 정보가 저장될 수 있다. 그 밖에도 차량 내 동승자 탑 승과 관련된 이벤트가 발생될 수 있으며, 이때 관련된 상황 정보로써 문자 타입의 동승자 탑승 정보가 저장될 수 있는 등 제한은 없다. 상황 정보 수집 관리기(112b)는 상황 정보 수집기(112a)를 통해 필요한 상황 정보를 수집하고, 상황 이해기 (112c)에 확인 신호를 전송한다. 상황 이해기(112c)는 상황 정보 DB, 장기 메모리 또는 단기 메모리 로부터 필요한 상황 정보를 가져와 액션 정보와 함께 대화 입력 관리기(111c)로 전달한다. 대화 입력 관리기(111c)는 상황 이해기(112c)의 출력을 대화 관리기로 입력한다. 이하, 사용자의 발화가 입력되기 전에 대화 시스템이 스스로 선발화를 출력하는 경우에 대해 설명한다. 도 24는 사용자의 입력이 수신되기 전에 대화 시스템이 먼저 발화를 출력하는 경우에 적용 가능한 대화 시스템 의 제어 블록도이고, 도 25a, 도 25b, 도 25c 및 도 25d는 선발화 조건 테이블에 저장하는 정보의 예시를 나타 낸 도면이다. 도 24을 참조하면, 대화 시스템의 입력 처리기는 선발화 상황인지 여부를 판단하는 선발화 판단기 와 중복 태스크 처리기를 더 포함할 수 있고, 저장부는 선발화 조건을 저장하는 선발화 조건 테 이블(145a)과 태스크 처리 DB(145b)를 더 포함할 수 있다. 상황 정보 DB, 장기 메모리 및 단기 메모리에 저장된 데이터는 선발화 판단기에 전달될 수 있다. 선발화 판단기는 전달된 데이터를 분석하여 선발화 조건 테이블(145a)에 저장된 선발화 조건이 충족되는지 여부를 판단할 수 있다. 또한, 입력처리기의 음성 입력 처리기 및 상황 정보 처리기는 동승자 탑승 여부를 나타내는 상 황 정보를 생성할 수 있으며, 생성된 상황 정보를 선발화 판단기로 전달할 수 있다. 또한, 입력처리기의 동승자 판단기(111d)는 동승자 인원 변화 예측 결과에 기초하여 동승자 인원 정보를 생성할 수 있으며, 생성된 동승자 인원 정보를 선발화 판단기로 전달할 수 있다. 또한, 차량이 경유지를 출발한 것으로 판단한 경우, 동승자 판단기(111d)는 동승자 인원 정보에 기초하여 경유 지 도착 전 동승자 인원 변화 예측 결과와 경유지 출발 후 동승자 인원 변화 결과를 비교할 수 있으며, 비교 결 과를 선발화 판단기로 전달할 수 있다. 선발화 판단기는 전달된 동승자 인원 정보 및 비교 결과를 분석하여 선발화 조건 테이블(145a)에 저장된 선발화 조건이 충족되는지 여부를 판단할 수 있다. 도 25a의 예시를 참조하면, 선발화 조건 테이블(145a)에는 상황 정보와 관련된 선발화 조건 및 해당 선발화 조 건이 만족되었을 때 출력되는 선발화 메시지가 상황 정보 별로 저장될 수 있다. 선발화 판단기는 상황 정보 DB로부터 전달된 상황 정보가 선발화 조건을 만족하면, 선발화 상황인 것으로 판단하고 선발화 트리거 신호를 발생시킨다. 선발화 판단기는 선발화 트리거 신호를 해당 선발화 상황에 대응되는 선발화 메시지와 함께 상황 이해기 (112c)로 전달할 수 있다. 또한, 해당 선발화 상황에 대한 정보를 함께 전달할 수 있다. 선발화 상황에 대한 정 보는 해당 선발화 상황에 대응되는 선발화 조건 또는 후술하는 선발화 상황에 대응되는 액션을 포함할 수 있다. 예를 들어, 상황 정보가 타이어 공기압인 경우에는 타이어 공기압이 미리 설정된 기준값 이하인 경우에 선발화 조건을 만족할 수 있다. 선발화 판단기는 타이어 공기압이 선발화 조건을 만족하는 경우, 타이어 공기압 부족으로 인한 선발화 상황인 것으로 판단하고, 선발화 트리거 신호를 발생시킬 수 있다. 선발화 판단기는 선발화 트리거 신호를 선발화 메시지와 함께 상황 이해기(112c)로 전달할 수 있다. 일 예 로, 타이어 공기압 부족으로 인한 선발화 상황에서는 “타이어 공기압이 너무 낮습니다”와 같이 타이어 공기압 이 부족하다는 정보를 알려주는 선발화 메시지가 상황 이해기(112c)에 전달될 수 있다. 또한, 상황 정보가 엔진 온도인 경우에는 엔진 온도가 미리 설정된 기준값 이상인 경우에 선발화 조건을 만족할 수 있다. 선발화 판단기는 엔진 온도가 선발화 조건을 만족하는 경우, 엔진 온도 이상으로 인한 선발화 상 황인 것으로 판단하고, 선발화 트리거 신호를 발생시킬 수 있다. 선발화 판단기는 선발화 트리거 신호를 선발화 메시지와 함께 상황 이해기(112c)로 전달할 수 있다. 일 예 로, 엔진 온도 이상으로 인한 선발화 상황에서는 “엔진 온도가 너무 높습니다”와 같이 엔진이 과열됐다는 정 보를 알려주는 선발화 메시지가 상황 이해기(112c)로 전달될 수 있다. 또한, 상황 정보가 잔유량인 경우에는 잔유량이 기준값 이하인 경우에 선발화 조건을 만족할 수 있다. 사용자가 차량의 내비게이션 서비스를 이용하여 목적지를 설정한 경우에는 현재 위치로부터 설정된 목적지까지의 거리에 기초하여 기준값이 설정될 수 있다. 목적지가 설정되지 않은 경우에는 목적지와 무관하게 디폴트로 설정된 기준 값이 사용될 수 있는바, 일 예로 연료 부족 경고등을 표시하는 기준값보다 작은 값을 잔유량 부족에 의한 선발 화 조건의 기준값으로 설정할 수 있다. 선발화 판단기는 잔유량이 선발화 조건을 만족하는 경우, 잔유량 부족으로 인한 선발화 상황인 것으로 판단하고, 선발화 트리거 신호를 발생시킬 수 있다. 선발화 판단기는 선발화 트리거 신호를 선발화 메시지와 함께 상황 이해기(112c)로 전달할 수 있다. 일 예 로, 잔유량 부족으로 인한 선발화 상황에서는 “목적지까지의 잔유량이 부족합니다”와 같이 잔유량이 부족하다 는 정보를 알려주는 선발화 메시지가 상황 이해기(112c)로 전달될 수 있다. 다만, 도 25a에 도시된 선발화 조건과 선발화 메시지는 대화 시스템에 적용될 수 있는 예시에 불과하다. 전술한 예시에서는 선발화 상황에 대응되는 선발화 메시지가 현재 상황을 알려주는 내용인 경우를 예로 들어 설 명하였으나, 대화 시스템이 선발화 상황에 필요한 특정 기능 또는 서비스의 실행을 먼저 제안하는 것도 가 능하다. 도 25b의 예시를 참조하면, 타이어 공기압 부족으로 인한 선발화 상황인 경우 또는 엔진 온도 이상으로 인한 선 발화 상황인 경우에 이에 대응되는 선발화 메시지로 “정비소를 예약할까요?”와 같이 정비소 예약 서비스를 선제적으로 제안하는 내용을 저장할 수 있다. 또한, 잔유량 부족으로 인한 선발화 상황인 경우에는 이에 대응되는 선발화 메시지로 “주유소를 안내할까요?” 와 같이 주유소 안내 서비스를 선제적으로 제안하는 내용을 저장할 수 있다. 또한, 상황 정보가 차량 내부 온도인 경우에는 차량 내부 온도가 미리 설정된 기준 범위를 벗어나는 경우에 선 발화 조건을 만족할 수 있다. 상황 이해기(112c)는 차량 내부 온도가 선발화 조건을 만족하는 경우, 차량 내부 온도 이상으로 인한 선발화 상황인 것으로 판단하고, 선발화 트리거 신호를 발생시킬 수 있다. 차량 내부 온도 이상으로 인한 선발화 상황에서는 “공기 조화기를 작동할까요?”와 같이 내부 온도 조절 기능 을 선제적으로 제안하는 내용이 선발화 메시지로 저장될 수 있다. 또한, 상황 정보가 마이크 입력인 경우에는 마이크 입력 값이 미리 설정된 기준값 이하인 경우에 선발화 조건을 만족할 수 있다. 상황 이해기(112c)는 마이크 입력이 선발화 조건을 만족하는 경우, 분위기 전환을 위한 선발화 상황인 것으로 판단하고, 선발화 트리거 신호를 발생시킬 수 있다. 이에 대응되는 선발화 메시지로는 “음악을 재생할까요?”와 같이 멀티 미디어 재생 서비스를 선제적으로 제안하는 내용이 저장될 수 있다. 또한, 상황 정보가 윈도우 개폐 여부와 강수 여부인 경우에, 윈도우가 오픈되어 있고 강수 상황인 경우에 선발 화 조건을 만족할 수 있다. 상황 이해기(112c)는 윈도우가 오픈되어 있고 강수 상황인 경우에 윈도우 오픈으로 인한 선발화 상황인 것으로 판단하고, 선발화 트리거 신호를 발생시킬 수 있다. 윈도우 오픈으로 인한 선발화 상황에서는 “윈도우를 클로즈할까요?”와 같이 윈도우 클로즈 기능을 선제적으로 제안하는 내용이 선발화 메시지로 저장될 수 있다. 전술한 도 25a 및 도 25b의 예시에서는, 선발화 조건 테이블(145a)에 선발화 상황에 대응되는 선발화 메시지가 미리 저장되는 경우를 예로 들었다. 그러나, 대화 시스템의 예시가 이에 한정되는 것은 아닌바, 선발화 상 황에 대응되는 액션이 미리 저장되는 것도 가능하다. 전술한 바와 같이, 사용자의 발화가 입력되는 경우에는 자연어 이해기(111b)가 도메인/액션 추론 규칙 DB 를 참조하여 사용자의 발화에 대응되는 액션을 추출하였다. 대화 시스템이 선발화를 출력하는 경우에는 도 25c에 도시된 바와 같이, 선발화 상황마다 그에 대응되는 액션이 미리 저장될 수 있다. 예를 들어, 타이어 공기압 이상으로 인한 선발화 상황 및 엔진 온도 이상으로 인한 선발화 상황의 경우에는 정 비소 안내가 그에 대응되는 액션으로 저장될 수 있고, 잔유량 부족으로 인한 선발화 상황에서는 주유소 안내가 그에 대응되는 액션으로 저장될 수 있다. 또한, 차량 내부 온도 이상으로 인한 선발화 상황의 경우에는 공기 조화기 작동이 그에 대응되는 액션으로 저장 될 수 있고, 분위기 전환을 위한 선발화 상황의 경우에는 멀티미디어 재생이 그에 대응되는 액션으로 저장될 수 있다. 윈도우 오픈으로 인한 선발화 상황의 경우에는 윈도우 개폐가 그에 대응되는 액션으로 저장될 수 있다. 전술한 바와 같이 선발화 상황에 대응되는 액션이 미리 저장되어 있는 경우에는, 선발화 트리거 신호와 함께 그 에 대응되는 액션이 상황 이해기(112c)에 전달되고, 대화 입력 관리기(111c)는 선발화 트리거 신호와 그에 대응 되는 액션을 대화 관리기에 입력할 수 있다. 이 경우, 대화 관리기에서는 사용자의 발화가 입력된 경 우와 동일한 동작이 수행될 수 있다. 다른 예로, 선발화 조건 테이블(145a)에 선발화 상황마다 그에 대응되는 가상의 사용자 발화를 매칭시켜 저장하 거나, 선발화 판단기가 선발화 상황에 대응되는 가상의 사용자 발화를 생성하는 것도 가능하다. 선발화 판 단기는 선발화 조건 테이블(145a)에 저장되거나 자신이 생성한 사용자 발화를 텍스트 형태로 자연어 이해 기(111b)에 전달할 수 있다. 예를 들어, 타이어 공기압 이상으로 인한 선발화 상황의 경우, “타이어 공기압 확 인해줘”나 “정비소 안내해줘”와 같은 가상의 사용자 발화가 저장되거나 생성될 수 있다. 또는, 차량 내부 온 도 이상으로 인한 선발화 상황의 경우에는 “에어컨 켜줘”와 같은 가상의 사용자 발화가 저장되거나 생성될 수 있다. 또는, 모바일 기기가 차량과 대화 시스템 사이의 게이트웨이 역할을 수행하는 모바일 게이트웨 이 방식에 있어서, 모바일 기기의 대화 시스템 클라이언트가 선발화 판단기의 동작 중 일부를 수행할 수 있다. 이 경우, 대화 시스템 클라이언트가 선발화 상황에 대응되는 가상의 사용자 발화를 생성 하여 자연어 이해기(111b)에 전달할 수 있다. 자연어 이해기(111b)는 전달된 가상의 사용자 발화에 대응되는 도메인, 액션 등을 추출하여 대화 입력 관리기 (111c)에 전달할 수 있다. 자연어 이해기(111b)가 추출한 액션은 선발화 상황에 대응되는 액션이 된다. 선발화 상황에 대응되는 액션이 대화 관리기에 전달된 이후의 과정은 사용자가 먼저 발화한 경우와 동일하게 진행 될 수 있다. 전술한 상황 정보, 선발화 조건, 선발화 메시지 및 액션은 대화 시스템의 실시예에 적용 가능한 예시들에 불과하고, 대화 시스템의 실시예가 전술한 예시들에 한정되는 것은 아니다. 이 외에도 다양한 상황 정보, 선발화 조건, 선발화 메시지 및 액션이 저장될 수 있다. 선발화 판단기가 선발화 트리거 신호와 선발화 상황에 관한 정보를 상황 이해기(112c)에 전달하면, 상황 이해기(112c)는 중복 태스크 처리기에 선발화 상황에 관한 정보를 전달한다. 중복 태스크 처리기는 태스크 처리 DB(145b)에 저장된 정보에 기초하여, 현재 발생한 선발화 상황과 관련 된 태스크가 이미 처리되었거나, 진행 중인 중복 태스크인지 여부를 판단할 수 있다. 태스크 처리 DB(145b)에는 대화 시스템에서 처리되었거나 진행 중인 태스크에 관한 정보가 저장된다. 예를 들어, 대화 이력(대화 내용과 각각의 대화 시점 포함), 대화 시점에서의 차량 상태, 태스크 완료 여부 등을 저 장할 수 있다. 또한, 대화와 관계없이 내비게이션 기능을 이용한 길 안내와 같은 태스크의 진행 및 처리 결과도 저장될 수 잇다. 구체적인 예로, 잔유량 부족으로 인한 선발화 상황에서는, 중복 태스크 처리기가 태스크 처리 DB(145b)에 저장된 정보에 기초하여 주유소 안내 태스크가 진행 중인지 여부를 판단할 수 있다. 주유소 안내를 위한 대화가 진행 중이거나 주유소 안내 액션이 진행 중인 경우, 중복 태스크 처리기는 현재 선발화 상황과 관련된 태 스크를 중복 태스크로 판단하고, 선발화 상황을 종료시킬 수 있다. 또는, 이전에 주유소 안내를 위한 발화를 출력하였고, 사용자가 주유소 안내를 거부한 대화 이력이 존재하는 경 우에도, 중복 태스크 처리기는 현재 선발화 상황과 관련된 태스크를 중복 태스크로 판단하고, 선발화 상황 을 종료시킬 수 있다. 또는, 주유소 안내를 위한 대화 이력과 관계 없이, 현재 내비게이션 기능을 이용한 주유소 안내 태스크가 진행 중인 경우에도, 중복 태스크 처리기는 현재 선발화 상황과 관련된 태스크를 중복 태스크로 판단하고, 선발 화 상황을 종료시킬 수 있다. 중복 태스크 처리기는 태스크 처리 DB(14b)에 저장된 정보로부터 현재 내비 게이션 기능을 이용한 주유소 안내 태스크가 진행 중임을 알 수 있다. 또는, 잔유량 안내와 관련된 대화가 수행된 시점으로부터 기준 시간이 경과하지 않은 경우에는 주유소 안내 태 스크가 진행 중이지 않더라도 사용자가 스스로 주유소를 향해 주행 중인 경우도 있을 수 있다는 점을 고려하여 현재 선발화 상황과 관련된 태스크를 중복 태스크로 판단하고, 선발화 상황을 종료시킬 수 있다. 또한, 사용자의 생일 또는 사용자 가족의 생일 등 장기 메모리에 저장된 정보에 기초하여 일정을 안내하기 위한 선발화 상황인 경우, 이전에 동일한 일정을 안내한 대화 이력이 존재하고, 해당 대화가 수행된 시점으로부 터 기준 시간만큼 경과하지 않았으면, 중복 태스크 처리기는 현재 선발화 상황과 관련된 태스크를 중복 태 스크로 판단하고, 선발화 상황을 종료시킬 수 있다. 즉, 중복 태스크 처리기는 태스크 처리 DB(145b)에 저장된 대화 이력에 기초하여 이미 출력된 선발화 인지 여부, 선발화 상황에 대한 사용자의 의사 등을 판단할 수 있고, 저장된 대화 시점, 사용자의 의사, 차량 상태 또는 태스크 완료 여부에 기초하여 중복 태스크 여부를 판단할 수 있다. 중복 태스크 처리기에는 태스크 처리 DB(145b)에 저장된 정보에 기초하여 중복 태스크인지 여부 즉, 선발 화 상황을 종료시킬 지 여부를 판단하는 정책이 저장될 수 있다. 중복 태스크 처리기는 저장된 정책에 따 라 현재 선발화 상황에 관련된 태스크가 중복 태스크인지 여부를 판단하고, 중복 태스크인 것으로 판단되면, 선 발화 상황을 종료시킬 수 있다. 한편, 전술한 예시에서는 선발화 처리를 위해 선발화 판단기, 중복 태스크 처리기, 선발화 조건 테이 블(145a), 태스크 처리 DB(145b)의 구성요소를 포함하는 경우에 대해 설명하였다. 그러나, 대화 시스템의 예시가 이에 한정되는 것은 아니며, 상기 추가된 구성요소들의 동작을 도 22a 및 도 22b에 도시된 구성요소들이 수행하는 것도 가능함은 물론이다. 예를 들어, 상황 이해기(112c)가 선발화 조건의 만족 여부를 판단하는 선발화 판단기의 동작 및 중복 태스 크를 처리하는 중복 태스크 처리시의 동작을 수행할 수 있다.또한, 선발화 조건 테이블(145a)에 저장되는 정보는 상황 이해 테이블에 저장될 수도 있으며, 태스크 처리 DB(145b)에 저장되는 정보는 후술하는 대화/액션 상태 DB에 저장되는 것도 가능하다. 도 25d의 예시를 참조하면, 선발화 조건 테이블(145a)에는 상황 정보와 관련된 선발화 조건 및 해당 선발화 조 건이 만족되었을 때 출력되는 선발화 메시지가 상황 정보 별로 저장될 수 있다. 즉, 대화 시스템은 상황 정보 및 선발화 조건에 기초하여 선발화 조건 테이블에서 저장된 선발화 메시지를 획득할 수 있다. 상황 정보가 동승자 탑승 여부인 경우에, 동승자의 탑승이 판단되면 선발화 조건을 만족할 수 있다. 선발화 판 단기는 동승자의 탑승이 판단되어 선발화 조건을 만족하는 경우, 동승자 탑승으로 인한 선발화 상황인 것으로 판단하고, 선발화 트리거 신호를 발생시킬 수 있다. 선발화 판단기는 선발화 트리거 신호를 저장된 선발화 메시지와 함께 대화 입력 관리기(111c)로 전달 수 있다. 일 예로, 동승자의 탑승으로 인한 선발화 상황에서는 “누구세요? 이름을 말씀해 주세요”와 같이 동승자 의 신원 정보를 요청하는 선발화 메시지가 대화 입력 관리기(111c)로 전달될 수 있다. 또한, 상황 정보가 동승자 탑승 여부인 경우에, 동승자의 비-탑승이 판단된 경우에 선발화 조건을 만족할 수 있 다. 선발화 판단기는 동승자의 비-탑승이 판단되어 선발화 조건을 만족하는 경우, 동승자의 비-탑승으로 인한 선발화 상황인 것으로 판단하고, 선발화 트리거 신호를 발생시킬 수 있다. 선발화 판단기는 선발화 트리거 신호를 저장된 선발화 메시지와 함께 대화 입력 관리기(111c)로 전달 수 있다. 일 예로, 동승자의 비-탑승으로 인한 선발화 상황에서는 “더 타실 분은 없으신가요”와 같이 동승자 존 재 여부를 확인하기 위한 내용의 선발화 메시지가 대화 입력 관리기(111c)로 전달될 수 있다. 또한, 상황 정보가 탑승예정자 탑승 예정 여부인 경우에, 대화 시스템이 탑승예정자의 탑승가능성을 예측 한 경우에 선발화 조건을 만족할 수 있다. 선발화 판단기는 탑승예정자의 탑승가능성이 예측되어 선발화 조건을 만족하는 경우, 탑승예정자가 탑승 예정인 선발화 상황인 것으로 판단하고, 선발화 트리거 신호를 발생 시킬 수 있다. 선발화 판단기는 선발화 트리거 신호를 저장된 선발화 메시지와 함께 대화 입력 관리기(111c)로 전달 수 있다. 일 예로, 탑승예정자가 탑승 예정인 선발화 상황에서는 “누가 중간에 탑승하나요? 이름을 말씀해 주세요 ”와 같이 동승자 존재 여부를 확인하기 위한 내용의 선발화 메시지가 대화 입력 관리기(111c)로 전달될 수 있 다. 또한, 상황 정보가 경유지 도착 전인 경우에, 동승자 인원 변화가 예측된 경우에 선발화 조건을 만족할 수 있다. 선발화 판단기는 동승자의 인원 변화가 예측되어 선발화 조건을 만족하는 경우, 경유지 도착 전인 경우에 의한 선발화 상황인 것으로 판단하고, 선발화 트리거 신호를 발생시킬 수 있다. 선발화 판단기는 선발화 트리거 신호를 저장된 선발화 메시지와 함께 대화 입력 관리기(111c)로 전달 수 있다. 일 예로, 경유지 도착 전인 경우에 의한 선발화 상황에서는 “A는 경유지에서 하차합니다. B는 경유지에 서 하차 후 재탑승합니다. C는 경유지에서 하차하지 않습니다. C는 경유지에서 하차하지 않습니다. D는 경유지 에서 탑승합니다”와 같이 동승자 인원 변화 예측 결과에 관한 내용의 선발화 메시지가 대화 입력 관리기(111 c)로 전달될 수 있다. 또한, 상황 정보가 경유지 출발 후인 경우에, 동승자 인원 변화가 예측된 경우에 선발화 조건을 만족할 수 있다. 선발화 판단기는 동승자의 인원 변화가 예측되어 선발화 조건을 만족하는 경우, 경유지 출발 후인 경우에 의한 선발화 상황인 것으로 판단하고, 선발화 트리거 신호를 발생시킬 수 있다. 선발화 판단기는 선발화 트리거 신호를 저장된 선발화 메시지와 함께 대화 입력 관리기(111c)로 전달 수 있다. 일 예로, 경유지 도착 후인 경우에 의한 선발화 상황에서는 “A는 가셨지요? B는 다시 탑승하였지요? C는 남아계시지요? D는 탑승 하셨지요?”와 같이 경유지 출발 후 동승자 인원 변화 결과를 확인하기 위해, 동승자 인원 변화 예측 결과가 맞는지 확인하는 내용의 선발화 메시지가 대화 입력 관리기(111c)로 전달될 수 있다. 또한, 상황 정보가 경유지 출발 후인 경우에, 동승자 인원 변화 예측 결과와 경유지 출발 후 동승자 인원 변화 결과가 비교된 경우에 선발화 조건을 만족할 수 있다. 선발화 판단기는 동승자 인원 변화 예측 결과와 경 유지 출발 후 동승자 인원 변화 결과가 비교되어 선발화 조건을 만족하는 경우, 경유지 출발 후인 경우에 의한 선발화 상황인 것으로 판단하고, 선발화 트리거 신호를 발생시킬 수 있다.선발화 판단기는 선발화 트리거 신호를 저장된 선발화 메시지와 함께 대화 입력 관리기(111c)로 전달 수 있다. 일 예로, 경유지 도착 후인 경우에 의한 선발화 상황에서는 “현재 동승자는 동승자 인원 변화 예측 결과 와 상이합니다\"와 같이 동승자 인원 변화 예측 결과와 경유지 출발 후 동승자 인원 변화가 상이함을 나타내는 선발화 메시지가 대화 입력 관리기(111c)로 전달될 수 있고, \"현재 동승자는 동승자 인원 변화 예측 결과와 동 일합니다\"와 같이 동승자 인원 변화 예측 결과와 경유지 출발 후 동승자 인원 변화 결과가 동일함을 나타내는 선발화 메시지가 대화 입력 관리기(111c)로 전달될 수 있다. 또한, 상황 정보가 동승자 탑승 여부인 경우에, 탑승이 판단된 동승자의 특성이 저장된 동승자 정보와 동일한 경우에 선발화 조건을 만족할 수 있다. 선발화 판단기는 동승자의 인원 변화가 예측되어 선발화 조건을 만 족하는 경우, 동승자의 탑승에 의한 선발화 상황인 것으로 판단하고, 선발화 트리거 신호를 발생시킬 수 있다. 선발화 판단기는 선발화 트리거 신호를 저장된 선발화 메시지와 함께 대화 입력 관리기(111c)로 전달 수 있다. 일 예로, 동승자의 탑승에 의한 선발화 상황에서는 “혹시 OO님 아니세요?”와 같이 동승자가 이전 주행 참여 동승자인지 여부를 확인하기 위한 내용의 선발화 메시지가 대화 입력 관리기(111c)로 전달될 수 있다. 이와 같이, 대화 시스템은 차량 내 동승자의 탑승 여부를 판단하고 선발화 조건 테이블(145a)을 이용하여 동승자 식별을 위한 선발화를 출력할 수 있다. 구체적으로, 대화 시스템은 차량 내 탑승자 간 대화 및 차량 조작 정보 중 적어도 하나에 기초하여 동승자 의 탑승을 판단할 수 있다. 예를 들어, 대화 시스템은 음성 입력 처리기에 입력된 차량 내 탑승자 간 대화에 기초하여 동승자의 탑승을 판단할 수 있다. 차량 내 탑승자는 운전자 및 적어도 하나의 동승자를 포함하 고, 차량 조작 정보는 음성 외 입력 장치의 조작 정보를 포함할 수 있다. 대화 시스템의 동승자의 탑승 판단은 차랑의 주행 시작 이후 일정시간 동안 또는 차량의 정차 이후 일정시간 동안 수행될 수 있다. 음성 입력 처리기는 차량에 마련된 음성 입력 장치 또는 모바일 기기에 마련된 음성 입력 장치를 통해 입력된 차량 내 탑승자 간 대화에 기초하여 동승자 각각의 음성을 구분할 수 있다. 구체적으 로, 음성 입력 처리기는 음성입력장치를 통해 입력된 동승자 각각의 음성의 비언어적 음성학 특성 및 언어적 특성에 기초하여 동승자 각각의 음성을 비교하여, 동승자 각각의 음성을 구분할 수 있다. 비언어적 음성 학 특성은 동승자 음성의 높낮이, 세기, 숨쉬기, 빠르기 등을 포함할 수 있다. 언어적 특성은 동승자 음성의 사 투리, 은어, 억양 등을 포함할 수 있다. 따라서, 음성 입력 처리기는 음성 입력 장치 또는 모바일 기기에 마련된 음성 입력 장치를 통해 입력된 동승자 각각의 음성을 음성 특성 정보에 기초하여 구분하여, 동승자 각각의 탑승을 판단할 수 있다. 음성 특성 정보는 비언어적 특성 및 언어적 특성 중 적어도 하나를 포함할 수 있다. 동승자의 탑승을 판단하기 위해 음성 입력 처리기가 입력 받은 차량 내 탑승자 간 대화는 차량에 의 도를 전달하는 발화가 아닌 운전자를 포함한 차량 내 탑승자 간의 대화를 의미할 수 있다. 또한, 대화 시스템의 상황 정보 처리기는 차량 조작 정보에 기초하여 동승자의 탑승을 판단할 수 있 다. 즉, 대화 시스템은 대화에 참여하지 않아 음성 입력 처리기를 통해 탑승을 판단하지 못한 동승자 가 존재하는지 여부를 확인하기 위해 차량 조작 정보에 기초하여 동승자의 탑승을 판단할 수 있다. 구체적으로, 상황 정보 처리기는 동승자의 음성 외 입력장치 조작을 감지할 수 있다. 음성 외 입력 장치는 동승자의 차량 내 탑승 및 착석 위치를 판단하기 위해 조수석(245b) 및 후열 시트(254c, 254d) 각 각에 마련된 윈도우 조정 버튼, 시트 조정 버튼, 공조 장치 조정 버튼 등을 포함할 수 있다. 상황 정보 처리기 는 음성 외 입력장치 조작을 감지하는 경우, 음성 외 입력장치 조작에 기초하여 차량 조작 정보 를 획득할 수 있다. 차량 조작 정보는 조수석(245b) 및 후열 시트(254c, 254d) 각각에 대한 윈도우 조정 버튼 조작 정보, 시트 조정 버튼 조작 정보 및 공조 장치 조정 버튼 조작 정보 중 적어도 하나를 포함할 수 있다. 상황 정보 처리기는 차량 조작 정보에 기초하여 동승자의 탑승을 판단할 수 있다. 즉, 입력 처리기는 음성 입력 처리기 및 상황 정보 처리기 중 적어도 하나를 통해 동승자가 탑 승한 상황이나 동승자가 탑승하지 않은 상황을 나타내는 동승자 탑승 정보를 수집할 수 있다. 차랑의 주행 시작 이후 일정시간 동안 또는 차량의 정차 이후 일정시간 동안 동승자의 탑승을 판단한 경우, 대화 시스템은 신원 정보 요청을 위한 선발화를 출력할 수 있다. 구체적으로, 대화 시스템은 동승자의 탑승을 판단한 경우, 동승자의 신원 정보를 요청하기 위한 선발화를 출력할 수 있다. 예를 들어, 대화 시스템은 동승자의 탑승을 판단한 경우, \"누구세요? 이름을 말씀해 주세요\"와 같이 동승 자의 신원 정보를 요청하기 위한 내용의 선발화를 출력할 수 있다. 입력 처리기의 선발화 판단기는 동승자 탑승 여부의 상황 정보에 기초하여 동승자의 탑승이 판단되었 는지 여부를 선발화 조건으로 선발화 출력 여부를 판단한다. 또한, 선발화 판단기는 동승자 탑승 여부의 상황 정보가 동승자의 탑승 판단이라는 선발화 조건을 만족하면, 선발화 상황인 것으로 판단하고 선발화 트리거 신호를 생성한다. 선발화 판단기는 \"누구세요? 이름을 말씀해 주세요\"와 같이 동승자가 탑승한 선발화 상황에 대응되는 선발 화 메시지를 추출한다. 선발화 판단기가 선발화 트리거 신호와 선발화 메시지를 대화 입력 관리기(111c)에 전달하면, 대화 입력 관리기(111c)는 대화 관리기에 선발화 메시지를 전달한다. 이 때, 선발화 트리거 신 호 또는 선발화 상황임을 나타내는 신호가 함께 전달되는 것도 가능하다. 대화 관리기는 전달된 선발화 메시지를 출력하기 위한 대화 태스크를 생성하고, 선발화 메시지를 결과 처 리기에 전달할 수 있다. 결과 처리기는 입력된 선발화 메시지를 스피커를 통해 출력할 수 있다. 대화 시스템은 동승자의 발화를 입력 받아 동승자를 식별할 수 있다. 구체적으로, 대화 시스템은 선 발화 메시지에 대한 동승자의 발화를 입력 받아 동승자를 식별할 수 있다. 예를 들어, 동승자는 동승자의 신원 정보 요청을 나타내는 선발화 메시지에 응답하여 \"나는 OO이야\"라고 발화할 수 있다. 즉, 동승자는 신원 정보를 요청하는 선발화 메시지에 응답하여 동승자 자신의 이름을 포함하는 메시지 를 발화할 수 있다. 동승자의 발화가 입력되면, 음성 입력 처리기가 입력된 동승자의 발화를 인식한다. 동승자의 발화는 차량 에 마련된 음성 입력 장치 또는 모바일 기기에 마련된 음성 입력 장치를 통해 입력될 수 있다. 음성 인식기(111a)는 입력된 동승자의 발화를 인식하여 텍스트 형태의 발화문으로 출력한다. 자연어 이해기 (111b)는 텍스트 형태의 발화문에 자연어 이해 기술을 적용하여, 그 결과를 출력한다. 자연어 이해 과정은 텍스트 형태의 발화문에 기초하여 형태소 분석을 수행하고, 형태소 분석 결과에 기초하여 이름을 인식하는 것을 포함할 수 있다. 또한, 자연어 이해기(111b)는 이름의 인식률을 높이기 위해 장기 메모리에 저장되어 있는 운전자의 전화번 호부를 이용할 수 있다. 구체적으로, 자연어 이해기(111b)는 동승자의 발화에 포함된 이름과 전화번호부에 포함 된 이름을 비교하여 동승자의 발화에 포함된 이름의 인식률을 높일 수 있다. 동승자 판단기(111d)는 자연어 이해기(111b)의 출력을 기반으로, 동승자의 이름을 확인할 수 있으며, 이를 통해 동승자의 신원을 식별할 수 있다. 이를 통해, 대화 시스템은 동승자의 발화에 기초하여 메시지를 발화한 동승자의 신원을 식별할 수 있다. 또한, 대화 시스템은 동승자의 발화의 방향 및 크기에 기초하여 발화가 발생하는 위치를 추정하여 동승자 의 차량 내 착석 위치를 판단할 수 있으며, 조수석(245b) 및 후열 시트(254c, 254d) 각각에 마련된 윈도우 조정 버튼, 시트 조정 버튼 및 공조 장치 조정 버튼에 대한 차량 조작 정보에 기초하여 동승자의 차량 내 착석 위치 를 판단할 수 있다. 이를 통해, 대화 시스템은 동승자와 차량 내 착석 위치를 매핑하여 동승자 각각의 착 석 위치 정보를 생성할 수 있다. 또한, 대화 시스템은 주행 중 동승자가 착석 위치를 변경하는 경우, 동승자의 발화 및 차량 조작 정보에 기초하여 동승자의 착석 위치 변경을 추정할 수 있으며, 동승자의 변경된 착석 위치를 결정할 수 있다. 이 경우, 대화 시스템은 동승자의 변경된 착석 위치를 반영한 착석 위치 정보를 생성할 수 있다. 식별된 동승자에 대한 동승자 정보는 저장부에 실시간으로 저장될 수 있으며, 동승자 정보는 개인 식별 정 보, 음성 특성 정보 및 착석 위치 정보를 포함할 수 있다.동승자의 탑승을 판단하지 못한 경우, 대화 시스템은 동승자 존재 여부 확인을 위한 선발화를 출력할 수 있다. 구체적으로, 대화 시스템은 차랑의 주행 시작 이후 일정시간 동안 또는 차량의 정차 이후 일정시간 동안 동승자의 탑승을 판단하지 못한 경우, 동승자 존재 여부를 확인하기 위한 선발화를 출력할 수 있 다. 예를 들어, 대화 시스템은 차랑의 주행 시작 이후 일정시간 동안 또는 차량의 정차 이후 일정시 간 동안 동승자의 탑승을 판단하지 못한 경우, \"더 타실 분은 없으신가요?”와 같이 운전자에게 동승자 존재 여 부를 확인하기 위한 내용의 선발화를 출력할 수 있다. 선발화 판단기는 동승자 탑승 여부의 상황 정보에 기초하여 동승자의 비-탑승을 선발화 조건으로 선발화 출력 여부를 판단한다. 또한, 선발화 판단기는 동승자 탑승 여부의 상황 정보가 동승자의 탑승이 판단되지 않은 선발화 조건을 만족하면, 선발화 상황인 것으로 판단하고 선발화 트리거 신호를 생성한다. 선발화 판단기는 \"더 타실 분은 없으신가요?\"와 같이 동승자가 탑승하지 않은 선발화 상황에 대응되는 선 발화 메시지를 추출한다. 선발화 판단기가 선발화 트리거 신호와 선발화 메시지를 대화 입력 관리기(111 c)에 전달하면, 대화 입력 관리기(111c)는 대화 관리기에 선발화 메시지를 전달한다. 이 때, 선발화 트리 거 신호 또는 선발화 상황임을 나타내는 신호가 함께 전달되는 것도 가능하다. 대화 관리기는 전달된 선발화 메시지를 출력하기 위한 대화 태스크를 생성하고, 선발화 메시지를 결과 처 리기에 전달할 수 있다. 결과 처리기는 입력된 선발화 메시지를 스피커를 통해 출력할 수 있다. 대화 시스템은 운전자의 발화를 입력 받아 동승자 존재 여부를 확인할 수 있다. 구체적으로, 대화 시스템 은 선발화 메시지에 대응한 운전자의 발화를 입력 받아 동승자 존재 여부를 확인할 수 있다. 예를 들어, 운전자는 동승자 존재 여부를 묻는 선발화 메시지에 응답하여 \"없어\"라고 발화하거나 \"있어\"라고 발 화할 수 있다. 즉, 운전자는 동승자 존재 여부를 묻는 선발화 메시지에 응답하여 동승자 존재 여부를 나타내는 응답을 포함하는 메시지를 발화할 수 있다. 운전자의 발화가 입력되면, 음성 입력 처리기가 입력된 운전자의 발화를 인식한다. 운전자의 응답은 차량 에 마련된 음성 입력 장치 또는 모바일 기기에 마련된 음성 입력 장치를 통해 입력될 수 있다. 음성 인식기(111a)는 입력된 사용자의 발화를 인식하여 텍스트 형태의 발화문으로 출력한다. 자연어 이해기 (111b)는 텍스트 형태의 발화문에 자연어 이해 기술을 적용하여, 그 결과를 출력한다. 자연어 이해기(111b)는 발화문으로부터 개체명을 인식할 수 있다. 개체명은 인명, 지명, 조직명, 시간, 날짜, 화폐 등의 고유 명사로서, 개체명 인식은 문장에서 개체명을 식별하고 식별된 개체명의 종류를 결정하는 작업이 다. 개체명 인식을 통해 문장에서 중요한 키워드를 추출하여 문장의 의미를 파악할 수 있다. 구체적으로, 자연어 이해 과정은 텍스트 형태의 발화문에 기초하여 형태소 분석을 수행하고, 형태소 분석 결과 에 기초하여 개체명을 인식하는 것을 포함할 수 있다. 자연어 이해기(111b)의 출력, 즉 자연어 이해 결과는 동승자의 발화에 대응되는 개체명, 형태소 분석 결과 등을 포함할 수 있다. 동승자 판단기(111d)는 자연어 이해기(111b)의 출력을 기반으로, 동승자 존재 여부를 식별할 수 있다. 이를 통해, 음성 입력 처리기는 운전자의 발화에 기초하여 동승자 존재 여부를 확인할 수 있다. 대화 시스템은 동승자를 식별함으로써 후술하는 바와 같이, 경유지에서의 동승자 각각의 하차 가능성 및 하차 후 재탑승 가능성을 예측하고 안내할 수 있다. 또한, 대화 시스템은 차랑의 주행 시작 이후 일정시간 동안 또는 차량의 정차 이후 일정시간 동 안 차량 내 탑승자 간 대화 및 차량 조작 정보에 기초하여 동승자를 식별하는 과정을 수행함으로써, 지속적으로 신규 탑승객을 식별할 수 있다. 또한, 이미 탑승하고 있는 동승자에 대해 대화 시스템이 신규 동승자로 잘못 인식하여 선발화를 출력하는 경우, 동승자는 자신의 이름을 포함한 메시지를 발화하여 자신이 기존의 동승자임을 확인시킬 수 있다. 또한, 대화 시스템은 동승자 인원 변화를 예측하고 선발화 조건 테이블(145a)을 이용하여 동승자 인원 변 화 예측 결과에 대한 선발화를 출력할 수 있다. 구체적으로, 대화 시스템은 앞서 설명한 바와 같이 동승자를 식별할 수 있다. 대화 시스템은 차량 내 탑승자 간 대화 및 차량 조작 정보 중 적어도 하나에 기초하여 동승자의 탑승을 판단하고, 선발화를 통해 동승 자를 식별할 수 있다. 대화 시스템은 차량 내 탑승자 간 대화에 기초하여 동승자 인원 정보를 생성할 수 있다. 구체적으로, 대화 시스템은 차량 내 탑승자 간 대화를 지속적으로 입력 받아 특정 경유지에서의 동승자 각각의 하차 가능성 및 하차 후 재탑승 가능성을 판단할 수 있다. 예를 들어, 대화 시스템 상의 음성 입력 처리기는 차량에 마련된 음성 입력 장치 또는 모 바일 기기에 마련된 음성 입력 장치를 통해 차량 내 탑승자 간 대화를 지속적으로 입력 받을 수 있다. 음성 인식기(111a)는 입력된 사용자의 발화를 인식하여 텍스트 형태의 발화문으로 출력한다. 자연어 이해기 (111b)는 텍스트 형태의 발화문에 자연어 이해 기술을 적용하여, 그 결과를 출력한다. 자연어 이해기(111b)는 발화문으로부터 개체명을 인식할 수 있다. 개체명은 인명, 지명, 조직명, 시간, 날짜, 화폐 등의 고유 명사로서, 개체명 인식은 문장에서 개체명을 식별하고 식별된 개체명의 종류를 결정하는 작업이 다. 개체명 인식을 통해 문장에서 중요한 키워드를 추출하여 문장의 의미를 파악할 수 있다. 구체적으로, 자연어 이해 과정은 텍스트 형태의 발화문에 기초하여 형태소 분석을 수행하고, 형태소 분석 결과 에 기초하여 개체명을 인식하는 것을 포함할 수 있다. 자연어 이해기(111b)의 출력, 즉 자연어 이해 결과는 동승자의 발화에 대응되는 개체명, 형태소 분석 결과 등을 포함할 수 있다. 동승자 판단기(111d)는 자연어 이해기(111b)의 출력을 기반으로, 동승자 인원 변화를 예측한다. 구체적으로, 동 승자 판단기(111d)는 동승자의 발화를 분석하여 특정 경유지에서의 동승자 인원 변화를 예측할 수 있다. 예를 들어, 특정 동승자가 \"나 곧 서울역에서 내려\"와 같이 특정 경유지에서 하차할 것임을 나타내는 메시지를 발화한 경우, 음성 인식기(111a)는 입력된 특정 동승자의 발화를 텍스트 형태의 발화문으로 출력하며, 자연어 이해기(111b)는 텍스트 형태의 발화문에 자연어 이해 기술을 적용하여, 그 결과를 출력한다. 구체적으로, 자연어 이해기(111b)는 개체명에 해당하는 \"서울역\"을 포함하여 \"나\", \"곧\", \"서울역\" 및 \"내려\" 로 나타낼 수 있는 형태소 분석 결과를 출력한다. 동승자 판단기(111d)는 자연어 이해기(111b)의 개체명, 형태소 분석 결과에 기초하여 특정 동승자가 특정 경유 지에서 하차할 것임을 예측할 수 있다. 구체적으로, 동승자 판단기(111d)는 특정 동승자가 \"나 곧 서울역에서 내려\"와 같이 특정 경유지에서 하차할 것 임을 나타내는 메시지를 발화한 경우, 특정 동승자가 멀지 않은 시점에서 서울역에서 하차할 것임을 예측할 수 있다. 즉, 동승자 판단기(111d)는 특정 경유지에서의 특정 동승자의 하차 가능성 및 시점을 예측할 수 있다. 또한, 특정 동승자가 \"나 서울역에서 내렸다가 다시 탈게\"와 같이 특정 경유지에서 하차한 후 다시 탑승할 것임 을 나타내는 메시지를 발화한 경우, 자연어 이해기(111b)는 개체명에 해당하는 \"서울역\"을 포함하여 \"나\", \"서 울역\", \"내렸다가\", \"다시\" 및 \"탈게\"로 나타낼 수 있는 형태소 분석 결과를 출력한다. 동승자 판단기(111d)는 자연어 이해기(111b)의 개체명, 형태소 분석 결과에 기초하여 특정 동승자가 특정 경유 지에서 하차한 후 재탑승할 것임을 예측할 수 있다. 구체적으로, 동승자 판단기(111d)는 특정 동승자가 \"나 서울역에서 내렸다가 다시 탈게\"와 같이 특정 경유지에 서 하차 후 다시 탑승할 것임을 나타내는 메시지를 발화한 경우, 특정 동승자가 서울역에서 하차한 후 재탑승할 것임을 예측할 수 있다. 즉, 동승자 판단기(111d)는 특정 동승자의 하차 후 재탑승 가능성을 예측할 수 있다. 또한, 대화 시스템은 차량 내 통화 내용을 입력 받아 통화 상대방의 탑승 가능성을 판단하여 탑승 예정 인 원을 예측할 수 있다. 구체적으로, 차량 내 탑승자가 통화 중 \"곧 서울역에서 만나자\"와 같이 탑승예정자가 특정 경유지에서 탑승할 것임을 나타내는 메시지를 발화한 경우, 자연어 이해기(111b)는 개체명에 해당하는 \"서울역\"을 포함하여 \"곧\",\"서울역\", \"만나자\"로 나타낼 수 있는 형태소 분석 결과를 출력한다. 동승자 판단기(111d)는 자연어 이해기(111b)의 개체명, 형태소 분석 결과에 기초하여 탑승예정자가 특정 경유지 에서 탑승할 것임을 예측할 수 있다. 구체적으로, 동승자 판단기(111d)는 차량 내 탑승자가 통화 중 \"곧 서울역에서 만나자\"와 같이 탑승예정자가 특 정 경유지에서 탑승할 것임을 나타내는 메시지를 발화한 경우, 탑승예정자가 서울역에서 탑승할 것임을 예측할 수 있다. 즉, 동승자 판단기(111d)는 탑승예정자의 탑승 가능성을 예측할 수 있다. 탑승예정자의 탑승 가능성을 예측한 경우, 대화 시스템은 탑승예정자 탑승 가능성을 확인하기 위한 선발화 를 출력할 수 있다. 예를 들어, 대화 시스템은 탑승예정자의 탑승 가능성을 예측한 경우, \"누가 중간에 탑승하나요? 이름을 말 씀해 주세요”와 같이 탑승예정자 탑승 가능성을 확인하기 위한 내용의 선발화를 출력할 수 있다. 선발화 판단기는 탑승예정자 탑승 예정 여부의 상황 정보에 기초하여 탑승가능성 예측을 선발화 조건으로 선발화 출력 여부를 판단한다. 또한, 선발화 판단기는 탑승예정자 탑승 예정 여부의 상황 정보가 탑승 가 능성 예측을 선발화 조건을 만족하면, 선발화 상황인 것으로 판단하고 선발화 트리거 신호를 생성한다. 선발화 판단기는 \"누가 중간에 탑승하나요? 이름을 말씀해주세요\"와 같이 탑승예정자가 탑승할 예정인 선 발화 상황에 대응되는 선발화 메시지를 추출한다. 선발화 판단기가 선발화 트리거 신호와 선발화 메시지를 대화 입력 관리기(111c)에 전달하면, 대화 입력 관리기(111c)는 대화 관리기에 선발화 메시지를 전달한다. 이 때, 선발화 트리거 신호 또는 선발화 상황임을 나타내는 신호가 함께 전달되는 것도 가능하다. 대화 관리기는 전달된 선발화 메시지를 출력하기 위한 대화 태스크를 생성하고, 선발화 메시지를 결과 처 리기에 전달할 수 있다. 결과 처리기는 입력된 선발화 메시지를 스피커를 통해 출력할 수 있다. 대화 시스템은 차량 내 탑승자의 발화를 입력 받아 탑승예정자의 탑승가능성을 확인할 수 있다. 구체적으 로, 대화 시스템은 선발화 메시지에 대응한 차량 내 탑승자의 발화를 입력 받아 탑승예정자 존재 여부를 확인할 수 있다. 동승자 판단기(111d)는 자연어 이해기(111b)의 출력을 기반으로, 차량 내 동승자 인원 변화를 예측한다. 구체적 으로, 동승자 판단기(111d)는 차량 내 탑승자 간의 대화에 기초하여 동승자 각각의 하차 가능성 및 하차 후 재 탑승 가능성을 예측할 뿐만 아니라, 차량 내 통화 내용에 기초하여 탑승 예정 인원을 예측할 수 있다. 동승자 판단기(111d)는 동승자 인원 변화 예측 결과에 기초하여 동승자 인원 정보를 생성할 수 있다. 즉, 동승자 판단기(111d)는 경유지에서의 동승자 각각의 하차 가능성, 경유지에서의 동승자 각각의 하차 후 재 탑승 가능성 및 경유지에서의 탑승예정자의 탑승 가능성에 기초하여 동승자 인원 정보를 생성할 수 있다. 대화 시스템은 경유지 도착 전, 동승자 인원 정보에 기초하여 동승자 인원 변화 예측 결과에 관한 선발화 를 출력할 수 있다. 예를 들어, 대화 시스템은 경유지에 도착 전이라고 판단한 경우, \"A는 경유지에서 하차합니다. B는 경유지 에서 하차 후 재탑승합니다. C는 경유지에서 하차하지 않습니다. D는 경유지에서 탑승합니다\"와 같이 동승자 인 원 변화 예측 결과에 관한 내용의 선발화를 출력할 수 있다. 즉, 대화 시스템은 경유지 도착 전, 동승자 인원 정보에 포함된 경유지에서의 동승자 각각의 하차 가능성, 재탑승 가능성 및 탑승 가능성에 관한 내용의 선발화를 출력할 수 있다. 다만, 대화 시스템은 경유지 도착 전 뿐만 아니라, 경유지 도착 직후에도 동승자 인원 변화 예측 결과에 관한 내용의 선발화를 출력할 수 있다. 또한, 경유지에서의 동승자 각각의 하차 가능성, 재탑승 가능성 및 탑승 가능성에 관한 내용은 \"다음에 또 만나 요\"와 같이 하차 인원에 대한 메시지, \"어서 다녀오세요\"와 같이 하차 후 재탑승 인원에 대한 메시지 등을 포함 할 수 있다. 대화 시스템은 차량 감지부가 감지한 차량의 위치, 차량 속도 등과 같은 차량 상태 정보에 기초하여 차량의 경유지 도착 직전 또는 도착 직후인지 여부를 판단할 수 있다. 구체적으로, 대화 시스템은 기어가 P단에 위치하는 경우, 차량이 경유지에 도착한 것으로 판단할 수 있으며, 속도가 10kph이하인 경우, 차량이 경유지에 도착 직전인 것으로 판단할 수 있다. 선발화 판단기는 경유지 도착 전이라는 상황 정보에 기초하여 동승자 인원 변화 예측을 선발화 조건으로 선발화 출력 여부를 판단한다. 선발화 판단기는 동승자 판단기(111d)로부터 전달받은 동승자 인원 정보에 기초하여 동승자 인원 변화 예측의 선발화 조건이 만족됨을 판단할 수 있다. 또한, 선발화 판단기는 경유 지 도착 전이라는 상황 정보가 동승자 인원 변화 예측의 선발화 조건을 만족하면, 선발화 상황인 것으로 판단하 고 선발화 트리거 신호를 생성한다. 선발화 판단기는 동승자 인원 정보에 기초하여 \"A는 경유지에서 하차합니다. B는 경유지에서 하차 후 재탑 승합니다. C는 경유지에서 하차하지 않습니다. D는 경유지에서 탑승합니다\"와 같이 동승자 인원 변화가 예측되 는 선발화 상황에 대응되는 선발화 메시지를 추출한다. 선발화 판단기가 선발화 트리거 신호와 선발화 메 시지를 대화 입력 관리기(111c)에 전달하면, 대화 입력 관리기(111c)는 대화 관리기에 선발화 메시지를 전 달한다. 이 때, 선발화 트리거 신호 또는 선발화 상황임을 나타내는 신호가 함께 전달되는 것도 가능하다. 대화 관리기는 전달된 선발화 메시지를 출력하기 위한 대화 태스크를 생성하고, 선발화 메시지를 결과 처 리기에 전달할 수 있다. 결과 처리기는 입력된 선발화 메시지를 스피커를 통해 출력할 수 있다. 대화 시스템은 동승자 인원 정보에 기초하여 동승자 인원 변화 예측 결과와 경유지 출발 후 동승자 인원 변화 결과를 비교할 수 있다. 대화 시스템은 차량 감지부가 감지한 차량의 위치, 차량 속도 등과 같은 차량 상태 정보에 기초하여 차량의 경유지 출발 여부를 판단할 수 있다. 구체적으로, 대화 시스템은 파킹 브레이크가 해제되거나, 시동이 온(ON)되거나, 브레이크 페달이 온(ON)되 는 것 등에 기초하여 차량이 경유지를 출발한 것으로 판단할 수 있다. 대화 시스템은 경유지 출발 후 동승자 인원 변화 결과를 판단하기 위해 음성 인식 처리기 및 상황 정 보 처리기를 통해 동승자를 감지할 수 있으며, 동승자 판단기(111d)를 통해 동승자를 식별할 수 있다. 따라서, 챠량이 경유지를 출발한 것으로 판단한 경우, 대화 시스템의 동승자 판단기(111d)는 동승자 인원 정보에 기초한 동승자 인원 변화 예측 결과와 경유지 출발 후 동승자 인원 변화 결과를 비교할 수 있다. 또한, 대화 시스템은 동승자 인원 변화 예측 결과와 경유지 출발 후 동승자 인원 변화 결과를 비교하기 위 해 선발화를 출력할 수 있습니다. 예를 들어, 대화 시스템은 경유지 출발 후 동승자 인원 변화 결과를 확인하기 위해, 동승자 인원 변화 예 측 결과가 맞는지 확인하는 내용의 선발화를 출력할 수 있다. 구체적으로, 대화 시스템은 \"A는 가셨지 요?\"와 같이 경유지에서 하차할 것으로 판단한 동승자가 경유지에서 하차하였는지 여부를 판단하는 내용의 선발 화를 출력할 수 있고, \"B는 다시 타셨지요?\"와 같이 경유지에서 하차 후 재탑승할 것으로 판단한 동승자가 경유 지에서 재탑승하였는지 여부를 판단하는 내용의 선발화를 출력할 수 있다. 또한, 대화 시스템은 \"C는 남아계시지요?\"와 같이 경유지에서 하차하지 않을 것으로 판단한 동승자가 경유 지에서 하차하지 않았는지 여부를 판단하는 내용의 선발화를 출력할 수 있고, \"D는 탑승 하셨지요?\"와 같이 경 유지에서 탑승할 것으로 판단한 탑승예정자가 탑승하였는지 여부를 판단하는 내용의 선발화를 출력할 수 있다. 선발화 판단기는 경유지 출발 후의 상황 정보에 기초하여 동승자 인원 변화가 예측되었는지 여부를 선발화 조건으로 선발화 출력 여부를 판단한다. 선발화 판단기는 동승자 판단기(111d)로부터 전달받은 동승자 인 원 정보에 기초하여 동승자 인원 변화 예측의 선발화 조건이 만족됨을 판단할 수 있다. 또한, 선발화 판단기 는 경유지 출발 후의 상황 정보가 동승자 인원 변화 예측의 선발화 조건을 만족하면, 선발화 상황인 것으 로 판단하고 선발화 트리거 신호를 생성한다. 선발화 판단기는 동승자 인원 변화에 대응되는 선발화 메시지를 추출한다. 선발화 판단기가 선발화 트리거 신호와 선발화 메시지를 대화 입력 관리기(111c)에 전달하면, 대화 입력 관리기(111c)는 대화 관리기 에 선발화 메시지를 전달한다. 이 때, 선발화 트리거 신호 또는 선발화 상황임을 나타내는 신호가 함께 전 달되는 것도 가능하다. 대화 관리기는 전달된 선발화 메시지를 출력하기 위한 대화 태스크를 생성하고, 선발화 메시지를 결과 처 리기에 전달할 수 있다. 결과 처리기는 입력된 선발화 메시지를 스피커를 통해 출력할 수 있다.대화 시스템은 차량 내 탑승자의 발화를 입력 받아 동승자 인원 변화 결과를 확인할 수 있다. 구체적으로, 대화 시스템의 동승자 판단기(111d)는 선발화 메시지에 대응한 차량 내 탑승자의 발화를 입력 받아 동승자 인원 변화 결과를 확인할 수 있다. 예를 들어, 차량 내 탑승자는 \"A는 가셨지요?\"와 같이 경유지에서 하차할 것으로 판단한 동승자가 경유지에서 하차하였는지 여부를 묻는 선발화 메시지에 응답하여 \"그래 갔어\"라고 발화하거나 \"아니 탔어\"라고 발화할 수 있다. 즉, 차량 내 탑승자는 경유지에서 하차할 것으로 판단한 동승자가 경유지에서 하차하였는지 여부를 묻는 선발화 메시지에 응답하여 동승자 인원 변화를 나타내는 메시지를 발화할 수 있다. 차량 내 탑승자의 발화가 입력되면, 음성 입력 처리기가 입력된 차량 내 탑승자의 발화를 인식한다. 차량 내 탑승자의 발화는 차량에 마련된 음성 입력 장치 또는 모바일 기기에 마련된 음성 입력 장치 를 통해 입력될 수 있다. 음성 인식기(111a)는 입력된 차량 내 탑승자의 발화를 인식하여 텍스트 형태의 발화문으로 출력한다. 자연어 이 해기(111b)는 텍스트 형태의 발화문에 자연어 이해 기술을 적용하여, 그 결과를 출력한다. 구체적으로, 자연어 이해 과정은 텍스트 형태의 발화문에 기초하여 형태소 분석을 수행하고, 형태소 분석 결과 에 기초하여 동승자 인원 변화를 인식하는 것을 포함할 수 있다. 이를 통해, 음성 입력 처리기의 동승자 판단기(111d)는 차량 내 탑승자의 발화에 기초하여 동승자 인원 변 화 결과를 확인할 수 있다. 대화 시스템은 동승자 인원 변화 예측 결과와 경유지 출발 후 동승자 인원 변화 결과의 비교 결과에 관한 선발화를 출력할 수 있다. 예를 들어, 대화 시스템은 \"현재 동승자는 동승자 인원 변화 예측 결과와 상이합니다\"와 같이 동승자 인원 변화 예측 결과와 경유지 출발 후 동승자 인원 변화 결과가 상이함을 나타내는 선발화 메시지를 출력할 수 있고, \"현재 동승자는 동승자 인원 변화 예측 결과와 동일합니다\"와 같이 동승자 인원 변화 예측 결과와 경유지 출발 후 동승자 인원 변화 결과가 동일함을 나타내는 선발화 메시지를 출력할 수 있다. 구체적으로, 선발화 판단기는 경유지 출발 후의 상황 정보에 기초하여 동승자 인원 변화 예측 결과와 경유 지 출발 후 동승자 인원 변화 결과가 비교되었는지 여부를 선발화 조건으로 선발화 출력 여부를 판단한다. 선발 화 판단기는 동승자 판단기(111d)로부터 전달받은 동승자 인원 변화 예측 결과와 경유지 출발 후 동승자 인원 변화 결과의 비교 결과에 기초하여 선발화 조건이 만족됨을 판단할 수 있다. 또한, 선발화 판단기는 경유지 출발 후의 상황 정보가 동승자 인원 변화 예측 결과와 경유지 출발 후 동승자 인원 변화 결과의 비교의 선발화 조건을 만족하면, 선발화 상황인 것으로 판단하고 선발화 트리거 신호를 생성한다. 선발화 판단기는 동승자 인원 변화 예측 결과와 경유지 출발 후 동승자 인원 변화 결과의 비교 결과에 기 초하여 비교 결과를 나타내는 선발화 메시지를 추출한다. 선발화 판단기가 선발화 트리거 신호와 선발화 메시지를 대화 입력 관리기(111c)에 전달하면, 대화 입력 관리기(111c)는 대화 관리기에 선발화 메시지를 전달한다. 이 때, 선발화 트리거 신호 또는 선발화 상황임을 나타내는 신호가 함께 전달되는 것도 가능하다. 대화 관리기는 전달된 선발화 메시지를 출력하기 위한 대화 태스크를 생성하고, 선발화 메시지를 결과 처 리기에 전달할 수 있다. 결과 처리기는 입력된 선발화 메시지를 스피커를 통해 출력할 수 있다. 따라서, 운전자는 대화 시스템의 동승자 인원 변화 예측 결과와 경유지 출발 후 동승자 인원 변화 결과의 비교 결과를 통해 동승자 각각의 하차 또는 탑승 여부를 확인할 수 있으며, 동승자 각각의 하차 또는 탑승에 집 중하지 않고, 주행 및 주차 등 차량 관리임무에 집중할 수 있다. 또한, 동승자는 경유지 도착 시 재탑승을 못해 원치 않게 남겨지거나, 하차하지 못하는 상황을 피할 수 있다. 대화 시스템은 차량의 주행 종료 시, 주행 관련 정보 및 동승자 각각에 대한 동승자 정보를 저장할 수 있 다. 예를 들어, 대화 시스템의 저장부는 차량의 주행이 종료한 경우, 차량의 주행에 대한 주행 관련 정보 및 차량이 주행하는 동안 탑승한 동승자 각각에 대한 동승자 정보를 저장할 수도 있다. 구체적으로, 대화 시스템의 저장부는 주행의 출발지, 경유지 및 도착지와 같은 차량의 주행에 대한 주행 관련 정보를 저장하고, 개인 식별 정보, 음성 특성 정보, 착석 위치 정보, 탑승 시각 정보, 하차 시각 정보, 탑승 장소 정보 및 하차 장소 정보 등과 같은 동승자 각각에 대한 동승자 정보를 저장할 수도 있다. 즉, 대화 시스템의 저장부는 차량 제어기로부터 GPS 값을 수집하여 주행의 출발지, 경유지 및 도착지와 같은 차량의 주행에 대한 주행 관련 정보를 저장할 수 있다. 또한, 대화 시스템의 저장부는 입력 처리기로부터 동승자 식별 정보, 음성 특성 정보, 착석 위 치 정보, 동승자 인원 정보 등을 수집하여 동승자 식별 정보, 음성 특성 정보, 착석 위치 정보, 탑승 시각 정보, 탑승 장소 정보, 하차 시각 정보 및 하차 장소 정보 등과 같은 동승자 각각에 대한 동승자 정보를 저장할 수 있다. 또한, 대화 시스템은 동승자의 탑승을 판단하고 선발화 조건 테이블(145a)을 이용하여 이전 주행에 참여한 동승자 식별을 위한 선발화를 출력할 수 있다. 구체적으로, 대화 시스템은 차량 내 탑승자 간 대화 및 차량 조작 정보에 기초하여 동승자의 탑승 여부를 판단할 수 있다. 구체적으로, 대화 시스템의 음성 입력 처리기는 차량 내 탑승자 간 대화를 입력 받 아 차량 내 탑승한 동승자의 탑승을 판단하고, 동승자 각각의 음성 특성, 착석 위치, 탑승 시각, 탑승 장소 등 의 특성을 획득할 수 있다. 대화 시스템은 동승자의 특성이 저장된 동승자 정보와 동일한지 여부를 판단할 수 있다. 구체적으로, 대화 시스템의 음성 입력 처리기는 탑승이 판단된 동승자의 음성 특성, 착석 위치, 탑승 시각, 탑승 장소 등의 특성을 저장부로부터 획득한 동승자 정보와 비교할 수 있다. 예를 들어, 음성 입력 처리기는 동승자 정보에 포함된 동승자의 음성 특성, 착석 위치, 탑승 시각 및 탑승 장소 정보와 탑승이 판단된 동승자의 특성과 비교할 수 있다. 음성 입력 처리기는 동승자 정보에 포함된 동승자의 음성 특성, 착석 위치, 탑승 시각 및 탑승 장소 중 적 어도 두 가지 이상이 감지된 동승자의 특성과 동일한 경우, 탑승이 판단된 동승자의 특성이 동승자 정보와 동일 한 것으로 판단할 수 있다. 음성 입력 처리기는 동승자 정보에 포함된 동승자의 음성 특성, 착석 위치, 탑승 시각 및 탑승 장소와 감 지된 동승자의 특성을 비교하는 경우, 음성 특성, 착석 위치, 탑승 시각 및 탑승 장소의 일정 구간의 유사 범위 까지 동일한 것으로 판단할 수 있다. 대화 시스템은 탑승이 판단된 동승자의 특성이 저장된 동승자 정보와 동일한 것으로 판단한 경우, 동승자 의 이전 주행 참여 여부 확인을 위한 선발화를 출력할 수 있다. 예를 들어, 대화 시스템은 탑승이 판단된 동승자의 특성이 저장된 동승자 정보와 동일한 것으로 판단한 경 우, \"혹시 OO님 아니세요?\"와 같이 동승자가 이전 주행 참여 동승자인지 여부를 확인하기 위한 내용의 선발화를 출력할 수 있다. 선발화 판단기는 동승자 탑승 여부의 상황 정보에 기초하여 탑승이 판단된 동승자의 특성이 저장된 동승자 정보와 동일한 것을 선발화 조건으로 선발화 출력 여부를 판단한다. 또한, 선발화 판단기는 동승자 탑승 여부의 상황 정보가 탑승이 판단된 동승자의 특성이 저장된 동승자 정보와 동일한 것으로 판단한 선발화 조건을 만족하면, 선발화 상황인 것으로 판단하고 선발화 트리거 신호를 생성한다. 선발화 판단기는 \"혹시 OO님 아니세요?\"와 같이 동승자가 탑승한 선발화 상황에 대응되는 선발화 메시지를 추출한다. 선발화 판단기가 선발화 트리거 신호와 선발화 메시지를 대화 입력 관리기(111c)에 전달하면, 대화 입력 관리기(111c)는 대화 관리기에 선발화 메시지를 전달한다. 이 때, 선발화 트리거 신호 또는 선 발화 상황임을 나타내는 신호가 함께 전달되는 것도 가능하다. 대화 관리기는 전달된 선발화 메시지를 출력하기 위한 대화 태스크를 생성하고, 선발화 메시지를 결과 처 리기에 전달할 수 있다. 결과 처리기는 입력된 선발화 메시지를 스피커를 통해 출력할 수 있다. 대화 시스템은 동승자의 발화를 입력 받아 동승자의 이전 주행 참여 여부를 확인할 수 있다. 구체적으로, 대화 시스템은 선발화 메시지에 대응한 동승자의 발화를 입력 받아 동승자가 이전 주행에 참여하였는지 여 부를 확인할 수 있다. 예를 들어, 동승자는 이전 주행에 참여하였는지 여부를 묻는 선발화 메시지에 응답하여 \"맞아\"라고 발화하거나 \"아니야\"라고 발화할 수 있다. 즉, 동승자는 이전 주행에 참여하였는지 여부를 묻는 선발화 메시지에 응답하여동승자가 이전 주행에 참여하였는지 여부를 나타내는 응답을 포함하는 메시지를 발화할 수 있다. 동승자의 발화가 입력되면, 음성 입력 처리기가 입력된 동승자의 발화를 인식한다. 동승자의 발화는 차량 에 마련된 음성 입력 장치 또는 모바일 기기에 마련된 음성 입력 장치를 통해 입력될 수 있다. 음성 인식기(111a)는 입력된 동승자의 발화를 인식하여 텍스트 형태의 발화문으로 출력한다. 자연어 이해기 (111b)는 텍스트 형태의 발화문에 자연어 이해 기술을 적용하여, 그 결과를 출력한다. 구체적으로, 자연어 이해 과정은 텍스트 형태의 발화문에 기초하여 형태소 분석을 수행하고, 형태소 분석 결과 에 기초하여 동승자가 이전 주행 참여하였는지 여부를 인식하는 것을 포함할 수 있다. 이를 통해, 음성 입력 처리기의 동승자 판단기(111d)는 동승자의 발화에 기초하여 동승자가 이전 주행에 참여하였는지 여부를 확인할 수 있다. 대화 시스템은 동승자의 이전 주행 참여의 경우, 차량 내 탑승자 간 대화 및 저장된 동승자 정보에 기초하 여 동승자 인원 정보를 생성할 수 있다. 즉, 대화 시스템은 차량 내 탑승자 간 대화에 기초하여 동승자 인 원 정보를 생성하는 경우, 저장된 동승자 정보를 추가적으로 고려할 수 있다. 예를 들어, 대화 시스템의 동승자 판단기(111d)는 자연어 이해기(111b)의 출력을 기반으로, 경유지에서의 동승자 인원 변화를 예측할 수 있다. 구체적으로, 동승자 판단기(111d)는 차량 내 탑승자 간의 대화 내용에 기 초하여 동승자 각각의 하차 가능성 및 하차 후 재탑승 가능성을 예측할 뿐만 아니라, 차량 내의 통화 내용에 기 초하여 탑승 예정 인원을 예측할 수 있다. 동승자 판단기(111d)는 차량 내 탑승자 간 대화에 기초하여 동승자 인원 변화를 예측할 때, 저장된 동승자 정보 중 하차 시각 정보 및 하차 장소 정보를 고려하여 동승자 인원 변화 예측 결과의 정확도를 높일 수 있다. 구체적으로, 동승자 판단기(111d)는 차량 내 탑승자 간 대화에 기초하여 동승자가 특정 경유지에서 하차할 것을 예측한 경우, 저장된 동승자의 동승자 정보 중 하차 시각 정보 및 하차 장소 정보를 고려하여 이전 주행에서의 동승자의 하차 시각 및 하차 장소를 확인할 수 있다. 동승자 판단기(111d)는 차량 내 탑승자 간 대화에 기초하여 예측한 동승자가 하차할 특정 경유지가 이전 주행에 서의 하차 장소와 일치하는지 여부를 판단할 수 있다. 동승자 판단기(111d)는 차량 내 탑승자 간 대화에 기초하여 예측한 동승자가 하차할 특정 경유지가 이전 주행에 서의 하차 장소와 일치하는 경우, 차량 내 탑승자 간 대화에 기초하여 예측한 동승자 인원 변환 예측을 이용하 여 동승자 인원 정보를 생성할 수 있다. 동승자 판단기(111d)는 차량 내 탑승자 간 대화에 기초하여 예측한 특정 동승자가 하차할 특정 경유지가 이전 주행에서의 하차 장소와 일치하지 않는 경우, 특정 동승자에게 하차할 지점이 특정 경유지가 맞는지 여부를 선 발화를 통해 확인할 수 있으며, 동승자의 발화에 기초하여 동승자 인원 정보를 생성할 수 있다. 도 26은 대화 관리기의 구성이 세분화된 제어 블록도이고, 도 27은 연관 액션 DB에 저장된 정보의 예시를 나타 낸 도면이고, 도 28은 액션 수행 조건 DB에 저장된 정보의 예시를 나타낸 도면이며, 도 29는 액션 인자 DB에 저 장된 정보의 예시를 나타낸 도면이다. 도 26을 참조하면, 대화 관리기는 대화 또는 액션을 생성/삭제/업데이트하도록 요청하는 대화 흐름 관리기 , 대화 흐름 관리기의 요청에 따라 대화 또는 액션을 생성/삭제/업데이트하는 대화 액션 관리기 , 상황에 대한 모호성과 대화에 대한 모호성을 해결하여 궁극적으로 사용자의 의도를 명확히 하는 모호성 해결기, 액션 수행에 필요한 인자를 관리하는 인자 관리기, 복수의 후보 액션들에 대해 액션 수행 가 부를 판단하고, 이들의 우선 순위를 결정하는 액션 우선순위 결정기 및 외부 컨텐츠 목록 및 관련 정보를 관리하고 외부 컨텐츠 쿼리에 필요한 인자 정보를 관리하는 외부 정보 관리기를 포함할 수 있다. 대화 관리기는 전술 또는 후술하는 동작을 수행하기 위한 프로그램이 저장되는 메모리 및 저장된 프로그램 을 실행시키는 프로세서를 포함할 수 있다. 메모리와 프로세서는 각각 적어도 하나 마련될 수 있고, 복수 개 마 련되는 경우에는 이들이 하나의 칩 상에 집적될 수도 있고 물리적으로 분리될 수도 있다. 또한, 대화 관리기에 포함되는 각각의 구성요소들이 단일 프로세서에 의해 구현되는 것도 가능하고, 별개 의 프로세서에 의해 구현되는 것도 가능하다.또한, 대화 관리기와 입력 처리기 역시 단일 프로세서에 의해 구현되는 것도 가능하고, 별개의 프로 세서에 의해 구현되는 것도 가능하다. 사용자의 발화가 입력된 경우 또는 선발화 상황에 매칭된 사용자 발화가 자연어 이해기(111b)에 전달된 경우에 는, 대화 입력 관리기(111c)가 자연어 이해 결과(자연어 이해기의 출력)와 상황 정보(상황 이해기의 출력)를 대 화 흐름 관리기에 전달한다. 또한, 선발화 상황이 발생한 경우에는 선발화 트리거 신호를 함께 전달하는 것도 가능하다. 자연어 이해기(111b)의 출력은 도메인, 액션 등의 정보 외에도 형태소 분석 결과와 같은 사용자의 발화 내용 자 체에 대한 정보도 포함한다. 상황 이해기(112c)의 출력은 상황 정보 외에도 상황 정보 수집 관리기(112b)에서 판단한 이벤트도 포함할 수 있다. 대화 흐름 관리기는 대화 입력 관리기(111c)로부터의 입력에 대응되는 대화 태스크 또는 액션 태스크가 대 화/액션 DB에 존재하는지 검색한다. 대화/액션 DB는 대화의 상태와 액션의 상태를 관리하기 위한 저장 공간으로서, 현재 진행 중인 대화, 액션 들과 앞으로 진행할 예비 액션들에 대한 대화 상태 및 액션 상태를 저장할 수 있다. 예를 들어, 종료된 대화/액 션, 정지된 대화/액션, 진행 중인 대화/액션, 진행될 대화/액션의 상태가 저장될 수 있다. 또한, 액션의 스위칭/네스팅 여부, 스위칭된 액션 인덱스, 액션 변경 시간, 화면/음성/명령어 등의 마지막 출력 상태 등을 저장할 수 있다. 예를 들어, 사용자 발화에 대응되는 도메인과 액션이 추출된 경우에는, 가장 최근에 저장된 대화 중 해당 도메 인과 액션에 대응되는 대화 또는 액션이 존재하면 이를 대화 입력 관리기(111c)로부터의 입력에 대응되는 대화 태스크 또는 액션 태스크로 판단할 수 있다. 사용자 발화에 대응되는 도메인과 액션이 추출되지 않은 경우에는, 임의의 태스크를 생성하거나, 가장 최근에 저장된 태스크를 참조하도록 대화 액션 생성기에 요청할 수 있다. 대화/액션 DB에 입력 처리기의 출력에 대응되는 대화 태스크 또는 액션 태스크가 존재하지 않으면, 대화 흐름 관리기는 대화 액션 관리기에 새로운 대화 태스크와 액션 태스크를 생성하도록 요청한다. 또한, 입력 처리기로부터 선발화 트리거 신호가 전달된 경우에는, 이미 진행중인 대화 태스크나 액션 태스 크가 존재하더라도, 일시적으로 이를 중단하고 선발화 상황에 대응되는 대화 태스크 또는 액션 태스크를 우선적 으로 생성할 수 있다. 또는, 정해진 규칙에 따라 우선 순위를 결정하는 것도 가능하다. 대화 입력 관리기(111c)로부터 선발화 트리거 신호와 함께 그에 대응되는 액션이 입력된 경우에는, 사용자의 발 화로부터 액션을 추출한 경우와 마찬가지로 대화 흐름 관리기가 대화 액션 관리기에 새로운 대화 태 스크와 액션 태스크를 생성하도록 요청할 수 있다. 또는, 대화 입력 관리기(111c)로부터 선발화 트리거 신호와 함께 그에 대응되는 선발화 메시지가 입력된 경우에 는, 입력된 선발화 메시지를 출력하기 위한 새로운 대화 태스크를 생성하도록 요청할 수 있다. 대화 흐름 관리기가 대화의 흐름을 관리함에 있어서, 대화 정책 DB를 참조할 수 있다. 대화 정책 DB는 대화를 전개하기 위한 정책을 저장하며, 구체적으로 대화를 선택/시작/제안/정지/종료하기 위한 정책 을 저장한다. 또한, 대화 정책 DB는 시스템이 응답을 출력하는 시점과 방법론에 대한 정책도 저장할 수 있으며, 다수의 서비스를 연계하여 응답을 만드는 정책과 기존의 액션을 삭제하고 다른 액션으로 교체하기 위한 정책을 저장할 수 있다. 예를 들어, 후보 액션이 복수이거나, 사용자의 의도나 상황에 대응되는 액션이 복수일 때(A 액션, B액션), “A 액션을 수행하고 B 액션을 수행하겠습니까?”와 같이 두 액션에 대한 응답을 한 번에 생성하는 정책과, “A액션 을 수행합니다” → “B액션을 수행할까요?”와 같이 하나의 액션에 대한 응답을 생성한 이후에, B 액션에 대해 서도 별도의 응답을 생성하는 정책이 모두 가능하다. 또한, 대화 정책 DB는 후보 액션들 간의 우선 순위를 결정하는 정책도 저장할 수 있다. 우선 순위 결정 정 책에 대해서는 후술하도록 한다. 대화 액션 관리기는 대화/액션 DB에 저장 공간을 할당하여, 입력 처리기의 출력에 대응되는 대 화 태스크와 액션 태스크를 생성한다. 한편, 사용자의 발화로부터 도메인과 액션을 추출할 수 없는 경우, 대화 액션 관리기는 임의의 대화 상태 를 생성할 수 있다. 이 경우, 후술하는 바와 같이, 모호성 해결기가 사용자의 발화 내용, 주변 상황, 차량 상태, 사용자 정보 등에 기초하여 사용자의 의도를 파악하고 이에 대응되는 적절한 액션을 판단할 수 있다. 대화/액션 DB에 입력 처리기의 출력에 대응되는 대화 태스크와 액션 태스크가 존재하면, 대화 흐름 관리기는 대화 액션 관리기가 해당 대화 태스크와 액션 태스크를 참조하도록 요청한다. 액션 우선순위 결정기는 연관 액션 DB(146b)에서 입력 처리기의 출력에 포함된 액션 또는 이벤트와 연관된 액션 목록을 검색하여 후보 액션을 추출한다. 도 27의 예시와 같이, 연관 액션 DB(146b)는 상호 연관된 액션들과 그들 사이의 관계 및 이벤트와 연관된 액션과 그들 사이의 관계를 나타낼 수 있다. 예를 들어, 길안내, 차량 상태 점검, 주유소 추천과 같은 액션이 연관된 액션으로 분류될 수 있고, 이들의 관계는 상호 연 계에 해당할 수 있다. 따라서, 길안내 액션을 수행함에 있어, 차량 상태 점검, 주유소 추천 등의 액션이 함께 수행될 수 있다. 여기서 함께 수행된다는 것은 길안내 액션의 전후로 수행되는 것과 길안내 액션의 수행 중에(경유지로 추가) 수행되는 것을 모두 포함할 수 있다. 경고등 출력 이벤트는 정비소 안내 액션이 연관된 이벤트-액션으로 저장될 수 있고, 이들의 관계 역시 상호 연 계에 해당할 수 있다. 따라서, 경고등 출력 이벤트가 발생한 경우에, 경고등의 종류 또는 정비의 필요 여부에 따라 정비소 안내 액션 을 수행할 수 있다. 입력 처리기로부터 사용자 발화에 대응되는 액션뿐만 아니라 상황 수집 관리기(112b)에서 판단한 이벤트도 함께 전송한 경우에는, 사용자 발화에 대응되는 액션과 연관된 액션과 함께 이벤트와 연관된 액션도 후보 액션 이 될 수 있다. 추출된 후보 액션 목록은 대화 액션 관리기로 전달되고, 대화 액션 관리기는 후보 액션 목록을 추가 하여 대화/액션 상태 DB의 액션 상태를 업데이트한다. 액션 우선순위 결정기는 액션 수행 조건 DB(146c)에서 각각의 후보 액션을 수행하기 위한 조건을 검색한다. 도 28의 예시와 같이, 액션 수행 조건 DB(146c)는 액션을 수행하기 위해 필요한 조건과 해당 조건의 만족 여부 를 판단하기 위해 사용되는 인자를 각각의 액션 별로 저장할 수 있다. 예를 들어, 차량 상태 점검 액션의 수행 조건은 목적지 거리가 100km 이상인 경우일 수 있고, 조건 판단을 위해 사용되는 인자는 목적지 거리에 해당한다. 주유소 추천 액션의 수행 조건은 목적지 거리가 주행 가능 거리(DT E)보다 먼 경우일 수 있고, 조건 판단을 위해 사용되는 인자는 목적지 거리와 주행 가능 거리(DTE)에 해당한다. 액션 우선순위 결정기는 후보 액션의 수행 조건을 대화 액션 관리기로 전달하고, 대화 액션 관리기 는 각 후보 액션 별 액션 수행 조건을 추가하여 대화/액션 상태 DB의 액션 상태를 업데이트한다. 액션 우선순위 결정기는 상황 정보 DB, 장기 메모리, 단기 메모리 또는 대화/액션 상태 DB에서 액션 수행 조건 판단을 위해 필요한 인자(이하, 조건 판단 인자라 한다)를 검색하고, 검색된 인자 를 이용하여 각 후보 액션의 수행 가부를 판단할 수 있다 액션 수행 조건 판단을 위해 사용되는 인자가 상황 정보 DB, 장기 메모리, 단기 메모리 또는 대 화/액션 상태 DB에 저장되지 않은 경우, 외부 정보 관리기를 통해 외부 컨텐츠 서버로부터 필요 한 인자를 가져올 수 있다. 액션 우선순위 결정기는 액션 수행 조건 판단을 위해 필요한 인자를 이용하여 각 후보 액션의 수행 가부를 판단할 수 있다. 또한, 각 후보 액션의 수행 가부 및 대화 정책 DB에 저장된 우선 순위 결정 규칙에 기초 하여 각 후보 액션의 우선 순위를 결정할 수 있다. 현재 상황에 따라 각 후보 액션에 대한 점수가 계산될 수 있다. 계산된 점수가 높은 순으로 높은 우선순위가 할 당된다. 예를 들어, 아래 [수학식 1]에 나타낸 바와 같이, 사용자 발화에 대응되는 액션, 안전도 점수, 편의 점 수, 처리 시간, 처리 시점(지금 당장 처리해야 하는지 여부), 사용자 선호도(서비스 제안 시 사용자의 수용 정도 또는 사용자가 사전에 정의한 선호도), 관리자 점수, 차량 상태 연관 점수, 액션 성공률(대화 성공률)이 점 수 계산의 인자로 사용될 수 있다. [수학식 1] 우선순위 점수 = w1*사용자 발화 액션 + w2*안전도 점수 + w3*편의점수 + w4*처리시간 + w5*처리시점 + w6*사용 자 선호도 + w7*관리자 점수 + w8*차량 상태 연관 점수 + w9*액션 성공률*액션 수행 가능 여부(1:가능, 미정 0:불가능) *액션 완료 여부(완료:1, 미완료:0)"}
{"patent_id": "10-2018-0077027", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "전술한 바와 같이, 액션 우선순위 결정기가 사용자의 발화나 상황 정보에 직접적으로 관련된 액션뿐만 아 니라 이와 연관된 액션 목록까지 검색하고 이들 사이의 우선 순위를 결정함으로써 사용자에게 가장 필요한 서비 스를 제공할 수 있게 된다. 액션 우선순위 결정기는 각 후보 액션의 수행 가부 및 우선 순위를 대화 액션 관리기로 전달하고, 대 화 액션 관리기는 전달된 정보를 추가하여 대화/액션 상태 DB의 액션 상태를 업데이트한다. 인자 관리기는 액션 인자 DB(146a)에서 각 후보 액션을 수행하는데 사용되는 인자(이하, 액션 인자라 한다.)를 검색할 수 있다. 도 29의 예시와 같이, 액션 인자 DB(146a)는 액션 별로 필수 인자, 선택 인자, 인자의 초기값 및 인자를 가져올 수 있는 참조 위치를 저장할 수 있다. 인자의 초기값이 저장되어 있는 경우에, 입력 처리기로부터 출력된 사용자의 발화나 상황 정보에 해당 인자에 대응되는 인자 값이 포함되어 있지 않고 상황 정보 DB에도 해당 인자 값이 저장되어 있지 않으면, 저장된 초기값에 따라 액션을 수행하거나, 저장된 초기값에 따라 액션을 수행 할 지 사용자에게 확인할 수 있다. 예를 들어, 길안내 액션을 수행하는데 사용되는 필수 인자는 현재 위치와 목적지를 포함할 수 있고, 선택 인자 는 경로 타입을 포함할 수 있다. 선택 인자의 초기값으로 빠른 경로가 저장될 수 있다. 현재 위치와 목적지는 대화/액션 상태 DB, 상황 정보 DB, 단기 메모리 또는 장기 메모리를 순차적으로 검색하여 획득할 수 있다. 차량 상태 점검 액션을 수행하는데 사용되는 필수 인자는 차량 상태 정보를 포함하고, 선택 인자는 점검 파트를 포함할 수 있다. 선택 인자의 초기값으로는 전체 파트가 저장될 수 있다. 차량 상태 정보는 상황 정보 DB 로부터 획득할 수 있다. 주유소 추천 액션을 수행하는데 사용되는 선택 인자는 선호 주유소를 포함할 수 있고, 선택 인자의 초기값으로 A 오일이 저장될 수 있다. 선호 주유소는 장기 메모리로부터 획득할 수 있다. 선택 인자에 차량의 유종, 기름 가격 등이 더 포함되는 것도 가능하다. 전술한 바와 같이, 인자 관리기는 액션 인자 DB(146a)에서 검색한 인자의 인자 값을 해당 참조 위치에서 가져온다. 인자 값을 가져올 수 있는 참조 위치는 상황 정보 DB, 장기 메모리, 단기 메모리, 대 화/액션 상태 DB 및 외부 컨텐츠 서버 중 적어도 하나일 수 있다. 인자 관리기가 외부 컨텐츠 서버로부터 인자 값을 가져오는 경우에는, 외부 정보 관리기를 통할 수 있다. 외부 정보 관리기는 외부 서비스 집합 DB(146d)를 참조하여 어디에서 정보를 가져올 지 판단할 수 있다. 외부 서비스 집합 DB(146d)는 대화 시스템과 연계된 외부 컨텐츠 서버에 대한 정보를 저장한다. 예를 들어, 외부 서비스 명칭, 외부 서비스 에 대한 설명, 외부 서비스 가 제공하는 정보의 타입, 외부 서비스 사용 방법, 외부 서비스 의 제공 주체 등에 대한 정보를 저장할 수 있다. 인자 관리기가 획득한 인자 값은 대화 액션 관리기로 전달되고, 대화 액션 관리기는 각 후보 액 션 별 인자 값을 액션 상태에 추가하여 대화/액션 상태 DB를 업데이트 한다. 인자 관리기는 모든 후보 액션의 인자 값을 획득하는 것도 가능하고, 액션 우선순위 결정기에서 수행 이 가능한 것으로 판단된 후보 액션의 인자 값만 획득하는 것도 가능하다. 또한, 인자 관리기는 동일한 정보를 나타내는 다양한 종류의 인자 값을 선택적으로 사용할 수 있다. 예를 들어, 목적지를 나타내는 텍스트 형태의 서울역은 내비게이션의 목적지 검색 서비스를 이용하여 POI 형태의 서 울역으로 변환될 수 있다. 대화나 상황에 모호성이 없는 경우에는 전술한 액션 우선순위 결정기, 인자 관리기 및 외부 정보 관 리기의 동작에 따라 필요한 정보를 얻고 대화와 액션을 관리할 수 있다. 그러나, 대화나 상황에 모호성이 있는 경우에는 액션 우선순위 결정기, 인자 관리기 및 외부 정보 관리기의 동작만으로는 사용자 에게 필요한 적절한 서비스를 제공하기 어렵다. 이러한 경우, 모호성 해결기가 대화에 대한 모호성 또는 상황에 대한 모호성을 해결할 수 있다. 예를 들어, 대화에 그 사람, 어제 거기, 아빠, 엄마, 할머니, 며느리 등과 같은 조응어가 포함되어 무엇을 지칭하는 지 모호한 경우에 모호성 해결기가 상황 정보 DB, 장기 메모기 또는 단기 메모리를 참조하 여 이러한 모호성을 해결하거나 이를 해결하기 위한 가이드를 제시할 수 있다. 예를 들어, “어제 거기”, “집 근처 A마트”, “어제 간 서울역” 등과 같이 대화에 포함된 모호한 단어가 액 션 인자의 인자 값이거나 조건 판단 인자의 인자 값에 해당할 수 있다. 그러나, 이 경우, 해당 단어 자체만으로 는 그 모호성으로 인해 실제로 액션을 수행하거나 액션 수행 조건을 판단할 수가 없다. 모호성 해결기는 상황 정보 DB, 장기 메모리 또는 단기 메모리에 저장된 정보를 참조하여 인자 값의 모호성을 해결할 수 있다. 또는, 필요에 따라 외부 정보 관리기를 이용하여 외부 컨텐츠 서버 로부터 필요한 정보를 가져오는 것도 가능하다. 예를 들어, 단기 메모리를 참조하여 사용자가 어제 갔던 장소를 검색함으로써 “어제 거기”를 길 안내 액 션의 목적지로 사용 가능한 정보로 변환할 수 있다. 또는, 장기 메모리를 참조하여 사용자의 집 주소를 검 색하고 외부 컨텐츠 서버로부터 집 주소 근처의 A마트에 관한 위치 정보를 가져옴으로써 “집 근처 A마트 ”를 길 안내 액션의 목적지로 사용 가능한 정보로 변환할 수 있다. 또한, 입력 처리기에서 액션(오브젝트, 오퍼레이터)이 명확하게 추출되지 않거나 사용자의 의도가 모호한 상황에서, 모호성 해결기가 모호성 해소 정보 DB(146e)를 참조하여 사용자의 의도를 파악하고, 이에 대응 되는 액션을 결정하는 것도 가능하다. 도 30은 모호성 해소 정보 DB에 저장되는 정보의 예시를 나타내는 도면이다. 모호성 해소 정보 DB(146e)는 차량 상태 정보와 주변 상황 정보에 기초하여, 발화문과 그에 대응되는 액션을 매 칭시켜 저장할 수 있다. 모호성 해소 정보 DB(146e)에 저장되는 발화문은 자연어 이해를 통해 액션을 추출할 수 없는 발화문일 수 있다. 도 30의 예시에서는 형태소 분석 결과에 따른 발화 내용이 손이 시리거나 손이 춥다는 내용인 경우에 대해 설명한다. 주변 상황 정보는 차량 외부 온도와 강우 여부를 포함할 수 있고, 차량 상태 정보는 에어컨/히터의 온/오프 여 부와 풍량, 풍향, 스티어링 열선의 온/오프 여부를 포함할 수 있다. 구체적인 예로, 외부 온도가 20도가 넘으면서 비가 오는 경우, 에어컨이 온(On)되어 있으면 에어컨 온도가 너무 낮게 설정되어 손이 시린 것으로 파악할 수 있고, 대응되는 차량 제어 액션으로 에어컨 온도 3도 높이기를 저장 할 수 있다. 외부 온도가 20도가 넘으면서 비가 오는 경우, 에어컨이 오프되어 있으면 강우로 인해 추위를 느끼는 것으로 파 악할 수 있고, 대응되는 차량 제어 액션으로 히터 On 을 저장할 수 있다. 외부 온도가 20도가 넘으면서 비가 오지 않는 경우, 에어컨이 온되어 있고, 에어컨 풍향이 상향(Up)으로 설정되 어 있으면 에어컨 바람이 손을 직접 향하여 손이 시린 것으로 파악할 수 있고, 대응되는 차량 제어 액션으로 에 어컨 풍향을 하향(Down)으로 변경하는 것을 저장할 수 있다. 외부 온도가 20도가 넘으면서 비가 오지 않는 경우, 에어컨이 온되어 있고, 에어컨 풍향이 하향으로, 풍량이 중 이상으로 설정되어 있으면 에어컨 풍향이 너무 강하여 추위를 느끼는 것으로 파악할 수 있고, 대응되는 차량 제 어 액션으로 에어컨 풍량을 낮추는 것을 저장할 수 있다. 외부 온도가 20도가 넘으면서 비가 오지 않는 경우, 에어컨이 온 되어 있고, 에어컨 풍향이 하향으로, 에어컨 풍량이 약하게(하) 설정되어 있으면 대응되는 차량 제어 액션으로 에어컨 온도를 3도 올리는 것을 저장할 수 있 다.외부 온도가 20도보다 낮으면서 히터가 오프되어 있는 경우에는, 추운 날씨로 인해 손이 시린 것으로 파악할 수 있고, 대응되는 차량 제어 액션으로 터 온을 저장할 수 있다. 외부 온도가 20도보다 낮으면서 히터가 온되어 있고 스티어링 열선이 오프되어 있는 경우, 온기가 손에 전달되 지 않아 손이 시린 것으로 파악할 수 있고, 대응되는 차량 제어 액션을 스티어링 열선 온으로 저장할 수 있다. 외부 온도가 20도보다 낮으면서 히터와 스티어링 열선이 모두 온 되어 있고, 히터 풍향이 하향으로 설정된 경우 에는 히터 바람이 손으로 전달되지 않아 손이 시린 것으로 파악할 수 있고, 대응되는 차량 제어 액션을 히터 풍 향의 양방향 변경으로 저장할 수 있다. 외부 온도가 20도보다 낮으면서 히터와 스티어링 열선이 모두 온되어 있고, 히터 풍향이 상향으로 설정되어 있 는 경우, 히터 온도가 최대치보다 낮게 설정되어 있으면, 대응되는 차량 제어 액션을 히터 온도 높이기로 저장 할 수 있다. 외부 온도가 20도보다 낮으면서 히터와 스티어링 열선이 모두 온되어 있고, 히터 풍향이 상향으로 설정되어 있 고 히터 온도가 최대치로 설정되어 있으며, 히터 풍량은 최대치로 설정되어 있지 않은 경우에는, 대응되는 차량 제어 액션을 히터 풍량 증가로 저장할 수 있다. 외부 온도가 20도보다 낮으면서 히터와 스티어링 열선이 모두 온되어 있고, 히터 풍향이 상향으로, 히터 온도와 히터 풍향이 모두 최대치로 설정되어 있는 경우에, 열선 시트가 오프되어 있으면, 대응되는 차량 제어 액션으로 열선 시트 온을 저장할 수 있다. 외부 온도가 20도보다 낮으면서 히터와 스티어링 열선이 모두 온되어 있고, 히터 풍향이 상향으로, 히터 온도와 히터 풍량이 모두 최대치로 설정되어 있으며, 열선 시트도 온되어 있는 경우에는, 대응되는 차량 제어 액션으로 현재 히터가 풀가동 중이므로 잠시 기다려 달라는 안내를 출력할 수 있다. 도 31a 및 도 31b는 모호성 해결기가 모호성 해소 정보 DB를 참조하여 모호성을 해결하고 액션을 추출하여 차량 을 제어하는 다양한 예시들을 정리한 테이블이다. 예를 들어, 도 31a 및 도 31b에 도시된 바와 같이, 형태소 분석 결과에 따른 발화 내용이 손이 시리거나 손이 춥다는 내용인 경우, 주변 상황이 여름이면서 차량 상태는 에어컨의 풍향이 탑승자의 머리 쪽(상향)을 향하고, 에어컨 설정 온도가 19도이며, 풍량이 상황인 경우에는 손으로 향하는 에어컨 바람으로 인해 손이 시린 것으로 파악할 수 있다. 따라서, 풍향을 발 쪽(하향)으로 변경하면서 풍량 세기를 줄이기 위한 에어컨 제어 액션을 해 당 발화에 대응되는 액션으로 추출하고, 추출된 액션에 따라 차량을 제어할 수 있다. 또한, 같은 내용의 발화에서, 주변 상황이 겨울이면서 차량 상태는 히터의 풍향이 탑승자의 발 쪽을 향하고, 에 어컨 설정 온도는 25이며, 풍량이 강하게 설정된 상황인 경우에는 온기가 사용자의 손에 전달되지 않아 손이 시 린 것으로 파악할 수 있다. 따라서, 스티어링 휠의 열선 온(On) 액션을 해당 발화에 대응되는 액션으로 추출하 고, 추출된 액션에 따라 차량을 제어할 수 있다. 형태소 분석 결과에 따른 발화 내용이 답답하다는 내용인 경우, 차량 상태가 차량 속도 시속 30km 이하, 차량 앞뒤 간격이 30cm 미만인 상황인 경우, 교통 체증으로 인해 느끼는 답답함인 것으로 파악할 수 있다. 따라서, 길안내 액션에서 경로 옵션(빠른 경로 안내)을 변경하거나 음악과 같은 멀티미디어 컨텐츠를 재생하거나, 채팅 기능을 온(On)시키는 액션을 해당 발화에 대응되는 액션으로 액션으로 추출하고, 추출된 액션에 따라 차량을 제 어할 수 있다. 형태소 분석 결과에 따른 발화 내용이 졸리다는 내용인 경우, 차량 상태가 내기모드인 상황이면, 공기 순환이 안됨에 따라 졸음이 유발된 것으로 파악할 수 있다. 따라서, 외기모드로 변경하는 액션을 해당 발화에 대응되는 액션으로 추출하고, 추출된 액션에 따라 차량을 제어할 수 있다. 또한, 같은 내용의 발화에서, 차량 상태가 외기모드이고 히터가 온(On)되어 있는 상황인 경우에는, 히터에서 방 출되는 온기로 인해 졸음이 유발된 것으로 파악할 수 있다. 따라서, 창문 열기를 해당 발화에 대응되는 액션으 로 추출하고, 추출된 액션에 따라 차량을 제어할 수 있다. 형태소 분석 결과에 따른 발화 내용이 땀이 난다거나 덥다는 내용인 경우, 주변 상황이 겨울이면서 차량 상태 는 히터가 온(On)되어 있는 상황이면, 히터의 온기로 인해 더위가 유발된 것으로 파악할 수 있다. 따라서, 히터 의 온도 낮추기나 풍량 줄이기를 해당 발화에 대응되는 액션으로 저장할 수 있다. 또한, 같은 내용의 발화에서 주변 상황이 겨울이면서 히터가 오프(Off)되어 있는 상황이면, 사용자의 신체 열기 로 인해 더위가 유발된 것으로 파악할 수 있다. 따라서, 창문 열기 또는 창문 열기 제안을 해당 발화에 대응되 는 액션으로 추출하고, 추출된 액션에 따라 차량을 제어할 수 있다. 또한, 같은 내용의 발화에서 주변 상황이 여름이면서 차량 상태가 에어컨이 오프되어 있는 상황이면, 차량 내부 온도가 높아서 더위가 유발된 것으로 파악할 수 있다. 따라서, 에어컨 실행(On)을 해당 발화에 대응되는 액션으 로 추출하고, 추출된 액션에 따라 차량을 제어할 수 있다. 또한, 같은 내용의 발화에서 주변 상황이 여름이면서 차량 상태가 에어컨이 온(On)되어 있는 상황이면, 에어컨 의 온도가 높게 설정되어 있어서 더위가 유발된 것으로 파악할 수 있다. 따라서, 에어컨 온도 낮추기 또는 풍량 증가를 해당 발화에 대응되는 액션으로 추출하고, 추출된 액션에 따라 차량을 제어할 수 있다. 형태소 분석 결과에 따른 발화 내용이 춥다는 내용인 경우, 주변 상황이 여름이면서 차량 상태가 에어컨이 온 (On)되어 있는 상황이면, 에어컨 온도가 지나치게 낮게 설정되어 있거나 에어컨 바람이 지나치게 강하기 때문에 추위가 유발된 것으로 파악할 수 있다. 따라서, 에어컨 온도 높이기나 풍량 감소를 해당 발화에 대응되는 액션 으로 추출하고, 추출된 액션에 따라 차량을 제어할 수 있다. 또한, 같은 내용의 발화에서 주변 상황이 여름이면서 차량 상태가 에어컨이 오프되어 있는 상황이면, 사용자의 신체 컨디션에 문제가 있어 추위가 유발된 것으로 파악할 수 있다. 따라서, 히터의 실행이나 사용자의 바이오 리듬 체크를 해당 발화에 대응되는 액션으로 추출하고, 추출된 액션에 따라 차량을 제어할 수 있다. 또한, 같은 내용의 발화에서 주변 상황이 겨울이면서 차량 상태가 히터가 온(On)되어 있는 상황이면, 히터의 온 도가 낮게 설정되어 있거나 풍량이 약하기 때문에 추위가 유발된 것으로 파악할 수 있다. 따라서, 히터 온도 높 이기나 풍량 증가를 해당 발화에 대응되는 액션으로 추출하고, 추출된 액션에 따라 차량을 제어할 수 있다. 또한, 같은 내용의 발화에서 주변 상황이 겨울이면서 히터가 오프되어 있는 상황이면, 히터의 미실행으로 인해 추위가 유발된 것으로 파악할 수 있다. 따라서, 히터 실행을 해당 발화에 대응되는 액션으로 추출하고, 추출된 액션에 따라 차량을 제어할 수 있다. 형태소 분석 결과에 따른 발화 내용이 머리가 아프다는 내용인 경우, 주변 상황이 겨울이면서 차량 상태가 히터 가 온(On) 되어 있는 상황이면, 공기 순환이 되지 않아 두통이 유발된 것으로 파악할 수 있다. 따라서, 외기모 드 변환 또는 창문 열기를 해당 발화에 대응되는 액션으로 추출하고, 추출된 액션에 따라 차량을 제어할 수 있 다. 또한, 같은 내용의 발화에서 주변 상황이 겨울이면서 차량 상태가 히터가 오프되어 있는 상황이면, 추위로 인해 두통이 유발된 것으로 파악할 수 있다. 따라서, 히터 실행을 해당 발화에 대응되는 액션으로 추출하고, 추출된 액션에 따라 차량을 제어할 수 있다. 또한, 같은 내용의 발화에서 주변 상황이 여름이면서 차량 상태가 에어컨이 오프되어 있는 상황이면, 더위로 인 해 두통이 유발된 것으로 파악할 수 있다. 따라서, 에어컨 실행을 해당 발화에 대응되는 액션으로 추출하고, 추 출된 액션에 따라 차량을 제어할 수 있다. 또한, 같은 내용의 발화에서 주변 상황이 여름이면서 차량 상태가 에어컨이 온(On)되어 있는 상황이면, 냉방병 으로 인해 두통이 유발된 것으로 파악할 수 있다. 따라서, 에어컨의 풍향이나 풍량의 변경을 해당 발화에 대응 되는 액션으로 추출하고, 추출된 액션에 따라 차량을 제어할 수 있다. 형태소 분석 결과에 따른 발화 내용이 찝찝하다는 내용인 경우, 주변 상황이 겨울이고 비가 오는 상황이면, 높 은 습도로 인해 불쾌함이 유발된 것으로 파악할 수 있다. 따라서, 디포그 기능의 실행이나 제습 기능의 실행을 해당 발화에 대응되는 액션으로 추출하고, 추출된 액션에 따라 차량을 제어할 수 있다. 또한, 같은 내용의 발화에서 주변 상황이 여름이고 비가 오지 않는 상황이면, 계절적 특성과 더위로 인해 불쾌 함이 유발된 것으로 파악할 수 있다. 따라서, 에어컨을 최저 온도로 실행시키는 것이 해당 발화에 대응되는 액 션으로 추출하고, 추출된 액션에 따라 차량을 제어할 수 있다. 또한, 같은 내용의 발화에서 주변 상황이 여름이고 비가 오는 상황이면, 더위와 높은 습도로 인해 불쾌함이 유 발된 것으로 파악할 수 있다. 따라서, 에어컨을 제습 모드로 실행하는 것이 해당 발화에 대응되는 액션으로 추 출하고, 추출된 액션에 따라 차량을 제어할 수 있다. 전술한 모호성 해결기의 동작에 의하면, 사용자의 발화나 상황에 모호성이 있는 경우이더라도 주변 상황 정보와 차량 상태 정보를 사용자의 발화와 함께 통합적으로 고려함으로써 사용자가 실제로 원하는 액션 또는 사용자에게 실제로 필요한 액션을 정확하게 파악하여 제공할 수 있다. 모호성 해결기가 판단한 액션에 관한 정보는 대화 액션 관리기로 전달될 수 있고, 대화 액션 관리기 는 전달된 정보에 기초하여 대화/액션 DB를 업데이트할 수 있다. 액션 우선순위 결정기와 인자 관리기는 모호성 해결기가 판단한 액션에 대해서도 전술한 바와 같이 액션 수행 조건을 판단하고, 우선 순위를 결정하고, 인자 값을 가져오는 동작을 수행한다. 각 액션을 수행하는데 사용되는 인자 값들 중 현재 상황과 대화를 통해 획득 가능한 값들이 모두 획득되면, 대 화 액션 관리기는 대화 흐름 관리기에 신호를 전송한다. 한편, 액션 수행이나 조건 판단에 있어 필요한 인자 값이 대화/액션 DB, 외부 컨텐츠 서버, 장기 메 모리, 단기 메모리 및 상황 정보 DB에 존재하지 않고, 사용자를 통해서만 획득될 수 있는 경우 에는 결과 처리기가 사용자에게 인자 값을 질의하기 위한 대화 응답을 생성하는 것도 가능하다. 대화 흐름 관리기는 1순위에 해당하는 액션에 관한 정보와 대화 상태를 결과 처리기로 전달한다. 대 화 정책에 따라 복수의 후보 액션에 관한 정보를 전달하는 것도 가능하다. 대화 시스템이 선발화를 출력하는 경우 즉, 입력 처리기에서 선발화 트리거 신호가 생성된 경우에는, 결과 처리기로 전달되는 대화 상태에 선발화 트리거 신호가 포함될 수 있다. 다만, 대화 상태에 반드시 선 발화 트리거 신호가 포함되어야 하는 것은 아니고, 선발화 상황임을 나타낼 수 있는 정보이면 어떤 형태의 것이 든 대화 상태에 포함될 수 있다. 대화 상태에 선발화 상황임을 나타내는 정보가 포함된 경우에는, 결과 처리기 가 대화 응답을 다른 형태의 응답에 우선하여 출력하거나, 다른 형태의 응답과 함께 출력할 수 있다. 또한, 대화 시스템이 선발화를 출력하는 경우에 있어서, 대화 입력 관리기(111c)로부터 선발화 상황에 대 응되는 선발화 메시지가 입력된 경우에는 전술한 모호성 해결, 인자 관리, 액션 순위 결정 등의 과정을 거치지 않고 선발화 메시지를 결과 처리기에 전달할 수 있다. 또한, 대화 시스템이 선발화를 출력하는 경우에 있어서, 대화 입력 관리기(111c)로부터 선발화 상황에 대 응되는 액션이 입력된 경우에는 전술한 모호성 해결, 인자 관리, 액션 순위 결정 등의 과정을 거치는 것도 가능 하고, 이러한 과정을 거치지 않고 선발화 상황에 대응되는 액션을 결과 처리기에 전달하는 것도 가능하다. 도 32는 결과 처리기의 구성을 세분화한 제어 블록도이다. 도 32를 참조하면, 결과 처리기는 대화 관리기로부터 입력된 액션을 수행하기 위해 필요한 응답의 생 성을 관리하는 응답 생성 관리기, 응답 생성 관리기의 요청에 따라 텍스트 응답, 이미지 응답 또는 오디오 응답을 생성하는 대화 응답 생성기, 응답 생성 관리기의 요청에 따라 차량 제어를 위한 명령 어 또는 외부 컨텐츠를 이용한 서비스를 제공하기 위한 명령어를 생성하는 명령어 생성기, 사용자가 원하 는 서비스를 제공하기 위해 다수의 서비스를 순차적 또는 산발적으로 실행하고 결과값을 취합해주는 서비스 편 집기, 생성된 텍스트 응답, 이미지 응답 또는 오디오 응답을 출력하거나 명령어 생성기가 생성한 명 령어를 출력하고, 출력이 복수인 경우에는 출력 순서를 결정하는 출력 관리기, 응답 생성 관리기와 출력 관리기의 출력에 기초하여 장기 메모리와 단기 메모리를 관리하는 메모리 관리기를 포함한다. 결과 처리기는 전술 또는 후술하는 동작을 수행하기 위한 프로그램이 저장되는 메모리 및 저장된 프로그램 을 실행시키는 프로세서를 포함할 수 있다. 메모리와 프로세서는 각각 적어도 하나 마련될 수 있고, 복수 개 마 련되는 경우에는 이들이 하나의 칩 상에 집적될 수도 있고 물리적으로 분리될 수도 있다. 또한, 결과 처리기에 포함되는 각각의 구성요소들이 단일 프로세서에 의해 구현되는 것도 가능하고, 별개 의 프로세서에 의해 구현되는 것도 가능하다. 또한, 결과 처리기와, 대화 관리기 및 입력 처리기 역시 단일 프로세서에 의해 구현되는 것도 가능하고, 별개의 프로세서에 의해 구현되는 것도 가능하다. 사용자의 발화나 상황에 대응하여 출력되는 응답은 대화 응답, 차량 제어, 외부 컨텐츠 제공 등을 포함할 수 있 다. 대화 응답은 초기 대화, 질의, 정보 제공을 포함하는 답변 등의 형식을 가질 수 있고 응답 템플릿에 데이터베이스화되어 저장될 수 있다. 응답 생성 관리기는 대화 응답 생성기와 명령어 생성기에 대화 관리기에서 결정된 액션을 수행하기 위해 필요한 응답의 생성을 요청한다. 이를 위해, 수행될 액션에 관한 정보를 대화 응답 생성기 와 명령어 생성기에 전송할 수 있고, 수행될 액션에 관한 정보는 액션명, 인자 값 등을 포함할 수 있다. 응답을 생성함에 있어, 대화 응답 생성기와 명령어 생성기는 현재 대화 상태와 액션 상태를 참조할 수 있다. 대화 응답 생성기는 응답 템플릿을 검색하여 대화 응답 서식을 추출할 수 있고, 추출된 대화 응답 서 식에 필요한 인자 값을 채워 대화 응답을 생성한다. 생성된 대화 응답은 응답 생성 관리기로 전달된다. 대 화 응답 생성에 필요한 인자 값이 대화 관리기로부터 전달되지 않거나, 외부 컨텐츠를 이용하라는 지시가 전달된 경우에는 외부 컨텐츠 서버로부터 제공받거나 장기 메모리, 단기 메모리 또는 상황 정보 DB에서 검색할 수 있다. 예를 들어, 대화 관리기에서 결정된 액션이 길 안내에 해당하는 경우, 응답 템플릿을 검색하여 “[현 재 위치:-]에서 [목적지:-]까지 [소요 시간:-]이 소요될 것으로 예상됩니다. 안내를 시작할까요?”를 대화 응답 서식으로 추출할 수 있다. 대화 응답 서식에 채워져야 할 인자 중에서 [현재 위치]와 [목적지]의 인자 값은 대화 관리기로부터 전달 되고, [소요 시간]의 인자 값은 전달되지 않을 수 있다. 이 경우, 대화 응답 생성기는 외부 컨텐츠 서버 에 [현재 위치]에서 [목적지]까지 소요되는 시간을 요청할 수 있다. 명령어 생성기는 사용자의 발화나 상황에 대한 응답이 차량 제어 또는 외부 컨텐츠 제공을 포함하는 경우, 이를 실행하기 위한 명령어를 생성한다. 예를 들어, 대화 관리기에서 결정된 액션이 공조 장치, 윈도우, 시트, AVN 등의 제어인 경우에 해당 제어를 실행하기 위한 명령어를 생성하여 응답 생성 관리기에 전달한 다. 또는, 대화 관리기에서 결정된 액션이 외부 컨텐츠의 제공을 필요로 하는 경우에는 외부 컨텐츠 서버(30 0)로부터 해당 컨텐츠를 제공받기 위한 명령어를 생성하여 응답 생성 관리기에 전달한다. 명령어 생성기에서 생성한 명령어가 복수인 경우, 서비스 편집기가 복수의 명령어를 실행하는 방법과 순서를 결정하여 응답 생성 관리기에 전달한다. 응답 생성 관리기는 대화 응답 생성기, 명령어 생성기 또는 서비스 편집기로부터 전달받은 응답을 출력 관리기에 전달한다. 출력 관리기는 대화 응답 생성기가 생성한 대화 응답과 명령어 생성기가 생성한 명령어의 출력 타이밍, 출력 순서, 출력 위치 등을 결정한다. 출력 관리기는 응답 생성기가 생성한 대화 응답과 명령어 생성기가 생성한 명령어를 적절한 타 이밍에 적절한 순서로 적절한 출력 위치에 전송하여 응답을 출력한다. TTS(Text to Speech) 응답은 스피커(23 2)를 통해 출력할 수 있고, 텍스트 응답은 디스플레이를 통해 출력할 수 있다. 대화 응답을 TTS 형태로 출 력하는 경우에는 차량에 마련된 TTS 모듈을 이용하거나 출력 관리기가 TTS 모듈을 포함할 수도 있다. 명령어는 그 제어 대상에 따라 차량 제어기로 전송될 수도 있고, 외부 컨텐츠 서버와 통신하기 위한 통신 장치로 전송될 수도 있다. 응답 생성 관리기는 대화 응답 생성기, 명령어 생성기 또는 서비스 편집기로부터 전달받은 응답을 메모리 관리기에도 전달할 수 있다. 또한, 출력 관리기도 자신이 출력한 응답을 메모리 관리기에 전달할 수 있다. 메모리 관리기는 응답 생성 관리기 및 출력 관리기로부터 전달받은 내용에 기초하여 장기 메모 리와 단기 메모리를 관리한다. 예를 들어, 메모리 관리기는 생성 및 출력된 대화 응답에 기초하 여 사용자와 시스템 간 대화 내용을 저장하여 단기 메모리를 업데이트할 수 있고, 사용자와의 대화를 통해 획득된 사용자 관련 정보를 저장하여 장기 메모리를 업데이트할 수 있다. 또한, 단기 메모리에 저장된 정보 중 사용자의 성향이나 선호도와 같이 의미 있고 영속성이 있는 정보 또 는 이러한 정보를 획득하는데 사용될 수 있는 정보를 장기 메모리에 저장할 수도 있다. 또한, 생성 및 출력된 명령어에 대응되는 차량 제어나 외부 컨텐츠 요청에 기초하여 장기 메모리에 저장된 사용자의 선호도나 차량 제어 이력 등을 업데이트할 수도 있다. 한편, 사용자의 발화 입력 이전에 대화 시스템이 선발화를 출력하는 경우에 있어서, 대화 입력 관리기 (111c)로부터 선발화 상황에 대응되는 액션을 입력 받은 경우에는, 액션에 관한 정보를 입력 받은 대화 응답 생 성기가 응답 템플릿을 검색하여 대화 응답 서식을 추출할 수 있고, 추출된 대화 응답 서식에 필요한 인자 값을 채워 대화 응답을 생성할 수 있다. 생성된 대화 응답은 응답 생성 관리기로 전달된다. 여기서의 대화 응답은 대화 시스템의 선발화가 된다. 응답 생성 관리기는 대화 응답 생성기로부터 전달받은 대화 응답을 출력 관리기에 전달한다. 출력 관리기는 대화 응답 생성기가 생성한 대화 응답을 스피커를 통해 출력할 수 있다. 결과 처리기가 대화 흐름 관리기로부터 선발화 상황에 대응되는 선발화 메시지 자체를 입력 받은 경 우에는, 입력된 선발화 메시지가 대화 응답이 되고, 입력된 선발화 메시지는 출력 관리기에 전달될 수 있 다. 출력 관리기는 전달된 선발화 메시지를 스피커를 통해 출력할 수 있다. 또한, 대화 시스템이 선발화를 출력한 이후에 사용자의 발화가 입력되면, 그 이후에는 앞서 설명한 사용자 의 발화를 처리하는 동작이 동일하게 수행될 수 있다. 전술한 실시예에 따른 대화 시스템에 의하면, 차량 내부에서 발생하는 다양한 상황을 고려하여 사용자에게 필요한 최적의 서비스를 제공할 수 있다. 특히, 사용자의 발화가 입력되지 않더라도 대화 시스템이 수집한 상황 정보 또는 운전자 정보에 기초하여 사용자에게 필요한 서비스를 스스로 판단하고 이를 선제적으로 제공하 는 것이 가능하다. 예를 들어, 차량 시동 시의 상황에 따라 차량 상태의 평가 기준을 가변화하고 이에 대한 피드백을 선제적으로 제공할 수 있다. 주행 시작 시점을 차량 시동 시, EPB(Electronic Parking Brake) 해제 시 또는 내비게이션 목 적지 설정 시 등으로 정의한다. 주행 가능 점수를 계산하는 차량 상태 평가 시스템 및 개별 장치에 가중치를 주 고, 상황 요소에 따라 개별 장치에 적용되는 가변적인 가중치를 변화시킨다. 차량 상태에 문제가 있는 것으로 판단될 경우, 정비소 안내 등 개별 장치에 대한 문제 해결 방안을 제공할 수 있다. 또한, 차량 시동 인가 시 목적지 대비 유량 부족 여부를 판단하고, 유량이 부족할 경우 이에 대한 피드백으로 목적지까지의 경로 내에 사용자 선호 주유소를 자동 경유지로 추가하고, 이를 사용자에게 안내할 수 있다. 또한, 사용자의 응답에 따라 자동 경유지로 추가되는 주유소가 변경될 수도 있다. 또한, 현재 차량 상태가 유량 부족을 나타내지 않더라도, 사용자의 향후 일정이나 주요 이동 기록, 잔유량 등을 종합적으로 고려하여 주유 장소나 시점을 선제적으로 제공할 수도 있다. 또한, 운전자의 신체 상태 및 수면 기록에 관한 정보를 획득하고, 획득된 정보에 기초하여 차량 시동 인가를 조 건부로 허가할 수 있다. 예를 들어, 차량 외부에서 신체 상태와 수면 기록을 인식하여 졸음 운전 가능성이 인지 되면 비운전을 추천할 수 있다. 또는 신체 상태나 수면 기록에 따라 권장 운전 시간에 대한 정보를 제공할 수도 있다. 또한, 졸음 운전 가능성을 나타내는 트리거가 반복적으로 발생할 경우, 졸음 운전 가능성을 감지하고 감지된 가 능성의 정도에 따라 경고를 출력하거나 자동으로 경로를 변경(휴게소)하는 피드백을 제공할 수 있다. 졸음 운전 가능성을 나타내는 트리거는 심박 저하가 나타난 경우, 선행 차량과의 거리가 기준 거리 이상인 경우, 속도가 기준 속도 이하인 경우와 같이 운전자의 상태나 차량의 상태를 수동적으로 측정하여 획득하는 것도 가능하고, 운전자에게 질의를 발화하고 이에 대한 운전자의 응답 속도를 측정하는 등 대화를 통해 능동적으로 획득하는 것 도 가능하다. 또한, 사용자가 감정을 표현하는 발화를 입력한 경우, 사용자의 발화로부터 특정 도메인이나 액션은 추출할 수 없지만 대화 시스템은 주변 상황 정보, 차량 상태 정보, 사용자 상태 정보 등을 이용하여 사용자의 의도를 파악하고 대화를 전개할 수 있다. 당해 예시는 전술한 바와 같이 모호성 해결기에서 사용자 발화의 모호성 을 해결함으로써 수행될 수 있다. 또한, 차량 내 동승자가 탑승한 경우, 동승자의 탑승을 판단하고 동승자를 식별하기 위한 내용의 선발화를 출력 할 수 있다. 구체적으로, 차량 내 동승자가 탑승한 경우, 대화 시스템은 음성 입력 또는 음성 외 입력을 통해 동승자의 탑승을 판단하고, 동승자의 신원을 식별하기 위하여 동승자에게 질의(예: 누구세요? 이름을 말씀 해 주세요.)를 발화하고, 이에 대한 동승자의 발화를 입력 받아, 대화를 통해 능동적으로 동승자를 식별하는 것도 가능하다. 또한, 차량 내 동승자의 인원 변화가 예측되는 경우, 동승자 인원 변화 예측 결과에 관한 내용의 선발화를 출력 할 수 있다. 구체적으로, 대화 시스템은 음성 입력을 통해 차량 내 탑승자 간 대화를 입력 받고, 동승자 각각의 하차 가능성 및 하차 후 재탑승 가능성을 예측하여 동승자 인원 변화 예측 결과에 관한 내용의 선발화를 출력할 수 있다. 이하 일 실시예에 따른 대화 시스템을 이용한 구체적인 대화 처리의 예시를 상세하게 설명하도록 한다. 도 33 내지 도 45는 사용자가 길 안내와 관련한 발화를 입력한 경우에 대화 시스템이 입력을 처리하고, 대 화를 관리하고, 결과를 출력하는 구체적인 예시를 나타낸 도면이다. 도 33에 도시된 바와 같이, 사용자가 “어제 간 서울역으로 가자”는 발화를 입력한 경우, 음성 인식기(111a)는 사용자의 음성을 텍스트 형태의 발화문(어제 간 서울역으로 가자)으로 출력한다. 자연어 이해기(111b)는 형태소를 분석하고, 도메인/액션 추론 규칙 DB를 참조하여, 형태소 분석 결과(어제 /NNG, 간/VV, 서울역/NNP, 가자/VV)로부터 [도메인: 내비게이션], [액션: 길안내], [화행: 요청], [인자: NLU 목적지: 서울역]을 추출하여 대화 입력 관리기(111c)에 입력할 수 있다. 도 34를 참조하면, 대화 입력 관리기(111c)는 자연어 이해기(111b)의 자연어 이해 결과를 상황 이해기(112c)에 전달하면서 추가 정보가 있으면 보내줄 것을 요청한다. 상황 이해기(112c)는 상황 이해 테이블을 검색하여 [도메인: 내비게이션], [액션: 길안내]와 관련된 상황 정보는 현재 위치이고 상황 정보 타입은 GPS 값임을 추출할 수 있다. 상황 이해기(112c)는 상황 정보 DB를 검색하여 현재 위치의 GPS 값을 추출한다. 상황 정보 DB에 현재 위치의 GPS 값이 저장되어 있지 않은 경우에는, 상황 정보 수집 관리기(112b)에 현재 위치의 GPS 값을 요청한다. 상황 정보 수집 관리기(112b)는 상황 정보 수집기(112a)에 신호를 보내 현재 위치의 GPS 값을 수집하도록 하고, 상황 정보 수집기(112a)는 차량 제어기로부터 GPS 값을 수집하여 상황 정보 DB에 저장하면서 GPS 값 수집 확인 신호를 상황 정보 수집 관리기(112b)에 전송한다. 상황 정보 수집 관리기(112b)가 상황 이해기(112 c)에 GPS 값 수집 확인 신호를 전달하면, 상황 이해기(112c)는 상황 정보 DB로부터 현재 위치의 GPS 값을 추출하여 대화 입력 관리기(111c)에 전달한다. 대화 입력 관리기(111c)는 자연어 이해 결과인 [도메인: 내비게이션], [액션: 길안내], [화행: 요청], [인자: NLU: 목적지: 서울역]와 [상황 정보: 현재 위치: 의왕역(GPS 값)]를 통합하여 대화 관리기에 전달한다. 도 35를 참조하면, 대화 흐름 관리기는 대화/액션 상태 DB를 검색하여 진행 중인 대화 태스크나 액션 태스크가 있는지 판단한다. 이 때, 대화 정책 DB를 참조할 수 있다. 당해 예시에서는 진행 중인 대화 태스 크나 액션 태스크가 없는 상태인 것으로 가정한다. 대화 흐름 관리기는 대화 액션 관리기에 입력 처리기의 출력에 대응되는 액션 태스크와 대화 태 스크를 생성하도록 요청한다. 액션 태스크와 대화 태스크를 생성하는 것은 액션 상태와 대화 상태에 대한 정보 를 저장하고 관리하기 위한 저장 공간을 할당하는 것을 의미한다. 따라서, 대화 액션 관리기는 대화/액션 상태 DB 내에 저장 공간을 할당하여 액션 상태에 대한 정보와 대화 상태에 대한 정보를 저장한다. 대화 액션 관리기는 액션 상태와 대화 상태를 액션 우선순위 결정기에 전달한다. 액션 우선순위 결정기는 연관 액션 DB(146b)에서 길 안내와 연계된 액션인 차량 상태 점검, 주유소 추천을 검색한다. 길 안내 액션 및 연계 액션들은 후보 액션이 된다. 액션 우선순위 결정기는 미리 저장된 규칙에 따라 각 후보 액션들의 우선 순위를 결정할 수 있다. 우선 순 위는 각 후보 액션 별 수행 조건이 판단되기 전에 결정될 수도 있고, 수행 조건이 판단된 이후에 수행 조건을 만족하는 후보 액션들에 대해서만 결정될 수도 있다. 후보 액션 목록은 다시 대화 액션 관리기로 전달되고, 대화 액션 관리기는 검색된 연계 액션들을 추 가하여 액션 상태를 업데이트한다. 도 36을 참조하면, 액션 우선순위 결정기는 액션 수행 조건 DB(146c)에서 각각의 후보 액션에 대한 수행 조건 및 수행 조건을 판단하기 위한 인자를 검색한다. 또한, 각 후보 액션들 사이의 우선 순위도 결정할 수 있 다. 예를 들어, 차량 상태 점검을 수행하기 위한 조건은 목적지 거리가 100km 이상인 경우일 수 있고, 수행 조건을 판단하기 위해 필요한 인자는 목적지 거리이다. 주유소 추천을 수행하기 위한 조건은 목적지 거리가 주행 가능 거리(DTE)보다 먼 경우일 수 있고, 수행 조건을 판단하기 위해 필요한 인자는 목적지 거리와 주행 가능 거리이다. 대화 액션 관리기는 대화/액션 상태 DB에 각 후보 액션을 수행하기 위한 조건과 조건 판단에 필요한 인자를 추가하여 액션 상태를 업데이트한다. 액션 우선순위 결정기는 각 후보 액션의 수행 조건 만족 여부를 판단하기 위해 필요한 인자 값을 대화/액 션 상태 DB, 상황 정보 DB, 장기 메모리 또는 단기 메모리에서 검색하여 가져올 수 있다. 인자 값이 이전 대화 내용에 포함되었거나, 대화 내용에 관련된 상황 정보에 포함되었거나, 발생된 이벤트에 관 련된 상환 정보에 포함된 경우, 대화/액션 상태 DB로부터 인자 값을 가져올 수 있다. 인자 값을 대화/액션 상태 DB, 상황 정보 DB, 장기 메모리 또는 단기 메모리에서 가져올 수 없는 경우에는 외부 정보 관리기에 요청할 수 있다. 예를 들어, 목적지 거리는 외부 정보 관리기를 통해, 내비게이션 서비스를 제공하는 외부 컨텐츠 서버 로부터 가져올 수 있고, DTE는 상황 정보 DB로부터 가져올 수 있다. 한편, 목적지 거리를 검색하기 위해서는 내비게이션 서비스에서 사용되는 정확한 목적지 정보가 필요하다. 당해 예시에서 사용자의 발화로부터 입력된 목적지는 “서울역”에 해당하는바, 서울역은 서울역으로 시작되는 다양한 종류의 장소를 나타내거나 특 정한 의미의 서울역일 수 있다. 따라서, “서울역”만으로는 정확한 목적지 거리를 검색하기 어렵다. 또한, 필요에 따라 인자 값을 차량과 연결된 모바일 기기에서 가져오는 것도 가능하다. 예를 들어, 장기 메모리에 저장되지 않은 연락처, 스케줄 등과 같은 사용자 정보가 인자 값으로 필요할 경우, 외부 정 보 관리기가 모바일 기기에 필요한 정보를 요청하여 필요한 인자 값을 획득할 수 있다. 또한, 저장부, 외부 컨텐츠 서버 및 모바일 기기를 통해서도 인자 값을 획득할 수 없는 경우에 는 사용자에게 질의하여 필요한 인자 값을 획득할 수 있다. 액션 우선순위 결정기는 인자 값을 이용하여 각 후보 액션의 수행 조건을 판단한다. 목적지 거리는 검색되 지 않았으므로, 일단 차량 상태 점검 액션과 주유소 추천 액션에 대해서는 수행 조건의 판단을 보류한다. 도 37에 도시된 바와 같이, 대화 액션 관리기는 대화/액션 상태 DB에 획득된 인자 값과 해당 인자 값 을 이용하여 판단된 액션 수행 조건 만족 여부를 추가하여 액션 상태를 업데이트한다. 대화 액션 관리기는 인자 관리기에 각 후보 액션의 수행에 사용되는 인자 목록을 요청한다. 인자 관리기는 액션 인자(146a)로부터 길 안내 액션의 수행에 사용되는 필수 인자로 현위치와 목적지를 추 출하고, 선택 인자로 경로 타입(초기값: 빠른 경로)을 추출할 수 있다. 차량 상태 점검 액션의 수행에 사용되는 선택 인자로 점검파트(초기값: 전체 파트)를 추출하고, 주유소 추천 액 션의 수행에 사용되는 선택 인자로 선호 주유소(초기값: A오일)를 추출할 수 있다. 추출된 인자 목록은 대화 액션 관리기로 전달되어 액션 상태를 업데이트하는데 사용될 수 있다. 인자 관리기는 각 후보 액션의 필수 인자와 선택 인자에 대응되는 인자 값을 획득하기 위해 대화/액션 상 태 DB, 상황 정보 DB, 장기 메모리 및 단기 메모리 중 각 인자의 참조 위치에서 해당 인자 값을 검색하고, 인자 값이 외부 서비스를 통해 제공되어야 하는 경우에는 외부 정보 관리기를 통해 외부 컨텐츠 서버에 필요한 인자 값을 요청할 수 있다. 후보 액션의 수행 조건을 판단하기 위해 사용되는 인자와, 후보 액션을 수행하는데 사용되는 인자가 상호 겹칠 수 있다. 액션 우선순위 결정기가 획득하여 대화/액션 상태 DB에 저장한 인자 값 중에 후보 액션을 수행하는데 사용되는 인자(필수 인자, 선택 인자)와 대응되는 것이 있으면, 이를 사용할 수 있다. 도 38을 참조하면, 대화 액션 관리기는 인자 관리기가 획득한 인자 값을 추가하여 액션 상태를 업데 이트한다. 전술한 바와 같이, 사용자 발화로부터 추출한 목적지(서울역)이 길 안내 액션의 인자로 사용되기에는 모호성이 있다. 따라서, 길 안내 액션의 인자(목적지), 차량 상태 점검 액션의 인자(목적지 거리), 주유소 추천 액션의 인자(목적지 거리)의 인자 값이 아직 획득되지 않았다. 모호성 해결기는 [인자:NLU:목적지:서울역]이 길 안내 액션에 적합한 목적지 인자로 변환하는데 모호성이 있는지 확인한다. 전술한 바와 같이 “서울역”은 서울역으로 시작되는 다른 종류의 장소를 의미할 수도 있고, 사용자가 의미하는 특정 위치의 서울역일 수도 있다. 모호성 해결기는 형태소 분석 결과를 참조하여 사용자 발화 중 서울역의 수식어가 있음을 확인한다. 모호 성 해결기는 “어제 간 서울역”의 위치를 파악하기 위해 장기 메모리, 단기 메모리에서 일정, 이동 위치, 연락처 등을 검색한다. 예를 들어, 모호성 해결기는 사용자의 어제 이동 위치로부터 “어제 간 서울역”이 “서울역 4번 출구”임 을 확인할 수 있다. “서울역 4번 출구”의 POI가 있음을 확인하고 해당 값을 가져온다. 모호성 해결기가 획득한 목적지 정보는 대화 액션 관리기로 전달되고, 대화 액션 관리기는 후보 액션의 목적지 인자에 “서울역 4번 출구”를 추가하여 액션 상태를 업데이트한다. 인자 관리기는 대화/액션 DB로부터 목적지 정보(서울역 4번 출구)를 가져오고, 외부 정보 관리기 를 통해 내비게이션 서비스를 제공하는 외부 컨텐츠 서버에 목적지 거리 값을 요청한다. 도 39를 참조하면, 외부 정보 관리기가 외부 컨텐츠 서버로부터 목적지 거리 값(80km)을 획득하여 인 자 관리기에 전달하면, 인자 관리기는 이를 대화 액션 관리기에 전달하여 액션 상태가 업데이트 될 수 있도록 한다. 액션 우선순위 결정기는 액션 상태를 참조하여 후보 액션의 수행 가능 여부를 판단하고, 우선 순위를 조절 할 수 있다. 길 안내 액션은 필수 인자인 현재 위치와 목적지의 인자 값이 획득되었으므로, 수행 가능하고, 차 량 상태 점검 액션은 목적지 거리(70km)가 100km 미만이므로 수행이 불가한 것으로 판단할 수 있다. 주유소 추 천 액션은 목적지 거리(80km)가 주행 가능 거리(DTE)보다 멀기 때문에 수행이 가능한 것으로 판단할 수 있다. 차량 상태 점검 액션은 수행이 불가하므로 우선순위 결정에서 제외한다. 따라서, 길 안내 액션이 우선순위 1번 으로, 주유소 추천 액션이 우선순위 2번으로 조절된다. 대화 액션 관리기는 후보 액션의 수행 가부와 조절된 우선 순위에 따라 액션 상태를 업데이트한다. 대화 흐름 관리기는 대화/액션 상태 DB에 저장된 대화 상태 및 액션 상태를 확인하고, 대화 정책 DB를 참조하여 대화를 진행하기 위한 대화 전략을 전개한다. 예를 들어, 수행 가능한 액션 중 우선 순위가 가장 높은 액션을 선택하고, 대화 정책 DB에 따라 대화를 진행하기 위한 응답을 생성하도록 응답 생성 관 리기에 요청할 수 있다. 대화/액션 DB에 저장된 대화 상태와 액션 상태는 [상태: 길안내 시작 확인]으로 각각 업데이트될 수 있다. 도 40을 참조하면, 응답 생성 관리기는 대화 흐름 관리기의 요청에 따라 대화 응답 생성기에 응 답 생성을 요청한다. 대화 응답 생성기는 응답 템플릿를 검색하여 TTS 응답, 텍스트 응답을 생성한다. 예를 들어, “의왕 역에서 서울역 4번 출구까지 30분이 소요될 것으로 예상됩니다. 안내를 시작할까요?”를 TTS와 텍스트로 출력할 수 있는 대화 응답을 생성할 수 있다. 또 다른 예로, 대화 흐름 관리기는 대화 응답 생성기에 선발화 이벤트를 전달할 수 있다. 이에 따라, 대화 응답 생성기는 “누구세요? 이름을 말씀해 주세요.”를 TTS와 텍스트로 출력할 수 있는 대화를 생성 할 수 있다. 또는, 대화 응답 생성기는 “A는 경유지에서 하차합니다”를 TTS와 텍스트로 출력할 수 있는 대화를 생성할 수 있다. 다시 말해서, 대화 응답 생성기는 동승자가 탑승한 경우 동승자를 식별하기 위한 질의뿐만 아니라, 동승자 각각의 하차 가능성 및 하차 후 재탑승 가능성을 판단하여 이에 관한 대화를 생성할 수 있다. 응답 생성 관리기는 대화 응답 생성기가 생성한 TTS 응답과 텍스트 응답을 출력 관리기와 메모 리 관리기에 전달하고, 출력 관리기는 TTS응답을 스피커에 전송하고 텍스트 응답을 디스플레이 에 전송한다. 이 때, 출력 관리기는 텍스트를 음성으로 합성하는 TTS모듈을 거쳐 TTS응답을 스피커 로 전송할 수 있다. 메모리 관리기는 사용자가 길 안내를 요청했음을 단기 메모리 또는 장기 메모리에 저장할 수 있 다. 디스플레이와 스피커를 통해 “의왕역에서 서울역 4번 출구까지 30분이 소요될 것으로 예상됩니다. 안내를 시작할까요?”라고 묻는 대화 응답이 출력된다. 도 41에 도시된 바와 같이, 사용자가 “그래”라고 발화 하면, 사용자의 발화는 음성 인식기(111a)로 입력되어 [텍스트: 그래]로 출력되고, 자연어 이해기(111b)는 사용 자의 발화로부터 [도메인:-], [액션:-], [화행: -], [형태소 분석 결과: 그래/IC]를 출력한다. 자연어 이해 결과는 대화 입력 관리기(111c)로 전달되고, 대화 입력 관리기(111c)는 이를 대화 관리기에 전달한다. 도 42를 참조하면, 대화 흐름 관리기는 대화/액션 상태 DB를 검색하여 이전 대화 상태를 분석하고, 진행 중인 [길 안내] 관련 대화/액션을 업데이트하도록 대화 액션 관리기에 요청한다. 대화 액션 관리기는 대화 상태와 액션 상태를 [상태: 길 안내 시작]으로 업데이트한다. 대화 흐름 관리기는 결과 처리기에 길 안내 시작을 위한 응답 생성을 요청한다. 도 43을 참조하면, 대화 액션 관리기는 대화 상태를 [상태: 다음 대화 진행]으로 업데이트하고, 액션 상태 를 [상태: execute]로 업데이트한다. 대화 흐름 관리기는 응답 생성 관리기에 길 안내를 위한 응답 생성을 요청한다. 응답 생성기는 “길 안내를 시작합니다”를 TTS와 텍스트로 출력할 수 있는 대화 응답을 생성하여 응답 생 성 관리기에 전달할 수 있다. 명령어 생성기는 길 안내를 수행하기 위한 명령어 [대상: 내비게이션, 명령: 길안내, 목적지: 서울역 4번 출구, 출발지: 의왕역]를 생성하여 응답 생성 관리기에 전달할 수 있다. 응답 생성 관리기는 생성된 대화 응답과 명령어를 출력 관리기에 전달한다. 출력 관리기는 디스 플레이 및 스피커를 통해 대화 응답을 출력하고, 길안내 명령어는 제어부를 통해 차량의 AVN에 전송하거나 내비게이션 서비스를 제공하는 외부 컨텐츠 서버에 전송할 수 있다. 도 44을 참조하면, 대화 흐름 관리기는 다음으로 실행 가능한 액션으로 주유소 추천을 선택하고, 주유소 추천 여부를 사용자에게 문의하는 응답을 생성하도록 응답 생성 관리기에 요청한다. 대화 상태와 액션 상태는 [상태: 연계 서비스 추천 확인]으로 업데이트될 수 있다. 응답 생성 관리기는 대화 응답 생성기에 TTS 응답 및 텍스트 응답 생성을 요청하고, 대화 응답 생성 기는 “목적지까지 이동하기 위한 연료가 부족합니다. 경유지로 A오일 주유소 추가할까요?”를 TTS와 텍스 트로 출력할 수 있는 대화 응답을 생성하여 응답 생성 관리기에 전달할 수 있다. 응답 생성 관리기는 대화 응답 생성기가 생성한 TTS 응답과 텍스트 응답을 출력 관리기와 메모 리 관리기에 전달하고, 출력 관리기는 TTS응답을 스피커에 전송하고 텍스트 응답을 디스플레이 에 전송한다. 디스플레이와 스피커를 통해 “목적지까지 이동하기 위한 연료가 부족합니다. 경유지로 A오일 주유소 추가할까요?”라고 묻는 대화 응답이 출력된다. 도 45에 도시된 바와 같이, 사용자가 “아니”라고 발화하면, 사용자의 발화는 음성 인식기(111a)로 입력되어 [텍스트: 아니]로 출력되고, 자연어 이해기(111b)는 사용자의 발화로부터 [도메인:-], [액션:-], [화행: -], [형태소 분석 결과: 아니/IC]를 출력한다. 대화 흐름 관리기는 대화 액션 관리기에 대화 상태 및 액션 상태의 업데이트를 요청한다. 대화 액션 관리기는 대화 상태를 [상태: 다음 대화 진행]으로 업데이트하고, 액션 상태를 [상태: CANCEL] 로 업데이트할 수 있다. 대화 흐름 관리기는 응답 생성 관리기에 주유소 추천 서비스를 취소했다는 응답을 생성하도록 요청하 고, 다음으로 진행 가능한 대화가 있는지 확인한다. 더 진행 가능한 대화가 없으면, 대화 상태를 [상태: IDLE]로 업데이트하고, 사용자의 입력을 기다린다. 앞서 설명한 데이터 처리의 흐름은 대화 시스템에 적용되는 일 예시에 불과하다. 따라서, 대화 시스템 의 각 구성요소들이 데이터를 처리하는 순서가 전술한 예시에 한정되는 것은 아니며, 복수의 구성요소들이 동시에 데이터를 처리하는 것도 가능하고, 전술한 예시와 다른 순서로 처리하는 것도 가능하다. 이하, 일 실시예에 따른 대화 처리 방법에 대해 설명한다. 일 실시예에 따른 대화 처리 방법에는 전술한 대화 시스템 또는 이를 포함하는 차량이 적용될 수 있다. 따라서, 도 1 내지 도 45에 대한 설명은 일 실시 예에 따른 대화 처리 방법에 대해서도 동일하게 적용될 수 있다. 도 46은 일 실시예에 따른 대화 처리 방법에 있어서, 사용자 입력을 처리하는 방법을 나타낸 순서도이다. 사용 자 입력을 처리하는 방법은 대화 시스템의 입력 처리기에서 수행될 수 있다. 도 46을 참조하면, 사용자의 발화가 입력되면(500의 예), 음성 인식기(111a)가 입력된 사용자의 발화를 인식한 다. 사용자의 발화는 차량에 마련된 음성 입력 장치 또는 모바일 기기에 마련된 음성 입력 장치를 통해 입력될 수 있다. 음성 인식기(111a)는 입력된 사용자의 발화를 인식하여 텍스트 형태의 발화문으로 출력한다. 자연어 이해기(111b)는 텍스트 형태의 발화문에 자연어 이해 기술을 적용하여, 그 결과를 출력한다. 구체적으로, 자연어 이해 과정은 텍스트 형태의 발화문에 기초하여 형태소 분석을 수행하고, 형태소 분석 결과에 기초하여 도메인을 추출하고, 개체명을 인식하고, 화행을 분석하고, 액션을 추출 하는 것을 포함할 수 있다. 도메인 추출, 개체명 인식 및 액션 추출을 위해 도메인/액션 추론 규칙DB을 참조할 수 있다. 자연어 이해기(111b)의 출력, 즉 자연어 이해 결과는 사용자의 발화에 대응되는 도메인, 액션, 화행, 형태소 분 석 결과 등을 포함할 수 있다. 추출된 액션과 관련된 상황 정보를 검색한다. 추출된 액션과 관련된 상황 정보는 상황 이해 테이블에 저장될 수 있고, 상황 이해기(112c)가 상황 이해 테이블에서 추출된 액션과 관련된 상황 정보를 검색하고, 검색된 상황 정보의 정보 값을 상황 정보DB, 장기 메모리 또는 단기 메모리로부터 가져온다. 추가 상황 정보가 필요한 경우(540의 예), 즉 상황 정보DB, 장기 메모리 또는 단기 메모리로부 터 가져올 수 없는 상황 정보가 있는 경우, 해당 상황 정보의 수집을 요청한다. 차량 상태 정보, 주변 환 경 정보, 운전자 정보 등의 음성 외 입력은 사용자의 발화 입력과 독립적으로 상황 정보 수집기(111a)를 통해 입력될 수 있다. 이러한 정보들은 주기적으로 입력될 수도 있고, 특정 이벤트 발생 시에 입력될 수도 있으며, 주기적으로 입력되 다가 특정 이벤트 발생 시에 추가적으로 더 입력될 수도 있다. 어느 경우이던지 정보의 수집이 요청되면 능동적 으로 해당 정보를 수집할 수 있다. 따라서, 액션과 관련된 상황 정보가 이미 수집되어 있는 경우에는 상황 정보 DB, 장기 메모리 또는 단기 메모리로부터 해당 정보를 가져오고, 그렇지 않은 경우에는 상황 정보 수집기(111a)를 통해 해당 정 보를 수집한다. 상황 정보의 수집을 요청 받은 상황 정보 수집기(111a)가 해당 상황 정보를 수집하여 상황 정보 DB에 저장 하면, 상황 이해기(112c)는 상황 정보 DB로부터 해당 상황 정보를 가져올 수 있다. 한편, 상황 정보 수집 관리기(112b)는 상황 정보 수집기(112a)가 수집한 데이터가 미리 설정된 조건을 만족하여 특정 이벤트가 발생한 것으로 판단하면 상황 이해기(112c)에 액션 트리거 신호를 전송할 수 있다. 상황 이해기(112c)는 상황 이해 테이블을 검색하여 해당 이벤트와 관련된 상황 정보를 검색하고, 검색된 상황 정보가 저장되어 있지 않으면 다시 상황 정보 수집 관리기(112b)에 상황 정보의 요청 신호를 전송한다. 필요한 상황 정보의 수집이 완료되면, 자연어 이해 결과와 상황 정보를 대화 관리기로 전송한다. 이 벤트가 발생된 경우에는, 이벤트와 관련된 정보(어떤 이벤트가 발생되었는지)와 발생된 이벤트와 관련된 상황 정보도 함께 전송할 수 있다. 도 47은 일 실시예에 따른 대화 처리 방법에 있어서, 입력 처리기의 출력을 이용하여 대화를 관리하는 방법을 나타낸 순서도이다. 대화를 관리하는 방법은 대화 시스템의 대화 관리기에서 수행될 수 있다. 도 47을 참조하면, 대화 흐름 관리기가 대화/액션 상태 DB에 관련 대화 이력이 있는지 검색한다 . 당해 예시에서는 사용자의 발화로부터 도메인과 액션을 추출할 수 있는 경우를 예로 들어 설명하나, 발화 내용 자체나 상황이 모호하여 사용자의 발화로부터 도메인과 액션을 추출할 수 없는 경우도 있을 수 있다. 이 경우, 대화 액션 관리기는 임의의 대화 상태를 생성하고, 모호성 해결기가 사용자의 발화 내용, 주변 상황, 차량 상태, 사용자 정보 등에 기초하여 사용자의 의도를 파악하고 이에 대응되는 적절한 액션을 판단할 수 있다. 관련 대화 이력이 존재하면(600의 예) 이를 참조하고, 존재하지 않으면(600의 아니오), 새로운 대화 태스 크 및 액션 태스크를 생성한다. 연관 액션 DB(146b)에서 사용자 발화로부터 추출된 액션(이하, 입력 액션이라 한다)과 연관된 연관 액션 목록을 검색하여 후보 액션 목록을 생성한다. 입력 액션 및 이와 연관된 액션들이 후보 액션 목록이 된다. 액션 수행조건 DB(146c)에서 후보 액션 별 수행 조건을 검색한다. 수행 조건은 액션을 수행하기 위해 필요 한 조건으로서, 해당 조건이 만족되면 액션 수행이 가능한 것으로 판단하고, 만족되지 않으면 액션 수행이 불가 한 것으로 판단한다. 액션 수행조건 DB(146c)에는 액션 수행 조건 판단에 사용되는 인자의 종류에 대한 정보도 함께 저장된다. 액션 수행 조건 판단에 사용되는 인자 값을 획득한다. 액션 수행 조건 판단에 사용되는 인자는 조건 판단 인자라 하기로 한다. 상황 정보 DB, 장기 메모리, 단기 메모리 또는 대화/액션 상태 DB를 검색하여 조건 판단 인자의 인자 값을 획득할 수 있다. 조건 판단 인자의 인자 값이 외부 서비스를 통해 제공되 어야 하는 경우에는, 외부 정보 관리기를 통해 외부 컨텐츠 서버로부터 필요한 인자 값을 제공받을 수 있다. 또한, 상황이나 발화가 모호하여 필요한 인자 값을 획득할 수 없는 경우에는 모호성 해결기를 통해 모호성 을 해결하여 필요한 인자 값을 획득할 수 있다. 또한, 획득된 인자가 액션 수행 조건 판단에 사용되기 어려운 비유효 인자인 경우에도 모호성 해결기가 비 유효 인자로부터 유효 인자를 획득할 수 있다. 획득된 조건 판단 인자에 기초하여 후보 액션 별로 수행 가부를 판단하고, 후보 액션들의 우선 순위를 결 정한다. 후보 액션들의 우선 순위를 결정하는 규칙은 미리 저장될 수 있다. 액션 우선순위 결정기는 액션 수행 가부가 판단된 이후에 액션 수행이 가능한 후보 액션들만 고려하여 우선 순위를 결정할 수 있다. 또 는, 액션들의 수행 가부에 상관없이 우선 순위를 결정한 이후에, 액션 수행 가부에 기초하여 우선 순위를 조절 할 수도 있다. 액션 인자 DB(146a)에서 후보 액션의 수행에 사용되는 인자 목록을 검색한다. 액션의 수행에 사용되는 인 자는 액션 인자라 하기로 한다. 액션 인자는 필수 인자와 선택 인자를 포함할 수 있다. 후보 액션의 수행에 사용되는 액션 인자의 인자 값을 획득한다. 상황 정보 DB, 장기 메모리, 단 기 메모리 또는 대화/액션 상태 DB를 검색하여 액션 인자의 인자 값을 획득할 수 있다. 액션 인자의 인자 값이 외부 서비스를 통해 제공되어야 하는 경우에는, 외부 정보 관리기를 통해 외부 컨텐츠 서버 로부터 필요한 인자 값을 제공받을 수 있다. 또한, 상황이나 발화가 모호하여 필요한 인자 값을 획득할 수 없는 경우에는 모호성 해결기를 통해 모호성 을 해결하여 필요한 인자 값을 획득할 수 있다. 또한, 획득된 인자가 액션의 수행에 사용되기 어려운 비유효 인자인 경우에도 모호성 해결기가 비유효 인 자로부터 유효 인자를 획득할 수 있다. 대화 액션 관리기에 의해 관리되는 대화 상태 및 액션 상태는 전술한 단계들이 수행되면서 상태가 변경될 때마다 업데이트될 수 있다. 획득 가능한 인자 값들이 모두 획득되면 대화 흐름 관리기가 결과 처리기에 후보 액션에 관한 정보와 대화 상태를 전달한다. 대화 정책에 따라 1순위에 해당하는 액션에 관한 정보만 전달하는 것도 가능하고, 복수의 후보 액션에 관한 정보를 전달하는 것도 가능하다. 한편, 필요한 인자 값이 외부 컨텐츠 서버, 장기 메모리, 단기 메모리 및 상황 정보 DB에 존재하지 않고, 사용자를 통해서만 획득될 수 있는 경우에는 사용자에게 인자 값을 질의하기 위한 대화 응답을 출력하는 것도 가능하다. 도 48은 일 실시예에 따른 대화 처리 방법에 있어서, 대화 관리의 결과에 대응되는 응답을 생성하기 위한 결과 처리 방법을 나타낸 순서도이다. 결과 처리 방법은 대화 시스템의 결과 처리기에 의해 수행될 수 있 다. 도 48을 참조하면, 대화 응답의 생성이 필요한 경우(700의 예), 대화 응답 생성기가 응답 템플릿을 검색한다. 응답 템플릿에서 현재 대화 상태와 액션 상태에 대응되는 대화 응답 서식을 추출하고, 대 화 응답 서식에 필요한 인자 값을 채워 대화 응답을 생성한다. 대화 응답 생성에 필요한 인자 값이 대화 관리기로부터 전달되지 않거나, 외부 컨텐츠를 이용하라는 지시 가 전달된 경우에는 외부 컨텐츠 서버로부터 제공받거나 장기 메모리, 단기 메모리 또는 상황 정보 DB에서 검색할 수 있다. 필요한 인자 값이 외부 컨텐츠 서버, 장기 메모리, 단기 메모리 및 상황 정보 DB에 존재하지 않고, 사용자를 통해서만 획득될 수 있는 경우에는 사용자에게 인자 값 을 질의하기 위한 대화 응답을 생성하는 것도 가능하다. 명령어 생성이 필요한 경우에는, 명령어 생성기가 차량 제어 또는 외부 컨텐츠 이용을 위한 명령어를 생성한다. 생성된 대화 응답 또는 명령어는 출력 관리기로 입력되고, 출력 관리기는 대화 응답과 명령어 사이의 출력 순서 또는 복수의 명령어 사이의 출력 순서를 결정할 수 있다. 생성된 대화 응답 또는 명령어에 기초하여 메모리를 업데이트한다. 메모리 관리기는 생성 및 출력된 대화 응답에 기초하여 사용자와 시스템 간 대화 내용을 저장하여 단기 메모리를 업데이트할 수 있고, 사용 자와의 대화를 통해 획득된 사용자 관련 정보를 저장하여 장기 메모리를 업데이트할 수 있다. 또한, 생성 및 출력된 차량 제어나 외부 컨텐츠 요청에 기초하여 장기 메모리에 저장된 사용자의 선호도나 차량 제어 이력 등을 업데이트할 수 있다. 출력 관리기는 대화 응답과 명령어를 적절한 출력 위치로 전송하여 응답을 출력한다. TTS 응답은 스 피커를 통해 출력할 수 있고, 텍스트 응답은 디스플레이를 통해 출력할 수 있다. 명령어는 그 제어 대상에 따라 차량 제어기로 전송될 수도 있고, 외부 컨텐츠 서버로 전송될 수도 있으며, 외부 컨텐츠 서버와 통신하기 위한 통신 장치로 전송될 수도 있다. 도 49 내지 도 51은 일 실시예에 따른 대화 처리 방법에 있어서, 사용자의 발화 입력 전에 대화 시스템이 선발 화를 출력하는 경우를 나타낸 순서도이다. 도 49를 참조하면, 상황 수집기(112a)와 상황 수집 관리기(112b)가 상황 정보를 수집한다. 구체적으로, 차 량 제어기는 잔유량, 강우량, 강우 속도, 주변 장애물 정보, 속도, 엔진 온도, 타이어 공기압, 현재 위치 등과 같이 차량에 마련된 센서로부터 획득되는 차량 상태 정보와 주변 환경 정보를 상황 처리기에 입력할 수 있고, 음성 외 입력 장치에 입력된 사용자 정보나 외부 컨텐츠 서버 또는 외부 기기로부터 획득된 정보 역시 상황 처리기에 입력될 수 있다. 수집된 상황 정보는 상황 정보 DB, 장기 메모리 또는 단기 메모리에 저장될 수 있다. 선발화 판단기는 상황 정보에 기초하여 선발화 조건을 판단한다. 선발화 조건은 선발화 조건 테이블 (145a)에 저장될 수 있다. 전술한 도 25a 내지 도 25d의 예시와 같이, 선발화 조건 테이블(145a)에는 상황 정보 와 관련된 선발화 조건이 상황 정보 별로 저장될 수 있다. 선발화 판단기는 상황 정보 DB, 장기 메모리 또는 단기 메모리로부터 전달된 상황 정보가 선발화 조건을 만족하면(812의 예), 선발화 상황인 것으로 판단하고 선발화 트리거 신호를 생성한다. 선발화 판단기는 선발화 상황에 대응되는 액션을 추출한다. 전술한 도 25c의 예시와 같이, 선발화 조 건 테이블(145a)에는 선발화 상황마다 그에 대응되는 액션이 미리 저장될 수 있다. 선발화 판단기는 선발 화 조건 테이블(145a)로부터 선발화 상황에 대응되는 액션을 추출할 수 있다. 또는, 선발화 판단기가 정해 진 규칙에 따라 선발화 상황에 대응되는 액션을 생성하는 것도 가능하다. 선발화 판단기가 선발화 트리거 신호와 선발화 상황에 대응되는 액션을 대화 입력 관리기(111c)에 전달하 면, 대화 입력 관리기(111c)는 대화 관리기에 선발화 상황에 대응되는 액션을 전달한다. 이 때, 선발 화 트리거 신호 또는 선발화 상황임을 나타내는 신호가 함께 전달되는 것도 가능하다. 선발화 상황에 대응되는 액션이 대화 관리기에 전달된 이후에는 전술한 도 47에 도시된 바와 같이 대화 태 스크 및 액션 태스크를 생성하고 액션 인자를 획득하는 일련의 과정들이 수행될 수 있다. 이 때, 다른 대화 태 스크나 액션 태스크가 수행중인 경우, 대화 흐름 관리기가 선발화 상황에 대한 태스크를 우선적으로 생성 및 처리하는 것도 가능하고, 정해진 규칙에 따라 우선 순위를 결정하는 것도 가능하다. 대화 관리기가 우선적으로 처리될 액션에 관한 정보를 결과 처리기에 전달하면, 응답 생성기는 응답 템플릿을 검색하여 대화 응답 서식을 추출할 수 있다. 응답 생성기는 추출된 응답 서식에 필요 한 인자 값을 채워 대화 응답을 생성할 수 있고, 생성된 대화 응답은 응답 생성 관리기를 통해 출력 관리 기에 전달될 수 있다. 출력 관리기는 생성된 대화 응답을 차량이나 모바일 기기에 마련된 스피커를 통해 출력할 수 있다. 또는, 선발화 상황에 대응되는 선발화 메시지 자체를 추출하거나 생성하는 것도 가능하다. 도 50을 참조하면, 상황 수집기(112a)와 상황 수집 관리기(112b)가 상황 정보를 수집하고, 선발화 판단기는 상황 정보에 기초하여 선발화 조건을 판단한다. 선발화 판단기는 상황 정보 DB, 장기 메모리 또는 단기 메모리로부터 전달된 상황 정보가 선발화 조건을 만족하면(822의 예), 선발화 상황인 것으로 판단하고 선발화 트리거 신호를 생성한다. 선발 화 판단기는 선발화 상황에 대응되는 선발화 메시지를 추출한다. 전술한 도 25a, 도 25b, 도25c 및 도 25d의 예시와 같이, 선발화 조건 테이블(145a)에는 선발화 상황마다 그에 대응되는 선발화 메시지가 미리 저 장될 수 있다. 미리 저장되는 선발화 메시지는 현재 상황을 알려주는 내용일 수도 있고, 선발화 상황에 필요한 특정 기능 또는 서비스의 실행을 먼저 제안하는 내용일 수도 있다. 또는 선발화 판단기가 미리 정해진 규 칙에 따라 선발화 메시지를 생성하는 것도 가능하다. 선발화 판단기가 선발화 트리거 신호와 선발화 메시지를 대화 입력 관리기(111c)에 전달하면, 대화 입력 관리기(111c)는 대화 관리기에 선발화 메시지를 전달한다. 이 때, 선발화 트리거 신호 또는 선발화 상황임을 나타내는 신호가 함께 전달되는 것도 가능하다. 대화 관리기는 전달된 선발화 메시지를 출력하기 위한 대화 태스크를 생성하고, 선발화 메시지를 결과 처 리기에 전달할 수 있다. 결과 처리기는 입력된 선발화 메시지를 스피커를 통해 출력할 수 있다. 또는, 선발화 상황에 대응되는 가상의 사용자의 발화를 추출하거나 생성하는 것도 가능하다. 도 51을 참조하면, 상황 수집기(112a)와 상황 수집 관리기(112b)가 상황 정보를 수집하고, 선발화 판단기는 상황 정보에 기초하여 선발화 조건을 판단한다. 상황 이해기(112c)는 상황 정보 DB, 장기 메모리 또는 단기 메모리로부터 전달된 상황 정보가 선발화 조건을 만족하면(832의 예), 선발화 상황인 것으로 판단하고 선발화 트리거 신호를 생성한다. 선발화 판단기는 선발화 상황에 대응되는 가상의 사용자 발화를 추출한다. 도면에 도시되지는 않았으 나, 선발화 조건 테이블(145a)에는 선발화 상황마다 그에 대응되는 가상의 사용자 발화가 미리 저장될 수 있다. 선발화 판단기는 선발화 조건 테이블(145a)로부터 선발화 상황에 대응되는 가상의 사용자 발화를 추출할 수 있다. 또는, 선발화 판단기가 정해진 규칙에 따라 선발화 상황에 대응되는 가상의 사용자 발화를 생성 하는 것도 가능하다. 선발화 판단기가 텍스트 형태의 가상의 사용자 발화를 자연어 이해기(111b)에 전달하면, 자연어 이해 기(111b)는 사용자가 실제로 발화한 경우와 마찬가지로 가상의 사용자 발화로부터 도메인, 액션 등을 추출할 수 있다. 대화 입력 관리기(111c)는 선발화 트리거 신호와 자연어 이해 결과를 대화 관리기에 전달한다. 여기 서, 자연어 이해 결과는 가상의 사용자 발화로부터 추출된 도메인, 액션 등을 포함할 수 있고, 추출된 도메인, 액션은 선발화 상황에 대응되는 도메인, 액션이 된다. 예를 들어, 모바일 기기가 차량과 대화 시스템 사이의 게이트웨이 역할을 수행하는 모바일 게이 트웨이 방식에 있어서, 모바일 기기의 대화 시스템 클라이언트가 선발화 판단기의 동작 중 일부 를 수행할 수 있다. 이 경우, 대화 시스템 클라이언트가 선발화 상황에 대응되는 가상의 사용자 발화를 생성하여 자연어 이해기(111b)에 전달할 수 있다 선발화 트리거 신호와 자연어 이해 결과가 대화 관리기에 전달된 이후에는 전술한 도 47에 도시된 바와 같 이 대화 태스크 및 액션 태스크를 생성하고 액션 인자를 획득하는 일련의 과정들이 수행될 수 있다. 이 때, 다 른 대화 태스크나 액션 태스크가 수행중인 경우, 대화 흐름 관리기가 선발화 상황에 대한 태스크를 우선적 으로 생성 및 처리하는 것도 가능하고, 정해진 규칙에 따라 우선 순위를 결정하는 것도 가능하다. 대화 관리기가 우선적으로 처리될 액션에 관한 정보를 결과 처리기에 전달하면, 응답 생성기는 응답 템플릿을 검색하여 대화 응답 서식을 추출할 수 있다. 응답 생성기는 추출된 응답 서식에 필요 한 인자 값을 채워 대화 응답을 생성할 수 있고, 생성된 대화 응답은 응답 생성 관리기를 통해 출력 관리 기에 전달될 수 있다. 출력 관리기는 생성된 대화 응답을 차량 또는 모바일 기기에 마련된 스피커를 통해 출력할 수 있다. 도 52는 일 실시예에 따른 대화 처리 방법에 있어서, 사용자의 발화 입력 전에 대화 시스템이 선발화를 출력하 는 경우에 중복 태스크를 처리하는 과정을 나타낸 순서도이다. 도 52를 참조하면, 상황 수집기(112a)와 상황 수집 관리기(112b)가 상황 정보를 수집하고, 선발화 판단기 는 상황 정보에 기초하여 선발화 조건을 판단한다. 선발화 판단기는 상황 정보 DB, 장기 메모리 또는 단기 메모리로부터 전달된 상황 정보가 선발화 조건을 만족하는지 여부를 판단하고, 선발화 조건이 만족되면(842의 예), 중복 태스크 처리기가 현 재 발생한 선발화 상황에 관련된 태스크의 중복 여부를 판단한다. 구체적으로, 중복 태스크 처리기는 태스크 처리 DB(145b)에 저장된 대화 시스템에서 처리되었거나 진 행 중인 태스크에 관한 정보에 기초하여 현재 발생한 선발화 상황과 관련된 대화, 액션 등의 태스크가 이미 처 리되었거나, 진행 중인지 여부를 판단할 수 있다. 예를 들어, 현재 발생한 선발화 상황에 관련된 대화가 이미 수행되었고, 대화 수행 시점으로부터 기준 시간이 경과하지 않았으면, 현재 선발화 상황에 관련된 태스크를 중복 태스크로 판단할 수 있다. 또는, 현재 발생한 선 발화 상황에 관련된 대화나 관련된 액션이 진행 중인 경우에도 중복 태스크로 판단할 수 있다. 즉, 중복 태스크 처리기는 태스크 처리 DB(145b)에 저장된 대화 이력 및 태스크 수행 여부에 기초하여 이 미 출력된 선발화 인지 여부, 선발화 상황에 대한 사용자의 의사 등을 판단할 수 있고, 저장된 대화 시점, 사용 자의 의사 또는 태스크 진행 여부에 기초하여 중복 태스크 여부를 판단할 수 있다. 현재 선발화 상황에 관련된 태스크가 중복 태스크인 것으로 판단되면(843의 예), 중복 태스크 처리기는 선 발화 상황을 종료시킨다. 중복 태스크가 아닌 것으로 판단되면(843의 아니오), 전술한 실시예와 같이 선발화 동작을 수행할 수 있다 . 예를 들어, 선발화 트리거 신호와 선발화 상황에 대응되는 액션 또는 선발화 메시지를 대화 관리기(12 0)에 전달할 수 있다. 또는, 선발화 상황에 대응되는 가상의 사용자 발화를 자연어 이해기(111b)에 전달하고, 자연어 이해 결과와 선발화 트리거 신호를 대화 관리기에 전달할 수도 있다. 전술한 실시예에서는, 선발화를 위한 대화 처리 방법을 수행하기 위해 선발화 판단기, 중복 태스크 처리기 와 같은 별도의 구성요소와 선발화 조건 테이블(145a), 태스크 처리 DB(145b)와 같은 별도의 저장소가 사 용되는 것으로 가정하여 설명하였다. 그러나, 대화 처리 방법의 실시예가 이에 한정되는 것은 아니고, 상황 이 해기(112c)가 선발화 판단기 및 중복 태스크 처리기의 동작을 수행하거나, 상황 이해 테이블에 선발화 조건 테이블(145a), 태스크 처리 DB(145b)에 저장되는 정보가 저장되는 것도 가능하다. 일 실시예에 따른 대화 처리 방법은 전술한 순서도 상의 순서에 의해 제한되지 않는다. 도 44 내지 도 52의 순 서도에 따른 흐름은 대화 처리 방법에 적용될 수 있는 일 예시에 불과하며, 복수의 단계가 동시에 수행되는 것 도 가능하고, 각 단계들의 순서가 바뀌는 것도 가능하다. 도 53은 일 실시예에 따른 대화 처리 방법에 있어서, 차량 내 동승자의 탑승을 판단하고 선발화를 출력하는 방 법을 나타낸 순서도이다. 도 53을 참조하면, 대화 시스템은 차량 내 탑승자 간 대화 및 차량 조작 정보 중 적어도 하나에 기초하여 동승자의 탑승을 판단할 수 있다. 예를 들어, 대화 시스템은 음성 입력 처리기에 입력된 차량 내 탑승자 간 대화에 기초하여 동승자의 탑승을 판단할 수 있다. 차량 내 탑승자는 운전자 및 적어도 하나의 동승자를 포함하고, 차량 조작 정보는 음성 외 입력 장치의 조작 정보를 포함할 수 있다. 대화 시스템의 동승자의 탑승 판단은 차랑의 주행 시작 이후 일정시간 동안 또는 차량의 정차 이후 일정시간 동안 수행될 수 있다. 음성 입력 처리기는 차량에 마련된 음성 입력 장치 또는 모바일 기기에 마련된 음성 입력 장치를 통해 입력된 차량 내 탑승자 간 대화에 기초하여 동승자 각각의 음성을 구분할 수 있다. 음성 입력 처리기는 음성 입력 장치 또는 모바일 기기에 마련된 음성 입력 장치를 통해 입 력된 동승자 각각의 음성을 음성 특성 정보에 기초하여 구분하여, 동승자 각각을 감지할 수 있다. 음성 특성 정보는 비언어적 특성 및 언어적 특성 중 적어도 하나를 포함할 수 있다. 동승자의 탑승을 판단하기 위해 음성 입력 처리기가 입력 받은 차량 내 탑승자 간 대화는 차량에 의 도를 전달하는 발화가 아닌 운전자를 포함한 차량 내 탑승자 간의 대화를 의미할 수 있다. 또한, 대화 시스템의 상황 정보 처리기는 차량 조작 정보에 기초하여 동승자의 탑승을 판단할 수 있 다. 즉, 대화 시스템은 대화에 참여하지 않아 음성 입력 처리기를 통해 탑승을 판단하지 못한 동승자 가 존재하는지 여부를 확인하기 위해 차량 조작 정보에 기초하여 동승자의 탑승을 판단할 수 있다. 차량 조작 정보는 조수석(245b) 및 후열 시트(254c, 254d) 각각에 대한 윈도우 조정 버튼 조작 정보, 시트 조정 버튼 조작 정보 및 공조 장치 조정 버튼 조작 정보 중 적어도 하나를 포함할 수 있다. 상황 정보 처리기는 차량 조작 정보에 기초하여 동승자의 탑승을 판단할 수 있다. 즉, 입력 처리기는 음성 입력 처리기 및 상황 정보 처리기 중 적어도 하나를 통해 동승자가 탑 승한 상황이나 동승자가 탑승하지 않은 상황을 나타내는 동승자 탑승 정보를 수집할 수 있다. 차랑의 주행 시작 이후 일정시간 동안 또는 차량의 정차 이후 일정시간 동안 동승자의 탑승을 판단한 경우(5300의 예), 대화 시스템은 신원 정보 요청을 위한 선발화를 출력할 수 있다. 구체적으로, 대 화 시스템은 동승자의 탑승을 판단한 경우, 동승자의 신원 정보를 요청하기 위한 선발화를 출력할 수 있다. 예를 들어, 대화 시스템은 동승자의 탑승을 판단한 경우, \"누구세요? 이름을 말씀해 주세요\"와 같이 동승 자의 신원 정보를 요청하기 위한 내용의 선발화를 출력할 수 있다. 입력 처리기의 선발화 판단기는 동승자 탑승 여부의 상황 정보에 기초하여 동승자의 탑승이 판단되었 는지 여부를 선발화 조건으로 선발화 출력 여부를 판단한다. 또한, 선발화 판단기는 동승자 탑승 여부의 상황 정보가 동승자의 탑승 판단이라는 선발화 조건을 만족하면, 선발화 상황인 것으로 판단하고 선발화 트리거 신호를 생성한다. 선발화 판단기는 \"누구세요? 이름을 말씀해 주세요\"와 같이 동승자가 탑승한 선발화 상황에 대응되는 선발 화 메시지를 추출한다. 선발화 판단기가 선발화 트리거 신호와 선발화 메시지를 대화 입력 관리기(111c)에 전달하면, 대화 입력 관리기(111c)는 대화 관리기에 선발화 메시지를 전달한다. 이 때, 선발화 트리거 신 호 또는 선발화 상황임을 나타내는 신호가 함께 전달되는 것도 가능하다. 대화 관리기는 전달된 선발화 메시지를 출력하기 위한 대화 태스크를 생성하고, 선발화 메시지를 결과 처 리기에 전달할 수 있다. 결과 처리기는 입력된 선발화 메시지를 스피커를 통해 출력할 수 있다. 대화 시스템은 동승자의 발화를 입력 받아 동승자를 식별할 수 있다. 구체적으로, 대화 시스템(10 0)은 선발화 메시지에 대한 동승자의 발화를 입력 받아 동승자를 식별할 수 있다. 예를 들어, 동승자는 동승자의 신원 정보 요청을 나타내는 선발화 메시지에 응답하여 \"나는 OO이야\"라고 발화할 수 있다. 즉, 동승자는 신원 정보를 요청하는 선발화 메시지에 응답하여 동승자 자신의 이름을 포함하는 메시지 를 발화할 수 있다. 동승자의 발화가 입력되면, 음성 입력 처리기가 입력된 동승자의 발화를 인식한다. 동승자의 발화는 차량 에 마련된 음성 입력 장치 또는 모바일 기기에 마련된 음성 입력 장치를 통해 입력될 수 있다. 음성 인식기(111a)는 입력된 동승자의 발화를 인식하여 텍스트 형태의 발화문으로 출력한다. 자연어 이해기 (111b)는 텍스트 형태의 발화문에 자연어 이해 기술을 적용하여, 그 결과를 출력한다. 자연어 이해 과정은 텍스트 형태의 발화문에 기초하여 형태소 분석을 수행하고, 형태소 분석 결과에 기초하여 이름을 인식하는 것을 포함할 수 있다. 또한, 자연어 이해기(111b)는 이름의 인식률을 높이기 위해 장기 메모리에 저장되어 있는 운전자의 전화번 호부를 이용할 수 있다. 구체적으로, 자연어 이해기(111b)는 동승자의 발화에 포함된 이름과 전화번호부에 포함 된 이름을 비교하여 동승자의 발화에 포함된 이름의 인식률을 높일 수 있다. 동승자 판단기(111d)는 자연어 이해기(111b)의 출력을 기반으로, 동승자의 이름을 확인할 수 있으며, 이를 통해 동승자의 신원을 식별할 수 있다. 이를 통해, 대화 시스템은 동승자의 발화에 기초하여 메시지를 발화한 동승자의 신원을 식별할 수 있다. 식별된 동승자에 대한 동승자 정보는 저장부에 실시간으로 저장될 수 있으며, 동승자 정보는 개인 식별 정 보, 음성 특성 정보 및 착석 위치 정보를 포함할 수 있다. 동승자의 탑승 판단하지 못한 경우(5300의 예), 대화 시스템은 동승자 존재 여부 확인을 위한 선발화를 출 력할 수 있다. 구체적으로, 대화 시스템은 차랑의 주행 시작 이후 일정시간 동안 또는 차량 의 정차 이후 일정시간 동안 동승자의 탑승을 판단하지 못한 경우, 동승자 존재 여부를 확인하기 위한 선 발화를 출력할 수 있다. 예를 들어, 대화 시스템은 차랑의 주행 시작 이후 일정시간 동안 또는 차량의 정차 이후 일정시 간 동안 동승자의 탑승을 판단하지 못한 경우, \"더 타실 분은 없으신가요?”와 같이 운전자에게 동승자 존재 여 부를 확인하기 위한 내용의 선발화를 출력할 수 있다. 선발화 판단기는 동승자 탑승 여부의 상황 정보에 기초하여 동승자가 비-탑승하였는지 여부를 선발화 조건 으로 선발화 출력 여부를 판단한다. 또한, 선발화 판단기는 동승자 탑승 여부의 상황 정보가 동승자가 탑 승하지 않은 선발화 조건을 만족하면, 선발화 상황인 것으로 판단하고 선발화 트리거 신호를 생성한다. 선발화 판단기는 \"더 타실 분은 없으신가요?\"와 같이 동승자가 탑승하지 않은 선발화 상황에 대응되는 선 발화 메시지를 추출한다. 선발화 판단기가 선발화 트리거 신호와 선발화 메시지를 대화 입력 관리기(111 c)에 전달하면, 대화 입력 관리기(111c)는 대화 관리기에 선발화 메시지를 전달한다. 이 때, 선발화 트리 거 신호 또는 선발화 상황임을 나타내는 신호가 함께 전달되는 것도 가능하다. 대화 관리기는 전달된 선발화 메시지를 출력하기 위한 대화 태스크를 생성하고, 선발화 메시지를 결과 처 리기에 전달할 수 있다. 결과 처리기는 입력된 선발화 메시지를 스피커를 통해 출력할 수 있다. 대화 시스템은 운전자의 발화를 입력 받아 동승자 존재 여부를 확인할 수 있다. 구체적으로, 대화 시스템은 선발화 메시지에 대응한 운전자의 발화를 입력 받아 동승자 존재 여부를 확인할 수 있다. 예를 들어, 운전자는 동승자 존재 여부를 묻는 선발화 메시지에 응답하여 \"없어\"라고 발화하거나 \"있어\"라고 발 화할 수 있다. 즉, 운전자는 동승자 존재 여부를 묻는 선발화 메시지에 응답하여 동승자 존재 여부를 나타내는 응답을 포함하는 메시지를 발화할 수 있다. 운전자의 발화가 입력되면, 음성 입력 처리기가 입력된 운전자의 발화를 인식한다. 운전자의 응답은 차량 에 마련된 음성 입력 장치 또는 모바일 기기에 마련된 음성 입력 장치를 통해 입력될 수 있다. 음성 인식기(111a)는 입력된 사용자의 발화를 인식하여 텍스트 형태의 발화문으로 출력한다. 자연어 이해기 (111b)는 텍스트 형태의 발화문에 자연어 이해 기술을 적용하여, 그 결과를 출력한다. 자연어 이해기(111b)는 발화문으로부터 개체명을 인식할 수 있다. 개체명은 인명, 지명, 조직명, 시간, 날짜, 화폐 등의 고유 명사로서, 개체명 인식은 문장에서 개체명을 식별하고 식별된 개체명의 종류를 결정하는 작업이 다. 개체명 인식을 통해 문장에서 중요한 키워드를 추출하여 문장의 의미를 파악할 수 있다. 구체적으로, 자연어 이해 과정은 텍스트 형태의 발화문에 기초하여 형태소 분석을 수행하고, 형태소 분석 결과 에 기초하여 개체명을 인식하는 것을 포함할 수 있다. 자연어 이해기(111b)의 출력, 즉 자연어 이해 결과는 동승자의 발화에 대응되는 개체명, 형태소 분석 결과 등을 포함할 수 있다. 동승자 판단기(111d)는 자연어 이해기(111b)의 출력을 기반으로, 동승자 존재 여부를 식별할 수 있다. 이를 통해, 음성 입력 처리기는 운전자의 발화에 기초하여 동승자 존재 여부를 확인할 수 있다. 도 54는 일 실시예에 따른 대화 처리 방법에 있어서, 동승자 인원 변화를 예측하고 선발화를 출력하는 방법을 나타낸 순서도이다. 도 54를 참조하면, 대화 시스템은 도 53에서 설명한 바와 같이, 동승자를 식별할 수 있다. 구체적으 로, 대화 시스템은 차량 내 탑승자 간 대화 및 차량 조작 정보 중 적어도 하나에 기초하여 동승자의 탑승 을 판단하고, 선발화를 통해 동승자를 식별할 수 있다. 대화 시스템은 차량 내 탑승자 간 대화에 기초하여 동승자 인원 정보를 생성할 수 있다. 구체적으로, 대화 시스템은 차량 내 탑승자 간 대화를 지속적으로 입력 받아 특정 경유지에서의 동승자 각 각의 하차 가능성 및 하차 후 재탑승 가능성을 판단할 수 있다. 예를 들어, 대화 시스템 상의 음성 입력 처리기는 차량에 마련된 음성 입력 장치 또는 모 바일 기기에 마련된 음성 입력 장치를 통해 차량 내 탑승자 간 대화를 지속적으로 입력 받을 수 있다. 음성 인식기(111a)는 입력된 사용자의 발화를 인식하여 텍스트 형태의 발화문으로 출력한다. 자연어 이해기 (111b)는 텍스트 형태의 발화문에 자연어 이해 기술을 적용하여, 그 결과를 출력한다. 자연어 이해기(111b)는 발화문으로부터 개체명을 인식할 수 있다. 개체명은 인명, 지명, 조직명, 시간, 날짜, 화폐 등의 고유 명사로서, 개체명 인식은 문장에서 개체명을 식별하고 식별된 개체명의 종류를 결정하는 작업이 다. 개체명 인식을 통해 문장에서 중요한 키워드를 추출하여 문장의 의미를 파악할 수 있다. 구체적으로, 자연어 이해 과정은 텍스트 형태의 발화문에 기초하여 형태소 분석을 수행하고, 형태소 분석 결과 에 기초하여 개체명을 인식하는 것을 포함할 수 있다. 자연어 이해기(111b)의 출력, 즉 자연어 이해 결과는 동승자의 발화에 대응되는 개체명, 형태소 분석 결과 등을 포함할 수 있다. 동승자 판단기(111d)는 자연어 이해기(111b)의 출력을 기반으로, 동승자 인원 변화를 예측한다. 구체적으로, 동 승자 판단기(111d)는 동승자의 발화를 분석하여 특정 경유지에서의 동승자 인원 변화를 예측할 수 있다. 동승자 판단기(111d)는 자연어 이해기(111b)의 개체명, 형태소 분석 결과에 기초하여 특정 동승자가 특정 경유 지에서 하차할 것임을 예측할 수 있다. 또한, 동승자 판단기(111d)는 자연어 이해기(111b)의 개체명, 형태소 분석 결과에 기초하여 특정 동승자가 특정 경유지에서 하차한 후 재탑승할 것임을 예측할 수 있다. 또한, 대화 시스템은 차량 내 통화 내용을 입력 받아 통화 상대방의 탑승 가능성을 판단하여 탑승 예정 인 원을 예측할 수 있다. 탑승예정자의 탑승 가능성을 예측한 경우, 대화 시스템은 탑승예정자 탑승 가능성을 확인하기 위한 선발화 를 출력할 수 있다. 예를 들어, 대화 시스템은 탑승예정자의 탑승 가능성을 예측한 경우, \"누가 중간에 탑승하나요? 이름을 말 씀해 주세요”와 같이 탑승예정자 탑승 가능성을 확인하기 위한 내용의 선발화를 출력할 수 있다. 선발화 판단기는 탑승예정자 탑승 예정 여부의 상황 정보에 기초하여 탑승가능성 예측을 선발화 조건으로 선발화 출력 여부를 판단한다. 또한, 선발화 판단기는 탑승예정자 탑승 예정 여부의 상황 정보가 탑승 가 능성 예측을 선발화 조건을 만족하면, 선발화 상황인 것으로 판단하고 선발화 트리거 신호를 생성한다. 선발화 판단기는 \"누가 중간에 탑승하나요? 이름을 말씀해주세요\"와 같이 탑승예정자가 탑승할 예정인 선 발화 상황에 대응되는 선발화 메시지를 추출한다. 선발화 판단기가 선발화 트리거 신호와 선발화 메시지를 대화 입력 관리기(111c)에 전달하면, 대화 입력 관리기(111c)는 대화 관리기에 선발화 메시지를 전달한다. 이 때, 선발화 트리거 신호 또는 선발화 상황임을 나타내는 신호가 함께 전달되는 것도 가능하다. 대화 관리기는 전달된 선발화 메시지를 출력하기 위한 대화 태스크를 생성하고, 선발화 메시지를 결과 처 리기에 전달할 수 있다. 결과 처리기는 입력된 선발화 메시지를 스피커를 통해 출력할 수 있다. 대화 시스템은 차량 내 탑승자의 발화를 입력 받아 탑승예정자의 탑승가능성을 확인할 수 있다. 구체적으 로, 대화 시스템은 선발화 메시지에 대응한 차량 내 탑승자의 발화를 입력 받아 탑승예정자 존재 여부를 확인할 수 있다. 동승자 판단기(111d)는 자연어 이해기(111b)의 출력을 기반으로, 차량 내 동승자 인원 변화를 예측한다. 구체적 으로, 동승자 판단기(111d)는 차량 내 탑승자 간의 대화에 기초하여 동승자 각각의 하차 가능성 및 하차 후 재 탑승 가능성을 예측할 뿐만 아니라, 차량 내 통화 내용에 기초하여 탑승 예정 인원을 예측할 수 있다. 동승자 판단기(111d)는 동승자 인원 변화 예측 결과에 기초하여 동승자 인원 정보를 생성할 수 있다. 즉, 동승자 판단기(111d)는 경유지에서의 동승자 각각의 하차 가능성, 경유지에서의 동승자 각각의 하차 후 재 탑승 가능성 및 경유지에서의 탑승예정자의 탑승 가능성에 기초하여 동승자 인원 정보를 생성할 수 있다. 대화 시스템은 경유지 도착 전, 동승자 인원 정보에 기초하여 동승자 인원 변화 예측 결과에 관한 선발화 를 출력할 수 있다. 예를 들어, 대화 시스템은 경유지에 도착 전이라고 판단한 경우, \"A는 경유지에서 하차합니다. B는 경유지 에서 하차 후 재탑승합니다. C는 경유지에서 하차하지 않습니다. D는 경유지에서 탑승합니다\"와 같이 동승자 인 원 변화 예측 결과에 관한 내용의 선발화를 출력할 수 있다. 즉, 대화 시스템은 경유지 도착 전, 동승자 인원 정보에 포함된 경유지에서의 동승자 각각의 하차 가능성, 재탑승 가능성 및 탑승 가능성에 관한 내용의 선발화를 출력할 수 있다. 다만, 대화 시스템은 경유지 도착 전 뿐만 아니라, 경유지 도착 직후에도 동승자 인원 변화 예측 결과에 관한 내용의 선발화를 출력할 수 있다. 또한, 경유지에서의 동승자 각각의 하차 가능성, 재탑승 가능성 및 탑승 가능성에 관한 내용은 \"다음에 또 만나 요\"와 같이 하차 인원에 대한 메시지, \"어서 다녀오세요\"와 같이 하차 후 재탑승 인원에 대한 메시지 등을 포함 할 수 있다. 대화 시스템은 차량 감지부가 감지한 차량의 위치, 차량 속도 등과 같은 차량 상태 정보에 기초하여 차량의 경유지 도착 직전 또는 도착 직후인지 여부를 판단할 수 있다. 구체적으로, 대화 시스템은 기어가 P단에 위치하는 경우, 차량이 경유지에 도착한 것으로 판단할 수 있으며, 속도가 10kph이하인 경우, 차량이 경유지에 도착 직전인 것으로 판단할 수 있다. 선발화 판단기는 경유지 도착 전이라는 상황 정보에 기초하여 동승자 인원 변화 예측을 선발화 조건으로 선발화 출력 여부를 판단한다. 선발화 판단기는 동승자 판단기(111d)로부터 전달받은 동승자 인원 정보에 기초하여 동승자 인원 변화 예측의 선발화 조건이 만족됨을 판단할 수 있다. 또한, 선발화 판단기는 경유 지 도착 전이라는 상황 정보가 동승자 인원 변화 예측를 선발화 조건을 만족하면, 선발화 상황인 것으로 판단하 고 선발화 트리거 신호를 생성한다. 선발화 판단기는 동승자 인원 정보에 기초하여 \"A는 경유지에서 하차합니다. B는 경유지에서 하차 후 재탑 승합니다. C는 경유지에서 하차하지 않습니다. D는 경유지에서 탑승합니다\"와 같이 동승자 인원 변화가 예측되 는 선발화 상황에 대응되는 선발화 메시지를 추출한다. 선발화 판단기가 선발화 트리거 신호와 선발화 메 시지를 대화 입력 관리기(111c)에 전달하면, 대화 입력 관리기(111c)는 대화 관리기에 선발화 메시지를 전 달한다. 이 때, 선발화 트리거 신호 또는 선발화 상황임을 나타내는 신호가 함께 전달되는 것도 가능하다. 대화 관리기는 전달된 선발화 메시지를 출력하기 위한 대화 태스크를 생성하고, 선발화 메시지를 결과 처 리기에 전달할 수 있다. 결과 처리기는 입력된 선발화 메시지를 스피커를 통해 출력할 수 있다. 대화 시스템은 동승자 인원 정보에 기초하여 동승자 인원 변화 예측 결과와 경유지 출발 후 동승자 인원 변화 결과를 비교할 수 있다. 대화 시스템은 차량 감지부가 감지한 차량의 위치, 차량 속도 등과 같은 차량 상태 정보에 기초하여 차량의 경유지 출발 여부를 판단할 수 있다. 구체적으로, 대화 시스템은 파킹 브레이크가 해제되거나, 시동이 온(ON)되거나, 브레이크 페달이 온(ON)되 는 것 등에 기초하여 차량이 경유지를 출발한 것으로 판단할 수 있다. 대화 시스템은 경유지 출발 후 동승자 인원 변화 결과를 판단하기 위해 음성 인식 처리기 및 상황 정 보 처리기를 통해 동승자의 탑승을 판단할 수 있으며, 동승자 판단기(111d)를 통해 동승자를 식별할 수 있 다. 따라서, 챠량이 경유지를 출발한 것으로 판단한 경우, 대화 시스템의 동승자 판단기(111d)는 동승자 인원 정보에 기초한 동승자 인원 변화 예측 결과와 경유지 출발 후 동승자 인원 변화 결과를 비교할 수 있다. 또한, 대화 시스템은 동승자 인원 변화 예측 결과와 경유지 출발 후 동승자 인원 변화 결과를 비교하기 위 해 선발화를 출력할 수 있습니다. 예를 들어, 대화 시스템은 경유지 출발 후 동승자 인원 변화 결과를 확인하기 위해, 동승자 인원 변화 예 측 결과가 맞는지 확인하는 내용의 선발화를 출력할 수 있다. 구체적으로, 대화 시스템은 \"A는 가셨지 요?\"와 같이 경유지에서 하차할 것으로 판단한 동승자가 경유지에서 하차하였는지 여부를 판단하는 내용의 선발 화를 출력할 수 있고, \"B는 다시 타셨지요?\"와 같이 경유지에서 하차 후 재탑승할 것으로 판단한 동승자가 경유 지에서 재탑승하였는지 여부를 판단하는 내용의 선발화를 출력할 수 있다. 또한, 대화 시스템은 \"C는 남아계시지요?\"와 같이 경유지에서 하차하지 않을 것으로 판단한 동승자가 경유 지에서 하차하지 않았는지 여부를 판단하는 내용의 선발화를 출력할 수 있고, \"D는 탑승 하셨지요?\"와 같이 경 유지에서 탑승할 것으로 판단한 탑승예정자가 탑승하였는지 여부를 판단하는 내용의 선발화를 출력할 수 있다. 선발화 판단기는 경유지 출발 후의 상황 정보에 기초하여 동승자 인원 변화가 예측되었는지 여부를 선발화 조건으로 선발화 출력 여부를 판단한다. 선발화 판단기는 동승자 판단기(111d)로부터 전달받은 동승자 인 원 정보에 기초하여 동승자 인원 변화 예측 결과의 선발화 조건이 만족됨을 판단할 수 있다. 또한, 선발화 판단 기는 경유지 출발 후의 상황 정보가 동승자 인원 변화 예측 결과의 선발화 조건을 만족하면, 선발화 상황 인 것으로 판단하고 선발화 트리거 신호를 생성한다. 선발화 판단기는 동승자 인원 변화에 대응되는 선발화 메시지를 추출한다. 선발화 판단기가 선발화 트리거 신호와 선발화 메시지를 대화 입력 관리기(111c)에 전달하면, 대화 입력 관리기(111c)는 대화 관리기 에 선발화 메시지를 전달한다. 이 때, 선발화 트리거 신호 또는 선발화 상황임을 나타내는 신호가 함께 전 달되는 것도 가능하다. 대화 관리기는 전달된 선발화 메시지를 출력하기 위한 대화 태스크를 생성하고, 선발화 메시지를 결과 처 리기에 전달할 수 있다. 결과 처리기는 입력된 선발화 메시지를 스피커를 통해 출력할 수 있다. 대화 시스템은 차량 내 탑승자의 발화를 입력 받아 동승자 인원 변화 결과를 확인할 수 있다. 구체적으로, 대화 시스템의 동승자 판단기(111d)는 선발화 메시지에 대응한 차량 내 탑승자의 발화를 입력 받아 동승자 인원 변화 결과를 확인할 수 있다. 예를 들어, 차량 내 탑승자는 \"A는 가셨지요?\"와 같이 경유지에서 하차할 것으로 판단한 동승자가 경유지에서 하차하였는지 여부를 묻는 선발화 메시지에 응답하여 \"그래 갔어\"라고 발화하거나 \"아니 탔어\"라고 발화할 수 있다. 즉, 차량 내 탑승자는 경유지에서 하차할 것으로 판단한 동승자가 경유지에서 하차하였는지 여부를 묻는 선발화 메시지에 응답하여 동승자 인원 변화 결과를 나타내는 메시지를 발화할 수 있다. 차량 내 탑승자의 발화가 입력되면, 음성 입력 처리기가 입력된 차량 내 탑승자의 발화를 인식한다. 차량 내 탑승자의 발화는 차량에 마련된 음성 입력 장치 또는 모바일 기기에 마련된 음성 입력 장치 를 통해 입력될 수 있다. 음성 인식기(111a)는 입력된 차량 내 탑승자의 발화를 인식하여 텍스트 형태의 발화문으로 출력한다. 자연어 이 해기(111b)는 텍스트 형태의 발화문에 자연어 이해 기술을 적용하여, 그 결과를 출력한다. 구체적으로, 자연어 이해 과정은 텍스트 형태의 발화문에 기초하여 형태소 분석을 수행하고, 형태소 분석 결과 에 기초하여 동승자 인원 변화 결과를 인식하는 것을 포함할 수 있다. 이를 통해, 음성 입력 처리기의 동승자 판단기(111d)는 차량 내 탑승자의 발화에 기초하여 동승자 인원 변 화 결과를 확인할 수 있다. 대화 시스템은 동승자 인원 변화 예측 결과와 경유지 출발 후 동승자 인원 변화결과의 비교 결과에 관한 선발화를 출력할 수 있다. 예를 들어, 대화 시스템은 \"현재 동승자는 동승자 인원 변화 예측 결과와 상이합니다\"와 같이 동승자 인원 변화 예측 결과와 경유지 출발 후 동승자 인원 변화 결과가 상이함을 나타내는 선발화 메시지를 출력할 수 있고, \"현재 동승자는 동승자 인원 변화 예측 결과와 동일합니다\"와 같이 동승자 인원 변화 예측 결과와 경유지 출발 후 동승자 인원 변화 결과가 동일함을 나타내는 선발화 메시지를 출력할 수 있다. 구체적으로, 선발화 판단기는 경유지 출발 후의 상황 정보에 기초하여 동승자 인원 변화 예측 결과와 경유 지 출발 후 동승자 인원 변화 결과가 비교되었는지 여부를 선발화 조건으로 선발화 출력 여부를 판단한다. 선발 화 판단기는 동승자 판단기(111d)로부터 전달받은 동승자 인원 변화 예측 결과와 경유지 출발 후 동승자 인원 변화 결과의 비교 결과에 기초하여 선발화 조건이 만족됨을 판단할 수 있다. 또한, 선발화 판단기는 경유지 출발 후의 상황 정보가 동승자 인원 변화 예측 결과와 경유지 출발 후 동승자 인원 변화 결과의 비교의 선발화 조건을 만족하면, 선발화 상황인 것으로 판단하고 선발화 트리거 신호를 생성한다. 선발화 판단기는 동승자 인원 변화 예측 결과와 경유지 출발 후 동승자 인원 변화 결과의 비교 결과에 기 초하여 비교 결과를 나타내는 선발화 메시지를 추출한다. 선발화 판단기가 선발화 트리거 신호와 선발화 메시지를 대화 입력 관리기(111c)에 전달하면, 대화 입력 관리기(111c)는 대화 관리기에 선발화 메시지를 전달한다. 이 때, 선발화 트리거 신호 또는 선발화 상황임을 나타내는 신호가 함께 전달되는 것도 가능하다. 대화 관리기는 전달된 선발화 메시지를 출력하기 위한 대화 태스크를 생성하고, 선발화 메시지를 결과 처 리기에 전달할 수 있다. 결과 처리기는 입력된 선발화 메시지를 스피커를 통해 출력할 수 있다. 따라서, 운전자는 대화 시스템의 동승자 인원 변화 예측 결과와 경유지 출발 후 동승자 인원 변화 결과의 비교 결과를 통해 동승자 각각의 하차 또는 탑승 여부를 확인할 수 있으며, 동승자 각각의 하차 또는 탑승에 집 중하지 않고, 주행 및 주차 등 차량 관리임무에 집중할 수 있다. 또한, 동승자는 경유지 도착 시 재탑승을 못해 원치 않게 남겨지거나, 하차하지 못하는 상황을 피할 수 있다. 대화 시스템은 차량의 주행 종료 시, 주행 관련 정보 및 동승자 각각에 대한 동승자 정보를 저장할 수 있 다. 예를 들어, 대화 시스템의 저장부는 차량의 주행이 종료한 경우, 차량의 주행에 대한 주행 관련 정보 및 차량이 주행하는 동안 탑승한 동승자 각각에 대한 동승자 정보를 저장할 수도 있다. 구체적으로, 대화 시스템의 저장부는 주행의 출발지, 경유지 및 도착지와 같은 차량의 주행에 대한 주행 관련 정보를 저장하고, 개인 식별 정보, 음성 특성 정보, 착석 위치 정보, 탑승 시각 정보, 하차 시각 정 보, 탑승 장소 정보 및 하차 장소 정보 등과 같은 동승자 각각에 대한 동승자 정보를 저장할 수도 있다. 즉, 대화 시스템의 저장부는 차량 제어기로부터 GPS 값을 수집하여 주행의 출발지, 경유지 및 도착지와 같은 차량의 주행에 대한 주행 관련 정보를 저장할 수 있다. 또한, 대화 시스템의 저장부는 입력 처리기로부터 동승자 식별 정보, 음성 특성 정보, 착석 위 치 정보, 동승자 인원 정보 등을 수집하여 동승자 식별 정보, 음성 특성 정보, 착석 위치 정보, 탑승 시각 정보, 탑승 장소 정보, 하차 시각 정보 및 하차 장소 정보 등과 같은 동승자 각각에 대한 동승자 정보를 저장할 수 있다. 도 55는 일 실시예에 따른 대화 처리 방법에 있어서, 이전 주행에 참여한 동승자의 탑승을 판단하고 선발화를 출력하는 방법을 나타낸 순서도이다. 대화 시스템은 차량 내 탑승자 간 대화 및 차량 조작 정보에 기초하여 동승자의 탑승 여부를 판단할 수 있 다. 구체적으로, 대화 시스템의 음성 입력 처리기는 차량 내 탑승자 간 대화를 입력 받아 차량 내 탑승한 동승자의 탑승을 판단하고, 동승자 각각의 음성 특성, 착석 위치, 탑승 시각, 탑승 장소 등의 특성을 획득할 수 있다. 대화 시스템은 동승자의 특성이 저장된 동승자 정보와 동일한지 여부를 판단할 수 있다. 구체적으로, 대화 시스템의 음성 입력 처리기는 감지된 동승자의 음성 특성, 착석 위치, 탑승 시각, 탑승 장소 등의 특성을 저장부로부터 획득한 동승자 정보와 비교할 수 있다. 예를 들어, 음성 입력 처리기는 동승자 정보에 포함된 동승자의 음성 특성, 착석 위치, 탑승 시각 및 탑승 장소 정보와 5510 단계에서 탑승이 판단된 동승자의 특성과 비교할 수 있다. 음성 입력 처리기는 동승자 정보에 포함된 동승자의 음성 특성, 착석 위치, 탑승 시각 및 탑승 장소 중 적 어도 두 가지 이상이 5510 단계에서 탑승이 판단된 동승자의 특성과 동일한 경우, 탑승이 판단된 동승자의 특성 이 동승자 정보와 동일한 것으로 판단할 수 있다. 음성 입력 처리기는 동승자 정보에 포함된 동승자의 음성 특성, 착석 위치, 탑승 시각 및 탑승 장소와 5510 단계에서 탑승이 판단된 동승자의 특성을 비교하는 경우, 음성 특성, 착석 위치, 탑승 시각 및 탑승 장소 의 일정 구간의 유사 범위까지 동일한 것으로 판단할 수 있다. 대화 시스템은 동승자의 특성이 저장된 동승자 정보와 동일한 것으로 판단한 경우(5510의 예), 동승자의 이전 주행 참여 여부 확인을 위한 선발화를 출력할 수 있다. 예를 들어, 대화 시스템은 탑승이 판단된 동승자의 특성이 저장된 동승자 정보와 동일한 것으로 판단한 경 우, \"혹시 OO님 아니세요?\"와 같이 동승자가 이전 주행 참여 동승자인지 여부를 확인하기 위한 내용의 선발화를 출력할 수 있다. 선발화 판단기는 동승자 탑승 여부의 상황 정보에 기초하여 감지된 동승자의 특성이 저장된 동승자 정보와 동일한 것을 선발화 조건으로 선발화 출력 여부를 판단한다. 또한, 선발화 판단기는 동승자 탑승 여부의 상황 정보가 탑승이 판단된 동승자의 특성이 저장된 동승자 정보와 동일한 것으로 판단한 선발화 조건을 만족하 면, 선발화 상황인 것으로 판단하고 선발화 트리거 신호를 생성한다. 선발화 판단기는 \"혹시 OO님 아니세요?\"와 같이 동승자가 탑승한 선발화 상황에 대응되는 선발화 메시지를 추출한다. 선발화 판단기가 선발화 트리거 신호와 선발화 메시지를 대화 입력 관리기(111c)에 전달하면, 대화 입력 관리기(111c)는 대화 관리기에 선발화 메시지를 전달한다. 이 때, 선발화 트리거 신호 또는 선 발화 상황임을 나타내는 신호가 함께 전달되는 것도 가능하다. 대화 관리기는 전달된 선발화 메시지를 출력하기 위한 대화 태스크를 생성하고, 선발화 메시지를 결과 처 리기에 전달할 수 있다. 결과 처리기는 입력된 선발화 메시지를 스피커를 통해 출력할 수 있다. 대화 시스템은 동승자의 발화를 입력 받아 동승자의 이전 주행 참여 여부를 확인할 수 있다. 구체적 으로, 대화 시스템은 선발화 메시지에 대응한 동승자의 발화를 입력 받아 동승자가 이전 주행에 참여하였 는지 여부를 확인할 수 있다. 예를 들어, 동승자는 이전 주행에 참여하였는지 여부를 묻는 선발화 메시지에 응답하여 \"맞아\"라고 발화하거나 \"아니야\"라고 발화할 수 있다. 즉, 동승자는 이전 주행에 참여하였는지 여부를 묻는 선발화 메시지에 응답하여 동승자가 이전 주행에 참여하였는지 여부를 나타내는 응답을 포함하는 메시지를 발화할 수 있다. 동승자의 발화가 입력되면, 음성 입력 처리기가 입력된 동승자의 발화를 인식한다. 동승자의 발화는 차량 에 마련된 음성 입력 장치 또는 모바일 기기에 마련된 음성 입력 장치를 통해 입력될 수 있다. 음성 인식기(111a)는 입력된 동승자의 발화를 인식하여 텍스트 형태의 발화문으로 출력한다. 자연어 이해기 (111b)는 텍스트 형태의 발화문에 자연어 이해 기술을 적용하여, 그 결과를 출력한다. 구체적으로, 자연어 이해 과정은 텍스트 형태의 발화문에 기초하여 형태소 분석을 수행하고, 형태소 분석 결과 에 기초하여 동승자가 이전 주행 참여하였는지 여부를 인식하는 것을 포함할 수 있다. 이를 통해, 음성 입력 처리기의 동승자 판단기(111d)는 동승자의 발화에 기초하여 동승자가 이전 주행 참 여하였는지 여부를 확인할 수 있다. 대화 시스템은 이전 주행 참여의 경우, 차량 내 탑승자 간 대화 및 저장된 동승자 정보에 기초하여 동승자 인원 정보를 생성할 수 있다. 즉, 대화 시스템은 5410 단계와 같이 차량 내 탑승자 간 대화에 기초 하여 동승자 인원 정보를 생성하는 경우, 저장된 동승자 정보를 추가적으로 고려할 수 있다. 예를 들어, 대화 시스템의 동승자 판단기(111d)는 자연어 이해기(111b)의 출력을 기반으로, 경유지에서의 동승자 인원 변화를 예측할 수 있다. 구체적으로, 동승자 판단기(111d)는 차량 내 탑승자 간의 대화 내용에 기 초하여 동승자 각각의 하차 가능성 및 하차 후 재탑승 가능성을 예측할 뿐만 아니라, 차량 내의 통화 내용에 기 초하여 탑승 예정 인원을 예측할 수 있다.동승자 판단기(111d)는 차량 내 탑승자 간 대화에 기초하여 동승자 인원 변화를 예측할 때, 저장된 동승자 정보 중 하차 시각 정보 및 하차 장소 정보를 고려하여 동승자 인원 변화 예측 결과의 정확도를 높일 수 있다. 구체적으로, 동승자 판단기(111d)는 차량 내 탑승자 간 대화에 기초하여 동승자가 특정 경유지에서 하차할 것을 예측한 경우, 저장된 동승자의 동승자 정보 중 하차 시각 정보 및 하차 장소 정보를 고려하여 이전 주행에서의 동승자의 하차 시각 및 하차 장소를 확인할 수 있다. 동승자 판단기(111d)는 차량 내 탑승자 간 대화에 기초하여 예측한 동승자가 하차할 특정 경유지가 이전 주행에 서의 하차 장소와 일치하는지 여부를 판단할 수 있다. 동승자 판단기(111d)는 차량 내 탑승자 간 대화에 기초하여 예측한 동승자가 하차할 특정 경유지가 이전 주행에 서의 하차 장소와 일치하는 경우, 차량 내 탑승자 간 대화에 기초하여 예측한 동승자 인원 변환 예측을 이용하 여 동승자 인원 정보를 생성할 수 있다. 동승자 판단기(111d)는 차량 내 탑승자 간 대화에 기초하여 예측한 특정 동승자가 하차할 특정 경유지가 이전 주행에서의 하차 장소와 일치하지 않는 경우, 특정 동승자에게 하차할 지점이 특정 경유지가 맞는지 여부를 선 발화를 통해 확인할 수 있으며, 동승자의 발화에 기초하여 동승자 인원 정보를 생성할 수 있다. 상기의 설명은 기술적 사상을 예시적으로 설명한 것에 불과한 것으로서, 본 발명의 기술 분야에서 통상의 지식 을 가진 자라면 본질적인 특성에서 벗어나지 않는 범위 내에서 다양한 수정, 변경 및 치환이 가능할 것이다. 따 라서, 상기에 개시된 실시예 및 첨부된 도면들은 기술적 사상을 한정하기 위한 것이 아니라 설명하기 위한 것이 고, 이러한 실시예 및 첨부된 도면에 의하여 기술적 사상의 범위가 한정되는 것은 아니다. 그 보호 범위는 아래 의 청구범위에 의하여 해석되어야 하며, 그와 동등한 범위 내에 있는 모든 기술적 사상은 권리범위에 포함되는 것으로 해석되어야 할 것이다. 지금까지 설명한 대화 시스템, 이를 포함하는 차량 및 대화 처리 방법에 의하면, 차량 환경에 특화된 대화 처리 기술을 이용하여 사용자의 의도에 부합되거나 사용자에게 필요한 최적의 서비스를 제공할 수 있다. 또한, 차량 내부에서 발생하는 다양한 상황을 고려하여 사용자에게 필요한 최적의 서비스를 제공할 수 있다. 특 히, 사용자의 발화와 무관하게 대화 시스템이 수집한 상황 정보 또는 운전자 정보에 기초하여 사용자에게 필요한 서비스를 스스로 판단하고 이를 선제적으로 제공하는 것이 가능하다."}
{"patent_id": "10-2018-0077027", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 일 실시예에 따른 대화 시스템의 제어 블록도이다. 도 2a는 차량 내부의 구성을 개략적으로 나타낸 도면이다. 도 2b는 도 2a와 다른 각도에서 바라본 차량 내부의 구성을 개략적으로 나타낸 도면이다. 도 3 내지 도 6은 대화 시스템과 운전자 사이에 주고 받을 수 있는 대화의 예시를 나타낸 도면이다. 도 7 및 도 8은 동승자 인원 변화를 예측하고 선발화를 출력하는 대화 시스템의 예시를 나타낸 도면이다. 도 9 및 도 10은 대화 시스템과 차량의 구성 요소들 사이의 사이의 연결 관계를 간략하게 나타낸 제어 블록도이 다. 도 11 및 도 12는 대화 시스템의 구성 요소와 차량의 구성 요소들 사이의 연결 관계를 간략하게 나타낸 제어 블 록도이다. 도 13은 대화 시스템이 차량에 마련되는 차량 단독 방식에 대한 제어 블록도이다. 도 14 및 도 15는 대화 시스템이 원격 서버에 마련되고 차량이 사용자와 대화 시스템을 연결하는 게이트웨이의 역할만 하는 차량 게이트웨이 방식에 대한 제어 블록도이다. 도 16은 차량 게이트웨이 방식에서 차량이 입력 처리와 출력 처리를 일부 수행할 수 있는 경우에 대한 제어 블 록도이다. 도 17은 원격 대화 시스템 서버와 차량이 모두 대화 처리를 수행할 수 있는 하이브리드 방식에 대한 제어 블록 도이다. 도 18및 도 19는 차량에 연결된 모바일 기기가 사용자와 원격 대화 시스템 서버를 연결하는 모바일 게이트웨이 방식에 대한 제어 블록도이다. 도 20은 모바일 기기에 대화 시스템이 탑재되는 모바일 단독 방식에 대한 제어 블록도이다. 도 21, 도 22a 및 도 22b는 대화 시스템의 구성 중 입력 처리기의 구성이 세분화된 제어 블록도이다. 도 23a, 도 23b 및 도 23c는 상황 이해 테이블에 저장되는 정보의 예시를 나타낸 도면이다. 도 24는 사용자의 입력이 수신되기 전에 대화 시스템이 먼저 발화를 출력하는 경우에 적용 가능한 대화 시스템 의 제어 블록도이다. 도 25a, 도 25b, 도 25c 및 도 25d는 선발화 조건 테이블에 저장하는 정보의 예시를 나타낸 도면이다. 도 26은 대화 관리기의 구성이 세분화된 제어 블록도이다. 도 27은 연관 액션 DB에 저장된 정보의 예시를 나타낸 도면이다. 도 28은 액션 수행 조건 DB에 저장된 정보의 예시를 나타낸 도면이다. 도 29는 액션 인자 DB에 저장된 정보의 예시를 나타낸 도면이다. 도 30은 모호성 해소 정보 DB에 저장되는 정보의 예시를 나타내는 도면이다. 도 31a 및 도 31b는 모호성 해결기가 모호성 해소 정보 DB를 참조하여 모호성을 해결하고 액션을 추출하여 차량 을 제어하는 다양한 예시들을 정리한 테이블이다. 도 32는 결과 처리기의 구성을 세분화한 제어 블록도이다. 도 33 내지 도 45는 사용자가 길 안내와 관련한 발화를 입력한 경우에 대화 시스템이 입력을 처리하고, 대화를 관리하고, 결과를 출력하는 구체적인 예시를 나타낸 도면이다. 도 46은 일 실시예에 따른 대화 처리 방법에 있어서, 사용자 입력을 처리하는 방법을 나타낸 순서도이다.도 47은 일 실시예에 따른 대화 처리 방법에 있어서, 입력 처리기의 출력을 이용하여 대화를 관리하는 방법을 나타낸 순서도이다. 도 48은 일 실시예에 따른 대화 처리 방법에 있어서, 대화 관리의 결과에 대응되는 응답을 생성하기 위한 결과 처리 방법을 나타낸 순서도이다. 도 49 내지 도 51은 일 실시예에 따른 대화 처리 방법에 있어서, 사용자의 발화 입력 전에 대화 시스템이 선발 화를 출력하는 경우를 나타낸 순서도이다. 도 52는 일 실시예에 따른 대화 처리 방법에 있어서, 사용자의 발화 입력 전에 대화 시스템이 선발화를 출력하 는 경우에 중복 태스크를 처리하는 과정을 나타낸 순서도이다. 도 53은 일 실시예에 따른 대화 처리 방법에 있어서, 차량 내 동승자의 탑승을 판단하고 선발화를 출력하는 방 법을 나타낸 순서도이다. 도 54는 일 실시예에 따른 대화 처리 방법에 있어서, 동승자 인원 변화를 예측하고 선발화를 출력하는 방법을 나타낸 순서도이다. 도 55는 일 실시예에 따른 대화 처리 방법에 있어서, 이전 주행에 참여한 동승자의 탑승을 판단하고 선발화를 출력하는 방법을 나타낸 순서도이다."}
