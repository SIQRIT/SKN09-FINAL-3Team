{"patent_id": "10-2020-0077374", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2021-0158695", "출원번호": "10-2020-0077374", "발명의 명칭": "영상에서 평면을 검출하는 전자 장치 및 그 동작 방법", "출원인": "삼성전자주식회사", "발명자": "어스 미카일로"}}
{"patent_id": "10-2020-0077374", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "전자 장치에서 영상에서 평면을 검출하는 방법에 있어서,평면을 포함하는 영상을 획득하는 단계;상기 영상에서, 객체를 검출하는 단계;상기 객체의 형상을 3차원으로 모델링하는 단계;상기 모델링된 결과에 기초하여, 상기 객체의 표면 중 상기 평면에 접촉된 표면을 식별하는 단계;상기 식별된 표면에 기초하여, 상기 영상에서, 상기 평면을 검출하는 단계를 포함하는, 방법."}
{"patent_id": "10-2020-0077374", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 3차원으로 모델링하는 단계는상기 영상에서, 상기 객체의 엣지 및 코너 중 적어도 하나를 검출하는 단계; 및상기 검출된 엣지 및 코너 중 적어도 하나에 기초하여, 상기 객체의 형상을 3차원으로 모델링하는 단계를 포함하는, 방법."}
{"patent_id": "10-2020-0077374", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서, 상기 객체의 엣지 및 코너 중 적어도 하나를 검출하는 단계는상기 영상에서, 상기 검출된 객체가 표시된 영역에서, 적어도 하나의 특징점을 추출하는 단계; 및상기 추출된 적어도 하나의 특징점 중에서, 상기 객체의 엣지 및 코너 중 적어도 하나를 검출하는 단계를 포함하는, 방법."}
{"patent_id": "10-2020-0077374", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서, 상기 3차원으로 모델링하는 단계는상기 객체의 타입을 식별하는 단계;상기 식별된 객체의 타입에 기초하여, 상기 객체가 놓인 상기 평면에 대한 타입을 결정하는 단계;상기 결정된 평면의 타입에 기초하여, 상기 평면에 놓인 상기 객체의 형상을 3차원으로 모델링하는 단계를 포함하는, 방법."}
{"patent_id": "10-2020-0077374", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서, 상기 객체를 검출하는 단계는상기 영상에 포함된 적어도 하나의 객체에 대한 중력 방향을 예측하는 단계; 및상기 중력 방향에 기초하여, 상기 적어도 하나의 객체 중 상기 평면을 검출하기 위한 객체를 검출하는 단계를포함하는, 방법."}
{"patent_id": "10-2020-0077374", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서, 상기 평면을 검출하는 단계는상기 식별된 표면에 기초하여, 상기 평면에 대한 적어도 하나의 특징점을 식별하는 단계;상기 식별된 적어도 하나의 특징점에 기초하여, 상기 평면을 3차원으로 모델링하는 단계; 및공개특허 10-2021-0158695-3-상기 모델링된 결과에 기초하여, 상기 영상에서 상기 평면을 검출하는 단계를 포함하는, 방법."}
{"patent_id": "10-2020-0077374", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에 있어서, 상기 평면이 검출된 결과에 기초하여, 상기 영상에서, 상기 검출된 평면을 기준으로, 증강 현실 이미지가 표시되는, 방법."}
{"patent_id": "10-2020-0077374", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "영상에서 평면을 검출하는 전자 장치에 있어서,평면을 포함하는 영상을 획득하고, 상기 영상에서, 객체를 검출하고, 상기 객체의 형상을 3차원으로모델링하고, 상기 모델링된 결과에 기초하여, 상기 객체의 표면 중 상기 평면에 접촉된 표면을 식별하고, 상기식별된 표면에 기초하여, 상기 영상에서, 상기 평면을 검출하는 적어도 하나의 프로세서; 및상기 평면이 검출된 결과에 관련된 정보를 표시하는 디스플레이를 포함하는, 전자 장치."}
{"patent_id": "10-2020-0077374", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서, 상기 적어도 하나의 프로세서는상기 영상에서, 상기 객체의 엣지 및 코너 중 적어도 하나를 검출하고,상기 검출된 엣지 및 코너 중 적어도 하나에 기초하여, 상기 객체의 형상을 3차원으로 모델링하는, 전자 장치."}
{"patent_id": "10-2020-0077374", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9항에 있어서, 상기 적어도 하나의 프로세서는상기 영상에서, 상기 검출된 객체가 표시된 영역에서, 적어도 하나의 특징점을 추출하고,상기 추출된 적어도 하나의 특징점 중에서, 상기 객체의 엣지 및 코너 중 적어도 하나를 검출하는, 전자 장치."}
{"patent_id": "10-2020-0077374", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제8항에 있어서, 상기 적어도 하나의 프로세서는상기 객체의 타입을 식별하고, 상기 식별된 객체의 타입에 기초하여, 상기 객체가 놓인 상기 평면에 대한 타입을 결정하고, 상기 결정된 평면의 타입에 기초하여, 상기 평면에 놓인 상기 객체의 형상을 3차원으로 모델링하는, 전자 장치."}
{"patent_id": "10-2020-0077374", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제8항에 있어서, 상기 적어도 하나의 프로세서는상기 영상에 포함된 적어도 하나의 객체에 대한 중력 방향을 예측하고,상기 중력 방향에 기초하여, 상기 적어도 하나의 객체 중 상기 평면을 검출하기 위한 객체를 검출하는, 전자 장치."}
{"patent_id": "10-2020-0077374", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제8항에 있어서, 상기 적어도 하나의 프로세서는상기 식별된 표면에 기초하여, 상기 평면에 대한 적어도 하나의 특징점을 식별하고, 상기 식별된 적어도 하나의특징점에 기초하여, 상기 평면을 3차원으로 모델링하고, 상기 모델링된 결과에 기초하여, 상기 영상에서 상기평면을 검출하는, 전자 장치."}
{"patent_id": "10-2020-0077374", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제8항에 있어서, 상기 평면이 검출된 결과에 기초하여, 상기 영상에서, 상기 검출된 평면을 기준으로, 증강 현실 이미지가 표시되는, 전자 장치.공개특허 10-2021-0158695-4-청구항 15 제1항 내지 제7항 중 어느 한 항의 방법을 구현하기 위한 프로그램이 기록된 컴퓨터로 읽을 수 있는 기록 매체."}
{"patent_id": "10-2020-0077374", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "평면을 포함하는 영상을 획득하고, 영상에서, 객체를 검출하고, 객체의 형상을 3차원으로 모델링하고, 모델링된 결과에 기초하여, 객체의 표면 중 평면에 접촉된 표면을 식별하고, 식별된 표면에 기초하여, 영상에서, 평면을 검출하는, 전자 장치에서 영상에서 평면을 검출하는 방법이 개시된다."}
{"patent_id": "10-2020-0077374", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는, 영상에 포함된 평면을 검출하는 전자 장치 및 그 동작 방법에 관한 것이다."}
{"patent_id": "10-2020-0077374", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "증강 현실(AR, Augmented Reality) 기술에 의하면, 실시간으로 현실 세계의 장면과 증강 현실 이미지가 혼합된 영상이 사용자에게 제공될 수 있다. 따라서, 광고, 네비게이션, 게임 등과 같은 서비스에서, 증강 현실 기술을 통해, 사용자에게 다양한 컨텐츠가 제공될 수 있다. 증강 현실 기술에 따르면, 사용자가 이질감을 느끼기 힘들도록 현실 세계의 장면에서 검출된 평면을 기준으로, 증강 현실 이미지를 배치할 수 있다. 다만, 기존의 평면을 검출하는 기술에 따르면, 현실 세계가 촬영된 영상에서, 평면이 표시된 영상 영역이 좁은 경우, 영상에서 획득될 수 있는 평면에 관한 정보가 부족함에 따라서, 평면 영역이 잘못 검출될 수 있다. 평면 영역이 잘못 검출되는 경우, 증강 현실 이미지가 잘못된 위치에 배치될 수 있으므로, 증강 현실 기술에 따 른 사용자 경험이 저하될 수 있는 문제점이 발생하게 된다."}
{"patent_id": "10-2020-0077374", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 개시가 해결하고자 하는 과제는 전술한 문제를 해결하기 위한 것으로서, 영상에서 평면을 검출하는 전자 장 치 및 그 동작 방법을 제공하기 위한 것이다. 또한, 상기 방법을 컴퓨터에서 실행시키기 위한 프로그램을 기록한 컴퓨터로 읽을 수 있는 기록매체를 제공하는 데 있다. 해결하려는 기술적 과제는 상기된 바와 같은 기술적 과제들로 한정되지 않으며, 또 다른 기술적 과제 들이 존재할 수 있다."}
{"patent_id": "10-2020-0077374", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상술한 기술적 과제를 달성하기 위한 기술적 수단으로서, 본 개시의 제1 측면은, 전자 장치에서 영상에서 평면 을 검출하는 방법에 있어서, 평면을 포함하는 영상을 획득하는 단계; 상기 영상에서, 객체를 검출하는 단계; 상 기 객체의 형상을 3차원으로 모델링하는 단계; 상기 모델링된 결과에 기초하여, 상기 객체의 표면 중 상기 평면 에 접촉된 표면을 식별하는 단계; 상기 식별된 표면에 기초하여, 상기 영상에서, 상기 평면을 검출하는 단계를 포함하는, 방법이 제공된다. 또한, 본 개시의 제2 측면은, 영상에서 평면을 검출하는 전자 장치에 있어서, 평면을 포함하는 영상을 획득하고, 상기 영상에서, 객체를 검출하고, 상기 객체의 형상을 3차원으로 모델링하고, 상기 모델링된 결과에 기초하여, 상기 객체의 표면 중 상기 평면에 접촉된 표면을 식별하고, 상기 식별된 표면에 기초하여, 상기 영상 에서, 상기 평면을 검출하는 적어도 하나의 프로세서; 및 상기 평면이 검출된 결과에 관련된 정보를 표시하는 디스플레이를 포함하는, 전자 장치가 제공된다. 또한, 본 개시의 제3 측면은, 제1 측면의 방법을 수행하도록 하는 프로그램이 저장된 기록매체를 제공할 수 있 다."}
{"patent_id": "10-2020-0077374", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "아래에서는 첨부한 도면을 참조하여 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자가 용이하게 실시할 수 있도록 본 발명의 실시예를 상세히 설명한다. 그러나 본 발명은 여러 가지 상이한 형태로 구현될 수 있으며 여기에서 설명하는 실시예에 한정되지 않는다. 그리고 도면에서 본 발명을 명확하게 설명하기 위해서 설명과 관 계없는 부분은 생략하였으며, 명세서 전체를 통하여 유사한 부분에 대해서는 유사한 도면 부호를 붙였다. 명세서 전체에서, 어떤 부분이 다른 부분과 \"연결\"되어 있다고 할 때, 이는 \"직접적으로 연결\"되어 있는 경우뿐 아니라, 그 중간에 다른 소자를 사이에 두고 \"전기적으로 연결\"되어 있는 경우도 포함한다. 또한 어떤 부분이 어떤 구성요소를 \"포함\"한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다른 구성요소를 제외하는 것이 아 니라 다른 구성요소를 더 포함할 수 있는 것을 의미한다. 본 개시에 따른 인공지능과 관련된 기능은 프로세서와 메모리를 통해 동작된다. 프로세서는 하나 또는 복수의 프로세서로 구성될 수 있다. 이때, 하나 또는 복수의 프로세서는 CPU, AP, DSP(Digital Signal Processor) 등 과 같은 범용 프로세서, GPU, VPU(Vision Processing Unit)와 같은 그래픽 전용 프로세서 또는 NPU와 같은 인 공지능 전용 프로세서일 수 있다. 하나 또는 복수의 프로세서는, 메모리에 저장된 기 정의된 동작 규칙 또는 인 공지능 모델에 따라, 입력 데이터를 처리하도록 제어한다. 또는, 하나 또는 복수의 프로세서가 인공지능 전용 프로세서인 경우, 인공지능 전용 프로세서는, 특정 인공지능 모델의 처리에 특화된 하드웨어 구조로 설계될 수 있다. 기 정의된 동작 규칙 또는 인공지능 모델은 학습을 통해 만들어진 것을 특징으로 한다. 여기서, 학습을 통해 만 들어진다는 것은, 기본 인공지능 모델이 학습 알고리즘에 의하여 다수의 학습 데이터들을 이용하여 학습됨으로 써, 원하는 특성(또는, 목적)을 수행하도록 설정된 기 정의된 동작 규칙 또는 인공지능 모델이 만들어짐을 의미 한다. 이러한 학습은 본 개시에 따른 인공지능이 수행되는 기기 자체에서 이루어질 수도 있고, 별도의 서버 및/ 또는 시스템을 통해 이루어 질 수도 있다. 학습 알고리즘의 예로는, 지도형 학습(supervised learning), 비지도 형 학습(unsupervised learning), 준지도형 학습(semi-supervised learning) 또는 강화 학습(reinforcement learning)이 있으나, 전술한 예에 한정되지 않는다. 인공지능 모델은, 복수의 신경망 레이어들로 구성될 수 있다. 복수의 신경망 레이어들 각각은 복수의 가중치들 (weight values)을 갖고 있으며, 이전(previous) 레이어의 연산 결과와 복수의 가중치들 간의 연산을 통해 신경 망 연산을 수행한다. 복수의 신경망 레이어들이 갖고 있는 복수의 가중치들은 인공지능 모델의 학습 결과에 의 해 최적화될 수 있다. 예를 들어, 학습 과정 동안 인공지능 모델에서 획득한 로스(loss) 값 또는 코스트(cost) 값이 감소 또는 최소화되도록 복수의 가중치들이 갱신될 수 있다. 인공 신경망은 심층 신경망(DNN:Deep Neural Network)를 포함할 수 있으며, 예를 들어, CNN (Convolutional Neural Network), DNN (Deep Neural Network), RNN (Recurrent Neural Network), RBM (Restricted Boltzmann Machine), DBN (Deep Belief Network), BRDNN(Bidirectional Recurrent Deep Neural Network) 또는 심층 Q-네트워크 (Deep Q-Networks) 등이 있으나, 전술한 예에 한정되지 않는다. 이하 첨부된 도면을 참고하여 본 발명을 상세히 설명하기로 한다. 도 1은 일 실시 예에 의한 영상에서 평면을 검출하는 일 예를 나타낸 블록도이다. 도 1을 참조하면, 일 실시 예에 의한 전자 장치는, 영상에 포함된 객체(110, 120)에 기초하여, 평면 을 검출하고, 검출된 평면에 따라, 증강 현실 이미지를 영상을 표시할 수 있다. 일 실시 예에 의한 전자 장치는, 영상과 증강 현실 이미지를 표시할 수 있는 장치일 수 있으며, 다양한 형태로 구현될 수 있다. 예를 들어, 본 명세서에서 기술되는 전자 장치는, 디지털 카메라, 스마트 폰(smart phone), 노트북 컴퓨터(laptop computer), 태블릿 PC, 전자북 단말기, 디지털방송용 단말기, PDA(Personal Digital Assistants), PMP(Portable Multimedia Player), 네비게이션, MP3 플레이어, 차 량(vehicle) 등이 있을 수 있으나, 이에 한정되는 것은 아니다. 본 명세서에서 기술되는 전자 장치는 사 용자에 의해 착용될 수 있는 장치(wearable device)일 수 있다. 웨어러블 디바이스는 액세서리 형 장치(예컨대, 시계, 반지, 팔목 밴드, 발목 밴드, 목걸이, 안경, 콘택트 렌즈), 머리 착용형 장치(head-mounted- device(HMD)), 직물 또는 의류 일체형 장치(예: 전자 의복), 신체 부착형 장치(예컨대, 스킨 패드(skin pad)), 또는 생체 이식형 장치(예: implantable circuit) 중 적어도 하나를 포함할 수 있으나, 이에 한정되는 것은 아 니다. 이하에서는, 설명의 편의상, 전자 장치가 스마트 폰인 경우를 예로 들어 설명하기로 한다. 일 실시 예에 의한 전자 장치는, 전자 장치에 구비된 카메라를 이용하여, 객체(110, 120)를 포함하 는 주변 환경이 촬영된 영상을 획득할 수 있다. 상술한 예에 한하지 않고, 전자 장치는, 외부 장치 (미도시)로부터 영상를 수신함으로써, 평면을 검출하기 위한 영상을 획득할 수도 있다. 일 실시 예에 의한 전자 장치는, 영상에서, 적어도 하나의 객체(110, 120)를 검출하고, 객체(110, 120)의 적어도 하나의 표면 중에서, 평면에 접촉된 표면을 식별할 수 있다. 일 실시 예에 의한 객체(110, 120)의 표면 중 평면에 접촉된 표면은 영상에서 직접적으로 표시되지 않을 수 있다. 따라서, 일 실시 예에 의한 전자 장치는, 평면에 접촉된 표면을 식별하기 위하여, 객 체(110, 120)의 형상을 식별하고, 식별된 객체(110, 120)의 형상을 3차원 모델로 모델링할 수 있다. 일 실시 예 에 의한 전자 장치는 객체(110, 120)가 모델링된 결과에 기초하여, 평면에 접촉된 표면을 식별함으 로써, 영상에서 평면을 검출할 수 있다. 일 실시 예에 따른, 상기 객체(110, 120)의 식별된 표면은, 객체(110, 120)의 3차원 모델에 포함된, 상기 객체(110, 120)의 적어도 하나의 표면 중 하나일 수 있다. 예를 들면, 전자 장치는 객체(110, 120)의 3차원 모델에서, 객체(110, 120)에 대한 적어도 하나의 표면을 식별하고, 적어도 하나의 표면 중, 평면을 검출하기 위한 표면을 식별할 수 있다. 일 실시 예에 의한 객체(110, 120)의 형상은, 영상에 표시된 객체(110, 120)의 형상에 기초하여, 영상 에 표시되어 있지 않은, 객체(110, 120)의 형상이 예측됨으로써, 예측된 결과에 기초하여, 객체(110, 12 0)의 형상이 3D 모델로 모델링될 수 있다. 일 실시 예에 의한 객체의 형상은, 영상에서 상기 객체가 인식된 결과에 기초하여, 예측될 수 있다. 예를 들어, 객체가 책, 박스, 탁자 등으로 인식된 경우, 객체의 형상은 직육면체 모양으로 3차원 모델링될 수 있다. 또한, 객체가 컵, 물병, 등으로 인식된 경우, 객체의 형상은, 원기둥 모양으로 3차원 모델링될 수 있다. 일 실시 예에 의한, 객체(110, 120)의 형상은, 직육면체, 원기둥, 원뿔 등 기하학적 모양의 형상을 포함할 수 있다. 일 실시 예에 의하면, 객체(110, 120)의 형상이 정확하게 기하학적 모양을 가지지 않더라도, 유사 범위에 서, 기하학적 모양에 따라, 객체(110, 120)의 형상이 3차원으로 모델링될 수 있다. 상술한 예에 한하지 않고, 전자 장치에 의해 식별될 수 있는, 객체(110, 120)의 형상은, 영상에 표시된 객체(110, 120)의 형상 에 기초하여, 영상에 표시되어 있지 않은, 객체(110, 120)의 형상이 예측됨으로써, 3차원으로 모델링될 수 있는 다양한 종류의 형상이 포함될 수 있다. 또한, 일 실시 예에 의한 전자 장치는, 영상에 표시된 객체(110, 120)의 형상에 한하지 않고, 영상 과 다른 관점(view)으로 객체(110, 120)가 촬영된 다른 영상들을 더 이용하여, 객체(110, 120)의 형상을 3 차원으로 모델링할 수 있다. 일 실시 예에 의한 전자 장치는, 객체(110, 120)의 형상이 모델링된 3차원 모델에 기초하여, 평면을 식별할 수 있다. 일 실시 예에 의하면, 객체(110, 120)의 3차원 모델에서, 평면과 맞닿은 면에 기초하여, 평면을 식별할 수 있다. 예를 들어, 전자 장치는 객체들(110, 120)의 바닥면을 각각 식별하고, 두 바닥면이 놓인, 평면을 영 상에서 식별할 수 있다. 따라서, 일 실시 예에 의하면, 영상에서 나타나는 평면 영역이 좁더라도, 평면 위에 놓여 있는 객체들(110, 120)의 정보에 기초하여, 영상에 포함된 평면이 정확하게 검출될 수 있다. 일 실시 예에 의한 전자 장치는, 식별된 평면을 기준으로, 증강 현실 이미지를 표시할 수 있다. 예를 들면, 증강 현실 이미지는, 평면 위에 놓여 있는 것처럼 표시됨으로써, 사용자는, 현실 세계에, 증강 현실 이미지가 실제로 존재하는 것처럼 느낄 수 있다. 도 2는 일 실시 예에 의한 평면을 검출하는 일 예를 나타낸 도면이다. 도 2를 참조하면, 일 실시 예에 의한 전자 장치는, 210에서, 영상에 포함된, 적어도 하나의 객체(211, 212, 213, 214)를 식별할 수 있다. 또한, 전자 장치는 220에서, 식별된 객체들(211, 212, 213, 214)의 형상을 3차원으로 모델링함으로써, 두 개의 평면(222, 223)을 검출할 수 있다. 일 실시 예에 따라 식별된 객체들 중에서, 객체(211, 214)은 각각 상자 및 테이블로 인식됨에 따라서, 직육면체 모양으로 3차원 모델링될 수 있다. 또한, 객체(212, 213)은, 머그컵으로 인식됨에 따라서, 원기둥 모양으로 3차 원 모델링될 수 있다. 일 실시 예에 의한 객체 인식은, 영상에서 객체를 인식하여 3차원 모델링을 수행하기 위 해 미리 학습된 인공지능 모델(ex. CNN)에 의해 수행될 수 있으나, 이에 한하지 않고, 다양한 방법에 따라서, 영상에서 객체가 인식될 수 있다. 또한, 일 실시 예에 의한 전자 장치는, 객체가 인식된 결과에 더하여, 영상에서 객체가 포함된 영역에서, 객체에 대한 특징점을 추출하고, 추출된 특징점에 기초하여, 객체들의 형상을 3차원으로 모델링할 수 있다. 예 를 들면, 객체의 특징점 중 객체의 코너 및 엣지 영역 중 적어도 하나에 위치한 특징점에 기초하여, 객체에 대 해 결정된 기하학적 모양에 따라서, 객체들의 형상이 3차원으로 모델링될 수 있다. 일 실시 예에 의한 특징점은, 객체가 표시된 영역에서, 영상의 특징을 나타내는 다양한 종류의 특징점을 포함할 수 있다. 일 실시 예에 의한 특징점은, 포인트 클라우드을 통해 추출될 수 있으나, 이에 한하지 않고, 다양한 방법에 따라서, 추출될 수 있다. 210을 참조하면, 전자 장치는, 영상에 포함된 적어도 하나의 객체(211, 212, 213, 214)들을 식별하고, 각 객체들의 형상을 3차원으로 모델링할 수 있다. 일 실시 예에 의한 전자 장치는, 각 객체들의 형상이 모델 링된 결과에 기초하여, 여러가지 관점(ex. 위, 아래, 뒤)에서 바라본 각각의 객체의 형상을 알 수 있도록, 각 객체들의 형상을 3차원으로 모델링할 수 있다. 일 실시 예에 의하면, 3차원 모델링이 평면을 검출하기 위한 것임을 고려하여, 평면과 맞닿은 면이 포함되도록, 객체의 형상이 모델링될 수 있다. 예를 들어, 테이블 모양의 객체는, 실제로는, 4개의 다리가 평면에 맞닿아 있으나, 테이블이 놓인 평면이 검출될 수 있도록, 4개의 다리 대신, 4개의 다리를 각각 꼭지점으로 하는, 바닥면이 포함된 형상으로 객체가 모델링될 수 있다. 도 3은 일 실시 예에 의한 전자 장치의 내부 구성을 설명하기 위한 블록도이다. 도 4는 일 실시 예에 의한 전자 장치의 내부 구성을 설명하기 위한 블록도이다. 도 3을 참조하면, 전자 장치는, 프로세서 및 디스플레이을 포함할 수 있다. 그러나, 도 3에 도시된 구성 요소 모두가 전자 장치의 필수 구성 요소인 것은 아니다. 도 3에 도시된 구성 요소보다 많은 구성 요소에 의해 전자 장치가 구현될 수도 있고, 도 3에 도시된 구성 요소보다 적은 구성 요소에 의해 전자 장치가 구현될 수도 있다. 예를 들면, 전자 장치는 도 4에 도시된 바와 같이, 일 실시예에 따른 전자 장치는, 프로세서 및 디스플레이 이외에 사용자 입력부, 출력부, 센싱부, 통신부, A/V 입력부 및 메모리를 더 포함할 수도 있다. 사용자 입력부는, 사용자가 전자 장치를 제어하기 위한 데이터를 입력하는 수단을 의미한다. 예를 들어, 사용자 입력부에는 키 패드(key pad), 돔 스위치 (dome switch), 터치 패드(접촉식 정전 용량 방식, 압력식 저항막 방식, 적외선 감지 방식, 표면 초음파 전도 방식, 적분식 장력 측정 방식, 피에조 효과 방 식 등), 조그 휠, 조그 스위치 등이 있을 수 있으나 이에 한정되는 것은 아니다. 일 실시 예에 의하면, 사용자 입력부는, 영상에서 평면을 검출하기 위한 사용자 입력을 수신할 수 있다. 예를 들면, 사용자 입력부는, 현실 세계가 촬영된 영상에 증강 현실 이미지를 표시하기 위한 사용자 입력 을 수신할 수 있다. 일 실시 예에 의하면, 사용자 입력에 따라서, 영상에 증강 현실 이미지를 표시하기 위하여, 영상에서 평면을 검출하는 동작이 수행될 수 있다. 출력부는, 오디오 신호 또는 비디오 신호 또는 진동 신호를 출력할 수 있으며, 출력부는 디스플레 이부, 음향 출력부, 및 진동 모터를 포함할 수 있다. 디스플레이부는 전자 장치에서 처리되는 정보를 표시 출력한다. 일 실시 예에 의하면, 디스플레이 부는 영상에서 평면이 검출된 결과에 관련된 정보를 표시할 수 있다. 예를 들면, 영상에서 검출된 평면에 기초하여, 증강 현실 이미지가 표시될 수 있다. 한편, 디스플레이부와 터치패드가 레이어 구조를 이루어 터치 스크린으로 구성되는 경우, 디스플레이부 는 출력 장치 이외에 입력 장치로도 사용될 수 있다. 디스플레이부는 액정 디스플레이(liquid crystal display), 박막 트랜지스터 액정 디스플레이(thin film transistor-liquid crystal display), 유기 발 광 다이오드(organic light-emitting diode), 플렉시블 디스플레이(flexible display), 3차원 디스플레이(3D display), 전기영동 디스플레이(electrophoretic display) 중에서 적어도 하나를 포함할 수 있다. 그리고 전자 장치의 구현 형태에 따라 전자 장치는 디스플레이부를 2개 이상 포함할 수도 있다. 음향 출력부는 통신부로부터 수신되거나 메모리에 저장된 오디오 데이터를 출력한다. 진동 모터는 진동 신호를 출력할 수 있다. 또한, 진동 모터는 터치스크린에 터치가 입력되는 경우 진동 신호를 출력할 수도 있다. 일 실시 예에 의하면, 음향 출력부 및 진동 모터는 영상에서 평면이 검출된 결과와 관련된 정보를 출력할 수 있다. 예를 들면, 음향 출력부 및 진동 모터에 의해, 검출된 평면에 기초하여, 제공되는 증강 현실 서비스와 관련된 정보가 출력될 수 있다. 프로세서는, 통상적으로 전자 장치의 전반적인 동작을 제어한다. 예를 들어, 프로세서는, 메 모리에 저장된 프로그램들을 실행함으로써, 사용자 입력부, 출력부, 센싱부, 통신부 , A/V 입력부 등을 전반적으로 제어할 수 있다. 전자 장치는 적어도 하나의 프로세서를 포함할 수 있다. 예를 들면, 전자 장치는 CPU(Central Processing Unit), GPU(Graphics Processing Unit), NPU(Neural Processing Unit) 등의 다양한 종류의 프로세서를 포함할 수 있다. 프로세서는 기본적인 산술, 로직 및 입출력 연산을 수행함으로써, 컴퓨터 프로그램의 명령을 처리하도록 구성될 수 있다. 명령은 메모리로부터 프로세서에 제공되거나, 통신부를 통해 수신되어 프로 세서로 제공될 수 있다. 예를 들면 프로세서는 메모리와 같은 기록 장치에 저장된 프로그램 코드 에 따라 명령을 실행하도록 구성될 수 있다. 일 실시 예에 의한 프로세서는 영상에서 객체를 검출하고, 검출된 객체의 형상을 3차원으로 모델링하여, 모델링된 결과에 따라서, 객체의 표면 중 평면에 접촉된 표면을 식별할 수 있다. 또한, 프로세서는 식별 된 객체의 표면에 기초하여, 영상에서 평면을 검출할 수 있다. 일 실시 예에 의하면 검출된 평면에 기초하여, 영상에서 증강현실 이미지가 표시될 수 있다. 일 실시 예에 의한 프로세서는, 영상에서 검출된 객체가 표시된 영역에서, 복수의 특징점들을 추출하고, 추출된 특징점들 중 객체의 엣지 또는 코너에 위치한 특징점을 식별할 수 있다. 또한, 프로세서는, 객체 의 엣지 또는 코너에 위치한 특징점에 기초하여, 객체의 형상을 3차원으로 모델링할 수 있다. 또한, 일 실시 예 에 의한 프로세서는, 객체가 인식된 결과에 따라서, 객체의 형상을 기하학적 모양으로 3차원 모델링할 수 있다. 일 실시 예에 의한 프로세서는 영상에서 검출된 객체의 타입을 식별하고, 식별된 타입에 기초하여, 객체 가 놓인 평면에 대한 타입을 결정할 수 있다. 예를 들어, 객체가 바닥 또는 테이블에 놓인 물체인 것으로 판단된 경우, 객체가 놓인 평면은, 테이블, 바닥 등 의 타입인 것으로 판단될 수 있다. 또한, 객체가 천장 또는 벽에 부착된 물체인 것으로 판단된 경우, 객체가 놓 인 평면은, 천장 또는 벽 타입인 것으로 판단될 수 있다. 일 실시 예에 의한 적어도 하나의 객체에 대해 각각 대응되는 평면의 타입이 결정되고, 동일한 평면의 타입을 가지는 적어도 하나의 객체에 대해 3차원 모델링이 수행되고, 하나의 평면이 검출될 수 있다. 예를 들어, 테이 블에 머그컵과, 책이 놓여있는 장면이 촬영된 영상에 대해, 머그컵과 책이 각각 하나의 평면에 대한 객체임을 고려하여, 3차원 모델링이 수행될 수 있고, 3차원 모델링 결과에 기초하여, 테이블에 대응하는 평면이 검출될 수 있다. 일 실시 예에 따라, 객체가 놓인 평면이 테이블, 바닥 등의 타입인 것으로 판단된 경우, 전자 장치에서 수집된 중력 정보에 기초하여, 객체의 형상이 3차원으로 모델링될 수 있다. 예를 들면, 전자 장치에서 수 집된 중력 정보에 기초하여, 영상에 포함된 객체에 대한 중력 방향이 예측될 수 있고, 예측된 중력 방향에 기초하여, 객체의 형상이 3차원으로 모델링될 수 있다. 일 실시 예에 의하면, 객체의 표면 중 평면에 접촉된 표면으로 식별된 표면에 기초하여, 평면에 대한 적어도 하 나의 특징점이 식별되고, 적어도 하나의 특징점에 기초하여, 평면이 3차원으로 모델링될 수 있다. 따라서, 일 실시 예에 의하면, 평면이 3차원으로 모델링된 결과에 기초하여, 영상에 포함된 평면이 검출될 수 있다. 센싱부는, 전자 장치의 상태 또는 전자 장치 주변의 상태를 감지하고, 감지된 정보를 프로세 서로 전달할 수 있다. 센싱부는, 지자기 센서(Geomagnetic sensor), 가속도 센서(Acceleration sensor), 온/습도 센서, 적외선 센서, 자이로스코프 센서, 위치 센서(예컨대, GPS), 기압 센서, 근접 센서, 및 RGB 센서(illuminance sensor) 중 적어도 하나를 포함할 수 있으나, 이에 한정되는 것은 아니다. 일 실시 예에 의하면, 센싱부는 중력을 감지하기 위한 중력 센서를 더 포함할 수 있고, 센싱부에 의해 감지된 중력의 방향에 기초하여, 영상에 포함된 객체에 대한 중력 방향이 예측될 수 있다. 일 실시 예에 의하면, 객체에 대하여 예측된 중력 방향에 기초하여, 객체의 형상이 3차원으로 모델링될 수 있다. 통신부는, 전자 장치가 서버 또는 외부 장치(미도시)와 통신을 하게 하는 하나 이상의 구성 요소를 포함할 수 있다. 예를 들어, 통신부는, 근거리 통신부, 이동 통신부, 방송 수신부 를 포함할 수 있다. 근거리 통신부(short-range wireless communication unit)는, 블루투스 통신부, BLE(Bluetooth Low Energy) 통신부, 근거리 무선 통신부(Near Field Communication unit), WLAN(와이파이) 통신부, 지그비 (Zigbee) 통신부, 적외선(IrDA, infrared Data Association) 통신부, WFD(Wi-Fi Direct) 통신부, UWB(ultra wideband) 통신부, Ant+ 통신부 등을 포함할 수 있으나, 이에 한정되는 것은 아니다. 이동 통신부는, 이동 통신망 상에서 기지국, 외부의 단말, 서버 중 적어도 하나와 무선 신호를 송수신한 다. 여기에서, 무선 신호는, 음성 호 신호, 화상 통화 호 신호 또는 문자/멀티미디어 메시지 송수신에 따른 다 양한 형태의 데이터를 포함할 수 있다. 방송 수신부는, 방송 채널을 통하여 외부로부터 방송 신호 및/또는 방송 관련된 정보를 수신한다. 방송 채널은 위성 채널, 지상파 채널을 포함할 수 있다. 구현 예에 따라서 전자 장치가 방송 수신부를 포함하지 않을 수도 있다. 일 실시 예에 의한, 통신부는 외부 장치(미도시)로부터 영상을 수신할 수 있다. 또한, 통신부(150 0)는 영상의 평면을 검출하는데 필요한 데이터를 송수신할 수 있다. A/V(Audio/Video) 입력부는 오디오 신호 또는 비디오 신호 입력을 위한 것으로, 이에는 카메라와 마이크로폰 등이 포함될 수 있다. 카메라는 화상 통화모드 또는 촬영 모드에서 이미지 센서를 통해 정지영상 또는 동영상 등의 화상 프레임을 얻을 수 있다. 이미지 센서를 통해 캡쳐된 이미지는 프로세서 또는 별도의 이미지 처리부(미도시)를 통해 처리될 수 있다. 일 실시 예에 의한 카메라는, 객체 및 평면을 포함하는 영상을 촬영함으로써, 평면을 검출하기 위한 영상이 획득될 수 있다. 마이크로폰은, 외부의 음향 신호를 입력 받아 전기적인 음성 데이터로 처리한다. 예를 들어, 마이크로폰 은 영상의 평면을 검출하기 위한 사용자의 음성 입력을 수신할 수 있다. 메모리는, 프로세서의 처리 및 제어를 위한 프로그램을 저장할 수 있고, 전자 장치로 입력되 거나 전자 장치로부터 출력되는 데이터를 저장할 수도 있다. 일 실시 예에 의한 메모리는 평면이 검출될 수 있는 적어도 하나의 영상을 저장할 수 있다. 또한, 메모리는 영상에서 평면을 검출하기 위한 다양한 데이터를 저장할 수 있다. 메모리는 플래시 메모리 타입(flash memory type), 하드디스크 타입(hard disk type), 멀티미디어 카드 마이크로 타입(multimedia card micro type), 카드 타입의 메모리(예를 들어 SD 또는 XD 메모리 등), 램(RAM, Random Access Memory) SRAM(Static Random Access Memory), 롬(ROM, Read-Only Memory), EEPROM(Electrically Erasable Programmable Read-Only Memory), PROM(Programmable Read-Only Memory), 자기 메모리, 자기 디스크, 광디스크 중 적어도 하나의 타입의 저장매체를 포함할 수 있다. 메모리에 저장된 프로그램들은 그 기능에 따라 복수 개의 모듈들로 분류할 수 있는데, 예를 들어, UI 모 듈, 터치 스크린 모듈, 알림 모듈 등으로 분류될 수 있다. UI 모듈은, 애플리케이션 별로 전자 장치와 연동되는 특화된 UI, GUI 등을 제공할 수 있다. 터치 스크린 모듈은 사용자의 터치 스크린 상의 터치 제스처를 감지하고, 터치 제스처에 관한 정보를 프로세서 로 전달할 수 있다. 일부 실시예에 따른 터치 스크린 모듈은 터치 코드를 인식하고 분석할 수 있다. 터치 스크린 모듈은 컨트롤러를 포함하는 별도의 하드웨어로 구성될 수도 있다. 터치스크린의 터치 또는 근접 터치를 감지하기 위해 터치스크린의 내부 또는 근처에 다양한 센서가 구비될 수 있다. 터치스크린의 터치를 감지하기 위한 센서의 일례로 촉각 센서가 있다. 촉각 센서는 사람이 느끼는 정도로 또는 그 이상으로 특정 물체의 접촉을 감지하는 센서를 말한다. 촉각 센서는 접촉면의 거칠기, 접촉 물체의 단 단함, 접촉 지점의 온도 등의 다양한 정보를 감지할 수 있다. 사용자의 터치 제스처에는 탭, 터치&홀드, 더블 탭, 드래그, 패닝, 플릭, 드래그 앤드 드롭, 스와이프 등이 있 을 수 있다. 알림 모듈은 전자 장치의 이벤트 발생을 알리기 위한 신호를 발생할 수 있다. 도 5는 일 실시 예에 의한 영상에서 평면을 검출하는 방법을 나타낸 순서도이다. 도 5를 참조하면, 단계 510에서, 전자 장치는, 평면을 검출하기 위한 영상을 획득할 수 있다. 일 실시 예 에 의한 전자 장치는, 사용자에게 증강현실 서비스를 제공하기 위하여, 영상에서 검출된 평면을 기준으로 증강 현실 이미지를 표시할 수 있다. 일 실시 예에 의하면 전자 장치에 의해, 실시간으로 주변 환경을 촬영 중인 영상이 평면을 검출하기 위한 영상으로서 획득될 수 있다. 따라서, 전자 장치는, 주변 환경이 촬영된 영상에, 증강현실 이미지가 결합 된 영상을 사용자에게 제공할 수 있다. 단계 520에서, 전자 장치는, 영상에서 평면을 검출하기 위한 기준이 되는 객체를 검출할 수 있다. 일 실 시 예에 의하면, 영상에 포함된 평면에 놓여있거나, 평면에 붙어있는 객체들 중에서 평면을 검출하기 위한 객체 가 검출될 수 있다. 예를 들면, 전자 장치는, 영상에 포함된 다양한 객체들과 평면을 미리 학습된 인공지 능 모델(ex. CNN)을 이용하여, 인식하고, 인식된 결과에 따라서, 평면을 검출하기 위한 객체가 식별될 수 있다. 상술한 예에 한하지 않고, 전자 장치는 다양한 방법에 따라서, 영상으로부터 평면을 검출하기 위한 객체 를 검출할 수 있다. 단계 530에서, 전자 장치는 단계 520에서 검출된 객체의 형상을 3차원으로 모델링할 수 있다. 일 실시 예에 의한 전자 장치는, 영상에서 검출된 객체의 엣지 및 코너 중 적어도 하나에 기초하여, 객체 의 형상을 3차원으로 모델링할 수 있다. 일 실시 예에 의한 전자 장치는, 영상에서 객체가 검출된 영역에 서, 적어도 하나의 특징점을 식별하고, 적어도 하나의 특징점의 특징에 따라서, 객체의 엣지 및 코너에 대응하 는 특징점을 식별함으로써, 객체의 엣지 및 코너를 영상에서 검출할 수 있다. 또한, 일 실시 예에 의한 전자 장치는, 객체의 타입에 기초하여, 객체의 형상을 3차원으로 모델링할 수 있다. 일 실시 예에 의한 전자 장치는, 객체의 타입에 기초하여, 객체가 놓인 평면에 대한 타입을 결정하 고, 평면의 타입에 기초하여, 객체의 형상을 3차원으로 모델링할 수 있다. 일 실시 예에 의한 객체의 타입이 바닥에 놓인 물체인 것으로 판단된 경우, 객체가 놓인 평면은, 바닥 타입인 것으로 판단될 수 있다. 또한, 객체가 벽에 부착된 물체인 것으로 판단된 경우, 객체가 놓인 평면은, 벽 타입인것으로 판단될 수 있다. 또한, 일 실시 예에 의한 전자 장치는, 객체에 대하여 예측된 중력 방향에 기초하여, 객체의 형상을 3차 원으로 모델링할 수 있다. 일 실시 예에 의한 전자 장치는, 전자 장치에 구비된 중력 센서에 따라 서, 전자 장치에 대해 적용되는 중력의 방향을 감지할 수 있다. 일 실시 예에 의한 전자 장치는, 전자 장치에서 감지된 중력의 방향에 기초하여, 영상의 객체에 대해 중력 방향을 예측할 수 있다. 예를 들면, 전자 장치는 객체가 촬영될 때의 전자 장치의 기울기 정보에 기초하여, 전자 장치에서 감지된 중력의 방향으로부터 객체에 대한 중력 방향을 예측할 수 있다. 상술한 예에 한하지 않고, 전자 장치 는 다양한 방법에 따라서, 객체에 대한 중력 방향을 예측할 수 있다. 일 실시 예에 따른, 객체의 형상은, 객체의 엣지 및 코너 영역 중 적어도 하나를 나타내도록, 기하학적 모양으 로 모델링될 수 있다. 예를 들어, 객체가 인식된 결과에 따라, 박스, 테이블, 책 등으로 인식된 객체는, 직육면 체 모양으로 모델링될 수 있다. 또한, 머그컵, 페트병 등으로 인식된 객체는, 원기둥 모양으로 모델링될 수 있 다. 일 실시 예에 의한 객체의 형상이 명확하게 기하학적 모양이 아니어도, 유사 범위에서 기하학적 모양으로 모델링될 수 있다. 상술한 예에 한하지 않고, 객체의 형상은 다양한 모양으로 모델링될 수 있다. 단계 540에서, 전자 장치는, 단계 530에서 모델링된 결과에 기초하여, 객체의 표면 중, 영상에서 검출하 고자 하는 평면에 접촉된 표면을 식별할 수 있다. 일 실시 예에 의하면, 객체의 엣지 및 코너 영역 중 적어도 하나에 기초하여, 객체의 형상이 기하학적 모양으로 모델링될 수 있고, 기하학적 모양에 의하면, 영상에서 나타나지 않은, 객체의 엣지 또는 코너 영역이 예측될 수 있다. 따라서, 일 실시 예에 따라 객체의 형상이 모델링된 결과에 의하면, 예측된 객체의 엣지 또는 코너 영역 에 기초하여, 객체의 표면 중 평면에 접촉된 표면이 식별될 수 있다. 단계 550에서, 전자 장치는, 단계 540에서 식별된 평면에 접촉된 객체의 표면에 기초하여, 영상에 포함된 평면을 검출할 수 있다. 일 실시 예에 의한 전자 장치는, 단계 540에서 식별된 평면에 접촉된 객체의 표 면의 방향 및 위치를 기준으로, 평면을 검출할 수 있다. 일 실시 예에 의하면, 3차원으로 모델링된 객체의 형상을 기준으로, 3차원으로 모델링된 평면이 검출됨으로써, 영상에 포함된 평면이 검출될 수 있다. 일 실시 예에 의하면, 단계 540에서 식별된 객체의 표면에 기초하여, 평 면에 대한 적어도 하나의 특징점이 검출될 수 있고, 검출된 특징점에 기초하여, 3차원으로 모델링된 평면이 검 출될 수 있다. 일 실시 예에 따라, 영상에서 검출된 객체가 복수 개 존재하는 경우, 복수 개의 객체의 표면에 기초하여 평면을 검출할 수 있다. 예를 들어, 복수 개의 객체의 표면의 방향 및 위치에 대하여 평균한 값에 기초하여, 평면이 검 출될 수 있다. 상술한 예에 한하지 않고, 일 실시 예에 의한 평면은, 다양한 방법에 따라서, 객체의 평면에 대 한 접촉면의 위치 및 방향에 기초하여, 검출될 수 있다. 일 실시 예에 의한 전자 장치는, 영상에 포함된 평면을 검출한 후, 검출된 평면에 기초하여, 실시간으로 촬영되는 영상에 포함된 평면에 증강현실 이미지를 결합하여 표시할 수 있다. 예를 들어, 전자 장치는, 실시간으로 촬영된 영상에 포함된 적어도 하나의 평면을 인식하고, 인식된 평면 중 일 실시 예에 따라 검출된 평면과 대응되는 평면을 식별할 수 있다. 따라서, 전자 장치는, 실시간으로 촬영된 영상의 장면이 변경되 더라도, 이전에 검출된 평면에 관한 정보에 기초하여, 현재 촬영된 영상의 장면에서 평면을 검출하고, 검출된 평면에 기초하여, 증강현실 이미지를 배치하여 표시할 수 있다. 도 6은 일 실시 예에 의한 영상에서 평면을 검출하는 일 예를 나타낸 블록도이다. 도 6을 참조하면, 일 실시 예에 의한 전자 장치는, 610에서, 영상에 포함된 적어도 하나의 객체를 검출할 수 있다. 일 실시 예에 의하면, 영상에서 객체를 인식하여 검출할 수 있도록 미리 학습된 인공지능 모델(ex. CNN)에 의하여, 영상에서 객체가 검출될 수 있다. 일 실시 예에 있어서, 620에 포함된 동작들은 실시간으로 촬영 중인 영상에 맞추어, 지속적으로 수행될 수 있으 나, 610 및 630에 포함된 동작들은, 현재 촬영 중인 영상에 실시간으로 맞추어 수행되지 않고, 비동기적으로 수 행될 수 있다. 일 실시 예에 의한 전자 장치는, 621에서 검출된 객체의 형상을 3차원으로 모델링하여, 평면에 접촉된 객 체의 표면을 식별함으로써, 객체 기반으로 평면을 검출할 수 있다. 또한, 일 실시 예에 의한 전자 장치는, 622에서, 621에서 검출된 평면에 기초하여, 현재 촬영된 영상에 포함된 평면을 식별할 수 있다. 또한, 일 실시 예에 의한 전자 장치는, 623에서, 현재 촬영된 영상에 포함된 객체 중 621에서 3차원으로 모델링된 객체와 대응되는 객체를 식별하여, 현재 영상에 포함된 객체를 3차원으로 모델링할 수 있다. 일 실시 예에 의하면, 625의 SLAM(Simultaneous localization and mapping), ToF(Time of Flight) 포인트 클라우드 등 의 방법에 따라서, 623의 객체를 식별하기 위한 동작이 수행될 수 있다. 일 실시 예에 의한 전자 장치는, 624에서, 현재 영상에 포함된 객체에 대한 3차원 모델에 기초하여, 객체 의 평면에 대한 접촉면을 식별할 수 있다. 일 실시 예에 의한 평면에 대한 접촉면은, 객체의 타입, 객체에 적용 되는 중력 방향 등 다양한 정보에 기초하여 식별될 수 있다. 예를 들어, 객체의 타입이, 바닥이나 테이블 위에 놓일 수 있는 물체에 해당되는 경우, 객체에 적용되는 중력 방향과 동일한 방향의 객체의 표면이 평면에 대한 접촉면으로 식별될 수 있다. 일 실시 예에 의한 전자 장치는, 626에서, 영상에서, 평면에 관련된 특징점들이 필터링될 수 있다. 일 실 시 예에 의하면, 625의 SLAM, ToF 포인트 클라우드 등의 방법에 따라서, 영상에서 추출된 특징점들 중 624에서, 식별된 접촉면에 기초하여, 평면과 관련된 특징점들이 추출될 수 있다. 일 실시 예에 의하면, 전자 장치는 624에서 식별된 접촉면의 방향과 위치에 기초하여, 평면의 방향과 위 치를 식별할 수 있다. 전자 장치는 식별된 평면의 방향과 위치에 기초하여, 영상에 대해 추출된 특징점들 중 평면과 관련된 특징점들을 추출할 수 있다. 일 실시 예에 의해 추출되는 평면의 특징점은, 평면의 엣지 또는 코너에 위치한 특징점을 포함할 수 있다. 일 실시 예에 의한 전자 장치는, 627에서, 626에서 추출된 평면과 관련된 특징점들에 기초하여, 영상에 포함된 평면의 위치, 방향, 및 크기를 식별할 수 있는, 평면에 대한 3차원 모델을 생성할 수 있다. 또한, 전자 장치는, 630에서, 현재 촬영된 영상에 포함된, 3차원 모델로 식별된 적어도 하나의 평면에 대해, 적어도 하나의 AR 객체를 배치할 수 있다. 일 실시 예에 의한 전자 장치는, 628에서, 각 평면에 AR 객체가 배치된 결과에 기초하여, 각 평면에 대한 가시성을 판단할 수 있다. 예를 들어, 영상에서 표시되는 평면의 크기가 기준값 이하이거나, 평면이 AR 객체가 배치되기에 적절하지 않은 위치에 존재하는지 여부에 기초하여, 영상에 포함된 각 평면에 대한 가시성이 판단될 수 있다. 상술한 예에 한하지 않고, 각 평면에 대한 가시성은, AR 객체를 배치하는데 이용될만한 평면인지 여부 를 판단하기 위한 다양한 방법에 따라서 판단될 수 있다. 일 실시 예에 의하면, 628에서 판단된 각 평면의 가시 성에 기초하여, AR 객체가 배치되는데 적절하지 않은 평면은 제외된 후, 626 및 627에 따라서, 평면에 대한 3차 원 모델이 생성될 수 있다. 도 7은 일 실시 예에 의한 객체의 표면 중 평면에 접촉된 표면을 식별하는 일 예를 나타낸 도면이다. 일 실시 예에 의한 전자 장치는 식별하고자 하는 평면과 관련된 객체가 표시된 영역에 대하여, 적어도 하 나의 특징점을 추출할 수 있다. 일 실시 예에 의하면, 전자 장치는, 영상 인식을 통하여, 영상에서 다양 한 종류의 객체를 식별하고, 식별된 객체들 중에서, 평면과 관련된 객체가 표시된 영역을 식별하여, 상기 영역 에서 적어도 하나의 특징점을 추출할 수 있다. 상술한 예에 한하지 않고, 다양한 방법에 따라서, 평면과 관련된 적어도 하나의 객체가 표시된 영역에 대하여 적어도 하나의 특징점이 추출될 수 있다. 일 실시 예에 의한 전자 장치는, 각 객체의 영역에서 추출된 적어도 하나의 특징점 중에서, 객체(711, 712, 713)의 엣지 및 코너 중 적어도 하나의 영역에 위치한 특징점을 식별하고, 식별된 특징점에 기초하여, 각 각의 객체(711, 712, 713)를 3차원으로 모델링할 수 있다. 일 실시 예에 의한 전자 장치는, 각각의 객체(711, 712, 713)에 대해 3차원으로 모델링된 결과에 따라, 각 객체들(711, 712, 713)에 대한 표면들 중에서 각각 평면에 접촉된 표면들을 식별할 수 있다. 일 실시 예에 의하면, 객체의 타입, 객체의 중력 방향 등 객체에 관한 다양한 정보에 기초하여, 객체의 표면들 중에서, 평면 과 접촉된 객체의 표면이 식별될 수 있다. 일 실시 예에 의하면, 평면과 접촉된 각 객체의 표면에 기초하여, 영상에 표시된 평면이 식별될 수 있다. 일 실 시 예에 의하면, 평면과 접촉된 각 객체의 표면에 기초하여, 평면에 대한 3차원 모델이 생성됨으로써, 평면이 식별될 수 있고, 평면에 대한 3차원 모델에 기초하여, AR 객체가 배치될 수 있다. 도 8은 일 실시 예에 의한 객체에 기초하여, 평면을 식별하는 일 예를 나타낸 도면이다. 일 실시 예에 의한 전자 장치는 810의 영상에 포함된 평면들(841, 842, 843, 844, 845)을 840과 같이 3 차원으로 모델링함으로써, 식별할 수 있다. 820에서, 일 실시 예에 의한 전자 장치는, 영상에서 객체를 인식하기 위하여 미리 학습된 인공지능 모델 을 이용하여, 영상에 포함된 객체가 표시된 영역들(821, 822, 823, 824, 825)을 식별할 수 있다. 일 실시 예에 의하면, 영상에서 인식된 객체 영역 중 821은 벽 타입의 평면을 검출하기 위해 이용될 수 있 다. 또한, 영상에서 인식된 객체 영역 중 822는 테이블 타입 1의 평면을 검출하기 위해 이용될 수 있다. 또한, 영상에서 인식된 객체 영역 중 823는 테이블 타입 2의 평면을 검출하기 위해 이용될 수 있다. 또한, 영상에서 인식된 객체 영역 중 테이블을 포함하는 824는 바닥 타입의 평면을 검출하기 위해 이용될 수 있 다. 또한, 영상에서 인식된 객체 영역 중 테이블을 825는 테이블 타입 3의 평면을 검출하기 위해 이용될 수 있다. 830에서, 일 실시 예에 의한 전자 장치는, 820에서 식별된 객체가 표시된 영역들(821, 822, 823, 824, 825)에서, 적어도 하나의 특징점(831, 832)을 추출할 수 있다. 다만, 일 실시 예에 의하면, 특징점(831, 832)들 중 객체의 엣지 및 코너 중 적어도 하나에 위치하는 특징점이 평면을 식별하기 위한 특징점으로 최종적으 로 추출될 수 있다. 일 실시 예에 의한 전자 장치는, 객체의 엣지 및 코너 중 적어도 하나에 위치하는 특징점에 기초하 여, 각각의 객체에 대한 3차원 모델을 생성하고, 생성된 3차원 모델에 기초하여, 각 객체의 평면에 대한 접촉면 을 식별할 수 있다. 따라서, 일 실시 예에 의한 전자 장치는, 상기 식별된 접촉면에 기초하여, 영상에 포 함된 평면들(841, 842, 843, 844, 845)을 840과 같이 3차원으로 모델링함으로써, 식별할 수 있다. 도 9는 일 실시 예에 의한 중력 방향에 따라서, 객체를 3차원으로 모델링하는 일 예를 나타낸 도면이다. 910을 참조하면, 일 실시 예에 의한 전자 장치는, 의자와 테이블을 포함하는 영상을 촬영할 수 있다. 일 실시 예에 의하면, 데이터 인식 모델에 따라서, 영상에서, 의자 및 테이블이 인식될 수 있 고, 의자 및 테이블의 모양에 기초하여, 각각에 대한 방향(911-1, 912-1)이 판단될 수 있다. 또한, 일 실시 예에 의한 전자 장치는, 전자 장치에서 측정된 중력 방향에 기초하여, 전자 장치 에서 촬영된 영상의 의자 및 테이블에 대해 적용되는 중력 방향(911-2, 912-2)을 판단할 수 있 다. 일 실시 예에 의하면, 의자 및 테이블의 방향(911-1, 912-1)이 각 객체에 적용되는 중력 방향 (911-2, 912-2)과 일치함에 따라서, 의자 및 테이블은 각각 중력과 직교하는 평면(ex. 바닥 평면)에 놓여있는 상태인 것으로 판단될 수 있다. 따라서, 일 실시 예에 의하면, 중력과 직교하는 평면을 검출하는데 의 자 및 테이블의 3차원 모델이 이용될 수 있다. 920을 참조하면, 910과 동일하게, 일 실시 예에 의한 전자 장치는, 의자와 테이블을 포함하는 영상을 촬영할 수 있다. 다만, 920의 의자는 910의 의자와는 다른 방향(921-1)을 향해 있는 상태에서 영상이 촬영될 수 있다. 일 실시 예에 의한 전자 장치는, 전자 장치에서 측정된 중력 방향에 기초하여, 전자 장치에 서 촬영된 영상의 의자 및 테이블에 대해 적용되는 중력 방향(921-2, 922-2)을 판단할 수 있다. 일 실시 예에 의하면, 의자의 방향(921-1)이 의자에 적용되는 중력 방향(921-2)과 상이한 것으로 판단될 수 있다. 또한, 테이블의 방향(922-1)은 테이블에 적용되는 중력 방향(922-2)과 일치하는 것으로 판 단될 수 있다. 따라서, 일 실시 예에 의하면, 테이블은 중력과 직교하는 평면에 놓여있는 상태이고, 의자는, 중력과 직교하는 평면에 위치하지 않는 상태인 것으로 판단될 수 있다. 따라서, 일 실시 예에 의하면, 중력과 직교하는 평면(ex. 바닥 평면)을 검출하는데, 의자에 대한 3차원 모델은 이용되지 않고, 테이블의 3차원 모델 이 이용될 수 있다.도 10은 일 실시 예에 의한 영상에 기초하여, 평면이 검출되는 일 예를 나타내는 도면이다. 도 10을 참조하면, 복수 개의 전자 장치(1000-1, 1000-2)에 의하여, 동시에 동일한 객체(1001, 1002, 1003)를 포함하는 복수 개의 영상이 촬영될 수 있다. 일 실시 예에 의하면, 하나의 전자 장치에 의하여, 동일한 객체(1001, 1002, 1003)를 포함하는 복수 개의 영상이 각각 다른 시점(time point)에서 촬영될 수도 이다. 일 실시 예에 의하면, 각각 다른 관점(view point)에서 촬영된 영상에 기초하여, 생성된 각각의 객체(1001, 1002, 1003)에 대한 3차원 모델은, 각각 다른 영상에 기초함에도 불구하고, 동일한 크기 및 위치를 가진 3차원 모델(1004, 1005)로 생성될 수 있다. 따라서, 각각의 객체(1001, 1002, 1003)에 대한 3차원 모델(1004, 1005) 에서 측정된 값들, 예를 들면, 각 객체(1001, 1002, 1003)의 크기를 나타내는 값(d1, d2, w3, l3)들과, 객체들 간 거리를 나타내는 값들(L13, L12)은 동일한 값으로 획득될 수 있다. 일 실시 예에 의하면, 각각 다른 관점(view point)에서 촬영된 영상에 기초하여 생성된, 동일한 객체에 대한 3 차원 모델은, 동일하게 생성될 수 있다. 따라서, 일 실시 예에 의하면, 각각 다른 관점(view point)에서 촬영된 복수 개의 영상에 기초하여, 획득된 적어도 하나의 객체에 대한 3차원 모델에 기초하여, 각 영상에 포함된 동일 한 평면이 식별될 수 있다. 일 실시 예에 의하면, 영상에 포함된 평면 영역이 좁은 경우에도, 평면에 놓인 객체를 활용하여, 효과적으로 평 면 영역을 검출함에 따라서, 증강 현실 서비스를 이용하는 사용자 경험이 증대될 수 있다. 기기로 읽을 수 있는 저장매체는, 비일시적(non-transitory) 저장매체의 형태로 제공될 수 있다. 여기서, ‘비 일시적 저장매체'는 실재(tangible)하는 장치이고, 신호(signal)(예: 전자기파)를 포함하지 않는다는 것을 의미 할 뿐이며, 이 용어는 데이터가 저장매체에 반영구적으로 저장되는 경우와 임시적으로 저장되는 경우를 구분하 지 않는다. 예로, '비일시적 저장매체'는 데이터가 임시적으로 저장되는 버퍼를 포함할 수 있다. 일 실시예에 따르면, 본 문서에 개시된 다양한 실시예들에 따른 방법은 컴퓨터 프로그램 제품(computer program product)에 포함되어 제공될 수 있다. 컴퓨터 프로그램 제품은 상품으로서 판매자 및 구매자 간에 거래될 수 있 다. 컴퓨터 프로그램 제품은 기기로 읽을 수 있는 저장 매체(예: compact disc read only memory (CD-ROM))의 형태로 배포되거나, 또는 어플리케이션 스토어(예: 플레이 스토어TM)를 통해 또는 두개의 사용자 장치들(예: 스 마트폰들) 간에 직접, 온라인으로 배포(예: 다운로드 또는 업로드)될 수 있다. 온라인 배포의 경우에, 컴퓨터 프로그램 제품(예: 다운로더블 앱(downloadable app))의 적어도 일부는 제조사의 서버, 어플리케이션 스토어의 서버, 또는 중계 서버의 메모리와 같은 기기로 읽을 수 있는 저장 매체에 적어도 일시 저장되거나, 임시적으로 생성될 수 있다. 또한, 본 명세서에서, “부”는 프로세서 또는 회로와 같은 하드웨어 구성(hardware component), 및/또는 프로 세서와 같은 하드웨어 구성에 의해 실행되는 소프트웨어 구성(software component)일 수 있다."}
{"patent_id": "10-2020-0077374", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "전술한 본 발명의 설명은 예시를 위한 것이며, 본 발명이 속하는 기술분야의 통상의 지식을 가진 자는 본 발명 의 기술적 사상이나 필수적인 특징을 변경하지 않고서 다른 구체적인 형태로 쉽게 변형이 가능하다는 것을 이해 할 수 있을 것이다. 그러므로 이상에서 기술한 실시예들은 모든 면에서 예시적인 것이며 한정적이 아닌 것으로 이해해야만 한다. 예를 들어, 단일형으로 설명되어 있는 각 구성 요소는 분산되어 실시될 수도 있으며, 마찬가 지로 분산된 것으로 설명되어 있는 구성 요소들도 결합된 형태로 실시될 수 있다. 본 발명의 범위는 상기 상세한 설명보다는 후술하는 특허청구범위에 의하여 나타내어지며, 특허청구범위의 의미 및 범위 그리고 그 균등 개념으로부터 도출되는 모든 변경 또는 변형된 형태가 본 발명의 범위에 포함되는 것으 로 해석되어야 한다.도면 도면1 도면2 도면3 도면4 도면5 도면6 도면7 도면8 도면9 도면10"}
{"patent_id": "10-2020-0077374", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 일 실시 예에 의한 영상에서 평면을 검출하는 일 예를 나타낸 블록도이다. 도 2는 일 실시 예에 의한 평면을 검출하는 일 예를 나타낸 도면이다. 도 3은 일 실시 예에 의한 전자 장치의 내부 구성을 설명하기 위한 블록도이다.도 4는 일 실시 예에 의한 전자 장치의 내부 구성을 설명하기 위한 블록도이다. 도 5는 일 실시 예에 의한 영상에서 평면을 검출하는 방법을 나타낸 순서도이다. 도 6은 일 실시 예에 의한 영상에서 평면을 검출하는 일 예를 나타낸 블록도이다. 도 7은 일 실시 예에 의한 객체의 표면 중 평면에 접촉된 표면을 식별하는 일 예를 나타낸 도면이다. 도 8은 일 실시 예에 의한 객체에 기초하여, 평면을 식별하는 일 예를 나타낸 도면이다. 도 9는 일 실시 예에 의한 중력 방향에 따라서, 객체를 3차원으로 모델링하는 일 예를 나타낸 도면이다. 도 10은 일 실시 예에 의한 영상에 기초하여, 평면이 검출되는 일 예를 나타내는 도면이다."}
