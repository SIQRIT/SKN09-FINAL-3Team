{"patent_id": "10-2022-0121290", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0042694", "출원번호": "10-2022-0121290", "발명의 명칭": "인공지능 디바이스를 사용을 고려한 인공지능 네트워크 실행 방법", "출원인": "한국전자기술연구원", "발명자": "전석훈"}}
{"patent_id": "10-2022-0121290", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "인공지능 네트워크를 구성하는 각 레이어들을 다수의 실행 주체들에게 분배하는 단계;분배 결과에 따라, 인공지능 네트워크를 실행하는 단계;를 포함하는 것을 특징으로 하는 인공지능 네트워크 연산 방법."}
{"patent_id": "10-2022-0121290", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "청구항 1에 있어서,실행 주체들은,호스트와 호스트에 연결된 적어도 하나의 디바이스를 포함하는 것을 특징으로 하는 인공지능 네트워크 연산 방법."}
{"patent_id": "10-2022-0121290", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "에 있어서,분배 단계는,각 레이어들의 실행 순서와 실행 주체를 기초로, 디바이스 연결 그래프를 생성하는 단계;를 더 포함하는 것을특징으로 하는 인공지능 네트워크 연산 방법."}
{"patent_id": "10-2022-0121290", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "청구항 3에 있어서,해당 레이어의 파라미터는,레이어의 구성에 대한 파라미터와 레이어의 연산에 필요한 파라미터를 포함하고,전송 단계는,해당 레이어의 파라미터를 바이너리 형태로 변환하여 전송하는 것을 특징으로 하는 인공지능 네트워크 연산 방법."}
{"patent_id": "10-2022-0121290", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "청구항 3에 있어서,해당 레이어는,하나의 레이어 또는 연속한 다수의 레이어를 결합한 레이어 블록인 것을 특징으로 하는 인공지능 네트워크 연산방법.공개특허 10-2024-0042694-3-청구항 6"}
{"patent_id": "10-2022-0121290", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "청구항 6에 있어서,실행 단계는,디바이스 연결 그래프를 기초로, 현재 레이어의 실행 주체를 확인하는 단계;실행 주체가 호스트이면, 호스트가 현재 레이어를 실행하는 단계;실행 주체가 디바이스이면, 해당 디바이스에 현재 레이어의 입력 데이터와 실행 명령을 전송하는 단계;해당 디바이스로부터 현재 레이어의 출력 데이터를 수신하는 단계;를 포함하는 것을 특징으로 하는 인공지능 네트워크 연산 방법."}
{"patent_id": "10-2022-0121290", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "청구항 7에 있어서,전송 단계는,텐서 형태의 입력 데이터를 바이너리 형태로 변환하여 전송하고,수신 단계는,바이너리 형태의 출력 데이터를 텐서 형태로 변환하여 전송하는 것을 특징으로 하는 인공지능 네트워크 연산 방법."}
{"patent_id": "10-2022-0121290", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "청구항 1에 있어서,다중 인공지능 네트워크를 구성하는 인공지능 네트워크들을 다수의 실행 주체들에게 분배하는 단계;를 더 포함하는 것을 특징으로 하는 인공지능 네트워크 연산 방법."}
{"patent_id": "10-2022-0121290", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "인공지능 네트워크를 구성하는 각 레이어들을 다수의 실행 주체들에게 분배하는 호스트;분배 결과에 따라, 호스트와 함께 인공지능 네트워크를 실행하는 디바이스들;을 포함하는 것을 특징으로 하는인공지능 시스템."}
{"patent_id": "10-2022-0121290", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "인공지능 네트워크를 구성하는 각 레이어들의 실행 주체를 확인하는 단계;실행 주체가 호스트에 연결된 디바이스이면, 해당 디바이스에 인공지능 네트워크의 생성을 명령하는 단계;공개특허 10-2024-0042694-4-해당 디바이스에, 해당 레이어의 파라미터를 전송하는 단계; 및인공지능 네트워크를 실행하는 단계;를 포함하는 것을 특징으로 하는 인공지능 네트워크 연산 방법."}
{"patent_id": "10-2022-0121290", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "인공지능 연산이 가능한 적어도 하나의 디바이스; 및인공지능 네트워크를 구성하는 각 레이어들의 실행 주체를 확인하고, 실행 주체가 디바이스이면 해당 디바이스에 인공지능 네트워크의 생성을 명령하며 해당 레이어의 파라미터를 전송하는 호스트;를 포함하는 것을 특징으로 하는 인공지능 시스템."}
{"patent_id": "10-2022-0121290", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "인공지능 디바이스를 사용을 고려한 인공지능 네트워크 실행 방법이 제공된다. 본 발명의 실시예에 따른 인공지 능 네트워크 연산 방법은 인공지능 네트워크를 구성하는 각 레이어들을 다수의 실행 주체들에게 분배하고, 분배 결과에 따라, 인공지능 네트워크를 실행한다. 이에 의해, 높은 자원을 사용을 요구하는 인공지능 네트워크를 각 각의 하드웨어 특성에 적합하도록 레이어 연산을 효과적으로 분산 처리함으로써, 자원이 부족한 경량 인공지능 하드웨어 플랫폼에서도 높은 속도로 인공지능 네트워크를 실행할 수 있게 된다."}
{"patent_id": "10-2022-0121290", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 인공지능 기술에 관한 것으로, 더욱 상세하게는 인공지능 연산이 가능한 디바이스들과 연동하여 인공 지능 네트워크를 효과적으로 실행하기 위한 방법에 관한 것이다."}
{"patent_id": "10-2022-0121290", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "인공지능 연산이 가능한 디바이스를 이용하여 인공지능 네트워크를 실행하는 경우, 연산에 필요한 파라미터 데 이터의 전송 및 입출력 데이터의 효과적인 전송을 위해, 수행할 태스크 단위로 모든 파라미터들을 해당 디바이 스의 메모리로 초기화한 뒤 입출력 데이터의 전송을 통해 인공지능 네트워크의 연산을 수행하고 있다. 여기서 파라미터 혹은 데이터의 크기가 해당 디바이스에서 사용할 수 있는 메모리의 크기 보다 크면, 데이터 입 력 배치 수를 줄이거나 크기를 줄여야 해당 디바이스를 사용할 수 있다는 문제가 있다. 일반적으로 GPU의 경우에는 사용 가능한 메모리의 크기가 매우 크긴 하지만, 학습 혹은 테스트에 사용할 입력 데이터의 해상도(resolution) 또는 배치 크기(이미지 개수)가 크다면 디바이스의 허용 메모리를 초과하여 오류 가 발생하기도 한다. 특히 경량 인공지능 시스템에서는 사용 가능한 메모리의 크기가 일반적으로 GPU에서 사용할 수 있는 메모리의 수보다 훨씬 적기 때문에, 인공지능 파라미터의 크기가 크거나 입력 데이터가 많다면 실행이 불가능하다. 대부분의 경량 인공지능 하드웨어 시스템에서는 MAC(Multiply And Accumulation) 연산의 크기 대비 메모리 용량 이 매우 적기 때문인데, 이러한 경량 인공지능 시스템에서 인공지능 모델을 실행하기 위해서는 효율적으로 네트 워크를 실행할 수 있는 방법이 요구된다."}
{"patent_id": "10-2022-0121290", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 상기와 같은 문제점을 해결하기 위하여 안출된 것으로서, 본 발명의 목적은, 인공지능 디바이스들과 연동하여 인공지능 네트워크를 효과적으로 실행하기 위한 방법 및 시스템을 제공함에 있다."}
{"patent_id": "10-2022-0121290", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기 목적을 달성하기 위한 본 발명의 일 실시예에 따른 인공지능 네트워크 연산 방법은 인공지능 네트워크를 구성하는 각 레이어들을 다수의 실행 주체들에게 분배하는 단계; 분배 결과에 따라, 인공지능 네트워크를 실행 하는 단계;를 포함한다.실행 주체들은, 호스트와 호스트에 연결된 적어도 하나의 디바이스를 포함할 수 있다. 분배 단계는, 각 레이어들의 실행 주체를 확인하는 단계; 실행 주체가 호스트에 연결된 디바이스이면, 해당 디 바이스에 인공지능 네트워크의 생성을 명령하는 단계; 해당 디바이스에, 해당 레이어의 파라미터를 전송하는 단 계;를 포함할 수 있다. 해당 레이어의 파라미터는, 레이어의 구성에 대한 파라미터와 레이어의 연산에 필요한 파라미터를 포함하고, 전 송 단계는, 해당 레이어의 파라미터를 바이너리 형태로 변환하여 전송할 수 있다. 해당 레이어는, 하나의 레이어 또는 연속한 다수의 레이어를 결합한 레이어 블록일 수 있다. 분배 단계는, 각 레이어들의 실행 순서와 실행 주체를 기초로, 디바이스 연결 그래프를 생성하는 단계;를 더 포 함할 수 있다. 실행 단계는, 디바이스 연결 그래프를 기초로, 현재 레이어의 실행 주체를 확인하는 단계; 실행 주체가 호스트 이면, 호스트가 현재 레이어를 실행하는 단계; 실행 주체가 디바이스이면, 해당 디바이스에 현재 레이어의 입력 데이터와 실행 명령을 전송하는 단계; 해당 디바이스로부터 현재 레이어의 출력 데이터를 수신하는 단계;를 포 함할 수 있다. 전송 단계는, 텐서 형태의 입력 데이터를 바이너리 형태로 변환하여 전송하고, 수신 단계는, 바이너리 형태의 출력 데이터를 텐서 형태로 변환하여 전송할 수 있다. 본 발명의 실시예에 따른 인공지능 네트워크 연산 방법은, 다중 인공지능 네트워크를 구성하는 인공지능 네트워 크들을 다수의 실행 주체들에게 분배하는 단계;를 더 포함할 수 있다. 본 발명의 다른 실시예에 따른 인공지능 시스템은 인공지능 네트워크를 구성하는 각 레이어들을 다수의 실행 주 체들에게 분배하는 호스트; 분배 결과에 따라, 호스트와 함께 인공지능 네트워크를 실행하는 디바이스들;을 포 함한다. 본 발명의 또 다른 실시예에 따른 인공지능 네트워크 연산 방법은, 인공지능 네트워크를 구성하는 각 레이어들 의 실행 주체를 확인하는 단계; 실행 주체가 호스트에 연결된 디바이스이면, 해당 디바이스에 인공지능 네트워 크의 생성을 명령하는 단계; 해당 디바이스에, 해당 레이어의 파라미터를 전송하는 단계; 및 인공지능 네트워크 를 실행하는 단계;를 포함한다. 본 발명의 또 다른 실시예에 따른 인공지능 시스템은, 인공지능 연산이 가능한 적어도 하나의 디바이스; 및 인 공지능 네트워크를 구성하는 각 레이어들의 실행 주체를 확인하고, 실행 주체가 디바이스이면 해당 디바이스에 인공지능 네트워크의 생성을 명령하며 해당 레이어의 파라미터를 전송하는 호스트;를 포함한다."}
{"patent_id": "10-2022-0121290", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "이상 설명한 바와 같이, 본 발명의 실시예들에 따르면, 높은 자원을 사용을 요구하는 인공지능 네트워크를 각각 의 하드웨어 특성에 적합하도록 레이어, 블록, 네트워크 연산을 효과적으로 분산 처리함으로써, 자원이 부족한 경량 인공지능 하드웨어 플랫폼에서도 높은 속도로 인공지능 네트워크를 실행할 수 있게 된다."}
{"patent_id": "10-2022-0121290", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하에서는 도면을 참조하여 본 발명을 보다 상세하게 설명한다. 본 발명의 실시예에서는 인공지능 연산이 가능한 디바이스들과 연동하여 인공지능 네트워크를 분배하여 효율적/ 효과적으로 실행하는 방법을 제시한다. 특히 메모리가 부족한 인공지능 디바이스들에 인공지능 네트워크의 레이어들을 적절히 분배하여 실행하거나, 나 아가 다중 인공지능 네트워크들을 적절히 분배하여 실행하는 것이다. 도 1과 도 2에는 본 발명이 적용가능한 인공지능 시스템인 경량 인공지능 하드웨어 플랫폼을 도시하였다. 도시 된 바와 같이 본 발명이 적용가능한 경량 인공지능 하드웨어 플랫폼은 하나의 호스트와 적어도 하나의 NN(Neural Network) 디바이스(210,220,230)를 포함하여 구성된다. 도 1에 제시된 시스템은 한 대의 NN 디바이스를 포함하고, 도 2에 제시된 시스템은 세 대의 NN 디바이스 (210,220,230)를 포함하여 구성된다. 한편 제시된 시스템들은 예시적인 것으로, 호스트에 연결되는 NN 디 바이스의 개수에 대해서는 사양과 필요에 따라 다양한 구성이 가능하다. NN 디바이스(210,220,230)는 BNN(Binarized Neural Network) 디바이스, CNN(Convolutional Neural Network) 디바이스, SNN(Spiking Neural Network) 디바이스, NPU(Neural Processing Unit) 디바이스, 뉴로모픽 (Neuromorphic) 디바이스 등으로 구현가능하며, 그 밖의 다른 종류의 디바이스로 구현할 수 있다. 도시된 인공지능 시스템에서 호스트는 NN 디바이스들(210,220,230)과 연동하여 인공지능 네트워크를 구성 하는 레이어들을 적절히 분배하고, 분배 결과에 따라 인공지능 네트워크를 실행한다. 이는 초기화 과정과 추론 과정으로 구분할 수 있다. 초기화 과정(Init)은 호스트가 인공지능 네트워크의 레이어들을 NN 디바이스들(210,220,230) 각각에 분배 하고, 실행을 위한 명령과 파라미터들을 해당 NN 디바이스들에 전송하는 과정이다. 추론 과정(run & outputs)은 호스트가 인공지능 네트워크를 구성하는 레이어들을 순서에 따라 수행하되, NN 디바이스들(210,220,230)에 분배된 레이어에 대해서는 해당 NN 디바이스에 입력 데이터를 전송하여 실행을 명령하고, 실행 결과를 수신하는 과정이다. 이하에서 초기화 과정과 추론 과정에 대해, 하나씩 상세히 설명한다. 도 3은 인공지능 네트워크 연산 방법에 있어서 초기화 과정의 상세 흐름도이다. 초기화 과정은 인공지능 네트워 크를 구성하는 각 레이어들을 다수의 실행 주체들에게 분배하고 필요한 데이터를 전송하여 주는 과정이다. 여기 서 실행 주체는 호스트와 NN 디바이스들(210,220,230)이다. 인공지능 네트워크는 다수의 레이어들로 구성되며, 입력에서 출력까지 단일 방향으로 연결된 순환하지 않는 그 래프 구조(DAG : Directed Acyclic Graph)를 갖는다. 초기화를 위해, 먼저 호스트는 인공지능 네트워크의 입력 레이어부터 순차적으로 각 레이어들의 실행 주체 를 확인한다(S310). 이는 각 레이어를 어느 실행 주체가 실행할 것인지 파악하기 위한 절차이다. 각 레이어들에 대한 실행 주체는 특성을 기초로 사용자가 설정할 수 있지만, 자동 설정도 가능하다. 현재 레이어에 대한 실행 주체가 NN 디바이스들(210,220,230) 중 하나라면(S320-yes), 호스트는 해당 디바 이스에 인공지능 네트워크의 생성을 명령한다(S330). 그리고 호스트는 해당 디바이스가 현재 레이어를 실행할 수 있도록 초기화시킨다(S340). S340단계의 초기 화 과정에 대해, 이하에서 도 4를 참조하여 상세히 설명한다. NN 디바이스 초기화를 위해, 도 4에 도시된 바와 같이 먼저 호스트는 텐서 형태로 되어 있는 현재 레이어 의 파라미터를 바이너리 형태로 변환한다(S341). 여기서 해당 레이어의 파라미터는 레이어의 구성(configuration)에 대한 파라미터와 레이어의 연산에 필요한 파 라미터를 포함한다. 컨볼루션 레이어의 경우를 예로 들면, 전자는 kernel size, stride, padding 등이고, 후자는 weight, bias 등을 말한다. 다음 호스트는 S341단계에서 변환된 파라미터를 패킷으로 구성하여(S342), 해당 디바이스로 전송한다 (S343). 다시 도 3을 참조하여 설명한다. 현재 레이어에 대한 실행 주체가 호스트로 확인 되면(S320-no), 호스트는 해당 레이어를 자신이 실행 하는 것으로 설정한다(S330). 이후 호스트는 각 레이어들의 실행 순서와 실행 주체를 기초로, 디바이스 연결 그래프(Device Connection Graph : DCG)를 생성한다(S350). S310단계 내지 S350단계는, 인공지능 네트워크를 구성하는 레이어들 모두에 대해 완료될 때까지 하나씩 순차적 으로 수행된다(S360,S370). 도 5에는 인공지능 네트워크들의 실행 그래프를 예시하였다. 의 경우 Layer #1,#2,#4는 호스트가 실행 하도록 설정되고, Layer #3은 MN 디바이스 #1이 실행하도록 설정된다. 의 경우 Layer #1은 호스트 가 실행하도록 설정되고, Layer #2~#4는 MN 디바이스 #1이 실행하도록 설정된다. 한편 의 경우 Layer #1~#4를 MN 디바이스 #1이 실행하도록 설정되고, 의 경우 Layer #1,#2는 MN 디바이스 #1이 실행하도록 설정되고, Layer #3,#4는 MN 디바이스 #2가 실행하도록 설정된다. 도 5의 의 경우는 MN 디바이스에 하나의 레이어만이 분배되지만, , 및 의 경우는 MN 디바이스에 연속한 다수의 레이어를 결합한 레이어 블록이 분배된다. 실행 그래프가 도 5에 도시된 바와 같은 인공지능 네트워크들에 대한 디바이스 연결 그래프를 도 6에 제시하였 다. 레이어가 분배되지 않은 경우 인공지능 네트워크 경로를 1 → 2 → 3 → 4 라고 한다면, 도 5의 예시의 경 우 도 6에서 1 → 2 → {3} → 4로 표현이 가능하다. 여기서 {?} 은 MN 디바이스의 실행 레이어를 의미한다. 마 찬가지로 도 5의 예시의 경우 1 → {2}가 되며, 디바이스의 출력이 곧 네트워크의 출력이 된다. 도 5의 예시의 경우 {1}이 되어 입력이 바로 디바이스로 들어가고 출력이 나오는 그래프가 되며, 예시 의 경우 {1}1 → {2}2 로 디바이스 두 개의 연결 그래프로 표현이 가능해진다. 이하에서는 추론 과정에 대해 도 7을 참조하여 설명한다. 도 7은 인공지능 네트워크 연산 방법에 있어서 추론 과정의 상세 흐름도이다. 추론 과정은 레이어 분배 결과에 따라 인공지능 네트워크를 실행하는 과정이다. 이를 위해 먼저 호스트는 초기화 과정에서 생성된 디바이스 연결 그래프를 기초로, 현재 레이어의 실행 주 체를 확인한다(S410). 확인된 실행 주체가 호스트 자신이면(S420-no), 호스트는 자신이 현재 레이어 를 실행한다(S430). 반면 확인된 주체가 디바이스이면(S420-yes), 호스트는 텐서 형태의 현재 레이어의 입력 데이터를 바이너 리 형태로 변환하여(S440), 해당 디바이스에 현재 레이어의 입력 데이터와 실행 명령을 전송하고, 해당 디바이 스는 수신한 입력 데이터로 현재 레이어를 실행시킨다(S450). 다음 호스트는 바이너리 형태의 현재 레이어의 출력 데이터를 텐서 형태로 변환하여 획득한다(S460). S410단계 내지 S460단계는, 인공지능 네트워크를 구성하는 레이어들 모두에 대해 완료될 때까지 하나씩 순차적 으로 수행된다(S470,S480). 레이어들 모두에 대해 S410단계 내지 S460단계가 완료되면, 인공지능 네트워크의 최 종 추론 결과를 얻을 수 있게 된다. 이하에서는 본 발명의 실시예에 대한 테스트에 대해 설명한다. 테스트에서는 ResNet-B 모델을 GPU/NPU로 CNN 연 산이 가능한 호스트와 BNN 디바이스 및 NPU 디바이스가 실행하였다. 도 8에는 ResNet-B 모델의 구조를 나타내었는데, →( → * 3 ) * 4 → 의 순서로 구성되어 있 다. 은 입력 특징 추출, 는 Residual block type_1, 은 Residual block type_0, 는 추론 확률 출 력을 수행한다. 도 8에 제시된 구조에서 디바이스들이 실행하는 블록은 와 이며, 디바이스의 메모리는 512Kbytes이다. 과 는 호스트가 실행한다.도 9와 도 10에는 ResNet-B 모델의 네트워크 구조를 나타내었는데, 파란색 부분은 호스트에 실행하는 과 에 해당한다. 주황색 부분은 디바이스들에서 실행하는데, 디바이스에서 사용 가능한 최대 메모리 크기가 512KByte이므로 입력과 레이어 파라미터의 합 그리고 출력의 총 크기가 이보다 적어야 한다. 따라서 음영으로 구분된 5번의 반복 실행이 필요하며, 디바이스에 네트워크 생성 명령을 내림으로써 자동적으로 초기화와 함께 실행이 된다. 이에 따라 디바이스 초기화 시 전체 디바이스 연결 그래프는 1 → [ → → → → ] → 7 이 된다. 각 그래프와 연동하여 살펴보면 도 11에 제시된 표와 같은 메모리 크기를 갖게 되며, 디바이스와 호스트의 입출 력을 통해 메모리가 부족한 시스템에서도 인공지능 디바이스의 빠른 연산 성능의 이점을 취할 수 있다. 또한, 단일 예시에서는 디바이스의 입출력 데이터의 크기가 1장의 입력 이미지에 대한 인공지능 모델 처리시 약 1.4MBytes의 데이터 입출력이 필요하고 이는 인공지능 연산 시간에 비해 많은 실행시간이 소요되므로 전체적인 인공지능 모델의 실행 속도에서의 이점을 보일 수 없지만 다중 인공지능 디바이스를 통해 분산처리가 가능하게 되면 약 88kbytes 의 데이터 입출력만(동일한 512kbytes의 메모리 spec을 갖는 5개의 인공지능 디바이스를 고려) 필요하기 때문에 실행 속도에서도 이점을 보일 수 있다. 지금까지 인공지능 디바이스를 사용을 고려한 인공지능 네트워크 실행 방법에 대해 바람직한 실시예를 들어 상 세히 설명하였다. 위 실시예에서는 GPU/CPU 기반의 호스트와 인공지능 디바이스의 동적 연동을 통해 인공지능 네트워크를 레이어 또는 블록 단위로 동적 분배하여 효율적인 인공지능 네트워크 실행이 가능하도록 하였다. 한편 다수의 인공지능 네트워크로 구성되는 다중 인공지능 모델에 대해서도 본 발명의 기술적 사상을 적용하여 네트워크 단위로 실행하는 것이 가능하다. 이를 테면, 도 12에 도시된 바와 같이 인공지능 디바이스 (210,220,230) 마다 인공지능 네트워크 A,B,C를 각각 동적으로 할당하여 실행하는 것이다. 이때 네트워크 할당 은 인공지능 디바이스의 특성을 고려하여 실행 가능한 것을 할당한다. 한편, 본 실시예에 따른 장치와 방법의 기능을 수행하게 하는 컴퓨터 프로그램을 수록한 컴퓨터로 읽을 수 있는 기록매체에도 본 발명의 기술적 사상이 적용될 수 있음은 물론이다. 또한, 본 발명의 다양한 실시예에 따른 기 술적 사상은 컴퓨터로 읽을 수 있는 기록매체에 기록된 컴퓨터로 읽을 수 있는 코드 형태로 구현될 수도 있다. 컴퓨터로 읽을 수 있는 기록매체는 컴퓨터에 의해 읽을 수 있고 데이터를 저장할 수 있는 어떤 데이터 저장 장 치이더라도 가능하다. 예를 들어, 컴퓨터로 읽을 수 있는 기록매체는 ROM, RAM, CD-ROM, 자기 테이프, 플로피 디스크, 광디스크, 하드 디스크 드라이브, 등이 될 수 있음은 물론이다. 또한, 컴퓨터로 읽을 수 있는 기록매체 에 저장된 컴퓨터로 읽을 수 있는 코드 또는 프로그램은 컴퓨터간에 연결된 네트워크를 통해 전송될 수도 있다. 또한, 이상에서는 본 발명의 바람직한 실시예에 대하여 도시하고 설명하였지만, 본 발명은 상술한 특정의 실시"}
{"patent_id": "10-2022-0121290", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "예에 한정되지 아니하며, 청구범위에서 청구하는 본 발명의 요지를 벗어남이 없이 당해 발명이 속하는 기술분야 에서 통상의 지식을 가진자에 의해 다양한 변형실시가 가능한 것은 물론이고, 이러한 변형실시들은 본 발명의 기술적 사상이나 전망으로부터 개별적으로 이해되어져서는 안될 것이다."}
{"patent_id": "10-2022-0121290", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1과 도 2는 본 발명이 적용가능한 경량 인공지능 하드웨어 플랫폼들을 예시한 도면들, 도 3은 인공지능 네트워크 연산 방법에 있어서 초기화 과정의 상세 흐름도, 도 4는, 도 3의 초기화 과정의 상세 흐름도, 도 5는 인공지능 네트워크들의 실행 그래프를 예시한 도면, 도 6은 도 5에 도시된 실행 그래프에 대한 디바이스 연결 그래프, 도 7은 인공지능 네트워크 연산 방법에 있어서 추론 과정의 상세 흐름도,도 8 내지 도 11은 테스트 예시, 그리고, 도 12는 본 발명이 적용가능한 경량 인공지능 하드웨어 플랫폼을 예시한 도면이다."}
