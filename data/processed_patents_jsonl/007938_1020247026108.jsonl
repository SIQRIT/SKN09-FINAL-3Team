{"patent_id": "10-2024-7026108", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0153975", "출원번호": "10-2024-7026108", "발명의 명칭": "온-디바이스 인공 지능 비디오 검색", "출원인": "퀄컴 인코포레이티드", "발명자": "파텔, 슈브함 디팍"}}
{"patent_id": "10-2024-7026108", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "인공 신경망(ANN)을 사용하여 모바일 디바이스에서 비디오를 검색하기 위한 컴퓨터 구현 방법으로서,상기 ANN에 의해, 상기 비디오 및 검색어(search query)를 수신하는 단계 - 상기 비디오는 프레임 시퀀스 및 관련 자막 정보를 포함함 -;상기 모바일 디바이스에서, 상기 ANN에 의해, 상기 검색어의 제1 단어 세트에 대한 제1 표현 및 상기 자막 정보의 제2 단어 세트에 대한 제2 표현을 생성하는 단계;상기 모바일 디바이스에서, 상기 ANN에 의해, 상기 제1 표현 및 상기 제2 표현에 기초하여 상관 관계를 결정하는 단계; 및상기 모바일 디바이스에서, 상기 ANN에 의해, 상기 상관 관계에 기초하여 상기 검색어에 응답하는 콘텐트를 포함하는 상기 비디오의 일부를 예측하는 단계를 포함하는, 컴퓨터 구현 방법."}
{"patent_id": "10-2024-7026108", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 예측하는 단계는 상기 검색어에 응답하는 상기 콘텐트를 포함하는 상기 비디오의 일부에대한 시작 시간 및 종료 시간을 추가로 나타내는, 컴퓨터 구현 방법."}
{"patent_id": "10-2024-7026108", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서, 상기 시작 시간에 포함된 상기 비디오의 일부를 상기 종료 시간까지 디스플레이하는 단계를 더포함하는, 컴퓨터 구현 방법."}
{"patent_id": "10-2024-7026108", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서, 상기 ANN은 트랜스포머 신경망을 포함하는, 컴퓨터 구현 방법."}
{"patent_id": "10-2024-7026108", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서, 상기 비디오에 포함된 폐쇄 캡셔닝 정보에 기초하여 상기 관련 자막 정보를 생성하는 단계를더 포함하는, 컴퓨터 구현 방법."}
{"patent_id": "10-2024-7026108", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서, 상기 검색어는 장면, 이벤트, 단어 또는 구에 대한 설명 중 하나 이상을 포함하는, 컴퓨터 구현 방법."}
{"patent_id": "10-2024-7026108", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에 있어서, 상기 검색어는 상기 모바일 디바이스의 음성 입력 텍스트 입력을 통해 공급되는, 컴퓨터 구현방법."}
{"patent_id": "10-2024-7026108", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "인공 신경망(ANN)을 사용하여 모바일 디바이스에서 비디오를 검색하기 위한 장치로서,메모리; 및상기 메모리에 결합된 적어도 하나의 프로세서를 포함하며, 상기 적어도 하나의 프로세서는,상기 ANN에 의해, 상기 비디오 및 검색어를 수신하고 - 상기 비디오는 프레임 시퀀스 및 관련 자막 정보를 포함함 -;상기 모바일 디바이스에서, 상기 ANN에 의해, 상기 검색어의 제1 단어 세트에 대한 제1 표현 및 상기 자막 정보공개특허 10-2024-0153975-3-의 제2 단어 세트에 대한 제2 표현을 생성하고;상기 모바일 디바이스에서, 상기 ANN에 의해, 상기 제1 표현 및 상기 제2 표현에 기초하여 상관 관계를 결정하고;상기 모바일 디바이스에서, 상기 ANN에 의해, 상기 상관 관계에 기초하여 상기 검색어에 응답하는 콘텐트를 포함하는 상기 비디오의 일부를 예측하도록 구성된, 장치."}
{"patent_id": "10-2024-7026108", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서, 상기 적어도 하나의 프로세서는 상기 검색어에 응답하는 상기 콘텐트를 포함하는 상기 비디오의 일부에 대한 시작 시간 및 종료 시간을 나타내는 예측을 생성하도록 추가로 구성되는, 장치."}
{"patent_id": "10-2024-7026108", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9항에 있어서, 상기 적어도 하나의 프로세서는 상기 시작 시간에 포함된 상기 비디오의 일부를 상기 종료 시간까지 디스플레이하도록 추가로 구성되는, 장치."}
{"patent_id": "10-2024-7026108", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제8항에 있어서, 상기 ANN은 트랜스포머 신경망을 포함하는, 장치."}
{"patent_id": "10-2024-7026108", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제8항에 있어서, 상기 적어도 하나의 프로세서는 상기 비디오에 포함된 폐쇄 캡셔닝 정보에 기초하여 상기 관련자막 정보를 생성하도록 추가로 구성되는, 장치."}
{"patent_id": "10-2024-7026108", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제8항에 있어서, 상기 검색어는 장면, 이벤트, 단어 또는 구에 대한 설명 중 하나 이상을 포함하는, 장치."}
{"patent_id": "10-2024-7026108", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제8항에 있어서, 상기 검색어는 상기 모바일 디바이스의 음성 입력 텍스트 입력을 통해 공급되는, 장치."}
{"patent_id": "10-2024-7026108", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "비일시적 컴퓨터 판독 가능 저장 매체에 기록된 인공 신경망(ANN)을 사용하여 모바일 디바이스에서 비디오를 검색하기 위한 프로그램 코드를 갖는 상기 비일시적 컴퓨터 판독 가능 저장 매체로서, 상기 프로그램 코드는 프로세서에 의해 실행되고,상기 ANN에 의해, 상기 비디오 및 검색어를 수신하기 위한 프로그램 코드 - 상기 비디오는 프레임 시퀀스 및 관련 자막 정보를 포함함 -;상기 모바일 디바이스에서, 상기 ANN에 의해, 상기 검색어의 제1 단어 세트에 대한 제1 표현 및 상기 자막 정보의 제2 단어 세트에 대한 제2 표현을 생성하기 위한 프로그램 코드;상기 모바일 디바이스에서, 상기 ANN에 의해, 상기 제1 표현 및 상기 제2 표현에 기초하여 상관 관계를 결정하기 위한 프로그램 코드; 및상기 모바일 디바이스에서, 상기 ANN에 의해, 상기 상관 관계에 기초하여 상기 검색어에 응답하는 콘텐트를 포함하는 상기 비디오의 일부를 예측하기 위한 프로그램 코드를 포함하는, 비일시적 컴퓨터 판독 가능 저장 매체."}
{"patent_id": "10-2024-7026108", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제15항에 있어서, 상기 프로그램 코드는 상기 검색어에 응답하는 상기 콘텐트를 포함하는 상기 비디오의 일부에대한 시작 시간 및 종료 시간을 나타내는 예측을 생성하기 위한 프로그램 코드를 더 포함하는, 비일시적 컴퓨터판독 가능 저장 매체."}
{"patent_id": "10-2024-7026108", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제16항에 있어서, 상기 프로그램 코드는 상기 시작 시간에 포함된 상기 비디오의 일부를 상기 종료 시간까지 디공개특허 10-2024-0153975-4-스플레이하기 위한 프로그램 코드를 더 포함하는, 비일시적 컴퓨터 판독 가능 저장 매체."}
{"patent_id": "10-2024-7026108", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제15항에 있어서, 상기 ANN은 트랜스포머 신경망을 포함하는, 비일시적 컴퓨터 판독 가능 저장 매체."}
{"patent_id": "10-2024-7026108", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제15항에 있어서, 상기 프로그램 코드는 상기 비디오에 포함된 폐쇄 캡셔닝 정보에 기초하여 상기 관련 자막 정보를 생성하기 위한 프로그램 코드를 더 포함하는, 비일시적 컴퓨터 판독 가능 저장 매체."}
{"patent_id": "10-2024-7026108", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제15항에 있어서, 상기 검색어는 장면, 이벤트, 단어 또는 구에 대한 설명 중 하나 이상을 포함하는, 비일시적컴퓨터 판독 가능 저장 매체."}
{"patent_id": "10-2024-7026108", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_21", "content": "제15항에 있어서, 상기 검색어는 상기 모바일 디바이스의 음성 입력 텍스트 입력을 통해 공급되는, 비일시적 컴퓨터 판독 가능 저장 매체."}
{"patent_id": "10-2024-7026108", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_22", "content": "인공 신경망(ANN)을 사용하여 모바일 디바이스에서 비디오를 검색하기 위한 장치로서,상기 ANN에 의해, 상기 비디오 및 검색어를 수신하기 위한 수단 - 상기 비디오는 프레임 시퀀스 및 관련 자막정보를 포함함 -;상기 모바일 디바이스에서, 상기 ANN에 의해, 상기 검색어의 제1 단어 세트에 대한 제1 표현 및 상기 자막 정보의 제2 단어 세트에 대한 제2 표현을 생성하기 위한 수단;상기 모바일 디바이스에서, 상기 ANN에 의해, 상기 제1 표현 및 상기 제2 표현에 기초하여 상관 관계를 결정하기 위한 수단; 및상기 모바일 디바이스에서, 상기 ANN에 의해, 상기 상관 관계에 기초하여 상기 검색어에 응답하는 콘텐트를 포함하는 상기 비디오의 일부를 예측하기 위한 수단을 포함하는, 장치."}
{"patent_id": "10-2024-7026108", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_23", "content": "제22항에 있어서, 상기 검색어에 응답하는 상기 콘텐트를 포함하는 상기 비디오의 일부에 대한 시작 시간 및 종료 시간을 나타내는 예측을 생성하기 위한 수단을 더 포함하는, 장치."}
{"patent_id": "10-2024-7026108", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_24", "content": "제23항에 있어서, 상기 시작 시간에 포함된 상기 비디오의 일부를 상기 종료 시간까지 디스플레이하기 위한 수단을 더 포함하는, 장치."}
{"patent_id": "10-2024-7026108", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_25", "content": "제22항에 있어서, 상기 ANN은 트랜스포머 신경망을 포함하는, 장치."}
{"patent_id": "10-2024-7026108", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_26", "content": "제22항에 있어서, 상기 비디오에 포함된 폐쇄 캡셔닝 정보에 기초하여 상기 관련 자막 정보를 생성하기 위한 수단을 더 포함하는, 장치."}
{"patent_id": "10-2024-7026108", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_27", "content": "제22항에 있어서, 상기 검색어는 장면, 이벤트, 단어 또는 구에 대한 설명 중 하나 이상을 포함하는, 장치."}
{"patent_id": "10-2024-7026108", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_28", "content": "공개특허 10-2024-0153975-5-제22항에 있어서, 상기 검색어는 상기 모바일 디바이스의 음성 입력 텍스트 입력을 통해 공급되는, 장치."}
{"patent_id": "10-2024-7026108", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "인공신경망(ANN)을 이용한 온-디바이스 비디오 쿼리 및 검색을 위한 컴퓨터 구현 방법은 ANN에 의해, 비디오 및 검색어를 수신하는 단계를 포함한다. 비디오에는 프레임 시퀀스 및 관련 자막 정보가 포함된다. 모바일 디바이 스에서 ANN에 의해, 검색어의 제1 단어 세트에 대한 제1 표현 및 자막 정보의 제2 단어 세트에 대한 제2 표현이 생성된다. 검색어와 자막 정보 사이의 상관 관계는 제1 표현과 제2 표현에 기초하여 ANN에 의해 모바일 디바이 스에서 결정된다. ANN은, 모바일 디바이스에서, 상관 관계에 기초하여 검색어에 응답하는 콘텐트를 포함하는 비 디오의 일부를 예측한다."}
{"patent_id": "10-2024-7026108", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "관련 출원들에 대한 상호 참조 본 출원은 2022년 3월 3일에 출원되고 \"ON-DEVICE ARTIFICIAL INTELLIGENCE VIDEO SEARCH\"이라는 명칭의 인도 특허 출원 번호 제202241011422호에 대한 우선권을 주장하며, 그 개시 내용은 그 전문에 참조로 명시적으로 통 합된다."}
{"patent_id": "10-2024-7026108", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 2, "content": "기술분야 본 개시의 양태는 일반적으로 신경망에 관한 것으로, 보다 구체적으로는 인공 신경망을 사용한 온-디바이스(on- device) 비디오 검색에 관한 것이다."}
{"patent_id": "10-2024-7026108", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "인공 신경망은 상호 연결된 인공 뉴런 그룹(예를 들어, 뉴런 모델)을 포함할 수 있다. 인공 신경망은 계산 디 바이스일 수도 있고, 계산 디바이스에 의해 수행될 방법으로 나타낼 수도 있다. 콘볼루션 신경망은 피드포워드 (feed-forward) 인공 신경망의 한 유형이다. 콘볼루션 신경망에는 각각 수용 필드가 있고 입력 공간을 집합적 으로 타일링(tile)하는 뉴런 모음이 포함될 수 있다. 심층 콘볼루션 신경망(deep convolutional neural network; DCN)과 같은 콘볼루션 신경망(convolutional neural network; CNN)에는 수많은 응용 분야가 있다. 특히, 이러한 신경망 아키텍처는 이미지 인식, 패턴 인식, 음성 인식, 자율 주행 및 기타 분류 태스크와 같은 다양한 기술에 사용된다. 예를 들어, 스마트폰이나 기타 모바일 디바이스와 같은 에지 디바이스는 예를 들어 음악이나 비디오와 같은 미 디어를 소비하는 데 널리 사용된다. 신경망의 많은 유용한 응용 분야를 고려하면, 에지 디바이스에 대한 사용 수요가 증가하고 있다. 비디오, 노래 또는 기타 시퀀스 내에서 특정 콘텐트를 검색하는 것은 사용자의 일반적 인 태스크이다. 예를 들어, 종종 사용자는 예를 들어 전체 영화나 비디오를 보지 않고, 예를 들어 영화에서 좋 아하거나 기억에 남는 장면, 중요한 이벤트(예를 들어, 목표) 대화 또는 비디오의 대화를 재생하기를 원할 수 있다. 그러나 이러한 이벤트를 자동으로 검색하는 것은 번거롭고 시간 소모적이며 전력 관점에서 계산 비용이 많이 든다. 이는 특히 모바일 디바이스와 같이 자원이 제한된 디바이스에서 악화된다. 본 개시는 각각 독립항에 명시되어 있다. 본 개시의 일부 양태는 종속항에 설명되어 있다. 본 개시의 일 양태에서, 인공 신경망(ANN)을 사용하여 모바일 디바이스에서 비디오를 검색하기 위한 컴퓨터 구 현 방법은, ANN에 의해, 비디오 및 검색어(search query)를 수신하는 단계를 포함한다. 비디오에는 프레임 시 퀀스 및 관련 자막 정보가 포함된다. 컴퓨터 구현 방법은 또한, 모바일 디바이스에서, ANN에 의해, 검색어의 제1 단어 세트에 대한 제1 표현 및 자막 정보의 제2 단어 세트에 대한 제2 표현을 생성하는 단계를 포함한다. 컴퓨터 구현 방법은, 모바일 디바이스에서, ANN에 의해, 제1 표현 및 제2 표현에 기초하여 상관 관계를 결정하 는 단계를 추가로 포함한다. 컴퓨터 구현 방법은, 모바일 디바이스에서, ANN에 의해, 상관 관계에 기초하여 검 색어에 응답하는 콘텐트를 포함하는 비디오의 일부를 예측하는 단계를 더 포함한다. 본 개시의 또 다른 양태는, ANN에 의해, 비디오 및 검색어를 수신하기 위한 수단을 포함하는 장치에 관한 것이다. 비디오에는 프레임 시퀀스 및 관련 자막 정보가 포함된다. 장치는 또한, 모바일 디바이스에서, ANN에 의 해, 검색어의 제1 단어 세트에 대한 제1 표현 및 자막 정보의 제2 단어 세트에 대한 제2 표현을 생성하기 위한 수단을 포함한다. 추가로, 장치는, 모바일 디바이스에서, ANN에 의해, 제1 표현 및 제2 표현에 기초하여 상관 관계를 결정하기 위한 수단을 포함한다. 장치는, 모바일 디바이스에서, ANN에 의해, 상관 관계에 기초하여 검 색어에 응답하는 콘텐트를 포함하는 비디오의 일부를 예측하기 위한 수단을 더 포함한다. 본 개시의 또 다른 양태에서, 비일시적 컴퓨터 구현 매체가 제시된다. 비일시적 컴퓨터 판독 가능 저장 매체는 그에 기록된 인공 신경망(ANN)을 사용하여 모바일 디바이스에서 비디오를 검색하기 위한 프로그램 코드를 갖는 다. 프로그램 코드는 프로세서에 의해 실행되며, ANN에 의해 비디오 및 검색어를 수신하기 위한 프로그램 코드를 포함한다. 비디오에는 프레임 시퀀스 및 관련 자막 정보가 포함된다. 프로그램 코드는 또한, 모바일 디바 이스에서, ANN에 의해, 검색어의 제1 단어 세트에 대한 제1 표현 및 자막 정보의 제2 단어 세트에 대한 제2 표 현을 생성하기 위한 프로그램 코드를 포함한다. 프로그램 코드는, 모바일 디바이스에서, ANN에 의해, 제1 표현 및 제2 표현에 기초하여 상관 관계를 결정하기 위한 프로그램 코드를 추가로 포함한다. 프로그램 코드는, 모바 일 디바이스에서, ANN에 의해, 상관 관계에 기초하여 검색어에 응답하는 콘텐트를 포함하는 비디오의 일부를 예 측하기 위한 프로그램 코드를 더 포함한다. 본 개시의 또 다른 양태는 인공 신경망(ANN)을 사용하여 모바일 디바이스에서 비디오를 검색하기 위한 장치에 관한 것이다. 장치는 메모리 및 메모리에 결합된 하나 이상의 프로세서를 갖는다. 프로세서(들)는, ANN에 의 해, 비디오 및 검색어를 수신하도록 구성된다. 비디오에는 프레임 시퀀스 및 관련 자막 정보가 포함된다. 프 로세서(들)는 또한, 모바일 디바이스에서, ANN에 의해, 검색어의 제1 단어 세트에 대한 제1 표현 및 자막 정보 의 제2 단어 세트에 대한 제2 표현을 생성하도록 구성된다. 프로세서(들)는, 모바일 디바이스에서, ANN에 의해, 제1 표현 및 제2 표현에 기초하여 상관 관계를 결정하도록 추가로 구성된다. 프로세서(들)는, 모바일 디 바이스에서, ANN에 의해, 상관 관계에 기초하여 검색어에 응답하는 콘텐트를 포함하는 비디오의 일부를 예측하 도록 추가로 구성된다. 본 개시의 추가 특징 및 이점이 아래에서 설명될 것이다. 당업자는 본 개시가 본 개시와 동일한 목적을 수행하 기 위해 다른 구조를 수정하거나 설계하기 위한 기초로서 쉽게 활용될 수 있음을 이해해야 한다. 또한, 당업자 는 이러한 동등한 구성이 첨부된 청구범위에 명시된 바와 같은 개시의 교시로부터 벗어나지 않는다는 것을 인식 해야 한다. 추가 목적 및 이점과 함께 구성 및 동작 방법에 관해, 본 개시의 특징이라고 생각되는 신규한 특징 은 첨부 도면과 관련하여 고려할 때 다음의 설명으로부터 더 잘 이해될 것이다. 그러나, 도면 각각은 예시 및 설명의 목적으로만 제공되며, 본 개시의 한계를 정의하려는 의도가 아니라는 것이 명백히 이해되어야 한다."}
{"patent_id": "10-2024-7026108", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "첨부된 도면과 관련하여 아래에 명시된 상세한 설명은 다양한 구성에 대한 설명으로 의도되었으며 설명된 개념 이 실행될 수 있는 유일한 구성을 나타내려는 의도는 아니다. 상세한 설명에는 다양한 개념에 대한 철저한 이 해를 제공할 목적으로 구체적인 내용이 포함되어 있다. 그러나, 이러한 개념이 이러한 특정 세부사항 없이도 실시될 수 있다는 것은 당업자에게 명백할 것이다. 일부 경우에, 잘 알려진 구조들 및 컴포넌트들은 이러한 개 념들을 모호하게 하는 것을 피하기 위해 블록도 형식으로 도시된다. 교시에 기초하여, 당업자는 본 개시의 범위가 본 개시의 임의의 다른 양태와 독립적으로 구현되든 또는 조합되 든 간에, 본 개시의 임의의 양태를 포괄하도록 의도된다는 것을 인식해야 한다. 예를 들어, 장치는 구현될 수 있거나 방법은 명시된 임의 개수의 양태를 사용하여 실시될 수 있다. 추가로, 본 개시의 범위는 명시된 본 개 시의 다양한 양태에 더하여 또는 그 이외의 다른 구조, 기능, 또는 구조 및 기능을 사용하여 실시되는 이러한 장치 또는 방법을 포괄하도록 의도된다. 개시된 본 개시의 임의의 양태는 청구범위의 하나 이상의 요소에 의해 구현될 수 있다는 것이 이해되어야 한다. \"예시적인(exemplary)\"라는 단어는 \"예, 인스턴스 또는 예시로서의 역할을 하는\"을 의미하는 데 사용된다. \"예 시적인\"으로 개시된 임의의 양태는 반드시 다른 양태보다 선호되거나 유리한 것으로 해석될 필요는 없다. 특정 양태가 설명되어 있지만, 이들 양태의 많은 변형 및 순열은 본 개시의 범위 내에 속한다. 바람직한 양태 의 일부 혜택 및 이점이 언급되어 있지만, 본 개시의 범위는 특정 혜택, 용도 또는 목적으로 제한되도록 의도되 지 않는다. 오히려, 본 개시의 양태는 다양한 기술, 시스템 구성, 네트워크 및 프로토콜에 광범위하게 적용 가 능하도록 의도되었으며, 이들 중 일부는 도면 및 바람직한 양태에 대한 다음 설명에서 예를 들어 예시되어 있다. 상세한 설명 및 도면은 본 개시를 제한하기보다는 단순히 예시하는 것이며, 본 개시의 범위는 첨부된 청 구범위 및 그 등가물에 의해 정의된다. 설명된 바와 같이, 비디오 내에서 특정 콘텐트를 검색하는 것은 사용자의 일반적인 태스크이다. 종종, 사용자 는 예를 들어 전체 영화나 비디오를 보지 않고, 영화에서 좋아하거나 기억에 남는 장면, 중요한 이벤트(예를 들 어, 목표) 대화 또는 비디오의 대화를 재생하기를 원할 수 있다. 그러나 이러한 이벤트를 자동으로 검색하는 것은 번거롭고 시간 소모적이며 전력 관점에서 계산 비용이 많이 든다. 이는 특히 모바일 디바이스와 같이 리 소스가 제한된 디바이스에서 악화된다. 비디오 검색을 위한 기존 기술에는 비디오 프레임의 의미론적 이해를 키우는 것이 포함되고 검색에 표시된 올바 른 비디오 순간을 찾기 위해 비디오 프레임 각각을 검색하는 것이 포함된다. 더 빠른 결과를 생성하기 위해, 일부 기존 기술에는 모든 비디오 프레임의 전처리 및 학습 내용을 캐시된 코퍼스/데이터베이스에 저장하는 것도 포함된다. 그러나, 비디오 프레임의 의미론적 이해는 어려운 태스크이다. 추가로, 이러한 기존 기술은 비디오 검색에 상당한 시간을 소비하므로 시간이 많이 걸린다. 더욱이, 기존 기술은 계산 비용이 많이 들고, 이는 스 마트폰이나 기타 모바일 디바이스와 같은 자원이 제한된 디바이스에서 악화된다. 이들 및 다른 과제를 해결하기 위해, 본 개시의 양태는 비디오의 온-디바이스 쿼리 및 검색에 관한 것이다. 인 공 신경망은 사용자의 검색어와 비디오의 자막 정보를 처리하고, 검색된 콘텐트가 포함될 가능성이 가장 높은 비디오 부분을 나타내는 예측을 생성할 수 있다. 일부 양태에서, 인공 신경망은 검색어와 일치하거나 검색된 콘텐트를 포함할 가능성이 있는 이벤트에 대한 N개의 예측 목록을 생성할 수 있으며(예를 들어, 검색어가 여러 번 발생하는 이벤트를 설명하는 경우), 여기서 N은 정수이다. 일부 양태에서, 예측은 검색된 콘텐트를 포함하는 부분을 식별하기 위한 시작 시간 및 종료 시간을 포함할 수 있다. 예측된 부분은 비디오 또는 미디어 플레이어에서 텍스트 또는 타임스탬프(예를 들어, 타임라인 위치)로 디스플레이될 수 있어, 사용자가 검색된 콘텐트를 재생하기 위해 예측된 부분으로 쉽게 탐색할 수 있거나, 일부 양태에서 모바일 디바이스는 예측된 부분을 자동으로 재생할 수 있다. 처리 및 예측은 온-디바이스에서 수행될 수 있다. 온-디바이스는 클라우드나 원격 컴퓨팅의 도움 없이 처리하고 예측하는 것을 의미할 수 있다. 도 1은 중앙 처리 유닛(central processing unit; CPU) 또는 인공 신경망(예를 들어, 종단 간 신경망 (neural end-to-end network))을 사용하여 비디오를 검색하도록 구성된 멀티 코어 CPU를 포함할 수 있는, 시스 템 온 칩(system-on-a-chip; SOC)의 예시적인 구현을 예시한다. 변수(예를 들어, 신경 신호 및 시냅스 가 중치), 계산 디바이스(예를 들어, 가중치가 있는 신경망)와 관련된 시스템 파라미터, 지연, 주파수 빈 (frequency bin) 정보 및 태스크 정보는 신경 처리 유닛(neural processing unit; NPU)과 관련된 메모리 블록에, CPU와 관련된 메모리 블록에, 그래픽 처리 유닛(graphics processing unit; GPU)과 관련된 메모리 블록에, 디지털 신호 프로세서(digital signal processor; DSP)와 관련된 메모리 블록에, 메모리 블록 에 저장될 수 있거나, 또는 다수의 블록에 걸쳐 분산될 수 있다. CPU에서 실행되는 명령어는 CPU와 연관된 프로그램 메모리로부터 로드될 수 있거나 또는 메모리 블록으로부터 로드될 수 있다. SOC는 또한 GPU, DSP, 연결성 블록과 같은 특정 기능에 맞춰진 추가 처리 블록을 포함할 수 있으며, 이에는 5세대(5G) 연결성, 4세대 롱 텀 에볼루션(4G LTE) 연결성, Wi-Fi 연결성, USB 연결성, 블루 투스(Bluetooth) 연결성 등, 및 예를 들어 제스처를 검출하고 인식할 수 있는 멀티미디어 프로세서가 포함 될 수 있다. 일 구현에서, NPU는 CPU, DSP 및/또는 GPU에서 구현된다. SOC는 또한센서 프로세서, 이미지 신호 프로세서(image signal processor; ISP), 및/또는 위성 위치 확인 시스 템을 포함할 수 있는 네비게이션 모듈을 포함할 수 있다. SOC는 ARM 명령어 세트에 기초할 수 있다. 본 개시의 양태에서, 범용 프로세서에 로드된 명령어는 ANN에 의해 수신되는 코드, 비디오 및 검색어를 포함할 수 있다. 비디오에는 프레임 시퀀스 및 관련 자막 정보 가 포함된다. 범용 프로세서는 또한 모바일 디바이스에서, ANN에 의해, 검색어의 제1 단어 세트에 대한 제1 표현 및 자막 정보의 제2 단어 세트에 대한 제2 표현을 생성하기 위한 코드를 포함할 수 있다. 범용 프로 세서는, 모바일 디바이스에서, ANN에 의해, 제1 표현과 제2 표현에 기초한 상관 관계를 결정하기 위한 코 드를 추가로 포함할 수 있다. 범용 프로세서는 모바일 디바이스에서, ANN에 의해, 상관 관계에 기초하여 검색어에 응답하는 콘텐트를 포함하는 비디오의 일부를 예측하기 위한 코드를 더 포함할 수 있다. 딥 러닝 아키텍처는 각 계층에서 연속적으로 더 높은 레벨의 추상화로 입력을 나타내도록 학습함으로써 객체 인 식 태스크를 수행할 수 있으며, 이로써 입력 데이터의 유용한 특징 표현을 구축할 수 있다. 이러한 방식으로, 딥 러닝은 기존 기계 학습의 주요 병목 현상을 해결한다. 딥 러닝이 출현하기 전에는, 객체 인식 문제에 대한 기계 학습 접근 방식이 아마도 얕은 분류기와 결합하여 인간이 설계한 특징에 크게 의존했을 수 있다. 얕은 분 류기는 예를 들어 특징 벡터 컴포넌트의 가중 합을 임계값과 비교하여 입력이 어느 클래스에 속하는지 예측할 수 있는 2-클래스 선형 분류기일 수 있다. 인간이 설계한 특징은 도메인 전문 지식을 갖춘 엔지니어가 특정 문 제 도메인에 맞게 조정된 템플릿 또는 커널일 수 있다. 이와 대조적으로, 딥 러닝 아키텍처는 인간 엔지니어가 설계할 수 있는 것과 유사한 특징을 나타내도록 학습하지만, 훈련을 통해 학습할 수 있다. 또한, 심층 네트워 크는 인간이 고려하지 않았을 수 있는 새로운 유형의 특징을 나타내고 인식하도록 학습할 수 있다. 딥 러닝 아키텍처는 특징의 계층 구조를 학습할 수 있다. 예를 들어 시각적 데이터가 제시되면, 제1 계층은 입 력 스트림에서 에지와 같은 상대적으로 간단한 특징을 인식하도록 학습할 수 있다. 또 다른 예에서, 청각 데이 터가 제시되면, 제1 계층은 특정 주파수의 스펙트럼 전력을 인식하도록 학습할 수 있다. 제1 계층의 출력을 입 력으로 받는 제2 계층은 시각 데이터의 경우 단순한 모양, 청각 데이터의 경우 소리의 조합과 같은 특징의 조합 을 인식하도록 학습할 수 있다. 예를 들어, 상위 계층은 시각적 데이터의 복잡한 모양이나 청각 데이터의 단어 를 나타내도록 학습할 수 있다. 더 높은 계층에서는 일반적인 시각적 객체나 음성 문구를 인식하도록 학습할 수 있다. 딥 러닝 아키텍처는 자연스러운 계층 구조를 갖는 문제에 적용될 때 특히 잘 수행할 수 있다. 예를 들어, 자동 차의 분류는 바퀴, 앞유리 및 기타 특징을 인식하는 제1 학습을 통해 이점을 얻을 수 있다. 이러한 특징은 자 동차, 트럭 및 비행기를 인식하기 위해 다양한 방식으로 상위 계층에서 결합될 수 있다. 신경망은 다양한 연결성 패턴으로 설계될 수 있다. 피드포워드 네트워크에서는, 정보가 하위 계층에서 상위 계 층으로 전달되며, 주어진 계층의 각 뉴런은 상위 계층의 뉴런과 통신한다. 위에서 설명된 바와 같이, 계층적 표현은 피드포워드 네트워크의 연속적인 계층에 구축될 수 있다. 신경망에는 순환 또는 피드백(하향식이라고도 함) 연결이 있을 수도 있다. 순환 연결에서는, 주어진 계층에 있는 뉴런의 출력이 동일한 계층에 있는 또 다른 뉴런으로 전달될 수 있다. 순환 아키텍처는 신경망에 순차적으로 전달되는 입력 데이터 청크 중 하나 이상에 걸쳐 있는 패턴을 인식하는 데 도움이 될 수 있다. 주어진 계층의 뉴런에서 하위 계층의 뉴런으로의 연결을 피 드백(또는 하향식) 연결이라고 한다. 피드백 연결이 많은 네트워크는 하이 레벨 개념의 인식이 입력의 특정 로 우 레벨 특징을 구별하는 것을 도울 때 도움이 될 수 있다. 신경망의 계층 간 연결은 완전히 연결되거나 로컬로 연결될 수 있다. 도 2a는 완전 연결식 신경망의 일 예를 예시한다. 완전 연결식 신경망에서, 제1 계층의 뉴런은 자신의 출력을 제2 계층의 모든 뉴런에 전달 할 수 있으므로 제2 계층의 각 뉴런은 제1 계층의 모든 뉴런으로부터 입력을 받을 수 있을 것이다. 도 2b는 로 컬 연결식 신경망의 일 예를 예시한다. 로컬 연결식 신경망에서, 제1 계층의 뉴런은 제2 계층의 제 한된 수의 뉴런에 연결될 수 있다. 보다 일반적으로는, 로컬 연결식 신경망의 로컬 연결식 계층은 계층의 각 뉴런이 동일하거나 유사한 연결성 패턴을 갖지만 서로 다른 값(예를 들어, 210, 212, 214 및 216)을 가질 수 있는 연결 강도를 갖도록 구성될 수 있다. 로컬 연결식 연결성 패턴은 상위 계층에서 공간적으로 구별되는 수 용 필드를 발생시킬 수 있는데, 이는 주어진 영역의 상위 계층 뉴런이 네트워크에 대한 전체 입력 중 제한된 부 분의 속성에 대한 훈련을 통해 조정된 입력을 수신할 수 있기 때문이다. 로컬 연결식 신경망의 한 예는 콘볼루션 신경망이다. 도 2c는 콘볼루션 신경망의 일 예를 예시한다. 콘 볼루션 신경망은 제2 계층의 각 뉴런에 대한 입력과 연관된 연결 강도가 공유되도록 구성될 수 있다(예를 들어, 208). 콘볼루션 신경망은 입력의 공간적 위치가 의미 있는 문제에 매우 적합할 수 있다.콘볼루션 신경망의 한 유형은 심층 콘볼루션 네트워크(deep convolutional network; DCN)이다. 도 2d는 자동 차 장착 카메라와 같은 이미지 캡처 디바이스로부터 입력된 이미지로부터 시각적 특징을 인식하도록 설계된 DCN의 상세한 예를 예시한다. 현재 예의 DCN은 교통 표지판과 교통 표지판에 제공된 번호를 식별하도록 훈련될 수 있다. 물론, DCN은 차선 표시 식별이나 신호등 식별과 같은 다른 태스크를 위해 훈 련될 수 있다. DCN은 지도 학습(supervised learning)을 통해 훈련될 수 있다. 훈련 동안, DCN에는 속도 제한 표 지판의 이미지와 같은 이미지가 제시될 수 있으며, 그런 다음 포워드 패스(forward pass)가 계산되어 출력 을 생성할 수 있다. DCN은 특징 추출 섹션과 분류 섹션을 포함할 수 있다. 이미지를 수신하면, 콘볼루션 계층은 이미지에 콘볼루션 커널(도시되지 않음)을 적용하여 제1 특징 맵 세트 를 생성할 수 있다. 일 예로서, 콘볼루션 계층에 대한 콘볼루션 커널은 28x28 특징 맵을 생성하는 5x5 커널일 수 있다. 본 예에서, 4개의 서로 다른 특징 맵이 제1 특징 맵 세트에서 생성되었기 때문에, 4 개의 서로 다른 콘볼루션 커널이 콘볼루션 계층의 이미지에 적용되었다. 콘볼루션 커널은 필터 또는 콘볼루션 필터라고도 한다. 제1 특징 맵 세트는 최대 풀링 계층(도시되지 않음)에 의해 서브샘플링되어 제2 특징 맵 세트를 생성 할 수 있다. 최대 풀링 계층은 제1 특징 맵 세트의 크기를 줄인다. 즉, 14x14와 같은 제2 특징 맵 세트 의 크기는 28x28과 같은 제1 특징 맵 세트의 크기보다 작다. 크기가 줄어들면 메모리 소비도 줄이면 서 후속 계층에 유사한 정보를 제공한다. 제2 특징 맵 세트는 하나 이상의 후속 콘볼루션 계층(도시되지 않음)을 통해 추가로 콘볼루션되어 하나 이상의 후속 특징 맵 세트(도시되지 않음)를 생성할 수 있다. 도 2d의 예에서, 제2 특징 맵 세트는 콘볼루션되어 제1 특징 벡터를 생성한다. 또한, 제1 특징 벡터 는 추가로 콘볼루션되어 제2 특징 벡터를 생성한다. 제2 특징 벡터의 각각의 특징은 \"표지판\", \"60\" 및 \"100\"과 같이 이미지의 가능한 특징에 대응하는 숫자를 포함할 수 있다. 소프트맥스 함수(도시되 지 않음)는 제2 특징 벡터의 숫자를 확률로 변환할 수 있다. 이와 같이, DCN의 출력은 이미지 가 하나 이상의 특징을 포함할 확률이다. 본 예에서, \"표지판\" 및 \"60\"에 대한 출력의 확률은 \"30\", \"40\", \"50\", \"70\", \"80\", \"90\" 및 \"100\"과 같 은 출력의 다른 것의 확률보다 높다. 훈련 전에는, DCN에 의해 생성된 출력은 부정확할 가능성 이 높다. 따라서, 출력과 타겟 출력 사이의 오차가 계산될 수 있다. 타겟 출력은 이미지의 실제값 (예를 들어, \"표지판\" 및 \"60\")이다. 그런 다음 DCN의 가중치는 DCN의 출력이 타겟 출력과 더 밀접하게 정렬되도록 조정될 수 있다. 가중치를 조정하기 위해, 학습 알고리즘은 가중치에 대한 기울기 벡터를 계산할 수 있다. 기울기는 가중치가 조정되면 오차가 증가하거나 감소하는 양을 나타낼 수 있다. 최상위 계층에서, 기울기는 끝에서 두 번째 계층 (penultimate layer)의 활성화된 뉴런과 출력 계층의 뉴런을 연결하는 가중치 값에 직접적으로 대응할 수 있다. 하위 계층에서, 기울기는 가중치 값과 상위 계층의 계산된 오차 기울기에 따라 달라질 수 있다. 그런 다음 가 중치를 조정하여 오차를 줄일 수 있다. 가중치를 조정하는 이러한 방식은 신경망을 통한 \"백워드 패스 (backward pass)\"를 포함하므로 \"역전파(back propagation)\"라고 할 수 있다. 실제로, 가중치의 오차 기울기는 소수의 예를 통해 계산될 수 있으므로, 계산된 기울기는 실제 오차 기울기에 근사한다. 이 근사 방법을 확률적 경사하강법(stochastic gradient descent)이라고 할 수 있다. 확률적 경사 하강법은 전체 시스템의 달성 가능한 오차율이 더 이상 감소하지 않을 때까지 또는 오차율이 타겟 레벨에 도달 할 때까지 반복될 수 있다. 학습 후, DCN에는 새로운 이미지가 제시될 수 있으며, 네트워크를 통한 포워드 패 스는 DCN의 추론 또는 예측으로 간주될 수 있는 출력을 산출할 수 있다. 심층 신뢰 신경망(deep belief network; DBN)은 여러 계층의 숨겨진 노드를 포함하는 확률적 모델이다. DBN은 훈련 데이터 세트의 계층적 표현을 추출하는 데 사용될 수 있다. DBN은 RBM(Restricted Boltzmann Machine)의 계층을 적층하여 얻을 수 있다. RBM은 입력 세트에 대한 확률 분포를 학습할 수 있는 일종의 인공 신경망이다. RBM은 각 입력이 분류되어야 하는 클래스에 대한 정보가 없을 때 확률 분포를 학습할 수 있기 때문에, RBM은 비 지도 학습(unsupervised learning)에 종종 사용된다. 하이브리드 비지도 및 지도 패라다임을 사용하여, DBN의 하위 RBM은 비지도 방식으로 훈련되어 특징 추출기 역할을 할 수 있으며, 상위 RBM은 지도 방식(이전 계층과 타 겟 클래스의 입력을 공동 분포에 대한)으로 훈련되어 분류기 역할을 할 수 있다. 심층 콘볼루션 네트워크(DCN)는 추가 풀링 및 정규화 계층으로 구성된 콘볼루션 네트워크의 네트워크이다. DCN 은 많은 태스크에서 최첨단(state-of-the-art) 성능을 달성했다. DCN은 입력 및 출력 타겟 모두 많은 예시에 대해 알려져 있고 경사하강법을 사용하여 네트워크의 가중치를 수정하는 데 사용되는 지도 학습을 사용하여 훈 련될 수 있다. DCN은 피드포워드 네트워크일 수 있다. 또한, 위에서 설명된 바와 같이, DCN의 제1 계층에 있는 뉴런에서 다음 상위 계층의 뉴런 그룹으로의 연결은 제1 계층의 뉴런에 걸쳐 공유된다. 빠른 처리를 위해 DCN의 피드포워드 및 공유 연결이 활용될 수 있다. 예를 들어, DCN의 계산 부담은 순환 연결 또는 피드백 연결을 포함하는 유사 한 크기의 신경망의 계산 부담보다 훨씬 적을 수 있다. 콘볼루션 네트워크의 각 계층 처리는 공간적으로 불변인 템플릿 또는 기본 투영으로 간주될 수 있다. 입력이 먼저 컬러 이미지의 적색, 녹색 및 청색 채널과 같은 다수의 채널로 분해되면, 해당 입력에 대해 훈련된 콘볼루 션 네트워크는 이미지 축을 따라 두 개의 공간 차원과 컬러 정보를 캡처하는 제3 차원을 갖는 3차원으로 간주될 수 있다. 콘볼루션 연결의 출력은 후속 계층에서 특징 맵을 형성하는 것으로 간주될 수 있으며, 특징 맵(예를 들어, 220)의 각 요소는 이전 계층(예를 들어, 특징 맵)의 뉴런 범위로부터 그리고 다수의 채널 각각으로 부터 입력을 수신한다. 특징 맵의 값은 정류(rectification), max(0, x)와 같은 비선형성으로 추가로 처리될 수 있다. 인접한 뉴런의 값은 추가로 풀링될 수 있으며, 이는 다운 샘플링에 해당하며 추가적인 로컬 불변성과 차원 감소를 제공할 수 있다. 화이트닝(whitening)에 해당하는 정규화는 또한 특징 맵의 뉴런 간 측면 억제 (lateral inhibition)를 통해 적용될 수 있다. 더 많은 레이블링된 데이터 포인트를 사용할 수 있게 되거나 계산 능력이 증가함에 따라 딥 러닝 아키텍처의 성 능이 증가할 수 있다. 현대의 심층 신경망은 불과 15년 전 일반적인 연구자가 사용할 수 있었던 것보다 수천 배 더 많은 컴퓨팅 리소스로 일상적으로 훈련된다. 새로운 아키텍처와 훈련 패러다임은 딥 러닝의 성능을 더욱 향상시킬 수 있다. 정류된 선형 유닛은 기울기 소실(vanishing gradient)로 알려진 훈련 문제를 줄일 수 있다. 새로운 훈련 기술은 과적합(over-fitting)을 줄여 더 큰 모델이 더 나은 일반화를 달성할 수 있도록 할 수 있다. 캡슐화 기술은 주어진 수용 필드에서 데이터를 추상화하고 전반적인 성능을 더욱 향상시킬 수 있다. 도 3은 심층 콘볼루션 네트워크를 예시하는 블록도이다. 심층 콘볼루셔널 네트워크는 연결성 및 가 중치 공유에 기초한 다수의 다른 유형의 계층을 포함할 수 있다. 도 3에 도시된 바와 같이, 심층 콘볼루션 네 트워크는 콘볼루션 블록(354A, 354B)을 포함한다. 콘볼루션 블록(354A, 354B) 각각은 콘볼루션 계층 (CONV), 정규화 계층(LNorm) 및 최대 풀링 계층(MAX POOL)으로 구성될 수 있다. 콘볼루션 계층은 특징 맵을 생성하기 위해 입력 데이터에 적용될 수 있는 하나 이상의 콘볼루션 필터를 포 함할 수 있다. 비록 2개의 콘볼루션 블록(354A, 354B) 만이 도시되어 있지만, 본 개시는 이에 제한적이지 않으 며, 대신, 설계 선호도에 따라 임의 개수의 콘볼루션 블록(354A, 354B)이 심층 콘볼루션 네트워크에 포함 될 수 있다. 정규화 계층은 콘볼루션 필터의 출력을 정규화할 수 있다. 예를 들어, 정규화 계층은 화이트닝 또는 측면 억제를 제공할 수 있다. 최대 풀링 계층은 로컬 불변성 및 차원 감소를 위해 공간에 대한 다운 샘플링 집계를 제공할 수 있다. 예를 들어, 심층 콘볼루션 네트워크의 병렬 필터 뱅크는 고성능 및 저전력 소비를 달성하기 위해 SOC의 CPU 또는 GPU에 로드될 수 있다. 대안적인 실시예에서, 병렬 필터 뱅크는 SOC의 DSP 또 는 ISP에 로드될 수 있다. 추가로, 심층 콘볼루션 네트워크는 센서 및 내비게이션에 각각 전용인 센 서 프로세서 및 내비게이션 모듈과 같은 SOC에 존재할 수 있는 다른 처리 블록에 액세스할 수 있다. 심층 콘볼루션 네트워크는 또한 하나 이상의 완전 연결식 계층(FC1 및 FC2)을 포함할 수 있다. 심층 콘볼루션 네트워크는 로지스틱 회귀(logistic regression; LR) 계층을 더 포함할 수 있다. 심층 콘 볼루션 네트워크의 각 계층(356, 358, 360, 362, 364) 사이에는 업데이트될 가중치(도시되지 않음)가 있다. 계층(예를 들어, 356, 358, 360, 362, 364) 각각의 출력은 콘볼루션 블록(354A) 중 제1 블록에 공급된 입력 데이터(예를 들어, 이미지, 오디오, 비디오, 센서 데이터 및/또는 기타 입력 데이터)로부터 계층적 특징 표현을 학습하기 위해 심층 콘볼루션 네트워크 내 계층(예를 들어, 356, 358, 360, 362, 364)의 연속 되는 계층의 입력 역할을 할 수 있다. 심층 콘볼루션 네트워크의 출력은 입력 데이터에 대한 분류 점수이다. 분류 점수는 확률 세트일 수 있으며, 여기서 각각의 확률은 특징 세트로부터의 특징을 포 함하는 입력 데이터의 확률이다. 도 4는 인공 지능(artificial intelligence; AI) 기능을 모듈화할 수 있는 예시적인 소프트웨어 아키텍처(40 0)를 예시하는 블록도이다. 아키텍처를 사용하여, 본 개시의 양태에 따르면, SOC(예를 들어, CPU, DSP, GPU 및/또는 NPU)의 다양한 처리 블록이 AI 애플리케이션에 대한 사후 훈련(post- training) 양자화에 대해 개시된 적응형 라운딩(adaptive rounding)을 지원하도록 할 수 있는 애플리케이션이 설계될 수 있다. AI 애플리케이션은 예를 들어 디바이스가 현재 동작하는 위치를 나타내는 장면의 검출 및 인식을 제공할 수 있는 사용자 공간에 정의된 기능을 호출하도록 구성될 수 있다. AI 애플리케이션은 예를 들어, 인식된 장면이 사무실인지, 강의실인지, 레스토랑인지, 또는 호수와 같은 야외 환경인지에 따라 마이크 및 카메 라를 다르게 구성할 수 있다. AI 애플리케이션은 AI 기능 애플리케이션 프로그래밍 인터페이스 (application programming interface; API)에 정의된 라이브러리와 연관된 컴파일된 프로그램 코드에 요 청할 수 있다. 이 요청은 궁극적으로 예를 들어 비디오 및 포지셔닝 데이터를 기반으로 추론 응답을 제공하도 록 구성된 심층 신경망의 출력에 의존할 수 있다. 런타임 프레임워크의 컴파일된 코드일 수 있는 런타임 엔진은 AI 애플리케이션에 추가로 액세스할 수 있다. AI 애플리케이션은 예를 들어 런타임 엔진이 특정 시간 간격으로 추론을 요청하거나 애플리케이션 의 사용자 인터페이스에 의해 검출된 이벤트에 의해 트리거되도록 할 수 있다. 추론 응답을 제공하게 될 때, 런타임 엔진은 차례로 SOC에서 실행되는 커널과 같은 운영 체제(OS) 공간의 운영 체제에 신호를 보낼 수 있다. 운영 체제는 차례로 CPU, DSP, GPU, NPU 또는 이들의 일부 조합에서 양자 화의 지속적인 완화가 수행되도록 할 수 있다. CPU는 운영 체제에 의해 직접 액세스될 수 있고, 다른 처 리 블록은 각각 DSP, GPU 또는 NPU에 대한 드라이버(414, 416 또는 418)와 같은 드라이버를 통 해 액세스될 수 있다. 예시적인 예에서, 심층 신경망은 CPU, DSP 및 GPU와 같은 처리 블록의 조합에서 실행되도록 구성되거나, NPU에서 실행될 수 있다. 애플리케이션(예를 들어, AI 애플리케이션)은 예를 들어 디바이스가 현재 동작하는 위치를 나타내는 장면 의 검출 및 인식을 제공할 수 있는 사용자 공간에 정의된 기능을 호출하도록 구성될 수 있다. 애플리케이 션은 예를 들어, 인식된 장면이 사무실인지, 강의실인지, 레스토랑인지, 또는 호수와 같은 야외 환경인지 에 따라 마이크 및 카메라를 다르게 구성할 수 있다. 애플리케이션은 장면 검출(SceneDetect) 애플리케이 션 프로그래밍 인터페이스(API)에 정의된 라이브러리와 연관된 컴파일된 프로그램 코드에 요청할 수 있다. 이 요청은 궁극적으로 예를 들어 비디오 및 포지셔닝 데이터를 기반으로 장면 추정을 제공하도록 구성된 서로 다른 신경망의 출력에 의존할 수 있다. 런타임 프레임워크의 컴파일된 코드일 수 있는 런타임 엔진은 애플리케이션에 추가로 액세스할 수 있 다. 애플리케이션은 예를 들어 런타임 엔진이 특정 시간 간격으로 장면 추정을 요청하거나 애플리케이션 의 사용자 인터페이스에 의해 검출된 이벤트에 의해 트리거되도록 할 수 있다. 장면을 추정하도록 발생 시, 런 타임 엔진은 차례로 SOC에서 실행되는 커널과 같은 운영 체제에 신호를 보낼 수 있다. 운영 체 제는 차례로 CPU, DSP, GPU, NPU 또는 이들의 일부 조합에서 계산이 수행되도록 할 수 있다. CPU는 운영 체제에 의해 직접 액세스될 수 있고, 다른 처리 블록은 DSP, GPU 또는 NPU에 대한 드라이버(414 내지 418)와 같은 드라이버를 통해 액세스될 수 있다. 예시적인 예에서, 차동 신경망은 CPU 및 GPU와 같은 처리 블록의 조합에서 실행되도록 구성되거나, NPU에서 실행될 수 있다. 설명된 바와 같이, 본 개시의 양태는 비디오의 온-디바이스 쿼리 및 검색에 관한 것이다. 인공 신경망은 사용 자의 검색어와 비디오의 자막 정보를 처리하고, 검색된 콘텐트가 포함될 가능성이 가장 높은 비디오 부분을 나 타내는 예측을 생성할 수 있다. 일부 양태에서, 인공 신경망은 검색어와 일치하거나 검색된 콘텐트를 포함할 가능성이 있는 이벤트에 대한 N개의 예측 목록을 생성할 수 있으며(예를 들어, 검색어가 여러 번 발생하는 이벤 트를 설명하는 경우), 여기서 N은 정수이다. 일부 양태에서, 예측은 검색된 콘텐트를 포함하는 부분을 식별하기 위한 시작 시간 및 종료 시간을 포함할 수 있다. 예측된 부분은 비디오 또는 미디어 플레이어에서 텍스트 또는 타임스탬프(예를 들어, 타임라인 위치)로 디스플레이될 수 있다. 결과적으로, 사용자는 검색된 콘텐트를 재생하기 위해 예측된 부분으로 더 쉽게 탐색할 수 있거나, 일부 양태에서는, 모바일 디바이스가 예측된 부분을 자동으로 재생할 수 있다. 처리 및 예측은 온- 디바이스에서 수행될 수 있다. 온-디바이스는 클라우드나 원격 컴퓨팅의 도움 없이 모바일 디바이스의 리소스 를 사용하여 처리하고 예측하는 것을 의미할 수 있다. 도 5는 본 개시의 양태에 따른 비디오의 온-디바이스 쿼리 및 검색을 위한 예시적인 프로세스를 예시하는 하이 레벨 블록도이다. 도 5를 참조하면, 블록에서, 프로세스는 모바일 디바이스를 통해 검색어 및 비디오를 수신할 수 있다. 검색어에는 예를 들어 비디오 내 장면이나 이벤트에 대한 설명이 포함될 수 있다. 블록에서, 비디오와 관련된 검색어 및 자막 정보가 처리될 수 있다. 인공 신경망(예를 들어, 도 3의 35 0)은 검색어 및 자막 정보를 처리할 수 있다. 자막 정보에는 비디오 내 장면이나 동작에 대한 설명이 포함될 수 있다. 자막 정보는 프레임 단위로 단락 형태로 제공될 수 있다. ANN은 검색어의 특징과 자막 정보를 결정 할 수 있다. 일부 양태에서, ANN은 검색어의 두드러진 부분을 결정하고 특징을 매칭하기 위해 비디오와 연관된 자막 정보를 검색할 수 있다. 블록에서, ANN은 검색어에 응답하여 주제 재료를 포함하는 비디오의 일부에 대한 예측을 생성할 수 있다. 예측에는 검색어에 설명된 장면이나 이벤트를 포함할 가능성이 가장 높은 프레임 세트가 포함될 수 있다. 일부 양태에서, 예측에는 검색어에 설명된 장면이나 이벤트가 포함될 가능성이 가장 높은 비디오 부분에 대한 시작 시간과 종료 시간이 포함될 수 있다. 블록에서, 비디오의 예측된 부분은 (예를 들어, 도 1의 멀티미디어 프로세서를 통해) 모바일 디바이 스의 디스플레이에 디스플레이될 수 있다. 도 6a는 본 개시의 양태에 따른 비디오의 쿼리 및 검색을 위한 예시적인 아키텍처를 예시하는 블록도이다. 도 6a를 참조하면, 아키텍처는 입력 디바이스를 포함할 수 있다. 입력 디바이스는 모바일 디바 이스의 마이크로폰(예를 들어, 도 1의 센서), 멀티미디어 디바이스(예를 들어, 도 1의 멀티미디어 프로세 서), 또는 텍스트 입력을 수신하는 입/출력 디바이스를 포함할 수 있다. 일부 양태에서, 입력 디바이스 는 음성 신호 또는 다른 센서 입력을 텍스트 입력으로 변환하도록 구성될 수 있다. 입력 디바이스는 사용자로부터 검색어를 수신할 수 있다. 검색어는 영화에 포함된 장면이나 이벤트에 대한 설명일 수 있다. 검 색어는 단어, 구, 또는 문장의 형태일 수 있다. 아키텍처는 또한 비디오 입력을 수신할 수 있다. 비디오 입력은 예를 들어 영화일 수 있다. 비디오 입력은 스토리지 또는 스트리밍 미디어 소스로부터 수신될 수 있다. 비디오 입력은 프레임의 시간적 시퀀스를 포함할 수 있다. 일부 양태에서, 비디오 입력은 연관된 폐쇄 캡셔닝(closed captioning; CC) 정보 또는 자막 정보를 포함할 수 있다. 자막 정보라고도 할 수 있는 폐쇄 캡셔닝 정보는 비디오 프레임에 디스플레이된 캐릭터 간의 영화 내 대화에 대한 시간별 대본을 포함할 수 있다. 일부 양태에서, 자막 생성기 는 선택적으로는 온-디바이스에 포함될 수 있으며, 예를 들어 이러한 정보가 비디오 입력에 포함되지 않은 경우 비디오 입력의 프레임에 대한 자막 정보를 생성하는 데 사용될 수 있다. 자막 정보는 예를 들 어, 문장이나 단락의 형태일 수 있다. 비디오에 대한 검색어 및 자막 정보는 온-디바이스 신경망에 공급될 수 있다. 온-디바이스 신경망은 예를 들어 트랜스포머 신경망일 수 있다. 트랜스포머 신경망은 셀프 어텐션(self-attention)을 사용하고 입력 시퀀스 내의 모든 위치에 대한 컨텍스트 정보를 제공하는 딥 러닝 모델이다. 일부 양태에서, 온-디바이스 신경 망은 ELECTRA(efficiently learning encoder that classifies token replacements accurately) 소형 모 델일 수 있다. 물론, 이는 단지 예일 뿐이며, 트랜스포머(BERT)의 양방향 인코더 표현, 견고하게 최적화된 BERT 접근 방식(RoBERTa), XLNet, 트랜스포머-XL 및 GPT(generative pre-trained transformer) 계열과 같은 다 른 아키텍처도 사용될 수 있다. ELECTRA 소형 모델은 NLP(natural language processor)에 대한 질문 답변이다. ELECTRA 소형 모델은 쿼리 및 입력 단락이 주어지면 답변을 예측하도록 사전 훈련될 수 있다. 온-디바이스 신경망은 검색어의 단어 표현과 자막 정보의 단어 표현을 생성할 수 있다. 단어 표현 각각에 는 검색어 내의 단어 각각에 기초한 컨텍스트 정보 및 자막 정보가 각각 포함될 수 있다. 온-디바이스 신경망 은 생성된 단어 표현에 기초하여 검색어와 자막 정보 사이의 상관 관계를 결정할 수 있다. 차례로, 온-디 바이스 신경망은 상관 관계에 기초하여 검색어에 응답하는 콘텐트를 포함하는 비디오 입력의 일부에 대한 예측을 생성할 수 있다. 예측은 검색된 콘텐트를 포함할 가능성이 가장 높은 비디오 부분을 나 타낼 수 있다. 일부 양태에서, 예측은 이러한 콘텐트를 포함하는 하나 이상의 프레임을 나타낼 수 있다. 예를 들어, 도 6a의 예에 도시된 바와 같이, 온-디바이스 신경망은 3개의 후보 부분을 생성할 수 있으며, 각각은 검색어를 충족할 수 있는 자막 정보를 포함한다. 일부 양태에서, 예측에는 또한 검색어에 응답하 는 콘텐트를 포함하는 비디오 입력의 부분 또는 세그먼트에 대한 시작 시간과 종료 시간이 포함될 수 있다. 재생 디바이스는 시작 시간 및 종료 시간에 의해 표시된 비디오 입력의 예측된 부분(들)의 목록을 디 스플레이할 수 있다. 또한, 일부 양태에서, 재생 디바이스는 식별된 시작 시간으로 탐색(예를 들어, 패스트 포 워드(fast-forward))하고 식별된 종료 시간까지 비디오 입력의 예측된 부분의 재생을 시작할 수 있다. 도 6b는 본 개시의 양태에 따른 예시적인 온-디바이스 신경망을 예시하는 블록도이다. 도 6b를 참조하면, 온-디바이스 신경망은 검색 생성기 네트워크 및 판별기 네트워크를 포함할 수 있다. 검색 생성 기 네트워크 및 판별기 네트워크는 각각 예를 들어 트랜스포머 네트워크로 구성될 수 있다. 검색 생 성기 네트워크는 검색어를 입력으로서 수신할 수 있고 검색어를 컨텍스트 벡터 표현(hSQ)에 매핑할 수 있다. 컨텍스트 벡터 표현(hSQ)은 검색어 내의 중요한 단어(예를 들어, 명사, 동사)에 초점을 맞출 수 있다. 컨텍스트 벡터 표현(hSQ)은 판별기 네트워크에 공급될 수 있다. 판별기 네트워크는 자막 정보를 제1 입력으로 수신할 수 있다. 판별기 네트워크는 비디오 입력(60 4)의 각 프레임과 연관된 자막 정보를 컨텍스트 벡터 표현(hSI)에 매핑할 수 있다. 일부 양태에서, 판별기 네트 워크는 자막 정보 내의 중요한 단어에 초점을 맞추도록 컨텍스트 벡터 표현(hSI)을 생성할 수 있다. 판별기 네트워크는 또한 컨텍스트 벡터 표현(hSQ)을 수신할 수 있다. 판별기 네트워크는 컨텍스트 벡 터 표현(hSQ)을 컨텍스트 벡터 표현(hSI)과 비교하여 컨텍스트 벡터 표현(hSQ)과 컨텍스트 벡터 표현(hSI) 사이의 상관 관계를 결정할 수 있다. 즉, 판별기 네트워크는 자막 정보에 포함된 단어와 데이터의 단어(예를 들 어, 검색어에서만)를 구별하도록 훈련될 수 있다. 컨텍스트 벡터 표현(hSQ)과 컨텍스트 벡터 표현(hSI) 사이의 상관 관계에 기초하여, 판별기 네트워크는 검색어가 자막 정보와 일치하는지, 이에 따라 비디오 입력(60 4)의 대응 부분이 검색어를 충족하는 콘텐트를 포함하는지 여부에 대한 예측(예를 들어, 608)을 생성할 수 있다. 도 7은 본 개시의 양태에 따른 인공 신경망(ANN)을 사용한 비디오의 쿼리 및 검색을 위한 예시적인 프로세스 를 예시하는 흐름도이다. 도 7에 도시된 바와 같이, 블록에서, 프로세스는, ANN에 의해, 비디 오 및 검색어를 수신하며, 비디오는 프레임 시퀀스 및 관련 자막 정보를 포함한다. 에를 들어, 도 6a를 참조하 여 설명된 바와 같이, 입력 디바이스는 사용자로부터 검색어를 수신할 수 있다. 검색어는 영화에 포함된 장면이나 이벤트에 대한 설명일 수 있다. 검색어는 단어, 구, 또는 문장의 형태일 수 있다. 아키텍처는 또한 비디오 입력을 수신할 수 있다. 비디오 입력은 예를 들어 영화일 수 있다. 비디오 입력 은 스토리지 또는 스트리밍 미디어 소스로부터 수신될 수 있다. 비디오 입력은 프레임의 시간적 시퀀스를 포함할 수 있다. 일부 양태에서, 비디오 입력은 연관된 폐쇄 캡셔닝(CC) 정보 또는 자막 정보를 포함할 수 있다. 자막 정보라고도 할 수 있는 폐쇄 캡셔닝 정보는 비디오 프레임에 디스플레이된 캐릭터 간의 영화 내 대화에 대한 시간별 대본을 포함할 수 있다. 블록에서, 프로세스는, 모바일 디바이스에서, ANN에 의해, 검색어의 제1 단어 세트에 대한 제1 표현 및 자막 정보의 제2 단어 세트에 대한 제2 표현을 생성한다. 도 6b에 참조하여 설명된 바와 같이, 검색 생성기 네트워크는 검색어를 입력으로서 수신할 수 있고 검색어를 컨텍스트 벡터 표현(hSQ)에 매핑할 수 있다. 컨 텍스트 벡터 표현(hSQ)은 검색어 내의 중요한 단어(예를 들어, 명사, 동사)에 초점을 맞출 수 있다. 마찬가지로, 판별기 네트워크는 자막 정보를 수신할 수 있다. 판별기 네트워크는 비디오 입력 의 각 프레임과 연관된 자막 정보를 컨텍스트 벡터 표현(hSI)에 매핑할 수 있다. 블록에서, 프로세스는, 모바일 디바이스에서, ANN에 의해, 제1 표현과 제2 표현에 기초한 상관 관계 를 결정한다. 예를 들어, 도 6b를 참조하여 설명된 바와 같이, 판별기 네트워크는 컨텍스트 벡터 표현 (hSQ)을 컨텍스트 벡터 표현(hSI)과 비교하여 컨텍스트 벡터 표현(hSQ)과 컨텍스트 벡터 표현(hSI) 사이의 상관 관 계를 결정할 수 있다. 즉, 판별기 네트워크는 자막 정보에 포함된 단어와 데이터의 단어(예를 들어, 검색 어에서만)를 구별하도록 훈련될 수 있다. 추가로, 상관 관계는 검색어의 단어에 대한 컨텍스트와 자막 정보의 단어에 대한 컨텍스트의 대응성에 기초할 수 있다. 블록에서, 프로세스는, 모바일 디바이스에서, ANN에 의해, 상관 관계에 기초하여 검색어에 응답하는 콘텐트를 포함하는 비디오의 일부를 예측한다. 예를 들어, 도 6b를 참조하여 설명된 바와 같이, 컨텍스트 벡터 표현(hSQ)과 컨텍스트 벡터 표현(hSI) 사이의 상관 관계에 기초하여, 판별기 네트워크는 검색어가 자막 정 보와 일치하는지, 이에 따라 비디오 입력의 대응 부분이 검색어를 충족하는 콘텐트를 포함하는지 여부에대한 예측(예를 들어, 608)을 생성할 수 있다. 예측은 검색된 콘텐트를 포함할 가능성이 가장 높은 비디 오 부분을 나타낼 수 있다. 일부 양태에서, 예측은 이러한 콘텐트를 포함하는 하나 이상의 프레임을 나타 낼 수 있다. 일부 양태에서, 예측에는 또한 검색어에 응답하는 콘텐트를 포함하는 비디오 입력의 부 분 또는 세그먼트에 대한 시작 시간과 종료 시간이 포함될 수 있다. 구현 예는 아래의 번호가 매겨진 조항에 포함되어 있다: 1. 인공 신경망(ANN)을 사용하여 모바일 디바이스에서 비디오를 검색하기 위한 컴퓨터 구현 방법으로서, ANN에 의해, 비디오 및 검색어를 수신하는 단계 - 비디오는 프레임 시퀀스 및 관련 자막 정보를 포함함 -; 모바일 디바이스에서, ANN에 의해, 검색어의 제1 단어 세트에 대한 제1 표현 및 자막 정보의 제2 단어 세트에 대한 제2 표현을 생성하는 단계; 모바일 디바이스에서, ANN에 의해, 제1 표현 및 제2 표현에 기초하여 상관 관계를 결정하는 단계; 및 모바일 디바이스에서, ANN에 의해, 상관 관계에 기초하여 검색어에 응답하는 콘텐트를 포함하는 비디오의 일부 를 예측하는 단계를 포함한다. 2. 조항 1의 컴퓨터 구현 방법에 있어서, 예측하는 단계는 검색어에 응답하는 콘텐트를 포함하는 비디오의 일부 에 대한 시작 시간 및 종료 시간을 추가로 나타낸다. 3. 조항 1 또는 2의 컴퓨터 구현 방법에 있어서, 시작 시간에 포함된 비디오의 일부를 종료 시간까지 디스플레 이하는 단계를 더 포함한다. 4. 조항 1 내지 3 중 어느 하나의 컴퓨터 구현 방법에 있어서, ANN은 트랜스포머 신경망을 포함한다. 5. 조항 1 내지 4 중 어느 하나의 컴퓨터 구현 방법에 있어서, 비디오에 포함된 폐쇄 캡셔닝 정보에 기초하여 관련 자막 정보를 생성하는 단계를 더 포함한다. 6. 조항 1 내지 5 중 어느 하나의 컴퓨터 구현 방법에 있어서, 검색어는 장면, 이벤트, 단어 또는 구에 대한 설 명 중 하나 이상을 포함한다. 7. 조항 1 내지 6 중 어느 하나의 컴퓨터 구현 방법에 있어서, 검색어는 모바일 디바이스의 음성 입력 텍스트 입력을 통해 공급된다. 8. 인공 신경망(ANN)을 사용하여 모바일 디바이스에서 비디오를 검색하기 위한 장치로서, 메모리; 및 메모리에 결합된 적어도 하나의 프로세서를 포함하며, 적어도 하나의 프로세서는, ANN에 의해, 비디오 및 검색어를 수신하고 - 비디오는 프레임 시퀀스 및 관련 자막 정보를 포함함 -; 모바일 디바이스에서, ANN에 의해, 검색어의 제1 단어 세트에 대한 제1 표현 및 자막 정보의 제2 단어 세트에 대한 제2 표현을 생성하고; 모바일 디바이스에서, ANN에 의해, 제1 표현 및 제2 표현에 기초하여 상관 관계를 결정하고; 모바일 디바이스에서, ANN에 의해, 상관 관계에 기초하여 검색어에 응답하는 콘텐트를 포함하는 비디오의 일부 를 예측하도록 구성된다. 9. 조항 8의 장치에 있어서, 적어도 하나의 프로세서는 검색어에 응답하는 콘텐트를 포함하는 비디오의 일부에 대한 시작 시간 및 종료 시간을 나타내는 예측을 생성하도록 추가로 구성된다. 10. 조항 8 또는 9의 장치에 있어서, 적어도 하나의 프로세서는 시작 시간에 포함된 비디오의 일부를 종료 시간 까지 디스플레이하도록 추가로 구성된다. 11. 조항 8 내지 10 중 어느 하나의 장치에 있어서, ANN은 트랜스포머 신경망을 포함한다. 12. 조항 8 내지 11 중 어느 하나의 장치에 있어서, 적어도 하나의 프로세서는 비디오에 포함된 폐쇄 캡셔닝 정 보에 기초하여 관련 자막 정보를 생성하도록 추가로 구성된다. 13. 조항 8 내지 12 중 어느 하나의 장치에 있어서, 검색어는 장면, 이벤트, 단어 또는 구에 대한 설명 중 하나 이상을 포함한다. 14. 조항 8 내지 13 중 어느 하나의 장치에 있어서, 검색어는 모바일 디바이스의 음성 입력 텍스트 입력을 통해 공급된다. 15. 비일시적 컴퓨터 판독 가능 저장 매체에 기록된 인공 신경망(ANN)을 사용하여 모바일 디바이스에서 비디오 를 검색하기 위한 프로그램 코드를 갖는 상기 비일시적 컴퓨터 판독 가능 저장 매체로서, 프로그램 코드는 프로 세서에 의해 실행되고, ANN에 의해, 비디오 및 검색어를 수신하기 위한 프로그램 코드 - 비디오는 프레임 시퀀스 및 관련 자막 정보를 포함함 -; 모바일 디바이스에서, ANN에 의해, 검색어의 제1 단어 세트에 대한 제1 표현 및 자막 정보의 제2 단어 세트에 대한 제2 표현을 생성하기 위한 프로그램 코드; 모바일 디바이스에서, ANN에 의해, 제1 표현 및 제2 표현에 기초하여 상관 관계를 결정하기 위한 프로그램 코드; 및 모바일 디바이스에서, ANN에 의해, 상관 관계에 기초하여 검색어에 응답하는 콘텐트를 포함하는 비디오의 일부 를 예측하기 위한 프로그램 코드를 포함한다. 16. 조항 15의 비일시적 컴퓨터 판독 가능 저장 매체에 있어서, 프로그램 코드는 검색어에 응답하는 콘텐트를 포함하는 비디오의 일부에 대한 시작 시간 및 종료 시간을 나타내는 예측을 생성하기 위한 프로그램 코드를 더 포함한다. 17. 조항 15 또는 16의 비일시적 컴퓨터 판독 가능 저장 매체에 있어서, 프로그램 코드는 시작 시간에 포함된 비디오의 일부를 종료 시간까지 디스플레이하기 위한 프로그램 코드를 더 포함한다. 18. 조항 15 내지 17 중 어느 하나의 비일시적 컴퓨터 판독 가능 저장 매체에 있어서, ANN은 트랜스포머 신경망 을 포함한다. 19. 조항 15 내지 18 중 어느 하나의 비일시적 컴퓨터 판독 가능 저장 매체에 있어서, 프로그램 코드는 비디오 에 포함된 폐쇄 캡셔닝 정보에 기초하여 관련 자막 정보를 생성하기 위한 프로그램 코드를 더 포함한다. 20. 조항 15 내지 19 중 어느 하나의 비일시적 컴퓨터 판독 가능 저장 매체에 있어서, 검색어는 장면, 이벤트, 단어 또는 구에 대한 설명 중 하나 이상을 포함한다. 21. 조항 15 내지 20 중 어느 하나의 비일시적 컴퓨터 판독 가능 저장 매체에 있어서, 검색어는 모바일 디바이 스의 음성 입력 텍스트 입력을 통해 공급된다. 22. 인공 신경망(ANN)을 사용하여 모바일 디바이스에서 비디오를 검색하기 위한 장치로서, ANN에 의해, 비디오 및 검색어를 수신하기 위한 수단 - 비디오는 프레임 시퀀스 및 관련 자막 정보를 포함함 -; 모바일 디바이스에서, ANN에 의해, 검색어의 제1 단어 세트에 대한 제1 표현 및 자막 정보의 제2 단어 세트에 대한 제2 표현을 생성하기 위한 수단; 모바일 디바이스에서, ANN에 의해, 제1 표현 및 제2 표현에 기초하여 상관 관계를 결정하기 위한 수단; 및 모바일 디바이스에서, ANN에 의해, 상관 관계에 기초하여 검색어에 응답하는 콘텐트를 포함하는 비디오의 일부 를 예측하기 위한 수단을 포함한다. 23. 조항 22의 장치에 있어서, 검색어에 응답하는 콘텐트를 포함하는 비디오의 일부에 대한 시작 시간 및 종료 시간을 나타내는 예측을 생성하기 위한 수단을 더 포함한다. 24. 조항 22 또는 23의 장치에 있어서, 시작 시간에 포함된 비디오의 일부를 종료 시간까지 디스플레이하기 위 한 수단을 더 포함한다. 25. 조항 22 내지 24 중 어느 하나의 장치에 있어서, ANN은 트랜스포머 신경망을 포함한다. 26. 조항 22 내지 25 중 어느 하나의 장치에 있어서, 비디오에 포함된 폐쇄 캡셔닝 정보에 기초하여 관련 자막 정보를 생성하기 위한 수단을 더 포함한다. 27. 조항 22 내지 26 중 어느 하나의 장치에 있어서, 검색어는 장면, 이벤트, 단어 또는 구에 대한 설명 중 하 나 이상을 포함한다. 28. 조항 22 내지 27 중 어느 하나의 장치에 있어서, 검색어는 모바일 디바이스의 음성 입력 텍스트 입력을 통 해 공급된다. 일 양태에서, 수신 수단, 생성 수단, 결정 수단, 예측 및/또는 디스플레이 수단은 인용된 기능을 수행하도록 구 성된 CPU, CPU와 관련된 프로그램 메모리, 전용 메모리 블록, 완전 연결식 계층, NPU/ 및/또는 라우팅 연결 처리 유닛일 수 있다. 또 다른 구성에서, 전술된 수단은 전술된 수단에 의해 인용된 기능을 수행하도록 구성된 임의의 모듈 또는 임의의 장치일 수 있다. 위에서 설명된 방법의 다양한 동작은 해당 기능을 수행할 수 있는 임의의 적절한 수단에 의해 수행될 수 있다. 수단은 이에 제한되는 것은 아니나, 회로, 주문형 집적 회로(application specific integrated circuit; ASIC) 또는 프로세서를 포함하는, 다양한 하드웨어 및/또는 소프트웨어 컴포넌트(들) 및/또는 모듈(들)을 포함할 수 있다. 일반적으로, 도면에 예시된 동작이 있는 경우, 이러한 동작에는 유사한 번호가 부여된 해당 대응 기능식 (means-plus-function) 컴포넌트가 있을 수 있다. 본원에 사용된 바와 같이, \"결정\"이라는 용어는 다양한 행동을 포함한다. 예를 들어, \"결정\"은 계산, 컴퓨팅, 처리, 유도, 조사, 검색(예를 들어, 테이블, 데이터베이스 또는 또 다른 데이터 구조에서 검색), 확인 등을 포 함할 수 있다. 추가로, \"결정\"은 수신(예를 들어, 정보 수신), 액세스(예를 들어, 메모리 내의 데이터에 액세 스) 등을 포함할 수 있다. 또한, \"결정\"은 해결, 선택, 선택, 확립 등을 포함할 수 있다. 본원에 사용된 바와 같이, 항목의 목록의 \"적어도 하나\"를 나타내는 문구는 단일 구성원을 포함하여 해당 항목 의 모든 조합을 나타낸다. 일 예로서, \"a, b 또는 c 중 적어도 하나\"는 a, b, c, a-b, a-c, b-c 및 a-b-c를 포괄하도록 의도된다. 본 개시와 관련하여 설명된 다양한 예시적인 로직 블록, 모듈 및 회로는 본원에 설명된 기능을 수행하도록 설계 된 범용 프로세서, 디지털 신호 프로세서(digital signal processor; DSP), 주문형 집적 회로(ASIC), 필드 프 로그래머블 게이트 어레이 신호 (field programmable gate array; FPGA) 또는 기타 프로그래머블 로직 디바이 스(programmable logic device; PLD), 이산 게이트 또는 트랜지스터 로직, 이산 하드웨어 컴포넌트들 또는 이들 의 임의의 조합으로 구현 또는 수행될 수 있다. 범용 프로세서는 마이크로프로세서일 수 있지만, 대안으로, 프 로세서는 임의의 상업적으로 이용 가능한 프로세서, 컨트롤러, 마이크로컨트롤러 또는 상태 머신일 수 있다. 프로세서는 또한 컴퓨팅 장치의 조합(예를 들어, DSP와 마이크로프로세서의 조합, 복수의 마이크로프로세서, DSP 코어와 결합된 하나 이상의 마이크로프로세서, 또는 임의의 이러한 다른 구성)으로 구현될 수 있다. 본 개시와 관련하여 설명된 방법 또는 알고리즘 단계는 하드웨어, 프로세서에 의해 실행되는 소프트웨어 모듈, 또는 이 둘의 조합으로 직접 구현될 수 있다. 소프트웨어 모듈은 해당 기술 분야에 알려진 임의 형태의 저장 매체에 상주할 수 있다. 사용될 수 있는 저장 매체의 일부 예에는 RAM(random access memory), ROM(read only memory), 플래시 메모리, EPROM(erasable programmable read-only memory), EEPROM(electrically erasable programmable read-only memory), 레지스터, 하드 디스크, 이동식 디스크, CD-ROM 등이 포함된다. 소프트웨어 모듈은 단일 명령어 또는 많은 명령어를 포함할 수 있으며, 여러 개의 서로 다른 코드 세그먼트에 걸쳐, 서로 다른 프로그램 중에서 그리고 여러 저장 매체에 걸쳐 분산될 수 있다. 저장 매체는 프로세서가 저장 매체로부 터 정보를 판독하고 저장 매체에 정보를 기록할 수 있도록 프로세서에 결합될 수 있다. 대안적으로, 저장 매체 는 프로세서에 통합될 수 있다. 본원에 개시된 방법은 설명된 방법을 달성하기 위한 하나 이상의 단계 또는 동작을 포함한다. 방법 단계 및/또 는 동작은 청구항의 범위를 벗어나지 않고 서로 상호 교환될 수 있다. 즉, 단계나 동작의 특정 순서가 지정되 지 않는 한, 청구항의 범위를 벗어나지 않고 특정 단계 및/또는 동작의 순서 및/또는 사용이 수정될 수 있다. 설명된 기능은 하드웨어, 소프트웨어, 펌웨어, 또는 이들의 임의의 조합으로 구현될 수 있다. 하드웨어로 구현 되는 경우, 예시적인 하드웨어 구성은 디바이스의 처리 시스템을 포함할 수 있다. 처리 시스템은 버스 아키텍 처로 구현될 수 있다. 버스에는 처리 시스템의 특정 애플리케이션과 전체 설계 제약 조건에 따라 임의 개수의 상호 연결 버스와 브리지가 포함될 수 있다. 버스는 프로세서, 기계 판독 가능 매체 및 버스 인터페이스를 포 함한 다양한 회로를 함께 링크할 수 있다. 버스 인터페이스는 무엇보다도 네트워크 어댑터를 버스를 통해 처리 시스템에 연결하는 데 사용될 수 있다. 네트워크 어댑터는 신호 처리 기능을 구현하는 데 사용될 수 있다. 특 정 양태의 경우, 사용자 인터페이스(예를 들어, 키패드, 디스플레이, 마우스, 조이스틱 등)도 버스에 연결될 수 있다. 버스는 또한 타이밍 소스, 주변 장치, 전압 조정기, 전력 관리 회로 등과 같은 다양한 기타 회로를 링크할 수 있으며, 이는 해당 기술 분야에 잘 알려져 있으므로 더 이상 설명되지 않을 것이다. 프로세서는 기계 판독 가능 매체에 저장된 소프트웨어 실행을 포함하여 버스 및 일반 처리를 관리하는 것을 책 임질 수 있다. 프로세서는 하나 이상의 범용 및/또는 특수 목적 프로세서로 구현될 수 있다. 예에는 마이크로 프로세서, 마이크로컨트롤러, DSP 프로세서 및 소프트웨어를 실행할 수 있는 기타 회로부가 포함된다. 소프트 웨어는 소프트웨어, 펌웨어, 미들웨어, 마이크로코드, 하드웨어 설명 언어 등으로 지칭되든 명령어, 데이터 또 는 임의의 이들의 조합을 의미하는 것으로 광범위하게 해석되어야 한다. 기계 판독 가능 매체에는 예를 들어 RAM(random access memory), 플래시 메모리, ROM(read only memory), PROM(programmable read-only memory), EPROM(erasable programmable read-only memory), EEPROM(electrically erasable programmable Read-only memory), 레지스터, 자기 디스크, 광학 디스크, 하드 드라이브 또는 임의의 기타 적합한 저장 매체 또는 이들의 임의의 조합이 포함될 수 있다. 기계 판독 가능 매체는 컴퓨터 프로그램 제품으로 구현될 수 있다. 컴퓨터 프 로그램 제품은 포장재를 포함할 수 있다. 하드웨어 구현에서, 기계 판독 가능 매체는 프로세서와 별개인 처리 시스템의 일부일 수 있다. 그러나, 당업자 라면 기계 판독 가능 매체 또는 그 임의의 부분이 처리 시스템 외부에 있을 수 있음을 쉽게 이해할 수 있을 것 이다. 예를 들어, 기계 판독 가능 매체는 전송 라인, 데이터에 의해 변조된 반송파 및/또는 디바이스와 별개인 컴퓨터 제품을 포함할 수 있으며, 이들 모두는 버스 인터페이스를 통해 프로세서에 의해 액세스될 수 있다. 대 안으로 또는 추가로, 기계 판독 가능 매체 또는 그 임의의 일부는 캐시 및/또는 일반 레지스터 파일의 경우와 같이 프로세서에 통합될 수 있다. 논의된 다양한 컴포넌트는 로컬 컴포넌트와 같이 특정 위치를 갖는 것으로 설명될 수 있지만, 특정 컴포넌트가 분산 컴퓨팅 시스템의 일부로 구성되는 등 다양한 방식으로 구성될 수도 있 다. 처리 시스템은 프로세서 기능을 제공하는 하나 이상의 마이크로프로세서 및 기계 판독 가능 매체의 적어도 일부 를 제공하는 외부 메모리를 갖는 범용 처리 시스템으로 구성될 수 있으며, 모두 외부 버스 아키텍처를 통해 기 타 지원 회로부와 함께 링크된다. 대안으로, 처리 시스템은 설명된 뉴런 모델 및 신경 시스템의 모델을 구현하 기 위한 하나 이상의 뉴로모픽(neuromorphic) 프로세서를 포함할 수 있다. 또 다른 대안으로서, 처리 시스템은 프로세서, 버스 인터페이스, 사용자 인터페이스, 지원 회로부, 및 기계 판독 가능 매체의 적어도 일부가 단일 칩에 통합되어 있는 주문형 집적 회로(ASIC)로 구현될 수 있거나, 또는 하나 이상의 FPGA(field programmable gate array), PLD(programmable logic device), 컨트롤러, 상태 머신, 게이트 로직, 개별 하드웨어 컴포넌트, 또는 임의의 기타 적합한 회로부, 또는 본 개시 전반에 걸쳐 설명된 다양한 기능을 수행할 수 있는 임의의 회로 조합으로 구현될 수 있다. 당업자는 특정 애플리케이션 및 전체 시스템에 부과된 전체 설계 제약에 따라 처리 시스템에 대해 설명된 기능을 가장 잘 구현하는 방법을 인식할 것이다. 기계 판독 가능 매체는 다수의 소프트웨어 모듈을 포함할 수 있다. 소프트웨어 모듈에는 프로세서에 의해 실행 시, 처리 시스템이 다양한 기능을 수행하도록 하는 명령어가 포함된다. 소프트웨어 모듈은 전송 모듈과 수신 모듈을 포함할 수 있다. 각 소프트웨어 모듈은 단일 저장 디바이스에 상주하거나 여러 저장 디바이스에 분산될 수 있다. 예를 들어, 소프트웨어 모듈은 트리거링 이벤트가 발생할 때 하드 드라이브에서 RAM으로 로드될 수 있다. 소프트웨어 모듈의 실행 동안, 프로세서는 액세스 속도를 높이기 위해 명령어 중 일부를 캐시로 로드할 수 있다. 그런 다음 하나 이상의 캐시 라인이 프로세서에 의한 실행을 위해 일반 레지스터 파일에 로드될 수 있다. 아래에서 소프트웨어 모듈의 기능을 참조 시, 이러한 기능은 해당 소프트웨어 모듈로부터 명령어를 실행 할 때 프로세서에 의해 구현된다는 것이 이해될 것이다. 더욱이, 본 개시의 양태는 프로세서, 컴퓨터, 머신, 또는 이러한 양태를 구현하는 기타 시스템의 기능을 개선시킨다는 것을 이해해야 한다. 소프트웨어로 구현되는 경우, 기능은 컴퓨터 판독 가능 매체에 하나 이상의 명령어 또는 코드로 저장되거나 송 신될 수 있다. 컴퓨터 판독 가능 매체는 한 장소에서 다른 장소로의 컴퓨터 프로그램의 전송을 용이하게 하는 임의의 매체를 포함하는 컴퓨터 저장 매체 및 통신 매체 모두를 포함한다. 저장 매체는 컴퓨터에 의해 액세스 될 수 있는 모든 사용 가능한 매체일 수 있다. 예를 들어, 제한 없이, 이러한 컴퓨터 판독 가능 매체는 RAM, ROM, EEPROM, CD-ROM 또는 기타 광 디스크 스토리지, 자기 디스크 스토리지 또는 기타 자기 스토리지 장치, 또 는 명령어나 데이터 구조의 형태로 원하는 프로그램 코드를 전달 또는 저장하는 데 사용될 수 있으며 컴퓨터에 의해 액세스될 수 있는 임의의 기타 매체를 포함할 수 있다. 추가로, 임의의 연결은 적절하게 컴퓨터 판독 가 능 매체라고 한다. 예를 들어, 소프트웨어가 동축 케이블, 광섬유 케이블, 연선, 디지털 가입자 회선(digital subscriber line; DSL) 또는 적외선(IR), 무선 및 마이크로파와 같은 무선 기술을 사용하여 웹사이트, 서버 또 는 기타 원격 소스로부터 송신되는 경우, 동축 케이블, 광섬유 케이블, 연선, DSL 또는 적외선, 무선 및 마이크 로파와 같은 무선 기술은 매체의 정의에 포함된다. 본원에 사용된 디스크(disk) 및 디스크(disc)에는 디스크(disk)들이 일반적으로 자기적으로 데이터를 재생하는 반면 디스크(disc)들은 레이저들로 데이터를 광학적으로 재생하는 컴팩트 디스크(CD), 레이저 디스크, 광 디스크, 디지털 다목적 디스크(DVD), 플로피 디스크 및 블루- 레이® 디스크가 포함된다. 따라서, 일부 양태에서 컴퓨터 판독 가능 매체는 비일시적 컴퓨터 판독 가능 매체 (예를 들어, 유형의(tangible) 매체)를 포함할 수 있다. 추가로, 기타 양태의 경우 컴퓨터 판독 가능 매체는 일시적 컴퓨터 판독 가능 매체(예를 들어, 신호)를 포함할 수 있다. 위의 조합들도 컴퓨터 판독 가능 저장 매 체의 범위에 포함되어야 한다. 따라서, 특정 양태는 본원에 제시된 동작을 수행하기 위한 컴퓨터 프로그램 제품을 포함할 수 있다. 예를 들어, 이러한 컴퓨터 프로그램 제품은 명령어가 저장(및/또는 인코딩)된 컴퓨터 판독 가능 매체를 포함할 수 있 으며, 명령어는 설명된 동작을 수행하기 위해 하나 이상의 프로세서에 의해 실행 가능하다. 특정 양태의 경우, 컴퓨터 프로그램 제품에는 포장재가 포함될 수 있다. 또한, 설명된 방법 및 기술을 수행하기 위한 모듈 및/또는 기타 적절한 수단은 다운로드될 수 있고/있거나 그렇 지 않으면 적용 가능한 경우 사용자 단말 및/또는 기지국에 의해 획득될 수 있다는 것이 이해되어야 한다. 예 를 들어, 이러한 디바이스는 서버에 결합되어 설명된 방법을 수행하기 위한 수단의 전송을 용이하게 할 수 있다. 대안으로, 설명된 다양한 방법은 저장 수단(예를 들어, RAM, ROM, 컴팩트 디스크(CD) 또는 플로피 디스 크와 같은 물리적 저장 매체 등)을 통해 제공될 수 있으므로, 사용자 단말 및/또는 기지국은 저장 수단을 디바 이스에 결합시키거나 제공 시 다양한 방법을 얻을 수 있다. 또한, 디바이스에 설명된 방법 및 기술을 제공하기 위한 임의의 기타 적합한 기술이 활용될 수 있다. 청구범위는 위에 예시된 정확한 구성 및 컴포넌트에 제한되지 않는다는 것을 이해해야 한다. 청구항의 범위를 벗어나지 않고 설명된 방법 및 장치의 배열, 동작 및 세부사항에 다양한 수정, 변경 및 변형이 이루어질 수 있 다.도면 도면1 도면2a 도면2b 도면2c 도면2d 도면3 도면4 도면5 도면6a 도면6b 도면7"}
{"patent_id": "10-2024-7026108", "section": "도면", "subsection": "도면설명", "item": 1, "content": "본 개시의 특징, 특성 및 이점은 유사한 참조 문자가 전체에 걸쳐 상응하게 식별되는 도면과 함께 취해질 때 아 래에 명시된 상세한 설명으로부터 보다 명백해질 것이다. 도 1은 본 개시의 특정 양태에 따른 범용 프로세서를 포함하는 시스템 온 칩(SOC)을 사용하는 신경망의 예시적 인 구현을 예시한다. 도 2a, 2b 및 2c는 본 개시의 양태에 따른 신경망을 예시하는 다이어그램이다. 도 2d는 본 개시의 양태에 따른 예시적인 딥 콘볼루션 망(DCN)을 예시하는 다이어그램이다. 도 3은 본 개시의 양태에 따른 예시적인 딥 콘볼루션 망(DCN)을 예시하는 블록도이다. 도 4는 본 개시의 양태에 따른 인공 지능(AI) 기능을 모듈화할 수 있는 예시적인 소프트웨어 아키텍처를 예시하 는 블록도이다. 도 5는 본 개시의 양태에 따른 비디오의 온-디바이스 쿼리 및 검색을 위한 예시적인 프로세서를 예시하는 하이 레벨 블록도이다. 도 6a는 본 개시의 양태에 따른 비디오의 쿼리 및 검색을 위한 예시적인 아키텍처를 예시하는 블록도이다. 도 6b는 본 개시의 양태에 따른 예시적인 온-디바이스 신경망을 예시하는 블록도이다. 도 7은 본 개시의 양태에 따른 인공 신경망을 사용한 비디오의 쿼리 및 검색을 위한 예시적인 프로세스를 예시 하는 흐름도이다."}
