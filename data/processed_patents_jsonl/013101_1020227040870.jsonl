{"patent_id": "10-2022-7040870", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0141429", "출원번호": "10-2022-7040870", "발명의 명칭": "이미지 프로세싱 방법 및 장치, 컴퓨터 디바이스, 컴퓨터-판독가능 저장 매체, 및 컴퓨터 프", "출원인": "텐센트 테크놀로지", "발명자": "허 커커"}}
{"patent_id": "10-2022-7040870", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "컴퓨터 디바이스에 의해 수행되는 이미지 프로세싱 방법으로서,얼굴 스와핑 요청(face swapping request)을 수신하는 단계 - 상기 얼굴 스와핑 요청은 스와핑 대상 이미지 내의 얼굴을 타깃 얼굴로 교체하는 것을 요청하기 위하여 이용됨 -;상기 스와핑 대상 이미지의 속성 파라미터, 상기 타깃 얼굴의 속성 파라미터, 및 상기 타깃 얼굴의 얼굴 특징을취득하는 단계 - 상기 스와핑 대상 이미지의 속성 파라미터는 상기 스와핑 대상 이미지 내의 얼굴의 3차원 속성을 지시함 -;상기 스와핑 대상 이미지의 속성 파라미터 및 상기 타깃 얼굴의 속성 파라미터에 기초하여 타깃 속성 파라미터를 결정하는 단계;상기 타깃 속성 파라미터 및 상기 타깃 얼굴의 얼굴 특징에 기초하여 타깃 종합 특징(target comprehensivefeature)을 결정하는 단계;상기 스와핑 대상 이미지의 이미지 인코딩 특징을 획득하기 위하여 상기 스와핑 대상 이미지를 인코딩하는단계;융합 인코딩 특징(fusion encoding feature)을 획득하기 위하여 정규화(normalization)에 의해 상기 타깃 종합특징을 상기 스와핑 대상 이미지의 상기 이미지 인코딩 특징으로 마이그레이팅(migrating)하는 단계; 및융합 얼굴을 포함하는 타깃 얼굴-스와핑된 이미지를 획득하기 위하여 상기 융합 인코딩 특징을 디코딩하는 단계- 상기 융합 얼굴은 상기 스와핑 대상 이미지 내의 얼굴 및 상기 타깃 얼굴의 융합임 -를 포함하는 이미지 프로세싱 방법."}
{"patent_id": "10-2022-7040870", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 타깃 얼굴의 속성 파라미터는 형상 계수이고, 상기 스와핑 대상 이미지의 속성 파라미터는 사전-구성 파라미터이고,상기 스와핑 대상 이미지의 속성 파라미터 및 상기 타깃 얼굴의 속성 파라미터에 기초하여 타깃 속성 파라미터를 결정하는 단계는,상기 타깃 얼굴의 상기 형상 계수 및 상기 스와핑 대상 이미지의 상기 사전-구성 파라미터를 상기 타깃 속성 파라미터인 것으로 결정하는 단계 - 상기 사전-구성 파라미터는 표정 계수, 각도 계수, 질감 계수, 및 조명 계수중의 적어도 하나를 포함함 - 를 포함하는, 이미지 프로세싱 방법."}
{"patent_id": "10-2022-7040870", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 융합 인코딩 특징을 획득하기 위하여 정규화에 의해 상기 타깃 종합 특징을 상기 스와핑 대상 이미지의 상기 이미지 인코딩 특징으로 마이그레이팅하는 단계는,제1 평균 및 제1 표준 편차를 준수하는 정규 분포(normal distribution)를 제1 특징 분포로서 취하기 위하여 적어도 하나의 특징 채널 내의 상기 이미지 인코딩 특징의 상기 제1 평균 및 상기 제1 표준 편차를 취득하고, 제2평균 및 제2 표준 편차를 준수하는 정규 분포를 제2 특징 분포로서 취하기 위하여 상기 적어도 하나의 특징 채널 내의 상기 타깃 종합 특징의 상기 제2 평균 및 상기 제2 표준 편차를 취득하는 단계; 및상기 융합 인코딩 특징을 획득하기 위하여 상기 제1 특징 분포로부터의 상기 이미지 인코딩 특징을 상기 제2 특징 분포로 정렬하는 단계공개특허 10-2023-0141429-3-를 포함하는, 이미지 프로세싱 방법."}
{"patent_id": "10-2022-7040870", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,상기 타깃 얼굴-스와핑된 이미지는 훈련된 얼굴 스와핑 모델을 호출함으로써 획득되고, 상기 얼굴 스와핑 모델은 상기 타깃 얼굴의 속성 파라미터 및 얼굴 특징에 기초하여 상기 타깃 얼굴을 임의의 얼굴 이미지로 스와핑하도록 구성되고,상기 이미지 프로세싱 방법은,제1 샘플 이미지의 얼굴 특징 및 속성 파라미터를 취득하고, 제2 샘플 이미지의 속성 파라미터를 취득하는 단계- 상기 제1 샘플 이미지는 상기 타깃 얼굴을 포함하고, 상기 제2 샘플 이미지는 교체 대상 얼굴을 포함함 -;상기 제1 샘플 이미지의 속성 파라미터 및 상기 제2 샘플 이미지의 속성 파라미터에 기초하여 샘플 속성 파라미터를 결정하는 단계 - 상기 샘플 속성 파라미터는 생성 대상 샘플 얼굴-스와핑된 이미지 내의 얼굴의 예상된 속성을 지시하기 위하여 이용됨 -; 및초기화된 얼굴 스와핑 모델을 통해:상기 샘플 속성 파라미터 및 상기 제1 샘플 이미지의 얼굴 특징에 기초하여 샘플 종합 특징을 결정하는 처리,샘플 인코딩 특징을 획득하기 위하여 상기 제2 샘플 이미지를 인코딩하는 처리,샘플 융합 특징을 획득하기 위하여 상기 샘플 종합 특징을 상기 제2 샘플 이미지의 상기 샘플 인코딩 특징으로마이그레이팅하는 처리,샘플 얼굴-스와핑된 이미지를 획득하기 위하여 상기 샘플 융합 특징을 디코딩하는 처리,상기 샘플 얼굴-스와핑된 이미지와 상기 샘플 속성 파라미터 사이의 제1 차이, 상기 샘플 얼굴-스와핑된 이미지의 얼굴 특징과 상기 제1 샘플 이미지의 얼굴 특징 사이의 제2 차이, 및 상기 샘플 얼굴-스와핑된 이미지와 상기 제2 샘플 이미지 사이의 제3 차이에 기초하여 상기 초기화된 얼굴 스와핑 모델의 총 손실을 결정하는 처리,및타깃 조건이 충족될 때까지 상기 총 손실에 기초하여 상기 초기화된 얼굴 스와핑 모델을 훈련시키고, 상기 타깃조건이 충족되는 것에 응답하여 획득된 모델을 상기 얼굴 스와핑 모델로서 취하는 처리의 프로세싱을 수행하는 단계를 더 포함하는, 이미지 프로세싱 방법."}
{"patent_id": "10-2022-7040870", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서,상기 샘플 얼굴-스와핑된 이미지와 상기 샘플 속성 파라미터 사이의 제1 차이, 상기 샘플 얼굴-스와핑된 이미지의 얼굴 특징과 상기 제1 샘플 이미지의 얼굴 특징 사이의 제2 차이, 및 상기 샘플 얼굴-스와핑된 이미지와 상기 제2 샘플 이미지 사이의 제3 차이에 기초하여 상기 초기화된 얼굴 스와핑 모델의 총 손실을 결정하는 단계전에, 상기 이미지 프로세싱 방법은,상기 샘플 얼굴-스와핑된 이미지의 속성 파라미터와 상기 샘플 속성 파라미터 사이의 제1 유사도를 취득하고,상기 제1 유사도를 상기 제1 차이로서 취하는 단계;상기 샘플 얼굴-스와핑된 이미지의 얼굴 특징과 상기 제1 샘플 이미지의 얼굴 특징 사이의 제2 유사도를 취득하고, 상기 제2 유사도를 상기 제2 차이로서 취하는 단계; 및상기 제2 샘플 이미지와 상기 샘플 얼굴-스와핑된 이미지 사이의 제3 유사도를 취득하고, 상기 제3 유사도를 상기 제3 차이로서 취하는 단계를 더 포함하는, 이미지 프로세싱 방법."}
{"patent_id": "10-2022-7040870", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "공개특허 10-2023-0141429-4-제5항에 있어서,상기 제2 샘플 이미지와 상기 샘플 얼굴-스와핑된 이미지 사이의 제3 유사도를 취득하는 것은,적어도 하나의 스케일(scale)에서의 상기 제2 샘플 이미지의 제1 스케일 이미지 및 적어도 하나의 스케일에서의상기 샘플 얼굴-스와핑된 이미지의 제2 스케일 이미지를 취득하는 것;상기 제2 샘플 이미지를 실제의 이미지로서 취하는 것;상기 제1 스케일 이미지들의 각각에 대응하는 판별 확률(discrimination probability)을 취하고, 상기 제2 스케일 이미지들의 각각에 대응하는 판별 확률을 취하는 것 - 이미지의 상기 판별 확률은 상기 이미지가 상기 실제의 이미지인 것으로 결정하는 확률을 지시하기 위하여 이용되고, 상기 이미지는 상기 제1 스케일 이미지 또는상기 제2 스케일 이미지임 -; 및상기 제1 스케일 이미지들의 각각에 대응하는 상기 판별 확률 및 상기 제2 스케일 이미지들의 각각에 대응하는상기 판별 확률에 기초하여 상기 제3 유사도를 결정하는 것을 포함하는, 이미지 프로세싱 방법."}
{"patent_id": "10-2022-7040870", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제4항에 있어서,상기 제1 샘플 이미지의 얼굴 특징 및 속성 파라미터를 취득하는 것은,적어도 2개의 자세 이미지(pose image)를 취득하고, 상기 적어도 2개의 자세 이미지를 상기 제1 샘플 이미지로서 취하는 것 - 상기 적어도 2개의 자세 이미지는 상기 타깃 얼굴의 적어도 2개의 얼굴 자세를 포함함 -;상기 적어도 2개의 자세 이미지에 기초하여 상기 적어도 2개의 얼굴 자세에 대응하는 얼굴 특징 및 속성 파라미터를 취득하는 것; 및상기 적어도 2개의 얼굴 자세에 대응하는 상기 얼굴 특징의 평균을 상기 제1 샘플 이미지의 상기 얼굴 특징으로서 취하고, 상기 적어도 2개의 얼굴 자세에 대응하는 상기 속성 파라미터의 평균을 상기 제1 샘플 이미지의 상기 속성 파라미터로서 취하는 것을 포함하고,이에 따라, 제1 샘플 이미지의 얼굴 특징 및 속성 파라미터를 취득한 후에, 상기 이미지 프로세싱 방법은,상기 제1 샘플 이미지의 얼굴 특징 및 속성 파라미터를 저장하는 단계를 더 포함하는, 이미지 프로세싱 방법."}
{"patent_id": "10-2022-7040870", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서,상기 적어도 2개의 자세 이미지를 취득하는 것은,상기 타깃 얼굴을 포함하는 적어도 2개의 이미지 프레임을 획득하기 위하여 타깃 객체의 비디오 내에 포함된 적어도 2개의 이미지 프레임에 대해 얼굴 인식을 수행하는 것 - 상기 타깃 얼굴은 상기 타깃 객체의 얼굴임 -; 및상기 적어도 2개의 자세 이미지를 획득하기 위하여 상기 적어도 2개의 이미지 프레임에 대해 얼굴 크롭핑(facecropping)을 수행하는 것을 포함하는, 이미지 프로세싱 방법."}
{"patent_id": "10-2022-7040870", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "이미지 프로세싱 장치로서,얼굴 스와핑 요청을 수신하도록 구성된 얼굴 파라미터 취득 모듈 - 상기 얼굴 스와핑 요청은 스와핑 대상 이미지 내의 얼굴을 타깃 얼굴로 교체하는 것을 요청하기 위하여 이용됨 -;상기 스와핑 대상 이미지의 속성 파라미터, 상기 타깃 얼굴의 속성 파라미터, 및 상기 타깃 얼굴의 얼굴 특징을취득하고 - 상기 스와핑 대상 이미지의 속성 파라미터는 상기 스와핑 대상 이미지 내의 얼굴의 3차원 속성을 지공개특허 10-2023-0141429-5-시함 -; 상기 스와핑 대상 이미지의 속성 파라미터 및 상기 타깃 얼굴의 속성 파라미터에 기초하여 타깃 속성파라미터를 결정하도록 구성된 타깃 속성 파라미터 결정 모듈;상기 타깃 속성 파라미터 및 상기 타깃 얼굴의 얼굴 특징에 기초하여 타깃 종합 특징을 결정하도록 구성된 종합특징 결정 모듈;상기 스와핑 대상 이미지의 이미지 인코딩 특징을 획득하기 위하여 상기 스와핑 대상 이미지를 인코딩하도록 구성된 인코딩 모듈;융합 인코딩 특징을 획득하기 위하여 정규화에 의해 상기 타깃 종합 특징을 상기 스와핑 대상 이미지의 상기 이미지 인코딩 특징으로 마이그레이팅하도록 구성된 마이그레이션 모듈; 및융합 얼굴을 포함하는 타깃 얼굴-스와핑된 이미지를 획득하기 위하여 상기 융합 인코딩 특징을 디코딩하도록 구성된 디코딩 모듈 - 상기 융합 얼굴은 상기 스와핑 대상 이미지 내의 얼굴 및 상기 타깃 얼굴의 융합임 -을 포함하는 이미지 프로세싱 장치."}
{"patent_id": "10-2022-7040870", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "메모리, 프로세서, 및 상기 메모리 상에 저장된 컴퓨터 프로그램을 포함하는 컴퓨터 디바이스로서, 상기 프로세서는 제1항 내지 제8항 중 어느 한 항에 따른 상기 이미지 프로세싱 방법을 구현하기 위하여 상기 컴퓨터 프로그램을 실행하는, 컴퓨터 디바이스."}
{"patent_id": "10-2022-7040870", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "컴퓨터 프로그램을 저장하는 컴퓨터-판독가능 저장 매체로서, 상기 컴퓨터 프로그램은, 프로세서에 의해 실행될때, 제1항 내지 제8항 중 어느 한 항에 따른 상기 이미지 프로세싱 방법을 구현하는, 컴퓨터-판독가능 저장 매체."}
{"patent_id": "10-2022-7040870", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "컴퓨터 프로그램을 포함하는 컴퓨터 프로그램 제품으로서, 상기 컴퓨터 프로그램은, 프로세서에 의해 실행될때, 제1항 내지 제8항 중 어느 한 항에 따른 상기 이미지 프로세싱 방법을 구현하는, 컴퓨터 프로그램 제품."}
{"patent_id": "10-2022-7040870", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "이 출원의 실시예는 이미지 프로세싱 방법 및 장치, 컴퓨터 디바이스, 컴퓨터-판독가능 저장 매체, 및 컴퓨터 프 로그램 제품을 제공하고, 인공 지능(AI), 컴퓨터 비전(CV), 맵, 지능형 수송 분야에 관련된다. 이미지 프로세싱 방법은 얼굴 스와핑 요청을 수신하는 단계; 스와핑 대상 이미지의 속성 파라미터, 타깃 얼굴의 속성 파라미터, (뒷면에 계속)"}
{"patent_id": "10-2022-7040870", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "관련된 출원 이 출원은 2022년 3월 30일자로 출원된 중국 특허 출원 제202210334052.7호에 대한 우선권을 주장하고, 이 중국 특허 출원은 그 전체적으로 참조로 본 명세서에 병합된다. 이 출원은 인공 지능(AI : artificial intelligence) 및 컴퓨터 비전(CV : computer vision)과 같은 기술의 분 야에 관한 것으로, 특히, 이미지 프로세싱 방법 및 장치, 컴퓨터 디바이스, 컴퓨터-판독가능 저장 매체, 및 컴 퓨터 프로그램 제품에 관한 것이다."}
{"patent_id": "10-2022-7040870", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "얼굴 스와핑(face swapping)은 컴퓨터 비전의 분야에서 중요한 기술이다. 얼굴 스와핑은 컨텐츠 제작, 영화 및 텔레비전 초상화 제작, 및 엔터테인먼트 비디오 제작과 같은 시나리오에서 폭넓게 이용된다. 주어진 이미지 A 및 주어진 이미지 B에 대하여, 얼굴 스와핑은 얼굴-스와핑된 이미지를 획득하기 위하여 이미지 A 내의 얼굴 특 징을 이미지 B로 마이그레이팅(migrating)하는 프로세스를 지칭한다. 관련된 기술에서, 얼굴 스와핑은 일반적으로 형상 맞춤(shape fitting)에 기초하여 실현된다. 예를 들어, 이미 지 A 내의 검출된 얼굴 핵심 포인트(key point) 및 이미지 B 내의 얼굴 핵심 포인트에 기초하여, 5개의 감각 기 관 및 얼굴의 윤곽과 같은 영역의 측면에서의 2개의 이미지 사이의 형상 변화 관계가 계산될 수 있고, 이미지 A 및 이미지 B 내의 얼굴은 형상 변화 관계에 따라 융합되어, 얼굴-스와핑된 이미지가 획득된다. 얼굴 스와핑은 위의 형상 맞춤 프로세스에서의 얼굴 변형(deformation) 및 융합(fusion)에 의해 실현된다. 그러 나, 이미지 A 및 이미지 B 내의 얼굴의 자세가 대폭 변동될 때, 자세에 있어서 대폭 변동되는 얼굴은 간단한 형 상 맞춤에 의해 프로세싱될 수 없어서, 이것은 얼굴-스와핑된 이미지 내의 비자연적인 얼굴 변형을 용이하게 초 래할 수 있다. 다시 말해서, 얼굴-스와핑된 이미지는 이미지 A 내의 얼굴과 덜 유사하여, 이것은 얼굴 스와핑의 낮은 정확도를 초래한다. 이 출원의 실시예는 얼굴 스와핑 전후의 유사도를 개선시킬 수 있어서, 얼굴 스와핑의 정확도를 개선시킬 수 있 는 이미지 프로세싱 방법 및 장치, 컴퓨터 디바이스, 컴퓨터-판독가능 저장 매체, 및 컴퓨터 프로그램 제품을 제공한다. 이 출원의 실시예는 이미지 프로세싱 방법을 제공하고, 이미지 프로세싱 방법은, 얼굴 스와핑 요청(face swapping request)을 수신하는 단계 - 얼굴 스와핑 요청은 스와핑 대상 이미지 내의 얼 굴을 타깃 얼굴로 교체하는 것을 요청하기 위하여 이용됨 -; 스와핑 대상 이미지의 속성 파라미터, 타깃 얼굴의 속성 파라미터, 및 타깃 얼굴의 얼굴 특징을 취득하는 단계 - 스와핑 대상 이미지의 속성 파라미터는 스와핑 대상 이미지 내의 얼굴의 3차원 속성을 지시함 -; 스와핑 대상 이미지의 속성 파라미터 및 타깃 얼굴의 속성 파라미터에 기초하여 타깃 속성 파라미터를 결정하는 단계; 타깃 속성 파라미터 및 타깃 얼굴의 얼굴 특징에 기초하여 타깃 종합 특징(target comprehensive feature)을 결 정하는 단계; 스와핑 대상 이미지의 이미지 인코딩 특징을 획득하기 위하여 스와핑 대상 이미지를 인코딩하는 단계; 융합 인코딩 특징(fusion encoding feature)을 획득하기 위하여 정규화(normalization)에 의해 타깃 종합 특징 을 스와핑 대상 이미지의 이미지 인코딩 특징으로 마이그레이팅(migrating)하는 단계; 및 융합 얼굴을 포함하는 타깃 얼굴-스와핑된 이미지를 획득하기 위하여 융합 인코딩 특징을 디코딩하는 단계 - 융 합 얼굴은 스와핑 대상 이미지 내의 얼굴 및 타깃 얼굴의 융합임 - 를 포함한다. 이 출원의 실시예는 이미지 프로세싱 장치를 제공하고, 이미지 프로세싱 장치는, 얼굴 스와핑 요청을 수신하도록 구성된 얼굴 파라미터 취득 모듈 - 얼굴 스와핑 요청은 스와핑 대상 이미지 내 의 얼굴을 타깃 얼굴로 교체하는 것을 요청하기 위하여 이용됨 -; 스와핑 대상 이미지의 속성 파라미터, 타깃 얼굴의 속성 파라미터, 및 타깃 얼굴의 얼굴 특징을 취득하고 - 스 와핑 대상 이미지의 속성 파라미터는 스와핑 대상 이미지 내의 얼굴의 3차원 속성을 지시함 -; 스와핑 대상 이 미지의 속성 파라미터 및 타깃 얼굴의 속성 파라미터에 기초하여 타깃 속성 파라미터를 결정하도록 구성된 타깃 속성 파라미터 결정 모듈; 타깃 속성 파라미터 및 타깃 얼굴의 얼굴 특징에 기초하여 타깃 종합 특징을 결정하도록 구성된 종합 특징 결정 모듈; 스와핑 대상 이미지의 이미지 인코딩 특징을 획득하기 위하여 스와핑 대상 이미지를 인코딩하도록 구성된 인코 딩 모듈; 융합 인코딩 특징을 획득하기 위하여 정규화에 의해 타깃 종합 특징을 스와핑 대상 이미지의 이미지 인코딩 특 징으로 마이그레이팅하도록 구성된 마이그레이션 모듈; 및 융합 얼굴을 포함하는 타깃 얼굴-스와핑된 이미지를 획득하기 위하여 융합 인코딩 특징을 디코딩하도록 구성된 디코딩 모듈 - 융합 얼굴은 스와핑 대상 이미지 내의 얼굴 및 타깃 얼굴의 융합임 - 을 포함한다. 이 출원의 실시예는 메모리, 프로세서, 및 메모리 상에서 저장된 컴퓨터 프로그램을 포함하는 컴퓨터 디바이스 를 제공하고, 프로세서는 상기한 이미지 프로세싱 방법을 구현하기 위하여 컴퓨터 프로그램을 실행한다. 이 출원의 실시예는 컴퓨터 프로그램을 저장하는 컴퓨터-판독가능 저장 매체를 제공하고, 컴퓨터 프로그램은, 프로세서에 의해 실행될 때, 상기한 이미지 프로세싱 방법을 구현한다. 이 출원의 실시예는 컴퓨터 프로그램을 포함하는 컴퓨터 프로그램 제품을 제공하고, 컴퓨터 프로그램은, 프로세 서에 의해 실행될 때, 상기한 이미지 프로세싱 방법을 구현한다. 이 출원의 실시예에서 제공된 기술적 해결책은 다음의 유익한 효과를 가진다: 이 출원의 실시예에 따르면, 타깃 속성 파라미터는 스와핑 대상 이미지의 속성 파라미터 및 타깃 얼굴의 속성 파라미터에 기초하여 결정되어, 생성되도록 예상된 이미지 내에 얼굴의 3 차원 속성 특징이 위치결정된다. 스와 핑 대상 이미지 및 타깃 얼굴을 종합적으로 나타낼 수 있는 타깃 종합 특징은 타깃 속성 파라미터 및 타깃 얼굴 의 얼굴 특징에 기초하여 획득된다. 스와핑 대상 이미지는 스와핑 대상 이미지의 이미지 인코딩 특징을 획득하 기 위하여 인코딩되어, 이미지 인코딩 특징을 통해 스와핑 대상 이미지의 픽셀-레벨 정제된 특징이 획득된다. 타깃 종합 특징은 융합 인코딩 특징을 획득하기 위하여 정규화에 의해 스와핑 대상 이미지의 이미지 인코딩 특 징으로 마이그레이팅된다. 이 출원의 실시예에서, 픽셀 레벨로 정제된 인코딩 특징은 글로벌 종합 특징(global comprehensive feature)과 혼합되고, 이미지 인코딩 특징은 타깃 종합 특징과 정렬되어, 생성된 융합 인코딩 특 징의 정확도가 개선된다. 융합 인코딩 특징은 융합 얼굴을 포함하는 타깃 얼굴-스와핑된 이미지를 획득하기 위 하여 디코딩되고, 디코딩된 이미지는 타깃 종합 특징을 도시하기 위하여 각각의 픽셀로 정제될 수 있어서, 이로 써 디코딩된 이미지 내의 융합 얼굴의 감각 기관이 타깃 얼굴에 더 근접하고, 이것은 감각 기관의 측면에서 융 합 얼굴과 타깃 얼굴 사이의 유사도를 개선시키고, 이에 의해 얼굴 스와핑의 정확도를 개선시킨다."}
{"patent_id": "10-2022-7040870", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "다음은 이 출원에서의 첨부 도면을 참조하여 이 출원의 실시예를 설명한다. 첨부 도면을 참조하여 이하에서 기 재된 구현예는 이 출원의 실시예를 설명하기 위하여 이용된 기술적 해결책의 예시적인 설명이고, 이 출원의 실 시예의 기술적 해결책에 대한 제한을 구성하지 않는다는 것이 이해되어야 한다. 이 출원의 실시예의 설명에서 참조된 바와 같은 얼굴 이미지, 예를 들어, 얼굴 스와핑 모델의 훈련에서 이용된 타깃 객체의 제1 샘플 이미지, 제2 샘플 이미지, 자세 이미지, 및 비디오와 같은 임의의 객체-관련된 데이터, 및 얼굴 스와핑 모델에 의해 수행된 얼굴 스와핑에서 이용된 스와핑 대상 이미지 및 타깃 얼굴의 얼굴 특징 및 속성 파라미터와 같은 임의의 객체-관련된 데이터는 관련된 객체의 동의 또는 허가로 모두 취득된다는 것이 이 해될 수 있다. 이 출원의 다음의 실시예가 특정 제품 또는 기술에 적용될 때, 허가 또는 동의가 객체로부터 획 득될 필요가 있고, 관련된 데이터의 수집, 이용, 및 프로세싱은 관련된 국가 및 지역의 관련된 법률, 규정, 및 표준을 따를 필요가 있다. 추가적으로, 이 출원의 이미지 프로세싱 방법을 이용함으로써 임의의 객체의 얼굴 이 미지에 대해 수행된 얼굴 스와핑 프로세스는 관련된 객체에 의해 그리고 관련된 객체의 허가 또는 동의로 트리 거링된 얼굴 스와핑 서비스 또는 얼굴 스와핑 요청에 기초하여 수행된 모든 얼굴 스와핑 프로세스이다. 이 출원에서 관여된 기술적 측면은 이하에서 소개된다: 1) 얼굴 스와핑: 얼굴 스와핑은 또 다른 이미지 내의 얼굴을 스와핑하기 위하여 하나의 얼굴 이미지 내의 타깃 얼굴을 이용하는 것을 의미한다. 2) 얼굴 스와핑 모델: 얼굴 스와핑 모델은 속성 파라미터 및 타깃 얼굴의 얼굴 특징에 기초하여 타깃 얼굴을 임 의의 스와핑 대상 이미지로 스와핑하기 위하여 호출될 수 있다. 이 출원의 실시예에 따른 이미지 프로세싱 방법 은 얼굴 스와핑 모델을 이용함으로써 스와핑 대상 이미지 내의 얼굴을 배타적 타깃 얼굴로 교체하는 것을 수반 할 수 있다.3) 스와핑 대상 이미지: 스와핑 대상 이미지는 얼굴이 스와핑될 필요가 있는 이미지이다. 예를 들어, 타깃 얼굴 은 스와핑 대상 이미지 내의 얼굴과 스와핑될 수 있다. 스와핑 대상 이미지는 이 출원의 실시예에 따른 이미지 프로세싱 방법을 이용함으로써 타깃 얼굴-스와핑된 이미지를 획득하기 위하여 스와핑된다는 것이 주목되어야 한 다. 타깃 얼굴-스와핑된 이미지 내에 포함된 융합 얼굴은 스와핑 대상 이미지 내의 얼굴 및 타깃 얼굴의 융합이 다. 융합 얼굴은 감각 기관의 측면에서 타깃 얼굴과 더 유사하다. 스와핑 대상 이미지 내의 얼굴의 표정 및 각 도와 같은 자세는 융합 얼굴에서 추가로 융합되어, 이로써 타깃 얼굴 이미지는 더욱 생성하고 현실적이다. 3) 속성 파라미터: 이미지의 속성 파라미터는 자세 및 공간 환경과 같은, 3 차원 공간에서의 얼굴의 속성을 나 타낼 수 있는 이미지 내의 얼굴의 3 차원 속성을 지시하기 위하여 이용된다. 4) 얼굴 특징: 얼굴 특징은 2 차원 평면에서의 이미지 내의 얼굴의 특징, 예를 들어, 2개의 눈 사이의 거리 및 코의 크기를 나타낸다. 얼굴 특징은 얼굴 특징을 갖는 객체의 아이덴티티(identity)를 나타낼 수 있다. 5) 타깃 얼굴: 타깃 얼굴은 이미지 내의 얼굴을 교체하기 위하여 이용된 배타적 얼굴(exclusive face)이다. 타 깃 얼굴은 사용자의 선택 조작에 기초하여 특정된 얼굴일 수 있다. 이 출원의 실시예는 타깃 얼굴을 배타적 얼 굴로서 취하는 얼굴 스와핑 서비스를 제공한다. 즉, 배타적 타깃 얼굴은 임의의 스와핑 대상 이미지로 스와핑될 수 있다. 예를 들어, 타깃 얼굴 A는 이미지 B의 얼굴을 교체할 수 있고, 타깃 얼굴 A는 또한, 이미지 C의 얼굴 을 교체할 수 있다. 6) 제1 샘플 이미지: 제1 샘플 이미지는 얼굴 스와핑 모델의 훈련에서 이용된 이미지인 타깃 얼굴을 포함한다. 7) 제2 샘플 이미지: 제2 샘플 이미지는 얼굴 스와핑 모델의 훈련에서 이용된 이미지인 교체 대상 얼굴을 포함 한다. 훈련 동안에, 제1 샘플 이미지 내의 타깃 얼굴은 배타적 얼굴로서 취해질 수 있고, 제1 샘플 이미지 내의 타깃 얼굴은 제2 샘플 이미지로 스와핑되어, 이 프로세스에 기초한 훈련에 의해 얼굴 스와핑 모델이 획득된다. 도 1은 이 출원의 실시예에 따른 이미지 프로세싱 방법의 구현 환경의 개략도이다. 도 1에서 도시된 바와 같이, 구현 환경은 서버 및 단말을 포함한다. 서버에는 훈련에 의해 획득된 얼굴 스와핑 모델이 제공된다. 서버는 얼굴 스와핑 모델에 기초한 얼굴 스와핑 기능을 갖는 단말을 제공할 수 있다. 얼굴 스와핑 기능은 타깃 얼굴에 기초하여 스와핑 대상 이미지 내의 얼굴을 스와핑하는 것을 의미하여, 이로써 생성된 타깃 얼굴 이미지 내의 융합 얼굴은 이미지 내의 원래의 얼굴 및 타깃 얼굴을 융합할 수 있다. 일부 실시예에서, 단말은 얼굴 스와핑 요청을 서버로 송신할 수 있다. 얼굴 스와핑 요청은 스와핑 대상 이미지를 운반할 수 있다. 서버는 얼굴 스와핑 요청에 기초하여, 타 깃 얼굴-스와핑된 이미지를 생성하기 위하여 이 출원의 이미지 프로세싱 방법을 수행할 수 있고, 타깃 얼굴-스 와핑된 이미지를 단말로 반환한다. 일부 실시예에서, 서버는 애플리케이션 프로그램의 백엔드 서버 (backend server)일 수 있다. 애플리케이션 프로그램은 단말 상에서 설치된다. 단말 및 서버는 얼 굴 스와핑 프로세스를 실현하기 위하여 애플리케이션 프로그램에 기초하여 데이터를 교환할 수 있다. 애플리케 이션 프로그램에는 얼굴 스와핑 기능이 제공될 수 있다. 애플리케이션 프로그램은 얼굴 스와핑 기능을 지원하는 임의의 애플리케이션이다. 예를 들어, 애플리케이션 프로그램은 비디오 편집 애플리케이션(video editing application), 이미지 프로세싱 툴(image processing tool), 비디오 애플리케이션(video application), 라이브 스트리밍 애플리케이션(live streaming application), 소셜 애플리케이션(social application), 컨텐츠 상호작 용 플랫폼(content interaction platform), 게임 애플리케이션(game application) 등을 포함하지만, 이것으로 제한되지는 않는다. 서버는 독립적인 물리적 서버일 수 있거나, 복수의 물리적 서버에 의해 형성된 서버 클러스터 또는 분산형 시스 템일 수 있거나, 클라우드 서비스, 클라우드 데이터베이스, 클라우드 컴퓨팅, 클라우드 기능, 클라우드 스토리 지(cloud storage), 네트워크 서비스, 클라우드 통신, 미들웨어 서비스, 도메인 명칭 서비스(domain name service), 보안 서비스, 컨텐츠 전달 네트워크(CDN : content delivery network), 빅 데이터(big data), 및 AI 플랫폼과 같은 기본적인 클라우드 컴퓨팅 서비스를 제공하는 클라우드 서버(cloud server) 또는 서버 클러스터 (server cluster)일 수 있다. 네트워크는 유선 네트워크 및 무선 네트워크를 포함할 수 있지만, 이것으로 제한 되지는 않는다. 유선 네트워크는 로컬 영역 네트워크(local area network), 대도시 영역 네트워크(metropolitan area network), 및 광역 네트워크(wide area network)를 포함한다. 무선 네트워크는, 블루투스(Bluetooth), Wi-Fi, 및 무선 통신을 구현하는 또 다른 네트워크를 포함한다. 단말은 (Android 폰 또는 iOS 폰과 같은) 스마 트 폰, 태블릿 컴퓨터, 랩톱 컴퓨터, 디지털 방송 수신기, 모바일 인터넷 디바이스(MID : mobile Internet device), 개인 정보 단말(personal digital assistant), 데스크톱 컴퓨터, (차량-장착형 내비게이션 단말 또는차량-장착형 컴퓨터와 같은) 차량-장착형 단말, 스마트 홈 기기, 항공기, 스마트 스피커, 스마트 시계 등일 수 있다. 단말 및 서버는 유선 또는 무선 통신에 의해 직접적으로 또는 간접적으로 접속될 수 있지만, 이것으로 제 한되지는 않는다. 이 출원의 이 실시예에 따른 이미지 프로세싱 방법은 AI 및 CV와 같은 다음의 기술에 관련된다. 예를 들어, 제1 샘플 이미지 내의 속성 파라미터를 추출하고 얼굴 스와핑 모델을 훈련시키는 프로세스는 클라우드 컴퓨팅 및 AI 기술 중 빅 데이터 프로세싱 기술을 이용함으로써 실현된다. 예를 들어, 얼굴 인식은 CV 기술을 이용함으로써 비디오 내의 이미지 프레임에 대해 수행되어, 타깃 얼굴을 포함하는 제1 샘플 이미지가 크롭 아웃(crop out)된 다. 인공 지능(AI)은 시뮬레이팅하고, 확장하고, 인간 지능을 확대하고, 환경을 지각하고, 지식을 취득하고, 지식을 이용하여 최적의 결과를 획득하기 위하여 디지털 컴퓨터 또는 디지털 컴퓨터에 의해 제어된 머신(machine)을 이 용하는 이론, 방법, 기술, 및 애플리케이션 시스템이다. 다시 말해서, AI는 컴퓨터 과학에서의 종합 기술이다. 이 기술은 지능의 본질을 이해하고, 인간 지능과 유사한 방식으로 반응할 수 있는 새로운 지능형 머신을 생성하 도록 시도한다. AI는 다양한 지능형 머신의 설계 원리 및 구현 방법을 연구하기 위한 것이어서, 이로써 머신은 지각하고, 추론하고, 판정을 행할 수 있다. AI 기술은 광범위한 분야에 관련되고 하드웨어 및 소프트웨어 기술의 둘 모두를 수반하는 종합적인 주제이다. 기본적인 AI 기술은 일반적으로, 센서, 전용 AI 칩, 클라우드 컴퓨팅, 분산형 스토리지, 빅 데이터 프로세싱 기 술, 오퍼레이팅/상호작용 시스템, 및 전기기계적 통합과 같은 기술을 포함한다. AI 소프트웨어 기술은 컴퓨터 비전(CV) 기술, 스피치 프로세싱 기술(speech processing technology), 자연어 프로세싱 기술(natural language processing technology), 머신 학습(ML : machine learning)/심층 학습(DL : deep learning), 자율 운전, 및 스마트 수송과 같은 몇몇 주요한 분야를 주로 포함한다. CV 기술은, \"보기(see)\" 위하여 머신을 어떻게 이용하는지를 연구하고, 또한, 인간 눈을 교체하여 타깃에 대한 인식 및 측정과 같은 머신 비전(machine vision)을 수행하고, 그래픽 프로세싱을 추가로 수행하기 위하여 카메 라 및 컴퓨터를 이용하는 과학이어서, 이로써 컴퓨터는 타깃을 인간의 눈이 관찰하기가 더 적당한 이미지, 또는 검출을 위한 도구로 송신된 이미지로 프로세싱한다. 과학적인 학문으로서, CV는 관련된 이론 및 기술을 연구하 고, 이미지 또는 다차원 데이터로부터 정보를 획득할 수 있는 AI 시스템을 확립하도록 시도한다. CV 기술은 일 반적으로, 이미지 프로세싱, 이미지 인식, 이미지 시맨틱 이해(image semantic understanding), 이미지 인출, 광학적 문자 인식(optical character recognition), 비디오 프로세싱, 비디오 시맨틱 이해, 비디오 컨텐츠/거동 인식, 3D 객체 재구성, 3D 기술, 가상 현실, 증강 현실, 동기식 위치결정 및 맵 구성, 자율 운전, 및 스마트 수 송과 같은 기술을 포함하고, 공통 얼굴 인식 및 지문 인식과 같은 생체계측 특징 인식 기술을 더 포함한다. 이 출원의 실시예의 해결된 기술적 문제의 목적, 구현된 기술적 해결책, 및 달성된 기술적 효과를 더 명확하게 하기 위하여, 다음은 첨부 도면을 참조하여 이 출원의 구현예를 상세하게 추가로 설명한다. 도 2는 이 출원의 실시예에 따른 얼굴 스와핑 모델에 대한 훈련 방법의 개략적인 흐름도이다. 방법은 컴퓨터 디 바이스(예컨대, 도 1에서 도시된 서버)에 의해 수행될 수 있다. 도 2에서 도시된 바와 같이, 방법은 다음의 단계 내지 단계를 포함한다. 단계: 컴퓨터 디바이스는 제1 샘플 이미지의 얼굴 특징 및 속성 파라미터를 취득하고, 제2 샘플 이미지의 속성 파라미터를 취득한다. 제1 샘플 이미지는 타깃 얼굴을 포함한다. 제2 샘플 이미지는 교체 대상 얼굴을 포함한다. 컴퓨터 디바이스는 임의의 얼굴을 포함하는 데이터를 제2 샘플 이미지로서 수집할 수 있고, 복수의 자세 각도에서의 타깃 얼굴을 포함하는 이미지를 제1 샘플 이미지로서 수집할 수 있다. 컴퓨터 디바이스는 얼굴 파라미터 추정 모델을 통해 제1 샘플 이미지의 속성 파라미터 및 제2 샘플 이미지의 속성 파라미터를 취득할 수 있다. 컴퓨터 디바이스는 얼굴 인식 모델을 통해 제1 샘플 이미지의 얼굴 특징을 취득할 수 있다. 얼굴 파라미터 추정 모델은 입력된 2 차원 얼굴 이미지에 기초하여 얼굴의 3 차원 속성 파라미터를 추정하도록 구성된다. 얼굴 파라미터 추정 모델은 컨볼루션 신경망 구조(convolutional neural network structure)의 모델 일 수 있다. 예를 들어, 얼굴 파라미터 추정 모델은 3D 변형가능 모델(3DMM : 3D morphable model)일 수 있다. 이 출원의 이 실시예에서, 입력된 2 차원 얼굴 이미지의 3 차원 속성 파라미터는 3DMM에서의 잔차 네트워크 (ResNet : residual network)를 통해 부분적으로 회귀(regress)될 수 있다. 얼굴 파라미터 추정 모델은 또한, 2 차원 이미지 내의 얼굴의 3 차원 속성 파라미터를 추출하는 기능을 갖는 임의의 다른 모델일 수 있다. 3DMM만이 본 명세서에서 예로서 취해진다. 속성 파라미터는 자세 및 공간 환경과 같은, 3 차원 공간에서의 얼굴의 속성을 나타낼 수 있는 이미지 내의 얼 굴의 3 차원 속성을 지시하기 위하여 이용된다. 속성 파라미터는 형상 계수(id_coeff), 표정 계수 (expression_coeff), 질감 계수(texture_coeff), 각도 계수(angles_coeff), 조명 계수(gamma_coeff) 등을 포함 하지만, 이것으로 제한되지는 않는다. 형상 계수는 얼굴의 형상, 얼굴의 5개의 감각 기관의 형상 등을 나타낸다. 각도 계수는 피치 각도 및 좌우 편향 각도와 같은 얼굴의 각도를 나타낸다. 질감 계수는 얼굴의 피부, 모발 등을 나타낼 수 있다. 조명 계수는 이미지 내의 얼굴이 위치되는 주변 환경의 조명을 나타낼 수 있 다. 이 출원의 이 실시예에 따른 컴퓨터 디바이스는 형상 계수, 표정 계수, 질감 계수, 각도 계수, 및 조명 계수 내 의 하나 이상의 특정된 항목을 다양한 샘플 이미지의 속성 파라미터로서 추출할 수 있거나, 모든 항목을 대응하 는 샘플 이미지의 속성 파라미터로서 추출할 수 있다. 이에 따라, 제1 샘플 이미지 및 제2 샘플 이미지의 속성 파라미터는 다음의 3개의 방식으로 취득될 수 있다. 방식 1에서, 컴퓨터 디바이스는 제1 샘플 이미지 내의 타깃 얼굴의 형상 계수를 제1 샘플 이미지의 속성 파라미 터로서 추출하고, 컴퓨터 디바이스는 제2 샘플 이미지 내의 표정 계수 및 각도 계수를 제2 샘플 이미지의 속성 파라미터로서 추출한다. 방식 1에서, 제1 샘플 이미지의 속성 파라미터는 제1 샘플 이미지 내의 타깃 얼굴의 형상 계수를 포함한다. 제2 샘플 이미지의 속성 파라미터는 제2 샘플 이미지 내의 얼굴의 표정 계수 및 각도 계수를 포함한다. 제1 샘플 이 미지의 형상 계수 및 제2 샘플 이미지의 표정 계수 및 각도 계수는 타깃 얼굴의 형상 특징, 및 표정 및 각도와 같은 교체 대상 얼굴의 특징의 후속 융합을 용이하게 하기 위하여 취득되어, 이로써 융합에 의해 획득된 샘플 얼굴-스와핑된 이미지 내의 얼굴은 타깃 얼굴의 5개의 감각 기관의 형상, 및 교체 대상 얼굴의 표정, 각도 등을 가질 수 있다. 그러므로, 5개의 감각 기관의 형상의 측면에서의 융합된 얼굴과 타깃 얼굴 사이의 유사도가 개선 된다. 방식 2에서, 제2 샘플 이미지에 대하여, 컴퓨터 디바이스는 제2 샘플 이미지의 사전-구성 파라미터를 제2 샘플 이미지의 속성 파라미터로서 취득할 수 있다. 제1 샘플 이미지에 대하여, 컴퓨터 디바이스는 제1 샘플 이미지 내의 타깃 얼굴의 형상 계수를 제1 샘플 이미지의 속성 파라미터로서 추출한다. 방식 2에서, 컴퓨터 디바이스는 요구된 바와 같이, 어느 항목이 제2 샘플 이미지의 속성 파라미터 내에 포함될 수 있는지를 구성한다. 제2 샘플 이미지의 속성 파라미터는 사전-구성 파라미터를 포함할 수 있다. 예를 들어, 사전-구성 파라미터는 표정 계수, 질감 계수, 각도 계수, 및 조명 계수 중의 적어도 하나를 포함할 수 있다. 사 전-구성 파라미터는 요구된 바와 같이 사전-구성된 파라미터이다. 예를 들어, 조명 계수 및 표정 계수를 포함하 는 사전-구성 파라미터를 통해, 융합에 의해 최종적으로 획득된 얼굴은 주변 환경의 조명 및 교체 대상 얼굴의 표정과 같은 특징을 가진다. 대안적으로, 사전-구성 파라미터는 질감 계수, 각도 계수 등을 포함할 수 있다. 세 부사항은 본 명세서에서 다시 설명되지 않는다. 방식 3에서, 컴퓨터 디바이스는 또한, 제1 샘플 이미지 및 제2 샘플 이미지의 복수의 파라미터를 대응하는 속성 파라미터로서 추출할 수 있다. 요구된 파라미터는 후속 단계에서 복수의 파라미터로부터 추가로 추출될 수 있다. 예로서, 제1 샘플 이미지의 속성 파라미터는 제1 샘플 이미지 내의 타깃 얼굴의 형상 계수, 표정 계수, 질감 계 수, 각도 계수, 및 조명 계수를 포함할 수 있다. 예를 들어, 속성 파라미터는 벡터(vector)로서 표현될 수 있다. 제1 샘플 이미지의 속성 파라미터가 위의 5개의 파라미터를 포함할 때, 제1 샘플 이미지의 속성 파라미터 는 257-차원 특징 벡터로서 표현될 수 있다. 제2 샘플 이미지의 속성 파라미터는 또한, 제2 샘플 이미지의 형상 계수, 표정 계수, 질감 계수, 각도 계수, 및 조명 계수를 포함할 수 있다. 이에 따라, 제2 샘플 이미지의 속성 파라미터는 또한, 257-차원 특징 벡터로서 표현될 수 있다. 일부 실시예에서, 컴퓨터 디바이스는 복수의 자세 각도에서 타깃 얼굴의 자세 이미지를 취득할 수 있고, 자세 이미지에 기초하여 제1 샘플 이미지의 얼굴 특징 및 속성 파라미터를 추출할 수 있다. 컴퓨터 디바이스가 제1 샘플 이미지의 얼굴 특징 및 속성 파라미터를 취득하는 프로세스는 다음의 기술적 해결책을 통해 실현될 수 있 다: 컴퓨터 디바이스는 적어도 2개의 자세 이미지를 제1 샘플 이미지로서 취득한다. 적어도 2개의 자세 이미지 는 타깃 얼굴의 적어도 2개의 얼굴 자세를 포함한다. 컴퓨터 디바이스는 적어도 2개의 자세 이미지에 기초하여 적어도 2개의 얼굴 자세에 대응하는 얼굴 특징 및 속성 파라미터를 취득한다. 컴퓨터 디바이스는 적어도 2개의얼굴 자세에 대응하는 얼굴 특징의 평균(mean)을 제1 샘플 이미지의 얼굴 특징으로서 취하고, 적어도 2개의 얼 굴 자세에 대응하는 속성 파라미터의 평균을 제1 샘플 이미지의 속성 파라미터로서 취한다. 컴퓨터 디바이스는 얼굴 파라미터 추정 모델을 호출하여, 적어도 2개의 자세 이미지들 각각의 속성 파라미터를 추출하고, 적어도 2 개의 자세 이미지의 속성 파라미터의 평균을 계산하고, 적어도 2개의 자세 이미지의 속성 파라미터의 평균을 제 1 샘플 이미지의 속성 파라미터로서 취할 수 있다. 컴퓨터 디바이스는 얼굴 인식 모델을 호출하여, 2 차원 평면 에서 적어도 2개의 자세 이미지들 각각의 얼굴 특징을 추출하고, 적어도 2개의 자세 이미지의 얼굴 특징의 평균 을 계산하고, 적어도 2개의 자세 이미지의 얼굴 특징의 평균을 제1 샘플 이미지의 얼굴 특징으로서 취할 수 있 다. 예를 들어, 제1 샘플 이미지의 얼굴 특징은 512-차원 특징 벡터일 수 있다. 얼굴 특징은 타깃 객체의 아이 덴티티를 나타낸다. 타깃 얼굴은 타깃 객체의 얼굴이다. 일부 실시예에서, 컴퓨터 디바이스는 비디오로부터 타깃 얼굴을 포함하는 복수의 자세 이미지를 추출할 수 있다. 컴퓨터 디바이스는 다음의 기술적 해결책을 통해 적어도 2개의 자세 이미지를 제1 샘플 이미지로서 취득 할 수 있다. 컴퓨터 디바이스는 타깃 얼굴을 포함하는 적어도 2개의 이미지 프레임을 획득하기 위하여 타깃 객 체의 비디오 내에 포함된 적어도 2개의 이미지 프레임에 대해 얼굴 인식을 수행한다. 타깃 얼굴은 타깃 객체의 얼굴이다. 컴퓨터 디바이스는 적어도 2개의 자세 이미지를 획득하기 위하여 적어도 2개의 이미지 프레임에 대해 얼굴 크롭핑(face cropping)을 수행하고, 적어도 2개의 자세 이미지를 제1 샘플 이미지로서 취한다. 얼굴 자세 는 얼굴 표정 및 각도, 얼굴의 5개의 감각 기관의 형상, 이동, 얼굴 상에 착용된 안경, 및 얼굴 화장과 같은 임 의의 속성을 포함할 수 있지만, 이것으로 제한되지는 않는다. 컴퓨터 디바이스는 얼굴 자세 내의 임의의 속성을 통해 자세를 구별할 수 있다. 예를 들어, 웃는 얼굴 및 화난 얼굴이 2개의 자세의 얼굴로서 취해질 수 있다. 안 경 쓴 얼굴 및 안경 쓰지 않은 얼굴이 또한, 2개의 자세의 얼굴로서 취해질 수 있다. 눈을 감은 45° 상향하는 피치 각도(pitch angle)의 얼굴 및 타깃 얼굴의 눈을 뜬 30° 하향하는 피치 각도의 얼굴은 또한, 2개의 자세의 얼굴로서 취해질 수 있다. 컴퓨터 디바이스는 또한, 타깃 얼굴의 복수의 독립적인 스틸 이미지를 취득할 수 있 고, 복수의 독립적인 스틸 이미지로부터 복수의 자세 이미지를 추출할 수 있다. 컴퓨터 디바이스는 또한, 적어 도 2개의 자세 이미지를 획득하기 위하여 복수의 스틸 이미지(still image)에 대해 얼굴 크롭핑을 수행할 수 있 고, 적어도 2개의 자세 이미지를 제1 샘플 이미지로서 취할 수 있다. 일부 실시예에서, 컴퓨터 디바이스는 다음의 기술적 해결책을 통해 자세 이미지를 획득하기 위하여 이미지 프레 임에 대해 얼굴 크롭핑을 수행할 수 있다. 먼저, 컴퓨터 디바이스는 이미지 프레임의 얼굴 좌표 박스(face coordinate box)를 획득하기 위하여 이미지 프레임에 대해 얼굴 검출을 수행한다. 구체적으로, 이미지 프레임 내의 타깃 얼굴이 위치되는 얼굴 영역은 얼굴 좌표 박스에 의해 원형화된다. 다음으로, 컴퓨터 디바이스는 이미 지 프레임 내의 타깃 얼굴 핵심 포인트를 획득하기 위하여 이미지 프레임의 얼굴 좌표 박스에 따라 이미지 프레 임에 대해 얼굴 등록(face registration)을 수행한다. 구체적으로, 타깃 얼굴 핵심 포인트는 5개의 감각 기관 핵심 포인트, 이미지 프레임 내의 타깃 얼굴의 얼굴 윤곽 핵심 포인트를 포함할 수 있고, 또한, 모발 핵심 포인 트 등을 포함할 수 있다. 컴퓨터 디바이스는 YOLO 네트워크와 같은 타깃 검출 네트워크를 통해 구현될 수 있고, 이미지 프레임에 대해 핵심 포인트 검출을 수행할 수 있다. 타깃 검출 네트워크의 입력 정보는 얼굴 이미지, 및 이미지 프레임 내의 얼굴 이미지의 얼굴 좌표 박스이고, 출력 정보는 타깃 얼굴 핵심 포인트를 포함하는 얼굴 핵심 포인트 좌표 시퀀스(face key point coordinate sequence)이다. 얼굴 핵심 포인트 좌표 시퀀스 내에 포함 된 핵심 포인트의 수량은 얼굴 세부사항에 대한 상이한 요건에 기초하여 사전-구성될 수 있다. 예를 들어, 얼굴 핵심 포인트 좌표 시퀀스 내에 포함된 핵심 포인트의 수량은 5, 68, 또는 90과 같은 고정된 값일 수 있다. 최종 적으로, 컴퓨터 디바이스는 자세 이미지를 획득하고, 얼굴 핵심 포인트 좌표 시퀀스에 의해 표현된 순서에 따라 타깃 얼굴 핵심 포인트를 접속하고, 접속에 의해 획득된 폐쇄된 그래프를 자세 이미지로서 취하기 위하여, 타깃 얼굴 핵심 포인트에 기초하여 이미지 프레임에 대해 얼굴 크롭핑을 수행한다. 일부 실시예에서, 제2 샘플 이미지를 취득하는 프로세스는 제1 샘플 이미지를 취득하는 프로세스와 유사하다. 예를 들어, 컴퓨터 디바이스는 객체를 포함하는 객체 이미지를 취득할 수 있고, 객체의 얼굴을 포함하는 이미지 를 획득하기 위하여 객체 이미지에 대해 얼굴 크롭핑을 수행할 수 있고, 객체의 얼굴을 포함하는 이미지를 제2 샘플 이미지로서 취할 수 있다. 얼굴 크롭핑은 자세 이미지를 획득하기 위하여 이미지 프레임에 대해 얼굴 크롭 핑을 수행하는 기술적 해결책과 유사한 방식으로 수행된다. 세부사항은 본 명세서에서 다시 설명되지 않는다. 추가적으로, 컴퓨터 디바이스는 얼굴 파라미터 추정 모델을 호출하여, 제2 샘플 이미지의 속성 파라미터를 추출 할 수 있다. 일부 실시예에서, 컴퓨터 디바이스는 제1 샘플 이미지의 얼굴 특징 및 속성 파라미터를 저장할 수 있다. 구체적 으로, 컴퓨터 디바이스는 제1 샘플 이미지의 얼굴 특징 및 속성 파라미터를 타깃 어드레스로 저장할 수 있다.타깃 어드레스는 사전-구성된 저장 어드레스이다. 타깃 얼굴의 얼굴 특징 및 속성 파라미터의 고정된 저장은 후 속 이용 시에 타깃 어드레스로부터의 데이터의 편리한 직접적인 추출을 가능하게 한다. 예를 들어, 배타적 얼굴 스와핑 서비스가 고정된 저장에 의해, 훈련된 얼굴 스와핑 모델을 이용함으로써 외부적으로 제공될 때, 컴퓨터 디바이스는 저장되었던 타깃 얼굴의 얼굴 특징 및 속성 파라미터를 직접적으로 추출할 수 있어서, 배타적 타깃 얼굴을 임의의 얼굴 이미지로 스와핑하는 배타적 얼굴 스와핑 프로세스가 실현될 수 있다. 또 다른 예에서, 타 깃 얼굴의 얼굴 특징 및 속성 파라미터는 반복적 훈련 국면에서의 훈련을 위하여 타깃 어드레스로부터 직접적으 로 추출될 수 있다. 단계: 컴퓨터 디바이스는 제1 샘플 이미지의 속성 파라미터 및 제2 샘플 이미지의 속성 파라미터에 기초하 여 샘플 속성 파라미터를 결정한다. 샘플 속성 파라미터는 생성 대상 샘플 얼굴-스와핑된 이미지 내의 얼굴의 예상된 속성을 지시하기 위하여 이용 된다. 단계에서의 방식 1에 대응하여, 컴퓨터 디바이스는 제1 샘플 이미지의 형상 계수 및 제2 샘플 이미지의 표 정 계수 및 각도 계수가 동일한 속성 파라미터인 것으로 결정할 수 있다. 단계에서의 방식 2 및 방식 3에 대응하여, 컴퓨터 디바이스는 요구된 바와 같이, 제1 샘플 이미지 및 제2 샘플 이미지의 다양한 속성 파라미터를 샘플 속성 파라미터로서 선택할 수 있다. 단계는 다음의 기술적 해 결책을 통해 구현될 수 있다: 컴퓨터 디바이스는 제1 샘플 이미지의 형상 계수 및 제2 샘플 이미지의 사전-구성 파라미터가 타깃 속성 파라미터인 것으로 결정한다. 제2 샘플 이미지의 사전-구성 파라미터는 표정 계수, 각도 계수, 질감 계수, 및 조명 계수 중의 적어도 하나를 포함한다. 단계에서의 방식 2에 대응하여, 사전-구성 파라미터는 단계에서의 방식 2에서 취득된 사전-구성 파라미터일 수 있다. 이 단계에서, 컴퓨터 디바이스 는 제2 샘플 이미지의 사전-구성 파라미터를 직접적으로 취득할 수 있다. 단계에서의 방식 3에 대응하여, 사전-구성 파라미터는 또한, 5개의 계수를 포함하는 속성 파라미터로부터 추출된 사전-구성 파라미터일 수 있다. 이 단계에서, 컴퓨터 디바이스는 사전-구성 파라미터 ID에 따라 제2 샘플 이미지로부터 사전-구성 파라미 터 ID에 대응하는 사전-구성 파라미터를 추출할 수 있다. 예를 들어, 사전-구성 파라미터 ID는 표정 계수, 각도 계수, 질감 계수, 및 조명 계수 중의 적어도 하나의 파라미터 ID를 포함할 수 있다. 예를 들어, 사전-구성 파라 미터는 표정 계수 및 각도를 포함할 수 있다. 즉, 생성 대상 샘플 얼굴-스와핑된 이미지 내의 얼굴은 얼굴의 형 상 및 타깃 얼굴의 5개의 감각 기관 뿐만 아니라, 제2 샘플 이미지 내의 얼굴의 표정 및 각도를 가지는 것으로 예상된다. 컴퓨터 디바이스는 타깃 얼굴의 형상 계수 및 제2 샘플 이미지의 표정 계수 및 각도가 타깃 속성 파 라미터인 것으로 결정할 수 있다. 또 다른 예에서, 사전-구성 파라미터는 또한, 질감 계수 및 조명 계수를 포함 할 수 있다. 즉, 샘플 얼굴-스와핑된 이미지 내의 얼굴은 타깃 얼굴의 형상 뿐만 아니라, 제2 샘플 이미지 내의 얼굴의 질감 계수 및 조명 계수를 가지는 것으로 예상된다. 컴퓨터 디바이스는 또한, 타깃 얼굴의 형상 계수 및 제2 샘플 이미지의 질감 계수 및 조명 계수가 샘플 속성 파라미터인 것으로 결정할 수 있다. 단계: 컴퓨터 디바이스는 샘플 속성 파라미터 및 제1 샘플 이미지의 얼굴 특징에 기초하여 샘플 종합 특징 을 결정한다. 컴퓨터 디바이스는 샘플 속성 파라미터 및 제1 샘플 이미지의 얼굴 특징을 스플라이싱(splice)할 수 있고, 스플 라이싱에 의해 획득된 스플라이싱 특징을 샘플 종합 특징으로서 취할 수 있다. 샘플 종합 특징은 생성되는 것으 로 예상된 샘플 얼굴 특징 내의 얼굴의 종합 특징을 나타낼 수 있다. 예를 들어, 샘플 속성 파라미터 및 얼굴 특징은 특징 벡터로서 표현될 수 있다. 컴퓨터 디바이스는 샘플 종합 특징에 대응하는 제3 특징 벡터를 획득하 기 위하여, 샘플 속성 파라미터에 대응하는 제1 특징 벡터 및 얼굴 특징에 대응하는 제2 특징 벡터를 스플라이 싱할 수 있다. 단계: 컴퓨터 디바이스는 샘플 인코딩 특징을 획득하기 위하여 제2 샘플 이미지를 인코딩한다. 컴퓨터 디바이스는 제2 샘플 이미지를 초기화된 얼굴 스와핑 모델의 인코더로 입력하고, 제2 샘플 이미지에 대 응하는 인코딩 벡터를 획득하기 위하여 인코더를 통해 제2 샘플 이미지를 인코딩하고, 인코딩 벡터를 샘플 인코 딩 특징으로서 취한다. 제2 샘플 이미지는 샘플 인코딩 특징을 획득하기 위하여 인코딩되어, 제2 샘플 이미지 내에 포함된 다양한 픽셀(pixel)의 픽셀-레벨 정보가 정확하게 정제된다. 인코더는 복수의 캐스케이딩된 컨볼루션 계층(cascaded convolutional layer)을 포함한다. 제2 샘플 이미지는 복수의 캐스케이딩된 컨볼루션 계층을 통해 컨볼루션된다. 각각의 컨볼루션 계층은 컨볼루션을 계속하기 위하여 컨볼루션 결과를 다음 컨볼루션 계층으로 입력한다. 최종적인 컨볼루션 계층은 샘플 인코딩 특징을 출력한다.단계: 컴퓨터 디바이스는 샘플 융합 특징을 획득하기 위하여 정규화에 의해 샘플 종합 특징을 제2 샘플 이 미지의 샘플 인코딩 특징으로 마이그레이팅한다. 컴퓨터 디바이스는 샘플 종합 특징 및 샘플 인코딩 특징의 융합을 실현하기 위하여 단계를 이용할 수 있다. 컴퓨터 디바이스는 샘플 융합 특징을 획득하기 위하여 정규화에 의해 샘플 종합 특징의 제3 특징 분포로 부터의 샘플 인코딩 특징을 제2 샘플 이미지의 제4 특징 분포로 정렬할 수 있다. 일부 실시예에서, 특징 분포는 평균 및 표준 편차를 포함할 수 있다. 이에 따라, 단계는 다음의 기술적 해결책을 통해 구현될 수 있다: 컴퓨터 디바이스는 제3 평균 및 제3 표준 편차를 준수하는 정규 분포(normal distribution)를 제3 특징 분포로 서 취하기 위하여 적어도 하나의 특징 채널 내의 샘플 인코딩 특징의 제3 평균 및 제3 표준 편차를 취득하고, 제4 평균 및 제4 표준 편차를 준수하는 정규 분포를 제4 특징 분포로서 취하기 위하여 적어도 하나의 특징 채널 내의 샘플 종합 특징의 제4 평균 및 제4 표준 편차를 취득한다. 컴퓨터 디바이스는 샘플 융합 특징을 획득하기 위하여, 각각의 특징 채널 내의 샘플 인코딩 특징의 평균 및 표준 편차(제3 특징 분포)를 대응하는 특징 채널 내의 샘플 종합 특징의 평균 및 표준 편차(제4 특징 분포)와 정렬한다. 컴퓨터 디바이스는 샘플 인코딩 특징의 각각의 특징 채널을 정규화할 수 있고, 샘플 융합 특징을 생성하기 위하여 정규화된 샘플 인코딩 특징의 평균 및 표준 편차를 샘플 종합 특징의 평균 및 표준 편차와 정렬할 수 있다. 예로서, 컴퓨터 디바이스는 다음의 공식 을 통해 샘플 인코딩 특징 및 샘플 종합 특징에 기초하여 제3 특징 분포로부터 제4 특징 분포로의 위의 정렬을 실현할 수 있고, 샘플 융합 특징을 계산할 수 있다. ; 여기서, x는 샘플 인코딩 특징을 나타내고, y는 샘플 종합 특징을 나타내고, 및 는 샘플 인코딩 특징 의 평균 및 표준 편차를 각각 나타내고, 및 는 샘플 종합 특징의 평균 및 표준 편차를 각각 나타낸다. 적응적 인스턴스 정규화(AdaIN : adaptive instance normalization)는 AdaIN 알고리즘을 채택하기 위한 것이다. AdaIN(x, y)는 AdaIN에 기초하여 생성된 샘플 융합 특징을 나타낸다. 예로서, 위의 AdaIN에 추가적으로, 인스턴스 정규화(IN : instance normalization) 알고리즘이 또한 채택될 수 있지만, 이것은 제한되지 않는다. 단계: 컴퓨터 디바이스는 샘플 얼굴-스와핑된 이미지를 획득하기 위하여 샘플 융합 특징을 디코딩한다. 컴퓨터 디바이스는 샘플 융합 특징이 초기화된 얼굴 스와핑 모델에서 디코더를 통과하게 하고, 디코더를 통해 샘플 융합 특징에 대응하는 이미지를 복원한다. 컴퓨터 디바이스는 디코더에 의해 출력된 이미지를 샘플 얼굴- 스와핑된 이미지로서 취한다. 디코더는 주입된 특징에 기초하여 주입된 특징에 대응하는 이미지를 복원할 수 있 다. 컴퓨터 디바이스는 샘플 얼굴-스와핑된 이미지를 획득하기 위하여 디코더를 통해 샘플 융합 이미지를 디코 딩한다. 예를 들어, 인코더는 입력된 이미지를 컨볼루션할 수 있다. 그러므로, 동작 동안에, 디코더는 샘플 융 합 특징에 대응하는 이미지를 복원하기 위하여, 인코더의 동작 원리에 따라 역 동작(reverse operation), 즉, 디컨볼루션 동작(deconvolution operation)을 수행할 수 있다. 예를 들어, 인코더는 오토인코더(AE : AutoEncoder)일 수 있고, 디코더는 AE에 대응하는 디코더일 수 있다. 인코더는 복수의 캐스케이딩된 컨볼루션 계층을 포함한다. 샘플 융합 특징은 복수의 캐스케이딩된 컨볼루션 계 층을 통해 디컨볼루션된다. 각각의 컨볼루션 계층은 디컨볼루션을 계속하기 위하여 디컨볼루션 결과를 다음 컨 볼루션 계층으로 입력한다. 최종적인 컨볼루션 계층은 샘플 얼굴-스와핑된 이미지를 출력한다. 단계를 통해, 특징 마이그레이션(feature migration)은 정규화에 의해 수행되어, 이로써 샘플 종합 특징은 임의의 이미지의 인코딩 특징으로 마이그레이팅되어, 샘플 종합 특징 및 샘플 인코딩 특징의 혼합이 실현될 수 있다. 또한, 샘플 인코딩 특징은 제2 샘플 이미지 내의 다양한 픽셀을 나타내는 특징이고, 샘플 종합 특징은 글 로벌 관점으로부터 제1 샘플 이미지 및 제2 샘플 이미지의 특징을 통합한다. 그러므로, 정규화에 의해, 픽셀 레 벨로 정제된 인코딩 특징과 글로벌 종합 특징 사이의 혼합이 실현되고, 샘플 인코딩 특징의 특징 분포는 샘플 종합 특징과 정렬되어, 생성된 샘플 융합 특징의 정확도가 개선된다. 단계를 통해, 이미지는 샘플 융합 특 징을 이용함으로써 디코딩되어, 이로써 디코딩된 이미지는 샘플 종합 특징을 도시하기 위하여 다양한 픽셀로 정 제될 수 있고, 이것은 감각 기관의 측면에서 디코됭된 이미지 내의 얼굴과 타깃 얼굴 사이의 유사도를 개선시키고, 얼굴 스와핑의 정확도를 개선시킨다. 단계: 샘플 얼굴-스와핑된 이미지와 샘플 속성 파라미터 사이의 제1 차이, 샘플 얼굴-스와핑된 이미지의 얼굴 특징과 제1 샘플 이미지의 얼굴 특징 사이의 제2 차이, 및 샘플 얼굴-스와핑된 이미지와 제2 샘플 이미지 사이의 제3 차이에 기초하여 초기화된 얼굴 스와핑 모델의 총 손실을 결정함. 제1 차이에 대응하는 제1 가중치, 제2 차이에 대응하는 제2 가중치, 및 제3 차이에 대응하는 제3 가중치가 취득 되고, 제1 차이, 제2 차이, 및 제3 차이는 총 손실을 획득하기 위하여 제1 가중치, 제2 가중치, 및 제3 가중치 에 기초하여 가중화되고 평균화된다. 차이에 대응하는 가중치는 사전-구성된 가중치일 수 있다. 단계: 타깃 조건이 충족될 때까지 총 손실에 기초하여 초기화된 얼굴 스와핑 모델을 훈련시키고, 타깃 조 건이 충족되는 것에 응답하여 획득된 모델을 얼굴 스와핑 모델로서 취함. 컴퓨터 디바이스는 샘플 얼굴-스와핑된 이미지와, 샘플 속성 파라미터, 제1 샘플 이미지의 얼굴 특징 뿐만 아니 라, 제2 샘플 이미지와의 사이의 복수의 유사도를 각각 결정할 수 있고, 복수의 유사도에 기초하여 총 손실을 획득할 수 있다. 일부 실시예에서, 초기화된 얼굴 스와핑 모델은 판별기(discriminator)를 포함할 수 있다. 컴 퓨터 디바이스는 판별기를 이용함으로써 샘플 얼굴-스와핑된 이미지의 인증성(authenticity)을 결정할 수 있다. 컴퓨터 디바이스가 총 손실을 결정하는 프로세스는 다음의 단계를 포함할 수 있다: 컴퓨터 디바이스는 샘플 얼 굴-스와핑된 이미지의 속성 파라미터와 샘플 속성 파라미터 사이의 제1 유사도를 취득하고, 제1 유사도를 제1 차이로서 취한다. 컴퓨터 디바이스는 샘플 얼굴-스와핑된 이미지의 얼굴 특징과 제1 샘플 이미지의 얼굴 특징 사이의 제2 유사도를 취득하고, 제2 유사도를 제2 차이로서 취한다. 컴퓨터 디바이스는 초기화된 얼굴 스와핑 모델의 판별기를 통해, 제2 샘플 이미지와 샘플 얼굴-스와핑된 이미지 사이의 제3 유사도를 취득하고, 제3 유사 도를 제1 차이로서 취한다. 컴퓨터 디바이스는 제1 유사도, 제2 유사도, 및 제3 유사도에 기초하여 총 손실을 결정한다. 컴퓨터 디바이스는 샘플 얼굴-스와핑된 이미지의 속성 파라미터를 추출할 수 있고, 다음의 공식 를 통해 샘 플 얼굴-스와핑된 이미지의 속성 파라미터와 샘플 속성 파라미터 사이의 제1 유사도를 결정할 수 있다. 3d feature loss = abs(gt 3d feature - result 3d feature) ; 여기서, 3d feature loss는 제1 유사도를 나타낸다. 제1 유사도의 값이 더 작을수록, 샘플 얼굴-스와핑된 이미 지의 속성 파라미터가 샘플 속성 파라미터에 더 근접한다. result 3d feature는 샘플 얼굴-스와핑된 이미지의 속성 파라미터를 나타내고, gt 3d feature는 샘플 속성 파라미터를 나타낸다. abs는 (gt 3d feature - result 3d feature)의 절대 값이다. 샘플 속성 파라미터는 타깃 얼굴의 형상 계수, 및 제2 샘플 이미지의 표정 계수 및 각도일 수 있다. 이에 따라, gt 3d feature는 다음의 공식 으로서 표현될 수 있다: gt 3d feature=source 3d feature id+target 3d feature expression+ target 3d feature angles; ; source 3d feature id는 제1 샘플 이미지의 형상 계수를 나타내고, target 3d feature expression은 제2 샘플 이미지의 표정 계수를 나타내고, target 3d feature angles는 제2 샘플 이미지의 각도를 나타낸다. 컴퓨터 디바이스는 샘플 얼굴-스와핑된 이미지의 얼굴 특징을 추출할 수 있고, 다음의 공식 를 통해 샘플 얼 굴-스와핑된 이미지의 얼굴 특징과 제1 샘플 이미지의 얼굴 특징 사이의 제2 유사도를 결정할 수 있다. id loss=1 - cosine similarity(result id feature, Mean Source ID) ; 여기서, id loss는 제2 유사도를 나타낸다. 제2 유사도의 값이 더 작을수록, 샘플 얼굴-스와핑된 이미지의 얼굴 특징이 제1 샘플 이미지의 얼굴 특징에 더 근접한다. result id feature는 샘플 얼굴-스와핑된 이미지의 얼굴 특징을 나타내고, Mean Source ID는 제1 샘플 이미지의 얼굴 특징을 나타낸다. cosine similarity(result id feature, Mean Source ID)는 result id feature와 Mean Source ID 사이의 코사인 유사도(cosine similarity)를 나타낸다. 코사인 유사도는 다음의 공식 에 의해 도시된 바와 같은 프로세스에서 결정될 수 있다: ; 여기서, A 및 B는 샘플 얼굴-스와핑된 이미지의 얼굴 특징에 대응하는 특징 벡터, 및 제1 샘플 이미지의 얼굴 특징에 대응하는 특징 벡터를 각각 나타낼 수 있다. 는 특징 벡터 A와 특징 벡터 B 사이의 각도를 나타낸다. Ai는 샘플 얼굴-스와핑된 이미지의 얼굴 특징 내의 i 번째 특징 채널의 컴포넌트를 나타낸다. Bi는 제1 샘플 이 미지의 얼굴 특징 내의 i 번째 특징 채널의 컴포넌트를 나타낸다. similarity 및 cos(θ)는 코사인 유사도를 나 타낸다. 컴퓨터 디바이스는 제2 샘플 이미지를 실제의 이미지로서 판별기로 입력할 수 있고, 샘플 얼굴-스와핑된 이미지 를 판별기로 입력할 수 있다. 컴퓨터 디바이스는 판별기를 통해 적어도 하나의 스케일(scale)에서의 제2 샘플 이미지의 제3 스케일 이미지 및 적어도 하나의 스케일에서의 샘플 얼굴-스와핑된 이미지의 제4 스케일 이미지를 각각 취득한다. 컴퓨터 디바이스는 제3 스케일 이미지들의 각각에 대응하는 판별 확률을 취득하고, 제4 스케일 이미지들의 각각에 대응하는 판별 확률을 취득한다. 이미지의 판별 확률은 이미지가 실제의 이미지인 것으로 결 정하는 확률을 지시하기 위하여 이용된다. 이미지는 제3 스케일 이미지 또는 제4 스케일 이미지이다. 컴퓨터 디 바이스는 제3 스케일 이미지들의 각각에 대응하는 판별 확률 및 제4 스케일 이미지들의 각각에 대응하는 판별 확률에 기초하여 제3 유사도를 결정한다. 예를 들어, 초기화된 얼굴 스와핑 모델은 생성기 및 판별기를 포함할 수 있다. 컴퓨터 디바이스는 판별기에 대응하는 판별 손실 값을 취득하고, 생성기에 대응하는 생성 손실 값을 취득하고, 생성 손실 값 및 판별 손실 값에 기초하여 제3 유사도를 결정한다. 생성기는 제2 샘플 이미지 및 제1 샘플 이미지에 기초하여 샘플 얼굴-스와핑된 이미지를 생성하도록 구성된다. 예를 들어, 생성기는 단계 내 지 단계에서 이용된 인코더 및 디코더를 포함할 수 있다. 제3 유사도는 생성 손실 값 및 판별 손실 값을 포함할 수 있다. 컴퓨터 디바이스는 샘플 얼굴-스와핑된 이미지의 판별 확률을 갖는 생성 손실 값을 나타낼 수 있다. 예를 들어, 컴퓨터 디바이스는 다음의 공식 을 통해 샘플 얼굴-스와핑된 이미지의 판별 확률에 기초하 여 생성 손실 값을 계산한다. G loss=log(1 - D(result)) ; 여기서, D(result)는 샘플 얼굴-스와핑된 이미지의 판별 확률을 나타내고, 샘플 얼굴-스와핑된 이미지의 판별 확률은 샘플 얼굴-스와핑된 이미지가 실제의 이미지에 속할 확률을 지칭하고, G loss는 생성 손실 값을 나타낸 다. 생성기는 복수의 캐스케이딩된 컨볼루션 계층을 포함한다. 예를 들어, 생성기는 U-Net 구조를 가질 수 있다. 제 2 샘플 이미지 및 제1 샘플 이미지는 U-Net을 통해 다운-샘플링된다. 그 다음으로, 다운-샘플링 결과는 샘플 얼 굴-스와핑된 이미지를 획득하기 위하여 업-샘플링된다. 판별기는 또한, 복수의 캐스케이딩된 컨볼루션 계층을 포함한다. 판별기는 U-Net의 다운-샘플링 구조 및 완전히 접속된 계층을 가진다. U-Net의 다운-샘플링 구조는 샘플 얼굴-스와핑된 이미지를 컨볼루션하고, 그 다음으로, 완전히 접속된 계층은 샘플 얼굴-스와핑된 이미지의 판별 확률을 획득하기 위하여 컨볼루션 결과를 맵핑한다. 판별기는 멀티-스케일(multi-scale) 판별기일 수 있다. 컴퓨터 디바이스는 다수의 스케일에서의 제4 스케일 이 미지를 획득하기 위하여, 예를 들어, 제1 스케일에서의 샘플 얼굴-스와핑된 이미지의 제4 스케일 이미지, 제2 스케일에서의 제4 스케일 이미지, 및 제3 스케일에서의 제4 스케일 이미지를 각각 획득하기 위하여, 판별기를 통해 샘플 얼굴-스와핑된 이미지를 스케일링할 수 있다. 유사하게, 컴퓨터 디바이스는 판별기를 통해 제1 스케 일에서의 제2 샘플 이미지의 제3 스케일 이미지, 제2 스케일에서의 제3 스케일 이미지, 및 제3 스케일에서의 제 3 스케일 이미지를 각각 취득할 수 있다. 제1 스케일, 제2 스케일, 및 제3 스케일은 요구된 바와 같이 설정될 수 있다. 예를 들어, 제1 스케일은 샘플 얼굴-스와핑된 이미지 또는 제2 샘플 이미지의 원래의 스케일일 수 있 다. 제2 스케일은 원래의 스케일의 1/2일 수 있다. 제3 스케일은 원래의 스케일의 1/4일 수 있다. 컴퓨터 디바 이스는 멀티-스케일 판별기를 통해 다양한 스케일에서의 스케일 이미지에 대응하는 판별 확률을 취득할 수 있고, 다수의 스케일에서의 스케일 이미지의 판별 확률에 기초하여 판별 손실 값을 계산할 수 있다. 예를 들어, 컴퓨터 디바이스는 다음의 공식 을 통해, 제3 스케일 이미지들의 각각에 대응하는 판별 확률 및 제4 스케일 이미지들의 각각에 대응하는 판별 확률에 기초하여 판별 손실 값을 취득한다. D loss = 1/3 * {-logD(template img)-log(1-D(result))-logD(template img1/2)-log(1-D(result1/2))- logD(template img1/4)-log(1-D(result 1/4))} ; 여기서, D(template img), D(template img1/2), 및 D(template img1/4)는 원래의 스케일에서의 제2 샘플 이미 지의 제3 스케일 이미지의 판별 확률, 1/2 스케일에서의 제2 샘플 이미지의 제3 스케일 이미지의 판별 확률, 및 1/4 스케일에서의 제2 샘플 이미지의 제3 스케일 이미지의 판별 확률을 각각 나타낸다. D(result), D(result1/2), 및 D(result 1/4)는 원래의 스케일에서의 샘플 얼굴-스와핑된 이미지의 제4 스케일 이미지의 판별 확률, 1/2 스케일에서의 샘플 얼굴-스와핑된 이미지의 제4 스케일 이미지의 판별 확률, 및 1/4 스케일에서의 샘플 얼굴-스와핑된 이미지의 제4 스케일 이미지의 판별 확률을 각각 나타낸다. 이 출원의 이 실시예에서, 제2 샘플 이미지는 실제의 이미지로서 취해질 수 있다. 컴퓨터 디바이스는 위의 판별 손실 값 및 생성 손실 값에 기초하여 제3 유사도를 결정할 수 있다. 예를 들어, 제3 유사도 = G loss + D loss이다. 판별기에 대하여, 생성 손실 값 및 판별 손실 값이 균형에 도달할 때, 판별 기는 훈련 정지 조건에 도달하였고, 추가의 훈련이 필요하지 않은 것으로 간주될 수 있다. 컴퓨터 디바이스는 다음의 공식 을 통해 제1 유사도, 제2 유사도, 및 제3 유사도에 기초하여 총 손실을 결정 할 수 있다. loss = id loss + 3d feature loss + D loss + G loss ; 여기서, loss는 총 손실을 나타내고, 3d feature loss는 제1 유사도를 나타내고, id loss는 제2 유사도를 나타 내고, (D loss + G loss)는 제3 유사도를 나타낸다. 컴퓨터 디바이스는 단계 내지 단계에 기초하여 초기화된 얼굴 스와핑 모델을 반복적으로 훈련시킬 수 있고, 각각의 반복적 훈련에 대응하는 총 손실을 취득할 수 있고, 각각의 반복적 훈련의 총 손실에 기초하여 초 기화된 얼굴 스와핑 모델의 파라미터를 조절할 수 있다. 예를 들어, 초기화된 얼굴 스와핑 모델에서의 인코더, 디코더, 및 판별기 내에 포함된 파라미터는 총 손실이 타깃 조건을 충족시킬 때까지 다수 회 최적화되고, 컴퓨 터 디바이스는 훈련을 정지시키고, 최종적인 최적화로부터 획득된 모델을 얼굴 스와핑 모델로서 취한다. 타깃 조건은 총 손실의 값이 타깃 수치 범위 내에 있는 것일 수 있다. 타깃 수치 범위는 복수의 실험에 따라 사전설 정된 범위이다. 예를 들어, 총 손실은 0.5 이하의 타깃 수치 범위 내에 있다. 대안적으로, 다수의 반복적 훈련 에 의해 소비된 시간은 최대 시간 길이를 초과한다. 최대 시간 길이는 훈련으로부터 애플리케이션 해제까지의 요구된 시간 길이의 70%이다. 예를 들어, 훈련으로부터 애플리케이션 해제까지의 요구된 시간 길이는 1 시간이 다. 다수의 반복적 훈련에 의해 소비된 시간이 0.7 시간을 초과할 경우에, 그것은 타깃 조건이 충족된다는 것을 지시한다. 도 3은 이 출원의 실시예에 따른 얼굴 스와핑 모델의 훈련 프로세스의 프레임워크의 개략도이다. 도 3에서 도시 된 바와 같이, 컴퓨터 디바이스는 객체 A의 얼굴을 배타적 타깃 얼굴로서 취할 수 있고, 객체 A의 얼굴의 복수 의 자세의 얼굴 이미지를 제1 샘플 이미지로서 취득할 수 있고, 3D 얼굴 파라미터 추정 모델을 통해 제1 샘플 이미지의 속성 파라미터를 추출할 수 있고, 얼굴 인식 모델을 통해 제1 샘플 이미지의 얼굴 특징을 추출할 수 있고, 3D 얼굴 파라미터 추정 모델을 통해 제2 샘플 이미지의 속성 파라미터를 추출할 수 있다. 컴퓨터 디바이 스는 제1 샘플 이미지의 얼굴 특징 및 형상 계수 및 제2 샘플 이미지의 (표정 계수 및 각도 계수와 같은) 사전- 구성 파라미터를 샘플 속성 파라미터로 통합한다. 컴퓨터 디바이스는 제2 샘플 이미지를 초기화된 얼굴 스와핑 모델로 입력할 수 있다. 초기화된 얼굴 스와핑 모델은 인코더 및 디코더를 포함할 수 있다. 컴퓨터 디바이스는 제2 샘플 이미지의 인코딩 특징을 획득하기 위하여 인코더를 통해 제2 샘플 이미지를 인코딩할 수 있다. 예를 들어, 제2 샘플 이미지는 대응하는 특징 벡터로서 인코딩된다. 컴퓨터 디바이스는 샘플 속성 파라미터 및 제2 샘플 이미지의 인코딩 특징에 기초하여 샘플 융합 특징을 획득하고, 샘플 융합 특징을 초기화된 얼굴 스와핑 모 델 내의 디코더로 주입한다. 디코더는 주입된 특징에 기초하여 주입된 특징에 대응하는 이미지를 복원할 수 있 다. 컴퓨터 디바이스는 샘플 얼굴-스와핑된 이미지를 획득하기 위하여 디코더를 통해 샘플 융합 이미지를 디코 딩한다. 예를 들어, 디코더는 샘플 융합 특징에 대응하는 이미지를 복원하기 위하여 인코더의 동작 원리에 따라 디컨볼루션 동작을 수행할 수 있다. 컴퓨터 디바이스는 멀티-스케일 판별기를 통해 제3 유사도를 취득하고, 샘플 얼굴-스와핑된 이미지의 추출된 얼 굴 특징 및 추출된 속성 파라미터에 기초하여 제1 유사도 및 제2 유사도를 취득하고, 총 손실에 따라 모델 파라 미터를 최적화하기 위하여 제1 유사도, 제2 유사도, 및 제3 유사도에 기초하여 총 손실을 계산한다. 컴퓨터 디 바이스는 위의 프로세스를 통해 반복적 훈련을 수행하고, 임의의 이미지 내의 얼굴을 배타적 타깃 얼굴로 교체 할 수 있는 얼굴 스와핑 모델을 획득하기 위하여, 타깃 조건이 충족될 때까지 훈련을 정지시킨다. 도 4는 이 출원의 실시예에 따른 이미지 프로세싱 방법의 시그널링 상호작용 도면이다. 도 4에서 도시된 바와 같이, 이미지 프로세싱 방법은 서버와 단말 사이의 상호작용을 통해 실현될 수 있다. 이미지 프로세싱 방법의 상호작용 프로세스는 단계 내지 단계를 참조하여 획득될 수 있다. 단계: 단말은 타깃 애플리케이션의 애플리케이션 페이지를 디스플레이하고, 애플리케이션 페이지는 타깃 트리거 제어부를 포함하고, 타깃 트리거 제어부는 스와핑 대상 이미지에 대한 얼굴 스와핑 요청을 트리거링하도록 구성된다. 타깃 애플리케이션은 얼굴 스와핑 기능을 제공할 수 있다. 얼굴 스와핑 기능은 배타적 타깃 얼굴에 대한 스와핑 대상 이미지 내의 얼굴을 스와핑하는 기능일 수 있다. 타깃 트리거 제어부는 타깃 애플리케이션의 애플리케이션 페이지 상에서 제공될 수 있다. 단말은 타깃 트리거 제어부 상의 객체의 트리거 동작에 기초하여 얼굴 스와핑 요청을 서버로 송신할 수 있다. 예를 들어, 타깃 애플리케이션은 이미지 프로세싱 애플리케이션, 라이브 스트리 밍 애플리케이션, 사진 툴, 비디오 편집 애플리케이션 등일 수 있다. 서버는 타깃 애플리케이션을 위한 백-엔드 서버(back-end server)일 수 있거나, 서버는 얼굴 스와핑 모델이 제공된 클라우드 컴퓨팅 센터 디바이스와 같은, 얼굴 스와핑 기능을 제공하기 위하여 이용된 임의의 컴퓨터 디바이스일 수 있다. 단계: 단말은 애플리케이션 페이지 상에서 타깃 트리거 제어부에 대한 트리거 동작을 수신하는 것에 응답 하여 스와핑 대상 이미지를 취득하고, 스와핑 대상 이미지에 기초하여 얼굴 스와핑 요청을 서버로 송신한다. 일부 실시예에서, 타깃 애플리케이션은 단일 이미지에 대한 얼굴 스와핑 기능을 제공할 수 있다. 예를 들어, 타 깃 애플리케이션은 이미지 프로세싱 애플리케이션, 라이브 스트리밍 애플리케이션, 소셜 애플리케이션 등일 수 있다. 스와핑 대상 이미지는 로컬 저장 공간으로부터 단말에 의해 취득되는 선택된 이미지, 또는 단말에 의해 취득되고 실시간으로 객체를 촬영함으로써 획득된 이미지일 수 있다. 일부 실시예에서, 타깃 애플리케이션은 비 디오 내에 포함된 각각의 이미지 프레임의 얼굴을 스와핑하는 기능을 제공할 수 있다. 예를 들어, 타깃 애플리 케이션은 비디오 편집 애플리케이션, 라이브 스트리밍 애플리케이션 등일 수 있다. 서버는 객체 A의 얼굴을 포 함하는 이미지 프레임을 타깃 얼굴로 전체적으로 교체할 수 있다. 스와핑 대상 이미지는 비디오 내의 각각의 이 미지 프레임을 포함할 수 있거나, 단말은 비디오 내의 각각의 이미지 프레임에 대해 초기 얼굴 검출을 수행할 수 있고, 비디오 내의 객체 A의 얼굴을 포함하는 각각의 이미지 프레임을 스와핑 대상 이미지로서 취할 수 있다. 단계: 서버는 단말에 의해 송신된 얼굴 스와핑 요청을 수신한다. 단계: 서버는 스와핑 대상 이미지의 속성 파라미터, 타깃 얼굴의 속성 파라미터, 및 타깃 얼굴의 얼굴 특 징을 취득하고 - 스와핑 대상 이미지의 속성 파라미터는 스와핑 대상 이미지 내의 얼굴의 3차원 속성을 지시함 -; 스와핑 대상 이미지의 속성 파라미터 및 타깃 얼굴의 속성 파라미터에 기초하여 타깃 속성 파라미터를 결정 한다. 얼굴 스와핑 요청은 스와핑 대상 이미지 내의 얼굴을 타깃 얼굴로 교체하는 것을 요청하기 위하여 이용된다. 스 와핑 대상 이미지의 속성 파라미터는 스와핑 대상 이미지 내의 얼굴의 3 차원 속성을 지시하기 위하여 이용된다. 서버는 3D 얼굴 파라미터 추정 모델을 통해 스와핑 대상 이미지의 속성 파라미터를 취득할 수 있다. 이미지의 속성 파라미터는 형상 계수, 표정 계수, 각도 계수, 질감 계수, 및 조명 계수 중의 적어도 하나를 포 함한다. 타깃 얼굴의 속성 파라미터 및 타깃 얼굴의 얼굴 특징은 사전-저장될 수 있다. 일부 실시예에서, 서버는 타깃 얼굴의 형상 계수 및 스와핑 대상 이미지의 사전-구성 파라미터가 타깃 속성 파 라미터인 것으로 결정할 수 있다. 사전-구성 파라미터는 표정 계수, 각도 계수, 질감 계수, 및 조명 계수 중의 적어도 하나를 포함한다. 예를 들어, 사전-구성 파라미터는 표정 계수 및 각도 계수를 포함할 수 있다. 대안적 으로, 사전-구성 파라미터는 질감 계수, 조명 계수 등을 포함할 수 있다. 단계: 서버는 타깃 속성 파라미터 및 타깃 얼굴의 얼굴 특징에 기초하여 타깃 종합 특징을 결정한다. 서버는 타깃 종합 특징을 획득하기 위하여 타깃 속성 파라미터 및 타깃 얼굴의 얼굴 특징을 스프라이싱할 수 있 다. 서버에는 훈련된 얼굴 스와핑 모델이 제공될 수 있다는 것이 주목되어야 한다. 서버는 얼굴 스와핑 모델을 통해 단계로부터 단계까지의 프로세스를 수행할 수 있다. 얼굴 스와핑 모델은 단계 내지 단계에 기초한 훈련에 의해 획득된다. 서버는 타깃 얼굴의 얼굴 특징 및 속성 파라미터를 예를 들어, 얼굴 스와핑 모델 의 훈련에서의 타깃 어드레스로 고정적으로 저장할 수 있다. 단계 및 단계를 수행할 때, 서버는 타깃 어드레스로부터 타깃 얼굴의 속성 파라미터를 추출할 수 있고, 단계를 수행할 수 있고, 서버는 타깃 어드 레스로부터 타깃 얼굴의 얼굴 특징을 추출하고, 단계를 수행한다. 서버는 얼굴 스와핑 모델을 통해 단계 로부터 단계까지의 프로세스를 수행할 수 있다. 단계: 서버는 스와핑 대상 이미지의 이미지 인코딩 특징을 획득하기 위하여 스와핑 대상 이미지를 인코딩 한다.단계: 융합 인코딩 특징을 획득하기 위하여 정규화에 의해 타깃 종합 특징을 스와핑 대상 이미지의 이미지 인코딩 특징으로 마이그레이팅함. 가능한 구현예에서, 컴퓨터 디바이스는 이미지 인코딩 특징의 평균 및 표준 편차를 타깃 종합 특징과 정렬할 수 있다. 단계는 다음의 기술적 해결책을 통해 구현될 수 있다: 서버는 제1 평균 및 제1 표준 편차를 준수하 는 정규 분포를 제1 특징 분포로서 취하기 위하여 적어도 하나의 특징 채널 내의 이미지 인코딩 특징의 제1 평 균 및 제1 표준 편차를 취득하고, 제2 평균 및 제2 표준 편차를 준수하는 정규 분포를 제2 특징 분포로서 취하 기 위하여 적어도 하나의 특징 채널 내의 타깃 종합 특징의 제2 평균 및 제2 표준 편차를 취득한다. 서버는 융 합 인코딩 특징을 획득하기 위하여 제1 특징 분포로부터의 이미지 인코딩 특징을 제2 특징 분포로 정렬한다. 구 체적으로, 서버는 각각의 특징 채널 내의 이미지 인코딩 특징의 평균 및 표준 편차가 대응하는 특징 채널 내의 타깃 종합 특징의 평균 및 표준 편차와 정렬되게 하기 위하여 이미지 인코딩 특징을 맵핑하여, 융합 인코딩 특 징을 획득한다. 예를 들어, 서버는 또한, 단계에서의 공식 을 이용함으로써 융합 인코딩 특징을 계산할 수 있다. 단계: 서버는 융합 얼굴을 포함하는 타깃 얼굴-스와핑된 이미지를 획득하기 위하여 융합 인코딩 특징을 디 코딩하고, 융합 얼굴은 스와핑 대상 이미지 내의 얼굴 및 타깃 얼굴의 융합이다. 서버가 타깃 얼굴-스와핑된 이미지를 획득하기 위하여 단계 내지 단계를 수행하는 구현 방식은, 컴퓨 터 디바이스가 샘플 얼굴-스와핑된 이미지를 획득하기 위하여 단계 내지 단계를 수행하는 구현 방식 과 유사하다. 세부사항은 본 명세서에서 다시 설명되지 않는다. 단계: 서버는 타깃 얼굴-스와핑된 이미지를 단말로 반환한다. 스와핑 대상 이미지가 단일 이미지일 때, 서버는 단일 스와핑 대상 이미지에 대응하는 타깃 얼굴-스와핑된 이미 지를 단말로 반환할 수 있다. 스와핑 대상 이미지가 비디오 내에 포함된 복수의 이미지 프레임일 때, 서버는 단 계 내지 단계를 통해, 비디오 내의 각각의 스와핑 대상 이미지 프레임에 대하여, 스와핑 대상 이미지 프레임에 대응하는 타깃 얼굴-스와핑된 이미지를 생성할 수 있다. 서버는 비디오에 대응하는 얼굴-스와핑된 비 디오를 단말로 반환할 수 있다. 얼굴-스와핑된 비디오는 각각의 이미지 프레임에 대응하는 타깃 얼굴-스와핑된 이미지를 포함한다. 단계: 단말은 서버에 의해 반환된 타깃 얼굴-스와핑된 이미지를 수신하고, 타깃 얼굴-스와핑된 이미지를 디스플레이한다. 단말은 애플리케이션 페이지 상에서 타깃 얼굴-스와핑된 이미지를 디스플레이할 수 있다. 대안적으로, 단말은 애플리케이션 페이지 상에서 얼굴-스와핑된 비디오 내의 각각의 타깃 얼굴-스와핑된 이미지를 플레이할 수 있다. 이 출원의 이 실시예에 따른 이미지 프로세싱 방법에서, 스와핑 대상 이미지의 속성 파라미터가 취득되고, 속성 파라미터는 이미지 내의 얼굴의 3 차원 속성 특징을 지시하기 위하여 이용되고, 타깃 속성 파라미터는 스와핑 대상 이미지의 속성 파라미터 및 타깃 얼굴의 속성 파라미터에 기초하여 결정되어, 생성되는 것으로 예상된 이 미지 내에 얼굴의 3 차원 속성 특징이 위치결정된다. 또한, 스와핑 대상 이미지 및 타깃 얼굴을 종합적으로 나 타낼 수 있는 타깃 종합 특징은 타깃 속성 파라미터 및 타깃 얼굴의 얼굴 특징에 기초하여 획득된다. 스와핑 대 상 이미지는 스와핑 대상 이미지의 이미지 인코딩 특징을 획득하기 위하여 인코딩되어, 이미지 인코딩 특징을 통해 스와핑 대상 이미지의 픽셀-레벨 정제된 특징이 획득된다. 또한, 타깃 종합 특징은 융합 인코딩 특징을 획 득하기 위하여 정규화에 의해 스와핑 대상 이미지의 이미지 인코딩 특징으로 마이그레이팅된다. 이 출원에서, 픽셀 레벨로 정제된 인코딩 특징 및 글로벌 종합 특징이 혼합되고, 이미지 인코딩 특징의 특징 분포가 타깃 종 합 특징과 정렬되어, 생성된 융합 인코딩 특징의 정확도가 개선된다. 융합 인코딩 특징은 융합 얼굴을 포함하는 타깃 얼굴-스와핑된 이미지를 획득하기 위하여 디코딩되고, 디코딩된 이미지는 타깃 종합 특징을 도시하기 위하 여 각각의 픽셀로 정제될 수 있어서, 이로써 디코딩된 이미지 내의 융합 얼굴의 감각 기관이 타깃 얼굴에 더 근 접하고, 이것은 감각 기관의 측면에서 융합 얼굴과 타깃 얼굴 사이의 유사도를 개선시키고, 이에 의해 얼굴 스 와핑의 정확도를 개선시킨다. 도 5는 이 출원의 실시예에 따른 이미지 프로세싱 장치의 개략적인 구조도이다. 도 5에서 도시된 바와 같이, 장 치는 얼굴 스와핑 요청을 수신하도록 구성된 속성 파라미터 취득 모듈 - 얼굴 스와핑 요청은 스와핑 대상 이미지 내의 얼굴을 타깃 얼굴로 교체하는 것을 요청하기 위하여 이용됨 -; 스와핑 대상 이미지의 속성 파라미 터, 타깃 얼굴의 속성 파라미터, 및 타깃 얼굴의 얼굴 특징을 취득하고 - 스와핑 대상 이미지의 속성 파라미터는 스와핑 대상 이미지 내의 얼굴의 3 차원 속성을 지시함 -; 스와핑 대상 이미지의 속성 파라미터 및 타깃 얼 굴의 속성 파라미터에 기초하여 타깃 속성 파라미터를 결정하도록 구성된 타깃 속성 파라미터 결정 모듈; 타깃 속성 파라미터 및 타깃 얼굴의 얼굴 특징에 기초하여 타깃 종합 특징을 결정하도록 구성된 종합 특징 결정 모듈; 스와핑 대상 이미지의 이미지 인코딩 특징을 획득하기 위하여 스와핑 대상 이미지를 인코딩하도록 구성된 인코딩 모듈; 융합 인코딩 특징을 획득하기 위하여 정규화에 의해 타깃 종합 특징을 스와핑 대상 이미지의 이미지 인코딩 특징으로 마이그레이팅하도록 구성된 마이그레이션 모듈; 및 융합 얼굴을 포함하 는 타깃 얼굴-스와핑된 이미지를 획득하기 위하여 융합 인코딩 특징을 디코딩하도록 구성된 디코딩 모듈 - 융합 얼굴은 스와핑 대상 이미지 내의 얼굴 및 타깃 얼굴의 융합임 - 을 포함한다. 일부 실시예에서, 타깃 얼굴의 속성 파라미터는 형상 계수이고, 스와핑 대상 이미지의 속성 파라미터는 사전-구 성 파라미터이다. 타깃 속성 파라미터 결정 모듈은 타깃 얼굴의 형상 계수 및 스와핑 대상 이미지의 사전-구성 파라미터가 타깃 속성 파라미터인 것으로 결정하도록 구성된다. 사전-구성 파라미터는 표정 계수, 각도 계수, 질감 계수, 및 조명 계수 중의 적어도 하나를 포함한다. 일부 실시예에서, 마이그레이션 모듈은 제1 평균 및 제1 표준 편차를 준수하는 정규 분포를 제1 특징 분포로서 취하기 위하여 적어도 하나의 특징 채널 내의 이미지 인코딩 특징의 제1 평균 및 제1 표준 편차를 취득하고, 제 2 평균 및 제2 표준 편차를 준수하는 정규 분포를 제2 특징 분포로서 취하기 위하여 적어도 하나의 특징 채널 내의 타깃 종합 특징의 제2 평균 및 제2 표준 편차를 취득하고; 융합 인코딩 특징을 획득하기 위하여 제1 특징 분포로부터의 이미지 인코딩 특징을 제2 특징 분포로 정렬하도록 구성된다. 일부 실시예에서, 타깃 얼굴-스와핑된 이미지는 훈련된 얼굴 스와핑 모델을 호출함으로써 획득된다. 얼굴 스와 핑 모델은 속성 파라미터 및 타깃 얼굴의 얼굴 특징에 기초하여 타깃 얼굴을 임의의 얼굴 이미지로 스와핑하도 록 구성된다. 장치는 모델 훈련 모듈을 더 포함한다. 모델 훈련 모듈은 제1 샘플 이미지의 얼굴 특징 및 속성 파라미터를 취득하고, 제2 샘플 이미지의 속성 파라미터를 취득하도록 구성된 취득 유닛 - 제1 샘플 이미지는 타깃 얼굴을 포함하고, 제2 샘플 이미지는 교체 대상 얼굴을 포함함 -; 제1 샘플 이미지의 속성 파라미터 및 제 2 샘플 이미지의 속성 파라미터에 기초하여 샘플 속성 파라미터를 결정하도록 구성된 샘플 속성 파라미터 결정 유닛 - 샘플 속성 파라미터는 생성 대상 샘플 얼굴-스와피이된 이미지 내의 얼굴의 예상된 속성을 지시하기 위 하여 이용됨 -; 및 샘플 속성 파라미터 및 제1 샘플 이미지의 얼굴 특징에 기초하여 샘플 종합 특징을 결정하도 록 구성된 샘플 종합 특징 취득 유닛; 샘플 인코딩 특징을 획득하기 위하여 제2 샘플 이미지를 인코딩하도록 구 성된 인코딩 유닛; 샘플 융합 특징을 획득하기 위하여 샘플 종합 특징을 제2 샘플 이미지의 샘플 인코딩 특징으 로 마이그레이팅하도록 구성된 마이그레이션 유닛; 샘플 얼굴-스와핑된 이미지를 획득하기 위하여 샘플 융합 특 징을 디코딩하도록 구성된 디코딩 유닛; 및 샘플 얼굴-스와핑된 이미지와 샘플 속성 파라미터 사이의 제1 차이, 샘플 얼굴-스와핑된 이미지의 얼굴 특징과 제1 샘플 이미지의 얼굴 특징 사이의 제2 차이, 및 샘플 얼굴-스와핑 된 이미지와 제2 샘플 이미지 사이의 제3 차이에 기초하여 초기화된 얼굴 스와핑 모델의 총 손실을 결정하고; 타깃 조건이 충족될 때까지 총 손실에 기초하여 초기화된 얼굴 스와핑 모델을 훈련시키고, 타깃 조건이 충족되 는 것에 응답하여 획득된 모델을 얼굴 스와핑 모델로서 취하도록 구성된 훈련 유닛을 포함한다. 일부 실시예에서, 훈련 유닛은, 샘플 얼굴-스와핑된 이미지의 속성 파라미터와 샘플 속성 파라미터 사이의 제1 유사도를 취득하고, 제1 유사도를 제1 차이로서 취하고; 샘플-얼굴 스와핑된 이미지의 얼굴 특징과 제1 샘플 이 미지의 얼굴 특징 사이의 제2 유사도를 취득하고, 제2 유사도를 제2 차이로서 취하고; 제1 샘플 이미지와 샘플 얼굴-스와핑된 이미지 사이의 제3 유사도를 취득하고, 제3 유사도를 제3 차이로서 취하도록 추가로 구성된다. 일부 실시예에서, 훈련 유닛은, 적어도 하나의 스케일에서의 제2 샘플 이미지의 제1 스케일 이미지 및 적어도 하나의 스케일에서의 샘플 얼굴-스와핑된 이미지의 제2 스케일 이미지를 취득하고; 제2 샘플 이미지를 실제의 이미지로서 취하고; 제1 스케일 이미지들의 각각에 대응하는 판별 확률을 취득하고, 제2 스케일 이미지들의 각 각에 대응하는 판별 확률을 취득하고 - 이미지의 판별 확률은 이미지가 실제의 이미지인 것으로 결정할 확률을 지시하기 위하여 이용되고, 이미지는 제1 스케일 이미지 또는 제2 스케일 이미지임 -; 제1 스케일 이미지들의 각각에 대응하는 판별 확률 및 제2 스케일 이미지들의 각각에 대응하는 판별 확률에 기초하여 제3 유사도를 결 정하도록 추가로 구성된다. 일부 실시예에서, 취득 유닛은, 적어도 2개의 자세 이미지를 취득하고, 적어도 2개의 자세 이미지를 제1 샘플 이미지로서 취하고 - 적어도 2개의 자세 이미지는 타깃 얼굴의 적어도 2개의 얼굴 자세를 포함함 -; 적어도 2개 의 자세 이미지에 기초하여 적어도 2개의 얼굴 자세에 대응하는 얼굴 특징 및 속성 파라미터를 취득하고; 적어 도 2개의 얼굴 자세에 대응하는 얼굴 특징의 평균을 제1 샘플 이미지의 얼굴 특징으로서 취하고, 적어도 2개의얼굴 자세에 대응하는 속성 파라미터의 평균을 제1 샘플 이미지의 속성 파라미터로서 취하도록 추가로 구성된다. 이에 따라, 장치는 저장 유닛을 더 포함한다. 저자 유닛은 제1 샘플 이미지의 얼굴 특징 및 속성 파라미터를 저 장하도록 구성된다. 일부 실시예에서, 취득 유닛은 타깃 얼굴 내에 포함된 적어도 2개의 이미지 프레임을 획득하기 위하여 타깃 객 체의 비디오 내에 포함된 적어도 2개의 이미지 프레임에 대해 얼굴 인식을 수행하고 - 타깃 얼굴은 타깃 객체의 얼굴임 -; 적어도 2개의 자세 이미지를 획득하기 위하여 적어도 2개의 이미지 프레임에 대해 얼굴 크롭핑을 수 행하도록 추가로 구성된다. 이 출원의 이 실시예에 따른 이미지 프로세싱 장치에서, 스와핑 대상 이미지의 속성 파라미터가 취득되고, 속성 파라미터는 이미지 내의 얼굴의 3 차원 속성 특징을 지시하기 위하여 이용되고, 타깃 속성 파라미터는 스와핑 대상 이미지의 속성 파라미터 및 타깃 얼굴의 속성 파라미터에 기초하여 결정되어, 생성되는 것으로 예상된 이 미지 내에 얼굴의 3 차원 속성 특징이 위치결정된다. 또한, 스와핑 대상 이미지 및 타깃 얼굴을 종합적으로 나 타낼 수 있는 타깃 종합 특징은 타깃 속성 파라미터 및 타깃 얼굴의 얼굴 특징에 기초하여 획득된다. 스와핑 대 상 이미지는 스와핑 대상 이미지의 이미지 인코딩 특징을 획득하기 위하여 인코딩되어, 이미지 인코딩 특징을 통해 스와핑 대상 이미지의 픽셀-레벨 정제된 특징이 획득된다. 또한, 타깃 종합 특징은 융합 인코딩 특징을 획 득하기 위하여 정규화에 의해 스와핑 대상 이미지의 이미지 인코딩 특징으로 마이그레이팅된다. 이 출원에서, 픽셀 레벨로 정제된 인코딩 특징 및 글로벌 종합 특징이 혼합되고, 이미지 인코딩 특징의 특징 분포가 타깃 종 합 특징과 정렬되고, 이에 의해, 생성된 융합 인코딩 특징의 정확도가 개선된다. 융합 인코딩 특징은 융합 얼굴 을 포함하는 타깃 얼굴-스와핑된 이미지를 획득하기 위하여 디코딩되고, 디코딩된 이미지는 타깃 종합 특징을 도시하기 위하여 각각의 픽셀로 정제될 수 있어서, 이로써 디코딩된 이미지 내의 융합 얼굴의 감각 기관이 타깃 얼굴에 더 근접하고, 이것은 감각 기관의 측면에서 융합 얼굴과 타깃 얼굴 사이의 유사도를 개선시키고, 이에 의해 얼굴 스와핑의 정확도를 개선시킨다. 이 출원의 실시예에서의 장치는 구현 원리에 있어서 유사한 이 출원의 실시예에 따른 이미지 프로세싱 방법을 수행할 수 있다. 이 출원의 실시예에서의 장치 내의 모듈에 의해 수행된 동작은 이 출원의 실시예에 따른 이미 지 프로세싱 방법에서의 단계에 대응한다. 장치의 모듈의 상세한 기능 설명은 대응하는 위에서의 이미지 프로세 싱 방법에서의 설명을 참조하여 구체적으로 획득될 수 있다. 세부사항은 본 명세서에서 다시 설명되지 않는다. 도 6은 이 출원의 실시예에 따른 컴퓨터 디바이스의 개략적인 구조도이다. 도 6에서 도시된 바와 같이, 컴퓨터 디바이스는 메모리, 프로세서, 및 메모리 내에 저장된 컴퓨터 프로그램을 포함하고, 프로세서는 이미지 프로세 싱 방법의 단계를 구현하기 위하여 위의 컴퓨터 프로그램을 실행한다. 이 출원의 이 실시예에 따른 이미지 프로세싱 장치에서, 스와핑 대상 이미지의 속성 파라미터가 취득되고, 속성 파라미터는 이미지 내의 얼굴의 3 차원 속성 특징을 지시하기 위하여 이용되고, 타깃 속성 파라미터는 스와핑 대상 이미지의 속성 파라미터 및 타깃 얼굴의 속성 파라미터에 기초하여 결정되어, 생성되는 것으로 예상된 이 미지 내에 얼굴의 3 차원 속성 특징이 위치결정된다. 또한, 스와핑 대상 이미지 및 타깃 얼굴을 종합적으로 나 타낼 수 있는 타깃 종합 특징은 타깃 속성 파라미터 및 타깃 얼굴의 얼굴 특징에 기초하여 획득된다. 스와핑 대 상 이미지는 스와핑 대상 이미지의 이미지 인코딩 특징을 획득하기 위하여 인코딩되어, 이미지 인코딩 특징을 통해 스와핑 대상 이미지의 픽셀-레벨 정제된 특징이 획득된다. 또한, 타깃 종합 특징은 융합 인코딩 특징을 획 득하기 위하여 정규화에 의해 스와핑 대상 이미지의 이미지 인코딩 특징으로 마이그레이팅된다. 이 출원에서, 픽셀 레벨로 정제된 인코딩 특징 및 글로벌 종합 특징이 혼합되고, 이미지 인코딩 특징의 특징 분포가 타깃 종 합 특징과 정렬되어, 생성된 융합 인코딩 특징의 정확도가 개선된다. 융합 인코딩 특징은 융합 얼굴을 포함하는 타깃 얼굴-스와핑된 이미지를 획득하기 위하여 디코딩되고, 디코딩된 이미지는 타깃 종합 특징을 도시하기 위하 여 각각의 픽셀로 정제될 수 있어서, 이로써 디코딩된 이미지 내의 융합 얼굴의 감각 기관이 타깃 얼굴에 더 근 접하고, 이것은 감각 기관의 측면에서 융합 얼굴과 타깃 얼굴 사이의 유사도를 개선시키고, 이에 의해 얼굴 스 와핑의 정확도를 개선시킨다. 예시적인 실시예에서는, 컴퓨터 디바이스가 제공된다. 도 6에서 도시된 바와 같이, 도 6에서 도시된 컴퓨터 디 바이스는 프로세서 및 메모리를 포함한다. 프로세서 및 메모리는 예를 들어, 버스 에 의해 접속된다. 임의적으로, 컴퓨터 디바이스는 트랜시버를 더 포함할 수 있다. 트랜시버 는 데이터 송신 및/또는 데이터 수신과 같은, 컴퓨터 디바이스와 또 다른 컴퓨터 디바이스 사이의 데이터 교환을 위하여 구성될 수 있다. 실제적인 애플리케이션 동안에, 하나 이상의 트랜시버가 있을 수 있다는것이 주목되어야 한다. 컴퓨터 디바이스의 구조는 이 출원의 이 실시예에 대한 제한을 구성하지 않는다. 프로세서는 중앙 프로세싱 유닛(CPU : central processing unit), 범용 프로세서, 데이터 신호 프로세서 (DSP : data signal processor), 애플리케이션 특정 집적 회로(ASIC : application specific integrated circuit), 필드 프로그래밍가능 게이트 어레이(FPGA : field programmable gate array) 또는 또 다른 프로그래 밍가능 로직 디바이스, 트랜지스터 로직 디바이스, 하드웨어 컴포넌트, 또는 그 임의의 조합일 수 있다. 프로세 서는 이 출원에서 개시된 내용을 참조하여 설명된 로직 블록, 모듈, 및 회로의 다양한 예를 구현하거나 수행할 수 있다. 프로세서는 또한, 예를 들어, 하나 이상의 마이크로프로세서의 조합, 또는 DSP 및 마이크로프로 세서의 조합을 포함하는, 컴퓨팅 기능을 구현하는 조합일 수 있다. 버스는 상기한 컴포넌트 사이에서 정보를 송신하기 위한 채널을 포함할 수 있다. 버스는 주변 컴포넌 트 상호접속(PCI : peripheral component interconnect) 버스, 확장된 산업 표준 아키텍처(EISA : extended industry standard architecture) 버스 등일 수 있다. 버스는 어드레스 버스, 데이터 버스, 제어 버스 등 으로 분류될 수 있다. 설명의 용이함을 위하여, 도 6에서의 버스는 오직 하나의 굵은 라인을 이용함으로써 표현 되지만, 이것은 오직 하나의 버스 또는 하나의 유형의 버스가 있다는 것을 지시하지는 않는다. 메모리는 정적 정보 및 명령을 저장할 수 있는 판독-전용 메모리(ROM : read-only memory) 또는 또 다른 유형의 정적 저장 디바이스, 정보 및 명령을 저장할 수 있는 랜덤 액세스 메모리(RAM : random access memory) 또는 또 다른 유형의 동적 저장 디바이스일 수 있거나, 전기적 소거가능 프로그래밍가능 판독-전용 메모리 (EEPROM : electrically erasable programmable read-only memory), 컴팩트 디스크 판독-전용 메모리(CD-ROM : compact disc read-only memory), 또는 다른 컴팩트 디스크 스토리지 또는 (압축된 광학 디스크, 레이저 디스크, 광학 디스크, 디지털 유니버셜 광학 디스크, 블루-레이 광학 디스크 등을 포함하는) 광학 디스크 스토 리지, 자기 디스크 저장 매체/또 다른 자기 저장 디바이스, 또는 컴퓨터 프로그램을 운반하거나 저장할 수 있고 컴퓨터에 의해 판독될 수 있는 임의의 다른 매체일 수 있지만, 이것으로 제한되지는 않는다. 메모리는 이 출원의 실시예를 수행하기 위한 컴퓨터 프로그램을 저장하도록 구성되고, 프로세서의 제 어 하에서 실행된다. 프로세서는 상기한 방법 실시에에서 도시된 단계를 구현하기 위하여 메모리 내 에 저장된 컴퓨터 프로그램을 실행하도록 구성된다. 컴퓨터 디바이스는 서버, 클라우드 컴퓨팅 센터 디바이스 등을 포함하지만, 이것으로 제한되지는 않는다. 이 출원의 실시예는 컴퓨터 프로그램을 저장하는 컴퓨터-판독가능 저장 매체를 제공하고, 컴퓨터 프로그램은, 프로세서에 의해 실행될 때, 상기한 방법 실시예에서 도시된 단계 및 대응하는 내용을 구현한다. 이 출원의 실시예는 컴퓨터 프로그램을 포함하는 컴퓨터 프로그램 제품을 제공하고, 컴퓨터 프로그램은, 프로세 서에 의해 실행될 때, 상기한 방법 실시예에서 도시된 단계 및 대응하는 내용을 구현한다."}
{"patent_id": "10-2022-7040870", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "본 기술분야에서의 통상의 기술자는 본 명세서에서 이용된 단수 형태 \"a\", \"an\", \"said\", 및 \"the\"는 문맥이 이 와 다르게 명확하게 지시하지 않으면, 복수 형태를 마찬가지로 포함할 수 있다는 것을 이해할 수 있다. 이 출원 의 실시예에서 이용된 용어 \"포함한다(comprise)\" 및 \"포함한다(include)\"는 기술적 분야에 의해 지원된 다른 특징, 정보, 데이터, 단계, 및 동작을 배제하지 않으면서, 제시된 특징, 정보, 데이터, 단계, 및 동작으로서 실 현될 수 있다. 이 출원의 명세서 및 청구범위에서 그리고 첨부 도면에서 (만약 존재한다면) \"제1(first)\", \"제2(second)\", \"제 3(third)\", \"제4(fourth)\", \"1\", 및 \"2\"와 같은 용어는 유사한 객체를 구별하기 위하여 이용되고, 반드시, 임의 의 특정한 순서 또는 시퀀스를 설명하기 위하여 이용되지는 않는다. 이러한 이용된 데이터는 적절한 상황에서 상호교환가능하여, 이로써 본 명세서에서 설명된 이 출원의 실시예는 단어로 예시되거나 설명된 것 이외의 순서 로 구현될 수 있다는 것이 이해된다. 동작 단계가 이 출원의 실시예의 흐름도에서 화살표에 의해 지시되지만, 단계는 반드시 화살표에 의해 순서대로 수행되는 것은 아니라는 것이 이해되어야 한다. 본 명세서에서 구체적으로 기재되지 않으면, 각각의 흐름도에서 의 구현 단계는 이 출원의 실시예의 일부 구현 시나리오에서 요구된 바와 같은 다른 순서로 수행될 수 있다. 추 가적으로, 각각의 흐름도에서의 단계의 일부 또는 전부는 실제적인 구현 시나리오에 기초하고, 복수의 하위-단 계 또는 국면을 포함할 수 있다. 하위-단계 또는 국면의 일부 또는 전부는 동시에 수행될 수 있다. 하위-단계 또는 국면의 각각은 또한, 상이한 시간에 수행될 수 있다. 상이한 실행 시간의 시나리오에서, 하위-단계 또는 국면의 실행 순서는 요구된 바와 같이 신축적으로 구성될 수 있고, 이것은 이 출원의 실시예에서 제한되지 않는다."}
{"patent_id": "10-2022-7040870", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "상기한 설명은 이 출원의 일부 구현 시나리오의 단지 예시적인 구현예이다. 본 기술분야에서의 통상의 기술자는 이 출원의 실시예의 보호 범위 내에 또한 속하는 이 출원의 해결책의 기술적 개념으로부터 이탈하지 않으면서, 이 출원의 기술적 사상에 기초하여 다른 유사한 구현 수단을 채택할 수 있다."}
{"patent_id": "10-2022-7040870", "section": "도면", "subsection": "도면설명", "item": 1, "content": "이 출원의 실시예에서의 기술적 해결책을 더 명확하게 설명하기 위하여, 다음은 이 출원의 실시예를 설명하기 위하여 요구된 첨부 도면을 간략하게 설명한다. 도 1은 이 출원의 실시예에 따른 이미지 프로세싱 방법의 구현 환경의 개략도이다. 도 2는 이 출원의 실시예에 따른 얼굴 스와핑 모델 훈련 방법에 대한 훈련 방법의 개략적인 흐름도이다. 도 3은 이 출원의 실시예에 따른 얼굴 스와핑 모델의 훈련 프로세스의 프레임워크의 개략도이다. 도 4는 이 출원의 실시예에 따른 이미지 프로세싱 방법의 시그널링 상호작용 도면이다. 도 5는 이 출원의 실시예에 따른 이미지 프로세싱 장치의 개략적인 구조도이다. 도 6은 이 출원의 실시예에 따른 컴퓨터 디바이스의 개략적인 구조도이다."}
