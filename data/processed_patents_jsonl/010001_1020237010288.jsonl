{"patent_id": "10-2023-7010288", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0048157", "출원번호": "10-2023-7010288", "발명의 명칭": "자율 주행을 위한 데이터 파이프 라인 및 딥 러닝 시스템", "출원인": "테슬라, 인크.", "발명자": "우바로프, 티모페이"}}
{"patent_id": "10-2023-7010288", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "방법에 있어서,차량 상의 센서를 사용하여 캡처된 이미지를 수신하는 단계;입력 데이터를 형성하는 상기 이미지로부터 글로벌 데이터 구성요소 및 특징 데이터 구성요소를 추출하는 단계- 상기 글로벌 데이터 구성요소는 글로벌 조명 데이터와 연관되고, 상기 특징 데이터 구성요소는 에지 데이터와연관됨 -;복수의 계층들을 포함하는 컨볼루션 신경망(CNN)에게 상기 입력 데이터를 제공하는 단계; 및상기 컨볼루션 신경망(CNN)의 결과에 기초하여, 상기 차량의 자율적 작동을 알려주는 차량 제어 결과를 나타내는 정보를 획득하는 단계를 포함하고,상기 복수의 계층들은,순차적(sequential)이고, 상기 컨볼루션 신경망(CNN)의 각 부분들을 형성하고,상기 특징 데이터 구성요소는,상기 복수의 계층들 중 제1 계층으로의 입력으로 제공되고,상기 글로벌 데이터 구성요소 및 이전 계층으로부터의 중간 결과 출력은,상기 복수의 계층들 중 제2 계층으로의 입력으로 제공되고,상기 제2 계층은,상기 제1 계층의 후속 계층인방법."}
{"patent_id": "10-2023-7010288", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,추출에 후속하여, 상기 글로벌 데이터 구성요소는 다운샘플링되고,상기 다운샘플링된 글로벌 데이터 구성요소는 상기 제2 계층으로의 입력으로 제공되는방법."}
{"patent_id": "10-2023-7010288", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 추출된 글로벌 데이터 구성요소에 노이즈 제거 필터가 적용되는방법."}
{"patent_id": "10-2023-7010288", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "공개특허 10-2023-0048157-3-제1항에 있어서,상기 글로벌 데이터 구성요소는 저역 통과 필터를 통하여 추출되는방법."}
{"patent_id": "10-2023-7010288", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서,상기 특징 데이터 구성요소는 고역 통과 필터를 통하여 추출되는방법."}
{"patent_id": "10-2023-7010288", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서,노이즈 제거(de-noising), 디모자이킹(demosaicing), 국부 대비 향상(local contrast enhancement), 이득 조정(gain adjustment) 및 스레시홀딩(thresholding) 처리 중 하나 이상이 상기 입력 데이터의 적어도 부분 상에 수행되는방법."}
{"patent_id": "10-2023-7010288", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에 있어서,상기 제1 계층은,상기 컨볼루션 신경망(CNN)의 초기 계층(initial layer)인방법."}
{"patent_id": "10-2023-7010288", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1항에 있어서,제3 데이터 구성요소는,대역 통과 필터를 통하여 상기 이미지로부터 추출되고,상기 제3 데이터 구성요소는,상기 입력 데이터의 부분을 형성하는방법."}
{"patent_id": "10-2023-7010288", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서,상기 제3 데이터 구성요소는,상기 컨볼루션 신경망(CNN)의 제3 계층에 제공되고,상기 제3 계층은,공개특허 10-2023-0048157-4-상기 제1 계층의 후속 계층이고, 상기 제2 계층의 이전 계층인방법."}
{"patent_id": "10-2023-7010288", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제1항에 있어서,상기 차량 제어 결과는,제동, 조향, 차선 변경, 가속 및 다른 차선으로의 합류 중 하나 이상과 연관되는방법."}
{"patent_id": "10-2023-7010288", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "컴퓨터 판독가능 기록매체에 저장된 컴퓨터 프로그램에 있어서,하나 이상의 프로세서에 의하여 실행되는 경우, 제1항 내지 제10항 중 어느 한 항의 방법을 실행하는컴퓨터 판독가능 기록매체에 저장된 컴퓨터 프로그램."}
{"patent_id": "10-2023-7010288", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "시스템에 있어서,차량 상의 복수의 센서들;하나 이상의 프로세서; 및컴퓨터 판독가능 기록매체를 포함하고,상기 컴퓨터 판독가능 기록매체는,상기 하나 이상의 프로세서에 의하여 실행되는 경우, 상기 프로세서로 하여금,상기 센서들 중 적어도 하나로부터 적어도 하나의 이미지를 수신하고,입력 데이터를 형성하는 상기 적어도 하나의 이미지로부터 글로벌 데이터 구성요소 및 특징 데이터 구성요소를추출하고 - 상기 글로벌 데이터 구성요소는 글로벌 조명 데이터와 연관되고, 상기 특징 데이터 구성요소는 에지데이터와 연관됨 -,복수의 계층들을 포함하는 컨볼루션 신경망(CNN)에게 상기 입력 데이터를 제공하고,상기 컨볼루션 신경망(CNN)의 결과에 기초하여, 상기 차량의 자율적 작동을 알려주는 차량 제어 결과를 나타내는 정보를 획득하도록 하고,상기 복수의 계층들은,순차적(sequential)이고, 상기 컨볼루션 신경망(CNN)의 각 부분들을 형성하고,상기 특징 데이터 구성요소는,상기 복수의 계층들 중 제1 계층으로의 입력으로 제공되고,상기 글로벌 데이터 구성요소 및 이전 계층으로부터의 중간 결과 출력은,상기 복수의 계층들 중 제2 계층으로의 입력으로 제공되고,상기 제2 계층은,공개특허 10-2023-0048157-5-상기 제1 계층의 후속 계층인시스템."}
{"patent_id": "10-2023-7010288", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제12항에 있어서,추출에 후속하여, 상기 글로벌 데이터 구성요소는 다운샘플링되고,상기 다운샘플링된 글로벌 데이터 구성요소는 상기 제2 계층으로의 입력으로 제공되는시스템."}
{"patent_id": "10-2023-7010288", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제12항에 있어서,상기 글로벌 데이터 구성요소는 저역 통과 필터를 통하여 추출되는시스템."}
{"patent_id": "10-2023-7010288", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제12항에 있어서,상기 특징 데이터 구성요소는 고역 통과 필터를 통하여 추출되는시스템."}
{"patent_id": "10-2023-7010288", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제12항에 있어서,제3 데이터 구성요소는,대역 통과 필터를 통하여 상기 이미지로부터 추출되고,상기 제3 데이터 구성요소는,상기 입력 데이터의 부분을 형성하는시스템."}
{"patent_id": "10-2023-7010288", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "차량에서 센서를 사용하여 캡처 한 이미지를 수신하여 복수의 구성요소 이미지로 분해한다. 복수의 구성요소 이 미지의 각 구성요소 이미지는 결과를 결정하기 위해 인공 신경망의 복수 계층의 다른 계층에 다른 입력으로 제공 된다. 인공 신경망의 결과는 차량을 적어도 부분적으로 자율적으로 작동하는 데 사용된다."}
{"patent_id": "10-2023-7010288", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 자율 주행을 위한 데이터 파이프 라인 및 딥 러닝 시스템에 관한 것이다."}
{"patent_id": "10-2023-7010288", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "본 발명은 자율 주행을 위한 데이터 파이프 라인 및 딥 러닝 시스템에 관한 것이다. 자율 주행(autonomous driving)을 구현하는 데 사용되는 딥 러닝 시스템(Deep learning system)은 일반적으로 입력으로 캡처된 센서 데이터에 의존한다. 전통적인 학습 시스템에서, 캡처된 센서 데이터는 캡처된 데이터를 센서 형식에서 학습 시스템의 초기 입력 계층(initial input layer)과 호환되는 형식으로 변환하여 딥 러닝 시스템과 호환된다. 이 변환(conversion)에는 원본 센서 데이터의 신호 충실도(fidelity)를 감소시킬 수 있는 압 축 및 다운샘플링이 포함될 수 있다. 또한 센서를 변경하려면 새로운 변환 프로세스가 필요할 수 있다. 따라서, 캡쳐 된 센서 데이터에서 신호 정보를 극대화하고 딥 러닝 분석을 위해 딥 러닝 네트워크에 더 높은 수준의 신 호 정보를 제공할 수 있는 맞춤형 데이터 파이프 라인(customized data pipeline)이 필요하다."}
{"patent_id": "10-2023-7010288", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명은 다양한 방식으로 구현될 수 있으며, 프로세스; 장치; 시스템; 물질의 구성; 컴퓨터 판독 가능 저장 매체 상에 구현된 컴퓨터 프로그램 제품; 및/또는 프로세서, 예컨대 프로세서에 결합된 메모리 상에 제공 및/또 는 의해 제공되는 명령어를 실행하도록 구성된 프로세서와 같은, 프로세서를 포함한다. 이 사양에서, 이러한 구 현들, 또는 본 발명이 취할 수 있는 임의의 다른 형태는 기술로 지칭될 수 있다. 일반적으로, 개시된 프로세스 의 단계의 순서는 본 발명의 범위 내에서 변경될 수 있다. 달리 명시되지 않는 한, 작업을 수행하도록 구성된 것으로 설명된 프로세서 또는 메모리와 같은 구성요소는 주어진 시간에 작업을 수행하도록 일시적으로 구성되는 일반 구성요소 또는 작업을 수행하도록 제작된 특정 구성요소로 구현될 수 있다. 본 명세서에서 사용되는 용어 '프로세서'는 컴퓨터 프로그램 명령과 같은 데이터를 처리하도록 구성된 하나 이상의 장치, 회로 및/또는 처리 코어를 의미한다. 본 발명의 하나 이상의 실시예에 대한 상세한 설명은 본 발명의 원리를 예시하는 첨부 도면과 함께 아래에 제공 된다. 본 발명은 이러한 실시예와 관련하여 설명되지만, 본 발명은 임의의 실시예로 제한되지 않는다. 본 발명 의 범위는 청구 범위에 의해서만 제한되고 본 발명은 수많은 대안, 수정 및 등가물을 포함한다. 본 발명의 완전 한 이해를 제공하기 위해 다음의 설명에서 다수의 특정 세부 사항이 설명된다. 이러한 세부 사항은 예의 목적으 로 제공되며 본 발명은 이러한 특정 세부 사항의 일부 또는 전부 없이 청구 범위에 따라 실시될 수 있다. 명확 성을 위해, 본 발명과 관련된 기술 분야에서 알려진 기술 자료는 본 발명이 불필요하게 모호 해지는 일이 없도 록 상세하게 설명하지 않았다. 자율 주행(autonomous driving)을 위해 센서 데이터를 추출하여 딥 러닝 네트워크(deep learning network)에 별도의 구성요소(component)로 제공하는 데이터 파이프 라인(data pipeline)이 공개된다. 일부 실시예에서, 자 율 주행은 딥 러닝 네트워크와 센서(sensor)로부터 받은 입력 데이터를 이용하여 구현된다. 예를 들면, 차량에 부착된 센서는 차량 제어 응답을 결정하기 위해 차량 주변 환경의 시각, 레이더(radar) 및 초음파(ultrasonic) 데이터와 같은 실시간 센서 데이터를 신경망(neural network)에 제공한다. 일부 실시예에서, 네트워크는 여러 계층(multiple layer)을 사용하여 구현된다. 센서 데이터는 데이터의 신호 정보를 기반으로 두 개 이상의 서로 다른 데이터 구성요소로 추출(extract)된다. 예를 들어, 특징(feature) 및/또는 에지 데이터(edge data)는 글로 벌 조명 데이터(global illumination data)와 같은 글로벌 데이터와 별개로 다른 데이터 구성요소로 추출될 수 있다. 서로 다른 데이터 구성요소는 딥 러닝 네트워크에 의해 에지 및 기타 특징을 식별하는 데 최종적으로 사 용될 데이터와 같은 대상 관련 데이터를 유지한다. 일부 실시예에서, 다른 데이터 구성요소는 특정 대상 특징을 식별하는 데 매우 관련성이 높은 데이터를 저장하지만 자체적으로 특징을 식별하거나 검출하지는 않는 컨테이너역할을 한다. 다양한 데이터 구성요소가 데이터를 추출하여 기계 학습 네트워크(machining learning network)의 적절한 단계에서 정확한 특징 검출을 보장한다. 일부 실시예에서, 그런 다음 다른 데이터 구성요소가 포함된 특 정 신호 정보를 향상시키기 위해 전처리될 수 있다. 데이터 구성요소를 압축 및/또는 다운샘플링 하여 리소스 및 계산 효율성을 높일 수 있다. 그런 다음 서로 다른 데이터 구성요소가 시스템의 서로 다른 계층에서 딥 러닝 시스템에 제공된다. 딥 러닝 네트워크는 추출 중에 유지되는 신호 정보를 입력으로 사용하여 데이터 구성요소의 대상 데이터(예를 들어, 에지, 객체 등)와 관련된 특징을 정확하게 식별하고 검출할 수 있다. 예를 들면, 특징 및 에지 데이터는 네트워크의 제1 계층에 제공되고 글로벌 데이터는 네트워크의 이후 계층에 제공된다. 각각의 타겟 신호 정보를 유지하는 서로 다른 데이터 구성요소를 추출함으로써 네트워크는 센서 데이터를 보다 효율적 으로 처리한다. 센서 데이터를 네트워크에 대한 초기 입력으로 수신하는 대신, 네트워크는 네트워크의 가장 적 절한 계층에서 가장 유용한 정보와 함께 제공된다. 일부 실시예에서, 캡처된 센서 데이터의 보다 완전한 버전은 네트워크에 의해 분석된다. 왜냐하면 서로 다른 데이터 구성요소가 의도된 목적을 위해 각 구성요소의 이미지 해상도를 완전히 활용할 수 있기 때문이다. 예를 들면, 특징 및 에지에 대한 입력은 특징 및 에지 데이터에 대 해 전체 해상도, 비트 범위 및 비트 깊이(bit depth)를 활용할 수 있는 반면 글로벌 조명에 대한 입력은 글로벌 조명 데이터에 대해 전체 해상도, 비트 범위 및 비트 깊이를 활용할 수 있다. 일부 실시예에서, 차량의 센서를 사용하여 캡처 한 이미지(image)가 수신된다. 예를 들어, 이미지는 HDR 전방 카메라(high dynamic range forward-facing camera)에서 캡처된다. 또 다른 예로, 초음파 데이터는 측면 초음 파 센서에서 캡처된다. 일부 실시예에서, 수신된 이미지는 복수의 구성요소 이미지(component image)로 분해 (decompose)된다. 예를 들어, 캡처된 HDR 이미지에서 특징 데이터(feature data)가 추출된다. 또 다른 예로, 글 로벌 조명 데이터(global illumination data)는 캡처된 HDR 이미지에서 추출된다. 또 다른 예로, 이미지는 고역 통과, 저역 통과 및/또는 대역 통과 필터를 사용하여 분해될 수 있다. 일부 실시예에서, 복수의 구성요소 이미 지의 각 구성요소 이미지는 결과를 결정하기 위해 인공 신경망(artificial neural network)의 복수 계층의 다른 계층에 대한 다른 입력으로서 제공된다. 예를 들어, 컨볼루션 신경망(convolutional neural network)과 같은 인 공 신경망은 입력 데이터를 처리하기 위한 여러 계층을 포함한다. 캡처된 이미지에서 분해된 다른 구성요소 이 미지는 신경망의 다른 계층에 대한 입력으로 제공된다. 예를 들면, 특징 데이터는 네트워크의 제1 계층에 대한 입력으로 제공되고, 글로벌 데이터는 네트워크의 이후 계층(예를 들어, 제3 계층)에 대한 입력으로 제공된다. 일부 실시예에서, 인공 신경망의 결과는 차량을 적어도 부분적으로 자율적(autonomously)으로 작동(operate)하 는 데 사용된다. 예를 들면, 인공 신경망을 이용한 딥 러닝 분석 결과는 차량의 조향(steering), 제동 (breaking), 조명(lighting) 및/또는 경고 시스템(warning system)을 제어하는 데 사용된다. 일부 실시예에서, 그 결과는 차량의 속도를 교통 상황에 자동으로 일치시키고, 차량이 운행 경로를 따르도록 조향하고, 물체가 검 출될 때 충돌을 피하고, 차량을 원하는 위치로 호출하고, 다른 자율 주행 애플리케이션 중에서 사용자에게 잠재 적 충돌을 경고하는 데 사용된다. 일부 실시예에서, 차량에는 데이터 캡처를 위한 여러 센서가 부착되어 있다. 예를 들어, 일부 실시예에서, 8 개 의 서라운드 카메라가 차량에 부착되어 최대 250 미터 범위의 차량 주변에서 360도 가시성을 제공한다. 일부 실 시예에서, 카메라 센서에는 넓은 전방 카메라, 좁은 전방 카메라, 후방 카메라, 전방 카메라 및/또는 후방 카메 라가 포함된다. 일부 실시예에서, 초음파 및 레이더 센서(ultrasonic and radar sensor)는 주변 세부 사항을 캡 처하는 데 사용된다. 예를 들어, 12 개의 초음파 센서를 차량에 부착하여 딱딱한 물체와 부드러운 물체를 모두 검출할 수 있다. 일부 실시예에서, 전방 레이더(forward-facing radar)는 주변 환경의 데이터를 캡처하는 데 사 용된다. 다양한 실시예에서, 레이더 센서는 폭우, 안개, 먼지 및 기타 차량에도 불구하고 주변 세부 사항을 캡 처 할 수 있다. 다양한 센서를 사용하여 차량 주변 환경을 캡처 하고 캡처된 이미지를 딥 러닝 분석을 위해 제 공한다. 센서에서 캡처 하고 공개된 딥 러닝 시스템을 사용하여 분석한 데이터를 사용하여, 자율 주행을 위한 기계 학습 결과가 결정된다. 다양한 실시예에서, 기계 학습 결과는 자율 주행 기능을 구현하기 위해 차량 제어 모듈에 제 공된다. 예를 들어, 차량 제어 모듈은 차량의 조향, 제동, 경고 시스템 및/또는 조명을 제어하는 데 사용될 수 있다. 일부 실시예에서, 차량은 도로를 운행하고, 차량 속도를 교통 상황에 맞추고, 차선 내에서 차량 유지하고, 운전자 입력없이 자동으로 차선 변경하고, 한 고속도로에서 다른 고속도로로 차량을 전환하고, 목적 지에 접근할 때 고속도로에서 빠져나오고, 자가 주차하고, 및 다른 자율 주행 애플리케이션 중에서 주차 지점으 로/에서 차량을 호출하도록 제어된다. 일부 실시예에서, 자율 주행 기능에는 느린 차량 뒤에서 차량을 더 빠른 차선으로 이동할 기회를 식별하는 기능이 포함된다. 일부 실시예에서, 기계 학습 결과는 운전자 상호 작용 (driver interaction)이 없는 자율 주행이 적절한시기와 비활성화 되어야 하는 시기를 결정하는 데 사용된다.다양한 실시예에서, 기계 학습 결과는 운전자가 차량을 운전하는 데 사용된다. 일부 실시예에서, 기계 학습 결과는 차량이 자동으로 주차 지점을 검색하고 차량을 주차하는 셀프 주차 모드를 구현하는 데 사용된다. 일부 실시예에서, 기계 학습 결과는 사용자 달력의 목적지를 사용하여 차량을 운행하는 데 사용된다. 다양한 실시예에서, 기계 학습 결과는 충돌 방지 및 자동 비상 제동과 같은 자율 주행 안전 기능 을 구현하는 데 사용된다. 예를 들어, 일부 실시예에서, 딥 러닝 시스템은 차량과 충돌할 수 있는 물체를 검출 하고 차량 제어 모듈이 이에 따라 제동(brake)을 적용한다. 일부 실시예에서, 차량 제어 모듈(vehicle control module)은 딥 러닝 분석을 사용하여 차량 옆, 앞 또는 뒤에서 장애물과의 잠재적 충돌을 차량 사용자에게 경고 하는 측면, 전방 및/또는 후방 충돌 경고(collision warning)를 구현한다. 다양한 실시예에서, 차량 제어 모듈 은 충돌 경고, 청각 경고, 시각적 경고 및/또는 물리적 경고(예를 들어, 진동 경고)와 같은 경고 시스템을 활성 화하여 사용자에게 긴급 상황을 알리거나 운전자의 주의가 필요한 시기를 알릴(inform) 수 있다. 일부 실시예에 서, 차량 제어 모듈은 예를 들어 비상 상황을 다른 당사자에게 알리기 위해 비상 응답 호출, 문자 메시지, 네트 워크 업데이트 및/또는 다른 통신 응답과 같은 통신 응답을 시작할 수 있다. 일부 실시예에서, 차량 제어 모듈 은 딥 러닝 분석 결과를 바탕으로 상향/하향등, 제동등, 실내등, 비상등 등 조명을 조정할 수 있다. 일부 실시 예에서, 차량 제어 모듈은 딥 러닝 분석 결과를 기반으로 경적 사용, 차량의 사운드 시스템에서 재생되는 오디 오(예를 들어, 음악, 전화 통화 등) 수정, 사운드 시스템의 볼륨 조정, 오디오 경고 재생, 마이크 활성화 등을 포함하여 차량 내부 또는 주변의 오디오를 추가로 조정할 수 있다. 도 1은 딥 러닝 파이프 라인을 사용하여 기계 학습 처리를 수행하는 프로세스의 일 실시예를 나타내는 흐름도이 다. 예를 들면, 도 1의 프로세스는 자율 주행 및 운전자 보조 자동차의 자율 주행 기능을 구현하여 안전을 개선 하고 사고 위험을 줄이는 데 활용될 수 있다. 일부 실시예에서, 도 1의 프로세스는 딥 러닝 분석을 위해 센서에 서 캡처 한 데이터를 전처리 한다. 센서 데이터를 전처리 하여, 딥 러닝 분석을 위해 제공되는 데이터가 강화되 어 차량 제어를 위한 보다 정확한 결과를 얻을 수 있다. 일부 실시예에서, 전처리는 센서가 캡처 한 데이터와 딥 러닝을 위해 신경망에서 예상(expect)하는 데이터 간의 데이터 불일치를 해결한다. 101에서 센서 데이터가 수신된다. 예를 들어, 센서 데이터는 차량에 부착된 하나 이상의 센서에 의해 캡처된다. 일부 실시예에서, 센서는 환경 및/또는 기타 차량에 부착되며 데이터는 원격으로 수신된다. 다양한 실시예에서, 센서 데이터는 이미지의 RGB 또는 YUV 채널과 같은 이미지 데이터이다. 일부 실시예에서, 센서 데이터는 HDR 카 메라를 사용하여 캡처된다. 일부 실시예에서, 센서 데이터는 레이더, LiDAR 및/또는 초음파 데이터이다. 다양한 실시예에서, LiDAR 데이터는 레이저 광을 사용하여 캡처된 데이터이며 레이저 이미징, 검출 및 범위 지정뿐만 아니라 빛 검출 및 범위 지정이라고하는 기술을 포함할 수 있다. 다양한 실시예에서, 센서 데이터의 비트 깊이 가 딥 러닝 분석을 위해 신경망의 비트 깊이를 초과한다. 103에서, 센서 데이터에 대해 데이터 전처리가 수행된다. 일부 실시예에서, 센서 데이터에 대해 하나 이상의 전 처리 패스(pre-processing pass)가 수행될 수 있다. 예를 들면, 데이터는 노이즈 제거, 정렬 문제 및/또는 흐림 등을 수정하기 위해 먼저 전처리 될 수 있다. 일부 실시예에서, 두 개 이상의 서로 다른 필터링 패스가 데이터 에 대해 수행된다. 예를 들면, 데이터에 대해 고역 통과 필터가 수행되고 데이터에 대해 저역 통과 필터가 수행 될 수 있다. 일부 실시예에서, 하나 이상의 대역 통과 필터(band-pass filter)가 수행될 수 있다. 예를 들면, 고역 통과 및 저역 통과에 추가하여 데이터에 대해 하나 이상의 대역 통과가 수행될 수 있다. 다양한 실시예에 서, 센서 데이터는 고역 통과 데이터 세트(high-pass data set) 및 저역 통과 데이터 세트(low-pass data se t)와 같은 두 개 이상의 데이터 세트로 분리된다. 일부 실시예에서, 하나 이상의 대역 통과 데이터 세트도 생성 된다. 다양한 실시예에서, 다른 데이터 세트는 센서 데이터의 다른 구성요소이다. 일부 실시예에서, 데이터를 전처리 하여 생성된 다양한 구성요소에는 특징 및/또는 에지 구성요소와 글로벌 데 이터 구성요소가 포함된다. 다양한 실시예에서, 특징 및/또는 에지 구성요소는 센서 데이터에 대해 통과 또는 대역 통과 필터를 수행하여 생성되고 글로벌 데이터 구성요소는 센서 데이터에 대해 저역 통과 또는 대역 통과 필터를 수행하여 생성된다. 일부 실시예에서, 특징/에지 데이터 및/또는 글로벌 데이터를 추출하기 위해 하나 이상의 상이한 필터 기술이 사용될 수 있다. 다양한 실시예에서, 센서 데이터의 하나 이상의 구성요소가 처리된다. 예를 들어, 고역 통과 구성요소는 이미지 데이터에서 노이즈를 제거하고/하거나 이미지 데이터에 대한 국부적 대비를 향상시킴으로써 처리될 수 있다. 일 부 실시예에서, 저역 통과 구성요소는 압축 및/또는 다운샘플링(downsample)된다. 다양한 실시예에서, 다른 구 성요소는 압축 및/또는 다운샘플링 된다. 예를 들면, 구성요소는 기계 학습 모델의 계층에 데이터를 입력하기 위한 데이터의 크기 및/또는 해상도를 조정하기 위해 적절하게 압축, 크기 조정 및/또는 다운샘플링 될 수있다. 일부 실시예에서, 센서 데이터의 비트 깊이(bit depth)가 조정된다. 예를 들면, 20 비트 또는 다른 적절 한 비트 깊이에서 데이터를 캡처 하는 카메라의 데이터 채널은 8 비트 기계 학습 모델을 위한 채널을 준비하기 위해 8 비트로 압축되거나 양자화된다. 일부 실시예에서, 하나 이상의 센서는 12 비트, 16 비트, 20 비트, 32 비트 또는 딥 러닝 네트워크에서 사용하는 비트 깊이보다 큰 다른 적절한 비트 깊이의 비트 깊이에서 데이터를 캡처 한다. 다양한 실시예에서, 103에서 수행되는 전처리는 이미지 전처리기에 의해 수행된다. 일부 실시예에서, 이미지 전 처리기(image pre-processor)는 그래픽 처리 장치(graphics processing unit)(GPU), 중앙 처리 장치(CPU), 인 공 지능(AI) 프로세서, 이미지 신호 프로세서(image signal processor), 톤 매퍼 프로세서(tone-mapper processor) 또는 기타 유사한 하드웨어 프로세서이다. 다양한 실시예에서, 서로 다른 이미지 전처리기가 서로 다른 데이터 구성요소를 병렬로 추출 및/또는 전처리하는 데 사용된다. 105에서, 딥 러닝 분석이 수행된다. 예를 들면, 인공 신경망과 같은 기계 학습 모델을 사용하여 딥 러닝 분석을 수행한다. 다양한 실시예에서, 딥 러닝 분석은 103에 대한 처리된 센서 데이터를 입력으로 수신한다. 일부 실시 예에서, 처리된 센서 데이터는 105에서 고역 통과 데이터 구성요소 및 저역 통과 데이터 구성요소와 같은 여러 다른 구성요소로서 수신된다. 일부 실시예에서, 다른 데이터 구성요소는 기계 학습 모델의 다른 계층에 대한 입 력으로 수신된다. 예를 들면, 신경망은 네트워크의 제1 계층에 대한 초기 입력으로 고역 통과 구성요소를 수신 하고 네트워크의 후속 계층(subsequent layer)에 대한 입력으로 저역 통과 구성요소를 수신한다. 107에서, 차량 제어를 위해 딥 러닝 분석 결과가 제공된다. 예를 들면, 결과는 차량의 속도 및/또는 조향을 조 정하기 위해 차량 제어 모듈에 제공될 수 있다. 다양한 실시예에서, 결과는 자율 주행 기능(autonomous driving functionality)을 구현하기 위해 제공된다. 예를 들어, 결과는 차량을 조향하여 피해야 하는 물체를 나타낼 수 있다. 또 다른 예로, 결과는 차선에서 차량의 위치를 제동하고 변경하여 피해야 하는 끼어드는 차(merging ca r)를 나타낼 수 있다. 도 2는 딥 러닝 파이프 라인(deep learning pipeline)을 사용하여 기계 학습 처리를 수행하는 프로세스의 일 실 시예를 나타내는 흐름도이다. 예를 들면, 도 2의 프로세스는 센서 데이터를 전처리 하고, 센서 데이터에서 이미 지 구성요소를 추출하고, 추출된 이미지 구성요소를 전처리 한 다음, 딥 러닝 분석을 위한 구성요소를 제공하는 데 활용될 수 있다. 딥 러닝 분석 결과는 자율 주행을 구현하여 안전성을 높이고 사고 위험을 줄이는 데 활용될 수 있다. 일부 실시예에서, 도 2의 프로세스는 도 1의 프로세스를 수행하는 데 사용된다. 일부 실시예에서, 단 계 201은 도 1의 101에서 수행된다; 단계 203, 205, 207 및/또는 209는 도 1의 103에서 수행된다; 및/또는 단 계 211은 도 1의 105 및/또는 107에서 수행된다. 추출된 센서 데이터의 구성요소를 처리하여, 기계 학습 모델에 제공되는 처리된 데이터는 강화되지 않은 데이터를 사용하는 대신 딥 러닝 분석에서 우수한 결과를 얻기 위해 강화된다. 표시된 예에서, 딥 러닝 분석 결과는 차량 제어에 사용된다. 201에서 센서 데이터가 수신된다. 다양한 실시예에서, 센서 데이터는 HDR 카메라와 같은 센서에서 캡처 한 이미 지 데이터이다. 일부 실시예에서, 센서 데이터는 하나 이상의 다른 센서에서 캡처된다. 일부 실시예에서, 이미 지 데이터는 데이터의 충실도를 높이기 위해 12 비트 이상의 비트 깊이를 사용하여 캡처된다. 203에서, 데이터는 전처리 된다. 일부 실시예에서, 데이터는 이미지 신호 프로세서, 그래픽 처리 장치(GPU), 톤 매퍼 프로세서, 중앙 처리 장치(CPU), 인공 지능(AI) 프로세서, 또는 다른 유사한 하드웨어 프로세서와 같은 이 미지 전처리기를 사용하여 전처리 된다. 다양한 실시예에서, 선형화, 디 모자이킹(demosaicing) 및/또는 다른 처리 기술이 캡처된 센서 데이터에 대해 수행될 수 있다. 다양한 실시예에서, 캡처된 데이터의 충실도를 향상시 키고/거나 후속 단계에서 오류의 도입을 줄이기 위해 고해상도 센서 데이터에 대해 전처리가 수행된다. 일부 실 시예에서, 전처리 단계는 선택 사항이다. 205에서, 하나 이상의 이미지 구성요소가 추출된다. 일부 실시예에서, 2 개의 이미지 구성요소가 추출된다. 예 를 들어, 센서 데이터의 특징/에지 데이터 구성요소가 추출되고 센서 데이터의 글로벌 데이터 구성요소가 추출 된다. 일부 실시예에서, 센서 데이터의 고역 통과 구성요소와 저역 통과 구성요소가 추출된다. 일부 실시예에서, 하나 이상의 추가 대역 통과 구성요소가 센서 데이터에서 추출된다. 다양한 실시예에서, 고역 통과, 저역 통과 및/또는 대역 통과 필터는 센서 데이터의 다른 구성요소를 추출하는 데 사용된다. 일부 실시예 에서, 톤 매퍼(tone-mapper)를 사용하여 이미지 구성요소를 추출한다. 일부 실시예에서, 글로벌 데이터 및/또는 저역 통과 구성요소 데이터는 비닝(binning) 또는 유사한 기술을 사용하여 센서 데이터를 다운샘플링 하여 추출 된다. 다양한 실시예에서, 추출은 대상 신호 정보를 이미지 데이터 구성요소로 유지하고 저장하지만 실제로 대 상 정보와 관련된 특징을 검출하거나 식별하지는 않는다. 예를 들면, 에지 데이터에 대응하는 이미지 구성요소의 추출은 에지를 정확하게 식별하기 위한 타겟 신호 정보를 갖는 이미지 구성요소를 생성하지만 205에서 수행 된 추출은 센서 데이터에서 에지의 존재를 검출하지 않는다. 일부 실시예에서, 기계 학습 네트워크의 제1 계층에 대해 추출된 이미지 데이터 구성요소는 딥 러닝 분석의 제1 계층의 응답을 보존하는 프로세스를 사용하여 추출된다. 예를 들면, 제1 계층 분석 이후 이미지 구성요소에 대 해 수행한 분석 결과는 이미지 구성요소로 추출하기 이전에 해당 센서 데이터에 대해 수행한 분석과 유사하도록, 제1 계층에 대한 관련 신호 정보가 보존된다. 따라서, 다양한 실시예에서, 결과는 5x5 매트릭스 필 터만큼 작은 필터에 대해 보존된다. 일부 실시예에서, 추출된 데이터 구성요소는 캡처된 이미지의 여러 채널을 하나 이상의 채널로 결합하여 생성된 다. 예를 들어, 빨강, 녹색 및 파랑 채널을 평균하여 데이터 구성요소에 대한 새 채널을 만들 수 있다. 다양한 실시예에서, 추출된 데이터 구성요소는 소스 캡처 데이터의 하나 이상의 상이한 채널 및/또는 상이한 센서의 하 나 이상의 상이한 캡처된 이미지로부터 구성될 수 있다. 예를 들면, 여러 센서의 데이터를 단일 데이터 구성요 소로 결합할 수 있다. 일부 실시예에서, 단계 203의 전처리기와 같은 이미지 전처리기가 다른 구성요소를 추출하는 데 사용된다. 일부 실시예에서, 이미지 신호 프로세서(image pre-processor)는 다른 구성요소를 추출하는 데 사용될 수 있다. 다양 한 실시예에서, 그래픽 처리 장치(GPU)는 다른 구성요소를 추출하는 데 사용될 수 있다. 일부 실시예에서, 여러 구성요소를 병렬로 추출할 수 있도록 서로 다른 구성요소를 추출하는 데 서로 다른 전처리기가 사용된다. 예를 들면, 이미지 신호 프로세서는 고역 통과 구성요소를 추출하는 데 사용될 수 있고 GPU는 저역 통과 구성요소를 추출하는 데 사용될 수 있이다. 또 다른 예로, 저역 통과 구성요소를 추출하기 위해 이미지 신호 프로세서가 사 용될 수 있고 고역 통과 구성요소를 추출하기 위해 GPU가 사용될 수 있다. 일부 실시예에서, 톤 매퍼 프로세서 는 이미지 구성요소(예를 들어, 고역 통과 구성요소)를 추출하는 데 사용되고 GPU는 별도의 이미지 구성요소(예 를 들어, 저역 통과 구성요소)를 병렬로 추출하는 데 사용된다. 일부 실시예에서, 톤 매퍼는 이미지 신호 프로 세서의 일부이다. 일부 실시예에서, 병렬로 추출을 수행하기 위해 유사한 전처리기의 다중 인스턴스가 존재한다. 207에서 구성요소 전처리가 수행된다. 일부 실시예에서, 단계 203 및/또는 205의 전처리기와 같은 이미지 전처 리기가 하나 이상의 구성요소를 전처리 하는데 사용된다. 일부 실시예에서, 서로 다른 구성요소에 대해 병렬로 전처리를 수행할 수 있도록 서로 다른 구성요소를 전처리 하는 데 서로 다른 전처리기가 사용된다. 예를 들면, 이미지 신호 프로세서는 고역 통과 구성요소를 처리하는 데 사용될 수 있고 그래픽 처리 장치(GPU)는 저역 통과 구성요소를 처리하는 데 사용될 수 있다. 일부 실시예에서, 톤 매퍼 프로세서는 하나의 이미지 구성요소를 처리 하는 데 사용되고 GPU는 별도의 이미지 구성요소를 병렬로 처리하는 데 사용된다. 일부 실시예에서, 상이한 구 성요소를 병렬로 처리하기 위해 유사한 전처리기의 다중 인스턴스가 존재한다. 다양한 실시예에서, 전처리는 이미지 구성요소 데이터를 다운샘플링 및/또는 압축하는 것을 포함한다. 일부 실 시예에서, 전처리에는 구성요소 데이터에서 노이즈 제거가 포함된다. 일부 실시예에서, 전처리는 캡처된 데이터 를 20 비트에서 8 비트 데이터 필드로 압축하거나 양자화 하는 것을 포함한다. 일부 실시예에서, 전처리에는 이 미지 구성요소의 크기를 더 낮은 해상도로 변환하는 작업이 포함된다. 예를 들어, 이미지 구성요소는 원래 센서 이미지 크기의 1/2, 1/4, 8 분의 1, 16 분의 1, 1 분의 1, 64 분의 1 또는 다른 적절한 스케일링 일 수 있다. 다양한 실시예에서, 이미지 구성요소는 기계 학습 모델의 입력 계층에 적합한 크기로 축소된다. 209에서, 구성요소는 딥 러닝 네트워크의 적절한 네트워크 계층에 제공된다. 예를 들어, 다른 구성요소가 네트 워크의 다른 계층에 제공될 수 있다. 일부 실시예에서, 네트워크는 여러 계층이 있는 신경망이다. 예를 들어 신 경망의 제1 계층은 입력 고역 통과 구성요소 데이터로 수신한다. 후속 네트워크 계층(subsequent network layer) 중 하나는 글로벌 조명 데이터에 해당하는 입력 저역 통과 구성요소 데이터를 수신한다. 다양한 실시예 에서, 205에서 추출되고 207에서 전처리 된 다른 구성요소는 신경망의 다른 계층에서 수신된다. 또 다른 예로, 특징 및/또는 에지 데이터 구성요소는 인공 신경망과 같은 딥 러닝 네트워크의 제1 계층에 대한 입력으로 제공 된다. 글로벌 데이터 구성요소(global data component)는 후속 계층(subsequent layer)에 제공되며 글로벌 데 이터가 특징 및/또는 에지 구성요소 데이터만큼 정밀도를 요구하지 않기 때문에 데이터의 압축 및/또는 다운샘 플링 된 버전으로 제공될 수 있다. 다양한 실시예에서, 글로벌 데이터는 정보 손실없이 더 쉽게 압축되며 네트 워크의 이후 계층에서 제공될 수 있다. 일부 실시예에서, 기계 학습 모델은 하나 이상의 후속 계층이 이전 계층보다 크기가 더 작은 크기 속성을 가진 입력 데이터를 수신하는 여러 순차적 계층(sequential layers)으로 구성된다. 예를 들면, 네트워크에 대한 제1계층은 캡처 이미지 크기와 유사한 이미지 크기를 수신할 수 있다. 후속 계층은 캡처 이미지 크기의 절반 또는 1/4 인 입력 데이터를 수신할 수 있다. 입력 데이터 크기의 감소는 후속 계층의 계산을 줄이고 딥 러닝 분석의 효율성을 향상시킨다. 센서 입력 데이터를 다른 구성요소와 다른 계층으로 제공함으로써, 계산 효율성이 증가한 다. 네트워크의 이전 계층은 특히 데이터 양과 데이터 크기가 후속 계층보다 크기 때문에 계산을 늘려야 한다. 입력 데이터가 네트워크의 이전 계층 및/또는 207에서의 전처리에 의해 압축 되었기 때문에 후속 계층이 계산하 기에 더 효율적일 수 있다. 211에서, 차량 제어를 위해 딥 러닝 분석 결과가 제공된다. 예를 들면, 처리된 이미지 구성요소를 사용한 기계 학습 결과는 차량의 움직임을 제어하는 데 활용될 수 있다. 일부 실시예에서, 결과는 차량 제어 작업에 해당한 다. 예를 들어, 결과는 차량의 속도 및 조향에 해당할 수 있다. 일부 실시예에서, 결과는 차량 조향에 사용되는 차량 제어 모듈에 의해 수신된다. 일부 실시예에서, 결과는 차량의 안전을 향상시키는 데 활용된다. 다양한 실 시예에서, 211에서 제공된 결과는 209에서 제공된 구성요소에 대한 딥 러닝 분석을 수행하여 결정된다. 도 3은 구성요소 데이터를 사용하여 기계 학습 처리를 수행하기 위한 프로세스의 일 실시예를 예시하는 흐름도 이다. 표시된 예에서, 도 3의 프로세스는 글로벌 데이터와 분리된 센서 데이터에서 특징 및 에지 데이터를 추출 하는 데 사용된다. 두 데이터 세트는 차량 제어 결과(vehicle control result)를 추론하기 위해 서로 다른 단계 에서 딥 러닝 네트워크에 입력된다. 두 구성요소를 분리하고 서로 다른 단계에서 제공함으로써, 네트워크의 초 기 계층은 초기 에지 및 특징 검출에 컴퓨팅 리소스를 할당할 수 있다. 일부 실시예에서, 초기 단계에서는 도로, 차선 표시, 장애물, 차량, 보행자, 교통 표지 등과 같은 물체의 초기 식별에 자원을 지원한다. 후속 계층 은 글로벌 데이터가 리소스 집약적이지 않기 때문에 보다 계산 효율적인 방식으로 글로벌 데이터를 활용할 수 있다. 기계 학습은 계산 및 데이터 집약적일 수 있으므로, 다양한 단계에서 서로 다른 이미지 구성요소를 활용 하는 데이터 파이프 라인은 딥 러닝 계산의 효율성을 높이고 분석에 필요한 데이터 리소스 요구 사항을 줄이기 위해 활용된다. 일부 실시예에서, 도 3의 프로세스는 도 1 및/또는 도 2의 프로세스를 수행하는 데 사용된다. 일부 실시예에서, 단계 301은 도 1의 101 및/또는 도 2의 201에서 수행된다; 단계 303은 도 1의 103 및/또는 도 2의 203에서 수행된다; 단계 311 및/또는 321은 도 1의 103 및/또는 도 2의 205에서 수행된다; 단계 313, 323 및/또는 325는 도 1의 103에서 및/또는 도 2의 207 및 209에서 수행된다; 단계 315 및/또는 335는 도 1의 105 및/또는 도 2의 211에서 수행된다; 및/또는 단계 337은 도 1의 107 및/또는 도 2의 211에서 수행된다. 301에서, 센서 데이터가 수신된다. 다양한 실시예에서, 센서 데이터는 차량의 하나 이상의 센서에 의해 캡처된 데이터이다. 일부 실시예에서, 센서 데이터는 도 1의 단계 101 및/또는 도 2의 단계 201과 관련하여 설명된 바 와 같이 수신된다. 303에서, 데이터 전처리가 수행된다. 예를 들어 센서 데이터는 데이터를 전처리 하여 향상된다. 일부 실시예에 서, 예를 들어 노이즈 제거, 정렬 또는 기타 적절한 필터를 수행하여 데이터를 정리한다. 다양한 실시예에서, 데이터는 도 1의 단계 103 및/또는 도 2의 단계 203과 관련하여 설명된 바와 같이 전처리 된다. 표시된 예에서, 처리는 단계 311 및 321로 계속된다. 일부 실시예에서, 311 및 321에서의 처리는 센서 데이터의 상이한 구성요 소를 추출하고 처리하기 위해 병렬로 실행된다. 일부 실시예에서, 각 처리 분기(branch of processing)(예를 들 어, 311에서 시작하는 분기 및 321에서 시작하는 분기)는 순차적으로 실행되거나 파이프 라인으로 실행된다. 예 를 들면, 처리는 네트워크의 초기 계층에 대한 데이터를 준비하기 위해 단계 311부터 수행된다. 일부 실시 양태 에서, 전처리 단계는 선택적이다. 311에서, 특징 및/또는 에지 데이터는 센서 데이터에서 추출된다. 예를 들어, 특징 데이터 및/또는 에지 데이터 는 캡처된 센서 데이터에서 구성요소 데이터로 추출된다. 일부 실시예에서, 구성요소 데이터는 특징 및/또는 에 지를 식별하기 위해 센서 데이터의 관련 신호 정보를 유지한다. 다양한 실시예에서, 추출 프로세스는 특징 및/ 또는 에지를 식별하고 검출하는 데 중요한 신호 정보를 보존하며 센서 데이터에서 특징 또는 에지를 실제로 식 별하거나 검출하지 않는다. 다양한 실시예에서, 특징 및/또는 에지는 315 및/또는 335에서 하나 이상의 분석 단 계 동안 검출된다. 일부 실시예에서, 추출된 특징 및/또는 에지 데이터는 원래 캡처된 데이터와 동일한 비트 깊 이를 갖다. 일부 실시예에서, 추출된 데이터는 특징 데이터, 에지 데이터 또는 특징과 에지 데이터의 조합이다. 일부 실시예에서, 고역 통과 필터(high-pass filter)는 센서 데이터에서 특징 및/또는 에지 데이터를 추출하는 데 사용된다. 다양한 실시예에서, 톤 매퍼 프로세서는 센서 데이터로부터 특징 및/또는 에지 데이터를 추출하도 록 교정된다. 313에서, 특징 및/또는 에지 데이터에 대해 전처리가 수행된다. 예를 들어, 신호 품질을 개선하기 위해 데이터 에 노이즈 제거 필터(denoising filter)를 적용할 수 있다 다른 예로서, 딥 러닝 분석 이전에 특징 및 에지 데이터를 향상시키기 위해 국부 대비 향상, 이득 조정, 스레시홀딩(thresholding), 노이즈 필터링 등과 같은 다른 전처리 기술이 적용될 수 있다. 다양한 실시예에서, 전처리는 센서 데이터 전체에 보다 일반적인 전처리 기술을 적용하는 것보다, 데이터의 특징 및 에지 특징을 향상시키기 위해 맞춤화 된다. 일부 실시예에서, 전처리는 추 출된 데이터에 대해 압축 및/또는 다운샘플링을 수행하는 것을 포함한다. 일부 실시 양태에서, 313에서의 전처 리 단계는 선택적이다. 315에서, 특징 및/또는 에지 데이터를 사용하여 초기 분석이 수행된다. 일부 실시예에서, 초기 분석은 신경망과 같은 기계 학습 모델을 사용하는 딥 러닝 분석이다. 다양한 실시예에서, 초기 분석은 네트워크의 제1 계층에 대 한 입력으로서 특징 및 에지 데이터를 수신한다. 일부 실시예에서, 네트워크의 초기 계층은 캡처된 이미지에서 특징 및/또는 에지의 검출에 우선 순위를 둔다. 다양한 실시예에서, 딥 러닝 분석은 컨볼루션 신경망과 같은 인 공 신경망을 사용하여 수행된다. 일부 실시예에서, 분석은 인공 지능(AI) 프로세서에서 실행된다. 321에서, 글로벌 데이터는 센서 데이터에서 추출된다. 예를 들어, 글로벌 데이터는 캡처된 센서 데이터에서 구 성요소 데이터로 추출된다. 일부 실시예에서, 글로벌 데이터는 글로벌 조명 데이터에 대응한다. 일부 실시예에 서, 추출된 글로벌 데이터는 원래 캡처된 데이터와 동일한 비트 깊이를 갖는다. 일부 실시예에서, 센서 데이터 로부터 글로벌 데이터를 추출하기 위해 저역 통과 필터(low-pass filter)가 사용된다. 다양한 실시예에서, 톤 매퍼 프로세서는 센서 데이터로부터 글로벌 데이터를 추출하도록 교정된다. 비닝, 리샘플링 및 다운샘플링과 같 은 다른 기술을 사용하여 글로벌 데이터를 추출할 수도 있다. 다양한 실시예에서, 추출 프로세스는 글로벌 적으 로 관련될 가능성이 있는 데이터를 보유하고 센서 데이터로부터 글로벌 특징을 식별하고 검출하지 않는다. 다양 한 실시예에서, 글로벌 특징은 335에서 수행된 분석에 의해 검출된다. 323에서, 글로벌 데이터에 대해 전처리가 수행된다. 예를 들어, 신호 품질을 개선하기 위해 데이터에 노이즈 제 거 필터를 적용할 수 있다. 또 다른 예로서, 딥 러닝 분석 전에 글로벌 데이터를 향상시키기 위해 국부 대비 향 상, 이득 조정, 스레시홀딩, 노이즈 필터링 등과 같은 다른 전처리 기술이 적용될 수 있다. 다양한 실시예에서, 전처리는 센서 데이터 전체에 보다 일반적인 전처리 기술을 적용하는 것 보다는 글로벌 데이터의 속성을 향상시 키도록 맞춤화 된다. 일부 실시예에서, 글로벌 데이터의 전처리는 데이터를 압축하는 것을 포함한다. 일부 실시 예에서, 323에서의 전처리 단계는 선택적이다. 325에서 글로벌 데이터는 다운샘플링 된다. 예를 들어, 글로벌 데이터의 해상도가 감소한다. 일부 실시예에서, 글로벌 데이터는 데이터 분석의 계산 효율을 개선하고 글로벌 데이터를 딥 러닝 네트워크의 나중 계층에 대한 입력으로서 구성하기 위해 크기가 감소된다. 일부 실시예에서, 글로벌 데이터는 비닝, 리샘플링 또는 다른 적절 한 기술에 의해 다운샘플링 된다. 일부 실시예에서, 다운샘플링은 그래픽 처리 장치(GPU) 또는 이미지 신호 프 로세서를 사용하여 수행된다. 다양한 실시예에서, 글로벌 데이터가 특징 및/또는 에지 데이터와 동일한 해상도 요구 사항을 갖지 않기 때문에 다운샘플링이 글로벌 데이터에 적합하다. 일부 실시예에서, 325에서 수행된 다운 샘플링은 글로벌 데이터가 321에서 추출될 때 수행된다. 335에서, 특징 및/또는 에지 데이터 및 글로벌 데이터에 대한 딥 러닝 분석 결과를 입력으로 사용하여 추가 딥 러닝 분석이 수행된다. 다양한 실시예에서, 딥 러닝 분석은 딥 러닝 네트워크의 나중 계층(later layer)에서 글 로벌 데이터를 입력으로 받는다. 다양한 실시예에서, 글로벌 데이터를 수신하는 계층의 예상 입력 데이터 크기 (expected input data size)가 초기 입력 계층의 예상 입력 데이터 크기보다 작다. 예를 들어, 글로벌 데이터 입력 계층에 대한 입력 크기는 딥 러닝 네트워크의 초기 계층에 대한 입력 크기의 절반 또는 1/4 일 수 있다. 일부 실시예에서, 네트워크의 이후 계층은 글로벌 데이터를 활용하여 초기 계층의 결과를 향상시킨다. 다양한 실시예에서, 딥 러닝 분석이 수행되고 차량 제어 결과가 결정된다. 예를 들어, 차량 제어 결과는 컨볼루션 신경 망을 사용하여 결정된다. 일부 실시예에서, 분석은 인공 지능(AI) 프로세서에서 실행된다. 337에서, 차량 제어를 위한 딥 러닝 분석 결과가 제공된다. 예를 들어, 추출 및 처리된 이미지 구성요소를 사용 한 기계 학습 결과는 차량의 움직임을 제어하는 데 활용된다. 일부 실시예에서, 결과는 차량 제어 동작에 대응 한다. 일부 실시 양태에서, 결과는 도 1의 단계 107 및/또는 도 2의 단계 211과 관련하여 설명된 바와 같이 제 공된다. 도 4는 고역 통과 및 저역 통과 구성요소 데이터를 사용하여 기계 학습 처리를 수행하기 위한 프로세스의 일 실 시예를 나타내는 흐름도이다. 표시된 예에서 도 4의 프로세스는 센서 데이터에서 두 데이터 구성요소를 추출하 고 인공 신경망과 같은 딥 러닝 네트워크의 다른 계층에 구성요소를 제공하는 데 사용된다. 두 구성요소는 고역 통과 및 저역 통과 필터를 사용하여 추출된다. 다양한 실시예에서, 결과는 개선된 정밀도, 안전성 및/또는 편안 함 결과를 갖는 자율 주행을 구현하는 데 사용된다. 일부 실시예에서, 도 4의 프로세스는 도 1, 2 및/또는 3의프로세스를 수행하는 데 사용된다. 일부 실시예에서, 단계 401은 도 1의 103에서, 도 2의 203에서 및/또는 도 3 의 303에서 수행된다; 단계 403은 도 1의 103에서, 도 2의 205에서 및/또는 도 3의 311에서 수행된다; 단계 413 은 도 1의 103에서, 도 2의 205에서 및/또는 도 3의 321에서 수행된다; 단계 405는 도 1의 103에서, 도 2의 207 및 209에서, 및/또는 도 3의 313에서 수행된다; 단계 415 및 417은 도 1의 103에서, 도 2의 207 및 209에 서, 및/또는 도 3의 323 및 325에서 수행된다; 단계 407은 도 1의 105에서, 도 2의 211에서 및/또는 도 3의 315에서 수행된다; 및/또는 단계 421은 도 1의 105에서, 도 2의 211에서 및/또는 도 3의 335에서 수행된다. 401에서, 데이터는 전처리된다. 일부 실시예에서, 데이터는 HDR(high dynamic range) 카메라, 레이더, 초음파 및/또는 LiDAR 센서와 같은 하나 이상의 센서로부터 캡처된 센서 데이터이다. 다양한 실시예에서, 데이터는 도 1의 103, 도 2의 203, 및/또는 도 3의 303과 관련하여 설명된 바와 같이 전처리 된다. 데이터가 전처리되면, 처 리는 403 및 413으로 계속된다. 일부 실시예에서, 단계 403 및 413은 병렬로 실행된다. 403에서, 고역 통과 필터가 데이터에 대해 수행된다. 예를 들어, 캡처된 센서 데이터에 대해 고역 통과 필터를 수행하여 고역 통과 구성요소 데이터를 추출한다. 일부 실시예에서, 고역 통과 필터는 그래픽 처리 장치(GPU), 톤 매퍼 처리기, 이미지 신호 프로세서, 또는 다른 이미지 전처리기를 사용하여 수행된다. 일부 실시예에서, 고 역 통과 데이터 구성요소는 캡처된 센서 데이터의 특징 및/또는 에지를 나타낸다. 다양한 실시예에서, 고역 통 과 필터는 딥 러닝 프로세스의 제1 계층의 응답을 보존하도록 구성된다. 예를 들어, 고역 통과 필터는 기계 학 습 네트워크의 상단에 있는 작은 필터에 대한 응답을 보존하기 위해 구성된다. 네트워크의 제1 계층에 대한 관 련 신호 정보는 제1 계층 이후의 고역 통과 구성요소 데이터에 대해 수행된 분석 결과가 제1 계층 이후에 필터 링 되지 않은 데이터에 대해 수행된 분석과 유사하도록 보존된다. 다양한 실시예에서, 결과는 5x5 매트릭스 필 터만큼 작은 필터에 대해 보존된다. 413에서, 데이터에 대해 저역 통과 필터가 수행된다. 예를 들어, 캡처된 센서 데이터에 대해 저역 통과 필터를 수행하여 저역 통과 구성요소 데이터를 추출한다. 일부 실시예에서, 저역 통과 필터는 그래픽 처리 장치(GPU), 톤 매퍼 프로세서, 이미지 신호 프로세서, 또는 다른 이미지 전처리기를 사용하여 수행된다. 일부 실시예에서, 저역 통과 데이터 구성요소는 글로벌 조명 데이터와 같은 캡처된 센서 데이터의 글로벌 데이터를 나타낸다. 다양한 실시예에서, 403 및 413에서 수행된 필터링은 동일하거나 다른 이미지 전처리기를 사용할 수 있다. 예를 들어 톤 매퍼 프로세서는 고역 데이터 구성요소를 추출하는 데 사용되고 그래픽 처리 장치(GPU)는 저역 통과 데 이터 구성요소를 추출하는 데 사용된다. 일부 실시예에서, 고역 통과 또는 저역 통과 데이터는 원래 캡처된 데 이터에서 데이터 구성요소 중 하나를 감산함으로써 추출된다. 405 및 415에서 각각의 고역 통과 및 저역 통과 데이터 구성요소에 대해 후처리(post-processing)가 수행된다. 다양한 실시예에서, 신호 품질을 향상시키고/거나 데이터를 표현하는 데 필요한 데이터의 양을 감소시키기 위해 상이한 후처리 기술이 이용된다. 예를 들어, 특히 노이즈 제거(de-noising), 디모자이킹(demosaicing), 국부 대 비 향상(local contrast enhancement), 이득 조정(gain adjustment) 및/또는 스레시홀딩(thresholding)이 각각 의 고역 통과 및/또는 저역 통과 데이터 구성요소에 대해 수행될 수 있다. 일부 실시예에서, 데이터 구성요소는 압축 및/또는 다운샘플링 된다. 예를 들어, 고역 통과 및/또는 저역 통과 데이터가 추출되면, 각 데이터 구성요 소는 전체 비트 깊이 범위를 보다 효율적으로 활용하기 위해 압축될 수 있다. 일부 실시예에서, 각각의 데이터 구성요소는 센서에 의해 캡처된 더 높은 비트 깊이에서 딥 러닝 네트워크와 호환되는 더 낮은 비트 깊이로 압축 되거나 양자화된다. 예를 들어, 12 비트, 16 비트, 20 비트, 32 비트 또는 채널당 다른 적절한 비트 깊이에서 캡처된 센서 데이터는 채널당 8 비트와 같은 낮은 비트 깊이로 압축되거나 양자화 될 수 있다. 일부 실시 양태 에서, 405 및/또는 415에서의 후처리 단계는 선택적이다. 417에서, 저역 통과 데이터 구성요소는 다운샘플링 된다. 다양한 실시예에서, 저역 통과 데이터 구성요소는 네 트워크의 나중 단계에서 네트워크로 공급되고 보다 효율적인 리소스 크기로 다운샘플링 될 수 있다. 예를 들어, 저역 통과 데이터 구성요소는 전체 센서 크기에서 추출되어 원래 크기의 절반 또는 1/4로 축소될 수 있다. 다른 비율의 감소도 가능하다. 다양한 실시예에서, 저역 통과 데이터는 다운샘플링 되지만 관련 신호 정보를 유지한 다. 많은 시나리오에서, 저역 통과 데이터는 신호 정보 손실없이 쉽게 다운샘플링 될 수 있다. 데이터를 다운샘 플링 하면 딥 러닝 네트워크의 이후 계층에서 데이터를 보다 쉽고 빠르게 분석할 수 있다. 407에서, 고역 통과 데이터 구성요소에 대해 딥 러닝 분석이 수행된다. 일부 실시예에서, 고역 통과 데이터 구 성요소는 딥 러닝 네트워크의 초기 계층으로 공급되고 특징 및 에지 검출을 위한 가장 중요한 데이터를 나타낸 다. 다양한 실시예에서, 고역 통과 데이터 구성요소를 사용하는 제1 계층에 대한 딥 러닝 분석의 결과는 네트워 크의 후속 계층에 공급된다. 예를 들어, 신경망은 다중 계층, 예를 들어 5 개 이상의 계층을 포함할 수 있다.제1 계층은 고역 통과 데이터 구성요소를 입력으로 받고 제2 계층은 제2 계층에서 수행한 딥 러닝 분석의 결과 를 수신한다. 다양한 실시예에서, 제2 또는 이후 계층은 추가 딥 러닝 분석을 수행하기 위한 추가 입력으로서 저역 통과 데이터 구성요소를 수신한다. 421에서, 407에서 수행된 분석 결과와 417에서 다운샘플링 된 저역 통과 데이터 구성요소를 사용하여 추가 딥 러닝 분석이 수행된다. 다양한 실시예에서, 딥 러닝 분석은 차량 제어 결과를 추론한다. 예를 들어 407, 421의 딥 러닝 분석 결과는 자율 주행 차량 제어에 사용된다. 도 5는 고역 통과, 대역 통과 및 저역 통과 구성요소 데이터를 사용하여 기계 학습 처리를 수행하기 위한 프로 세스의 일 실시예를 나타내는 흐름도이다. 표시된 예에서, 도 5의 프로세스는 센서 데이터에서 3 개 이상의 데 이터 구성요소를 추출하고 인공 신경망과 같은 딥 러닝 네트워크의 여러 계층에서 구성요소를 제공하는 데 사용 된다. 도 4의 프로세스와 유사하게 고역 통과 및 저역 통과 구성요소가 추출된다. 또한 도 5의 프로세스는 하나 이상의 대역 통과 데이터 구성요소를 추출한다. 다양한 실시예에서, 센서 데이터를 딥 러닝 네트워크의 서로 다 른 계층에 제공되는 여러 구성요소로 분해하면 딥 러닝 분석이 네트워크의 서로 다른 계층에서 서로 다른 데이 터 세트를 강조할 수 있다. 일부 실시예에서, 도 5의 프로세스는 도 1, 2, 3 및/또는 4의 프로세스를 수행하는 데 사용된다. 일부 실시예에 서, 단계 501은 도 1의 103에서, 도 2의 203에서, 도 3의 303에서 및/또는 도 4의 401에서 수행된다. 일부 실시 예에서, 단계 503은 도 1의 103에서, 도 2의 205에서, 도 3의 311에서 및/또는 도 4의 403에서 수행된다; 단계 513은 도 1의 103에서, 도 2의 205에서 및/또는 도 3의 311 또는 321에서 수행된다; 및/또는 단계 523은 도 1의 103, 도 2의 205, 도 3의 321, 및/또는 도 4의 413에서 수행된다. 일부 실시예에서, 단계 505는 도 1의 103에 서, 도 2의 207 및 209에서, 도 3의 313에서 및/또는 도 4의 단계 405에서 수행된다; 단계 515는 도 1의 103에 서, 도 2의 207 및 209에서, 도 3의 313, 323 및/또는 325에서, 및/또는 도 4의 405, 415 및/또는 417에서 수 행된다; 및/또는 단계 525는 도 1의 103에서, 도 2의 207 및 209에서, 도 3의 323 및 325에서, 및/또는 도 4의 415 및 417에서 수행된다. 일부 실시예에서, 단계 537은 도 1의 105, 도 2의 211, 도 3의 315 및 335에서; 및/ 또는 도 4의 407 및 421에서 수행된다. 501에서, 데이터가 전처리 된다. 일부 실시예에서, 데이터는 HDR(high dynamic range) 카메라, 레이더, 초음파 및/또는 LiDAR 센서와 같은 하나 이상의 센서로부터 캡처된 센서 데이터이다. 다양한 실시예에서, 데이터는 도 1의 103, 도 2의 203, 도 3의 303, 및/또는 도 4의 401에 대해 설명된 바와 같이 전처리 된다. 데이터가 전처리 되면 처리는 503, 513 및 523으로 계속된다. 일부 실시예에서, 단계 503, 513 및 523은 병렬로 실행된다. 503에서, 데이터에 대해 고역 통과 필터가 수행된다. 예를 들어, 캡처된 센서 데이터에 대해 고역 통과 필터를 수행하여 고역 통과 구성요소 데이터를 추출한다. 일부 실시예에서, 고역 통과 필터는 그래픽 처리 장치(GPU), 톤 매퍼 처리기, 이미지 신호 프로세서 또는 다른 이미지 전처리기를 사용하여 수행된다. 일부 실시예에서, 고 역 통과 데이터 구성요소는 캡처된 센서 데이터의 특징 및/또는 에지를 나타낸다. 513에서, 하나 이상의 대역 통과 데이터 구성요소를 추출하기 위해 데이터에 대해 하나 이상의 대역 통과 필터 가 수행된다. 예를 들어, 캡처된 센서 데이터에 대해 대역 통과 필터가 수행되어 특징, 에지, 중간 및/또는 글 로벌 데이터의 혼합을 포함하는 구성요소 데이터를 추출한다. 다양한 실시예에서, 하나 이상의 대역 통과 구성 요소가 추출될 수 있다. 일부 실시예에서, 저역 통과 필터는 그래픽 처리 장치(GPU), 톤 매퍼 프로세서, 이미지 신호 프로세서 또는 다른 이미지 전처리기를 사용하여 수행된다. 일부 실시예에서, 대역 통과 데이터 구성요소 는 주로 에지/특징 데이터도 아니고 캡처된 센서 데이터의 주로 글로벌 데이터도 아닌 데이터를 나타낸다. 일부 실시예에서, 대역 통과 데이터는 고역 통과 데이터 구성요소 및 저역 통과 데이터 구성요소만을 사용하여 손실 될 수 있는 데이터 충실도를 보존하기 위해 사용된다. 523에서, 데이터에 대해 저역 통과 필터가 수행된다. 예를 들어, 캡처된 센서 데이터에 대해 저역 통과 필터를 수행하여 저역 통과 구성요소 데이터를 추출한다. 일부 실시예에서, 저역 통과 필터는 그래픽 처리 장치(GPU), 톤 매퍼 프로세서, 이미지 신호 프로세서, 또는 다른 이미지 전처리기를 사용하여 수행된다. 일부 실시예에서, 저역 통과 데이터 구성요소는 글로벌 조명 데이터와 같은 캡처된 센서 데이터의 글로벌 데이터를 나타낸다. 다양한 실시예에서, 503, 513 및 523에서 수행되는 필터링은 동일하거나 상이한 이미지 전처리기를 사용할 수 있다. 예를 들어, 톤 매퍼 프로세서는 고역 통과 데이터 구성요소를 추출하는 데 사용되고 그래픽 처리 장치 (GPU)는 대역 통과 및/또는 저역 통과 데이터 구성요소를 추출하는 데 사용된다. 일부 실시예에서, 데이터 구성 요소는 원래 캡처된 데이터에서 하나 이상의 데이터 구성요소를 감산함으로써 추출된다.505, 515 및 525에서, 각각의 고역 통과, 대역 통과 및 저역 통과 데이터 구성요소에 대해 후처리가 수행된다. 다양한 실시예에서, 신호 품질을 향상시키고/거나 데이터를 표현하는 데 필요한 데이터의 양을 감소시키기 위해 상이한 후처리 기술이 이용된다. 일부 실시예에서, 상이한 구성요소는 데이터 구성요소를 수신하는 네트워크 계 층에 대해 적절한 크기로 압축 및/또는 다운샘플링 된다. 다양한 실시예에서, 고역 통과 데이터는 대역 통과 데이터보다 더 높은 해상도를 가질 것이고 대역 통과 데이터는 저역 통과 데이터보다 더 높은 해상도를 가질 것 이다. 일부 실시예에서, 상이한 대역 통과 데이터 구성요소는 또한 각각이 입력으로서 제공되는 네트워크 계층 에 대해 적절한 상이한 해상도를 가질 것이다. 일부 실시예에서, 각각의 데이터 구성요소는 센서에 의해 캡처된 더 높은 비트 깊이에서 딥 러닝 네트워크와 호환되는 더 낮은 비트 깊이로 압축되거나 양자화된다. 예를 들어, 채널당 12 비트로 캡처된 센서 데이터는 채널당 8 비트로 압축되거나 양자화 될 수 있다 다양한 실시예에서, 전 처리 필터는 도 2의 207 및/또는 도 4의 405, 415 및/또는 417에 대해 설명된 바와 같이 적용된다. 537에서, 505, 515 및 525의 데이터 구성요소 결과를 사용하여 딥 러닝 분석이 수행된다. 일부 실시예에서, 고 역 통과 데이터 구성요소는 딥 러닝 네트워크의 초기 계층으로 공급되고 특징 및 에지 검출을 위한 가장 중요한 데이터를 나타낸다. 하나 이상의 대역 통과 데이터 구성요소는 네트워크의 중간 계층(들)으로 공급되고 특징/에 지 및/또는 유익한 중간 또는 글로벌 정보를 식별하기 위한 추가 데이터를 포함한다. 저역 통과 데이터 구성요 소는 네트워크의 나중 계층으로 공급되며 딥 러닝 네트워크의 분석 결과를 개선하기 위해 글로벌 정보를 포함한 다. 딥 러닝 분석을 수행할 때, 결과의 정확성을 높이기 위해 분석이 진행됨에 따라 서로 다른 센서 데이터를 나타내는 추가 데이터 구성요소가 서로 다른 계층으로 공급된다. 다양한 실시예에서, 딥 러닝 분석은 차량 제어 결과를 추론한다. 예를 들어, 딥 러닝 분석 결과는 자율 주행을 위한 차량 제어에 사용된다. 일부 실시예에서, 기계 학습 결과는 차량을 적어도 부분적으로 자율적으로 작동하기 위해 차량 제어 모듈에 제공된다. 도 6은 자율 주행을 위한 딥 러닝 시스템의 일 실시예를 나타낸 블록도이다. 일부 실시예에서, 도 6의 딥 러닝 시스템은 자가 주행 및 운전자 보조 자동차(self-driving and driver-assisted automobile)를 위한 자율 주행 기능을 구현하는 데 사용될 수 있다. 예를 들어, 차량에 부착된 센서를 사용하여 센서 데이터를 캡처 하고 다른 입력 구성요소로 처리하고 딥 러닝 네트워크의 여러 단계로 공급한다. 딥 러닝 분석 결과는 차량 제어 모듈에서 차량 작동을 지원하는 데 사용된다. 일부 실시예에서, 차량 제어 모듈은 차량의 자율 주행 또는 운전자 보조 작 동을 위해 사용된다. 다양한 실시예에서, 도 1-5의 프로세스는 도 6에 설명된 것과 같은 딥 러닝 시스템을 활용 한다. 도시된 예에서, 딥 러닝 시스템(deep learning system)은 센서(sensor), 이미지 전처리기(image pre-processor), 딥 러닝 네트워크(deep learning network), 인공 지능(artificial intelligence)(AI) 프로세서, 차량 제어 모듈(vehicle control module) 및 네트워크 인터페이스 (network interface)를 포함하는 딥 러닝 네트워크이다. 다양한 실시예에서, 상이한 구성요소는 통신 가능 하게 연결된다. 예를 들어, 센서로부터의 센서 데이터는 이미지 전처리기에 공급된다. 이미지 전처리 기의 처리된 센서 데이터 구성요소는 AI 프로세서에서 실행되는 딥 러닝 네트워크에 공급된다. AI 프로세서에서 실행되는 딥 러닝 네트워크의 출력은 차량 제어 모듈에 공급된다. 다양한 실시 예에서, 네트워크 인터페이스는 차량의 자율 작동에 기초하여 원격 서버와 통신하고, 전화를 걸고, 문자 메시지를 보내고/또는 수신하는 데 사용된다. 일부 실시예에서, 센서는 하나 이상의 센서를 포함한다. 다양한 실시예에서, 센서는 차량의 상이한 위치에서 차량에 부착될 수 있고/있거나 하나 이상의 상이한 방향으로 배향될 수 있다. 예를 들어, 센서는 전방, 후방, 측면 등의 방향으로 차량의 전방, 측면, 후방 및/또는 지붕 등에 부착될 수 있다. 일부 실시예에서, 센서는 높은 동적 범위 카메라와 같은 이미지 센서 일 수 있다. 일부 실시예에서, 센서 는 비 시각적 센서를 포함한다. 일부 실시예에서, 센서는 무엇보다도 레이더(radar), LiDAR 및/또는 초음 파 센서를 포함한다. 일부 실시예에서, 센서는 차량 제어 모듈과 함께 차량에 장착되지 않는다. 예를 들어, 센서는 주변 차량에 장착되거나 도로 또는 주변에 부착될 수 있으며 센서 데이터를 캡처 하기 위한 딥 러닝 시스템의 일부로 포함된다. 일부 실시예에서, 이미지 전처리기는 센서의 센서 데이터를 전처리 하는데 사용된다. 예를 들어, 이 미지 전처리기는 센서 데이터를 전처리하고, 센서 데이터를 하나 이상의 구성요소로 분할하고, 및/또는 하 나 이상의 구성요소를 후처리하는데 사용될 수 있다. 일부 실시예에서, 이미지 전처리기는 그래픽 처리 장 치(GPU), 중앙 처리 장치(CPU), 이미지 신호 프로세서, 또는 특수 이미지 프로세서이다. 다양한 실시예에서, 이 미지 전처리기는 높은 동적 범위 데이터를 처리하기위한 톤 매퍼 프로세서이다. 일부 실시예에서, 이미지 전처리기는 인공 지능(AI) 프로세서의 일부로서 구현된다. 예를 들어, 이미지 전처리기는 AI 프로세서의 구성요소 일 수 있다. 일부 실시예에서, 딥 러닝 네트워크는 자율 차량 제어를 구현하기 위한 딥 러닝 네트워크이다. 예를 들어, 딥 러닝 네트워크는 센서 데이터를 사용하여 훈련되고 차량 제어 결과를 차량 제어 모듈에 출력하는 데 사용되는 컨볼루션 신경망(CNN)과 같은 인공 신경망 일 수 있다. 다양한 실시예에서, 딥 러닝 네트워크(60 5)는 다단계 학습 네트워크이고 네트워크의 2 개 이상의 상이한 단계에서 입력 데이터를 수신할 수 있다. 예를 들어, 딥 러닝 네트워크는 딥 러닝 네트워크의 제1 계층에서 특징 및/또는 에지 데이터를 수신하고 딥 러닝 네트워크의 이후 계층(예를 들어, 제2 또는 제3 등의 계층)에서 글로벌 데이터를 수신할 수 있다. 다양한 실시예에서, 딥 러닝 네트워크는 네트워크의 둘 이상의 상이한 계층에서 데이터를 수신하고 상이한 계층을 통해 처리될 때 데이터를 압축 및/또는 축소할 수 있다. 예를 들어, 계층 하나(layer one)의 데이터 크 기는 후속 단계의 데이터보다 높은 해상도이다. 일부 실시예에서, 계층 하나의 데이터 크기는 캡처된 이미지 데 이터의 전체 해상도이고 후속 계층의 데이터는 캡처된 이미지 데이터의 더 낮은 해상도(예를 들어, 크기의 1/ 4)이다. 다양한 실시예에서, 딥 러닝 네트워크의 후속 계층(들)에서 이미지 전처리기로부터 수신된 입력 데이터는 하나 이상의 이전 계층을 통해 처리되는 데이터의 내부 데이터 해상도(들)와 일치한다. 일부 실시예에서, 인공 지능(AI) 프로세서는 딥 러닝 네트워크를 실행하기 위한 하드웨어 프로세서이 다. 일부 실시예에서, AI 프로세서는 센서 데이터에 대해 컨볼루션 신경망(CNN)을 사용하여 추론을 수행하 기 위한 특수 AI 프로세서이다. 일부 실시예에서, AI 프로세서는 센서 데이터의 비트 깊이에 대해 최적화 된다. 일부 실시예에서, AI 프로세서는 무엇보다도 컨볼루션, 내적, 벡터 및/또는 행렬 연산을 포함하는 신경망 연산과 같은 딥 러닝 연산을 위해 최적화된다. 일부 실시예에서, AI 프로세서는 그래픽 처리 장치 (GPU)를 사용하여 구현된다. 다양한 실시예에서, AI 프로세서는 실행될 때 AI 프로세서가 수신된 입력 센 서 데이터에 대해 딥 러닝 분석을 수행하고 적어도 부분적으로 차량을 자율적으로 작동하는 데 사용되는 기계 학습 결과를 결정하게 하는 명령을 AI 프로세서에 제공하도록 구성된 메모리에 결합된다. 일부 실시예에서, 차량 제어 모듈은 인공 지능(AI) 프로세서의 출력을 처리하고 출력을 차량 제어 동 작으로 변환하기 위해 사용된다. 일부 실시예에서, 차량 제어 모듈은 자율 주행을 위해 차량을 제어하기 위해 사용된다. 일부 실시예에서, 차량 제어 모듈은 차량의 속도 및/또는 조향을 조정할 수 있다. 예를 들 어, 차량 제어 모듈은 제동(braking), 조향(steering), 차선 변경(changing lanes), 가속(accelerating) 및 다른 차선으로의 합류(merging into a different lane) 등을 통해 차량을 제어하는 데 사용될 수 있다. 일부 실시예에서, 차량 제어 모듈은 브레이크 등, 방향 지시등, 헤드 라이트 등과 같은 차량 조명을 제어하기 위해 사용된다. 일부 실시예에서, 차량 제어 모듈은 차량의 사운드 시스템, 오디오 경고 재생, 마이크 활 성화, 경적 활성화 등과 같은 차량 오디오 상태를 제어하는 데 사용된다. 일부 실시예에서, 차량 제어 모듈 은 잠재적 충돌 또는 의도된 목적지의 접근과 같은 운전 이벤트를 운전자 및/또는 승객에게 알리기 위해 경고 시스템을 포함하는 알림 시스템을 제어하는 데 사용된다. 일부 실시예에서, 차량 제어 모듈은 차량의 센서와 같은 센서를 조정하는 데 사용된다. 예를 들어, 차량 제어 모듈은 방향 수정, 출력 해상도 및 /또는 형식 유형 변경, 캡처 속도 증가 또는 감소, 캡처된 동적 범위 조정, 카메라의 초점 조정, 센서의 활성화 및/또는 비활성화 등과 같은 하나 이상의 센서의 파라미터를 변경하는 데 사용될 수 있다. 일부 실시예에서, 차 량 제어 모듈은 필터의 주파수 범위 수정, 특징 및/또는 에지 검출 파라미터 조정, 채널 및 비트 깊이 조 정 등과 같은 이미지 전처리기의 파라미터를 변경하는 데 사용될 수 있다. 다양한 실시예에서, 차량 제어 모듈은 차량의 자율 주행 및/또는 운전자 지원 제어를 구현하는 데 사용된다. 일부 실시예에서, 네트워크 인터페이스는 음성 데이터를 포함하는 데이터를 전송 및/또는 수신하기 위한 통신 인터페이스이다. 다양한 실시예에서, 네트워크 인터페이스는 원격 서버와의 인터페이싱, 연결 및 음 성 호출, 문자 메시지 전송 및/또는 수신 등을 위한 셀룰러 또는 무선 인터페이스를 포함한다. 예를 들면, 네트 워크 인터페이스는 센서, 이미지 전처리기, 딥 러닝 네트워크, AI 프로세서 및/또는 차량 제어 모듈에 대한 명령 및/또는 작동 파라미터에 대한 업데이트를 수신하는 데 사용될 수 있다. 예를 들어, 딥 러닝 네트워크의 기계 학습 모델은 네트워크 인터페이스를 사용하여 업데이트 될 수 있다. 또 다른 예로, 네트워크 인터페이스는 센서의 펌웨어 및/또는 이미지 처리 파라미터와 같은 이미지 전처리기의 동작 파라미터를 업데이트 하는데 사용될 수 있다. 일부 실시예에서, 네트워크 인터페이스 는 사고 또는 근처 사고의 경우 긴급 서비스와 긴급 연락을 하기 위해 사용된다. 예를 들어, 충돌이 발생 한 경우, 네트워크 인터페이스를 사용하여 긴급 서비스에 도움을 요청하고 긴급 서비스에 차량의 위치 및 충돌 세부 정보를 알릴 수 있다. 다양한 실시예에서, 네트워크 인터페이스는 목적지 위치 및/또는 예상 도 착 시간을 검색 및/또는 업데이트 하기 위해 캘린더 정보에 액세스 하는 것과 같은 자율 주행 기능을 구현하는데 사용된다. 전술한 실시예가 이해의 명확성을 위해 일부 상세하게 설명되었지만, 본 발명은 제공된 세부 사항에 제한되지 않는다. 본 발명을 구현하는 많은 대안적인 방법이 있다. 개시된 실시예는 예시 적이며 제한적이지 않다."}
{"patent_id": "10-2023-7010288", "section": "도면", "subsection": "도면설명", "item": 1, "content": "본 발명의 다양한 실시예가 다음의 상세한 설명 및 첨부 도면에서 개시된다. 도 1은 딥 러닝 파이프 라인을 사용하여 기계 학습 처리를 수행하기 위한 프로세스의 실시예를 예시하는 흐름도 이다. 도 2는 딥 러닝 파이프 라인을 사용하여 기계 학습 처리를 수행하기 위한 프로세스의 실시예를 예시하는 흐름도 이다. 도 3은 구성요소 데이터를 사용하여 기계 학습 처리를 수행하기 위한 프로세스의 실시예를 예시하는 흐름도이다. 도 4는 고역 통과 및 저역 통과 구성요소 데이터를 사용하여 기계 학습 처리를 수행하기 위한 프로세스의 실시 예를 예시하는 흐름도이다. 도 5는 고역 통과, 대역 통과 및 저역 통과 구성요소 데이터를 사용하여 기계 학습 처리를 수행하기 위한 프로 세스의 실시예를 예시하는 흐름도이다. 도 6은 자율 주행을 위한 딥 러닝 시스템의 일 실시예를 나타내는 블록도이다."}
