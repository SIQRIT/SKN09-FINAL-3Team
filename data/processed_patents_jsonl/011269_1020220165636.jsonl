{"patent_id": "10-2022-0165636", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0103952", "출원번호": "10-2022-0165636", "발명의 명칭": "객체 인식 기반 지능형 특수효과 생성 장치 및 방법", "출원인": "세종대학교산학협력단", "발명자": "송오영"}}
{"patent_id": "10-2022-0165636", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "객체 인식 기반 지능형 특수효과 생성 장치에 있어서,객체에 대해 촬영한 영상을 수신하는 통신 모듈;상기 수신한 영상으로부터 특수효과 정보를 생성하는 프로그램이 저장된 메모리; 및상기 메모리에 저장된 프로그램을 실행하는 프로세서를 포함하며, 상기 프로그램은, 카메라로부터 획득한 객체 영상을 객체 인식 모델에 입력하여 각 객체의 속성이 매칭된 객체이미지를 추출하고, 상기 각 객체의 속성 별 객체 이미지의 크기 정보를 무게 추정 모델에 입력하여 상기 각 객체의 무게 정보를 도출하고,상기 각 객체의 속성 별 무게 정보에 기초하여 상기 각 객체에 매핑되는 특수효과 제어 정보를 결정하는 것인,특수효과 생성 장치."}
{"patent_id": "10-2022-0165636", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 객체 인식 모델은 미리 설정된 물체를 포함한 객체 영상으로부터 식별된 각 객체 이미지와 상기 각 객체의속성을 레이블링한 훈련 데이터에 기반하여 구축된 것으로서, 깊이 카메라로부터 획득한 각 객체까지의 깊이 정보를 전이학습(transfer learning)을 통해 학습하여 상기 객체이미지의 2차원 좌표를 증강 현실의 3차원 좌표로 변환하는 것이고,상기 각 객체 이미지는 상기 각 객체에 적합하도록 형성된 바운딩 박스의 크기로 잘려진 이미지인 것인, 특수효과 생성 장치."}
{"patent_id": "10-2022-0165636", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,상기 프로그램은상기 각 객체까지의 깊이 정보를 기초로 뷰 절두체(View Frustum)의 크기 정보를 산출하고, 상기 뷰 절두체의크기 정보와 상기 객체 이미지의 크기 정보에 기초하여, 각 객체의 실제 가로 및 세로 길이 정보를 산출하는 것인, 특수효과 생성 장치."}
{"patent_id": "10-2022-0165636", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서,상기 무게 추정 모델은 상기 각 객체의 실제 가로 및 세로 길이 정보를 입력으로 하여 상기 각 객체의 무게 정보가 출력되도록 상기 각 객체의 속성 별로 다중회귀모델이 구축되는 것인, 특수효과 생성 장치."}
{"patent_id": "10-2022-0165636", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "공개특허 10-2023-0103952-3-제1항에 있어서,상기 프로그램은상기 각 객체의 속성 별 상기 무게 정보가 클수록 화재 특수효과의 크기, 강도 및 지속 시간이 증가되도록 제어하는 것인, 특수효과 생성 장치."}
{"patent_id": "10-2022-0165636", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "객체 인식 기반 지능형 특수효과 생성 장치에 의한 특수효과 생성 방법에 있어서,(a) 카메라로부터 획득한 객체 영상을 객체 인식 모델에 입력하여 각 객체의 속성이 매칭된 객체 이미지를 추출하는 단계; (b) 상기 각 객체의 속성 별 객체 이미지의 크기 정보를 무게 추정 모델에 입력하여 상기 각 객체의 무게 정보를 도출하는 단계; 및(c) 상기 각 객체의 속성 별 무게 정보에 기초하여 상기 각 객체에 매핑되는 특수효과 제어 정보를 결정하는 단계를 포함하는 것인, 특수효과 생성 방법."}
{"patent_id": "10-2022-0165636", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6항에 있어서,상기 객체 인식 모델은 미리 설정된 물체를 포함한 객체 영상으로부터 식별된 각 객체 이미지와 상기 각 객체의속성을 레이블링한 훈련 데이터에 기반하여 구축된 것으로서, 깊이 카메라로부터 획득한 각 객체까지의 깊이 정보를 전이학습(transfer learning)을 통해 학습하여 상기 객체이미지의 2차원 좌표를 증강 현실의 3차원 좌표로 변환하는 것이고,상기 각 객체 이미지는 상기 각 객체에 적합하도록 형성된 바운딩 박스의 크기로 잘려진 이미지인 것인, 특수효과 생성 방법."}
{"patent_id": "10-2022-0165636", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서,상기 (b) 단계는상기 각 객체까지의 깊이 정보를 기초로 뷰 절두체(View Frustum)의 크기 정보를 산출하고, 상기 뷰 절두체의크기 정보와 상기 객체 이미지의 크기 정보에 기초하여, 각 객체의 실제 가로 및 세로 길이 정보를 산출하는 단계를 포함하는 것인, 특수효과 생성 방법."}
{"patent_id": "10-2022-0165636", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서,상기 무게 추정 모델은 상기 각 객체의 실제 가로 및 세로 길이 정보를 입력으로 하여 상기 각 객체의 무게 정보가 출력되도록 상기 각 객체의 속성 별로 다중회귀모델이 구축되는 것인, 특수효과 생성 방법."}
{"patent_id": "10-2022-0165636", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제6항에 있어서,상기 (c) 단계는공개특허 10-2023-0103952-4-상기 각 객체의 속성 별 상기 무게 정보가 클수록 불 특수효과의 크기, 강도 및 지속 시간이 증가되도록 제어하는 것인, 특수효과 생성 방법."}
{"patent_id": "10-2022-0165636", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명의 일 실시예에 따른 객체 인식 기반 지능형 특수효과 생성 장치는 객체에 대해 촬영한 영상을 수신하는 통신 모듈; 수신한 영상으로부터 특수효과 정보를 생성하는 프로그램이 저장된 메모리; 및 메모리에 저장된 프로 그램을 실행하는 프로세서를 포함하며, 프로그램은, 카메라로부터 획득한 객체 영상을 객체 인식 모델에 입력하 여 각 객체의 속성이 매칭된 객체 이미지를 추출하고, 각 객체의 속성 별 객체 이미지의 크기 정보를 무게 추정 모델에 입력하여 각 객체의 무게 정보를 도출하고, 각 객체의 속성 별 무게 정보에 기초하여 각 객체에 매핑되는 특수효과 제어 정보를 결정한다."}
{"patent_id": "10-2022-0165636", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 객체 인식 기반 지능형 특수효과 생성 장치 및 방법에 관한 것이다."}
{"patent_id": "10-2022-0165636", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "일반적으로 혼합현실(Mixed Reality, MR)이란, 가상 세계와 현실 세계를 합쳐서 새로운 환경이나 시각화 등 새 로운 정보를 만들어내는 등의 실감 영상 기술을 말한다. 혼합현실을 구현하기 위해 증강현실(Augmented Reality, AR) 기술과 가상현실(Virtual Reality, VR) 기술이 연 구되고 있다. 증강현실 기술은 사용자가 자각하는 현실에 컴퓨터가 만든 정보를 추가하는 것이며, 가상현실 기 술은 실제와 유사하지만 현실은 아닌 환경이나 상황을 만드는 것이다. 다만 현실 세계의 물리 법칙을 가상 세계 에 적용되지 않는 점 등의 한계가 있다. 이러한 한계를 극복하기 위해, 인지하는 현실을 공간 정보를 활용하여 가상/증강/혼합현실 환경에서 지능형 특수효과를 생성/변형/상호작용하는 방법 및 장치가 연구되고 있다. 이와 관련하여, 현실 세계에서 획득한 객체의 종류와 위치를 알면 물리적 공간의 관계에 기반한 특수효과를 사 용하여 사실적인 VR/AR 콘텐츠를 제작하는 기술이 있다. 증강현실(AR) 기술은 실시간으로 현실에 있는 정보 일부를 대체하며, 사용자에게 가상 콘텐츠를 제공하는 동시 에 실제 환경에서의 사용자 경험을 유지하도록 한다. 그러나 기존의 기술은 가상 객체 간의 생성 및 상호작용에 한정되며, 실제 현실의 공간 정보는 가상 객체를 놓기 위한 책상의 수평 평면(Horizontal Plane) 밖에 활용되지 못한다는 한계가 있다. 따라서 공간 정보를 활용하여 생성/변형/상호작용할 수 있는 지능형 특수효과를 제공하기 위해서는 현실 정보의 인지 기술과 특수효과의 증강 기술이 필요하다. 현실 정보의 인지 기술은 딥러닝 기반 객체 탐지 알고리즘이 대표적이며, 자율주행차의 도로 분석, 사람 추적 등 여러 분야에 쓰이고 있다. 기존의 이미지 기반 딥러닝 기술은 기본적으로 2차원 이미지를 분석하고 있고, 혼 합현실은 실제 우리가 생활하고 있는 3차원 공간이기 때문에 적용이 어렵다. 이처럼 기존의 연구는 대부분 2차 원 이미지를 통한 물체 인식이 진행되고 있다. 이와 관련된 기존의 혼합 현실 기술의 구체적인 내용을 살펴보면 다음과 같다. 첫째, 뉴럴 네트워크(신경망)를 적용한 이미지 분석 및 객체 분류 방법은 영역 지정과 회귀의 두 가지 유형이 있다. 예를 들어 영역 지정 방법 으로서, R-CNN, SPP-Net, Fast R-CNN, Faster R-CNN등의 알고리즘은 선택적 검색을 사용하여 이미지에서 제안 영역을 추출한 다음 제안 영역 내에서 이미지를 분류한다. 그리고 회귀 방법의 모델로서, YOLO는 객체 경계 상 자(Bounding Box)와 클래스 이름을 예측하여, 빠른 탐지가 가능하다. 그러나 네트워크 아키텍처가 단순하기 때 문에 프레임 속도가 증가하면 탐지 정확도가 떨어진다는 한계가 있다. 둘째, 증강현실 기술은 실시간으로 현실의 물체 일부를 가상 정보로 대체(증강)하는 것이다. 즉 증강현실 기술 은 현실 세계와 가상 세계를 결합하는 기능, 실시간으로 가상의 상호작용을 제공하는 기능 및 3차원 공간에서 가상 정보를 표현하는 기능을 포함한다. 즉, 증강현실 기술은 객체의 높이, 넓이, 그리고 깊이와 같은 3차원 정 보를 이용하여 증강현실 환경에서 보다 자연스러운 특수효과 상호작용을 구현하기 위해 연구되고 있다. 일 예 로, 기존의 3차원 정보를 이용한 증강현실 기술은 객체에 올려져있는 그림, 마커 따위를 인식해 이에 지정된 효 과를 증강하는 기술이 있다. 그러나 기존의 증강현실 기술은 어디에 어떠한 물체가 있는지, 평면은 어떻게 구성 되고 있는지와 공간 정보를 바탕으로 한 시각적인 특수효과 구현을 효과적으로 할 수 있으나, 이러한 물체가 어 떠한 물체인지, 상황 판단과 같은 공간 이외의 갑작스러운 상황은 이해하지 못한다는 한계가 있다. 따라서, 한계가 있는 두 기술의 장점을 병합시켜 인공지능을 통한 물체의 인식과 이를 증강현실 기술을 통한 3 차원 위치에서의 증강 및 물체에 따른 지능적인 특수효과 구현을 제공하는 기술의 필요성이 요구되고 있다. 선행기술문헌특허문헌 (특허문헌 0001) 대한민국 등록특허공보 제10-22403513호(발명의 명칭: 증강 현실 콘텐츠 표시를 위한 장치 및 그 제어방법)"}
{"patent_id": "10-2022-0165636", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명의 일 실시예에 따른 객체 인식 기반 지능형 특수효과 생성 장치 및 방법은 객체 탐지 기술에 이미지의 깊이와 실제 3차원 위치를 알 수 있는 증강현실 기술을 결합하여 사용자가 지능적으로 장면을 이해할 수 있는 특수효과를 제공하고자 한다."}
{"patent_id": "10-2022-0165636", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 일 실시예에 따른 객체 인식 기반 지능형 특수효과 생성 장치는 객체에 대해 촬영한 영상을 수신하는 통신 모듈; 수신한 영상으로부터 특수효과 정보를 생성하는 프로그램이 저장된 메모리; 및 메모리에 저장된 프 로그램을 실행하는 프로세서를 포함하며, 프로그램은, 카메라로부터 획득한 객체 영상을 객체 인식 모델에 입력 하여 각 객체의 속성이 매칭된 객체 이미지를 추출하고, 각 객체의 속성 별 객체 이미지의 크기 정보를 무게 추 정 모델에 입력하여 각 객체의 무게 정보를 도출하고, 각 객체의 속성 별 무게 정보에 기초하여 각 객체에 매핑 되는 특수효과 제어 정보를 결정한다. 본 발명의 다른 실시예에 따른 객체 인식 기반 지능형 특수효과 생성 장치에 의한 특수효과 생성 방법은 (a) 카 메라로부터 획득한 객체 영상을 객체 인식 모델에 입력하여 각 객체의 속성이 매칭된 객체 이미지를 추출하는 단계; (b) 각 객체의 속성 별 객체 이미지의 크기 정보를 무게 추정 모델에 입력하여 각 객체의 무게 정보를 도 출하는 단계; 및 (c) 각 객체의 속성 별 무게 정보에 기초하여 각 객체에 매핑되는 특수효과 제어 정보를 결정 하는 단계를 포함한다."}
{"patent_id": "10-2022-0165636", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명의 일 실시예에 따른 객체 인식 기반 지능형 특수효과 생성 장치 및 방법은 이미지 기반 딥러닝 기법을 활용하여 실시간으로 물체를 인식하고, 증강현실 기술을 통한 3차원 위치에서 인식한 물체에 대하여 특수효과를 제공함으로써 사용자에게 보다 실감적인 혼합현실 경험을 제공할 수 있다."}
{"patent_id": "10-2022-0165636", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하에서는 첨부한 도면을 참조하여, 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자가 용이하게 실시 할 수 있도록 본 발명의 실시예를 상세히 설명한다. 그러나, 본 발명은 여러 가지 상이한 형태로 구현될 수 있 으며 여기에서 설명하는 실시예에 한정되지 않는다. 그리고, 도면에서 본 발명을 명확하게 설명하기 위해서 설 명과 관계없는 부분은 생략하였으며, 명세서 전체를 통하여 유사한 부분에 대해서는 유사한 도면 부호를 붙였다. 명세서 전체에서, 어떤 부분이 다른 부분과 \"연결\"되어 있다고 할 때, 이는 \"직접적으로 연결\"되어 있는 경우, 그 중간에 다른 소자를 사이에 두고 \"전기적으로 연결\"되어 있는 경우도 포함한다. 또한, 어떤 부분이 어떤 구 성요소를 \"포함\"한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다른 구성요소를 제외하는 것이 아니라 다 른 구성요소를 더 포함할 수 있는 것을 의미한다. 본 명세서에 있어서 '부(部)'란, 하드웨어 또는 소프트웨어에 의해 실현되는 유닛(unit), 양방을 이용하여 실현 되는 유닛을 포함하며, 하나의 유닛이 둘 이상의 하드웨어를 이용하여 실현되어도 되고, 둘 이상의 유닛이 하나 의 하드웨어에 의해 실현되어도 된다. 한편, '~부'는 소프트웨어 또는 하드웨어에 한정되는 의미는 아니며, '~ 부'는 어드레싱할 수 있는 저장 매체에 있도록 구성될 수도 있고 하나 또는 그 이상의 프로세서들을 재생시키도 록 구성될 수도 있다. 따라서, 일 예로서 '~부'는 소프트웨어 구성요소들, 객체지향 소프트웨어 구성요소들, 클 래스 구성요소들 및 태스크 구성요소들과 같은 구성요소들과, 프로세스들, 함수들, 속성들, 프로시저들, 서브루 틴들, 프로그램 코드의 세그먼트들, 드라이버들, 펌웨어, 마이크로코드, 회로, 데이터, 데이터베이스, 데이터 구조들, 테이블들, 어레이들 및 변수들을 포함한다. 구성요소들과 '~부'들 안에서 제공되는 기능은 더 작은 수 의 구성요소들 및 '~부'들로 결합되거나 추가적인 구성요소들과 '~부'들로 더 분리될 수 있다. 뿐만 아니라, 구 성요소들 및 '~부'들은 디바이스 내의 하나 또는 그 이상의 CPU들을 재생시키도록 구현될 수도 있다. 도 1은 본 발명의 일 실시예에 따른 객체 인식 기반 지능형 특수효과 생성 장치의 구성을 보여주는 도면이다. 도 1을 참조하면, 본 발명의 일 실시예에 따른 객체 인식 기반 특수효과 생성 장치는 카메라, 통신 모 듈, 메모리, 프로세서 및 데이터베이스를 포함한다. 통신 모듈은 통신망과 연동하여 특수효과 생성 장치에 카메라로 촬영된 이미지를 송수신할 수 있 는 통신 인터페이스를 제공하는데, 특히 카메라 기기 및 관리 서버와의 데이터를 송수신하는 역할을 수행할 수 있다 여기서, 통신 모듈은 다른 네트워크 장치와 유무선 연결을 통해 제어 신호 또는 데이터 신호와 같은 신호를 송수신하기 위해 필요한 하드웨어 및 소프트웨어를 포함하는 장치일 수 있다. 예를 들어 카메라는 2차원 영상을 촬영할 수 있는 카메라 모듈로서, 사용자 단말에 장착된 것일 수 있으나 이에 한정된 것은 아니다. 또한 카메라 모듈은 LiDAR 스캐너와 같이 3차원 깊이 데이터를 측정할 수 있는 깊이 카메라를 포함할 수 있다. 메모리는 특수효과 정보를 생성하는 프로그램이 기록된 것일 수 있다. 또한, 메모리는 프로세서(13 0)가 처리하는 데이터를 일시적 또는 영구적으로 저장하는 기능을 수행할 수 있다. 여기서, 메모리는 휘발 성 저장 매체(volatile storage media) 또는 비휘발성 저장 매체(non-volatile storage media)를 포함할 수 있 으나, 본 발명의 범위가 이에 한정되는 것은 아니다. 메모리에는 객체 인식 기반 지능형 특수효과 생성 방법을 제공하는 프로그램이 저장된다. 이러한 메모리 에는 특수효과 생성 장치의 구동을 위한 운영 체제나 객체 인식 기반 지능형 특수효과 생성 방법을 제공하는 프로그램의 실행 과정에서 발생되는 여러 종류가 데이터가 저장된다. 프로세서는 메모리에 저장된 프로그램을 실행하되, 객체 인식 기반 지능형 특수효과 생성 방법을 제 공하는 프로그램의 실행에 따라 다음과 같은 처리를 수행한다. 프로그램은, 카메라로부터 획득한 객체 영상을 객체 인식 모델에 입력하여 각 객체의 속성이 매칭된 객체 이미 지를 추출하고, 각 객체의 속성 별 객체 이미지의 크기 정보를 무게 추정 모델에 입력하여 각 객체의 무게 정보 를 도출하고, 각 객체의 속성 별 무게 정보에 기초하여 각 객체에 매핑되는 특수효과 제어 정보를 결정한다. 이러한 프로세서는 데이터를 처리할 수 있는 모든 종류의 장치를 포함할 수 있다. 예를 들어 프로그램 내 에 포함된 코드 또는 명령으로 표현된 기능을 수행하기 위해 물리적으로 구조화된 회로를 갖는, 하드웨어에 내 장된 데이터 처리 장치를 의미할 수 있다. 이와 같이 하드웨어에 내장된 데이터 처리 장치의 일 예로써, 마이 크로프로세서(microprocessor), 중앙처리장치(central processing unit: CPU), 프로세서 코어(processor core), 멀티프로세서(multiprocessor), ASIC(application-specific integrated circuit), FPGA(field programmable gate array) 등의 처리 장치를 망라할 수 있으나, 본 발명의 범위가 이에 한정되는 것은 아니다. 데이터베이스는 객체 인식 기반 지능형 특수효과 생성 방법을 수행하기 위해 공동으로 필요한 데이터를 유 기적으로 결합하여 저장한 매체일 수 있다. 데이터베이스는 미리 설정된 물체를 포함한 객체 영상, 각 물 체에 적합하도록 형성된 바운딩 박스 크기로 잘려진 객체 이미지, 각 객체의 종류, 재질, 크기 또는 무게를 포 함하는 객체의 속성 및 학습 데이터가 저장된 것일 수 있다. 이러한 데이터베이스는 메모리와는 별도의 구 성 요소로서 포함되거나, 또는 메모리의 일부 영역에 구축될 수도 있다. 도 2는 본 발명의 일 실시예에 따른 객체 인식 기반 지능형 특수효과 생성 장치의 세부 모듈을 설명하기 위한 블록도이고, 도 3은 본 발명의 일 실시예에 따른 객체 인식 기반 지능형 특수효과 생성 장치를 설명하기 위한 도면이다. 도 2를 참조하면, 프로세서는 메모리에 저장된 프로그램의 실행에 따라 다양한 기능을 수행하는 세부 모듈을 포함할 수 있다. 세부 모듈은 객체 인식 모델, 객체 크기 산출부, 무게 추정 모델 및 특 수 효과 제어부를 포함한다. 도 3을 참조하면 프로그램은 카메라로부터 획득한 객체 영상을 객체 인식 모델에 입력하여 각 객체의 속성이 매칭된 객체 이미지를 추출할 수 있다. 이때 각 객체의 속성은 객체의 종류, 재질, 크기 및 무게를 포함 할 수 있으나 이에 한정되는 것은 아니다. 이어서 프로그램은 객체 크기 산출부를 통해 산출한 각 객체의 속성 별 객체 이미지의 크기 정보를 무게 추정 모델에 입력하여 각 객체의 무게 정보를 도출할 수 있다. 다음으로 프로그램은 특수 효과 제어부를 통해 각 객체의 속성 별 무게 정보와 깊이 카메라로부터 획득한 각 객체까지의 깊이 정보에 기초하여 각 객체에 매핑되는 특수효과 제어 정보를 결정할 수 있다. 이로 인해 본 발명은 객체 탐지 기술에 이미지의 깊이 정보와 실제 3차원 위치를 알 수 있는 증강현실 기술을 결합하여 사용자에게 보다 실감적인 특수효과를 제공할 수 있다. 이하, 도 3 내지 도 6을 참조하여 프로세서의 각 모듈의 구성을 상세히 설명하고자 한다. 도시된 것처럼 객체 인식 모델은 미리 설정된 물체를 포함한 객체 영상으로부터 식별된 각 객체 이미지와 각 객체의 속성을 레이블링한 훈련 데이터에 기반하여 구축된 것일 수 있다. 또한 객체 인식 모델은 깊이 카메라로부터 획득한 각 객체까지의 깊이 정보를 전이학습(transfer learning)을 통해 학습하여 객체 이미지의 2차원 좌표를 증강 현실의 3차원 좌표로 변환할 수 있다. 이때 각 객체 이미지는 각 객체에 적합하도록 형성된 바운딩 박스의 크기로 잘려진 이미지일 수 있다. 이에따라 객체 인식 모델은 카메라로부터 획득한 객체 영상이 입력되면 각 객체의 속성이 매칭된 객체 이미지를 추출할 수 있다. 예를 들어, 객체 이미지(바운딩 박스)에는 각 객체의 속성으로서, 객체의 종류, 객체 의 재질, 후술하는 객체의 크기 또는 객체의 무게가 매칭되어 데이터베이스에 저장될 수 있다. 예시적으로, 객체의 종류는 컵, 공, 화이트보드, 캔, 노트북, 병, 의자, 키보드, 마우스, 시계, 휴대전화, 가방, 상자, 휴지, 화분, 문손잡이, 소파, 계단, 쓰레기통, 책, 전자레인지, 수건, 숟가락, 프린터, 액자, 덤벨, 서랍장, 탁자, 카메라, 냉장고 등 객체 인식 모델로부터 인식하고자하는 대상 물체로 분류될 수 있다. 또한 객체의 재질은 세라믹컵, 종이컵, 유리컵 등을 포함하는 컵 카테고리 내에 분류되는 재질 별 객체, 야 구공, 축구공, 테니스공, 골프공 등을 포함하는 공 카테고리 내에서 분류되는 재질 별 객체, 플라스틱 병, 유리 병 등을 포함하는 병 카테고리 내에서 분류되는 재질 별 객체를 포함할 수 있다. 또한 객체 이미지는 사용자 단말의 화면을 통한 2차원의 이미지 기반 좌표를 이용하므로, 사용자 단말에 포함된 깊이 카메라로부터 측정된 깊이 정보에 기반한 전이학습을 통해 객체의 정확한 3차원 좌표를 파악할 수 있다. 이때 전이학습을 통한 객체 인식 모델의 상세한 학습 과정은 도 8 및 도9를 참조하여 후술하도록 한다. 도 4는 본 발명의 일 실시예에 따른 객체 크기 산출부를 설명하기 위한 도면이다. 도 4를 참조하면 객체 크기 산출부는 각 객체까지의 깊이 정보를 기초로 뷰 절두체(View Frustum)의 크기 정보를 산출하고, 뷰 절두체의 크기 정보와 객체 이미지(바운딩 박스)의 크기 정보에 기초하여, 각 객체의 실제 가로 및 세로 길이 정보를 산출할 수 있다. 즉, 바운딩 박스(객체 이미지)의 크기는 객체의 실제 크기에 대응될 수 있다. 예시적으로 객체 크기 산출부는 각 객체까지의 깊이 정보와 바운딩 박스의 크기를 뷰 절두체의 크기 비율 과 비교하여 인식한 객체의 실제 크기를 산출할 수 있다. 예를 들어 기하학에서 절두체는 입체를 절단하는 하나 나 두 평행면 사이의 부분을 의미한다. 컴퓨터 그래픽스에서 뷰 절두체는 스크린에서 볼 수 있는 삼차원 영역으 로 뷰포트(viewport)의 카메라에 대해서 상대적으로 배치된 장면 내의 3차원 볼륨을 의미한다. 즉 도 4에 도시 된 바와 같이, 깊이 카메라로부터 물체(객체)까지의 깊이 정보를 알면 3차원 공간에서 사각형으로 정의되는 뷰 절두체의 크기를 알 수 있다. 여기서 뷰 절두체의 크기는 스크린에서 보여지는 현실 세계의 실제 크기를 의미한 다. 원근 중심에서 화면의 상하단 중점을 잇는 선을 연장하였을 때 생기는 각도를 FoV(Field of View)라고 한다. 프로그램은 레이캐스트(Raycast)와 같은 3차원 랜더링 프로그램을 통해 물체와 충돌이 일어나는 지점에서 뷰 절두체의 시야각을 FoV로 정의하며 물체의 깊이 정보와 결합하여 뷰 절두체의 실제 크기를 산출할 수 있다. 객체 크기 산출부는 스크린 사이즈(스크린의 크기)를 획득할 수 있으며, 스크린 사이즈는 뷰 절두체의 실 제 크기에 대응되며, 수식1에 따라 객체의 실제 크기를 획득할 수 있다. <수식1>"}
{"patent_id": "10-2022-0165636", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "이후 프로그램은 객체 인식 모델에서 추출된 실제 객체의 2차원 좌표(x, y)에 깊이 카메라로부터 획득한 각 객체의 깊이 정보(z)를 매핑하여, 3차원 공간 상의 각 객체의 좌표를 파악하여, 이를 기초로 각 객체와 증강 현실의 상호작용을 수행할 수 있다. 또한 프로그램은 무게 추정 모델을 통해 각 객체의 무게 정보를 도출하고, 특수 효과 제어부를 통해 각 객체의 속성 별 무게 정보에 기초하여 각 객체에 매핑되는 특수효과 제어 정보를 결정할 수 있다. 예시적으로 무게 추정 모델은 각 객체의 실제 가로 및 세로 길이 정보를 입력으로 하여 각 객체의 무게 정 보가 출력되도록 각 객체의 속성 별로 다중회귀모델이 구축된 것일 수 있다. 예시적으로, 무게 추정 모델은 각 클래스(객체의 종류)마다 각각의 다중 선형 회귀 모델을 생성하여 인식 된 클래스 정보에 따라 수식2에 따른 해당 회귀 모델을 실행시켜 무게 값을 획득하도록 구성될 수 있다. <수식2>"}
{"patent_id": "10-2022-0165636", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "여기서, 는 무게, X1은 세로, X2는 가로를 의미하고, 는 해당 수식의 회귀선을 평행이동 시키는 정도이고, 는 세로 길이에 따라 무게 Y의 영향을 미치는 정도이고, 는 가로 길이에 따라 무게 Y의 영향을 미치는 정도 를 의미하는 회귀 계수이며, 해당 수식은 객체의 종류 별 객체의 크기에 따른 무게 학습 데이터를 바탕으로 무 게 값이 결정되는 것 일 수 있다. 예시적으로, 특수 효과 제어부는 각 객체의 속성 별 무게 정보가 클수록 불 특수효과의 크기, 강도 및 지 속 시간 이 증가되도록 특수효과 제어 정보를 제어할 수 있다. 도 5 및 도 6은 본 발명의 일 실시예에 따른 사용자 인터페이스의 일 예를 도시한 도면이다. 도 5를 참조하면, 프로그램은 카메라로부터 수신된 객체 영상을 실시간으로 수신하여 객체 이미지가 추출되면, 각 객체와 대응하는 바운딩 박스와 각 객체에 매칭된 객체의 종류, 재질, 무게, 크기를 포함하는 속성을 사용자 인터페이스를 통해 제공할 수 있다. 도 6은 특수효과 제어 정보가 불 효과로 설정된 경우를 나타낸 것이다. 프로그램은 각 객체의 속성으로 검출된 종이컵과 책의 객체의 종류, 종이 재질, 각 객체의 바운딩박스의 크기, 객체의 무게에 따라 불 효과의 크기, 강 도 및 지속시간이 맵핑될 수 있다. 예를 들어 도 6(a)는 책에서 발화가 시작된 것이며, 도6(b)는 시간이 지남에 따라 책에 나타나는 불 효과의 크기, 강도 및 지속시간이 증가한 것을 나타낸 것이다. 이때 책의 무게는 책의 연소 시간(불 효과의 지속 시간), 불의 크기, 불의 강도를 결정하는 연료의 양을 의미할 수 있다. 이하에서는 상술한 도 1 내지 도 6에 도시된 구성 중 동일한 기능을 수행하는 구성의 경우 설명을 생략하기로 한다. 도 7은 본 발명의 다른 실시예에 따른 객체 인식 기반 지능형 특수효과 생성 방법을 설명하기 위한 순서도이다. 도 7을 참조하면, 본 발명의 객체 인식 기반 지능형 특수효과 생성 장치에 의한 특수효과 생성 방법은 카메라로 부터 획득한 객체 영상을 객체 인식 모델에 입력하여 각 객체의 속성이 매칭된 객체 이미지를 추출하는 단계 (S110), 각 객체의 속성 별 객체 이미지의 크기 정보를 무게 추정 모델에 입력하여 각 객체의 무게 정보를 도출 하는 단계(S120) 및 각 객체의 속성 별 무게 정보에 기초하여 각 객체에 매핑되는 특수효과 제어 정보를 결정하 는 단계(S130)를 포함한다. 이하 도 7 내지 도 21를 참조하여 본 발명의 구조물의 특수효과 생성 장치에 대한 실시예와 실험적 검증 결과를 설명한다. 도 8 및 도 9는 본 발명의 일 실시예에 따른 객체 인식 모델의 학습 과정을 설명하기 위한 도면이다. 먼저, YOLO 모델은 실시간 물체 인식에서의 초당 프레임 속도(FPS)가 45FPS에 도달할 수 있어, 실시간 이미지 분석에 적합하다. YOLO 모델은 FPS가 크게 떨어지는 영역 지정 방식 대신 회귀 방식을 사용하여, 객체 경계 상 자와 클래스 이름을 예측할 수 있다. 따라서 본 발명의 일 실시예에 따른 객체 인식 모델은 증강현실에서 실시간 객체 인식이 요구됨에 따라 YOLO모델을 적용할 수 있다. YOLO 모델은 전체 이미지를 네트워크에 입력하여, 경계 상자의 이미지 좌표와 해당 클래스의 레이블(Label)을 직접 반환할 수 있다. 특히, YOLOv3가 이전 세대 대비 더욱 뛰어난 규모의 예측이 가능하여 YOLO 모델 중에서 YOLOv3 심층 신경망을 객체 인식 모델에 적용할 수 있다. 예를 들어, YOLOv3 심층 신경망에서 각 입력 이 미지는 각각 32, 16 및 8만큼 다운샘플링되며, 이전 81개 레이어의 원본 입력이 다운샘플링된 후 82번째 레이어 에서 이미지 검출이 처음 수행된다. 이후 106번째 레이어에서 피쳐 맵을 생성하며 최종 이미지 검출이 수행된다. 텐서(Tensor) 절차 수준에서 YOLOv3 네트워크는 입력 이미지를 S × S 셀 그리드로 나누고, 각 셀은 중심이 그리드 셀 내부에 있는 잠재적 개체의 경계 상자(B)와 클래스 확률(C)을 예측하는 역할을 한다. 각 경계 상자에는 4개의 경계 상자 좌표와 개체 신뢰도 점수의 5가지 속성이 있으며, 이를 바탕으로 최종 물체 감지와 신뢰도를 분석한다. 또한 객체 인식 모델은 물리적 객체 인식을 위한 전이학습 모델을 포함할 수 있다. 즉 전이학습 모델은 혼 합현실 환경에서의 실행(implementation)을 위한 프레임워크가 필요하다. 증강현실 및 추후 가상현실 환경 실행 을 위해, 본 발명은 게임 엔진을 활용할 수 있다. 본 발명에서 활용하는 게임엔진은 증강현실과 가상현실을 비 롯한 대부분의 혼합현실 환경의 개발 및 빌드를 지원한다. 도 8은 FC 레이어의 필터 값 변경을 통한 데이터 세트 변경을 도시한 것이다. 도시된 바와 같이 객체 인식 모델 은 전이 학습(Transfer Learning)을 통한 ONNX의 교체를 통해, YOLOv3모델의 FC 레이어의 필터 값 변경을 통한 데이터 세트 변경을 하여 원하는 객체에 대한 물체 인식을 진행할 수 있다. 따라서 본 발명은 원하는 범위에 대한 좁은 대상을 지정하여 COCO와 같은 기존 학습 모델보다 빠르게 객체를 인 식하고 학습 모델의 성능을 높일 수 있다. 본 발명은 YOLOv3-tiny를 사용하여 학교, 사무실, 연구실에서 쉽게 볼 수 있는 상자, 병, 컵 등 진행 중인 20가 지 물체를 목표로 물리적 객체 학습을 진행하였다. 도 9는 YOLOv3-tiny를 통한 20가지 물체의 전이 학습 결과를 도시한 것이다. ONNX로의 전환 방법은 OpenVINO를 사용하였다. OpenVINO는 추론 엔진을 사용하여 Intel 하드에서에서의 딥러닝 모델을 최적화 할 수 있는 무료 툴 킷으로, 이를 이용하여 커스텀 모델의 ONNX로의 전환을 수행하였다. 도시된 바와 같이 객체 인식 모델은 개체당 700가지의 데이터 세트를 사용하여, 전이 학습을 통해 모델을 생성하였으며, 개체당 200개의 데이터를 사용하여 mAP(Mean Average Precision)를 측정하는 데 사용되었다. 다음으로 특수 효과 제어부를 통해 실제 증강현실에서 객체 인식 모델의 객체 인식을 적용할 수 있다. 증강현실에서의 구현은 자신만의 모델을 사용하여 실시간 2차원 이미지를 3차원 증강현실 장면에 사용할 수 있는 기존의 게임 엔진을 활용하였다. 이와 같은 게임 엔진은 객체 인식 모델로부터 추출된 객체 이미 지를 실시간으로 입력하여, 프레임 당 동일한 물체를 가리키고 있는 바운딩 박스를 그룹화하고 가장 높은 추론 신뢰도 점수를 가진 박스를 선택하여 위치를 적용(Localization)할 수 있다. 도 10은 기존의 게임 엔진을 통한 증강현실에서의 객체 인식 모델의 적용을 도시한 것이다. 도시된 바와 같이, 객체 인식 모델은 커스텀된 ONNX의 적용을 통해, 증강현실 상의 원하는 개체에 대한 인식이 가능하다. 도 11 및 도 12는 본 발명의 객체 인식 모델의 물체 인식에 대한 정확도 측정 결과를 도시한 것이다. 도시된 바 와 같이 기존의 분류 성능 모델을 측정하는 데이터셋과 달리, 선명한 이미지에 대해서만 데이터셋을 선정하여 mAP 값의 조금 더 높은 결과값이 산출되도록 하였다. 정확도를 측정하였을 때 70mAP의 결과값이 도출되었다. 또한 객체 인식 모델의 물체 인식 속도 역시 기존의 COCO 모델에 비해 크게 빠른 것이 확인되었다. 같은 물체의 인식을 시작하였을 때 바운딩 박스의 생성 속도는 1.80ms로 기존 모델의 3.72ms보다 크게 감소하였으며, 바운딩 박스의 생성 시작 이후 신뢰도가 가장 높은 박스를 적용하기까지 걸리는 시간은 2.57s로 기존 모델의 3.16s를 상회하는 것으로 나타난다. (COCO 모델과 동일한 개체를 가지고 있는 컴퓨터 마우스 기준, 20회 측정의 평균) 본 발명은 2차원 이미지를 기반으로 하여, 증강현실 환경에서의 증강을 위해서는 깊이의 값을 알아야 한다. 즉 객체 인식 모델은 카메라를 통해 획득한 객체 이미지와 깊이 카메라로부터 획득한 각 객체까지의 깊이 정 보에 전이학습을 수행하여 객체 이미지의 2차원 좌표를 증강 현실의 3차원 좌표로 변환할 수 있다. 예시적으로 기존의 게임 엔진을 통해 2차원 화면에서 목표(Target)가 된 좌표가 인식된 3차원 공간에 증강될 수 있다. 본 발명의 프로그램은 적중(Hit) 테스팅이라고도 할 수 있는 3차원 렌더링 프로그램을 이용하여 레이(원점 및 방향으로 정의, Ray)가 추적을 하는 대상과 교차하는 위치를 결정할 수 있다. 여기서 물체의 2차원 이미지에서 의 X, Y값을 알 수 있으므로, 3차원 증강현실에서 구현이 이미 되어 있는 추적이 가능한 객체와의 교차점을 구 한다면, 깊이의 값(Z)을 정확히 타게팅 할 수 있다. 예를 들어 추적 가능한 대상(Trackable Type)은 평면(Plane), 특징이 되는 점(Point Cloud), 얼굴(AR Face) 등 이 있다. 이 중 편의를 위해 추적이 가능한 모든 대상(All Trackable Types)이 겹쳤을 경우 지정된 x, y 좌표값 과 교차하는 지점에 적중할 수 있도록 하였다. 예를 들어 주로 추적이 되는 대상은 평면, 그 중에서도 물체를 자연스럽게 올려놓을 수 있는 바닥, 책상 위 등의 수평 평면(Horizontal Plane)이 포함된다. 도 13은 게임 엔진을 통해 추적된 평면을 도시한 것이다. 평면이 잘 인식되었는지 확인을 하기 위해 평면 시각 화를 나타냈으며, 이를 통해 확인된 평면은 도13의 오른쪽과 같이 나타난다. 이는 타게팅 된 플랫폼에 따라 평면의 추적이 이루어지며, LiDAR Scanner가 탑재된 사용자 단말 의 경우 별도 계산 없이도 곧바로 깊이에 대한 인식이 가능하기 때문에 매우 빠르게 평면의 인식이 가능하다. 이 평면들은 이 제 모두 증강현실 상의 추적이 가능한 대상(Trackable Type)이 되었으며, 화면 상의 X, Y 좌표를 지정할 경우 겹치고 있는 3차원 대상(평면)에 직접 증강이 가능한 것이다. 도 14a는 3차원 렌더링 프로그램의 클래스를 사용에 따른 메소드를 도시한 것이고, 도 14b는 전이 학습의 2차원 좌표값을 통한 증강현실 상의 3차원 좌표로의 전환을 도시한 것이다. 본 발명의 일 실시예에 따른 메소드는 단일 Raycast(Single Raycast)이며, 이는 도 14a와 같이 나타난다. 도 14a에 도시된 것처럼 Vector2 형식의 screenPoint는 화면 상의 지정된 x, y의 값, hitResults는 추적 가능 한 대상(평면)과 지정된 좌표가 겹쳤는지에 대한 여부, TrackableType는 추적 가능한 대상의 범위 선정이다. 전 이 학습이 완료된 물체 인식은 X 좌표값 / Y 좌표값 / Label명 세 가지의 값을 반환한다. 이 중 X 좌표값과 Y 좌표값을 Raycast를 이용한다면 깊이를 포함하고 있는 증강현실 상의 좌표로의 이동(도 14b에 도시)이가능하다. 이를 통해 프로그램은 해당 물체가 어떠한 물체인지를 인지할 수 있으며, 증강현실에서의 정확한 좌표값을 알고 있기 때문에 특수 효과 제어부를 통해 특수효과의 오브젝트와의 관계 작용이 가능하다. 도 15a 내지 도 15d는 게임 엔진을 이용한 특수효과의 조절과정을 도시한 것이다. 도시된 바와 같이 본 발명의 일 실시예에 따른 특수 효과 제어부는 게임 엔진을 이용하여 특수효과 제어 정보를 설정할 수 있다. 예시적으로 게임 엔진은 사실적으로 구현되어있는 다양한 특수효과를 포함한다. 예를 들어 특수효과의 오브젝트 는 움직이는 액체, 연기, 구름, 화염과 같은 다양한 효과가 있으며, 게임 엔진은 이러한 특수효과를 시뮬레이션 할 수 있는 기능을 제공한다. 즉 본 발명의 특수 효과 제어부는 기존 게임 엔진을 통하여 인지된 물체와 상황에 따른 다른 특수효과를 표현할 수 있다. 도 15a에 도시된 것처럼 특수 효과 제어부는 게임 엔진을 이용하여 간단하게 특수효과의 물리적 특성(크기, 속도와 같은 물성치)에 대한 기본적인 조절과 시각적 효과를 구현할 수 있다. 일 예로 특수효과 제 어부는 증강현실의 특수효과 구현을 위해, 불의 세기를 임의로 조절할 수 있다. 또한 특수 효과 제어부는재질(Material)과 같이 특수 효과의 오브젝트에 적용할 수 있는 효과 외에도 특수 효과의 속성(Property), 모듈(Module)에 포함된 다양한 값을 조절할 수 있다. 공통적으로 조절할 수 있는 대표 적인 속성 값들은 도 15b에 도시된 것과 같고, 모듈 값들은 도 15c에 도시된 것과 같다. 또한 특수효과를 증강현실에서 구현하려면 증강현실에서의 정보를 불러와, 해당 특수효과를 적절한 위치에 놓아 야 한다. 위치를 생각하지 않고 구현한다면, 현실과 다른 모습이 되어 사실적인 표현이 불가능하기 때문이다. 이를 위해 인식되어 있는 수평 평면(Horizontal Plane)위에 특수효과를 생성(Instantiate)할 수 있다. 이를 고려하여 특수 효과 제어부는 특수효과의 오브젝트들을 평면의 바닥을 인식할 수 있는 수평 평면에 생성하여, 중력에 영향으로 바닥에 있는 것과 같이 나타낼 수 있다. 도 15d는 AR의 수평 평면(Horizontal Plane) 위에서의 특수효과 생성을 도시한 것이다. 도시된 바와 같이 불 특 수효과를 수평 평면에서 생성되도록 하여 빌드를 하면 인식된 물체 위치에서 불이 일어난 듯한 사실적인 효과 표현을 얻을 수 있다 즉 프로그램이 인식된 물체의 위치를 파악하면, 특수 효과 제어부를 통해 증강현실 내에서 해당 물체가 특 수효과의 오브젝트와 상호작용을 할 수 있다. 도시된 것처럼 물체가 인식되었을 때 평면 위에 생성되는 불 특수 효과를 해당 좌표 위에 놓아, 물체가 타는 듯한 연출이 가능하다. 이와 같은 지능형 특수효과를 구현하기 위해, 본 발명은 물체에 따른 각기 다른 특수효과 구현이 가능하도록 전 이학습의 세 가지 반환값 중 하나인 레이블(Label)을 이용할 수 있다. Label은 해당 물체의 인식된 이름이며, 이를 통해 물체가 어떠한 종류인지 분류할 수 있으므로 각기 다른 특수효과의 구현이 가능하다. 예시로, 후술하 는 도 16에 도시된 것처럼 종이 컵과 병을 적용시킬 수 있다. 도 16은 물체의 인식된 레이블에 따른 각기 다른 특수효과를 물체의 좌표 위에 증강하도록 하는 해당 코드의 일 예를 도시한 것이고, 도 17은 물체의 속성에 따라 다른 크기를 가진 특수효과가 표시되는 일 예를 도시한 것이다. 도 16에 도시된 것처럼 해당 코드는 물체의 인식된 레이블에 따른 각기 다른 특수효과를 물체의 좌표 위에 증강 시키도록 한다. outline.Label는 반환된 전이 학습이 완료된 물체의 레이블이다. 의 자유로운 크기 적용을 통해 컵에서의 불길은 작게, 병에서의 크기는 크게 표현하도록 설정하였다. 이와 같이 설정된 특수효과 제어 정보가 실행된 결과는 도 17에 도시된 것과 같다. 예를 들어, 도 17(a)는 객체의 종류가 컵으로 인식되었을 때 증강된 작은 불길을 나타낸 것이고, 도 17(b)는 객 체의 종류가 병으로 인식하였을 때 증강된 큰 불길을 나타낸 것이고, 도 17(c)는 객체의 종류 및 위치를 인식함 에 따라 불 특수효과의 크기가 컵과 병의 위치에 따라 다르게 나타난 것이다. 이와 같이, 프로그램은 인지된 물체의 증강된 3차원 위치와 레이블값을 파악하면 증강현실에서의 다양한 상호작 용이 가능하다. 또한, 객체 크기 산출부를 통해 바운딩 박스의 크기를 이용하여 물체(객체)의 실제 크기도 대략적으로 산출할 수 있다. 무게 추정 모델을 통해 물체의 실제 크기를 이용하여 물체의 무게를 산출할수 있다. 물체의 크기와 무게에 기초하여 특수 효과 제어부를 통해 증강된 특수 효과를 3차원 공간 내 인 식된 물체에 사실적으로 표현할 수 있다. 추가 실시예로, 본 발명은 상술한 데이터와 증강현실 기술이 어떻게 결합할 수 있는지의 예제를 제작된 소방 로 봇을 통해 제안한다. 도 18은 게임 엔진을 활용한 소방 로봇의 예시도이고, 도 19는 물 분출구 특수효과 귀속을 통한 소방 로봇의 구현 예시를 도시한 것이다. 본 발명은 물체의 인식을 통한 레이블의 이름과 3차원 좌표값을 통해서 증강현실에서 제공하는 다양한 기능의 응용이 가능하다. 예시적으로, 게임 엔진에서 가상 객체로 제공되는 로봇(도 18에 도시)을 활용하여 증강된 불 특수효과를 소화할 수 있는 소방 로봇을 제공할 수 있다. 소방 로봇 객체를 활용하여 추적이 가능한 평면 위를 이동하도록 적용할 수 있다. 터치 인터페이스를 이용하여 터치된 좌표를 Raycast하여 소방 로봇이 수평 표면 위 를 실시간으로 움직이도록 하여, 사용자와 소방 로봇이 적용된 증강현실 간의 상호작용이 가능하다. 또한 게임 엔진의 기능을 통해 증강현실 내에서 소방 로봇이 여기저기 이동하며 불을 끌 수 있도록 할 수 있다. 예를 들어 불을 끄러 다니는 소방관과 같은 연출을 위해, 해당 로봇의 물 분출구를 설정한 앞부분에서 물줄기가 나오는 특수효과를 표현하였다. 해당 물 특수효과 역시 게임 엔진을 통해 직관적으로 물줄기 폭과 세기를 임의 로 조절할 수 있다. 예를 들어 소방 로봇이 불길을 만났을 경우 해당 불길을 소화하는 것을 표현할 수 있다. 소방 로봇과 증강된 특 수효과와의 만남, 즉 게엠 엔진의 충돌(Collision)을 감지하는 기능을 통해 소방 로봇과 불길의 충돌 인식이 가 능하다. 즉, 소방 로봇의 본체가 불길과 부딪혔을 때 불길이 소멸(Destroy)되도록 설정할 수 있다. 이를 통해 전이 학습으로 인식된 물체가 증강현실 고유의 기능과 상호 작용이 가능하다. 도 20 및 도 21은 본 발명의 일 실시예에 따른 객체 인식 기반 지능형 특수효과 생성 장치의 지능형 특수효과의 일 예를 도시한 것이다. 도시된 것처럼 증강현실에서의 상호작용을 통해 개발자는 다양한 시나리오의 적용이 가능하다. 도 20(a)를 참조 하면 종이컵에 무심코 버린 담배꽁초에서 불길이 시작될 수 있다. 인식된 종이컵은 타는 물질이므로, 종이컵인 것이 인식된 순간 해당 좌표 위에 작은 불 특수효과를 생성할 수 있다. 도 20(b) 및 도 20(c)를 참조하면 종이 컵의 바로 옆에는 마찬가지로 타는 물질인 종이 박스가 있어, 불이 박스 위로 옮겨 붙는다. 바운딩 박스의 크기 를 통한 박스의 대략적인 크기를 산출할 수 있으며, 박스의 크기에 따라 더욱 크거나 작은 불이 옮겨붙도록 나 타낼 수 있다. 도 20(d)를 참조하면 종이컵의 바로 옆에 있는 플라스틱 병은 불길에 휩싸이지는 않으나, 유독해 보이는 검은 연기를 뿜으며 천천히 녹아내리는 모습이 나타날 수 있다. 도 21(a)를 참조하면 증강된 세 가지의 불 특수효과는 다른 크기, 강도, 및 모양으로 각각 다른 위치에 증강되는 것을 확인할 수 있다. 도 21(b)를 참 조하면 상황을 해결하기 위해 증강현실 내를 터치 기반으로 돌아다닐 수 있는 소방 로봇을 증강현실 세계에 불 러온다. 소방 로봇은 불 특수효과와 충돌(Collide)하였을 때 불을 끌 수 있으며, 불길이 소멸된 상태가 나타날 수 있다. 이상에서 설명한 방법은 컴퓨터에 의해 실행되는 프로그램 모듈과 같은 컴퓨터에 의해 실행가능한 명령어를 포 함하는 기록 매체의 형태로도 구현될 수 있다. 컴퓨터 판독 가능 매체는 컴퓨터에 의해 액세스될 수 있는 임의 의 가용 매체일 수 있고, 휘발성 및 비휘발성 매체, 분리형 및 비분리형 매체를 모두 포함한다. 또한, 컴퓨터 판독가능 매체는 컴퓨터 저장 매체를 포함할 수 있다. 컴퓨터 저장 매체는 컴퓨터 판독가능 명령어, 데이터 구 조, 프로그램 모듈 또는 기타 데이터와 같은 정보의 저장을 위한 임의의 방법 또는 기술로 구현된 휘발성 및 비 휘발성, 분리형 및 비분리형 매체를 모두 포함한다."}
{"patent_id": "10-2022-0165636", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "본 발명이 속하는 기술분야의 통상의 지식을 가진 자는 상술한 설명을 기초로 본 발명의 기술적 사상이나 필수 적인 특징을 변경하지 않고서 다른 구체적인 형태로 쉽게 변형이 가능하다는 것을 이해할 수 있을 것이다. 그러 므로 이상에서 기술한 실시예들은 모든 면에서 예시적인 것이며 한정적이 아닌 것으로 이해되어야만 한다. 본 발명의 범위는 후술하는 특허청구범위에 의하여 나타내어지며, 특허청구범위의 의미 및 범위 그리고 그 균등 개 념으로부터 도출되는 모든 변경 또는 변형된 형태가 본 발명의 범위에 포함되는 것으로 해석되어야 한다."}
{"patent_id": "10-2022-0165636", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일 실시예에 따른 객체 인식 기반 지능형 특수효과 생성 장치의 구성을 보여주는 도면이다. 도 2는 본 발명의 일 실시예에 따른 객체 인식 기반 지능형 특수효과 생성 장치의 세부 모듈을 설명하기 위한 블록도이다. 도 3은 본 발명의 일 실시예에 따른 객체 인식 기반 지능형 특수효과 생성 장치를 설명하기 위한 도면이다. 도 4는 본 발명의 일 실시예에 따른 객체 크기 산출부를 설명하기 위한 도면이다. 도 5 및 도 6은 본 발명의 일 실시예에 따른 사용자 인터페이스의 일 예를 도시한 도면이다. 도 7은 본 발명의 다른 실시예에 따른 객체 인식 기반 지능형 특수효과 생성 방법을 설명하기 위한 순서도이다. 도 8 및 도 9는 본 발명의 일 실시예에 따른 객체 인식 모델의 학습 과정을 설명하기 위한 도면이다. 도 10은 기존의 게임 엔진을 통한 증강현실에서의 적용을 도시한 것이다. 도 11 및 도 12는 본 발명의 객체 인식 모델의 물체 인식에 대한 정확도 측정 결과를 도시한 것이다. 도 13은 게임 엔진을 통해 추적된 평면을 도시한 것이다. 도 14a는 Raycast Manager 클래스를 사용에 따른 메소드를 도시한 것이다. 도 14b는 전이 학습의 2차원 좌표값을 통한 증강현실 상의 3차원 좌표로의 전환을 도시한 것이다. 도 15a 내지 도 15d는 Unity의 Particle System을 이용한 특수효과의 조절과정을 도시한 것이다. 도 16은 물체의 인식된 레이블에 따른 각기 다른 특수효과를 물체의 좌표 위에 증강하도록 하는 해당 코드의 일 예를 도시한 것이다. 도 17은 물체의 속성에 따라 다른 크기를 가진 특수효과가 표시되는 일 예를 도시한 것이다. 도 18은 Unit-E를 활용한 소방 로봇의 예시도이다. 도 19는 Unit-E의 물 분출구 특수효과 귀속을 통한 소방 로봇의 구현 예시를 도시한 것이다. 도 20 및 도 21은 본 발명의 일 실시예에 따른 객체 인식 기반 지능형 특수효과 생성 장치의 지능형 특수효과의 일 예를 도시한 것이다."}
