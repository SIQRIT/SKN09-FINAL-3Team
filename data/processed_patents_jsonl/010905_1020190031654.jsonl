{"patent_id": "10-2019-0031654", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2020-0111948", "출원번호": "10-2019-0031654", "발명의 명칭": "인공 신경망을 처리하는 방법 및 이를 위한 전자 장치", "출원인": "삼성전자주식회사", "발명자": "이정훈"}}
{"patent_id": "10-2019-0031654", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "전자 장치가 인공 신경망을 처리하는 방법에 있어서,제1 프로세서 및 제2 프로세서를 이용하여 상기 인공 신경망을 구성하는 일 신경망 레이어의 연산을 수행하기위한, 신경망 연산 계획을 획득하는 동작;상기 획득된 신경망 연산 계획에 따라, 상기 제1 프로세서를 이용하여 상기 일 신경망 레이어의 일부 연산을 수행하고, 상기 제2 프로세서를 이용하여 상기 일 신경망 레이어의 다른 일부 연산을 수행하는 동작;상기 제1 프로세서의 수행 결과에 따른 제1 출력 값 및 상기 제2 프로세서의 수행 결과에 따른 제2 출력 값을획득하는 동작; 및상기 획득된 제1 출력 값 및 상기 제2 출력 값을 상기 인공 신경망을 구성하는 다른 일 신경망 레이어의 입력값으로써 이용하는 동작을 포함하는,인공 신경망 처리 방법."}
{"patent_id": "10-2019-0031654", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서상기 신경망 연산 계획은,상기 제1 프로세서 및 상기 제2 프로세서 간의 연산 비율, 또는 상기 제1 프로세서 및 상기 제2 프로세서 각각의 연산량 중 적어도 하나를 포함하는,인공 신경망 처리 방법."}
{"patent_id": "10-2019-0031654", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 제1 프로세서 및 상기 제2 프로세서 각각에서 이용되는 데이터 타입을 획득하는 동작을 더 포함하고,상기 일 신경망 레이어의 연산을 수행하는 동작은,상기 획득된 신경망 연산 계획 및 상기 데이터 타입에 따라, 상기 제1 프로세서를 이용하여 상기 일 신경망 레이어의 일부 연산을 수행하고, 상기 제2 프로세서를 이용하여 상기 일 신경망 레이어의 다른 일부 연산을 수행하는 동작을 포함하는,인공 신경망 처리 방법."}
{"patent_id": "10-2019-0031654", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,상기 신경망 연산 계획을 획득하는 동작은,상기 제1 프로세서 및 상기 제2 프로세서 각각의 상기 일 신경망 레이어의 처리 시간 또는 상기 제1 프로세서및 상기 제2 프로세서 각각의 가용 자원 중 적어도 하나에 기반하여, 상기 신경망 연산 계획을 획득하는 동작을포함하는,공개특허 10-2020-0111948-3-인공 신경망 처리 방법."}
{"patent_id": "10-2019-0031654", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서,상기 신경망 연산 계획을 획득하는 동작은,상기 인공 신경망의 구조로서, 상기 인공 신경망의 입력 값의 크기, 필터의 크기, 필터의 개수 또는 출력 값의크기 중 적어도 하나에 기반하여, 상기 신경망 연산 계획을 획득하는 동작을 포함하는,인공 신경망 처리 방법."}
{"patent_id": "10-2019-0031654", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서,상기 일 신경망 레이어의 연산을 수행하는 동작은,제1 입력 채널을 대상으로 상기 제1 프로세서를 이용하여 상기 일 신경망 레이어의 일부 연산을 수행하고, 상기제1 입력 채널과 다른 제2 입력 채널을 대상으로 상기 제2 프로세서를 이용하여 상기 일 신경망 레이어의 다른일부 연산을 수행하는 동작을 포함하는,인공 신경망 처리 방법."}
{"patent_id": "10-2019-0031654", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6항에 있어서,상기 일 신경망 레이어는,컨벌루션 레이어, 완전 연결 레이어, LSTM 레이어 또는 GRU 레이어인,인공 신경망 처리 방법."}
{"patent_id": "10-2019-0031654", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1항에 있어서,상기 일 신경망 레이어의 연산을 수행하는 동작은,제1 출력 채널을 대상으로 상기 제1 프로세서를 이용하여 상기 일 신경망 레이어의 일부 연산을 수행하고, 상기제1 출력 채널과 다른 제2 출력 채널을 대상으로 상기 제2 프로세서를 이용하여 상기 일 신경망 레이어의 다른일부 연산을 수행하는 동작을 포함하는,인공 신경망 처리 방법."}
{"patent_id": "10-2019-0031654", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서,상기 일 신경망 레이어는,풀링 레이어인,공개특허 10-2020-0111948-4-인공 신경망 처리 방법."}
{"patent_id": "10-2019-0031654", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제1항에 있어서,상기 신경망 연산 계획을 획득하는 동작은,상기 제1 프로세서 및 상기 제2 프로세서를 이용하여 상기 인공 신경망을 구성하는 복수 개의 신경망 레이어들각각의 연산을 수행하기 위한, 신경망 연산 계획을 획득하는 동작을 포함하는,인공 신경망 처리 방법."}
{"patent_id": "10-2019-0031654", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "인공 신경망을 처리하는 전자 장치에 있어서,적어도 하나의 인스트럭션들을 저장하는 메모리;상기 메모리와 동작 가능하게 연결된, 제1 프로세서 및 제2 프로세서를 포함하는 복수 개의 프로세서들을 포함하고,상기 복수 개의 프로세서들 중 적어도 하나는, 인공 신경망에 포함된 일 신경망 레이어의 연산을 수행하기 위한신경망 연산 계획을 획득하고,상기 획득된 신경망 연산 계획에 따라, 상기 제1 프로세서는 상기 일 신경망 레이어의 일부 연산을 수행하고,상기 제2 프로세서는 상기 일 신경망 레이어의 다른 일부 연산을 수행하고,상기 복수 개의 프로세서들 중 적어도 하나는, 상기 제1 프로세서의 수행 결과에 따른 획득된 제1 출력 값 및상기 제2 프로세서의 수행 결과에 따른 획득된 제2 출력 값을 상기 인공 신경망을 구성하는 다른 일 신경망 레이어의 입력 값으로써 이용하는,전자 장치."}
{"patent_id": "10-2019-0031654", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항에 있어서상기 신경망 연산 계획은,상기 제1 프로세서 및 상기 제2 프로세서 간의 연산 비율, 또는 상기 제1 프로세서 및 상기 제2 프로세서 각각의 연산량 중 적어도 하나를 포함하는,전자 장치."}
{"patent_id": "10-2019-0031654", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제11항에 있어서,상기 복수 개의 프로세서들 중 적어도 하나는, 상기 제1 프로세서 및 상기 제2 프로세서 각각에서 이용되는 데이터 타입을 획득하고,상기 획득된 신경망 연산 계획 및 상기 데이터 타입에 따라, 상기 제1 프로세서는 상기 일 신경망 레이어의 일부 연산을 수행하고, 상기 제2 프로세서는 상기 일 신경망 레이어의 다른 일부 연산을 수행하는,공개특허 10-2020-0111948-5-전자 장치."}
{"patent_id": "10-2019-0031654", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제11항에 있어서,상기 복수 개의 프로세서들 중 적어도 하나는, 상기 제1 프로세서 및 상기 제2 프로세서 각각의 상기 일 신경망레이어의 실행 시간 또는 상기 제1 프로세서 및 상기 제2 프로세서 각각의 가용 자원 중 적어도 하나에 기반하여, 상기 신경망 연산 계획을 획득하는,전자 장치."}
{"patent_id": "10-2019-0031654", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제11항에 있어서,상기 복수 개의 프로세서들 중 적어도 하나는, 상기 인공 신경망의 구조로서, 상기 인공 신경망의 입력 값의 크기, 필터의 크기, 필터의 개수 또는 출력 값의 크기 중 적어도 하나에 기반하여, 상기 신경망 연산 계획을 획득하는,전자 장치."}
{"patent_id": "10-2019-0031654", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제11항에 있어서,상기 제1 프로세서는 제1 입력 채널을 대상으로 상기 일 신경망 레이어의 일부 연산을 수행하고, 상기 제2 프로세서는 상기 제1 입력 채널과 다른 제2 입력 채널을 대상으로 상기 일 신경망 레이어의 다른 일부 연산을 수행하는,전자 장치."}
{"patent_id": "10-2019-0031654", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제16항에 있어서,상기 일 신경망 레이어는,컨벌루션 레이어, 완전 연결 레이어, LSTM 레이어 또는 GRU 레이어인,전자 장치."}
{"patent_id": "10-2019-0031654", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제11항에 있어서,상기 제1 프로세서는 제1 출력 채널을 대상으로 상기 일 신경망 레이어의 일부 연산을 수행하고, 상기 제2 프로세서는 상기 제1 출력 채널과 다른 제2 출력 채널을 대상으로 상기 일 신경망 레이어의 다른 일부 연산을 수행하는,전자 장치."}
{"patent_id": "10-2019-0031654", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "공개특허 10-2020-0111948-6-제18항에 있어서,상기 일 신경망 레이어는,풀링 레이어인,전자 장치."}
{"patent_id": "10-2019-0031654", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제11항에 있어서,상기 인공 신경망은,컨벌루션 신경망(convolution neural network)인, 전자 장치."}
{"patent_id": "10-2019-0031654", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 개시에 따른 전자 장치가 인공 신경망을 처리하는 방법은, 제1 프로세서 및 제2 프로세서를 이용하여 상기 인 공 신경망을 구성하는 일 신경망 레이어의 연산을 수행하기 위한, 신경망 연산 계획을 획득하는 동작, 상기 획득 된 신경망 연산 계획에 따라, 상기 제1 프로세서를 이용하여 상기 일 신경망 레이어의 일부 연산을 수행하고, 상 기 제2 프로세서를 이용하여 상기 일 신경망 레이어의 다른 일부 연산을 수행하는 동작, 상기 제1 프로세서의 수 행 결과에 따른 제1 출력 값 및 상기 제2 프로세서의 수행 결과에 따른 제2 출력 값을 획득하는 동작, 및 상기 획득된 제1 출력 값 및 상기 제2 출력 값을 상기 인공 신경망을 구성하는 다른 일 신경망 레이어의 입력 값으로 서 이용하는 동작을 포함한다."}
{"patent_id": "10-2019-0031654", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 인공 신경망을 처리하는 방법 및 이를 위한 전자 장치에 관한 것으로, 특히, 인공 신경망의 연산을 수행하는 기술과 관련된다."}
{"patent_id": "10-2019-0031654", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "인공 신경망(artificial neural network)은 동물 신경계의 뉴런 구조를 수학적 표현에 기초하여 획득한 통계학 적 학습 알고리즘으로서, 구체적인 태스크 절차 및 규칙 없이, 학습을 통하여 문제 해결 능력을 가지는 모델 전 반을 가리킬 수 있다. 인공 신경망은 인공 지능 분야의 핵심이 되는 알고리즘으로서, 음성 인식, 언어 인식, 필기 인식, 영상 인식, 컨텍스트 추론 등 다양한 분야에서 활용될 수 있다. 최근에는, 컨벌루션 신경망(CNN; convolutional neural network) 기반의 딥러닝 알고리즘이 컴퓨터 비전과 음성 인식 등의 분야에서 탁월한 성능을 보이고 있다. 컨벌루션 신경망은 전-역방향 인공 신경망의 일종으로, 추상화 된 정보를 추출하는 다양한 영상 처리에서 활발하게 연구되고 있다. 예로, 전자 장치는 컨벌루션 신경망에 기초 하여 입력 영상을 작은 구역으로 나누어 특징을 인식하고 신경망 단계가 진행되면서 나누어진 영상을 결합해 전 체를 인식할 수 있다. 한편, 이러한 인공 신경망을 효율적인 활용하기 위하여는, 인공 신경망을 운영하는 신경망 프레임워크의 성능 향상이 요구될 수 있다. 신경망 프레임워크는 인공 신경망을 처리할 자원의 운영 및 인공 신경망의 처리 방법 등을 관장할 수 있다."}
{"patent_id": "10-2019-0031654", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "인공 신경망은 사용자 경험을 더욱 풍부하게 하고, 사용자에게 맞춤화된 서비스를 제공하기 위하여 모바일 장치 에서 이용될 수도 있다. 모바일 장치에서 인공 신경망을 이용하는 경우, 외부의 클라우드 자원에 상당 부분 의존할 수 있다. 클라우드 자원을 이용하는 경우, 모바일 장치는 네트워크 상태에 따라 데이터 추론이 지연되거나, 인터넷과 연결이 끊어 졌을 때는 데이터 추론을 할 수 없다는 문제점이 있다. 또한, 개인 데이터가 클라우드에 제공됨에 따라 사용자보안에 취약한 문제가 발생될 수 있다. 또한, 클라우드 자원의 사용자가 증가할수록, 클라우드 자원을 이용한 데이터 추론에 병목 현상이 발생할 수 있다. 최근에는, 기술의 발전에 따라 모바일 장치의 프로세서(예: Sytem-on-a Chips; SoCs)의 성능이 더욱 향상되고 있다. 이는 모바일 장치의 하드웨어 자원을 이용하여 인공 신경망을 이용한 데이터 추론을 가능하게 할 수 있다. 이에, 모바일 장치의 하드웨어 자원을 효율적으로 이용하기 위한 신경망 프레임워크의 운영이 필요하다. 즉, 인공 신경망의 추론 레이턴시(inference latency)가 최소화될 필요성이 요구된다."}
{"patent_id": "10-2019-0031654", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상술한 바와 같은 목적을 달성하기 위한 본 개시의 실시 예에 따른 전자 장치가 인공 신경망을 처리하는 방법은, 제1 프로세서 및 제2 프로세서를 이용하여 상기 인공 신경망을 구성하는 일 신경망 레이어의 연산을 수 행하기 위한, 신경망 연산 계획을 획득하는 동작, 상기 획득된 신경망 연산 계획에 따라, 상기 제1 프로세서를 이용하여 상기 일 신경망 레이어의 일부 연산을 수행하고, 상기 제2 프로세서를 이용하여 상기 일 신경망 레이 어의 다른 일부 연산을 수행하는 동작, 상기 제1 프로세서의 수행 결과에 따른 제1 출력 값 및 상기 제2 프로세 서의 수행 결과에 따른 제2 출력 값을 획득하는 동작, 및 상기 획득된 제1 출력 값 및 상기 제2 출력 값을 상기 인공 신경망을 구성하는 다른 일 신경망 레이어의 입력 값으로써 이용하는 동작을 포함한다. 상술한 바와 같은 목적을 달성하기 위한 본 개시의 실시 예에 따른 인공 신경망을 처리하는 전자 장치는, 적어 도 하나의 인스트럭션들을 저장하는 메모리, 상기 메모리와 동작 가능하게 연결된, 제1 프로세서 및 제2 프로세 서를 포함하는 복수 개의 프로세서들을 포함하고, 상기 복수 개의 프로세서들 중 적어도 하나는, 인공 신경망에 포함된 일 신경망 레이어의 연산을 수행하기 위한 신경망 연산 계획을 획득하고, 상기 획득된 신경망 연산 계획 에 따라, 상기 제1 프로세서는 상기 일 신경망 레이어의 일부 연산을 수행하고, 상기 제2 프로세서는 상기 일 신경망 레이어의 다른 일부 연산을 수행하고, 상기 복수 개의 프로세서들 중 적어도 하나는, 상기 제1 프로세서 의 수행 결과에 따른 획득된 제1 출력 값 및 상기 제2 프로세서의 수행 결과에 따른 획득된 제2 출력 값을 상기 인공 신경망을 구성하는 다른 일 신경망 레이어의 입력 값으로써 이용한다.."}
{"patent_id": "10-2019-0031654", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "이상에서 살펴본 바와 같이 본 개시의 실시 예에 따르면, 복수 개의 프로세서를 효율적으로 활용함에 따라, 인 공 신경망의 처리 속도가 크게 향상될 수 있으며, 자원 소모가 최소화되어 에너지 효율성이 향상될 수 있다. 이에 따라, 인공 신경망의 신속한 추론 및 피드백이 가능하게 되어, 본 개시의 실시예들이 적용된 전자 장치를 이용하는 사용자 만족도가 증가하고, 인공 지능을 활용하는 다양한 서비스의 발전이 가능하게 된다. 이 외에, 본 개시를 통해 직접적 또는 간접적으로 파악되는 다양한 효과들이 제공될 수 있다."}
{"patent_id": "10-2019-0031654", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 본 개시의 다양한 실시 예가 첨부된 도면을 참조하여 기재된다. 본 개시의 다양한 실시예들 및 이에 사용 된 용어들은 본 문서에 기재된 기술적 특징들을 특정한 실시예들로 한정하려는 것이 아니며, 해당 실시예의 다 양한 변경, 균등물, 또는 대체물을 포함하는 것으로 이해되어야 한다. 도면의 설명과 관련하여, 유사한 또는 관 련된 구성요소에 대해서는 유사한 참조 부호가 사용될 수 있다. 아이템에 대응하는 명사의 단수 형은 관련된 문 맥상 명백하게 다르게 지시하지 않는 한, 상기 아이템 한 개 또는 복수 개를 포함할 수 있다. 본 문서에서, \"A 또는 B\", \"A 및 B 중 적어도 하나\",“A 또는 B 중 적어도 하나,”\"A, B 또는 C,\" \"A, B 및 C 중 적어도 하나, ”및 “A, B, 또는 C 중 적어도 하나\"와 같은 문구들 각각은 그 문구들 중 해당하는 문구에 함께 나열된 항목들 중 어느 하나, 또는 그들의 모든 가능한 조합을 포함할 수 있다. \"제 1\", \"제 2\", 또는 \"첫째\" 또는 \"둘째\"와 같은 용어들은 단순히 해당 구성요소를 다른 해당 구성요소와 구분하기 위해 사용될 수 있으며, 해당 구성요소 들을 다른 측면(예: 중요성 또는 순서)에서 한정하지 않는다. 어떤(예: 제 1) 구성요소가 다른(예: 제 2) 구성 요소에, “기능적으로” 또는 “통신적으로”라는 용어와 함께 또는 이런 용어 없이, “커플드” 또는 “커넥티 드”라고 언급된 경우, 그것은 상기 어떤 구성요소가 상기 다른 구성요소에 직접적으로(예: 유선으로), 무선으 로, 또는 제 3 구성요소를 통하여 연결될 수 있다는 것을 의미한다. 본 개시에서, 사용자라는 용어는 전자 장치를 사용하는 사람 또는 전자 장치를 사용하는 장치(예: 인공지능 전 자 장치)를 지칭할 수 있다. 도 1은 본 개시의 일 실시 예에 따른 전자 장치의 구성을 나타내는 블록도이다. 도 1을 참조하면, 본 개시의 실시예에서의 전자 장치는 복수 개의 프로세서들 및 메모리를 포함 할 수 있다. 도 1에 도시된 전자 장치의 구성은 예시적인 것이며, 본 문서에 개시되는 다양한 실시 예를 구현할 수 있는 다양한 변형이 가능하다. 예를 들어, 전자 장치는 도 2에 도시된 전자 장치와 같은 구성을 포함하거나, 이 구성들을 활용하여 적절하게 변형될 수 있다. 이하에서는 전자 장치를 기준으로 본 개시의 다양한 실시 예들이 설명된다. 전자 장치는 인공 지능 서비스를 제공 또는 지원하는 장치일 수 있다. 전자 장치는, 예로, 전자 장치 는, 예를 들면, 휴대용 통신 장치 (예: 스마트폰), 컴퓨터 장치, 휴대용 멀티미디어 장치, 의료 기기, 카메라, 웨어러블 장치, 디지털 TV, 또는 가전 장치를 포함할 수 있으나, 전술한 기기들에 한정되지 않는다. 복수 개의 프로세서들은 전자 장치의 적어도 하나의 다른 구성요소들의 제어 및/또는 통신에 관한 연 산이나 데이터 처리를 실행할 수 있다. 복수 개의 프로세서들은 메모리에 저장된 인공 신경망(또는, 인공 신경망 모델)을 이용하여 입력 값에 대한 신경망 학습 결과를 획득할 수 있다. 또는, 복수 개의 프로 세서들은 메모리에 저장된 인공 신경망을 이용하여 입력 값에 대한 신경망 처리를 수행하고 출력 값 을 획득할 수 있다. 복수 개의 프로세서들은 중앙 처리 장치(CPU; central processing unit)(예: big CPU, LITTLE CPU), 그래 픽처리장치(GPU; graphic processing unit), 어플리케이션 프로세서(AP; application processor), DSPs(Domain-Specific Processors), 커뮤니케이션 프로세서(CP; communication processor) 또는 신경망 처리 장치(Neural Processing Unit) 중 둘 이상의 조합일 수 있다. 이 경우, 동일한 종류의 프로세서가 둘 이상 이용 될 수도 있다. 일 실시예에 따르면, 복수 개의 프로세서들 중 적어도 하나는 인공 신경망(예: 컨벌루션 신경망 (convolution neural network))에 포함된 일 신경망 레이어의 연산을 수행하기 위한 신경망 연산 계획을 획득할 수 있다. 획득된 신경망 연산 계획에 따라, 제1 프로세서는 일 신경망 레이어의 일부 연산을 수행하고, 제 2 프로세서는 일 신경망 레이어의 다른 일부 연산을 수행할 수 있다. 그리고, 복* 개의 프로세서들 중 적어도 하나는 제1 프로세서의 수행 결과에 따른 획득된 제1 출력 값 및 제2 프로세서의 수행 결 과에 따른 획득된 제2 출력 값을 인공 신경망을 구성하는 다른 일 신경망 레이어의 입력 값으로서 이용할 수 있 다. 이 때, 복수 개의 프로세서들 중 적어도 하나는, 제1 프로세서 또는 제2 프로세서 중 적어도 하나를 포함할 수도 있다. 일 실시예에 따르면, 복수 개의 프로세서들 중 적어도 하나는 제1 프로세서 및 제2 프로세서 각 각에서 이용되는 데이터 타입을 획득할 수 있다. 획득된 신경망 연산 계획 및 데이터 타입에 따라, 제1 프로세 서는 일 신경망 레이어의 일부 연산을 수행하고, 제2 프로세서는 일 신경망 레이어의 다른 일부 연산 을 수행할 수 있다. 일 실시예에 따르면, 복수 개의 프로세서들 중 적어도 하나는 제1 프로세서 및 제2 프로세서 각 각의 일 신경망 레이어의 실행 시간 또는 제1 프로세서 및 제2 프로세서 각각의 가용 자원 중 적어도 하나에 기반하여, 신경망 연산 계획을 획득할 수 있다. 일 실시예에 따르면, 복수 개의 프로세서들 중 적어도 하나는 인공 신경망의 구조로서, 인공 신경망의 입 력 값의 크기, 필터의 크기, 필터의 개수 또는 출력 값의 크기 중 적어도 하나에 기반하여, 신경망 연산 계획을 획득할 수 있다. 일 실시예에 따르면, 제1 프로세서는 제1 입력 채널을 대상으로 일 신경망 레이어의 일부 연산을 수행하고, 제2 프로세서는 제1 입력 채널과 다른 제2 입력 채널을 대상으로 일 신경망 레이어의 다른 일부 연산을 수행할 수 있다. 이 때, 일 신경망 레이어는, 컨벌루션 레이어 또는 완전 연결 레이어일 수 있다. 일 실시예에 따르면, 제1 프로세서는 제1 출력 채널을 대상으로 일 신경망 레이어의 일부 연산을 수행하고, 제2 프로세서는 제1 출력 채널과 다른 제2 출력 채널을 대상으로 일 신경망 레이어의 다른 일부 연산을 수행할 수 있다. 이 때, 일 신경망 레이어는, 풀링 레이어일 수 있다. 메모리는 전자 장치가 동작하기 위한 각종 소프트웨어 프로그램(또는, 어플리케이션), 전자 장치 의 동작을 위한 데이터들 및 인스트럭션들(instructions)을 저장할 수 있다. 이러한, 프로그램의 적어도 일부는 무선 또는 유선 통신을 통해 외부 서버로부터 다운로드 될 수 있다. 메모리는 복수 개의 프로세서 들 중 적어도 하나에 의해 액세스되며, 복수 개의 프로세서들 중 적어도 하나는 메모리에 포함 된 소프트웨어 프로그램, 데이터들 및 인스트럭션들의 독취/기록/수정/삭제/갱신 등을 수행할 수 있다. 메모리는 인공 신경망(또는, 인공 신경망 모델)을 저장할 수 있다. 또한, 메모리는 인공 신경망 의 연산 결과 또는 인공 신경망의 테스트 결과인 출력 값을 저장할 수 있다. 본 개시의 인공 신경망은, 복수 개 의 레이어들로 구성되며, 각 레이어에 포함된 인공 뉴런(artificial neurons)들은 가중치(weight)를 가지며 서 로 연결될 수 있다. 각 뉴런들은 입력 값에, 가중치를 곱하고 함수를 적용함으로써 출력 값을 획득하고, 이를 다른 뉴런으로 전송할 수 있다. 인공 신경망은 추론의 정확도를 향상시키기 위하여 가중치를 조절하도록 학습될 수 있다. 예로, 신경망 학습은 방대한 양의 학습 데이터를 이용하여 전체 신경망의 비용 함수(cost function)를 최소화시키는 방향으로 각 뉴 런들의 특성들(예: 가중치, 바이어스 등)을 최적화시키는 과정일 수 있다. 신경망 학습은 피드포워드(feed- forward) 과정과 역전파(backpropagation) 과정을 통하여 수행될 수 있다. 예로, 전자 장치는 피드포워드 과정을 통해 최종 출력 레이어까지의 모든 뉴런들의 입력과 출력을 단계적으로 계산할 수 있다. 또한, 전자 장 치는 역전파 과정을 이용하여 최종 출력 레이어에서의 오차를 단계적으로 계산할 수 있다. 전자 장치(10 0)는 계산된 오차 값들을 이용하여 각 숨은 층의 특성들을 추정할 수 있다. 즉, 신경망 학습은 피드포워드 과정 및 역전파 과정을 이용하여 최적의 파라미터(예: 가중치 또는 바이어스)를 획득하는 과정일 수 있다. 일 실시예에 따르면, 메모리는 복수 개의 프로세서들 별 인공 신경망의 처리 시간, 또는 복수 개의 프로세서 별 인공 신경망을 구성하는 신경망 레이어들 각각에 대한 처리 시간을 포함하는 레이어 분할 데 이터베이스를 포함할 수 있다. 또한, 메모리는 인공 신경망을 처리하기에 적합한 복수 개의 프로세서들 각각의 데이터 타입을 포함할 수 있다. 일 실시예에 따르면, 메모리는 후술할 레이어 분배부(도 4의 410)의 처리 결과를 저장할 수도 있다. 예로, 메모리는 복수 개의 프로세서들 간의 연산 비율, 또는 복수 개의 프로세서들 각각의 연산량 중 적어도 하나를 저장할 수 있다. 도 1의 각 구성 요소인 복수 개의 프로세서들 및 메모리는 버스로 연결될 수 있다. 버스는, 예를 들 면, 구성요소들을 서로 연결하고, 구성요소들 간의 통신(예: 제어 메시지 및/또는 데이터)을 전달하는 회로를 포함할 수 있다. 도 2는 본 개시의 실시예들에 적용될 수 있는 컨벌루션 신경망의 구조를 나타낸다. 본 개시에서는, 인공 신경망 중에서 모바일 서비스에서 광범위하게 이용되는 컨벌루션 신경망을 대상으로 설명 하나, 본 개시의 실시예들이 당업자의 수준에서 컨벌루션 신경망이 아닌 다른 신경망을 대상으로 이용될 수 있 음은 물론이다. 도 2의 (a)의 컨벌루션 신경망은 주어진 입력 값에 대하여 다른 동작을 수행하는 복수 개의 레이어들(layers)로 구성될 수 있다. 이 경우, 중간 출력 값들은 일반적으로 3차원(예: 채널, 높이, 폭)의 뉴런들의 값들이며, 복수 개의 레이어들은 일반적으로 세 개의 타입으로 구분될 수 있다. 예로, 복수 개의 레이어는 컨벌루션 레이어들 (convolution layer, 210,230), 풀링 레이어들(pooling layer, 220,240), 완전 연결 레이어들(Fully-connected layer, 250, 260) 및 소프트맥스 레이어(solftmax laeyer, 270)을 포함할 수 있으나, 구현 방식에 따라 일부 레이어가 추가 또는 생략될 수 있음은 물론이다. 컨벌루션 레이어들(210,230)는 입력 값들에 대하여 컨벌루션 연산을 수행한 결과 값들의 집합일 수 있다. 도 2의 (b)는 컨벌루션 레이어의 연산 예를 나타낸다. 도 2의 (b)에서, 컨벌루션 레이어가 ic 입력 채널들을 수용하는 경우, 필터가 k x k 크기의 각각의 로컬 입력 값들에 적용되어, 필터 및 로컬 입력 값 간의 점곱(dot product)이 계산될 수 있다. 이는, 모든 입력 채널들에 있어서 입력 값의 높이 및 폭을 고려하여 수행될 수 있다. 컨벌루션 레이어는 점곱 결과를 바이어스(bias)하여 누적하고, 누적된 값에 활성화 함수(activation function)(예: Rectified Linear Unit, ReLU)를 적용하여 oc 출력 채널들을 획득할 수 있다. 풀링 레이어들(220,240)은 글로벌 함수(예: max, average)를 로컬 입력 값들에 적용하여 공간적 크기를 줄일 수 있다. 공간적 크기를 줄이기 위한 풀링의 예로, 최대 풀링은 로컬 내의 입력 값들 중에서 최대 값을 뽑아낼 수 있다. 컨벌루션 신경망은 컨벌루션 레이어들(210,230) 및 풀링 레이어들(220,240)을 통하여 입력 데이터를 잘 표현할 수 있는 특징 값(또는, 특징 맵(feature map))들을 추출할 수 있다. 완전 연결 레이어들(250,260)은 이전 레이어와 전체 뉴런들이 연결되는 레이어일 수 있다. 소프트맥스 레이어 는 액티베이션 함수의 일종으로 여러 개의 분류를 가질 수 있는 함수일 수 있다. 컨벌루션 신경망은 완전 연결 레이어(250,260) 및 소프트맥스 레이어를 통하여 추출된 특징 값에 따른 분 류 결과를 산출할 수 있다. 도 3a 및 도 3b는, 인공 신경망의 연산을 수행하는 과정을 나타낸다. 도 3a 및 도 3b에서 각각의 신경망 프레임워크는 제1 프로세서(예: CPU) 및 제2 프로세서(예: GPU) 모두를 이용 하여 입력 값들을 처리함으로써 처리량을 향상시킬 수 있다. 먼저, 도 3a의 (a)의 제1 신경망 프레임워크는 특정 프로세서에서 모든 신경망 레이어들을 실행하도록 제어할 수 있다. 복수 개의 입력 값들이 수신되는 경우, 신경망 프레임워크는 복수 개의 입력 값들 각각에 대한 인공 신경망의 실행을 서로 다른 프로세서로 분산시킬 수 있다. 예로, 도 3의 (a)의 신경망 프레임워크는 첫 번째 입 력 이미지에 대하여는 상 측의 제1 프로세서(예: CPU)의 이미지 분류 신경망을 이용하고, 두 번째 입력 이미지 에 대하여는 하 측의 제2 프로세서(예: GPU)의 이미지 분류 신경망을 이용할 수 있다. 제1 프로세서 및 제2 프로세서를 이용하는 경우, 복수 개의 입력 값들이 병렬로 처리되기 때문에 처리량이 향상 될 수 있는 장점이 있으나, 각각의 입력 값이 각각의 프로세서에 의하여 처리되기 때문에, 특정 프로세서의 성 능에 의하여 인공 신경망 전체의 레이턴시가 좌우될 수가 있다. 도 3a의 (b)의 제2 신경망 프레임워크는 복수 개의 신경망 레이어들의 실행을 서로 다른 프로세서로 분산시킬 수 있다. 예로, 도 3a의 (b)의 신경망 프레임워크는 제1 프로세서(예: CPU)를 이용하여 제1 및 제4 신경망 레이 어들(301,304)을 실행하고, 제2 프로세서(예: GPU)를 이용하여 제2, 제3 및 제5 신경망 레이어들(302,303,30 5)을 실행할 수 있다. 이 경우, 제1 프로세서 및 제2 프로세서 간의 공유를 위한 중간 결과 값들(311,312,313) 이 발생할 수 있다. 또한, 각각의 신경망 레이어가 각각의 프로세서에 의하여 단계적으로 처리되기 때문에, 특 정 프로세서의 성능에 의하여 인공 신경망 전체의 레이턴시가 좌우될 수 있다. 전술한 도 3a에서, 제1 및 제2 신경망 프레임워크는 복수 개의 프로세서들을 순차적으로 이용하여 신경망 레이 어를 실행하기 때문에, 특정 프로세서의 성능에 의하여 인공 신경망의 실행 성능이 제한될 수 있다. 이에, 특정 프로세서의 성능에 의한 지연을 최소화하기 위하여, 도 3b의 제3 신경망 프레임워크와 같이 제1 프 로세서(예: CPU) 및 제2 프로세서(예: GPU)를 동시에 이용하여 하나의 신경망 레이어를 처리하는 방식이 이용될 수 있다. 이 경우, 제1, 제2, 및 제4 신경망 레이어들(321,322,324)은 제1 프로세서 및 제2 프로세서에서 동시 에 처리될 수 있다. 또한, 제3 및 제5 신경망 레이어들(323,325)은 전술한 도 3a의 (b)와 같이, 제1 프로세서 (예: CPU) 및 제2 프로세서(예: GPU)에서 각각 실행될 수 있다. 다양한 실시예로, 제3 및 제5 신경망 레이어들 (323,325)은 전술한 도 3a의 (a)와 같이, 제1 프로세서(예: CPU) 및 제2 프로세서(예: GPU) 중 어느 하나의 프 로세서에서만 수행될 수도 있다. 이 때, 신경망 계측 박스의 높이는 제1 및 제2 프로세서 각각의 신경망 레이어 의 계산량을 나타낼 수 있다. 도 3b의 제3 신경망 프레임워크에 따르면 인공 신경망의 처리 속도가 크게 향상될 수 있다. 제1 프로세서(예: CPU) 및 제2 프로세서(예: GPU) 각각의 신경망 레이어의 실행 레이턴시 및 처리량이 근사할수록 상기 제3 신경 망 프레임워크는 더욱 효과적으로 동작할 수 있다. 도 4는, 본 개시의 일 실시예에 따른 인공 신경망을 처리하기 위한 신경망 프레임워크의 구성을 나타낸다. 인공 신경망의 연산 성능을 극대화하기 위하여, 복수 개의 프로세서들의 연산량을 효율적으로 분배할 필요 가 있다. 예로, 출력 채널들 관점에서 복수 개의 프로세서들을 대상으로 연산량을 분배하여, 잉여 계산을 줄이고, 성능 이득을 극대화하는 방안이 모색될 수 있다. 이 경우, 복수 개의 프로세서들이 거의 동일한 시간에 하나의 신경망 레이어에 대한 연산을 수행할 필요성이 요구된다. 이를 위하여, 도 4의 레이어 분배부는 제1 프로세서 및 제2 프로세서를 이용하여 인공 신경망을 구성하는 일 신경망 레이어의 연산을 수행하기 위한, 신경망 연산 계획을 획득할 수 있다. 레이어 분배부가 신경망 연산 계획을 획득한다는 것은, 상기 신경망 연산 계획을 메모리로부터 획득하거나, 외부 장치로부터 획득 하는 것을 포함할 수 있다. 외부 장치로부터 신경망 연산 계획을 획득하는 경우, 레이어 분배부는 복수 개 의 프로세서들의 정보를 외부 장치로 전송하여, 전송에 대한 응답으로 신경망 연산 계획을 획득하는 것을 포함할 수 있다. 또한, 레이어 분배부는 처리할 인공 신경망이 주어진 경우, 인공 신경망의 구조를 분석하 여, 가용한 복수 개의 프로세서들을 대상으로, 인공 신경망을 구성하는 각 신경망 레이어에 대한 신경망 연산 계획을 결정하여 획득할 수도 있다. 신경망 연산 계획은, 예로, 제1 프로세서 및 제2 프로세서 간의 연산 비율, 또는 제1 프로세서 및 제2 프로세서 각각의 연산량 중 적어도 하나를 포함할 수 있다. 레이어 분배부는 인공 신경망 구조로서 인공 신경망의 입력 값의 크기, 필터의 크기, 필터의 개수 또는 인 공 신경망의 출력 값의 크기 중 적어도 하나에 기반하여 일 신경망 레이어의 연산을 수행할 복수 개의 프로세서 들 각각의 연산 정도를 결정할 수 있다. 이때, 레이어 분배부는 복수 개의 프로세서들을 이용하 여 인공 신경망을 구성하는 복수 개의 신경망 레이어들 각각의 연산을 수행하기 위한, 신경망 연산 계획을 결정 할 수 있다. 일 실시예로, 레이어 분배부는 레이어 분할 데이터베이스에 포함된 정보를 참조하여 신경망 연산 계 획을 결정할 수 있다. 레이어 분할 데이터베이스에 포함된 정보는, 예로, 복수 개의 프로세서들 별 인공 신경망의 처리 시간, 또는 복수 개의 프로세서들 별 인공 신경망을 구성하는 신경망 레이어들 각각에 대한 처리 시간을 포함할 수 있다. 이때, 일 프로세서의 신경망 레이어의 처리 시간은, 예로, 상기 프로세서가 상기 일 신경망 레이어를 100% 활용한다고 가정했을 때의 처리 시간을 포함할 수 있다. 또한, 레이어 분배부는 상기 일 신경망 레이어에 대한 처리 시간 및 복수 개의 프로세서들 각각의 가 용 자원을 고려하여, 상기 일 신경망 레이어에 대한 복수 개의 프로세서들 각각의 연산 계획을 나타내는신경망 연산 계획을 결정할 수 있다. 또한, 레이어 분배부는 기 결정된 신경망 연산 계획을 이용하여, 신규 인공 신경망에 대한 신경망 연산 계 획을 결정할 수 있다. 또한, 레이어 분배부는 결정된 신경망 연산 계획에 따라 연산을 수행한, 복수 개의 프로세서들의 각 각의 실제 레이턴시를 이용하여 인공 신경망에 대한 신경망 연산 계획을 결정할 수 있다. 또한, 레이어 분배부는 전자 장치의 현재 가용 전력(예: 배터리 용량) 및 전자 장치의 전력 효 율을 고려하여, 전자 장치의 에너지 상황에 적합한 신경망 연산 계획을 결정할 수 있다. 예로, 레이어 분 배부는 전자 장치가 최소의 전력을 이용하도록 신경망 연산 계획을 결정할 수도 있다. 구체적으로, 레이어 분배부는 인공 신경망의 연산에 최소의 전력이 사용될 수 있도록, 복수 개의 프로세서들 별 인공 신경망을 구성하는 신경망 레이어들 각각에 대한 전력 효율을 분석할 수 있다. 레이어 분배부는 분석 된 전력 효율에 기반하여, 신경망 레이어의 연산을 수행하는 복수 개의 프로세서들 중 적어도 하나의 동작 주파수를 조절하거나, 복수 개의 프로세서들 중 적어도 하나의 전력을 오프하여, 최소의 전력으로 인공 신 경망 연산을 수행하는 신경망 연산 계획을 수립할 수 있다. 레이어 분배부에서 신경망 연산 계획이 결정되면, 신경망 연산 계획에 따라 제1 프로세서는 일 신경망 레 이어의 일부 연산을 수행하고, 제2 프로세서는 상기 일 신경망 레이어의 다른 일부 연산을 수행할 수 있다. 제1 프로세서의 수행 결과에 따라 제1 출력 값이 획득되고, 제2 프로세서의 수행 결과에 따라 제2 출력 값이 획득되 면, 획득된 제1 출력 값 및 제2 출력 값은 다른 일 신경망 레이어의 입력 값으로 이용될 수 있다. 구체적으로, 도 5는, 채널 지향(channel-wise) 관점에서 복수 개의 프로세서들이 신경망 레이어의 연산을 분배하여 수행하는 과정을 나타낸다. 도 5에서, 제1 및 제2 프로세서의 연산 비율은, p:(1-p)로 가정할 수 있다. 도 5의 (a)는 컨벌루션 레이어 또는 완전 연결 레이어에서 복수 개의 프로세서들이 연산을 분배하여 수행하는 과정을 나타내고, 도 5의 (b)는 풀링 레이어에서 복수 개의 프로세서들이 연산을 분배하여 수행 하는 과정을 나타낸다. 도 5의 (a)의 컨벌루션 레이어 또는 완전 연결 레이어에서는 출력 채널에 기반하여, 복수 개의 프로세서들(11 0)이 신경망 레이어의 연산을 분배하여 실행할 수 있다. 예로, 제1 및 제2 프로세서의 연산 정도에 따라, 입력 값이 적용되는 필터들(511,512)이 채널 별로 분배될 수 있다. 제1 및 제2 프로세서 각각은 분배된 필터들 (511,512)을 이용하여 각각의 출력 값들(521,522)을 생성할 수 있다. 생성된 각각의 출력 값들(521,522)은 합쳐 져서 완전한 출력 값을 생성할 수 있다. 이 경우, 필터들이 오버랩되지 않고 분배되기 때문에, 제1 및 제2 프로세서 간에는 중복되는 연산이 최소화될 수 있다. 다양한 실시예로, 인공 신경망은 순환 신경망(RNN; Recurrent Neural Network) 계열의 LSTM(Long Short Term Memory) 레이어 및 GRU(Gated Recurrent Unit) 레이어를 포함할 수도 있다. 이 경우, 도 5의 (a)와 같이 출력 채널에 기반하여, 복수 개의 프로세서들이 LSTM 레이어 또는 GRU 레이어의 연산을 분배하여 실행할 수도 있다. 도 5의 (b)의 풀링 레이어에서는 입력 채널에 기반하여, 복수 개의 프로세서들이 신경망 레이어의 연산을 분배하여 실행할 수 있다. 예로, 제1 및 제2 프로세서의 연산 정도에 따라, 입력 값이 채널 별로 분배될 수 있다. 제1 및 제2 프로세서 각각은 분배된 입력 값을 대상으로 전역 함수(global function) 필터들(551,55 2)을 적용하여 복수 개의 출력 값들(561,562)을 생성할 수 있다. 생성된 각각의 출력 값들(561,562)은 합쳐져서 완전한 출력 값을 생성할 수 있다. 이 경우에도 입력 값이 분리되어 분배되기 때문에, 제1 및 제2 프로세 서 간에는 중복되는 연산이 최소화될 수 있다. 다시 도 4에서, 레이어 분배부는 신경망 워크프레임의 성능을 극대화하기 위하여 데이터타입 데이터베이스 에 포함된 정보를 참조하여, 각 프로세서들이 사용할 데이터 타입을 획득할 수 있다. 데이터타입 데이터베 이스에 포함된 정보는, 예로, 인공 신경망을 처리하기에 적합한 복수 개의 프로세서들 각각의 데이터 타입을 포함할 수 있다. 복수 개의 프로세서들 별 데이터 타입을 참조하여, 레이어 분배부는 복수 개 의 프로세서들 각각에 적합한 양자화 방식을 결정할 수도 있다. 이 때, 데이터 타입은, 예로, 16비트 부동소수점(16-bit floating-points, F16), 8비트 양자화 정수(quantized 8-bit integers, QUInt8) 등을 포함할 수 있으나, 전술한 타입에 제한되는 것은 아니다. 일반적으로, GPU는 그래픽 어플리케이션의 이용에 최적화되도록 부동 소수점을 이용하고, CPU는 한 사이클 당 다수의 8비트 정수를 처리할 수 있는 벡터 ALUs(Arithmetic Logic Units)을 포함할 수 있다. 이 경우, 데이터 타입의 변환을 위하여, 예로, 반정밀 부동 소수점(half-precision floating point) 방식 또는 선형 양자화 (linear quantization) 방식이 이용될 수 있다. 반정밀 부동 소수점 방식은, 지수와 가수를 줄임으로써 32비트 의 부동 소수점을 16비트의 부동 소수점으로 표현할 수 있다. 선형 양자화 방식은 32비트의 부동 소수점을 8비 트의 양의 정수로 표현할 수 있다. 레이어 분배부는 입력 값, 필터, 출력 값을 선형 양자화된 8비트의 정수 값으로 저장할 수 있다. 이는 CPU, GPU 및 메모리 간의 데이터 이동 크기를 최소화할 수 있다. 도 6은, 전술한 두 종류의 양자화 방법의 적용에 따른 신경망 실행 레이턴시를 감소하는 과정을 나타내는 도면 이다. 도 6의 (a)는 CPU를 대상으로 데이터 타입을 변환하여 신경망 레이어의 연산을 수행하는 예이고, 도 6의 (b)는 GPU를 대상으로 데이터 타입을 변환하여 신경망 레이어의 연산을 수행하는 예이다. 도 6의 (a)에서, CPU는 벡터 ALUs의 충분한 활용을 위하여 8비트 정수로 신경망의 연산을 수행할 수 있다. CPU 에서 8비트의 입력 값과 필터와의 컨벌루션 연산의 누적에 따라 32비트 값이 생성되면, 32비트 출력 값은 기 정 의된 양자화 과정을 거쳐서 8비트의 정수 값으로 변환될 수 있다. 도 6의 (b)에서, GPU는 연산 레이턴시를 최소화하기 위하여, 16비트 부동 소수점으로 신경망의 연산을 수행할 수 있다. 이에, 도 6의 (b)에서 8비트 입력 값은 역양자화를 통하여 16비트 값으로 변환되고, 16비트의 입력 값 과 필터와의 컨벌루션 연산의 누적에 따라 16비트 값이 생성되면, 16비트 출력 값은 기정의된 양자화 과정을 거 쳐서 8비트의 정수 값으로 변환될 수 있다. 이와 같이, 각 프로세서들이 이용할 데이터 타입을 지정함에 따라, 신경망 레이어의 연산 레이턴시가 최소화되 고, CPU, GUP 및 메모리 간에 데이터의 이동에 필요한 자원 소비가 최소화될 수 있다. 한편, 최근의 인공 신경망의 연산은 동일한 입력 값을 여러 시퀀스들에 따라 분기(branch)하여 처리하는 방식으 로 수행될 수도 있다. 이는, 입력 값이 매우 크거나, 신경망 레이어의 수가 많아서 오버피팅(overfitting) 발생 가능성이 큰 상황에서 이용될 수 있다. 분기 연산은, 다른 필터 크기들을 이용하여 컨벌루션 연산을 수행하거나, 동일한 입력 값에 대하여 병렬로 풀링 연산을 수행한 후, 출력 채널 차수를 기준으로 연산 결과를 연결하여 최종 출력 값을 획득하는 방식으로 수행될 수 있다. 이러한, 분기 연산 방식의 인공 신경망 처리는, 예로, GoogLeNet, SqueezeNet 모듈 등이 있을 수 있다. 본 개시의 실시 예들은 전술한 분기 연산 방식의 인공 신경망 처리에도 적용되어 실행 레이턴시(execution latency)을 더욱 줄일 수 있다. 예로, 레이어 분배부는 분기에 대응되도록 프로세서 별로 연산을 분배할 수 있다. 구체적으로, 레이어 분배부는 병렬 가능한 분기 세트를 식별하고, 식별된 분기 세트들 각각을 제 1 프로세서 및 제2 프로세서에 할당할 수 있다. 이에 따라, 제1 및 제2 프로세서가 인공 신경망을 대상으로 분 기 연산을 수행하는 것이 가능해질 수 있다. 도 7은, 도 4의 신경망 프레임워크의 레이어 분배부를 상세하게 나타내는 도면이다. 도 7에서, 레이어 분배부는 도 4의 레이어 분배부에 대응될 수 있다. 레이어 분배부는 전술한 채널 지향 기준의 신경망 레이어 연산 분배 방식, 프로세서 별 적합한 양자화 방식 또는 분기 대응 연산 분배 방식 중 적어도 하나를 수행하는 인공 신경망 프레임워크를 위한 소프트웨어 레이어일 수 있다. 레이어 분배부는 인공 신경망 및 필터를 분석하여, 상기 방식들을 인공 신경망의 연산에 적용할 수 있다. 레이어 분배부는 신경망 분할부 및 신경망 실행부를 포함할 수 있다. 신경망 분할부는 프 로세서 간 협력 실행하는 신경망 연산 계획을 획득할 수 있다. 예로, 신경망 분할부는, 전술한 채널 지향 기준의 신경망 레이어 연산 분배 방식을 실행하기 위하여, 프로세서 별 최적의 분배 비율을 결정할 수 있다. 예 로, 신경망 분할부는 신경망 레이어의 파라미터(예: 필터 크기, 카운트(count) 등) 및 복수 개의 프로세서 들 각각의 가용 자원을 고려하여, 프로세서 별 레이턴시를 예측하고, 이를 고려하여 복수 개의 프로세서 별 최적의 분배 비율을 결정할 수 있다. 이때, 프로세서 별 레이턴시를 예측하기 위하여, 예로, 로지스틱 회귀 (logistic regression) 알고리즘이 이용될 수 있다. 신경망 실행부는 신경망 연산 계획에 기반하여, 인공 신경망을 실행할 수 있다. 먼저, 신경망 실행부(71 2)는 필터들을 제1 및 제2 프로세서의 메모리로 업로드할 수 있다. 필터들이 업로드되면, 신경망 분할부는 필터들의 값을 16비트 부동 소수점으로 역양자화(dequantize)할 수 있다. 이후, 신경망 실행부는 최적의 분배 비율로 레이어의 연산을 수행하기 위하여, 미들웨어의 API 함수(예: GPU 실행을 위한 OpenCL 커맨드 등)를 실행시킬 수 있다. 도 8은 본 개시의 실시예에 따른 인공 신경망을 처리하는 전자 장치의 흐름도를 나타낸다. 먼저, 동작 801에서, 전자 장치는 제1 프로세서 및 제2 프로세서를 이용하여 인공 신경망을 구 성하는 일 신경망 레이어의 연산을 수행하기 위한, 신경망 연산 계획을 획득할 수 있다. 이때, 신경망 연산 계 획은, 제1 프로세서 및 제2 프로세서 간의 연산 비율, 또는 제1 프로세서 및 제2 프로세서 각각의 연산량 중 적어도 하나를 포함할 수 있다. 일 실시예에 따르면, 전자 장치는 제1 프로세서 및 제2 프로세서 각각의 일 신경망 레이어의 처 리 시간 또는 제1 프로세서 및 제2 프로세서 각각의 가용 자원 중 적어도 하나에 기반하여, 신경망 연산 계획을 획득할 수 있다. 일 실시예에 따르면, 전자 장치는 인공 신경망의 구조로서, 인공 신경망의 입력 값의 크기, 필터의 크기, 필터의 개수 또는 출력 값의 크기 중 적어도 하나에 기반하여, 신경망 연산 계획을 획득할 수 있다. 일 실시예에 따르면, 전자 장치는 제1 프로세서 및 제2 프로세서를 이용하여 인공 신경망을 구 성하는 복수 개의 신경망 레이어들 각각의 연산을 수행하기 위한, 신경망 연산 계획을 획득할 수 있다. 동작 803에서, 전자 장치는 획득된 신경망 연산 계획에 따라, 제1 프로세서를 이용하여 일 신경망 레 이어의 일부 연산을 수행하고, 제2 프로세서를 이용하여 일 신경망 레이어의 다른 일부 연산을 수행할 수 있다. 일 실시예에 따르면, 전자 장치는 제1 프로세서 및 제2 프로세서 각각에서 이용되는 데이터 타 입을 획득할 수 있다. 그리고, 획득된 신경망 연산 계획 및 데이터 타입에 따라, 제1 프로세서를 이용하여 일 신경망 레이어의 일부 연산을 수행하고, 제2 프로세서를 이용하여 일 신경망 레이어의 다른 일부 연산 을 수행할 수 있다. 일 실시예에 따르면, 전자 장치는 제1 입력 채널을 대상으로 제1 프로세서를 이용하여 일 신경망 레 이어의 일부 연산을 수행하고, 제1 입력 채널과 다른 제2 입력 채널을 대상으로 제2 프로세서를 이용하여 일 신경망 레이어의 다른 일부 연산을 수행할 수 있다. 이때, 일 신경망 레이어는 컨벌루션 레이어 또는 완전 연결 레이어일 수 있다. 일 실시예에 따르면, 전자 장치는 제1 출력 채널을 대상으로 제1 프로세서를 이용하여 일 신경망 레 이어의 일부 연산을 수행하고, 제1 출력 채널과 다른 제2 출력 채널을 대상으로 제2 프로세서를 이용하여 일 신경망 레이어의 다른 일부 연산을 수행할 수 있다. 이때, 일 신경망 레이어는 풀링 레이어일 수 있다. 동작 805에서, 전자 장치는 제1 프로세서의 수행 결과에 따른 제1 출력 값 및 제2 프로세서의 수행 결과에 따른 제2 출력 값을 획득할 수 있다. 동작 807에서, 전자 장치는 획득된 제1 출력 값 및 제2 출력 값을 인공 신경망을 구성하는 다른 일 신경망 레이어의 입력 값으로써 이용할 수 있다. 본 개시에 따라. 복수 개의 프로세서를 이용하여 인공 신경망을 구성하는 복수 개의 레이어들 각각에 대하여 협 업 연산을 수행하는 경우, 인공 신경망의 처리 시간이 종래 기술 대비 크게 개선될 수 있다. 예로, 본 개시의 실시예에 따라 이미지 분류 신경망들(예: GoogLeNet, SqueezeNet, VGG-16, AlexNet, MobileNet)의 처리 시간 및 소모 전력이 단일의 프로세서를 이용하는 종래 기술 대비 크게 개선될 수 있다. 본 개시의 실시예를 갤럭시 노트 5에 적용한 결과, 처리 시간은 종래 기술 대비 평균 59.9%가 단축되고, 소모 에너지는 종래 기술 대비 평균 26%가 감소되는 것이 확인될 수 있다. 또한, 본 개시의 실시예를 갤럭시 A5에 적 용한 결과, 처리 시간은 종래 기술 대비 평균 69.6%가 단축되고, 소모 에너지는 종래 기술 대비 평균 34%가 감 소되는 것이 확인될 수 있다. 이와 같이, 인공 신경망의 처리 시간 단축 및 에너지의 소비량 감소는 인공 신경망의 효율적인 운영 및 활용 분 야의 다양화에 큰 기여가 될 수 있다. 본 문서에서 사용된 용어 \"모듈\"은 하드웨어, 소프트웨어 또는 펌웨어로 구현된 유닛을 포함할 수 있으며, 예를 들면, 로직, 논리 블록, 부품, 또는 회로 등의 용어와 상호 호환적으로 사용될 수 있다. 모듈은, 일체로 구성된 부품 또는 하나 또는 그 이상의 기능을 수행하는, 상기 부품의 최소 단위 또는 그 일부가 될 수 있다. 예를 들 면, 일 실시예에 따르면, 모듈은 ASIC(application-specific integrated circuit)의 형태로 구현될 수 있다. 본 문서의 다양한 실시예들은 기기(machine)(예: 전자 장치) 의해 읽을 수 있는 저장 매체(storage medium)(예: 메모리)에 저장된 하나 이상의 명령어들을 포함하는 소프트웨어로서 구현될 수 있다. 예를 들 면, 기기(예: 전자 장치)의 프로세서(예: 복수 개의 프로세서들 중 적어도 하나)는, 저장 매체로부터 저장된 하나 이상의 명령어들 중 적어도 하나의 명령을 호출하고, 그것을 실행할 수 있다. 이것은 기기가 상기 호출된 적어도 하나의 명령어에 따라 적어도 하나의 기능을 수행하도록 운영되는 것을 가능하게 한다. 상기 하 나 이상의 명령어들은 컴파일러에 의해 생성된 코드 또는 인터프리터에 의해 실행될 수 있는 코드를 포함할 수 있다. 기기로 읽을 수 있는 저장매체는, 비일시적(non-transitory) 저장매체의 형태로 제공될 수 있다. 여기서, ‘비일시적’은 저장매체가 실재(tangible)하는 장치이고, 신호(signal)(예: 전자기파)를 포함하지 않는다는 것 을 의미할 뿐이며, 이 용어는 데이터가 저장매체에 반영구적으로 저장되는 경우와 임시적으로 저장되는 경우를 구분하지 않는다. 일 실시예에 따르면, 본 문서에 개시된 다양한 실시예들에 따른 방법은 컴퓨터 프로그램 제품(computer program product)에 포함되어 제공될 수 있다. 컴퓨터 프로그램 제품은 상품으로서 판매자 및 구매자 간에 거래될 수 있 다. 컴퓨터 프로그램 제품은 기기로 읽을 수 있는 저장 매체(예: compact disc read only memory (CD-ROM))의 형태로 배포되거나, 또는 어플리케이션 스토어(예: 플레이 스토어TM)를 통해 또는 두개의 사용자 장치들(예: 스 마트폰들) 간에 직접, 온라인으로 배포(예: 다운로드 또는 업로드)될 수 있다. 온라인 배포의 경우에, 컴퓨터 프로그램 제품의 적어도 일부는 제조사의 서버, 어플리케이션 스토어의 서버, 또는 중계 서버의 메모리와 같은 기기로 읽을 수 있는 저장 매체에 적어도 일시 저장되거나, 임시적으로 생성될 수 있다. 다양한 실시예들에 따르면, 상기 기술한 구성요소들의 각각의 구성요소(예: 모듈 또는 프로그램)는 단수 또는 복수의 개체를 포함할 수 있다. 다양한 실시예들에 따르면, 전술한 해당 구성요소들 중 하나 이상의 구성요소들 또는 동작들이 생략되거나, 또는 하나 이상의 다른 구성요소들 또는 동작들이 추가될 수 있다. 대체적으로 또는 추가적으로, 복수의 구성요소들(예: 모듈 또는 프로그램)은 하나의 구성요소로 통합될 수 있다. 이런 경우, 통 합된 구성요소는 상기 복수의 구성요소들 각각의 구성요소의 하나 이상의 기능들을 상기 통합 이전에 상기 복수 의 구성요소들 중 해당 구성요소에 의해 수행되는 것과 동일 또는 유사하게 수행할 수 있다. 다양한 실시예들에 따르면, 모듈, 프로그램 또는 다른 구성요소에 의해 수행되는 동작들은 순차적으로, 병렬적으로, 반복적으로, 또는 휴리스틱하게 실행되거나, 상기 동작들 중 하나 이상이 다른 순서로 실행되거나, 생략되거나, 또는 하나 이상의 다른 동작들이 추가될 수 있다."}
{"patent_id": "10-2019-0031654", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은, 본 개시의 일 실시예에 따른 전자 장치의 구성을 나타내는 블록도를 나타낸다. 도 2는, 본 개시의 실시예들에 적용될 수 있는 컨벌루션 신경망의 구조를 나타낸다. 도 3a 및 도 3b는, 본 개시의 일 실시예에 따른 인공 신경망의 연산을 수행하는 과정을 나타낸다. 도 4는, 본 개시의 일 실시예에 따른 인공 신경망을 처리하기 위한 신경망 프레임워크의 구성을 나타낸다. 도 5는, 본 개시의 일 실시예에 따른 복수 개의 프로세서들이 신경망 레이어의 연산을 분배하여 수행하는 과정 을 나타낸다. 도 6은, 본 개시의 일 실시예에 따라 변환된 데이터 구조를 이용하여, 복수 개의 프로세서들이 신경망 레이어의 연산을 수행하는 과정을 나타낸다.도 7은, 본 개시의 일 실시예에 따른 레이어 분배부를 상세하게 나타낸다. 도 8은, 본 개시의 일 실시예에 따른 인공 신경망을 처리하는 전자 장치의 흐름도를 나타낸다."}
