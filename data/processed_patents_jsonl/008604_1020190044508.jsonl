{"patent_id": "10-2019-0044508", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2020-0121666", "출원번호": "10-2019-0044508", "발명의 명칭": "오차 보정 방법 및 센서 시스템", "출원인": "광주과학기술원", "발명자": "류제하"}}
{"patent_id": "10-2019-0044508", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "공간 센서가, 공간 내 오브젝트의 포즈를 측정한 제1 측정값을 획득하는 단계;정밀 센서가, 상기 공간 내 상기 오브젝트의 포즈를 측정한 제2 측정값을 획득하는 단계; 및상기 공간 센서의 포즈의 측정 값, 상기 제1 측정값 및 상기 제1 측정값에 대응하는 제2 측정값을 이용하여 인공 신경망을 트레이닝 하는 단계를 포함하는오차 보정 방법."}
{"patent_id": "10-2019-0044508", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1항에 있어서,상기 인공 신경망을 트레이닝 하는 단계는,상기 공간 센서의 포즈의 측정 값 및 상기 제1 측정값을 입력으로, 상기 제2 측정값을 출력으로 이용하여, 상기인공 신경망을 트레이닝 하는 단계를 포함하는오차 보정 방법."}
{"patent_id": "10-2019-0044508", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 2항에서,상기 인공 신경망을 트레이닝 하는 단계는,상기 공간 센서의 포즈의 측정 값 및 상기 공간 센서에서 상기 오브젝트의 특정 포즈를 측정한 상기 제1측정값을 입력으로, 상기 정밀 센서에서 상기 오브젝트의 특정 포즈를 측정한 상기 제2 측정값을 출력으로 이용하여,상기 인공 신경망을 트레이닝 하는 단계를 포함하는오차 보정 방법."}
{"patent_id": "10-2019-0044508", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 1항에 있어서,상기 인공 신경망을 트레이닝 하는 단계는,상기 공간 센서의 동일한 포즈에 대하여, 상기 오브젝트의 포즈를 다양하게 변경하면서 획득한 상기 제1 측정값및 상기 오브젝트의 포즈를 다양하게 변경하면서 획득한 상기 제1 측정값에 대응하는 상기 제2 측정값을 이용하여 상기 인공 신경망을 트레이닝 하는 단계를 포함하는오차 보정 방법."}
{"patent_id": "10-2019-0044508", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제 1항에 있어서,상기 인공 신경망을 트레이닝 하는 단계는,상기 공간 센서의 복수의 포즈의 측정 값, 상기 복수의 포즈를 가지는 상기 공간 센서가 상기 오브젝트를 측정한 상기 제1 측정값 및 상기 제1 측정값에 대응하는 제2 측정값을 이용하여 상기 인공 신경망을 트레이닝 하는단계를 포함하는오차 보정 방법.공개특허 10-2020-0121666-3-청구항 6 제 1항에 있어서,다른 공간 센서가, 다른 공간 내 오브젝트의 포즈를 측정한 제3 측정값을 획득하는 단계; 및상기 다른 공간 센서의 포즈의 측정 값 및 상기 제3 측정값을 상기 트레이닝 된 인공 신경망에 입력하여, 상기제3 측정값을 보정한 제4 측정값을 획득하는 단계를 더 포함하는오차 보정 방법."}
{"patent_id": "10-2019-0044508", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "가상 현실을 위한 센서 시스템에 있어서,상기 센서 시스템이 설치된 특정 공간 내 특정 오브젝트의 포즈를 측정한 측정값을 획득하는 VR 공간 센서;교정 모델을 저장하는 메모리; 및상기 VR 공간 센서의 포즈의 측정값 및 상기 측정값을 상기 교정 모델에 입력하여, 상기 VR 공간 센서가 획득한측정값을 보정한 보정 값을 획득하는 프로세서를 포함하고,상기 교정 모델은,공간 센서의 포즈의 측정값, 상기 공간 센서가 공간 내 오브젝트의 포즈를 측정한 제1 측정값, 및, 정밀 센서가상기 공간 내 상기 오브젝트의 포즈를 측정한 제2 측정값을 이용하여 트레이닝 된 인공 신경망을 포함하는센서 시스템."}
{"patent_id": "10-2019-0044508", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제 7항에 있어서,상기 교정 모델은,상기 공간 센서의 포즈의 측정값 및 상기 제1 측정값을 입력으로, 상기 제2 측정값을 출력으로 이용하여 트레이닝 된 인공 신경망인센서 시스템."}
{"patent_id": "10-2019-0044508", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제 8항에서,상기 교정 모델은,상기 공간 센서의 포즈의 측정 값 및 상기 공간 센서에서 상기 오브젝트의 특정 포즈를 측정한 상기 제1측정값을 입력으로, 상기 정밀 센서에서 상기 오브젝트의 상기 특정 포즈를 측정한 상기 제2 측정값을 출력으로 이용하여 트레이닝 된 인공 신경망인센서 시스템."}
{"patent_id": "10-2019-0044508", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제 7항에 있어서,상기 교정 모델은,상기 공간 센서의 동일한 포즈에 대하여, 상기 오브젝트의 포즈를 다양하게 변경하면서 획득한 상기 제1 측정값및 상기 오브젝트의 포즈를 다양하게 변경하면서 획득한 상기 제1 측정값에 대응하는 제2 측정값을 이용하여 트레이닝 된 인공 신경망인센서 시스템."}
{"patent_id": "10-2019-0044508", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "공개특허 10-2020-0121666-4-제 7항에 있어서,상기 교정 모델은,상기 공간 센서의 복수의 포즈의 측정 값, 상기 복수의 포즈를 가지는 상기 공간 센서가 상기 오브젝트를 측정한 상기 제1 측정값 및 상기 제1 측정값에 대응하는 제2 측정값을 이용하여 트레이닝 된 인공 신경망인센서 시스템."}
{"patent_id": "10-2019-0044508", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "오차 보정 방법이 개시된다. 본 발명의 실시 예에 따른 오차 보정 방법은, 공간 센서가 공간 내 오브젝트의 포즈 를 측정한 제1 측정값을 획득하는 단계, 정밀 센서가 상기 공간 내 상기 오브젝트의 포즈를 측정한 제2 측정값을 획득하는 단계, 및, 상기 공간 센서의 포즈의 측정 값, 상기 제1 측정값 및 상기 제1 측정값에 대응하는 제2 측 정값을 이용하여 인공 신경망을 트레이닝 하는 단계를 포함한다."}
{"patent_id": "10-2019-0044508", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은, 공간 센서로 측정된 측정 값에 정밀 센서로 측정된 측정 값을 레이블링 하여 인공 신경망을 트레이 닝 함으로써, 공간 센서로 측정된 측정 값을 가지고 정밀 센서로 측정된 측정 값을 추론할 수 있는 오차 보정 방법 및 센서 시스템에 관한 것이다."}
{"patent_id": "10-2019-0044508", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "인공 지능(artificial intelligence)은 인간의 지능으로 할 수 있는 사고, 학습, 자기계발 등을 컴퓨터가 할 수 있도록 하는 방법을 연구하는 컴퓨터 공학 및 정보기술의 한 분야로, 컴퓨터가 인간의 지능적인 행동을 모방할 수 있도록 하는 것을 의미한다. 또한, 인공지능은 그 자체로 존재하는 것이 아니라, 컴퓨터 과학의 다른 분야와 직간접으로 많은 관련을 맺고 있다. 특히 현대에는 정보기술의 여러 분야에서 인공지능적 요소를 도입하여, 그 분야의 문제 풀이에 활용하려 는 시도가 매우 활발하게 이루어지고 있다. 한편, 인공지능을 이용하여 주변의 상황을 인지 및 학습하고 사용자가 원하는 정보를 원하는 형태로 제공하거나 사용자가 원하는 동작이나 기능을 수행하는 기술이 활발하게 연구되고 있다. 근래에 가상현실 기술이 많이 사용되고 있으며, 가상현실 시스템에는 공간상의 오브젝트의 포즈를 측정하는 모 션 트래커(Motion tracker)(예: VIVE 트래커)가 주로 사용한다. 오브젝트의 포즈를 이용하여 가상현실을 현실감 있게 구현하기 위해서는, 매우 정교한 측정 시스템을 제공할 필 요성이 있다."}
{"patent_id": "10-2019-0044508", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 상술한 문제점을 해결하기 위한 것으로, 본 발명의 목적은, 공간 센서로 측정된 측정 값에 정밀 센서 로 측정된 측정 값을 레이블링 하여 인공 신경망을 트레이닝 함으로써, 공간 센서로 측정된 측정 값을 가지고 정밀 센서로 측정된 측정 값을 추론할 수 있는 오차 보정 방법 및 센서 시스템을 제공하기 위함이다."}
{"patent_id": "10-2019-0044508", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 실시 예에 따른 오차 보정 방법은, 공간 센서가 공간 내 오브젝트의 포즈를 측정한 제1 측정값을 획 득하는 단계, 정밀 센서가, 상기 공간 내 상기 오브젝트의 포즈를 측정한 제2 측정값을 획득하는 단계, 및, 상 기 공간 센서의 포즈의 측정 값, 상기 제1 측정값 및 상기 제1 측정값에 대응하는 제2 측정값을 이용하여 인공 신경망을 트레이닝 하는 단계를 포함한다. 이 경우 상기 인공 신경망을 트레이닝 하는 단계는, 상기 공간 센서의 포즈의 측정 값 및 상기 제1 측정값을 입 력으로, 상기 제2 측정값을 출력으로 이용하여, 상기 인공 신경망을 트레이닝 하는 단계를 포함할 수 있다. 이 경우 상기 인공 신경망을 트레이닝 하는 단계는, 상기 공간 센서의 포즈의 측정 값 및 상기 공간 센서에서 상기 오브젝트의 특정 포즈를 측정한 상기 제1측정값을 입력으로, 상기 정밀 센서에서 상기 오브젝트의 특정 포 즈를 측정한 상기 제2 측정값을 출력으로 이용하여, 상기 인공 신경망을 트레이닝 하는 단계를 포함할 수 있다. 한편 상기 인공 신경망을 트레이닝 하는 단계는, 상기 공간 센서의 동일한 포즈에 대하여, 상기 오브젝트의 포 즈를 다양하게 변경하면서 획득한 상기 제1 측정값 및 상기 오브젝트의 포즈를 다양하게 변경하면서 획득한 상기 제1 측정값에 대응하는 상기 제2 측정값을 이용하여 상기 인공 신경망을 트레이닝 하는 단계를 포함할 수 있 다. 한편 상기 인공 신경망을 트레이닝 하는 단계는, 상기 공간 센서의 복수의 포즈의 측정 값, 상기 복수의 포즈를 가지는 상기 공간 센서가 상기 오브젝트를 측정한 상기 제1 측정값 및 상기 제1 측정값에 대응하는 제2 측정값 을 이용하여 상기 인공 신경망을 트레이닝 하는 단계를 포함할 수 있다. 한편 다른 공간 센서가, 다른 공간 내 오브젝트의 포즈를 측정한 제3 측정값을 획득하는 단계, 및, 상기 다른 공간 센서의 포즈의 측정 값 및 상기 제3 측정값을 상기 트레이닝 된 인공 신경망에 입력하여, 상기 제3 측정값 을 보정한 제4 측정값을 획득하는 단계를 더 포함할 수 있다. 한편 가상 현실을 위한 센서 시스템은, 상기 센서 시스템이 설치된 특정 공간 내 특정 오브젝트의 포즈를 측정 한 측정값을 획득하는 VR 공간 센서, 교정 모델을 저장하는 메모리, 및, 상기 VR 공간 센서의 포즈의 측정값 및 상기 측정값을 상기 교정 모델에 입력하여, 상기 VR 공간 센서가 획득한 측정값을 보정한 보정 값을 획득하는 프로세서를 포함하고, 상기 교정 모델은, 공간 센서의 포즈의 측정값, 상기 공간 센서가 공간 내 오브젝트의 포 즈를 측정한 제1 측정값, 및, 정밀 센서가 상기 공간 내 상기 오브젝트의 포즈를 측정한 제2 측정값을 이용하여 트레이닝 된 인공 신경망을 포함할 수 있다. 이 경우 상기 교정 모델은, 상기 공간 센서의 포즈의 측정값 및 상기 제1 측정값을 입력으로, 상기 제2 측정값 을 출력으로 이용하여 트레이닝 된 인공 신경망일 수 있다. 이 경우 상기 교정 모델은, 상기 공간 센서의 포즈의 측정 값 및 상기 공간 센서에서 상기 오브젝트의 특정 포 즈를 측정한 상기 제1측정값을 입력으로, 상기 정밀 센서에서 상기 오브젝트의 상기 특정 포즈를 측정한 상기 제2 측정값을 출력으로 이용하여 트레이닝 된 인공 신경망일 수 있다. 한편 상기 교정 모델은, 상기 공간 센서의 동일한 포즈에 대하여, 상기 오브젝트의 포즈를 다양하게 변경하면서 획득한 상기 제1 측정값 및 상기 오브젝트의 포즈를 다양하게 변경하면서 획득한 상기 제1 측정값에 대응하는 제2 측정값을 이용하여 트레이닝 된 인공 신경망일 수 있다. 한편 상기 교정 모델은, 상기 공간 센서의 복수의 포즈의 측정 값, 상기 복수의 포즈를 가지는 상기 공간 센서 가 상기 오브젝트를 측정한 상기 제1 측정값 및 상기 제1 측정값에 대응하는 제2 측정값을 이용하여 트레이닝 된 인공 신경망일 수 있다."}
{"patent_id": "10-2019-0044508", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 첨부된 도면을 참조하여 본 명세서에 개시된 실시 예를 상세히 설명하되, 도면 부호에 관계없이 동일하거 나 유사한 구성요소는 동일한 참조 번호를 부여하고 이에 대한 중복되는 설명은 생략하기로 한다. 이하의 설명 에서 사용되는 구성요소에 대한 접미사 \"모듈\" 및 \"부\"는 명세서 작성의 용이함만이 고려되어 부여되거나 혼용 되는 것으로서, 그 자체로 서로 구별되는 의미 또는 역할을 갖는 것은 아니다. 또한, 본 명세서에 개시된 실시 예를 설명함에 있어서 관련된 공지 기술에 대한 구체적인 설명이 본 명세서에 개시된 실시 예의 요지를 흐릴 수 있다고 판단되는 경우 그 상세한 설명을 생략한다. 또한, 첨부된 도면은 본 명세서에 개시된 실시 예를 쉽게 이 해할 수 있도록 하기 위한 것일 뿐, 첨부된 도면에 의해 본 명세서에 개시된 기술적 사상이 제한되지 않으며, 본 발명의 사상 및 기술 범위에 포함되는 모든 변경, 균등물 내지 대체물을 포함하는 것으로 이해되어야 한다. 제1, 제2 등과 같이 서수를 포함하는 용어는 다양한 구성요소들을 설명하는데 사용될 수 있지만, 상기 구성요소 들은 상기 용어들에 의해 한정되지는 않는다. 상기 용어들은 하나의 구성요소를 다른 구성요소로부터 구별하는목적으로만 사용된다. 어떤 구성요소가 다른 구성요소에 \"연결되어\" 있다거나 \"접속되어\" 있다고 언급된 때에는, 그 다른 구성요소에 직접적으로 연결되어 있거나 또는 접속되어 있을 수도 있지만, 중간에 다른 구성요소가 존재할 수도 있다고 이 해되어야 할 것이다. 반면에, 어떤 구성요소가 다른 구성요소에 \"직접 연결되어\" 있다거나 \"직접 접속되어\" 있 다고 언급된 때에는, 중간에 다른 구성요소가 존재하지 않는 것으로 이해되어야 할 것이다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 출원에서, \"포함한다\" 또 는 \"가지다\" 등의 용어는 명세서상에 기재된 특징, 숫자, 단계, 동작, 구성요소, 부품 또는 이들을 조합한 것이 존재함을 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성요소, 부품 또는 이 들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되어야 한다. 본 발명을 구현함에 있어서 설명의 편의를 위하여 구성요소를 세분화하여 설명할 수 있으나, 이들 구성요소가 하나의 장치 또는 모듈 내에 구현될 수도 있고, 혹은 하나의 구성요소가 다수의 장치 또는 모듈들에 나뉘어져서 구현될 수도 있다. 도 1 및 도 2는 센서 시스템의 교정 과정에서 발생할 수 있는 문제점을 설명하기 위한 도면이다. 근래에 가상현실 기술이 많이 사용되고 있으며, 가상현실 시스템에는 공간상의 오브젝트의 포즈를 측정하는 모 션 트래커(Motion tracker)(예: VIVE 트래커)가 주로 사용한다. 이와 같이 가상 현실의 구현을 위하여 공간상의 오브젝트의 포즈를 측정하는 시스템을 센서 시스템이라 명칭할 수 있다. 일반적으로 가상현실을 위한 센서 시스템은 측정 공간 상에 존재하는 오브젝트의 포즈를 측정한다. 그리고 이러 한 센서 시스템의 정확도를 향상시키기 위한 목적으로 교정(calibration)이 수행된다. 센서 시스템으로는 광학식 센서(Optical Sensor)가 가장 보편적이며, 그 외에는 정교한 엔코더를 이용하는 기계 식 센서(Mechanical Sensor)나 자기장을 이용하는 자기장 센서(Magnetic Sensor) 등이 있다. 이 중 광학식 센서(Optical Sensor)는 설치하는 방법에 따라 오차범위에 영향을 주고, 측정공간 내에서도 오브 젝트의 위치마다 오차 범위의 차이가 발생하기 때문에, 다른 방식에 비해 빈번하게 교정(Calibration)을 수행되 어야 한다. 교정(calibration)이란, 센서 시스템의 측정 오차를 보정하는 것을 의미한다. 교정(calibration)을 수행하는 대표적인 방법으로 도1에서 도시하는 바와 같이 매우 정밀하게 제작된 교정도구 를 측정공간 내에서 움직이면서 교정 도구의 형상을 이용하여 교정(Calibration)을 수행하는 방 법과, 도2와 같이 매우 정밀한 정밀 센서(예: 기계식 트래커)를 이용하여 측정공간 내의 여러 지점을 측정한 측정 값을 이용하여 교정(Calibration)을 수행하는 방법이 있다. 다만 위와 같은 교정(calibration) 방식은 센서 시스템이 설치 될 때마다 수행되어야 하기 때문에, 센서 시스템 의 설치 시 설치 기사가 출동하거나, 개인이 직접 교정 도구나 정밀 센서를 가지고 교정을 해야 한다는 문제가 있었다. 또한 위와 같은 교정 (calibration) 방식은, 시간이 흐름에 따라 센서 시스템(예를 들어 카메라(111, 112))의 포즈가 변경되는 경우 오차가 발생하기 때문에, 주기적으로 설치 기사가 출동하거나 개인이 직접 교정을 해야 한다는 문제가 있었다. 또한 센서 시스템을 설치할 때마다 센서 시스템의 포즈에 미묘한 변화가 발생한다. 따라서 센서 시스템의 판매 자 입장에서는, 센서 시스템을 설치할 때마다 소비자를 방문하여 교정(calibration)을 해줘야 하는 문제가 있었 다. 또한 교정(calibration)은 측정 공간 내의 각 지점마다 발생하는 측정오차를 측정하고 측정오차를 기반으 로 오차모델(Error Model)을 추정하는 과정이다. 따라서, 가능하면 다양한 위치, 더 넓은 공간에 대해 오차를 측정하여 교정(Calibration)을 수행할수록 오차모 델(Error Model)을 정밀하게 추정되고, 이에 따라 측정 오차를 효과적으로 줄일 수 있다. 다만 측정공간이 큰 경우 이러한 조건을 만족하도록 교정(Calibration)을 수행하는 것이 힘들다. 특히 도2의 방 식을 이용하는 경우, 정밀 센서의 매우 좁은 측정 범위 때문에, 넓은 측정 공간에 대하여 충분한 데이터를 획득하기 어려운 문제가 있다. 또한 현재 센서 시스템은 측정 공간 내 메인 영역에 대해서만 높은 정확도를 보이는 문제가 있었다. 도 3은 본 발명의 실시 예에 따른, 인공 신경망의 학습 장치의 구성을 나타낸 블록도이다. 학습 장치는 데이터 마이닝, 데이터 분석, 지능형 의사 결정 및 기계 학습 알고리즘을 위해 이용될 정보를 수신, 분류, 저장 및 출력하도록 구성될 수 있다. 여기서, 기계 학습 알고리즘은 딥 러닝 알고리즘을 포함할 수 있다. 도 3을 참조하면, 학습 장치는 공간 센서, 정밀 센서, 메모리, 전원 공급부 및 프로 세서를 포함할 수 있다. 공간 센서는 센서 시스템을 구성하는 것으로 공간 내 오브젝트의 포즈를 측정한 측정 값을 획득할 수 있다. 공간 센서는 광학식 센서, 기계식 센서 및 자기장 센서 중 적어도 하나일 수 있다. 한편 센서 시스템에서는 광학식 센서가 가장 보편적으로 사용되며, 이하에서는 공간 센서가 광학식 센서 중 카메라인 것으로 가정하여 설명한다. 공간 센서는 공간 내 오브젝트의 포즈를 측정한 제1 측정값을 획득할 수 있다. 여기서 오브젝트는 마커(marker)를 포함할 수 있다. 또한 오브젝트의 포즈는, 오브젝트의 위치 및 방향 중 적어 도 하나를 포함할 수 있다. 또한 제1 측정 값은, 공간 센서가 오브젝트의 위치 및 방향 중 적어도 하나를 측정하여 산출한 값을 의미 할 수 있다. 한편 공간 센서는 복수의 공간 센서를 포함할 수 있으며, 제1 측정 값은 복수의 공간 센서에서 각각 측정 한 복수의 측정 값을 조합하여 산출될 수 있다. 한편 정밀 센서는 센서 시스템을 구성하지 않는 것으로, 공간 내 오브젝트의 포즈를 측정한 측정값을 획득 할 수 있다. 정밀 센서는 광학식 센서, 기계식 센서 및 자기장 센서 중 적어도 하나일 수 있다. 또한 정밀 센서는 공간 센서이 비하여, 더욱 정밀한 측정이 가능하여 공간 내 오브젝트의 포즈를 더욱 정밀하게 측정한 측정 값을 획득할 수 있다. 정밀 센서는 공간 내 오브젝트의 포즈를 측정한 제2 측정값을 획득할 수 있다. 여기서 제2 측정 값은, 정밀 센서가 오브젝트의 위치 및 방향 중 적어도 하나를 측정하여 산출한 값을 의 미할 수 있다. 메모리는 모델 저장부 및 데이터베이스 등을 포함할 수 있다. 모델 저장부는 트레이닝 중인 또는 트레이닝 된 모델(또는 인공 신경망, 231a)을 저장하며, 트레이닝을 통 하여 모델이 업데이트되면 업데이트 된 모델을 저장할 수 있다. 도 3에 도시된 인공 신경망(231a)은 복수의 은닉층을 포함하는 인공 신경망의 하나의 예시일 뿐이며, 본 발명의 인공 신경망이 이에 한정되는 것은 아니다. 인공 신경망(231a)은 하드웨어, 소프트웨어 또는 하드웨어와 소프트웨어의 조합으로 구현될 수 있다. 인공 신경 망(231a)의 일부 또는 전부가 소프트웨어로 구현되는 경우, 인공 신경망(231a)을 구성하는 하나 이상의 명령어 는 메모리에 저장될 수 있다. 데이터베이스는 모델 학습을 위하여 이용되는 학습 데이터(또는 훈련 데이터), 모델의 학습 히스토리 등을 저장한다. 프로세서는 학습 장치의 전반적인 동작을 제어할 수 있다. 한편 머신 러닝(machine learning)은 인공지능의 한 분야로, 컴퓨터에 명시적인 프로그램 없이 배울 수 있는 능 력을 부여하는 연구 분야이다. 구체적으로 머신 러닝은, 경험적 데이터를 기반으로 학습을 하고 예측을 수행하고 스스로의 성능을 향상시키는 시스템과 이를 위한 알고리즘을 연구하고 구축하는 기술이라 할 수 있다. 머신 러닝의 알고리즘들은 엄격하게 정해진 정적인 프로그램 명령들을 수행하는 것이라기보다, 입력 데이터를 기반으로 예측이나 결정을 이끌어내기 위해 특정한 모델을 구축하는 방식을 취한다. 용어 ‘머신 러닝’은 용어 ‘기계 학습’과 혼용되어 사용될 수 있다. 인공신경망은 생물학적 뉴런의 동작원리와 뉴런간의 연결 관계를 모델링한 것으로 노드(node) 또는 처리 요소 (processing element)라고 하는 다수의 뉴런들이 레이어(layer) 구조의 형태로 연결된 정보처리 시스템이다. 인공 신경망은 일반적으로 다음의 세가지 인자, 즉 다른 레이어의 뉴런들 사이의 연결 패턴 연결의 가 중치를 갱신하는 학습 과정 이전 레이어로부터 수신되는 입력에 대한 가중 합으로부터 출력값을 생성하는 활성화 함수에 의해 정의될 수 있다. 인공 신경망은, DNN(Deep Neural Network), RNN(Recurrent Neural Network), BRDNN(Bidirectional Recurrent Deep Neural Network), MLP(Multilayer Perceptron), CNN(Convolutional Neural Network)와 같은 방식의 네트 워크 모델들을 포함할 수 있으나, 이에 한정되지 않는다. 인공신경망은 계층 수에 따라 단층 신경망(Single-Layer Neural Networks)과 다층 신경망(Multi-Layer Neural Networks)으로 구분된다. 일반적인 단층 신경망은, 입력층과 출력층으로 구성된다. 또한 일반적인 다층 신경망은 입력층(Input Layer)과 하나 이상의 은닉층(Hidden Layer), 출력층(Output Layer)으로 구성된다. 입력층은 외부의 자료들을 받아들이는 층으로서, 입력층의 뉴런 수는 입력되는 변수의 수와 동일하며, 은닉층은 입력층과 출력층 사이에 위치하며 입력층으로부터 신호를 받아 특성을 추출하여 출력층으로 전달한다. 출력층은 은닉층으로부터 신호를 받고, 수신한 신호에 기반한 출력 값을 출력한다. 뉴런간의 입력신호는 각각의 연결강도 (가중치)와 곱해진 후 합산되며 이 합이 뉴런의 임계치보다 크면 뉴런이 활성화되어 활성화 함수를 통하여 획득 한 출력값을 출력한다. 한편 입력층과 출력 층 사이에 복수의 은닉층을 포함하는 심층 신경망은, 기계 학습 기술의 한 종류인 딥 러닝 을 구현하는 대표적인 인공 신경망일 수 있다. 인공 신경망은 훈련 데이터(training data)를 이용하여 학습(training)될 수 있다. 여기서 학습이란, 입력 데이 터를 분류(classification)하거나 회귀분석(regression)하거나 군집화(clustering)하는 등의 목적을 달성하기 위하여, 학습 데이터를 이용하여 인공 신경망의 파라미터(parameter)를 결정하는 과정을 의미할 수 있다. 인공 신경망의 파라미터의 대표적인 예시로써, 시냅스에 부여되는 가중치(weight)나 뉴런에 적용되는 편향(bias)을 들 수 있다. 한편 인공 신경망의 학습 방식 중 지도 학습에 대하여 설명한다. 지도 학습은 훈련 데이터로부터 하나의 함수를 유추해내기 위한 기계 학습의 한 방법이다. 지도 학습에서는, 훈련 데이터에 대한 레이블(label)이 주어진 상태에서 인공 신경망을 학습시킨다. 여기서 레이블이란, 훈련 데이터가 인공 신경망에 입력되는 경우 인공 신경망이 추론해 내야 하는 정답(또는 결 과 값)을 의미할 수 있다. 본 명세서에서는 훈련 데이터가 입력되는 경우 인공 신경망이 추론해 내야 하는 정답(또는 결과값)을 레이블 또 는 레이블링 데이터(labeling data)이라 명칭 한다. 또한 본 명세서에서는, 인공 신경망의 학습을 위하여 훈련 데이터에 레이블을 설정하는 것을, 훈련 데이터에 레 이블링 데이터를 레이블링(labeling) 한다고 명칭 한다. 이 경우 훈련 데이터와 훈련 데이터에 대응하는 레이블)은 하나의 트레이닝 셋(training set)을 구성하고, 인공 신경망에는 트레이닝 셋의 형태로 입력될 수 있다. 인공 신경망은 훈련 데이터와 레이블링 데이터를 이용하여, 훈련 데이터와 레이블링 데이터의 연관 관계에 대한 함수를 유추할 수 있다. 그리고, 인공 신경망에서 유추된 함수에 대한 평가를 통해 인공 신경망의 파라미터가결정(최적화)될 수 있다. 프로세서는 훈련 데이터 또는 트레이닝 셋(training set)을 이용하여 인공 신경망(231a)을 훈련(training, 또는 학습)시킬 수 있다. 구체적으로 프로세서는 다양한 학습 기법을 이용하여 인공 신경망(231a)을 반복적으로 학습시킴으로써, 인 공 신경망(231a)의 최적화된 모델 파라미터들을 결정할 수 있다 본 명세서에서는 훈련 데이터를 이용하여 학습됨으로써 파라미터가 결정된 인공 신경망을 학습 모델, 학습된 모 델(a trained model) 또는 교정 모델이라 칭할 수 있다. 전원공급부는 프로세서의 제어 하에서, 외부의 전원, 내부의 전원을 인가 받아 학습 장치에 포 함된 각 구성요소들에 전원을 공급할 수 있다. 도 4 및 도 5는 본 발명의 실시 예에 따른, 인공 신경망의 트레이닝 방법을 설명하기 위한 도면이다. 도 5에서 A 측정 값은 공간 센서가 오브젝트를 측정한 측정 값을 의미할 수 있으며, B 측정 값은 정밀 센 서가 오브젝트를 측정한 측정 값을 의미할 수 있다. 프로세서는 공간 센서의 포즈를 측정한 측정 값, 제1 측정 값 및 제1 측정 값에 대응하는 제2 측정 값을 이용하여 인공 신경망을 트레이닝 할 수 있다. 여기서 공간 센서의 포즈를 측정한 측정 값은, 공간 센서의 위치(x, y, z) 및 방향(회전)(qx, qy, qz, rw)을 측정하여 산출한 값을 의미할 수 있다. 또한 공간 센서의 포즈는 복수의 공간 센서(210a, 210b) 간의 상대적인 포즈일 수 있다. 구체적으로, 복수의 공간 센서(210a, 210b) 각각은 다른 공간 센서를 촬영할 수 있다. 예를 들어 제1 공간 센서 (210a)는 제2 공간 센서(210b)를 촬영할 수 있으며, 제2 공간 센서(210b)는 제1 공간 센서(210a)를 촬영할 수 있다. 이에 따라 제1 공간 센서(210a)에서 본 제2 공간 센서(210b)의 상대적인 포즈를 측정한 값(410b) 및 제2 공간 센서(210b)에서 본 제1 공간 센서(210a)의 상대적인 포즈(410a)를 측정한 값이 획득될 수 있다. 한편 공간 센서(210a, 210b)는 공간 내 오브젝트의 포즈를 측정한 제1 측정 값을 획득할 수 있다. 구체적으로 공간 센서(210a, 210b)는, 제1 공간 센서(210a)가 오브젝트를 촬영한 영상 및 제2 공간 센서(210b) 가 오브젝트를 촬영한 영상을 이용하여 공간 내 오브젝트의 포즈(위치 및 방향 중 적어도 하나)를 측정한 제1 측정 값을 획득할 수 있다. 한편 정밀 센서는 공간 내 오브젝트의 포즈를 측정한 제2 측정 값을 획득할 수 있다. 정밀 센서에 의한 오브젝트의 포즈 측정은 측정 공간 내에서 수행될 수 있다. 한편 프로세서는 공간 센서의 포즈의 측정 값 및 제1 측정 값을 입력으로, 제2 측정 값을 출력으로 이용하 여 인공 신경망을 트레이닝 할 수 있다. 즉 인공 신경망의 훈련 데이터는 공간 센서의 포즈의 측정 값 및 제1 측정 값일 수 있다. 또한 인공 신경망이 추론해 내야 하는 정답(또는 결과 값)은 제2 측정 값일 수 있다. 그리고 프로세서는 공간 센서의 포즈의 측정 값 및 제1 측정 값에 레이블링 데이터(제2 측정 값)를 레이블 링 하여 인공 신경망에 제공할 수 있다. 이 경우 인공 신경망은 훈련 데이터와 레이블링 데이터를 이용하여, 훈련 데이터와 레이블링 데이터의 연관 관 계에 대한 함수를 유추할 수 있다. 그리고, 인공 신경망에서 유추된 함수에 대한 평가를 통해 인공 신경망의 파 라미터(가중치(weight), 편향(bias) 등)가 결정(최적화)될 수 있다. 한편 정밀 센서에서 측정된 제2 측정 값은, 정밀 센서에서 측정된 제2 측정 값을 공간 센서 상에서의 측정 값으 로 변환한 측정 값을 포함할 수 있다. 즉 변환된 제2 측정 값은, 공간 센서의 좌표와 정밀 센서의 좌표 간의 관계에 기초하여, 정밀 센서의 측정 값을 공간 센서의 좌표 공간으로 좌표 변환한 측정 값을 의미할 수 있다. 이 경우 프로세서는 공간 센서의 포즈의 측정 값 및 제1 측정 값을 입력으로, 상기 변환된 제2 측정 값을 출력으로 이용하여 인공 신경망을 트레이닝 할 수 있다. 즉 인공 신경망의 훈련 데이터는 공간 센서의 포즈의 측정 값 및 제1 측정 값일 수 있다. 또한 인공 신경망이 추론해 내야 하는 정답(또는 결과 값)은 변환된 제2 측정 값일 수 있다. 한편 인공 신경망을 트레이닝 하는 경우, 제1 측정 값에 제1 측정 값에 대응하는 제2 측정 값이 레이블링 될 수 있다. 여기서 제1 측정 값에 대응하는 제2 측정 값이란, 특정 포즈의 오브젝트를 공간 센서에서 촬영하여 제1 측정 값 을 획득한 경우, 상기 특정 포즈(동일한 포즈)의 오브젝트를 촬영하여 획득한 정밀 센서의 측정 값일 수 있다. 즉 프로세서는, 공간 센서의 포즈의 측정 값 및 공간 센서에서 오브젝트의 특정 포즈를 측정한 제1측정값을 입 력으로, 그리고 정밀 센서에서 오브젝트의 특정 포즈(동일한 포즈)를 측정한 제2 측정값을 출력으로 이용하여, 인공 신경망을 트레이닝 할 수 있다. 또한 인공 신경망을 트레이닝 하는 경우, 제1 측정 값 및 제1 측정 값에 대응하는 공간 센서의 포즈의 측정 값 이 훈련 데이터로 사용될 수 있다. 여기서 제1 측정 값에 대응하는 공간 센서의 포즈의 측정 값이란, 공간 센서가 오브젝트를 촬영하여 제1 측정 값을 획득했을 때 공간 센서의 포즈를 산출한 값을 의미할 수 있다. 즉 동일 시점에서의, 공간 센서의 포즈, 공간 센서에서 관측한 오브젝트의 포즈, 정밀 센서에서 관측한 오브젝 트의 포즈가 인공 신경망에 제공되어 트레이닝이 수행될 수 있다. 도 6은 다양한 훈련데이터를 확보하여 인공신경망을 트레이닝 하는 방법을 설명하기 위한 도면이다. 프로세서는, 공간 센서의 동일한 포즈에 대하여, 오브젝트의 포즈를 다양하게 변경하면서 획득한 제1 측정값 및 상기 오브젝트의 포즈를 다양하게 변경하면서 획득한 제1 측정값에 대응하는 제2 측정값을 이용하여 인공 신경 망을 트레이닝 할 수 있다. 구체적으로 프로세서는 공간 센서의 특정 포즈에서, 오브젝트의 제1 포즈를 측정한 제1 측정 값 및 제2 측정 값 을 획득할 수 있다. 이 경우 프로세서는 특정 포즈의 측정 값, 제1 측정 값 및 제2 측정 값을 이용하여 인공 신 경망을 트레이닝 할 수 있다. 또한 프로세서는 공간 센서의 동일한 포즈(상기 특정 포즈)에서, 오브젝트의 제2 포즈를 측정한 제1 측정 값 및 제2 측정 값을 획득할 수 있다. 이 경우 프로세서는 특정 포즈의 측정 값, 제1 측정 값 및 제2 측정 값을 이용 하여 인공 신경망을 트레이닝 할 수 있다. 이와 같은 방식으로 프로세서는, 공간 센서의 동일한 포즈에 대하여, 측정 공간 내 다양한 위치에서 획득한 제1 측정 값 및 제2 측정 값을 이용하여 인공 신경망을 트레이닝 할 수 있다. 한편 프로세서는, 공간 센서의 복수의 포즈의 측정 값, 복수의 포즈를 가지는 공간 센서가 오브젝트를 측정한 제1 측정값 및 제1 측정값에 대응하는 제2 측정값을 이용하여 인공 신경망을 트레이닝 할 수 있다. 구체적으로 프로세서는 공간 센서의 제1 포즈에서, 오브젝트의 제1 포즈를 측정한 제1 측정 값 및 제2 측정 값 을 획득할 수 있다. 이 경우 프로세서는 공간 센서의 제1 포즈의 측정 값, 오브젝트의 제1 포즈를 측정한 제1 측정 값 및 제2 측정 값을 이용하여 인공 신경망을 트레이닝 할 수 있다. 또한 프로세서는 공간 센서의 제2 포즈에서, 오브젝트의 제1 포즈를 측정한 제1 측정 값 및 제2 측정 값을 획득 할 수 있다. 이 경우 프로세서는 공간 센서의 제2 포즈의 측정 값, 오브젝트의 제1 측정 값 및 제2 측정 값을 이용하여 인공 신경망을 트레이닝 할 수 있다. 이와 같은 방식으로 프로세서는, 공간 센서의 포즈를 변경시키면서, 측정 공간 내 다양한 측정 지점에서 측정한 측정 값을 이용하여 인공 신경망을 트레이닝 할 수 있다. 예를 들어 프로세서는, 공간 센서의 제1 포즈에 대하여, 오브젝트의 포즈를 다양하게 변경하면서 획득한 제1 측 정값 및 상기 오브젝트의 포즈를 다양하게 변경하면서 획득한 제1 측정값에 대응하는 제2 측정값을 이용하여 인 공 신경망을 트레이닝 할 수 있다. 그리고 나서 프로세서는, 공간 센서의 제2 포즈에 대하여, 오브젝트의 포즈를 다양하게 변경하면서 획득한 제1 측정값 및 상기 오브젝트의 포즈를 다양하게 변경하면서 획득한 제1 측정값에 대응하는 제2 측정값을 이용하여 인공 신경망을 트레이닝 할 수 있다. 이와 같이 인공 신경망은 다양한 훈련 데이터를 이용하여, 제1 측정 값과 제2 측정 값(변환된 제2 측정 값) 간 의 차이가 줄어들도록 트레이닝 될 수 있다. 그리고 제1 측정 값과 제2 측정 값(변환된 제2 측정 값) 간의 차이가 기 설정된 값보다 작아지면, 프로세서는 인공 신경망의 트레이닝을 중단할 수 있다. 한편 이와 같이 트레이닝 된 인공 신경망을 교정 모델이라 명칭할 수 있다. 도 7은 본 발명의 실시 예에 따른, 교정 모델이 탑재된 센서 시스템을 설명하기 위한 도면이다. 센서 시스템은, 공간 센서, 통신부, 메모리, 전원 공급부 및 프로세서를 포함할 수 있다. 공간 센서는 센서 시스템이 실제 설치된 환경에서, 센서 시스템이 설치된 공간 내 오브젝트의 포즈를 측정한 측정 값을 획득할 수 있다. 도 3에서 설명한 공간 센서에 대한 설명은, 센서 시스템의 공간 센서에도 적용될 수 있다. 한편 센서 시스템에 포함되는 공간 센서는, 학습 장치에 포함되는 공간 센서와 상이한 것으로, 다른 공간 센서 또는 VR 공간 센서라 명칭 될 수 있다. 한편 센서 시스템에 포함되는 공간 센서는 공간 내 오브젝트의 포즈를 측정한 제3 측정값을 획득할 수 있다. 여기서 공간은, 센서 시스템이 실제로 설치된 공간을 의미하는 것으로, 다른 공간이라 명칭될 수 있다. 한편 트레이닝 된 인공 신경망(731a), 즉 교정 모델은, 하드웨어, 소프트웨어 또는 하드웨어와 소프트웨어의 조 합으로 구현될 수 있다. 인공 신경망(731a)의 일부 또는 전부가 소프트웨어로 구현되는 경우, 인공 신경망 (731a)을 구성하는 하나 이상의 명령어는 메모리에 저장될 수 있다. 통신부는 VR(Virtual Reality) 기기와 통신하여, 오브젝트의 포즈에 대한 정보를 VR 기기에 전송할 수 있 다. 프로세서는 센서 시스템의 전반적인 동작을 제어할 수 있다. 도 8은 본 발명의 실시 예에 따른, 센서 시스템의 동작 방법을 설명하기 위한 도면이다. 도 8에서 A 측정 값은 공간 센서가 오브젝트를 측정한 측정 값을 의미할 수 있다. 프로세서는 센서 시스템에 포함되는 공간 센서의 포즈를 측정한 측정 값을 획득할 수 있다. 여기서 공간 센서의 포즈를 측정한 측정 값은, 공간 센서의 위치(x, y, z) 및 방향(회전)(qx, qy, qz, rw)을 측정하여 산출한 값을 의미할 수 있다. 또한 공간 센서의 포즈는, 공간 센서에 포함되는 복수의 공간 센서 간의 상대적인 포즈일 수 있다. 한편 센서 시스템에 포함되는 공간 센서는 센서 시스템이 설치된 공간 내 오브젝트의 포즈를 측 정한 제3 측정 값을 획득할 수 있다. 구체적으로 공간 센서는, 제1 공간 센서가 오브젝트를 촬영한 영상 및 제2 공간 센서가 오브젝트를 촬영한 영상을 이용하여 공간 내 오브젝트의 포즈(위치 및 방향 중 적어도 하나)를 측정한 제3 측정 값을 획득할 수 있 다. 한편 프로세서는, 공간 센서의 포즈의 측정 값 및 제3 측정 값을 이용하여 제3 측정 값을 보정한 제4 측정 값(보정 값)을 획득할 수 있다. 구체적으로, 프로세서는 공간 센서의 포즈의 측정 값 및 제3 측정값을 트레이닝 된 인공 신경망(교정 모델)에 입력할 수 있다. 이 경우 트레이닝 된 인공 신경망(교정 모델)은, 내부적으로 설정되어 있는 파라미터 에 따라, 제3 측정값을 보정한 제4 측정값을 출력할 수 있다. 이에 따라 프로세서는 공간 센서가 오 브젝트의 포즈를 측정한 제3 측정 값을 보정한 제4 측정 값을 획득할 수 있다. 한편 훈련 데이터로 오브젝트의 다양한 포즈에 대한 제1 측정 값 및 제2 측정 값이 사용되었다. 따라서 트레이 닝 된 인공 신경망(교정 모델)은, 제3 측정 값을 오브젝트의 다양한 포즈에 따라 보정한 제4 측정 값을 추론할 수 있다. 또한 훈련 데이터로 공간 센서의 다양한 포즈에 대한 제1 측정 값 및 제2 측정 값이 사용되었다. 따라서 트레이닝 된 인공 신경망(교정 모델)은, 제3 측정 값을 공간 센서의 다양한 포즈에 따라 보정한 제4 측정 값을 추론할 수 있다. 한편 정밀 센서에 의해 측정된 제2 측정 값은 공간 센서에 의해 측정된 제1 측정 값에 비하여 더욱 정밀한 값이다. 그리고 인공 신경망은 제1 측정 값을 입력 값으로 제2 측정 값을 출력 값으로 하여 제1 측정 값 과 제2 측정 값 사이의 차이가 작아지도록 트레이닝 되었다. 따라서 트레이닝 된 트레이닝 된 인공 신경망(교정 모델)은 제3 측정 값을 이용하여, 제3 측정 값보다 더욱 정 밀한 값인 제4 측정 값을 추론해낼 수 있다. 한편 프로세서는 획득한 제4 측정 값을 VR 기기에 전송할 수 있다. 이와 같이 본 발명은, 센서 시스템이 설치 될 때마다 교정을 수행할 필요 없이, 공간 센서에서 측정한 제3 측정 값만 있으면 제3 측정 값을 더욱 정밀하게 보정한 제4 측정 값을 획득할 수 있다. 따라서 본 발명에 따르면, 센서 시스템의 설치 시 설치 기사가 출동하거나, 개인이 직접 교정 도구나 정밀 센서 를 가지고 교정을 할 필요가 없다. 또한 본 발명에 따르면, 시간이 흐름에 따라 공간 센서의 포즈가 변경되는 경우에도 교정 모델이 공간 센서의 포즈 변경을 반영하여 보정을 하기 때문에, 주기적으로 설치 기사가 출동하거나 개인이 직접 교정을 할 필요가 없다는 장점이 있다. 또한 센서 시스템의 판매자 입장에서는, 센서 시스템을 설치해 줄 때 마다 사람을 파견하여 교정을 해줄 필요 없이, 교정 모델을 탑재하여 제품을 판매하기만 하면 되는 장점이 있다. 또한 본 발명에 따르면, 글로벌한 교정 모델을 생성하여 동일한 제품들에 탑재만 하면 되기 때문에, 넓은 측정 공간, 측정 공간 내 다양한 지점에서 훈련 데이터를 충분히 확보한 후 교정 모델을 생성할 수 있다. 따라서 비용 및 노력이 현격히 줄어들면서도, 보정의 정확도를 향상시킬 수 있는 장점이 있다. 또한, 측정 공간 내 메인 영역뿐만 아니라 측정 공간 내 다양한 지점에서 보정의 정확도를 향상시킬 수 있는 장점이 있다. 전술한 본 발명은, 프로그램이 기록된 매체에 컴퓨터가 읽을 수 있는 코드로서 구현하는 것이 가능하다. 컴퓨터 가 읽을 수 있는 매체는, 컴퓨터 시스템에 의하여 읽혀질 수 있는 데이터가 저장되는 모든 종류의 기록장치를 포함한다. 컴퓨터가 읽을 수 있는 매체의 예로는, HDD(Hard Disk Drive), SSD(Solid State Disk), SDD(Silicon Disk Drive), ROM, RAM, CD-ROM, 자기 테이프, 플로피 디스크, 광 데이터 저장 장치 등이 있다. 또한, 상기 컴 퓨터는 서버의 프로세서를 포함할 수도 있다. 따라서, 상기의 상세한 설명은 모든 면에서 제한적으로 해석 되어서는 아니 되고 예시적인 것으로 고려되어야 한다. 본 발명의 범위는 첨부된 청구항의 합리적 해석에 의해 결정되어야 하고, 본 발명의 등가적 범위 내에서의 모든 변경은 본 발명의 범위에 포함된다."}
{"patent_id": "10-2019-0044508", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1 및 도 2는 종래의 문제점을 설명하기 위한 도면이다. 도 3은 본 발명의 실시 예에 따른, 인공 신경망의 학습 장치의 구성을 나타낸 블록도이다. 도 4 및 도 5는 본 발명의 실시 예에 따른, 인공 신경망의 트레이닝 방법을 설명하기 위한 도면이다. 도 6은 다양한 훈련데이터를 확보하여 인공신경망을 트레이닝 하는 방법을 설명하기 위한 도면이다. 도 7은 본 발명의 실시 예에 따른, 교정 모델이 탑재된 센서 시스템을 설명하기 위한 도면이다. 도 8은 본 발명의 실시 예에 따른, 센서 시스템의 동작 방법을 설명하기 위한 도면이다."}
