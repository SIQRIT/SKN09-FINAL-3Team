{"patent_id": "10-2022-0042470", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0143495", "출원번호": "10-2022-0042470", "발명의 명칭": "딥 러닝을 이용한 음성 기반의 사용자 감성분석 방법", "출원인": "주식회사 히포티앤씨", "발명자": "정태명"}}
{"patent_id": "10-2022-0042470", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "사용자가 입력한 음성 데이터를 전송받는 단계;상기 음성 데이터를 전처리하여 세기, 높낮이 및 맵시에 대한 정보를 포함하는 음성 특징 데이터를 추출하는 단계;제1 인공지능을 이용하여 상기 음성 데이터로부터 문자를 추출하는 문자 데이터 추출 단계; 및제2 인공지능을 이용하여 상기 음성 특징 데이터 및 상기 문자 데이터를 기반으로 분석하여 감성을 특정하는 감성 특정 단계를 포함하는 딥 러닝을 이용한 음성 기반의 사용자 감성분석 방법."}
{"patent_id": "10-2022-0042470", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1 항에 있어서,상기 음성 특징 데이터를 추출하는 단계는 상기 음성 데이터로부터 시간에 따른 주파수의 분포를 추출하는 것을특징으로 하는 딥 러닝을 이용한 음성 기반의 사용자 감성분석 방법."}
{"patent_id": "10-2022-0042470", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2 항에 있어서,상기 음성 특징 데이터를 추출하는 단계는,상기 주파수 분포를 mel 스케일로 매핑하여 mel 스펙토그램(spectogram)으로 변환하여 제1 음성 특성 데이터를추출하는 단계; 및상기 주파수 분포를 OpenSMILE 툴킷으로 제2 음성 특징 데이터를 추출하는 단계를 포함하는 딥 러닝을 이용한음성 기반의 사용자 감성분석 방법."}
{"patent_id": "10-2022-0042470", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3 항에 있어서,상기 제1 인공지능은 STT(Speech to Text) 기반의 딥 러닝 모델인 것을 특징으로 하는 딥 러닝을 이용한 음성기반의 사용자 감성분석 방법."}
{"patent_id": "10-2022-0042470", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4 항에 있어서,상기 제1 인공지능은 wav2vec을 기반으로 상기 문자 데이터를 추출하는 딥 러닝을 이용한 음성 기반의 사용자감성분석 방법."}
{"patent_id": "10-2022-0042470", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5 항에 있어서,상기 감성 특정 단계는, 상기 제2 인공지능이 상기 제1 음성 특성 데이터, 상기 제2 음성 특성 데이터 및 상기문자 데이터를 기반으로 감성을 특정하여 수행되는 딥 러닝을 이용한 음성 기반의 사용자 감성분석 방법."}
{"patent_id": "10-2022-0042470", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6 항에 있어서,상기 감성 특정 단계에서 특정된 상기 특정 감성을 기반으로 상기 사용자에게 전달하는 메시지를 생성하는 메시공개특허 10-2023-0143495-3-지 생성 단계를 더 포함하는 딥 러닝을 이용한 음성 기반의 사용자 감성분석 방법."}
{"patent_id": "10-2022-0042470", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7 항에 있어서,상기 메시지 생성 단계는 챗봇을 이용하여 수행되는 딥 러닝을 이용한 음성 기반의 사용자 감성분석 방법."}
{"patent_id": "10-2022-0042470", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8 항에 있어서,상기 메시지 생성 단계는 상기 특정 감성 및 상기 문자 데이터를 기반으로 정신 질환 관리를 위한 상담 내용을생성하는 딥 러닝을 이용한 음성 기반의 사용자 감성분석 방법."}
{"patent_id": "10-2022-0042470", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9 항에 있어서,상기 메시지 생성 단계는,상기 정신 질환 관리를 위한 상담 내용은 자폐증 및 우울증에 대응하여 상기 상담 내용을 생성하는 딥 러닝을이용한 음성 기반의 사용자 감성분석 방법."}
{"patent_id": "10-2022-0042470", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은, 사용자가 입력한 음성 데이터를 전송받는 단계, 음성 데이터를 전처리하여 세기, 높낮이 및 맵시에 대한 정보를 포함하는 음성 특징 데이터를 추출하는 단계, 제1 인공지능을 이용하여 음성 데이터로부터 문자를 추출하는 문자 데이터 추출 단계 및 제2 인공지능을 이용하여 음성 특징 데이터 및 문자 데이터를 기반으로 분석 하여 감성을 특정하는 감성 특정 단계를 포함하는 딥 러닝을 이용한 음성 기반의 사용자 감성분석 방법에 관한 것이다. 본 발명에 따른 딥 러닝을 이용한 음성 기반의 사용자 감성분석 방법은 텍스트의 의미 및 음성 특징을 기반으로 사용자의 감성을 보다 정확하게 판단할 수 있어, 심리적 치료의 효과를 상승시킬 수 있다."}
{"patent_id": "10-2022-0042470", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 딥 러닝을 이용한 음성 기반의 사용자 감성분석 방법에 관한 것이다."}
{"patent_id": "10-2022-0042470", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "최근 인공지능 기술이 급속도로 발전함에 따라 전문가에 의한 정신 건강 관련 상담에도 활발하게 적용이 이루어 지고 있다. 이와 관련하여 챗봇(chatbot)을 이용하여 텍스트 기반의 정보를 입력받고, 이를 통하여 감정을 추출 하고 상담을 위한 내용을 생성하여 전달하는 방식이 가장 많이 활용되고 있다. 이러한 종래기술과 관련하여 대한민국 공개특허 제10-2021-0061126 호가 개시되어 있다. 그러나 이러한 텍스트 기반의 챗봇은 문장의 의미를 기준으로 의미를 해석하고 사용자의 감성을 추축하고 있으나, 실제 사람의 감성을 추측하는 것에는 한계가 있었다. 선행기술문헌 특허문헌 (특허문헌 0001) 대한민국 공개특허 제10-2021-0061126 호"}
{"patent_id": "10-2022-0042470", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 종래의 상담 서비스에서 활용되는 사람의 감성을 판단하는데 한계가 있는 문제점을 해결하기 위한 딥 러닝을 이용한 음성 기반의 사용자 감성분석 방법을 제공하는 것에 그 목적이 있다."}
{"patent_id": "10-2022-0042470", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기 과제의 해결 수단으로서, 사용자가 입력한 음성 데이터를 전송받는 단계, 음성 데이터를 전처리하여 세기, 높낮이 및 맵시에 대한 정보를 포함하는 음성 특징 데이터를 추출하는 단계, 제1 인공지능을 이용하여 음성 데 이터로부터 문자를 추출하는 문자 데이터 추출 단계 및 제2 인공지능을 이용하여 음성 특징 데이터 및 문자 데이터를 기반으로 분석하여 감성을 특정하는 감성 특정 단계를 포함하는 딥 러닝을 이용한 음성 기반의 사용자 감성분석 방법이 제공될 수 있다. 한편, 음성 특징 데이터를 추출하는 단계는 음성 데이터로부터 시간에 따른 주파수의 분포를 추출할 수 있다. 나아가, 음성 특징 데이터를 추출하는 단계는, 주파수 분포를 mel 스케일로 매핑하여 mel 스펙토그램 (spectogram)으로 변환하여 제1 음성 특성 데이터를 추출하는 단계 및 주파수 분포를 OpenSMILE 툴킷으로 제2 음성 특징 데이터를 추출하는 단계를 포함할 수 있다. 한편, 제1 인공지능은 STT(Speech to Text) 기반의 딥 러닝 모델일 수 있다. 또한, 제1 인공지능은 wav2vec을 기반으로 문자 데이터를 추출할 수 있다. 한편, 감성 특정 단계는 제2 인공지능이 제1 음성 특성 데이터, 제2 음성 특성 데이터 및 문자 데이터를 기반으 로 감성을 특정하여 수행될 수 있다. 한편, 감성 특정 단계에서 특정된 특정 감성을 기반으로 사용자에게 전달하는 메시지를 생성하는 메시지 생성 단계를 더 포함할 수 있다. 한편, 메시지 생성 단계는 챗봇을 이용하여 수행될 수 있다. 또한, 메시지 생성 단계는 특정 감성 및 문자 데이터를 기반으로 정신 질환 관리를 위한 상담 내용을 생성할 수 있다. 한편, 메시지 생성 단계는 정신 질환 관리를 위한 상담 내용은 자폐증 및 우울증에 대응하여 상담 내용을 생성 할 수 있다."}
{"patent_id": "10-2022-0042470", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명에 따른 딥 러닝을 이용한 음성 기반의 사용자 감성분석 방법은 텍스트의 의미 및 음성 특징을 기반으로 사용자의 감성을 보다 정확하게 판단할 수 있어, 심리적 치료의 효과를 상승시킬 수 있다."}
{"patent_id": "10-2022-0042470", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 본 발명의 실시 예에 따른 딥 러닝을 이용한 음성 기반의 사용자 감성분석 방법에 대하여, 첨부된 도면을 참조하여 상세히 설명한다. 그리고 이하의 실시예의 설명에서 각각의 구성요소의 명칭은 당업계에서 다른 명칭 으로 호칭될 수 있다. 그러나 이들의 기능적 유사성 및 동일성이 있다면 변형된 실시예를 채용하더라도 균등한 구성으로 볼 수 있다. 또한 각각의 구성요소에 부가된 부호는 설명의 편의를 위하여 기재된다. 그러나 이들 부 호가 기재된 도면상의 도시 내용이 각각의 구성요소를 도면내의 범위로 한정하지 않는다. 마찬가지로 도면상의 구성을 일부 변형한 실시예가 채용되더라도 기능적 유사성 및 동일성이 있다면 균등한 구성으로 볼 수 있다. 또 한 당해 기술 분야의 일반적인 기술자 수준에 비추어 보아, 당연히 포함되어야 할 구성요소로 인정되는 경우, 이에 대하여는 설명을 생략한다. 도 1은 본 발명의 일 실시예에 따른 딥 러닝을 이용한 음성 기반의 사용자 감성분석 방법의 개념도이다. 도 1을 참조하면, 본 발명의 일 실시예에 따른 딥 러닝을 이용한 음성 기반의 사용자 감성분석 방법은 사용자로 부터 입력된 음성 데이터를 근거로 의미와 음성 특성을 추출하고 현재의 감성 상태를 판단할 수 있도록 구성된 다. 이후 판단된 감성 상태는 챗봇이 상담이나 대화를 통한 메시지 생성시 기준이 되는 요소로 활용될 수 있다. 사용자는 널리 보급된 스마트 디바이스를 이용하여 음성을 입력하며, 스마트 디바이스는 서버로 음 성 데이터를 전송하게 된다. 서버에서는 인공지능을 이용하여 최종적으로 현재 사용자의 감성을 판단하고 적절한 메시지를 생성하여 사용자의 스마트 디바이스로 전송할 수 있게 된다. 도 2는 본 발명의 일 실시예에 따른 딥 러닝을 이용한 음성 기반의 사용자 감성분석 방법을 수행하는 시스템의 블록도이다. 도 2를 참조하면, 본 발명에 따른 딥 러닝을 이용한 음성 기반의 사용자 감성분석 방법은 스마트 디바이스 와 서버를 통하여 수행될 수 있다. 스마트 디바이스는 스파트 폰, 스마트 워치, 스마트 패드, PC, 랩톱, PDA 등의 기기를 뜻한다. 다만 스마트 디바이스란 이에 한정하지 않고, 사용자가 음성을 입력할 수 있으며, 디스플레이 기능을 갖고, 또한 외부와 의 통신이 가능한 장치를 뜻한다. 한편, 이러한 스마트 디바이스는 챗봇이 구현되는 어플리케이션 또는 프로그램이 설치될 수 있다. 서버는 데이터베이스부, 전처리부, 제1 인공지능부, 제2 인공지능부 및 챗봇을 포함할 수 있다. 서버는 외부의 스마트 디바이스와 유선 또는 무선으로 통신하여 정보를 송수신할 수 있도록 구성된다. 데이터베이스부는 사용자로부터 전송받은 음성데이터, 그리고 제1 인공지능부 및 제2 인공지능부에 의해 판단된 데이터를 저장할 수 있도록 구성된다. 또한 데이터베이스부는 정신의학에서 진단과 치료에 사 용되는 다양한 정보를 포함할 수 있다. 특히 사용자의 다양한 감정, 예를 들어 편안함, 행복함, 즐거움, 흥분됨, 슬픔, 화남, 두려움, 짜증남, 무력감 등의 감정과 이에 따라 나타나는 음성적인 특징들에 관한 데이터 를 포함할 수 있다. 데이터 베이스에 포함된 정보는 지속적으로 업데이트 될 수 있으며, 제1 인공지능부 및 제2 인공지능부에서 추가적인 학습의 수행시 활용될 수 있다. 전처리부는 사용자로부터 획득된 음성 데이터를 전처리할 수 있도록 구성된다. 전처리부는 음성 데이터로부터 음성 특징을 추출하며, 문자로 변환하기 위한 전처리를 수행할 수 있다. 전 처리부는 사용자로부터 전송받은 음성 데이터에서 세기, 높낮이 및 맵시에 대한 정보를 추출하여 음성 특징 데이터를 생성할 수 있도록 구성된다. 전처리부는 일 예로서, OpenSmile 툴 킷, 푸리에 트랜스폼, mel 스케 일로 변환하기 위한 알고리즘/프로그램을 포함할 수 있다. 한편, 설명하지는 않았으나, 음성 데이터를 분석하기 위해 수행되는 노이즈 제거와 같은 필수적인 전처리를 수행하기 위한 알고리즘/프로그램을 추가로 포함할 수 있 다. 제1 인공지능부는 음성 데이터로부터 문자 데이터를 추출할 수 있도록 구성된다. 제1 인공지능부는 STT(Speech to Text) 기반의 딥러닝 모델을 포함할 수 있다. 제1 인공지능부는 일 예로서 wav2vec을 기반으 로 구성될 수 있다. 이때 제1 인공지능부는 미리 학습된 상태로 이용될 수 있으며, 또한 데이터베이스부 에 저장된 음성 데이터 및 문자 데이터를 기반으로 지속적으로 학습이 진행될 수 있다. 제2 인공지능부는 음성 특징 데이터 및 문자 데이터를 기반으로 사용자의 감성을 판단할 수 있도록 구성된 다. 제2 인공지능부는 제1 인공지능부가 추출한 문자 데이터를 수신하며, 전처리부에서 생성한 음 성 특징 데이터를 수신하여 입력값으로 사용한다. 이때 제2 인공지능부는 미리 학습된 상태로 사용될 수 있 다. 학습 데이터는 동일한 문장에 대하여 다양한 감정 상태에서 발성하는 음성 데이터가 이용될 수 있다. 일 예 로서 사용자가‘괜찮아’라고 음성을 입력했을 때, 사용자의 감정은 ‘짜증남’,‘안도감’,‘화남’,‘슬픔’ 등과 같이 다양한 감정을 수반할 수 있다. 이러한 의미 및 감정을 기반으로 학습 데이터를 생성하고, 실제 발성 한 사용자가 입력한 피드백을 이용하여 반복학습을 수행할 수 있다. 제2 인공지능부의 판단은 말하고자 하는 의미와 현재 감성에 괴리감이 있는 경우 정확한 의도를 파악하기에 용이하다. 일 예로서 자폐증, 우울증과 같이 말하는 내용으로부터 사용자의 현재 감성에 대한 인식이 어려운 경 우에 보다 효과적으로 감성을 파악할 수 있게 된다. 제2 인공지능부 또한 제1 인공지능부와 마찬가지로 사용됨에 따라 사용자에 의한 음성 데이터로부터 지 속적인 학습을 수행하여 감성 판단의 정확도를 향상시킬 수 있게 된다. 챗봇은 제2 인공지능부로부터 획득된 감성판단 결과와 제1 인공지능부에서 추출한 문자데이터를 기 반으로 적절한 메시지를 생성할 수 있도록 구성된다. 생성된 메시지는 패킷으로 스마트 디바이스로 전송될 수 있다. 이후 스마트 디바이스에서는 화면에 대화창으로 표시하거나, 스피커를 이용하여 음성 메시지로 변 환하여 사용자에게 전달될 수 있다. 이하에서는 도 3 내지 도 4를 참조하여, 본 발명에 따른 딥 러닝을 이용한 음성 기반의 사용자 감성분석 방법에 대하여 설명하도록 한다. 도 3은 본 발명의 일 실시예에 따른 딥 러닝을 이용한 음성 기반의 사용자 감성분석 방법의 순서도이며, 도 4는 전처리부의 작동에 대한 개념을 도시한 도면이다. 도 3을 참조하면, 본 발명의 일 실시예에 따른 딥 러닝을 이용한 음성 기반의 사용자 감성분석 방법은 음성 데 이터를 전송받는 단계(S100), 음성 특징 데이터를 추출하는 단계(S200), 문자 데이터 추출 단계(S300) 및 감성 특정 단계(S400)를 포함할 수 있다. 음성 데이터를 전송받는 단계(S100)는 사용자의 음성을 디지털 신호로 전환하여 전송받는 단계에 해당한다. 본 단계는 사용자가 말하는 음성 및 챗봇과 대화하는 과정에서 획득될 수 있다. 본 단계에서 음성 데이터는 스마트 디바이스에 내장된 마이크를 이용하여 획득되거나 또는 PC와 같은 디바이스와 플러그-인 되는 마이크를 이용하 여 획득될 수 있다. 음성 특징 데이터를 추출하는 단계(S200)는 수신된 음성 데이터를 기반으로 전처리를 수행하여 인공지능이 감정 을 판단하기 용이한 상태로 변환하는 단계이다. 음성 특징 데이터를 추출하는 단계는 음성 데이터로부터 소리의 2D wave 형태에서, 푸리에 트랜스폼 및 mel 스케일 변환을 수행하여 제1 음성 특징 데이터를 획득하게 된다. 또 한 음성 데이터의 주파수 분포를 추출하여 제2 음성 특징 데이터를 생성한다. 이때 OpenSMILE 툴 킷과 같은 상 용 프로그램이 사용될 수 있다. 도 4를 참조하면, 사용자로부터 획득된 2D 데이터는 푸리어 트랜스폼을 이용하여 1차로 변환되고, 이후 mel scale로 매핑하여 mel spectrogram으로 변환될 수 있다. 다시 도 1을 참조하면, 문자 데이터 추출 단계(S300)는 음성 데이터로부터 문자 데이터를 추출하는 단계에 해당 한다. 본 단계는 딥 러닝 기반의 제1 인공지능을 이용하여 수행될 수 있다. 제1 인공지능은 STT(Speech to Text) 기반의 딥 러닝 모델일 수 있다. 감성 특정 단계(S400)는 제1 음성 특징 데이터, 제2 음성 특징 데이터와 문자 테이터를 기반으로 사용자의 감성 을 특정하는 단계이다. 본 단계에서는 딥 러닝된 제2 인공지능을 이용하여 수행될 수 있다. 전술한 바와 같이, 본 발명에 따른 일 실시예인 딥 러닝을 이용한 음성 기반의 사용자 감성분석 방법은 사용자 의 음성으로부터 발성에 의해 전달되는 의미와 음성 특징에 의한 정보를 기반으로 감정을 추출하여 정신질환의 진단 및 치료, 그리고 상담시에 적절한 솔루션을 선택할 수 있는 기준으로 활용될 수 있다. 이하에서는 도 5 및 도 6을 참조하여 본 발명의 다른 실시예에 따른 딥 러닝을 이용한 음성 기반의 사용자 감성 분석 방법에 대하여 설명하도록 한다. 본 실시예에서는 전술한 실시예와 동일한 단계를 포함할 수 있으며, 이러 한 각 단계에 대하여는 중복기재를 피하기 위해 설명을 생략하고 차이가 있는 단계에 대하여 상세히 설명하도록 한다. 도 5는 본 발명의 다른 실시예에 따른 딥 러닝을 이용한 음성 기반의 사용자 감성분석 방법의 순서도이며, 도 6 은 본 발명의 일 실시예에 따른 딥 러닝을 이용한 음성 기반의 사용자 감성분석 방법을 이용하여 구현되는 어플 리케이션의 화면의 예시이다. 본 발명의 다른 실시예에 따른 딥 러닝을 이용한 음성 기반의 사용자 감성분석 방법이 어플리케이션에 의해 사 용자와 상호작용할 수 있도록 구성된다. 도 5를 참조하면, 본 실시예에서는 문자 시현 단계(S500), 감성 특정 결과 제공 단계(S500) 및 메시지 생성 단 계(S600)를 더 포함할 수 있다. 본 실시예에서 문자 시현 단계(S500), 감성 특정 결과 제공 단계(S500) 및 메시 지 생성 단계(S600)는 사용자가 챗봇을 이용하여 대화하는 경우 지속적으로 반복수행될 수 있다. 문자 시현 단계(S500)는 문자 데이터 추출 단계(S300)에서 추출된 문자 데이터를 사용자의 단말기에 시현하는 단계에 해당한다. 이 경우 사용자는 별도의 텍스트를 입력하지 않더라도 음성을 분석하여 추출된 문자 텍스트를 화면상에 시현할 수 있게 된다. 도 6(a)를 참조하면, 사용자가 입력한 음성이 텍스트로 전환되어 단말기의 디스 플레이 상에서 좌측에 치우쳐 시현도고 있다. 감성 특정 결과 제공 단계(S500)는 사용자로부터 적어도 1회 입력된 음성 데이터를 기반으로 판단된 감성에 대 하여 사용자가 인지할 수 있도록 시현하는 단계에 해당한다. 이때 사용자의 감성 특정에 대한 결과는 소정 기준 에 따라 매칭되는 정보를 표현할 수 있도록 구성된다. 일 예로서, 우울감에 대한 수치를 정량화하여 소정 기준 에 따라 분류하여 추가 정보를 시현할 수 있다. 본 단계에서는 도 6(b)를 참조하면, 사용자가 챗봇과 당일 대화 한 내용을 기반으로 사용자의 감정을 특정하고 이를 시현하여 ‘우울한 날’ 과 같이 사용자가 인지하기 쉬운 상태로 분류하여 시현할 수 있다. 또한 도 6(c)와 같이 날짜에 따른 상태와 변화를 판단할 수 있도록 미리 저장된 감정상태 정보를 이용하여 동시 에 소정기간동의 감성 특정 결과를 시현할 수 있게 된다. 이러한 방식은 사용자의 자가 진단을 용이하게 하며, 또한 장기적인 관점에서 개선 또는 악화 여부를 판단할 수 있게 한다. 메시지 생성 단계(S00)는 특정된 감정과 문자 데이터를 기반으로 사용자에게 긍정적인 영향을 줄 수 있는 메시 지를 생성하는 단계에 해당한다. 본 단계에서는 미리 학습된 인공지능(챗봇)을 이용하여 증상에 따른 적절한 메 시지를 생성할 수 있도록 구성된다. 일 예로서, 본 단계는 사용자가 우울증이며, 현재의 감정상태가 무기력한 것으로 판단단 경우 정신의학에서 치료방법으로 사용되는 행동을 유도할 수 있는 메시지를 생성할 수 있다. 일 예로서 도 6(a)와 에서와 같이 행동을 유도할 수 있는 ‘맑은 공기를 느껴보는건 어때요?’ 과 같이 기분전환 또는 신체 리듬을 끌어올릴 수 있는 행동을 유도하도록 메시지를 생성할 수 있다. 이와 같이 생성된 메시지는 전술한 문자 시현 단계(S500)와 같이 사용자의 단말기상에 시현될 수 있다. 본 단계는 사용자와의 대화 과정에 서 지속적으로 수행될 수 있다. 한편, 전술한 본 발명의 일 실시예에 따른 딥 러닝을 이용한 음성 기반의 사용자 감성분석 방법은 도 1 및 도 2 에서 설명한 시스템에 의하여 수행될 수 있다. 이상에서 설명한 바와 같이, 본 발명에 따른 딥 러닝을 이용한 음성 기반의 사용자 감성분석 방법은 음성 데이 터로부터 말하고자 하는 의미와 음성 특징을 추출하여 사용자의 감성을 판단할 수 있으므로 현재의 심리 상태를 적절하게 반영할 수 있으며, 또한 적절한 솔루션을 제공하는데 정확한 기준으로 사용될 수 있다."}
{"patent_id": "10-2022-0042470", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일 실시예에 따른 딥 러닝을 이용한 음성 기반의 사용자 감성분석 방법의 개념도이다. 도 2는 본 발명의 일 실시예에 따른 딥 러닝을 이용한 음성 기반의 사용자 감성분석 방법을 수행하는 시스템의 블록도이다. 도 3은 본 발명의 일 실시예에 따른 딥 러닝을 이용한 음성 기반의 사용자 감성분석 방법의 순서도이다. 도 4는 전처리부의 작동에 대한 개념을 도시한 도면이다. 도 5는 본 발명의 다른 실시예에 따른 딥 러닝을 이용한 음성 기반의 사용자 감성분석 방법의 순서도이다. 도 6은 본 발명의 일 실시예에 따른 딥 러닝을 이용한 음성 기반의 사용자 감성분석 방법을 이용하여 구현되는 어플리케이션의 화면의 예시이다."}
