{"patent_id": "10-2021-0082549", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2022-0134408", "출원번호": "10-2021-0082549", "발명의 명칭": "캐릭터를 활용한 인공지능 자연어 처리 기반의 화상교육 콘텐츠 제공 방법 및 장치", "출원인": "주식회사 트랜스버스", "발명자": "장대익"}}
{"patent_id": "10-2021-0082549", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "참가자간 비대면으로 진행되는 화상교육 콘텐츠를 제공하는 장치에 있어서, 외부 서버로부터 적어도 하나 이상의 참가자의 화상교육 서비스 접속을 확인하는 참가자 확인부;상기 적어도 하나의 참가자 각각에 대한 영상 및 음성 데이터를 획득하여 참가자 발언 정보를 수집하는 참가자정보 수집부;상기 참가자 발언 정보를 발언 텍스트로 변환하여 발언 분석 정보를 생성하는 발언 변환 처리부; 및상기 발언 분석 정보를 기반으로 캐릭터를 생성하고, 상기 캐릭터를 활용한 화상교육 콘텐츠를 외부 서버를 통해 참가자 단말로 제공하는 캐릭터 형성 처리부를 포함하는 것을 특징으로 하는 캐릭터를 활용한 인공지능 자연어 처리 기반의 화상교육 콘텐츠 제공 장치."}
{"patent_id": "10-2021-0082549", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 발언 변환 처리부는,상기 참가자 발언 정보에 포함된 참가자의 음성 발언을 인식하여 발언 텍스트로 변환하고, 인공지능 자연어 처리 기능을 적용하여 상기 발언 텍스트를 질문과 응답으로 구분하고, 상기 발언 텍스트를 코사인 유사도 측정 후비교하여 동일한 주제의 세트로 그룹화하여 대화 챕터로 구분하여 상기 발언 분석 정보를 생성하는 것을 특징으로 하는 캐릭터를 활용한 인공지능 자연어 처리 기반의 화상교육 콘텐츠 제공 장치."}
{"patent_id": "10-2021-0082549", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,상기 캐릭터 형성 처리부는,상기 적어도 하나의 참가자 수와 동일한 수로 가상의 캐릭터를 생성하고, 상기 적어도 하나의 참가자 각각의 상기 캐릭터를 통해 상기 대화 챕터에 대응하는 음성 발언 및 텍스트가 출력되도록 하는 것을 특징으로 하는 캐릭터를 활용한 인공지능 자연어 처리 기반의 화상교육 콘텐츠 제공 장치."}
{"patent_id": "10-2021-0082549", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서,상기 캐릭터 형성 처리부는,상기 대화 챕터의 문구를 분석하여, 분석 결과에 따라 복수의 후보 캐릭터를 추출하고, 상기 참가자의 얼굴 표정 또는 음성을 분석하여 감정 상태를 판단한 후 복수의 후보 캐릭터 각각의 속성정보를 기반으로 상기 감정 상태에 대응되는 캐릭터를 선정하며, 선정된 상기 캐릭터를 통해 음성 발언 및 텍스트가 출력되도록 하는 것을 특징으로 하는 캐릭터를 활용한 인공지능 자연어 처리 기반의 화상교육 콘텐츠 제공 장치."}
{"patent_id": "10-2021-0082549", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제2항에 있어서,상기 캐릭터 형성 처리부는,상기 적어도 하나 이상의 참가자의 연령대, 대화 주제어 및 대화 난이도 중 적어도 하나의 조건에 매칭되는 캐릭터를 선정하여 생성하고, 참가자의 영상에 포함된 참가자의 얼굴 표정 또는 전신의 움직임을 상기 캐릭터에반영하여 캐릭터가 실시간 변경되도록 하는 것을 특징으로 하는 캐릭터를 활용한 인공지능 자연어 처리 기반의공개특허 10-2022-0134408-3-화상교육 콘텐츠 제공 장치."}
{"patent_id": "10-2021-0082549", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5항에 있어서,상기 캐릭터 형성 처리부는,상기 참가자의 성별, 연령 및 학년 중 적어도 하나의 개인 속성정보를 기반으로 제1 스코어를 산출하고, 상기대화의 주제어를 기반으로 제2 스코어를 산출하며, 상기 제1 스코어 및 상기 제2 스코어를 이용하여 최종 스코어를 산출하되,상기 캐릭터 형성 처리부는, 상기 최종 스코어를 복수의 캐릭터 각각의 기준 스코어와 비교하여 상기 최종 스코어와 가장 차이값이 작은 상기 기준 스코어에 대응하는 상기 캐릭터를 선정하여, 상기 참가자의 얼굴 표정 또는전신의 움직임을 상기 캐릭터에 반영하여 캐릭터가 실시간 변경되도록 하는 것을 특징으로 하는 캐릭터를 활용한 인공지능 자연어 처리 기반의 화상교육 콘텐츠 제공 장치."}
{"patent_id": "10-2021-0082549", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에 있어서,참가자 중 특정 참가자를 선정하고, 선정된 참가자로부터 평서문 콘텐츠를 획득하는 평서문 콘텐츠 획득부; 및상기 평서문 콘텐츠를 질의응답 또는 대화 형식의 대화문 콘텐츠로 변환하는 콘텐츠 변환 처리부를 추가로 포함하는 것을 특징으로 하는 캐릭터를 활용한 인공지능 자연어 처리 기반의 화상교육 콘텐츠 제공장치."}
{"patent_id": "10-2021-0082549", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서,상기 콘텐츠 변환부는,상기 평서문 콘텐츠의 음성 또는 텍스트 콘텐츠에 인공지능 자연어 처리 기능을 적용하여 주제별 챕터를 구분하고, 평서문 형식의 상기 평서문 콘텐츠를 질의응답 또는 대화 형식의 상기 대화문 콘텐츠로 변환하는 것을 특징으로 하는 캐릭터를 활용한 인공지능 자연어 처리 기반의 화상교육 콘텐츠 제공 장치."}
{"patent_id": "10-2021-0082549", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서,상기 콘텐츠 변환부는,상기 평서문 콘텐츠를 자연어 처리한 자연어 처리 결과를 기반으로 구분된 주제별 챕터 각각에 대한 콘텐츠를수집하고, 수집된 콘텐츠 각각에 대한 순차정보를 확인하며, 순차정보가 확인된 콘텐츠 각각에 대한 순차정보의중요도에 따른 가중치를 산출하되,상기 콘텐츠 변환부는, 상기 주제별 챕터 각각에 대한 콘텐츠 각각에 상기 가중치를 부여하고, 상기 가중치를반영한 콘텐츠를 배열하여 상기 대화문 콘텐츠로 변환하는 것을 특징으로 하는 캐릭터를 활용한 인공지능 자연어 처리 기반의 화상교육 콘텐츠 제공 장치."}
{"patent_id": "10-2021-0082549", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9항에 있어서,상기 캐릭터 형성 처리부는,상기 대화문 콘텐츠의 대화 주체의 수에 따라 상기 캐릭터를 생성하고, 상기 캐릭터를 통해 상기 대화문 콘텐츠에 대응하는 음성 발언 및 텍스트가 출력되도록 하는 것을 특징으로 하는 캐릭터를 활용한 인공지능 자연어 처리 기반의 화상교육 콘텐츠 제공 장치."}
{"patent_id": "10-2021-0082549", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "공개특허 10-2022-0134408-4-제1항에 있어서,상기 참가자 정보 수집부는,상기 적어도 하나의 참가자 각각에 대한 시선 집중 감지정보를 획득하며,상기 캐릭터 형성 처리부는,상기 시선 집중 감지정보를 기반으로 복수의 참가자들의 시선이 집중되는 곳을 판단하고, 시선이 집중되는 곳으로 판단된 특정 캐릭터의 크기를 조정하거나 위치를 변경하는 것을 특징으로 하는 캐릭터를 활용한 인공지능 자연어 처리 기반의 화상교육 콘텐츠 제공 장치."}
{"patent_id": "10-2021-0082549", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "화상교육 콘텐츠 제공 장치가 참가자간 비대면으로 진행되는 화상교육 콘텐츠를 제공하는 방법에 있어서, 외부 서버로부터 적어도 하나 이상의 참가자의 화상교육 서비스 접속을 확인하는 참가자 확인 단계;상기 적어도 하나의 참가자 각각에 대한 영상 및 음성 데이터를 획득하여 참가자 발언 정보를 수집하는 참가자정보 수집 단계;상기 참가자 발언 정보를 발언 텍스트로 변환하여 발언 분석 정보를 생성하는 발언 변환 처리 단계; 및상기 발언 분석 정보를 기반으로 캐릭터를 생성하고, 상기 캐릭터를 활용한 화상교육 콘텐츠를 외부 서버를 통해 참가자 단말로 제공하는 캐릭터 형성 처리 단계를 포함하는 것을 특징으로 하는 캐릭터를 활용한 인공지능 자연어 처리 기반의 화상교육 콘텐츠 제공 방법."}
{"patent_id": "10-2021-0082549", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "캐릭터를 활용한 인공지능 자연어 처리 기반의 화상교육 콘텐츠 제공 방법 및 장치를 개시한다. 본 발명의 실시예에 따른 화상교육 콘텐츠 제공 장치는, 외부 서버로부터 적어도 하나 이상의 참가자의 화상교육 서비스 접속을 확인하는 참가자 확인부; 상기 적어도 하나의 참가자 각각에 대한 영상 및 음성 데이터를 획득하 여 참가자 발언 정보를 수집하는 참가자 정보 수집부; 상기 참가자 발언 정보를 발언 텍스트로 변환하여 발언 분 석 정보를 생성하는 발언 변환 처리부; 및 상기 발언 분석 정보를 기반으로 캐릭터를 생성하고, 상기 캐릭터를 활용한 화상교육 콘텐츠를 외부 서버를 통해 참가자 단말로 제공하는 캐릭터 형성 처리부를 포함할 수 있다."}
{"patent_id": "10-2021-0082549", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 캐릭터를 활용한 인공지능 자연어 처리 기반의 화상교육 콘텐츠 제공 방법 및 장치에 관한 것이다."}
{"patent_id": "10-2021-0082549", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "이 부분에 기술된 내용은 단순히 본 발명의 실시예에 대한 배경 정보를 제공할 뿐 종래기술을 구성하는 것은 아 니다. 최근 코로나19의 영향으로 인해 2020년 1학기부터 초/중/고/대학의 수업이 대부분 비대면 강의로 전격 대체되었 다. 그러나 비대면 수업을 받는 전국 대학생들을 대상으로 전국대학학생회네트워크가 실시한 조사에 따르면 응 답자의 64%이상이 비대면 수업에 만족하지 못한 것으로 나타났으며 온라인 수업의 내용 전달력이 대면 수업의 경우보다 좋다고 응답한 학생은 9%에 불과하였다. 현재 국내에서 사용되고 있는 실시간 비대면 화상교육 서비스는 줌, 웹엑스, 구글클래스 등 대부분 해외 서비스 가 다수를 차지하고 있으며 단순히 교사와 학생 간의 영상 및 음성 발표자료를 통한 교류가 가능할 뿐이고 화상 수업의 내용을 새로운 형식의 콘텐츠로 자동 변환하여 제공할 수 있는 기능은 기존 서비스에서 개시된 바가 없 었다."}
{"patent_id": "10-2021-0082549", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 비대면 온라인 화상교육에서, 참가자, 특히 온라인 교육 환경에서 쉽게 흥미를 잃을 수 있는 유아 및 초등학생 등의 화상교육 몰입도가 낮아지는 문제와 화상교육 콘텐츠에 대한 이해가 떨어질 수 있는 문제를 해결 하기 위하여 캐릭터를 활용한 인공지능 자연어 처리 기반의 화상교육 콘텐츠 제공 방법 및 장치를 제공하는 데 주된 목적이 있다."}
{"patent_id": "10-2021-0082549", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 일 측면에 의하면, 상기 목적을 달성하기 위한 화상교육 콘텐츠 제공 장치는, 외부 서버로부터 적어 도 하나 이상의 참가자의 화상교육 서비스 접속을 확인하는 참가자 확인부; 상기 적어도 하나의 참가자 각각에 대한 영상 및 음성 데이터를 획득하여 참가자 발언 정보를 수집하는 참가자 정보 수집부; 상기 참가자 발언 정 보를 발언 텍스트로 변환하여 발언 분석 정보를 생성하는 발언 변환 처리부; 및 상기 발언 분석 정보를 기반으 로 캐릭터를 생성하고, 상기 캐릭터를 활용한 화상교육 콘텐츠를 외부 서버를 통해 참가자 단말로 제공하는 캐 릭터 형성 처리부를 포함할 수 있다. 그리고, 상기 발언 변환 처리부는, 상기 참가자 발언 정보에 포함된 참가자의 음성 발언을 인식하여 발언 텍스 트로 변환하고, 인공지능 자연어 처리 기능을 적용하여 상기 발언 텍스트를 질문과 응답으로 구분하고, 상기 발 언 텍스트를 코사인 유사도 측정 후 비교하여 동일한 주제의 세트로 그룹화하여 대화 챕터로 구분하여 상기 발 언 분석 정보를 생성한다. 그리고, 상기 캐릭터 형성 처리부는, 상기 적어도 하나의 참가자 수와 동일한 수로 가상의 상기 캐릭터를 생성 하고, 상기 적어도 하나의 참가자 각각의 상기 캐릭터를 통해 상기 대화 챕터에 대응하는 음성 발언 및 텍스트 가 출력되도록 한다. 그리고, 상기 캐릭터 형성 처리부는, 상기 대화 챕터의 문구를 분석하여, 분석 결과에 따라 복수의 후보 캐릭터 를 추출하고, 상기 참가자의 얼굴 표정 또는 음성을 분석하여 감정 상태를 판단한 후 복수의 후보 캐릭터 각각 의 속성정보를 기반으로 상기 감정 상태에 대응되는 캐릭터를 선정하며, 선정된 상기 캐릭터를 통해 음성 발언 및 텍스트가 출력되도록 한다. 그리고, 상기 캐릭터 형성 처리부는, 상기 적어도 하나 이상의 참가자의 연령대, 대화 주제어 및 대화 난이도 중 적어도 하나의 조건에 매칭되는 캐릭터를 선정하여 생성하고, 참가자의 영상에 포함된 참가자의 얼굴 표정 또는 전신의 움직임을 상기 캐릭터에 반영하여 캐릭터가 실시간 변경되도록 한다. 그리고, 상기 캐릭터 형성 처리부는, 상기 참가자의 성별, 연령 및 학년 중 적어도 하나의 개인 속성정보를 기 반으로 제1 스코어를 산출하고, 상기 대화의 주제어를 기반으로 제2 스코어를 산출하며, 상기 제1 스코어 및 상 기 제2 스코어를 이용하여 최종 스코어를 산출하되, 상기 캐릭터 형성 처리부는, 상기 최종 스코어를 복수의 캐 릭터 각각의 기준 스코어와 비교하여 상기 최종 스코어와 가장 차이값이 작은 상기 기준 스코어에 대응하는 상 기 캐릭터를 선정하여, 상기 참가자의 얼굴 표정 또는 전신의 움직임을 상기 캐릭터에 반영하여 캐릭터가 실시 간 변경되도록 한다. 그리고, 화상교육 콘텐츠 제공 장치는, 참가자 중 특정 참가자를 선정하고, 선정된 참가자로부터 평서문 콘텐츠 를 획득하는 평서문 콘텐츠 획득부; 및 상기 평서문 콘텐츠를 질의응답 또는 대화 형식의 대화문 콘텐츠로 변환 하는 콘텐츠 변환부를 추가로 포함할 수 있다. 그리고, 상기 콘텐츠 변환부는, 상기 평서문 콘텐츠의 음성 또는 텍스트 콘텐츠에 인공지능 자연어 처리 기능을 적용하여 주제별 챕터를 구분하고, 평서문 형식의 상기 평서문 콘텐츠를 대화 형식의 상기 대화문 콘텐츠로 변 환한다. 그리고, 상기 콘텐츠 변환부는, 상기 평서문 콘텐츠를 자연어 처리한 자연어 처리 결과를 기반으로 구분된 주제 별 챕터 각각에 대한 콘텐츠를 수집하고, 수집된 콘텐츠 각각에 대한 순차정보를 확인하며, 순차정보가 확인된 콘텐츠 각각에 대한 순차정보의 중요도에 따른 가중치를 산출하되, 상기 콘텐츠 변환부는, 상기 주제별 챕터 각 각에 대한 콘텐츠 각각에 상기 가중치를 부여하고, 상기 가중치를 반영한 콘텐츠를 배열하여 상기 대화문 콘텐 츠로 변환한다. 그리고, 상기 캐릭터 형성 처리부는, 상기 대화문 콘텐츠의 대화 주체의 수에 따라 상기 캐릭터를 생성하고, 상 기 캐릭터를 통해 상기 대화문 콘텐츠에 대응하는 음성 발언 및 텍스트가 출력되도록 한다. 그리고, 상기 참가자 정보 수집부는, 상기 적어도 하나의 참가자 각각에 대한 시선 집중 감지정보를 획득하며, 상기 캐릭터 형성 처리부는, 상기 시선 집중 감지정보를 기반으로 복수의 참가자들의 시선이 집중되는 곳을 판 단하고, 시선이 집중되는 곳으로 판단된 특정 캐릭터의 크기를 조정하거나 위치를 변경한다. 또한, 본 발명의 다른 측면에 의하면, 상기 목적을 달성하기 위한 화상교육 콘텐츠 제공 방법은, 외부 서버로부 터 적어도 하나 이상의 참가자의 화상교육 서비스 접속을 확인하는 참가자 확인 단계; 상기 적어도 하나의 참가 자 각각에 대한 영상 및 음성 데이터를 획득하여 참가자 발언 정보를 수집하는 참가자 정보 수집 단계; 상기 참 가자 발언 정보를 발언 텍스트로 변환하여 발언 분석 정보를 생성하는 발언 변환 처리 단계; 및 상기 발언 분석 정보를 기반으로 캐릭터를 생성하고, 상기 캐릭터를 활용한 화상교육 콘텐츠를 외부 서버를 통해 참가자 단말로제공하는 캐릭터 형성 처리 단계를 포함할 수 있다."}
{"patent_id": "10-2021-0082549", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "이상에서 설명한 바와 같이, 본 발명의 캐릭터를 활용한 인공지능 자연어 처리 기반의 화상교육 콘텐츠 제공 장 치는 비대면 화상교육에서 교사 및 학생 등 참가자의 음성 발언 내용을 기능을 활용하여 텍스트로 변환하고 인 공 STT 지능 자연어 처리 기능을 적용하여 발언 텍스트를 질문과 응답으로 구분하고 발언 텍스트의 코사인 유사 도 측정 후 비교하여 동일한 주제의 세트가 되는 대화 챕터로 구분하며 상기 구분된 대화 챕터를 캐릭터를 활용 한 대화 형식의 화상교육 콘텐츠로 변환함으로써, 참가자 특히 학생들의 화상교육 몰입도를 향상시키고 화상교 육 콘텐츠에 대한 이해도를 높이는 효과가 있다."}
{"patent_id": "10-2021-0082549", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 본 발명의 바람직한 실시예를 첨부된 도면들을 참조하여 상세히 설명한다. 본 발명을 설명함에 있어, 관 련된 공지 구성 또는 기능에 대한 구체적인 설명이 본 발명의 요지를 흐릴 수 있다고 판단되는 경우에는 그 상 세한 설명은 생략한다. 또한, 이하에서 본 발명의 바람직한 실시예를 설명할 것이나, 본 발명의 기술적 사상은 이에 한정하거나 제한되지 않고 당업자에 의해 변형되어 다양하게 실시될 수 있음은 물론이다. 이하에서는 도면 들을 참조하여 본 발명에서 제안하는 캐릭터를 활용한 인공지능 자연어 처리 기반의 화상교육 콘텐츠 제공 방법 및 장치에 대해 자세하게 설명하기로 한다. 도 1은 본 발명의 실시예에 따른 캐릭터를 활용한 인공지능 자연어 처리 기반의 화상교육 콘텐츠 제공 시스템을 개략적으로 나타낸 블록 구성도이다. 본 실시예에 따른 캐릭터를 활용한 인공지능 자연어 처리 기반의 화상교육 콘텐츠 제공 시스템은 화상교육 입출 력장치, 화상교육 중앙서버 및 화상교육 콘텐츠 제공 장치를 포함한다. 도 1의 캐릭터를 활용한 인공 지능 자연어 처리 기반의 화상교육 콘텐츠 제공 시스템은 일 실시예에 따른 것으로서, 도 1에 도시된 모든 블록 이 필수 구성요소는 아니며, 다른 실시예에서 캐릭터를 활용한 인공지능 자연어 처리 기반의 화상교육 콘텐츠 제공 시스템에 포함된 일부 블록이 추가, 변경 또는 삭제될 수 있다. 화상교육 입출력장치는 각 참가자의 화상교육 참여를 가능하게 하는 마이크 및 카메라를 포함하는 PC 또는 스마트폰 등 참가자의 개인 디바이스로 형성된다. 화상교육 중앙서버는 각 참가자의 화상교육 입출력장치들과 영상 및 음성 데이터를 송수신하며 명령을 처리 하는 화상교육 플랫폼으로 형성된다. 화상교육 콘텐츠 제공 장치는 화상교육 중앙서버의 영상 및 음성 데이터를 수신하여 참가자의 음성 발언 을 기능을 활용 STT(Speech to text)하여 텍스트로 변환하고 인공지능 자연어 처리 기능을 적용하여 발언 텍스 트를 질문과 응답으로 구분하고 발언 텍스트의 코사인 유사도 측정 후 비교하여 동일한 주제의 세트가 되는 대 화 챕터로 구분한다. 또한, 화상교육 콘텐츠 제공 장치는 구분된 대화 챕터 텍스트를 이용하여 캐릭터를 활용한 화상교육 콘텐츠 를 생성하여 화상교육 중앙서버를 통해 화상교육 입출력장치에 제공한다. 화상교육 콘텐츠 제공 장치 는 참가자 수와 동일한 수로 가상의 아바타 캐릭터를 화면에 생성하고 구분된 대화 챕터를 각 참가자에 해당하 는 아바타 캐릭터가 음성 발언 및 텍스트로 표시할 수 있다. 이하, 본 발명의 제1 실시예에 따른 캐릭터를 활용한 인공지능 자연어 처리 기반의 화상교육 콘텐츠 제공 시스 템의 동작에 대해 설명하도록 한다. 참가자가 화상교육에 참여하여 발언하면 참가자의 발언을 화상교육 콘텐츠 제공 장치가 텍스트로 변환하고 발언 내용의 맥락을 판단하여 발언을 질문과 응답으로 구분할 수 있는 머신러닝 선행학습이 완료된 인공지능의 자연어 처리 기능을 적용하여 발언 텍스트를 질의응답으로 구분하고 발언 텍스트의 코사인 유사도를 기준으로 발언 텍스트를 주제별 대화 챕터로 구분하고 화상교육 콘텐츠 제공 장치가 참가자 수와 동일한 수의 가상 아 바타 캐릭터를 생성하여 아바타 캐릭터가 참가자의 음성 발언 및 텍스트를 대신하여 발언하거나 표시하는 화상 교육 콘텐츠를 생성한다. 이때 캐릭터의 음성 발언 되는 목소리는 참가자의 목소리와 동일 또는 유사하거나 전 혀 다른 종류의 목소리로 변경하여 출력할 수 있다. 또한 캐릭터의 음성 발언 및 텍스트는 참가자가 발언한 것"}
{"patent_id": "10-2021-0082549", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "과 동일한 내용이거나 화상교육 콘텐츠 제공 장치가 인공지능 자연어 처리 기능을 적용하여 요약하거나 대화 문 형식의 표현으로 문장의 주어 어미 등을 변환한 것일 수 있다. 더불어 화상교육 콘텐츠 제공 장치가 생성 하는 아바타 캐릭터의 종류나 목소리 문장의 주어 어미 등은 참가자의 연령이나 발언 텍스트의 주제에 어울리는 것으로 자동으로 선택될 수 있고, 캐릭터의 얼굴이 참가자의 얼굴을 본따 생성되는 것도 가능하다. 이하, 본 발명의 제2 실시예에 따른 캐릭터를 활용한 인공지능 자연어 처리 기반의 화상교육 콘텐츠 제공 시스 템의 동작에 대해 설명하도록 한다. 화상교육 콘텐츠 제공 장치는 참가자의 연령대나 대화의 주제어 등에 따라 다른 종류의 캐릭터로 참가자의 얼굴 또는 전신을 실시간 자동 변경하여 표시하는 것을 특징으로 한다. 참가자가 화상교육에 참여하여 발언하면 참가자의 발언을 화상교육 콘텐츠 제공 장치가 텍스트로 변환하고 발언 내용의 맥락을 판단하여 발언을 질문과 응답으로 구분할 수 있는 머신러닝 선행학습이 완료된 인공지능의 자연어 처리 기능을 적용하여 발언 텍스트를 질의응답으로 구분하고 발언 텍스트의 코사인 유사도를 기준으로 발언 텍스트를 주제별 대화 챕터로 구분하고 화상교육 콘텐츠 제공 장치가 참가자의 연령대나 대화의 주제어 등에 따라 다른 종류의 캐릭터로 참가자의 얼굴 또는 전신을 실시간으로 자동 변경하여 표시한다. 예를 들어, 동물에 관한 발언 텍스트가 감지되면 개나 고양이 등의 캐릭터로 참가자의 얼굴 또는 전신을 변경하 고 참가자의 연령대가 10세 이상 15세 미만, 15세 이상 등일 때 해당 연령층이 선호하는 캐릭터를 자동으로 선 택하고 온라인 화상수업 화면 상에 참가자의 얼굴 또는 전신을 대신하여 표시할 수 있다. 이하, 본 발명의 제3 실시예에 따른 캐릭터를 활용한 인공지능 자연어 처리 기반의 화상교육 콘텐츠 제공 시스 템의 동작에 대해 설명하도록 한다. 화상교육 콘텐츠 제공 장치는 평서문의 음성 또는 텍스트 콘텐츠에 인공지능 자연어 처리 기능을 적용하여 주제별 챕터를 구분하고 평서문 형식의 화상교육 콘텐츠를 대화문 형식의 화상교육 콘텐츠로 변환하고 상기 화상교육 콘텐츠 제공 장치는 가상의 아바타 캐릭터를 화면에 생성하고, 평서문 형식의 화상교육 콘텐 츠에서 변환된 대화문 형식의 화상교육 콘텐츠를 둘 이상의 아바타 캐릭터가 음성 발언 및 텍스트로 표시하는 것을 특징으로 한다. 본 발명의 제3 실시예는 도4에 도시된 바와 같이 일방향의 강의, 책, 뉴스 등과 같은 평서문 형식의 화상교육용 콘텐츠를 화상교육 콘텐츠 제공 장치에 입력하면 평서문 형식의 콘텐츠를 인공지능 프로세서 장치가 텍스트 로 변환하고 평서문 내용의 맥락을 판단하여 발언을 질문과 응답에 해당하는 대화형 문장으로 변환할 수 있는머신러닝 선행학습이 완료된 인공지능의 자연어 처리 기능을 적용하여 평서문 형식의 텍스트를 대화문 형식의 텍스트로 변환하고 변환된 대화형 텍스트의 코사인 유사도를 기준으로 대화형 텍스트를 주제별 대화 챕터로 구 분하고 화상교육 콘텐츠 제공 장치가 둘 이상의 가상 아바타 캐릭터를 생성하여 아바타 캐릭터가 대화형 텍스트를 음성 발언 또는 텍스트로 표시하는 화상교육 콘텐츠를 생성한다. 도 2는 본 발명의 실시예에 따른 캐릭터를 활용한 인공지능 자연어 처리 기반의 화상교육 콘텐츠 제공 장치를 개략적으로 나타낸 블록 구성도이다. 본 실시예에 따른 화상교육 콘텐츠 제공 장치는 참가자 확인부, 참가자 정보 수집부, 발언 변환 처리부, 평서문 콘텐츠 획득부, 콘텐츠 변환 처리부 및 캐릭터 형성 처리부를 포함한다. 참가자 확인부는 외부 서버로부터 적어도 하나 이상의 참가자의 화상교육 서비스 접속을 확인한다. 참가자 정보 수집부는 적어도 하나의 참가자 각각에 대한 영상 및 음성 데이터를 획득하여 참가자 발언 정 보를 수집한다. 발언 변환 처리부는 참가자 발언 정보를 발언 텍스트로 변환하여 발언 분석 정보를 생성한다. 발언 변환 처리부는 참가자 발언 정보에 포함된 참가자의 음성 발언을 인식하여 발언 텍스트로 변환하고, 인공지능 자연어 처리 기능을 적용하여 상기 발언 텍스트를 질문과 응답으로 구분한다. 이후, 발언 변환 처리부 는 발언 텍스트를 코사인 유사도 측정 후 비교하여 동일한 주제의 세트로 그룹화하여 대화 챕터로 구분하 여 발언 분석 정보를 생성한다. 캐릭터 형성 처리부는 발언 분석 정보를 기반으로 캐릭터를 생성하고, 캐릭터를 활용한 화상교육 콘텐츠를 화상교육 중앙서버를 통해 화상교육 입출력장치로 제공한다. 이하, 제1 실시예에 따른 캐릭터 형성 처리부의 동작을 설명하도록 한다. 캐릭터 형성 처리부는 적어도 하나의 참가자 수와 동일한 수로 가상의 상기 캐릭터를 생성하고, 상기 적어 도 하나의 참가자 각각의 캐릭터를 통해 대화 챕터에 대응하는 음성 발언 및 텍스트가 출력되도록 한다. 캐릭터 형성 처리부는 대화 챕터의 문구를 분석하여, 분석 결과에 따라 복수의 후보 캐릭터를 추출하고, 참가자의 얼굴 표정 또는 음성을 분석하여 감정 상태를 판단한 후 복수의 후보 캐릭터 각각의 속성정보를 기반 으로 상기 감정 상태에 대응되는 캐릭터를 선정한다. 이후, 캐릭터 형성 처리부는 선정된 캐릭터를 통해 음성 발언 및 텍스트가 출력되도록 한다. 이하, 제2 실시예에 따른 캐릭터 형성 처리부의 동작을 설명하도록 한다. 캐릭터 형성 처리부는 적어도 하나 이상의 참가자의 연령대, 대화 주제어 및 대화 난이도 중 적어도 하나 의 조건에 매칭되는 캐릭터를 선정하여 생성한다. 캐릭터 형성 처리부는 참가자의 영상에 포함된 참가자의 얼굴 표정 또는 전신의 움직임을 상기 캐릭터에 반영하여 캐릭터가 실시간 변경되도록 한다. 캐릭터 형성 처리부는 참가자의 성별, 연령 및 학년 중 적어도 하나의 개인 속성정보를 기반으로 제1 스코 어를 산출하고, 대화의 주제어를 기반으로 제2 스코어를 산출하며, 제1 스코어 및 제2 스코어를 합산하여 최종 스코어를 산출한다. 캐릭터 형성 처리부는 최종 스코어를 복수의 캐릭터 각각의 기준 스코어와 비교하여 최종 스코어와 가장 차이값이 작은 기준 스코어에 대응하는 캐릭터를 선정한다. 캐릭터 형성 처리부는 선정된 캐릭터에 참가자 의 얼굴 표정 또는 전신의 움직임을 반영하여 캐릭터가 실시간 변경되도록 한다. 이하, 제3 실시예에 따른 캐릭터 형성 처리부의 동작을 설명하도록 한다. 여기서, 캐릭터 형성 처리부 는 평서문 콘텐츠 획득부 및 콘텐츠 변환 처리부와의 연동을 통해 캐릭터를 형성한다. 평서문 콘텐츠 획득부는 참가자 중 특정 참가자를 선정하고, 선정된 특정 참가자로부터 평서문 콘텐츠를 획득한다. 여기서, 특정 참가자는 화상교육 콘텐츠를 제공하는 메인 참가자(예: 교사, 진행자 등)일 수 있다. 콘텐츠 변환 처리부는 평서문 콘텐츠를 질의응답 또는 대화 형식의 대화문 콘텐츠로 변환한다. 구체적으로, 콘텐츠 변환 처리부는 평서문 콘텐츠의 음성 또는 텍스트 콘텐츠에 인공지능 자연어 처리 기 능을 적용하여 주제별 챕터를 구분한다. 이후, 콘텐츠 변환 처리부는 구분된 주제별 챕터를 기준으로 평서문 형식의 평서문 콘텐츠를 질의응답 또는 대화 형식의 대화문 콘텐츠로 변환한다. 콘텐츠 변환 처리부는 평서문 콘텐츠를 자연어 처리한 자연어 처리 결과를 기반으로 구분된 주제별 챕터 각각에 대한 콘텐츠를 수집하고, 수집된 콘텐츠 각각에 대한 순차정보를 확인하며, 순차정보가 확인된 콘텐츠 각각에 대한 순차정보의 중요도에 따른 가중치를 산출한다. 콘텐츠 변환 처리부는 주제별 챕터 각각에 대 한 콘텐츠 각각에 가중치를 부여하고, 가중치를 반영한 콘텐츠를 배열하여 상기 대화문 콘텐츠로 변환한다. 캐릭터 형성 처리부는 대화문 콘텐츠의 대화 주체의 수에 따라 상기 캐릭터를 생성하고, 캐릭터를 통해 대 화문 콘텐츠에 대응하는 음성 발언 및 텍스트가 출력되도록 한다. 한편, 참가자 정보 수집부에서 적어도 하나의 참가자 각각에 대한 시선 집중 감지정보를 획득한 경우, 캐 릭터 형성 처리부는 다음과 같은 동작을 수행할 수 있다. 여기서, 시선 집중 감지정보는 화상교육 입출력 장치 각각으로부터 수집된 정보로서, 참가자의 시선이 머무는 위치를 감지한 정보를 의미한다. 캐릭터 형성 처리부는 시선 집중 감지정보를 기반으로 복수의 참가자들의 시선이 집중되는 곳을 판단하고, 시선이 집중되는 곳으로 판단된 특정 캐릭터의 크기를 조정할 수 있다. 구체적으로, 캐릭터 형성 처리부는 시선이 집중되는 곳으로 판단된 특정 캐릭터의 크기를 상기 특정 캐릭 터를 제외한 나머지 캐릭터의 크기보다 커지도록 조정할 수 있다. 또한, 캐릭터 형성 처리부는 특정 캐릭 터의 크기를 조정하면서 특정 캐릭터가 정중앙 또는 화면의 최상단에 위치하도록 복수의 캐릭터의 위치나 배열 을 조정할 수 있다. 도 3은 본 발명의 제1 실시예에 따른 캐릭터를 활용한 인공지능 자연어 처리 기반의 화상교육 콘텐츠 제공 방법 을 설명하기 위한 순서도이다. 화상교육 콘텐츠 제공 장치는 외부 서버로부터 적어도 하나 이상의 참가자의 화상교육 서비스 접속을 확인한 다(S210). 화상교육 콘텐츠 제공 장치는 적어도 하나의 참가자 각각에 대한 영상 및 음성 데이터를 획득하여 참가자 발 언 정보를 수집한다(S220). 화상교육 콘텐츠 제공 장치는 참가자 발언을 발언 텍스트로 변환하고(S230), 발언 텍스트의 질의응답 구분 및 대화 챕터 구분을 수행하여 발언 분석 정보를 생성한다(S240). 화상교육 콘텐츠 제공 장치는 참가자 발언 정보에 포함된 참가자의 음성 발언을 인식하여 발언 텍스트로 변환하고, 인공지능 자연어 처리 기능을 적용하여 발언 텍스트를 질문과 응답으로 구분한다. 화상교육 콘텐츠 제공 장치는 발언 분석 정보를 기반으로 캐릭터를 생성한다(S250). 화상교육 콘텐츠 제공 장치는 생성된 캐릭터를 통해 음성 발언 및 텍스트 표시하여 캐릭터를 활용한 화상교 육 콘텐츠를 화상교육 중앙서버를 통해 화상교육 입출력장치로 제공한다(S260). 도 4는 본 발명의 제2 실시예에 따른 캐릭터를 활용한 인공지능 자연어 처리 기반의 화상교육 콘텐츠 제공 방법 을 설명하기 위한 순서도이다. 화상교육 콘텐츠 제공 장치는 외부 서버로부터 적어도 하나 이상의 참가자의 화상교육 서비스 접속을 확인한 다(S310). 화상교육 콘텐츠 제공 장치는 적어도 하나의 참가자 각각에 대한 영상 및 음성 데이터를 획득하여 참가자 발 언 정보를 수집한다(S320). 화상교육 콘텐츠 제공 장치는 참가자 발언을 발언 텍스트로 변환하고(S330), 발언 텍스트의 질의응답 구분 및 대화 챕터 구분을 수행하여 발언 분석 정보를 생성한다(S340). 화상교육 콘텐츠 제공 장치는 참가자 발언 정보에 포함된 참가자의 음성 발언을 인식하여 발언 텍스트로 변환하고, 인공지능 자연어 처리 기능을 적용하여 발언 텍스트를 질문과 응답으로 구분한다. 화상교육 콘텐츠 제공 장치는 참가자 관련 조건에 따라 서로 다른 종류의 캐릭터를 생성한다(S350). 화상교 육 콘텐츠 제공 장치는 적어도 하나 이상의 참가자의 연령대, 대화 주제어 및 대화 난이도 중 적어도 하나의 조건에 매칭되는 캐릭터를 선정하여 생성한다. 화상교육 콘텐츠 제공 장치는 참가자의 표정 또는 움직임을 실시간 반영하여 캐릭터를 표시한다(S360). 화상 교육 콘텐츠 제공 장치는 참가자의 영상에 포함된 참가자의 얼굴 표정 또는 전신의 움직임을 상기 캐릭터에반영하여 캐릭터가 실시간 변경되도록 한다. 도 5는 본 발명의 제3 실시예에 따른 캐릭터를 활용한 인공지능 자연어 처리 기반의 화상교육 콘텐츠 제공 방법 을 설명하기 위한 순서도이다. 화상교육 콘텐츠 제공 장치는 외부 서버로부터 적어도 하나 이상의 참가자의 화상교육 서비스 접속을 확인한 다(S410). 화상교육 콘텐츠 제공 장치는 특정 참가자로부터 평서문 콘텐츠를 획득한다(S420). 여기서, 특정 참가자는 화상교육 콘텐츠를 제공하는 메인 참가자(예: 교사, 진행자 등)일 수 있다. 화상교육 콘텐츠 제공 장치는 평서문 콘텐츠를 질의응답 또는 대화 형식의 대화문 콘텐츠로 변환한다(S430). 구체적으로, 화상교육 콘텐츠 제공 장치는 평서문 콘텐츠의 음성 또는 텍스트 콘텐츠에 인공지능 자연어 처 리 기능을 적용하여 주제별 챕터를 구분하고, 구분된 주제별 챕터를 기준으로 평서문 형식의 평서문 콘텐츠를 질의응답 또는 대화 형식의 대화문 콘텐츠로 변환한다. 화상교육 콘텐츠 제공 장치는 적어도 두 개 이상의 캐릭터를 생성하고(S440), 생성된 캐릭터를 통해 대화문 콘텐츠에 대한 음성 발언 및 텍스트를 표시한다(S450). 화상교육 콘텐츠 제공 장치는 대화문 콘텐츠의 대화 주체의 수에 따라 캐릭터를 생성하고, 캐릭터를 통해 대화문 콘텐츠에 대응하는 음성 발언 및 텍스트가 출력되 도록 한다. 도 3 내지 도 5 각각에서는 각 단계를 순차적으로 실행하는 것으로 기재하고 있으나, 반드시 이에 한정되는 것 은 아니다. 다시 말해, 도 3 내지 도 5 각각에 기재된 단계를 변경하여 실행하거나 하나 이상의 단계를 병렬적 으로 실행하는 것으로 적용 가능할 것이므로, 도 3 내지 도 5 각각은 시계열적인 순서로 한정되는 것은 아니다. 도 3 내지 도 5 각각에 기재된 본 실시예에 따른 화상교육 콘텐츠 제공 방법은 애플리케이션(또는 프로그램)으 로 구현되고 단말장치(또는 컴퓨터)로 읽을 수 있는 기록매체에 기록될 수 있다. 본 실시예에 따른 화상교육 콘 텐츠 제공 방법을 구현하기 위한 애플리케이션(또는 프로그램)이 기록되고 단말장치(또는 컴퓨터)가 읽을 수 있 는 기록매체는 컴퓨팅 시스템에 의하여 읽혀질 수 있는 데이터가 저장되는 모든 종류의 기록장치 또는 매체를 포함한다. 본 발명의 제1 실시예에 따른 캐릭터를 활용한 인공지능 자연어 처리 기반의 화상교육 콘텐츠 제공 동작을 더욱 자세히 설명하면 다음과 같다. 참가자가 화상교육에 참여하여 발언하면 참가자의 발언을 화상교육 콘텐츠 제공 장치가 텍스트로 변환하고 발언 내용의 맥락을 판단하여 발언을 질문과 응답으로 구분할 수 있는 머신러닝 선행학습이 완료된 인공지능의 자연어 처리 기능을 적용하여 발언 텍스트를 질의응답으로 구분하고 발언 텍스트의 코사인 유사도를 기준으로 발언 텍스트를 주제별 대화 챕터로 구분하고 화상교육 콘텐츠 제공 장치가 참가자 수와 동일한 수의 가상 아 바타 캐릭터를 생성하여 아바타 캐릭터가 참가자의 음성 발언 및 텍스트를 대신하여 발언하거나 표시하는 화상 교육 콘텐츠를 생성한다. 이때 캐릭터의 음성 발언 되는 목소리는 참가자의 목소리와 동일 또는 유사하거나 전 혀 다른 종류의 목소리로 변경하여 출력할 수 있다. 또한 캐릭터의 음성 발언 및 텍스트는 참가자가 발언한 것"}
{"patent_id": "10-2021-0082549", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "과 동일한 내용이거나 화상교육 콘텐츠 제공 장치가 인공지능 자연어 처리 기능을 적용하여 요약하거나 대화 문 형식의 표현으로 문장의 주어 어미 등을 변환한 것일 수 있다. 더불어 화상교육 콘텐츠 제공 장치가 생성 하는 아바타 캐릭터의 종류나 목소리 문장의 주어 어미 등은 참가자의 연령이나 발언 텍스트의 주제에 어울리는 것으로 자동으로 선택될 수 있고, 캐릭터의 얼굴이 참가자의 얼굴을 본따 생성되는 것도 가능하다. 도 6은 본 발명의 제2 실시예에 따른 캐릭터를 활용한 인공지능 자연어 처리 기반의 화상교육 콘텐츠 제공 동작 을 나타낸 예시도이다. 도 6을 참고하면, 화상교육 콘텐츠 제공 장치는 참가자의 연령대나 대화의 주제어 등에 따라 다른 종류의 캐 릭터로 참가자의 얼굴 또는 전신을 실시간 자동 변경하여 표시하는 것을 특징으로 한다. 참가자가 화상교육에 참여하여 발언하면 참가자의 발언을 화상교육 콘텐츠 제공 장치가 텍스트로 변환하고 발언 내용의 맥락을 판단하여 발언을 질문과 응답으로 구분할 수 있는 머신러닝 선행학습이 완료된 인공지능의 자연어 처리 기능을 적용하여 발언 텍스트를 질의응답으로 구분하고 발언 텍스트의 코사인 유사도를 기준으로 발언 텍스트를 주제별 대화 챕터로 구분하고 화상교육 콘텐츠 제공 장치가 참가자의 연령대나 대화의 주제어 등에 따라 다른 종류의 캐릭터로 참가자의 얼굴 또는 전신을 실시간으로 자동 변경하여 표시한다. 예를 들어, 도 6에 도시된 바와 같이 동물에 관한 발언 텍스트가 감지되면 개나 고양이 등의 캐릭터로 참가자의 얼굴 또는 전신을 변경하고 참가자의 연령대가 10세 이상 15세 미만, 15세 이상 등일 때 해당 연령층이 선호하 는 캐릭터를 자동으로 선택하고 화상수업 화면 상에 참가자의 얼굴 또는 전신을 대신하여 표시할 수 있다. 도 7은 본 발명의 다른 실시예에 따른 캐릭터를 활용한 인공지능 자연어 처리 기반의 화상교육 콘텐츠 제공 동 작을 나타낸 예시도이다. 화상교육 콘텐츠 제공 장치는 적어도 하나의 참가자 각각에 대한 시선 집중 감지정보를 획득한 경우, 도 7과 같은 동작을 수행할 수 있다. 화상교육 콘텐츠 제공 장치는 시선 집중 감지정보를 기반으로 복수의 참가자들의 시선이 집중되는 곳을 판단 하고, 시선이 집중되는 곳으로 판단된 특정 캐릭터의 크기나 위치를 조정할 수 있다. 예를 들어 도 7을 참조하면, 화상교육 콘텐츠 제공 장치는 시선이 집중되는 곳이 참가자 B의 캐릭터인 것으 로 판단되면, B 캐릭터의 크기를 B 캐릭터를 제외한 나머지 캐릭터(A 캐릭터, C 캐릭터, D 캐릭터)의 크기보다 커지도록 조정할 수 있다. 한편, 화상교육 콘텐츠 제공 장치는 시선이 집중되는 곳이 참가자 A의 캐릭터인 것으로 판단되면, A 캐릭터 의 크기를 조정하면서 A 캐릭터가 정중앙 또는 화면의 최상단에 위치하도록 복수의 캐릭터의 위치나 배열을 조 정할 수 있다. 도 8은 본 발명의 다른 실시예에 따른 캐릭터를 활용한 인공지능 자연어 처리 기반의 화상교육 콘텐츠 제공 동 작을 나타낸 예시도이다. 화상교육 콘텐츠 제공 장치는 적어도 하나의 참가자 각각에 대한 참가자 발언 정보를 분석하고, 발언 정도에 따라 도 8과 같은 동작을 수행할 수 있다. 화상교육 콘텐츠 제공 장치는 참가자 발언 정보를 발언 텍스트로 변환하여 생성된 발언 분석 정보를 기반으 로 참가자 각각의 발언 정도를 판단하고, 발언 정도에 따라 특정 캐릭터의 크기를 조정할 수 있다. 예를 들어 도 8을 참조하면, 화상교육 콘텐츠 제공 장치는 발언 정도가 많은 캐릭터가 참가자 B의 캐릭터인 것으로 판단되면, B 캐릭터의 크기를 B 캐릭터를 제외한 나머지 캐릭터(A 캐릭터, C 캐릭터, D 캐릭터)의 크기 보다 커지도록 조정할 수 있다. 한편, 화상교육 콘텐츠 제공 장치는 발언 정도에 따라 모든 캐릭터의 크기를 조정하고, 서로 다른 크기로 조 정된 캐릭터를 순차적 또는 랜덤으로 배열할 수 있다. 이상의 설명은 본 발명의 실시예의 기술 사상을 예시적으로 설명한 것에 불과한 것으로서, 본 발명의 실시예가 속하는 기술 분야에서 통상의 지식을 가진 자라면 본 발명의 실시예의 본질적인 특성에서 벗어나지 않는 범위에 서 다양한 수정 및 변형이 가능할 것이다. 따라서, 본 발명의 실시예들은 본 발명의 실시예의 기술 사상을 한정 하기 위한 것이 아니라 설명하기 위한 것이고, 이러한 실시예에 의하여 본 발명의 실시예의 기술 사상의 범위가 한정되는 것은 아니다. 본 발명의 실시예의 보호 범위는 아래의 청구범위에 의하여 해석되어야 하며, 그와 동등 한 범위 내에 있는 모든 기술 사상은 본 발명의 실시예의 권리범위에 포함되는 것으로 해석되어야 할 것이다."}
{"patent_id": "10-2021-0082549", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 실시예에 따른 캐릭터를 활용한 인공지능 자연어 처리 기반의 화상교육 콘텐츠 제공 시스템을 개략적으로 나타낸 블록 구성도이다. 도 2는 본 발명의 실시예에 따른 캐릭터를 활용한 인공지능 자연어 처리 기반의 화상교육 콘텐츠 제공 장치를 개략적으로 나타낸 블록 구성도이다. 도 3은 본 발명의 제1 실시예에 따른 캐릭터를 활용한 인공지능 자연어 처리 기반의 화상교육 콘텐츠 제공 방법 을 설명하기 위한 순서도이다. 도 4는 본 발명의 제2 실시예에 따른 캐릭터를 활용한 인공지능 자연어 처리 기반의 화상교육 콘텐츠 제공 방법 을 설명하기 위한 순서도이다. 도 5는 본 발명의 제3 실시예에 따른 캐릭터를 활용한 인공지능 자연어 처리 기반의 화상교육 콘텐츠 제공 방법 을 설명하기 위한 순서도이다. 도 6은 본 발명의 제2 실시예에 따른 캐릭터를 활용한 인공지능 자연어 처리 기반의 화상교육 콘텐츠 제공 동작 을 나타낸 예시도이다. 도 7은 본 발명의 다른 실시예에 따른 캐릭터를 활용한 인공지능 자연어 처리 기반의 화상교육 콘텐츠 제공 동 작을 나타낸 예시도이다. 도 8은 본 발명의 다른 실시예에 따른 캐릭터를 활용한 인공지능 자연어 처리 기반의 화상교육 콘텐츠 제공 동 작을 나타낸 예시도이다."}
