{"patent_id": "10-2017-0144234", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2018-0060971", "출원번호": "10-2017-0144234", "발명의 명칭": "사용자 입력에 기반한 문장을 제공하는 장치 및 방법", "출원인": "삼성전자주식회사", "발명자": "이지연"}}
{"patent_id": "10-2017-0144234", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "컴퓨터 실행가능 명령어(computer executable instruction)를 저장하는 메모리; 상기 컴퓨터 실행가능 명령어를 실행함으로써, 사용자로부터 입력된 축약어와 사용자 입력에 기반한 문장을 제공하는 장치에서 획득된 사용자의 상황 정보를 분석하고, 상기 축약어와 상기 상황 정보에 기초하여, 상기 축약어에 대응되는 문장을 생성하는 적어도 하나의 프로세서; 및상기 사용자로부터 축약어를 입력받고, 상기 축약어에 대응되는 문장을 상기 사용자에게 제공하며, 상기 사용자의 선택에 따라, 상기 축약어를 상기 축약어에 대응되는 문장으로 대체하여 표시하는 입출력부;를 포함하는, 사용자 입력에 기반한 문장을 제공하는 장치."}
{"patent_id": "10-2017-0144234", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1 항에 있어서,상기 입출력부는,상기 축약어에 대응되는 문장이 복수 개인 경우, 상기 축약어를 대신할 최적의 문장을 나타내는 우선순위에 기초하여, 상기 축약어에 대응되는 문장을 상기 사용자에게 제공하는, 사용자 입력에 기반한 문장을 제공하는 장치."}
{"patent_id": "10-2017-0144234", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 1 항에 있어서,상기 입출력부는,상기 축약어에 대응되는 문장에 선택 가능한 표현이 포함되는 경우, 상기 선택 가능한 표현을 선택할 수 있는사용자 인터페이스를 함께 제공하는, 사용자 입력에 기반한 문장을 제공하는 장치."}
{"patent_id": "10-2017-0144234", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 1 항에 있어서,상기 적어도 하나의 프로세서는,상기 축약어와 상기 사용자의 상황 정보를 인공 지능 알고리즘을 이용하여 학습된 데이터 인식 모델에 적용하여축약어에 대응되는 문장을 생성하는, 사용자 입력에 기반한 문장을 제공하는 장치."}
{"patent_id": "10-2017-0144234", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제 4 항에 있어서, 상기 학습된 데이터 인식 모델은 상기 사용자 입력에 기반한 문장을 제공하는 장치 외부의 서버에 저장되어 있거나, 상기 사용자 입력에 기반한 문장을 제공하는 장치의 요청에 따라 상기 서버로부터 수신되는, 사용자 입력에 기반한 문장을 제공하는 장치.공개특허 10-2018-0060971-3-청구항 6 제 1 항에 있어서,상기 상황 정보는 상대방에 대한 정보이고상기 적어도 하나의 프로세서는,상기 축약어와 상기 사용자와 상기 상대방의 관계에 기초하여, 상기 축약어에 대응되는 문장을 생성하는, 사용자 입력에 기반한 문장을 제공하는 장치."}
{"patent_id": "10-2017-0144234", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제 1 항에 있어서,상기 상황 정보는 상기 축약어의 입력이 수행되는 애플리케이션의 종류이고상기 적어도 하나의 프로세서는,상기 축약어와 상기 애플리케이션의 특성 또는 기능에 기초하여, 상기 축약어에 대응되는 문장을 생성하는, 사용자 입력에 기반한 문장을 제공하는 장치."}
{"patent_id": "10-2017-0144234", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제 1 항에 있어서,상기 상황 정보는 상기 축약어 입력 이전에 입력된 콘텐츠의 내용이고,상기 적어도 하나의 프로세서는,상기 축약어와 상기 축약어 입력 이전에 입력된 콘텐츠의 내용에 기초하여, 상기 축약어에 대응되는 문장을 생성하는, 사용자 입력에 기반한 문장을 제공하는 장치."}
{"patent_id": "10-2017-0144234", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제 1 항에 있어서,상기 상황 정보는 과거의 사용자 입력 히스토리로부터 파악되는 사용자 입력 패턴이고,상기 적어도 하나의 프로세서는,상기 축약어와 상기 사용자 입력 패턴에 기초하여, 상기 축약어에 대응되는 문장을 생성하는, 사용자 입력에 기반한 문장을 제공하는 장치."}
{"patent_id": "10-2017-0144234", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제 1 항에 있어서,상기 적어도 하나의 프로세서는,상기 사용자의 선택에 따른 상기 축약어에 대응되는 문장에 기초하여, 축약어와 문장 간의 관련도를 학습하는,사용자 입력에 기반한 문장을 제공하는 장치."}
{"patent_id": "10-2017-0144234", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "사용자로부터 축약어를 입력받는 단계;공개특허 10-2018-0060971-4-상기 사용자의 상황 정보를 획득하는 단계; 상기 축약어와 상기 상황 정보에 기초하여, 상기 축약어에 대응되는 문장을 상기 사용자에게 제공하는 단계; 및상기 사용자의 선택에 따라, 상기 축약어를 상기 축약어에 대응되는 문장으로 대체하여 표시하는 단계;를 포함하는, 사용자 입력에 기반한 문장을 제공하는 방법."}
{"patent_id": "10-2017-0144234", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제 11 항에 있어서,상기 제공하는 단계는,상기 축약어에 대응되는 문장이 복수 개인 경우, 상기 축약어를 대신할 최적의 문장을 나타내는 우선순위에 기초하여, 상기 축약어에 대응되는 문장을 상기 사용자에게 제공하는, 사용자 입력에 기반한 문장을 제공하는 방법."}
{"patent_id": "10-2017-0144234", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제 11 항에 있어서,상기 제공하는 단계는,상기 축약어에 대응되는 문장에 선택 가능한 표현이 포함되는 경우, 상기 선택 가능한 표현을 선택할 수 있는사용자 인터페이스를 함께 제공하는, 사용자 입력에 기반한 문장을 제공하는 방법."}
{"patent_id": "10-2017-0144234", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제 11 항에 있어서,상기 제공하는 단계는,상기 축약어와 상기 사용자의 상황 정보를 인공 지능 알고리즘을 이용하여 학습된 데이터 인식 모델의 입력 값으로 하여, 상기 학습된 데이터 인식 모델에서 생성된 축약어에 대응되는 문장을 상기 사용자에게 제공하는, 사용자 입력에 기반한 문장을 제공하는 방법."}
{"patent_id": "10-2017-0144234", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제 11 항에 있어서,상기 상황 정보는 상대방에 대한 정보이고상기 제공하는 단계는,상기 축약어와 상기 사용자와 상기 상대방의 관계에 기초하여, 상기 축약어에 대응되는 문장을 상기 사용자에게제공하는, 사용자 입력에 기반한 문장을 제공하는 방법."}
{"patent_id": "10-2017-0144234", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제 11 항에 있어서,상기 상황 정보는 상기 축약어의 입력이 수행되는 애플리케이션의 종류이고,상기 제공하는 단계는,상기 축약어와 상기 애플리케이션의 특성 또는 기능에 기초하여, 상기 축약어에 대응되는 문장을 상기 사용자에공개특허 10-2018-0060971-5-게 제공하는, 사용자 입력에 기반한 문장을 제공하는 방법."}
{"patent_id": "10-2017-0144234", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제 11 항에 있어서,상기 상황 정보는 상기 축약어 입력 이전에 입력된 콘텐츠의 내용이고,상기 제공하는 단계는,상기 축약어와 상기 축약어 입력 이전에 입력된 콘텐츠의 내용에 기초하여, 상기 축약어에 대응되는 문장을 상기 사용자에게 제공하는, 사용자 입력에 기반한 문장을 제공하는 방법."}
{"patent_id": "10-2017-0144234", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제 11 항에 있어서,상기 상황 정보는 과거의 사용자 입력 히스토리로부터 파악되는 사용자 입력 패턴이고,상기 제공하는 단계는,상기 축약어와 상기 사용자 입력 패턴에 기초하여, 상기 축약어에 대응되는 문장을 상기 사용자에게 제공하는,사용자 입력에 기반한 문장을 제공하는 방법."}
{"patent_id": "10-2017-0144234", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제 11 항에 있어서,상기 사용자의 선택에 따른 상기 축약어에 대응되는 문장에 기초하여, 축약어와 문장 간의 관련도를 학습하는단계를 더 포함하는, 사용자 입력에 기반한 문장을 제공하는 방법."}
{"patent_id": "10-2017-0144234", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제 11 항 내지 제 19 항 중에 어느 한 항의 방법을 컴퓨터에서 실행시키기 위한 프로그램을 기록한 컴퓨터로 읽을 수 있는 기록매체."}
{"patent_id": "10-2017-0144234", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "사용자로부터 입력된 축약어에 대응되는 문장을 생성하여 사용자에게 제공함에 있어서, 상황 정보를 더 고려하여 현재 상황에 가장 적합한 문장을 사용자에게 제공하는 사용자 입력에 기반한 문장을 제공하는 장치 및 방법을 개 시한다. 상기 사용자 입력에 기반한 문장을 제공하는 방법 중 적어도 일부는 규칙 기반 모델, 또는 기계학습, 신 경망 또는 딥러닝 알고리즘 중 적어도 하나에 따라 학습된 인공 지능 모델을 이용하여 수행될 수 있다. 상기 규 칙 기반 모델 또는 인공 지능 모델은 상기 입력된 축약어 및 상황 정보를 입력 값으로 이용하여 현재 상황에 가 장 적합한 문장을 사용자에게 제공할 수 있다."}
{"patent_id": "10-2017-0144234", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "사용자 입력에 기반한 문장을 제공하는 장치 및 방법에 관한 것이다. 또한, 본 개시는 기계 학습 알고리즘을 활용하여 인간 두뇌의 인지, 판단 등의 기능을 모사하는 인공 지능 (Artificial Intelligence, AI) 시스템 및 그 응용에 관한 것이다."}
{"patent_id": "10-2017-0144234", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "최근 스마트폰과 같은 모바일 디바이스가 널리 사용됨에 따라, 사용자는 모바일 디바이스에서 다양한 애플리케 이션을 실행시키고, 각 애플리케이션에서 사용자가 원하는 내용의 사용자의 입력을 입력할 수 있다. 모바일 디 바이스에서 이전에 입력했던 사용자의 입력에 대한 통계치를 이용하여, 사용자의 입력을 보조하는 방식이 있다. 또한, 근래에는 인간 수준의 지능을 구현하는 인공 지능 시스템이 다양한 분야에서 이용되고 있다. 인공 지능 기계가 스스로 학습하고 판단하며 똑똑해지는 시스템이다. 인공 지능 시스템은 사용할수록 인식률이 향상되고 사용자 취향을 보다 정확하게 이해할 수 있다. 인공 지능 기술은 기계학습(예로, 딥러닝) 및 기계학습을 활용한 요소 기술들로 구성된다. 기계학습은 입력 데이터들의 특징을 스스로 분류/학습하는 알고리즘 기술이며, 요소기술은 딥러닝 등의 기계학 습 알고리즘을 활용하여 인간 두뇌의 인지, 판단 등의 기능을 모사하는 기술로서, 언어적 이해, 시각적 이해, 추론/예측, 지식 표현, 동작 제어 등의 기술 분야로 구성된다. 인공 지능 기술이 응용되는 다양한 분야는 다음과 같다. 언어적 이해는 인간의 언어/문자를 인식하고 응용/처리 하는 기술로서, 자연어 처리, 기계 번역, 대화시스템, 질의 응답, 음성 인식/합성 등을 포함한다. 시각적 이해 는 사물을 인간의 시각처럼 인식하여 처리하는 기술로서, 객체 인식, 객체 추적, 영상 검색, 사람 인식, 장면 이해, 공간 이해, 영상 개선 등을 포함한다. 추론 예측은 정보를 판단하여 논리적으로 추론하고 예측하는 기술 로서, 지식/확률 기반 추론, 최적화 예측, 선호 기반 계획, 추천 등을 포함한다. 지식 표현은 인간의 경험정보 를 지식데이터로 자동화 처리하는 기술로서, 지식 구축(데이터 생성/분류), 지식 관리(데이터 활용) 등을 포함 한다. 동작 제어는 차량의 자율 주행, 로봇의 움직임을 제어하는 기술로서, 움직임 제어(항법, 충돌, 주행), 조 작 제어(행동 제어) 등을 포함한다."}
{"patent_id": "10-2017-0144234", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "사용자로부터 입력된 축약어에 대응되는 문장을 생성하여 사용자에게 제공함에 있어서, 상황 정보를 더 고려하 여 현재 상황에 가장 적합한 문장을 사용자에게 제공하는 사용자 입력에 기반한 문장을 제공하는 장치 및 방법 을 제공하는 것이다."}
{"patent_id": "10-2017-0144234", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "제 1 측면에 따른 사용자 입력에 기반한 문장을 제공하는 장치는, 컴퓨터 실행가능 명령어(computer executable instruction)를 저장하는 메모리; 상기 컴퓨터 실행가능 명령어를 실행함으로써, 사용자로부터 입력된 축약어와 사용자 입력에 기반한 문장을 제공하는 장치에서 획득된 사용자의 상황 정보를 분석하고, 상기 축약어와 상기 상황 정보에 기초하여, 상기 축약어에 대응되는 문장을 생성하는 적어도 하나의 프로세서; 및 상기 사용자로부 터 축약어를 입력받고, 상기 축약어에 대응되는 문장을 상기 사용자에게 제공하며, 상기 사용자의 선택에 따라, 상기 축약어를 상기 축약어에 대응되는 문장으로 대체하여 표시하는 입출력부;를 포함한다. 제 2 측면에 따른 사용자 입력에 기반한 문장을 제공하는 방법은, 사용자로부터 축약어를 입력받는 단계; 상기 사용자의 상황 정보를 획득하는 단계; 상기 축약어와 상기 상황 정보에 기초하여, 상기 축약어에 대응되는 문장 을 상기 사용자에게 제공하는 단계; 및 상기 사용자의 선택에 따라, 상기 축약어를 상기 축약어에 대응되는 문 장으로 대체하여 표시하는 단계;를 포함한다. 제 3 측면에 따라, 상기 사용자 입력에 기반한 문장을 제공하는 방법을 컴퓨터에서 실행시키기 위한 프로그램을 기록한 컴퓨터로 읽을 수 있는 기록매체이다."}
{"patent_id": "10-2017-0144234", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하 첨부된 도면을 참조하면서 오로지 예시를 위한 실시예를 상세히 설명하기로 한다. 하기 실시예는 기술적 내용을 구체화하기 위한 것일 뿐 권리 범위를 제한하거나 한정하는 것이 아님은 물론이다. 상세한 설명 및 실시"}
{"patent_id": "10-2017-0144234", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "예로부터 해당 기술분야의 전문가가 용이하게 유추할 수 있는 것은 권리범위에 속하는 것으로 해석된다. 한편, 본 명세서에서 어떤 구성이 다른 구성과 \"연결\"되어 있다고 할 때, 이는 '직접적으로 연결'되어 있는 경 우뿐 아니라, '그 중간에 다른 구성을 사이에 두고 연결'되어 있는 경우도 포함한다. 또한, 어떤 구성이 다른 구성을 \"포함\"한다고 할 때, 이는 특별히 반대되는 기재가 없는 한, 그 외 다른 구성을 제외하는 것이 아니라 다른 구성들 더 포함할 수도 있다는 것을 의미한다. 또한, 본 명세서에서 사용되는 '제 1' 또는 '제 2' 등과 같이 서수를 포함하는 용어는 다양한 구성 요소들을 설 명하는데 사용할 수 있지만, 상기 구성 요소들은 상기 용어들에 의해 한정되어서는 안 된다. 상기 용어들은 하 나의 구성 요소를 다른 구성 요소로부터 구별하는 목적으로만 사용된다. 본 명세서에서 \"축약어\"란 축약된 형태의 언어을 총칭하는 용어로서, 준말(abbreviation), 약어(acronym), 약자, 등을 의미할 수 있다. 본 명세서에서 \"상황 정보(context)\"란 사용자와 다른 사용자, 시스템, 또는 디바이스의 애플리케이션 간의 상 호 작용에 영향을 미치는 환경의 특징을 규정하는 정보를 의미할 수 있다. 예를 들어, 상황 정보는 사용자의 프 로파일, 위치, 주변의 사람들을 비롯한 사용자 상황(User context)에 대한 정보를 포함할 수 있다. 또는, 상황 정보에는 조명, 소음 레벨, 교통 상태, 온도 등 물리적 상황(Physical context)에 대한 정보를 포함할 수 있다. 또는, 상황 정보는 시간, 주, 달, 계절 등 시간적 상황(Time context)에 대한 정보를 포함할 수 있다. 또한, 상 황 정보는 네트워크 연결 상태, 통신 대역폭 등 컴퓨팅 상황(Computing context)에 대한 정보를 포함할 수 있다. 이런 상황 정보들은 다양한 감지 모듈 또는 애플리케이션을 통해 파악되어, 다양한 응용 서비스 제공에 이용되거나, 다른 상황 정보와 묶여 제3의 결론을 얻는 추론에 사용될 수 있다. 본 명세서에서 \"사용자 입력에 기반한 문장을 제공하는 장치\"란 사용자로부터 입력받은 축약어에 기초하여 문장 을 제공할 수 있는 장치를 총칭하는 용어를 의미한다. 예를 들어, 스마트폰이나 노트북과 같은 휴대용 디바이스 나 데스크톱 PC와 같은 고정형 디바이스 모두가 사용자 입력에 기반한 문장을 제공하는 장치에 해당될 수 있다. 본 실시예들은 사용자 입력에 기반한 문장을 제공하는 장치 및 방법에 관한 것으로서 이하의 실시예들이 속하는 기술 분야에서 통상의 지식을 가진 자에게 널리 알려져 있는 사항들에 관해서는 자세한 설명을 생략한다. 도 1은 일 실시예에 따른 사용자 입력에 기반한 문장을 제공하는 장치를 설명하기 위한 블록도이다. 도 1에 도시된 바와 같이, 일 실시예에 따른 사용자 입력에 기반한 문장을 제공하는 장치는 메모리 , 제어부, 입출력부를 포함할 수 있다. 메모리는 제어부의 처리 및 제어를 위한 프로그램을 저장할 수 있고, 사용자 입력에 기반한 문장을 제공하는 장치로 입력되거나 사용자 입력에 기반한 문장을 제공하는 장치로부터 출력되는 데이터를 저장할 수도 있다. 메모리는 컴퓨터 실행가능 명령어(computer executable instruction)를 저장할 수 있 다. 제어부는, 통상적으로 사용자 입력에 기반한 문장을 제공하는 장치의 전반적인 동작을 제어한다. 제어부는 적어도 하나의 프로세서를 구비할 수 있다. 제어부는 그 기능 및 역할에 따라, 복수의 프 로세서들을 포함하거나, 통합된 형태의 하나의 프로세서를 포함할 수 있다. 제어부를 구성하는 적어도 하나의 프로세서는 메모리에 저장된 컴퓨터 실행가능 명령어를 실행함으 로써, 사용자로부터 입력된 축약어와 사용자 입력에 기반한 문장을 제공하는 장치에서 획득된 사용자의 상황 정 보를 분석하고, 축약어와 상황 정보에 기초하여, 축약어에 대응되는 적어도 하나의 문장을 생성할 수 있다. 제 어부를 구성하는 적어도 하나의 프로세서는 사용자로부터 입력된 축약어를 대신할 최적의 문장을 생성할 수 있다. 제어부를 구성하는 적어도 하나의 프로세서는 상황 정보를 분석하여 추출된 특징과 사용자로부터 입력된 축약어에 기초하여, 축약어에 대응되는 문장을 생성할 수 있다. 제어부를 구성하는 적어도 하나의 프로세 서는 동일한 축약어라 하더라도, 상황 정보에 따라 축약어에 대응되는 문장을 서로 다르게 생성할 수 있다. 제어부를 구성하는 적어도 하나의 프로세서는 축약어와 사용자의 상황 정보를 학습된 데이터 인식 모델에 적용하여 축약어에 대응되는 문장을 생성할 수 있다. 학습된 데이터 인식 모델은 사용자 입력에 기반한 문장을 제공하는 장치 외부의 서버에 저장되어 있거나, 사용자 입력에 기반한 문장을 제공하는 장치의 요 청에 따라 서버로부터 수신될 수 있다. 사용자의 상황 정보는 상대방에 대한 정보, 축약어의 입력이 수행되는 애플리케이션의 종류, 축약어 입력 이전 에 입력된 콘텐츠의 내용, 과거의 사용자 입력 히스토리로부터 파악되는 사용자 입력 패턴, 사용자의 위치 또는 사용자 입력이 수행된 시기 등과 같은 다양한 데이터일 수 있다. 제어부를 구성하는 적어도 하나의 프로세서는 축약어와 사용자와 상대방의 관계에 기초하여, 축약어에 대 응되는 문장을 생성할 수 있다. 다른 예로, 제어부를 구성하는 적어도 하나의 프로세서는 축약어와 애플 리케이션의 특성 또는 기능에 기초하여, 축약어에 대응되는 문장을 생성할 수 있다. 또 다른 예로, 제어부 를 구성하는 적어도 하나의 프로세서는 축약어와 축약어 입력 이전에 입력된 콘텐츠의 내용에 기초하여, 축약어에 대응되는 문장을 생성할 수 있다. 또 다른 예로, 제어부를 구성하는 적어도 하나의 프로세서는 축약어와 사용자 입력 패턴에 기초하여, 축약어에 대응되는 문장을 생성할 수 있다. 제어부를 구성하는 적어도 하나의 프로세서는 축약어와 다양한 상황 정보들의 조합에 기초하여, 축약어에 대응되는 문장을 생성할 수 있다. 한편, 제어부를 구성하는 적어도 하나의 프로세서는 사용자의 선택에 따른 축약어에 대응되는 문장에 기 초하여, 축약어와 문장 간의 관련도를 학습할 수 있다. 제어부를 구성하는 적어도 하나의 프로세서는 축 약어에 대응되는 문장을 생성하는데 이용되는 데이터 인식 모델의 학습용 데이터로써, 축약어와 사용자의 선택 에 따른 축약어에 대응되는 문장을 이용할 수 있다. 입출력부는 사용자로부터 축약어를 입력받고, 축약어에 대응되는 문장을 사용자에게 제공할 수 있다. 입 출력부는 사용자의 선택에 따라, 축약어를 축약어에 대응되는 문장으로 대체하여 표시할 수 있다. 입출력 부는 축약어에 대응되는 문장이 복수 개인 경우, 축약어를 대신할 최적의 문장을 나타내는 우선순위에 기 초하여, 축약어에 대응되는 문장을 사용자에게 제공할 수 있다. 입출력부는 축약어에 대응되는 문장에 선 택 가능한 표현이 포함되는 경우, 선택 가능한 표현을 선택할 수 있는 사용자 인터페이스를 함께 제공할 수 있 다. 도 2는 일 실시예에 따른 제어부의 블록도이다. 도 2를 참조하면, 일부 실시예에 따른 제어부는 데이터 학습부 및 데이터 인식부를 포함할 수 있다. 데이터 학습부는 축약어에 대응되는 문장을 생성하기 위한 기준을 학습할 수 있다. 데이터 학습부 는 축약어에 대응되는 문장을 생성하기 위하여 어떤 데이터를 이용할지, 데이터를 이용하여 문장을 어떻게 생성 할지에 관한 기준을 학습할 수 있다. 데이터 학습부는 학습에 이용될 학습용 데이터를 획득하고, 획득된 학습용 데이터를 후술할 데이터 인식 모델에 적용함으로써, 축약어에 대응되는 문장을 생성하기 위한 기준을 학 습할 수 있다. 데이터 학습부는 지도 학습 방식 또는 비지도 학습 방식에 따라 학습용 데이터를 이용하여 데이터 인식 모델을 학습시킬 수 있다. 일 실시예로, 데이터 학습부는 학습용 데이터로서, 문장 및 문장을 생성할 때 반영된 상황 정보를 이용할 수 있다. 데이터 학습부는 문장에 대응하는 축약어를 더 이용할 수 있으며, 이 때, 문장은 축약어를 대체 하는 문장이 될 수 있다. 상황 정보는 문장을 선택 또는 생성하는 주체, 문장을 읽는 상대방에 대한 정보, 상기 주체와 상기 상대방 간의 상호 관계에 해당하는 데이터를 포함할 수 있다. 또한, 상황 정보는, 상기 문장을 제 공하는 어플리케이션의 종류를 나타내는 데이터를 포함할 수 있다. 또한, 상황 정보는, 상기 문장 전후의 콘텐 츠(예로, 텍스트, 이미지, 동영상 또는 음성 등)를 포함할 수 있다. 또한, 상황 정보는, 상기 문장을 생성한 주 체가 과거에 입력한 히스토리로부터 파악되는 입력 패턴, 상기 문장이 생성된 시기, 상기 문장이 생성 또는 등 록된 위치(예로, 소셜 네트워크 서비스의 종류(예로, 페이스북 또는 트위터 등), 문장이 기재된 도서명 등), 문장에 대한 평가 정보, 상기 문장에 대한 댓글, 상기 댓글을 생성한 상대방에 대한 정보를 포함할 수 있다. 또한, 상황 정보는 문장 전후의 스타일 또는 문장의 스타일(예로, 형식적(formal), 비형식적(informal), 비속어, 교양어 은어 등)에 대한 정보를 포함할 수 있다. 일 실시예로, 상황 정보는 문장의 태그에 포함될 수 있다. 이 경우, 데이터 학습부는 태그에 포함된 상황 정보를 선택하여 학습용 데이터로서 이용할 수 있다. 또는, 상황 정보는 문장과 별도의 파일로 존재할 수 있다. 이 경우, 데이터 학습부는 문장이 지시하는 주소(예로, URL 등)를 참조하여 주소에 위치하는 파일을 학습 용 데이터로서 이용할 수 있다. 데이터 인식부는 다양한 종류의 데이터에 기초하여 축약어에 대응되는 문장을 생성할 수 있다. 데이터 인 식부는 학습된 데이터 인식 모델을 이용하여, 사용자로부터 입력된 축약어와 사용자의 상황 정보에 기초 하여, 축약어에 대응되는 문장을 생성할 수 있다. 데이터 인식부는 학습에 의해 기 설정된 기준에 따라 사용자로부터 입력된 축약어 및 사용자의 상황 정보를 포함하는 인식용 데이터를 획득하고, 획득된 인식용 데이 터를 입력 값으로 하여 데이터 인식 모델을 이용함으로써, 축약어에 대응되는 문장을 생성(또는, 추정, 추론, 예측)할 수 있다. 이 경우, 축약어를 입력한 사용자의 상황 정보는, 문장을 제공 받는 상대방에 대한 정보, 축약어의 입력이 수행 되는 어플리케이션의 종류, 축약어 입력 이전에 입력된 콘텐츠의 내용, 과거의 사용자 입력 히스토리로부터 파 악되는 사용자 입력 패턴, 사용자의 위치 또는 사용자의 입력이 수행된 시기 등을 포함할 수 있다. 한편, 사용자로부터 입력된 축약어 및 사용자의 상황 정보에 대응되는 인식용 데이터를 데이터 인식 모델의 입 력 값으로 하여 생성된 축약어에 대응되는 문장은, 데이터 인식 모델을 갱신하는데 이용될 수 있다. 데이터 학습부 및 데이터 인식부 중 적어도 하나는, 적어도 하나의 하드웨어 칩 형태로 제작되어 전자 장치에 탑재될 수 있다. 예를 들어, 데이터 학습부 및 데이터 인식부 중 적어도 하나는 인공 지능(AI; artificial intelligence)을 위한 전용 하드웨어 칩 형태로 제작될 수도 있고, 또는 기존의 범용 프로 세서(예: CPU 또는 application processor) 또는 그래픽 전용 프로세서(예: GPU)의 일부로 제작되어 전술한 각 종 전자 장치에 탑재될 수도 있다. 이 때, 인공 지능을 위한 전용 하드웨어 칩은 확률 연산에 특화된 전용 프로 세서로서, 기존의 범용 프로세서보다 병렬처리 성능이 높아 기계 학습과 같은 인공 지능 분야의 연산 작업을 빠 르게 처리할 수 있다. 이 경우, 데이터 학습부 및 데이터 인식부는 하나의 전자 장치에 탑재될 수도 있으며, 또는 별개의 전자 장치들에 각각 탑재될 수도 있다. 예를 들어, 데이터 학습부 및 데이터 인식부 중 하나는 전 자 장치에 포함되고, 나머지 하나는 서버에 포함될 수 있다. 또한, 데이터 학습부 및 데이터 인식부 는 유선 또는 무선으로 통하여, 데이터 학습부가 구축한 모델 정보를 데이터 인식부로 제공 할 수도 있고, 데이터 인식부로 입력된 데이터가 추가 학습 데이터로서 데이터 학습부로 제공될 수 도 있다. 한편, 데이터 학습부 및 데이터 인식부 중 적어도 하나는 소프트웨어 모듈로 구현될 수 있다. 데이 터 학습부 및 데이터 인식부 중 적어도 하나가 소프트웨어 모듈(또는, 인스터력션(instruction) 포 함하는 프로그램 모듈)로 구현되는 경우, 소프트웨어 모듈은 컴퓨터로 읽을 수 있는 판독 가능한 비일시적 판독 가능 기록매체(non-transitory computer readable media)에 저장될 수 있다. 또한, 이 경우, 적어도 하나의 소 프트웨어 모듈은 OS(Operating System)에 의해 제공되거나, 소정의 애플리케이션에 의해 제공될 수 있다. 또는, 적어도 하나의 소프트웨어 모듈 중 일부는 OS(Operating System)에 의해 제공되고, 나머지 일부는 소정의 애플 리케이션에 의해 제공될 수 있다. 도 3은 일 실시예에 따른 데이터 학습부의 블록도이다. 도 3을 참조하면, 일부 실시예에 따른 데이터 학습부는 데이터 획득부(1210-1), 전처리부(1210-2), 학습 데이터 선택부(1210-3), 모델 학습부(1210-4) 및 모델 평가부(1210-5)를 포함할 수 있다. 일부 실시예에 따른 데이터 학습부는 데이터 획득부(1210-1) 및 모델 학습부(1210-4)를 필수적으로 포함하고, 전처리부(1210- 2), 학습 데이터 선택부(1210-3) 및 모델 평가부(1210-5) 중 적어도 하나를 선택적으로 더 포함하거나, 모두 포 함하지 않을 수도 있다. 데이터 획득부(1210-1)는 축약어에 대응되는 문장을 생성하기 위한 기준을 학습하기 위하여 필요한 데이터를 획 득할 수 있다. 데이터 획득부(1210-1)는 축약어에 대응되는 문장을 생성하기 위한 학습을 위하여 필요한 데이터를 획득할 수 있다. 예를 들어, 데이터 획득부(1210-1)는 영상 데이터(예를 들어, 이미지, 동영상), 텍스트 데이터, 음성 데이터 등 을 획득할 수 있다. 예를 들어, 데이터 획득부(1210-1)는 사용자 입력에 기반한 문장을 제공하는 장치에 서 직접 입력된 데이터나 선택된 데이터 등을 획득할 수 있다. 또한, 데이터 획득부(1210-1)는 사용자 입력에 기반한 문장을 제공하는 장치에서 다양한 센서들을 이용하여 감지되는 다양한 센싱 정보들을 획득할 수 있다. 또한, 데이터 획득부(1210-1)는 사용자 입력에 기반한 문장을 제공하는 장치와 통신하는 서버와 같 은 외부 장치로부터 수신된 데이터를 획득할 수 있다. 데이터 획득부(1210-1)는 사용자로부터 입력받은 데이터, 사용자 입력에 기반한 문장을 제공하는 장치에 기 저장된 데이터, 또는 서버와 같은 외부 장치로부터 수신된 데이터 등을 획득할 수 있으나, 이에 제한되지 않 는다. 데이터 획득부(1210-1)는 사용자로부터 입력 받은 데이터, 사용자 입력에 기반한 문장을 제공하는 장치 에 기 저장된 데이터, 및 서버와 같은 외부 장치로부터 획득한 데이터를 조합하여 필요한 데이터를 획득 할 수도 있다. 전처리부(1210-2)는 축약어에 대응되는 문장을 생성하기 위한 학습에 획득된 데이터가 이용될 수 있도록, 획득 된 데이터를 전처리할 수 있다. 전처리부(1210-2)는 후술할 모델 학습부(1210-4)가 상황 판단을 위한 학습을 위 하여 획득된 데이터를 이용할 수 있도록, 획득된 데이터를 기 설정된 포맷으로 가공할 수 있다. 예를 들어, 전처리부(1210-2)는 데이터 획득부(1210-1)에서 획득한 텍스트, 이미지, 동영상, 음성 등의 데이터 에 대해, 의미 있는 데이터를 선별할 수 있도록 노이즈를 제거하거나, 소정의 형태로 가공할 수 있다. 또는, 전 처리부(1210-2)는 획득한 데이터의 형태를 학습에 적절한 데이터의 형태로 가공할 수 있다. 전처리부(1210-2)는 음성 데이터를 텍스트 데이터로 가공할 수 있다. 학습 데이터 선택부(1210-3)는 전처리된 데이터 중에서 축약어에 대응되는 문장을 생성하기 위한 학습에 필요한 학습용 데이터를 선택할 수 있다. 선택된 학습용 데이터는 모델 학습부(1210-4)에 제공될 수 있다. 학습 데이터 선택부(1210-3)는 축약어에 대응되는 문장을 생성하기 위한 기 설정된 기준에 따라, 전처리된 데이터 중에서 문 장을 생성하기 위한 학습에 필요한 학습용 데이터를 선택할 수 있다. 기 설정된 기준은, 예로, 데이터의 속성, 데이터의 생성 시간, 데이터의 생성자, 데이터의 신뢰도, 데이터의 대상, 데이터의 생성 지역 및 데이터의 크기 중 적어도 하나를 포함할 수 있다. 또한, 학습 데이터 선택부(1210-3)는 후술할 모델 학습부(1210-4)에 의한 학습에 의해 기 설정된 기준에 따라 학습용 데이터를 선택할 수도 있다. 학습 데이터 선택부(1210-3)는 텍스트, 이미지, 동영상, 음성 등의 각각의 데이터 형태마다, 데이터 선택을 위 한 기준을 가질 수 있으며, 이와 같은 기준을 이용하여 학습에 필요한 학습용 데이터를 선택할 수 있다. 학습 데이터 선택부(1210-3)는 어떤 축약어로부터 어떤 문장이 생성되는지 학습하기 위한 학습에 필요한 학습용 데이터를 선택할 수 있다. 또한, 학습 데이터 선택부(1210-3)는 어떤 축약어로부터 어떤 문장이 생성될 때, 어 떤 상황 정보가 사용되었는지 학습하기 위한 학습에 필요한 데이터를 선택할 수 있다. 학습 데이터 선택부 (1210-3)는 축약어, 축약어를 대체한 문장, 축약어를 대체한 문장을 생성할 때 반영된 상황 정보에 해당하는 다 양한 종류의 데이터를 선택할 수 있다. 예를 들어, 학습 데이터 선택부(1210-3)는 축약어를 입력하고 축약어를 대체한 문장을 선택 또는 생성하는 주체, 상대방에 대한 정보, 상기 주체와 상기 상대방 상호 간의 관계에 해당하는 데이터를 선택할 수 있다. 또 한, 학습 데이터 선택부(1210-3)는 실행된 애플리케이션의 종류를 나타내는 데이터를 선택할 수 있다. 예로, 학 습 데이터 선택부(1210-3)는 축약어 또는 문장을 제공하거나 제공 받은 어플리케이션의 종류를 나타내는 데이터 를 포함할 수 있다. 또한, 학습 데이터 선택부(1210-3)는 축약어 및 축약어를 대체한 문장의 전후의 콘텐츠(예 로, 텍스트, 이미지, 동영상, 음성) 등의 데이터를 선택할 수 있다. 또는, 학습 데이터 선택부(1210-3)는 사용 자의 위치 또는 사용자 입력이 수행된 시기에 관한 데이터를 선택할 수 있다. 또는, 학습 데이터 선택부(1210- 3)는 축약어 또는 문장이 생성된 시기, 축약어 또는 문장이 생성 또는 등록된 위치, 축약어 또는 문장에 대한 평가 정보, 축약어 또는 문장에 대한 댓글, 상기 댓글을 생성한 상대방에 대한 정보를 포함할 수 있다. 또는, 학습 데이터 선택부(1210-3)는 축약어 또는 문장의 스타일에 대한 정보를 포함할 수 있다. 또한, 학습 데이터 선택부(1210-3)는 과거의 사용자 입력 히스토리에 관한 데이터를 선택할 수 있다. 예로, 학 습 데이터 선택부(1210-3)는 축약어 또는 문장을 생성한 주체의 과거의 입력 히스토리에 관한 데이터를 선택할수 있다. 모델 학습부(1210-4)는 학습용 데이터에 기초하여 축약어에 대응되는 문장을 어떻게 생성할지에 관한 기준을 학 습할 수 있다. 또한, 모델 학습부(1210-4)는 축약어에 대응되는 문장을 생성하기 위하여 어떤 학습용 데이터를 이용해야 하는지에 대한 기준을 학습할 수도 있다. 모델 학습부(1210-4)는 축약어와 사용자의 상황 정보에 기초하여 축약어에 대응되는 문장을 어떻게 생성할지 학 습할 수 있다. 예를 들어, 모델 학습부(1210-4)는 축약어를 포함하는 단어 또는 구절에 어떤 것들이 있는지, 상 대방이 특정 상대인지 불특정 다수인지, 사용자와 상대방의 관계가 생성된 문장에 어떠한 영향을 미치는지 학습 할 수 있다. 또한, 모델 학습부(1210-4)는 실행된 애플리케이션이 채팅 애플리케이션인지, 문자 또는 이메일 애 플리케이션인지, SNS 애플리케이션인지에 따라, 애플리케이션의 기능 또는 특성이 축약어에 대응되는 문장을 생 성하는데 어떠한 영향을 미치는지 학습할 수 있다. 또한, 모델 학습부(1210-4)는 축약어를 대체한 문장의 전후 의 텍스트, 이미지, 동영상, 음성 등의 데이터로부터, 축약어와 축약어에 대응되는 문장의 관련도를 학습할 수 있다. 또한, 모델 학습부(1210-4)는 사용자의 위치 또는 사용자의 입력 시기가 축약어에 대응되는 문장 생성에 있어서 중요 상황 정보로서 동작하는지 여부를 학습할 수 있다. 또한, 모델 학습부(1210-4)는 문장에 대한 평가 정보 또는 댓글이 축약어에 대응되는 문장 생성에 있어서 중요 상황 정보로서 동작하는지 여부를 학습할 수 있 다. 또한, 모델 학습부(1210-4)는 과거의 사용자 입력 히스토리에 관한 데이터로부터 사용자의 입력 패턴을 학 습할 수 있다. 한편, 모델 학습부(1210-4)는 같은 축약어에 대하여, 서로 다른 문장이 생성된 경우, 원인에 해당할 수 있는 중 요 상황 정보가 무엇인지 학습할 수 있다. 또한, 모델 학습부(1210-4)는 축약어에 대응되는 문장을 생성하는데 이용되는 데이터 인식 모델을 학습용 데이 터를 이용하여 학습시킬 수 있다. 이 경우, 데이터 인식 모델은 미리 구축된 모델일 수 있다. 예를 들어, 데이 터 인식 모델은 기본 학습용 데이터(예를 들어, 샘플 텍스트 등)을 입력 받아 미리 구축된 모델일 수 있다. 데 이터 인식 모델은, 축약어와 상황 정보에 기초하여 축약어에 대응되는 문장을 생성(또는, 추정, 추론, 예측)하 도록 설정될 수 있다. 데이터 인식 모델은, 인식 모델의 적용 분야, 학습의 목적 또는 장치의 컴퓨터 성능 등을 고려하여 구축될 수 있다. 데이터 인식 모델은, 예를 들어, 신경망(Neural Network)을 기반으로 하는 모델일 수 있다. 데이터 인식 모델은 인간의 뇌 구조를 컴퓨터 상에서 모의하도록 설계될 수 있다. 데이터 인식 모델은 인간의 신경망의 뉴런 (neuron)을 모의하는, 가중치를 가지는 복수의 네트워크 노드들을 포함할 수 있다. 복수의 네트워크 노드들은 시냅스(synapse)를 통하여 신호를 주고 받는 뉴런의 시냅틱(synaptic) 활동을 모의하도록 각각 연결 관계를 형 성할 수 있다. 데이터 인식 모델은, 일 예로, 신경망 모델, 또는 신경망 모델에서 발전한 딥 러닝 모델을 포함 할 수 있다. 딥 러닝 모델에서 복수의 네트워크 노드들은 서로 다른 깊이(또는, 레이어)에 위치하면서 컨볼루션 (convolution) 연결 관계에 따라 데이터를 주고 받을 수 있다. 예컨대, DNN(Deep Neural Network), RNN(Recurrent Neural Network), BRDNN(Bidirectional Recurrent Deep Neural Network)과 같은 모델이 데이터 인식 모델로서 사용될 수 있으나, 이에 한정되지 않는다. 다양한 실시예에 따르면, 모델 학습부(1210-4)는 미리 구축된 데이터 인식 모델이 복수 개가 존재하는 경우, 입 력된 학습용 데이터와 기본 학습용 데이터의 관련성이 큰 데이터 인식 모델을 학습할 데이터 인식 모델로 결정 할 수 있다. 이 경우, 기본 학습용 데이터는 데이터의 타입 별로 기 분류되어 있을 수 있으며, 데이터 인식 모 델은 데이터의 타입 별로 미리 구축되어 있을 수 있다. 예를 들어, 기본 학습용 데이터는 학습용 데이터가 생성 된 지역, 학습용 데이터가 생성된 시간, 학습용 데이터의 크기, 학습용 데이터의 장르, 학습용 데이터의 생성자, 학습용 데이터 내의 오브젝트의 종류 등과 같은 다양한 기준으로 기 분류되어 있을 수 있다. 또한, 모델 학습부(1210-4)는, 예를 들어, 오류 역전파법(error back-propagation) 또는 경사 하강법(gradient descent)을 포함하는 학습 알고리즘 등을 이용하여 데이터 인식 모델을 학습시킬 수 있다. 또한, 모델 학습부(1210-4)는, 예를 들어, 학습용 데이터를 입력 값으로 하는 지도 학습(supervised learning) 을 통하여, 데이터 인식 모델을 학습시킬 수 있다. 또한, 모델 학습부(1210-4)는, 예를 들어, 별다른 지도없이 축약어에 대응되는 문장을 생성하기 위해 필요한 데이터의 종류를 스스로 학습함으로써, 축약어에 대응되는 문 장을 생성하기 위한 기준을 발견하는 비지도 학습(unsupervised learning)을 통하여, 데이터 인식 모델을 학습 시킬 수 있다. 또한, 모델 학습부(1210-4)는, 예를 들어, 학습에 따른 축약어에 대응되는 문장을 생성한 결과가 올바른지에 대한 피드백을 이용하는 강화 학습(reinforcement learning)을 통하여, 데이터 인식 모델을 학습시킬 수 있다. 또한, 모델 학습부(1210-4)는 상황 정보를 고려하여 축약어에 대응되는 문장을 생성하도록 설정된 복수 개의 데 이터 인식 모델들을 생성할 수도 있다. 예로, 모델 학습부(1210-4)는 문장의 스타일, 문장을 제공하는 어플리케 이션의 종류, 문장을 읽는 상대방, 문장이 생성되는 위치에 따라 구분된 복수 개의 데이터 인식 모델들을 생성 할 수 있다. 데이터 인식 모델이 학습되면, 모델 학습부(1210-4)는 학습된 데이터 인식 모델을 저장할 수 있다. 이 경우, 모 델 학습부(1210-4)는 학습된 데이터 인식 모델을 데이터 인식부를 포함하는 전자 장치의 메모리에 저장할 수 있다. 또는, 모델 학습부(1210-4)는 학습된 데이터 인식 모델을 후술할 데이터 인식부를 포함하는 전 자 장치의 메모리에 저장할 수 있다. 또는, 모델 학습부(1210-4)는 학습된 데이터 인식 모델을 전자 장치와 유 선 또는 무선 네트워크로 연결되는 서버의 메모리에 저장할 수도 있다. 이 경우, 학습된 데이터 인식 모델이 저장되는 메모리는, 예를 들면, 전자 장치의 적어도 하나의 다른 구성요소 에 관계된 명령 또는 데이터를 함께 저장할 수도 있다. 또한, 메모리는 소프트웨어 및/또는 프로그램을 저장할 수도 있다. 프로그램은, 예를 들면, 커널, 미들웨어, 어플리케이션 프로그래밍 인터페이스(API) 및/또는 어플리 케이션 프로그램(또는 \"어플리케이션\") 등을 포함할 수 있다. 모델 평가부(1210-5)는 데이터 인식 모델에 평가 데이터를 입력하고, 평가 데이터로부터 출력되는 인식 결과가 소정 기준을 만족하지 못하는 경우, 모델 학습부(1210-4)로 하여금 다시 학습하도록 할 수 있다. 이 경우, 평가 데이터는 데이터 인식 모델을 평가하기 위한 기 설정된 데이터일 수 있다. 예를 들어, 모델 평가부(1210-5)는 평가 데이터에 대한 학습된 데이터 인식 모델의 인식 결과 중에서, 인식 결 과가 정확하지 않은 평가 데이터의 개수 또는 비율이 미리 설정된 임계치를 초과하는 경우 소정 기준을 만족하 지 못한 것으로 평가할 수 있다. 예컨대, 소정 기준이 비율 2%로 정의되는 경우, 학습된 데이터 인식 모델이 총 1000개의 평가 데이터 중의 20개를 초과하는 평가 데이터에 대하여 잘못된 인식 결과를 출력하는 경우, 모델 평 가부(1210-5)는 학습된 데이터 인식 모델이 적합하지 않은 것으로 평가할 수 있다. 한편, 학습된 데이터 인식 모델이 복수 개가 존재하는 경우, 모델 평가부(1210-5)는 각각의 학습된 데이터 인식 모델에 대하여 소정 기준을 만족하는지를 평가하고, 소정 기준을 만족하는 모델을 최종 데이터 인식 모델로서 결정할 수 있다. 이 경우, 소정 기준을 만족하는 모델이 복수 개인 경우, 모델 평가부(1210-5)는 평가 점수가 높은 순으로 미리 설정된 어느 하나 또는 소정 개수의 모델을 최종 데이터 인식 모델로서 결정할 수 있다. 한편, 데이터 학습부 내의 데이터 획득부(1210-1), 전처리부(1210-2), 학습 데이터 선택부(1210-3), 모델 학습부(1210-4) 및 모델 평가부(1210-5) 중 적어도 하나는, 적어도 하나의 하드웨어 칩 형태로 제작되어 전자 장치에 탑재될 수 있다. 예를 들어, 데이터 획득부(1210-1), 전처리부(1210-2), 학습 데이터 선택부(1210-3), 모델 학습부(1210-4) 및 모델 평가부(1210-5) 중 적어도 하나는 인공 지능(AI; artificial intelligence)을 위 한 전용 하드웨어 칩 형태로 제작될 수도 있고, 또는 기존의 범용 프로세서(예: CPU 또는 application processor) 또는 그래픽 전용 프로세서(예: GPU)의 일부로 제작되어 전술한 각종 전자 장치에 탑재될 수도 있다. 또한, 데이터 획득부(1210-1), 전처리부(1210-2), 학습 데이터 선택부(1210-3), 모델 학습부(1210-4) 및 모델 평가부(1210-5)는 하나의 전자 장치에 탑재될 수도 있으며, 또는 별개의 전자 장치들에 각각 탑재될 수도 있다. 예를 들어, 데이터 획득부(1210-1), 전처리부(1210-2), 학습 데이터 선택부(1210-3), 모델 학습부(1210-4) 및 모델 평가부(1210-5) 중 일부는 전자 장치에 포함되고, 나머지 일부는 서버에 포함될 수 있다. 또한, 데이터 획득부(1210-1), 전처리부(1210-2), 학습 데이터 선택부(1210-3), 모델 학습부(1210-4) 및 모델 평가부(1210-5) 중 적어도 하나는 소프트웨어 모듈로 구현될 수 있다. 데이터 획득부(1210-1), 전처리부(1210- 2), 학습 데이터 선택부(1210-3), 모델 학습부(1210-4) 및 모델 평가부(1210-5) 중 적어도 하나가 소프트웨어 모듈(또는, 인스터력션(instruction) 포함하는 프로그램 모듈)로 구현되는 경우, 소프트웨어 모듈은 컴퓨터로 읽을 수 있는 판독 가능한 비일시적 판독 가능 기록매체(non-transitory computer readable media)에 저장될 수 있다. 또한, 이 경우, 적어도 하나의 소프트웨어 모듈은 OS(Operating System)에 의해 제공되거나, 소정의 애플리케이션에 의해 제공될 수 있다. 또는, 적어도 하나의 소프트웨어 모듈 중 일부는 OS(Operating System)에 의해 제공되고, 나머지 일부는 소정의 애플리케이션에 의해 제공될 수 있다. 도 4는 일 실시예에 따른 데이터 인식부의 블록도이다. 도 4를 참조하면, 일부 실시예에 따른 데이터 인식부는 데이터 획득부(1220-1), 전처리부(1220-2), 인식 데이터 선택부(1220-3), 인식 결과 제공부(1220-4) 및 모델 갱신부(1220-5)를 포함할 수 있다. 일부 실시예에 따른, 데이터 인식부는 데이터 획득부(1220-1) 및 인식 결과 제공부(1220-4)를 필수적으로 포함하고, 전 처리부(1220-2), 인식 데이터 선택부(1220-3) 및 모델 갱신부(1220-5) 중 적어도 하나를 선택적으로 더 포함할 수 있다. 데이터 인식부는 학습된 데이터 인식 모델을 이용하여, 사용자로부터 입력된 축약어와 사용자의 상황 정 보에 기초하여, 축약어에 대응되는 문장을 생성할 수 있다. 데이터 획득부(1220-1)는 축약어에 대응되는 문장을 생성하기 위해 필요한 다양한 종류의 데이터를 획득할 수 있다. 예를 들어, 데이터 획득부(1220-1)는 영상 데이터, 텍스트 데이터, 음성 데이터 등을 획득할 수 있다. 예 를 들어, 데이터 획득부(1220-1)는 사용자 입력에 기반한 문장을 제공하는 장치에서 직접 입력된 데이터 나 선택된 데이터 등을 획득하거나, 사용자 입력에 기반한 문장을 제공하는 장치에서 다양한 센서들을 이 용하여 감지되는 다양한 센싱 정보들을 획득할 수 있다. 또한, 데이터 획득부(1220-1)는 사용자 입력에 기반한 문장을 제공하는 장치와 통신하는 서버와 같은 외부 장치로부터 수신된 데이터를 획득할 수 있다. 예로, 데이터 획득부는 축약어에 대응되는 문장을 생성하기 위하여 사용자로부터 입력된 축약어를 획득할 수 있다. 전처리부(1220-2)는 축약어에 대응되는 문장을 생성하기 위해 획득된 데이터가 이용될 수 있도록, 획득된 데이 터를 전처리할 수 있다. 전처리부(1220-2)는 후술할 인식 결과 제공부(1220-4)가 축약어에 대응되는 문장을 생 성하기 위하여 획득된 데이터를 이용할 수 있도록, 획득된 데이터를 기 설정된 포맷으로 가공할 수 있다. 예를 들어, 전처리부(1220-2)는 데이터 획득부(1220-1)에서 획득한 텍스트, 이미지, 동영상, 음성 등의 데이터 에 대해, 의미 있는 데이터를 선별할 수 있도록 노이즈를 제거하거나, 소정의 형태로 가공할 수 있다. 또는, 전 처리부(1220-2)는 획득한 데이터의 형태를 학습에 적절한 데이터의 형태로 가공할 수 있다. 전처리부(1220-2)는 음성 데이터를 텍스트 데이터로 가공할 수 있다. 인식 데이터 선택부(1220-3)는 전처리된 데이터 중에서 축약어에 대응되는 문장을 생성하는데 필요한 인식용 데 이터를 선택할 수 있다. 선택된 인식용 데이터는 인식 결과 제공부(1220-4)에게 제공될 수 있다. 인식 데이터 선택부(1220-3)는 축약어에 대응되는 문장을 생성하기 위한 기 설정된 기준에 따라, 전처리된 데이터 중에서 일 부 또는 전부를 선택할 수 있다. 또한, 인식 데이터 선택부(1220-3)는 전술한 모델 학습부(1210-4)에 의한 학습 에 의해 기 설정된 기준에 따라 데이터를 선택할 수도 있다. 기 설정된 기준은, 예로, 데이터의 속성, 데이터의 생성 시간, 데이터의 생성자, 데이터의 신뢰도, 데이터의 대상, 데이터의 생성 지역 및 데이터의 크기 중 적어 도 하나를 포함할 수 있다. 예를 들어, 인식 데이터 선택부(1220-3)는 축약어를 입력하고 축약어를 대체한 문장을 선택 또는 생성하는 주체, 상대방에 대한 정보, 상기 주체와 상기 상대방 상호 간의 관계에 해당하는 데이터를 선택할 수 있다. 또 한, 인식 데이터 선택부(1220-3)는 실행된 애플리케이션(예로, 축약어를 제공 받는 어플리케이션)의 종류를 나 타내는 데이터를 선택할 수 있다. 또한, 인식 데이터 선택부(1220-3)는 축약어 및 축약어를 대체한 문장의 전후 의 콘텐츠(예로, 텍스트, 이미지, 동영상, 음성) 등의 데이터를 선택할 수 있다. 또한, 인식 데이터 선택부 (1220-3)는 사용자의 위치 또는 사용자 입력이 수행된 시기에 관한 데이터를 선택할 수 있다. 또한, 인식 데이 터 선택부(1220-3)는 과거의 사용자 입력 히스토리에 관한 데이터를 선택할 수 있다. 인식 데이터 선택부(1220- 3)에서 선택된 적어도 하나의 데이터는 축약어에 대응되는 문장을 생성할 때, 상황 정보로써 이용될 수 있다. 인식 결과 제공부(1220-4)는 선택된 데이터를 데이터 인식 모델에 적용하여 축약어에 대응되는 문장을 생성(또 는, 추정, 추론, 예측)할 수 있다. 인식 결과 제공부(1220-4)는 데이터의 인식 목적에 따라 축약어에 대응되는 문장을 제공할 수 있다. 인식 결과 제공부(1220-4)는 인식 데이터 선택부(1220-3)에 의해 선택된 데이터를 입력 값으로 이용함으로써, 선택된 데이터를 데이터 인식 모델에 적용할 수 있다. 또한, 인식 결과는 데이터 인식 모 델에 의해 결정될 수 있다. 인식 결과 제공부(1220-4)는 축약어와 사용자의 상황 정보에 기초하여 축약어에 대 응되는 문장을 생성할 수 있다. 인식 결과 제공부(1220-4)는 축약어를 포함하는 단어 또는 구절, 문장에 어떤 것들이 있는지 확인하고, 상대방 이 특정 상대인지 불특정 다수인지, 사용자와 상대방의 관계를 고려하여 축약어에 대응되는 문장을 생성할 수 있다. 예를 들어, 인식 결과 제공부(1220-4)는 사용자에 의해 입력된 축약어에 대응될 수 있는 모든 단어 또는 구절, 문장을 확인할 수 있다. 또한, 인식 결과 제공부(1220-4)는 상대방이 특정 상대인 경우, 사용자와 상대방의 관계에 따라, 어투나 높임말과 같은 표현을 문장을 생성할 때 반영할 수 있다. 인식 결과 제공부(1220-4)는 특정 상대방이 아닌 불특정 다수에게 제공하는 글인 경우, 사용자의 평소 입력 패턴에 기초하여 축약어에 대응 되는 문장을 생성할 수 있다. 또한, 인식 결과 제공부(1220-4)는 실행된 애플리케이션이 채팅 애플리케이션인지, 문자 또는 이메일 애플리케 이션인지, SNS 애플리케이션인지에 따라, 애플리케이션의 특성 또는 기능을 축약어에 대응되는 문장을 생성하는 데 반영할 수 있다. 예를 들어, 사용자 입력이 수행되는 애플리케이션이 채팅 애플리케이션인 경우, 인식 결과 제공부(1220-4)는 대화 내용의 맥락 또는 대화 주제에 부합하는 축약어에 대응되는 문장을 생성할 수 있다. 인 식 결과 제공부(1220-4)는 축약어에 대응되는 문장을 생성함에 있어 축약어가 입력되기 직전의 상대방이 입력한 문장에 대한 답변을 자동완성하는 것에 초점을 둘 수 있다. 다른 예로, 사용자 입력이 수행되는 애플리케이션이 문자 또는 이메일 애플리케이션인 경우, 인식 결과 제공부(1220-4)는 상대방과 이전에 주고 받은 문자 또는 메 일 히스토리에 공통으로 나오는 내용이나 콘텐츠 분야에 기초하여, 축약어에 대응되는 문장을 생성할 수 있다. 다른 예로, 사용자 입력이 수행되는 애플리케이션이 SNS 애플리케이션인 경우, 특정 SNS에서만 사용되는 단어 또는 말투에 기초하여, 축약어에 대응되는 문장을 생성할 수 있다. 또한, 인식 결과 제공부(1220-4)는 축약어 입력 이전에 입력된 콘텐츠의 내용에 기초하여 축약어에 대응되는 문 장을 생성할 수 있다. 인식 결과 제공부(1220-4)는 축약어가 입력되기 전의 텍스트, 이미지, 동영상, 음성 등의 데이터에 기초하여, 축약어에 대응되는 문장을 생성할 수 있다. 예를 들어, 인식 결과 제공부(1220-4)는 축약어 가 입력되기 전의 텍스트에서 사용자가 입력한 축약어와 동일한 형태의 축약어를 가질 수 있는 단어 또는 구절 을 추출할 수 있다. 또한, 인식 결과 제공부(1220-4)는 이미지 또는 동영상에 포함된 객체에 관한 정보에 기초 하여, 축약어에 대응되는 문장을 생성할 수 있다. 또한, 인식 결과 제공부(1220-4)는 음성 데이터를 텍스트 변 환하거나 음성 데이터에 관한 정보에 기초하여, 축약어에 대응되는 문장을 생성할 수 있다. 또한, 인식 결과 제공부(1220-4)는 사용자의 위치 또는 사용자 입력이 수행된 시기에 관한 데이터에 기초하여, 축약어에 대응되는 문장을 생성할 수 있다. 예를 들어, 인식 결과 제공부(1220-4)는 사용자 입력에 기반한 문장 을 제공하는 장치에서 획득된 사용자의 위치 또는 사용자 입력이 수행된 시기에 기초하여, 축약어에 대응 되는 문장을 생성할 수 있다. 또한, 인식 결과 제공부(1220-4)는 과거의 사용자 입력 히스토리에 관한 데이터에 기초하여, 축약어에 대응되는 문장을 생성할 수 있다. 예를 들어, 인식 결과 제공부(1220-4)는 과거의 사용자 입력 히스토리로부터 파악된 문 장 구성 습관 또는 빈도가 높은 표현과 같은 사용자의 입력 패턴에 기초하여, 축약어에 대응되는 문장을 생성할 수 있다. 인식 결과 제공부(1220-4)에서 생성된 축약어에 대응되는 문장이 복수 개인 경우, 인식 결과 제공부(1220-4)는 축약어를 대신할 최적의 문장을 나타내는 우선순위를 함께 제공할 수 있다. 이 경우, 가장 우선순위가 높은 문 장이 축약어에 대응되는 문장으로서 사용자에게 제공될 수 있다. 또는, 복수 개의 문장들이 우선순위에 따라 정 렬되어 사용자에게 제공될 수 있다. 한편, 인식 결과 제공부(1220-4)는 같은 축약어에 대하여, 상황 정보에 따라 서로 다른 문장을 생성할 수 있다. 예로, 상황 정보로서 대화 주제가 식당에 관한 주제이며, 사용자로부터 입력된 축약어가 \"ㅇㅌㄹㅇ ㅊㅇㅈ\"인 것으로 판단되면, 인식 결과 제공부(1220-4)는 축약어에 대응되는 문장으로서 \"이탈리안 식당 찾아줘\"이라는 문 장을 생성할 수 있다. 반면에, 상황 정보로서 대화 주제가 집에 관한 주제이며, 사용자로부터 입력된 축약어가 동일한 \"ㅇㅌㄹㅇ ㅊㅇㅈ\"인 것으로 판단되면, 인식 결과 제공부(1220-4)는 축약어에 대응되는 문장으로서 \"인 테리어 업체 찾아줘\"라는 문장을 생성할 수 있다. 모델 갱신부(1220-5)는 인식 결과 제공부(1220-4)에 의해 제공되는 인식 결과에 대한 평가에 기초하여, 데이터 인식 모델이 갱신되도록 할 수 있다. 예를 들어, 모델 갱신부(1220-5)는 인식 결과 제공부(1220-4)에 의해 제공 되는 축약어에 대응되는 문장을 모델 학습부(1210-4)에게 제공함으로써, 모델 학습부(1210-4)가 데이터 인식 모 델을 갱신하도록 할 수 있다. 모델 갱신부(1220-5)는 인식 결과 제공부(1220-4)에서 축약어에 대응되는 문장을 생성할 때 이용한 상황 정보에 해당하는 다양한 데이터와 축약어를 축약어에 대응되는 문장과 함께 모델 학습부 (1210-4)에 제공할 수 있다. 이 경우, 축약어에 대응되는 문장은 사용자의 피드백으로서 사용자에 의하여 선택 된 문장이 될 수 있다. 예로, 인식 결과 제공부(1220-4)에서 제공되는 문장들이 복수 개인 경우, 우선순위에 따 라 정렬되어 복수 개의 문장들이 사용자에게 제공될 수 있다. 이 경우, 모델 갱신부(1220-5)는 복수 개의 문장 들 중에서 사용자에 의하여 선택된 문장, 상기 문장에 대응되는 축약어, 상기 문장을 생성할 때 이용한 상황 정보에 해당하는 데이터를 모델 학습부(1210-4)에게 제공할 수 있다. 또는, 인식 결과 제공부(1220-4)에서 제공되 는 문장에 선택 가능한 표현이 포함되는 경우, 복수 개의 표현들 중 선택 가능한 표현을 선택할 수 있는 사용자 인터페이스가 사용자에게 제공될 수 있다. 이 경우, 모델 갱신부(1220-5)는 사용자에 의하여 선택된 표현을 포 함하는 문장, 상기 문장에 대응하는 축약어, 상기 문장을 생성할 때 이용한 상황 정보에 해당하는 데이터를 모 델 학습부(1210-4)에게 제공할 수 있다. 한편, 데이터 인식부 내의 데이터 획득부(1220-1), 전처리부(1220-2), 인식 데이터 선택부(1220-3), 인식 결과 제공부(1220-4) 및 모델 갱신부(1220-5) 중 적어도 하나는, 적어도 하나의 하드웨어 칩 형태로 제작되어 전자 장치에 탑재될 수 있다. 예를 들어, 데이터 획득부(1220-1), 전처리부(1220-2), 인식 데이터 선택부(1220- 3), 인식 결과 제공부(1220-4) 및 모델 갱신부(1220-5) 중 적어도 하나는 인공 지능(AI; artificial intelligence)을 위한 전용 하드웨어 칩 형태로 제작될 수도 있고, 또는 기존의 범용 프로세서(예: CPU 또는 application processor) 또는 그래픽 전용 프로세서(예: GPU)의 일부로 제작되어 전술한 각종 전자 장치에 탑재 될 수도 있다. 또한, 데이터 획득부(1220-1), 전처리부(1220-2), 인식 데이터 선택부(1220-3), 인식 결과 제공부(1220-4) 및 모델 갱신부(1220-5)는 하나의 전자 장치에 탑재될 수도 있으며, 또는 별개의 전자 장치들에 각각 탑재될 수도 있다. 예를 들어, 데이터 획득부(1220-1), 전처리부(1220-2), 인식 데이터 선택부(1220-3), 인식 결과 제공부 (1220-4) 및 모델 갱신부(1220-5) 중 일부는 전자 장치에 포함되고, 나머지 일부는 서버에 포함될 수 있다. 또한, 데이터 획득부(1220-1), 전처리부(1220-2), 인식 데이터 선택부(1220-3), 인식 결과 제공부(1220-4) 및 모델 갱신부(1220-5) 중 적어도 하나는 소프트웨어 모듈로 구현될 수 있다. 데이터 획득부(1220-1), 전처리부 (1220-2), 인식 데이터 선택부(1220-3), 인식 결과 제공부(1220-4) 및 모델 갱신부(1220-5) 중 적어도 하나가 소프트웨어 모듈(또는, 인스터력션(instruction) 포함하는 프로그램 모듈)로 구현되는 경우, 소프트웨어 모듈은 컴퓨터로 읽을 수 있는 판독 가능한 비일시적 판독 가능 기록매체(non-transitory computer readable media)에 저장될 수 있다. 또한, 이 경우, 적어도 하나의 소프트웨어 모듈은 OS(Operating System)에 의해 제공되거나, 소정의 애플리케이션에 의해 제공될 수 있다. 또는, 적어도 하나의 소프트웨어 모듈 중 일부는 OS(Operating System)에 의해 제공되고, 나머지 일부는 소정의 애플리케이션에 의해 제공될 수 있다. 도 5는 일부 실시예에 따른 사용자 입력에 기반한 문장을 제공하는 장치 및 서버가 서로 연동함으 로써 데이터를 학습하고 인식하는 예시를 나타내는 도면이다. 장치의 데이터 인식부는, 예로, 도 4의 데이터 인식부에 대응될 수 있다. 또한, 장치 의 데이터 인식부에 포함되는 데이터 획득부(1220-1), 전처리부(1220-2), 인식 데이터 선택부(1220-3), 인식 결과 제공부(1220-4) 및 모델 갱신부(1220-5) 각각은, 도 4의 데이터 인식부에 포함되는 데이터 획 득부(1220-1), 전처리부(1220-2), 인식 데이터 선택부(1220-3), 인식 결과 제공부(1220-4) 및 모델 갱신부 (1220-5)에 각각 대응될 수 있다. 또한, 서버의 데이터 학습부에 포함되는 데이터 획득부(2210-1), 전처리부(2210-2), 학습 데이터 선택부(2210-3), 모델 학습부(2210-4) 및 모델 평가부(2210-5) 각각은, 도 3의 데이터 학습부의 데이터 획득부(1210-1), 전처리부(1210-2), 학습 데이터 선택부(1210-3), 모델 학습부 (1210-4), 모델 평가부(1210-5)에 각각 대응될 수 있다. 장치는 근거리 통신 또는 원거리 통신을 통하여 서버와 서로 연결될 수 있다. 장치 및 서버 가 서로 연결된다는 것은 장치 및 서버가 직접 연결되거나, 또는 다른 구성 요소(예로, 제3 구성요소로서, AP(access point), 허브(hub), 중계기기, 기지국, 공유기 및 게이트웨이(gateway) 중 적어도 하 나)를 통하여 연결되는 것을 포함할 수 있다. 도 5를 참조하면, 서버는 축약어에 대응되는 문장을 생성하기 위한 기준을 학습할 수 있으며, 사용자 입 력에 기반한 문장을 제공하는 장치는 서버에서 학습된 데이터 인식 모델을 이용하여, 사용자로부터 입력된 축약어와 사용자의 상황 정보에 기초하여, 축약어에 대응되는 문장을 생성할 수 있다. 이 경우, 서버의 데이터 학습부는 도 3에 도시된 데이터 학습부의 기능을 수행할 수 있다. 서버의 데이터 학습부는 축약어에 대응되는 문장을 생성하기 위하여 어떤 데이터를 이용할지, 데이 터를 이용하여 문장을 어떻게 생성할지에 관한 기준을 학습할 수 있다. 서버의 데이터 학습부는 학 습에 이용될 데이터를 획득하고, 획득된 데이터를 후술할 데이터 인식 모델에 적용함으로써, 축약어에 대응되는 문장을 생성하기 위한 기준을 학습할 수 있다. 예로, 데이터 학습부는 축약어, 축약어에 대응되는 문장 및 상황 정보를 이용하여 축약어에 대응되는 문장을 생성하도록 설정된 데이터 인식 모델을 생성할 수 있다. 또한, 사용자 입력에 기반한 문장을 제공하는 장치의 인식 결과 제공부(1220-4)는 인식 데이터 선택부 (1220-3)에 의해 선택된 데이터를 서버에 의해 생성된 데이터 인식 모델에 적용하여 축약어에 대응되는 문장을 생성할 수 있다. 예를 들어, 인식 결과 제공부(1220-4)는 인식 데이터 선택부(1220-3)에 의해 선택된 데 이터를 서버에게 전송하고, 서버가 인식 데이터 선택부(1220-3)에 의해 선택된 데이터를 인식 모델 에 적용하여 축약어에 대응되는 문장을 생성할 것을 요청할 수 있다. 또한, 인식 결과 제공부(1220-4)는 서버 에 의해 생성된 축약어에 대응되는 문장을 서버로부터 수신할 수 있다. 예를 들어, 사용자 입력에 기반한 문장을 제공하는 장치는 사용자로부터 입력된 축약어와 사용자 입력에 기반한 문장을 제공하는 장치에서 획득된 사용자의 상황 정보를 서버로 전송할 수 있다. 서버 는 사용자 입력에 기반한 문장을 제공하는 장치로부터 수신된 축약어와 상황 정보를 서버에 저장된 데이터 인식 모델에 적용시킴으로써, 축약어에 대응되는 문장을 생성할 수 있다. 서버는 서버 에서 획득된 사용자의 상황 정보를 더 반영하여, 축약어에 대응되는 문장을 생성할 수 있다. 서버 에서 생성된 축약어에 대응되는 문장은 사용자 입력에 기반한 문장을 제공하는 장치로 전송될 수 있다. 또는, 사용자 입력에 기반한 문장을 제공하는 장치의 인식 결과 제공부(1320-4)는 서버에 의해 생 성된 데이터 인식 모델을 서버로부터 수신하고, 수신된 데이터 인식 모델을 이용하여 축약어에 대응되는 문장을 생성할 수 있다. 이 경우, 사용자 입력에 기반한 문장을 제공하는 장치의 인식 결과 제공부(1220- 4)는 인식 데이터 선택부(1220-3)에 의해 선택된 데이터를 서버로부터 수신된 데이터 인식 모델에 적용하 여 축약어에 대응되는 문장을 생성할 수 있다. 사용자 입력에 기반한 문장을 제공하는 장치는 사용자로부 터 입력된 축약어와 사용자 입력에 기반한 문장을 제공하는 장치에서 획득된 사용자의 상황 정보를 서버 로부터 수신된 데이터 인식 모델에 적용시킴으로써, 축약어에 대응되는 문장을 생성할 수 있다. 서버 는 서버에서 획득된 사용자의 상황 정보를 사용자 입력에 기반한 문장을 제공하는 장치로 전 송하여, 사용자 입력에 기반한 문장을 제공하는 장치가 축약어에 대응되는 문장을 생성할 때 더 이용하도 록 할 수 있다. 예로, 장치는 서버로부터 생성된 데이터 인식 모델을 수신하여 메모리에 저 장할 수 있다. 장치는 주기적 또는 비주기적(예로, 장치의 요청 시)으로 갱신된 데이터 인식 모델 을 서버로부터 수신할 수도 있다. 이 경우, 장치의 인식 결과 제공부(1220-4)는 인식 데이터 선택 부(1220-3)에 의해 선택된 데이터를 메모리에 저장된 데이터 인식 모델에 적용하여 축약어에 대응되는 문 장을 생성할 수 있다. 도 6은 일 실시예에 따른 사용자 입력에 기반한 문장을 제공하는 장치에서 축약어에 대응되는 문장을 제 공하는 과정을 설명하기 위한 도면이다. 사용자 입력에 기반한 문장을 제공하는 장치에서 사용자 입력이 가능한 애플리케이션이 실행되면, 도 6에 도시된 바와 같이, 사용자 입력을 위한 사용자 인터페이스가 제공될 수 있다. 사용자 입력이 가능한 애플리케이 션은 채팅 애플리케이션, 이메일 애플리케이션, 문자 애플리케이션, SNS 애플리케이션, 커뮤니티 애플리케이션 등이 될 수 있다. 사용자 입력을 위한 사용자 인터페이스는 입력창과 자판을 포함할 수 있으며, 도 6에서는 한 글 자판인 경우를 설명한다. 한국어의 경우, 사용자가 자신이 쓰고자 하는 문장의 축약어로써, 각 글자의 초성에 해당하는 자음들만을 입력 할 수 있다. 이때, 사용자 입력에 기반한 문장을 제공하는 장치는 사용자 편의를 증대시키기 위해, 자음 만 있는 자판을 제공할 수 있다. 도 6에 도시된 바와 같이, 사용자는 \"ㅈㄱㅇㄷ\"라고 자음들로 구성된 축약어를 입력할 수 있다. 사용자 입력에 기반한 문장을 제공하는 장치는 사용자로부터 축약어를 입력받기 전 또는 후에 사용자의 상황 정보를 획득할 수 있다. 일 예로, 사용자가 사용자 입력에 기반한 문장을 제공하는 장치에서 사용자 입력이 가능한 애플리케이션을 실행하고, 상대방을 선택하거나 소정의 기능을 실행하는 경우, 사용자 입력에 기 반한 문장을 제공하는 장치는 축약어를 입력받기 전이라도 사용자의 상황 정보를 획득할 수 있다. 다른 예로, 사용자 입력에 기반한 문장을 제공하는 장치는 사용자가 사용자 입력에 기반한 문장을 제공하는 장 치에 축약어 입력을 시작한 후에 상황 정보를 획득할 수도 있다. 상황 정보가 상대방에 대한 정보인 경우, 사용자 입력에 기반한 문장을 제공하는 장치는 상대방이 특정인 인지 불특정 다수인지 확인하여, 상대방이 특정인이라면 상대방의 이름, 별명, 나이 또는 성별 등의 다양한 정 보로부터 사용자와 상대방의 관계를 파악할 수 있다. 예를 들어, 도 6에서, 상대방의 이름이 \"아내\"라고 저장되 어 있는 것으로부터, 사용자 입력에 기반한 문장을 제공하는 장치는 상대방과 사용자가 부부임을 파악할수 있다. 상황 정보가 축약어의 입력이 수행되는 애플리케이션의 종류인 경우, 사용자 입력에 기반한 문장을 제공하는 장 치는 실행된 애플리케이션이 무엇인지 확인하여, 실행된 애플리케이션의 특성 또는 기능을 파악할 수 있 다. 예를 들어, 도 6에서 실행된 애플리케이션이 채팅 애플리케이션임을 확인함으로써, 사용자 입력에 기반한 문장을 제공하는 장치는 채팅 애플리케이션이 메시지를 비롯한 다양한 콘텐츠를 주고받는 특성이 있음을 파악하거나 콘텐츠 송수신을 위한 다양한 기능이 있음을 파악할 수 있다. 상황 정보가 축약어 입력 이전에 입력된 콘텐츠의 내용인 경우, 사용자 입력에 기반한 문장을 제공하는 장치 는 사용자의 축약어 입력 이전에 사용자가 어떤 콘텐츠들을 입력했는지 확인하여, 특정 상대방, 특정 시 기, 특정 주제 등의 다양한 카테고리별로 축약어 입력 이전에 입력된 콘텐츠의 내용을 파악할 수 있다. 예를 들 어, 도 6에서, 축약어 입력 이전에 입력된 콘텐츠들이 존재한다면, 사용자 입력에 기반한 문장을 제공하는 장치 는 현재 채팅 상대방인 아내와 이전에 주고받은 콘텐츠들이 무엇이 있는지, 최근 1주일 동안 어떤 콘텐츠 들이 입력되었었는지, 대화에 반복적으로 등장한 주제가 무엇이었는지 등을 파악할 수 있다. 상황 정보가 과거의 사용자 입력 히스토리로부터 파악되는 사용자 입력 패턴인 경우, 사용자 입력에 기반한 문 장을 제공하는 장치는 사용자의 축약어 입력 이전에 사용자가 어떠한 방식으로 입력하였는지 확인하여, 문장 구성 습관 또는 빈도가 높은 표현들과 같은 사용자의 입력 패턴을 파악할 수 있다. 예를 들어, 사용자의 과거 사용자 입력들로부터, 사용자 입력에 기반한 문장을 제공하는 장치는 사용자가 문장을 끝까지 입력 하지 않거나 문장에서 기호 등을 사용하지 않는 습관이 있는지 등을 파악할 수 있고, 특정 단어가 대부분 문장 에 포함되었었는지 등을 파악할 수 있다. 사용자 입력에 기반한 문장을 제공하는 장치는 축약어와 상황 정보에 기초하여, 축약어에 대응되는 문장 을 사용자에게 제공할 수 있다. 도 6에 도시된 예에 따르면, 사용자 입력에 기반한 문장을 제공하는 장치(100 0)는 사용자가 입력한 축약어가 \"ㅈㄱㅇㄷ\"라는 점, 상대방이 아내라는 점, 채팅 애플리케이션이 실행되고 있다 는 점, 채팅 애플리케이션을 통해 아내와 주고받은 과거 대화 내용으로부터 가장 최근의 대화 주제 또는 대화 분위기가 어떠하였는지, 어떤 말투를 쓰는지 등에 기초하여 축약어 \"ㅈㄱㅇㄷ\"에 대응되는 문장을 생성할 수 있 다. 사용자 입력에 기반한 문장을 제공하는 장치는 축약어와 사용자의 상황 정보를 학습된 데이터 인식 모델의 입력 값으로 하여, 학습된 데이터 인식 모델에서 생성된 축약어에 대응되는 문장을 사용자에게 제공할 수 있다. 도 6에 도시된 바와 같이, 사용자 입력에 기반한 문장을 제공하는 장치는 축약어 \"ㅈㄱㅇㄷ\"에 대응하여, \"지금어디\", \"자기어디야?\", \"지금어디야\"와 같은 문장을 사용자에게 제공할 수 있다. 사용자 입력에 기반한 문 장을 제공하는 장치는 축약어에 대응되는 문장이 복수 개인 경우, 축약어를 대신할 최적의 문장을 나타내 는 우선순위에 기초하여, 축약어에 대응되는 문장을 사용자에게 제공할 수 있다. 사용자 입력에 기반한 문장을 제공하는 장치는 우선순위가 높은 문장부터 가장 위쪽에 배치하여 순서대로 제공하거나, 소정의 우선순위 내에 해당하는 문장들만 사용자에게 제공할 수 있다. 사용자 입력에 기반한 문장을 제공하는 장치는 사용자의 선택에 따라, 축약어를 축약어에 대응되는 문장 으로 대체하여 표시할 수 있다. 사용자는 사용자 입력에 기반한 문장을 제공하는 장치에 표시된 적어도 하나의 축약어에 대응되는 문장에 대해, 사용자가 원하는 문장을 선택함으로써, 사용자가 입력한 축약어를 사용 자가 선택한 문장으로 대체시킬 수 있다. 도 6에 도시된 바와 같이, 사용자 입력에 기반한 문장을 제공하는 장 치에 축약어 \"ㅈㄱㅇㄷ\"에 대응하여, \"지금어디?\", \"자기어디야?\", \"지금어디야\"와 같은 문장들이 제공되 는 경우, 사용자는 이와 같은 문장들 중에 사용자가 의도했던 문장을 선택하여, 사용자가 입력한 축약어 \"ㅈㄱ ㅇㄷ\"를 선택한 문장으로 대체하여 표시하도록 할 수 있다. 도 7은 다른 실시예에 따른 사용자 입력에 기반한 문장을 제공하는 장치에서 축약어에 대응되는 문장을 제공하는 과정을 설명하기 위한 도면이다. 사용자 입력에 기반한 문장을 제공하는 장치에서 사용자 입력이 가능한 애플리케이션이 실행되면, 도 7에 도시된 바와 같이, 사용자 입력을 위한 사용자 인터페이스가 제공될 수 있다. 도 7에서는 영문 자판인 경우를 설명한다. 영어의 경우, 사용자가 자신이 쓰고자 하는 문장의 축약어로써, 각 단어의 알파벳 문자 또는 소정의 기호를 입 력할 수 있다. 도 7에 도시된 바와 같이, 사용자는 \"I e p w/ t @ y!\"라는 알파벳 문자 및 기호로 구성된 축약 어를 입력할 수 있다.사용자 입력에 기반한 문장을 제공하는 장치는 사용자로부터 축약어를 입력받기 전 또는 후에 사용자의 상황 정보를 획득할 수 있다. 예를 들어, 도 7에서, 상대방의 이름이 \"Jane\"이라고 저장되어 있는 것으로부터, 사용자 입력에 기반한 문장을 제공하는 장치는 \"Jane\"에 관한 다양한 데이터를 수집하여, 사용자와 \"Jane\"의 관계를 파악할 수 있다. 또한, 실행된 애플리케이션이 채팅 애플리케이션임을 확인함으로써, 사용자 입력에 기반한 문장을 제공하는 장 치는 채팅 애플리케이션이 메시지를 비롯한 다양한 콘텐츠를 주고받는 특성이 있음을 파악하거나 콘텐츠 송수신을 위한 다양한 기능이 있음을 파악할 수 있다. 또한, 축약어 입력 이전에 입력된 콘텐츠들이 존재한다면, 사용자 입력에 기반한 문장을 제공하는 장치는 현재 채팅 상대방인 \"Jane\"과 이전에 주고받 은 콘텐츠들이 무엇이 있는지, 특정 기간 동안 어떤 콘텐츠들이 입력되었었는지, 대화에 반복적으로 등장한 주 제가 무엇이었는지 등을 파악할 수 있다. 또한, 사용자의 과거 사용자 입력들로부터, 사용자 입력에 기반한 문 장을 제공하는 장치는 사용자가 문장을 끝까지 입력하지 않거나 문장에서 기호 등을 사용하지 않는 습관 이 있는지 등을 파악할 수 있고, 특정 단어가 대부분 문장에 포함되었었는지 등을 파악할 수 있다. 사용자 입력에 기반한 문장을 제공하는 장치는 축약어와 상황 정보에 기초하여, 축약어에 대응되는 문장 을 사용자에게 제공할 수 있다. 도 7에 도시된 예에 따르면, 사용자 입력에 기반한 문장을 제공하는 장치(100 0)는 사용자가 입력한 축약어가 \"I e p w/ t @ y!\"이고, 상대방이 \"Jane\"이며, 채팅 애플리케이션이 실행되고 있고, 채팅 애플리케이션을 통해 \"Jane\"과 주고받은 과거 대화 내용으로부터 가장 최근의 대화 주제 또는 대화 분위기가 어떠하였는지, 어떤 말투를 쓰는지 등에 기초하여 축약어 \"I e p w/ t @ y!\"에 대응되는 문장을 생성 할 수 있다. 사용자 입력에 기반한 문장을 제공하는 장치는 축약어와 사용자의 상황 정보를 학습된 데이 터 인식 모델의 입력 값으로 하여, 학습된 데이터 인식 모델에서 생성된 축약어에 대응되는 문장을 사용자에게 제공할 수 있다. 도 7에 도시된 바와 같이, 사용자 입력에 기반한 문장을 제공하는 장치는 축약어 \"I e p w/ t @ y!\"에 대 응하여, \"I eat pizza with Tiffany at yummy restaurant!\", \"I enjoy party with Tom at y club!\"과 같은 문 장을 사용자에게 제공할 수 있다. 사용자 입력에 기반한 문장을 제공하는 장치는 사용자의 선택에 따라, 축약어를 축약어에 대응되는 문장 으로 대체하여 표시할 수 있다. 도 7에 도시된 바와 같이, 사용자 입력에 기반한 문장을 제공하는 장치에 축약어 \"I e p w/ t @ y!\"에 대응하여, \"I eat pizza with Tiffany at yummy restraunt!\", \"I enjoy party with Tom at y club!\"와 같은 문장들이 제공되는 경우, 사용자는 이와 같은 문장들 중에 사용자가 의도했던 문 장을 선택하여, 사용자가 입력한 축약어 \"I e p w/ t @ y!\"를 선택한 문장으로 대체하여 표시하도록 할 수 있다. 도 8은 또 다른 실시예에 따른 사용자 입력에 기반한 문장을 제공하는 장치에서 축약어에 대응되는 문장 을 제공하는 과정을 설명하기 위한 도면이다. 도 8은 상대방으로부터 문자 메시지가 수신되어, 사용자가 수신된 문자 메시지를 확인하기 위하여 문자 애플리 케이션을 실행시킨 경우를 나타낸다. 사용자 입력에 기반한 문장을 제공하는 장치에서 문자 애플리케이션 이 실행되면, 도 8에 도시된 바와 같이, 상대방으로부터 수신된 메시지와 사용자 입력을 위한 사용자 인터페이 스가 제공될 수 있다. 도 8에 도시된 바와 같이, 사용자는 \"ㄷㅊ\"이라고 자음들로 구성된 축약어를 입력할 수 있다. 사용자 입력에 기반한 문장을 제공하는 장치는 사용자로부터 축약어를 입력받기 전 또는 후에 사용자의 상황 정보를 획득할 수 있다. 사용자가 사용자 입력에 기반한 문장을 제공하는 장치에서 문자 애플리케이 션을 실행하고, 수신된 메시지를 확인하는 경우, 사용자 입력에 기반한 문장을 제공하는 장치는 축약어를 입력받기 전이라도 상대방의 전화번호 또는 이름, 문자 애플리케이션이 실행, 수신된 메시지의 내용 등와 같은 사용자의 상황 정보를 획득할 수 있다. 또는, 사용자 입력에 기반한 문장을 제공하는 장치는 사용자가 사 용자 입력에 기반한 문장을 제공하는 장치에 축약어가 입력되기 시작한 때 또는 입력이 완료된 후에 상대 방의 전화번호 또는 이름, 문자 애플리케이션이 실행, 수신된 메시지의 내용 등과 같은 상황 정보를 획득할 수 도 있다. 도 8에 도시된 예에서, 사용자 입력에 기반한 문장을 제공하는 장치는 문자 애플리케이션의 실행 사실, 상대방의 전화번호, 상대방의 말투, 상대방의 최근 메시지 내용, 메시지가 수신된 시각, 사용자의 위치 등의 사 용자의 상황 정보를 획득할 수 있다. 한편, 문자 애플리케이션의 경우, 상대방과 문답 형식으로 대화가 이루어지는게 일반적인 바, 사용자 입력에 기반한 문장을 제공하는 장치는 상대방의 메시지에 대한 답변에 초점 을 맞추어 문장을 생성할 수 있다. 사용자 입력에 기반한 문장을 제공하는 장치는 축약어와 상황 정보에 기초하여, 축약어에 대응되는 문장 을 사용자에게 제공할 수 있다. 도 8에 도시된 예에 따르면, 사용자 입력에 기반한 문장을 제공하는 장치(100 0)는 사용자가 입력한 축약어가 \"ㄷㅊ\"라는 점, 문자 애플리케이션이 실행되고 있다는 점, 상대방의 최근 메시 지로부터 대화의 주제 또는 상대방의 질문이 무엇인지, 존댓말과 같은 말투를 쓰는지 등에 기초하여, 상대방의 질문에 대한 예상 답변을 중심으로 축약어 \"ㄷㅊ\"에 대응되는 문장을 생성할 수 있다. 한편, 사용자 입력에 기반한 문장을 제공하는 장치는 축약어에 대응되는 문장에 선택 가능한 표현이 포함 되는 경우, 선택 가능한 표현을 선택할 수 있는 사용자 인터페이스를 축약어에 대응되는 문장과 함께 제공할 수 있다. 도 8에 도시된 바와 같이, 사용자 입력에 기반한 문장을 제공하는 장치는 축약어 \"ㄷㅊ\"에 대응하 여, \"20분 후 도착 예정입니다\"와 같은 문장을 사용자에게 제공할 수 있다. 이때, 사용자 입력에 기반한 문장을 제공하는 장치는 숫자 \"20\"과 같은 표현을 조절할 수 있도록, 선택 가능한 표현을 선택할 수 있는 사용자 인터페이스를 함께 제공할 수 있다. 사용자 입력에 기반한 문장을 제공하는 장치는 사용자의 선택에 따라, 축약어를 축약어에 대응되는 문장 으로 대체하여 표시할 수 있다. 사용자는 사용자 입력에 기반한 문장을 제공하는 장치에 표시된 축약어에 대응되는 문장이 사용자가 원하는 문장에 해당되면 이를 선택함으로써, 사용자가 입력한 축약어를 사용자가 선 택한 문장으로 대체시킬 수 있다. 도 8에 도시된 바와 같이, 사용자 입력에 기반한 문장을 제공하는 장치(100 0)는 축약어 \"ㄷㅊ\"에 대응하여, \"20분 후 도착 예정입니다\"와 같은 문장이 제공되는 경우, 사용자는 제공된 문 장을 선택하여, 사용자가 입력한 축약어 \"ㄷㅊ\"를 선택한 문장으로 대체하여 표시하도록 할 수 있다. 사용자의 입력창에 축약어 \"ㄷㅊ\"를 대신하여 \"20분 후 도착 예정입니다\"와 같은 문장이 입력된 경우, 사용자는 메시지 전송 버튼을 눌러 축약어에 대응되는 문장을 상대방에게 전송할 수 있다. 도 9는 다른 일 실시예에 따른 사용자 입력에 기반한 문장을 제공하는 장치를 설명하기 위한 블록도이다. 도 9에 도시된 바와 같이, 다른 일 실시예에 따른 사용자 입력에 기반한 문장을 제공하는 장치는 메모리 , 제어부, 입출력부, 센싱부, 통신부 및 A/V 입력부를 포함할 수 있다. 메모리는 제어부의 처리 및 제어를 위한 프로그램을 저장할 수 있고, 사용자 입력에 기반한 문장을 제공하는 장치로 입력되거나 사용자 입력에 기반한 문장을 제공하는 장치로부터 출력되는 데이터를 저장할 수도 있다. 메모리는 컴퓨터 실행가능 명령어(computer executable instruction)를 저장할 수 있 다. 메모리는 플래시 메모리 타입(flash memory type), 하드디스크 타입(hard disk type), 멀티미디어 카드 마이크로 타입(multimedia card micro type), 카드 타입의 메모리(예를 들어 SD 또는 XD 메모리 등), 램(RAM, Random Access Memory) SRAM(Static Random Access Memory), 롬(ROM, Read-Only Memory), EEPROM(Electrically Erasable Programmable Read-Only Memory), PROM(Programmable Read-Only Memory), 자기 메모리, 자기 디스크, 광디스크 중 적어도 하나의 타입의 저장매체를 포함할 수 있다. 메모리에 저장된 프로그램들은 그 기능에 따라 복수 개의 모듈들로 분류할 수 있는데, 예를 들어, UI 모 듈, 터치 스크린 모듈, 알림 모듈 등으로 분류될 수 있다. UI 모듈은, 애플리케이션 별로 사용자 입력에 기반한 문장을 제공하는 장치와 연동되는 특화된 UI, GUI 등을 제공할 수 있다. 터치 스크린 모듈은 사용자의 터치 스크린 상의 터치 제스처를 감지하고, 터치 제스처에 관한 정보를 제어부로 전달할 수 있다. 일부 실시예에 따른 터치 스크린 모듈은 터치 코드를 인식하고 분 석할 수 있다. 터치 스크린 모듈은 별도의 하드웨어로도 구성될 수도 있다. 사용자의 터치 제스처에는 탭, 터치 &홀드, 더블 탭, 드래그, 패닝, 플릭, 드래그 앤드 드롭, 스와이프 등이 있을 수 있다. 알림 모듈은 사용자 입 력에 기반한 문장을 제공하는 장치의 이벤트 발생을 알리기 위한 신호를 발생할 수 있다. 사용자 입력에 기반한 문장을 제공하는 장치에서 발생되는 이벤트의 예로는 메시지 수신, 키 신호 입력, 콘텐츠 입력, 콘텐츠 전송, 소정의 조건에 해당되는 콘텐츠 검출 등이 있다. 알림 모듈은 디스플레이부를 통해 비디오 신호 형태로 알림 신호를 출력할 수도 있고, 음향 출력부를 통해 오디오 신호 형태로 알림 신호를 출력할 수도 있고, 진동 모터를 통해 진동 신호 형태로 알림 신호를 출력할 수도 있다. 제어부는, 통상적으로 사용자 입력에 기반한 문장을 제공하는 장치의 전반적인 동작을 제어한다. 예를 들어, 제어부는, 메모리에 저장된 프로그램들을 실행함으로써, 입출력부, 센싱부, 통신부, A/V 입력부 등을 전반적으로 제어할 수 있다. 구체적으로, 제어부는 적어도 하나의 프로세서를 구비할 수 있다. 제어부는 그 기능 및 역할에 따 라, 복수의 프로세서들을 포함하거나, 통합된 형태의 하나의 프로세서를 포함할 수 있다. 제어부를 구성하는 적어도 하나의 프로세서는 메모리에 저장된 컴퓨터 실행가능 명령어를 실행함으 로써, 사용자로부터 입력된 축약어와 사용자 입력에 기반한 문장을 제공하는 장치에서 획득된 사용자의 상황 정보를 분석하고, 축약어와 상황 정보에 기초하여, 축약어에 대응되는 적어도 하나의 문장을 생성할 수 있 다. 제어부를 구성하는 적어도 하나의 프로세서는 축약어와 사용자의 상황 정보를 학습된 데이터 인식 모 델에 적용하여 축약어에 대응되는 문장을 생성할 수 있다. 사용자의 상황 정보는 상대방에 대한 정보, 축약어의 입력이 수행되는 애플리케이션의 종류, 축약어 입력 이전에 입력된 콘텐츠의 내용, 과거의 사용자 입력 히스토 리로부터 파악되는 사용자 입력 패턴, 사용자의 위치 또는 사용자 입력이 수행된 시기 등과 같은 다양한 데이터 일 수 있다. 학습된 데이터 인식 모델은 사용자 입력에 기반한 문장을 제공하는 장치 외부의 서버에 저장 되어 있거나, 사용자 입력에 기반한 문장을 제공하는 장치의 요청에 따라 서버로부터 수신될 수 있다. 제어부를 구성하는 적어도 하나의 프로세서는 사용자의 선택에 따른 축약어에 대응되는 문장에 기초하여, 축약어와 문장 간의 관련도를 학습할 수 있다. 제어부를 구성하는 적어도 하나의 프로세서는 축약어에 대 응되는 문장을 생성하는데 이용되는 데이터 인식 모델의 학습용 데이터로써, 축약어와 사용자의 선택에 따른 축 약어에 대응되는 문장을 이용할 수 있다. 입출력부는 사용자 입력부와 출력부을 포함할 수 있다. 입출력부는 사용자 입력부 와 출력부가 분리된 형태이거나, 터치스크린과 같이 통합된 하나의 형태일 수 있다. 입출력부는 사용자로부터 축약어를 입력받고, 제어부에서 생성한 축약어에 대응되는 문장을 사용자 에게 제공할 수 있다. 입출력부는 사용자의 선택에 따라, 축약어를 축약어에 대응되는 문장으로 대체하여 표시할 수 있다. 입출력부는 축약어에 대응되는 문장이 복수 개인 경우, 축약어를 대신할 최적의 문장을 나타내는 우선순위에 기초하여, 축약어에 대응되는 문장을 사용자에게 제공할 수 있다. 입출력부는 축약 어에 대응되는 문장에 선택 가능한 표현이 포함되는 경우, 선택 가능한 표현을 선택할 수 있는 사용자 인터페이 스를 함께 제공할 수 있다. 사용자 입력부는, 사용자가 사용자 입력에 기반한 문장을 제공하는 장치를 제어하기 위한 데이터를 입력하는 수단을 의미할 수 있다. 사용자 입력부는 사용자로부터 축약어를 입력받을 수 있고, 사용자로부 터 축약어에 대응되는 문장을 선택받을 수 있다. 사용자 입력부는 키 패드(key pad), 터치 패널(접촉식 정전 용량 방식, 압력식 저항막 방식, 적외선 감지 방식, 표면 초음파 전도 방식, 적분식 장력 측정 방식, 피에조 효과 방식 등), 팬인식 패널 등이 될 수 있다. 뿐만 아니라, 사용자 입력부는 조그 휠, 조그 스위치 등이 있을 수 있으나 이에 한정되 는 것은 아니다. 출력부는 사용자 입력에 기반한 문장을 제공하는 장치에서 애플리케이션이 실행된 결과를 출력할 수 있다. 출력부는 사용자 입력에 기반한 문장을 제공하는 장치의 동작 결과를 출력할 수 있고, 사 용자 입력이 있는 경우, 사용자의 입력에 따라 변경된 결과를 출력할 수 있다. 출력부는, 오디오 신호 또는 비디오 신호 또는 진동 신호를 출력할 수 있으며, 출력부는 디스플레 이부, 음향 출력부, 및 진동 모터를 포함할 수 있다. 디스플레이부는 사용자 입력에 기반한 문장을 제공하는 장치에서 처리되는 정보를 디스플레이한다. 예를 들어, 디스플레이부는, 메신저 또는 SNS 애플리케이션의 실행 화면을 디스플레이하거나, 사용자의 조작을 입력받기 위한 사용자 인터페이스를 디스플레이할 수 있다. 한편, 디스플레이부와 터치패드가 레이어 구조를 이루어 터치 스크린으로 구성되는 경우, 디스플레이부 는 출력 장치 이외에 입력 장치로도 사용될 수 있다. 디스플레이부는 액정 디스플레이(liquid crystal display), 박막 트랜지스터 액정 디스플레이(thin film transistor-liquid crystal display), 유기 발 광 다이오드(organic light-emitting diode), 플렉시블 디스플레이(flexible display), 3차원 디스플레이(3D display), 전기영동 디스플레이(electrophoretic display) 중에서 적어도 하나를 포함할 수 있다. 그리고 사용 자 입력에 기반한 문장을 제공하는 장치의 구현 형태에 따라 사용자 입력에 기반한 문장을 제공하는 장치 는 디스플레이부를 2개 이상 포함할 수도 있다. 이때, 2개 이상의 디스플레이부는 힌지(hinge)를 이용하여 마주보게 배치될 수 있다. 음향 출력부는 통신부로부터 수신되거나 메모리에 저장된 오디오 데이터를 출력한다. 또한, 음향 출력부는 사용자 입력에 기반한 문장을 제공하는 장치에서 수행되는 기능(예를 들어, 호신호 수신음, 메시지 수신음, 알림음)과 관련된 음향 신호를 출력한다. 이러한 음향 출력부에는 스피커 (speaker), 버저(Buzzer) 등이 포함될 수 있다. 진동 모터는 진동 신호를 출력할 수 있다. 예를 들어, 진동 모터는 오디오 데이터 또는 비디오 데 이터(예컨대, 호신호 수신음, 메시지 수신음 등)의 출력에 대응하는 진동 신호를 출력할 수 있다. 또한, 진동 모터는 터치스크린에 터치가 입력되는 경우 진동 신호를 출력할 수도 있다. 센싱부는, 사용자 입력에 기반한 문장을 제공하는 장치의 상태 또는 사용자 입력에 기반한 문장을 제공하는 장치 주변의 상태를 감지하고, 감지된 정보를 제어부로 전달할 수 있다. 센싱부는, 지자기 센서(Magnetic sensor), 가속도 센서(Acceleration sensor), 온/습도 센 서, 적외선 센서, 자이로스코프 센서, 위치 센서(예컨대, GPS), 기압 센서, 근 접 센서, 및 RGB 센서(illuminance sensor) 중 적어도 하나를 포함할 수 있으나, 이에 한정되는 것은 아니다. 각 센서들의 기능은 그 명칭으로부터 당업자가 직관적으로 추론할 수 있으므로, 구체적인 설명은 생략하기로 한다. 통신부는, 사용자 입력에 기반한 문장을 제공하는 장치와 다른 장치 또는 서버 간의 통신을 하게 하는 하나 이상의 구성요소를 포함할 수 있다. 예를 들어, 통신부는, 근거리 통신부, 이동 통신부 , 방송 수신부를 포함할 수 있다. 근거리 통신부(short-range wireless communication unit)는, 블루투스 통신부, BLE(Bluetooth Low Energy) 통신부, 근거리 무선 통신부(Near Field Communication unit), WLAN(와이파이) 통신부, 지그비 (Zigbee) 통신부, 적외선(IrDA, infrared Data Association) 통신부, WFD(Wi-Fi Direct) 통신부, UWB(ultra wideband) 통신부, Ant+ 통신부 등을 포함할 수 있으나, 이에 한정되는 것은 아니다. 이동 통신부는, 이동 통신망 상에서 기지국, 외부의 단말, 서버 중 적어도 하나와 무선 신호를 송수신한 다. 여기에서, 무선 신호는, 음성 호 신호, 화상 통화 호 신호 또는 문자/멀티미디어 메시지 송수신에 따른 다 양한 형태의 데이터를 포함할 수 있다. 방송 수신부는, 방송 채널을 통하여 외부로부터 방송 신호 및/또는 방송 관련된 정보를 수신한다. 방송 채널은 위성 채널, 지상파 채널을 포함할 수 있다. 구현 예에 따라서 사용자 입력에 기반한 문장을 제공하는 장 치가 방송 수신부를 포함하지 않을 수도 있다. 또한, 통신부는, 콘텐츠를 송수신 또는 업로드하기 위하여 다른 장치, 서버, 주변 기기 등과 통신을 수행 할 수 있다. A/V(Audio/Video) 입력부는 오디오 신호 또는 비디오 신호 입력을 위한 것으로, 이에는 카메라와 마이크로폰 등이 포함될 수 있다. 카메라은 화상 통화모드 또는 촬영 모드에서 이미지 센서를 통해 정지영상 또는 동영상 등의 화상 프레임을 얻을 수 있다. 이미지 센서를 통해 캡쳐된 이미지는 제어부 또 는 별도의 이미지 처리부(미도시)를 통해 처리될 수 있다. 카메라에서 처리된 화상 프레임은 메모리에 저장되거나 통신부를 통하여 외부로 전송될 수 있다. 카메라는 단말기의 구성 태양에 따라 2개 이상이 구비될 수도 있다. 마이크로폰은, 외부의 음향 신호를 입력 받아 전기적인 음성 데이터로 처리한다. 예를 들어, 마이크로폰 은 외부 디바이스 또는 화자로부터 음향 신호를 수신할 수 있다. 마이크로폰는 외부의 음향 신호를 입력 받는 과정에서 발생 되는 잡음(noise)를 제거하기 위한 다양한 잡음 제거 알고리즘을 이용할 수 있다. 도 10은 일 실시예에 따른 콘텐츠를 처리하는 방법을 나타내는 흐름도이다. 1010 단계에서, 사용자 입력에 기반한 문장을 제공하는 장치는 사용자로부터 축약어를 입력받는다. 1020 단계에서, 사용자 입력에 기반한 문장을 제공하는 장치는 사용자의 상황 정보를 획득한다. 1030 단계에서, 사용자 입력에 기반한 문장을 제공하는 장치는 축약어와 상황 정보에 기초하여, 축약어에 대응되는 문장을 사용자에게 제공한다.사용자 입력에 기반한 문장을 제공하는 장치는 축약어에 대응되는 문장이 복수 개인 경우, 축약어를 대신 할 최적의 문장을 나타내는 우선순위에 기초하여, 축약어에 대응되는 문장을 상기 사용자에게 제공할 수 있다. 또한, 사용자 입력에 기반한 문장을 제공하는 장치는 축약어에 대응되는 문장에 선택 가능한 표현이 포함 되는 경우, 선택 가능한 표현을 선택할 수 있는 사용자 인터페이스를 함께 제공할 수 있다. 사용자 입력에 기반한 문장을 제공하는 장치는 축약어와 사용자의 상황 정보를 학습된 데이터 인식 모델 의 입력 값으로 하여, 학습된 데이터 인식 모델에서 생성된 축약어에 대응되는 문장을 사용자에게 제공할 수 있 다. 상황 정보가 상대방에 대한 정보인 경우, 사용자 입력에 기반한 문장을 제공하는 장치는 축약어와 사 용자와 상대방의 관계에 기초하여, 축약어에 대응되는 문장을 사용자에게 제공할 수 있다. 상황 정보가 축약어 의 입력이 수행되는 애플리케이션의 종류인 경우, 사용자 입력에 기반한 문장을 제공하는 장치는 축약어 와 애플리케이션의 특성 또는 기능에 기초하여, 축약어에 대응되는 문장을 사용자에게 제공할 수 있다. 상황 정 보가 축약어 입력 이전에 입력된 콘텐츠의 내용인 경우, 사용자 입력에 기반한 문장을 제공하는 장치는 축약어와 축약어 입력 이전에 입력된 콘텐츠의 내용에 기초하여, 축약어에 대응되는 문장을 사용자에게 제공할 수 있다. 상황 정보가 과거의 사용자 입력 히스토리로부터 파악되는 사용자 입력 패턴인 경우, 사용자 입력에 기반한 문장을 제공하는 장치는 축약어와 사용자 입력 패턴에 기초하여, 축약어에 대응되는 문장을 사용 자에게 제공할 수 있다. 1040 단계에서, 사용자 입력에 기반한 문장을 제공하는 장치는 사용자의 선택에 따라, 축약어를 축약어에 대응되는 문장으로 대체하여 표시한다. 사용자 입력에 기반한 문장을 제공하는 장치는 사용자의 선택에 따른 축약어에 대응되는 문장에 기초하여, 축약어와 문장 간의 관련도를 학습할 수 있다. 도 11 및 도 12는 일부 실시예에 따른 데이터 인식 모델을 이용하는 네트워크 시스템의 흐름도들이다. 도 11에서, 네트워크 시스템은 제1 구성 요소 및 제2 구성 요소를 포함할 수 있다. 여기서, 제1 구 성 요소은 장치이고, 제2 구성 요소는 데이터 분석 모델이 저장된 서버 또는 적어도 하나의 서버를 포함하는 클라우드가 될 수 있다. 또는, 제1 구성 요소는 범용 프로세서이고, 제2 구성 요 소는 인공 지능 전용 프로세서가 될 수 있다. 또는, 제1 구성 요소는 적어도 하나의 어플리케이션 이 될 수 있고, 제2 구성 요소는 운영 체제(operating system, OS)가 될 수 있다. 즉, 제2 구성 요소 는 제1 구성 요소보다 더 집적화되거나, 전용화되거나, 딜레이(delay)가 작거나, 성능이 우세하거 나 또는 많은 리소스를 가진 구성 요소로서, 데이터 인식 모델의 생성, 갱신 또는 적용 시에 요구되는 많은 연 산을 제1 구성 요소보다 신속하고 효과적으로 처리할 수 있는 구성 요소가 될 수 있다. 한편, 제1 구성 요소 및 제2 구성 요소 간에 데이터를 송/수신하기 위한 인터페이스가 정의될 수 있다. 예로, 데이터 인식 모델에 적용할 학습 데이터를 인자 값(또는, 매개 값 또는 전달 값)으로 갖는 API(application program interface)가 정의될 수 있다. API는 어느 하나의 프로토콜(예로, 장치에서 정 의된 프로토콜)에서 다른 프로토콜(예로, 서버에서 정의된 프로토콜)의 어떤 처리를 위해 호출할 수 있는 서브 루틴 또는 함수의 집합으로 정의될 수 있다. 즉, API를 통하여 어느 하나의 프로토콜에서 다른 프로토콜의 동작이 수행될 수 있는 환경이 제공될 수 있다. 일 실시예로, 도 11의 1110 단계에서, 제1 구성 요소는 사용자로부터 축약어를 입력 받을 수 있다. 1120 단계에서, 제1 구성 요소는 사용자의 상황 정보를 획득할 수 있다. 1130 단계에서, 제1 구성 요소는 축약어 및 상황 정보를 제2 구성 요소에게 전송할 수 있다. 예로, 제1 구성 요소는 데이터 인식 모델의 이용을 위하여 제공되는 API 함수의 인자 값으로 축약어 및 상황 정 보를 이용할 수 있다. 상기 API 함수는 축약어 및 상황 정보를 데이터 인식 모델에 적용할 데이터로서 제2 구성 요소에게 전송할 수 있다. 이 때, 제1 구성 요소는 축약어 또는 문장을 약속된 통신 포맷에 따라 변경하여 제2 구성 요소에게 전송할 수 있다. 1140 단계에서, 제2 구성 요소는 수신된 축약어 및 상황 정보를 축약어에 대응하는 문장을 생성하도록 설 정된 데이터 인식 모델에 적용할 수 있다. 예로, 제2 구성 요소는 수신된 축약어 및 상황 정보를 제2 구 성 요소에 저장된 데이터 인식 모델의 입력 값으로 적용할 수 있다. 1150 단계에서, 적용 결과로서, 제2 구성 요소는 축약어에 대응되는 문장을 획득할 수 있다. 예로, 상황 정보가 축약어의 입력이 수행되는 어플리케이션의 종류인 경우, 제2 구성 요소는 데이터 인식 모델을 이용하여 축약어와 어플리케이션의 특성 또는 기능에 기초하는 축약어에 대응되는 문장을 획득할 수 있다. 또는, 상황 정보가 축약어 입력 이전에 입력된 콘텐츠의 내용인 경우, 제2 구성 요소는 데이터 인식 모델을 이 용하여 축약어 및 축약어 입력 이전에 입력된 콘텐츠의 내용에 기초하는 축약어에 대응되는 문장을 획득할 수 있다. 또는, 상황 정보가 과거의 사용자 입력 히스토리로부터 파악되는 사용자 입력 패턴인 경우, 제2 구성 요 소는 데이터 인식 모델을 이용하여 축약어 및 사용자 입력 패턴에 기초하는 축약어에 대응되는 문장을 획 득할 수 있다. 1160 단계에서, 제2 구성 요소는 축약어에 대응되는 문장을 제1 구성 요소에게 전송할 수 있다. 이 때, 제2 구성 요소는 축약어에 대응되는 문장을 약속된 포맷에 따라 변경하여 제1 구성 요소에게 전송할 수 있다. 1170 단계에서, 제1 구성 요소는 수신된 축약어에 대응되는 문장을 사용자에게 제공할 수 있다. 1180 단계에서, 제1 구성 요소는 사용자의 선택에 따라, 축약어를 축약어에 대응되는 문장으로 대체하여 표시할 수 있다. 한편, 도 11에서, 1130 단계 내지 1170 단계는 도 10의 1030 단계에 대응될 수 있다. 즉, 도 10에서 축약어와 상황 정보에 기초하여 축약어에 대응되는 문장을 사용자에게 제공하는 단계는, 도 11에서, 제1 구성 요소(110 1)가 축약어 및 상황 정보를 제2 구성 요소로 전송하고, 제2 구성 요소로부터 데이터 인식 모델로 의 적용 결과인 축약어에 대응하는 문장을 수신하여 사용자에게 제공하는 단계를 포함할 수 있다. 도 12는, 본 개시의 다른 실시예에 따른 데이터 인식 모델을 이용하는 네트워크 시스템의 흐름도이다. 도 12에서, 네트워크 시스템은 제1 구성 요소, 제2 구성 요소 및 제3 구성 요소를 포함할 수 있다. 여기서, 제1 구성 요소는 전술한 도 11의 제1 구성 요소에 대응될 수 있고, 제2 구성 요소 및 제3 구성 요소는 전술한 도 11의 제2 구성 요소에 대응될 수 있다. 이 경우, 제2 구성 요소 및 제3 구성 요소은 서로 다른 데이터 인식 모델을 저장한 상태일 수 있다. 예로, 제2 구성 요소 및 제3 구성 요소는 상황 정보의 종류에 따라 구분된 서로 다른 데이터 인식 모델을 저장한 상태일 수 있다. 예로, 제2 구성 요소는 문장 전후의 스타일 또는 문장의 스타일이 형식적 (formal)인 경우에 이용하는 데이터 인식 모델을 저장할 수 있고, 제3 구성 요소는 문장 전후의 스타일이 비형식적(informal)인 경우에 이용하는 데이터 인식 모델을 저장할 수 있다. 또는, 제2 구성 요소는 문장 을 제공하는 어플리케이션의 종류가 문자 어플리케이션, 메신저 어플리케이션 또는 메일 어플리케이션인 경우에 이용하는 데이터 인식 모델을 저장할 수 있고, 제3 구성 요소는 문장을 제공하는 어플리케이션의 종류가 편집 어플리케이션(워드 어플리케이션 또는 한글 어플리케이션 등)인 경우에 이용하는 데이터 인식 모델을 저장 할 수 있다. 일 실시예로, 도 12의 1210 단계에서, 제1 구성 요소는 사용자로부터 축약어를 입력 받을 수 있다. 1220 단계에서, 제1 구성 요소는 사용자의 상황 정보를 획득할 수 있다. 1230 단계에서, 제1 구성 요소는 상황 정보의 종류를 판단할 수 있다. 판단 결과, 상황 정보의 종류가 제1 상황 정보인 경우, 1240 단계에서, 제1 구성 요소는 축약어 및 제1 상황 정보를 제2 구성 요소에게 전송할 수 있다. 1250 단계에서, 제2 구성 요소는 수신된 축약어 및 제1 상황 정보를 축약어에 대응하는 문장을 생성하도 록 설정된 데이터 인식 모델에 적용할 수 있다. 이 경우, 데이터 인식 모델은 제1 상황 정보에 기초하여 학습된 데이터 인식 모델일 수 있다. 예로, 데이터 인식 모델은 형식적인 문장을 학습용 데이터로서 이용하여 학습된 데이터 인식 모델일 수 있다. 1260 단계 및 1270 단계에서, 제2 구성 요소가 데이터 인식 모델을 이용하여 획득한 축약어에 대응하는 문장을 제1 구성 요소로 전송하면, 1280 단계 및 1290 단계에서, 제1 구성 요소는 축약어에 대응하 는 문장을 사용자에게 제공할 수 있다. 상기 단계들에 대응하는 설명은 도 11의 1150 단계 내지 1180 단계에 대 응되어 중복되는 설명은 생략한다.한편, 1230 단계에서, 제1 구성 요소가 상황 정보의 종류를 판단한 결과, 상황 정보의 종류가 제2 상황 정보인 경우, 1310 단계에서, 제1 구성 요소는 축약어 및 제2 상황 정보를 제3 구성 요소에게 전송 할 수 있다. 1320 단계에서, 제3 구성 요소는 수신된 축약어 및 제2 상황 정보를 축약어에 대응하는 문장을 생성하도 록 설정된 데이터 인식 모델에 적용할 수 있다. 이 경우, 데이터 인식 모델은 제2 상황 정보에 기초하여 학습된 데이터 인식 모델일 수 있다. 예로, 데이터 인식 모델은 비형식적인 문장을 학습용 데이터로서 이용하여 학습된 데이터 인식 모델일 수 있다. 1330 단계 및 1340 단계에서, 제3 구성 요소가 데이터 인식 모델을 이용하여 획득한 축약어에 대응하는 문장을 제1 구성 요소로 전송하면, 1280 단계 및 1290 단계에서, 제1 구성 요소는 축약어에 대응하 는 문장을 사용자에게 제공할 수 있다. 상기 단계들에 대응하는 설명은 도 11의 1150 단계 내지 1180 단계에 대 응되어 중복되는 설명은 생략한다. 한편, 상술한 사용자 입력에 기반한 문장을 제공하는 방법은 컴퓨터에서 실행될 수 있는 프로그램으로 작성가능 하고, 컴퓨터로 읽을 수 있는 저장매체를 이용하여 이와 같은 프로그램을 동작시키는 범용 디지털 컴퓨터에서 구현될 수 있다. 이와 같은 컴퓨터로 읽을 수 있는 저장매체는 read-only memory (ROM), random-access memory (RAM), flash memory, CD-ROMs, CD-Rs, CD+Rs, CD-RWs, CD+RWs, DVD-ROMs, DVD-Rs, DVD+Rs, DVD-RWs, DVD+RWs, DVD-RAMs, BD-ROMs, BD-Rs, BD-R LTHs, BD-REs, 마그네틱 테이프, 플로피 디스크, 광자기 데이터 저 장 장치, 광학 데이터 저장 장치, 하드 디스크, 솔리드-스테이트 디스크(SSD), 그리고 명령어 또는 소프트웨어, 관련 데이터, 데이터 파일, 및 데이터 구조들을 저장할 수 있고, 프로세서나 컴퓨터가 명령어를 실행할 수 있도 록 프로세서나 컴퓨터에 명령어 또는 소프트웨어, 관련 데이터, 데이터 파일, 및 데이터 구조들을 제공할 수 있 는 어떠한 장치라도 될 수 있다. 또한, 개시된 실시예들에 따른 방법은 컴퓨터 프로그램 제품(computer program product)으로 제공될 수 있다. 컴퓨터 프로그램 제품은 S/W 프로그램, S/W 프로그램이 저장된 컴퓨터로 읽을 수 있는 저장 매체 또는 판매자 및 구매자 간에 거래되는 상품을 포함할 수 있다. 예를 들어, 컴퓨터 프로그램 제품은 전자 장치, 전자 장치의 제조사, 서버, 서버의 제조사 또는 전자 마켓(예, 구글 플레이 스토어, 앱 스토어)을 통해 전자적으로 배포되는 S/W 프로그램 형태의 상품(예, 다운로더블 앱)을 포함할 수 있다. 전자적 배포를 위 하여, S/W 프로그램의 적어도 일부는 저장 매체에 저장되거나, 임시적으로 생성될 수 있다. 이 경우, 저장 매체 는 제조사 또는 전자 마켓의 서버, 또는 중계 서버의 저장매체가 될 수 있다. 이제까지 실시예들을 중심으로 살펴보았다. 개시된 실시예들이 속하는 기술 분야에서 통상의 지식을 가진 자는 개시된 실시예들이 본질적인 특성에서 벗어나지 않는 범위에서 변형된 형태로 구현될 수 있음을 이해할 수 있을 것이다. 그러므로 개시된 실시예들은 한정적인 관점이 아니라 설명적인 관점에서 고려되어야 한다. 발명의 범위 는 전술한 실시예들의 설명이 아니라 특허청구범위에 나타나 있으며, 그와 동등한 범위 내에 있는 모든 차이점 은 발명의 범위에 포함된 것으로 해석되어야 할 것이다."}
{"patent_id": "10-2017-0144234", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 일 실시예에 따른 사용자 입력에 기반한 문장을 제공하는 장치를 설명하기 위한 블록도이다. 도 2는 일 실시예에 따른 제어부의 블록도이다. 도 3은 일 실시예에 따른 데이터 학습부의 블록도이다. 도 4는 일 실시예에 따른 데이터 인식부의 블록도이다. 도 5는 일부 실시예에 따른 사용자 입력에 기반한 문장을 제공하는 장치 및 서버가 서로 연동함으로써 데이터를 학습하고 인식하는 예시를 나타내는 도면이다. 도 6은 일 실시예에 따른 사용자 입력에 기반한 문장을 제공하는 장치에서 축약어에 대응되는 문장을 제공하는 과정을 설명하기 위한 도면이다. 도 7은 다른 실시예에 따른 사용자 입력에 기반한 문장을 제공하는 장치에서 축약어에 대응되는 문장을 제공하 는 과정을 설명하기 위한 도면이다. 도 8은 또 다른 실시예에 따른 사용자 입력에 기반한 문장을 제공하는 장치에서 축약어에 대응되는 문장을 제공 하는 과정을 설명하기 위한 도면이다.도 9는 다른 일 실시예에 따른 사용자 입력에 기반한 문장을 제공하는 장치를 설명하기 위한 블록도이다. 도 10은 일 실시예에 따른 사용자 입력에 기반한 문장을 제공하는 방법을 나타내는 흐름도이다. 도 11 및 도 12는 일 실시예에 따른 데이터 인식 모델을 이용하는 네트워크 시스템의 흐름도들이다."}
