{"patent_id": "10-2024-0128954", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2025-0045479", "출원번호": "10-2024-0128954", "발명의 명칭": "가상 아바타를 생성하는 전자 장치 및 그 동작 방법", "출원인": "주식회사 오버더핸드", "발명자": "김상효"}}
{"patent_id": "10-2024-0128954", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "가상 아바타를 생성하는 전자 장치의 동작 방법에 있어서,스트리머(streamer)에 대한 영상 정보를 획득하는 단계;상기 영상 정보를 기반으로 상기 스트리머의 움직임 및 표정 중 적어도 하나에 대한 랜드마크(landmark)를 추출하는 단계;상기 랜드마크를 기반으로 상기 스트리머에 대한 표현 정보를 확인하는 단계; 및상기 표현 정보를 기반으로 상기 스트리머에 대응하는 가상 아바타를 생성하는 단계를 포함하는 동작 방법."}
{"patent_id": "10-2024-0128954", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1 항에 있어서,상기 랜드마크를 추출하는 단계는 상기 영상 정보에 대한 전처리 과정을 수행하는 단계를 포함하되,상기 전처리 과정은 상기 영상 정보에 대한 리사이징(resizing), 정규화(normalization) 및 바이너리 변환(binary translation) 중 적어도 일부 과정을 포함하는 동작 방법."}
{"patent_id": "10-2024-0128954", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1 항에 있어서,상기 영상 정보를 기반으로 상기 스트리머의 움직임에 대한 랜드마크를 추출하는 경우, 상기 랜드마크는 상기영상 정보에 포함된 스트리머의 신체 일부 이미지로부터 인식된 관절 위치에 대응하는 복수의 기준점들로 구성되는 동작 방법."}
{"patent_id": "10-2024-0128954", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1 항에 있어서,상기 영상 정보를 기반으로 상기 스트리머의 표정에 대한 랜드마크를 추출하는 경우, 상기 랜드마크는 인공지능모델을 통해 상기 영상 정보에 포함된 스트리머의 얼굴 이미지에 대응하여 도출된 복수의 기준점들로 구성되는동작 방법."}
{"patent_id": "10-2024-0128954", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1 항에 있어서,상기 랜드마크를 추출하는 단계는:상기 영상 정보를 기반으로 미리 설정된 주기에 대응하여 복수의 이미지들을 샘플링(sampling)하는 단계;상기 복수의 이미지들을 시간 순으로 배열하여 이미지 정보 세트를 구성하는 단계; 및상기 이미지 정보 세트를 기반으로 상기 스트리머의 움직임 및 표정 중 적어도 하나에 대한 랜드마크를 추출하는 단계를 포함하는 동작 방법."}
{"patent_id": "10-2024-0128954", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1 항에 있어서,상기 스트리머에 대한 표현 정보를 확인하는 단계는 상기 랜드마크를 기반으로 복수의 표현 처리 항목들 각각에대한 가중치를 부여하는 단계를 포함하고,공개특허 10-2025-0045479-3-상기 가상 아바타는 상기 복수의 표현 처리 항목들 각각에 대한 가중치를 기반으로 도출된 표정 및 움직임 중적어도 하나가 구현되어 생성되는 동작 방법."}
{"patent_id": "10-2024-0128954", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1 항에 있어서,상기 가상 아바타를 기반으로 컨텐츠를 생성하는 단계를 더 포함하는 동작 방법."}
{"patent_id": "10-2024-0128954", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1 항에 있어서,상기 스트리머에 대한 영상 정보는 복수의 촬영 장치들로부터 획득된 각각의 영상 데이터에 대한 융합을 통해도출된 동작 방법."}
{"patent_id": "10-2024-0128954", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "가상 아바타를 생성하기 위한 전자 장치로서,트랜시버, 명령어를 저장하는 메모리 및 프로세서를 포함하고,상기 트랜시버 및 상기 메모리와 연결되는 상기 프로세서는,스트리머(streamer)에 대한 영상 정보를 획득하고,상기 영상 정보를 기반으로 상기 스트리머의 움직임 및 표정 중 적어도 하나에 대한 랜드마크(landmark)를 추출하고,상기 랜드마크를 기반으로 상기 스트리머에 대한 표현 정보를 확인하고,상기 표현 정보를 기반으로 상기 스트리머에 대응하는 가상 아바타를 생성하는 전자 장치."}
{"patent_id": "10-2024-0128954", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "하드웨어와 결합되어, 가상 아바타를 생성하는 방법을 실행하기 위하여 컴퓨터 판독 가능 저장 매체에 저장된컴퓨터 프로그램에 있어서,상기 가상 아바타를 생성하는 방법은:스트리머(streamer)에 대한 영상 정보를 획득하는 단계;상기 영상 정보를 기반으로 상기 스트리머의 움직임 및 표정 중 적어도 하나에 대한 랜드마크(landmark)를 추출하는 단계;상기 랜드마크를 기반으로 상기 스트리머에 대한 표현 정보를 확인하는 단계; 및상기 표현 정보를 기반으로 상기 스트리머에 대응하는 가상 아바타를 생성하는 단계를 포함하는 컴퓨터 프로그램."}
{"patent_id": "10-2024-0128954", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 개시는 가상 아바타를 생성하는 전자 장치 및 그 동작 방법에 관한 것으로, 본 개시의 실시 예에 따른 가상 아바타를 생성하는 전자 장치의 동작 방법에 있어서, 상기 동작 방법은 스트리머(streamer)에 대한 영상 정보를 획득하는 단계, 상기 영상 정보를 기반으로 상기 스트리머의 움직임 및 표정 중 적어도 하나에 대한 랜드마크 (landmark)를 추출하는 단계, 상기 랜드마크를 기반으로 상기 스트리머에 대한 표현 정보를 확인하는 단계 및 상 기 표현 정보를 기반으로 상기 스트리머에 대응하는 가상 아바타를 생성하는 단계를 포함할 수 있다."}
{"patent_id": "10-2024-0128954", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 컨텐츠(contents) 제작 기술에 관한 것으로, 보다 구체적으로, 스트리머(streamer)에 대한 영상 정보 를 기반으로 가상 아바타를 생성하는 전자 장치 및 그 동작 방법에 관한 것이다."}
{"patent_id": "10-2024-0128954", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "인터넷의 보급화에 따라 개인 방송 또는 컨텐츠(Contents) 공유를 지원하기 위한 다양한 미디어 플랫폼(Media platform)들이 구축되고 있으며, 컨텐츠 제작자(또는 스트리머, Streamer)는 미디어 플랫폼을 통하여 제작된 컨 텐츠를 시청자에게 제공할 수 있다. 종래 방송 매체와는 달리, 미디어 플랫폼을 통한 컨텐츠 제공 방식은 채널 개설 및 콘텐츠 주제에 대한 특별한 제한을 두지 않고, 시청자의 컨텐츠 이용에도 특별한 제한을 두지 않으므로급속도로 대중화되고 있으며, 이에 따라 미디어 플랫폼을 통하여 컨텐츠를 제공하는 스트리머의 유입이 급증하 고 있다. 스트리머 유입이 급증함에 따라 보다 다양한 형태의 컨텐츠가 제공되고 있으며, 이와 같은 현상과 더불어 가상 아바타를 이용한 컨텐츠가 출현하였다. 가상 아바타를 이용한 컨텐츠는 현실 세계와 유사한 상호작용을 구현하 면서도 현실의 제약 조건을 벗어난 무한 경험의 기회를 제공할 수 있어 새로운 컨텐츠 양식 중 하나로 각광받고 있다. 이러한 시류에 따라 가상 아바타에 대한 많은 연구가 이루어지고 있으나, 현재의 가상 아바타 구현 기술 은 사실감과 표현력 측면에서의 한계가 존재한다. 관련하여, 한국 공개특허공보 10-2023-0050570A 및 한국 공개특허공보 10-2022-0160558A 등의 선행문헌들을 참 조할 수 있다."}
{"patent_id": "10-2024-0128954", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 개시는 스트리머(streamer)에 대한 영상 정보를 기반으로 가상 아바타를 생성하는 전자 장치 및 그 동작 방 법을 제공하는 것을 목적으로 한다. 본 개시는 스트리머의 움직임 및 표정과 관련한 표현을 반영한 가상 아바타를 생성하는 전자 장치 및 그 동작 방법을 제공하는 것을 목적으로 한다. 본 개시가 해결하고자 하는 과제들은 상술한 과제에 제한되지 않으며, 언급되지 않은 또 다른 과제들은 아래의 기재로부터 통상의 기술자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2024-0128954", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 개시의 일 실시 예에 따른 가상 아바타를 생성하는 전자 장치의 동작 방법에 있어서, 상기 동작 방법은 스트 리머(streamer)에 대한 영상 정보를 획득하는 단계, 상기 영상 정보를 기반으로 상기 스트리머의 움직임 및 표 정 중 적어도 하나에 대한 랜드마크(landmark)를 추출하는 단계, 상기 랜드마크를 기반으로 상기 스트리머에 대 한 표현 정보를 확인하는 단계 및 상기 표현 정보를 기반으로 상기 스트리머에 대응하는 가상 아바타를 생성하 는 단계를 포함할 수 있다. 예로서, 상기 랜드마크를 추출하는 단계는 상기 영상 정보에 대한 전처리 과정을 수행하는 단계를 포함하되, 상 기 전처리 과정은 상기 영상 정보에 대한 리사이징(resizing), 정규화(normalization) 및 바이너리 변환(binary translation) 중 적어도 일부 과정을 포함할 수 있다. 예로서, 상기 영상 정보를 기반으로 상기 스트리머의 움직임에 대한 랜드마크를 추출하는 경우, 상기 랜드마크 는 상기 영상 정보에 포함된 스트리머의 신체 일부 이미지로부터 인식된 관절 위치에 대응하는 복수의 기준점들 로 구성될 수 있다. 예로서, 상기 영상 정보를 기반으로 상기 스트리머의 표정에 대한 랜드마크를 추출하는 경우, 상기 랜드마크는 인공지능 모델을 통해 상기 영상 정보에 포함된 스트리머의 얼굴 이미지에 대응하여 도출된 복수의 기준점들로 구성될 수 있다. 예로서, 상기 랜드마크를 추출하는 단계는 상기 영상 정보를 기반으로 미리 설정된 주기에 대응하여 복수의 이 미지들을 샘플링(sampling)하는 단계, 상기 복수의 이미지들을 시간 순으로 배열하여 이미지 정보 세트를 구성 하는 단계 및 상기 이미지 정보 세트를 기반으로 상기 스트리머의 움직임 및 표정 중 적어도 하나에 대한 랜드 마크를 추출하는 단계를 포함할 수 있다. 예로서, 상기 스트리머에 대한 표현 정보를 확인하는 단계는 상기 랜드마크를 기반으로 복수의 표현 처리 항목 들 각각에 대한 가중치를 부여하는 단계를 포함하고, 상기 가상 아바타는 상기 복수의 표현 처리 항목들 각각에 대한 가중치를 기반으로 도출된 표정 및 움직임 중 적어도 하나가 구현되어 생성될 수 있다. 예로서, 상기 동작 방법은 상기 가상 아바타를 기반으로 컨텐츠를 생성하는 단계를 더 포함할 수 있다. 예로서, 상기 스트리머에 대한 영상 정보는 복수의 촬영 장치들로부터 획득된 각각의 영상 데이터에 대한 융합 을 통해 도출될 수 있다. 본 개시의 일 실시 예에 따른 가상 아바타를 생성하기 위한 전자 장치로서, 상기 전자 장치는 트랜시버, 명령어 를 저장하는 메모리 및 프로세서를 포함하고, 상기 트랜시버 및 상기 메모리와 연결되는 상기 프로세서는, 스트 리머(streamer)에 대한 영상 정보를 획득하고, 상기 영상 정보를 기반으로 상기 스트리머의 움직임 및 표정 중 적어도 하나에 대한 랜드마크(landmark)를 추출하고, 상기 랜드마크를 기반으로 상기 스트리머에 대한 표현 정 보를 확인하고, 상기 표현 정보를 기반으로 상기 스트리머에 대응하는 가상 아바타를 생성할 수 있다. 본 개시의 일 실시 예에 따른 하드웨어와 결합되어, 가상 아바타를 생성하는 방법을 실행하기 위하여 컴퓨터 판 독 가능 저장 매체에 저장된 컴퓨터 프로그램에 있어서, 상기 가상 아바타를 생성하는 방법은 스트리머 (streamer)에 대한 영상 정보를 획득하는 단계, 상기 영상 정보를 기반으로 상기 스트리머의 움직임 및 표정 중 적어도 하나에 대한 랜드마크(landmark)를 추출하는 단계, 상기 랜드마크를 기반으로 상기 스트리머에 대한 표 현 정보를 확인하는 단계 및 상기 표현 정보를 기반으로 상기 스트리머에 대응하는 가상 아바타를 생성하는 단 계를 포함할 수 있다."}
{"patent_id": "10-2024-0128954", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 개시에 따르면, 스트리머(streamer)에 대한 영상 정보를 기반으로 가상 아바타를 생성하는 전자 장치 및 그 동작 방법을 제공함으로써, 스트리머의 컨텐츠(contents) 제작 편의성을 향상시킬 수 있다. 본 개시에 따르면, 스트리머의 움직임 및 표정과 관련한 표현을 반영한 가상 아바타를 생성하는 전자 장치 및 그 동작 방법을 제공함으로써, 보다 생동감 있는 가상 아바타를 구현할 수 있다. 본 개시에 따른 효과들은 상술한 효과에 제한되지 않으며, 언급되지 않은 또 다른 효과들은 아래의 기재로부터 통상의 기술자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2024-0128954", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 첨부된 도면들에 기재된 내용들을 참조하여 본 발명에 따른 예시적 실시 예를 상세하게 설명한다. 다만, 본 발명이 예시적 실시 예들에 의해 제한되거나 한정되는 것은 아니다. 다른 정의가 없다면, 본 명세서에서 사 용되는 모든 용어(기술 및 과학적 용어를 포함)는 본 개시가 속하는 기술 분야에서 통상의 지식을 가진 자에게 공통적으로 이해될 수 있는 의미로 사용될 것이나, 이는 당 분야에 종사하는 기술자의 의도 또는 판례, 새로운 기술의 출현 등에 따라 달라질 수 있다. 또한, 일반적으로 사용되는 사전에 정의되어 있는 용어들은 명백하게 특별히 정의되어 있지 않는 한 이상적으로 또는 과도하게 해석되지 않는다. 특정한 경우, 출원인이 임의로 선정한 용어도 있으며, 이 경우 해당되는 설명 부분에서 상세히 그 의미를 기재할 것이다. 따라서, 본 개시에서 사용되는 용어는 단순한 용어의 명칭이 아닌,그 용어가 가지는 의미와 본 개시의 전반에 걸친 내용을 토대로 정의되어야 한다. 본 명세서 전체에서 어떤 부분이 어떤 구성요소를 \"포함\"한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다른 구성요소를 제외하는 것이 아니라, 다른 구성요소를 더 포함할 수 있음을 의미한다. 또한, 본 명세서에서 사용된 단수형은 특별히 언급하지 않는 한 복수형도 포함한다. 또한, 본 명세서 전체에서 기재된 \"a, b 및/또는 c 중 적어도 하나\"의 표현은, 'a 단독', 'b 단독', 'c 단독', 'a 및 b', 'a 및 c', 'b 및 c', 또는 'a, b, c 모두'를 포괄할 수 있다. 한편, 본 명세서에서 사용되는 \"제1 및/또는 제2\" 등의 용어는 다양한 구성요소들을 설명하기 위하여 사용될 수 있으나, 이는 하나의 구성요소를 다른 구성요소로부터 구별하기 위한 목적으로만 사용될 뿐, 해당 용어로 지칭 되는 구성요소로 한정하기 위한 것은 아니다. 예를 들어, 본 발명의 권리 범위를 벗어나지 않는 한, 제1 구성요 소는 제2 구성요소로 명명될 수 있으며, 제2 구성요소 또한 제1 구성요소로 명명될 수 있다. 또한, 본 명세서에 기재된 “…부”, “…모듈” 등의 용어는 적어도 하나의 기능이나 동작을 처리하는 단위를 의미하며, 이는 하드웨어 또는 소프트웨어로 구현되거나 하드웨어와 소프트웨어의 결합으로 구현될 수 있다. 또 한, 본 명세서에서 본 개시의 실시 예는 기능적인 블록 구성들 및 다양한 처리 단계들로 나타내어질 수 있다. 이러한 기능 블록들은 특정 기능들을 실행하는 다양한 개수의 하드웨어 또는/및 소프트웨어 구성들로 구현될 수 있다. 예를 들어, 본 개시의 실시 예는 하나 이상의 마이크로프로세서의 제어 또는 다른 제어 장치들에 의해서 다양한 기능들을 실행할 수 있는, 메모리, 프로세싱, 로직(logic), 룩 업 테이블(look-up table) 등과 같은 직 접 회로 구성들을 채용할 수 있다. 본 명세서에 개시된 구성 요소들이 소프트웨어 프로그래밍 또는 소프트웨어 요소들로 실행될 수 있는 것과 유사 하게, 본 개시의 실시 예는 데이터 구조, 프로세스들, 루틴들 또는 다른 프로그래밍 구성들의 조합으로 구현되 는 다양한 알고리즘을 포함하여, C, C++, 자바(Java), 어셈블러(assembler) 등과 같은 프로그래밍 또는 스크립 팅 언어로 구현될 수 있다. 기능적인 측면들은 하나 이상의 프로세서들에서 실행되는 알고리즘으로 구현될 수 있다. 또한, 본 실시 예는 전자적인 환경 설정, 신호 처리, 및 데이터 처리 중 적어도 하나를 위하여 종래 기술 을 채용할 수 있다. “매커니즘”, “요소”, “수단”, “구성”과 같은 용어는 넓게 사용될 수 있으며, 기계 적이고 물리적인 구성들로 한정되는 것은 아니다. 상기 용어는 프로세서 등과 연계하여 소프트웨어의 일련의 처 리들(routines)의 의미를 포함할 수 있다. 본 명세서에 첨부된 처리 흐름도 도면들의 각 블록과 흐름도 도면들의 조합들은 컴퓨터 프로그램 인스트럭션들 에 의해 수행될 수 있다. 이들 컴퓨터 프로그램 인스트럭션들은 범용 컴퓨터, 특수용 컴퓨터 또는 기타 프로그 램 가능한 데이터 프로세싱 장비의 프로세서에 탑재될 수 있으므로, 컴퓨터 또는 기타 프로그램 가능한 데이터 프로세싱 장비의 프로세서를 통해 수행되는 그 인스트럭션들이 흐름도 블록(들)에서 설명된 기능들을 수행하는 수단을 생성하게 된다. 이들 컴퓨터 프로그램 인스트럭션들은 특정 방식으로 기능을 구현하기 위해 컴퓨터 또는 기타 프로그램 가능한 데이터 프로세싱 장비를 지향할 수 있는 컴퓨터 이용 가능 또는 컴퓨터 판독 가능 메모리에 저장되는 것이 가능 하며, 그 컴퓨터 이용가능 또는 컴퓨터 판독 가능 메모리에 저장된 인스트럭션들은 흐름도 블록(들)에서 설명된 기능을 수행하는 인스트럭션 수단을 내포하는 제조 품목을 생산하는 것도 가능하다. 컴퓨터 프로그램 인스트럭션들은 컴퓨터 또는 기타 프로그램 가능한 데이터 프로세싱 장비 상에 탑재되는 것도 가능하므로, 컴퓨터 또는 기타 프로그램 가능한 데이터 프로세싱 장비 상에서 일련의 동작 단계들이 수행되어 컴퓨터로 실행되는 프로세스를 생성해서 컴퓨터 또는 기타 프로그램 가능한 데이터 프로세싱 장비를 수행하는 인스트럭션들은 흐름도 블록(들)에서 설명된 기능들을 실행하기 위한 단계들을 제공하는 것도 가능하다. 또한, 각 블록은 특정된 논리적 기능(들)을 실행하기 위한 하나 이상의 실행 가능한 인스트럭션들을 포함하는 모듈, 세그먼트 또는 코드의 일부를 나타낼 수 있다. 또, 몇 가지 대체 실행 예들에서는 블록들에서 언급된 기 능들이 순서를 벗어나서 발생하는 것도 가능할 수 있다. 예컨대, 잇달아 도시되어 있는 두 개의 블록들은 사실 실질적으로 동시에 수행되는 것도 가능하고 또는 그 블록들이 때때로 해당하는 기능에 따라 역순으로 수행되는 것도 가능하다. 본 명세서에서 언급되는 “전자 장치” 또는 “단말”은 네트워크를 통해 서버나 타 단말에 접속할 수 있는 컴 퓨터나 휴대용 단말로 구현될 수 있다. 여기서, 컴퓨터는 예를 들어, 웹 브라우저(WEB Browser)가 탑재된 노트 북, 데스크톱(desktop), 랩톱(laptop) 등을 포함하고, 휴대용 단말은 예를 들어, 휴대성과 이동성이 보장되는 무선 통신 장치로서, IMT(International Mobile Telecommunication), CDMA(Code Division Multiple Access),W-CDMA(W-Code Division Multiple Access), LTE(Long Term Evolution) 등의 통신 기반 단말, 스마트폰, 태블릿 PC 등과 같은 모든 종류의 핸드헬드(Handheld) 기반의 무선 통신 장치를 포함할 수 있다. 또한, 본 명세서에서 언급되는 “전자 장치” 또는 “단말”은 프로세서, 프로그램 데이터를 저장하고 실행하는 메모리, 디스크 드라 이브와 같은 영구 저장부(permanent storage), 외부 장치와 통신하는 통신 포트, 터치 패널, 키(key), 버튼 등 과 같은 사용자 인터페이스 장치 등도 포함할 수 있다. 한편, 본 개시에 따른 실시 예에서, 인공지능과 관련된 기능은 프로세서 및 메모리를 통해 구현될 수 있다. 이 때, 프로세서는 CPU(Center Processing Unit), AP(Application Processor), DSP(Digital Signal Processor) 등과 같은 범용 프로세서, GPU(Graphic Processing Unit), VPU(Vision Processing Unit)와 같은 그래픽 전용 프로세서 및 NPU(Neural network Processing Unit)와 같은 인공지능 전용 프로세서 중 어느 하나일 수 있다. 프로세서는 메모리에 저장된 기 정의된 동작 규칙 또는 인공지능 모델에 따라 입력 데이터를 처리할 수 있다. 또는, 프로세서가 인공지능 전용 프로세서인 경우, 인공지능 전용 프로세서는 특정 인공지능 모델의 처리에 특 화된 하드웨어 구조로 설계될 수 있다. 본 개시에 따른 일부 실시 예에서, 인공지능과 관련된 기능은 복수의 프 로세서들을 통해 구현될 수 있다. 본 개시에 따른 실시 예에서, 기 정의된 동작 규칙 또는 인공지능 모델은 기계학습을 수행하도록 구성될 수 있 다. 여기서, 기계학습을 수행하도록 구성된다는 것은, 기 정의된 동작 규칙 또는 인공지능 모델이 학습 알고리 즘을 기반으로 다수의 학습 데이터들을 이용하여 학습되어 원하는 특성(또는 목적)을 수행하도록 구성됨을 의미 한다. 이러한 학습은 본 개시에 따른 인공지능이 구현되는 장치 자체에서 이루어질 수도 있고, 별도의 서버 및/ 또는 시스템을 통해 이루어질 수도 있다. 인공지능 모델은 뉴럴 네트워크(또는 인공 신경망)로 구현될 수 있으며, 기계학습과 인지과학에서 생물학의 신 경을 모방한 통계학적 학습 알고리즘에 기반하여 동작할 수 있다. 뉴럴 네트워크는 시냅스의 결합으로 네트워크 를 형성한 인공 뉴런(노드)이 학습을 통해 시냅스의 결합 세기를 변화시켜 문제 해결 능력을 가지는 모델 전반 을 의미할 수 있다. 뉴럴 네트워크는 복수의 신경망 레이어(layer)들로 구성될 수 있으며, 예시적으로 뉴럴 네 트워크는 입력 레이어(input layer), 은닉 레이어(hidden layer) 및 출력 레이어(output layer)를 포함할 수 있다. 복수의 신경망 레이어들 각각은 적어도 하나의 노드(node) 및 적어도 하나의 가중치(weight)를 포함할 수 있으며, 이전(previous) 레이어의 연산 결과와 가중치 간의 연산을 통해 신경망 연산을 수행할 수 있다. 복수의 신경망 레이어들이 가지고 있는 적어도 하나의 가중치는 인공지능 모델의 학습 결과에 의하여 최적화될 수 있다. 예를 들어, 학습 과정동안 인공지능 모델에서 획득한 손실(loss) 값 또는 비용(cost) 값이 감소 또는 최 소화되도록 적어도 하나의 가중치가 갱신될 수 있다. 뉴럴 네트워크는 임의의 입력으로부터 예측하고자 하는 결 과를 추론할 수 있다. 인공지능 모델의 학습 방법은 학습 방식에 따라 입력 데이터 및 출력 데이터가 훈련 데이터로써 제공되어 문제 (입력 데이터)에 대응하는 정답(출력 데이터)이 정해져 있는 지도학습(supervised learning), 출력 데이터 없이 입력 데이터만 제공되어 문제(입력 데이터)에 대응하는 정답(출력 데이터)이 정해지지 않은 비지도학습 (unsupervised learning) 및 현재 상태(state)에서 어떤 행동(action)을 취할 때마다 보상(reward)이 부여되고, 이러한 보상을 최대화하는 방향으로 학습을 진행하는 강화학습(reinforcement learning) 등으로 구분 될 수 있다. 또는, 학습 모델의 구조인 아키텍처에 따라 구분될 수도 있다. 본 개시의 실시 예에서, 인공지능 모델은 GoogleNet, AlexNet, VGG Network 등과 같은 CNN(Convolution Neural Network), R-CNN(Region with Convolution Neural Network), RPN(Region Proposal Network), RNN(Recurrent Neural Network), S-DNN(Stacking-based deep Neural Network), S-SDNN(State-Space Dynamic Neural Network), Deconvolution Network, DBN(Deep Belief Network), RBM(Restrcted Boltzman Machine), Fully Convolutional Network, LSTM(Long Short-Term Memory) Network, Classification Network, Generative Modeling, eXplainable AI, Continual AI, Representation Learning, AI for Material Design, 자연어 처리를 위한 BERT, SP-BERT, MRC/QA, Text Analysis, Dialog System, GPT-3, GPT-4, 비전 처리를 위한 Visual Analytics, Visual Understanding, Video Synthesis, ResNet 데이터 지능을 위한 Anomaly Detection, Prediction, Time-Series Forecasting, Optimization, Recommendation, Data Creation 등 다양한 인공지능 구 조 및 알고리즘 중 적어도 하나를 이용할 수 있으며, 상술한 예시들은 본 개시의 실시 예에 따라 이용되는 인공 지능 구조 및 알고리즘의 예를 나열한 것인 뿐, 본 개시의 실시 예에 따라 이용되는 인공지능 구조 및 알고리즘 을 제한하는 것은 아니다. 한편, 본 개시에 있어서, 소프트웨어 모듈 또는 알고리즘으로 구현되는 방법들은 프로세서상에서 실행 가능한 컴퓨터가 읽을 수 있는 코드들 또는 프로그램 명령들로서 컴퓨터가 읽을 수 있는 기록 매체 상에 저장될 수 있 다. 여기서 컴퓨터가 읽을 수 있는 기록 매체는 마그네틱 저장 매체(예컨대, ROM(read-only memory), RAM(random-Access memory), 플로피 디스크, 하드 디스크 등) 및 광학적 판독 매체(예컨대, 시디롬(CD-ROM), 디브이디(DVD: Digital Versatile Disc)) 등을 포함할 수 있다. 컴퓨터가 읽을 수 있는 기록 매체는 네트워크 로 연결된 컴퓨터 시스템들에 분산되어 실행될 수 있다. 이하, 본 개시의 다양한 실시 예들은 첨부된 도면을 참조하여 상세하게 설명될 것이다. 실시 예를 설명함에 있 어서 본 발명이 속하는 기술 분야에 익히 알려져 있고 본 발명과 직접적으로 관련이 없는 기술 내용에 대해서는 설명을 생략할 것이다. 이는 불필요한 설명을 생략함으로써 본 발명의 요지를 흐리지 않고 더욱 명확히 전달하 기 위함이다. 마찬가지 이유로 첨부 도면에 있어서 일부 구성요소는 과장되거나 생략되거나 개략적으로 도시되 었다. 또한, 각 구성요소의 크기는 실제 크기를 전적으로 반영하는 것이 아니다. 본 명세서에서, 전문에 걸쳐 동일한 참조 부호는 동일한 또는 대응하는 구성 요소를 지칭할 수 있다. 도 1은 본 개시의 실시 예에 따른 컨텐츠 제공 시스템을 나타내기 위한 도면이다. 도 1을 참조하면, 본 개시의 실시 예에 따른 컨텐츠 제공 시스템은 제1 전자 장치, 제2 전자 장치 , 스트리머(streamer) 단말 및 시청자 단말을 포함할 수 있다. 본 개시의 실시 예에 따른 컨텐 츠 제공 시스템에서, 제1 전자 장치 및 제2 전자 장치 상호 간, 제1 전자 장치 및 스트리머 단말 상호 간, 그리고 제2 전자 장치 및 시청자 단말 상호 간은 네트워크 또는 물리적으로 구현 된 전기적 연결 구조를 통한 통신을 수행하고, 정보를 교환할 수 있다. 본 개시의 실시 예에 따르면, 네트워크는 PAN(Personal Area Network), LAN(Local Area Network), CAN(Campus Area Network), MAN(Metropolitan Area Network), WAN(Wide Area Network), BBN(Broad Band Network), 인터넷 중 적어도 하나의 네트워크를 포함할 수 있다. 또한, 네트워크는 버스 네트워크, 스타 네트워크, 링 네트워크, 메쉬 네트워크, 스타-버스 네트워크, 트리 또는 계층적(Hierarchical) 네트워크 등을 포함하는 네트워크 토폴로 지 중 적어도 하나를 포함할 수 있다. 본 개시의 실시 예에서, 수행되는 통신 방식은 상술한 네트워크의 종류에 제한되지 않으며, 네트워크가 포함할 수 있는 통신망을 활용하는 통신 방식뿐 아니라 기기 간의 근거리 무선 통 신 또한 포함할 수 있다. 본 개시의 실시 예에서, 제1 전자 장치 및 제2 전자 장치 각각은 트랜시버, 메모리 및 프로세서를 포 함할 수 있다. 또한, 제1 전자 장치 및 제2 전자 장치 각각은 적어도 하나의 기능이나 동작을 처리하 는 단위를 의미하며, 이는 하드웨어나 소프트웨어, 또는, 하드웨어 및 소프트웨어의 결합으로 구현될 수 있다. 실시 예에서, 제1 전자 장치 및 제2 전자 장치 각각은 네트워크 서버로 구현되는 다수의 컴퓨터 시스 템 또는 컴퓨터 소프트웨어를 포함할 수 있다. 예로서, 제1 전자 장치 및 제2 전자 장치 각각은 인트 라넷 또는 인터넷과 같은 컴퓨터 네트워크를 통하여 다른 네트워크 서버와 통신할 수 있는 하위 장치와 연결되 어 작업 수행 요청을 접수하고, 그에 대한 작업을 수행하여 수행 결과를 제공하는 컴퓨터 시스템 및 컴퓨터 소 프트웨어를 지칭할 수 있다. 한편, 본 명세서에서 제1 전자 장치 및 제2 전자 장치는 물리적으로 분리된 구성인 것으로 언급되나, 이는 본 개시에 따른 일부 실시 예에 불과하며, 본 개시의 또 다른 실시 예에 따르면 제1 전자 장치 및 제 2 전자 장치는 논리적으로 분리된 구조일 수 있고, 이 경우, 하나의 서버에서 분리된 기능에 의하여 구현 될 수 있다. 이외에도, 제1 전자 장치 및 제2 전자 장치 각각은 네트워크 서버 상에서 동작할 수 있 는 일련의 응용 프로그램 및 내부에 구축되어 있는 각종 데이터베이스를 포함하는 광의의 개념으로 이해될 수 있다. 예로서, 제1 전자 장치 및 제2 전자 장치 각각은 도스(DOS), 윈도우(Windows), 리눅스 (Linux), 유닉스(Unix) 또는 맥OS(MacOS) 등의 운영 체제에 따라 다양하게 제공되는 네트워크 서버 프로그램을 이용하여 구현될 수 있다. 본 개시의 실시 예에서, 제1 전자 장치는 컨텐츠(contents)를 제작 및 생성하기 위한 프로그램을 스트리머 단말에 대하여 제공할 수 있다. 예로서, 제1 전자 장치로부터 스트리머 단말에 대하여 제공되는 프로그램은 메타버스(metaverse) 기반의 컨텐츠를 제작 및 생성하기 위한 프로그램일 수 있다. 실시 예에서, 스 트리머는 제1 전자 장치로부터 제공된 프로그램을 이용하여 시청자에게 제공할 컨텐츠를 제작 및 생성할 수 있다. 구체적으로, 스트리머는 스트리머 단말을 통하여 제1 전자 장치에 대하여 컨텐츠 제작 및 생성을 위한 임의의 정보를 제공할 수 있으며, 제1 전자 장치는 스트리머 단말로부터 획득한 정보를 기반으로 컨텐츠를 제작할 수 있다.실시 예에서, 컨텐츠 제작 및 생성을 위한 임의의 정보는 스트리머에 대한 영상(또는 이미지) 정보를 포함할 수 있다. 스트리머에 대한 영상 정보는 카메라, 캠코더, 웹 캠 등과 같은 촬영 장치(미도시)를 이용하여 스트리머 를 촬영함으로써 획득되는 정보를 의미할 수 있으며, 촬영 장치와 네트워크 또는 물리적으로 구현된 전기적 연 결을 통해 통신을 수행하는 스트리머 단말을 통해 제1 전자 장치에 대하여 제공될 수 있다. 실시 예 에서, 촬영 장치는 영상 정보를 감지하기 위한 센서 디바이스를 포함할 수 있으며, 센서 디바이스는 일반 가시 광선 영역을 감지하여 RGB 영상 또는 바이너리 영상을 취득할 수 있다. 또는, 일부 실시 예에서, 복수의 촬영 장치들로부터 획득된 스트리머에 대한 영상 정보가 스트리머 단말을 통해 제1 전자 장치에 대하여 제 공될 수 있다. 이 경우, 복수의 촬영 장치들로부터 획득된 각각의 영상 정보는 데이터 퓨전(fusion)을 통해 융 합될 수 있다. 또는, 일부 실시 예에서, 제1 전자 장치는 기 생성된 컨텐츠를 스트리머 단말로부터 제공받을 수 있으며, 기 생성된 컨텐츠로부터 스트리머에 대한 영상 정보를 추출할 수 있다. 본 개시의 실시 예에서, 제1 전자 장치는 스트리머에 대한 영상 정보를 기반으로 가상 아바타를 생성할 수 있다. 실시 예에서, 제1 전자 장치는 미리 설정된 알고리즘 또는 인공지능 모델을 이용하여 스트리머에 대 한 영상 정보에 대응하는 가상 아바타를 생성할 수 있다. 구체적으로, 제1 전자 장치는 스트리머의 표정 및 움직임과 관련한 표현을 반영하여 가상 아바타를 생성할 수 있다. 가상 아바타를 생성하기 위한 제1 전자 장 치의 구성 및 동작에 대하여는 후술할 도 2 내지 도 8을 통해 상세히 설명할 것이다. 제1 전자 장치 는 생성된 가상 아바타를 기반으로 제작 및 생성된 컨텐츠를 제2 전자 장치에 대하여 제공할 수 있다. 본 개시의 실시 예에서, 제2 전자 장치는 제1 전자 장치로부터 획득한 컨텐츠 정보를 저장하고, 시청 자 단말에 대하여 컨텐츠를 제공할 수 있다. 제2 전자 장치는 해당 컨텐츠를 시청하는 시청자의 시청 자 단말에 대하여 해당 컨텐츠에 대한 정보를 전송하거나, 시청자에게 실시간 스트리밍(Streaming) 방식으 로 컨텐츠를 제공하는 미디어 서비스를 제공할 수 있다. 예를 들어, 제2 전자 장치는 유튜브(Youtube), 아 프리카(Africa) TV, 트위치(Twitch) 등과 같은 미디어 플랫폼을 통하여 시청자에게 컨텐츠를 제공할 수 있다. 본 개시의 실시 예에 따른 컨텐츠 제공 시스템은 스트리머에 대한 영상 정보를 기반으로 가상 아바타를 생 성하고, 이를 기반으로 제작 및 생성된 컨텐츠를 시청자에게 제공함으로써, 스트리머의 컨텐츠 제작 편의성을 향상시킬 수 있다. 또한, 본 개시의 실시 예에 따른 컨텐츠 제공 시스템은 스트리머의 움직임 및 표정과 관 련한 표현을 반영한 가상 아바타를 생성하고, 이를 기반으로 제작 및 생성된 컨텐츠를 시청자에게 제공함으로써, 보다 생동감 있는 가상 아바타를 구현할 수 있고, 이에 따라 시청자는 보다 현실감 있는 버츄어 (virtual) 컨텐츠를 향유할 수 있다. 도 2는 본 개시의 실시 예에 따른 전자 장치를 나타내기 위한 블록도이다. 도 2에 도시된 전자 장치는 상술한 도 1의 제1 전자 장치(110, 도 1 참조)에 대응할 수 있으며, 도 2를 참 조하면, 전자 장치는 표현 식별부 및 컨텐츠 생성부를 포함할 수 있다. 본 개시의 실시 예에 따르면, 표현 식별부는 스트리머 단말(130, 도 1 참조)로부터 획득한 스트리머에 대 한 영상 정보를 기반으로 스트리머의 표정 및 움직임과 관련한 표현을 식별할 수 있다. 구체적으로, 표현 식별 부는 전자 장치에 대하여 미리 설정된 알고리즘을 기반으로 이미지 정보를 분석하고, 분석 결과를 기 반으로 스트리머의 움직임 및 표정과 관련된 표현을 식별하거나, 전자 장치에 구축된 인공지능 모델을 통 하여 스트리머에 대한 영상 정보를 기반으로 스트리머의 움직임 및 표정과 관련된 표현을 식별할 수 있다. 전자 장치는 식별된 표현과 관련된 정보를 포함하는 표현 정보를 컨텐츠 생성부에 대하여 제공할 수 있다. 본 개시의 실시 예에 따른 표현 식별부의 구체적인 구성 및 동작은 후술할 도 3, 도 5a 및 도 5b를 통해 상세히 설명할 것이다. 본 개시의 실시 예에 따르면, 컨텐츠 생성부는 표현 식별부로부터 획득한 표현 정보를 기반으로 스트 리머에 대응하는 가상 아바타를 생성할 수 있다. 실시 예에서, 가상 아바타는 스트리머의 움직임 및 표정을 구 현하도록 생성될 수 있으며, 컨텐츠 생성부는 생성된 가상 아바타를 기반으로 컨텐츠를 생성할 수 있다. 한편, 컨텐츠 생성부로부터 생성된 컨텐츠와 관련된 정보를 포함하는 컨텐츠 정보는 미디어 서비스를 제공 하기 위한 제2 전자 장치(120, 도 1 참조)에 대하여 제공될 수 있으며, 해당 컨텐츠 시청을 요청하는 시청자 단 말(140, 도 1 참조)에 대하여 컨텐츠를 제공할 수 있다. 한편, 도시되지 않았으나 일부 실시 예에서, 스트리머 단말로부터 전자 장치에 대하여 영상 정보가 제공되는 경우, 영상 정보로부터 이미지 정보를 추출하기 위한 샘플링(sampling) 처리부(미도시)를 통해 해당 영상을 샘플링하여 복수의 이미지들을 추출할 수 있다. 샘플링 처리부는 복수의 이미지들 각각에 대한 정보를시간 순으로 배열한 이미지 정보 세트를 표현 식별부에 대하여 제공할 수 있으며, 표현 식별부는 이 미지 정보 세트에 포함된 이미지들 각각을 기반으로 스트리머의 표정 및 움직임의 변화에 대한 표현 정보를 도 출할 수 있다. 실시 예에서, 샘플링 처리부에 의하여 이미지 정보가 추출되는 샘플링 주기(sampling period)는 전자 장치에 대하여 미리 설정될 수 있다. 도 3은 본 개시의 실시 예에 따른 표현 식별부를 나타내기 위한 블록도이다. 도 3에 도시된 표현 식별부는 상술한 도 2의 표현 식별부(200, 도 2 참조)에 대응할 수 있으며, 도 3을 참 조하면, 본 개시의 실시 예에 따른 표현 식별부는 전처리부, 랜드마크 추출부 및 표현 결정부 를 포함할 수 있다. 본 개시의 실시 예에 따른 전처리부는 스트리머 단말(130, 도 1 참조)로부터 획득한 영상 정보(또는 이미 지 정보 세트)에 대한 전처리를 수행할 수 있으며, 전처리 과정은 영상 정보에 대한 리사이징(resizing), 정규 화(normalization) 및 바이너리 변환(binary translation) 중 적어도 일부 과정을 포함할 수 있다. 일부 실시 예에서, 영상 정보에 대한 전처리 과정이 요구되지 않는 경우, 전처리부에 의하여 수행되는 전처리 과정은 배제될 수 있다. 전처리부는 전처리 과정이 수행된 영상 정보(또는 이미지 정보 세트)를 랜드마크 추출부 에 대하여 제공할 수 있다. 본 개시의 실시 예에 따른 랜드마크 추출부는 스트리머의 표정 및 움직임을 식별하기 위하여 전처리부 로부터 획득한 영상 정보(또는 이미지 정보 세트)로부터 랜드마크를 추출할 수 있다. 실시 예에서, 스트리 머의 표정을 식별하기 위한 랜드마크는 영상 정보 상의 스트리머의 얼굴로부터 획득될 수 있으며, 스트리머의 얼굴로부터 확인되는 2차원 또는 3차원의 기준점 집합을 의미할 수 있다. 한편, 실시 예에서, 스트리머의 움직 임을 식별하기 위한 랜드마크는 영상 정보 상의 스트리머의 신체 일부(예를 들어, 손, 팔, 머리, 몸통 등)로부 터 획득될 수 있으며, 스트리머의 신체 일부로부터 확인되는 2차원 또는 3차원의 기준점 집합을 의미할 수 있다. 실시 예에서, 랜드마크 추출부는 인공지능 모델을 통하여 랜드마크를 추출할 수 있으며, 추출된 랜 드마크에 대한 정보는 표현 결정부에 대하여 제공될 수 있다. 랜드마크 추출을 위한 인공지능 모델의 학습 방법 및 스트리머의 표정 및 움직임과 관련하여 추출되는 랜드마크에 대하여는 후술할 도 5a 및 도 5b를 통해 상세히 설명할 것이다. 본 개시의 실시 예에 따른 표현 결정부는 랜드마크 추출부로부터 추출된 랜드마크를 기반으로 스트리 머의 표정 및 움직임과 관련된 표현을 결정할 수 있다. 구체적으로, 표현 결정부는 랜드마크 정보를 기반 으로 미리 설정된 복수의 표현 처리 항목들 각각에 대한 가중치를 도출할 수 있으며, 도출된 가중치를 기반으로 표현 정보를 결정할 수 있다. 일부 실시 예에서, 표현 결정부는 인공지능 모델을 이용하여 복수의 표현 처 리 항목들 각각에 대한 가중치를 도출할 수 있다. 표현 정보는 컨텐츠 생성부(220, 도 2 참조)에 제공되어 컨텐 츠 생성부에 의하여 생성되는 컨텐츠의 가상 아바타에 대하여 적용될 수 있다. 표현 결정부에 의하여 표현 정보가 결정되는 구체적인 동작은 후술할 도 6을 통해 상세히 설명할 것이다. 도 4는 본 개시의 실시 예에 따른 전자 장치(200, 도 2 참조)의 동작 방법을 설명하기 위한 순서도이다. S410 단계에서, 본 개시의 실시 예에 따른 전자 장치는 스트리머 단말(130, 도 1 참조)로부터 스트리머에 대한 영상(또는 이미지) 정보를 획득할 수 있다. 스트리머에 대한 영상 정보는 스트리머 단말과 전기적으 로 연결된 촬영 장치에 의하여 획득될 수 있으며, 일부 실시 예에서, 영상 정보는 미리 설정된 샘플링 주기에 대응하여 샘플링될 수 있고, 샘플링된 복수의 이미지들 각각은 시간 순으로 시퀀셜하게 배열되어 이미지 정보 세트를 형성할 수 있다. S420 단계에서, 본 개시의 실시 예에 따른 전자 장치는 영상 정보(또는 이미지 정보 세트)에 대한 전처리 를 수행할 수 있다. 실시 예에서, 영상 정보에 대한 전처리는 전자 장치에 대하여 설정된 사양에 대응하여 수행될 수 있으며, 리사이징, 정규화 및 바이너리 변환 중 적어도 일부 과정을 포함할 수 있다. S430 단계에서, 본 개시의 실시 예에 따른 전자 장치는 영상 정보를 기반으로 스트리머의 표정 및 움직임 을 식별하기 위한 랜드마크를 추출할 수 있다. 실시 예에서, 랜드마크는 스트리머의 표정 및 움직임을 식별하기 위하여 추출되는 2차원 또는 3차원의 기준점 집합을 의미할 수 있으며, 인공지능 모델에 대하여 입력된 영상 정 보를 기반으로 도출될 수 있다. 전자 장치에 의하여 도출되는 랜드마크에 대한 구체적인 내용은 후술할 도 5a 및 도 5b를 통해 상세히 설명할 것이다. S440 단계에서, 본 개시의 실시 예에 따른 전자 장치는 S430 단계에서 추출된 랜드마크를 기반으로 스트리 머에 대응하는 가상 아바타에 대하여 반영될 표현을 결정할 수 있다. 구체적으로, 전자 장치는 스트리머의표정을 식별하기 위하여 도출된 제1 랜드마크 정보를 기반으로 가상 아바타에 대하여 적용될 표정을 결정할 수 있으며, 스트리머의 움직임을 식별하기 위하여 도출된 제2 랜드마크 정보를 기반으로 가상 아바타에 대하여 적 용될 움직임을 결정할 수 있다. 전자 장치에 의한 표현 결정 방법은 후술할 도 6을 통하여 상세히 설명할 것이다. S450 단계에서, 본 개시의 실시 예에 따른 전자 장치는 S440 단계에서 확인된 표현 정보를 기반으로 컨텐 츠를 생성할 수 있다. 실시 예에서, 전자 장치는 스트리머의 표정 및 움직임이 적용된 가상 아바타를 생성 할 수 있으며, 생성된 가상 아바타를 기반으로 시청자에게 제공되는 컨텐츠를 생성할 수 있다. 실시 예에 따르 면, 전자 장치는 영상 정보(또는 이미지 정보 세트)를 기반으로 표현 정보를 도출하므로, 도출되는 표현 정보를 기반으로 생성된 가상 아바타는 시간의 흐름에 따른 스트리머의 표현 변화를 반영할 수 있다. 이에 따라, 전자 장치는 실제 스트리머의 표정 및 행동을 반영하여 생동감 있는 가상 아바타를 구현할 수 있다. S460 단계에서, 본 개시의 실시 예에 따른 전자 장치는 S450 단계에서 생성된 컨텐츠 정보를 미디어 서비 스를 제공하기 위한 외부 서버(예를 들어, 제2 전자 장치(120, 도 1 참조))에 대하여 제공할 수 있다. 외부 서 버는 전자 장치로부터 획득한 컨텐츠 정보를 저장하고, 시청자 단말(140, 도 1 참조)에 대하여 컨텐츠를 제공할 수 있다. 도 5a는 본 개시의 실시 예에 따라 스트리머의 표정과 관련된 랜드마크를 추출하는 과정을 설명하기 위한 도면 이다. 도 5a의 (A)는 전자 장치(200, 도 2 참조)에 대하여 제공되는 스트리머에 대한 이미지 정보를 도시한 것으로, 전자 장치는 도 5a의 (B)에 도시된 바와 같이 스트리머에 대한 이미지 정보에 나타난 스트리머의 얼굴에 대응하여 스트리머의 표정과 관련된 랜드마크(LM)를 추출할 수 있다. 실시 예에서, 전자 장치는 미리 설정 된 알고리즘 또는 인공지능 모델을 이용하여 스트리머의 표정과 관련된 랜드마크(LM)를 추출할 수 있다. 인공지 능 모델을 통하여 스트리머의 표정이 식별되는 경우, 인공지능 모델은 얼굴 이미지로부터 얼굴 형태 및 표정을 식별하기 위한 복수의 기준점들로 구성된 랜드마크(LM)를 추출하도록 학습될 수 있으며, 인공지능 모델을 학습 시키기 위한 학습 데이터로서 복수의 얼굴 이미지들 및 복수의 얼굴 이미지들 각각에 대응하는 랜드마크 정보가 이용될 수 있다. 일 실시 예에서, 스트리머의 표정을 식별하기 위한 랜드마크(LM)는 476개의 기준점들로 구성될 수 있으며, 전자 장치로부터 도출된 랜드마크를 기반으로 스트리머의 얼굴 표정이 식별될 수 있다. 전자 장치에 의한 표정 식별 방법은 후술할 도 6을 통하여 상세히 설명할 것이다. 도 5b는 본 개시의 실시 예에 따라 스트리머의 움직임과 관련된 랜드마크를 추출하는 과정을 설명하기 위한 도 면이다. 도 5b는 전자 장치(200, 도 2 참조)에 의하여 손의 움직임 식별하는 과정을 설명하기 위한 도면으로, 전자 장치 는 스트리머에 대한 이미지 정보에 나타난 스트리머의 손을 인식하고, 인식된 손에 대한 트래킹(trackin g)을 통해 스트리머의 손의 움직임을 식별하기 위한 랜드마크를 추출할 수 있다. 실시 예에서, 전자 장치 는 미리 설정된 알고리즘 또는 인공지능 모델을 이용하여 스트리머의 손의 움직임과 관련된 랜드마크(LM)를 추 출할 수 있으며, 일부 실시 예에서, 손의 움직임과 관련된 랜드마크(LM)는 스트리머에 대한 이미지 정보로부터 인식된 손에 위치하는 관절 위치에 대응하여 도출되도록 설정될 수 있다. 일 실시 예에서, 스트리머의 손의 움 직임을 식별하기 위한 랜드마크(LM)는 한 손에 대하여 21개의 기준점들로 구성(양 손에 대하여는 42개의 기준점 들이 도출될 수 있음)될 수 있으며, 전자 장치로부터 도출된 랜드마크(LM)를 기반으로 스트리머의 손의 움 직임이 식별될 수 있다. 본 개시의 실시 예에 따르면, 전자 장치는 동일한 원리에 의하여 손의 움직임 외 스트리머의 머리 움직임, 몸통 움직임 등을 식별할 수 있으며, 이와 관련된 설명은 생략한다. 도 6은 본 개시의 실시 예에 따라 가상 아바타에 구현되는 표현을 결정하는 과정을 설명하기 위한 도면이다. 도 6은 전자 장치(200, 도 2 참조)로부터 도출된 스트리머의 얼굴에 대하여 도출된 랜드마크를 기반으로 표정을 결정하기 위한 테이블을 도시한 것으로, 도 6에 도시된 테이블은 전자 장치에 대하여 미리 정의되어 저장 될 수 있다. 구체적으로, 전자 장치에 대하여 복수의 표현 처리 항목들이 정의된 테이블이 저장될 수 있으 며, 도 6에 도시된 테이블은 스트리머의 표정과 관련한 복수의 표현 처리 항목들을 포함하고 있다. 전자 장치 는 추출된 랜드마크를 기반으로 복수의 표현 처리 항목들 각각에 대한 가중치를 도출할 수 있으며, 각 항 목에 대하여 도출된 가중치를 기반으로 가상 아바타에 표현된 표정 정보를 결정할 수 있다. 각 항목에 대하여 부여되는 가중치는 0 내지 1의 범위의 값일 수 있으며, 가중치 0은 해당 항목에 대응하는 움직임이 없는 중립 (neutral) 상태인 것을 의미하고, 가중치 1은 해당 항목에 대응하는 움직임이 최대(maximum) 상태인 것을 의미할 수 있다. 한편, 도 6에 도시된 복수의 표현 처리 항목들은 본 개시의 일 실시 예에 따른 것으로, 본 개시에 따른 전자 장치에 대하여 미리 저장되는 복수의 표현 처리 항목들의 개수 및 속성은 도 6에 도시된 항목들 에 한정되지 않는다. 도 7a는 본 개시의 실시 예에 따라 스트리머의 표정에 따른 가상 아바타의 구현 양상을 설명하기 위한 도면이다. 도 7a를 참조하면, 전자 장치(200, 도 2 참조)에 대하여 입력되는 스트리머의 영상 정보(또는 이미지 정 보)(DATA_IN)에 대응하여 생성되는 가상 아바타의 표정 구현 양상(DATA_OUT)을 확인할 수 있다. 제1 사례(CASE 1)에서, 웃는 표정의 스트리머 영상 정보가 입력되는 경우, 전자 장치는 상술한 과정을 통해 스트리머의 얼굴에 대응하는 랜드마크를 도출하고, 도출된 랜드마크를 기반으로 확인된 표정 정보를 기반으로 가상 아바타 를 생성할 수 있다. 한편, 제2 사례(CASE 2) 및 제3 사례(CASE 3)에서도 스트리머의 표정을 반영한 가상 아바타 가 생성됨을 확인할 수 있다. 도 7b는 본 개시의 실시 예에 따라 스트리머의 움직임에 따른 가상 아바타의 구현 양상을 설명하기 위한 도면이 다. 도 7b를 참조하면, 전자 장치(200, 도 2 참조)에 대하여 입력되는 스트리머의 영상 정보(또는 이미지 정보 (DATA_IN)에 대응하여 생성되는 가상 아바타의 움직임 구현 양상(DATA_OUT)을 확인할 수 있다. 제1 사례(CASE 1)에서, 두 개의 손가락을 펼친 스트리머 영상 정보가 입력되는 경우, 전자 장치는 상술한 과정을 통해 스 트리머의 움직임에 대응하는 랜드마크를 도출하고, 도출된 랜드마크를 기반으로 확인된 움직임 정보를 기반으로 가상 아바타를 생성할 수 있다. 한편, 제2 사례(CASE2) 및 제3 사례(CASE 3)에서도 스트리머의 움직임을 반영한 가상 아바타가 생성됨을 확인할 수 있다. 도 8은 본 개시의 실시 예에 따른 전자 장치를 나타내기 위한 블록도이다. 도 8에 도시된 전자 장치는 상술한 도 1의 제1 전자 장치(110, 도 1 참조)에 대응할 수 있다. 도 8을 참조 하면, 본 개시의 실시 예에 따른 전자 장치는 트랜시버, 프로세서 및 메모리를 포함할 수 있다. 전자 장치는 트랜시버를 통하여 외부 단말 및 외부 장치 중 적어도 하나와 연결되고, 데이터를 교환 할 수 있다. 예로서, 전자 장치는 트랜시버를 통하여 스트리머 단말(130, 도 1 참조)과 연결될 수 있 다. 프로세서는 상술한 도 1 내지 도 7b를 통하여 설명한 적어도 하나의 장치에 의한 동작 및 적어도 하나의 방법을 수행할 수 있다. 또한, 프로세서는 상술한 도 1 내지 도 7b를 통하여 설명한 적어도 하나의 장치에 의한 동작 및 적어도 하나의 방법을 수행하기 위한 프로그램을 실행할 수 있으며, 상술한 도 1 내지 도 7b를 통 하여 설명한 적어도 하나의 장치에 의한 동작 및 적어도 하나의 방법을 수행하기 위하여 정보를 처리하고, 전자 장치를 제어할 수 있다. 메모리는 도 1 내지 도 7b를 통하여 설명한 적어도 하나의 장치에 의한 동작 및 적어도 하나의 방법을 수 행하기 위한 정보를 저장할 수 있다. 또한, 메모리는 프로세서에 의하여 실행되는 프로그램의 코드를 저장할 수 있다. 실시 예에서, 메모리는 휘발성 메모리 또는 비휘발성 메모리일 수 있다. 상술된 내용은 본 개시를 실시하기 위한 구체적인 실시 예들이다. 본 개시는 상술된 실시 예들뿐만 아니라, 단 순하게 설계 변경되거나 용이하게 변경할 수 있는 실시 예들 또한 포함할 것이다. 또한, 본 개시는 상술된 실시 예들을 이용하여 용이하게 변형하여 실시할 수 있는 기술들도 포함할 것이다. 따라서, 본 개시의 범위는 상술된 실시 예들에 국한되어 정해져서는 안 되며 후술하는 특허청구범위뿐만 아니라 본 개시의 특허청구범위와 균등한 것들에 의해 정해져야 할 것이다."}
{"patent_id": "10-2024-0128954", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 개시의 실시 예에 따른 컨텐츠 제공 시스템을 나타내기 위한 도면이다. 도 2는 본 개시의 실시 예에 따른 전자 장치를 나타내기 위한 블록도이다. 도 3은 본 개시의 실시 예에 따른 표현 식별부를 나타내기 위한 블록도이다. 도 4는 본 개시의 실시 예에 따른 전자 장치의 동작 방법을 설명하기 위한 순서도이다. 도 5a는 본 개시의 실시 예에 따라 스트리머(streamer)의 표정과 관련된 랜드마크를 추출하는 과정을 설명하기 위한 도면이다. 도 5b는 본 개시의 실시 예에 따라 스트리머의 움직임과 관련된 랜드마크를 추출하는 과정을 설명하기 위한 도 면이다. 도 6은 본 개시의 실시 예에 따라 가상 아바타에 구현되는 표현을 결정하는 과정을 설명하기 위한 도면이다. 도 7a는 본 개시의 실시 예에 따라 스트리머의 표정에 따른 가상 아바타의 구현 양상을 설명하기 위한 도면이다. 도 7b는 본 개시의 실시 예에 따라 스트리머의 움직임에 따른 가상 아바타의 구현 양상을 설명하기 위한 도면이 다. 도 8은 본 개시의 실시 예에 따른 전자 장치를 나타내기 위한 블록도이다."}
