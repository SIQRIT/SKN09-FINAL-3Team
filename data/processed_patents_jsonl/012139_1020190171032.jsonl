{"patent_id": "10-2019-0171032", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2021-0079004", "출원번호": "10-2019-0171032", "발명의 명칭": "컴퓨팅 장치 및 그 동작 방법", "출원인": "삼성전자주식회사", "발명자": "김동완"}}
{"patent_id": "10-2019-0171032", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "컴퓨팅 장치에 있어서,하나 이상의 인스트럭션을 저장하는 메모리; 및상기 메모리에 저장된 상기 하나 이상의 인스트럭션을 실행하는 프로세서를 포함하고, 상기 프로세서는, 상기하나 이상의 인스트럭션을 실행함으로써, 타 음성 어시스턴트에 대응하는 트리거 워드를 인식하고,상기 타 음성 어시스턴트에 대하여 발화되는 발화 내용에 대응하여 상기 타 음성 어시스턴트에 의해 제공되는상기 타 음성 어시스턴트의 반응 동작을 분석하고,상기 발화 내용에 대응하여 수행되는 동작을 시뮬레이션하고, 상기 타 음성 어시스턴트의 반응 동작 분석 결과 및 상기 시뮬레이션 결과에 기반하여, 후속 동작을 수행하는,컴퓨팅 장치."}
{"patent_id": "10-2019-0171032", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 프로세서는, 상기 하나 이상의 인스트럭션을 실행함으로써, 상기 트리거 워드를 인식한 결과에 따라 특정된 트리거 워드의 인식률이 임계치 미만인 경우, 상기 특정된 트리거 워드를 학습하는, 컴퓨팅 장치."}
{"patent_id": "10-2019-0171032", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 타 음성 어시스턴트에 대한 상기 발화 내용은, 서비스 요청을 위한 발화 내용, 상기 서비스 요청에 대응한상기 타 음성 어시스턴트의 반응 발화 내용, 또는 상기 타 음성 어시스턴트의 질문에 대한 사용자의 답변 발화내용 중 적어도 하나를 포함하는, 컴퓨팅 장치."}
{"patent_id": "10-2019-0171032", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,상기 타 음성 어시스턴트의 반응 동작은, 음성 반응 동작, 이미지 반응 동작 또는 텍스트 반응 동작 중 적어도하나를 포함하는, 컴퓨팅 장치."}
{"patent_id": "10-2019-0171032", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서,상기 프로세서는, 상기 하나 이상의 인스트럭션을 실행함으로써, 상기 음성 반응 동작, 상기 비디오 반응 동작 또는 상기 텍스트 반응 동작 중 적어도 하나에 기초하여 상기 타음성 어시스턴트의 반응 동작이 상기 발화 내용에 대응하는 결과를 도출했는지 여부를 판단하는 , 컴퓨팅 장치."}
{"patent_id": "10-2019-0171032", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서,상기 프로세서는, 상기 하나 이상의 인스트럭션을 실행함으로써, 상기 시뮬레이션 결과 상기 발화 내용에 대응하는 결과를 도출한 것으로 판단됨에 따라 사용자에게 통지를 제공공개특허 10-2021-0079004-3-하는, 컴퓨팅 장치."}
{"patent_id": "10-2019-0171032", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6항에 있어서,상기 프로세서는, 상기 하나 이상의 인스트럭션을 실행함으로써, 상기 타 음성 어시스턴트의 반응 동작이 상기 발화 내용에 대응하는 결과를 도출하지 못한 것으로 판단된 경우,상기 사용자에게 통지를 실시간으로 제공하는, 컴퓨팅 장치."}
{"patent_id": "10-2019-0171032", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제6항에 있어서,상기 프로세서는, 상기 하나 이상의 인스트럭션을 실행함으로써, 상기 타 음성 어시스턴트의 반응 동작이 상기 발화 내용에 대응하는 결과를 도출하지 못한 것으로, 상기 사용자의 요청이 있는 경우 상기 통지를 상기 사용자에게 제공하는, 컴퓨팅 장치."}
{"patent_id": "10-2019-0171032", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1항에 있어서,상기 프로세서는, 상기 하나 이상의 인스트럭션을 실행함으로써, 상기 시뮬레이션 결과 상기 동작 수행이 실패로 판단됨에 따라, 실패로 판단된 동작 수행 결과를 시스템 학습업데이트에 이용하는, 컴퓨팅 장치."}
{"patent_id": "10-2019-0171032", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9항에 있어서,상기 프로세서는, 상기 하나 이상의 인스트럭션을 실행함으로써,상기 동작 수행 실패가 인식 실패 또는 의도 분석 오류에 기인된 것으로 판단됨에 따라 음성 인식 시스템을 학습 및 업데이트 수행하는, 컴퓨팅 장치."}
{"patent_id": "10-2019-0171032", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "컴퓨팅 장치의 동작 방법에 있어서,타 음성 어시스턴트에 대응하는 트리거 워드를 인식하는 동작,상기 타 음성 어시스턴트에 대하여 발화되는 발화 내용에 대응하여 상기 타 음성 어시스턴트에 의해 제공되는상기 타 음성 어시스턴트의 반응 동작을 분석하는 동작,상기 발화 내용에 대응하여 수행되는 동작을 시뮬레이션하는 동작, 및 상기 타 음성 어시스턴트의 반응 동작 분석 결과 및 상기 시뮬레이션 결과에 기반하여, 후속 동작을 결정하고수행하는 동작을 포함하는, 컴퓨팅 장치의 동작 방법."}
{"patent_id": "10-2019-0171032", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항에 있어서,상기 타 음성 어시스턴트에 대한 상기 발화 내용은, 서비스 요청을 위한 발화 내용, 상기 서비스 요청에 대응한상기 타 음성 어시스턴트의 반응 발화 내용, 또는 상기 타 음성 어시스턴트의 질문에 대한 사용자의 답변 발화내용 중 적어도 하나를 포함하는, 컴퓨팅 장치의 동작 방법."}
{"patent_id": "10-2019-0171032", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제11항에 있어서,상기 타 음성 어시스턴트의 반응 동작은, 음성 반응 동작, 이미지 반응 동작 또는 텍스트 반응 동작 중 적어도공개특허 10-2021-0079004-4-하나를 포함하는, 컴퓨팅 장치의 동작 방법."}
{"patent_id": "10-2019-0171032", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제13항에 있어서,상기 음성 반응 동작, 상기 비디오 반응 동작 또는 상기 텍스트 반응 동작 중 적어도 하나에 기초하여 상기 타음성 어시스턴트의 반응 동작이 상기 발화 내용에 대응하는 결과를 도출했는지 여부를 판단하는 동작을 더 포함하는, 컴퓨팅 장치의 동작 방법."}
{"patent_id": "10-2019-0171032", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제14항에 있어서,상기 타 음성 어시스턴트의 반응 동작이 상기 발화 내용에 대응하는 결과를 도출하지 못한 것으로 판단된 경우,사용자에게 통지를 실시간으로 제공하는 동작을 더 포함하는, 컴퓨팅 장치의 동작 방법."}
{"patent_id": "10-2019-0171032", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제14항에 있어서,상기 타 음성 어시스턴트의 반응 동작이 상기 발화 내용에 대응하는 결과를 도출하지 못한 것으로, 사용자의 요청이 있는 경우 상기 통지를 상기 사용자에게 제공하는 동작을 더 포함하는, 컴퓨팅 장치의 동작 방법."}
{"patent_id": "10-2019-0171032", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제11항에 있어서,상기 시뮬레이션 결과 상기 동작 수행이 실패로 판단됨에 따라, 실패로 판단된 동작 수행 결과를 시스템 학습업데이트에 이용하는 동작을 더 포함하는, 컴퓨팅 장치의 동작 방법."}
{"patent_id": "10-2019-0171032", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제11항에 있어서,상기 시뮬레이션 결과 상기 동작 수행이 실패로 판단됨에 따라, 상기 동작 수행 실패가 인식 실패 또는 의도 분석 오류에 기인된 것으로 판단됨에 따라 음성 인식 시스템을 학습 및 업데이트 수행하는 동작을 더 포함하는,컴퓨팅 장치의 동작 방법."}
{"patent_id": "10-2019-0171032", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제11항에 있어서,서비스 요청에 대응하는 동작 수행 실패가 기능 또는 서비스의 부재로 인해 기인된 것으로 판단됨에 따라 상기기능 또는 상기 서비스 개선을 위한 시스템을 학습 및 업데이트 하거나 또는 상기 기능/서비스 개선 요청을 외부 서버로 전송하는 동작을 더 포함하는, 컴퓨팅 장치의 동작 방법."}
{"patent_id": "10-2019-0171032", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "컴퓨팅 장치의 동작 방법을 수행하는 프로그램이 기록된 컴퓨터 판독가능 기록 매체에 있어서, 상기 컴퓨팅 장치의 동작 방법은, 타 음성 어시스턴트에 대응하는 사용자의 트리거 워드를 인식하는 동작,상기 타 음성 어시스턴트에 대하여 발화되는 발화 내용에 대응하여 상기 타 음성 어시스턴트에 의해 제공되는상기 타 음성 어시스턴트의 반응 동작을 분석하는 동작,상기 발화 내용에 대응하여 수행되는 동작을 시뮬레이션하는 동작, 및 상기 타 음성 어시스턴트의 반응 동작 분석 결과 및 상기 시뮬레이션 결과에 기반하여, 후속 동작을 결정하고수행하는 동작을 포함하는, 컴퓨터 판독가능 기록 매체.공개특허 10-2021-0079004-5-"}
{"patent_id": "10-2019-0171032", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "실시예들에 따라, 컴퓨팅 장치 및 그 동작 방법이 개시된다. 실시예들에 따른 컴퓨팅 장치는, 하나 이상의 인스 트럭션을 저장하는 메모리; 및 상기 메모리에 저장된 상기 하나 이상의 인스트럭션을 실행하는 프로세서를 포함 하고, 상기 프로세서는, 상기 하나 이상의 인스트럭션을 실행함으로써, 타 음성 어시스턴트에 대응하는 트리거 워드를 인식하고, 상기 타 음성 어시스턴트에 대해서 발화되는 발화 내용에 대응하여 제공되는 상기 타 음성 어 시스턴트의 반응 동작을 분석할 수 있다. 컴퓨팅 장치는 또한 발화 내용에 대응하여 수행되는 동작을 시뮬레이 션하고, 상기 타 음성 어시스턴트의 반응 동작 분석 결과 및 상기 시뮬레이션 결과에 기반하여, 후속 동작을 수 행한다."}
{"patent_id": "10-2019-0171032", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "다양한 실시예들은 컴퓨팅 장치 및 그 동작 방법에 관한 것으로, 보다 구체적으로는, 음성 어시스턴트 기능을 개선시킬 수 있는 컴퓨팅 장치 및 그 동작 방법에 관한 것이다."}
{"patent_id": "10-2019-0171032", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "근래 들어 인공 지능을 이용하여 음성 어시스턴트 기능을 지원하는 다양한 기기가 보급화되고 있다. 인공 지능 시스템은 인간 수준의 지능을 구현하는 컴퓨터 시스템이며, 기존 룰(rule) 기반 스마트 시스템과 달리 기계가 스스로 학습하고 판단하며 똑똑해지는 시스템이다. 인공지능 시스템은 사용할수록 인식률이 향상되고 사용자의 취향을 보다 정확하게 이해할 수 있게 되어, 기존의 룰 기반 스마트 시스템은 점차 딥러닝 기반 인공지능 시스 템으로 대체되고 있다. 인공 지능을 이용한 음성 어시스턴트 기능을 지원하는 기기는, 비디오 오디오 등의 컨텐츠를 검색하거나, 상식 이나 생활 정보 등을 검색하거나, 또는 특정한 어플리케이션 등을 실행하는 등의 다양한 기능을 수행할 수 있다. 또한, 인공 지능을 이용한 음성 어시스턴트 기능은 스피커, TV, 스마트폰, OTT 박스 등 다양한 컴퓨팅 장치에서 구현될 수 있다. 이와 같이 인공 지능을 이용한 음성 어시스턴트 기능을 지원하는 기기가 다양한 형태로 보급됨에 따라 댁 내에 서도 다양한 기기에 다양한 음성 어시스턴트 기능이 구현되어 있을 수 있다. 또한 하나의 기기에도 두 개 이상 의 음성 어시스턴트 기능이 구현되어 있을 수 있다. 예를 들어 댁내 설치된 텔레비전에 복수의 음성 어시스턴 트 기능 모듈이 설치되어 있을 수 있다. 일반적으로 각 음성 어시스턴트 기능 모듈은 해당 음성 어시스턴트 기 능 모듈에 대응하는 트리거 워드 등으로 호출되어 동작 상태로 웨이크업 될 수 있다. 또한 음성 어시스턴트 기 능 모듈이 기본적으로는 음성을 이용하여 서비스를 제공하는 것은 유사하겠지만, 다양한 음성 어시스턴트 기능 모듈 각각은 나름대로의 고유한 기능이나 서비스를 제공할 수 있거나 또는 다른 음성 어시스턴트 기능 모듈보다 더 강력한 기능이나 서비스를 제공할 수 있는 응용이나 분야가 있을 수 있다. 그러나, 사용자로서는 다수의 음성 어시스턴트 기능 모듈 중에서 어떤 음성 어시스턴트 기능 모듈이 사용자의 현재 요구 사항을 가장 적절하게 서비스해줄 수 있는지를 인식하기 어려울 수 있다."}
{"patent_id": "10-2019-0171032", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "다양한 실시예들은, 따라서, 하나 이상의 타 음성 어시스턴트 모듈 즉, 이웃 음성 어시스턴트 모듈의 동작을 모 니터링함으로써 본 음성 어시스턴트 모듈의 성능을 개선시킬 수 있는 컴퓨팅 장치 및 방법을 제공하는 것을 목 적으로 한다."}
{"patent_id": "10-2019-0171032", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "일 실시예에 따른 컴퓨팅 장치는, 하나 이상의 인스트럭션을 저장하는 메모리; 및 상기 메모리에 저장된 상기 하나 이상의 인스트럭션을 실행하는 프로세서를 포함하고, 상기 프로세서는, 상기 하나 이상의 인스트럭션을 실 행함으로써, 타 음성 어시스턴트에 대응하는 트리거 워드를 인식하고, 상기 타 음성 어시스턴트에 대하여 발화 되는 발화 내용에 대응하여 상기 타 음성 어시스턴트에 의해 제공되는 상기 타 음성 어시스턴트의 반응 동작을 분석하고, 상기 발화 내용에 대응하여 수행되는 동작을 시뮬레이션하고, 상기 타 음성 어시스턴트의 반응 동작 분석 결과 및 상기 시뮬레이션 결과에 기반하여, 후속 동작을 수행한다. 일 실시예에 따라 프로세서는, 상기 하나 이상의 인스트럭션을 실행함으로써, 상기 트리거 워드를 인식한 결과 에 따라 특정된 트리거 워드의 인식률이 임계치 미만인 경우, 상기 특정된 트리거 워드를 학습할 수 있다. 일 실시예에 따라 타 음성 어시스턴트에 대한 상기 발화 내용은, 서비스 요청을 위한 발화 내용, 상기 서비스 요청에 대응한 상기 타 음성 어시스턴트의 반응 발화 내용, 또는 상기 타 음성 어시스턴트의 질문에 대한 사용 자의 답변 발화 내용 중 적어도 하나를 포함할 수 있다. 일 실시예에 따라 타 음성 어시스턴트의 반응 동작은, 음성 반응 동작, 이미지 반응 동작 또는 텍스트 반응 동 작 중 적어도 하나를 포함할 수 있다. 일 실시예에 따라 프로세서는, 상기 하나 이상의 인스트럭션을 실행함으로써, 상기 음성 반응 동작, 상기 비디 오 반응 동작 또는 상기 텍스트 반응 동작 중 적어도 하나에 기초하여 상기 타 음성 어시스턴트의 반응 동작이 상기 발화 내용에 대응하는 결과를 도출했는지 여부를 판단할 수 있다. 일 실시예에 따라 프로세서는, 상기 하나 이상의 인스트럭션을 실행함으로써, 상기 시뮬레이션 결과 상기 발화 내용에 대응하는 결과를 도출한 것으로 판단됨에 따라 사용자에게 통지를 제공할 수 있다. 일 실시예에 따라 프로세서는, 상기 하나 이상의 인스트럭션을 실행함으로써, 상기 타 음성 어시스턴트의 반응 동작이 상기 발화 내용에 대응하는 결과를 도출하지 못한 것으로 판단된 경우, 상기 사용자에게 통지를 실시간 으로 제공할 수 있다. 일 실시예에 따라 프로세서는, 상기 하나 이상의 인스트럭션을 실행함으로써, 상기 타 음성 어시스턴트의 반응 동작이 상기 발화 내용에 대응하는 결과를 도출하지 못한 것으로, 상기 사용자의 요청이 있는 경우 상기 통지를 상기 사용자에게 제공할 수 있다. 일 실시예에 따라 프로세서는, 상기 하나 이상의 인스트럭션을 실행함으로써, 상기 시뮬레이션 결과 상기 동작 수행이 실패로 판단됨에 따라, 실패로 판단된 동작 수행 결과를 시스템 학습 업데이트에 이용할 수 있다. 일 실시예에 따라 프로세서는, 상기 하나 이상의 인스트럭션을 실행함으로써, 상기 동작 수행 실패가 인식 실패 또는 의도 분석 오류에 기인된 것으로 판단됨에 따라 음성 인식 시스템을 학습 및 업데이트 수행할 수 있다. 일 실시예에 따른 컴퓨팅 장치의 동작 방법은, 타 음성 어시스턴트에 대응하는 트리거 워드를 인식하는 동작, 상기 타 음성 어시스턴트에 대하여 발화되는 발화 내용에 대응하여 상기 타 음성 어시스턴트에 의해 제공되는 상기 타 음성 어시스턴트의 반응 동작을 분석하는 동작, 상기 발화 내용에 대응하여 수행되는 동작을 시뮬레이 션하는 동작, 및 상기 타 음성 어시스턴트의 반응 동작 분석 결과 및 상기 시뮬레이션 결과에 기반하여, 후속 동작을 결정하고 수행하는 동작을 포함한다. 일 실시예에 따라 컴퓨팅 장치의 동작 방법을 수행하는 프로그램이 기록된 컴퓨터 판독가능 기록 매체에 있어서, 상기 컴퓨팅 장치의 동작 방법은, 타 음성 어시스턴트에 대응하는 사용자의 트리거 워드를 인식하는 동 작, 상기 타 음성 어시스턴트에 대하여 발화되는 발화 내용에 대응하여 상기 타 음성 어시스턴트에 의해 제공되 는 상기 타 음성 어시스턴트의 반응 동작을 분석하는 동작, 상기 발화 내용에 대응하여 수행되는 동작을 시뮬레 이션하는 동작, 및 상기 타 음성 어시스턴트의 반응 동작 분석 결과 및 상기 시뮬레이션 결과에 기반하여, 후속 동작을 결정하고 수행하는 동작을 포함한다."}
{"patent_id": "10-2019-0171032", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 개시서의 다양한 실시예들에 따르면, 타 음성 어시스턴트 시스템과 별도의 연동이나 복잡한 구조의 필요 없 이 타 음성 어시스턴트에 발화 및 요청한 내용, 타 음성 어시스턴트의 반응 내용 및 실패했던 원인 등을 분석함 으로써 본 음성 어시스턴트 시스템의 지능 향상 및 서비스 개선을 제공할 수 있다. 예를 들어, 타 음성 어시스턴트에 대한 사용자의 서비스 요청에 대응하는 발화 내용에 대응하는 동작을 시뮬레 이션 해 본 결과 만약 실패한 경우에도 이러한 실패 동작을 본 음성 어시스턴트의 학습의 기회로 이용하거나 사 용자가 요청한 기능이나 서비스를 업데이트하는 기회로 이용함으로써 본 음성 어시스턴트의 지능을 향상시키고, 기능이나 서비스 제공 확대를 할 수 있다. 예를 들어, 타 음성 어시스턴트에 대한 사용자의 서비스 요청에 대응하는 발화 내용에 대응하는 동작을 시뮬레 이션 해 본 결과 성공한 경우, 타 음성 어시스턴트의 동작 제공 실패한 서비스에 대해서 사용자에게 본 음성 어 시스턴트에서 해당 서비스 제공이 가능함을 안내하거나 또는 실제로 제공함으로써, 사용자에게 편의성을 제공할 수 있다. 이와 같이 타 음성 어시스턴트가 실패한 기능이나 서비스를 제공해줌으로써 본 음성 어시스턴트가 타 음성 어시 스턴트보다 지능적인 어시스턴트라는 이미지를 심어줌으로써 사용자의 만족도를 향상시킴으로써 타 음성 어시스 턴트 대비 경쟁력을 확보할 수 있다."}
{"patent_id": "10-2019-0171032", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 명세서에서 사용되는 용어에 대해 간략히 설명하고, 본 발명에 대해 구체적으로 설명하기로 한다. 본 발명에서 사용되는 용어는 본 발명에서의 기능을 고려하면서 가능한 현재 널리 사용되는 일반적인 용어들을 선택하였으나, 이는 당 분야에 종사하는 기술자의 의도 또는 판례, 새로운 기술의 출현 등에 따라 달라질 수 있 다. 또한, 특정한 경우는 출원인이 임의로 선정한 용어도 있으며, 이 경우 해당되는 발명의 설명 부분에서 상세 히 그 의미를 기재할 것이다. 따라서 본 발명에서 사용되는 용어는 단순한 용어의 명칭이 아닌, 그 용어가 가지 는 의미와 본 발명의 전반에 걸친 내용을 토대로 정의되어야 한다. 명세서 전체에서 어떤 부분이 어떤 구성요소를 \"포함\"한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다른 구성요소를 제외하는 것이 아니라 다른 구성요소를 더 포함할 수 있음을 의미한다. 또한, 명세서에 기재된 \"...부\", \"모듈\" 등의 용어는 적어도 하나의 기능이나 동작을 처리하는 단위를 의미하며, 이는 하드웨어 또는 소프트웨어로 구현되거나 하드웨어와 소프트웨어의 결합으로 구현될 수 있다. 아래에서는 첨부한 도면을 참고하여 실시예들에 대하여 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자 가 용이하게 실시할 수 있도록 상세히 설명한다. 그러나 본 발명은 여러 가지 상이한 형태로 구현될 수 있으며 여기에서 설명하는 실시예에 한정되지 않는다. 그리고 도면에서 본 발명을 명확하게 설명하기 위해서 설명과 관 계없는 부분은 생략하였으며, 명세서 전체를 통하여 유사한 부분에 대해서는 유사한 도면 부호를 붙였다. 본 명세서의 실시예에서 \"사용자\"라는 용어는 제어 장치를 이용하여 컴퓨팅 장치 또는 전자 장치의 기능 또는 동작을 제어하는 사람을 의미하며, 시청자, 관리자 또는 설치 기사를 포함할 수 있다. 도 1은 다양한 실시예들에 따라 음성 어시스턴트 기능을 개선하기 위한 시스템의 개념을 설명하기 위한 참고도 이다. 도 1을 참조하면, 시스템은 하나 이상의 음성 어시스턴트를 포함할 수 있다. 예를 들어, 시스템은, 텔레비전에 설치된 음성 어시스턴트 구글라 10, 스마트폰에 설치된 음성 어시스턴트 시리우스 20, OTT 박스에 설치된 어시 스턴트 알렉스 30, 스피커에 설치된 어시스턴트 빅스비 100을 포함할 수 있다. 음성 어시스턴트는 인공 지능을 이용하여 비서(어시스턴스) 서비스를 제공하는 기술을 말한다. 인공지능 시스템 은 인간 수준의 지능을 구현하는 컴퓨터 시스템으로서 기계가 스스로 학습하고 판단하며, 사용할수록 인식률이 향상되는 시스템이다. 인공지능 기술은 입력 데이터들의 특징을 스스로 분류/학습하는 알고리즘을 이용하는 기 계학습(딥러닝) 기술 및 기계학습 알고리즘을 활용하여 인간 두뇌의 인지, 판단 등의 기능을 모사하는 요소 기 술들로 구성된다. 요소기술들은, 예로, 인간의 언어/문자를 인식하는 언어적 이해 기술, 사물을 인간의 시각처 럼 인식하는 시각적 이해 기술, 정보를 판단하여 논리적으로 추론하고 예측하는 추론/예측 기술, 인간의 경험 정보를 지식데이터로 처리하는 지식 표현 기술 및 차량의 자율 주행, 로봇의 움직임을 제어하는 동작 제어 기술 중 적어도 하나를 포함할 수 있다. 음성 어시스턴트는 어시스턴트 서비스를 제공하기 위해 음성 인식, 영상 인식, 정보 추천 등에 인공 지능을 이 용할 수 있다. 음성 인식을 위한 언어적 이해는 인간의 언어/문자를 인식하고 응용/처리하는 기술로서, 자연어 처리, 기계 번역, 대화시스템, 질의 응답, 음성 인식/합성 등을 포함한다. 영상 인식을 위한 시각적 이해는 사 물을 인간의 시각처럼 인식하여 처리하는 기술로서, 객체 인식, 객체 추적, 영상 검색, 사람 인식, 장면 이해, 공간 이해, 영상 개선 등을 포함한다. 정보 추천을 위한 추론 예측은 정보를 판단하여 논리적으로 추론하고 예 측하는 기술로서, 지식/확률 기반 추론, 최적화 예측, 선호 기반 계획, 추천 등을 포함한다. 일반적으로 각 음성 어시스턴트는 고유의 트리거 워드나 웨이크업 워드를 수신하면 이를 인식하고 서비스를 요 청하는 사용자 90로부터 다음 발화 내용을 리스닝하는 상태로 진입한다. 예를 들어, 이웃 음성 어시스턴트 구 글라 10는 \"하이 구글라\"라는 트리거 워드에 의해, 이웃 음성 어시스턴트 시리우스 20는 \"하이 시리우스\"라는 트리거 워드에 의해, 이웃 어시스턴트 알렉스 30는 \"하이 알렉스\" 라는 트리거 워드에 의해, 본 어시스턴트 빅 스비 100a는 \"하이 빅스비\"라는 트리거 워드에 의해 웨이크업 될 수 있다. 통상적으로 각 음성 어시스턴트는 자신의 고유 트리거 워드를 인식하도록 학습되어 있어서, 사용자가 타 음성 어시스턴트를 호출하는 트리거 워드를 발화한다고 하여도 해당 음성 어시스턴트가 아닌 다른 음성 어시스턴트는 발화된 트리거 워드를 인식할 수 없는 것이 일반적이다. 그러나 본 개시서에 개시된 실시예들에 따른 음성 어시스턴트는, 자신의 트리거 워드 뿐만 아니라 타 음성 어시 스턴트 고유의 트리거 워드도 함께 학습해놓음으로써, 사용자가 타 음성 어시스턴트를 호출하는 트리거 워드를 인식할 수 있다. 일단 트리거 워드가 인식되고 나면 실시예에 따른 음성 어시스턴트는 이후의 발화 내용 즉, 사용자가 서비스를 요청하는 발화 내용, 사용자의 서비스 요청에 반응하는 타 음성 어시스턴트의 반응 동작에 따른 발화 내용을 포함하여, 사용자와 타 음성 어시스턴트 간의 대화 내용을 듣고 인식할 수 있다. 예를 들어, 도 1을 참조하면, 사용자 90가 \"하이, 시리우스\"라고 트리거 워드를 발화한 경우에, 본 음성 어시스턴트 빅스비 100a는 이러한 트리거 워드를 인식하고 다음 발화 내용을 리스닝하는 상태로 진입할 수 있다. 그리고 타 어시 스턴트 시리우스가 대답을 하거나 이후의 반응 내용을 포함하는 발화 내용을 인식할 수 있다. 물론 본 음성 어 시스턴트 빅스비 100a는 시리우스 뿐만 아니라 타 음성 어시스턴트인 구글라, 알렉스 등도 모두 학습을 해놓고 각 타 음성 어시스턴트의 트리거 워드를 인식할 수 있다. 그리고, 실시예들에 따른 음성 어시스턴트는 인식한 발화 내용 또는 대화 내용을 이용하여, 후속 동작을 수행할 수 있다. 예를 들어, 실시예들에 따른 음성 어시스턴트는 인식한 발화 내용 또는 대화 내용을 기초로, 자신의 기능을 학습하거나 업데이트할 수 있다. 또는, 실시예들에 따른 음성 어시스턴트는 인식한 발화 내용 또는 대 화 내용을 기초로, 사용자에게 사용자가 요청한 서비스에 대한 가이드나 추천 서비스를 제공할 수 있다. 실시예들에 따른 음성 어시스턴트는 타 음성 어시스턴트를 호출하는 사용자의 트리거 워드를 인식하고, 타 음성 어시스턴트에 대해서 서비스를 요청하기 위한 사용자의 발화 내용 및 이러한 사용자의 발화 내용에 대응하여 제 공되는 타 음성 어시스턴트의 반응 동작을 인식하고 분석할 수 있다. 또한, 실시예들에 따른 음성 어시스턴트는 타 음성 어시스턴트에 대해서 서비스를 요청하기 위한 사용자의 발화 내용에 대응하여 수행되는 동작을 직접 시뮬레이션할 수 있다. 또한, 실시예들에 따른 음성 어시스턴트는 타 음성 어시스턴트의 반응 동작을 분석한 결과 및 직접 시뮬레이션 수행한 결과에 기반하여, 후속 동작을 결정하고 수행할 수 있다. 일 실시예에 따라 음성 어시스턴트는 사용자가 발화한 트리거 워드를 인식할 때, 인식한 결과에 따라 특정된 트 리거 워드의 인식률이 임계치 미만인 경우, 인식률이 임계치 미만으로 특정된 트리거 워드를 학습할 수 있다. 인식률이 임계치 미만인 경우, 해당 트리거 워드의 인식에 대한 학습이 부족한 것으로 나타내므로 이를 강화하 기 위해 학습을 수행할 수 있다. 일 실시예에 따라, 실시예들에 따른 음성 어시스턴트는, 타 음성 어시스턴트에 대한 사용자의 발화 내용으로서, 서비스 요청을 위한 발화 내용, 또는 타 음성 어시스턴트의 질문에 대한 사용자의 답변 발화 내용 중 적어도 하 나를 인식할 수 있다. 실시예들에 따른 음성 어시스턴트는 사용자의 서비스 요청에 대응하여 제공되는 타 음성 어시스턴트의 반응 동 작을 인식할 수 있다. 이때, 실시예들에 따른 음성 어시스턴트는 타 음성 어시스턴트의 음성 반응 동작 뿐만 아니라 시각적 반응 동작 또는 텍스트 반응 동작도 인식할 수 있다. 실시예들에 따른 음성 어시스턴트는 타 음성 어시스턴트의 음성 반응 동작을 분석할 때, 음성 반응 동작 내에 미리 지정된 단어가 있는지 여부, 또는 추가적인 질문형 반응인지 여부를 이용하여 음성 반응 동작을 분석할 수 있다. 실시예들에 따른 음성 어시스턴트는 타 음성 어시스턴트의 시각적 반응 동작 또는 텍스트 반응 동작을 분석할 때, 시각적 반응 동작 또는 텍스트 반응 동작에 따라 자동 문자 인식 기술을 이용하여 아이템 또는 텍스트를 인 식하고, 인식된 아이템 또는 텍스트의 의미를 분석할 수 있다. 실시예들에 따른 음성 어시스턴트는 타 음성 어시스턴트의 음성 반응 동작, 시각적 반응 동작 또는 텍스트 반응 동작 중 적어도 하나에 기초하여 타 음성 어시스턴트의 반응 동작의 성공이나 실패 여부를 판단할 수 있다. 즉, 이러한 성공이나 실패 여부는, 발화 내용에 대응하는 결과를 도출하였는지 여부에 따라서 결정될 수 있다. 실시예들에 따른 음성 어시스턴트는 타 음성 어시스턴트에 서비스 요청을 위해 발화한 사용자의 발화 내용에 대 응하여 수행되는 동작을 시뮬레이션 해보고, 시뮬레이션 결과 동작 수행이 성공으로 판단됨에 따라 사용자에게 통지를 제공할 수 있다. 예를 들어, 실시예들에 따른 음성 어시스턴트는 시뮬레이션 결과 동작 수행이 성공인 경우, 사용자에게 통지를 실시간으로 제공하거나 또는 사용자의 요청이 있는 경우 통지를 사용자에게 제공할 수 있다. 사용자에게 통지를 실시간으로 할 지 추후 본 음성 어시스턴트를 호출하는 사용자의 요청이 있는 경우에 할지는, 타 음성 어시스턴트에게 사용자가 요청한 서비스의 내용에 따라서 결정될 수 있다. 서비스 내용이 현 재 시점에서 수행되어야 의미가 있는 것이라면 실시간으로 통지를 하는 것이 바람직하다. 예를 들어 “지금 날 씨가 어때” 또는 “지금 친구에게 전화 걸어줘” 와 같은 서비스 요청은 현재 서비스가 수행되지 않는다면 의 미가 없는 종류의 서비스들이다. 따라서 이러한 현재 시간과 관련된 서비스 내용에 대해서는 사용자에게 실시 간으로 통지를 해주는 것이 바람직하다. 서비스 내용이 반드시 현재 수행될 필요성이 떨어지는 것이라면 나중 에 통지를 할 수 있다. 예를 들어, “다음주 스케쥴 알려줘” 또는 “요즘 인기곡 틀어줘”와 같은 서비스 요 청은 상대적으로 현재 시점과의 관련성이 떨어지는 것으로 판단될 수 있고 이 경우에는 실시간이 아니라 추후 사용자가 본 음성 어시스턴트를 호출하여 어떤 서비스를 요청한 경우, 해당 서비스 요청에 대한 반응 제공 후, 추가적으로 사용자가 이전에 타 음성 어시스턴트에 의해 실패했던 서비스들에 대해서 현재 제공될 수 있음을 가 이드 할 수 있다. 예를 들어, 본 음성 어시스턴트는 일차적으로 사용자가 요청한 서비스 제공 후에, “다음주 스케쥴도 알려드릴까요? “ 와 같이 이전 실패한 서비스들을 사용자가 원하는지 문의하는 통지를 할 수 있다. 실시예들에 따른 음성 어시스턴트는 시뮬레이션 결과 동작 수행이 실패로 판단됨에 따라, 실패로 판단된 동작 수행 결과를 시스템 학습 업데이트에 이용할 수 있다. 실시예들에 따른 음성 어시스턴트는 시뮬레이션의 동작 수행 실패가 인식 실패 또는 의도 분석 오류에 기인된 것으로 판단됨에 따라 음성 인식 시스템을 학습 및 업데이트 수행할 수 있다. 실시예들에 따른 음성 어시스턴트는 시뮬레이션의 동작 수행 실패가 기능 또는 서비스의 부재로 인해 기인된 것으로 판단됨에 따라 기능 또는 서비스 개선을 위한 시스템을 학습 및 업데이트 하거나 또는 기능/서비스 개선 요청을 외부 서버로 전송할 수 있다. 이와 같이 실시예들에 따른 음성 어시스턴트에 의하면, 타 음성 어시스턴트의 동작을 분석하여 타 음성 어시스 턴트가 실행하지 못하는 기능/서비스의 실패 원인을 분석함으로써 실패 경험으로 인한 사용자의 니즈를 모니터 링하여 실패했던 기능/서비스를 제공하거나 제안을 해 줄 수 있다. 또한 이와 같은 실시예들에 따른 음성 어시 스턴트의 동작은, 다른 음성 어시스턴트와 제품 연동의 필요 없이, 사용자가 타 음성 어시스턴트에게 발화한 내 용이나 타 음성 어시스턴트가 사용자에게 반응한 내용을 음성 인식 또는 문자 인식에 의해 인식함으로써 복잡한 시스템 구현 없이 실시예들에 따른 음성 어시스턴트의 지능 향상을 이룰 수 있고 또한 타 음성 어시스턴트에서 실패했던 기능 이나 서비스 등을 사용자에게 제공할 수 있다. 도 2a는 일 실시 예에 따라 음성 어시스턴트가 구현된 컴퓨팅 장치의 일 예 100a를 나타낸다. 도 2a에 도시된 컴퓨팅 장치 100a는 도 1에 도시된 컴퓨팅 장치 100의 일 예를 나타낸다. 도 2a에 도시된 예에서는 음성 어시 스턴트의 기능을 수행하는 모듈 대부분이 컴퓨팅 장치 100a의 내부에 배열되어 있다. 도 2a를 참조하면, 컴퓨팅 장치 100a은 입력 모듈 110, 디스플레이 120(또는, 터치 스크린 디스플레이), 스피커 130, 메모리140, 통신 회로 150 및 프로세서160를 포함할 수 있다. 컴퓨팅 장치 100의 적어도 일부 구성(예: 입력 모듈 110, 디스플레이 120, 스피커 130, 메모리140, 통신 회로 150 등은 프로세서160에 전기적으로 연결될 수 있다. 다양한 실시 예에서, 컴퓨팅 장치 100는 전자 장치, 사용자 단말로 명명될 수 있으며, 도 2에 도시된 구성요소 외에 구성요소를 더 포함할 수 있거나, 일부 구성요소는 생략될 수 있다. 일 실시예에 따라 입력 모듈 110은 사용자로부터 사용자 입력을 수신할 수 있다. 일 실시 예에 따라, 입력 모듈 110은 사용자의 발화를 음성 신호로 수신할 수 있는 마이크 111를 포함할 수 있 다. 예를 들어, 입력 모듈 110은 발화 입력 시스템(speech input system)을 포함하고, 상기 발화 입력 시스템을 통해 사용자의 발화를 음성 신호로 수신할 수 있다. 일 실시 예에서, 마이크 111는 사용자 발화에 따른 입력을 수신하기 위하여 항시 구동되는 상태(예: always on)로 제어되거나 또는 컴퓨팅 장치100의 일부에 제공되는 하 드웨어 키에 사용자 조작이 인가되는 경우 구동될 수 있다. 마이크 111는 수신된 아날로그 음성 신호를 디지털 화하여 프로세서 160으로 전달할 수 있다. 이와 같이 디지털화된 음성 신호는 음성 인식 에이전트 211에 의해 트리거 워드를 인식하고, 사용자의 발화 내용을 인식하고, 타 음성 어시스턴트의 반응 내용을 인식하는데 이용 될 수 있다. 다른 실시예에 따라, 컴퓨팅 장치 100a는 내부 설치된 마이크 111로부터가 아니라 외부 장치로부터 음성 신호를 수신할 수 있다. 예를 들어, 컴퓨팅 장치 100a는 원격 제어 장치 (리모트 콘트롤러) 또는 스마트 폰으로부터 디지털화된 음성 신호를 수신할 수 있다. 예를 들어, 원격 제어 장치나 스마트 폰은 마이크를 포함하고 사용자 의 아날로그 음성 신호를 마이크를 통해서 수신하고, 이러한 아날로그 음성 신호를 디지털화하여 디지털화한 음 성 신호를 통신 회로를 통해 컴퓨팅 장치 100a로 전달할 수 있다. 컴퓨팅 장치 100a는 통신 회로 150를 통해 디지털화한 음성 신호를 수신하여 이를 프로세서 160으로 전달할 수 있다. 일 실시예에 따라, 입력 모듈 110은 마이크 111 이외에도, 연결된 외부 장치(예: 키보드, 헤드셋)로부터 사용자 입력을 수신할 수 있다. 다른 예를 들어, 입력 모듈 110은 디스플레이 120와 결합된 터치 스크린(예: 터치 스 크린 디스플레이)을 포함할 수 있다. 또 다른 예를 들어, 입력 모듈 110은 컴퓨팅 장치 100에 위치한 하드웨어 키(또는, 물리적 키, 또는 정전용량 방식의 버튼)를 포함할 수 있다. 일 실시예에 따라 디스플레이 120는 이미지나 비디오, 및/또는 어플리케이션의 실행 화면을 표시할 수 있다. 예 를 들어, 디스플레이 120는 어플리케이션의 그래픽 사용자 인터페이스(graphic user interface)(GUI)를 표시할 수 있다. 일 실시 예에 따라 스피커 130는 음성 신호를 출력할 수 있다. 예를 들어, 스피커 130는 컴퓨팅 장치 100 내부 에서 생성된 음성 신호를 외부로 출력할 수 있다.메모리 110는 플래시 메모리 타입(flash memory type), 하드디스크 타입(hard disk type), 멀티미디어 카드 마 이크로 타입(multimedia card micro type), 카드 타입의 메모리(예를 들어 SD 또는 XD 메모리 등), 램(RAM, Random Access Memory) SRAM(Static Random Access Memory), 롬(ROM, Read-Only Memory), EEPROM(Electrically Erasable Programmable Read-Only Memory), PROM(Programmable Read-Only Memory), 자기 메모리, 자기 디스크, 광디스크 중 적어도 하나의 타입의 저장매체를 포함할 수 있다. 일 실시 예에 따라 메모리 140는 복수의 어플리케이션 141을 저장할 수 있다. 메모리 140에 저장된 복수의 어플 리케이션은 사용자 입력에 따라 선택되어 실행되고 동작할 수 있다. 일 실시 예에 따르면, 메모리 140는 사용자 입력을 인식하는데 필요한 정보를 저장할 수 있는 데이터베이스를 포함할 수 있다. 예를 들어, 메모리 140은 로 그(log) 정보를 저장할 수 있는 로그 데이터베이스를 포함할 수 있다. 다른 예를 들어, 메모리140는 사용자 정 보를 저장할 수 있는 개인 정보 데이터베이스를 포함할 수 있다. 일 실시 예에 따라 메모리 140는 복수의 어플리케이션을 저장하고, 복수의 어플리케이션은 프로세서 160에 로드 되어 동작할 수 있다. 예를 들어, 메모리 140에 저장된 복수의 어플리케이션은 프로세서 160의 실행 관리 모듈 214에 의해 로드되어 동작할 수 있다. 복수의 어플리케이션은 기능을 수행하는 실행 서비스(또는 복수의 동작 (또는, 단위 동작을 포함할 수 있다. 실행 서비스는 실행 관리 모듈 214에 의해 생성되고, 복수의 동작을 실행 할 수 있다. 일 실시 예에 따라, 어플리케이션의 동작이 실행되었을 때, 동작의 실행에 따른 실행 상태 화면은 디스플레이 120에 표시될 수 있다. 일 실시 예에 따른 통신 회로 150는 적어도 하나의 외부 장치(예: 어시스턴트 서버 200)와 규정된 프로토콜 (protocol)에 따른 유선 통신 또는 무선 통신을 수립할 수 있다. 통신 회로 150는 상기 유선 통신 또는 무선 통 신을 기반으로 음성 인식 서비스의 운용에 관계되는 적어도 하나의 정보를 송수신할 수 있다. 통신 회로 150는 컴퓨팅 장치와 무선 통신 시스템 사이 또는 컴퓨팅 장치과 다른 전자 장치가 위치한 네트워크 사이의 무선 통신을 가능하게 하는 하나 이상의 모듈을 포함할 수 있다. 예를 들어, 통신 회로 150는 방송 수신 모듈, 이동통신 모듈, 무선 인터넷 모듈 및 근거리 통신 모듈을 포함할 수 있다. 통신 회로 150는 송/수신부로 호칭될 수 있다. 방송 수신 모듈은 방송 채널을 통하여 외부의 방송 관리 서버로부터 방송 신호 및/또는 방송 관련된 정보를 수 신한다. 이동통신 모듈은, 이동 통신망 상에서 기지국, 외부의 단말, 서버 중 적어도 하나와 무선 신호를 송수 신한다. 무선 인터넷 모듈은 무선 인터넷 접속을 위한 모듈을 말하는 것으로, 디바이스에 내장되거나 외장될 수 있다. 무선 인터넷 기술로는 WLAN(Wireless LAN)(WiFi), Wibro(Wireless broadband), Wimax(World Interoperability for Microwave Access), HSDPA(High Speed Downlink Packet Access) 등이 이용될 수 있다. 근거리 통신 모듈은 근거리 통신을 위한 모듈을 말한다. 근거리 통신 기술로 블루투스(Bluetooth), RFID(Radio Frequency Identification), 적외선 통신(IrDA, infrared Data Association), UWB(Ultra Wideband), ZigBee 등이 이용될 수 있다. 일 실시예에 따라, 프로세서 160는 컴퓨팅 장치 100a의 전반적인 동작을 제어할 수 있다. 예를 들어, 프로세서 160는 입력 모듈 110을 제어하여 사용자 입력을 수신할 수 있다. 프로세서 160는 디스플레이 120를 제어하여 이 미지를 표시할 수 있다. 프로세서 160는 스피커130를 제어하여 음성 신호를 출력할 수 있다. 프로세서 160는 메 모리 140를 제어하여 필요한 정보를 불러오거나 저장할 수 있다. 일 실시 예에서, 프로세서160는 메모리140에 저장된 명령어들을 실행하여 음성 어시스턴트 200을 구동시킬 수 있다. 본 발명의 다양한 실시 예에서 언급되는 여러 모듈들은 하드웨어로 구현될 수도 있고, 소프트웨어로 구현 될 수도 있다. 본 발명의 다양한 실시 예에서 음성 어시스턴트 200에 의해 수행되는 동작은 프로세서160에 의해 수행되는 동작으로 이해될 수 있다. 일 실시예에 따라 음성 어시스턴트 200는 음성 어시스턴트 에이전트 210와 음성 인식 엔진 220을 포함할 수 있 다. 음성 어시스턴트 에이전트 210는 사용자의 트리거워드를 인식하고 사용자의 발화 내용을 기초로 분석된 결 과를 이용하여 후속 동작을 결정하는 역할을 수행할 수 있다. 음성 인식 엔진 220는 주로 사용자의 발화 내용 이나 타 음성 어시스턴트의 발화 내용을 인식하고 인식된 결과를 음성 어시스턴트 에이전트 210으로 제공하는 역할을 할 수 있다. 음성 어시스턴트 에이전트 210는 음성 인식 에이전트 211, 자동 문자 인식 모듈 215, 실행 관리 모듈 216을 포 함할 수 있다. 일 실시예에 따라 음성 인식 에이전트 211는 사용자 입력, 즉, 사용자 발화 음성을 음성 인식 엔진 220으로 전 달하기 전에, 상기 사용자 발화 음성을 전처리할 수 있다. 일 실시 예에 따르면, 음성 인식 에이전트 211 상기 사용자 입력을 전처리하기 위하여, 적응 반향 제거(adaptive echo canceller)(AEC) 모듈, 노이즈 억제(noise suppression)(NS) 모듈, 종점 검출(end-point detection)(EPD) 모듈 또는 자동 이득 제어(automatic gain control)(AGC) 모듈을 포함할 수 있다. 상기 적응 반향 제거부는 상기 사용자 발화 음성에 포함된 에코(echo)를 제거할 수 있다. 상기 노이즈 억제 모듈은 상기 사용자 입력에 포함된 배경 잡음을 억제할 수 있다. 상기 종점 검출 모듈은 상기 사용자 입력에 포함된 사용자 음성의 종점을 검출하여 사용자의 음성이 존재하는 부분을 찾을 수 있다. 상기 자동 이득 제어 모듈은 상기 사용자 입력을 인식하여 처리하기 적합하도록 상기 사용자 입력의 음량을 조절할 수 있다. 일 실시 예에 따르면, 음성 인식 에이전트 211성능을 위하여 상기 전처리 구성을 전부 포함할 수 있지만, 다른 실시 예에서 음성 인식 에이전트 211는 저전력으로 동작하기 위해 상기 전처리 구성 중 일부를 포함할 수 있다. 일 실시예에 따라 음성 인식 에이전트 211는 트리거 워드 인식 모듈 212, 시뮬레이션 제어 모듈 213 및 후속 동 작 관리 모듈 215를 포함할 수 있다. 일 실시예에 따라 음성 인식 에이전트 211는 사용자가 음성 어시스턴트를 호출하는 트리거 워드를 인식하는 트 리거 워드 인식 모듈 212을 포함할 수 있다. 트리거 워드 인식 모듈 212은 음성 인식 모듈을 통해 사용자의 트 리거 워드를 인식할 수 있고, 상기 트리거 워드를 수신한 경우 사용자 입력을 수신하기 위해 음성 인식 에이전 트 211을 활성화시킬 수 있다. 일 실시 예에 따르면, 음성 인식 에이전트 211의 트리거 워드 인식 모듈 212은 저전력 프로세서(예: 오디오 코덱에 포함된 프로세서)에 구현될 수 있다. 일 실시 예에 따르면, 음성 인식 에이 전트 211는 하드웨어 키를 통한 사용자 입력에 따라 활성화될 수 있다. 일 실시예에 따라, 음성 인식 에이전트 211는 트리거 워드 인식 모듈 212을 이용하여 해당 어시스턴트의 트리거 워드 뿐만 아니라 하나 이상의 타 음성 어시스턴트들의 트리거 워드를 인식할 수 있다. 일 실시예에 따라, 트리거 워드 인식 모듈 212는 본 음성 어시스턴트의 트리거 워드 뿐만 아니라 하나 이상의 타 음성 어시스턴트의 트리거 워드를 저장해놓고, 이를 기반으로 수신된 사용자 음성이 해당 음성 어시스턴트의 트리거 워드인지 또는 타 음성 어시스턴들의 트리거 워드인지 인식할 수 있다. 예를 들어, 트리거 워드 인식 모 듈 212는 본 음성 어시스턴트의 트리거 워드에 해당하는\"하이 빅스비\"및 하나 이상의 타 음성 어시스턴트의 트 리거 워드인, \"하이 구글라\", \"하이 시리우스\", \"하이 알렉스\"을 저장해 놓을 수 있다. 일 실시예에 따라, 트리거 워드 인식 모듈 212에서 인식하는 본 음성 어시스턴트의 트리거 워드 및 하나 이상의 타 음성 어시스턴트의 트리거 워드는 음향 모델, 발음 기호 등을 이용하여 미리 학습시켜 놓을 수 있다. 예를 들어, 트리거 워드 인식 모듈 212는 음성 어시스턴트 200의 트리거 워드인 예를 들어 \"하이 빅스비\" 라는 트리 거 워드를 인식할 수 있을 뿐만 아니라 예를 들어 도 1에 도시된 바와 같은 타 음성 어시스턴트들, \"하이 구글 라\", \"하이 시리우스\", \"하이 알렉스\" 등의 트리거 워드도 인식할 수 있다. 이는 본 음성 어시스턴트 200의 트 리거 워드의 인식과 동일하게 타 음성 어시스턴트의 트리거 워드의 음향 모델, 발음 기호 등을 학습시켜 놓음으 로써, 타 음성 어시스턴트의 트리거 워드를 인식할 수 있다. 일 실시예에 따라 트리거 워드 인식 모듈 212은 인식 스코어의 임계치를 이용하여, 어떤 트리거 워드의 인식 스 코어가 임계치를 넘는 경우에 해당 트리거 워드를 인식한 것으로 판단하고, 임계치를 넘지 않는 경우에 해당 트 리거 워드를 인식하지 못한 것으로 판단할 수 있다. 예를 들어, 어떤 트리거 워드를 수신한 경우에 음성 인식 에이전트 211의 웨이크 업 인식 모듈은 트리거 워드를 인식하기 위한 동작을 수행하고, 동작 수행 결과 해당 웨 이크업 인식 모듈이 알고 있는 하나 이상의 트리거워드 들에 대한 스코어를 출력할 수 있다. 예를 들어, \"하이 빅스비\" 라는 트리거 워드가 입력된 경우에 웨이크업 인식 모듈은 빅스비에 대해서는 임계치를 넘는 인식 스코 어를 획득할 것이고, 그외 다른 음성 어시스턴트 트리거 워드에 대응해서는 임계치를 넘지 않는 인식 스코어를 획득함으로써, 웨이크업 인식 모듈은 입력된 트리거 워드가 빅스비에 대응되는 것임을 인식할 수 있게 된다. 웨이크업 인식 모듈은 입력된 트리거 워드의 최적의 인식 및 오인식 방지를 감안하여 인식 스코어 임계치를 적 절한 값으로 설정할 수 있다. 또한 이러한 인식 스코어 임계치는 시스템의 성능이나 동작 상태에 따라 적절하 게 더 학습되거나 업데이트될 수 있다. 일 실시예에 따라 트리거 워드 인식 모듈 212이 본 음성 어시스턴트 200의 트리거 워드 나 타 음성 어시스턴트 의 트리거 워드를 인식한 경우에 다음 사용자의 발화 내용을 수신하기 위한 리스닝 상태로 진입할 수 있다. 이 후에 본 음성 어시스턴트 200의 트리거 워드를 인식한 경우에 이후 수신되는 사용자의 발화 내용에 따라 동작을 수행하고 사용자에게 반응을 하지만, 타 음성 어시스턴트 200의 트리거워드를 인식한 경우에 이후 수신되는 사 용자의 발화 내용에 대해서는 직접적으로 반응을 하지 않도록 구성될 수 있다. 일 실시예에 따라 트리거 워드 인식 모듈 212은 타 음성 어시스턴트의 트리거 워드를 인식하고 나서, 사용자와 타 음성 어시스턴트 간의 대화 내용에 대응하는 발화 내용을 수신하고, 수신된 발화 내용을 음성 분석을 위해 음성 인식 엔진 220으로 전달할 수 있다. 예를 들어, 트리거 워드 인식 모듈 212이 타 음성 어시스턴트의 트리 거 워드 인식 후에 수신하는 발화 내용은, 사용자가 타 음성 어시스턴트에 서비스를 요청하기 위한 발화 내용, 예를 들어, \"음악 틀어줘\"와 같은 발화 내용이나, 사용자의 의도를 정확하게 확인하기 위해 타 음성 어시스턴트 가 사용자에게 반응하는 발화 내용, 예를 들어, \"어떤 음악을 원하세요?\" 와 같은 발화 내용이나, 사용자의 서 비스 요청에 대해서 타 음성 어시스턴트가 서비스 제공으로 반응한 발화 내용, 예를 들어, \"네, 최신 인기 팝송 을 들려드리겠습니다\" 와 같은 발화 내용을 모두 포함할 수 있다. 일 실시 예에 따라, 트리거 워드 인식 모듈 212은 음성을 인식하기 위한 알고리즘을 이용하여 사용자 입력을 인 식할 수 있다. 상기 음성을 인식하기 위해 사용되는 알고리즘은, 예를 들어, HMM(hidden markov model) 알고리 즘, ANN(artificial neural network) 알고리즘 또는 DTW(dynamic time warping) 알고리즘 중 적어도 하나일 수 있다. 시뮬레이션 제어 모듈 213은 음성 인식 엔진 220으로부터 사용자의 서비스 요청에 대응하는 발화 내용을 수행하 기 위한 동작을 시뮬레이션하라는 지시에 따라 음성 인식 엔진 220으로부터 수신한 작업 룰에 따라 동작을 수행 하도록 실행 관리 모듈 216에 지시할 수 있다. 또한 실행 관리 모듈 216으로부터 사용자 발화 내용에 대응하는 동작 수행 결과를 음성 인식 엔진 220으로 제공할 수 있다. 예를 들어, 사용자의 서비스 요청에 대응하는 발화 내용이 \"오늘 날씨 알려줘\" 라면, 이러한 서비스 요청에 따라 결정되는 작업 룰, 예를 들어, 날씨 어플리케이션 을 실행하고, 실행된 날씨 어플리케이션에서 오늘의 날씨를 검색하고, 검색된 오늘의 날씨를 출력 하는 작업 룰 을 음성 인식 엔진 220으로부터 수신하여 이를 실행관리 모듈 216에 전달할 수 있다. 후속 동작 관리 모듈 214는 음성 인식 엔진 220의 원인 분석 모듈 224로부터 본 음성 어시스턴트의 시뮬레이션 동작 실행의 실패 여부 및 실패 원인 결과 등을 수신하고, 이에 따라 후속 동작을 결정하고 실행할 수 있다. 후속 동작 관리 모듈 214는 시뮬레이션 동작 실행이 실패인 경우, 실패의 원인에 따라서, 인식 기능을 업데이 트하거나 학습하거나, 기능/서비스 도메인을 확장하거나, 외부 서비스 연동 등의 제어를 수행할 수 있다. 일 실시예에 따라 시뮬레이션 동작 실행의 실패의 원인이 사용자의 발화 내용 인식 오류나 인식 불능 등의 경우, 또는 의도 분석이 잘못되었을 경우, 후속 동작 관리 모듈 214는 음성 인식 엔진 220으로 자동 음성 인식 모듈 221이나 자연어 이해 모듈 223을 학습 및 업데이트하도록 하는 명령을 보냄으로써, 음성 인식, 자연어 처 리, 의도 분석, 도메인 분류 등 각 기능에 대해서 언어/음향 모델, 임계치, 후보 선정 기준 등의 요소별로 학습 및 업데이트가 진행되게 할 수 있다. 일 실시예에 따라 시뮬레이션 동작 실행의 실패의 원인이 기능/서비스의 부재로 인한 경우, 후속 동작 관리 모 듈 214는, 기능 개선 항목 또는 서비스 개선 항목으로 기록을 해두거나 해당 기능을 제공하는 서버로 기능 개선 항목을 전송함으로써, 컴퓨팅 장치 100의 소프트웨어가 업데이트될 수 있도록 할 수 있다. 일 실시예에 따라 시뮬레이션 동작 실행의 실패의 원인이 기능/서비스의 부재로 인한 경우, 후속 동작 관리 모 듈 214는 기능을 제공하는 서버나 서비스 검색 서버를 통해서 기능이나 서비스가 존재하는지 검색을 해보고, 만 약 기능이나 서비스가 이용가능한 경우, 다운로드를 진행하여 기능이나 서비스에 대한 소프트웨어를 설치할 수 있다. 일 실시예에 따라 시뮬레이션 동작 실행의 실패의 원인이 기능/서비스의 부재로 인한 경우, 후속 동작 관리 모 듈 214이 기능을 제공하는 서버나 서비스 검색 서버를 통해서 검색해 본 결과 현재로서는 이용불가능이지만, 이 용가능한 시점을 확인할 수 있는 경우, 후속 동작 관리 모듈 214는 사용자에게 이와 같은 기능이나 서비스가 언 제 업데이트 예정인지 또는 언제 사용가능한지를 통지될 수 있도록 음성 인식 엔진 220의 자연어 이해 모듈 223 으로 대화 시스템을 업데이트하도록 지시할 수 있다. 예를 들어, 후속 동작 관리 모듈 214의 검색 결과 현재 이용가능하지 않은 서비스가 다음달에 이용가능 예정인 경우, \"해당 서비스는 다음달에 이용가능합니다. 양해 부탁드립니다\"라는 반응이 출력될 수 있도록 대화 시스템을 업데이트하도록 자연어 이해 모듈 223에 요청할 수 있다. 후속 동작 관리 모듈 214는 시뮬레이션 동작 실행이 성공인 경우, 타 음성 어시스턴트가 제공에 실패한 서비스 를 제공가능함을 나타내는 통지를 사용자에게 출력할 수 있다. 후속 동작 관리 모듈 214는 시뮬레이션 동작 실행이 성공인 경우, 타 음성 어시스턴트가 제공에 실패한 서비스 를 제공가능함을 나타내는 통지를 사용자에게 출력할 때, 서비스의 내용에 따라서 실시간으로 제공할 필요가 있 는 서비스인지를 판단하고, 판단에 따라서, 실시간으로 통지를 출력하거나 또는 사용자로부터 서비스 요청을 수 신한 경우에 통지를 출력할 수 있다. 일 실시예에 따라 후속 동작 관리 모듈 214는 타 음성 어시스턴트가 제공에 실패한 서비스의 내용이 실시간으로 통지를 제공해야 의미가 있는 경우, 예를 들어, 현재 시간과 관련되어 있는 서비스 요청인 경우에는, 해당 서비 스 제공가능함을 나타내는 통지를 실시간으로 출력할 수 있다. 예를 들어, 사용자의 서비스 요청이, \"현재 시 간 알려줘\", \"지금 생중계중인 월드컵 경기 채널 보여줘\", \"현재 위치에 가까운 이탈리안 레스토랑을 알려줘\" 등과 같이 현재 장소나 현재 시간과 밀접한 연관이 있어서 추후에는 통지하는 것이 의미가 없는 것으로 판단되 는 경우에는 사용자에게 실시간으로 해당 서비스 제공가능함을 나타내는 통지를 출력할 수 있다. 예를 들어, 타 음성 어시스턴트에 대한 사용자의 서비스 요청이 \"지금 생중계중인 월드컵 경기 채널 보여줘\" 인 경우, 타 음성 어시스턴트가 서비스 응답에 실패한 경우, 본 음성 어시스턴트는 먼저 \"빅스비입니다. 지금 생중계중인 월 드컵 경기 채널을 틀어드릴까요?\"라고 먼저 사용자의 의도를 확인한 후 사용자가 긍정으로 대답한 경우 해당 서 비스를 제공할 수 있다. 일 실시예에 따라 후속 동작 관리 모듈 214는 타 음성 어시스턴트가 제공에 실패한 서비스의 내용이 반드시 실 시간으로 제공될 필요성이 떨어지는 경우, 즉, 현재 시간이나 현재 장소와의 관련성이 약한 경우, 해당 서비스 제공가능함을 나타내는 통지를 추후에 본 음성 어시스턴트로의 서비스 요청이 있을 때 출력할 수 있다. 사용자 입장에서는 예를 들어 타 음성 어시스턴트인 시리우스에게 서비스 요청하였는데, 시리우스의 서비스 제공 실패 후 바로 말을 걸지도 않은 다른 음성 어시스턴트로부터의 대화 요청이 불쑥 시작되면, 사용자들에 따라서는 놀 라거나 불편함을 느끼게 될 수도 있다. 따라서 시간적 긴급성이 중요한 서비스가 아닌 경우에는 추후에 통지를 제공하는 것이 바람직할 수도 있다. 예를 들어, 사용자의 서비스 요청이, \"강남에 있는 이탈리안 레스토랑 맛집 추천해줘\", \"이번 달 한국에서의 축 제 정보 알려줘\" 등과 같은 서비스 요청은 현재 장소나 현재 시간과는 연관성이 떨어지므로 추후에 서비스를 제 공한다고 해도 유효할 수 있다. 따라서, 이와 같은 경우, 후속 동작 관리 모듈 214는 타 음성 어시스턴트로의 서비스 요청이 있는 실시간으로 통지를 제공하는 것이 아니라, 해당 서비스 제공가능함을 나타내는 통지를 기억 해두었다가, 추후에 사용자로부터 본 음성 어시스턴트에 대한 다른 서비스 요청이 있는 경우 해당 다른 서비스 요청을 먼저 처리하고 나서, 이어서 기억해두었던 타 음성 어시스턴트에서 서비스 실패했던 서비스가 제공가능 함을 나타내는 통지를 출력할 수 있다. 예를 들어, 추후에, 사용자로부터 \"오늘 날씨 어때?\"라는 서비스 요청이 있는 경우, 해당 서비스 요청에 대해서 처리를 하여 \"오늘 날씨는 맑고 따뜻합니다\"와 같은 응답을 제공하고 나 서, 이어서, \"이번 달 한국에서의 축제 정보를 알려드릴까요\" 라고 먼저 사용자의 의도를 확인한 후 사용자가 긍정으로 대답한 경우 해당 서비스를 제공할 수 있다. 일 실시예에 따라 자동 문자 인식 모듈 215는 디스플레이 120에 표시된 화면을 캡쳐하고 캡쳐된 화면에서 ACR 기술 등을 이용하여 문자 나 텍스트를 인식하고 분석함으로써 문자나 텍스트의 의미를 분석할 수 있다. 예를 들어 타 음성 어시스턴트가 컴퓨팅 장치 100에 설치되어 있고, 사용자의 타 음성 어시스턴트에 대한 서비스 요 청에 대한 응답으로 타 음성 어시스턴트가 텍스트 반응을 한 경우, 자동 문자 인식 모듈 215는 화면에 표시된 타 음성 어시스턴트의 텍스트 반응에 따른 화면을 캡쳐하여 화면에 포함된 텍스트를 분석할 수 있다. 예를 들 어, 타 음성 어시스턴트가 텍스트 반응으로서 \"죄송합니다. 요청하신 서비스를 처리할 수 없습니다\"라는 화면을 출력한 경우, 자동 문자 인식 모듈 215는 이와 같은 화면을 캡쳐하여 \"죄송합니다. 요청하신 서비스를 처리할 수 없습니다\"라는 텍스트를 인식하고, 인식된 텍스트를 음성 인식 엔진 220으로 제공하여 텍스트의 의미를 분석 하도록 할 수 있다. 일 실시예에 따라, 실행 관리 모듈 216은 음성 인식 에이전트 211로부터 작업 룰을 수신하여 어플리케이션을 실 행시키고, 어플리케이션이 상기 작업 룰에 포함된 동작을 실행하도록 할 수 있다. 예를 들어, 실행 관리 모듈 216은 어플리케이션으로 동작을 실행하기 위한 명령 정보를 송신할 수 있고, 상기 어플리케이션으로부터 동작의 완료 정보를 수신할 수 있다. 일 실시예에 따라, 실행 관리 모듈 216는 어플리케이션의 동작의 실행 상태를 관리할 수 있다. 예를 들어, 실행 관리 모듈 216은 어플리케이션으로부터 상기 동작의 실행 상태에 대한 정보를 수신하고, 동작의 실행 상태에 대한 정보를 시뮬레이션 제어 모듈 213으로 송신할 수 있다. 음성 인식 엔진 220는 음성 인식 모듈 221, 발화 내용 분석 모듈 222, 음성 텍스트 변환 모듈 226을 포함할 수 있다. 도 2a를 참조하면, 음성 인식 엔진 220는 자동 음성 인식(automatic speech recognition)(ASR) 모듈 221, 자연 어 이해(natural language understanding)(NLU) 모듈223, 원인 분석 모듈 224, 자연어 생성(natural language generator)(NLG) 모듈 225 또는 텍스트 음성 변환(text to speech)(TTS) 모듈 226을 포함할 수 있다. 다양한 실시 예에서, 상술된 음성 인식 엔진 220의 구성요소221, 223, 224, 225 또는 226는 개별적으로 구현되거나 또 는, 적어도 일부 구성요소는 통합되어 구현될 수 있다. 일 실시 예에 따르면, 음성 인식 엔진 220는 상기 구성 요소(221, 223, 224, 225 또는 226의 기능 동작을 전반적으로 제어하는 컨트롤러(또는, 프로세서), 상기 컨트롤 러에 연결된 저장 장치(또는, 메모리) 또는 통신망 접속을 지원하는 통신 인터페이스(또는, 통신 모듈)를 포함 할 수 있다. 일 실시 예에 따라, 자동 음성 인식 모듈 221은 사용자 단말로부터 수신된 사용자 입력을 텍스트 데이터로 변환 할 수 있다. 예를 들어, 자동 음성 인식 모듈 221은 발화 인식 모듈을 포함할 수 있다. 상기 발화 인식 모듈은 음향(acoustic) 모델 및 언어(language) 모델을 포함할 수 있다. 예를 들어, 상기 음향 모델은 발성에 관련된 정보를 포함할 수 있고, 상기 언어 모델은 단위 음소 정보 및 단위 음소 정보의 조합에 대한 정보를 포함할 수 있다. 상기 발화 인식 모듈은 발성에 관련된 정보 및 단위 음소 정보에 대한 정보를 이용하여 사용자 발화를 텍 스트 데이터로 변환할 수 있다. 상기 음향 모델 및 언어 모델에 대한 정보는, 예를 들어, 자동 음성 인식 데이 터베이스(automatic speech recognition database)(ASR DB) 에 저장될 수 있다. 일 실시예에 따라 자동 음성 인식 모듈 221은 음성 인식 에이전트 211로부터 수신한 발화 내용, 즉, 사용자가 타 음성 어시스턴트에 서비스를 요청하기 위한 발화 내용, 사용자의 의도를 정확하게 확인하기 위해 타 음성 어 시스턴트가 사용자에게 반응하는 발화 내용, 사용자의 서비스 요청에 대해서 타 음성 어시스턴트가 서비스 제공 으로 반응한 발화 내용에 대응하는 음성 신호를 수신하고, 이를 텍스트 데이터로 변환(Speech To Text)할 수 있 다. 일 실시예에 따라 자동 음성 인식 모듈 221은 정확한 인식을 위해 타 음성 어시스턴트의 고유 음성 반응 화자 음성 목소리에 대해서 미리 학습을 해둘 수 있다. 각 타 음성 어시스턴트는 고유의 화자 음성이 있기 때문에, 이와 같이 각각의 타 음성 어시스턴트의 고유 화자 음성에 대해 학습을 해둠으로써 타 음성 어시스턴트의 반응 발화 내용이 입력되었을 때 인식률을 높일 수 있다. 발화 내용 분석 모듈 222는 자연어 이해 모듈 223, 원인 분석 모듈 224, 자연어 생성 모듈 225를 포함할 수 있 다. 일 실시 예에 따라, 자연어 이해 모듈 223은 자동 음성 인식 모듈 221로부터 텍스트 데이터를 수신하고, 문법적 분석(syntactic analyze) 또는 의미적 분석(semantic analyze)을 수행하여 사용자 의도를 파악할 수 있다. 상 기 문법적 분석은 사용자 입력을 문법적 단위(예: 단어, 구, 형태소 등)로 나누고, 상기 나누어진 단위가 어떤 문법적인 요소를 갖는지 파악할 수 있다. 상기 의미적 분석은 의미(semantic) 매칭, 룰(rule) 매칭, 포뮬러 (formula) 매칭 등을 이용하여 수행할 수 있다. 이에 따라, 자연어 이해 모듈 223은 사용자 입력이 어느 도메인 (domain), 의도(intent) 또는 상기 의도를 표현하는데 필요한 파라미터(parameter)를 얻을 수 있다. 일 실시 예에 따라, 자연어 이해 모듈 223은 도메인(domain), 의도(intend) 및 상기 의도를 파악하는데 필요한 파라미터(parameter)로 나누어진 매칭 규칙을 이용하여 사용자의 의도 및 파라미터를 결정할 수 있다. 예를 들 어, 상기 하나의 도메인(예: 알람)은 복수의 의도(예: 알람 설정, 알람 해제 등)를 포함할 수 있고, 하나의 의 도는 복수의 파라미터(예: 시간, 반복 횟수, 알람음 등)을 포함할 수 있다. 복수의 룰은, 예를 들어, 하나 이상 의 필수 요소 파라미터를 포함할 수 있다. 상기 매칭 규칙은 자연어 인식 데이터베이스(natural language understanding database)(NLU DB) 에 저장될 수 있다. 일 실시 예에 따라, 자연어 이해 모듈 223은 형태소, 구 등의 언어적 특징(예: 문법적 요소)을 이용하여 사용자 입력으로부터 추출된 단어의 의미를 파악하고, 상기 파악된 단어의 의미를 도메인 및 의도에 매칭시켜 사용자의 의도를 결정할 수 있다. 예를 들어, 자연어 이해 모듈 223은 각각의 도메인 및 의도에 사용자 입력에서 추출된 단어가 얼마나 포함되어 있는지를 계산하여 사용자 의도를 결정할 수 있다. 일 실시 예에 따르면, 자연어 이해 모듈 223은 상기 의도를 파악하는데 기초가 된 단어를 이용하여 사용자 입력의 파라미터를 결정할 수 있다. 일 실시 예에 따르면, 자연어 이해 모듈 223은 사용자 입력의 의도를 파악하기 위한 언어적 특징이 저장된 자연어인식 데이터베이스를 이용하여 사용자의 의도를 결정할 수 있다. 다른 실시 예에 따르면, 자연어 이해 모듈 223 은 개인화 언어 모델(personal language model)(PLM)을 이용하여 사용자의 의도를 결정할 수 있다. 예를 들어, 자연어 이해 모듈 223은 개인화된 정보(예: 연락처 리스트, 음악 리스트)를 이용하여 사용자의 의도를 결정할 수 있다. 상기 개인화 언어 모델은, 예를 들어, 자연어 인식 데이터베이스 521에 저장될 수 있다. 일 실시 예에 따르면, 자연어 이해 모듈 223뿐만 아니라 자동 음성 인식 모듈221도 자연어 인식 데이터베이스에 저장된 개인 화 언어 모델을 참고하여 사용자의 음성을 인식할 수 있다. 일 실시 예에 따라, 자연어 이해 모듈 223은 사용자 입력의 의도 및 파라미터에 기초하여 작업 룰을 생성할 수 있다. 예를 들어, 자연어 이해 모듈 223은 사용자 입력의 의도에 기초하여 실행될 어플리케이션을 선택하고, 상 기 선택된 어플리케이션 에서 수행될 동작을 결정할 수 있다. 상기 자연어 이해 모듈 223은 상기 결정된 동작에 대응되는 파라미터를 결정하여 작업 룰을 생성할 수 있다. 일 실시 예에 따르면, 자연어 이해 모듈 223에 의해 생성된 작업 룰은 실행될 어플리케이션, 상기 어플리케이션 에서 실행될 동작 및 상기 동작을 실행하는데 필요 한 파라미터에 대한 정보를 포함할 수 있다. 일 실시 예에 따라, 자연어 이해 모듈 223은 사용자 입력의 의도 및 파라미터에 기초하여 실행될 어플리케이션, 상기 어플리케이션 에서 실행될 동작 및 상기 동작을 실행하는데 필요한 파라미터를 결정하여 하나의 작업 룰, 또는 복수의 작업 룰을 생성할 수 있다. 예를 들어, 자연어 이해 모듈 223은 사용자 단말의 정보를 이용하여 상 기 실행될 어플리케이션 및 상기 어플리케이션 에서 실행될 동작을 사용자 입력의 의도에 따라 온톨로지 (ontology) 또는 그래프 모델(graph model) 형태로 배열하여 작업 룰을 생성할 수 있다. 일 실시 예에 따라, 자연어 이해 모듈 223은 생성된 복수의 작업 룰 중 적어도 하나의 작업 룰을 선택할 수 있 다. 예를 들어, 자연어 이해 모듈 223은 상기 복수의 작업 룰 최적의 작업 룰을 선택할 수 있다. 다른 예를 들 어, 자연어 이해 모듈 223은 사용자 발화에 기초하여 일부 동작만이 특정된 경우 복수의 작업 룰을 선택할 수 있다. 자연어 이해 모듈 223은 사용자의 추가 입력에 의해 상기 복수의 작업 룰 중 하나의 작업 룰을 결정할 수 있다. 일 실시 예에 따라, 자연어 이해 모듈 223은 사용자 입력에 대한 요청으로 작업 룰을 음성 어시스턴트 에이전트 210로 송신할 수 있다. 예를 들어, 자연어 이해 모듈 223은 사용자 입력에 대응되는 하나의 작업 룰을 음성 어 시스턴트 에이전트 210로 송신할 수 있다. 다른 예를 들어, 자연어 이해 모듈 223은 사용자 입력에 대응되는 복 수의 작업 룰을 음성 어시스턴트 에이전트 210로 송신할 수 있다. 상기 복수의 작업 룰은, 예를 들어, 사용자 발화에 기초하여 일부 동작만이 특정된 경우 자연어 이해 모듈 223에 의해 생성될 수 있다. 일 실시예에 따라, 자연어 이해 모듈 223은 사용자의 의도가 명확한지 여부를 판단할 수 있다. 예를 들어, 자 연어 이해 모듈 223은 파라미터의 정보가 충분하지 여부에 기초하여 사용자의 의도가 명확한지 여부를 판단할 수 있다. 자연어 이해 모듈 223은 사용자의 의도가 명확하지 않은 경우 사용자에게 필요한 정보를 요청하는 피 드백을 수행할 수 있다. 예를 들어, 자연어 이해 모듈 223은 사용자의 의도를 파악하기 위한 파라미터에 대한 정보를 요청하는 피드백을 수행할 수 있다. 일 실시예에 따라, 자연어 이해 모듈 223은 콘텐츠 제공(content provider) 모듈을 포함할 수 있다. 상기 콘텐 츠 제공 모듈은 자연어 이해 모듈 223에서 파악된 의도 및 파라미터에 기초하여 동작을 수행할 수 있는 경우, 사용자 입력에 대응되는 태스크를 수행한 결과를 생성하고, 사용자 입력에 대한 응답으로 상기 콘텐츠 제공 모 듈에서 생성된 상기 결과를 컴퓨팅 장치로 송신할 수 있다. 일 실시 예에 따라, 자연어 이해 모듈 223은 사용자의 의도 및 파라미터를 결정하고, 상기 결정된 사용자의 의 도 및 파라미터에 대응되는 응답(예: 작업 룰)을 생성할 수 있다. 이에 따라, 생성된 응답은 음성 어시스턴트 에이전트 210로 송신될 수 있다. 일 실시 예에 따라, 자연어 이해 모듈 223은 자동 음성 인식 모듈 221로부터 발화 내용에 대응하는 텍스트 데이 터, 즉, 사용자가 타 음성 어시스턴트에 서비스를 요청하기 위한 발화 내용, 사용자의 의도를 정확하게 확인하 기 위해 타 음성 어시스턴트가 사용자에게 반응하는 발화 내용, 사용자의 서비스 요청에 대해서 타 음성 어시스 턴트가 서비스 제공으로 반응한 발화 내용에 대응하는 텍스트를 수신하고, 사용자의 의도 또는 타 음성 어시스 턴트의 반응 내용의 의도를 분석할 수 있다. 일 실시예에 따라 자연어 이해 모듈 223은 사용자가 타 음성 어시스턴트에 서비스를 요청하기 위한 발화 내용을 수신하고, 사용자의 의도가 기능 제어인지, 기기 제어인지, 컨텐츠 검색인지, 생활 서비스 요청인지, 음악 재생 등 인지 등 사용자의 의도를 분석할 수 있다. 또한, 사용자의 의도가 명확하지 않은 경우 타 음성 어시스턴트는 질문을 하거나 확인을 요청하는 질문형 반응을 할 수 있고 이에 대한 응답으로 사용자는 답변 발화를 할 수 있는데, 자연어 이해 모듈 223은 이와 같은 답변 발화 내용을 더 참조하여 사용자의 의도를 분석할 수 있다. 자연어 이해 모듈 223은 이러한 사용자 답변 발화 내용을 분석함으로써 사용자가 더 이상 기능 수행을 원하지 않는지, 타 어시스턴트의 기능 수행 결과에 불만족하는지 판단할 수 있다. 예를 들어, 사용자의 답변 발화 내 용에 \"okay\"나 \"Right\" 등이 포함된 경우에는 타 어시스턴트의 기능 수행이나 반응에 만족하는 것으로 판단될 수 있고, 사용자의 답변 발화 내용에 \"stop\"이나 \"I don't want\", \"No\", \"Cancel\", \"Exit\"등의 단어가 포함된 경우 타 어시스턴트의 기능 수행이나 반응에 불만족한 것으로 판단될 수 있다. 일 실시예에 따라 자연어 이해 모듈 223은 사용자의 의도를 정확하게 확인하기 위해 타 음성 어시스턴트가 사용 자에게 반응하는 발화 내용, 사용자의 서비스 요청에 대해서 타 음성 어시스턴트가 서비스 제공으로 반응한 발 화 내용에 대응하는 텍스트를 수신하고, 타 음성 어시스턴트의 음성 반응을 분석할 수 있다. 일 실시예에 따라, 자연어 이해 모듈 223은 사용자에 의해 요청된 기능에 대해서 타 음성 어시스턴트가 요청된 기능을 수행할 수 없다고 대답하고 있는지를 판단할 수 있다. 예를 들어, 타 음성 어시스턴트가 요청된 기능을 수행할 수 없다고 대답하는 것으로서, 예를 들어 \"sorry, I can't help you\" 나 \"Sorry, there is no function\" 과 같은 응답이 있을 수 있다. 자연어 이해 모듈 223은 타 음성 어시스턴트의 발화 내용 중 \"sorry\", \"I can't\", \"Unfortunately\" 등과 같은 불가능 또는 실패를 의미하는 단어가 포함되어 있는지 확인할 수 있다. 일 실시예에 따라 자연어 이해 모듈 223과 별도의 의도 분석 시스템이 있는 경우, 발화 내용의 의도는 이러한 의도 분석 시스템을 이용하여 분석될 수 있다. 일 실시 예에 따라, 원인 분석 모듈 225는 자연어 이해 모듈 223 로부터의 결과, 예를 들어, 사용자의 의도 또 는 타 음성 어시스턴트의 반응 내용의 의도를 수신하고, 사용자의 발화 내용에 대한 타 음성 어시스턴트의 반응 발화 내용이 성공인지 실패인지를 판단할 수 있다. 또한 원인 분석 모듈 225는 사용자의 발화 내용에 대한 타 음성 어시스턴트의 반응 발화 내용에 따라 타 음성 어시스턴트의 서비스 응답이 실패로 판단된 경우, 실패의 원 인이 무엇인지 판단할 수 있다. 일 실시예에 따라 원인 분석 모듈 224는 사용자의 서비스 요청이 무엇이었고, 사용자의 서비스 요청에 대해 타 음성 어시스턴트에 의해 어떤 결과가 제공되었는지, 타 음성 어시스턴트로부터 질문 또는 확인 요청이 있었을 때 사용자가 어떤 단계에서 해당 동작을 이탈했는지 등을 분석함으로써, 타 음성 어시스턴트의 서비스 제공이 성공인지 실패인지 판단할 수 있다. 예를 들어, 사용자의 서비스 요청의 의도와 타 음성 어시스턴트의 반응 결과의 의도가 부합한다면 해당 서비스 요청은 성공으로 판단될 수 있다. 예를 들어, 사용자의 서비스 요청에 대한 타 음성 어시스턴트의 반응 결과에 대해서 사용자의 긍정적인 대답, 예를 들어, \"Okay\", 나 \"Thank you\" 등이 포함되어 있다면 해당 서비스 요청은 성공으로 판단될 수 있다. 반대로, 사용자의 서비스 요청의 의도와 타 음성 어시스턴트의 반응 결과의 의도가 부합하지 않다면 해당 서비스 요청은 실패로 판단될 수 있다. 예를 들어, 사용자의 서비스 요청에 대한 타 음 성 어시스턴트의 반응 결과에 대해서 사용자의 부정적인 대답, 예를 들어, \"No\", 나 \"Exit\" 등이 포함되어 있다 면 해당 서비스 요청은 실패로 판단될 수 있다. 일 실시예에 따라 원인 분석 모듈 224는 타 음성 어시스턴트의 서비스 제공이 실패로 판단된 경우 실패의 원인 또는 사용자의 불만족 원인을 분석할 수 있다. 예를 들어, 원인 분석 모듈 224는 타 음성 어시스턴트가 사용자의 발화 내용을 제대로 이해하지 못했는지, 즉 인식 결과가 잘못되었는지 분석할 수 있다. 예를 들어, 사용자의 서비스 요청의 의도와 타 음성 어시스턴트의 반응 결과의 의도가 부합하지 않다면, 원인 분석 모듈 224는 해당 서비스 제공 실패 원인이 음성 인식 오류나 음성 인식 불능에 기인한 것으로 판단할 수 있다. 예를 들어, 원인 분석 모듈 224는 타 음성 어시스턴트가 사용자의 발화 내용은 제대로 인식하였지만 사용자에 의해 요구되는 기능이나 서비스의 부재로 인해 해당 서비스 제공이 실패한 것인지 분석할 수 있다. 예를 들어, 타 음성 어시스턴트의 반응 내용에 \"죄송합니다. 요청하신 기능은 현재 제공되지 않습니다\", 또는 \"죄송하지만, 요청하신 서비스는 다음 달부터 서비스 예정입니다\" 와 같은 발화 내용이 포함된 경우, 원인 분석 모듈 224는 사용자에 의해 요구되는 기능이나 서비스의 부재로 인해 해당 서비스 제공이 실패한 것으로 판단할 수 있다. 예를 들어, 원인 분석 모듈 224는 타 음성 어시스턴트가 사용자에 의해 요구되는 기능이나 서비스를 제공하고 있지만 추가 설정이나 계정 입력 등의 추가 작업이 요구됨으로 인해 해당 서비스 제공이 실패한 것으로 분석할수 있다. 예를 들어, 사용자의 서비스 요청이 특정한 비디오나 오디오 등의 컨텐츠 요청이 있었던 경우, 타 음 성 어시스턴트가 해당 컨텐츠 제공을 위해서 추가 설정이나 계정 입력을 요청하는 반응에 대해서, 사용자로부터 추가적인 대답없이 대화 이탈이나 부정적인 답변이 있었던 경우, 원인 분석 모듈 224는 추가 설정이나 계정 입 력 등의 추가 작업 요구로 인해 해당 서비스 제공이 실패한 것으로 판단할 수 있다. 예를 들어, 사용자로부터 \"BTS의 최신곡 틀어줘\"라는 서비스 요청이 있는 경우, 타 음성 어시스턴트는 사용자에 의해 요청된 BTS의 최신 곡을 스트리밍하기 위해 해당 BTS 의 최신곡을 스트리밍 다운 받을 수 있는 컨텐츠 제공 서버에 접속하고 로그 인을 해야 할 수 있다. 이 경우 타 음성 어시스턴트에 해당 컨텐츠 제공 서버에 로그인 할 수 있는 사용자 계 정 정보를 갖고 있지 않은 경우 또는 사용자가 해당 컨텐츠 제공 서버에 처음부터 사용자 계정 정보를 갖고 있 지 않은 경우, 타 음성 어시스턴트는 사용자에게 해당 컨텐츠 제공 서버의 계정 정보를 사용자에게 요청하거나 또는 계정을 만들기 위한 사용자 정보를 요청하는 반응을 할 수 있다. 이 과정에서 사용자는 추가적인 계정 정 보나 사용자 정보를 입력해야 하는 번거로움 때문에 사용자는 더 이상의 진행을 하지 않고 해당 서비스 요청이 나 대화를 이탈할 수 있다. 이와 같은 경우에 원인 분석 모듈 224는 타 음성 어시스턴트가 사용자에 의해 요구 되는 기능이나 서비스를 제공하고 있지만 추가 설정이나 계정 입력 등의 추가 작업이 요구됨으로 인해 해당 서 비스 제공이 실패한 것으로 분석할 수 있다. 일 실시 예에 따라, 원인 분석 모듈 225는 사용자의 발화 내용에 대한 타 음성 어시스턴트의 반응 발화 내용이 성공인지 실패인지를 판단하고, 서비스 제공이 실패인 경우, 실패에 대응하는 분석 결과를 음성 인식 에이전트 211로 제공할 수 있다. 음성 인식 에이전트 211의 시뮬레이션 제어 모듈 212은 원인 분석 모듈 224로부터 타 음성 어시스턴트의 실패에 대응하는 분석 결과를 수신하고, 실패한 서비스 요청에 대해서 본 시스템에서 해당 서비스 요청에 대응하는 발 화 내용에 대응하여 동작이 수행가능한지 시뮬레이션을 수행하도록 음성 인식 엔진 220으로 제어 신호를 보낼 수 있다. 시뮬레이션 수행 제어 신호를 수신한 음성 인식 엔진 220은 자동 음성 인식 모듈 221 및 발화 내용 분석 모듈 222를 이용하여 사용자의 서비스 요청에 대응하는 발화 내용을 인식하여 분석하고 발화 내용에 대응하여 수행되 는 동작을 구동해볼 수 있다. 구체적으로 자동 음성 인식 모듈 221은 사용자의 서비스 요청에 대응하는 발화 음성을 수신하여 인식함으로써 텍스트 데이터로 변환하여 발화 내용 분석 모듈 222로 전달하면 발화 내용 분석 모듈 222의 자연어 이해 모듈 223은 발화 내용에 대응하는 텍스트 데이트를 수신하여 사용자의 의도를 파악하고 파악된 사용자의 의도에 따라 동작되어야 하는 작업 룰을 생성하여 이 작업 룰을 시뮬레이션 제어 모듈 213으로 전달하면, 시뮬레이션 제어 모듈 213은 수신된 작업 룰을 실행 관리 모듈 216으로 제공한다. 실행 관리 모듈 216은 수신된 작업 룰에 따라 하나 이상의 어플리케이션을 실행하여 실행한 결과를 다시 시뮬레이션 제어 모듈 213으로 제공할 수 있고, 시뮬레이션 제어 모듈 213은 어플리케이션 실행 결과를 음성 인식 엔진 220의 원인 분 석 모듈 224로 제공할 수 있다. 시뮬레이션에 따라 어플리케이션 실행 결과를 수신한 원인 분석 모듈 224는 시뮬레이션 수행에 따라 서비스 요 청에 대응한 동작의 성공 또는 실패를 분석할 수 있다. 일 실시예에 따라 원인 분석 모듈 224는 시뮬레이션 결과 동작 수행 성공인 경우 동작 수행이 성공했음을 나타 내는 결과를 시뮬레이션 제어 모듈 213으로 전달할 수 있다. 일 실시예에 따라 원인 분석 모듈 224는 시뮬레이션 결과 동작 수행 실패인 경우 동작 수행의 실패의 원인을 분 석할 수 있다. 시뮬레이션 동작 수행의 실패의 원인은, 사용자의 발화 내용의 인식 오류나 인식 불능, 사용자 에 의해 요청된 기능이나 서비스 부재, 계정 정보 부재 등을 포함할 수 있다. 원인 분석 모듈 224는 시뮬레이 션 결과 동작 수행 실패인 경우 동작 수행이 실패했음을 나타내는 결과와 함께 실패의 원인에 대한 정보도 함께 시뮬레이션 제어 모듈 213으로 전달할 수 있다. 일 실시예에 따라, 자연어 생성 모듈(NLG) 225은 수신된 정보를 텍스트 형태로 변경할 수 있다. 상기 텍스트 형 태로 변경된 정보는 자연어 발화의 형태일 수 있다. 상기 지정된 정보는, 예를 들어, 추가 입력에 대한 정보, 사용자 입력에 대응되는 동작의 완료를 안내하는 정보 또는 사용자의 추가 입력을 안내하는 정보(예: 사용자 입 력에 대한 피드백 정보)일 수 있다. 상기 텍스트 형태로 변경된 정보는 음성 어시스턴트 에이전트 210로 송신되 어 디스플레이에 표시되거나, 텍스트 음성 변환 모듈 226로 송신되어 음성 형태로 변경될 수 있다. 일 실시예에 따라, 텍스트 음성 변환 모듈 226은 텍스트 형태의 정보를 음성 형태의 정보로 변경할 수 있다. 텍 스트 음성 변환 모듈 226은 자연어 생성 모듈 225로부터 텍스트 형태의 정보를 수신하고, 상기 텍스트 형태의 정보를 음성 형태의 정보로 변경하여 음성 어시스턴트 에이전트 210로 전달할 수 있다. 음성 어시스턴트 에이전 트 210은 상기 음성 형태의 정보를 스피커로 출력할 수 있다. 도 2b는 일 실시 예에 따라 음성 어시스턴트가 구현된 컴퓨팅 장치의 다른 예 100b를 나타낸다. 도 2b를 참조하면, 컴퓨팅 장치 100b는 네트워크 350를 통하여 음성 어시스턴트 서버 300에 연결될 수 있다. 도 2a에 도시된 컴퓨팅 장치 100a과 유사하지만, 도 2a에 도시된 컴퓨팅 장치 100a의 메모리 140에 저장되었던 음성 인식 엔진 220이 도 2b에 도시된 음성 어시스턴트 서버 300의 메모리 320에 저장되어 있다. 음성 어시스턴트 서버 300는 프로세서 310, 메모리 320, 통신 회로 330을 포함한다. 프로세서 310는 음성 어시스턴트 서버 300의 메모리 320과 통신 회로 330의 제어를 포함하여 음성 어시스턴트 서버 300의 기능을 전반적으로 제어할 수 있다. 통신 회로 330은 프로세서 310의 제어에 따라서 네트워크 350를 통하여 컴퓨팅 장치 100의 통신을 수행할 수 있 다. 메모리 320는 음성 인식 엔진 220을 포함할 수 있다. 이러한 음성 인식 엔진 220은 도 2a에 도시된 음성 인식 엔진에 대응되는 역할을 할 수 있다. 도 2a에 도시된 컴퓨팅 장치 100에서는 음성 어시스턴트의 기능을 모두 컴퓨팅 장치 100에서 수행하였지만, 도 2b에 도시된 시스템에서는 음성 어시스턴트의 기능을 컴퓨팅 장치 100b와 음성 어시스턴트 서버 300가 함께 수 행할 수 있다. 도 2b에 도시된 예에서, 음성 어시스턴트의 기능 중, 입력된 발화 내용을 인식하고 인식된 발화 내용을 분석하며, 분석 결과에 따라 타 음성 어시스턴트의 반응 내용이 실패인 지 성공인지 판단하거나, 실패인 경우 그 원인이 무엇인지 판단하거나 또는 사용자의 발화 내용에 따라 수행되는 동작의 시뮬레이션을 위한 작업 룰의 결정은 음성 어시스턴트 서버 300의 음성 인식 엔진 220에 의해 수행될 수 있다. 따라서, 도 2b를 참조하면, 컴퓨팅 장치 100b의 음성 어시스턴트 에이전트 210는 어시스턴트를 호출하기 위해 발화되는 트리거 워드를 인식하고, 인식이 되면 트리거 워드 이후 발화되는 발화 음성을 음성 어시스턴트 서버 300으로 전달하고, 음성 어시스턴트 서버 300의 음성 인식 엔진 220은 전달된 발화 음성을 텍스트로 변환하여 발화 내용을 분석하고, 분석 결과에 따라 타 음성 어시스턴트의 반응 내용이 실패인 지 성공인지 판단할 수 있 다. 음성 인식 엔진 220은 분석한 내용을 컴퓨팅 장치 100b로 전달할 수 있고, 컴퓨팅 장치 100b는 음성 인식 엔진 220으로부터 수신된 결과를 이용하여 발화 내용에 대응하는 동작 시뮬레이션을 해보거나 후속동작을 제어 할 수 있다. 한편, 도 2a 내지 도 2b에 도시된 컴퓨팅 장치 100a, 100b의 블록도는 일 실시예를 위한 블록도이다. 블록도의 각 구성요소는 실제 구현되는 컴퓨팅 장치 100a, 100b의 사양에 따라 통합, 추가, 또는 생략될 수 있다. 예를 들어, 필요에 따라 2 이상의 구성요소가 하나의 구성요소로 합쳐지거나, 혹은 하나의 구성요소가 2 이상의 구성 요소로 세분화되어 구성될 수 있다. 또한, 각 블록에서 수행하는 기능은 실시예들을 설명하기 위한 것이며, 그 구체적인 동작이나 장치는 본 발명의 권리범위를 제한하지 아니한다. 이상 설명한 도 2a의 시스템은 사용자 디바이스 측에서 음성 인식(Auto Speech Recognition, ASR)이 수행되는 온-디바이스 음성 인식에 관한 것으로, 대기 시간(latency)이 짧고 네트워크가 연결이 되지 않는 경우에도 이용 가능하다는 장점이 있다. 반면에 도 2b에 도시된 바와 같이 서버 측에서 음성 인식이 수행되는 서버-기반 음성 인식은, 서버에 저장된 더 많은 데이터베이스에 기초하여 음성 인식이 수행되므로 좀더 성능이 좋아질 수 있는 장점이 있다. 그러나, 본 개시서에 개시된 실시예들은 도 2a나 도 2b에 도시된 형태로 제한되지 않는다. 예 를 들어, 도 2b의 음성 어시스턴트 서버는 음성 어시스턴트 200의 구성요소 중 음성 인식 엔진 220의 구성만을 포함하는 것으로 도시되었지만, 이러한 실시예에 한정되지 않는다. 일 실시예에 따라, 음성 인식 시스템의 성능 향상을 위해, 도 2a에 도시된 음성 인식 엔진 220의 일부 구성요소 는 컴퓨팅 장치 100b에 포함될 수 있거나 또는 음성 어시스턴트 에이전트 210의 일부 구성 요소 또한 서버 컴퓨 터 300에 포함될 수 있다. 또는 일 실시예에 따라 도 2a에 도시된 음성 어시스턴트 200에 포함된 음성 어시스턴트 에이전트 210 및 음성 인식 엔진 220 전부가 서버 컴퓨터 300에 포함되어, 컴퓨팅 장치 100b는 음성의 입/출력 및 이미지 데이터의 입 출력에만 관여하고, 음성 어시스턴트 기능의 대부분이 서버 컴퓨터 300에 의해 수행될 수도 있다. 또는 일 실시예에 따라, 음성 인식 시스템의 성능 향상을 위해, 도 2b에 도시된 음성 인식 에이전트 210의 일 부 구성 요소 및/또는 음성 인식 엔진 220의 일부 구성 요소는 별도의 제3의 서버 컴퓨터에 포함되어 수행될 수 도 있다. 도 3은 일 실시 예에 따라 음성 어시스턴트가 구현된 컴퓨팅 장치의 다른 예 100c를 나타낸다. 도 3을 참조하면 컴퓨팅 장치 100c는 도 2a에 도시된 컴퓨팅 장치 100a와 대체로 유사하지만, 컴퓨팅 장치 100c 에서는 입력 모듈 110, 디스플레이 120, 스피커 130의 하나 이상이 외부 장치에 의해 대체되거나, 또는 추가적 인 외부 장치가 연결될 수 있다. 일 실시예에 따라, 컴퓨팅 장치 100c는 마이크를 포함하는 입력 모듈 110에 더하여 추가적으로, 마이크를 포함 하는 원격 제어 장치 410으로부터 네트워크 450을 통하여 사용자의 발화 내용이나 타 음성 어시스턴트의 반응 내용을 수신할 수 있다. 일 실시예에 따라, 컴퓨팅 장치 100c는 마이크를 포함하는 입력 모듈 110 을 포함하지 않고, 마이크를 포함하는 원격 제어 장치 410으로부터 네트워크 450을 통하여 사용자의 발화 내용이나 타 음성 어시스턴트의 반응 내용을 수신할 수 있다. 일 실시예에 따라 원격 제어 장치 410는 마이크를 구비하고, 적외선 통신이나 근거리 통신 (와이파이나 블루투 스 등)을 수행하는 리모트 콘트롤러, 리모트 콘트롤 앱을 설치하고 TV 등의 장치를 제어하거나 음성 인식 기능 을 수행할 수 있는 스마트폰, 또는 AI 스피커 등을 포함할 수 있다. 일 실시예에 따라, 컴퓨팅 장치 100c는 디스플레이 120에 더하여 추가적으로, 디스플레이 장치 420과 통신함으 로써, 컴퓨팅 장치 100c에서 처리된 이미지의 출력을 위해 디스플레이 장치 420로 전달할 수 있다. 이 경우 컴 퓨팅 장치 100c에 포함된 디스플레이 120는 알림 등의 용도로 사용되는 간단한 표시창이 될 수 있다. 일 실시예에 따라, 컴퓨팅 장치 100c는 디스플레이 120을 포함하지 않고, 네트워크 450을 통하여 컴퓨팅 장치 100c에서 처리된 이미지의 출력을 위해 처리된 이미지를 디스플레이 장치 420로 전송할 수 있다. 컴퓨팅 장치 100c와 디스플레이 장치 420는 네트워크 450을 통해 연결될 수 있거나, 또는 HDMI, DP, 썬더볼트 등의 비디오 오디오를 동시에 전송할 수 있는 입출력 포트 또는 비디오 오디오 신호를 별개로 출력하는 입출력 포트 등을 통해 연결될 수 있다. 일 실시예에 따라, 컴퓨팅 장치 100c는 스피커 130에 더하여 추가적으로, 오디오 출력 장치 430과 통신함으로써, 컴퓨팅 장치 100c에서 처리된 음성의 출력을 위해 오디오 출력 장치 430로 전달할 수 있다. 일 실시예에 따라, 컴퓨팅 장치 100c는 스피커 130를 포함하지 않고, 네트워크 450을 통하여 컴퓨팅 장치 100c 에서 처리된 음성의 출력을 위해, 처리된 음성을 오디오 출력 장치 430으로 전송할 수 있다. 컴퓨팅 장치 100c와 오디오 출력 장치 430는 네트워크 450을 통해 연결될 수 있거나, 또는 HDMI, DP, 썬더볼트 등의 비디오 오디오를 동시에 전송할 수 있는 입출력 포트 또는 비디오 오디오 신호를 별개로 출력하는 입출력 포트 등을 통해 연결될 수 있다. 도 4는 일 실시예에 따라 음성 어시스턴트가 설치되는 다양한 형태를 설명하기 위한 참고도이다. 도 4를 참조하면, 시스템은 제1장치 10, 제2장치 20, 제3장치 30, 컴퓨팅 장치 100을 포함한다. 제1장치 10에 는 제1 음성 어시스턴트 11이 설치되어 있고, 제2 장치 20는 제2 음성 어시스턴트 21이 설치되어 있고, 제3 장 치 30에는 제3음성 어시스턴트 31이 설치되어 있다. 또한 일 실시예에 따른 컴퓨팅 장치 100에는 제4 음성 어 시스턴트 40, 제5음성 어시스턴트 50 및 본 개시서에 개시된 실시예에 따른 음성 어시스턴트 200이 설치되어 있 다. 본 실시예에 따른 음성 어시스턴트 200는 다른 장치 즉, 제1 장치, 제2 장치, 제3 장치에 설치된 제1 음성 어시 스턴트, 제2음성 어시스턴트, 제3음성 어시스턴트의 반응을 모니터링할 수 있을 뿐만 아니라, 같은 컴퓨팅 장 치 100에 설치된 제4 음성 어시스턴트, 제5음성 어시스턴트의 반응을 모니터링할 수 있다. 같은 컴퓨팅 장치 100에 설치된 타 음성 어시스턴트라도 다른 장치에 설치된 음성 어시스턴트와 마찬가지로 마이크를 통하여 음성 입력을 수신함으로써 타 음성 어시스턴트의 반응을 모니터링할 수 있다. 특히 동일한 컴퓨팅 장치 100에 설치된 제4음성 어시스턴트 40 및 제5 음성 어시스턴트 50에 대해서는 이들의 음성 반응 뿐만 아니라 디스플레이를 통해서 출력되는 시각적 반응까지도 캡쳐하여 분석에 이용할 수 있다. 도 5 및 도 6은 실시예들에 따라 음성 어시스턴트를 포함하는 컴퓨팅 장치에서의 동작 방법의 일 예를 나타내는 흐름도이다. 도 5를 참조하면, 동작 510에서, 컴퓨팅 장치 100는 타 음성 어시스턴트의 트리거 워드를 수신할 수 있다. 동작 520에서, 컴퓨팅 장치 100는 타 음성 어시스턴트의 트리거 워드를 인식가능한지 판단할 수 있다. 컴퓨팅 장치 100가 타 음성 어시스턴트의 트리거 워드의 인식이 가능하지 않은 경우, 예를 들어 인식률이 좋지 않은 경우, 동작 530에서 해당 트리거 워드의 인식률을 높이기 위한 학습을 진행하고 종료할 수 있다. 컴퓨팅 장치 100가 타 음성 어시스턴트의 트리거 워드의 인식이 가능한 경우, 동작 540에서, 사용자 발화 내용 을 수신하고 분석할 수 있다. 여기서 사용자 발화 내용은, 타 음성 어시스턴트에 서비스를 요청하기 위한 사용 자의 발화 내용이나 사용자의 의도를 확인하기 위한 타 음성 어시스턴트의 질문에 대한 대답에 대응하는 발화 내용, 또는 타 음성 어시스턴트의 반응에 대한 사용자의 후속 발화 내용을 포함할 수 있다. 컴퓨팅 장치 100는 사용자의 발화 내용을 분석하여 사용자의 의도가 무엇인지 파악할 수 있다. 일 실시예에 따라 컴퓨팅 장치 100는 사용자의 의도를 분석하기 위해 음성으로 수신되는 사용자 발화 내용 뿐만 아니라 텍스트를 통한 사용자의 입력을 이용할 수도 있다. 예를 들어, 타 음성 어시스턴트가 메뉴나 버튼 등을 이용하여 사용자의 의도를 문의하는 UI 를 포함하는 화면을 출력하고, 사용자가 이에 대한 응답으로 UI에서 메 뉴나 버튼을 선택하는 경우, 컴퓨팅 장치 100는 선택된 버튼을 포함하는 화면을 캡쳐하고 자동 문자 인식 (Automatic Character Recognition) 기술 등을 이용하여 사용자가 선택한 메뉴나 버튼에 대응하는 텍스트를 추 출하고 이러한 텍스트를 분석함으로써 사용자의 의도를 분석할 수 있다. 동작 550에서, 컴퓨팅 장치 100는 타 음성 어시스턴트의 반응 동작을 수신하고 분석할 수 있다. 여기서 타 음 성 어시스턴트의 반응 동작은 사용자의 서비스 요청에 대응한 반응 동작 뿐만 아니라 사용자의 의도를 확인하기 위해 사용자에게 질문하는 발화 내용을 포함할 수 있다. 컴퓨팅 장치 100는 타 음성 어시스턴트의 반응 동작을 분석함으로써, 타 음성 어시스턴트가 제대로 음성 인식을 하고 있는지, 타 음성 어시스턴트가 사용자의 의도를 제대로 파악하고 있는지, 타 음성 어시스턴트가 사용자의 의도에 따라 적합하게 서비스를 제공하는지를 판단할 수 있다. 일 실시예에 따라 타 음성 어시스턴트의 반응 동작은 음성 반응 동작 뿐만 아니라 텍스트 반응 동작을 포함할 수 있다. 음성 반응 동작은, 사용자의 서비스 요청에 대한 타 음성 어시스턴트의 응답이 음성으로 출력되는 것 을 의미한다. 텍스트 반응 동작은, 사용자의 서비스 요청에 대한 타 음성 어시스턴트의 응답이 텍스트를 포함하 는 이미지로 출력되는 것을 의미한다. 여기서 텍스트를 포함하는 이미지는 실제 텍스트를 포함하는 이미지 뿐 만 아니라, 버튼이나 메뉴와 같은 아이템들을 포함하는 비쥬얼 UI를 포함하는 이미지를 포함할 수 있다. 타 음 성 어시스턴트의 음성 반응 동작은 음성 인식 모듈 등에 의해 인식될 수 있고, 텍스트 반응 동작은 디스플레이 화면을 캡쳐하고 나서 자동 문자 인식 (Automatic Character Recognition) 기술 등을 이용하여 텍스트를 추출할 수 있다. 동작 560에서, 컴퓨팅 장치 100는 사용자 발화 내용 분석 결과 및 타 음성 어시스턴트의 반응 동작 분석 결과에 기초해서, 타 음성 어시스턴트의 서비스 제공 실패 여부를 판단할 수 있다. 일 실시예에 따라 타 음성 어시스턴트의 서비스 제공 실패 여부를 판단한 결과, 타 음성 어시스턴트의 서비스 제공이 성공한 경우 컴퓨팅 장치는 동작을 종료할 수 있다. 다른 실시예에 따라 타 음성 어시스턴트의 서비스 제공이 성공한 경우에도 동작 A로 진행하여 사용자 발화 내용 에 대응하여 수행되는 동작을 시뮬레이션 해볼 수 있다. 타 음성 어시스턴트의 서비스 제공 실패 여부를 판단한 결과, 타 음성 어시스턴트의 서비스 제공이 실패한 경우 A로 진행한다. A로 진행하여, 동작 605에서, 컴퓨팅 장치는 사용자 발화 내용에 대응하여 수행되는 동작을 시뮬레이션 수행해 본다. 동작 610에서, 컴퓨팅 장치 100는 시뮬레이션 수행 결과 동작이 성공인지를 판단하고, 시뮬레이션 동작 수행이 실패인 경우 동작 615로 진행한다. 동작 615에서, 컴퓨팅 장치 100는 시뮬레이션 동작 수행의 실패의 원인을 분석할 수 있다. 동작 620에서, 컴퓨팅 장치 100는 시뮬레이션 동작 수행 실패의 원인이 음성인식 이나 의도 분석 실패인지, 기 능 서비스 부재인지를 판단할 수 있다. 시뮬레이션 동작 수행 실패의 원인이 음성 인식 실패인 경우, 동작 625에서 컴퓨팅 장치 100는 음성 인식 기능 을 학습할 수 있다. 따라서 비록 시뮬레이션 동작 수행이 실패인 경우라도, 컴퓨팅 장치 100는 어느 부분에 대 해서 음성 인식 기능이 취약한지를 스스로 파악하여 음성 인식 기능에 대한 학습을 수행함으로써 스스로 음성 인식 기능을 개선시킬 수 잇다. 시뮬레이션 동작 수행 실패의 원인이 기능/서비스 부재인 경우, 동작 630에서, 컴퓨팅 장치 100는 기능/서비스 서버에 업데이트를 요청할 수 있다. 따라서, 비록 시뮬레이션 동작 수행이 실패인 경우라도, 컴퓨팅 장치 100 는 자신에게 부족한 서비스 내지 기능을 검색하여 업데이트해 놓거나, 부족한 서비스 내지 기능을 기록해둠으로 써 자신이 부족한 서비스 내지 기능을 인지하고 관리할 수 있다. 동작 610에서, 컴퓨팅 장치 100는 시뮬레이션 수행 결과 동작이 성공인지를 판단하고, 시뮬레이션 동작 수행이 성공인 경우 동작 635로 진행한다. 동작 635에서, 컴퓨팅 장치 100는 타 음성 어시스턴트가 실패했던 서비스의 긴급성을 판단할 수 있다. 예를 들 어, 해당 서비스가 실시간으로 제공해야 의미가 있는 서비스 인지 또는 실시간으로 제공하지 않아도 상관없는 내용의 서비스인지를 판단할 수 있다. 동작 640에서, 컴퓨팅 장치 100는 서비스의 긴급성 판단 결과 실시간으로 제공해야 하는 서비스 내용인지 아닌 지 여부를 판단할 수 있다. 판단결과, 실시간으로 제공해야 의미가 있는 서비스 내용인 경우, 동작 645에서, 컴퓨팅 장치 100는 실시간으로 사용자에게 해당 서비스를 제공가능함을 통지할 수 있다. 판단결과, 추후 제공해도 문제 없는 서비스 내용인 경우, 동작 650에서, 컴퓨팅 장치 100는 본 음성 어시스턴트 에 대한 사용자의 서비스 요청에 대해서 응답을 한 후, 사용자에게 이전 타 음성 어시스턴트가 실패했던 서비스 를 제공가능함을 나타내는 통지를 출력할 수 있다. 이상 도 6에 도시된 동작 635에서는 시뮬레이션 동작이 성공인 경우 사용자에게 통지하는 시점을 결정하기 위해 서비스 내용의 긴급성을 판단하는 것으로 설명되었다. 그러나 반드시 서비스 내용의 긴급성을 기준으로 판단할 필요는 없다. 다양한 다른 기준에 따라서 실시간으로 통지를 제공할지 추후 제공할지 결정할 수 있을 것이다. 또는, 다른 실시예로서 실시간/추후 통지를 판단하지 않고 컴퓨팅 장치 100 내부적으로 디폴트로, 통지를 실시 간으로 제공할지 추후 제공할지 결정되어 있을 수 있다. 또한, 도 5, 및 6에 도시된 동작에서는 주로 타 음성 어시스턴트의 서비스 제공이 실패한 경우 컴퓨팅 장치 100 가 사용자 서비스 요청에 대응하는 발화 내용에 대응하는 동작을 시뮬레이션 하는 것으로 설명되었지만, 반드시 이에 한정되는 것은 아니고, 컴퓨팅 장치 100는 타 음성 어시스턴트의 서비스 제공 실패 여부와 상관 없이 항상 사용자 서비스 요청에 대응하는 동작을 시뮬레이션 해볼 수 있다. 이 경우, 컴퓨팅 장치 100는 타 음성 어시스 턴트의 서비스 결과와 자신이 시뮬레이션한 결과를 비교하고, 자신이 시뮬레이션 한 결과가 타 음성 어시스턴 트의 서비스 결과보다 더 우수하다고 판단된 경우, 이러한 더 개선된 서비스 결과를 제공할 수 있음을 사용자에 게 통지할 수 있다. 이하에서는 도 7 내지 도 17을 참조하여, 실시예들에 따른 컴퓨팅 장치에서의 다양한 시나리오를 설명한다. 도 7은 일 실시예에 따라 컴퓨팅 장치 100에서 타 음성 어시스턴트 트리거 워드의 인식을 실패한 경우의 동작을 설명하기 위한 흐름도이다. 도 7을 참조하면, 동작 701에서, 음성 인식 에이전트 211는 타 음성 어시스턴트 트리거워드를 수신할 수 있다. 동작 702에서 음성 인식 에이전트 211는 타 음성 어시스턴트 트리거워드를 인식 동작 수행하지만, 인식이 실패 할 수 있다. 개시된 실시예에 따른 음성 인식 에이전트 211는 본 음성 어시스턴트의 트리거 워드 뿐만 아니라 하나 이상의 타 음성 어시스턴트의 트리거 워드를 미리 학습해둠으로써 인식할 수 있다. 이와 같이 음성 인식 에이전트 211가 복수개의 트리거 워드를 학습해두면 후추 트리거 워드가 입력되었을 때, 음성 인식 모듈을 이용하여 음성 인 식을 수행해보면, 음성 인식 에이전트 211이 학습해놓은 각 음성 어시스턴트에 대응하는 음성 인식 스코어가 출 력될 수 있다. 그리고 음성 인식 스코어가 미리 정해진 임계치를 넘는 경우에 해당 임계치를 넘은 스코어를 가 진 음성 어시스턴트의 트리거 워드임을 인식할 수 있다. 따라서, 음성 어시스턴트 트리거 워드의 인식 결과 미 리 정해진 임계치를 넘는 스코어가 출력되지 않는 경우에도, 스코어 값을 기초로 어느 음성 어시스턴트에 대응 하는 트리거 워드의 인식이 실패했는지는 알 수 있게 된다. 도 8은 타 음성 어시스턴트 트리거 워드의 인식을 실패한 경우의 상황을 나타내는 참고도이다. 예를 들어 도 8에 도시된 바와 같이 사용자가 타 음성 어시스턴트에 대해서 “하이 시리우스”를 발화한 경우, 본 음성 어시스턴트인 빅스비는 “하이 시리우스”라는 트리거 워드를 수신하여 이 트리거 워드가 어느 음성 어 시스턴트에 대응하는 것인지 인식을 수행할 수 있다. 이때, 트리거 워드 인식 수행 결과, 빅스비가 인식하고 있는 복수의 트리거 워드중에서 “시리우스” 음성 어시스턴트가 가장 높은 스코어, 예를 들어 50 퍼센트로 인 식되기는 했지만, 이 가장 높은 스코어가 인식 성공으로 판단할 수 있는 임계치인 80 퍼센트 보다는 작은 경우, 본 어시스턴트인 빅스비는 트리거 워드의 인식 실패로 판단할 수 있다. 따라서, 동작 703에서 음성 인식 에이전트 211는 해당 인식 실패한 트리거 워드에 대해서 인식 기능을 향상시키 기 위한 학습을 수행할 수 있다. 이와 같이 타 음성 어시스턴트의 트리거 워드의 인식을 실패한 경우라도, 실패한 트리거 워드의 인식을 위한 학 습을 수행함으로써 음성 인식 에이전트 211의 트리거 워드 인식 기능을 보다 향상시킬 수 있다. 도 9는 일 실시예에 따라 사용자의 타 음성 어시스턴트 트리거 워드 발화 후 타 음성 어시스턴트에서 반응이 없 는 경우의 동작을 설명하기 위한 흐름도이다. 도 9를 참조하면, 동작 901에서, 음성 인식 에이전트 211는 타 음성 어시스턴트 트리거워드를 수신할 수 있다. 동작 902에서 음성 인식 에이전트 211는 타 음성 어시스턴트 트리거워드를 인식하는데 성공하고, 사용자 발화를 기다리는 리스닝 상태로 진입할 수 있다. 동작 903에서 음성 인식 에이전트 211는 사용자의 발화 음성을 수신하고, 동작 904에서 음성 인식 에이전트 211 는 수신된 사용자의 발화 음성을 자동음성 인식 모듈 221로 제공할 수 있다. 동작 905에서, 자동 음성 인식 모듈 221은 수신된 사용자의 발화 음성을 인식하여 텍스트 데이터로 변환하고 발 화 내용에 대응하는 텍스트 데이터를 발화 내용 분석 모듈 222로 제공할 수 있다. 동작 906에서, 발화 내용 분석 모듈 222는 사용자의 발화 내용에 대응하는 텍스트 데이터를 수신하고 사용자의 의도 등을 분석하여 분석 결과를 음성 인식 에이전트 211로 전달할 수 있다. 동작 907에서, 이러한 사용자의 발화 내용에 대응해서 타 음성 어시스턴트의 음성 반응이 없는 것을 인식할 수 있다. 예를 들어 사용자의 발화 내용을 수신하고 나서 소정 시간 경과해도 타 음성 어시스턴트의 음성 반응이 없는 경우가 있을 수 있다. 이는 타 음성 어시스턴트에서 여러가지 원인 등에 의해 발생할 수 있는 데 예를 들 어 타 음성 어시스턴트의 음성 인식 기능이 좋지 않은 경우 발생할 수 있다. 도 10은 타 음성 어시스턴트로부터 트리거 워드에 대한 반응이 없는 경우의 상황을 나타내는 참고도이다. 도 10을 참조하면, 예를 들어 사용자는 타 음성 어시스턴트인 시리우스에 대해서 “하이 시리우스”라고 트리거 워드를 발화하였는데 소정 시간이 경과하여도 타 음성 어시스턴트인 시리우스에게서 아무런 반응이 없는 경우 사용자는 매우 답답함을 느끼거나 또는 신속한 반응이 필요한 서비스를 사용자가 요청하려고 하는 경우에는 사 용자에게 불편함을 줄 수 있다. 동작 908에서, 음성 인식 에이전트 211는 이와 같은 경우에 후속 동작을 결정할 수 있다. 예를 들어, 이와 같 은 경우에 음성 인식 에이전트 211가 끼어들어 대신 반응을 제공하기로 결정한 경우에, 동작 909에서 음성 인식 에이전트 211는 반응으로 이용할 발화 내용을 생성하여 이를 텍스트 음성 변화 모듈 226으로 제공할 수 있다. 예를 들어, 음성 인식 에이전트 211는 “빅스비 입니다. 제가 도와드릴까요?” 와 같은 발화 내용 텍스트를 텍 스트 음성 변환 모듈 226으로 제공할 수 있다. 동작 910에서, 텍스트 음성 변환 모듈 226은 수신된 발화 내용 텍스트를 음성으로 변환하고 변환된 음성을 음성 인식 에이전트 211로 제공하면, 동작 911에서, 음성 인식 에이전트 211는 “빅스비입니다. 제가 도와드릴까요?” 와 같은 발화 음성을 출력할 수 있다. 도 9에 도시된 상황에서는 동작 903 부터 동작 906까지 타 음성 어시스턴트 트리거 워드 이외의 사용자 발화가 있는 경우를 도시하였지만, 사용자 발화가 없는 경우도 마찬가지로 적용될 수 있다. 도 11은 일 실시예에 따라 사용자의 타 음성 어시스턴트에 대한 서비스 요청에 대해서 타 음성 어시스턴트의 서 비스 제공이 실패되고, 본 음성 어시스턴트에서 시뮬레이션 결과 성공한 경우 실시간으로 사용자에게 통지를 제 공하는 경우의 동작을 설명하기 위한 흐름도이다. 도 11을 참조하면, 동작 1101에서, 음성 인식 에이전트 211는 타 음성 어시스턴트 트리거워드를 수신할 수 있다. 동작 1102에서 음성 인식 에이전트 211는 타 음성 어시스턴트 트리거워드를 인식하는데 성공하고, 사용자 발화 를 기다리는 리스닝 상태로 진입할 수 있다. 동작 1103에서 음성 인식 에이전트 211는 사용자의 발화 음성을 수신하고, 동작 1104에서 음성 인식 에이전트 211는 수신된 사용자의 발화 음성을 자동음성 인식 모듈 221로 제공할 수 있다. 동작 1105에서, 자동 음성 인식 모듈 221은 수신된 사용자의 발화 음성을 인식하여 텍스트 데이터로 변환하고 발화 내용에 대응하는 텍스트 데이터를 발화 내용 분석 모듈 222로 제공할 수 있다. 동작 1106에서, 발화 내용 분석 모듈 222는 사용자의 발화 내용에 대응하는 텍스트 데이터를 수신하고 사용자의 의도 등을 분석하여 분석 결과를 음성 인식 에이전트 211로 전달할 수 있다. 동작 1107에서, 음성 인식 에이전트 211는 타 음성 어시스턴트로 요청하는 사용자의 발화 내용에 응답하는 타 음성 어시스턴트의 음성 반응에 대응하는 발화 내용을 수신할 수 있다. 동작 1108에서 음성 인식 에이전트 211는 수신된 타 음성 어시스턴트의 음성 반응에 대응하는 발화 내용을 자동 음성 인식 모듈 221로 제공할 수 있다. 동작 1109에서, 자동 음성 인식 모듈 221은 수신된 타 음성 어시스턴트의 음성 반응에 따른 발화 음성을 인식하 여 텍스트 데이터로 변환하고 발화 내용에 대응하는 텍스트 데이터를 발화 내용 분석 모듈 222로 제공할 수 있 다. 동작 1110에서, 발화 내용 분석 모듈 222는 타 음성 어시스턴트의 음성 반응에 대응하는 발화 내용에 대응하는 텍스트 데이터를 수신하고 타 음성 어시스턴트의 의도 등을 분석하여 분석 결과를 음성 인식 에이전트 211로 전 달할 수 있다. 동작 1111에서, 음성 인식 에이전트 211는 사용자의 발화 내용을 분석한 분석 결과 및 타 음성 어시스턴트의 발 화 내용을 분석한 분석 결과를 토대로 타 음성 어시스턴트의 서비스 제공의 실패 여부를 판단할 수 있다. 실패 여부를 판단한 결과, 실패인 것으로 판단된 경우, 음성 인식 에이전트 2111는 사용자의 발화 내용에 대한 서비스를 제공할 수 있는지 여부를 보기 위해, 사용자의 발화 내용에 대응하여 수행되는 동작의 수행을 시뮬레 이션 해본다. 시뮬레이션은 사용자의 서비스 요청을 위한 발화 내용에 대응해서 실제로 발화 내용에 따른 서비 스 제공을 위해 동작을 수행해보는 것이지만, 다만 실제 동작 수행의 결과는 사용자에게 제공되지 않는다. 동작 1112에서, 사용자의 발화 내용에 대응하는 동작 수행의 시뮬레이션을 위해, 음성 인식 에이전트 211는 실 제 동작과 마찬가지로 사용자의 발화 내용을 자동 음성 인식 모듈 221로 제공하고, 동작 1113에서 자동 음성 인 식 모듈 221은 수신된 사용자의 발화 내용에 대응하는 음성을 텍스트로 변환하여 발화 내용분석 모듈 222로 제 공한다. 동작 1114에서 발화 내용 분석 모듈 222는 수신된 사용자의 발화 내용에 대응하는 텍스트 데이터를 기초로 사용 자의 의도를 분석하고 사용자의 의도에 대응하여 동작되어야 하는 작업 룰을 결정하며, 결정된 작업 룰을 음성 인식 에이전트 211로 제공할 수 있다. 동작 1115에서, 음성 인식 에이전트 211는 발화 내용 분석 모듈 222로부터 수신된 작업 룰을 실행 관리 모듈 216로 제공할 수 있다. 동작 1116에서, 실행 관리 모듈 216은 음성 인식 에이전트 211로부터 수신한 작업 룰에 따라 하나 이상의 어플 리케이션을 실행함으로써 작업 룰에 정의된 동작을 수행을 하고, 어플리케이션 실행 결과 또는 동작 수행 결과를 음성 인식 에이전트 211로 제공할 수 있다. 동작 1117에서, 음성 인식 에이전트 211는 실행 관리 모듈 216으로부터 수신한 동작 수행 결과를 분석하여, 사 용자의 발화 내용에 대응하는 동작이 제대로 수행되었는지, 즉, 사용자의 발화 내용에 대응하는 서비스의 제공 을 위한 동작이 수행가능한지 여부를 판단할 수 있다. 이때 음성 인식 에이전트 211이 사용자의 발화 내용에 대응하는 동작 수행을 시뮬레이션 해 본 결과, 동작 성공으로 판단된 경우, 음성 인식 에이전트 211는 해당 서 비스를 본 음성 어시스턴트에서 제공가능함을 나타내는 통지를 사용자에게 출력할 수 있는데, 이러한 통지의 출 력 시점은 다양하게 결정될 수 있다. 예를 들어, 타 음성 어시스턴트에서 제공이 실패되었던 서비스를 본 음성 어시스턴트에서 제공가능함을 나타내는 통지는 실시간으로 사용자에게 출력될 수 있다. 예를 들어, 서비스 내 용이 현재 시간이나 현재 장소와 밀접하게 관련되어 있어서 서비스 제공가능함을 나타내는 통지를 추후에 사용 자에게 알려주는 것이 의미가 없어지는 경우, 음성 인식 에이전트 211는 서비스 통지를 실시간으로 출력할 수 있다. 서비스 통지를 실시간으로 출력하기로 결정한 경우에, 동작 1118에서 음성 인식 에이전트 211는 사용자에게 통 지할 내용에 대한 텍스트를 결정하여 텍스트 음성 변환 모듈 226으로 제공할 수 있다. 동작 1119에서, 텍스트 음성 변환 모듈 226은 음성 인식 에이전트 211로부터 수신한 텍스트를 음성으로 변환하 고 이를 음성 인식 에이전트 211로 제공하면, 동작 1120에서, 음성 인식 에이전트 211는 수신된 음성을 사용자 에게 출력할 수 있다. 한편, 도 11에는 도시되지 않았지만, 사용자의 발화 내용 분석이나 타 음성 어시스턴트의 반응 내용 분석에는 음성 반응 뿐만 아니라 텍스트 반응도 이용될 수 있다. 예를 들어, 타 음성 어시스턴트가 사용자의 서비스 요청에 대한 응답으로 비쥬얼 UI를 출력한 경우 그리고 사용 자가 출력된 비쥬얼 UI에서 특정한 메뉴나 버튼을 선택한 경우, 이러한 비쥬얼 UI는 타 음성 어시스턴트의 텍스 트 반응으로 분석될 수 있고, 비쥬얼 UI에서 특정한 메뉴나 버튼을 선택한 결과는 사용자의 의도 분석에 이용될 수 있다. 도 17은 일 실시예에 따라 비쥬얼 UI가 출력되고 이러한 비쥬얼 UI반응을 이용하는 방법을 설명하기 위한 참고 도이다. 도 17을 참조하면, 컴퓨팅 장치 100에 타 음성 어시스턴트 구글라 1710와 본 음성 어시스턴트 빅스비 1720가 함 께 설치되어 있는 상황에서, 사용자는 타 음성 어시스턴트인 구글라에게 “하이 구글라! 노래 틀어줘”라는 요 청을 했고, 이에 대해 타 음성 어시스턴트는 비쥬얼 UI 로서 “죄송합니다. 계정 로그인이 필요합니다. 계속 진 행할까요? <예> <아니오>”를 포함하는 그래픽 유저 인터페이스 1700을 출력한 상태이다. 이와 같이 타 음성 어 시스턴트의 텍스트 반응이 있는 경우 음성 인식 에이전트 211는 디스플레이 120에 출력된 화면을 캡쳐하고 자동 문자 인식 모듈 215로 하여금 캡쳐된 화면에서 문자를 인식하도록 할 수 있다. 인식된 문자는 발화 내용 분석 모듈 222의 자연어 이해 모듈 223로 전달되어 텍스트의 의미가 분석되도록 할 수 있다. 도 12a는 일 실시예에 따라 도 11에 도시된 동작의 상황을 나타내기 위한 참고도이다. 도 12a를 참조하면, 사용자는 타 음성 어시스턴트 시리우스에게 서비스 요청을 위해 “하이, 시리우스! 지금 월 드컵 생중계 라디오 틀어줘!”라는 발화를 할 수 있다. 그런데 이러한 사용자의 서비스 요청에 대해서 타 음성 어시스턴트 시리우스는 통신상의 문제로 인해 서비스 제 공에 실패하고 “죄송합니다. 지금 통신 연결 상태가 좋지 않습니다” 라는 음성 반응을 출력할 수 있다. 본 음성 어시스턴트 빅스비는 이와 같이 타 음성 어시스턴트에 대해서 서비스 요청을 위한 사용자의 발화 내용 과 이러한 서비스 요청에 대한 타 음성 어시스턴트의 음성 반응을 인식하고 분석함으로써, 타 음성 어시스턴트 시리우스가 사용자에 의해 요청된 서비스 제공에 실패한 것으로 판단할 수 있다. 그리고 이와 같이 타 음성 어 시스턴트가 서비스 제공에 실패한 것으로 판단된 경우, 본 음성 어시스턴트 빅스비는 타 음성 어시스턴트가 제 공에 실패했던 서비스 동작 즉 “지금 월드컵 생중계 라디오 틀어줘”에 대응하는 동작이 수행가능한지 시뮬레 이션 해보고, 만약 수행가능하다면 사용자에게 바로 해당 서비스가 제공가능함을 통지할 수 있다. 예를 들어, 본 음성 어시스턴트 빅스비는 “빅스비입니다. 제가 대신 월드컵 생중계 라디오 틀어드릴까요?” 라는 가이드 음성을 출력할 수 있다. 예를 들어 지금 생중계되고 있는 컨텐츠 제공을 서비스로 요청하는 경우에, 이러한 타 입의 서비스는 “생중계” 라는 특성상 나중에 서비스 제공되는 것이 사용자에게 도움이 되지 않을 수 있으므로, 이러한 타입의 서비스에 대해서, 서비스 제공 가능함을 나타내는 통지를 실시간으로 출력하는 것이바람직할 수 있다. 도 11에서는 동작 1111에서, 타 음성 어시스턴트의 발화 음성 분석 결과, 타 음성 어시스턴트의 서비스 제공이 실패한 경우 본 음성 어시스턴트가 사용자의 서비스 요청에 대응하는 동작을 시뮬레이션하는 것으로 설명되었다. 그러나, 실시예들은 반드시 이에 한정되지 않는다. 실시예들에 따라서는 타 음성 어시스턴트의 서비스 제공이 실패가 아닌 경우에도 본 음성 어시스턴트는 사용자의 서비스 요청에 대응하는 동작을 시뮬레이 션 해보고, 타 음성 어시스턴트의 서비스 결과와 본 음성 어시스턴트의 시뮬레이션 결과를 비교해보고, 비교 결 과 본 음성 어시스턴트의 시뮬레이션 결과에 따라 서비스 제공가능함을 사용자에게 통지하는 것이 바람직할 수 있다. 도 12b는 일 실시예에 따라 타 음성 어시스턴트의 서비스 결과와 본 음성 어시스턴트의 시뮬레이션 결과를 비교 해보고, 비교 결과 본 음성 어시스턴트의 시뮬레이션 결과에 따라 서비스 제공가능함을 나타내기 통지를 출력하 는 상황을 설명하기 위한 참고도이다. 도 12b를 참조하면, 사용자는 타 음성 어시스턴트 시리우스에게 서비스 요청을 위해 “하이, 시리우스! 삼성 뮤 직에서 최신 곡 틀어줘!”라는 발화를 할 수 있다. 그런데 이러한 사용자의 서비스 요청에 대해서 타 음성 어시스턴트 시리우스는 아직 삼성 뮤직 사이트에 로그인 상태가 아니어서 “계정 로그인이 필요합니다. 로그인 정보를 알려주세요” 라는 음성 반응을 출력할 수 있다. 본 음성 어시스턴트 빅스비는 자신이 동일한 서비스 요청에 대해서 수행되는 동작을 시뮬레이션 해 본 결과, 자 신은 이미 삼성 뮤직 사이트에 로그인된 상태임을 확인할 수 있다. 따라서, 본 음성 어시스턴트 빅스비는, 타 음성 어시스턴트의 서비스 결과 즉, 로그인이 필요한 상태와 자신의 시뮬레이션 결과 즉, 이미 로그인이 된 상 태를 비교하고, 비교 결과에 따라 자신의 시뮬레이션 결과는 더 이상의 계정 로그인 작업이 필요없으므로, 자신 의 시뮬레이션 결과가 더 우수한 성능을 나타냄을 확인할 수 있다. 따라서, 본 음성 어시스턴트 빅스비는 사용 자에게 바로 해당 서비스가 제공가능함을 통지할 수 있다. 예를 들어, 본 음성 어시스턴트 빅스비는 “빅스비 입니다. 저는 이미 로그인 되어 있습니다. 바로 삼성 뮤직에서 최신곡 틀어드릴까요?”라는 가이드 음성을 출 력할 수 있다. 따라서, 이와 같은 실시예를 통해서, 본 음성 어시스턴트는 타 음성 어시스턴트가 서비스 제공에 반드시 실패한 경우 뿐만 아니라, 성공이나 성공에 유사한 결과를 내는 경우에도, 본 음성 어시스턴트의 시뮬레 이션 결과가 타 음성 어시스턴트의 서비스 결과보다 더 우수하다고 판단될 수 있는 경우, 자신이 서비스 제공가 능함을 사용자에게 통지함으로써, 사용자에게 더 퀄리티 좋은 서비스를 제공할 수 있다. 도 13은 일 실시예에 따라 사용자의 타 음성 어시스턴트에 대한 서비스 요청에 대해서 타 음성 어시스턴트의 서 비스 제공이 실패되고, 본 음성 어시스턴트에서 시뮬레이션 결과 성공한 경우, 사용자의 추후 서비스 제공 요청 이 있는 경우 사용자에게 통지를 제공하는 경우의 동작을 설명하기 위한 흐름도이다. 음성 인식 에이전트 211는 타 음성 어시스턴트 트리거 워드를 수신하는 동작 1301에서부터 실행 관리 모듈 216 이 음성 인식 에이전트 211로부터 수신한 작업 룰에 따라 하나 이상의 어플리케이션을 실행함으로써 작업 룰에 정의된 동작을 수행을 하고, 어플리케이션 실행 결과 또는 동작 수행 결과를 음성 인식 에이전트 211로 제공하 는 동작 1316 까지는 도 11에 도시된 대응되는 동작과 동일하므로 그에 대한 설명은 생략한다. 동작 1317에서, 음성 인식 에이전트 211는 실행 관리 모듈 216으로부터 수신한 동작 수행 결과를 분석하여, 사 용자의 발화 내용에 대응하는 동작이 제대로 수행되었는지, 즉, 사용자의 발화 내용에 대응하는 서비스의 제공 을 위한 동작이 수행가능한지 여부를 판단할 수 있다. 이때 음성 인식 에이전트 211이 사용자의 발화 내용에 대응하는 동작 수행을 시뮬레이션 해 본 결과, 동작 성공으로 판단된 경우, 음성 인식 에이전트 211는 해당 서 비스를 본 음성 어시스턴트에서 제공가능함을 나타내는 통지를 사용자에게 출력할 수 있는데, 이러한 통지의 출 력 시점은 다양하게 결정될 수 있다. 예를 들어, 타 음성 어시스턴트에서 제공이 실패되었던 서비스를 본 음성 어시스턴트에서 제공가능함을 나타내는 통지는 추후에 사용자로부터 다른 임의의 서비스 요청이 수신되었을 때 출력될 수 있다. 예를 들어, 서비스 내용이 현재 시간이나 현재 장소와 밀접하게 관련된 것이 아니어서 서비스 제공가능함을 나타내는 통지를 추후에 사용자에게 알려주어도 사용자에게 도움이 될 수 있는 경우, 음성 인식 에이전트 211는 서비스 통지를 추후에 출력하는 것으로 결정할 수 있다. 즉, 음성 인식 에이전트 211는 현재 타 음성 어시스턴트가 제공하는 데에 실패했던 서비스를 본 음성 어시스턴트에서 제공가능함을 나타내는 통지를 추후 사용자의 서비스 요청이 있을 때 추가적인 가이드로 출력하려는 스케쥴을 기억할 수 있다. 소정 시간이 경과한 후에 동작 1318에서 음성 인식 에이전트 21는 사용자로부터 본 음성 어시스턴트를 호출하는 트리거 워드를 수신할 수 있다. 동작 1319에서 음성 인식 에이전트 211는 본 음성 어시스턴트 트리거워드를 인식하는데 성공하고, 사용자 발화 를 기다리는 리스닝 상태로 진입할 수 있다. 동작 1320에서 음성 인식 에이전트 211가 서비스를 요청하는 사용자의 발화를 수신하면, 동작 1321에서 음성 인 식 에이전트 211는 사용자의 발화 내용을 자동 음성 인식 모듈 221로 제공하고, 동작 1322에서 자동 음성 인식 모듈 221은 수신된 사용자의 발화 내용에 대응하는 음성을 텍스트로 변환하여 발화 내용분석 모듈 222로 제공한 다. 동작 1323에서 발화 내용 분석 모듈 222는 수신된 사용자의 발화 내용에 대응하는 텍스트 데이터를 기초로 사용 자의 의도를 분석하고 사용자의 의도에 대응하여 동작되어야 하는 작업 룰을 결정하며, 결정된 작업 룰을 음성 인식 에이전트 211로 제공할 수 있다. 동작 1324에서, 음성 인식 에이전트 211는 발화 내용 분석 모듈 222로부터 수신된 작업 룰을 실행 관리 모듈 216로 제공하면, 동작 1325에서, 실행 관리 모듈 216은 음성 인식 에이전트 211로부터 수신한 작업 룰에 따라 하나 이상의 어플리케이션을 실행함으로써 작업 룰에 정의된 동작을 수행을 하고, 어플리케이션 실행 결과 또는 동작 수행 결과를 음성 인식 에이전트 211로 제공할 수 있다. 동작 1326에서, 음성 인식 에이전트 211는 실행 관리 모듈 216으로부터 수신한 동작 수행 결과를 분석하여, 사 용자의 발화 내용에 대응하는 동작이 제대로 수행되었으면, 즉, 사용자의 발화 내용에 대응하는 서비스의 제공 을 위한 동작이 성공적으로 수행되었으면 수행된 동작 결과를 사용자에게 출력할 수 있다. 그리고 나서 동작 1327에서, 음성 인식 에이전트 211는 이전에 기억해두었던 통지 즉, 타 음성 어시스턴트에서 실패했던 서비스를 본 음성 어시스턴트에서 제공가능함을 나타내는 통지를 사용자에게 추가적으로 출력할 수 있 다. 이를 위해 동작 1327에서 음성 인식 에이전트 211는 사용자에게 통지할 내용에 대한 텍스트를 결정하여 텍 스트 음성 변환 모듈 226으로 제공할 수 있다. 동작 1328에서, 텍스트 음성 변환 모듈 226은 음성 인식 에이전트 211로부터 수신한 텍스트를 음성으로 변환하 고 이를 음성 인식 에이전트 211로 제공하면, 동작 1329에서, 음성 인식 에이전트 211는 수신된 음성을 사용자 에게 출력할 수 있다. 동작 1327과 동작 1328은 동작 1317에 이어서 수행되어 미리 통지할 내용에 대한 음성 변환을 수행해놓고 변환 된 음성 데이터를 음성 인식 에이전트 211가 저장해놓고, 동작 1326을 수행한 후 바로 추가적인 가이드를 출력 할 수도 있을 것이다. 도 14는 일 실시예에 따라 도 13에 도시된 동작의 상황을 나타내기 위한 참고도이다. 도 14를 참조하면, 사용자는 타 음성 어시스턴트 시리우스에게 서비스 요청을 위해 “하이, 시리우스! 강남역 근처의 맛집 알려줘!”라는 발화를 할 수 있다. 그런데 이러한 사용자의 서비스 요청에 대해서 타 음성 어시스턴트 시리우스는 통신상의 문제 또는 여러가지 원 인으로 인해 서비스 제공에 실패하고 “죄송합니다. 지금 처리가 어렵습니다” 라는 음성 반응을 출력할 수 있 다. 본 음성 어시스턴트 빅스비는 이와 같이 타 음성 어시스턴트에 대해서 서비스 요청을 위한 사용자의 발화 내용 과 이러한 서비스 요청에 대한 타 음성 어시스턴트의 음성 반응을 인식하고 분석함으로써, 타 음성 어시스턴트 시리우스가 사용자에 의해 요청된 서비스 제공에 실패한 것으로 판단할 수 있다. 그리고 이와 같이 타 음성 어 시스턴트가 서비스 제공에 실패한 것으로 판단된 경우, 본 음성 어시스턴트 빅스비는 타 음성 어시스턴트가 제 공에 실패했던 서비스 동작 즉 “강남역 근처의 맛집 알려줘”에 대응하는 동작이 수행가능한지 시뮬레이션 해 보고, 만약 수행가능하다면 사용자에게 해당 서비스가 제공가능함을 나타내는 통지를 저장해둘 수 있다. 그리고 나서, 추후 사용자가 본 음성 어시스턴트 빅스비에게 “하이 빅스비! 내일 날씨 알려줘!”라는 서비스 요청 발 화를 하면, 본 음성 어시스턴트 빅스비는, 날씨 어플리케이션 등을 검색하여 내일 날씨를 확인하는 동작을 수행 하고, 동작 수행 결과, 예를 들어, “네, 내일 날씨는 따뜻하고 맑습니다.” 라는 응답 음성을 출력할 수 있다. 또한 본 음성 어시스턴트 빅스비는 저장해두었던 통지, 예를 들어, “강남역 근처의 맛집도 알려드릴까요?” 라 는 가이드 음성을 출력할 수 있다. 어떤 임의의 장소에 기반한 정보 제공은 통상적으로는 시간과 밀접한 관련 은 없으므로, 이와 같은 서비스는 사용자가 애초에 요청했던 시간이 아니라 시간차를 두고 서비스 제공되어도 사용자게 유익할 경우가 많이 있기 때문에, 이와 같은 경우 추가적인 가이드로서 통지를 출력하는 것이 사용자에게 의미가 있을 수 있다. 이와 같이 추가적인 가이드를 제공함으로써, 사용자는 자신이 이전에 제공받기를 실패했던 서비스에 대해서 재차 문의하거나 요청하는 것 없이 음성 어시스턴트에서 가이드를 제공받을 수 있으 므로 사용자의 편의성을 증대시킬 수 있다. 도 15는 일 실시예에 따라 사용자의 타 음성 어시스턴트에 대한 서비스 요청에 대해서 타 음성 어시스턴트의 서 비스 제공이 실패되고, 본 음성 어시스턴트에서 시뮬레이션 결과도 실패한 경우의 후속 동작을 설명하기 위한 흐름도이다. 음성 인식 에이전트 211가 타 음성 어시스턴트 트리거 워드를 수신하는 동작 1501에서부터 실행 관리 모듈 216 이 음성 인식 에이전트 211로부터 수신한 작업 룰에 따라 하나 이상의 어플리케이션을 실행함으로써 작업 룰에 정의된 동작을 수행을 하고, 어플리케이션 실행 결과 또는 동작 수행 결과를 음성 인식 에이전트 211로 제공하 는 동작 1516 까지는 도 11에 도시된 대응되는 동작과 동일하므로 그에 대한 설명은 생략한다. 동작 1517에서, 음성 인식 에이전트 211는 실행 관리 모듈 216으로부터 수신한 동작 수행 결과를 분석하여, 사 용자의 발화 내용에 대응하는 동작이 제대로 수행되었는지, 즉, 사용자의 발화 내용에 대응하는 서비스의 제공 을 위한 동작이 수행가능한지 여부를 판단할 수 있다. 이때 음성 인식 에이전트 211이 사용자의 발화 내용에 대응하는 동작 수행을 시뮬레이션 해 본 결과, 동작 실패로 판단된 경우, 음성 인식 에이전트 211는 동작 실패 의 원인을 분석할 수 있다. 음성 인식 에이전트 211는 동작 실패의 원인 분석 결과, 동작 실패의 원인이 음성 인식이나 의도 분석에 오류가 있는 것으로 판단된 경우, 동작 1518에서 음성 인식 에이전트 211는 자동음성 인식 모듈 221로 학습 지시를 전 달하거나, 동작 1519에서 발화 내용 분석 모듈 222로 학습 지시를 전달할 수 있다. 이와 같은 학습 지시를 수 신한 자동 음성 인식 모듈 221 이나 발화 내용 분석 모듈 222는 내부의 하나 이상의 모듈들에 대해 언어/음향 모델, 임계치 설정 기준, 후보 선정 기준 등 요소별로 학습 및 업데이트를 진행할 수 있다. 이와 같이 타 음성 어시스턴트가 제공을 실패한 서비스에 대해서 본 음성 어시스턴트도 시뮬레이션 결과 동작 실패인 경우라도, 본 음성 어시스턴트는 이 실패 원인에 따라 자동 음성 인식 모듈이나 발화 내용 분석 모듈의 학습이나 업데이트의 기초로 삼을 수 있으므로, 본 음성 어시스턴트의 성능을 향상시킬 수 있다. 도 16은 일 실시예에 따라 사용자의 타 음성 어시스턴트에 대한 서비스 요청에 대해서 타 음성 어시스턴트의 서 비스 제공이 실패되고, 본 음성 어시스턴트에서 시뮬레이션 결과도 실패한 경우의 후속 동작을 설명하기 위한 흐름도이다. 음성 인식 에이전트 211가 타 음성 어시스턴트 트리거 워드를 수신하는 동작 1601에서부터 실행 관리 모듈 216 이 음성 인식 에이전트 211로부터 수신한 작업 룰에 따라 하나 이상의 어플리케이션을 실행함으로써 작업 룰에 정의된 동작을 수행을 하고, 어플리케이션 실행 결과 또는 동작 수행 결과를 음성 인식 에이전트 211로 제공하 는 동작 1616 까지는 도 11에 도시된 대응되는 동작과 동일하므로 그에 대한 설명은 생략한다. 동작 1617에서, 음성 인식 에이전트 211는 실행 관리 모듈 216으로부터 수신한 동작 수행 결과를 분석하여, 사 용자의 발화 내용에 대응하는 동작이 제대로 수행되었는지, 즉, 사용자의 발화 내용에 대응하는 서비스의 제공 을 위한 동작이 수행가능한지 여부를 판단할 수 있다. 이때 음성 인식 에이전트 211이 사용자의 발화 내용에 대응하는 동작 수행을 시뮬레이션 해 본 결과, 동작 실패로 판단된 경우, 음성 인식 에이전트 211는 동작 실패 의 원인을 분석할 수 있다. 음성 인식 에이전트 211는 동작 실패의 원인 분석 결과, 동작 실패의 원인이 사용 자의 요청에 대응하는 기능이나 서비스가 본 음성 어시스턴트에 부재하거나 이용가능하지 않은 것에 기인한 것으로 판단할 수 있다. 일 실시예에 따라 동작 1618에서, 음성 인식 에이전트 211는 현재 본 음성 어시스턴트에서 부재하거나 이용가능 하지 않은 기능 이나 서비스를 제공하는 서버 1600를 검색하고, 검색된 서버 1600로 해당 기능이나 서비스 제공 요청을 전달할 수 있다. 동작 1619에서, 음성 인식 에이전트 211는 기능/서비스 제공 서버 1600에서 요청한 기능이나 서비스에 대응하는 소프트웨어 모듈을 다운로드받거나 또는 소프트웨어 업데이트 버전을 다운로드받고 해당 모듈을 설치하거나 또 는 소프트웨어 업데이트에 이용할 수 있다. 만약 기능/서비스 제공 서버1600에서 요청한 기능이나 소프트웨어를 획득할 수 없는 경우 기능/서비스 제공 서 버 1600에 해당 기능이나 서비스가 본 컴퓨팅 장치에서 필요한 기능/서비스 임을 등록해둘 수 있다. 또한 현재 기능/서비스 제공 서버1600에서 요청한 기능이나 소프트웨어를 획득할 수 없는 경우, 음성 인식 에이 전트 211는 해당 기능이나 서비스를 기능 개선 항목으로 기록해두어 관리할 수 있다. 또한, 음성 인식 에이전트 211는 기능/서비스 제공 서버에 요청한 기능이나 소프트웨어를 조회한 결과 현재는 획득할 수 없지만, 추후 어느 시점에 이용가능한지 또는 업데이트가능한지에 대한 정보를 수신한 경우, 이러한 기능이나 서비스에 대해서, 이용가능한 시점 또는 업데이트가능한 시점에 대한 정보를 발화 내용 분석 모듈 222 의 대화 시스템에 저장해두고, 추후 사용자가 이러한 기능이나 서비스를 요청한 경우, 이용가능한 시점이나 업 데이트가능한 시점에 대한 정보를 제공할 수 있다. 예를 들어, 본 음성 어시스턴트에서 현재 이용가능하지 않 은 서비스에 대해서, 사용자로부터 요청이 있는 경우, 본 음성 어시스턴트는 단지 “현재 서비스할 수 없는 기 능입니다” 라고만 반응하는 대신에 “해당 서비스는 다음달에 이용가능합니다. 양해 부탁드립니다.” 와 같이 사용자가 요청한 서비스를 이용가능한 시점에 대한 통지를 사용자에게 제공함으로써, 사용자에게 단순히 서비스 불능임을 통지하는 것보다 보다 많은 정보를 제공함으로써 사용자로 하여금 해당 서비스에 예측을 가능하게 함 으로써 사용자 편의성을 증대시킬 수 있다. 일부 실시예는 컴퓨터에 의해 실행되는 프로그램 모듈과 같은 컴퓨터에 의해 실행가능한 명령어를 포함하는 기 록 매체의 형태로도 구현될 수 있다. 컴퓨터 판독 가능 매체는 컴퓨터에 의해 액세스될 수 있는 임의의 가용 매 체일 수 있고, 휘발성 및 비휘발성 매체, 분리형 및 비분리형 매체를 모두 포함한다. 또한, 컴퓨터 판독가능 매 체는 컴퓨터 저장 매체를 포함할 수 있다. 컴퓨터 저장 매체는 컴퓨터 판독가능 명령어, 데이터 구조, 프로그램 모듈 또는 기타 데이터와 같은 정보의 저장을 위한 임의의 방법 또는 기술로 구현된 휘발성 및 비휘발성, 분리 형 및 비분리형 매체를 모두 포함한다. 개시된 실시예들은 컴퓨터로 읽을 수 있는 저장 매체(computer-readable storage media)에 저장된 명령어를 포 함하는 S/W 프로그램으로 구현될 수 있다. 컴퓨터는, 저장 매체로부터 저장된 명령어를 호출하고, 호출된 명령어에 따라 개시된 실시예에 따른 동작이 가 능한 장치로서, 개시된 실시예들에 따른 전자 장치를 포함할 수 있다. 컴퓨터로 읽을 수 있는 저장매체는, 비일시적(non-transitory) 저장매체의 형태로 제공될 수 있다. 여기서,‘비 일시적’은 저장매체가 신호(signal)를 포함하지 않으며 실재(tangible)한다는 것을 의미할 뿐 데이터가 저장매 체에 반영구적 또는 임시적으로 저장됨을 구분하지 않는다. 또한, 개시된 실시예들에 따른 제어 방법은 컴퓨터 프로그램 제품(computer program product)에 포함되어 제공 될 수 있다. 컴퓨터 프로그램 제품은 상품으로서 판매자 및 구매자 간에 거래될 수 있다. 컴퓨터 프로그램 제품은 S/W 프로그램, S/W 프로그램이 저장된 컴퓨터로 읽을 수 있는 저장 매체를 포함할 수 있다. 예를 들어, 컴퓨터 프로그램 제품은 디바이스의 제조사 또는 전자 마켓(예, 구글 플레이 스토어, 앱 스토 어)을 통해 전자적으로 배포되는 S/W 프로그램 형태의 상품(예, 다운로더블 앱)을 포함할 수 있다. 전자적 배포 를 위하여, S/W 프로그램의 적어도 일부는 저장 매체에 저장되거나, 임시적으로 생성될 수 있다. 이 경우, 저장 매체는 제조사의 서버, 전자 마켓의 서버, 또는 SW 프로그램을 임시적으로 저장하는 중계 서버의 저장매체가 될 수 있다. 컴퓨터 프로그램 제품은, 서버 및 디바이스로 구성되는 시스템에서, 서버의 저장매체 또는 디바이스의 저장매체 를 포함할 수 있다. 또는, 서버 또는 디바이스와 통신 연결되는 제 3 장치(예, 스마트폰)가 존재하는 경우, 컴 퓨터 프로그램 제품은 제 3 장치의 저장매체를 포함할 수 있다. 또는, 컴퓨터 프로그램 제품은 서버로부터 디바 이스 또는 제 3 장치로 전송되거나, 제 3 장치로부터 디바이스로 전송되는 S/W 프로그램 자체를 포함할 수 있다. 이 경우, 서버, 디바이스 및 제 3 장치 중 하나가 컴퓨터 프로그램 제품을 실행하여 개시된 실시예들에 따른 방 법을 수행할 수 있다. 또는, 서버, 디바이스 및 제 3 장치 중 둘 이상이 컴퓨터 프로그램 제품을 실행하여 개시 된 실시예들에 따른 방법을 분산하여 실시할 수 있다. 예를 들면, 서버(예로, 클라우드 서버 또는 인공 지능 서버 등)가 서버에 저장된 컴퓨터 프로그램 제품을 실행 하여, 서버와 통신 연결된 디바이스가 개시된 실시예들에 따른 방법을 수행하도록 제어할 수 있다. 또 다른 예로, 제 3 장치가 컴퓨터 프로그램 제품을 실행하여, 제 3 장치와 통신 연결된 디바이스가 개시된 실 시예에 따른 방법을 수행하도록 제어할 수 있다. 제 3 장치가 컴퓨터 프로그램 제품을 실행하는 경우, 제 3 장 치는 서버로부터 컴퓨터 프로그램 제품을 다운로드하고, 다운로드 된 컴퓨터 프로그램 제품을 실행할 수 있다.또는, 제 3 장치는 프리로드 된 상태로 제공된 컴퓨터 프로그램 제품을 실행하여 개시된 실시예들에 따른 방법 을 수행할 수도 있다. 또한, 본 명세서에서, \"부\"는 프로세서 또는 회로와 같은 하드웨어 구성(hardware component), 및/또는 프로세 서와 같은 하드웨어 구성에 의해 실행되는 소프트웨어 구성(software component)일 수 있다."}
{"patent_id": "10-2019-0171032", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "전술한 본 개시의 설명은 예시를 위한 것이며, 본 개시가 속하는 기술분야의 통상의 지식을 가진 자는 본 개시 의 기술적 사상이나 필수적인 특징을 변경하지 않고서 다른 구체적인 형태로 쉽게 변형이 가능하다는 것을 이해 할 수 있을 것이다. 그러므로 이상에서 기술한 실시예들은 모든 면에서 예시적인 것이며 한정적이 아닌 것으로 이해해야만 한다. 예를 들어, 단일형으로 설명되어 있는 각 구성 요소는 분산되어 실시될 수도 있으며, 마찬가 지로 분산된 것으로 설명되어 있는 구성 요소들도 결합된 형태로 실시될 수 있다. 본 개시의 범위는 상기 상세한 설명보다는 후술하는 특허청구범위에 의하여 나타내어지며, 특허청구범위의 의미 및 범위 그리고 그 균등 개념으로부터 도출되는 모든 변경 또는 변형된 형태가 본 개시의 범위에 포함되는 것으 로 해석되어야 한다.도면 도면1 도면2a 도면2b 도면3 도면4 도면5 도면6 도면7 도면8 도면9 도면10 도면11 도면12a 도면12b 도면13 도면14 도면15 도면16 도면17"}
{"patent_id": "10-2019-0171032", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 다양한 실시예들에 따라 음성 어시스턴트 기능을 개선하기 위한 시스템의 개념을 설명하기 위한 참고도 이다. 도 2a는 일 실시 예에 따라 음성 어시스턴트가 구현된 컴퓨팅 장치의 일 예를 나타낸다. 도 2b는 일 실시 예에 따라 음성 어시스턴트가 구현된 컴퓨팅 장치의 다른 예를 나타낸다. 도 3은 일 실시 예에 따라 음성 어시스턴트가 구현된 컴퓨팅 장치의 다른 예를 나타낸다. 도 4는 일 실시예에 따라 음성 어시스턴트가 설치되는 다양한 형태를 설명하기 위한 참고도이다. 도 5 및 도 6은 실시예들에 따라 음성 어시스턴트를 포함하는 컴퓨팅 장치에서의 동작 방법의 일 예를 나타내는 흐름도이다. 도 7은 일 실시예에 따라 컴퓨팅 장치 100에서 타 음성 어시스턴트 트리거 워드의 인식을 실패한 경우의 동작을 설명하기 위한 흐름도이다. 도 8은 타 음성 어시스턴트 트리거 워드의 인식을 실패한 경우의 상황을 나타내는 참고도이다. 도 9는 일 실시예에 따라 사용자의 타 음성 어시스턴트 트리거 워드 발화후 타 음성 어시스턴트에서 반응이 없 는 경우의 동작을 설명하기 위한 흐름도이다. 도 10은 타 음성 어시스턴트로부터 트리거 워드에 대한 반응이 없는 경우의 상황을 나타내는 참고도이다. 도 11은 일 실시예에 따라 사용자의 타 음성 어시스턴트에 대한 서비스 요청에 대해서 타 음성 어시스턴트의 서 비스 제공이 실패되고, 본 음성 어시스턴트에서 시뮬레이션 결과 성공한 경우 실시간으로 사용자에게 통지를 제 공하는 경우의 동작을 설명하기 위한 흐름도이다. 도 12a는 일 실시예에 따라 도 11에 도시된 동작의 상황을 나타내기 위한 참고도이다. 도 12b는 일 실시예에 따라 타 음성 어시스턴트의 서비스 결과와 본 음성 어시스턴트의 시뮬레이션 결과를 비교 해보고, 비교 결과 본 음성 어시스턴트의 시뮬레이션 결과에 따라 서비스 제공가능함을 나타내기 통지를 출력하 는 상황을 설명하기 위한 참고도이다. 도 13은 일 실시예에 따라 사용자의 타 음성 어시스턴트에 대한 서비스 요청에 대해서 타 음성 어시스턴트의 서 비스 제공이 실패되고, 본 음성 어시스턴트에서 시뮬레이션 결과 성공한 경우 사용자의 요청에 기반하여 사용자 에게 통지를 제공하는 경우의 동작을 설명하기 위한 흐름도이다. 도 14는 일 실시예에 따라 사용자에게 통지를 사용자의 요청에 기반하여 제공하는 경우의 상황을 설명하기 위한 참고도이다. 도 15는 일 실시예에 따라 사용자의 타 음성 어시스턴트에 대한 서비스 요청에 대해서 타 음성 어시스턴트의 서 비스 제공이 실패되고, 본 음성 어시스턴트에서 시뮬레이션 결과 실패한 경우의 동작의 일 예를 설명하기 위한 흐름도이다. 도 16은 일 실시예에 따라 사용자의 타 음성 어시스턴트에 대한 서비스 요청에 대해서 타 음성 어시스턴트의 서 비스 제공이 실패되고, 본 음성 어시스턴트에서 시뮬레이션 결과 실패한 경우의 동작의 다른 예를 설명하기 위 한 흐름도이다. 도 17는 일 실시예에 따라 텍스트 분석을 수행하는 경우의 화면의 일 예를 나타낸다."}
