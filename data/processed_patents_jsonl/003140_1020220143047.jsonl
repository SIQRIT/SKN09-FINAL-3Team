{"patent_id": "10-2022-0143047", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0061407", "출원번호": "10-2022-0143047", "발명의 명칭": "고화질 동영상으로부터 효율적으로 배경을 제거하기 위한 인공지능 기술 기반의 고해상도 배", "출원인": "(주)비타소프트", "발명자": "홍순기"}}
{"patent_id": "10-2022-0143047", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "원시 동영상으로부터 다수의 프레임 이미지를 추출하는 프레임 추출단계와, 추출된 프레임 이미지에 대해서 인공지능 알고리즘으로 배경을 분리하는 배경 분리단계와, 배경 분리된 프레임 이미지를 합하여 배경 분리된 목적동영상을 생성하는 단계를 포함하는 인공지능 기술을 기반하여 동영상에서 배경을 제거하는 방법에 있어서, 상기 원시 동영상으로부터 추출한 다수의 연속 프레임 이미지에 대해서 객체 인식 신경망 모델을 기반으로 객체들을 인식하는 자동 인식하고, 객체 인식 신경망 모델이 인식한 객체들을 화면에 표시하여 사용자가 필요한 객체를 선택하도록 하는 객체 선택 단계와, 사용자가 객체를 선택하면, 상기 다수의 연속 프레임을 순차적으로 바꾸어 가며 해당 프레임 내에서 선택한 객체만을 연속적으로 트래킹하며, 배경 제거 인공지능 모델에 의해 해당 객체 선택 영역에서 배경을 제거하는 배경 제거 단계와, 배경 제거된 연속 프레임 이미지를 결합하여 동영상을 생성하는 동영상 생성 단계를 포함하는 것을 특징으로 하는 인공지능 기술을 기반하여 동영상에서 배경을 제거하는 방법"}
{"patent_id": "10-2022-0143047", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 객체 선택 단계에서 제시되는 객체 인식 영역은 세그멘테이션(Segmentation) 형식으로 동일 객체의 외관을따라 다각형으로 선택 표시하는 것을 특징으로 하는 인공지능 기술을 기반하여 동영상에서 배경을 제거하는 방법"}
{"patent_id": "10-2022-0143047", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 객체 선택 단계에서 제시되는 객체 인식 영역은 개별 객체(인스턴스)의 변화 속도를 기준으로 구분되어 선택할 수 있도록 표시하는 것을 특징으로 하는 인공지능 기술을 기반하여 동영상에서 배경을 제거하는 방법"}
{"patent_id": "10-2022-0143047", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항 내지 제3항 중 어느 한 항에 있어서,상기 객체 선택 단계에서 객체 선택 단계에서는 객체의 인식 여부와 관계 없이 임의의 영역을 지정하여 선택하는 단계를 포함하고 있는 것을 특징으로 하는 인공지능 기술을 기반하여 동영상에서 배경을 제거하는 방법"}
{"patent_id": "10-2022-0143047", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명에 따르면, 원시 동영상으로부터 다수의 프레임 이미지를 추출하는 프레임 추출단계와, 추출된 프레임 이 미지에 대해서 인공지능 알고리즘으로 배경을 분리하는 배경 분리단계와, 배경 분리된 프레임 이미지를 합하여 배경 분리된 목적 동영상을 생성하는 단계를 포함하는 인공지능 기술을 기반하여 동영상에서 배경을 제거하는 방 (뒷면에 계속)"}
{"patent_id": "10-2022-0143047", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 2개 이상의 객체를 포함한 디지털 이미지 또는 디지털 동영상 이미지로부터 배경 이미지를 제거하고 필요한 전경 이미지 객체만을 온전히 추출하기 위한 영상 처리 프로그램의 소프트웨어 기술에 대한 것이며, 특 히 딥러닝 기반의 인공지능 기술로 동영상으로부터 남겨야 할 필요한 객체를 지정하고 높은 해상도로 불필요한 배경을 제거하기 위한 소프트웨어 기술에 대한 것이다."}
{"patent_id": "10-2022-0143047", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "종래에는 동영상 또는 이미지로부터 배경을 제거하고 그 배경을 다른 배경과 합성하기 위한 기술에 대한 요구가 높다. 방송용, 영화 제작용 등 이외에도, 홀로그램 장치용 콘텐츠 제작, 투명 디스플레이용 콘텐츠 제작 등에서도 많 이 필요하며, 최근에는 다양한 메타버스 콘텐츠를 제작하기 위해 2D 이미지 촬영부터 배경 제거 후 3D 모델을 제작 하는 등의 경우에 많이 사용된다. 배경 제거 요구를 쉽게 구현하기 위해서 많이 사용하는 종래의 방법은 크로마키(Chroma Key) 촬영기법이며, 이 기법에 따르면 전경(추출해야 할 객체)의 뒤쪽에 특정 색상(일반적으로는 푸른색 블루스크린)을 배경을 두고 촬 영한 후에, 촬영된 영상에서 배경 색상을 전체적으로 제거하여 전경 영상을 추출하는 기법이다. 그러나, 자연 상태 등에서 촬영한 이미지의 경우, 배경은 다양한 색상을 가지게 되므로, 일괄적으로 제거하기 위해서는 특별한 기법이 필요하다. 인공지능 기술이 발전한 최근에는 이미지와 해당 이미지에서 배경을 제거한 이미지를 세트로 다량의 학습 이미 지를 제작하고 이 학습 이미지를 학습하는 방법을 통해, 높은 해상도의 이미지에서도 전경과 배경을 비교적 잘 분리하고 있다. 도 1은 종래의 학습 데이터 세트(원본 이미지와 GT: Ground Truth 이미지)의 예를 보여 준다. 선행기술문헌 특허문헌 (특허문헌 0001) 한국등록특허공보 제10-2015939호, 2019.08.28. 비특허문헌 (비특허문헌 0001) Highly Accurate Dichotomous Image Segmentation (2022.Mar.06) (비특허문헌 0002) https://arxiv.org/abs/2203.03041"}
{"patent_id": "10-2022-0143047", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "최근에 인공지능 기술의 발전으로 배경 이미지를 제거하는 좋은 기술들이 많이 공개되고 있다. 최근 최고 성능 (SOTA)로 알려진 알로리즘으로는 IS-NET 등의 알고리즘이 있고 기본적으로 제공하는 성능도 매우 높은 편이다. 그러나, 이러한 알로리즘의 경우에도 어플리케이션 형식으로 적용하려면, 하나의 이미지의 여러 개의 객체가 포 함된 경우, 어떤 객체까지를 전경으로 분리하고, 어떤 객체까지를 배경으로 분리할 것인가의 문제가 여전히 남 는다. 예를 들면, 도면 2에 도시한 이미지에서, 전경은 '새'만 선택할 것인지, 새가 앉은 '가지'까지일까? 그것은 배 경 제거된 동영상을 사용할 사용자가 선택할 것이다. 일반적으로 동영상의 경우, 다수의 프레임으로 분리한 후에, 분리된 이미지 각각에서 배경을 제거하는 일을 반 복하고, 배경이 모두 제거된 프레임을 다시 모아서, 동영상을 만들는 과정을 거치기 된다. 따라서, 각각의 프레 임에 대해 반복된 작업을 하려면 많은 시간과 노력이 필요하다. 특히, 털이 많은 동물, 그물 등의 경우 처러 난 이도가 높은 경우에는 너무 많은 시간이 필요하다. 본 발명의 기술적 과제는 동영상 이미지에서 배경 분리를 분리할 때, 객체 인식(Object Detection)기술을 활용 하여 전경의 객체들을 식별하여 필요한 객체를 선택하도록 하고, 사용자가 객체를 선택하면 선택된 객체만을 트래킹하면서 경계면에서의 정밀한 분리 실행할 수 있도록 하는 기술을 제공하는 것이다. 이러한 과제를 제공함으로써, 사용자가 전경을 지정하면 해당 전경만을 높은 정밀도 분리해내 배경 제거 과정을 간단히 할 수 있게 되었다."}
{"patent_id": "10-2022-0143047", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명은 전술한 과제를 해결하기 위해서, 원시 동영상으로부터 다수의 프레임 이미지를 추출하는 프레임 추출단계와, 추출된 프레임 이미지에 대해서 인 공지능 알고리즘으로 배경을 분리하는 배경 분리단계와, 배경 분리된 프레임 이미지를 합하여 배경 분리된 목적 동영상을 생성하는 단계를 포함하는 인공지능 기술을 기반하여 동영상에서 배경을 제거하는 방법에 있어서, 상 기 원시 동영상으로부터 추출한 다수의 연속 프레임 이미지에 대해서 객체 인식 신경망 모델을 기반으로 객체들 을 인식하는 자동 인식하고, 객체 인식 신경망 모델이 인식한 객체들을 화면에 표시하여 사용자가 필요한 객체 를 선택하도록 하는 객체 선택 단계와, 사용자가 객체를 선택하면, 상기 다수의 연속 프레임을 순차적으로 바꾸 어 가며 해당 프레임 내에서 선택한 객체만을 연속적으로 트래킹하며, 배경 제거 인공지능 모델에 의해 해당 객 체 선택 영역에서 배경을 제거하는 배경 제거 단계와, 배경 제거된 연속 프레임 이미지를 결합하여 동영상을 생 성하는 동영상 생성 단계를 포함하는 것을 특징으로 하는 인공지능 기술을 기반하여 동영상에서 배경을 제거하 는 방법을 제공한다. 또한, 상기 객체 선택 단계에서 제시되는 객체 인식 영역은 세그멘테이션(Segmentation) 형식으로 동일 객체의 외관을 따라 다각형으로 선택 표시하는 것이 바람직하다. 보다 정밀한 지정을 위해 폴리곤 형식으로 영역을 지 정할 수 있도록 할 필요할 수 있다. 또한, 상기 객체 선택 단계에서 제시되는 객체 인식 영역은 개별 객체(인스턴스)의 변화 속도를 기준으로 구분 되어 선택할 수 있도록 표시하는 것도 바람직하다. 필요에 따라 개별 인스턴스를 잘 분리해 표시할 수 있도록 할 수 있다. 특히, 상기 객체 선택 단계에서 객체 선택 단계에서는 객체의 인식 여부와 관계 없이 임의의 영역을 지정하여 선택하는 단계를 포함하고 있는 것이 더욱 바람직하다. 전경과 배경을 분리할 필요가 없거나, 특정 영역 전체를 선택하는 것이 더 좋다고 판단되는 경우, 사용자에게 그 영역을 전체 지정할 수 있도록 하기 위함이다."}
{"patent_id": "10-2022-0143047", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "전술한 발명을 제공함으로써, 여러 객체와 복잡한 배경 영상을 포함하는 디지털 동영상에서 필요한 객체만을 선 택하고자 할 때, 인공지능 기술을 이용하여 인식한 객체로부터 필요한 객체를 선택하고 지정하는 하는 것만으로, 쉽고 간단하게 높은 정밀도의 객체만을 분리해낸 배경 제거 동영상을 얻을 수 있다."}
{"patent_id": "10-2022-0143047", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하 본 발명의 상세한 내용을 실시예를 중심으로 설명하고자 한다. 도 5는 인공지능을 활용하여 2개 이상의 객체를 포함한 동영상으로부터 배경을 제거하는 과정을 도시한 순서도 이다. 단계 S1에서 사용자가 2개 이상의 객체가 포함된 사용자가 본 발명이 적용된 소프트웨어에서 원시 동영상을 지 정하면, 우선 소프트웨어는 지정한 동영상에서 다수의 프레임 이미지를 추출한다. 동영상에서 추출할 프레임은 특정하지 않으며, 원본 동영상의 FPS를 기준으로 모두 추출하여야 품질을 유지할 수 있다. 그 다음, 단계 S2에서 다수의 추출된 동영상 프레임 각각에 대해서, 인공지능 알고리즘을 적용하여 다수의 프레 임 이미지에 대해서 객체 인식을 실행한다. 이때, 사용될 인공지능 기반의 객체 인식의 알고리즘은 CNN 기술을 응용한 알고리즘이 보통 사용될 수 있으며, ResNet, DenseNet, EfficentNet 등의 객체 인식 알고리즘 중 어느 하나를 활용할 수 있다. 그외에 다양한 공개 된 객체 인식 알고리즘을 활용할 수 있다. 또한, 객체를 인식하는 방식은 인스턴스(instance) 별로 분리하여 적용하는 것이 더욱 바람직하다. 예를 들면, 여러 객체가 있는 경우, 동종 객체일지라도 인스턴스를 구분하여 적용하는 것이 적합하다. 나뭇가지가 여러개인 경우, 각각을 하나의 인스턴스로 구분 표시하여 사용자가 선택할 수 있도록 한다. 객체 또는 인스턴스를 구분할 때, 개별 객체의 이동 속도를 기준으로 객체를 구분하는 기법이 병행될 수 있다. 서로 다른 객체(또는 인스턴스)는 움직이는 속력과 방향이 다르다는 점을 활용하는 기법이다. 특히 비교적 고정 된 배경을 기준으로 전경의 변화가 큰 경우(카메라를 움직이는 경우를 포함) 배경을 분리해 낼 때 유용할 수 있 다. 다음 단계 S3에서, 사용자는 객체 인식 알고리즘에서 인식한 객체를 확인하고 전경으로 취득하고자 하는 객체를 선정한다. 이 과정은 제시된 인스턴스 들 중에 남겨야 할 것이 어떤 것인지를 지정하여 힌트(Hint)를 주는 것과 도 같다. 도 4 및 도 5는 객체 인식 알고리즘으로부터 자동 인식된 객체에 대해서 사용자가 필요한 객체를 선택하는 과정 을 보여주기 위한 도면이다. 사용자는 도 4에서처럼. 'A' 만을 선택할 수도 있고, 'A'와 'B'를 모두 선택할 수 도 있다. 또는 도면에 도시하지는 않았지만, 동영상의 진행 과정에서 다른 'C'가 등장할 수도 있다. 사용자는 프레임을 넘겨 가면서, A, B, C 등 전경으로 포함할 객체를 모두 선택할 수 있다. 객체가 움직일 수 있으므로, 객체의 위치는 프레임마다에서 매변 변경되며, 객체의 위치는 정보량을 적게 하기 위해서 바운딩 박스(Bounding Box)를사용하였지만, 세그멘테이션(segmentation)형식이 될 수도 있고, 다각형 (polygon)으로 객체의 윤곽을 따라 그려 선택하는 Segmentation 형식으로 지정될 수도 있다. 물론 동일유형의 객체를 모두 포함하여 선택하는 Sementic Segmentation일 수도 있고 객별 객체를 선택하도록 하는 Instance Segmentation 형식일 수도 있다. 바운딩 박스는 클릭 한 번과 드래그로 지정할 수 있다는 장점이 있고, 폴리곤 은 보다 세밀하게 영역을 지정할 수 있다는 장점이 있으므로, 두 가지를 모두 사용하여 선택 영역을 지정할 수 있도록 하는 것이 바람직하다. 다음으로 사용자가 선택한 객체(선택한 영역)에 대해서 배경 분리 알고리즘을 적용하여, 해당 객체를 포함한 영 역을 배경 분리 알고리즘으로 전달하여 배경과 전경을 정밀 분리하여야 한다. . 단계 S4에서 사용자가 선택한 객체의 영역(남겨질 영역)을 배경 분리 알고리즘으로 전달한다. 사용자가 배경 제 거 알고리즘으로 전달할 선택 영역 정보의 형식은 다수의 위치 정보(XY 좌표, 픽셀)로 직선 연결하여 정해지는 다각형(polygon) 영역이지만, 전달되는 선택 영역의 정보 형식은 바운딩 빅스(Bounding Box) 형식의 4개 좌표 정보의 결합의 형식이거나, 또는 세그멘테이션 Segmentation 형식의 폴리곤 정보의 어느 한가지 일 수 있다. 데 이터는 프레임 이미지 별로 선택 영역의 정보가 전달된다. 도 6은 선택 영역을 지정하는 다른 방식으로, 이미지 중의 임의의 영역 전체를 선택하여 전경 영역(남겨야 할 영역)으로 선택하는 도구의 작동 원리를 보여주기 위한 것이다. 하단의 'E'로 표시한 영역은 그 특징상 전경과 배경의 분리 난이도가 높은 영역이고 전경과 배경이 가까이 배치되어 있어 하나로 묶어 남겨지는 것이 보다 자 연 스러운 경우이다. 이런 경우를 지정하기 위해 임의의 영역을 지정하여 남겨야 할 영역으로 선택할 수 있도록 한다. 단계 S5에서 배경 제거 알고리즘은 프레임 이미지 별로 전달된 선택 영역의 정보를 영역을 잡아 해당 영역 내 에서 전경과 배경을 분리한다. 즉, 배경을 제거하고 남겨질 영역을 채택한다. 선택 영역 이외의 영역에 대해서는 배경으로 취급하여 모두 삭제 처리한다. 이러한 과정을 거치고 나면, 배경제거 전용 알고리즘에 의해 프레임 이미지 각각에 대한 배경 제거가 이루어진 다. 프레임 이미지의 사용자가 지정한 영역 내의 객체는 트래킹 되면서, 프레임 이미지를 넘겨 가면서 연속 지정되 고, 프레임 이미지 마다에 대해서 트래킹된 객체 영역을 지정하기 위한 폴리곤 형식의 포인트 연결 영역 내부의 정보는 배경 제거 알고리즘으로 전달된다. 배경 제거 알고리즘은 전달된 영역 내의 이미지에 대해서 전경과 배경을 분리하면서 배경을 제거하는 제거 작업 을 실행한다. 배경 제거 알고리즘으로는 현존 최고 성능으로 알려진 'IS-NET' 같은 알고리즘이 활용할 수 있다. 다수의 프레임 이미지에 대해서 배경 제거가 이루어지고 나면, 단계 S6에서 배경 제거된 다수의 프레임 이미지 는 개별 프레임 이미지로 저장되어 검수 단게를 거치게 된다. 이후, 검수를 마친 후에, 만족스러운 수준이 되면, 사용자는 최종 결과를 요구하고 그에 따라 단계 S7에서 다수의 프레임 이미지는 하나의 동영상으로 결합 된다, 동영상 결합 단계에서는 보통 ffmpeg 같은 동영상 압축 알고리즘이 널리 사용된다. 산업상 이용가능성 본 발명은 동영상에서 복잡한 배경을 제거하는 경우에 유용하며, 배경이 복잡한 자연 환경에서 촬영이 불가피한 동식물 동영상에서 배경을 제거하고 필요한 전경만을 포함한 영상 등을 제작하는 홀로그램 제작 과정 또는 최근 에 각광 받기 시작한 투명 디스플레이 등에서 특히 유용하다. 종래에서 프레임을 추출한 후, 프레임마다에서 배경을 제거한 후, 프레임을 결합해 동영상을 제작하는 고된 작 업을 지속해야 하였으며, 인공지능 기술이 공개된 후에는 그 성능이 충분하지 않아서 일부 객체가 프레임마다에 서 포함 또는 비포함되어 자동화가 불가능하였다."}
{"patent_id": "10-2022-0143047", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 종래의 인공지능을 활용한 배경 제거 동영상의 학습에 사용되는 학습 데이터 셋의 일 예를 도시한 도면, 도 2는 인공지능을 활용하여 2개 이상의 객체가 포함된 동영상에서 배경을 제거하는 처리의 전후 과정을 도시한 도면, 도 3은 인공지능을 활용하여 2개 이상의 객체를 포함한 동영상으로부터 배경을 제거하는 과정을 도시한 순서도 도 4 및 도 5는 자동 인식된 객체에 대해서 사용자가 필요한 객체를 선택하는 과정을 보여주기 위한 도면, 도 6은 전체 선택 영역을 지정하는 경우에 지정형식을 설명하기 위한 도면이다."}
