{"patent_id": "10-2021-7042477", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2022-0000422", "출원번호": "10-2021-7042477", "발명의 명칭": "인공 신경망", "출원인": "마이크론 테크놀로지, 인크.", "발명자": "에일러트, 션 스테판"}}
{"patent_id": "10-2021-7042477", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "컴퓨팅 디바이스에 구현되는 방법에 있어서, 상기 방법은,인공 신경망(artificial neural network)의 제1 부분을 상기 컴퓨팅 디바이스의 로컬 메모리에 저장하는 단계로서, 상기 컴퓨팅 디바이스의 상기 인공 신경망의 제2 부분은 원격 디바이스의 메모리에 저장되고, 상기 원격 디바이스와 상기 컴퓨팅 디바이스는 유선 또는 무선 네트워크 연결을 통해 연결되는, 상기 저장하는 단계;상기 인공 신경망의 상기 제1 부분의 출력을 생성하기 위해 상기 컴퓨팅 디바이스의 애플리케이션을 실행하는단계로서, 상기 인공 신경망의 상기 제2 부분은 상기 인공 신경망의 상기 제2 부분의 출력을 생성하기 위한 입력으로서 상기 인공 신경망의 상기 제1 부분의 출력을 수신하도록 구성된, 상기 실행하는 단계;상기 컴퓨팅 디바이스에 의해, 상기 원격 디바이스의 메모리의 적어도 일부에 액세스하는 단계; 및상기 컴퓨팅 디바이스에서, 상기 인공 신경망의 상기 제2 부분의 출력에 대응하는 결과를 생성하는 단계를 포함하는, 방법."}
{"patent_id": "10-2021-7042477", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "청구항 1에 있어서, 상기 원격 디바이스의 메모리 부분에 액세스하는 단계는 상기 원격 디바이스의 메모리 부분에 저장된 상기 인공 신경망의 상기 제2 부분에 액세스하는 단계를 포함하고; 상기 방법은,상기 컴퓨팅 디바이스에 의해, 상기 인공 신경망의 상기 제2 부분의 출력을 생성하기 위해 상기 인공 신경망의상기 제2 부분에 상기 입력을 인가하는 단계를 더 포함하는, 방법."}
{"patent_id": "10-2021-7042477", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "청구항 2에 있어서,상기 컴퓨팅 디바이스에 의해, 상기 인공 신경망의 상기 제1 부분을 상기 원격 디바이스의 메모리에 저장하는단계;상기 컴퓨팅 디바이스에서, 상기 인공 신경망의 상기 제1 부분에 액세스하기 위한 제1 가상 어드레스 영역을 상기 원격 디바이스에 매핑하는 단계;상기 원격 디바이스로부터 상기 컴퓨팅 디바이스에서 상기 인공 신경망의 상기 제2 부분을 수신하는 단계; 및상기 컴퓨팅 디바이스에서, 상기 인공 신경망의 상기 제1 부분을 액세스하기 위한 제2 가상 어드레스 영역을 상기 컴퓨팅 디바이스의 상기 로컬 메모리에 매핑하는 단계를 더 포함하는, 방법."}
{"patent_id": "10-2021-7042477", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "청구항 1에 있어서, 상기 원격 디바이스의 메모리 부분에 액세스하는 단계는 상기 인공 신경망의 상기 제2 부분의 대체물로서 대체 모듈에 액세스하는 단계를 포함하고; 및상기 결과는 상기 입력을 상기 대체 모듈에 인가함으로써 생성되는, 방법."}
{"patent_id": "10-2021-7042477", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "청구항 4에 있어서, 상기 대체 모듈은 상기 결과의 계산을 보조하는데 있어서 사용자 입력을 수신하도록 구성되는, 방법."}
{"patent_id": "10-2021-7042477", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "공개특허 10-2022-0000422-3-청구항 4에 있어서, 상기 대체 모듈은 상기 인공 신경망의 상기 제2 부분의 간략화된 모델을 포함하는, 방법."}
{"patent_id": "10-2021-7042477", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "청구항 4에 있어서,상기 유선 또는 무선 네트워크 연결의 성능 저하 예측에 응답하여 상기 대체 모듈을 수신하는 단계를 더 포함하는, 방법."}
{"patent_id": "10-2021-7042477", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "청구항 1에 있어서,상기 컴퓨팅 디바이스에 의해, 상기 인공 신경망의 상기 제2 부분에 입력을 인가하도록 상기 원격 디바이스에요청하는 단계;를 더 포함하고,상기 컴퓨팅 디바이스에 의해, 상기 원격 디바이스의 메모리의 적어도 일부에 액세스하는 단계는 상기 원격 디바이스에 생성된 상기 인공 신경망의 상기 제2 부분의 출력에 액세스하는 단계를 포함하는, 방법."}
{"patent_id": "10-2021-7042477", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "청구항 1에 있어서,상기 유선 또는 무선 네트워크 연결의 성능 저하를 검출하는 단계; 및상기 성능 저하에 응답하여, 상기 인공 신경망의 상기 제2 부분과 관련된 애플리케이션 계산을 스킵하는 단계를더 포함하는, 방법."}
{"patent_id": "10-2021-7042477", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "컴퓨팅 디바이스에 구현되는 방법에 있어서, 상기 방법은,유선 또는 무선 네트워크를 통해 원격 디바이스와의 연결을 수립하는 단계로서, 상기 원격 디바이스는 인공 신경망의 제1 부분을 상기 원격 디바이스의 로컬 메모리에 저장하도록 구성되고, 상기 컴퓨팅 디바이스의 메모리에 액세스하도록 구성된, 상기 수립하는 단계;상기 원격 디바이스에 대해, 상기 컴퓨팅 디바이스의 메모리에 상기 인공 신경망의 제2 부분을 저장하는 단계;및상기 인공 신경망의 상기 제2 부분에 대한 액세스를 포함하는 상기 컴퓨팅 디바이스의 상기 메모리에 대한 액세스를 상기 원격 디바이스에 제공하는 단계로서, 상기 원격 디바이스는 상기 인공 신경망의 상기 제1 부분의 출력을 생성하기 위해 애플리케이션을 실행하도록 구성되고, 상기 인공 신경망의 상기 제2 부분은 상기 인공 신경망의 상기 제2 부분의 출력을 생성하기 위한 입력으로서 상기 인공 신경망의 상기 제1 부분의 출력을 수신하도록 구성된, 상기 제공하는 단계를 포함하는, 방법."}
{"patent_id": "10-2021-7042477", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "청구항 10에 있어서, 상기 원격 디바이스는 상기 인공 신경망의 상기 제2 부분에 상기 입력을 인가할 때 상기컴퓨팅 디바이스의 메모리에 저장된 상기 인공 신경망의 상기 제2 부분에 액세스하도록 구성되는, 방법."}
{"patent_id": "10-2021-7042477", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "청구항 10에 있어서,상기 인공 신경망의 상기 제2 부분의 대체물로서 대체 모듈을 상기 원격 디바이스에 송신하는 단계를 더 포함하고, 상기 원격 디바이스는 연결이 성능 저하될 때 상기 인공 신경망의 상기 제2 부분에 의한 처리를 상기 대체모듈에 의한 처리로 교체하도록 구성된, 방법."}
{"patent_id": "10-2021-7042477", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "에 있어서,상기 애플리케이션에서 상기 인공 신경망의 사용 패턴에 기초하여 상기 인공 신경망의 상기 제2 부분의 간략화된 모델을 생성하는 단계를 더 포함하는, 방법."}
{"patent_id": "10-2021-7042477", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "청구항 14에 있어서,상기 연결이 성능 저하될 것으로 예상되는 기간 동안 상기 사용 패턴을 예측하는 단계를 더 포함하는, 방법."}
{"patent_id": "10-2021-7042477", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "청구항 10에 있어서,상기 컴퓨팅 디바이스에서, 상기 인공 신경망의 상기 제2 부분에 입력을 인가하기 위한 상기 원격 디바이스로부터의 요청을 수신하는 단계;상기 컴퓨팅 디바이스에 의해, 상기 인공 신경망의 상기 제2 부분의 출력을 생성하기 위해 상기 인공 신경망의상기 제2 부분의 계산을 수행하는 단계; 및상기 인공 신경망의 상기 제2 부분의 출력을 상기 원격 디바이스에 제공하는 단계를 더 포함하는, 방법."}
{"patent_id": "10-2021-7042477", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "청구항 10에 있어서,상기 인공 신경망의 상기 제1 부분이 상기 원격 디바이스의 애플리케이션에서 사용되고 있는 기간에 기계 학습기술을 사용하여 상기 인공 신경망의 상기 제2 부분을 업데이트하는 단계를 더 포함하는, 방법."}
{"patent_id": "10-2021-7042477", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "인공 신경망을 갖는 컴퓨팅 시스템에 있어서, 상기 시스템은,로컬 메모리 및 통신 디바이스를 갖는 컴퓨팅 디바이스; 및로컬 메모리 및 통신 디바이스를 갖는 원격 디바이스;를 포함하고,상기 컴퓨팅 디바이스의 통신 디바이스 및 상기 원격 디바이스의 통신 디바이스는 유선 또는 무선 네트워크를통해 연결되도록 구성되고;상기 원격 디바이스는 상기 컴퓨팅 디바이스에 상기 원격 디바이스의 로컬 메모리에 대한 액세스를 제공하도록구성되고;상기 컴퓨팅 디바이스 및 상기 원격 디바이스는 상기 인공 신경망을 저장하고 상기 인공 신경망에 기반하여 처리할 때 협력하도록 구성된, 시스템."}
{"patent_id": "10-2021-7042477", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "청구항 18에 있어서, 상기 인공 신경망은 제1 부분 및 제2 부분으로 파티션(partition)되고; 상기 컴퓨팅 디바이스는 상기 인공 신경망의 상기 제1 부분을 저장하고 상기 인공 신경망의 상기 제1 부분을 사용하여 상기 인공신경망에 대한 입력을 처리하도록 구성되고; 및 상기 원격 디바이스는 상기 인공 신경망의 상기 제2 부분을 저장하고 상기 인공 신경망의 상기 제2 부분을 사용하여 상기 인공 신경망의 상기 제1 부분으로부터의 출력을 처리하도록 구성된, 컴퓨팅 시스템."}
{"patent_id": "10-2021-7042477", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "청구항 18에 있어서, 상기 컴퓨팅 디바이스와 상기 원격 디바이스 사이의 연결이 성능 저하될 때 상기 인공 신경망의 제2 부분의 대체물로서 대체 모듈이 구성되는, 컴퓨팅 시스템."}
{"patent_id": "10-2021-7042477", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_21", "content": "공개특허 10-2022-0000422-5-청구항 18에 있어서, 상기 컴퓨팅 디바이스의 통신 디바이스와 상기 원격 디바이스의 통신 디바이스는 5세대 셀룰러 네트워크를 통해 연결되는, 컴퓨팅 시스템."}
{"patent_id": "10-2021-7042477", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "서비스로서 메모리를 위한 네트워크 통신을 스로틀링하는 시스템, 방법 및 장치가 설명된다. 예를 들어, 컴퓨팅 디바이스는 대여자 디바이스와 컴퓨팅 디바이스 사이의 통신 연결을 통해 대여자 디바이스의 랜덤 액세스 메모리 의 일정량을 차용할 수 있다. 컴퓨팅 디바이스는 컴퓨팅 디바이스에서 실행하는 애플리케이션에 가상 메모리를 할당할 수 있고; 적어도 가상 메모리의 부분이 대여자 디바이스에 의해 컴퓨팅 디바이스에 대여된 메모리의 양에 호스팅되도록 구성할 수 있다. 컴퓨팅 디바이스는 메모리 영역에 저장된 콘텐츠의 중요도 레벨에 따라 통신 연결 을 통해 메모리의 양을 액세스할 때 메모리 영역에 의해 사용되는 데이터 통신을 스로틀링할 수 있다."}
{"patent_id": "10-2021-7042477", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "관련 출원 본 출원은 \"인공 신경망(ANN) 애플리케이션을 위한 서비스로서의 메모리\"라는 제목으로 2019년 5월 28일에 출원 된 출원된 미국 특허 출원 일련 번호 16/424,429에 대한 우선권을 주장하고, 이의 전체 개시는 본 출원에 참조 로 포함된다. 기술 분야 본 출원에 개시된 적어도 일부 실시예는 운영 체제 및 ANN(Artificial Neural Network)에 의해 제공되는 메모리 서비스에 관한 것이다."}
{"patent_id": "10-2021-7042477", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "일부 컴퓨터 시스템에서, 운영 체제는 애플리케이션이 메모리의 가상 어드레스를 사용하여 컴퓨터 시스템의 하 나 이상의 메모리 서브 시스템의 메모리 컴포넌트에 데이터를 저장하거나 메모리 컴포넌트로부터 데이터를 검색 할 수 있게 한다. 운영 체제는 컴퓨터 시스템의 중앙 처리 유닛(CPU) 및/또는 그래픽 처리 유닛(GPU) 및/또는 시스템 온 칩(SoC)에 연결된 하나 이상의 메모리 서브 시스템의 가상 메모리 어드레스와 물리적 메모리 어드레 스 간의 매핑을 정의한다. 이러한 매핑은 페이지 테이블을 사용하여 정의될 수 있다. 페이지 테이블 엔트리는 가상 메모리 페이지의 가상 메모리 어드레스 세트와 물리적 메모리 페이지의 대응하는 물리적 메모리 어드레스 세트 간의 매핑을 지정한다. 페이지 테이블은 가상 메모리 어드레스를 메모리 서브 시스템의 대응하는 물리적 메모리 어드레스로 변환함으로써 가상 메모리 어드레스에 대해 요청된 메모리 액세스를 구현하는데 사용될 수 있다. 컴퓨터 프로세서는 운영 체제에 의해 정의된 페이지 테이블에 따라 가상 메모리 어드레스의 물리적 메모리 어드 레스로의 변환을 수행하도록 구성된 메모리 관리 유닛(MMU)을 가질 수 있다. MMU(memory management unit)은 최 근에 사용한 페이지 테이블 엔트리를 캐시하도록 구성된 TLB(translation lookaside buffer)를 가질 수 있다. MMU(memory management unit)는 캐시 제어 및/또는 메모리 보호와 같은 다른 메모리 관련 태스크를 수행할 수 있다. 일반적으로, 컴퓨터에서 메모리를 위한 가상 어드레스 공간은 미리 결정된 크기의 페이지로 분할될 수 있다. 가 상 메모리 페이지는 가상 메모리 어드레스 집합으로 표시된다; 가상 메모리 어드레스는 메모리 서브 시스템에 있는 물리적 메모리 페이지의 물리적 메모리 어드레스에 매핑될 수 있다; 페이지 테이블 엔트리는 가상 메모리 페이지와 물리적 메모리 페이지 간의 어드레스 매핑을 정의한다. 일부 컴퓨터 시스템에서, 운영 체제는 메모리 모듈의 메모리 페이지를 통해 저장 디바이스 또는 메모리 디바이 스의 데이터 페이지에 액세스하기 위해 페이징 기술(paging technique)을 사용할 수 있다. 다른 시간 인스턴스 에서, 메모리 모듈의 동일한 메모리 페이지는 컴퓨터 시스템의 저장소 또는 메모리 디바이스 또는 다른 저장소 또는 메모리 디바이스에 있는 메모리의 다른 페이지에 액세스하기 위해 프록시로 사용될 수 있다. RDMA(remote direct memory access)는 관련된 컴퓨터의 운영 체제를 수반하지 않고(예를 들어, RDMA 동작을 위 한 메모리 자원 협상 및 설정을 위해 운영 체제가 실행된 후) 한 컴퓨터에서 다른 컴퓨터로 직접 메모리 액세스 를 허용하는 기술이다. RDMA 동작(예를 들어, 판독 또는 기록) 전에, 커맨드가 실행되어 하나 이상의 네트워킹 디바이스를 통해 두 컴퓨터 간에 메모리 매핑을 수립한다. 컴퓨터에서 실행되는 애플리케이션이 RDMA 동작을 수 행하면, 애플리케이션 데이터가 컴퓨터 네트워크를 통해 직접 전달되어 레이턴시가 줄어들고 빠른 데이터 전송 이 가능하다. RDMA는 네트워크 어댑터를 사용하여 애플리케이션 메모리로 또는 애플리케이션 메모리에서 데이터 를 전송하므로 애플리케이션 메모리와 운영 체제의 데이터 버퍼 간에 데이터를 복사할 필요가 없다."}
{"patent_id": "10-2021-7042477", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 2, "content": "발명의 내용"}
{"patent_id": "10-2021-7042477", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 출원에 개시된 적어도 일부 실시예는 통신 네트워크 연결을 통한 운영체제간 메모리 서비스의 기술을 제공하 여, 차용자 디바이스가 대여자 디바이스의 통신 링크 및 메모리를 사용하여 메모리 용량을 확장할 수 있도록 한 다. 차용자 디바이스 및/또는 대여자 디바이스의 운영 체제는 통신 링크를 통해 간격을 끊김없이 연결하도록 구 성될 수 있으므로 차용자 디바이스에서 실행되는 애플리케이션이 로컬 메모리와 차용된 메모리를 구별 없이 사 용할 수 있다. 로컬 메모리는 차용자 디바이스에 물리적으로 설치된다; 차용된 메모리는 통신 연결을 통해 차용 자 디바이스에 연결된 대여자 디바이스에 물리적으로 설치된다. 옵션으로, 차용된 메모리 및/또는 차용자 디바이스의 로컬 메모리의 일부는 컴퓨터 네트워크를 통해 다른 디바 이스에 대여될 수 있다. 차용자 디바이스는 다수의 대여자 디바이스를 가질 수 있다. 따라서, 차용자-대여자 디 바이스 계층은 디바이스 간의 통신 링크 계층에서 형성될 수 있다. 차용자 디바이스의 운영 체제는 가상 대 물리적 메모리 맵을 사용하여 로컬 메모리와 차용된 메모리의 차이를 브리징할 수 있다. 예를 들어, 차용자 디바이스의 운영 체제는 페이지 폴트의 결정으로 이어질 수 있는 차용자 디바이스의 TLB(Translation Lookaside Buffer) 오류에 대한 응답으로 PTE(Page Table Entry)을 조작하여 통신 링크를 통해 차용된 메모리에 액세스할 때 애퍼처(aperture), 프록시 및/또는 캐시와 같은 차용자 디바이스의 로컬 메모리 부분을 사용할 수 있다. 대여자 디바이스와 차용자 디바이스 간의 캐시 일관성이 개선된 대역폭 사 용을 위해 완화될 수 있다. 로컬 메모리와 차용된 메모리 영역 간의 차이는 차용자 디바이스에서 실행되는 애플 리케이션으로부터 차용자 디바이스의 운영 체제에 의해 차폐되므로 차용자 디바이스에서 실행되는 애플리케이션 은 차용자 디바이스에 구성된 로컬 랜덤 액세스 메모리를 액세스하는 것과 동일한 방식으로 차용된 메모리에 바 이트 액세스할 수 있다. 운영 체제의 메모리 서비스는 일관성이 없는(non-coherent) 통신 링크를 통해 다수의 운영 체제에 의해 공유되 는 통합 어드레스 공간 하에 컴퓨터 시스템에서 멀티 레벨 바이트 어드레스 지정 가능 메모리를 구성하는데 사 용될 수 있다. 예를 들어, 웨어러블 컴퓨팅 디바이스는 개인 영역 네트워크 또는 근거리 통신망을 통해 모바일 컴퓨팅 디바이스로부터 메모리를 차용할 수 있다. 웨어러블 컴퓨팅 디바이스는 스마트 워치, 모션 추적 디바이 스 또는 스마트 유리일 수 있고, 모바일 컴퓨팅 디바이스는 스마트 폰, 터치 패드 컴퓨터, 또는 노트북 컴퓨터 등일 수 있다. 웨어러블 컴퓨팅 디바이스 및/또는 모바일 컴퓨팅 디바이스는 근거리 통신망을 통해 컴퓨팅 기기 로부터 메모리를 차용할 수 있다. 예를 들어, 컴퓨팅 기기는 미니 서버, 데스크탑 컴퓨터, 메모리 기기 또는 저 장 기기 등일 수 있다. 모바일 컴퓨팅 디바이스 및/또는 컴퓨팅 기기는 인터넷 및/또는 클라우드 컴퓨팅을 통해 서버 컴퓨터 또는 서버 팜에서 메모리를 차용할 수 있다. 메모리 자원의 대여자-차용자의 멀티 레벨 계층에서, 각각의 후속 상위 레벨 디바이스(예를 들어, 모바일 컴퓨 팅 디바이스, 컴퓨팅 기기, 서버 컴퓨터 또는 팜)는 메모리 용량을 사용하여 하위 레벨 디바이스(예를 들어, 웨어러블 컴퓨팅 디바이스, 모바일 컴퓨팅 디바이스, 컴퓨팅 기기) 및/또는 동일한 레벨의 디바이스의 메모리 용 량을 요구에 따라 부스트할 수 있다. IoT 디바이스는 건축 자재(벽, 도로 등을 구성)와 같은 환경을 구성한다. 밀도는 낮지만 부피가 매우 큰 저렴한 메모리 기술은 매우 저렴한 비용으로 건축물에 저밀도 메모리(및 컴퓨 팅)를 통합할 수 있다. 따라서, 우리는 임의의 디바이스가 사용할 수 있는 환경의 일부로 일종의 '메모리 문 제'(또는 컴퓨팅 문제일 수 있음)를 갖게 된다. 옵션으로, 특정 디바이스 및/또는 네트워크 연결의 가용성에 따라 계층 구조의 일부 레벨은 스킵될 수 있다. 예 를 들어, 웨어러블 컴퓨팅 디바이스는 모바일 컴퓨팅 디바이스를 거치지 않고 컴퓨팅 기기로부터 메모리를 차용 할 수 있다; 모바일 컴퓨팅 디바이스는 근거리 통신망에서 컴퓨팅 기기를 통하지 않고 인터넷을 통해 서버 컴퓨 터 또는 서버 팜로부터 메모리를 차용할 수 있다. 기기 및 클라우드 레벨에서, 메모리 자원은 MaaS (Memory as a Service)를 이용한 유틸리티로서 프로비저닝 (provision)될 수 있다. 이러한 배열은 웨어러블 컴퓨팅 디바이스, 모바일 컴퓨팅 디바이스, 및/또는 사물 인터 넷의 컴퓨팅 디바이스와 같은 저레벨 컴퓨팅 디바이스에 엄청난 영구 메모리 용량 및 온디맨드 저장 자원을 제 공할 수 있다. 저레벨 컴퓨팅 디바이스에서 실행되는 애플리케이션은 운영 체제에 의해 제공되는 메모리 서비스 를 사용하여 차용된 메모리가 차용자 디바이스의 로컬 메모리인 것처럼 투명한(transparent) 방식으로 차용된 메모리를 사용할 수 있다. 결과적으로, 차용된 메모리를 사용하기 위해 애플리케이션에서 특별한 프로그래밍이 필요하지 않다. 차용자 디바이스에서 실행되는 애플리케이션은 차용된 메모리를 사용하여 데이터를 지속적으로 저장할 수 있으 므로 파일 시스템을 통해 데이터를 저장하기 위한 동작의 필요성을 제거하거나 줄일 수 있다. 예를 들어, 대여 자 기기/서버는 영구 랜덤 액세스 메모리 또는 저장 용량을 제공하여 차용자 기기에 메모리 자원을 제공하고 차 용된 메모리가 차용자 디바이스에서 가상 비휘발성 랜덤 액세스 메모리로 취급될 수 있도록 제공되는 메모리 자 원에 저장된 데이터의 지속성 및/또는 중복성을 관리할 수 있다. 옵션으로, 서비스로 제공되는 메모리는 클라이언트/차용자 간의 메모리 페이지 공유, 잠금 메커니즘, 타임아웃 메커니즘 등을 위한 시맨틱스(semantics)를 포함할 수 있다. 예를 들어, 전화는 차용자 디바이스로서, 대여자 디바이스로 기능하는 메모리 기기로부터 무선 근거리 통신망 (WLAN)(예를 들어, 홈 Wi-Fi 액세스 포인트를 통해 가능해짐)을 통해 8테라 바이트(TB)의 관측 가능한 메모리를 획득할 수 있다. 8TB의 메모리는 8TB의 로컬 메모리가 있는 전화기에서 실행되는 애플리케이션과 동일한 방식으 로 전화기의 운영 체제 하에서 실행되는 애플리케이션에 관측될 수 있다. 대안으로, 전화기는 대여자 디바이스 로 구성된 서버 또는 클라우드 컴퓨팅 인프라스트럭처에서 셀룰러 통신 네트워크를 통해 8TB의 관측 가능한 메 모리를 획득할 수 있다. 옵션으로, 전화기는 메모리 기기에서 8TB의 관측 가능한 메모리의 일부를, 서버 또는 클라우드 컴퓨팅 인프라스트럭처에서 8TB의 관측 가능한 메모리의 일부를 차용할 수 있다. 전화기가 8MB의 물리 적 로컬 메모리만 가지고 있을 지라도, 8TB의 관측 가능한 메모리는 전화기의 운영 체제에 의해 전화기에서 가 상으로 사용할 수 있게 되어 전화기에서 실행되는 애플리케이션은 가상/원격 메모리를 사용할 수 있다. 8TB의 차용된 메모리는 전화기의 메모리 용량을 8TB 이상으로 확장한다; 차용된 메모리가 있는 전화기에서 실행되는 애플리케이션의 경우 전화기의 메모리 용량은 8TB 이상의 로컬 랜덤 액세스 메모리가 있는 전화기와 동일한 것으로 보인다. 차용자 디바이스는 전형적으로 메모리를 차용할 때 차용된 메모리를 한번에 사용하지 않기 때문에, 대여자 디바 이스는 메모리를 차용할 때 차용된 디바이스에 대여된 메모리를 블록 할당할 필요가 없다. 대여자 디바이스는 메모리의 씬 프로비저닝(예를 들어, 씬 프로비저닝 메모리)을 구현하고 차용된 메모리의 증가하는 양을 사용하 여 차용자 디바이스에 응답하여 메모리를 증분하여 할당할 수 있다. 차용자 디바이스의 운영 체제하에서 실행되는 애플리케이션은 대여자 디바이스(들)로부터 차용된 주문형 메모리 페이지를 판독하고 기록할 수 있다. 대여자 디바이스의 물리적 페이지 할당 및/또는 차용자 디바이스의 대응하 는 할당은 페이지에 대한 기록 동작에 응답하여 수행되도록 구성될 수 있다. 차용자 디바이스의 로컬 메모리의 일부는 차용된 페이지에 액세스할 때 캐시, 프록시 및/또는 애퍼처로 구성될 수 있다. 차용자 디바이스에서 실 행되는 애플리케이션이 가상 페이지에 액세스하면, 차용자 디바이스의 운영 체제는 액세스한 가상 페이지의 콘 텐츠를 로컬 메모리로 마이그레이션할 수 있다. 로컬 메모리 페이지가 일정 시간 동안 액세스되지 않았고 및/또 는 다른 페이지의 콘텐츠를 호스팅하는데 사용되는 경우, 차용자 디바이스의 운영 체제는 로컬 메모리의 가상 페이지의 콘텐츠를 대여자 디바이스의 차용된 메모리로 축출하거나 마이그레이션할 수 있다. 옵션으로, 차용자 디바이스의 운영 체제는 차용자 디바이스의 로컬 랜덤 액세스 메모리의 일부를 중요한 데이터에 대한 고속 버퍼로 사용할 수 있고, 원격 대여자 디바이스에 물리적으로 상주하는 차용된 메모리를 사용하여 덜 중요한 데이터 를 보유할 수 있다. 덜 중요한 데이터 및/또는 덜 자주 사용되는 데이터는 필요할 때 차용자 디바이스의 로컬 랜덤 액세스 메모리로 마이그레이션될 수 있다. 일반적으로, 계층의 하위 레벨 디바이스에 대한 대여자 디바이스는 자체가차용자-대여자 디바이스 계층에서 상 위 레벨의 차용자 디바이스일 수 있다. 예를 들어, 차용자 디바이스인 전화기는 대여자 디바이스인 메모리 기기 로부터 8TB의 메모리를 차용할 수 있다. 차용자 디바이스로서 메모리 기기는 서버에서 4TB의 메모리를 차용하고, 서버로부터 차용된 4TB의 메모리와 로컬 메모리 4TB를 전화기에 대여된 8TB의 메모리로 조합할 수 있 다. 일부 구현예에서, 서버로부터 차용된 4TB 메모리는 전화기에 식별될 수 있어서 전화기와 기기 사이의 연결 을 사용할 수 없을 때, 전화기는 서버에 대한 대체 연결을 사용하여 메모리 기기를 거치지 않고 4TB 메모리를 계속 사용할 수 있다. 그러나, 기기가 원격 서버보다 전화기에 더 가깝기 때문에 대체 연결은 메모리 기기에 대 한 연결보다 느릴 수 있다. 대여자 디바이스의 운영 체제와 차용자 디바이스의 운영 체제는 서로 통신하여 대여자 디바이스와 차용자 디바 이스 사이의 통신 링크를 통해 끊김 없는 메모리 액세스를 가능하게 할 수 있다. 따라서, 차용자 디바이스에서 실행되는 애플리케이션이 메모리를 사용하기 시작하기 전에 대여자 디바이스에 물리적 메모리를 미리 할당할 필 요가 없다. 페이지 축출 트래픽 및 대여자 디바이스 메모리 가용성은 차용자 디바이스에서 실행되는 애플리케이 션의 풋프린트가 증가함에 따라 차용된 메모리 사용량의 크기를 결정한다. 애플리케이션(예를 들어, RDMA 프로 토콜의 경우 요구됨)에 대한 대여자 디바이스의 물리적 메모리 사전 할당 요구 사항을 제거하면 특수 프로그래 밍(예를 들어, RDMA를 통한 MPI(Message Passing Interface))이 필요하지 않으며, RDMA 등의 경우에서와 같이 확장형 애플리케이션 용량의 모든 이점을 활용하면서도 원래 코드에서 다양한 구성의 디바이스에서 애플리케이 션 프로그램이 제대로 기능하는 것을 허용한다. 일반적으로, 대여자 디바이스는 특정 차용자 디바이스에 대해 수동 모드 또는 능동 모드에서 동작하도록 구성될 수 있다. 대여자 디바이스는 다른 차용자 디바이스에 대해 상이한 모드에서 동작할 수 있다. 수동 모드에서, 대여자 디바이스의 운영 체제는 링크를 통해 차용자 디바이스의 운영 체제에 의해 캐시되거나 마이그레이션된 메모리 페이지를 관측하고 이에 따라 이러한 페이지에 대응하는 자체 페이지 테이블 엔트리를 수정한다. 대여자 운영 체제가 페이지 이동에 대해 수행하는 관측은 예를 들어, 버스 스누핑(bus snooping) 또 는 하드웨어 모니터링을 통해 수행할 수 있다. 차용자 디바이스의 운영 체제는 차용자 디바이스의 로컬 메모리 및 대여자 디바이스에 물리적으로 상주하는 차 용된 메모리에 대한 페이지 테이블을 유지하도록 구성된다. 일반적으로, 차용된 메모리의 페이지가 차용자 디바 이스에서 실행 중인 애플리케이션에 의해 액세스되고 있을 때, 페이지의 콘텐츠는 현재 차용자 디바이스의 로컬 메모리 페이지에 저장되거나 저장되지 않을 수 있다. 차용자 디바이스가 차용자 디바이스의 로컬 메모리에 존재하지 않는 페이지에 액세스하면 페이지 폴트가 발생한 다. 우리의 목적을 위해 우리는 두 가지 경우에 발생하는 페이지 폴트를 고려한다: 1) 액세스된 페이지가 전혀 존재하지 않는다; 2) 액세스된 페이지는 존재하지만 로컬 메모리에는 존재하지 않는다. 페이지가 존재하지 않는 경우에는, 기록되거나 판독되지 않은 것이다. 해당 페이지에 대한 PTE(page table entry)가 없다. 페이지가 액세스되는 것은 처음이다. 이러한 페이지에 대해 판독 작업을 수행하면 실제 페이지 를 할당할 필요가 없다. 일부 운영 체제(예를 들어, Linux)는 0으로 채워진 가짜 페이지를 제공할 수 있는데, 이는 페이지가 기록된 적이 없고 데이터가 포함되어 있지 않기 때문이다. 따라서, 이러한 페이지에서 수행된 판 독 동작은 결과적으로 0이 된다. 이 경우 OS는 이 페이지 폴트에 대한 핸들러를 실행한다 : TLB 미스는 페이지 워크(page walk)를 유발하여 PTE가 없는 페이지에서 판독 동작이 수행된다고 결정한다. 결과적으로 0 페이지에 대한 매핑이 리턴된다. 페이지에 대한 기록 동작이 처음으로 수행되면 이는 트루 폴트(true fault)이다. 트루 폴트는 로컬 메모리에 새 로운 PTE 및 페이지 할당을 초래한다. 이 경우에 대한 페이지 폴트 핸들러의 예 : TLB 미스가 페이지 워크를 유 발하여 PTE가 없는 페이지에서 기록 동작이 수행되었음을 결정한다. 결과적으로 운영 체제는 새 페이지를 할당 하고, PTE를 생성하고 페이지 테이블에 PTE를 설치한다. PTE가 TLB에 캐시된 후 폴트가 해결된다. 차용된 페이지에 액세스할 때 페이지 폴트가 발생하고 페이지의 콘텐츠가 현재 차용자 디바이스의 로컬 메모리 에 없는 경우(예를 들어, 차용된 페이지의 콘텐츠가 대여자 디바이스로 마이그레이션/축출된 후), 차용자 디바 이스의 운영 체제는 차용된 페이지의 콘텐츠를 검색하거나 마이그레이션하기 위해 차용자 디바이스와 대여자 디바이스 간의 통신 링크를 통해 대여자 디바이스와 통신할 수 있다. 캐싱 동작은 상술한 2가지 경우의 처리와 관련하여 수행될 수 있다. 예를 들어, 대여자 디바이스는 페이지 복사 본을 보관할 수 있다. 복사본은 차용자 디바이스가 페이지를 더 이상 수정하지 않는 경우에 유용할 수 있다(예 를 들어, 페이지에서 판독 작업만 수행). 이러한 상황에서는, 페이지의 실제 복사본이 대여자 디바이스에 이미 존재하기 때문에 축출이 필요하지 않다. 유사하게, 차용자 디바이스는 차용자 디바이스와 대여자 디바이스 간의 통신 링크를 자유롭게 사용할 수 있을 때 페이지의 추측적 축출(speculative eviction)을 수행할 수 있다. 옵션으로, 대여자 디바이스 및/또는 차용자 디바이스는 대여자 디바이스와 차용자 디바이스 간의 콘텐츠 마이그 레이션 동작을 가속화하는 펌웨어/하드웨어로 구성될 수 있다. 옵션으로, 대여자 디바이스의 운영 체제는 페이지 테이블 워커, TLB(Translation Lookaside Buffer), CAM(Content-addressable memory), 룩업 테이블 등과 같은 관련 자원 및 페이지 테이블 세트를 자체적으로 유지 하고 운영하도록 구성될 수 있다. 대여자 디바이스의 운영 체제는 대여자 디바이스로부터 메모리를 차용하는 임의의 차용자 디바이스로부터의 메 모리 액세스 요청을 모니터링한다. 차용자 디바이스(예를 들어, 원자성, 잠금, 세마포어, 플래그, 시간 초과 등) 간에 페이지 공유를 위한 시맨틱스를 제공하도록 구성될 수 있다. 그 결과, 차용된 메모리의 어드레스 공간 은 대여자 디바이스의 페이지 테이블에 따라 차용자 디바이스 간에 통합된다. 분산 애플리케이션은 대여자 디바 이스를 통해 차용된 메모리를 다른 차용자 디바이스에서 실행되는 다른 인스턴스 애플리케이션과 공유함으로써 통합 어드레스 공간을 활용할 수 있다. 옵션으로, 대여자 디바이스는 차용자 디바이스에 대여된 메모리의 특정 영역에 대한 계산 결과를 생성하기 위해 차용자 디바이스로부터의 요청을 수락하도록 구성될 수 있다. 따라서, 대여자 디바이스는 차용자 디바이스에 대 여된 메모리 자원 뿐만 아니라 메모리의 데이터를 처리하기 위한 컴퓨팅 파워도 제공한다. 차용자 디바이스 및 대여자 디바이스의 운영 체제에 의해 제공되는 메모리 서비스는 차용자 디바이스에서 실행 되는 애플리케이션이 페이지 세분화도(granularity)로 폴트 해결된 차용된 메모리를 바이트 세분화도에서 처리 할 수 있게 한다. 차용자 디바이스의 운영 체제는 차용자 디바이스와 대여자 디바이스 사이의 통신 링크를 통해 페이지를 로컬 메 모리에서 대여자 디바이스로 축출하거나 마이그레이션할 수 있다. 차용자 디바이스의 운영 체제는 페이지의 빈 번하지 않은 사용에 기초하여 및/또는 다른 페이지보다 덜 최근에 사용된 페이지에 기초하여 또는 중요도 또는 다른 가능한 측정 가능한 시스템 파라미터를 기반으로 차용자 디바이스의 로컬 랜덤 액세스 메모리에서 차용된 메모리로 축출 또는 마이그레이션할 페이지를 식별할 수 있다. 차용자 디바이스의 운영 체제는 대여자 디바이스 로부터 페이지 마이그레이션 또는 새로운 로컬 페이지 할당과 같은 다른 용도를 위해 로컬 메모리를 해제 하기 위해 차용된 페이지를 축출하거나 마이그레이션하기로 결정할 수 있다. 이 방법의 결과로 현재 페이지 소유자 (차용자 또는 대여자)는 페이지의 실제 복사본을 소유한다. 소유자가 페이지를 릴리즈한 후에도 페이지가 여전 히 수정되지 않은 경우를 대비하여 다른 디바이스는 여전히 이를 캐시할 수 있다. 예를 들어, 차용자가 대여자 로부터 페이지를 가져오면, 대여자는 더 이상 해당 페이지를 가지고 있지 않다. 그러나, 대여자 디바이스는 페 이지 복사본을 삭제할 수 없지만 보관할 수 있다; 축출 시 페이지가 수정되지 않는 경우, 링크를 통해 대여자 디바이스로 다시 전송할 필요가 없다. 대여자가 이를 수정하거나 다른 차용자에게 제공하려는 경우에는 어떻게 되는가? 이 경우 다른 차용자로부터의 기록 요청을 병합하기 위해 모든 기록이 대여자 디바이스에서 발생해야 한다. 페이지를 축출시키거나 마이그레이션하기 위해, 차용자 디바이스의 운영 체제는 페이지의 콘텐츠를 대여자 디바 이스에 전달하여 대여자 디바이스가 해당 페이지를 대여자 디바이스의 메모리에 저장하게 한다. 그런 다음 차용 자 디바이스의 운영 체제는 페이지 테이블을 업데이트하여 페이지가 현재 차용자 디바이스의 로컬 메모리가 아 니라 대여자 디바이스에 있음을 나타낼 수 있다. 활성 모드에서, 대여자 디바이스의 운영 체제는 차용자 디바이스의 페이지 테이블을 모니터링하고, 사용되지 않 은 페이지를 식별하고, 다른 메모리 사용자를 위해 사용되지 않은 페이지의 용도를 변경하도록 구성될 수 있다. 대여자 디바이스와 차용자 디바이스 간의 상호작용은 가상화를 통해 구현될 수 있으며, 이는 대여자 디바이스가 차용자 디바이스의 페이지 테이블 사용을 모니터링할 수 있게 한다. 예를 들어, 차용자 디바이스의 운영 체제는 대여자 디바이스의 운영 체제에서의 동작을 위해 부분적으로 가상화 될 수 있다. 차용자 디바이스의 운영 체제의 메모리 관리 코드/서브루틴 중 일부는 대여자 디바이스에서 및/또 는 대여자 디바이스의 운영 체제의 일부로 실행되도록 가상화를 통해 구성될 수 있다. 이러한 구현예에서, 차용 자 디바이스의 운영 체제는 대여자 디바이스의 운영 체제 레벨에서 하드웨어/펌웨어 가속될 수 있는 이러한 서 브루틴을 실행하기 위해 대여자 디바이스의 운영 체제로 메모리 액세스 요청을 확장할 수 있다. 예를 들어, 대여자 디바이스의 운영 체제는 가상 메모리 디바이스를 생성하고 가상 메모리 디바이스를 차용자 디바이스에 제공할 수 있다. 차용자 디바이스는 요청 시 가상 메모리 디바이스를 요청할 수 있고, 차용자 디바 이스에서 실행되는 애플리케이션의 메모리 자원 요구 사항을 서비스하기 위해 가상 메모리 디바이스를 사용할 수 있도록 할 수 있다. 일부 경우에, 차용자 디바이스에서 실행되는 애플리케이션이 차용자 디바이스와 대여자 디바이스 사이의 통신 링크로 인한 레이턴시를 허용하거나 수용할 수 있는 경우, 차용된 페이지에 대한 액세스는 전체 페이지를 대여 자로 마이그레이션하지 않고 통신 링크를 통해 직접 이루어질 수 있다. 다른 구현예에서, 콘텐츠 마이그레이션 은 서브 페이지 레벨에서 구성될 수 있다; 액세스 중이거나 액세스할 것으로 예상되는 페이지 부분만 마이그레 이션된다. 옵션으로, 운영 체제는 직접 메모리 액세스를 구현하는데 RDMA(remote direct memory access) 기술을 사용할 수 있다. 옵션으로, 이러한 직접 메모리 액세스는 메모리 컨트롤러 및/또는 메모리 관리 유닛에서 구현 될 수 있으므로 표준 RDMA 프로토콜 및 그 오버헤드를 피할 수 있다. 일부 구현예에서, 차용자 디바이스의 운영 체제는 가상 메모리 페이지의 물리적 위치를 동적으로 조정하도록 구 성된다. 가상 메모리의 페이지는 페이지의 가상 메모리 어드레스에 의해 지정된다. 가상 메모리 페이지는 처음 에 차용자 디바이스의 로컬 메모리에 위치될 수 있고, 차후에 대여자 디바이스에 의해 차용자 디바이스에 대여 된 메모리로 이동되고, 차후에 차용자 디바이스의 다른 로컬 페이지로 이동될 수 있다. 대여자 디바이스에서 차용자 디바이스로 가상 페이지를 마이그레이션하기 위해, 차용자 디바이스는 대여자 디바 이스로부터 페이지의 콘텐츠를 페치하고, 콘텐츠를 로컬 메모리에 저장하고, 관련 페이지 테이블을 업데이트하 여 로컬 물리적 페이지와 가상 페이지 간의 매핑을 수립한다. 가상 페이지가 차용자 디바이스로 마이그레이션되 면, 대여자 디바이스는 이전에 가상 페이지에 사용되었던 물리적 메모리를 해제하고 거기에 저장된 데이터를 소 거할 수 있다. 옵션으로, 대여자 디바이스의 운영 체제는 가상 페이지에 대해 이전에 사용된 페이지를 리저브하 고 그 콘텐츠를 가상 페이지의 백업 복사본으로 유지할 수 있다. 반대 방향으로, 차용자 디바이스의 운영 체제는 가상 페이지를 차용자 디바이스에서 대여자 디바이스로 마이그 레이션할 수 있다. 예를 들어, 차용자 디바이스의 운영 체제는 대여자 디바이스에서 차용된 페이지의 할당을 요 청할 수 있고, 대여자 디바이스의 차용된 메모리에 저장하기 위한 가상 페이지의 콘텐츠를 송신할 수 있다. 가 상 페이지의 콘텐츠가 대여자 디바이스에 저장되면, 차용자 디바이스의 운영 체제는 가상 페이지에 대한 페이지 테이블을 업데이트하여 가상 페이지와 차용된 메모리의 물리적 위치 간의 매핑을 식별하여 대여자 디바이스로의 페이지의 마이그레이션을 완료할 수 있다. 가상 페이지를 마이그레이션한 후, 이전에 가상 페이지를 호스팅하는 데 사용된 로컬 메모리는 다른 가상 페이지를 호스팅하는데 사용될 수 있다. 이러한 구현예에서, 가상 메모리 또는 가상 메모리 어드레스 공간의 미리 결정된 부분을 대여자 디바이스(들)의 차용된 메모리에 정적으로 (statically) 매핑할 필요가 없다. 또한, 가상 페이지는 미리 결정된 대여자 디바이스에서 호스팅될 필요가 없다. 예를 들어, 차용자 디바이스의 운영 체제는 가상 페이지를 제1 대여자 디바이스에서 차용자 디바이스로 마이그레이션한 다음, 가상 페이지를 차용자 디바이스에서 제2 대여자 디바이스로 마이그레이션할 수 있다. 일부 경우에, 차용자 디바이스의 운영 체 제는 페이지의 콘텐츠를 차용자 디바이스로 다운로드한 다음 이 콘텐츠를 제2 대여자 디바이스로 업로드하지 않 고 가상 페이지를 제1 대여자 디바이스에서 제2 대여자 디바이스로 마이그레이션할 것을 요청할 수 있다. MaaS(Memory as a Service) 기술을 사용하여, 모바일 디바이스 벤더는 운영 체제 레벨에서 테라바이트의 메모리 용량을 갖는 모바일 디바이스를 마케팅할 수 있으며, 이는 클라우드 컴퓨팅 인프라스트럭처를 포함하는 대여자 디바이스의 신생 메모리에 의해 백킹된다. 예를 들어, 128MB 로컬 메모리로 구성된 스마트폰의 애플리케이션은 전화기가 컴퓨터 네트워크, 인터넷 또는 로컬 메모리 기기 또는 본 출원에서 설명된 MaaS의 개념을 구현하는 다 른 디바이스에 연결되어 있을 때 64TB의 랜덤 액세스 메모리에 액세스할 수 있다. 도 1은 컴퓨팅 디바이스 또는 서버 컴퓨터가 다른 컴퓨팅 디바이스 및/또는 다른 서버 컴퓨터로부터 메모리를 차용할 수 있고 및/또는 메모리를 대여할 수 있는 시스템을 도시한다. 도 1은 컴퓨터 네트워크 및/또는 인터넷을 통해 연결된 차용자 디바이스 및 대여자 디바이스의 예로서 컴 퓨팅 디바이스(101 및 103) 및 서버 컴퓨터(105 및 107)를 예시하며, 여기에는 제5 세대 셀룰러 네트워크와 같 은 셀룰러 통신 네트워크를 포함할 수 있다. 컴퓨팅 디바이스(101 및 103) 및 서버 컴퓨터(105 및 107) 각각은 다른 디바이스로부터 메모리를 차용할 수 있 고 및/또는 다른 디바이스에 메모리를 대여할 수 있다. 컴퓨팅 디바이스(101 및 103) 및 서버 컴퓨터(105 및 107) 각각은 하나 이상의 통신 디바이스(예를 들어, 117, 137, 157 및 177)를 구비하여 서로 또는 시스템의 다 른 컴퓨팅 디바이스 또는 서버 컴퓨터와 하나 이상의 통신 링크를 수립할 수 있다. 컴퓨팅 디바이스(101 및 103) 및 서버 컴퓨터(105 및 107) 각각은 운영 체제(예를 들어, 113, 133, 153 및 173)의 명령과 같은 명령 및 운영 체제에서 실행되는 애플리케이션 또는 프로그램을 실행하도록 구성된 하나 이상의 프로세서(들)(예를 들어, 115, 135, 155 및 175)를 가질 수 있다. 컴퓨팅 디바이스(101 및 103) 및 서버 컴퓨터(105 및 107) 각각은 개개의 프로세서(예를 들어, 115, 135, 155 및 175)에 (예를 들어, 메모리 버스를 통해) 연결된 로컬 랜덤 액세스 메모리(예를 들어, 111, 131, 151 및 171)를 가질 수 있다. 일부 예들에서, 디바이스 A 또는 디바이스 B는 웨어러블 컴퓨팅 디바이스, 사물 인터넷의 컴퓨팅 디 바이스, 모바일 컴퓨팅 디바이스 등일 수 있다. 일부 예에서, 서버 P 또는 서버 Q는 미니 서버, 개인용 컴퓨터, 메모리 기기, 저장 기기, 네트워크 저장 디바이스, 서버 컴퓨터, 서버 팜 등일 수 있다. 일 예에서, 디바이스 A는 유선 연결, 무선 개인 영역 네트워크(WPAN), 무선 근거리 통신망(WLAN), 및/또는 무선 광역 통신망(WWAN)를 사용하여 디바이스 B, 서버 P 및/또는 서버 Q에 연결될 수 있다. 다른 예에서, 디바이스 B는 유선 연결, 무선 근거리 통신망(WLAN) 및/또는 무선 광역 네트워크(WWAN)를 사 용하여 서버 P 및/또는 서버 Q에 연결될 수 있다. 다른 예에서, 서버 P는 유선 연결, 근거리 통신망, 무선 근거리 통신망(WLAN), 무선 광역 통신망(WWAN) 및 /또는 인터넷을 사용하여 서버 Q에 연결될 수 있다. 서버 P는 서버 Q로부터 메모리를 차용할 수 있고 차용된 메모리 및/또는 로컬 메모리를 디바이스(101 및 103)(및/또는 유사한 디바이스)에 대여할 수 있다. 디바이스 B는 서버 P 및/또는 서버 Q로부 터 메모리를 차용할 수 있고 차용된 메모리 및/또는 로컬 메모리를 디바이스 A(및/또는 유사한 디바이스) 에 대여할 수 있다. 일반적으로, 컴퓨팅 디바이스는 하나 이상의 차용자 디바이스에 메모리를 대여할 수 있고, 하나 이상의 대여자 디바이스로부터 메모리를 차용할 수 있다. 운영 체제(113, 133, 157 및 173)는 애플리케이션 및 프로그램이 물리적 할당에 대한 인식 없이 가상 메모리를 사용할 수 있도록 애플리케이션 및 프로그램에 메모리 서비스를 제공하도록 구성되어 이러한 가상 메모리가 부 분적으로 차용된 메모리에 할당되고, 부분적으로 로컬 메모리에 할당된다(111, 131, 151, 171). 운영 체제와 지 원 하드웨어는 가상 메모리 할당을 관리하기 위해 애플리케이션과 프로그램의 책임을 가지며, 이는 애플리케이 션과 프로그램이 로컬 메모리와 차용된 메모리 할당의 차이를 처리하도록 디자인된 특수 코드 섹션이나 지정된 명령을 갖지 않는 편리함을 제공한다. 일례에서, 서버 Q의 로컬 메모리의 일부가 서버 P에 대여된다. 서버 P는 차용된 메모리의 일부 및/또는 로컬 메모리의 일부를 디바이스 B에 대여하고, 이는 결국 차용된 메모리의 일부 및/또 는 로컬 메모리를 디바이스 A에 대여한다. 따라서, 운영 체제에 의해 디바이스 A의 프로세 서에서 실행되는 애플리케이션에 할당된 가상 메모리는 부분적으로 디바이스 A의 로컬 메모리에, 부분적으로는 디바이스 B의 로컬 메모리, 부분적으로 서버 P의 로컬 메모리 , 및/또는 부분적으로 서버 Q의 로컬 메모리에 상주할 수 있다. 운영 체제(113, 133, 157, 173)는 서로 협력하여 다양한 디바이스(예를 들어, 111, 131, 151 및/또는 171)의 로컬 메모리 중에서 애플리케 이션이 사용하는 가상 메모리의 물리적 할당 및/또는 메모리 서비스를 제공하도록 구성되어, 디바이스 A 및 해 당 로컬 메모리에서 실행되도록 프로그래밍된 애플리케이션이 디바이스 B, 서버 P 및/또는 서버 Q에 의해 디바이스 A에 대여된 차용된 메모리(131, 151 및/또는 171)에 부분적으로 할당된 가상 메모 리로 수정 없이 실행할 수도 있다. 도 2는 근거리 통신망, 광역 통신망 및/또는 5세대 셀룰러 네트워크와 같은 셀룰러 통신 네트워크를 통한 유선 또는 무선 연결과 같은 통신 네트워크 연결을 통해 운영 체제 간 메모리 서비스를 구현하는 차용자 디바이 스 및 대여자 디바이스를 도시한다. 도 2에서, 차용자 디바이스는 대여자 디바이스로부터 메모리를 차용하고; 대여자 디바이스는 메 모리를 차용자 디바이스에 대여한다. 예를 들어, 차용자 디바이스는 도 1의 시스템에서 디바이 스 A, 디바이스 B 또는 서버 P일 수 있다; 대여자 디바이스는 도 1의 시스템에서 디바이스 B, 서버 P 또는 서버 P일 수 있다. 또한 대여자 디바이스 기능은 차용자 디바이스에서 구 현되어 다른 디바이스에 메모리를 대여할 수 있다. 유사하게, 차용자 디바이스 기능은 대여자 디바이스에 서 구현되어 다른 디바이스로부터 메모리를 차용할 수 있다. 도 2에서, 차용자 디바이스는 통신 디바이스, 메모리 관리 유닛(MMU)을 갖는 하나 이상의 프로 세서, 및 로컬 랜덤 액세스 메모리를 갖는다. 프로세서(들) 및 로컬 메모리는 일부 실시예 에서 별도의 컴퓨터 칩에 있을 수 있고/있거나 별도의 집적 회로 다이에 형성될 수 있으며, 다른 실시예에서 동 일한 컴퓨터 칩에 패키징되고/되거나 동일한 집적 회로 다이(예를 들어, SoC(System-On-a-Chip)에)에 형성될 수 있다. 차용자 디바이스의 운영 체제는 메모리 맵을 유지하도록 구성된 메모리 서비스 모듈을 포 함한다. 메모리 맵은 가상 메모리와 물리적 메모리 사이의 매핑을 식별하며, 여기서 물리적 메모리는 부분 적으로 차용자 디바이스의 로컬 메모리에 있고, 부분적으로 대여자 디바이스의 대여된 메모리 에 있을 수 있다. 운영 체제는 차용자 디바이스에서 실행되는 하나 이상의 애플리케이션(예를 들어, 212)에 가상 메모리를 서비스한다. 프로세서(들)는 애플리케이션 코드의 명령을 실행함으로써 애플리케이션을 실행할 수 있다. 애플리케이션 메모리 판독 및 기록 명령은 가상 메모리를 사용할 수 있다. 메모리 관리 유닛(MMU)는 메모리 맵에 따라 가상 메모리 어드레스를 물리적 메모리 어드레스로 변환한다. 차용자 디바이스가 대여자 디바이스로부터 메모리를 차용할 때, 차용된 메모리는 가상으로 차용 자 디바이스에 있고, 물리적으로 로컬 랜덤 액세스 메모리의 대여된 메모리와 같이 대여자 디바 이스에 있다. 옵션으로, 대여자 디바이스는 주변 버스 및/또는 디바이스 컨트롤러를 통해 대여자 디 바이스의 프로세서(들)에 결합된 저장 디바이스에서 대여된 메모리의 일부 또는 전체를 구 성할 수 있다. 예를 들어, 대여자 디바이스의 운영 체제는 대여자 디바이스에서 실행되는 애플 리케이션(예를 들어, 232)에 가상 메모리로서 메모리 자원을 할당하는 것과 유사한 방식으로 메모리 자원의 일 부를 차용자 디바이스의 운영 체제에 가상 메모리로 할당할 수 있다. 따라서, 차용자 디바이스 의 운영 체제에 의해 사용되는 차용된 메모리는 애플리케이션에 의해 사용되는 가상 메모리로서 및/또는 대여자 디바이스의 다른 차용자에 의해 사용되는 차용된 메모리로서 통합 가상 메모리 어드레스 공간에 있을 수 있다. 대안적으로, 대여자 디바이스의 운영 체제는 차용된 메모리에 대한 가상 메모리 컴포넌트를 생성할 수 있고; 차용자 디바이스의 운영 체제는 차용자 디바이스의 가상 메 모리 컴포넌트에 액세스 가능하게 될 수 있다. 가상 메모리 컴포넌트에 대한 가상 메모리 컨트롤러는 차용자 디 바이스에 액세스 가능한 가상 메모리 컴포넌트에 액세스하기 위해 운영 체제에서 구현될 수 있다. MMU는 가상 메모리 컨트롤러를 가속화하기 위해 하드웨어 블록을 구현할 수 있으며, 그렇게 함으로써 가상 메모리 컴포넌트 액세스 속도를 향상시킬 수 있다. 일부 예에서 차용된 메모리는 암시적이어서, 차용자 디바이스에서 실행되는 애플리케이션의 나머지 가상 메모리와 구별할 수 없다. 메모리 맵을 판독하여 가상 페이지 어드레스를 물리적 어드레스로 변환할 때만 구별되며, 해당 변환 시 물리적 어드레스는 대여된 메모리에 있는 것으로 나타난다. 다른 예에서, 운 영 체제는 가상 메모리가 대여자 디바이스에 의해 제공되는 차용된 메모리에 속하는 경우 가상 메모리의 일부에 대한 명시적 식별을 저장한다. 모든 경우에 운영 체제는 해당 디바이스로 마이그레이션한 후 차용자 디바이스에 또는 대여자 디바이스에 물리적으로 대여된 메모리에 있는 차용된 메모리 인 가상 메모리로부터 판독하고 가상 메모리에 기록 위해 대여자 디바이스에 액세스하기 위해 메모리 맵을 구성한다. 메모리 맵은 페이지 테이블을 통해 구현될 수 있다. 페이지 테이블의 일부는 메모리 관리 유닛(MMU) 에 캐싱되어 프로세서(들)에서 실행된 명령이 메모리 관리 유닛(MMU)에 캐싱된 페이지 테이블의 부분 에 정의된 가상 어드레스에 액세스할 때, 메모리 관리 유닛은 가상 어드레스를 물리적 어드레스로 변환한 다. 성공적인 어드레스 변환은 프로세서(들)가 운영 체제의 코드를 실행할 필요 없이 메모리 액세스를 진행할 수 있게 한다. 메모리 관리 유닛(MMU)이 메모리 관리 유닛(MMU)에 캐시된 페이지 테이블을 사용하여 가상 메모리 어 드레스를 성공적으로 변환할 수 없는 경우, 페이지 테이블 엔트리 캐시 미스(page table entry cache miss)가 생성되고, 이는 프로세서가 이 캐시 미스를 해결하기 위해 운영 체제의 메모리 서비스의 명령을 실행하게 한다. 일부 구현예에서 MMU는 MMU의 캐시에서 페이지 테이블 엔트리 캐시 미스를 해결하도록 설 계된 하드웨어 IP를 포함한다. MMU의 일부인 이 IP는 물리적 메모리에 저장된 페이지 테이블로부터 필수 페이지 테이블 엔트리를 추출한다. 필수 엔트리가 존재하지 않거나 존재하지만 가상 페이지 어드레스를 물리적 대여된 메모리의 어드레스로 변환하면, 이 페이지 폴트가 이 페이지에 대해 생성된다. 이 폴트는 하드웨어 에서 직접 MMU 및 통신 디바이스에 의해 해결될 수 있다. 대안적으로, 이 폴트는 하드웨어 블록 : MMU, 프로세서, 통신 디바이스)에 의해 지원되는 소프트웨어의 운영 체제 및 메모리 서비 스에 의해 해결될 수 있다. 운영 체제 또는 MMU의 메모리 서비스가 액세스되는 가상 메모리 어드레스가 차용된 메모리(20 4)에 있다고 결정할 때, 메모리 서비스 또는 MMU는 로컬 물리적 메모리의 물리적 페이지를 할당 하고, 통신 디바이스(217, 237) 및 컴퓨터 네트워크 연결을 통해 대여자 디바이스와 통신하여 물리적 대여된 메모리에서 물리적 로컬 메모리로 차용된 메모리의 페이지를 마이그레이션하고, 가상 페 이지를 할당된 로컬 물리적 페이지에 매핑하는 페이지 테이블 엔트리를 생성하고 페이지 테이블 엔트리를 메모 리 관리 유닛(MMU) 에 로드할 수 있다. 따라서, 페이지 폴트 이전에, 차용된 메모리의 가상 페이지는 대여자 디바이스의 대여된 메모리에 물리적으로 위치된다. 페이지 폴트 처리 후, 가상 페이지는 로컬 메모리에 위치된다. 대여자 디바이스의 대여된 메모리에 있는 페이지의 콘텐츠는 미래의 사용 및 다른 목적을 위해 여전히 저장될 수 있다. 마이그레이션에 사용할 수 있는 해제 로컬 페이지가 없을 때, 메모리 서비스는 현재 로컬 메모리에 있는 선택된 가상 페이지를 대여된 메모리로 축출할 수 있다. 선택된 가상 페이지를 대여자 디바이스(20 3)로 축출할 때, 메모리 서비스는 대여자 디바이스와 통신하여 가상 페이지의 콘텐츠를 로컬 메모리 에서 대여된 메모리로 송신하고, 메모리 맵을 업데이트한다. 로컬 메모리에서 가상 페이지 를 축출한 후, 축출된 가상 페이지에 사용되었던 로컬 메모리의 공간은 해제될 수 있다. 예를 들어, 메모리 서비스는 최소로 빈번하게 사용된 가상 페이지 또는 최소로 최근에 사용된 가상 페이지 를 축출하도록 구성될 수 있다. 도 2에서, 대여자 디바이스는 통신 디바이스, 메모리 관리 유닛(MMU)을 갖는 하나 이상의 프로 세서, 및 로컬 랜덤 액세스 메모리를 갖는다. 옵션으로, 대여자 디바이스는 주변 버스 및/또는 컴퓨터 네트워크를 통해 프로세서(들)에 연결된 하나 이상의 저장 디바이스를 포함한다. 예를 들어, 저장 디바이스는 솔리드 스테이트 드라이브(SSD) 또는 하드 드라이브(HD)일 수 있다. 대여자 디바이스의 운영 체제는 메모리 맵을 유지하도록 구성된 메모리 서비스 모듈을 포 함한다. 메모리 맵은 가상 메모리와 물리적 메모리 간의 매핑을 식별한다. 메모리 맵은 메모리에 저 장되거나 콘텐츠 어드레스 지정 가능 메모리 또는 특수 캐시와 같은 전용 메모리일 수 있다. 운영 체제는 해당 애플리케이션을 서비스하는 차용자 디바이스와 유사한 방식으로 대여자 디바이스에서 실행 되는 하나 이상의 애플리케이션에 가상 메모리를 서비스한다. 옵션으로, 대여자 디바이스는 통합된 가상 메모리 공간에서 차용자 디바이스에 대여된 메모리를 프로비저닝한다. 차용자 디바이스의 메모리 서비스는 메모리 서비스에 의해 프로비저닝된 가상 메모리를 사용하는 애플리케이션과 동일한 방식으로 차용된 메모리를 사용한다. 예를 들어, 대여자 디바이스의 메모리 서비스는 대여자 디바이스에서 실행되는 애플리케이션에 가상 메모리를 할당하고, 메모리 서비스가 대여자 디바이스에서 실행되는 애플리케이션인 것처럼 차용자 디바이스의 메모리 서비스에 의해 사용하는 차용된 메모리로 가상 메모리를 할당할 수 있다. 따라서, 대여자 디 바이스 및 차용자 디바이스(및 대여자 디바이스로부터 메모리를 차용한 다른 디바이스)에서 실 행되는 애플리케이션은 통합된 가상 어드레스 공간에서 동작할 수 있다. 통합된 가상 어드레스 공간을 기 반으로 협력 계산이 구성될 수 있다. 또한, 대여자 디바이스가 다른 디바이스/서버(예를 들어, 105 또는 107)로부터 메모리를 차용할 때, 차용된 메모리는 통합 가상 어드레스 공간에서도 프로비저닝될 수 있다. 통합 어드레스 공간은 컴퓨팅 디바이스 간의 데이터 공유 및 협업 계산을 가능하게 할 수 있다.대여자 디바이스의 메모리 서비스는 차용된 디바이스에 의해 액세스된 차용된 메모리에 대 응하는 대여된 메모리의 가상 어드레스와 대여된 메모리의 물리적 어드레스 간의 매핑을 포함하는 메 모리 맵을 유지할 수 있다. 예를 들어, 차용된 페이지에 액세스할 때 차용된 디바이스에 의해 식별된 가상 페이지의 페이지 테이블 엔트리는 가상 페이지의 어드레스와 차용자 디바이스를 대신하여 계산을 수 행하기 위해 대여자 디바이스의 프로세서(들)에 대한 대여된 메모리의 물리적 어드레스 간의 변환을 가능하게 하기 위해 메모리 관리 유닛(MMU)에 로드될 수 있다. 옵션으로, 대여자 디바이스는 메모리 관리 유닛과 유사한 하드웨어를 포함하여 차용자 디바이스에 알려진 차용된 메모리와 대여자 디 바이스에서 물리적으로 액세스 가능한 대여된 메모리 간의 매핑을 식별하는 메모리 맵을 사용하 여 대여자 디바이스와 차용자 디바이스 간의 최적화된 및/또는 가속화된 데이터 전송을 가능하게 할 수 있다. 도 3은 일 실시예에 따른 차용된 메모리를 구현하는 기술을 예시한다. 예를 들어, 도 3의 기술은 도 2에 예시된 차용자 디바이스에 구현될 수 있다. 도 3은 메모리, 물리적 어드레스(예를 들어, 257)를 사용하여 메모리에 액세스하도록 구성된 메모리 관리 유닛(MMU) 및 가상 어드레스 영역(예를 들어,, 261, 263, 265, …)과 가상 메모리 영역이 매핑되는 어드레스 영역, 예를 들어, 물리적 어드레스 영역(예를 들어, 281, 283, …) 및 차용된 메모리 영역(예를 들어, 273, 275, …) 간의 매핑을 정의하는 메모리 맵을 예시한다. 예를 들어, 차용된 메모리 어드레스 영역(예를 들어, 273, 275, …)은 대여자 디바이스에 의해 할당된 가 상 어드레스 영역을 차용된 디바이스에 프로비저닝/대여된 메모리로 식별하도록 구성될 수 있다. 예를 들어, 가상 어드레스 영역 A는 메모리 맵의 물리적 어드레스 영역과 연관되어 가상 메모리 영역이 현재 로컬 물리적 메모리의 대응하는 영역에 직접 매핑됨을 나타낸다. 예를 들어, 가상 어드레스 영역 B는 메모리 맵에서 차용된 메모리 어드레스 영역 X 및 물리적 어드레스 영역 S와 연관되어 가상 어드레스 영역 B가 은 차용된 메모리 어드레스 영역 X에 매핑 되고 물리적 어드레스 영역 S에 물리적으로 상주한다. 따라서, 가상 어드레스 영역 B에 대한 액세스 는 로컬 메모리의 물리 어드레스 영역 S에 액세스함으로써 이루어질 수 있다. 가상 어드레스 영역 C는 메모리 맵에서 차용된 메모리 어드레스 영역 Y와 연관되고 메모리 맵의 임의의 물리적 어드레스 영역과 연관되지 않는다. 따라서, 가상 어드레스 영역 C에 액세스하기 위해 차용자 디바이스는 대여자 디바이스와 통신해야 한다. 물리적 어드레스 영역 S의 콘텐츠는 물리적 어드레스 영역 S를 해제하기 위해 대여자 디바이스로 축 출될 수 있다. 물리적 어드레스 영역 S가 해제되면, 차용된 메모리 어드레스 영역 Y와 같은 다른 차 용된 메모리 어드레스 영역의 물리적 배치에 사용될 수 있다. 차용된 메모리 어드레스 영역 Y의 콘텐츠가 대여자 디바이스에서 물리적 어드레스 영역 S에 대여자 디바이스로 마이그레이션되면, 물리적 어드레스 영 역 S는 통합 어드레스 공간의 차용된 메모리 어드레스 영역 Y에 매핑되고, 도 4에 예시된 차용자 디 바이스의 물리적 어드레스 영역 S에 물리적으로 위치된 가상 어드레스 영역 C에 대한 액세스를 제공 하기 위해 사용될 수 있다. 도 5에서, 메모리 관리 유닛(MMU)(예를 들어, 도 3에 예시된 과 유사)은 가상 대 물리적 메모리 맵 (예를 들어, 차용자 디바이스의 운영 체제에 의해 유지되는 메모리 맵의 부분)을 저장할 수 있 는 변환 색인 버퍼(TLB)(예를 들어, 도 3에 예시된 과 유사)를 갖는다. 차용자 디바이스의 프로세서 가 가상 어드레스를 사용하는 명령을 실행할 때, TLB는 가상 대 물리적 메모리 맵을 사용 하여 가상 어드레스를 물리적 어드레스로 변환하고; 메모리 관리 유닛(MMU)은 (예를 들어, 메모 리 버스를 통해) 메모리의 메모리 페이지에 액세스하기 위해 물리적 어드레스를 사용할 수 있다. TLB에 로드된 가상 대 물리적 메모리 맵은 전형적으로 차용자 디바이스의 운영 체제에 의 해 관리되는 메모리 맵의 부분이다. 차용자 디바이스의 프로세서가 TLB의 가상 대 물리적 메모리 맵에 포함되지 않은 가상 어드레스를 사용하는 명령을 실행할 때, 메모리 관리 유닛(MMU) 프 로세서가 운영 체제를 실행하게 할 수 있으며, 이는 TLB에서 가상 대 물리적 메모리 맵의 일부를 교체하도록 프로그래밍되어 TLB의 업데이트된 가상 대 물리적 메모리 맵이 가상 어드레스(예 를 들어, 255)를 물리적 어드레스(예를 들어, 257)로 변환하기 위한 데이터를 포함한다.메모리 관리 유닛(MMU)은 전형적으로 차용자 디바이스의 메모리 관리 유닛(MMU)과 차용자 디바 이스의 로컬 메모리 사이에 연결된 메모리 버스를 통해 메모리에 액세스하도록 구성된다. 가상 어드레스가 처음에 차용된 메모리 어드레스 영역(예를 들어, 275)에 매핑된 가상 어드레스 영역(예를 들어, 265)에 있을 때, 운영 체제는 대여자 디바이스의 대여된 메모리로부터 이 영역의 콘텐츠를 메모리 의 물리적 어드레스 영역(예를 들어, 283)으로 마이그레이션할 수 있고, TLB의 가상 대 물리적 메모 리 맵을 업데이트하여 가상 어드레스를 차용된 메모리 어드레스 영역(예를 들어, 275)으로 변환하지 않고 가상 어드레스에 직접 대응하는 물리적 어드레스로 가상 어드레스를 변환할 수 있도록 한다. 일부 실시예에서, 메모리 관리 유닛(MMU)은 명시적 마이그레이션 없이 컴퓨터 네트워크 연결(예를 들어, 205)을 통해 통신 디바이스를 사용하여 차용된 메모리에 액세스하도록 추가로 구성된다. 이러한 상황 에서, 운영 체제는 가상 어드레스 영역(예를 들어, 265)의 콘텐츠를 마이그레이션할 필요가 없다. 차용된 메모리의 물리적 어드레스는 대여자 디바이스의 대여된 메모리에 있는 메모리 페이지(26 0)에 액세스하기 위한 통신 디바이스에 대한 정보를 포함할 수 있다. 물리적 어드레스를 사용하고 통 신 디바이스를 통해 이루어진 메모리 액세스 요청은 운영 체제를 통해 대여자 디바이스에서 처 리될 수 있다. 대안적으로, 통신 디바이스 및/또는 메모리 관리 유닛(MMS)은 운영 체제를 실행 하지 않고 (예를 들어, 판독 또는 기록을 위해) 대여된 메모리에 이러한 액세스 요청을 처리하도록 구성될 수 있다 (예를 들어, 대여자 디바이스의 MMS의 TLB에 캐싱된 가상 대 물리적 메모리 맵에 기초하여 또는 유사한 동작을 수행하도록 대여자 디바이스에 구성된 하드웨어 가속 컴포넌트에 기초하여). 가상 대 물리적 메모리 맵은 페이지 테이블 엔트리의 형태로 구현될 수 있다. 도 6은 컴퓨팅 시스템의 차용자-대여자 메모리 계층을 예시한다. 도 6에서, 대여자 디바이스는 도 2의 차용자 디바이스가 대여자 디바이스로부터 메모리를 대여 하는 것과 유사한 방식으로 하나 이상의 대여자 서버로부터 메모리를 차용할 수 있다. 대여자 디바이스 는 차용자 디바이스에 대여를 위한 사용 가능한 메모리로 로컬 물리적 메모리(예를 들어, 도 2 에 도시된 231)의 적어도 일부 및/또는 대여자 서버(예를 들어, 245)로부터 차용된 메모리 중 일부를 풀링 (pool)한다. 하나 이상의 차용자 디바이스는 대여자 디바이스로부터 메모리를 차용할 수 있다. 전형적인 차용자 메모리는 다수의 차용된 메모리 영역(295, 297, …, 299) 및 다수의 로컬 메모리 영역 (291, 293, …)을 가질 수 있다. 차용자 디바이스의 차용된 메모리 영역(295, 297, …, 299)은 대여자 디 바이스의 대여된 메모리에서 차용자 디바이스(291, 293, …)의 로컬 메모리 영역으로의 마이그레이션을 통해 액 세스될 수 있다. 차용된 메모리 영역(295, 297, …, 299)이 차용자 디바이스에서 사용되지 않는 경우, 도 4 및 도 5에 도시된 바와 같이 대여자 디바이스로 다시 축출될 수 있다. 유사하게, 대여자 디바이스는 자신의 로컬 메모리 또는 대여자 서버로부터 차용된 로컬 메모리에서 차용자 디바이스에 대여된 영역(예를 들어, 299)을 호스팅할 수 있다. 일반적으로, 하나 이상의 대여자 디바이스가 차용자 디바이스에 메모리 서비스를 제공하는데 사용될 수 있다; 그리고 하나 이상의 대여자 서버가 계층 구조에 구성될 수 있다. 옵션으로, 계층에서 서비스로 제공되는 메모리(예를 들어, 295, 297, …, 299)는 통합된 가상 어드레스 공간에 구성된다. 따라서, 차용자 디바이스, 대여자 디바이스 및 대여자 서버는 통합 가상 어드레스 공 간의 가상 어드레스를 참조하여 메모리의 데이터를 처리하는데 협력할 수 있다. 예를 들어, 도 6의 차용자 디바이스는 도 1의 시스템에서 디바이스 A 또는 디바이스 B일 수 있 다. 예를 들어, 도 6의 대여자 디바이스는 도 1의 시스템에서 디바이스 B 또는 서버 P일 수 있다. 예를 들어, 도 6의 대여자 서버는 도 1의 시스템에서 서버 P 또는 Q일 수 있다. 도 7은 통신 네트워크 연결을 통해 운영 체제 간 메모리 서비스를 구현하는 방법을 도시한다. 예를 들어, 도 7 의 방법은 도 1의 시스템에서 구현될 수 있고, 차용자-대여자 구성은 도 2에 예시되고 및/또는 차용자-대여자 메모리 계층은 도 6에 예시된다. 블록에서, 차용자 디바이스에서 대여자 디바이스로의 통신 연결이 수립된다. 블록에서, 차용자 디바이스는 대여자 디바이스로부터 일정량의 메모리를 차용하기 위해 대여자 디바이스와 통신한다. 대여자 디바이스는 차용자 디바이스가 차용된 대여된 메모리를 차용 된 메모리가 가상 메모리로 사용할 수 있는 차용된 메모리로 할당할 수 있다. 메모리를 차용/대여함 으로써, 디바이스(201 및 203)는 차용자 디바이스의 프로세서(들)가 차용된 메모리/대여된 메모리 를 판독 및/또는 기록할 수 있는 구성을 수립한다. 일부 경우에, 대여된 메모리는 그 자체가 다른 대 여자 디바이스(예를 들어, 245)로부터 차용된 메모리이다. 블록에서, 차용자 디바이스의 운영 체제는 차용된 메모리를 커버하도록 차용자 디바이스 의 가상/논리적 어드레스 공간을 확장한다. 차용자 디바이스의 프로세서에서 실행되는 애플리케 이션(예를 들어, 212)은 차용된 메모리와 로컬 메모리를 구분하지 않고 공간의 가상 어드레스를 사용 할 수 있다. 블록에서, 차용자 디바이스의 운영 체제는 논리 어드레스 공간의 확장된 부분을 차용된 메모리 에 매핑하는 메모리 맵(예를 들어, 페이지 테이블의 형태로)을 생성한다. 블록에서, 차용자 디바이스의 운영 체제는 논리 어드레스 공간의 확장된 부분을 애플리케이션 에 할당한다. 블록에서, 차용자 디바이스의 운영 체제는 차용자 디바이스의 물리적 메모리의 일부 에 대한 액세스를 통해 차용된 메모리에 대한 액세스를 서비스한다. 도 8은 일 실시예에 따른 차용된 메모리의 페이지를 서비스하는 방법을 도시한다. 예를 들어, 도 8의 방법은 도 1의 시스템에서 구현될 수 있고, 차용자-대여자 구성은 도 2에 예시되고 및/또는 차용자-대여자 메모리 계층은 도 6에 예시된다. 예를 들어, 도 8의 방법은 도 7의 방법의 블록을 구현하는데 사용될 수 있다. 블록에서, 차용자 디바이스는 차용된 메모리 페이지를 위해 차용자 디바이스의 물리적 메 모리의 페이지를 리저브한다. 블록에서, 차용자 디바이스의 프로세서는 차용된 메모리의 메모리 페이지에 대응하는 가상 메모리 어드레스에 액세스한다. 차용된 메모리 페이지는 물리적으로 대여자 디바이스의 대여된 메모리에 있을 수 있다. 블록에서, 차용자 디바이스의 메모리 관리 유닛(MMU)은 가상 메모리 어드레스를 로컬 물리 적 메모리 어드레스로 변환하기 위해 TLB(Translation Lookaside Buffer)에서 이용 가능한 페이지 테이블 엔트리가 없다고 결정한다. 그러한 결정(예를 들어, TLB 미스)은 차용자 디바이스가 메모리 맵에서 페이지 테이블 엔트리를 검색하기 위해 운영 체제를 실행하게 한다. 블록에서, 차용자 디바이스 상에서 실행되는 운영 체제는 페이지의 가상 메모리 어드레스를 페 이지의 차용된 메모리 어드레스로 변환하는 메모리 맵의 페이지 테이블 엔트리를 식별한다. 블록 에서, 차용자 디바이스에서 실행되는 운영 체제는 대여자 디바이스와 통신하고, 차용된 메 모리 어드레스를 가진 차용된 페이지의 물리적 콘텐츠를 로컬 메모리로 마이그레이션하고 해당 콘텐츠를 로컬 메모리의 사용 가능한 물리적 어드레스에 배치한다. 대여자 디바이스에서 차용자 디바이스로의 차용된 페이지의 페이지 마이그레이션을 위한 로컬 메모리가 충분하지 않은 경우, 차용자 디바이스에서 대여자 디바이스로 다른 차용된 페이지의 차용된 페이지 축출이 수행될 필요가 있을 수 있다. 블록에서, 차용자 디바이스에서 실행되는 운영 체제는 차용된 페이지의 가상 어드레스(예를 들 어, 255)를 로컬 메모리의 물리적 어드레스에 매핑하는 페이지 테이블 엔트리를 생성한다. 블록에서, 차용자 디바이스에서 실행되는 운영 체제는 페이지 테이블 엔트리를 TLB(Translation Lookaside Buffer)에 로드하고, 이는 프로세서가 변환된 물리적 메모리 어드레스를 사용하여 가상 메 모리 어드레스를 계속 액세스할 수 있도록 한다. 일부 상황에서, 차용자 디바이스와 대여자 디바이스 사이의 컴퓨터 네트워크 연결은 통신 대역 폭이 제한되고/되거나 성능 저하된다. 차용자 디바이스는 메모리 영역의 중요도에 기초하여 다른 메모리 영역에 할당된 네트워크 트래픽/대역폭을 스로틀링할 수 있다. 예를 들어, 차용된 메모리의 페이지는 메모리에 저장된 콘텐츠의 카테고리, 차용된 메모리를 사용하는 애 플리케이션의 우선 순위, 및/또는 애플리케이션에 의해 제안된 데이터 중요도 레벨에 기초한 중요도 표시자로 태깅될 수 있다. 차용자 디바이스와 대여자 디바이스 사이의 연결 대역폭이 성능 저하되면, 가장 덜중요한 페이지는 이러한 페이지의 페치, 폐기, 축출 및/또는 마이그레이션을 위해 더 적은 통신 대역폭을 할당 하여 액세스할 가능성을 낮추도록 구성할 수 있다. 차용자 디바이스와 대여자 디바이스 사이의 연결 대역폭의 성능 저하를 고려하여 가장 중요하지 않은 페이지에 대한 액세스가 느려지고 및/또는 일시적으로 차단 될 수 있다. 중지 메모리의 동작은 해당 메모리로부터 요구된 로드를 시도하는 애플리케이션을 정지 또는 일시 중단함으로써 준비될 수 있다. 해당 시간 동안 애플리케이션이 진행되지 않을 수 있다. 애플리케이션이 차용된 메모리에 액세 스하지 못하도록 차단된 경우 정상적인 성능 저하를 수행할 수 있다. 애플리케이션은 로드 또는 저장 동작이 일 시 중단될 수 있음을 인식할 수 있다; 매우 다른 프로그래밍 패러다임이 사용될 수 있다. 예를 들어, 각각의 메 모리 액세스는 트라이-캐치(try-catch) 예외 래퍼(exception wrapper)로 래핑될 수 있다. 그러나, 이러한 접근 방식에는 상당한 비용이 든다. 또한, 이러한 예외를 정상적으로 처리하도록 애플리케이션이 처리될 수 있다. 예 를 들어, 애플리케이션은 중단된 로드/저장 동작과 관련하여 일부 컨텍스트를 개방 상태로 두고 해당 컨텍스트 를 관리하여 해당 로드/저장이 결국 서비스되어야 하는지 여부를 데이터 이동 인프라에 알릴 수 있다. 차용된 메모리 페이지가 중요도(criticality)에 따라 스로틀링될 때, 차용된 메모리에서 실행되는 애플리 케이션은 치명적인 오류 없이 여전히 정상적으로 성능 저하될 수 있으며, 도달 가능/사용 가능한 콘텐츠가 적은 감소된 기능으로 진행할 수 있다. 예를 들어, 미디어 라이브러리는 사용 빈도, 사용 이력 및/또는 예측된 사용량에 기초하여 콘텐츠를 우선 순위 화할 수 있다. 우선 순위화는 콘텐츠가 저장되는 차용된 메모리 페이지의 중요도를 결정하는데 사용될 수 있다. 따라서, 차용된 메모리의 덜 중요한 콘텐츠에 대한 액세스가 미디어 라이브러리의 사용 가능성에 대한 영향이 감소하여 제한되고/되거나 차단될 수 있다. 도 9는 서비스로서의 메모리에 대한 네트워크 트래픽이 스로틀링될 수 있는 것에 기초하여 상이한 중요도 레벨 (또는 우선순위 레벨)의 메모리 영역을 갖는 차용자 디바이스를 도시한다. 예를 들어, 차용자 디바이스 는 도 2에 도시된 방식으로 구현될 수 있고 및/또는 도 6에 예시된 계층 구조에서 또는 도 1에 예시된 시 스템에서 메모리를 차용할 수 있다. 도 9에서, 차용된 메모리의 메모리 영역(295, 297, …, 299)은 중요도 레벨(401, 403, …, 405)로 개별적 으로 라벨링될 수 있다. 중요도 레벨(401, 403, …, 405)은 메모리 영역(295, 297, … 299) 간의 상대적 우선 순위를 순위화한다. 차용자 디바이스와 대여자 디바이스(들)(예를 들어, 203) 간의 통신에 사용되는 네트 워크 대역폭은 중요도 레벨(401, 403, …, 405)에 따라 할당될 수 있다. 예를 들어, 다수의 영역(예를 들어, 295, 297)이 대여자 디바이스에서 차용자 디바이스로 마이그레이 션되어야 하는 경우, 영역(예를 들어, 295, 297)은 중요도 레벨에 따라(예를 들어, 401, 403) 순서대로 마이그 레이션될 수 있다. 이러한 배열에서, 높은 중요도 레벨의 메모리 영역에 대한 반복적인 요청은 낮은 중요도 레 벨의 메모리 영역에 대한 액세스를 무기한 지연시킬 수 있다. 대안적으로, 대역폭은 상이한 중요도 레벨의 다수의 영역(예를 들어, 295, 297) 사이에서 공유될 수 있다. 예를 들어, 주어진 시간 기간 내 다른 영역에 대해 허용된 네트워크 연결을 통한 데이터 통신의 양은 메모리 영 역의 중요도 레벨에 기초하여 결정된 비율에 할당될 수 있다. 따라서, 낮은 중요도 레벨의 메모리 페이지의 콘 텐츠를 페치하는 것은 높은 중요도 레벨의 메모리 페이지의 콘텐츠를 페치하는 것보다 더 오래 걸릴 것이다. 그 러나, 낮은 중요도 페이지의 페치는 높은 중요도 페이지의 페치에 의해 완전히 차단되지는 않다. 또한, 전체 가 용 대역폭이 성능 저하될 때 높은 중요도 페이지에 대한 액세스 성능이 낮은 중요도 페이지보다 덜 심각하게 성 능 저하될 수 있도록 전체 가용 대역폭에 기초하여 비율이 조정될 수 있다. 따라서, 차용자 디바이스에서 실행 되는 애플리케이션에 대한 사용자 경험은 덜 중요한 측면의 액세스 속도를 선택적으로 성능 저하시켜 최적화될 수 있다. 도 9에서, 로컬 메모리의 메모리 영역(예를 들어, 291, …, 293)의 콘텐츠 또한 중요도 레벨(예를 들어, 407, …, 409)에 따라 라벨링될 수 있다. 중요도 레벨(예를 들어, 407, …, 409)은 전체 가용 대역폭의 상당한 성능 저하를 예상하여 덜 중요한 콘텐츠를 차용된 메모리로 예측 축출 또는 마이그레이션하는데 사용될 수 있다. 예를 들어, 서브 페이지 세분화도에서의 대역폭 공유의 특정 모델에서, 링크 레벨 대역폭 관리 능력 또는 링크 에 대한 강제 청크가 사용될 수 있다. 이러한 구현은 잠재적으로 비효율적인 비 스로틀(non-throttle) 시나리오 로 이어질 수 있다. 대안적으로, 관리의 세분화도가 페이지(서브 페이지 대신)인 경우, 단일 페이지를 페치하는데 걸리는 실제 시간이 아니라 페치된 페이지 속도가 느릴 수 있다. 특정 구현예에서, 낮은 중요도 레벨의 메모 리 페이지의 콘텐츠를 페치하는 것은 높은 중요도 레벨의 메모리 페이지의 콘텐츠를 페치하는 것보다 더 오랜 시간이 걸릴 수 있다. 다른 구현예에서, 낮은 중요도 페이지를 페치하는데 걸리는 지속 시간은 실질적으로 일정 하게 유지될 수 있지만 낮은 중요도 페이지의 그룹이 페치될 수 있는 속도는 높은 중요도 페이지의 그룹에 비해 느릴 수 있다. 예를 들어, 일부 경우에, 차용자 디바이스는 여러 대여자 디바이스(예를 들어, 103, 105 및/또는 107)로부 터 메모리를 차용한다. 예를 들어, 차용자 디바이스는 하나의 대여자(예를 들어, 105 또는 107)에게 차용 자 디바이스에 대여된 메모리 페이지를 다른 대여자(예를 들어, 103 또는 105)에게 직접 전송하거나 복사 하도록 지시할 수 있다. 대안적으로, 차용자 디바이스는 메모리 페이지를 하나의 대여자(예를 들어, 105 또는 107)에서 로컬 메모리로 마이그레이션한 페이지를 다른 대여자(예를 들어, 103 또는 105)로 축출할 수 있 다. 도 10은 일 실시예에 따른 메모리 맵에서 메모리 영역의 중요도 레벨(또는 우선순위 레벨)을 태깅하는 것을 예 시한다. 예를 들어, 도 10의 메모리 맵은 도 9의 중요도 라벨링을 구현하기 위해 사용될 수 있다. 도 10에서, 가상 메모리 어드레스 영역(261, 263, 265, …)은 도 3, 4 또는 5와 유사한 방식으로 물리적 어드레 스 영역(282, 283) 및 차용된 메모리 어드레스 영역(273, 275, …)에 매핑될 수 있다. 예를 들어, 메모리 맵 은 페이지 테이블의 형태로 지정될 수 있다. 또한, 각각의 가상 어드레스 영역(261, 263, 265, …)에 대해, 메모리 맵은 중요도 레벨(예를 들어, 411, 413 또는 415)을 포함할 수 있다. 중요도 레벨(예를 들어, 411, 413 또는 415)은 가상 어드레스 영역(예를 들어, 261, 263 또는 265)의 대역폭의 공유를 결정하는데 사용될 수 있고 차용자 디바이스와 대여자 디바 이스 사이에서 데이터를 통신하는데 사용될 수 있다. 도 11은 일 실시예에 따른 메모리 영역의 중요도 레벨/우선순위 레벨을 식별하는 방법을 예시한다. 예를 들어, 도 11의 방법은 도 9 내지 도 10의 중요도 레벨(예를 들어, 401 내지 415) 중 임의의 것을 결정하는데 사용될 수 있다. 도 11에서, 메모리 영역의 콘텐츠의 중요도 레벨은 콘텐츠 카테고리, 콘텐츠를 제어하는 애플리케이 션(예를 들어, 212)의 우선 순위, 및/또는 콘텐츠에 대한 애플리케이션(예를 들어, 212)에 의해 요청된 우 선순위에 기초하여 결정될 수 있다. 상이한 콘텐츠 카테고리는 미리 결정된 가중치를 가질 수 있다. 애플리케이션이 데이터를 저장하기 위한 메모리 페이지를 할당할 때, 애플리케이션은 애플리케이션 상태, 이력/로그 데이터, 미디어, 센서 데이터 등과 같은 메 모리 페이지의 콘텐츠 카테고리를 식별할 수 있다. 운영 체제는 콘텐츠 카테고리에 기초하여 중 요도에 대한 미리 결정된 가중치를 할당할 수 있다. 상이한 애플리케이션은 그것들의 중요도에 대해 미리 결정된 가중치를 가질 수 있다. 사용자 디바이스의 사용자 는 다른 애플리케이션에 대한 경험보다 하나의 애플리케이션에 대한 경험을 더 가치 있게 여기고 따라서, 상이한 애플리케이션에 대한 가중치 할당을 맞춤화할 수 있다. 일부 경우에, 상이한 애플리케이션이 상호 종속 성을 가질 수 있다. 따라서, 다른 애플리케이션에 중요한 서비스를 제공하는 애플리케이션에 더 높은 우선순위 를 지정할 수 있다. 동일한 애플리케이션 및 동일한 콘텐츠 카테고리의 데이터의 상이한 서브 세트는 상이한 우선순위를 가질 수 있다. 애플리케이션이 맞춤형 우선 순위를 요청하도록 프로그래밍될 때, 애플리케이션 은 운영 체제에 이용 가능하지 않을 수 있는 정보에 기초하여 개선된 예측(예를 들어, 439)을 할 수 있다. 애플리케이션이 맞춤형 우선순위를 요청하지 않는 경우, 운영 체제는 애플리케이션의 메모 리 사용량을 추적하고 콘텐츠에 대한 사용량 기반 우선순위를 요청할 수 있다. 콘텐츠 카테고리, 애플리케이션 우선순위, … 및/또는 요청된 우선순위를 조합하여 중요도 레벨 을 생성하기 위해 미리 결정된 기능이 사용될 수 있다. 예를 들어, 콘텐츠 카테고리, 애플리케이션 우선순위, …, 요청된 우선순위에 대한 가중치를 계산하고 합산하여 중요도 레벨로 총 가중치를 획득할 수 있다. 예를 들어, 우선 순위(433…, 435)는 곱셈을 통해 콘텐츠 카테고리의 가중치를 증가 또는 감소시키는데 적용되는 가중치를 생성하기 위해 합산될 수 있다. 도 12는 일 실시예에 따른 서비스로서의 메모리에 대한 네트워크 통신을 스로틀링하는 방법을 도시한다. 예를 들어, 도 12의 방법은 도 2, 6 또는 9에 도시된 차용자 디바이스에서 구현될 수 있다. 예를 들어, 도 12의 방법은 차용 메모리에 도 1의 디바이스 A, 디바이스 B 또는 서버 P로 구현될 수 있다. 블록에서, 차용자 디바이스와 대여자 디바이스 사이에 통신 연결(예를 들어, 205)이 수립된다. 예를 들어, 연결은 도 1에 도시된 네트워크 및/또는 인터넷을 통해 이루어질 수 있다. 블록 에서, 차용자 디바이스는 대여자 디바이스와 통신하여 차용자 디바이스가 통신 연결 을 통해 차용자 디바이스에 의해 액세스를 위해 대여자 디바이스에 의해 대여된 메모리의 양을 사용하도록 허가를 획득한다. 블록에서, 차용자 디바이스의 운영 체제는 가상 메모리를 차용자 디바이스에서 실행되는 애플리 케이션(예를 들어, 212)에 할당한다. 블록에서, 차용자 디바이스의 운영 체제는 대여자 디바이스에 의해 차용자 디바이스에 대 여된 메모리의 양에 적어도 부분적으로 기초하여 호스팅되도록 가상 메모리를 구성한다. 블록에서, 차용자 디바이스는 애플리케이션(예를 들어, 212)에 의해 사용되는 메모리 영역(예를 들어, 291 내지 299, 261 내지 265, 273 내지 275, 및 281 내지 283) 내의 콘텐츠의 중요도 레벨(예를 들어, 401 내지 415)을 결정한다. 블록에서, 차용자 디바이스는 중요도 레벨에 기초하여 통신 연결의 네트워크 대역폭을 대여자 디바이스에 의해 통신 연결을 통해 차용자 디바이스에 대여된 메모리의 양에 액세스할 때 메모리 영역에 의해 사용되는 데이터 통신에 할당한다. 대여자 디바이스에 의해 대여된 메모리는 다른 디바이스(예를 들어, 245)로부터 대여자 디바이스에 의해 부분적으로 차용될 수 있다. 중요도 레벨(예를 들어, 401 내지 415, 421)은 콘텐츠의 카테고리, 콘텐츠를 제어하는 애플리케이션(예를 들어, 212)의 우선순위, 또는 애플리케이션(예를 들어, 212)에 의해 콘텐츠에 대해 요청된 우선순위 또는 이들의 조합에 적어도 부분적으로 기초하여 식별될 수 있다. 예를 들어, 애플리케이션(예를 들어, 212)은 콘텐츠의 사용 이력, 후속 시간 기간의 콘텐츠의 예측된 사용량 (예를 들어, 439) 또는 콘텐츠의 사용 빈도(예를 들어, 437), 또는 이들의 조합을 기반으로 메모리 영역에 저장 된 콘텐츠에 대한 우선 순위를 요청할 수 있다. 일부 경우에, 운영 체제는 사용 이력을 수집하고, 예 측된 사용량(예를 들어, 439) 및/또는 사용 빈도(예를 들어, 437)를 결정하고 및/또는 애플리케이션(예를 들어, 212)을 대신하여 요청된 우선순위를 계산할 수 있다. 네트워크 대역폭을 할당하기 위해, 차용자 디바이스의 운영 체제 또는 차용자 디바이스의 통신 디바이스는 메모리 영역에 콘텐츠의 중요도 레벨에 대응하는 비율에 따라 대여자 디바이스에 의해 차 용자 디바이스에 대여된 메모리의 양에 액세스할 때 통신 연결을 통한 메모리 영역에 대한 시간 기간 에 사용되는 데이터 통신의 양을 스로틀링(throttle)/제어할 수 있다. 따라서, 일정 시간 동안, 메모리 영역에 사용되는 통신은 비율에 따라 허용된 것으로 볼 수 있다; 다른 메모리 영역에 대한 데이터 통신의 평균 속도는 비율에 비례하도록 제어될 수 있다. 일부 경우에, 차용자 디바이스는 후속 기간에 통신 연결의 네트워크 대역폭의 성능 저하를 예측할 수 있다. 이에 응답하여, 운영 체제는 메모리 영역에 있는 콘텐츠의 중요도 레벨에 따라 차용자 디바이스의 로컬 메모리와 대여자 디바이스에 의해 차용자 디바이스에 대여된 메모리의 양 사이에서 가상 메모리의 호스팅을 조정할 수 있다. 예를 들어, 차용자 디바이스의 운영 체제는 제2 메모리 영역보다 낮은 중요도 레벨을 갖는 제1 메모 리 영역을 식별할 수 있다. 운영 체제는 제1 메모리 영역과 연관된 가상 메모리 영역이 로컬 메모리 에서 호스팅되거나 캐시되는 것에서 대여자 디바이스에 의해 차용자 디바이스에 대여된 메모리 의 양에서 호스팅되는 것으로 마이그레이션되도록 가상 메모리의 호스팅을 재구성할 수 있다; 제2 메모리 영역 과 연관된 가상 메모리 영역은 대여자 디바이스에 의해 차용자 디바이스에 대여된 메모리의 양 으로 호스팅되는 것에서 차용자 디바이스의 로컬 메모리에서 호스팅되거나 캐시되는 것으로 마이그레 이션될 수 있다. 일부 실시예에서, 컴퓨팅 디바이스의 메모리 관리 유닛(MMU)은 네트워크 연결을 통해 차용된 메모리에 대한 액 세스를 가속화하도록 구성된다. 예를 들어, 차용자 디바이스의 메모리 관리 유닛(MMU)은 메모리 버스를 통해 차용자 디바이스의 로컬 랜덤 액세스 메모리에 액세스하도록 구성될 뿐만 아니라, 또한 통신 디바이스를 사용하여 네트 워크 연결을 통해 대여자 디바이스의 대여된 메모리에서 호스팅되는 차용된 메모리에 액세 스하도록 구성될 수 있다. 메모리 관리 유닛(MMU)은 차용자 디바이스의 프로세서가 그 운영 체 제의 명령을 실행하게 할 필요 없이 메모리 관리 유닛(MMU)에 의해 가상 어드레스로부터 변환된 물리적 어드레스에 따라 통신 디바이스를 사용하여 대여자 디바이스의 대여된 메모리에 액 세스할 수 있다. 예를 들어, 대여된 메모리에 액세스할 때 운영 체제에 의해 수행되는 일부 루틴 동작은 메모리 관리 유닛(MMU)에서 구현될 수 있으므로 루틴 동작은 프로세서(들)가 그들의 실행 유닛에서 명령을 실행하 지 않고 수행될 수 있다. 이러한 MMU 구현/지원은 물리적으로 대여자 디바이스의 대여된 메모리에 있 는 차용된 메모리에 액세스할 때 프로세서의 효율성을 향상시킬 수 있다. 일반적으로, 운영 체제는 메모리 관리 유닛(MMU)이 처리할 수 있는 것보다 더 많은 상황을 처리하도 록 프로그래밍될 수 있다. 예를 들어, 네트워크 연결을 통해 대여된 메모리에 액세스하기 위한 통신 이 메모리 관리 유닛(MMU)의 처리 능력을 넘어서는 예외적인 조건에 직면할 때, 운영 체제는 그러한 상황을 처리하도록 실행될 수 있다. 도 13 내지 도 15는 일부 실시예에 따른 차용된 메모리에 액세스하기 위한 하드웨어 가속 구성을 예시한다. 예 를 들어, 도 13 내지 도 15의 기술은 도 2의 메모리 서비스 기술 및 도 3의 메모리 매핑 기술과 도 1 또는 도 6 의 시스템에서 구현될 수 있다. 도 13에서, 차용자 디바이스의 메모리 관리 유닛(MMU)은 로컬 랜덤 액세스 메모리에 대한 연결 및 차용자 디바이스의 통신 디바이스에 대한 연결을 갖도록 구성된다. 일부 경우에, 통신 디바이스 는 메모리 관리 유닛(MMU)의 일부이다. 변환 색인 버퍼(TLB)에 캐시된 가상 대 물리적 메모리 맵은 가상 어드레스를 물리적 어드레스 로 변환하기 위한 정보를 포함한다. 차용자 디바이스의 실행 유닛에서 명령이 실행될 때, 레지스터 중 하나에 저장되고/되거나 실행 유닛에 의해 생성된 가상 어드레스는 명령을 로드하고, 피연산자를 검색하고, 계산 결과를 저장하기 위해 사용될 수 있다. 이러한 상황에서, 차용자 디바이스는 가상 어드레스에 의해 식별된 가상 메모리에 액세스한다. 가상 어드레스에 의해 식별된 가상 메모리가 로컬 메모리의 메모리 페이지에서 호스팅되는 경우, 물리적 어드레스는 메모리 동작(예를 들어, 판독 또는 기록)을 위해 메모리 페이지를 어드레싱 하기 위해 메모리 관리 유닛에 충분하도록 구성된다. 가상 어드레스에 의해 식별된 가상 메모리가 대여자 디바이스 내부에 물리적으로 있는 대여 메모리 의 메모리 페이지에서 호스팅되는 경우, 물리적 어드레스는 통신 디바이스가 컴퓨터 네트 워크 연결을 통해 대여자 디바이스에 액세스 요청을 송신하기 위한 충분한 정보를 포함하도록 구성된 다. 예를 들어, 가상 어드레스에 의해 식별된 가상 메모리가 대여된 메모리의 메모리 페이지에서 호 스팅되는 경우, 물리적 어드레스는 대여자 디바이스의 운영 체제에 의해 서비스되는 가상 메모리 공 간의 가상 메모리 어드레스 및 대여자 디바이스의 네트워크 어드레스를 포함할 수 있다. 메모리 관리 유닛 (MMU)은 네트워크 어드레스를 사용하여 대여자 디바이스에 액세스 요청을 송신하도록 통신 디바이스 에 요청하고; 액세스 요청은 대여자 디바이스의 메모리 페이지를 식별하는 가상 어드레스를 포 함한다. 통신 디바이스가 액세스 요청을 수신할 때, 통신 디바이스는 프로세서(들)가 가상 어드레스에 액세스하도록 메모리 관리 유닛(MMU)에 지시하는 것과 유사한 방식으로 차용자 디바이스로부터의 액 세스 요청에 포함된 가상 어드레스에 의해 식별된 메모리 페이지에 액세스하도록 메모리 관리 유닛 (MMU)에 지시하도록 구성될 수 있다. 일부 경우에, 통신 디바이스는 메모리 관리 유닛(MMU)의 일부이다.예를 들어, 가상 어드레스가 대여자 디바이스의 가상 대 물리적 메모리 맵을 사용하여 메모리 페이지(26 0)의 물리적 어드레스로 변환될 때, 메모리 관리 유닛(MMU)은 어드레스 변환을 수행하고 물리적 메모리 어 드레스를 사용하여 메모리 페이지에 액세스한다. 가상 어드레스의 변환을 위한 가상 대 물리적 메모리 맵 이 대여자 디바이스의 메모리 관리 유닛(MMU)에 아직 없는 경우, 대여자 디바이스의 운영 체제 는 메모리 관리 유닛(MMU)이 메모리 페이지에 액세스하기 위해 어드레스 변환을 수행하도록 가 상 대 물리적 메모리 맵의 관련 부분을 대여자 디바이스의 메모리 관리 장치(MMU)에 로드하도록 실행 될 수 있다. 일부 예에서, 대여자 디바이스는 저장 디바이스에서 차용자 디바이스에 의해 사용되는 가상 어 드레스를 호스팅할 수 있다. 가상 어드레스를 변환하기 위한 메모리 관리 유닛(MMU)의 실패/페이지 폴트 (fault)에 응답하여, 메모리 관리 유닛(MMU)는 프로세서(들)가 운영 체제를 실행하게 하고, 이 는 저장 디바이스에서 대여된 메모리로 데이터 콘텐츠를 로드하고 액세스를 가능하게 하기 위해 메모 리 관리 유닛(MMU)의 변환 색인 버퍼(TLB)를 업데이트한다. 대안적으로, 운영 체제는 대여자 디바이 스의 로컬 메모리에 캐싱 또는 버퍼링 또는 재호스팅하지 않고 저장 디바이스로부터 직접 액세스 요 청을 서비스할 수 있다. 일부 예에서, 대여자 디바이스는 다른 대여자 디바이스(예를 들어, 205)에서 차용자 디바이스에 의해 사용되는 가상 어드레스를 호스팅할 수 있다. 이러한 상황에서, 대여자 디바이스는 대여자 디바이스 에 액세스하는 차용자 디바이스와 유사한 방식으로 자신의 대여자(예를 들어, 205)에 액세스할 수 있다. 옵션으로, 차용자 디바이스의 실행 유닛 중 하나에서 액세스되는 가상 어드레스가 통신 디바이 스를 통한 액세스를 위해 물리적 어드레스로 변환될 때, 통신 디바이스는 도 14에 도시된 바와 같이 대여자 디바이스로부터 통신 디바이스의 버퍼로 가상 어드레스 영역을 마이그레이션할 수 있다. 예를 들어, 가상 메모리의 페이지에 있는 가상 어드레스가 액세스되고 있을 때, 통신 디바이스는 전 체 페이지(또는 그 일부)를 페이지에 대한 추가 액세스를 예상하여 통신 디바이스의 버퍼로 마이그레 이션할 수 있다. 대안적으로, 차용자 디바이스의 메모리 관리 유닛(MMU)은 도 15에 도시된 바와 같이, 대여된 메모리 의 일부를 캐싱하기 위한 버퍼로서 로컬 랜덤 액세스 메모리의 일부를 유보하도록 구성될 수 있다. 옵션으로, 차용자 디바이스의 메모리 관리 유닛(MMU)은 도 5에 도시된 것에 대해 유사한 방식으로 가 상 대 물리적 메모리 페이지에서 식별된 가상 메모리 영역의 호스팅 조정을 관리하도록 추가로 구성될 수 있다. 예를 들어, 메모리 관리 유닛(MMU)이 대여자 디바이스의 대여된 메모리에 호스팅된 가상 영역이 로컬 메모리에서 호스팅된 가상 영역보다 더 빈번하게 및/또는 최근에 액세스된다고 결정할 때, 메모리 관 리 유닛(MMU)은 통신 디바이스를 사용하여 더 빈번하게 및/또는 최근에 액세스한 가상 영역을 로컬 메모리에서 호스팅되도록 마이그레이션하고 축출하고, 덜 빈번하게 및/또는 최근에 액세스한 가상 영역을 대여된 메모리에서 호스팅하도록 축출할 수 있다. 따라서, 메모리 관리 유닛(MMU)은 TLB(translation lookaside buffer)에 캐싱된 가상 대 물리적 메모리 맵에서 식별된 가상 메모리 영역의 호스팅을 최 적화하고, 조정에 따라 변환 색인 버퍼(TLB)에 캐시된 가상 대 물리적 메모리 맵으로 업데이트할 수 있다. 차용자 디바이스의 운영 체제는 다른 가상 메모리 영역의 호스팅을 추가로 조정하는데 사용될 수 있다. 도 16 및 17은 일부 실시예에 따른 대여된 메모리에 대한 액세스를 제공하기 위한 하드웨어 가속 구성을 예시한 다. 예를 들어, 도 13, 14 또는 15에 도시된 대여자 디바이스의 구성은 도 16 또는 17의 구성으로 대체될 수 있다. 도 16에서, 대여자 디바이스는 주변 버스 및 메모리 버스를 갖는다. 대여자 디바이스의 통신 디바이스 및 저장 디바이스는 주변 버스를 통해 대여자 디바이스 의 프로세서에 연결된다. 대여자 디바이스의 로컬 랜덤 액세스 메모리는 메모리 버스(51 3)를 통해 프로세서(들)에 연결된다. 운영 체제는 초기에 저장 디바이스에 저장되고 후속하여 실행을 위해 랜덤 액세스 메모리에 로 드될 수 있다. 통신 디바이스가 차용자 디바이스에 의해 사용되는 차용된 메모리에 대해 운영 체제에 의 해 할당된 가상 메모리 어드레스를 식별하는 메모리 액세스 요청을 수신할 때, 통신 디바이스는 메모리 액세스 요청에 따라 처리하도록 프로세서에 요청하도록 구성된다. 통신 디바이스가 액세스 요청을 수신할 때, 대여자 디바이스에서 실행되는 운영 체제는 저 장 디바이스 또는 랜덤 액세스 메모리의 가상 어드레스를 호스팅할 수 있다 (예를 들어, 메모리 맵의 구성을 통해). 가상 어드레스가 메모리에서 호스팅되고 메모리 관리 유닛(MMU)이 가상 어드레스를 변환하 기 위해 메모리 맵의 캐싱된 부분을 갖는 경우, 프로세서(들)는 메모리 맵의 캐시된 부분으로부 터 결정된 메모리 페이지의 물리적 어드레스에 액세스함으로써 액세스 요청을 처리할 수 있다. 가상 어드레스가 메모리에서 호스팅되고 메모리 관리 유닛(MMU)이 가상 어드레스를 변환하 기 위한 메모리 맵의 캐시된 부분을 갖지 않는 경우, 프로세서(들)는 메모리 관리 유닛(MMU)이 가상 어드레스를 메모리 페이지의 물리적 어드레스로 변환할 수 있도록 운영 체제를 실행하여 메모리 맵의 캐시된 부분을 업데이트할 수 있다. 가상 어드레스가 하드 드라이브 또는 솔리드 스테이트 드라이브와 같은 저장 디바이스에서 호스팅되 는 경우, 메모리 관리 유닛(MMU)은 가상 어드레스를 변환하기 위한 메모리 맵의 캐싱된 부분을 갖지 않다 (예를 들어, 페이지 폴트를 생성함으로써). 이에 응답하여, 메모리 관리 유닛(MMU)은 프로세서 (들)가 운영 체제를 실행하게 하며, 이는 저장 디바이스에 액세스함으로써 액세스 요청을 구현하도록 구성될 수 있고 및/또는 가상 메모리 영역(예를 들어, 가상 메모리 페이지)을 랜덤 액세스 메모리 로 마이그레이션하도록 구성될 수 있다. 가상 어드레스가 다른 대여자 디바이스(예를 들어, 245)에서 호스팅되는 경우, 대여자 디바이스는 가 상 어드레스를 자신의 대여자 디바이스(예를 들어, 245)의 네트워크 어드레스를 식별하는 물리적 어드레스 및 대여자 디바이스(예를 들어, 245)에 의해 할당된 가상 어드레스로 변환한다(옵션으로 통합 어드레스 공간에 서 가상 어드레스와 동일하도록 구성될 수 있음). 그런 다음, 대여자 디바이스는 대여자 디바이스 에 액세스하는 차용자 디바이스와 유사한 방식으로 자신의 대여자 디바이스(예를 들어, 245)에 액세 스할 수 있다. 액세스 요청은 차용자 디바이스의 프로세서에서 명령 실행 동안 요청된 메모리 액세스에 대응하 는 형태로 구성될 수 있다. 예를 들어, 차용자 디바이스의 프로세서가 가상 어드레스에서 명령 로드를 요청할 때, 액세스 요청은 가상 어드레스로부터 명령 검색을 요청하도록 구성된다 (통합 어드 레스 공간의 가상 어드레스와 동일하도록 옵션으로 구성할 수 있음). 예를 들어, 차용자 디바이스의 프로세서가 가상 어드레스로부터 피연산자의 로딩을 요청할 때, 액세스 요청은 가상 어드레스로부터 피연산자의 검색을 요청하도록 구성되고; 차용자 디바이스 의 프로세서가 가상 어드레스에 계산 결과를 저장하도록 요청할 때, 액세스 요청은 가상 어드레 스로부터 피연산자의 검색을 요청하도록 구성된다. 옵션으로, 액세스 요청은 가상 어드레스 영역의 마이그레이션을 구현하도록 구성될 수 있다. 예를 들어, 가상 어드레스가 액세스될 때, 통신 디바이스는 대여자 디바이스와 차용자 디바이스 사이 의 가상 메모리 영역의 마이그레이션을 자동으로 가능하게 하도록 구성된다. 옵션으로, 통신 디바이스는 대여자 디바이스의 메모리 관리 유닛(MMU)의 일부로서 구현된다. 옵션으로, 메모리 관리 유닛(MMU)은 도 17에 도시된 바와 같이 통신 디바이스를 동작시키기 위한 네 트워크 컨트롤러를 포함하도록 구성된다. 도 17에서, 메모리 관리 유닛(MMU)은 메모리에 대한 물리적 어드레스를 사용하여 메모리 페이지(26 0)에 액세스하도록 구성된 메모리 컨트롤러를 갖는다. 또한, 메모리 관리 유닛(MMU)은 네트워크 기반 메모리 액세스 요청(예를 들어, 507)을 처리하도록 구성된 네트워크 컨트롤러를 갖는다. 이러한 네트워크 기반 메모리 액세스 요청은 그것의 차용자 디바이스(예를 들어, 201) 또는 대여자 디바이스(예를 들어, 245)로부터의 요청일 수 있다.도 18은 일 실시예에 따른 메모리 관리 유닛을 통해 차용된 메모리에 대한 액세스를 가속화하는 방법을 도시한 다. 예를 들어, 도 18의 방법은 도 1에 도시된 디바이스 A 또는 디바이스 B, 또는 서버 P에서 구현될 수 있다. 예를 들어, 도 18의 방법은 도 2, 6, 9, 13, 14 또는 15에 도시된 차용자 디바이스에서 구현될 수 있다. 예를 들어, 도 18의 방법은 도 2, 3 또는 13에서 17에 도시된 메모리 관리 유닛 또는 메 모리 관리 유닛에서 구현될 수 있다. 도 18의 블록에서, 메모리 관리 유닛(예를 들어, 216 또는 236)은 메모리 관리 유닛(예를 들어, 216 또는 236)의 변환 색인 버퍼(예를 들어, 253)에 가상 대 물리적 메모리 맵(예를 들어, 253)을 캐싱한다. 예를 들어, 가상 대 물리적 메모리 맵(예를 들어, 253)은 메모리 관리 유닛(예를 들어, 216 또는 236)이 구성된 컴퓨팅 디바이스(예를 들어, 201 또는 203)의 운영 체제(예를 들어, 213 또는 233)에 의해 관리되는 페이지 테 이블의 부분일 수 있다. 블록에서, 메모리 관리 유닛(예를 들어, 216 또는 236)은 마이크로프로세서(예를 들어, 215 또는 235)에서 명령의 실행을 위해 가상 메모리 어드레스(예를 들어, 255 또는 509)에 액세스하기 위한 요청을 수신한다. 예를 들어, 가상 메모리 어드레스는 프로세서에서 명령의 실행을 위해 레지스터에 저장될 수 있 다. 가상 메모리 어드레스는 가상 메모리 어드레스로부터 명령을 로드하거나, 가상 메모리 어드레스 로부터 명령의 피연산자를 로드하거나, 명령의 실행 후에 실행 유닛에 의해 생성된 컴퓨팅 결과를 저 장하는데 사용될 수 있다. 일부 예에서, 가상 메모리 어드레스는 차용자 디바이스(예를 들어, 201)에 대한 네트워크 연결로부터의 메 모리 액세스 요청에서 통신 디바이스에서 수신되고; 통신 디바이스는 액세스 요청을 처리할 것 을 메모리 관리 유닛에 요청하도록 구성된다. 블록에서, 메모리 관리 유닛(예를 들어, 216 또는 236)은 변환 색인 버퍼(예를 들어, 253)에 캐싱된 가상 대 물리적 메모리 맵(예를 들어, 253)을 사용하여 가상 메모리 어드레스(예를 들어, 255)를 물리적 메모리 어드 레스(예를 들어, 257)로 변환한다. 블록에서, 물리적 메모리 어드레스(예를 들어, 257)가 로컬 메모리(예를 들어, 211 또는 231)를 위한 것인 지 여부가 결정된다. 예를 들어, 메모리 관리 유닛(예를 들어, 216 또는 236)은 메모리 컨트롤러(예를 들어, 521)를 통한 메모리 버 스(예를 들어, 511) 및 네트워크 컨트롤러를 통한 컴퓨터 네트워크 (예를 들어, 109) 둘 모두에 대한 연결 을 가질 수 있다. 블록에서, 물리적 메모리 어드레스(예를 들어, 257)가 로컬 메모리(예를 들어, 211 또는 231) (예를 들어, 제1 메모리 유형의)에 대한 것으로 결정되면, 메모리 관리 유닛(예를 들어, 216 또는 236)은 메모리 버스 에 연결된 메모리 컨트롤러에 물리적 어드레스의 메모리 페이지에 액세스하도록 지시한다. 블록에서, 물리적 메모리 어드레스(예를 들어, 257)가 로컬 메모리(예를 들어, 211 또는 231)(예를 들어, 제2 메모리 유형)에 대한 것이 아닌 것으로 결정되면, 메모리 관리 유닛은 (예를 들어, 216 또는 236) 물 리적 어드레스에 따라 컴퓨터 네트워크 연결에 연결된 네트워크 컨트롤러에 메모리 페이지(26 0)에 액세스하도록 지시한다. 도 18의 방법을 수행하도록 구성된 메모리 관리 유닛(MMU)(216 또는 236)은 다른 디바이스(예를 들어, 245)를 위해 메모리를 차용하는 대여자 디바이스 또는 차용자 디바이스의 마이크로프로세서(215 또는 235)에 서 사용될 수 있다. 그러한 메모리 관리 유닛(MMU)(216 또는 236)을 갖는 통신 디바이스(예를 들어, 201 또는 203)는 로컬 랜덤 액 세스 메모리(예를 들어, 211 또는 213)에 및 적어도 하나 마이크로프로세서(예를 들어, 215 또는 235)에서 결합 된 메모리 버스를 가질 수 있다. 마이크로프로세서(예를 들어, 215)는 레지스터(예를 들어, 501) 및 실행 유닛 (예를 들어, 503)을 추가로 가질 수 있다. 컴퓨팅 디바이스(예를 들어, 201 또는 203)는 명령을 포함하는 운영 체제(예를 들어, 213 또는 233)를 가지며, 이는 명령이 적어도 하나의 마이크로프로세서(예를 들어, 215 또는 235)에 의해 실행될 때 컴퓨팅 디바이스가 통신 디바이스(예를 들어, 217 또는 237)를 사용하여 네트워크 연결을 통해 대여자 디바이스(예를 들어, 203 또는 245)로부터 일정량의 메모리를 차용할 수 있게 한다.실행 유닛은 대여자 디바이스(예를 들어, 203 또는 245)로부터 차용된 메모리의 양에 매핑된 적어도 가상 메모리 어드레스를 사용하여 명령을 실행하도록 구성된다. 예를 들어, 실행 유닛에서 명령의 실행을 위해 레지스터로부터 제1 가상 메모리 어드레스를 검 색한 후, 메모리 관리 유닛(MMU)은 제1 가상 메모리 어드레스를 네트워크 연결을 통해 대여자 디바이스(예를 들어, 203 또는 245)를 식별하는 제1 물리적 어드레스 및 제2 가상 메모리 어드레스로 변환한다. 메모리 관리 유닛(MMU)는 제2 가상 메모리 어드레스를 사용하여 대여자 디바이스에 의해 네트워크 연결를 통해 컴퓨팅 디바이스에 대여된 메모리에 액세스하도록 통신 디바이스에 지시한다. 예를 들어, 제1 물리적 어드레스는 대여자 디바이스의 컴퓨터 네트워크 어드레스를 포함할 수 있다. 실행 유닛에서 명령의 실행은 제1 가상 메모리 어드레스에서 판독하거나 기록하기 위한 메모리 동작 을 생성할 수 있고; 메모리 관리 유닛은 제2 가상 메모리 어드레스에서 메모리 동작에 대한 요청 을 생성하고 통신 연결을 통해 대여자 디바이스에 요청을 송신하도록 통신 디바이스 에 지시하도록 구성된다. 동작 가능하게, 제2 가상 메모리 어드레스는 제1 가상 메모리 어드레스와 동일할 수 있어서 대여자 디바이스 및 차용자 디바이스가 통합된 가상 어드레스 공간을 사용할 수 있다. 예를 들어, 운영 체제 는 통합 가상 어드레스 공간에서 대여자 디바이스에 의해 지정된 가상 메모리 어드레스에 기초하여 차용된 메모리의 양의 식별을 수신하도록 구성될 수 있고; 운영 체제는 통합 가상 어드레스 공간의 가상 메모리 어드레스로부터 직접 가상 메모리를 애플리케이션에 할당하도록 구성될 수 있다. 옵션으로, 메모리 관리 유닛은 버퍼를 포함하고; 메모리 관리 유닛은 또한 제1 가상 메모리 어 드레스가 레지스터로부터 수신된 것에 응답하여 대여자 디바이스에 의해 차용자 디바이스 에 대여된 메모리의 양의 일부에 대해 버퍼에 캐시를 수립하기 위해, 통신 디바이스에게 대여자 디바이스와 통신하도록 지시하도록 더 구성된다. 예를 들어, 통신 디바이스는 페이지 테이블의 가상 어드레스가 사용될 때 페이지 테이블에 따라 메모리의 페이지를 캐싱할 수 있다. 옵션으로, 메모리 관리 유닛은 가상 메모리와 물리적 메모리 사이의 메모리 매핑으로부터 동적으로 변경하 도록 추가로 구성된다. 예를 들어, 가상 메모리 어드레스 세트에 의해 식별된 가상 메모리는 초기에 (예를 들어, 번역 색인 버퍼(TLB)에서 대여자 디바이스에 의해 차용자 디바이스에 대여된 메모리에 매 핑될 수 있고; 매핑은 가상 메모리를 로컬 랜덤 액세스 메모리의 일부로 재매핑하도록 변경될 수 있다. 예를 들어, 메모리 관리 유닛은 가상 메모리 맵에서 식별된 2개의 가상 메모리 영역 매핑을 변환 색 인 버퍼(TLB)에 캐시된 물리적 메모리 맵으로 스왑(swap)할 수 있어서 초기에 로컬 메모리의 영 역에 매핑된 제1 가상 메모리 영역은 대여자 디바이스의 대여된 메모리의 영역에 재매핑되고, 다른 대여자 디바이스의 대여된 메모리의 영역(또는 다른 영역)으로 처음에 매핑된 제2 가상 메모리 영역 은 로컬 메모리의 영역(또는 다른 영역)에 재매핑된다. 예를 들어, 메모리 관리 유닛은 과거 기간의 메모리 사용 이력 또는 차후 기간의 예측된 메모리 사용량에 기초하여 스왑을 위한 제1 가상 메모리 영역 및 제2 메모리 영역을 식별하도록 추가로 구성될 수 있다. 예를 들 어, 가장 최근에 사용된 및/또는 가장 적게 사용된 가상 메모리 페이지가 로컬 메모리에서 대여된 메모리 로 스왑될 수 있고; 가장 최근에 사용된 및/또는 가장 자주 사용된 가상 메모리 페이지는 대여된 메모리 로부터 로컬 메모리로 스왑될 수 있다. 인공 지능(AI) 에이전트는 MaaS(Memory as a Service)에 대한 네트워크 연결의 성능 저하를 예측하기 위해 차용 자 디바이스 및/또는 대여자 디바이스에 구성될 수 있다. 예측에 응답하여 네트워크 연결성 성능 저하가 발생하 기 전 기간 동안, 차용자 디바이스 및/또는 대여자 디바이스의 운영 체제는 네트워크 성능 저하 또는 정전 기간 동안 네트워크 연결을 통해 마이그레이션해야 할 수 있는 콘텐츠를 식별할 수 있고, 네트워크 성능 저하 또는 정전 전에 콘텐츠 마이그레이션을 시작하여 네트워크 성능 저하 또는 정전 동안에 관련 콘텐츠에 로컬로 액세스 할 수 있고 중요한 데이터를 안전한 위치에 백업할 수 있다. 예를 들어, 네트워크 성능 저하 또는 정전 동안 차용자 디바이스에서 사용될 것으로 예측된 데이터는 예측된 사 용 및/또는 데이터의 중요도에 기초하여 차용자 디바이스로 프리페치될 수 있다. 예를 들어, 차용자 디바이스에서 손실될 수 있고/있거나 네트워크 성능 저하 또는 정전 동안(예를 들어, 차용자 디바이스의 정전 또는 차용자 디바이스에 의해 경험될 수 있는 위험한 상태로 인해) 대여자 디바이스에서 백업 해야 할 필요가 있다고 예측되는 특정 데이터는 데이터 손실 가능성을 최소화하기 위해 대여자 디바이스에 복사 할 수 있다. 예를 들어, 전화가 사용자가 신뢰할 수 없는 셀룰러 데이터 연결로 산악 지역을 통해 운전할 것임을 감지하면, 전화에서 실행되는 AI 에이전트는 산악 지역의 서비스에 대한 차용자 디바이스 맵 및/또는 다른 중요 데이터의 로컬 메모리 또는 저장소로 프리페치할 수 있다. 기간 동안 사용되지 않을 것으로 예상되는 데이터는 프리페치 된 콘텐츠를 위한 공간을 전화기에 만들기 위해 대여자 디바이스/서버에 의해 대여자 디바이스에 대여된 메모리 에 복사하거나 스왑될 수 있다. 예를 들어, 드론은 중요 미션(mission-critical) 태스크를 위해 출발하도록 스케줄링될 수 있다; 스케줄링된 태 스크/동작을 기반으로, 드론은 해당 특정 태스크/동작(예를 들어, 탱크와 같은 특정 객체를 감지하는 특징 추출 라이브러리 및/또는 인공 신경망 모델)에 사용될 데이터를 프리페치할 수 있다. 예를 들어, 전화 또는 웨어러블 디바이스는 배터리가 임계 레벨(예를 들어, 50%) 아래로 떨어지는 것을 검출할 수 있다; 네트워크 성능 저하 또는 정전 동안 발생할 수 있는 예측된 정전에 응답하여(예를 들어, 전력 사용 이 력 및/또는 위치 이력/스케줄에 따라 결정됨), 디바이스는 데이터 손실을 방지하기 위해 특정 중요한 데이터를 대여자 디바이스 또는 서버로부터 차용된 메모리로 푸시할 수 있다. 도 19 및 도 20은 일부 실시예에 따른 지능형 콘텐츠 마이그레이션을 수행하도록 구성된 차용자 디바이스 및 대 여자 디바이스를 도시한다. 예를 들어, 도 19 내지 도 20의 기술은 도 3의 메모리 매핑 기술 및 도 2의 메모리 서비스 기술과 도 1 또는 도 6의 시스템에서 구현될 수 있다. 도 13 - 18과 관련하여 논의된 메모리 관리 유닛(216 및 236)을 통해 콘텐츠 마이그레이션이 가속화될 수 있다. 도 19에서, 차용자 디바이스는 운영 체제의 일부로서 옵션으로 구성되는 인공 지능(AI) 에이전트 를 갖는다. AI 에이전트는 메모리 사용 이력, 위치 이력, 스케줄링된 동작, 배터리 파워 레벨(예를 들어, 차용자 디바이스가 배터리를 통해 파워가 공급되는 경우), 배터리 사용 이력 등과 같은 운영 체제에 의해 수집된 다양한 정보를 기반으로 콘텐츠 마이그레이션 결정을 생성하도록 구성된다. AI 에이전트는 운영 체제에 의해 수집된 정보(573, 575, 577, …, 및/또는 579)에 기초하여 예측된 네트워크 성능 저하/정전 기간에 사용되는 상이한 메모리 영역의 가능성을 순위화하도록 구성될 수 있다. 예를 들어, 인공 신경망은 정보(573, 575, 577, … 및/또는 579)의 타이밍에 기반하여 네트워크에서 사용되는 상이한 메모리 영역(예를 들어, 도 10에 예시된 263, 265, …)의 가능성을 순위화하는 점수를 생성하도록 트레이닝될 수 있다. 상이한 메모리 영역이 후속 기간에 사용될 가능성 및/또는 메모리 영역의 콘텐츠의 중요도(예를 들어, 도 11에 예시된 421)에 기초하여, AI 에이전트는 가상 메모리 영역이 호스팅되는 물리적 메모리 영역을 변경하기 위한 마이그레이션 결정을 생성할 수 있다. 예를 들어, 네트워크 성능 저하 또는 정전 동안 사용될 가능성이 있는 가상 메모리 영역은 물리적으로 다른 디 바이스(예를 들어, 103, 105, 107)에 있는 차용된 메모리에서 호스팅되는 것으로부터 차용자 디바이스 의 로컬 저장 디바이스 또는 로컬 랜덤 액세스 메모리에 호스팅되는 것으로 마이그레이션될 수 있다. 예를 들어, 로컬 저장 디바이스는 플래시 드라이브/메모리, 솔리드 스테이트 드라이브, 하드 드라이 브 등일 수 있다. 예를 들어, 네트워크 성능 저하 또는 정전 이후까지 차용자 디바이스에서 사용될 가능성이 없는 가상 메모 리 영역은 차용자 디바이스의 로컬 저장 디바이스 또는 로컬 랜덤 액세스 메모리에서 호스팅되 는 것에서 물리적으로 다른 디바이스(예를 들어, 103, 105, 107 또는 203)에 있는 차용된 메모리에 호스팅 되는 것으로 반대 방향으로 마이그레이션될 수 있다. 로컬 메모리/저장소에서 차용/대여된 메모리로의 마이그레 이션은 데이터를 보존하는데 차용자 디바이스보다 더 신뢰할 수 있는 위치(예를 들어, 대여자 디바이스 또 는 서버)로 중요 데이터를 저장하거나 백업하는 방법으로 사용될 수도 있다. AI 에이전트는 사용되는 가상 메모리 영역의 가능성 뿐만 아니라 가상 메모리 영역과 연관된 원하는 기능 에 대한 가상 메모리 영역의 중요도 및 예측된 네트워크 성능 저하 또는 정전 기간 동안의 네트워크 연결성능 레벨 에 기초하여 마이그레이션을 위한 가상 메모리 영역에 점수를 매기도록 구성될 수 있다. 가상 메모리 영역 마이그레이션에 대한 점수화되는 장점은 가상 메모리 영역을 사전에 마이그레이션하는 비용에 비교하여 측 정될 수 있고,이는 프리페치/마이그레이션 기간 동안 성능을 저하시킬 수 있고 및/또는 마이그레이션된 데이터 가 결국 사용되지 않을 때 불필요한 비용을 초래할 수 있다. 이익 점수가 가상 메모리 영역을 마이그레이션하는 비용 점수보다 높을 때, AI 에이전트는 가상 메모리 영역을 하나 이상의 대여자 디바이스(예를 들어, 103, 105, 107 또는 203)로 마이그레이션하기로 결정할 수 있다. 옵션으로, AI 에이전트는 도 20에 도시된 바와 같이 대여자 디바이스(예를 들어, 103, 105, 107, 또는 203)에서 적어도 부분적으로 구현될 수 있다. 예를 들어, 대여자 디바이스(예를 들어, 203)는 차용자 디바이스(예를 들어, 201)에 의해 사용되는 대여된 메모 리의 사용을 모니터링하는 AI 에이전트를 포함할 수 있다. 대여자 디바이스(예를 들어, 203)의 운영 체제는 차용자 디바이스의 메모리 사용 이력, 차용자 디바이스의 위치 이력, 차용자 디바이스의 스케줄링된 동작 등을 추적할 수 있다. 차용자 디바이스는 차용자 디바이스의 배터리 잔량, 차용자 디바이스의 현재 위치, 차용자 디바이스의 스케줄링된 동작과 같은 차용자 디바이스의 상태와 관련된 특정 정보를 제공할 수 있다. 예를 들어, 차용자 디바이스는 대여자 디바이스에 의해 차용자 디바이스에 대여된 차용된 메모 리에 정보(예를 들어, 573 내지 579)를 저장함으로써 자신의 동작에 대한 정보(예를 들어, 573 내지 579) 를 공유할 수 있다. 따라서, 대여자 디바이스와 차용자 디바이스는 MaaS(Memory as a Service)를 통 해 정보(예를 들어, 573 내지 579)를 공유할 수 있다. 또한, AI 에이전트(들)(571 및/또는 572)는 대여된 메모리/차용된 메모리에서 실행되도록 구성될 수 있다. 따라서, 대여자 디바이스 및 차용자 디바이스는 협력 방식으로 AI 에이전트(들)(571 및/또는 572)를 실행할 수 있다. 예를 들어, 차용자 디바이스는 AI 에이전트를 실행하여 위치 이력 및 배터리 파워 레벨과 같은 차용자 디바이스에 대한 정보를 제공 및/또는 업데이트할 수 있고, 그런 다음 대여자 디바이스 에 AI 에이전트(571/572)를 실행하여 마이그레이션 결정을 내리도록 요청한다. 예를 들어, 차용자 디바이스는 AI 에이전트를 실행하기 위한 가상 메모리 영역을 할당할 수 있다. 가 상 메모리 영역은 가상 메모리 영역에 또한 저장할 수 있는 정보(예를 들어, 573, 575, 557, …, 및/또는 579) 를 제공 및/도는 업데이트하기 위해 차용자 디바이스의 로컬 메모리에 초기에 호스트(또는 캐싱)될 수 있다. 후속하여, 차용자 디바이스는 가상 메모리 영역을 차용된 메모리로 마이그레이션할 수 있고; 가상 메모리 영역의 콘텐츠는 대여자 디바이스의 대여된 메모리에 저장된다. 대여자 디바이스 는 마이그레이션 결정을 하기 위해 AI 에이전트 (예를 들어, AI 에이전트로서)의 실행을 계속할 수 있다. 차용자 디바이스는 AI 에이전트를 추가로 실행하여 추가 정보를 제공하고/하거나 향 후 마이그레이션 결정을 위한 상태를 업데이트할 수 있다. 따라서, 차용자 디바이스는 AI 에이전트 (571/572)에 의해 사용되는 데이터를 제공할 수 있고; 대여자 디바이스는 데이터를 처리하기 위한 컴퓨팅 파워를 제공할 수 있다. 일부 실시예에서, 컴퓨팅 디바이스(예를 들어, 도 1의 201 및 203, 또는 101 내지 107)는 컴퓨팅 디바이스 간에 /중에 자유롭게 가상 메모리 영역의 호스팅의 마이그레이션을 허용하는 서비스로서 메모리로 구성된다. 가상 메 모리 영역이 디바이스들 중 하나에서 호스팅될 때, 현재 가상 메모리 영역을 호스팅하는 디바이스는 가상 메모 리 영역에 대한 다른 컴퓨팅 디바이스(들)에 자신의 메모리 자원을 제공하는 대여자로서 기능한다. 가상 메모리 영역의 호스팅이 다른 디바이스로 마이그레이션될 때, 해당 디바이스는 가상 메모리 영역에 대한 다른 컴퓨팅 디바이스(들)에 메모리 자원을 제공하는 대여자 역할을 한다. 주어진 컴퓨팅 디바이스는 가상 메모리 영역의 세 트에 대한 대여자 및 가상 메모리 영역의 다른 세트에 대한 차용자로서 기능할 수 있다; 및 차용자 또는 대여자 로서의 컴퓨팅 디바이스의 역할은 특정 가상 메모리 영역에 대해 수시로 동적으로 변경될 수 있다. 큰 로컬 메 모리 자원을 갖는 컴퓨팅 디바이스는 다른 컴퓨팅 디바이스(들)보다 더 많은 가상 메모리 영역을 호스팅할 수 있다. 컴퓨팅 디바이스는 MaaS(Memory as a Service)를 통해 로컬 메모리 자원을 공유할 수 있다. 네트워크 연 결(예를 들어, 205)이 이용 가능할 때, 가상 메모리 영역은 (예를 들어, 도 1에 도시된 시스템에서) 한 디바이 스에서 다른 디바이스로 자유롭게 마이그레이션할 수 있다. 도 21 내지 도 24는 일부 실시예에 따른 콘텐츠 이동을 도시한다. 도 21은 가상 어드레스 영역에 대한 대여자 디바이스의 메모리 자원을 차용하는 차용자 디바이스 를 도시한다. 차용자 디바이스는 가상 어드레스 영역을 대여자 디바이스 식별자와 연관시 키는 메모리 맵을 저장한다. 예를 들어, 대여자 디바이스 식별자는 대여자 디바이스의 인터넷 프로토콜(IP) 어드레스, 대여자 디바이스 의 호스트 이름, 대여자 디바이스의 URL(Uniform Resource Locator), UUID(Universally Unique Identifier) 등 일 수 있다. 대여자 디바이스 식별자에 기초하여, 차용자 디바이스는 대여자 디바이스의 물리적 메모리 영역 에 액세스할 수 있다. 예를 들어, 차용자 디바이스의 MMU 또는 차용자 디바이스의 프로세 서에서 실행되는 차용자 디바이스의 운영 체제는 도 17에 도시된 메모리 액세스 요청을 생 성할 수 있다. 가상 어드레스 영역의 가상 어드레스에 데이터를 저장하거나 데이터를 로드하라는 요 청은 대여자 디바이스 식별자에 따라 네트워크 연결을 통해 송신된다. 요청을 수신한 차용 자 디바이스는 대여자 디바이스의 운영 체제에 의해 유지된 메모리 맵에 의해 식별된 메모 리 영역의 메모리 페이지(예를 들어, 도 17에 예시된 260)에 데이터를 저장하거나 메모리 페이지로부터 데 이터를 로드할 수 있다. 도 21에서, 대여자 디바이스의 메모리 맵은 가상 어드레스 영역을 대여자 디바이스 식별자(58 3)와 연관시키며, 이는 가상 어드레스 영역이 대여자 디바이스에서 호스팅됨을 나타낸다. 대여자 디 바이스의 메모리 맵은 가상 어드레스 영역을 물리적 어드레스 영역에 매핑하고, 이는 대여 자 디바이스의 MMU가 가상 어드레스 영역의 가상 어드레스를 물리적 어드레스 영역의 물리적 어드레스로 변환하는 것을 허용한다. 물리적 어드레스 영역은 대여자 디바이스의 로컬 메모리 (593 또는 231)에서 메모리 영역을 식별할 수 있다. 물리적 어드레스 영역의 물리적 어드레스는 메모 리 영역의 메모리 페이지에 액세스하는데 사용될 수 있다. 도 22는 가상 어드레스 영역의 호스팅을 대여자 디바이스에서 차용자 디바이스로 마이그레이션한 결 과를 예시한다. 대여자 디바이스의 로컬 메모리(593 또는 231)에 있는 메모리 영역에서 차용자 디바 이스의 로컬 메모리(591 또는 211)에 있는 메모리 영역으로 콘텐츠를 복사한 후, 차용자 디바이스 는 가상 어드레스 영역을 차용자 디바이스 식별자와 연관시키기 위해 자신의 메모리 맵을 업데이트할 수 있으며, 이는 가상 어드레스 영역이 차용자 디바이스에서 호스팅됨을 나타낸다. 또한, 메모리 맵은 가상 어드레스 영역을 물리적 어드레스 영역에 매핑한다. 따라서, 가상 어드레스 영역의 가상 어드레스는 물리적 어드레스 영역의 물리적 어드레스로 변환될 수 있다(예를 들어, 도 3에 예시된 바와 같이). 도 22에서, 대여자 디바이스는 가상 어드레스 영역이 차용자 디바이스에서 호스팅됨을 나타내는 차용자 디바이스를 연관시키기 위해 메모리 맵을 업데이트한다. 또한, 가상 어드레스 영역은 더 이상 메모리 영역의 물리적 어드레스 영역에 매핑되지 않는다. 따라서, 가상 어드레스 영역을 호스팅하는데 이전에 사용된 메모리 영역이 해제될 수 있고 다른 가상 어드레스 영역을 호스팅하는데 사용 될 수 있다. 도 22의 구성은 가상 어드레스 영역에 대한 대여자 디바이스에 의한 메모리 영역의 차용을 반영 한다. 대여자 디바이스가 가상 어드레스 영역의 가상 어드레스에 액세스하면, 대여자 디바이스 는 도 21의 구성으로 대여자 디바이스에 의해 차용자 디바이스에 대여된 메모리에 액세스하는 차용자 디바이스와 유사한 방식으로 차용자 디바이스에 의해 대여자 디바이스에 대여된 메모리 에 액세스할 수 있다. 따라서, 가상 어드레스 영역의 호스팅 마이그레이션을 통해 대여자/차용자 역 할은 역전될 수 있다; 주어진 디바이스는 상이한 디바이스의 위치 메모리에서 호스팅되는 다른 가상 어드레스 영역과 관련하여 다른 대여자/차용자 역할을 가질 수 있다. 도 23은 가상 어드레스 영역이 차용자 디바이스 식별자와 연관되어 차용자 디바이스의 로컬 메 모리(591 또는 211)의 메모리 영역에서 호스팅되는 구성을 예시한다. 그러나, 대여자 디바이스의 메 모리 맵은 가상 어드레스 영역을 대여자 디바이스의 로컬 메모리(593 또는 231)에 있는 메모리 영역의 물리적 어드레스 영역과 추가로 연관시킨다. 따라서, 대여자 디바이스의 메모리 영역 에 있는 콘텐츠는 차용자 디바이스의 메모리 영역에 있는 콘텐츠의 백업 복사본, 캐시 복사본 또는 미러 복사본으로 사용될 수 있고, 가상 어드레스 영역이 공식적으로 호스팅된다.유사하게, 도 24는 가상 어드레스 영역이 대여자 디바이스 식별자와 연관되어 대여자 디바이스 의 로컬 메모리(593 또는 231)의 메모리 영역에서 호스팅되는 구성을 예시한다. 그러나, 차용자 디바이스 의 메모리 맵은 가상 어드레스 영역을 차용자 디바이스의 로컬 메모리(591 또는 211)에 있 는 메모리 영역의 물리적 어드레스 영역과 추가로 연관시킨다. 따라서, 차용자 디바이스의 메모 리 영역에 있는 콘텐츠는 대여자 디바이스의 메모리 영역에 있는 콘텐츠의 백업 복사본, 캐시 복사본 또는 미러 복사본으로 사용될 수 있고, 가상 어드레스 영역이 공식적으로 호스팅된다. 옵션으로, 디바이스(201 및 203)는 로컬 저장 디바이스(예를 들어, 232)의 콘텐츠를 호스팅, 백업, 캐시 또는 미러링하도록 구성될 수도 있다. 도 21 내지 도 24의 기술을 사용하여, 가상 어드레스 영역의 콘텐츠는 마이그레이션 결정에 따라 다 른 디바이스(예를 들어, 201 및 203)에서 마이그레이션, 미러링, 백업 또는 캐싱될 수 있다. 도 25는 일부 실시예에 따른 차용된 메모리를 갖는 컴퓨팅 시스템에서 콘텐츠를 마이그레이션하는 방법을 도시 한다. 예를 들어, 도 25의 방법은 도 1, 2, 13, 14, 21, 22, 23 또는 24에 예시된 컴퓨팅 시스템에서 구현될 수 있다. 블록에서, 제1 컴퓨팅 디바이스(예를 들어, 201) 및 제2 컴퓨팅 디바이스(예를 들어, 203)가 컴퓨터 네트 워크(예를 들어, 109)를 통해 연결된다. 블록에서, 제1 및 제2 컴퓨팅 디바이스(예를 들어, 201 및 203)는 컴퓨터 네트워크(예를 들어, 109)를 가 로질러 가상 메모리 어드레스를 통한 액세스를 위해 메모리 자원을 프로비저닝한다. 예를 들어, 제1 컴퓨팅 디바이스(예를 들어, 201)는 제2 컴퓨팅 디바이스(예를 들어, 203)로부터 메모리를 차용 할 수 있고(예를 들어, 도 21 또는 24에 도시된 바와 같이); 제2 컴퓨팅 디바이스(예를 들어, 203)는 제1 컴퓨 팅 디바이스(예를 들어, 201)로부터 메모리를 차용할 수 있다(예를 들어, 도 22 또는 23에 도시된 바와 같이). 블록에서, 제1 및 제2 컴퓨팅 디바이스(예를 들어, 201 및 203)는 가상 메모리 어드레스의 제1 부분(예를 들어, 263)을 제1 컴퓨팅 디바이스(예를 들어, 도 3에 도시된 영역, 메모리, 유닛)에 매핑 하고, 가상 메모리 어드레스의 제2 부분(예를 들어, 265)을 제2 컴퓨팅 디바이스(예를 들어, 도 3에 도시 된 영역, 메모리, 유닛)에 매핑한다. 블록에서, 제1 및 제2 컴퓨팅 디바이스(예를 들어, 201 및 203)는 제1 및 제2 컴퓨팅 디바이스(예를 들어, 201 및 203) 사이의 네트워크 연결(예를 들어, 205)이 성능 저하되는 기간을 예측한다. 블록에서, 제1 및 제2 컴퓨팅 디바이스(예를 들어, 201 및 203)는 기간의 예측에 기초하여 제1 가상 메모 리 어드레스 영역의 콘텐츠에 대한 마이그레이션 결정을 내린다. 블록에서, 제1 및 제2 컴퓨팅 디바이스(예를 들어, 201 및 203)는 기간 이전에 그리고 마이그레이션 결정 에 대한 응답으로 제1 및 제2 컴퓨팅 디바이스(예를 들어, 201 및 203) 간에 가상 메모리 어드레스 영역의 콘텐츠를 통신한다. 예를 들어, 제1 및 제2 컴퓨팅 디바이스(예를 들어, 201 및 203)에 구성된 AI 에이전트(571/572)는 메모리 사용 이력, 위치 이력 , 스케줄링된 동작, 배터리 파워 레벨, 배터리 사용 이력 등에 기초하여 마이그레이션 결정을 할 수 있다. 예를 들어, AI 에이전트(571/572)는 가상 메모리 어드레스 영역의 사용을 예측할 수 있고; 사용은 네트워 크 성능 저하 기간 동안 제1 컴퓨팅 디바이스(예를 들어, 201)에서 발생할 것으로 예측된다. 가상 메모리 어드 레스 영역이 현재 제2 컴퓨팅 디바이스의 로컬 메모리(또는 스토리지)에 매핑되고 있는 경우, 네트워크 성능 저하의 예측 기간 동안 네트워크 연결을 사용할 수 없는 경우에도 콘텐츠에 액세스할 수 있 도록 로컬 메모리(또는 스토리지)에 콘텐츠를 사용할 수 있도록 마이그레이션 결정이 이루어질 수 있 다. 다른 예에서, AI 에이전트(571/572)는 가상 메모리 어드레스 영역의 콘텐츠가 기간 동안(예를 들어, 배터 리 파워 부족 또는 위험한 상태로 인해) 손실될 수 있음을 예측할 수 있다. 가상 메모리 어드레스 영역이 현재 제1 컴퓨팅 디바이스의 로컬 메모리(또는 스토리지)에 매핑되고 있는 경우, 네트워크 연결(20 5)이 예측된 기간 동안 콘텐츠를 백업할 수 없는 경우에도 콘텐츠가 보존되도록 로컬 메모리(또는 스토리지)에서 콘텐츠를 사용할 수 있도록 마이그레이션 결정이 이루어질 수 있다. 마이그레이션 결정에 응답하여 그리고 가상 어드레스 영역의 마이그레이션된 콘텐츠를 제1 컴퓨팅 디 바이스(예를 들어, 201)의 로컬 메모리(또는 스토리지)에 저장한 후, 가상 메모리 어드레스 영역의 메모리 매핑은 도 22 또는 23에 예시된 바와 같이, 가상 메모리 어드레스 영역을 제1 컴퓨팅 디바이스(예 를 들어, 201)의 로컬 메모리(또는 스토리지)에 매핑함으로써 변경될 수 있다. 유사하게, 마이그레이션 결정에 응답하여 그리고 가상 어드레스 영역의 마이그레이션된 콘텐츠를 제2 컴퓨팅 디바이스(예를 들어, 203)의 로컬 메모리(또는 스토리지)에 저장한 후, 가상 메모리 어드레스 영역 의 메모리 매핑은 도 21 또는 24에 예시된 바와 같이, 가상 메모리 어드레스 영역을 제2 컴퓨팅 디바 이스(예를 들어, 203)의 로컬 메모리(또는 스토리지)에 매핑함으로써 변경될 수 있다. 가상 메모리 어드레스 영역이 제1 컴퓨팅 디바이스의 로컬 메모리(또는 스토리지)에 매핑될 때, 가상 메모리 어드레스 영역은 도 22 및 도 23에 예시된 바와 같이 제1 컴퓨팅 디바이스의 식별자 와 제2 컴퓨팅 디바이스의 메모리 맵에 연관된다; 가상 메모리 어드레스 영역이 제2 컴퓨 팅 디바이스의 로컬 메모리(또는 스토리지)에 매핑될 때, 가상 메모리 어드레스 영역은 도 21 및 도 24에 예시된 바와 같이, 제 2 컴퓨팅 디바이스의 식별자와 제 1 컴퓨팅 디바이스의 메모 리 맵에 연관된다. 옵션으로, 가상 메모리 어드레스 영역은 제1 컴퓨팅 디바이스의 로컬 메모리(또는 스토리지)에 매핑되고, 가상 메모리 어드레스 영역은 도 22 및 도 23에 예시된 바와 같이 제1 컴퓨팅 디바이스의 식별자와 제1 컴퓨팅 디바이스의 메모리 맵에 추가로 연관된다; 가상 메모리 어드레스 영역 이 제2 컴퓨팅 디바이스의 로컬 메모리(또는 스토리지)에 매핑될 때, 가상 메모리 어드레스 영 역은 도 21 및 도 24에 도시된 바와 같이, 제 2 컴퓨팅 디바이스의 식별자와 제 2 컴퓨팅 디바 이스의 메모리 맵에 추가로 연관된다. 가상 메모리 어드레스 영역이 제1 컴퓨팅 디바이스의 로컬 메모리(또는 스토리지)에 매핑되면, 제1 컴퓨팅 디바이스의 메모리 맵은 도 22 및 23에 예시된 바와 같이, 가상 메모리 어드레스 영역 을 제1 컴퓨팅 디바이스의 로컬 메모리(또는 스토리지)에 있는 물리적 메모리 어드레스 영역 (587/588)에 매핑한다; 가상 메모리 어드레스 영역이 제2 컴퓨팅 디바이스의 로컬 메모리(또는 스토 리지)에 매핑되면, 제2 컴퓨팅 디바이스의 메모리 맵은 가상 메모리 어드레스 영역을 도 21 및 도 24에 도시된 바와 같이, 제2 컴퓨팅 디바이스의 로컬 메모리(또는 스토리지)에 있는 물리적 메모리 어드레스 영역(585/586)에 매핑한다. 제1 컴퓨팅 디바이스의 물리적 메모리 어드레스 영역 (587/588)과 제2 컴퓨팅 디바이스의 물리적 메모리 어드레스 영역(585/586) 간에 콘텐츠를 복사함으로써 콘텐츠 마이그레이션이 수행된다. 옵션으로, 가상 메모리 어드레스 영역이 제1 컴퓨팅 디바이스의 로컬 메모리(또는 스토리지)에 매핑된 후, 제2 컴퓨팅 디바이스는 도 23에 도시된 바와 같이 가상 메모리 어드레스 영역의 콘텐츠의 캐시, 미러 또는 백업 사본을 저장하도록 제2 컴퓨팅 디바이스의 물리적 메모리 어드레스 영역(585/586)을 구성할 수 있다. 유사하게, 가상 메모리 어드레스 영역이 제2 컴퓨팅 디바이스의 로컬 메모리(또는 스토리지)에 매핑된 후, 제1 컴퓨팅 디바이스는 도 24에 도시된 바와 같이 가상 메모리 어드레스 영역의 콘텐츠의 캐시, 미러 또는 백업 사본을 저장하기 위해 제1 컴퓨팅 디바이스에 물리적 메모리 어드레스 영역 (587/588)을 구성할 수 있다. 마이그레이션 결정은 제1 컴퓨팅 디바이스의 예측된 위치, 제1 컴퓨팅 디바이스의 스케줄링된 동작, 스케줄링된 동작에 사용될 소프트웨어/ 데이터의 식별, 과거에 반복된 동작으로부터 식별된 제1 컴퓨팅 디바이 스의 예측된 동작, 제1 컴퓨팅 디바이스의 배터리 사용 이력 등에 기초하여 이루어 진다. 예를 들어, 마이그레이션 결정은 가상 메모리 어드레스의 일부에 저장된 인공 신경망에 적어도 부분적으로 기초하여 이루어질 수 있다. 제1 컴퓨팅 디바이스에서 실행되는 AI 에이전트는 가상 메모리 어드레스 의 일부를 사용하여 인공 신경망에 데이터를 제공할 수 있으며; 제2 컴퓨팅 디바이스에서 실행되는 AI 에 이전트는 가상 메모리 어드레스의 일부를 사용하여 마이그레이션 결정을 위한 계산을 수행할 수 있다. 서비스로서의 메모리(MaaS)는 메모리 중심 컴퓨팅 모델을 지원한다. 예를 들어, MaaS는 가상 메모리 호스팅이 네트워크화된 컴퓨터 간에 유동하는 것을 허용한다. 결과적으로 가상 메모리의 콘텐츠는 컴퓨터의 프로세서 간 에 끊김없이 유동할 수 있다. 따라서, 네트워크의 컴퓨터는 메모리 자원 공유를 통하여 컴퓨팅 자원, 데이터 및 /또는 컴퓨팅 결과에 기여할 수 있다. 예를 들어, 씬 클라이언트는 기기 또는 서버에서 메모리를 차용할 수 있다. 클라이언트에게 메모리를 대여함으 로써, 기기 또는 서버의 프로세서(들)는 클라이언트에 의해 차용된 메모리의 콘텐츠에 쉽게 액세스하고 클라이 언트에 대한 요청에 대한 응답으로 클라이언트를 대신하여 계산을 수행할 수 있다. 예를 들어, 클라이언트는 차용된 메모리에 계산을 설정하고 기기 또는 서버에 추가 계산을 인계하도록 요청할 수 있다. 차용된 메모리는 데이터 및/또는 데이터 처리를 위한 코드를 저장할 수 있다; 그리고 기기 또는 서버 는 마치 계산이 기기 또는 서버에서 초기에 설정된 것처럼 데이터에 대해 동작하고/하거나 코드를 실행할 수 있 다. 예를 들어, 클라이언트는 클라이언트에 특정한 데이터를 제공하도록 컴퓨팅 태스크를 설정할 수 있다; 그리 고 기기 또는 서버는 클라이언트에 대한 태스크의 처리 집약적인 부분을 수행할 수 있다. 예를 들어, 클라이언트는 초기에 클라이언트의 로컬 메모리에서 가상 메모리 영역을 호스트할 수 있다. 그 후, 클라이언트는 기기 또는 서버에 의해 클라이언트에 대여된 메모리의 가상 메모리 영역을 재 호스팅할 수 있다. 클라이언트는 가상 메모리 영역에서 루틴 또는 명령 세트의 실행을 계속하도록 기기 또는 서버에 요청할 수 있 다; 기기 또는 서버는 옵션으로 클라이언트에 대여된 메모리를 제어하고 클라이언트에 대여된 메모리의 데이터 를 추가로 처리할 수 있는 루틴 또는 명령을 실행할 수 있다. 요청 완료 후, 기기 또는 서버는 클라이언트에 통 지를 제공하여 클라이언트가 기기 또는 서버의 계산 결과를 검색하게 하고 및/또는 가상 메모리 영역에서 루틴 또는 명령의 실행을 계속하도록 할 수 있다. 일부 경우에, 애플리케이션이 가상 메모리 영역에서 실행되도록 구 성된다; 애플리케이션의 실행은 일부 스테이지에서 클라이언트에서 수행되고 다른 스테이지에서 기기 또는 서버 로 전송될 수 있다. 따라서, 클라이언트와 기기 또는 서버는 공유 메모리를 통해 계산 자원을 공유할 수 있다. 유사하게, 기기 또는 서버는 메모리에 태스크를 설정하고, 메모리를 클라이언트(예를 들어, 에지 컴퓨팅 디바이 스)에 대여하고, 클라이언트에게 클라이언트의 데이터에 대해 로컬 컴퓨팅을 수행하도록 요청하고, 메모리에서 결과를 다시 획득할 수 있다. 또한, 기기 또는 서버는 다수의 클라이언트에 대여된 다수의 메모리 영역에서 태스크를 설정할 수 있다. 클라이 언트는 각각의 차용된 메모리 영역에서 태스크를 실행하여 기기 또는 서버에 입력을 제공할 수 있다. 따라서, MaaS(Memory as a Service)는 새로운 메모리 중심 컴퓨팅 모델을 가능하게 한다. 도 26 및 27은 디바이스 및 기기/서버와 같은 상이한 컴퓨터의 로컬 메모리에 가상 어드레스 영역을 선택적으로 호스팅하는 것에 기초한 분산 컴퓨팅을 도시한다. 일반적으로, 디바이스는 도 1의 디바이스(101 또는 103) 또는 서버일 수 있거나 또는 도 2, 6, 9, 13 - 15, 19 및/또는 21 - 24의 차용자 디바이스일 수 있다. 일반적으로, 기기/서버는 도 1의 디바이스 또는 서버(105 또는 107)일 수 있거나 또는 도 2, 6, 13 - 17, 20 및/또는 21 - 24의 대여자 디바이스일 수 있다. 도 26에서, 디바이스는 애플리케이션을 위한 가상 어드레스 영역을 할당한다. 가상 어드레스 영 역은 애플리케이션이 디바이스에서 실행되고 있는 기간 동안 디바이스의 로컬 메모리(21 1)에서 호스팅될 수 있다. 예를 들어, 가상 메모리 어드레스 영역은 디바이스의 메모리 맵과 기기/서버의 메모리 맵 둘 모두에서 디바이스의 디바이스 식별자 A와 연관된다. 디바이스의 메모리 맵은 가 상 메모리 어드레스 영역을 물리적 어드레스 영역과 추가로 연관시킨다. 따라서, 메모리 맵은 가상 어드레스 영역의 가상 어드레스를 물리적 어드레스 영역의 대응하는 물리적 어드레스로 변환하 기 위해 애플리케이션을 실행하는 프로세서에 의해 사용될 수 있다. 물리적 어드레스는 디바이스 의 로컬 메모리에 있는 메모리 영역의 메모리 페이지에 액세스하는데 사용될 수 있다. 예를 들어, 디바이스에서 실행되는 애플리케이션은 가상 어드레스 영역을 사용하여 메모리 영역 의 데이터를 판독하고, 데이터에 대해 동작하고, /또는 메모리 영역에 데이터를 저장 할 수 있다. 가상 어드레스 영역은 도 27에 도시된 바와 같이 기기/서버의 로컬 메모리에서 재호스팅될 수 있다. 로컬 메모리의 메모리 영역의 콘텐츠를 기기/서버로 송신하고, 메모리 영역의 콘텐츠를 기기/서버의 로컬 메모리에 저장한 후, 가상 어드레스 영역은 디바이스의 메모리 맵 및 기기/서버의 메모리 맵 둘 모두에서 기기/서버의 디바이스 식별자 B와 연관된다. 또한, 디바이스의 메모리 맵은 가상 메모리 어드레스 영역을 물리적 어드레스 영역과 연관 시킨다. 따라서, 메모리 맵은 가상 어드레스 영역의 가상 어드레스를 물리적 어드레스 영역의 대응하는 물리적 어드레스로 변환하기 위해 해당 애플리케이션을 실행하는 기기/서버의 프로세서 에 의해 사용될 수 있다. 물리적 어드레스는 기기/서버의 로컬 메모리에 있는 메모리 영역(58 6)의 메모리 페이지에 액세스하는데 사용될 수 있다. 예를 들어, 기기/서버에서 실행되는 애플리케이션은 가상 어드레스 영역을 사용하여 메모리 영 역의 데이터를 판독하고, 데이터에 대해 동작하고 및/또는 메모리 영역에 데이터를 저장할 수 있다. 디바이스의 애플리케이션 및 기기/서버의 애플리케이션은 데이터, 처리 자원 및/또는 계산 결과를 공유하기 위해 동일한 가상 어드레스 영역을 사용하도록 구성될 수 있다. 일부 예에서, 가상 어드레스 영역이 기기/서버의 로컬 메모리에서 재 호스팅될 때, 디바이스 는 기기/서버의 로컬 메모리에 있는 콘텐츠의 백업, 미러 또는 캐시 사본으로서의 가상 어드레 스 영역을 위한 메모리 영역을 유지할 수 있다. 옵션으로, 디바이스의 애플리케이션 및 기 기/서버의 애플리케이션은 메모리 영역(588 및 586)에서 동시에 실행될 수 있다; 애플리케이션(212 및 232)은 처리 태스크 및 데이터 동기화를 조정하기 위해 프로세스 간 호출로 서로 통신할 수 있다. 옵션으로, 애플리케이션(212 및 232)은 디바이스 및 기기/서버에서 상이한 프로세스로서 실행되는 명 령 세트이다. 도 28 및 29는 애플리케이션의 실행의 상이한 스테이지에서 상이한 컴퓨터 상에서 애플리케이션을 선 택적으로 실행하는 것을 예시한다. 도 28 및 29에서, 애플리케이션(또는 그 일부)은 가상 어드레스 영역 에 상주하도록 구성된다. 프로세서(들)는 실행을 위해 그리고 데이터를 판독, 처리 및/또는 저 장하기 위해 가상 어드레스 영역으로부터 애플리케이션을 로드할 수 있다. 가상 어드레스 영역이 디바이스의 로컬 메모리에 호스팅되거나 캐시되면, 디바이스는 애플 리케이션을 실행할 수 있다. 가상 어드레스 영역이 기기/서버의 로컬 메모리에 호스팅되거 나 캐시되면, 기기/서버는 애플리케이션을 실행할 수 있다. 따라서, 디바이스 및 기기/서버는 애플리케이션의 실행의 상이한 스테이지를 실행하기 위해 서 로 협력할 수 있다. 예를 들어, 디바이스는 애플리케이션을 실행하여 추가 처리(예를 들어, 계산 및/ 또는 자원 집약적 태스크)를 위해 데이터를 설정할 수 있다. 신청자/서버는 추가 처리를 위해 애플리 케이션의 실행을 계속할 수 있다. 신청자/서버에 의한 추가 처리 후에, 디바이스는 신청자/서버 에 의해 제공된 계산 결과를 사용하기 위해 애플리케이션을 계속 실행할 수 있다. 일반적으로, 다수의 가상 어드레스 영역(예를 들어, 581)은 애플리케이션 및 그 데이터를 위해 사용 될 수 있다. 가상 어드레스 영역 중 일부(예를 들어, 581)는 디바이스에 호스팅될 수 있다; 다른 가상 어 드레스 영역(예를 들어, 581)은 기기/서버(및/또는 다른 디바이스)에서 호스팅될 수 있다. 도 30 및 31은 상이한 컴퓨터(621 및 623)에서 호스팅되는 가상 기계에서 애플리케이션을 실행하는 것을 예시한다. 예를 들어, 디바이스의 프로세서(들) 및 기기/서버의 프로세서(들)는 상이한 명령 세트를 가질 수 있다. 따라서, 애플리케이션의 명령은 디바이스의 프로세서(들) 및 기기/서버의 프로세서(들) 둘 모두에서 실행을 위해 호환되지 않을 수 있다. 도 30 및 도 31에서, 디바이스는 가상 기계를 실행한다. 애플리케이션은 기기/서버에서 호 스팅되는 가상 기계와 호환되는 가상 기계 내에서 실행되도록 구성된다. 따라서, 가상 어드레스 영역 이 기기/서버에서 재호스팅될 때(예를 들어, 도 31에 도시된 바와 같이), 가상 어드레스 영역의 애플리케이션은 가상 기계에서 실행 가능하다. 일부 예에서, 기기/서버의 가상 기계는 디바이스를 에뮬레이트한다. 따라서, 애플리케이션(62 7)은 가상 기계 없이 네이티브 모드로 디바이스에서 실행될 수 있다; 기기/서버는 일단 가상 어드레 스 영역이 기기/서버에서 재 호스팅되거나, 캐시되거나, 미러링되면 애플리케이션의 실행을 계속할 수 있다. 가상 어드레스 영역이 기기/서버에서 호스팅되는 경우, 디바이스는 로컬 메모리에 가상 어 드레스 영역의 캐시되거나 미러링된 버전을 가질 수 있다. 기기/서버는 메모리 영역에 호스팅된 가상 어드레스 영역에서 애플리케이션을 실행할 수 있는 반면, 디바이스는 메모리 영역에 캐시/미러링된 가상 어드레스 영역에서 애플리케이션을 동시에 실행할 수 있다. 예를 들어, 디바이스(62 1)에서 애플리케이션의 실행 프로세스는 두 개의 실행 프로세스로 분기될 수 있다. 프로세스 중 하나는 디 바이스에서 계속되고 다른 프로세스는 기기/서버에서 실행된다. 실행 중인 두 프로세스는 데이터 처 리 및/또는 데이터 동기화를 조정하기 위해 서로 통신할 수 있다. 실행 중인 프로세스 중 하나는 디바이스 및 기기/서버에서 병렬 실행 기간 후에 적절한 스테이지에서 종료될 수 있다. 도 32는 MaaS(Memory as a Service) 기반의 분산 컴퓨팅 방법을 도시한다. 예를 들어, 도 32의 방법은 컴퓨팅 디바이스 및 컴퓨터 네트워크를 통해 컴퓨팅 디바이스에 연결된 원격 디바이 스를 사용하여 구현될 수 있다. 컴퓨팅 디바이스 및 원격 디바이스는 도 26 내지 도 31에 도시된 디바이스 및 기기/서버일 수 있다. 예를 들어, 컴퓨팅 디바이스 및 원격 디바이스는 도 2, 6, 9, 13 내지 17, 및/또 는 19 내지 24에 도시된 차용자 디바이스 및 대여자 디바이스일 수 있다. 예를 들어, 컴퓨팅 디바이 스 및 원격 디바이스는 도 1에 도시된 디바이스(101, 103) 및 서버(105, 107) 중 일부일 수 있다. 단계 (651 및 671)에서, 컴퓨팅 디바이스는 원격 디바이스로부터 메모리를 차용하고; 원격 디바이스는 메모리를 컴퓨팅 디바이스에 대여한다. 단계 에서, 컴퓨팅 디바이스는 가상 메모리 어드레스 영역(예를 들어, 581)을 컴퓨팅 디바이스에서 실행되 는 애플리케이션(예를 들어, 212 또는 627)에 할당한다. 단계 에서, 컴퓨팅 디바이스는 가상 메모리 어드레스 영역(예를 들어, 581)을 컴퓨팅 디바이스의 로컬 메 모리(예를 들어, 211)에 매핑한다. 단계 에서, 컴퓨팅 디바이스에서 실행 중인 애플리케이션(예를 들어, 212 또는 627)은 컴퓨팅 디바이스의 로컬 메모리(예를 들어, 211)에 매핑되는 가상 메모리 어드레스 영역의 가상 메모리 어드레스에 따라 컴퓨팅 디 바이스의 로컬 메모리(예를 들어, 211)에 데이터를 저장한다. 단계 에서, 컴퓨팅 디바이스는 가상 메모리 어드레스 영역(예를 들어, 581)의 콘텐츠의 적어도 일부를 원 격 디바이스에 송신한다. 단계에서, 원격 디바이스는 컴퓨팅 디바이스로부터 가상 메모리 어드레스 영역 (예를 들어, 581)의 콘텐츠의 적어도 일부를 수신한다. 단계 (661 및 675)에서, 컴퓨팅 디바이스와 원격 디바이스는 가상 메모리 어드레스 영역(예를 들어, 581)을 원 격 디바이스의 로컬 메모리(예를 들어, 231)의 차용된 부분으로 매핑하기 위해 서로 통신한다. 단계 (663 및 677)에서, 컴퓨팅 디바이스는 가상 메모리 어드레스 영역(예를 들어, 581)의 데이터를 처리하기 위한 요청을 원격 디바이스에 발송한다; 원격 디바이스는 가상 메모리 어드레스 영역(예를 들어, 581)의 데이터 를 처리하라는 요청을 컴퓨팅 디바이스로부터 수신한다. 단계 에서, 원격 디바이스는 요청에 따라 애플리케이션(예를 들어, 232 또는 627)을 실행한다. 단계 에서, 원격 디바이스는 가상 메모리 어드레스 영역(예를 들어, 581)을 애플리케이션(예를 들어, 232 또는 617)에 할당한다. 단계 에서, 원격 디바이스에서 실행되는 애플리케이션(예를 들어, 232 또는 617)은 원격 디바이스에서 호 스팅되는 가상 메모리 어드레스 영역(예를 들어, 581)을 사용하여 데이터를 처리한다. 예를 들어, 요청은 컴퓨팅 디바이스에서 실행 중인 애플리케이션(예를 들어, 212 또는 627)이 종료되기 전에 컴 퓨팅 디바이스에서 원격 디바이스로 발송될 수 있다. 가상 메모리 어드레스 영역(예를 들어, 581)을 원격 디바이스의 로컬 메모리의 차용된/대여된 부분으로 매핑한 후, 컴퓨팅 디바이스는 원격 디바이스에 매핑된 가상 메모리 어드레스 영역(예를 들어, 581)의 백업, 미러 또는 캐시 복사본으로 가상 메모리 어드레스 영역(예를 들 어, 581)을 호스팅하는데 이전에 사용된 메모리 영역(예를 들어, 588)을 유지할 수 있다. 따라서, 컴퓨팅 디바 이스 및 원격 디바이스는 가상 메모리 어드레스 영역(예를 들어, 581)의 콘텐츠의 개별 복사본에 동시에 및/또 는 병렬로 애플리케이션(예를 들어, 212, 232 또는 627)을 실행할 수 있다 (예를 들어, 컴퓨팅 디바이스 및 원 격 디바이스의 메모리 영역(588 및 586)에 각각 저장됨).옵션으로, 컴퓨팅 디바이스와 원격 디바이스는 한 번에 디바이스 중 하나에서 그것들의 애플리케이션(예를 들어, 212, 232 또는 627)을 실행하기 위해 서로 통신할 수 있다. 예를 들어, 원격 디바이스에서 수행된 처리 후에, 원격 디바이스는 컴퓨팅 디바이스가 원격 디바이스에서 수행된 처리 결과를 사용하는 애플리 케이션(예를 들어, 212 또는 627)을 계속 실행하게 하는 요청을 컴퓨팅 디바이스에 발송할 수 있다. 가상 메모리 어드레스 영역(예를 들어, 581)의 콘텐츠는 가상 메모리 어드레스 영역(예를 들어, 581)의 동기화 및/또는 재호스팅을 통해 애플리케이션(예를 들어, 212, 232 또는 627)을 실행하기 위해 업데이트될 수 있다. 일부 경우에, 컴퓨팅 디바이스는 원격 디바이스에서 호스팅되는 가상 메모리 어드레스 영역에서 직접 애플리케 이션을 실행할 수 있다(예를 들어, 도 13 내지 도 17과 관련하여 논의된 메모리 액세스 가속 기술을 사용하여). 일부 경우에, 가상 메모리 어드레스 영역(예를 들어, 581)은 컴퓨팅 디바이스에서 실행되는 애플리케이션(예를 들어, 212 또는 627)을 위해 컴퓨팅 디바이스에서 다시 재 호스트되거나 컴퓨팅 디바이스에서 캐시/미러링된다. 옵션으로, 동일한 가상 메모리 어드레스 영역(예를 들어, 581)을 사용하기 위해 컴퓨팅 디바이스 및 원격 디바 이스를 실행하는 애플리케이션(예를 들어, 212, 232 또는 627)은 동일한 명령 세트를 가질 수 있다. 또한, 명령 세트는 도 28 - 31에 예시된 바와 같이 실행을 위해 컴퓨팅 디바이스 및/또는 원격 디바이스에 의해 가상 메모 리 어드레스 영역(예를 들어, 581)으로 로드될 수 있다. 예를 들어, 컴퓨팅 디바이스의 프로세서에 있는 프로그 램 카운터는 가상 메모리 어드레스 영역(예를 들어, 581)에 가상 어드레스를 저장할 수 있다; 프로세서는 애플 리케이션(예를 들어, 627)의 실행을 위해 가상 어드레스에서 애플리케이션(예를 들어, 627)의 명령을 검색할 수 있다. 일부 예에서, 컴퓨팅 디바이스 및 상기에서 논의된 원격 디바이스와 유사한 디바이스 그룹은 시스템을 형성하기 위해 컴퓨터 네트워크를 통해 연결될 수 있다. 시스템의 각각의 디바이스는 운영 체제를 통해 : 가상 메모리 어 드레스 영역을 사용하여 메모리에 액세스하는 애플리케이션을 실행하고; 애플리케이션이 각각의 디바이스에서 실행되고 있는 제1 기간 동안 가상 메모리 어드레스 영역을 로컬 메모리에 매핑하고; 각각의 디바이스에서 애플 리케이션을 시작한 후 그리고 각각의 디바이스에서 애플리케이션을 종료하기 전의 제2 기간 동안 가상 메모리 어드레스 영역을 복수의 컴퓨팅 디바이스 내의 원격 디바이스의 로컬 메모리에 매핑하고; 및 적어도 제2 기간 동안 가상 메모리 어드레스 영역의 데이터를 처리하도록 원격 디바이스에 요청하도록 구성될 수 있다. 가상 메 모리 어드레스 영역은 가상 메모리 어드레스 영역에 저장된 명령 및/또는 데이터를 사용하여 계산을 가능하게 하기 위해 그룹의 임의의 디바이스에서 동적으로 재호스팅될 수 있다. 차용된 메모리에서 호스팅되는 가상 메모리 영역에 액세스하는 동안 메모리 관리 유닛(MMU)에서 메모리 폴트 (memory fault)가 발생하면, 차용된 디바이스의 운영 체제는 메모리 폴트를 갖는 메모리 영역의 콘텐츠를 페치 하고 차용자 디바이스의 로컬 메모리에 가상 메모리 영역을 캐시하도록 실행될 수 있다. 예를 들어, 미리 결정된 크기(예를 들어, 4KB)의 가상 메모리 페이지에서 메모리 폴트가 발생하면, 전체 메모리 페이지의 콘텐츠는 대여자 디바이스에서 페치되어 차용자 디바이스의 로컬 메모리의 페이지에 캐시될 수 있다. 그런 다음 운영 체제는 페이지 테이블 엔트리를 생성하여 가상 메모리의 페이지를 로컬 메모리의 페이지에 매핑 하고 메모리 폴트를 처리하기 위해 TLB(translation lookaside buffer)를 업데이트할 수 있다. 그러나, 프로세서에서 실행되는 애플리케이션은 페이지의 일부만을 사용할 수 있다. 이러한 상황에서, 네트워크 연결을 통해 대여자 디바이스에서 대여자 디바이스로 전체 페이지의 콘텐츠를 마이그레이션하여 메모리 폴트를 처리하는 것은 비효율적이다. 바람직하게는, 차용자 디바이스는 페이지의 메모리 폴트에 응답하여 미리 결정된 크기(예를 들어, 64바이트 또 는 512비트)의 캐시 라인과 같은 페이지의 일부를 마이그레이션하도록 구성된다. 캐시되는 페이지 부분은 가상 메모리 어드레스를 통해 현재 액세스 중인 메모리 위치를 포함한다. 페이지의 다른 부분은 가상 메모리 어드레 스 액세스에 대한 응답으로 캐시될 필요가 없다. 따라서, 메모리 폴트를 처리하는 시간이 단축된다; 네트워크 대역폭 사용의 효율성이 향상된다. 예를 들어, 비트마스크는 차용자 디바이스의 로컬 메모리에서 캐시 라인 가용성을 태깅하는데 사용될 수 있다. 비트마스크의 각 비트는 비트마스크의 비트가 나타내는 캐시 라인이 로컬 메모리에서 사용 가능한지 여부를 식 별하는데 사용된다. 메모리 관리 유닛(MMU)은 차용된 메모리의 가상 메모리 페이지를 차용된 메모리 페이지의 캐시로 기능하는 로컬 메모리의 페이지에 매핑하는 페이지 테이블 엔트리를 가질 수 있다. MMU가 페이지 테이블 엔트리에 따라 계산된 물리적 메모리 어드레스에 따라 메모리 위치에 액세스하기 전에, 차용자 디바이스는 메모 리 위치를 포함하는 캐시 라인에 대한 비트마스크의 해당 비트를 체크하도록 구성될 수 있다. 비트마스크의 비트가 캐시 라인을 현재 로컬 메모리에서 사용할 수 없음을 나타내는 경우, 차용자 디바이스는 MMU가 물리적 메 모리 어드레스를 사용하게 하기 전에 대여자 디바이스로부터 캐시 라인을 페치할 수 있다. 옵션으로, 애플리케이션은 비트마스크를 체크하기 위한 명령을 포함하도록 코딩될 수 있다. 예를 들어, 애플리 케이션이 메모리 양의 애플리케이션을 요청할 때, 애플리케이션 프로그램은 요청된 메모리의 캐시 라인을 추적 하기 위해 비트마스크에 해당하는 메모리 양을 할당할 수도 있다. 메모리 위치를 포함하는 캐시 라인의 로컬 가 용성을 체크하고 구현하기 위해 미리 결정된 기능/유틸리티가 제공될 수 있다. 캐시 라인에 대한 비트마스크의 비트가 설정되지 않은 경우, 캐시 라인의 메모리 위치에 액세스하기 직전에, 차용자 디바이스의 운영 체제가 캐 시 라인을 페치하도록 실행될 수 있다. 애플리케이션은 메모리 위치에 액세스하기 전에 메모리 위치에 대해 미 리 결정된 기능/유틸리티를 호출할 수 있다. 예를 들어, 컴파일러는 애플리케이션 프로그램에서 이루어진 메모리 액세스를 인식하고, 캐시 라인의 가용성을 체크하고 구현하기 위해 기능/유틸리티에 코드/명령/호출을 자동으로 주입할 수 있다. 일부 경우에, 애플리케이션 프로그램은 캐시 라인 레벨에서 데이터 마이그레이션을 적용하도록 컴파일러에 선택 적으로 요청하는 태그를 포함할 수 있다. 예를 들어, 메모리 페이지가 로컬 메모리에 캐시되지 않을 때 전체 메 모리 페이지가 페치 및 캐시되도록 메모리 페이지 레벨에서 마이그레이션하도록 하나의 목적에 할당된 메모리 양을 프로그래밍할 수 있다. 이 메모리의 페이지에 대한 로컬 캐시 라인 가용성을 추적하는데 비트마스크가 필 요/사용되지 않는다. 대조적으로, 다른 목적을 위해 할당된 다른 양의 메모리는 동일한 메모리 페이지의 다른 캐시 라인을 캐싱하지 않고 메모리 페이지의 일부 캐시 라인이 페치되고 로컬에 캐시될 수 있도록 캐시 라인 레 벨에서 마이그레이션하도록 프로그래밍될 수 있다. 비트마스크는 로컬 캐시 라인 가용성을 추적하는데 사용된다. 일부 실시예에서, 메모리 관리 유닛(MMU)은 비트마스크에 기초하여 파인 그레인 데이터 마이그레이션을 수행하 도록 구성된다. 물리적 어드레스에 따라 메모리 위치에 액세스하기 전에, MMU는 관련 비트 마스크를 체크하여 해당 캐시 라인이 차용자 디바이스의 로컬 메모리에서 사용 가능한지 여부를 결정한다. 캐시 라인이 현재 로컬 메모리에서 사용 가능하지 않은 경우, MMU는 운영 체제가 캐시 라인을 페치하도록 메모리 폴트를 발생시키거나 또는 캐시 라인를 페치할 때 운영 체제를 호출/실행하지 않고 캐시 라인을 페치하도록 통신 디바이스를 제어할 수 있다. 일반적으로, 메모리 상태 맵은 원격 대여자 컴퓨터에서 호스팅되는 가상 메모리 영역 부분의 로컬 가용성을 추 적하는데 사용될 수 있다. 상태 맵의 비트는 해당 비트에 대응하는 부분이 차용자 디바이스의 로컬 메모리에서 현재 사용 가능/캐시되는지 여부를 나타내는데 사용할 수 있다. 또한, 차용자 디바이스 및/또는 대여자 디바이스는 차용된 메모리의 데이터 사용 패턴을 추적할 수 있다. 데이 터 마이그레이션 세분화도 레벨은 데이터 사용 패턴에 따라 결정될 수 있다. 예를 들어, 페이로드와 네트워크 통신 프로토콜 오버헤드 간의 비율을 줄이기 위해, 데이터 마이그레이션을 위 한 최소 단위(예를 들어, 64바이트의 캐시 라인)는 차용자 디바이스와 대여자 디바이스 간에 메모리 데이터를 송신하기 위해 미리 결정될 수 있다. 애플리케이션의 데이터 사용 패턴에 기초하여, 차용자 디바이스 및/또는 대여자 디바이스는 차용된 메모리의 일부에 대한 데이터 마이그레이션을 위한 최적화된 단위(예를 들어, 캐시 라인의 최적화된 수)를 결정할 수 있다. 차용된 메모리의 다른 부분은 데이터 마이그레이션에 대해 상이한 최적 화된 단위를 가질 수 있다. 최적화된 디바이스는 레이턴시 감소의 장점과 마이그레이션이 필요하지 않은 데이터 마이그레이션 비용의 균형을 유지한다. 도 33은 서브 영역 콘텐츠의 캐시 상태를 식별하도록 구성된 메모리 상태 맵을 도시한다. 도 33에서, 변환 색인 버퍼(TLB)는 가상 어드레스 영역(예를 들어, 581)과 물리적 어드레스 영역(예를 들 어, 587) 간의 매핑을 정의하는 가상 대 물리적 메모리 맵을 저장한다. 도 33에서, 가상 어드레스 영역은 최소 크기(예를 들어, 4KB의 메모리 페이지)를 가져서 가상 어드레스 영 역의 가상 어드레스의 일부가 변환 색인 버퍼(TLB)에 정의되어 있으면, 가상 어드레스 영역의 가상 어드레스의 나머지 부분도 변환 색인 버퍼(TLB)에 정의된다. 따라서, 가상 대 물리적 메모리 맵(25 3)을 사용하여 가상 어드레스 영역의 가상 어드레스를 변환할 수 있으면, 전체 가상 어드레스 영역의 임의의 어드레스는 영역의 해당 물리 어드레스로 변환될 수 있다. 바람직하게는, 가상 어드레스 영역의 콘텐츠는 차용자 디바이스와 대여자 디바이스 사이에서 한 번에 하나 의 서브 영역으로 마이그레이션될 수 있다. 도 33에서, 메모리 상태 맵은 가상 어드레스 영역의 서브 영역의 가용성 상태(711, 713, …, 719)를 표시하는데 사용된다. 각각의 서브 영역은 미리 결정된 크기(예를 들어, 64B의 캐시 라인)를 가질 수 있다. 서 브 영역의 콘텐츠는 차용자 디바이스의 로컬 메모리에 호스팅/캐시되거나 대여자 디바이스의 로컬 메모리에 호 스팅/저장될 수 있다. 상태(711, 713, …, 719)는 해당 서브 영역이 로컬 메모리에 캐시/호스팅되는지 여부를 나타낸다. 메모리 상태 맵을 사용하여 로컬 캐시 가용성의 상태(711, 713, … 719)를 추적하기 위해, 차용 자 디바이스와 대여자 디바이스 간의 데이터 마이그레이션은 선택된 서브 영역(예를 들어, 711, 713, …)에 대 해 수행될 수 있지만 다른 서브 영역(예를 들어, 719, …)에 대해서는 수행될 수 없다. 도 34는 서브 영역 레벨에서 페치/마이그레이션될 수 있는 차용된 메모리에 액세스하기 위한 메모리 상태 맵의 사용을 예시한다. 예를 들어, 도 34의 가상 어드레스 영역과 메모리 상태 맵은 도 33의 가상 어드레 스 영역 및 메모리 상태 맵의 예일 수 있다. 도 34에서, 가상 어드레스 영역은 다수의 서브 영역(721, 723, …, 729)을 갖는다. 번역 색인 버퍼에 서브 영역(721, 723, …, 729) 중 어느 하나의 매핑이 정의되면, 모든 서브 영역(721, 723, …, 729)도 정의된 다. 따라서, 가상 어드레스 영역은 변환 색인 버퍼의 물리적 어드레스에 대한 매핑을 정의하는 최소 단위이다. 메모리 상태 맵의 비트(711, 713, …, 719)는 각각 서브 영역(721, 723, …, 729)에 대응한다. 메모리 상 태 맵의 비트(예를 들어, 711)가 제1 미리 결정된 값(예를 들어, 0)을 가질 때, 비트(예를 들어, 711)는 해당 서브 영역(예를 들어, 721)의 콘텐츠가 원격 메모리 영역(예를 들어, 대여자 디바이스 또는 기 기/서버)에서 호스팅된다는 나타내는데 사용될 수 있다. 메모리 상태 맵의 비트(예를 들어, 713)가 제2 미리 결정된 값(예를 들어, 1)을 가질 때, 비트(예를 들어, 713)는 해당 서브 영역(예를 들어, 723)의 콘텐 츠가 로컬 메모리 영역(예를 들어, 차용자 디바이스 또는 디바이스)에서 호스팅된다는 것을 나 타내는데 사용된다. 메모리 상태 맵을 사용하여, 차용자 디바이스(예를 들어, 101, 103, 105, 201 또는 621)는 변환 색인 버퍼 (TLB)를 사용하여 가상 어드레스에서 변환된 물리적 어드레스를 사용하기 전에 네트워크 연결 (예를 들어, 205)을 통해 데이터 마이그레이션을 수행할지 여부를 결정할 수 있다. 예를 들어, 차용자 디바이스에서 실행되는 애플리케이션은 해당 서브 영역(예를 들어, 721 또는 723)의 가 상 어드레스에 액세스하기 전에, 메모리 상태 맵을 할당한 다음 해당 비트(예를 들어, 711 또는 713)의 값 을 체크하라는 명령을 포함할 수 있다. 예를 들어, 컴파일러는 차용된 메모리에 의존할 수 있는 메모리 사용에 대한 이러한 명령을 삽입하도록 구성될 수 있다. 예를 들어, 가상 대 물리적 메모리 맵은 메모리 상태 맵의 로컬을 식별할 수 있고; 차용자 디바이스 (예를 들어, 201 또는 621)의 메모리 관리 유닛(MMU)은 메모리 상태 맵을 체크하도록 구성될 수 있다. 메모리 상태 맵의 해당 비트가 미리 결정된 제1 값(예를 들어, 0)을 갖는 경우, 메모리 관리 유닛 (MMU)은 메모리 폴트를 생성하여 차용자 디바이스의 운영 체제에 원격 메모리 영역의 서브 영역 에서 로컬 메모리 영역의 서브 영역으로 콘텐츠를 페치할 것을 요청할 수 있다. 서브 영역(72 1)의 콘텐츠가 로컬 메모리 영역에서 호스팅/캐시된 후, 메모리 관리 유닛(MMU)는 물리적 어드레스 를 사용하여 가상 어드레스에서 프로세서에 의해 요청된 메모리 액세스를 수행할 수 있다. 옵션 으로, 메모리 관리 유닛(MMU)은 차용자 디바이스의 운영 체제를 실행하지 않고 통신 디바이스를 사용하여 서브 영역의 콘텐츠를 페치하도록 구성될 수 있다. 메모리 상태 맵의 해당 비트가 미리 결정된 제2 값(예를 들어, 1)을 갖는 경우, 메모리 관리 유닛 (MMU)은 물리적 어드레스를 사용하여 가상 어드레스에서 프로세서에 의해 요청된 메모리 액세스를 수행할 수 있다. 도 35는 차용된 메모리에 대한 파인 그레인 데이터 마이그레이션을 위해 구성된 차용자 디바이스 및 차용 자 디바이스를 도시한다. 도 35에서, 대여자 디바이스의 메모리 영역은 차용자 디바이스에 대여된다. 차용자 디바이스 의 메모리 관리 유닛(MMU)은 도 33 및 도 34와 관련하여 상기에서 논의된 것과 같은 방식으로 가상대 물리적 메모리 맵을 저장한다. 가상 대 물리적 메모리 맵의 매핑은 가상 어드레스 영역의 세 분화도 레벨에서 지정된다. 차용자 디바이스는 로컬 메모리 영역을 대여자 디바이스의 차용된 메모리 영역의 캐시로서 사용한다. 차용자 디바이스는 가상 어드레스 영역에 대한 메모리 상태 맵을 저장하여 도 34에 도시된 서브 영역 레벨에서 파인 그레인 데이터 마이그레이션을 허용한다. 메모리 상태 맵은 가상 어드레스 영역을 사용하여 애플리케이션에 의해 관리될 수 있다. 예를 들어, 가상 어드레스 영역이 애플리케이션에서 사용하기 위해 할당될 때, 애플리케이션은 메모 리 상태 맵을 위한 메모리도 할당할 수 있다. 애플리케이션은 서브 영역(721, 723, …, 729)의 가상 어드 레스에 액세스하기 전에 서브 영역(721, 723, …, 729)의 로컬 가용성에 대해 메모리 상태 맵을 체크하는 명령을 포함한다. 이러한 명령은 컴파일러를 사용하여 자동화된 방식으로 삽입되거나 애플리케이션의 프로 그래머에 의해 프로그래밍될 수 있다. 대안적으로 또는 조합하여, 메모리 상태 맵은 운영 체제에 의해 관리될 수 있다. 예를 들어, 운영 체 제가 대여자 디바이스로부터 차용된 원격 메모리 영역에 액세스하기 위해 가상 대 물리적 메모 리 맵을 업데이트할 때, 운영 체제는 메모리 상태 맵를 위한 메모리를 할당할 수 있다. 가상 어 드레스 영역이 메모리 영역에 완전히 캐시되기 전에, 메모리 관리 유닛(MMU)(또는 실행 유닛 에서 실행되는 명령)은 가상 어드레스 영역의 어드레스에 액세스하기 전에 로컬 가용성에 대한 메모 리 상태 맵을 체크할 것을 운영 체제에 요청하도록 구성될 수 있다. 대안적으로 또는 조합하여, 메모리 상태 맵은 메모리 관리 유닛(MMU)에 의해 관리될 수 있다. 예를 들어, 레지스터의 가상 어드레스가 가상 어드레스 영역의 메모리에 액세스하는데 사용되는 것에 응답 하여, 메모리 관리 유닛(MMU)은 로컬 가용성을 위해 메모리 상태 맵을 체크하도록 구성될 수 있다. 메모리 상태 맵은 가상 어드레스 영역에 할당된 메모리 영역의 일부일 수 있으며, 메모리 영역 에 대한 로컬 메모리의 미리 리저브된 부분 또는 가상 어드레스 영역에 대한 가상 대 물리적 메모리 맵의 표시자에 의해 메모리 영역과 연관된 로컬 메모리의 일부일 수 있다. 옵션으로, 메모리 관 리 유닛(MMU)은 로컬 가용성 체크를 가속화하기 위해 메모리 상태 맵 또는 그 일부를 캐시할 수 있다. 액세스 중인 서브 영역(예를 들어, 721)이 현재 로컬 메모리에서 사용 가능하지 않은 경우, 메모리 관리 유닛(MMU)은 운영 체제에 대응하는 원격 서브 영역(예를 들어, 741)을 로컬 서브 영역(예를 들어, 731)으로 콘텐츠를 페치하도록 요청할 수 있다. 예를 들어, 메모리 관리 유닛(MMU)는 메모리 폴트 발생을 통해 요청할 수 있다. 대안적으로, 메모리 관리 유닛(MMU)은 운영 체제를 실행하지 않고, 원격 메모리 영역에 직접 액 세스하기 위해 통신 디바이스를 제어하도록 구성될 수 있다. 예를 들어, 도 13 내지 도 18의 기술은 차용 자 디바이스와 대여자 디바이스 간의 데이터 통신을 가속화하는데 사용될 수 있다. 옵션으로, 대여자 디바이스는 또한 차용자 디바이스로부터 수신된 데이터 마이그레이션 요청을 고려 하여 메모리 상태 맵을 추적할 수 있다. 대여자 디바이스는 일정 기간 동안의 메모리 상태 맵의 변화에 기초하여 메모리 사용 이력을 추적할 수 있다. 메모리 사용 이력은 대여자 디바이스에 의해 서브 영역(721, 723, …, 729)의 타이밍 및 패턴을 예측하는데 사용될 수 있다. 따라서, 대여자 디바이스 는 서브 영역(721, 723, …, 729)에 대한 캐시 미스를 줄이기 위해 서브 영역(721, 723, …, 729)을 기반 으로 예측 데이터 마이그레이션을 스케줄링할 수 있다. 예를 들어, 차용자 디바이스는 차용자 디바이스에서 서브 영역(721, 723, …, 729)의 사용 타이밍의 예측과 관련될 수 있는 정보를 제공할 수 있다. 이러한 정보의 예는 애플리케이션의 식별, 애플리케이션의 실행 마일스톤 등을 포함할 수 있다. 이러한 정보는 메모리 사용 이력의 일부로 수집될 수 있다. 대여자 디바이 스의 인공 지능(AI) 엔진은 (예를 들어, 인공 신경망(ANN)을 사용하여) 서브 영역 사용 예측을 수행하도록 구성될 수 있다. ANN은 애플리케이션의 메모리 사용 패턴을 결정하기 위해 다수의 차용자 디바이스(예를 들어, 201)의 사용 이력을 사용하여 옵션으로 트레이닝될 수 있다. 따라서, 대여자 디바이스의 컴퓨팅 파워 및/ 또는 데이터는 차용된 메모리를 사용하는 차용자 디바이스의 성능을 높이는데 사용될 수 있다. 대안적으로, 또는 조합하여, 차용자 디바이스는 또한 메모리 사용 이력을 수집하도록 구성될 수 있다. 예를 들어, 차용자 디바이스는 대여자 디바이스에 의해 차용자 디바이스에 대여된 메모리영역에 데이터를 저장함으로써 자신의 메모리 사용 이력 데이터를 대여자 디바이스와 공유할 수 있다. 예 를 들어, 대여자 디바이스는 예측을 위한 ANN 모델을 주기적으로 업데이트하고, 서비스로서의 메모리를 통 해 모델을 차용자 디바이스에 공유하여 차용자 디바이스가 개선된 예측을 수행할 수 있도록 할 수 있 다. 도 36은 차용된 메모리에 대한 파인 그레인 데이터 마이그레이션 방법을 도시한다. 예를 들어, 도 36의 방법은 도 2, 6, 9, 13 내지 17, 및/또는 19-24에 도시된 차용자 디바이스 및/또는 대여자 디바이스 또는 도 1에 도시된 디바이스(101, 103) 및 서버(105, 107)에서 구현될 수 있다. 블록에서, 컴퓨팅 디바이스(예를 들어, 201)는 컴퓨터 네트워크(예를 들어, 109)를 통해 원격 디바이스(예 를 들어, 203)로부터 메모리를 차용한다. 블록에서, 컴퓨팅 디바이스는 가상 메모리 어드레스 영역을 할당하여 원격 디바이스에 의해 컴퓨팅 디바이스에 대여된 메모리 양의 일부를 어드레싱한다. 블록에서, 컴퓨팅 디바이스는 차용된 메모리의 일부의 캐시로서 컴퓨팅 디바이스의 물리적 메모리 영 역을 구성한다. 블록에서, 컴퓨팅 디바이스는 가상 메모리 어드레스 영역과 물리적 메모리 영역에 대응하는 물 리적 메모리 어드레스 영역 사이의 매핑을 식별하는 가상 대 물리적 메모리 맵을 저장한다. 블록에서, 컴퓨팅 디바이스는 가상 메모리 어드레스 영역의 서브 영역(721, 723, …, 729)의 캐시 가 용성 상태(711, 713, …, 719)를 식별하는 메모리 상태 맵을 저장한다. 블록에서, 컴퓨팅 디바이스는 가상 메모리 어드레스를 사용하여 메모리 액세스를 만들기 전에, 가상 대 물리적 메모리 맵을 사용하여 가상 메모리 어드레스를 물리적 메모리 어드레스로 변환한다. 블록 (763 및 765)에서, 컴퓨팅 디바이스는 가상 메모리 어드레스를 포함하는 서브 영역(예를 들어, 721, 723, … 또는 729)을 식별하고 서브 영역(예를 들어, 721, 723, … 또는 729)의 캐시 가용성 상태(예를 들어, 711, 713, … 또는 719)를 체크한다. 블록 (766 및 767)에서, 서브 영역(예를 들어, 721, 723, …, 또는 729)이 물리적 메모리 영역에 아직 캐 시되지 않은 것으로 결정되면, 컴퓨팅 디바이스는 서브 영역을 캐시하기 위해 원격 디바이스와 통신한다. 블록에서, 일단 서브 영역(예를 들어, 721, 723, … 또는 729)이 물리적 메모리 영역에 캐시되면, 컴 퓨팅 디바이스는 물리적 메모리 어드레스를 사용하여 메모리 액세스를 수행한다, 예를 들어, 서브 영역(예를 들어, 721, 723, …, 또는 729)이 물리적 메모리 영역에 아직 캐시되지 않은 것으로 결정되면, 컴퓨팅 디바이스는 메모리 폴트를 생성할 수 있다. 메모리 폴트에 응답하여, 컴퓨팅 디 바이스의 운영 체제는 물리적 메모리 영역에서 대응하는 서브 영역을 캐시하기 위해 원격 디바이스와 통신 하도록 실행된다. 대안적으로, 컴퓨팅 디바이스의 메모리 관리 유닛(예를 들어, 216)은 서브 영역(예를 들어, 721, 723, … 또는 729)이 물리적 메모리 영역에 아직 캐시되지 않은 것으로 결정된 경우 원격 디바이스와 통신하여 물 리적 메모리 영역에서 대응하는 서브 영역을 캐싱하도록 구성된다. 메모리 관리 유닛(예를 들어, 216)은 컴퓨팅 디바이스의 운영 체제(예를 들어, 213)를 실행하는 컴퓨팅 디바이스의 프로세서(들)(예를 들어, 215) 없이 동작 하는 캐싱을 수행할 수 있다. 예를 들어, 컴파일러는 애플리케이션의 프로그램을 컴파일할 때 애플리케이션에 명령을 주입할 수 있다. 애플리 케이션이 운영 체제에서 할당된 가상 메모리 어드레스를 사용하여 메모리에 액세스하기 직전에 명령이 실 행되어 가상 메모리 어드레스의 로컬 캐시 가용성을 체크하도록 명령이 애플리케이션의 위치에 주입된다. 따라 서, 명령은 서브 영역의 가상 어드레스에 액세스하기 직전에 대응하는 서브 영역을 캐싱할 것을 컴퓨팅 디바이 스의 운영 체제에 요청하도록 구성될 수 있다. 예를 들어, 컴파일러는 동적으로 할당된 메모리에 대한 액세스가 이루어지는 애플리케이션의 프로그램 내 위치 를 결정하도록 구성될 수 있다. 프로그램의 메모리 액세스 요청은 해당 메모리 액세스 요청을 하기 전에 로컬 캐시 가용성 상태를 체크하는 수정된 버전의 메모리 액세스 요청으로 대체될 수 있다. 컴퓨팅 디바이스는 원격 디바이스에 의해 컴퓨팅 디바이스에 대여된 메모리의 부분을 어드레스 지정하기 위한 가상 메모리 어드레스 영역의 할당에 응답하여 메모리 상태 맵을 저장하기 위해 메모리를 할당 하도록 구성될 수 있다. 예를 들어, 컴퓨팅 디바이스에서 실행되는 애플리케이션이 운영 체제에 메모 리 양을 요청할 때, 운영 체제는 연관된 메모리 상태 맵에 대해 대응하는 양의 메모리를 할당할 수 있다. 메모리 상태 맵의 위치는 가상 어드레스 영역에 대한 가상 대 물리적 메모리 맵의 부분에서 지 정될 수 있다. 예를 들어, 가상 대 물리적 메모리 맵의 적어도 일부는 컴퓨팅 디바이스의 메모리 관리 유닛의 변환 색인 버퍼에 로드될 수 있다. 가상 메모리 맵의 일부가 변환 색인 버퍼에 있을 때, 메모리 관리 유닛은 가상 메모리 어드레스를 물리적 메모리 어드레스로 변환하기에 충분한 자원을 가진다. 물리적 메모리 어드레스, 메모리 관리 유닛, 운영 체제 또는 컴파일러에 의해 삽입된 명령/루틴 을 사용하기 전에, 가상 메모리 어드레스가 물리적 메모리 어드레스를 통해 액세스될 수 있도록 메모 리 상태 맵을 체크한다. 옵션으로, 메모리 관리 유닛은 변환 색인 버퍼에 로딩된 가상 대 물리적 메모리 맵이 가상 어드 레스 영역의 어드레스를 물리적 어드레스 영역의 어드레스로 변환하기 위한 부분을 포함할 때 메모리 상태 맵의 적어도 일부를 캐시할 수 있다. 옵션으로, 컴퓨팅 디바이스 및/또는 원격 디바이스는 메모리 상태 맵에 대한 변경에 기초하여 가상 메모리 어드레스 영역의 메모리 사용 이력을 추적할 수 있다. 컴퓨팅 디바이스 및/또는 원격 디바이스는 가상 메 모리 어드레스 영역의 서브 영역의 사용을 예측할 수 있다. 예측된 사용량을 갖는 서브 영역이 물리적 메 모리 영역에서 로컬 캐시 가용성이 부족한 경우, 컴퓨팅 디바이스와 원격 디바이스는 물리적 메모리 영역 에서 서브 영역을 캐시하기 위해 서로 통신할 수 있다. 예를 들어, 메모리 사용 이력을 사용하여 트레이닝 된 ANN을 기반으로 예측이 수행될 수 있다. ANN은 입력 정보를 처리하고 처리 결과를 생성하기 위해 인공 뉴런 세트를 사용한다. 전형적인 인공 뉴런은, 예 를 들어, ANN에 대한 입력으로서 및/또는 ANN에 있는 하나 이상의 다른 인공 뉴런으로부터 하나 이상의 입력 신 호를 수신하도록 구성된다. 인공 뉴런은 수신 입력 신호를 처리하여 예를 들어, ANN의 출력 및/또는 ANN의 하나 이상의 다른 인공 뉴런에 대한 입력으로서 하나 이상의 출력 신호를 생성한다. 예를 들어, 전형적인 인공 뉴런 은 수신된 입력 신호를 합산으로 더하고, 미리 결정된 비선형 함수를 합산에 적용하여 출력을 생성하고, 출력에 상이한 가중치를 적용하여 ANN의 출력으로 제공되고 및/또는 다른 인공 뉴런으로 발송되는 상이한 출력 신호를 생성할 수 있다. 비선형 함수 및/또는 가중치의 파라미터와 같이, 입력 신호로부터 출력 신호를 생성하는데 사 용되는 인공 뉴런의 파라미터는 ANN이 입력 신호에서 유용한 출력을 생성하는데 사용될 수 있도록 하나 이상의 기계 학습 기술을 통해 트레이닝될 수 있다. 예를 들어, ANN은 센서, 카메라, 레이더(무선 감지 및 범위 지정), 라이더(광 검출 및 범위 지정), 소나(음향 탐색 범위 지정) 등의 물체를 인식, 분류 또는 식별하기 위해 자율 차량에서 사용될 수 있다. 예를 들어, ANN은 모바일 디바이스에서 애플리케이션 사용 패턴, 위치 패턴, 모션 센 서 입력 등을 기반으로 사용자 액션을 예측, 인식, 분류 또는 식별하는데 사용할 수 있다. 서비스로서의 메모리(MaaS)는 ANN을 포함하는 계산을 조직화 및/또는 최적화하는데 사용될 수 있다. 예를 들어, ANN의 뉴런 계층은 계층의 성능 평가/추정 및 이들의 중요도에 기초하여 로컬 메모리 및 차용된 메 모리에 저장하기 위해 파티션될 수 있다. 대여자 디바이스와 차용자 디바이스 간의 연결이 성능 저하되면, 덜 중요한 계층을 차용된 메모리에 배치하여 차용된 메모리가 액세스 속도가 느려지거나 액세스할 수 없게 될 때 덜 중요한 계층의 처리가 스킵될 수 있다. 일부 경우에, ANN의 계층은 로컬에서 수행되는 대체 처리로 대체될 수 있다(예를 들어, 사용자로부터의 옵션 도 움/지원); 그러한 계층은 대여자 디바이스와 차용자 디바이스 사이의 연결성 성능 저하를 예상하여 차용된 메모 리에 구성될 수 있다. 일부 경우에, 대여자 디바이스는 ANN의 계층을 저장하기 위한 메모리 뿐만 아니라 ANN의 계층의 응답을 처리하 기 위한 컴퓨팅 파워도 제공한다. 예를 들어, 차용된 메모리를 사용할 때 성능 저하된 메모리 액세스 시간과 계 층을 처리하기 위해 대여자 디바이스의 컴퓨팅 파워를 사용할 때 향상된 계산 시간의 트레이드-오프를 결정하기 위해 성능 추정이 이루어질 수 있다. 계층을 저장하기 위해 차용된 메모리를 사용하고/하거나 대여자 디바이스 에서 메모리에 저장된 계층과 관련된 계산을 수행하기 위해 대여자 디바이스를 사용하기로 한 결정은 계층 적용 의 성능 추정 및/또는 중요도를 기반으로 할 수 있다. 도 37은 상기에서 논의된 서비스로서의 메모리를 제공하는 디바이스 및 기기/서버 상에 구성된 ANN을 예시한다. 도 37에서, ANN은 계층 A와 계층 B를 포함한다. 각 계층(803 및 805)은 다수의 인공 뉴런을 포 함할 수 있다. 예를 들어, 계층 A의 인공 뉴런은 인공 신경망에 대한 입력을 수신하고, 출력으 로서 계층 B의 인공 뉴런에 대한 입력 신호를 생성한다. 계층 B의 인공 뉴런은 입력 신호 를 처리하여 ANN의 출력을 생성한다. 도 37에서, 계층 A의 인공 뉴런의 계산 모델은 디바이스에 구성되고; 계층 B의 인공 뉴런의 계 산 모델은 기기/서버에 구성된다. 예를 들어, 계층 B의 인공 뉴런의 계산 모델은 기기/서버로부터 기기에 의해 차용된 메모리 에 모델을 저장함으로써 기기/서버에 구성될 수 있다. 디바이스에서 기기/서버로 입력 신 호를 송신하고 다시 디바이스로 출력을 획득하는 것은 기기/서버로부터 계층 B의 인 공 뉴런 모델을 페치하고 그리고/그런다음 축출하는 것보다 네트워크 자원을 덜 사용할 수 있다. 그러한 상황에 서, 디바이스를 대신하여 입력으로부터 출력을 계산하도록 기기/서버에 요청하는 것이 네 트워크 대역폭 사용에서 더 효율적일 수 있다. 전형적으로, 기기/서버 상의 인공 신경 계층 B에 의한 처리는 입력 신호를 기기/서버로 송 신하는 단계, 기기/서버의 처리 능력을 사용하여 입력 신호로부터 출력을 생성하는 단계, 기기/ 서버로부터의 출력을 디바이스로 송신하는 단계를 포함한다. 전형적으로, 디바이스 상의 인공 신경 계층 B에 의한 처리는 계층 B를 위한 공간을 만들기 위해 디바이스로부터 기기/서버로 콘텐츠를 축출하는 단계, 계층 B의 인공 뉴런의 계산 모델을 디바 이스로 마이그레이션하는 단계, 디바이스의 처리 능력을 사용하여 입력 신호에서 출력을 생성하는 단계, 및 이전에 축출된 콘텐츠를 디바이스로 다시 마이그레이션하는 단계를 포함한다. 일부 경우에, 계층 B의 인공 뉴런과 관련된 계산은 처리 집약적이다. 기기/서버 상의 계층 B에 의한 처리는 디바이스 상의 계층 B에 의한 처리보다 시간이 덜 걸릴 수 있다. 따라서, 디바이스(62 1)는 계층 B의 인공 뉴런의 모델을 사용하여 입력 신호를 처리하도록 기기/서버에 요청할 수 있 다. 일부 예에서, 기기/서버는 디바이스 및/또는 다른 디바이스(예를 들어, 유사한 환경 및/또는 조건에 서 사용되는 디바이스와 유사한 디바이스)로부터 수신된 추가 입력 및/또는 출력에 기초하여 인공 신 경망을 추가로 트레이닝할 수 있다. 기기/서버에서 하나 이상의 기계 학습 기술을 사용하여 수행된 트레이닝의 결과는 인공 신경 계층 A의 모델 및/또는 인공 신경 계층 B의 모델을 업데이트하는데 사 용될 수 있다. 일부 경우에, 계층 B의 인공 뉴런은 출력의 결과를 개선/미세 조정하는데 사용된다. 디바이스와 기기/서버 사이의 네트워크 연결이 성능 저하되어 계층 B의 인공 뉴런 모델에 액세스하기 위한 통신 비용 및/또는 지연의 관점에서 개선의 이익이 미미하면, 디바이스는 계층 B의 인공 뉴런을 포함하는 계산을 스킵할 수 있다. 예를 들어, 도 38에 도시된 바와 같이, 사용자 입력/지원이 있거나 없는 출력을 처리하기 위해 대안적인 모듈이 사용될 수 있다. 도 38은 인공 신경망의 일부의 처리를 교체하기 위해 옵션으로 사용될 수 있는 대체 모듈을 갖는 인 공 신경망을 도시한다. 대체 모듈은 인공 신경 계층 B에 대한 입력 신호를 처리하여 대체 출력을 생성하도록 구성된다. 예를 들어, 대체 모듈은 인공 신경 계층 B의 간략화된 버전이거나 인공 뉴런을 사용하지 않는 프로그 래밍된 루틴일 수 있다. 대체 모듈은 인공 신경 계층 B보다 적은 메모리 및/또는 처리 능력을 사용한 다. 옵션으로, 대체 모듈은 옵션의 사용자 입력을 수신하여 대체 출력을 생성하는 것을 돕도록 구성된다. 디바이스와 기기/서버 사이의 네트워크 연결이 성능 저하되면, 디바이스는 인공 신경 계층 B에 의한 처리를 스킵하고 인공 신경 계층 B의 출력에 대체물로서 대체 출력을 생성하기 위해 대체 모듈을 사용할 수 있다. 따라서, 인공 신경망을 기반으로 실행되는 애플리케이션(예를 들 어, 212 또는 627)은 차용된 메모리에 저장된 인공 신경 계층 B에 일시적으로 액세스할 수 없는 경우에도계속 기능할 수 있다. 예를 들어, 디바이스와 기기/서버 사이의 컴퓨터 네트워크 연결의 성능 저하를 예상하여, 인공 신경 계층 B의 모델은 디바이스의 로컬 메모리로부터 축출되고 기기/서버로 마이그레이션될 수 있다. 대체 모듈은 ANN에 대한 입력을 처리하기 위한 전체 메모리 요구사항이 감소되도록 디바 이스로 마이그레이션될 수 있다. 디바이스는 일정 기간 동안 인공 신경 계층 B액세스 없이 옵션 사용자 입력의 형태로 디바이스의 사용자로부터 가능한 도움을 받아 입력을 처리하여 출력(81 4)을 생성할 수 있다. 일반적으로, ANN은 많은 계층 및/또는 많은 서브 네트워크를 가질 수 있다. 디바이스 및/또는 기기/ 서버는 예측된 네트워크 성능 저하 기간 동안 ANN의 사용 패턴을 예측하고 예측된 사용 패턴을 사용 하여 대체 모듈을 생성함으로써 ANN을 간략화할 수 있다. 예를 들어, ANN의 서브 네트워크는 특정 사용 패턴에 대해 거의 일정한 출력을 생성할 수 있다. 따라서, ANN의 서브 네트워크의 근사 출력을 제공하여 서브 네트워크가 간략화될 수 있다. 예를 들어, ANN의 서브 네트워크의 출력은 ANN이 특정 사용 패턴에 따라 사용될 때 경험적 공식을 사용하여 근 사화될 수 있다. 따라서, 서브 네트워크는 실험식을 구현하는 대체 모듈에 의해 간략화될 수 있다. 도 39는 도 37 또는 38에 도시된 ANN과 같은 인공 신경망에 기초하여 계산을 처리하도록 구성된 컴퓨 팅 디바이스 및 기기/서버를 도시한다. 예를 들어, 디바이스는 도 1의 디바이스(101 또는 103) 또는 서버 또는 도 2, 6, 9, 13 - 15, 19, 21 - 24, 및/또는 26 - 31의 차용자 디바이스일 수 있다. 예를 들어, 기기/서버는 도 1의 디바이스 또는 서버(105 또는 107) 또는 도 2, 6, 13 - 17, 20, 21 - 24 및/또는 26 - 31의 대여자 디바이스(20 3)일 수 있다. 도 39에서, 디바이스는 기기/서버로부터 일정량의 메모리를 차용한다. 인공 신경 계층 A와 같은 ANN의 일부는 로컬 메모리에 캐시, 호스팅, 미러링 또는 로드되는 가상 어드레스 영역에 저장된 다. 가상 어드레스 영역은 디바이스의 로컬 메모리에서 로컬 메모리 영역에 대응하는 물리 적 어드레스 영역으로의 매핑을 통해 액세스될 수 있다. 애플리케이션(예를 들어, 소프트웨어 및/또는 하드웨어를 통해 구현됨)은 로컬 메모리 영역에 저장된 인공 신경 계층 A의 모델을 사용하여 계산을 수행할 수 있다. 인공 신경 계층 A와 같은 ANN의 다른 부분은 기기/서버의 원격 메모리 영역에서 호스팅되 는 다른 가상 어드레스 영역에 저장될 수 있다. 옵션으로, 인공 신경 계층 A의 출력은 인공 신경 계층 B에 대한 입력(예를 들어, 815)으로서 기기/서 버에 제공될 수 있다. 예를 들어, 디바이스에서 실행되는 애플리케이션은 인공 신경 계층 B를 사용하여 입력을 처리하기 위해 기기/서버의 애플리케이션에 요청을 발송할 수 있다. 일부 예에서, 동일한 애플리케이션(예를 들어, 627)은 상이한 스테이지에서 및/또는 병렬로(예를 들어, 도 28 내지 도 31에 도시됨) 디바이스 및 기기 디바이스에 의한 실행을 위해 가상 어드레스 영역에서 구성 될 수 있다. 옵션으로, 인공 신경 계층 A의 출력은 가상 어드레스 영역 및/또는 그 콘텐츠를 기기/서버에서 디바이스로 마이그레이션함으로써 디바이스에 의해 처리될 수 있다. 예를 들어, 디바이스는 가 상 어드레스 영역을 로컬 메모리 영역으로 마이그레이션하기 위한 공간을 만들기 위해 로컬 메모리 에서 가상 어드레스 영역을 축출할 수 있다. 옵션으로, 인공 신경 계층 A의 출력은 인공 신경 계층 B에 의해 추가 처리되지 않고 애플리케이션 에서 직접 사용될 수 있다. 예를 들어, 네트워크 연결이 성능 저하되면, 애플리케이션은 인공 신경 계층 B를 포함하는 계산을 스킵할 수 있다. 일부 경우에, 애플리케이션의 대체 모듈은 인 공 신경 계층 B를 통한 처리의 대체물로 사용된다. 대체 모듈은 디바이스의 사용자에게 유효한 대체 출력을 생성하는데 도움을 제공하도록 요청할 수 있다. 일부 경우에, 사용자 입력은 지도 기계 학습 기술 을 사용하여 인공 신경망을 추가로 트레이닝하는데 사용된다. 도 40은 차용된 메모리로 인공 신경망을 사용하는 방법을 도시한다. 예를 들어, 도 40의 방법은 도 1, 2, 13 - 14, 21 - 24, 26 - 31, 35 및/또는 39에 도시된 컴퓨팅 시스템에서 구현될 수 있다. 블록에서, 컴퓨팅 디바이스(예를 들어, 621)는 유선 또는 무선 컴퓨터 네트워크(예를 들어, 109)를 통해 원격 디바이스(예를 들어, 623)로부터 메모리(예를 들어, 586)를 차용한다. 블록에서, 컴퓨팅 디바이스는 인공 신경망의 제1 부분(예를 들어, 803)을 컴퓨팅 디바이스(62 1)의 로컬 메모리(211/588)에 저장한다. 블록에서, 컴퓨팅 디바이스는 인공 신경망의 제2 부분(예를 들어, 805)을 원격 디바이스의 차용된 메모리에 저장한다. 블록에서, 컴퓨팅 디바이스는 인공 신경망의 제1 부분(예를 들어, 803)의 출력(예를 들어, 81 5)을 생성한다. 블록에서, 컴퓨팅 디바이스와 원격 디바이스(예를 들어, 623) 사이의 유선 또는 무선 네트워크 연결 (예를 들어, 205)이 성능 저하되었는지 여부가 결정된다. 블록에서, 네트워크 연결이 성능 저하된 것으로 결정된 경우 인공 신경망의 제2 부분(예 를 들어, 805)의 대체물로 사용될 수 있는 대체 모듈(예를 들어, 807)이 사용 가능한지 여부가 결정된다. 블록에서, 컴퓨팅 디바이스는 대체 모듈(예를 들어, 807)이 컴퓨팅 디바이스 상에서 이용가능하 다고 결정될 때, 대체 모듈을 사용하여 출력을 처리한다. 그렇지 않으면, 컴퓨팅 디바이스(62 1)는 인공 신경망의 제2 부분(예를 들어, 805)에 의한 처리를 스킵할 수 있다. 블록에서, 네트워크 연결이 성능 저하되지 않은 것으로 결정된 경우 컴퓨팅 디바이스는 원 격 디바이스에서 차용된 메모리에 저장된 제2 부분을 사용하여 출력을 처리하도록 원격 디 바이스에 요청한다. 대안적으로, 컴퓨팅 디바이스는 제2 부분을 차용된 메모리에서 컴퓨팅 디바이스의 로컬 메 모리(211/588)로 마이그레이션하고 컴퓨팅 디바이스에서 출력을 처리할 수 있다. 블록에서, 원격 디바이스는 원격 디바이스에 의해 컴퓨팅 디바이스에 대여된 메모리 에 저장된 제2 부분을 사용하여 인공 신경망의 제2 부분의 출력을 생성한다. 블록에서, 컴퓨팅 디바이스는 원격 디바이스로부터 제2 부분의 출력을 수신한다. 예 를 들어, 원격 디바이스는 컴퓨팅 디바이스에 대여된 메모리의 일부에 출력을 저장할 수 있고, 출력의 가용성에 대한 통지를 컴퓨팅 디바이스에 발송할 수 있다. 컴퓨팅 디바이스는 원 격 디바이스로부터 차용된 메모리의 일부에 액세스함으로써 출력에 액세스할 수 있다. 옵션으로, 컴퓨팅 디바이스 및/또는 원격 디바이스는 네트워크 연결의 성능 저하를 예측할 수 있다. 이에 응답하여, 대체 모듈은 컴퓨팅 디바이스의 로컬 메모리에 구성된다. 예를 들어, 대체 모듈은 인공 신경망의 제2 부분의 출력에 대한 대체물로 대체 출력 의 계산을 보조하는 사용자 입력을 수신하도록 구성될 수 있다. 예를 들어, 대체 모듈은 인공 신경망의 제2 부분의 간략화된 모델일 수 있다. 간략화는 유선 또 는 무선 네트워크 연결의 성능 저하 예측에 기초하고 및/또는 인공 신경망 사용 패턴 예컨대, 현재 사용 패턴, 네트워크 연결의 성능 저하 이전에 사용 패턴, 인공 신경망의 이력 사용에 기초하여 예측된 사용의 예측 패턴을 기반으로 할 수 있다. 일부 예에서, 컴퓨팅 디바이스 및/또는 원격 디바이스는 인공 신경망의 제2 부분을 사용하 는 계산을 완료하는데 필요한 시간 추정치를 계산할 수 있다. 시간 추정치는 인공 신경망의 제2 부분(80 5)을 컴퓨팅 디바이스에 의한 계산을 수행하기 위한 컴퓨팅 디바이스로 마이그레이션시키기 위해 계 산될 수 있다. 시간 추정치는 또한 원격 디바이스가 인공 신경망의 제2 부분에 대응하는 계산을 수행하기 위해 자신의 계산 파워를 사용할 수 있도록 원격 디바이스에 출력을 제공하기 위해 계산될 수 있다. 시간 추정치는 옵션 중 하나를 선택하기 위해 비교될 수 있다. 인공 신경망의 제2 부분을 사용하여 인공 신경망의 제1 부분의 출력 처리를 수행할지 여부의 선택은 또한 에너지/파워 소 비 고려 사항에 기초할 수 있다(예를 들어, 컴퓨팅 디바이스의 배터리 수명 연장, 전체 파워 소비 감소등). 옵션으로, 원격 디바이스는 인공 신경망의 제1 부분이 컴퓨팅 디바이스의 애플리케이션 에서 사용되고 있는 기간에 기계 학습 기술을 사용하여 컴퓨팅 디바이스에 대여된 메모리에 저 장된 인공 신경망의 제2 부분을 업데이트할 수 있다. 예를 들어, 컴퓨팅 디바이스가 인공 신경망의 일부를 원격 디바이스에 의해 컴퓨팅 디바이스 에 대여된 메모리에 저장할 때, 원격 디바이스는 인공 신경망의 부분을 자동으로 업데이트 할 수 있다. 따라서, 컴퓨팅 디바이스에 의해 전체적으로 사용되는 인공 신경망의 기능은 인공 신경 망을 사용하는 애플리케이션을 중단하지 않고 업데이트될 수 있다. 따라서, 컴퓨팅 디바이스 및 원격 디바이스는 인공 신경망을 저장하고 인공 신경망에 기초 한 처리에서 협력하도록 구성될 수 있다. 일 실시예에서, 대여자 디바이스와 차용자 디바이스는 논리 어드레스 공간에서 상호작용할 수 있다. 애퍼처는 차용자 디바이스의 RAM에 구성될 수 있다. 예를 들어, 대여자 디바이스는 가상 메모리 디바이스를 생성한다. 차 용자는 이를 물리적 RAM 공간의 특정 영역에 애퍼처로서 할당한다. 차용자 물리적 어드레스 공간 내의 애퍼처 위치는 퍼져, 분산되어 있고 인접하지 않을 수 있다. 그러나 가상 메모리 디바이스에 대해 각 도메인은 차용자 의 물리적 어드레스 공간과 상이할 수 있는 연속적인 논리적 어드레스 공간의 뷰를 가지고 있다. 대여자 디바이 스는 논리적 애퍼처 어드레스를 사용하여 이러한 애퍼처에 액세스(판독 및 기록 모두)할 수 있다. 차용자 디바 이스에 의해 대여자 가상 디바이스에 두 가지 유형의 애퍼처가 개방된다: 논리적 애퍼처 공간에서 차용자 디바 이스의 프로세스 페이지가 대여자 디바이스에 가시적이도록 프로세스(애플리케이션) 페이지 애퍼처; 및 논리적 애퍼처 공간에 차용자 디바이스의 프로세스 페이지 테이블에 대한 액세스를 허용하는 유지 관리 애퍼처. 유지 관리 애퍼처는 자유 페이지 프레임 리스트 등을 식별하는 데 사용될 수 있다. 프로세스 페이지 애퍼처와 유지 관리 애퍼처는 하나로 결합될 수 있다. 차용자 디바이스에서 실행되는 각 프로세스는 고유한 애퍼처 세트를 가 질 수 있다. 논리적 애퍼처 어드레스는 차용자 물리적 어드레스와 다르다. 차용자 디바이스의 메모리 관리자(MM)는 DMA 요청 의 논리적 어드레스를 해당 물리적 어드레스로 변환하도록 구성된다. 따라서, 대여자 디바이스는 차용자의 실제 물리적 어드레스 공간을 볼 수 없다. 이것은 보호 및 DMA 격리를 위해 구현된다. 따라서, 각각의 논리 어드레스 는 약간의 레이턴시를 추가하는 어드레스 변환을 거친다. 그러나 메모리 관리자(MM)에는 속도를 높이는 메커니 즘이 있을 수 있다. 예를 들어, 페이지 테이블 엔트리(PTE)가 변환 색인 버퍼(TLB)에서 발견되지 않는 경우 페 이지 테이블 워크를 수행하도록 하드웨어를 구성할 수 있다. 논리적 어드레스가 차용자의 물리적 어드레스에 매 핑되는 방법에 대한 알고리즘이 미리 정의되어 있기 때문에, 디바이스는 최대 효율성을 위해 이 알고리즘을 따 르도록 최적화, 트레이닝, 조정될 수 있다. 차용 프로세서 메모리 관리와 원격 디바이스 DMA 메모리 관리 둘 모 두는 MM(memory manager)의 제어 하에 있을 수 있다. 메모리 관리자(MM)는 페이지 애퍼처 공간의 자유 페이지 프레임(PF)에 대한 페이지 프레임 포인터(PFP) 리스트 를 유지한다. 리스트는 유지 관리 애퍼처 내의 미리 결정된 위치에 저장된다. 대여자 디바이스는 이 리스트를 라운드 로빈 방식으로 스캔한다. 따라서, MM과 대여자 디바이스 둘 모두는 자유 페이지 프레임(PF)에서 동기화 된다. 동기화 지점이 과거에 있다(최악의 상호 연결 레이턴시, 대기열 지연 등으로 제한됨). 그러나 이것은 페 이지 애퍼처에서 새로운 할당에 사용되는 소수의 무료 PF를 갖는데 장애물이 되어서는 안 된다. 대여자 디바이 스는 동기화 상태(예를 들어, 해당 리스트에서 마지막으로 액세스한 포인터)를 MM에(예를 들어, 인터럽트를 통 해) 보고한다. MM은 동기화된 리스트의 크기가 너무 작아지면 FPFL(free page frame list)에 추가 PFP(page frame pointer)를 배치하여 이 인터럽트에 반응한다. MM과 대여자 디바이스 둘 모두는 FPFL(Free Page Frame List)(예를 들어, FIFO)을 수정하는 알고리즘도 알고 있다. 대안은 MM이 자유 PFP(페이지 프레임 포인터) 리스 트를 디바이스에 직접 전달하는 것이다. MM은 페이지 테이블을 스캔하고 각 스캔 반복에서 PTE의 '액세스된' 비트를 삭제하고, 여기서 '액세스된' 비트 는 CPU가 페이지에 액세스할 때마다 TLB에 의해 PTE에서 설정된다. 또한 후속 스캔 반복에서 PTE에 액세스하지 않는 경우 페이지당 에이지 카운터를 증분시킨다(차용자 CPU에 의해 PTE/페이지가 액세스된 경우 에이지 카운터 가 재설정됨). 결과적으로 카운터는 페이지 '스테일네스(staleness)'의 측정치를 제공한다. 논리 어드레스 공간에서 상호작용하는 대여자 디바이스와 차용자 디바이스의 후기록(write-back)(축출) 경로에 서, 후기록(축출)은 통신 링크에서 활동이 적은 기간 동안 수행된다. 그러나 링크 대역폭이 항상 포화 상태인경우, 이 경로는 영향을 미치므로 추가로 최적화되어야 한다. 스캔하는 동안, MM은 에이지가 특정 트리거 제한 에 도달한 페이지에 대해 PTE에 '보호된' 비트를 설정한다. 또한 각각 PTE(차용자 페이지 애퍼처 공간에 PFP)에 서 PFP를 판독하고 이 PFP를 FPFL에 추가한다. 대여자 디바이스는 링크를 통해 애퍼처의 페이지 테이블을 스캔 하고 '액세스된' 비트가 삭제된 보호된 PTE를 찾는다(두 조건 모두에서 페이지가 차용자 디바이스에서 대여자 디바이스로 마이그레이션 할 준비가 되었음을 나타냄). 대안적으로, 대여자 디바이스는 FPFL을 스캔하고 거기에 서 차용자 PFP를 획득할 수 있다(대여자 디바이스는 어쨌든 차용자 디바이스에서 자유 PFP를 획득하여 아래에서 논의되는 포워드 경로 동안 차용자의 페이지를 마이그레이션하고 저장하기 위해 해당 리스트를 스캔한다). 대여 자 디바이스는 보호된 페이지를 자체적으로 마이그레이션하여 그것을 가져올 수 있다. 그렇게 할 때 MM은 각 PTE에 대해 '디바이스 액세스' 비트를 설정하고, 이 페이지는 대여자 디바이스에 의해 액세스된다(대여자 디바 이스에 의한 모든 액세스는 어쨌든 MM을 통과한다). 대여자 디바이스는 대여자 디바이스에 의해 정의된 자체 구 현 방식에 따라 일부 PF의 자체 가상 어드레스 공간에 각 페이지를 배치한다. 대여자 디바이스는 새로운 PFP를 차용자 PTE의 자체 어드레스 공간에 설치한다. 따라서, 마이그레이션된 각 페이지에 대한 PTE는 '보호' 비트가 설정, '액세스' 비트 삭제되고, '디바이스 액세스' 비트 설정되고 및 디바이스 어드레스 공간의 PF에 PFP가 포 인팅된다. 논리 어드레스 공간에서 상호작용하는 대여자 디바이스와 차용자 디바이스의 포워드 경로에서, 차용자 CPU는 디 바이스 공간에 대한 PFP를 사용하여 보호된 PTE에 액세스할 때 인터럽트를 생성한다. 인터럽트에는 가상 어드레 스와 PTE가 포함되어 있다고 가정한다. 인터럽트 시점에 차용자 CPU는 이미 하드웨어 페이지 테이블 워크를 거 쳐(PTE가 TLB에 없는 경우), 코어 TLB에 PTE를 배치했다. 인터럽트는 두 부분으로 분할된다; 그리고 그것의 인 터럽트 핸들러(handler)는 병렬로 실행된다: 로컬(MM) 및 원격(대여자 디바이스). 인터럽트는 대여자 디바이스 에 의해 레이턴시가 제한된다. MM은 인터럽트된 가상 어드레스에 대한 새로운 PTE를 페이지 애퍼처 공간의 물리 적 페이지에 대한 PF 포인터로 설치한다(MM은 MM과 디바이스 둘 모두에 알려진 자유 PF 리스트에서 다음 PF를 선택한다). 새로운 PTE는 모든 TLB에 배치된다. 마이그레이션 전에 페이지가 있던 이전 PF가 회수되지 않은 경 우 해당 데이터가 여전히 존재하고 MM이 이 이전 PFP를 설치하고 데이터가 즉시 사용 가능할 수 있다. (이 기능 을 지원하기 위해, MM은 딕셔너리(dictionary) \"PTE => FPFL 리스트의 이전 PFP\"를 유지해야 한다). 대여자 디 바이스는 위 단계에서 MM에 의해 PTE에 설치된 것과 동일한 PF 포인터가 포인팅하는 페이지 애퍼처 공간의 위치 에 페이지 데이터를 기록한다(디바이스는 MM과 디바이스 간에 알려져 있고 동기화된 FPFL에서 다음 PFP를 선택 한다). 대여자 디바이스는 MM에 인터럽트를 발송하여 PTE의 보호를 해제하고 차용자 디바이스에서 대기 중인 프 로세스를 다시 시작한다. 대안으로, 대여자 디바이스는 새로운 PTE를 애퍼처에 직접 기록할 수 있다. 그러나, 대여자 디바이스는 PTE 위치, 즉 차용자 디바이스의 페이지 테이블 구조를 알아야 한다. 다른 실시예에서, 대여자 디바이스 및 차용자 디바이스는 가상 어드레스 공간 처리에서 상호작용할 수 있다. 예 를 들어, 대여자 디바이스는 애퍼처 역할을 하는 차용자 RAM의 특정 영역에 할당될 수 있다. 차용자 디바이스의 CPU/프로세서에서 실행되는 특정 프로세스의 데이터를 애퍼처에 할당할 수 있다. 대여자 디바이스에 개방된 애 퍼처에는 두 가지 유형이 있다 : 가상 어드레스 공간(애플리케이션)의 프로세스 데이터(페이지)를 위한 애퍼처 와 물리적 어드레스 공간의 프로세스 페이지 테이블을 위한 애퍼처. 애퍼처 할당은 유연할 수 있다. 예를 들어, 하나의 구현예에서 모든 애플리케이션 프로세스에 두 개의 애퍼처를 사용할 수 있다; 또는, 많은 프로세스 데이 터 애퍼처 및/또는 많은 페이지 테이블 애퍼처가 다른 구현예에서 애플리케이션 프로세스에 사용될 수 있다; 또 는 추가 구현예에서, 동적인 애퍼처 세트는 증가하거나 축소될 수 있는 활성/작업 프로세스의 현재 세트를 수용 하도록 관리될 수 있다. 메모리 관리자는 데이터를 애퍼처에 할당하도록 구성된다. 메모리 관리자는 하드웨어 가속 기능이 있는 운영 체제의 일부일 수 있다. 대여자 디바이스는 애퍼처를 통해 프로세스 가상 어드레스 공간 및 페이지 테이블에 액세스(예를 들어, 판독 및 기록)할 수 있다. 대여자 디바이스에 의한 판독 및 기록은 차용 자 디바이스의 CPU 캐시와 일관될 수 있다; 캐시가 순서화를 지원하는 경우 순서화가 유지될 수 있다. 프로세스 가상 어드레스 공간에서 상호작용하는 대여자 디바이스와 차용자 디바이스의 후기록(축출) 경로에서, 대여자 디바이스는 가상 어드레스를 디바이스 가상 어드레스로 변환하는 자체 페이지 테이블 구조를 유지한다. 대여자 디바이스는 마이그레이션된 페이지에 대해 자체 PTE(페이지 테이블 엔트리)를 설치한다. 나중에 대여자 디바이스는 어드레스 공간에서 특정 페이지를 검색할 때 테이블에서 페이지 워크를 수행할 수 있다. 디바이스 어드레스 공간은 프로세스 ID로 레이블이 지정되고 차용자 디바이스에서 개방된 프로세스/애퍼처의 가상 어드레 스 공간과 상관된 다수의 어드레스 공간을 포함할 수 있다. 그 결과, 가상 공간은 대여자 디바이스와 차용자 디 바이스 간에 일관성이 있다. 따라서, 대여자 디바이스는 페이지에 저장된 데이터에 대해 잠재적으로 계산 또는 압축을 수행할 수 있다. 메모리 관리자가 '디바이스 액세스' 비트가 설정된 보호된 모든 페이지에 대해 PTE를 스캔할 때 프로세스 가상 공간 애퍼처에서 물리적 공간을 회수하고 해당 페이지 프레임(또는 물리적 어드레스)을 널(null)로 설정하고 '액세스된 디바이스' 비트도 삭제한다. 따라서, 마이그레이션된 모든 페이지는 널 포인 트 프레임으로 PTE를 보호했다. 프로세스 가상 어드레스 공간에서 상호작용하는 대여자 디바이스 및 차용자 디바이스의 포워드 경로에서, 차용 자 CPU가 널 포인터로 보호된 PTE에 액세스할 때 둘 모두에 포워딩되는 인터럽트를 생성한다: 통신 링크를 통해 직접 대여자 디바이스 및 동시에 메모리 관리자에. 인터럽트에 대한 응답으로, 메모리 관리자는 액세스된 페이 지에 대해 새로운 페이지 프레임 포인터를 사용하여 새 PTE를 설치한다(예를 들어, 메모리 관리자가 사용할 수 있는 여러 자유 페이지 프레임 중 하나를 사용). 인터럽트에 대한 응답으로, 대여자 디바이스는 페이지 테이블 을 워크(walk)하고(예를 들어, 더 빠르게 만들기 위해 자체 TLB 및 하드웨어 페이지 워커를 가질 수 있음), 페 이지를 찾아 프로세스 애퍼처(가상 공간에서)에 페이지를 기록하고 차용자 디바이스에 직접 인터럽트 발송한다. 메모리 관리자는 대여자 디바이스로부터 기록 요청을 수신하고 로컬 TLB(MM이 방금 설치했기 때문에 해당 페이 지에 대한 PTE가 있어야 함)를 검색하고 디바이스 페이지에서 수신된 데이터를 PTE에 의해 포인팅된 페이지 프 레임에 기록하고, 해당 페이지에 대한 PTE를 보호 해제하여 디바이스 인터럽트를 처리하고('디바이스 액세스' 비트가 설정된 경우), 프로세스를 재개한다. 일반적으로, 상기에서 논의된 각각의 디바이스 또는 서버(예를 들어, 101, 103, 105, 107, 201, 203, 621, 623)는 하나 이상의 데이터 처리 시스템으로서 구현될 수 있다. 전형적인 데이터 처리 시스템은 마이크로프로세서(들)와 메모리를 상호 연결하는 상호 연결(예를 들어, 버스 및 시스템 코어 로직)을 포함할 수 있다. 마이크로프로세서는 또한 온 다이 캐시 계층 구조를 가질 수 있다. 상호 연결은 마이크로프로세서(들)와 메모리를 함께 상호 연결하고 또한 I/O 컨트롤러(들)를 통해 입력/출력 (I/O) 디바이스(들)에 상호 연결한다. I/O 디바이스는 디스플레이 디바이스 및/또는 주변 디바이스 예컨대, 마 우스, 키보드, 모뎀, 네트워크 인터페이스, 프린터, 스캐너, 비디오 카메라 및 당업계에 알려진 다른 디바이스 를 포함할 수 있다. 일 실시예에서, 데이터 처리 시스템이 서버 시스템일 때, 프린터, 스캐너, 마우스, 및/또는 키보드와 같은 I/O 디바이스의 일부는 옵션이다. 상호 연결은 다양한 브리지, 컨트롤러 및/또는 어댑터를 통해 서로 연결된 하나 이상의 버스를 포함할 수 있다. 일 실시예에서, I/O 컨트롤러는 USB 주변기기를 제어하기 위한 USB(Universal Serial Bus) 어댑터, 및/또는 IEEE-1394 주변기기를 제어하기 위한 IEEE-1394 버스 어댑터를 포함한다. 메모리는 ROM(Read Only Memory), 휘발성 RAM(Random Access Memory), 및 하드 드라이브, 플래시 메모리 등과 같은 비휘발성 메모리 중 하나 이상을 포함할 수 있다. 휘발성 RAM은 전형적으로 메모리의 데이터를 리프레시하거나 유지하기 위해 지속적으로 파워를 필요로 하는 동 적 RAM(DRAM)으로 구현된다. 비휘발성 메모리는 전형적으로 자기 하드 드라이브, 자기 광학 드라이브, 광학 드 라이브(예를 들어, DVD RAM), FLASH 메모리, 3D 크로스 포인트 또는 시스템에서 파워가 제거된 후에도 데이터를 유지하는 다른 유형의 메모리 시스템이다. 비휘발성 메모리는 또한 랜덤 액세스 메모리일 수 있다. 비휘발성 메모리는 데이터 처리 시스템의 나머지 컴포넌트에 직접 연결된 로컬 디바이스일 수 있다. 모뎀이나 이더넷 인터페이스와 같은 네트워크 인터페이스를 통해 데이터 처리 시스템에 결합된 네트워크 저장 디바이스와 같이 시스템으로부터 원격인 비휘발성 메모리도 사용할 수 있다. 본 개시에서, 일부 기능 및 동작은 설명을 간략화하기 위해 소프트웨어 코드에 의해 수행되거나 소프트웨어 코 드에 의해 야기되는 것으로 설명된다. 그러나, 이러한 표현은 또한 기능이 마이크로프로세서 또는 SoS(System- on-a-Chip)의 IP 블록과 같은 프로세서에 의한 코드/명령 실행으로 인해 발생할 수 있음을 지정하는데 사용된다. 대안적으로 또는 조합하여, 본 출원에 설명된 기능 및 동작은 ASIC(Application-Specific Integrated Circuit) 또는 FPGA(Field-Programmable Gate Array)를 사용하는 것과 같이 소프트웨어 명령을 사용하거나 사용하지 않고 특수 목적 회로를 사용하여 구현될 수 있다. 실시예는 소프트웨어 명령 없이 또는 소프트웨어 명령과 조합하여 유선 회로부를 사용하여 구현될 수 있다. 따라서, 이 기술은 하드웨어 회로부와 소프트웨어의 특정 조합에 제한 되지 않고 데이터 처리 시스템에 의해 실행되는 명령에 대한 특정 소스로 제한되지 않는다. 일 실시예는 완전히 기능하는 컴퓨터 및 컴퓨터 시스템에서 구현될 수 있지만, 다양한 실시예는 다양한 형태의 컴퓨팅 제품으로서 배포될 수 있고 실제로 배포에 영향을 미치는데 사용되는 특정 유형의 기계 또는 컴퓨터 판 독 가능 매체 여부에 관계없이 적용될 수 있다. 개시된 적어도 일부 양태는 적어도 부분적으로 소프트웨어로 구현될 수 있다. 즉, 기술은 ROM, 휘발성 RAM, 비 휘발성 메모리, 캐시 또는 원격 저장 디바이스와 같은 메모리에 포함된 명령 시퀀스를 실행하는 마이크로프로세 서와 같은 프로세서에 응답하여 컴퓨터 시스템 또는 기타 데이터 처리 시스템에서 수행될 수 있다. 실시예를 구현하기 위해 실행되는 루틴은 운영 체제 또는 \"컴퓨터 프로그램\"이라고 하는 특정 애플리케이션, 컴 포넌트, 프로그램, 객체, 모듈 또는 명령 시퀀스의 일부로 구현될 수 있다. 컴퓨터 프로그램은 전형적으로 컴퓨 터의 다양한 메모리 및 저장 디바이스에 다양한 시간에 설정된 하나 이상의 명령을 포함하며, 컴퓨터의 하나 이 상의 프로세서에 의해 판독되고 실행될 때 컴퓨터가 다양한 양태를 포함하는 엘리먼트를 실행하는데 필요한 작 업을 수행하게 한다. 기계 판독 가능 매체는 데이터 처리 시스템에 의해 실행될 때 시스템이 다양한 방법을 수행하게 하는 소프트웨 어 및 데이터를 저장하는데 사용될 수 있다. 실행 가능한 소프트웨어 및 데이터는 예를 들어, ROM, 휘발성 RAM, 비휘발성 메모리 및/또는 캐시를 비롯한 다양한 위치에 저장될 수 있다. 이 소프트웨어 및/또는 데이터의 일부 는 이러한 저장 디바이스 중 하나에 저장될 수 있다. 또한 중앙 집중식 서버 또는 피어 투 피어 네트워크에서 데이터와 명령을 획득할 수 있다. 데이터 및 명령의 다른 부분은 다른 중앙 서버 및/또는 피어 투 피어 네트워 크에서 다른 시간에 다른 통신 세션 또는 동일한 통신 세션에서 획득할 수 있다. 데이터 및 명령은 애플리케이 션을 실행하기 전에 전체가 획득될 수 있다. 또는, 실행에 필요할 때 적시에 데이터 및 명령의 일부를 동적으로 획득할 수 있다. 따라서, 데이터 및 명령이 특정 시간에 전체가 기계 판독 가능한 매체에 있을 필요는 없다. 컴퓨터 판독 가능 매체의 예는 비일시적, 기록 가능 및 기록 불가 유형 매체 예컨대, 휘발성 및 비휘발성 메모 리 디바이스, 판독 전용 메모리(ROM), 랜덤 액세스 메모리(RAM), 플래시 메모리 디바이스, 플로피 및 다른 이동 식 디스크, 자기 디스크 저장 매체, 광학 저장 매체(예를 들어, CD ROM(Compact Disk Read-Only Memory), DVD(Digital Versatile Disk) 등) 등을 포함할 수 있지만 이에 한정되지 않는다. 컴퓨터 판독 가능 매체는 명령 을 저장할 수 있다. 명령은 또한 전기, 광학, 음향 또는 반송파, 적외선 신호, 디지털 신호 등과 같은 전파된 신호의 다른 형태에 대한 디지털 및 아날로그 통신 링크로 구현될 수 있다. 그러나 반송파, 적외선 신호, 디지털 신호와 같은 전파 되는 신호는, 유형의 기계 판독 가능 매체가 아니며 명령을 저장하도록 구성되어 있지 않다. 일반적으로, 기계 판독 가능 매체는 기계(예를 들어, 컴퓨터, 네트워크 디바이스, 개인 휴대 정보 단말기, 제조 도구, 하나 이상의 프로세서 세트가 있는 임의의 디바이스)에 의해 액세스 가능한 형태로 정보를 제공(즉, 저장 및/또는 송신)하는 임의의 메커니즘을 포함한다. 다양한 실시예에서, 하드와이어드 회로부는 기술을 구현하기 위해 소프트웨어 명령과 조합하여 사용될 수 있다. 따라서, 기술은 하드웨어 회로부 및 소프트웨어의 특정 조합에 제한되지 않고, 데이터 처리 시스템에 의해 실행 되는 명령에 대한 특정 소스로 제한되지 않는다. 상기 설명 및 도면은 예시적이며 제한하는 것으로 해석되어서는 안 된다. 철저한 이해를 돕기 위해 여러 가지 구체적인 세부 사항이 설명되어 있다. 그러나 어떤 경우에는 설명을 모호하게 하는 것을 피하기 위해 잘 알려져 있거나 통상적인 세부 사항을 설명하지 않다. 본 개시에서 하나 또는 실시예에 대한 참조는 반드시 동일한 실시 예에 대한 참조는 아니며; 및 그러한 참조는 적어도 하나를 의미한다. 전술한 명세서에서, 본 개시는 그 특정 예시적인 실시예를 참조하여 설명되었다. 하기 청구범위에 기재된 바와 같은 더 넓은 정신 및 범위를 벗어나지 않고 다양한 수정이 이루어질 수 있음이 명백할 것이다. 따라서, 본 명 세서 및 도면은 제한적인 의미가 아니라 예시적인 의미로 간주되어야 한다.도면 도면1 도면2 도면3 도면4 도면5 도면6 도면7 도면8 도면9 도면10 도면11 도면12 도면13 도면14 도면15 도면16 도면17 도면18 도면19 도면20 도면21 도면22 도면23 도면24 도면25 도면26 도면27 도면28 도면29 도면30 도면31 도면32 도면33 도면34 도면35 도면36 도면37 도면38 도면39 도면40"}
{"patent_id": "10-2021-7042477", "section": "도면", "subsection": "도면설명", "item": 1, "content": "실시예는 유사한 참조가 유사한 엘리먼트를 나타내는 첨부 도면의 도면에서 제한이 아니라 예시의 방식으로 예 시된다. 도 1은 컴퓨팅 디바이스 또는 서버 컴퓨터가 다른 컴퓨팅 디바이스 및/또는 다른 서버 컴퓨터로부터 메모리를 차용할 수 있고 및/또는 메모리를 대여할 수 있는 시스템을 도시한다. 도 2는 일 실시예에 따른 통신 네트워크 연결을 통해 운영 체제 간 메모리 서비스를 구현하는 차용자 디바이스 (borrower device) 및 대여자 디바이스(lender device)를 도시한다. 도 3은 일 실시예에 따른 차용된 메모리를 사용하는 기술을 예시한다. 도 4는 일 실시예에 따른 상이한 차용된 메모리 영역에 대한 액세스를 가능하게 하기 위한 물리적 메모리 영역 의 사용을 예시한다. 도 5는 일 실시예에 따른 상이한 차용된 메모리 영역에 대한 액세스를 가능하게 하기 위한 물리적 메모리 영역 의 다른 사용을 예시한다. 도 6은 컴퓨팅 시스템의 차용자-대여자 메모리 계층을 예시한다. 도 7은 통신 네트워크 연결을 통해 운영 체제 간 메모리 서비스를 구현하는 방법을 도시한다. 도 8은 일 실시예에 따른 차용된 메모리의 페이지를 서비스하는 방법을 도시한다. 도 9는 서비스로서의 메모리에 대한 네트워크 트래픽이 스로틀링될 수 있는 것에 기초하여 상이한 중요도 레벨 의 메모리 영역을 갖는 차용자 디바이스를 도시한다. 도 10은 일 실시예에 따른 메모리 맵에서 메모리 영역의 중요도 레벨을 태깅하는 것을 예시한다. 도 11은 일 실시예에 따른 메모리 영역의 중요도 레벨을 식별하는 방법을 예시한다. 도 12는 일 실시예에 따른 서비스로서의 메모리에 대한 네트워크 통신을 스로틀링하는 방법을 도시한다. 도 13 내지 도 15는 일부 실시예에 따른 차용된 메모리에 액세스하기 위한 하드웨어 가속 구성을 예시한다. 도 16 및 17은 일부 실시예에 따른 대여된 메모리에 대한 액세스를 제공하기 위한 하드웨어 가속 구성을 예시한 다. 도 18은 일 실시예에 따른 메모리 관리 유닛을 통해 차용된 메모리에 대한 액세스를 가속화하는 방법을 도시한 다. 도 19 및 도 20은 일부 실시예에 따른 지능형 콘텐츠 마이그레이션을 수행하도록 구성된 차용자 디바이스 및 대 여자 디바이스를 도시한다. 도 21 내지 도 24는 일부 실시예에 따른 콘텐츠 이동을 예시한다. 도 25는 일부 실시예에 따른 차용된 메모리를 갖는 컴퓨팅 시스템에서 콘텐츠를 마이그레이션하는 방법을 도시 한다. 도 26 및 도 27은 상이한 컴퓨터의 로컬 메모리에 가상 어드레스 영역을 선택적으로 호스팅하는 것에 기초한 분 산 컴퓨팅을 예시한다.도 28 및 29는 애플리케이션 실행의 상이한 단계에서 상이한 컴퓨터 상에서 애플리케이션을 선택적으로 실행하 는 것을 예시한다. 도 30 및 31은 상이한 컴퓨터에서 호스팅되는 가상 기계에서 애플리케이션을 실행하는 것을 예시한다. 도 32는 MaaS(Memory as a Service) 기반의 분산 컴퓨팅 방법을 도시한다. 도 33은 서브 영역 콘텐츠의 캐시 상태를 식별하도록 구성된 메모리 상태 맵을 도시한다. 도 34는 서브 영역 레벨에서 마이그레이션될 수 있는 차용된 메모리에 액세스하기 위한 메모리 상태 맵의 사용 을 예시한다. 도 35는 차용된 메모리에 대한 파인 그레인 데이터 마이그레이션(fine grain data migration)을 위해 구성된 차 용자 디바이스 및 대여자 디바이스를 도시한다. 도 36은 차용된 메모리에 대한 파인 그레인 데이터 마이그레이션 방법을 도시한다. 도 37은 서비스로서의 메모리를 통해 디바이스 및 기기/서버에 구성된 인공 신경망을 예시한다. 도 38은 대안적인 모듈을 갖는 인공 신경망을 예시한다. 도 39는 인공 신경망에 기초하여 계산을 처리하도록 구성된 컴퓨팅 디바이스 및 기기/서버를 도시한다. 도 40은 차용된 메모리로 인공 신경망을 사용하는 방법을 도시한다."}
