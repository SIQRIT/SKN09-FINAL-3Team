{"patent_id": "10-2023-0023179", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0082141", "출원번호": "10-2023-0023179", "발명의 명칭": "센서를 통한 관객 탐지, 추적 및 행동에 따른 인터랙션 시스템", "출원인": "주식회사 리맵", "발명자": "김영주"}}
{"patent_id": "10-2023-0023179", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "실감형 콘텐츠가 실행되기 위한 실제 공간; 상기 실제 공간에 배치되는 객체; 상기 실제 공간의 벽면 또는 바닥면에 표시되는 미디어아트; 상기 실제 공간에 배치되는 조명설비; 상기 실제 공간에 배치되는 음향설비; 상기 실제 공간에서 동작 가능하게 프로그래밍된 로봇; 상기 미디어아트, 조명설비, 음향설비 및 로봇의 각 플레이를 제어하는 컨트롤러; 및 상기 실제 공간에서 관객을 탐지, 추적 및 행동을 감지하여 그에 매칭되는 관객동작신호를 생성하는 관객인식센서;를 포함하되, 상기 컨트롤러는, 상기 미디어아트, 조명설비, 음향설비 및 로봇의 각 플레이를 정해진 타임 코드에 따라 제어하는 시나리오 모듈; 및 상기 관객인식센서로부터 수신된 관객동작신호를 분석하여 소정의 기준에 따라 인터랙션 포인트를 설정하고, 인터랙션 포인트가 설정된 경우 상기 시나리오 모듈에 의한 제어에 우선하여 상기 미디어아트, 조명설비, 음향설비 및 로봇의 각 플레이를 상기 관객동작신호에 대응되게 제어할 수 있는 인터랙션 모듈;을 포함하는 것을 특징으로 하는 센서를 통한 관객 탐지, 추적 및 행동에 따른 인터랙션 시스템."}
{"patent_id": "10-2023-0023179", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 컨트롤러는, 상기 미디어아트, 조명설비, 음향설비 및 로봇을 각각 독립적으로 제어하는 복수개의 하부서버; 및 상기 복수개의 하부서버에 의한 제어를 상호 실시간으로 동기화시키는 메인서버;를 포함하는 것을 특징으로 하는 센서를 통한 관객 탐지, 추적 및 행동에 따른 인터랙션 시스템."}
{"patent_id": "10-2023-0023179", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서, 상기 인터랙션 모듈은, 상기 미디어아트, 조명설비, 음향설비 및 로봇의 플레이 제어를 통해 연출 가능한 다수의 연출 이벤트가 저장된 이벤트DB가 구비되고, 상기 관객인식센서로부터 수신된 관객동작신호를 소정의 기준또는 랜덤으로 상기 이벤트DB에 저장된 다수의 연출 이벤트 중 어느 하나에 매칭시켜 그 매칭된 연출 이벤트가플레이되도록 제어하는 것을 특징으로 하는 센서를 통한 관객 탐지, 추적 및 행동에 따른 인터랙션 시스템."}
{"patent_id": "10-2023-0023179", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항 내지 제3항 중 어느 하나의 항에 있어서, 상기 관객인식센서는, 빛을 이용한 거리 측정을 통해 관객을 탐지 및 추적하고, 관객이 벽면 또는 바닥면의 특정 위치를 터치했는지여부를 감지할 수 있는 라이다(Lidar) 센서; 및 상기 로봇에 설치되어 관객을 촬영하고, 촬영된 이미지를 분석하여 관객의 행동을 인식할 수 있는 이미지 센서;를 포함하는 것을 특징으로 하는 센서를 통한 관객 탐지, 추적 및 행동에 따른 인터랙션 시스템."}
{"patent_id": "10-2023-0023179", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항 내지 제3항 중 어느 하나의 항에 있어서, 공개특허 10-2024-0082141-3-상기 로봇은, 상호 관절로 연결되어 동작 가능한 복수개의 아암; 상기 복수개의 아암의 선단에 구비되어 관객에게 영상을 통해 시각적 정보를 전달할 수 있는 모니터; 및 상기 관객에게 소리를 통해 청각적 정보를 전달할 수있는 스피커; 외부로부터 입력된 텍스트를 인식하고, 인식된 텍스트를 변환하여 상기 스피커를 통해 소리로 출력할 수 있는 TTS 모듈; 및 상기 스피커에서 출력되는 소리와 동조되며 상기 모니터에서 출력되는 영상에 변화를 줄 수 있는 싱크 모듈;이 구비된 것을 특징으로 하는 센서를 통한 관객 탐지, 추적 및 행동에 따른 인터랙션시스템."}
{"patent_id": "10-2023-0023179", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5항에 있어서, 상기 로봇은, 관객의 음성을 감지할 수 있는 마이크; 및 상기 마이크에 감지된 관객의 음성을 인식하고, 인공지능 기술을 이용하여 인식된 관객의 음성에 대응할 수 있는 대화문을 생성하며, 생성된 대화문을 상기 TTS 모듈을 이용하여 상기 스피커를 통해 소리로 출력할 수 있는 대화 모듈;이 더 구비된 것을 특징으로 하는 센서를 통한 관객 탐지, 추적 및 행동에 따른 인터랙션 시스템."}
{"patent_id": "10-2023-0023179", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 센서를 통한 관객 탐지, 추적 및 행동에 따른 인터랙션 시스템에 관한 것으로, 보다 상세하게는 실감 형 콘텐츠에서 센서를 통해 관객을 탐지, 추적 및 행동을 감지하여 그에 매칭되는 관객동작신호를 생성하고, 관 객동작신호에 따라 인터랙션되는 미디어아트, 조명설비, 음향설비 및 로봇 등 다양한 오브제의 융합된 플레이를 (뒷면에 계속)"}
{"patent_id": "10-2023-0023179", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 센서를 통한 관객 탐지, 추적 및 행동에 따른 인터랙션 시스템에 관한 것으로, 보다 상세하게는 실감 형 콘텐츠에서 센서를 통해 관객을 탐지, 추적 및 행동을 감지하여 그에 매칭되는 관객동작신호를 생성하고, 관 객동작신호에 따라 인터랙션되는 미디어아트, 조명설비, 음향설비 및 로봇 등 다양한 오브제의 융합된 플레이를 연출할 수 있는 센서를 통한 관객 탐지, 추적 및 행동에 따른 인터랙션 시스템에 관한 것이다."}
{"patent_id": "10-2023-0023179", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "실감형 콘텐츠는 정보통신기술(ICT)을 기반으로 인간의 오감을 극대화하여 실제와 유사한 경험을 제공하는 차세 대 콘텐츠이다. 소비자와 콘텐츠의 능동적 상호작용성과 오감을 만족시키는 경험 제공, 이동성이 특징이다. 가상현실(VR), 증강현실(AR), 홀로그램, 오감 미디어 등이 대표적인 실감형 콘텐츠의 예가 되고 있으며 실감형 콘텐츠는 게임, 영화를 넘어 교육, 의료, 자동차 등 다양한 분야에서 적용되고 발전될 것으로 기대되고 있다. 종래기술로 대한민국 공개특허공보 제10-2022-0036496호(2022.03.23. 공개)에는 다양한 센서들에 기반한 복합 센싱 및 복수의 스크린들에 기반한 영상 블렌딩(blending)을 통한 '이머시브 콘텐츠 제공 시스템'이 제안된 바 있다. 하지만, 상기의 종래기술은 제공되는 실감형 콘텐츠가 단순히 복수의 스크린들에 기반한 영상 블렌딩(blendin g)으로만 구성되어 있어 관객의 행동에 대응되는 인터랙션에 한계가 있고, 사용자의 행동을 감지하는 장치로 깊 이 카메라만을 이용하여 관객을 탐지하고 추적하는 데에는 한계가 있었다."}
{"patent_id": "10-2023-0023179", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 상기와 같은 종래기술의 문제점을 해결하기 위하여 안출된 것으로 본 발명의 목적은 동작 가능한 로 봇을 실감형 콘텐츠의 소재로 활용하여 로보틱아트 실감형 콘텐츠의 제공이 가능하고, 센서를 통해 관객을 탐지, 추적 및 행동을 감지하여 그에 매칭되는 인터랙션 플레이를 연출할 수 있는 센서를 통한 관객 탐지, 추적 및 행동에 따른 인터랙션 시스템을 제공하는 데에 있다."}
{"patent_id": "10-2023-0023179", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기와 같은 목적을 달성하고자 본 발명에 따른 센서를 통한 관객 탐지, 추적 및 행동에 따른 인터랙션 시스템 은 실감형 콘텐츠가 실행되기 위한 실제 공간; 상기 실제 공간에 배치되는 객체; 상기 실제 공간의 벽면 또는 바닥면에 표시되는 미디어아트; 상기 실제 공간에 배치되는 조명설비; 상기 실제 공간에 배치되는 음향설비; 상 기 실제 공간에서 동작 가능하게 프로그래밍된 로봇; 상기 미디어아트, 조명설비, 음향설비 및 로봇의 각 플레이를 제어하는 컨트롤러; 및 상기 실제 공간에서 관객을 탐지, 추적 및 행동을 감지하여 그에 매칭되는 관객동 작신호를 생성하는 관객인식센서;를 포함하되, 상기 컨트롤러는 상기 미디어아트, 조명설비, 음향설비 및 로봇 의 각 플레이를 정해진 타임 코드에 따라 제어하는 시나리오 모듈; 및 상기 관객인식센서로부터 수신된 관객동 작신호를 분석하여 소정의 기준에 따라 인터랙션 포인트를 설정하고, 인터랙션 포인트가 설정된 경우 상기 시나 리오 모듈에 의한 제어에 우선하여 상기 미디어아트, 조명설비, 음향설비 및 로봇의 각 플레이를 상기 관객동작 신호에 대응되게 제어할 수 있는 인터랙션 모듈;을 포함하는 것을 특징으로 한다. 여기서, 상기 컨트롤러는 상기 미디어아트, 조명설비, 음향설비 및 로봇을 각각 독립적으로 제어하는 복수개의 하부서버; 및 상기 복수개의 하부서버에 의한 제어를 상호 실시간으로 동기화시키는 메인서버;를 포함하는 것을 특징으로 한다. 여기서, 상기 인터랙션 모듈은 상기 미디어아트, 조명설비, 음향설비 및 로봇의 플레이 제어를 통해 연출 가능 한 다수의 연출 이벤트가 저장된 이벤트DB가 구비되고, 상기 관객인식센서로부터 수신된 관객동작신호를 소정의 기준 또는 랜덤으로 상기 이벤트DB에 저장된 다수의 연출 이벤트 중 어느 하나에 매칭시켜 그 매칭된 연출 이벤 트가 플레이되도록 제어하는 것을 특징으로 한다. 여기서, 상기 관객인식센서는 빛을 이용한 거리 측정을 통해 관객을 탐지 및 추적하고, 관객이 벽면 또는 바닥 면의 특정 위치를 터치했는지 여부를 감지할 수 있는 라이다(Lidar) 센서; 및 상기 로봇에 설치되어 관객을 촬 영하고, 촬영된 이미지를 분석하여 관객의 행동을 인식할 수 있는 이미지 센서;를 포함하는 것을 특징으로 한다. 여기서, 상기 로봇은 상호 관절로 연결되어 동작 가능한 복수개의 아암; 상기 복수개의 아암의 선단에 구비되어 관객에게 영상을 통해 시각적 정보를 전달할 수 있는 모니터; 및 상기 관객에게 소리를 통해 청각적 정보를 전 달할 수 있는 스피커; 외부로부터 입력된 텍스트를 인식하고, 인식된 텍스트를 변환하여 상기 스피커를 통해 소 리로 출력할 수 있는 TTS 모듈; 및 상기 스피커에서 출력되는 소리와 동조되며 상기 모니터에서 출력되는 영상 에 변화를 줄 수 있는 싱크 모듈;이 구비된 것을 특징으로 한다. 여기서, 상기 로봇은 관객의 음성을 감지할 수 있는 마이크; 및 상기 마이크에 감지된 관객의 음성을 인식하고, 인공지능 기술을 이용하여 인식된 관객의 음성에 대응할 수 있는 대화문을 생성하며, 생성된 대화문을 상기 TTS 모듈을 이용하여 상기 스피커를 통해 소리로 출력할 수 있는 대화 모듈;이 더 구비된 것을 특징으로 한다."}
{"patent_id": "10-2023-0023179", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "상기와 같은 구성에 의하여 본 발명에 따른 센서를 통한 관객 탐지, 추적 및 행동에 따른 인터랙션 시스템은 로 보틱아트 실감형 콘텐츠의 제공이 가능하고, 센서를 통해 관객을 탐지, 추적 및 행동을 감지하여 그에 매칭되는 인터랙션 플레이를 연출할 수 있는 장점이 있다. 또한, 본 발명에 따른 센서를 통한 관객 탐지, 추적 및 행동에 따른 인터랙션 시스템은 관객감지센서로 라이다 (Lidar) 센서와 이미지 센서를 이용하여 효과적으로 관객을 탐지, 추적 및 행동을 감지할 수 있는 장점이 있다. 또한, 본 발명에 따른 센서를 통한 관객 탐지, 추적 및 행동에 따른 인터랙션 시스템은 복수개의 하부서버와 이 를 동기화시키는 메인서버의 분산구조를 통해 각 오브제 상호 간의 연동 플레이에 레이턴시를 최소화할 수 있는 장점이 있다."}
{"patent_id": "10-2023-0023179", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하에서는 도면에 도시된 실시예를 참조하여 본 발명에 따른 센서를 통한 관객 탐지, 추적 및 행동에 따른 인 터랙션 시스템을 보다 상세하게 설명하기로 한다. 도 1은 본 발명의 일실시예에 따른 센서를 통한 관객 탐지, 추적 및 행동에 따른 인터랙션 시스템의 구성도이고, 도 2는 본 발명의 일실시예에 따른 로봇의 구성도이며, 도 3은 본 발명의 일실시예에 따른 하부서 버 및 메인서버의 구성도이고, 도 4는 본 발명의 일실시예에 따른 실제 공간과 가상의 3D 공간의 구성 관계도이 다. 도 1을 살펴보면, 본 발명의 일실시예에 따른 센서를 통한 관객 탐지, 추적 및 행동에 따른 인터랙션 시스템은 실제 공간과, 객체와, 미디어아트와, 조명설비와, 음향설비와, 로봇과, 관객인식센서 와, 컨트롤러를 포함한다. 상기 실제 공간은 실제로 실감형 콘텐츠가 실행되기 위한 공간이다. 본 발명의 일실시예에서 제공되는 실감형 콘텐츠는 별도의 실감형 콘텐츠 저작 도구를 통해 도 4에 도시된 바와 같이 가상의 3D 공간(10a)에서 저작될 수 있다. 이에 도 5 내지 도 8에는 가상의 3D 공간(10a)을 이용하여 본 발명을 설명하였으나 가상의 3D 공간(10a)에서의 구성과 실제 공간에서의 구성은 도 4에 도시된 바와 같이 실질적으로 일대일 매칭된다. 상기 객체는 상기 실제 공간에 배치되는 구성으로 도 5의 (a)에 가상의 객체(20a)로 도시된 바와 같이 3D 공간(10a)의 바닥면에 놓이는 의자 등의 소품이 될 수 있고, 도 6에 도시된 바와 같이 가상의 로봇(60a)을 원통형으로 둘러싸는 샤막(20a')이 될 수도 있다. 상기 미디어아트는 상기 실제 공간의 벽면 또는 바닥면에 표시되는 구성이다. 상기 미디어아트를 구현하기 위해서는 실제 공간의 벽면에 부착되는 대형 디스플레이 장치 또는 벽면을 향해 영상을 투사하는 프로젝터 등이 이용될 수 있다. 한편, 실감형 콘텐츠 저작 도구를 통해 구현된 가상의 미디어아트(30a)와 실제 미디어아트는 도 4에 도시된 바와 같이 저작 도구의 컨트롤러부와 본 시스템의 컨트롤러의 정보 교환을 통해 동기화 가능하고, 고 속 통신망을 이용해 양자간 실시간 동기화 또한 가능하게 구성될 수 있다. 상기 조명설비 및 음향설비는 조명 효과와 음향 효과를 위해 상기 실제 공간에 배치되는 구성이다. 상기 조명설비 및 음향설비 또한 실감형 콘텐츠 저작 도구를 통해 가상으로 배치되어 가상의 3D 공간 (10a)에서의 조명 및 음향 효과를 확인함으로써 실제 공간에서 최적화된 조명설비 및 음향설비의 종류 및 배치를 정할 수 있게 구성되는 것이 바람직하다. 한편, 가상의 조명설비(40a) 및 음향설비(50a)의 플레이는 도 4에 도시된 바와 같이 저작 도구의 컨트롤러부 와 본 시스템의 컨트롤러의 정보 교환을 통해 실제 조명설비 및 음향설비의 플레이와 동기화 가능하고, 고속 통신망을 이용해 양자간 실시간 동기화 또한 가능하게 구성될 수 있다. 상기 로봇은 상기 실제 공간에서 동작 가능하게 프로그래밍된 구성이다. 실감형 콘텐츠 저작 도구에서는 상기 실제 공간에서 동작 가능하게 프로그래밍된 로봇을 3D 공간(10a) 에 가상의 로봇(60a)으로 구현할 수 있고, 도 4에 도시된 바와 같이 상호간 플레이의 동기화가 가능하도록 구성 된다. 즉, 가상의 로봇(60a)과 실제 로봇은 상호 동일한 동작이 가능하도록 프로그래밍되고, 가상의 3D 공간(10 a)에 적용된 상기 가상의 로봇(60a)의 플레이(속도, 스케일 등)를 시뮬레이션한 후 조정된 움직임 값이 실제 로 봇에 적용되도록 정보를 송수신하여 상호 동기화시킬 수 있게 된다. 본 발명의 일실시예에서 상기 로봇은 도 2에 도시된 바와 같이 복수개의 아암과, 모니터와, 스피커 와, 마이크와, TTS 모듈과, 싱크 모듈고, 대화 모듈이 구비될 수 있다.한편, 도 6에 도시된 바와 같이 가상의 로봇(60a) 주변으로 가상의 객체(20a)로서의 샤막(20a')을 원통형으로 세워서 상기 샤막(20a')에 미디어아트(30a)가 표시되도록 구성하는 것과 같이 실제 공간에서 로봇 주변 을 구성할 수 있다. 상기 복수개의 아암은 복수개가 상호 관절로 연결되어 동작 가능한 구성이다. 상기 모니터는 상기 복수개의 아암의 선단에 구비되어 관객에게 영상을 통해 시각적 정보를 전달할 수 있는 구성이다. 상기 모니터에는 관객에게 친숙함을 제공할 수 있는 캐릭터 얼굴 화면을 표시할 수 있다. 상기 스피커는 상기 관객에게 소리를 통해 청각적 정보를 전달할 수 있는 구성이고, 상기 마이크는 관 객의 음성을 감지할 수 있는 구성이다. 상기 TTS 모듈은 외부로부터 입력된 텍스트를 인식하고, 인식된 텍스트를 변환하여 상기 스피커를 통해 소리로 출력할 수 있는 구성이다. 상기 TTS 모듈은 운영요원에 의해 실시간으로 관객과의 소통을 위한 텍스트가 입력되도록 구성될 수도 있고, 후술할 대화 모듈에서 생성된 대화문이 텍스트로 입력되도록 구성될 수도 있다. 상기 싱크 모듈은 상기 스피커에서 출력되는 소리와 동조되며 상기 모니터에서 출력되는 영상에 변 화를 줄 수 있는 구성이다. 일예로 상기 모니터에 캐릭터 얼굴 화면이 표시된 경우 상기 싱크 모듈은 상기 캐릭터 얼굴 화면의 입 술이 스피커에서 출력되는 소리에 맞춰 립싱크되도록 구성할 수 있다. 상기 대화 모듈은 상기 마이크에 감지된 관객의 음성을 인식하고, 인공지능 기술을 이용하여 인식된 관 객의 음성에 대응할 수 있는 대화문을 생성하며, 생성된 대화문을 상기 TTS 모듈을 이용하여 상기 스피커 를 통해 소리로 출력할 수 있는 구성이다. 상기와 같은 구성에 의하여 본 발명의 일실시예에 따른 로봇은 관객과 대화를 통한 인터랙션 플레이를 할 수 있게 된다. 상기 관객인식센서는 상기 실제 공간에서 관객을 탐지, 추적 및 행동을 감지하여 그에 매칭되는 관객동 작신호를 생성하는 구성이다. 본 발명의 일실시예에서 상기 관객인식센서는 라이다(Lidar) 센서와, 이미지 센서를 포함한다. 상기 라이다(Lidar) 센서는 빛을 이용한 거리 측정을 통해 관객을 탐지 및 추적하고, 관객이 벽면 또는 바 닥면의 특정 위치를 터치했는지 여부를 감지할 수 있는 구성이다. 상기 이미지 센서는 상기 로봇에 설치되어 관객을 촬영하고, 촬영된 이미지를 분석하여 관객의 행동을 인식할 수 있는 구성이다. 상기와 같이 라이다(Lidar) 센서와, 이미지 센서의 조합을 통해 본 발명에 따른 관객인식센서는 관 객을 효과적으로 탐지, 추적 및 행동을 감지할 수 있게 된다. 상기 컨트롤러는 상기 미디어아트, 조명설비, 음향설비 및 로봇의 각 플레이를 제어하는 구성으로 시나리오 모듈과, 인터랙션 모듈이 구비된다. 상기 시나리오 모듈은 상기 미디어아트, 조명설비, 음향설비 및 로봇의 각 플레이를 정해 진 타임 코드에 따라 제어하는 구성이다. 즉, 상기 시나리오 모듈는 실감형 콘텐츠의 전체적인 스토리를 시간의 순서에 따라 순차적으로 진행할 수 있도록 하는 구성이다. 상기 인터랙션 모듈은 상기 관객인식센서로부터 수신된 관객동작신호를 분석하여 소정의 기준에 따라 인터랙션 포인트를 설정하고, 인터랙션 포인트가 설정된 경우 상기 시나리오 모듈에 의한 제어에 우선하여 상기 미디어아트, 조명설비, 음향설비 및 로봇의 각 플레이를 상기 관객동작신호에 대응되게 제어할 수 있는 구성이다. 본 발명의 일실시예에서 상기 인터랙션 모듈은 상기 미디어아트, 조명설비, 음향설비 및 로봇 의 플레이 제어를 통해 연출 가능한 다수의 연출 이벤트가 저장된 이벤트DB가 구비된다. 또한, 상기 인터랙션 모듈은 상기 관객인식센서로부터 수신된 관객동작신호를 소정의 기준 또는 랜덤으 로 상기 이벤트DB에 저장된 다수의 연출 이벤트 중 어느 하나에 매칭시켜 그 매칭된 연출 이벤트가 플레이 되도록 제어할 수 있다. 실감형 콘텐츠 저작 도구를 통한 가상의 3D 공간(10a)을 예로 들면 도 7(a)에서와 같이 대기 상태로 있다가 관 객(70a)이 등장하는 경우 도 7의 (b)에서와 같이 벽면 및 바닥면에 미디어아트(30a)가 표시되고, 관객(70a)이 로봇(60a)을 향해 이동하는 경우 로봇(60a)은 관객을 향해 방향을 전환하는 연출 이벤트가 플레이되도록 구성될 수 있다. 한편, 상기 컨트롤러는 도 3에 도시된 바와 같이 상기 미디어아트, 조명설비, 음향설비 및 로 봇을 각각 독립적으로 제어하는 복수개의 하부서버와, 상기 복수개의 하부서버에 의한 제어를 상호 실시간으로 동기화시키는 메인서버를 포함한다. 이러한 복수개의 하부서버에 의한 분산구조 및 메인서버를 통한 동기화를 통해 상기 미디어아트, 조명설비, 음향설비 및 로봇 상호 간의 연동 플레이에 레이턴시를 최소화할 수 있게 된다. 앞에서 설명되고 도면에서 도시된 센서를 통한 관객 탐지, 추적 및 행동에 따른 인터랙션 시스템은 본 발명을 실시하기 위한 하나의 실시예에 불과하며, 본 발명의 기술적 사상을 한정하는 것으로 해석되어서는 안된다. 본 발명의 보호범위는 이하의 특허청구범위에 기재된 사항에 의해서만 정하여지며, 본 발명의 요지를 벗어남이 없"}
{"patent_id": "10-2023-0023179", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "이 개량 및 변경된 실시예는 본 발명이 속하는 기술분야에서 통상의 지식을 가진 자에게 자명한 것인 한 본 발 명의 보호범위에 속한다고 할 것이다."}
{"patent_id": "10-2023-0023179", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일실시예에 따른 센서를 통한 관객 탐지, 추적 및 행동에 따른 인터랙션 시스템의 구성도 도 2는 본 발명의 일실시예에 따른 로봇의 구성도 도 3은 본 발명의 일실시예에 따른 하부서버 및 메인서버의 구성도 도 4는 본 발명의 일실시예에 따른 실제 공간과 가상의 3D 공간의 구성 관계도 도 5는 본 발명의 일실시예에 따른 객체, 미디어아트 및 조명설비의 배치에 대한 설명을 위한 예시도 도 6은 본 발명의 일실시예에 따른 객체, 조명설비, 음향설비 및 로봇의 배치에 대한 설명을 위한 예시도 도 7은 본 발명의 일실시예에 따른 센서를 통한 관객 탐지, 추적 및 행동에 따른 인터랙션 시스템의 작동 상태 예시도도 8은 본 발명의 일실시예에 따른 센서를 통한 관객 탐지, 추적 및 행동에 따른 인터랙션 시스템을 이용한 실 감형 콘텐츠의 실행 예시도"}
