{"patent_id": "10-2023-0011530", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0119458", "출원번호": "10-2023-0011530", "발명의 명칭": "다중 인공지능 음성 인식 모델 및 챗봇을 이용하여 인식 정확도가 개선된 음성 인식 처리 장", "출원인": "주식회사 아이에스피디", "발명자": "정한별"}}
{"patent_id": "10-2023-0011530", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "음성 인식을 위한 복수의 음성 인식 모델들을 포함하는 다중 음성 인식 모델을 사전 구축하는 인식 모델구축부;음성 인식 대상 데이터를 상기 다중 음성 인식 모델에 입력하여, 상기 음성 인식 모델들 각각의 처리 결과를 획득하는 다중 인식 처리부;상기 다중 음성 인식 모델들의 인식 결과에 따라, 각 음성 인식 모델의 자모열 인식 결과를 산출하고, 상기 자모열 인식 결과를 비교하여, 음성 인식 모델 간 자모열 유사도를 산출하는 자모열 유사도 측정부;상기 자모열 유사도에 기초하여, 상기 복수의 음성 인식 모델들 중 하나 이상의 음성 인식 모델의 인식 결과를이용한 출력값을, 챗봇 질의 기반으로 보정하는 챗봇 질의 보정부; 및상기 챗봇 질의 보정부의 보정 결과 및 상기 자모열 유사도를 이용하여, 상기 음성 인식 대상 데이터에 대응하는 인식 결과 정보를 출력하는 출력부를 포함하는음성 인식 처리 장치."}
{"patent_id": "10-2023-0011530", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 자모열 유사도 측정부는,상기 음성 인식 모델의 단어 인식 결과 또는 글자 인식 결과를, 자음 및 모음이 독립적인 문자 코드로 나열되도록 분리하여, 상기 자모열 인식 결과를 산출하는음성 인식 처리 장치."}
{"patent_id": "10-2023-0011530", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,상기 자모열 유사도 측정부는,상기 글자 인식 결과의 문자 코드 또는 상기 단어 인식 결과를 구성하는 하나 이상의 문자 코드에 매핑된 제1언어 인식 결과 데이터를, 초성, 중성 또는 종성에 대응하는 상대 거리 위치 값으로 각각 변환 및 결합하여, 상기 자모열 인식 결과를 산출하는음성 인식 처리 장치."}
{"patent_id": "10-2023-0011530", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서,상기 자모열 유사도 측정부는,상기 복수의 음성 인식 모델 각각의 자모열 인식 결과 상호간 유사도를 산출하고, 상기 산출된 자모열 인식 결과 상호간 유사도를 조합 연산하여, 상기 자모열 유사도를 산출하는음성 인식 처리 장치."}
{"patent_id": "10-2023-0011530", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서,상기 챗봇 질의 보정부는,공개특허 10-2024-0119458-3-상기 음성 인식 대상 데이터의 단어별 자모열 유사도를 식별하고, 상기 단어별 자모열 유사도가 임계조건에 해당하는 단어가 하나 이상 식별되는 경우, 상기 출력값을 챗봇 질의 기반으로 보정하기 위한 질의 정보를 사용자단말로 전송하는음성 인식 처리 장치."}
{"patent_id": "10-2023-0011530", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5항에 있어서,상기 질의 정보는,상기 자모열 유사도가 임계조건에 해당하는 단어의 각 음성 인식 모델별 인식 결과를 이용하여, 상기 임계조건에 해당하는 단어의 각 음성 인식 모델별 인식 결과 중 어느 하나를 상기 사용자 단말에서 선택 가능하도록 구성되는 질의 인터페이스 선택 정보를 포함하는음성 인식 처리 장치."}
{"patent_id": "10-2023-0011530", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6항에 있어서,상기 챗봇 질의 보정부는,상기 질의 인터페이스 선택 정보 출력에 따라 상기 사용자 단말로부터 수신되는 응답 정보에 기초하여, 상기 출력값을 보정 처리하는음성 인식 처리 장치."}
{"patent_id": "10-2023-0011530", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "음성 인식을 위한 복수의 음성 인식 모델들을 포함하는 다중 음성 인식 모델을 사전 구축하는 단계;음성 인식 대상 데이터를 상기 다중 음성 인식 모델에 입력하여, 상기 음성 인식 모델들 각각의 처리 결과를 획득하는 단계;상기 다중 음성 인식 모델들의 인식 결과에 따라, 각 음성 인식 모델의 자모열 인식 결과를 산출하고, 상기 자모열 인식 결과를 비교하여, 음성 인식 모델 간 자모열 유사도를 산출하는 단계;상기 자모열 유사도에 기초하여, 상기 복수의 음성 인식 모델들 중 하나 이상의 음성 인식 모델의 인식 결과를이용한 출력값을, 챗봇 질의 기반으로 보정하는 단계; 및상기 보정 결과 및 상기 자모열 유사도를 이용하여, 상기 음성 인식 대상 데이터에 대응하는 인식 결과 정보를출력하는 단계를 포함하는음성 인식 처리 장치의 동작 방법."}
{"patent_id": "10-2023-0011530", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서,상기 자모열 유사도를 산출하는 단계는,상기 음성 인식 모델의 단어 인식 결과 또는 글자 인식 결과를, 자음 및 모음이 독립적인 문자 코드로 나열되도록 분리하여, 상기 자모열 인식 결과를 산출하는 단계를 포함하는음성 인식 처리 장치의 동작 방법."}
{"patent_id": "10-2023-0011530", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9항에 있어서,상기 자모열 유사도를 산출하는 단계는,상기 글자 인식 결과의 문자 코드 또는 상기 단어 인식 결과를 구성하는 하나 이상의 문자 코드에 매핑된 제1공개특허 10-2024-0119458-4-언어 인식 결과 데이터를, 초성, 중성 또는 종성에 대응하는 상대 거리 위치 값으로 각각 변환 및 결합하여, 상기 자모열 인식 결과를 산출하는음성 인식 처리 장치의 동작 방법."}
{"patent_id": "10-2023-0011530", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제10항에 있어서,상기 자모열 유사도를 산출하는 단계는,상기 복수의 음성 인식 모델 각각의 자모열 인식 결과 상호간 유사도를 산출하고, 상기 산출된 자모열 인식 결과 상호간 유사도를 조합 연산하여, 상기 자모열 유사도를 산출하는음성 인식 처리 장치의 동작 방법."}
{"patent_id": "10-2023-0011530", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제8항에 있어서,상기 보정하는 단계는,상기 음성 인식 대상 데이터의 단어별 자모열 유사도를 식별하고, 상기 단어별 자모열 유사도가 임계조건에 해당하는 단어가 하나 이상 식별되는 경우, 상기 출력값을 챗봇 질의 기반으로 보정하기 위한 질의 정보를 사용자단말로 전송하는 단계를 포함하는음성 인식 처리 장치의 동작 방법."}
{"patent_id": "10-2023-0011530", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제12항에 있어서,상기 질의 정보는,상기 자모열 유사도가 임계조건에 해당하는 단어의 각 음성 인식 모델별 인식 결과를 이용하여, 상기 임계조건에 해당하는 단어의 각 음성 인식 모델별 인식 결과 중 어느 하나를 상기 사용자 단말에서 선택 가능하도록 구성되는 질의 인터페이스 선택 정보를 포함하는음성 인식 처리 장치의 동작 방법."}
{"patent_id": "10-2023-0011530", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제13항에 있어서,상기 보정하는 단계는,상기 질의 인터페이스 선택 정보 출력에 따라 상기 사용자 단말로부터 수신되는 응답 정보에 기초하여, 상기 출력값을 보정 처리하는 단계를 포함하는음성 인식 처리 장치의 동작 방법."}
{"patent_id": "10-2023-0011530", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명의 실시 예에 따른 음성 인식 처리 장치는, 음성 인식을 위한 복수의 음성 인식 모델들을 포함하는 다중 음성 인식 모델을 사전 구축하는 인식 모델 구축부; 음성 인식 대상 데이터를 상기 다중 음성 인식 모델에 입력 하여, 상기 음성 인식 모델들 각각의 처리 결과를 획득하는 다중 인식 처리부; 상기 다중 음성 인식 모델들의 인 식 결과에 따라, 각 음성 인식 모델의 자모열 인식 결과를 산출하고, 상기 자모열 인식 결과를 비교하여, 음성 인식 모델 간 자모열 유사도를 산출하는 자모열 유사도 측정부; 상기 자모열 유사도에 기초하여, 상기 복수의 음 성 인식 모델들 중 하나 이상의 음성 인식 모델의 인식 결과를 이용한 출력값을 챗봇 질의 기반으로 보정하는 챗 봇 질의 보정부; 및 상기 챗봇 질의 보정부의 보정 결과 및 상기 자모열 유사도를 이용하여, 상기 음성 인식 대 상 데이터에 대응하는 인식 결과 정보를 출력하는 출력부를 포함한다."}
{"patent_id": "10-2023-0011530", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 음성 인식 처리 장치 및 그 동작 방법에 관한 것이다. 보다 구체적으로, 본 발명은 다중 인공지능 음 성 인식 모델 및 챗봇을 이용하여 인식 정확도가 개선된 음성 인식 처리 장치 및 그 동작 방법에 관한 것이다."}
{"patent_id": "10-2023-0011530", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "일반적으로, 자동 음성 인식(Automatic speech recognition, ASR)은 음성-텍스트 변환(speech-to-text, STT)으 로도 알려진 음성 녹음을 자동으로 인식하여 텍스트로 변환하는 과정을 포함한다. 이러한 STT를 위한 데이터는 크게 음향학적 관점과 언어학점 관점으로 볼 수 있다. 음향학점 관점은 말하는 이, 공간, 노이즈 등의 환경적인 데이터가 주를 이루고 언어학적 관점에서는 어휘, 문맥, 문법 등을 모델링하기 위 한 언어 데이터가 주를 이룬다. 또한, STT는 크게 음성/언어 데이터로부터 인식 네트워크 모델을 생성하는 오프라인 학습 단계와 사용자가 발성 한 음성을 인식하는 온라인 탐색 단계로 나뉘며, STT 엔진은 음성과 언어 데이터의 사전 지식을 사용해서 음성 신호로부터 문자 정보를 출력하는데 이 때 해석이라는 차원에서 STT 알고리즘을 디코더(Decoder)라고도 부릅니 다. 디코딩 단계에서는 학습 단계 결과인 음향 모델(Acoustic Model), 언어 모델(Language Model)과 발음 사전 (Pronunciation Lexicon)을 이용하여 입력된 특징 벡터를 모델과 비교, 스코어링(Scoring)하여 단어 열을 최종 결정짓는다. 음향 모델링은 해당 언어의 음운 환경별 발음의 음향적 특성을 확률 모델로 대표 패턴을 생성하는 과정이고, 언 어모델링은 어휘 선택, 문장 단위 구문 구조 등 해당 언어의 사용성 문제에 대해 문법 체계를 통계적으로 학습 하는 과정으로서, 발음 사전 구축을 위해서는 텍스트를 소리 나는 대로 변환하는 음소 변환(Grapheme-to- Phoneme) 구현 과정이 필요하며, 표준 발음을 대상으로 하는 발음 변환 규칙만으로는 방언이나 사용자의 발화 습관과 어투에 따른 다양한 패턴을 반영하기 어려운 경우가 있어 별도의 사전 구축이 필요하다. 이에 따라 구축되는 음향 모델은 대부분 확률 통계 방식이나 신경망 기반의 딥러닝 학습 방식으로 이루어지고 있으며, 각각의 모델의 연구와 모델별 특성에 따라 개별 모델들의 STT의 성능 향상이 이루어지고 있다. 한편, 이러한 STT는 최근 다양한 API들로 구현되고 있는 챗봇 기능의 자연어 처리 기술 중 하나로서 이용되고 있는 바, 차량용 내비게이션, 키오스크, 대화형 IVR, 가상비서, 스마트 홈 등에 서 광범위하게 이용되고 있으며, 이러한 챗봇 기술은 TTS와 STT 그리고, AI 처리기술을 혼합하여 구현되고 있다. 그러나, 아직까지도 자동음성인식을 위한 개별 모델의 인식 정확도는 90%정도가 한계이며, 여전히 인식 오류가 발생되고 있다. 특히, 생활 노이즈, 노인과 어린이의 부정확한 발음 특징 등으로 인해 인식 정확도의 편차가 큰 문제점이 있다. 또한, 인식할 단어가 지정되어 있는 자동음성인식 모델의 경우 문법교정 절차에서 일반적으로 많이 쓰이는 단어 로 변환이 되어, 특히 유사한 발음의 단어 인식에서 실제 화자의 의미가 왜곡될 수 있다. 특히, 인식 가능한 단어가 제한적인 자동음성인식 모델 이용시에는, 잘못 인식된 단어 또는 글자의 보정 자체가 불가하므로, 결과적으로 실제 생활에서의 인식 정확도 저하를 극복할 수가 없게 되는 바, 이러한 자동음성인식 방식에 대한 근본적인 변화를 통해 인식 정확도를 개선하는 것이 요구되고 있다."}
{"patent_id": "10-2023-0011530", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 상기한 바와 같은 문제점들을 해결하고자 안출된 것으로, 다중 인공지능 음성인식 모델을 이용한 모 델별 음성 인식 예측 결과를 자모분리 처리하고, 자모분리 처리된 자모열의 유사도에 따른 챗봇기반 질의 검증 을 수행함으로써, 인식 가능한 단어가 제한적인 경우라 하더라도 그 인식 정확도를 보정할 수 있으며, 특히 생 활 노이즈, 노인과 어린이의 부정확한 발음 특징 등으로 인한 인식 정확도의 편차를 최소화할 수 있는 다중 인 공지능 음성 인식 모델 및 챗봇을 이용하여 인식 정확도가 개선된 음성 인식 처리 장치 및 그 동작 방법을 제공 하는 데 그 목적이 있다."}
{"patent_id": "10-2023-0011530", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기한 바와 같은 과제를 해결하기 위한 본 발명의 실시 예에 따른 장치는, 음성 인식을 위한 복수의 음성 인식 모델들을 포함하는 다중 음성 인식 모델을 사전 구축하는 인식 모델 구축부; 음성 인식 대상 데이터를 상기 다 중 음성 인식 모델에 입력하여, 상기 음성 인식 모델들 각각의 처리 결과를 획득하는 다중 인식 처리부; 상기 다중 음성 인식 모델들의 인식 결과에 따라, 각 음성 인식 모델의 자모열 인식 결과를 산출하고, 상기 자모열 인식 결과를 비교하여, 음성 인식 모델 간 자모열 유사도를 산출하는 자모열 유사도 측정부; 상기 자모열 유사 도에 기초하여, 상기 복수의 음성 인식 모델들 중 하나 이상의 음성 인식 모델의 인식 결과를 이용한 출력값을 챗봇 질의 기반으로 보정하는 챗봇 질의 보정부; 및 상기 챗봇 질의 보정부의 보정 결과 및 상기 자모열 유사도 를 이용하여, 상기 음성 인식 대상 데이터에 대응하는 인식 결과 정보를 출력하는 출력부를 포함한다. 또한, 상기한 바와 같은 과제를 해결하기 위한 본 발명의 실시 예에 따른 방법은, 음성 인식을 위한 복수의 음 성 인식 모델들을 포함하는 다중 음성 인식 모델을 사전 구축하는 단계; 음성 인식 대상 데이터를 상기 다중 음 성 인식 모델에 입력하여, 상기 음성 인식 모델들 각각의 처리 결과를 획득하는 단계; 상기 다중 음성 인식 모 델들의 인식 결과에 따라, 각 음성 인식 모델의 자모열 인식 결과를 산출하고, 상기 자모열 인식 결과를 비교하 여, 음성 인식 모델 간 자모열 유사도를 산출하는 단계; 상기 자모열 유사도에 기초하여, 상기 복수의 음성 인 식 모델들 중 하나 이상의 음성 인식 모델의 인식 결과를 이용한 출력값을 챗봇 질의 기반으로 보정하는 단계; 및 상기 보정 결과 및 상기 자모열 유사도를 이용하여, 상기 음성 인식 대상 데이터에 대응하는 인식 결과 정보 를 출력하는 단계를 포함한다."}
{"patent_id": "10-2023-0011530", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명의 실시 예에 따르면, 다중 인공지능 음성인식 모델을 이용한 모델별 음성 인식 예측 결과를 자모분리 처리하고, 자모분리 처리된 자모열의 유사도에 따른 챗봇기반 질의 검증을 수행함으로써 음성 인식 모델의 출력 정확도를 기존의 개별 모델보다 크게 향상시킬 수 있다. 이에 따라, 본 발명의 실시 예에 따르면, 인식 가능한 단어가 제한적인 경우라 하더라도 그 인식 정확도를 보정 할 수 있으며, 특히 생활 노이즈, 노인과 어린이의 부정확한 발음 특징 등으로 인한 인식 정확도의 편차를 최소 화할 수 있는 다중 인공지능 음성 인식 모델 및 챗봇을 이용하여 인식 정확도가 개선된 음성 인식 처리 장치 및 그 동작 방법을 제공할 수 있다."}
{"patent_id": "10-2023-0011530", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하의 내용은 단지 본 발명의 원리를 예시한다. 그러므로 당업자는 비록 본 명세서에 명확히 설명되거나 도시 되지 않았지만 본 발명의 원리를 구현하고 본 발명의 개념과 범위에 포함된 다양한 장치와 방법을 발명할 수 있 는 것이다. 또한, 본 명세서에 열거된 모든 조건부 용어 및 실시 예들은 원칙적으로, 본 발명의 개념이 이해되 도록 하기 위한 목적으로만 명백히 의도되고, 이와 같이 특별히 열거된 실시 예들 및 상태들에 제한적이지 않는 것으로 이해되어야 한다. 또한, 본 발명의 원리, 관점 및 실시 예들 뿐만 아니라 특정 실시 예를 열거하는 모든 상세한 설명은 이러한 사 항의 구조적 및 기능적 균등물을 포함하도록 의도되는 것으로 이해되어야 한다. 또한 이러한 균등물들은 현재 공지된 균등물뿐만 아니라 장래에 개발될 균등물 즉 구조와 무관하게 동일한 기능을 수행하도록 발명된 모든 소 자를 포함하는 것으로 이해되어야 한다. 따라서, 예를 들어, 본 명세서의 블록도는 본 발명의 원리를 구체화하는 예시적인 회로의 개념적인 관점을 나타 내는 것으로 이해되어야 한다. 이와 유사하게, 모든 흐름도, 상태 변환도, 의사 코드 등은 컴퓨터가 판독 가능 한 매체에 실질적으로 나타낼 수 있고 컴퓨터 또는 프로세서가 명백히 도시되었는지 여부를 불문하고 컴퓨터 또 는 프로세서에 의해 수행되는 다양한 프로세스를 나타내는 것으로 이해되어야 한다. 또한 프로세서, 제어 또는 이와 유사한 개념으로 제시되는 용어의 명확한 사용은 소프트웨어를 실행할 능력을 가진 하드웨어를 배타적으로 인용하여 해석되어서는 아니 되고, 제한 없이 디지털 신호 프로세서(DSP) 하드웨어, 소프트웨어를 저장하기 위한 롬(ROM), 램(RAM) 및 비휘발성 메모리를 암시적으로 포함하는 것으로 이 해되어야 한다. 주지관용의 다른 하드웨어도 포함될 수 있다. 상술한 목적, 특징 및 장점은 첨부된 도면과 관련한 다음의 상세한 설명을 통하여 보다 분명해질 것이며, 그에"}
{"patent_id": "10-2023-0011530", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "따라 본 발명이 속하는 기술분야에서 통상의 지식을 가진 자가 본 발명의 기술적 사상을 용이하게 실시할 수 있 을 것이다. 또한, 본 발명을 실시함에 있어서 본 발명과 관련된 공지 기술에 대한 구체적인 설명이 본 발명의요지를 불필요하게 흐릴 수 있다고 판단되는 경우에 그 상세한 설명을 생략하기로 한다. 본 출원에서 사용한 용어는 단지 특정한 실시 예를 설명하기 위해 사용된 것으로, 본 발명을 한정하려는 의도가 아니다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 출원에서, \"포함 하다\" 또는 \"가지다\" 등의 용어는 명세서상에 기재된 특징, 숫자, 단계, 동작, 구성요소, 부품 또는 이들을 조 합한 것이 존재함을 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성요소, 부 품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되어야 한다. 이하, 첨부한 도면들을 참조하여, 본 발명의 바람직한 실시 예를 보다 상세하게 설명하고자 한다. 본 발명을 설 명함에 있어 전체적인 이해를 용이하게 하기 위하여 도면상의 동일한 구성요소에 대해서는 동일한 참조부호를 사용하고 동일한 구성요소에 대해서 중복된 설명은 생략한다. 도 1은 본 발명의 실시 예에 따른 전체 시스템을 개략적으로 도시한 도면이며, 도 2는 본 발명의 실시 예에 따 른 음성 인식 처리 장치를 보다 구체적으로 설명한 블록도이다. 도 2를 참조하면, 본 발명의 일 실시 예에 따른 시스템은 음성 인식 처리 장치 및 사용자 단말을 포 함할 수 있다. 보다 구체적으로, 음성 인식 처리 장치 및 사용자 단말은 공중망(Public network)과의 연결을 통해 유선 및 무선 중 하나 이상으로 연결되어 데이터를 송수신할 수 있다. 상기 공중망은 국가 혹은 통신 기간 사업 자가 구축 및 관리하는 통신망으로, 일반적으로 전화망, 데이터망, CATV망 및 이동 통신망 등을 포함하여 불특 정 다수의 일반인이 타 통신망이나 인터넷에 접속 가능하도록 연결 서비스를 제공한다. 여기서 상기 공중망 네트워크는 근거리 통신망(Local Area Network; LAN), 광역 통신망(Wide Area Network; WAN), 부가가치 통신망(Value Added Network; VAN), 개인 근거리 무선통신(Personal Area Network; PAN), 이동 통신망(Mobile radio communication network) 또는 위성 통신망 등과 같은 모든 종류의 유/무선 네트워크로 구 현될 수 있다. 그리고 본 명세서에서 설명되는 사용자 단말은 PC(personal computer), 노트북 컴퓨터(laptop computer), 휴대폰(Mobile phone), 스마트폰(Smart Phone), 태블릿 PC(Tablet PC), PDA(Personal Digital Assistants), PMP(Portable Multimedia Player) 등이 포함될 수 있다. 또한 음성 인식 처리 장치 및 사용자 단말은 상기 장치 구분에 한정되지 않고 데이터 처리 및 저장, 관리 기능을 고도화하여 확장할 수 있는 서버 시스템 관련 장치를 포함할 수 있다. 또한, 음성 인식 처리 장치 및 사용자 단말은 각 통신망에 상응하는 프로토콜로 통신하기 위한 각각 의 통신 모듈을 포함할 수 있다. 그리고, 음성 인식 처리 장치는, 사용자 단말의 요청에 따라, 음성 인식 서비스를 제공하는 서비스 제공 장치일 수 있다. 음성 인식 처리 장치는, 사용자 단말에서 수신되는 음성 인식 대상 데이터로부터, 본 발명의 실시 예 에 따른 다중 인공지능 음성 인식 모델의 자모열 유사도를 이용한 음성 인식 및 보정 처리를 수행하고, 보정 처 리에 따라 결정된 출력값으로부터 획득된 인식 결과 정보를 사용자 단말로 제공하는 서비스 제공 장치일 수 있다. 또한, 음성 인식 처리 장치는, 본 발명의 실시 예에 따른 다중 인공지능 음성 인식 모델의 자모열 유사도 를 이용한 음성 인식 처리 및 챗봇 기반 질의 보정을 수행하는 음성 인식 처리 어플리케이션을 사용자 단말 로 제공하고, 사용자 단말에서 상기 다중 인공지능 음성 인식 모델의 자모열 유사도를 이용한 음성 인식 처리가 수행되도록 하는 서비스 제공 장치일 수 있다. 또한, 사용자 단말 및 음성 인식 처리 장치는 하나의 음성 인식 시스템으로 동작할 수 있으며, 본 발 명의 실시 예에 따른 다중 인공지능 음성 인식 모델의 자모열 유사도를 이용한 음성 인식 처리 기능의 각 일부 가 사용자 단말 및 음성 인식 처리 장치로 분산되어 처리될 수도 있다. 따라서, 본 명세서에서는 음성 인식 처리 장치의 구성과 동작을 중심으로 설명하나, 사용자 단말 또 한 음성 인식 처리 장치의 구성을 구비하거나, 동작을 수행할 수 있음은 자명할 것이다.보다 구체적으로, 본 발명의 실시 예에 따른 음성 인식 처리 장치는, 인식 모델 구축부, 다중 인식 처리부, 자모열 유사도 측정부, 챗봇 질의 보정부 및 출력부를 포함한다. 먼저, 인식 모델 구축부는, 음성 인식을 위한 복수의 음성 인식 모델들을 포함하는 다중 음성 인식 모델을 사전 구축한다. 여기서, 상기 다중 음성 인식 모델은 복수의 음성 인식 모델들을 포함할 수 있다. 복수의 음성 인식 모델들은, 현재 알려진 다양한 음성 인식 방식에 대응하여 각각 분류 및 구축될 수 있으며, 학습 대상이 어떠한 분류인지, 어떠한 카테고리의 음성을 학습하였는지, 어떠한 알고리즘을 사용하였는지 등에 따라서 서로 상이한 모델로 분 류 및 구축될 수 있다. 보다 구체적으로, 도 2에 도시된 바오 같이, 인식 모델 구축부는, 각각의 음성 인식(ASR, Automatic Speech Recognition) 모델을 운용하는 업체별 서비스별로 제공되는 복수의 음성 인식 모델의 API 등을 이용하여, 다중으로 처리되는 음성 인식 서비스 프로세스를 구성함으로써, 다중 음성 인식 모델을 사전 구축할 수 있다. 예를 들어, 도 2를 참조하면, 인식 모델 구축부는, Google사의 Conformer 서비스, Google사의 음성 인식 API 서비스, Facebook사의 wav2vec 2.0서비스, Microsoft사의 Azure API 서비스, amazon사의 Transcribe API 서비스, IBM사의 Watson Services, NEVER사의 하이퍼클로바 서비스, SK텔레콤의 에이닷 서비스, 기타 KoSpeech Model을 이용한 다양한 오픈 소스 기반 한국어 음성 인식 모델 서비스 등을 다중으로 이용하도록 구성함으로써, 다중 음성 인식 모델을 사전 구축할 수 있다. 이러한 다중 음성 인식 모델의 출력은, 각 음성 인식 모델별 인식 결과일 수 있으며, 인식 결과는 텍스트 데이터로 구성되는 단어 인식 결과 또는 글자 인식 결과를 포함할 수 있 다. 또한, 상기 각 음성 인식 모델은, 개별 학습 모델에 따라 개별적으로 구성될 수 있는 바, 개별 학습 모델에 따 른 데이터 셋을 이용하여 딥러닝 학습을 수행하는 하나 이상의 뉴럴 네트워크 모델을 포함할 수 있다. 예를 들 어, 뉴럴 네트워크 모델은, 나이, 성별, 직업, 건강 등과 같이 특정 카테고리별 음성 데이터와 텍스트 인식 결 과를 학습한 딥러닝 뉴럴 네트워크 모델로써, 알려진 CNN, RNN 또는 CRNN 방식을 이용하여 각각의 카테고리별 음성과 그 인식 결과를 학습함에 따라, 각 음성 인식 결과를 출력하는 학습 모델이 구축될 수 있다. 그리고, 다중 인식 처리부는, 음성 인식 대상 데이터를 상기 다중 음성 인식 모델에 입력하여, 상기 복수 의 음성 인식 모델들 각각의 처리 결과를 획득한다. 전술한 바와 같이, 인식 모델 구축부에서 각각의 분류 에 따라 구축된 모델들에서는 다양한 인식 결과가 출력될 수 있다. 이러한 인식 결과는 텍스트 데이터로 구성되 는 단어 인식 결과 또는 글자 인식 결과를 포함할 수 있다. 그리고, 자모열 유사도 측정부는, 상기 다중 음성 인식 모델들의 인식 결과로부터, 각 음성 인식 모델의 자모열 인식 결과를 산출하고, 상기 자모열 인식 결과를 비교하여, 음성 인식 모델 간 자모열 유사도를 산출한 다. 여기서, 자모열 유사도 측정부는, 상기 음성 인식 모델의 단어 인식 결과 또는 글자 인식 결과를, 자음 및 모음이 독립적인 문자 코드로 나열되도록 분리하여, 상기 자모열 인식 결과를 산출할 수 있다. 예를 들어, 자모열 유사도 측정부는, 상기 글자 인식 결과의 문자 코드 또는 상기 단어 인식 결과를 구성 하는 하나 이상의 문자 코드에 매핑된 제1 언어 인식 결과 데이터를, 초성, 중성 또는 종성에 대응하는 상대 거 리 위치 값으로 각각 변환 및 결합하여, 상기 자모열 인식 결과를 산출할 수 있는 것이다. 이에 따라, 자모열 유사도 측정부는, 상기 복수의 음성 인식 모델 각각의 자모열 인식 결과 상호간 유사도 를 산출하고, 상기 산출된 자모열 인식 결과 상호간 유사도를 조합 연산하여, 상기 자모열 유사도를 산출할 수 있다. 보다 구체적으로, 자모열 유사도 측정부는, 띄어쓰기를 기준으로 인식되는 단어별 인식 결과 또는, 각 문 자별 인식 결과의 자음 문자와 모음 문자를 초성,중성 및 종성과 같은 발음 순서대로 분리하여, 문자 코드별로 변환함에 따라 분리 구성하고, 분리 구성된 문자 코드들을 연결하여 자모열 인식 결과를 획득할 수 있다. 예를 들어 '챗'이라는 한글 문자의 음성 인식 결과는. 자모열 유사도 측정부에서 'ㅊㅐㅅ'과 같은 유니코드 기 반으로 초성, 중성, 종성이 각각 분리 변환 처리됨에 따라, 자모열 인식 결과로서 획득될 수 있다.그리고, 자모열 유사도 측정부는, 분리 구성된 자모열 인식 결과를 비교함에 따라 각 음성 인식 모델 간 자모열 유사도를 측정할 수 있다. 이러한 자모열 분리 및 비교방식은, 기존의 기존의 단어유사도 또는 글자유사 도 비교에서의 유사발음 단어들에 대한 부적절한 비교과정에서의 오류를 방지할 수 있게 한다. 예를 들어, 특정 음성을, 제1 인식 모델이 '신라면'으로 인식하고, 제2 인식 모델이 '진라면'으로 인식하는 경 우, 단어 유사도 기반 다중 인식 방식에서는 '진라면' '신라면'은 완전히 유사하지 않은 단어이기 때문에, 제1 인식 모델, 제2 인식 모델 어디서 잘못된 인식이 이루어졌는지를 확인할 수 없고 인식 실패로 출력될 수밖에 없 는 문제점이 있다. 나아가, 글자 유사도 기반 인식 프로세스에서도 '진'과 '신'은 완전히 다른 글자이므로, 인식 실패만이 도출될 뿐, 시스템 자체적으로 이를 보정하거나 오류를 수정할 수는 없는 문제점이 있다. 이에 반하여, 본 발명의 실시 예에 따른 자모열 유사도 측정부는, 자모열 유사도를 측정할 수 있는 바, 이에 따라, 제1 모델의 '신라면' 인식 결과는 'ㅅㅣㄴㄹㅏㅁㅕㄴ' 으로 자모열 분리되며, 제2 모델의 '진라 면'은 인식 결과는 'ㅈㅣㄴㄹㅏㅁㅕㄴ' 으로 자모열 분리되고, 제1 모델과 제2 모델 간 인식 결과의 자모열 유 사도는 70%이상 유사한 것으로 도출될 수 있으므로, 첫번째 자음만이 인식에 차이가 있는 것으로 확인 가능하며, 최종적으로 이를 보정할 수 있는 문자 코드의 위치 정보가 도출될 수 있는 것이다. 또한, 이러한 자모열 분리를 효율적으로 처리하기 위하여, 자모열 유사도 측정부는, 상기 글자 인식 결과 의 문자 코드 또는 상기 단어 인식 결과를 구성하는 하나 이상의 문자 코드에 매핑된 제1 언어 인식 결과 데이 터를, 초성, 중성 또는 종성에 대응하는 상대 거리 위치 값으로 각각 변환 및 결합하여, 상기 자모열 인식 결과 를 산출할 수 있는 것이다. 예를 들어, 한글 유니코드에서 사용하는 자모는 초성 19자, 중성 21자, 종성 27자로, 조합 가능한 글자 수는 19x21x28(종성 없음 포함)=11,172자이며. 한글 문자 코드로 이루어진 문자열 내에서 종성과 종성, 중성과 중성, 종성과 종성 사이의 거리는 항상 일정하게 구성될 수 있다. 이에 따라, 자모열 유사도 측정부는, 음성 인식 결과를 유니코드로 변환하고, 유니코드로 변환된 문자열의 글자별로, 초성, 중성, 종성 간 상대 거리를, 유니코드의 시작위치('가')로부터의 거리에 따라 각각 산출하여 연결하는 방식 등으로, 자모열 인식 결과를 구성할 수 있다. 예를 들어, '췟'의 경우, 유니코드 테이블의 첫 글자인 '가' 를 기준으로 종성 'ㅅ' 까지 종성 간 거리가 19이 며, 중성인 'ㅞ' 까지의 중성 간 거리가 15이며, 초성인 'ㅊ'까지의 초성 간 거리가 14로 산출되는 바, 각 상대 거리 위치 정보를 자모열 인식 결과로서 구성하면, 이로부터 매핑되는 문자 코드들을 변환 연결하여 구성된 'ㅊ ㅞㅅ' 이라는 분리된 자모음 인식 결과가 획득될 수 있다. 한글 문자 인식의 경우, 자모열 구성 코드로 구성하여 보면 아래와 같이 수행될 수 있다. ********************************************* //초성 매핑 문자 코드 구성 chut = 'ㄱㄲㄴㄷㄸㄹㅁㅂㅃㅅㅆㅇㅈㅉㅊㅋㅌㅍㅎ#' //중성 매핑 문자 코드 구성 ga = 'ㅏㅐㅑㅒㅓㅔㅕㅖㅗㅘㅙㅚㅛㅜㅝㅞㅟㅠㅡㅢㅣ#' //종성 매핑 문자 코드 구성 ggut = ' ㄱㄲㄳㄴㄵㄶㄷㄹㄺㄻㄼㄽㄾㄿㅀㅁㅂㅄㅅㅆㅇㅈㅊㅋㅌㅍㅎ#' //유니코드 시작 위치 설정 BASE = 0xAC00 //음성 인식 결과 입력 query = '췟' //상대 위치 정보 기반 자모열 인식 결과 구성, *ord()함수는 대상 문자 값을 아스키 숫자로 변환해주는 함수임.code = ord(query) - BASE //종성 상대 위치 정보 추출 jongsung = code % 28 //중성 상대 위치 정보 추출 jungsung = ((code-jongsung) // 28) % 21 //초성 상대 위치 정보 추출 chosung = ((code - jongsung) // 28) // 21 //상대 위치 정보에 매핑된 문자 코드 출력 print(chut[chosung], ga[jungsung], ggut[jongsung]) ********************************************* 상기 코드의 수행 결과는 아래와 같이 이루어질 수 있다. >>> ㅊ ㅞ ㅅ 여기서, 상기 chut 변수(=첫소리), ga 변수(=가운뎃소리), ggut 변수(=끝소리)는 자모조합에서 일반적으로 사용 하는 변수이다. 한편, 자모열 유사도 측정부는, 획득된 자모열 인식 결과를 각 다중 음성 인식 모델별로 비교함에 따라, 음성 인식 모델 간 자모열 유사도를 측정할 수 있다. 여기서, 자모열 유사도 측정은 알려진 SequenceMatcher 알 고리즘의 ratio 메서드 등을 활용할 수 있으며, 이에 따라 각 유사도(Similarity)를 계산하는 함수를 이용하여 음성 인식 모델 간 자모열 유사도를 도출할 수 있다. 해당 함수는, 자모열을 비교하여 그 유사도를 출력하는 함 수로서, 예를 들어 banana와 유사한 manana의 경우 83%가 유사하다는 결과 등을 출력할 수 있다. 여기서, 자모열 유사도는 각 음성 인식 모델과 음성 인식 모델 상호간 산출될 수 있으며, 상호간 산출된 자모열 유사도들을 종합하여, 최종적인 자모열 유사도가 결정될 수 있다. 이는 각 음성 인식 모델 상호간 산출된 자모 열 유사도 값의 평균 값, 중간 값 또는 이들을 조합하여 산출되는 다양한 통계적 값으로 구성될 수 있다. 그리고, 챗봇 질의 보정부는, 상기 음성 인식 대상 데이터의 단어별 자모열 유사도를 식별하고, 상기 단어 별 자모열 유사도가 임계조건 이내인 단어가 하나 이상 식별되는 경우, 상기 출력값을 챗봇 질의 기반으로 보정 하기 위한 질의 정보를 상기 사용자 단말로 전송할 수 있다. 여기서, 상기 질의 정보는, 상기 자모열 유사도가 임계조건 이내인 단어의 각 음성 인식 모델별 인식 결과를 이 용하여, 상기 임계조건에 해당하는 단어의 각 음성 인식 모델별 인식 결과 중 어느 하나를 상기 사용자 단말에 서 선택 가능하도록 구성되는 질의 인터페이스 선택 정보를 포함할 수 있다. 그리고, 상기 챗봇 질의 보정부는, 상기 질의 인터페이스 선택 정보 출력에 따라 상기 사용자 단말로 부터 수신되는 응답 정보에 기초하여, 상기 출력값을 보정 처리할 수 있다. 여기서, 상기 챗봇 질의 및 보정 처리는, 각 상기 단어별 자모열 유사도가 임계조건에 해당하는 단어가 식별된 단어의 각 음성 인식 모델별 인식 결과 일치여부를, 사전 구성된 자모열 유사도 기반 챗봇 질의 테이블에 적용 함에 따라, 선택적으로 수행될 수 있다. 이러한 자모열 유사도 기반 챗봇 질의 테이블 및 그에 따른 챗봇 질의 보정부의 동작에 대하여는 도 4 내지 도 6을 참조하여 보다 구체적으로 후술하도록 한다. 그리고, 출력부는, 상기 챗봇 질의 보정부의 보정 결과 및 상기 자모열 유사도를 이용하여, 상기 음성 인 식 대상 데이터에 대응하는 인식 결과 정보를 출력한다. 출력부의 인식 결과는 사용자 단말 또는 별 도의 외부 장치로 출력될 수 있다. 또한, 출력된 상기 인식 결과는 하나 이상의 음성 인식 모델 각각에 대응하는 모델 식별 정보를 포함할 수 있는 바, 다중 인식 모델 중 어떠한 모델에서 획득된 인식 결과인지를 확인할 수 있도록 하며, 이는 다시 인식 모델 구축부로 피드백되어, 학습 데이터 갱신 및 신뢰도 향상에 이용될 수 있도록 한다.도 3은 본 발명의 실시 예에 따른 음성 인식 처리 장치의 동작을 설명하기 위한 흐름도이다. 도 3을 참조하면, 본 발명의 실시 예에 따른 음성 인식 처리 장치는, 음성 인식을 위한 복수의 음성 인식 모델들을 포함하는 다중 음성 인식 모델을 사전에 구축한다(S101). 이후, 음성 인식 처리 장치는, 음성 인식 대상 데이터를, 음성 인식을 위한 복수의 음성 인식 모델들을 포 함하는 다중 음성 인식 모델에 입력하여, 상기 음성 인식 모델들 각각의 처리 결과를 획득한다(S103). 그리고, 음성 인식 처리 장치는, 상기 음성 인식 모델들의 인식 결과를 단어별로 자모 분리 처리하고, 자 모 분리 처리된 결과를 비교하여, 단어별 자모열 유사도를 측정한다(S105). 이후, 음성 인식 처리 장치는, 상기 단어별 자모열 유사도에 기초한 챗봇 질의 보정을 위한 질의 정보를 구성하고, 질의 정보를 이용하여 사용자 단말로 선택적 질의를 수행한다(S107). 그리고, 음성 인식 처리 장치는, 상기 사용자 단말의 질의 응답 정보와 자모열 유사도에 따라, 보정된 최 종 인식 결과 정보를 출력한다(S109). 도 4는 본 발명의 실시 예에 따른 음성 인식 처리 과정을 설명하기 위한 자모열 유사도 기반 챗봇 질의 테이블 을 나타낸다. 도 4를 참조하면, 본 발명의 실시 예에 따른 음성 인식 처리 장치는, 각 상기 단어별 자모열 유사도가 임 계조건에 해당하는 단어가 식별된 단어의 각 음성 인식 모델별 인식 결과 일치여부를, 사전 구성된 자모열 유사 도 기반 챗봇 질의 테이블에 적용함에 따라, 인식 결과 보정을 선택적으로 수행할 수 있다. 도 4는 이러한 자모열 유사도 기반 챗봇 질의 테이블을 예시한 것으로, 챗봇 질의 보정부는, 각 음성 인식 모델(ASR)별 인식 결과의 자모열 유사도 측정 결과에 따라, 챗봇 질의 여부 및 챗봇 질의 내용을 결정할 수 있 다. 도 4를 참조하면, 먼저, 모든 모델의 인식 결과 상호간 자모열 유사도가 모두 일치하는 경우에는 별도의 챗봇 질의 및 보정 없이 인식 결과가 출력될 수 있다. 그러나, 자모열 유사도가 임계조건(예를 들어, 3개 중 2개가 일치하나 1개가 일치하지 않는 경우로서, 100% 미만 70% 이상인 경우) 이내로 측정된 하나 이상의 단어가 존재 하는 경우, 질의 정보는, 상기 하나 이상의 단어에 대응하여 선택 가능하게 구성된 각 모델별 인식 결과 정보를 포함할 수 있다. 예를 들어, 도 4에 도시된 바와 같이, 자모열 유사도가 70% 이상인 단어 중, 3개의 모델의 자모열 인식 결과 중 하나의 모델만이 다르게 인식된 경우에는, 2개 모델의 동일한 인식 결과와, 1개 모델의 다르게 인식된 결과 중 어느 하나를 선택하게 하는 질의 인터페이스가 구성될 수 있다. 또한, 도 4에 도시된 바와 같이, 자모열 유사도가 70% 미만인 단어 중, 3개의 모델의 자모열 인식 결과 중 하나 의 모델만이 다르게 인식된 경우에는, 2개 모델의 동일한 인식 결과가 맞는지만을 YES 또는 NO로 단순히 선택할 수 있는 질의 인터페이스가 구성될 수 있다. 또한, 도 4에 도시된 바와 같이, 자모열 유사도가 70% 미만인 단어 중, 3개의 모델의 자모열 인식 결과가 모두 다른 경우에는 다시 음성인식을 요청하는 질의 인터페이스가 구성될 수 있다. 도 5 내지 도 6은 본 발명의 실시 예에 따른 음성 인식 처리 과정 및 질의 과정을 설명하기 위한 예시도이다. 도 5를 참조하면, 앞서 도 4에서 도시된 바와 같이, 사용자의 음성 인식에 있어서, 다중 음성 인식 모델을 활용 하되, 다중 음성 인식 모델 상호간 인식 결과를 자모열 유사도에 따라 비교함에 따라, 그 인식 결과에 오류가 있는지를 확인할 수 있다. 또한, 음성 인식 처리 장치는, 이러한 오류가 어디에서 얼마나 존재하는지를 미 리 파악하고, 이에 대응하는 적절한 질의를 사용자 단말로 요청하며, 그 질의 결과에 대응하는 적절한 보 정을 수행함에 따라, 정확한 인식 결과를 도출할 수 있게 된다. 또한, 인식 결과는 다시 각 모델별 학습 데이터 로서 활용됨에 따라, 피드백에 따른 정확도 향상이 지속적으로 이루어질 수 있다. 또한, 도 6에 도시된 바와 같이, 각 질의 정보에 따른 질의 인터페이스는, 별도의 구체적인 텍스트 입력 등을 하지 않더라도, 간단히 1번, 2번 등으로 음성 인식 결과를 쉽게 선택할 수 있는 화면 인터페이스로 구성될 수있는 바, 노약자나 어린이 등의 사용자라 하더라도 쉽게 음성 인식 기반의 다양한 서비스를 제공받을 수 있도록 하는 편의성을 가져올 수 있다. 상술한 본 발명에 따른 방법은 컴퓨터에서 실행되기 위한 프로그램으로 제작되어 컴퓨터가 읽을 수 있는 기록 매체에 저장될 수 있으며, 컴퓨터가 읽을 수 있는 기록 매체의 예로는 ROM, RAM, CD-ROM, 자기 테이프, 플로피 디스크, 광 데이터 저장장치 등이 있으며, 또한 캐리어 웨이브(예를 들어 인터넷을 통한 전송)의 형태로 구현되 는 것도 포함한다. 컴퓨터가 읽을 수 있는 기록 매체는 네트워크로 연결된 컴퓨터 시스템에 분산되어, 분산방식으로 컴퓨터가 읽을 수 있는 코드가 저장되고 실행될 수 있다. 그리고, 상기 방법을 구현하기 위한 기능적인(function) 프로그램,"}
{"patent_id": "10-2023-0011530", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "코드 및 코드 세그먼트들은 본 발명이 속하는 기술분야의 프로그래머들에 의해 용이하게 추론될 수 있다. 또한, 이상에서는 본 발명의 바람직한 실시 예에 대하여 도시하고 설명하였지만, 본 발명은 상술한 특정의 실시"}
{"patent_id": "10-2023-0011530", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "예에 한정되지 아니하며, 청구범위에서 청구하는 본 발명의 요지를 벗어남이 없이 당해 발명이 속하는 기술분야 에서 통상의 지식을 가진 자에 의해 다양한 변형 실시가 가능한 것은 물론이고, 이러한 변형 실시들은 본 발명 의 기술적 사상이나 전망으로부터 개별적으로 이해되어서는 안될 것이다."}
{"patent_id": "10-2023-0011530", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 실시 예에 따른 전체 시스템을 개략적으로 도시한 도면이다. 도 2는 본 발명의 실시 예에 따른 음성 인식 처리 장치를 보다 구체적으로 설명한 블록도이다. 도 3은 본 발명의 실시 예에 따른 음성 인식 처리 장치의 동작을 설명하기 위한 흐름도이다. 도 4는 본 발명의 실시 예에 따른 음성 인식 처리 과정을 설명하기 위한 자모열 유사도 기반 챗봇 질의 테이블 을 나타낸다. 도 5 내지 도 6은 본 발명의 실시 예에 따른 음성 인식 처리 과정 및 질의 과정을 설명하기 위한 예시도이다."}
