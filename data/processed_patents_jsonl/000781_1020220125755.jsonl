{"patent_id": "10-2022-0125755", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0011068", "출원번호": "10-2022-0125755", "발명의 명칭": "자율주행 자동차의 객체 인식률 개선 방법 및 그 장치", "출원인": "포티투닷 주식회사", "발명자": "이재윤"}}
{"patent_id": "10-2022-0125755", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "주행 중에 획득된 제1영상에서 제1객체를 인식하는 단계;상기 제1영상에서 상기 인식된 제1객체가 소정기간 사라졌다가 재출현하는 것을 감지하는 단계;상기 제1객체가 재출현하는 것을 감지하면, 상기 제1객체에 대한 학습데이터를 산출하는 단계; 및상기 산출된 학습데이터에 기반한 정보로, 영상에 포함된 객체를 인식하는 인식모델이 학습되도록 제어하는 단계를 포함하는, 자율주행 자동차의 객체 인식률 개선 방법."}
{"patent_id": "10-2022-0125755", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,주행 중에 획득된 제2영상에 포함된 제2객체를 상기 학습된 인식모델의 인식기법으로 인식하여, 제2영상에서 제2객체를 프레임누락없이 인식하는 단계를 더 포함하는, 자율주행 자동차의 객체 인식률 개선 방법,"}
{"patent_id": "10-2022-0125755", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 제1영상은 적어도 세 개 이상의 프레임을 포함하고,상기 소정기간은,적어도 하나 이상의 프레임에 대한 시간범위 값인, 자율주행 자동차의 객체 인식률 개선 방법."}
{"patent_id": "10-2022-0125755", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,상기 제1영상은 적어도 세 개 이상의 프레임을 포함하고,상기 소정기간은,1 내지 3 프레임에 대한 시간범위 값인, 자율주행 자동차의 객체 인식률 개선 방법."}
{"patent_id": "10-2022-0125755", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서,상기 학습데이터는,상기 제1객체의 분류코드 및 상기 제1객체가 최초에 인식된 후에 소정기간 사라졌다가 재출현한 이력에 대한 정보를 포함하는, 자율주행 자동차의 객체 인식률 개선 방법."}
{"patent_id": "10-2022-0125755", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5항에 있어서,상기 학습데이터는,상기 제1객체의 신뢰도(confidence)에 대한 정보를 더 포함하는, 자율주행 자동차의 객체 인식률 개선 방법."}
{"patent_id": "10-2022-0125755", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "공개특허 10-2024-0011068-3-제1항에 있어서,상기 산출된 학습데이터를 기설정된 필터기준으로 필터링하여, 상기 산출된 학습데이터에 기반한 정보를 산출하는 단계를 더 포함하는, 자율주행 자동차의 객체 인식률 개선 방법."}
{"patent_id": "10-2022-0125755", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서,상기 제1영상은,복수의 프레임을 포함하는 동영상이고,상기 기설정된 필터기준은,상기 제1객체가 제1프레임에 인식된 후에 제2프레임에서 소정기간 사라졌다가 제3프레임에 재출현할 때의 일련의 프레임의 시간길이에 대한 필터기준이고, 상기 산출된 학습데이터에 대한 기반한 정보를 산출하는 단계는,상기 제1프레임과 제3프레임간의 시간길이가 기준프레임길이보다 더 길면, 상기 학습데이터에 기반한 정보를산출하고,상기 기준프레임길이는, 상기 제1영상의 프레임레이트, 상기 제1영상속의 객체의 이동속도, 상기 제1영상을 촬영한 카메라의 화각, 상기 제1영상을 촬영한 카메라의 각도, 상기 제1영상을 촬영한 카메라의 렌즈의 왜곡률 중적어도 하나에 의해 결정되는, 자율주행 자동차의 객체 인식률 개선 방법."}
{"patent_id": "10-2022-0125755", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제7항에 있어서,상기 제1영상은,복수의 프레임을 포함하는 동영상이고,상기 기설정된 필터기준은,제1프레임에 인식된 후에 제2프레임에서 소정기간 사라졌다가 제3프레임에 재출현한 상기 제1객체의 종류를 구분하기 위한 구분기준이고,상기 산출된 학습데이터에 대한 기반한 정보를 산출하는 단계는,상기 제1객체의 종류가 승용차, 트럭, 버스, 미상체(misc.)라면, 상기 학습데이터에 기반한 정보를 산출하는 자율주행 자동차의 객체 인식률 개선 방법."}
{"patent_id": "10-2022-0125755", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제7항에 있어서,상기 제1영상은,복수의 프레임을 포함하는 동영상이고,상기 기설정된 필터기준은,제1프레임에 인식된 후에 제2프레임에서 소정기간 사라졌다가 제3프레임에 재출현한 상기 제1객체의 크기를 구분하기 위한 크기기준이고,상기 산출된 학습데이터에 대한 기반한 정보를 산출하는 단계는,상기 제1객체의 높이(height)가 기설정된 픽셀을 초과하면, 상기 학습데이터에 기반한 정보를 산출하는, 자율주행 자동차의 객체 인식률 개선 방법."}
{"patent_id": "10-2022-0125755", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제7항에 있어서,공개특허 10-2024-0011068-4-상기 제1영상은,복수의 프레임을 포함하는 동영상이고,상기 기설정된 필터기준은,제1프레임에 인식된 후에 제2프레임에서 소정기간 사라졌다가 제3프레임에 재출현한 상기 제1객체의 크기를 구분하기 위한 크기기준이고,상기 산출된 학습데이터에 대한 기반한 정보를 산출하는 단계는,상기 제1객체의 너비(width)가 기설정된 픽셀을 초과하면, 상기 학습데이터에 기반한 정보를 산출하는, 자율주행 자동차의 객체 인식률 개선 방법."}
{"patent_id": "10-2022-0125755", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제1항에 있어서,상기 산출된 학습데이터에 기반한 정보는,상기 산출된 학습데이터에 대해서 능동 학습(active learning)이 적용된 정보인, 자율주행 자동차의 객체 인식률 개선 방법."}
{"patent_id": "10-2022-0125755", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제1항에 있어서,상기 산출된 학습데이터에 기반한 정보는,사용자의 입력을 통해서 상기 학습데이터에 포함된 객체의 종류가 라벨링된(labeled) 정보인, 자율주행 자동차의 객체 인식률 개선 방법."}
{"patent_id": "10-2022-0125755", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제1항에 따른 방법을 구현하기 위한 프로그램을 저장하고 있는 컴퓨터 판독가능한 기록매체."}
{"patent_id": "10-2022-0125755", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "자율주행 자동차의 객체 인식률 개선 장치에 있어서,적어도 하나의 프로그램이 저장된 메모리; 및상기 적어도 하나의 프로그램을 실행함으로써, 연산을 수행하는 프로세서를 포함하고,상기 프로세서는,주행 중에 획득된 제1영상에서 제1객체를 인식하고,상기 제1영상에서 상기 인식된 제1객체가 소정기간 사라졌다가 재출현하는 것을 감지하고,상기 제1객체가 재출현하는 것을 감지하면, 상기 제1객체에 대한 학습데이터를 산출하고,상기 산출된 학습데이터에 기반한 정보로, 영상에 포함된 객체를 인식하는 인식모델이 학습되도록 제어하는, 장치."}
{"patent_id": "10-2022-0125755", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명의 일 실시예는, 상기 기술적 과제를 해결하기 위한 본 발명의 일 실시 예에 따른 방법은, 주행 중에 획 득된 제1영상에서 제1객체를 인식하는 단계; 상기 제1영상에서 상기 인식된 제1객체가 소정기간 사라졌다가 재출 현하는 것을 감지하는 단계; 상기 제1객체가 재출현하는 것을 감지하면, 상기 제1객체에 대한 학습데이터를 산출 하는 단계; 및 상기 산출된 학습데이터에 기반한 정보로, 영상에 포함된 객체를 인식하는 인식모델이 학습되도록 제어하는 단계를 포함하는 객체 인식률 개선 방법을 개시한다."}
{"patent_id": "10-2022-0125755", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 자율주행 자동차의 객체 인식률 개선 방법 및 그 장치에 관한 것으로서, 보다 구체적으로는, 객체를 인식하고 자율적으로 운행이 가능한 자율주행 자동차가 주행 중에 도로 상의 객체를 인식하는 성능을 향상시키 기 위한 객체 인식률 개선 방법 및 그 장치에 관한 것이다."}
{"patent_id": "10-2022-0125755", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "정보통신 기술과 차량 산업의 융합으로 인해 빠르게 차량의 스마트화가 진행되고 있다. 스마트화로 인해, 차량 은 단순한 기계적 장치에서 스마트카로 진화하고 있으며, 특히, 스마트카의 핵심기술로 자율 주행(self- driving)이 주목 받고 있다. 자율 주행이란, 운전자가 핸들과 가속페달, 브레이크 등을 조작하지 않아도 차량에 탑재된 자율 주행 모듈이 차량의 주행상태를 능동적으로 제어함으로써, 차량 스스로 목적지까지 찾아가는 기술 이다. 자율주행 자동차의 안전한 자율주행을 위해서, 자율 주행 과정에서 차량이 보행자나 다른 차량을 정확하게 인식 하고, 인식된 객체와의 거리를 산출하는 방법에 대한 연구가 다양하게 이루어지고 있으나, 차량이 주행 중에 도 로 상에 출현가능한 객체 특성은 사실상 무한에 가깝고, 자율주행 자동차에 탑재되는 모듈의 프로세싱 능력에 한계가 존재하여, 도로 상에 있는 객체를 완벽하게 인식할 수 있는 방법은 현재 알려져 있지 않다. 카메라를 통한 객체 인식 및 거리추정의 경우, 실제 3차원 세계의 객체를 2차원 이미지에 투영하였기 때문에 거 리에 대한 정보가 많이 손실된다. 특히, 보행자 위치 계산에 많이 사용되는 특징들(보행자의 키나 지면에 닿아 있는 점)의 편차가 크기 때문에 오차가 크다. 레이더(RADAR)를 통한 객체 인식 및 거리추정의 경우, 레이더가 운용하는 전파 특성상 객체를 빠르게 파악하고 분류하는 능력이 떨어지기 때문에, 보행자인지 또는 차량인지에 대한 판단이 어렵고, 특히, 도로상에 있는 보행 자나 이륜차(자전거나 오토바이)의 경우 신호세기가 작기 때문에 인식결과가 더욱 안 좋은 경향이 있다. 최근에는 라이다(LiDAR)를 이용한 객체 인식 및 거리 추정 기술이 상대적으로 높은 정확도를 갖고 있어서 각광 받고 있으나, 고출력 레이저는 위험성이 있어서 라이다는 출력을 낮춘 레이저를 기반으로 동작할 수 밖에 없고, 레이더가 사용하는 전파와는 다르게 레이저는 주변 환경의 영향을 크게 받으며, 라이다 센서의 지나치게 높은 비용이 한계점으로 지적된다."}
{"patent_id": "10-2022-0125755", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 2, "content": "전술한 배경기술은 발명자가 본 발명의 도출을 위해 보유하고 있었거나, 본 발명의 도출 과정에서 습득한 기술 정보로서, 반드시 본 발명의 출원 전에 일반 공중에게 공개된 공지기술이라 할 수는 없다. 선행기술문헌 특허문헌 (특허문헌 0001) 대한민국 등록특허 제10-2438114호 (2022.08.25)"}
{"patent_id": "10-2022-0125755", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명이 해결하고자 하는 기술적 과제는, 자율 주행 자동차의 객체 인식률을 개선하기 위한 방법을 제공하는 데에 있다."}
{"patent_id": "10-2022-0125755", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기 기술적 과제를 해결하기 위한 본 발명의 일 실시 예에 따른 방법은, 주행 중에 획득된 제1영상에서 제1객 체를 인식하는 단계; 상기 제1영상에서 상기 인식된 제1객체가 소정기간 사라졌다가 재출현하는 것을 감지하는 단계; 상기 제1객체가 재출현하는 것을 감지하면, 상기 제1객체에 대한 학습데이터를 산출하는 단계; 및 상기 산출된 학습데이터에 기반한 정보로, 영상에 포함된 객체를 인식하는 인식모델이 학습되도록 제어하는 단계를 포함한다. 상기 방법에 있어서, 주행 중에 획득된 제2영상에 포함된 제2객체를 상기 학습된 인식모델의 인식기법으로 인식 하여, 제2영상에서 제2객체를 프레임누락없이 인식하는 단계를 더 포함할 수 있다. 상기 방법에 있어서, 상기 제1영상은 적어도 세 개 이상의 프레임을 포함하고, 상기 소정기간은, 적어도 하나 이상의 프레임에 대한 시간범위 값일 수 있다. 상기 방법에 있어서, 상기 제1영상은 적어도 세 개 이상의 프레임을 포함하고, 상기 소정기간은, 1 내지 3 프레 임에 대한 시간범위 값일 수 있다.상기 방법에 있어서, 상기 학습데이터는, 상기 제1객체의 분류코드 및 상기 제1객체가 최초에 인식된 후에 소정 기간 사라졌다가 재출현한 이력에 대한 정보를 포함할 수 있다. 상기 방법에 있어서, 상기 학습데이터는, 상기 제1객체의 신뢰도(confidence)에 대한 정보를 더 포함할 수 있다. 상기 방법에 있어서, 상기 산출된 학습데이터를 기설정된 필터기준으로 필터링하여, 상기 산출된 학습데이터에 기반한 정보를 산출하는 단계를 더 포함할 수 있다. 상기 방법에 있어서, 상기 제1영상은, 복수의 프레임을 포함하는 동영상이고, 상기 기설정된 필터기준은, 상기 제1객체가 제1프레임에 인식된 후에 제2프레임에서 소정기간 사라졌다가 제3프 레임에 재출현할 때의 일련의 프레임의 시간길이에 대한 필터기준이고, 상기 산출된 학습데이터에 대한 기반한 정보를 산출하는 단계는, 상기 제1프레임과 제3프레임간의 시간길이가 기준프레임길이보다 더 길면, 상기 학습 데이터에 기반한 정보를 산출하고, 상기 기준프레임길이는, 상기 제1영상의 프레임레이트, 상기 제1영상속의 객 체의 이동속도, 상기 제1영상을 촬영한 카메라의 화각, 상기 제1영상을 촬영한 카메라의 각도, 상기 제1영상을 촬영한 카메라의 렌즈의 왜곡률 중 적어도 하나에 의해 결정될 수 있다. 상기 방법에 있어서, 상기 제1영상은, 복수의 프레임을 포함하는 동영상이고, 상기 기설정된 필터기준은, 제1프 레임에 인식된 후에 제2프레임에서 소정기간 사라졌다가 제3프레임에 재출현한 상기 제1객체의 종류를 구분하기 위한 구분기준이고, 상기 산출된 학습데이터에 대한 기반한 정보를 산출하는 단계는, 상기 제1객체의 종류가 승 용차, 트럭, 버스, 미상체(misc.)라면, 상기 학습데이터에 기반한 정보를 산출할 수 있다. 상기 방법에 있어서, 상기 제1영상은, 복수의 프레임을 포함하는 동영상이고, 상기 기설정된 필터기준은, 제1프 레임에 인식된 후에 제2프레임에서 소정기간 사라졌다가 제3프레임에 재출현한 상기 제1객체의 크기를 구분하기 위한 크기기준이고, 상기 산출된 학습데이터에 대한 기반한 정보를 산출하는 단계는, 상기 제1객체의 높이 (height)가 기설정된 픽셀을 초과하면, 상기 학습데이터에 기반한 정보를 산출할 수 있다. 상기 방법에 있어서, 상기 제1영상은, 복수의 프레임을 포함하는 동영상이고, 상기 기설정된 필터기준은, 제1프 레임에 인식된 후에 제2프레임에서 소정기간 사라졌다가 제3프레임에 재출현한 상기 제1객체의 크기를 구분하기 위한 크기기준이고, 상기 산출된 학습데이터에 대한 기반한 정보를 산출하는 단계는, 상기 제1객체의 너비 (width)가 기설정된 픽셀을 초과하면, 상기 학습데이터에 기반한 정보를 산출할 수 있다. 상기 방법에 있어서, 상기 산출된 학습데이터에 기반한 정보는, 상기 산출된 학습데이터에 대해서 능동 학습 (active learning)이 적용된 정보일 수 있다. 상기 방법에 있어서, 상기 산출된 학습데이터에 기반한 정보는, 사용자의 입력을 통해서 상기 학습데이터에 포 함된 객체의 종류가 라벨링된 정보일 수 있다. 상기 기술적 과제를 해결하기 위한 본 발명의 다른 일 실시 예에 따른 장치는, 자율주행 자동차의 객체 인식률 개선 장치에 있어서, 적어도 하나의 프로그램이 저장된 메모리; 및 상기 적어도 하나의 프로그램을 실행함으로 써, 연산을 수행하는 프로세서를 포함하고, 상기 프로세서는, 주행 중에 획득된 제1영상에서 제1객체를 인식하 고, 상기 제1영상에서 상기 인식된 제1객체가 소정기간 사라졌다가 재출현하는 것을 감지하고, 상기 제1객체가 재출현하는 것을 감지하면, 상기 제1객체에 대한 학습데이터를 산출하고, 상기 산출된 학습데이터에 기반한 정 보로, 영상에 포함된 객체를 인식하는 인식모델이 학습되도록 제어한다. 본 발명의 일 실시예는, 상기 방법을 실행시키기 위한 프로그램을 저장하고 있는 컴퓨터 판독가능한 기록매체를 제공할 수 있다."}
{"patent_id": "10-2022-0125755", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명에 따르면, 카메라로 주행 중 영상을 획득하여 도로 상의 객체를 인식하는 방식으로 동작하는 자율주행 자동차의 객체 인식률이 현저하게 개선될 수 있다."}
{"patent_id": "10-2022-0125755", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명은 다양한 변환을 가할 수 있고 여러 가지 실시예를 가질 수 있는바, 특정 실시예들을 도면에 예시하고"}
{"patent_id": "10-2022-0125755", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "상세한 설명에 상세하게 설명하고자 한다. 본 발명의 효과 및 특징, 그리고 그것들을 달성하는 방법은 도면과 함께 상세하게 후술되어 있는 실시예들을 참조하면 명확해질 것이다. 그러나 본 발명은 이하에서 개시되는 실시 예들에 한정되는 것이 아니라 다양한 형태로 구현될 수 있다. 이하, 첨부된 도면을 참조하여 본 발명의 실시예들을 상세히 설명하기로 하며, 도면을 참조하여 설명할 때 동일 하거나 대응하는 구성 요소는 동일한 도면부호를 부여하고 이에 대한 중복되는 설명은 생략하기로 한다. 이하의 실시예에서, 제1, 제2 등의 용어는 한정적인 의미가 아니라 하나의 구성 요소를 다른 구성 요소와 구별 하는 목적으로 사용되었다. 이하의 실시예에서, 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 이하의 실시예에서, 포함하다 또는 가지다 등의 용어는 명세서상에 기재된 특징, 또는 구성요소가 존재함을 의 미하는 것이고, 하나 이상의 다른 특징을 또는 구성요소가 부가될 가능성을 미리 배제하는 것은 아니다. 어떤 실시예가 달리 구현 가능한 경우에 특정한 공정 순서는 설명되는 순서와 다르게 수행될 수도 있다. 예를 들어, 연속하여 설명되는 두 공정이 실질적으로 동시에 수행될 수도 있고, 설명되는 순서와 반대의 순서로 진행 될 수 있다. 도 1 내지 도 3은 일 실시예에 따른 자율 주행 방식을 설명하기 위한 도면들이다. 도 1을 참조하면, 본 발명의 일 실시예에 따른 자율 주행 장치는, 차량에 장착되어 자율주행 자동차을 구현 할 수 있다. 자율주행 자동차에 장착되는 자율 주행 장치는, 주변의 상황 정보를 수집하기 위한 다양한 센 서들을 포함할 수 있다. 일례로, 자율 주행 장치는 자율주행 자동차의 전면에 장착된 이미지 센서 및/또는 이벤트 센서를 통해, 전방에서 운행 중인 선행 차량의 움직임을 감지할 수 있다. 자율 주행 장치는 자율주 행 자동차의 전면은 물론, 옆 차로에서 운행중인 다른 주행 차량과, 자율주행 자동차 주변의 보행 자 등을 감지하기 위한 센서들을 더 포함할 수 있다. 자율주행 자동차 주변의 상황 정보를 수집하기 위한 센서들 중 적어도 하나는, 도 1에 도시한 바와 같이 소정의 화각(FoV)을 가질 수 있다. 일례로, 자율주행 자동차의 전면에 장착된 센서가 도 1에 도시한 바와 같은 화 각(FoV)을 갖는 경우에, 센서의 중앙에서 검출되는 정보가 상대적으로 높은 중요도를 가질 수 있다. 이는, 센서 의 중앙에서 검출되는 정보에, 선행 차량의 움직임에 대응하는 정보가 대부분 포함되어 있기 때문일 수 있 다. 자율 주행 장치는, 자율주행 자동차의 센서들이 수집한 정보를 실시간으로 처리하여 자율주행 자동차의 움직임을 제어하는 한편, 센서들이 수집한 정보 중에 적어도 일부는 메모리 장치에 저장할 수 있다. 도 2를 참조하면, 자율 주행 장치는 센서부, 프로세서, 메모리 시스템, 및 차체 제어 모듈 등을 포함할 수 있다. 센서부는 복수의 센서들(42-45)을 포함하며, 복수의 센서들(42-45)은 이미지 센서,이벤트 센서, 조도 센서, GPS 장치, 가속도 센서 등을 포함할 수 있다. 센서들(42-45)이 수집한 데이터는 프로세서로 전달될 수 있다. 프로세서는 센서들(42-45)이 수집한 데 이터를 메모리 시스템에 저장하고, 센서들(42-45)이 수집한 데이터에 기초하여 차체 제어 모듈을 제어 하여 차량의 움직임을 결정할 수 있다. 메모리 시스템은 둘 이상의 메모리 장치들과, 메모리 장치들을 제어 하기 위한 시스템 컨트롤러를 포함할 수 있다. 메모리 장치들 각각은 하나의 반도체 칩으로 제공될 수 있다. 메모리 시스템의 시스템 컨트롤러 외에, 메모리 시스템에 포함되는 메모리 장치들 각각은 메모리 컨트 롤러를 포함할 수 있으며, 메모리 컨트롤러는 신경망과 같은 인공지능(AI) 연산 회로를 포함할 수 있다. 메모리 컨트롤러는 센서들(42-45) 또는 프로세서로부터 수신한 데이터에 소정의 가중치를 부여하여 연산 데이터를 생성하고, 연산 데이터를 메모리 칩에 저장할 수 있다. 도 3은 자율 주행 장치가 탑재된 자율주행 자동차의 센서가 획득한 영상 데이터의 예시를 나타낸 도면이다. 도 3을 참조하면, 영상 데이터는 자율주행 자동차의 전면에 장착된 센서가 획득한 데이터일 수 있다. 따라서 영상 데이터에는 자율주행 자동차의 전면부, 자율주행 자동차과 같은 차로의 선행 차량, 자율주행 자동차 주변의 주행 차량 및 비관심영역 등이 포함될 수 있다. 도 3에 도시한 실시예에 따른 영상 데이터에서, 자율주행 자동차의 전면부와 비관심영역이 나타나 는 영역의 데이터는 자율주행 자동차의 운행에 영향을 미칠 가능성이 거의 없는 데이터일 수 있다. 다시 말해, 자율주행 자동차의 전면부와 비관심영역은 상대적으로 낮은 중요도를 갖는 데이터로 간주될 수 있다. 반면, 선행 차량과의 거리, 및 주행 차량의 차로 변경 움직임 등은 자율주행 자동차의 안전한 운행에 있어서 매우 중요한 요소일 수 있다. 따라서, 영상 데이터에서 선행 차량 및 주행 차량 등이 포함 되는 영역의 데이터는 자율주행 자동차의 운행에 있어서 상대적으로 높은 중요도를 가질 수 있다. 자율 주행 장치의 메모리 장치는, 센서로부터 수신한 영상 데이터의 영역별로 가중치를 다르게 부여하여 저 장할 수 있다. 일례로, 선행 차량과 주행 차량 등이 포함되는 영역의 데이터에는 높은 가중치를 부여하 고, 자율주행 자동차의 전면부와 비관심영역이 나타나는 영역의 데이터에는 낮은 가중치를 부여할 수 있다. 도 4a 및 도 4b는 일 실시예에 따른 차량 외부를 촬영하는 카메라와 관련된 도면이다. 카메라는 차량에 탑재되어 차량의 외부를 촬영할 수 있다. 카메라는 차량의 전방, 측방, 후방 등을 촬영할 수 있다. 본 발명에 따른 객체 인식률 개선 장치는 카메라에서 촬영된 복수의 영상을 획득할 수 있다. 카메라에서 촬영된 복수의 영상에는 복수의 객체가 포함될 수 있다. 객체에 관한 정보는 객체 종류 정보 및 객체 속성 정보를 포함한다. 여기에서, 객체 종류 정보는 객체의 종류를 나타내는 인덱스 정보이며, 큰 범위인 그룹과 세부 범위인 클래스로 구성된다. 그리고, 객체 속성 정보는 객체 의 현재 상태에 대한 속성 정보를 나타내는 것이며, 움직임 정보, 회전 정보, 교통 정보, 색상 정보, 및 가시성 정보를 포함한다. 일 실시예에서, 객체 종류 정보에 포함되는 그룹 및 클래스는 아래의 표 1과 같을 수 있으나, 이에 제한되지 않 는다. 표 1 Group Class Flat Road, Sidewalk, Parking, Ground, Crosswalk Human Pedestrian, Rider Vehicle Car, Truck, Bus ConstructionBuilding Wall, Guard rail, Tunnel, fence, gas station, pylon Object Pole, Traffic sign, Traffic light, color corn Nature vegetation, terrain, paddy field, river, lake Void Static Lane Dotted line, Solid line, Dotted and Solid line, Double Solid line Sky Sky Animal Dog, Cat, bird또한, 객체 속성 정보에 포함되는 정보에는 Action, Rotate, Traffic info, color, Visibility 정보가 포함될 수 있다. Action 정보는 객체의 움직임 정보를 표현하며 정차, 주차, 이동 등으로 정의될 수 있다. 차량의 경우 정차, 주 차, 이동이 객체 속성 정보로 결정될 수 있고, 보행자의 경우 이동, 정지, 알 수 없음이 객체 속성 정보로 결정 될 수 있고, 신호등과 같이 움직일 수 없는 객체의 경우 디폴트 값인 정지로 객체 속성 정보가 결정될 수 있다. Rotate 정보는 객체의 회전 정보를 표현하며 정면, 후면, 수평(horizontal), 수직(vertical), 측면 등으로 정의 될 수 있다. 차량의 경우 정면, 후면, 측면으로 객체 속성 정보가 정해질 수 있고, 가로 또는 세로 방향의 신호 등은 각각 수평 또는 수직으로 객체 속성 정보가 정해질 수 있다. Traffic info는 객체의 교통정보를 의미하며, 교통표지판의 지시, 주의, 규제, 보조 표지 등으로 정의될 수 있 다. Color는 객체의 색상 정보를 의미하며 객체의 색상, 신호등 및 교통표지판의 색상을 표현할 수 있다. 도 4a를 참조하면, 객체는 보행자일 수 있다. 이미지는 소정의 크기를 가질 수 있다. 복수의 이미지 에는 동일한 객체가 포함될 수 있으나, 차량이 도로를 따라 주행함에 따라 차량과 객체의 상대 적 위치는 계속 변하고, 또한 객체도 시간에 따라 이동을 함으로써, 이에 따라 동일한 객체라도 각 이미지 내에서의 위치가 달라지게 된다. 각 이미지에서 동일한 객체가 어떤 것인지 결정하기 위해 이미지 전체를 이용하는 경우, 데이터 전송량 및 연산 량이 상당히 커지게 된다. 이에 따라, 차량에 탑재되는 장치에서 엣지 컴퓨팅을 통해 처리되기 어렵고, 실시간 분석 또한 어렵다. 도 4b를 참조하면, 이미지에 포함된 바운딩 박스가 도시된다. 바운딩 박스(Bounding box)는 객체 (object)에 대한 메타데이터로서, 바운딩 박스 정보에는 객체 종류 정보(그룹, 클래스 등), 이미지 상의 위치 정보, 크기 정보 등이 포함될 수 있다. 도 4b를 참조하면, 바운딩 박스 정보는 해당 객체가 보행자 클래스에 해당한다는 정보와, 객체의 좌 측 상단 꼭지점이 이미지 상의 (x, y) 에 위치한다는 정보, 객체의 크기가 w x h 라는 정보, 그리고 객체 가 이동 중이라는 현재 상태 정보(즉, Action 정보)를 포함할 수 있다. 도 5는 일 실시예에 따른 객체 인식 방법을 설명하는 흐름도이다. 객체 인식률 개선 장치는 카메라로부터 획득된 동영상을 프레임별로 분리하여 복수의 프레임을 획득할 수 있다. 복수의 프레임은 이전 프레임 및 현재 프레임을 포함할 수 있다. 객체 인식률 개선 장치는 이전 프레임에서 제1 보행자 객체를 인식할 수 있다. 일 실시예에서, 객체 인식률 개선 장치는 프레임을 동일한 크기의 그리드로 나누고, 각 그리드에 대해 그리드 중앙을 중심으로 미리 정의된 형태로 지정된 경계박스의 개수를 예측하며 이를 기반으로 신뢰도를 계산할 수 있 다. 객체 인식률 개선 장치는 프레임에 객체가 포함되어 있는지, 또는, 배경만 단독으로 있는지 여부를 결정하 고, 높은 객체 신뢰도를 갖는 위치를 선택하여 객체 카테고리를 결정함으로써 결과적으로 객체를 인식할 수 있 다. 다만, 본 개시에서 객체를 인식하는 방법은 이에 제한되지 않는다. 객체 인식률 개선 장치는 이전 프레임에서 인식된 제1 보행자 객체의 제1 위치 정보를 획득할 수 있 다. 도 4a 및 도 4b에서 상술한 바와 같이, 제1 위치 정보는 이전 프레임 상의 제1 보행자 객체에 대 응하는 바운딩 박스의 어느 하나의 꼭지점(예를 들어, 좌측 상단 꼭지점) 좌표 정보 및 가로, 세로 길이 정보를 포함할 수 있다. 또한, 객체 인식률 개선 장치는 현재 프레임에서 인식된 제2 보행자 객체의 제2 위치 정보를 획득할 수 있다. 객체 인식률 개선 장치는 이전 프레임에서 인식된 제1 보행자 객체의 제1 위치 정보, 및 현재 프레임 에서 인식된 제2 보행자 객체의 제2 위치 정보 간의 유사도를 산출할 수 있다. 도 5를 참조하면, 제1 위치 정보 및 제2 위치 정보를 이용하여, 객체 인식률 개선 장치는 제1 보행자 객체 및 제2 보행자 객체간의 교집합 및 합집합을 산출할 수 있다. 객체 인식률 개선 장치는 합집합 영역 대비 교집합 영역의 값을 산출하고, 산출된 값이 임계값 이상인 경우, 제1 보행자 객체 및 제2 보행자 객체 가 동일한 보행자 객체인 것으로 결정할 수 있다. 그러나, 객체 간의 동일성을 판별하는 방법은 상술한 방법으로 제한되지 않는다. 도 6은 본 발명의 일 실시예에 따라서, 자율주행 자동차의 객체 인식률을 개선하는 방법을 개념적으로 설명하기 위한 도면이다."}
{"patent_id": "10-2022-0125755", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "item": 3, "content": "도 6를 참조하여 본 발명의 일 실시예를 요약하면, 본 발명의 일 실시예는, raw data를 제1모델 및 제2모델을 통해 입력하였을 때, 각각의 모델에서 산출되는 결과데이터를 편차데이터산출모듈이 수신 하여 처리함으로써, 편차데이터가 산출되도록 하고, 산출된 편차데이터를 Weakness Point 분석모듈 이 수신하여 분석하도록 함으로써, Weakness Point를 파악하는 것으로 이해될 수 있다. 보다 구체적으로, 본 발명에서 raw data는 자율주행 자동차에 장착된 카메라 모듈이 수집한 영상을 의미한 다. 특히, raw data는 카메라 모듈에서 생성된 후에 전처리(pre-processing)가 되지 않은 동영상(video) 데이터로서, 복수의 프레임으로 구성되어 있으며, 프레임레이트는 1초당 60프레임이 될 수 있으나, 이에 제한되 지 않는다. 제1모델은 자율주행 자동차에 장착되어 있는 모델로서, raw data를 입력데이터로 수신하여, raw data에 포함된 객체를 인식한 결과를 출력데이터로 출력하는 모델을 의미한다. 제2모델은 자율주행 자동차와 통신가능한 서버에 포함된 모델로서, 제1모델과 마찬가지로 raw data를 입력데이터로 수신하여, raw data에 포함된 객체를 인식한 결과를 출력데이터로 출력하는 모 델을 의미한다. 자율주행 자동차의 카메라모듈은 통신모듈을 통해서 수집된 raw data가 제1모델뿐만 아니라 제2모델에도 송신되어 처리될 수 있도록 제어된다. 제1모델 및 제2모델에서 출력되는 출력데이터는, 영상의 각 프레임마다 포함된 차량, 보행자 등의 상 대적 위치, 크기, 방향에 대한 정보 중 적어도 하나에 대한 정보를 포함할 수 있다. 본 발명에서 제1모델은 자율주행 자동차에 장착된 특성상, 제2모델과 비교했을 때 상대적으로 제한된 리소스를 갖고 제한된 환경에서 동작하게 된다. 위와 같은 모델 스케일(scale)의 차이로 인해서, raw data(61 0)를 제2모델에 입력했을 때에 영상에서 인식된 객체의 수와 종류에 대한 정보는, raw data를 제1모 델에 입력했을 때에 인식된 객체의 수와 종류에 대한 정보보다 더 개선된 정보가 될 수 있다. 표 2"}
{"patent_id": "10-2022-0125755", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "표 3"}
{"patent_id": "10-2022-0125755", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "표 2 및 표 3은 제1모델 및 제2모델의 성능을 수치화하여 나타낸 일 예이다. 보다 구체적으로, 표 2 는 제1모델을 YoloV4-CSP로 채택했을 때의 객체 인식률을 나타내고 있고, 표 3은 제2모델을 YoloV4- P7로 채택했을 때의 객체 인식률을 나타내고 있다. 표 2 및 표 3을 비교하면, raw data에 포함되어 있는 객체로서, 승용차(car), 보행자(pedestrian), 트럭(truck), 버스(bus), 이륜차(two wheeler) 및 미상체(misc: miscellaneous)의 인식률이, YoloV4-P7가 YoloV4-CSP보다 전체적으로 월등한 것을 알 수 있다. 표 2 및 표 3은 제1모델 및 제2모델의 성능을 수치화하여 예시적으로 나타낸 것이므로, 본 발명에서 의 제1모델 및 제2모델은 표 2 및 표 3에서 설명한 YoloV4-CSP, YoloV4-P7으로 각각 제한되지 않는 다. 편차데이터산출모듈은 제1모델 및 제2모델의 출력데이터를 분석하여 편차데이터를 산출할 수 있다. 편차데이터는 raw data를 제1모델에 입력한 결과와 raw data를 제2모델에 입력한 결과간의 편차에 대한 데이터를 의미하고, 보다 상세하게는, 동일한 프레임별로 비교하여 산출될 수 있 다. 예를 들어, raw data가 10프레임으로 구성된 동영상 데이터라면, 편차데이터는 raw data의 제1프레임을 제1모델에 입력한 결과 및 raw data의 제1프레임을 제2모델에 입력한 결과를 비교 하여 편차를 산출한 결과일 수 있다. 편차데이터산출모듈은 raw data를 구성하는 프레임별로 서로 간의 바운딩 박스(bounding box)의 IoU 값(Intersection over Union Value)을 계산하여, 가장 큰 IoU를 갖는 바운딩박스끼리 매칭하고, 매칭한 결과에 서 제2모델의 출력데이터에만 탐지되는 바운딩박스를 Weakness Point대상으로 판단하여 Weakness Point 분 석모듈로 전달할 수 있다. 편차데이터산출모듈이 IoU값을 기준으로 프레임간에 바운딩 박스를 매칭하여 편 차데이터를 산출하는 방법은 도 5에서 이미 설명한 바 있으므로, 생략하기로 한다. 이하에서는, raw data를 제1모델에 입력하여 출력된 데이터를 제1인식결과, raw data를 제2모델 에 입력하여 출력된 데이터를 제2인식결과로 호칭하기로 한다. Weakness Point분석모듈은 편차데이터산출모듈로부터 편차데이터를 수신하여 Weakness Point를 분석 한다. 여기서, Weakness Point는 자율주행 자동차에 장착되어 있어서 제2모델에 비해서 상대적으로 낮은 연산량을 가질 수 밖에 없는 제1모델의 한계성능에 의해서, 제2모델에서는 검출된 객체가 제1모델 에서는 검출되지 않은 경우, 그 검출되지 않은 정보에 대한 데이터를 의미한다. 예를 들어, 제2모델 이 raw data를 수신하여 영상속에서 승용차 1대, 버스 1대를 객체로서 인식하고, 제1모델이 raw data를 수신하여 영상속에서 승용차 1대를 객체로서 인식했다면, Weakness Point는 제1모델이 인식 (탐지)하지 못한 버스 1대에 대한 정보가 될 수 있다. Weakness Point분석모듈이 분석한 Weakness Point는 제1모델의 객체 인식 성능을 향상시키기 위한 학습데이터로 사용될 수 있다. 또한, Weakness Point는 제1모델의 학습데이터로 사용되기 위해서 일련의 전처리 프로세스(또는 필터링 프로세스)에 의해 전처리될 수 있으며, 이에 대해서는 후술한다. 도 6에서 제1모델, 편차데이터산출모듈 및 Weakness Point분석모듈은, 본 발명의 일 실시예에 따른 자율주행 자동차의 객체 인식률 개선 장치에 물리적 또는 논리적으로 포함되는 형태로 구현될 수 있다. 또 한, 도 6에서 제1모델, 제2모델, 편차데이터산출모듈 및 Weakness Point분석모듈은 본 발 명이 실제로 구현될 경우에는 다른 명칭으로 호칭될 수도 있으며, 어느 하나의 모듈이 다른 하나에 통합되는 형 태로 구현될 수도 있다. 도 7a 내지 도 7c는 본 발명의 일 실시예에 따른, 객체 인식률 개선 장치에서 수행되는 필터링 프로세스를 설명 하기 위한 도면이다. 먼저, 도 7a는 필터링되기 전의 편차데이터를 나타낸 것으로서, 도 7a에는 제1객체(710a), 제2객체(720a), 제3 객체(730a), 제4객체(740a) 및 제5객체(750a)가 객체로서 인식된 것이 도식적으로 표현되어 있다. 보다 자세하 게는, 도 7a에 도시된 5개의 객체는 제1인식결과에서는 인식되지 않았으나, 제2인식결과에서는 인식되어서 편차 데이터로 가공되어 Weakness Point분석모듈에 전달된 것으로 이해될 수 있으며, Weakness Point분석모듈 은 기설정된 필터기준으로 필터링을 수행하여, 편차데이터에서 의미 있는 객체정보만 남길 수 있다. 일 예로서, 기설정된 필터기준은 편차데이터에 포함된 바운딩박스의 크기에 대한 크기기준이고, Weakness Point 분석모듈은 편차데이터에 기반한 정보로서, 크기기준보다 더 작은 크기의 바운딩박스를 제거할 수 있다. 여기서, 크기기준은 높이(height)가 120픽셀미만이거나, 너비(width)가 120픽셀미만인 바운딩박스를 제거하기 위한 기준이 될 수 있으나, 상술한 값은 예시적인 값이므로 실시예에 따라서, 높이 또는 너비에 대한 기준값은 달라질 수 있다. 다른 일 예로서, 기설정된 필터기준은 편차데이터에 포함된 바운딩박스의 객체의 종류를 구분하기 위한 구분기 준이고, Weakness Point분석모듈은 편차데이터에 기반한 정보로서, 구분기준에 따라 특정 종류의 객체의 바운딩박스를 제거할 수 있다. 여기서, 특정 종류란 바운딩박스의 상단에 기재된 클래스(class)를 의미하며, 도 7a의 5개의 바운딩박스에는 총 4개 종류의 클래스(car, truck, pedestrian, two wheeler)가 도시되어 있다.Weakness Point분석모듈에 설정되어 있는 필터기준에 높이(height)가 120픽셀미만이거나, 너비(width)가 120픽셀미만인 바운딩박스를 제거하기 위한 크기기준과, 보행자나 이륜차에 대한 바운딩박스를 제거하기 위한 구분기준이 동시에 설정되어 있다면, 도 7a에서 제2객체(720a), 제3객체(730a), 제4객체(740a)는 제거되고, 제1 객체(710a) 및 제5객체(750a)만이 남게 된다. 도 7b는 도 7a와 마찬가지로 필터링되기 전의 편차데이터를 나타낸 것으로서, 도 7b에는 제6객체(710b)가 객체 로서 인식된 것이 도식적으로 나타나 있다. 보다 자세하게는, 도 7b에 도시된 제6객체(710b)는 제1인식결과에서는 인식되지 않았으나, 제2인식결과에서는 인식되어서 편차데이터로 가공되어 Weakness Point분석모듈에 전달된 것으로 이해될 수 있으며, Weakness Point분석모듈은 기설정된 필터기준으로 필터링을 수행하여, 편차데이터에서 의미 있는 객체정보만 남길 수 있다. 다만, 도 7b에서 제6객체(710b)는 하나의 객체가 아니라 제7객체(720b) 및 제8객체(730b)가 우연히 겹쳐지는 과 정에서 하나의 객체로 오인식된 것이며, 형태상의 특성상 매우 낮은 신뢰도(confidence)인 0.3396이 기록되어 있는 것을 알 수 있다. 일 예로서, 도 7b에서 기설정된 필터기준은 편차데이터에 포함된 바운딩박스의 신뢰도에 대한 신뢰도기준이고, Weakness Point분석모듈은 편차데이터에 기반한 정보로서, 신뢰도기준보다 더 낮은 신뢰도의 바운딩박스를 제거할 수 있다. 여기서, 신뢰도기준은 0.6이 될 수 있으나, 실시예에 따라 달라질 수 있다. 도 7b에서 Weakness Point분석모듈은 신뢰도 기준에 따라서 제6객체(710b)의 바운딩박스를 제거할 수 있으 며, 제6객체(710b)의 바운딩박스가 제거된 후에는 도 7b의 프레임에는 잔여 바운딩박스가 없으므로, 제1인식결 과 및 제2인식결과는 사실상 동일한 것으로 간주될 수 있다. 제1인식결과 및 제2인식결과가 사실상 동일하다는 것은 제1모델이 제6객체(710b)를 학습하지 않아도 된다는 것을 의미한다. 도 7c는 도 7a 및 도 7b와 마찬가지로 필터링되기 전의 편차데이터를 나타낸 것으로서, 도 7c에는 제9객체 (710c), 제10객체(720c), 제11객체(730c)가 객체로서 인식된 것이 도식적으로 나타나 있다. 보다 구체적으로, 도 7c에 도시된 객체 중 제10객체(720c) 및 제11객체(730c)는 제1인식결과 및 제2인식결과에 모두 객체로 인식된 차량으로, 바운딩박스가 제거되어 있으나, 제9객체(710c)는 도로에서 주행 중인 자율주행 자동차의 주행에 영향을 줄 가능성이 없는 객체임에도 불구하고 트럭(truck)이라는 클래스로 분류되어 바운딩박 스가 적용되어 있는 것이, 도 7c에 도시되어 있다. 통상적으로 더 높은 인식성능을 갖는 제2모델이 인식하는 객체의 수가 많지만, 특정한 경우, 제1모델(62 0)이 객체가 아닌 대상을 객체로 오인하거나, 제2모델이 오동작하여 객체가 아니어서 제1모델에 인식 되지 않은 객체를 정상적인 객체로 오인식하는 경우가 발생될 수 있으며, Weakness Point분석모듈은 기설 정된 필터기준에 따라서, 제9객체(710c)가 실제 도로가 아닌 위치에 도로에만 존재하는 객체가 존재하는 것으로 판단하여, 해당 바운딩박스를 제거할 수 있다. 도 7c에서 제9객체(710c)의 바운딩박스가 제거되면, 제1인식결과 및 제2인식결과의 편차가 실질적으로 없게 되므로, 제1모델이 학습할 데이터도 당연히 없어진다. 도 8은 본 발명의 다른 일 실시예에 따라서, 자율주행 자동차의 객체 인식률 개선을 위해서 능동 학습이 적용되 는 과정을 설명하기 위한 도면이다. 본 발명에 따른 객체 인식률 개선 장치는, 도 8에 도시되어 있는 분류모듈, 라벨링데이터수집모듈, 학습모델 및 예측모델을 물리적 또는 논리적인 형태로 포함할 수 있다. 도 8에서 학습모델은 입 력되는 데이터를 통해 학습되고 있는 모델, 예측모델은 학습이 완료되어 시험데이터가 입력되면 그에 따른 결과데이터를 출력할 수 있는 예측성 모델(predictive model)을 각각 의미하는 것으로 간주하며, 학습모델(85 0)은 학습을 통해서 인식률이 개선되는 모델이므로, 결국, 자율주행 자동차에 장착되는 제1모델을 의미한 다. 통상적으로 머신러닝을 수행하기 위해서 raw data를 전처리하는 과정의 필수과정인 데이터의 라벨링(labeling) 은 데이터의 특징이 정확하게 구분되지 않아서 사람(human)에 의해서 수행되나, 본 발명에 따른 객체 인식률 개 선 장치는, 자동라벨링(auto-labeling)을 일부 포함하는 능동 학습(active learning)에 의한 능동 라벨링 (active learning)을 수행함으로써, 학습모델이 raw data의 특징을 빠르고 효율적으로 학습할 수 있 도록 유도하게 된다. 도 8에서 raw data는 도 6과 동일하게, 자율주행 자동차가 주행 중에 카메라로 촬영하여 수집한 영상을 의 미한다. raw data는 분류 모듈에 의해 자동적으로 라벨링될 수 있다. 구체적으로, raw data가 복수의 프 레임으로 구성된 영상이라면, 분류 모듈은 각 프레임별로 객체를 자동으로 인식하고, 특정 프레임의 a객체 는 트럭, b객체는 보행자, c객체는 이륜차 등으로 객체의 클래스를 자동으로 분류할 수 있다. 분류 모듈은 raw data를 분석하면서, 내부적인 분류알고리즘을 통해서 분류가 어렵다고 판단한 객체 에 대해서는 자동으로 라벨링을 수행하지 않으며, 여기서, 분류가 어렵다고 판단된 객체는 도 6 내지 도 7c에서 설명한 Weakness Point가 될 수 있다. 즉, 필터기준에 의해 필터되고도 제1모델 및 제2모델의 결과의 차이라고 판단된 도 7a의 제1객체(710a) 및 제5객체(750a)는 분류모듈에 의해서 분류가 어렵다고 판단된 객체가 될 수 있다. 분류가 어렵다고 판단된 객체에 대한 정보는 분류 모듈에 의해서 자동으로 수집되어 고도의 분류기준을 습득한 사용자에게 전달되며, 사용자는 데이터에 대한 라벨링을 완료한 후에, 라 벨링데이터를 라벨링데이터수집모듈에 전달하게 된다. 라벨링데이터수집모듈은 분류모듈로부터 자동으로 라벨링된 데이터와 사용자로부터 수동으로 라 벨링된 데이터를 전부 전달받아서 학습모델이 라벨링된 데이터를 학습하도록 제어한다. 학습모델에서 불규칙성에의해 학습이 되지 않는 데이터는, 다시 분류모듈로 전달되어 분류모듈 또는 사용자에 의해 라벨링되고 학습모델에 재입력되는 과정을 반복하게 되며, 최종적으로 raw data의 객체 인식에 대한 학습이 완료된 모델은 예측모델이 되어, 새로 입력되는 raw data에 포함된 객체들을 정확하게 인식할 수 있게 된다. 위와 같이, 선별된 일부 데이터에 대해서만 고도의 분류기준을 습득한 사용자에게 라벨링되고, 나머지 데 이터에 대해서는 자동으로 라벨링을 수행하는 능동 학습을 적용함에 따라서, 본 발명에 따른 학습모델은 빠르게 정확하게 학습데이터(영상의 객체에 대한 정보)를 학습할 수 있으며, 분류모듈에서는 도 7a 내지 도 7c에서 설명한 필터링 기준이 적용됨에 따라서, 사용자가 수동으로 해야하는 라벨링 작업량이 현저하게 감소될 수 있다. 즉, 본 발명에 따르면, 기존의 라벨링 작업으로 인해 발생되는 과도한 비용(시간적인 비용, 금 전상의 비용)을 최소화할 수 있게 된다. 도 9는 본 발명에 따른 객체 인식률 개선 방법의 일 예를 흐름도로 나타낸 도면이다. 도 9에 따른 방법은 전술한 객체 인식률 개선 장치에 의해 구현될 수 있으므로, 이하에서는, 도 6 내지 도 8을 참조하여 설명하기로 하며, 도 6 내지 도 8에서 설명한 내용과 중복되는 설명은 생략하기로 한다. 객체 인식률 개선 장치는 주행 중에 획득된 제1영상에 포함된 객체를 제1인식기법으로 인식하여, 제1인식결과를 산출할 수 있다(S910). 객체 인식률 개선 장치는 제2인식기법으로 제1영상에 포함된 객체를 인식한 제2인식결과를 수신할 수 있다 (S930). 객체 인식률 개선 장치는 제1인식결과 및 제2인식결과의 편차데이터를 산출할 수 있다(S950). 객체 인식률 개선 장치는 단계 S950에서 산출한 편차데이터에 기반한 정보로 제1인식기법으로 영상에 포함된 객 체를 인식하는 제1모델이 학습되도록 제어할 수 있다(S970). 도 10은 본 발명의 또 다른 일 실시예에 따른 객체 인식률 개선 방법을 설명하기 위한 도면이다. 본 선택적 일 실시예는 도 6 내지 도 9에서 설명한 객체 인식률 개선 방법과 동일한 프로세스를 일부 공유한다. 주행 중에 획득된 영상을 분석하여 객체를 인식하는 구성은 동일하게 이루어지나, 동일한 영상을 서로 다른 인 식기법을 적용하여 객체를 인식하고 편차데이터를 산출했던 도 6에서의 방법과 다르게, 본 실시 예에서는 하나 의 인식기법을 통해 영상에 포함된 객체를 인식하게 된다. 전술한 제1모델, 제2모델과 구분하기 위해 서, 본 실시 예에서 영상의 객체를 인식하는 모델을 인식모델이라고 호칭하기로 한다. 도 10을 참조하면, 총 4개의 프레임이 도시되어 있으며, 각 프레임별로 최소 하나 이상의 객체가 프레임의 특정 위치에 위치하고 있다. 보다 구체적으로, 도 10에서 i번째 프레임, i+1번째 프레임, i+3번째 프레임에는 상단과 하단에 각각 객체가 존재하는 것이 인식되었으나, i+2번째 프레임에서는 하단의 객체가 일시적으로 소실되어 상 단에만 객체가 존재하는 것으로 인식된 것을 알 수 있다. 본 실시 예에 따른 객체 인식률 개선 장치는 도 10처 럼 특정한 객체에 대해서 트래킹(tracking)이 이루어지고 있는 과정에서 갑자기 특정 프레임에서 객체의 소실이 발생되었다가, 짧은 시간내에 객체가 인식된 경우를 Weakness Point로 간주하여 인식모델을 학습시킬 학습데이터로 변환시킬 수 있다. 즉, 본 실시 예는, 트래킹이 정상적으로 이루어진 객체가 특정 프레임에서 소실되었다가 재출현했다면, 자율주 행 자동차의 객체 인식 모듈의 성능한계가 발생한 것으로서, 객체 인식 모듈에 대한 추가학습을 통해서 객체 인 식 성능을 향상시키기 위한 실시예로 이해될 수 있다. 표 4 도 6에서 설명한 실시예 도 10에서 설명한 실시예 기본적인 프로세스서로 다른 인식기법으로 영상속 객체를 인식하는 두 모델의 결과데이터로 자율 주행 자동차에 장착된 인식모델의 Weakness Point를 파악미리 정해진 인식기법으로 영상속 객체 를 인식하는 인식모델이 트래킹되던 객 체가 일시적으로 사라졌다가 빠르게 재 출현한 것을 기초로 자율주행 자동차에 장착된 인식모델의 Weakness Point를 파 악"}
{"patent_id": "10-2022-0125755", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "차이점 요약1) 제1모델, 제2모델 모두 필요 2) 동일한 프레임별로 비교1) 제1모델만 필요 2) 한 영상의 연속된 프레임들의 객체의 존부상태를 비교 표 4는 도 6 내지 도 9를 통해 설명한 실시예와 도 10에서 설명하는 실시예의 차이를 기재한 표이다. 표 4를 참 조하면, 본 발명의 두 실시예는 모두 자율주행 자동차에 장착되는 객체 인식 모듈의 성능상의 한계(Weakness Point)가 발생되는 지점을 파악하고, 그 파악된 성능상의 한계를 보완하기 위한 학습데이터를 생성하여 객체 인 식 모듈(인식모델)을 빠르고 효율적으로 학습시키기 위한 목적은 일치하지만, 이를 구현하기 위한 구성상의 차 이가 일부 존재하는 것을 알 수 있다. 도 11은 도 10에서 설명한 실시예에 따른 객체 인식률 개선 방법을 흐름도로 나타낸 도면이다. 먼저, 객체 인식률 개선 장치는 주행 중에 획득된 제1영상에서 제1객체를 인식할 수 있다(S1110). 여기서, 객체 인식률 개선 장치가 제1영상에서 제1객체를 인식했다는 것은, 도 10에 도시된 것처럼, 제1영상을 구성하는 프레 임 중에서 제1객체를 인식하여 제1객체에 대한 크기 및 종류(class)에 대한 정보를 파악한 것을 의미한다. 이어서, 객체 인식률 개선 장치는 제1영상에서 제1객체가 소정기간 사라졌다가 재출현하는지 여부를 감지할 수 있다(S1130). 여기서, 소정기간은 적어도 하나 이상의 프레임에 대한 시간범위 값일 수 있다. 수집된 제1영상의 프레임레이트 가 30frames/초라면, 소정기간은 0초에서 1/30초에 해당하는 시간범위 값일 수 있다. 다른 예로서, 소정기간은 1 내지 3 프레임에 대한 시간범위 값일 수 있으며, 도 10에서 소정기간은 1프레임에 대한 시간범위 값인 것을 알 수 있다. 소정기간이 3프레임에 대한 시간범위 값이면, i번째 프레임에 트래킹되던 제1객체가 i+1번째 프레임에 소실되었다가 i+5번째 프레임에서 재출현하면, 소정기간 사라진 것으로 간주될 수 있다. 객체 인식률 개선 장치는 제1객체가 재출현한 것을 감지한 것을 기초로 하여, 제1객체에 대한 학습데이터를 산 출할 수 있다(S1150). 제1객체가 사라진 후에 재출현하지 않지 않거나, 재출현하더라도 소정기간이 경과한 이후 에 재출현하는 경우에는, 객체 인식률 개선 장치는 조건을 만족하지 못한 것으로 간주하고, 제1객체에 대한 학 습데이터를 산출하지 않는다. 특히, 제1객체가 사라진 후에 소정기간보다 더 긴 시간이 경과한 후에 재출현한 경우는, 인식모델이 인식성능의 한계로 제1객체를 인식하지 못한 것이 아니라, 다른 객체에 의해서 제1객체가 차폐되어 인식하지 못했을 가능성이 높으므로, 학습데이터를 산출할 조건이 만족된 것으로 볼 수 없다. 단계 S1150에서 학습데이터는 제1객체의 크기, 위치, 분류코드(class), 제1객체가 최초에 인식된 후에 소정기간 사라졌다가 재출현한 이력(history)에 대한 정보, 제1객체의 신뢰도(confidence)에 대한 정보 중 적어도 하나 이상을 포함할 수 있다. 객체 인식률 개선 장치는 단계 S1150에서 산출한 학습데이터에 기반한 정보로, 주행 중에 획득된 영상에서 객체 를 인식하는 자율주행 자동차의 인식모델이 학습되도록 제어할 수 있다(S1170). 단계 S1170에서 학습데이터에 기반한 정보는 단계 S1150에서 산출된 학습데이터를 인식모델의 입력될 수 있도록 적어도 한번 이상 더 가공한 정보를 의미하며, 일 예로서, 학습데이터를 기설정된 필터기준으로 필터링한 정보 일 수 있다.선택적 일 실시예로서, 기설정된 필터기준은 제1객체가 제1프레임에 인식된 후에 제2프레임에서 사라졌다가 제3 프레임에 재출현할 때의 일련의 프레임의 시간길이에 대한 필터기준일 수 있고, 객체 인식률 개선 장치는 이 필 터기준을 통해서, 제1프레임과 제3프레임간의 시간길이가 10프레임의 길이보다 더 긴 경우에만, 학습데이터에 대한 기반한 정보가 산출되도록 할 수 있다. 본 필터기준은 여러 프레임을 통해서 충분히 길게 트래킹된 객체만 선택적으로 학습하겠다는 것을 의미한다. 본 선택적 일 실시예에서, 10프레임의 길이는 기준프레임길이로 호칭될 수 있으며, 가변적인 값이 될 수 있다. 예를 들어, 기준프레임길이는, 제1영상의 프레임레이트, 제1영상속의 제1객체의 이동속도, 제1영상을 촬영한 카 메라의 화각, 제1영상을 촬영한 카메라의 각도, 제1영상을 촬영한 카메라의 렌즈의 왜곡률 중 적어도 하나에 의 해 결정되는 값일 수 있다. 즉, 기준프레임길이는 실시예에 따라서, 10프레임보다 더 짧아질 수도 있고 더 길어 질 수도 있다. 본 발명은 제1객체의 속도, 카메라의 물리적, 논리적 상태를 고려함에 따라서, 종래보다 더 정확 한 객체 인식이 가능하다. 다른 선택적 일 실시예로서, 기설정된 필터기준은 제1프레임에 인식된 후에 제2프레임에서 소정기간 사라졌다가 제3프레임에 재출현한 상기 제1객체의 종류를 구분하기 위한 구분기준일 수 있고, 객체 인식률 개선 장치는 이 구분기준을 통해서, 제1객체의 종류(class)가 승용차, 트럭, 버스, 미상체(misc.)인 경우에만, 학습데이터에 기 반한 정보가 산출되도록 할 수 있다. 본 필터기준은 자율주행에 있어서 높은 중요도를 갖는 객체인 승용차, 트 럭, 버스, 미상체를 중점적으로 학습하겠다는 것을 의미한다. 또 다른 선택적 일 실시예로서, 기설정된 필터기준은 제1프레임에 인식된 후에 제2프레임에서 소정기간 사라졌 다가 제3프레임에 재출현한 상기 제1객체의 크기를 구분하기 위한 크기기준일 수 있고, 객체 인식률 개선 장치 는 이 크기기준을 통해서, 제1객체의 높이(height) 또는 너비(width)가 기설정된 픽셀을 초과하면, 학습데이터 에 기반한 정보가 산출되도록 할 수 있다. 본 필터기준은 충분히 큰 크기의 제1객체에 대해서만 인식모델을 학 습시키겠다는 것을 의미한다. 표 4에서 비교하여 설명한 것처럼, 객체가 소실되었다가 재출현했을 때, 인식모델이 객체가 소실된 구간에서 객 체를 완전히 사라지지 않았음에도 불구하고 인식하지 못하는 것은 인식모델의 제한된 성능에 의한 것이므로, 도 8에서 설명한 인식모델의 Weakness Point로 분류될 수 있으며, 동일한 방식으로 능동학습(active learning)이 적용될 수 있다. 즉, 객체의 분류기준을 숙지한 사용자의 입력을 통해서 학습데이터에 포함된 객체의 종류가 정확하게 라벨링되 면, 라벨링된 데이터는 학습데이터에 기반한 정보로서 라벨링데이터수집모듈을 거쳐서 인식모델에 입력될 수 있 다. 반복적인 학습을 통해 학습이 완료된 인식모델은 제2영상을 새로운 시험데이터로 입력받았을 때, 프레임누 락없이 제2영상의 제2객체를 정확히 인식할 수 있게 된다. 도 12는 일 실시예에 따른 객체 인식률 개선 장치의 블록도이다. 도 12를 참조하면, 객체 인식률 개선 장치는 통신부, 프로세서 및 DB를 포함할 수 있 다. 도 12의 객체 인식률 개선 장치에는 실시예와 관련된 구성요소들만이 도시되어 있다. 따라서, 도 12"}
{"patent_id": "10-2022-0125755", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 7, "content": "에 도시된 구성요소들 외에 다른 범용적인 구성요소들이 더 포함될 수 있음을 당해 기술분야의 통상의 기술자라 면 이해할 수 있다. 통신부는 외부 서버 또는 외부 장치와 유선/무선 통신을 하게 하는 하나 이상의 구성 요소를 포함할 수 있다. 예를 들어, 통신부는, 근거리 통신부(미도시), 이동 통신부(미도시) 및 방송 수신부(미도시) 중 적 어도 하나를 포함할 수 있다. DB는 객체 인식률 개선 장치 내에서 처리되는 각종 데이터들을 저장하는 하드웨어로서, 프로세서 의 처리 및 제어를 위한 프로그램을 저장할 수 있다. DB는 DRAM(dynamic random access memory), SRAM(static random access memory) 등과 같은 RAM(random access memory), ROM(read-only memory), EEPROM(electrically erasable programmable read-only memory), CD-ROM, 블루레이 또는 다른 광학 디스크 스토리지, HDD(hard disk drive), SSD(solid state drive), 또는 플 래시 메모리를 포함할 수 있다. 프로세서는 객체 인식률 개선 장치의 전반적인 동작을 제어한다. 예를 들어, 프로세서는 DB에 저장된 프로그램들을 실행함으로써, 입력부(미도시), 디스플레이(미도시), 통신부, DB 등을 전반적으로 제어할 수 있다. 프로세서는, DB에 저장된 프로그램들을 실행함으로써, 객체 인식률 개선 장치의 동작을 제어할 수 있다. 프로세서는 도 1 내지 도 11에서 상술한 객체 인식률 개선 장치의 동작 중 적어도 일부를 제어할 수 있다. 일 예로서, 프로세서는 도 6 내지 도 9에서 설명한 것처럼, 자동차가 주행 중에 획득된 제1영상에 포함된 객체를 제1인식기법으로 인식하여 제1인식결과를 산출하고, 제2인식기법으로 제1영상에 포함된 객체를 인식한 제2인식결과를 수신하고, 제1인식결과 및 상기 제2인식결과의 편차데이터를 산출하고, 산출된 편차데이터에 기 반한 정보로 제1인식기법으로 동작하는 제1모델이 학습되도록 제어할 수 있다. 다른 예로서, 프로세서는 도 10 내지 도 11에서 설명한 것처럼, 주행 중에 획득된 제1영상에서 제1객체를 인식하고, 제1영상에서 제1객체가 소정기간 사라졌다가 재출현하는 것을 감지하고, 제1객체가 재출현하는 것을 감지하면, 제1객체에 대한 학습데이터를 산출하여, 산출된 학습데이터에 기반한 정보로, 영상에 포함된 객체를 인식하는 인식모델이 학습되도록 제어할 수 있다. 프로세서는 ASICs(application specific integrated circuits), DSPs(digital signal processors), DSPDs(digital signal processing devices), PLDs(programmable logic devices), FPGAs(field programmable gate arrays), 제어기(controllers), 마이크로 컨트롤러(micro-controllers), 마이크로 프로세서 (microprocessors), 기타 기능 수행을 위한 전기적 유닛 중 적어도 하나를 이용하여 구현될 수 있다. 객체 인식률 개선 장치는 차량 내에 임베디드 되는 전자 장치일 수 있다. 예를 들어, 객체 인식률 개선 장치는 생산 과정 이후 튜닝(tuning)을 통해 차량 내에 장착되는 전자 장치일 수 있다. 이상 설명된 본 발명에 따른 실시예는 컴퓨터상에서 다양한 구성요소를 통하여 실행될 수 있는 컴퓨터 프로그램 의 형태로 구현될 수 있으며, 이와 같은 컴퓨터 프로그램은 컴퓨터로 판독 가능한 매체에 기록될 수 있다. 이때, 매체는 하드 디스크, 플로피 디스크 및 자기 테이프와 같은 자기 매체, CD-ROM 및 DVD와 같은 광기록 매 체, 플롭티컬 디스크(floptical disk)와 같은 자기-광 매체(magneto-optical medium), 및 ROM, RAM, 플래시 메 모리 등과 같은, 프로그램 명령어를 저장하고 실행하도록 특별히 구성된 하드웨어 장치를 포함할 수 있다. 한편, 상기 컴퓨터 프로그램은 본 발명을 위하여 특별히 설계되고 구성된 것이거나 컴퓨터 소프트웨어 분야의 당업자에게 공지되어 사용 가능한 것일 수 있다. 컴퓨터 프로그램의 예에는, 컴파일러에 의하여 만들어지는 것 과 같은 기계어 코드뿐만 아니라 인터프리터 등을 사용하여 컴퓨터에 의해서 실행될 수 있는 고급 언어 코드도 포함될 수 있다. 본 발명에서 설명하는 특정 실행들은 일 실시예들로서, 어떠한 방법으로도 본 발명의 범위를 한정하는 것은 아 니다. 명세서의 간결함을 위하여, 종래 전자적인 구성들, 제어 시스템들, 소프트웨어, 상기 시스템들의 다른 기 능적인 측면들의 기재는 생략될 수 있다. 또한, 도면에 도시된 구성 요소들 간의 선들의 연결 또는 연결 부재들 은 기능적인 연결 및/또는 물리적 또는 회로적 연결들을 예시적으로 나타낸 것으로서, 실제 장치에서는 대체 가 능하거나 추가의 다양한 기능적인 연결, 물리적인 연결, 또는 회로 연결들로서 나타내어질 수 있다. 또한, “필 수적인”, “중요하게” 등과 같이 구체적인 언급이 없다면 본 발명의 적용을 위하여 반드시 필요한 구성 요소 가 아닐 수 있다. 본 발명의 명세서(특히 특허청구범위에서)에서 “상기”의 용어 및 이와 유사한 지시 용어의 사용은 단수 및 복 수 모두에 해당하는 것일 수 있다. 또한, 본 발명에서 범위(range)를 기재한 경우 상기 범위에 속하는 개별적인 값을 적용한 발명을 포함하는 것으로서(이에 반하는 기재가 없다면), 발명의 상세한 설명에 상기 범위를 구성하 는 각 개별적인 값을 기재한 것과 같다. 마지막으로, 본 발명에 따른 방법을 구성하는 단계들에 대하여 명백하 게 순서를 기재하거나 반하는 기재가 없다면, 상기 단계들은 적당한 순서로 행해질 수 있다. 반드시 상기 단계 들의 기재 순서에 따라 본 발명이 한정되는 것은 아니다. 본 발명에서 모든 예들 또는 예시적인 용어(예들 들어, 등등)의 사용은 단순히 본 발명을 상세히 설명하기 위한 것으로서 특허청구범위에 의해 한정되지 않는 이 상 상기 예들 또는 예시적인 용어로 인해 본 발명의 범위가 한정되는 것은 아니다. 또한, 당업자는 다양한 수정, 조합 및 변경이 부가된 특허청구범위 또는 그 균등물의 범주 내에서 설계 조건 및 팩터에 따라 구성될 수 있음을 알 수 있다.도면 도면1 도면2 도면3 도면4a 도면4b 도면5 도면6 도면7a 도면7b 도면7c 도면8 도면9 도면10 도면11 도면12"}
{"patent_id": "10-2022-0125755", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1 내지 도 3은 일 실시예에 따른 자율 주행 방식을 설명하기 위한 도면들이다. 도 4a 및 도 4b는 일 실시예에 따른 차량 외부를 촬영하는 카메라와 관련된 도면이다.도 5는 일 실시예에 따른 객체 인식 방법을 설명하는 흐름도이다. 도 6은 본 발명의 일 실시예에 따라서, 자율주행 자동차의 객체 인식률을 개선하는 방법을 개념적으로 설명하기 위한 도면이다. 도 7a 내지 도 7c는 본 발명의 일 실시예에 따른, 객체 인식률 개선 장치에서 수행되는 필터링 프로세스를 설명 하기 위한 도면이다. 도 8은 본 발명의 다른 일 실시예에 따라서, 자율주행 자동차의 객체 인식률 개선을 위해서 능동 학습이 적용되 는 과정을 설명하기 위한 도면이다. 도 9는 본 발명의 따른 객체 인식률 개선 방법의 일 예를 흐름도로 나타낸 도면이다. 도 10은 본 발명의 또 다른 일 실시예에 따른 객체 인식률 개선 방법을 설명하기 위한 도면이다. 도 11은 도 10에서 설명한 실시예에 따른 객체 인식률 개선 방법을 흐름도로 나타낸 도면이다. 도 12는 일 실시예에 따른 객체 인식률 개선 장치의 블록도이다."}
