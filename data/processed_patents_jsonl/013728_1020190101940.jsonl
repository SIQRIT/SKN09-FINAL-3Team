{"patent_id": "10-2019-0101940", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2021-0022434", "출원번호": "10-2019-0101940", "발명의 명칭": "음성인식 방법 및 장치", "출원인": "주식회사 포켓메모리", "발명자": "조용석"}}
{"patent_id": "10-2019-0101940", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "(a) 사용자의 음성 신호를 획득하는 단계;(b) 상기 획득된 음성 신호를 이용하여 상기 음성 신호의 음성인식 여부를 판단하는 단계;(c) 상기 음성 신호가 인식되는 경우, 상기 음성 신호에 대응하는 제1 텍스트 정보를 출력하는 단계; 및(d) 상기 음성 신호가 인식되지 않는 경우, 상기 사용자의 부가 신호를 획득하고, 상기 부가 신호에 대응하는제2 텍스트 정보를 출력하는 단계;를 포함하는,음성 인식 방법."}
{"patent_id": "10-2019-0101940", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 (a) 단계는,상기 음성 신호의 데시벨(decibel, dB)이 임계값 이상인 경우, 상기 사용자의 음성 신호를 획득하는 단계;를 포함하는,음성 인식 방법."}
{"patent_id": "10-2019-0101940", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 (b) 단계는,상기 음성 신호를 시간 도메인과 주파수 도메인에 대한 사운드 스펙트로그램으로 변환하는 단계;상기 사운드 스펙트로그램으로부터 상기 제1 텍스트 정보를 추출하는 단계; 및 상기 제1 텍스트 정보를 이용하여 상기 음성 신호의 인식 여부를 판단하는 단계;를 포함하는,음성 인식 방법."}
{"patent_id": "10-2019-0101940", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서,상기 제1 텍스트 정보를 이용하여 상기 음성 신호의 인식 여부를 판단하는 단계는,상기 제1 텍스트 정보로부터 상기 제1 텍스트 정보의 구문 정보를 추출하는 단계; 및상기 추출된 구문 정보가 미리 정의된 구문 정보와 일치하는지 여부를 판단하는 단계;를 포함하는,공개특허 10-2021-0022434-3-음성 인식 방법."}
{"patent_id": "10-2019-0101940", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서,상기 (a) 단계는,상기 사용자의 음성 신호의 적어도 일부를 획득하는 단계;를 포함하고,상기 (b) 단계는,상기 음성 신호의 적어도 일부를 클라우드 서버에게 송신하는 단계; 상기 클라우드 서버로부터 상기 음성 신호의 적어도 일부에 대한 음성 인식 결과를 수신하는 단계; 및상기 음성 인식 결과를 이용하여 상기 음성 신호의 음성인식 여부를 판단하는 단계;를 포함하는,음성 인식 방법."}
{"patent_id": "10-2019-0101940", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서,상기 (d) 단계는,상기 음성 신호가 인식되지 않는 경우, 상기 사용자의 음성 신호의 재요청 신호를 출력하는 단계; 및상기 재요청 신호의 출력에 응답하여 상기 사용자의 부가 신호를 획득하는 단계;를 포함하는,음성 인식 방법."}
{"patent_id": "10-2019-0101940", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에 있어서,상기 사용자의 부가 신호는, 상기 사용자의 시선(line of sight) 신호, 음성 신호 및 동작 신호 중 적어도 하나를 포함하는,음성 인식 방법."}
{"patent_id": "10-2019-0101940", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1항에 있어서,상기 (c) 단계 이후에,상기 음성 신호와 상기 제1 텍스트 정보를 이용하여 음성인식 인공지능 학습모델을 학습시키는 단계;를 더 포함하는,음성 인식 방법. 공개특허 10-2021-0022434-4-청구항 9 사용자의 음성 신호를 획득하는 입력부;상기 획득된 음성 신호를 이용하여 상기 음성 신호의 음성인식 여부를 판단하는 제어부; 및상기 음성 신호가 인식되는 경우, 상기 음성 신호에 대응하는 제1 텍스트 정보를 출력하고,상기 음성 신호가 인식되지 않는 경우, 상기 사용자의 부가 신호를 획득하고, 상기 부가 신호에 대응하는 제2텍스트 정보를 출력하는 출력부;를 포함하는,음성 인식 장치."}
{"patent_id": "10-2019-0101940", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9항에 있어서,상기 입력부는,상기 음성 신호의 데시벨(decibel, dB)이 임계값 이상인 경우, 상기 사용자의 음성 신호를 획득하는,음성 인식 장치."}
{"patent_id": "10-2019-0101940", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제9항에 있어서,상기 제어부는,상기 음성 신호를 시간 도메인과 주파수 도메인에 대한 사운드 스펙트로그램으로 변환하고,상기 사운드 스펙트로그램으로부터 상기 제1 텍스트 정보를 추출하며,상기 제1 텍스트 정보를 이용하여 상기 음성 신호의 인식 여부를 판단하는,음성 인식 장치."}
{"patent_id": "10-2019-0101940", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항에 있어서,상기 제어부는,상기 제1 텍스트 정보로부터 상기 제1 텍스트 정보의 구문 정보를 추출하고,상기 추출된 구문 정보가 미리 정의된 구문 정보와 일치하는지 여부를 판단하는,음성 인식 장치."}
{"patent_id": "10-2019-0101940", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제9항에 있어서,상기 입력부는, 상기 사용자의 음성 신호의 적어도 일부를 획득하고,상기 음성 신호의 적어도 일부를 클라우드 서버에게 송신하고,상기 클라우드 서버로부터 상기 음성 신호의 적어도 일부에 대한 음성 인식 결과를 수신하는 통신부;공개특허 10-2021-0022434-5-를 더 포함하며,상기 제어부는, 상기 음성 인식 결과를 이용하여 상기 음성 인식 신호의 음성인식 여부를 판단하는,음성 인식 장치."}
{"patent_id": "10-2019-0101940", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제9항에 있어서,상기 출력부는, 상기 음성 신호가 인식되지 않는 경우, 상기 사용자의 음성 신호의 재요청 신호를 출력하고,상기 입력부는, 상기 재요청 신호의 출력에 응답하여 상기 사용자의 부가 신호를 획득하는,음성 인식 장치."}
{"patent_id": "10-2019-0101940", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제9항에 있어서,상기 사용자의 부가 신호는, 상기 사용자의 시선(line of sight) 신호, 음성 신호 및 동작 신호 중 적어도 하나를 포함하는,음성 인식 장치."}
{"patent_id": "10-2019-0101940", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제9항에 있어서,상기 제어부는,상기 음성 신호와 상기 제1 텍스트 정보를 이용하여 음성인식 인공지능 학습모델을 학습시키는,음성 인식 장치."}
{"patent_id": "10-2019-0101940", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 음성인식 방법 및 장치에 관한 것이다. 본 발명의 일 실시예에 따른 음성 인식 방법은 (a) 사용자의 음성 신호를 획득하는 단계; (b) 상기 획득된 음성 신호를 이용하여 상기 음성 신호의 음성인식 여부를 판단하는 단계; (c) 상기 음성 신호가 인식되는 경우, 상기 음성 신호에 대응하는 제1 텍스트 정보를 출력하는 단계; 및 (d) 상기 음성 신호가 인식되지 않는 경우, 상기 사용자의 부가 신호를 획득하고, 상기 부가 신호에 대응하는 제 2 텍스트 정보를 출력하는 단계;를 포함할 수 있다."}
{"patent_id": "10-2019-0101940", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 음성인식 방법 및 장치에 관한 것으로, 더욱 상세하게는 사용자의 음성 신호에 대한 음성 인식이 실 패하는 경우에 사용자로부터 추가적인 부가 신호를 획득하여, 획득된 부가 신호에 대응하는 텍스트 정보를 제공 하기 위한 음성인식 방법 및 장치에 관한 것이다."}
{"patent_id": "10-2019-0101940", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "음성 인식 기술은 미리 수집된 음성데이터로부터 각 음소별 확률 모델을 미리 학습하고, 이후 입력된 음성데이 터가 어느 음소에 가장 가까운지를 판단하여 이로부터 음소열을 추정하는 방식을 사용한다. 이때 사용하는 각 음소별 확률 모델을 음향모델이라고 부르며, 음향모델은 음성 인식 기술의 성능을 좌우하는 중요한 요소 중에 하나이다. 최근 음성 인식 기술의 관심이 집중되면서, 음성 인식을 용이하게 하기 위한 다양한 알고리즘이 제안되었다. 다 만, 기존의 음성 인식 기술은 음성 인식을 어떠한 방식으로 수행할 것인지에 대한 연구만이 진행되고 있을 뿐, 음성 인식이 제대로 수행되지 않은 경우, 이에 대한 대응 방식을 제시하지 못하는 문제점이 있다. 선행기술문헌 특허문헌 (특허문헌 0001) [특허문헌 1] 한국공개특허 제10-2019-0035454호"}
{"patent_id": "10-2019-0101940", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 전술한 문제점을 해결하기 위하여 창출된 것으로, 음성인식 방법 및 장치를 제공하는 것을 그 목적으 로 한다. 또한, 본 발명은 음성 신호가 인식되는 경우, 음성 신호에 대응하는 제1 텍스트 정보를 출력하고, 초기 음성 신 호가 인식되지 않더라도, 부가 신호를 추가적으로 획득하여, 다수의 후보 텍스트 정보 중 사용자의 음성 신호에 대한 제2 텍스트 정보를 출력하기 위한 음성인식 방법 및 장치를 제공하는 것을 그 목적으로 한다. 또한, 본 발명은 클라우드 서버에게 사용자의 음성 신호의 적어도 일부를 실시간으로 송신함으로써, 클라우드 서버를 통해 사용자의 자연어 음성(즉, 음성 신호)을 실시간으로 분석하기 위한 음성인식 방법 및 장치를 제공 하는 것을 그 목적으로 한다. 본 발명의 목적들은 이상에서 언급한 목적들로 제한되지 않으며, 언급되지 않은 또 다른 목적들은 아래의 기재 로부터 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2019-0101940", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기한 목적들을 달성하기 위하여, 본 발명의 일 실시예에 따른 음성 인식 방법은 (a) 사용자의 음성 신호를 획 득하는 단계; (b) 상기 획득된 음성 신호를 이용하여 상기 음성 신호의 음성인식 여부를 판단하는 단계; (c) 상 기 음성 신호가 인식되는 경우, 상기 음성 신호에 대응하는 제1 텍스트 정보를 출력하는 단계; 및 (d) 상기 음 성 신호가 인식되지 않는 경우, 상기 사용자의 부가 신호를 획득하고, 상기 부가 신호에 대응하는 제2 텍스트 정보를 출력하는 단계;를 포함할 수 있다. 실시예에서, 상기 (a) 단계는, 상기 음성 신호의 데시벨(decibel, dB)이 임계값 이상인 경우, 상기 사용자의 음 성 신호를 획득하는 단계;를 포함할 수 있다. 실시예에서, 상기 (b) 단계는, 상기 음성 신호를 시간 도메인과 주파수 도메인에 대한 사운드 스펙트로그램으로 변환하는 단계; 상기 사운드 스펙트로그램으로부터 상기 제1 텍스트 정보를 추출하는 단계; 및 상기 제1 텍스트 정보를 이용하여 상기 음성 신호의 인식 여부를 판단하는 단계;를 포함할 수 있다. 실시예에서, 상기 제1 텍스트 정보를 이용하여 상기 음성 신호의 인식 여부를 판단하는 단계는, 상기 제1 텍스 트 정보로부터 상기 제1 텍스트 정보의 구문 정보를 추출하는 단계; 및 상기 추출된 구문 정보가 미리 정의된 구문 정보와 일치하는지 여부를 판단하는 단계;를 포함할 수 있다. 실시예에서, 상기 (a) 단계는, 상기 사용자의 음성 신호의 적어도 일부를 획득하는 단계;를 포함하고, 상기 (b) 단계는, 상기 음성 신호의 적어도 일부를 클라우드 서버에게 송신하는 단계; 상기 클라우드 서버로부터 상기 음 성 신호의 적어도 일부에 대한 음성 인식 결과를 수신하는 단계; 및 상기 음성 인식 결과를 이용하여 상기 음성 신호의 음성인식 여부를 판단하는 단계;를 포함할 수 있다. 실시예에서, 상기 (d) 단계는, 상기 음성 신호가 인식되지 않는 경우, 상기 사용자의 음성 신호의 재요청 신호 를 출력하는 단계; 및 상기 재요청 신호의 출력에 응답하여 상기 사용자의 부가 신호를 획득하는 단계;를 포함 할 수 있다. 실시예에서, 상기 사용자의 부가 신호는, 상기 사용자의 시선(line of sight) 신호, 음성 신호 및 동작 신호 중 적어도 하나를 포함할 수 있다. 실시예에서, 상기 음성 인식 방법은, 상기 (c) 단계 이후에, 상기 음성 신호와 상기 제1 텍스트 정보를 이용하 여 음성인식 인공지능 학습모델을 학습시키는 단계;를 더 포함할 수 있다. 실시예에서, 음성 인식 장치는 사용자의 음성 신호를 획득하는 입력부; 상기 획득된 음성 신호를 이용하여 상기 음성 신호의 음성인식 여부를 판단하는 제어부; 및 상기 음성 신호가 인식되는 경우, 상기 음성 신호에 대응하 는 제1 텍스트 정보를 출력하고, 상기 음성 신호가 인식되지 않는 경우, 상기 사용자의 부가 신호를 획득하고, 상기 부가 신호에 대응하는 제2 텍스트 정보를 출력하는 출력부;를 포함할 수 있다. 실시예에서, 상기 입력부는, 상기 음성 신호의 데시벨(decibel, dB)이 임계값 이상인 경우, 상기 사용자의 음성 신호를 획득할 수 있다. 실시예에서, 상기 제어부는, 상기 음성 신호를 시간 도메인과 주파수 도메인에 대한 사운드 스펙트로그램으로 변환하고, 상기 사운드 스펙트로그램으로부터 상기 제1 텍스트 정보를 추출하며, 상기 제1 텍스트 정보를 이용 하여 상기 음성 신호의 인식 여부를 판단할 수 있다. 실시예에서, 상기 제어부는, 상기 제1 텍스트 정보로부터 상기 제1 텍스트 정보의 구문 정보를 추출하고, 상기 추출된 구문 정보가 미리 정의된 구문 정보와 일치하는지 여부를 판단할 수 있다. 실시예에서, 상기 입력부는, 상기 사용자의 음성 신호의 적어도 일부를 획득하고, 상기 음성 신호의 적어도 일 부를 클라우드 서버에게 송신하고, 상기 클라우드 서버로부터 상기 음성 신호의 적어도 일부에 대한 음성 인식 결과를 수신하는 통신부;를 더 포함하며, 상기 제어부는, 상기 음성 인식 결과를 이용하여 상기 음성 인식 신호 의 음성인식 여부를 판단할 수 있다. 실시예에서, 상기 출력부는, 상기 음성 신호가 인식되지 않는 경우, 상기 사용자의 음성 신호의 재요청 신호를 출력하고, 상기 입력부는, 상기 재요청 신호의 출력에 응답하여 상기 사용자의 부가 신호를 획득할 수 있다. 실시예에서, 상기 사용자의 부가 신호는, 상기 사용자의 시선(line of sight) 신호, 음성 신호 및 동작 신호 중 적어도 하나를 포함할 수 있다. 실시예에서, 상기 제어부는, 상기 음성 신호와 상기 제1 텍스트 정보를 이용하여 음성인식 인공지능 학습모델을 학습시킬 수 있다. 상기한 목적들을 달성하기 위한 구체적인 사항들은 첨부된 도면과 함께 상세하게 후술될 실시예들을 참조하면 명확해질 것이다. 그러나, 본 발명은 이하에서 개시되는 실시예들에 한정되는 것이 아니라, 서로 다른 다양한 형태로 구성될 수 있으며, 본 발명의 개시가 완전하도록 하고 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자(이하, \"통 상의 기술자\")에게 발명의 범주를 완전하게 알려주기 위해서 제공되는 것이다."}
{"patent_id": "10-2019-0101940", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명의 일 실시예에 의하면, 음성 신호가 인식되는 경우, 음성 신호에 대응하는 제1 텍스트 정보를 출력함으 로써, 사용자는 음성인식 장치가 사용자의 음성 신호를 제대로 인식했는지 직접 확인할 수 있다. 또한, 본 발명의 일 실시예에 의하면, 초기 음성 신호가 인식되지 않더라도, 부가 신호를 추가적으로 획득하여, 다수의 후보 텍스트 정보 중 사용자의 음성 신호에 대한 제2 텍스트 정보를 출력하여 음성인식 성공률을 높일 수 있다. 또한, 본 발명의 일 실시예에 의하면, 클라우드 서버에게 사용자의 음성 신호의 적어도 일부를 실시간으로 송신 함으로써, 클라우드 서버를 통해 사용자의 자연어 음성(즉, 음성 신호)을 실시간으로 분석하여 텍스트 형식으로 변환함에 따라 보다 빠르게 자연어 처리가 가능하다."}
{"patent_id": "10-2019-0101940", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 2, "content": "본 발명의 효과들은 상술된 효과들로 제한되지 않으며, 본 발명의 기술적 특징들에 의하여 기대되는 잠정적인 효과들은 아래의 기재로부터 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2019-0101940", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명은 다양한 변경을 가할 수 있고, 여러 가지 실시예들을 가질 수 있는 바, 특정 실시예들을 도면에 예시 하고 이를 상세히 설명하고자 한다. 청구범위에 개시된 발명의 다양한 특징들은 도면 및 상세한 설명을 고려하여 더 잘 이해될 수 있을 것이다. 명 세서에 개시된 장치, 방법, 제법 및 다양한 실시예들은 예시를 위해서 제공되는 것이다. 개시된 구조 및 기능상 의 특징들은 통상의 기술자로 하여금 다양한 실시예들을 구체적으로 실시할 수 있도록 하기 위한 것이고, 발명 의 범위를 제한하기 위한 것이 아니다. 개시된 용어 및 문장들은 개시된 발명의 다양한 특징들을 이해하기 쉽게 설명하기 위한 것이고, 발명의 범위를 제한하기 위한 것이 아니다. 본 발명을 설명함에 있어서, 관련된 공지기술에 대한 구체적인 설명이 본 발명의 요지를 불필요하게 흐릴 수 있 다고 판단되는 경우, 그 상세한 설명을 생략한다. 이하, 본 발명의 일 실시예에 따른 음성인식 방법 및 장치를 설명한다. 도 1은 본 발명의 일 실시예에 따른 음성인식 시스템을 도시한 도면이다. 도 1을 참고하면, 음성인식 장치는 사용자로부터 음성 신호를 획득하고, 획득된 음성 신호를 이용하여 음 성 신호의 음성인식 여부를 판단할 수 있다. 일 실시예에서, 음성인식 장치는 사용자의 음성 신호를 텍스트 정보로 변환한 후, 변환된 텍스트 정보를 이용하여 음성 인식을 수행하여 음성인식 여부를 판단할 수 있다. 다른 실시예에서, 음성인식 장치는 사용자의 음성 신호의 적어도 일부를 클라우드 서버에게 송신하고, 클라우드 서버로부터 사용자의 음성 신호의 적어도 일부에 대한 음성 인식 결과를 수신하여 음 성인식 여부를 판단할 수 있다. 음성인식 장치는 음성 신호가 인식되는 경우, 음성 신호에 대응하는 제1 텍스트 정보를 출력할 수 있다. 여기서, 제1 텍스트 정보는 사용자의 음성 신호로부터 변환된 텍스트 정보를 포함할 수 있다. 즉, 본 발명에 따른 음성인식 장치는 음성 신호가 인식되는 경우, 음성 신호에 대응하는 제1 텍스트 정보 를 출력함으로써, 사용자는 음성인식 장치가 사용자의 음성 신호를 제대로 인식했는지 직접 확인할 수 있 다. 반면, 음성인식 장치는 음성 신호가 인식되지 않는 경우, 사용자의 부가 신호를 획득하여, 부가 신호에 대 응하는 제2 텍스트 정보를 출력할 수 있다. 여기서, 제2 텍스트 정보는 사용자의 음성 신호에 대한 다수의 후보 텍스트 정보 중 하나를 포함할 수 있다. 즉, 본 발명에 따른 음성인식 장치는 초기 음성 신호가 인식되지 않더라도, 부가 신호를 추가적으로 획득 하여, 다수의 후보 텍스트 정보 중 사용자의 음성 신호에 대한 제2 텍스트 정보를 출력하여 음성인식 성공률을 높일 수 있다. 일 실시예에서, 음성인식 장치는 제1 텍스트 정보 또는 제2 텍스트 정보 각각에 대응하는 응답 메시지를 출력할 수 있다. 일 실시예에서, 음성인식 장치는 키오스크(kiosk), 스마트폰, 태블릿 PC, 노트북 등 다양한 형태로 구현될 수 있으나, 이에 제한되지 않는다. 도 2는 본 발명의 일 실시예에 따른 음성인식 장치의 동작 방법을 도시한 도면이다. 도 2를 참고하면, S201 단계는 사용자의 음성 신호를 획득하는 단계이다. 일 실시예에서, 음성 신호의 데시벨 (decibel, dB)이 임계값 이상인 경우, 사용자의 음성 신호를 획득할 수 있다. S203 단계는 획득된 음성 신호를 이용하여 음성 신호의 음성인식 여부를 판단하는 단계이다. 일 실시예에서, 음성 신호를 시간 도메인과 주파수 도메인에 대한 사운드 스펙트로그램(spectrogram)으로 변환 하고, 사운드 스펙트로그램으로부터 제1 텍스트 정보를 추출하며, 제1 텍스트 정보를 이용하여 음성 신호의 인 식 여부를 판단할 수 있다. 일 실시예에서, 변환된 음성 신호에 대한 사운드 스펙트로그램과 해당 사운드 스펙트로그램에 대응되는 제1 텍 스트 정보를 추출할 수 있다. 일 실시예에서, 음성 신호를 사운드 스펙트로그램으로 변환하고, 사운드 스펙트로그램을 음성인식 인공지능 학 습모델에 적용하여 제1 텍스트 정보를 추출하고 음성 인식을 수행할 수 있다. 여기서, 사운드 스펙트로그램은 시간 도메인과 주파수 도메인에 대한 음성 신호의 진폭 크기를 색상으로 표현한 그래프를 의미할 수 있다. 일 실시예에서, S201 단계에서 사용자의 음성 신호의 적어도 일부를 획득할 수 있으며, 이 경우, 음성 신호의 적어도 일부를 클라우드 서버에게 송신할 수 있다. 즉, 음성 신호 전체를 획득한 후, 전체 음성 신호에 대한 음성 인식을 수행하는 것이 아니라, 실시간으로 획득 되는 음성 신호의 일부분을 클라우드 서버에게 송신할 수 있다. 여기서, 전체 음성 신호는 음성 신호의 데시벨(decibel, dB)이 임계값 이상인 경우 획득되는 사용자의 음성 신 호 전체를 의미할 수 있다. 즉, 전체 음성 신호는 음성인식 장치가 사용자의 음성 신호의 데시벨이 임계값 이상인 경우 음성 신호 획득을 시작하고, 이후, 사용자가 발화를 종료함으로써 음성 신호의 데시벨이 임계값 이 하로 떨어지는 경우 음성 신호 획득을 종료하는데, 이 때, 획득되는 전체 음성 신호를 의미할 수 있다. 또한, 일 실시예에서, 클라우드 서버로부터 음성 신호의 적어도 일부에 대한 음성 인식 결과를 수신하며, 음성 인식 결과를 이용하여 음성 신호의 음성인식 여부를 판단할 수 있다. 즉, 클라우드 서버는 실시간으로 수신되는 음성 신호의 각 부분을 텍스트 정보로 변환하고, 변환된 텍스트 정보에 대하여 음성 인식을 수행하여, 음성 인식 결과를 음성인식 장치에게 송신할 수 있다. 여기서, 음성 신호의 각 부분에 대한 음성 인식 결과는 ‘중간 인식 결과’ 또는 이와 동등한 기술적 의미를 갖는 용어로 지 칭될 수 있다. 또한, 클라우드 서버는 최종적으로 전체 음성 신호를 전부 수신한 후, 전체 음성 신호를 텍스트 정보로 변 환하고, 변환된 텍스트 정보에 대하여 음성 인식을 수행하여, 음성 인식 결과를 음성인식 장치에게 송신할 수 있다. 여기서, 전체 음성 신호에 대한 음성 인식 결과는 ‘최종 인식 결과’ 또는 이와 동등한 기술적 의미 를 갖는 용어로 지칭될 수 있다. 이와 같이, 본 발명에 따른 음성인식 방법은 사용자의 자연어 음성(즉, 음성 신호)을 실시간으로 분석하여 텍스 트 형식으로 변환함에 따라, 기존의 사용자의 전체 음성이 끝난 후 분석하여 변환하는 방식에 비해 실시간으로 자연어 처리를 수행함으로써 보다 빠르게 자연어 처리가 가능하다. 일 실시예에서, 제1 텍스트 정보로부터 제1 텍스트 정보의 구문(syntax) 정보를 추출하고, 추출된 구문 정보가 미리 정의된 구문 정보와 일치하는지 여부를 판단함으로써, 음성 신호의 인식 여부를 판단할 수 있다. S205 단계는 음성 신호가 인식되는 경우, 음성 신호에 대응하는 제1 텍스트 정보를 출력하는 단계이다. 일 실시예에서, 음성 신호가 인식되는 경우, 음성 신호와 제1 텍스트 정보를 이용하여 음성인식 인공지능 학습 모델을 학습시킬 수 있다. 즉, 음성 신호와 이에 대응하는 제1 텍스트 정보를 학습 데이터로 이용하여 음성인식 인공지능 학습모델을 학습시킴으로써, 지속적으로 음성인식 정확도를 높일 수 있다. S207 단계는 음성 신호가 인식되지 않는 경우, 사용자의 부가 신호를 획득하고, 부가 신호에 대응하는 제2 텍스 트 정보를 출력하는 단계이다. 일 실시예에서, 음성 신호가 인식되지 않는 경우, 사용자의 음성 신호의 재요청 신호를 출력하고, 재요청 신호 의 출력에 응답하여 사용자의 부가 신호를 획득할 수 있다. 예를 들어, 재요청 신호는 “다시 말씀을 해주시겠습니까?”와 같은 텍스트 정보 및 사운드 정보 중 적어도 하 나를 의미할 수 있다. 즉, 음성 신호가 인식되지 않는 경우, 사용자의 음성 신호의 재요청 신호를 텍스트 정보 로 화면에 디스플레이하거나, 사운드 정보로 스피커를 통해 출력할 수 있다. 일 실시예에서, 사용자의 부가 신호는, 사용자의 시선(line of sight) 신호, 음성 신호 및 동작 신호 중 적어도 하나를 포함할 수 있다. 예를 들어, 사용자의 시선 신호에 포함된 시선 패턴 정보 및 동작 정보에 포함된 동작 패턴 정보 중 적어도 하 나를 이용하여 사용자의 음성 신호와 관련된 감정 상태를 파악함으로써, 음성 신호에 대하여 부가 신호에 대응 하는 제2 텍스트 정보를 출력할 수 있다. 도 3은 본 발명의 일 실시예에 따른 음성인식 장치의 기능적 구성을 도시한 도면이다. 도 3을 참고하면, 음성인식 장치는 입력부, 제어부, 저장부, 출력부 및 통신부(35 0)를 포함할 수 있다. 입력부는 사용자의 음성 신호를 획득할 수 있다. 일 실시예에서, 입력부는 마이크로폰으로 구현될 수 있으며, 음성인식 장치와 일체형(all-in-one)뿐만 아니라 분리된 형태로 구현될 수 있다. 제어부는 획득된 음성 신호를 이용하여 음성 신호의 인식 여부를 판단할 수 있다. 일 실시예에서, 제어부는 적어도 하나의 프로세서 또는 마이크로(micro) 프로세서를 포함하거나, 또는, 프 로세서의 일부일 수 있다. 또한, 제어부는 CP(communication processor)라 지칭될 수 있다. 제어부 는 본 발명의 다양한 실시예에 따른 대화서비스 제공 장치의 동작을 제어할 수 있다. 저장부는 음성인식 인공지능 학습모델을 학습시키기 위한 학습 데이터를 저장할 수 있다. 일 실시예에서, 저장부는 음성 신호의 인식 여부를 판단하기 위해 미리 정의된 구문 정보를 저장할 수 있 다. 일 실시예에서, 저장부는 사용자의 부가 신호와 비교하기 위한 미리 정의된 사용자의 시선 신호, 음성 신 호 및 동작 신호 중 적어도 하나를 저장할 수 있다. 일 실시예에서, 저장부는 휘발성 메모리, 비휘발성 메모리 또는 휘발성 메모리와 비휘발성 메모리의 조합 으로 구성될 수 있다. 그리고, 저장부는 제어부의 요청에 따라 저장된 데이터를 제공할 수 있다. 출력부는 음성 신호가 인식되는 경우, 음성 신호에 대응하는 제1 텍스트 정보를 출력할 수 있다. 또한, 출 력부는 음성 신호가 인식되지 않는 경우, 사용자의 부가 신호를 획득하고, 부가 신호에 대응하는 제2 텍스 트 정보를 출력할 수 있다. 일 실시예에서, 출력부는 음성인식 장치에서 처리되는 정보를 화면으로 디스플레이할 수 있다. 예를 들면, 출력부는 액정 디스플레이(LCD; Liquid Crystal Display), 발광 다이오드(LED; Light Emitting Diode) 디스플레이, 유기 발광 다이오드(OLED; Organic LED) 디스플레이, 마이크로 전자기계 시스템(MEMS; Micro Electro Mechanical Systems) 디스플레이 및 전자 종이(electronic paper) 디스플레이 중 적어도 어느 하나를 포함할 수 있으나, 이에 제한되지 않는다. 일 실시예에서, 출력부는 음성인식 장치에서 처리되는 정보를 사운드로 출력할 수 있다. 예를 들어, 출력부는 스피커 또는 사운드를 출력할 수 있는 다양한 출력 단자로 구현될 수 있다. 일 실시예에서, 통신부는 음성 신호의 적어도 일부를 클라우드 서버에게 송신하고, 클라우드 서버 로부터 음성 신호의 적어도 일부에 대한 음성 인식 결과를 수신할 수 있다. 일 실시예에서, 통신부는 유선 통신 모듈 및 무선 통신 모듈 중 적어도 하나를 포함할 수 있다. 통신부 의 전부 또는 일부는 '송신부', '수신부' 또는 '송수신부(transceiver)'로 지칭될 수 있다. 도 3을 참고하면, 음성인식 장치는 입력부, 제어부, 저장부, 출력부 및 통신부(35 0)를 포함할 수 있다. 본 발명의 다양한 실시예들에서 음성인식 장치는 도 3에 설명된 구성들이 필수적인 것은 아니어서, 도 3에 설명된 구성들보다 많은 구성들을 가지거나, 또는 그보다 적은 구성들을 가지는 것으로 구현될 수 있다. 이상의 설명은 본 발명의 기술적 사상을 예시적으로 설명한 것에 불과한 것으로, 통상의 기술자라면 본 발명의 본질적인 특성이 벗어나지 않는 범위에서 다양한 변경 및 수정이 가능할 것이다. 따라서, 본 명세서에 개시된 실시예들은 본 발명의 기술적 사상을 한정하기 위한 것이 아니라, 설명하기 위한 것이고, 이러한 실시예들에 의하여 본 발명의 범위가 한정되는 것은 아니다. 본 발명의 보호범위는 청구범위에 의하여 해석되어야 하며, 그와 동등한 범위 내에 있는 모든 기술 사상은 본 발명의 권리범위에 포함되는 것으로 이해되어야 한다."}
{"patent_id": "10-2019-0101940", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일 실시예에 따른 음성인식 시스템을 도시한 도면이다. 도 2는 본 발명의 일 실시예에 따른 음성인식 방법을 도시한 도면이다. 도 3은 본 발명의 일 실시예에 따른 음성인식 장치의 기능적 구성을 도시한 도면이다."}
