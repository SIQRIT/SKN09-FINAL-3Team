{"patent_id": "10-2019-0088228", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2021-0011162", "출원번호": "10-2019-0088228", "발명의 명칭": "디스플레이장치 및 그 제어방법", "출원인": "삼성전자주식회사", "발명자": "장정록"}}
{"patent_id": "10-2019-0088228", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "디스플레이장치에 있어서,디스플레이와,상기 디스플레이장치의 사용 환경에 관한 정보를 획득하고,스타일을 변경할 제1이미지를 식별하고,상기 획득된 사용 환경에 관한 정보에 기초하여, 상기 제1이미지에 적용 가능하도록 마련된 복수의 스타일 중에서 어느 하나의 스타일을 식별하고,상기 식별된 스타일에 관한 정보에 기초하여 상기 제1이미지로부터 변환된 제2이미지를 획득하고,상기 획득된 제2이미지를 표시하도록 상기 디스플레이를 제어하는 프로세서를 포함하는 디스플레이장치."}
{"patent_id": "10-2019-0088228", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 식별된 스타일에 관한 정보는 딥 러닝 기반의 인공신경망 모델을 포함하는 디스플레이장치."}
{"patent_id": "10-2019-0088228", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,상기 프로세서는, 상기 복수의 스타일에 각기 대응하는 복수의 모델 중에서 상기 식별된 스타일에 대응하는 모델에 기초하여 상기 제1이미지를 변환시키는 디스플레이장치."}
{"patent_id": "10-2019-0088228", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,상기 사용 환경에 관한 정보는, 상기 디스플레이장치의 사용 시간, 사용 장소, 사용 이력, 또는 주변 환경 중적어도 하나에 관한 정보를 포함하는 디스플레이장치."}
{"patent_id": "10-2019-0088228", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서,상기 프로세서는, 상기 디스플레이장치의 사용 환경에 관한 복수의 속성 항목 별 속성값들이 정의된 룩업테이블에 기초하여 상기 획득된 사용 환경에 관한 정보를 처리하는 디스플레이장치."}
{"patent_id": "10-2019-0088228", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서,상기 프로세서는,상기 복수의 스타일 중에서 상기 획득된 사용 환경에 관한 정보에 기초하여 제1스타일을 식별하고,상기 제1이미지의 속성에 관한 정보에 기초하여 제2스타일을 식별하고,상기 제1스타일에 관한 정보 및 상기 제2스타일에 관한 정보에 기초하여 상기 제1이미지를 변환시키는 디스플레이장치."}
{"patent_id": "10-2019-0088228", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "공개특허 10-2021-0011162-3-제6항에 있어서,상기 프로세서는, 이미지에 관한 복수의 속성 항목 별 속성값들이 정의된 룩업테이블에 기초하여 상기 제1이미지의 속성에 관한 정보를 처리하는 디스플레이장치."}
{"patent_id": "10-2019-0088228", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제6항에 있어서,상기 제1이미지의 속성에 관한 정보는, 상기 제1이미지의 오브젝트에 관한 정보를 포함하는 디스플레이장치."}
{"patent_id": "10-2019-0088228", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1항에 있어서,서버와 통신하는 통신회로를 더 포함하며,상기 프로세서는, 상기 제1이미지의 정보를 상기 통신회로를 통해 상기 서버에 전송하고, 상기 서버에 의해 변환된 상기 제2이미지의 정보를 상기 서버로부터 상기 통신회로를 통해 획득하는 디스플레이장치."}
{"patent_id": "10-2019-0088228", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제1항에 있어서,상기 스타일은, 상기 제1이미지의 색상, 채도, 명도, 콘트라스트, 상기 제1이미지 내 오브젝트의 에지의 종류,또는 상기 오브젝트에 적용되는 텍스처의 종류 중 적어도 어느 하나를 포함하는 디스플레이장치."}
{"patent_id": "10-2019-0088228", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "디스플레이장치의 제어방법에 있어서,디스플레이장치의 사용 환경에 관한 정보를 획득하는 단계와,스타일을 변경할 제1이미지를 식별하는 단계와,상기 획득된 사용 환경에 관한 정보에 기초하여, 상기 제1이미지에 적용 가능하도록 마련된 복수의 스타일 중에서 어느 하나의 스타일을 식별하는 단계와,상기 식별된 스타일에 관한 정보에 기초하여 상기 제1이미지로부터 변환된 제2이미지를 획득하는 단계와,상기 획득된 제2이미지를 표시하는 단계를 포함하는 디스플레이장치의 제어방법."}
{"patent_id": "10-2019-0088228", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항에 있어서,상기 식별된 스타일에 관한 정보는 딥 러닝 기반의 인공신경망 모델을 포함하는 디스플레이장치의 제어방법."}
{"patent_id": "10-2019-0088228", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제12항에 있어서,상기 복수의 스타일에 각기 대응하는 복수의 모델 중에서 상기 식별된 스타일에 대응하는 모델에 기초하여 상기제1이미지를 변환시키는 디스플레이장치의 제어방법."}
{"patent_id": "10-2019-0088228", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제11항에 있어서,상기 사용 환경에 관한 정보는, 상기 디스플레이장치의 사용 시간, 사용 장소, 사용 이력, 또는 주변 환경 중적어도 하나에 관한 정보를 포함하는 디스플레이장치의 제어방법."}
{"patent_id": "10-2019-0088228", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제11항에 있어서,공개특허 10-2021-0011162-4-상기 디스플레이장치의 사용 환경에 관한 복수의 속성 항목 별 속성값들이 정의된 룩업테이블에 기초하여 상기획득된 사용 환경에 관한 정보를 처리하는 디스플레이장치의 제어방법."}
{"patent_id": "10-2019-0088228", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제11항에 있어서,상기 복수의 스타일 중에서 상기 획득된 사용 환경에 관한 정보에 기초하여 제1스타일을 식별하고,상기 제1이미지의 속성에 관한 정보에 기초하여 제2스타일을 식별하고,상기 제1스타일에 관한 정보 및 상기 제2스타일에 관한 정보에 기초하여 상기 제1이미지를 변환시키는 디스플레이장치의 제어방법."}
{"patent_id": "10-2019-0088228", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제16항에 있어서,이미지에 관한 복수의 속성 항목 별 속성값들이 정의된 룩업테이블에 기초하여 상기 제1이미지의 속성에 관한정보를 처리하는 디스플레이장치의 제어방법."}
{"patent_id": "10-2019-0088228", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제16항에 있어서,상기 제1이미지의 속성에 관한 정보는, 상기 제1이미지의 오브젝트에 관한 정보를 포함하는 디스플레이장치의제어방법."}
{"patent_id": "10-2019-0088228", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제11항에 있어서,상기 제1이미지의 정보를 상기 서버에 전송하고, 상기 서버에 의해 변환된 상기 제2이미지의 정보를 상기 서버로부터 획득하는 디스플레이장치의 제어방법."}
{"patent_id": "10-2019-0088228", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제11항에 있어서,상기 스타일은, 상기 제1이미지의 색상, 채도, 명도, 콘트라스트, 상기 제1이미지 내 오브젝트의 에지의 종류,또는 상기 오브젝트에 적용되는 텍스처의 종류 중 적어도 어느 하나를 포함하는 디스플레이장치의 제어방법."}
{"patent_id": "10-2019-0088228", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "디스플레이장치는, 디스플레이장치의 사용 환경에 관한 정보를 획득하고, 스타일을 변경할 제1이미지를 식별하고, 획득된 사용 환경에 관한 정보에 기초하여 제1이미지에 적용 가능하도록 마련된 복수의 스타일 중에서 어느 하나의 스타일을 식별하고, 식별된 스타일에 관한 정보에 기초하여 제1이미지로부터 변환된 제2이미지를 획 득하고, 획득된 제2이미지를 표시하도록 디스플레이를 제어하는 프로세서를 포함한다."}
{"patent_id": "10-2019-0088228", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 이미지 등의 시각적 컨텐트를 처리하는 디스플레이장치 및 그 제어방법에 관한 것으로서, 상세하게는 입력되는 이미지의 스타일을 변경하여 새로운 이미지를 생성하는 디스플레이장치 및 그 제어방법에 관한 것이다."}
{"patent_id": "10-2019-0088228", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "소정의 정보를 특정 프로세스에 따라서 연산 및 처리하기 위해, 연산을 위한 CPU, 칩셋, 메모리 등의 전자부품 들을 기본적으로 포함하는 전자장치는, 처리 대상이 되는 정보 또는 사용 용도가 무엇인지에 따라서 다양한 종 류로 구분될 수 있다. 예를 들면, 전자장치에는 범용의 정보를 처리하는 PC나 서버 등의 정보처리장치, 영상데 이터를 처리하는 영상처리장치, 오디오를 처리하는 오디오장치, 가정 내 잡무를 수행하는 생활가전 등이 있다. 영상처리장치는 처리된 영상데이터를 자체 구비한 디스플레이 패널(display panel) 상에 영상으로 표시하는 디 스플레이장치로 구현될 수 있다 디스플레이장치는 기본적으로 동영상, 이미지 등의 컨텐트를 표시하는 장치이지만, 컨텐트에 사용자가 요구하는 여러 기능을 반영함으로써 해당 컨텐트를 변형시키는 서비스를 제공할 수도 있다. 이러한 서비스의 한 가지 예시로는 스타일 트랜스퍼(style transfer)를 들 수 있다. 스타일 트랜스퍼는, 입력 이미지에 사용자가 지정한 스 타일을 적용하여 변형시켜 새로운 출력 이미지를 생성하는 기능이다. 즉, 스타일 트랜스퍼는 입력 이미지의 컨 텐트를 유지하면서 입력 이미지의 스타일을 변경하는 방식이다. 입력 이미지의 스타일을 바꾸는 방법은 여러 가 지가 가능한데, AI(Artificial Intelligence)에 의한 머신러닝(Machine-learning) 또는 딥러닝(Deep- learning)에 기반한 모델링 변환 방법이 한 가지 예시가 될 수 있다. 디스플레이장치는 다양한 스타일에 대응하는 CNN(Convolutional Neural Network) 기반 모델을 보유하고 있거나 또는 억세스 할 수 있게 마련된다. 디스플레이장치는 입력 이미지에 대해 적용될 수 있는 다양한 스타일의 리스 트를 표시하고, 리스트 상에서 사용자에게 선택된 하나 이상의 스타일을 식별한다. 디스플레이장치는 식별된 하 나 이상의 스타일에 대응하는 모델을 획득하고, 획득한 모델에 의해 입력 이미지를 출력 이미지로 변환시킨다. 이러한 출력 이미지는, 입력 이미지의 컨텐트와, 획득한 모델의 스타일을 가진다. 이러한 방식은 사용자가 직접 스타일을 선택하게 된다. 디스플레이장치가 제공하는 다양한 스타일 중에서 입력 이미지에 최적화되거나 가장 어울리는 스타일이 무엇인지 판단하기 위해서는, 사용자가 여러 스타일을 개별적으 로 입력 이미지에 적용되도록 일일이 선택하고, 각 스타일에 따른 출력 이미지를 직접 보고 비교해 보아야 한다. 또는, 스타일 트랜스퍼를 제공하는 특정 서비스 또는 어플리케이션에서 기본 변환 시나리오를 제공할 수 있다. 그런데, 이러한 기본 변환 시나리오는 사용자의 개입이 없는 경우에는 하나의 고정된 방법에 따라서 입력 이미 지가 변환되므로, 결과적으로 입력 이미지에 최적화되거나 어울리지 않는 스타일이 반영될 수도 있다. 이러한 관점에서, 다양한 스타일 별 모델을 구비한 스타일 트랜스퍼 서비스에서, 입력 이미지에 최적화된 스타 일을 사용자의 개입을 최소화시켜 제공하도록 함으로써, 가장 최적의 출력 이미지를 자동으로 사용자에게 제공 할 수 있는 것이 바람직하다."}
{"patent_id": "10-2019-0088228", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 실시예에 따른 디스플레이장치는, 디스플레이와, 상기 디스플레이장치의 사용 환경에 관한 정보를 획 득하고, 스타일을 변경할 제1이미지를 식별하고, 상기 획득된 사용 환경에 관한 정보에 기초하여, 상기 제1이미 지에 적용 가능하도록 마련된 복수의 스타일 중에서 어느 하나의 스타일을 식별하고, 상기 식별된 스타일에 관 한 정보에 기초하여 상기 제1이미지로부터 변환된 제2이미지를 획득하고, 상기 획득된 제2이미지를 표시하도록 상기 디스플레이를 제어하는 프로세서를 포함한다. 또한, 상기 식별된 스타일에 관한 정보는 딥 러닝 기반의 인공신경망 모델을 포함할 수 있다. 또한, 상기 프로세서는, 상기 복수의 스타일에 각기 대응하는 복수의 모델 중에서 상기 식별된 스타일에 대응하 는 모델에 기초하여 상기 제1이미지를 변환시킬 수 있다. 또한, 상기 사용 환경에 관한 정보는, 상기 디스플레이장치의 사용 시간, 사용 장소, 사용 이력, 또는 주변 환 경 중 적어도 하나에 관한 정보를 포함할 수 있다. 또한, 상기 프로세서는, 상기 디스플레이장치의 사용 환경에 관한 복수의 속성 항목 별 속성값들이 정의된 룩업 테이블에 기초하여 상기 획득된 사용 환경에 관한 정보를 처리할 수 있다. 또한, 상기 프로세서는, 상기 복수의 스타일 중에서 상기 획득된 사용 환경에 관한 정보에 기초하여 제1스타일 을 식별하고, 상기 제1이미지의 속성에 관한 정보에 기초하여 제2스타일을 식별하고, 상기 제1스타일에 관한 정 보 및 상기 제2스타일에 관한 정보에 기초하여 상기 제1이미지를 변환시킬 수 있다. 또한, 상기 프로세서는, 이미지에 관한 복수의 속성 항목 별 속성값들이 정의된 룩업테이블에 기초하여 상기 제 1이미지의 속성에 관한 정보를 처리할 수 있다. 또한, 상기 제1이미지의 속성에 관한 정보는, 상기 제1이미지의 오브젝트에 관한 정보를 포함할 수 있다. 또한, 디스플레이장치는 서버와 통신하는 통신회로를 더 포함하며, 상기 프로세서는, 상기 제1이미지의 정보를 상기 통신회로를 통해 상기 서버에 전송하고, 상기 서버에 의해 변환된 상기 제2이미지의 정보를 상기 서버로부 터 상기 통신회로를 통해 획득할 수 있다. 또한, 상기 스타일은, 상기 제1이미지의 색상, 채도, 명도, 콘트라스트, 상기 제1이미지 내 오브젝트의 에지의 종류, 또는 상기 오브젝트에 적용되는 텍스처의 종류 중 적어도 어느 하나를 포함할 수 있다. 또한, 본 발명의 실시예에 따른 디스플레이장치의 제어방법은, 디스플레이장치의 사용 환경에 관한 정보를 획득 하는 단계와, 스타일을 변경할 제1이미지를 식별하는 단계와, 상기 획득된 사용 환경에 관한 정보에 기초하여, 상기 제1이미지에 적용 가능하도록 마련된 복수의 스타일 중에서 어느 하나의 스타일을 식별하는 단계와, 상기 식별된 스타일에 관한 정보에 기초하여 상기 제1이미지로부터 변환된 제2이미지를 획득하는 단계와, 상기 획득 된 제2이미지를 표시하는 단계를 포함한다."}
{"patent_id": "10-2019-0088228", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하에서는 첨부도면을 참조하여 본 발명에 따른 실시예들에 관해 상세히 설명한다. 각 도면을 참조하여 설명하 는 실시예들은 특별한 언급이 없는 한 상호 배타적인 구성이 아니며, 하나의 장치 내에서 복수 개의 실시예가"}
{"patent_id": "10-2019-0088228", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "선택적으로 조합되어 구현될 수 있다. 이러한 복수의 실시예의 조합은 본 발명의 기술분야에서 숙련된 기술자가 본 발명의 사상을 구현함에 있어서 임의로 선택되어 적용될 수 있다. 만일, 실시예에서 제1구성요소, 제2구성요소 등과 같이 서수를 포함하는 용어가 있다면, 이러한 용어는 다양한 구성요소들을 설명하기 위해 사용되는 것이며, 용어는 하나의 구성요소를 다른 구성요소와 구별하기 위하여 사 용되는 바, 이들 구성요소는 용어에 의해 그 의미가 한정되지 않는다. 실시예에서 사용하는 용어는 해당 실시예 를 설명하기 위해 적용되는 것으로서, 본 발명의 사상을 한정하지 않는다. 또한, 본 명세서에서의 복수의 구성요소 중 \"적어도 하나(at least one)\"라는 표현이 나오는 경우에, 본 표현은 복수의 구성요소 전체 뿐만 아니라, 복수의 구성요소 중 나머지를 배제한 각 하나 혹은 이들의 조합 모두를 지 칭한다. 도 1은 전자장치에 입력되는 입력 이미지의 처리 서비스를 제공하는 몇 가지 예시를 나타내는 예시도이다. 도 1에 도시된 바와 같이, 본 실시예에 따른 전자장치는 영상을 표시 가능한 디스플레이장치로 구현된다. 디스플레이장치로 구현되는 경우에, 전자장치는 TV, 컴퓨터, 태블릿, 휴대용 미디어 플레이어, 웨어러블 디바이스, 기타 모바일기기 등을 포함한다. 다만, 실제로 전자장치는 디스플레이장치 뿐만 아니라, 영상처 리장치, 생활가전, 정보처리장치 등 다양한 종류의 장치로 구현될 수 있다. 본 실시예에서는 해당 실시예에 따 른 특징을 간결하게 설명하기 위해, 전자장치가 입력 이미지 및 출력 이미지 자체적으로 표시할 수 있는 디스플레이장치로 구현되는 경우에 관해 설명하는 것 뿐임을 밝힌다. 전자장치는 사용자에게 입력 이미지의 스타일 변환 서비스를 전자장치 단독으로, 또는 전자장치 와 통신 가능한 서버와 함께 제공한다. 스타일 변환 서비스는 예를 들면 전자장치에서 구동되는 소정의 어플리케이션을 통해 제공될 수 있다. 스타일 변환 서비스는 입력 이미지의 스타일을 변환하여 출력 이미지를 생성하는 서비스이다. 입력 이미지는 다양한 표현 대상들이 스타일에 의해 시각적으로 표현됨으로써 형성된다. 스타일은 이미지에서 대상이 표현되는 기법 등에 의해서도 정해질 수 있다. 입력 이미지가 한낮의 거리를 나타낸다고 하면, 입 력 이미지 내에서 거리, 거리를 둘러싼 건물, 거리를 오가는 사람들 등은 표현 대상 중 하나인 오브젝트에 해당한다. 또한, 입력 이미지 내에서 한낮임을 느끼게 하는 태양빛의 높은 광량, 태양빛에 따른 노란색의 색감 등은 스타일에 해당한다. 여기서, 한낮에 해당하는 스타일 대신에 밤에 해당하는 스타일을 입력 이미지에 대해 적용한다고 가정한다. 밤에 해당하는 스타일은 예를 들면, 전체적으로 어두운 느낌을 주도록 낮은 광량, 흑색 기조의 색감, 광을 발산하는 광원 및 그 주변 사이의 콘트라스트 강조 등이 가능하다. 만일 입력 이미지의 여러 오브젝 트들을 그대로 유지한 상태에서 밤에 해당하는 스타일이 입력 이미지에 적용되면, 입력 이미지는 밤 의 거리를 나타내는 출력 이미지로 변환된다. 또한, 입력 이미지의 하늘에 눈발이 흩날리는 시각적 효과를 추가함으로써, 여름에 제작된 입력 이미지가 겨울인 느낌의 출력 이미지로 변환될 수도 있다. 즉, 동일한 오브젝트가 상이한 스타일로 표현됨으로써, 출력 이미지는 입력 이미지와 상이한 느낌을 사용자에게 줄 수 있다. 이와 같이, 스타일 변환 서비스는 입력 이미지를 표현하는 스타일을 변경함으로써, 입력 이미지의 오 브젝트를 포함하지만 입력 이미지와 상이한 느낌의 출력 이미지를 사용자에게 제공한다. 스타일은 여 러 가지의 구체적인 항목들을 포함할 수 있는데, 예를 들면 입력 이미지의 색상, 채도, 명도, 콘트라스트, 오브젝트의 에지 또는 경계선의 종류, 오브젝트에 적용되는 텍스처의 종류 등이 있다. 입력 이미지의 스타일을 선택된 스타일로 변경하는 방법은 여러 가지가 가능하며, 한 가지 예시로는 딥러 닝 기반의 CNN 모델에 따른 변환 방법이 있으나, 이에 제한되는 것은 아니다. 예를 들면, 전자장치 또는 서버는 복수의 스타일에 각기 대응하는 복수의 모델의 DB(141, 142)을 저장한다. 스타일에 대응하는 모델 은 CNN 모델에 따른다. 기 설정된 조건에 의하여 하나 이상의 스타일이 선택되면, 선택된 스타일에 대응하는 모 델이 DB(141, 142)로부터 식별되며, 식별된 모델에 의해 입력 이미지의 스타일이 변경된다. 상기한 조건에 관해서는 후술한다. 스타일에 대응하는 모델의 DB(141, 142)의 저장 위치에 따라서, 전자장치가 입력 이미지의 스타일을 변환하는 예와, 서버가 입력 이미지의 스타일을 변환하는 예가 있으나, 이에 한정되지 않으며 다른 외부장치를 이용하는 예도 가능하다. 한 가지 예시에 따르면, 전자장치는 입력 이미지를 획득하면, DB로부터 소정 조건에 따른 스타 일에 대응하는 모델을 식별하고, 식별된 모델에 의해 입력 이미지를 출력 이미지로 변환한다. 전자장 치는 변환된 출력 이미지를 저장하거나 표시함으로써 사용자에게 제공한다. 다른 한 가지 예시에 따르면, 전자장치는 입력 이미지를 획득하면, 획득한 입력 이미지를 네트 워크를 통해 서버에 전송한다. 서버는 DB로부터 소정 조건에 따른 스타일에 대응하는 모델을 식별하고, 식별된 모델에 의해 입력 이미지를 출력 이미지로 변환하고, 출력 이미지를 전자장치 에 전송한다. 전자장치는 수신된 출력 이미지를 사용자에게 제공한다. 이하 실시예에서는 전자 장치가 입력 이미지의 스타일을 변환하는 경우를 기반으로 설명하며, 서버에 관한 경우는 전자 장치에 관한 경우를 응용할 수 있으므로 자세한 설명을 생략한다. 이하, 전자장치의 구성에 관해 설명한다. 도 2는 전자장치의 구성 블록도이다. 도 2에 도시된 바와 같이, 전자장치은 통신부와, 신호입출력부와, 디스플레이부와, 사용자 입력부와, 저장부와, 프로세서를 포함한다. 서버는 서버통신부와, 서버저장부와, 서버프로세서를 포함한다. 이하, 전자장치의 구성에 관해 설명한다. 본 실시예서는 전자장치가 디스플레이장치인 경우에 관해 설명하지만, 전자장치는 다양한 종류의 장치로 구현될 수 있으므로, 본 실시예가 전자장치의 구성을 한정하는 것은 아니다. 전자장치가 디스플레이장치로 구현되지 않는 경우도 가능하며, 이 경우의 전자장치는 디스플레이부와 같은 영상 표시를 위한 구성요소들을 포함하지 않을 수 있다. 통신부는 다양한 종류의 유선 및 무선 통신 프로토콜에 대응하는 통신모듈, 통신칩 등의 구성요소들 중 적 어도 하나 이상을 포함하는 양방향 통신회로이다. 예를 들면, 통신부는 와이파이 방식에 따라서 AP와 무선 통신을 수행하는 무선통신모듈이나, 라우터 또는 게이트웨이에 유선 접속된 랜카드로 구현될 수 있다. 예를 들 면, 통신부는 네트워크 상의 서버와 통신함으로써, 서버와의 사이에 데이터 패킷을 송수신할 수 있다. 신호입출력부는 셋탑박스 또는 광학미디어 재생장치와 같은 외부장치와 일대일 또는 일대다 방식으로 유선 접속됨으로써, 해당 외부장치에 대해 데이터를 수신하거나 또는 데이터를 출력한다. 신호입출력부는 예를 들면, HDMI 포트, DisplayPort, USB 포트 등과 같이, 기 설정된 전송규격에 따른 커넥터 또는 포트 등을 포함한 다. 디스플레이부는 화면 상에 영상을 표시할 수 있는 디스플레이 패널을 포함한다. 디스플레이 패널은 액정 방식과 같은 수광 구조 또는 OLED 방식과 같은 자발광 구조로 마련된다. 디스플레이부는 디스플레이 패널 의 구조에 따라서 부가적인 구성을 추가로 포함할 수 있는데, 예를 들면 디스플레이 패널이 액정 방식이라면, 디스플레이부는 액정 디스플레이 패널과, 광을 공급하는 백라이트유닛과, 액정 디스플레이 패널의 액정을 구동시키는 패널구동기판을 포함한다. 사용자입력부는 사용자의 입력을 수행하기 위해 사용자가 조작할 수 있도록 마련된 다양한 종류의 입력 인 터페이스 관련 회로를 포함한다. 사용자입력부는 전자장치의 종류에 따라서 여러 가지 형태의 구성이 가능하며, 예를 들면 전자장치의 기계적 또는 전자적 버튼부, 전자장치과 분리된 리모트 컨트롤러, 터치패드, 디스플레이부에 설치된 터치스크린 등이 있다. 저장부는 프로세서에 의해 억세스되며, 프로세서의 제어에 따라서 데이터의 독취, 기록, 수정, 삭제, 갱신 등의 동작이 수행된다. 저장부는 전원의 제공 유무와 무관하게 데이터를 저장할 수 있는 플래 시메모리(flash-memory), HDD(hard-disc drive), SSD(solid-state drive) ROM(Read Only Memory) 등과 같은 비휘발성 메모리와, 처리를 위한 데이터가 로딩되는 버퍼(buffer), 램(RAM; Random Access Memory) 등과 같은 휘발성 메모리를 포함한다. 저장부는 운영체제와, 운영체제 상에서 실행되도록 마련된 다양한 어플리케이 션과, 이미지의 스타일 변환을 위한 모델을 저장한다. 프로세서는 인쇄회로기판 상에 장착되는 CPU, 칩셋, 버퍼, 회로 등으로 구현되는 하나 이상의 하드웨어 프 로세서를 포함하며, 설계 방식에 따라서는 SOC(system on chip)로 구현될 수도 있다. 프로세서는 전자장치 이 디스플레이장치로 구현되는 경우에 디멀티플렉서, 디코더, 스케일러, 오디오 DSP, 앰프 등의 다양한 프 로세스에 대응하는 모듈들을 포함한다. 여기서, 이러한 모듈들 중 일부 또는 전체가 SOC로 구현될 수 있다. 예 를 들면, 디멀티플렉서, 디코더, 스케일러 등 영상처리와 관련된 모듈이 영상처리 SOC로 구현되고, 오디오 DSP 는 SOC와 별도의 칩셋으로 구현되는 것이 가능하다. 프로세서는 통신부, 신호입출력부, 저장부 등으로부터 입력 이미지를 획득하면, 저장부 에 저장되거나 또는 서버에 마련된 모델에 기초하여 해당 입력 이미지의 스타일 전환 프로세스를 수 행한다. 스타일 전환 프로세스에 관한 자세한 설명은 후술한다. 이하, 서버의 구성에 관해 설명한다. 서버통신부는 다양한 종류의 유선 및 무선 통신 프로토콜에 대응하는 통신모듈, 통신칩 등의 구성요소들 중 적어도 하나 이상을 포함하는 양방향 통신회로이다. 서버통신부는 광역 네트워크에 접속됨으로써 전자 장치을 비롯한 다양한 종류의 클라이언트와 네트워크를 통해 통신할 수 있다. 서버저장부는 서버프로세서에 의해 데이터의 독취, 기록, 수정, 삭제, 갱신 등의 동작이 수행된다. 서버저장부는 플래시메모리, HDD, SSD, 버퍼, 램 등의 다양한 비휘발성 메모리 및 휘발성 메모리를 포함한 다. 만일 서버가 이미지의 스타일 변환을 수행하도록 마련된 경우에, 서버저장부는 스타일 변환을 위 한 모델을 저장할 수 있다. 서버프로세서는 인쇄회로기판 상에 장착되는 CPU, 칩셋, 버퍼, 회로 등으로 구현되는 하나 이상의 하드웨 어 프로세서를 포함하며, 설계 방식에 따라서는 SOC로 구현될 수도 있다. 서버프로세서는 전자장치로 부터 수신되는 정보에 기반하여 다양한 처리를 수행할 수 있다. 예를 들면, 서버가 이미지의 스타일 변환 을 수행하도록 마련된 경우에 서버통신부를 통해 전자장치로부터 입력 이미지가 수신되면, 서버프로세서는 서버저장부에 저장된 모델에 기반하여 입력 이미지의 스타일 변환 프로세스를 수행한다. 이하, 전자장치가 수행하는 스타일 변환 프로세스에 관해 설명한다. 도 3은 전자장치가 수행하는 스타일 변환 방법을 나타내는 플로우차트이다. 도 3에 도시된 바와 같이, 다음의 동작은 전자장치의 프로세서에 의해 실행된다. 310 단계에서 전자장치는 전자장치의 사용 환경에 관한 정보를 획득한다. 전자장치의 사용 환경은 여러 가지 항 목을 포함할 수 있는데, 예를 들면 현재 시간, 전자장치의 사용 지역, 전자장치의 사용 이력, 전자장치의 기기 정보 등이 있다. 즉, 본 실시예에서의 사용 환경은 단순히 전자장치의 주변 환경에 한정되는 좁은 의미가 아니 다. 본 실시예에서의 사용 환경은, 전자장치 자체적인 장치 속성 등의 내재적 환경과, 전자장치가 사용되는 일 시, 시즌, 장소, 지역, 통신환경 등 전반적인 외부적 환경에 관한, 보다 넓은 의미이다. 320 단계에서 전자장치는 제1이미지를 식별한다. 제1이미지는 사용자 입력에 따라서 식별될 수 있다. 제1이미지 는 전자장치에 기 저장된 복수의 이미지 중에서 사용자 입력에 따라서 선택되거나, 외부장치로부터 수신될 수 있다. 전자장치에서 이미지 전환 프로세스에 관한 앱이 실행중인 경우에, 해당 앱을 통해 제1이미지가 식별될 수 있다. 330 단계에서 전자장치는 제1이미지에 적용 가능하게 마련된 복수의 스타일 중에서, 획득한 사용 환경 정보에 기초하여 적어도 하나의 스타일을 식별한다. 340 단계에서 전자장치는 식별된 스타일에 관한 정보에 기초하여 제1이미지를 제2이미지로 변환한다. 여기서, 변환 방법이 딥 러닝에 따른 스타일 변환 방법일 경우, 식별된 스타일에 관한 정보는 예를 들면 해당 스타일에 대응하는 CNN 모델일 수 있다. 350 단계에서 전자장치는 제2이미지를 표시함으로써, 제2이미지를 사용자에게 제공한다. 이와 같이, 전자장치는 제1영상의 스타일을 변경하여 제2영상을 생성함에 있어서, 전자장치의 사용 환경에 맞는 스타일을 자동으로 선택한다. 이로써, 전자장치는 사용자가 스타일을 선택하는 입력 동작 없이, 최적화된 스타 일의 제2영상을 사용자에게 제공할 수 있다. 이하, 전자장치가 입력 이미지의 스타일을 변경하는 구체적인 방법에 관해 설명한다. 도 4는 전자장치가 수행하는 스타일 변환 프로세스의 개략적인 과정을 나타내는 예시도이다. 도 4에 도시된 바와 같이, 전자장치는 입력 이미지가 식별되면, 현재 시점에 대응하는 컨텍스트(context) 정보를 분석 및 필터링하는 컨텍스트 분석을 수행한다. 전자장치는 컨텍스트 분석에 따라서 입력 이 미지에 대응하는 컨텍스트 정보가 획득되면, 획득된 컨텍스트 정보에 대응하여 모델의 선택 및 적용 을 수행한다. 전자장치는 모델의 선택 및 적용에 의해, 최종적으로 출력 이미지를 획득한다. 컨텍스 트 분석은 앞선 도 3의 330 단계에 해당하며, 모델의 선택 및 적용 중에서 스타일의 식별은 도 3의 330 단계에 해당하고 모델의 식별 및 적용은 도 3의 340 단계에 해당한다. 최초 획득한 컨텍스트 정보는 기본적으로 현재 시점에서 전자장치의 사용 환경에 관련된 다양한 정보를 나타낸 다. 그러나, 최초 획득한 컨텍스트 정보는 스타일 변환 프로세스와 관련된 정보 뿐만 아니라 무관한 정보도 포 함할 수 있다. 또한, 스타일 변환 프로세스와 관련된 컨텍스트 정보라고 하더라도, 해당 정보가 스타일 변환 프 로세스에서 사용될 수 있는 형식을 갖추지 못할 수도 있다. 이러한 관점에서, 전자장치는 최초 획득한 컨텍스트 정보로부터 불필요한 정보를 제외하는 한편 필요한 정보를 정규화시키는 작업을 컨텍스트 분석에서 수행한 다. 이러한 작업에서는 사전에 마련된 컨텍스트 테이블이 활용된다. 전자장치는 입력 이미지의 획득에 응답하여 기 저장된 컨텍스트 테이블을 호출한다. 컨텍스트 테이블 은 전자장치의 사용 환경에 관련된 복수의 속성 항목과, 각 속성 별로 복수의 속성값을 정의한다. 컨텍스 트 테이블은 예를 들어 룩업 테이블 형태로 마련된다. 컨텍스트 테이블은 전자장치가 제조 단계에서 획득하거나, 서버로부터 수신 및 업데이트될 수 있다. 컨텍스트 분석에서, 전자장치는 현재 시점에 대응하는 다양한 제1컨텍스트 정보를 획득하고, 컨텍스트 테 이블을 사용하여 제1컨텍스트 정보를 입력 이미지에 대응하는 제2컨텍스트 정보로 변환한다. 컨텍스 트 테이블의 구현 형태 및 사용 방법의 예시에 관해서는 후술한다. 전자장치는 제2컨텍스트 정보를 획득하면, 스타일 및 모델 DB를 사용하여 제2컨텍스트 정보에 대응하는 스 타일 및 모델을 식별한다. 스타일 및 모델 DB는, 복수의 컨텍스트 정보에 각기 대응하는 스타일과, 해당 스타일을 구현하기 위한 모델의 데이터가 저장된다. 스타일 및 모델 DB의 예시에 관해서는 후술한다. 전자장치는 식별된 스타일에 대응하는 모델을 사용하여, 입력 이미지의 스타일을 변경시킴으로써 출력 이 미지를 생성한다. 한편, 본 실시예에서는 전자장치에 의해 모든 프로세스가 진행되는 경우에 관해 설명하였으나, 일부 프로세스가 서버에 의해 진행되는 경우도 가능하다. 예를 들면, 서버는 컨텍스트 테이블 및 스타일 및 모델 DB을 저장하고, 컨텍스트 분석 및 모델 의 선택 및 적용을 수행하도록 마련된다. 이 경우에, 전자장치는 입력 이미지가 식별되면 입력 이미 지를 서버에 전송한다. 서버는 앞선 실시예에서 설명한 바와 같이 컨텍스트 분석 및 모델의 선택 및 적용을 수행하여 입력 이미지를 출력 이미지로 변환하고, 출력 이미지를 전자장치에 전송 한다. 이로써, 전자장치는 출력 이미지를 획득한다. 또는, 서버는 컨텍스트 분석 및 모델의 선택 및 적용 중 어느 하나의 프로세스만을 수행하도록 마련 될 수도 있다. 전자장치는 프로세스 진행 중의 결과물을 필요 시에 서버에 전송하고, 서버에서 수행된 프로세스 의 결과물을 서버로부터 수신한다. 이하, 컨텍스트 테이블의 예시에 관해 설명한다. 도 5는 전자장치가 참조하는 컨텍스트 테이블의 예시도이다. 도 5에 도시된 바와 같이, 전자장치는 제1컨텍스트 정보가 획득되면, 컨텍스트 테이블을 사용하여 제 1컨텍스트 정보로부터 제2컨텍스트 정보를 획득하는 컨텍스트 분석을 수행한다. 전자장치는 기기 자체적으로 마련된 구성요소들로부터, 또는 서버나 타 외부장치로부터 제1컨텍스트 정보 를 획득할 수 있다. 제1컨텍스트 정보는 여러 가지 카테고리의 정보를 포함할 수 있다. 이러한 카테고리의 예시로는, 시간, 날짜, 계절 등의 시간 속성이 있고, 전자장치의 설치 위치나 장소, 설치 지역, 설치 국가 등의 장소 속성이 있고, 전자장치의 사용자 계정, 사용 이력 등의 사용자 속성이 있고, 현재 날씨, 주변 밝기 등의 주변 환경 속성 등이 있다. 예를 들면, 전자장치는 네트워크에 통신 접속하기 위한 IP 어드레스 등의 네트워크 정보에 기초하여 전자장치의 설치 지역 또는 설치 국가를 식별할 수 있다. 전자장치는 서버로부터 취득한 시간 정보 또는 자체적으로 구비한 시계로부터 현재 일시, 년, 계절 등을 식별할 수 있다. 전자장치는 IoT 기기로부터 현재 온도를 식별할 수 있다. 전자장치는 밝기 센서로부터 주변 밝기를 식별할 수 있다. 전자장치는 날씨 관리 서버로부터 현재 날씨를 식별할 수 있다. 이상의 예시는 극히 일부에 불과한 것으로서, 제1컨텍스트 정보는 전자장치의 사용 환경 에 관련된 한정되지 않은 다양한 정보를 포함한다. 컨텍스트 테이블은 복수의 속성 항목과, 각 속성 항목의 속성값을 테이블 형식으로 정의한다. 본 실시예의 컨텍스트 테이블은 실제로 구현되는 경우에 비해 극히 일부의 데이터만을 나타내고 있으며, 이는 실시예를 간결하게 나타내기 위함이다. 예를 들면 컨텍스트 테이블은 시간, 계절, 기기 위치, 날씨 등의 항목들을 포함한다. \"시간\"의 속성은 새벽, 아침, 오후, 저녁, 밤 등의 속성값을 가진다. \"계절\"의 속성은 봄, 여름, 가 을, 겨울 등의 속성값을 가진다. 이러한 식으로, 각 속성은 복수의 속성값을 가진다. 전자장치는 제1컨텍스트 정보로부터 컨텍스트 테이블의 각 속성에 해당하는 정보가 있는지 분석하고, 분석 결과에 따라서 각 속성 항목의 속성값을 식별한다. 예를 들면, 제1컨텍스트 정보는 전자장치와 통신 하는 IoT 기기 중 전자시계로부터 획득한 현재 시간이 밤이고, 서버로부터 획득한 현재 계절 정보가 겨울이고, 전자장치와 통신하는 IoT 기기 중 CCTV로부터 획득한 기기 위치가 실내이고, 서버로부터 획득한 날씨 정보가 눈 을 나타낼 수 있다. 전자장치는 식별된 각 속성 항목의 속성값들에 의해 제2컨텍스트 정보를 생성한다. 예를 들면, 전자장치는 제1컨텍스트 정보에 기초하여, \"시간:밤, 계절:겨울, 기기 위치:실내, 날씨:눈\"이라는 내용의 제2컨텍스트 정보를 획득할 수 있다. 제2컨텍스트 정보의 이러한 형식은 한 가지 예시에 불과하므로, 본 실시예에 서 나타낸 형식이 제2컨텍스트 정보의 구현 방식을 한정하는 것은 아니다. 이하, 전자장치가 제2컨텍스트 정보에 대응하는 스타일 및 모델을 선택하는 예시에 관해 설명한다. 도 6은 전자장치가 참조하는 스타일 및 모델 DB의 예시도이다. 도 6에 도시된 바와 같이, 스타일 및 모델 DB는 복수의 컨텍스트 정보에 각기 대응하는 복수의 스타일과, 각 스타일에 대응하는 모델 데이터를 저장한다. 스타일 및 모델 DB는 각 스타일에 대응하는 추가 이펙트 데이터를 추가적으로 저장할 수 있다. 스타일에 대응하는 추가 이펙트 데이터가 반드시 있어야 하는 것은 아니 며, 스타일에 따라서는 추가 이펙트 데이터를 가지지 않는 경우도 있다. 전자장치는 스타일 및 모델 DB로부터 제2컨텍스트 정보에 대응하는 스타일을 식별하고, 식별된 스타 일에 대응하는 모델 데이터 및 추가 이펙트 데이터를 획득한다. 전자장치는 획득한 모델 데이터, 또는 획득한 모델 데이터 및 추가 이펙트 데이터를 사용하여, 입력 이미지를 출력 이미지로 변환시킨다. 모델 데이터는 학습을 통해 사전에 생성된 인공지능 모델로서, 컨텍스트 정보에 최적화되도록 설계된다. 예를 들어 스타일 2에 대응하는 컨텍스트 정보가 \"시간:밤, 계절:겨울, 기기 위치:실외, 날씨:눈\"인 경우를 고려한다. 위치가 실외이고 시간이 밤인 소정 장소는, 태양빛이 없으므로 인공 광원을 제외하고는 하늘을 포함 하여 전체적으로 어두컴컴한 색감을 나타내며, 인공 광원은 상대적으로 밝은 반면에 그 주위는 급격하게 어두워 지므로 인공 광원 주위의 콘트라스트가 강조될 것이다. 모델 2는, 소정의 이미지가 상기한 느낌으로 표현되도록 설계된다. 추가 이펙트 데이터는 모델 데이터와 별도로 이미지 상에 다양한 시각적 이펙트를 반영한다. 예를 들어 계절이 겨울이고 날씨가 눈인 장소는, 전체적으로 눈발이 날리는 모습이 나타날 것이다. 스타일 2에 대응하는 이펙트 2 는, 모델 데이터가 반영되는 이미지 전체, 또는 이미지 내 일부 오브젝트에 눈발이 흩날리는 이펙트를 부여한다. 다른 예시로서 스타일 4에 대응하는 컨텍스트 정보는 \"시간:낮, 계절:가을, 기기 위치:실외, 날씨:맑음\"이다. 장소가 실외에 낮이고 맑은 날씨이면, 해당 장소는 태양광으로 인해 높은 광량과 전체적으로 밝은 분위기를 나 타낼 것이다. 또한, 계절이 가을이고 장소가 실외라면, 해당 장소에서 하늘은 두드러진 파란색을 나타낼 것이다. 모델 4는 소정의 이미지가 이러한 느낌으로 표현되도록 설계된다. 스타일에 대응하는 모델의 설계 및 구현 방식은 인공지능에 의한 학습 모델에 관한 기술에 의해 제안된다. 모델 데이터는 예를 들면 딥러닝 기반의 CNN 모델로 구현될 수 있다. 예를 들어 Fully Connected Layer만으로 구성된 인공 신경망의 입력데이터는 1차원 형태로 한정된다. 한 장의 컬러 사진은 3차원 데이터이다. 사진 데이터로 FCNN(Fully Connected Neural Network)를 학습시켜야 할 경우에, 3차원 사진 데이터는 1차원으로 평면화되어야 한다. 사진 데이터를 평면화시키는 과정에서 공간 정보가 손실될 수 밖에 없으므로, 결과적으로 이미지 공간 정 보 유실로 인한 정보 부족으로 인해, 인공 신경망이 특징을 추출하고 학습함에 있어서 비효율적이며, 정확도를 높이는 데에 한계가 있다. CNN은 이미지의 공간 정보를 유지한 상태로 학습이 가능한 모델이다. CNN은 FCNN에 비해, 각 레이어의 입출력 데이터의 형상 유지, 이미지의 공간 정보를 유지하면서 인접 이미지와 의 특징을 효과적으로 인식, 복수의 필터로 이미지의 특징 추출 및 학습, 추출한 이미지의 특징을 모으고 강화 하는 풀링(Pooling) 레이어, 필터를 공유 패러미터로 사용하므로 상대적으로 학습할 패러미터가 적음 등의 특징 을 가진다. CNN은 이미지의 특징을 추출하는 부분과 클래스를 분류하는 부분으로 나눌 수 있다. 특징 추출 영역은 Convolution Layer와 Pooling Layer를 여러 겹 쌓는 형태로 구성된다. Convolution Layer는 입력 데이터에 필 터를 적용 후 활성화 함수를 반영하는 필수요소이다. Convolution Layer 다음에 위치하는 Pooling Layer는 선택 적인 레이어이다. CNN 마지막 부분에는 이미지 분류를 위한 Fully Connected 레이어가 추가된다. 이미지의 특징 을 추출하는 부분과 이미지를 분류하는 부분 사이에 이미지 형태의 데이터를 배열 형태로 만드는 Flatten 레이 어가 위치한다. CNN은 이미지 특징 추출을 위하여 입력 데이터를 필터가 순회하며 합성곱(convolution)을 계산하고, 그 계산 결 과를 이용하여 Feature map을 만든다. Convolution Layer는 Filter 크기, Stride, Padding 적용 여부, Max Pooling 크기에 따라서 출력 데이터의 Shape이 변경된다. 스타일 변환 프로세스는, 상기와 같은 원리에 따라서 마련된 모델에 의해 입력 이미지를 변환시킴으로써, 입력 이미지가 원래 가지고 있던 스타일 대신에, 해당 모델의 스타일이 입력 이미지에 새로 반영되도록 변형시키는 과정이다. 이와 같이, 본 실시예에 따른 전자장치는 스타일 및 모델 DB를 사용하여 입력 이미지에 대응하는 모 델을 자동으로 선택하고, 선택한 모델에 의해 출력 이미지를 생성할 수 있다.한편, 앞선 실시예에서는 전자장치가 전자장치의 사용 환경에 관한 컨텍스트 정보에 대응하는 모델을 사용하는 경우에 관해 설명하였다. 그러나, 전자장치가 사용할 모델을 선택하는 기준은 전자장치의 사용 환경만으로 한정 되는 것은 아니다. 이하, 전자장치가 전자장치의 사용 환경 및 입력 이미지의 속성을 함께 고려하여 출력 이미 지를 생성하는 실시예에 관해 설명한다. 도 7은 전자장치가 입력 이미지의 속성 및 전자장치의 사용 환경을 함께 고려하는 스타일 변환 프로세스의 개략 적인 과정을 나타내는 예시도이다. 도 7에 도시된 바와 같이, 전자장치는 입력 이미지가 식별되면, 입력 이미지의 속성에 대응하는 이미 지 정보를 분석하는 이미지 분석과, 현재 시점에 대응하는 컨텍스트(context) 정보를 분석 및 필터링하는 컨텍스트 분석을 함께 수행한다. 전자장치는 모델의 선택 및 적용에 의해, 최종적으로 출력 이미지 를 획득한다. 이미지 정보 및 컨텍스트 정보가 구분되어 있는 경우에, 이미지 정보는 입력 이미지에 관련된 정보를 포함하며, 컨텍스트 정보는 입력 이미지를 제외한 사용 환경에 관한 정보를 포함한다. 이미지 분석 및 컨텍스트 분석, 그리고 모델 선택 및 적용 중에서 스타일 식별 단계까지는 앞선 도 3의 330 단계에 해당한다. 모델 선택 및 적용 중에서 모델의 식별 및 적용 단계는 도 3의 340 단계에 해당한다. 컨텍스트 분석은 앞선 실시예와 실질적으로 동일한 원리에 따른다. 즉, 본 실시예에서 전자장치가 컨텍스 트 테이블을 사용하여 컨텍스트 분석을 수행하는 방법은 앞선 실시예와 실질적으로 동일하므로, 자세 한 설명을 생략한다. 본 실시예가 앞선 실시예와 상이한 점은 다음과 같다. 본 실시예에 따른 전자장치는 이미지정보 테이블을 사용하여 이미지 분석을 추가적으로 수행한다. 이미지정보 테이블은 복수의 이미지 속성에 관련된 항목과, 각 항목의 복수의 속성값을 정의한다. 이미지정보 테이블은 예를 들면 룩업테이블로 마련된다. 이 미지정보 테이블은 전자장치가 제조 단계에서 획득하거나, 서버로부터 수신 및 업데이트될 수 있다. 이미 지정보 테이블의 예시에 관해서는 후술한다. 전자장치는 이미지 분석에서 입력 이미지를 형성하는 컨텐트를 분석한다. 전자장치는 이미지정보 테 이블을 사용하여 입력 이미지의 컨텐트 속성을 나타내는 이미지 정보를 획득한다. 한편 앞선 실시예에서와 달리, 본 실시예에 따른 스타일 및 모델 DB는 컨텍스트 정보에 대응하는 스타일 및 모델과, 이미지 정보에 대응하는 스타일 및 모델을 함께 포함한다. 즉, 전자장치는 모델의 선택 및 적용 에서, 스타일 및 모델 DB로부터 이미지 정보에 대응하는 제1스타일 및 컨텍스트 정보에 대응하는 제2 스타일을 각기 식별할 수 있다. 전자장치는 스타일 및 모델 DB로부터 제1스타일에 대응하는 제1모델 및 제 2스타일에 대응하는 제2모델을 획득한다. 전자장치는 입력 이미지에 획득한 제1모델 및 제2모델을 함께 적용함으로써 출력 이미지를 생성한다. 여기서, 제1모델 및 제2모델을 입력 이미지에 적용하는 순서는 한정되지 않는다. 예를 들어, 전자장치는 제1모델에 기초하여 입력 이미지를 변환시킨다. 변환된 입력 이미지는 제1모델에 의한 제1스타일이 반영된 상태이다. 이후, 전자장치는 제1스타일이 반영된 입력 이미지를 다시 제2모델에 기초하여 변환시키 고, 제2모델에 의한 제2스타일이 추가로 반영되도록 한다. 이로써, 입력 이미지는 최종적으로 제1스타일 및 제2스타일이 함께 반영된 출력 이미지로 변환된다. 반드시 제1모델이 제2모델보다 선행하여 적용되어야 하는 것은 아니며, 제2모델이 제1모델보다 선행하여 적용되는 경우도 가능하다. 한편, 본 실시예에서는 전자장치에 의해 모든 프로세스가 진행되는 경우에 관해 설명하였으나, 일부 프로세스가 서버에 의해 진행되는 경우도 가능하다. 예를 들면, 서버는 이미지정보 테이블, 컨텍스트 테이블 및 스타일 및 모델 DB을 저장하고, 이 미지 분석, 컨텍스트 분석 및 모델의 선택 및 적용을 수행하도록 마련된다. 이 경우에, 전자장 치는 입력 이미지가 식별되면 입력 이미지를 서버에 전송한다. 서버는 앞선 실시예에서 설명한 바와 같이 이미지 분석, 컨텍스트 분석 및 모델의 선택 및 적용을 수행하여 입력 이미지를 출력 이미지로 변환하고, 출력 이미지를 전자장치에 전송한다. 이로써, 전자장치는 출력 이미지를 획 득한다. 또는, 서버는 이미지 분석, 컨텍스트 분석 및 모델의 선택 및 적용 중 일부 프로세스만을 수행 하도록 마련될 수도 있다. 전자장치는 프로세스 진행 중의 결과물을 필요 시에 서버에 전송하고, 서버에서 수행된 프로세스의 결과물을 서버로부터 수신한다. 이하, 이미지정보 테이블의 예시에 관해 설명한다. 도 8은 전자장치가 참조하는 이미지정보 테이블의 예시도이다. 도 8에 도시된 바와 같이, 전자장치는 입력 이미지가 획득되면, 이미지정보 테이블을 사용하여 입력 이미지를 분석함으로써 입력 이미지에 관한 이미지 정보를 획득하기 위한 이미지 분석을 수행한 다. 이미지정보 테이블은 복수의 속성 항목과, 각 속성 항목의 속성값을 테이블 형식으로 정의한다. 본 실시예 의 이미지정보 테이블은 실제로 구현되는 경우에 비해 극히 일부의 데이터만을 나타내고 있으며, 이는 실 시예를 간결하게 나타내기 위함이다. 예를 들면 이미지정보 테이블은 이미지의 전반적인 배경을 나타내는 장면, 이미지 내의 배경 또는 전경을 형성하는 오브젝트, 오브젝트의 상대적 거리를 나타내는 뎁스, 사람 또는 동물인 오브젝트의 감정 상태를 나타내는 이모션 등의 항목들을 포함한다. \"장면\"의 속성은, 거실, 오피스, 거 리, 침실, 숲 등의 속성값을 가진다. \"오브젝트\"의 속성은, 사람, 동물, 산, 빌딩 등의 속성값을 가진다. 이러 한 방식으로 각 속성 항목은 복수의 속성값을 가진다. 전자장치는 이미지정보 테이블에 정의된 속성 항목들이 입력 이미지에서 어떻게 나타나는지 분석하고, 각 속성 항목들에 관한 입력 이미지의 속성값을 식별함으로서 이미지 정보를 획득한다. 이 미지 분석은 여러 가지 방법 중 하나 이상이 적용될 수 있다. 예를 들면, AI의 딥 러닝에 기반한 신경망 모델이 적용되거나, 이미지 전체의 스캐닝을 통한 오브젝트의 식별 방법이 적용되거나, 이미지가 가진 메타데이터의 참 조 방법이 적용될 수 있다. 이 외에도, 다양한 방법의 이미지 분석이 가능하다. 전자장치는 입력 이미지를 분석함으로써 입력 이미지의 컨텐트를 이루는 여러 구성요소들, 즉 이미지 정보 테이블에 정의되는 항목들을 식별한다. 전자장치는 식별된 항목들에 마련된 복수의 속성값 중에서 입 력 이미지가 나타내는 속성값을 식별하고, 이들을 종합하여 이미지 정보를 생성한다. 예를 들어 입력 이미지가 숲에서 사람과 동물이 함께 놀고 있고, 사람은 상대적으로 멀리 있으며 동물은 상대적으로 가까이 있고, 사람 및 동물 모두 즐거워하는 모습을 나타낸다고 가정한다. 전자장치는 이미지정보 테이블의 정의에 기초하여, \"장면:숲, 오브젝트:사람, 오브젝트:동물, 뎁스:사람-원거리, 뎁스:동물-근거 리, 이모션:사람-즐거움, 이모션:동물-즐거움\"과 같은 내용의 입력 이미지에 대응하는 이미지 정보를 생성할 수 있다. 이미지 정보의 이러한 형식은 한 가지 예시에 불과하므로, 본 실시예에서 나타낸 형식이 이미지 정보의 구현 방식을 한정하는 것은 아니다. 이하, 전자장치가 입력 이미지의 속성을 고려하여 출력 이미지를 생성하는 실시예에 관해 설명한다. 도 9는 전자장치가 입력 이미지의 속성을 고려한 스타일 변환 프로세스의 개략적인 과정을 나타내는 예시도이다. 도 9에 도시된 바와 같이, 전자장치는 입력 이미지가 식별되면, 입력 이미지의 속성에 대응하는 이미 지 정보를 분석하는 이미지 분석을 수행한다. 전자장치는 이미지 분석에 따라서 입력 이미지에 대응하는 이미지 정보가 획득되면, 획득된 이미지 정보에 대응하여 모델의 선택 및 적용을 수행한다. 전자 장치는 모델의 선택 및 적용에 의해, 최종적으로 출력 이미지를 획득한다. 전자장치는 이미지정보 테이블을 사용하여 이미지 정보를 획득한다. 이미지정보 테이블은 복수의 이 미지 속성에 관련된 항목과, 각 항목의 복수의 속성값을 정의한다. 이미지정보 테이블은 앞선 실시예에서 설명한 내용과 실질적으로 동일하므로, 자세한 설명을 생략한다. 전자장치는 이미지 분석에서 입력 이미지 를 형성하는 컨텐트를 분석한다. 전자장치는 이미지정보 테이블을 사용하여 입력 이미지의 컨텐 트 속성을 나타내는 이미지 정보를 획득한다. 본 실시예에 따른 스타일 및 모델 DB는 이미지 정보에 대응하는 스타일 및 모델을 포함한다. 전자장치는 모델의 선택 및 적용에서, 스타일 및 모델 DB로부터 이미지 정보에 대응하는 스타일과, 본 스타일에 대응하는 모델을 획득한다. 전자장치는 식별된 스타일에 대응하는 모델을 사용하여, 입력 이미지의 스타일을 변경시킴으로써 출력 이 미지를 생성한다. 본 실시예의 경우도 앞선 실시예들과 마찬가지로, 전자장치가 모든 프로세스를 수행할 수도 있고, 서버가 일부 프로세스를 분담하여 수행할 수도 있다. 이하, 전자장치가 이미지 정보에 대응하는 스타일 및 모델을 선택하는 예시에 관해 설명한다. 도 10은 전자장치가 참조하는 스타일 및 모델 DB의 예시도이다. 도 10에 도시된 바와 같이, 스타일 및 모델 DB는 복수의 이미지 정보에 각기 대응하는 복수의 스타일과, 각 스타일에 대응하는 모델 데이터를 저장한다. 스타일 및 모델 DB는 각 스타일에 대응하는 추가 이펙트 데이터를 추가적으로 저장할 수 있다. 스타일에 대응하는 추가 이펙트 데이터가 반드시 있어야 하는 것은 아니 며, 스타일에 따라서는 추가 이펙트 데이터를 가지지 않는 경우도 있다. 전자장치는 스타일 및 모델 DB로부터 이미지 정보에 대응하는 스타일을 식별하고, 식별된 스타일에 대응하는 모델 데이터 및 추가 이펙트 데이터를 획득한다. 전자장치는 획득한 모델 데이터, 또는 획득한 모델 데이터 및 추가 이펙트 데이터를 사용하여, 입력 이미지를 출력 이미지로 변환시킨다. 모델 데이터는 학습을 통해 사전에 생성된 인공지능 모델로서, 이미지 정보에 최적화되도록 설계된다. 예를 들 어 스타일 A에 대응하는 이미지 정보가 \"장면:숲, 오브젝트:사람, 뎁스:원거리, 이모션:즐거움\"이고, 스타일 B 에 대응하는 이미지 정보가 \"장면:실내, 오브젝트:사람, 뎁스:근거리, 이모션:화남\"인 경우를 고려한다. 숲인 장소는 실내인 장소에 비해 인공적인 색감보다 자연의 색감이 보다 강조된다. 예를 들어 여름인 경우에, 숲인 장소는 푸른색 계열이 두드러지게 나타날 것이다. 동일한 장소에서 사람에 포커스를 맞추고자 한다면, 사람이 근거리에 있는 경우는 사람이 원거리에 있는 경우에 비해 밝은 색감을 강조해야 할 수도 있다. 동일한 장소의 동일한 거리에 있는 인물이라고 해도, 즐거움을 나타내기 위해서는 해당 인물에 상대적으로 밝은 색감이 부여되 고, 화남을 나타내기 위해서는 해당 인물에 상대적으로 어두운 색감이 부여될 수도 있다. 각 모델은 이러한 점 을 고려하여 설계된다. 스타일에 대응하는 모델의 설계 및 구현 방식은 인공지능 기반의 학습 모델에 관한 기술에서 제안되므로 자세한 설명을 생략한다. 이와 같이, 본 실시예에 따른 전자장치는 스타일 및 모델 DB를 사용하여 입력 이미지에 대응하는 모델을 자동으로 선택하고, 선택한 모델에 의해 출력 이미지를 생성할 수 있다. 이상 실시예들에서 설명한 바와 같은 장치의 동작은, 해당 장치에 탑재된 인공지능에 의해 수행될 수 있다. 인 공지능은 기계 학습 알고리즘을 활용하여 다양한 제반 시스템에 적용될 수 있다. 인공지능 시스템은 인간 수준 내지는 인간 수준에 버금가는 지능을 구현하는 컴퓨터 시스템으로서, 기계, 장치 또는 시스템이 자율적으로 학 습하고 판단하며, 사용 경험의 누적에 기반하여 인식률 및 판단 정확도가 향상되는 시스템이다. 인공지능 기술 은 입력되는 데이터들의 특징을 스스로 분류하고 학습하는 알고리즘을 이용한 기계학습 기술 및 알고리즘을 활 용하여, 인간의 두뇌의 인지, 판단 등의 기능을 모사하는 요소 기술들로 구성된다. 요소 기술들은, 예를 들면 인간의 언어와 문자를 인식하는 언어적 이해 기술, 사물을 인간의 시각처럼 인식하는 시각적 이해 기술, 정보를 판단하여 논리적으로 추론하고 예측하는 추론 및 예측 기술, 인간의 경험 정보를 지 식 데이터로 처리하는 지식 표현 기술, 차량의 자율 주행이나 로봇의 움직임을 제어하는 동작 제어 기술 중 적 어도 어느 하나를 포함한다. 여기서, 언어적인 이해는 인간의 언어 또는 문자를 인식하고 응용 처리하는 기술로서, 자연어의 처리, 기계 번 역, 대화 시스템, 질의 응답, 음성 인식 및 합성 등을 포함한다. 추론 예측은 정보를 판단하여 논리적으로 예측하는 기술로서, 지식 및 확률 기반 추론, 최적화 예측, 선호 기반 계획, 추천 등을 포함한다. 지식 표현은 인간의 경험 정보를 지식 데이터로 자동화 처리하는 기술로서, 데이터의 생성 및 분류와 같은 지식 구축, 데이터의 활용과 같은 지식 관리 등을 포함한다. 본 발명의 예시적 실시예에 따른 방법들은 다양한 컴퓨터 수단을 통하여 수행될 수 있는 프로그램 명령 형태로 구현되어 컴퓨터 판독 가능 매체에 기록될 수 있다. 이러한 컴퓨터 판독 가능 매체는 프로그램 명령, 데이터 파 일, 데이터 구조 등을 단독으로 또는 조합하여 포함할 수 있다. 예를 들어, 컴퓨터 판독 가능 매체는 삭제 가능 또는 재기록 가능 여부와 상관없이, USB 메모리장치와 같은 비휘발성 저장 장치, 또는 예를 들어 RAM, ROM, 플 래시메모리, 메모리 칩, 집적 회로와 같은 메모리, 또는 예를 들어 CD, DVD, 자기 디스크 또는 자기 테이프 등 과 같은 광학 또는 자기적으로 기록 가능함과 동시에 기계(예를 들어, 컴퓨터)로 읽을 수 있는 저장 매체에 저장될 수 있다. 이동 단말 내에 포함될 수 있는 메모리는 본 발명의 실시 예들을 구현하는 지시들을 포함하는 프 로그램 또는 프로그램들을 저장하기에 적합한 기계로 읽을 수 있는 저장 매체의 한 예임을 알 수 있을 것이다. 본 저장 매체에 기록되는 프로그램 명령은 본 발명을 위하여 특별히 설계되고 구성된 것들이거나 컴퓨터 소프트 웨어의 기술 분야에서 숙련된 기술자에게 공지되어 사용 가능한 것일 수도 있다. 또는, 본 컴퓨터 프로그램 명 령은 컴퓨터 프로그램 프로덕트에 의해 구현될 수도 있다."}
{"patent_id": "10-2019-0088228", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 전자장치에 입력되는 입력 이미지의 처리 서비스를 제공하는 몇 가지 예시를 나타내는 예시도이다. 도 2는 전자장치의 구성 블록도이다. 도 3은 전자장치가 수행하는 스타일 변환 방법을 나타내는 플로우차트이다. 도 4는 전자장치가 수행하는 스타일 변환 프로세스의 개략적인 과정을 나타내는 예시도이다. 도 5는 전자장치가 참조하는 컨텍스트 테이블의 예시도이다. 도 6은 전자장치가 참조하는 스타일 및 모델 DB의 예시도이다. 도 7은 전자장치가 입력 이미지의 속성 및 전자장치의 사용 환경을 함께 고려하는 스타일 변환 프로세스의 개략 적인 과정을 나타내는 예시도이다. 도 8은 전자장치가 참조하는 이미지정보 테이블의 예시도이다. 도 9는 전자장치가 입력 이미지의 속성을 고려한 스타일 변환 프로세스의 개략적인 과정을 나타내는 예시도이다. 도 10은 전자장치가 참조하는 스타일 및 모델 DB의 예시도이다."}
