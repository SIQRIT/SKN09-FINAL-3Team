{"patent_id": "10-2023-0080455", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0178516", "출원번호": "10-2023-0080455", "발명의 명칭": "주행영상의 객체 인식도 향상 방법 및 그 장치", "출원인": "포티투닷 주식회사", "발명자": "조명훈"}}
{"patent_id": "10-2023-0080455", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "주행 중에 획득된 제1영상을 수신하는 단계;상기 수신된 제1영상의 가로 및 세로 중 적어도 하나를 기준으로 상기 수신된 제1영상을 적어도 두 개의 분할영상으로 분할하는 단계;상기 분할영상별로 객체를 인식하고, 인식된 객체별로 외곽선을 생성하는 단계; 및상기 외곽선이 생성된 분할영상들을 통합하여 제2영상을 생성하는 단계;를 포함하는, 주행영상의 객체 인식도향상 방법."}
{"patent_id": "10-2023-0080455", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 분할된 분할영상들은, 상기 제1영상의 일부를 공통적으로 포함하는, 주행영상의 객체 인식도 향상 방법."}
{"patent_id": "10-2023-0080455", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 분할된 분할영상들은,상기 제1영상을 상기 분할영상들로 분할하는 분할선에 인접한 영역의 영상을 공통적으로 포함하는, 주행영상의객체 인식도 향상 방법."}
{"patent_id": "10-2023-0080455", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,상기 적어도 두 개의 분할영상으로 분할하는 단계는,상기 제1영상의 가로를 종단하는 종분할선을 기준으로, 상기 제1영상을 분할하는, 주행영상의 객체 인식도 향상방법."}
{"patent_id": "10-2023-0080455", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서,상기 적어도 두 개의 분할영상으로 분할하는 단계는,상기 제1영상의 세로를 횡단하는 횡분할선을 기준으로, 상기 제1영상을 분할하는, 주행영상의 객체 인식도 향상방법."}
{"patent_id": "10-2023-0080455", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서, 상기 적어도 두 개의 분할영상으로 분할하는 단계는,상기 제1영상의 가로를 종단하는 종분할선 및 상기 제1영상의 세로를 횡단하는 횡분할선을 기준으로, 상기 제1영상을 분할하는, 주행영상의 객체 인식도 향상 방법."}
{"patent_id": "10-2023-0080455", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에 있어서,공개특허 10-2024-0178516-3-상기 제2영상을 생성하는 단계는,상기 외곽선이 생성된 분할영상들에 공통적으로 포함되어 있는 중복영역을 탐지하고, 상기 탐지된 중복영역을제거한 후에 통합하여 상기 제2영상을 생성하는, 주행영상의 객체 인식도 향상 방법."}
{"patent_id": "10-2023-0080455", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1항에 있어서,상기 적어도 두 개의 분할영상으로 분할하는 단계는,상기 수신된 제1영상을 적어도 두 개의 분할영상으로 분할하고, 상기 분할된 분할영상들의 화면비율(aspectratio)을 기설정된 비율로 리사이즈하는, 주행영상의 객체 인식도 향상 방법."}
{"patent_id": "10-2023-0080455", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1항에 있어서,상기 적어도 두 개의 분할영상으로 분할하는 단계는,상기 수신된 제1영상의 하단의 일부영역을 제거하고, 상기 일부영역이 제거된 제1영상을 적어도 두 개의 분할영상으로 분할하는, 주행영상의 객체 인식도 향상 방법."}
{"patent_id": "10-2023-0080455", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제1항에 있어서,상기 적어도 두 개의 분할영상으로 분할하는 단계는,상기 수신된 제1영상을 제1개수의 분할영상으로 분할하는 단계; 및상기 수신된 제1영상을 제2개수의 분할영상으로 분할하는 단계;를 포함하고,상기 외곽선을 생성하는 단계는,상기 제1개수 및 상기 제2개수의 분할영상들로부터 객체를 일괄적으로 인식하고, 인식된 객체별로 외곽선을 생성하고,상기 제2영상을 생성하는 단계는,상기 외곽선이 생성된 제1개수 및 제2개수의 분할영상들을 통합하여 제2영상을 생성하는, 주행영상의 객체 인식도 향상 방법."}
{"patent_id": "10-2023-0080455", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제1항에 따른 방법을 실행시키기 위한 프로그램을 저장하고 있는 컴퓨터 판독가능한 기록매체."}
{"patent_id": "10-2023-0080455", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "적어도 하나의 프로그램이 저장된 메모리; 및상기 적어도 하나의 프로그램을 실행함으로써, 연산을 수행하는 프로세서를 포함하고,상기 프로세서는,주행 중에 획득된 제1영상을 수신하고, 상기 수신된 제1영상의 가로 및 세로 중 적어도 하나를 기준으로 상기 수신된 제1영상을 적어도 두 개의 분할영상으로 분할하고,상기 분할영상별로 객체를 인식하고, 인식된 객체별로 외곽선을 생성하고,상기 외곽선이 생성된 분할영상들을 통합하여 제2영상을 생성하는, 주행영상의 객체 인식도 향상 장치."}
{"patent_id": "10-2023-0080455", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명의 일 실시예는, 주행 중에 획득된 제1영상을 수신하는 단계; 상기 수신된 제1영상의 가로 및 세로 중 적 어도 하나를 기준으로 상기 수신된 제1영상을 적어도 두 개의 분할영상으로 분할하는 단계; 상기 분할영상별로 객체를 인식하고, 인식된 객체별로 외곽선을 생성하는 단계; 및 상기 외곽선이 생성된 분할영상들을 통합하여 제 2영상을 생성하는 단계;를 포함하는, 주행영상의 객체 인식도 향상 방법을 개시한다."}
{"patent_id": "10-2023-0080455", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 영상에 포함된 객체를 인식하는 알고리즘을 개선하기 위한 방법에 관한 것으로서, 보다 구체적으로는, 도로에서 주행 중에 획득된 주행영상에서 객체를 인식하는 객체 인식도를 대폭 향상시킬 수 있는 방법 및 그 방법을 구현하기 위한 장치에 관한 것이다."}
{"patent_id": "10-2023-0080455", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "정보통신 기술과 차량 산업의 융합으로 인해 빠르게 차량의 스마트화가 진행되고 있다. 스마트화로 인해, 차량 은 단순한 기계적 장치에서 스마트카로 진화하고 있으며, 특히, 스마트카의 핵심기술로 자율 주행(self- driving)이 주목 받고 있다. 자율 주행이란, 운전자가 핸들과 가속페달, 브레이크 등을 조작하지 않아도 차량에 탑재된 자율 주행 모듈이 차량의 주행상태를 능동적으로 제어함으로써, 차량 스스로 목적지까지 찾아가는 기술 이다. 자율주행 자동차의 안전한 자율주행을 위해서, 자율 주행 과정에서 차량이 보행자나 다른 차량을 정확하게 인식 하고, 인식된 객체와의 거리를 산출하는 방법에 대한 연구가 다양하게 이루어지고 있으나, 차량이 주행 중에 도 로 상에 출현가능한 객체 특성은 사실상 무한에 가깝고, 자율주행 자동차에 탑재되는 모듈의 프로세싱 능력에 한계가 존재하여, 도로 상에 있는 객체를 완벽하게 인식할 수 있는 방법은 현재 알려져 있지 않다. 카메라를 통한 객체 인식 및 거리추정의 경우, 실제 3차원 세계의 객체를 2차원 이미지에 투영하였기 때문에 거 리에 대한 정보가 많이 손실된다. 특히, 보행자 위치 계산에 많이 사용되는 특징들(보행자의 키나 지면에 닿아 있는 점)의 편차가 크기 때문에 오차가 크다. 레이더(RADAR)를 통한 객체 인식 및 거리추정의 경우, 레이더가 운용하는 전파 특성상 객체를 빠르게 파악하고 분류하는 능력이 떨어지기 때문에, 보행자인지 또는 차량인지에 대한 판단이 어렵고, 특히, 도로상에 있는 보행 자나 이륜차(자전거나 오토바이)의 경우 신호세기가 작기 때문에 인식결과가 더욱 더 안 좋은 경향이 있다. 최근에는 라이다(LiDAR)를 이용한 객체 인식 및 거리 추정 기술이 상대적으로 높은 정확도를 갖고 있어서 각광 받고 있으나, 고출력 레이저는 위험성이 있어서 라이다는 출력을 낮춘 레이저를 기반으로 동작할 수 밖에 없고, 레이더가 사용하는 전파와는 다르게 레이저는 주변 환경의 영향을 크게 받고, 라이다 센서의 지나치게 높은 비 용이 한계점으로 지적된다. 한편, 도로를 주행하는 도중에 촬영된 주행영상에서 거리나 크기 특성으로 인해서, 매우 작은 크기로 촬영되어 영상에 담기는 객체들이 있을 수 있다. 예를 들어, 신체가 작은 어린이, 카메라로부터 멀리 떨어져서 작게 보이 는 신호등과 같은 객체들은, 안전한 자율주행을 위해서 학습모델에 의해 필수적이고 선제적으로 학습되어야 하 는 객체들이지만, 그 객체들에 대한 인식도가 낮은 한계점이 있다. 종래의 딥러닝 기반 모델을 이용한 객체 검출 방법은, 수신된 영상의 사이즈(해상도)를 객체 인식 모듈(object detector)에서 지원하는 사이즈에 맞춰서 변경하고, 변경된 영상을 객체 인식 모듈에 입력함으로써 예측 결과를 얻고, 예측 결과를 최초 수신된 영상의 해상도에 맞게 재변환하는 프로세스로 진행되는 것이 일반적이다. 특히, 객체 인식 모듈에서 주로 사용되는 영상의 해상도는 640*640 또는 1280*1280이며, 과도한 GPU메모리가 필요하고 학습시간이 지나치게 길어지는 문제로 인해서, 앞서 설명한 해상도보다 더 큰 사이즈의 영상은 객체 인식 모듈 의 입력 영상으로 사용되지 않았다. 그러나, 자동차에 탑재되는 카메라 모듈의 스펙이 나날이 향상됨에 따라서, 카메라로부터 수신되는 영상의 해상도는 1280*1280보다 훨씬 더 클 수 밖에 없고, 큰 해상도의 영상이 객체 인 식 모듈에 입력되기 위해서 변환되면서, 영상속에 작은 크기로 촬영된 객체들에 대한 인식도(인식률)가 낮아지 는 문제가 있다."}
{"patent_id": "10-2023-0080455", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 2, "content": "전술한 배경기술은 발명자가 본 발명의 도출을 위해 보유하고 있었거나, 본 발명의 도출 과정에서 습득한 기술 정보로서, 반드시 본 발명의 출원 전에 일반 공중에게 공개된 공지기술이라 할 수는 없다. 선행기술문헌 특허문헌"}
{"patent_id": "10-2023-0080455", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 3, "content": "(특허문헌 0001) 대한민국 등록특허 제10-2438114호 (2022.08.25) 발명의 내용"}
{"patent_id": "10-2023-0080455", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명이 해결하고자 하는 기술적 과제는, 주행영상의 객체 인식도를 향상시키기 위한 방법 및 그 방법을 구현 하기 위한 장치를 제공하는 데에 있다."}
{"patent_id": "10-2023-0080455", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기 기술적 과제를 해결하기 위한 본 발명의 일 실시예에 따른 방법은, 주행 중에 획득된 제1영상을 수신하는 단계; 상기 수신된 제1영상의 가로 및 세로 중 적어도 하나를 기준으로 상기 수신된 제1영상을 적어도 두 개의 분할영상으로 분할하는 단계; 상기 분할영상별로부터 객체를 일괄적으로 객체를 인식하고, 인식된 객체별로 외 곽선을 생성하는 단계; 및 상기 외곽선이 생성된 분할영상들을 통합하여 제2영상을 생성하는 단계;를 포함한다. 상기 방법에 있어서, 상기 분할된 분할영상들은, 상기 제1영상의 일부를 공통적으로 포함할 수 있다. 상기 방법에 있어서, 상기 분할된 분할영상들은, 상기 제1영상을 상기 분할영상들로 분할하는 분할선에 인접한 영역의 영상을 공통적으로 포함할 수 있다. 상기 방법에 있어서, 상기 적어도 두 개의 분할영상으로 분할하는 단계는, 상기 제1영상의 가로를 종단하는 종 분할선을 기준으로, 상기 제1영상을 분할할 수 있다. 상기 방법에 있어서, 상기 적어도 두 개의 분할영상으로 분할하는 단계는, 상기 제1영상의 세로를 횡단하는 횡 분할선을 기준으로, 상기 제1영상을 분할할 수 있다. 상기 방법에 있어서, 상기 적어도 두 개의 분할영상으로 분할하는 단계는, 상기 제1영상의 가로를 종단하는 종 분할선 및 상기 제1영상의 세로를 횡단하는 횡분할선을 기준으로, 상기 제1영상을 분할할 수 있다. 상기 방법에 있어서, 상기 제2영상을 생성하는 단계는, 상기 외곽선이 생성된 분할영상들에 공통적으로 포함되 어 있는 중복영역을 탐지하고, 상기 탐지된 중복영역을 제거한 후에 통합하여 상기 제2영상을 생성할 수 있다. 상기 방법에 있어서, 상기 적어도 두 개의 분할영상으로 분할하는 단계는, 상기 수신된 제1영상을 적어도 두 개 의 분할영상으로 분할하고, 상기 분할된 분할영상들의 화면비율(aspect ratio)을 기설정된 비율로 리사이즈할 수 있다. 상기 방법에 있어서, 상기 적어도 두 개의 분할영상으로 분할하는 단계는, 상기 수신된 제1영상의 하단의 일부 영역을 제거하고, 상기 일부영역이 제거된 제1영상을 적어도 두 개의 분할영상으로 분할할 수 있다. 상기 방법에 있어서, 상기 적어도 두 개의 분할영상으로 분할하는 단계는, 상기 수신된 제1영상을 제1개수의 분 할영상으로 분할하는 단계; 및 상기 수신된 제1영상을 제2개수의 분할영상으로 분할하는 단계;를 포함하고, 상 기 외곽선을 생성하는 단계는, 상기 제1개수 및 상기 제2개수의 분할영상들로부터 객체를 일괄적으로 인식하고, 인식된 객체별로 외곽선을 생성하고, 상기 제2영상을 생성하는 단계는, 상기 외곽선이 생성된 제1개수 및 제2개 수의 분할영상들을 통합하여 제2영상을 생성할 수 있다. 상기 기술적 과제를 해결하기 위한 본 발명의 다른 일 실시예에 따른 장치는, 적어도 하나의 프로그램이 저장된 메모리; 및 상기 적어도 하나의 프로그램을 실행함으로써, 연산을 수행하는 프로세서를 포함하고, 상기 프로세 서는, 주행 중에 획득된 제1영상을 수신하고, 상기 수신된 제1영상의 가로 및 세로 중 적어도 하나를 기준으로 상기 수신된 제1영상을 적어도 두 개의 분할영상으로 분할하고, 상기 분할영상별로 객체를 인식하고, 인식된 객 체별로 외곽선을 생성하고, 상기 외곽선이 생성된 분할영상들을 통합하여 제2영상을 생성할 수 있다. 본 발명의 일 실시예는 상기 방법을 실행시키기 위한 프로그램을 저장하고 있는 컴퓨터 판독가능한 기록매체를 제공할 수 있다."}
{"patent_id": "10-2023-0080455", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명에 따르면, 주행영상에서 작은 크기로 촬영된 객체에 대한 인식도를 대폭 향상시킬 수 있게 된다."}
{"patent_id": "10-2023-0080455", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명은 다양한 변환을 가할 수 있고 여러 가지 실시 예를 가질 수 있는바, 특정 실시 예들을 도면에 예시하"}
{"patent_id": "10-2023-0080455", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "고 상세한 설명에 상세하게 설명하고자 한다. 본 발명의 효과 및 특징, 그리고 그것들을 달성하는 방법은 도면 과 함께 상세하게 후술되어 있는 실시 예들을 참조하면 명확해질 것이다. 그러나 본 발명은 이하에서 개시되는 실시 예들에 한정되는 것이 아니라 다양한 형태로 구현될 수 있다. 이하, 첨부된 도면을 참조하여 본 발명의 실시 예들을 상세히 설명하기로 하며, 도면을 참조하여 설명할 때 동 일하거나 대응하는 구성 요소는 동일한 도면부호를 부여하고 이에 대한 중복되는 설명은 생략하기로 한다. 이하의 실시 예에서, 제1, 제2 등의 용어는 한정적인 의미가 아니라 하나의 구성 요소를 다른 구성 요소와 구별 하는 목적으로 사용되었다. 이하의 실시 예에서, 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 이하의 실시 예에서, 포함하다 또는 가지다 등의 용어는 명세서상에 기재된 특징, 또는 구성요소가 존재함을 의 미하는 것이고, 하나 이상의 다른 특징을 또는 구성요소가 부가될 가능성을 미리 배제하는 것은 아니다. 어떤 실시 예가 달리 구현 가능한 경우에 특정한 공정 순서는 설명되는 순서와 다르게 수행될 수도 있다. 예를 들어, 연속하여 설명되는 두 공정이 실질적으로 동시에 수행될 수도 있고, 설명되는 순서와 반대의 순서로 진행 될 수 있다. 도 1 내지 도 3은 일 실시예에 따른 자율 주행 방식을 설명하기 위한 도면들이다. 도 1을 참조하면, 본 발명의 일 실시예에 따른 자율 주행 장치는, 차량에 장착되어 자율주행 자동차를 구현 할 수 있다. 자율주행 자동차에 장착되는 자율 주행 장치는, 주변의 상황 정보를 수집하기 위한 다양한 센 서들을 포함할 수 있다. 일례로, 자율 주행 장치는 자율주행 자동차의 전면에 장착된 이미지 센서 및/또는 이벤트 센서를 통해, 전방에서 운행 중인 선행 차량의 움직임을 감지할 수 있다. 자율 주행 장치는 자율주 행 자동차의 전면은 물론, 옆 차로에서 운행중인 다른 주행 차량과, 자율주행 자동차 주변의 보행 자 등을 감지하기 위한 센서들을 더 포함할 수 있다. 자율주행 자동차 주변의 상황 정보를 수집하기 위한 센서들 중 적어도 하나는, 도 1에 도시한 바와 같이 소정의 화각(FoV)을 가질 수 있다. 일례로, 자율주행 자동차의 전면에 장착된 센서가 도 1에 도시한 바와 같은 화 각(FoV)을 갖는 경우에, 센서의 중앙에서 검출되는 정보가 상대적으로 높은 중요도를 가질 수 있다. 이는, 센서 의 중앙에서 검출되는 정보에, 선행 차량의 움직임에 대응하는 정보가 대부분 포함되어 있기 때문일 수 있다. 자율 주행 장치는, 자율주행 자동차의 센서들이 수집한 정보를 실시간으로 처리하여 자율주행 자동차의 움직임을 제어하는 한편, 센서들이 수집한 정보 중에 적어도 일부는 메모리 장치에 저장할 수 있다. 도 2를 참조하면, 자율 주행 장치는 센서부, 프로세서, 메모리 시스템, 및 차체 제어 모듈 등을 포함할 수 있다. 센서부는 복수의 센서들(42-45)을 포함하며, 복수의 센서들(42-45)은 이미지 센서, 이벤트 센서, 조도 센서, GPS 장치, 가속도 센서 등을 포함할 수 있다. 센서들(42-45)이 수집한 데이터는 프로세서로 전달될 수 있다. 프로세서는 센서들(42-45)이 수집한 데 이터를 메모리 시스템에 저장하고, 센서들(42-45)이 수집한 데이터에 기초하여 차체 제어 모듈을 제어 하여 차량의 움직임을 결정할 수 있다. 메모리 시스템은 둘 이상의 메모리 장치들과, 메모리 장치들을 제어 하기 위한 시스템 컨트롤러를 포함할 수 있다. 메모리 장치들 각각은 하나의 반도체 칩으로 제공될 수 있다. 메모리 시스템의 시스템 컨트롤러 외에, 메모리 시스템에 포함되는 메모리 장치들 각각은 메모리 컨트 롤러를 포함할 수 있으며, 메모리 컨트롤러는 신경망과 같은 인공지능(AI) 연산 회로를 포함할 수 있다. 메모리 컨트롤러는 센서들(42-45) 또는 프로세서로부터 수신한 데이터에 소정의 가중치를 부여하여 연산 데이터를 생성하고, 연산 데이터를 메모리 칩에 저장할 수 있다. 도 3은 자율 주행 장치가 탑재된 자율주행 자동차의 센서가 획득한 영상 데이터의 예시를 나타낸 도면이다. 도 3을 참조하면, 영상 데이터는 자율주행 자동차의 전면에 장착된 센서가 획득한 데이터일 수 있다. 따라서 영상 데이터에는 자율주행 자동차의 전면부, 자율주행 자동차과 같은 차로의 선행 차량, 자율주행 자동차 주변의 주행 차량 및 비관심영역 등이 포함될 수 있다. 도 3에 도시한 실시예에 따른 영상 데이터에서, 자율주행 자동차의 전면부와 비관심영역이 나타나 는 영역의 데이터는 자율주행 자동차의 운행에 영향을 미칠 가능성이 거의 없는 데이터일 수 있다. 다시 말해, 자율주행 자동차의 전면부와 비관심영역은 상대적으로 낮은 중요도를 갖는 데이터로 간주될 수 있다. 반면, 선행 차량과의 거리, 및 주행 차량의 차로 변경 움직임 등은 자율주행 자동차의 안전한 운행에 있어서 매우 중요한 요소일 수 있다. 따라서, 영상 데이터에서 선행 차량 및 주행 차량 등이 포함 되는 영역의 데이터는 자율주행 자동차의 운행에 있어서 상대적으로 높은 중요도를 가질 수 있다. 자율 주행 장치의 메모리 장치는, 센서로부터 수신한 영상 데이터의 영역별로 가중치를 다르게 부여하여 저 장할 수 있다. 일례로, 선행 차량과 주행 차량 등이 포함되는 영역의 데이터에는 높은 가중치를 부여하 고, 자율주행 자동차의 전면부와 비관심영역이 나타나는 영역의 데이터에는 낮은 가중치를 부여할 수 있다. 도 4a 및 도 4b는 일 실시예에 따른 차량 외부를 촬영하는 카메라와 관련된 도면이다. 카메라는 차량에 탑재되어 차량의 외부를 촬영할 수 있다. 카메라는 차량의 전방, 측방, 후방 등을 촬영할 수 있다. 본 발명에 따른 장치는 카메라에서 촬영된 복수의 영상을 획득할 수 있다. 카메라에서 촬영된 복수의 영 상에는 복수의 객체가 포함될 수 있다. 객체에 관한 정보는 객체 종류 정보 및 객체 속성 정보를 포함한다. 여기에서, 객체 종류 정보는 객체의 종류를 나타내는 인덱스 정보이며, 큰 범위인 그룹과 세부 범위인 클래스로 구성된다. 그리고, 객체 속성 정보는 객체 의 현재 상태에 대한 속성 정보를 나타내는 것이며, 움직임 정보, 회전 정보, 교통 정보, 색상 정보, 및 가시성 정보 등을 포함한다. 일 실시예에서, 객체 종류 정보에 포함되는 그룹 및 클래스는 아래의 표 1과 같을 수 있으나, 이에 제한되지 않 는다. 표 1 Group Class Flat Road, Sidewalk, Parking, Ground, Crosswalk Human Pedestrian, Rider Vehicle Car, Truck, Bus ConstructionBuilding Wall, Guard rail, Tunnel, fence, gas station, pylon Object Pole, Traffic sign, Traffic light, color corn Nature vegetation, terrain, paddy field, river, lakeVoid Static Lane Dotted line, Solid line, Dotted and Solid line, Double Solid line Sky Sky Animal Dog, Cat, bird 움직임 정보는 객체의 움직임 정보를 표현하며 정차, 주차, 이동 등으로 정의될 수 있다. 차량의 경우 정차, 주 차, 이동이 객체 속성 정보로 결정될 수 있고, 보행자의 경우 이동, 정지, 알 수 없음이 객체 속성 정보로 결정 될 수 있고, 신호등과 같이 움직일 수 없는 객체의 경우 디폴트 값인 정지로 객체 속성 정보가 결정될 수 있 다.회전 정보는 객체의 회전 정보를 표현하며 정면, 후면, 수평(horizontal), 수직(vertical), 측면 등으로 정 의될 수 있다. 차량의 경우 정면, 후면, 측면으로 객체 속성 정보가 정해질 수 있고, 가로 또는 세로 방향의 신 호등은 각각 수평 또는 수직으로 객체 속성 정보가 정해질 수 있다. 교통 정보는 객체의 교통정보를 의미하며, 교통표지판의 지시, 주의, 규제, 보조 표지 등으로 정의될 수 있다. 색상 정보는 객체의 색상 정보를 의미하며 객체의 색상, 신호등 및 교통표지판의 색상을 표현할 수 있다. 도 4a를 참조하면, 객체는 보행자일 수 있다. 이미지는 소정의 크기를 가질 수 있다. 복수의 이미지 에는 동일한 객체가 포함될 수 있으나, 차량이 도로를 따라 주행함에 따라 차량과 객체의 상대 적 위치는 계속 변하고, 또한 객체도 시간에 따라 이동을 함으로써, 이에 따라 동일한 객체라도 각 이미지 내에서의 위치가 달라지게 된다. 각 이미지에서 동일한 객체가 어떤 것인지 결정하기 위해 이미지 전체를 이용하는 경우, 데이터 전송량 및 연산 량이 상당히 커지게 된다. 이에 따라, 차량에 탑재되는 장치에서 엣지 컴퓨팅을 통해 처리되기 어렵고, 실시간 분석 또한 어렵다. 도 4b를 참조하면, 이미지에 포함된 바운딩 박스가 도시된다. 바운딩 박스(Bounding box)는 객체 (object)에 대한 메타데이터로서, 바운딩 박스 정보에는 객체 종류 정보(그룹, 클래스 등), 이미지 상의 위치 정보, 크기 정보 등이 포함될 수 있다. 도 4b를 참조하면, 바운딩 박스 정보는 해당 객체가 보행자 클래스에 해당한다는 정보와, 객체의 좌 측 상단 꼭지점이 이미지 상의 (x, y) 에 위치한다는 정보, 객체의 크기가 w x h 라는 정보, 그리고 객체 가 이동 중이라는 현재 상태 정보(즉, 움직임 정보)를 포함할 수 있다. 도 5는 일 실시예에 따른 객체 인식 방법을 설명하는 개략도이다. 객체 인식도 향상 장치는 카메라로부터 획득된 동영상을 프레임별로 분리하여 복수의 프레임을 획득할 수 있다. 복수의 프레임은 이전 프레임 및 현재 프레임을 포함할 수 있다. 객체 인식도 향상 장치는 이전 프레임에서 제1 보행자 객체를 인식할 수 있다. 일 실시예에서, 객체 인식도 향상 장치는 프레임을 동일한 크기의 그리드로 나누고, 각 그리드에 대해 그리드 중앙을 중심으로 미리 정의된 형태로 지정된 경계박스의 개수를 예측하며 이를 기반으로 신뢰도를 계산할 수 있 다. 객체 인식도 향상 장치는 프레임에 객체가 포함되어 있는지, 또는, 배경만 단독으로 있는지 여부를 결정하 고, 높은 객체 신뢰도를 갖는 위치를 선택하여 객체 카테고리를 결정함으로써 결과적으로 객체를 인식할 수 있 다. 다만, 본 개시에서 객체를 인식하는 방법은 이에 제한되지 않는다. 객체 인식도 향상 장치는 이전 프레임에서 인식된 제1 보행자 객체의 제1 위치 정보를 획득할 수 있 다. 도 4a 및 도 4b에서 상술한 바와 같이, 제1 위치 정보는 이전 프레임 상의 제1 보행자 객체에 대 응하는 바운딩 박스의 어느 하나의 꼭지점(예를 들어, 좌측 상단 꼭지점) 좌표 정보 및 가로, 세로 길이 정보를 포함할 수 있다. 또한, 객체 인식도 향상 장치는 현재 프레임에서 인식된 제2 보행자 객체의 제2 위치 정보를 획득할 수 있다. 객체 인식도 향상 장치는 이전 프레임에서 인식된 제1 보행자 객체의 제1 위치 정보, 및 현재 프레임 에서 인식된 제2 보행자 객체의 제2 위치 정보 간의 유사도를 산출할 수 있다. 도 5를 참조하면, 제1 위치 정보 및 제2 위치 정보를 이용하여, 객체 인식도 향상 장치는 제1 보행자 객체 및 제2 보행자 객체간의 교집합 및 합집합을 산출할 수 있다. 객체 인식도 향상 장치는 합집합 영역 대비교집합 영역의 값을 산출하고, 산출된 값이 임계값 이상인 경우, 제1 보행자 객체 및 제2 보행자 객체 가 동일한 보행자 객체인 것으로 결정할 수 있다. 그러나, 객체 간의 동일성을 판별하는 방법은 상술한 방법으로 제한되지 않는다. 도 6은 본 발명에 따른 객체 인식도 향상 방법의 일 실시예를 도식적으로 설명하기 위한 도면이다. 보다 구체적으로, 도 6의 (A)는 자동차에 장착된 카메라로부터 수신된 영상으로서, 아직 객체가 검출되지 않은 로우 데이터(raw data)에 해당된다. 이하에서, 도 6의 (A)와 같이 아직 객체 인식 모듈에 입력되지 않은 영상을 제1영상으로 호칭하기로 한다. 도 6의 (A)의 제1영상에는 승용차 1대, 이륜차 1대, 행인 1명이 이동하는 객체로 포함되어 있고, 그 외에, 횡단보도 신호등 2대 및 차도 신호등 2대가 고정객체로 포함되어 있다. 본 발명에 따른 객체 인식도 향상 방법은 도 6의 (A)와 같은 제1영상을 수신하고 나서, 수신된 제1영상을 도 6 의 (B)와 같이 적어도 두 개 이상의 분할영상으로 분할하는 프로세스를 포함할 수 있다. 특히, 제1영상을 분할 하여 생성되는 분할영상들은 서로 배타적인 정보만 포함하는 것이 아니라, 일부 공통된 부분을 포함할 수 있다. 일 예로, 도 6의 (B)에는 총 4개의 분할영상이 도시되어 있으며, 4개의 분할영상에는 모두 라이더가 탑승하고 있는 이륜차의 뒷모습이 모두 포함되어 있는 것을 알 수 있다. 도 6의 (B)의 분할영상 중의 하나에 라이더가 탑 승하고 있는 이륜차를 완전하게 포함하고 있는데도 불구하고, 나머지 3개의 분할영상에 라이더가 탑승하고 있는 이륜차의 뒷모습이 영상에 포함되어 있다는 것은, 본 발명의 제1영상을 분할하여 생성되는 분할영상들간에는 공 통된 부분이 포함될 수 있다는 것을 의미한다. 도 6의 (B)에 도시된 것처럼, 제1영상에서 분할된 분할영상들은 영상의 상단 및 하단 영역이 패딩(padding)처리될 수 있다. 도 7은 본 발명에 따른 객체 인식도 향상 방법의 다른 일 실시예를 도식적으로 설명하기 위한 도면이다. 보다 구체적으로, 도 7의 (A)는 도 6의 (B)와 동일하게 제1영상에서 분할되어 생성된 4개의 분할영상을 도식적 으로 나타내고 있다. 도 7의 (A)에 도시된 4개의 분할영상들은 일부 공통된 부분(공통된 객체에 대한 정보)을 포함하고 있다. 본 발명에 따른 객체 인식도 향상 방법은, 도 7의 (A)와 같은 4개의 분할영상이 생성되면, 4개의 분할영상을 객 체 인식 모듈(object detector)에 입력하여, 분할영상별로 객체가 인식되도록 하는 프로세스를 수행할 수 있다. 본 발명에서 객체 인식 모듈은 본 발명에 따른 장치에 물리적 또는 논리적으로 포함되어 있는 장치를 의미하는 것으로서, 딥러닝 기반의 학습모델을 기반으로 입력된 영상에서 자동차의 자율주행을 구현하기 위해서 필요한 객체들을 인식하고, 객체를 인식한 결과를 외곽선 형태로 라벨링(labelling)을 수행할 수 있다. 본 발명에서 제1영상은 분할영상으로 분할되는 과정에서 자연스럽게 해상도가 줄어들게 되므로, 분할영상은 통 상적인 객체 인식 모듈에서 요구하는 영상의 해상도를 충족하게 될 수 있다. 또한, 실시예에 따라, 분할영상의 해상도가 객체 인식 모듈의 입력 영상의 사이즈보다 여전히 더 클 경우에는, 분할영상의 해상도를 객체 인식 모 듈이 요구하는 사이즈로 변환하기 위한 추가적인 변환 처리가 수행될 수도 있다. 도 7의 (B)를 참조하면, 도 7의 (A)에 도시되어 있던 4개의 분할영상에서 신호등에 해당하는 객체들에만 선택적 으로 외곽선이 생성된 것을 알 수 있다. 보다 구체적으로, 객체 인식 모듈은 도 7의 (A)에 도시된 4개의 분할영 상을 각각 입력영상으로 받아서(또는, 실시예에 따라서, 4개의 분할영상을 배치(batch) 방식으로 일괄적으로 받 아서), 객체 인식 모듈에 미리 설정되어 있는 딥러닝 기반의 객체 인식 알고리즘을 기반으로, 각각의 분할영상 에서 목표로 하는 객체를 검출하고, 검출된 객체에 대해서 외곽선이 생성되도록 할 수 있다. 도 7의 (B)에서 객 체 인식 모듈은 오직 분할영상에 포함되어 있는 여러 종류의 객체 중에서 신호등에 해당하는 객체만 인식하는 모듈인 것으로 간주하며, 그 결과, 도 7의 (B)에 도시된 4개의 분할영상에는 횡단보도 신호등 2대 및 차도 신호 등 2대가 객체로서 검출된 것을 알 수 있다. 도 7의 (B)에 제1 차도 신호등 및 제1 횡단보도 신호등은 크기가 매우 작은 객체로서, 기존 기술에 따라 객체를 검출하면 검출되지 않는 객체이지만, 본 발명에 따르면, 영상을 분할영상들로 분할하여 객체 인식 모듈에 입력하는 프로세스를 포함하게 따라, 다른 신호등에 비해서 크기가 작은 제1 차도 신호등 및 제1 횡단보도 신호등도 객체로 검출될 수 있다. 도 7의 (B)의 분할영상에서 검출된 객체들은 외곽선으로 2D 바운딩 박스가 적용되어 있으나, 실시예에 따라서, 큐보이드(cuboid) 형태의 외곽선이 적용될 수도 있다. 도 8은 본 발명에 따른 객체 인식도 향상 방법의 또 다른 일 실시예를 도식적으로 설명하기 위한 도면이다. 도 8의 (A)는 도 7의 (B)와 동일하게 제1영상에서 분할되어 생성된 4개의 분할영상마다 신호등이 객체로서 검출 된 결과를 나타내고 있다. 본 발명에 따른 객체 인식도 향상 장치는, 도 8의 (A)에 도시되어 있는 4개의 분할영 상을 통합하여, 도 8의 (B)에 도시되어 있는 통합영상을 생성할 수 있다. 통합영상에는 객체 인식 모듈에서 인 식하는 것으로 설정되어 있는 객체들이 모두 검출되어 외곽선이 적용되어 있으며, 이하에서, 통합영상은 도 6의 (A)에서 설명한 제1영상과 구분하기 위해서, 제2영상으로 호칭하기로 한다. 본 발명에 따른 객체 인식도 향상 장치는, 도 8의 (A)에 도시된 4개의 분할영상들을 도 8의 (B)에 도시된 제2영 상으로 통합하기 위해서, 분할영상별로 공통적으로 포함하고 있는 객체들에 대한 정보를 제거하는 프로세스를 필수적으로 수행할 수 있으며, 이에 대해서는 도 9 내지 도 11을 통해서 후술하기로 한다. 또한, 도 6 내지 도 8에서 분할영상의 수를 4개로 설명하였으며, 본 발명에서 분할영상의 수는 적어도 2개 이상 이면 족하므로, 앞서 설명한 4개에 의해 제한되지 않는다. 그 외에도, 도 6 내지 도 8에서 객체 인식 모듈에 의해 탐지되는 주요 객체는 횡단보도 신호등 및 차로 신호등 을 포함하는 신호등이었으나, 이는 설명의 편의를 위한 것일 뿐, 본 발명에 따른 방법이 수행되면서 인식되는 객체의 범위는 특정한 범주의 것으로 제한되지 않는다. 도 6 내지 도 8에서 설명한 본 발명에 따른 객체 인식도 향상 방법에 따르면, 수신된 제1영상에 포함되어 있는 객체들 중에서 작은 크기로 촬영된 객체를 정확하게 인식할 수 있다. 특히, 본 발명에 따른 객체 인식도 향상 방법은 수신된 제1영상을 일부 공통된 부분을 포함하는 분할영상으로 분할하고, 분할영상별로 객체 인식 모듈에 입력되도록 함으로써, 영상의 전체크기(해상도)와 비교하여 작은 크기로 촬영된 중요 객체(예를 들어, 신호등) 가 분할영상에서는 상대적으로 크기비(size ratio)가 향상되는 효과가 발생되면서, 종래의 방법으로는 탐지되지 않았던 작은 크기의 객체들도 인식될 수 있는 장점이 있다. 이하에서는, 도 6 내지 도 8을 통해서 개념적으로 설명한 본 발명의 프로세스를 더욱 더 구체적으로 설명하기로 한다. 도 9는 본 발명에 따른 객체 인식도 향상 방법의 일 예를 흐름도로 나타낸 도면이다. 도 9에 따른 방법은 본 발명에 따른 객체 인식도 향상 장치에 의해 구현될 수 있으며, 객체 인식도 향상 장치를 구성하는 하위 모듈의 기능에 대해서는 도 15를 통해서 설명하기로 한다. 객체 인식도 향상 장치는 제1영상을 원본영상으로서 수신할 수 있다(S910). 단계 S910에서 객체 인식도 향상 장치가 수신하는 제1영상은 자동차에 장착된 카메라가 도로(차도)를 주행하면 서 촬영함으로써 생성된 영상으로서, 1920*1280 픽셀로 이루어진 영상일 수 있으나 이에 한정되지 않는다. 즉, 자동차에 장착되어 있는 카메라의 성능에 따라서, 제1영상은 Full HD급인 1920*1080보다 더 높은 해상도인 QHD(2560*1440)나 UHD(3840*2160)급의 해상도의 영상이 수신될 수도 있다. 본 발명의 특성상, 제1영상의 해상도 가 높으면 높을수록, 분할영상들의 해상도도 높아지고, 그에 따라서, 더 작은 크기의 객체도 더 정확하게 인식 (검출)될 수 있게 된다. 이어서, 객체 인식도 향상 장치는 수신된 제1영상을 분할하고 변환할 수 있다(S920). 단계 S920에서 제1영상을 분할하는 프로세스는 도 6 내지 도 8에서 설명한 분할영상을 생성하는 프로세스를 의 미한다. 객체 인식도 향상 장치는 수신된 제1영상의 크기(해상도)에 따라서, 몇 개의 분할영상으로 분할할지에 대한 기준을 테이블(table)형태로 미리 저장하고 있다가 이를 참조하여 영상 분할 프로세스를 수행할 수 있다. 예를 들어, 제1영상의 해상도가 1920*1280이라면, 객체 인식도 향상 장치는 내부적으로 저장되어 있는 설정값을 참조하여, 제1영상을 총 4개의 분할영상으로 분할시킬 수 있다. 이때, 분할영상의 해상도는 480*320이 되지만, 도 6 내지 도 8에서 설명한 것처럼, 분할영상의 해상도를 구성하는 픽셀 중에서는 실질적으로 의미가 없는 패딩 영역에 대한 픽셀도 포함될 수 있다. 단계 S920에서 객체 인식도 향상 장치에는 제1영상을 몇 개의 분할영상으로 분할할지에 대한 기준값이 저장되어 있을 뿐만 아니라, 분할영상별로 공통적으로 포함하는 중복영역의 크기(해상도)에 대한 정보도 같이 저장되어 있다. 분할영상별로 공통적으로 포함하는 중복영역의 크기에 대한 정보에 대해서는 도 10을 통해 후술하기로 한 다. 단계 S920에서, 객체 인식도 향상 장치는 분할영상의 해상도를 객체 인식 모듈(object detector)에 입력하기 위 해서 추가로 변환할 수 있다. 통상적으로, 객체 인식 모듈은 가로 및 세로의 길이가 같은 영상을 적합한 입력영 상의 크기로 하기에, 객체 인식도 향상 장치는, 분할영상의 해상도를 2차적으로 가로와 세로의 길이가 같아지도록 변환할 필요가 있다. 객체 인식도 향상 장치는 제1영상을 통해서 분할영상이 생성되면, 생성된 분할영상들을 객체 인식 모듈(Object Detector)에 입력(S930)하여, 분할영상별로 특정한 객체들을 인식하여 검출할 수 있도록 한다(S940). 여기서, 객체 인식 모듈은 딥러닝(deep learning)기반으로 동작하는 학습모델로서, 일정한 크기의 영상을 입력으로 받아 서, 입력된 영상에서 특정한 객체들을 선택적으로 인식하고, 그 인식의 결과로 객체별로 외곽선이 생성된 영상 을 출력할 수 있는 모델을 의미한다. 이어서, 객체 인식도 향상 장치는 외곽선이 생성된 분할영상들을 통합하여 제2영상을 생성하게 되며, 이 과정에 서, 객체 인식도 향상 장치는 분할영상들을 통합할 때, 분할영상에서 검출된 객체들별로 좌표 변환을 수행하고, 분할영상마다 공통적으로 포함되어 있는 중복부분을 제거하는 프로세스를 수행할 수 있다(S950). 단계 S950에서 객체 인식도 향상 장치는 각각의 분할영상을 기준으로 구한 외곽선의 좌표를 원본영상인 제1영상 의 기준 좌표로 변환하고, 각각의 분할영상에서의 객체 인식 결과(외곽선)를 통합하는 방식으로 분할영상을 통 합시킬 수 있다. 이 과정에서, 객체 인식도 향상 장치는 좌표 변환 이후 분할영상들별로 중복영역을 제거하기 위해서, 객체 인식 모듈에서 지원하는 NMS(Non-maximum Suppression)알고리즘을 이용할 수 있다. 객체 인식도 향상 장치는 NMS를 분할영상을 통해 크롭(crop)된 객체가 NMS알고리즘을 통해서 제대로 제거되지 않는 경우, 크 롭된 객체와 원래 객체간의 교집합을 산출하고, 산출된 교집합을 이용하여 크롭된 객체를 추가적으로 제거할 수 있다. 최종적으로, 객체 인식도 향상 장치는 작은 크기의 객체도 정확하게 인식하여 외곽선이 생성된 제2영상을 획득 할 수 있다(S960). 도 10은 객체 인식도 향상 장치가 분할영상의 중복 영역의 크기를 결정하는 프로세스를 설명하기 위한 도면이다. 도 10에서 객체 인식도 향상 장치는 수신된 제1영상을 4개의 분할영상으로 분할하기로 결정하였으며, 4개의 분 할영상은 제1분할영상, 제2분할영상, 제3분할영상 및 제4분할영상으로 도 10에 각각 도시되어 있다. 도 10을 참조하면, 제1분할영상, 제2분할영상, 제3분할영상 및 제4분할영상은 공통적 으로 중복영역을 포함하도록 분할되는 것을 알 수 있다. 또한, 제1분할영상은 인접한 분할영상인 제2분할영상 및 제3분할영상과 중복영역 외에 각각 공통되는 중복된 부분을 포함할 수 있으 며, 나머지 제2분할영상, 제3분할영상 및 제4분할영상도 마찬가지다. 도 11은 객체 인식도 향상 장치가 종분할선을 기준으로 분할영상을 생성하는 경우를 설명하기 위한 도면이다. 도 11에서 제1분할영상 및 제3분할영상은 도 10의 제1분할영상 및 제3분할영상에 각각 대응될 수 있다. 도 11에서 제1분할영상 및 제3분할영상은 제1중복영역을 공통적으로 포함하 도록 분할되며, 도 11에서 제1분할영상 및 제3분할영상은 동일한 높이(height)에 있으므로, 종분할 선을 기준으로 분할영상이 생성되는 것으로 이해될 수 있다. 도 11과 같이 제1영상이 분할됨에 따라서, 제1분할 영상은 제1분할영상의 고유한 영상부분과 제1중복영역을 포함하고, 제3분할영상은 제3 분할영상의 고유한 영상부분과 제1중복영역을 포함하게 된다. 수학식 1 수학식 2"}
{"patent_id": "10-2023-0080455", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "수학식 1 및 수학식 2는 객체 인식도 향상 장치가 종분할선을 기준으로 분할영상을 생성할 때 참조하는 수학식 들을 나타낸다. 수학식 2는 수학식 1을 기준이 되는 변수를 달리하여 재정리한 수식임을 알 수 있다. 수학식 1 및 수학식 2에서, W1는 제1영상의 가로길이, px는 분할영상의 가로길이, n은 분할영상의 개수, Ox는 중복영역의 가로길이를 각각 의미한다. 본 발명에 따른 객체 인식도 장치는 제1영상을 수신하고 나서 제1영상의 해상도가 파악되면, 파악된 제1영상의 해상도에 따라서, 분할영상의 개수인 n을 결정하고, 결정된 n에 따라서 순차적으로 중복영역의 가로길이를 결정한 후, 분할영상의 가로길이를 결정할 수 있다. 도 11에 도시되어 있지 않지만, 도 11에서 종분할선은 제1영상의 가로길이의 중앙에 위치한 것으로 간주하며, 객체 인식도 향상 장치는 종분할선을 기준으로 종분할선에 인접한 제1중복영역을 설정하고, 설정된 제1중 복영역이 제1분할영상 및 제3분할영상에 모두 포함되도록 연산을 하여 분할영상을 생성하게 된다. 도 12는 객체 인식도 향상 장치가 횡분할선을 기준으로 분할영상을 생성하는 경우를 설명하기 위한 도면이다. 도 12에서 제1분할영상 및 제2분할영상은 도 10의 제1분할영상 및 제2분할영상에 각각 대응될 수 있다. 도 12에서 제1분할영상 및 제2분할영상은 제2중복영역을 공통적으로 포함하 도록 분할되며, 도 12에서 제1분할영상 및 제3분할영상은 동일한 너비(width)에 위치하고 있으므로, 도 11과 달리, 종분할선이 아니라 횡분할선을 기준으로 분할영상이 생성되는 것으로 이해될 수 있다. 도 12와 같이 제1영상이 분할됨에 따라서, 제1분할영상은 제1분할영상의 고유한 영상부분과 제2중 복영역을 포함하고, 제2분할영상은 제3분할영상의 고유한 영상부분과 제1중복영역을 포함하게 된다. 수학식 3"}
{"patent_id": "10-2023-0080455", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "수학식 4"}
{"patent_id": "10-2023-0080455", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "수학식 3 및 수학식 4는 객체 인식도 향상 장치가 횡분할선을 기준으로 분할영상을 생성할 때 참조하는 수학식 들을 나타낸다. 수학식 4는 수학식 3을 기준이 되는 변수를 달리하여 재정리한 수식임을 알 수 있다. 수학식 3 및 수학식 4에서, H1는 제1영상의 세로길이, py는 분할영상의 세로길이, n은 분할영상의 개수, Oy는 중복영역의 세로길이를 각각 의미한다. 본 발명에 따른 객체 인식도 장치는 제1영상을 수신하고 나서 제1영상의 해상도가 파악되면, 파악된 제1영상의 해상도에 따라서, 분할영상의 개수인 n을 결정하고, 결정된 n에 따라서 순차적으로 중복영역의 세로길이를 결정한 후, 분할영상의 세로길이를 결정할 수 있다.도 12에 도시되어 있지 않지만, 도 12에서 횡분할선은 제1영상의 세로길이의 중앙에 위치한 것으로 간주하며, 객체 인식도 향상 장치는 횡분할선을 기준으로 횡분할선에 인접한 제2중복영역을 설정하고, 설정된 제2중 복영역이 제1분할영상 및 제2분할영상에 모두 포함되도록 연산을 하여 분할영상을 생성하게 된다. 도 11 및 도 12에서 설명한 분할영상의 생성 프로세스는 동시에 적용될 수 있으며, 제1영상에 종분할선 및 횡분 할선을 기준으로 분할영상이 생성되면, 도 10에서 설명한 것처럼, 제1분할영상 내지 제4분할영상은 모두 공통적으로 중복영역을 포함하게 되는 형태로 분할영상들이 생성될 수 있다. 선택적 일 실시예로서, 본 발명에 따른 객체 인식도 향상 장치는, 수신된 제1영상을 제1개수의 분할영상으로 분 할하고, 수신된 제1영상의 사본을 다시 제2개수의 분할영상으로 분할한 후에, 제1개수 및 제2개수의 분할영상별 로 객체를 인식하고, 인식된 객체별로 외곽선을 생성함으로써 제2영상을 생성할 수도 있다. 예를 들어, 객체 인 식도 향상 장치는 도 10처럼 2*2개의 분할영상을 생성한 후에, 다시 3*3개의 분할영상을 생성하여, 총 13개의 분할영상에 대해서 객체 인식 프로세스를 적용한 후, 13개의 분할영상을 통합하여 제2영상을 생성할 수도 있다. 또한, 다른 선택적 일 실시예로서, 객체 인식도 향상 장치는, 원본 영상인 제1영상을 분할영상과 함께 객체 인 식 모듈에 입력하고, 그 결과를 통합하여 제2영상을 생성할 수도 있다. 예를 들어, 객체 인식도 향상 장치는 도 10처럼 2*2개의 분할영상을 생성한 후에, 다시 3*3개의 분할영상을 생성하고 나서, 제1영상에 대해서도 객체 인 식 프로세스를 적용함으로써, 총 14개(제1영상 1개, 분할영상 13개)의 영상들을 통합하여 제2영상을 생성할 수 도 있다. 전술한 두 가지 선택적 일 실시예들은 작은 크기의 객체뿐만 아니라 다양한 크기의 객체를 검출하기 위해서 활 용될 수 있다. 도 13은 객체 인식도 향상 장치에서 객체 인식 모듈에 입력될 영상을 변환하는 프로세스의 다른 일 실시예를 설 명하기 위한 도면이다. 먼저, 도 13의 (A)는 객체 인식 모듈에 입력되는 일반적인 영상을 도식적으로 나타내고 있다. 이어서, 도 13의 (B)는 도 13의 (A)와 같은 제1영상이 입력으로 들어오면, 화면비율(aspect ratio)을 유지하면서 영상의 상하단 부에 패딩(padding)을 삽입하는 방식으로 제1영상을 가공하는 프로세스를 도식적으로 나타내며, 도 13의 (C)는 제1영상에 패딩을 삽입하지 않고 영상을 단순히 리사이즈(resize)하는 프로세스를 도식적으로 나타내고 있다. 즉, 도 13을 참조하면, 최초에 수신된 제1영상은 분할되어 분할영상이 된 후에, 도 13의 (B) 또는 도 13의 (C) 처럼, 화면비율을 유지하면서 패딩이 추가되어 객체 인식 모듈에 입력되거나 기존의 화면비율과 무관하게 분할 영상의 크기에 맞춰서 단순 리사이즈되어 객체 인식 모듈에 입력되는 것을 알 수 있다. 도 14는 객체 인식도 향상 장치에서 객체 인식 모듈에 입력될 영상을 변환하는 프로세스의 또 다른 일 실시예를 설명하기 위한 도면이다. 본 발명에 따른 객체 인식도 향상 장치는, 제1영상을 복수의 분할영상으로 분할하기에 앞서, 객체 인식 모듈에 서 검출하고자 하는 객체가 신호등이라면, 신호등의 특성상 영상의 하단에 위치하지 않으므로, 이 정보를 이용 하여 제1영상의 일부만 크롭(crop)하고 나서, 복수 개의 분할영상을 생성할 수도 있다. 예를 들어, 객체 인식도 향상 장치는, 제1영상의 상단 60%에 해당하는 영역만 크롭하고 제1영상의 하단의 일부영역(40%에 해당하는 영역)을 제거하고 사용할 수도 있으며, 60%라는 수치는 예시값이므로, 실시예에 따라서 60%의 수치는 달라질 수 있다. 도 15는 일 실시예에 따른 객체 인식도 향상 장치의 블록도이다. 도 15를 참조하면, 객체 인식도 향상 장치는 통신부, 프로세서 및 DB를 포함할 수 있 다. 도 15의 객체 인식도 향상 장치에는 실시예와 관련된 구성요소들만이 도시되어 있다. 따라서, 도 15"}
{"patent_id": "10-2023-0080455", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "에 도시된 구성요소들 외에 다른 범용적인 구성요소들이 더 포함될 수 있음을 당해 기술분야의 통상의 기술자라 면 이해할 수 있다. 통신부는 외부 서버 또는 외부 장치와 유선/무선 통신을 하게 하는 하나 이상의 구성 요소를 포함할 수 있다. 예를 들어, 통신부는, 근거리 통신부(미도시), 이동 통신부(미도시) 및 방송 수신부(미도시) 중 적 어도 하나를 포함할 수 있다. DB는 객체 인식도 향상 장치 내에서 처리되는 각종 데이터들을 저장하는 하드웨어로서, 프로세서 의 처리 및 제어를 위한 프로그램을 저장할 수 있다. DB는 DRAM(dynamic random access memory), SRAM(static random access memory) 등과 같은 RAM(random access memory), ROM(read-only memory), EEPROM(electrically erasable programmable read-only memory), CD-ROM, 블루레이 또는 다른 광학 디스크 스토리지, HDD(hard disk drive), SSD(solid state drive), 또는 플 래시 메모리를 포함할 수 있다. 프로세서는 객체 인식도 향상 장치의 전반적인 동작을 제어한다. 예를 들어, 프로세서는 DB에 저장된 프로그램들을 실행함으로써, 입력부(미도시), 디스플레이(미도시), 통신부, DB 등을 전반적으로 제어할 수 있다. 프로세서는, DB에 저장된 프로그램들을 실행함으로써, 객체 인식 도 향상 장치의 동작을 제어할 수 있다. 프로세서는 도 6 내지 도 14에서 상술한 객체 인식도 향상 장치의 동작 중 적어도 일부를 제어할 수 있다. 일 예로서, 프로세서는 주행 중에 획득된 제1영상을 수신하고, 수신된 제1영상의 가로 및 세로 중 적어도 하나를 기준으로 수신된 제1영상을 적어도 두 개의 분할영상으로 분할하고, 분할영상별로 객체를 인식하고, 인 식된 객체별로 외곽선을 생성하고, 외곽선이 생성된 분할영상들을 통합하여 제2영상을 생성할 수 있다. 프로세서는 ASICs(application specific integrated circuits), DSPs(digital signal processors), DSPDs(digital signal processing devices), PLDs(programmable logic devices), FPGAs(field programmable gate arrays), 제어기(controllers), 마이크로 컨트롤러(micro-controllers), 마이크로 프로세서 (microprocessors), 기타 기능 수행을 위한 전기적 유닛 중 적어도 하나를 이용하여 구현될 수 있다. 본 발명에 따르면, 촬영지로부터 멀리 떨어져 있거나 복수의 객체가 인접하여 배치된 신호등 따위의 작은 객체 들에 대한 인식도를 대폭 향상시킬 수 있다. 이상 설명된 본 발명에 따른 실시 예는 컴퓨터상에서 다양한 구성요소를 통하여 실행될 수 있는 컴퓨터 프로그 램의 형태로 구현될 수 있으며, 이와 같은 컴퓨터 프로그램은 컴퓨터로 판독 가능한 매체에 기록될 수 있다. 이 때, 매체는 하드 디스크, 플로피 디스크 및 자기 테이프와 같은 자기 매체, CD-ROM 및 DVD와 같은 광기록 매체, 플롭티컬 디스크(floptical disk)와 같은 자기-광 매체(magneto-optical medium), 및 ROM, RAM, 플래시 메모리 등과 같은, 프로그램 명령어를 저장하고 실행하도록 특별히 구성된 하드웨어 장치를 포함할 수 있다. 한편, 상기 컴퓨터 프로그램은 본 발명을 위하여 특별히 설계되고 구성된 것이거나 컴퓨터 소프트웨어 분야의 당업자에게 공지되어 사용 가능한 것일 수 있다. 컴퓨터 프로그램의 예에는, 컴파일러에 의하여 만들어지는 것 과 같은 기계어 코드뿐만 아니라 인터프리터 등을 사용하여 컴퓨터에 의해서 실행될 수 있는 고급 언어 코드도 포함될 수 있다. 본 발명에서 설명하는 특정 실행들은 일 실시 예들로서, 어떠한 방법으로도 본 발명의 범위를 한정하는 것은 아 니다. 명세서의 간결함을 위하여, 종래 전자적인 구성들, 제어 시스템들, 소프트웨어, 상기 시스템들의 다른 기 능적인 측면들의 기재는 생략될 수 있다. 또한, 도면에 도시된 구성 요소들 간의 선들의 연결 또는 연결 부재들 은 기능적인 연결 및/또는 물리적 또는 회로적 연결들을 예시적으로 나타낸 것으로서, 실제 장치에서는 대체 가 능하거나 추가의 다양한 기능적인 연결, 물리적인 연결, 또는 회로 연결들로서 나타내어질 수 있다. 또한, “필 수적인”, “중요하게” 등과 같이 구체적인 언급이 없다면 본 발명의 적용을 위하여 반드시 필요한 구성 요소 가 아닐 수 있다. 본 발명의 명세서(특히 특허청구범위에서)에서 “상기”의 용어 및 이와 유사한 지시 용어의 사용은 단수 및 복 수 모두에 해당하는 것일 수 있다. 또한, 본 발명에서 범위(range)를 기재한 경우 상기 범위에 속하는 개별적인 값을 적용한 발명을 포함하는 것으로서(이에 반하는 기재가 없다면), 발명의 상세한 설명에 상기 범위를 구성하 는 각 개별적인 값을 기재한 것과 같다. 마지막으로, 본 발명에 따른 방법을 구성하는 단계들에 대하여 명백하 게 순서를 기재하거나 반하는 기재가 없다면, 상기 단계들은 적당한 순서로 행해질 수 있다. 반드시 상기 단계 들의 기재 순서에 따라 본 발명이 한정되는 것은 아니다. 본 발명에서 모든 예들 또는 예시적인 용어(예들 들어, 등등)의 사용은 단순히 본 발명을 상세히 설명하기 위한 것으로서 특허청구범위에 의해 한정되지 않는 이 상 상기 예들 또는 예시적인 용어로 인해 본 발명의 범위가 한정되는 것은 아니다. 또한, 당업자는 다양한 수정, 조합 및 변경이 부가된 특허청구범위 또는 그 균등물의 범주 내에서 설계 조건 및 팩터에 따라 구성될 수 있음을 알 수 있다.도면 도면1 도면2 도면3 도면4a 도면4b 도면5 도면6 도면7 도면8 도면9 도면10 도면11 도면12 도면13 도면14 도면15"}
{"patent_id": "10-2023-0080455", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1 내지 도 3은 일 실시예에 따른 자율 주행 방식을 설명하기 위한 도면들이다. 도 4a 및 도 4b는 일 실시예에 따른 차량 외부를 촬영하는 카메라와 관련된 도면이다. 도 5는 일 실시예에 따른 객체 인식 방법을 설명하는 개략도이다. 도 6은 본 발명에 따른 객체 인식도 향상 방법의 일 실시예를 도식적으로 설명하기 위한 도면이다. 도 7은 본 발명에 따른 객체 인식도 향상 방법의 다른 일 실시예를 도식적으로 설명하기 위한 도면이다. 도 8은 본 발명에 따른 객체 인식도 향상 방법의 또 다른 일 실시예를 도식적으로 설명하기 위한 도면이다. 도 9는 본 발명에 따른 객체 인식도 향상 방법의 일 예를 흐름도로 나타낸 도면이다. 도 10은 객체 인식도 향상 장치가 분할영상의 중복 영역의 크기를 결정하는 프로세스를 설명하기 위한 도면이다. 도 11은 객체 인식도 향상 장치가 종분할선을 기준으로 분할영상을 생성하는 경우를 설명하기 위한 도면이다. 도 12는 객체 인식도 향상 장치가 횡분할선을 기준으로 분할영상을 생성하는 경우를 설명하기 위한 도면이다. 도 13은 객체 인식도 향상 장치에서 객체 인식 모듈에 입력될 영상을 변환하는 프로세스의 다른 일 실시예를 설 명하기 위한 도면이다. 도 14는 객체 인식도 향상 장치에서 객체 인식 모듈에 입력될 영상을 변환하는 프로세스의 또 다른 일 실시예를 설명하기 위한 도면이다. 도 15는 일 실시예에 따른 객체 인식도 향상 장치의 블록도이다."}
