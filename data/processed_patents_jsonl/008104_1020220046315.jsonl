{"patent_id": "10-2022-0046315", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0147378", "출원번호": "10-2022-0046315", "발명의 명칭": "GPGPU 환경에서의 타일링 기반 GEMM에 대하여 지도 학습 기법을 활용한 타일링 파라미터 예측", "출원인": "한양대학교 산학협력단", "발명자": "박영준"}}
{"patent_id": "10-2022-0046315", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "GPGPU 환경에서의 타일링 기반 GEMM에 대하여 지도 학습 기법을 활용한 타일링 파라미터 예측 방법에 있어서,타일링 기반 GEMM(GEneral Matrix Multiplication)을 사용하는 GPU 환경에서 DNN 응용의 정보를 분석하여 합성데이터 세트를 생성하는 단계;상기 합성 데이터 세트를 기반으로 완전 연결 계층(fully-connected layer)으로 구성된 인공 신경망 모델을 학습하는 단계; 상기 학습된 모델을 사용하여 타겟 DNN 응용의 레이어 정보 및 타겟 CPU의 정보를 기반으로 타일링 파라미터를예측하는 단계;상기 예측된 타일링 파라미터를 DNN 응용의 런타임에 해당 타일링 파라미터를 적용하는 단계를 포함하는 것을특징으로 하는 GPGPU 환경에서의 타일링 기반 GEMM에 대하여 지도 학습 기법을 활용한 타일링 파라미터 예측 방법."}
{"patent_id": "10-2022-0046315", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 타일링 기반 GEMM(GEneral Matrix Multiplication)을 사용하는 GPU 환경에서 DNN 응용의 정보를 분석하여합성 데이터 세트를 생성하는 단계는상기 GPU 환경에서 DNN 응용의 각 레이어 별 GEMM의 크기 및 실제 신경망에서 GEMM작업의 각 차원의 범위를 분석하여 합성 데이터 세트를 생성하는 단계를 포함하는 것을 특징으로 하는 GPGPU 환경에서의 타일링 기반 GEMM에 대하여 지도 학습 기법을 활용한 타일링 파라미터 예측 방법."}
{"patent_id": "10-2022-0046315", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,상기 GEMM작업의 각 차원(M, N, K) 중 치수 M은 신경망의 출력 뉴런을 의미하고, 차수 K는 입력 뉴런의 수를 의미하고, 차수 N은 대상 신경망의 배치 크기를 의미하는 것을 특징으로 하는 GPGPU 환경에서의 타일링 기반 GEMM에 대하여 지도 학습 기법을 활용한 타일링 파라미터 예측 방법."}
{"patent_id": "10-2022-0046315", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,각 GEMM 작업에 따라 WT(warp tiles) 크기 및 TBT(threadblock tiles)의 크기를 변경하여 복수의 타일 구성 집합을 정의하는 단계; 및상기 합성 데이터 세트 중 상기 복수의 타일 구성 집합에 대한 브루트 포스를 검색한 후 상기 브루트 포스 검색결과를 최적 타일 구성 테이블로 기록하는 단계를 더 포함하는 것을 특징으로 하는 GPGPU 환경에서의 타일링 기반 GEMM에 대하여 지도 학습 기법을 활용한 타일링 파라미터 예측 방법.공개특허 10-2023-0147378-3-청구항 5 제1항에 있어서,상기 합성 데이터 세트를 기반으로 완전 연결 계층(fully-connected layer)으로 구성된 인공 신경망 모델을 학습하는 단계는상기 합성 데이터 세트의 상기 브루트 포스 검색을 완료한 후 상기 최적 타일 구성 테이블을 사용하여 상기 인공 신경망 모델을 학습하는 단계를 포함하는 것을 특징으로 하는 GPGPU 환경에서의 타일링 기반 GEMM에 대하여 지도 학습 기법을 활용한 타일링 파라미터 예측 방법."}
{"patent_id": "10-2022-0046315", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "타일링 기반 GEMM(GEneral Matrix Multiplication)을 사용하는 GPU 환경에서 DNN 응용의 정보를 분석하여 합성데이터 세트를 생성하는 브루트 포스 검색부;상기 합성 데이터 세트를 기반으로 완전 연결 계층(fully-connected layer)으로 구성된 인공 신경망 모델을 학습하는 모델 트레이닝부; 및상기 학습된 모델을 사용하여 타겟 DNN 응용의 레이어 정보 및 타겟 CPU의 정보를 기반으로 타일링 파라미터를예측하고, 상기 예측된 타일링 파라미터를 DNN 응용의 런타임에 해당 타일링 파라미터를 적용하는 실제 DNN 적용부를 포함하는 것을 특징으로 하는GPGPU 환경에서의 타일링 기반 GEMM에 대하여 지도 학습 기법을 활용한 타일링 파라미터 예측 프레임워크."}
{"patent_id": "10-2022-0046315", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6항에 있어서,상기 브루트 포스 검색부는상기 GPU 환경에서 DNN 응용의 각 레이어 별 GEMM의 크기 및 실제 신경망에서 GEMM작업의 각 차원(M, N, K)의범위를 분석하여 합성 데이터 세트를 생성하는 것을 특징으로 하는GPGPU 환경에서의 타일링 기반 GEMM에 대하여 지도 학습 기법을 활용한 타일링 파라미터 예측 프레임워크."}
{"patent_id": "10-2022-0046315", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서,상기 브루트 포스 검색부는상기 GEMM작업의 각 차원(M, N, K) 중 치수 M은 신경망의 출력 뉴런을 의미하고, 차수 K는 입력 뉴런의 수를 의미하고, 차수 N은 대상 신경망의 배치 크기를 의미하는 것을 특징으로 하는 GPGPU 환경에서의 타일링 기반 GEMM에 대하여 지도 학습 기법을 활용한 타일링 파라미터 예측 프레임워크."}
{"patent_id": "10-2022-0046315", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제7항에 있어서,상기 모델 트레이닝부는각 GEMM 작업에 따라 WT(warp tiles) 크기 및 TBT(threadblock tiles)의 크기를 변경하여 복수의 타일 구성 집합을 정의하고, 상기 합성 데이터 세트 중 상기 복수의 타일 구성 집합에 대한 브루트 포스 검색 후 상기 브루트 포스 검색 결과를 최적 타일 구성 테이블로 기록하는 것을 특징으로 하는 공개특허 10-2023-0147378-4-GPGPU 환경에서의 타일링 기반 GEMM에 대하여 지도 학습 기법을 활용한 타일링 파라미터 예측 프레임워크."}
{"patent_id": "10-2022-0046315", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제6항에 있어서,상기 모델 트레이닝부는상기 합성 데이터 세트의 상기 브루트 포스 검색을 완료한 후 상기 최적 타일 구성 테이블을 사용하여 상기 인공 신경망 모델을 학습하는 것을 특징으로 하는 GPGPU 환경에서의 타일링 기반 GEMM에 대하여 지도 학습 기법을 활용한 타일링 파라미터 예측 프레임워크."}
{"patent_id": "10-2022-0046315", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명의 일 실시예에 따른 GPGPU 환경에서의 타일링 기반 GEMM에 대하여 지도 학습 기법을 활용한 타일링 파라 미터 예측 방법은 타일링 기반 GEMM(GEneral Matrix Multiplication)을 사용하는 GPU 환경에서 DNN 응용의 정보 를 분석하여 합성 데이터 세트를 생성하는 단계, 상기 합성 데이터 세트를 기반으로 완전 연결 계층(fully- connected layer)으로 구성된 인공 신경망 모델을 학습하는 단계, 상기 학습된 모델을 사용하여 타겟 DNN 응용의 레이어 정보 및 타겟 CPU의 정보를 기반으로 타일링 파라미터를 예측하는 단계, 상기 예측된 타일링 파라미터를 DNN 응용의 런타임에 해당 타일링 파라미터를 적용하는 단계를 포함한다."}
{"patent_id": "10-2022-0046315", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 GPGPU 환경에서의 타일링 기반 GEMM에 대하여 지도 학습 기법을 활용한 타일링 파라미터 예측 방법 및 이를 적용한 프레임워크에 관한 것으로, 보다 구체적으로 GPGPU 환경에서의 타일링 기반 GEMM 연산의 최적 타일링 파라미터를 지도 학습 기법을 바탕으로 예측한 후 대상 응용 실행 시 각 GEMM에 대하여 도출된 최적 타 일링 파라미터를 자동으로 적용할 수 있도록 GPGPU 환경에서의 타일링 기반 GEMM에 대하여 지도 학습 기법을 활 용한 타일링 파라미터 예측 방법 및 이를 적용한 프레임워크에 관한 것이다."}
{"patent_id": "10-2022-0046315", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "GPGPU(General-Purpose Computing on Graphics Processing)는 HPC 분야, 게임, 시뮬레이션, 인공지능 분야 등 에 많이 이용되고 그 수가 점점 증가하고 있다. GPU를 사용하여 많은 작업들을 수행하고 GPU의 이용 분야도 다 양하게 발전하고 있다. 최신의 GPU는 그래픽 처리뿐 아니라 GPGPU 프로그램을 지원하는 고성능의 데이터 병렬 연산을 제공하고 있다. 또한 대량의 스레드를 생성하여 처리할 수 있도록 그 성능도 계속 발전하고 있다. 이러한 GPGPU 환경에서의 GEMM(GEneral Matrix Multiplication) 연산은 최근 딥러닝 연구에서 가장 중요한 연 산 중 하나이다. GPU용 최신 대수(linear algebra) 알고리즘 템플릿에서는 타일링 기반 GEMM 연산을 통해 높은 성능을 제공한다. 최적의 GEMM 성능을 위해서는 가장 적합한 타일링 파라미터를 찾는 것이 중요하다. 하지만 매번 수십, 수백개의 가용한 모든 타일링 파라미터를 고려하는 것은 매우 비효율적이다. 이에 더불어, 숙련된 프로그래머가 최적의 타일링 파라미터를 예측하는 것은 대상 GEMM의 크기 및 모양, 그리고 대상 GPU의 구조 등이 성능에 크게 영향을 끼치므로 상당히 어려운 작업이다."}
{"patent_id": "10-2022-0046315", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 타일링 기반 GEMM을 사용하는 GPU 환경에서 대상 DNN 응용의 각 레이어에 따른 최적의 타일링 파라미 터를 실시간으로 예측하여 상황에 맞게 적용할 수 있는 GPGPU 환경에서의 타일링 기반 GEMM에 대하여 지도 학습 기법을 활용한 타일링 파라미터 예측 방법 및 이를 적용한 프레임워크를 제공하는 것을 목적으로 한다. 또한, 본 발명은 GPGPU 환경에서의 타일링 기반 GEMM 연산의 최적 타일링 파라미터를 지도 학습 기법을 바탕으 로 예측한 후 대상 응용 실행 시 각 GEMM에 대하여 도출된 최적 타일링 파라미터를 자동으로 적용할 수 있도록 GPGPU 환경에서의 타일링 기반 GEMM에 대하여 지도 학습 기법을 활용한 타일링 파라미터 예측 방법 및 이를 적 용한 프레임워크를 제공하는 것을 목적으로 한다. 본 발명의 목적들은 이상에서 언급한 목적으로 제한되지 않으며, 언급되지 않은 본 발명의 다른 목적 및 장점들 은 하기의 설명에 의해서 이해될 수 있고, 본 발명의 실시예에 의해 보다 분명하게 이해될 것이다. 또한, 본 발 명의 목적 및 장점들은 특허 청구 범위에 나타낸 수단 및 그 조합에 의해 실현될 수 있음을 쉽게 알 수 있을 것 이다."}
{"patent_id": "10-2022-0046315", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "이러한 목적을 달성하기 위한 GPGPU 환경에서의 타일링 기반 GEMM에 대하여 지도 학습 기법을 활용한 타일링 파 라미터 예측 방법은 타일링 기반 GEMM(GEneral Matrix Multiplication)을 사용하는 GPU 환경에서 DNN 응용의 정보를 분석하여 합성 데이터 세트를 생성하는 단계, 상기 합성 데이터 세트를 기반으로 완전 연결 계층(fully- connected layer)으로 구성된 인공 신경망 모델을 학습하는 단계, 상기 학습된 모델을 사용하여 타겟 DNN 응용 의 레이어 정보 및 타겟 CPU의 정보를 기반으로 타일링 파라미터를 예측하는 단계, 상기 예측된 타일링 파라미 터를 DNN 응용의 런타임에 해당 타일링 파라미터를 적용하는 단계를 포함한다. 또한, 이러한 목적을 달성하기 위한 GPGPU 환경에서의 타일링 기반 GEMM에 대하여 지도 학습 기법을 활용한 타 일링 파라미터 예측 프레임워크는 타일링 기반 GEMM(GEneral Matrix Multiplication)을 사용하는 GPU 환경에서 DNN 응용의 정보를 분석하여 합성 데이터 세트를 생성하는 브루트 포스 검색부, 상기 합성 데이터 세트를 기반 으로 완전 연결 계층(fully-connected layer)으로 구성된 인공 신경망 모델을 학습하는 모델 트레이닝부 및 상 기 학습된 모델을 사용하여 타겟 DNN 응용의 레이어 정보 및 타겟 CPU의 정보를 기반으로 타일링 파라미터를 예 측하고, 상기 예측된 타일링 파라미터를 DNN 응용의 런타임에 해당 타일링 파라미터를 적용하는 실제 DNN 적용 부를 포함한다."}
{"patent_id": "10-2022-0046315", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "전술한 바와 같은 본 발명에 의하면, 타일링 기반 GEMM을 사용하는 GPU 환경에서 대상 DNN 응용의 각 레이어에 따른 최적의 타일링 파라미터를 실시간으로 예측하여 상황에 맞게 적용할 수 있다는 장점이 있다. 또한 본 발명에 의하면, GPGPU 환경에서의 타일링 기반 GEMM 연산의 최적 타일링 파라미터를 지도 학습 기법을 바탕으로 예측한 후 대상 응용 실행 시 각 GEMM에 대하여 도출된 최적 타일링 파라미터를 자동으로 적용할 수 있다는 장점이 있다."}
{"patent_id": "10-2022-0046315", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "전술한 목적, 특징 및 장점은 첨부된 도면을 참조하여 상세하게 후술되며, 이에 따라 본 발명이 속하는 기술분 야에서 통상의 지식을 가진 자가 본 발명의 기술적 사상을 용이하게 실시할 수 있을 것이다. 본 발명을 설명함 에 있어서 본 발명과 관련된 공지 기술에 대한 구체적인 설명이 본 발명의 요지를 불필요하게 흐릴 수 있다고 판단되는 경우에는 상세한 설명을 생략한다. 이하, 첨부된 도면을 참조하여 본 발명에 따른 바람직한 실시예를상세히 설명하기로 한다. 도면에서 동일한 참조부호는 동일 또는 유사한 구성요소를 가리키는 것으로 사용된다. 본 명세서에서 사용된 용어 중 “타일링 기반 GEMM (GEneral Matrix Multiplication)”은 타일링 기반 GEMM에 서는 GPU 등의 병렬 프로세서에서 가용한 모든 자원 활용을 극대화하기 위해 전체 워크로드를 타일로 구분하여 가용한 연산 코어에 균형적으로 할당한다. 타일링 파라미터에 따라 GPU의 자원 활용률이 많은 영향을 받으므로 타일의 크기와 모양을 최적으로 설정하는 것이 중요한 연산이다. 본 명세서에서 사용된 용어 중 “ 지도 학습 기법 (Supervised Learning)”은 분류(classification) 문제를 위 한 기계 학습(machine learning) 기법 중 하나로, 선행 지식으로부터 습득된 많은 수의 분류 결과들을 통해 모 델을 학습하고, 새로운 데이터에 대한 분류를 수행하는 기법이다. 본 명세서에서 사용된 용어 중 “CUDA MPS (CUDA Multi-Process Service)”는 GPU 기반 환경에서의 다중 프로 세스 처리를 지원하는 솔루션이다. 특히, 사용자가 대상 GPU에서 활성화 할 컴퓨팅 코어의 수를 조절할 수 있는 기능을 포함하고 있다. 도 1은 종래의 타일 기반 CUTLAS GEMM 작동 과정을 설명하기 위한 도면이다. 도 1을 참조하면, CUTLASS 라이브러리에서 전체 작업량은 효율적인 GEMM 실행을 위해 다중 스레드 블록 타일 (TBT)과 워프 타일(WT)로 나뉜다. 도 1은 출력 매트릭스에서 TBT와 WT를 정의하는 방법과 입력 매트릭스의 어떤 부분이 각 TBT와 관련이 있는지를 간략하게 보여준다. 여기서, 출력 매트릭스는 먼저 동일한 크기의 여러 개의 2차원 TBT로 분할되고, TBT는 여러 개의 2차원 WT로 더 분할된다. 각 TBT는 두 입력 매트릭스의 해당 행 데이터와 열 데이터를 로드하여 GPU 공유 메모리에 저장한다. TBT의 각 워프타일은 공유 메모리에 저장된 해당 입력 매트릭스 데이터를 레지스터 파일로 순차적으로 가져오고 외부 생성물 기반 매트릭스 곱셈 방법을 통해 GEMM 연산을 수행한다. TBT와 WT의 모양은 타일 구성에 대한 일부 제약 조건이 충족되면 결정할 수 있다. CUTLASS의 TBT와 WT는 각각 GPU의 스레드 블록과 워프 구조에 해당한다. 런타임에 GPU의 스트리밍 멀티프로세서 (SM) 코어에서 각 스레드 블록(또는 TBT)의 할당은 동시에 할당될 수 있는 최대량을 기반으로 한다. 스트리밍 멀티프로세서(SM)에 동시에 할당할 수 있는 스레드 블록의 수는 대상 GPU 구조의 SM 내 리소스 또는 각 스레드 블록 타일당 WT 수에 따라 달라진다. 즉, 도 1의 TBTm, TBTn, WTm, WTn 계수를 설정하여 각 타일의 크기를 결정하는 것은 대상 GPU의 총 리소스 활용 도에 큰 영향을 미친다. 도 2는 대상 GEMM 별, GPU 별 타일링 파라미터에 따른 GEMM 성능 차이를 설명하기 위한 그래프이다. 도 2를 참조하면, 최적의 타일 구성을 찾으려면 특정 최상의 타일 모양을 찾기 전에 타일 크기를 결정하는 것이 중요하다. 그림 2(a)는 TBT 크기를 변경할 때 2080Ti GPU에서 입력 매트릭스 크기가 다른 4개의 GEMM 작업의 상 대적인 성능을 보여준다. 그림 2(a)에서 x축은 기본 타일 크기의 1/2에서 1/4로 감소된 순서로 (TBT, WT) 형태의 CUTLASS 타일 구성을 나 타낸다. Y축은 기본 타일 구성의 성능에 대해 정규화된 상대적인 GEMM 성능을 나타낸다. 그림 2(a)에서 작은 GEMM 작업(128×128×128, 512×512×512)의 성능은 타일 크기가 작아질수록 크게 향상된다. 대상 GEMM 크기가 작을 때 GPU 리소스를 충분히 활용할 수 있는 충분한 수의 TBT를 만들 수 없기 때 문이다. 예를 들어, 대상 출력 매트릭스 크기가 512×512인 대상 GEMM에 대해 TBT가 128128로 설정된 경우 TBT 의 총 수는 16개다. 대상 GPU에 16개 이상의 SM이 있는 경우, TBT는 16개 SM에만 할당되며 다른 SM은 유휴 상태를 유지한다. 따라서, 주어진 SM을 충분히 활용하기 위해 GEMM 작업의 TBT 크기를 더 작은 크기로 조정해야 한다. 그림 2(a)의 대형 GEMM 작업(4096×4096×4096, 8192×4096×4096)의 경우 TBT 크기가 감소하면 GEMM 성능이 거의 개선되지 않거나 약간 감소한다는 점에 유의한다. 이는 충분히 큰 GEMM에 대한 CUTLASS 기본 타일 구성에서도 모든 SM이 이미 충분히 활용되고 있기 때문에 작은 TBT 구성이 최적의 구성이 아닐 수 있기 때문이다. 이러한 GEMM 작업의 경우, 메모리 대역폭 및 컴퓨팅 기능과 같은 다른 아키텍처별 기능은 최적의 타일 구성을 결정하는 데 더 중요한 요소가 될 것이다. 도 2(b)는 다양한 대상 GPU에서 GEMM 작업(2048×1000×3200)을 위해 기본 타일 설정으로 정규화된 5가지 타일 구성의 상대적인 성능을 보여준다. 도 2(b)에서 GPU당 SM의 수는 왼쪽 에서 오른쪽으로 증가한다. 도 2(b)에 표시된 5TBT 크기는 기본 타일 설정보다 작다. 도 2(b)에서 가장 적은 수의 SM으로 구성된 1050Ti는 기본 설정보다 더 나은 성능을 보이지 않는다. 다만 TitanXp와 V100은 SM이 다수 포함돼 TBT 크기가 작을 때 더 나은 성능을 보인다. 2080Ti는 소형 타일 구성에서 도 최고의 성능을 보여준다. 전반적으로, GEMM 작업의 최상의 타일 구성은 대상 GPU 아키텍처에 따라 매우 다양 하므로, 특정 대상 GPU에 대한 정확한 타일 구성을 선택하는 것은 GEMM 성능을 최대화하기 위한 주요 과제이다. 도 3은 RTX 2080 Ti GPU 환경에서 다양한 GEMM에 대해 가용한 타일링 파라미터의 성능 분포를 설명하기 위한 도 면이다. 도 3을 참조하면, 대상 GEMM이 대상 GPU의 크기보다 상대적으로 작을 때, 최적의 타일 구성은 작은 경향이 있다. 그러나 일반적인 추세에도 불구하고 다양한 GEMM 작업에 대한 최적의 TBT 크기 또는 모양을 결정하는 것 은 여전히 매우 어려운 문제이다. 도 3은 2080TI GPU의 실제 신경망에서 여러 GEMM 작업에 대한 최상의 타일 구성의 분포를 보여준다. x축에 표시 된 각 타일 구성은 왼쪽에서 오른쪽으로 TBT 크기가 증가하는 순서로 배열된 GEMM 작업으로부터 얻은 최적의 타 일 구조를 의미한다. Y축은 해당 타일 구성에서 최대 성능을 나타내는 GEMM 작업 수를 나타낸다. 또한 각 막대는 기본 타일 구조에 대한 상대적 성능 이득을 기반으로 한 4가지 GEMM 범주의 분율(0-1.05×, 1.05×-1.25×, 1.25×-1.5× 및 1.5× 이상)을 나타낸다. 도 3은 다양한 GEMM의 최적 TBT 크기가 210 ~ 215 범위로 분포되어 있음을 주로 보여준다. 먼저, 소규모 GEMM에 대한 최적의 TBT 크기를 예상할 수 있다. 그러나 소규모 GEMM 작업에 대한 최적의 TBT 크기가 210 - 212 범위로 분포되어 있기 때문에 여전히 최적이라고 정확한 TBT 크기를 결정할 수 없다. 마찬가지로, 대형 GEMM의 경우에도 최적 TBT 크기가 213에서 215까지 분포 되어 있기 때문에 최적의 TBT 크기를 구체적으로 예측할 수 없다. 따라서, 특정 GEMM 작업 중 최적의 타일 크기 를 찾는 것은 어려운 과제이다. 최적의 CUTLASS 타일 구성을 찾으려면 타일 크기 외에 각 타일의 모양도 신중하게 결정해야 하는데, 이는 도 3 과 같이 가로 세로 비율만 다른 여러 개의 동일한 크기의 타일이 다양한 실용적인 GEMM에 최적으로 보고되기 때 문이다. 보다 구체적으로, 도 3에서 213TBT 크기가 동일한 총 11개의 타일 모양이 최적의 구성으로 선정되었으며, 다른 TBT 크기에서도 유사한 추세를 보인다. 따라서, 최적의 타일 모양을 찾는 것은 GEMM 성능을 최대화하기 위한 또 다른 중요한 과제이다. 도 4 및 도 5는 본 발명의 일 실시예에 따른 GPGPU 환경에서의 타일링 기반 GEMM에 대하여 지도 학습 기법을 활 용한 타일링 파라미터 예측 프레임워크를 설명하기 위한 도면이다. 도 4 및 도 5를 참조하면, 앞서 언급한 문제를 해결하기 위해 다양한 딥 러닝 애플리케이션에서 사용될 다양한 대상 GEMM 연산에 대한 최적의 CUTLASS 타일 구성을 예측하기 위해 효과적인 FCNN 모델을 훈련하는 타일링 파라 미터 예측 프레임워크를 제안한다. 훈련된 모델의 신뢰 수준을 향상시키기 위해 CUTLASS-tailor에 대한 FCNN 교 육은 대표적인 합성 데이터 세트에 의존하며, 이는 실제 신경망용 GEMM 연산의 입력 매트릭스 쌍과 유사하게 생 성된다. 이러한 본 발명의 일 실시예에 따른 GPGPU 환경에서의 타일링 기반 GEMM에 대하여 지도 학습 기법을 활용한 타 일링 파라미터 예측 프레임워크는 브루트 포스 검색부, 모델 트레이닝부 및 실제 NN 적용부를 포함한다. 브루트 포스 검색부는 다양한 DNN 응용의 정보(예를 들어, 각 레이어 별 GEMM의 크기, 종횡비 등)를 분석 하여 합성 데이터 세트를 생성하고, 가용한 타일링 파라미터에 대한 무차별 조사를 진행한다.특히, 대상 GPU 환경에 국한되지 않는 모델을 학습하기 위하여, 브루트 포스 검색부는 CUDA MPS를 통해 활 성화된 GPU 코어의 수를 조절하여 GPU의 구조적 특성이 모델에 반영되도록 훈합성 데이터 세트를 생성한다. FCNN 모델을 효율적으로 훈련하려면 실제 매트릭스 쌍과 유사한 잘 정의된 합성 데이터 세트를 만드는 것이 중 요하다. 합성 데이터 세트를 생성하기 위해 먼저 실제 신경망에서 일반적으로 사용되거나 사용될 가능성이 높은 GEMM 작업의 각 차원(M, N, K)의 범위를 설정한다. [표 1]은 최신 ML 기반 연구에 채택된 FC 레이어의 다양한 형태를 나열한다. 이때, 치수 M과 K는 각각 신경망의 출력 뉴런과 입력 뉴런의 수를 나타낸다. [표 1]"}
{"patent_id": "10-2022-0046315", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "N 차원은 일반적으로 대상 신경망의 배치 크기에 사용된다. [표 1]에 따르면, 여러 네트워크의 뉴런 수는 작거 나(예: 10개, 84개), 또는(예: 9216개) 클 수 있다. 이때, 그 숫자들은 종종 2x의 형태가 아니기 때문에 불규칙 성도 고려되어야 한다. N 차원의 경우 2x이며, 여기서 x는 32, 64, 128 및 256과 같이 8보다 작다. 다양한 신경망 구조 [표 I]의 통찰 력을 바탕으로 먼저 [표 2]의 합성 데이터 세트에 대한 적절한 차원의 기본 세트를 설정했다. 합성 데이터 세트의 M 및 K 차원은 주로 정규 및 비정규 숫자를 모두 다루기 위해 2x 및 1002x 숫자로 구성된다. N 차원은 주로 2x의 정수로 구성되어 있으며, 자주 사용되는 배치 중 일부는 32, 64 및 128이다. M과 K 차원의 경우, 기본 목표값이 기하급수적으로 증가하기 때문에 큰 숫자 사이의 여러 중간 숫자가 추가로 고려 된다. 합성 데이터 세트의 수치적 적용 범위를 확보하기 위해, 브루트 포스 검색부는 지수 성장이 큰 구간의 경 우 2048 및 1600 단계의 정수를 추가한다. 또한 N 차원은 배치 크기 이외의 분류를 위한 다수의 대상 클래스로 도 사용될 수 있으므로, 본 발명은 대상 GEMM이 네트워크의 마지막 수준의 완전히 연결된 계층일 때 N 차원 집 합에 10, 100 및 1000을 추가한다. 위의 고려사항에 기초하여 최종 합성 데이터 세트는 [표 2]로 정의된다. [표 2]"}
{"patent_id": "10-2022-0046315", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "총 3,969개의 합성 GEMM 데이터 세트에는 다양한 GEMM 출력 매트릭스 크기와 가로 세로 비율이 포함되어 있으므 로 일반적으로 사용되는 GEMM의 각 차원을 적절하게 나타낼 수 있다. 모델 트레이닝부는 브루트 포스 검색부로부터 수신된 합성 데이터 세트를 기반으로 완전 연결 계층 (fully-connected layer)으로 구성된 인공 신경망 모델을 학습한다. 이때, 모델 트레이닝부는 문턱 성능 (Threshold performance)을 설정하여 다중 타일링 파라미터를 고려할 수 있는 다중-라벨 분류(Multi-label classification)를 수행하는 모델을 학습한다. 먼저, 모델 트레이닝부는 사용 가능한 타일 구성 집합을 정의한다. 이때, 이론적으로는 모든 TBT(threadblock tiles) 및 WT(warp tiles) 구성을 사용할 수 있지만, 대상 CPU 구조, CUDA 프로그래밍 모델 및 CUTLASS 구현 때문에 모든 조합을 사용할 수 있는 것은 아니다. 따라서 모델 트레이닝부는 다음의 한계 를 고려하여 사용 가능한 타일 구성 집합을 정의한다. 첫째, 각 GEMM 작업의 WT 크기는 TBT 크기를 초과할 수 없다. 둘째, GEMM 작동을 위한 TBT의 각 치수는 해당 WT 치수의 배수여야 한다. 셋째, CUTLASS 라이브러리의 사전 정의된 제한 때문에 WT 크기가 32보다 작을 수 없다. 마지막으로, GPU 실행 모델을 기반으로 한 효율적인 GPU 워프 스케줄링을 보장하기 위해 각 TBT에 대해 4개 이 상의 WT가 권장된다. 그것들을 합쳐서, 모델 트레이닝부는 사용 가능한 총 173개의 커틀라스(CUTLASS) 타 일 구성을 설정한다. 그 후, 모델 트레이닝부는 신속한 교육을 위한 최적의 타일 구성 테이블 구성한다. 숨겨진 레이어 모양 또 는 학습 속도와 같은 다양한 하이퍼 매개 변수를 휩쓸어 정확한 훈련된 모델을 얻기 위해서는 여러 훈련 과정이 필요하다. 따라서, 모델 트레이닝부는 대상 GPU에서 GEMM 작업의 불필요한 반복 컴파일 및 중복 실행을 방지하기 위 해 실제 훈련 전에 각 GEMM의 사용 가능한 타일 구성에 대한 모든 브루트 포스 검색 결과를 최적의 타일 구성 테이블로 기록한다. 상기와 같이, 모델 트레이닝부는 브루트 포스 검색을 완료한 후 사전 구성된 최적 타일 구성 테이블을 사 용하여 모델을 여러 번 훈련시킨다. 그 후, 모델 트레이닝부는 지도 학습 환경을 설정한다. CUTLASS-tailor를 위한 FCNN 네트워크는 동일한 수의 뉴런을 가진 두 개의 완전히 연결된 레이어로 구성되며, 각 레이어를 활성화하기 위해 ReLU 기능이 사용된다. 마지막 5개 레이어에서 softmax를 적용하여 타일 구성을 분류한다. 네트워크 하이퍼 파라미터와 관련하여 배치 크기 또는 학습 속도가 다른 다양한 구성을 시도했으며, 훈련은 배 치 크기가 1이고 학습 속도가 0.001인 구성과 잘 맞는다. 또한 손실 함수를 위해 Adam 최적화 도구와 희소 범주 교차 엔트로피를 채택했다. 훈련 단계는 훈련 정확도가 적절한 수준으로 수렴될 때까지 계속되며, 대부분의 시험에서 1000에폭이면 충분하다. 실제 NN 적용부는 모델 트레이닝부에 의해 학습된 모델을 이용하여 타겟 DNN 응용의 레이어 정보 및 타겟 CPI의 정보를 기반을 최적의 타일링 파라미터를 예측하고 이를 DNN 응용의 런타임에 해당 타일링 파라미터 를 적용한다. 실제 NN 적용부는 오프라인 훈련 중에 습득한 지식을 기반으로 보이지 않는 커널에 대한 최적의 타일 구성 을 예측하는 모델 트레이닝부에 의해 학습된 모델을 참조한다. 추론 단계에서 실제 NN 적용부는 각 대상 GEMM에 대해 몇 번의 시도 후 최적의 성능을 가진 타일 구성을 도출한다. 섹션 V-A2에서 CUTLASS-tailor의 K-times trial에 대한 분석을 Top-K 정확도와 성능으로 다룬다. 그 후, 실제 NN 적용부의 최적의 타일 구성은 CUTLASS 템플릿과 함께 NVCC에 의해 CUDA 커널 바이너리로 컴파일되고, 컴파일된 바이너리는 TensorFlow 프레임워크로 전달된다. 대상 신경망은 완전히 연결된 각 레이어 에 대해 최적의 타일 구성을 적용하는 맞춤형 CUTLASS GEMM 커널을 사용하여 모델을 훈련시킨다. 도 6은 본 발명의 일 실시예에 따른 GPGPU 환경에서의 타일링 기반 GEMM에 대하여 지도 학습 기법을 활용한 타 일링 파라미터 예측 및 실시간 적용 구현 결과도이다. 도 6을 참조하면, GPGPU 환경에서의 타일링 기반 GEMM에 대하여 지도 학습 기법을 활용한 타일링 파라미터 예측 프레임워크는 GPU에서 가용한 GEMM 타일링 파라미터를 모두 분류해낸다. 이때, 대상 GPU 구조에 따라 가용한 타일링 파라미터의 수가 다를 수 있다. 그리고, GPGPU 환경에서의 타일링 기반 GEMM에 대하여 지도 학습 기법을 활용한 타일링 파라미터 예측 프레임워 크는 무차별 대입 검색을 통해 얻은 트레이닝 데이터 세트에서 임계값에 따라 최적의 타일링 파라미터를 분류한 후 트레이닝 데이터 세트에 대하여 정규화 및 파라미터 이진화를 수행한다. GPGPU 환경에서의 타일링 기반 GEMM에 대하여 지도 학습 기법을 활용한 타일링 파라미터 예측 프레임워크는 앞 에서 세팅한 내용을 바탕으로 다중-라벨 분류용 모델 트레이닝을 수행한다. 그 후, GPGPU 환경에서의 타일링 기반 GEMM에 대하여 지도 학습 기법을 활용한 타일링 파라미터 예측 프레임워 크는 트레이닝이 끝난 모델로부터 top-K 순위의 타일링 파라미터를 예측하고, 예측된 타일링 파라미터들을 실시 간으로 각각 수행하고, 이 중 최적의 타일링 파라미터를 응용에 적용한다. 한정된 실시예와 도면에 의해 설명되었으나, 본 발명은 상기의 실시예에 한정되는 것은 아니며, 이는 본 발명이 속하는 분야에서 통상의 지식을 가진 자라면 이러한 기재로부터 다양한 수정 및 변형이 가능하다. 따라서, 본 발명 사상은 아래에 기재된 특허청구범위에 의해서만 파악되어야 하고, 이의 균등 또는 등가적 변형 모두는 본 발명 사상의 범주에 속한다고 할 것이다."}
{"patent_id": "10-2022-0046315", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 종래의 타일 기반 CUTLAS GEMM 작동 과정을 설명하기 위한 도면이다. 도 2는 대상 GEMM 별, GPU 별 타일링 파라미터에 따른 GEMM 성능 차이를 설명하기 위한 그래프이다. 도 3은 RTX 2080 Ti GPU 환경에서 다양한 GEMM에 대해 가용한 타일링 파라미터의 성능 분포를 설명하기 위한 도 면이다. 도 4 및 도 5는 본 발명의 일 실시예에 따른 GPGPU 환경에서의 타일링 기반 GEMM에 대하여 지도 학습 기법을 활 용한 타일링 파라미터 예측 프레임워크를 설명하기 위한 도면이다. 도 6은 본 발명의 일 실시예에 따른 GPGPU 환경에서의 타일링 기반 GEMM에 대하여 지도 학습 기법을 활용한 타 일링 파라미터 예측 및 실시간 적용 구현 결과도이다."}
