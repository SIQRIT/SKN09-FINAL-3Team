{"patent_id": "10-2022-0017437", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0120787", "출원번호": "10-2022-0017437", "발명의 명칭": "챗봇 기반의 비대면 헬스케어 서비스", "출원인": "미디어젠", "발명자": "송민규"}}
{"patent_id": "10-2022-0017437", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "음성 입력부;상기 음성 입력부를 통해 입력된 사용자의 음성에 대해 음성인식 동작을 수행하는 음성 인식부; 및상기 음성 인식부를 통해 추출된 텍스트를 분석하여 상기 사용자 의도(intention)을 추출하고, 미리 정해진 우선순위의 시나리오에 따라 상기 사용자의 의도가 반영된 챗봇 응답을 생성하는 프로세서;를 포함하되,상기 프로세서는,명령어 처리, 질의내용 처리, 일상대화 처리 및 감정(emotion) 처리의 동작을 순차적으로 수행하여 상기 챗봇응답을 출력하도록 제어하는 것을 특징으로 하는 챗봇 대화 처리 장치."}
{"patent_id": "10-2022-0017437", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1 항에 있어서,상기 음성인식의 결과에 기초하여 상기 챗봇 응답을 생성하기 위한 비교 데이터가 저장된 데이터베이스;를 더포함하고,상기 데이터베이스는,상기 추출된 텍스트가 매칭 가능한 복수의 도메인, 상기 복수의 도메인 각각에 포함되는 복수의 카테고리로 구분되고,상기 복수의 도메인은, 미디어, 건강체크, 일반 명령어, 일상 대화, 감정 태그를 포함하는 것을 특징으로 하는챗봇 대화 처리 장치."}
{"patent_id": "10-2022-0017437", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 2 항에 있어서,상기 프로세서는,상기 사용자의 건강상태 정보가 등록된 경우, 상기 데이터베이스의 복수의 도메인 중 상기 건강체크 항목과 상기 등록된 건강상태 정보를 매칭하여 자동으로 챗봇 시스템을 웨이크업 시키고, 상기 건강상태를 질의하는 챗봇질의를 출력하도록 제어하는 것을 특징으로 하는 챗봇 대화 처리 장치."}
{"patent_id": "10-2022-0017437", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 2 항에 있어서,상기 복수의 카테고리는, 상기 챗봇 응답을 생성하기 위한 키워드를 포함하고,상기 프로세서는,상기 음성 인식부를 통해 추출된 텍스트에 상기 데이터 베이스에 저장된 상기 키워드에 매칭되는 경우, 상기 키워드에 기초하여 상기 사용자 의도를 유추하는 것을 특징으로 하는 챗봇 대화 처리 장치."}
{"patent_id": "10-2022-0017437", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "음성 입력부를 통해 입력된 사용자의 음성에 대해 음성인식을 수행하는 단계;상기 음성 인식부를 통해 추출된 텍스트를 분석하여 사용자 의도(intention)를 추출하는 단계;미리 정해진 우선순위의 시나리오에 따라 상기 사용자 의도가 반영된 챗봇 응답을 생성하는 단계;를 포함하되,공개특허 10-2023-0120787-3-상기 미리 정해진 우선순위는,명령어 처리, 질의내용 처리, 일상대화 처리 및 감정(emotion) 처리의 동작을 순차적으로 수행하는 순서인 것을특징으로 하는 챗봇 대화 처리 방법."}
{"patent_id": "10-2022-0017437", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제 5 항에 있어서,상기 음성인식의 결과에 기초하여 상기 챗봇 응답을 생성하기 위한 비교 데이터가 저장된 데이터베이스를 구성하는 단계;를 더 포함하고,상기 데이터베이스는,상기 추출된 텍스트가 매칭 가능한 복수의 도메인(domain), 상기 복수의 도메인 각각에 포함된 복수의 카테고리(category)로 구분되고,상기 복수의 도메인은, 미디어, 건강체크, 일반 명령어, 일상 대화, 감정 태그를 포함하는 것을 특징으로 하는챗봇 대화 처리 방법."}
{"patent_id": "10-2022-0017437", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제 6 항에 있어서,상기 사용자의 건강상태 정보를 등록하는 단계;상기 데이터베이스의 복수의 도메인 중 상기 건강체크 항목과 상기 등록된 건강상태 정보를 매칭하여 자동으로챗봇 시스템을 웨이크업 시키는 단계; 및상기 건강상태를 질의하는 챗봇질의를 출력하도록 제어하는 단계;를 더 포함하는 것을 특징으로 하는 챗봇 대화 처리 방법."}
{"patent_id": "10-2022-0017437", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제 5 항에 있어서,상기 추출된 텍스트를 상기 미리 정해진 우선순위의 시나리오와 비교한 결과, 상기 사용자의 감정상태를 인식한경우, 상기 데이터베이스에 저장된 감정태그에 기초하여 상기 감정 상태를 판단하는 단계; 및상기 판단된 감정상태에 대응되는 상기 챗봇응답을 출력하도록 제어하는 단계;를 더 포함하는 것을 특징으로 하는 챗봇 대화 처리 방법."}
{"patent_id": "10-2022-0017437", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제 5 항 내지 제 8 항 중 어느 한 항에 기재된 챗봇 대화 처리 방법을 실행시키도록 구현되어 컴퓨터 판독 가능한 기록매체에 저장된 컴퓨터 프로그램."}
{"patent_id": "10-2022-0017437", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 명세서의 일 실시예에 따른 챗봇 대화 처리 장치는 음성 입력부; 상기 음성 입력부를 통해 입력된 사용자의 음성에 대해 음성인식 동작을 수행하는 음성 인식부; 및 상기 음성 인식부를 통해 추출된 텍스트를 분석하여 상 기 사용자 의도(intention)을 추출하고, 미리 정해진 우선순위의 시나리오에 따라 상기 사용자의 의도가 반영된 챗봇 응답을 생성하는 프로세서;를 포함하되, 상기 프로세서는, 명령어 처리, 질의내용 처리, 일상대화 처리 및 감정(emotion) 처리의 동작을 순차적으로 수행하여 상기 챗봇 응답을 출력하도록 제어하는 것을 특징으로 한다."}
{"patent_id": "10-2022-0017437", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 명세서는 챗봇 대화 처리 장치 및 방법에 관한 것이다."}
{"patent_id": "10-2022-0017437", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "챗봇(chat bot)은 사용자가 컴퓨터와 문자 또는 음성을 통해 대화를 나누듯이 상호작용할 수 있도록 하는 컴퓨 터 프로그램을 의미할 수 있다. 최근 딥러닝 등 기계학습 기술의 발전과 이를 처리하기 위한 컴퓨터의 성능이 향상됨에 따라 다양한 산업분야에 서 챗봇이 활용되고 있다. 과거에는 주로 기업이 고객을 응대하기 위해 FAQ 형태의 챗봇(자주 묻는 질문에 대 해 정해진 응답을 출력하는 애플리케이션이나 웹 페이지)을 서비스하였으나, 최근에는 스마트폰 등 모바일 기기의 발달로 인해 사용자와 일반적인 문답을 주고 받거나(예를 들어, \"프랑스 수도는 어디야?\" 라고 물으면, \"파 리 입니다\" 라고 답변함) 개인감정을 공유할 수 있는 일상대화형 챗봇이 대중화 되고 있다. 특히, 1인 가구의 증가 및 노인인구의 증가에 따라 타인과 감정을 공유하거나 해소할 수 있는 기회가 적은 계층 에 있어서 인공 지능 기술을 이용하여 가상의 대화를 나누고 감정을 공유할 수 있는 챗봇의 수요가 점차적으로 증가하고 있다. 이러한 감정 공유 챗봇 기술에 있어서 가장 중요한 과제 중 하나는, 사용자의 질문에 대해 정해 진 답변만을 기계적으로 출력하는 것이 아니라 사용자가 실제 사람과 자연스러운 대화를 나누는 듯한 느낌을 갖 도록 하는 것이다. 이를 위해 사용자의 입력에 대한 챗봇의 음성답변에 억양을 추가하는 등으로 시도되고 있으 나, 감정 표현을 적용하기 어려운 문제가 있다."}
{"patent_id": "10-2022-0017437", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 명세서는 전술한 문제점을 해결하기 위한 것으로서, 챗봇에 입력되는 사용자 입력을 미리 정해진 순서에 따 라 분석하여 감정 상태에 대한 대화가 필요한지를 판단함으로써, 감정 상태 기반의 챗봇 응답을 출력할 수 있는 장치 및 방법을 제공한다. 본 발명이 이루고자 하는 기술적 과제들은 이상에서 언급한 기술적 과제들로 제한되지 않으며, 언급되지 않은"}
{"patent_id": "10-2022-0017437", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 2, "content": "또 다른 기술적 과제들은 이하의 발명의 상세한 설명으로부터 본 발명이 속하는 기술분야에서 통상의 지식을 가 진 자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2022-0017437", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 명세서의 일 실시예에 따른 챗봇 대화 처리 장치는, 음성 입력부; 상기 음성 입력부를 통해 입력된 사용자의 음성에 대해 음성인식 동작을 수행하는 음성 인식부; 및 상기 음성 인식부를 통해 추출된 텍스트를 분석하여 상 기 사용자 의도(intention)을 추출하고, 미리 정해진 우선순위의 시나리오에 따라 상기 사용자의 의도가 반영된 챗봇 응답을 생성하는 프로세서;를 포함하되, 상기 프로세서는, 명령어 처리, 질의내용 처리, 일상대화 처리 및 감정(emotion) 처리의 동작을 순차적으로 수행하여 상기 챗봇 응답을 출력하도록 제어한다. 상기 챗봇 대화 처리 장치는, 상기 음성인식의 결과에 기초하여 상기 챗봇 응답을 생성하기 위한 비교 데이터가 저장된 데이터베이스;를 더 포함하고, 상기 데이터베이스는, 상기 추출된 텍스트가 매칭 가능한 복수의 도메인, 상기 복수의 도메인 각각에 포함되는 복수의 카테고리로 구분되고, 상기 복수의 도메인은, 미디어, 건강체크, 일반 명령어, 일상 대화, 감정 태그를 포함할 수 있다. 상기 프로세서는, 상기 사용자의 건강상태 정보가 등록된 경우, 상기 데이터베이스의 복수의 도메인 중 상기 건 강체크 항목과 상기 등록된 건강상태 정보를 매칭하여 자동으로 챗봇 시스템을 웨이크업 시키고, 상기 건강상태 를 질의하는 챗봇 질의를 출력하도록 제어할 수 있다. 상기 복수의 카테고리는, 상기 챗봇 응답을 생성하기 위한 키워드를 포함하고, 상기 프로세서는, 상기 음성 인 식부를 통해 추출된 텍스트에 상기 데이터 베이스에 저장된 상기 키워드에 매칭되는 경우, 상기 키워드에 기초 하여 상기 사용자 의도를 유추할 수 있다. 본 명세서의 다른 실시예에 다른 챗봇 대화 처리 방법은, 음성 입력부를 통해 입력된 사용자의 음성에 대해 음 성인식을 수행하는 단계; 상기 음성 인식부를 통해 추출된 텍스트를 분석하여 사용자 의도(intention)를 추출하 는 단계; 미리 정해진 우선순위의 시나리오에 따라 상기 사용자 의도가 반영된 챗봇 응답을 생성하는 단계;를 포함하되, 상기 미리 정해진 우선순위는, 명령어 처리, 질의내용 처리, 일상대화 처리 및 감정(emotion) 처리의 동작을 순차적으로 수행하는 순서일 수 있다. 상기 챗봇 대화 처리 방법은, 상기 음성인식의 결과에 기초하여 상기 챗봇 응답을 생성하기 위한 비교 데이터가 저장된 데이터베이스를 구성하는 단계;를 더 포함하고, 상기 데이터베이스는, 상기 추출된 텍스트가 매칭 가능 한 복수의 도메인(domain), 상기 복수의 도메인 각각에 포함된 복수의 카테고리(category)로 구분되고, 상기 복 수의 도메인은, 미디어, 건강체크, 일반 명령어, 일상 대화, 감정 태그를 포함할 수 있다. 상기 챗봇 대화 처리 방법은, 상기 사용자의 건강상태 정보를 등록하는 단계; 상기 데이터베이스의 복수의 도메 인 중 상기 건강체크 항목과 상기 등록된 건강상태 정보를 매칭하여 자동으로 챗봇 시스템을 웨이크업 시키는 단계; 및 상기 건강상태를 질의하는 챗봇질의를 출력하도록 제어하는 단계;를 더 포함할 수 있다.상기 챗봇 대화 처리 방법은, 상기 추출된 텍스트를 상기 미리 정해진 우선순위의 시나리오와 비교한 결과, 상 기 사용자의 감정상태를 인식한 경우, 상기 데이터베이스에 저장된 감정태그에 기초하여 상기 감정 상태를 판단 하는 단계; 및 상기 판단된 감정상태에 대응되는 상기 챗봇응답을 출력하도록 제어하는 단계;를 더 포함할 수 있다. 본 명세서의 다른 실시예는 챗봇 대화 처리 방법을 실행시키도록 구현되어 컴퓨터 판독 가능한 기록매체에 저장 된 컴퓨터 프로그램을 포함한다."}
{"patent_id": "10-2022-0017437", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 명세서의 일 실시예에 따르면, 챗봇에 입력되는 사용자 입력을 미리 정해진 순서에 따라 분석하여 감정 상태 에 대한 대화가 필요한지를 판단함으로써, 감정 상태 기반의 챗봇 응답을 출력할 수 있다. 본 발명에서 얻을 수 있는 효과는 이상에서 언급한 효과로 제한되지 않으며, 언급하지 않은 또 다른 효과들은"}
{"patent_id": "10-2022-0017437", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 2, "content": "아래의 기재로부터 본 발명이 속하는 기술분야에서 통상의 지식을 가진 자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2022-0017437", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 첨부된 도면을 참조하여 본 명세서에 개시된 실시예를 상세히 설명하되, 도면 부호에 관계없이 동일하거 나 유사한 구성요소는 동일한 참조 번호를 부여하고 이에 대한 중복되는 설명은 생략하기로 한다. 이하의 설명 에서 사용되는 구성요소에 대한 접미사 \"모듈\" 및 \"부\"는 명세서 작성의 용이함만이 고려되어 부여되거나 혼용 되는 것으로서, 그 자체로 서로 구별되는 의미 또는 역할을 갖는 것은 아니다. 또한, 본 명세서에 개시된 실시 예를 설명함에 있어서 관련된 공지 기술에 대한 구체적인 설명이 본 명세서에 개시된 실시예의 요지를 흐릴 수 있다고 판단되는 경우 그 상세한 설명을 생략한다. 또한, 첨부된 도면은 본 명세서에 개시된 실시예를 쉽게 이 해할 수 있도록 하기 위한 것일 뿐, 첨부된 도면에 의해 본 명세서에 개시된 기술적 사상이 제한되지 않으며, 본 발명의 사상 및 기술 범위에 포함되는 모든 변경, 균등물 내지 대체물을 포함하는 것으로 이해되어야 한다. 제1, 제2 등과 같이 서수를 포함하는 용어는 다양한 구성요소들을 설명하는데 사용될 수 있지만, 상기 구성요소 들은 상기 용어들에 의해 한정되지는 않는다. 상기 용어들은 하나의 구성요소를 다른 구성요소로부터 구별하는 목적으로만 사용된다. 어떤 구성요소가 다른 구성요소에 \"연결되어\" 있다거나 \"접속되어\" 있다고 언급된 때에는, 그 다른 구성요소에 직접적으로 연결되어 있거나 또는 접속되어 있을 수도 있지만, 중간에 다른 구성요소가 존재할 수도 있다고 이 해되어야 할 것이다. 반면에, 어떤 구성요소가 다른 구성요소에 \"직접 연결되어\" 있다거나 \"직접 접속되어\" 있 다고 언급된 때에는, 중간에 다른 구성요소가 존재하지 않는 것으로 이해되어야 할 것이다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 출원에서, \"포함한다\" 또는 \"가지다\" 등의 용어는 명세서상에 기재된 특징, 숫자, 단계, 동작, 구성요소, 부 품 또는 이들을 조합한 것이 존재함을 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성요소, 부품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되어야 한다. 도 1은 본 명세서의 일 실시예에 따른 대화형 챗봇 시스템의 구성을 설명하기 위한 도면이다. 도 1을 참조하면, 챗봇 시스템은 자연어 이해(Natural Language Understanding, NLU) 모듈, 대화 운영 체제 모델, 데이터 베이스, 응답생성기를 포함할 수 있다. 실시예에 따라 챗봇 시스템은 챗봇 응답출력 인터페이스를 포함할 수 있으며, 상기 챗봇 응답 출력 인터페이스는 오디오 출력부, 디스플레이부 등 을 포함할 수 있다.\"나 오늘 슬픈일이 있었어\"를 이해하고 그에 해당하는 정보(대화문)를 대화운영체제 모델 (Dialogue Management Model, DMM)을 통해서 추출하여 화자에게 음성이나 문자로 \"슬픈일이 있더라도 용기를 잃 지 마세요\"로 챗봇 응답을 출력할 수 있다. 상기 챗봇 응답은 NLU, DMM을 거쳐서 해독한 후 필요한 정보를 데이터 베이스에 API 콜을 전송할 수 있다. 이 때 경우에 따라 사용자의 요구 문장을 해독할 때, 지난 대화 정보와 챗봇의 처리된 응답, API 검색 정보 결과가 추가적으로 활용될 수도 있다. API 콜로 데이터베이스에서 구한 정보를 DMM에서 챗봇 응답 문장으로 만들어 응답 생성기(Message Generator, 14)에 보내서 응답 문장을 출력한다. 이와 같은 방식으로 사용자가 요구하는 정보를 찾아서 사용자 에게 출력하는 방식으로 챗봇 대화가 진행될 수 있다. NLU는 음성언어처리 모델(ASR)의 결과에 기초하여 사용자의 의도(intent) 및 상기 의도 중 구체적인 요구사 항(entities)를 추론할 수 있다. 이상, 챗봇 시스템의 기본적인 아키텍처에 대하여 설명하였으며, 도 2를 참조하여 챗봇 대화 처리 장치에 대하 여 구체적으로 설명한다. 도 2는 본 명세서의 일 실시예에 따른 챗봇 대화 처리 장치의 블록도이다. 도 2를 참조하면, 본 명세서의 일 실시예에 따른 챗봇 대화 처리 장치는, 오디오 출력 장치, 입력 장치 (120, 출력 장치, 프로세서, 메모리, 데이터 베이스, 음성 처리 장치를 포함할 수 있다. 여기서, 음성 처리 장치는 음성인식 모듈(ASR, 171), AI 에이전트, NLU 모듈, TTS 모듈 을 포함할 수 있다. 입력 장치는 마이크로폰, 터치 입력 장치, 키보드, 마우스, 스타일러스 또는 다른 입력 장치와 같은 오디 오 출력 장치를 포함할 수 있다. 상기 출력 장치는 디스플레이(visual display or tactile display), 오디오 스피커, 헤드폰, 프린터 또는 기타 출력 장치가 포함될 수 있다. 입력 장치 및/또는 출 력 장치는 또한 USB(Universal Serial Bus), FireWire, Thunderbolt 또는 다른 연결 프로토콜과 같은 외 부 주변 장치 연결용 인터페이스를 포함할 수 있다. 입력 장치 및/또는 출력 장치는 또한 이더넷 포 트, 모뎀 등과 같은 네트워크 연결을 포함할 수 있다. 무선 주파수(RF), 적외선(infrared), 블루투스 (Bluetooth), 무선 근거리 통신망(WLAN)(WiFi 등)과 같은 무선 통신 장치 또는 5G 네트워크, LTE(Long Term Evolution) 네트워크, WiMAN 네트워크, 3G 네트워크와 같은 무선 네트워크 무선 장치를 포함할 수 있다. TTS 장 치는 입력 장치 및/또는 출력 장치를 통해 인터넷 또는 분산 컴퓨팅 환경(distributed computing environment)을 포함할 수도 있다. 프로세서 는 데이터를 처리하기 위한 CPU, 데이터를 처리하는 컴퓨터 판독 가능한 명령 및 데이터 및 명령 들을 저장하기 위한 메모리에 대응될 수 있다. 상기 메모리는 휘발성 RAM, 비휘발성 ROM 또는 다른 타입의 메모리를 포함할 수 있다. 데이터 베이스는 음성인식을 위한 제1 데이터베이스와, 음성인식 결과를 활용하여 음성합성을 위한 제2 데 이터베이스로 구분될 수 있다. 상기 제1 데이터베이스는 사용자의 의도를 추론하기 위한 적어도 하나의 도메인 및 상기 각각의 도메인에 포함되어 사용자의 의도를 추론하는데 활용되는 카테고리를 포함할 수 있다. 상기 제2 데이터 베이스는 발화 내용에 대응되는 음성 유닛을 포함할 수 있다. 한편, 챗봇 대화 처리 장치는 음성 처리 모듈을 포함할 수 있다. 음성 처리모듈은 자동 음성 인식 (Auto Speech Recognition, ASR) 모듈, 지능형 에이전트(Artificial Intelligent Agent), 자연어 이 해(Natural Language Understanding, NLU) 모듈, 텍스트 음성 변환(Text-to-Speech, TTS) 모듈를 포 함할 수 있다. ASR 모듈은 수신된 사용자 음성 입력을 텍스트 데이터로 변환할 수 있다. ASR 모듈은 프론트-엔드 스피치 프리프로세서(front-end speech pre-processor)를 포함할 수 있다. 프론 트-엔드 스피치 프리프로세서는 스피치 입력으로부터 대표적인 특징을 추출한다. 예를 들어, 프론트-엔드 스피 치 프리프로세서는 스피치 입력을 푸리에 변환을 수행하여 대표적인 다차원 벡터의 시퀀스로서 스피치 입력을 특징짓는 스펙트럼 특징을 추출한다. 또한, ASR 모듈은 하나 이상의 스피치 인식 모델(예컨대, 음향 모델 및/또는 언어 모델)을 포함하고, 하나 이상의 스피치 인식 엔진을 구비할 수 있다. 스피치 인식 모델의 예는 은 닉 마르코프 모델(hidden Markov models), 가우시안 혼합 모델(Gaussian-Mixture Models), 딥 신경망 모델 (Deep Neural Network Models), n-gram 언어 모델, 및 기타 통계 모델을 포함할 수 있다. 스피치 인식 엔진의 예는 동적 시간 왜곡 기반 엔진 및 가중치 유한 상태 변환기(WFST) 기반 엔진을 포함할 수 있다. 하나 이상의 스피치 인식 모델 및 하나 이상의 스피치 인식 엔진은 중간 인식 결과들(예를 들어, 음소, 음소 문자열, 및 하 위 단어들), 및 궁극적으로 텍스트 인식 결과들(예컨대, 단어, 단어 문자열, 또는 토큰들의 시퀀스)을 생성하기 위해 프론트-엔드 스피치 프리프로세서의 추출된 대표 특징들을 처리하는 데 사용될 수 있다. ASR 모듈이 텍스트 문자열(예를 들어, 단어들, 또는 단어들의 시퀀스, 또는 토큰들의 시퀀스)을 포함하는 인식 결과를 생성하면, 인식 결과는 의도 추론을 위해 자연 언어 처리 모듈로 전달될 수 있다. 일부 예들 에서, ASR 모듈은 스피치 입력의 다수의 후보 텍스트 표현들을 생성한다. 각각의 후보 텍스트 표현은 스피 치 입력에 대응하는 단어들 또는 토큰들의 시퀀스이다. NLU 모듈은 문법적 분석(Syntactic analyze) 또는 의미적 분석(Semantic analyze)을 수행하여 사용자 의 도를 파악할 수 있다. 상기 문법적 분석은 문법 단위(예를 들어, 단어, 구, 형태소 등)를 나누고, 나누어진 단 위가 어떠한 문법적인 요소를 갖는지 파악할 수 있다. 상기 의미적 분석은 의미(semantic) 매칭, 룰(rule) 매칭, 포뮬러(formula) 매칭 등을 이용하여 수행할 수 있다. 이에 따라, NUL 모듈은 사용자 입력이 어느 도메인(domain), 의도(intent) 또는 상기 의도를 표현하는데 필요한 파라미터(parameter)를 획득할 수 있다. 상기 NLU 모듈은 도메인, 의도 및 상기 의도를 파악하는데 필요한 파라미터로 나누어진 매핑 규칙을 이용 하여 사용자의 의도 및 파라미터를 결정할 수 있다. 예를 들어, 하나의 도메인(예를 들어, 건강상태 체크)은 복 수의 의도(예를 들어, 복약, 걷기, 식사, 기상, 컨디션, 통증, 수면)를 포함할 수 있고, 하나의 의도는 복수의 파라미터(예를 들어, 시간, 반복 횟수, 알람음 등)을 포함할 수 있다. 복수의 룰은, 예를 들어, 하나 이상의 필 수 요소 파라미터를 포함할 수 있다. 상기 매칭 규칙은 자연어 이해 데이터 베이스(Natural Language Understanding Database)에 저장될 수 있다. 상기 NLU 모듈은 형태소, 구 등의 언어적 특징(예를 들어, 문법적 요소)을 이용하여 사용자 입력으로부터 추출된 단어의 의미를 파악하고, 상기 파악된 단어의 의미를 도메인 및 의도에 매칭시켜 사용자의 의도를 결정 한다. 예를 들어, NLU 모듈은 각각의 도메인 및 의도에 사용자 입력에서 추출된 단어가 얼마나 포함되어 있는지를 계산하여 사용자 의도를 결정할 수도 있다. 일 실시예에 따르면, NLU 모듈은 상기 의도를 파악하 는데 기초가된 단어를 이용하여 사용자 입력의 파라미터를 결정할 수 있다. 일 실시예에 따르면, NLU 모듈(17 3)은 사용자 입력의 의도를 파악하기 위한 언어적 특징이 저장된 자연어 인식 데이터 베이스를 이용하여 사용자 의 의도를 결정할 수 있다. 또한 일 실시예에 따르면, NLU 모듈은 개인화 언어 모델(personal language model, PLM)을 이용하여 사용자의 의도를 결정할 수 있다. 예를 들어, NLU 모듈은 개인화된 정보(예를 들 어, 병원 방문기록, 병원 진단 기록, 복용 중인 약품 정보 등)을 이용하여 사용자의 의도를 결정할 수 있다. 상 기 개인화 언어 모델은, 예를 들어, 자연어 인식 데이터 베이스에 저장될 수 있다. 일 실시예에 따르면, NLU 모 듈 뿐 아니라 ASR 모듈도 자연어 인식 데이터 베이스에 저장된 개인화 언어 모델을 참고하여 사용자 음성을 인식할 수 있다. NLU 모듈은 자연어 생성 모듈(미도시)을 더 포함할 수 있다. 상기 자연어 생성 모듈은 지정된 정보를 텍스 트 형태로 변경할 수 있다. 상기 텍스트 형태로 변경된 정보는 자연어 발화의 형태일 수 있다. 상기 지정된 정 보는 예를 들어, 추가 입력에 대한 정보, 사용자 입력에 대응되는 동작의 완료를 안내하는 정보 또는 사용자의 추가 입력을 안내하는 정보 등을 포함할 수 있다. 상기 텍스트 형태로 변경된 정보는 클라이언트 디바이스로 전 송되어 디스플레이에 표시되거나, TTS 모듈로 전송되어 음성 형태로 변경될 수 있다. 음성 합성 모듈(TTS 모듈, 174)은 텍스트 형태의 정보를 음성 형태의 정보로 변경할 수 있다. TTS 모듈은 NLU 모듈의 자연어 생성 모듈로부터 텍스트 형태의 정보를 수신하고, 상기 텍스트 형태의 정보를 음성 형 태의 정보로 변경하여 음성 형태의 정보를 스피커를 통해 출력할 수 있다. 음성 합성 모듈은 제공된 텍스트에 기초하여 스피치 출력을 합성한다. 예를 들어, 음성 인식 모듈 (ASR)에서 생성된 결과는 텍스트 문자열의 형태이다. 음성 합성 모듈은 텍스트 문자열을 가청 스피치출력으로 변환한다. 음성 합성 모듈은, 텍스트로부터의 스피치 출력을 생성하기 위하여 임의의 적절한 스 피치 합성 기법을 사용하는데, 이는 편집 합성(concatenative synthesis), 단위 선택 합성(unit selection synthesis), 다이폰 합성, 도메인-특정 합성, 포먼트 합성(Formant synthesis), 조음 합성(Articulatory synthesis), HMM(hidden Markov model) 기반 합성, 및 정현파 합성(sinewave synthesis)을 포함하지만 이로 한 정되지 않는다. 일부 예들에서, 음성 합성 모듈은 단어들에 대응하는 음소 문자열에 기초하여 개별 단어들을 합성하도록 구성된다. 예를 들어, 음소 문자열은 생성된 텍스트 문자열의 단어와 연관된다. 음소 문자열은 단어와 연관된 메타데이터에 저장된다. 음성 합성 모듈은 스피치 형태의 단어를 합성하기 위해 메타데이터 내의 음소 문 자열을 직접 프로세싱하도록 구성된다. 한편, 본 발명의 일 실시예에 따른 챗봇 대화 처리 장치는 지능형 에이전트(Artificial Intelligence Agent, AI 에이전트)를 더 포함할 수 있다. 상기 지능형 에이전트는 전술한 ASR 모듈, NLU 모듈 및/또는 TTS 모듈이 수행하는 기능 중 적어도 일부의 기능을 수행하도록 설계될 수 있다. 또한 상기 지능 형 에이전트 모듈은 ASR 모듈, NLU 모듈 및/또는 TTS 모듈 각각의 독립적인 기능을 수행하 는데 기여할 수 있다. 상기 지능형 에이전트 모듈은 심층학습(딥러닝)을 통해 전술한 기능들을 수행할 수 있다. 상기 심층학습은 심층 신경망(DNN, deep neural networks), 합성곱 신경망(CNN, convolutional deep neural networks), 순환 신 경망(RNN, Recurrent Boltzmann Machine), 제한 볼츠만 머신(RBM, Restricted Boltzmann Machine), 심층 신뢰 신경망(DBN, deep belief networks), 심층 Q-네트워크(Deep Q-Network)와 같은 다양한 딥 러닝 기법들이 컴퓨 터비젼, 음성인식, 자연어처리, 음성/신호처리 등의 분야에 적용될 수 있다. 지능형 에이전트 모듈은 자연어 처리 분야에서 심층 인공신경망 구조를 이용하여 자동 번역(machine translation), 감정 분석(emotion analysis), 정보 검색(information retrieval)을 비롯한 다양한 자연언어처 리 과정을 수행할 수 있다. 한편, 상기 챗봇 대화 처리 장치는, 다양한 개인화된 정보를 수집하여 상기 지능형 에이전트의 기능을 지원할 수 있는 서비스 매니저(service manager)를 더 포함할 수 있다. 상기 서비스 매니저를 통해 획득되는 개인화된 정보는, 클라이언트 디바이스가 클라우드 환경을 통해 이용하는 적어도 하나의 데이터(캘린더 애플리케이션, 메 시징 서비스, 건강관리 애플리케이션 사용 등)를 포함할 수 있다. 예를 들어, 상기 개인화된 정보는, 맵(maps), SMS, News, Music, Stock, Weather, wikipedia 정보를 포함할 수 있다. 상기 지능형 에이전트은 설명의 편의를 위해 ASR 모듈, NLU 모듈 및 TTS 모듈과 구분되도 록 별도의 블럭으로 표현하였으나, 상기 지능형 에이전트는 상기 각 모듈(171,173,174)의 적어도 일부 또 는 전부의 기능을 수행할 수도 있다. 도 3은 본 명세서의 일 실시예에 따른 챗봇 대화 처리 방법의 흐름도이다. 도 3에 도시된 방법은 도 2의 프로세 서를 통해 구현될 수 있다. 프로세서는 챗봇 대화 처리 장치의 입력 인터페이스(문자 입력 또는 음성 입력)를 통해 입력된 사용자 요 구사항을 수신한다. 일 실시예에 따라 프로세서는 사용자 음성을 수신하여 음성인식 동작을 수행할 수 있 다(S300). 상기 음성인식 동작은 도 2에서 설명한 음성 처리 모듈에서 수행될 수 있으며, ASR 모듈은 수신된 음성 신호를 텍스트로 전환한다. NLU는 전환된 텍스트를 분석하여 사용자 의도를 추출할 수 있다. 프로세서는 상기 전환된 텍스트에 기초하여 챗봇 응답을 생성하기 데이터베이스에 저장된 비교 기준 데이 터를 활용한다. 상기 데이터 베이스는 음성인식 결과로 추출된 텍스트가 매칭 가능한 복수의 도메인, 상기 복수 의 도메인 각각에 포함된 복수의 카테고리로 구분될 수 있다. 여기서 복수의 도메인은 1) 특정 목적 달성을 위 한 대화 주제, 2) 장치 동작 등 서비스 및 기기 제어를 위한 대화 주제, 3) 유용한 정보를 제공하기 위한 정보 안내 주제, 4) 잡담 형식의 정서적 감성 대화 주제 등으로 구분될 수 있다. 또는 복수의 도메인은 미디어, 건강 체크, 일반 명령어, 일상대화, 감정태그 등으로 분류될 수도 있다. 복수의 도메인 종류은 전술한 예들로 한정되 지 않고 다양하게 변형되어 실시될 수 있다. 본 명세서의 일 실시예에 따르면 도 4의 구조로 구성된 데이터베이스가 적용될 수 있다. 도 4를 참조하면 사용 자 의도(intention)을 추출하기 위한 도메인으로서, 미디어 도메인, 건강체크 도메인, 일반 명령(C&C) 도메인, 건강 정보 안내 도메인, 일상 대화(Small Talk) 도메인으로 구분될 수 있다.미디어 도메인은 특정 멀티미디어의 재생 및 종료 카테고리를 포함한다. 건강체크 도메인은 복약, 걷기, 식사, 컨디션, 통증, 수면 등의 카테고리를 포함한다. 음성인식 결과 데이터 베 이스에서 건강 체크 도메인에 매칭된 경우, 프로세서는 상기 복수의 카테고리 항목들 중 적어도 하나를 포 함하는 챗봇 응답을 생성할 수 있다. 특히, 건강체크 도메인이 매칭된 경우 프로세서는 사용자의 건강 관 리를 위해 복수의 카테고리에 대하여 순차적으로 챗봇 응답을 출력함으로써, 사용자와의 커뮤니케이션을 수행하 도록 제어할 수도 있다. 일반 명령(C&C) 도메인은 긴급상황, 날씨, 일정, 요일, 알람 등 한번의 챗봇 응답으로 서비스가 종료되는 것으 로서, 사용자의 간단한 질의 사항에 답변할 수 있는 항목득이 포함될 수 있다. 건강 정보 안내 도메인은, 질병, 예방, 부작용, 음식 등 미리 준비된 정보를 제공하는 도메인이다. 일상대화(small talk) 도메인은 안부, 음식, 추억, 운동, 노래, 가족, 여행, 동물, 나이, 성별, 고향, 생일 등 일상적인 가벼운 대화 주제를 포함할 수 있다. 데이터 베이스는 감정 태그 도메인을 포함할 수 있으며, 감정 태그 도메인은 기쁨, 슬픔, 등 총 7개의 감정 태 그 정보를 포함할 수 있다. 음성인식 결과가 감정 태그 중 특정 감정 태그에 매칭되는 경우, 특정 감정 상태에 따른 안내 멘트를 챗봇 응답으로 구성할 수 있다. 데이터 베이스는 타임아웃 및 거절 도메인을 포함할 수 있다. 거절 도메인의 경우 음성인식 결과, 입력된 정보 가 부정확한 경우에 매칭되는 도메인이다. 타임아웃 도메인은 챗봇 대화 처리 장치가 웨이크업 된 후 소정 시간 동안 음성 입력이 존재하지 않는 경우 매칭되는 도메인으로서, 각각 미리 준비된 챗봇 응답이 출력될 수 있다. 프로세서는 미리 정해진 우선순위의 시나리오에 따라 사용자의 의도가 반영된 챗봇 응답을 생성할 수 있다 (S320). 여기서 상기 미리 정해진 우선순위는, 1) 명령어 처리, 2) 질의 내용 처리, 3) 일상대화 처리, 4) 감정 (emotion) 처리의 동작을 순차적으로 수행하는 것을 의미할 수 있다. 예를 들어, 명령어와 감정상태를 유추할 수 있는 텍스트를 모두 포함하는 경우, 용자의 음성에 대응하는 챗봇 응답을 생성하는 과정에서 명령어 처리를 우선적으로 수행하는 것을 의미할 수 있다. 도 5a 내지 도 5c를 참조하여 본 명세서의 일 실시예에 따른 데이터 베이스에 기초하여 챗봇 응답을 구성하는 예를 보다 구체적으로 설명한다. 도 5a를 참조하면, 미디어 도메인은 특정 멀티미디어의 재생(Play) 및 종료(Stop)의 카테고리로 구분될 수 있다. 여기서 특정 멀티 미디어는 제한적인 것은 아니며 챗봇 대화 처리 장치에 저장된 멀티 미디어 또는 클라 우드 환경에서 검색된 결과의 멀티 미디어를 챗봇 대화처리 장치의 출력 장치를 통해 재생하는 스트리밍 멀티미 디어 컨텐츠를 포함할 수 있다. 프로세서는 사용자의 음성을 인식한 결과 \"특정 멀티미디어 콘텐츠\"에 대 응되는 키워드, \"재생 또는 종료\"와 관련된 키워드가 검출된 경우, 데이터 베이스 내에서 미디어 도메인과 1차 적으로 매칭을 수행하고, 2차적으로 재생 또는 종료와 관련된 카테고리와 매칭을 수행한다. 데이터 베이스 내에 의 도메인과 카테고리에 대한 매칭 수행이 완료되면, 프로세서는 사용자의 의도가 \"특정 멀티미디어 콘텐 츠의 재생\", \"특정 멀티미디어 콘텐츠의 재생 종료\" 등과 같이 사용자의 의도를 특정할 수 있다. 일반 명령 도메인의 경우, 응급상황(Emergency) 카테고리를 포함할 수 있다. 응급상황 카테고리는, 통증(Pain), 화재(fire), 공포(scary), 의식불명(black out), 가스 사고(Gas), 119, 경찰, 피곤(GetTired) 등의 키워드를 포함할 수 있다. 프로세서는 응급상황이 일반 명령 도메인에 포함되는 카테고리로서, 응급상황에 대처할 수 있는 추가적인 액션을 취할 것을 요구하는 것으로 사용자의 의도를 판단할 수 있다. 도 5b를 참조하면, 데이터베이스는 건강 정보안내 도메인을 포함할 수 있으며, 건강 정보안내 도메인은 건강과 관련된 다양한 카테고리를 포함할 수 있다. 예를 들어, 춘곤증(springfever), 혈당(bloodsugar), 고구마 (sweetpotato), 혈관(bloodvessel) 등의 카테고리가 포함될 수 있다. 음성인식 결과가 건강 정보안내 도메인에 매칭되며, 키워드 \"혈당\"이 포함된 경우, 프로세서는 사용자의 의도를 혈당 관리 방법(Care_broodsugar) 요청으로 판단하여, 챗봇 응답을 생성하도록 제어할 수 있다. 또한 예를 들어, 음성인식 결과가 건강 정보안내 도메인에 매칭되며, 키워드 \"단백질(protein)\"이 포함된 경우, 프로세서는 사용자의 의도를 혈당 관리 방 법(HowToIntake_protein) 요청으로 판단하여, 챗봇 응답을 생성하도록 제어할 수 있다. 한편, 동일한 키워드라 하더라도, 해당 키워드가 매칭되는 도메인이 다른 경우, 사용자 의도를 다르게 판단할 수 있다. 일상대화(small talk) 도메인은 안부, 음식, 추억, 운동, 노래, 가족 등의 제1 카테고리와 나이, 성별, 고향, 생일 등 제2 카테고리로 구분될 수 있다. 제1 카테고리의 경우, 특정 카테고리의 키워드를 질의하는 것이며, 제2 카테고리는 단순 질의 내용을 포함하여 사용자와의 대화가 연속되는 것을 의미할 수 있다. 이에 따라 프로세 서는 음성인식 결과, 텍스트가 단순 질의인 경우 제1 카테고리에 매칭시키고, 일회성 질의가 아닌 사용자 가 대화를 원하는 것으로 판단한 경우 제2 카테고리에 매칭시킬 수 있다. 도 5c를 참조하면, 상기 데이터 베이스는 감정 도메인을 포함할 수 있으며, 상기 감정 도메인은 기쁨, 슬픔, 분 노, 불안, 상처, 당황, 중립 등의 감정 카테고리를 포함할 수 있다. 프로세서는 음성인식 결과, 텍스트에 감정 상태를 나타내는 키워드가 포함된 경우, 사용자의 의도를 특정 상태의 감정 상태에 대응하는 챗봇 응답을 출력해줄 것으로 인식하고, 미리 준비된(또는 음성인식 결과에 대응되는) 챗봇 응답을 생성할 수 있다. 상기 미리 정해진 우선순위의 시나리오에 따라 챗봇 응답을 출력하는 구성에 대하여 도 6을 통해 보다 구체적으 로 설명한다. 도 6을 참조하면, 프로세서는 챗봇 기능이 웨이크업 상태에서(S400), 사용자의 음성을 수신할 수 있다 (S410). 프로세서는 수신된 음성에 대하여 음성인식 모듈을 통해 음성인식 동작을 수행할 수 있다. 프로세 서는 음성 인식 결과를 분석하여 사용자의 의도를 분석하되, 본 명세서의 일 실시예에 따르면 미리 정해진 우선순위의 시나리오에 따라 사용자의 의도가 반영된 챗봇 응답을 생성한다. 프로세서는 음성인식 결과에 대하여 1차적으로 기본 명령어 시나리오에 해당되는 것인지, 건강정보 안내 시나리오에 해당되는 것인지 판단하는 1차 사용자 의도 판단 동작을 수행할 수 있다. 프로세서는 1차 사용자 의도 판단 동작 수행 결과, 사용자의 의도가 명령어 처리 요청, 또는 건강 정보 안 내 요청으로 판단한 경우(S420:YES), 명령어 수행(S421) 또는 요청 정보 안내(S423)를 챗봇 응답으로 생성할 수 있다. 프로세서는 1차 사용자 의도 판단 동작 수행 결과, 기본 명령어 처리 또는 건강정보 안내 요청이 아닌 것으로 판단한 경우(S420:NO), 2차 사용자 의도 판단 동작을 수행할 수 있다(S430). 상기 2차 사용자 의도 판단 동작은 음성 인식 결과가 일상 대화 요청인 경우(S430:YES), 프로세서는 일상대화 시나리오에 따른 챗봇 응답을 생성할 수 있다(S431). 프로세서는 2차 사용자 의도 판단 동작 수행 결과, 일상 대화 요청이 아닌 것으로 판단 경우(S430:N0), 3 차 사용자 의도 판단 동작을 수행할 수 있다(S440). 3차 사용자 의도 판단 동작은 음성 인식 결과에 감정 상태 가 포함되어 있는지 판단하는 동작일 수 있다. 상기 3차 사용자 의도 판단 결과, 음성 인식 결과에 사용자의 감정 상태를 추론할 수 있는 키워드가 포함된 것으로 판단한 경우(S440:YES), 프로세서는 사용자의 감정상 태를 반영하여 감정 안내 음성을 챗봇 응답으로 구성하여 출력하도록 제어할 수 있다(S441). 이상 도 6을 통해 미리 정해진 우선순위에 따라 사용자의 의도를 판단하는 챗봇 대화 처리 방법에 대하여 설명 하였다. 그러나 본 명세서는 이에 한정되지 않는다. 예를 들어, 프로세서는 도 6에 도시된 제1 내지 제3 사용자 의도 판단 과정(S420, S430, S440)을 수행한 결과, 미리 정해진 우선순위에 따른 시나리오(데이터 베이 스의 인 및/또는 카테고리)에 매칭되지 않는 경우는, 챗봇 대화가 종료되는 것이 아니라, 인공지능 에이전트(AI Agent)를 통해 사용자의 의도를 추론하는 동작을 수행할 수 있다. 예를 들어, 도 2에서 음성 처리 모듈은 인공지능 에이전트를 포함할 수 있으며, 인공지능 에이전트 는 전술한 ASR 동작, NLU 동작 및 TTS 동작을 수행하는 것 외에 사용자와 상호 작용(interactive operation)을 지원할 수 있다. 인공지능 에이전트는 컨텍스트 정보를 이용하여 NLU 모듈이 ASR 모듈 로부터 수신된 텍스트 표현들에 포함된 정보를 보다 명확하게 하고, 보완하거나 추가적으로 정의하는 동작 을 수행하는데 기여할 수 있다. 여기서, 컨텍스트 정보는, 사용자의 선호도, 사용자 디바이스(챗봇 대화 처리 장치 포함) 하드웨어 및/또는 소프트웨어 상태들, 사용자 입력 전, 입력 중, 또는 입력 직후에 수집되는 다양한 센서 정보, 상기 인공지능 에이전트와 사용자 사이의 이전 상호 작용들(예를 들어, 대화) 등을 포함할 수 있다. 본 문서에서 컨텍스트 정보는 동적이고, 시간, 위치, 대화의 내용 및 기타 요소들에 따라 가변되는 특징임을 물 론이다. 전술한 본 발명은, 프로그램이 기록된 매체에 컴퓨터가 읽을 수 있는 코드로서 구현하는 것이 가능하다. 컴퓨터 가 읽을 수 있는 매체는, 컴퓨터 시스템에 의하여 읽혀질 수 있는 데이터가 저장되는 모든 종류의 기록장치를 포함한다. 컴퓨터가 읽을 수 있는 매체의 예로는, HDD(Hard Disk Drive), SSD(Solid State Disk), SDD(Silicon Disk Drive), ROM, RAM, CD-ROM, 자기 테이프, 플로피 디스크, 광 데이터 저장 장치 등이 있으며, 또한 캐리어 웨이브(예를 들어, 인터넷을 통한 전송)의 형태로 구현되는 것도 포함한다. 따라서, 상기의 상세한 설명은 모든 면에서 제한적으로 해석되어서는 아니되고 예시적인 것으로 고려되어야 한다. 본 발명의 범위는 첨부된 청구항의 합리적 해석에 의해 결정되어야 하고, 본 발명의 등가적 범위 내에서의 모든 변경은 본 발명의 범위에 포함 된다."}
{"patent_id": "10-2022-0017437", "section": "도면", "subsection": "도면설명", "item": 1, "content": "본 명세서에 관한 이해를 돕기 위해 상세한 설명의 일부로 포함되는, 첨부 도면은 본 명세서에 대한 실시예를 제공하고, 상세한 설명과 함께 본 명세서의 기술적 특징을 설명한다. 도 1은 본 명세서의 일 실시예에 따른 대화형 챗봇 시스템의 구성을 설명하기 위한 도면이다. 도 2는 본 명세서의 일 실시예에 따른 챗봇 대화 처리 장치의 블록도이다. 도 3은 본 명세서의 일 실시예에 따른 챗봇 대화 처리 방법의 흐름도이다. 도 4는 본 명세서의 일 실시예에 따른 챗봇응답을 생성하기 위한 데이터 베이스의 구성을 설명하기 위한 예시이 다. 도 5a 내지 도 5c는 본 명세서의 일 실시예에 따라 사용자 의도를 추론하기 위한 데이터베이스의 예시이다. 도 6은 본 명세서의 일 실시예에 따른 챗봇 대화 처리 방법이 적용되는 시나리오를 설명하기 위한 흐름도이다."}
