{"patent_id": "10-2022-0187955", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0008685", "출원번호": "10-2022-0187955", "발명의 명칭": "문답 처리 방법과 장치, 문답 모델의 훈련 방법과 장치, 전자 기기, 저장 매체 및 컴퓨터 프", "출원인": "베이징 바이두 넷컴 사이언스 테크놀로지 컴퍼니", "발명자": "지앙 웬빈"}}
{"patent_id": "10-2022-0187955", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "문답 처리 방법으로서,질문 데이터 및 후보 답안을 포함하는 처리 대상 데이터를 취득하는 단계;상기 처리 대상 데이터에 대해 공통 시맨틱 이해를 진행하여 공통 데이터 특징을 얻는 단계;상기 공통 데이터 특징에 기초하여, 후보 문답 처리 모드로부터 목표 문답 처리 모드를 선택하는 단계; 및상기 목표 문답 처리 모드를 이용하여 상기 공통 데이터 특징을 처리하여, 상기 후보 답안에서 상기 질문 데이터에 대한 목표 답안을 얻는 단계를 포함하는, 문답 처리 방법."}
{"patent_id": "10-2022-0187955", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 후보 문답 처리 모드는 모드 라벨을 포함하고, 상기 공통 데이터 특징에 기초하여, 후보 문답 처리 모드로부터 목표 문답 처리 모드를 선택하는 단계는,상기 공통 데이터 특징과 상기 모드 라벨 사이의 유사도에 기초하여, 상기 후보 문답 처리 모드로부터 상기 목표 문답 처리 모드를 선택하는 것을 포함하되,상기 공통 데이터 특징은 상기 질문 데이터의 분야 정보를 나타내고, 상기 모드 라벨은 상기 후보 문답 처리 모드가 대한 분야를 나타내는문답 처리 방법."}
{"patent_id": "10-2022-0187955", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,상기 목표 문답 처리 모드는 복수의 목표 문답 처리 모드를 포함하고, 상기 목표 문답 처리 모드를 이용하여 상기 공통 데이터 특징을 처리하여, 상기 후보 답안에서 상기 질문 데이터에 대한 목표 답안을 얻는 단계는,상기 복수의 목표 문답 처리 모드 각각을 이용하여 상기 공통 데이터 특징을 처리하여, 상기 복수의 목표 문답처리 모드와 일일이 대응하는 복수의 목표 답안을 얻는 것,각 목표 문답 처리 모드에 대해, 상기 유사도에 기초하여 각 목표 문답 처리 모드에 대한 목표 답안의 가중치를결정하는 것 및 상기 가중치에 기초하여, 상기 복수의 목표 답안으로부터 상기 질문 데이터에 대한 목표 답안을 선택하는 것을 포함하는, 문답 처리 방법."}
{"patent_id": "10-2022-0187955", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,상기 후보 문답 처리 모드는 복수의 후보 문답 처리 모드를 포함하고, 상기 공통 데이터 특징에 기초하여, 후보문답 처리 모드로부터 목표 문답 처리 모드를 선택하는 단계는, 컴퓨팅 자원에 기초하여, 선택해야 하는 목표 문답 처리 모드의 수량을 결정하는 것; 및상기 수량 및 상기 공통 데이터 특징에 기초하여, 상기 복수의 후보 문답 처리 모드로부터 상기 수량의 상기 목표 문답 처리 모드를 선택하는 것공개특허 10-2023-0008685-3-을 포함하는, 문답 처리 방법."}
{"patent_id": "10-2022-0187955", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서,상기 처리 대상 데이터에 대해 공통 시맨틱 이해를 진행하여 공통 데이터 특징을 얻는 단계는,제1 지식 데이터를 취득하는 것,상기 제1 지식 데이터에 기초하여, 상기 처리 대상 데이터에 대해 공통 시맨틱 이해를 진행하여, 질문 특징, 후보 답안 특징 및 제1 연관 정보를 얻되, 여기서, 상기 제1 연관 정보는 상기 질문 데이터와 상기 후보 답안 사이의 연관성을 나타내는 것 및상기 질문 특징, 상기 후보 답안 특징 및 상기 제1 연관 특징을 상기 공통 데이터 특징으로 결정하는 것을 포함하는, 문답 처리 방법."}
{"patent_id": "10-2022-0187955", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항 또는 제5항에 있어서,상기 목표 문답 처리 모드를 이용하여 상기 공통 데이터 특징을 처리하여, 상기 후보 답안에서 상기 질문 데이터에 대한 목표 답안을 얻는 단계는,제2 지식 데이터를 취득하는 것,상기 목표 문답 처리 모드를 이용하여 상기 제2 지식 데이터에 기초하여, 상기 공통 데이터 특징을 처리하고 상기 질문 데이터 및 상기 후보 답안 사이의 제2 연관 정보를 얻는 것 및상기 제2 연관 정보에 기초하여, 상기 후보 답안으로부터 상기 질문 데이터에 대한 목표 답안을 결정하는 것을 포함하는, 문답 처리 방법."}
{"patent_id": "10-2022-0187955", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제5항에 있어서,상기 처리 대상 데이터는 상기 질문 데이터에 대한 설명 정보를 더 포함하고, 상기 공통 데이터 특징은 상기 설명 정보에 대한 설명 특징을 더 포함하는문답 처리 방법."}
{"patent_id": "10-2022-0187955", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "질문 데이터, 후보 답안 및 샘플 라벨을 포함하는 샘플 데이터를 취득하되, 상기 샘플 라벨은 상기 후보 답안과상기 질문 데이터 사이의 연관성을 나타내며, 훈련 대상 문답 모델 중의 공통 이해 네트워크를 이용하여, 상기 샘플 데이터에 대해 공통 시맨틱 이해를 진행하여 공통 데이터 특징을 얻으며, 상기 훈련 대상 문답 모델 중의 후보 문답 네트워크에 대해, 상기 공통 데이터 특징에 기초하여 상기 후보 문답네트워크로부터 목표 문답 네트워크를 선택하며, 상기 목표 문답 네트워크를 이용하여 상기 공통 데이터 특징을 처리하여 상기 후보 답안 중 상기 질문 데이터에대한 목표 답안을 얻으며, 상기 목표 답안 및 상기 샘플 라벨에 기초하여, 상기 훈련 대상 문답 모델의 모델 파라미터를 조정하는 것을 포함하는문답 모델의 훈련 방법."}
{"patent_id": "10-2022-0187955", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서,공개특허 10-2023-0008685-4-상기 후보 문답 네트워크는 네트워크 라벨을 포함하고, 상기 공통 데이터 특징에 기초하여 상기 후보 문답 네트워크로부터 목표 문답 네트워크를 선택하는 것은,상기 공통 데이터 특징과 상기 네트워크 라벨 사이의 유사도에 기초하여, 상기 후보 문답 네트워크로부터 상기목표 문답 네트워크를 선택하는 것을 포함하고,여기서, 상기 공통 데이터 특징은 상기 질문 데이터의 분야 정보를 나타내고, 상기 네트워크 라벨은 상기 후보문답 네트워크가 대한 분야를 나타내는문답 모델의 훈련 방법."}
{"patent_id": "10-2022-0187955", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9항에 있어서,상기 목표 문답 네트워크는 복수의 목표 문답 네트워크를 포함하고, 상기 목표 문답 네트워크를 이용하여 상기공통 데이터 특징을 처리하여 상기 후보 답안 중 상기 질문 데이터에 대한 목표 답안을 얻는 것은,상기 복수의 목표 문답 네트워크 각각을 이용하여 상기 공통 데이터 특징을 처리하여, 상기 복수의 목표 문답네트워크와 일일이 대응하는 복수의 목표 답안을 얻으며, 각 목표 문답 네트워크에 대해, 상기 유사도에 기초하여 각 목표 문답 네트워크에 대한 목표 답안의 가중치를결정하며, 상기 가중치에 기초하여, 상기 복수의 목표 답안으로부터 상기 질문 데이터에 대한 목표 답안을 선택하는 것을포함하는문답 모델의 훈련 방법."}
{"patent_id": "10-2022-0187955", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제8항에 있어서,상기 후보 문답 네트워크는 복수의 후보 문답 네트워크를 포함하고, 상기 공통 데이터 특징에 기초하여 상기 후보 문답 네트워크로부터 목표 문답 네트워크를 선택하는 것은,컴퓨팅 자원에 기초하여, 선택해야 하는 목표 문답 네트워크의 수량을 결정하며, 상기 수량 및 상기 공통 데이터 특징에 기초하여, 상기 복수의 후보 문답 네트워크로부터 상기 수량의 상기 목표 문답 네트워크를 선택하는 것을 포함하는문답 모델의 훈련 방법."}
{"patent_id": "10-2022-0187955", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제8항에 있어서,상기 훈련 대상 문답 모델의 공통 이해 네트워크를 이용하여, 상기 샘플 데이터에 대해 공통 시맨틱 이해를 진행하여 공통 데이터 특징을 얻는 것은,제1 지식 데이터를 취득하며,상기 제1 지식 데이터에 기초하여, 상기 샘플 데이터에 대해 공통 시맨틱 이해를 진행하여, 질문 특징, 후보 답안 특징 및 제1 연관 정보를 얻되, 상기 제1 연관 정보는 상기 질문 데이터와 상기 후보 답안 사이의 연관성을나타내고, 상기 질문 특징, 상기 후보 답안 특징 및 상기 제1 연관 특징을 상기 공통 데이터 특징으로 결정하는 것을 포함하는문답 모델의 훈련 방법."}
{"patent_id": "10-2022-0187955", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제8항 또는 제12항에 있어서,공개특허 10-2023-0008685-5-상기 목표 문답 네트워크를 이용하여 상기 공통 데이터 특징을 처리하여 상기 후보 답안 중 상기 질문 데이터에대한 목표 답안을 얻는 것은,제2 지식 데이터를 취득하며,상기 목표 문답 네트워크를 이용하여 상기 제2 지식 데이터에 기초하여, 상기 공통 데이터 특징을 처리하고 상기 질문 데이터와 상기 후보 답안 사이의 제2 연관 정보를 얻으며, 상기 제2 연관 정보에 기초하여, 상기 후보 답안으로부터 상기 질문 데이터에 대한 목표 답안을 결정하는 것을포함하는문답 모델의 훈련 방법."}
{"patent_id": "10-2022-0187955", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제12항에 있어서,상기 샘플 데이터는 상기 질문 데이터에 대한 설명 정보를 더 포함하고, 상기 공통 데이터 특징은 상기 설명 정보에 대한 설명 특징을 더 포함하는문답 모델의 훈련 방법."}
{"patent_id": "10-2022-0187955", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "문답 처리 장치로서,질문 데이터 및 후보 답안을 포함하는 처리 대상 데이터를 취득하기 위한 취득모듈,상기 처리 대상 데이터에 대해 공통 시맨틱 이해를 진행하여 공통 데이터 특징을 얻기 위한 시맨틱 이해모듈,상기 공통 데이터 특징에 기초하여, 후보 문답 처리 모드로부터 목표 문답 처리 모드를 선택하기 위한선택모듈, 및상기 목표 문답 처리 모드를 이용하여 상기 공통 데이터 특징을 처리하여, 상기 후보 답안에서 상기 질문 데이터에 대한 목표 답안을 얻기 위한 처리모듈을 포함하는, 문답 처리 장치."}
{"patent_id": "10-2022-0187955", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제15항에 있어서,상기 후보 문답 처리 모드는 모드 라벨을 포함하고, 상기 선택모듈은, 또한,상기 공통 데이터 특징과 상기 모드 라벨 사이의 유사도에 기초하여, 상기 후보 문답 처리 모드로부터 상기 목표 문답 처리 모드를 선택하는 데 사용되되,상기 공통 데이터 특징은 상기 질문 데이터의 분야 정보를 나타내고, 상기 모드 라벨은 상기 후보 문답 처리 모드가 대한 분야를 나타내는, 문답 처리 장치."}
{"patent_id": "10-2022-0187955", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제16항에 있어서,상기 목표 문답 처리 모드는 복수의 목표 문답 처리 모드를 포함하고, 상기 처리모듈은,상기 복수의 목표 문답 처리 모드 각각을 이용하여 상기 공통 데이터 특징을 처리하여 상기 복수의 목표 문답처리 모드와 일일이 대응하는 복수의 목표 답안을 얻기 위한 제1 처리 서브모듈,각 목표 문답 처리 모드에 대해, 상기 유사도에 기초하여 각 목표 문답 처리 모드에 대한 목표 답안의 가중치를결정하기 위한 제1 결정 서브모듈, 및상기 가중치에 기초하여, 상기 복수의 목표 답안으로부터 상기 질문 데이터에 대한 목표 답안을 선택하기 위한제1 선택 서브모듈공개특허 10-2023-0008685-6-을 포함하는, 문답 처리 장치."}
{"patent_id": "10-2022-0187955", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제15항에 있어서,상기 후보 문답 처리 모드는 복수의 후보 문답 처리 모드를 포함하고, 상기 선택모듈은,컴퓨팅 자원에 기초하여, 선택해야 하는 목표 문답 처리 모드의 수량을 결정하기 위한 제2 결정 서브모듈,상기 수량 및 상기 공통 데이터 특징에 기초하여, 상기 복수의 후보 문답 처리 모드로부터 상기 수량의 상기 목표 문답 처리 모드를 선택하기 위한 제2 선택 서브모듈을 포함하는, 문답 처리 장치."}
{"patent_id": "10-2022-0187955", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제15항에 있어서,상기 시맨틱 이해모듈은, 제1 지식 데이터를 취득하기 위한 제1 취득 서브모듈,상기 제1 지식 데이터에 기초하여, 상기 처리 대상 데이터에 대해 공통 시맨틱 이해를 진행하여 질문 특징, 후보 답안 특징 및 제1 연관 정보를 얻기 위한 것이되, 상기 제1 연관 정보는 상기 질문 데이터와 상기 후보 답안사이의 연관성을 나타내는 시맨틱 이해 서브모듈, 및 상기 질문 특징, 상기 후보 답안 특징 및 상기 제1 연관 특징을 상기 공통 데이터 특징으로 결정하기 위한 제3결정 서브모듈을 포함하는, 문답 처리 장치."}
{"patent_id": "10-2022-0187955", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제15항 또는 제19항에 있어서,상기 처리모듈은,제2 지식 데이터를 취득하기 위한 제2 취득 서브모듈,상기 목표 문답 처리 모드를 이용하여 상기 제2 지식 데이터에 기초하여, 상기 공통 데이터 특징을 처리하고,상기 질문 데이터 및 상기 후보 답안 사이의 제2 연관 정보를 얻기 위한 제2 처리 서브모듈,상기 제2 연관 정보에 기초하여, 상기 후보 답안으로부터 상기 질문 데이터에 대한 목표 답안을 결정하기 위한제4 결정 서브모듈을 포함하는, 문답 처리 장치."}
{"patent_id": "10-2022-0187955", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_21", "content": "제19항에 있어서,상기 처리 대상 데이터는 상기 질문 데이터에 대한 설명 정보를 더 포함하고, 상기 공통 데이터 특징은 상기 설명 정보에 대한 설명 특징을 더 포함하는문답 처리 장치."}
{"patent_id": "10-2022-0187955", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_22", "content": "문답 모델의 훈련 장치로서,질문 데이터, 후보 답안 및 샘플 라벨을 포함하는 샘플 데이터를 취득하기 위한 것이되, 상기 샘플 라벨은 상기후보 답안과 상기 질문 데이터 사이의 연관성을 나타내는 취득모듈,훈련 대상 문답 모델 중의 공통 이해 네트워크를 이용하여, 상기 샘플 데이터에 대해 공통 시맨틱 이해를 진행공개특허 10-2023-0008685-7-하여 공통 데이터 특징을 얻기 위한 시맨틱 이해모듈,상기 훈련 대상 문답 모델 중의 후보 문답 네트워크에 대해, 상기 공통 데이터 특징에 기초하여 상기 후보 문답네트워크로부터 목표 문답 네트워크를 선택하기 위한 선택모듈,상기 목표 문답 네트워크를 이용하여 상기 공통 데이터 특징을 처리하여 상기 후보 답안에서 상기 질문 데이터에 대한 목표 답안을 얻기 위한 처리모듈, 및상기 목표 답안 및 상기 샘플 라벨에 기초하여, 상기 훈련 대상 문답 모델의 모델 파라미터를 조정하기 위한 조정모듈을 포함하는, 문답 모델의 훈련 장치."}
{"patent_id": "10-2022-0187955", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_23", "content": "제22항에 있어서,상기 후보 문답 네트워크는 네트워크 라벨을 포함하고, 상기 선택모듈은, 또한상기 공통 데이터 특징과 상기 네트워크 라벨 사이의 유사도에 기초하여, 상기 후보 문답 네트워크로부터 상기목표 문답 네트워크를 선택하는 데 사용되되,상기 공통 데이터 특징은 상기 질문 데이터의 분야 정보를 나타내고, 상기 네트워크 라벨은 상기 후보 문답 네트워크가 대한 분야를 나타내는, 문답 모델의 훈련 장치."}
{"patent_id": "10-2022-0187955", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_24", "content": "제23항에 있어서,상기 목표 문답 네트워크는 복수의 목표 문답 네트워크를 포함하고, 상기 처리모듈은,상기 복수의 목표 문답 네트워크 각각을 이용하여 상기 공통 데이터 특징을 처리하여, 상기 복수의 목표 문답네트워크와 일일이 대응하는 복수의 목표 답안을 얻기 위한 제1 처리 서브모듈,각 목표 문답 네트워크에 대해, 상기 유사도에 기초하여 각 목표 문답 네트워크에 대한 목표 답안의 가중치를결정하기 위한 제1 결정 서브모듈, 및상기 가중치에 기초하여, 상기 복수의 목표 답안으로부터 상기 질문 데이터에 대한 목표 답안을 선택하기 위한제1 선택 서브모듈을 포함하는, 문답 모델의 훈련 장치."}
{"patent_id": "10-2022-0187955", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_25", "content": "제22항에 있어서,상기 후보 문답 네트워크는 복수의 후보 문답 네트워크를 포함하고, 상기 선택모듈은, 컴퓨팅 자원에 기초하여, 선택해야 하는 목표 문답 네트워크의 수량을 결정하기 위한 제2 결정 서브모듈,상기 수량 및 상기 공통 데이터 특징에 기초하여, 상기 복수의 후보 문답 네트워크로부터 상기 수량의 상기 목표 문답 네트워크를 선택하기 위한 제2 선택 서브모듈을 포함하는, 문답 모델의 훈련 장치."}
{"patent_id": "10-2022-0187955", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_26", "content": "제22항에 있어서,상기 시맨틱 이해모듈은,제1 지식 데이터를 취득하기 위한 제1 취득 서브모듈,상기 제1 지식 데이터에 기초하여, 상기 샘플 데이터에 대해 공통 시맨틱 이해를 진행하여 질문 특징, 후보 답안 특징 및 제1 연관 정보를 얻기 위한 것이되, 상기 제1 연관 정보는 상기 질문 데이터와 상기 후보 답안 사이공개특허 10-2023-0008685-8-의 연관성을 나타내는 시맨틱 이해 서브모듈, 및상기 질문 특징, 상기 후보 답안 특징 및 상기 제1 연관 특징을 상기 공통 데이터 특징으로 결정하기 위한 제3결정 서브모듈을 포함하는, 문답 모델의 훈련 장치."}
{"patent_id": "10-2022-0187955", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_27", "content": "제22항 또는 제26항에 있어서,상기 처리모듈은,제2 지식 데이터를 취득하기 위한 제2 취득 서브모듈,상기 목표 문답 네트워크를 이용하여 상기 제2 지식 데이터에 기초하여, 상기 공통 데이터 특징을 처리하고 상기 질문 데이터와 상기 후보 답안 사이의 제2 연관 정보를 얻기 위한 제2 처리 서브모듈,상기 제2 연관 정보에 기초하여, 상기 후보 답안으로부터 상기 질문 데이터에 대한 목표 답안을 결정하기 위한제4 결정 서브모듈을 포함하는, 문답 모델의 훈련 장치."}
{"patent_id": "10-2022-0187955", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_28", "content": "제26항에 있어서,상기 샘플 데이터는 상기 질문 데이터에 대한 설명 정보를 더 포함하고, 상기 공통 데이터 특징은 상기 설명 정보에 대한 설명 특징을 더 포함하는, 문답 모델의 훈련 장치."}
{"patent_id": "10-2022-0187955", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_29", "content": "적어도 하나의 프로세서, 및상기 적어도 하나의 프로세서와 통신 연결되는 메모리를 포함하는 전자기기로서,상기 메모리에는 상기 적어도 하나의 프로세서에 의해 실행 가능한 명령어가 저장되어 있고, 상기 명령어가 상기 적어도 하나의 프로세서에 의해 실행될 경우, 상기 적어도 하나의 프로세서로 하여금 제1항 내지 제5항 및제7항 내지 제12항중 어느 한 항의 방법을 실행하도록 하는. 전자기기."}
{"patent_id": "10-2022-0187955", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_30", "content": "컴퓨터 명령어가 저장되어 있는 비일시적 컴퓨터 판독 가능 저장 매체로서,상기 컴퓨터 명령어가 상기 컴퓨터에 의해 실행될 경우, 제1항 내지 제5항 및 제7항 내지 제12항중 어느 한 항의 방법을 구현하는, 비일시적 컴퓨터 판독 가능 저장 매체."}
{"patent_id": "10-2022-0187955", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_31", "content": "저장 매체에 저장되어 있는 컴퓨터 프로그램으로서,상기 컴퓨터 프로그램이 프로세서에 의해 실행될 경우, 제1항 내지 제5항 및 제7항 내지 제12항 중 어느 한 항의 방법을 구현하는, 컴퓨터 프로그램."}
{"patent_id": "10-2022-0187955", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 개시는 문답 처리 방법과 장치, 문답 모델의 훈련 방법과 장치, 전자 기기, 저장 매체 및 컴퓨터 프로그램을 제공하며, 인공지능"}
{"patent_id": "10-2022-0187955", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": ", 구체적으로는 자연어 처리, 딥 러닝 및 지식 그래프 기술 분야에 관한 것이다. 문답 처리 방법은, 질문 데이터 및 후보 답안을 포함하는 처리 대상 데이터를 취득하며, 처리 대상 데이터에 대 해 공통 시맨틱 이해를 진행하여 공통 데이터 특징을 얻으며, 공통 데이터 특징에 기초하여, 후보 문답 처리 모 드로부터 목표 문답 처리 모드를 선택하며, 및 목표 문답 처리 모드를 이용하여 공통 데이터 특징을 처리하여, 후보 답안에서 상기 질문 데이터에 대한 목표 답안을 얻는 것을 포함한다. 대 표 도 - 도2"}
{"patent_id": "10-2022-0187955", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 2, "content": "공개특허10-2023-0008685 CPC특허분류 G06F 16/35 (2019.01) G06F 16/36 (2019.01) G06F 40/30 (2020.01) G06N 3/08 (2023.01) 발명자 차이 춘광 중국 베이징 100085 하이디엔 디스트릭트 샹디 10 번가 넘버 10 바이두 캠퍼스 2층주 용 중국 베이징 100085 하이디엔 디스트릭트 샹디 10 번가 넘버 10 바이두 캠퍼스 2층명 세 서 청구범위 청구항 1 문답 처리 방법으로서, 질문 데이터 및 후보 답안을 포함하는 처리 대상 데이터를 취득하는 단계; 상기 처리 대상 데이터에 대해 공통 시맨틱 이해를 진행하여 공통 데이터 특징을 얻는 단계; 상기 공통 데이터 특징에 기초하여, 후보 문답 처리 모드로부터 목표 문답 처리 모드를 선택하는 단계; 및 상기 목표 문답 처리 모드를 이용하여 상기 공통 데이터 특징을 처리하여, 상기 후보 답안에서 상기 질문 데이 터에 대한 목표 답안을 얻는 단계 를 포함하는, 문답 처리 방법. 청구항 2 제1항에 있어서, 상기 후보 문답 처리 모드는 모드 라벨을 포함하고, 상기 공통 데이터 특징에 기초하여, 후보 문답 처리 모드로 부터 목표 문답 처리 모드를 선택하는 단계는, 상기 공통 데이터 특징과 상기 모드 라벨 사이의 유사도에 기초하여, 상기 후보 문답 처리 모드로부터 상기 목 표 문답 처리 모드를 선택하는 것을 포함하되, 상기 공통 데이터 특징은 상기 질문 데이터의 분야 정보를 나타내고, 상기 모드 라벨은 상기 후보 문답 처리 모 드가 대한 분야를 나타내는 문답 처리 방법. 청구항 3 제2항에 있어서, 상기 목표 문답 처리 모드는 복수의 목표 문답 처리 모드를 포함하고, 상기 목표 문답 처리 모드를 이용하여 상 기 공통 데이터 특징을 처리하여, 상기 후보 답안에서 상기 질문 데이터에 대한 목표 답안을 얻는 단계는, 상기 복수의 목표 문답 처리 모드 각각을 이용하여 상기 공통 데이터 특징을 처리하여, 상기 복수의 목표 문답 처리 모드와 일일이 대응하는 복수의 목표 답안을 얻는 것, 각 목표 문답 처리 모드에 대해, 상기 유사도에 기초하여 각 목표 문답 처리 모드에 대한 목표 답안의 가중치를 결정하는 것 및 상기 가중치에 기초하여, 상기 복수의 목표 답안으로부터 상기 질문 데이터에 대한 목표 답안을 선택하는 것 을 포함하는, 문답 처리 방법. 청구항 4 제1항에 있어서, 상기 후보 문답 처리 모드는 복수의 후보 문답 처리 모드를 포함하고, 상기 공통 데이터 특징에 기초하여, 후보 문답 처리 모드로부터 목표 문답 처리 모드를 선택하는 단계는, 컴퓨팅 자원에 기초하여, 선택해야 하는 목표 문답 처리 모드의 수량을 결정하는 것; 및 상기 수량 및 상기 공통 데이터 특징에 기초하여, 상기 복수의 후보 문답 처리 모드로부터 상기 수량의 상기 목 표 문답 처리 모드를 선택하는 것을 포함하는, 문답 처리 방법. 청구항 5 제1항에 있어서, 상기 처리 대상 데이터에 대해 공통 시맨틱 이해를 진행하여 공통 데이터 특징을 얻는 단계는, 제1 지식 데이터를 취득하는 것, 상기 제1 지식 데이터에 기초하여, 상기 처리 대상 데이터에 대해 공통 시맨틱 이해를 진행하여, 질문 특징, 후 보 답안 특징 및 제1 연관 정보를 얻되, 여기서, 상기 제1 연관 정보는 상기 질문 데이터와 상기 후보 답안 사 이의 연관성을 나타내는 것 및 상기 질문 특징, 상기 후보 답안 특징 및 상기 제1 연관 특징을 상기 공통 데이터 특징으로 결정하는 것 을 포함하는, 문답 처리 방법. 청구항 6 제1항 또는 제5항에 있어서, 상기 목표 문답 처리 모드를 이용하여 상기 공통 데이터 특징을 처리하여, 상기 후보 답안에서 상기 질문 데이 터에 대한 목표 답안을 얻는 단계는, 제2 지식 데이터를 취득하는 것, 상기 목표 문답 처리 모드를 이용하여 상기 제2 지식 데이터에 기초하여, 상기 공통 데이터 특징을 처리하고 상 기 질문 데이터 및 상기 후보 답안 사이의 제2 연관 정보를 얻는 것 및 상기 제2 연관 정보에 기초하여, 상기 후보 답안으로부터 상기 질문 데이터에 대한 목표 답안을 결정하는 것 을 포함하는, 문답 처리 방법. 청구항 7 제5항에 있어서, 상기 처리 대상 데이터는 상기 질문 데이터에 대한 설명 정보를 더 포함하고, 상기 공통 데이터 특징은 상기 설 명 정보에 대한 설명 특징을 더 포함하는 문답 처리 방법. 청구항 8 질문 데이터, 후보 답안 및 샘플 라벨을 포함하는 샘플 데이터를 취득하되, 상기 샘플 라벨은 상기 후보 답안과 상기 질문 데이터 사이의 연관성을 나타내며, 훈련 대상 문답 모델 중의 공통 이해 네트워크를 이용하여, 상기 샘플 데이터에 대해 공통 시맨틱 이해를 진행 하여 공통 데이터 특징을 얻으며, 상기 훈련 대상 문답 모델 중의 후보 문답 네트워크에 대해, 상기 공통 데이터 특징에 기초하여 상기 후보 문답 네트워크로부터 목표 문답 네트워크를 선택하며, 상기 목표 문답 네트워크를 이용하여 상기 공통 데이터 특징을 처리하여 상기 후보 답안 중 상기 질문 데이터에 대한 목표 답안을 얻으며, 상기 목표 답안 및 상기 샘플 라벨에 기초하여, 상기 훈련 대상 문답 모델의 모델 파라미터를 조정하는 것을 포 함하는 문답 모델의 훈련 방법. 청구항 9 제8항에 있어서,상기 후보 문답 네트워크는 네트워크 라벨을 포함하고, 상기 공통 데이터 특징에 기초하여 상기 후보 문답 네트 워크로부터 목표 문답 네트워크를 선택하는 것은, 상기 공통 데이터 특징과 상기 네트워크 라벨 사이의 유사도에 기초하여, 상기 후보 문답 네트워크로부터 상기 목표 문답 네트워크를 선택하는 것을 포함하고, 여기서, 상기 공통 데이터 특징은 상기 질문 데이터의 분야 정보를 나타내고, 상기 네트워크 라벨은 상기 후보 문답 네트워크가 대한 분야를 나타내는 문답 모델의 훈련 방법. 청구항 10 제9항에 있어서, 상기 목표 문답 네트워크는 복수의 목표 문답 네트워크를 포함하고, 상기 목표 문답 네트워크를 이용하여 상기 공통 데이터 특징을 처리하여 상기 후보 답안 중 상기 질문 데이터에 대한 목표 답안을 얻는 것은, 상기 복수의 목표 문답 네트워크 각각을 이용하여 상기 공통 데이터 특징을 처리하여, 상기 복수의 목표 문답 네트워크와 일일이 대응하는 복수의 목표 답안을 얻으며, 각 목표 문답 네트워크에 대해, 상기 유사도에 기초하여 각 목표 문답 네트워크에 대한 목표 답안의 가중치를 결정하며, 상기 가중치에 기초하여, 상기 복수의 목표 답안으로부터 상기 질문 데이터에 대한 목표 답안을 선택하는 것을 포함하는 문답 모델의 훈련 방법. 청구항 11 제8항에 있어서, 상기 후보 문답 네트워크는 복수의 후보 문답 네트워크를 포함하고, 상기 공통 데이터 특징에 기초하여 상기 후 보 문답 네트워크로부터 목표 문답 네트워크를 선택하는 것은, 컴퓨팅 자원에 기초하여, 선택해야 하는 목표 문답 네트워크의 수량을 결정하며, 상기 수량 및 상기 공통 데이터 특징에 기초하여, 상기 복수의 후보 문답 네트워크로부터 상기 수량의 상기 목 표 문답 네트워크를 선택하는 것을 포함하는 문답 모델의 훈련 방법. 청구항 12 제8항에 있어서, 상기 훈련 대상 문답 모델의 공통 이해 네트워크를 이용하여, 상기 샘플 데이터에 대해 공통 시맨틱 이해를 진 행하여 공통 데이터 특징을 얻는 것은, 제1 지식 데이터를 취득하며, 상기 제1 지식 데이터에 기초하여, 상기 샘플 데이터에 대해 공통 시맨틱 이해를 진행하여, 질문 특징, 후보 답 안 특징 및 제1 연관 정보를 얻되, 상기 제1 연관 정보는 상기 질문 데이터와 상기 후보 답안 사이의 연관성을 나타내고, 상기 질문 특징, 상기 후보 답안 특징 및 상기 제1 연관 특징을 상기 공통 데이터 특징으로 결정하는 것을 포함 하는 문답 모델의 훈련 방법. 청구항 13 제8항 또는 제12항에 있어서,상기 목표 문답 네트워크를 이용하여 상기 공통 데이터 특징을 처리하여 상기 후보 답안 중 상기 질문 데이터에 대한 목표 답안을 얻는 것은, 제2 지식 데이터를 취득하며, 상기 목표 문답 네트워크를 이용하여 상기 제2 지식 데이터에 기초하여, 상기 공통 데이터 특징을 처리하고 상 기 질문 데이터와 상기 후보 답안 사이의 제2 연관 정보를 얻으며, 상기 제2 연관 정보에 기초하여, 상기 후보 답안으로부터 상기 질문 데이터에 대한 목표 답안을 결정하는 것을 포함하는 문답 모델의 훈련 방법. 청구항 14 제12항에 있어서, 상기 샘플 데이터는 상기 질문 데이터에 대한 설명 정보를 더 포함하고, 상기 공통 데이터 특징은 상기 설명 정 보에 대한 설명 특징을 더 포함하는 문답 모델의 훈련 방법. 청구항 15 문답 처리 장치로서, 질문 데이터 및 후보 답안을 포함하는 처리 대상 데이터를 취득하기 위한 취득모듈, 상기 처리 대상 데이터에 대해 공통 시맨틱 이해를 진행하여 공통 데이터 특징을 얻기 위한 시맨틱 이해모듈, 상기 공통 데이터 특징에 기초하여, 후보 문답 처리 모드로부터 목표 문답 처리 모드를 선택하기 위한 선택모듈, 및 상기 목표 문답 처리 모드를 이용하여 상기 공통 데이터 특징을 처리하여, 상기 후보 답안에서 상기 질문 데이 터에 대한 목표 답안을 얻기 위한 처리모듈 을 포함하는, 문답 처리 장치. 청구항 16 제15항에 있어서, 상기 후보 문답 처리 모드는 모드 라벨을 포함하고, 상기 선택모듈은, 또한, 상기 공통 데이터 특징과 상기 모드 라벨 사이의 유사도에 기초하여, 상기 후보 문답 처리 모드로부터 상기 목 표 문답 처리 모드를 선택하는 데 사용되되, 상기 공통 데이터 특징은 상기 질문 데이터의 분야 정보를 나타내고, 상기 모드 라벨은 상기 후보 문답 처리 모 드가 대한 분야를 나타내는, 문답 처리 장치. 청구항 17 제16항에 있어서, 상기 목표 문답 처리 모드는 복수의 목표 문답 처리 모드를 포함하고, 상기 처리모듈은, 상기 복수의 목표 문답 처리 모드 각각을 이용하여 상기 공통 데이터 특징을 처리하여 상기 복수의 목표 문답 처리 모드와 일일이 대응하는 복수의 목표 답안을 얻기 위한 제1 처리 서브모듈, 각 목표 문답 처리 모드에 대해, 상기 유사도에 기초하여 각 목표 문답 처리 모드에 대한 목표 답안의 가중치를 결정하기 위한 제1 결정 서브모듈, 및 상기 가중치에 기초하여, 상기 복수의 목표 답안으로부터 상기 질문 데이터에 대한 목표 답안을 선택하기 위한 제1 선택 서브모듈을 포함하는, 문답 처리 장치. 청구항 18 제15항에 있어서, 상기 후보 문답 처리 모드는 복수의 후보 문답 처리 모드를 포함하고, 상기 선택모듈은, 컴퓨팅 자원에 기초하여, 선택해야 하는 목표 문답 처리 모드의 수량을 결정하기 위한 제2 결정 서브모듈, 상기 수량 및 상기 공통 데이터 특징에 기초하여, 상기 복수의 후보 문답 처리 모드로부터 상기 수량의 상기 목 표 문답 처리 모드를 선택하기 위한 제2 선택 서브모듈 을 포함하는, 문답 처리 장치. 청구항 19 제15항에 있어서, 상기 시맨틱 이해모듈은, 제1 지식 데이터를 취득하기 위한 제1 취득 서브모듈, 상기 제1 지식 데이터에 기초하여, 상기 처리 대상 데이터에 대해 공통 시맨틱 이해를 진행하여 질문 특징, 후 보 답안 특징 및 제1 연관 정보를 얻기 위한 것이되, 상기 제1 연관 정보는 상기 질문 데이터와 상기 후보 답안 사이의 연관성을 나타내는 시맨틱 이해 서브모듈, 및 상기 질문 특징, 상기 후보 답안 특징 및 상기 제1 연관 특징을 상기 공통 데이터 특징으로 결정하기 위한 제3 결정 서브모듈 을 포함하는, 문답 처리 장치. 청구항 20 제15항 또는 제19항에 있어서, 상기 처리모듈은, 제2 지식 데이터를 취득하기 위한 제2 취득 서브모듈, 상기 목표 문답 처리 모드를 이용하여 상기 제2 지식 데이터에 기초하여, 상기 공통 데이터 특징을 처리하고, 상기 질문 데이터 및 상기 후보 답안 사이의 제2 연관 정보를 얻기 위한 제2 처리 서브모듈, 상기 제2 연관 정보에 기초하여, 상기 후보 답안으로부터 상기 질문 데이터에 대한 목표 답안을 결정하기 위한 제4 결정 서브모듈 을 포함하는, 문답 처리 장치. 청구항 21 제19항에 있어서, 상기 처리 대상 데이터는 상기 질문 데이터에 대한 설명 정보를 더 포함하고, 상기 공통 데이터 특징은 상기 설 명 정보에 대한 설명 특징을 더 포함하는 문답 처리 장치. 청구항 22 문답 모델의 훈련 장치로서, 질문 데이터, 후보 답안 및 샘플 라벨을 포함하는 샘플 데이터를 취득하기 위한 것이되, 상기 샘플 라벨은 상기 후보 답안과 상기 질문 데이터 사이의 연관성을 나타내는 취득모듈, 훈련 대상 문답 모델 중의 공통 이해 네트워크를 이용하여, 상기 샘플 데이터에 대해 공통 시맨틱 이해를 진행하여 공통 데이터 특징을 얻기 위한 시맨틱 이해모듈, 상기 훈련 대상 문답 모델 중의 후보 문답 네트워크에 대해, 상기 공통 데이터 특징에 기초하여 상기 후보 문답 네트워크로부터 목표 문답 네트워크를 선택하기 위한 선택모듈, 상기 목표 문답 네트워크를 이용하여 상기 공통 데이터 특징을 처리하여 상기 후보 답안에서 상기 질문 데이터 에 대한 목표 답안을 얻기 위한 처리모듈, 및 상기 목표 답안 및 상기 샘플 라벨에 기초하여, 상기 훈련 대상 문답 모델의 모델 파라미터를 조정하기 위한 조 정모듈 을 포함하는, 문답 모델의 훈련 장치. 청구항 23 제22항에 있어서, 상기 후보 문답 네트워크는 네트워크 라벨을 포함하고, 상기 선택모듈은, 또한 상기 공통 데이터 특징과 상기 네트워크 라벨 사이의 유사도에 기초하여, 상기 후보 문답 네트워크로부터 상기 목표 문답 네트워크를 선택하는 데 사용되되, 상기 공통 데이터 특징은 상기 질문 데이터의 분야 정보를 나타내고, 상기 네트워크 라벨은 상기 후보 문답 네 트워크가 대한 분야를 나타내는, 문답 모델의 훈련 장치. 청구항 24 제23항에 있어서, 상기 목표 문답 네트워크는 복수의 목표 문답 네트워크를 포함하고, 상기 처리모듈은, 상기 복수의 목표 문답 네트워크 각각을 이용하여 상기 공통 데이터 특징을 처리하여, 상기 복수의 목표 문답 네트워크와 일일이 대응하는 복수의 목표 답안을 얻기 위한 제1 처리 서브모듈, 각 목표 문답 네트워크에 대해, 상기 유사도에 기초하여 각 목표 문답 네트워크에 대한 목표 답안의 가중치를 결정하기 위한 제1 결정 서브모듈, 및 상기 가중치에 기초하여, 상기 복수의 목표 답안으로부터 상기 질문 데이터에 대한 목표 답안을 선택하기 위한 제1 선택 서브모듈 을 포함하는, 문답 모델의 훈련 장치. 청구항 25 제22항에 있어서, 상기 후보 문답 네트워크는 복수의 후보 문답 네트워크를 포함하고, 상기 선택모듈은, 컴퓨팅 자원에 기초하여, 선택해야 하는 목표 문답 네트워크의 수량을 결정하기 위한 제2 결정 서브모듈, 상기 수량 및 상기 공통 데이터 특징에 기초하여, 상기 복수의 후보 문답 네트워크로부터 상기 수량의 상기 목 표 문답 네트워크를 선택하기 위한 제2 선택 서브모듈 을 포함하는, 문답 모델의 훈련 장치. 청구항 26 제22항에 있어서, 상기 시맨틱 이해모듈은, 제1 지식 데이터를 취득하기 위한 제1 취득 서브모듈, 상기 제1 지식 데이터에 기초하여, 상기 샘플 데이터에 대해 공통 시맨틱 이해를 진행하여 질문 특징, 후보 답 안 특징 및 제1 연관 정보를 얻기 위한 것이되, 상기 제1 연관 정보는 상기 질문 데이터와 상기 후보 답안 사이의 연관성을 나타내는 시맨틱 이해 서브모듈, 및 상기 질문 특징, 상기 후보 답안 특징 및 상기 제1 연관 특징을 상기 공통 데이터 특징으로 결정하기 위한 제3 결정 서브모듈 을 포함하는, 문답 모델의 훈련 장치. 청구항 27 제22항 또는 제26항에 있어서, 상기 처리모듈은, 제2 지식 데이터를 취득하기 위한 제2 취득 서브모듈, 상기 목표 문답 네트워크를 이용하여 상기 제2 지식 데이터에 기초하여, 상기 공통 데이터 특징을 처리하고 상 기 질문 데이터와 상기 후보 답안 사이의 제2 연관 정보를 얻기 위한 제2 처리 서브모듈, 상기 제2 연관 정보에 기초하여, 상기 후보 답안으로부터 상기 질문 데이터에 대한 목표 답안을 결정하기 위한 제4 결정 서브모듈 을 포함하는, 문답 모델의 훈련 장치. 청구항 28 제26항에 있어서, 상기 샘플 데이터는 상기 질문 데이터에 대한 설명 정보를 더 포함하고, 상기 공통 데이터 특징은 상기 설명 정 보에 대한 설명 특징을 더 포함하는, 문답 모델의 훈련 장치. 청구항 29 적어도 하나의 프로세서, 및 상기 적어도 하나의 프로세서와 통신 연결되는 메모리 를 포함하는 전자기기로서, 상기 메모리에는 상기 적어도 하나의 프로세서에 의해 실행 가능한 명령어가 저장되어 있고, 상기 명령어가 상 기 적어도 하나의 프로세서에 의해 실행될 경우, 상기 적어도 하나의 프로세서로 하여금 제1항 내지 제5항 및 제7항 내지 제12항중 어느 한 항의 방법을 실행하도록 하는. 전자기기. 청구항 30 컴퓨터 명령어가 저장되어 있는 비일시적 컴퓨터 판독 가능 저장 매체로서, 상기 컴퓨터 명령어가 상기 컴퓨터에 의해 실행될 경우, 제1항 내지 제5항 및 제7항 내지 제12항중 어느 한 항 의 방법을 구현하는, 비일시적 컴퓨터 판독 가능 저장 매체. 청구항 31 저장 매체에 저장되어 있는 컴퓨터 프로그램으로서, 상기 컴퓨터 프로그램이 프로세서에 의해 실행될 경우, 제1항 내지 제5항 및 제7항 내지 제12항 중 어느 한 항 의 방법을 구현하는, 컴퓨터 프로그램. 발명의 설명 기 술 분 야 본 개시는 인공지능 기술 분야, 구체적으로는 자연어 처리, 딥 러닝 및 지식 그래프 기술 분야에 관한 것으로서, 보다 구체적으로는, 문답 처리 방법, 문답 모델의 훈련 방법, 장치, 전자 기기, 매체 및 프로그램 제 품에 관한 것이다."}
{"patent_id": "10-2022-0187955", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "관련 기술에서, 사용자가 질문을 하면, 일반적으로 복수의 후보 답안으로부터 질문에 대한 목표 답안을 결정해 야 한다. 예를 들어, 의료 문답 분야에서, 사용자가 한 의료 질문에 대해, 복수의 후보 답안에서 해당 의료 질 문에 대한 목표 답안을 결정해야 한다. 하지만, 관련 기술은 복수의 후보 답안으로부터 목표 답안을 선택하는 정확도가 상대적으로 낮아, 사용자의 요구를 만족시키기 어렵다. 본 개시는 문답 처리 방법, 문답 모델의 훈련 방법, 장치, 전자 기기, 저장매체 및 프로그램 제품을 제공한다. 본 개시의 일 측면에 의하면, 질문 데이터 및 후보 답안을 포함하는 처리 대상 데이터를 취득하며, 상기 처리 대상 데이터에 대해 공통 시맨틱 이해를 진행하여 공통 데이터 특징을 얻으며, 상기 공통 데이터 특징에 기초하 여, 후보 문답 처리 모드로부터 목표 문답 처리 모드를 선택하며, 상기 목표 문답 처리 모드를 이용하여 상기 공통 데이터 특징을 처리하여, 상기 후보 답안 중 상기 질문 데이터에 대한 목표 답안을 얻는 것을 포함하는 문 답 처리 방법을 제공한다. 본 개시의 다른 측면에 의하면, 질문 데이터, 후보 답안 및 샘플 라벨을 포함하는 샘플 데이터를 취득하되, 상 기 샘플 라벨은 상기 후보 답안과 상기 질문 데이터 사이의 연관성을 나타내며, 훈련 대상 문답 모델 중의 공통 이해 네트워크를 이용하여, 상기 샘플 데이터에 대해 공통 시맨틱 이해를 진행하여 공통 데이터 특징을 얻으며, 상기 훈련 대상 문답 모델 증의 후보 문답 네트워크에 대해, 상기 공통 데이터 특징에 기초하여 상기 후보 문답 네트워크로부터 목표 문답 네트워크를 선택하며, 상기 목표 문답 네트워크를 이용하여 상기 공통 데이터 특징을 처리하여 상기 후보 답안에서 상기 질문 데이터에 대한 목표 답안을 얻으며, 상기 목표 답안 및 상기 샘플 라벨 에 기초하여, 상기 훈련 대상 문답 모델의 모델 파라미터를 조정하는 것을 포함하는 문답 모델의 훈련 방법을 제공한다. 본 개시의 다른 측면에 의하면, 취득모듈, 시맨틱 이해모듈, 선택모듈 및 처리모듈을 포함하는 문답 처리 장치 를 제공한다. 취득모듈은, 질문 데이터 및 후보 답안을 포함하는 처리 대상 데이터를 취득하는 데 사용된다. 시 맨틱 이해모듈은, 상기 처리 대상 데이터에 대해 공통 시맨틱 이해를 진행하여 공통 데이터 특징을 얻는 데 사 용된다. 선택모듈은, 상기 공통 데이터 특징에 기초하여, 후보 문답 처리 모드로부터 목표 문답 처리 모드를 선 택하는 데 사용된다. 처리모듈은, 상기 목표 문답 처리 모드를 이용하여 상기 공통 데이터 특징을 처리하여, 상 기 후보 답안 중 상기 질문 데이터에 대한 목표 답안을 얻는 데 사용된다. 본 개시의 다른 측면에 의하면, 취득모듈, 시맨틱 이해모듈, 선택모듈, 처리모듈 및 조정모듈을 포함하는 문답 모델의 훈련 장치를 제공한다. 취득모듈은, 질문 데이터, 후보 답안 및 샘플 라벨을 포함하는 샘플 데이터를 취 득하는 데 사용되고, 여기서, 상기 샘플 라벨은 상기 후보 답안과 상기 질문 데이터 사이의 연관성을 나타낸다. 시맨틱 이해모듈은, 훈련 대상 문답 모델의 공통 이해 네트워크를 이용하여, 상기 샘플 데이터에 대해 공통 시 맨틱 이해를 진행하여 공통 데이터 특징을 얻는 데 사용된다. 선택모듈은, 상기 훈련 대상 문답 모델 중의 후보 문답 네트워크에 대해, 상기 공통 데이터 특징에 기초하여 상기 후보 문답 네트워크로부터 목표 문답 네트워크 를 선택하는 데 사용된다. 처리모듈은, 상기 목표 문답 네트워크를 이용하여 상기 공통 데이터 특징을 처리하여 상기 후보 답안에서 상기 질문 데이터에 대한 목표 답안을 얻는 데 사용된다. 조정모듈은, 상기 목표 답안 및 상기 샘플 라벨에 기초하여, 상기 훈련 대상 문답 모델의 모델 파라미터를 조정하는 데 사용된다. 본 개시의 다른 측면에 의하면, 적어도 하나의 프로세서 및 상기 적어도 하나의 프로세서와 통신가능하게 연결 되는 메모리를 포함하는 전자 기기를 제공한다. 여기서, 상기 메모리에는 상기 적어도 하나의 프로세서에 의해 실행 가능한 명령어가 저장되어 있고, 상기 명령어가 상기 적어도 하나의 프로세서에 의해 실행될 경우, 상기 적어도 하나의 프로세서로 하여금 상기 문답 처리 방법 및/또는 문답 모델의 훈련 방법을 실행하도록 한다. 본 개시의 다른 측면에 의하면, 컴퓨터 명령어가 저장되어 있는 비일시적 컴퓨터 판독가능 저장매체로서, 상기 컴퓨터 명령어가 상기 컴퓨터에 의해 실행될 경우, 상기 문답 처리 방법 및/또는 문답 모델의 훈련 방법을 구현 하는 비일시적 컴퓨터 판독가능 저장매체를 제공한다. 본 개시의 다른 측면에 의하면, 컴퓨터 프로그램/명령어가 포함되어 있는 컴퓨터 프로그램 제품으로서, 상기 컴 퓨터 프로그램/명령어가 프로세서에 의해 실행될 경우, 상기 문답 처리 방법의 단계 및/또는 문답 모델의 훈련 방법의 단계를 구현하는 컴퓨터 프로그램 제품을 제공한다.본 명세서에 기술된 내용은 그 목적이 본 개시의 실시예의 핵심 또는 중요한 특징을 지정하기 위한 것이 아니고, 또한, 본 개시의 범위는 이에 한정되지 아니함을 이해하여야 한다. 본 개시의 다른 특징들은 하기 설명 으로부터 용이하게 이해할 수 있을 것이다."}
{"patent_id": "10-2022-0187955", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 도면을 참조하여 본 개시의 예시적인 실시예들을 설명한다. 쉽게 이해할 수 있도록, 본 개시의 실시예들 의 세부사항을 포함하게 되는데, 이들은 단지 예시적인 것에 불과하다. 따라서, 당업자라면 본 개시의 범위 및 취지를 벗어나지 않으면서 본 개시의 실시예에 대해 여러가지 변경 및 수정이 이루어질 수 있음을 이해할 것이다. 또한, 명확성과 간결성을 위해 하기의 설명에 있어서, 공지된 기능 및 구성에 대한 설명은 생략한다. 본 명세서에서 사용하는 용어는 단지 구체적인 실시예를 설명하기 위한 것으로서, 본 발명을 한정하기 위한 취 지로 해석되어서는 아니된다. 본 명세서에서 사용하는 \"포함\", \"구비\" 등 용어는 언급된 특징, 단계, 동작 및/ 또는 부품의 존재를 의미하는데, 하나 또는 복수의 다른 특징, 단계, 동작 또는 부품의 존재 또는 추가를 배제 하지는 않는다. 본 명세서에서 사용되는 모든 용어(기술적 및 과학적 용어 포함)는 별도로 정의되지 않는 한, 당업자가 통상적 으로 이해하는 의미를 갖는다. 본 명세서에서 사용되는 용어는 본 명세서의 문맥과 일치하는 의미를 갖는 것으 로 해석되어야 하며, 이상적이거나 과도하게 용통성이 없는 의미로 해석되어서는 아니되는 점에 유의해야 한다. \"A, B 및 C중 적어도 하나\"와 같은 표현을 사용할 경우, 당업자가 통상적으로 이해하는 해당 표현의 의미에 따 라 해석되어야 한다(예를 들어, \"A, B 및 C중 적어도 하나를 구비한 시스템\"에는, A만 구비한 시스템, B만 구비 한 시스템, C만 구비한 시스템, A 및 B를 구비한 시스템, A 및 C를 구비한 시스템, B 및 C를 구비한 시스템, 및 /또는 A, B, C를 구비한 시스템이 포함되는데, 이에 한정되지는 않는다). 도 1은 예시적인 문답 처리의 응용장면을 개략적으로 나타낸다. 도 1에 도시된 바와 같이, 본 개시의 실시예에 따른 응용장면은 예를 들어, 처리 대상 데이터 및 문 답 모델을 포함한다. 예시적으로, 예를 들어, 처리 대상 데이터는 질문 데이터 및 복수의 후보 답안A, B, C를 포함한다. 처리 대상 데이터를 문답 모델에 입력하여 처리하고, 복수의 후보 답안A, B, C로부터 질문 데이터에 대한 목표 답안을 선택하는데, 예를 들어, 목표 답안은 후보 답안B를 포함한다. 질문 데이터는 예를 들어 의료 질문을 포함하고, 문답 모델은 예를 들어 자연어 처리 모델, 분류 모델 등 을 포함한다. 예시적으로, 문답 모델은 정규화(Regularization) 방법, 조합식(Ensembling) 방법, 리허설(Rehearsal) 방 법, 이중 기억(Dual-memory) 방법, 희소-코딩(Sparse-coding) 방법을 이용하여 훈련될 수 있다. 정규화 방법은, 모델이 새로운 태스크를 학습할 때 기존의 학습 결과에 영향을 주지 않도록 하기 위해, 문답 모 델의 모델 파라미터를 업데이트할 때 제한을 추가한다. 조합식 방법은, 모델이 새로운 태스크를 학습할 때 새로운 모델을 추가하여, 복수의 태스크가 실질적으로 여전 히 복수의 모델에 대응하도록 한다. 리허설 방법은, 모델이 새로운 태스크를 학습하는 동안 기존의 태스크의 데이터를 혼합하여, 모델이 새로운 태 스크를 학습하면서 기존 태스크도 고려하도록 한다. 이중 기억 방법은, 인류의 기억 메커니즘을 참조하여 장기 기억 메커니즘과 단기 기억 메커니즘을 설정하고, 둘 사이의 배합을 통해 신구 지식 사이의 조정을 구현하도록 한다. 희소-코딩 방법은, 모델 파라미터를 희소화하여, 매번 지식 학습이 소수의 신경원에만 영향을 갖게 함으로써, 새로운 지식이 기존 지식에 대한 간섭을 감소시키도록 한다. 본 개시의 실시예에 따른 문답 처리 방법 및 문답 모델은 조합식 방법 및 희소-코딩 방법을 참조한다. 조합식 방법은, 복수의 모델 네트워크를 도입하여 모델의 파라미터 공간을 명시적으로 추가하여, 서로 다른 파라미터 공간에서 합리적인 배치를 통해 지속적인 학습을 실현하는 것이다. 희소-코딩 방법은, 서로 다른 파라미터 공간 을 희소 활성화하여 기존 파라미터 공간의 잠재력을 암시적으로 증가시켜, 새로운 지식이 기존 지식에 대한 영 향을 감소시킴으로써 지속적인 학습을 실현하는 것이다. 본 개시의 실시예는 최적화된 문답 처리 방법 및 문답 모델의 훈련 방법을 제안한다. 이하, 도 2~도 5를 참조하 여 본 개시의 예시적인 실시 형태에 따른 문답 처리 방법 및 문답 모델의 훈련 방법을 설명하기로 한다. 도 2는 본 개시의 일 실시예에 따른 문답 처리 방법의 흐름도를 개략적으로 나타낸다. 도 2에 도시된 바와 같이, 본 개시의 실시예에 따른 문답 처리 방법은 예를 들어, 동작S210~동작S240을 포 함할 수 있다. 동작S210에서는, 질문 데이터 및 후보 답안을 포함하는 처리 대상 데이터를 취득한다. 동작S220에서는, 처리 대상 데이터에 대해 공통 시맨틱 이해를 진행하여 공통 데이터 특징을 얻는다. 동작S230에서는, 공통 데이터 특징에 기초하여, 후보 문답 처리 모드로부터 목표 문답 처리 모드를 선택한다. 동작S240에서는, 목표 문답 처리 모드를 이용하여 공통 데이터 특징을 처리하여, 후보 답안에서 질문 데이터에 대한 목표 답안을 얻는다. 예시적으로, 예를 들어, 처리 대상 데이터는 질문 데이터 및 복수의 후보 답안을 포함하고, 복수의 후보 답안 중의 각 후보 답안과 질문 데이터의 매칭 정도가 서로 다르기에, 복수의 후보 답안으로부터 질문 데이터와 가장 매칭되는 후보 답안을 선택하여, 질문 데이터에 대한 목표 답안으로 해야 한다. 예를 들어, 우선 처리 대상 데이터에 대해 공통 시맨틱 이해를 진행하여 공통 데이터 특징을 얻고, 그 다음, 공 통 데이터 특징에 기초하여, 후보 문답 처리 모드로부터 목표 문답 처리 모드를 선택하며, 목표 문답 처리 모드 를 이용하여 공통 데이터 특징을 처리하여, 복수의 후보 답안에서 질문 데이터에 대한 목표 답안을 얻는다. 일 예시에 있어서, 훈련된 문답 모델을 통해 처리 대상 데이터를 처리하여 목표 답안을 얻을 수 있다. 훈련된 문답 모델은, 예를 들어 딥 러닝 모델을 포함한다. 예를 들어, 훈련된 문답 모델은 복수의 네트워크를 포함하고, 복수의 네트워크는 공통 이해 네트워크 및 복수의 후보 문답 네트워크를 포함하고, 후보 문답 네트워 크는 예를 들어 분류 네트워크를 포함하며, 후보 문답 네트워크는 바로 후보 문답 처리 모드이다. 공통 이해 네트워크를 통해, 처리 대상 데이터에 대해 공통 시맨틱 이해를 진행하여 공통 데이터 특징을 얻고, 공통 데이터 특징은 적어도 질문 데이터에 대한 특징과 후보 답안에 대한 특징을 포함한다. 후보 문답 네트워크 에서 목표 문답 네트워크를 선택한 후, 목표 문답 네트워크를 이용하여 질문 데이터에 대한 특징과 후보 답안에 대한 특징을 처리하여, 복수의 후보 답안에 대한 분류를 실현하고, 분류 결과에 따라 복수의 후보 답안으로부터 질문 데이터와 가장 일치하는 목표 답안을 선택한다. 본 개시의 실시예에 의하면, 우선 공통 시맨틱 이해를 처리하여 처리 대상 데이터의 공통 데이터 특징을 얻은 후, 공통 데이터 특징에 기초하여 복수의 후보 문답 처리 모드로부터 적합한 목표 문답 처리 모드를 선택하고, 목표 문답 처리 모드를 이용하여 공통 데이터 특징을 처리하여 목표 답안을 얻음으로써, 목표 답안의 정확도를 향상시키고 문답 효과를 향상시킨다.도 3은 본 개시의 일 실시예에 따른 문답 처리 방법의 원리도를 개략적으로 나타낸다. 도 3에 도시된 바와 같이, 처리 대상 데이터는 예를 들어 질문 데이터 및 복수의 후보 답안A, B, C를 포함하고, 공통 이해 모드를 이용하여, 처리 대상 데이터에 대해 공통 시맨틱 이해를 진행하여 공통 데이터 특징을 얻는다. 예시적으로, 복수의 후보 문답 처리 모드(331, 332, 333)에 대해, 각 후보 문답 처리 모드는, 예를 들어 모드 라벨을 포함한다. 선택 메커니즘은 공통 데이터 특징과 모드 라벨 사이의 유사도에 기초하여, 복수의 후보 문답 처리 모드 (331, 332, 333)로부터 목표 문답 처리 모드를 선택한다. 예를 들어, 공통 데이터 특징은 질문 데이터의 분야 정보를 나타내고, 모드 라벨은 후보 문답 처리 모드가 대한 분야를 나타낸다. 질문 데이터가 특정 분야에 대한 것일 때, 선택된 목표 문답 처리 모드는 해당 분야에 대한 질문을 잘 처리한다. 질문 데이터가 특정 의료 분야에 대한 질문인 경우, 서로 다른 후보 문답 처리 모드는, 예를 들어 서로 다른 의 료 분야의 문제를 잘 처리하기에, 모드 라벨에 기초하여 질문 데이터가 속하는 분야를 잘 처리할 수 있는 목표 문답 처리 모드를 결정할 수 있다. 예를 들어, 후보 문답 네트워크를 포함하는 하나의 후보 문답 처리 모드를 예로 들면, 특정 의료 분야의 샘플 데이터(샘플 데이터는 질문과 답안을 포함)를 이용하여 해당 후보 문답 네트워크를 훈련시킴으로써, 해당 후보 문답 네트워크가 해당 의료 분야의 의료 문답 데이터를 잘 처리하도록 한다. 예를 들어, 공통 데이터 특징과 복수의 후보 문답 처리 모드(331, 332, 333)의 모드 라벨 사이의 유사도는 각각 0.2, 0.8, 0.7이다. 유사도가 높은 하나 또는 복수의 후보 문답 처리 모드를 목표 문답 처리 모드로 선택한다. 목표 문답 처리 모드의 수량을 결정할 때, 컴퓨팅 자원에 기초하여 선택해야 하는 목표 문답 처리 모드의 수량 을 결정한다. 다음, 수량 및 공통 데이터 특징에 기초하여, 복수의 후보 문답 처리 모드로부터 해당 수량의 목 표 문답 처리 모드를 선택한다. 예를 들어, 컴퓨팅 자원이 충분한 경우, 복수의 목표 문답 처리 모드를 선택할 수 있고, 컴퓨팅 자원이 부족한 경우, 소량의(예를 들어, 하나) 목표 문답 처리 모드를 선택할 수 있다. 예를 들어, 수량이 2인 경우, 유사도가 가장 높은 두 개의 후보 문답 처리 모드를 목표 문답 처리 모드로 선택하며, 즉, 목표 문답 처리 모드는 후보 문답 처리 모드 및 후보 문답 처리 모드를 포함한다. 복수의 목표 문답 처리 모드를 결정한 후, 복수의 목표 문답 처리 모드 각각을 이용하여 공통 데이터 특징을 처 리하여 복수의 목표 문답 처리 모드와 일일이 대응하는 복수의 목표 답안을 얻는다. 예를 들어, 제1 목표 문답 처리 모드(후보 문답 처리 모드)에 대응되는 목표 답안은 후보 답안A이고, 또한, 제1 목표 문답 처리 모드(후보 문답 처리 모드)가 목표 답안의 확률 0.7을 출력할 수 있다. 제2 목 표 문답 처리 모드(후보 문답 처리 모드)에 대응되는 목표 답안은 후보 답안B이며, 또한 제2 목표 문답 처 리 모드(후보 문답 처리 모드)가 목표 답안의 확률 0.9을 출력할 수 있다. 각 목표 문답 처리 모드에 대해, 유사도에 기초하여 각 목표 문답 처리 모드에 대한 목표 답안의 가중치를 결정 하며, 예를 들어, 제1 목표 문답 처리 모드(후보 문답 처리 모드)에 대한 가중치는 0.8이고, 제2 목표 문 답 처리 모드(후보 문답 처리 모드)에 대한 가중치는 0.7이다. 가중치에 기초하여, 복수의 목표 답안으로부터 질문 데이터에 대한 목표 답안을 선택한다. 예를 들어, 가중치를 확률에 곱하여 계산 결과를 얻고, 수치가 높은 계산 결과에 대응되는 목표 답안을 최종 목표 답안으로 한다. 예 를 들어, 후보 답안A의 계산 결과는 0.56이고, 후보 답안B의 계산 결과는 0.63이면, 후보 답안B를 질문 데이터 에 대한 목표 답안으로 한다. 다른 일 실시예에 있어서, 또한, 목표 문답 처리 모드는 목표 답안만 출력하고, 유사도가 높은 목표 문답 처리 모드에 대응되는 목표 답안을 최종 목표 답안으로 할 수 있다. 본 개시의 실시예에 의하면, 공통 특징 데이터 및 후보 문답 처리 모드의 모드 라벨 사이의 유사도에 기초하여 목표 문답 처리 모드를 결정함으로써, 결정된 목표 문답 처리 모드가 질문 데이터에 기초하여 목표 답안을 얻을 때 정확도가 더 높도록 한다.또한, 컴퓨팅 자원에 기초하여 목표 문답 처리 모드의 수량을 결정하여 데이터 처리의 유연성을 향상시키고, 컴 퓨팅 자원이 충분한 경우, 보다 많은 목표 문답 처리 모드를 이용하여 목표 답안을 얻을 수 있어, 목표 답안의 정확성을 향상시킬 수 있다. 또한, 유사도에 기초하여 목표 답안의 가중치를 결정하고, 가중치에 기초하여 최종 목표 답안을 선택하며, 목표 후보 처리 모드의 전문성과 처리 정확도를 종합적으로 고려함으로써, 목표 답안의 정확성이 보다 향상되도록 한 다. 도 4는 본 개시의 다른 실시예에 따른 문답 처리 방법의 원리도를 개략적으로 나타낸다. 도 4에 도시된 바와 같이, 상기 실시예의 기초에서, 본 개시의 실시예는 제1 지식 데이터 및 제2 지식 데 이터를 더 도입한다. 예를 들어, 공통 이해 모드를 통해 처리 대상 데이터에 대해 공통 시맨틱 이해를 처리하여 공통 데이터 특징을 얻는 과정에서, 제1 지식 데이터를 취득할 수 있다. 그리고, 제1 지식 데이터에 기초하여, 처리 대상 데이터에 대해 공통 시맨틱 이해를 진행하여 질문 특징, 후보 답안 특징 및 제1 연관 정보를 얻는다. 제1 연관 정보는, 예를 들어 질문 데이터와 후보 답안 사이의 연관성을 나타낸다. 질문 특징, 후보 답안 특징 및 제1 연 관 특징을 공통 데이터 특징으로 결정한다. 제1 지식 데이터는, 예를 들어 상식 데이터 또는 전문 데이터를 포함하고, 제1 지식 데이터는 질문 데이터와 후보 답안 사이의 연관성을 어느 정도 포함한다. 전문 데이터는, 예를 들어 의료 분야의 데이터이다. 다른 일 실시예에 있어서, 처리 대상 데이터는 질문 데이터에 대한 설명 정보를 더 포함할 수 있고, 이때, 공통 데이터 특징은 설명 정보에 대한 설명 특징을 더 포함한다. 예를 들어, 질문 데이터가 질병에 대한 질문인 경우, 설명 정보는 질병의 증상을 포함할 수 있다. 이해할 수 있듯이, 처리 대상 데이터에 설명 정보가 포함되어 있어, 처리 대상 데이터에 보다 풍부한 정보가 포 함되도록 함으로써, 문답 효과를 향상시킬 수 있다. 목표 문답 처리 모드를 결정한 후, 제2 지식 데이터를 취득할 수 있고, 목표 문답 처리 모드를 이용하여 제2 지식 데이터에 기초하여, 공통 데이터 특징을 처리하고 질문 데이터 및 후보 답안 사이의 제2 연관 정 보를 얻을 수 있다. 즉, 제2 연관 정보는, 예를 들어 질문 데이터 및 후보 답안 사이의 연관성을 나타낸다. 다 음, 제2 연관 정보에 기초하여, 후보 답안으로부터 질문 데이터에 대한 목표 답안을 결정한다. 제2 지식 데이터는, 예를 들어 상식 데이터 또는 전문 데이터를 포함하고, 제2 지식 데이터는 질문 데이터와 후보 답안 사이의 연관성을 어느 정도 포함한다. 제2 지식 데이터와 제1 지식 데이터는 동 일하거나 서로 다를 수 있다. 제2 지식 데이터와 제1 지식 데이터는 지식 그래프 데이터를 포함할 수 있다. 본 개시의 실시예에 의하면, 공통 이해 모드 또는 목표 문답 처리 모드를 이용하여 데이터를 처리할 때, 지식 데이터를 참조하는 방식으로 처리 결과의 정확성을 향상시킬 수 있다. 쉽게 이해할 수 있도록, 앞에서 설명한 원리도와 결합하여 구체적인 실시예를 개시하게 되는데, 해당 실시예는 본 개시를 한정하기 위한 것이 아님을 이해할 수 있을 것이다. 예를 들어, \"특정 건강 문제가 있을 때 어떻게 해결해야 하는가\"와 같은 질문 데이터이며, 설명 정보는 해당 건 강 질문에 대응되는 다양한 증상을 나타내며, 후보 답안은 예를 들어 다양한 해결 방법을 포함한다. 예를 들어, 건강 문제는 특정 질병을 포함하고, 그 해결 방법에는 해당 질병에 대한 약물 또는 완화 방법을 포함한다. 예시 적으로, 질문 데이터는 10개의 단어를 포함하고, 설명 정보는 100개의 단어를 포함하며, 후보 답안은 10개의 단 어를 포함하여, 총 120개의 단어를 포함한다. 공통 이해 모드는, 예를 들어 자연어 처리 기능을 갖고 있고, 공통 이해 모드를 이용하여 120개의 단어를 처리 하여 공통 데이터 특징을 얻으며, 공통 데이터 특징은 예를 들어 120개의 벡터를 포함한다. 한가지 방식에서, 제1 지식 데이터를 참조하여 120개의 벡터를 생성할 수 있고, 생성된 120개의 벡터는 지식 컨텐츠에 기초하여 연관될 수 있다. 예를 들어, 질문 데이터에 \"감기\" 단어가 포함되고, 후보 답안에는 \"물 마시기\"라는 단어가 포 함되는 경우, 제1 지식 데이터에 \"물 마시기는 감기 증상을 완화시킬 수 있다\"라는 지식이 포함되어 있다면, 이 지식에 기초하여 생성된 \"감기\" 벡터와 \"물 마시기\" 벡터는 일정한 연관성을 갖고 있다(연관성을 갖는 것은, 예 를 들어 벡터가 비교적 유사함을 포함).이어서, 공통 이해 모드에 의해 얻은 120개의 벡터에 대해 처리(예를 들어, 평균 처리)하여 목표 벡터를 얻을 수 있다. 각 후보 문답 처리 모드에 대해, 각 후보 문답 모드는 예를 들어, 후보 문답 처리 모드가 대응되는 분 야를 나타내기 위한 하나의 모드 라벨을 갖고 있으며, 모드 라벨은 벡터일 수 있다. 선택 메커니즘은, 목표 벡 터와 각 모드 라벨을 매칭시켜 유사도가 가장 높은 하나 또는 복수의 후보 문답 처리 모드를 목표 문답 처리 모 드로 활성화할 수 있다. 다음, 120개의 벡터를 활성화된 각 목표 문답 처리 모드에 입력하고, 활성화된 각 목표 문답 처리 모드에서 목 표 답안을 출력한다. 활성화된 목표 문답 처리 모드가 복수를 포함하는 경우, 각 목표 문답 처리 모드에 대응되 는 유사도를 가중치로 하여, 출력된 목표 답안에 대해 가중치를 부여하여 최종 목표 답안을 결정한다. 예시적으로, 활성화된 각 목표 문답 처리 모드는 분류 모델을 포함하고, 분류 모델은 120개의 벡터에 기초하여 분류하여 분류 결과를 얻을 수 있으며, 분류 결과는 예를 들어 10개의 후보 답안 중 각 후보 답안이 질문에 답 하는 데 사용되는 확률을 나타낸다. 한가지 경우, 분류 모델을 이용하여 분류하는 과정에서, 분류 정확도를 향 상시키기 위해 제2 지식 데이터를 참조하여 분류할 수도 있다. 도 5는 본 개시의 일 실시예에 따른 문답 모델의 훈련 방법의 흐름도를 개략적으로 나타낸다. 도 5에 도시된 바와 같이, 본 개시의 실시예에 따른 문답 모델의 훈련 방법은, 예를 들어 동작S510~동작 S560을 포함할 수 있다. 동작S510에서는, 질문 데이터, 후보 답안 및 샘플 라벨을 포함하는 샘플 데이터를 취득하고, 샘플 라벨은 후보 답안과 질문 데이터 사이의 연관성을 나타낸다. 동작S520에서는, 훈련 대상 문답 모델 중의 공통 이해 네트워크를 이용하여, 샘플 데이터에 대해 공통 시맨틱 이해를 진행하여 공통 데이터 특징을 얻는다. 동작S530에서는, 훈련 대상 문답 모델 중의 후보 문답 네트워크에 대해, 공통 데이터 특징에 기초하여 후보 문 답 네트워크로부터 목표 문답 네트워크를 선택한다. 동작S540에서는, 목표 문답 네트워크를 이용하여 공통 데이터 특징을 처리하여 후보 답안에서 질문 데이터에 대 한 목표 답안을 얻는다. 동작S550에서는, 목표 답안 및 샘플 라벨에 기초하여, 훈련 대상 문답 모델의 모델 파라미터를 조정한다. 본 개시의 실시예에 따른 공통 이해 네트워크는, 예를 들어 앞에서 언급한 공통 이해 모드와 같거나 유사하며, 후보 문답 네트워크는, 예를 들어 앞에서 언급한 후보 문답 처리 모드와 같거나 유사하며, 목표 문답 네트워크 는, 예를 들어 앞에서 언급한 목표 문답 처리 모드와 같거나 유사하다. 예시적으로, 복수의 샘플 데이터를 이용하여 문답 모델을 훈련할 수 있다. 각 샘플 데이터는 후보 답안과 질문 데이터 사이의 연관성을 나타내는 샘플 라벨을 갖고 있다. 예를 들어, 샘플 데이터에 하나의 질문 데이터와 복 수의 후보 답안A, B, C를 포함하는 경우, 샘플 데이터는 예를 들어 후보 답안B가 질문 데이터에 대한 최적 답안 임을 나타낸다. 목표 문답 네트워크를 통해 공통 데이터 특징을 처리하여 후보 답안 중 질문 데이터에 대한 목표 답안을 얻은 후, 목표 답안을 샘플 라벨과 비교하여 손실값을 얻고, 손실값에 기초하여 훈련 대상 문답 모델의 모델 파라미 터를 역방향 조정함으로써, 문답 모델을 훈련하여 얻도록 한다. 모델 파라미터는 공통 이해 네트워크의 파라미 터 및 후보 문답 네트워크의 파라미터를 포함한다. 본 개시의 실시예에 의하면, 우선 공통 이해 네트워크를 이용하여 공통 시맨틱 이해를 진행하여 처리 대상 데이 터의 공통 데이터 특징을 얻은 후, 공통 데이터 특징에 기초하여 복수의 후보 문답 네트워크로부터 적합한 목표 문답 네트워크를 선택하고, 목표 문답 네트워크를 이용하여 공통 데이터 특징을 처리하여 목표 답안을 얻으며, 목표 답안과 샘플 라벨에 기초하여 모델의 파라미터를 조정함으로써, 문답 모델의 정확성을 향상시켜, 문답 효 과를 향상시킨다. 일 실시예에 있어서, 후보 문답 네트워크는 네트워크 라벨을 포함하고, 공통 데이터 특징과 네트워크 라벨 사이 의 유사도에 기초하여, 후보 문답 네트워크로부터 목표 문답 네트워크를 선택할 수 있다. 공통 데이터 특징은 질문 데이터의 분야 정보를 나타내고, 네트워크 라벨은 후보 문답 네트워크가 대한 분야를 나타낸다. 여기서, 네트워크 라벨은 예를 들어 앞에서 언급한 모드 라벨과 같거나 유사하다.일 실시예에 있어서, 목표 문답 네트워크는 복수의 목표 문답 네트워크를 포함한다. 복수의 목표 문답 네트워크 각각을 이용하여 공통 데이터 특징을 처리하여 복수의 목표 문답 네트워크와 일일이 대응하는 복수의 목표 답안 을 얻는다. 각 목표 문답 네트워크에 대해, 유사도에 기초하여 각 목표 문답 네트워크에 대한 목표 답안의 가중 치를 결정하고, 다음, 가중치에 기초하여 복수의 목표 답안으로부터 질문 데이터에 대한 목표 답안을 선택한다. 일 실시예에 있어서, 후보 문답 네트워크는 복수의 후보 문답 네트워크를 포함하고, 컴퓨팅 자원에 기초하여, 선택해야 하는 목표 문답 네트워크의 수량을 결정할 수 있다. 다음, 수량 및 공통 데이터 특징에 기초하여, 복 수의 후보 문답 네트워크로부터 이 수량의 목표 문답 네트워크를 선택한다. 일 실시예에 있어서, 훈련 대상 문답 모델 중의 공통 이해 네트워크를 이용하여, 샘플 데이터에 대해 공통 시맨 틱 이해를 진행하여 공통 데이터 특징을 얻는 것은, 제1 지식 데이터를 취득하며, 제1 지식 데이터에 기초하여, 샘플 데이터에 대해 공통 시맨틱 이해를 진행하여 질문 특징, 후보 답안 특징 및 제1 연관 정보를 얻되, 제1 연 관 정보는 질문 데이터와 후보 답안 사이의 연관성을 나타내며, 그리고 질문 특징, 후보 답안 특징 및 제1 연관 특징을 공통 데이터 특징으로 결정하는 것을 포함한다. 예시적으로, 샘플 데이터는 질문 데이터에 대한 설명 정보를 더 포함하고, 공통 데이터 특징은 설명 정보에 대 한 설명 특징을 더 포함한다. 일 실시예에 있어서, 목표 문답 네트워크를 이용하여 공통 데이터 특징을 처리하여 후보 답안에서 질문 데이터 에 대한 목표 답안을 얻는 것은, 제2 지식 데이터를 취득하는 것을 포함한다. 목표 문답 네트워크를 이용하여 제2 지식 데이터에 기초하여, 공통 데이터 특징을 처리하고 질문 데이터와 후보 답안 사이의 제2 연관 정보를 얻는다. 다음, 제2 연관 정보에 기초하여, 후보 답안으로부터 질문 데이터에 대한 목표 답안을 결정한다. 본 개시의 실시예에 따른 문답 모델은 조합식 방법 및 희소-코딩 방법을 참조한다. 조합식 방법은, 복수의 모델 네트워크를 도입하여 모델의 파라미터 공간을 명시적으로 추가하여, 서로 다른 파라미터 공간에서 합리적인 배 치를 통해 지속적인 학습을 구현하는 것이다. 예를 들어, 본 개시의 실시예에서는 복수의 후보 문답 네트워크를 도입하였다. 희소-코딩 방법은, 서로 다른 파라미터 공간을 희소 활성화하여 기존 파라미터 공간의 잠재력을 암 시적으로 증가시켜, 새로운 지식이 기존 지식에 대한 영향을 감소시킴으로써 지속적인 학습을 실현하는 것이다. 예를 들어, 본 개시의 실시예에서의 복수의 후보 문답 네트워크는 동일한 모델 구조일 수 있으며, 서로 다른 후 보 답안 네트워크를 훈련하는 경우, 모델의 서로 다른 파라미터를 조정할 수 있다. 본 개시의 실시예에서는 분야 장면과 무관한 공통 시맨틱 이해 부분에 대해 공유된 공통 이해 네트워크를 채택 하고, 분야 장면과 관련된 추리 결정 부분에 대해 복수의 후보 답안 네트워크를 채택하며, 모델 파라미터의 규 모를 제어하는 전제하에 보다 효율적으로 파라미터의 공간 확장 및 배치를 진행할 수 있다. 즉, 복수의 후보 문 답 네트워크를 도입하면, 모델 파라미터의 규모를 효과적으로 제어할 수 있을 뿐만 아니라, 선택 메커니즘에 따 라 후보 문답 네트워크를 보다 효율적으로 배치할 수 있다. 따라서, 모델 파라미터의 규모를 효과적으로 제어하 는 기초에서 보다 좋은 훈련 효과를 구현할 수 있다. 도 6은 본 개시의 일 실시예에 따른 문답 처리 장치의 블록도를 개략적으로 나타낸다. 도 6에 도시된 바와 같이, 본 개시의 실시예에 따른 문답 처리 장치는, 예를 들어 취득모듈, 시맨틱 이해모듈, 선택모듈 및 처리모듈을 포함한다. 취득모듈은 질문 데이터 및 후보 답안을 포함하는 처리 대상 데이터를 취득하는 데 사용될 수 있다. 본 개 시의 실시예에 의하면, 취득모듈은 예를 들어 상기 도 2에서 설명한 동작S210을 실행할 수 있으므로, 여기 서는 설명을 생략한다. 시맨틱 이해모듈은 처리 대상 데이터에 대해 공통 시맨틱 이해를 진행하여 공통 데이터 특징을 얻는 데 사 용될 수 있다. 본 개시의 실시예에 의하면, 시맨틱 이해모듈은 예를 들어 상기 도 2에서 설명한 동작S220 을 실행할 수 있으므로, 여기서는 설명을 생략한다. 선택모듈은 공통 데이터 특징에 기초하여, 후보 문답 처리 모드로부터 목표 문답 처리 모드를 선택하는 데 사용될 수 있다. 본 개시의 실시예에 의하면, 선택모듈은 예를 들어 상기 도 2에서 설명한 동작S230을 실 행할 수 있으므로, 여기서는 설명을 생략한다. 처리모듈은 목표 문답 처리 모드를 이용하여 공통 데이터 특징을 처리하여, 후보 답안에서 질문 데이터에 대한 목표 답안을 얻는 데 사용될 수 있다. 본 개시의 실시예에 의하면, 처리모듈은 예를 들어 상기 도 2 에서 설명한 동작S240을 실행할 수 있으므로, 여기서는 설명을 생략한다. 본 개시의 실시예에 의하면, 후보 문답 처리 모드는 모드 라벨을 포함하고, 또한 선택모듈은, 공통 데이터 특징과 모드 라벨 사이의 유사도에 기초하여, 후보 문답 처리 모드로부터 목표 문답 처리 모드를 선택하는 데 사용되며, 여기서, 공통 데이터 특징은 질문 데이터의 분야 정보를 나타내고, 모드 라벨은 상기 후보 문답 처리 모드가 대한 분야를 나타낸다. 본 개시의 실시예에 의하면, 목표 문답 처리 모드는 복수의 목표 문답 처리 모드를 포함하고, 처리모듈은 제1 처리 서브모듈, 제1 결정 서브모듈 및 제1 선택 서브모듈을 포함한다. 제1 처리 서브모듈은, 복수의 목표 문답 처리 모드 각각을 이용하여 공통 데이터 특징을 처리하여 복수의 목표 문답 처리 모드와 일일이 대응하는 복수의 목표 답안을 얻는 데 사용된다. 제1 결정 서브모듈은, 각 목표 문답 처리 모드에 대해, 유사도에 기초하 여 각 목표 문답 처리 모드에 대한 목표 답안의 가중치를 결정하는 데 사용된다. 제1 선택 서브모듈은, 가중치 에 기초하여, 복수의 목표 답안으로부터 질문 데이터에 대한 목표 답안을 선택하는 데 사용된다. 본 개시의 실시예에 의하면, 후보 문답 처리 모드는 복수의 후보 문답 처리 모드를 포함하고, 선택모듈은 제2 결정 서브모듈 및 제2 선택 서브모듈을 포함한다. 제2 결정 서브모듈은, 컴퓨팅 자원에 기초하여, 선택해야 하는 목표 문답 처리 모드의 수량을 결정하는 데 사용된다. 제2 선택 서브모듈은, 수량 및 공통 데이터 특징에 기초하여, 복수의 후보 문답 처리 모드로부터 수량의 목표 문답 처리 모드를 선택하는 데 사용된다. 본 개시의 실시예에 의하면, 시맨틱 이해모듈은 제1 취득 서브모듈, 시맨틱 이해 서브모듈 및 제3 결정 서 브모듈을 포함한다. 제1 취득 서브모듈은, 제1 지식 데이터를 취득하는 데 사용된다. 시맨틱 이해 서브모듈은, 제1 지식 데이터에 기초하여, 처리 대상 데이터에 대해 공통 시맨틱 이해를 진행하여 질문 특징, 후보 답안 특 징 및 제1 연관 정보를 얻는 데 사용되며, 여기서, 제1 연관 정보는 질문 데이터와 후보 답안 사이의 연관성을 나타낸다. 제3 결정 서브모듈은, 질문 특징, 후보 답안 특징 및 제1 연관 특징을 공통 데이터 특징으로 결정하 는 데 사용된다. 본 개시의 실시예에 의하면, 처리모듈은 제2 취득 서브모듈, 제2 처리 서브모듈 및 제4 결정 서브모듈을 포함한다. 제2 취득 서브모듈은, 제2 지식 데이터를 취득하는 데 사용된다. 제2 처리 서브모듈은, 목표 문답 처 리 모드를 이용하여 제2 지식 데이터에 기초하여, 공통 데이터 특징을 처리하고 질문 데이터 및 후보 답안 사이 의 제2 연관 정보를 얻는 데 사용된다. 제4 결정 서브모듈은, 제2 연관 정보에 기초하여, 후보 답안으로부터 질 문 데이터에 대한 목표 답안을 결정하는 데 사용된다. 본 발명의 실시예에 의하면, 처리 대상 데이터는 질문 데이터에 대한 설명 정보를 더 포함하고, 공통 데이터 특 징은 설명 정보에 대한 설명 특징을 더 포함한다. 도 7은 본 개시의 일 실시예에 따른 문답 모델의 훈련 장치의 블록도를 개략적으로 나타낸다. 도 7에 도시된 바와 같이, 본 개시의 실시예에 따른 문답 모델의 훈련 장치는, 예를 들어, 취득모듈, 시맨틱 이해모듈, 선택모듈, 처리모듈 및 조정모듈을 포함한다. 취득모듈은 질문 데이터, 후보 답안 및 샘플 라벨을 포함하는 샘플 데이터를 취득하는 데 사용될 수 있고, 여기서, 샘플 라벨은 후보 답안과 질문 데이터 사이의 연관성을 나타낸다. 본 개시의 실시예에 의하면, 취득모 듈은 예를 들어 상기 도 5에서 설명한 동작S510을 실행할 수 있으므로, 여기서는 설명을 생략한다. 시맨틱 이해모듈은 훈련 대상 문답 모델의 공통 이해 네트워크를 이용하여, 샘플 데이터에 대해 공통 시맨 틱 이해를 진행하여 공통 데이터 특징을 얻는 데 사용될 수 있다. 본 개시의 실시예에 의하면, 시맨틱 이해모듈 은 예를 들어 상기 도 5에서 설명한 동작S520을 실행할 수 있으므로, 여기서는 설명을 생략한다. 선택모듈은 훈련 대상 문답 모델의 후보 문답 네트워크에 대해, 공통 데이터 특징에 기초하여 후보 문답 네트워크로부터 목표 문답 네트워크를 선택하는 데 사용될 수 있다. 본 개시의 실시예에 의하면, 선택모듈(73 0)은 예를 들어 상기 도 5에서 설명한 동작S530을 실행할 수 있으므로, 여기서는 설명을 생략한다. 처리모듈은 목표 문답 네트워크를 이용하여 공통 데이터 특징을 처리하여 후보 답안 중 질문 데이터에 대 한 목표 답안을 얻는 데 사용될 수 있다. 본 개시의 실시예에 의하면, 처리모듈은 예를 들어 상기 도 5에 서 설명한 동작S540을 실행할 수 있으므로, 여기서는 설명을 생략한다. 조정모듈은 목표 답안 및 샘플 라벨에 기초하여, 훈련 대상 문답 모델의 모델 파라미터를 조정하는 데 사 용될 수 있다. 본 개시의 실시예에 의하면, 조정모듈은 예를 들어 상기 도 5에서 설명한 동작S550을 실행 할 수 있으므로, 여기서는 설명을 생략한다. 본 개시의 실시예에 의하면, 후보 문답 네트워크는 네트워크 라벨을 포함하고, 또한 선택모듈은, 공통 데 이터 특징과 네트워크 라벨 사이의 유사도에 기초하여, 후보 문답 네트워크로부터 목표 문답 네트워크를 선택하 는 데 사용되며, 여기서, 공통 데이터 특징은 질문 데이터의 분야 정보를 나타내고, 네트워크 라벨은 후보 문답 네트워크가 대한 분야를 나타낸다. 본 개시의 실시예에 의하면, 목표 문답 네트워크는 복수의 목표 문답 네트워크를 포함하고, 처리모듈은 제 1 처리 서브모듈, 제1 결정 서브모듈 및 제1 선택 서브모듈을 포함한다. 제1 처리 서브모듈은, 복수의 목표 문 답 네트워크 각각을 이용하여 공통 데이터 특징을 처리하여 복수의 목표 문답 네트워크와 일일이 대응하는 복수 의 목표 답안을 얻는 데 사용된다. 제1 결정 서브모듈은, 각 목표 문답 네트워크에 대해, 상기 유사도에 기초하 여 각 목표 문답 네트워크에 대한 목표 답안의 가중치를 결정하는 데 사용된다. 제1 선택 서브모듈은, 가중치에 기초하여, 복수의 목표 답안으로부터 질문 데이터에 대한 목표 답안을 선택하는데 사용된다. 본 개시의 실시예에 의하면, 후보 문답 네트워크는 복수의 후보 문답 네트워크를 포함하고, 선택모듈은 제 2 결정 서브모듈 및 제2 선택 서브모듈을 포함한다. 제2 결정 서브모듈은, 컴퓨팅 자원에 기초하여, 선택해야 하는 목표 문답 네트워크의 수량을 결정하는 데 사용된다. 제2 선택 서브모듈은, 수량 및 공통 데이터 특징에 기초하여, 복수의 후보 문답 네트워크로부터 수량의 목표 문답 네트워크를 선택하는 데 사용된다. 본 개시의 실시예에 의하면, 시맨틱 이해모듈은 제1 취득 서브모듈, 시맨틱 이해 서브모듈 및 제3 결정 서 브모듈을 포함한다. 제1 취득 서브모듈은, 제1 지식 데이터를 취득하는 데 사용된다. 시맨틱 이해 서브모듈은, 제1 지식 데이터에 기초하여, 샘플 데이터에 대해 공통 시맨틱 이해를 진행하여 질문 특징, 후보 답안 특징 및 제1 연관 정보를 얻는 데 사용되며, 여기서, 제1 연관 정보는 질문 데이터와 후보 답안 사이의 연관성을 나타낸 다. 제3 결정 서브모듈, 질문 특징, 후보 답안 특징 및 제1 연관 특징을 공통 데이터 특징으로 결정하는 데 사 용된다. 본 개시의 실시예에 의하면, 처리모듈은 제2 취득 서브모듈, 제2 처리 서브모듈 및 제4 결정 서브모듈을 포함한다. 제2 취득 서브모듈은, 제2 지식 데이터를 취득하는 데 사용된다. 제2 처리 서브모듈은, 목표 문답 네 트워크를 이용하여 제2 지식 데이터에 기초하여, 공통 데이터 특징을 처리하고 질문 데이터와 후보 답안 사이의 제2 연관 정보를 얻는 데 사용된다. 제4 결정 서브모듈은, 제2 연관 정보에 기초하여, 후보 답안으로부터 질문 데이터에 대한 목표 답안을 결정하는 데 사용된다. 본 개시의 실시예에 의하면, 샘플 데이터는 질문 데이터에 대한 설명 정보를 더 포함하고, 공통 데이터 특징은 설명 정보에 대한 설명 특징을 더 포함한다. 본 개시의 기술방안에 있어서, 관련되는 사용자 개인 정보의 수집, 저장, 응용, 가공, 전송, 제공 및 공개 등 처리는 모두 관련 법률과 법규의 규정에 부합되고, 공중도덕에 어긋나지 않는다. 본 개시의 실시예에 의하면, 본 개시는 전자기기, 컴퓨터 판독가능 저장매체 및 컴퓨터 프로그램 제품을 더 제 공한다. 도 8은 본 개시의 실시예를 구현하기 위한 문답 처리 및/또는 문답 모델의 훈련을 수행하기 위한 전자기기의 블 록도이다. 도 8은 본 개시의 실시예를 구현하는데 사용될 수 있는 예시적인 전자기기의 개략적인 블록도를 나타낸다. 전자기기는 예를 들어, 랩탑 컴퓨터, 데스크 탑 컴퓨터, 워크스테이션, PDA(Personal Digital Assistants), 서버, 블레이드 서버, 메인프레임 컴퓨터, 및 기타 적절한 컴퓨터와 같은 다양한 형태의 디지털 컴퓨터를 포함할 수 있다. 전자기기는 예를 들어, PDA(Personal Digital Assistants), 셀룰러 전화기, 스마트 폰, 웨어러블 장비, 및 기타 유사한 계산 장비와 같은 다양한 형태의 모바일 장비를 포함할 수 있다. 본 명세서 에 기재된 부품, 이들의 연결 및 관계, 그리고 이들의 기능은 단지 예시적인 것에 불과하며, 본 명세서에서 설 명 및/또는 요구하는 본 개시의 범위를 한정하기 위한 것이 아니다. 도 8에 도시된 바와 같이, 기기는 ROM(Read Only Memory)에 저장된 컴퓨터 프로그램 또는 저장 유닛 으로부터 RAM(Random Access Memory)에 로딩된 컴퓨터 프로그램에 따라 각종 적당한 동작 및 처리를 실행할 수 있는 컴퓨팅 유닛을 포함한다. 또한, RAM에는 기기의 동작에 필요한 다양한 프로그램 및 데이터가 더 저장될 수 있다. 컴퓨팅 유닛, ROM 및 RAM은 버스라인을 통해 서로 연결된다. 입력/출력(I/O) 인터페이스도 버스라인에 연결된다. 기기내의 복수의 부품은 I/O 인터페이스에 연결되고, 상기 부품에는, 예를 들어 키보드, 마우스 등과 같은 입력 유닛, 예를 들어 각종 유형의 디스플레이, 스피커 등과 같은 출력 유닛, 예를 들어 자기 디스크, 광 디스크 등과 같은 저장 유닛, 및 예를 들어 네트워크 카드, 모뎀, 무선 통신 송수신기 등과 같 은 통신 유닛이 포함된다. 통신 유닛에 의해, 기기는 인터넷과 같은 컴퓨터 네트워크 및/또는 각종 전자통신망을 통해 다른 장비와 정보/데이터를 교환할 수 있다. 컴퓨팅 유닛은 처리 기능 및 계산 기능을 가진 각종 범용 및/또는 주문형 처리 어셈블리일 수 있다. 컴퓨 팅 유닛의 일부 실예로서는, 중앙 처리 장치(CPU), 그래픽 처리 장치(GPU), 각종 주문형 인공지능(AI) 컴 퓨팅 칩, 각종 머신 러닝 모델 알고리즘을 운행하는 컴퓨팅 유닛, 디지털 신호 프로세서(DSP), 및 임의의 적합 한 프로세서, 컨트롤러, 마이크로 컨트롤러 등이 포함될 수 있는데, 이에 한정되지는 않는다. 컴퓨팅 유닛(80 1)은 앞에서 설명한 각 방법 및 처리를 실행하는데, 예를 들어 문답 처리 방법 및/또는 문답 모델의 훈련 방법 을 실행한다. 예를 들어, 일부 실시예에 있어서, 문답 처리 방법 및/또는 문답 모델의 훈련 방법은 예를 들어 저장 유닛과 같은 기계 판독가능 매체에 포함되는 컴퓨터 소프트웨어 프로그램의 형태로 실현될 수 있다. 일부 실시예에 있어서, 컴퓨터 프로그램의 일부 또는 전부는 ROM 및/또는 통신 유닛을 거쳐 기기 에 로딩 및/또는 설치될 수 있다. 컴퓨터 프로그램이 RAM에 로딩되고 컴퓨팅 유닛에 의해 실행 될 경우, 앞에서 설명한 문답 처리 방법 및/또는 문답 모델의 훈련 방법의 하나 또는 복수의 단계를 실행할 수 있다. 선택적으로, 다른 실시예에 있어서, 컴퓨팅 유닛은 다른 임의의 적합한 방식(예를 들어, 펌웨어)을 통해 문답 처리 방법 및/또는 문답 모델의 훈련 방법을 실행하도록 구성될 수 있다. 본 명세서에서 설명한 시스템 및 기술의 다양한 실시 형태는 디지털 전자 회로 시스템, 집적 회로 시스템, FPGA(Field Programmable Gate Array), ASIC(Application Specific Integrated circuit), ASSP(Application Specific Standard Product), SOC(System on Chip), CPLD(Complex Programmable Logic Device), 컴퓨터 하드 웨어, 펌웨어, 소프트웨어, 및/또는 이들의 조합으로 구현될 수 있다. 이러한 다양한 실시 형태는 하나 또는 복 수의 컴퓨터 프로그램을 통해 구현될 수 있고, 상기 하나 또는 복수의 컴퓨터 프로그램은 적어도 하나의 프로그 램 가능 프로세서를 포함하는 프로그램 가능 시스템에서 실행 및/또는 해석될 수 있으며, 상기 프로그램 가능 프로세서는 주문형 또는 범용 프로그램 가능 프로세서일 수 있고, 저장 시스템, 적어도 하나의 입력장치, 및 적 어도 하나의 출력장치로부터 데이터 및 명령어를 수신하고, 데이터 및 명령어를 저장 시스템, 적어도 하나의 입 력장치, 및 적어도 하나의 출력장치로 전송할 수 있다. 본 개시의 방법을 실시하기 위한 프로그램 코드는 하나 또는 복수의 프로그래밍 언어의 임의의 조합을 통해 프 로그래밍을 실행할 수 있다. 이러한 프로그램 코드는 범용 컴퓨터, 주문형 컴퓨터 또는 다른 프로그래밍 가능한 문답 처리 장치 및/또는 문답 모델의 훈련 장치의 프로세서 또는 컨트롤러에 제공되어, 프로그램 코드가 프로세 서 또는 컨트롤러에 의해 실행됨으로써, 흐름도 및/또는 블록도에서 규정한 기능/동작을 실시하도록 할 수 있다. 프로그램 코드는 전부 머신에 의해 실행되거나 또는 부분적으로 머신에 의해 실행될 수 있고, 또는 독립 적인 소프트웨어 패키지로서 부분적으로 머신에 의해 실행됨과 동시에 부분적으로 원격 머신에 의해 실행되거나, 또는 전부 원격 머신 또는 서버에 의해 실행될 수 있다. 본 명세서에 있어서, 기계 판독가능 매체는 실체적인 매체일 수 있고, 상기 매체에는 명령어 실행 시스템, 장치 또는 기기에 의해 사용되거나 또는 명령어 실행 시스템, 장치 또는 기기와 결합하여 사용되는 프로그램이 포함 되거나 저장될 수 있다. 기계 판독가능 매체는 기계 판독가능 신호 매체 또는 기계 판독가능 저장매체일 수 있 다. 기계 판독가능 신호 매체는, 전자적, 자기적, 광학적, 전자기적, 적외선적 반도체 시스템, 장치 또는 기기, 또는 이들의 임의의 적합한 조합을 포함할 수 있는데, 이에 한정되지는 않는다. 기계 판독가능 저장매체의 보다 구체적인 실예로는, 하나 또는 복수의 라인에 의해 전기적으로 연결되는 휴대용 컴퓨터 디스크, 하드 디스크, RAM, ROM, EPROM(Erasable Programming ROM), 플래시 메모리, 광 파이버, CD-ROM, 광학적 저장 장비, 자기적 저장 장비, 또는 이들의 임의의 적합한 조합일 수 있다. 사용자와의 인터액션을 제공하기 위해서는, 컴퓨터를 통해 본 명세서에서 설명한 시스템 및 기술을 구현할 수 있는데, 상기 컴퓨터는, 사용자에게 정보를 표시하기 위한 문답 처리 장치 및/또는 문답 모델의 훈련 장치(예를 들어, CRT(음극선관) 또는 LCD(액정 디스플레이) 모니터), 및 사용자가 상기 컴퓨터에 입력을 제공할 수 있는 키보드 및 포인팅 디바이스(예를 들어, 마우스 또는 트랙 볼)를 포함한다. 기타 유형의 장치도 사용자와의 인터 액션을 제공하는데 사용될 수 있다. 예를 들어, 사용자에게 제공되는 피드백은 임의의 형태의 센싱 피드백(예를 들어, 시각 피드백, 청각 피드백, 또는 촉각 피드백)일 수 있고, 임의의 형태(소리 입력, 음성 입력, 또는 촉각입력을 포함)로 사용자로부터의 입력을 수신할 수 있다. 본 명세서에서 설명한 시스템 및 기술은, 백 그라운더 부품을 포함하는 컴퓨팅 시스템(예를 들어, 데이터 서 버), 또는 미들웨어 부품을 포함하는 컴퓨팅 시스템(예를 들어, 애플리케이션 서버), 또는 프론트 앤드 부품을 포함하는 컴퓨팅 시스템(예를 들어, GUI 또는 웹 브라우저를 갖는 사용자 컴퓨터로서, 사용자는 상기 GUI 또는 상기 웹 브라우저를 통하여 본 명세서에서 설명한 시스템 및 기술의 실시 형태와 인터액션을 할 수 있음), 또는 이러한 백 그라운더 부품, 미들웨어 부품, 또는 프론트 앤드 부품의 임의의 조합을 포함하는 컴퓨팅 시스템에서 구현될 수 있다. 시스템의 부품은 임의의 형태 또는 매체의 디지털 데이터 통신(예를 들어, 통신 네트워크)을 통해 서로 연결될 수 있다. 통신 네트워크는 예를 들어 근거리 통신망(LAN), 광역 통신망(WAN) 및 인터넷을 포 함할 수 있다. 컴퓨터 시스템은 클라이언트 및 서버를 포함할 수 있다. 클라이언트 및 서버는 일반적으로 서로 멀리 떨어져 있 고, 통상적으로 통신 네트워크를 통해 인터액션을 진행한다. 클라이언트와 서버의 관계는 대응하는 컴퓨터에서 실행되고 서로 클라이언트-서버의 관계를 갖는 컴퓨터 프로그램에 의해 생성된다. 서버는 클라우드 서버일 수도 있고, 분산 시스템의 서버 또는 블록체인과 결합된 서버일 수도 있다. 상기에서 설명한 다양한 프로세스를 사용하여 각 단계의 순서를 조정하거나, 일부 단계를 추가 또는 삭제할 수 있다는 점을 이해하여야 한다. 예를 들어, 본 개시에 개시된 기술 방안이 원하는 결과를 구현할 수 있는 한, 본 개시에 기재된 다양한 단계는 병렬적으로 또는 순차적으로, 또는 서로 다른 순서로 실행될 수 있고, 본 개시는 이에 대해 특별히 한정하지 않는다. 본 개시의 보호범위는 상기 다양한 실시 형태에 의해 제한되지 않는다. 당업자라면, 설계 요구 및 기타 요인에 의해, 다양한 수정, 조합, 서브 조합 및 교체가 이루어질 수 있음을 이해할 것이다. 본 개시의 취지 및 원칙 내 에서 이루어진 임의의 수정, 등가 교체 및 개선 등은 모두 본 개시의 보호범위에 속한다. 도면 도면1 도면2 도면3 도면4 도면5 도면6 도면7 도면8"}
{"patent_id": "10-2022-0187955", "section": "도면", "subsection": "도면설명", "item": 1, "content": "첨부된 도면은 본 기술방안을 보다 쉽게 이해하도록 하기 위한 것이고, 본 개시는 이에 한정되지 않는다. 도 1은 예시적인 문답 처리의 응용장면을 개략적으로 나타낸다. 도 2는 본 개시의 일 실시예에 따른 문답 처리 방법의 흐름도를 개략적으로 나타낸다. 도 3은 본 개시의 일 실시예에 따른 문답 처리 방법의 원리도를 개략적으로 나타낸다. 도 4는 본 개시의 다른 실시예에 따른 문답 처리 방법의 원리도를 개략적으로 나타낸다. 도 5는 본 개시의 일 실시예에 따른 문답 모델의 훈련 방법의 흐름도를 개략적으로 나타낸다. 도 6은 본 개시의 일 실시예에 따른 문답 처리 장치의 블록도를 개략적으로 나타낸다. 도 7은 본 개시의 일 실시예에 따른 문답 모델의 훈련 장치의 블록도를 개략적으로 나타낸다. 및 도 8은 본 개시의 실시예를 구현하기 위한 문답 처리 및/또는 문답 모델의 훈련을 수행하기 위한 전자 기기의 블록도이다."}
