{"patent_id": "10-2023-0025272", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0131787", "출원번호": "10-2023-0025272", "발명의 명칭": "비협조적인 환경에서 무인항공기의 카메라 영상 정보를 기반으로 다수 목표물의 GPS 좌표를", "출원인": "경북대학교 산학협력단", "발명자": "이규만"}}
{"patent_id": "10-2023-0025272", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "학습된(Pre-training)인공지능 딥러닝 모델을 통해, 무인항공기에 설정된 임무에 대응하는 목표물을 탐지(detect)하고, 탐지된 목표물을 포함하는 바운딩 박스(Bounding box)를 생성하는 탐지부;카메라 이미지 평면(image plane)상에 픽셀로 나타낸 목표점인 기준 픽셀을 설정하는 설정부;2차원 픽셀 좌표계에서 상기 목표물의 기준 픽셀 좌표를 산출하는 산출부;무인항공기의 고도정보, 목표물의 깊이(depth) 정보 중 적어도 하나를 이용하여, 상기 목표물의 기준 픽셀 좌표를 3차원 좌표로 변환하고, 변환된 3차원 좌표의 좌표계를 변환하여 목표물의 GPS 좌표를 획득하는 변환부; 를포함하는 무인항공기의 카메라 영상 정보를 기반으로 목표물의 GPS 좌표를 추정하는 장치."}
{"patent_id": "10-2023-0025272", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 목표물은지상 목표물과 상공 목표물을 포함하고, 상기 변환부; 는 무인항공기의 고도정보를 상기 지상 목표물의 깊이 정보로 이용하여, 상기 목표물의 기준 픽셀 좌표를 3차원 좌표로 변환하는 것을 특징으로 하는 무인항공기의 카메라 영상 정보를 기반으로 목표물의 GPS 좌표를 추정하는장치."}
{"patent_id": "10-2023-0025272", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서, 상기 변환부; 는 깊이를 측정하는 스테레오 카메라나 깊이 카메라를 통해 상기 상공 목표물의 깊이 정보를 획득하여, 상기 목표물의 기준 픽셀 좌표를 3차원 좌표로 변환하는 것을 특징으로 하는 무인항공기의 카메라 영상 정보를 기반으로목표물의 GPS 좌표를 추정하는 장치."}
{"patent_id": "10-2023-0025272", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제2항 또는 3항에 있어서, 상기 변환부; 는 무인항공기의 카메라 모델을 통해, 2차원 좌표인 목표물의 기준 픽셀 좌표에 대한 카메라 좌표계의 3차원 위치를 계산하고, 카메라와 무인항공기 CG(Center of Gravity) 간 외부 파라미터 값을 이용하여, 목표물의 기준 픽셀 좌표를 무인항공기의 몸체 좌표계에 대한 3차원 좌표로 변환하는 것을 특징으로 하는 무인항공기의 카메라영상 정보를 기반으로 목표물의 GPS 좌표를 추정하는 장치."}
{"patent_id": "10-2023-0025272", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서, 상기 변환부; 는무인항공기의 현재 GPS 좌표를 이용해서 무인항공기 몸체 좌표계로 나타낸 목표물의 3차원 좌표를, ECEF(Earth-Centered Earth-Fixed)좌표계로 변환한 후, 다시 LLA(Latitude-Longitude-Altitude)좌표계로 변환하여, 목표물공개특허 10-2024-0131787-3-의 GPS 좌표를 획득하는 것을 특징으로 하는 무인항공기의 카메라 영상 정보를 기반으로 목표물의 GPS 좌표를추정하는 장치."}
{"patent_id": "10-2023-0025272", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "(A) 탐지부에서 학습된(Pre-training) 인공지능 딥러닝 모델을 통해, 무인항공기에 설정된 임무에 대응하는 목표물을 탐지(detect)하고, 탐지된 목표물을 포함하는 바운딩 박스(Bounding box)를 목표물의 크기에 따라 생성하는 단계;(B) 설정부에서 카메라 이미지 평면(image plane)상에 픽셀로 나타낸 목표점인 기준 픽셀을 설정하는 단계;(C) 산출부에서 2차원 픽셀 좌표계에서 상기 목표물의 기준 픽셀 좌표를 산출하는 단계;(D) 변환부에서 무인항공기의 고도정보, 목표물의 깊이(depth) 정보 중 적어도 하나를 이용하여, 상기 목표물의기준 픽셀 좌표를 3차원 좌표로 변환하고, 변환된 3차원 좌표의 좌표계를 변환하여 목표물의 GPS 좌표를 획득하는 단계; 를 포함하는, 무인항공기의 카메라 영상 정보를 기반으로 목표물의 GPS 좌표를 추정하는 방법."}
{"patent_id": "10-2023-0025272", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6항에 있어서, 상기 목표물은지상 목표물과 상공 목표물을 포함하고,상기 (D)의 단계; 는 무인항공기의 고도정보를 상기 지상 목표물의 깊이 정보로 이용하여, 상기 목표물의 기준 픽셀 좌표를 3차원 좌표로 변환하는 것을 특징으로 하는, 무인항공기의 카메라 영상 정보를 기반으로 목표물의 GPS 좌표를 추정하는방법."}
{"patent_id": "10-2023-0025272", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제6항에 있어서, 상기 (D)의 단계; 는 깊이를 측정하는 스테레오 카메라나 깊이 카메라를 통해 상기 상공 목표물의 깊이 정보를 획득하여, 상기 목표물의 기준 픽셀 좌표를 3차원 좌표로 변환하는 것을 특징으로 하는, 무인항공기의 카메라 영상 정보를 기반으로목표물의 GPS 좌표를 추정하는 방법."}
{"patent_id": "10-2023-0025272", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제7항 또는 8항에 있어서, 상기 (D)의 단계; 는 무인항공기의 카메라 모델을 통해, 2차원 좌표인 목표물의 기준 픽셀 좌표에 대한 카메라 좌표계의 3차원 위치를 계산하고, 카메라와 무인항공기 CG(Center of Gravity) 간 외부 파라미터 값을 이용하여, 목표물의 기준 픽셀 좌표를 무인항공기의 몸체 좌표계에 대한 3차원 좌표로 변환하는 것을 특징으로 하는, 무인항공기의 카메라영상 정보를 기반으로 목표물의 GPS 좌표를 추정하는 방법."}
{"patent_id": "10-2023-0025272", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9항에 있어서, 상기 (D)의 단계; 는무인항공기의 현재 GPS 좌표를 이용해서 무인항공기 몸체 좌표계로 나타낸 목표물의 3차원 좌표를, ECEF(Earth-Centered Earth-Fixed)좌표계로 변환한 후, 다시 LLA(Latitude-Longitude-Altitude)좌표계로 변환하여, 목표물공개특허 10-2024-0131787-4-의 GPS 좌표를 획득하는 것을 특징으로 하는, 무인항공기의 카메라 영상 정보를 기반으로 목표물의 GPS 좌표를추정하는 방법."}
{"patent_id": "10-2023-0025272", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "실시예에 따른 무인항공기의 카메라 영상 정보를 기반으로 목표물의 GPS 좌표를 추정하는 장치는 학습된(Pre- training) 인공지능 딥러닝 모델을 통해, 무인항공기에 설정된 임무에 대응하는 목표물을 탐지(detect)하고, 탐 지된 목표물을 포함하는 바운딩 박스(Bounding box)를 목표물의 크기에 따라 생성하는 탐지부; 카메라 이미지 평 면(image plane)상에 픽셀로 나타낸 목표점인 기준 픽셀을 설정하는 설정부; 2차원 픽셀 좌표계에서 목표물의 기 준 픽셀 좌표를 산출하는 산출부; 무인항공기의 고도정보, 목표물의 깊이(depth) 정보 중 적어도 하나를 이용하 여, 상기 목표물의 기준 픽셀 좌표를 3차원 좌표로 변환하고, 변환된 3차원 좌표의 좌표계를 변환하여 목표물의 GPS 좌표를 획득하는 변환부; 를 포함한다."}
{"patent_id": "10-2023-0025272", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 목표물의 GPS 좌표를 추정하는 장치 및 방법에 관한 것으로 구체적으로, 비협조적인 환경에서 무인항 공기의 카메라 영상 정보를 기반으로 다수 목표물의 GPS 좌표를 추정하는 장치 및 방법에 관한 것이다."}
{"patent_id": "10-2023-0025272", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "본 명세서에서 달리 표시되지 않는 한, 이 섹션에 설명되는 내용들은 이 출원의 청구항들에 대한 종래 기술이 아니며, 이 섹션에 포함된다고 하여 종래 기술이라고 인정되는 것은 아니다. 실종자 수색 또는 안티 드론 차원의 레이더로 잡히지 않는 표적의 전역 위치 계산과 같은 임무 수행을 위해서는 다수 목표물의 위치 좌표를 정확하게 파악하는 것이 중요하다. 이를 위해, 목표물에 설치된 위치 센서나 단말을 통해, 목표물의 위치 좌표를 획득할 수도 있겠지만, 실종자 수색, 탐지 등의 실제 상황에서는 비협조적인 환경 에서도 목표물의 위치 좌표를 획득해야만 한다. 비협조적인 환경은 예컨대, 상호 통신이 불가능한 목표물이거나 ADS-B(Automatic Dependent Surveillance - Broadcast) 와 같은 시스템이 탑재되어 있지 않은 목표물인 경우와 같이 무선통신을 통해 목표물의 위치를 파악할 수 없는 경우를 의미한다. 이러한 비협조적인 환경에서는 일반적 으로 목표물의 위치를 가늠하기 어려운 실정이다. 선행기술문헌 특허문헌 (특허문헌 0001) 1. 한국 특허공개 제10-2021-0146562호 (2021.12.06) (특허문헌 0002) 2. 한국 특허등록 제10-0496814호 (2005.06.14)"}
{"patent_id": "10-2023-0025272", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "실시예에 따른 무인항공기의 카메라 영상 정보를 기반으로 목표물의 GPS 좌표를 추정하는 장치 및 방법은 무인 항공기에 탑재된 카메라 영상을 기반으로 탐지된 다수 목표물의 GPS 좌표를 계산하여, 3차원 지도상에서 다수 목표물의 정확한 전역 위치를 추정한다. 실시예에서는 학습된(pre-training) 인공지능 딥러닝 모델을 통해서 실종자, 교통법규 위반차량 탐지 등 주어진 임무에 대응하는 목표물을 자동으로 탐지(detect)한다. 실시예에서는 탐지된 목표물을 포함하는 목표물 크기에 따른 바운딩 박스를 생성한다. 실시예에서는 탐지된 목표물의 탐지 위치(지상, 상공)에 따라 바운딩 박스의 기 준 픽셀을 설정하고, 목표물의 기준 픽셀 좌표를 산출하여, 산출된 기준 픽셀 좌표를 무인항공기 좌표계를 포함 하는 좌표계로 변환한 후 무인항공기의 목표물 GPS 좌표를 최종적으로 획득한다. 실시예에 따른 무인항공기의 카메라 영상 정보를 기반으로 목표물의 GPS 좌표를 추정하는 장치 및 방법은 사용 자의 목적에 따라서 바운딩 박스 내 원하는 목표물 기준 픽셀을 선택할 수 있다. 또한, 실시예에 따른 무인항공 기의 카메라 영상 정보를 기반으로 목표물의 GPS 좌표를 추정하는 장치 및 방법은 탐지된 목표물이 지상 목표물 인 경우에는 무인항공기에 탑재된 고도계 정보를 통해 깊이 정보를 계산하고, 상공 목표물인 경우에는 스테레오 카메라나 깊이 카메라를 탑재하여 목표물의 깊이 정보를 획득할 수 있다."}
{"patent_id": "10-2023-0025272", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "실시예에 따른 무인항공기의 카메라 영상 정보를 기반으로 목표물의 GPS 좌표를 추정하는 장치는, 학습된(Pre- training) 인공지능 딥러닝 모델을 통해, 무인항공기에 설정된 임무에 대응하는 목표물을 탐지(detect)하고, 탐 지된 목표물을 포함하는 바운딩 박스(Bounding box)를 생성하는 탐지부; 카메라 이미지 평면(image plane)상에 픽셀로 나타낸 목표점인 기준 픽셀을 설정하는 설정부; 2차원 픽셀 좌표계에서 목표물의 기준 픽셀 좌표를 산출 하는 산출부; 목표물의 고도정보, 깊이(depth) 정보 중 적어도 하나를 이용하여, 목표물의 기준 픽셀 좌표를 3 차원 좌표로 변환하고, 변환된 3차원 좌표의 좌표계를 변환하여 목표물의 GPS 좌표를 획득하는 변환부; 를 포함 한다."}
{"patent_id": "10-2023-0025272", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "이상에서와 같은 무인항공기의 카메라 영상 정보를 기반으로 목표물의 GPS 좌표를 추정하는 장치 및 방법은 목 표물의 개수나 상공, 지상 등 목표물의 탐지 위치에 관계없이 카메라 영상을 통해 자동으로 목표물의 전역 위치 를 지도에 표시함으로써, 실종자 수색 또는 안티 드론 차원의 레이더로 잡히지 않는 표적의 전역 위치 계산과 같은 다양한 임무를 보다 정확하게 수행할 수 있도록 한다. 실시예에 따른 무인항공기의 카메라 영상 정보를 기반으로 목표물의 GPS 좌표를 추정하는 장치 및 방법은 컴퓨 터 비전, 인공지능, 로보틱스, 항공우주, 비행 동역학 좌표변환 분야에서 도출된 것으로, 실종자 수색, 침범 무 인기 탐지 등에 활용될 수 있다. 실시예에 따른 무인항공기의 카메라 영상 정보를 기반으로 목표물의 GPS 좌표를 추정하는 장치 및 방법은 무인 항공기를 활용한 실종자, 유류품 수색, 위험 지역에 있는 사람들의 위치 정보 추정, 무인항공기의 착륙 및 배달 을 위한 목적지의 GPS 좌표 추정, 시설물 점검 시 점검 대상의 위치 정보 획득 및 상공에 위치한 적군 무인기의 GPS 좌표 추정 과정 등에서 이용될 수 있다."}
{"patent_id": "10-2023-0025272", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 2, "content": "본 발명의 효과는 상기한 효과로 한정되는 것은 아니며, 본 발명의 상세한 설명 또는 특허청구범위에 기재된 발 명의 구성으로부터 추론 가능한 모든 효과를 포함하는 것으로 이해되어야 한다."}
{"patent_id": "10-2023-0025272", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명의 이점 및 특징, 그리고 그것들을 달성하는 방법은 첨부되는 도면과 함께 상세하게 후술되어 있는 실시 예들을 참조하면 명확해질 것이다. 그러나 본 발명은 이하에서 개시되는 실시 예들에 한정되는 것이 아니라 서 로 다른 다양한 형태로 구현될 수 있으며, 단지 본 실시 예들은 본 발명의 개시가 완전하도록 하고, 본 발명이"}
{"patent_id": "10-2023-0025272", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "속하는 기술분야에서 통상의 지식을 가진 자에게 발명의 범주를 완전하게 알려주기 위해 제공되는 것이며, 본 발명은 청구항의 범주에 의해 정의될 뿐이다. 명세서 전체에 걸쳐 동일 도면부호는 동일 구성 요소를 지칭한다. 본 발명의 실시 예들을 설명함에 있어서 공지 기능 또는 구성에 대한 구체적인 설명이 본 발명의 요지를 불필요 하게 흐릴 수 있다고 판단되는 경우에는 그 상세한 설명을 생략할 것이다. 그리고 후술되는 용어들은 본 발명의 실시 예에서의 기능을 고려하여 정의된 용어들로서 이는 사용자, 운용자의 의도 또는 관례 등에 따라 달라질 수 있다. 그러므로 그 정의는 본 명세서 전반에 걸친 내용을 토대로 내려져야 할 것이다. 실시예에 따른 무인항공기의 카메라 영상 정보를 기반으로 목표물의 GPS 좌표를 추정하는 장치 및 방법은 무인 항공기에 탑재된 카메라 영상을 기반으로 탐지된 다수 목표물의 GPS 좌표인 위치 좌표를 추정하여, 3차원 지도 상에서 다수 목표물의 정확한 전역 위치를 표시한다. 실시예에서는 학습된(pre-training) 인공지능 딥러닝 모델을 통해서 실종자, 교통법규 위반차량 탐지 등 주어진 임무에 대응하는 목표물을 자동으로 탐지(detect)한다. 실시예에서는 탐지된 목표물을 포함하는 목표물 크기에 따른 바운딩 박스를 생성한다. 실시예에서는 탐지된 목표물의 탐지 위치(지상, 상공)에 따라 바운딩 박스의 기 준 픽셀을 설정하고, 목표물의 기준 픽셀 좌표를 산출하여, 산출된 기준 픽셀 좌표를 3차원 좌표로 변환한 후 무인항공기의 GPS 좌표를 사용하여 적절히 좌표 변환하여, GPS 좌표를 최종적으로 획득한다. 실시예에 따른 무인항공기의 카메라 영상 정보를 기반으로 다수 목표물의 GPS 좌표를 추정하는 장치 및 방법은 사용자의 목적에 따라서 바운딩 박스 내 원하는 목표물 기준 픽셀을 선택할 수 있다. 또한, 실시예에 따른 다수 목표물의 GPS 좌표를 추정하는 장치 및 방법은 탐지된 목표물이 지상 목표물인 경우에는 무인항공기에 탑재된 고도계 정보를 통해 깊이 정보를 계산하고, 상공 목표물인 경우에는 스테레오 카메라나 깊이 카메라를 통해 목 표물의 깊이 정보를 획득할 수 있다. 좌표를 변환할 때에는 깊이 정보가 필요하다. 2차원 이미지에서 3차원 공 간(2D to 3D)으로 좌표 변환하는 경우, 2차원 정보를 가지고 3차원 복원하다는 것은 한 차원 정보를 더 생성하 는 것이다. 이 경우 스케일 불명확성(scale ambiguity)이 발생하여, 정확한 스케일(scale)은 모르기 때문에, 비 율대로 비례하게 복원할 수 있다. 만약, 정확하게 알고 있는 깊이 정보인, 기준이 되는 한 축의 값을 알고 있다 면, 스케일(scale)을 정확히 알기 때문에 더 이상 비례해서 변환하는 것이 아니라 2차원 이미지에서 3차원 공간 (2D to 3D)으로 정확한 좌표변환을 할 수 있다. 무인항공기는 고도계를 사용하여 고도 정보를 알고 있기 때문에 지상 목표물의 스케일(scale)을 알기 위한 깊이 정보로 측정된 고도값을 사용한다. 상공 목표물인 경우는 탑재 되어 있는 스테레오 카메라, 깊이 카메라 등 깊이 정보를 측정할 수 있는 카메라 센서를 통해 깊이 정보를 알 수 있다. 도 1은 실시예에 따른 무인항공기의 목표물 GPS 좌표 추정 장치의 데이터 처리 구성을 나타낸 도면이다. 도 1을 참조하면, 실시예에 따른 무인항공기의 목표물 GPS 좌표 추정 장치는 탐지부, 설정부, 산출부 및 변환부를 포함하여 구성될 수 있다. 본 명세서에서 사용되는 '부' 라는 용어는 용어가 사 용된 문맥에 따라서, 소프트웨어, 하드웨어 또는 그 조합을 포함할 수 있는 것으로 해석되어야 한다. 예를 들어, 소프트웨어는 기계어, 펌웨어(firmware), 임베디드코드(embedded code), 및 애플리케이션 소프트웨어일 수 있다. 또 다른 예로, 하드웨어는 회로, 프로세서, 컴퓨터, 집적 회로, 집적 회로 코어, 센서, 멤스(MEMS; Micro-Electro-Mechanical System), 수동 디바이스, 또는 그 조합일 수 있다. 탐지부는 학습된(Pre-training) 인공지능 딥러닝 모델을 통해, 무인항공기에 설정된 임무에 대응하는 목표 물을 탐지(detect)한다. 무인항공기에 설정된 임무는 실종자 수색, 차량 탐지 및 상공의 적군기 탐지 등을 포함 할 수 있다. 또한, 실시예에서 탐지부는 적어도 하나 이상의 목표물을 탐지하는 멀티 타겟팅(Multi Targeting)을 수행할 수 있다. 실시예에서 탐지부는 지상 목표물과 상공 목표물을 모두 탐지할 수 있다. 지상 목표물은 지상에 위치하는 목표물이고, 상공 목표물은 상공에 위치하는 목표물이다. 실시예에서 탐지부는 지상 목표물 탐지 과정과 상공 목표물 탐지 과정이 구분되어 트레이닝된 인공지능 딥러닝 모델을 통해, 지상 목표물과 상공 목표물을 탐 지할 수 있다. 실시예에서 인공지능 딥러닝 모델은 DNN(Deep Neural Network), CNN(Convolutional Neural Network) RNN(Recurrent Neural Network) 및 BRDNN(Bidirectional Recurrent Deep Neural Network) 중 적어도 하나를 포함하고, 이에 한정하지 않는다. 실시예에서 인공지능 딥러닝 모델은 지상 목표물의 종류에 따라 다양 한 목표물 탐지 과정을 분류하고, 분류된 목표물 탐지 과정을 학습할 수 있다. 목표물의 종류에는 사람, 유류품, 모자, 자전거 등이 포함될 수 있으나, 이에 한정되지 않는다. 탐지부는 탐지된 목표물이 포함된 바운딩 박스(Bounding box)를 목표물의 크기에 따라 생성한다. 이후, 설정부는 바운딩 박스에 포함된 목표물의 기준 픽셀을 설정한다. 실시예에서 목표물의 기준 픽셀은 카메라 이미지 평면(image plane)상에 픽셀로 나타낸 목표점일 수 있다. 즉, 설정부는 바운딩 박스 내에서 목표점을 획득하기 위해 기준 픽셀을 설정할 수 있다. 실시예에서 설정부는 목표물의 기준 픽셀을 바운딩 박스의 중심점으로 설정할 수 있다. 또한, 실시예에서 설정부는 사용자의 목적에 따라 바운딩 박스 내에서 목표물의 기준 픽셀을 원하는 픽셀 로 설정할 수도 있다. 예컨대, 사용자의 목적이 격추이고, 목표물이 항공기인 경우, 항공기의 날개 부분이 목표 물의 기준 픽셀로 설정될 수 있고, 목표물이 건물인 경우, 건물의 핵심 부분이 기준 픽셀로 설정될 수 있다. 또 한, 사용자의 목적이 수색이고, 목표물이 사람인 경우, 사람의 자세에 따라 목표물의 기준 픽셀이 설정될 수 있 다. 예컨대, 서 있는 사람이라면, 지면의 위치 정보가 필요하기 때문에, 탐지된 사람의 발 쪽 부분이 목표물의 기준 픽셀로 설정될 수 있다. 만일 누워 있는 사람이라면, 사람의 몸통부분이 목표물의 기준 픽셀로 설정될 수 있다. 산출부는 2차원 픽셀 좌표계에서 목표물의 기준 픽셀 좌표를 산출한다. 산출부는 설정부에서 설 정된 목표물의 기준 픽셀을 2차원 픽셀 좌표계에서의 좌표값으로 산출한다. 변환부는 무인항공기의 고도정보, 깊이(depth) 정보 중 적어도 하나를 이용하여, 목표물의 기준 픽셀 좌표 를 3차원 좌표로 변환한다. 여기서, 3차원 좌표는 카메라 좌표계 기준 3차원 값이다. 이를 무인항공기 몸체 좌 표계로 변환하기 위해서는 외부 파라미터(extrinsic parameter)가 사용된다. 외부 파라미터는, 무인항공기 몸체 중심을 기준으로 카메라가 어디에 탑재되어 있고, 어느 방향으로 탑재되어 있는지를 나타내는 변수로서, 카메라 틸트각을 포함할 수 있다. 즉, 실시예에서 변환된 3차원 좌표의 좌표계는, 무인항공기에서 사용하는 무인항공기 몸체 좌표계일 수 있다. 이후, 변환부는 3차원 좌표의 좌표계를 변환하여 무인항공기의 목표물 GPS 좌표를 획득한다. 이하, 변환부에서의 목표물 GPS 좌표 획득 과정을 상세히 설명한다. 도 2는 실시예에 따른 변환부의 데이터 처리 구성을 나타낸 도면이다. 도 2를 참조하면, 실시예에 따른 변환부는 차원 변환부, 좌표계 변환부 및 GPS 좌표 획득부 를 포함하여 구성될 수 있다. 실시예에서 차원 변환부는 기준 픽셀 좌표의 좌표계를 변환한다. 차원 변환부는 목표물의 기준 픽셀 좌표를, 2차원 픽셀 좌표계에서 3차원인 무인항공기 몸체 좌표계로 변환할 수 있다. 보다 구체적으로, 차원 변환부는 지상 목표물인 경우, 무인항공기의 고도정보를 지상 목표물의 깊이 정보 로 이용하여, 2차원 픽셀 좌표계에서 산출된 목표물의 기준 픽셀 좌표를 3차원으로 변환한다. 실시예에서 차원 변환부는 무인항공기의 카메라 모델을 통해, 2차원 좌표인 목표물의 기준 픽셀 좌표에 대 한 카메라 좌표계의 3차원 위치 차이를 계산하고, 카메라와 무인항공기 CG(Center of Gravity) 간 외부 파마리 터 값을 이용하여, 목표물의 기준 픽셀 좌표를 무인항공기의 몸체 좌표계에 대한 3차원 좌표로 변환한다. 도 3은 실시예에 따른 무인항공기와 지상 목표물의 위치 관계를 나타낸 도면이다. 도 3을 참조하면, 실시예에서 차원 변환부는, 무인항공기에 탑재된 카메라를 핀홀 카메라 모델로 설정하여, 2차원 기준 픽셀 좌표를 수학식 1을 통해 카메라의 3차원 좌표로 변환할 수 있다. 수학식 1 Pc~K-1Pu (K: 카메라의 고유 행렬(intrinsic matrix), Pu(u,v,1)T: 픽셀 좌표계의 2차원 좌표를 동차 좌표계(homogeneous coordinate)로 나타낸 3차원 벡터, Pc: 카메라 좌표계로 변환된 3차원 좌표) 이후, 차원 변환부는 카메라 좌표계와 무인항공기 몸체 좌표계의 원점이 같은 위치에 놓여 있다고 가정하 고, 수학식 2를 이용하여 카메라 좌표계로 변환된 3차원 좌표 Pc를 무인항공기 몸체 좌표계의 벡터 PB로 변환한 다. 수학식 2 PB=RBCPC (RBC: 카메라 좌표계로부터 무인항공기 몸체 좌표계로의 3차원 회전 변환 행렬, Pc: 카메라 좌표계로 변환된 3차 원 좌표) 차원 변환부는 무인항공기에 탑재된 카메라가 지면 방향으로 0도 이상 90도 이하의 범위에서 틸트(tilt)되 어 있으므로, 카메라 좌표계로부터 무인항공기 몸체 좌표계로의 3차원 회전 변환 행렬RBC을 수학식 3을 통해 산 출할 수 있다. 수학식 3 RBC=Ry(-π/2) Rz(-π/2) Rx(θ) (Ry: y축 회전 변환 행렬, Rz: z축 회전 변환 행렬 Rx: x축 회전 변환 행렬) 이후, 차원 변환부는 수학식 1 및 수학식 2를 통해, 도출된 수학식 4를 이용하여 무인항공기 몸체 좌표계 의 벡터 PB를 산출한다. 수학식 4 PB~ RBC K-1Pu (K: 카메라의 내부 파라미터(intrinsic matrix), Pu(u,v,1)T: 픽셀 좌표계의 2차원 좌표를 동차 좌표계 (homogeneous coordinate)로 나타낸 3차원 벡터) 한편, 차원 변환부는 탐지된 목표물이 상공 목표물인 경우, 무인항공기에 탑재된 스테레오 카메라 또는 깊이(depth) 카메라를 통해 상공 목표물의 깊이(depth) 정보를 수집하여, 상공 목표물의 GPS 좌표를 추정할 수 있도록 한다. 예컨대, 차원 변환부는 상공 목표물의 깊이 정보(zc)가 주어지면 카메라 좌표계로 나타낸 상공 목표물의 3 차원 위치 정보 Pc를 수학식 5를 이용하여 산출하고, 수학식 6을 이용하여 무인항공기 몸체 좌표계의 벡터 PB를 산출한다. 수학식 5"}
{"patent_id": "10-2023-0025272", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "(Pc: 카메라 좌표계로 변환된 3차원 좌표, K: 카메라의 내부 파라미터(intrinsic matrix), zc: 목표물의 깊이 정보, I: 단위행렬, Pu: 픽셀 좌표계의 2차원 좌표를 동차 좌표계(homogeneous coordinate)로 나타낸 3차원 벡 터) 수학식 6"}
{"patent_id": "10-2023-0025272", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "(PB: 무인항공기 몸체 좌표계의 벡터, RBC: 카메라 좌표계로부터 무인항공기 몸체 좌표계로의 3차원 회전 변환 행렬, K: 카메라의 내부 파라미터(intrinsic matrix), zc: 목표물의 깊이 정보, I: 단위행렬, Pu: 픽셀 좌표계 의 2차원 좌표를 동차 좌표계(homogeneous coordinate)로 나타낸 3차원 벡터) 실시예에서는 차원 변환부가 목표물의 2차원 기준 픽셀 좌표를 무인항공기의 3차원 몸체 좌표계로 변환하 면, 좌표계 변환부는 무인항공기의 3차원 몸체 좌표계로 변환된 목표물 좌표를 기반으로 무인항공기와 목 표물 간의 상대적 위치 차를 계산하고, 3차원으로 변환된 목표물의 좌표를 ENU(East-North-Up)좌표계로 변환한 다. 도 4는 실시예에 따른 무인항공기와 상공 목표물과의 위치 관계를 나타낸 도면이고, 도 5는 실시예에 따른 FRD(Front - Right - Down)의 XBYB평면을 나타낸 도면이다. 도 4 및 도 5를 참조하면, 실시예에서 좌표계 변환부는 목표물의 기준 픽셀 좌표를 무인항공기 몸체 좌표계로 변환한 3차원 좌표를 Pt=(xt, yt, zt)T라고 가정 하여, 무인항공기 몸체 좌표계의 XBYB평면상에서 목표물과 무인항공기가 이루는 각 Ψ를 수학식 7을 통해 계산한 다. 수학식 7 Ψ=tan-1(yt / xt) 이때, 좌표계 변환부는 지상 목표물이 무인항공기 고도 기준이 되는 지면의 해수면 고도와 동일한 고도의 지면 상에 놓여있다고 가정한다. 실시예에서 지상 목표물의 기준 픽셀은 사용자가 특별히 선택하지 않으면, 자동 탐지된 바운딩 박스의 중심점으 로 설정될 수 있다. 이에 따라, 좌표계 변환부는 수학식 8을 통해 무인항공기에 탑재된 고도계 정보를 이 용하여 무인항공기 몸체 좌표계의 XBYB평면상에서 지상 목표물까지의 거리 dt를 산출한다. 수학식 8"}
{"patent_id": "10-2023-0025272", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "(h: 무인항공기의 고도, dt: 무인항공기 몸체 좌표계 원점을 지면에 내린 수선의 발로부터 목표물까지의 거리) 한편, 상공 목표물의 기준 픽셀은 사용자가 특별히 선택하지 않으면, 바운딩 박스의 중심점이 상공 목표물의 기 준 픽셀로 설정된다. 따라서, 좌표계 변환부는 수학식 9를 통해, 무인항공기 몸체 좌표계의 XBYB평면상에서 상공 목표물까지의 거리 dt를 계산한다. 수학식 9"}
{"patent_id": "10-2023-0025272", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "(xt: x좌표, yt: y좌표) 또한, 좌표계 변환부는 무인항공기의 고도계 정보(h)가 주어지면, 상공 목표물의 고도(ht)를 수학식 10을 통해 산출한다. 수학식 10 ht=h-zt (h: 무인항공기의 고도, zt: 무인항공기 몸체 좌표로 변환한 3차원 좌표의 z 좌표) 이후, 좌표계 변환부는 지상 목표물과 상공 목표물 모두, 계산된 무인항공기 몸체 좌표계의 XBYB평면상에서 목표물과 무인항공기가 이루는 각 Ψ 및 무인항공기 몸체 좌표계의 XBYB평면상에서 상공 목표물까지의 거리 dt를 이용하여 수학식 11 및 수학식 12를 통해, 무인항공기의 몸체 좌표계(FRD)를 관성 좌표계(ENU)로 변환한다. 실시예에서 좌표계 변환부는 수학식 11을 이용하여, ENU 좌표계에서의 목표물 x좌표(xENU)를 산출한다. 수학식 11"}
{"patent_id": "10-2023-0025272", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 7, "content": "(dt: 무인항공기 몸체 좌표계의 XBYB평면상에서 목표물까지의 거리, Ψ: 항공기 몸체 좌표계의 XBYB평면상에서 목 표물과 무인항공기가 이루는 각, α: 나침반의 북쪽을 기준으로 시계 방향으로 무인항공기의 헤딩 각도 (0≤α <360))좌표계 변환부는 수학식 12를 이용하여, ENU 좌표계에서의 목표물 y 좌표(yENU)를 산출한다. 수학식 12"}
{"patent_id": "10-2023-0025272", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 8, "content": "(dt: 무인항공기 몸체 좌표계의 XBYB평면상에서 상공 목표물까지의 거리, Ψ: 항공기 몸체 좌표계의 XBYB평면상에 서 목표물과 무인항공기가 이루는 각, α: 나침반의 북쪽을 기준으로 시계 방향으로 무인항공기의 헤딩 각도 (0 ≤α <360)) 실시예에서는 GPS 좌표 획득부는 ENU 좌표계로 나타낸 목표물 좌표를 GPS 좌표로 변환한다. GPS 좌표는 위 도, 경고, 고도를 포함하는 좌표이다. 예컨대, GPS 좌표 획득부는 먼저, ENU 좌표계로 나타낸 목표물의 좌 표를 ECEF(Earth-Centered Earth-Fixed) 좌표계로 변환 후, ECEF 좌표계에서 LLA 좌표계(GPS 좌표)로 변환하여 목표물 GPS 좌표를 획득할 수 있다. 실시예에서, GPS 좌표 획득부는 무인항공기의 현재 GPS 좌표를 이용해서 ENU 좌표계에서의 목표물 좌표를 ECEF 좌표계로 변환한 후, 다시 LLA(Latitude-Longitude-Altitude)좌표계로 변환하여, 무인항공기의 목표물 GPS 좌표를 최종 획득한다. 구체적으로, GPS 좌표 획득부는 수학식 13 내지 수학식 18을 이용하여 좌표계 변환부에서 산출된 ENU(East-North-Up) 좌표계의 목표물 좌표를 ECEF 좌표계로 변환한다. 실시예에서 GPS 좌표 획득부는 ENU 좌표계에서 ECEF 좌표계로 변환을 위해 먼저 수학식 13을 이용하여 t를 산출한다. 수학식 13"}
{"patent_id": "10-2023-0025272", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 9, "content": "(zENU: ENU 좌표계로 나타낸 목표물의 z좌표, yENU: ENU 좌표계로 나타낸 목표물의 y좌표, Φ: 무인항공기의 위도) 이렇게 산출된 t 는 탐지부, 설정부, 산출부 및 획득부를 포함하는 각 구성에서의 시간 동 기화에 사용될 수 있다. 이후, GPS 좌표 획득부는 수학식 14를 이용하여 ECEF 좌표계에서 무인항공기와 목표물 간 x축의 상대적 위 치차이인 dx를 산출한다. 수학식 14"}
{"patent_id": "10-2023-0025272", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 10, "content": "(λ: 무인항공기의 경도) 이후, GPS 좌표 획득부는 수학식 15를 이용하여 ECEF 좌표계에서 무인항공기와 목표물 간 y축의 상대적 위 치차이인 dy를 산출한다. 수학식 15"}
{"patent_id": "10-2023-0025272", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 11, "content": "(λ: 무인항공기의 경도) 이후, GPS 좌표 획득부는 수학식 16을 이용하여 ECEF 좌표계로 나타낸 무인항공기의 x축 위치인 x0를 산출 한다. 수학식 16"}
{"patent_id": "10-2023-0025272", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 12, "content": "(Φ: 무인항공기의 위도, N(Φ): 위도(Φ )에 따른 지구 타원체의 곡률 반경, λ: 무인항공기의 경도) 이후, GPS 좌표 획득부는 수학식 17을 이용하여 ECEF 좌표계로 나타낸 무인항공기의 y 축 위치인 y0를 산 출한다. 수학식 17"}
{"patent_id": "10-2023-0025272", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 13, "content": "(Φ: 무인항공기의 위도, N(Φ): 위도(Φ )에 따른 지구 타원체의 곡률 반경, λ: 무인항공기의 경도) 실시예에서 위도(Φ)에 따른 지구 타원체의 곡률 반경 N(Φ)은 수학식 18을 통해 위치 좌표 획득부에서 산 출될 수 있다. 수학식 18"}
{"patent_id": "10-2023-0025272", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 14, "content": "(a: 지구 타원체(WGS84)의 장축, b: 지구 타원체(WGS84)의 단축, Φ: 무인항공기의 위도) 이후, GPS 좌표 획득부는 ECEF 좌표계로 나타낸 무인항공기 위치 정보와, 무인항공기와 목표물 간 상대적 위치차를 통해 수학식 19를 이용하여, ECEF 좌표계의 x좌표인 XECEF를 산출한다. 수학식 19"}
{"patent_id": "10-2023-0025272", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 15, "content": "(x0: ECEF 좌표계로 나타낸 무인항공기의 위치, dx: ECEF 좌표계에서 무인항공기와 목표물 간 상대적 위치차) GPS 좌표 획득부는 ECEF 좌표계로 나타낸 무인항공기 위치 정보와, 무인항공기와 목표물 간 상대적 위치차 를 통해 수학식 20을 이용하여, ECEF 좌표계의 y좌표인 yECEF를 산출한다. 수학식 20"}
{"patent_id": "10-2023-0025272", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 16, "content": "(y0: ECEF 좌표계로 나타낸 무인항공기의 위치, dy: ECEF 좌표계에서 무인항공기와 목표물 간 상대적 위치차) 즉, 실시예에서 GPS 좌표 획득부는 수학식 19및 수학식 20을 이용하여 목표물의 위치를 ECEF 좌표계로 변 환할 수 있다. 이후, GPS 좌표 획득부는 ECEF 좌표계로 나타난 목표물의 좌표를 GPS 좌표로 변환하여(ECEF to LLA) 무인 항공기의 목표물 GPS 좌표를 최종적으로 획득한다. 실시예에서는 GPS 좌표 획득부는 수학식 19와 수학식 20을 이용하여 획득한 ECEF 좌표계로 변환된 목표물 의 좌표를 수학식 21 내지 수학식 26을 이용하여 GPS 좌표로 변환하고, 변환된 좌표를 목표물 GPS 좌표로 추정 한다. 실시예에서 GPS 좌표 획득부는 수학식 21을 이용하여 ECEF 좌표계에서 목표물 위치 벡터의 크기 r을 산출 한다. 수학식 21"}
{"patent_id": "10-2023-0025272", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 17, "content": "이후, GPS 좌표 획득부는 수학식 22를 이용하여 선형 이심률 E를 산출한다. 수학식 22"}
{"patent_id": "10-2023-0025272", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 18, "content": "(a: 지구 타원체(WGS84)의 장축, b: 지구 타원체(WGS84)의 단축) 이후, GPS 좌표 획득부는 수학식 23을 이용하여 u를 산출한다. 수학식 23"}
{"patent_id": "10-2023-0025272", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 19, "content": "이후, GPS 좌표 획득부는 수학식 24를 이용하여 β0를 산출한다. (u: 공초점 타원체의 단축, β: 지구 중심에서 기준 타원체로의 각도, β0: 지구 중심에서 공초점 타원체로의 각도) 수학식 24"}
{"patent_id": "10-2023-0025272", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 20, "content": "이후, GPS 좌표 획득부는 수학식 25를 이용하여 Δβ를 산출한다. 수학식 25"}
{"patent_id": "10-2023-0025272", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 21, "content": "이후, GPS 좌표 획득부는 수학식 26를 이용하여 β를 산출한다. 수학식 26"}
{"patent_id": "10-2023-0025272", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 22, "content": "이하에서는 무인항공기의 목표물 GPS 좌표 추정 방법에 대해서 차례로 설명한다. 실시예에 따른 무인항공기의 목표물 GPS 좌표 추정 방법의 작용(기능)은 무인항공기의 목표물 GPS 좌표 추정 시스템의 기능과 본질적으로 같 은 것이므로 도 1 내지 도 5와 중복되는 설명은 생략하도록 한다. 도 6은 실시예에 따른 무인항공기의 목표물 GPS 좌표 추정 방법의 데이터 처리 흐름을 나타낸 도면이다. 도 6을 참조하면, S100 단계에서는 탐지부에서 학습된(Pre-training) 인공지능 딥러닝 모델을 통해, 무인항공기 에 설정된 임무에 대응하는 목표물을 탐지(detect)하고, 탐지된 목표물을 포함하는 바운딩 박스(Bounding box) 를 목표물의 크기에 따라 생성한다. S200 단계에서는 설정부에서 카메라 이미지 평면(image plane)상에 픽셀로나타낸 목표점인 기준 픽셀을 설정한다. S300 단계에서는 산출부에서 2차원 픽셀 좌표계에서 목표물의 기준 픽 셀 좌표를 산출한다. S400 단계에서는 변환부에서 목표물의 고도정보, 목표물의 깊이 정보 중 적어도 하나를 이 용하여, 목표물의 기준 픽셀 좌표를, 3차원 좌표로 변환하고, 변환된 3차원 좌표의 좌표계를 변환한다. 이후, S500 단계에서는 변환부에서 목표물의 GPS 좌표를 획득한다. 도 7은 실시예에 따른 S400 단계의 데이터 처리과정을 나타낸 도면이다. 도 7을 참조하면, S410 단계에서는 차원 변환부에서 기준 픽셀 좌표의 좌표계를 변환한다. 보다 구체적으로, S410 단계에서는 목표물의 기준 픽셀 좌표를, 2차원 픽셀 좌표계에서 3차원 카메라 좌표계로 변환 후 3차원 Body-fixed 좌표계(FRD 좌표계)로 변환한다. S410 단계에서 2차원 픽셀 좌표계를 3차원 카메라 좌표계 변환 시, 핀홀 카메라 모델을 사용하고, 이때 지상 목표물을 위한 무인항공기의 고도 정보와 상공 목표물을 위한 목표물 의 깊이 정보가 사용될 수 있다. 또한, 3차원 카메라 좌표계를 3차원 body-fixed 좌표계 변환 시, 카메라와 무인항공기 CG 사이의 외부 파라미터 가 사용될 수 있다. S430 단계에서는 좌표계 변환부에서 무인항공기 몸체 좌표계로 변환된 목표물 좌표를 기반으로 무인항공기 와 목표물 간의 상대적 위치 차를 계산하고, 목표물의 좌표를 ENU(East-North-Up)좌표계로 변환한다. 실시예에 서 S430 단계에서는 목표물의 좌표를 Body-fixed 좌표계(FRD 좌표계)를 ENU 좌표계인 관성 좌표계로 변환한다. S450 단계에서는 GPS 좌표 획득부에서 ENU 좌표계로 나타낸 목표물 좌표를 GPS 좌표로 변환한다. 구체적으 로, S450 단계에서는 ENU 좌표계를 ECEF 좌표계로 변환하고, LLA 좌표계(목표물 GPS 좌표)로 변환한다. 실시예 에서는 ENU 좌표계를 ECEF 좌표계로 변환 시, 무인항공기의 GPS 좌표값을 사용한다. 이상에서와 같은 무인항공기의 목표물 GPS 좌표 추정 장치 및 방법은 목표물의 개수나 상공, 지상 등 목표물의 탐지 위치에 관계없이 카메라 영상을 통해 자동으로 목표물의 전역 위치를 지도해 표시함으로써, 실종자 구출 또는 안티 드론 차원의 레이더로 잡히지 않는 표적 전역 위치 계산과 같은 다양한 임무를 보다 정확하게 수행할 수 있도록 한다. 실시예에 따른 무인항공기의 목표물 GPS 좌표 추정 장치 및 방법은 무인항공기를 활용한 실종자, 유류품 수색, 위험 지역에 있는 사람들의 위치 정보 추정, 무인항공기의 착륙 및 배달을 위한 목적지의 GPS 좌표 추정, 시설 물 점검 시 점검 대상의 위치 정보 획득 및 상공에 적군 무인기의 GPS 좌표 추정 과정에서 이용될 수 있다."}
{"patent_id": "10-2023-0025272", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 23, "content": "개시된 내용은 예시에 불과하며, 특허청구범위에서 청구하는 청구의 요지를 벗어나지 않고 당해 기술분야에서 통상의 지식을 가진 자에 의하여 다양하게 변경 실시될 수 있으므로, 개시된 내용의 보호범위는 상술한 특정의 실시예에 한정되지 않는다.도면 도면1 도면2 도면3 도면4 도면5 도면6 도면7"}
{"patent_id": "10-2023-0025272", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 실시예에 따른 무인항공기의 카메라 영상 정보를 기반으로 목표물의 GPS 좌표를 추정하는 장치의 데이터 처리 구성을 나타낸 도면 도 2는 실시예에 따른 변환부의 데이터 처리 구성을 나타낸 도면 도 3은 실시예에 따른 무인항공기와 지상 목표물의 위치 관계를 나타낸 도면 도 4는 실시예에 따른 무인항공기와 상공 목표물과의 위치 관계를 나타낸 도면 도 5는 실시예에 따른 FRD(Front - Right - Down)의 XBYB평면을 나타낸 도면 도 6은 실시예에 따른 무인항공기의 카메라 영상 정보를 기반으로 목표물의 GPS 좌표를 추정하는 방법의 데이터 처리 흐름을 나타낸 도면 도 7은 실시예에 따른 S400 단계의 데이터 처리과정을 나타낸 도면"}
