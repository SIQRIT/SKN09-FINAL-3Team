{"patent_id": "10-2022-0099345", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0068279", "출원번호": "10-2022-0099345", "발명의 명칭": "다중 이미지의 분할 배열 방식 기반 데이터 구축 및 학습 시스템, 방법", "출원인": "한국전자통신연구원", "발명자": "김진우"}}
{"patent_id": "10-2022-0099345", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "차량에 배치된 복수 개의 카메라가 촬영한 영상을 수신하는 입력부; 상기 영상을 단일 영상으로 통합하고, 도로 상황 및 객체에 대한 정보를 추정하는 프로그램이 저장된 메모리;및상기 프로그램을 실행시키는 프로세서를 포함하고, 상기 프로세서는 상기 영상에 중복되어 포함되는 도로 상황 및 객체를 하나의 상황으로 통합 인식하는 것인 다중 이미지의 분할 배열 방식 기반 데이터 구축 및 학습 시스템."}
{"patent_id": "10-2022-0099345", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 입력부는 상기 복수 개의 카메라로부터 상이한 화각을 가지는 상기 영상을 수신하는 것인 다중 이미지의 분할 배열 방식 기반 데이터 구축 및 학습 시스템."}
{"patent_id": "10-2022-0099345", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서, 상기 프로세서는 상기 상이한 화각을 가지는 영상을 재배열하고 통합하여, 섹션 별로 상기 영상이 배치되는 상기 단일 영상을 구성하는 것인 다중 이미지의 분할 배열 방식 기반 데이터 구축 및 학습 시스템."}
{"patent_id": "10-2022-0099345", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서, 상기 프로세서는 상기 단일 영상 내의 객체에 대한 주석 처리를 수행하여, 각 섹션 별로 객체의 일부가 보여지고, ROI가 온전히 보여지고, ROI가 상대적으로 작아지는 객체 정보를 통합 관리하여 학습 레벨로 전달할 데이터를 구축하는 것 인 다중 이미지의 분할 배열 방식 기반 데이터 구축 및 학습 시스템."}
{"patent_id": "10-2022-0099345", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서, 상기 프로세서는 상기 단일 영상과, 거리 센서 및 위치 센서 기반의 보정된 정보를 이용하여, 영상 내 객체의구조적 데이터를 구축하고, 상기 구조적 데이터에는 객체, 모델, 클래스, 포지션, 헤딩, 사이즈, 타겟 정보가포함되는 것인 다중 이미지의 분할 배열 방식 기반 데이터 구축 및 학습 시스템. 공개특허 10-2023-0068279-3-청구항 6 제5항에 있어서, 상기 프로세서는 이미지 메인 섹터 및 이미지 서브 섹터를 포함하는 상기 단일 영상으로 통합하고, 상기 영상내 객체의 구조적 데이터를 이용하여 학습한 결과를 이용하여 실시간 실행 시 통합된 영상 입력만으로 최종 추정 정보를 출력하는 것인 다중 이미지의 분할 배열 방식 기반 데이터 구축 및 학습 시스템."}
{"patent_id": "10-2022-0099345", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "다중 이미지의 분할 배열 방식 기반 데이터 구축 및 학습 시스템에 의해서 수행되는 다중 이미지의 분할 배열방식 기반 데이터 구축 및 학습 방법에 있어서, (a) 복수 개의 카메라가 촬영한 영상 데이터를 획득하는 단계; (b) 상기 영상 데이터를 타일 배열의 단일 프레임으로 통합하는 단계; (c) 상기 단일 프레임 내에 존재하는 객체에 라벨링된 객체 정보를 영상 도메인으로 변환하는 단계; 및(d) 상기 영상 도메인으로 변환한 영상과 영상 도메인 라벨링 정보를 통합하여 학습 데이터로 생산하는 단계를 포함하는 다중 이미지의 분할 배열 방식 기반 데이터 구축 및 학습 방법."}
{"patent_id": "10-2022-0099345", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1항에 있어서, 상기 (a) 단계는 상이한 화각과 해상도를 가지도록 촬영 정보가 설정된 상기 복수 개의 카메라로부터 상기 영상데이터를 획득하는 것인 다중 이미지의 분할 배열 방식 기반 데이터 구축 및 학습 방법."}
{"patent_id": "10-2022-0099345", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제7항에 있어서, 상기 (b) 단계는 상기 단일 프레임 내의 섹션 별로 일부 보여지는 객체, 온전한 형태로 보여지는 ROI 정보, 원거리에 위치하여 상대적으로 ROI가 작은 객체 정보를 통합 관리하여 학습 레벨로 전달 가능한 데이터를 구축하는 것인 다중 이미지의 분할 배열 방식 기반 데이터 구축 및 학습 방법."}
{"patent_id": "10-2022-0099345", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제7항에 있어서, 상기 (c) 단계는 버드아이 뷰 상 객체 좌표 정보, 객체 크기에 해당하는 형태 모델링 정보, 이동 방향 정보를포함하는 상기 객체 정보를 영상 도메인으로 변환하는 것인 다중 이미지의 분할 배열 방식 기반 데이터 구축 및 학습 방법."}
{"patent_id": "10-2022-0099345", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "공개특허 10-2023-0068279-4-제7항에 있어서, 상기 (d) 단계는 객체, 모델, 클래스, 포지션, 헤딩, 사이즈, 타겟 정보를 포함하는 영상 내 객체의 구조적 데이터를 이용하여 학습을 수행하는 것인 다중 이미지의 분할 배열 방식 기반 데이터 구축 및 학습 방법."}
{"patent_id": "10-2022-0099345", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 다중 이미지의 분할 배열 방식 기반 데이터 구축 및 학습 시스템, 방법에 관한 것이다. 본 발명에 따른 다중 이미지의 분할 배열 방식 기반 데이터 구축 및 학습 시스템은 차량에 배치된 복수 개의 카 메라가 촬영한 영상을 수신하는 입력부와, 영상을 단일 영상으로 통합하고, 도로 상황 및 객체에 대한 정보를 추 정하는 프로그램이 저장된 메모리 및 프로그램을 실행시키는 프로세서를 포함하고, 프로세서는 영상에 중복되어 포함되는 도로 상황 및 객체를 하나의 상황으로 통합 인식한다."}
{"patent_id": "10-2022-0099345", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 다중 이미지의 분할 배열 방식 기반 데이터 구축 및 학습 시스템, 방법에 관한 것이다."}
{"patent_id": "10-2022-0099345", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "글로벌 자동차 회사들은 카메라, 라이다, 레이더, 초음파 센서 등을 융합하여 다양한 자율주행 인식 기술을 제 안하고 있으며, 특정 기업은 카메라 인식만의 전방위 인식 기반 자율주행 기술을 제안하여 선도 기업의 포지션 을 공고히 하고 있다. 복수 개의 영상을 독립적으로 병렬 또는 순차적으로 처리하는 방식은 시간 지연, 동기화, 프로세싱 로드 측면에 서의 문제점이 있으며, 복수 개의 영상을 이용하여 개별적으로 객체를 인식하고 통합하는 방식은 동일한 객체에 대한 식별과 통합이 어려운 문제점이 있다."}
{"patent_id": "10-2022-0099345", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 전술한 문제점을 해결하기 위해 제안된 것으로, 다중 카메라 및 센서 융합 방식의 문제점(동기화, 통 합 시 발생 가능한 오류)을 해소하고, 다중 모노 카메라 영상의 입력만으로 종래의 스테레오 방식/다중 센서 융 합 방식보다 효율적이고 처리 속도가 빠르며 정확도가 높은 자율주행용 인식 기술을 제공하는데 그 목적이 있다. 본 발명은 다중 카메라로부터 획득한 이미지의 재배열 및 확장 가능한 데이터 구성을 통한 자율주행용 인식 기 술을 제안하며, 구체적으로는 자율주행 시스템에서의 인식 범위 및 목적에 따라 장착된 복수 개의 카메라로부터 입력되는 영상을 동시에 인식하고, 전방위 또는 부분, 근거리, 원거리를 포함한 주행에 필요한 모든 범위 내 이 동 객체와 주행 상황에 대해 보다 정확하고 효율적으로 인식 가능한 인공지능 데이터 구축 및 학습 기술을 제안 한다."}
{"patent_id": "10-2022-0099345", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명에 따른 다중 이미지의 분할 배열 방식 기반 데이터 구축 및 학습 시스템은 차량에 배치된 복수 개의 카 메라가 촬영한 영상을 수신하는 입력부와, 영상을 단일 영상으로 통합하고, 도로 상황 및 객체에 대한 정보를 추정하는 프로그램이 저장된 메모리 및 프로그램을 실행시키는 프로세서를 포함하고, 프로세서는 영상에 중복되 어 포함되는 도로 상황 및 객체를 하나의 상황으로 통합 인식한다. 상기 입력부는 상기 복수 개의 카메라로부터 상이한 화각을 가지는 상기 영상을 수신한다. 상기 프로세서는 상기 상이한 화각을 가지는 영상을 재배열하고 통합하여, 섹션 별로 상기 영상이 배치되는 상 기 단일 영상을 구성한다. 상기 프로세서는 상기 단일 영상 내의 객체에 대한 주석 처리를 수행하여, 각 섹션 별로 객체의 일부가 보여지 고, ROI가 온전히 보여지고, ROI가 상대적으로 작아지는 객체 정보를 통합 관리하여 학습 레벨로 전달할 데이터 를 구축한다. 상기 프로세서는 상기 단일 영상과, 거리 센서 및 위치 센서 기반의 보정된 정보를 이용하여, 영상 내 객체의 구조적 데이터를 구축하고, 상기 구조적 데이터에는 객체, 모델, 클래스, 포지션, 헤딩, 사이즈, 타겟 정보가 포함된다. 상기 프로세서는 이미지 메인 섹터 및 이미지 서브 섹터를 포함하는 상기 단일 영상으로 통합하고, 상기 영상 내 객체의 구조적 데이터를 이용하여 학습한 결과를 이용하여 실시간 실행 시 통합된 영상 입력만으로 최종 추 정 정보를 출력한다. 본 발명에 따른 다중 이미지의 분할 배열 방식 기반 데이터 구축 및 학습 방법은 (a) 복수 개의 카메라가 촬영 한 영상 데이터를 획득하는 단계와, (b) 영상 데이터를 타일 배열의 단일 프레임으로 통합하는 단계와, (c) 단 일 프레임 내에 존재하는 객체에 라벨링된 객체 정보를 영상 도메인으로 변환하는 단계 및 (d) 영상 도메인으로 변환한 영상과 영상 도메인 라벨링 정보를 통합하여 학습 데이터로 생산하는 단계를 포함한다. 상기 (a) 단계는 상이한 화각과 해상도를 가지도록 촬영 정보가 설정된 상기 복수 개의 카메라로부터 상기 영상 데이터를 획득한다. 상기 (b) 단계는 상기 단일 프레임 내의 섹션 별로 일부 보여지는 객체, 온전한 형태로 보여지는 ROI 정보, 원 거리에 위치하여 상대적으로 ROI가 작은 객체 정보를 통합 관리하여 학습 레벨로 전달 가능한 데이터를 구축한 다. 상기 (c) 단계는 버드아이 뷰 상 객체 좌표 정보, 객체 크기에 해당하는 형태 모델링 정보, 이동 방향 정보를 포함하는 상기 객체 정보를 영상 도메인으로 변환한다. 상기 (d) 단계는 객체, 모델, 클래스, 포지션, 헤딩, 사이즈, 타겟 정보를 포함하는 영상 내 객체의 구조적 데 이터를 이용하여 학습을 수행한다."}
{"patent_id": "10-2022-0099345", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명에 따르면, 복수 개 카메라의 다양한 화각 및 해상도를 효율적으로 통합하는 인공지능 기반 인식 기술에 서, 중복되는 범위의 다중 영상에 포함되는 객체를 하나의 객체로 융합하여 인식하는 것이 가능하고, 근거리에 서 원거리의 객체를 보다 효율적으로 인식하는 것이 가능하다. 본 발명에 따르면, 종래 기술에 따른 레이다, 라이다 위주의 자율주행 인식 방식을 벗어나, 고속 처리가 가능한 복수 개 카메라를 동시에 효율적으로 통합 및 융합 인식함으로써, 자율주행의 범위를 확장하고 신뢰도를 상승시 키는 효과가 있다."}
{"patent_id": "10-2022-0099345", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 2, "content": "본 발명의 효과는 이상에서 언급한 것들에 한정되지 않으며, 언급되지 아니한 다른 효과들은 아래의 기재로부터 당업자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2022-0099345", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명의 전술한 목적 및 그 이외의 목적과 이점 및 특징, 그리고 그것들을 달성하는 방법은 첨부되는 도면과 함께 상세하게 후술되어 있는 실시예들을 참조하면 명확해질 것이다."}
{"patent_id": "10-2022-0099345", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "그러나 본 발명은 이하에서 개시되는 실시예들에 한정되는 것이 아니라 서로 다른 다양한 형태로 구현될 수 있 으며, 단지 이하의 실시예들은 본 발명이 속하는 기술분야에서 통상의 지식을 가진 자에게 발명의 목적, 구성 및 효과를 용이하게 알려주기 위해 제공되는 것일 뿐으로서, 본 발명의 권리범위는 청구항의 기재에 의해 정의 된다. 한편, 본 명세서에서 사용된 용어는 실시예들을 설명하기 위한 것이며 본 발명을 제한하고자 하는 것은 아니다. 본 명세서에서, 단수형은 문구에서 특별히 언급하지 않는 한 복수형도 포함한다. 명세서에서 사용되는 \"포함한 다(comprises)\" 및/또는 \"포함하는(comprising)\"은 언급된 구성소자, 단계, 동작 및/또는 소자가 하나 이상의 다른 구성소자, 단계, 동작 및/또는 소자의 존재 또는 추가됨을 배제하지 않는다. 최근 자율주행시스템이 레벨 4이상으로 기술이 발전함에 따라, 대표적으로 테슬라 社는 카메라 인식만으로 360 도 전방위 인식을 수행하고, 차선 유지, 차선 변경 등 자율주행에 필요한 데이터 구조를 확장하며, 지속적으로 데이터를 학습하여 자율주행 성능을 개선하고 있다. 또한, 8개의 카메라를 통한 인식의 경우 병렬 또는 순차적 인식 방식을 통해 각각의 영상 데이터를 확보하고, 딥러닝 기술을 활용한 이동 객체의 위치, 종류, 차선, 인프 라 인식을 통해 보다 정교한 자율주행 기술을 확보하고자 막대한 투자를 하고 있다. 전술한 대표적인 선도 기업 의 기술 개발 트렌드에 따라, 여러 대의 카메라 만을 활용한 인식 기술 개발이 주도적으로 이루어지고 있다. 복수 개의 영상을 독립적으로 병렬 처리하거나, 순차적으로 처리하는 방식은 처리 과정에서의 시간 지연 문제, 동기화 문제, 프로세싱 부하의 문제가 있다. 즉, 복수 개의 영상을 이용하여 개별적으로 객체를 인식하고, 인식 결과를 통합하는 방식은 동일한 객체에 대한 식별과 통합 과정에서의 문제점이 수반된다. 이하에서는, 본 발명의 실시예에 따른 다중 이미지의 분할 배열 방식 기반 데이터 구축 및 학습 시스템, 방법을 설명하기에 앞서, i) 화각과 해상도가 큰 단일 영상 기반 인식 기술의 장/단점과, ii) 원거리/중거리/근거리 뷰 를 확보할 수 있는 복수의(3개의) 카메라 영상 기반 인식 기술의 장/단점에 대해 설명한다. 자율주행 시 전방 주행 환경을 예를 들어 설명하며, 전방 객체(장애물, 목표물)는 근거리에서는 넓은 화각으로, 원거리일수록 좁은 화각으로 인식하는 것이 하드웨어 및 소프트웨어 측면에서 효율적인데, 특성 비교를 위해 동 일한 하드웨어에서 구동하였을 때를 가정하여 설명한다. i) 화각 (FOV: Field of View)과 해상도가 큰 영상 1장 기반 인식 기술과 관련하여, 장점으로는 1) 카메라 영상 1장으로 처리함으로써 효율적이고, 2) 단일 영상이므로 복수 개 영상 처리 과정에서 발생되는 동기화 및 통합 시의 문제가 없다. 단점으로는 1) 거리가 멀수록 객체에 해당하는 확보 가능한 픽셀 수가 작기 때문에, 원거리 영상 기반 거리/위치 추정 시 오차 범위가 크고, 2) 해상도가 크기 때문에 고성능 CPU/GPU가 필요하고, 3) 측면 /상하단의 왜곡이 커서 단일 영상 기반 거리/위치 추정 및 센서 융합 시 오차가 커지는 문제점이 있고, 4) 작은 객체를 검출하기 위해서 딥러닝 네트워크 레이어 수가 많아지고, 학습 시 입력 영상 크기가 크기 때문에 동일 하드웨어를 이용하는 경우여도 실시간 처리 속도가 상대적으로 느린 문제점이 있다. ii) 원거리/중거리/근거리를 뷰를 확보할 수 있는 카메라 영상 3개 기반 인식 기술과 관련하여, 장점으로는 1) 저해상도의 3개의 카메라로 근거리부터 원거리까지 넓은 범위로 객체 인식을 정확하게 할 수 있고, 2) 중거리, 원거리의 경우 화각이 작은 렌즈를 활용하여 왜곡이 적으므로 보다 정확한 추정이 가능하고, 3) 근거리의 경우 화각이 큰 렌즈를 활용하여 왜곡이 작은 부분의 객체 인식 결과만을 활용하므로 중거리 이상의 객체에 대한 오 차를 제외할 수 있으며, 4) 거리가 먼 객체라고 하더라도 작은 화각을 통해 객체에 해당하는 큰 픽셀 범위를 확 보하여 원거리 영상 기반 거리/위치 추정 시 오차 범위가 작다. 단점으로는 1) 카메라가 3개 필요하기 때문에 병렬 처리 및 동기화 문제가 존재하고, 2) 순차적으로 처리할 시 카메라 간의 딜레이 문제가 있고, 통합 시 같 은 객체에 대한 정보가 달라질 수 있다는 문제가 있다(모노 카메라 기반 거리 추정 시 오차 및 추적 아이디 문 제). 영상으로부터 객체의 3차원 위치 정보를 추정하기 위한 기술로는, 센서 융합 정보를 바탕으로 영상/거리 센서의 상호 위치 관계성을 이용한 프로젝션 (projection) 방식과, 라이다 기반 3차원 객체 추정 방식 및 스테레오 방 식의 거리 추정 방식이 제안되었으나, 본원 발명의 실시예에 따르면 아래와 같은 차이점이 있다. 본 발명의 실시예에 따르면, 목적과 특성에 따라 자율주행차량에 설치된 여러 대의 카메라 정보를 1장의 영상으 로 통합하고, 여러 상황에 대한 인식을 단 1번의 딥러닝 네트워크를 활용하여 수행함으로써, 도로 상황 및 객체에 대한 정보를 추정한다. 본 발명의 실시예에 따르면, 여러 개의 카메라로부터 획득된 입력 영상에 중복적으로 포함된 객체 및 도로 상황 을 하나의 상황으로 통합 인식하는 방법을 제안하고, 이를 기반으로 자율 주행에 필요한 객체의 정보를 통합하 기 위한 딥러닝 네트워크 구축 방법을 제안하며, 딥러닝 네트워크에 입력되어야 할 데이터 구조 및 그 가공 방 법을 제안한다. 본 발명의 실시예에 따르면, 다중 카메라의 타일 배열로 통합된 하나의 영상(분할 배열 영상)과 그 영상에 존재 하는 객체에 라벨링(labeling)된 이동 가능한 객체 정보를 영상 도메인으로 변환하며, 객체 정보에는 버드아이 뷰 상 객체 좌표 정보, 객체 크기에 상응하는 형태 모델링 정보, 이동방향 정보가 포함된다. 영상 도메인 라벨 링 정보와 영상 도메인으로 변환 표기된 영상을 통합하여 인공지능 학습 데이터로 재생산함으로써, 1장(1 프레 임)의 데이터로 구성한다. 구축된 데이터는 단일 영상 및 연속된 2개의 영상의 관계성을 고려하여, 주행 상황과 객체 정보 추정을 위한 다중 딥러닝 네트워크 (검출:detection → 비교:comparing → 통합:merge → 추 정:estimation)순으로 학습 과정을 거치게 된다. 본 발명의 실시예에 따르면, 저해상도 스펙의 복수 개(3개)의 카메라를 이용하여 근거리부터 원거리까지 넓은 범위로 정확하게 객체 인식을 수행한다. 카메라 영상 1장으로 처리 가능한 방법을 제안하여 효율성이 높고, 전 술한 종래 기술의 동기화 및 통합 과정에서 문제가 없다. 작은 객체를 검출하기 위해서 딥러닝 네트워크 레이어 수가 작아도 무방하며, 학습 시 입력 영상 크기가 작으므로 실시간 처리 속도가 동일 하드웨어 기준에서 상대적 으로 빠르다는 장점이 있다. 단일(1장)의 영상에 원하는 영상(데이터)을 추가 및 재배열 하는 방식을 제안하여, 섹션(1장 내의 영상을 구분하기 위해 부여된 아이디)을 확장 하고 구조를 변경하는 것이 가능하다(예: 원거리~ 근거리 정보: 전방, 측방, 후방, 신호등, 작은 객체 등). 단일(1장)의 데이터로 여러 종류의 데이터를 한번에 딥러닝 처리 가능한 장점이 있다. 학습 데이터 구조화의 경우 전방을 촬영하는 복수 개의 카메라(본 발명의 실 시예에서는 3개임을 가정하여 설명하나, 그 개수는 특성에 따라 변경 가능함)로 원거리부터 근거리까지의 서로 다른 장면(Scene)에서 인식되는 동일한 객체를 판별하고, 동일 객체 추적 아이디를 부여하는 것이 가능하다. 모 노 카메라와 센서 융합 데이터를 기반으로 학습을 수행하고, 실제 실행(Inference) 가능한 구조로는 카메라만 활용(레이다, 라이다 등은 학습 시 데이터 구축에만 활용)하는 특징이 있으며, 영상 데이터 입력만으로 거리/위 치/크기/추적/방향 정보의 추정이 가능한 장점이 있다. 도 1은 본 발명의 실시예에 따른 다중 이미지의 분할 배열 방식 기반 데이터 구축 및 학습 시스템을 도시한다. 본 발명의 실시예에 따른 다중 이미지의 분할 배열 방식 기반 데이터 구축 및 학습 시스템은 차량에 배치된 복 수 개의 카메라가 촬영한 영상을 수신하는 입력부와, 영상을 단일 영상으로 통합하고, 도로 상황 및 객체에 대한 정보를 추정하는 프로그램이 저장된 메모리 및 프로그램을 실행시키는 프로세서를 포함하고, 프로 세서는 영상에 중복되어 포함되는 도로 상황 및 객체를 하나의 상황으로 통합 인식한다. 입력부는 복수 개의 카메라로부터 상이한 화각을 가지는 영상을 수신한다. 또는, 입력부는 복수 개의 카메라로부터 상이한 화각과 해상도를 가지는 영상을 수신한다. 프로세서는 상기 영상을 재배열하고 통합하여 단일 영상을 구성하고, 단일 영상에는 섹션 별로 상기 영상이 배치된다. 프로세서는 단일 영상 내의 객체에 대한 주석 처리를 수행하여, 각 섹션 별로 객체의 일부가 보여지고, ROI 가 온전히 보여지고, ROI가 상대적으로 작아지는 객체 정보를 통합 관리하여 학습 레벨로 전달할 데이터를 구축 한다. 프로세서는 단일 영상과, 거리 센서 및 위치 센서 기반의 보정된 정보를 이용하여, 영상 내 객체의 구조적 데이터를 구축하고, 구조적 데이터에는 객체, 모델, 클래스, 포지션, 헤딩, 사이즈, 타겟 정보가 포함된다. 프로세서는 이미지 메인 섹터 및 이미지 서브 섹터를 포함하는 단일 영상으로 통합하고, 영상 내 객체의 구 조적 데이터를 이용하여 학습한 결과를 이용하여 실시간 실행 시 통합된 영상 입력만으로 최종 추정 정보를 출 력한다. 도 2는 본 발명의 실시예에 따른 다중 카메라 재배열 데이터 구조를 도시하며, 이하에서는 도 2를 참조하여 통 합 영상 구축 과정에 대해 설명한다. 본 발명의 실시예에 따른 다중 카메라의 타일 배열로 통합된 하나의 데이터는 도 2에 도시된 바와 같이, 여러 개의 카메라 영상을 목적과 특성에 맞게 재배열하고 통합한 1장의 형태의 데이터이며, 각 섹션(도 2의 101, 102, 103으로 도시함)의 정보를 가진 형태로 구성된다. 각 섹션(101, 102, 103)별로, 목적에 따라 다른 카메라 화각(FOV: Field of Vidw), 위치, 해상도, 왜곡 정보를 가진 여러 개의 영상이 위치되도록 통합 영상을 구성한다. 본 발명의 상세한 설명에서는, 자율주행 차량의 전방 범위를 기준으로 설명하며, 신호등, 후측면, 후면 등 다양 한 영상을 재배열하는 것이 가능한 플랫폼 형식의 딥러닝 학습 데이터 가공/구축에 대한 방법을 제안한다. 도 2를 참조하면, 자율주행 또는 주행보조 시스템에서 활용 가능한, 서로 다른 화각과 해상도를 가지는 3개의 영상으로 예를 들어 설명한다. 카메라는 가상의 기준점을 두고 세로 또는 가로로 배치될 수 있다. 카메라의 구 성 형태는 상대적으로 화각이 좁은 것이 상단에 위치하고, 순차적으로 화각이 넓어질수록 아래에 위치하도록 배 치하여 영상을 구성한다. 제1 섹션에 해당되는 영상은 좁은 화각의 영상으로 원거리 범위를 촬영한 영상이고, 제2 섹션에 해당 되는 영상은 3개의 영상 중 중심 역할을 하는 중/근거리 범위를 촬영한 영상이고, 제3 섹션에 해당되는 영 상은 넓은 화각의 영상으로 근거리 범위를 촬영한 영상이다. 3개의 영상을 1장으로 통합한 형태에서, 각 객체에 대한 주석 처리 (labeling 또는 Annotation)를 통해, 제1 섹 션에서 일부 보여지는 차량(노란색 승합차)과 제2 섹션에서 ROI(객체를 labeling 한 영역)가 큰 온전 한 형태로 보이는 차량 형태, 제3 섹션에서 동일한 객체지만 제2 섹션 대비 상대적으로 ROI가 작은 정보를 통합 관리하여, 학습 레벨로 전달할 수 있도록 데이터를 구축한다. 도 3은 본 발명의 실시예에 따른 다중, 다종 센서 통합 타일형 데이터 가공 과정을 도시하고, 이하에서는 도 3 을 참조하여 영상 및 이에 상응하는 객체의 동적/기하학적 정보 통합을 통해 데이터를 가공하고 구축하는 과정 을 설명한다. 도 2에서 설명한 통합 영상을 도 3에서는 통합 영상 데이터로 도시한다. 영상은 1:N 비율 학습 영상 (301-4)에 도시한 바와 같이, 다양한 형태의 통합된 영상이 사용될 수 있다. 본 발명의 실시예에 따르면, 영상 도메인에서 구축된 통합 영상 데이터, 이에 상응하는 거리 및 위치 센서 로 상호 보정(calibration)된 정보를 활용하여, 영상 내 객체의 구조적 데이터를 구축한다. 통합 영상 데이터에서 객체에 대한 ROI(301-1)를 지정하고, ROI 내의 센서 데이터 기반으로 검출한 객체 후보군(301-2)에 상응하는 위치 좌표(302-1)를 선택한다. 이 때, ROI 좌우 끝점 하단에 대한 좌표 정보(301- 3)를 저장하고, 위치 좌표(302-1)에서의 ROI 내 센싱 정보를 기반으로 사전에 정의된 적합한 모델(301-2)을 선 택하고, 이에 상응하는 객체의 진행 방향(302-3, Heading)을 정의한다. 도 4는 본 발명의 실시예에 따른 다중 재배열 통합 데이터 학습 및 추정 과정을 도시하고, 이하에서는 도 4를 참조하여 통합 데이터를 기반으로 학습하는 방법 및 도출되는 최종 결과에 대해 설명한다. 도 4를 참조하면, 도 2를 참조하여 설명한 여러 개의 통합된 형태의 영상과, 도 3을 참조하여 설명한 영상 내 객체에 상응하는 동적 및 기하학적 데이터를 통합함으로써, 학습(Training)하고 실행(Inference)하는 과정을 도 시한다. 각 섹션(101, 102, 103)에서 나타내는 영상의 데이터 섹션에 대해, 통합 영상은 IMS(Image Main Sector) 및 IMS 내에 타일 형태로 재배치 가능한 ISS(Image Sub Sector)로 구성된다. 즉, IMS는 크게 가로 또는 세로에 대한 큰 섹션을 이루는 것을 의미하고, ISS는 세션 내에 여분 또는 재배치 가능한 공간을 의미한다. IMS 내의 ISS에는 데이터 주석 처리(Annotation) 시 영역에 대한 정보가 추가된다. 추가 서브 섹터(201-1)에는 기존의 3개의 카메라 영상을 통합한 형태 이외에, 신호등 정보를 포함한 영상이 추 가 배치된다. 본 발명의 실시예에 따른 타일 방식의 통합 영상과 동적/기하학적 정보 학습은, 통합 영상과 영상 내 객체의 구조적 데이터를 융합하여 학습(Training)하는 과정에서 도출된 최종 학습 정보를 바탕으로 수행되 며, 실시간 실행(Inference, 207)에서는 통합된 영상의 입력만으로 영상 내 객체의 구조적 데이터를 포함 하는 형태로 최종 추정 정보를 확보한다. 타일 방식의 통합 영상에 대해, 객체 검출 네트워크에서는 각 섹션(101, 102, 103)에 해당되는 영상 도메 인에서 검출할 객체에 해당하는 영상 내 객체의 구조적 데이터를 포함하여 학습이 수행된다. 비교 네트워크는 각 섹션에 해당하는 객체의 정보를 비교하고 통합하는 네트워크로서, 각 섹션(101, 102, 103)에서 검출되는 정보에 대해 객체의 크기와 위치에 따라 가중치를 부여한다. 통합 네트워크는 객체에 부여된 가중치, 위치, 크기, 종류, 모델, 방향 정보를 통합하며, 각 섹션(101, 102, 103)에서 도출된 객체의 중복된 정보에 대해 가중치 네트워크를 기반으로 우선 순위를 정의하여, 한 프레 임의 통합 도메인으로 객체의 동적/기하학적 정보를 취합한다. 통합 네트워크를 통과한 프레임에 해당되는 결과에 대해서는 N개의 프레임 정보를 저장하고, 추적 아이디, 속도, 타겟 상태를 추정하고, 통합된 섹터 정보를 취합하여 자율주행 환경을 인식하는 정보로 활용한다. 도 5는 본 발명의 실시예에 따른 다중 이미지의 분할 배열 방식 기반 데이터 구축 및 학습 방법을 도시한다. 본 발명에 따른 다중 이미지의 분할 배열 방식 기반 데이터 구축 및 학습 방법은 복수 개의 카메라가 촬영한 영 상 데이터를 획득하는 단계(S510)와, 영상 데이터를 타일 배열의 단일 프레임으로 통합하는 단계(S520)와, 단일 프레임 내에 존재하는 객체에 라벨링된 객체 정보를 영상 도메인으로 변환하는 단계(S530) 및 영상 도메인으로 변환한 영상과 영상 도메인 라벨링 정보를 통합하여 학습 데이터로 생산하는 단계(S540)를 포함한다. S510 단계는 상이한 화각과 해상도를 가지도록 촬영 정보가 설정된 복수 개의 카메라로부터 영상 데이터를 획득 한다. S520 단계는 단일 프레임 내의 섹션 별로 일부 보여지는 객체, 온전한 형태로 보여지는 ROI 정보, 원거리에 위 치하여 상대적으로 ROI가 작은 객체 정보를 통합 관리하여 학습 레벨로 전달 가능한 데이터를 구축한다. S530 단계는 버드아이 뷰 상 객체 좌표 정보, 객체 크기에 해당하는 형태 모델링 정보, 이동 방향 정보를 포함 하는 객체 정보를 영상 도메인으로 변환한다. S540 단계는 객체, 모델, 클래스, 포지션, 헤딩, 사이즈, 타겟 정보를 포함하는 영상 내 객체의 구조적 데이터 를 이용하여 학습을 수행한다. 한편, 본 발명의 실시예에 따른 방법은 컴퓨터 시스템에서 구현되거나, 또는 기록매체에 기록될 수 있다. 컴퓨 터 시스템은 적어도 하나 이상의 프로세서와, 메모리와, 사용자 입력 장치와, 데이터 통신 버스와, 사용자 출력 장치와, 저장소를 포함할 수 있다. 전술한 각각의 구성 요소는 데이터 통신 버스를 통해 데이터 통신을 한다. 컴퓨터 시스템은 네트워크에 커플링된 네트워크 인터페이스를 더 포함할 수 있다. 프로세서는 중앙처리 장치 (central processing unit (CPU))이거나, 혹은 메모리 및/또는 저장소에 저장된 명령어를 처리하는 반도체 장치 일 수 있다. 메모리 및 저장소는 다양한 형태의 휘발성 혹은 비휘발성 저장매체를 포함할 수 있다. 예컨대, 메모리는 ROM 및 RAM을 포함할 수 있다. 따라서, 본 발명의 실시예에 따른 방법은 컴퓨터에서 실행 가능한 방법으로 구현될 수 있다. 본 발명의 실시예 에 따른 방법이 컴퓨터 장치에서 수행될 때, 컴퓨터로 판독 가능한 명령어들이 본 발명에 따른 방법을 수행할 수 있다. 한편, 상술한 본 발명에 따른 방법은 컴퓨터로 읽을 수 있는 기록매체에 컴퓨터가 읽을 수 있는 코드로서 구현 되는 것이 가능하다. 컴퓨터가 읽을 수 있는 기록 매체로는 컴퓨터 시스템에 의하여 해독될 수 있는 데이터가 저장된 모든 종류의 기록 매체를 포함한다. 예를 들어, ROM(Read Only Memory), RAM(Random Access Memory), 자기 테이프, 자기 디스크, 플래시 메모리, 광 데이터 저장장치 등이 있을 수 있다. 또한, 컴퓨터로 판독 가능 한 기록매체는 컴퓨터 통신망으로 연결된 컴퓨터 시스템에 분산되어, 분산방식으로 읽을 수 있는 코드로서 저장되고 실행될 수 있다. 도 6은 본 발명의 실시예에 따른 방법을 구현하기 위한 컴퓨터 시스템을 나타낸 블록도이다. 도 6을 참조하면, 컴퓨터 시스템은, 버스를 통해 통신하는 프로세서, 메모리, 입력 인 터페이스 장치, 출력 인터페이스 장치, 및 저장 장치 중 적어도 하나를 포함할 수 있다. 컴 퓨터 시스템은 또한 네트워크에 결합된 통신 장치를 포함할 수 있다. 프로세서는 중앙 처리 장치(central processing unit, CPU)이거나, 또는 메모리 또는 저장 장치에 저장된 명령을 실행하 는 반도체 장치일 수 있다. 메모리 및 저장 장치는 다양한 형태의 휘발성 또는 비휘발성 저장 매체 를 포함할 수 있다. 예를 들어, 메모리는 ROM(read only memory) 및 RAM(random access memory)를 포함할 수 있다. 본 기재의 실시예에서 메모리는 프로세서의 내부 또는 외부에 위치할 수 있고, 메모리는 이미 알려진 다 양한 수단을 통해 프로세서와 연결될 수 있다. 메모리는 다양한 형태의 휘발성 또는 비휘발성 저장 매체이며, 예를 들어, 메모리는 읽기 전용 메모리(read-only memory, ROM) 또는 랜덤 액세스 메모리(random access memory, RAM)를 포함할 수 있다. 따라서, 본 발명의 실시예는 컴퓨터에 구현된 방법으로서 구현되거나, 컴퓨터 실행 가능 명령이 저장된 비일시 적 컴퓨터 판독 가능 매체로서 구현될 수 있다. 한 실시예에서, 프로세서에 의해 실행될 때, 컴퓨터 판독 가능 명령은 본 기재의 적어도 하나의 양상에 따른 방법을 수행할 수 있다. 통신 장치는 유선 신호 또는 무선 신호를 송신 또는 수신할 수 있다. 또한, 본 발명의 실시예에 따른 방법은 다양한 컴퓨터 수단을 통해 수행될 수 있는 프로그램 명령 형태로 구현 되어, 컴퓨터 판독 가능 매체에 기록될 수 있다. 상기 컴퓨터 판독 가능 매체는 프로그램 명령, 데이터 파일, 데이터 구조 등을 단독으로 또는 조합하여 포함할 수 있다. 상기 컴퓨터 판독 가능 매체에 기록되는 프로그램 명령은, 본 발명의 실시예를 위해 특별히 설계되어 구성된 것이거나, 컴퓨터 소프트웨어 분야의 통상의 기술자에게 공지되어 사용 가능한 것일 수도 있다. 컴퓨터 판독 가능 기록 매체는 프로그램 명령을 저장하고 수행하도록 구성된 하드웨어 장치를 포함할 수 있다. 예를 들 어, 컴퓨터 판독 가능 기록 매체는 하드 디스크, 플로피 디스크 및 자기 테이프와 같은 자기 매체(magnetic media), CD-ROM, DVD와 같은 광 기록 매체(optical media), 플롭티컬 디스크(floptical disk)와 같은 자기-광 매체(magneto-optical media), 롬(ROM), 램(RAM), 플래시 메모리 등일 수 있다. 프로그램 명령은 컴파일러에 의해 만들어지는 것과 같은 기계어 코드뿐만 아니라, 인터프리터 등을 통해 컴퓨터에 의해 실행될 수 있는 고급 언어 코드를 포함할 수 있다. 이상에서 본 발명의 실시예에 대하여 상세하게 설명하였지만 본 발명의 권리범위는 이에 한정되는 것은 아니고 다음의 청구범위에서 정의하고 있는 본 발명의 기본 개념을 이용한 당업자의 여러 변형 및 개량 형태 또한 본 발명의 권리범위에 속하는 것이다."}
{"patent_id": "10-2022-0099345", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 실시예에 따른 다중 이미지의 분할 배열 방식 기반 데이터 구축 및 학습 시스템을 도시한다. 도 2는 본 발명의 실시예에 따른 다중 카메라 재배열 데이터 구조를 도시한다. 도 3은 본 발명의 실시예에 따른 다중, 다종 센서 통합 타일형 데이터 가공 과정을 도시한다. 도 4는 본 발명의 실시예에 따른 다중 재배열 통합 데이터 학습 및 추정 과정을 도시한다. 도5는 본 발명의 실시예에 따른 다중 이미지의 분할 배열 방식 기반 데이터 구축 및 학습 방법을 도시한다. 도 6은 본 발명의 실시예에 따른 방법을 구현하기 위한 컴퓨터 시스템을 나타낸 블록도이다."}
