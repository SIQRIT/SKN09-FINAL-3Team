{"patent_id": "10-2023-0122926", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2025-0040199", "출원번호": "10-2023-0122926", "발명의 명칭": "객체가 갇혀 있는 상황을 인식하기 위한 방법 및 장치", "출원인": "에스케이텔레콤 주식회사", "발명자": "마춘페이"}}
{"patent_id": "10-2023-0122926", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "객체가 갇혀 있는 상황을 인식하기 위한 컴퓨터 구현 방법으로서,감시 공간을 촬영한 복수개의 프레임들 사이에서 동일성을 갖는 객체를 식별하는 과정;상기 객체의 행위에 관한 하나 이상의 시간적 특징량들을 산출하는 과정; 및상기 하나 이상의 시간적 특징량들 및 상기 하나 이상의 시간적 특징량들 각각에 대해 기정의된 하나 이상의 통계치들을 기초로, 상기 객체가 상기 감시 공간 내에 갇혀 있는 상황일 가능성을 수치화하는 과정을 포함하는 방법."}
{"patent_id": "10-2023-0122926", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 하나 이상의 시간적 특징량들은, 상기 객체의 체류시간을 포함하되,상기 산출하는 과정은, 상기 객체가 검출된 프레임들 간의 시간적 거리에 기초하여 상기 객체의 체류시간을 산출하는, 방법."}
{"patent_id": "10-2023-0122926", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 하나 이상의 시간적 특징량들은, 상기 객체의 이동거리를 포함하되,상기 산출하는 과정은, 각 프레임에서 상기 객체를 대표하는 포인트를 결정하는 과정; 및상기 복수개의 프레임들 내에서의 상기 포인트의 픽셀 이동량에 기초하여, 상기 객체의 이동거리를 산출하는 과정을 포함하는, 방법."}
{"patent_id": "10-2023-0122926", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서,상기 결정하는 과정은,상기 복수개의 프레임들에서 검출된 객체의 개수에 기초하여, 상기 객체를 둘러싸는 바운딩박스의 중점 및 상기객체에 대해 추출된 키포인트 중 어느 하나를 상기 객체를 대표하는 포인트로 결정하는, 방법."}
{"patent_id": "10-2023-0122926", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서,상기 하나 이상의 시간적 특징량들은, 상기 객체의 자세 변화빈도를 포함하되,상기 산출하는 과정은,각 프레임에서 추출되는 하나 이상의 키포인트들을 이용하여, 상기 각 프레임 내에서 상기 객체의 뷰(view) 및포스처(posture) 중 하나 이상을 추정하는 과정; 및상기 복수개의 프레임들 중, 이전 프레임 대비 상기 뷰 및 상기 포스처 중 하나 이상이 변화한 프레임의 수에기초하여, 상기 객체의 자세 변화빈도를 산출하는 과정을 포함하는 방법."}
{"patent_id": "10-2023-0122926", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "공개특허 10-2025-0040199-3-제1항에 있어서,상기 하나 이상의 시간적 특징량들은, 구조요청 발생빈도를 포함하되,상기 산출하는 과정은,각 프레임에서 추출되는 하나 이상의 키포인트들을 이용하여, 각 프레임 내에서 상기 객체가 구조 요청을 나타내는 제스처를 취하고 있는지 여부를 판단하는 과정; 및상기 복수개의 프레임들 중, 상기 객체가 상기 구조 요청을 나타내는 제스처를 취하고 있는 것으로 판단된 프레임의 수에 기초하여, 상기 구조요청 발생빈도를 산출하는 과정을 포함하는, 방법."}
{"patent_id": "10-2023-0122926", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6항에 있어서,상기 구조요청 발생빈도를 산출하는 과정은,기정의된 개수 이상의 연속된 프레임들에서 상기 객체가 상기 구조 요청을 나타내는 제스처를 취하고 있는 것으로 판단된 경우에, 상기 구조요청 발생빈도를 증가시키는 과정을 포함하는, 방법."}
{"patent_id": "10-2023-0122926", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제6항에 있어서,상기 구조 요청을 나타내는 제스처는, 팔을 교차하는 제스처를 포함하되,상기 판단하는 과정은,상기 키포인트들을 잇는 선분들 중 상기 객체의 몸통에 대응하는 선분과 상기 객체의 각 위팔(upper arm)에 대응하는 선분 사이의 각도가 기정의된 임계 각도 이상이고, 상기 객체의 양 아래팔(forearm)에 각각 대응하는 선분들 사이에 교점이 존재할 제1 조건을 만족하는 경우에, 상기 객체가 상기 팔을 교차하는 제스처를 취하고 있는 것으로 판단하는, 방법."}
{"patent_id": "10-2023-0122926", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서,상기 판단하는 과정은,상기 교점과 상기 객체의 양 손목 및 양 팔꿈치에 대응하는 키포인트들에 의해 정의되는 영역의 중점 간의 거리가 기정의된 임계 거리보다 작을 제2 조건을 더 만족하는 경우에, 상기 객체가 상기 팔을 교차하는 제스처를 취하고 있는 것으로 판단하는, 방법."}
{"patent_id": "10-2023-0122926", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제6항에 있어서,상기 구조 요청을 나타내는 제스처는, 손을 흔드는 제스처를 포함하되,상기 판단하는 과정은,상기 키포인트들을 잇는 선분들 중 상기 객체의 몸통에 대응하는 선분과 상기 객체의 각 위팔에 대응하는 선분사이의 각도가 기정의된 임계 각도 이상이고, 상기 객체의 각 손목에 대응하는 키포인트들을 기준으로 정의된복수개의 제1 관심영역들 중 어느 하나 이상에서 모션 블러(motion blur)가 검출되는 제3 조건을 만족하는 경우에, 상기 객체가 상기 손을 흔드는 제스처를 취하고 있는 것으로 판단하는, 방법."}
{"patent_id": "10-2023-0122926", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제10항에 있어서,상기 판단하는 과정은,공개특허 10-2025-0040199-4-상기 객체의 머리에 대응하는 키포인트에 의해 정의되는 제2 관심영역 내에서만 모션 블러가 검출되는 것인 제4조건을 더 만족하는 경우에, 상기 객체가 상기 손을 흔드는 제스처를 취하고 있는 것으로 판단하는, 방법."}
{"patent_id": "10-2023-0122926", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제6항에 있어서,상기 산출하는 과정은,상기 객체의 뷰 및 포스처 중 하나 이상이 미리 설정된 제5 조건을 만족하는지 여부를 판단하는 과정을 더 포함하는, 방법."}
{"patent_id": "10-2023-0122926", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "명령어들을 저장하는 메모리; 및 적어도 하나의 프로세서를 포함하되,상기 적어도 하나의 프로세서는 상기 명령어들을 실행함으로써,감시 공간을 촬영한 복수개의 프레임들 사이에서 동일성을 갖는 객체를 식별하고,상기 객체의 행위에 관한 하나 이상의 시간적 특징량들을 산출하고,상기 하나 이상의 시간적 특징량들 및 상기 하나 이상의 시간적 특징량들 각각에 대해 기정의된 하나 이상의 통계치들을 기초로, 상기 객체가 상기 감시 공간 내에 갇혀 있는 상황일 가능성을 수치화하는, 장치."}
{"patent_id": "10-2023-0122926", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제1항 내지 제12항 중 어느 한 항에 따른 방법이 포함하는 각 과정을 실행시키기 위하여 컴퓨터로 읽을 수 있는기록매체에 저장된 컴퓨터프로그램."}
{"patent_id": "10-2023-0122926", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "객체가 갇혀 있는 상황을 인식하기 위한 방법 및 장치를 개시한다. 본 개시의 일 측면에 의하면, 객체가 갇혀 있는 상황을 인식하기 위한 컴퓨터 구현 방법으로서, 감시 공간을 촬 영한 복수개의 프레임들 사이에서 동일성을 갖는 객체를 식별하는 과정; 상기 객체의 행위에 관한 하나 이상의 시간적 특징량들을 산출하는 과정; 및 상기 하나 이상의 시간적 특징량들 및 상기 하나 이상의 시간적 특징량들 각각에 대해 기정의된 하나 이상의 통계치들을 기초로, 상기 객체가 상기 감시 공간 내에 갇혀 있는 상황일 가능 성을 수치화하는 과정을 포함하는 방법을 제공한다."}
{"patent_id": "10-2023-0122926", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 객체가 갇혀 있는 상황을 인식하기 위한 방법 및 장치에 관한 것이다."}
{"patent_id": "10-2023-0122926", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "이하에 기술되는 내용은 단순히 본 실시예와 관련되는 배경 정보만을 제공할 뿐 종래기술을 구성하는 것이 아니 다. 최근 IT 기술의 발달에 따라, 카메라에 의해 촬영되는 영상으로부터 객체의 행위나, 객체가 처한 상황을 인식하 는 기술의 연구가 활발히 이루어지고 있다. 영상으로부터 객체의 행위를 인식하는 기술에는 주로 인공지능 모델 기반의 알고리즘이 활용되고 있다. 인공지능 모델이 특정 행위를 인식하도록 학습시키기 위해서는 수많은 학습 데이터가 필요하며, 학습 데이터 구축 및 학습에는 큰 비용과 시간이 소모된다."}
{"patent_id": "10-2023-0122926", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 개시는, 감시 공간 내에 갇힌 객체로부터 관측되는 통계적 특징을 활용해, 영상을 기반으로 객체가 갇혀 있 는 상황을 인식할 수 있는 방법 및 장치를 제공하는 데 주된 목적이 있다. 본 발명이 해결하고자 하는 과제들은 이상에서 언급한 과제들로 제한되지 않으며, 언급되지 않은 또 다른 과제 들은 아래의 기재로부터 통상의 기술자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2023-0122926", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 개시의 일 측면에 의하면, 객체가 갇혀 있는 상황을 인식하기 위한 컴퓨터 구현 방법으로서, 감시 공간을 촬 영한 복수개의 프레임들 사이에서 동일성을 갖는 객체를 식별하는 과정; 상기 객체의 행위에 관한 하나 이상의시간적 특징량들을 산출하는 과정; 및 상기 하나 이상의 시간적 특징량들 및 상기 하나 이상의 시간적 특징량들 각각에 대해 기정의된 하나 이상의 통계치들을 기초로, 상기 객체가 상기 감시 공간 내에 갇혀 있는 상황일 가 능성을 수치화하는 과정을 포함하는 방법을 제공한다. 본 개시의 다른 측면에 의하면, 명령어들을 저장하는 메모리; 및 적어도 하나의 프로세서를 포함하되, 상기 적 어도 하나의 프로세서는 상기 명령어들을 실행함으로써, 감시 공간을 촬영한 복수개의 프레임들 사이에서 동일 성을 갖는 객체를 식별하고, 상기 객체의 행위에 관한 하나 이상의 시간적 특징량들을 산출하고, 상기 하나 이 상의 시간적 특징량들 및 상기 하나 이상의 시간적 특징량들 각각에 대해 기정의된 하나 이상의 통계치들을 기 초로, 상기 객체가 상기 감시 공간 내에 갇혀 있는 상황일 가능성을 수치화하는, 장치를 제공한다. 본 개시의 다른 측면에 의하면, 전술한 방법이 포함하는 각 과정을 실행시키기 위하여 컴퓨터로 읽을 수 있는 기록매체에 저장된 컴퓨터프로그램을 제공한다."}
{"patent_id": "10-2023-0122926", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 개시의 실시예에 의하면, 감시 공간 내에 갇힌 객체로부터 관측되는 통계적 특징을 활용하여, 객체가 갇혀 있는 상황을 정확하고 효율적으로 인식할 수 있다는 효과가 있다. 본 개시의 실시예에 의하면, 모바일 기기 또는 감시 공간 내에 설치된 인터폰 통해 감시 공간 내에 갇힌 사람이 물리적으로 구조를 요청하는 방식 대비 더 안전하고 빠르게 갇힘 상황을 인식할 수 있다는 효과가 있다. 예컨대, 본 개시의 실시예에 의하면, 인터폰을 통해 연결될 관제 요원이 부재한 경우, 감시 공간 내 전원 공급 이 중단되어 인터폰 사용이 불가능한 경우, 및/또는 모바일 기기의 통신 연결 상태가 좋지 않은 경우에도, 영상 을 기반으로 갇힘 상황을 자동으로 인식할 수 있어, 인명 피해를 최소화할 수 있다. 본 개시의 실시예에 의하면, 사회적 약자(예컨대, 노인 또는 아동 등)나, 언어적 장애를 가진 사람들과 같이, 구조 요청을 위해 큰소리를 내기 어려운 사람들의 갇힘 상황을 효과적으로 인식할 수 있다. 본 개시의 효과들은 이상에서 언급한 효과들로 제한되지 않으며, 언급되지 않은 또 다른 효과들은 아래의 기재 로부터 통상의 기술자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2023-0122926", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 본 개시의 일부 실시예들을 예시적인 도면을 이용해 상세하게 설명한다. 각 도면의 구성 요소들에 참조 부호를 부가함에 있어서, 동일한 구성 요소들에 대해서는 비록 다른 도면 상에 표시되더라도 가능한 한 동일한 부호를 가지도록 하고 있음에 유의해야 한다. 또한, 본 개시를 설명함에 있어, 관련된 공지 구성 또는 기능에 대한 구체적인 설명이 본 개시의 요지를 흐릴 수 있다고 판단되는 경우에는 그 상세한 설명은 생략한다. 본 개시에 따른 실시예의 구성요소를 설명하는 데 있어서, 제1, 제2, i), ii), a), b) 등의 부호를 사용할 수 있다. 이러한 부호는 그 구성요소를 다른 구성 요소와 구별하기 위한 것일 뿐, 그 부호에 의해 해당 구성요소의 본질 또는 차례나 순서 등이 한정되지 않는다. 명세서에서 어떤 부분이 어떤 구성요소를 '포함' 또는 '구비'한 다고 할 때, 이는 명시적으로 반대되는 기재가 없는 한 다른 구성요소를 제외하는 것이 아니라 다른 구성요소를 더 포함할 수 있는 것을 의미한다. 첨부된 도면과 함께 이하에 개시될 상세한 설명은 본 개시의 예시적인 실시형태를 설명하고자 하는 것이며, 본 개시가 실시될 수 있는 유일한 실시형태를 나타내고자 하는 것이 아니다. 본 개시에서 영상이라는 용어는, 정지 영상(still image)과 동영상(video)을 모두 포괄하는 의미로 사용될 수 있다. 도 1은 본 개시가 적용될 수 있는 예시적인 시스템을 개략적으로 나타낸 블록구성도이다. 영상 처리장치는 카메라로부터 획득한 영상에 대한 추론을 수행할 수 있다. 영상 처리장치는 영상 내 하나 이상의 객체의 행위를 인식하고/거나, 영상에 나타난 상황을 인식할 수 있다. 예컨대, 영상 처리장치 는 영상을 기반으로 특정 객체의 행위를 분석하여, 해당 객체가 카메라가 설치된 감시 공간 내에 갇혀 있는지를 판단할 수 있다. 객체가 갇혀 있다고 판단된 경우, 영상 처리장치는 구조 경보를 생성할 수 있다. 구조 경보는 감시 공간을 모니터링하는 관제요원에게 시각적, 청각적 및/또는 촉각적으로 제공되고/거나, 긴급 구조 기관(예컨대, 소방청)에서 운용하는 서버로 전송될 수 있다. 이하 본 개시를 설명함에 있어, 영상 처리장치는 엘리베이터의 내부 공간을 촬영한 영상을 이용하여, 사람 이 엘리베이터에 갇혀있는 상황을 인식하는 장치인 것으로 가정하여 설명한다. 그러나 본 개시의 기술적 사상은, 다른 감시 공간을 촬영한 영상을 이용하여, 객체의 갇힘 상황 또는 객체의 구조 요청을 인식하고자 하 는 경우에도 실질적인 기술적 사상의 변경 없이 적용될 수 있음에 유의하여야 한다. 도 2는 본 개시의 일 실시예에 따른 카메라의 설치 환경을 예시적으로 나타낸 도면이다. 도 3은 본 개시의 일 실시예에 따른 카메라에 의해 촬영된 영상을 예시적으로 나타낸 도면이다. 카메라는 엘리베이터(EV)의 천장 부근에 설치될 수 있다. 카메라는 엘리베이터(EV)를 상방에서 소정의 각도로 내려다본 하이 앵글의 영상(IMG)을 촬영할 수 있다. 카메라는 엘리베이터(EV)의 일측 모서리에 설치 되어 내부 공간을 대각선 방향으로 내려다볼 수 있다. 이에 따라, 영상(IMG) 내에서, 바닥면은 다이아몬드에 가 까운 형상을 가질 수 있다. 또한, 영상(IMG) 내에서, 카메라가 설치된 모서리에 대해 대각선 방향에 위치한 모서리(CL)는 영상(IMG)의 수평방향(X)에 대해 수직에 가까운 각도를 가질 수 있다. 영상(IMG) 내에서 바닥면이 중앙에 근접한 곳에 위치하도록, 카메라의 위치 및/또는 각도가 조정될 수 있다. 카메라의 시야에 바닥 면의 대부분의 영역이 포함될 수 있도록, 카메라의 위치 및/또는 각도가 조정될 수 있다. 사람이 카메라 바 로 아래에 서는 경우와 같은 특정한 케이스를 제외하고는, 카메라의 시야에 사람의 전신이 포함될 수 있도 록, 카메라의 위치 및/또는 각도가 조정될 수 있다. 다시 도 1을 참조하면, 영상 처리장치는 객체 검출모듈, 키포인트 추정모듈, 객체 추적모듈 , 및 갇힘 인식모듈을 전부 또는 일부 포함할 수 있다. 도 1에 도시된 모든 블록이 필수 구성요소인 것은 아니며, 다른 실시예에서 일부 블록이 추가, 변경 또는 삭제될 수 있다. 한편, 도 1에 도시된 구성요소들 은 기능적으로 구분되는 요소들을 나타낸 것으로서, 적어도 하나의 구성요소가 실제 물리적 환경에서는 서로 통 합되는 형태로 구현될 수도 있다. 객체 검출모듈은 영상으로부터 사전에 정의된 유형의 객체를 검출할 수 있다. 여기서, 사전에 정의된 유형 의 객체는, 예컨대, 사람일 수 있다. 객체 검출모듈은 객체를 둘러싼 바운딩박스(bounding box)를 생성할 수 있다. 여기서, 하나의 바운딩박스는 적어도 하나의 객체를 포함할 수 있다. 객체 검출모듈은 동일한 유 형의 복수개의 객체들을 각각 둘러싸는 복수개의 바운딩박스들을 검출할 수 있다. 키포인트 추정모듈은 영상으로부터 객체에 대응하는 키포인트(key point)들의 위치를 추정할 수 있다. 키 포인트는, 랜드마크(landmark) 또는 관절점(joint) 등으로 지칭될 수도 있다. 도 4a 및 도 4b는 본 개시의 다양한 실시예들에 따른 키포인트들을 예시적으로 나타낸 도면이다. 키포인트 추정모듈은 객체의 하나 이상의 부위들에 각각 대응하는 키포인트들(J0 내지 J19)의 위치를 추정 할 수 있다. 키포인트 추정모듈이 키포인트를 추출하는 부위 및 키포인트들의 수는 구현예에 따라 달라질 수 있다. 예컨대, 도 4a에서는 머리 부위에서 하나의 키포인트(J0)만이 추출되는 것으로 예시하고 있으나, 다른 예에 따른 키포인트 추정모듈은 도 4b에 도시된 것과 같이 머리의 세부적인 부위들(예컨대, 눈, 코, 귀 등)에 대응하는 복수개의 키포인트들(J15 내지 J19)을 추출할 수도 있다. 표 1은 도 4a 및 도 4b에 도시된 키포 인트들(J0 내지 J19)에 대응하는 신체 부위를 나타낸다. 표 1 키포인트 부위 키포인트 부위 J0 머리 중심 J15 코 J1 목 J16 오른쪽 눈 J2 오른쪽 어깨 J17 왼쪽 눈 J3 오른쪽 팔꿈치 J18 오른쪽 귀 J4 오른쪽 손목 J19 왼쪽 귀 J5 왼쪽 어깨 J6 왼쪽 팔꿈치 J7 왼쪽 손목 J8 몸통 아래쪽 J9 오른쪽 엉덩이 J10 오른쪽 무릎 J11 오른쪽 발목 J12 왼쪽 엉덩이 J13 왼쪽 무릎 J14 왼쪽 발목 키포인트 추정모듈은 영상 및/또는 해당 영상에 대한 객체 검출 결과를 기초로, 하나 이상의 키포인트들의 좌표를 추정할 수 있다. 일 예로, 키포인트 추정모듈은 객체가 검출된 부분이 크롭된 영상을 입력받아, 해 당 객체에 대해 추출된 하나 이상의 키포인트들의 좌표를 출력할 수 있다. 다른 예로, 키포인트 추정모듈 은 영상과 바운딩박스의 좌표를 입력받아, 해당 객체에 대하 추출된 하나 이상의 키포인트들의 좌표를 출력할 수도 있다. 키포인트 추정모듈은, 하나 이상의 키포인트들의 좌표와 함께, 각 키포인트가 해당 좌표에 위 치할 확률을 나타내는 신뢰도(confidence score)를 추정할 수 있다. 객체 추적모듈은 복수개의 프레임들 사이에서 영상에 나타난 객체를 추적하고, 동일성을 갖는 객체를 식별 할 수 있다. 예컨대, 객체 추적모듈은 복수개의 프레임들에서 검출된 바운딩 박스들 중에서, 동일성을 갖 는 객체를 둘러싼 바운딩 박스들에 동일한 식별자를 할당할 수 있다. 객체 검출, 키포인트 추정, 및 객체 추적을 구현하기 위한 구체적인 방법은, 해당 분야에서 일반적인 바 자세한 설명은 생략하도록 한다. 갇힘 인식모듈은 영상으로부터 추정된 키포인트들 및/또는 객체 추적 결과를 기초로, 갇혀있는 객체의 행 위 및/또는 객체가 갇혀 있는 상황을 인식할 수 있다. 갇힘 인식모듈은 복수개의 프레임들에서 식별된 객체의 행위에 관한 하나 이상의 시간적 특징량들을 산출 할 수 있다. 여기서, 시간적 특징량은, 객체가 감시 공간 내에 갇혀 있는 상황일 가능성 판단하기 위한 지표로, 객체의 체류시간, 이동거리, 자세 변화빈도 및 구조요청 발생빈도 중 하나 이상을 포함할 수 있다. 복수개의 프 레임에서 서로 구별되는 복수개의 객체가 식별된 경우, 객체별로 시간적 특징량들이 산출될 수 있다. 도 5는 본 개시의 일 실시예에 따른 갇힘 인식모듈을 개략적으로 나타낸 블록구성도이다. 갇힘 인식모듈은 체류시간 분석모듈, 동선 분석모듈, 자세 인식모듈, 제스처 인식모듈 및 확률 산출모듈의 전부 또는 일부를 포함할 수 있다. 체류시간 분석모듈은 객체 추적결과를 기초로, 객체가 감시 공간 내에 체류한 시간을 파악할 수 있다. 체 류시간 분석모듈은 객체가 검출된 프레임들 간의 시간적 거리에 기초하여 객체의 체류시간을 산출할 수 있 다. 일 예로, 체류시간 분석모듈은 현재 프레임 내에 존재하는 객체(또는 이의 바운딩 박스)와 동일한 식별자를 갖는 객체(또는 이의 바운딩 박스)가 최초로 검출된 프레임으로부터, 현재 프레임까지의 시간적 거리에 기초하여 객체의 체류시간을 산출할 수 있다. 동선 분석모듈은 객체 추적결과를 기초로 객체의 궤적(trajectory)을 분석하여, 객체의 배회행동을 인식할 수 있다. 객체의 배회행동은, 객체의 공간상 궤적의 분포가 상대적으로 넓게 나타나는 경우를 의미할 수 있다. 동선 분석모듈은 객체의 배회행동 발생 여부를 나타내는 지표로, 객체의 이동거리를 계산할 수 있다. 동선 분석모듈은 각 프레임에서 객체를 대표하는 포인트를 결정하고, 복수개의 프레임들 내에서의 해당 포 인트의 픽셀 이동량에 기초하여 객체의 이동거리를 산출할 수 있다. 동선 분석모듈은 픽셀 이동량을 객체 의 이동거리로 간주하거나, 픽셀 이동량을 실세계에서의 거리 단위(예컨대, m)로 환산할 수도 있다. 이를 위해, 동선 분석모듈은 픽셀 이동량에 적용할 환산비를 미리 저장하고 있을 수 있다. 도 6은 본 개시의 일 실시예에 따라 객체의 이동거리를 산출하는 동작을 설명하기 위해 참조되는 예시도이다. 도 6은 복수개의 프레임들에서 각각 검출된 바운딩 박스들(BBOXN 내지 BBOXN+K)을 하나의 프레임에 중첩한 모습 을 보여준다. 동선 분석모듈은 바운딩 박스(BBOXN 내지 BBOXN+K)의 중점을 객체를 대표하는 포인트로 사용 할 수 있다. 동선 분석모듈은 시간의 흐름에 따른 중점(CN 내지 CN+K)의 이동거리를 산출할 수 있다. 예컨 대, 동선 분석모듈은 기정의된 개수의 프레임들 중, 서로 인접한 프레임에서 검출된 바운딩 박스들의 중점 간의 거리의 합을 계산할 수 있다. 다른 예에서, 동선 분석모듈은 객체의 키포인트들 중 어느 하나 이상을 객체를 대표하는 포인트로 사용할 수도 있다. 예를 들어, 머리 부위에 대응하는 키포인트들 중 어느 하나(머리 중심에 대응하는 키포인트(J0), 코 에 대응하는 키포인트(J15), 눈에 대응하는 키포인트(J16 또는 J17), 또는 입에 대응하는 키포인트(미도시))가 객체를 대표하는 포인트로 사용될 수 있다. 이러한 머리 부위에 대응하는 키포인트들은 폐색(occlusion)에 강인 한 특성을 가지므로, 감시 공간 내에 복수개의 객체들이 존재하는 경우에도 이동거리를 정확하게 산출할 수 있 다. 또 다른 예에서, 동선 분석모듈은 영상에서 검출된 객체의 수에 따라, 객체를 대표하는 포인트를 다르게 결정할 수 있다. 예컨대, 동선 분석모듈은, 영상에서 검출된 객체의 수가 1개인 경우 바운딩 박스의 중점 을 기준으로 이동거리를 계산하고, 객체의 수가 2개 이상인 경우에는 키포인트를 기준으로 이동거리를 계산할 수 있다. 자세 인식모듈은 각 프레임 내의 객체의 자세를 인식할 수 있다. 객체의 자세는, 객체의 뷰 및 포스처 (posture)의 조합으로 표현될 수 있다. 객체의 뷰는, 객체가 촬영된 방향을 의미할 수 있다. 예컨대, 객체의 뷰 는, 정면 뷰(front view), 후면 뷰(back view), 및/또는 측면 뷰(side view)를 포함할 수 있다. 객체의 포스처 는, 예컨대, 서있는 것(stand), 앉아 있는 것(sit), 누워 있는 것(lie), 굽히고 있는 것(bend), 무릎을 꿇고 있 는 것(kneel), 및/또는 쪼그리고 앉아 있는 것(squat)을 포함할 수 있다. 자세 인식모듈은 각 프레임에서 추출된 키포인트들 간의 상관관계(예컨대, 키포인트들 간의 각도 및/또는 거리 등)를 기초로, 객체의 뷰 및/또 는 포스처를 인식할 수 있다. 이를 위해, 자세 인식모듈은 다양한 규칙기반 또는 학습기반 알고리즘을 활 용할 수 있으며, 본 개시에서는 이에 대해 특정한 방식으로 한정하지 않는다. 자세 인식모듈은 일정 기간 동안 객체의 자세가 변화한 빈도를 산출할 수 있다. 자세 인식모듈은 이 전 프레임 대비 객체의 뷰 및 포스처 중 하나 이상이 변화한 프레임의 수에 기초하여 객체의 자세 변화빈도를 산출할 수 있다. 여기서, 이전 프레임은, 직전 프레임 또는 소정의 시간 간격 이전에 획득된 프레임일 수 있다. 표 2는 연속한 6개의 프레임에서 인식되는 객체의 자세의 예를 보여준다. 표 2에서, 이전 프레임 대비 자세가 변화된 경우를 밑줄 및 볼드체로 강조하였다. 표 2 frame NthN+1thN+2thN+3thN+4thN+5th view frontside back backside front posture stand standbend sit squat lie 자세 인식모듈은 기정의된 개수의 프레임들 중에서, 이전 프레임 대비 객체의 뷰가 변화한 프레임의 수 및 이전 프레임 대비 객체의 포스처가 변화한 프레임의 수의 합을 객체의 자세 변화빈도로서 산출할 수 있다. 예컨 대, 표 2의 예시에서는, 6개의 프레임 동안 객체의 뷰 및 포스처가 각각 4번씩 변화하였으므로, 자세 변화빈도 는 8이 될 수 있다. 제스처 인식모듈은 각 프레임 내에서 객체가 취하고 있는 제스처를 인식할 수 있다. 제스처 인식모듈(50 6)은 각 프레임에서 추출된 키포인트들을 이용하여, 객체가 구조 요청을 나타내는 제스처를 취하고 있는지 여부 를 판정할 수 있다. 구조 요청을 나타내는 제스처는, 팔을 교차하는 제스처 및 손을 흔드는 제스처 중 하나 이 상을 포함할 수 있다. 제스처 인식모듈은 각 제스처에 대해 기정의된 판정 조건을 기초로, 객체가 팔을 교차하고 있는지, 및/또 는 손을 흔들고 있는지를 판단할 수 있다. 도 7은 본 개시의 일 실시예에 따라 팔을 교차하는 제스처를 인식하기 위한 는 조건을 설명하기 위해 참조되는 예시도이다. 도 7을 참조하면, 팔을 교차하는 제스처의 판정 조건은, 객체의 위팔(upper arm)에 대응하는 선분과 몸통에 대 응하는 선분 사이의 각도(θL 및 θR)가 기정의된 임계각도 이상일 것을 포함할 수 있다. 위팔에 대응하는 선분 은, 어깨에 대응하는 키포인트(J2 및 J5)와 팔꿈치에 대응하는 키포인트(J3 및 J6)를 잇는 선분일 수 있다. 몸 통에 대응하는 선분은, 어깨에 대응하는 키포인트(J2 및 J5)와 엉덩이에 대응하는 키포인트(J9 및 J12)를 잇는 선분일 수 있다. 제스처 인식모듈은 오른쪽 팔꿈치, 오른쪽 어깨 및 오른쪽 엉덩이에 각각 대응하는 3개의 키포인트들(J3, J2, 및 J9)의 좌표를 이용하여, 해당 키포인트들(J3, J2, 및 J9) 사이의 각도(θR)를 산출할 수 있다. 마찬가지로, 제스처 인식모듈은 왼쪽 팔꿈치, 왼쪽 어깨 및 왼쪽 엉덩이에 각각 대응하는 3개의 키 포인트들(J6, J5, 및 J12)의 좌표를 이용하여, 해당 키포인트들(J6, J5, 및 J12) 사이의 각도(θL)를 산출할 수 있다. 임계각도는, 예컨대 60°일 수 있으나 이에 한정되는 것은 아니다. 팔을 교차하는 제스처의 판정 조건은, 객체의 아래팔(forearm)에 각각 대응하는 선분들 사이에 교점(POI)이 존 재할 것을 포함할 수 있다. 아래팔에 대응하는 선분은, 팔꿈치에 대응하는 키포인트(J3 및 J6)와 손목에 대응하 는 키포인트(J4 및 J7)를 잇는 선분일 수 있다. 제스처 인식모듈은 오른쪽 팔꿈치, 오른쪽 손목, 왼쪽 팔 꿈치 및 왼쪽 손목에 각각 대응하는 4개의 키포인트들(J3, J4, J6 및 J7)의 좌표들의 기하학적 관계를 기초로, 교점(POI)의 존재여부를 판단할 수 있다. 일부 실시예들에서, 제스처 인식의 정확도를 높이기 위해, 교점(POI)의 위치에 관한 추가적인 조건이 부가될 수 있다. 예를 들어, 팔을 교차하는 제스처의 판정 조건은, 교점(POI)이 양쪽 손목 및 양쪽 팔꿈치에 대응하는 4개 의 키포인트들(J3, J4, J6 및 J7)에 의해 정의되는 관심영역의 중앙부에 위치할 것을 포함할 수 있다. 관 심영역의 중앙부는, 관심영역의 중점으로부터 일정 임계거리 이내의 부분일 수 잇다. 도 8은 본 개시의 일 실시예에 따라 손을 흔드는 제스처를 인식하기 위한 조건을 설명하기 위해 참조되는 예시 도이다. 도 8을 참조하면, 손을 흔드는 제스처의 판정 조건은, 객체의 위팔에 대응하는 선분과 몸통에 대응하는 선분 사 이의 각도(θL 및 θR)가 기정의된 임계각도 이상일 것을 포함할 수 있다. 이를 위한 구체적인 방법은, 도 7에서 전술하였으므로 자세한 설명은 생략하도록 한다. 단일 프레임 내에서 손을 흔드는 동적인 제스처를 인식하기 위해, 모션 블러(motion blur)의 발생 여부에 관한 조건이 부가될 수 있다. 손을 흔드는 제스처의 판정 조건은, 손 관심영역들(Hand ROIs, 800 및 820) 중 어느 하 나 이상에서 모션 블러가 검출될 것을 포함할 수 있다. 여기서, 손 관심영역(800 및 820)은 양 손목에 대응하는 키포인트들(J4 및 J7)을 기준으로 정의될 수 있다. 예를 들어, 손 관심영역(800 및 820)은, 각 손목에 대응하는 키포인트들(J4 및 J7)을 중점으로 갖고, 아래팔에 대응하는 선분의 길이의 배수에 해당하는 너비 및 높이를 갖 는 사각형의 영역으로 정의될 수 있으나, 이에 한정되는 것은 아니다. 제스처 인식모듈은 다양한 영상처리 기술을 활용하여 모션 블러를 검출할 수 있다. 예를 들어, 제스처 인식모듈은 손 관심영역들(800 및 820) 에 대해 계산된 라플라시안 분산(variance of Laplacian)이 일정 임계치(예컨대, 10) 이하인 경우에, 해당 관심 영역 내에 모션 블러가 존재하는 것으로 판단할 수 있다. 일부 실시예들에서, 카메라의 흔들림 등으로 인한 오인식을 방지하기 위해, 모션 블러의 발생 위치에 대한 추가적인 조건이 더 부가될 수 있다. 예를 들어, 손을 흔드는 제스처의 판정 조건은, 머리 관심영역 내에 서만 모션 블러가 검출될 것을 포함할 수 있다. 여기서, 머리 관심영역은 머리 부위에서 추출된 키포인트를 기준으로 정의될 수 있다. 일 예로, 머리 관심영역은, 머리 중심에 대응하는 키포인트(J0)에 대응하는 키포인트를 중점으로 갖고, 양 어깨에 대응하는 키포인트들(J2 및 J5) 사이의 거리의 배수에 해당하는 너비 및 높이를 갖는 사각형의 영역으로 정의될 수 있다. 다른 예에서, 머리 관심영역은, 코에 대응하는 키포인트 (J15)를 중점으로 가질 수도 있다. 일부 실시예들에서, 제스처 인식모듈은 자세 인식 결과를 추가로 활용하여 구조 요청을 나타내는 제스처를 인식할 수도 있다. 예를 들어, 제스처 인식모듈은 객체의 뷰 또는 포스처에 관한 추가적인 제약조건이 더 충족되는 경우에, 객체가 구조 요청을 나타내는 제스처를 취하고 있는 것으로 판정할 수 있다. 여기서, 객체의 뷰에 관한 제약조건은, 객체의 정면 뷰가 인식되었을 것을 포함할 수 있다. 객체의 포스처에 관한 제약조건은 서 있는 포스처가 인식되었을 것 및/또는 앉아 있는 포스처가 인식되었을 것을 포함할 수 있다. 구조 요청자는 주로 카메라를 정면으로 응시하며, 서있는 상태 또는 지쳐서 바닥에 앉은 상태로 구조를 요청하는 경향성이 높 기 때문에, 이러한 제약조건을 통해 인식 정확도를 높이고 오인식을 효과적으로 줄일 수 있다. 제스처 인식모듈은 복수개의 프레임들에서 각각 인식된 순간적인 제스처들의 조합을 기초로, 객체가 구조 를 요청하는 행위를 행하고 있는지 판정하고 이러한 행위가 발생한 빈도를 산출할 수 있다. 제스처 인식모듈 은 구조요청 발생 여부의 판정 정확도를 높이기 위해, 복수개의 프레임들에서 인식된 제스처들에 시간적 보팅(temporal voting)을 적용할 수 있다. 도 9a 및 도 9b은 본 개시의 일 실시예에 따라 구조요청 발생 여부를 판정하기 위한 기준을 설명하기 위해 참조 되는 예시도이다. 제스처 인식모듈은 구조 요청을 나타내는 제스처가 복수개의 프레임들에서 연속적으로 인식되었는지에 기 초하여, 구조요청 발생 여부를 판정할 수 있다. 일 예로, 도 9a를 참조하면 제스처 인식모듈은 연속된 3개 의 프레임에서, 구조 요청을 나타내는 것으로 정의된 특정한 하나의 제스처가 연속적으로 인식될 경우, 구조 요 청이 발생한 것으로 판정할 수 있다. 다른 예로, 도 9b를 참조하면 제스처 인식모듈은 연속된 3개의 프레 임에서, 구조 요청을 나타내는 것으로 정의된 복수개의 제스처들 중 임의의 제스처가 인식될 경우, 구조 요청이 발생한 것으로 판정할 수도 있다. 즉, 도 9b의 예시에서는, 복수개의 연속된 프레임들 내에서 서로 다른 제스처 들이 인식된 경우라도, 해당 제스처들이 모두 구조 요청을 나타내는 것으로 정의된 것이라면, 구조요청이 발생 한 것으로 판정할 수 있다. 이를 통해, 다양한 구조요청 제스처가 섞여서 나타나는 경우에도, 구조요청 행위가 발생한 것으로 인식할 수 있다. 일부 실시예들에서, 제스처 인식모듈은 미리 정의된 개수의 프레임들을 단위로 구조요청 발생 여부를 판정 할 수 있다. 예를 들어, 제스처 인식모듈은 10개의 프레임들 중에서 3개 이상의 연속된 프레임에서 구조요 청을 나타내는 제스처가 인식된 경우, 구조 요청이 발생한 것으로 판정할 수 있다. 제스처 인식모듈은 구조 요청이 발생한 것으로 판정된 횟수를 카운트하여, 구조요청 발생빈도를 산출할 수 있다. 확률 산출모듈은 시간적 특징량들 및 이들 각각에 대해 기정의된 하나 이상의 통계치들을 기초로, 객체가 감시 공간 내에 갇혀 있는 상황일 가능성을 수치화할 수 있다. 확률 산출모듈은 입력 영상으로부터 산출된 시간적 특징량(들)을 일반적인 객체(즉, 갇혀 있지 않은 객 체)에 대해 사전에 산출된 시간적 특징량들의 통계치와 비교할 수 있다. 일 예로, 확률 산출모듈은 입력 영상에서 분석된 체류시간이 일반적인 객체의 체류시간에 대한 통계치보다 클수록, 영상 내의 객체가 갇혀 있는 상황일 가능성이 크다고 판단할 수 있다. 다른 예로, 확률 산출모듈은 입력 영상에서 분석된 이동거리가 일반적인 객체의 이동거리에 대한 통계치보다 클수록, 영상 내의 객체가 갇혀 있는 상황일 가능성이 크다고 판 단할 수 있다. 또 다른 예로, 확률 산출모듈은 입력 영상에서 분석된 자세 변화빈도가 일반적인 객체의 자 세 변환빈도에 대한 통계치보다 클수록, 영상 내의 객체가 갇혀 있는 상황일 가능성이 크다고 판단할 수 있다. 또 다른 예로, 확률 산출모듈은 입력 영상에서 분석된 구조요청 발생빈도가 일반적인 상황에서의 구조요청 발생빈도에 대한 통계치보다 클수록, 영상 내의 객체가 갇혀 있는 상황일 가능성이 크다고 판단할 수 있다. 확률 산출모듈은 사전에 정의된 확률 테이블을 이용하여, 산출된 시간적 특징량을 확률 값으로 환산 할 수 있다. 확률 테이블은, 특징별로 별도로 구비될 수 있다. 예컨대, 확률 산출모듈은 제1 확률 테이블 에서 체류시간에 대응하는 제1 확률을 조회하고, 제2 확률 테이블에서 이동거리에 대응하는 제2 확률을 조회하 고, 제3 확률 테이블에서 자세 변화빈도에 대응하는 제3 확률을 조회하며, 제4 확률 테이블에서 구조요청 발생 빈도에 대응하는 제4 확률을 조회할 수 있다. 표 3 내지 표 6은 제1 내지 제4 확률 테이블을 각각 예시한 표이다. 표 3 체류시간 1 3 5 10 30 60[분] 이상 확률 0 20 40 60 80100 [%] 표 4 이동거리 5 10 15 20 30 60[m] 이상 확률 0 20 40 60 80100 [%] 표 5 자세 변화빈도 5 10 15 20 30 60[회] 이상 확률 0 20 40 60 80100 [%] 표 6 구조요청 발생빈도 1 2 3 4 5 6[회] 이상 확률 50 60 70 80 90100 [%] 확률 테이블은, 카메라가 설치된 환경 및 기타 결정적 요소를 고려하여, 사전 조사를 통해 통계적으로 도출된 것일 수 있다. 예를 들어, 카메라가 고층 빌딩의 엘리베이터 내에 설치된 경우, 탑승객이 고층으로 이동할수록 일반적인 상황에서의 체류시간이 증가하게 된다. 따라서, 저층 빌딩의 엘리베이터에 적용되는 경우 와 대비할 때, 제1 확률 테이블 내의 각 확률 값에 대응하는 체류시간이 상대적으로 증가할 수 있다. 즉, 체류 시간이 동일할 때 이로부터 환산되는 제1 확률은 상대적으로 감소할 수 있다. 또한, 체류시간 증가에 대응하여, 이동 거리 및 자세 변화빈도도 상대적으로 증가할 수 있다. 확률 산출모듈은 특징별로 산출된 확률들 가중-합산(weighted sum)하여, 최종 확률을 산출할 수 있다. 확 률 산출모듈에 의해 분석되는 특징들은 객체의 갇힘 상황을 인식하는데 영향을 미치는 정도가 서로 다를 수 있다. 이를 반영하기 위해 갇힘 인식모듈은, 각 특징에 대한 확률에 서로 다른 가중치를 부여할 수 있 다. 예를 들어, 구조요청이 발생한 경우 객체가 갇혀 있을 가능성이 상대적으로 더 높으므로, 제4 확률에 대해 상대적으로 높은 가중치를 부여하고, 제1 내지 제3 확률들에 상대적으로 낮은 가중치를 부여할 수 있다. 여기서, 가중치는, 카메라가 설치된 환경 및 기타 결정적 요소를 고려하여, 사전 조사를 통해 통계적으로 도출된 값일 수 있다. 도 10은 본 개시의 일 실시예에 따른 객체가 갇혀있는 상황을 인식하는 방법을 나타내는 흐름도이다. 영상 처리장치는 감시 공간을 촬영한 복수개의 프레임들 사이에서 동일성을 갖는 객체를 식별할 수 있다 (S1000). 예컨대, 영상 처리장치는 공지의 객체추적 알고리즘을 활용하여, 동일성을 갖는 객체에 관한 바운 딩박스들에 동일한 식별자를 부여할 수 있다. 영상 처리장치는 객체의 행위에 관한 하나 이상의 시간적 특징량들을 산출할 수 있다(S1020). 하나 이상의 시간적 특징량들 중 적어도 일부는, 객체의 특정 부위에 대응하는 하나 이상의 키포인트들을 기초로 산출될 수 있다. 이를 위해, 영상 처리장치는 과정 S900 또는 과정 S920을 수행하기에 앞서, 각 프레임에서 객체에 대 한 하나 이상의 키포인트들을 추출할 수 있다. 일 예로, 하나 이상의 시간적 특징량들은, 객체의 체류시간을 포함할 수 있다. 영상 처리장치는 객체가 검 출된 프레임들 간의 시간적 거리에 기초하여 객체의 체류시간을 산출할 수 있다. 다른 예로, 하나 이상의 시간적 특징량들은, 객체의 이동거리를 포함할 수 있다. 영상 처리장치는 프레임에 서 객체를 대표하는 포인트를 결정하고, 복수개의 프레임들 내에서의 해당 포인트의 픽셀 이동량에 기초하여 객 체의 이동거리를 산출할 수 있다. 여기서, 객체를 대표하는 포인트는, 예컨대, 객체를 둘러싼 바운딩 박스의 어느 한 꼭짓점, 바운딩 박스의 중점, 또는 객체의 특정 신체부위(예컨대, 눈, 코, 또는 귀)에 대응하는 키포인트 일 수 있다. 예컨대, 영상 처리장치는 복수개의 프레임들에서 검출된 객체의 개수에 기초하여, 객체를 둘러 싸는 바운딩박스의 중점 및 객체에 대해 추출된 키포인트 중 어느 하나를 객체를 대표하는 포인트로 결정할 수 있다. 또 다른 예로, 하나 이상의 시간적 특징량들은, 객체의 자세 변화빈도를 포함할 수 있다. 영상 처리장치는 각 프레임에서 추출되는 하나 이상의 키포인트들을 이용하여, 각 프레임 내에서 객체의 뷰 및 객체의 포스처 중 하나 이상을 추정할 수 있다. 영상 처리장치는 복수개의 프레임들 중 이전 프레임 대비 뷰 및 포스처 중 하 나 이상이 변화한 프레임의 수에 기초하여, 객체의 자세 변화빈도를 산출할 수 있다. 또 다른 예로, 하나 이상의 시간적 특징량들은, 구조요청 발생빈도를 포함할 수 있다. 영상 처리장치, 하나 이상의 프레임들에서 객체가 구조 요청을 나타내는 제스처를 취하고 있는 경우, 구조요청이 발생한 것으로 판단 할 수 있다. 이를 위해, 영상 처리장치는 각 프레임에서 추출되는 하나 이상의 키포인트들을 이용하여, 각 프레임 내에서 객체가 구조 요청을 나타내는 제스처를 취하고 있는지 여부를 판단할 수 있다. 일부 실시예에서, 구조 요청을 나타내는 제스처는, 팔을 교차하는 제스처를 포함할 수 있다. 영상 처리장치(1 0)는 키포인트들을 잇는 선분들 중 객체의 몸통에 대응하는 선분과 객체의 각 위팔에 대응하는 선분 사이의 각 도가 기정의된 임계 각도 이상이고, 객체의 양 아래팔에 대응하는 선분들 사이에 교점이 존재할 제1 조건을 만 족하는 경우, 객체가 팔을 교차하는 제스처를 취하고 있는 것으로 판단할 수 있다. 여기서, 영상 처리장치 는 제1 조건에 더불어, 양 아래팔에 각각 대응하는 선분들의 교점과 객체의 양 손목 및 양 팔꿈치에 대응하는 키포인트들에 의해 정의되는 영역의 중점 간의 거리가 기정의된 임계 거리보다 작을 제2 조건을 더 만족하는 경 우에, 객체가 팔을 교차하는 제스처를 취하고 있는 것으로 판단할 수도 있다. 부가적으로 또는 대안적으로, 구조 요청을 나타내는 제스처는, 손을 흔드는 제스처를 포함할 수 있다. 영상 처 리장치는 키포인트들을 잇는 선분들 중 객체의 몸통에 대응하는 선분과 객체의 각 위팔에 대응하는 선분 사 이의 각도가 기정의된 임계 각도 이상이고, 객체의 각 손목에 대응하는 키포인트들을 기준으로 정의된 복수개의 제1 관심영역들 중 어느 하나 이상에서 모션 블러가 검출되는 제3 조건을 만족하는 경우에, 객체가 손을 흔드는 제스처를 취하고 있는 것으로 판단할 수 있다. 여기서, 영상 처리장치는 제3 조건에 더불어, 객체의 머리에 대응하는 키포인트에 의해 정의되는 제2 관심영역 내에서만 모션 블러가 검출되는 것인 제4 조건을 더 만족하는 경우에, 객체가 손을 흔드는 제스처를 취하고 있는 것으로 판단할 수도 있다. 구현예에 따라, 영상 처리장치는, 전술한 조건들에 더불어, 객체의 뷰 및 객체가 취하고 있는 포스처 중 하 나 이상이 미리 설정된 제5 조건을 더 만족하는지 여부를 더 판단할 수도 있다. 여기서, 제5 조건은, 객체의 정 면 뷰가 인식된 것을 포함 수 있다. 부가적으로 또는 대안적으로, 제5 조건은, 서 있는 포스처가 인식된 것 또 는 앉아 있는 포스처가 인식된 것을 포함할 수도 있다. 영상 처리장치는 복수개의 프레임들 중 객체가 구조 요청을 나타내는 제스처를 취하고 있는 것으로 판단된 프레임의 수에 기초하여, 구조요청 발생빈도를 카운트할 수 있다. 일부 실시예에서, 영상 처리장치는 기정 의된 개수 이상의 연속된 프레임들에서 객체가 구조 요청을 나타내는 제스처를 취하고 있는 것으로 판단된 경우 에, 구조요청 발생빈도를 증가시킬 수 있다. 영상 처리장치는 산출된 하나 이상의 시간적 특징량들 및 해당 하나 이상의 시간적 특징량들 각각에 대해 기정의된 하나 이상의 통계치들을 기초로, 객체가 감시 공간 내에 갇혀 있는 상황일 가능성을 수치화할 수 있다 (S1040). 예컨대, 영상 처리장치는 시간적 특징량들의 각 항목에 대해 정의된 확률 테이블을 이용하여 항목 별 확률을 산출할 수 있다. 영상 처리장치는 항목별 확률을 가중-합산하여, 최종 확률을 산출할 수 있다. 도 11은 본 개시의 일 실시예에 따른 제스처 인식방법을 나타내는 흐름도이다. 선택적으로, 영상 처리장치는 객체의 자세에 관한 조건이 충족되는지 판단할 수 있다(S1100). 예컨대, 객체 의 자세에 관한 조건은, 객체의 정면 뷰가 인식된 경우, 객체가 서 있는 포스처가 인식된 경우, 및/또는 객체가 앉아 있는 포스처가 인식된 경우에 충족될 수 있다. 객체의 자세에 관한 조건이 충족되지 않는 경우, 영상 처리 장치는 객체가 구조를 요청하는 제스처를 취하고 있지 않은 것으로 판정할 수 있다. 영상 처리장치는 객체의 팔-몸통 사잇각에 관한 조건이 충족되는지 판단할 수 있다(S1110). 예컨대, 도 7 내지 도 8을 참조하면, 객체의 팔-몸통 사잇각에 관한 조건은, 객체의 오른쪽 팔꿈치, 오른쪽 어깨 및 오른쪽 엉덩이에 대응하는 키포인트들(J3, J2 및 J9) 사이의 각도(θR) 및 객체의 왼쪽 팔꿈치, 왼쪽 어깨 및 왼쪽 엉덩이에 대응하는 키포인트들(J5, J6 및 J12) 사이의 각도(θL)가 모두 소정의 임계각도 이상인 경우에 충족될 수 있다. 객체의 팔-몸통 사잇각에 관한 조건이 충족되지 않는 경우, 영상 처리장치는 객체가 구조를 요청 하는 제스처를 취하고 있지 않은 것으로 판정할 수 있다. 영상 처리장치는 제1 관심영역에서 모션 블러가 발생되었는지 판단할 수 있다(S1120). 예컨대, 도 8을 참조 하면, 제1 관심영역은 객체의 손목에 대응하는 키포인트들(J4 및 J7)을 기준으로 정의되는 손 관심영역(800 및 820)일 수 있다. 선택적으로, 영상 처리장치는 제2 관심영역 내에서만 모션 블러가 발생되었는지를 더 판단할 수 있다 (S1130). 예컨대, 도 8을 참조하면, 제2 관심영역은 객체의 머리 중심에 대응하는 키포인트(J0)를 기준으로 정 의되는 머리 관심영역일 수 있다. 제2 관심 영역 내에서만 모션 블러가 발생한 것으로 판단된 경우, 영상 처리장치는 객체가 손을 흔드는 제 스처를 취하고 있는 것으로 판정할 수 있다(S1140). 영상 처리장치는 객체의 양팔이 교차하고 있는지 판단할 수 있다(S1150). 예컨대, 도 7을 참조하면, 영상 처리장치는 객체의 오른쪽 팔꿈치 및 오른쪽 손목 대응하는 키포인트들(J3 및 J4)을 잇는 선분과 객체의 왼 쪽 팔꿈치 및 왼쪽 손목 대응하는 키포인트들(J6 및 J7)을 잇는 선분 사이에 교점(POI)이 존재하는지에 기초하 여, 양팔의 교차 여부를 판단할 수 있다. 한편, 도 11에서는, 과정 S1120에서 제1 관심 영역에서 모션블러가 발 생하지 않은 것으로 판단된 경우에 과정 S1150을 수행하는 것으로 도시하나 본 개시가 이에 한정되는 것은 아니 다. 다른 예에서, 과정 S1150은 과정 S1120에 선행하여 수행되거나, 과정 S1120과 병렬적으로 수행될 수도 있다. 선택적으로, 영상 처리장치는 양팔 사이의 교점의 위치에 관한 조건이 충족되는지를 더 판단할 수 있다 (S1160). 예컨대, 도 7을 참조하면, 교점(POI)의 위치에 관한 조건은, 해당 교점(POI)이 객체의 오른쪽 팔꿈치, 오른쪽 손목, 왼쪽 팔꿈치 및 왼쪽 손목 대응하는 키포인트들(J3, J4, J6 및 J7)에 의해 정의되는 관심영역 의 중앙부에 위치하는 경우에 충족될 수 있다. 영상 처리장치는 교점(POI)과 관심영역의 중점 간 의 거리에 기초하여, 교점(POI)이 관심영역의 중앙부에 위치하는지를 판단할 수 있다. 교점의 위치에 관한 조건이 충족된 것으로 판단된 경우, 영상 처리장치는 객체가 팔을 교차하는 제스처를 취하고 있는 것으로 판정할 수 있다(S1170). 이상과 같이 본 개시의 실시예에 의하면, 객체가 감시 공간 내에 갇혀있는 경우에 구조를 요청하기 위해 취할 가능성이 큰 2가지 제스처를 자동으로 인식할 수 있다. 또한, 객체의 자세, 두 팔 사이의 교점 위치, 및/또는 모션 블러 검출 위치에 대한 추가적인 제약 조건을 통해, 제스처의 인식 정확도를 높이는 동시에, 오인식을 효 과적으로 줄일 수 있다. 도 12는 본 개시에서 설명된 장치 및 방법들을 구현하기 위해 사용될 수 있는 예시적인 컴퓨팅 장치를 개략적으 로 나타낸 블록구성도이다. 컴퓨팅 장치는 메모리, 프로세서, 스토리지, 입출력 인터페이스 및 통신 인터페이 스 중 일부 또는 전부를 포함할 수 있다. 컴퓨팅 장치는 영상 처리장치의 적어도 일부를 구조적 및/또는 기능적으로 포함할 수 있다. 컴퓨팅 장치는 데스크탑 컴퓨터, 서버, AI 가속기 등과 같은 고정형 (stationary) 컴퓨팅 장치뿐만 아니라, 랩탑 컴퓨터, 스마트 폰 등과 같은 휴대용(mobile) 컴퓨팅 장치일 수도 있다. 메모리는 프로세서로 하여금 본 개시의 다양한 실시예에 따른 방법 또는 동작을 수행하도록 하는 프로그램을 저장할 수 있다. 예를 들면, 프로그램은 프로세서에 의해서 실행 가능한(executable) 복수의 명령어들을 포함할 수 있고, 복수의 명령어들이 프로세서에 의해서 실행됨으로써 도 10에 도시된 방법이 수행될 수 있다. 메모리는 단일 메모리 또는 복수의 메모리들일 수 있다. 이 경우, 본 개시의 다양한 실시예에 따른 방법 또는 동작을 수행하기 위해 필요한 정보는 단일 메모리에 저장되거나 복수의 메모리들에 나뉘어 저장될 수 있다. 메모리가 복수의 메모리들로 구성된 경우, 복수의 메모리들은 물리적으로 분리될 수 있다. 메모리는 휘발성 메모리 및 비휘발성 메모리 중 적어도 하나를 포함할 수 있다. 휘발성 메모리는 SRAM(Static Random Access Memory) 또는 DRAM(Dynamic Random Access Memory) 등을 포함하고, 비휘발성 메모리는 플래시 메모리(flash memory) 등을 포함한다. 프로세서는 적어도 하나의 명령어들을 실행할 수 있는 적어도 하나의 코어를 포함할 수 있다. 프로세서 는 메모리에 저장된 명령어들을 실행할 수 있다. 프로세서는 단일 프로세서 또는 복수의 프 로세서들일 수 있다. 스토리지는 컴퓨팅 장치에 공급되는 전력이 차단되더라도 저장된 데이터를 유지한다. 예를 들면, 스 토리지는 비휘발성 메모리를 포함할 수도 있고, 자기 테이프, 광학 디스크, 자기 디스크와 같은 저장 매 체를 포함할 수도 있다. 스토리지에 저장된 프로그램은 프로세서에 의해서 실행되기 이전에 메모리로 로딩될 수 있다. 스토리지는 프로그램 언어로 작성된 파일을 저장할 수 있고, 파일로부터 컴파일러 등에 의해서 생 성된 프로그램은 메모리로 로딩될 수 있다. 스토리지는 프로세서에 의해서 처리될 데이터 및/또는 프로세서에 의해서 처리된 데이터를 저장할 수 있다. 일 예로, 스토리지는 확률 테이블을 저장하고 있을 수 있다. 입출력 인터페이스는 키보드, 마우스 등과 같은 입력 장치를 포함할 수 있고, 디스플레이 장치, 프린터 등과 같은 출력 장치를 포함할 수 있다. 사용자는 입출력 인터페이스를 통해 프로세서에 의한 프로 그램의 실행을 트리거하고/거나 프로세서의 처리 결과를 확인할 수 있다. 통신 인터페이스는 외부 네트워크에 대한 액세스를 제공할 수 있다. 예를 들면, 컴퓨팅 장치는 통신 인터페이스를 통해 다른 장치들(예컨대, 카메라)과 통신할 수 있다. 본 발명에 따른 장치 또는 방법의 각 구성요소는 하드웨어 또는 소프트웨어로 구현되거나, 하드웨어 및 소프트 웨어의 결합으로 구현될 수 있다. 또한, 각 구성요소의 기능이 소프트웨어로 구현되고 마이크로프로세서가 각 구성요소에 대응하는 소프트웨어의 기능을 실행하도록 구현될 수도 있다. 본 명세서에 설명되는 시스템들 및 기법들의 다양한 구현예들은, 디지털 전자 회로, 집적회로, FPGA(field programmable gate array), ASIC(application specific integrated circuit), 컴퓨터 하드웨어, 펌웨어, 소프 트웨어, 및/또는 이들의 조합으로 실현될 수 있다. 이러한 다양한 구현예들은 프로그래밍가능 시스템 상에서 실 행 가능한 하나 이상의 컴퓨터 프로그램들로 구현되는 것을 포함할 수 있다. 프로그래밍가능 시스템은, 저장 시 스템, 적어도 하나의 입력 디바이스, 그리고 적어도 하나의 출력 디바이스로부터 데이터 및 명령들을 수신하고 이들에게 데이터 및 명령들을 전송하도록 결합되는 적어도 하나의 프로그래밍가능 프로세서(이것은 특수 목적 프로세서일 수 있거나 혹은 범용 프로세서일 수 있음)를 포함한다. 컴퓨터 프로그램들(이것은 또한 프로그램들, 소프트웨어, 소프트웨어 애플리케이션들 혹은 코드로서 알려져 있음)은 프로그래밍가능 프로세서에 대한 명령어 들을 포함하며 \"컴퓨터가 읽을 수 있는 기록매체\"에 저장된다. 컴퓨터가 읽을 수 있는 기록매체는, 컴퓨터 시스템에 의하여 읽혀질 수 있는 데이터가 저장되는 모든 종류의 기 록장치를 포함한다. 이러한 컴퓨터가 읽을 수 있는 기록매체는 ROM, CD-ROM, 자기 테이프, 플로피디스크, 메모 리 카드, 하드 디스크, 광자기 디스크, 스토리지 디바이스 등의 비휘발성(non-volatile) 또는 비일시적인(non- transitory) 매체일 수 있으며, 또한 데이터 전송 매체(data transmission medium)와 같은 일시적인 (transitory) 매체를 더 포함할 수도 있다. 또한, 컴퓨터가 읽을 수 있는 기록매체는 네트워크로 연결된 컴퓨터 시스템에 분산되어, 분산방식으로 컴퓨터가 읽을 수 있는 코드가 저장되고 실행될 수도 있다. 본 명세서의 흐름도/타이밍도에서는 각 과정들을 순차적으로 실행하는 것으로 기재하고 있으나, 이는 본 개시의 일 실시예의 기술 사상을 예시적으로 설명한 것에 불과한 것이다. 다시 말해, 본 개시의 일 실시예가 속하는 기 술 분야에서 통상의 지식을 가진 자라면 본 개시의 일 실시예의 본질적인 특성에서 벗어나지 않는 범위에서 흐 름도/타이밍도에 기재된 순서를 변경하여 실행하거나 각 과정들 중 하나 이상의 과정을 병렬적으로 실행하는 것으로 다양하게 수정 및 변형하여 적용 가능할 것이므로, 흐름도/타이밍도는 시계열적인 순서로 한정되는 것은 아니다. 이상의 설명은 본 실시예의 기술 사상을 예시적으로 설명한 것에 불과한 것으로서, 본 실시예가 속하는 기술 분 야에서 통상의 지식을 가진 자라면 본 실시예의 본질적인 특성에서 벗어나지 않는 범위에서 다양한 수정 및 변 형이 가능할 것이다. 따라서, 본 실시예들은 본 실시예의 기술 사상을 한정하기 위한 것이 아니라 설명하기 위 한 것이고, 이러한 실시예에 의하여 본 실시예의 기술 사상의 범위가 한정되는 것은 아니다. 본 실시예의 보호 범위는 아래의 청구범위에 의하여 해석되어야 하며, 그와 동등한 범위 내에 있는 모든 기술 사상은 본 실시예의권리범위에 포함되는 것으로 해석되어야 할 것이다."}
{"patent_id": "10-2023-0122926", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 개시가 적용될 수 있는 예시적인 시스템을 개략적으로 나타낸 블록구성도이다. 도 2는 본 개시의 일 실시예에 따른 카메라의 설치 환경을 예시적으로 나타낸 도면이다. 도 3은 본 개시의 일 실시예에 따른 카메라에 의해 촬영된 영상을 예시적으로 나타낸 도면이다. 도 4a 및 도 4b는 본 개시의 일 실시예에 따른 키포인트들의 다양한 예를 보여주는 도면이다. 도 5는 본 개시의 일 실시예에 따른 갇힘 인식모듈을 개략적으로 나타낸 블록구성도이다. 도 6은 본 개시의 일 실시예에 따라 객체의 이동거리를 산출하는 동작을 설명하기 위해 참조되는 예시도이다. 도 7은 본 개시의 일 실시예에 따라 팔을 교차하는 제스처를 인식하기 위한 조건을 설명하기 위해 참조되는 예 시도이다. 도 8은 본 개시의 일 실시예에 따라 손을 흔드는 제스처를 인식하기 위한 조건을 설명하기 위해 참조되는 예시 도이다. 도 9a 및 도 9b은 본 개시의 일 실시예에 따라 구조요청 발생 여부를 판정하기 위한 기준을 설명하기 위해 참조 되는 예시도이다. 도 10은 본 개시의 일 실시예에 따른 객체가 갇혀있는 상황을 인식하는 방법을 나타내는 흐름도이다. 도 11은 본 개시의 일 실시예에 따른 제스처 인식방법을 나타내는 흐름도이다. 도 12는 본 개시에서 설명된 장치 및 방법들을 구현하기 위해 사용될 수 있는 예시적인 컴퓨팅 장치를 개략적으 로 나타낸 블록구성도이다."}
