{"patent_id": "10-2022-0031444", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0134307", "출원번호": "10-2022-0031444", "발명의 명칭": "심층 신경망 기반 분할 학습을 위한 모델 재분할 방법 및 장치", "출원인": "한국전자통신연구원", "발명자": "이창식"}}
{"patent_id": "10-2022-0031444", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "심층신경망 기반 분할 학습을 위한 모델 재분할 방법에서, 소정 주기마다, 네트워크 품질 상태와 컴퓨팅 자원 사용 현황, 배터리 소모량에 대한 정보를 모델 분할기에게전달하는 단계;학습 단말의 상태 정보를 수신하는 단계;상기 학습 단말의 상태 정보를 기초로 상기 모델 재분할이 필요한 경우, 학습 중지와 함께 현재까지 학습된 모델의 가중치 값을 요청하는 단계;모델 분할기로부터 학습 중지 및 모델의 가중치 값에 대한 요청을 수신하는 단계;학습 과정을 중지하고, 현재까지 학습된 모델의 가중치 값을 모델 분할기로 전달하고 모델 가중치 값을 수신하고 이를 취합하는 단계;분할 정책에 따라 모델을 재분할하고, 분할된 모델의 가중치를 현재 취합된 가중치 값으로 초기화하고 분할된각 모델을 모델 학습기와 학습 단말로 전달하고, 학습 재시작을 요청하는 단계를 포함하되, 상기 절차를 일정 주기마다 반복하는, 분할 학습을 위한 모델 재분할 방법"}
{"patent_id": "10-2022-0031444", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 개시는 심층신경망 기반 분할 학습을 위한 모델 재분할 방법에 관한 것으로, 소정 주기마다, 네트워크 품질 상태와 컴퓨팅 자원 사용 현황, 배터리 소모량에 대한 정보를 모델 분할기에게 전달하고, 학습 단말의 상태 정보 를 수신하고, 상기 학습 단말의 상태 정보를 기초로 상기 모델 재분할이 필요한 경우, 학습 중지와 함께 현재까 지 학습된 모델의 가중치 값을 요청하고, 모델 분할기로부터 학습 중지 및 모델의 가중치 값에 대한 요청을 수신 하고, 학습 과정을 중지하고, 현재까지 학습된 모델의 가중치 값을 모델 분할기로 전달하고 모델 가중치 값을 수 신하고 이를 취합하고, 분할 정책에 따라 모델을 재분할하고, 분할된 모델의 가중치를 현재 취합된 가중치 값으 로 초기화하고 분할된 각 모델을 모델 학습기와 학습 단말로 전달하고, 학습 재시작을 요청하되, 상기 절차를 일 정 주기마다 반복하는 것을 그 요지로 한다."}
{"patent_id": "10-2022-0031444", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 모델 재분할 방법 및 장치에 대한 것으로서, 구체적으로, 심층 신경망 기반 분할 학습을 위한 모델 재분할 방법 및 장치에 대한 기술이다."}
{"patent_id": "10-2022-0031444", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "기존의 심층신경망 모델 학습 구조에서는, 네트워크 상에 흩어져 있는 여러 단말의 데이터를 중앙의 클라우드 서버로 전달한 뒤 클라우드 서버에서 수집한 방대한 양의 데이터를 기반으로 모델을 학습하는 방식이었다. 하지 만, 방대한 양의 데이터를 클라우드 서버로 전달하는 과정에서 발생하는 네트워크 부하와 데이터의 프라이버시 및 데이터 보안에 대한 문제가 제기됨에 따라, 클라우드 서버와 단말 간에 연동하여 학습하는 연합 학습 방식에 대한 활용도가 증가하고 있다. 연합 학습은 단말에서 발생하는 데이터를 클라우드 서버로 전송하는 대신에, 단 말이 자체적으로 모델을 학습하고 학습된 모델의 가중치를 일정 주기마다 서버로 전달하는 방식이다. 각 단말로 부터 모델의 가중치를 전달받은 서버는 모델 가중치를 취합하여 하나의 글로벌 모델을 생성하고 해당 모델을 단 말로 전달한다. 취합된 글로벌 모델을 전달받은 단말은 이어서 다음 데이터 샘플에 대한 학습을 진행하게 된다. 연합 학습은 학습 데이터를 주고받는 대신 모델의 가중치를 주고받는 구조이기 때문에, 학습에 사용되는 모델의 크기와 모델을 구성하는 파라미터 개수가 커짐에 따라 네트워크에 많은 부하가 걸리게 되고 이는 학습 속도 저 하의 주요 원인이 되기도 한다. 특히, 인공지능 모델을 적용하는 여러 어플리케이션에서 모델의 정확도에 대한 요구사항이 높아짐에 따라, 모델의 구조가 더욱 복잡해지고 모델 파라미터의 개수도 점점 늘어나고 있는 추세이 다. 이에 따라 연합 학습 과정의 최적화를 위한 다양한 방안들이 제시되고 있다. 특히, 클라우드 서버와 달리 단말 에 인접한 엣지 서버를 활용으로써, 엣지 서버와 학습 단말 간에 연합 학습을 통해 네트워크의 부하를 줄이고 학습 속도를 향상시키는 방안이 제시되고 있다. 이 외에도 연합 학습에 참여하는 여러 단말 중 최적의 단말을선택하는 방법, 단말에서 학습된 모델의 가중치 값을 서버와 교환하는 주기에 대한 최적화, 모델의 가중치 값을 압축하는 방법 등을 통해 학습 속도를 향상시키기 위한 연구가 진행되고 있다. 하지만, 학습 단말은 메모리와 컴퓨팅 자원(CPU, GPU)이 엣지 서버에 비해 상대적으로 부족할 뿐만 아니라 배터리 소모에 대한 많은 제약을 가 지고 있다. 특히, 심층 신경망 모델의 크기가 더욱 커지고 단말에서 수용해야 하는 모델의 개수가 점차 늘어나 는 경우에는 이러한 제약사항은 실질적인 문제점으로 작용할 수 있다. 이러한 문제는 엣지 서버와 학습 단말 간에 모델을 분할하여 학습하는 분할 학습 (split learning)을 통해 완화 될 수 있다. 분할 학습은 심층 신경망을 레이어 단위로 분할하여 학습하는 방법으로써, 입력 레이어에서 분할 레이어까지 연산은 단말에서 진행하고, 분할 레이어부터 출력 레이어까지의 연산을 엣지 서버에서 진행하는 방 식이다. 일반적으로 하나의 장비에서 전체 모델을 학습하는 것과 달리, 분할된 모델을 학습 단말과 엣지 서버가 각각 가지고 있는 구조이기 때문에 학습을 위해 필요한 정보를 주고받는 과정이 필요하다. 상기 언급한 연합 학습과 분할 학습의 차이는 다음과 같다. 연합 학습의 경우에는 학습 단말에서 일정 횟수동안 학습 과정을 거치고 일정 주기마다 엣지 서버로 학습된 모델 가중치를 전달하기 때문에, 대량의 데이터가 간헐 적으로 발생하는 특성을 지닌다. 반면에, 분할 학습의 경우에는 한 번에 보내는 데이터의 양은 비교적 적지만 매 반복 마다 단말과 엣지 서버 간에 계산된 결과를 주고받아야 하는 특성을 가진다. 특히, 분할 학습의 경우 분할 레이어의 위치에 따라서 전체 학습 속도가 크게 영향을 받을 수 있으며, 이는 다음과 같은 심층신경망의 특성에 기인한다. 심층 신경망을 구성하는 각 레이어는 연산에 소요되는 시간과 연산된 출력 데이터의 크기 측면에서 서로 다른 특성을 가진다. 예를 들어, 일반적으로 많이 사용되는 Convolutional Neural Networks (CNN)의 경우, convolution 연산을 하는 레이어는 연산 속도는 빠르지만 출력 데이터의 크기가 매우 큰 특징을 가진다. 반면, 레이어의 모든 뉴런이 이웃 레이어의 모든 뉴런과 연결되어 있는 완전 연결된 레이어는 연산 속도는 느리지만 출력 데이터의 크기가 매우 작은 특징을 가진다. 이처럼 각 레이어마다 서로 다른 연산 특성을 가지기 때문에, 모델을 분할하는 레이어의 위치에 따라서 모델의 학습 속도 측면에서 많은 차이가 날 수 있다. 예를 들어, 출력 데이터의 크기가 매우 큰 레이어가 분할 레이어 로 결정되어 분할 학습이 진행되는 과정에서, 학습 단말과 엣지 서버 간 네트워크 상태가 지속적으로 나빠질 경 우 데이터를 주고받는 데 소요되는 시간이 길어지기 때문에 전체 학습 속도가 현저하게 낮아질 수 있다. 또한, 단말의 컴퓨팅 리소스와 배터리 소모량이 부족한 상황에서 단말에서 많은 연산을 수행하도록 모델이 분할되어 있다면, 단말의 연산 속도 저하로 인해 전체 학습 속도에 영향을 끼칠 수 있다. 그런데, 종래 기술의 경우, 학습 시작되기 전에 임의로 분할 레이어가 결정되며, 분할된 각 모델은 엣지 서버와 학습 단말로 전달된 후 학습이 완료될 때까지 고정되는 방식이다. 이러한 구조에서는 네트워크 상태, 단말의 컴 퓨팅 리소스, 배터리 소모량에 따른 고려가 이루어 지지 않기 때문에 최적화된 분할 학습이 이루어지기 어려운 문제점이 있었다."}
{"patent_id": "10-2022-0031444", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 개시의 목적은 네트워크 상태와 단말의 컴퓨팅 리소스, 배터리 소모량에 따라 학습 과정에서 동적으로 심층 신경망 분할을 재설정함으로써 학습 시간을 최소화하는 모델 재분할 방법 및 장치를 제공하는 것을 목적으로 한 다. 본 개시의 목적은 분할 학습의 네트워크 환경과 학습 단말의 상태 변화에 따라서 심층 신경망 모델 재분할을 동 적으로 실시하여, 불안정한 네트워크 환경과 학습 단말의 자원 상태에서도 학습 속도 면에서 향상된 성능을 달 성하는 모델 재분할 방법 및 장치를 제공하는 것을 목적으로 한다. 본 개시의 다른 목적 및 장점들은 하기의 설명에 의해서 이해될 수 있으며, 본 개시의 실시예에 의해 보다 분명 하게 알게 될 것이다. 또한, 본 개시의 목적 및 장점들은 특허청구범위에 나타낸 수단 및 그 조합에 의해 실현 될 수 있음을 쉽게 알 수 있을 것이다."}
{"patent_id": "10-2022-0031444", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 개시의 일 실시예에 따른, 심층신경망 기반 분할 학습을 위한 모델 재분할 방법은, 소정 주기마다, 네트워크 품질 상태와 컴퓨팅 자원 사용 현황, 배터리 소모량에 대한 정보를 모델 분할기에게 전달하는 단계; 학습 단말 의 상태 정보를 수신하는 단계; 상기 학습 단말의 상태 정보를 기초로 상기 모델 재분할이 필요한 경우, 학습 중지와 함께 현재까지 학습된 모델의 가중치 값을 요청하는 단계; 모델 분할기로부터 학습 중지 및 모델의 가중 치 값에 대한 요청을 수신하는 단계; 학습 과정을 중지하고, 현재까지 학습된 모델의 가중치 값을 모델 분할기 로 전달하고 모델 가중치 값을 수신하고 이를 취합하는 단계; 분할 정책에 따라 모델을 재분할하고, 분할된 모 델의 가중치를 현재 취합된 가중치 값으로 초기화하고 분할된 각 모델을 모델 학습기와 학습 단말로 전달하고, 학습 재시작을 요청하는 단계를 포함하되, 상기 절차를 일정 주기마다 반복한다."}
{"patent_id": "10-2022-0031444", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 개시의 일 실시예에 따르면, 고정된 분할 모델을 사용하여 분할 학습을 진행하는 기존의 방법과 비교해서 학 습 단말과 서버 간 네트워크 상태와 학습 단말의 컴퓨팅 자원, 배터리 소모량 등의 상태 정보를 이용하여 동적 으로 모델의 재분할을 실행함으로써, 더욱 빠른 속도로 심층 신경망 모델을 학습할 수 있는 장점이 있다. 본 개시의 일 실시 예에 따르면, 현재 학습 중인 모델 가중치 값을 계속해서 전달받을 필요 없이 모델의 재분할 이 필요한 시점에만 전달받기 때문에, 불필요한 통신 비용을 줄이고 분할 학습 과정에 대한 영향을 최소화할 수 있는 효과가 있다. 본 개시에서 얻을 수 있는 효과는 이상에서 언급한 효과들로 제한되지 않으며, 언급하지 않은 또 다른 효과들은"}
{"patent_id": "10-2022-0031444", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 2, "content": "아래의 기재로부터 본 개시가 속하는 기술분야에서 통상의 지식을 가진 자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2022-0031444", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하에서는 첨부한 도면을 참고로 하여 본 개시의 실시 예에 대하여 본 개시가 속하는 기술 분야에서 통상의 지 식을 가진 자가 용이하게 실시할 수 있도록 상세히 설명한다. 그러나, 본 개시는 여러 가지 상이한 형태로 구현 될 수 있으며 여기에서 설명하는 실시 예에 한정되지 않는다. 본 개시의 실시 예를 설명함에 있어서 공지 구성 또는 기능에 대한 구체적인 설명이 본 개시의 요지를 흐릴 수 있다고 판단되는 경우에는 그에 대한 상세한 설명은 생략한다. 그리고, 도면에서 본 개시에 대한 설명과 관계없 는 부분은 생략하였으며, 유사한 부분에 대해서는 유사한 도면 부호를 붙였다. 본 개시에 있어서, 서로 구별되는 구성요소들은 각각의 특징을 명확하게 설명하기 위함이며, 구성요소들이 반드 시 분리되는 것을 의미하지는 않는다. 즉, 복수의 구성요소가 통합되어 하나의 하드웨어 또는 소프트웨어 단위 로 이루어질 수도 있고, 하나의 구성요소가 분산되어 복수의 하드웨어 또는 소프트웨어 단위로 이루어질 수도 있다. 따라서, 별도로 언급하지 않더라도 이와 같이 통합된 또는 분산된 실시 예도 본 개시의 범위에 포함된다. 본 개시에 있어서, 다양한 실시 예에서 설명하는 구성요소들이 반드시 필수적인 구성요소들을 의미하는 것은 아 니며, 일부는 선택적인 구성요소일 수 있다. 따라서, 일 실시 예에서 설명하는 구성요소들의 부분집합으로 구성 되는 실시 예도 본 개시의 범위에 포함된다. 또한, 다양한 실시 예에서 설명하는 구성요소들에 추가적으로 다른 구성요소를 포함하는 실시 예도 본 개시의 범위에 포함된다. 본 개시에 있어서, 제1, 제2 등의 용어는 하나의 구성요소를 다른 구성요소로부터 구별하는 목적으로만 사용되 며, 특별히 언급되지 않는 한 구성요소들 간의 순서 또는 중요도 등을 한정하지 않는다. 따라서, 본 개시의 범 위 내에서 일 실시 예에서의 제1 구성요소는 다른 실시 예에서 제2 구성요소라고 칭할 수도 있고, 마찬가지로 일 실시예에서의 제2 구성요소를 다른 실시예에서 제1 구성요소라고 칭할 수도 있다. 본 개시의 어떤 구성요소가 다른 구성요소에 “연결되어” 있다거나 “접속되어” 있다고 언급된 때에는, 그 다 른 구성요소에 직접적으로 연결되어 있거나 또는 접속되어 있을 수도 있으나, 중간에 다른 구성요소가 존재할 수도 있다고 이해되어야 할 것이다. 반면에, 어떤 구성 요소가 다른 구성 요소에 “직접 연결되어” 있다거나, “직접 접속되어” 있다고 언급된 때에는, 중간에 다른 구성 요소가 존재하지 않는 것으로 이해되어야 할 것이다. 또한, 본 개시에 있어서 본 개시의 실시예를 도시한 일 도면이 다른 도면과 양자 택일의 실시예에 해당하지 않 는 한 각 도면에 대한 설명은 서로 다른 도면에 적용될 수 있다. 이하, 도면을 참조하여 본 개시에 대하여 더욱 상세하게 설명할 것이다. 도 1은 본 개시의 일 실시예에 따른, 심층 신경망 분할 학습 시스템의 구성을 도시한 도면이다. 도 1을 참조하면, 심층 신경망 분할 학습 시스템은 엣지 서버, 학습 단말을 포함한다. 엣지 서버는 네트워크 상태, 컴퓨팅 리소스, 배터리 소모량에 대한 상태 정보를 학습 단말로부터 수 신한다. 엣지 서버는 모델 분할기, 모델 학습기를 포함한다. 모델 분할기는 심층 신경망을 분할한다. 모델 학습기는 분할된 모델 중 상위 모델을 가지고 학습을 담당한다. 학습 단말은 분할된 모델 중 하위 모델을 가지고 학습을 담당한다. 엣지 서버의 모델 학습기와 학습 단말은 서로 연동하여 학습에 필요한 계산 값을 주고받음으로 써 전체적인 모델의 학습을 수행한다. 전체 N개의 레이어로 구성된 오리지널 모델이 L번째 레이어를 기준으로 분할될 경우를 예로 들면, 구체적으로 분할 학습이 수행되는 과정은 다음과 같다. 입력 레이어부터 L번째 레이어로 구성된 하위 모델은 학습 단말로 전달되고, L번째 레이어부터 출력 레이 어로 구성된 상위 모델은 모델 학습기로 전달된다(S110). 학습 단말에서 가지고 있는 데이터 샘플들을 이용하여 하위 모델에 대한 연산을 수행한다. 학습 단말(20 0)에서 L번째 레이어까지 연산을 수행하고, 연산된 결과와 학습에 사용한 샘플의 라벨 값을 함께 엣지 서버 의 모델 학습기로 전달한다(S120). 학습 단말로부터 데이터를 수신한 모델 학습기에서는, 이어서 L번째 레이어부터 상위 모델에 대한 연 산을 수행한다(S130). 출력 레이어의 결과로 도출된 값과 실제 라벨 값의 차이에 따른 에러 값을 계산하고 이를 기반으로 모델의 가중 치를 업데이트하는 백 프로퍼게이션(back propagation) 과정을 수행한다(S140). 모델의 가중치를 업데이트 하는 과정은, 각 가중치가 에러에 어느 정도 영향을 끼쳤는지 편미분 값을 계산하여 업데이트 되는 것으로써, 모델 학습기에서 L번째 레이어와 (L+1)번째 레이어 사이의 가중치까지 업데이트 를 한 이후, 학습 단말에게 가중치 업데이트에 필요한 편미분 값을 전달한다(S150). 편미분 값을 전달받은 학습 단말에서는 L번째 레이어와 (L-1)번째 레이어 사이의 가중치를 업데이트 하고, 입력 레이어까지 back propagation 과정을 이어가면서 모델의 가중치를 업데이트 한다(S160). 학습 단말에서 입력 레이어까지의 가중치 업데이트가 끝나면 한번의 학습 반복이 끝나게 된다. 해당 학습 과정은 반복 횟수 또는 학습 정확도가 일정 값에 도달할 때까지 반복된다(S170). 학습 과정과는 별개로, 학습 단말은 현재 네트워크 품질 정보, CPU/GPU 등의 컴퓨팅 자원 사용 상황, 배터 리 소모량과 같은 상태 정보를 일정 주기마다 모델 분할기로 전달한다. 해당 정보는 모델 분할기에서 모델 재분할에 대한 필요성을 판단하기 위해 사용한다. 도 2는 본 개시의 일 실시예에 따른 심층 신경망 재분할 시스템 및 방법을 도시한 도면이다. 도 2를 참조하면, 심층 신경망 재분할 시스템은 엣지 서버, 학습 단말을 포함한다. 엣지 서버의 모델 분할기는 분할 정책부, 학습 제어부를 포함한다. 분할 정책부는 학습 단말의 네트워크 상태, 컴퓨팅 자원, 배터리 소모량 등의 정보를 바탕으로 새로운 모 델 분할을 결정한다. 분할 정책부의 경우, 다양한 형태의 분할 정책이 사전에 정의되어 있을 수 있다. 예를 들어, 학습 단말의 컴퓨팅 자원 또는 배터리 잔량이 일정 값 이하이면, 분할 정책부에서 모델의 재분할이 필요하다고 판단하여 학습 단말의 연산량과 배터리 소모를 줄일 수 있는 새로운 분할 레이어를 결정할 수 있다. 학습 단말과 엣지 서버 간 네트워크의 상태를 예측하여 네트워크 상태가 악화될 가능성이 높을 경우 분할 정책부에서 모델의 재분할이 필요하다고 판단하여 출력 데이터의 크기가 작은 레이어를 새로운 분할 레이어로 결정할 수 있다. 학습 제어부는 학습 단말로부터 상태 정보를 수신하는 기능, 학습 단말과 모델 학습기에게 학습 중지 및 현재까지 학습된 모델의 가중치 값을 요청하는 기능, 학습 단말과 모델 학습기로부터 가중치 값을 수신하고 이를 취합하는 기능, 분할된 모델을 학습 단말과 모델 학습기에게 전달하고 학 습 재시작을 요청하는 기능을 제공한다. 학습 제어부와 분할 정책부는 모델 분할기 내에서 서로 연동하여 동작한다. 분할 정책부는 학습 제어부를 통하여 학습 단말로부터 상태 정보를 전달받고 모델 재분할 여부 를 판단한다. 분할 정책부에서 모델 재분할이 필요하다고 판단될 경우, 학습 제어부를 통하여 학습 단말과 모델 학습기에게 학습 중지 및 현재까지 학습된 모델의 가중치 값을 요청한다. 학습 제어부에서 취합된 모델 가중치 값은, 분할 정책부에서 재분할 완료된 모델의 가중치 값을 초기 화하는데 사용되며, 각 모델은 학습 제어부를 통하여 각각 모델 분할기와 학습 단말로 전달된다. 도 3은 본 개시의 일 실시 예에 따른, 심층 신경망 모델 재분할 방법의 순서도를 도시한 도면이다. 학습 단말과 엣지 서버의 모델 학습기는 각각의 분할된 모델을 기반으로 분할 학습을 진행한다(S310). 분할 학습이 진행되는 과정에서 학습 단말은 현재 네트워크 품질 상태를 비롯하여 컴퓨팅 자원 사용 현황, 배터 리 소모량과 같은 상태 정보를 주기적으로 모델 분할기에게 전달한다(S315). 단말의 상태 정보는 모델 분할기의 학습 제어부를 통해 수신되며, 이는 분할 정책부로 전달된다(S320). 분할 정책부는 해당 정보를 바탕으로 하여, 정의되어 있는 분할 정책을 통해 모델 재분할이 필요한지 여부에 대 해서 판단한다(S325). 모델의 재분할이 필요하면(S325), 학습 제어부는 모델 학습기와 학습 단말에게 학습 중지와 함께 현재까지 학습 된 모델의 가중치 값을 요청한다(S330). 모델 분할기로부터 해당 요청을 전달받은 모델 학습기와 학습 단말은 학습 과정을 중지하고, 현재까지 학습된 모델의 가중치 값을 모델 분할기로 전달한다(S335). 학습 제어부는 모델 학습기와 학습 단말로부터 모델 가중치 값을 수신하고 이를 취합한다(S340). 분할 정책부는 정의되어 있는 분할 정책에 따라 모델을 재분할한다(S345). 분할된 모델의 가중치는 현재 취합된 가중치 값으로 초기화된다(S350). 학습 제어부는 분할된 각 모델을 모델 학습기와 학습 단말로 전달하고, 학습 재시작을 요청한다(S355). 새롭게 분할된 모델을 수신한 모델 학습기와 학습 단말은 학습 과정을 다시 시작하고, 이후 모델 분할기, 모델 학습기, 그리고 학습 단말은 상기 언급한 (학습 단말이 자신의 상태 정보를 모델 분할기에게 전달하는 단계부터) 과정을 반복한다. 도 4는 본 개시의 일 실시 예에 따른, 심층 신경망 모델 장치를 도시한 도면이다. 도 4를 참조하면, 심층 신경망 모델 장치는 디바이스를 포함한다. 디바이스는 메모리, 프로 세서, 송수신부 및 주변 장치를 포함할 수 있다. 또한, 일 예로, 디바이스는 다른 구 성을 더 포함할 수 있으며, 상술한 실시 예로 한정되지 않는다. 이때, 일 예로, 디바이스는 상술한 심층 신경망 모델 장치일 수 있다. 보다 상세하게는, 도 4의 디바이스는 심층 신경망 모델 장치, 서버 등과 같은 예시적인 하드웨어/소프트 웨어 아키텍처일 수 있다. 이때, 일 예로, 메모리는 비이동식 메모리 또는 이동식 메모리일 수 있다. 또 한, 일 예로, 주변 장치는 디스플레이, GPS 또는 다른 주변기기들을 포함할 수 있으며, 상술한 실시예로 한정되지 않는다. 또한, 일 예로, 상술한 디바이스는 상기 송수신부와 같이 통신 회로를 포함할 수 있으며, 이에 기 초하여 외부 디바이스와 통신을 수행할 수 있다. 또한, 일 예로, 프로세서는 범용 프로세서, DSP(digital signal processor), DSP 코어, 제어기, 마이크 로 제어기, ASIC들(Application Specific Integrated Circuits), FPGA(Field Programmable Gate Array) 회로 들, 임의의 다른 유형의 IC(integrated circuit) 및 상태 머신과 관련되는 하나 이상의 마이크로프로세서 중 적 어도 하나 이상일 수 있다. 즉, 상술한 디바이스를 제어하기 위한 제어 역할을 수행하는 하드웨어적/소프 트웨어적 구성일 수 있다. 이때, 프로세서는 심층 신경망 모델 장치의 다양한 필수 기능들을 수행하기 위해 메모리에 저장된 컴퓨터 실행가능한 명령어들을 실행할 수 있다. 일 예로, 프로세서는 신호 코딩, 데이터 처리, 전력 제어, 입출력 처리 및 통신 동작 중 적어도 어느 하나를 제어할 수 있다. 또한, 프로세서는 물리 계층, MAC 계층, 어플리케이션 계층들을 제어할 수 있다. 또한, 일 예로, 프로세서는 액세스 계층 및/또는 어플 리케이션 계층 등에서 인증 및 보안 절차를 수행할 수 있으며, 상술한 실시 예로 한정되지 않는다. 일 예로, 프로세서는 송수신부를 통해 다른 장치들과 통신을 수행할 수 있다. 일 예로, 프로세서 는 컴퓨터 실행가능한 명령어들의 실행을 통해 노드가 네트워크를 통해 다른 노드들과 통신을 수행하게 제어할 수 있다. 즉, 본 발명에서 수행되는 통신이 제어될 수 있다. 일 예로, 송수신부는 안테나를 통해 RF 신호를 전송할 수 있으며, 다양한 통신망에 기초하여 신호를 전송할 수 있다. 또한, 일 예로, 안테나 기술로서 MIMO 기술, 빔포밍 등이 적용될 수 있으며, 상술한 실시예로 한정되지 않는다. 또한, 송수신부를 통해 송수신한 신호는 변조 및 복조되어 프로세서에 의해 제어될 수 있으며, 상 술한 실시 예로 한정되지 않는다. 본 개시의 다양한 실시 예는 모든 가능한 조합을 나열한 것이 아니고 본 개시의 대표적인 양상을 설명하기 위한 것이며, 다양한 실시 예에서 설명하는 사항들은 독립적으로 적용되거나 또는 둘 이상의 조합으로 적용될 수도 있다. 또한, 본 개시의 다양한 실시 예는 하드웨어, 펌웨어(firmware), 소프트웨어, 또는 그들의 결합 등에 의해 구현 될 수 있다. 하드웨어에 의한 구현의 경우, 하나 또는 그 이상의 ASICs(Application Specific Integrated Circuits), DSPs(Digital Signal Processors), DSPDs(Digital Signal Processing Devices), PLDs(Programmable Logic Devices), FPGAs(Field Programmable Gate Arrays), 범용 프로세서(general processor), 컨트롤러, 마이크로 컨트롤러, 마이크로 프로세서 등에 의해 구현될 수 있다. 예를 들어, 종단 혹 은 에지에서 사용될 수 있는 비 일시적 컴퓨터 판독가능한 매체에 저장된 프로그램의 형식이나, 에지 혹은 클라 우드에서 사용될 수 있는 비 일시적 컴퓨터 판독 가능한 매체에 저장된 프로그램의 형식으로도 구현될 수 있음 은 자명하다. 또한, 다양한 하드웨어 및 소프트웨어의 결합으로도 구현될 수 있다. 본 개시의 범위는 다양한 실시 예의 방법에 따른 동작이 장치 또는 컴퓨터 상에서 실행되도록 하는 소프트웨어 또는 머신-실행 가능한 명령들(예를 들어, 운영체제, 애플리케이션, 펌웨어(firmware), 프로그램 등), 및 이러 한 소프트웨어 또는 명령 등이 저장되어 장치 또는 컴퓨터 상에서 실행 가능한 비-일시적 컴퓨터-판독가능 매체 (non-transitory computer-readable medium)를 포함한다."}
{"patent_id": "10-2022-0031444", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "이상에서 설명한 본 개시는, 본 개시가 속하는 기술분야에서 통상의 지식을 가진 자에게 있어 본 개시의 기술적 사상을 벗어나지 않는 범위 내에서 여러 가지 치환, 변형 및 변경이 가능하므로, 본 개시의 범위는 전술한 실시 예 및 첨부된 도면에 의해 한정되는 것이 아니다.도면 도면1 도면2 도면3 도면4"}
{"patent_id": "10-2022-0031444", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 개시의 일 실시 예에 따른, 심층 신경망 분할 학습 시스템의 구성을 도시한 도면이다. 도 2는 본 개시의 일 실시 예에 따른 심층 신경망 재분할 시스템 및 방법을 도시한 도면이다. 도 3은 본 개시의 일 실시 예에 따른, 심층 신경망 모델 재분할 방법의 순서도를 도시한 도면이다. 도 4는 본 개시의 일 실시 예에 따른, 심층 신경망 모델 장치를 도시한 도면이다."}
