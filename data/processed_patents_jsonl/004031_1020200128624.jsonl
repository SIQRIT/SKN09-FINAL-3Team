{"patent_id": "10-2020-0128624", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2022-0045695", "출원번호": "10-2020-0128624", "발명의 명칭": "위성영상자료와 인공지능기법을 이용한 엽면습윤기간 예측 방법", "출원인": "대한민국", "발명자": "신주영"}}
{"patent_id": "10-2020-0128624", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "위성영상자료 및 엽면습윤기간 관측자료를 수집하여 DB(Database)를 구축하는 제1단계(S10)와,상기 DB를 전처리하여 학습, 검증, 평가 자료를 각각 준비하는 제2단계(S20)와,상기 학습, 검증, 평가 자료와 인공지능모형을 이용하여 엽면습윤기간 예측모형을 구축하는 제3단계(S30)와,상기 엽면습윤기간 예측모형과 상기 위성영상자료를 이용하여 대상지역의 엽면습윤기간을 예측하는 제4단계(S40)를 포함하는 것을 특징으로 하는 위성영상자료와 인공지능기법을 이용한 엽면습윤기간 예측 방법."}
{"patent_id": "10-2020-0128624", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 제1단계(S10)는 해당 분석기간에 대한 상기 위성영상자료를 수집하여 상기 DB를 구축하는 단계(S11)와, 엽면습윤기간 관측장비가 설치되어 있는 지점에서 관측자료 및 관측장비의 정보를 수집하여 상기 DB를 구축하는단계(S12)를 포함하는 것을 특징으로 하는 위성영상자료와 인공지능기법을 이용한 엽면습윤기간 예측 방법."}
{"patent_id": "10-2020-0128624", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,상기 제2단계(S20)는 상기 DB에서 관측장비의 위치와 같은 위치의 위성영상픽셀을 추출하는 단계(S21)와, 상기위성영상픽셀과 엽면습윤기간 관측정보를 결합하는 단계(S22)와, 상기 결합된 자료로부터 학습, 검증, 평가 자료를 생성하는 단계(S23)를 포함하는 것을 특징으로 하는 위성영상자료와 인공지능기법을 이용한 엽면습윤기간예측 방법."}
{"patent_id": "10-2020-0128624", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서,상기 제3단계(S30)는 상기 학습 및 검증 자료를 이용하여 인공지능모형들의 초매개변수(hyperparameter)를 정하는 단계(S31)와, 상기 인공지능모형들의 입력변수(위성 영상 채널자료)를 결정하는 단계(S32)와, 상기 평가 자료를 이용하여 완성된 각 인공지능모형의 성능을 평가하는 단계(S33)와, 상기 평가를 기반으로 최종 엽면습윤기간 예측모형을 결정하는 단계(S34)를 포함하는 것을 특징으로 하는 위성영상자료와 인공지능기법을 이용한 엽면습윤기간 예측 방법."}
{"patent_id": "10-2020-0128624", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서,상기 제4단계(S40)는 상기 위성영상자료를 취득하는 단계(S41)와, 상기 위성영상자료 및 인공지능모형을 이용하여 대상지역의 엽면습윤기간 정보를 제공하는 단계(S42)를 포함하는 것을 특징으로 하는 위성영상자료와 인공지능기법을 이용한 엽면습윤기간 예측 방법."}
{"patent_id": "10-2020-0128624", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 위성영상자료와 인공지능 기법을 적용하여 엽면습윤기간 관측장비가 설치되어 있는 않는 위치에서의 엽면습윤기간 정보를 확보할 수 있고, 표준화 방안이 없어 발생하는 엽면습윤기간 관측자료의 비균질한 품질 문 제에 대하여 단일 모형을 넓은 지역에 적용함으로써 동질한 품질의 엽면습윤기간 정보를 얻을 수 있는 위성영상 자료와 인공지능기법을 이용한 엽면습윤기간 예측 방법에 관한 발명이다."}
{"patent_id": "10-2020-0128624", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 위성영상자료와 인공지능기법을 이용한 엽면습윤기간 예측 방법에 관한 것으로, 더욱 상세하게는 천 리안 정지궤도의 실시간 위성자료와 인공지능 기법을 이용하여 지상면에 존재하는 식물의 엽면에 습기가 존재하 는 시간을 예측하는 위성영상자료와 인공지능기법을 이용한 엽면습윤기간 예측 방법에 관한 것이다."}
{"patent_id": "10-2020-0128624", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "식물의 전염병은 농업 및 임업 생산량 증대에 악영향을 주는 주요 원인이 된다. 박테리아와 진균류에 의한 식물 전염병은 엽면습윤기간[식물의 잎에 존재하는 수분(엽면습윤)의 지속기간]과 특 정 기온에 따라 발병률이 변하는 것으로 알려져 있다. 농업 및 임업 생산량 증대를 위해서는 식물 전염병에 대한 적절한 예측기술이 개발될 필요가 있다. 식물 전염병에 큰 영향 요인인 기온은 세계기상기구에서 정해진 규칙에 따라서 다양한 장소에서 관측되고 있어, 기온자료에 대한 접근성이 높다. 또한, 높은 접근성으로 인하여 많은 연구가 진행되어 다른 기상요소들 보다 높 은 예측 정확도를 가진다. 하지만, 엽면습윤기간은 세계기상기구에서 지정한 정규 기상요소가 아니라 관측기기, 장비, 설치 위치와 같은 규칙이 정해져 있지 않다. 이런 이유로 많은 기관에서 다른 관측 방법을 사용하고 있어 자료들간의 동질성을 확 보하기가 어렵다. 또한, 정규 기상요소가 아니기 때문에 대부분의 기상관측소에서 엽면습윤기간을 관측하고 있 지 않다. 이런 이유로 엽면습윤기간 자료에 대한 접근성과 품질이 낮아져 식물의 전염병 연구 및 예측에 많은 문제점으로 여겨지고 있다. 이와 같이 위에서 언급된 문제점과 한계들을 극복하기 위하여 관측기기가 없는 위치에서도 동질한 품질을 갖는 엽면습윤기간 정보를 획득할 수 있는 방법의 개발이 요구되고 있는 현실이다. 선행기술문헌 특허문헌 (특허문헌 0001) 대한민국 등록특허공보 제1114513호"}
{"patent_id": "10-2020-0128624", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명의 목적은 정지궤도 위성영상을 이용한 옆면습윤기간을 예측하여 엽면습윤기간 관측장비가 설치되어 있 지 않는 지점에서도 엽면습윤기간 정보를 얻을 수 있는 위성영상자료와 인공지능기법을 이용한 엽면습윤기간 예 측 방법을 제공함에 있다. 본 발명의 목적은 위성영상과 단일화된 방법으로 넓은 지역의 동질한 품질의 엽면습윤기간 정보를 얻을 수 있는 위성영상자료와 인공지능기법을 이용한 엽면습윤기간 예측 방법을 제공함에 있다."}
{"patent_id": "10-2020-0128624", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기 목적을 달성하기 위한 본 발명에 따른 위성영상자료와 인공지능기법을 이용한 엽면습윤기간 예측 방법은, 위성영상자료 및 엽면습윤기간 관측자료를 수집하여 DB(Database)를 구축하는 제1단계와, 상기 DB를 전처리하여 학습, 검증, 평가 자료를 각각 준비하는 제2단계와, 상기 학습, 검증, 평가 자료와 인공지능모형을 이용하여 엽면습윤기간 예측모형을 구축하는 제3단계와, 상기 엽면습윤기간 예측모형과 상기 위성영상자료를 이용하여 대상지역의 엽면습윤기간을 예측하는 제4단계를 포함하는 것을 그 기술적 방법상의 기본 특징으로 한다."}
{"patent_id": "10-2020-0128624", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명은 위성영상자료와 인공지능 기법을 적용하여 엽면습윤기간 관측장비가 설치되어 있는 않는 위치에서의 엽면습윤기간 정보를 확보할 수 있는 효과가 있다. 본 발명은 관측 방법의 표준화된 방안이 없어 발생하는 엽면습윤기간 관측자료의 비균질한 품질 문제에 대하여 단일 모형을 넓은 지역에 적용함으로써 동질한 품질의 엽면습윤기간 정보를 얻을 수 있는 효과가 있다."}
{"patent_id": "10-2020-0128624", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명에 따른 위성영상자료와 인공지능기법을 이용한 엽면습윤기간 예측 방법의 바람직한 실시예를 도면을 참 조하여 설명하기로 하고, 그 실시예로는 다수 개가 존재할 수 있으며, 이러한 실시예를 통하여 본 고안의 목적, 특징 및 이점들을 더욱 잘 이해할 수 있게 된다. 도 1은 본 발명에 따른 위성영상자료와 인공지능기법을 이용한 엽면습윤기간 예측 방법을 나타내는 흐름도이다. 본 발명에 따른 위성영상자료와 인공지능기법을 이용한 엽면습윤기간 예측 방법은 도 1에 도시된 바와 같이 위 성영상자료 및 엽면습윤기간 관측자료를 수집하여 DB(Database)를 구축하는 제1단계(S10)와, 상기 DB를 전처리 하여 학습, 검증, 평가 자료를 각각 준비하는 제2단계(S20)와, 상기 학습, 검증, 평가 자료와 인공지능모형을 이용하여 엽면습윤기간 예측모형을 구축하는 제3단계(S30)와, 상기 엽면습윤기간 예측모형과 상기 위성영상자료 를 이용하여 대상지역의 엽면습윤기간을 예측하는 제4단계(S40)를 포함한다. 상기 제1단계(S10)는 해당 분석기간에 대한 위성영상자료를 수집하여 DB를 구축하는 단계(S11)와, 엽면습윤기간 관측장비가 설치되어 있는 지점에서 관측자료 및 관측장비의 정보를 수집하여 DB를 구축하는 단계(S12)를 포함 한다. 구체적으로, 상기 제1단계(S10)는 해당 분석기간에 대하여 위성영상자료를 수집하여 DB를 구축하는 단계(S11)로 대상지역의 정지궤도 위성 또는 공간 및 시간에 고해상도를 가지는 관측자료를 수집한다. 위성영상자료의 시간 해상도는 1시간 이하일 때만 엽면습윤기간 측정에 사용될 수 있고, 위성관측자료는 위성에 탑재되어 있는 분광카메라를 통하여 얻어진 위성영상자료이다. 이 위성영상자료는 수백 ㎚에서 수천 ㎚ 영역의 여러 협대역밴드로 구성된 채널별 영상자료로 물체에서 반사 또 는 방출시키는 복사휘도(radiance)를 관측한다. 보통 4㎛ 파장을 기준으로 그 미만은 단파채널 그 이상은 장파 채널로 구분하며, 이 채널자료 모두 사용될 수 있다. 그리고, 대상지역 근처에 설치되어 있는 엽면습윤기간 관측장비의 정보(위치정도, 장비의 형태 등)와 관측자료 를 수집하여 DB를 구축한다. 상기 제2단계(S20)는 DB에서 관측장비의 위치와 같은 위치의 위성영상픽셀을 추출하는 단계(S21)와, 위성영상픽 셀과 엽면습윤기간 관측정보를 결합하는 단계(S22)와, 이와 같이 결합된 자료로부터 학습, 검증, 평가 자료를 생성하는 단계(S23)를 포함한다. 인공지능기법을 이용하여 엽면습윤을 예측하는 모형을 구축하기 위해서는 인공지능기법 학습에 사용될 학습자료 와, 이 학습자료를 통해 만들어진 모형의 초매개변수를 최적화한 자료와, 입력변수 선택을 위한 검증자료와 최 종으로 구축된 모형의 성능을 평가하기 위한 평가자료가 필요하다. 위 세 자료를 만들기 위해서는 구축된 DB에서 관측장비의 위치정보를 이용하여 같은 위치의 위성영상픽셀을 추 출하여 입력자료 DB를 구축한다. 만들어진 입력자료 DB를 엽면습윤 관측자료 DB와 결합하여 최종 DB를 구축하고, 최종 DB에서 6(학습):2(검 증):2(평가)의 비율로 학습, 검증, 평가 자료로 나누어 놓는다. 상기 제3단계(S30)는 학습 및 검증 자료를 이용하여 인공지능모형들의 초매개변수(hyperparameter)를 정하는 단 계(S31)와, 인공지능모형들의 입력변수(위성 영상 채널자료)를 결정하는 단계(S32)와, 평가 자료를 이용하여 완 성된 각 인공지능모형의 성능을 평가하는 단계(S33)와, 이와 같은 평가를 기반으로 최종 엽면습윤기간 예측모형 을 결정하는 단계(S34)를 포함한다. 구축된 학습 및 검증 자료를 이용하여 다양한 인공지능 모형의 초매개변수를 최적화한다. 인공지능 모형의 종류로는 인공신경망(artificial neural network), 깊은신경망(deep neural network, DNN), 랜덤포레스트(random forest, RF), 그레디언트부스팅모형(gradient boosted model), 로지스틱 희귀분석 (logistic regression), 서포트벡터머신(support vector machine)과 같은 분류(classification) 모형을 사용할 수 있다. 분류기(classifier)로서 작동할 수 있는 모든 인공지능기법을 본 발명에서 이용할 수 있고, 인공지능기법에 따 라 다른 초매개변수를 가지기 때문에 최적화 방법으로는 다양한 방법론이 적용될 수 있다. 본 발명에서 인공지능 모형의 입력변수는 위성영상자료로서 분광카메라로 촬영된 다양한 밴드의 영상자료를 의 미한다. 즉, 위성영상자료의 어떤 밴드 자료를 사용하여 엽면습윤기간을 예측하는 가를 검증 자료를 이용하여 선택하게 된다. 엽면습윤은 일반적으로 밤과 일출시간에 존재하기 때문에 장파채널의 자료와 낮에 태양광에 민감한 단파채널이 엽면습윤을 표현하는 데 유리하다. 위성에 탑재된 분광카메라의 특성은 채널마다 다르기 때문에 모든 채널 자료를 입력자료로서의 적합성을 검증자 료로 검증하여 선택한다. 최적화된 매개변수와 입력변수 조합을 가지는 인공기법들의 엽면습윤의 예측 성능의 평가자료를 이용하여 평가 한다. 즉, 완성된 모든 인공지능 모형의 엽면습윤 예측 성능과 엽면습윤기간 예측 성능을 제곱근오차, 상대오차, 상관 계수, 정확도 등과 같은 평가지표를 이용하여 평가한다. 평가결과를 기반으로 최고의 성능을 보이는 인공지능 모형을 최종 엽면습윤기간 예측 모형을 결정한다. 상기 제4단계(S40)는 위성영상자료를 취득하는 단계(S41)와, 위성영상자료 및 인공지능모형을 이용하여 대상지 역의 엽면습윤기간 정보를 제공하는 단계(S42)를 포함한다. 즉, 실시간 위성영상자료를 취득하여 완성된 엽면습윤기간 예측 모형에 위성자료를 입력하여 위성영상이 커버하 는 지역의 엽면습윤기간 정보를 출력한다. 도 2는 본 발명에 따른 위성영상자료와 인공지능기법을 이용한 엽면습윤기간 예측 방법을 설명하기 위하여 천리 안 2호기의 영상자료와 랜덤포레스트(RF)와 깊은신경망(DNN)을 이용하여 개발한 엽면습윤기간 예측모형의 2020 년3월1일부터 동년3월4일까지의 예측 결과 예시도로서 위성영상자료와 인공지능 기법을 적용하여 엽면습윤기간 관측장비가 설치되어 있는 않는 위치에서의 엽면습윤기간 정보를 확보할 수 있고, 표준화 방안이 없어 발생하는 엽면습윤기간 관측자료의 비균질한 품질 문제에 대하여 단일 모형을 넓은 지역에 적용함으로써 동질한 품질의 엽면습윤기간 정보를 얻을 수 있는 모습을 보여주고 있다. 산업상 이용가능성 본 발명은 관측기기가 없는 위치에서도 동질한 품질을 갖는 엽면습윤기간을 예측할 수 있는 농업 및 임업 분야 관련의 산업에 이용 가능하다."}
{"patent_id": "10-2020-0128624", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명에 따른 위성영상자료와 인공지능기법을 이용한 엽면습윤기간 예측 방법을 나타내는 흐름도. 도 2는 본 발명에 따른 위성영상자료와 인공지능기법을 이용한 엽면습윤기간 예측 방법을 설명하기 위하여 천리 안 2호기의 영상자료와 랜덤포레스트(RF)와 깊은신경망(DNN)을 이용하여 개발한 엽면습윤기간 예측모형의 2020 년3월1일부터 동년3월4일까지의 예측 결과 예시도."}
