{"patent_id": "10-2019-0128476", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2021-0045119", "출원번호": "10-2019-0128476", "발명의 명칭": "로봇 및 상기 로봇의 위치 보정 방법", "출원인": "엘지전자 주식회사", "발명자": "이동학"}}
{"patent_id": "10-2019-0128476", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "실외에서 주행하는 로봇의 위치를 측정하는 위치 측정 센서;상기 로봇의 주변에 대한 영상을 획득하는 카메라;상기 실외에 존재하는 복수의 장소 각각의 위치 및 외관 특징을 포함하는 장소 정보를 저장하고, 하나 이상의명령어를 저장하는 메모리; 및상기 하나 이상의 명령을 실행함으로써 상기 측정된 위치를 보정하는 프로세서;를 포함하되, 상기 프로세서는, 상기 획득된 영상을 분석하여 상기 획득된 영상 내에 존재하는 M(1 이상의 정수)개의 제1 장소의 외관 특징을 추출하고, 상기 M개의 제1 장소의 외관 특징을 이용하여 상기 장소 정보 내에서 N(1 이상 M이하의 정수)개의 제2 장소의 위치를 선택하고, 상기 N개의 제2 장소의 위치에 기초하여 상기 측정된 로봇의 위치를 보정하는, 로봇."}
{"patent_id": "10-2019-0128476", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 프로세서는,상기 장소 정보에 포함된 복수의 장소 중 상기 측정된 로봇의 위치와 인접한 위치에 존재하는 하나 이상의 제2장소를 선택하고, 상기 하나 이상의 제2 장소의 외관 특징과 상기 M개의 제1 장소의 외관 특징을 비교하여 상기N개의 제2 장소를 선택하는, 로봇."}
{"patent_id": "10-2019-0128476", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서, 상기 프로세서는 인공 신경망 기반의 알고리즘 모델을 이용하여 상기 M개의 제1 장소의 외관 특징을 추출하되, 상기 알고리즘 모델은 입력 노드로 구성된 입력 레이어, 출력 노드로 구성된 출력 레이어 및 입력 레이어와 출력 레이어 사이에 배치되며, 은닉 노드로 구성된 하나 이상의 은닉 레이어를 포함하고, 학습을 통해 노드들을연결하는 에지의 가중치 및 노드들의 바이어스가 업데이트되는, 로봇."}
{"patent_id": "10-2019-0128476", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서, 사진으로 구성되는 제1 웹 지도에서 추출된 상기 실외의 장소의 외부 사진을 학습 데이터로 하여 상기 알고리즘모델을 학습하는 러닝 프로세서;를 더 포함하는, 로봇."}
{"patent_id": "10-2019-0128476", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제3항에 있어서, 상기 학습된 알고리즘 모델의 입력 레이어로 상기 획득된 영상이 입력되고, 상기 학습된 알고리즘 모델의 출력레이어로 상기 M개의 제1 장소의 외관 특징이 출력되는, 로봇.공개특허 10-2021-0045119-3-청구항 6 제1항에 있어서, 상기 외관 특징은 상기 장소와 인접하게 배치된 구조물 내에 표시된 상호 정보와 대응되는, 로봇."}
{"patent_id": "10-2019-0128476", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6항에 있어서, 상기 장소 정보는 실외에 존재하는 복수의 장소의 위치 및 상호 정보를 포함하는 제2 웹 지도를 이용하여 생성되는, 로봇."}
{"patent_id": "10-2019-0128476", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1항에 있어서, 상기 프로세서는,상기 획득된 영상을 이용하여 상기 로봇을 기준으로 한 N개의 제1 장소의 상대 위치를 산출하고, 상기 N개의 제1 장소의 상대 위치와 상기 N개의 제2 장소의 위치를 이용하여 상기 측정된 로봇의 위치를 보정하되, 상기 N개의 제1 장소는 상기 M개의 제1 장소 중 상기 N개의 제2 장소와 동일한 외관 특징을 가지는 장소인, 로봇."}
{"patent_id": "10-2019-0128476", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제6항에 있어서, 상기 획득된 영상과 대응되는 뎁스(depth) 데이터를 획득하는 뎁스 센서;를 더 포함하되,상기 외관 특징은 상기 장소와 인접하게 배치된 간판 구조물 내에 표시된 상호 정보와 대응되고, 상기 프로세서는, 상기 획득된 영상을 분석하여 상기 N개의 제1 장소의 간판 구조물의 중앙부를 검출하고, 상기 획득된 뎁스 데이터를 이용하여 상기 로봇을 기준으로 한 상기 N개의 제1 장소의 간판 구조물의 중앙부의상대 위치를 산출하되, 상기 제1 장소의 간판 구조물의 중앙부의 상대 위치와 상기 제1 장소의 상대 위치는 서로 대응되는, 로봇,"}
{"patent_id": "10-2019-0128476", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9항에 있어서, 상기 프로세서는 상기 N개의 제1 장소의 간판 구조물의 에지를 산출하고, 상기 N개의 제1 장소의 에지에 기초하여 상기 적어도일부의 제1 장소의 간판 구조물에 대한 소실점을 산출하고, 상기 검출된 소실점을 이용하여 상기 로봇을 기준으로 한 상기 N개의 제1 장소의 간판 구조물의 상대 각도를 산출하고, 공개특허 10-2021-0045119-4-상기 산출된 상대 각도는 상기 상대 위치를 산출하는데 이용되는, 로봇."}
{"patent_id": "10-2019-0128476", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제8항에 있어서, 상기 프로세서는 상기 N개의 보정 위치를 산출하고, 상기 N개의 보정 위치를 가중합하여 상기 측정된 로봇의 위치를 보정하되, 상기 N개의 보정 위치 중 i번째 보정 위치는, 상기 N개의 제2 장소 중 i번째 제2 장소의 위치 및 상기 N개의 제1 장소 중 i번째 제1 장소를 기준으로 한 상기 로봇의 상대 위치에 기초하여 산출되며, 상기 i번째 제1 장소를 기준으로 한 상기 로봇의 상대 위치는 상기 i번째 제1 장소의 상대 위치를 이용하여 산출되는, 로봇."}
{"patent_id": "10-2019-0128476", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항에 있어서, 상기 i번째 보정 위치와 대응되는 가중치는 상기 i번째 제1 장소와 상기 로봇 간의 거리 및 상기 로봇에서 바라본 상기 i번째 제1 장소의 각도와 반비례하도록 설정되는, 로봇."}
{"patent_id": "10-2019-0128476", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제1항에 있어서, 상기 위치는 위도 및 경도에 의해 정의되고, 상기 위치 측정 센서는 GPS 센서 또는 GLONASS 센서와 대응되는, 로봇."}
{"patent_id": "10-2019-0128476", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "실외에서 주행하는 로봇의 위치를 측정하는 위치 측정 센서;상기 로봇의 주변에 대한 영상을 획득하는 카메라; 하나 이상의 명령어를 저장하는 메모리; 및상기 하나 이상의 명령을 실행함으로써 상기 측정된 위치를 보정하는 프로세서;를 포함하되, 상기 프로세서는, 상기 획득된 영상에 기초하여 상기 획득된 영상 내에 존재하는 제1 장소의 외관 특징을 추출하고, 상기 제1 장소의 외관 특징과 동일한 외관 특징을 가지는 제2 장소의 위치를 미리 획득된 장소 정보 내에서 선택하고, 상기 제2 장소의 위치에 기초하여 상기 측정된 로봇의 위치를 보정하되, 상기 장소 정보는 상기 실외에 존재하는 복수의 장소 각각에 대한 위치 및 외관 특징을 포함하는, 로봇."}
{"patent_id": "10-2019-0128476", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "위치 측정 센서가 실외에서 주행하는 로봇의 위치를 측정하는 단계;카메라가 상기 로봇의 주변 환경에 대한 영상을 획득하는 단계;프로세서가 상기 획득된 영상을 분석하여 상기 획득된 영상 내에 존재하는 M(1 이상의 정수)개의 제1 장소의 외관 특징을 추출하는 단계; 프로세서가 상기 N개의 제1 장소의 외관 특징의 적어도 일부와 동일한 외관 특징을 가지는 N(1 이상의 정수)개공개특허 10-2021-0045119-5-의 제2 장소의 위치를 미리 획득된 장소 정보 내에서 선택하는 단계; 및상기 N개의 제2 장소의 위치에 기초하여 상기 측정된 로봇의 위치를 보정하는 단계;를 포함하되, 상기 장소 정보는 상기 실외에 존재하는 복수의 장소 각각에 대한 위치 및 외관 특징을 포함하는, 로봇의 위치보정 방법."}
{"patent_id": "10-2019-0128476", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제15항에 있어서, 상기 선택하는 단계는, 상기 장소 정보에 포함된 복수의 장소 중 상기 측정된 로봇의 위치와 인접한 위치에 존재하는 하나 이상의 제2장소를 선택하고, 상기 하나 이상의 제2 장소의 외관 특징과 상기 M개의 제1 장소의 외관 특징을 비교하여 상기N개의 제2 장소를 선택하는, 로봇의 위치 보정 방법."}
{"patent_id": "10-2019-0128476", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제15항에 있어서, 상기 추출하는 단계는, 인공 신경망 기반의 알고리즘 모델을 이용하여 상기 M개의 제1 장소의 외관 특징을 추출하되, 상기 알고리즘 모델은 입력 노드로 구성된 입력 레이어, 출력 노드로 구성된 출력 레이어 및 입력 레이어와 출력 레이어 사이에 배치되며, 은닉 노드로 구성된 하나 이상의 은닉 레이어를 포함하고, 학습을 통해 노드들을연결하는 에지의 가중치 및 노드들의 바이어스가 업데이트되는, 로봇의 위치 보정 방법."}
{"patent_id": "10-2019-0128476", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제17항에 있어서, 상기 알고리즘 모델은 사진으로 구성되는 제1 웹 지도에서 추출된 상기 실외의 장소의 외부 사진을 학습 데이터로 하여 학습되는, 로봇의 위치 보정 방법."}
{"patent_id": "10-2019-0128476", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제15항에 있어서, 상기 외관 특징은 상기 장소와 인접하게 배치된 구조물 내에 표시된 상호 정보와 대응되는, 로봇의 위치 보정방법."}
{"patent_id": "10-2019-0128476", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제15항에 있어서, 상기 장소 정보는 실외에 존재하는 복수의 장소의 위치 및 상호 정보를 포함하는 제2 웹 지도를 이용하여 생성되는, 로봇의 위치 보정 방법."}
{"patent_id": "10-2019-0128476", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "로봇 및 상기 로봇의 위치 보정 방법이 개시된다. 개시된 로봇은 실외에서 주행하는 로봇의 위치를 측정하는 위 치 측정 센서, 상기 로봇의 주변에 대한 영상을 획득하는 카메라, 상기 실외에 존재하는 복수의 장소 각각의 위 치 및 외관 특징을 포함하는 장소 정보를 저장하고, 하나 이상의 명령어를 저장하는 메모리 및 상기 하나 이상의 명령을 실행함으로써 상기 측정된 위치를 보정하는 프로세서를 포함하되, 상기 프로세서는, 상기 획득된 영상을 분석하여 상기 획득된 영상 내에 존재하는 M(1 이상의 정수)개의 제1 장소의 외관 특징을 추출하고, 상기 M개의 제1 장소의 외관 특징을 이용하여 상기 장소 정보 내에서 N(1 이상 M 이하의 정수)개의 제2 장소의 위치를 선택 하고, 상기 N개의 제2 장소의 위치에 기초하여 상기 측정된 로봇의 위치를 보정한다."}
{"patent_id": "10-2019-0128476", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 로봇 및 상기 로봇의 위치 보정 방법에 관한 것이다."}
{"patent_id": "10-2019-0128476", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "로봇은 산업용으로 개발되어 공장 자동화의 일 부분을 담당하여 왔다. 최근에는 로봇을 응용한 분야가 더욱 확 대되어, 의료용 로봇, 우주 항공 로봇 등이 개발되고, 일반 가정에서 사용할 수 있는 가정용 로봇도 만들어지고 있다. 이러한 로봇 중에서 자력으로 주행이 가능한 것을 이동 로봇이라고 한다. 로봇 이용의 증가에 따라, 단순 기능의 반복 수행을 넘어서 다양한 정보, 재미, 서비스를 제공할 수 있는 로봇 에 대한 요구가 많아지고 있다. 이에 따라, 가정, 식당, 매장, 공공 장소 등에 배치되어 사람에게 편의를 제공 하는 다양한 로봇이 개발되고 있다. 특히, 이동 로봇은 물류를 고객에게 배송하는데 사용될 수 있다. 이 때, 이동 로봇에는 카메라 및 복수의 센서 가 부착되며, 카메라로부터 획득된 영상 및 복수의 센서에서 획득된 다양한 센싱 정보들을 이용하여 주행 경로 가 설정된다. 이 과정에서, 이동 로봇은 공간에 배치된 사물들 혹은 공간의 구조에 대한 정보를 맵 상에 저장 할 수 있으며, 저장된 맵을 더 참조하여 주행 경로를 설정한다. 한편, 이동 로봇에는 GPS 모듈이 설치되고, 이에 기초하여 이동 로봇의 위치가 측정된다. 그러나, GPS 모듈이 비교적 저가이거나 또는 환경적 영향으로 인해서, GPS 모듈에서의 위치 측정이 정확하게 수행되지 않는 경우가 발생할 수 있다. 이 경우, 정확하지 않는 위치 측정으로 인해, 실외에 주행하는 차량과 이동 로봇 간의 사고가 발생하는 문제점이 있다."}
{"patent_id": "10-2019-0128476", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명의 목적은 실외에서 이동하는 로봇의 측정 위치의 오차를 정확하게 보정할 수 있는 로봇의 위치 보정 방 법 및 이를 구현하는 로봇을 제공하는 것이다. 또한 본 발명의 목적은 웹 지도에 반영된 근처의 주요 장소의 정보를 로봇의 지도에 등록하고, 로봇이 해당 주 요 장소를 발견할 경우 등록된 장소의 정보를 활용하여 로봇의 위치를 보정하는 로봇의 위치 보정 방법 및 이를 구현하는 로봇을 제공하는 것이다. 본 발명의 목적들은 이상에서 언급한 목적으로 제한되지 않으며, 언급되지 않은 본 발명의 다른 목적 및 장점들 은 하기의 설명에 의해서 이해될 수 있고, 본 발명의 실시예에 의해 보다 분명하게 이해될 것이다. 또한, 본 발 명의 목적 및 장점들은 특허 청구 범위에 나타낸 수단 및 그 조합에 의해 실현될 수 있음을 쉽게 알 수 있을 것 이다."}
{"patent_id": "10-2019-0128476", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명에 따른 로봇은, 실외에서 주행하는 로봇의 위치를 측정하는 위치 측정 센서, 상기 로봇의 주변에 대한 영상을 획득하는 카메라, 상기 실외에 존재하는 복수의 장소 각각의 위치 및 외관 특징을 포함하는 장소 정보를 저장하고, 하나 이상의 명령어를 저장하는 메모리 및 상기 하나 이상의 명령을 실행함으로써 상기 측정된 위치 를 보정하는 프로세서를 포함하되, 상기 프로세서는, 상기 획득된 영상을 분석하여 상기 획득된 영상 내에 존재 하는 M(1 이상의 정수)개의 제1 장소의 외관 특징을 추출하고, 상기 M개의 제1 장소의 외관 특징을 이용하여 상 기 장소 정보 내에서 N(1 이상 M 이하의 정수)개의 제2 장소의 위치를 선택하고, 상기 N개의 제2 장소의 위치에 기초하여 상기 측정된 로봇의 위치를 보정한다. 또한, 본 발명에 따른 로봇은, 실외에서 주행하는 로봇의 위치를 측정하는 위치 측정 센서, 상기 로봇의 주변에 대한 영상을 획득하는 카메라, 하나 이상의 명령어를 저장하는 메모리 및 상기 하나 이상의 명령을 실행함으로 써 상기 측정된 위치를 보정하는 프로세서를 포함하되, 상기 프로세서는, 상기 획득된 영상에 기초하여 상기 획 득된 영상 내에 존재하는 제1 장소의 외관 특징을 추출하고, 상기 제1 장소의 외관 특징과 동일한 외관 특징을가지는 제2 장소의 위치를 미리 획득된 장소 정보 내에서 선택하고, 상기 제2 장소의 위치에 기초하여 상기 측 정된 로봇의 위치를 보정하되, 상기 장소 정보는 상기 실외에 존재하는 복수의 장소 각각에 대한 위치 및 외관 특징을 포함할 수 있다. 또한, 본 발명에 따른 로봇의 위치 보정 방법은 위치 측정 센서가 실외에서 주행하는 로봇의 위치를 측정하는 단계, 카메라가 상기 로봇의 주변 환경에 대한 영상을 획득하는 단계, 프로세서가 상기 획득된 영상을 분석하여 상기 획득된 영상 내에 존재하는 M(1 이상의 정수)개의 제1 장소의 외관 특징을 추출하는 단계, 프로세서가 상 기 N개의 제1 장소의 외관 특징의 적어도 일부와 동일한 외관 특징을 가지는 N(1 이상의 정수)개의 제2 장소의 위치를 미리 획득된 장소 정보 내에서 선택하는 단계 및 상기 N개의 제2 장소의 위치에 기초하여 상기 측정된 로봇의 위치를 보정하는 단계를 포함하되, 상기 장소 정보는 상기 실외에 존재하는 복수의 장소 각각에 대한 위 치 및 외관 특징을 포함한다."}
{"patent_id": "10-2019-0128476", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명에 따르면, 실외에서 이동하는 로봇의 측정 위치의 오차를 정확하게 보정할 수 있다. 또한, 본 발명에 따르면, 웹 지도에 반영된 근처의 주요 장소의 정보를 로봇의 지도에 등록하고, 로봇이 해당 주요 장소를 발견할 경우 등록된 장소의 정보를 활용하여 로봇의 위치를 보정할 수 있다. 상술한 효과와 더불어 본 발명의 구체적인 효과는 이하"}
{"patent_id": "10-2019-0128476", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "전술한 목적, 특징 및 장점은 첨부된 도면을 참조하여 상세하게 후술되며, 이에 따라 본 발명이 속하는 기술분 야에서 통상의 지식을 가진 자가 본 발명의 기술적 사상을 용이하게 실시할 수 있을 것이다. 본 발명을 설명함 에 있어서 본 발명과 관련된 공지 기술에 대한 구체적인 설명이 본 발명의 요지를 불필요하게 흐릴 수 있다고 판단되는 경우에는 상세한 설명을 생략한다. 이하, 첨부된 도면을 참조하여 본 발명에 따른 바람직한 실시예를 상세히 설명하기로 한다. 도면에서 동일한 참조부호는 동일 또는 유사한 구성요소를 가리키는 것으로 사용된다. 비록 제1, 제2, A, B, (a), (b) 등이 다양한 구성요소들을 서술하기 위해서 사용되나, 이들 구성 요소들은 이들 용어에 의해 제한되지 않음은 물론이다. 이들 용어들은 단지 하나의 구성요소를 다른 구성요소와 구별하기 위 하여 사용하는 것으로, 특별히 반대되는 기재가 없는 한, 제1 구성 요소는 제2 구성 요소일 수도 있음은 물론이 다. 어떤 구성 요소가 다른 구성요소에 \"연결\", \"결합\" 또는 \"접속\"된다고 기재된 경우, 그 구성 요소는 그 다른 구 성요소에 직접적으로 연결되거나 또는 접속될 수 있지만, 각 구성 요소 사이에 다른 구성 요소가 \"개재\"되거나, 각 구성 요소가 다른 구성 요소를 통해 \"연결\", \"결합\" 또는 \"접속\"될 수도 있다고 이해되어야 할 것이다. 그리고, 명세서 전체에서, \"A 및/또는 B\" 라고 할 때, 이는 특별한 반대되는 기재가 없는 한, A, B 또는 A 및 B 를 의미하며, \"C 내지 D\" 라고 할 때, 이는 특별한 반대되는 기재가 없는 한, C 이상이고 D 이하인 것을 의미한 다. 명세서 전체에서, 특별히 반대되는 기재가 없는 한, 각 구성 요소는 단수일 수도 있고 복수일 수도 있다. 본 명세서에서 사용되는 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 출원에서, \"구성된다\" 또는 \"포함한다\" 등의 용어는 명세서 상에 기재된 여러 구성 요소들, 또는 여러 단계들을 반드시 모두 포함하는 것으로 해석되지 않아야 하며, 그 중 일부 구성 요소들 또는 일부 단계들은 포함되지 않을 수도 있고, 또는 추가적인 구성 요소 또는 단계들을 더 포함할 수 있는 것으로 해석되어야 한다. 본 발명을 구현함에 있어서 설명의 편의를 위하여 구성요소를 세분화하여 설명할 수 있으나, 이들 구성요소가 하나의 장치 또는 모듈 내에 구현될 수도 있고, 혹은 하나의 구성요소가 다수의 장치 또는 모듈들에 나뉘어져서 구현될 수도 있다. 이하, 본 명세서에서 로봇은 특정한 기능을 수행하며, 특정 지역을 주행하는 장치를 통칭한다. 로봇이 수행하 는 기능이란 청소, 배송, 안내, 맵 작성 등의 기능 등과 같이 이동하는 장치가 제공할 수 있는 다양한 기능들을 포함한다. 특히, 설명의 편의를 위해, 본 명세서에 개시된 로봇은 물류를 배송하기 위한 로봇, 즉 배송 로봇으 로 가정하여 설명한다. 도 1은 본 발명의 일 실시예에 따른 AI 장치의 개략적인 구성을 도시한 도면이다. AI 장치는 TV, 프로젝터, 휴대폰, 스마트폰, 데스크탑 컴퓨터, 노트북, 디지털 방송용 단말기, PDA(personal digital assistants), PMP(portable multimedia player), 네비게이션, 태블릿 PC, 웨어러블 장치, 셋톱박스(STB), DMB 수신기, 라디오, 세탁기, 냉장고, 데스크탑 컴퓨터, 디지털 사이니지, 로봇, 차량 등 과 같은, 고정형 기기 또는 이동 가능한 기기 등으로 구현될 수 있다. 도 1을 참조하면, AI 장치는 통신부, 입력부, 러닝 프로세서, 센싱부, 출력부, 메모리 및 프로세서 등을 포함할 수 있다. 통신부는 유무선 통신 기술을 이용하여 다른 AI 장치(100a 내지 100e)나 후술할 AI 서버 등의 외부 장치들과 데이터를 송수신할 수 있다. 예컨대, 통신부는 외부 장치들과 센서 정보, 사용자 입력, 학습 모델, 제어 신호 등을 송수신할 수 있다. 이 때, 통신부가 이용하는 통신 기술에는 GSM(Global System for Mobile communication), CDMA(Code Division Multi Access), LTE(Long Term Evolution), 5G, WLAN(Wireless LAN), Wi-Fi(Wireless-Fidelity), 블 루투스(Bluetooth), RFID(Radio Frequency Identification), 적외선 통신(Infrared Data Association; IrDA), ZigBee, NFC(Near Field Communication) 등이 있다. 입력부는 다양한 종류의 데이터를 획득할 수 있다. 이때, 입력부는 영상 신호 입력을 위한 카메라, 오디오 신호를 수신하기 위한 마이크로폰, 사용자로부터 정보를 입력 받기 위한 사용자 입력부 등을 포함할 수 있다. 여기서, 카메라나 마이크로폰을 센서로 취급하여, 카메라나 마이크로폰으로부터 획득한 신호를 센싱 데이터 또는 센서 정보라고 할 수도 있다. 입력부는 모델 학습을 위한 학습 데이터 및 학습 모델을 이용하여 출력을 획득할 때 사용될 입력 데이터 등을 획득할 수 있다. 입력부는 가공되지 않은 입력 데이터를 획득할 수도 있으며, 이 경우 프로세서 또는 러닝 프로세서는 입력 데이터에 대하여 전처리로써 입력 특징점(input feature)을 추출할 수 있다. 러닝 프로세서는 학습 데이터를 이용하여 인공 신경망으로 구성된 모델을 학습시킬 수 있다. 여기서, 학습된 인공 신경망을 학습 모델이라 칭할 수 있다. 학습 모델은 학습 데이터가 아닌 새로운 입력 데 이터에 대하여 결과 값을 추론해 내는데 사용될 수 있고, 추론된 값은 어떠한 동작을 수행하기 위한 판단의 기 초로 이용될 수 있다. 이 때, 러닝 프로세서는 AI 서버의 러닝 프로세서과 함께 AI 프로세싱을 수행할 수 있다. 러닝 프로세서는 AI 장치에 통합되거나 구현된 메모리를 포함할 수 있다. 또는, 러닝 프로세서(13 0)는 메모리, AI 장치에 직접 결합된 외부 메모리 또는 외부 장치에서 유지되는 메모리를 사용하여 구현될 수도 있다. 센싱부는 다양한 센서들을 이용하여 AI 장치 내부 정보, AI 장치의 주변 환경 정보 및 사용자 정보 중 적어도 하나를 획득할 수 있다. 이 때, 센싱부에 포함되는 센서에는 근접 센서, 조도 센서, 가속도 센서, 자기 센서, 자이로 센서, 관성 센서, RGB 센서, IR 센서, 지문 인식 센서, 초음파 센서, 광 센서, 마이크로폰, 라이다, 레이더 등이 있다.출력부는 시각, 청각 또는 촉각 등과 관련된 출력을 발생시킬 수 있다. 이 때, 출력부에는 시각 정보를 출력하는 디스플레이부, 청각 정보를 출력하는 스피커, 촉각 정보를 출력 하는 햅틱 모듈 등이 포함될 수 있다. 메모리는 AI 장치의 다양한 기능을 지원하는 데이터를 저장할 수 있다. 예컨대, 메모리는 입력 부에서 획득한 입력 데이터, 학습 데이터, 학습 모델, 학습 히스토리 등을 저장할 수 있다. 프로세서는 데이터 분석 알고리즘 또는 머신 러닝 알고리즘을 사용하여 결정되거나 생성된 정보에 기초하 여, AI 장치의 적어도 하나의 실행 가능한 동작을 결정할 수 있다. 그리고, 프로세서는 AI 장치 의 구성 요소들을 제어하여 결정된 동작을 수행할 수 있다. 이를 위해, 프로세서는 러닝 프로세서 또는 메모리의 데이터를 요청, 검색, 수신 또는 활용할 수 있고, 적어도 하나의 실행 가능한 동작 중 예측되는 동작이나, 바람직한 것으로 판단되는 동작을 실행하도록 AI 장치의 구성 요소들을 제어할 수 있다. 이 때, 프로세서는 결정된 동작을 수행하기 위하여 외부 장치와의 연계가 필요한 경우, 해당 외부 장치를 제어하기 위한 제어 신호를 생성하고, 생성한 제어 신호를 해당 외부 장치에 전송할 수 있다. 프로세서는 사용자 입력에 대하여 의도 정보를 획득하고, 획득한 의도 정보에 기초하여 사용자의 요구 사 항을 결정할 수 있다. 이 때, 프로세서는 음성 입력을 문자열로 변환하기 위한 STT(Speech To Text) 엔진 또는 자연어의 의도 정 보를 획득하기 위한 자연어 처리(NLP: Natural Language Processing) 엔진 중에서 적어도 하나 이상을 이용하여, 사용자 입력에 상응하는 의도 정보를 획득할 수 있다. STT 엔진 또는 NLP 엔진 중에서 적어도 하나는 머신 러닝 알고리즘에 따라 학습된 인공 신경망으로 구성될 수 있다. 그리고, STT 엔진 또는 NLP 엔진 중에서 적어도 하나는 러닝 프로세서에 의해 학습된 것이나, AI 서버의 러닝 프로세서에 의해 학습된 것이거나, 또는 이들의 분산 처리에 의해 학습된 것일 수 있다. 프로세서는 AI 장치의 동작 내용이나 동작에 대한 사용자의 피드백 등을 포함하는 이력 정보를 수집 하여 메모리 또는 러닝 프로세서에 저장하거나, AI 서버 등의 외부 장치에 전송할 수 있다. 수 집된 이력 정보는 학습 모델을 갱신하는데 이용될 수 있다. 프로세서는 메모리에 저장된 응용 프로그램을 구동하기 위하여, AI 장치의 구성 요소들 중 적어 도 일부를 제어할 수 있다. 나아가, 프로세서는 응용 프로그램의 구동을 위하여, AI 장치에 포함된 구성 요소들 중 둘 이상을 서로 조합하여 동작시킬 수 있다. 도 2는 본 발명의 일 실시예에 따른 AI 서버의 개략적인 구성을 도시한 도면이다. 도 2를 참조하면, AI 서버는 머신 러닝 알고리즘을 이용하여 인공 신경망을 학습시키거나 학습된 인공 신 경망을 이용하는 장치를 의미할 수 있다. 여기서, AI 서버는 복수의 서버들로 구성되어 분산 처리를 수행할 수도 있고, 5G 네트워크로 정의될 수 있 다. 이 때, AI 서버는 AI 장치의 일부의 구성으로 포함되어, AI 프로세싱 중 적어도 일부를 함께 수 행할 수도 있다. AI 서버는 통신부, 메모리, 러닝 프로세서 및 프로세서 등을 포함할 수 있다. 통신부는 AI 장치 등의 외부 장치와 데이터를 송수신할 수 있다. 메모리는 모델 저장부를 포함할 수 있다. 모델 저장부는 러닝 프로세서을 통하여 학습 중 인 또는 학습된 모델(또는 인공 신경망, 231a)을 저장할 수 있다. 러닝 프로세서는 학습 데이터를 이용하여 인공 신경망(231a)을 학습시킬 수 있다. 학습 모델은 인공 신경 망의 AI 서버에 탑재된 상태에서 이용되거나, AI 장치 등의 외부 장치에 탑재되어 이용될 수도 있다. 학습 모델은 하드웨어, 소프트웨어 또는 하드웨어와 소프트웨어의 조합으로 구현될 수 있다. 학습 모델의 일부 또는 전부가 소프트웨어로 구현되는 경우 학습 모델을 구성하는 하나 이상의 명령어(instruction)는 메모리에 저장될 수 있다. 프로세서는 학습 모델을 이용하여 새로운 입력 데이터에 대하여 결과 값을 추론하고, 추론한 결과 값에 기 초한 응답이나 제어 명령을 생성할 수 있다. 앞서 설명한 AI 장치 및 AI 서버는 본 명세서에 후술되는 내용에 적용될 수 있으며, 본 명세서에서 제안하는 방법들의 기술적 특징을 구체화하거나 명확하게 하는데 보충될 수 있다. 도 3은 본 발명의 일 실시예에 따른 로봇의 개략적인 구성을 도시한 도면이다. 도 3을 참조하면, 본 발명의 일 실시예에 따른 로봇은 앞서 언급한 바와 같이 물류의 배송에 이용되는 이 동 로봇일 수 있으며, 주행부, 통신부, 카메라, 센싱부, 메모리, 러닝 프로세서 및 프로세서를 포함한다. 이하, 각 구성 요소 별로 그 기능을 상세하게 설명한다. 주행부는 액츄에이터, 모터 등이 포함되고, 로봇을 주행시킨다. 통신부는 외부 장치와 통신을 수행한다. 이 때, 통신부는 이동통신 모듈, 근거리 통신 모듈 등을 포 함할 수 있다. 이동 통신 모듈은 이동 통신을 위한 기술 표준들 또는 통신 방식을 사용하여 통신을 수행할 수 있다. 여기서, 기술 표준들 또는 통신 방식은 GSM(Global System for Mobile communication), CDMA(Code Division Multi Access), CDMA2000(Code Division Multi Access 2000), EV-DO(Enhanced Voice-Data Optimized or Enhanced Voice-Data Only), WCDMA(Wideband CDMA), HSDPA(High Speed Downlink Packet Access), HSUPA(High Speed Uplink Packet Access), LTE(Long Term Evolution), LTE-A(Long Term Evolution-Advanced), 5G 네트워크 등을 포함할 수 있다. 근거리 통신 모듈은 근거리 통신(Short range communication)을 위한 것으로서, 블루투스(Bluetooth), RFID(Radio Frequency Identification), 적외선 통신(Infrared Data Association; IrDA), UWB(Ultra Wideband), ZigBee, NFC(Near Field Communication), Wi-Fi(Wireless-Fidelity), Wi-Fi Direct, Wireless USB(Wireless Universal Serial Bus) 기술 중 적어도 하나를 포함할 수 있다. 카메라는 로봇의 주변 환경에 대한 영상을 획득한다. 센싱부는 다양한 센서들을 이용하여 로봇의 주변 환경 정보 등을 획득한다. 일례로, 센싱부는 근접 센서(proximity sensor), 조도 센서(illumination sensor), 터치 센서(touch sensor), 가속도 센서(acceleration sensor), 자기 센서(magnetic sensor), 중력 센서(G-sensor), 자이로스코 프 센서(gyroscope sensor), 모션 센서(motion sensor), RGB 센서, 적외선 센서(infrared sensor), 초음파 센 서(ultrasonic sensor), 광 센서(optical sensor), 라이다 센서, 레이더 센서 등을 포함할 수 있다. 특히, 센싱부는 로봇의 위치를 측정하는 위치 측정 센서를 포함할 수 있다. 일례로, 위치 측정 센서 는 GPS 센서 또는 GLONASS 센서일 수 있다. 이 때, 위치는 경도 및 위도에 의해 정의된다. 그리고, 센싱부는 뎁스 센서를 포함할 수 있다. 뎁스 센서는 특정 영역에 대한 뎁스 영상을 획득한다. 보다 상세하게, 뎁스 센서는 장면의 깊이, 즉 센서와 객체까지의 거리를 측정하여 영상으로 출력하는 기기이다. 뎁스 센서는 Time-of-Flight(TOF) 기술을 사용하여 장면의 깊이 영상을 획득한다. TOF 기술이란 적외선 신호가 촬영하는 장면 내의 물체에 반사되어 돌아오는 시간을 계산하여 거리를 측정하는 방식이다. TOF 기술을 이용하 여 획득한 장면의 깊이 정보는 양자화 과정을 통해 깊이 영상으로 표현된다. 메모리는 휘발성 및/또는 비휘발성 메모리일 수 있고, 로봇의 적어도 하나의 다른 구성요소에 관계된 명령 또는 데이터를 저장한다. 특히, 메모리는 로봇의 측정 위치의 보정을 위해 사용되는 인공 신경 망 기반의 알고리즘 모델을 저장한다. 또한, 메모리는 측정 위치의 보정에 사용되는 장소 정보를 저장할 수 있다. 장소 정보는 실외(외부)에 존재하는 복수의 장소 각각에 대한 위치 및 외관 특징을 포함할 수 있다. 이는 아래에서 보다 상세하게 설명하기로 한다. 러닝 프로세서는 인공 신경망 기반의 알고리즘 모델을 학습하는 기능을 수행한다. 프로세서는 중앙처리장치, 애플리케이션 프로세서, 또는 커뮤니케이션 프로세서 중 하나 또는 그 이상을 포함할 수 있다. 예를 들면, 프로세서는 로봇의 적어도 하나의 다른 구성요소들의 제어 및/또는 통 신에 관한 연산이나 데이터 처리를 실행할 수 있다. 특히, 프로세서는 컴퓨터 프로그램의 실행에 관계된 명령을 실행할 수 있으며, 인공 신경망 기반의 모델을 이용하여 로봇의 측정 위치를 보정할 수 있다. 이하, 인공 신경망 기반의 알고리즘을 간략하게 설명한 후, 본 발명의 일 실시예에 따른 로봇의 위치 보정 방법을 상세하게 설명하기로 한다. 한편, 인공 지능은 인공적인 지능 또는 이를 만들 수 있는 방법론을 연구하는 분야를 의미하며, 머신 러닝(기계 학습, Machine Learning)은 인공 지능 분야에서 다루는 다양한 문제를 정의하고 그것을 해결하는 방법론을 연구 하는 분야를 의미한다. 머신 러닝은 어떠한 작업에 대하여 꾸준한 경험을 통해 그 작업에 대한 성능을 높이는 알고리즘으로 정의하기도 한다. 인공 신경망(ANN: Artificial Neural Network)은 머신 러닝에서 사용되는 모델로써, 시냅스의 결합으로 네트워 크를 형성한 인공 뉴런(노드)들로 구성되는, 문제 해결 능력을 가지는 모델 전반을 의미할 수 있다. 인공 신경 망은 다른 레이어의 뉴런들 사이의 연결 패턴, 모델 파라미터를 갱신하는 학습 과정, 출력값을 생성하는 활성화 함수(Activation Function)에 의해 정의될 수 있다. 인공 신경망은 입력층(Input Layer), 출력층(Output Layer), 그리고 선택적으로 하나 이상의 은닉층(Hidden Layer)를 포함할 수 있다. 각 층은 하나 이상의 뉴런을 포함하고, 인공 신경망은 뉴런과 뉴런을 연결하는 시냅 스를 포함할 수 있다. 인공 신경망에서 각 뉴런은 시냅스를 통해 입력되는 입력 신호들, 가중치, 편향에 대한 활성 함수의 함수 값을 출력할 수 있다. 모델 파라미터는 학습을 통해 결정되는 파라미터를 의미하며, 시냅스 연결의 가중치와 뉴런의 편향 등이 포함된 다. 그리고, 하이퍼파라미터는 머신 러닝 알고리즘에서 학습 전에 설정되어야 하는 파라미터를 의미하며, 학습 률(Learning Rate), 반복 횟수, 미니 배치 크기, 초기화 함수 등이 포함된다. 인공 신경망의 학습의 목적은 손실 함수를 최소화하는 모델 파라미터를 결정하는 것으로 볼 수 있다. 손실 함 수는 인공 신경망의 학습 과정에서 최적의 모델 파라미터를 결정하기 위한 지표로 이용될 수 있다. 머신 러닝은 학습 방식에 따라 지도 학습(Supervised Learning), 비지도 학습(Unsupervised Learning), 강화 학습(Reinforcement Learning)으로 분류할 수 있다. 지도 학습은 학습 데이터에 대한 레이블(label)이 주어진 상태에서 인공 신경망을 학습시키는 방법을 의미하며, 레이블이란 학습 데이터가 인공 신경망에 입력되는 경우 인공 신경망이 추론해 내야 하는 정답(또는 결과 값)을 의미할 수 있다. 비지도 학습은 학습 데이터에 대한 레이블이 주어지지 않는 상태에서 인공 신경망을 학습시키는 방법을 의미할 수 있다. 강화 학습은 어떤 환경 안에서 정의된 에이전트가 각 상태에서 누적 보상을 최대화하는 행동 혹은 행동 순서를 선택하도록 학습시키는 학습 방법을 의미할 수 있다. 인공 신경망 중에서 복수의 은닉층을 포함하는 심층 신경망(DNN: Deep Neural Network)으로 구현되는 머신 러닝 을 딥 러닝(심층 학습, Deep Learning)이라 부르기도 하며, 딥 러닝은 머신 러닝의 일부이다. 이하에서, 머신 러닝은 딥 러닝을 포함하는 의미로 사용된다. 도 4는 본 발명의 일 실시예에 따른 로봇의 위치 보정 방법의 흐름도를 도시한 도면이다. 여기서, 로봇은 실외(외부)를 이동하는 것으로 가정한다. 이하, 각 단계 별로 수행되는 과정을 설명한다. 먼저, 단계(S402)에서, 실외에 존재하는 복수의 장소에 대한 장소 정보가 획득된다. 이 때, 복수의 장소 각각 은 로봇의 측정된 위치를 보정하기 위해 설정되는 랜드마크와 대응된다. 일례로서, 장소 정보는 통신부를 통해 외부 서버 등에서 수신되거나 사용자 인터페이스를 통해 사용자로부 터 입력될 수 있으며, 획득된 장소 정보는 메모리에 저장될 수 있다. 장소 정보는 복수의 장소 각각에 대한 위치 및 외관 특징을 포함한다. 위치는 위도 및 경로로 정의되며, GPS 위치 정보와 대응될 수 있다. 외관 특징은 장소의 형상의 특징과 대응될 수 있다. 바람직하게, 외관 특징은 장소의 외부에 배치된 구조물, 바람직하게는 간판 구조물에 표시된 상호 정보일 수 있다. 장소 정보 내에서의 외관 특징은 사진으로 표현되거 나 텍스트 형태로 표현될 수 있다. 이하, 설명의 편의를 위해, \"외관 특징\"을 \"상호 정보\"로 가정하여 설명한다. 그러나, 본 발명이 이에 한정되 는 것은 아니다. 도 5에서는 텍스트 형태로 구성되는 장소 정보의 일례를 도시하고 있다. 도 5를 참조하면, 텍스트 형태의 장소 정보는 장소의 인덱스와, 경도 및 위도로 정의되는 위치와, 상호 정보를 포함할 수 있다. 본 발명의 일 실시예에 따르면, 장소 정보는 복수의 장소의 위치 및 상호 정보를 담고 있는 웹 지도를 이용하여 생성될 수 있다. 사용자는 웹 지도에 기초하여 로봇이 이동하는 지역에 대한 장소 정보를 생성하고, 이를 로봇에 등록할 수 있다. 웹 지도는 로드 뷰, 스트리트 뷰 등과 같이 사진으로 구성되는 제1 웹 지도와, 상호 정보를 포함하는 일반적인 지도 형태의 제2 웹 지도를 포함한다. 도 6은 제1 웹 지도의 일례를 도시한 도면이다. 도 6을 참조하면, 제1 웹 지도에는 다양한 장소의 외부 형상과 관련된 사진이 표시된다. 한편, 특정 장소를 선택하면 선택된 장소와 대응되는 위치(경도, 위도)가 표시될 수 있다. 도 7은 제2 웹 지도의 일례를 도시한 도면이다. 도 7을 참조하면, 제2 웹 지도에는 다양한 장소의 상호 정보가 표시되며, 특정 장소를 선택하면 선택된 장소와 대응되는 위치(경도, 위도)가 표시될 수 있다. 요컨대, 장소 정보가 텍스트 형태로 구성되는 경우 제2 웹 지도가 장소 정보의 생성에 이용될 수 있고, 장소 정 보가 사진 정보와 및 텍스트 형태로 구성되는 경우 제1 웹 지도 및 제2 웹 지도 모두가 장소 정보의 생성에 이 용될 수 있다. 다음으로, 단계(S404)에서, 위치 측정 센서가 로봇의 위치를 측정한다. 이 때, 위치 측정 센서가 비교적 저가인 상황 등으로 인하여 측정된 로봇의 위치는 정확하지 않는 위치일 수 있다. 즉, 위치 측정 센서를 통해 측정된 로봇의 위치와 로봇와 실제 위치는 동일하지 않을 수 있다. 계속하여, 단계(S406)에서, 카메라는 로봇의 주변 환경에 대한 영상을 획득한다. 여기서, 획득되는 영상에는 특정 지역에 존재하는 M(1 이상의 장소)개의 장소에 대한 외부 형상이 포함될 수 있 다. 특히, 영상 내에는 M개의 장소의 외부에 배치된 구조물의 형상이 포함될 수 있다. 여기서, 구조물은 장소 의 상호 정보가 기재된 간판 구조물일 수 있다. 한편, 영상에 포함되는 장소를 편의상 \"제1 장소\"라고 호칭하 기로 한다. 일례로, 카메라에서 획득되는 영상은 도 6에 표현된 도면과 유사한 형태일 수 있다. 한편, 단계(S404)과 단계(S406)는 동시에 수행될 수도 있다. 그 후, 단계(S408)에서, 프로세서는 획득된 영상을 분석하여 상기 획득된 영상 내에 존재하는 M개의 제1 장소의 상호 정보를 추출한다. 본 발명의 일 실시예에 따르면, 프로세서는 미리 학습된 인공 신경망 기반의 알고리즘 모델을 이용하여 M 개의 제1 장소의 상호 정보를 추출할 수 있다. 일례로, 알고리즘 모델은 CNN(Convolutional Neural Network) 기반의 알고리즘 모델일 수 있다. 즉, 상기에서 설명한 인공 신경망의 설명을 참조하면, 알고리즘 모델은 입력 노드로 구성된 입력 레이어, 출력 노드로 구성된 출력 레이어 및 입력 레이어와 출력 레이어 사이에 배치되며, 은닉 노드로 구성된 하나 이상의 은닉 레이어를 포함하고, 학습을 통해 노드들을 연결하는 에지의 가중치 및 노드들의 바이어스가 업데이트된다. 그리고, 카메라에서 획득된 영상이 학습된 알고리즘 모델의 입력 레이어로 입력되고, 학습된 알고리즘 모 델의 출력 레이어로 M개의 제1 장소의 상호 정보가 출력될 수 있다. 한편, 알고리즘 모델의 학습은 러닝 프로세서에 의해 수행될 수 있다. 본 발명의 일 실시예에 따르면, 러닝 프로세서는 제1 웹 지도에서 추출된 사진을 학습 데이터로 이용하여 알고리즘 모델을 학습할 수 있다. 즉, 제1 웹 지도는 사진들로 이루어지며, 사진에는 복수의 장소에 대한 외부 형상, 특히 장소의 간판 구조물이 포함된다. 따라서, 러닝 프로세서는 제1 웹 지도에서 추출된 복수의 사진을 알고리즘 모델의 입력 레이어 로 입력하여 학습 과정을 수행할 수 있다. 다음으로, 단계(S410)에서, 프로세서는 측정된 로봇의 위치와 인접한 위치에 존재하는 하나 이상의 장소를 장소 정보 내에서 선택한다. 여기서, \"인접한\"의 의미는 \"측정된 로봇의 위치를 기준으로 한 기 설정된 반경 이내\"의 의미와 대응된다. 즉, 장소가 프랜차이즈 스토어(franchise store)인 경우, 서로 다른 지역에 동일한 상호 정보를 가지는 장소가 존재할 수 있다. 이 경우, 장소가 명확하게 검색되지 않을 수 있다. 따라서, 단계(S410)는 검색의 정확성을 위해 수행되는 단계이다. 일례로서, 도 5의 일례를 참고하면, 위치 측정 센서를 통해 측정된 로봇의 위치가 (37.495688, 127.026643)인 경우, 프로세서는 기 설정된 반경을 고려하여 장소 정보 내에서 C 카페 및 D 편의점을 선택 할 수 있다. 한편, 검색된 하나 이상의 장소를 편의상 \"제2 장소\"라 호칭하기로 한다. 계속하여, 단계(S412)에서, 프로세서는 단계(S408)에서 추출된 M개의 제1 장소의 상호 정보를 이용하여 하 나 이상의 장소 정보 내에서 N(1 이상 M 이하의 정수)개의 제2 장소를 선택한다. 보다 상세하게, 프로세서는 M개의 제1 장소의 적어도 일부와 동일한 상호 정보를 가지는 N개의 제2 장소를 상기 하나 이상의 제2 장소에서 선택한다. 이 때, 적어도 일부의 제1 장소는 N개일 수 있다. 즉, 하나 이상의 제2 장소는 랜드마크로 등록된 장소이고, 추출된 M개의 제1 장소는 랜드마크로 등록된 장소일 수도 있고 랜드마크로 등록되지 않는 장소일 수 있다. 따라서, 단계(S412)는 추출된 M개의 제1 장소 각각이 등 록된 랜드마크인지 여부를 확인하는 과정일 수 있으며, 하나 이상의 제2 장소의 외관 특징과 M개의 제1 장소의 외관 특징을 비교하여 N개의 제2 장소를 선택한다. 일례로, 3개의 제1 장소가 추출되고, 3개의 제1 장소 중 2개의 제1 장소의 상호 정보가 2개의 제2 장소의 상호 정보와 동일한 경우, 프로세서는 2개의 제2 장소를 선택한다. 마지막으로, 단계(S414)에서, 프로세서는 N개의 제2 장소의 위치에 기초하여 측정된 로봇의 위치를 보정한 다. 이하, 도 8을 참조하여 단계(S414)의 과정을 설명하기로 한다. 단계(S4141)에서, 뎁스 센서는 획득된 영상과 대응되는 뎁스 영상을 획득한다. 단계(S4142)에서, 프로세서는 획득된 영상 및 뎁스 영상을 이용하여 로봇을 기준으로 한 적어도 일부 의 제1 장소(즉, N개의 제1 장소) 각각의 상대 위치를 산출한다. 보다 상세하게, 프로세서는 획득된 영상을 이용하여 N개의 제1 장소의 간판 구조물의 에지를 검출하고, 에 지가 만나는 꼭지점을 이용하여 N개의 제1 장소의 간판 구조물의 중앙부를 산출한다. 그리고, 프로세서는 획득된 뎁스 데이터를 이용하여 로봇을 기준으로 한 N개의 제1 장소의 간판 구조물의 중앙부의 상대 위치 를 산출한다. 이 때, 제1 장소의 간판 구조물의 중앙부의 상대 위치는 제1 장소의 상대 위치이다. 한편, 프로세서는 N개의 제1 장소의 간판 구조물의 에지를 산출하고, N개의 제1 장소의 간판 구조물의 에 지에 기초하여 N개의 제1 장소의 간판 구조물에 대한 소실점을 산출할 수 있다. 그리고, 프로세서는 검출 된 소실점을 이용하여 로봇을 기준으로 한 N개의 제1 장소의 간판 구조물의 상대 각도를 산출할 수 있다. 상대 각도를 통해 상대 위치가 보다 정확하게 산출될 수 있다. 즉, 로봇이 산출된 상대 각도만큼 제1 장 소의 간판 구조물로 회전함으로써 제1 장소의 상대 위치가 보다 정확하게 산출될 수 있다. 도 9에서는 상기에서 설명한 산출 과정의 개념을 도시하고 있다. 그 후, 단계(S4143)에서, 프로세서는 N개의 제1 장소의 상대 위치와 N개의 제2 장소의 위치를 이용하여 측 정된 로봇의 위치를 보정한다. 보다 상세하게, 프로세서는 N개의 보정 위치를 산출하고 N개의 보정 위치를 가중합하여 측정된 로봇 의 위치를 보정한다. 이 때, N개의 보정 위치 중 i번째 보정 위치는, N개의 제2 장소 중 i번째 제2 장소의 위치 및 N개의 제1 장소 중 i번째 제1 장소를 기준으로 한 로봇의 상대 위치에 기초하여 산출된다. 그리고, i번째 제1 장소를 기 준으로 한 로봇의 상대 위치는 i번째 제1 장소의 상대 위치를 이용하여 산출될 수 있다. 일례로, i번째 제1 장소를 기준으로 한 로봇의 상대 위치는 i번째 제1 장소의 상대 위치의 인버스 값(inverse value)일 수 있다. 본 발명의 일 실시예에 따르면, i번째 보정 위치는 아래의 수학식 1로 표현될 수 있다. 수학식 1"}
{"patent_id": "10-2019-0128476", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "여기서, eXr_i는 i번째 보정 위치, eXl_i는 i번째 제2 장소의 위치, lXr_i는 i번째 제1 장소를 기준으로 한 로봇 의 상대 위치, 는 컴파운트(compound) 연산자를 각각 의미한다. 그리고, N개의 보정 위치의 가중합은 아래의 수학식 2로 표현될 수 있다. 수학식 2"}
{"patent_id": "10-2019-0128476", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "여기서, wi는 i번째 보정 위치와 대응되는 가중치, 즉 i번째 가중치를 의미한다. 본 발명의 일 실시예에 따르면, i번째 가중치는 i번째 제1 장소와 로봇 간의 거리 및 로봇에서 바라 본 i번째 제1 장소의 각도(즉, i번째 제1 장소의 간판 구조물의 각도)와 반비례하도록 설정될 수 있다. 한편, N개의 보정 위치의 가중합은 실제의 로봇의 위치와 거의 동일하다. 그리고, N개의 보정 위치의 가 중합이 산출된 시점에서, 프로세서는 산출된 N개의 보정 위치의 가중합을 로봇의 위치로 판단한다. 또한, N개의 보정 위치의 가중합이 산출된 이후 시점에서, 프로세서는 산출된 N개의 보정 위치의 가중합을 이용하여 상기 측정된 로봇의 위치를 보정할 수 있다. 요컨대, 본 발명은 웹 지도에 반영된 근처의 주요 장소의 정보를 로봇의 지도에 등록하고, 로봇이 해 당 주요 장소를 발견할 경우 등록된 장소의 정보를 활용하여 로봇의 위치를 보정한다. 따라서, 로봇이 SLAM(Simultaneous Localization And Mapping) 기반으로 이동하는 경우, SLAM의 결과가 아무리 정확하다 하더라도 추정의 결과이기 때문에 불확실성이 존재하지만, 본 발명을 적용하는 경우 불확실성 을 대폭 감소시키고, 누적오차를 줄일 수 있다. 보다 상세하게, 일반적인 Visual SLAM의 경우 루프 클로져(loop closure)을 수행하기 위해 특정 루프를 지그재 그로 주행하는데, 이는 빠른 시간 안에 정확하게 배달 업무를 수행해야 하는 배송 로봇에게는 매우 비효율적이 다. 또한, 재방문한 장소를 인식하여 루프 클로져가 수행되는데, 주행 당시의 환경적 요인 및 위치 추정의 성능 등에 따라 루프 클로져의 결과가 동일하지 않다. 하지만, 사전에 등록한 랜드마크를 기준으로 루프 클로져 를 수행할 경우 불필요한 이동을 제거하고, 일관되고 정확한 결과를 얻을 수 있다. 또한, 본 발명의 실시예를 구성하는 모든 구성 요소들이 하나로 결합되거나 결합되어 동작하는 것으로 설명되었 다고 해서, 본 발명이 반드시 이러한 실시예에 한정되는 것은 아니며, 본 발명의 목적 범위 내에서 모든 구성 요소들이 하나 이상으로 선택적으로 결합하여 동작할 수도 있다. 또한, 그 모든 구성 요소들이 각각 하나의 독 립적인 하드웨어로 구현될 수 있지만, 각 구성 요소들의 그 일부 또는 전부가 선택적으로 조합되어 하나 또는 복수의 하드웨어에서 조합된 일부 또는 전부의 기능을 수행하는 프로그램 모듈을 갖는 컴퓨터 프로그램으로서 구현될 수도 있다. 그 컴퓨터 프로그램을 구성하는 코드들 및 코드 세그먼트들은 본 발명의 기술 분야의 당업자 에 의해 용이하게 추론될 수 있을 것이다. 이러한 컴퓨터 프로그램은 컴퓨터가 읽을 수 있는 저장매체(Computer Readable Media)에 저장되어 컴퓨터에 의하여 읽혀지고 실행됨으로써, 본 발명의 실시예를 구현할 수 있다. 컴 퓨터 프로그램의 저장매체로서는 자기 기록매체, 광 기록매체, 반도체 기록소자를 포함하는 저장매체를 포함한 다. 또한 본 발명의 실시예를 구현하는 컴퓨터 프로그램은 외부의 장치를 통하여 실시간으로 전송되는 프로그램 모듈을 포함한다. 이상과 같이 본 발명에 대해서 예시한 도면을 참조로 하여 설명하였으나, 본 명세서에 개시된 실시 예와 도면에 의해 본 발명이 한정되는 것은 아니며, 본 발명의 기술사상의 범위 내에서 통상의 기술자에 의해 다양한 변형이 이루어질 수 있음은 자명하다. 아울러 앞서 본 발명의 실시 예를 설명하면서 본 발명의 구성에 따른 작용 효과 를 명시적으로 기재하여 설명하지 않았을 지라도, 해당 구성에 의해 예측 가능한 효과 또한 인정되어야 함은 당 연하다."}
{"patent_id": "10-2019-0128476", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일 실시예에 따른 AI 장치의 개략적인 구성을 도시한 도면이다. 도 2는 본 발명의 일 실시예에 따른 AI 서버의 개략적인 구성을 도시한 도면이다. 도 3은 본 발명의 일 실시예에 따른 로봇의 개략적인 구성을 도시한 도면이다."}
