{"patent_id": "10-2025-0019218", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2025-0053787", "출원번호": "10-2025-0019218", "발명의 명칭": "텍스트를 포함하는 입력 정보에 기초하여 모션을 생성하는 모션 생성 장치 및 그의 동작 방법", "출원인": "주식회사 아이리브", "발명자": "이도희"}}
{"patent_id": "10-2025-0019218", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "텍스트를 포함하는 입력 정보에 기초하여 모션을 생성하는 모션 생성 장치에있어서, 적어도 하나의 명령어(instruction)를 저장하는 메모리; 및상기 메모리에 저장된 상기 적어도 하나의 명령어를 실행하는 적어도 하나의 프로세서를 포함하고,상기 적어도 하나의 프로세서는,캐릭터의 움직임을 나타내는 상기 텍스트를 포함하는 상기 입력 정보를 획득하고,상기 획득한 입력 정보로부터 특징 정보를 추출하고,상기 추출된 특징 정보를 이용하여 상기 캐릭터의 상기 움직임에 대한 모션 데이터를 생성하고,상기 생성된 모션 데이터를 후처리하여, 보정 모션 데이터를 획득하고,상기 획득된 보정 모션 데이터에 기초하여, 상기 캐릭터의 모션 애니메이션을 생성하는 모션 생성 장치."}
{"patent_id": "10-2025-0019218", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1 항에 있어서,상기 적어도 하나의 프로세서는,상기 텍스트로부터 추출된 상기 특징 정보로부터, 상기 캐릭터의 상기 움직임에 대한 상기 모션 데이터를 추론하도록 학습된 인공 지능 모델을 이용하여, 상기 특징 정보로부터 상기 모션 데이터를 생성하는 모션 생성장치."}
{"patent_id": "10-2025-0019218", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2 항에 있어서,상기 입력 정보는, 상기 캐릭터의 상기 움직임과 관련된 컨트롤 요소를 더 포함할 수 있고,상기 컨트롤 요소는, 오디오, 감정(emotion), 상기 움직임의 스타일, 이미지, 포즈 또는 비디오 중 적어도 하나를 포함할 수 있는 모션 생성 장치."}
{"patent_id": "10-2025-0019218", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3 항에 있어서,상기 적어도 하나의 프로세서는,상기 텍스트 및 상기 컨트롤 요소로부터 추출된 상기 특징 정보로부터 상기 모션 데이터를 추론하도록 학습된인공 지능 모델을 이용하여, 상기 특징 정보로부터 상기 모션 데이터를 생성하는 모션 생성 장치."}
{"patent_id": "10-2025-0019218", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4 항에 있어서,상기 적어도 하나의 프로세서는,모션 후처리 모듈을 이용하여, 상기 모션 데이터를 후처리하여 상기 보정 모션 데이터를 획득하고,상기 모션 후처리 모듈은,필터링 기반 부자연 동작 개선 모듈, 인공 지능 기반 부자연 동작 모듈 또는 물리 엔진 기반 부자연 동작 개선모듈 중 적어도 하나를 포함하는 모션 생성 장치.공개특허 10-2025-0053787-3-청구항 6 제5 항에 있어서,상기 적어도 하나의 프로세서는,상기 생성된 모션 데이터를 분석하여, 상기 모션 데이터의 후처리 정도를 포함하는 후처리 정보를 획득하고, 상기 획득한 후처리 정보를 이용하여 상기 생성된 모션 데이터를 후처리하여 상기 보정 모션 데이터를 획득하는모션 생성 장치."}
{"patent_id": "10-2025-0019218", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "텍스트를 포함하는 입력 정보에 기초하여 모션을 생성하는 모션 생성 장치의동작 방법에 있어서,캐릭터의 움직임을 나타내는 상기 텍스트를 포함하는 상기 입력 정보를 획득하는 단계;상기 획득한 입력 정보의 특징 정보를 추출하는 단계;상기 추출된 특징 정보를 이용하여, 상기 캐릭터의 상기 움직임에 대한 모션 데이터를 생성하는 단계;상기 생성된 모션 데이터를 후처리하여, 보정 모션 데이터를 획득하는 단계; 및상기 획득된 보정 모션 데이터에 기초하여, 상기 캐릭터의 모션 애니메이션을 생성하는 단계를 포함하는 모션생성 장치의 동작 방법."}
{"patent_id": "10-2025-0019218", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7 항에 있어서,상기 입력 정보는, 상기 캐릭터의 상기 움직임과 관련된 컨트롤 요소를 더 포함할 수 있고, 상기 컨트롤요소는, 오디오, 감정(emotion), 상기 움직임의 스타일, 이미지, 포즈 또는 비디오 중 적어도 하나를 포함하며,상기 모션 데이터를 생성하는 단계에서는, 상기 텍스트 및 상기 컨트롤 요소로부터 추출된 상기 특징 정보로부터, 상기 캐릭터의 상기 움직임에 대한 상기 모션 데이터를 추론하도록 학습된 인공 지능 모델을 이용하여, 상기 특징 정보로부터 상기 모션 데이터를 생성하는 모션 생성 장치의 동작 방법."}
{"patent_id": "10-2025-0019218", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8 항에 있어서,상기 보정 모션 데이터를 획득하는 단계에서는, 모션 후처리 모듈을 이용하여 상기 모션 데이터를 후처리하여상기 보정 모션 데이터를 획득하고,상기 모션 후처리 모듈은, 필터링 기반 부자연 동작 개선 모듈, 인공 지능 기반 부자연 동작 모듈 또는 물리 엔진 기반 부자연 동작 개선 모듈 중 적어도 하나를 포함하는 모션 생성 장치의 동작 방법."}
{"patent_id": "10-2025-0019218", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "컴퓨터와 결합되어, 제7 내지 제9 항 중 어느 하나의 항의 방법을 실행시키기 위한 프로그램이 저장된 컴퓨터판독 가능한 기록매체."}
{"patent_id": "10-2025-0019218", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 개시의 일 실시예는, 텍스트를 포함하는 입력 정보에 기초하여 모션을 생성하는 모션 생성 장치 및 모션 생성 장치의 동작 방법을 개시한다. 모션 생성 장치는 적어도 하나의 명령어(instruction)를 저장하는 메모리 및 메모 리에 저장된 적어도 하나의 명령어를 실행하는 적어도 하나의 프로세서를 포함하고, 적어도 하나의 프로세서는, 캐릭터의 움직임을 나타내는 텍스트를 포함하는 입력 정보를 획득하고, 획득한 입력 정보로부터 특징 정보를 추 출하고, 추출된 특징 정보를 이용하여 캐릭터의 움직임에 대한 모션 데이터를 생성하고, 생성된 모션 데이터를 후처리하여 보정 모션 데이터를 획득하고, 획득된 보정 모션 데이터에 기초하여 캐릭터의 모션 애니메이션을 생 성할 수 있다."}
{"patent_id": "10-2025-0019218", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 모션 생성 장치에 관한 것으로, 보다 구체적으로는 텍스트를 포함하는 입력 정보에 기초하여 모션을 생성하는 모션 생성 장치 및 그의 동작 방법에 관한 것이다."}
{"patent_id": "10-2025-0019218", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "최근 들어, 기술의 발전에 따라, 텍스트의 내용 또는 텍스트의 문맥 등을 고려하여, 텍스트로부터 특징을 추출 하여 아바타 등의 캐릭터의 모션을 추정하거나 혹은 텍스트에 포함된 동작을 수행하는 캐릭터의 모션을 생성하는 기술이 이용되고 있다. 그러나, 텍스트의 입력 만으로는 생성하고자 하는 캐릭터의 모션을 모두 설명하기 어려운 경우가 존재할 수 있 다. 또한, 텍스트의 입력에 기초하여 생성된 캐릭터의 모션이 의도한 바와 다른 경우에 재차 수정된 텍스트를 입력하여 새로운 캐릭터 모션을 생성하더라도, 여전히 의도한 바와 다른 캐릭터의 모션이 생성되는 문제점이 있 었다. 선행기술문헌 특허문헌 (특허문헌 0001) 공개번호 제10-2023-0075998 호 (공개일자: 2023년 05월 31일)"}
{"patent_id": "10-2025-0019218", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "사용자가 상상한 동작을 텍스트를 입력하거나 또는 텍스트와 텍스트 이외의 컨트롤 요소를 추가로 입력하여, 상 상한 동작을 수행하는 캐릭터의 모션 애니메이션을 생성하고자 할 수 있다. 이때, 컨트롤 요소는 생성하고자 하 는 캐릭터의 동작에 대한 정보를 제공할 수 있는 요소일 수 있다. 또한, 입력된 텍스트 또는 텍스트와 컨트롤 요소에 의하여 생성된 모션 데이터를 분석하여, 모션 데이터가 필터 링되어야 할 부자연스러운 동작을 포함하거나, 물리 엔진을 기반할 때 부자연스러운 동작을 포함하거나, 혹은 학습된 인공 지능 모델에 따라 부자연스러운 동작을 포함한다고 판단되는 경우 해당 동작들을 제거하거나 개선 하는 후처리를 통하여 보정 모션 데이터를 생성할 수 있다. 보정 모션 데이터를 통하여 캐릭터의 모션 애니메이션을 생성할 수 있고, 이때에도 모션 애니메이션을 생성하고 자 하는 캐릭터를 선택하거나, 캐릭터에 적용할 모션 데이터를 선택하는 편집 기능을 제공할 수도 있다. 본 개시가 해결하고자 하는 과제들은 이상에서 언급된 과제로 제한되지 않으며, 언급되지 않은 또 다른 과제들 은 아래의 기재로부터 통상의 기술자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2025-0019218", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상술한 기술적 과제를 달성하기 위한 본 개시에 따르면, 텍스트를 포함하는 입력 정보에 기초하여 모션을 생성 하는 모션 생성 장치가 제공될 수 있다. 모션 생성 장치는 적어도 하나의 명령어(instruction)를 저장하는 메모 리를 포함할 수 있다. 모션 생성 장치는 메모리에 저장된 적어도 하나의 명령어를 실행하는 적어도 하나의 프로 세서를 포함할 수 있다. 적어도 하나의 프로세서는, 캐릭터의 움직임을 나타내는 텍스트를 포함하는 입력 정보 를 획득할 수 있다. 적어도 하나의 프로세서는, 획득한 입력 정보로부터 특징 정보를 추출할 수 있다. 적어도 하나의 프로세서는, 추출된 특징 정보를 이용하여 캐릭터의 움직임에 대한 모션 데이터를 생성할 수 있다. 적어 도 하나의 프로세서는, 생성된 모션 데이터를 후처리하여 보정 모션 데이터를 획득할 수 있다. 적어도 하나의 프로세서는, 획득된 보정 모션 데이터에 기초하여 캐릭터의 모션 애니메이션을 생성할 수 있다. 또한, 본 개시에 따르면, 텍스트를 포함하는 입력 정보에 기초하여 모션을 생성하는 모션 생성 장치의 동작 방 법이 개시될 수 있다. 모션 생성 장치의 동작 방법은 캐릭터의 움직임을 나타내는 텍스트를 포함하는 입력 정보 를 획득하는 단계를 포함할 수 있다. 모션 생성 장치의 동작 방법은 획득한 입력 정보의 특징 정보를 추출하는 단계를 포함할 수 있다. 모션 생성 장치의 동작 방법은 추출된 특징 정보를 이용하여, 캐릭터의 움직임에 대한 모션 데이터를 생성하는 단계를 포함할 수 있다. 모션 생성 장치의 동작 방법은 생성된 모션 데이터를 후처리하 여, 보정 모션 데이터를 획득하는 단계를 포함할 수 있다. 모션 생성 장치의 동작 방법은 획득된 보정 모션 데 이터에 기초하여, 캐릭터의 모션 애니메이션을 생성하는 단계를 포함할 수 있다. 이 외에도, 본 개시를 구현하기 위한 방법을 실행하기 위한 컴퓨터 프로그램을 기록하는 컴퓨터 판독 가능한 기 록 매체가 더 제공될 수 있다."}
{"patent_id": "10-2025-0019218", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 개시의 전술한 과제 해결 수단에 의하면, 모션 생성 장치는 텍스트 외에도 생성하고자 하는 캐릭터의 동작에 대한 추가 정보를 제공할 수 있는 컨트롤 요소를 입력하여, 의도하는 동작을 수행하는 캐릭터의 모션 애니메이 션을 생성할 수 있다. 또한, 캐릭터의 모션 애니메이션을 생성하는 과정에서 생성되는 모션 데이터를 분석하여, 부자연스러운 동작을 필터링하거나, 물리 엔진에 기반하여 개선하거나, 혹은 학습된 인공 지능 모델을 이용하여 개선할 수 있다. 또 한, 후처리 과정에서, 각각의 후처리 동작에서 사용되는 계수를 다르게 입력하여, 후처리되는 정도를 제어할 수 도 있다. 또한, 모션 애니메이션을 생성하고자 하는 캐릭터를 선택하거나, 적용할 모션 데이터를 선택하는 기능을 제공하 여, 사용자가 원하는 캐릭터의 모션 애니메이션을 생성할 수 있도록 하여, 사용자의 편의성을 향상시킬 수 있다. 본 개시의 효과들은 이상에서 언급된 효과로 제한되지 않으며, 언급되지 않은 또 다른 효과들은 아래의 기재로 부터 통상의 기술자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2025-0019218", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 개시 전체에 걸쳐 동일 참조 부호는 동일 구성요소를 지칭한다. 본 개시가 실시예들의 모든 요소들을 설명"}
{"patent_id": "10-2025-0019218", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "하는 것은 아니며, 본 개시가 속하는 기술분야에서 일반적인 내용 또는 실시예들 간에 중복되는 내용은 생략한 다. 명세서에서 사용되는 '부, 모듈, 부재, 블록'이라는 용어는 소프트웨어 또는 하드웨어로 구현될 수 있으며, 실시예들에 따라 복수의 '부, 모듈, 부재, 블록'이 하나의 구성요소로 구현되거나, 하나의 '부, 모듈, 부재, 블 록'이 복수의 구성요소들을 포함하는 것도 가능하다. 또한 어떤 부분이 어떤 구성요소를 \"포함\"한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다른 구성요소를 제외하는 것이 아니라 다른 구성요소를 더 포함할 수 있는 것을 의미한다. 제1, 제2 등의 용어는 하나의 구성요소를 다른 구성요소로부터 구별하기 위해 사용되는 것으로, 구성요소가 전 술된 용어들에 의해 제한되는 것은 아니다. 단수의 표현은 문맥상 명백하게 예외가 있지 않는 한, 복수의 표현을 포함한다. 각 단계들에 있어 식별부호는 설명의 편의를 위하여 사용되는 것으로 식별부호는 각 단계들의 순서를 설명하는 것이 아니며, 각 단계들은 문맥상 명백하게 특정 순서를 기재하지 않는 이상 명기된 순서와 다르게 실시될 수 있다. 이하 첨부된 도면들을 참고하여 본 개시의 작용 원리 및 실시예들에 대해 설명한다. 본 명세서에서 '본 개시에 따른 장치'는 연산처리를 수행하여 사용자에게 결과를 제공할 수 있는 다양한 장치들 이 모두 포함된다. 예를 들어, 본 개시에 따른 장치는, 컴퓨터, 서버 장치 및 휴대용 단말기를 모두 포함하거나, 또는 어느 하나의 형태가 될 수 있다. 여기에서, 상기 컴퓨터는 예를 들어, 웹 브라우저(WEB Browser)가 탑재된 노트북, 데스크톱(desktop), 랩톱 (laptop), 태블릿 PC, 슬레이트 PC 등을 포함할 수 있다. 상기 서버 장치는 외부 장치와 통신을 수행하여 정보를 처리하는 서버로써, 애플리케이션 서버, 컴퓨팅 서버, 데이터베이스 서버, 파일 서버, 게임 서버, 메일 서버, 프록시 서버 및 웹 서버 등을 포함할 수 있다. 상기 휴대용 단말기는 예를 들어, 휴대성과 이동성이 보장되는 무선 통신 장치로서, PCS(Personal Communication System), GSM(Global System for Mobile communications), PDC(Personal Digital Cellular), PHS(Personal Handyphone System), PDA(Personal Digital Assistant), IMT(International Mobile Telecommunication)-2000, CDMA(Code Division Multiple Access)-2000, W-CDMA(W-Code Division Multiple Access), WiBro(Wireless Broadband Internet) 단말, 스마트 폰(Smart Phone) 등과 같은 모든 종류의 핸드헬드 (Handheld) 기반의 무선 통신 장치와 시계, 반지, 팔찌, 발찌, 목걸이, 안경, 콘택트 렌즈, 또는 머리 착용형 장치(head-mounted-device(HMD) 등과 같은 웨어러블 장치를 포함할 수 있다. 본 개시에 따른 인공 지능과 관련된 기능은 프로세서와 메모리를 통해 동작된다. 프로세서는 하나 또는 복수의 프로세서로 구성될 수 있다. 이때, 하나 또는 복수의 프로세서는 CPU, AP, DSP(Digital Signal Processor) 등 과 같은 범용 프로세서, GPU, VPU(Vision Processing Unit)와 같은 그래픽 전용 프로세서 또는 NPU와 같은 인 공 지능 전용 프로세서일 수 있다. 하나 또는 복수의 프로세서는, 메모리에 저장된 기 정의된 동작 규칙 또는 인공 지능 모델에 따라, 입력 데이터를 처리하도록 제어한다. 또는, 하나 또는 복수의 프로세서가 인공 지능 전 용 프로세서인 경우, 인공 지능 전용 프로세서는, 특정 인공 지능 모델의 처리에 특화된 하드웨어 구조로 설계 될 수 있다. 기 정의된 동작 규칙 또는 인공 지능 모델은 학습을 통해 만들어진 것을 특징으로 한다. 여기서, 학습을 통해 만들어진다는 것은, 기본 인공 지능 모델이 학습 알고리즘에 의하여 다수의 학습 데이터들을 이용하여 학습됨으 로써, 원하는 특성(또는, 목적)을 수행하도록 설정된 기 정의된 동작 규칙 또는 인공 지능 모델이 만들어짐을 의미한다. 이러한 학습은 본 개시에 따른 인공 지능이 수행되는 기기 자체에서 이루어질 수도 있고, 별도의 서 버 및/또는 시스템을 통해 이루어 질 수도 있다. 학습 알고리즘의 예로는, 지도형 학습(supervised learning), 비지도 형 학습(unsupervised learning), 준지도형 학습(semi-supervised learning) 또는 강화 학습 (reinforcement learning)이 있으나, 전술한 예에 한정되지 않는다. 도 1은 본 개시의 일 실시예에 따른 모션 생성 장치의 구성을 도시한 블록도이다. 일 실시예에서, 모션 생성 장치는 캐릭터의 움직임을 나타내는 텍스트를 포함하는 입력 정보를 제공받아, 입력 정보에 기초하여 캐릭터의 모션 애니메이션을 생성하는 장치일 수 있다. 일 실시예에서, 모션 생성 장치 를 이용하여, 생성하고자 하는 캐릭터의 움직임을 텍스트 또는 텍스트와 추가 컨트롤 요소(예를 들어, 캐 릭터의 움직임과 관련된 오디오, 이미지, 비디오, 포즈, 감정, 스타일 등)을 입력하여, 캐릭터의 모션 애니메이 션을 생성할 수 있다. 이때, 캐릭터는 사람, 동물, 소설이나 만화의 등장인물, 아바타, 게임의 등장 인물 등 움직임을 가질 수 있는 객체일 수 있고, 어느 하나로 제한되지 않는다. 모션 애니메이션은, 캐릭터와 캐릭터의 움직임을 나타낼 수 있 는 동영상 또는 적어도 하나의 이미지 등을 의미할 수 있다. 도 1을 참조하면, 일 실시예에서, 모션 생성 장치는 디스플레이, 메모리, 적어도 하나의 프로세 서, 입/출력 인터페이스부 및 통신 인터페이스부를 포함할 수 있다. 다만, 도 1에 도시된 구성 요소들은 본 개시에 따른 모션 생성 장치를 구현하는데 필수적인 것은 아니다. 일 실시예에서, 본 명세서 상에서 설명되는 모션 생성 장치는 위에서 열거된 구성 요소들보다 많거나, 혹은 적은 구성 요소들을 가질 수도 있다. 디스플레이, 메모리 및 적어도 하나의 프로세서, 입/출력 인터페이스부 및 통 신 인터페이스부는 각각 전기적 및/또는 물리적으로 서로 연결될 수 있다. 일 실시예에서, 디스플레이는 모션 생성 장치에서 처리되거나 생성되는 정보를 표시할 수 있다. 디스 플레이는 모션 생성 장치에서 제공되는 입력 인터페이스를 표시할 수 있다. 일 실시예에서, 디스플레이는 모션 생성 장치에서 구동되는 응용 프로그램의 실행화면 정보, 또는 이 러한 실행화면 정보에 따른 UI(User Interface), GUI(Graphic User Interface) 정보를 표시할 수 있다. 일 실시예에서, 적어도 하나의 프로세서는 UI 또는 GUI를 표시하도록 디스플레이를 제어하여, 모션 생성 장치를 사용하는 사용자에게 입력 인터페이스를 제공할 수 있다. 사용자는 디스플레이에 표시되 는 입력 인터페이스를 통하여 모션 생성 장치에 캐릭터의 움직임을 나타내는 텍스트, 캐릭터의 움직임과 관련된 컨트롤 요소 또는 후처리 정보 등을 제공할 수 있다. 일 실시예에서, 적어도 하나의 프로세서는 입력 정보에 기초하여 생성한 모션 데이터 또는 캐릭터의 모션 애니메이션를 표시하도록 디스플레이를 제어할 수 있다. 일 실시예에서, 적어도 하나의 프로세서는 생성된 모션 데이터 또는 캐릭터의 모션 애니메이션를 디스플레이를 통하여 사용자에게 제공할 수 있다. 사용자는 디스플레이에 표시되는 모션 데이터 또는 캐릭터의 모션 애니메이션을 통하여, 후처리 정보를 입 력하거나, 캐릭터의 모션 애니메이션의 생성을 종료할 수 있다. 다만, 본 개시는 이에 제한되지 않고, 모션 생성 장치는 디스플레이를 포함하지 않을 수도 있다. 모 션 생성 장치는 후술할 입/출력 인터페이스부 또는 통신 인터페이스부를 통하여 획득한 입력 정 보에 기초하여 모션 애니메이션을 생성할 수도 있다. 일 실시예에서, 메모리는 모션 생성 장치의 다양한 기능을 지원하는 데이터와, 적어도 하나의 프로세 서의 동작을 위한 프로그램을 저장할 수 있고, 입/출력되는 데이터들(예를 들어, 문장, 음악 파일, 정지 영상, 동영상 등)을 저장할 있고, 본 장치에서 구동되는 다수의 응용 프로그램(application program 또는 애플 리케이션(application)), 본 장치의 동작을 위한 적어도 하나의 데이터들, 적어도 하나의 명령어(instruction) 를 저장할 수 있다. 일 실시예에서, 메모리에는 텍스트를 포함하는 입력 정보에 기초하여 모션을 생성하는 동작을 수행하기 위 한 입력 정보 전처리 모듈, 모션 생성 모듈, 모션 후처리 모듈 및 모션 렌더링 모듈을 포 함할 수 있다. 메모리에 포함되는 '모듈'은 적어도 하나의 프로세서에 의해 수행되는 기능이나 동작 을 처리하는 단위를 의미할 수 있다. 메모리에 포함되는 '모듈'은 명령어들(instructions), 알고리즘, 또 는 프로그램 코드와 같은 소프트웨어로 구현될 수 있다. 이러한 응용 프로그램 중 적어도 일부는, 무선 통신을 통해 외부 서버로부터 다운로드 될 수 있다. 일 실시예에서, 각각의 입력 정보 전처리 모듈, 모션 생성 모듈, 모션 후처리 모듈 및 모션 렌 더링 모듈은, 각각의 동작을 수행하도록 미리 학습된 인공 지능 모델을 포함할 수 있다. 인공 지능 모델은 복수의 신경망 레이어들로 구성될 수 있다. 복수의 신경망 레이어들 각각은 복수의 가중치들 (weight values)을 갖고 있으며, 이전(previous) 레이어의 연산 결과와 복수의 가중치들 간의 연산을 통해 신경 망 연산을 수행한 다. 복수의 신경망 레이어들이 갖고 있는 복수의 가중치들은 인공 지능 모델의 학습 결과에 의해 최적화될 수 있다. 예를 들어, 학습 과정 동안 인공 지능 모델에서 획득한 로스(loss) 값 또는 코스트(cost) 값이 감소 또는 최소화되도록 복수의 가중치들이 갱신될 수 있다. 인공 신경망은 심층 신경망(DNN: Deep Neural Network)를 포 함할 수 있으며, 예를 들어, CNN (Convolutional Neural Network), DNN (Deep Neural Network), RNN (Recurrent Neural Network), RBM (Restricted Boltzmann Machine), DBN (Deep Belief Network), BRDNN(Bidirectional Recurrent Deep Neural Network), 트랜스포머(Transformer), 심층 Q-네트워크 (Deep Q- Networks) 또는 부스팅(Boosting) 알고리즘 등이 있으나, 전술한 예에 한정되지 않는다. 각각의 모듈들(121, 122, 123, 124)은 해당 동작을 수행하기 위하여 미리 학습된 모델을 전이 학습(Transfer Learning) 및 파인 튜닝을 통하여 최적화된 인공 지능 모델을 포함할 수도 있다. 이러한, 메모리는 플래시 메모리 타입(flash memory type), 하드디스크 타입(hard disk type), SSD 타입 (Solid State Disk type), SDD 타입(Silicon Disk Drive type), 멀티미디어 카드 마이크로 타입(multimedia card micro type), 카드 타입의 메모리(예를 들어 SD 또는 XD 메모리 등), 램(random access memory; RAM), SRAM(static random access memory), 롬(read-only memory; ROM), EEPROM(electrically erasable programmable read-only memory), PROM(programmable read-only memory), 자기 메모리, 자기 디스크 및 광디스 크 중 적어도 하나의 타입의 저장매체를 포함할 수 있다. 또한, 메모리는 모션 생성 장치와는 분리되어 있 으나, 유선 또는 무선으로 연결된 데이터베이스가 될 수도 있다. 일 실시예에서, 적어도 하나의 프로세서는 CPU, AP, DSP(Digital Signal Processor) 등과 같은 범용 프로 세서, GPU, VPU(Vision Processing Unit)와 같은 그래픽 전용 프로세서 또는 NPU와 같은 인공 지능 전용 프로 세서일 수 있다. 적어도 하나의 프로세서는 메모리에 저장된 명령어들 또는 또는 인공 지능 모델에 따라, 환자 관련 정보를 처리하도록 제어한다. 또는, 적어도 하나의 프로세서가 인공 지능 전용 프로세서인 경우, 인공 지능 전용 프로세서는, 특정 인공 지능 모델의 처리에 특화된 하드웨어 구조로 설계될 수 있다. 일 실시예에서, 적어도 하나의 프로세서는 모션 생성 장치의 전반적인 동작들을 제어할 수 있다. 일 실시예에서, 적어도 하나의 프로세서는 메모리에 저장된 적어도 하나 이상의 명령어를 실행하여, 모 션 생성 장치의 동작을 제어할 수 있다. 일 실시예에서, 적어도 하나의 프로세서는 메모리에 포 함된 입력 정보 전처리 모듈, 모션 생성 모듈, 모션 후처리 모듈 또는 모션 렌더링 모듈의 적어도 하나의 명령어들 또는 프로그램 코드를 실행함으로써 텍스트를 포함하는 입력 정보에 기초하여 모션을 생성하는 동작을 수행할 수 있다. 일 실시예에서, 입/출력 인터페이스부는 사용자 또는 외부로부터 정보를 입력받거나, 혹은 외부로 정보를 제공하기 위한 것으로서, 입/출력 인터페이스부를 통해 입력 정보가 입력되면, 적어도 하나의 프로세서 는 입력 정보에 기초하여 모션을 생성하도록 모션 생성 장치를 제어할 수 있다. 또한, 모션 생성 장 치는 생성된 모션을 입/출력 인터페이스부를 통하여 주변 전자 장치로 제공할 수도 있다. 일 실시예에서, 입/출력 인터페이스부는 디스플레이를 통하여 표시될 수도 있다. 또한, 입/출력 인터 페이스부는 마우스(mouse), 키보드(keyboard) 등의 장치를 포함할 수 있다. 일 실시예에서, 사용자는 키보 드 등을 이용하여 텍스트를 포함하는 입력 정보를 입력하고, 디스플레이를 통하여 생성된 모션을 제공받을 수도 있다. 또한, 입/출력 인터페이스부는 마이크 등의 음성 입력 인터페이스를 포함할 수 있다. 일 실시예에서, 사용 자는 마이크 등을 이용하여 컨트롤 요소를 입력할 수도 있다. 일 실시예에서 통신 인터페이스부는 외부의 서버 또는 주변의 다른 전자 장치들과 모션 생성 장치 간 의 데이터 통신을 수행할 수 있다. 일 실시예에서, 통신 인터페이스부는 외부의 서버 또는 주변의 다른 전자 장치들과 통신을 가능하게 하는 하나 이상의 구성 요소를 포함할 수 있으며, 예를 들어, 무선 통신 모듈, 근거리 통신 모듈, 위치 정보 모듈 중 적어도 하나를 포함할 수 있다. 무선 통신 모듈은 와이파이(Wifi) 모듈, 와이브로(Wireless broadband) 모듈 외에도, GSM(global System for Mobile Communication), CDMA(Code Division Multiple Access), WCDMA(Wideband Code Division Multiple Access), UMTS(universal mobile telecommunications system), TDMA(Time Division Multiple Access), LTE(Long Term Evolution), 4G, 5G, 6G 등 다양한 무선 통신 방식을 지원하는 무선 통신 모듈을 포함할 수 있 다. 무선 통신 모듈은 데이터 신호를 송신하는 안테나 및 송신기(Transmitter)를 포함하는 무선 통신 인터페이스를 포함할 수 있다. 또한, 무선 통신 모듈은 적어도 하나의 프로세서의 제어에 따라 무선 통신 인터페이스를 통해 적어도 하나의 프로세서로부터 출력된 디지털 제어 신호를 아날로그 형태의 무선 신호로 변조하는 데 이터 신호 변환 모듈을 더 포함할 수 있다. 무선 통신 모듈은 데이터 신호를 수신하는 안테나 및 수신기(Receiver)를 포함하는 무선 통신 인터페이스를 포 함할 수 있다. 또한, 무선 통신 모듈은 무선 통신 인터페이스를 통하여 수신한 아날로그 형태의 무선 신호를 디 지털 제어 신호로 복조하기 위한 데이터 신호 변환 모듈을 더 포함할 수 있다. 근거리 통신 모듈은 근거리 통신(Short range communication)을 위한 것으로서, 블루투스(Bluetooth™), RFID(Radio Frequency Identification), 적외선 통신(Infrared Data Association; IrDA), UWB(Ultra Wideband), ZigBee, NFC(Near Field Communication), Wi-Fi(Wireless-Fidelity), Wi-Fi Direct, Wireless USB(Wireless Universal Serial Bus) 기술 중 적어도 하나를 이용하여, 근거리 통신을 지원할 수 있다. 일 실시예에서, 모션 생성 장치는 통신 인터페이스부를 통하여 외부의 서버 또는 주변의 전자 장치와 통신을 수행할 수 있다. 일 실시예에서, 외부의 서버는 애플리케이션 서버, 컴퓨팅 서버, 데이터베이스 서버, 파일 서버, 게임 서버, 메일 서버, 프록시 서버 및 웹 서버 등을 포함할 수 있다. 일 실시예에서, 외부의 서버 또는 주변의 전자 장치에, 본 개시에 설명하는 텍스트를 포함하는 입력 정보에 기 초하여 모션을 생성하는 방법을 포함하는 모델이 포함되어 있을 수도 있다. 모션 생성 장치는 입/출력 인 터페이스부를 통하여 외부의 서버 또는 주변의 전자 장치로부터 텍스트를 포함하는 입력 정보에 기초하여 모션을 생성하는 방법을 포함하는 모델을 제공받을 수도 있다. 에 제공할 수 있다. 이하, 설명의 편의를 위하여, 텍스트를 포함하는 입력 정보에 기초하여 모션을 생성하는동작은 모션 생성 장치 에서 이루어지는 것으로 설명한다. 도 2는 본 개시의 일 실시예에 따른 모션 생성 장치의 동작을 설명하기 위한 순서도이다. 도 3은 본 개시의 일 실시예에 따른 모션 생성 장치의 동작을 설명하기 위한 도면이다. 도 2 및 도 3을 참조하면, 일 실시예에서, 모션 생성 장치의 동작 방법은 캐릭터의 움직임을 나타내는 텍 스트를 포함하는 입력 정보를 획득하는 단계(S100)를 포함할 수 있다. 일 실시예에서, 적어도 하나의 프로 세서는 입력 정보를 획득하는 단계(S100)에서 텍스트를 포함하는 입력 정보를 획득할 수 있다. 일 실시예에서, 텍스트는 캐릭터의 움직임을 나타낼 수 있다. 도 3에는 텍스트가 “a main is running”으로 도시되어 있다. 도 3에 도시된 텍스트는, “남자가 달리고 있다”라는 남자 캐릭터의 움직 임에 대한 정보를 포함할 수 있다. 일 실시예에서, 텍스트는 움직임의 주체와, 움직임의 내용에 대한 정보 가 포함될 수 있다. 다만, 본 개시는 이에 제한되지 않고, 텍스트는 다양한 캐릭터의 움직임에 대한 정보 를 포함할 수 있다. 일 실시예에서, 입력 정보에는 캐릭터의 움직임과 관련된 컨트롤 요소를 더 포함할 수 있다. 일 실시예에 서, 컨트롤 요소는 캐릭터의 움직임과 관련된 오디오, 감정(emotion), 움직임의 스타일, 이미지, 포즈 또 는 비디오 중 적어도 하나를 포함할 수 있다. 일 실시예에서, 컨트롤 요소에 포함된 오디오는 캐릭터의 목소리이거나, 혹은 무드를 나타내는 배경음악 등을 포함할 수 있다. 일 실시예에서, 컨트롤 요소에 포함된 감정은 캐릭터의 움직임에 영향을 줄 수 있는 감정 상태(예를 들어, 기쁨, 우울함, 자신감 넘치는 상태)를 포함할 수 있다. 일 실시예에서, 컨트롤 요소(31 0)에 포함된 움직임의 스타일은 캐릭터의 움직임의 스타일(예를 들어, 과장된 행동, 소녀같은 느낌 등)을 포함 할 수 있다. 일 실시예에서, 컨트롤 요소에 포함된 이미지는 특정 포즈를 취한 이미지나, 특정 분위기를 나타내는 이미지를 포함할 수 있다. 일 실시예에서, 컨트롤 요소에 포함된 포즈는 캐릭터의 움직임의 중간 에 취해야 하는 키프레임 포즈(예를 들어, 1초 경과 시에 박수를 취는 포즈, 3초 경과 시에 의자에 앉아있는 포 즈 등)를 포함할 수 있다. 일 실시예에서, 컨트롤 요소에 포함된 비디오는 참고가 될 사람 또는 동물의 행 동을 나타내는 동영상(예를 들어, 올림픽 체조 선수의 경기 영상)을 포함할 수 있다. 일 실시예에서, 모션 생성 장치의 동작 방법은 획득한 입력 정보의 특징 정보를 추출하는 단계(S200)를 포 함할 수 있다. 일 실시예에서, 적어도 하나의 프로세서는 입력 정보의 특징 정보를 추출하는 단계(S200)에 서, 입력 정보 전처리 모듈의 명령어들 또는 프로그램 코드를 실행함으로써, 입력 정보의 특징 정보를 추 출할 수 있다. 일 실시예에서, 입력 정보 전처리 모듈은 제공받은 입력 정보를 후술할 모션 생성 모듈을 이용하여 모션 데이터를 생성하기 위한 형태로 변환하는 동작이나 기능에 관한 명령어들 또는 프로그램 코드로 구성될 수 있다. 일 실시예에서, 입력 정보 전처리 모듈은 입력 정보를 이용하여 특징 정보를 추출하기 전에, 입력 정보에 포함된 노이즈를 제거하는 등의 전처리 동작을 수행하기 위한 명령어들 또는 프로그램 코드로 구성될 수 있다. 이하, 입력 정보 전처리 모듈에 대하여는 도 4에서 후술하도록 한다. 일 실시예에서, 모션 생성 장치의 동작 방법은 추출된 특징 정보를 이용하여, 캐릭터의 움직임에 대한 모 션 데이터를 생성하는 단계(S300)를 포함할 수 있다. 일 실시예에서, 적어도 하나의 프로세서는 모션 데이 터를 생성하는 단계(S300)에서, 모션 생성 모듈의 명령어들 또는 프로그램 코드를 실행함으로써, 캐릭터의 움직임에 대한 모션 데이터를 생성할 수 있다. 일 실시예에서, 모션 생성 모듈은 추출된 특징 정보를 이용하여 캐릭터의 움직임에 대한 모션 데이터를 생 성하는 동작이나 기능에 관한 명령어들 또는 프로그램 코드로 구성될 수 있다. 일 실시예에서, 모션 생성 모듈 은 특징 정보를 모션 데이터를 생성하기 위한 모션 특징값으로 변환하는 동작이나 기능에 관한 명령어들 또는 프로그램 코드로 구성될 수 있다. 일 실시예에서, 모션 생성 모듈은 변환된 모션 특징값을 이용하여 캐릭터의 위치에 대한 정보나 캐릭터의 관절의 각도에 대한 정보 등을 포함하는 모션 데이터를 생성하는 동작이 나 기능에 관한 명령어들 또는 프로그램 코드로 구성될 수 있다. 이하, 모션 생성 모듈에 대하여는 도 5에 서 후술하도록 한다. 일 실시예에서, 모션 생성 장치의 동작 방법은 생성된 모션 데이터를 후처리하여, 보정 모션 데이터를 획 득하는 단계(S400)를 포함할 수 있다. 일 실시예에서, 적어도 하나의 프로세서는 보정 모션 데이터를 획득하는 단계(S400)에서, 모션 후처리 모듈의 명령어들 또는 프로그램 코드를 실행함으로써, 생성된 모션 데 이터를 후처리하여 보정 모션 데이터를 획득할 수 있다. 일 실시예에서, 모션 후처리 모듈은 생성된 모션 데이터를 후처리하여, 보정 모션 데이터를 획득하는 동작 이나 기능에 관한 명령어들 또는 프로그램 코드로 구성될 수 있다. 일 실시예에서, 모션 후처리 모듈은 생 성된 모션 데이터를 분석하여 획득된 모션 데이터의 후처리 정도를 포함하는 후처리 정보를 이용하여 생성된 모 션 데이터의 후처리 정도를 결정하고, 결정된 후처리 정도에 따라 모션 데이터를 후처리하여 보정 모션 데이터 를 획득할 수 있다. 일 실시예에서, 모션 생성 장치는 모션 후처리 모듈을 통하여, 캐릭터의 모션 애 니메이션을 생성하는 과정에서, 사용자에게 캐릭터 모션 애니메이션을 편집하는 기능을 제공할 수도 있다. 이하, 편집 기능은 모션 데이터의 후처리를 통하여 이루어질 수도 있다. 일 실시예에서, 모션 후처리 모듈은 필터링 기반 부자연 동작 개선 모듈, 인공 지능 기반 부자연 동작 모 듈 또는 물리 엔진 기반 부자연 동작 개선 모듈 중 적어도 하나를 포함할 수 있다. 이하, 모션 후처리 모듈 에 대하여는 도 6 내지 도 9에서 후술하도록 한다. 일 실시예에서, 모션 생성 장치의 동작 방법은 획득된 보정 모션 데이터에 기초하여, 캐릭터의 모션 애니 메이션을 생성하는 단계(S500)를 포함할 수 있다. 캐릭터의 모션 애니메이션을 생성하는 단계(S500)에서, 획득 된 보정 모션 데이터를 렌더링하여 모션 애니메이션을 생성할 수 있다. 일 실시예에서, 적어도 하나의 프로세서는 캐릭터의 모션 애니메이션을 생성하는 단계(S500)에서, 모션 렌 더링 모듈의 명령어들 또는 프로그램 코드를 실행함으로써, 획득된 보정 모션 데이터를 렌더링하여 모션 애니메이션을 생성할 수 있다. 일 실시예에서, 모션 렌더링 모듈은 획득된 보정 모션 데이터를 이용하여, 캐릭터에 보정 모션 데이터를 렌더링하여 캐릭터의 모션 애니메이션을 생성하는 동작이나 기능에 관한 명령어들 또는 프로그램 코드로 구성될 수 있다. 다만, 본 개시는 이에 제한되지 않고, 모션 생성 모듈을 이용하여 생성된 모션 데이터가 후처리 가 필요하지 않다고 판단되는 경우, 모션 렌더링 모듈은 모션 데이터를 이용하여 캐릭터에 모션 데이터를 렌더링하여 캐릭터의 모션 애니메이션을 생성하는 동작이나 기능에 관한 명령어들 또는 프로그램 코드로 구성될 수 있다. 이하, 모션 렌더링 모듈에 대하여는 도 10에서 후술하도록 한다. 일 실시예에서, 적어도 하나의 프로세서는 생성된 모션 애니메이션의 결과에 기초하여, 입정 정보 전처리 모듈을 통하여 입력 정보의 특징 정보를 추출하는 동작, 모션 후처리 모듈을 통하여 보정 모션 데이 터를 획득하는 동작 또는 모션 렌더링 모듈을 통하여 모션 애니메이션을 생성하는 동작 중 적어도 하나의 동작을 재차 수행할 수 있다. 적어도 하나의 프로세서는 생성된 모션 애니메이션의 결과에 기초하여, 입정 정보 전처리 모듈을 통하여 입력 정보의 특징 정보를 추출하는 동작, 모션 후처리 모듈을 통하여 보 정 모션 데이터를 획득하는 동작 또는 모션 렌더링 모듈을 통하여 모션 애니메이션을 생성하는 동작 중 적 어도 하나의 동작을 수행할 때 사용되는 계수를 변경하며 적절한 모션 애니메이션이 생성되도록 동작을 반복할 수 있다. 도 4는 본 개시의 일 실시예에 따른 입력 정보 전처리 모듈의 동작을 설명하기 위한 도면이다. 도 1, 도 3 및 도 4를 참조하면, 일 실시예에서, 입력 정보 전처리 모듈은 텍스트 특징값 추출 모델, 각 컨트롤 요소 별 특징값 추출 모델 및 특징 퓨전 전처리 모델을 포함할 수 있다. 일 실시예에서, 텍스트 특징값 추출 모델은 획득된 텍스트에 포함된 캐릭터나, 캐릭터의 행동의 특징, 해당 텍스트가 생성된 의도 등을 파악하여 텍스트 특징값(feature value)을 추출할 수 있다. 일 실 시예에서, 텍스트 특징값 추출 모델에 텍스트가 입력으로 주어지면, 텍스트 특징값이 출력으로 생성 될 수 있다. 일 실시예에서, 각 컨트롤 요소 별 특징값 추출 모델은 획득된 컨트롤 요소에 포함된 정보를 추출할 수 있다. 일 실시예에서, 각 컨트롤 요소 별 특징값 추출 모델은 컨트롤 요소에 포함된 요소들의 종 류에 따라, 대응되는 정보를 추출할 수 있다. 일 실시예에서, 컨트롤 요소가 음악을 포함하는 경우, 각 컨 트롤 요소 별 특징값 추출 모델은 해당 음악의 분위기, 음악의 강도, 음악의 속도 등의 정보를 특징값으로 추출할 수 있다. 일 실시예에서, 각 컨트롤 요소 별 특징값 추출 모델에 컨트롤 요소가 입력으로 주 어지면, 각 컨트롤 요소 별 특징값이 출력으로 생성될 수 있다. 일 실시예에서, 텍스트 특징값 및 각 컨트롤 요소 별 특징값은 특징 정보로 지칭될 수도 있다. 입력 정보 전처리 모듈은 텍스트를 포함하는 입력 정보에 기초하여 특징 정보를 추출할 수 있다. 일 실시예에서, 특징 퓨전 전처리 모델은 텍스트 특징값 추출 모델에서 추출된 텍스트 특징값 및 각 컨트롤 요소 별 특징값 추출 모델에서 추출된 각 컨트롤 요소 별 특징값을 퓨전하여 합성 특징값을 생성할 수 있다. 일 실시예에서, 합성 특징값은 텍스트 특징값에 포함된 캐릭터나, 캐릭터의 행동의 특징 및 해당 텍스트가 생성된 의도와 각 컨트롤 요소 별 특징값에 포함된 컨트롤 요소의 정보를 포함할 수 있 다. 일 실시예에서, 텍스트 특징값 추출 모델은 획득된 텍스트에 포함된 캐릭터나, 캐릭터의 행동의 특징, 해당 텍스트가 생성된 의도 등을 파악하여 텍스트 특징값(feature value)을 추론하도록 미리 학습된 인공 지능 모델을 포함할 수 있다. 일 실시예에서, 각 컨트롤 요소 별 특징값 추출 모델은 획득된 컨트롤 요소에 따라, 각 컨트롤 요소 별 특징값을 추론하도록 미리 학습된 인공 지능 모델을 포함할 수 있다. 일 실시예에서, 특징 퓨전 전처리 모델은 텍스트 특징값 및 각 컨트롤 요소 별 특징값을 퓨전하여 합성 특징값을 추론하도록 미리 학습된 인공 지능 모델을 포함할 수 있다. 일 실시예에서, 텍스트 특징값 추출 모델은 Seq2Seq 모델, BERT(Bidirectional Encoder Representations from Transforemrs), CNN, RNN, Attention 매커니즘 등을 포함할 수 있고, 어느 하나로 제한되지 않는다. 일 실시예에서, 각 컨트롤 요소 별 특징값 추출 모델은 2D CNN, 3D CNN, Optical Flow-based 모델 등을 포함 할 수 있고, 어느 하나로 제한되지 않는다. 일 실시예에서, 특징 퓨전 전처리 모델은 Attention 매커니즘, Multi-modal 모델(예를 들어, Early Fusion, Late Fusion) 등을 포함할 수 있고, 어느 하나로 제한되지 않는다. 도 5는 본 개시의 일 실시예에 따른 모션 생성 모듈의 동작을 설명하기 위한 도면이다. 도 1, 도 3 및 도 5를 참조하면, 일 실시예에서, 모션 생성 모듈은 모션 특징값 매핑 모델 및 모션 특징값 기반 모션 생성 모델을 포함할 수 있다. 일 실시예에서, 모션 특징값 매핑 모델은 생성된 특징 정보를 모션 데이터를 생성하기 위한 모션 특징값으 로 매핑할 수 있다. 일 실시예에서, 모션 특징값 매핑 모델은 합성 특징값을 모션 데이터를 생성하기 위한 모션 특징값으로 변환할 수 있다. 일 실시예에서, 모션 특징값 매핑 모델은 합성 특징값을 모션 특징값으로 변환하는 과정에서, 컨트롤 특징값을 이용할 수 있다. 컨트롤 특징값에 따라 합성 특징값 을 모션 특징값으로 매핑하는 과정에서, 매핑되는 모션 특징값이 변경될 수 있다. 일 실시예에서, 모션 특징값 기반 모션 생성 모델은 모션 특징값 매핑 모델을 통하여 매핑된 모션 특 징값을 이용하여 모션 데이터를 생성할 수 있다. 일 실시예에서, 모션 데이터는 캐릭터의 위치, 캐릭 터에 포함된 복수의 관절들의 위치, 복수의 관절들 간의 각도 등에 대한 정보를 포함할 수 있다. 일 실시예에서, 모션 데이터는 2D에서의 캐릭터의 모션 정보뿐만 아니라, 3D에서의 캐릭터의 모션 정보도 포 함할 수 있다. 일 실시예에서, 모션 데이터는 복수의 프레임들에 걸친 캐릭터의 모션 정보를 포함할 수 있다. 일 실시예에서, 모션 특징값 매핑 모델은 생성된 합성 특징값 또는 합성 특징값과 컨트롤 특징 값을 모션 데이터를 생성하기 위한 모션 특징값으로 매핑하도록 미리 학습된 인공 지능 모델을 포함 할 수 있다. 일 실시예에서, 모션 특징값 기반 모션 생성 모델은 모션 특징값 매핑 모델을 통하여 매 핑된 모션 특징값을 이용하여 모션 데이터를 추론하도록 미리 학습된 인공 지능 모델을 포함할 수 있다. 일 실시예에서, 모션 특징값 매핑 모델 및 모션 특징값 기반 모션 생성 모델은 합성 특징값또는 합성 특징값과 컨트롤 특징값에 기초하여 모션 데이터를 추론하도록 함께 미리 학습된 인공 지 능 모델을 포함할 수 있다. 일 실시예에서, 모션 데이터를 생성하는 단계(S300)에서는, 텍스트 및 컨트롤 요소로부터 추출 된 특징 정보로부터, 캐릭터의 움직임에 대한 모션 데이터를 추론하도록 학습된 인공 지능 모델을 이용하 여, 특징 정보로부터 모션 데이터를 생성할 수 있다. 일 실시예에서, 모션 특징값 매핑 모델 및 모션 특징값 기반 모션 생성 모델은 Seq2Seq, CNN, RNN, LSTM(Long Short-Term Memory) 또는 트랜스포머(Transformer) 등을 포함할 수 있다. 일 실시예에서, 모션 특징 값 매핑 모델은 인코더(Encoder)로서 생성된 합성 특징값 또는 합성 특징값과 컨트롤 특징값 을 모션 특징값으로 변환하도록 미리 학습된 것일 수 있다. 모션 특징값 기반 모션 생성 모델은 생성 모델(Generative Model)로서 변환된 모션 특징값을 이용하여 모션 데이터를 추론하도록 미리 학습된 것일수 있다. 다만, 이는 일 예시로서, 모션 특징값 매핑 모델 및 모션 특징값 기반 모션 생성 모델은 어 느 하나로 제한되지 않는다. 일 실시예에서, 입력 정보 전처리 모듈 및 모션 생성 모듈은 캐릭터의 움직임을 나타내는 텍스트와 해당 텍스트에 대응되는 캐릭터의 모션 데이터의 훈련 데이터 세트에 의하여, 텍스트가 제공될 경우, 대응되는 캐릭터의 모션 데이터가 추론되도록 미리 학습된 인공 지능 모델을 포함할 수 있다. 일 실시예에서, 입력 정보 전처리 모듈은 미리 학습된 내용에 따라, 입력된 텍스트를 대응되는 모션 데이터를 생성하기 위하여 필요 한 특징 정보로 추출할 수 있다. 모션 생성 모듈은 추출된 특징 정보에 기초하여 모션 데이터를 추론 할 수도 있다. 도 6은 본 개시의 일 실시예에 따른 모션 후처리 모듈의 동작을 설명하기 위한도면이다. 도 1, 도 3 및 도 6을 참조하면, 일 실시예에서, 모션 후처리 모듈은 모션 데이터에 포함된 부자연스 러운 동작을 제거하거나, 혹은 자연스러운 동작으로 변경하는 후처리를 통하여 보정 모션 데이터를 생성할 수 있다. 일 실시예에서, 도 6에는 모션 후처리 모듈이 필터링 기반 부자연 동작 개선 모듈, 인공 지능 모델 기반 부자연 동작 개선 모듈 및 물리 엔진 기반 부자연 동작 개선 모듈을 모두 포함하는 것으로 도시되어 있으나, 본 개시는 이에 제한되지 않는다. 모션 후처리 모듈은 필터링 기반 부자연 동작 개선 모 듈, 인공 지능 모델 기반 부자연 동작 개선 모듈 또는 물리 엔진 기반 부자연 동작 개선 모듈 중 적어도 하나를 포함할 수 있다. 또한, 도 6에는 모션 후처리 모듈에 포함된 필터링 기반 부자연 동작 개선 모듈, 인공 지능 모델 기 반 부자연 동작 개선 모듈 및 물리 엔진 기반 부자연 동작 개선 모듈에 의하여 순차적으로 모션 데이 터의 후처리 동작이 이루어지는 것으로 도시되었으나, 본 개시는 이에 제한되지 않는다. 필터링 기반 부자 연 동작 개선 모듈, 인공 지능 모델 기반 부자연 동작 개선 모듈 및 물리 엔진 기반 부자연 동작 개 선 모듈은 서로 병렬적으로 동작할 수도 있다. 또한, 필터링 기반 부자연 동작 개선 모듈, 인공 지능 모델 기반 부자연 동작 개선 모듈 및 물리 엔진 기반 부자연 동작 개선 모듈의 동작 순서는 서로 달 라질 수도 있다. 도 7는 본 개시의 일 실시예에 따른 필터링 기반의 부자연 동작 개선 모듈의 동작을 설명하기 위한 도면이다. 이하, 도 6에서 설명한 구성과 동일한 구성에 대하여는 동일한 도면 부호를 부여하고, 중복되는 설명은 생략하 도록 한다. 도 1, 도 3, 도 6 및 도 7을 참조하면, 일 실시예에서, 필터링 기반의 부자연 동작 개선 모듈은 생성된 모 션 데이터를 후처리하여, 모션 데이터에 포함된 지터링(jittering) 현상, 발이 바닥에 접지되지 않거 나 미끄러지는 현상, 리타겟팅된 캐릭터의 비율이 달라, 메쉬(mesh)가 겹치는 현상 등의 오류를 제거하여 보정 모션 데이터를 획득할 수 있다. 이때, 모션 데이터는 입력 모션 시퀀스로 지칭될 수도 있고, 보정 모 션 시퀸스는 수정 모션 시퀀스로 지칭될 수도 있다. 일 실시예에서, 필터링 기반의 부자연 동작 개선 모듈은 모션 데이터의 후처리 정도를 포함하는 후처리 정 보를 획득할 수 있다. 후처리 정보는, 생성된 모션 데이터를 분석하여, 모션 데이터에 포함된 노이즈의 정도나, 모션 데이터에 미리 설정된 특정 조건들(예를 들어, 필터링 기반의 부자연 동작 개선 모듈에서 필터링하는 것으로 설정된 조건들)이 포함되는지 여부를 반영하여 생성된 것일 수 있다. 일 실시예에서, 후처리 정보는 생 성된 모션 데이터 혹은 이전에 후처리가 완료된 보정 모션 데이터 또는 보정 모션 데이터를 이용하여 생성된 캐 릭터 모션 애니메이션을 분석하여 생성된 것일 수 있다. 일 실시예에서, 도 7에는 후처리 정보가 사용자 수정 정보로 도시되어 있다. 일 실시예에서, 후처리 정보는 입/출력 인터페이스부(예를 들어, 수정 계수 입력부 )를 통하여 획득한 사용자의 입력에 의하여 생성된 정보일 수도 있다. 이하, 설명의 편의를 위하여 후처리 정보를 사용자 수정 정보로 지칭하도록 한다. 일 실시예에서, 필터링 기반의 부자연 동작 개선 모듈은 수정 계수 입력부를 통하여 획득한 사용자 수정 정보를 통하여, 부자연 동작을 개선하기 위한 필터링 알고리즘의 계수들을 획득할 수 있다. 필터링 기반의 부자연 동작 개선 모듈은 수정 계수 변형을 통하여, 사용자 수정 정보를 통하여 획득한 필터링 알고리즘의 계수들을 각각의 필터링 알고리즘에 대응되는 형태로 변환할 수 있다. 일 실시예에서, 필터링 기반의 부자연 동작 개선 모듈은 조인트 그룹 부분 필터링 알고리즘을 통하여, 모션 데이터에 포함된 캐릭터의 스켈레톤 관절 중 부자연스러운 동작의 오류의 수정이 필요한 관 절을 지정할 수 있다. 일 실시예에서, 필터링 기반의 부자연 동작 개선 모듈은 지터링 오류 제거 알고리즘을 통하여, 모션 데이터 중 떨리는 현상이 발생하는 데이터를 제거할 수 있다. 일 실시예에서, 필터 링 기반의 부자연 동작 개선 모듈은 스무딩 오류 제거 알고리즘을 통하여, 모션 데이터에 포함 된 캐릭터의 모션의 동작을 부드럽게 하거나, 혹은 랜덤한 동작 정보를 추가할 수 있다. 일 실시예에서, 필터링 기반의 부자연 동작 개선 모듈은 풋 컨택트 오류 제거 알고리즘을 통하여, 모 션 데이터에 포함된 캐릭터의 발바닥의 좌표 정보와 바닥의 좌표 정보가 차이가 나는 경우, 해당 부분을 제거할 수 있다. 일 실시예에서, 필터링 기반의 부자연 동작 개선 모듈은 풋 슬라이딩 오류 제거 알 고리즘을 통하여, 모션 데이터에 포함된 캐릭터의 동작 중 바닥에서 미끌어지는 현상이 발생하는 부분을 제거할 수 있다. 일 실시예에서, 필터링 기반의 부자연 동작 개선 모듈은 조인트 비율 수정 알고리즘 을 통하여, 모션 데이터에 포함된 캐릭터의 스켈레톤 관절 중 부자연스러운 동작의 오류의 수정이 필요한 관절을 지정할 수 있다. 도 7에는 필터링 기반의 부자연 동작 개선 모듈이 조인트 그룹 부분 필터링 알고리즘, 지터링 오류 제거 알고리즘, 스무딩 오류 제거 알고리즘, 풋 컨택트 오류 제거 알고리즘, 풋 슬라이딩 오류 제거 알고리즘 및 조인트 비율 수정 알고리즘을 순차적으로 이용하는 것으로 도시되어 있으나, 본 개 시는 이에 제한되지 않는다. 필터링 기반의 부자연 동작 개선 모듈은 각각의 알고리즘들 중 적어도 하나의 알고리즘을 이용할 수 있고, 이용 순서는 달라질 수도 있다. 도 8은 본 개시의 일 실시예에 따른 인공 지능 모델 기반의 부자연 동작 개선 모듈의 동작을 설명하기 위한 도 면이다. 이하, 도 7에서 설명한 구성과 동일한 구성에 대하여는 동일한 도면 부호를 부여하고, 중복되는 설명은 생략하도록 한다. 도 1, 도 3 및 도 8을 참조하면, 일 실시예에서, 인공 지능 모델 기반의 부자연 동작 개선 모듈은 생성된 모션 데이터에 기초하여, 모션 생성 모듈을 통하여 부자연스러운 동작이 제거된 모션 데이터를 생성 하기 위하여, 모션 생성 모듈의 파라미터를 조절하는 동작을 수행할 수 있다. 일 실시예에서, 인공 지능 모델 기반 부자연 동작 개선 모듈은 수정 계수 입력부를 통하여 획득한 사 용자 수정 정보를 수정 계수 벡터화 알고리즘을 통하여, 통합이 가능한 벡터 형태로 변환할 수 있다. 이때, 통합이 가능한 벡터 형태란, 모션 생성 모듈을 이용하여 모션 데이터를 생성하기 위하여 변환된 모 션 데이터에 통합하기 위한 벡터 형태를 의미할 수 있다. 일 실시예에서, 인공 지능 모델 기반 부자연 동작 개선 모듈은 사용자 수정 정보에 기초하여, 조인트 그룹 지정을 통하여 모션 데이터에 포함된 캐릭터의 스켈레톤 관절 중 오류 수정이 필요한 스켈레톤 관절을 지정할 수 있다. 일 실시예에서, 인공 지능 모델 기반 부자연 동작 개선 모듈은 조인트 벡터 마스 킹을 통하여 오류 수정이 필요하다고 지정된 스켈레톤 관절의 조인트 정보를 나타내는 벡터를 마스킹할 수 있다. 일 실시예에서, 인공 지능 모델 기반 부자연 동작 개선 모듈은 수정 계수 통합을 통하여, 통합이 가 능한 벡터 형태로 변환된 사용자 수정 정보 및 오류 수정이 필요하다고 지정된 스켈레톤 관절의 조인트 정 보를 나타내는 벡터를 마스킹하는 것을 통합할 수 있다. 이를 통하여, 모션 생성 모듈에 제공하는 부자연 스러운 동작이 제거된 모션 데이터를 생성하기 위하여, 모션 생성 모듈의 파라미터를 조절할 수 있다. 모 션 생성 모듈은 조절된 파라미터를 이용하여, 특징 정보를 이용하여 부자연스러운 동작이 제거된, 보정 모 션 데이터를 생성할 수 있다. 도 9는 본 개시의 일 실시예에 따른 물리 엔진 기반의 부자연 동작 개선 모듈의 동작을 설명하기 위한 도면이다. 이하, 도 7에서 설명한 구성과 동일한 구성에 대하여는 동일한 도면 부호를 부여하고, 중복되는 설명 은 생략하도록 한다. 도 1, 도 3 및 도 8을 참조하면, 일 실시예에서, 물리 엔진 기반의 부자연 동작 개선 모듈은 생성된 모션 데이터에 물리 엔진 기반의 시뮬레이션 기법을 활용하여, 모션 데이터에 포함된 부자연스러운 동작을 제거하고, 추가 제어 정보에 맞는 애니메이션을 생성하여 보정 모션 데이터를 획득할 수 있다. 일 실시예에서, 물리 엔진 기반의 부자연 동작 개선 모듈은 모션 데이터를 보정하는 정도를 결정하는 수정 계수를 결정하는 모듈과 물리 엔진 기반으로 모션 데이터를 후처리하는 모듈을 포함할 수 있다. 일 실시예에서, 물리 엔진 기반의 부자연 동작 개선 모듈은 수정 계수 입력부를 통하여, 모션 데이터 에 포함된 부자연스러운 동작의 정도에 따라 결정된 사용자 수정 정보를 획득할 수 있다. 이때, 모션데이터에 포함된 부자연스러운 동작의 정도는 풋컨탠트 수정 정보, 풋슬라이딩 수정 정보, 궤적 정보, 목 표 지점 정보 또는 회피 영역 정보 중 적어도 하나를 포함할 수 있다. 일 실시예에서, 물리 엔진 기반의 부자연 동작 개선 모듈은 수정 계수 변형 알고리즘을 통하여 통합이 가능한 벡터 형태로 변환할 수 있다. 일 실시예에서, 물리 엔진 기반의 부자연 동작 개선 모듈은 조인트 그룹 지정 입력부를 통하여, 모션 데이터에 포함된 캐릭터의 스켈레톤 관절 중 오류 수정이 필요한 스켈레톤 관절을 지정하는 조인트 지정 정보를 획득할 수 있다. 일 실시예에서, 물리 엔진 기반의 부자연 동작 개선 모듈은 조인트 벡터 마 스킹을 통하여, 오류 수정이 필요하다고 지정된 스켈레톤 관절의 조인트 정보를 나타내는 벡터를 마스킹할 수 있다. 일 실시예에서, 물리 엔진 기반의 부자연 동작 개선 모듈은 수정 계수 통합을 통하여, 통합이 가능한 벡터 형태로 변환된 사용자 수정 정보 및 오류 수정이 필요하다고 지정된 스켈레톤 관절의 조인트 정보를 나타내는 벡터를 마스킹하는 것을 통합할 수 있다. 일 실시예에서, 물리 엔진 기반의 부자연 동작 개선 모듈은 모션 생성 모듈과 피드백을 통하여, 통합 된 수정 계수를 이용하여 물리 기반의 모션 제어 조건을 투영시켜, 모션 데이터를 수정할 수 있다. 일 실시예에서, 물리 엔진 기반의 부자연 동작 개선 모듈은 물리 기반의 강화학습 제어 모델을 이용 하여, 통합된 수정 계수에 기반하여 캐릭터가 이동하고 동작하도록, 모션 데이터를 수정할 수 있다. 일 실 시예에서, 물리 엔진 기반의 부자연 동작 개선 모듈은 모션 생성 모듈, 물리 기반의 모션 제어 조건 투영 및 물리 기반의 강화학습 제어 모델의 동작을 통하여, 부자연스러운 동작이 개선된 보정 모션 데이터를 생성할 수 있다. 도 10은 본 개시의 일 실시예에 따른 모션 렌더링 모듈의 동작을 설명하기 위한 도면이다. 도 1, 도 3 및 도 10을 참조하면, 일 실시예에서, 모션 렌더링 모듈은 보정 모션 데이터에 기초하여, 캐릭터에 보정 모션 데이터를 렌더링하여 캐릭터의 모션 애니메이션을 생성할 수 있다. 일 실시예에서, 모션 렌더링 모듈은 생성한 보정 모션 데이터를 시각화하기 위하여, 캐릭터에 보정 모션 데이터를 리-타겟팅(re-targeting)하여 보졍 모션 데이터에 대응되는 캐릭터의 모션 애니메이 션을 생성할 수 있다. 일 실시예에서, 모션 렌더링 모듈은 캐릭터의 모션 애니메이션을 생성하는데 있어, 렌더링 선택 신호 를 이용할 수 있다. 일 실시예에서, 렌더링 선택 신호는 데이터베이스에 저장된 복수의 보정 모션 데이터들 중 렌더링하고자 하는 보정 모션 데이터를 선택하는 모션 데이터 선택에 대한 정보를 포 함할 수 있다. 일 실시예에서, 렌더링 선택 신호는 보정 모션 데이터를 이용하여 모션 애니메이션 을 생성하고자 하는 캐릭터 모델의 선택에 대한 정보를 포함할 수 있다. 일 실시예에서, 렌더링 선 택 신호는 생성된 캐릭터 모션 애니메이션의 시각화를 위하여, 캐릭터 모션 애니메이션을 재생 또는 정지시키는 정보를 포함할 수 있다. 일 실시예에서, 렌더링 선택 신호는 입/출력 인터페이스부를 통하여 획득되거나, 혹은 통신 인터페 이스부를 통하여 획득될 수 있다. 일 실시예에서, 모션 렌더링 모듈은 생성된 보정 모션 데이터를 로딩할 수 있다. 이때, 모션 렌더링 모듈은 생성된 보정 모션 데이터가 저장된 데이터 베이스로부터 보정 모션 데이터를 로딩할 수 있다. 일 실시예에서, 모션 렌더링 모듈은 로딩한 보정 모션 데이터를 파싱(parsing, 1030)하여, 보정 모 션 데이터를 분석하고, 캐릭터 모션 애니메이션을 생성하기 위하여 필요한 정보를 추출할 수 있다. 이때, 캐릭터 모션 애니메이션을 생성하기 위하여 필요한 정보는 각 프레임에서의 캐릭터의 위치, 캐릭터 의 스켈레톤 관절의 위치, 캐릭터의 스켈레톤 관절의 각도 등을 포함할 수 있다. 이때, 모션 렌더링 모듈 은 렌더링 선택 신호에 포함된 모션 데이터를 선택하는 정보에 기초하여, 선택된 보정 모션 데이터 를 파싱할 수 있다. 다만, 본 개시는 이에 제한되지 않고, 모션 렌더링 모듈은 보정 모션 데이터 를 로딩하는 단계에서 렌더링 선택 신호에 포함된 모션 데이터를 선택하는 정보에 기 초하여 데이터 베이스에 포함된 복수의 보정 모션 데이터들 중 선택된 보정 모션 데이터를 로딩할 수도 있다. 일 실시예에서, 모션 렌더링 모듈은 렌더링 선택 신호에 포함된 캐릭터 모델의 선택 정보에 기초하여, 선택된 캐릭터에 로딩하여 파싱된 보정 모션 데이터를 리타겟팅 할 수 있다. 모션 렌더링 모듈은 선택된 캐릭터의 스켈레톤 관절에 로딩하여 파싱된 보정 모션 데이터를 적용할 수 있다. 일 실시예에서, 모션 렌더링 모듈은 렌더링 선택 신호에 포함된, 캐릭터 모션 애니메이션을 재 생 또는 정지시키는 정보에 기초하여, 보정 모션 데이터가 리타겟팅된 캐릭터의 애니메이션을 렌더링 하여 시각화할 수 있다. 일 실시예에서, 모션 렌더링 모듈은 보정 모션 데이터가 리타겟팅된 캐릭터 의 애니메이션을 렌더링하여 캐릭터의 모션 애니메이션을 생성할 수 있다. 한편, 개시된 실시예들은 컴퓨터에 의해 실행 가능한 명령어를 저장하는 기록매체의 형태로 구현될 수 있다. 명 령어는 프로그램 코드의 형태로 저장될 수 있으며, 프로세서에 의해 실행되었을 때, 프로그램 모듈을 생성하여 개시된 실시예들의 동작을 수행할 수 있다. 기록매체는 컴퓨터로 읽을 수 있는 기록매체로 구현될 수 있다. 컴퓨터가 읽을 수 있는 기록매체로는 컴퓨터에 의하여 해독될 수 있는 명령어가 저장된 모든 종류의 기록 매체 를 포함한다. 예를 들어, ROM(Read Only Memory), RAM(Random Access Memory), 자기 테이프, 자기 디스크, 플 래쉬 메모리, 광 데이터 저장장치 등이 있을 수 있다."}
{"patent_id": "10-2025-0019218", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "이상에서와 같이 첨부된 도면을 참조하여 개시된 실시예들을 설명하였다. 본 개시가 속하는 기술분야에서 통상 의 지식을 가진 자는 본 개시의 기술적 사상이나 필수적인 특징을 변경하지 않고도, 개시된 실시예들과 다른 형 태로 본 개시가 실시될 수 있음을 이해할 것이다. 개시된 실시예들은 예시적인 것이며, 한정적으로 해석되어서 는 안 된다."}
{"patent_id": "10-2025-0019218", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 개시의 일 실시예에 따른 모션 생성 장치의 구성을 도시한 블록도이다. 도 2는 본 개시의 일 실시예에 따른 모션 생성 장치의 동작을 설명하기 위한 순서도이다. 도 3은 본 개시의 일 실시예에 따른 모션 생성 장치의 동작을 설명하기 위한 도면이다. 도 4는 본 개시의 일 실시예에 따른 입력 정보 전처리 모듈의 동작을 설명하기 위한 도면이다. 도 5는 본 개시의 일 실시예에 따른 모션 생성 모듈의 동작을 설명하기 위한 도면이다. 도 6은 본 개시의 일 실시예에 따른 모션 후처리 모듈의 동작을 설명하기 위한도면이다. 도 7는 본 개시의 일 실시예에 따른 필터링 기반의 부자연 동작 개선 모듈의 동작을 설명하기 위한 도면이다. 도 8은 본 개시의 일 실시예에 따른 인공 지능 모델 기반의 부자연 동작 개선 모듈의 동작을 설명하기 위한 도 면이다. 도 9는 본 개시의 일 실시예에 따른 물리 엔진 기반의 부자연 동작 개선 모듈의 동작을 설명하기 위한 도면이다. 도 10은 본 개시의 일 실시예에 따른 모션 렌더링 모듈의 동작을 설명하기 위한 도면이다."}
