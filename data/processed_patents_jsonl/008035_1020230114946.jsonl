{"patent_id": "10-2023-0114946", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2025-0032301", "출원번호": "10-2023-0114946", "발명의 명칭": "XR 기기를 이용한 실감형 가상 골프 서비스", "출원인": "주식회사 키네버스", "발명자": "김경모"}}
{"patent_id": "10-2023-0114946", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "XR(eXtended Reality)을 이용한 실감형 가상 골프 서비스 제공 방법으로서,바닥에 놓여진 실제 골프 공을 XR 기기의 카메라를 통해 촬영한 후, XR 기기의 디스플레이부에 표시되는 가상골프 환경 내에 재현하여 표시하는 단계와;상기 XR 기기를 착용한 사용자의 골프 스윙을 상기 XR 기기의 카메라를 통하여 실시간 촬영하는 단계와;상기 사용자의 골프 스윙 모션을 상기 XR 기기에 탑재된 인공신경망 모델을 통하여 실시간 분석하는 단계와;상기 실시간 분석된 사용자의 골프 스윙 모션을 XR 기기의 디스플레이부에 표시되는 가상 골프 환경 내에 재현하여 표시하는 단계를 포함하는 방법."}
{"patent_id": "10-2023-0114946", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 명세서의 일 예시는 XR(eXtended Reality)을 이용한 실감형 가상 골프 서비스 제공 방법을 제시한다. 상기 방 법은 바닥에 놓여진 실제 골프 공을 XR 기기의 카메라를 통해 촬영한 후, XR 기기의 디스플레이부에 표시되는 가 상 골프 환경 내에 재현하여 표시하는 단계와; 상기 XR 기기를 착용한 사용자의 골프 스윙을 상기 XR 기기의 카 메라를 통하여 실시간 촬영하는 단계와; 상기 사용자의 골프 스윙 모션을 상기 XR 기기에 탑재된 인공신경망 모 델을 통하여 실시간 분석하는 단계와; 그리고 상기 실시간 분석된 사용자의 골프 스윙 모션을 XR 기기의 디스플 레이부에 표시되는 가상 골프 환경 내에 재현하여 표시하는 단계를 포함할 수 있다."}
{"patent_id": "10-2023-0114946", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 XR 기기를 이용한 실감형 가상 골프 서비스에 관한 것이다."}
{"patent_id": "10-2023-0114946", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "골프 인구가 증가하면서, 가상 골프 시뮬레이션 장치 등을 이용한 골프 연습 및 가상의 골프경기를 즐길 수 있 는 이른바 스크린 골프 시스템이 등장하게 되었다. 이와 같은 스크린 골프 시스템은 실내에 가상 골프장을 디스플레이할 수 있는 스크린을 설치하고, 골퍼가 골프 공을 상기 스크린을 향해 타격을 하면 골프공의 속도, 방향 등을 감지하여 상기 스크린상에 골프공의 진행을 표 시해주는 시스템이다. 이와 같이 가상 골프 시뮬레이션 장치에 의해 구현되는 스크린 골프 시스템 등에서는 골프 연습장에서 골프공을 타격하는 것과 동일하게 골프공을 타격하면서 실제로 골프장에서 라운드를 하는 것과 같은 현장감을 줄 수 있는 특징을 갖추고 있다. 가상 골프 시뮬레이션 장치에 의해 구현되는 스크린 골프 시스템 등에서는 실제 골프장에서 골프 라운딩하는 것 과 같은 리얼리티를 제공할 수 있을 뿐만 아니라 여러 가지 첨단 장치들과 시스템을 통해 서비스되는 특성상 실 제 골프장이나 골프 연습장에서는 제공하기 힘든 다양한 컨텐츠를 제공함으로써 골퍼들로 하여금 흥미를 유발하 여, 시장 규모를 키워왔다. 또한 실제 골프장에서의 골프 라운딩과는 별도로 가상 골프 시뮬레이션에 의한 스크린 골프가 하나의 독립적인 문화 또는 e-스포츠의 영역을 갖게 됨으로써 그러한 독립적인 문화를 즐기는 사람들이 그들만의 문화를 형성하 여 왔다. 도 1은 종래의 스크린 골프 시스템에 적용되는 센싱장치의 일 예에 대해 나타낸 도면이다. 도 1에 도시된 바와 같이 스크린 골프를 위한 공간을 마련하는 부스(BT) 내에서, 사용자(P)의 전방에 스크린 을 설치하고 영상출력장치가 골프코스에 대한 영상(SI)을 상기 스크린에 출력하며, 부스 바닥(B 1)에 타석을 마련하고 사용자(P)가 골프공을 타격하면, 부스(BT)의 천장에 설치된 제1 카메라와 제2 카메라가 각각 타격된 골프공을 촬영하여 시뮬레이터(SM)로 전송하고, 시뮬레이터(SM)는 각각의 카메라 가 취득한 영상을 분석하여 골프공에 대한 3차원 공간 상에서의 위치 정보를 산출하고 그 산출된 위치 정보 에 기초하여 골프공의 운동에 따른 운동 파라미터를 산출하며 그 산출된 골프공의 운동 파라미터에 기초한 볼의 궤적에 대한 시뮬레이션 영상이 상기 골프코스의 영상 상에서 이루어질 수 있도록 한다. 도 1에 도시된 바와 같이, 종래에는 가상 골프 시뮬레이션 장치에 이용되는 골프공을 감지하기 위한 센싱장치의 제1 카메라와 제2 카메라가 부스(BT)의 천장, 즉 사용자(P)의 머리 위쪽에 가깝게 배치되어설치되었다. 즉, 종래에는 골프공의 3차원 좌표를 획득하기 위하여 두 대의 카메라, 즉 스테레오스코픽(Stereoscopic) 방 식을 사용하였다. 그러나, 이와 같이 종래의 스테레오스코픽 방식은 골프공의 좌표를 얻는데 그쳤을 뿐이며, 사용자(P)의 모션과 그에 따른 골프채의 스윙 궤적을 분석하지 아니하였기 때문에, 실제 골프와는 이질감이 존재하여 왔다."}
{"patent_id": "10-2023-0114946", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "최근 XR(eXtended Reality) 기기들의 개발과 보급이 확산되고 있다. 또한, 최근 인공지능(artificial intelligence: AI)도 점차 발전하고 있다. AI는 인간의 지능, 즉 인식 (Recognition), 분류(Classification), 추론(Inference), 예측(Predict), 조작/의사결정(Control/Decision making) 등을 할 수 있는 지능을 인공적으로 모방하는 것을 의미한다. 따라서, 본 명세서의 발명자들은 XR 기기와 인공 지능을 이용하여 보다 실감나는 가상 골프 게임 서비스를 개발 할 필요성이 있다는 것을 인지하였다."}
{"patent_id": "10-2023-0114946", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "전술한 목적을 달성하기 위하여, 본 명세서의 일 예시는 XR(eXtended Reality)을 이용한 실감형 가상 골프 서비 스 제공 방법을 제시한다. 상기 방법은 바닥에 놓여진 실제 골프 공을 XR 기기의 카메라를 통해 촬영한 후, XR 기기의 디스플레이부에 표시되는 가상 골프 환경 내에 재현하여 표시하는 단계와; 상기 XR 기기를 착용한 사용 자의 골프 스윙을 상기 XR 기기의 카메라를 통하여 실시간 촬영하는 단계와; 상기 사용자의 골프 스윙 모션을 상기 XR 기기에 탑재된 인공신경망 모델을 통하여 실시간 분석하는 단계와; 그리고 상기 실시간 분석된 사용자 의 골프 스윙 모션을 XR 기기의 디스플레이부에 표시되는 가상 골프 환경 내에 재현하여 표시하는 단계를 포함 할 수 있다."}
{"patent_id": "10-2023-0114946", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 개시의 예시들에 따르면, XR 기기와 인공 지능을 이용하여 보다 실감나는 가상 골프 게임 서비스를 제공할 수 있다."}
{"patent_id": "10-2023-0114946", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 개시의 예시들의 특정한 구조적 내지 단계적 설명들은 단지 본 개시의 개념에 따른 예시를 설명하기 위한 것 이다. 따라서 본 개시의 개념에 따른 예시들은 다양한 형태로 실시될 수 있다. 본 개시의 개념에 따른 예시들은 다양한 형태로 실시될 수 있다. 본 개시는 본 개시의 예시들에 한정되는 것으로 해석되어서는 아니 된다. 본 개시의 개념에 따른 예시에 다양한 변경을 가할 수 있고 여러 가지 형태를 가질 수 있다. 이에, 특정 예시들 을 도면에 예시하고 본 개시 또는 출원에 대해서 상세하게 설명하고자 한다. 그러나, 이는 본 개시의 개념에 따 른 예시를 특정한 개시 형태에 대해 한정하려는 것이 아니다. 본 개시의 개념에 따른 여시는 본 개시의 사상 및 기술 범위에 포함되는 모든 변경, 균등물 내지 대체물을 포함하는 것으로 이해되어야 한다. 제1 및/또는 제2 등의 용어는 다양한 구성 요소들을 설명하는데 사용될 수 있지만, 상기 구성 요소들은 상기 용 어들에 의해 한정되어서는 안 된다. 상기 용어들은 하나의 구성 요소를 다른 구성 요소로부터 구별하는 목적으 로만 사용될 수 있다. 상기 용어들은 본 개시의 개념에 따른 권리 범위로부터 이탈되지 않은 채, 제1 구성요소 는 제2 구성요소로 명명될 수 있고, 유사하게 제2 구성요소는 제1 구성요소로도 명명될 수 있다. 어떤 구성요소가 다른 구성요소에 \"연결되어\" 있다거나 \"접속되어\" 있다고 언급된 때에는, 그 다른 구성요소에 직접적으로 연결되어 있거나 또는 접속되어 있을 수도 있다. 하지만 복수의 구성요소들 중간에 다른 구성요소가 존재할 수도 있다고 이해되어야 할 것이다. 반면에, 어떤 구성요소가 다른 구성요소에 \"직접 연결되어\" 있다거 나 \"직접 접속되어\" 있다고 언급된 때에는, 중간에 다른 구성요소가 존재하지 않는 것으로 이해되어야 할 것이다. 구성요소들 간의 관계를 설명하는 다른 표현들, 즉 \"~사이에\"와 \"바로 ~사이에\" 또는 \"~에 이웃하는\"과 \"~ 에 직접 이웃하는\" 등도 마찬가지로 해석되어야 한다. 본 개시에서 사용한 용어는 단지 특정한 예시를 설명하기 위해 사용된 것으로, 본 개시를 한정하려는 의도가 아 니다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 개시에서, \"포함하 다\" 또는 \"가지다\" 등의 용어는 서술된 특징, 숫자, 단계, 동작, 구성요소, 부분품 또는 이들을 조합한 것이 존 재함을 지정하려는 것이다. 따라서 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성요소, 부분품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되어야 한다. 다르게 정의되지 않는 한, 기술적이거나 과학적인 용어를 포함해서 여기서 사용되는 모든 용어들은 본 개시가 속하는 기술 분야에서 통상의 지식을 가진 자에 의해 일반적으로 이해되는 것과 동일한 의미를 가지고 있다. 일 반적으로 사용되는 사전에 정의되어 있는 것과 같은 용어들은 관련 기술의 문맥상 가지는 의미와 일치하는 의미 를 가지는 것으로 해석되어야 한다. 일반적으로 사용되는 사전에 정의되어 있는 것과 같은 용어들은 본 개시에 서 명백하게 정의하지 않는 한, 이상적이거나 과도하게 형식적인 의미로 해석되지 않는다. 예시를 설명함에 있어서 본 개시가 속하는 기술 분야에 익히 알려져 있고 본 개시와 직접적으로 관련이 없는 기 술 내용에 대해서는 설명을 생략한다. 이는 불필요한 설명을 생략함으로써 본 개시의 요지를 흐리지 않고 더욱 명확히 전달하기 위함이다. <인공지능> 인간은 인식(Recognition), 분류(Classification), 추론(Inference), 예측(Predict), 조작/의사결정 (Control/Decision making) 등을 할 수 있는 지능을 갖추고 있다. 인공지능(artificial intelligence: AI)은 인간의 지능을 인공적으로 모방하는 것을 의미한다. 인간의 뇌는 뉴런(Neuron)이라는 수많은 신경세포로 이루어져 있다. 각각의 뉴런은 시냅스(Synapse)라고 불리는 연결부위를 통해 수백에서 수천 개의 다른 뉴런들과 연결되어 있다. 인간의 지능을 모방하기 위하여, 생물학적 뉴런의 동작원리와 뉴런 간의 연결 관계를 모델링한 것을, 인공신경망모델이라고 한다. 즉, 인공신경망은 뉴런 들을 모방한 노드들을 레이어(Layer: 계층) 구조로 연결시킨, 시스템이다. 이러한 인공신경망모델은 레이어 수에 따라 '단층 신경망'과 '다층 신경망'으로 구분한다. 일반적인 다층신경망 은 입력 레이어와 은닉 레이어, 출력 레이어로 구성된다. 입력 레이어(input layer)은 외부의 자료들을 받 아들이는 레이어로서, 입력 레이어의 뉴런 수는 입력되는 변수의 수와 동일하다. 은닉 레이어(hidden layer)은 입력 레이어와 출력 레이어 사이에 위치하며 입력 레이어로부터 신호를 받아 특성을 추출하여 출력층으로 전달한다. 출력 레이어(output layer)은 은닉 레이어로부터 신호를 받아 외부로 출력한다. 뉴런 간의 입력신호는 0에서 1 사이의 값을 갖는 각각의 연결강도와 곱해진 후 합산된다. 이 합이 뉴런의 임계치보다 크면 뉴런이 활성화되어 활성화 함수를 통하여 출력 값으로 구현된다. 한편, 보다 높은 인공 지능을 구현하기 위하여, 인공신경망의 은닉 레이어의 개수를 늘린 것을 심층 신경망 (Deep Neural Network, DNN)이라고 한다. DNN은 다양한 구조로 개발되고 있다. 예를 들면, DNN의 일 예시인 합성곱 신경망(convolutional neural network, CNN)은 입력 값 (영상 또는 이미지)의 특징들을 추출하고, 추출된 출력 값의 패턴을 파악하기에 용이 한 것으로 알려져 있다. CNN은 합성곱 연산, 활성화 함수 연산, 풀링(pooling) 연산 등이 특정 순서로 처리되는 형태로 구성될 수 있다. 예를 들면, DNN의 레이어 각각에서, 파라미터(i.e., 입력 값, 출력 값, 가중치 또는 커널 등)는 복수의 채널로 구성된 행렬일 수 있다. 파라미터는 합성곱 또는 행렬 곱셈으로 NPU에서 처리될 수 있다. 각 레이어에서 연산이 처리된 출력 값이 생성된다. 예를 들면, 트랜스포머(transformer)는 어텐션(attention) 기술에 기반한 DNN이다. 트랜스포머는 행렬 곱셈 (matrix multiplication) 연산을 다수 활용한다. 트랜스포머는 입력 값과 쿼리(query; Q), 키(key; K), 및 값 (value; V) 등의 파라미터를 사용하여 출력 값인 어텐션(Q,K,V)를 획득할 수 있다. 트랜스포머는 출력 값 (즉, 어텐션(Q,K,V))에 기초하여 다양한 추론 연산을 처리할 수 있다. 트랜스포머는 CNN 보다 더 우수한 추론 성능을 보여주는 경향이 있다. 도 2는 예시적인 인공신경망모델을 설명하는 개략적인 개념도이다. 이하 신경 프로세싱 유닛에서 작동될 수 있는 예시적인 인공신경망모델(110a)의 연산에 대하여 설명한다. 도 2의 예시적인 인공신경망모델(110a)은 객체 인식, 음성 인식 등 다양한 추론 기능을 수행하도록 학습된 인공 신경망일 수 있다. 인공신경망모델(110a)은 심층 신경망(DNN, Deep Neural Network)일 수 있다. 단, 본 개시의 예시들에 따른 인공신경망모델(110a)은 심층 신경망에 제한되지 않는다. 예를 들어, 인공신경망모델(110a)은 DaViT, MobileViT, Swin-Transformer, Transformer, YOLO, CNN, PIDNet, BiseNet, RCNN, VGG, VGG16, DenseNet, SegNet, DeconvNet, DeepLAB V3+, U-net, SqueezeNet, Alexnet, ResNet18, MobileNet-v2, GoogLeNet, Resnet-v2, Resnet50, Resnet101, Inception-v3 등의 모델로 구현될 수 있다. 단, 본 개시는 상술한 모델들에 제한되지 않는다. 또한 인공신경망모델(110a)은 적어도 두 개의 서로 다 른 모델들에 기초한 앙상블 모델일 수도 있다. 이하 예시적인 인공신경망모델(110a)에 의해서 수행되는 추론 과정에 대해서 설명하기로 한다. 인공신경망모델(110a)은 입력 레이어(110a-1), 제1 연결망(110a-2), 제1 은닉 레이어(110a-3), 제2 연결망 (110a-4), 제2 은닉 레이어(110a-5), 제3 연결망(110a-6), 및 출력 레이어(110a-7)을 포함하는 예시적인 심층 신경망 모델이다. 단, 본 개시는 도 1에 도시된 인공신경망모델에만 제한되는 것은 아니다. 제1 은닉 레이어 (110a-3) 및 제2 은닉 레이어(110a-5)는 복수의 은닉 레이어로 지칭되는 것도 가능하다. 입력 레이어(110a-1)는 예시적으로, x1 및 x2 입력 노드를 포함할 수 있다. 즉, 입력 레이어(110a-1)는 2개의 입력 값에 대한 정보를 포함할 수 있다. 제1 연결망(110a-2)은 예시적으로, 입력 레이어(110a-1)의 각각의 노드를 제1 은닉 레이어(110a-3)의 각각의 노 드로 연결시키기 위한 6개의 가중치 값에 대한 정보를 포함할 수 있다. 각각의 가중치 값은 입력 노드 값과 곱 해지고, 곱해진 값들의 누산된 값이 제1 은닉 레이어(110a-3)에 저장된다. 가중치 값과 입력 노드 값은 인공신 경망모델의 파라미터로 지칭될 수 있다. 제1 은닉 레이어(110a-3)는 예시적으로 a1, a2, 및 a3 노드를 포함할 수 있다. 즉, 제1 은닉 레이어(110a-3)는 3개의 노드 값에 대한 정보를 포함할 수 있다. 도 2의 제1 프로세싱 엘리먼트(PE1)는 a1 노드의 연산을 처리할 수 있다. 도 2의 제2 프로세싱 엘리먼트(PE2)는 a2 노드의 연산을 처리할 수 있다. 도 2의 제3 프로세싱 엘리먼트(PE3)는 a3 노드의 연산을 처리할 수 있다.제2 연결망(110a-4)은 예시적으로, 제1 은닉 레이어(110a-3)의 각각의 노드를 제2 은닉 레이어(110a-5)의 각각의 노드로 연결시키기 위한 9개의 가중치 값에 대한 정보를 포함할 수 있다. 제2 연결망(110a-4)의 가중치 값은 제1 은닉 레이어(110a-3)로부터 입력되 는 노드 값과 각각 곱해지고, 곱해진 값들의 누산된 값이 제2 은닉 레이어(110a-5)에 저장된다. 제2 은닉 레이어(110a-5)는 예시적으로 b1, b2, 및 b3 노드를 포함할 수 있다. 즉, 제2 은닉 레이어(110a-5)는 3개의 노드 값에 대한 정보를 포함할 수 있다. 도 2의 제4 프로세싱 엘리먼트(PE4)는 b1 노드의 연산을 처리할 수 있다. 도 2의 제5 프로세싱 엘리먼트(PE5)는 b2 노드의 연산을 처리할 수 있다. 도 2의 제6 프로세싱 엘리먼트(PE6)는 b3 노드의 연산을 처리할 수 있다. 제3 연결망(110a-6)은 예시적으로, 제2 은닉 레이어(110a-5)의 각각의 노드와 출력 레이어(110a-7)의 각각의 노 드를 연결하는 6개의 가중치 값에 대한 정보를 포함할 수 있다. 제3 연결망(110a-6)의 가중치 값은 제2 은닉 레 이어(110a-5)로부터 입력되는 노드 값과 각각 곱해지고, 곱해진 값들의 누산된 값이 출력 레이어(110a-7)에 저 장된다. 출력 레이어(110a-7)는 예시적으로 y1, 및 y2 노드를 포함할 수 있다. 즉, 출력 레이어(110a-7)는 2개의 노드 값에 대한 정보를 포함할 수 있다. 도 2의 제7 프로세싱 엘리먼트(PE7)는 y1 노드의 연산을 처리할 수 있다. 도 2의 제8 프로세싱 엘리먼트(PE8)는 y2 노드의 연산을 처리할 수 있다. 각각의 노드는 특징 값에 대응될 수 있으며, 특징 값은 특징맵에 대응될 수 있다. 도 3a은 컨볼루션 신경망(CNN)의 기본 구조를 설명하기 위한 도면이다. 도 3a을 참조하면, 입력 이미지는 특정 사이즈(size)의 행과 특정 사이즈의 열로 구성된 2차원적 행렬로 표시될 수 있다. 입력 이미지는 복수의 채널을 가질 수 있는데, 여기서 채널은 입력 데이터 이미지의 컬러 성분의 수를 나타낼 수 있다. 컨볼루션 과정은 입력 이미지를 지정된 간격으로 순회하면서 커널과 합성곱 연산을 수행하는 것을 의미한다. 컨볼루션 신경망은 현재 레이어의 출력 값(합성곱 또는 행렬 곱셈)을 다음 레이어의 입력 값으로 전달하는 구조 를 가질 수 있다. 예를 들면, 합성곱(컨볼루션)은, 두 개의 주요 파라미터(입력 특징맵 및 커널)에 의해 정의된다. 파라미터는 입 력 특징맵, 출력 특징맵, 활성화 맵, 가중치, 커널, 및 어텐션(Q,K,V) 등을 포함할 수 있다, 합성곱(컨볼루션)은 입력 특징맵 위로 커널 윈도우를 슬라이딩 한다. 커널이 입력 특징맵을 슬라이딩 하는 단차 사이즈를 보폭(stride)이라고 한다. 합성곱 이후에는 풀링(pooling)이 적용될 수 있다. 또한, 컨볼루션 신경망의 끝단에는 FC (fully-connected)레 이어가 배치될 수 있다. 도 3b는 컨볼루션 신경망의 동작을 이해하기 쉽게 나타낸 종합도이다. 도 3b을 참조하면, 예시적으로 입력 이미지가 6 x 6 크기를 갖는 2차원적 행렬인 것으로 나타나 있다. 또한, 도 3b에는 예시적으로 3개의 노드, 즉 채널 1, 채널 2, 채널 3이 사용되는 것으로 나타내었다. 먼저, 합성곱 동작에 대해서 설명하기로 한다. 입력 이미지(도 3b에서는 예시적으로 6 x 6 크기인 것으로 나타내어짐)는 첫 번째 노드에서 채널 1을 위한 커널 1(도 3b에서는 예시적으로 3 x 3 크기인 것으로 나타내어짐)과 합성곱되고, 그 결과로서 특징맵1(도 3b에서는 예시적으로 4 x 4 크기인 것으로 나타내어짐)이 출력된다. 또한, 상기 입력 이미지(도 3b에서는 예시적으로 6 x 6 크기인 것으로 나타내어짐)는 두 번째 노드에서 채널 2를 위한 커널 2(도 3b에서는 예시적으로 3 x 3 크기인 것으로 나타내어짐)와 합성곱되고 그 결과로서 특징맵 2(도 3b에서는 예시적으로 4 x 4 크기인 것으로 나타내어 짐)가 출력된다. 또한, 상기 입력 이미지는 세 번째 노드에서 채널 3을 위한 커널 3(도 3b에서는 예시적으로 3 x 3 크기인 것으로 나타내어짐)과 합성곱되고, 그 결과로서 특징맵3(도 3b에서는 예시적으로 4 x 4 크기인 것으로 나타내어짐)이 출력된다. 각각의 합성곱을 처리하기 위해서 신경 프로세싱 유닛의 프로세싱 엘리먼트들(PE1 to PE12)은 MAC 연산을 수행하도록 구성된다. 다음으로, 활성화 함수의 동작에 대해서 설명하기로 한다. 합성곱 동작으로부터 출력되는 특징맵1, 특징맵2 그리고 특징맵3(도 2b에서는 각각의 크기는 예시적으로 4 x 4 인 것으로 나타내어짐)에 대해서 활성화 함수가 적용될 수 있다. 활성화 함수가 적용되고 난 이후의 출력은 예 시적으로 4 x 4의 크기일 수 있다. 다음으로, 폴링(pooling) 동작에 대해서 설명하기로 한다. 상기 활성화 함수로부터 출력되는 특징맵1, 특징맵2, 특징맵3(도 2b에서는 각각의 크기는 예시적으로 4 x 4인 것으로 나타내어짐)은 3개의 노드로 입력된다. 활성화 함수로부터 출력되는 특징맵들을 입력으로 받아서 폴링 (pooling)을 수행할 수 있다. 상기 폴링이라 함은 크기를 줄이거나 행렬 내의 특정 값을 강조할 수 있다. 폴링 방식으로는 최대값 폴링과 평균 폴링, 최소값 폴링이 있다. 최대값 폴링은 행렬의 특정 영역 안에 값의 최댓값 을 모으기 위해서 사용되고, 평균 폴링은 특정 영역내의 평균을 구하기 위해서 사용될 수 있다. 도 3b의 예시에서는 4 x 4 크기의 특징맵이 폴링에 의하여 2 x 2 크기로 줄어지는 것으로 나타내었다. 구체적으로, 첫 번째 노드는 채널 1을 위한 특징맵1을 입력으로 받아 폴링을 수행한 후, 예컨대 2 x 2 행렬로 출력한다. 두 번째 노드는 채널 2을 위한 특징맵2을 입력으로 받아 폴링을 수행한 후, 예컨대 2 x 2 행렬로 출 력한다. 세 번째 노드는 채널 3을 위한 특징맵3을 입력으로 받아 폴링을 수행한 후, 예컨대 2 x 2 행렬로 출력 한다. 전술한 합성곱, 활성화 함수과 폴링이 반복되고 최종적으로는, 도 3a와 같이 fully connected로 출력될 수 있다. 해당 출력은 다시 이미지 인식을 위한 인공신경망으로 입력될 수 있다. 단, 본 개시는 특징맵, 커널의 크 기에 제한되지 않는다. 지금까지 설명한 CNN은 다양한 심층신경망(DNN) 방법 중에서도 컴퓨터 비전(Vision) 분야에서 가장 많이 쓰이는 방법이다. 특히, CNN은 이미지 분류(image classification) 및 객체 검출(objection detection)과 같은 다양한 작업을 수행하는 다양한 연구 영역에서 놀라운 성능을 보였다. 한편, 실시간 객체 검출을 위한 인공신경망 모델 중 하나인 YOLO(You Only Look Once)를 여러 분야에서 적용하 려는 시도들이 있다. YOLO는 최첨단 실시간 객체 검출 모델이다. 기존의 모델보다 빠르고 정확한 데이터 처리 속도를 갖는다. YOLO는 입력된 이미지를 일정 분할로 그리드한 다음, 신경망을 통과하여 바운딩 박스와 클래스 예측을 생성하여 최종 감지 출력을 결정한다. I. 본 명세서의 제1 개시 본 명세서의 제1 개시는 사용자의 골프 스윙 모션을 분석 및 학습하여 인공지능 모델을 구축하는 것을 제안한다. 또한, 본 명세서의 제1 개시는 사용자의 골프 클럽에 의해서 임팩트되어 비행하는 골프 공의 움직임 을 측정 및 추적한 후 학습하여 인공지능 모델을 구축하는 것을 제안한다. 이에 대하여 도면을 참조하여 보다 상세하게 설명하면 다음과 같다. 도 4는 본 명세서의 제1 개시에 따른 학습 방법을 나타낸 예시도이다. 도 5a 내지 도 5b는 골프 스윙 과정에서 골격(skeleton)을 이용한 자세 추정(pose estimation)의 일 예시를 나타낸다. 도 6은 골프 스윙 과정을 골격 형 태로 나타낸 예시도이다. 도 4를 참조하여 알 수 있는 바와 같이, 카메라를 이용하여 사용자(예컨대, 골프 프로 선수 등)의 골프 스윙 모 션을 캡쳐한다(S401). 상기 카메라는 상기 사용자의 전면 또는 측면에 설치될 수 있다. 또는 일 예시에 따르면, 상기 카메라는 상기 사용자의 머리에 착용되는 XR 기기 내에 장착되어 있는 카메라일 수 있다. 이와 같이 상기 카메라가 상기 XR 기 기 내에 장착되어 있는 카메라일 경우, 촬영이 1인칭 시점으로 되기 때문에, 본 명세서에서 개시되는 방안에는 더 적합하다. 다음으로, 카메라를 통해서 캡쳐된 영상 내의 사용자의 골프 스윙 모션을 분석하고 학습하여 제1 인공신경망모 델을 구축한다 (S403). 구체적으로 설명하면, 도 5a 및 도 5b에 도시된 바와 같이 영상의 매 프레임 단위로 사용자의 골격이 취해진 자 세를 추정함으로써, 즉, 자세 추정(pose estimation)을 수행함으로써, 골프 스윙 모션을 매 프레임 단위로 분석 한다. 특히나, 도 5a 및 도 5b에 도시된 바와 같이, 사용자의 자세 추정을 골격 단위로 수행하면, 기존에는 사 용자가 착용한 의류 때문에 가려져서 쉽게 판독해내기 어려웠던 자세를 보다 쉽게 알아낼 수 있다. 영상에서 매 프레임 단위의 자세 추정은 인공신경망 모델 중 하나인 YOLO를 이용하여 달성될 수 있다. 따라서, 상기 사용자의 골프 스윙과 그리고 비행하는 골프 공의 움직임 간의 상관 관계가 분석될 수 있다. 또한, 골프 스윙 과정 중에서 어느 부분이 잘못되었는지를 정확하게 짚어낼 수 있게 된다. 그리고, 분석된 골프 스윙 모션을 학습시켜, 제1 인공신경망 모델을 구축한다. 학습 과정은 매 프레임 단위로 수행될 수 있다. 또한, 병행하여, 매 프레임 단위로 추정된 자세 추정을 다시 시간순서데로 연결한 하나의 골프 스윙 모션도 학습될 수 있다. 한편, S403 과정에서는, 사용자의 골프 스윙에 의한 골프채의 운동(골프채 헤드의 각속도, 가속도) 뿐만 아니라, 골프채의 자세(즉, 골프채의 각도, 골프 채의 페이스면의 각도)도 함께 분석되고, 학습될 수 있다. 즉, 도 6을 참조하여 알 수 있는 바와 같이, 골프 스윙에 의한 골프 채의 운동도 함께 분석되고, 학습될 수 있다. S403 과정에서 구축된 제1 인공신경망 모델은 전술한 YOLO를 기반으로 구축된 것일 수 있다. YOLO는 인체 골격 을 이용한 자세 추정에 탁월한 성능을 나타낼 수 있기 때문이다. 다음으로, 사용자의 골프 클럽에 의해서 임팩트 되어 비행하는 골프 공의 움직임을 측정하고 추적한다(S405). 상기 측정 및 추적은 종래와 마찬가지로 저렴한 방식인, 스테레오스코픽 방식에 의해서 수행될 수 있다. 그러나 정확도를 향상시키기 위해서, 특정 파장의 광선을 이용하여 골프공의 움직임을 측정 및 추적할 수 있다. 구체적 으로 설명하면, 특정 파장의 광선(예 레이저)을 쏜 후 반사광을 수광하여 골프공의 상승 각도, 회전 방향, 회전 량과 가속도, 속도를 측정할 수 있다. 또한, 골프공의 움직임을 추적하면서 측정을 지속하거나 보정할 수 있다. 한편, 상기 비행하는 골프 공의 움직임을 인공신경망 모델을 이용하여 학습한 후, 제2 인공신경망 모델을 구축 한다(S407). 구체적으로, 상기 S405 과정에서 측정되고 추적된 골프 공의 움직임이 매 프레임 단위로 분석 및 학습됨으로써, 제2 인공신경망 모델이 구축될 수 있다. 상기 S407 과정에서 구축된 제2 인공신경망 모델은 SORT(Simple Online and Realtime Tracking) 또는 DEEP SORT 기반일 수 있다. 다음으로, 상기 사용자의 골프 스윙과 비행하는 골프 공의 움직임 간의 상관 관계를 분석하여 제3 인공신경망 모델을 구축한다(S409). S409 과정은 S403 과정에 의해서 구축된 제1 인공신경망 모델과 S407 과정에 의해서 구 축된 제2 인공신경망 모델 간의 상관 관계를 분석하여 하나로 병합된 제3 인공신경망 모델을 구축하는 과정으로 설명할 수 있다. 즉, 도 1에 도시된 종래 기술은 골프 공의 움직임만을 분석하였고, 사용자의 골프 스윙과 그에 따른 골프채의 스윙 궤적을 분석하지 아니하였기 때문에, 실재감이 낮은 단점이 있었다. 이를 극복하기 위하여, 본 명세서의 제1 개시는, 상기 사용자의 골프 스윙과 그리고 비행하는 골프 공의 움직임 간의 상관 관계를 분석 한 후, 하나로 병합시킨 제3 인공신경망 모델을 생성한다. 만약, 제1 인공신경망 모델이 YOLO 기반이고, 제2 인공신경망 모델이 SORT 또는 DEEP SORT 기반인 경우, 이 둘 이 병합된 제3 인공신경망 모델은 퓨전 인공신경망 모델일 수 있다. 퓨전 인공신경망 모델이라 함은, 2가지의 이종 인공신경망 모델이 하나로 합쳐진 것을 일컫는다. 이와 같은 퓨전 인공신경망 모델은 더 많은 파라미터를 갖게 되어 정확도를 높일 수 있는 장점이 있다. 즉, 골프 공의 비행 운동은 골프 스윙에 종속적이므로, 골프 공 의 비행 운동을 표현하기 위한 파라미터로서 골프 스윙과 관련된 파라미터도 사용하게 된다면, 정확도를 더 높 일 수 있다. 도 7은 본 명세서의 제1 개시에 따라 학습된 인공신경망 모델을 시각화한 예시도이다. 도 7을 참고하여 알 수 있는 바와 같이, 본 명세서의 제1 개시에 따르면, 카메라를 통해 촬영한 영상 내에서 사 용자의 골프 스윙을 골격(Skelton)의 움직임으로 단순화하여 표현할 수 있다. 이와 같이 골프 스윙을 골격의 움 직으로 단순화하면 기구학(Kinematics)에 의하여, 골프채를 휘두르는 손의 각속도 및 속도를 손쉽게 구할 수 있 고 나아가서는 골프채 헤드의 각속도 및 속도도 손쉽게 구해낼 수 있다. 따라서 골프채의 무게만 안다면, 골프 공에 가해지는 충격량도 알아낼 수 있다. 골프채의 무게에 대한 정보는 대체로 골프채를 비전(Vision) 인식하여 판별해내고, 이를 데이터베이스에서 조회함으로써 획득할 수 있다. 한편, 골프공에 가해지는 충격량은 일반 물리법칙에 따라 골프공의 운동량으로부터 알아낼 수도 있다. 또한, 도 7에 도시된 바와 같이, 골프채 헤드의 궤적도 학습되어 인공신경망 모델로 구축될 수 있다. 도 7에는 정확하게 도시되지 않았지만, 전술한 바와 같이 골프채 페이스면의 각도도 학습되어 인공신경망 모델 로 구축될 수 있다. II. 본 명세서의 제2 개시 본 명세서의 제2 개시는 전술한 제1 개시에 따라 구축된 인공신경망 모델을 이용하여, XR 기기를 통해 가상 골 프 게임 서비스를 제공하는 방안을 제시한다. 도 8은 본 명세서의 제2 개시에서 사용되는 XR 기기의 일 예를 나타낸 예시도이다. 도 8에 도시된 바와 같이, 가상 골프 게임 서비스를 제공하기 위하여 확장현실(eXtended Reality, XR) 기기가 활용될 수 있다. 확장현실(XR)은 가상현실(Virtual Reality, XR), 증강현실(Augmented Reality, AR), 혼합현실(Mixed Reality, MR)을 총칭한다. VR 기술은 현실 세계의 객체나 배경 등을 CG 영상으로만 제공하고, AR 기술은 실제 사물 영상 위에 가상으로 만들어진 CG 영상을 함께 제공하며, MR 기술은 현실 세계에 가상 객체들을 섞고 결합시켜서 제공 하는 컴퓨터 그래픽 기술이다. MR 기술은 현실 객체와 가상 객체를 함께 보여준다는 점에서 AR 기술과 유사하다. 그러나, AR 기술에서는 가상 객체가 현실 객체를 보완하는 형태로 사용되는 반면, MR 기술에서는 가상 객체와 현실 객체가 동등한 성격으로 사용된다는 점에서 차이점이 있다. XR 기술은 HMD(Head-Mount Display), HUD(Head-Up Display), 휴대폰, 태블릿 PC, 랩탑, 데스크탑, TV, 디지털 사이니지 등에 적용될 수 있고, XR 기술이 적용된 장치를 XR 장치(XR Device)라 칭할 수 있다. 도 9는 도 8에 도시된 XR 기기의 구성을 예시적으로 나타낸 블록도이다. 도 9를 참조하여 알 수 있는 바와 같이, XR 기기은 신경 프로세싱 유닛, 메모리, 무선 통신부 , 입력부, 출력부, 시스템 버스, CPU을 포함할 수 있다. 상기 무선 통신부은 근거리 통신 송수신기를 포함할 수 있다. 상기 근거리 통신 송수신기는 예를 들면 WLAN(Wireless LAN), Wi-Fi(Wireless-Fidelity), Wi-Fi(Wireless Fidelity) Direct, 블루투스 (Bluetooth쪠), RFID(Radio Frequency Identification), 적외선 통신(Infrared Data Association; IrDA), UWB(Ultra Wideband), ZigBee, NFC(Near Field Communication), Wireless USB(Wireless Universal Serial Bus) 등을 지원할 수 있다. 상기 출력부은 디스플레이와 스피커를 포함할 수 있다. XR 기기는 상기 무선 통신부를 통해 네트워크 상의 서버로부터 XR 기기를 위한 영상, 즉 골프장 영 상을 수신할 수 있다. 상기 수신된 영상은 CPU으로 전달될 수 있다. 상기 CPU는 디코더를 포함할 수 있고, 상기 영상을 디코딩하여 상기 디스플레이에 표시할 수 있다. 상기 입력부는 XR 기기에 입력되는 다양한 데이터 또는 신호를 제공하는 다양한 구성 요소들을 포 함할 수 있다, 상기 입력부는 영상 신호 입력을 위한 카메라, 음향 신호 입력을 위한 마이크로폰 , 조도 센서, 라이다 센서 등을 포함할 수 있다. 입력부의 카메라는 가시광선 카메라, 근적외선 카메라, 및 트루뎁스(truedepth) 카메라 중 적어도 하나로 구성될 수 있다. 단, 이에 제한되지 않으며, 카메라는 가시광선, 근적외선을 동시에 감지하도록 구성된 복합 이미지 센서로 구성되어 가시광선과 근적외선을 동시에 감지하도록 구성되는 것도 가능하다. 상기 카메라는 복수 개일 수 있다. 상기 복수 개의 카메라들 중 제1 복수의 카메라들은 전방을 향하도록 배치되어 있다. 이러한 제1 복수의 카메라들은 스테레오스코픽 방식으로 골프공의 검출하고 추적하기 위하여 촬 영하는 기능을 담당할 수 있다. 또한, 제1 복수의 카메라들은 스테레오스코픽 방식으로 사용자의 골프 스윙(즉, 사용자의 팔 동작)과 그에 따른 골프채의 움직임을 검출하고 추적하기 위하여 촬영하는 기능을 담당할 수 있다. 그리고 상기 복수 개의 카메라들 중 제2 복수의 카메라들은 아래쪽을 향하도록 배치되어 있어서, 제1 복수의 카 메라에 의해서 포착되지 않을 수 있는 사용자의 하체의 모션을 검출하고 추척하기 위하여 촬영하는 기능을 담당할 수 있다. 상기 라이다 센서는 실제 세상에 놓여진 골프공을 감지(즉, 사용자가 골프 어드레스 자세를 취했을 때 골 프공을 감지)하고 골프공의 좌표 및 거리를 정확하게 측정 및 추적하는데 사용될 수 있다. 또한, 라이다 센서는 골프공에 진입하는 골프채 헤드의 각도 및 궤도를 정확하게 측정 및 추적하는데 사용될 수 있다. 상기 디스플레이는 CPU의 제어에 따라 XR 영상을 출력할 수 있다. 상기 디스플레이는 투명 글래스를 포함할 수 있다. 상기 NPU는 가상 골프 서비스를 위해 필요한 복수의 인공신경망 모델을 위한 연산을 수행할 수 있다. 예를 들어, 복수의 인공신경망 모델은 객체 검출(Object Detection)/객체 분리(Object Segmentation) 또는 객체 추 적(Object Tracking)을 위한 제1 인공신경망 모델, 자세 추정(Pose Estimation)을 위한 제2 인공신경망 모델, 스케일링을 위한 제3 인공신경망 모델, 모션 예측을 위한 제4 인공신경망 모델 중 하나 이상을 포함할 수 있다. 바닥에 놓여진 실제 골프공을 상기 XR 기기의 상기 카메라를 통해 영상으로 촬영한 경우, 상기 제1 인공신경망 모델은 상기 영상 내에서 상기 골프공을 객체로서 검출할 수 있다. 또한, 상기 제1 인공신경망 모델 은 상기 영상 내에서 상기 골프공이라는 객체를 분리시킬 수 있다. 이 경우, 상기 분리된 골프공 이미지는 상기 XR 기기의 디스플레이에 표시되는 가상의 골프 환경 내에 표시될 수 있다. 또한, 상기 제1 인공신 경망 모델은 바닥에 놓여진 실제 골프공을 사용자가 골프 스윙을 통하여 골프채로 타격하여 날라가는 경우, 비 행하는 골프공을 추적할 수 있다. 그러면, 상기 XR 기기의 디스플레이에 표시되는 가상의 골프 환경 에서는 상기 골프공의 이미지가 비행하는 것으로 표시될 수 있다. 한편, 사용자가 상기 XR 기기를 착용한 상태에서 골프 스윙을 하는 경우, 상기 XR 기기의 카메라 중에서 전방을 향하도록 배치된 제1 복수의 카메라를 통하여 사용자의 팔 동작과 그에 따른 골프채의 움 직임이 촬영되고, 아래쪽을 향하도록 배치된 제2 복수의 카메라를 통하여 사용자의 하체의 모션이 검출되면, 상 기 제2 인공 신경망 모델은 사용자의 골프 스윙 모션을 분석한다. 즉, 사용자가 상기 XR 기기를 착용한 상 태에서 골프 스윙을 하는 경우, 상기 XR 기기의 제1 복수의 카메라와 제2 복수의 카메라를 통하여 도 5a 내지 도 5b 또는 도 6과 같이 골격 기준으로 골프 스윙이 분석된다. 그러면, 상기 XR 기기의 디스플레이 에 표시되는 가상의 골프 환경에서는 사용자의 골프 스윙이 그대로 재현되어 표시될 수 있다. 상기 스케일링을 위한 제3 인공신경망 모델은 미리 저장된 골프 프로의 골프 스윙을 사용자의 신체 사이즈에 맞 도록 스케일링하기 위한 것이다. 예를 들어, 사용자가 자신의 골프 스윙과 함께 타이거 우즈의 골프 스윙이 XR 기기의 디스플레이에 표시되길 원한다고 가정하자. 이때, 사용자의 신장 조건이 확연하게 차이가 난다면, 사용자는 직관적으로 자신의 골프 스윙과 타이거 우즈의 골프 스윙을 비교하기 어려울 수 있다. 따라서, 상기 제3 인공신경망 모델은 타이거 우즈의 골프 스윙을 상기 사용자의 신장에 맞도록 스케일링할 수 있다. 이를 위하여, 상기 사용자는 상기 XR 기기의 상기 라이다 센서 또는 상기 카메라 중에 서 트루뎁스 카메라를 통하여 사전에 자신의 몸을 스캔하여 신체 정보(예컨대, 키, 팔길이, 다리 길이 등)가 상 기 XR 기기에 입력되도록 할 수 있다. 상기 제4 인공신경망 모델은 골프공의 비행을 예측하기 위해서 사용될 수 있다. 예를 들어, 가로 4m x 세로 4m x 높이 3m 크기의 실제 공간의 중앙에서 XR 기기를 착용한 상태에서 골프 스윙을 하였다고 가정하자. 실 제 공간의 중앙에서 사용자가 골프 스윙을 하였기 때문에 골프공은 2m만 비행한 후 벽에 부딛힐 것이다. 상기 제1 인공신경망 모델은 상기 사용자가 골프 스윙을 통하여 골프채로 타격하여 날라가는 시점부터 벽에 부딛히기 직전까지 비행하는 골프공을 추적하는데 이용된다. 그러나, 상기 제4 인공신경망 모델은 상기 실제 골프공이 상 기 실제 세상의 공간 벽에 부딛힌 이후에도, 상기 XR 기기의 디스플레이에 표시되는 가상의 골프 환경에서는 상기 골프공의 이미지가 계속 비행하여 날라가는 것으로 표시하기 위하여, 상기 실제 골프공이 벽에 부딛히기 직전까지 비행하였던 것을 바탕으로, 상기 제4 인공신경망 모델은 상기 골프공이 앞으로의 비행을 예 측할 수 있다. 또한, 상기 제4 인공신경망 모델은 상기 XR 기기의 카메라, 예컨대 전방을 향하도록 배치된 제1 복 수의 카메라 또는 아래쪽을 향하도록 배치된 제2 복수의 카메라를 통하여 촬영된 사용자의 골프 스윙이 부분적 인 경우, 상기 부분적인 골프 스윙을 기반으로 전체 골프 스윙을 만들어낼 수 있다. 예를 들어, 상기 XR 기기 의 카메라의 화각이 좁아서, 사용자의 골프 스윙 모션 중 일부분이 촬영되지 않은 경우, 상기 제4 인공신경망 모델은 촬영되지 않은 부분을 생성해낼 수 있다. 도 10은 본 명세서의 제2 개시의 일 예시에 따른 방법을 나타낸 예시도이고, 도 11은 XR 기기를 착용한 사용자 가 골프를 즐기는 예를 나타낸 예시도이고, 도 12는 XR 기기의 디스플레이에 표시되는 가상 골프 환경을 나타낸 예시도이다. 도 10을 참조하여 알 수 있는 바와 같이, XR 기기의 카메라를 통해 바닥에 놓여진 실제 골프 공이 주 피사체로 촬영될 수 있다(S1001). 그리고, 객체 검출/객체 분리를 위한 인공신경망을 통해, 상기 촬영된 이미지 내에서 상기 실제 골프공이 검출 되고, 상기 골프공의 이미지가 배경으로부터 분리될 수 있다(S1003). 다음으로, 상기 XR 기기의 디스플레이에 표시되는 가상 골프 환경 내에 상기 실제 골프 공의 이미지가 합성되어 표시될 수 있다(S1005). 다음으로, 상기 XR 기기의 카메라를 통해 사용자의 골프 어드레스 자세도 촬영될 수 있다(S1007). 그러면, 사용자의 골프 어드레스 자세가 상기 XR 기기의 디스플레이에 표시되는 가상 골프 환경 내에 재현되어 표시될 수 있다(S1009). 상기 XR 기기의 카메라를 통해 촬영되는 사용자의 골프 스윙 모션이 도 12에 도시된 바와 같이 상기 XR 기기의 디스플레이에 표시되는 가상 골프 환경 내에 재현되어 표시될 수 있다(S1011). 사용자의 골프 스윙 모션에 따라 골프채가 실제 공에 임팩트되어 비행하는 것을 상기 XR 기기의 카메라를 통해 촬영한 후, 상기 XR 기기의 디스플레이에 표시되는 가상 골프 환경 내에 표시할 수 있다(S1013). 도 13은 본 명세서의 제2 개시의 다른 일 예시에 따른 방법을 나타낸 예시도이다. 먼저, XR 기기는 사용자의 신체 정보를 라이다 센서 혹은 트루뎁스 카메라 등을 통하여 획득할 수 있다 (S1301). 다음으로, XR 기기는 복수의 가상 골퍼 중에서 하나의 가상 골퍼에 대한 선택을 상기 사용자로부터 수신 할 수 있다(S1303). 이어서, 상기 XR 기기는 선택된 가상 골퍼의 신체를 상기 사용자의 신체를 기준으로 스케일링할 수 있다 (S1305). 상기 XR 기기는 사용자의 골프 스윙과 가상 골퍼의 스윙이 대비될 수 있도록 디스플레이에 표시되는 가상 골프 환경 내에 표시할 수 있다(S1307). 본 명세서와 도면에 나타난 본 개시의 예시들은 본 개시의 기술 내용을 쉽게 설명하고 본 개시의 이해를 돕기 위해 특정 예를 제시한 것뿐이며, 본 명의 범위를 한정하고자 하는 것은 아니다. 지금까지 설명한 예시들 이외 에도 다른 변형 예들이 실시 가능하다는 것은 본 개시가 속하는 기술 분야에서 통상의 지식을 가진 자에게 자명 한 것이다.도면 도면1 도면2 도면3a 도면3b 도면4 도면5a 도면5b 도면6 도면7 도면8 도면9 도면10 도면11 도면12 도면13"}
{"patent_id": "10-2023-0114946", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 종래의 스크린 골프 시스템에 적용되는 센싱장치의 일 예에 대해 나타낸 도면이다. 도 2는 예시적인 인공신경망모델을 설명하는 개략적인 개념도이다. 도 3a은 컨볼루션 신경망(CNN)의 기본 구조를 설명하기 위한 도면이다. 도 3b는 컨볼루션 신경망의 동작을 이해하기 쉽게 나타낸 종합도이다. 도 4는 본 명세서의 제1 개시에 따른 학습 방법을 나타낸 예시도이다. 도 5a 내지 도 5b는 골프 스윙 과정에서 골격(skeleton)을 이용한 자세 추정(pose estimation)의 일 예시를 나 타낸다. 도 6은 골프 스윙 과정을 골격 형태로 나타낸 예시도이다. 도 7은 본 명세서의 제1 개시에 따라 학습된 인공신경망 모델을 시각화한 예시도이다. 도 8은 본 명세서의 제2 개시에서 사용되는 XR 기기의 일 예를 나타낸 예시도이다. 도 9는 도 8에 도시된 XR 기기의 구성을 예시적으로 나타낸 블록도이다. 도 10은 본 명세서의 제2 개시의 일 예시에 따른 방법을 나타낸 예시도이다. 도 11은 XR 기기를 착용한 사용자가 골프를 즐기는 예를 나타낸 예시도이다. 도 12는 XR 기기의 디스플레이에 표시되는 가상 골프 환경을 나타낸 예시도이다. 도 13은 본 명세서의 제2 개시의 다른 일 예시에 따른 방법을 나타낸 예시도이다."}
