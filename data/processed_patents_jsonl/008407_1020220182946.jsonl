{"patent_id": "10-2022-0182946", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0102026", "출원번호": "10-2022-0182946", "발명의 명칭": "생성 모델 기반 데이터 분류 방법 및 장치", "출원인": "서울대학교산학협력단", "발명자": "윤성로"}}
{"patent_id": "10-2022-0182946", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "프로세서를 포함한 데이터 분류 장치에 의해 수행되는 생성 모델 기반 데이터 분류 방법으로서,결측치가 있는 입력 데이터를 기반으로 제 1 생성 모델을 실행하여 상기 결측치를 채운 대체 데이터(imputeddata)를 생성하는 단계;상기 입력 데이터의 클래스 라벨 및 상기 대체 데이터를 기반으로 평가 모델을 실행하여 상기 대체 데이터에 대한 평가 데이터를 생성하는 단계; 및상기 평가 데이터를 기반으로 상기 제 1 생성 모델 및 상기 평가 모델을 학습하는 단계를 포함하는,데이터 분류 방법."}
{"patent_id": "10-2022-0182946", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1 항에 있어서,상기 대체 데이터를 생성하는 단계는,상기 입력 데이터의 저차원 벡터를 획득하는 단계; 및상기 저차원 벡터를 입력으로 상기 제 1 생성 모델을 실행하는 단계를 포함하는,데이터 분류 방법."}
{"patent_id": "10-2022-0182946", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 2 항에 있어서,상기 저차원 벡터를 획득하는 단계는,상기 결측치를 무작위 숫자로 채운 데이터를 입력으로 인코더 네트워크를 실행하여 상기 저차원 벡터를 추출하는 단계를 포함하는,데이터 분류 방법."}
{"patent_id": "10-2022-0182946", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 1 항에 있어서,상기 대체 데이터는 상기 입력 데이터와 동일한 차원의 벡터로서, 적어도 하나의 특징 벡터를 포함하고,상기 평가 데이터는 상기 대체 데이터의 각 특징 벡터가 결측치를 채운 것인 지에 대한 예상값 및 상기 클래스라벨이 유사 라벨(pseudo label)인지에 대한 예상값을 포함한 이진 벡터인,데이터 분류 방법."}
{"patent_id": "10-2022-0182946", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제 1 항에 있어서,공개특허 10-2024-0102026-3-상기 학습하는 단계는,상기 입력 데이터, 상기 대체 데이터, 상기 평가 데이터 및 상기 클래스 라벨을 기반으로 정의된 제 1 손실 함수를 이용하여 상기 제 1 생성 모델 및 상기 평가 모델을 생성적 적대 신경망(Generative AdversarialNetwork; GAN) 학습 방법에 의해 학습하는 단계를 포함하는,데이터 분류 방법."}
{"patent_id": "10-2022-0182946", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제 1 항에 있어서,상기 입력 데이터가 라벨 결측인 경우, 상기 평가 데이터를 생성하는 단계는,상기 대체 데이터를 기반으로 분류기 네트워크를 실행하여 상기 입력 데이터의 유사 라벨을 획득하는 단계; 및상기 유사 라벨을 상기 클래스 라벨로 하여 상기 평가 모델을 실행하여 상기 평가 데이터를 생성하는 단계를 포함하고,상기 방법은,상기 대체 데이터, 상기 유사 라벨 및 상기 평가 데이터의 유사 라벨인지에 대한 예상값을 기반으로 정의된 제 2 손실 함수를 이용하여 상기 분류기 네트워크를 준지도 학습 방법에 의해 학습하는 단계를 더 포함하는,데이터 분류 방법."}
{"patent_id": "10-2022-0182946", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제 2 항에 있어서,상기 입력 데이터가 소수 클래스 라벨인 경우, 상기 저차원 벡터를 획득하는 단계는,소수(minor) 클래스 라벨을 기반으로 제 2 생성 모델을 실행하여 상기 저차원 벡터를 생성하는 단계를포함하고,상기 방법은,상기 대체 데이터를 기반으로 분류기 네트워크를 실행하여 상기 입력 데이터의 클래스를 예측하는단계; 및상기 대체 데이터, 상기 예측된 클래스 및 상기 소수 클래스 라벨을 기반으로 정의된 제 3 손실 함수를 이용하여 상기 제 2 생성 모델을 학습하는 단계를 더 포함하는,데이터 분류 방법."}
{"patent_id": "10-2022-0182946", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제 1 항에 있어서,상기 대체 데이터를 기반으로 분류기 네트워크를 실행하여 상기 입력 데이터의 클래스를 예측하는 단계를 더 포함하는,데이터 분류 방법."}
{"patent_id": "10-2022-0182946", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "프로세서를 포함한 데이터 분류 장치에 의해 수행되는 생성 모델 기반 데이터 분류 방법으로서,결측치가 있는 입력 데이터를 기반으로 제 1 생성 모델을 실행하여 상기 결측치를 채운 대체 데이터(imputeddata)를 생성하는 단계; 및공개특허 10-2024-0102026-4-상기 대체 데이터를 기반으로 분류기 네트워크를 실행하여 상기 입력 데이터의 클래스를 예측하는 단계를 포함하고,상기 대체 데이터를 생성하는 단계는,상기 결측치를 무작위 숫자로 채운 데이터를 입력으로 인코더 네트워크를 실행하여 추출된 저차원 벡터 또는 소수(minor) 데이터 라벨을 기반으로 제 2 생성 모델을 실행하여 생성된 저차원 벡터를 입력으로 상기 제 1 생성모델을 실행하는 단계를 포함하는,데이터 분류 방법."}
{"patent_id": "10-2022-0182946", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "생성 모델 기반 데이터 분류 장치로서,적어도 하나의 명령어를 저장한 메모리; 및프로세서를 포함하고, 상기 적어도 하나의 명령어는 상기 프로세서에 의해 실행될 때 상기 프로세서로 하여금,결측치가 있는 입력 데이터를 기반으로 제 1 생성 모델을 실행하여 상기 결측치를 채운 대체 데이터(imputeddata)를 생성하고,상기 입력 데이터의 클래스 라벨 및 상기 대체 데이터를 기반으로 평가 모델을 실행하여 상기 대체 데이터에 대한 평가 데이터를 생성하고,상기 평가 데이터를 기반으로 상기 제 1 생성 모델 및 상기 평가 모델을 학습하도록 구성되는,데이터 분류 장치."}
{"patent_id": "10-2022-0182946", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제 10 항에 있어서,상기 적어도 하나의 명령어는 상기 프로세서에 의해 실행될 때 상기 프로세서로 하여금, 상기 대체 데이터를 생성하기 위하여,상기 입력 데이터의 저차원 벡터를 획득하고,상기 저차원 벡터를 입력으로 상기 제 1 생성 모델을 실행하도록 구성되는,데이터 분류 장치."}
{"patent_id": "10-2022-0182946", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제 11 항에 있어서,상기 적어도 하나의 명령어는 상기 프로세서에 의해 실행될 때 상기 프로세서로 하여금, 상기 저차원 벡터를 획득하기 위하여,상기 결측치를 무작위 숫자로 채운 데이터를 입력으로 인코더 네트워크를 실행하여 상기 저차원 벡터를 추출하도록 구성되는,데이터 분류 장치."}
{"patent_id": "10-2022-0182946", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제 10 항에 있어서,공개특허 10-2024-0102026-5-상기 대체 데이터는 상기 입력 데이터와 동일한 차원의 벡터로서, 적어도 하나의 특징 벡터를 포함하고,상기 평가 데이터는 상기 대체 데이터의 각 특징 벡터가 결측치를 채운 것인 지에 대한 예상값 및 상기 클래스라벨이 유사 라벨(pseudo label)인지에 대한 예상값을 포함한 이진 벡터인,데이터 분류 장치."}
{"patent_id": "10-2022-0182946", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제 10 항에 있어서,상기 적어도 하나의 명령어는 상기 프로세서에 의해 실행될 때 상기 프로세서로 하여금, 상기 학습을 위해,상기 입력 데이터, 상기 대체 데이터, 상기 평가 데이터 및 상기 클래스 라벨을 기반으로 정의된 제 1 손실 함수를 이용하여 상기 제 1 생성 모델 및 상기 평가 모델을 생성적 적대 신경망(Generative AdversarialNetwork; GAN) 학습 방법으로 학습하도록 구성되는,데이터 분류 장치."}
{"patent_id": "10-2022-0182946", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제 10 항에 있어서,상기 적어도 하나의 명령어는 상기 프로세서에 의해 실행될 때 상기 프로세서로 하여금, 상기 입력 데이터가 라벨 결측인 경우,상기 평가 데이터를 생성하기 위하여, 상기 대체 데이터를 기반으로 분류기 네트워크를 실행하여 상기 입력 데이터의 유사 라벨을 획득하고, 상기 유사 라벨을 상기 클래스 라벨로 하여 상기 평가 모델을 실행하여 상기 평가 데이터를 생성하도록 구성되고,상기 대체 데이터, 상기 유사 라벨 및 상기 평가 데이터의 유사 라벨인지에 대한 예상값을 기반으로 정의된 제2 손실 함수를 이용하여 상기 분류기 네트워크를 준지도 학습 방법에 의해 학습하도록 구성되는,데이터 분류 장치."}
{"patent_id": "10-2022-0182946", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제 11 항에 있어서,상기 적어도 하나의 명령어는 상기 프로세서에 의해 실행될 때 상기 프로세서로 하여금, 상기 입력 데이터가 소수 클래스 라벨인 경우,상기 저차원 벡터를 획득하기 위하여, 상기 소수 클래스 라벨을 기반으로 제 2 생성 모델을 실행하여 상기 저차원 벡터를 생성하도록 구성되고,상기 대체 데이터를 기반으로 분류기 네트워크를 실행하여 상기 입력 데이터의 클래스를 예측하고, 상기 대체데이터, 상기 예측된 클래스 및 상기 소수 클래스 라벨을 기반으로 정의된 제 3 손실 함수를 이용하여 상기 제2 생성 모델을 학습하도록 구성되는,데이터 분류 장치."}
{"patent_id": "10-2022-0182946", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제 10 항에 있어서,상기 적어도 하나의 명령어는 상기 프로세서에 의해 실행될 때 상기 프로세서로 하여금, 상기 대체 데이터를 기공개특허 10-2024-0102026-6-반으로 분류기 네트워크를 실행하여 상기 입력 데이터의 클래스를 예측하도록 구성되는,데이터 분류 장치."}
{"patent_id": "10-2022-0182946", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "생성 모델 기반 데이터 분류 방법 및 장치에 관한 것으로, 생성 모델 기반 불완전 데이터 분류 모델을 이용하여 결측치, 클래스 불균형 및 라벨 결측 중 하나 이상의 문제가 존재하는 불완전 데이터를 분류하는 방법 및 장치를 제공한다."}
{"patent_id": "10-2022-0182946", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 생성 모델 기반 데이터 분류 방법 및 장치에 관한 것으로, 생성 모델 기반 불완전 데이터 분류 모델 을 이용하여 결측치, 클래스 불균형 및 라벨 결측 중 하나 이상의 문제가 존재하는 불완전 데이터를 분류하는 방법 및 장치에 관한 것이다."}
{"patent_id": "10-2022-0182946", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "이하에서 기술되는 내용은 본 발명의 실시예와 관련되는 배경 정보를 제공할 목적으로 기재된 것일 뿐이고, 기 술되는 내용들이 당연하게 종래기술을 구성하는 것은 아니다. 최근 인공지능 (AI) 및 딥러닝 기술이 급속도로 발전함에 따라 이를 실제 산업에 응용하는 사례가 많아지고 있 다. 컴퓨터 비전과 음성 인식 등에서 좋은 성능을 보이고 있으며, 최근 추천 시스템, 질병 진단까지 그 영역을 확장하고 있다. 하지만 실제 산업에서 취득된 대부분의 학습 데이터들은 불완전한데, 특히 특징값이나 정답 라벨이 결측되어 있 거나, 클래스에 불균형이 존재한다. 이러한 불완전 데이터 문제로 인해 딥러닝 기반 분류기의 학습이 불가능해 지거나, 학습된 모델의 성능을 크게 떨어뜨리기 때문에 데이터 전처리를 통해 위 문제들을 해결하는 것이 필수 적이다. 결측치 예측(Imputation)은 데이터 내에 결측된 정보를 예측하는 기술로서, 현재까지 제안된 결측치 예측 기술 은, 불완전 데이터의 여러 문제들을 동시에 해결하지 못한다. 이에 각각의 문제를 해결하기 위한 개별 기술들을 순차적으로 적용하여 위 문제들이 동시에 존재하는 학습 데이터로부터 분류기를 학습하려는 시도들이 있었다. 하지만 이와 같은 방식은 학습 데이터에 존재하는 불완전 문제에 따라 별도의 전처리 파이프라인을 구축해야 한 다는 단점과, 각각의 기술이 하나의 문제에만 집중하기 때문에 문제들 간의 연관성을 무시하며 이로 인해 문제 들 간의 연관성을 학습하기 어려운 한계가 있다. 한편, 전술한 선행기술은 발명자가 본 발명의 도출을 위해 보유하고 있었거나, 본 발명의 도출 과정에서 습득한 기술 정보로서, 반드시 본 발명의 출원 전에 일반 공중에게 공개된 공지기술이라 할 수는 없다."}
{"patent_id": "10-2022-0182946", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명의 일 과제는 전술한 문제점을 해결하기 위하여, 특별한 전처리 파이프라인 없이도, 구성요소 간의 상호 작용을 통해 여러 불완전 데이터 문제를 동시에 고려할 수 있는 데이터 분류 방법 및 장치를 제공하는 것이다. 본 발명의 일 과제는 딥 러닝 기반의 분류기에서 불완전 데이터 문제들을 동시에 해결하면서 분류 성능을 높일 수 있는 생성 모델 기반 불완전 데이터 분류 모델과 이를 이용한 데이터 분류 방법 및 장치를 제공하는 것이다. 본 발명의 목적은 이상에서 언급한 과제에 한정되지 않으며, 언급되지 않은 본 발명의 다른 목적 및 장점들은 하기의 설명에 의해서 이해될 수 있고, 본 발명의 실시 예에 의해 보다 분명하게 이해될 것이다. 또한, 본 발명 의 목적 및 장점들은 청구범위에 나타낸 수단 및 그 조합에 의해 실현될 수 있음을 알 수 있을 것이다."}
{"patent_id": "10-2022-0182946", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "실시예에 의하면 프로세서를 포함한 데이터 분류 장치에 의해 수행되는 생성 모델 기반 데이터 분류 방법으로서, 결측치가 있는 입력 데이터를 기반으로 제 1 생성 모델을 실행하여 상기 결측치를 채운 대체 데이 터(imputed data)를 생성하는 단계; 상기 입력 데이터의 클래스 라벨 및 상기 대체 데이터를 기반으로 평가 모 델을 실행하여 상기 대체 데이터에 대한 평가 데이터를 생성하는 단계; 및 상기 평가 데이터를 기반으로 상기 제 1 생성 모델 및 상기 평가 모델을 학습하는 단계를 포함하는, 데이터 분류 방법을 제공한다. 상기 대체 데이터를 생성하는 단계는, 상기 입력 데이터의 저차원 벡터를 획득하는 단계; 및 상기 저차원 벡터 를 입력으로 상기 제 1 생성 모델을 실행하는 단계를 포함할 수 있다. 상기 저차원 벡터를 획득하는 단계는,상기 결측치를 무작위 숫자로 채운 데이터를 입력으로 인코더 네트워크를 실행하여 상기 저차원 벡터를 추출하는 단계를 포함할 수 있다. 상기 대체 데이터는 상기 입력 데이터와 동일한 차원의 벡터로서, 적어도 하나의 특징 벡터를 포함하고, 상기 평가 데이터는 상기 대체 데이터의 각 특징 벡터가 결측치를 채운 것인 지에 대한 예상값 및 상기 클래스 라벨 이 유사 라벨(pseudo label)인지에 대한 예상값을 포함한 이진 벡터일 수 있다. 상기 학습하는 단계는, 상기 입력 데이터, 상기 대체 데이터, 상기 평가 데이터 및 상기 클래스 라벨을 기반으 로 정의된 제 1 손실 함수를 이용하여 상기 제 1 생성 모델 및 상기 평가 모델을 생성적 적대 신경망 (Generative Adversarial Network; GAN) 학습 방법에 의해 학습하는 단계를 포함할 수 있다. 상기 입력 데이터가 라벨 결측인 경우, 상기 평가 데이터를 생성하는 단계는,상기 대체 데이터를 기반으로 분류 기 네트워크를 실행하여 상기 입력 데이터의 유사 라벨을 획득하는 단계; 및상기 유사 라벨을 상기 클래스 라벨 로 하여 상기 평가 모델을 실행하여 상기 평가 데이터를 생성하는 단계를 포함하고, 상기 방법은,상기 대체 데 이터, 상기 유사 라벨 및 상기 평가 데이터의 유사 라벨인지에 대한 예상값을 기반으로 정의된 제 2 손실 함수 를 이용하여 상기 분류기 네트워크를 준지도 학습 방법에 의해 학습하는 단계를 더 포함할 수 있다. 상기 입력 데이터가 소수 클래스 라벨인 경우, 상기 저차원 벡터를 획득하는 단계는, 소수(minor) 클래스 라벨 을 기반으로 제 2 생성 모델을 실행하여 상기 저차원 벡터를 생성하는 단계를 포함하고,상기 방법은,상기 대체 데이터를 기반으로 분류기 네트워크를 실행하여 상기 입력 데이터의 클래스를 예측하는 단계; 및 상기 대체 데 이터, 상기 예측된 클래스 및 상기 소수 클래스 라벨을 기반으로 정의된 제 3 손실 함수를 이용하여 상기 제 2 생성 모델을 학습하는 단계를 더 포함할 수 있다. 상기 대체 데이터를 기반으로 분류기 네트워크를 실행하여 상기 입력 데이터의 클래스를 예측하는 단계를 더 포 함할 수 있다. 실시예에 의하면, 프로세서를 포함한 데이터 분류 장치에 의해 수행되는 생성 모델 기반 데이터 분류 방법으로 서, 결측치가 있는 입력 데이터를 기반으로 제 1 생성 모델을 실행하여 상기 결측치를 채운 대체 데이터 (imputed data)를 생성하는 단계; 및 상기 대체 데이터를 기반으로 분류기 네트워크를 실행하여 상기 입력 데이 터의 클래스를 예측하는 단계를 포함하고, 상기 대체 데이터를 생성하는 단계는,상기 결측치를 무작위 숫자로 채운 데이터를 입력으로 인코더 네트워크를 실행하여 추출된 저차원 벡터 또는 소수(minor) 데이터 라벨을 기반 으로 제 2 생성 모델을 실행하여 생성된 저차원 벡터를 입력으로 상기 제 1 생성 모델을 실행하는 단계를 포함 하는, 데이터 분류 방법을 제공한다. 실시예에 의하면, 생성 모델 기반 데이터 분류 장치로서, 적어도 하나의 명령어를 저장한 메모리; 및 프로세서 를 포함하고, 상기 적어도 하나의 명령어는 상기 프로세서에 의해 실행될 때 상기 프로세서로 하여금, 결측치가 있는 입력 데이터를 기반으로 제 1 생성 모델을 실행하여 상기 결측치를 채운 대체 데이터(imputed data)를 생 성하고, 상기 입력 데이터의 클래스 라벨 및 상기 대체 데이터를 기반으로 평가 모델을 실행하여 상기 대체 데 이터에 대한 평가 데이터를 생성하고, 상기 평가 데이터를 기반으로 상기 제 1 생성 모델 및 상기 평가 모델을 학습하도록 구성되는, 데이터 분류 장치를 제공한다. 상기 적어도 하나의 명령어는 상기 프로세서에 의해 실행될 때 상기 프로세서로 하여금, 상기 대체 데이터를 생 성하기 위하여, 상기 입력 데이터의 저차원 벡터를 획득하고, 상기 저차원 벡터를 입력으로 상기 제 1 생성 모 델을 실행하도록 구성될 수 있다. 상기 적어도 하나의 명령어는 상기 프로세서에 의해 실행될 때 상기 프로세서로 하여금, 상기 저차원 벡터를 획 득하기 위하여, 상기 결측치를 무작위 숫자로 채운 데이터를 입력으로 인코더 네트워크를 실행하여 상기 저차원 벡터를 추출하도록 구성될 수 있다. 상기 대체 데이터는 상기 입력 데이터와 동일한 차원의 벡터로서, 적어도 하나의 특징 벡터를 포함하고, 상기 평가 데이터는 상기 대체 데이터의 각 특징 벡터가 결측치를 채운 것인 지에 대한 예상값 및 상기 클래스 라벨 이 유사 라벨(pseudo label)인지에 대한 예상값을 포함한 이진 벡터일 수 있다. 상기 적어도 하나의 명령어는 상기 프로세서에 의해 실행될 때 상기 프로세서로 하여금, 상기 학습을 위해, 상 기 입력 데이터, 상기 대체 데이터, 상기 평가 데이터 및 상기 클래스 라벨을 기반으로 정의된 제 1 손실 함수 를 이용하여 상기 제 1 생성 모델 및 상기 평가 모델을 생성적 적대 신경망(Generative Adversarial Network;GAN) 학습 방법으로 학습하도록 구성될 수 있다. 상기 적어도 하나의 명령어는 상기 프로세서에 의해 실행될 때 상기 프로세서로 하여금, 상기 입력 데이터가 라 벨 결측인 경우, 상기 평가 데이터를 생성하기 위하여, 상기 대체 데이터를 기반으로 분류기 네트워크를 실행하 여 상기 입력 데이터의 유사 라벨을 획득하고, 상기 유사 라벨을 상기 클래스 라벨로 하여 상기 평가 모델을 실 행하여 상기 평가 데이터를 생성하도록 구성되고, 상기 대체 데이터, 상기 유사 라벨 및 상기 평가 데이터의 유 사 라벨인지에 대한 예상값을 기반으로 정의된 제 2 손실 함수를 이용하여 상기 분류기 네트워크를 준지도 학습 방법에 의해 학습하도록 구성될 수 있다. 상기 적어도 하나의 명령어는 상기 프로세서에 의해 실행될 때 상기 프로세서로 하여금, 상기 입력 데이터가 소 수 클래스 라벨인 경우, 상기 저차원 벡터를 획득하기 위하여, 상기 소수 클래스 라벨을 기반으로 제 2 생성 모 델을 실행하여 상기 저차원 벡터를 생성하도록 구성되고, 상기 대체 데이터를 기반으로 분류기 네트워크를 실행 하여 상기 입력 데이터의 클래스를 예측하고, 상기 대체 데이터, 상기 예측된 클래스 및 상기 소수 클래스 라벨 을 기반으로 정의된 제 3 손실 함수를 이용하여 상기 제 2 생성 모델을 학습하도록 구성될 수 있다. 상기 적어도 하나의 명령어는 상기 프로세서에 의해 실행될 때 상기 프로세서로 하여금, 상기 대체 데이터를 기 반으로 분류기 네트워크를 실행하여 상기 입력 데이터의 클래스를 예측하도록 구성될 수 있다. 전술한 것 외의 다른 측면, 특징, 및 이점이 이하의 도면, 청구범위 및 발명의 상세한 설명으로부터 명확해질 것이다."}
{"patent_id": "10-2022-0182946", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "실시예에 의하면, 불완전 데이터 문제의 유형 별로 전처리 파이프라인을 구축할 필요가 없고, 불완전 데이터 분 류 모델의 구성요소 간의 상호작용을 통해 여러 불완전 데이터 문제를 동시에 고려함으로써 분류 성능을 극대화 할 수 있다. 실시예에 의하면, 전체적으로 적은 수의 학습 데이터 중에서 불완전 데이터를 제외하지 않고 최대한 활용할 수 있어 동일한 성능을 얻기 위한 데이터 취득 비용을 절감할 수 있다. 실시예에 의하면, 딥 러닝 기반의 분류기에서 불완전 데이터 문제들을 동시에 해결하면서 분류 성능을 높일 수 있기 때문에, 불완전 학습 데이터를 이용하는 모든 딥러닝 기반 분류기에 적용 가능하다."}
{"patent_id": "10-2022-0182946", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 2, "content": "본 발명의 효과는 이상에서 언급된 것들에 한정되지 않으며, 언급되지 아니한 다른 효과들은 아래의 기재로부터 당업자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2022-0182946", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명은 여러 가지 상이한 형태로 구현될 수 있으며, 여기에서 설명하는 실시 예들에 한정되지 않는다. 이하 실시 예에서는 본 발명을 명확하게 설명하기 위해서 설명과 직접적인 관계가 없는 부분을 생략하지만, 본 발명 의 사상이 적용된 장치 또는 시스템을 구현함에 있어서, 이와 같이 생략된 구성이 불필요함을 의미하는 것은 아 니다. 아울러, 명세서 전체를 통하여 동일 또는 유사한 구성요소에 대해서는 동일한 참조번호를 사용한다. 이하의 설명에서 제1, 제2 등의 용어는 다양한 구성요소들을 설명하는데 사용될 수 있지만, 상기 구성요소들은 상기 용어들에 의해 한정되어서는 안 되며, 상기 용어들은 하나의 구성요소를 다른 구성요소로부터 구별하는 목 적으로만 사용된다. 또한, 이하의 설명에서 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표 현을 포함한다. 이하의 설명에서, \"포함하다\" 또는 \"가지다\" 등의 용어는 명세서 상에 기재된 특징, 숫자, 단계, 동작, 구성요 소, 부분품 또는 이들을 조합한 것이 존재함을 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성요소, 부분품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되어야 한다. 종래의 소수 클래스의 오버샘플링을 수행하기 위한 기술은 소수 클래스 데이터 간의 선형 보간을 통해 오버샘플 링을 수행하기 때문에 고해상도 이미지 등의 고차원 데이터를 처리하기 위해 많은 연산량과 시간을 요구한다. 또한 데이터 내 비선형 패턴이 충분히 모델링되지 못한다. 이와 달리 본 발명의 오버샘플링을 위한 생성자는 학습된 딥러닝 네트워크를 이용하기 때문에 오버샘플링에 필 요한 연산량을 효과적으로 낮출 수 있고 비선형 패턴 모델링에 유리하다. 그리고 고차원 데이터 자체가 아닌 정 보가 압축된 저차원 벡터를 오버샘플링하기 때문에 상대적으로 쉬운 생성 작업으로 치환되어 높은 품질의 오버 샘플링을 수행할 수 있다. 또한 종래 기술은 전자의무기록 (EMR)로부터 환자의 질병을 예측하기 위해, 결측치가 있는 기록은 제외하고 결 측치가 없는 기록만을 모델 학습에 이용하며, 라벨이 결측된 경우에도 학습에서 제외하여 학습에 이용가능한 기 록 수가 현저히 감소하게 되고, 심한 경우 학습에 이용가능한 기록이 하나도 남지 않는 경우가 발생한다. 하지만 본 발명은 불완전한 데이터를 효과적으로 처리하여 모델 학습에 최대한 활용함으로써 모든 기록에 결측 치가 존재하는 경우에도 학습이 가능하며, 학습된 분류기 네트워크의 성능을 극대화할 수 있다. 한편, 기계학습 기반의 결측치 예측, 오버샘플링, 준지도학습 기법을 순차적으로 적용하여 데이터를 전처리한 후 DNN을 분류기 네트워크로 이용하는 기술은, 데이터에 존재하는 불완전 문제에 따라 전처리 기법을 선택하고 파이프라인을 설계하는 과정이 필요하고, 각각의 전처리 기술이 하나의 데이터 불완전 문제에만 집중하므로 문 제들 간의 연관성을 무시한다. 이와 달리 본 발명은 불완전 문제들이 존재하는 데이터가 입력되면 이를 자동적으로 처리하여 분류기 네트워크 를 학습시키므로 특별한 전처리 파이프라인을 설계할 필요가 없다. 또한 구성요소 간의 상호작용을 통해 여러 불완전 데이터 문제를 동시에 고려하여 분류 성능을 극대화 할 수 있다. 예를 들면, 제2 생성 모델이 저차원 벡터를 생성하면, 제1 생성 모델이 생성된 저차원 벡터를 받아 전체 특징값 이 결측된 것으로 간주하고 전체 특징값을 예측함으로써 데이터를 오버샘플링하게 된다. 오버샘플링된 데이터는 평가 모델에 입력되어 각 특징값이 잘 생성되었는지 평가받을 수 있고, 분류기 네트워크 에 입력되어 오버샘플링 된 데이터가 소수 클래스에 부합하는지 평가받을 수 있다. 라벨이 결측된 데이터를 분 류기 네트워크가 입력받아 유사라벨을 생성하면, 평가모델이 데이터와 Pseudo-label이 잘 부합하는지 평가한다. 이처럼 구성요소들이 다른 불완전 문제를 해결하는 구성요소에 활용되면서 시너지 효과를 발생시키고 최종적인 분류 성능을 향상시키게 된다. 본 발명은 결측치, 클래스 불균형, 라벨 결측 중 하나 이상의 데이터 불완전 문제가 존재하는 학습 데이터로부 터 딥러닝 기반 생성 모델을 이용하여 분류 성능을 극대화하는 알고리즘에 관한 것이다. 데이터 불완전 문제들 을 동시에 고려하여 사용하기에 간편한 동시에 구성요소 간 상호작용을 통해 분류 성능을 크게 개선할 수 있는 장점이 있다. 결측치 예측(Imputation) 기술은 데이터 내에 결측된 정보를 예측하는 것을 통칭한다. 오버샘플링 (Oversampling)은 클래스가 불균형한 학습 데이터에서 소수 클래스 데이터를 생성함으로써 다수 클래스의 데이 터 수와 동일하게 만드는 방법이다. 준지도학습 (Semi-supervised learning) 기술은 라벨이 결측된 데이터를 활 용하여 분류기의 성능을 높이는 학습 방식을 통칭한다. 본 발명에서는 유사라벨(Pseudo-label)을 생성하는 기술 이 이용되었다. 실시예에 따른 딥러닝 기반 생성 모델은 데이터의 분포를 모델링하며, 데이터 내의 문제를 해결 하는 데 활용될 수 있다. 본 발명은 인코더 네트워크를 이용하여 불완전 데이터로부터 저차원 특징값을 추출하고, 생성 모델을 이용하여 결측치와 소수 클래스 데이터를 생성하며, 분류기 네트워크는 분류를 수행함과 동시에 결측된 라벨을 예측할 수 있다. 본 발명은 딥러닝 기반의 여러 분류 시스템에 적용될 수 있다. 이하 도면을 참고하여 본 발명을 상세히 설명하기로 한다. 도 1은 실시예에 따른 생성 모델 기반 불완전 데이터 분류 장치의 동작을 개략적으로 설명하기 위한 예시도이다. 실시예에 따른 생성 모델 기반 데이터 분류 장치는 입력 데이터(DTA)를 분류하고 그 결과로 입력 데이터 (DTA)의 클래스(OUT_CLAS)를 출력한다. 일 예에서 입력 데이터(DTA)는 결측치가 있는 불완전 데이터(Imperfect Data)일 수 있다. 여기서 불완전 데이터 는 완전한 데이터라면 갖춰야할 정보 내지 값을 적어도 하나 결여한 데이터를 의미한다. 즉, 불완전 데이터는 적어도 하나의 결측치를 포함한다. 도 1에서 예시적인 결측 위치를 사선으로 표시하였다. 예를 들어 입력 데이터는 이미지, 시계열, 테이블 등 종류에 구애 받지 않으며, 결측치는 이미지의 경우 픽셀 또는 패치, 시계열과 테이블의 경우 특징값이 될 수 있다. 불완전 데이터는 예를 들어 결측치가 있는 데이터(일부 결측), 라벨이 없는 데이터(라벨 결측) 및 소수 클래스 데이터(전체 결측)를 포함한다. 불완전 데이터의 유형은 도 2를 참조하여 후술한다. 실시예에 따른 생성 모델 기반 데이터 분류 장치는 입력 데이터(DTA)의 결측치를 예측하여 대체 데이터 (Imputed Data)(P_DTA)를 생성하고, 생성된 대체 데이터(P_DTA)를 분류한 결과(OUT_CLAS)를 불완전 데이터 (DTA)의 분류 결과(클래스)로 출력한다. 한편 학습 과정에서 데이터 분류 장치는 입력 데이터(DTA)의 클래스 라벨(L)을 입력받을 수 있다. 라벨이 결측된 입력 데이터(DTA)의 경우 데이터 분류 장치는 유사 라벨(Pseudo Lable)을 생성할 수 있다. 도 2는 예시적인 불완전 데이터를 설명하기 위한 도면이다. 도 1을 참조하여 입력 데이터는(DTA)는 예를 들어 라벨(L1)이 있고 일부 데이터가 결측된 제 1 불완전 데이터 (DTA1), 라벨(L2)이 없는 제 2 불완전 데이터(DTA2) 및 소수 클래스 데이터(minor class data)로서 라벨(L3)이 있고 전체 데이터를 결측한 제 3 불완전 데이터(DTA3)를 포함한다. 도 2의 각 데이터에서 예시적인 결측 위치를 사선으로 표시하였다. 데이터 분류 장치는 불완전 데이터 분류 모델의 학습 과정에서 입력 데이터(DTA)의 라벨을 이용할 수 있다. 예를 들어 제 1 불완전 데이터(DTA1)는 정답 라벨(L1)이 주어지고, 제 3 불완전 데이터(DTA3)는 소수 클 래스 라벨(L3)이 주어진다. 예를 들어 제 2 불완전 데이터(DTA2)는 라벨(L2)이 결여되었다.데이터 분류 장치는 실시예에 따른 데이터 분류 과정을 실행하는 과정에서 입력 데이터(DTA)에 결측된 데 이터가 있는 경우 입력 데이터(DTA)의 결측치를 예상치로 채워서 도 1을 참조하여 대체 데이터(P_DTA)를 생성한 다. 예를 들어, 데이터 분류 장치는 제 1 불완전 데이터(DTA1)에 대한 제 1 대체 데이터(P_DTA1), 제 2 불완전 데이터(DTA2)에 대한 제 2 대체 데이터(P_DTA2) 및 제 3 불완전 데이터(DTA3)에 대한 제 3 대체 데이터 (P_DTA3)를 생성한다. 예를 들어, 제 1 대체 데이터(P_DTA1)은 데이터 분류 장치가 제 1 불완전 데이터(DTA1)의 결측치(예시적으 로 사선으로 표시한 위치)에 대해 예측한 대체 값(imputed value)을 포함한다. 예를 들어, 제 3 대체 데이터(P_DTA3)는 데이터 분류 장치가 제 3 불완전 데이터(DTA3)의 소수 클래스 라 벨(L3)에 대해 예측한 소수 클래스 데이터를 포함한다. 예를 들어 라벨(P_L2)는 제 2 불완전 데이터(DTA2)의 대체 데이터(P_DTA2)를 후술할 분류기 네트워크(C)에 입력 하여 얻은 유사 라벨이다. 도 3은 예시적인 불완전 데이터 유형을 결정하기 위한 흐름도이다. 도 2를 참조하여 입력 데이터(DTA)는 예시적으로 세 가지 유형의 불완전 데이터(DTA1, DTA2, DTA3)를 포함한다. 입력 데이터(DTA)는 결측이 없는 완전 데이터(DTA4)를 포함한다. 단계(P1)에서 입력 데이터(DTA)의 라벨 유무를 판단한다. 라벨이 없으면 제 2 불완전 데이터(DTA2)로 간주한다. 단계(P1)에서 라벨이 있으면 단계(P2)에서 입력 데이터(DTA)가 소수 클래스 라벨인지 판단한다. 소수 클래스 라 벨이면 제 3 불완전 데이터(DTA3)로 간주한다. 단계(P2)에서 소수 클래스 라벨이 아니면 단계(P3)에서 결측치가 있는 지 판단한다. 결측치가 있으면 제 1 불완 전 데이터(DTA1)로 간주한다. 결측치가 없으면 완전한 데이터(DTA4)로 간주한다. 도 4에 도시된 흐름도는 예시적인 것이고 다른 적절한 순서에 따라 불완전 데이터의 유형을 구분할 수 있다. 다 른 예에서 불완전 데이터의 유형 정보는 불완전 데이터와 함께 제공될 수 있다. 도 4는 실시예에 따른 생성 모델 기반 불완전 데이터 분류 모델의 블록도이다. 생성 모델 기반 데이터 분류 장치는 불완전 데이터 분류 모델을 실행하여 실시예에 따른 데이터 분류 방 법을 수행한다. 불완전 데이터 분류 모델은 예를 들어 인코더 네트워크(E), 제 1 생성 모델(G1), 제 2 생성 모델(G2), 평가 모 델(D) 및 분류기 네트워크(C)를 포함한다. 불완전 데이터 분류 모델의 구체적인 학습 과정 등은 이하에서 도면 을 참조하여 후술한다. 도 5는 실시예에 따른 생성 모델 기반 데이터 분류 장치의 블록도이다. 실시예에 따른 생성 모델 기반 데이터 분류 장치는 프로세서 및 메모리를 포함할 수 있다. 데이 터 분류 장치는 필요에 따라 추가적인 구성을 더 포함할 수 있다. 프로세서는 일종의 중앙처리장치로서, 메모리에 저장된 하나 이상의 명령어를 실행하여 데이터 분류 장치의 동작을 제어할 수 있다. 프로세서는 데이터를 처리할 수 있는 모든 종류의 장치를 포함할 수 있다. 프로세서는 예를 들어 프 로그램 내에 포함된 코드 또는 명령으로 표현된 기능을 수행하기 위해 물리적으로 구조화된 회로를 갖는, 하드 웨어에 내장된 데이터 처리 장치를 의미할 수 있다. 이와 같이 하드웨어에 내장된 데이터 처리 장치의 일 예로서, 마이크로프로세서(microprocessor), 중앙처리장치 (central processing unit: CPU), 프로세서 코어(processor core), 멀티프로세서(multiprocessor), ASIC(application-specific integrated circuit), FPGA(field programmable gate array) 등의 처리 장치를 망 라할 수 있으나, 이에 한정되는 것은 아니다. 프로세서는 하나 이상의 프로세서를 포함할 수 있다. 프로세서는 메모리에 저장된 프로그램, 명령어들에 기반하여 실시예에 따른 데이터 분류 방법을 실행 할 수 있다.메모리는 내장 메모리 및/또는 외장 메모리를 포함할 수 있으며, DRAM, SRAM, 또는 SDRAM 등과 같은 휘발 성 메모리, OTPROM(one time programmable ROM), PROM, EPROM, EEPROM, mask ROM, flash ROM, NAND 플래시 메 모리, 또는 NOR 플래시 메모리 등과 같은 비휘발성 메모리, SSD, CF(compact flash) 카드, SD 카드, Micro-SD 카드, Mini-SD 카드, Xd 카드, 또는 메모리 스틱(memory stick) 등과 같은 플래시 드라이브, 또는 HDD와 같은 저장 장치를 포함할 수 있다. 메모리는 자기 저장 매체(magnetic storage media) 또는 플래시 저장 매체 (flash storage media)를 포함할 수 있으나, 이에 한정되는 것은 아니다. 이하에서 중복을 피하기 위해 생성 모델 기반 데이터 분류 장치의 동작을 간략히 서술하고, 구체적인 설명 은 도 6 내지 도 17을 참조하여 후술한다. 생성 모델 기반 데이터 분류 장치는 적어도 하나의 명령어를 저장한 메모리 및 프로세서를 포함 하고, 메모리에 저장된 적어도 하나의 명령어는 프로세서에 의해 실행될 때 프로세서로 하여금, 결측치가 있는 입력 데이터(DTA)를 기반으로 제 1 생성 모델(G1)을 실행하여 결측치를 채운 대체 데이터(P_DT A)를 생성하고, 입력 데이터(DTA)의 클래스 라벨(L) 및 대체 데이터(P_DTA)를 기반으로 평가 모델(D)을 실행하 여 대체 데이터(P_DTA)에 대한 평가 데이터를 생성하고, 평가 데이터를 기반으로 제 1 생성 모델(G1) 및 평가 모델(D)을 학습하도록 구성될 수 있다. (도 6 참조) 메모리에 저장된 적어도 하나의 명령어는 프로세서에 의해 실행될 때 프로세서로 하여금, 대체 데이터(P_DTA)를 생성하기 위하여, 입력 데이터(DTA)의 저차원 벡터(FV_DTA)를 획득하고, 저차원 벡터(FV_DT A)를 입력으로 제 1 생성 모델(G1)을 실행하도록 구성될 수 있다. (도 7의 단계(S11) 참조) 메모리에 저장된 적어도 하나의 명령어는 프로세서에 의해 실행될 때 프로세서로 하여금, 저차 원 벡터(FV_DTA)를 획득하기 위하여, 입력 데이터(DTA)의 결측치를 무작위 숫자로 채운 데이터를 입력으로 인코 더 네트워크(E1)를 실행하여 저차원 벡터(FV_DTA)를 추출하도록 구성될 수 있다. (도 7의 단계(S12) 참조) 여기서 대체 데이터(P_DTA)는 입력 데이터(DTA)와 동일한 차원의 벡터로서, 적어도 하나의 특징 벡터를 포함하 고, 평가 데이터는 대체 데이터(P_DTA)의 각 특징 벡터가 결측치를 채운 것인 지에 대한 예상값 및 클래스 라벨 (L)이 유사 라벨인지에 대한 예상값을 포함한 이진 벡터로 표현될 수 있다. 메모리에 저장된 적어도 하나의 명령어는 프로세서에 의해 실행될 때 프로세서로 하여금, 학습 을 위해, 입력 데이터(DTA), 대체 데이터(P_DTA), 평가 데이터 및 클래스 라벨(L)을 기반으로 정의된 제 1 손실 함수(LF1)를 이용하여 제 1 생성 모델(G1) 및 평가 모델(D)을 생성적 적대 신경망(Generative Adversarial Network; GAN) 학습 방법으로 학습하도록 구성될 수 있다. 메모리에 저장된 적어도 하나의 명령어는 프로세서에 의해 실행될 때 프로세서로 하여금, 입력 데이터(DTA)가 라벨 결측인 경우(즉, DTA2인 경우), 평가 데이터를 생성하기 위하여, 대체 데이터(P_DTA2)를 기 반으로 분류기 네트워크(C)를 실행하여 입력 데이터(DTA2)의 유사 라벨(P_L2)을 획득하고, 유사 라벨(P_L2)을 클래스 라벨(L)로 하여 평가 모델(D)을 실행하여 평가 데이터를 생성하도록 구성되고, 대체 데이터(P_DTA2), 유 사 라벨(P_L2) 및 평가 데이터의 유사 라벨인지에 대한 예상값을 기반으로 정의된 제 2 손실 함수(LF2)를 이용 하여 분류기 네트워크(C)를 준지도 학습 방법에 의해 학습하도록 구성될 수 있다. 메모리에 저장된 적어도 하나의 명령어는 프로세서에 의해 실행될 때 프로세서로 하여금, 입력 데이터(DTA)가 전체 결측(DTA3)인 소수 클래스 라벨(L3)인 경우, 저차원 벡터(FV_DTA3)를 획득하기 위하여, 소 수 클래스 라벨(L3)을 기반으로 제 2 생성 모델(G2)을 실행하여 저차원 벡터(FV_DTA3)를 생성하도록 구성되고, 대체 데이터(P_DTA3)를 기반으로 분류기 네트워크(C)를 실행하여 입력 데이터(DTA3)의 클래스를 예측하고, 대체 데이터(P_DTA3), 예측된 클래스 및 소수 클래스 라벨(L3)을 기반으로 정의된 제 3 손실 함수(LF3)를 이용하여 제 2 생성 모델(G2)을 학습하도록 구성될 수 있다. 메모리에 저장된 적어도 하나의 명령어는 프로세서에 의해 실행될 때 프로세서로 하여금, 대체 데이터(P_DTA)를 기반으로 분류기 네트워크(C)를 실행하여 입력 데이터(DTA)의 클래스(OUT_CLS)를 예측하도록 구성될 수 있다. 도 6은 실시예에 따른 생성 모델 기반 데이터 분류 방법의 학습 흐름도이다. 실시예에 따른 생성 모델 기반 데이터 분류 방법은 프로세서에 의해 결측치가 있는 입력 데이터(DTA)를 기 반으로 제 1 생성 모델(G1)을 실행하여 결측치를 채운 대체 데이터(imputed data)(P_DTA)를 생성하는 단계(S1), 입력 데이터(IN_DTA_의 클래스 라벨(L) 및 대체 데이터(P_DTA)를 기반으로 평가 모델(D)을 실행하여 대체 데이터(P_DTA)에 대한 평가 데이터를 생성하는 단계(S2) 및 평가 데이터를 기반으로 제 1 생성 모델(G1) 및 평가 모 델(D)을 학습하는 단계(S3)를 포함한다. 단계(S1)은 프로세서에 의해 결측치가 있는 입력 데이터(DTA)를 기반으로 제 1 생성 모델(G1)을 실행하여 결측치를 채운 대체 데이터(imputed data)(P_DTA)를 생성한다. 대체 데이터(P_DTA)는 입력 데이터(DTA)와 동일한 차원의 벡터로서, 적어도 하나의 특징 벡터를 포함한다. 대체 데이터는 제 1 생성 모델(G1)을 이용하여 입력 데이터(DTA)의 결측치를 채운 데이터로서 입력 데이터(DTA)와 동 일한 차원의 벡터이다. 단계(S2)는 프로세서에 의해 입력 데이터(DTA)의 저차원 벡터(FV_DTA)를 획득하는 단계 및 저차원 벡터 (FV_DTA)를 입력으로 제 1 생성 모델(G1)을 실행하는 단계를 포함할 수 있다. 단계(S1)에 대하여는 도 7을 참조 하여 후술한다. 단계(S2)는 입력 데이터(IN_DTA_의 클래스 라벨(L) 및 대체 데이터(P_DTA)를 기반으로 평가 모델(D)을 실행하여 대체 데이터(P_DTA)에 대한 평가 데이터를 생성한다. 평가 데이터는 대체 데이터(P_DTA)의 각 특징 벡터가 결측치를 채운 것인 지에 대한 예상값 및 클래스 라벨이 유사 라벨(pseudo label)인지에 대한 예상값을 포함한 이진 벡터이다. 예를 들어 평가 데이터는 대체 데이터에 포함된 적어도 하나의 특징 벡터의 개수에 1을 더한 만큼의 원소 개수를 가지는 벡터일 수 있다. 단계(S2)에 후속하여 단계(S3)은 프로세서에 의해 평가 데이터를 기반으로 제 1 생성 모델(G1) 및 평가 모 델(D)을 학습하는 단계를 포함한다. 단계(S3)은 입력 데이터(DTA), 대체 데이터(P_DTA), 평가 데이터 및 클래스 라벨(L)을 기반으로 정의된 제 1 손 실 함수(LF1)를 이용하여 제 1 생성 모델(G1) 및 평가 모델(D)을 생성적 적대 신경망(Generative Adversarial Network; GAN) 학습 방법에 의해 학습하는 단계를 포함한다. 이에 대하여는 도 10 및 도 14를 참조하여 후술한 다. 한편, 입력 데이터(DTA)가 라벨 결측인 제 2 불완전 데이터(DTA2)인 경우, 단계(S2)는 대체 데이터(P_DTA2)를 기반으로 분류기 네트워크(C)를 실행하여 입력 데이터(DTA, 즉 DTA2)의 유사 라벨(P_L2)을 획득하는 단계 및 유 사 라벨(P_L2)을 클래스 라벨(L)로 하여 평가 모델(D)을 실행하여 평가 데이터를 생성하는 단계를 포함한다. 여기서 실시예에 따른 데이터 분류 방법은, 대체 데이터(P_DTA2), 유사 라벨(P_L2) 및 평가 데이터의 유사 라벨 인지에 대한 예상값을 기반으로 정의된 제 2 손실 함수(LF2)를 이용하여 분류기 네트워크(C)를 준지도(Semi- supervised) 학습 방법에 의해 학습하는 단계를 더 포함할 수 있다. 입력 데이터(DTA)가 전체 결측(DTA3)이고 소수 클래스 라벨(L3)이 주어진 경우, 단계(S1)의 저차원 벡터 (FV_DTA)를 획득하는 단계는 소수 클래스 라벨(L3)을 기반으로 제 2 생성 모델(G2)을 실행하여 저차원 벡터 (FV_DTA3)를 생성하는 단계를 포함할 수 있다. 여기서 실시예에 따른 데이터 분류 방법은, 대체 데이터(P_DTA3)를 기반으로 분류기 네트워크(C)를 실행하여 입 력 데이터(DTA, 즉 DTA3)의 클래스를 예측하는 단계 및 대체 데이터, 예측된 클래스 및 소수 클래스 라벨(L3)을 기반으로 정의된 제 3 손실 함수(LF3)를 이용하여 제 2 생성 모델(G2)을 학습하는 단계를 더 포함할 수 있다. 불완전 데이터 분류 모델의 학습이 완료되면 실시예에 따른 데이터 분류 방법은 학습된 불완전 데이터 분류 모 델을 이용하여 임의의 입력 데이터(DTA)에 대한 클래스를 예측한다. 예를 들어, 실시예에 따른 데이터 분류 방법은 입력 데이터(DTA)에 대한 대체 데이터(P_DTA)를 기반으로 분류기 네트워크(C)를 실행하여 입력 데이터(DTA)의 클래스(OUT_CLS)를 예측하는 단계(도 8을 참조하여 S4)를 더 포함 할 수 있다. 이에 대하여는 도 8을 참조하여 후술한다. 도 7은 실시예에 따른 생성 모델 기반 데이터 분류 방법의 일 과정의 세부 흐름도이다. 단계(S1)은 입력 데이터(DTA)의 저차원 벡터(FV_DTA)를 획득하는 단계 및 저차원 벡터를 입력으로 제 1 생성 모 델(G1)을 실행하는 단계를 포함한다. 여기서 저차원 벡터를 획득하는 단계는 입력 데이터(DTA)의 결측치를 무작위 숫자(random number)로 채운 데이 터를 입력으로 인코더 네트워크(E)를 실행하여 저차원 벡터(FV_DTA)를 추출하는 단계(S11)을 포함할 수 있다. 예를 들면, 일부 결측인 입력 데이터(DTA1) 및 라벨 결측인 입력 데이터(DTA3)에 대하여 단계(S11)을 실행할 수있다. 이에 대하여는 도 10 및 도 11 등을 참조하여 후술한다. 저차원 벡터를 획득하는 단계는 입력 데이터(DTA)가 전체 결측(DTA3)인 소수 클래스 라벨(L3)인 경우, 소수 클 래스 라벨(L3)을 기반으로 제 2 생성 모델(G2)을 실행하여 저차원 벡터(FV_DTA)를 생성하는 단계(S12)를 포함할 수 있다. 이에 대하여는 도 12 등을 참조하여 후술한다. 도 8은 실시예에 따른 생성 모델 기반 데이터 분류 방법의 분류 흐름도이다. 실시예에 따른 데이터 분류 방법은, 결측치가 있는 입력 데이터(DTA)를 기반으로 제 1 생성 모델(G1)을 실행하 여 결측치를 채운 대체 데이터(P_DTA)를 생성하는 단계(S1) 및 대체 데이터(P_DTA)를 기반으로 분류기 네트워크 (C)를 실행하여 입력 데이터(DTA)의 클래스(OUT_CLS)를 예측하는 단계(S4)를 포함할 수 있다. 여기서, 대체 데이터(P_DTA)를 생성하는 단계(S1)는, 입력 데이터(DTA)의 결측치를 무작위 숫자로 채운 데이터 를 입력으로 인코더 네트워크(E)를 실행하여 추출(도 7을 참조하여 S11)된 저차원 벡터(FV_DTA) 또는 소수 데이 터 라벨(L3)을 기반으로 제 2 생성 모델(G2)을 실행하여 생성(도 7을 참조하여 S12)된 저차원 벡터(FV_DTA3)를 입력으로 제 1 생성 모델(G1)을 실행하는 단계를 포함할 수 있다. 이로써 실시예에 따른 데이터 분류 방법은 임의의 입력 데이터(DTA)에 대한 클래스(OUT_CLS)를 예측한다. 도 9는 실시예에 따른 생성 모델 기반 데이터 분류 과정을 전체적으로 설명하기 위한 도면이다. 도 9의 제 1 불완전 데이터(DTA1) 및 라벨(L1), 제 2 불완전 데이터(DTA2) 및 라벨(L2), 그리고 제 3 불완전 데 이터(DTA3) 및 라벨(L3)에서 배경색이 있으면 데이터가 존재하고 배경색이 없으면 결측 위치를 나타낸다. 실시예에 따른 생성 모델 기반 데이터 분류 방법은 결측치가 존재하는 입력 데이터(DTA)를 인코더 네트워크(E) 에 입력하여 저차원 벡터(FV_DTA)를 추출하고 제 1 생성 모델(G1)에 입력하여 결측치를 예측하여 결측치가 없는 대체 데이터(P_DTA)를 생성한다(도 6을 참조하여 S1 및 도 7을 참조하여 S11). 실시예에 따른 생성 모델 기반 데이터 분류 방법은 소수 클래스 정보(L3)를 제 2 생성 모델(G2)에 입력하여 저 차원 벡터(FV_DTA3)를 생성한 후 이를 제 1 생성 모델(G1)에 입력하여 오버샘플링(oversample)을 수행하여 대체 데이터(P_DTA3)을 생성한다(도 6을 참조하여 S1 및 도 7을 참조하여 S12). 실시예에 따른 생성 모델 기반 데이터 분류 방법은 클래스 라벨(L)이 존재하지 않는 입력 데이터(DTA2)를 인코 더 네트워크(E)와 제 1 생성 모델(G1)에 입력하여 결측치를 우선 예측하여 대체 데이터(P_DTA2)를 생성한다(도 6을 참조하여 S1 및 도 7을 참조하여 S11). 이에 후속하여 도 6을 참조하여 전술한대로, 실시예에 따른 생성 모 델 기반 데이터 분류 방법은 대체 데이터(P_DTA2)를 분류기 네트워크(C)에 입력하여 유사 라벨(Pseudo- label)(P_L2)을 생성함으로써 준지도 학습을 수행하는 단계를 포함할 수 있다. 도 10은 실시예에 따른 생성 모델 기반 데이터 분류 방법의 결측치 예측 학습 과정을 설명하기 위한 도면이다. 도 10은 학습 및 테스트 데이터에 존재하는 결측치를 예측하는 과정을 도시한다. 결측치 예측 과정은 결측치가 존재하는 입력 데이터(DTA1)를 받아 저차원 벡터(FV_DTA1)로 정보를 압축시키는 인코더 네트워크(E), 저차원 벡 터(FV_DTA1)를 받아 결측치를 예측하는 제 1 생성 모델(G1), 그리고 예측된 결측치를 평가하는 평가 모델(D)로 구성된다. 여기서 제 1 생성 모델(G1)에 의해 예측된 결측치는 전술한 대체 데이터(P_DTA1)에 대응한다. 인코더 네트워크(E)는 결측치가 존재하는 데이터(DTA1)를 입력으로 받는다. 데이터의 결측치 부분은 무작위 숫 자로 채워 입력한다. 인코더 네트워크(E)의 구조는 예를 들어, 데이터가 이미지인 경우 CNN (Convolutional Neural Network), 시계 열인 경우 RNN (Recurrent Neural Network), 테이블인 경우 MLP (Multi-Layer Perceptron)로 구성할 수 있고, 이에 한정되는 것은 아니고 데이터에 따라 적절한 구조로 구성될 수 있다. 인코더 네트워크(E)의 출력은 뉴럴 네트워크의 연산에 의해 고차원 입력 데이터의 정보가 압축된 저차원 벡터 (FV_DTA1)이다. 인코더 네트워크(E)는 입력 데이터(DTA1)의 정보를 담은 저차원 벡터(FV_DTA1)를 출력하도록 학 습되며, 제 1 생성 모델(G1)에게 입력 데이터(DTA1)의 압축된 정보를 저차원 벡터(FV_DTA1)에 담아 전달하게 된 다. 인코더 네트워크(E)의 학습은 기존에 다른 빅데이터로 학습된 모델 (e.g. DenseNet)을 그대로 이용하거나, 인코 더 네트워크(E)에 연결된 제 1 생성 모델(G1)의 손실 함수(예를 들어 후술할 제 1 손실 함수, LF1)를 역전파할 수 있다.한편, 여러 종류의 입력 데이터를 함께 이용하는 경우 각각을 위한 인코더 네트워크(E)를 구성하여 이용할 수 있다. 예를 들면, 이미지와 테이블 데이터를 동시에 이용하는 경우 이미지를 위한 CNN 인코더, 테이블을 위한 MLP 인코더를 각각 구성하여 두 인코더 네트워크의 출력을 연결 (concatenate)시켜 저차원 벡터로 활용할 수 있 다. 제 1 생성 모델(G1)은 인코더 네트워크(E)가 생성한 저차원 벡터(FV_DAT1)를 입력으로 받는다. 여기서 제 1 생성 모델(G1)은 GAN (Generative adversarial network), VAE (Variational autoencoder) 등의 생 성 모델을 이용할 수 있으며, 생성 모델의 구조는 예를 들어 데이터가 이미지인 경우 Transposed CNN, 시계열인 경우 RNN, 테이블인 경우 MLP로 구성할 수 있다. 제 1 생성 모델(G1)의 출력은 입력 데이터(DTA1)와 동일한 차원을 가진 벡터로서 전술한 대체 데이터(P_DTA1)이 다. 대체 데이터(P_DTA1)는 입력 데이터(DTA1)의 결측치 부분 원소만 제 1 생성 모델(G1)의 출력의 동일한 위치의 원소로 대체함으로써 결측치를 채우게 된다. 제 1 생성 모델(G1)은 학습 데이터와 생성된 데이터 사이의 분포가 가까워질 수 있도록 하는 손실 함수(후술할 제 1 손실 함수, LF1)를 최소화하도록 학습된다. 평가 모델(D)은 결측치가 채워진 대체 데이터(P_DTA1)와 클래스 라벨(L)을 입력받아 대체 데이터(P_DTA1) 및 라 벨(L)을 평가한다. 여기서 평가 모델(D)의 구조는 예를 들어 데이터가 이미지인 경우 CNN, 시계열인 경우 RNN, 테이블인 경우 MLP 로 구성할 수 있으며, 이에 한정되는 것은 아니고 데이터에 따라 적절한 구조로 구성될 수 있다. 평가 모델(D)의 출력은 전술한 평가 데이터에 대응하고, (입력된 데이터(P_DTA1)의 특징값 수 + 1)개의 원소를 가진 벡터이다. 평가 데이터의 마지막 원소를 제외한 벡터의 각 원소는 대체 데이터(P_DAT1)의 각 특징값이 결측치를 채운 것으 로 예상되는 경우 0, 원래 결측되지 않은 데이터로 예상되는 경우 1에 가깝도록 하는 것을 목표로 한다. 평가 모델(D)은 제 1 생성 모델(G1)의 학습을 돕거나, 추후 유사 라벨을 이용한 준지도학습에 이용될 수 있다. 제 1 생성 모델(G1)과 평가 모델(D)을 GAN(Generative Adversarial Network)으로 구성한 경우 인코더 네트워크 (E), 제 1 생성 모델(G1), 평가 모델(D)은 다음의 수학식 1의 제 1 손실 함수(LF1)를 이용하여 학습할 수 있다. 수학식 1"}
{"patent_id": "10-2022-0182946", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "위 식에서 x는 결측치가 존재하는 입력 데이터, m은 x의 각 원소가 결측치인지 아닌지를 표시하는 이진 벡터 (원소가 0인 경우 결측치, 1인 경우 결측치가 아님), d는 입력 데이터의 특징값 수, G는 제1 생성 모델, D1:d는 평가 모델(D)의 출력 벡터(즉, 평가 데이터)의 마지막 원소를 제외한 출력값, E는 인코더 네트워크이다. 이상에서 도 10을 참조하여 설명한 제 1 생성 모델(G1)과 평가 모델(D)이 다른 불완전 문제들을 해결하는 데에 도 활용될 수 있다. 도 11은 실시예에 따른 생성 모델 기반 데이터 분류 방법의 라벨 결측 준지도 학습 과정을 설명하기 위한 도면 이다. 도 11은 입력 데이터에 존재하는 라벨 결측 문제, 즉 제 2 불완전 데이터(DTA2)의 라벨 결측을 해결하는 과정을 도시한다. 라벨이 결측된 데이터(DTA2)를 인코더 네트워크(E)와 제 1 생성 모델(G1)에 차례로 입력하여 결측치를 예측한 후, 이를 분류기 네트워크(C)에 입력하여 유사 라벨(P_L2)을 생성한다. 여기서 분류기 네트워크(C)의 구조는 예를 들어 데이터가 이미지인 경우 CNN, 시계열인 경우 RNN, 테이블인 경 우 MLP로 구성할 수 있고, 이제 제한되지 않고 데이터에 따라 적절한 분류기 구조를 적용할 수 있다. 유사 라벨(P_L2)은 분류기 네트워크(C)가 예측한 라벨로, 클래스 라벨(L)과 동일한 모양의 벡터이다. 결측치가 채워진 대체 데이터(P_DTA2)와 유사 라벨(P_L2)을 평가 모델(D)에 입력하여 생성된 라벨을 평가하는 방식으로 준지도 학습을 수행한다. 이 때, 평가 모델(D)의 출력 벡터의 마지막 원소가 입력된 클래스 라벨을 평가하는 데 이용되며, 입력된 클래스 라벨이 실제 라벨인 경우 1, 유사 라벨인 경우 0에 가깝게 출력하는 것을 목표로 한다. 준지도 학습을 위해 분 류기 네트워크(C)와 평가 모델(D)은 수학식 2의 제 2 손실 함수(LF2)로 학습될 수 있다. 수학식 2"}
{"patent_id": "10-2022-0182946", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "위 식에서 은 결측치를 채운 라벨이 존재하는 데이터, 는 결측치를 채운 라벨이 없는 데이터, Dd+1는 평가 모 델(D)의 출력 벡터(즉, 평가 데이터)의 마지막 원소, C는 분류기 네트워크이다. 도 12는 실시예에 따른 생성 모델 기반 데이터 분류 방법의 저차원 오버샘플링 학습 과정을 설명하기 위한 도면 이다. 도 12는 학습 데이터에 존재하는 클래스 불균형 문제를 해결하기 위해 필요한 오버샘플링 과정을 도시한다. 분류기 네트워크(C) 학습 시 클래스 불균형 문제가 존재하는 데이터에서 소수 클래스와 다수 클래스의 데이터 수를 동일하게 맞춰주기 위하여 오버샘플링을 수행한다. 제 2 생성 모델(G2)은 소수 클래스 라벨(L3)을 입력받는다. 여기서 제 2 생성 모델(G2)은 GAN 등의 생성 모델을 이용할 수 있으며, 예를 들어 MLP 구조를 이용할 수 있다. 제 2 생성 모델(G2)의 출력은 제 1 생성 모델(G1)에 입력하기 위한 저차원 벡터(FV_DTA3)이다. 제 2 생성 모델 (G2)이 소수 클래스에 부합하는 저차원 벡터(FV_DTA3)를 생성하면, 이를 결측치 예측 기술(도 10 참조)의 제 1 생성 모델(G1)이 전체 특징값을 결측치로 생각하여 전체 특징값을 예측하는 방식으로 오버샘플링을 수행한다. 오버샘플링된 데이터(P_DTA3)는 결측치 예측 기술(도 10 참조)의 평가 모델(D)에 입력되어 오버샘플링된 데이터 (P_DTA3)의 각 특징값이 바르게 생성되었는지를 결측치 예측 기술에서의 제 1 손실 함수(LF1)와 동일한 손실 함 수를 계산한다. 이 때 전체 특징값을 결측치로 생각하고 생성하였으므로, 제 1 손실 함수의 수학식 1에서 m은 영벡터(zero vector)를 이용한다. 추가로 오버샘플링된 데이터(P_DTA3)를 분류기 네트워크(C)에도 입력되어 소수 클래스에 부합하는 데이터가 생 성되었는지에 대한 수학식 3의 제 3 손실 함수(LF3)를 계산하여 제 2 생성 모델(G2)의 학습에 이용할 수 있다. 예를 들어 제 3 손실 함수(LF3)의 예로 교차-엔트로피(cross-entropy)를 이용할 수 있다. 수학식 3"}
{"patent_id": "10-2022-0182946", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "수학식 3에서 는 오버샘플링된 데이터, 는 소수 클래스 라벨, C는 분류기 네트워크이다. 한편, 분류기 네트워크(C) 학습을 위해 한 배치 (batch)의 데이터가 입력되면 도 10, 도 11 및 도 12를 참조하 여 서술한 학습 방법에 의해 내부적으로 가공된 데이터를 이용하여 분류기 네트워크(C)가 학습된다 인코더 네트워크(E)와 제 1 생성 모델(G1)을 이용하여 결측치를 예측하고, 제 2 생성 모델(G2)과 제 1 생성 모 델(G1)을 이용하여 클래스 불균형 문제의 경우 배치 내 다수 데이터와 소수 데이터의 수가 일치하도록 소수 데 이터를 오버샘플링한다. 또한, 라벨이 결측된 데이터의 경우 분류기 네트워(C)를 이용한 준지도학습을 통해 분 류 성능을 높이는 데 활용한다. 최종적으로 분류기 네트워크(C)는 교차-엔트로피(cross-entropy)와 같은 손실 함수를 통해 올바른 클래스 라벨 을 예측하도록 학습될 수 있다. 도 13은 실시예에 따른 생성 모델 기반 데이터 분류 방법의 분류 과정을 설명하기 위한 도면이다. 학습이 완료된 불완전 데이터 분류 모델을 이용한 데이터 분류 장치에 결측치가 존재하는 테스트 데이터 (DTA)가 입력되었을 때 인코더 네트워(E)와 제 1 생성 모델(G1)을 통해 결측치를 예측한 후 분류기 네트워크 (C)에 입력된다. 분류기 네트워크(C)는 클래스 예측 결과(OUT_CLS)를 출력한다. 도 14는 실시예에 따른 생성 모델 기반 불완전 데이터 분류 모델의 인코더 네트워크 및 제 1 생성 모델의 학습 과정을 설명하기 위한 흐름도이다. 도 14는 인코더 네트워크(E) 및 제 1 생성 모델(G1)의 학습 과정을 도시한다. 단계(S141)에서 결측치가 존재하는 데이터(DTA1)을 획득한다. 단계(S142)에서 인코더 네트워크(E)는 결측치가 존재하는 데이터(DTA1)을 입력받고 단계(S143)에서 저차원 벡터 (FV_DTA1)을 출력한다. 단계(S144)에서 제 1 생성 모델(G1)은 저차원 벡터(FV_DTA1)을 입력받고 단계(S145)에서 결측치를 채운 데이터 (P_DTA1)을 출력한다. 단계(S146)에서 평가 모델(D)은 대체 데이터(P_DTA1)을 입력으로 평가 데이터를 출력한다. 단계(S147)에서 제 1 손실 함수(LF1)를 연산한다. 단계(S148)에서 제 1 손실 함수(LF1)를 기반으로 인코더 네트워크(E) 및 제 1 생성 모델(G1)을 업데이트한다. 추가적으로 제 1 손실 함수(LF1)으로 평가 모델(D)도 함께 업데이트할 수 있다. 도 15는 실시예에 따른 생성 모델 기반 불완전 데이터 분류 모델의 분류기 네트워크의 학습 과정을 설명하기 위한 도면이다. 도 15는 분류기 네트워크(C)의 학습 과정을 도시한다. 단계(S151)에서 결측치가 있는 입력 데이터(DTA)를 획득한다. 단계(S152E)에서 인코더 네트워크(E)는 입력 데이터(DTA)가 제 1 불완전 데이터(DTA1) 또는 제 2 불완전 데이터 (DTA2)인 경우, 단계(S153E)에서 저차원 벡터(FV_DTA1, FV_DTA2)를 추출한다. 단계(S152G2)에서 제 2 생성 모델(G2)은 입력 데이터(DTA)가 소수 라벨 데이터(L3)인 경우 제 2 생성 모델(G2) 에 의해 단계(S153G2)에서 저차원 벡터(FV_DTA3)를 생성한다. 단계(S154)에서 제 1 생성 모델(G1)은 저차원 벡터(S153E, S153G2)를 입력받아서 단계(S155)에서 결측치가 없는 대체 데이터(P_DTA)를 생성한다. 단계(S156)에서 분류기 네트워크(C)를 실행하고 단계(S157)에서 입력 데이터(DTA)에 라벨이 존재하는 지 여부를 판단한다. 라벨이 존재하는 경우 단계(S156Y1)의 대체 데이터(P_DTA1)와 라벨(L1) 또는 오버샘플링된 대체 데이터(P_DTA 3)와 소수 클래스 라벨(L3)에 대하여 단계(S157Y2)에서 분류기 네트워크(C) 학습을 위한 제 4 손실 함수(LF4)를 계산한다. 예를 들어 제 4 손실 함수는 교차-엔트로피를 이용할 수 있다. 라벨이 존재하지 않는 경우 단계(S156N1)의 대체 데이터(P_DTA2)와 단계(S156)에서 출력된 유사 라벨(P_L2)에 대하여 단계(S157N2)에서 평가 모델(D)을 실행하여 평가 데이터를 생성하고 단계(S157N3)에서 준지도 학습을 위 한 제 2 손실 함수(LF2)를 계산한다. 단계(S158)에서 단계(S157Y2) 및 단계(S157N3)를 기초로 분류기 네트워크(C)를 업데이트 한다. 도 16은 실시예에 따른 생성 모델 기반 불완전 데이터 분류 모델의 제 2 생성 모델의 학습 과정을 설명하기 위 한 흐름도이다. 단계(S161)의 클래스 불균형이 존재하는 데이터(DTA3)를 입력으로 단계(S162)에서 제 2 생성 모델(G2)를 실행하 여 단계(S163)에서 저차원 벡터(FV_DTA3)이 생성된다. 단계(S164a)는 단계(S163)에서 저차원 벡터 생성을 위한 제 5 손실 함수(LF5)를 계산한다. 여기서 제 5 손실 함수는 제 2 생성 모델(G2)이 저차원 벡터를 생성할 수 있도록 일반적인 생성모델과 각 생성 모델의 알려진 손실함수를 이용할 수 있다. 예를 들면 제 2 생성 모델(G2)을 GAN으로 구성할 경우 제 5 손실함 수는 다음의 수학식 4와 같은 손실함수를 이용할 수 있다. 수학식 4"}
{"patent_id": "10-2022-0182946", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "여기서 z는 균등분포나 표준정규분포와 같은 간단한 분포에서 랜덤하게 샘플링한 원소값을 갖는 벡터이고, y는 소수 클래스 라벨을 의미한다. 수학식 4에서 D2의 경우 GAN은 평가 모델이 필요한 생성모델이기 때문에 제 2 생성 모델(G2)로 GAN을 이용한다 면 새로운 평가 모델(D2)이 필요하고, 다른 생성 모델을 이용하는 경우 새로운 평가 모델(D2)는 필요하지 않을 수 있다. 단계(S164b1)에서 단계(S163)의 저차원 벡터(FV_DTA3)을 입력으로 제 1 생성 모델(G1)을 실행하여 단계 (S164b2)에서 오버샘플링된 대체 데이터(P_DTA3)을 생성한다. 단계(S164b3)에서 분류기 네트워크(C)를 실행하고, 단계(S164b4)에서 대체 데이터(P_DTA3)이 소수 클래스 라벨 (L3)에 부합하는 지에 대한 제 3 손실 함수(LF3)를 계산한다. 한편, 단계(S164c1)에서 대체 데이터(P_DTA3)를 입력으로 평가 모델(D)를 실행하고 단계(S164c2)에서 결측치 예 측을 위한 제 1 손실 함수(LF1)을 계산한다. 단계(S165)에서 단계(S164a), 단계(S164b4) 및 단계(S164c2)의 결과를 기반으로 제 2 생성 모델(G2)를 업데이 트한다. 한편, 일 예에서, 도 14, 도 15 및 도 16에서 전술한 바에 따라 불완전 데이터 분류 모델을 구성하는 각 모델이 돌아가며 학습될 수 있다. 예를 들어 임의의 순서대로 학습될 수 있다. 도 17은 실시예에 따른 생성 모델 기반 불완전 데이터 분류 모델의 학습이 완료된 후 테스트 데이터가 입력되었 을 때 분류 과정을 설명하기 위한 흐름도이다. 도 17은 불완전 데이터 분류 모델의 학습이 완료된 후 결측치가 존재하는 테스트 데이터가 입력되었을 때 분류 과정을 도시한다. 단계(S171)에서 테스트 데이터(DTA)가 입력되고 단계(S172)에서 인코더 네트워크(E)를 실행하여 단계(S173)에서 저차원 벡터(FV_DTA)를 추출한다. 단계(S174)에서 제 1 생성 모델(G1)을 실행하여 결측치가 없는 대체 데이터(P_DTA)를 생성하고 단계(S176)에서 분류기 네트워크(C)를 실행하여 클래스 라벨(OUT_CLS)를 예측한다. 본 발명은 불완전 데이터로 분류를 수행하는 산업 전반에 활용될 수 있다. 특히 AI 헬스케어의 경우 불완전 데 이터 문제가 존재하는 대표적인 분야이고, 환자 데이터와 라벨을 취득하기 위해 많은 비용이 소모되므로 불완전 데이터를 분류 모델 학습에 최대한 활용할 수 있는 본 발명이 큰 이점을 가질 수 있다. 또한 현재 활용중인 전 자의무기록 (EMR) 뿐만 아니라 추후 활발히 활용될 웨어러블 장치를 활용한 생체 데이터, 유전자 데이터, IoT 기술을 활용한 환자 상태 정보 데이터 등에도 불완전 데이터 문제가 존재할 것이므로 본 기술이 진단 프로세스, 제품 및 서비스를 개발하는 산업에 응용될 수 있다. 불완전 데이터 문제로 인해 기존에는 딥러닝 기반의 분류기 가 잘 수행하지 못하는 것으로 여겨졌던 작업들이 가능해짐에 따라 딥러닝 기반 분류기의 산업 적용 영역을 확 장할 수 있다. 본 기술은 불완전 데이터를 다루는 AI 헬스케어나 머신 비전 등의 시장에 광범위하게 적용될 것이다. 마켓스앤 마켓스의 보고서에는 글로벌 AI 헬스케어 시장이 2018년부터 연평균 50%씩 성장하여 2025년 362억 달러 (약 43 조원) 규모를 형성할 것으로 예측하였으며, 글로벌 머신 비전 시장이 2020년부터 연평균 6.1%씩 성장하여 2025 년 130억 달러 (약 15조원) 규모를 형성할 것으로 예측하였다. 특히 AI 헬스케어 시장에서는 환자 데이터의 절대적인 수가 적은 경우가 많고 라벨링 비용이 높은데, 본 기술이 적은 수의 학습 데이터를 제외하지 않고 최대한 활용할 수 있어 동일한 성능을 얻기 위한 데이터 취득 비용을 절감할 수 있을 것으로 예상된다. 또한 현재 활용중인 전자의무기록 (EMR) 뿐만 아니라 추후 활발히 활용될 웨어러블 장치를 활용한 생체 데이터, 유전자 데이터, IoT 기술을 활용한 환자 상태 정보 데이터 등에도 불완전 데이터 문제가 존재할 수 있기 때문에 본 기술이 진단 프로세스를 효율화하고, 새로운 의료인공지능 제품 및 서비스를 개발하여 시장을 활성화시키는 데 일조할 것으로 예상된다. 머신 비전 시장에서도 스마트팩토리의 최적 생산을 위한 딥러닝 기반의 품질 모니터링 시 발생할 수 있는 불완 전 데이터 문제를 해결할 수 있어 시장을 활성화할 수 있을 것으로 예상된다. 이외에도 본 기술을 통해 딥러닝 기반의 분류기에서 불완전 데이터 문제들을 동시에 해결하면서 분류 성능을 높일 수 있기 때문에, 불완전 학습 데이터를 이용하는 모든 딥러닝 기반 분류기에 적용이 예상되며 시장 진입이 용이할 것으로 보인다. 이와 더불어 딥러닝 기반 분류기의 적용 영역이 위 언급한 시장 이외에 불완전 데이터를 이용하는 타 산업으로 도 확장될 것으로 예상되기 때문에, 본 기술이 적용될 수 있는 시장은 더욱 더 방대해질 것으로 예상된다. 불완 전 데이터 문제로 인해 기존에는 딥러닝 기반의 분류기가 잘 수행하지 못하는 것으로 여겨졌던 작업들이 가능해 짐에 따라 본 기술이 적용될 수 있는 시장이 더욱 활성화 될 것으로 예상할 수 있다. 전술한 본 발명의 일 실시예에 따른 방법은 프로그램이 기록된 매체에 컴퓨터가 읽을 수 있는 코드로서 구현하 는 것이 가능하다. 컴퓨터가 읽을 수 있는 매체는, 컴퓨터 시스템에 의하여 읽혀질 수 있는 데이터가 저장되는 모든 종류의 기록장치를 포함한다. 컴퓨터가 읽을 수 있는 매체의 예로는, HDD(Hard Disk Drive), SSD(Solid State Disk), SDD(Silicon Disk Drive), ROM, RAM, CD-ROM, 자기 테이프, 플로피 디스크, 광 데이터 저장 장치 등이 있다."}
{"patent_id": "10-2022-0182946", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "이상 설명된 본 발명의 실시 예에 대한 설명은 예시를 위한 것이며, 본 발명이 속하는 기술분야의 통상의 지식 을 가진 자는 본 발명의 기술적 사상이나 필수적인 특징을 변경하지 않고서 다른 구체적인 형태로 쉽게 변형이 가능하다는 것을 이해할 수 있을 것이다. 그러므로 이상에서 기술한 실시 예들은 모든 면에서 예시적인 것이며 한정적이 아닌 것으로 이해하여야 한다. 예를 들어, 단일형으로 설명되어 있는 각 구성 요소는 분산되어 실시될 수도 있으며, 마찬가지로 분산된 것으로 설명되어 있는 구성 요소들도 결합된 형태로 실시될 수 있다. 본 발명의 범위는 상기 상세한 설명보다는 후술하는 청구범위에 의하여 나타내어지며, 청구범위의 의미 및 범위 그리고 그 균등 개념으로부터 도출되는 모든 변경 또는 변형된 형태가 본 발명의 범위에 포함되는 것으로 해석 되어야 한다."}
{"patent_id": "10-2022-0182946", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 실시예에 따른 생성 모델 기반 불완전 데이터 분류 장치의 동작을 개략적으로 설명하기 위한 예시도이다. 도 2는 예시적인 불완전 데이터를 설명하기 위한 도면이다. 도 3은 예시적인 불완전 데이터 유형을 결정하기 위한 흐름도이다. 도 4는 실시예에 따른 생성 모델 기반 불완전 데이터 분류 모델의 블록도이다. 도 5는 실시예에 따른 생성 모델 기반 데이터 분류 장치의 블록도이다. 도 6은 실시예에 따른 생성 모델 기반 데이터 분류 방법의 학습 흐름도이다. 도 7은 실시예에 따른 생성 모델 기반 데이터 분류 방법의 일 과정의 세부 흐름도이다. 도 8은 실시예에 따른 생성 모델 기반 데이터 분류 방법의 분류 흐름도이다. 도 9는 실시예에 따른 생성 모델 기반 데이터 분류 과정을 전체적으로 설명하기 위한 도면이다. 도 10은 실시예에 따른 생성 모델 기반 데이터 분류 방법의 결측치 예측 학습 과정을 설명하기 위한 도면이다. 도 11은 실시예에 따른 생성 모델 기반 데이터 분류 방법의 라벨 결측 준지도 학습 과정을 설명하기 위한 도면 이다. 도 12는 실시예에 따른 생성 모델 기반 데이터 분류 방법의 저차원 오버샘플링 학습 과정을 설명하기 위한 도면이다. 도 13은 실시예에 따른 생성 모델 기반 데이터 분류 방법의 분류 과정을 설명하기 위한 도면이다. 도 14는 실시예에 따른 생성 모델 기반 불완전 데이터 분류 모델의 인코더 네트워크 및 제 1 생성 모델의 학습 과정을 설명하기 위한 흐름도이다. 도 15는 실시예에 따른 생성 모델 기반 불완전 데이터 분류 모델의 분류기 네트워크의 학습 과정을 설명하기 위한 도면이다. 도 16은 실시예에 따른 생성 모델 기반 불완전 데이터 분류 모델의 제 2 생성 모델의 학습 과정을 설명하기 위 한 흐름도이다. 도 17은 실시예에 따른 생성 모델 기반 불완전 데이터 분류 모델의 학습이 완료된 후 테스트 데이터가 입력되었 을 때 분류 과정을 설명하기 위한 흐름도이다."}
