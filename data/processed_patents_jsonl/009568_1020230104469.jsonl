{"patent_id": "10-2023-0104469", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2025-0023224", "출원번호": "10-2023-0104469", "발명의 명칭": "음성 인식을 통한 실시간 통번역 및 대화 방법", "출원인": "주식회사 엔디소프트", "발명자": "박남도"}}
{"patent_id": "10-2023-0104469", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "음성 인식을 통한 실시간 통번역 및 대화 방법으로서, 제 1 단말기를 통하여 실시간으로 입력되는 제 1 음성 정보를 수신하는 단계;상기 제 1 음성 정보를 스펙트로그램 정보로 변환하는 단계;상기 스펙트로그램 정보를 Conformer 기반의 음향 처리기를 통하여 발음 텍스트 정보를 추출하는 단계;상기 발음 텍스트 정보를 학습된 어휘 사전 모듈에 입력한 후 상기 발음 텍스트 정보와 유사도가 가장 높은 실제 어휘 텍스트 정보로 변환시키는 단계;상기 실제 어휘 텍스트 정보를 은닉 마르코프 모델(Hidden Markov Model) 기반의 언어 처리기에 입력하여 상기단말기를 통하여 입력된 상기 제 1 음성 정보에 대한 전체 문장 텍스트 정보로 출력하는 단계를 구비하며,순차적으로 출력되는 상기 실제 어휘 텍스트 정보는 표준 외국어 번역기로 제공되어 소정의 외국어 텍스트 정보로 변환된 후 상기 외국어 텍스트 정보에 대응하는 제 2 음성 정보로 제 1 단말기와 연동되는 제 2 단말기로실시간 출력되되, 실시간 출력되는 상기 제 2 음성 정보는 상기 제 1 음성 정보를 소정 구간 분할하여 실행되며, 상기 소정 구간의 분할 판정은 상기 제 1 음성 정보 중 조건문, 부사 또는 부사구로 구성되거나, 상기 제 1 음성 정보에 술어부가 포함되는 문장에 대항하는 경우, 상기 조건문, 상기 부사, 상기 부사구, 또는 상기 술어부가 포함되는 문장을 판정한 후, 상기 조건문, 상기 부사, 상기 부사구, 또는 술어부가 포함되는 문장을 상기 제 2 음성 정보로실시간 순차 번역하여 상기 제 2 단말기로 순차 출력시키는 것을 특징으로 하는 음성 인식을 통한 실시간 통번역 및 대화 방법."}
{"patent_id": "10-2023-0104469", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 단말기를 통하여 입력되는 음성 정보를 ASR을 통하여 표준화한 후, 번역기를 거쳐 텍스트로 변환시키 되, 텍스트를 분석하여 조선문, 부사, 부사구, 술어부, 구두점 등을 판정하여 해당 텍스트를 실시간 순차 통번역 하여 다른 단말기로 출력할 수 있도록 한 음성 인식을 통한 실시간 통번역 및 대화 방법에 관한 것이다. (뒷면에 계속)"}
{"patent_id": "10-2023-0104469", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 음성 인식을 통한 실시간 통번역 및 대화 방법에 관한 것으로, 단말기를 통하여 입력되는 음성 정보 를 ASR을 통하여 표준화한 후, 번역기를 거쳐 텍스트로 변환시키되, 텍스트를 분석하여 조선문, 부사, 부사구, 술어부, 구두점 등을 판정하여 해당 텍스트를 실시간 순차 통번역하여 다른 단말기로 출력할 수 있도록 한 음성 인식을 통한 실시간 통번역 및 대화 방법에 관한 것이다."}
{"patent_id": "10-2023-0104469", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "학술대회 및 비즈니스를 원활히 추진하는데 가장 큰 어려움 중 하나는 언어이다. 아무리 오랜 기간 외국어를 공 부했다 하더라도, 외국어로 발표하는 것은 쉽지 않은 일이다. 모국어로 발표하고 이를 통역자가 동시에 통역해 준다면 훨씬 부담감이 줄어들 것이고 질문에 대해 쉽게 답변이 가능하며, 나아가 비즈니스 측면에서 좋은 결과 도 이끌어 낼 수 있다. 하지만 동시통역자를 필요한 시기에 구하기 어렵고 해당 장소에 동행해야 하며 그것도 국외라면 상당한 비용이 소요된다. 따라서 이용자가 언제 어디서든지 동시통역 서비스를 제공받을 수 있는 이용 자와 동시통역자간 실시간 동시통역 연계 기술이 필요하다. 이러한 문제는 여행지에서 만나는 현지인과의 대화, 또는 전화 등을 이용한 외국인과의 대화에서도 발생할 수 있다. 이 때문에 다국어 대화를 실시간으로 번역 내지 통역해주는 다양한 프로그램이 개발되어 앱 또는 웹에서 제공되 고 있다. 그런데, 대부분의 통번역 프로그램의 경우, 화자가 말을 끝내는 시점을 판정한 후 그때까지 화자가 말한 내용을 소정의 외국어로 번역 내지 통역하는 방식을 취하고 있다. 예컨대, 널리 알려진 구글 또는 파파고 통번역 시스템의 경우 화자의 말이 종결되면 그때까지 화자가 말한 내용 을 전체 텍스트로 번역하거나 이를 통역하여 스피커를 통하여 출력하는 방식을 취하고 있다. 그런데, 이러한 방식의 경우 화자의 말이 길어지는 경우 실시간 통역이 상대방에게 전달되지 못하고 이 때문에 대화의 흐름이 끊기는 문제 등이 발생할 수 있다. 선행기술문헌 특허문헌 (특허문헌 0001) 1. 특허출원 10-2020-0118268호, 발명의 명칭 : 분절에 의한 문맥 소실을 방지하는 신경망 기 반 실시간 자동통역 방법"}
{"patent_id": "10-2023-0104469", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "이에 본 발명에서는 화자가 말하는 중이라도 화자가 말하는 언어를 분석하여 화자가 말하는 의미를 왜곡시키지 않고 순차적으로 통번역 가능하도록 하는 방법을 제안하고자 한다."}
{"patent_id": "10-2023-0104469", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명에서 제안하는 음성 인식을 통한 실시간 통번역 및 대화 방법은 제 1 단말기를 통하여 실시간으로 입력되는 제 1 음성 정보를 수신하는 단계; 상기 제 1 음성 정보를 스펙트로그램 정보로 변환하는 단계; 상기 스펙트로그램 정보를 Conformer 기반의 음향 처리기를 통하여 발음 텍스트 정보를 추출하는 단계; 상기 발음 텍스트 정보를 학습된 어휘 사전 모듈에 입력한 후 상기 발음 텍스트 정보와 유사도가 가장 높은 실 제 어휘 텍스트 정보로 변환시키는 단계; 상기 실제 어휘 텍스트 정보를 은닉 마르코프 모델(Hidden Markov Model) 기반의 언어 처리기에 입력하여 상기 단말기를 통하여 입력된 상기 제 1 음성 정보에 대한 전체 문장 텍스트 정보로 출력하는 단계를 구비하며, 순차적으로 출력되는 상기 실제 어휘 텍스트 정보는 표준 외국어 번역기로 제공되어 소정의 외국어 텍스트 정 보로 변환된 후 상기 외국어 텍스트 정보에 대응하는 제 2 음성 정보로 제 1 단말기와 연동되는 제 2 단말기로 실시간 출력되되, 실시간 출력되는 상기 제 2 음성 정보는 상기 제 1 음성 정보를 소정 구간 분할하여 실행되며, 상기 소정 구간 의 분할 판정은 상기 제 1 음성 정보 중 조건문, 부사 또는 부사구로 구성되거나, 상기 제 1 음성 정보에 술어 부가 포함되는 문장에 대항하는 경우, 상기 조건문, 상기 부사, 상기 부사구, 또는 상기 술어부가 포함되는 문 장을 판정한 후, 상기 조건문, 상기 부사, 상기 부사구, 또는 술어부가 포함되는 문장을 상기 제 2 음성 정보로 실시간 순차 번역하여 상기 제 2 단말기로 순차 출력시키는 것을 특징으로 한다."}
{"patent_id": "10-2023-0104469", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "단말기를 통하여 기존 동시 통역 앱의 경우, 문장이 끝나는 시점을 확인한 후 문장 전체를 번역하여 제공함으로 써 실시간 의사 전달에 문제가 있었으나, 본 본 발명에서 제안하는 단말기를 통하여 입력되는 음성 정보를 ASR 을 통하여 표준화한 후, 번역기를 거쳐 텍스트로 변환시키되, 텍스트를 분석하여 조선문, 부사, 부사구, 술어부, 구두점 등을 판정하여 해당 텍스트를 실시간 순차 통번역하여 다른 단말기로 출력하는 경우, 대화의 단 절없이 실시간으로 상대방의 의사를 파악할 수 있다는 이점이 있다"}
{"patent_id": "10-2023-0104469", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 본 발명의 기술적 사상인 음성 인식을 통한 실시간 번역 및 대화 방법에 대하여 설명하기로 한다. 먼저, 본 발명에서 제안하는 음성 인식을 통한 실시간 번역 및 대화 방법은 단말기를 통한 대화에 적용 가능하 다, 여기서,본 발명의 단말기는 서버와 유무선으로 연동되는 스마트폰, 컴퓨터, 태블릿 등을 포함한다. 먼저, 본 발명의 음성 인식을 통한 실시간 번역 및 대화 방법을 가능하게 하는 기능을 갖는 서버에 대하여 설명 하기로 한다 본 발명의 서버는 인공지능 학습된 자동음성인식 시스템 (ASR : Automatic Speech Recognition)을 구비하며, 본 발명의 자동음성인식 시스템은 적어도 음향 추출기, 음향 처리기, 어휘 처리기, 언어 처리기 등을 포함한다. 본 발명에서 실시하는 ASR은 단말기를 통하여 입력되는 음성에 대하여 VAD 모듈을 거치도록 하고 있다. 여기서 VAD(Voice Activity Detection) 모듈은 단말기를 통하여 입력되는 정보 중에서 배경 잡음과 묵음 정보(묵음 시 간), 그리고 음성 정보를 구분할 수 있도록 학습되어 있다. 본 발명에서는 VAD 모듈을 활용함으로써 배경 잡음 을 제거함과 아울러 묵음 정보를 획들할 수 있으며 이러한 묵음 정보는 본 발명의 실시간 통번역에 있어서 중요 한 기능을 수행하게 되며 입력되는 음성 입력의 종점(구술 문장의 끝맺음)을 판단하기도 한다. 이러한 본 발명의 VAD 모듈에 의하여 단말기를 통하여 서버로 전송되는 정보 중에서 음성 정보만이 추출되어 후 술되는 ASR로 전달되게 된다. 도 1에는 본 발명에 따른 음성 인식을 통한 실시간 번역 및 대화 방법을 설명하기 위한 개념도의 일예가 도시되 어 있으며, 도 2에는 도 2는 본 발명에 따른 음성 인식을 통한 실시간 번역 및 대화 방법의 실시예가 도시되어 있다. 본 발명에 있어서, ASR의 일 구성인 음향 추출기(예컨대, MFCC기반의 음향추출기)는 서버와 연동되는 단달기를 통하여 입력된 음성 정보 수신하여, 음성 정보의 고유한 특징을 추출한 데이터 정보(스펙트로그램 정보)를 생성 한다 다음, 본 발명의 음향 처리기는 Conformer model기반의 음향처리기로 구성될 수 있으며, 음향 추추출기의 스펙 트로그램 정보를 수신하여 해당 스펙트로그램 정보의 음성 특징을 분석한 후 해당 음성 특징과 유사도가 가장 높은 발음 텍스트를 추출한다. 다음, 본 발명의 어휘 처리기는 인공지능으로 학습된 어휘 사전 모듈을 구비하며, 음향 처리기를 통하여 수신되 는 발음 텍스트를 학습된 어휘 사전 모듈과 비교하여 가장 유사도가 높은 실제 어휘 텍스트로 변환시킨다. 여기서, 실제 어휘 텍스트란 발음 텍스트 정보를 통번역에 용이한 표준어 텍스트로 변환시키거나, 부정확인 발 음 텍스트 정보를 추정 보완하여 정확한 의미를 갖는 실제 어휘 텍스트로 변환시키는 과정을 의미한다. 예컨대, 음향 처리기의 발음 텍스트 정보가 \" 여기가 어덴교\"인 경우, 음향 처리기에서는 \"여기가 어디인가요\" 와 같이 표준어에 매칭될 수 있는 실제 어휘 텍스트로 변환시키는 기능을 수행한다. 여기서, 본 발명의 음향 처리기는, 예컨대 \"안녕하십니까, 말좀 물읍시다, 요 밥집 잘하는데가 어덴교?” 라는 텍스트 정보에 대하여 일예로 \"안녕하십니까, 말씀 좀 묻겠습니다. 여기 밥집 잘하는 곳이 어디입니까?” 형태 의 텍스트로 변환시키는 기능을 수행하며, 이러한 본 발명의 음향 처리기는 단순히 단어만 추론하여 소정의 텍 스트로 변환시키는 것이 아니라 입력된 텍스트 정보의 단어, 문장, 문단 단위 추론, 및 연산 등을 통하여 표준 화된 텍스트로 변환시킬 수 있다. 다음, 본 발명의 언어 처리기는(예컨대, 은닉마코프모델(Hidden Markov Models, HMMs)기반의 언어 처리기)는 순차적으로 입력되는 실제 어휘 텍스트 정보를 실제 언어구조에 맞게 조합한 후 전체 텍스트 정보를 산출하는 기능을 수행한다. 한편, 본 발명의 서버는 실시간 대화 번역 즉 실시간 통역을 실시하기 위하여 실시간 대화 번역기를 추가로 구 비한다. 본 발명의 실시간 대화 번역기는 어휘 처리기로부터 출력되는 실제 어휘 텍스트 정보를 수신하여 번역하는 기능 을 수행한다. 본 발명의 실시간 번역은 단말기를 통하여 입력되는 음성 정보의 마지막 종결전 순차 번역이 가능하도록 다음과 같은 기능을 수행하게 된다. 먼저, 본 발명의 실시간 대화 번역기는 어휘 처리기로부터 수신되는 실제 어휘 텍스트 정보의 구두점(구어체의 끝맺음, 구어체의 한문장을 의미한다), 품사와 문장을 분석하는 기능을 구비한다. 본 발명의 실시간 대화 번역기에서는 어휘 처리기로부터 수신되는 실제 어휘 텍스트 정보가 조건문인지 여부를 판단하는 기능과, 부사 또는 부사구인지 여부를 판단하는 기능과, 순차적으로 입력되는 실제 어휘 텍스트 정보 중 술어부인지 여부, 그리고 문장의 종점을 나타내는 구두점 부분이 포함되어 있는지 판단하는 기능등을 구비한 다. 예컨대, 본 발명의 실시간 번역 처리기에서 판단한 실제 어휘 텍스트 정보가 조건문에 해당하는 경우, 이를 실 시간으로 영어 등과 같은 외국어로 번역하여 출력할 수 있다. 또한, 본 발명의 실시간 번역 처리기에서 판단한 실제 어휘 텍스트 정보가 기학습되어 있는 부사 또는 부사구에 해당하는 경우, 이를 실시간으로 영어 등과 같은 외국어로 번역하여 출력할 수 있다. 또한, 본 발명의 실시간 번역 처리기에서 판단한 실제 어휘 텍스트 정보에 술어부가 포함되어 있는 경우, 술어 부까지 포함하는 실제 어휘 텍스트 정보를 실시간으로 영어 등과 같은 외국어로 번역하여 출력한다 또한, 본 발명의 실시간 번역 처리기에서 판단한 실제 어휘 텍스트 정보에 구두점이 있는 문장이라고 판단되는 경우, 구두점까지 포함하는 실제 어휘 텍스트 정보를 실시간으로 영어 등과 같은 외국어로 번역하여 출력한다. 위에서 설명한 번역은, 조건문, 부사 또는 부사구, 술어부가 포함된 경우의 문장, 구두점이 포함되어 있는 문장 각각에 대하여 독립적으로 순차 번역이 이루어지게 된다. 예컨대, \"내일 만약 비가 온다면, 야외 나들이 가는 것을 자제해야 한다\"라는 정보에 대하여 조건문인 \"내일 만 약 비가 온다면\"에 대하여 먼저 번역이 이루어지고, 구두점을 포함하는 다음 문장인 \"야외 나들이 가는 것을 자 제해야 한다\"에 대하여 순차 번역이 진행되는 방식이다. 여기서, 만약 \"내일\"을 부사 또는 \"부사구\"로 판단하는 경우, \"내일\"을 번역 번역한 후 \"만약 비가 온다면\"을 순차 번력할 수 있다. 이를 구체적으로 설명하면 다음과 같다. 예컨대 실시간 번역 처리기로 순차 입력되는 실제 어휘 텍스트 정보가 다음과 같다고 가정하자. 단말기를 통하여 입력된 대화 내용이 \"그리고, 재미있게 대화를 나누고 싶다면 상대방의 입장에서 생각을 해야 지\"라고 하면, 실제 어휘 텍스트 정보는 순차적으로 다음과 같을 수 있다. 1. 그리고 2. 재미있게 3. 대화를 4. 나누고 5. 싶다면 6. 상대방의 7. 입장에서 8. 생각을 9. 해야지 여기서 위 대화 내용을 영어로 번역한 경우 다음과 같은 문장이 될 수 있을 것이다. \"And if you want to have a fun conversation, you have to think from the other person's point of view\" 그런데, 본 발명에서는 실시간으로 번역하기 위하여 대화의 내용을 다음과 같은 방법과 같이 끊어 가면서 실시 간으로 번역하게 된다. 먼저, 본 발명에 있어서, \"그리고\"는 부사이므로 이에 대응하는 외국어(예컨대 영어)인 And 로 번역하여 실시간 출력한다. 다음 \"재미있게\" 또한 부사이므로 이에 대응하는 외국어인 funny 를 실시간으로 출력할 수도 있다. 다음, 조건문인 \"대화를 나누고 싶다면\"를 \"if you want to have a conversation\"로 번역하여 실시간 출력할 수 있다. 참고로, 이 경우는 술어를 포함한 직전 텍스트 정보를 포함하여 번역한 경우에 해당할 수도 있다. 다음, \"상대방의 입장에서\"는 \"from the other person's point of view\"로 번역하여 실시간 출력할 수 있다. 참고로, 이 경우는 부사구로 판정한 경우에 해당한다 다음, 술어부를 포함하는 \"생각을 해야지\"는 \"you have to think about it\"로 번역하여 실시간 출력할 수 있다. 참고로, 이 경우는 술어(해야지)를 포함한 직전 텍스트 정보를 포함하여 번역한 경우의 일예이다. 결과적으로 화자의 상대방은 실시간으로, \"and, funny, if you want to have a conversation, from the other person's point of view, you have to think about it\"이라는 문장을 듣을 수 있다. 물론, 위 문장은 정확한 번역 문장과는 다소 차이가 있을 수 있다. 그러나 본 발명 방법을 실시하는 경우, 화자가 말하고자 하는 내용의 범위 내에서 실시간으로 상대방에게 충분 하게 의사를 전달할 수 있다. 충분한 의사 전달 가능 여부는 실시간 번역 처리기의 문단 분석 능력에 따라 차 이가 있을 수 있다. 그러나, 본 발명에서 제안하는 방법을 실시하는 경우, 화자 및 그 상대방은 상이한 어어를 사용하는 경우에도 실시간으로 상대가 하는 말의 의미를 이해할 수 있고 따라서 실시간적으로 응답을 할 수 있 다는 이점을 가진다. 예컨대, 화자의 대화를 실시간 통번역하여 상대방에게 제공할 수 있으므로, 상대방은 화자의 대화 중간에 자신 의 의사를 실시간으로 전달할 수 있는 이점이 있다 즉, 본 본 발명에서 제안하는 단말기를 통하여 입력되는 음성 정보를 ASR을 통하여 표준화한 후, 번역기를 거쳐 텍스트로 변환시키되, 텍스트를 분석하여 조선문, 부사, 부사구, 술어부, 구두점 등을 판정하여 해당 텍스트를 실시간 순차 통번역하여 다른 단말기로 출력하는 경우, 대화의 단절없이 실시간으로 상호간의 의사를 파악할 수 있다는 이점이 있다."}
{"patent_id": "10-2023-0104469", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명에 따른 음성 인식을 통한 실시간 번역 및 대화 방법을 설명하기 위한 개념도의 일예이다. 도 2는 본 발명에 따른 음성 인식을 통한 실시간 번역 및 대화 방법의 실시예이다."}
