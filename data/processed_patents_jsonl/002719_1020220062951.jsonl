{"patent_id": "10-2022-0062951", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0163182", "출원번호": "10-2022-0062951", "발명의 명칭": "인공지능을 적용한 3차원 얼굴스캔 자동매칭장치 및 그 장치의 구동방법, 그리고 매체에 저장", "출원인": "주식회사 메가젠임플란트", "발명자": "박광범"}}
{"patent_id": "10-2022-0062951", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "사용자의 얼굴을 컴퓨터 단층촬영(CT)시 얼굴 중앙 부위를 캡쳐하여 얻은 제1 이미지 데이터 및 상기 사용자의얼굴을 3D 스캔(scan) 방식으로 촬영하여 얻은 제2 이미지 데이터를 수신하는 통신 인터페이스부; 및인공지능(AI)을 적용해 상기 제1 이미지 데이터와 상기 제2 이미지 데이터를 분석하여 공통되게 검출되는 랜드마크(landmark)의 검출점을 찾고, 상기 제2 이미지 데이터상에서 찾은 상기 검출점에 대한 2차원 좌표값을 3차원 좌표값으로 변환하여 상기 변환한 3차원 좌표값을 근거로 상기 제2 이미지 데이터를 CT 촬영영상 데이터에자동 매칭시켜 상기 사용자의 얼굴을 3D로 시각화하는 제어부를 포함하는 것을 특징으로 하는, 인공지능을 적용한 3차원 얼굴 스캔 자동 매칭 장치."}
{"patent_id": "10-2022-0062951", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 제어부는, 상기 인공지능을 적용하여 상기 제1 이미지 데이터와 상기 제2 이미지 데이터를 분석하여 특징점과 관련한 다수의 검출점을 각각 추출하고, 상기 추출한 다수의 검출점 중에서 서로 공통되는 복수의 랜드마크 검출점을 추출하는 것을 특징으로 하는, 인공지능을 적용한 3차원 얼굴 스캔 자동 매칭 장치."}
{"patent_id": "10-2022-0062951", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,상기 제어부는, 상기 CT 촬영시의 얼굴 부위와 상기 3D 스캔 촬영시의 얼굴 부위에서 상기 특징점의 위치가 변경되지 않는 검출점을 상기 랜드마크 검출점으로 추출하는 것을 특징으로 하는, 인공지능을 적용한 3차원 얼굴스캔 자동 매칭 장치."}
{"patent_id": "10-2022-0062951", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제2항에 있어서,상기 제어부는, 상기 특징점 및 상기 복수의 랜드마크 검출점을 검출하기 위한 기준정보를 기설정하고, 상기 기설정한 기준 정보를 근거로 상기 인공지능을 적용해 상기 특징점 및 상기 랜드마크 검출점을 검출하는 것을 특징으로 하는, 인공지능을 적용한 3차원 얼굴 스캔 자동 매칭 장치."}
{"patent_id": "10-2022-0062951", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서,상기 제어부는, 상기 기준정보로서 상기 특징점으로 이루어지는 형상(shape)을 판단하여 판단 결과를 근거로 상기 랜드마크 검출점을 확정하는 것을 특징으로 하는, 인공지능을 적용한 3차원 얼굴 스캔 자동 매칭 장치."}
{"patent_id": "10-2022-0062951", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서,상기 제어부는, 상기 제2 이미지 데이터를 3차원의 UV 맵(map) 데이터로 변환하고, 상기 변환한 UV 맵 데이터및 상기 얼굴스캔 촬영시 생성되는 3차원 데이터를 이용해 상기 검출점에 대한 2차원 좌표값을 상기 3차원 좌표값으로 변환하며, 상기 3차원 좌표값의 변환시 3개의 좌표에 의해 형성되는 형상 및 각 좌표의 컬러정보를 판단하여 판단 결과를 근거로 3차원 좌표값의 변환을 수행하는 것을 특징으로 하는, 인공지능을 적용한 3차원 얼굴스캔 자동 매칭 장치."}
{"patent_id": "10-2022-0062951", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "통신 인터페이스부가, 사용자의 얼굴을 컴퓨터 단층촬영시 얼굴 중앙 부위를 캡쳐하여 얻은 제1 이미지 데이터공개특허 10-2023-0163182-3-및 상기 사용자의 얼굴을 3D 스캔 방식으로 촬영하여 얻은 제2 이미지 데이터를 수신하는 단계; 및제어부가, 인공지능을 적용해 상기 제1 이미지 데이터와 상기 제2 이미지 데이터를 분석하여 공통되게 검출되는랜드마크의 검출점을 찾고, 상기 제2 이미지 데이터상에서 찾은 상기 검출점에 대한 2차원 좌표값을 3차원 좌표값으로 변환하여 상기 변환한 3차원 좌표값을 근거로 상기 제2 이미지 데이터를 CT 촬영영상 데이터에 자동 매칭시켜 상기 사용자의 얼굴을 3D로 시각화하는 단계를 포함하는 것을 특징으로 하는, 인공지능을 적용한 3차원얼굴 스캔 자동 매칭 장치의 구동방법."}
{"patent_id": "10-2022-0062951", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서,상기 시각화하는 단계는,상기 인공지능을 적용하여 상기 제1 이미지 데이터와 상기 제2 이미지 데이터를 분석하여 특징점과 관련한 다수의 검출점을 각각 추출하는 단계; 및 상기 추출한 다수의 검출점 중에서 서로 공통되는 복수의 랜드마크 검출점을 추출하는 단계를 포함하는 것을 특징으로 하는, 인공지능을 적용한 3차원 얼굴 스캔 자동 매칭 장치의 구동방법."}
{"patent_id": "10-2022-0062951", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서,상기 복수의 랜드마크 검출점을 추출하는 단계는,상기 CT 촬영시의 얼굴 부위와 상기 3D 스캔 촬영시의 얼굴 부위에서 상기 특징점의 위치가 변경되지 않는 검출점을 상기 랜드마크 검출점으로 추출하는 것을 특징으로 하는, 인공지능을 적용한 3차원 얼굴 스캔 자동 매칭장치의 구동방법."}
{"patent_id": "10-2022-0062951", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제8항에 있어서,상기 시각화하는 단계는,상기 특징점 및 상기 복수의 랜드마크 검출점을 검출하기 위한 기준정보를 기설정하는 단계; 및 상기 기설정한 기준 정보를 근거로 상기 인공지능을 적용해 상기 특징점 및 상기 랜드마크 검출점을 검출하는단계를 포함하는 것을 특징으로 하는, 인공지능을 적용한 3차원 얼굴 스캔 자동 매칭 장치의 구동방법."}
{"patent_id": "10-2022-0062951", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제10항에 있어서,상기 랜드마크 검출점을 검출하는 단계는,상기 기준정보로서 상기 특징점으로 이루어지는 형상을 판단하여 판단 결과를 근거로 상기 랜드마크 검출점을확정하는 단계를 포함하는 것을 특징으로 하는, 인공지능을 적용한 3차원 얼굴 스캔 자동 매칭 장치의구동방법."}
{"patent_id": "10-2022-0062951", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제7항에 있어서,상기 시각화하는 단계는,상기 제2 이미지 데이터를 3차원의 UV 맵(map) 데이터로 변환하는 단계;상기 변환한 UV 맵 데이터 및 상기 얼굴스캔 촬영시 생성되는 3차원 데이터를 이용해 상기 검출점에 대한 2차원좌표값을 상기 3차원 좌표값으로 변환하는 단계; 및상기 3차원 좌표값의 변환시 3개의 좌표값에 의해 형성되는 형상 및 각 좌표의 컬러정보를 판단하여 판단 결과를 근거로 3차원 좌표값의 변환을 수행하는 단계를 포함하는 것을 특징으로 하는, 인공지능을 적용한 3차원 얼공개특허 10-2023-0163182-4-굴 스캔 자동 매칭 장치의 구동방법."}
{"patent_id": "10-2022-0062951", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "인공지능을 적용한 3차원 얼굴 스캔 자동 매칭 방법을 실행하기 위하여 매체에 저장된 컴퓨터프로그램으로서,상기 인공지능을 적용한 3차원 얼굴 스캔 자동 매칭 방법은,사용자의 얼굴을 컴퓨터 단층촬영시 얼굴 중앙 부위를 캡쳐하여 얻은 제1 이미지 데이터 및 상기 사용자의 얼굴을 3D 스캔 방식으로 촬영하여 얻은 제2 이미지 데이터를 수신하는 단계; 및인공지능을 적용해 상기 제1 이미지 데이터와 상기 제2 이미지 데이터를 분석하여 공통되게 검출되는 랜드마크의 검출점을 찾고, 상기 제2 이미지 데이터상에서 찾은 상기 검출점에 대한 2차원 좌표값을 3차원 좌표값으로변환하여 상기 변환한 3차원 좌표값을 근거로 상기 제2 이미지 데이터를 CT 촬영영상 데이터에 자동 매칭시켜상기 사용자의 얼굴을 3D로 시각화하는 단계를 실행시키는 것을 특징으로 하는, 매체에 저장된 컴퓨터프로그램."}
{"patent_id": "10-2022-0062951", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "인공지능을 적용한 3차원 얼굴스캔 자동매칭장치 및 그 장치의 구동방법, 그리고 매체에 저장된 컴퓨터프로그램 이 개시된다. 본 발명에 따른, 인공지능을 적용한 3차원 얼굴 스캔 자동 매칭 장치는, 사용자의 얼굴을 컴퓨터 단층촬영(CT)시 얼굴 중앙 부위를 캡쳐하여 얻은 제1 이미지 데이터 및 사용자의 얼굴을 3D 스캔(scan) 방식으로 촬영하여 얻은 제2 이미지 데이터를 수신하는 통신 인터페이스부; 및 인공지능(AI)을 적용해 제1 이미지 데이터 와 제2 이미지 데이터를 분석하여 공통되게 검출되는 랜드마크(landmark)의 검출점을 찾고, 제2 이미지 데이터상 에서 찾은 검출점에 대한 2차원 좌표값을 3차원 좌표값으로 변환하여 변환한 3차원 좌표값을 근거로 제2 이미지 데이터를 CT 촬영영상 데이터에 자동 매칭시켜 사용자의 얼굴을 3D로 시각화하는 제어부를 포함한다."}
{"patent_id": "10-2022-0062951", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 인공지능을 적용한 3차원 얼굴스캔 자동매칭장치 및 그 장치의 구동방법에 관한 것으로서, 보다 상세 하게는, 가령 치과나 미용치료시 사용자의 웃는 얼굴에 대한 컴퓨터 단층촬영(Computed Tomography, CT)을 3D로 시각화하여 볼 수 있도록 해 진단 정확도를 높이려는 인공지능을 적용한 3차원 얼굴스캔 자동매칭장치 및 그 장 치의 구동방법, 그리고 매체에 저장된 컴퓨터프로그램에 관한 것이다."}
{"patent_id": "10-2022-0062951", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "치과용 임플란트는 원래 인체조직이 상실되었을 때, 회복시켜 주는 대치물을 의미하지만, 치과에서는 인공으로 만든 치아를 이식하는 일련의 시술을 가리킨다. 상실된 치근(뿌리)을 대신할 수 있도록 인체에 거부반응이 없는 티타늄(titanium) 등으로 만든 치근인 픽스츄어(fixture)를 치아가 빠져나간 치조골에 심은 뒤, 인공치아를 고 정시켜 치아의 기능을 회복하도록 하는 시술이다. 일반 보철물이나 틀니의 경우, 시간이 지나면 주위 치아와 뼈 가 상하지만 임플란트는 주변 치아조직을 상하지 않게 하며, 자연치아와 기능이나 모양이 같으면서도 충치가 생 기지 않으므로 반영구적으로 사용할 수 있는 장점이 있다. 인공치아 시술(또는 임플란트 또는 임플란트 시술)은, 픽스츄어의 종류에 따라 다양하지만 소정의 드릴을 사용 하여 식립위치를 천공한 후 픽스츄어를 치조골에 식립하여 뼈에 골융합시킨 다음, 픽스츄어에 지대주(abutmen t)를 결합시킨 후에, 지대주에 최종 보철물을 씌움으로써 완료되는 것이 일반적이다. 치과용 임플란트는 단일 결손치 수복은 물론이거니와 부분 무치아 및 완전 무치아 환자에게 의치의 기능을 증진시키고, 치아 보철 수복 의 심미적인 면을 개선시키며, 나아가 주위의 지지골 조직에 가해지는 과도한 응력을 분산시킴과 아울러 치열의 안정화에 도움을 준다. 한편, 임플란트 시술 과정에서 임플란트 시술의 정확성을 높이기 위해 모의시술 및 시술계획이 수반된다. 이러 한 모의시술 및 시술계획에는 피시술자의 구강 영역에 대한 정확한 데이터가 필수적이다. 일반적으로 피시술자 의 구강 영역에 대한 데이터를 획득하기 위해 피시술자의 구강 영역을 컴퓨터 단층촬영(Computed Tomography, CT) 기구로 촬영하여 입체 영상 데이터를 획득하는 방식이 사용된다. 그런데 컴퓨터 단층촬영은 사용자 즉 환자 얼굴의 실제 비율을 3D로 볼 수 있다는 점에서는 장점이 있으나, 방 사선 노출로 인해 권고사항으로서 눈을 감거나 입을 다물로 촬영하는 것이 일반적이며, 반면 실제 치과나 미용 치료의 경우에는 사용자의 웃는 얼굴을 반영하는 것이 중요하므로, 웃는 얼굴에 사용자의 위치(예: 구강 내 치 아 등)를 일치시키기 위한 방법이 절실히 요구되고 있다. 선행기술문헌 특허문헌"}
{"patent_id": "10-2022-0062951", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 2, "content": "(특허문헌 0001) 한국등록특허공보 제10-1877895호(2018.07.06) 발명의 내용"}
{"patent_id": "10-2022-0062951", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명의 실시예는 가령 치과나 미용치료시 사용자의 웃는 얼굴에 대한 컴퓨터 단층촬영을 3D로 시각화하여 볼 수 있도록 해 진단 정확도를 높이려는 인공지능을 적용한 3차원 얼굴스캔 자동매칭장치 및 그 장치의 구동방법, 그리고 매체에 저장된 프로그램을 제공함에 그 목적이 있다."}
{"patent_id": "10-2022-0062951", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 일 측면에 따르면, 사용자의 얼굴을 컴퓨터 단층촬영(CT)시 얼굴 중앙 부위를 캡쳐하여 얻은 제1 이 미지 데이터 및 상기 사용자의 얼굴을 3D 스캔(scan) 방식으로 촬영하여 얻은 제2 이미지 데이터를 수신하는 통 신 인터페이스부; 및 인공지능(AI)을 적용해 상기 제1 이미지 데이터와 상기 제2 이미지 데이터를 분석하여 공 통되게 검출되는 랜드마크(landmark)의 검출점을 찾고, 상기 제2 이미지 데이터상에서 찾은 상기 검출점에 대한 2차원 좌표값을 3차원 좌표값으로 변환하여 상기 변환한 3차원 좌표값을 근거로 상기 제2 이미지 데이터를 CT 촬영영상 데이터에 자동 매칭시켜 상기 사용자의 얼굴을 3D로 시각화하는 제어부를 포함하는 것을 특징으로 하 는, 인공지능을 적용한 3차원 얼굴 스캔 자동 매칭 장치가 제공될 수 있다. 상기 제어부는, 상기 인공지능을 적용하여 상기 제1 이미지 데이터와 상기 제2 이미지 데이터를 분석하여 특징 점과 관련한 다수의 검출점을 각각 추출하고, 상기 추출한 다수의 검출점 중에서 서로 공통되는 복수의 랜드마 크 검출점을 추출할 수 있다. 상기 제어부는, 상기 CT 촬영시의 얼굴 부위와 상기 3D 스캔 촬영시의 얼굴 부위에서 상기 특징점의 위치가 변 경되지 않는 검출점을 상기 랜드마크 검출점으로 추출하는 것을 특징으로 할 수 있다. 상기 제어부는, 상기 특징점 및 상기 복수의 랜드마크 검출점을 검출하기 위한 기준정보를 기설정하고, 상기 기 설정한 기준 정보를 근거로 상기 인공지능을 적용해 상기 특징점 및 상기 랜드마크 검출점을 검출할 수 있다. 상기 제어부는, 상기 기준정보로서 상기 특징점으로 이루어지는 형상(shape)을 판단하여 판단 결과를 근거로 상 기 랜드마크 검출점을 확정할 수 있다. 상기 제어부는, 상기 제2 이미지 데이터를 3차원의 UV 맵(map) 데이터로 변환하고, 상기 변환한 UV 맵 데이터 및 상기 얼굴스캔 촬영시 생성되는 3차원 데이터를 이용해 상기 검출점에 대한 2차원 좌표값을 상기 3차원 좌표 값으로 변환하며, 상기 3차원 좌표값의 변환시 3개의 좌표에 의해 형성되는 형상 및 각 좌표의 컬러정보를 판단 하여 판단 결과를 근거로 3차원 좌표값의 변환을 수행할 수 있다. 또한, 본 발명의 다른 측면에 따르면, 통신 인터페이스부가, 사용자의 얼굴을 컴퓨터 단층촬영시 얼굴 중앙 부 위를 캡쳐하여 얻은 제1 이미지 데이터 및 상기 사용자의 얼굴을 3D 스캔 방식으로 촬영하여 얻은 제2 이미지 데이터를 수신하는 단계; 및 제어부가, 인공지능을 적용해 상기 제1 이미지 데이터와 상기 제2 이미지 데이터를 분석하여 공통되게 검출되는 랜드마크의 검출점을 찾고, 상기 제2 이미지 데이터상에서 찾은 상기 검출점에 대 한 2차원 좌표값을 3차원 좌표값으로 변환하여 상기 변환한 3차원 좌표값을 근거로 상기 제2 이미지 데이터를 CT 촬영영상 데이터에 자동 매칭시켜 상기 사용자의 얼굴을 3D로 시각화하는 단계를 포함하는 것을 특징으로 하 는, 인공지능을 적용한 3차원 얼굴 스캔 자동 매칭 장치의 구동방법이 제공될 수 있다. 상기 시각화하는 단계는, 상기 인공지능을 적용하여 상기 제1 이미지 데이터와 상기 제2 이미지 데이터를 분석 하여 특징점과 관련한 다수의 검출점을 각각 추출하는 단계; 및 상기 추출한 다수의 검출점 중에서 서로 공통되 는 복수의 랜드마크 검출점을 추출하는 단계를 포함할 수 있다. 상기 복수의 랜드마크 검출점을 추출하는 단계는, 상기 CT 촬영시의 얼굴 부위와 상기 3D 스캔 촬영시의 얼굴 부위에서 상기 특징점의 위치가 변경되지 않는 검출점을 상기 랜드마크 검출점으로 추출할 수 있다. 상기 시각화하는 단계는, 상기 특징점 및 상기 복수의 랜드마크 검출점을 검출하기 위한 기준정보를 기설정하는 단계; 및 상기 기설정한 기준 정보를 근거로 상기 인공지능을 적용해 상기 특징점 및 상기 랜드마크 검출점을 검출하는 단계를 포함할 수 있다, 상기 랜드마크 검출점을 검출하는 단계는, 상기 기준정보로서 상기 특징점으로 이루어지는 형상을 판단하여 판 단 결과를 근거로 상기 랜드마크 검출점을 확정하는 단계를 포함할 수 있다.상기 시각화하는 단계는, 상기 제2 이미지 데이터를 3차원의 UV 맵(map) 데이터로 변환하는 단계; 상기 변환한 UV 맵 데이터 및 상기 얼굴스캔 촬영시 생성되는 3차원 데이터를 이용해 상기 검출점에 대한 2차원 좌표값을 상 기 3차원 좌표값으로 변환하는 단계; 및 상기 3차원 좌표값의 변환시 3개의 좌표값에 의해 형성되는 형상 및 각 좌표의 컬러정보를 판단하여 판단 결과를 근거로 3차원 좌표값의 변환을 수행하는 단계를 포함할 수 있다. 또한, 본 발명의 또 다른 측면에 따르면, 인공지능을 적용한 3차원 얼굴 스캔 자동 매칭 방법을 실행하기 위하 여 매체에 저장된 컴퓨터프로그램으로서, 상기 인공지능을 적용한 3차원 얼굴 스캔 자동 매칭 방법은, 사용자의 얼굴을 컴퓨터 단층촬영시 얼굴 중앙 부위를 캡쳐하여 얻은 제1 이미지 데이터 및 상기 사용자의 얼굴을 3D 스 캔 방식으로 촬영하여 얻은 제2 이미지 데이터를 수신하는 단계; 및 인공지능을 적용해 상기 제1 이미지 데이터 와 상기 제2 이미지 데이터를 분석하여 공통되게 검출되는 랜드마크의 검출점을 찾고, 상기 제2 이미지 데이터 상에서 찾은 상기 검출점에 대한 2차원 좌표값을 3차원 좌표값으로 변환하여 상기 변환한 3차원 좌표값을 근거 로 상기 제2 이미지 데이터를 CT 촬영영상 데이터에 자동 매칭시켜 상기 사용자의 얼굴을 3D로 시각화하는 단계 를 실행시키는 것을 특징으로 하는, 매체에 저장된 컴퓨터프로그램이 제공될 수 있다."}
{"patent_id": "10-2022-0062951", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명의 실시예에 따르면 치과치료나 미용치료시 사용자의 웃는 얼굴을 반영하여 CT 촬영영상을 3D로 시각화 하여 볼 수 있으므로, 진단의 정확도를 높일 수 있을 것이다. 또한, 본 발명의 실시예에 따르면 CT 촬영에 의한 영상 데이터와 사용자의 웃는 얼굴을 촬영한 스캔 데이터의 이종(heterogeneity)의 데이터를 결합할 때 인공지능 프로그램을 적용함으로써 데이터 처리의 정확도와 신속성 을 높일 수 있을 것이다."}
{"patent_id": "10-2022-0062951", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 명세서에 개시되어 있는 본 발명의 개념에 따른 실시 예들에 대해서 특정한 구조적 또는 기능적 설명들은 단 지 본 발명의 개념에 따른 실시예들을 설명하기 위한 목적으로 예시된 것으로서, 본 발명의 개념에 따른 실시예 들은 다양한 형태들로 실시될 수 있으며 본 명세서에 설명된 실시 예들에 한정되지 않는다. 본 발명의 개념에 따른 실시예들은 다양한 변경들을 가할 수 있고 여러 가지 형태들을 가질 수 있으므로 실시예 들을 도면에 예시하고 본 명세서에 상세하게 설명하고자 한다. 그러나, 이는 본 발명의 개념에 따른 실시예들을 특정한 개시 형태들에 대해 한정하려는 것이 아니며, 본 발명의 사상 및 기술 범위에 포함되는 모든 변경, 균등 물, 또는 대체물을 포함한다. 제1 또는 제2 등의 용어는 다양한 구성 요소들을 설명하는데 사용될 수 있지만, 상기 구성 요소들은 상기 용어 들에 의해 한정되어서는 안 된다. 상기 용어들은 하나의 구성 요소를 다른 구성 요소로부터 구별하는 목적으로 만, 예컨대 본 발명의 개념에 따른 권리 범위로부터 이탈되지 않은 채, 제1구성요소는 제2구성요소로 명명될 수있고, 유사하게 제2구성요소는 제1구성요소로도 명명될 수 있다. 어떤 구성요소가 다른 구성요소에 \"연결되어\" 있다거나 \"접속되어\" 있다고 언급된 때에는, 그 다른 구성요소에 직접적으로 연결되어 있거나 또는 접속되어 있을 수도 있지만, 중간에 다른 구성요소가 존재할 수도 있다고 이 해되어야 할 것이다. 반면에, 어떤 구성요소가 다른 구성요소에 \"직접 연결되어\" 있다거나 \"직접 접속되어\" 있 다고 언급된 때에는, 중간에 다른 구성요소가 존재하지 않는 것으로 이해되어야 할 것이다. 구성요소들 간의 관 계를 설명하는 다른 표현들, 즉 \"~사이에\"와 \"바로 ~사이에\" 또는 \"~에 이웃하는\"과 \"~에 직접 이웃하는\" 등도 마찬가지로 해석되어야 한다. 본 명세서에서 사용한 용어는 단지 특정한 실시 예를 설명하기 위해 사용된 것으로, 본 발명을 한정하려는 의도 가 아니다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 명세서에서, \"포함하다\" 또는 \"가지다\" 등의 용어는 실시된 특징, 숫자, 단계, 동작, 구성요소, 부분품 또는 이들을 조합한 것이 존재함을 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성요소, 부분품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되어야 한다. 다르게 정의되지 않는 한, 기술적이거나 과학적인 용어를 포함해서 여기서 사용되는 모든 용어들은 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자에 의해 일반적으로 이해되는 것과 동일한 의미를 가진다. 일반적 으로 사용되는 사전에 정의되어 있는 것과 같은 용어들은 관련 기술의 문맥상 가지는 의미와 일치하는 의미를 갖는 것으로 해석되어야 하며, 본 명세서에서 명백하게 정의하지 않는 한, 이상적이거나 과도하게 형식적인 의 미로 해석되지 않는다. 도면들에 있어서, 층 및 영역들의 두께는 명확성을 기하기 위하여 과장된 것이다. 층이 다른 층 또는 기판 \"상\"에 있다고 언급되거나, 층이 다른 층 또는 기판과 결합 또는 접착된다고 언급되는 경우에, 그것은 다른 층 또는 기판상에 직접 형성될 수 있거나 또는 그들 사이에 제3의 층이 개재될 수도 있다. 명세서 전체에 걸쳐서 동일한 참조번호로 표시된 부분들은 동일한 구성요소들을 의미한다. 상단, 하단, 상면, 하면, 전면, 후면, 또는 상부, 하부 등의 용어는 구성요소에 있어 상대적인 위치를 구별하기 위해 사용되는 것이다. 예를 들어, 편의상 도면상의 위쪽을 상부, 도면상의 아래쪽을 하부로 명명하는 경우, 실 제에 있어서는 본 발명의 권리 범위를 벗어나지 않으면서 상부는 하부로 명명될 수 있고, 하부는 상부로 명명될 수 있다. 또한, 도면의 구성요소는 반드시 축척에 따라 그려진 것은 아니고, 예컨대, 본 발명의 이해를 돕기 위 해 도면의 일부 구성요소의 크기는 다른 구성요소에 비해 과장될 수 있다. 이하, 도면을 참조하여 본 발명의 실시예에 대하여 상세히 설명한다. 도 1은 본 발명의 실시예에 따른 AI 기반 3D 얼굴스캔 자동매칭장치의 세부 구조를 예시한 블록다이어그램이며, 도 2는 SCOUT 영상과 얼굴스캔(Face Scan) 영상의 데이터 구성을 설명하기 위한 도면이다. 도 1에 도시된 바와 같이, 본 발명의 실시예에 따른 인공지능(AI) 기반(혹은 적용) 3D 얼굴스캔 자동매칭장치 (및 소프트웨어)(이하, 장치로 기술함)는 통신 인터페이스부, 제어부, AI 기반 3D 얼굴스캔 자 동매칭부 및 저장부의 일부 또는 전부를 포함한다. 구체적인 설명에 앞서, 본 발명의 실시예에 따른 AI 기반 3D 얼굴스캔 자동매칭장치는 치과 등에서 사용하 는 데스크탑컴퓨터, 랩탑컴퓨터, 태블릿PC, 스마트폰 등 다양한 장치를 포함할 수 있지만, CT 촬영을 수행하는 CT 촬영장치 및 사용자 즉 환자의 얼굴을 3D 촬영하는 3D 스캔장치를 포함할 수도 있으므로, 본 발명의 실시예 에서는 어느 하나의 장치에 특별히 한정하지는 않을 것이다. 나아가 AI 기반 3D 얼굴스캔 자동매칭장치는 해당 장치 내에 포함되는 컴퓨터 판독가능 기록매체나 매체에 저장되는 컴퓨터프로그램(혹은 소프트웨어)를 포 함할 수 있다. 예를 들어, 3D 스캔장치는 3방향에 위치한 카메라에서 동시에 촬영이 이루어짐으로써 왜곡없는 3 차원 스캔 데이터를 얻을 수 있다. 이는 도 2의 (b)에서 보여주고 있다. 물론 3D 스캔장치이므로 도 2의 (b)에 서와 같이 2차원의 텍스처 이미지 데이터와 흑백의 3차원 영상에 대한 3차원 데이터를 얻을 수 있는 것은 자명 하다. 또한, 본 발명의 실시예에 따른 CT 촬영장치는 CBCT(Cone Beam CT)가 사용될 수 있다. CBCT는 주로 치과에서 많 이 사용되고 있다. CBCT는 일반 병원에서 촬영하는 메디컬 CT보다 작으며 서서 촬영이 가능하고 시간도 15초 ~ 30초 정도로 메디컬 CT보다 소요 시간이 짧다. 물론, 엑스레이(X-ray) 신호를 받아들이는 센서 즉 검출기를 통 해 단층촬영이 이루어진다. 엑스레이를 조사하면 얼굴 내의 다양한 조직이나 기관 등에 의해 반사되는 신호를 검출기를 통해 센싱하여 이를 깊이 정보로 활용함으로써 3차원 데이터 생성이 가능하게 된다. 이와 같이 치과에 서 사용하는 CBCT는 구강이나 두부(머리)를 시각적으로 보기 위해 활용된다. CT 촬영 중에 또는 별도의 카메라등을 통해 환자의 얼굴 중앙 부분의 캡쳐 이미지를 취득하게 되는데 이는 SCOUT 영상(혹은 이미지)이라고 명명 될 수 있다. 환자의 본 검사에 앞서 병변의 위치나 관심 부위를 찾기 위해 촬영이 이루어지며 이때 검사 범위를 정하기 위한 기준을 설정하기 위해 SCOUT 영상이 사용된다. 다시 말해, SCOUT 영상은 직접적인 검사에 앞서 환 자의 병 등의 유무를 확인하여 촬영 부위를 지정하기 위해 촬영하는 영상으로 예를 들어 촬영기사가 SCOUT 영상 을 보고 촬영할 부위를 지정하면 지정된 범위 내에서 일정한 두께로 영상이 연속 쵤영된다. 그러므로 촬영된 슬 라이스 영상(slice image)의 위치를 파악하여 SCOUT 영상에 라인을 생성한 뒤 SCOUT 영상과 슬라이스 영상을 연 동시키면 CT 등의 영상을 조회하다가 영상의 위치를 확인할 수 있고, 생성된 라인을 클릭할 경우 해당 슬라이스 영상을 출력시켜 원하는 영상에 빠르게 접근할 수 있는 기능을 부여할 수 있다. CT 등의 영상은 환자의 상태나 필요에 따라 한번에 적게는 수십, 많게는 수백장을 찍게 된다. 일반적으로 의사 들은 연속 촬영된 슬라이스 영상을 보고 환자의 상태를 진단하게 되는데 수십장이나 되는 영상 중에서 이상부위 나 필요한 부분을 찾아내려면 시간이 많이 걸린다. 따라서 SCOUT 영상에 라인을 생성하여 라인을 직접 클릭하게 되면 해당 부위의 슬라이스 영상을 바로 출력시켜 주어 빠른 시간 내에 원하는 부위의 영상을 볼 수 있다. SCOUT 라인을 생성할 때 가장 중요한 점은 생성될 라인의 위치에 찍혀진 슬라이스 영상의 위치가 정확히 일치해 야 한다는 점이다. 따라서 SCOUT 이미지와 각각의 슬라이스 영상 사이의 연관성을 구분하여 정확한 위치에 SCOUT 라인을 생성해 주어야 한다. 본 발명의 실시예에 따른 AI 기반 3D 얼굴스캔 자동매칭장치는 R2 STUDIO Q 촬영을 수행할 수 있으며, 이 때 발생되는 데이터는 CBCT 영상, 도 2의 (a)에서와 같은 SCOUT 영상, 도 2의 (b)에서와 같은 얼굴 스캔 영상이 3가지 데이터로 구성될 수 있다. 여기서, \"R2 STUDIO Q 촬영\"이란 본 발명의 실시예에 따른 동작을 수행하기 위 하여 별도로 제작되어 사용되는 장치 즉 AI 기반 3D 얼굴스캔 자동매칭장치에 의해 이루어지는 촬영을 의 미한다고 볼 수 있다. SCOUT 영상이나 3D 얼굴 영상은 3차원 데이터로 도 2에서 볼 수 있는 바와 같이 텍스처 (Texture) 이미지 파일(bmp, png, jpg 등), 3차원 영상 파일(.obj), 설정 파일(.mtl)을 포함할 수 있다. 텍스처(혹은 텍스쳐) 이미지 파일은 환자의 스캔에 의해 얻을 수 있는 파일이며, 색 즉 컬러 정보를 갖는 파일 이다. 얼굴 겉 표면인 스킨(skin) 데이터라고 볼 수 있다. 텍스처 이미지 파일은 OBJ 파일에 사용될 이미지로써 3차원 영상과 결합하여 사용된다. 또한 3차원 영상 파일은 흰색 즉 흑백으로 이루어지는 데이터를 의미한다. 3 차원 영상 파일은 OBJ 파일 포맷으로 사용하며, 3차원으로 표현하기 위한 좌표(값)와 얼굴 표면에 색상 혹은 컬 러를 지정할 수 있는 데이터로 구성된다. 이러한 3차원 영상은 V와 VT 인자를 포함할 수 있다. V는 3차원 좌표 (X, Y, Z)의 좌표값이 기록되어 있으며, 3개씩 묶어서 표면을 생성한다. 이로 인해 3개의 좌표는 폴리곤 (polygon) 구조를 갖는다. 즉 3개의 좌표에 의해 형성되는 폴리곤 구조가 되는 것이다. VT는 3차원 영상의 표면 즉 얼굴피부 표면에 할당될 색상에 대한 텍스처 이미지 좌표를 기록한다. 예를 들어, 텍스처 이미지 파일 색상 을 획득하여 표면에 색상을 적용한다. MTL 파일은 3차원 영상이 사용할 텍스처 이미지 파일의 시스템 경로 및 효과를 위한 설정값을 포함하고 있다. 상기의 내용을 전제로, 도 1의 통신 인터페이스부는 데이터 수신부로서 동작할 수 있다. 통신 인터페이스 부는 CBCT 촬영이나 3D 얼굴스캔 촬영을 통해 SCOUT 영상의 SCOUT 데이터와 얼굴스캔 영상의 스캔 데이터 를 각각 수신한다. 예를 들어, CBCT와 같은 단층촬영장치를 통해서는 SCOUT 이미지의 데이터를 수신할 수 있고, 3D 얼굴스캔장치를 통해서는 도 2의 (b)에서와 같은 얼굴스캔 이미지의 데이터를 수신할 수 있다. 2개의 이미지 데이터는 가령 환자의 얼굴에 대한 서로 다른 즉 이종의 특성을 갖는 데이터이다. SCOUT 데이터는 환자가 CT 촬 영을 위해 방사선 때문에 부득이하게 눈을 감고 또 입을 다물고 찍는 촬영 이미지의 데이터라면, 얼굴스캔 이미 지 데이터는 환자가 CT와 같이 방사선의 노출이 없기 때문에 일상 생활에서와 같이 웃는 모습의 얼굴 이미지에 대한 데이터이다. 제어부는 도 1의 통신 인터페이스부, AI 기반 3D 얼굴스캔 자동매칭부 및 저장부의 전반적 인 제어 동작을 담당한다. 제어부는 통신 인터페이스부를 통해 SCOUT 이미지 데이터 및 3D 얼굴스캔 이미지 데이터가 수신되면 이를 저장부에 임시 저장한 후 불러내어 AI 기반 3D 얼굴스캔 자동 매칭부(13 0)로 제공한다. 물론 제어부는 AI 기반 3D 얼굴스캔 자동 매칭부를 통해 CBCT 영상 데이터와 얼굴스캔 영상의 통합 (혹은 중첩)이 이루어지게 되면, 치과 의사의 명령에 따라 해당 통합된 데이터를 3D로 시각화하여 화면에 보여 줄 수 있다. 해당 화면은 컴퓨터의 모니터가 될 수 있으며, 별도의 디스플레이부가 될 수 있다. AI 기반 3D 얼굴스캔 자동매칭부는 가령 CT 촬영 중에 환자의 얼굴 중앙 부위를 캡쳐하여 얻은 SCOUT 영상 데이터와 얼굴스캔 영상 데이터의 자동 매칭 동작을 수행하며, 이의 과정에서 AI 프로그램을 적용함으로써 매칭동작의 정확도를 증가시킬 수 있다. 이러한 동작은 앞서 언급한 바와 같이 CT 촬영시에 환자의 방사선 노출을 방지하기 위해 눈을 감거나 입을 다물고 촬영이 이루어지지만 실제로 치과나 미용치료시에는 환자의 웃는 얼굴 을 통해 환자의 위치가 일치하도록 하기 위해서라고 볼 수 있다. 다시 말해서, AI 기반 3D 얼굴스캔 자동매칭부 는 CT 촬영 영상에서 환자가 눈을 감고 입을 다물고 촬영이 이루어지지만, 얼굴 표면에 대한 이미지 데이 터만을 얼굴스캔 이미지 데이터로 대체하려는 것이다. 다만, 이의 경우 환자의 웃을 때의 골격 구조, 치아의 위 치 등은 CT 촬영시와 다르게 되므로, 이를 얼굴스캔 이미지 데이터를 근거로 보정하여 3D 시각화가 이루어지도 록 동작한다고 볼 수 있다. 이때, 2차원의 SCOUT 영상 데이터와 얼굴스캔 영상 데이터에서 공통되게 검출되는 랜드마크의 검출점을 근거로 CT 영상 데이터를 변환해 줌으로써 이를 통해 데이터 처리의 정확도를 높일 수 있 는 것이다. 좀더 구체적으로 AI 기반 3D 얼굴스캔 자동매칭부는 2차원, 3차원 데이터를 활용하여 임상적 의미를 가지 는 n개의 3차원 좌표를 검출한다. 그리고 SCOUT 데이터와 얼굴스캔 데이터의 매칭 과정을 인공지능 즉 AI 프로 그램을 적용해 자동화한다. 예를 들어, SCOUT 영상 데이터와 얼굴스캔 영상 데이터에서 서로 다른 2개의 얼굴에 대한 특징점을 검출할 수 있다. 본 발명의 실시예에서는 가령 51개의 특징점 검출을 통해 얼굴을 인식한다. 그 리고, 그 검출된 특징점 중에서 눈을 감을 때나 웃을 때에 변함이 없는 즉 공통되는 부분에 대한 n개의 랜드마 크(landmark)를 검출한다. 랜드마크의 검출점은 4 ~ 6개, 최대 51개가 될 수 있다. 본 발명의 실시예에서는 이 의 과정에서 특징점을 검출하고, 또 랜드마크를 정확히 검출할 수 있도록 인공지능을 통해 일관된 위치에 기준 점(혹은 기준정보)을 설정한다. 기준정보는 이미지상에서 화소정보나 화소경계 정보, 또 화소정보에 의한 형상 등 다양한 정보가 사용될 수 있다. 본 발명의 실시예에서는 코의 끝이나 콧망울 끝 등의 부위가 랜드마크에 해 당한다. 따라서 기준점을 설정하게 되면 인공지능을 통해 영상분석을 수행하여 물론 학습 동작을 수행함으로써 코의 끝과 콧망울 끝 등의 부위를 정확히 마킹(marking)하는 것이 가능할 수 있다. 더 정확하게는 마킹보다는 기준정보를 근거로 해당 검출점을 인식한다는 것이 바람직할 수 있다. 이는 경우에 따라서는 검출점을 추출한다 는 것으로 표현될 수도 있을 것이다. 따라서, 동일 부위에 해당하는 SCOUT 영상 데이터의 좌표값(혹은 제1 좌표 값)과 3D 스캔영상 데이터의 좌표값(혹은 제2 좌표값)을 서로 매칭시켜 줌으로써 3D 시각화 데이터를 볼 때 웃 는 얼굴 이미지를 통해 CT 영상을 볼 수 있게 되는 것이다. 예를 들어 2개의 좌표값을 통해 변환 관계 등을 알 수 있기 때문에 웃는 얼굴의 스캔영상 데이터를 3차원의 CT 촬영 영상 데이터에 매칭 또는 중첩하더라도 변환 관계를 근거로 CT 영상 데이터를 변환하여 웃는 얼굴이 결합된 3D 시각화 데이터를 생성할 수 있는 것이다. 예를 들어, 위의 마킹(혹은 검출점 검출) 동작을 수동으로 진행한다고 가정해 보자. 자동이 아닌 수동으로 작업 이 이루어지므로 잘못될 경우 재수행 동작이 필요할 것이다. 또한, 수동 진행으로 인하여 데이터 처리에 많은 시간이 소요된다. 반면 발명의 실시예에서와 같이 인공지능을 적용하는 경우 원클릭(one click)으로 콧망울 끝 등의 10개 포인트 마킹을 완료할 수 있고, 또 일관된 위치에 마킹을 수행할 수 있게 된다. 또는 일관된 위치의 검출이 가능할 수 있다. 이를 통해 웃는 얼굴에 대한 CT 영상을 볼 수 있어 진단 정확도가 높아지게 된다. 물론 CT 영상은 깊이 정보를 가지고 있는 단층 촬영 데이터를 결합함으로써 3D 시각화가 가능하다. AI 기반 3D 얼굴 스캔 자동매칭부와 관련한 자세한 내용은 이후에 좀더 다루기로 한다. 저장부는 제어부의 제어하에 처리되는 데이터를 임시 저장한다. 제어부는 통신 인터페이스부 에서 SCOUT 이미지(혹은 영상) 데이터와 3D 얼굴스캔 데이터가 수신되는 경우 이를 저장부에 임시 저 장한 후 불러내어 AI기반 3D 얼굴스캔 자동매칭부로 제공하여 인공지능을 적용한 자동 매칭 동작이 이루어 지도록 한다. 상기한 내용 이외에도 도 1의 통신 인터페이스부, 제어부, AI 기반 3D 얼굴스캔 자동매칭부 및 저장부는 다양한 동작을 수행할 수 있으며, 기타 자세한 내용은 이후에 계속해서 다루기로 한다. 본 발명의 실시예에 따른 도 1의 통신 인터페이스부, 제어부, AI 기반 3D 얼굴스캔 자동매칭부 및 저장부는 서로 물리적으로 분리된 하드웨어 모듈로 구성되지만, 각 모듈은 내부에 상기의 동작을 수행 하기 위한 소프트웨어를 저장하고 이를 실행할 수 있을 것이다. 다만, 해당 소프트웨어는 소프트웨어 모듈의 집 합이고, 각 모듈은 하드웨어로 형성되는 것이 얼마든지 가능하므로 소프트웨어니 하드웨어니 하는 구성에 특별 히 한정하지 않을 것이다. 예를 들어 저장부는 하드웨어인 스토리지(storage) 또는 메모리(memory)일 수 있다. 하지만, 소프트웨어적으로 정보를 저장(repository)하는 것도 얼마든지 가능하므로 위의 내용에 특별히 한정하지는 않을 것이다. 한편, 본 발명의 다른 실시예로서 제어부는 CPU 및 메모리를 포함할 수 있으며, 원칩화하여 형성될 수 있 다. CPU는 제어회로, 연산부(ALU), 명령어해석부 및 레지스트리 등을 포함하며, 메모리는 램을 포함할 수 있다.제어회로는 제어동작을, 그리고 연산부는 2진비트 정보의 연산동작을, 그리고 명령어해석부는 인터프리터나 컴 파일러 등을 포함하여 고급언어를 기계어로, 또 기계어를 고급언어로 변환하는 동작을 수행할 수 있으며, 레지 스트리는 소프트웨어적인 데이터 저장에 관여할 수 있다. 상기의 구성에 따라, 가령 AI 기반 3D 얼굴스캔 자동 매칭장치는 동작 초기에 AI 기반 3D 얼굴스캔 자동매칭부에 저장되어 있는 프로그램을 복사하여 메모 리 즉 램(RAM)에 로딩한 후 이를 실행시킴으로써 데이터 연산 처리 속도를 빠르게 증가시킬 수 있다. 딥러닝 모 델 같은 경우 램(RAM)이 아닌 GPU 메모리에 올라가 GPU를 이용하여 수행 속도를 가속화하여 실행될 수도 있다. 도 3은 도 1의 AI 기반 3D 얼굴스캔 자동매칭부의 세부 구조를 예시한 블록 다이어그램, 도 4는 수동 방식과 인 공지능을 적용한 자동 방식으로 검출점에 마킹(혹은 검출)을 수행할 때를 비교 설명하기 위한 도면, 도 5는 도 3의 얼굴 및 랜드마크 검출부의 세부 동작을 설명하기 위한 도면, 도 6은 도 5의 S500 단계 내지 S520를 설명하 기 위한 도면, 도 7은 도 5의 S540 단계를 설명하기 위한 도면, 그리고 도 8은 도 3의 3D 포인트 검출부의 세부 동작을 설명하기 위한 도면, 도 9는 도 8의 S800 단계 내지 S850 단계를 설명하기 위한 도면이다. 도 3에 도시된 바와 같이, 본 발명의 실시예에 따른 도 1의 AI 기반 3D 얼굴스캔 자동매칭부는 데이터 수 신부, AI 기반 (검출점) 마킹부, 검출점(point) 매칭부 및 3D 시각화부의 일부 또는 전부를 포 함할 수 있다. 여기서, \"일부 또는 전부를 포함한다\"는 것은 데이터 수신부나 3D 시각화부와 같은 일부 구성요소가 생략 되어 AI 기반 3D 얼굴스캔 자동매칭부가 구성되거나, 검출점 매칭부와 같은 일부 구성요소가 AI 기반 검출점 마킹부와 통합되어 구성될 수 있는 것 등을 의미하는 것으로서, 발명의 충분한 이해를 돕기 위하여 전부 포함하는 것으로 설명한다. 데이터 수신부는 CBCT 촬영장치로부터 SCOUT 이미지 데이터를 수신할 수 있으며, 얼굴스캔장치로부터 얼굴 스캔 이미지 데이터를 수신할 수 있다. 물론 이외에도 데이터 수신부는 3D 시각화를 위하여 다시 말해 시 각화 데이터 생성을 위하여 3차원의 CT 영상 데이터를 더 수신할 수 있다. 본 발명의 실시예에서는 2차원의 얼 굴스캔 이미지 데이터를 3차원의 CT 영상 데이터에 매칭시킴으로써 이를 통해 환자의 웃는 얼굴에 대한 CT 영상 을 볼 수 있어 정확한 진단이 이루어지도록 하기 위해서이다. AI 기반 검출점 마킹부는 도 3에서 볼 수 있는 바와 같이 데이터 입력부, 얼굴 및 랜드마크 검출부 , 3D 검출점(혹은 특징점) 검출부 및 결과 출력부의 일부 또는 전부를 포함한다. 여기서, \"일부 또는 전부를 포함한다\"는 것은 앞서서의 의미와 크게 다르지 않다. 데이터 입력부, 얼굴 및 랜드마크 검출 부, 3D 검출점 검출부 및 결과 출력부는 하드웨어나 소프트웨어 또는 그 조합에 의해 구성될 수 있으며, 본 발명의 실시예에서는 SW에 의한 구성이 바람직할 수 있지만, 어느 하나의 형태에 특별히 한정하지는 않을 것이다. 얼굴 및 랜드마크 검출부는 도 4 내지 도 7에서 볼 수 있는 바와 같이 인공지능을 통해 SCOUT 데이터와 얼 굴스캔 데이터의 매칭을 자동화할 수 있다. 다시 말해, 사람의 얼굴에는 대략 27개의 검출점 혹은 특징점이 존 재할 수 있다. 이때, 본 발명의 실시예에서는 눈을 깜빡일 때에도 움직이지 않는 점 즉 얼굴에서 위치가 변경되 지 않는 점을 랜드마크로서 이용하게 되며, 도 5 내지 도 7은 이의 과정을 보여주고 있다. 다시 말해 얼굴 및 랜드마크 검출부는 도 5의 S520 단계를 수행하기 위하여 얼굴 영역 검출 동작을 수행한다. 도 6은 텍스처 영상에서 자동 매칭을 위한 특징점 검출 모습을 보여주고 있다. 입력된 정답 영역 즉 기준정보와 인공지능 프로 그램(혹은 알고리즘)이 예측한 영역의 중첩(overlap) 정도가 50% 이상인 경우 사용할 수 있다. 도 6에서와 같은 과정을 반복하여 인공지능이 얼굴 영역을 제안한다. 즉 얼굴 인식을 위하여 본 발명의 실시예에서는 입력된 SCOUT 이미지 데이터에 대하여 복수의 영역을 설정하여 또는 설정된 영역을 변경해 가면서 특징점을 검출할 수 있고, 이를 인공지능을 통해 학습함으로써 검출된 특징점을 통해 얼굴 영역을 정확히 인식할 수 있다. 이어 얼굴 및 랜드마크 검출부는 도 5의 S540 단계의 동작을 수행할 수 있다. 다시 말해, 얼굴 영역이 인 식되면 해당 얼굴 영역에서 가령 웃을 때와 눈을 깜빡일 때에도 움직이지 않는 점 즉 랜드마크를 검출한다. 도 7은 랜드마크 검출 AI를 설명하기 위한 도면이다. 본 발명의 실시예에서는 얼굴에서 검출 가능한 51개의 특징점 중에서 랜드마크로서 사용될 수 있는 특징점을 4개 ~ 6개로 한정하여 사용할 수 있다. 도 7에서 볼 수 있는 바 와 같이 눈의 안쪽 꼬리 2곳, 그리고 콧망울 끝, 그리고 미간의 정중앙 부위가 사용될 수 있다. 따라서, 6개의 점에 대한 형상을 판단 혹은 학습함으로써 랜드마크의 검출 정확도를 높일 수 있다. 이를 통해 얼굴 및 랜드마 크 검출부는 SCOUT 이미지 데이터와 얼굴스캔 이미지 데이터에서 6개의 랜드마크 2차원 좌표를 출력할 수 있다. 즉 얼굴 및 랜드마크 검출부에서는 SCOUT 이미지가 환자의 실제 얼굴 비율과 동일하므로 이를 이용 해 얼굴스캔 이미지 데이터에서 랜드마크를 검출한다고 볼 수 있다.또한, 도 3의 3D 검출점 검출부는 랜드마크의 2D 좌표를 3D 좌표로 환산 즉 변환하기 위한 동작을 수행한 다. 도 8 및 도 9는 도 3의 3D 검출점 검출부에서 이루어지는 구체적인 동작 흐름 및 모습을 각각 보여주 고 있다. 3D 검출점 검출부는 n개 가령 6개의 랜드마크 좌표를 얼굴스캔 이미지 데이터를 UV 맵 좌표로 변 환된 데이터에 근거하여 3D 좌표로 변환한다. 이를 위하여 3D 검출점 검출부는 V 즉 3차원 좌표로 이루어 지는 모양 또는 형태를 계산하거나 VT 즉 텍스처 이미지에서의 위치에 대한 컬러정보를 확인해 볼 수 있다. 더 정확하게는 얼굴스캔 이미지 데이터를 UV 맵 좌표로 변환한 후 변환한 얼굴스캔 이미지 데이터와 3D 얼굴스캔 영상 데이터는 좌표값을 포함하고 있으므로, 이를 통해 랜드마크의 2차원 좌표에 대한 3차원 좌표로의 변환이 이루어지게 된다. 이러한 과정은 도 9에서 잘 보여주고 있다. 물론 3차원 좌표로의 변환 과정에서도 다양한 동작이 더 수행될 수 있다. 예를 들어 V를 계산하는 과정에서 OBJ 의 꼭지점(Vertices)과 텍스쳐 좌표값의 개수가 동일하지 않은 경우에는 부적절한 3D 좌표로 판단하여 경고 (warning)로 인식할 수 있다. 이의 경우에는 해당 좌표값을 무시하고 좌표값 계산을 위한 동작을 재수행할 수도 있다. UV 맵 좌표는 2차원의 얼굴스캔 이미지 데이터를 별도의 알고리즘 등을 이용해 3차원 이미지 데이터로 변 환한 후 이를 통해 얻을 수 있는 맵 좌표라 볼 수 있다. 다시 말해 UV 맵핑은 2차원 이미지를 3차원 모델로 만 드는 3차원 모델링 프로세스로 가령 가장 단순한 UV 매핑은 3개의 단계로 이루어질 수 있다. 메시(mesh) 해체, 텍스처 만들기, 텍스처 적용 단계이다. 이를 통해 가령 도 9에서 볼 수 있는 바와 같이 3D 얼굴스캔 데이터에 2 차원의 얼굴스캔 이미지 데이터를 변환한 UV 맵 데이터를 중첩할 수 있어 랜드마크 2차원 좌표값에 대한 3차원 좌표값을 추출하는 것이 가능할 수 있다. 상기한 바와 같이 3D 검출점 검출부는 UV 맵을 통해 n개의 랜드마크 좌표를 3차원으로 변환하고, 그 변환 된 3차원 좌표에 대하여 V와 VT를 각각 계산하여 이상이 없다고 판단될 때 가령 OBJ의 꼭지점과 텍스쳐 좌표값 의 개수가 동일할 때에 3D 랜드마크 좌표로 변환하게 되며, 가령 OBJ의 꼭지점과 텍스쳐 좌표값의 개수가 동일 하지 않은 경우에는 부적절한 3D 좌표로 판단하여 별도의 변환 동작이 미수행될 수도 있다. 도 9는 3D 검출점 검출부를 통해 좌표 변환이 이루어지는 과정을 잘 보여주고 있다. 검출점 매칭부는 3차원 좌표값으로 변환한 랜드마크의 검출점을 기준으로 얼굴스캔 이미지 데이터를 3차원 의 CT 촬영영상과 매칭(또는 중첩)시키고 이를 통해 환자의 웃는 얼굴에 대한 CT 영상을 볼 수 있도록 한다. 이 를 통해 얼굴스캔 이미지 데이터를 3차원의 CT 촬영영상에 매칭시킴으로써 환자가 웃을 때 골격 구조나 치아의 노출 정도 등이 변경됨으로써 이를 통해 정밀 진단이 이루어질 수 있다. 결론적으로, SCOUT 이미지는 환자의 얼굴 실제 비율이지만, 치과나 미용치료시에는 환자의 웃는 얼굴일 때의 잇 몸 형상을 정확히 파악하고 또 이때 보철물 및 보형물이 어떠한 영향을 미치는지에 더 관심이 있을 수 있다. 이 를 위해서는 SCOUT 이미지 데이터를 기준으로 3D 얼굴스캔 이미지 데이터에서 랜드마크 즉 눈을 깜빡이는 경우 에도 움직이지 않는 검출점을 찾고, 그 검출점을 근거로 얼굴스캔 이미지를 CT 촬영 영상에 매칭시킴으로써 웃 는 얼굴에 대한 CT 영상을 3D로 시각화하여 볼 수 있게 되는 것이다. 이의 과정에서 얼굴스캔 이미지 데이터에 서 검출되는 랜드마크의 검출점에 대한 좌표값은 2차원이므로, 해당 좌표를 3차원으로 변환하여 변환된 3차원 좌표값을 통해 CT 영상과 매칭시켜 3D 시각화가 가능하게 된다. 이의 과정에서 본 발명의 실시예는 얼굴을 인식하고, 또 얼굴에서 검출되는 특징점들을 통해 랜드마크의 검출점 을 검출하기 위해 인공지능을 적용함으로써 인공지능을 통해 얼굴에서 정확한 위치의 랜드마크 검출점이 검출되 며, 이를 통해 일관된 위치의 검출 또는 마킹이 이루어짐으로써 매칭의 정확도를 높일 수 있다. 아울러, 매칭이 나 검출의 경우에는 얼굴스캔 이미지를 UV 맵으로 변환하여 이를 근거로 2차원의 랜드마크 검출점에 대한 3차원 좌표값을 얻게 되며, 3차원 좌표값으로의 변환 여부를 결정하는 과정에서 좌표값으로 이루어지는 형상을 판단하 거나 색상정보를 확인함으로써 확인 혹은 판단 결과를 근거로 2차원 랜드마크 검출점의 좌표값에 대한 3차원 좌 표값의 변환을 최종 결정하게 되는 것이다. 이러한 과정을 통해 3차원 좌표로의 변환이 이루어지게 되면 얼굴스캔 데이터를 CT 촬영영상 데이터에 매칭시킴 으로써 웃는 얼굴을 통한 CT 촬영영상의 3D 시각화가 이루어지게 된다. 랜드마크의 검출점에 대한 정확한 마킹 이나 검출이 이루어져야 그에 대한 정확한 좌표값이 검출될 수 있기 때문에 해당 검출 동작은 인공지능을 통해 또는 학습을 통해 관심 영역의 특징 가령 기준 정보로서 화소 정보 등을 분석함으로써 이를 통해 정확한 위치에 랜드마크의 검출점에 대한 마킹이나 검출이 가능하게 된다. 인공지능을 통해서는 기준점 혹은 기준값을 근거로 그에 해당하는 정확한 검출이 이루어지게 된다. 예를 들어 기준점으로서 눈의 안쪽 꼬리의 경우 지정된 화소 특 성을 가질 수 있으므로 이에 대한 정보를 사전에 설정해 줄 수 있고, 인공지능은 화소 분석의 결과와 기설정된 정보를 대비함으로써 정확한 위치를 검출할 수 있다.도 10은 도 1의 AI 기반 3D 얼굴스캔 자동매칭장치 (및 소프트웨어)의 구동과정을 나타내는 흐름도이다. 설명의 편의상 도 10을 도 1과 함께 참조하면, 본 발명의 실시예에 따른 도 1의 AI 기반 3D 얼굴스캔 자동매칭 장치는 사용자의 얼굴을 컴퓨터 단층촬영시 얼굴 중앙 부위를 캡쳐하여 얻은 제1 이미지 데이터 및 사용자 의 얼굴을 3D 스캔 방식으로 촬영하여 얻은 제2 이미지 데이터를 수신한다(S1000). 여기서, 제1 이미지 데이터 는 도 2의 (a)에서와 같이 CT 촬영시 얼굴 중앙부분의 캡쳐 이미지인 SCOUT 이미지 데이터라고 볼 수 있으며, 제2 이미지 데이터는 도 2의 (b)에서와 같은 얼굴 스캔 영상의 이미지 데이터일 수 있다. 물론 이의 과정에서 CT 촬영영상에 대한 3차원 영상 데이터와 얼굴스캔에 대한 3차원 영상 데이터를 수신하거나 생성할 수도 있다. 또한, AI 기반 3D 얼굴스캔 자동매칭장치는 인공지능(AI)을 적용해 제1 이미지 데이터와 제2 이미지 데이 터를 분석하여 공통되게 검출되는 랜드마크의 검출점을 찾고 혹은 검출하고, 제2 이미지 데이터상에서 찾은 검 출점에 대한 2차원 좌표값을 3차원 좌표값으로 변환하여 변환한 3차원 좌표값을 근거로 제2 이미지 데이터를 CT 촬영영상 데이터에 자동 매칭시켜 사용자의 얼굴을 3D로 시각화한다(S1010) 좀더 정확히 말해서, AI 기반 3D 얼굴스캔 자동매칭장치는 인공지능 프로그램을 실행하여 기설정된 기준점 또는 기준정보를 근거로 SCOUT 이미지 데이터의 검출점 즉 랜드마크의 검출점과 얼굴스캔 이미지 데이터에서의 랜드마크의 검출점에 대한 정확한 검출을 수행할 수 있다. 그리고 그 랜드마크의 검출점을 근거로 추출되는 좌 표값을 근거로 얼굴스캔 이미지 데이터를 이용하여(예: UV 맵 데이터로 변환함) 또는 얼굴스캔 영상의 3차원 데 이터를 이용하여 3차원 좌표로 변환하여 이를 근거로 얼굴스캔 이미지 데이터를 3차원의 CT 촬영 데이터에 매칭 시켜 환자의 웃는 얼굴에 대한 CT 촬영영상을 볼 수 있도록 한다. 물론 이는 3D 시각화를 통해 가능할 수 있다. 상기한 내용 이외에도 도 1의 AI 기반 3D 얼굴스캔 자동매칭장치는 다양한 동작을 수행할 수 있으며, 기타 자세한 내용은 앞서 충분히 설명하였으므로 그 내용들로 대신하고자 한다. 이상에서는 바람직한 실시예에 대하여 도시하고 설명하였지만, 본 발명은 상술한 특정의 실시예에 한정되지 아"}
{"patent_id": "10-2022-0062951", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "니하며, 청구범위에서 청구하는 본 발명의 요지를 벗어남이 없이 당해 발명이 속하는 기술분야에서 통상의 지식 을 가진 자에 의해 다양한 변형실시가 가능한 것은 물론이고, 이러한 변형실시들은 본 발명의 기술적 사상이나 전망으로부터 개별적으로 이해되어져서는 안될 것이다. 한편, 본 발명의 실시 예를 구성하는 모든 구성 요소들이 하나로 결합하거나 결합하여 동작하는 것으로 설명되 었다고 해서, 본 발명이 반드시 이러한 실시 예에 한정되는 것은 아니다. 즉, 본 발명의 목적 범위 안에서라면, 그 모든 구성 요소들이 하나 이상으로 선택적으로 결합하여 동작할 수도 있다. 또한, 그 모든 구성요소들이 각 각 하나의 독립적인 하드웨어로 구현될 수 있지만, 각 구성 요소들의 그 일부 또는 전부가 선택적으로 조합되어 하나 또는 복수 개의 하드웨어에서 조합된 일부 또는 전부의 기능을 수행하는 프로그램 모듈을 갖는 컴퓨터 프 로그램으로서 구현될 수도 있다. 그 컴퓨터 프로그램을 구성하는 코드들 및 코드 세그먼트들은 본 발명의 기술 분야의 당업자에 의해 용이하게 추론될 수 있을 것이다. 이러한 컴퓨터 프로그램은 컴퓨터가 읽을 수 있는 비일 시적 저장매체(non-transitory computer readable media)에 저장되어 컴퓨터에 의하여 읽혀지고 실행됨으로써, 본 발명의 실시 예를 구현할 수 있다. 여기서 비일시적 판독 가능 기록매체란, 레지스터, 캐시(cache), 메모리 등과 같이 짧은 순간 동안 데이터를 저 장하는 매체가 아니라, 반영구적으로 데이터를 저장하며, 기기에 의해 판독(reading)이 가능한 매체를 의미한다. 구체적으로, 상술한 프로그램들은 CD, DVD, 하드 디스크, 블루레이 디스크, USB, 메모리 카드, ROM 등과 같은 비일시적 판독가능 기록매체에 저장되어 제공될 수 있다. 이상에서는 본 발명의 바람직한 실시 예에 대하여 도시하고 설명하였지만, 본 발명은 상술한 특정의 실시 예에"}
{"patent_id": "10-2022-0062951", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "한정되지 아니하며, 청구범위에 청구하는 본 발명의 요지를 벗어남이 없이 당해 발명이 속하는 기술분야에서 통 상의 지식을 가진 자에 의해 다양한 변형실시가 가능한 것은 물론이고, 이러한 변형실시들은 본 발명의 기술적 사상이나 전망으로부터 개별적으로 이해되어서는 안 될 것이다."}
{"patent_id": "10-2022-0062951", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 실시예에 따른 AI 기반 3D 얼굴스캔 자동매칭장치의 세부 구조를 예시한 블록다이어그램이다. 도 2는 SCOUT 영상과 얼굴 스캔(Face Scan) 영상의 데이터 구성을 설명하기 위한 도면이다. 도 3은 도 1의 AI 기반 3D 얼굴스캔 자동매칭부의 세부구조를 예시한 블록 다이어그램이다. 도 4는 수동 방식과 인공지능을 적용한 자동 방식으로 검출점에 마킹(혹은 검출)을 수행할 때를 비교 설명하기 위한 도면이다. 도 5는 도 3의 얼굴 및 랜드마크 검출부의 세부동작을 설명하기 위한 도면이다. 도 6은 도 5의 S500 단계 내지 S520를 설명하기 위한 도면이다. 도 7은 도 5의 S540 단계를 설명하기 위한 도면이다. 도 8은 도 3의 3D 포인트 검출부의 세부동작을 설명하기 위한 도면이다. 도 9는 도 8의 S800 단계 내지 S840 단계를 설명하기 위한 도면이다. 도 10은 도 1의 AI 기반 3D 얼굴스캔 자동매칭장치의 구동과정을 나타내는 흐름도이다."}
