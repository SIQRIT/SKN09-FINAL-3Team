{"patent_id": "10-2022-0035448", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0137686", "출원번호": "10-2022-0035448", "발명의 명칭": "뉴럴 네트워크의 추론 단계에서의 미분 계산 방법 및 장치", "출원인": "삼성전자주식회사", "발명자": "김건희"}}
{"patent_id": "10-2022-0035448", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "복수의 레이어들로 구성된 뉴럴 네트워크의 추론(inference) 방법에 있어서,상기 뉴럴 네트워크의 입력 데이터를 수신하는 단계;상기 복수의 레이어들 각각에 있어서, 해당 레이어의 출력 액티베이션의 상기 입력 데이터에 대한 미분 데이터를 획득하는 단계; 및상기 해당 레이어의 출력 액티베이션의 상기 입력 데이터에 대한 미분 데이터에 기초하여, 상기 뉴럴 네트워크의 출력 데이터의 입력 데이터에 대한 미분 데이터를 획득하는 단계를 포함하는 추론 방법."}
{"patent_id": "10-2022-0035448", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 미분 데이터를 획득하는 단계는상기 복수의 레이어들 각각에 있어서, 상기 해당 레이어의 상기 입력 데이터에 대한 자코비언 행렬(jacobianmatrix)을 계산하는 단계를 포함하는, 추론 방법."}
{"patent_id": "10-2022-0035448", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 미분 데이터를 획득하는 단계는상기 복수의 레이어들 각각에 대하여 순전파(forward propagation)를 수행함으로써, 상기 해당 레이어의 상기입력 데이터에 대한 자코비언 행렬을 계산하는 단계를 포함하는, 추론 방법."}
{"patent_id": "10-2022-0035448", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,상기 미분 데이터를 획득하는 단계는상기 복수의 레이어들 각각에 대한 역전파(back propagation) 수행 없이, 상기 해당 레이어의 상기 입력 데이터에 대한 자코비언 행렬을 계산하는 단계를 포함하는, 추론 방법."}
{"patent_id": "10-2022-0035448", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서,상기 복수의 레이어들 각각에 대하여 순전파를 수행함으로써, 해당 레이어의 출력 액티베이션을 획득하는 단계;공개특허 10-2023-0137686-3-및상기 해당 레이어의 출력 액티베이션에 기초하여, 상기 뉴럴 네트워크의 출력 데이터를 획득하는 단계를 더 포함하는, 추론 방법."}
{"patent_id": "10-2022-0035448", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서,복수의 원소들을 포함하는 상기 입력 데이터에 있어서, 상기 복수의 원소들 중 미분값이 필요한 하나 이상의 원소로 구성된 미분 입력 데이터를 획득하는 단계를 더 포함하는 추론 방법."}
{"patent_id": "10-2022-0035448", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6항에 있어서,상기 미분 데이터를 획득하는 단계는상기 복수의 레이어들 각각에 있어서, 상기 해당 레이어의 상기 미분 입력 데이터에 대한 자코비언 행렬을 계산하는 단계를 포함하는, 추론 방법."}
{"patent_id": "10-2022-0035448", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서,상기 미분 입력 데이터의 원소 수 및 상기 복수의 레이어들의 상기 미분 입력 데이터에 대한 자코비언 행렬의차원 중 최대값에 기초하여 상기 뉴럴 네트워크의 추론에 필요한 메모리 크기가 결정되는, 추론 방법."}
{"patent_id": "10-2022-0035448", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "하드웨어와 결합되어 제1항 내지 제8항 중 어느 하나의 항의 방법을 실행시키기 위하여 매체에 저장된 컴퓨터프로그램."}
{"patent_id": "10-2022-0035448", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "복수의 레이어들로 구성된 뉴럴 네트워크의 추론(inference) 장치에 있어서,상기 뉴럴 네트워크의 입력 데이터를 수신하고, 상기 복수의 레이어들 각각에 있어서, 해당 레이어의 출력 액티베이션의 상기 입력 데이터에 대한 미분 데이터를 획득하고, 상기 해당 레이어의 출력 액티베이션의 상기 입력데이터에 대한 미분 데이터에 기초하여, 상기 뉴럴 네트워크의 출력 데이터의 입력 데이터에 대한 미분 데이터를 획득하는 프로세서를 포함하는 추론 장치."}
{"patent_id": "10-2022-0035448", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제10항에 있어서,상기 프로세서는공개특허 10-2023-0137686-4-상기 복수의 레이어들 각각에 있어서, 상기 해당 레이어의 상기 입력 데이터에 대한 자코비언 행렬(jacobianmatrix)을 계산하는, 추론 장치."}
{"patent_id": "10-2022-0035448", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제10항에 있어서,상기 프로세서는상기 복수의 레이어들 각각에 대하여 순전파(forward propagation)를 수행함으로써, 상기 해당 레이어의 상기입력 데이터에 대한 자코비언 행렬을 계산하는, 추론 장치."}
{"patent_id": "10-2022-0035448", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제10항에 있어서,상기 프로세서는상기 복수의 레이어들 각각에 대한 역전파(back propagation) 수행 없이, 상기 해당 레이어의 상기 입력 데이터에 대한 자코비언 행렬을 계산하는, 추론 장치."}
{"patent_id": "10-2022-0035448", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제10항에 있어서,상기 프로세서는상기 복수의 레이어들 각각에 대하여 순전파를 수행함으로써, 해당 레이어의 출력 액티베이션을 획득하고, 상기해당 레이어의 출력 액티베이션에 기초하여, 상기 뉴럴 네트워크의 출력 데이터를 획득하는, 추론 장치."}
{"patent_id": "10-2022-0035448", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제10항에 있어서,상기 프로세서는복수의 원소들을 포함하는 상기 입력 데이터에 있어서, 상기 복수의 원소들 중 미분값이 필요한 하나 이상의 원소로 구성된 미분 입력 데이터를 획득하는, 추론 장치."}
{"patent_id": "10-2022-0035448", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제15항에 있어서,상기 프로세서는상기 복수의 레이어들 각각에 있어서, 상기 해당 레이어의 상기 미분 입력 데이터에 대한 자코비언 행렬을 계산하는, 추론 장치."}
{"patent_id": "10-2022-0035448", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제16항에 있어서,상기 미분 입력 데이터의 원소 수 및 상기 복수의 레이어들의 상기 미분 입력 데이터에 대한 자코비언 행렬의공개특허 10-2023-0137686-5-차원 중 최대값에 기초하여 상기 뉴럴 네트워크의 추론에 필요한 메모리 크기가 결정되는, 추론 장치."}
{"patent_id": "10-2022-0035448", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "뉴럴 네트워크의 추론 단계에서의 미분 계산 방법 및 장치가 개시된다. 일 실시예에 따른 복수의 레이어들로 구 성된 뉴럴 네트워크의 추론(inference) 방법은 뉴럴 네트워크의 입력 데이터를 수신하는 단계; 복수의 레이어들 각각에 있어서, 해당 레이어의 출력 액티베이션의 입력 데이터에 대한 미분 데이터를 획득하는 단계; 및 해당 레 이어의 출력 액티베이션의 입력 데이터에 대한 미분 데이터에 기초하여, 뉴럴 네트워크의 출력 데이터의 입력 데 이터에 대한 미분 데이터를 획득하는 단계를 포함한다."}
{"patent_id": "10-2022-0035448", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "아래 실시예들은 뉴럴 네트워크의 추론 단계에서의 미분 계산 방법 및 장치에 관한 것이다."}
{"patent_id": "10-2022-0035448", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "인공지능(Artificial Intelligence, AI) 시스템은 인간 수준의 지능을 구현하는 컴퓨터 시스템이며, 기존 Rule 기반 스마트 시스템과 달리 기계가 스스로 학습하고 판단하며 똑똑해지는 시스템이다. 인공지능 시스템은 사용 할수록 인식률이 향상되고 사용자 취향을 보다 정확하게 이해할 수 있게 되어, 기존 Rule 기반 스마트 시스템은 점차 딥러닝 기반 인공지능 시스템으로 대체되고 있다. 인공지능 기술은 기계학습(딥러닝) 및 기계학습을 활용한 요소 기술들로 구성된다. 기계학습은 입력 데이터들의 특징을 스스로 분류/학습하는 알고리즘 기술이며, 요소기술은 딥러닝 등의 기계학 습 알고리즘을 활용하여 인간 두뇌의 인지, 판단 등의 기능을 모사하는 기술로서, 언어적 이해, 시각적 이해, 추론/예측, 지식 표현, 동작 제어 등의 기술 분야로 구성된다. 인공지능 기술이 응용되는 다양한 분야는 다음과 같다. 언어적 이해는 인간의 언어/문자를 인식하고 응용/처리 하는 기술로서, 자연어 처리, 기계 번역, 대화시스템, 질의 응답, 음성 인식/합성 등을 포함한다. 시각적 이해 는 사물을 인간의 시각처럼 인식하여 처리하는 기술로서, 객체 인식, 객체 추적, 영상 검색, 사람 인식, 장면 이해, 공간 이해, 영상 개선 등을 포함한다. 추론 예측은 정보를 판단하여 논리적으로 추론하고 예측하는 기술 로서, 지식/확률 기반 추론, 최적화 예측, 선호 기반 계획, 추천 등을 포함한다. 지식 표현은 인간의 경험정보 를 지식데이터로 자동화 처리하는 기술로서, 지식 구축(데이터 생성/분류), 지식 관리(데이터 활용) 등을 포함 한다. 동작 제어는 차량의 자율 주행, 로봇의 움직임을 제어하는 기술로서, 움직임 제어(항법, 충돌, 주행), 조작 제어(행동 제어) 등을 포함한다."}
{"patent_id": "10-2022-0035448", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "일 실시예에 따른 복수의 레이어들로 구성된 뉴럴 네트워크의 추론(inference) 방법은 상기 뉴럴 네트워크의 입 력 데이터를 수신하는 단계; 상기 복수의 레이어들 각각에 있어서, 해당 레이어의 출력 액티베이션의 상기 입력 데이터에 대한 미분 데이터를 획득하는 단계; 및 상기 해당 레이어의 출력 액티베이션의 상기 입력 데이터에 대 한 미분 데이터에 기초하여, 상기 뉴럴 네트워크의 출력 데이터의 입력 데이터에 대한 미분 데이터를 획득하는 단계를 포함한다. 상기 미분 데이터를 획득하는 단계는 상기 복수의 레이어들 각각에 있어서, 상기 해당 레이어의 상기 입력 데이 터에 대한 자코비언 행렬(jacobian matrix)을 계산하는 단계를 포함할 수 있다. 상기 미분 데이터를 획득하는 단계는 상기 복수의 레이어들 각각에 대하여 순전파(forward propagation)를 수행 함으로써, 상기 해당 레이어의 상기 입력 데이터에 대한 자코비언 행렬을 계산하는 단계를 포함할 수 있다. 상기 미분 데이터를 획득하는 단계는 상기 복수의 레이어들 각각에 대한 역전파(back propagation) 수행 없이, 상기 해당 레이어의 상기 입력 데이터에 대한 자코비언 행렬을 계산하는 단계를 포함할 수 있다. 일 실시예에 따른 추론 방법은 상기 복수의 레이어들 각각에 대하여 상기 순전파를 수행함으로써, 해당 레이어 의 출력 액티베이션을 획득하는 단계; 및 상기 해당 레이어의 출력 액티베이션에 기초하여, 상기 뉴럴 네트워크 의 출력 데이터를 획득하는 단계를 더 포함할 수 있다. 일 실시예에 따른 추론 방법은 복수의 원소들을 포함하는 상기 입력 데이터에 있어서, 상기 복수의 원소들 중 미분값이 필요한 하나 이상의 원소로 구성된 미분 입력 데이터를 획득하는 단계를 더 포함할 수 있다.상기 미분 데이터를 획득하는 단계는 상기 복수의 레이어들 각각에 있어서, 상기 해당 레이어의 상기 미분 입력 데이터에 대한 자코비언 행렬을 계산하는 단계를 포함할 수 있다. 상기 미분 입력 데이터의 원소 수 및 상기 복수의 레이어들의 상기 미분 입력 데이터에 대한 자코비언 행렬의 차원 중 최대값에 기초하여 상기 뉴럴 네트워크의 추론에 필요한 메모리 크기가 결정될 수 있다. 일 실시예에 따른 복수의 레이어들로 구성된 뉴럴 네트워크의 추론(inference) 장치는 상기 뉴럴 네트워크의 입 력 데이터를 수신하고, 상기 복수의 레이어들 각각에 있어서, 해당 레이어의 출력 액티베이션의 상기 입력 데이 터에 대한 미분 데이터를 획득하고, 상기 해당 레이어의 출력 액티베이션의 상기 입력 데이터에 대한 미분 데이 터에 기초하여, 상기 뉴럴 네트워크의 출력 데이터의 입력 데이터에 대한 미분 데이터를 획득하는 프로세서를 포함한다. 상기 프로세서는 상기 복수의 레이어들 각각에 있어서, 상기 해당 레이어의 상기 입력 데이터에 대한 자코비언 행렬(jacobian matrix)을 계산할 수 있다. 상기 프로세서는 상기 복수의 레이어들 각각에 대하여 순전파(forward propagation)를 수행함으로써, 상기 해당 레이어의 상기 입력 데이터에 대한 자코비언 행렬을 계산할 수 있다. 상기 프로세서는 상기 복수의 레이어들 각각에 대한 역전파(back propagation) 수행 없이, 상기 해당 레이어의 상기 입력 데이터에 대한 자코비언 행렬을 계산할 수 있다. 상기 프로세서는 상기 복수의 레이어들 각각에 대하여 상기 순전파를 수행함으로써, 해당 레이어의 출력 액티베 이션을 획득하고, 상기 해당 레이어의 출력 액티베이션에 기초하여, 상기 뉴럴 네트워크의 출력 데이터를 획득 할 수 있다. 상기 프로세서는 복수의 원소들을 포함하는 상기 입력 데이터에 있어서, 상기 복수의 원소들 중 미분값이 필요 한 하나 이상의 원소로 구성된 미분 입력 데이터를 획득할 수 있다. 상기 프로세서는 상기 복수의 레이어들 각각에 있어서, 상기 해당 레이어의 상기 미분 입력 데이터에 대한 자코 비언 행렬을 계산할 수 있다. 상기 미분 입력 데이터의 원소 수 및 상기 복수의 레이어들의 상기 미분 입력 데이터에 대한 자코비언 행렬의 차원 중 최대값에 기초하여 상기 뉴럴 네트워크의 추론에 필요한 메모리 크기가 결정될 수 있다."}
{"patent_id": "10-2022-0035448", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 명세서에서 개시되어 있는 특정한 구조적 또는 기능적 설명들은 단지 기술적 개념에 따른 실시예들을 설명하 기 위한 목적으로 예시된 것으로서, 실제로 구현된 형태는 다양한 다른 모습을 가질 수 있으며 본 명세서에 설 명된 실시예로만 한정되지 않는다. 제1 또는 제2 등의 용어는 다양한 구성요소들을 설명하는데 사용될 수 있지만, 이런 용어들은 하나의 구성요소 를 다른 구성요소로부터 구별하는 목적으로만 이해되어야 한다. 예를 들어 제1 구성요소는 제2 구성요소로 명명 될 수 있고, 유사하게 제2 구성요소는 제1 구성요소로도 명명될 수 있다. 어떤 구성요소가 다른 구성요소에 \"연결되어\" 있다거나 \"접속되어\" 있다고 언급된 때에는, 그 다른 구성요소에 직접적으로 연결되어 있거나 또는 접속되어 있을 수도 있지만, 중간에 다른 구성요소가 존재할 수도 있다고 이해되어야 할 것이다. 반면에, 어떤 구성요소가 다른 구성요소에 \"직접 연결되어\" 있다거나 \"직접 접속되어\" 있 다고 언급된 때에는, 중간에 다른 구성요소가 존재하지 않는 것으로 이해되어야 할 것이다. 구성요소들 간의 관계를 설명하는 표현들, 예를 들어 \"~간의\"와 \"바로~간의\" 또는 \"~에 이웃하는\"과 \"~에 직접 이웃하는\" 등도 마찬가지로 해석되어야 한다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 명세서에서, \"포함하다\" 또는 \"가지다\" 등의 용어는 실시된 특징, 숫자, 단계, 동작, 구성요소, 부분품 또는 이들을 조합한 것이 존재함 을 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성요소, 부분품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되어야 한다. 다르게 정의되지 않는 한, 기술적이거나 과학적인 용어를 포함해서 여기서 사용되는 모든 용어들은 해당 기술 분야에서 통상의 지식을 가진 자에 의해 일반적으로 이해되는 것과 동일한 의미를 가진다. 일반적으로 사용되 는 사전에 정의되어 있는 것과 같은 용어들은 관련 기술의 문맥상 가지는 의미와 일치하는 의미를 갖는 것으로 해석되어야 하며, 본 명세서에서 명백하게 정의하지 않는 한, 이상적이거나 과도하게 형식적인 의미로 해석되지 않는다. 실시예들은 퍼스널 컴퓨터, 랩톱 컴퓨터, 태블릿 컴퓨터, 스마트 폰, 텔레비전, 스마트 가전 기기, 지능형 자동 차, 키오스크, 웨어러블 장치 등 다양한 형태의 제품으로 구현될 수 있다. 이하, 실시예들을 첨부된 도면을 참 조하여 상세하게 설명한다. 각 도면에 제시된 동일한 참조 부호는 동일한 부재를 나타낸다. 도 1a는 일 실시예에 따른 인공 신경망에서 수행되는 연산을 설명하기 위한 도면이다. 인공 신경망이란 사람의 두뇌가 정보를 처리하는 방식을 모방한 연산 시스템이다. 심층 신경망(Deep Neural Network)은 인공 신경망을 구현하는 하나의 방식으로서, 복수의 레이어(layer)를 포함 할 수 있다. 예를 들어, 심층 신경망은 입력 데이터가 인가되는 입력 레이어(Input Layer), 학습을 바탕으로 입력 데이터에 기반한 예측을 통해 도출된 결과 값을 출력하는 출력 레이어(Output Layer) 및 입력 레이어와 출 력 레이어 사이에 다중의 은닉 레이어(Hidden Layer)을 포함한다. 심층 신경망은 정보를 처리하기 위해 이용되는 알고리즘에 따라, 컨볼루션 신경망(Convolutional Neural Network), 리커런트 신경망(Recurrent Neural Network) 등으로 분류된다. 인공 신경망을 학습하는 방식을 딥러닝(Deep Learning)이라 하며, 상술한 바와 같이 딥러닝에는 컨볼루션 신경 망, 리커런트 신경망 방식과 같이 다양한 알고리즘이 이용될 수 있다. 이 때, 인공 신경망을 학습한다는 것은 계층간 가중치 및 바이어스 또는 인접한 계층 중 서로 다른 레이어에 속 하는 복수의 뉴런들간의 가중치 및 바이어스를 결정하고 갱신하는 것을 나타낼 수 있다. 예를 들어, 복수의 계층적 구조 및 복수의 레이어들, 또는, 뉴런들 간의 가중치 및 바이어스를 총칭하여 인공 신경망의 연결성(connectivity)이라 할 수 있다. 따라서, 인공 신경망을 학습한다는 것은 연결성을 구축하고 학습하는 것을 나타낼 수 있다. 도 1a를 참조하면, 인공 신경망은 입력 레이어, 히든 레이어들 및 출력 레이어를 포함하는 구조를 가지며, 수신 되는 입력 데이터(예를 들어, I1 및 I2)를 기초로 연산을 수행하고, 수행 결과를 기초로 출력 데이터(예를 들어, O1 및 O2)를 생성할 수 있다. 인공 신경망은 앞서 설명된 바와 같이, 1개 이상의 히든 레이어들을 포함하는 DNN 또는 n-계층 인공 신경망일 수 있다. 예를 들어, 도 1a에 도시된 바와 같이, 인공 신경망은 입력 레이어(Layer 1), 1개의 히든 레이어들 (Layer 1 및 Layer 3) 및 출력 레이어(Layer 4)를 포함하는 DNN일 수 있다. DNN은 Convolutional Neural Networks(CNN), Recurrent Neural Networks(RNN), Deep Belief Networks, Restricted Boltzman Machines 등을 포함할 수 있으나, 이에 제한되지 않는다. 예를 들어, 컨볼루션 신경망은 합성곱(Convolution) 연산을 사용하며, 예를 들어, 영상에서 객체, 얼굴, 장면을 인식하기 위해 패턴을 찾는데 유용하다. 컨볼루션 신경망은 영상의 특징을 추출하기 위하여 필터(filter)가 입력 영상의 픽셀 또는 데이터를 일정 간격 으로 순회하면서 합성곱 연산을 수행하고, 합성곱 연산의 결과를 이용하여 특징 맵(feature map) 또는 활성도 맵(activation map)을 생성할 수 있다. 여기서, '필터'는 예를 들어, 영상의 특징을 찾아내기 위한 공용 파라미터 또는 가중치 파라미터들을 포함할 수 있다. 필터는 '커널'이라고도 불릴 수 있다. 또한, 입력 영상에 필 터를 적용할 때, 필터가 입력 영상의 픽셀 또는 데이터를 이동(또는 순회)하는 일정 간격은 '스트라이드 (stride)'라고 부를 수 있다. 예를 들어, 스트라이드가 '2'인 경우, 필터는 입력 영상의 픽셀 또는 데이터에서 2칸씩 이동하면서 합성곱 연산을 수행할 수 있다. 이 경우, 스트라이드 파라미터 = 2라고 표현될 수 있다. '특징 맵'은 합성곱 연산을 통해 원 영상(original image)의 정보가 압축된 것으로서, 예를 들어, 행렬의 형태 로 표현될 수 있다. 또한, 활성도 맵은 특징 맵에 활성 함수(activation function)를 적용한 결과에 해당할 수 있다. 다시 말해, 활성도 맵은 컨볼루션 신경망에서 컨볼루션 연산을 수행하는 컨볼루션 레이어들의 최종 출력 결과에 해당할 수 있다. 컨볼루션 신경망에서 최종 출력되는 데이터의 형태(shape)는 예를 들어, 필터의 크기, 스트라이드(Stride), 패 딩(Padding)의 적용 여부, 및/또는 맥스 풀링(Max Pooling)의 크기 등에 따라서 변경될 수 있다. 컨볼루션 레 이어에서는 필터와 스트라이드의 작용으로 인해 특징 맵의 크기가 입력 데이터보다 작을 수 있다. '패딩'은 데이터의 외곽에 지정된 픽셀 수(예를 들어, '2')만큼 특정 값을 채워 넣는 것으로 이해될 수 있다. 예를 들어, 패딩이 '2'로 설정된 경우, 32 x 32의 크기를 갖는 데이터 외곽의 상, 하, 좌, 우에는 각각 2 픽셀 만큼 특정 값(예를 들어, '0')이 채워질 수 있다. 따라서, 패딩이 '2'로 설정된 경우, 최종적인 데이터의 크기 는 36 x 36 크기가 될 수 있다. 이 경우, '패딩 파라미터= 2'라고 표현될 수 있다. 이와 같이, 패딩을 통해 컨볼루션 레이어의 출력 데이터의 사이즈가 조절될 수 있다. 예를 들어, 패딩을 사용하지 않는 경우, 데이터의 공간적 크기는 컨볼루션 레이어를 지날 때마다 작아지게 되므 로 데이터의 가장자리의 정보들이 사라질 수 있다. 패딩은 이와 같이 데이터의 가장자리의 정보가 사라지는 것 을 방지하거나, 또는 컨볼루션 레이어의 출력을 입력 데이터의 공간적 크기와 동일하게 맞춰 주기 위해 사용될 수 있다. 인공 신경망이 DNN 아키텍처로 구현된 경우 유효한 정보를 처리할 수 있는 보다 많은 레이어들을 포함하므로, 인공 신경망은 싱글 레이어를 갖는 인공 신경망보다 복잡한 데이터 집합들을 처리할 수 있다. 한편, 인공 신경 망은 4개의 레이어들을 포함하는 것으로 도시되어 있으나, 이는 예시에 불과할 뿐 인공 신경망은 더 적거나 많 은 레이어들을 포함하거나, 더 적거나 많은 채널들을 포함할 수 있다. 즉, 인공 신경망은 도 1a에 도시된 것과 는 다른, 다양한 구조의 레이어들을 포함할 수 있다. 인공 신경망에 포함된 레이어들 각각은 복수의 채널들을 포함할 수 있다. 채널은 뉴런(neuron), 프로세싱 엘리 먼트(Processing element, PE), 유닛(unit) 또는 이와 유사한 용어들로 알려진, 복수의 인공 노드(artificial node)들에 해당될 수 있다. 예를 들어, 도 1a에 도시된 바와 같이, Layer 1은 1개의 채널들(노드들), Layer 1 및 Layer 3 각각은 3개의 채널들을 포함할 수 있다. 다만, 이는 예시에 불과할 뿐 인공 신경망에 포함된 레이 어들 각각은 다양한 개수의 채널들(노드들)을 포함할 수 있다. 인공 신경망의 레이어들 각각에 포함된 채널들은 서로 연결되어 데이터를 처리할 수 있다. 예를 들어, 하나의 채널은 다른 채널들로부터 데이터를 수신하여 연산할 수 있고, 연산 결과를 또 다른 채널들로 출력할 수 있다. 채널들 각각의 입력 및 출력 각각은 입력 액티베이션 및 출력 액티베이션이라고 지칭될 수 있다. 즉, 액티베이 션은 한 채널의 출력임과 동시에, 다음 레이어에 포함된 채널들의 입력에 해당되는 파라미터일 수 있다. 한편, 채널들 각각은 이전 레이어에 포함된 채널들로부터 수신된 액티베이션들 및 웨이트 및 바이어스에 기초하여 자 신의 액티베이션을 결정할 수 있다. 웨이트는 각 채널에서의 출력 액티베이션을 계산하기 위해 이용되는 파라 미터로서, 채널들 간의 연결관계에 할당되는 값일 수 있다. 채널들 각각은 입력을 수신하여 출력 액티베이션을 출력하는 연산 유닛(computational unit) 또는 프로세싱 엘 리먼트(processing element)에 의해 처리될 수 있고, 채널들 각각의 입력-출력은 매핑될 수 있다. 예를 들어, σ는 활성화 함수이고, 는 j 번째 레이어에 포함된 k 번째 노드로부터 (j+1) 번째 레이어에 포함된 i번 째 노드로의 웨이트이며, 는 j 번째 레이어에 포함된 i 번째 노드의 바이어스(bias) 값이고, 는 j 번째 레이 어의 i 번째 노드의 액티베이션이라고 할 때, 액티베이션 는 다음과 같은 수학식 1을 따를 수 있다.수학식 1"}
{"patent_id": "10-2022-0035448", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "item": 2, "content": "도 1a에 도시된 바와 같이, 2번째 레이어(Layer 2)의 첫 번째 채널(CH 1)의 액티베이션은 로 표현될 수 있다. 또한, 은 수학식 1에 따라 의 값을 가질 수 있다. 다만, 앞 서 설명한 수학식 1은 인공 신경망에서 데이터를 처리하기 위해 이용되는 액티베이션 및 웨이트 및 바이어스를 설명하기 위한 예시일 뿐, 이에 제한되지 않는다. 액티베이션은 이전 레이어로부터 수신된 액티베이션들의 가 중치 합(weighted sum)을 sigmoid 함수나 Rectified Linear Unit (ReLU) 함수 등의 액티베이션 함수에 통과시 킴으로써 획득된 값일 수 있다. 도 1b는 일 실시예에 따른 인공 신경망 시스템을 설명하기 위한 도면이다. 도 1b를 참조하면, 일 실시예에 따른 인공 신경망 시스템은 학습 장치 및 추론 장치를 포함할 수 있 다. 일 실시예에 따른 학습 장치는 뉴럴 네트워크를 생성하거나, 뉴럴 네트워크를 훈련(train)(또는 학습 (learn))하거나, 뉴럴 네트워크를 재훈련(retrain)하는 기능들과 같은 다양한 프로세싱 기능들을 갖는 컴퓨팅 디바이스에 해당된다. 예를 들어, 학습 장치는 PC(personal computer), 서버 디바이스, 모바일 디바이스 등의 다양한 종류의 디바이스들로 구현될 수 있다. 학습 장치는 주어진 초기 뉴럴 네트워크를 반복적으로 훈련(학습)시킴으로써, 훈련된 뉴럴 네트워크 를 생성할 수 있다. 훈련된 뉴럴 네트워크를 생성하는 것은 뉴럴 네트워크 파라미터를 결정하는 것을 의 미할 수 있다. 여기서, 파라미터들은 예를 들어 뉴럴 네트워크의 입/출력 액티베이션들, 웨이트들, 바이어스들 등 뉴럴 네트워크에 입/출력되는 다양한 종류의 데이터를 포함할 수 있다. 뉴럴 네트워크의 반복적인 훈련이 진행됨에 따라, 뉴럴 네트워크의 파라미터들은 주어진 입력에 대해 보다 정확한 출력을 연산하기 위해 조정될 (tuned) 수 있다. 학습 장치는 훈련된 뉴럴 네트워크를 추론 장치에 전달할 수 있다. 추론 장치는 모바일 디바이스, 임베디드(embedded) 디바이스 등에 포함될 수 있다. 추론 장치는 뉴럴 네트워크의 구동을 위한 전용 하드웨어일 수 있다. 일 실시예에 따른 추론은 훈련된 뉴럴 네트워크를 구동하는 동작을 의미할 수 있다. 추론 장치는 훈련된 뉴럴 네트워크를 그대로 구동하거나, 훈련된 뉴럴 네트워크가 가공(예를 들 어, 양자화)된 뉴럴 네트워크를 구동할 수 있다. 추론 장치는, 학습 장치와는 별도의 독립적인 디바이스에서 구현될 수 있다. 하지만, 이에 제한되지 않고, 추론 장치는 학습 장치와 동일한 디바이스 내에도 구현될 수 있다. 아래에서 상세히 설명하겠지만, 일 실시예에 따른 추론 장치는 훈련된 뉴럴 네트워크의 출력 데이터 의 입력 데이터에 대한 미분 데이터를 획득할 수 있다. 예를 들어, 딥러닝 시뮬레이션(deep learning simulation) 등에서 훈련된 뉴럴 네트워크의 출력 데이터의 입력 데이터에 대한 미분값이 필요할 수 있다. 일 실시예에 따른 미분 계산 방법을 설명하기에 앞서, 도 2를 참조하여 종래의 미분 계산 방법을 설명한다. 도 2를 참조하면, 뉴럴 네트워크는 d0개의 원소(component)를 포함하는 입력 데이터(x0=( )를 수신 할 수 있다. 이후, 뉴럴 네트워크를 구성하는 복수의 레이어들 각각은 순전파(forward propagation)를 통해 출 력 액티베이션(xi=( )을 획득하여, 최종 출력 데이터(xn=( )를 출력할 수 있다. 그러나, 종래의 경우 뉴럴 네트워크의 출력 데이터(xn)의 입력 데이터(x0)에 대한 미분 데이터(예를 들어, 미분 값을 자코비언 행렬(jacobian matrix)로 표현할 경우: J(xn)(xi))을 얻기 위해서는 추론을 수행한후, 역전파(back propagation)를 별도로 수행하여야 한다. 이때, 역전파 수행을 위해 각 레이어의 출력(xi)을 저장하고 있어야 한다. 여기서, 각 레이어의 출력(xi)은 도 1a를 참조하여 전술한 출력 액티베이션을 의미할 수 있다. 따라서, 종래의 경우 미분 데이터를 얻기 위하여 추론 과정 중 레이어 별 출력 액티베이션을 저장하고 있어야 하기 때문에 메모리 사용량이 많고, 역전파를 추가로 수행해야 하기 때문에 동작 시간이 추가로 소요될 수 있다. 도 3은 일 실시예에 따른 미분 계산 방법을 설명하기 위한 순서도이다. 도 3의 동작은 도시된 순서 및 방식으로 수행될 수 있지만, 도시된 실시예의 사상 및 범위를 벗어나지 않으면서 일부 동작의 순서가 변경되거나 일부 동작이 생략될 수 있다. 도 3에 도시된 다수의 동작은 병렬로 또는 동시 에 수행될 수 있다. 도 3의 단계들은 도 1b를 참조하여 전술한 추론 장치에 의해 수행될 수 있다. 일 실시예에 따른 추론 장치는 역전파 없이 순전파(forward propagation)만을 통해 입력 데이터에 대한 출 력 데이터의 미분 데이터를 획득할 수 있다. 단계에서, 일 실시예에 따른 추론 장치는 뉴럴 네트워크의 입력 데이터를 수신한다. 이 때, 일 실시 예에 따른 입력 데이터는 복수의 원소들을 포함할 수 있다. 추론 장치는 입력 데이터에 대한 출력 데이터의 미분 데이터를 얻기 위하여 필요한 정보를 매 레이어 별로 계산하며 진행할 수 있다. 매 레이어 마다 계산하는 정보는 해당 레이어의 출력 액티베이션과 입력 데이터에 대한 미분 데이터를 포함할 수 있고, 이전 레이어들에 대한 정보는 저장하지 않을 수 있다. 보다 구체적으로, 단계에서, 일 실시예에 따른 추론 장치는 복수의 레이어들 각각에 있어서, 해당 레 이어의 출력 액티베이션의 입력 데이터에 대한 미분 데이터를 획득한다. 예를 들어, 추론 장치는 해당 레 이어의 입력 데이터에 대한 자코비언 행렬을 계산할 수 있다. 추론 장치는 뉴럴 네트워크의 추론이 끝남과 동시에 자코비언 행렬을 통해 입력 데이터에 대한 출력 데이 터의 미분 데이터를 함께 획득할 수 있다. 보다 구체적으로, 단계에서, 일 실시예에 따른 추론 장치는 해당 레이어의 출력 액티베이션의 입력 데이터에 대한 미분 데이터에 기초하여, 뉴럴 네트워크의 출력 데이터의 입력 데이터에 대한 미분 데이터를 획 득한다. 다시 말해, 일 실시예에 따른 추론 장치는 역전파가 필요 없으므로, 실행 속도 측면에서 이득을 갖고, 중 간 레이어의 액티베이션 저장이 필요 없으므로 메모리 사용량도 줄일 수 있다. 수학식을 참조하여 단계(310 내지 330)의 동작을 보다 상세히 설명하면, 뉴럴 네트워크의 레이어는 다음과 같은 수학식 2를 따를 수 있다. 수학식 2"}
{"patent_id": "10-2022-0035448", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "수학식 2에서, 는 각각 i번째 레이어의 입력 액티베이션, 웨이트, 바이어스를 지칭하고 는 액티베이션 함수를 의미할 수 있다. 뉴럴 네트워크의 출력 데이터(y=xn)의 입력 데이터(x0)에 대한 미분 데이터는 다음과 같은 수학식 3을 따를 수 있다.수학식 3"}
{"patent_id": "10-2022-0035448", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "수학식 3에 따르면, k-1번째 레이어를 지난 후 값을 저장하고 있으면 k-1번째 이전 레이어의 웨이트나 액티베 이션 정보는 미분 데이터 를 얻는 데 더 이상 필요 없을 수 있다. 다시 말해, 일 실시예에 따른 추론 장치는 별도로 역전파를 수행하지 않아도, 뉴럴 네트워크의 추론 과정 에서 매 레이어 마다 출력 액티베이션과 입력 데이터에 대한 미분 데이터를 계산하면, 순전파를 통해 최종 미분 데이터 를 얻을 수 있다. 도 4는 일 실시예에 따른 미분 데이터를 획득하는 방법을 설명하기 위한 도면이다. 도 3을 참조하여 설명한 내용은 도 4에도 동일하게 적용될 수 있는 바, 중복되는 내용을 생략할 수 있다. 도 4를 참조하면, 일 실시예에 따른 뉴럴 네트워크는 d0개의 원소(component)를 포함하는 입력 데이터 (x0=( )를 수신할 수 있다. 나아가, 일 실시예에 따른 추론 장치는 복수의 원소들을 포함하는 입력 데이터(x0=( )에 있 어서, 복수의 원소들 중 미분 데이터이 필요한 하나 이상의 원소로 구성된 미분 입력 데이터 ( )를 획득할 수 있다. 일 실시예에 따른 추론 장치는 뉴럴 네트워크의 각 레이어를 통과할 때마다 레이어의 출력 액티베이션 과 함께 출력 액티베이션의 미분 입력 데이터( 에 대한 미분 데이터(예를 들어, )를 함께 계산할 수 있다. 추론 장치는 매 레이어 마다 위 과정을 반복함으로써, 최종 뉴럴 네트워크의 출력 데이터( )와 미분 데이 터(예를 들어, )를 얻을 수 있다. 일 실시예에 따른 추론 장치는 미분 데이터를 얻기 위하여 역전파 연산을 계산하지 않아도 되므로 속도 향 상을 기대할 수 있다. 또한 연산이 끝난 레이어의 가중치 및 액티베이션을 더 이상 저장하지 않아도 되므로 메 모리 사용량의 획기적인 감소를 기대할 수 있다. 보다 구체적으로, 최초 입력 데이터( )중 m개의 차원(dimension)에 대한 미분 데이터가 필 요한 경우, 기존 방법은 총 개의 액티베이션을 저장할 메모리가 필요하지만, 일 실시예에 따르 면 이전 레이어의 정보를 저장할 필요가 없으므로 의 메모리만 요구된다. 즉, 신경망의 깊 이가 깊을수록, 또는 필요한 미분 데이터의 개수가 작을수록 일 실시예에 따른 방법이 크게 유리할 수 있다.도 5는 일 실시예에 따른 다층 퍼셉트론 네트워크에서 미분 데이터를 획득하는 방법을 설명하기 위한 도면이다. 도 5를 참조하면, 일 실시예에 따른 다층 퍼셉트론(MLP; multilayer perceptron) 에서의 의 과정에 서 자코비언 행렬은 이므로 , 로 대 체 시 이므로 한번의 행렬 연산으로 모두 계산이 가능할 수 있다. 활성화 함수 에 대하여 , 임을 이용하면 출력 데이터와 자코비언 행렬 을 계산할 수 있다. 도 6은 일 실시예에 따른 추론 장치의 하드웨어 구성을 도시한 블록도이다. 도 6을 참고하면, 일 실시예에 따른 추론 장치는 프로세서 및 메모리를 포함한다. 추론 장치 는 도 1a의 추론 장치일 수 있다. 도 6에 도시된 추론 장치에는 본 실시예들와 관련된 구성요소들만이 도시되어 있다. 따라서, 추론 장치 에는 도 6에 도시된 구성요소들 외에 다른 범용적인 구성요소들이 더 포함될 수 있음은 당업자에게 자명하 다. 이하에서, 도 6의 추론 장치는 전자 장치로 지칭될 수도 있다. 일 실시예에 따른 추론 장치는 뉴럴 네트워크에 대한 추론을 수행하는 컴퓨팅 디바이스에 해당된다. 예를 들어, 추론 장치는 PC(personal computer), 서버 디바이스, 모바일 디바이스 등에 해당될 수 있고, 나아가 서 뉴럴 네트워크를 이용한 음성 인식, 영상 인식 등을 수행하는 자율주행 자동차, 로보틱스, 스마트폰, 태블릿 디바이스, AR(Augmented Reality) 디바이스, IoT(Internet of Things) 디바이스 등에 구비된 장치일 수 있으나, 이에 제한되지 않고 다양한 종류의 디바이스들에 해당될 수 있다. 프로세서는 추론 장치의 동작들을 제어하기 위한 전반적인 제어 기능들을 수행하는 하드웨어 구성이 다. 예를 들어, 프로세서는 추론 장치 내의 메모리에 저장된 프로그램들을 실행함으로써, 추론 장치를 전반적으로 제어할 수 있다. 프로세서는 추론 장치 내에 구비된 CPU(central processing unit), GPU(graphics processing unit), AP(application processor), NPU(neural processing unit) 등으로 구현될 수 있으나, 이에 제한되지 않는다. 메모리는 프로세서 내에서 처리되는 각종 뉴럴 네트워크 데이터들을 저장하는 하드웨어로서, 예를 들 어, 메모리는 뉴럴 네트워크에 입력될 데이터 세트들 등을 저장할 수 있다. 또한, 메모리는 프로세서 에 의해 구동될 다양한 애플리케이션들, 예를 들어 뉴럴 네트워크 미분 데이터 획득을 위한 애플리케이션, 뉴럴 네트워크 구동 애플리케이션, 드라이버 등을 저장할 수 있다. 메모리는 휘발성 메모리(volatile memory) 또는 불휘발성 메모리(nonvolatile memory) 중 적어도 하나를 포함할 수 있다. 불휘발성 메모리는 ROM (Read Only Memory), PROM (Programmable ROM), EPROM (Electrically Programmable ROM), EEPROM (Electrically Erasable and Programmable ROM), 플래시 메모리, PRAM (Phase- change RAM), MRAM (Magnetic RAM), RRAM (Resistive RAM), FRAM (Ferroelectric RAM) 등을 포함한다. 휘발성 메모리는 DRAM (Dynamic RAM), SRAM (Static RAM), SDRAM (Synchronous DRAM), PRAM (Phase-change RAM), MRAM (Magnetic RAM), RRAM (Resistive RAM), FeRAM (Ferroelectric RAM) 등을 포함한다. 나아가서, 메모리 는 HDD(Hard Disk Drive), SSD(Solid State Drive), CF(compact flash), SD(secure digital), Micro- SD(micro secure digital), Mini-SD(mini secure digital), xD(extreme digital) 또는 Memory Stick 중 적어 도 하나를 포함할 수 있다. 이상에서 설명된 실시예들은 하드웨어 구성요소, 소프트웨어 구성요소, 및/또는 하드웨어 구성요소 및 소프트웨 어 구성요소의 조합으로 구현될 수 있다. 예를 들어, 실시예들에서 설명된 장치, 방법 및 구성요소는, 예를 들 어, 프로세서, 콘트롤러, ALU(arithmetic logic unit), 디지털 신호 프로세서(digital signal processor), 마 이크로컴퓨터, FPGA(field programmable gate array), PLU(programmable logic unit), 마이크로프로세서, 또는 명령(instruction)을 실행하고 응답할 수 있는 다른 어떠한 장치와 같이, 범용 컴퓨터 또는 특수 목적 컴퓨터를 이용하여 구현될 수 있다. 처리 장치는 운영 체제(OS) 및 상기 운영 체제 상에서 수행되는 소프트웨어 애플리 케이션을 수행할 수 있다. 또한, 처리 장치는 소프트웨어의 실행에 응답하여, 데이터를 접근, 저장, 조작, 처리 및 생성할 수도 있다. 이해의 편의를 위하여, 처리 장치는 하나가 사용되는 것으로 설명된 경우도 있지만,"}
{"patent_id": "10-2022-0035448", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "해당 기술분야에서 통상의 지식을 가진 자는, 처리 장치가 복수 개의 처리 요소(processing element) 및/또는 복수 유형의 처리 요소를 포함할 수 있음을 알 수 있다. 예를 들어, 처리 장치는 복수 개의 프로세서 또는 하 나의 프로세서 및 하나의 콘트롤러를 포함할 수 있다. 또한, 병렬 프로세서(parallel processor)와 같은, 다른 처리 구성(processing configuration)도 가능하다. 소프트웨어는 컴퓨터 프로그램(computer program), 코드(code), 명령(instruction), 또는 이들의 조합을 포함 할 수 있으며, 원하는 대로 동작하도록 처리 장치를 구성하거나 독립적으로 또는 결합적으로(collectively) 처 리 장치를 명령할 수 있다. 소프트웨어 및/또는 데이터는, 처리 장치에 의하여 해석되거나 처리 장치에 명령 또는 데이터를 제공하기 위하여, 어떤 유형의 기계, 구성요소(component), 물리적 장치, 가상 장치(virtual equipment), 컴퓨터 저장 매체 또는 장치, 또는 전송되는 신호 파(signal wave)에 영구적으로, 또는 일시적으로 구체화(embody)될 수 있다. 소프트웨어는 네트워크로 연결된 컴퓨터 시스템 상에 분산되어서, 분산된 방법으로 저장되거나 실행될 수도 있다. 소프트웨어 및 데이터는 컴퓨터 판독 가능 기록 매체에 저장될 수 있다. 실시예에 따른 방법은 다양한 컴퓨터 수단을 통하여 수행될 수 있는 프로그램 명령 형태로 구현되어 컴퓨터 판 독 가능 매체에 기록될 수 있다. 컴퓨터 판독 가능 매체는 프로그램 명령, 데이터 파일, 데이터 구조 등을 단독 으로 또는 조합하여 포함할 수 있다. 매체에 기록되는 프로그램 명령은 실시예를 위하여 특별히 설계되고 구성 된 것들이거나 컴퓨터 소프트웨어 당업자에게 공지되어 사용 가능한 것일 수도 있다. 컴퓨터 판독 가능 기록 매체의 예에는 하드 디스크, 플로피 디스크 및 자기 테이프와 같은 자기 매체(magnetic media), CD-ROM, DVD와 같은 광기록 매체(optical media), 플롭티컬 디스크(floptical disk)와 같은 자기-광 매체(magneto-optical media), 및 롬(ROM), 램(RAM), 플래시 메모리 등과 같은 프로그램 명령을 저장하고 수행하도록 특별히 구성된 하드웨어 장치가 포함된다. 프로그램 명령의 예에는 컴파일러에 의해 만들어지는 것과 같은 기계어 코드뿐만 아니라 인터프리터 등을 사용해서 컴퓨터에 의해서 실행될 수 있는 고급 언어 코드를 포함한다."}
{"patent_id": "10-2022-0035448", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "이상과 같이 실시예들이 비록 한정된 도면에 의해 설명되었으나, 해당 기술분야에서 통상의 지식을 가진 자라면 상기를 기초로 다양한 기술적 수정 및 변형을 적용할 수 있다. 예를 들어, 설명된 기술들이 설명된 방법과 다 른 순서로 수행되거나, 및/또는 설명된 시스템, 구조, 장치, 회로 등의 구성요소들이 설명된 방법과 다른 형태 로 결합 또는 조합되거나, 다른 구성요소 또는 균등물에 의하여 대치되거나 치환되더라도 적절한 결과가 달성될 수 있다. 그러므로, 다른 구현들, 다른 실시예들 및 특허청구범위와 균등한 것들도 후술하는 특허청구범위의 범위에 속한 다.도면 도면1a 도면1b 도면2 도면3 도면4 도면5 도면6"}
{"patent_id": "10-2022-0035448", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1a는 일 실시예에 따른 인공 신경망에서 수행되는 연산을 설명하기 위한 도면이다. 도 1b는 일 실시예에 따른 인공 신경망 시스템을 설명하기 위한 도면이다. 도 2는 종래의 미분 계산 방법을 설명하기 위한 도면이다. 도 3은 일 실시예에 따른 미분 계산 방법을 설명하기 위한 순서도이다. 도 4는 일 실시예에 따른 미분 데이터를 획득하는 방법을 설명하기 위한 도면이다. 도 5는 일 실시예에 따른 다층 퍼셉트론 네트워크에서 미분 데이터를 획득하는 방법을 설명하기 위한 도면이다. 도 6은 일 실시예에 따른 추론 장치의 하드웨어 구성을 도시한 블록도이다."}
