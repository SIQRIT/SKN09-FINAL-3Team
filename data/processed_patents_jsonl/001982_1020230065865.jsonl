{"patent_id": "10-2023-0065865", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0168172", "출원번호": "10-2023-0065865", "발명의 명칭": "인공지능을 이용한 화자 분할을 수행하기 위한 방법 및 그 장치", "출원인": "한양대학교 산학협력단", "발명자": "장준혁"}}
{"patent_id": "10-2023-0065865", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "인공지능을 이용하여 전자 장치에 의해 수행되는 방법에 있어서,음성 데이터를 수신하는 단계; 및기 학습된 인공지능 네트워크 모델을 통해 상기 음성 데이터를 입력 자료로 하여 화자 정보를 출력하는 단계를포함하고,상기 기 학습된 인공지능 네트워크 모델은:음성 데이터 셋을 수신하고, 상기 음성 데이터 셋으로부터 제1 화자에 대한 제1 라벨 시퀀스 및 제2 화자에 대한 제2 라벨 시퀀스를 추정하고, 상기 제1 라벨 시퀀스를 기반으로 제1 타겟 매트릭스 및 상기 제2 라벨 시퀀스를 기반으로 제2 타겟 매트릭스를생성하고, 복수의 인코더 블록들 중 제1 인코더 블록의 적어도 2개의 헤드를 결정하고,상기 적어도 2개의 헤드 중 제1 헤드로부터 상기 음성 데이터 셋을 기반으로 제1 어텐션 매트릭스를 생성하고, 상기 적어도 2개의 헤드 중 제2 헤드로부터 상기 음성 데이터 셋을 기반으로 제2 어텐션 매트릭스를 생성하고,상기 제1 타겟 매트릭스, 상기 제2 타겟 매트릭스, 상기 제1 어텐션 매트릭스 및 상기 제2 어텐션 매트릭스를기반으로 제1 손실을 계산하고, 그리고상기 제1 손실을 기반으로 사전 학습되는 방법."}
{"patent_id": "10-2023-0065865", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 제1 어텐션 매트릭스 및 상기 제2 어텐션 매트릭스는 화자의 음성 패턴을 기반으로 결정되고,상기 제1 손실은 상기 제1 타겟 매트릭스 및 상기 제1 어텐션 매트릭스 간의 이진 교차 엔트로피(binary crossentropy: BCE) 손실과 상기 제2 타겟 매트릭스 및 상기 제2 어텐션 매트릭스 간의 BCE 손실을 결합하여 계산되는 방법."}
{"patent_id": "10-2023-0065865", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 기 학습된 인공지능 네트워크 모델은:상기 제1 라벨 시퀀스 및 상기 제2 라벨 시퀀스를 기반으로 제3 라벨 시퀀스를 생성하고,상기 제3 라벨 시퀀스를 기반으로 제3 타겟 매트릭스를 생성하고, 상기 복수의 인코더 블록들 중 제2 인코더 블록의 제2 헤드를 결정하고, 상기 제2 헤드로부터 상기 음성 데이터 셋을 기반으로 제3 어텐션 매트릭스를 생성하고,상기 제3 타겟 매트릭스 및 상기 제3 어텐션 매트릭스를 기반으로 제2 손실을 계산하고, 공개특허 10-2024-0168172-3-상기 제1 손실에 상기 제2 손실을 결합한 손실을 기반으로 사전 학습되는 방법."}
{"patent_id": "10-2023-0065865", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서,상기 제3 라벨 시퀀스는 상기 제1 라벨 시퀀스 및 상기 제2 라벨 시퀀스가 중첩되는 지를 나타내는 요소를 포함하는 방법."}
{"patent_id": "10-2023-0065865", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제3항에 있어서,상기 제3 라벨 시퀀스는 상기 음성 데이터 셋의 음성 활동 패턴을 기반으로 결정되고,상기 제2 손실은 상기 제3 타겟 매트릭스 및 상기 제3 어텐션 매트릭스 간의 평균 제곱 오차(mean squareerror: MSE)로 계산되는 방법."}
{"patent_id": "10-2023-0065865", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제3항에 있어서,상기 기 학습된 인공지능 네트워크 모델은:상기 음성 데이터 셋을 기반으로 상기 복수의 인코더 블록들을 통해 화자 포스테리어(speaker posterior)를 생성하고, 상기 음성 데이터 셋을 기반으로 제4 라벨 시퀀스를 추정하고,상기 생성한 화자 포스테리어 및 상기 제4 라벨 시퀀스를 기반으로 제3 손실을 계산하는 방법."}
{"patent_id": "10-2023-0065865", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6항에 있어서,상기 기 학습된 인공지능 네트워크 모델은 상기 제1 손실, 상기 제2 손실, 및 상기 제3 손실을 결합한 손실을기반으로 사전 학습되고,상기 제3 손실은 상기 화자 포스테리어와 상기 제4 라벨 시퀀스 간의 BCE 손실인 방법."}
{"patent_id": "10-2023-0065865", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "전자 장치에 있어서,메모리;모뎀;기 학습된 인공지능 네트워크 모델;상기 모뎀 및 상기 메모리에 연결되는 프로세서를 포함하고,상기 프로세서는:음성 데이터를 수신하고, 및상기 기 학습된 인공지능 네트워크 모델을 통해 상기 음성 데이터를 입력 자료로 하여 화자 정보를 출력하도록공개특허 10-2024-0168172-4-구성되고,상기 기 학습된 인공지능 네트워크 모델은:음성 데이터 셋을 수신하고, 상기 음성 데이터 셋으로부터 제1 화자에 대한 제1 라벨 시퀀스 및 제2 화자에 대한 제2 라벨 시퀀스를 추정하고, 상기 제1 라벨 시퀀스를 기반으로 제1 타겟 매트릭스 및 상기 제2 라벨 시퀀스를 기반으로 제2 타겟 매트릭스를생성하고, 복수의 인코더 블록들 중 제1 인코더 블록의 적어도 2개의 헤드를 결정하고,상기 적어도 2개의 헤드 중 제1 헤드로부터 상기 음성 데이터 셋을 기반으로 제1 어텐션 매트릭스를 생성하고, 상기 적어도 2개의 헤드 중 제2 헤드로부터 상기 음성 데이터 셋을 기반으로 제2 어텐션 매트릭스를 생성하고,상기 제1 타겟 매트릭스, 상기 제2 타겟 매트릭스, 상기 제1 어텐션 매트릭스 및 상기 제2 어텐션 매트릭스를기반으로 제1 손실을 계산하고, 그리고상기 제1 손실을 기반으로 사전 학습되는 전자 장치."}
{"patent_id": "10-2023-0065865", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서,상기 제1 어텐션 매트릭스 및 상기 제2 어텐션 매트릭스는 화자의 음성 패턴을 기반으로 결정되고,상기 제1 손실은 상기 제1 타겟 매트릭스 및 상기 제1 어텐션 매트릭스 간의 이진 교차 엔트로피(binary crossentropy: BCE) 손실과 상기 제2 타겟 매트릭스 및 상기 제2 어텐션 매트릭스 간의 BCE 손실을 결합하여 계산되는 전자 장치."}
{"patent_id": "10-2023-0065865", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제8항에 있어서,상기 기 학습된 인공지능 네트워크 모델은:상기 제1 라벨 시퀀스 및 상기 제2 라벨 시퀀스를 기반으로 제3 라벨 시퀀스를 생성하고,상기 제3 라벨 시퀀스를 기반으로 제3 타겟 매트릭스를 생성하고, 상기 복수의 인코더 블록들 중 제2 인코더 블록의 제2 헤드를 결정하고, 상기 제2 헤드로부터 상기 음성 데이터 셋을 기반으로 제3 어텐션 매트릭스를 생성하고,상기 제3 타겟 매트릭스 및 상기 제3 어텐션 매트릭스를 기반으로 제2 손실을 계산하고, 상기 제1 손실에 상기 제2 손실을 결합한 손실을 기반으로 사전 학습되는 전자 장치."}
{"patent_id": "10-2023-0065865", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제10항에 있어서, 상기 제3 라벨 시퀀스는 상기 제1 라벨 시퀀스 및 상기 제2 라벨 시퀀스가 중첩되는 지를 나타내는 요소를 포함하는 전자 장치."}
{"patent_id": "10-2023-0065865", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "공개특허 10-2024-0168172-5-제10항에 있어서,상기 제3 라벨 시퀀스는 상기 음성 데이터 셋의 음성 활동 패턴을 기반으로 결정되고,상기 제2 손실은 상기 제3 타겟 매트릭스 및 상기 제3 어텐션 매트릭스 간의 평균 제곱 오차(mean squareerror: MSE)로 계산되는 전자 장치."}
{"patent_id": "10-2023-0065865", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제10항에 있어서, 상기 기 학습된 인공지능 네트워크 모델은:상기 음성 데이터 셋을 기반으로 상기 복수의 인코더 블록들을 통해 화자 포스테리어(speaker posterior)를 생성하고, 상기 음성 데이터 셋을 기반으로 제4 라벨 시퀀스를 추정하고,상기 생성한 화자 포스테리어 및 상기 제4 라벨 시퀀스를 기반으로 제3 손실을 계산하는 전자 장치."}
{"patent_id": "10-2023-0065865", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제13항에 있어서,상기 기 학습된 인공지능 네트워크 모델은 상기 제1 손실, 상기 제2 손실, 및 상기 제3 손실을 결합한 손실을기반으로 사전 학습되고,상기 제3 손실은 상기 화자 포스테리어와 상기 제4 라벨 시퀀스 간의 BCE 손실인 전자 장치."}
{"patent_id": "10-2023-0065865", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "프로세서(processor)에 의해 실행 가능한 인공지능 알고리즘을 통해 방향 추정 방법을 수행하기 위한 매체에 저장된 프로그램으로서,음성 데이터를 수신하는 단계; 및기 학습된 인공지능 네트워크 모델을 통해 상기 음성 데이터를 입력 자료로 하여 화자 정보를 출력하는 단계를포함하고,상기 기 학습된 인공지능 네트워크 모델은:음성 데이터 셋을 수신하고,상기 음성 데이터 셋으로부터 제1 화자에 대한 제1 라벨 시퀀스 및 제2 화자에 대한 제2 라벨 시퀀스를 추정하고, 상기 제1 라벨 시퀀스를 기반으로 제1 타겟 매트릭스 및 상기 제2 라벨 시퀀스를 기반으로 제2 타겟 매트릭스를생성하고, 복수의 인코더 블록들 중 제1 인코더 블록의 적어도 2개의 헤드를 결정하고,상기 적어도 2개의 헤드 중 제1 헤드로부터 상기 음성 데이터 셋을 기반으로 제1 어텐션 매트릭스를 생성하고, 상기 적어도 2개의 헤드 중 제2 헤드로부터 상기 음성 데이터 셋을 기반으로 제2 어텐션 매트릭스를 생성하고,상기 제1 타겟 매트릭스, 상기 제2 타겟 매트릭스, 상기 제1 어텐션 매트릭스 및 상기 제2 어텐션 매트릭스를기반으로 제1 손실을 계산하고, 그리고공개특허 10-2024-0168172-6-상기 제1 손실을 기반으로 사전 학습되는 프로그램."}
{"patent_id": "10-2023-0065865", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명의 실시 예에 따른 인공지능을 이용하여 전자 장치에 의해 수행되는 방법에 있어서, 음성 데이터를 수신 하는 단계; 및 기 학습된 인공지능 네트워크 모델을 통해 상기 음성 데이터를 입력 자료로 하여 화자 정보를 출 력하는 단계를 포함하고, 상기 기 학습된 인공지능 네트워크 모델은 음성 데이터 셋을 수신하고, 상기 음성 데이 (뒷면에 계속)"}
{"patent_id": "10-2023-0065865", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 인공지능을 이용하여 화자 분할을 수행하기 위한 방법 및 그 장치 나타낸다. 구체적으로, 인공지능을 보조 손실을 추가로 부여하여 학습시키는 화자 분할 방법을 제안한다."}
{"patent_id": "10-2023-0065865", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "본 개시는 음성 데이터에서 서로 다른 화자들의 발화를 구분하고 분리하는 화자 분할 시스템, 장치 및 방법에 관한 것이다. 화자 분할 기술은 음성 신호로부터 2명 이상의 화자들의 발화를 구분하고 분리하여 각 화자 별로 언제 발언을 했는지를 결정하고, 개별적으로 처리하거나 분석할 수 있다. 화자 분할 기술은 다양한 화자가 존재 하는 환경에서 누가 발언을 하고 있는지, 각 화자의 의견이 무엇인지 정확히 기록하기 위해 필요한 기술이다. 화자 분할 기술은 비즈니스 회의나 인터뷰 등 여러 명의 화자가 대화식으로 진행하는 오디오 데이터를 인식하기 위한 음성 관련 어플리케이션에 사용될 수 있다. 또한, 화자 분할 시스템은 화자를 분할하는 과정에서 음성의 다른 구간에서 추출된 임베딩이 같은 화자인지 아닌지 비교하여 구분하는 화자 검증(speaker verification) 시 스템에도 적용될 수 있다. 나아가, 화자 분리 후 분할된 음성을 기반으로 문자로 기록하기 위한 음성인식에도 도움을 줄 수 있다. 즉, 여러 발화자들의 목소리를 구별하여 화자 분할을 수행함으로써 섞인 음성 구간에 대한 음성 인식 기술의 성능 향상에도 기여할 수 있는 기술로 대두되고 있다. 화자 분할 시스템은 다양한 종류가 존재하지만, 기존에 존재하는 종단간 화자 분할 시스템인 self-attentive end-to-end speaker diarization (SA-EEND)이 주로 사용되며 최신 알고리즘인 트랜스포머 인코더 블록을 사용 되었다. 이처럼 화자 분할 기술을 위하여 트랜스포머 인코더 기반의 종단간 시스템이 주로 사용되나, 인코더 블 록 수의 증가 및 하위 계층에 대한 기여도가 크지 않다는 한계점이 있으며 추가 손실을 부여하는 방법에서 성능 개선을 위해 모든 블록에서 순열 불변 방식으로 학습해야하므로 연산량이 증가하는 측면의 문제점이 있었다. 따 라서, 이러한 시스템의 성능을 개선하기 위하여 인코더 블록 자체의 학습 만이 아니라 이를 구성하는 각 헤드의 학습을 도모하는 방법이 개발되고 있다."}
{"patent_id": "10-2023-0065865", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 개시에서는 새로운 보조 손실을 도입하여 효율적으로 인공지능을 학습시키는 방법 및 그 장치를 제공하고자 한다. 본 개시에서는 인코더 기반의 종단간 시스템에 대하여 연산량을 크게 증가 시키지 않으면서 효율적으로 학습을 수행하기 위한 방법 및 그 장치를 제공하고자 한다."}
{"patent_id": "10-2023-0065865", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 실시 예에 따른 인공지능을 이용하여 전자 장치에 의해 수행되는 방법에 있어서, 음성 데이터를 수신 하는 단계; 및 기 학습된 인공지능 네트워크 모델을 통해 상기 음성 데이터를 입력 자료로 하여 화자 정보를 출 력하는 단계를 포함하고, 상기 기 학습된 인공지능 네트워크 모델은 음성 데이터 셋을 수신하고, 상기 음성 데 이터 셋으로부터 제1 화자에 대한 제1 라벨 시퀀스 및 제2 화자에 대한 제2 라벨 시퀀스를 추정하고, 상기 제1 라벨 시퀀스를 기반으로 제1 타겟 매트릭스 및 상기 제2 라벨 시퀀스를 기반으로 제2 타겟 매트릭스를 생성하고, 복수의 인코더 블록들 중 제1 인코더 블록의 적어도 2개의 헤드를 결정하고, 상기 적어도 2개의 헤드 중 제1 헤드로부터 상기 음성 데이터 셋을 기반으로 제1 어텐션 매트릭스를 생성하고, 상기 적어도 2개의 헤드 중 제2 헤드로부터 상기 음성 데이터 셋을 기반으로 제2 어텐션 매트릭스를 생성하고, 상기 제1 타겟 매트릭스, 상기 제2 타겟 매트릭스, 상기 제1 어텐션 매트릭스 및 상기 제2 어텐션 매트릭스를 기반으로 제1 손실을 계산 하고, 그리고 상기 제1 손실을 기반으로 사전 학습될 수 있다.일 실시예에서, 상기 제1 어텐션 매트릭스 및 상기 제2 어텐션 매트릭스는 화자의 음성 패턴을 기반으로 결정되 고, 상기 제1 손실은 상기 제1 타겟 매트릭스 및 상기 제1 어텐션 매트릭스 간의 이진 교차 엔트로피(binary cross entropy: BCE) 손실과 상기 제2 타겟 매트릭스 및 상기 제2 어텐션 매트릭스 간의 BCE 손실을 결합하여 계산될 수 있다. 일 실시예에서, 상기 기 학습된 인공지능 네트워크 모델은 상기 제1 라벨 시퀀스 및 상기 제2 라벨 시퀀스를 기 반으로 제3 라벨 시퀀스를 생성하고, 상기 제3 라벨 시퀀스를 기반으로 제3 타겟 매트릭스를 생성하고, 상기 복 수의 인코더 블록들 중 제2 인코더 블록의 제2 헤드를 결정하고, 상기 제2 헤드로부터 상기 음성 데이터 셋을 기반으로 제3 어텐션 매트릭스를 생성하고, 상기 제3 타겟 매트릭스 및 상기 제3 어텐션 매트릭스를 기반으로 제2 손실을 계산하고, 상기 제1 손실에 상기 제2 손실을 결합한 손실을 기반으로 사전 학습될 수 있다. 일 실시예에서, 상기 제3 라벨 시퀀스는 상기 제1 라벨 시퀀스 및 상기 제2 라벨 시퀀스가 중첩되는 지를 나타 내는 요소를 포함할 수 있다. 일 실시예에서, 상기 제3 라벨 시퀀스는 상기 음성 데이터 셋의 음성 활동 패턴을 기반으로 결정되고, 상기 제2 손실은 상기 제3 타겟 매트릭스 및 상기 제3 어텐션 매트릭스 간의 평균 제곱 오차(mean square error: MSE)로 계산될 수 있다. 일 실시예에서, 상기 기 학습된 인공지능 네트워크 모델은: 상기 음성 데이터 셋을 기반으로 상기 복수의 인코더 블록들을 통해 화자 포스테리어(speaker posterior)를 생 성하고, 상기 음성 데이터 셋을 기반으로 제4 라벨 시퀀스를 추정하고, 상기 생성한 화자 포스테리어 및 상기 제4 라벨 시퀀스를 기반으로 제3 손실을 계산할 수 있다. 일 실시예에서, 상기 기 학습된 인공지능 네트워크 모델은 상기 제1 손실, 상기 제2 손실, 및 상기 제3 손실을 결합한 손실을 기반으로 사전 학습되고, 상기 제3 손실은 상기 화자 포스테리어와 상기 제4 라벨 시퀀스 간의 BCE 손실일 수 있다. 본 발명의 실시 예에 따른 전자 장치에 있어서, 메모리; 모뎀; 기 학습된 인공지능 네트워크 모델; 상기 모뎀 및 상기 메모리에 연결되는 프로세서를 포함하고, 상기 프로세서는 음성 데이터를 수신하고, 및 상기 기 학습된 인공지능 네트워크 모델을 통해 상기 음성 데이터를 입력 자료로 하여 화자 정보를 출력하도록 구성되고, 상기 기 학습된 인공지능 네트워크 모델은 음성 데이터 셋을 수신하고, 상기 음성 데이터 셋으로부터 제1 화자에 대 한 제1 라벨 시퀀스 및 제2 화자에 대한 제2 라벨 시퀀스를 추정하고, 상기 제1 라벨 시퀀스를 기반으로 제1 타 겟 매트릭스 및 상기 제2 라벨 시퀀스를 기반으로 제2 타겟 매트릭스를 생성하고, 복수의 인코더 블록들 중 제1 인코더 블록의 적어도 2개의 헤드를 결정하고, 상기 적어도 2개의 헤드 중 제1 헤드로부터 상기 음성 데이터 셋 을 기반으로 제1 어텐션 매트릭스를 생성하고, 상기 적어도 2개의 헤드 중 제2 헤드로부터 상기 음성 데이터 셋 을 기반으로 제2 어텐션 매트릭스를 생성하고, 상기 제1 타겟 매트릭스, 상기 제2 타겟 매트릭스, 상기 제1 어 텐션 매트릭스 및 상기 제2 어텐션 매트릭스를 기반으로 제1 손실을 계산하고, 그리고 상기 제1 손실을 기반으 로 사전 학습될 수 있다. 본 발명의 실시 예에 따른 프로세서(processor)에 의해 실행 가능한 인공지능 알고리즘을 통해 방향 추정 방법 을 수행하기 위한 매체에 저장된 프로그램으로서, 음성 데이터를 수신하는 단계; 및 기 학습된 인공지능 네트워 크 모델을 통해 상기 음성 데이터를 입력 자료로 하여 화자 정보를 출력하는 단계를 포함하고, 상기 기 학습된 인공지능 네트워크 모델은 음성 데이터 셋을 수신하고, 상기 음성 데이터 셋으로부터 제1 화자에 대한 제1 라벨 시퀀스 및 제2 화자에 대한 제2 라벨 시퀀스를 추정하고, 상기 제1 라벨 시퀀스를 기반으로 제1 타겟 매트릭스 및 상기 제2 라벨 시퀀스를 기반으로 제2 타겟 매트릭스를 생성하고, 복수의 인코더 블록들 중 제1 인코더 블록 의 적어도 2개의 헤드를 결정하고, 상기 적어도 2개의 헤드 중 제1 헤드로부터 상기 음성 데이터 셋을 기반으로 제1 어텐션 매트릭스를 생성하고, 상기 적어도 2개의 헤드 중 제2 헤드로부터 상기 음성 데이터 셋을 기반으로 제2 어텐션 매트릭스를 생성하고, 상기 제1 타겟 매트릭스, 상기 제2 타겟 매트릭스, 상기 제1 어텐션 매트릭스 및 상기 제2 어텐션 매트릭스를 기반으로 제1 손실을 계산하고, 그리고 상기 제1 손실을 기반으로 사전 학습될 수 있다."}
{"patent_id": "10-2023-0065865", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 개시의 일 실시예에 따르면, 보조 손실의 부여를 통해 학습되는 패턴의 다양성을 증가시키고 효과적인 학습 이 가능하게 되고, 화자 분할 시스템의 성능이 향상될 수 있다."}
{"patent_id": "10-2023-0065865", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명의 기술적 사상은 다양한 변경을 가할 수 있고 여러 가지 실시 예를 가질 수 있는 바, 특정 실시 예들을 도면에 예시하고 이를 상세한 설명을 통해 상세히 설명하고자 한다. 그러나, 이는 본 발명의 기술적 사상을 특 정한 실시 형태에 대해 한정하려는 것이 아니며, 본 발명의 기술적 사상의 범위에 포함되는 모든 변경, 균등물 내지 대체물을 포함하는 것으로 이해되어야 한다. 본 발명의 기술적 사상을 설명함에 있어서, 관련된 공지 기술에 대한 구체적인 설명이 본 발명의 요지를 불필요 하게 흐릴 수 있다고 판단되는 경우 그 상세한 설명을 생략한다. 또한, 본 명세서의 설명 과정에서 이용되는 숫자(예를 들어, 제1, 제2 등)는 하나의 구성요소를 다른 구성요소와 구분하기 위한 식별기호에 불과하다. 또한, 본 명세서에서, 일 구성요소가 다른 구성요소와 \"연결된다\" 거나 \"접속된다\" 등으로 언급된 때에는, 상기 일 구성요소가 상기 다른 구성요소와 직접 연결되거나 또는 직접 접속될 수도 있지만, 특별히 반대되는 기재가 존재하지 않는 이상, 중간에 또 다른 구성요소를 매개하여 연결되거나 또는 접속될 수도 있다고 이해되어야 할 것이다. 또한, 본 명세서에 기재된 \"~부\", \"~기\", \"~자\", \"~모듈\" 등의 용어는 적어도 하나의 기능이나 동작을 처리하는 단위를 의미하며, 이는 프로세서(Processor), 마이크로 프로세서(Micro Processer), 마이크로 컨트롤러(Micro Controller), CPU(Central Processing Unit), GPU(Graphics Processing Unit), APU(Accelerate Processor Unit), DSP(Drive Signal Processor), ASIC(Application Specific Integrated Circuit), FPGA(Field Programmable Gate Array) 등과 같은 하드웨어나 소프트웨어 또는 하드웨어 및 소프트웨어의 결합으로 구현될 수 있으며, 적어도 하나의 기능이나 동작의 처리에 필요한 데이터를 저장하는 메모리(memory)와 결합되는 형태 로 구현될 수도 있다. 그리고 본 명세서에서의 구성부들에 대한 구분은 각 구성부가 담당하는 주기능 별로 구분한 것에 불과함을 명확 히 하고자 한다. 즉, 이하에서 설명할 2개 이상의 구성부가 하나의 구성부로 합쳐지거나 또는 하나의 구성부가 보다 세분화된 기능별로 2개 이상으로 분화되어 구비될 수도 있다. 그리고 이하에서 설명할 구성부 각각은 자 신이 담당하는 주기능 이외에도 다른 구성부가 담당하는 기능 중 일부 또는 전부의 기능을 추가적으로 수행할 수도 있으며, 구성부 각각이 담당하는 주기능 중 일부 기능이 다른 구성부에 의해 전담되어 수행될 수도 있음은 물론이다. 본 개시의 실시예들을 설명함에 있어서 관련된 기능 혹은 구성에 대한 구체적인 설명이 본 개시의 요지를 불필 요하게 흐릴 수 있다고 판단된 경우 그 상세한 설명은 생략한다. 그리고 후술되는 용어들은 본 개시에서의 기능 을 고려하여 정의된 용어들로서 이는 사용자, 운용자의 의도 또는 관례 등에 따라 달라질 수 있다. 그러므로 그 정의는 본 명세서 전반에 걸친 내용을 토대로 내려져야 할 것이다. 마찬가지 이유로 첨부 도면에 있어서 일부 구성요소는 과장되거나 생략되거나 개략적으로 도시될 수 있다. 또한, 각 구성요소의 크기는 실제 크기를 전적으로 반영하는 것이 아니다. 각 도면에서 동일한 또는 대응하는 구성요소에는 동일한 참조 번호를 부여하였다. 본 개시의 이점 및 특징, 그리고 그것들을 달성하는 방법은 첨부되는 도면과 함께 상세하게 후술되어 있는 실시 예들을 참조하면 명확해질 것이다. 그러나 본 개시는 이하에서 개시되는 실시예들에 한정되는 것이 아니라 서로 다른 다양한 형태로 구현될 수 있으며, 단지 실시예들은 본 개시의 설명이 완전하도록 하고, 본 개시의 실시예"}
{"patent_id": "10-2023-0065865", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "들이 속하는 기술분야에서 통상의 지식을 가진 자에게 발명의 범주를 완전하게 알려주기 위해 제공되는 것이며, 본 개시의 청구하고자 하는 범위는 청구항의 범주에 의해 정의될 뿐이다. 이때, 처리 흐름도를 보이는 도면들의 각 블록과 처리 흐름도 도면들의 조합들은 컴퓨터 프로그램 인스트럭션들 에 의해 수행될 수 있음을 이해할 수 있을 것이다. 이들 컴퓨터 프로그램 인스트럭션들은 범용 컴퓨터, 특수용 컴퓨터 또는 기타 프로그램 가능한 데이터 프로세싱 장비의 프로세서에 탑재될 수 있으므로, 컴퓨터 또는 기타 프로그램 가능한 데이터 프로세싱 장비의 프로세서를 통해 수행되는 그 인스트럭션들이 흐름도 블록(들)에서 설 명된 기능들을 수행하는 수단을 생성하게 된다. 이들 컴퓨터 프로그램 인스트럭션들은 특정 방식으로 기능을 구 현하기 위해 컴퓨터 또는 기타 프로그램 가능한 데이터 프로세싱 장비를 지향할 수 있는 컴퓨터 이용 가능 또는 컴퓨터 판독 가능 메모리에 저장되는 것도 가능하므로, 그 컴퓨터 이용가능 또는 컴퓨터 판독 가능 메모리에 저 장된 인스트럭션들은 흐름도 블록(들)에서 설명된 기능을 수행하는 인스트럭션 수단을 내포하는 제조 품목을 생 산하는 것도 가능하다. 컴퓨터 프로그램 인스트럭션들은 컴퓨터 또는 기타 프로그램 가능한 데이터 프로세싱 장 비 상에 탑재되는 것도 가능하므로, 컴퓨터 또는 기타 프로그램 가능한 데이터 프로세싱 장비 상에서 일련의 동 작 단계들이 수행되어 컴퓨터로 실행되는 프로세스를 생성해서 컴퓨터 또는 기타 프로그램 가능한 데이터 프로 세싱 장비를 수행하는 인스트럭션들은 흐름도 블록(들)에서 설명된 기능들을 실행하기 위한 단계들을 제공하는 것도 가능하다. 또한, 각 블록은 특정된 논리적 기능(들)을 실행하기 위한 하나 이상의 실행 가능한 인스트럭션들을 포함하는 모듈, 세그먼트 또는 코드의 일부를 나타낼 수 있다. 또, 몇 가지 대체 실행 예들에서는 블록들에서 언급된 기 능들이 순서를 벗어나서 발생하는 것도 가능함을 주목해야 한다. 예컨대, 잇달아 도시되어 있는 두 개의 블록들 은 사실 실질적으로 동시에 수행되는 것도 가능하고 또는 그 블록들이 때때로 해당하는 기능에 따라 역순으로 수행되는 것도 가능하다. 본 개시에서 사용되는 '~부(unit or part)'라는 용어는 소프트웨어 또는 FPGA(field-Programmable Gate Array) 또는 ASIC(Application Specific Integrated Circuit)과 같은 하드웨어 구성요소를 의미하며, '~부'는 특정한 역할들을 수행하도록 구성될 수 있다. 그렇지만 '~부'는 소프트웨어 또는 하드웨어에 한정되는 의미는 아니다. '~부'는 어드레싱할 수 있는 저장 매체에 있도록 구성될 수도 있고 하나 또는 그 이상의 프로세서들을 실행시키 도록 구성될 수도 있다. 따라서, 일 예로서 '~부'는 소프트웨어 구성요소들, 객체지향 소프트웨어 구성요소들, 클래스 구성요소들 및 태스크 구성요소들과 같은 구성요소들과, 프로세스들, 함수들, 속성들, 프로시저들, 서브 루틴들, 프로그램 코드의 세그먼트들, 드라이버들, 펌웨어, 마이크로코드, 회로, 데이터, 데이터베이스, 데이터 구조들, 테이블들, 어레이들, 및 변수들을 포함한다. 구성요소들과 '~부'들 안에서 제공되는 기능은 더 작은 수 의 구성요소들 및 '~부'들로 결합되거나 추가적인 구성요소들과 '~부'들로 더 분리될 수 있다. 뿐만 아니라, 구 성요소들 및 '~부'들은 디바이스 또는 보안 멀티미디어카드 내의 하나 또는 그 이상의 CPU들을 재생시키도록 구 현될 수도 있다. 또한 실시예에서 '~부'는 하나 이상의 프로세서 및/또는 장치를 포함할 수 있다. 이하, 본 발명의 기술적 사상에 따른 실시 예들을 차례로 상세히 설명한다. 도 1은 본 개시의 일 실시 예에 따른 인공지능 구조의 기본적인 원리를 나타낸 개념도이다. 도 1을 참조하면, 인공지능 구조에서 학습이 수행되는 기본적인 원리를 나타낸다. 인공지능 기술은 학습, 문제 해결, 인식 등과 같이 주로 인간 지능과 연결된 인지 문제를 해결하기 위한 기술을 나타낸다. 인공지능은 Machine learning(ML)이라고 불리는 기계 학습 방식과 Deep learning(DL)이라고 불리는 딥 러닝 방식을 통해 학습될 수 있다. 머신 러닝은 패턴 인식 및 학습에 사용되는 기법에 주로 사용되며 기록된 데이터를 학습하여 이를 기반으로 이후의 데이터를 예측하는 알고리즘을 나타낸다. 사전에 정의된 규칙이나 패 턴을 기반으로 하지 않고 데이터로부터 스스로 학습하는 기술을 나타낸다. 반면에 딥 러닝은 머신 러닝의 한 분 야로 인공 신경망(Artificial Neural Network: ANN)을 기반으로 하여 데이터를 처리하는 차이점이 있다. 딥 러닝은 인공 신경망을 이용하기 때문에 머신 러닝보다 더욱 복잡하고 정교한 연산을 처리할 수 있다. 딥 러닝을 위한 알고리즘 종류로는 합성곱 신경망(Convolution neural network: CNN), DNN(deep neural network), 인공 신경망(ANN), 순환 신경망(Recurrent Neural Network: RNN)등을 포함할 수 있다. 도 1을 참고하면, 인공지능 구조는 인공지능 모듈로 나타낼 수 있다. 인공지능 모듈은 소정의 입력 데이터를 수신하여 모듈에서 미리 정해진 방식을 통해 학습을 수행하고, 학습 결과에 대한 출력 데이터 를 출력하게 된다. 일 실시예에 따르면, 입력 데이터에는 소정의 데이터(ex 그림, 음성 등), 음성 신 호, 입력 시퀀스, 입력 피쳐(feature)(예를 들면, 피쳐 벡터)를 포함할 수 있다. 출력 데이터에는 출력 시 퀀스, 향상된 음성 신호, 음성 인식 정보, 화자 분할 정보, 라벨(label) 시퀀스, 화자 포스테리어(posterior) 등이 포함될 수 있다. 도 2는 본 개시의 일 실시예에 따른 인공지능 네트워크의 구조를 나타낸 도면이다. 도 2에서 사용되는 인공지능 알고리즘은 도 1의 인공지능 모듈의 종류 중 하나일 수 있다. 도 2를 참조하면, 인공지능 시스템의 구조는 음성 데이터와 인공지능 알고리즘 구조를 포함할 수 있다. 일 실시예에 따르면, 인공지능 알고리즘 구조는 데이터 전처리, 인공지능 학습, 출력 데이터 확인으로 단 계가 나뉘어질 수 있다. 본 개시에서는 일반적인 SA-EEND 딥러닝 모델을 바탕으로 구성될 수 있다. 음성 인식 시스템 또는 인공지능 알고리즘 모델에 음성 정보(음성 신호 또는 음성 데이터)가 입력될 수 있다. 상기 음성 정보는 로 T 길이를 갖는 피쳐(특징) 벡터일 수 있다. 음성 정보는 데이터 전처리를 통해 로그-멜 형태로 변형될 수 있다. 예를 들면, 화자 분할 시스템은 23차원의 로그-멜 필터뱅크 에너지를 추출하여 입 력 피쳐로 사용할 수 있다. 이 경우 프레임의 길이는 25ms로 10ms씩 프레임을 쉬프트하여 추출한 음향 피쳐 (acoustic feature)일 수 있다. 음성 인식 시스템은 입력 음성 정보를 기반으로 화자 라벨 시퀀스(또는 화자 타 겟 시퀀스) ( )를 예측할 수 있다. 입력된 로그-멜은 선형 계층(linear layer) 연산 및/ 또는 layernorm(LN) 연산(미도시)을 통해 수학식 1과 같이 임베딩(embedding)으로 변환될 수 있다. [수학식 1]"}
{"patent_id": "10-2023-0065865", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "변환된 임베딩은 수학식 2에 대응하여 복수의 인코더 블록들(215a 내지 215d)을 통해 임베딩 시퀀스(Ep)로 표현 될 수 있다. 여기서 t는 타임 프레임을 나타낼 수 있다. [수학식 2]"}
{"patent_id": "10-2023-0065865", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "인코더 블록들(215a 내지 215d)은 multi-head self attention (MHSA)와 fully connected feed-forward networks 구조로 구성될 수 있다. 여기서 MHSA는 입력 시퀀스의 각 위치에 대한 자기 어텐션을 수행하여 특징 정보를 추출할 수 있다. MHSA는 어텐션 메커니즘을 여러 개의 어텐션 헤드(head)로 확장하여 사용할 수 있다. 각 어텐션 헤드는 입력 시퀀스의 다른 위치와의 상관 관계를 계산하고, 각 위치에 대한 가중치를 결정할 수 있 다. 이를 통해 인공지능 알고리즘 모델은 입력 시퀀스의 다양한 부분 간의 관계를 모델링하고, 입력에 대한 다 양한 관점에서의 정보를 효과적으로 수집할 수 있다. 이 때, MHSA를 수행하는 각 어텐션 헤드는 수학식 3과 같이 scaled dot-product 방식으로 프레임-레벨 어텐션 가중치(frame-level attention weight)를 계산하여 글로벌 피쳐(global feature) 관계를 고려할 수 있다. [수학식 3]"}
{"patent_id": "10-2023-0065865", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "여기서 Q는 query, K는 key, V는 value를 나타내고 d는 hidden space의 차원, A는 어텐션 가중치 매트릭스를 나타낼 수 있다.인코더 블록들(215a 내지 215d)을 거친 후 수학식 4와 같이 다시 layer norm(LN) 연산 및 선형 계층 연산 을 수행하고, sigmoid 연산을 통해 화자 정보(예를 들어, 화자 포스테리어(speaker posterior))( )를 출력할 수 있다. 획득된 화자 포스테리어는 시퀀스의 형태로 변형될 수 있다. [수학식 4]"}
{"patent_id": "10-2023-0065865", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "이를 기반으로 모델을 학습시키기 위해 예측한 정답 라벨 시퀀스(또는 타겟 라벨(ground truth label)(yt)와 획 득된 화자 포스테리어( ) 간의 순열 불변(permutation invariant)(φ)를 고려하여 이진 교차 엔트로피 (binary cross entropy: BCE) 손실을 계산하는 수식은 수학식 5와 같다. [수학식 5]"}
{"patent_id": "10-2023-0065865", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 7, "content": "여기서 H는 이진 교차 엔트로피 손실을 나타내고, s는 화자의 수를 나타낼 수 있다. SS-EEND 시스템에서 학습을 위한 손실인 화자 분할 손실( )는 수학식 6과 같이 계산될 수 있다. [수학식 6]"}
{"patent_id": "10-2023-0065865", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 8, "content": "여기서 는 화자의 모든 가능 순열을 나타내고, 는 화자 순열에 따른 화자 라벨 시퀀스를 나타낼 수 있다. 도 2에서는 출력에 따라 2개의 화자 순열에 따른 화자 라벨 시퀀스(240a, 240b)를 가지는 것으로 나타난다. 각 각의 화자 순열에 따른 화자 라벨 시퀀스(240a, 240b)와 화자 라벨 시퀀스(또는 화자 타겟 시퀀스)를 기반 으로 화자 분할 손실을 계산할 수 있다. 도 2를 참조하면, 트랜스포머 인코더 기반의 종단간 화자 분할 시스템에서, self attention을 계산하는 어텐션 헤드의 학습을 도모하기 위하여 추가적인 보조 손실을 정의할 수 있다. 첫번째로, 헤드가 각 화자의 음성 패턴 학습을 수행하기 위한 화자 별(speaker-wise) VAD(voice activity detection) 손실(SVAD 손실, ( )(290a, 290b)을 설정할 수 있다. SVAD 손실은 화자 라벨 시퀀스( )를 이용하여 SVAD 타겟 매트릭스(또는 타겟 마스크)( )를 도출하여 BCE loss(290a, 290b)를 구하는 방식으로 계산될 수 있다. 예를 들어, 타겟 매트릭스 는 타겟 시퀀스에 상응하여 10x10의구조로 결정될 수 있다. 타겟 매트릭스는 트랜스포머 인코더의 어텐션 매트 릭스와 동일한 구조를 가질 수 있다. 타겟 매트릭스는 타겟 시퀀스의 시간 및 음성 정보를 기반으로 결정될 수 있다. SVAD 손실(290a, 290b)을 계산하는 방식은 수학식 7 및 8과 같다. [수학식 7]"}
{"patent_id": "10-2023-0065865", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 9, "content": "[수학식 8] 여기서, 는 SVAD 손실을 부여하고자 하는 h번째 self 어텐션 헤드에서 계산된 어텐션 가중치 매트릭스이고, 는 각각 의 (i,j)번째 요소를 나타낼 수 있다. 일 예로, 4번째 인코더 블록(215d)에서 어텐션 매트릭스(270b)를 결정하고, 어텐션 매트릭스의 4개의 헤드 중 2개의 어텐션 헤드의 어텐션 매트릭스(280a, 280b)를 결정하여 화자 라벨 시퀀스로부터 도출된 SVAD 타겟 마스크들(또는 타겟 매트릭스)(260a, 260b)을 기반으로 BCE 손실을 결정할 수 있다. 이를 통해 SVAD 손실(290a, 290b)를 계산할 수 있다. 다음으로, 헤드가 전반적인 음성 활동(speech activity) 패턴의 학습을 수행할 수 있도록 중복 음성 감지 (overlapped speech detection) 손실(OSD 손실, )를 추가 설정할 수 있다. OSD 손실을 부여하기 위하여 OSD 라벨 시퀀스( )를 수학식 9와 같이 정의할 수 있다. 일 실시예에서 OSD 라벨 시퀀스의 k값을 음성, 비음성, 중첩구간을 구분하기 위하여 로 설정할 수 있다. [수학식 9]"}
{"patent_id": "10-2023-0065865", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 10, "content": "상기 OSD 라벨 시퀀스를 기반으로 수학식 10과 같이 SVAD 손실을 구하는 방식과 동일한 방식으로 행렬 연산을 통해 OSD 타겟 매트릭스(또는 타겟 마스크)( )를 생성하여 생성된 타겟 매트릭스를 이용해 수학식 11과 같 이 평균 제곱 오차(mean squared error: MSE)를 통해 OSD 손실( )을 계산할 수 있다. 예를 들어, OSD 타겟 매 트릭스는 제1 화자 및 제2 화자의 타겟 시퀀스에서 중복되는 부분에 대하여 매트릭스화 한 것일 수 있다. [수학식 10]"}
{"patent_id": "10-2023-0065865", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 11, "content": "[수학식 11]"}
{"patent_id": "10-2023-0065865", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 12, "content": "여기서, 는 각각 의 (i,j)번째 요소를 나타내고, 는 OSD 손실을 부여하고자 하는 어텐션 헤드의 가중치 매트릭스의 (i,j)번째 요소를 나타낼 수 있다. 도 2를 참조하면, 타겟 시퀀스를 기반으로 OSD 라벨 시퀀스를 도출하고, OSD 라벨 시퀀스를 기반으로 OSD 타겟 매트릭스(260c)를 생성할 수 있다. 첫번째 인코더 블록(215a)에서 4개의 어텐션 헤드를 가지는 어텐션 매 트릭스(270a)를 추출하고 그 중 하나의 헤드의 어텐션 매트릭스를 추출하여, 생성된 OSD 타겟 매트릭스 (260c)를 기반으로 OSD 손실를 계산할 수 있다. 상기 추가로 정의한 두 종류의 보조 손실(SVAD 손실, OSD 손실)을 부여하는 방법으로 이후 도 4의 (a)에 나타난 것과 같이 단위 행렬의 형태와 가장 유사한 형태를 가지는 헤드부터 순서대로 부여하는 방식을 취할 수 있다. 즉, 손실을 부여할 헤드로 단위 행렬과 패턴이 유사한 헤드를 찾기 위하여 연산되는 어텐션 가중치 매트 릭스의 대각 합을 계산하고, 이때 가장 큰 값을 가지는 헤드에 대하여 보조 손실을 부여하는 방식을 사용할 수 있다. 따라서, 종래의 손실인 화자 분할 손실과 새로 부여한 보조 손실(SVAD 손실, OSD 손실)은 수학식 12와 같은 방 식으로 모두 결합되어 인공지능 알고리즘 모델, 화자 분할 시스템의 학습에 사용될 수 있다.[수학식 12]"}
{"patent_id": "10-2023-0065865", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 13, "content": "여기서 및 는 hyperparameter로 실험을 통해 결정될 수 있으며, 예를 들어, 모두 0 내지 1 이내의 값으로 설정할 수 있다. 도 2에서는 음성 활동과 화자 활동 타겟을 이용하여 새로운 타겟을 생성하고, 생성한 타겟과 특정 인코더의 헤 드 간의 BCE 손실 또는 MSE를 계산하여 보조 손실을 부여하는 방식으로 기존의 순열 불변 학습 방법에 추가한 것일 수 있다. 일 실시예로, 음성 인식 알고리즘은 파이썬을 기반으로 한 딥러닝 툴킷인 파이토치를 사용하여 구현될 수 있다. 학습을 위하여 switchboard-2, switchboard cellular, NIST speaker recognition evaluation 데이터 셋을 기반 으로 2명의 화자에 대해 시뮬레이션 하여 생성한 데이터 셋을 사용할 수 있다. 실제 환경에서의 음성인 CALLHOME 데이터셋을 이용하여 학습 및 평가할 수 있다. 시뮬레이션 데이터의 각 화자 별 발화는 10-20개의 범 위에서 랜덤하게 선택하고, 반향(reverberation)과 MUSAN 데이터 셋의 잡음을 섞어 생성할 수 있다. 모든 데이 터 셋은 전화망에서 녹음될 수 있다. 도 3은 본 개시의 일 실시예에 따른 인공지능 알고리즘 모델과 기존 종단간 화자 분할 시스템의 성능을 나타낸 표이다. 도 3에서 사용된 인공지능 알고리즘은 도 2의 인공지능 모듈과 동일한 것일 수 있다. 도 3에서는 사용된 인공지능 모델들에 대하여 분할 오류율(diarization error rate: DER)을 측정한 것이다. DER 은 수치가 낮을수록 성능이 좋은 것으로 해석될 수 있다. 실험에 사용된 데이터 셋인 Sim2spk 및 CH(CALLHOME)은 각각 시뮬레이션한 데이터와 실제 환경에서 녹음된 데이터 셋이며, 두 데이터셋 모두 전화 망 환경의 대화를 포함한다. Sim2spk에서는 가중치를 34.4, 27.3, 19.6 3가지로 설정하여 테스트를 진행하 였다. 성능을 테스트하기 위해 사용된 인공지능 모델은 다음과 같다. SA-EEND SA-EEND↑ RX-EEND RX-EEND↑ SVAD 손실만 추가 부여한 모델 OSD 손실만 추가 부여한 모델 SVAD 및 OSD 손실 모두를 추가 부여한 모델 여기서 RX-EEND(residual auxiliary end-to-end speech recognition)으로 잔류 보조 손실을 기반으로 음성 인 식을 수행하는 알고리즘 모델일 수 있다. , 모델(↑가 붙은 모델, 도면에서는 십자가 모양)은 기존 모델 에 대하여 논문에 제안된 성능이 아닌 해당 모델에 대한 제안된 방법을 직접 설계하여 실험했을 때의 결과를 나 타낸 것이다. 또한, , 모델에 대하여는 4개의 트랜스포머 인코더 헤드에서 몇 번째 인코더 헤드를 기반으로 추가 손실 을 계산할 건지를 구분하여 실험을 진행하였으며, 모델에서는 SVAD 손실의 경우 4번째 인코더 헤드를 고정으 로 하고 OSD 손실만 인코더 헤드를 다르게 하여 테스트를 진행하였다. 도 3을 참조하면, 종래의 인공지능 알고리즘 모델인 SA-EEND(305, 310)와 SA-EEND보다 개선된 방식인 RX- EEND(315, 320)에 대하여 RX-EEND(315, 320)에서의 성능이 높게 나타나는 것을 확인할 수 있다. 도 2에서 제안 한 인공지능 알고리즘 모델에서는 SVAD 손실만을 부여한 모델에서는 1-4번째 인코더 헤드 중에서 4번째 인 코더 헤드에 SVAD 손실을 부여한 경우 가장 성능이 좋은 것을 확인할 수 있었다. OSD 손실만을 부여한 모델에서는 1-4번째 인코더 헤드 중 2번째 인코더 헤드를 제외한 나머지 인코더들에서는 대체로 유사한 성능을 나타내었다. 위 실험 결과를 반영하여 SVAD 손실과 OSD 손실 모두를 부여한 모델에서는 SVAD 손실을 4번째 인코더 헤드에 부여하는 것으로 고정한 뒤 OSD 손실만을 인코더 헤드를 변경하며 실험을 진행하였다. OSD 손실 만을 부여한 모델에서는 근소하게나마 4번째 인코더 헤드에 손실을 부여했을 때 가장 성능이 잘 나오는 것으로 확인되었으나, 두 가지 손실을 모두 부여한 경우에는 OSD 손실을 첫번째 인코더 헤드에 부여한 경우에 가 장 성능이 뛰어난 것을 확인할 수 있었다. 그리고 보조 손실 각각을 따로 부여한 모델들과 비교하여 손실들 모 두를 부여하여 학습시킨 모델이 성능이 좋았으며, RX-EEND와 비교하여 유사한 정도의 성능을 나타낼 수 있 었다. 다만, RX-EEND 모델의 경우 모든 인코더 블록에서 순열 분열 방식으로 학습해야 하므로 연산량이 크 다는 단점이 있어 연산량을 줄이고 유사한 성능을 가질 수 있음을 확인할 수 있다. 도 4는 본 개시의 실시예에 따른 인공지능 알고리즘 모델 및 종래의 알고리즘 모델에 대한 인코더 블록의 헤드 를 도식화한 것이다. 도 4에서는 보조 손실이 트랜스포머 인코더 블록에 미치는 영향을 확인하기 위하여 각 헤드의 어텐션 행렬을 시 각화 한 것이다. 도 4는 도 3에서 설명한 (a) SA-EEND, (b) RX-EEND, (c) SVAD 손실만을 부여한 모 델, (d) OSD 손실만을 부여한 모델, (e)는 SA-EEND에 두 가지 보조 손실을 모두 부여한 모델을 나타낸 것이다. 각각의 모델에 대하여, 4개의 헤드로 구분하고 각각의 헤드에 대해 어텐션 가중치 매트리스의 패턴이 명확하게 나타나는 지를 확인한다. 도 4를 참조하면, 헤드 1 및 헤드 2 에서는 보조 손실을 하나씩 부여한 (c)모델과 (d)모델 에서 관찰된 패턴이 (a)모델에서 관찰된 패턴과 다르게 나타난다. (e)모델에서 관찰된 패턴은 (c)모델에서의 패턴과 유사하게 나타난다. 이를 기반으로, OSD 손실과 SVAD 손실이 모두 동일한 인코더 블 록에 부여되는 경우 OSD 손실보다 SVAD 손실에 더 많은 영향을 받을 수 있음을 나타낸다. 또한, 헤드 3 및 헤드 4 의 경우 모델에서의 패턴이 (a)모델에서의 패턴과 유사한 것 을 확인할 수 있다. 이를 통해 (b)모델의 경우 (a)모델을 개선할 때 주로 마지막 블록 외에 하위 인 코더 블록에 적용된 보조 BCE 손실에 기인한 것이라고 판단될 수 있다. 또한 2번째 헤드의 경우 보조 손실 부여 를 하여도 크게 영향을 끼치지 않음을 확인할 수 있었다. 결론적으로, 보조 손실을 부여한 모델들(430, 440, 450)의 경우 종래의 기본 모델인 (a)모델 에 비하여 더 명확한 패턴을 나타내는 것을 확인할 수 있었다. 도 5는 본 개시의 일 실시예에 따른 인공지능 알고리즘 모델에 대해 보조 손실을 부여하는 헤드를 선택하는 방 법에 따른 성능의 변화를 나타낸 것이다. 도 5에서의 인공지능 알고리즘은 도 2 내지 도 4에서의 보조 손실을 부여한 인공지능 알고리즘 모델(또는 화자 분할 시스템)일 수 있다. 도 5를 참조하면, SVAD 손실만을 부여한 모델, OSD 손실만을 부여한 모델, 두 가지 보조 손실을 모두 부여한 모델을 사용하여 실험을 진행하였다. 이 경우, 3가지 모델 모두에서 보조 손실을 부여할 때 임의로 헤드를 선택하여 보조 손실을 부여하는 것보다 단위 행렬의 패턴을 나타내는 헤드(즉, 도 4에 따라 두 손실 모 두 4번째 헤드)에 보조 손실을 부여하는 것이 성능이 더 좋게 나타나는 것을 확인할 수 있었다. 여기서, 단위 행렬의 패턴을 나타내는 헤드를 결정하기 위하여 대각합이 가장 큰 값을 나타내는 헤드를 결정할 수 있다. 도 6은 본 개시의 일 실시예에 따른, 화자 분할을 위한 전자 장치에 대한 블록 구성도이다. 도 6을 참조하면, 전자 장치는 모뎀(MODEM, 620), 메모리(MEMORY, 640) 및 프로세서(PROCESSOR, 630)를 포함할 수 있다. 모뎀은 다른 전자 장치들과 전기적으로 연결되어 상호 통신이 이뤄지도록 하는 통신 모뎀일 수 있다. 특히 모뎀은 데이터 입력을 수신하여 프로세서로 전송할 수 있고, 프로세서는 입력된 데이터 값을 메 모리에 저장할 수 있다. 또한, 시스템에서 학습된 인공지능 알고리즘에 의해 출력된 데이터 값 또는 정보 를 다른 전자 장치로 전송할 수 있다.메모리는 전자 장치의 동작을 위한 각종 정보 및 프로그램 명령어들이 저장되는 구성으로서, 하드 디 스크(Hard Disk), SSD(Solid State Drive) 등과 같은 기억장치일 수 있다. 특히, 메모리는 프로세서(63 0)의 제어에 의해 모뎀에서 입력되는 하나 이상의 데이터 입력 값을 저장할 수 있다. 또한, 메모리는 프로세서에 의해 실행 가능한 음성 인식을 위한 인공지능 알고리즘과 같은 프로그램 명령어들을 저장할 수 있다. 또한, 메모리는 본 개시에서 설명한 추가적인 보조 손실을 부여하는 방식 통해 학습된 인공지능 알 고리즘과 같은 프로그램 (또는 프로그램 명령어)를 저장할 수 있다. 프로세서는 적어도 하나의 프로세서로 구성되며, 메모리에 저장된 데이터 및 프로그램 명령어들을 이 용하여 음성 사건 검출과 관련된 인공지능 알고리즘을 학습하고 이를 활용하여 데이터를 계산할 수 있다. 프로 세서는 도 1 내지 도 5에서 설명한 모든 인공지능 알고리즘을 제어하고 계산할 수 있다. 프로세서는 이후 도 7에서 설명하는 방법에 대한 동작을 수행할 수 있다. 도 7은 본 개시의 일 실시예에 따른 화자 분할 방법을 설명하기 위한 순서도이다. 이하 도 7을 참조하여, 도 1 내지 도 6을 참조하여 설명한 전자 장치의 인공지능 알고리즘의 학습 동작 및 화자 분할 방법에 대해 정리하여 설명한다. 각 동작들은 일련의 과정에서 필수적으로 포함되어야 하는 동작들은 아니 며 상황에 따라 일부만이 구성되어 동작할 수 있다. 단계 S710에서, 인공지능을 통한 화자 분할을 수행하기 위하여 음성 데이터를 수신할 수 있다. 상기 음성 데이 터는 입력 정보로 활용되어 인공지능을 학습시키는데 사용될 수 있다. 상기 음성 데이터는 적어도 하나의 화자 의 음성이 포함될 수 있다. 단계 S720에서, 기 학습된 인공지능 네트워크 모델을 통해 상기 음성 데이터를 입력 자료로 하여 화자 정보를 출력할 수 있다. 상기 화자 정보는 화자에 따른 음성 정보, 화자 포스테리어(speaker posterior)(예를 들어, 도 2의 화자 포스테리어), 화자 순열 정보 등이 포함될 수 있다. 상기 기 학습된 인공지능 네트워크 모델은 화자 분할 시스템 또는 화자 분할을 위한 전자 장치에 포함될 수 있 다. 상기 기 학습된 인공지능 네트워크 모델은 음성 데이터 셋을 수신할 수 있다. 상기 음성 데이터 셋에 포함 된 음성 정보는 피쳐 벡터의 형태일 수 있다. 상기 음성 정보는 로그-멜 형태로 인공지능 알고리즘 모델에서 변 환될 수 있다. 상기 음성 데이터 셋으로부터 제1 화자에 대한 제1 라벨 시퀀스 및 제2 화자에 대한 제2 라벨 시퀀스(예를 들 어, 도 2의 화자 라벨 시퀀스)를 추정할 수 있다. 상기 제1 라벨 시퀀스를 기반으로 제1 타겟 매트릭스(예를 들어, 도 2의 SVAD 타겟 매트릭스(260a)) 및 상기 제 2 라벨 시퀀스를 기반으로 제2 타겟 매트릭스(예를 들어, 도 2의 SVAD 타겟 매트릭스(260b))를 생성할 수 있다. 복수의 인코더 블록들(예를 들어, 도 2의 인코더 블록들(215a 내지 215d) 중 제1 인코더 블록(예를 들어, 도 2 의 인코더 블록(215d))의 적어도 2개의 헤드(예를 들어, 도 2의 어텐션 매트릭스(280a, 280b))를 결정할 수 있 다. 상기 적어도 2개의 헤드 중 제1 헤드(예를 들어, 도 2의 어텐션 매트릭스(280a))로부터 상기 음성 데이터 셋을 기반으로 제1 어텐션 매트릭스를 생성할 수 있다. 상기 적어도 2개의 헤드 중 제2 헤드(예를 들어, 도 2의 어텐션 매트릭스(280b))로부터 상기 음성 데이터 셋을 기반으로 제2 어텐션 매트릭스를 생성할 수 있다. 상기 제1 타겟 매트릭스, 상기 제2 타겟 매트릭스, 상기 제1 어텐션 매트릭스 및 상기 제2 어텐션 매트릭스를 기반으로 제1 손실을 계산할 수 있다. 상기 제1 손실을 기반으로 사전 학습될 수 있다. 추가적으로, 상기 제1 어텐션 매트릭스 및 상기 제2 어텐션 매트릭스는 화자의 음성 패턴을 기반으로 결정될 수 있다. 상기 제1 손실은 상기 제1 타겟 매트릭스 및 상기 제1 어텐션 매트릭스 간의 이진 교차 엔트로피(binary cross entropy: BCE) 손실(예를 들어, 도 2의 BCE 손실(290a))과 상기 제2 타겟 매트릭스 및 상기 제2 어텐션 매트릭스 간의 BCE 손실(예를 들어, 도 2의 BCE 손실(290b))을 결합하여 계산될 수 있다. 추가적으로, 상기 기 학습된 인공지능 네트워크 모델은 상기 제1 라벨 시퀀스 및 상기 제2 라벨 시퀀스를 기반 으로 제3 라벨 시퀀스(예를 들어, 도 2의 OSD 라벨 시퀀스)를 생성하고, 상기 제3 라벨 시퀀스를 기반으로 제3 타겟 매트릭스(예를 들어, 도 2의 OSD 타겟 매트릭스(260c))를 생성하고, 상기 복수의 인코더 블록들 중 제2 인 코더 블록(예를 들어, 도 2의 인코더 블록(215a))의 제2 헤드를 결정하고, 상기 제2 헤드로부터 상기 음성 데이터 셋을 기반으로 제3 어텐션 매트릭스(예를 들어, 도 2의 어텐션 매트릭스)를 생성하고, 상기 제3 타겟 매트릭스 및 상기 제3 어텐션 매트릭스를 기반으로 제2 손실(예를 들어, 도 2의 OSD 손실)을 계산하고, 상 기 제1 손실에 상기 제2 손실을 결합한 손실을 기반으로 사전 학습될 수 있다. 추가적으로, 상기 제3 라벨 시퀀스는 상기 제1 라벨 시퀀스 및 상기 제2 라벨 시퀀스가 중첩되는 지(예를 들어, 수학식 9의 요소 k)를 나타내는 요소를 포함할 수 있다. 추가적으로, 상기 제3 라벨 시퀀스는 상기 음성 데이터 셋의 음성 활동 패턴을 기반으로 결정되고, 상기 제2 손 실은 상기 제3 타겟 매트릭스 및 상기 제3 어텐션 매트릭스 간의 평균 제곱 오차(mean square error: MSE)로 계 산될 수 있다. 추가적으로, 상기 기 학습된 인공지능 네트워크 모델은 상기 음성 데이터 셋을 기반으로 상기 복수의 인코더 블 록들을 통해 화자 포스테리어(speaker posterior)(예를 들어, 도 2의 화자 포스테리어)를 생성하고, 상기 음성 데이터 셋을 기반으로 제4 라벨 시퀀스(예를 들어, 도 2의 라벨 시퀀스)를 추정하고, 상기 생성한 화 자 포스테리어 및 상기 제4 라벨 시퀀스를 기반으로 제3 손실(예를 들어, 도 2의 화자 분할 손실))을 계산할 수 있다. 추가적으로, 상기 기 학습된 인공지능 네트워크 모델은 상기 제1 손실, 상기 제2 손실, 및 상기 제3 손실을 결 합한 손실을 기반으로 사전 학습되고, 상기 제3 손실은 상기 화자 포스테리어와 상기 제4 라벨 시퀀스 간의 BCE 손실(예를 들어, 도 2의 BCE 손실)일 수 있다. 이상, 본 발명의 기술적 사상을 다양한 실시 예들을 들어 상세하게 설명하였으나, 본 발명의 기술적 사상은 상 기 실시 예들에 한정되지 않고, 본 발명의 기술적 사상의 범위 내에서 당 분야에서 통상의 지식을 가진 자에 의 하여 여러가지 변형 및 변경이 가능하다."}
{"patent_id": "10-2023-0065865", "section": "도면", "subsection": "도면설명", "item": 1, "content": "본 발명의 상세한 설명에서 인용되는 도면을 보다 충분히 이해하기 위하여 각 도면의 간단한 설명이 제공된다. 도 1은 본 개시의 일 실시 예에 따른 인공지능 구조의 기본적인 원리를 나타낸 개념도이다. 도 2는 본 개시의 일 실시예에 따른 인공지능 네트워크의 구조를 나타낸 도면이다. 도 3은 본 개시의 일 실시예에 따른 인공지능 알고리즘 모델과 기존 종단간 화자 분할 시스템의 성능을 나타낸 표이다. 도 4는 본 개시의 실시예에 따른 인공지능 알고리즘 모델 및 종래의 알고리즘 모델에 대한 인코더 블록의 헤드 를 도식화한 것이다. 도 5는 본 개시의 일 실시예에 따른 인공지능 알고리즘 모델에 대해 보조 손실을 부여하는 헤드를 선택하는 방 법에 따른 성능의 변화를 나타낸 것이다. 도 6은 본 개시의 일 실시예에 따른, 화자 분할을 위한 전자 장치에 대한 블록 구성도이다. 도 7은 본 개시의 일 실시예에 따른 화자 분할 방법을 설명하기 위한 순서도이다."}
