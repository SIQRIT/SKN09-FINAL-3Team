{"patent_id": "10-2022-0048998", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0149594", "출원번호": "10-2022-0048998", "발명의 명칭": "증강현실 영상 표시 방법", "출원인": "주식회사 큐에스", "발명자": "신준범"}}
{"patent_id": "10-2022-0048998", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "대상 객체의 공간 상에서의 오리엔테이션과 크기를 고려한 증강현실 영상 표시 방법에 있어서,대상 객체의 색상 정보를 포함하는 제1 영상 및 상기 대상 객체의 깊이(Depth) 정보를 포함하는 제2 영상을 획득하는 단계로써, 상기 제1 영상 및 상기 제2 영상은 동일한 제1 장면을 촬영한 영상이고;상기 제1 영상 내에서 상기 대상 객체에 해당하는 제1 영역을 설정하는 단계;상기 제2 영상에서 상기 제1 영역에 상응하는 제2 영역을 설정하는 단계;상기 제1 영상으로부터 생성된 상기 대상 객체의 식별 정보를 이용하여 기준 모델을 로드 하는 단계;상기 제2 영역과 상기 기준 모델의 비교 결과에 기초하여 상기 제2 영상에서의 상기 대상 객체의 크기, 오리엔테이션 및 위치를 결정하는 단계; 및상기 대상 객체의 크기, 오리엔테이션 및 위치 중 적어도 하나를 참조하여 상기 제1 영상 상에 상기 대상 객체와 관련된 정보를 나타내는 제3 영상을 표시하는 단계; 를 포함하는, 증강현실 영상 표시 방법."}
{"patent_id": "10-2022-0048998", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "청구항 1에 있어서상기 제1 영역을 설정하는 단계는학습된 인공 신경망을 이용하여 상기 제1 영상으로부터 상기 대상 객체에 해당하는 제1 영역 및 상기 대상 객체의 상기 식별 정보를 결정하는 단계; 를 포함하고,상기 인공 신경망은 입력된 영상에 대해 상기 입력된 영상 내에서 객체에 해당하는 영역과 객체의 식별 정보를 출력하도록 학습된신경망인, 증강현실 영상 표시 방법."}
{"patent_id": "10-2022-0048998", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "청구항 1에 있어서상기 기준 모델은 상기 대상 객체의 3차원 형상을 포함하는 모델이고,상기 대상 객체의 크기, 오리엔테이션 및 위치를 결정하는 단계는상기 제2 영역 내의 깊이 정보로부터 도출되는 3차원 형상과 상기 기준 모델에 포함된 상기 대상 객체의 3차원형상 간의 비교를 통해 상기 제1 장면에서 상기 대상 객체의 크기, 오리엔테이션 및 위치를 결정하는 단계; 를포함하고,상기 크기는상기 대상 객체의 소정의 기준 크기에 대한 상기 제1 장면에서의 대상 객체의 크기의 비율을 포함하고,상기 오리엔테이션은적어도 하나의 기준 방향에 대한 상기 대상 객체의 회전 정도를 포함하고,상기 위치는상기 대상 객체에 대해 설정된 소정의 기준 지점의 상기 제1 장면에서의 위치를 포함하는, 증강현실 영상 표시방법."}
{"patent_id": "10-2022-0048998", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "공개특허 10-2023-0149594-3-청구항 1에 있어서상기 제3 영상을 표시하는 단계는상기 대상 객체의 크기, 오리엔테이션 및 위치를 고려하여 상기 대상 객체를 구성하는 적어도 하나의 부품을 상기 대상 객체에 인접하여 나열한 제3 영상을 표시하는 단계; 를 포함하는, 증강현실 영상 표시 방법."}
{"patent_id": "10-2022-0048998", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "청구항 4에 있어서상기 제3 영상을 표시하는 단계는상기 대상 객체의 오리엔테이션과 상기 적어도 하나의 부품의 결합 방향 및 결합 순서 중 적어도 하나에 따라상기 적어도 하나의 부품의 표시 위치를 결정하는 단계; 를 더 포함하는, 증강현실 영상 표시 방법."}
{"patent_id": "10-2022-0048998", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "청구항 1에 있어서상기 증강현실 영상 표시 방법은상기 대상 객체의 크기, 오리엔테이션 및 위치를 결정하는 단계 이후에,상기 기준 모델로부터 제4 영상을 생성하여 상기 제1 영상의 적어도 일부를 상기 제4 영상으로 대체하여 표시하는 단계; 를 더 포함하는, 증강현실 영상 표시 방법."}
{"patent_id": "10-2022-0048998", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "청구항 6에 있어서상기 제4 영상으로 대체하여 표시하는 단계는상기 대상 객체의 크기 및 오리엔테이션을 고려하여 상기 기준 모델로부터 프로젝션 영상인 상기 제4 영상을 생성하는 단계; 를 포함하고,상기 프로젝션 영상은 상기 기준 모델이 상기 결정된 대상 객체의 크기이고 상기 오리엔테이션에 따라 회전된 상태에서의 2차원 영상인, 증강현실 영상 표시 방법."}
{"patent_id": "10-2022-0048998", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 대상 객체의 공간 상에서의 오리엔테이션과 크기를 고려한 증강현실 영상 표시 방법으로, 대상 객체의 깊이 정보에 기반하여 대상 객체의 크기, 오리엔테이션 및 위치를 결정하고 이에 기반하여 증강현실 영상표시하 는 방법에 관한 것이다."}
{"patent_id": "10-2022-0048998", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 대상 객체의 공간 상에서의 오리엔테이션과 크기를 고려한 증강현실 영상 표시 방법으로, 대상 객체 의 깊이 정보에 기반하여 대상 객체의 크기, 오리엔테이션 및 위치를 결정하고 이에 기반하여 증강현실 영상을 표시하는 방법에 관한 것이다."}
{"patent_id": "10-2022-0048998", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "구조물이나 기계장치의 유지관리를 하기 위해서는 수년간의 경험이 필요하고, 숙련자라 할지라도 신규 구조물이 나 기계장치의 도입 시 이를 숙지하는데 오랜 시간이 소요된다. 통상 정비사들은 설비의 유지 보수를 위한 매뉴 얼을 항상 휴대하여 유지 보수 업무를 수행하여 왔다. 종래의 2차원 매뉴얼은 단순히 구성요소의 설명과 2차원 도면으로만 각 부품을 확인할 수 있도록 작성되어 있어, 사용자가 부품의 상세 설명을 확인하거나 상세 구성을 분해, 조립, 회전, 확대, 축소하는 것이 불가한 한 계점이 있었다. 이러한 문제점을 해결하기 위하여, 실사 영상을 기반으로 한 정비 매뉴얼 단말기를 제공하는 방법이 안출 되었 다. 선행기술문헌 1을 참조하면, 실사 영상을 기반으로 한 정비 매뉴얼 단말기는 정비하고자 하는 영역을 카메 라로 촬영하여 무선통신을 통해 정비 가이드 관리 서버로 전송하고, 정비 가이드 관리 서버는 전송받은 실사 영 상을 분석하여 이에 따른 정비 가이드 영상을 무선통신을 통해 정비 매뉴얼 단말기로 전송함으로써, 정비하고자하는 영역에 대해서 실사 영상으로 구현된 정비 가이드를 실시간으로 제공받을 수 있게 된다. 하지만, 이와 같은 종래의 객체 인식 기법은 2차원 이미지가 중점적으로 사용되어 왔으며, 단순히 관련된 정보 를 표시하는 것에 불과했기에 제공된 정보에 기반하여 사용자의 추가적인 노력을 요한다는 한계점이 있었다. 선행기술문헌 특허문헌 (특허문헌 0001) 1. 한국 특허 등록 제 10-1195446 호 (발명의 명칭 : 증강현실 기반의 정비 가이드 제공 단말 기 및 이를 이용한 정비 가이드 제공 방법)"}
{"patent_id": "10-2022-0048998", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "이에, 본 발명은 단말에서 획득된 영상 내의 객체를 인식하고, 인식된 객체의 정보를 실시간 영상 상에 표시하 고자 한다. 또한 본 발명은 인식된 객체와 관련된 정보를 실시간 영상 내 증강 현실로 표시하되, 영상 내에서의 객체의 크 기와 오리엔테이션을 고려하여 제공하고자 한다. 또한 본 발명은 실시간 영상의 일부를 대체하여 보다 더 상세한 정보를 갖는 영상을 제공하고자 한다."}
{"patent_id": "10-2022-0048998", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 일 실시예에 따른 대상 객체의 공간 상에서의 오리엔테이션과 크기를 고려한 증강현실 영상 표시 방 법은, 대상 객체의 색상 정보를 포함하는 제1 영상 및 상기 대상 객체의 깊이(Depth) 정보를 포함하는 제2 영상 을 획득하는 단계로써, 상기 제1 영상 및 상기 제2 영상은 동일한 제1 장면을 촬영한 영상이고; 상기 제1 영상 내에서 상기 대상 객체에 해당하는 제1 영역을 설정하는 단계; 상기 제2 영상에서 상기 제1 영역에 상응하는 제 2 영역을 설정하는 단계; 상기 제1 영상으로부터 생성된 상기 대상 객체의 식별 정보를 이용하여 기준 모델을 로드 하는 단계; 상기 제2 영역과 상기 기준 모델의 비교 결과에 기초하여 상기 제2 영상에서의 상기 대상 객체 의 크기, 오리엔테이션 및 위치를 결정하는 단계; 상기 대상 객체의 크기, 오리엔테이션 및 위치 중 적어도 하 나를 참조하여 상기 제1 영상 상에 상기 대상 객체와 관련된 정보를 나타내는 제3 영상을 표시하는 단계; 를 포 함할 수 있다. 상기 제1 영역을 설정하는 단계는 학습된 인공 신경망을 이용하여 상기 제1 영상으로부터 상기 대상 객체에 해 당하는 제1 영역 및 상기 대상 객체의 상기 식별 정보를 결정하는 단계; 를 포함할 수 있다. 이때 상기 인공 신 경망은 입력된 영상에 대해 상기 입력된 영상 내에서 객체에 해당하는 영역과 객체의 식별 정보를 출력하도록 학습된 신경망일 수 있다. 상기 기준 모델은 상기 대상 객체의 3차원 형상을 포함하는 모델이고, 상기 대상 객체의 크기, 오리엔테이션 및 위치를 결정하는 단계는 상기 제2 영역 내의 깊이 정보로부터 도출되는 3차원 형상과 상기 기준 모델에 포함된 상기 대상 객체의 3차원 형상 간의 비교를 통해 상기 제1 장면에서 상기 대상 객체의 크기, 오리엔테이션 및 위 치를 결정하는 단계; 를 포함할 수 있다. 이때 상기 크기는 상기 대상 객체의 소정의 기준 크기에 대한 상기 제 1 장면에서의 대상 객체의 크기의 비율을 포함하고, 상기 오리엔테이션은 적어도 하나의 기준 방향에 대한 상기 대상 객체의 회전 정도를 포함하고, 상기 위치는 상기 대상 객체에 대해 설정된 소정의 기준 지점의 상기 제1 장면에서의 위치를 포함할 수 있다. 상기 제3 영상을 표시하는 단계는 상기 대상 객체의 크기, 오리엔테이션 및 위치를 고려하여 상기 대상 객체를 구성하는 적어도 하나의 부품을 상기 대상 객체에 인접하여 나열한 제3 영상을 표시하는 단계; 를 포함할 수 있 다. 상기 제3 영상을 표시하는 단계는 상기 대상 객체의 오리엔테이션과 상기 적어도 하나의 부품의 결합 방향 및 결합 순서 중 적어도 하나에 따라 상기 적어도 하나의 부품의 표시 위치를 결정하는 단계; 를 더 포함할 수 있 다.본 발명의 일 실시예에 따른 증강현실 영상 표시 방법은 상기 대상 객체의 크기, 오리엔테이션 및 위치를 결정 하는 단계 이후에, 상기 기준 모델로부터 제4 영상을 생성하여 상기 제1 영상의 적어도 일부를 상기 제4 영상으 로 대체하여 표시하는 단계; 를 더 포함할 수 있다. 상기 제4 영상으로 대체하여 표시하는 단계는 상기 대상 객체의 크기 및 오리엔테이션을 고려하여 상기 기준 모 델로부터 프로젝션 영상인 상기 제4 영상을 생성하는 단계; 를 포함할 수 있다. 이때 상기 프로젝션 영상은 상 기 기준 모델이 상기 결정된 대상 객체의 크기이고 상기 오리엔테이션에 따라 회전된 상태에서의 2차원 영상일 수 있다."}
{"patent_id": "10-2022-0048998", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명에 따르면 획득된 영상 내의 객체를 인식하고, 인식된 객체의 정보를 실시간 영상 상에 표시할 수 있다. 또한 인식된 객체와 관련된 정보를 실시간 영상 내 증강 현실로 표시하되, 영상 내에서의 객체의 크기와 오리엔 테이션을 고려하여 제공할 수 있다. 또 실시간 영상의 일부를 대체하여 보다 더 상세한 정보를 갖는 영상을 제공할 수 있다."}
{"patent_id": "10-2022-0048998", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명의 이점 및 특징, 그리고 그것들을 달성하는 방법은 첨부되는 도면과 함께 상세하게 후술되어 있는 실시 예들을 참조하면 명확해질 것이다. 그러나 본 발명은 이하에서 개시되는 실시예들에 한정되는 것이 아니라 서로 다른 다양한 형태로 구현될 것이며, 단지 본 실시예들은 본 발명의 개시가 완전하도록 하며, 본 발명이 속하는"}
{"patent_id": "10-2022-0048998", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "기술분야에서 통상의 지식을 가진 자에게 발명의 범주를 완전하게 알려주기 위해 제공되는 것이며, 본 발명은 청구항의 범주에 의해 정의될 뿐이다. 비록 제1, 제2 등이 다양한 구성요소들을 서술하기 위해서 사용되나, 이들 구성요소들은 이들 용어에 의해 제한 되지 않음은 물론이다. 이들 용어들은 단지 하나의 구성요소를 다른 구성요소와 구별하기 위하여 사용하는 것이다. 따라서, 이하에서 언급되는 제1 구성요소는 본 발명의 기술적 사상 내에서 제2 구성요소일 수도 있음은 물 론이다. 이하의 실시예에서, 포함하다 또는 가지다 등의 용어는 명세서상에 기재된 특징, 또는 구성요소가 존재함을 의 미하는 것이고, 하나 이상의 다른 특징들 또는 구성요소가 부가될 가능성을 미리 배제하는 것은 아니다. 도면에서는 설명의 편의를 위하여 구성 요소들이 그 크기가 과장 또는 축소될 수 있다. 예컨대, 도면에서 나타 난 각 구성의 크기 및 형태는 설명의 편의를 위해 임의로 나타내었으므로, 본 발명이 반드시 도시된 바에 한정 되지 않는다. 명세서 전체에 걸쳐 동일 참조 부호는 동일 구성 요소를 지칭한다. 본 발명의 여러 실시예들의 각각 특징들이 부분적으로 또는 전체적으로 서로 결합 또는 조합 가능하며, 당업자 가 충분히 이해할 수 있듯이 기술적으로 다양한 연동 및 구동이 가능하며, 각 실시예들이 서로에 대하여 독립적 으로 실시 가능할 수도 있고 연관 관계로 함께 실시 가능할 수도 있다. 이하, 첨부된 도면을 참고로 하여 본 발명의 증강현실 영상 표시 방법에 대하여 자세히 설명한다. 도 1은 본 발명의 일 실시예에 따른 영상 제공 시스템의 구성을 개략적으로 도시한 도면이다. 본 발명의 일 실시예에 따른 영상 제공 시스템은 대상 객체의 공간 상에서의 오리엔테이션과 크기를 고려한 증 강현실 영상을 제공할 수 있다. 가령 본 발명의 일 실시예에 따른 영상 제공 시스템은 차량의 휠이 대상 객체인 경우, 휠의 크기, 휠의 오리엔테이션 및 휠의 위치를 고려하여 휠을 구성하는 부품을 휠의 축 방향으로 나열하 여 표시한 증강현실 영상을 제공할 수 있다. 또한 본 발명의 일 실시예에 따른 영상 제공 시스템은 대상 객체의 영상을 기 저장된 기준 모델로부터 생성된 프로젝션 영상으로 대체하여 제공할 수 있다. 가령 전술한 예시 에서와 같이 차량의 휠이 대상 객체인 경우 휠 의 크기 및 휠의 오리엔테이션을 고려하여 기준 모델로부터 프로젝션 영상을 생성하고, 생성된 영상을 대상 객 체의 영상의 적어도 일부분에 갈음하여 제공할 수 있다. 본 발명에서 '대상 객체'는 증강현실 영상의 대상이 되는 객체를 의미할 수 있다. 가령 대상 객체는 구분된 객 체 전체를 의미할 수도 있고, 구분된 객체의 일부분을 의미할 수도 있다. 예를 들어 대상 객체는 도 1에 도시된 차량 전체일 수도 있고, 차량의 휠일 수도 있다. 다만 이는 예시적인 것으로 본 발명의 사상이 이에 한정되는 것은 아니다. 본 발명에서 대상 객체의 '오리엔테이션'은 적어도 하나의 기준 방향에 대한 대상 객체의 회전 정도를 의미할 수 있다. 가령 오리엔테이션은 3차원 공간을 정의하는 3개의 축 각각에 대한 대상 객체의 회전 각도를 의미할 수 있다. 다만 이는 예시적인 것으로 다양한 좌표계가 본 발명의 오리엔테이션의 표현에 사용될 수 있다. 본 발명에서 대상 객체의 '크기'는 대상 객체에 대해 미리 설정된 기준 크기에 대한 공간 상의 대상 객체의 상 대적 크기를 의미할 수 있다. 가령 대상 객체의 크기는 0.7, 1.4와 같이 미리 설정된 기준 크기에 대한 상대적 크기일 수 있다. 본 발명에서 대상 객체의 위치는 대상 객체에 대해 설정된 소정의 기준 지점의 특정 장면(또는 특정 공간)에서 의 위치를 의미할 수 있다. 가령 대상 객체의 위치는 특정 장면 내에서의 2차원 좌표의 형태로 표현될 수 있다. 본 발명에서 '기준 모델'은 대상 객체에 대해 미리 생성된 3차원 모델로써, 객체의 3차원 형상 및/또는 외형에 대한 정보를 포함하는 데이터를 의미할 수 있다. 가령 대상 객체가 힐인 경우 기준 모델은 휠의 3차원 형상 정 보를 포함하는 데이터 일 수 있다. 본 발명에서 '프로젝션 영상'은 기준 모델이 특정 크기이고 특정 오리엔테이션에 따라 회전된 상태에서의 2차원 영상을 의미할 수 있다. 본 발명에서 '제1 영상'은 대상 객체 또는 대상 객체가 위치한 환경의 색상 정보를 포함하는 영상을 의미할 수 있다. 가령 제1 영상은 가시광선 대역의 파장의 광을 주로 기록하는 영상 획득 장치에 의해 생성된 RGB 영상일 수 있다. 본 발명에서 '제2 영상'은 객체 또는 대상 객체가 위치한 환경의 깊이(또는 거리) 정보를 포함하는 영상을 의미 할 수 있다. 가령 제2 영상은 Lidar가 획득한 거리 정보에 기반하여 생성된 영상일 수 있다. 본 발명에서 '인공 신경망'은 소정의 목적에 따라 학습된 것으로, 머신 러닝(Machine Learning) 또는 딥러닝 (Deep Learning) 기법에 의해 학습된 것을 의미할 수 있다. 인공 신경망에 대해서는 도 3 내지 도 5를 참조하여 후술한다. 본 발명의 일 실시예에 따른 영상 제공 시스템은 도 1에 도시된 바와 같이 영상 표시 장치, 대상 객체 및 서버를 포함할 수 있다. 본 발명의 일 실시예에 따른 영상 표시 장치는 대상 객체의 공간 상에서의 오리엔테이션과 크기를 고 려한 증강현실 영상을 제공할 수 있다. 또한 본 발명의 일 실시예에 따른 영상 표시 장치는 대상 객체 의 영상을 기 저장된 기준 모델로부터 생성된 프로젝션 영상으로 대체하여 제공할 수 있다. 도 2는 본 발명의 일 실시예에 따른 영상 표시 장치의 구성을 개략적으로 도시한 도면이다. 본 발명의 일 실시예에 따른 영상 표시 장치는 제1 영상 획득부, 제2 영상 획득부, 제어부 , 통신부, 메모리 및 디스플레이부를 포함할 수 있다. 본 발명의 일 실시예에 따른 제1 영상 획득부는 대상 객체에 대한 제1 영상을 획득할 수 있다. 가령 제1 영상 획득부는 대상 객체의 색상 정보를 포함하는 RGB 영상을 획득할 수 있다. 본 발명의 일 실시예에 따른 제2 영상 획득부는 대상 객체에 대한 제2 영상을 획득할 수 있다. 가령 제2 영상 획득부는 대상 객체의 깊이(거리)정보를 포함하는 깊이 영상을 획득할 수 있다. 본 발명의 일 실시예에 따른 제어부는 대상 객체에 대한 증강현실 영상을 제공하는 일련의 과정을 처 리할 수 있다. 이때 본 발명의 일 실시예에 따른 제어부는 프로세서(processor)와 같이 데이터를 처리할 수 있는 모든 종류의 장치를 포함할 수 있다. 여기서, '프로세서(processor)'는, 예를 들어 프로그램 내에 포함 된 코드 또는 명령으로 표현된 기능을 수행하기 위해 물리적으로 구조화된 회로를 갖는, 하드웨어에 내장된 데 이터 처리 장치를 의미할 수 있다. 이와 같이 하드웨어에 내장된 데이터 처리 장치의 일 예로써, 마이크로프로 세서(microprocessor), 중앙처리장치(central processing unit: CPU), 프로세서 코어(processor core), 멀티프 로세서(multiprocessor), ASIC(application-specific integrated circuit), FPGA(field programmable gate array) 등의 처리 장치를 망라할 수 있으나, 본 발명의 범위가 이에 한정되는 것은 아니다. 본 발명의 일 실시예에 따른 통신부는 영상 표시 장치가 서버와 같은 다른 네트워크 장치와 데 이터를 송수신하기 위한 기능을 수행하기 위한 하드웨어 및/또는 소프트웨어를 의미할 수 있다. 가령 통신부 는 서버로부터 기준 모델을 수신하여 메모리에 저장하는 기능을 수행할 수 있다. 다만 이는 예 시적인 기능으로 통신부의 기능이 이에 한정되는 것은 아니다. 본 발명의 일 실시예에 따른 메모리는 제어부가 처리하는 데이터, 명령어(instructions), 프로그램, 프로그램 코드, 또는 이들의 결합 등을 일시적 또는 영구적으로 저장하는 기능을 수행한다. 가령 메모리는 복수의 기준 모델과 관련된 데이터를 일시적 및/또는 영구적으로 저장할 수도 있다. 이와 같은 메모리는 자기 저장 매체(magnetic storage media) 또는 플래시 저장 매체(flash storage media)를 포함할 수 있으나, 본 발명의 범위가 이에 한정되는 것은 아니다. 본 발명의 일 실시예에 따른 디스플레이부는 대상 객체에 대한 실시간 영상 및/또는 증강현실 영상을 표시할 수 있다. 이와 같은 디스플레이부는 가령 CRT(Cathode Ray Tube), LCD(Liquid Crystal Display), PDP (Plasma Display Panel), LED(Light-Emitting Diode) 및 OLED(Organic Light Emitting Diode) 중 어느 하 나로 구성될 수 있으나, 본 발명의 사상은 이에 제한되지 않는다. 도 1에는 설명의 편의를 위해 영상 표시 장치가 태블릿 PC와 같은 형태인 것으로 도시 되었지만, 영상 표 시 장치의 형태가 이에 한정되는 것이 아니다. 가령 영상 표시 장치는 신체에 부착 가능한 웨어러블 형태(예를 들어 안경, 시계 등)로 구현될 수도 있다. 본 발명에서 대상 객체는 전술한 바와 같이 증강현실 영상의 대상이 되는 객체를 의미할 수 있다. 가령 대 상 객체는 구분된 객체 전체를 의미할 수도 있고, 구분된 객체의 일부분을 의미할 수도 있다. 예를 들어 대상 객체는 도 1에 도시된 차량 전체일 수도 있고, 차량의 휠일 수도 있다. 다만 이는 예시적인 것으로 본 발 명의 사상이 이에 한정되는 것은 아니다. 본 발명에서 서버는 전술한 영상 표시 장치에 데이터를 제공하는 장치일 수 있다. 가령 서버는 대상 객체의 식별 정보를 생성하는데 사용되는 인공 신경망과 관련된 데이터(예를 들어 학습된 계수, 가중치 등)를 영상 표시 장치에 제공할 수 있다. 또한 서버는 복수의 기준 모델과 관련된 데이터를 영상 표 시 장치에 제공할 수도 있다. 다만 상술한 데이터들은 예시적인 것으로 본 발명의 사상이 이에 한정되는 것은 아니다. 이하에서는 인공 신경망의 구조와 학습 과정에 대해서 먼저 설명하고, 영상 표시 장치가 증강현실 영상을 제공하는 과정을 나중에 설명한다. 도 3은 인공 신경망의 예시적인 구조를 설명하기 위한 도면이다. 본 발명의 일 실시예에서, 인공 신경망은 서버에 의해 학습되어 영상 표시 장치로 전송될 수 있다. 이하에서는 인공 신경망이 서버에 의해 학습됨을 전제로 설명한다. 본 발명의 일 실시예에 따른 인공 신경망은 도 3에 도시된 바와 같은 합성 곱 신경망(CNN: Convolutional Neural Network) 모델에 따른 인공 신경망일 수 있다. 이때 CNN 모델은 복수의 연산 레이어(Convolutional Layer, Pooling Layer)를 번갈아 수행하여 최종적으로는 입력 데이터의 특징을 추출하는 데 사용되는 계층 모델 일 수 있다. 이때 본 발명의 일 실시예에 따른 서버는 학습 데이터를 지도학습(Supervised Learning) 기법 에 따라 처리하여 인공 신경망 모델을 구축하거나 학습시킬 수 있다. 본 발명의 일 실시예에 따른 서버는 입력 데이터의 특징 값을 추출하기 위한 컨볼루션 레이어(Convolution layer), 추출된 특징 값을 결합하여 특징 맵을 구성하는 풀링 레이어(pooling layer)를 생성할 수 있다. 또한 본 발명의 일 실시예에 따른 서버는 생성된 특징 맵을 결합하여, 입력 데이터가 복수의 항목 각각에 해당할 확률을 결정할 준비를 하는 풀리 커넥티드 레이어(Fully Connected Layer)를 생성할 수 있다. 마지막으로 서버는 입력 데이터에 대응되는 출력을 포함하는 아웃풋 레이어(Output Layer)를 산출할 수 있 다. 도 3에 도시된 예시에서는, 입력 데이터가 5X7 형태의 블록으로 나누어지며, 컨볼루션 레이어의 생성에 5X3 형 태의 단위 블록이 사용되고, 풀링 레이어의 생성에 1X4 또는 1X2 형태의 단위 블록이 사용되는 것으로 도시 되 었지만, 이는 예시적인 것으로 본 발명의 사상이 이에 한정되는 것은 아니다. 이와 같은 입력 데이터의 분할 크기, 컨볼루션 레이어에 사용되는 단위 블록의 크기, 풀링 레이어의 수, 풀링 레이어의 단위 블록의 크기 등은 인공 신경망의 학습 조건을 나타내는 파라미터 셋에 포함되는 항목일 수 있다. 바꾸어 말하면, 파라미터 셋은 상술한 항목들을 결정하기 위한 파라미터(즉 구조 파라미터)들을 포함할 수 있다. 따라서 파라미터 셋의 변경 및/또는 조절에 따라 인공 신경망의 구조가 변경될 수 있으며, 이에 따라 동일한 학 습 데이터를 이용하더라도 학습 결과가 달라질 수 있다. 한편 이와 같은 인공 신경망은 서버의 메모리(미도시)에 인공 신경망을 구성하는 적어도 하나의 노드의 계 수, 노드의 가중치 및 인공 신경망을 구성하는 복수의 레이어 간의 관계를 정의하는 함수의 계수들의 형태로 저 장될 수 있다. 또한 서버에 저장된 데이터(인공 신경망과 관련된 데이터)는 영상 표시 장치로 전송되 어 영상 표시 장치가 증강현실 영상을 표시하는 과정에 사용 될 수 있다. 이에 대한 상세한 설명은 후술한 다. 도 4는 본 발명의 일 실시예에 따른 서버가 복수의 학습 데이터를 이용하여 인공 신경망을 학습 하는 방법을 설명하기 위한 도면이다. 본 발명의 일 실시예에 따른 인공 신경망은 복수의 학습 데이터 각각에 포함되는 입력 데이터와 출력 데이터 간의 상관관계를 학습한(또는 학습하는) 신경망을 의미할 수 있다. 이 때 복수의 학습 데이터 각각 에 포함되는 입력 데이터와 출력 데이터는 시스템의 목적 및/또는 용도에 따라 다양하게 결정될 수 있다. 따라서 본 발명의 일 실시예에 따른 인공 신경망은 입력 데이터의 입력에 따라, 그에 대응되는 출력 데이 터를 출력하도록 학습된(또는 학습되는) 신경망을 의미할 수 있다. 가령 인공 신경망이 영상에서 객체를 인식하는데 사용되는 경우, 복수의 학습 데이터 각각은 입력 영 상과 해당 영상 내에서의 객체의 위치, 해당 영상 내에서의 객체의 크기 및 객체의 클래스를 포함할 수 있다. 예를 들어 첫 번째 학습 데이터의 경우 인식의 대상이 되는 객체를 포함하는 영상(511A), 영상(511A) 내에 서의 객체의 위치(511B), 영상(511A) 내에서의 객체의 크기(511C) 및 객체의 클래스(511D)를 포함할 수 있다. 이와 유사하게 두 번째 학습 데이터 및 세 번째 학습 데이터도 각각 상술한 항목들을 포함할 수 있다. 다만 상술한 항목들은 예시적인것으로 본 발명의 사상이 이에 한정되는 것은 아니다. 도 5는 학습된 인공 신경망의 입력 데이터 및 출력 데이터를 도시한 도면이다. 전술한 바와 같이 인공 신경망은 입력 데이터의 입력에 따라, 그에 대응되는 출력 데이터를 출력하도록 학 습된(또는 학습되는) 신경망을 의미할 수 있다. 본 발명의 일 실시예에 따른 인공 신경망은 대상 객체를 포함하는 영상이 입력됨에 따라 해당 영상 내에서 대상 객체에 해당하는 영역과 객체의 식별 정보를 출력 데이터로 출력할 수 있다. 이때 '영역'은 대상 객체의 영상 내에서의 위치와 대상 객체의 영상 내에서의 크기의 형태로 출력될 수 있다. 가령 도 5에 도 시된 바와 같이 영역은 중심 좌표(X, Y), 영역의 가로 크기(W) 및 영역의 세로 크기(H) 형태로 출력될 수 있다. 다만 이는 예시적인것으로 본 발명의 사상이 이에 한정되는 것은 아니다. 이하에서는 상술한 과정에 따라 인공 신경망이 학습되어 서버에서 영상 표시 장치로 전송되어 있음을 전제로 영상 표시 장치가 증강현실 영상을 표시하는 과정을 중심으로 설명한다. 또한 설명의 편의 를 위해 대상 객체가 차량의 '휠'인 것을 전제로 설명한다. 도 6은 본 발명의 일 실시예에 따른 영상 표시 장치가 제1 영상 및 제2 영상을 획득하는 과정을 설명하기 위한 도면이다. 본 발명의 일 실시예에 따른 영상 표시 장치는 대상 객체의 색상 정보를 포함하는 제1 영상 및 대상 객체의 깊이(Depth) 정보를 포함하는 제2 영상을 획득할 수 있다. 이때 제1 영상 및 제2 영상은 동일한 제1 장면을 촬영한 영상일 수 있다. 바꾸어 말하면 제1 영상은 제1 장면의 색상 정보를 수집한 영상이고, 제2 영상은 제1 장면(40 0)의 깊이 정보를 수집한 영상일 수 있다. 한편 본 발명에서 제1 영상의 촬영 범위와 제2 영상의 촬 영 범위는 동일하거나 어느 하나의 촬영 범위가 다른 하나의 촬영 범위를 포함할 수 있다. 본 발명의 일 실시예에 따른 영상 표시 장치는 제1 영상 내에서 대상 객체에 해당하는 제1 영역을 설 정할 수 있다. 본 발명의 일 실시예에 따른 영상 표시 장치는 도 3 내지 도 5에서 설명한 인공 신경망을 이용하여 제1 영역을 설정할 수 있다. 가령 본 발명의 일 실시예에 따른 영상 표시 장치는 제1 영상을 인공 신 경망에 입력하고, 그 출력으로써 휠에 해당하는 제1 영역(위치 및 크기)과 식별 정보(클래스'휠')를 획득 할 수 있다. 본 발명의 선택적 실시예에 따른 영상 표시 장치는 제1 영상에서 식별된 대상 객체가 복수인 경우, 복수의 대상 객체 각각에 대한 영역과 식별 정보를 생성하고, 복수의 대상 객체를 선택 가능한 형태로 사용자에 게 제공할 수 있다. 사용자는 제공된 복수의 대상 객체 중 적어도 하나를 선택하고, 그에 따라 후술하는 과정이 진행될 수 있다. 본 발명의 일 실시예에 따른 영상 표시 장치는 제2 영상에서 제1 영역에 상응하는 제2 영역을 설정할 수 있다. 도 7은 본 발명의 일 실시예에 따른 영상 표시 장치가 제2 영역을 설정하는 과정을 설명하기 위한 도 면이다. 설명의 편의를 위해서, 대상 객체가 휠이며 도 5의 인공 신경망의 출력 결과에 도시된 바와 같이 휠을 포 함하는 영역이 전술한 과정에 따라 제1 영역으로 설정되었음을 전제로 설명한다. 상술한 가정 하에, 본 발명의 일 실시예에 따른 영상 표시 장치는 제2 영상에서 제1 영역에 상응하는 제2 영역을 설정할 수 있다. 이때 설정된 제2 영역은 제1 영상 상의 제1 영역에 해당하는 영역 의 깊이 정보만을 포함할 수 있다. 즉 제1 영역과 제2 영역은 장면 상의 동일한 부분에 대해서 각각 색상 정보와 깊이 정보를 가지는 부분 영상에 해당할 수 있다. 본 발명의 일 실시예에 따른 영상 표시 장치는 전술한 과정에 따라 생성된 대상 객체의 식별 정보를 이용 하여 기준 모델을 로드 할 수 있다. 가령 영상 표시 장치는 메모리로부터 휠의 기준 모델을 로드 할 수도 있고, 서버로부터 휠의 기준 모델을 로드 할 수도 있다. 본 발명의 일 실시예에 따른 영상 표시 장치는 전술한 과정에 따라 제2 영상 상에 설정된 제2 영역 과 기준 모델의 비교 결과에 기초하여 제2 영상에서의 대상 객체의 크기, 오리엔테이션 및 위치를 결 정할 수 있다. 도 8은 본 발명의 일 실시예에 따른 영상 표시 장치가 대상 객체의 크기, 오리엔테이션 및 위치를 결정하 는 과정을 설명하기 위한 도면이다. 전술한 바와 같이 기준 모델은 대상 객체의 3차원 형상을 포함하는 모델일 수 있다. 또한 제2 영역은 대상 객체의 깊이 정보를 포함하는 영역일 수 있다. 따라서 본 발명의 일 실시예에 따른 영상 표시 장치는 제2 영역 내의 깊이 정보로부터 도출되는 3차 원 형상과 기준 모델에 포함된 대상 객체의 3차원 형상 간의 비교를 통해 제1 장면에서 대상 객체의 크기, 오리엔테이션 및 위치를 결정할 수 있다. 이때 대상 객체의 크기는 소정의 기준 크기에 대한 제1 장면에서의 대상 객체의 크기의 비율을 포함할 수 있다. 가령 대상 객체의 크기는 휠의 기준 크기에 대한 제1 장면에서의 휠의 크기의 비율을 포함할 수 있 다. 오리엔테이션은 적어도 하나의 기준 방향에 대한 대상 객체의 회전 정도를 포함할 수 있다. 가령 오리엔테이션 은 X, Y, Z 축 방향 각각에 대한 휠의 회전 정도를 포함할 수 있다. 위치는 대상 객체에 대해 설정된 소정의 기준 지점의 제1 장면에서의 위치를 포함할 수 있다. 가령 위치는 휠의 외면의 중심점의 제1 장면(또는 제1 영상)에서의 위지 좌표를 포함할 수 있다. 본 발명의 일 실시예에 따른 영상 표시 장치는 상술한 과정에 따라 결정된 대상 객체의 크기, 오리엔테이 션 및 위치 중 적어도 하나를 참조하여 상기 제1 영상 상에 대상 객체와 관련된 정보를 나타내는 제3 영상을 표시할 수 있다. 도 9는 제1 영상상에 표시되는 예시적인 제3 영상을 도시한 도면이다. 본 발명의 일 실시예에 따른 영상 표시 장치는 대상 객체의 크기, 오리엔테이션 및 위치를 고려하여 대상 객체를 구성하는 적어도 하나의 부품을 대상 객체에 인접하여 나열한 제3 영상을 표시할 수 있다. 이때 본 발명의 일 실시예에 따른 영상 표시 장치는 대상 객체의 오리엔테이션과 대상 객체의 적어도 하나의 부품 의 결합 방향 및 결합 순서 중 적어도 하나에 따라 적어도 하나의 부품의 표시 위치를 결정할 수 있다. 가령 영상 표시 장치는 도 9에 도시된 바와 같이 대상 객체 휠에 대한 제3 영상으로써, 휠의 축 방향 으로 휠을 구성하는 부품들을 결합 순서와 방향을 고려하여 나열한 제3 영상을 표시할 수 있다. 이와 같이 본 발명은 단순히 대상 객체에 대한 영상을 대상 객체에 인접하여 표시하는 것이 아니라, 대상 객체 의 크기, 오리엔테이션 및 위치를 모두 고려하여 표시함으로써 더 정밀한 정보를 제공할 수 있도록 한다. 한편 본 발명의 일 실시예에 따른 영상 표시 장치는 기준 모델로부터 제4 영상을 생성하여 제1 영상 의 적어도 일부를 제4 영상으로 대체하여 표시할 수 있다. 도 10은 제1 영상에서 휠에 해당하는 영역이 제4 영상으로 대체된 영상을 도시한 도면이다. 본 발명의 일 실시예에 따른 영상 표시 장치는 대상 객체의 크기 및 오리엔테이션을 고려하여 기준 모델로 부터 프로젝션 영상인 제4 영상을 생성할 수 있다. 이때 프로젝션 영상은 전술한 바와 같이 기준 모델이 결정된 대상 객체의 크기이고 해당 오리엔테이션에 따라 회전된 상태에서의 2차원 영상일 수 있다. 가령 영상 표시 장치는 도 10에 도시된 바와 같이 휠의 기준 모델로부터 프로젝션 영상인 제4 영상을 생성하고, 이를 제1 영상에서 휠을 나타내는 영역에 갈음하여 표시할 수 있다. 이로써 본 발명은 식별된 대상 객체에 대해서 보다 상세한 정보를 제공하는 영상을 표시할 수 있다. 본 발명의 일 실시예에 따른 영상 표시 장치는 장면의 변화에 따라 상술한 과정을 반복하여 수행할 수 있 다. 가령 사용자가 영상 표시 장치의 촬영 각도 및/또는 촬영 위치를 변경함에 따라 영상 표시 장치 는 변경된 각도 및/또는 위치를 기준으로 대상 객체에 대한 제3 영상을 생성하여 제공할 수 있다. 도 11은 본 발명의 일 실시예에 따른 영상 표시 장치에 의해 수행되는 증강현실 영상 표시 방법을 설명하 기 위한 흐름도이다. 이하에서는 도 1 내지 도 10을 함께 참조하여 설명한다. 본 발명의 일 실시예에 따른 영상 표시 장치는 대상 객체의 색상 정보를 포함하는 제1 영상 및 대상 객체 의 깊이(Depth) 정보를 포함하는 제2 영상을 획득할 수 있다.(S1110) 도 6은 본 발명의 일 실시예에 따른 영상 표시 장치가 제1 영상 및 제2 영상을 획득하는 과정을 설명하기 위한 도면이다.전술한 바와 같이 제1 영상 및 제2 영상은 동일한 제1 장면을 촬영한 영상일 수 있다. 바꾸어 말하면 제1 영상은 제1 장면의 색상 정보를 수집한 영상이고, 제2 영상은 제1 장면(40 0)의 깊이 정보를 수집한 영상일 수 있다. 한편 본 발명에서 제1 영상의 촬영 범위와 제2 영상의 촬 영 범위는 동일하거나 어느 하나의 촬영 범위가 다른 하나의 촬영 범위를 포함할 수 있다. 본 발명의 일 실시예에 따른 영상 표시 장치는 제1 영상 내에서 대상 객체에 해당하는 제1 영역을 설 정할 수 있다. (S1120) 본 발명의 일 실시예에 따른 영상 표시 장치는 도 3 내지 도 5에서 설명한 인공 신경망을 이용하여 제1 영역을 설정할 수 있다. 가령 본 발명의 일 실시예에 따른 영상 표시 장치는 제1 영상을 인공 신 경망에 입력하고, 그 출력으로써 휠에 해당하는 제1 영역(위치 및 크기)과 식별 정보(클래스'휠')를 획득 할 수 있다. 본 발명의 선택적 실시예에 따른 영상 표시 장치는 제1 영상에서 식별된 대상 객체가 복수인 경우, 복수의 대상 객체 각각에 대한 영역과 식별 정보를 생성하고, 복수의 대상 객체를 선택 가능한 형태로 사용자에 게 제공할 수 있다. 사용자는 제공된 복수의 대상 객체 중 적어도 하나를 선택하고, 그에 따라 후술하는 과정이 진행될 수 있다. 본 발명의 일 실시예에 따른 영상 표시 장치는 제2 영상에서 제1 영역에 상응하는 제2 영역을 설정할 수 있다.(S1130) 도 7은 본 발명의 일 실시예에 따른 영상 표시 장치가 제2 영역을 설정하는 과정을 설명하기 위한 도 면이다. 설명의 편의를 위해서, 대상 객체가 휠이며 도 5의 인공 신경망의 출력 결과에 도시된 바와 같이 휠을 포 함하는 영역이 전술한 과정에 따라 제1 영역으로 설정되었음을 전제로 설명한다. 상술한 가정 하에, 본 발명의 일 실시예에 따른 영상 표시 장치는 제2 영상에서 제1 영역에 상응하는 제2 영역을 설정할 수 있다. 이때 설정된 제2 영역은 제1 영상 상의 제1 영역에 해당하는 영역 의 깊이 정보만을 포함할 수 있다. 즉 제1 영역과 제2 영역은 장면 상의 동일한 부분에 대해서 각각 색상 정보와 깊이 정보를 가지는 부분 영상에 해당할 수 있다. 본 발명의 일 실시예에 따른 영상 표시 장치는 전술한 과정에 따라 생성된 대상 객체의 식별 정보를 이용 하여 기준 모델을 로드 할 수 있다.(S1140) 가령 영상 표시 장치는 메모리로부터 휠의 기준 모델을 로드 할 수도 있고, 서버로부터 휠의 기준 모델을 로드 할 수도 있다. 본 발명의 일 실시예에 따른 영상 표시 장치는 전술한 과정에 따라 제2 영상 상에 설정된 제2 영역 과 기준 모델의 비교 결과에 기초하여 제2 영상에서의 대상 객체의 크기, 오리엔테이션 및 위치를 결 정할 수 있다. (S1150) 도 8은 본 발명의 일 실시예에 따른 영상 표시 장치가 대상 객체의 크기, 오리엔테이션 및 위치를 결정하 는 과정을 설명하기 위한 도면이다. 전술한 바와 같이 기준 모델은 대상 객체의 3차원 형상을 포함하는 모델일 수 있다. 또한 제2 영역은 대상 객체의 깊이 정보를 포함하는 영역일 수 있다. 따라서 본 발명의 일 실시예에 따른 영상 표시 장치는 제2 영역 내의 깊이 정보로부터 도출되는 3차 원 형상과 기준 모델에 포함된 대상 객체의 3차원 형상 간의 비교를 통해 제1 장면에서 대상 객체의 크기, 오리엔테이션 및 위치를 결정할 수 있다. 이때 대상 객체의 크기는 소정의 기준 크기에 대한 제1 장면에서의 대상 객체의 크기의 비율을 포함할 수 있다. 가령 대상 객체의 크기는 휠의 기준 크기에 대한 제1 장면에서의 휠의 크기의 비율을 포함할 수 있 다. 오리엔테이션은 적어도 하나의 기준 방향에 대한 대상 객체의 회전 정도를 포함할 수 있다. 가령 오리엔테이션 은 X, Y, Z 축 방향 각각에 대한 휠의 회전 정도를 포함할 수 있다. 위치는 대상 객체에 대해 설정된 소정의 기준 지점의 제1 장면에서의 위치를 포함할 수 있다. 가령 위치는 휠의 외면의 중심점의 제1 장면(또는 제1 영상)에서의 위지 좌표를 포함할 수 있다.본 발명의 일 실시예에 따른 영상 표시 장치는 기준 모델로부터 제4 영상을 생성하여 제1 영상의 적 어도 일부를 제4 영상으로 대체하여 표시할 수 있다.(S1160) 도 10은 제1 영상에서 휠에 해당하는 영역이 제4 영상으로 대체된 영상을 도시한 도면이다. 본 발명의 일 실시예에 따른 영상 표시 장치는 대상 객체의 크기 및 오리엔테이션을 고려하여 기준 모델로 부터 프로젝션 영상인 제4 영상을 생성할 수 있다. 이때 프로젝션 영상은 전술한 바와 같이 기준 모델이 결정된 대상 객체의 크기이고 해당 오리엔테이션에 따라 회전된 상태에서의 2차원 영상일 수 있다. 가령 영상 표시 장치는 도 10에 도시된 바와 같이 휠의 기준 모델로부터 프로젝션 영상인 제4 영상을 생성하고, 이를 제1 영상에서 휠을 나타내는 영역에 갈음하여 표시할 수 있다. 이로써 본 발명은 식별된 대상 객체에 대해서 보다 상세한 정보를 제공하는 영상을 표시할 수 있다. 본 발명의 일 실시예에 따른 영상 표시 장치는 상술한 과정에 따라 결정된 대상 객체의 크기, 오리엔테이 션 및 위치 중 적어도 하나를 참조하여 상기 제1 영상 상에 대상 객체와 관련된 정보를 나타내는 제3 영상을 표시할 수 있다.(S1170) 도 9는 제1 영상상에 표시되는 예시적인 제3 영상을 도시한 도면이다. 본 발명의 일 실시예에 따른 영상 표시 장치는 대상 객체의 크기, 오리엔테이션 및 위치를 고려하여 대상 객체를 구성하는 적어도 하나의 부품을 대상 객체에 인접하여 나열한 제3 영상을 표시할 수 있다. 이때 본 발명의 일 실시예에 따른 영상 표시 장치는 대상 객체의 오리엔테이션과 대상 객체의 적어도 하나의 부품 의 결합 방향 및 결합 순서 중 적어도 하나에 따라 적어도 하나의 부품의 표시 위치를 결정할 수 있다. 가령 영상 표시 장치는 도 9에 도시된 바와 같이 대상 객체 휠에 대한 제3 영상으로써, 휠의 축 방향 으로 휠을 구성하는 부품들을 결합 순서와 방향을 고려하여 나열한 제3 영상을 표시할 수 있다. 이와 같이 본 발명은 단순히 대상 객체에 대한 영상을 대상 객체에 인접하여 표시하는 것이 아니라, 대상 객체 의 크기, 오리엔테이션 및 위치를 모두 고려하여 표시함으로써 더 정밀한 정보를 제공할 수 있도록 한다. 본 발명의 일 실시예에 따른 영상 표시 장치는 장면의 변화에 따라 상술한 단계 S1110 내지 S1170을 반복 하여 수행할 수 있다. 가령 사용자가 영상 표시 장치의 촬영 각도 및/또는 촬영 위치를 변경함에 따라 영 상 표시 장치는 변경된 각도 및/또는 위치를 기준으로 대상 객체에 대한 제3 영상을 생성하여 제공할 수 있다. 이상 설명된 본 발명에 따른 실시예는 컴퓨터 상에서 다양한 구성요소를 통하여 실행될 수 있는 컴퓨터 프로그 램의 형태로 구현될 수 있으며, 이와 같은 컴퓨터 프로그램은 컴퓨터로 판독 가능한 매체에 기록될 수 있다. 이 때, 매체는 하드 디스크, 플로피 디스크 및 자기 테이프와 같은 자기 매체, CD-ROM 및 DVD와 같은 광 기록 매체, 플롭티컬 디스크(floptical disk)와 같은 자기-광 매체(magneto-optical medium), 및 ROM, RAM, 플래시 메모리 등과 같은, 프로그램 명령어를 저장하고 실행하도록 특별히 구성된 하드웨어 장치를 포함할 수 있다. 나 아가, 매체는 네트워크 상에서 전송 가능한 형태로 구현되는 무형의 매체를 포함할 수 있으며, 예를 들어 소프 트웨어 또는 애플리케이션 형태로 구현되어 네트워크를 통해 전송 및 유통이 가능한 형태의 매체일 수도 있다. 한편, 상기 컴퓨터 프로그램은 본 발명을 위하여 특별히 설계되고 구성된 것이거나 컴퓨터 소프트웨어 분야의 당업자에게 공지되어 사용 가능한 것일 수 있다. 컴퓨터 프로그램의 예에는, 컴파일러에 의하여 만들어지는 것 과 같은 기계어 코드 뿐만 아니라 인터프리터 등을 사용하여 컴퓨터에 의해서 실행될 수 있는 고급 언어 코드도 포함될 수 있다. 본 발명에서 설명하는 특정 실행들은 일 실시예들로서, 어떠한 방법으로도 본 발명의 범위를 한정하는 것은 아 니다. 명세서의 간결함을 위하여, 종래 전자적인 구성들, 제어 시스템들, 소프트웨어, 상기 시스템들의 다른 기 능적인 측면들의 기재는 생략될 수 있다. 또한, 도면에 도시된 구성 요소들 간의 선들의 연결 또는 연결 부재들 은 기능적인 연결 및/또는 물리적 또는 회로 적 연결들을 예시적으로 나타낸 것으로서, 실제 장치에서는 대체 가능하거나 추가의 다양한 기능적인 연결, 물리적인 연결, 또는 회로 연결 들로서 나타내어질 수 있다. 또한, “필수적인”, “중요하게” 등과 같이 구체적인 언급이 없다면 본 발명의 적용을 위하여 반드시 필요한 구성 요소가 아닐 수 있다."}
{"patent_id": "10-2022-0048998", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "이상 첨부된 도면을 참조하여 본 발명의 실시예들을 설명하였지만, 본 발명이 속하는 기술분야에서 통상의 지식 을 가진 자는 본 발명의 그 기술적 사상이나 필수적인 특징을 변경하지 않고서 다른 구체적인 형태로 실시될 수있다는 것을 이해할 수 있을 것이다. 그러므로 이상에서 기술한 실시예들은 모든 면에서 예시적인 것이며 한정 적이 아닌 것으로 이해해야만 한다. [이 발명을 지원한 국가연구개발사업] [부처명] 경상북도 [과제관리(전문)기관명] 구미전자정보기술원 [연구사업명] 경상북도 4차산업혁명 핵심기술개발사업 [연구과제명] 실물 객체와 증강데이터 정밀 정합을 위한 인공지능 혼합학습(RGBD+3D) 기반 3D 객체 인식기술 개 발 [연구과제번호] SF321006A [기여율] 1/1 [과제수행기관명] 주식회사 큐에스 [연구기간] 2021.07.01 ~ 2022.06.30"}
{"patent_id": "10-2022-0048998", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일 실시예에 따른 영상 제공 시스템의 구성을 개략적으로 도시한 도면이다. 도 2는 본 발명의 일 실시예에 따른 영상 표시 장치의 구성을 개략적으로 도시한 도면이다. 도 3은 인공 신경망의 예시적인 구조를 설명하기 위한 도면이다. 도 4는 본 발명의 일 실시예에 따른 서버가 복수의 학습 데이터를 이용하여 인공 신경망을 학습 하는 방법을 설명하기 위한 도면이다. 도 5는 학습된 인공 신경망의 입력 데이터 및 출력 데이터를 도시한 도면이다. 도 6은 본 발명의 일 실시예에 따른 영상 표시 장치가 제1 영상 및 제2 영상을 획득하는 과정을 설명하기 위한 도면이다. 도 7은 본 발명의 일 실시예에 따른 영상 표시 장치가 제2 영역을 설정하는 과정을 설명하기 위한 도 면이다. 도 8은 본 발명의 일 실시예에 따른 영상 표시 장치가 대상 객체의 크기, 오리엔테이션 및 위치를 결정하 는 과정을 설명하기 위한 도면이다. 도 9는 제1 영상상에 표시되는 예시적인 제3 영상을 도시한 도면이다. 도 10은 제1 영상에서 휠에 해당하는 영역이 제4 영상으로 대체된 영상을 도시한 도면이다. 도 11은 본 발명의 일 실시예에 따른 영상 표시 장치에 의해 수행되는 증강현실 영상 표시 방법을 설명하 기 위한 흐름도이다."}
