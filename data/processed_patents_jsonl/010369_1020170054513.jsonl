{"patent_id": "10-2017-0054513", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2018-0069660", "출원번호": "10-2017-0054513", "발명의 명칭": "음성 인식 방법 및 장치", "출원인": "삼성전자주식회사", "발명자": "최성자"}}
{"patent_id": "10-2017-0054513", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "음성 인식 장치가 동작하는 상황(situation)과 관련된 정보에 기초하여 적어도 하나의 활성화 단어를 결정하는단계;입력 오디오 신호를 수신하는 단계;상기 입력 오디오 신호에 상기 적어도 하나의 활성화 단어에 포함되는 활성화 단어를 발화하는 음성 신호가 포함되었는지 여부에 기초하여, 상기 입력 오디오 신호에 대한 음성 인식을 수행하는 단계; 및음성 인식이 수행된 결과를 출력하는 단계를 포함하는, 음성 인식 방법."}
{"patent_id": "10-2017-0054513", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1 항에 있어서,상기 상황과 관련된 정보는,상기 음성 인식 장치의 위치, 시간, 상기 음성 인식 장치가 다른 전자 장치와 연결되었는지 여부, 상기 음성 인식 장치가 움직이는지 여부, 및 상기 음성 인식 장치의 사용자의 특성과 관련된 정보 중 적어도 하나를 포함하는 것을 특징으로 하는, 음성 인식 방법."}
{"patent_id": "10-2017-0054513", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1 항에 있어서,상기 적어도 하나의 활성화 단어를 결정하는 단계는,상기 음성 인식 장치의 음성 인식 기능이 민감하게 활성화 되는 정도에 기초하여, 상기 결정되는 적어도 하나의활성화 단어의 개수를 결정하는 단계를 포함하는 것을 특징으로 하는, 음성 인식 방법."}
{"patent_id": "10-2017-0054513", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1 항에 있어서,복수의 상황들 각각에 대해서 대응하는 복수의 활성화 단어들을 저장하는 단계를 더 포함하고,상기 적어도 하나의 활성화 단어를 결정하는 단계는,상기 음성 인식 장치가 동작하는 상황과 관련된 정보를 획득하는 단계; 및상기 음성 인식 장치가 동작하는 상황에 대응하는 상기 적어도 하나의 활성화 단어를 결정하는 단계를 포함하는것을 특징으로 하는, 음성 인식 방법."}
{"patent_id": "10-2017-0054513", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1 항에 있어서,상기 입력 오디오 신호를 수신하는 단계는,상기 입력 오디오 신호를 저장하는 단계를 포함하고,상기 음성 인식을 수행하는 단계는,상기 입력 오디오 신호가 상기 적어도 하나의 활성화 단어에 포함되는 활성화 단어를 발화하는 음성 신호를 포함하는지 여부를 판단하는 단계; 및상기 입력 오디오 신호가 상기 적어도 하나의 활성화 단어에 포함되는 활성화 단어를 발화하는 음성 신호를 포함한다고 판단되는 경우, 상기 저장된 입력 오디오 신호 및 이후에 수신되는 입력 오디오 신호에 대한 음성 인공개특허 10-2018-0069660-3-식을 수행하는 단계를 포함하는 것을 특징으로 하는, 음성 인식 방법."}
{"patent_id": "10-2017-0054513", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1 항에 있어서,상기 음성 인식을 수행하는 단계는,상기 적어도 하나의 활성화 단어에 포함되는 활성화 단어를 발화하는 음성 신호를 포함하는 상기 입력 오디오신호에 대한 음성 인식을 수행하는 단계를 포함하는 것을 특징으로 하는, 음성 인식 방법."}
{"patent_id": "10-2017-0054513", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1 항에 있어서,상기 음성 인식이 수행된 결과를 출력하는 단계는,상기 음성 인식이 수행된 결과를 바로 출력할지 혹은 사용자로부터 확인 명령이 수신되면 상기 음성 인식이 수행된 결과를 출력할지 여부를 결정하는 단계를 포함하는 것을 특징으로 하는, 음성 인식 방법."}
{"patent_id": "10-2017-0054513", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1 항에 있어서,상기 음성 인식이 수행된 결과를 출력하는 단계는,상기 입력 오디오 신호에 대해서 음성 인식을 수행함으로써, 사용자가 발화한 텍스트를 추출하는 단계;상기 추출된 텍스트에 대한 자연어 이해(Natural Language Understanding) 및 문형 분석에 기초하여, 상기 입력오디오 신호에 포함되는 음성 명령이 상기 음성 인식 장치의 응답을 요청하는 직접 명령인지 여부를 판단하는단계; 및상기 음성 명령이 직접 명령이라고 판단되는 경우, 상기 음성 명령에 대해 응답하는 동작을 수행하는 단계를 포함하는 것을 특징으로 하는, 음성 인식 방법."}
{"patent_id": "10-2017-0054513", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8 항에 있어서,상기 음성 인식이 수행된 결과를 출력하는 단계는,상기 음성 명령이 직접 명령이 아니라고 판단되는 경우, 상기 음성 명령에 대한 응답이 가능함을 표시하는단계; 및사용자로부터 확인 명령이 수신되면, 상기 음성 명령에 대해 응답하는 동작을 수행하는 단계를 포함하는 것을특징으로 하는, 음성 인식 방법."}
{"patent_id": "10-2017-0054513", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제1 항에 있어서,상기 음성 인식 장치가 복수의 상황들에서 사용자로부터 수신하는 음성 명령들에 대한 정보를 수신하는 단계;상기 음성 명령들에 포함되는 복수의 단어들을 추출하는 단계; 및상기 복수의 상황들 중에서 특정 상황에서 수신되는 음성 명령들 내에 상기 복수의 단어들이 포함되는 빈도에기초하여, 적어도 하나의 단어를 상기 특정 상황에 대응하는 활성화 단어로서 저장하는 단계를 더 포함하는 것을 특징으로 하는, 음성 인식 방법."}
{"patent_id": "10-2017-0054513", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제1 항에 있어서,상기 적어도 하나의 활성화 단어를 결정하는 단계는,공개특허 10-2018-0069660-4-상기 음성 인식 장치와 연결된 적어도 하나의 전자 장치에 대한 정보를 획득하는 단계; 및상기 적어도 하나의 전자 장치와 관련된 단어를 상기 적어도 하나의 활성화 단어로서 결정하는 단계를 포함하는것을 특징으로 하는, 음성 인식 방법."}
{"patent_id": "10-2017-0054513", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "입력 오디오 신호를 수신하는 수신부;음성 인식 장치가 동작하는 상황과 관련된 정보에 기초하여 적어도 하나의 활성화 단어를 결정하고, 상기 입력오디오 신호에 상기 적어도 하나의 활성화 단어에 포함되는 활성화 단어를 발화하는 음성 신호가 포함되었는지여부에 기초하여, 상기 입력 오디오 신호에 대한 음성 인식을 수행하는, 프로세서; 및음성 인식이 수행된 결과를 출력하는, 출력부를 포함하는, 음성 인식 장치."}
{"patent_id": "10-2017-0054513", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제12 항에 있어서,상기 상황과 관련된 정보는,상기 음성 인식 장치의 위치, 시간, 상기 음성 인식 장치가 다른 전자 장치와 연결되었는지 여부, 상기 음성 인식 장치가 움직이는지 여부, 및 상기 음성 인식 장치의 사용자의 특성과 관련된 정보 중 적어도 하나를 포함하는 것을 특징으로 하는, 음성 인식 장치."}
{"patent_id": "10-2017-0054513", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제12 항에 있어서,상기 프로세서는, 상기 적어도 하나의 활성화 단어를 결정함에 있어서,상기 음성 인식 장치의 음성 인식 기능이 민감하게 활성화 되는 정도에 기초하여, 상기 결정되는 적어도 하나의활성화 단어의 개수를 결정하는 것을 특징으로 하는, 음성 인식 장치."}
{"patent_id": "10-2017-0054513", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제12 항에 있어서,복수의 상황들 각각에 대해서 대응하는 복수의 활성화 단어들을 저장하는 메모리를 더 포함하고,상기 프로세서는, 상기 적어도 하나의 활성화 단어를 결정함에 있어서,상기 음성 인식 장치가 동작하는 상황과 관련된 정보를 획득하고, 상기 음성 인식 장치가 동작하는 상황에 대응하는 상기 적어도 하나의 활성화 단어를 결정하는 것을 특징으로 하는, 음성 인식 장치."}
{"patent_id": "10-2017-0054513", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제12 항에 있어서,상기 입력 오디오 신호를 저장하는 메모리를 더 포함하고,상기 프로세서는, 상기 음성 인식을 수행함에 있어서,상기 입력 오디오 신호가 상기 적어도 하나의 활성화 단어에 포함되는 활성화 단어를 발화하는 음성 신호를 포함하는지 여부를 판단하고, 상기 입력 오디오 신호가 상기 적어도 하나의 활성화 단어에 포함되는 활성화 단어를 발화하는 음성 신호를 포함한다고 판단되는 경우, 상기 저장된 입력 오디오 신호 및 이후에 수신되는 입력오디오 신호에 대한 음성 인식을 수행하는 것을 특징으로 하는, 음성 인식 장치."}
{"patent_id": "10-2017-0054513", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제12 항에 있어서,상기 프로세서는, 상기 음성 인식을 수행함에 있어서,상기 적어도 하나의 활성화 단어에 포함되는 활성화 단어를 발화하는 음성 신호를 포함하는 상기 입력 오디오공개특허 10-2018-0069660-5-신호에 대한 음성 인식을 수행하는 것을 특징으로 하는, 음성 인식 장치."}
{"patent_id": "10-2017-0054513", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제12 항에 있어서,상기 프로세서는,상기 음성 인식이 수행된 결과를 바로 출력할지 혹은 사용자로부터 확인 명령이 수신되면 상기 음성 인식이 수행된 결과를 출력할지 여부를 결정하는 것을 특징으로 하는, 음성 인식 장치."}
{"patent_id": "10-2017-0054513", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제12 항에 있어서,상기 프로세서는, 상기 입력 오디오 신호에 대해서 음성 인식을 수행함으로써, 사용자가 발화한 텍스트를 추출하고, 상기 추출된텍스트에 대한 자연어 이해 및 문형 분석에 기초하여, 상기 입력 오디오 신호에 포함되는 음성 명령이 상기 음성 인식 장치의 응답을 요청하는 직접 명령인지 여부를 판단하고, 상기 음성 명령이 직접 명령이라고 판단되는경우, 상기 음성 명령에 대해 응답하는 동작을 수행하는 것을 특징으로 하는, 음성 인식 장치."}
{"patent_id": "10-2017-0054513", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제19 항에 있어서,상기 프로세서는, 상기 음성 명령이 직접 명령이 아니라고 판단되는 경우, 상기 음성 명령에 대한 응답이 가능함을 표시하도록 상기 출력부를 제어하고, 사용자로부터 확인 명령이 수신되면, 상기 음성 명령에 대해 응답하는 동작을 수행하는것을 특징으로 하는, 음성 인식 장치."}
{"patent_id": "10-2017-0054513", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_21", "content": "음성 인식 장치가 음성 인식 방법을 실행하도록 하는 명령어들을 포함하는 하나 이상의 프로그램이 기록된 컴퓨터로 읽을 수 있는 기록 매체에 있어서, 상기 음성 인식 방법은,상기 음성 인식 장치가 동작하는 상황과 관련된 정보에 기초하여 적어도 하나의 활성화 단어를 결정하는 단계;입력 오디오 신호를 수신하는 단계;상기 입력 오디오 신호에 상기 적어도 하나의 활성화 단어에 포함되는 활성화 단어를 발화하는 음성 신호가 포함되었는지 여부에 기초하여, 상기 입력 오디오 신호에 대한 음성 인식을 수행하는 단계; 및음성 인식이 수행된 결과를 출력하는 단계를 포함하는, 기록 매체."}
{"patent_id": "10-2017-0054513", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 개시는 딥러닝 등의 기계 학습 알고리즘을 활용하여 인간 두뇌의 인지, 판단 등의 기능을 모사하는 인공지능 (AI) 시스템 및 그 응용에 관련된 것이다. 상황에 따라 결정되는 활성화 단어에 응답하여 음성 인식을 수행하는 음성 인식 방법 및 장치가 제공될 수 있다."}
{"patent_id": "10-2017-0054513", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 딥러닝 등의 기계 학습 알고리즘을 활용하여 인간 두뇌의 인지, 판단 등의 기능을 모사하는 인공지능 (AI) 시스템 및 그 응용에 관련된 것이다. 본 개시는 음성 인식 방법 및 장치에 관한 것으로서, 보다 상세하게는 음성 인식 장치가 동작하는 상황과 관련 된 정보에 기초하여 결정된 활성화 단어에 응답하여 음성 인식을 수행하는 음성 인식 방법 및 장치에 관한 것일 수 있다."}
{"patent_id": "10-2017-0054513", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "인공지능(Artificial Intelligence, AI) 시스템은 인간 수준의 지능을 구현하는 컴퓨터 시스템이며, 기존 Rule 기반 스마트 시스템과 달리 기계가 스스로 학습하고 판단하며 똑똑해지는 시스템이다. 인공지능 시스템은 사용 할수록 인식률이 향상되고 사용자 취향을 보다 정확하게 이해할 수 있게 되어, 기존 Rule 기반 스마트 시스템은점차 딥러닝 기반 인공지능 시스템으로 대체되고 있다. 인공지능 기술은 기계학습(딥러닝) 및 기계학습을 활용한 요소 기술들로 구성된다. 기계학습은 입력 데이터들의 특징을 스스로 분류/학습하는 알고리즘 기술이며, 요소기술은 딥러닝 등의 기계학 습 알고리즘을 활용하여 인간 두뇌의 인지, 판단 등의 기능을 모사하는 기술로서, 언어적 이해, 시각적 이해, 추론/예측, 지식 표현, 동작 제어 등의 기술 분야로 구성된다. 인공지능 기술이 응용되는 다양한 분야는 다음과 같다. 언어적 이해는 인간의 언어/문자를 인식하고 응용/처리 하는 기술로서, 자연어 처리, 기계 번역, 대화시스템, 질의 응답, 음성 인식/합성 등을 포함한다. 시각적 이해 는 사물을 인간의 시각처럼 인식하여 처리하는 기술로서, 객체 인식, 객체 추적, 영상 검색, 사람 인식, 장면 이해, 공간 이해, 영상 개선 등을 포함한다. 추론 예측은 정보를 판단하여 논리적으로 추론하고 예측하는 기술 로서, 지식/확률 기반 추론, 최적화 예측, 선호 기반 계획, 추천 등을 포함한다. 지식 표현은 인간의 경험정보 를 지식데이터로 자동화 처리하는 기술로서, 지식 구축(데이터 생성/분류), 지식 관리(데이터 활용) 등을 포함 한다. 동작 제어는 차량의 자율 주행, 로봇의 움직임을 제어하는 기술로서, 움직임 제어(항법, 충돌, 주행), 조 작 제어(행동 제어) 등을 포함한다. 최근에 스마트폰과 같이 다양한 기능을 복합적으로 수행하는 전자 장치들이 개발됨에 따라, 조작성을 향상시키 기 위하여 음성 인식 기능이 탑재된 전자 장치들이 출시되고 있다. 음성 인식 기능은, 별도의 버튼 조작 또는 터치 모듈에 대한 접촉에 의하지 않고 사용자의 음성을 인식함으로써 사용자가 장치를 손쉽게 제어할 수 있도록 한다는 장점을 가진다. 이러한 음성 인식 기능에 의하면, 예를 들어 스마트폰과 같은 휴대용 단말기에서는 별도의 버튼을 누르는 조작 없이 통화 기능을 수행하거나 문자 메시지를 작성할 수 있으며, 길찾기, 인터넷 검색, 알람 설정 등 다양한 기 능을 손쉽게 설정할 수 있다."}
{"patent_id": "10-2017-0054513", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "사용자가 음성 인식 장치와 자연스럽게 대화하듯이 발화함으로써 음성 인식 장치를 제어할 수 있도록 하여 사용 자의 편의를 높일 수 있는 방법이 요구된다."}
{"patent_id": "10-2017-0054513", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상술한 기술적 과제를 달성하기 위한 기술적 수단으로서, 일 실시예에 따른 음성 인식 방법은, 음성 인식 장치 가 동작하는 상황(situation)과 관련된 정보에 기초하여 적어도 하나의 활성화 단어를 결정하는 단계; 입력 오 디오 신호를 수신하는 단계; 상기 입력 오디오 신호에 상기 적어도 하나의 활성화 단어에 포함되는 활성화 단어 를 발화하는 음성 신호가 포함되었는지 여부에 기초하여, 상기 입력 오디오 신호에 대한 음성 인식을 수행하는 단계; 및 음성 인식이 수행된 결과를 출력하는 단계를 포함할 수 있다. 일 실시예에 따른 음성 인식 장치는, 입력 오디오 신호를 수신하는 수신부; 음성 인식 장치가 동작하는 상황과 관련된 정보에 기초하여 적어도 하나의 활성화 단어를 결정하고, 상기 입력 오디오 신호에 상기 적어도 하나의 활성화 단어에 포함되는 활성화 단어를 발화하는 음성 신호가 포함되었는지 여부에 기초하여, 상기 입력 오디오 신호에 대한 음성 인식을 수행하는, 프로세서; 및 음성 인식이 수행된 결과를 출력하는, 출력부를 포함할 수 있 다. 일 실시예에 따른 음성 인식 장치가 음성 인식 방법을 실행하도록 하는 명령어들을 포함하는 하나 이상의 프로 그램이 기록된 컴퓨터로 읽을 수 있는 기록 매체에 있어서, 음성 인식 방법은, 상기 음성 인식 장치가 동작하는 상황과 관련된 정보에 기초하여 적어도 하나의 활성화 단어를 결정하는 단계; 입력 오디오 신호를 수신하는 단 계; 상기 입력 오디오 신호에 상기 적어도 하나의 활성화 단어에 포함되는 활성화 단어를 발화하는 음성 신호가 포함되었는지 여부에 기초하여, 상기 입력 오디오 신호에 대한 음성 인식을 수행하는 단계; 및 음성 인식이 수 행된 결과를 출력하는 단계를 포함할 수 있다."}
{"patent_id": "10-2017-0054513", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "아래에서는 첨부한 도면을 참조하여 본 개시가 속하는 기술 분야에서 통상의 지식을 가진 자가 용이하게 실시할 수 있도록 본 개시의 실시예를 상세히 설명한다. 그러나 본 개시는 여러 가지 상이한 형태로 구현될 수 있으며 여기에서 설명하는 실시예에 한정되지 않는다. 또한, 도면에서 본 개시를 명확하게 설명하기 위해서 설명과 관 계없는 부분은 생략하였으며, 명세서 전체를 통하여 유사한 부분에 대해서는 유사한 도면 부호를 붙였다. 본 개시의 일부 실시예는 기능적인 블록 구성들 및 다양한 처리 단계들로 나타내어질 수 있다. 이러한 기능 블 록들의 일부 또는 전부는, 특정 기능들을 실행하는 다양한 개수의 하드웨어 및/또는 소프트웨어 구성들로 구현 될 수 있다. 예를 들어, 본 개시의 기능 블록들은 하나 이상의 마이크로프로세서들에 의해 구현되거나, 소정의 기능을 위한 회로 구성들에 의해 구현될 수 있다. 또한, 예를 들어, 본 개시의 기능 블록들은 다양한 프로그래 밍 또는 스크립팅 언어로 구현될 수 있다. 기능 블록들은 하나 이상의 프로세서들에서 실행되는 알고리즘으로 구현될 수 있다. 또한, 본 개시는 전자적인 환경 설정, 신호 처리, 및/또는 데이터 처리 등을 위하여 종래 기 술을 채용할 수 있다. 또한, 도면에 도시된 구성 요소들 간의 연결 선 또는 연결 부재들은 기능적인 연결 및/또는 물리적 또는 회로적 연결들을 예시적으로 나타낸 것일 뿐이다. 실제 장치에서는 대체 가능하거나 추가된 다양한 기능적인 연결, 물 리적인 연결, 또는 회로 연결들에 의해 구성 요소들 간의 연결이 나타내어질 수 있다. 이하 첨부된 도면을 참고하여 본 개시를 상세히 설명하기로 한다. 도 1a, 1b 및 1c는 일 실시예에 따른 음성 인식 시스템을 설명하기 위한 도면이다. 일 실시예에 따른 음성 인식 시스템은 딥러닝 기반 인공지능 시스템일 수 있다. 일 실시예에 따른 음성 인식 시스템은 인공지능 기술을 이용 함으로써, 음성 인식 장치가 동작하는 상황을 추론 및 예측하고, 인간의 언어를 인식하고 응용 및 처리할 수 있 다. 도 1a에 도시된 바와 같이, 일 실시예에 따른 음성 인식 시스템은 음성 인식 장치(100-1)를 포함할 수 있다. 예 를 들어, 음성 인식 장치(100-1)는, 스마트폰, 태블릿 PC, PC, 스마트 TV, PDA(personal digital assistant), 랩톱, 미디어 플레이어, 마이크로 서버, GPS(global positioning system) 장치, 전자책 단말기, 디지털방송용 단말기, 네비게이션, 키오스크, MP3 플레이어, 디지털 카메라 및 자동차의 전자 제어 장치, 중앙 정보 디스플레 이(CID, Central Information Display) 등 모바일 컴퓨팅 장치 또는 비모바일 컴퓨팅 장치일 수 있으나, 이에 제한되지 않는다. 일 실시예에 따른 음성 인식 장치(100-1)는, 화자가 발화한 음성 신호를 포함하는 오디오 신호를 입력 받고, 음성 신호에 대해서 음성 인식을 수행할 수 있다. 음성 인식 장치(100-1)는, 음성 인식 결과 를 출력할 수 있다. 또한, 도 1b에 도시된 바와 같이, 일 실시예에 따른 음성 인식 시스템은 음성 인식 장치(100-2) 및 음성 인식 장치(100-2)와 연결된 전자 장치를 포함할 수 있다. 음성 인식 장치(100-2)와 전자 장치는 유선 또는무선으로 연결 될 수 있다. 예를 들어, 음성 인식 장치(100-2)와 연결된 전자 장치는, 스마트폰, 태블릿 PC, PC, 스마트 TV, 자동차의 전자 제어 장치, 중앙 정보 디스플레이와 같은 모바일 컴퓨팅 장치 또는 비모바일 컴퓨팅 장치일 수 있다. 음성 인식 장치(100-2)는 전자 장치와 연동하는 웨어러블 디바이스, 스마트폰, 태 블릿 PC, PC, 네비게이션 또는 스마트 TV 등일 수 있으나, 이에 제한되지 않는다. 일 실시예에 따른 음성 인식 장치(100-2)는, 화자가 발화한 음성 신호를 포함하는 오디오 신호를 입력 받고, 입력된 오디오 신호를 전자 장치에게 송신 할 수 있다. 또는, 음성 인식 장치(100-2)는, 화자가 발화한 음성 신호를 포함하는 오디오 신호를 입력 받고, 입력된 오디오 신호로부터 검출된 음성 신호를 전자 장 치에게 송신 할 수 있다. 또는, 음성 인식 장치(100-2)는, 화자가 발화한 음성 신호를 포함하는 오디 오 신호를 입력 받고, 입력된 오디오 신호로부터 검출된 음성 신호의 특징을 전자 장치에게 송신 할 수 있 다. 전자 장치는, 음성 인식 장치(100-2)로부터 수신된 신호에 기초하여 음성 인식을 수행할 수 있다. 예를 들 어, 전자 장치는 음성 인식 장치(100-2)에서 입력된 오디오 신호로부터 검출된 음성 신호에 대해서 음성 인식을 수행할 수 있다. 전자 장치는, 음성 인식 결과를 출력하거나, 음성 인식 장치(100-2)가 음성 인식 결과를 출력 하도록 음성 인식 장치(100-2)에게 음성 인식 결과를 송신할 수 있다. 또한, 도 1c에 도시된 바와 같이, 일 실시예에 따른 음성 인식 시스템은 음성 인식 장치(100-3) 및 음성 인식 장치(100-3)와 연결된 서버를 포함할 수 있다. 음성 인식 장치(100-3)와 서버는 유선 또는 무선으로 연결 될 수 있다. 일 실시예에 따른 음성 인식 장치(100-3)는, 화자가 발화한 음성 신호를 포함하는 오디오 신호를 입력 받고, 입력된 오디오 신호를 서버에게 송신 할 수 있다. 또는, 음성 인식 장치(100-3)는, 화자가 발화 한 음성 신호를 포함하는 오디오 신호를 입력 받고, 입력된 오디오 신호로부터 검출된 음성 신호를 서버에 게 송신 할 수 있다. 또는, 음성 인식 장치(100-3)는, 화자가 발화한 음성 신호를 포함하는 오디오 신호를 입력 받고, 입력된 오디오 신호로부터 검출된 음성 신호의 특징을 서버에게 송신 할 수 있다. 서버는, 음성 인식 장치(100-3)로부터 수신된 신호에 기초하여 음성 인식을 수행할 수 있다. 예를 들어, 서버는 음성 인식 장치(100-3)에서 입력된 오디오 신호로부터 검출된 음성 신호에 대해서 음성 인식을 수 행할 수 있다. 서버는, 음성 인식 장치(100-3)가 음성 인식 결과를 출력 하도록 음성 인식 장치(100-3)에 게 음성 인식 결과를 송신할 수 있다. 도 1a, 1b 및 1c에 도시된 음성 인식 시스템은, 사용자의 음성을 인식함으로써 사용자가 장치를 손쉽게 제어할 수 있도록 한다는 장점을 가진다. 다만, 음성 인식 장치가 음성 인식 기능을 계속해서 활성화 하는 경우, 입력되는 오디오 신호가 음성 인식의 대 상이 되는 발화인지 또는 음성 인식의 대상이 아닌 잡음인지 여부를 음성 인식 장치가 구분하기 어렵기 때문에 음성 인식 성능이 저하되는 문제가 발생한다. 또한, 음성 인식 장치가 음성 검출 동작 및 음성 인식 동작을 계 속해서 수행하게 되면, 음성 인식 장치는 전력이나 메모리 용량을 불필요하게 소비할 수 있다. 따라서, 음성 인식 장치는, 사용자가 음성 명령을 발화할 때에만 음성 인식 기능을 활성화 시킬 수 있어야 한다. 일 예로서, 종래의 음성 인식 장치는, 사용자가 버튼을 누름으로써 음성 인식 기능을 활성화 시키는 방법을 이 용하였다. 이러한 활성화 방법은, 사용자가 음성 인식 장치로부터 일정한 물리적 거리 내에 위치하여야 한다는 제약이 있고, 음성 인식 기능의 활성화를 원하지 않을 경우 버튼을 누르지 않도록 사용자의 주의를 요한다는 단 점이 있었다. 다른 예로서, 종래의 음성 인식 장치는, 미리 결정된 하나의 특정한 활성화 단어가 발화되면 음성 인식 기능을 활성화 시키는 방법을 이용하였다. 이러한 활성화 방법은, 사용자가 음성 명령을 발화하기 전에 특정한 활성화 단어를 발화해야 하므로 부자연스럽다는 단점이 있었다. 앞에서 살펴본 바와 같이 종래의 음성 인식 장치는, 음성 인식 기능을 활성화 시키기 위하여 사용자의 적극적인 행동을 필요로 하였다. 따라서, 사용자의 적극적인 행동이 개입되지 않을 경우 음성 인식 기능을 시작할 수 없 었으므로, 음성 인식 장치가 음성 인식을 통하여 상황을 앞서서 주도하는(proactive) 서비스를 제공하는데 제약 이 있었다. 따라서, 일 실시예에 따른 음성 인식 장치는, 사용자가 음성 인식 장치와 자연스럽게 대화하듯이 발화함으로써 음성 인식 장치를 제어할 수 있도록 하여 사용자의 편의를 높일 수 있는 방법을 제공한다. 일 실시예에 따른 음 성 인식 장치는, 사용자의 직접적인 동작이 없는 경우에도 상황을 앞서서 주도하는(proactive) 서비스를 제공할 수 있다. 일 실시예는, 음성 인식 장치가 동작하는 상황에 따라 지정된 다수의 활성화 단어들에 기초하여 음성 인식 기능을 활성화하는 방법을 제안한다. 또한, 일 실시예는, 음성 인식 장치가 음성 인식을 수행하기 이전에 동작하는 방법을 제안한다. 도 2a는 일반적인 음성 인식 장치의 동작 방법을 설명하기 위한 도면이다. 도 2a는 일반적인 음성 인식 장치가 “하이 갤럭시”라는 하나의 특정한 활성화 단어가 발화되면 음성 인 식 기능을 활성화하는 경우를 예로 들어 도시한다. 도 2a에 도시된 바와 같이, 사용자는, 오늘 날씨를 묻기 위하여 음성 명령 앞에 “하이 갤럭시”라는 활성 화 단어를 발화하여야 한다. 음성 인식 장치는, “하이 갤럭시”라는 활성화 단어를 발화하는 음성 신호가 수신되면, 음성 인식 기능을 활성화 할 수 있다. 음성 인식 장치는, 활성화 단어 다음에 발화되는 문장인 “오늘 날씨 어때?”라는 사 용자의 음성 명령에 대해서 음성 인식을 수행하고, 사용자의 음성 명령에 대한 응답으로서 “오늘 날씨는 맑음 입니다”라는 날씨 정보를 제공할 수 있다. 다음으로, 사용자는, 현재 시각을 묻기 위하여 음성 명령 앞에 “하이 갤럭시”라는 활성화 단어를 발화하 여야 한다. 음성 인식 장치는, “하이 갤럭시”라는 활성화 단어를 발화하는 음성 신호가 수신되면, 음성 인식 기능을 활성화 할 수 있다. 음성 인식 장치는, 활성화 단어 다음에 발화되는 문장인 “지금 몇 시야?”라는 사용 자의 음성 명령에 대해서 음성 인식을 수행하고, 사용자의 음성 명령에 대한 응답으로서 “오후 3시 20분입니다.”라는 시각 정보를 제공할 수 있다. 도 2a에 도시된 바와 같이, 지정된 하나의 활성화 단어만을 이용하여 음성 인식 기능을 활성화 하는 경우, 활성 화 단어를 매번 발화하는 것이 사용자에게 번거롭고 부자연스러울 수 있다. 따라서, 일 실시예는, 별도의 활성화 단어를 발화하거나 음성 인식 기능을 활성화 시키기 위한 사용자의 동작 없이도, 음성 인식 장치가 사용자가 자연스럽게 발화하는 음성 명령에 대한 음성 인식을 수행할 수 있는 방법을 제안한다. 도 2b는 일 실시예에 따른 음성 인식 장치의 동작 방법을 설명하기 위한 도면이다. 도 2b에 도시된 바와 같이, 사용자는, 오늘 날씨를 묻기 위하여 별도의 활성화 동작 없이 오늘 날씨를 묻는 음성 명령인 “오늘 날씨 어때?”를 발화할 수 있다. 일 실시예에 따른, 음성 인식 장치는, “오늘 날씨 어때?”라는 음성 명령을 발화하는 음성 신호가 수신되면, 음성 인식 기능을 활성화 할 수 있다. 음성 인식 장 치는, “오늘 날씨 어때?”라는 사용자의 음성 명령에 대해서 음성 인식을 수행하고, 사용자의 음성 명령 에 대한 응답으로서 “오늘 날씨는 맑음입니다”라는 날씨 정보를 제공할 수 있다. 다음으로, 사용자는, 현재 시각을 묻기 위하여 별도의 활성화 동작 없이 현재 시각을 묻는 음성 명령인 “ 지금 몇 시야?”를 발화할 수 있다. 음성 인식 장치는, “지금 몇 시야?”라는 음성 명령을 발화하는 음성 신호가 수신되면, 음성 인식 기능을 활성화 할 수 있다. 음성 인식 장치는, “지금 몇 시야?”라는 사용자 의 음성 명령에 대해서 음성 인식을 수행하고, 사용자의 음성 명령에 대한 응답으로서 “오후 3시 20분입니다. ”라는 시각 정보를 제공할 수 있다. 이하에서는, 일 실시예에 따른 음성 인식 장치가 음성 인식 방법을 수행하는 구체적인 방법에 대해 서술하도록 하겠다. 다만, 도 1a, 1b, 및 1c에 도시된 바와 같이, 일 실시예에 따른 음성 인식 시스템은 적어도 하나의 음 성 인식 장치를 포함하고, 서버 또는 전자 장치를 더 포함할 수 있다. 이하에서는, 설명의 편의를 위해 “음성 인식 장치”에서 수행되는 음성 인식 방법에 대해 서술하지만, 이하에서 기술되는 음성 인식 장치의 동작의 일 부 또는 전부는 서버에서도 수행될 수 있으며, 복수의 전자 장치들에 의해 부분적으로 수행될 수 있다. 도 3은 일 실시예에 따라 음성 인식 장치가 음성 인식을 수행하는 방법의 흐름도이다. 단계 S310에서 일 실시예에 따른 음성 인식 장치는, 음성 인식 장치가 동작하는 상황과 관련된 정보 에 기초하여 적어도 하나의 활성화 단어를 결정할 수 있다. 일 실시예에 따른 음성 인식 장치는 인공지능 기술을 이용함으로써, 음성 인식 장치가 동작하는 상황을 추론 및 예측하고, 적어도 하나의 활성화 단어를 결정할 수 있다. 상황과 관련된 정보는, 음성 인식 장치의 위치, 시간, 음성 인식 장치가 다른 전자 장치와 연결되었 는지 여부, 음성 인식 장치가 접속한 네트워크의 종류, 음성 인식 장치가 움직이는지 여부, 및 음성 인식 장치를 사용하는 사용자의 특성과 관련된 정보 중 적어도 하나를 포함할 수 있다. 일 예로서, 음성 인식 장치는, 음성 인식 장치와 연결된 적어도 하나의 전자 장치에 대한 정보를 획 득할 수 있다. 음성 인식 장치는, 적어도 하나의 전자 장치와 관련된 단어를 적어도 하나의 활성화 단어로 서 결정할 수 있다. 다른 예로서, 음성 인식 장치는, 음성 인식 장치가 접속된 네트워크에 대한 정보 를 획득할 수 있다. 음성 인식 장치는, 음성 인식 장치가 접속된 네트워크에 대한 정보에 기초하여, 음성 인식 장치가 동작하는 상황을 파악할 수 있다. 예를 들어, 음성 인식 장치는, 음성 인식 장치가 접속된 네트워크에 대한 정보에 기초하여, 음성 인식 장치가 동작하는 위치를 파악할 수 있다. 예를 들어, 음성 인식 장치는, 음성 인식 장치가 집 안에 설치된 WiFi에 접속하는 경우, 음성 인식 장치 의 위치가 집 안이라고 판단할 수 있다. 음성 인식 장치는, 집에 대응하는 적어도 하나의 활성화 단 어를 결정할 수 있다. 예를 들어, 음성 인식 장치는, TV, 에어컨, 청소기, 날씨, 일정 등을 집에 대응하는 활성화 단어들로서 결정할 수 있다. 일 실시예에 따른 음성 인식 장치는, 적어도 하나의 활성화 단어를 결정하기에 앞서, 복수의 상황들 각각 에 대응하는 복수의 후보 활성화 단어들을 저장하는 단계를 더 포함할 수 있다. 음성 인식 장치는, 음성 인식 장치가 동작하는 상황과 관련된 정보를 획득하고, 저장된 데이터를 검색함으로써, 음성 인식 장치 가 동작하는 상황에 대응하는 적어도 하나의 후보 활성화 단어를 추출할 수 있다. 음성 인식 장치는, 적어도 하나의 후보 활성화 단어를 적어도 하나의 활성화 단어로서 결정할 수 있다. 일 실시예에 따른 음성 인식 장치는, 복수의 후보 활성화 단어들을 저장하기 위해서, 음성 인식 장치(10 0)가 복수의 상황들에서 사용자로부터 수신하는 음성 명령들에 대한 정보를 수신할 수 있다. 음성 인식 장치 는, 음성 명령들에 포함되는 복수의 단어들을 추출할 수 있다. 음성 인식 장치는, 복수의 상황들 중 에서 특정 상황에서 수신되는 음성 명령들 내에 복수의 단어들이 포함되는 빈도에 기초하여, 적어도 하나의 단 어를 특정 상황에 대응하는 후보 활성화 단어로서 저장할 수 있다. 일 실시예에 따른 음성 인식 장치는, 음성 인식 장치의 음성 인식 기능이 민감하게 활성화 되는 정도 에 기초하여, 결정되는 적어도 하나의 활성화 단어의 개수를 결정할 수 있다. 예를 들어, 음성 인식 장치의 음성 인식 기능이 민감하게 활성화 되는 정도는, 다양한 음성 신호들에 응답 하여 음성 인식 장치가 활성화되는 속도, 음성 인식 장치가 활성화되는 난이도, 및 음성 인식 장치 가 활성화 되는 빈도 중 적어도 하나를 의미할 수 있다. 예를 들어, 다양한 음성 신호들에 응답하여 음성 인식 장치가 높은 빈도로 활성화될 경우, 음성 인식 장치의 음성 인식 기능이 민감하게 활성화 된다 고 판단될 수 있다. 다양한 음성 신호들에 응답하여 음성 인식 장치가 상대적으로 낮은 빈도로 활성화될 경우, 음성 인식 장치의 음성 인식 기능이 덜 민감하게 활성화 된다고 판단될 수 있다. 음성 인식 기능이 민감하게 활성화 되는 정도는, 사용자 입력에 기초하여 결정되거나, 음성 인식 장치의 위치에 기초하여 결정될 수 있다. 예를 들어, 음성 인식 장치가 집과 같이 사적인 공간에 위치한 경우, 음 성 인식 기능이 민감하게 활성화되도록 결정되고, 음성 인식 장치가 회사와 같이 많은 사람들이 있는 공적 인 공간에 위치한 경우, 음성 인식 기능이 덜 민감하게 활성화되도록 결정될 수 있다. 예를 들어, 음성 인식 장 치가 집과 같이 사적인 공간에 위치한 경우, 음성 인식 기능이 높은 빈도로 활성화되도록 결정되고, 음성 인식 장치가 회사와 같이 많은 사람들이 있는 공적인 공간에 위치한 경우, 음성 인식 기능이 상대적으로 낮은 빈도로 활성화되도록 결정될 수 있다. 단계 S320에서 일 실시예에 따른 음성 인식 장치는, 입력 오디오 신호를 수신할 수 있다. 예를 들어, 음성 인식 장치는, 실시간으로 입력되는 입력 오디오 신호를 소정 길이의 프레임 단위로 분할 하고, 프레임 단위로 분할된 입력 오디오 신호를 처리할 수 있다. 프레임 단위로 분할된 입력 오디오 신호로부 터, 프레임 단위의 음성 신호를 검출할 수 있다. 일 실시예에 따른 음성 인식 장치는, 입력 오디오 신호를 수신하고 저장할 수 있다. 예를 들어, 음성 인식 장치는, VAD(Voice Activation Detection) 또는 EPD(End Point Detection)에 의해 발화의 존재 또는 부재 (presence or absence of human speech)를 검출함으로써, 문장 단위로 입력 오디오 신호를 수신하고 저장할 수있다. 예를 들어, 음성 인식 장치는, 발화가 시작되면 문장이 시작되었다고 판단하고 입력되는 오디오 신호의 저 장을 시작할 수 있다. 음성 인식 장치는, 침묵(pause) 후 발화가 시작되면 문장이 시작되었다고 판단하고 입력되는 오디오 신호의 저장을 시작할 수 있다. 일 실시예에 따른 음성 인식 장치는, 활성화 단어의 발화 없이 발화가 종료되면 문장이 종료되었다고 판단 하고 저장되었던 오디오 신호를 삭제할 수 있다. 또는, 음성 인식 장치는, 도 5에 도시된 바와 같이 소정 시간 길이 단위로 오디오 신호를 수신하고 저장할 수 있다. 단계 S330에서 일 실시예에 따른 음성 인식 장치는, 입력 오디오 신호에 적어도 하나의 활성화 단어에 포 함되는 활성화 단어를 발화하는 음성 신호가 포함되었는지 여부에 기초하여, 입력 오디오 신호에 대한 음성 인 식을 수행할 수 있다. 일 실시예에 따른 음성 인식 장치는, 인공지능 기술을 이용함으로써, 입력 오디오 신호에 포함되는 화자의 언어를 인식하고 응용 및 처리할 수 있다. 일 실시예에 따른 음성 인식 장치는, 적어도 하나의 활성화 단어에 포함되는 활성화 단어를 발화하는 음성 신호를 포함하는 입력 오디오 신호에 대해서 음성 인식을 수행할 수 있다. 일 실시예에 따른 음성 인식 장치는, 입력 오디오 신호가 활성화 단어를 발화하는 음성 신호를 포함하는지 여부를 판단할 수 있다. 음성 인식 장치는, 입력 오디오 신호가 적어도 하나의 활성화 단어에 포함되는 활 성화 단어를 발화하는 음성 신호를 포함한다고 판단되는 경우, 저장된 입력 오디오 신호 및 이후에 수신되는 입 력 오디오 신호에 대해서 음성 인식을 수행할 수 있다. 일 실시예에 따른 음성 인식 장치는, 활성화 단어를 포함하는 음성 명령을 포함하는 오디오 신호를 서버 (또는 내장된 음성 인식 모듈)에게 전송할 수 있다. 서버(또는 내장된 음성 인식 모듈)는, 수신된 오디오 신호 로부터 활성화 단어를 추출할 수 있다. 서버(또는 내장된 음성 인식 모듈)는, 활성화 단어를 포함한 음성 명령 을 인식할지, 활성화 단어를 제거하고 활성화 단어의 앞 뒤에 위치한 음성 명령을 인식할지 여부를 판단할 수 있다. 서버(또는 내장된 음성 인식 모듈)는, 판단 결과에 기초하여 음성 인식을 수행할 수 있다. 음성 인식 장 치는, 활성화 단어가 음성 명령 내에서 의미를 갖는 경우, 활성화 단어를 포함한 음성 명령에 대해 음성 인식을 수행할 수 있다. 반면에, 음성 인식 장치는, 활성화 단어가 음성 명령 내에서 의미를 갖지 않는 경 우, 활성화 단어를 제거한 앞 문장 또는 뒤 문장에 대해 음성 인식을 수행할 수 있다. 예를 들어, 음성 인식 장치의 음성 인식 기능을 활성화 하기 위해서, “하이 로봇”이 기본 활성화 단어로 서 결정되고, “날씨”가 음성 인식 장치의 현재 상황에 대응하는 활성화 단어로서 결정된 경우를 예로 들 어 설명한다. 사용자는 음성 인식 장치에게 “하이 로봇. 하나(Hana)에게 전화를 걸어줘”라고 발화할 수 있다. 음성 인 식 장치는, “하이 로봇”이라는 활성화 단어를 발화하는 음성 신호를 수신하였으므로, 활성화 단어를 포 함하는 음성 명령인 “하이 로봇. 하나에게 전화를 걸어줘”를 서버(또는 내장된 음성 인식 모듈)에게 전송할 수 있다. 서버(또는 내장된 음성 인식 모듈)는, 활성화 단어인 “하이 로봇”이 음성 명령 내에서 의미를 갖지 않는 기본 활성화 단어이므로, 활성화 단어를 제거한 음성 명령인 “하나에게 전화를 걸어줘”에 대해서만 음성 인식을 수행할 수 있다. 또는, 사용자는 음성 인식 장치에게 “오늘 날씨 어때?”라고 발화할 수 있다. 음성 인식 장치는, “ 날씨”라는 활성화 단어를 발화하는 음성 신호를 수신하였으므로, 활성화 단어를 포함하는 음성 명령인 “오늘 날씨 어때?”를 서버(또는 내장된 음성 인식 모듈)에게 전송할 수 있다. 서버(또는 내장된 음성 인식 모듈)는, 활성화 단어인 “날씨”가 음성 명령 내에서 의미를 가지므로, 활성화 단어를 포함한 음성 명령인 “오늘 날씨 어때?”에 대해서 음성 인식을 수행할 수 있다. 일 실시예에 따른 음성 인식 장치는, 입력 오디오 신호로부터 활성화 단어를 발화하는 음성 명령이 제외된 오디오 신호를 서버(또는 내장된 음성 인식 모듈)에게 전송할 수 있다. 음성 인식 장치는 입력 오디오 신 호로부터 활성화 단어를 추출할 수 있다. 음성 인식 장치는, 활성화 단어를 발화하는 음성 명령을 포함하 는 오디오 신호를 서버(또는 내장된 음성 인식 모듈)에게 전송할지, 활성화 단어를 발화하는 음성 명령이 제거 된 오디오 신호를 전송할지 여부를 판단할 수 있다. 음성 인식 장치는, 활성화 단어가 음성 명령 내에서 의미를 갖는 경우, 활성화 단어를 발화하는 음성 명령을 포함하는 오디오 신호를 서버(또는 내장된 음성 인식 모듈)에게 전송할 수 있다. 반면에, 음성 인식 장치는, 활성화 단어가 음성 명령 내에서 의미를 갖지 않는 경우, 활성화 단어를 발화하는 음성 명령을 제거한 앞 문장 또는 뒤 문장을 서버(또는 내장된 음성 인식 모듈)에게 전송할 수 있다. 예를 들어, 음성 인식 장치의 음성 인식 기능을 활성화 하기 위해서, “하이 로봇”이 기본 활성화 단어로 서 결정되는 경우를 예로 들어 설명한다. 사용자는 음성 인식 장치에게 “하이 로봇. 하나(Hana)에게 전화를 걸어줘”라고 발화할 수 있다. 음성 인 식 장치는, 활성화 단어인 “하이 로봇”이 음성 명령 내에서 의미를 갖지 않는 기본 활성화 단어이므로, 활성화 단어를 발화한 음성 명령을 제거한 오디오 신호인 “하나에게 전화를 걸어줘”만을 서버(또는 내장된 음 성 인식 모듈)에게 전송할 수 있다. 일 실시예에 따른 음성 인식 장치는, 입력 오디오 신호가 활성화 단어를 발화하는 음성 신호를 포함한다고 판단되는 경우, 입력 오디오 신호에 포함되는 음성 명령이 음성 인식 장치의 응답을 요청하는 직접 명령인 지 여부를 판단할 수 있다. 음성 인식 장치는, 추출된 텍스트에 대한 자연어 이해(Natural Language Understanding) 및 문형 분석에 기초하여, 음성 명령이 직접 명령인지 간접 명령인지 여부를 판단할 수 있다. 예를 들어, 음성 인식 장치는, 음성 명령의 종결 어미, 억양, 음성 명령이 수신되는 방향 및 음성 명령의 크기 중 적어도 하나에 기초하여, 음성 명령이 직접 명령인지 간접 명령인지 여부를 판단할 수 있다. 음성 인식 장치는, 판단된 음성 명령의 형태에 따라, 음성 명령을 서버(또는 내장된 음성 인식 모듈)에게 전송할 것 인지 여부 또는 음성 명령에 대해 음성 인식을 수행할 것인지 여부를 결정할 수 있다. 예를 들어, 음성 인식 장 치는, 인공지능 기술을 이용하여 자연어 이해 및 문형 분석을 수행할 수 있다. 일 실시예에 따른 음성 인식 장치는, 음성 명령이 직접 명령이라고 판단 되는 경우, 활성화 단어를 포함하 는 음성 명령을 포함하는 오디오 신호를 서버(또는 내장된 음성 인식 모듈)에게 전송할 수 있다. 활성화 단어를 발화하는 음성 신호가 수신되면, 음성 인식 장치는, 저장된 입력 오디오 신호 및 이후에 수신되는 입력 오 디오 신호를 서버(또는 내장된 음성 인식 모듈)에게 전송할 수 있다. 일 실시예에 따른 음성 인식 장치는, 저장된 입력 오디오 신호 중에서 활성화 단어가 포함된 문장을 포함 하는 신호를 검색하고 추출할 수 있다. 음성 인식 장치는, 활성화 단어가 포함된 문장을 포함하는 오디오 신호를 서버(또는 내장된 음성 인식 모듈)에게 전송할 수 있다. 서버(또는 내장된 음성 인식 모듈)는, 음성 명 령에 대한 음성 인식을 수행할 수 있다. 반면에, 일 실시예에 따른 음성 인식 장치는, 음성 명령이 음성 인식 장치의 응답을 요청하는 직접 명령이 아닌 간접 명령이라고 판단되는 경우, 음성 명령을 포함하는 오디오 신호를 서버(또는 내장된 음성 인식 모듈)에게 전송하지 않을 수 있다. 음성 인식 장치는, 이 전에 입력되었던 오디오 신호를 무시하고, 새롭 게 입력 오디오 신호를 수신하고 저장하는 동작을 반복할 수 있다. 음성 인식 장치는, 새로운 입력 오디오 신호가 활성화 단어를 발화하는 음성 신호를 포함하는지 여부를 판단할 수 있다. 단계 S340에서 일 실시예에 따른 음성 인식 장치는, 음성 인식이 수행된 결과를 출력할 수 있다. 일 실시예에 따른 음성 인식 장치는, 서버(또는 내장된 음성 인식 모듈)에서 음성 인식이 수행된 결과를 출력할 수 있다. 일 예로서, 음성 인식이 수행된 결과는, 음성 명령으로부터 추출된 텍스트를 포함할 수 있다. 다른 예로서, 음성 인식이 수행된 결과는, 음성 인식이 수행된 결과에 대응하는 동작을 수행하는 화면일 수 있 다. 음성 인식 장치는, 음성 인식이 수행된 결과에 대응하는 동작을 수행할 수 있다. 예를 들어, 음성 인 식 장치는, 음성 인식이 수행된 결과에 대응하는 음성 인식 장치의 기능을 결정하고, 해당 기능을 수 행하는 화면을 출력할 수 있다. 또는, 음성 인식 장치는, 음성 인식이 수행된 결과에 대응하는 키워드를 외부 서버로 전송하고, 전송된 키워드에 관련된 정보를 서버로부터 수신하여 화면 상에 출력할 수 있다. 일 실시예에 따른 음성 인식 장치는, 음성 명령을 분석함으로써, 분석 결과에 기초하여 음성 인식이 수행 된 결과를 출력하는 방법을 결정할 수 있다. 일 예로서, 음성 인식 장치는, 음성 명령에 응답하여, 소리, 빛, 영상, 진동 등 다양한 방식으로 음성 인 식이 수행된 결과를 출력할 수 있다. 다른 예로서, 음성 인식 장치는, 음성 명령에 대한 응답을 대기하면 서, 응답 대기 중임을 사용자에게 알릴 수 있다. 예를 들어, 음성 인식 장치는, 소리, 빛, 영상, 진동 등 다양한 방식으로 응답 대기 중임을 사용자에게 알릴 수 있다. 또 다른 예로서, 음성 인식 장치는, 음성 인 식이 수행된 결과를 저장하고, 이후에 사용자가 음성 인식이 수행된 결과와 관련된 발화를 할 때에, 음성 인식 이 수행된 결과를 출력할 수 있다. 일 실시예에 따른 음성 인식 장치는, 입력 오디오 신호에 포함되는 음성 명령이 음성 인식 장치의 응 답을 요청하는 직접 명령인지 여부를 판단할 수 있다. 음성 인식 장치는, 판단된 음성 명령의 형태에 따라 음성 인식이 수행된 결과를 바로 출력할지 혹은 사용자로부터 확인 명령이 수신되면 상기 음성 인식이 수행된 결과를 출력할지 여부를 결정할 수 있다. 일 실시예에 따른 음성 인식 장치는, 입력 오디오 신호에 대해서 음성 인식을 수행함으로써, 사용자가 발 화한 텍스트를 추출할 수 있다. 음성 인식 장치는, 추출된 텍스트에 대한 자연어 이해 및 문형 분석에 기 초하여, 입력 오디오 신호에 포함되는 음성 명령이 음성 인식 장치의 응답을 요청하는 직접 명령인지 여부를 판 단할 수 있다. 음성 인식 장치는, 음성 명령이 직접 명령이라고 판단되는 경우, 음성 명령에 대해 응답하 는 동작을 수행할 수 있다. 음성 인식 장치는, 음성 명령이 직접 명령이 아니라고 판단되는 경우, 음성 명령에 대한 응답이 가능하고 응답 대기 중임을 표시할 수 있다. 음성 인식 장치는, 사용자로부터 확인 명령이 수신되면, 음성 명령에 대해 응답하는 동작을 수행할 수 있다. 도 4는 일 실시예에 따라 음성 인식 장치가 음성 인식을 수행하는 방법을 설명하기 위한 도면이다. 도 4는 음성 인식 장치가 자동차의 전자 제어 장치와 연결되어 동작하는 경우를 예로 들어 도시한다. 예를 들어, 음성 인식 장치는 자동차의 전자 제어 장치와 블루투스(Bluetooth) 방식으로 통신할 수 있다. 일 실시예에 따른 음성 인식 장치는, 음성 인식 장치가 자동차의 전자 제어 장치에 연결되었다 는 정보에 기초하여, 음성 인식 장치의 위치가 자동차라고 판단할 수 있다. 음성 인식 장치는, 자동 차에 대응하는 적어도 하나의 활성화 단어를 결정할 수 있다. 예를 들어, 음성 인식 장치는, 네비게이션, 에어컨, 창문, 주유구, 트렁크, 사이드 미러 등을 포함하는 자동차에 대응하는 후보 활성화 단어들과 예를 들어, 문자 메시지(text message), 일정 등을 포함하는 자동차에서 사용 가능한 기능에 대응하는 후보 활성화 단어들을 추출할 수 있다. 음성 인식 장치는, 추출된 후보 활성화 단어들을 현재 상황에 적합한 활성화 단 어들로서 결정할 수 있다. 또한, 일 실시예에 따른 음성 인식 장치는, 음성 인식 장치가 움직이는지 여부에 기초하여, 활성화 단어를 결정할 수 있다. 음성 인식 장치는, 자동차가 주행 중인 경우, 자동차에 대응하는 후보 활성화 단 어들과 자동차에서 사용 가능한 기능에 대응하는 후보 활성화 단어들 중에서 안전한 자동차 운행에 방해가 되지 않는 후보 활성화 단어들만을 활성화 단어들로서 결정할 수 있다. 예를 들어, 음성 인식 장치는, 자동차가 정지 중인 경우, 네비게이션, 에어컨, 주유구, 트렁크, 사이드 미 러, 문자 메시지, 일정 등 자동차와 관련된 모든 후보 활성화 단어들을 활성화 단어로서 결정할 수 있다. 반면 에, 음성 인식 장치는, 자동차가 주행 중인 경우, 안전한 자동차 운행에 방해가 될 수 있는 음성 명령들에 는 응답하지 않도록 활성화 단어를 결정할 수 있다. 예를 들어, 자동차가 주행 중인 경우, 음성 명령에 의해 자 동차의 트렁크를 열거나, 주유구를 여는 것은 안전한 자동차 운행에 방해가 될 수 있다. 따라서, 음성 인식 장 치는, 자동차가 주행 중인 경우, 안전한 자동차 운행에 방해가 되지 않는, 네비게이션, 에어컨, 문자 메시 지, 일정 등의 일부 후보 활성화 단어들만을 활성화 단어들로서 결정할 수 있다. 음성 인식 장치는, 음성 인식을 수행하기에 앞서, 입력 오디오 신호를 수신하고 저장할 수 있다. 음성 인 식 장치는, 입력되는 오디오 신호를 분석함으로써, 입력되는 오디오 신호가 활성화 단어를 발화하는 음성 신호를 포함하는지 여부를 판단할 수 있다. 사용자는, 기차역까지 가는 길을 안내 받기 위하여 “하이 로봇”과 같은 특정 활성화 단어를 발화하지 않 아도 음성 인식 기능을 이용할 수 있다. 사용자는, 기차역까지 가는 길을 안내 받기 위하여 길 안내를 요청 하는 음성 명령인 “기차역 가는 길을 네비게이션에서 찾아줘!”를 발화할 수 있다. 일 실시예에 따른, 음성 인 식 장치는, 자동차에 대응하는 활성화 단어인 “네비게이션”을 발화하는 음성 신호가 수신되면, 음성 인 식 기능을 활성화 할 수 있다. 음성 인식 장치는, “네비게이션”을 발화하는 음성 신호를 포함하는 전체 음성 명령인 “기차역 가는 길 을 네비게이션에서 찾아줘!” 에 대해서 음성 인식을 수행할 수 있다. 음성 인식 장치는, “네비게이션” 을 발화하는 음성 신호가 수신되면, 활성화 단어 이후에 수신되는 음성 명령인 “에서 찾아줘”를 서버(또는 내 장된 음성 인식 모듈)에게 전송하고 음성 인식을 수행할 수 있다. 또한, 음성 인식 장치는, 활성화 단어 이후에 수신되는 음성 명령과 함께, 이전에 수신되어 저장된 음성 명령을 서버(또는 내장된 음성 인식 모듈)에 게 전송하고 음성 인식을 수행할 수 있다. 음성 인식 장치는, “네비게이션”을 발화하는 음성 신호가 수신되면, 활성화 단어 이전에 수신되어 저장된 음성 명령인 “기차역 가는 길을”, 활성화 단어 “네비게이션”, 및 활성화 단어 이후에 수신되는 음성 명령인 “에서 찾아줘” 에 대해서 음성 인식을 수행할 수 있다. 음성 인식 장치는, 사용자의 음성 명령에 대한 응답으로서 기차역까지 가는 경로를 안내 할 수 있다. 도 4에는, 음성 인식 장치의 위치가 자동차인 경우가 예로서 도시되었다. 그러나, 실시예는 이에 제한되지 않는다. 예를 들어, 음성 인식 장치의 위치가 집이라고 판단되는 경우, “전등, 텔레비전, 에어컨, 세탁기, 냉장고, 날씨, 날짜, 시간” 등을 집에 대응하는 활성화 단어들로서 결정할 수 있다. 각 상황에 대응하는 활성화 단어의 구체적인 예는 다음과 같다. 일 실시예에 따른 음성 인식 장치는, 음성 인식 장치의 위치 또는 음성 인식 장치가 위치한 공 간의 특성에 기초하여, 적어도 하나의 활성화 단어를 결정할 수 있다. 음성 인식 장치는, 음성 인식 장치가 어떠한 전자 장치와 연결되었는지, 어떠한 네트워크에 연결되었 는지 또는 어떠한 기지국에 연결되었는지에 기초하여 음성 인식 장치의 위치와 관련된 정보를 획득할 수 있다. 예를 들어, 음성 인식 장치는, 자동차 내의 오디오와 블루투스 방식으로 연결된 경우, 음성 인식 장치 가 자동차 내에 위치한 것으로 판단할 수 있다. 또는, 음성 인식 장치는, 음성 인식 장치에 포 함된 GPS(Global Positioning system) 모듈에 의해 현재 위치와 관련된 정보를 획득할 수 있다. 일 예로서, 음성 인식 장치는, 음성 인식 장치가 집 안에 위치한 경우, 집 안에서 음성 인식 장치 가 제어할 수 있는 전자 장치 또는 전자 장치의 기능과 관련된 단어들을 활성화 단어들로서 결정할 수 있 다. 음성 인식 장치는, 음성 인식 장치의 집 안에서의 위치가 달라짐에 따라서, 위치에 따라 서로 다 른 단어들을 활성화 단어들로서 결정할 수 있다. 예를 들어, 음성 인식 장치가 거실에 위치한 경우, 집 안 의 모든 전자 장치들과 관련된 단어들을 활성화 단어들로서 결정할 수 있다. 반면에, 음성 인식 장치가 방 안에 위치한 경우, 방 안의 전자 장치들과 관련된 단어들만을 활성화 단어들로서 결정할 수 있다. 다른 예로서, 음성 인식 장치는, 음성 인식 장치가 차량 안에 위치한 경우, 차량 안에서 음성 인식 장치가 제어할 수 있는 전자 장치 또는 기능과 관련된 단어들을 활성화 단어들로서 결정할 수 있다. 음성 인식 장치는, 음성 인식 장치의 차량 안에서의 위치가 달라지거나 음성 인식 장치의 사용자의 특성이 달라짐에 따라서도, 서로 다른 활성화 단어를 결정할 수 있다. 음성 인식 장치가 운전석에 위치하거나 음성 인식 장치의 사용자가 운전을 하는 경우, 차량 안에서 운전자가 제어할 수 있는 모든 전자 장치들 및 기능들과 관련된 단어들을 활성화 단어들로서 결정할 수 있다. 반면에, 음성 인식 장치가 운전석 이외의 좌석에 위치하거나 음성 인식 장치의 사용자가 운전을 하지 않는 경우, 운전에 방해되지 않는 전자 장치들 및 기능들과 관련된 단어들만을 활성화 단어들로서 결정할 수 있 다. 예를 들어, 음성 인식 장치의 사용자가 운전을 하는 운전자인 경우, “사이드 미러”, “라이트”, “핸들 ” 등 차량의 운행과 관련된 단어들을 활성화 단어들로서 결정할 수 있다. 반면에, 음성 인식 장치의 사용 자가 운전을 하지 않는 탑승자인 경우, “에어컨”, “라디오” 등 차량의 운행과 관련이 없는 전자 장치들과 관련된 단어들만을 활성화 단어들로서 결정할 수 있다. 다른 예로서, 음성 인식 장치는, 음성 인식 장치가 야외에 위치한 경우, 주변에 잡음이 존재하는 환 경인지 여부에 기초하여 활성화 단어를 결정할 수 있다. 예를 들어, 음성 인식 장치는, 잡음 발생이 많은 환경에서는 잡음과 특성이 유사한 단어는 활성화 단어로서 결정하지 않을 수 있다. 다른 예로서, 음성 인식 장치는, 음성 인식 장치가 위치한 공간이 공용 공간인지 또는 개인 공간인지 에 기초하여 활성화 단어를 결정할 수 있다. 예를 들어, 음성 인식 장치는, 회사의 복도와 같은 공용 공간 에 위치한 경우, 공용 공간에 대응하는 단어들만을 활성화 단어들로서 결정할 수 있다. 반면에, 음성 인식 장치 는, 개인 사무실과 같은 개인 공간에 위치한 경우, 공용 공간에 대응하는 단어들과 함께, 사적인 용무와 관련된 단어들도 활성화 단어들로서 결정할 수 있다. 예를 들어, 음성 인식 장치는, 공용 공간에 위치한 경우, “에어컨”, “전등” 등과 같이 공용 공간에 대응하는 활성화 단어들에 의해 음성 인식 기능을 활성화할 수 있다. 그러나, 음성 인식 장치는, 개인 공간에 위치한 경우, “에어컨”, “전등” 등과 같이 공용 공 간에 대응하는 활성화 단어들과 함께, “전화” 또는 “텍스트 메시지”와 같이 사적인 용무와 관련된 활성화단어들에 의해서도 음성 인식 기능을 활성화할 수 있다. 다른 예로서, 음성 인식 장치는, 음성 인식 장치가 위치한 지역에 기초하여, 지역의 언어적 특성이 반영된 단어들을 활성화 단어들로서 결정할 수 있다. 예를 들어, 음성 인식 장치는, 방언이 사용되는 지역 에 위치한 경우, 방언이 반영된 단어들을 활성화 단어들로서 결정할 수 있다. 일 실시예에 따른 음성 인식 장치는, 시간에 기초하여, 적어도 하나의 활성화 단어를 결정할 수 있다. 일 예로서, 음성 인식 장치는, 특정 기간동안 특정 단어를 활성화 단어로서 이용할 수 있다. 음성 인식 장 치는, 특정 기간이 지나면, 더 이상 특정 단어를 활성화 단어로서 이용하지 않을 수 있다. 음성 인식 장치는, 사용자로부터 수신되는 음성 명령들을 학습함으로써, 최근 사용 빈도수가 높아진 단어 를 활성화 단어로서 결정할 수 있다. 예를 들어, 사용자가 제주도로의 여행을 앞두고 있다면, 사용자는 “제주 도”와 관련된 정보를 얻기 위하여 “제주도”와 관련된 음성 명령들을 음성 인식 장치에게 자주 입력할 수 있다. 음성 인식 장치는, 임계 빈도 수 이상으로 자주 등장하는 단어를 활성화 단어로서 추가할 수 있 다. 따라서, 사용자는 별도로 음성 인식 기능을 활성화시키는 동작을 하지 않더라도, 추가된 활성화 단어가 포 함된 음성 명령을 발화하는 것만으로도 음성 인식 기능을 이용할 수 있다. 다른 예로서, 음성 인식 장치는, 음성 인식 장치가 동작하고 있는 현재 시간 정보에 기초하여 활성화 단어를 결정할 수 있다. 예를 들어, 음성 인식 장치는, 계절, 요일, 날짜, 주말인지 평일인지 여부, 시간 대에 따라서 서로 다른 활성화 단어들을 이용할 수 있다. 음성 인식 장치는, 계절, 요일, 날짜, 시간 등에 따라 사용자로부터 수신되는 음성 명령들을 학습함으로써, 각 상황에 적합한 활성화 단어를 갱신하고, 갱신된 활성화 단어를 이용할 수 있다. 다른 예로서, 음성 인식 장치는, 음성 인식 장치의 사용자의 움직임에 기초하여, 적어도 하나의 활성 화 단어를 결정할 수 있다. 음성 인식 장치는, 음성 인식 장치의 사용자가 멈춰 있는지, 걷는지, 또 는 뛰는지 여부에 따라 발화 특성의 변화를 활성화 단어를 결정하는 데에 반영할 수 있다. 예를 들어, 음성 인 식 장치는, 음성 인식 장치의 사용자가 걷거나 뛰고 있는 경우, 사용자가 숨을 헐떡이는 특성을 활성 화 단어를 결정하는 데에 반영할 수 있다. 일 실시예에 따른 음성 인식 장치는, 음성 인식 장치를 사용하는 사용자의 특성과 관련된 정보에 기 초하여, 적어도 하나의 활성화 단어를 결정할 수 있다. 일 예로서, 음성 인식 장치는, 음성 인식 장치의 사용자의 나이에 기초하여 적어도 하나의 활성화 단 어를 결정할 수 있다. 음성 인식 장치는, 음성 인식 장치의 사용자가 성인인 경우, 성인의 공통적인 관심사와 관련된 단어 들을 활성화 단어들로서 결정할 수 있다. 예를 들어, 음성 인식 장치는, 성인의 공통적인 관심사와 관련된 단어들인 “뉴스, 스포츠” 등을 활성화 단어들로서 결정할 수 있다. 음성 인식 장치는, 음성 인식 장치의 사용자가 성인이 아닌 경우, 미성년자의 특성과 관련된 단어들 을 활성화 단어들로서 결정할 수 있다. 예를 들어, 음성 인식 장치는, 사용자가 고등학생인 경우, 고등학 생의 공통적인 관심사와 관련된 단어들인 “시험, 수학, 미분적분” 등을 활성화 단어들로서 결정할 수 있다. 다른 예로서, 음성 인식 장치는, 음성 인식 장치의 사용자의 성별에 기초하여 적어도 하나의 활성화 단어를 결정할 수 있다. 음성 인식 장치는, 음성 인식 장치의 사용자가 여성인 경우, 여성의 공통적인 관심사와 관련된 단어 들을 활성화 단어들로서 결정할 수 있다. 예를 들어, 음성 인식 장치는, 여성의 공통적인 관심사와 관련된 단어인 “화장품”을 활성화 단어로서 결정할 수 있다. 다른 예로서, 음성 인식 장치는, 음성 인식 장치의 사용자의 직업 또는 취미에 기초하여 적어도 하나 의 활성화 단어를 결정할 수 있다. 음성 인식 장치는, 사용자의 직업 별 특성이 반영된 단어들 또는 취미와 관련된 단어들을 활성화 단어들로 서 결정할 수 있다. 예를 들어, 음성 인식 장치의 사용자의 취미가 음악 감상인 경우, 취미와 관련된 단어 들인 “음악, 라디오” 등을 활성화 단어들로서 결정할 수 있다. 한편, 음성 인식 장치는, 음성 인식 장치가 한 명의 사람에 의해서만 이용되는지 또는 여러 명의 사 람들에 의해서 이용되는지에 따라 서로 다르게 동작할 수 있다. 음성 인식 장치가 여러 명의 사람들에 의 해서 이용되는 경우에는, 음성 인식을 수행하기에 앞서, 음성의 특징을 분석함으로써 사용자의 성별 또는 연령 을 인식하거나, 얼굴의 특징을 분석함으로써 사용자를 식별하는 동작을 수행할 수 있다. 음성 인식 장치는, 식별된 사용자에게 적합한 단어들을 활성화 단어들로서 결정할 수 있다. 한편, 일 실시예에 따른 음성 인식 장치는, 활성화 단어를 결정하는데 있어서, 여러 단어들이 사용된 이력 을 반영할 수 있다. 일 실시예에 따른 음성 인식 장치는, 활성화 단어를 결정하는데 있어서, 사용자에 관계없이 공통적으로 단 어들이 사용된 이력을 반영할 수 있다. 음성 인식 장치는, 사용자에 관계없이 공통적으로, 각 상황에 대응 하는 후보 활성화 단어들을 포함하는 데이터 베이스로부터 활성화 단어를 결정할 수 있다. 그러나 일 실시예는 이에 제한되지 않는다. 일 실시예에 따른 음성 인식 장치는, 활성화 단어를 결정하는데 있어서, 각 개인에 의해 단어들이 사용된 이력을 반영할 수 있다. 음성 인식 장치는, 개인 별로 각 상황에 적합한 후보 활성화 단어들을 포함하는 데이터 베이스를 관리할 수 있다. 음성 인식 장치는, 개인별로 각 상황에서 단어들을 사용하는 빈도를 누 적하여 계산함으로써, 개인화된 데이터 베이스를 업데이트할 수 있다. 음성 인식 장치는, 개인화된 데이터 베이스로부터 현재 상황에 적합한 활성화 단어를 결정할 수 있다. 도 5는 일 실시예에 따라 음성 인식 장치가 음성 인식을 수행하는 방법의 구체적인 흐름도이다. 도 5의 S510 및 S520은 도 3의 S310에 대응되고, 도 5의 S530은 도 3의 S320에 대응되고, 도 5의 S540 내지 S580은 도 3의 S330에 대응되고, 도 5의 S590은 도 3의 S340에 대응될 수 있다. 도 3의 각 단계에 대응되는 도 5의 각 단계에 대해서는, 도 3에 대한 설명이 적용될 수 있다. 따라서, 중복되는 동작에 대한 설명은 생략한다. 단계 S510에서 일 실시예에 따른 음성 인식 장치는 음성 인식 장치가 동작하는 상황과 관련된 정보를 획득할 수 있다. 일 실시예에 따른 음성 인식 장치는, 하나 이상의 센서를 포함하고, 음성 인식 장치가 동작하는 상황 을 판단하기 위한 다양한 정보를 감지할 수 있다. 예를 들어, 음성 인식 장치에 포함된 센서는, 음성 인식 장치의 위치, 음성 인식 장치의 움직임과 관련된 정보, 음성 인식 장치를 사용하고 있는 사용자 를 식별할 수 있는 정보, 음성 인식 장치의 주변 환경 정보 등을 감지할 수 있다. 예를 들어, 음성 인식 장치는, 조도 센서, 바이오 센서, 기울기 센서, 위치 센서, 근접 센서, 지자기 센서, 자이로스코프 센서, 온도/습도 센서, 적외선 센서, 및 속도/가속도 센서 중 적어도 하나 또는 이들의 조 합을 포함할 수 있다. 일 실시예에 따른 음성 인식 장치는, 외부의 전자 장치에서 감지된 정보를 음성 인식 장치가 동작하 는 상황과 관련된 정보로서 획득할 수 있다. 예를 들어, 외부의 전자 장치는, 조도 센서, 바이오 센서, 기울기 센서, 위치 센서, 근접 센서, 지자기 센서, 자이로스코프 센서, 온도/습도 센서, 적외선 센서, 및 속도/가속도 센서 중 적어도 하나 또는 이들의 조합을 포함할 수 있다. 일 실시예에 따른 음성 인식 장치는, 사용자 입력을 음성 인식 장치가 동작하는 상황과 관련된 정보 로서 획득할 수 있다. 음성 인식 장치는, 음성 인식 장치가 동작하는 위치 또는 음성 인식 장치(10 0)의 사용자의 특성과 관련된 정보 등을 사용자 입력으로부터 획득할 수 있다. 일 실시예에 따른 음성 인식 장치는, 다른 전자 장치와의 통신을 통해서 음성 인식 장치가 동작하는 상황과 관련된 정보를 획득할 수 있다. 예를 들어, 음성 인식 장치는, 집 안에 존재하는 것으로 인식되는 전자 장치와 근거리 통신에 의해 연결되는 경우, 음성 인식 장치가 집 안에 존재하는 것으로 결정할 수 있 다. 예를 들어, 음성 인식 장치는, 음성 인식 장치의 위치로서 “집, 실내, 사적인 공간”이라는 정 보를 획득할 수 있다. 단계 S520에서 일 실시예에 따른 음성 인식 장치는, 단계 S510에서 획득된 정보에 기초하여 적어도 하나의 활성화 단어를 결정할 수 있다. 일 예로서, 음성 인식 장치는, 활성화 단어를 결정하기에 앞서, 복수의 상황들에 대해서 각 상황에 적합한 후보 활성화 단어들을 저장할 수 있다. 음성 인식 장치는, 단계 S510에서 획득된 정보에 기초하여, 저장된 데이터로부터 현재 상황에 적합한 후보 활성화 단어들을 검색할 수 있다. 음성 인식 장치는, 검색된 후보활성화 단어들 중에서 적어도 하나를 활성화 단어로서 결정할 수 있다. 다른 예로서, 음성 인식 장치는, 활성화 단어를 결정하기에 앞서, 복수의 상황들에 대해서 각 상황에 적합 한 후보 활성화 단어들을 저장한 서버와 통신할 수 있다. 음성 인식 장치는, 단계 S510에서 획득된 정보에 기초하여, 서버로부터 현재 상황에 적합한 후보 활성화 단어들을 검색할 수 있다. 음성 인식 장치는, 검색 된 후보 활성화 단어들 중에서 적어도 하나를 활성화 단어로서 결정할 수 있다. 서버에 저장된 상황 별 후보 활 성화 단어들은 복수의 음성 인식 장치들에 의해 공유되고 이용될 수 있다. 음성 인식 장치는, 음성 인식 장치의 음성 인식 기능이 민감하게 활성화 되는 정도에 기초하여, 결정 되는 활성화 단어의 개수를 결정할 수 있다. 일 실시예에 따르면, 각 상황에 따른 후보 활성화 단어들에 대해서 는 우선 순위가 할당될 수 있다. 음성 인식 장치는, 음성 인식 기능이 민감하게 활성화 되는 정도 및 우선 순위에 기초하여, 후보 활성화 단어들 중에서 일부를 적어도 하나의 활성화 단어로서 결정할 수 있다. 일 실시예에 따른, 음성 인식 장치는, 음성 인식 장치의 사용자의 특성과 관련된 정보에 기초하여 적 어도 하나의 활성화 단어를 결정할 수 있다. 일 예로서, 다양한 연령대의 가족들이 이용하는 음성 인식 장치 는, 음성 연령을 인식하거나, 사용자의 얼굴을 인식하거나, 초기에 입력된 사용자 정보에 기초하여, 서로 다른 활성화 단어들을 결정할 수 있다. 예를 들어, 음성 인식 장치는, 부모가 집에서 음성 인식 장치를 이용하고 있는 경우, TV, 에어컨, 청 소기, 날씨, 일정, 인터넷 접속, 어린이용 TV 채널 시청, 난방, 냉방, 습도 조절 등 집과 관련된 모든 후보 활 성화 단어들을 적어도 하나의 활성화 단어로서 결정할 수 있다. 반면에, 음성 인식 장치는, 아이가 집에서 음성 인식 장치를 이용하고 있는 경우, 아이의 음성 명령에 의해 제어되는 것이 허용되는 음성 명령들에 대해서만 응답하도록 활성화 단어를 결정할 수 있다. 따라서, 음성 인식 장치는, 날씨, 어린이용 TV 채널 시청 등의 일부 후보 활성화 단어들만을 적어도 하나의 활성화 단어로서 결정할 수 있다. 단계 S530에서 일 실시예에 따른 음성 인식 장치는, 입력 오디오 신호를 수신하고 저장할 수 있다. 단계 S540에서 일 실시예에 따른 음성 인식 장치는, 소정 시간 이상 길이의 입력 오디오 신호가 저장되었 는지 여부를 판단할 수 있다. 만약, 소정 시간 이상 길이의 입력 오디오 신호가 저장된 경우, 단계 S560에서 음 성 인식 장치는, 과거에 수신되었던 입력 오디오 신호를 삭제할 수 있다. 도 5에는 소정 시간 길이 단위로 오디오 신호를 수신하는 경우를 예로 들어 도시하였으나, 실시예는 도 5에 도 시된 바에 제한되지 않는다. 앞서 설명한 바와 같이, 일 실시예에 따른 음성 인식 장치는, 문장 단위로 오 디오 신호를 수신하고 저장할 수 있다. 또는, 음성 인식 장치는, 소정 크기의 데이터 단위로 오디오 신호 를 수신하고 저장할 수 있다. 단계 S550에서 일 실시예에 따른 음성 인식 장치는, 활성화 단어를 발화하는 음성 신호가 수신되었는지 여 부를 판단할 수 있다. 활성화 단어를 발화하는 음성 신호가 수신되면, 단계 S570에서 일 실시예에 따른 음성 인식 장치는, 저장 된 입력 오디오 신호 및 이후에 수신되는 입력 오디오 신호를 서버(또는 내장된 음성 인식 모듈)에게 전송할 수 있다. 음성 인식 장치는, 저장된 입력 오디오 신호 중에서 활성화 단어가 포함된 문장을 포함하는 신호를 검색하고 추출할 수 있다. 음성 인식 장치는, 활성화 단어가 포함된 문장을 포함하는 오디오 신호를 서버 (또는 내장된 음성 인식 모듈)에게 전송할 수 있다. 일 실시예에 따른 음성 인식 장치는, 활성화 단어가 포함된 문장을 포함하는 신호를 검색하고 추출하기 위 해서 다음과 같은 방법을 이용할 수 있다. 일 예로서, 음성 인식 장치는, 묵음 구간의 길이, 문형(sentence structure) 및 억양 중 적어도 하나에 기 초하여 문장의 시작과 끝을 판단할 수 있다. 음성 인식 장치는, 판단된 결과에 기초하여, 활성화 단어가 포함된 문장에 대응하는 오디오 신호를 서버(또는 내장된 음성 인식 모듈)에게 전송할 수 있다. 다른 예로서, 음성 인식 장치는, 활성화 단어가 발화된 음성 신호로부터 일정 길이의 과거 음성 신호 및 현재 수신되는 음성 신호를 문장의 시작과 끝으로서 판단할 수 있다. 음성 인식 장치는, 판단된 결과에 기 초하여, 활성화 단어가 포함된 문장에 대응하는 오디오 신호를 서버(또는 내장된 음성 인식 모듈)에게 전송할 수 있다. 또 다른 예로서, 음성 인식 장치는, 활성화 단어의 문법 상 위치에 기초하여, 활성화 단어가 발화된 음성 신호 이전의 가변적 길이의 과거 음성 신호 및 활성화 단어가 발화된 음성 신호 이후의 가변적 길이의 음성 신 호를 문장의 시작과 끝으로서 판단할 수 있다. 음성 인식 장치는, 판단된 결과에 기초하여, 활성화 단어가 포함된 문장에 대응하는 오디오 신호를 서버(또는 내장된 음성 인식 모듈)에게 전송할 수 있다. 단계 S550에서 활성화 단어를 발화하는 음성 신호가 수신되지 않았다고 판단되는 경우, 음성 인식 장치는, 소정 시간 이상 길이의 입력 오디오 신호를 수신하고 저장하는 동작을 반복하여 수행할 수 있다. 단계 S580에서 일 실시예에 따른 음성 인식 장치는 음성 인식을 수행할 수 있다. 음성 인식 장치는, 입력 오디오 신호로부터 음성 신호의 주파수 특성을 추출하고, 음향 모델과 언어 모델을 이용하여 음성 인식을 수행 할 수 있다. 단계 S590에서 일 실시예에 따른 음성 인식 장치는 음성 인식이 수행된 결과를 출력할 수 있다. 음성 인식 장치는, 소리, 빛, 영상, 진동 등 다양한 방식으로 음성 인식이 수행된 결과를 출력할 수 있다. 도 6은 일 실시예에 따라 음성 인식 장치가 음성 인식이 수행된 결과를 출력하는 방법의 흐름도이다. 도 6의 S610 내지 S650은 도 3의 S330에 대응될 수 있다. 단계 S610에서 일 실시예에 따른 음성 인식 장치는, 음성 명령을 분석할 수 있다. 음성 인식 장치는, 자연어 이해 및 대화 관리(Dialogue Management)를 통해 음성 명령을 분석할 수 있다. 음성 인식 장치는, 음성 인식이 수행된 결과에 대해서 자연어 이해를 수행할 수 있다. 음성 인식 장치 는, 음성 명령에 대한 음성 인식을 수행함으로써, 화자가 발화한 것으로 추정되는 텍스트를 추출할 수 있 다. 음성 인식 장치는, 화자가 발화한 것으로 추정되는 텍스트에 대해서 자연어 이해를 수행할 수 있다. 음성 인식 장치는, 자연어 처리를 통해 화자의 발화 의도를 파악할 수 있다. 단계 S620에서 일 실시예에 따른 음성 인식 장치는, 음성 명령이 음성 인식 장치의 응답을 요청하는 직접 명령인지 여부를 판단할 수 있다. 음성 인식 장치는, 음성 명령의 문형, 억양, 음성 명령이 수신되는 방향 및 음성 명령의 크기 또는 자연어 이해의 결과 중 적어도 하나에 기초하여, 음성 명령이 직접 명령인지 간 접 명령인지 여부를 판단할 수 있다. 일 실시예에 따르면, 음성 명령이란, 음성 인식 장치가 수신하는 모든 음향학적 신호(acoustic speech signal)를 의미하거나, 음성 인식 장치가 수신하는 음향학적 신호 중에서 인간이 발화한 음성 신호를 의미 할 수 있다. 직접 명령은, 사용자가 음성 인식 장치가 음성 명령에 응답하는 동작을 수행하도록 하기 위해 서 의도적으로 발화한 음성 명령을 포함할 수 있다. 간접 명령은, 사용자가 발화한 음성 명령들 중에서, 직접 명령을 제외한 모든 음성 명령을 포함할 수 있다. 예를 들어, 간접 명령은, 사용자가 음성 인식 장치가 음 성 인식을 수행할 것을 의도하지 않고 발화한 음성 신호를 포함할 수 있다.단계 S630에서 일 실시예에 따른 음 성 인식 장치는, 음성 명령이 직접 명령이라고 판단되는 경우, 음성 명령에 대해 응답하는 동작을 수행할 수 있다. 음성 명령이 음성 인식 장치의 응답을 요청하는 직접 명령이 아닌 간접 명령이라고 판단되는 경우, 단계 S640 에서 일 실시예에 따른 음성 인식 장치는 음성 명령에 대한 응답이 가능함을 표시할 수 있다. 음성 인식 장치는, 음성 명령에 대한 응답을 대기하면서, 응답 대기 중임을 사용자에게 알릴 수 있다. 단계 S650에서 일 실시예에 따른 음성 인식 장치는, 사용자로부터 확인 명령을 수신할 수 있다. 음성 인식 장치는, 사용자로부터 확인 명령이 수신되면, 음성 명령에 대해 응답하는 동작을 수행할 수 있다. 도 7은 음성 인식 장치가 가정용 로봇 내에 포함되는 경우를 예로 들어 도시한다. 그러나, 일 실시예는 도 7에 제한되지 않으며, 음성 인식 장치는 다양한 모바일 컴퓨팅 장치 또는 비모바일 컴퓨팅 장치일 수 있다. 또는, 음성 인식 장치는, 집 안의 다양한 가전 제품들을 연결하는 홈 네트워크를 제어하는 중앙 제 어 장치 내에 포함될 수 있다. 도 7은 음성 인식 장치가 “날씨”를 현재 상황에 대응하는 활성화 단어로서 결정한 경우를 도시한다. 도 7 의 (a)에서 사용자는, 다른 화자와의 대화 중에 내일 날씨가 궁금하다는 의사를 표현하는 “내일 날씨 가 어떨지 모르겠네”라는 발화를 할 수 있다. 음성 인식 장치는, “날씨”라는 활성화 단어를 발화하는 음성 신호를 수신하였으므로, 활성화 단어를 포함하는 문장인 “내일 날씨가 어떨지 모르겠네” 에 대해서 음성 인식을 수행할 수 있다. 음성 인식 장치는, 활성화 단어인 “날씨”를 발화하는 음성 신호가 수신되면, 음 성 인식 기능을 활성화 할 수 있다. 음성 인식 장치는, “날씨”를 발화하는 음성 신호를 포함하는 전체 음성 명령인 “내일 날씨가 어떨지 모 르겠네” 에 대해서 음성 인식을 수행할 수 있다. 또는, 음성 인식 장치는, “날씨”를 발화하는 음성 신호가 수신되면, 활성화 단어 이후에 수신되는 음성 명령인 “가 어떨지 모르겠네”를 서버에게 전송함으로써 서버에서 음성 인식이 수행되도록 할 수 있다. 또한, 음성 인식 장치는, 활성화 단어 이후에 수신되는 음성 명령과 함께, 이전에 수신되어 저장된 음성 명령을 서버에게 전송하고, 서버에서 음성 인식이 수행된 결과를 서버로부터 수신할 수 있다. 음성 인식 장치는, “날씨”를 발화하는 음성 신호가 수신되면, 활성화 단어 이전에 수신되어 저장된 음성 명령인 “내일”, 활성 화 단어 “날씨”, 및 활성화 단어 이후에 수신되는 음성 명령인 “가 어떨지 모르겠네” 에 대해서 음성 인식 을 수행할 수 있다. 음성 인식 장치는, 음성 인식이 수행된 결과에 대응하는 키워드인 “내일 날씨”를 외부 서버로 전송하고, 전송된 키워드에 관련된 정보인 “화창함”을 서버로부터 수신하여 저장할 수 있다. 음성 인식 장치는, 음성 인식이 수행된 음성 명령에 대해서 자연어 처리 및 문형 분석을 수행함으로써, 음 성 명령이 음성 인식 장치의 응답을 요청하는 직접 명령인지 여부를 판단할 수 있다. 예를 들어, 음성 인 식 장치는, 도 7의 (a)에서 발화된 음성 명령은 간접 명령이라고 판단할 수 있다. 음성 명령이 음성 인식 장치의 응답을 요청하는 직접 명령이 아닌 간접 명령이라고 판단되므로, 일 실시예 에 따른 음성 인식 장치는 음성 명령에 대한 응답이 가능함을 표시할 수 있다. 예를 들어, 음성 인식 장치 는, 소리, 빛, 영상, 진동 등 다양한 방식으로 응답 대기 중임을 사용자에게 알릴 수 있다. 도 7의 (b)에 도시된 바와 같이, 사용자는, 음성 인식 장치가 응답 대기 중임을 인식하고, 음성 명령 에 대한 응답을 하라는 확인 명령을 내릴 수 있다. 예를 들어, 사용자는, 미리 약속된 확인 명령인 “말해 봐 로봇”이라는 발화를 함으로써, 음성 인식 장치에게 확인 명령을 내릴 수 있다. 음성 인식 장치는, 사용자로부터 확인 명령이 수신되면, 음성 명령에 대해 응답하는 동작으로서 “내일 날씨는 화창 합니다”라는 음성을 출력할 수 있다. 상술한 바와 같이, 일 실시예에 따른 음성 인식 장치는, 사용자가 직접적으로 음성 인식 기능을 활성화시 키기 위한 동작을 미리 수행하지 않고 상황에 적합한 자연스러운 발화를 하는 것만으로도, 음성 인식을 수행할 수 있다. 음성 인식 장치는, 사용자가 발화한 상황에 적합한 자연스러운 발화 내에 포함되는 단어를 활성 화 단어로서 인식함으로써, 음성 인식을 수행할 수 있다. 또한, 일 실시예에 따르면, 도 7에 도시된 바와 같이 “말해봐 로봇”이라는 사용자의 음성 명령을 수신하기 이 전에, 사용자가 알고자 하는 내용인 “오늘 날씨”에 대한 정보를 미리 획득할 수 있다. 일 실시예에 따른 음성 인식 장치는, 사용자가 음성 인식 장치가 음성 인식 기능을 수행하도록 음성 명령을 발화 하기 전에 상황을 앞서서 주도하는(proactive) 서비스를 제공할 수 있다. 도 7에서는, 음성 인식 장치가 음성 명령이 간접 명령일 경우, 음성 명령에 대한 응답을 대기하면서 응답 대기 중임을 사용자에게 알리는 방식으로 동작하는 경우를 예로 들어 도시하였다. 그러나, 일 실시예는 도 7에 제한되지 않는다. 예를 들어, 도 8에 도시된 바와 같이, 일 실시예에 따른 음성 인식 장치는, 음성 명령이 음성 인식 장치 의 응답을 요청하는 직접 명령인 경우에만 음성 인식을 수행한 결과를 출력할 수 있다. 음성 인식 장치 는, 음성 명령이 음성 인식 장치의 응답을 요청하는 직접 명령이 아닌 경우, 별도의 동작을 취하지 않을 수 있다. 도 8은 음성 인식 장치가 “에어컨”을 현재 상황에 대응하는 활성화 단어로서 결정한 경우를 도시한다. 도 8에서 제1 사용자는, 제2 사용자와의 대화 중에 현재 날씨에 대해서 설명하는 “오늘은 에어컨을 틀 어야 하는 날씨야”라는 발화를 할 수 있다. 음성 인식 장치는, “에어컨”이라는 활성화 단어를 발화하는 음성 신호를 수신하였으므로, 활성화 단어를 포함하는 음성 명령인 “오늘은 에어컨을 틀어야 하는 날씨야”가 직접 명령인지 간접 명령인지 여부를 판단할 수 있다. 음성 인식 장치는, 제1 사용자의 음성 명령은 직접 명령이 아니라고 판단할 수 있다. 예를 들어, 음성 인식 장치는, 제1 사용자의 음성 명령은 질문을 하거나 명령을 내리는 문형을 가지고 있지 않으므로직접 명령이 아니라고 판단할 수 있다. 음성 인식 장치는, 제1 사용자의 음성 명령이 직접 명령이 아 니라고 판단되므로, 음성 명령을 포함하는 오디오 신호를 서버(또는 내장된 음성 인식 모듈)에게 전송하지 않을 수 있다. 음성 인식 장치는, 수신되고 저장되었던 제1 사용자의 발화를 무시하고, 새롭게 입력 오디오 신호를 수신하고 저장하는 동작을 반복할 수 있다. 다음으로, 도 8에서 제2 사용자는, 제1 사용자의 발화에 응답하여 에어컨의 전원을 켤 것을 음성 인식 장치에게 요청하는 음성 명령인 “에어컨 틀어”라는 발화를 할 수 있다. 음성 인식 장치는, “에어컨”이라는 활성화 단어를 발화하는 음성 신호를 수신하였으므로, 활성화 단어를 포함하는 음성 명령인 “에어컨 틀어”가 직접 명령인지 여부를 판단할 수 있다. 음성 인식 장치는, 제2 사용자의 음성 명령이 직접 명령이라고 판단할 수 있다. 예를 들어, 음성 인식 장치는, 제2 사용자의 음성 명령이 명령을 내리는 문형을 가지고 있으므로 직접 명령이라고 판단할 수 있다. 음성 인식 장치는, 제2 사용자의 음성 명령이 직접 명령이라고 판단되므로, 활성화 단어를 포함 하는 음성 명령을 포함하는 오디오 신호를 서버(또는 내장된 음성 인식 모듈)에게 전송할 수 있다. 서버(또는 내장된 음성 인식 모듈)는, 음성 명령에 대한 음성 인식을 수행할 수 있다. 음성 인식 장치는, 음성 인식 결과에 응답하여, 에어컨의 전원이 켜지도록 에어컨을 제어할 수 있다. 도 9는 일 실시예에 따라 음성 인식 장치가 음성 명령이 직접 명령인지 여부를 판단하는 방법의 흐름도이다. 도 9의 S910 내지 S930은 도 6의 S610에 대응될 수 있다. 단계 S910에서 일 실시예에 따른 음성 인식 장치는, 자연어 이해에 기초한 매칭 정확도에 기초하여 음성 명령을 필터링할 수 있다. 음성 인식 장치는, 자연어 이해에 기초하여, 사용자의 음성 명령을 기계가 인식 할 수 있는 명령과 매칭시킬 수 있는 정도를 나타내는 매칭 정확도를 계산할 수 있다. 음성 인식 장치는, 계산된 매칭 정확도와 미리 결정된 임계값을 비교함으로써, 음성 명령이 음성 인식 장치의 응답을 요청하 는 직접 명령인지 여부를 1차적으로 판단할 수 있다. 단계 S920에서 일 실시예에 따른 음성 인식 장치는, 음성 명령의 문형을 분석함으로써, 음성 명령이 직접 명령인지 여부를 2차적으로 판단할 수 있다. 음성 인식 장치는, 음성 명령에 포함되는 형태소들을 분석하 고, 종결 어미에 기초하여 음성 명령의 문형을 분석할 수 있다. 예를 들어, 음성 인식 장치는, 음성 명령 이 의문문(예를 들어, “야?”, “니?” 등) 또는 명령문(예를 들어, “켜”, “꺼”, “해” 등)의 형태를 가 진다고 판단되는 경우, 음성 명령이 직접 명령이라는 신뢰값에 가중치를 부여할 수 있다. 단계 S930에서 일 실시예에 따른 음성 인식 장치는, 단계 S910 및 단계 S920에서 계산된 신뢰값에 기초하 여 음성 명령을 필터링할 수 있다. 음성 인식 장치는, 단계 S910 및 단계 S920을 거쳐 계산된 신뢰값을 미 리 결정된 임계값과 비교함으로써, 음성 명령이 직접 명령인지 여부를 최종적으로 판단할 수 있다. 한편, 일 실시예에 따른 음성 인식 장치는, 상황에 적합한 활성화 단어를 결정하기에 앞서, 각 상황에 따 른 후보 활성화 단어들을 추출할 수 있다. 음성 인식 장치는, 추출된 후보 활성화 단어들을 내장된 데이터 베이스 또는 외부 서버에 포함된 데이터 베이스 내에 저장할 수 있다. 도 10은 일 실시예에 따라 음성 인식 장치가 상황들에 대응하는 후보 활성화 단어들을 결정하는 방법의 흐름도 이다. 단계 S1010에서 일 실시예에 따른 음성 인식 장치는, 각 상황에 따라 발화 가능한 음성 명령들을 그룹화할 수 있다. 각 상황에 따라 발화 가능한 음성 명령들은, 각 상황에서 사용자에 의해 발화될 것으로 예상되는 음성 명령들 또는 각 상황에서 사용자에 의해 발화되었던 음성 명령들을 포함할 수 있다. 일 실시예에 따른 음성 인식 장치는, 복수의 상황들에서 사용자가 발화한 말뭉치(corpus)를 수신하고, 수 신된 말뭉치에 포함되는 음성 명령들을 그룹화할 수 있다. 음성 인식 장치는, 말뭉치에 포함되는 음성 명 령들이 각각 어떠한 상황에서 발화된 것인지에 대한 정보를 말뭉치와 함께 수신할 수 있다. 단계 S1020에서 일 실시예에 따른 음성 인식 장치는 상황 별로 발화 가능한 음성 명령들 내에 포함되는 단 어들에 대한 통계를 추출할 수 있다. 음성 인식 장치는, 복수의 상황들 중에서 각 상황에서 수신되는 음성 명령들 내에 복수의 단어들이 포함되는 빈도를 추출할 수 있다. 단계 S1030에서 일 실시예에 따른 음성 인식 장치는 상황 별 음성 명령들 내에 고유하게 높은 빈도로 포함 되는 적어도 하나의 단어를 추출할 수 있다.음성 인식 장치는, 복수의 상황들에서 발화된 음성 명령들 내에서 공통적으로 임계 빈도 이상으로 자주 등 장하는 단어는, 특정 상황에서 발화된 음성 명령들 내에서 고유하게 높은 빈도로 포함되는 단어에서 제외할 수 있다. 음성 인식 장치는, 특정 상황에서 발화된 음성 명령들 내에서만 임계 빈도 이상으로 자주 등장하는 단어를, 특정 상황 내에서 발화된 음성 명령들 내에서 고유하게 높은 빈도로 등장하는 단어라고 판단할 수 있다. 단계 S1040에서 일 실시예에 따른 음성 인식 장치는 추출된 적어도 하나의 단어를 각 상황에 대한 후보 활 성화 단어로서 결정할 수 있다. 음성 인식 장치는, 복수의 상황들에 대해서 각 상황에 적합한 후보 활성화 단어들을 저장할 수 있다. 일 실시예에 따른 음성 인식 장치는, 저장된 데이터로부터 현재 상황에 대응하는 적어도 하나의 후보 활성 화 단어를 추출할 수 있다. 음성 인식 장치는, 추출된 후보 활성화 단어들 중에서 적어도 하나를 활성화 단어로서 결정할 수 있다. 도 10에서는, 복수의 상황들에서 발화 가능한 음성 명령들을 포함하는 말뭉치를 분석함으로써 후보 활성화 단어 를 결정하는 경우를 예로 들어 설명하였다. 그러나 일 실시예는 도 10에 제한되지 않으며, 각 상황에 대응하는 후보 활성화 단어를 사용자가 직접 입력하거나 삭제할 수도 있다. 음성 인식 장치는, 사용자 입력에 기초 하여, 특정 상황에 대응하는 후보 활성화 단어를 데이터 베이스 내에 저장하거나, 특정 후보 활성화 단어를 삭 제할 수 있다. 예를 들어, 사용자가 집 안에 공기 청정기를 새롭게 설치한 경우, 음성 인식 장치는, 사용 자 입력에 기초하여, “공기 청정기”를 집과 관련된 후보 활성화 단어로서 추가할 수 있다. 이하에서는, 일 실시예에 따른 음성 인식 장치의 구성을 설명한다. 이하에서 서술하는 음성 인식 장치 의 각 구성은, 상술한 음성 인식 장치가 음성 인식을 수행하는 방법의 각 단계를 수행할 수 있다. 도 11a 및 11b는 일 실시예에 따른 음성 인식 장치의 블록도이다. 도 11a에 도시된 바와 같이, 일 실시예에 따른 음성 인식 장치는, 수신부, 프로세서, 및 출력 부를 포함할 수 있다. 그러나, 도 11a에 도시된 구성 요소 모두보다 많은 구성 요소에 의해 음성 인식 장 치가 구현될 수도 있다. 도 11b에 도시된 바와 같이, 일 실시예에 따른 음성 인식 장치는, 메모리 , 사용자 입력부, 통신부, 및 감지부 중 적어도 하나를 더 포함할 수 있다. 예를 들어, 본 발명의 일 실시예에 따른 음성 인식 장치는, 비모바일 컴퓨팅 디바이스, 모바일 컴퓨팅 디 바이스, 자동차의 전자 제어 장치 및 서버 중 적어도 하나에 포함되거나, 비모바일 컴퓨팅 디바이스, 모바일 컴 퓨팅 디바이스, 자동차의 전자 제어 장치 및 서버 중 적어도 하나에 유, 무선으로 연결되도록 구현될 수 있다. 일 실시예에 따른 수신부는, 오디오 신호를 수신할 수 있다. 예를 들어, 수신부는, 마이크로폰 (Microphone)에 의해 외부의 소리를 전기적인 음향 데이터로 변환함으로써 오디오 신호를 직접 수신할 수 있다. 또는, 수신부는, 외부 장치로부터 송신된 오디오 신호를 수신할 수 있다. 도 11a에는, 수신부가, 음성 인식 장치의 내부에 포함되는 것으로 도시되었으나, 다른 일 실시예에 따른 수신부는 별도의 장치 내에 포함되고 음성 인식 장치와는 유, 무선으로 연결되는 형태로 구현될 수 있다. 일 실시예에 따른 프로세서는 음성 인식 장치의 전반적인 동작을 제어할 수 있다. 예를 들어, 프로 세서는, 수신부, 및 출력부를 제어할 수 있다. 일 실시예에 따른 프로세서는 인공지능 기술을 이용하여 음성 인식 장치의 동작을 제어할 수 있다. 일 실시예에 따른 프로세서는, 음성 인식 장치가 동작하는 상황과 관련된 정보에 기초하여 적어도 하나의 활성화 단어를 결정할 수 있다. 프로세서는, 예를 들어, 음성 인식 장치의 위치, 시간, 음성 인식 장치가 다른 전자 장치와 연결되었는지 여부, 음성 인식 장치가 움직이는지 여부, 및 음성 인식 장치의 사용자의 특성과 관련된 정보 중 적어도 하나를 음성 인식 장치가 동작하는 상황과 관련된 정 보로서 획득할 수 있다. 일 실시예에 따른 프로세서는, 현재 상황에 대응하는 적어도 하나의 활성화 단어를 결정함에 있어서, 음 성 인식 장치의 음성 인식 기능이 민감하게 활성화 되는 정도에 기초하여, 결정되는 적어도 하나의 활성화 단어의 개수를 결정할 수 있다. 일 실시예에 따른 프로세서는, 적어도 하나의 활성화 단어에 포함되는 활성화 단어를 발화하는 음성 신호 가 수신되었다고 판단되는 경우, 입력 오디오 신호에 대한 음성 인식을 수행할 수 있다.일 실시예에 따른 프로세서는, 수신부에서 입력된 입력 오디오 신호로부터 음성 신호를 검출하고, 음성 신호에 대한 음성 인식을 수행할 수 있다. 프로세서는, 음성 인식을 수행하기 위한 음성 인식 모듈 을 포함할 수 있다. 일 실시예에서, 프로세서는 입력 오디오 신호로부터 음성 신호의 주파수 특성을 추출 하고, 음향 모델과 언어 모델을 이용하여 음성 인식을 수행 할 수 있다. 주파수 특성은, 음향 입력의 주파수 스 펙트럼을 분석하여 추출되는, 음향 입력의 주파수 성분들의 분포를 의미할 수 있다. 따라서, 도 11b에 도시된 바와 같이, 음성 인식 장치는, 음향 모델과 언어 모델을 저장하는 메모리를 더 포함할 수 있다. 일 실시예에 따른 프로세서는, 활성화 단어를 발화하는 음성 신호가 수신되었다고 판단되는 경우, 활성화 단어를 발화하는 음성 신호를 포함하는 입력 오디오 신호에 대한 음성 인식을 수행할 수 있다. 일 실시예에 따른 프로세서는, 음성 인식을 수행하기에 앞서, 입력 오디오 신호를 수신하고 저장할 수 있 다. 프로세서는, 입력 오디오 신호가 활성화 단어를 발화하는 음성 신호를 포함하는지 여부를 판단할 수 있다. 프로세서는, 입력 오디오 신호가 적어도 하나의 활성화 단어에 포함되는 활성화 단어를 발화하는 음성 신호를 포함한다고 판단되는 경우, 저장된 입력 오디오 신호 및 이후에 수신되는 입력 오디오 신호에 대한 음성 인식을 수행할 수 있다. 일 실시예에 따른 프로세서는, 음성 인식이 수행된 결과를 바로 출력할지 혹은 사용자로부터 확인 명령이 수신되면 음성 인식이 수행된 결과를 출력할지 여부를 결정할 수 있다. 프로세서는, 입력 오디오 신호에 대해서 음성 인식을 수행함으로써, 사용자가 발화한 텍스트를 추출할 수 있다. 프로세서는, 추출된 텍스 트에 대한 자연어 이해 및 문형 분석에 기초하여, 입력 오디오 신호에 포함되는 음성 명령이 음성 인식 장치의 응답을 요청하는 직접 명령인지 여부를 판단할 수 있다. 일 실시예에 따른 프로세서는, 음성 명령이 직접 명령이라고 판단되는 경우, 음성 명령에 대해 응답하는 동작을 수행할 수 있다. 프로세서는, 음성 명령이 직접 명령이 아니라고 판단되는 경우, 음성 명령에 대 한 응답이 가능함을 표시하도록 출력부를 제어할 수 있다. 프로세서는, 수신부를 통해 사용 자로부터 확인 명령이 수신되면, 음성 명령에 대해 응답하는 동작을 수행할 수 있다. 한편, 일 실시예에 따른 프로세서는, 특정 기능을 실행하는 하드웨어 및/또는 소프트웨어 구성들로 구현 될 수 있다. 예를 들어, 프로세서는, 음성 인식 장치가 동작하는 상황을 분석하는 사용자 상황 분석 부(미도시), 현재 상황에 대응하는 후보 활성화 단어들을 데이터베이스로부터 추출하는 후보 활성화 단어 추출 부(미도시), 현재 상황에 따라 활성화 단어를 전환하는 활성화 단어 전환부(미도시), 활성화 단어를 발화하는 음성 명령을 포함하는 오디오 신호를 처리하는 오디오 신호 처리부(미도시) 중 적어도 하나를 포함할 수 있다. 일 실시예에 따른 프로세서가 수행하는 기능들은, 적어도 하나의 마이크로프로세서에 의해 구현되거나, 해당 기능을 위한 회로 구성들에 의해 구현될 수 있다. 프로세서가 수행하는 기능들의 일부 또는 전부는, 프로세서에서 실행되는 다양한 프로그래밍 언어 또는 스크립트 언어로 구성된 소프트웨어 모듈에 의해 구 현될 수 있다. 도 11a 및 도 11b는 음성 인식 장치가 하나의 프로세서를 포함하는 것으로 도시하였 지만, 실시예는 이에 제한되지 않는다. 음성 인식 장치는, 복수의 프로세서들을 포함할 수 있다. 일 실시예에 따른 출력부는, 입력 오디오 신호에 대해서 음성 인식이 수행된 결과를 출력 할 수 있다. 출 력부는, 음성 인식이 수행된 결과를 사용자에게 알리거나, 외부 디바이스(예를 들어, 스마트 폰, 스마트 TV, 스마트 와치, 서버 등)에게 전송할 수 있다. 예를 들어, 출력부는, 오디오 신호 또는 비디오 신호를 출력 할 수 있는 스피커 또는 디스플레이를 포함할 수 있다. 또는, 일 실시예에 따른 출력부는, 음성 인식이 수행된 결과에 대응하는 동작을 수행할 수 있다. 예를 들 어, 음성 인식 장치는, 음성 인식이 수행된 결과에 대응하는 음성 인식 장치의 기능을 결정하고, 해 당 기능을 수행하는 화면을 출력부를 통해 출력할 수 있다. 또는, 음성 인식 장치는, 음성 인식이 수행된 결과에 대응하는 키워드를 외부 서버로 전송하고, 전송된 키워드에 관련된 정보를 서버로부터 수신하여 출력부를 통해 화면 상에 출력할 수 있다. 일 실시예에 따른 출력부는, 외부로부터 수신되거나, 프로세서에서 처리되거나, 저장된 정보를 빛, 소리, 영상 및 진동 중 적어도 하나의 형태로 출력한다. 예를 들어, 출력부는, 텍스트 또는 영상을 출력 하는 디스플레이, 소리를 출력하는 음향 출력부 및 진동을 출력하는 진동 모터 중 적어도 하나를 더 포함할 수 있다. 도 11b의 메모리는, 프로세서에서 음성 인식이 수행된 결과를 저장할 수 있다. 메모리는, 수 신부를 통해 수신되는 입력 오디오 신호를 저장할 수 있다. 메모리는 문장 단위로, 일정한 시간 길 이 단위로, 또는 일정한 데이터 크기 단위로, 입력 오디오 신호를 수신하고 저장할 수 있다. 일 실시예에 따른 메모리는, 음성 인식 장치를 제어하기 위해서 프로세서에서 실행되는 명령 들을 저장할 수 있다. 일 실시예에 따른 메모리는, 복수의 상황들 각각에 대해서 대응하는 복수의 후보 활성화 단어들을 포함하 는 데이터 베이스를 저장할 수 있다. 프로세서는, 적어도 하나의 활성화 단어를 결정함에 있어서, 메모리 에 저장된 데이터로부터 음성 인식 장치가 동작하는 상황에 대응하는 적어도 하나의 후보 활성화 단어를 검색할 수 있다. 프로세서는, 검색된 후보 활성화 단어들 중에서 적어도 하나를 활성화 단어로서 결정할 수 있다. 일 실시예에 따른 메모리는, 문형 및 문법에 대한 정보를 포함하는 데이터 베이스를 포함할 수 있다. 프 로세서는, 메모리에 저장된 문형 및 문법에 대한 정보를 이용함으로써, 입력 오디오 신호에 포함되 는 음성 명령이 직접 명령인지 여부를 판단할 수 있다. 일 실시예에 따른 메모리는 플래시 메모리 타입(flash memory type), 하드디스크 타입(hard disk type), 멀티미디어 카드 마이크로 타입(multimedia card micro type), 카드 타입의 메모리(예를 들어 SD 또는 XD 메모 리 등), 램(RAM, Random Access Memory) SRAM(Static Random Access Memory), 롬(ROM, Read-Only Memory), EEPROM(Electrically Erasable Programmable Read-Only Memory), PROM(Programmable Read-Only Memory), 자기 메모리, 자기 디스크, 광디스크 중 적어도 하나의 타입의 저장매체를 포함할 수 있다. 일 실시예에 따른 사용자 입력부는, 음성 인식 장치를 제어하기 위한 사용자 입력을 수신할 수 있다. 수신부는 사용자의 터치를 수신하는 터치 패널, 사용자의 푸시 조작을 수신하는 버튼, 사용자의 회 전 조작을 수신하는 휠, 키보드(key board), 및 돔 스위치 (dome switch) 등을 포함하는 사용자 입력 디바이스 를 포함할 수 있으나 이에 제한되지 않는다. 일 실시예에 따른 통신부는, 유선 통신 또는 무선 통신을 통해 외부의 전자 장치 또는 서버와 통신할 수 있다. 예를 들어, 통신부는, 복수의 상황들에 대해서 각 상황에 적합한 후보 활성화 단어들을 포함하는 데이터 베이스를 저장하는 서버와 통신할 수 있다. 통신부는, 서버로부터 현재 상황에 적합한 적어도 하 나의 후보 활성화 단어를 검색하고 추출할 수 있다. 프로세서는, 검색된 후보 활성화 단어들 중에서 적어 도 하나를 활성화 단어로서 결정할 수 있다. 일 실시예에 따른 통신부는, 외부의 전자 장치로부터 음성 인식 장치가 동작하는 상황과 관련된 정 보를 획득할 수 있다. 통신부는, 외부의 전자 장치에서 감지된 정보를 음성 인식 장치가 동작하는 상황과 관련된 정보로서 획득할 수 있다. 일 실시예에 따른 통신부는, 음성 인식 기능을 수행하는 서버와 통신할 수 있다. 예를 들어, 통신부 는, 활성화 단어가 포함된 문장을 포함하는 오디오 신호를 서버에게 전송할 수 있다. 통신부는, 서 버에서 수행된 음성 인식 결과를 수신할 수 있다. 일 실시예에 따른 통신부는, 근거리 통신 모듈, 유선 통신 모듈, 이동 통신 모듈, 방송 수신 모듈 등을 포함할 수 있다. 일 실시예에 따른 감지부는, 하나 이상의 센서를 포함하고, 음성 인식 장치가 동작하는 상황을 판단 하기 위한 다양한 정보를 감지할 수 있다. 예를 들어, 감지부는, 음성 인식 장치의 위치, 음성 인식 장치의 움직임과 관련된 정보, 음성 인식 장치를 사용하고 있는 사용자를 식별할 수 있는 정보, 음성 인식 장치의 주변 환경 정보 등을 감지할 수 있다. 예를 들어, 감지부는, 조도 센서, 바이오 센서, 기울기 센서, 위치 센서, 근접 센서, 지자기 센서, 자이 로스코프 센서, 온도/습도 센서, 적외선 센서, 및 속도/가속도 센서 중 적어도 하나 또는 이들의 조합을 포함할 수 있다. 도 11a 및 11b에 도시된 블록도는 음성 인식 서버에도 적용될 수 있다. 일 실시예에 따른 음성 인식 서버는, 입 력 오디오 신호를 음성 인식 장치로부터 수신하는 수신부를 포함할 수 있다. 음성 인식 서버는 음성 인식 장치 와 유선 또는 무선으로 연결될 수 있다. 또한, 음성 인식 서버는 프로세서와 출력부를 포함할 수 있으며, 메모리와 통신부를 더 포함할 수 있다. 음성 인식 서버의 프로세서는, 입력 오디오 신호로부터 음성 신호를 검출하고, 음성 신호에 대한 음성 인식을 수행할 수 있다. 음성 인식 서버의 출력부는, 음성 인식이 수행된 결과를 음성 인식 장치에게 송신할 수 있다. 음성 인식 장치는 음성 인식 서버로부터 수신된 음성 인식이 수행된 결과를 출력할 수 있다. 한편, 상술한 실시예는, 컴퓨터에서 실행될 수 있는 프로그램으로 작성 가능하고, 컴퓨터에 의해 판독 가능한 매체를 이용하여 상기 프로그램을 동작시키는 범용 디지털 컴퓨터에서 구현될 수 있다. 또한, 상술한 실시예에 서 사용된 데이터의 구조는 컴퓨터 판독 가능 매체에 여러 수단을 통하여 기록될 수 있다. 또한, 상술한 실시예 는 컴퓨터에 의해 실행되는 프로그램 모듈과 같은 컴퓨터에 의해 실행가능한 명령어를 포함하는 기록 매체의 형 태로 구현될 수 있다. 예를 들어, 소프트웨어 모듈 또는 알고리즘으로 구현되는 방법들은 컴퓨터가 읽고 실행할 수 있는 코드들 또는 프로그램 명령들로서 컴퓨터가 읽을 수 있는 기록 매체에 저장될 수 있다. 컴퓨터 판독 가능 매체는 컴퓨터에 의해 액세스될 수 있는 임의의 기록 매체일 수 있고, 휘발성 및 비휘발성 매 체, 분리형 및 비분리형 매체를 포함할 수 있다. 컴퓨터 판독 가능 매체는 마그네틱 저장매체, 예를 들면, 롬, 플로피 디스크, 하드 디스크 등을 포함하고,) 광학적 판독 매체, 예를 들면, 시디롬, DVD 등과 같은 저장 매체 를 포함할 수 있으나, 이에 제한되지 않는다. 또한, 컴퓨터 판독 가능 매체는 컴퓨터 저장 매체 및 통신 매체를 포함할 수 있다. 또한, 컴퓨터가 읽을 수 있는 복수의 기록 매체가 네트워크로 연결된 컴퓨터 시스템들에 분산되어 있을 수 있으 며, 분산된 기록 매체들에 저장된 데이터, 예를 들면 프로그램 명령어 및 코드가 적어도 하나의 컴퓨터에 의해 실행될 수 있다. 본 개시에서 설명된 특정 실행들은 일 실시예 일 뿐이며, 어떠한 방법으로도 본 개시의 범위를 한정하는 것은 아니다. 명세서의 간결함을 위하여, 종래 전자적인 구성들, 제어 시스템들, 소프트웨어, 및 상기 시스템들의 다 른 기능적인 측면들의 기재는 생략될 수 있다. 본 명세서에 기재된 \"...부\", \"모듈\" 등의 용어는 적어도 하나의 기능이나 동작을 처리하는 단위를 의미하며, 이는 하드웨어 또는 소프트웨어로 구현되거나 하드웨어와 소프트웨어의 결합으로 구현될 수 있다. \"부\", \"모 듈\"은 어드레싱될 수 있는 저장 매체에 저장되며 프로세서에 의해 실행될 수 있는 프로그램에 의해 구현될 수도 있다. 예를 들어, “부”, \"모듈\" 은 소프트웨어 구성 요소들, 객체 지향 소프트웨어 구성 요소들, 클래스 구성 요소 들 및 태스크 구성 요소들과 같은 구성 요소들과, 프로세스들, 함수들, 속성들, 프로시저들, 서브루틴들, 프로 그램 코드의 세그먼트들, 드라이버들, 펌웨어, 마이크로 코드, 회로, 데이터, 데이터베이스, 데이터 구조들, 테 이블들, 어레이들 및 변수들에 의해 구현될 수 있다.?"}
{"patent_id": "10-2017-0054513", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1a, 1b 및 1c는 일 실시예에 따른 음성 인식 시스템을 설명하기 위한 도면이다. 도 2a는 일반적인 음성 인식 장치의 동작 방법을 설명하기 위한 도면이다. 도 2b는 일 실시예에 따른 음성 인식 장치의 동작 방법을 설명하기 위한 도면이다. 도 3은 일 실시예에 따라 음성 인식 장치가 음성 인식을 수행하는 방법의 흐름도이다. 도 4는 일 실시예에 따라 음성 인식 장치가 음성 인식을 수행하는 방법을 설명하기 위한 도면이다. 도 5는 일 실시예에 따라 음성 인식 장치가 음성 인식을 수행하는 방법의 구체적인 흐름도이다. 도 6은 일 실시예에 따라 음성 인식 장치가 음성 인식이 수행된 결과를 출력하는 방법의 흐름도이다. 도 7은 일 실시예에 따라 음성 인식 장치가 음성 인식이 수행된 결과를 출력하는 방법을 설명하기 위한 도면이 다. 도 8은 일 실시예에 따라 음성 인식 장치가 음성 인식이 수행된 결과를 출력하는 방법을 설명하기 위한 도면이 다. 도 9는 일 실시예에 따라 음성 인식 장치가 음성 명령이 직접 명령인지 여부를 판단하는 방법의 흐름도이다. 도 10은 일 실시예에 따라 음성 인식 장치가 상황들에 대응하는 활성화 단어들을 결정하는 방법의 흐름도이다. 도 11a 및 11b는 일 실시예에 따른 음성 인식 장치의 블록도이다."}
