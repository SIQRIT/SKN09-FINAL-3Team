{"patent_id": "10-2020-0180495", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2022-0089870", "출원번호": "10-2020-0180495", "발명의 명칭": "신경망 모델 학습 방법 및 장치, 컴퓨터 프로그램", "출원인": "성균관대학교산학협력단", "발명자": "이지형"}}
{"patent_id": "10-2020-0180495", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "컴퓨팅 디바이스에 의해 수행되며, 신경망(Neural Network)을 통해 입력 데이터의 클래스를 식별하도록 구성된신경망 모델을 학습시키기 위한 방법으로서, 상기 방법은,원본 데이터를 이용하여 상기 신경망 모델을 학습시키는 제1 학습 단계로서,상기 원본 데이터에 대한 제1 특징 맵을 생성하는 단계, 및상기 생성된 제1 특징 맵으로부터 상기 원본 데이터에 대한 제1 클래스 액티베이션 맵(Class Activation Map)을생성하는 단계를 포함하는, 제1 학습 단계; 및상기 원본 데이터로부터 변환된 적대 데이터(Adversarial Data)를 이용하여 상기 신경망 모델을 학습시키는 제2학습 단계로서,상기 적대 데이터에 대한 제2 특징 맵을 생성하는 단계,상기 생성된 제2 특징 맵으로부터 상기 적대 데이터에 대한 제2 클래스 액티베이션 맵을 생성하는 단계, 및상기 제1 및 제2 클래스 액티베이션 맵에 대한 로짓 페어링(Logit Pairing)을 기반으로 상기 제2 클래스 액티베이션 맵이 상기 제1 클래스 액티베이션 맵을 추종하도록 상기 신경망 모델을 학습시키는 단계를 포함하는, 제2학습 단계;를 포함하는 것을 특징으로 하는 신경망 모델 학습 방법."}
{"patent_id": "10-2020-0180495", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 적대 데이터는, 상기 원본 데이터에 PGD(Projected Gradient Descent) 알고리즘을 적용하여 획득되는 것을특징으로 하는 신경망 모델 학습 방법."}
{"patent_id": "10-2020-0180495", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 제2 학습 단계의 상기 신경망 모델을 학습시키는 단계는,상기 제2 클래스 액티베이션 맵이 상기 제1 클래스 액티베이션 맵을 추종하여, 상기 적대 데이터의 클래스를 상기 원본 데이터의 클래스로 식별하도록 상기 신경망 모델을 학습시키는 것을 특징으로 하는 신경망 모델 학습방법."}
{"patent_id": "10-2020-0180495", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서,상기 제2 학습 단계의 상기 신경망 모델을 학습시키는 단계는,로짓 페어링을 기반으로 상기 제1 클래스 액티베이션 맵에 대한 상기 제2 클래스 액티베이션 맵의 손실을 지표하는 손실 함수를 정의하고, 상기 손실 함수의 출력값이 최소화되도록 상기 신경망 모델을 학습시키는 것을 특징으로 하는 신경망 모델 학습 방법.공개특허 10-2022-0089870-3-청구항 5 제4항에 있어서,상기 손실 함수는, 상기 제1 클래스 액티베이션 맵의 액티베이션 값과, 상기 제2 클래스 액티베이션 맵의 액티베이션 값 간의 차이를 지표하는 것을 특징으로 하는 신경망 모델 학습 방법."}
{"patent_id": "10-2020-0180495", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "프로세서(processor); 및상기 프로세서를 통해 실행되며, 신경망(Neural Network)을 통해 입력 데이터의 클래스를 식별하도록 구성된 신경망 모델을 학습시키기 위한 적어도 하나의 명령이 저장된 메모리;를 포함하고,상기 프로세서를 통해 실행되는 상기 적어도 하나의 명령은,원본 데이터를 통한 상기 신경망 모델의 학습을 통해 상기 원본 데이터에 대한 제1 특징 맵을 생성하도록 하는명령,상기 생성된 제1 특징 맵으로부터 상기 원본 데이터에 대한 제1 클래스 액티베이션 맵(Class Activation Map)을생성하도록 하는 명령,상기 원본 데이터로부터 변환된 적대 데이터(Adversarial Data)를 통한 상기 신경망 모델의 학습을 통해 상기적대 데이터에 대한 제2 특징 맵을 생성하도록 하는 명령,상기 생성된 제2 특징 맵으로부터 상기 적대 데이터에 대한 제2 클래스 액티베이션 맵을 생성하도록 하는 명령,및상기 제1 및 제2 클래스 액티베이션 맵에 대한 로짓 페어링(Logit Pairing)을 기반으로 상기 제2 클래스 액티베이션 맵이 상기 제1 클래스 액티베이션 맵을 추종하도록 상기 신경망 모델을 학습시키도록 하는 명령을 포함하는 것을 특징으로 하는, 신경망 모델 학습 장치."}
{"patent_id": "10-2020-0180495", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6항에 있어서,상기 프로세서는, 상기 신경망 모델을 학습시키도록 하는 명령 실행 시,상기 제2 클래스 액티베이션 맵이 상기 제1 클래스 액티베이션 맵을 추종하여, 상기 적대 데이터의 클래스를 상기 원본 데이터의 클래스로 식별하도록 상기 신경망 모델을 학습시키는 것을 특징으로 하는 신경망 모델 학습장치."}
{"patent_id": "10-2020-0180495", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서,상기 프로세서는, 상기 신경망 모델을 학습시키도록 하는 명령 실행 시,로짓 페어링을 기반으로 상기 제1 클래스 액티베이션 맵에 대한 상기 제2 클래스 액티베이션 맵의 손실을 지표하는 손실 함수를 정의하고, 상기 손실 함수의 출력값이 최소화되도록 상기 신경망 모델을 학습시키는 것을 특징으로 하는 신경망 모델 학습 장치."}
{"patent_id": "10-2020-0180495", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "공개특허 10-2022-0089870-4-제8항에 있어서,상기 손실 함수는, 상기 제1 클래스 액티베이션 맵의 액티베이션 값과, 상기 제2 클래스 액티베이션 맵의 액티베이션 값 간의 차이를 지표하는 것을 특징으로 하는 신경망 모델 학습 장치."}
{"patent_id": "10-2020-0180495", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "하드웨어와 결합되어, 신경망(Neural Network)을 통해 입력 데이터의 클래스를 식별하도록 구성된 신경망 모델을 학습시키기 위한 단계들을 실행시키기 위해 컴퓨터 판독 가능 기록 매체에 저장된 컴퓨터 프로그램으로서,상기 단계들은,원본 데이터를 이용하여 상기 신경망 모델을 학습시키는 제1 학습 단계로서,상기 원본 데이터에 대한 제1 특징 맵을 생성하는 단계, 및상기 생성된 제1 특징 맵으로부터 상기 원본 데이터에 대한 제1 클래스 액티베이션 맵(Class Activation Map)을생성하는 단계를 포함하는, 제1 학습 단계; 및상기 원본 데이터로부터 변환된 적대 데이터(Adversarial Data)를 이용하여 상기 신경망 모델을 학습시키는 제2학습 단계로서,상기 적대 데이터에 대한 제2 특징 맵을 생성하는 단계,상기 생성된 제2 특징 맵으로부터 상기 적대 데이터에 대한 제2 클래스 액티베이션 맵을 생성하는 단계, 및상기 제1 및 제2 클래스 액티베이션 맵에 대한 로짓 페어링(Logit Pairing)을 기반으로 상기 제2 클래스 액티베이션 맵이 상기 제1 클래스 액티베이션 맵을 추종하도록 상기 신경망 모델을 학습시키는 단계를 포함하는, 제2학습 단계;를 포함하는, 컴퓨터 판독 가능 기록 매체에 저장된 컴퓨터 프로그램."}
{"patent_id": "10-2020-0180495", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 신경망 모델 학습 방법 및 장치, 컴퓨터 프로그램에 관한 것으로서, 상기 방법은, 원본 데이터를 이용 하여 신경망 모델을 학습시키는 제1 학습 단계로서, 원본 데이터에 대한 제1 특징 맵을 생성하는 단계, 및 생성 된 제1 특징 맵으로부터 원본 데이터에 대한 제1 클래스 액티베이션 맵(Class Activation Map)을 생성하는 단계 를 포함하는, 제1 학습 단계, 및 원본 데이터로부터 변환된 적대 데이터(Adversarial Data)를 이용하여 신경망 모델을 학습시키는 제2 학습 단계로서, 적대 데이터에 대한 제2 특징 맵을 생성하는 단계, 생성된 제2 특징 맵으 로부터 적대 데이터에 대한 제2 클래스 액티베이션 맵을 생성하는 단계, 및 제1 및 제2 클래스 액티베이션 맵에 대한 로짓 페어링(Logit Pairing)을 기반으로 제2 클래스 액티베이션 맵이 제1 클래스 액티베이션 맵을 추종하도 록 신경망 모델을 학습시키는 단계를 포함하는, 제2 학습 단계를 포함하는 것을 특징으로 한다."}
{"patent_id": "10-2020-0180495", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 신경망 모델 학습 방법 및 장치, 컴퓨터 프로그램에 관한 것으로서, 더욱 상세하게는 Adversarial Attack에 강인하도록 신경망 모델을 학습시키기 위한 신경망 모델 학습 방법 및 장치, 컴퓨터 프로그램에 관한 것이다."}
{"patent_id": "10-2020-0180495", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "딥 러닝(Deep Learning)은 기계가 사람처럼 생각하고 배울 수 있도록 하는 인공지능(AI) 기술을 의미하며, 인공 신경망 이론을 기반으로 복잡한 비선형 문제를 기계가 스스로 학습하여 해결할 수 있도록 한다. 이러한 딥 러닝 기술을 적용하면 사람이 모든 판단 기준을 정해주지 않아도 컴퓨터가 스스로 인지, 추론 및 판단을 수행할 수 있어 패턴 분석 분야에서 광범위하게 적용되고 있다. 인공 신경망(ANN: Artificial Neural Network)은 입력 계층(input layer)과 출력 계층(output layer) 사이에 복수 개의 은닉 계층(hidden layer)들로 이뤄진 구조로 구성되며, 선형 맞춤(linear fitting)과 비선형 변환 (nonlinear transformation or activation) 등을 반복적으로 수행한다. 인공 신경망은 이미지 인식, 음성 인식, 침입 감내 시스템(Intrusion Tolerance System) 및 자연어 처리 (Natural Language Processing) 등 광범위한 분야에 적용되고 있어 그 보안 문제가 제기되어 왔다. 구체적으로, 입력 데이터에 야기된 미소 변조를 인간이 육안으로 인지할 수 없는 경우라도, 미소 변조가 발생한 입력 데이터 는 인공 신경망이 입력 데이터의 클래스를 잘못 식별하도록 하는 문제점을 야기할 수 있다. 예를 들어, 인공 신 경망을 통해 도로 표지판을 인식하여 주행하는 자율 주행 차량에 있어, 인공 신경망으로 입력되는 도로 표지판 이미지를 미소 변조시킴으로써 자율 주행 차량의 의도치 않는 동작이 유발되는 문제점이 존재한다(예: 좌회전 표시 이미지의 미소 변조가 자율 주행 차량의 우회전을 유발하는 경우). 상기한, 미소 변조된 입력 데이터를 적대적 예제(Adversarial Example)라 하며, 최소한의 이미지 변조를 통해 원래 이미지의 클래스와는 다른 클래스 로 인식되도록 하는 것을 Adversarial Attack 또는 Evasion Attack(기만 공격, 또는 회피 공격)이라 한다."}
{"patent_id": "10-2020-0180495", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 2, "content": "본 발명의 배경기술은 대한민국 공개특허공보 제10-2017-0095582호(2017.08.23. 공개)에 개시되어 있다."}
{"patent_id": "10-2020-0180495", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명의 일 측면에 따른 목적은 원본 데이터(원본 이미지)와 적대 데이터(적대적 이미지)에 대한 해석상의 일 치를 확보하여 Adversarial Attack에 강인하도록 인공 신경망을 학습시키기 위한 신경망 모델 학습 방법 및 장 치, 컴퓨터 프로그램을 제공하는 것이다."}
{"patent_id": "10-2020-0180495", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 일 측면에 따른 신경망 모델 학습 방법은, 컴퓨팅 디바이스에 의해 수행되며, 신경망(Neural Network)을 통해 입력 데이터의 클래스를 식별하도록 구성된 신경망 모델을 학습시키기 위한 방법으로서, 상기 방법은, 원본 데이터를 이용하여 상기 신경망 모델을 학습시키는 제1 학습 단계로서, 상기 원본 데이터에 대한 제1 특징 맵을 생성하는 단계, 및 상기 생성된 제1 특징 맵으로부터 상기 원본 데이터에 대한 제1 클래스 액티 베이션 맵(Class Activation Map)을 생성하는 단계를 포함하는, 제1 학습 단계, 및 상기 원본 데이터로부터 변 환된 적대 데이터(Adversarial Data)를 이용하여 상기 신경망 모델을 학습시키는 제2 학습 단계로서, 상기 적대 데이터에 대한 제2 특징 맵을 생성하는 단계, 상기 생성된 제2 특징 맵으로부터 상기 적대 데이터에 대한 제2 클래스 액티베이션 맵을 생성하는 단계, 및 상기 제1 및 제2 클래스 액티베이션 맵에 대한 로짓 페어링(Logit Pairing)을 기반으로 상기 제2 클래스 액티베이션 맵이 상기 제1 클래스 액티베이션 맵을 추종하도록 상기 신경 망 모델을 학습시키는 단계를 포함하는, 제2 학습 단계를 포함하는 것을 특징으로 한다. 본 발명에 있어 상기 적대 데이터는, 상기 원본 데이터에 PGD(Projected Gradient Descent) 알고리즘을 적용하 여 획득되는 것을 특징으로 한다. 본 발명에 있어 상기 제2 학습 단계의 상기 신경망 모델을 학습시키는 단계는, 상기 제2 클래스 액티베이션 맵 이 상기 제1 클래스 액티베이션 맵을 추종하여, 상기 적대 데이터의 클래스를 상기 원본 데이터의 클래스로 식 별하도록 상기 신경망 모델을 학습시키는 것을 특징으로 한다. 본 발명에 있어 상기 제2 학습 단계의 상기 신경망 모델을 학습시키는 단계는, 로짓 페어링을 기반으로 상기 제 1 클래스 액티베이션 맵에 대한 상기 제2 클래스 액티베이션 맵의 손실을 지표하는 손실 함수를 정의하고, 상기 손실 함수의 출력값이 최소화되도록 상기 신경망 모델을 학습시키는 것을 특징으로 한다. 본 발명에 있어 상기 손실 함수는, 상기 제1 클래스 액티베이션 맵의 액티베이션 값과, 상기 제2 클래스 액티베 이션 맵의 액티베이션 값 간의 차이를 지표하는 것을 특징으로 한다. 본 발명의 일 측면에 따른 신경망 모델 학습 장치는 프로세서(processor), 및 상기 프로세서를 통해 실행되며, 신경망(Neural Network)을 통해 입력 데이터의 클래스를 식별하도록 구성된 신경망 모델을 학습시키기 위한 적 어도 하나의 명령이 저장된 메모리를 포함하고, 상기 프로세서를 통해 실행되는 상기 적어도 하나의 명령은, 원 본 데이터를 통한 상기 신경망 모델의 학습을 통해 상기 원본 데이터에 대한 제1 특징 맵을 생성하도록 하는 명 령, 상기 생성된 제1 특징 맵으로부터 상기 원본 데이터에 대한 제1 클래스 액티베이션 맵(Class Activation Map)을 생성하도록 하는 명령, 상기 원본 데이터로부터 변환된 적대 데이터(Adversarial Data)를 통한 상기 신 경망 모델의 학습을 통해 상기 적대 데이터에 대한 제2 특징 맵을 생성하도록 하는 명령, 상기 생성된 제2 특징 맵으로부터 상기 적대 데이터에 대한 제2 클래스 액티베이션 맵을 생성하도록 하는 명령, 및 상기 제1 및 제2 클래스 액티베이션 맵에 대한 로짓 페어링(Logit Pairing)을 기반으로 상기 제2 클래스 액티베이션 맵이 상기 제1 클래스 액티베이션 맵을 추종하도록 상기 신경망 모델을 학습시키도록 하는 명령을 포함하는 것을 특징으로 한다. 본 발명의 일 측면에 따른 컴퓨터 프로그램은 하드웨어와 결합되어, 신경망(Neural Network)을 통해 입력 데이 터의 클래스를 식별하도록 구성된 신경망 모델을 학습시키기 위한 단계들을 실행시키기 위해 컴퓨터 판독 가능기록 매체에 저장된 컴퓨터 프로그램으로서, 상기 단계들은, 원본 데이터를 이용하여 상기 신경망 모델을 학습 시키는 제1 학습 단계로서, 상기 원본 데이터에 대한 제1 특징 맵을 생성하는 단계, 및 상기 생성된 제1 특징 맵으로부터 상기 원본 데이터에 대한 제1 클래스 액티베이션 맵(Class Activation Map)을 생성하는 단계를 포함 하는, 제1 학습 단계, 및 상기 원본 데이터로부터 변환된 적대 데이터(Adversarial Data)를 이용하여 상기 신경 망 모델을 학습시키는 제2 학습 단계로서, 상기 적대 데이터에 대한 제2 특징 맵을 생성하는 단계, 상기 생성된 제2 특징 맵으로부터 상기 적대 데이터에 대한 제2 클래스 액티베이션 맵을 생성하는 단계, 및 상기 제1 및 제2 클래스 액티베이션 맵에 대한 로짓 페어링(Logit Pairing)을 기반으로 상기 제2 클래스 액티베이션 맵이 상기 제1 클래스 액티베이션 맵을 추종하도록 상기 신경망 모델을 학습시키는 단계를 포함하는, 제2 학습 단계를 포 함하는 것을 특징으로 한다."}
{"patent_id": "10-2020-0180495", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명의 일 측면에 따르면, 본 발명은 원본 데이터에 대한 제1 클래스 액티베이션 맵과 적대 데이터에 대한 제2 클래스 액티베이션 맵 간의 손실이 최소화되도록 하는 방식으로 인공 신경망 모델을 학습시켜 원본 데이터 및 적대 데이터 간의 해석상의 일치가 확보되도록 함으로써, Adversarial Attack에 강인하도록 인공 신경망을 학습시킬 수 있다."}
{"patent_id": "10-2020-0180495", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 첨부된 도면들을 참조하여 본 발명에 따른 신경망 모델 학습 방법 및 장치, 컴퓨터 프로그램의 실시예를 설명한다. 이 과정에서 도면에 도시된 선들의 두께나 구성요소의 크기 등은 설명의 명료성과 편의상 과장되게 도시되어 있을 수 있다. 또한, 후술되는 용어들은 본 발명에서의 기능을 고려하여 정의된 용어들로서 이는 사용 자, 운용자의 의도 또는 관례에 따라 달라질 수 있다. 그러므로 이러한 용어들에 대한 정의는 본 명세서 전반에 걸친 내용을 토대로 내려져야 할 것이다. 도 1은 본 발명의 일 실시예에 따른 신경망 모델 학습 장치를 설명하기 위한 블록구성도이고, 도 2는 본 발명의 일 실시예에 따른 신경망 모델 학습 방법을 통해 신경망 모델이 학습되는 과정을 보인 예시도이며, 도 3은 본 발명의 일 실시예에 따른 신경망 모델 학습 방법을 설명하기 위한 흐름도이고, 도 4는 본 발명의 일 실시예에 따른 신경망 모델 학습 방법에 따라 신경망 모델이 학습되는 과정에서 도출되는 제1 및 제2 클래스 액티베이션 맵의 예시를 보인 예시도이다. 본 실시예에서 학습 대상이 되는 신경망 모델(Neural Network Model)은 입력되는 데이터의 클래스를 식별하도록 구성된 인공 신경망 모델로서, 본 실시예에서는 도 2에 도시된 것과 같이 CNN(Convolutional Neural Network) 모델을 예시로서 설명한다. 상기와 같은 신경망 모델을 학습시키기 위한, 본 실시예의 신경망 모델 학습 장치는 도 1에 도시된 것과 같이 메모리 및 프로세서를 포함할 수 있다. 메모리에는 신경망 모델을 학습시키기 위한 적어도 하나의 명령이 저장될 수 있다. 메모리는 휘발성 저장 매체 및/또는 비휘발성 저장 매체로 구현될 수 있으며, 예를 들어 읽기 전용 메모리(ROM: Read Only Memory) 및/또는 랜덤 액세스 메모리(RAM: Random Access Memory)로 구현될 수 있다. 프로세서는 신경망 모델에 대한 학습을 수행하는 학습 주체로서, 중앙 처리 장치(CPU: Central Processing Unit) 또는 SoC(System on Chip)로 구현될 수 있으며, 운영 체제 또는 어플리케이션을 구동하여 프로세서 에 연결된 복수의 하드웨어 또는 소프트웨어 구성요소들을 제어할 수 있고, 각종 데이터 처리 및 연산을 수행할 수 있다. 프로세서는 메모리에 저장된 적어도 하나의 명령을 실행시키고, 그 실행 결과 데이터를 메 모리에 저장하도록 구성될 수 있다. 메모리에 저장되어 프로세서에 의해 실행되는 적어도 하나의 명령은, ⅰ)원본 데이터를 통한 신경망 모델의 학습을 통해 원본 데이터에 대한 제1 특징 맵을 생성하도록 하는 명령과, ⅱ)제1 특징 맵으로부터 원본 데이터에 대한 제1 클래스 액티베이션 맵을 생성하도록 하는 명령과, ⅲ)원본 데이터로부터 변환된 적대 데이터 를 통한 신경망 모델의 학습을 통해 적대 데이터에 대한 제2 특징 맵을 생성하도록 하는 명령과, ⅳ)제2 특징 맵으로부터 적대 데이터에 대한 제2 클래스 액티베이션 맵을 생성하도록 하는 명령과, ⅴ)제1 및 제2 클래스 액 티베이션 맵에 대한 로짓 페어링(Logit Pairing)을 기반으로 제2 클래스 액티베이션 맵이 제1 클래스 액티베이 션 맵을 추종하도록 신경망 모델을 학습시키도록 하는 명령을 포함할 수 있다. 도 2는 본 실시예에 따른 신경망 모델 학습 방법이 수행되는 과정을 도시하고 있다. 도 2에 도시된 것과 같이 본 실시예의 신경망 모델 학습 방법은 크게 원본 데이터가 이용되는 학습 과정, 원본 데이터로부터 변환된 적대 데이터(적대적 예제, Adversarial Example)가 이용되는 학습 과정으로 구성될 수 있다. 원본 데이터 및 적대 데 이터는 이미지 데이터에 해당할 수 있으며, 적대 데이터는 원본 데이터에 PGD(Projected Gradient Descent) 알 고리즘을 적용하여 획득될 수 있다. 본 실시예에서 신경망 모델이 학습되는 방식에 대하여 개괄적으로 설명하면, 프로세서는 메모리에 저 장된 명령어를 실행시켜, 도 2에 도시된 것과 같이 입력 데이터를 그 클래스와 함께 신경망 모델에 입력하여 입 력 데이터의 채널별 특징 맵(Feature Map)을 추출하고, 추출된 각 채널별 특징 맵에 대하여 GAP(Global Average Pooling)를 적용한 후, GAP 적용 결과값과 선형 레이어(FC: Fully-Connected layer)의 가중치 벡터 간의 가중 합(weighted sum) 결과값을 분류기(예: SoftMax)에 적용하여 입력 데이터의 클래스를 예측하는 동작을 반복적으 로 수행하는 과정에서 신경망 모델의 파라미터(필터 파라미터, 가중치 벡터 등)를 갱신하는 방식으로 신경망 모 델의 학습을 수행할 수 있다. 한편, Adversarial Attack에 대한 신경망 모델의 강인성(Robustness)을 확보하기 위해서는 원본 데이터 및 적대 데이터에 대한 해석상의 일치가 확보되도록 신경망 모델을 학습시킬 필요가 있으며, 즉 신경망 모델에 대하여 적대 데이터를 통한 Adversarial Attack이 가해진 경우에도 원본 데이터와 동일한 클래스로 식별하도록 신경망 모델을 학습시킬 필요가 있다. 본 실시예에서는 원본 데이터 및 적대 데이터에 대한 해석상의 일치가 확보되도 록 신경망 모델을 학습시키기 위한 수단으로서, 원본 데이터 및 적대 데이터 각각의 클래스 액티베이션 맵 (Class Activation Map)에 대한 로짓 페어링(Logit Pairing) 방식을 채용하며, 이하에서는 상기 구성에 대하여 신경망 모델의 학습 방법으로서 구체적으로 설명한다. 도 3을 참조하면, 먼저 프로세서는 원본 데이터를 이용하여 신경망 모델을 학습시키는 제1 학습 단계 (S100)를 수행한다. S100 단계에서, 프로세서는 신경망 모델의 Feature Extractor를 통해 원본 데이터에 대한 제1 특징 맵을 채널별로 생성한다(S110). 후속하여, 채널별 제1 특징 맵에 대하여 GAP를 적용한 후, GAP 적용 결과값과 선형 레이어의 가중치 벡터 간의 가중합을 분류기에 적용하여 원본 데이터의 클래스를 예측하는 동작을 반복적으로 수행하는 방식을 통해 신경망 모델이 학습되는 과정이 수행된다. 또한, 프로세서는 S110 단계에서 생성된 채널별 제1 특징 맵으로부터 원본 데이터에 대한 제1 클래스 액티 베이션 맵을 생성한다(S120). S120 단계에서, 프로세서는 제1 특징 맵과 상기한 선형 레이어의 가중치 벡 터를 채널별로 곱한 후 그 결과를 합산하여 제1 클래스 액티베이션 맵을 생성한다. 제1 클래스 액티베이션 맵은 하기 수학식 1로 표현될 수 있다. 수학식 1 수학식 1에서, c는 타겟 클래스를 의미하고, k는 채널 인덱스를 의미하며, CAMc clean은 타겟 클래스 c에 대한 제1 클래스 액티베이션 맵을 의미하고, αkc는 타겟 클래스 c 및 채널 k에 대한 선형 레이어의 가중치 벡터를 의미하 며, Ak는 채널 k에 대한 제1 특징 맵을 의미한다. 한편, 제1 클래스 액티베이션 맵의 액티베이션 값(CAMc clean/act)은, 활성화 함수 'ReLU'를 적용하여 하기 수학식 2와 같이 정의된다. 수학식 2"}
{"patent_id": "10-2020-0180495", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "신경망 모델을 통해 분류하려는 클래스의 수를 n으로 정의하면, 전술한 S110 단계 및 S120 단계는 타겟 클래스 c가 0에서 n-1까지 n회 수행될 수 있으며, 이에 따라 제1 클래스 액티베이션 맵의 액티베이션 값 또한 n개 산출 된다. 산출된 n개의 액티베이션 값의 집합을 '제1 액티베이션 값(TotalCAMclean)'으로 정의할 때, 제1 액티베이션 값(TotalCAMclean)은 하기 수학식 3으로 표현될 수 있다. 수학식 3"}
{"patent_id": "10-2020-0180495", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "제1 학습 단계(S100)를 통해 획득된 제1 액티베이션 값(TotalCAMclean)은 이하에서 설명하는 제2 학습 단계(20 0)에서의 입력 데이터가 된다. S100 단계 이후, 프로세서는 적대 데이터를 이용하여 신경망 모델을 학습시키는 제2 학습 단계(S200)를 수 행하며, S200 단계는 적대적 훈련(Adversarial Training) 과정으로서 기능한다. S200 단계에서, 프로세서는 신경망 모델의 Feature Extractor를 통해 적대 데이터에 대한 제2 특징 맵을 채널별로 생성한다(S210). 이어서, 프로세서는 S210 단계에서 생성된 채널별 제2 특징 맵으로부터 적대 데이터에 대한 제2 클래스 액 티베이션 맵을 생성한다(S220). S220 단계의 동작 방식은 S120 단계와 동일하며, 이에 따라 S220 단계에서 산출 되는 적대 데이터에 대한 제2 클래스 액티베이션 맵(CAMc adv), 제2 클래스 액티베이션 맵의 액티베이션 값 ((CAMc adv/act)), 및 제2 액티베이션 값(TotalCAMadv)은 각각 하기 수학식 4 내지 6으로 표현될 수 있다. 수학식 4 수학식 5"}
{"patent_id": "10-2020-0180495", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "수학식 6"}
{"patent_id": "10-2020-0180495", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "item": 5, "content": "도 4는 본 실시예에서 도출된 제1 및 제2 클래스 액티베이션 맵의 예시를 보이고 있으며, 클래스의 수(n)는 10 으로 하여 클래스별로 제1 및 제2 클래스 액티베이션 맵을 도출하였다. S220 단계 이후, 프로세서는 제1 및 제2 클래스 액티베이션 맵에 대한 로짓 페어링(Logit Pairing)을 기반 으로 제2 클래스 액티베이션 맵이 제1 클래스 액티베이션 맵을 추종하도록, 그리고 그에 따라 적대 데이터의 클 래스를 원본 데이터의 클래스로 식별하도록 신경망 모델을 학습시킨다(S230). 구체적으로, S230 단계에서 프로세서는 로짓 페어링을 기반으로 제1 클래스 액티베이션 맵에 대한 제2 클 래스 액티베이션 맵의 손실을 지표하는 손실 함수를 정의하고, 손실 함수의 출력값이 최소화되도록 신경망 모델 을 학습시킨다. 여기서, 손실 함수는 제1 클래스 액티베이션 맵의 액티베이션 값과, 제2 클래스 액티베이션 맵 의 액티베이션 값 간의 차이를 지표하며, 분류하려는 클래스의 수가 n개임을 고려하여, 손실 함수는 전술한 제1 액티베이션 값(TotalCAMclean) 및 제2 액티베이션 값(TotalCAMadv) 간의 차이를 지표하는 것으로 특정될 수 있다. 상기한 '차이'로서 본 실시예에서는 평균 제곱 오차(MSE: Mean Square Error)를 채용하며, 따라서 손실 함수는 하기 수학식 7로 정의될 수 있다. 수학식 7"}
{"patent_id": "10-2020-0180495", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "추가적으로, 전술한 손실 함수에는 원본 데이터 및 적대 데이터의 클래스 액티베이션 맵 간의 손실에 더하여, 원본 데이터의 분류 성능을 확보하기 위해 기본적인 크로스-엔트로피 손실 함수(LossCrossEntropy))가 반영될 수 있"}
{"patent_id": "10-2020-0180495", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 7, "content": "으며(크로스-엔트로피 손실 함수에 관하여는 본 기술분야에서 주지된 것이므로 구체적인 설명은 생략한다), 따 라서 최종적인 손실 함수(Loss)는 하기 수학식 8로 정의될 수 있다. 수학식 8"}
{"patent_id": "10-2020-0180495", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 8, "content": "이에 따라, S230 단계에서 프로세서는 수학식 8에 따른 손실 함수의 출력값이 최소화되도록 신경망 모델에 대한 Adversarial Training을 수행하여, 적대 데이터의 클래스를 원본 데이터의 클래스로 식별하도록 신경망 모 델을 학습시킴으로써, Adversarial Attack에 강인하도록 신경망 모델을 학습시킬 수 있다.한편, 본 실시예에 따른 신경망 모델 학습 방법은 하드웨어와 결합되어 전술한 S100 단계 및 S200 단계를 실행 시키기 위한 컴퓨터 프로그램으로 작성될 수 있으며, 컴퓨터로 판독 가능한 기록매체에 저장되어 상기 컴퓨터 프로그램을 동작시키는 범용 디지털 컴퓨터에서 구현될 수 있다. 컴퓨터로 판독 가능한 기록매체는 ROM, RAM, 하드 디스크, 플로피 디스크, 자기 테이프와 같은 자기 매체(magnetic media), CD-ROM, DVD와 같은 광기록 매체 (optical media), 플롭티컬 디스크(floptical disk)와 같은 자기-광 매체(magneto-optical media), 플래시 메 모리(flash memory)와 같은 프로그램 명령어들을 저장하고 수행하도록 특별히 구성된 하드웨어 장치가 해당될 수 있다. 본 명세서에서 설명된 구현은, 예컨대, 방법 또는 프로세스, 장치, 소프트웨어 프로그램, 데이터 스트림 또는 신호로 구현될 수 있다. 단일 형태의 구현의 맥락에서만 논의(예컨대, 방법으로서만 논의)되었더라도, 논의된 특징의 구현은 또한 다른 형태(예컨대, 장치 또는 프로그램)로도 구현될 수 있다. 장치는 적절한 하드웨어, 소 프트웨어 및 펌웨어 등으로 구현될 수 있다. 방법은, 예컨대, 컴퓨터, 마이크로프로세서, 집적 회로 또는 프로 그래밍가능한 로직 디바이스 등을 포함하는 프로세싱 디바이스를 일반적으로 지칭하는 프로세서 등과 같은 장치 에서 구현될 수 있다. 프로세서는 또한 최종-사용자 사이에 정보의 통신을 용이하게 하는 컴퓨터, 셀 폰, 휴대 용/개인용 정보 단말기(personal digital assistant: \"PDA\") 및 다른 디바이스 등과 같은 통신 디바이스를 포 함한다. 본 발명은 도면에 도시된 실시예를 참고로 하여 설명되었으나, 이는 예시적인 것에 불과하며 당해 기술이 속하"}
{"patent_id": "10-2020-0180495", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 9, "content": "는 기술분야에서 통상의 지식을 가진 자라면 이로부터 다양한 변형 및 균등한 타 실시예가 가능하다는 점을 이 해할 것이다. 따라서, 본 발명의 진정한 기술적 보호범위는 아래의 특허청구범위에 의하여 정해져야 할 것이다."}
{"patent_id": "10-2020-0180495", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일 실시예에 따른 신경망 모델 학습 장치를 설명하기 위한 블록구성도이다. 도 2는 본 발명의 일 실시예에 따른 신경망 모델 학습 방법을 통해 신경망 모델이 학습되는 과정을 보인 예시도 이다. 도 3은 본 발명의 일 실시예에 따른 신경망 모델 학습 방법을 설명하기 위한 흐름도이다. 도 4는 본 발명의 일 실시예에 따른 신경망 모델 학습 방법에 따라 신경망 모델이 학습되는 과정에서 도출되는 제1 및 제2 클래스 액티베이션 맵의 예시를 보인 예시도이다."}
