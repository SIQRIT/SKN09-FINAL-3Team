{"patent_id": "10-2009-0093473", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2011-0035662", "출원번호": "10-2009-0093473", "출원인": "아주대학교산학협력단", "발명자": "최유주"}}
{"patent_id": "10-2009-0093473", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "감시 목표 지역을 촬영하는 복수의 감시 카메라와;상기 복수의 감시 카메라에 의해 촬영된 영상을 기초로 보행자 특성 정보를 추출하고, 상기 추출된 보행자 특성정보 중 검색하고자 하는 보행자 특성 정보에 매칭되는 보행자 특성 정보가 추출된 영상을 검출하는 영상 처리서버; 및상기 검색하고자 하는 보행자 특성 정보를 입력하거나 상기 검출된 영상을 영상 검색 화면에 표시하는 사용자인터페이스 부를 포함하는 지능형 영상 검색 시스템."}
{"patent_id": "10-2009-0093473", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1항에 있어서, 상기 영상 처리 서버는,상기 복수의 감시 카메라에 의해 촬영된 영상을 기초로 보행자를 감지하고, 상기 감지된 보행자의 이동을 추적하며, 상기 추적된 보행자의 특성 정보를 추출하는 보행자 추적 및 특성 추출기; 및상기 추출된 보행자 특성 정보 중 상기 검색하고자 하는 보행자 특성 정보에 매칭되는 보행자 특성 정보가 추출된 영상을 상기 사용자 인터페이스 부로 출력하는 특성 매칭 및 결과 출력기를 포함하는 것을 특징으로 하는 지능형 영상 검색 시스템."}
{"patent_id": "10-2009-0093473", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 2항에 있어서, 상기 보행자 추적 및 특성 추출기는,상기 복수의 감시 카메라에 의해 촬영된 영상으로부터 모션 히스토리 정보를 출력하는 옵티컬 플로우 분석기와;상기 복수의 감시 카메라에 의해 촬영된 영상에 상기 출력된 모션 히스토리 정보를 결합하여 배경 차 영상을 출력하는 적응적 배경 차감기와;상기 배경 차 영상을 기초로 그리드 기반 영역 분할을 수행하고, 그리드 패치 별 배경픽셀 대비 전경픽셀 비율을 계산하여 보행자 관심 영역(Region Of Interest)을 검출하고, 상기 검출된 보행자 ROI를 추적하는 보행자 추적기; 및상기 보행자 추적기로부터 제공된 보행자 ROI와 영상 데이터 저장부로부터 제공된 정지 영상 및 메타데이터를이용하여 보행자 특성 정보를 추출하는 보행자 특성 추출기를 포함하는 것을 특징으로 하는 지능형 영상 검색시스템."}
{"patent_id": "10-2009-0093473", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 3항에 있어서,상기 적응적 배경 차감기는 근사적 메디안 필터링 기반 배경 차감 기법을 이용하여 배경 차 영상을 출력하는 것을 특징으로 하는 지능형 영상 검색 시스템."}
{"patent_id": "10-2009-0093473", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제 2항에 있어서, 상기 특성 매칭 및 결과 출력기는,상기 보행자 추적 및 특성 추출기로부터 제공된 보행자 특성 정보 중 상기 검색하고자 하는 보행자 특성 정보에공개특허 10-2011-0035662-3-매칭되는 보행자 특성 정보가 포함된 영상을 검출하는 보행자 특성 매칭기; 및상기 검출된 영상을 상기 사용자 인터페이스 부로 출력하는 조회 결과 출력기를 포함하는 것을 특징으로 하는지능형 영상 검색 시스템."}
{"patent_id": "10-2009-0093473", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제 1항에 있어서,상기 보행자의 특성 정보는 보행자의 키, 모자색, 안경 착용 유무, 보행자의 의상 색 중 적어도 하나임을 특징으로 하는 지능형 영상 검색 시스템."}
{"patent_id": "10-2009-0093473", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "복수의 감시 카메라로부터 촬영된 영상을 수신하는 과정과;상기 수신된 영상을 기초로 보행자의 특성 정보를 추출하는 과정과;상기 추출된 보행자 특성 정보 중 사용자로부터 입력된 검색하고자 하는 보행자 특성 정보에 매칭되는 보행자특성 정보가 추출된 영상을 검출하는 과정; 및상기 검출된 영상을 영상 검색 화면에 표시하는 과정을 포함하는 지능형 영상 검색 방법."}
{"patent_id": "10-2009-0093473", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제 7항에 있어서, 상기 보행자의 특성 정보를 추출하는 과정은,상기 수신된 영상으로부터 모션 히스토리 정보를 출력하는 과정과;상기 수신된 영상에 상기 출력된 모션 히스토리 정보를 결합하여 배경 차 영상을 출력하는 과정과;상기 출력된 배경 차 영상을 기초로 보행자 관심 영역(Region Of Interest)을 검출하고, 상기 검출된 보행자ROI를 추적하는 과정; 및상기 추적된 보행자 ROI와 정지 영상 및 메타데이터를 이용하여 보행자 특성 정보를 추출하는 과정을 포함하는것을 특징으로 하는 지능형 영상 검색 방법."}
{"patent_id": "10-2009-0093473", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제 8항에 있어서, 상기 보행자 ROI를 검출하는 과정은,상기 출력된 배경 차 영상을 기초로 그리드 기반 영역 분할을 수행하고, 그리드 패치 별 배경픽셀 대비 전경픽셀 비율을 계산하여 상기 보행자 ROI를 검출하는 것을 특징으로 하는 지능형 영상 검색 방법."}
{"patent_id": "10-2009-0093473", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제 7항에 있어서, 상기 보행자의 특성 정보는 보행자의 키, 모자 색, 안경 착용 유무, 보행자의 의상 색 중 적어도 하나임을 특징으로 하는 지능형 영상 검색 방법."}
{"patent_id": "10-2009-0093473", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "복수의 감시 카메라를 구비하는 지능형 영상 검색 시스템에 있어서,공개특허 10-2011-0035662-4-상기 복수의 감시 카메라에 의해 촬영된 영상을 기초로 상기 보행자의 특성 정보를 추출하고, 상기 추출된 보행자 특성 정보 중 검색하고자 하는 보행자 특성 정보에 매칭되는 보행자 특성 정보가 추출된 영상을 검출하는 영상 처리 장치를 포함하는 지능형 영상 검색 시스템."}
{"patent_id": "10-2009-0093473", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제 11항에 있어서,상기 검색하고자 하는 보행자 특성 정보를 입력하거나 상기 검출된 영상을 영상 검색 화면에 표시하는 사용자인터페이스 부를 더 포함하는 것을 특징으로 하는 지능형 영상 검색 시스템."}
{"patent_id": "10-2009-0093473", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제 11항에 있어서, 상기 영상 처리 장치는,상기 복수의 감시 카메라에 의해 촬영된 영상을 기초로 보행자를 감지하고, 상기 감지된 보행자의 이동을 추적하며, 상기 추적된 보행자의 특성 정보를 추출하는 보행자 추적 및 특성 추출기; 및상기 추출된 보행자 특성 정보 중 상기 검색하고자 하는 보행자 특성 정보에 매칭되는 보행자 특성 정보가 추출된 영상을 검출하는 특성 매칭 및 결과 출력기를 포함하는 것을 특징으로 하는 지능형 영상 검색 시스템."}
{"patent_id": "10-2009-0093473", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제 13항에 있어서, 상기 보행자 추적 및 특성 추출기는,상기 복수의 감시 카메라에 의해 촬영된 영상으로부터 모션 히스토리 정보를 출력하는 옵티컬 플로우 분석기와;상기 복수의 감시 카메라에 의해 촬영된 영상에 상기 모션 히스토리 정보를 결합하여 배경 차 영상을 출력하는적응적 배경 차감기와;상기 배경 차 영상을 기초로 그리드 기반 영역 분할을 수행하고, 그리드 패치 별 배경픽셀 대비 전경픽셀 비율을 계산하여 보행자 관심 영역(Region Of Interest)을 검출하고, 상기 검출된 보행자 ROI를 추적하는 보행자 추적기; 및상기 보행자 추적기로부터 제공된 보행자 ROI와 영상 데이터 저장부로부터 제공된 정지 영상 및 메타데이터를이용하여 보행자 특성 정보를 추출하는 보행자 특성 추출기를 포함하는 것을 특징으로 하는 지능형 영상 검색시스템."}
{"patent_id": "10-2009-0093473", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제 14항에 있어서,상기 적응적 배경 차감기는 근사적 메디안 필터링 기반 배경 차감 기법을 이용하여 배경 차 영상을 출력하는 것을 특징으로 하는 지능형 영상 검색 시스템."}
{"patent_id": "10-2009-0093473", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제 13항에 있어서, 상기 특성 매칭 및 결과 출력기는,상기 보행자 추적 및 특성 추출기로부터 제공된 보행자 특성 정보 중 상기 검색하고자 하는 보행자 특성 정보에매칭되는 보행자 특성 정보가 포함된 영상을 검출하는 보행자 특성 매칭기; 및상기 검출된 영상을 출력하는 조회 결과 출력기를 포함하는 것을 특징으로 하는 지능형 영상 검색 시스템.공개특허 10-2011-0035662-5-명 세 서발명의 상세한 설명 기 술 분 야본 발명은 영상 검색 시스템 및 그 방법에 관한 것으로, 보다 구체적으로는 감시 카메라를 이용한 지능형 영상 [0001]검색 시스템 및 그 방법에 관한 것이다. 배 경 기 술어떤 특정 행위나 사건이 일어나는 것을 감지하는 영상 감시 시스템은 사람 추적을 이용한 연구 분야 중에서도 [0002]가장 중요하게 인식되고 있다. 그 이유는 사회가 발전할수록 공공 장소뿐 아니라 개인 공간에서도 개인 및 시설물의 안전에 대한 중요성이 높이 인식되고 있기 때문이다. 현대사회가 정보화, 무인화, 자동화, 전산화의 성격이 증가함에 따라 자신과 사업장의 안전과 재산에 대한 안전 [0003]성과 보안성의 문제점에 대한 경고가 지속적으로 대두하고 있다. 따라서 자신과 사업장의 재산과 안전을 보호,관리하기 위한 노력이 계속되고 있으며, 주요 시설물 및 관공서, 학교, 기업, 가정에 이르기까지 보안의 중요성과 범위가 넓어져 가고 있어 영상 감시 시스템의 중요성과 개발의 필요성이 요구되고 있다.특히, 영상 감시 및 보안 시스템인 CCTV 기술, IP 카메라 네트워크 기술이 최근 급속히 발전해 지능화 되어 가 [0004]고 있다. 영상 감시 시스템이 인공 지능을 부여 받아 지능형 시스템으로 거듭나기 위한 방법은 크게 3가지가 있다. 첫 번째는 별도의 서버를 두고 이곳에서 여러 곳의 영상을 수집하고, 상기 수집된 영상을 다양하게 분석하는 기 [0005]능을 소프트웨어 형태로 구현하는 것이다. 두 번째 방법은 CCTV 카메라가 포착한 영상을 저장, 녹화, 재생하는DVR에 움직임 감지 기능 보다 한 단계 진화한 지능형 기능을 추가하는 것이다. 그리고 마지막으로는 카메라 자체 내에 또는 인코더 장비에 칩을 내장하거나 네트워크 연결을 통해 소프트웨어를 구동시키는 방법이 있다. 이 가운데 별도의 서버에 소프트웨어를 구동시켜 여러 가지 지능형 기능을 가능하도록 하는 지능형 영상 감시 [0006]시스템은 컴퓨터 소프트웨어의 발전과 그 궤를 같이 한다. 컴퓨터에 활용되는 각종 소프트웨어가 비디오 영상처리에도 적용되기 시작하면서 영상이 분석, 추적, 분류되기 시작하였다. 이러한 지능형 감시 시스템의 등장은각 카메라로부터 입력되는 영상 데이터를 단순하게 체크하는 정도에서 벗어나 컴퓨터 기술과 영상 처리 소프트웨어를 통해 영상 데이터 내 관심있는 객체의 탐지 및 추적 등을 수행하는 영상 감시 체계를 구축할 수 있음을의미하는 것이기도 하다.이러한 지능형 영상 감시 시스템을 효율적으로 구현하기 위해서는 카메라 영상으로부터 다중 보행자의 안정적 [0007]검출 및 추적, 보행자의 특성 추출, 보행자 특성 기반 영상 검색 기술들이 요구된다. 발명의 내용 해결 하고자하는 과제본 발명은 감시 카메라 영상에 대한 지능화 검색을 지원하기 위한 다중 보행자 감지 및 추적 방법을 제공한다. [0008]또한, 본 발명은 감시 카메라로부터 입력되는 다중 보행자의 특성을 추출하고, 상기 추출된 다중 보행자 특성을 [0009]기반으로 사용자가 원하는 보행자를 검색하기 위한 방법을 제공한다. 과제 해결수단본 발명은 감시 목표 지역을 촬영하는 복수의 감시 카메라와, 상기 복수의 감시 카메라에 의해 촬영된 영상을 [0010]기초로 보행자 특성 정보를 추출하고, 상기 추출된 보행자 특성 정보 중 검색하고자 하는 보행자 특성 정보에매칭되는 보행자 특성 정보가 추출된 영상을 검출하는 영상 처리 서버 및 상기 검색하고자 하는 보행자 특성 정보를 입력하거나 상기 검출된 영상을 영상 검색 화면에 표시하는 사용자 인터페이스 부를 포함하는 지능형 영상검색 시스템을 제공한다.또한, 본 발명은 복수의 감시 카메라로부터 촬영된 영상을 수신하는 과정과, 상기 수신된 영상을 기초로 보행자 [0011]의 특성 정보를 추출하는 과정과, 상기 추출된 보행자 특성 정보 중 사용자로부터 입력된 검색하고자 하는 보행공개특허 10-2011-0035662-6-자 특성 정보에 매칭되는 보행자 특성 정보가 추출된 영상을 검출하는 과정 및 상기 검출된 영상을 영상 검색화면에 표시하는 과정을 포함하는 지능형 영상 검색 방법을 제공한다.또한, 본 발명은 복수의 감시 카메라를 구비하는 지능형 영상 검색 시스템에 있어서, 상기 복수의 감시 카메라 [0012]에 의해 촬영된 영상을 기초로 상기 보행자의 특성 정보를 추출하고, 상기 추출된 보행자 특성 정보 중 검색하고자 하는 보행자 특성 정보에 매칭되는 보행자 특성 정보가 추출된 영상을 검출하는 영상 처리 장치를 포함하는 지능형 영상 검색 시스템을 제공한다. 효 과본 발명은 감시 카메라 영상으로부터 다중 보행자를 안정적으로 검출 및 추적하여 보행자의 특성을 추출할 수 [0013]있다. 또한, 본 발명은 감시 목표 지역에 설치되어 있는 다수의 감시 카메라로부터 실시간 영상을 입력 받아, 온라인 [0014]혹은 오프라인 영상 조회를 원하는 사용자가 검색하고자 하는 보행자 특성 정보를 입력하면 상기 특성 정보에해당하는 보행자를 검출하여 온라인 비디오 영상 혹은 오프라인 대표 프레임 영상에 표시할 수 있다. 발명의 실시를 위한 구체적인 내용하기에서 본 발명을 설명함에 있어 관련된 공지 기능 또는 구성에 대한 구체적인 설명이 본 발명의 요지를 불필 [0015]요하게 흐릴 수 있다고 판단되는 경우에는 그 상세한 설명을 생략할 것이다. 그리고 후술 되는 용어들은 본 발명에서의 기능을 고려하여 정의된 용어들로서 이는 사용자, 운용자의 의도 또는 관례 등에 따라 달라질 수있다. 그러므로 그 정의는 본 명세서 전반에 걸친 내용을 토대로 내려져야 할 것이다.본 발명의 실시 예는 감시 카메라 영상에 대한 지능화 검색을 지원하기 위하여 다중 보행자를 안정적으로 감지 [0016]및 추적하고, 상기 다중 보행자 각각의 특성을 추출하여 보행자 특성에 기반한 영상 검색 기술을 제공한다.구체적으로, 본 발명의 실시 예는 감시 카메라로부터 실시간 입력되는 영상을 기반으로 다중 보행자를 감지하는 [0017]방법, 상기 다중 보행자를 추적하는 방법, 상기 다중 보행자 각각의 특성을 추출하는 방법을 제공함으로써 사용자가 찾고자 하는 보행자를 효율적으로 검색할 수 있다.이하에서는, 본 발명의 바람직한 실시 예에 대해 도면을 참조하여 상세히 설명하도록 한다. [0018]도 1은 본 발명의 바람직한 실시 예에 따른 감시 카메라 영상 기반 지능화 검색 시스템을 도시하고 있다. [0019]도 1을 참조하면, 상기 시스템(100)은 감시 카메라(102), 영상 처리 서버(104), 영상 데이터 저장부(106) 및 사 [0020]용자 인터페이스 부(108)를 포함한다. 상기 영상 처리 서버(104)는 영상 처리 장치(미도시) 내에 구현될 수 있고, 상기 영상 처리 장치는 상기 감시 카메라(102)를 포함할 수 있음은 당업자에게 자명하다. 이하, 본 발명의내용과 관련 없는 상기 시스템(100)의 다른 구성 요소들에 대해서는 생략하도록 한다.상기 감시 카메라(102)는 감시 목표 지역에 설치되어 보행자의 위치 및 움직임 등을 촬영한다. [0021]상기 영상 처리 서버(104)는 상기 감시 카메라(102)로부터 입력되는 실시간 영상을 기반으로 보행자를 감지 및 [0022]추적하고, 보행자의 특성을 추출하는 기능을 수행한다. 또한, 상기 영상 처리 서버(104)는 상기 감시 카메라로부터 입력되는 보행자의 특성 정보와 사용자에 의해 입력된 보행자 특성 정보를 비교함으로써 사용자가 원하는보행자를 검색하는 기능을 수행한다. 한편, 상기 영상 처리 서버(104)는 상기 감시 카메라(102)로부터 실시간영상을 입력 받아 대표 프레임들을 추출하고, 상기 추출된 대표 프레임들을 상기 영상 데이터 저장부(106)에 저장한다. 상기 사용자 인터페이스 부(108)는 온라인 또는 오프라인 영상 조회를 원하는 사용자에 의해 보행자 특성 정보 [0023]가 입력되면, 상기 보행자 특성 정보에 매칭되는 보행자를 온라인 비디오 영상 혹은 오프라인 대표 프레임 영상에 표시하는 영상 검색 창을 제공한다. 상기 영상 검색 창은 실시간 영상 검색 모드와 오프라인 대표 영상 조회모드로 구분될 수 있다. 또한, 상기 영상 검색 창에는 쿼리(query) 입력 창을 구비하고 있어 사용자가 검색하고자 하는 보행자의 특성 정보를 입력할 수 있다.이하에서는 상기 영상 처리 서버(104)의 구성 및 동작에 대해 도면을 참조하여 상세히 설명하도록 한다. [0024]도 2는 본 발명의 바람직한 실시 예에 따른 영상 처리 서버의 구성도를 도시하고 있다. [0025]도 2를 참조하면, 상기 영상 처리 서버(104)는 크게 세 가지의 주요 모듈인 영상 및 쿼리 입력기(202), 보행자 [0026]공개특허 10-2011-0035662-7-추적 및 특성 추출기(204), 특성 매칭 및 결과 출력기(206)를 포함한다.상기 영상 및 쿼리 입력기(202)는 감시 카메라 영상 입력기(208), 정지 영상/메타데이터 입력기(210), 쿼리 입 [0027]력기(212)로 구성될 수 있다.상기 감시 카메라 영상 입력기(208)는 감시 카메라(102)로부터 데이터 스트림 형태의 영상 신호를 수신한 후 상 [0028]기 보행자 추적 및 특성 추출기(204)로 전달하는 기능을 수행한다. 상기 감시 카메라 영상 입력기는 최대 2대의감시 카메라의 영상을 동시에 확인할 수 있고, IP 주소 지정에 따라 임의의 권한이 주어진 감시 카메라로의 접근이 가능하다.상기 정지 영상/메타데이터 입력기(210)는 영상 데이터 저장부(106)로부터 정지 원영상, 배경차감 영상, 각 프 [0029]레임 영상 별 보행자 영역 정보를 읽어 상기 보행자 추적 및 특성 추출기(204)로 제공한다. 상기 쿼리 입력기(212)는 사용자 인터페이스 부(108)로부터 검색하고자 하는 보행자의 특성 정보가 입력되면, [0030]상기 보행자 특성 정보를 상기 특성 매칭 및 결과 출력기(206)로 제공한다. 상기 보행자의 특성 정보는 보행자의 키, 모자 색, 착용하는 의상의 색상 등의 정보가 될 수 있다.상기 보행자 추적 및 특성 추출기(204)는 옵티컬 플로우 분석기(214), 적응적 배경 차감기(216), 보행자 추적기 [0031](218), 대표 프레임 추출기(220), 보행자 특성 추출기(222)로 구성될 수 있다.상기 보행자 추적 및 특성 추출기(204)는 상기 옵티컬 플로우 분석기(214)를 통하여 객체의 움직임 정보를 추출 [0032]하고, 이를 적응적 배경 차감기(216)와 결합하여 보행자의 영역을 안정적으로 추출하는 기능을 수행한다. 또한,조명 조건이 수시로 변화하는 실외 환경에서 배경의 변화를 빠르게 수용한다. 상기 보행자 추적 및 특성 추출기(204)는 배경으로 인식되는 보행자를 빠르게 제거하면서, 일시적으로 움직임이 없는 보행자의 경우에도 안정적으로 영역을 추출하는 기능을 제공한다. 먼저, 상기 옵티컬 플로우 분석기(214)는 상기 감시 카메라 영상 입력기(208)로부터 제공된 영상을 이용하여 객 [0033]체의 움직임 정보(즉, 각 픽셀 별 모션 벡터)를 추출하고, 이를 적응적 메디안 배경 차감기(216)의 입력 정보로제공한다. 여기서, 옵티컬 플로우(optical flow)란 시간적으로 연속된 여러 영상에서 현재 영상과 이전 영상을 비교하여 [0034]밝기로 나타난 화소(pixel)의 이동 방향을 나타내는 벡터를 일컫는다. 객체의 동적 움직임을 나타내는 옵티컬플로우를 통해 시간에 따라 변화하는 영상에서 객체의 움직임 정보가 결정되고, 나아가 배경(background)과 전경(foreground)의 안정적인 구분이 가능하게 된다.상기 옵티컬 플로우를 계산하는 대표적인 방법으로, Gradient 기반의 Lucas-Kanade 방법과 Horn-Schunck 방법이 [0035]있다. 상기 두 가지 방법 모두 렌즈 구경 문제(aperture problem)를 해결하기 위한 방안을 제시하고 있다.첫 번째 방법인 Lucas-Kanade 방법은 가장 널리 이용되고 있는 방법으로서 속도가 빠르고 노이즈에 강하며 간단 [0036]하여 실시간 실행이 필요한 곳에 적합하다. 기본적으로 상기 Lucas-Kanade 방법은 하기 수학식 1의 잘 알려진모션 제약 식에 기반을 둔다.수학식 1, 여기서 I는 (x,y,t)에서 명도(intensity)이며, [0037]는 이미지 속도이다.그러나, 이러한 한계만으로는 옵티컬 플로우의 국소에 한정된 해석에 기인한 렌즈구경문제(aperture problem)로 [0038]인하여 이동 위치추정이 어렵다. 이 때문에 Lucas와 Kanade는 국소 윈도우 내의 옵티컬 플로우 v를 상수로 가정하고, 그 윈도우 내에서 하기 수학식 2와 같이 정의되는 에러 함수 E의 가중 제곱 합(weighted sum-of-squares)을 최소화하는 방법을 제안한다.공개특허 10-2011-0035662-8-수학식 2, 여기서 w는 가중함수이다. [0039]따라서, 상기 옵티컬 플로우 v는 하기 수학식 3과 같이 최소 제곱법으로 구할 수 있다. [0040]수학식 3[0041]두 번째 방법인 Horn-Schunck 방법은 하기 수학식 4로 정의되는 옵티컬 플로우 구속 방정식(optical flow [0042]constraint equation)에 기반을 둔다. 수학식 4, 여기서 , 는 옵티컬 플로우 벡터를 이루는 구 [0043]성 성분으로서 속도 벡터이고, 이다. 상기 수학식 4에서 는 영상으로부터 측정되는 값이며, 이를 이용하여 u와 v를 계산하게 된 [0044]다. 그런데 방정식은 하나이고 구해야 할 미지수는 두 개이므로, 다른 가정이 없는 한, 한 점에서 u, v의 값을결정할 수 없다. 이를 렌즈 구경 문제라고 부른다. Horn과 Schunck는 상기 렌즈 구경 문제를 해결하기 위해 변분법(variation of calculus)에 의해 오차함수(error function)를 최소화시킴으로써 옵티컬 플로우 필드(optical flow field)를 얻는 방법을 제안한다.즉, 상기 옵티컬 플로우 필드(optical flow field)가 평탄하다고 가정하면, 상기 수학식 4는 상기 변분법에 의 [0045]해 해를 계산해 낼 수가 있다. 이를 위하여 속도 필드의 평탄성 정도에 대한 척도(smoothness measure:)와 옵티컬 플로우 구속 방정식 상의 오차()는 각각 하기 수학식 5와 같이 표현된다.공개특허 10-2011-0035662-9-수학식 5[0046]가중 상수(weighting constant) λ를 이용하고, 상기 수학식 5를 종합하여 오차함수 를 표현하면, [0047]이 된다. 그리고, 상기 를 최소화함으로써 u, v를 구하면 하기 수학식 6과 같이 표현된다.수학식 6, 여기서 이다. [0048]상기 옵티컬 플로우 분석기(214)는 전술한 두 가지 방법 중 어느 하나의 방법을 이용하여 객체의 움직임 정보를 [0049]추출할 수 있다. 즉, 상기 옵티컬 플로우 분석기(214)는 각 픽셀 별 모션 벡터의 크기가 일정 임계값 이하의 경우 정지 객체로 판별하여 0 값으로 표시하고, 일정 임계값 이상의 픽셀의 경우에만 255로 표시한 바이너리 영상을 생성한다.적응적 배경 차감기(216)는 배경 학습을 위한 별도의 전처리 과정 없이 배경모델링을 미디언 모델링 기법을 적 [0050]용하여 수행한다. 이때, 상기 옵티컬 플로우 분석기(214)의 출력에 의하여 생성된 모션 바이너리 영상을 읽어,모션 정보가 있는 픽셀의 경우 배경 모델 갱신에서 제외하고 모션 정보가 없는 픽셀의 경우 배경 모델 갱신 과정을 수행하도록 한다. 상기 적응적 배경 차감기(216)는 미디언 배경 모델과 현재 입력된 프레임 영상 간의 차영상(즉, 바이너리 영상)을 생성한다.실외 영상의 경우, 조명이 안정적이지 못하고 배경 또한 나무, 물결, 분수 등 움직임이 많은 것이 특징이다. 또 [0051]한, 배경 모델링을 위하여 보행자나 차량 등 동적 객체가 전혀 없는 배경 프레임을 일정 기간 확보하는 것은 불가능하다. 그러므로, 배경의 정보가 적응적으로 갱신되고, 시간에 따른 조명의 변화에 안정적으로 동적 객체 영역을 추출할 수 있는 방법이 필요하다. 즉, 전술한 옵티컬 플로우 기법과 함께 효율적인 배경 차감 기법이 요구된다. 상기 배경 차감 기법에는 Running Gaussian Average(RGA: Running Gaussian average) 기법, Gaussian Mixture [0052]Model(GMM: Gaussian mixture model) 기법, 변동 개수의 가우시안을 기반으로 한 GMM(GMM with adaptivenumber of Gaussians) 기법, 근사적 메디안 필터링 기반 배경 차감(AMF: Approximated median filtering) 기법등이 있다.이하, 본 발명의 바람직한 실시 예에서는 상기 배경 차감 기법들 중 근사적 메디안 필터링 기반 배경 차감(AMF) [0053]기법을 이용하여 배경을 모델링하는 방법에 대해 설명하도록 한다. 하지만, 상기 배경을 모델링함에 있어서 상기 근사적 메디안 필터링 기반 배경 차감(AMF) 기법이 아닌 다른 배경 차감 기법에 의해 구현될 수 있음은 당업자에게 자명하다.상기 근사적 메디안 필터링 기반 배경 차감(AMF) 기법은 상기 옵티컬 플로우 정보를 배경 갱신을 위한 기반 정 [0054]보로 활용함으로써, 움직임이 없는 배경에 대한 안정적인 갱신뿐 만 아니라, 배경에 포함되어 있던 보행자 영역을 적응적으로 배경 영상에서 제거할 수 있다.즉, 기본 배경 모델링 기법은 잡음에 강한 근사적 메디안 배경 모델링 기법을 이용한다. 그리고 배경 갱신 영역 [0055]공개특허 10-2011-0035662-10-을 선별할 때, 일정 기간의 옵티컬 플로우 영상 정보를 포함하고 있는 모션 히스토리 정보를 조회하여 상기 모션 히스토리 정보가 없는 영역에 대해서만 배경 갱신을 수행한다.예를 들어, 도 3은 어느 한 시점에서의 원 영상(좌) 및 배경 평균 영상(우)을 도시하고 있다. 도 3을 참조하면, [0056]어느 한 시점에서의 배경 평균 영상에는 보행자의 영역이 배경 영상으로 포함되어 있음을 확인할 수 있다.도 4는 시간 별 원 영상(좌), 모션 히스토리 영상(중), 배경 차감 결과 영상(우)을 도시하고 있다. 도 4를 참조 [0057]하면, 본 발명의 실시 예에 따른 옵티컬 플로우 이미지 기반 근사적 메디안 배경 모델링 기법을 적용함으로써배경 차감 결과가 생성됨을 확인할 수 있다. 즉, 초기에 배경 영상에 포함되어 있던 보행자의 영역이 본연의 배경 정보로 갱신되어 시간이 지남에 따라 정확한 보행자 영역이 배경 차감 결과 생성됨을 확인할 수 있다.도 5는 본 발명의 바람직한 실시 예에 따른 배경 갱신 절차를 도시하고 있다. 도 5를 참조하면, 502 단계에서 [0058]상기 옵티컬 플로우 분석기는 원 영상을 기초로 모션 히스토리 영상을 추출한다.504 단계에서, 상기 적응적 배경 차감기는 상기 모션 히스토리 영상을 기초로 배경 갱신을 수행한다. 즉, 상기 [0059]적응적 배경 차감기는 상기 모션 히스토리 정보를 조회하여 상기 모션 히스토리 정보가 없는 영역에 대해서만배경 갱신을 수행한다. 상기 504 단계가 완료되면, 506 단계에서 상기 적응적 배경 차감기는 원 영상과 배경 갱신 영상을 기초로 배경 차영상을 출력한다. 상기 504 단계인 배경 갱신 과정을 반복함으로써, 상기 적응적 배경 차감기는 시간에 따라 변화하는 배경을 적 [0060]응적으로 갱신하여 배경 차영상을 획득할 수 있다.이상, 전술한 상기 옵티컬 플로우 분석기와 상기 적응적 배경 차감기를 이용하여 다중 보행자 영역을 안정적으 [0061]로 감지할 수 있다. 상기 다중 보행자 영역이 감지되면, 보행자의 관심 영역(Region Of Interest, 이하 'ROI'로칭함)을 검출하고, 상기 보행자의 이동을 추적하는 동작을 수행한다.상기 보행자 추적기(218)는 상기 적응적 배경 차감기(216)로부터 생성된 배경 차영상을 입력으로 그리드 기반 [0062]영역 분할을 수행하고, 그리드 패치 별 배경픽셀 대비 전경픽셀 비율을 계산하여 전경영역, 즉 동적 객체 영역에 대한 관심 영역을 추출하는 기능을 수행한다.도 6은 본 발명의 바람직한 실시 예에 따른 보행자 ROI 검출 절차를 도시하고 있다. 도 6을 참조하면, 602 단계 [0063]에서 상기 옵티컬 플로우 분석기는 원 영상을 기초로 모션 히스토리 영상을 추출한다.604 단계에서, 상기 적응적 배경 차감기는 상기 모션 히스토리 영상을 기초로 배경 갱신을 수행한다. 이후, 606 [0064]단계에서 상기 적응적 배경 차감기는 원 영상과 배경 갱신 영상을 이용하여 배경 차감 영상을 출력한다. 608 단계에서, 상기 적응적 배경 차감기는 상기 배경 차감 영상에 잡음 제거를 수행한 후 상기 보행자 추적기로 출력한다.상기 608 단계가 완료되면, 610 단계에서 상기 보행자 추적기는 배경 차영상을 입력으로 그리드 기반 영역 분할 [0065]을 수행한다. 그리고, 612 단계에서 상기 보행자 추적기는 그리드 패치 별 배경픽셀 대비 전경픽셀 비율을 계산하여 전경영역, 즉 동적 객체 영역에 대한 관심 영역을 검출한다. 이후, 614 단계에서 상기 보행자 추적기는 상기 모션 히스토리 영상을 이용하여 전경 ROI를 갱신한다. 이상, 전술한 과정을 통해 감시 카메라로부터 실시간으로 입력되는 영상을 기반으로 다중 보행자 영역을 감지하 [0066]고, 감지된 보행자의 ROI를 검출할 수 있다.한편, 상기 보행자의 ROI를 검출하는 과정에서, 초기 배경 화면에 포함된 동적 객체로서 동적 객체가 움직여져 [0067]서 배경에서 제거되었음에도 불구하고, 배경영상에서 바로 사라지지 않고, 동적 객체 영역으로 표현되는 현상을고스트(Ghost) 현상이라 한다. 이러한 현상을 제거하기 위하여, 전경영역으로 추적된 영역 별로 대응되는 모션영상 영역을 검사하여 모션 픽셀의 비율이 일정 임계값 이하이면 해당 전경영역은 고스트 영역으로 판별하여 동적 객체 후보에서 제외시키는 객체단위 정보정합 처리를 수행한다. 예를 들어, 도 7을 참조하면, 배경차감 영상과 모션 영상을 기반으로 하여 최종 동적 객체 영역을 추출하는 과정을 예제 화면을 통해 확인할 수 있다.보행자의 전경 ROI 검출이 완료되면, 상기 보행자 추적기(218)는 프레임 간 최소거리의 인접 ROI끼리의 매칭을 [0068]통하여 동일 보행자를 추적하는 기능을 수행한다. 즉, 상기 보행자 추적기(218)는 동일 프레임 내에서 ROI의 크기 및 위치에 기반하여 트랙 갱신, 트랙 생성, 트랙 병합 및 트랙 나눔을 수행함으로써 다중 보행자의 영역을추적한다.실루엣이나 영역을 기반으로 다중 보행자를 추적하는 방법은 지능형 감시 시스템에서 있어서 가장 중요한 기술 [0069]공개특허 10-2011-0035662-11-요소로 꼽히고 있다. 추출된 전경 블럽 마다 하나의 트랙을 할당하고, 객체의 이동에 따라 트랙의 생성 및 제거를 수행함으로써, 다수의 보행자 영역을 추적한다. 하나의 객체가 두 개의 이상의 영역으로 분리되어 표현되더라도 전경 블럽의 크기와 거리를 고려하여 일정기간 동안 이들이 같이 움직이는 경우, 하나로 합쳐 하나의 트랙으로 관리한다. 또한, 각 트랙은 움직이는 객체의 색 정보를 가지고 있어 프레임 간 추적 시 색 정보에 의한 확인 과정을 수행할 수 있다.도 8은 본 발명의 바람직한 실시 예에 따른 다중 보행자 영역 감지 및 추적 절차를 도시하고 있다. [0070]도 8을 참조하면, 802 단계 내지 814 단계는 보행자의 전경 ROI를 검출하는 동작을 수행한다. 상기 802 단계 내 [0071]지 814 단계는 전술한 상기 602 단계 내지 614 단계와 동일한 동작을 수행하기 때문에, 이하에서는 상기 동작에대한 구체적인 설명을 생략하도록 한다.상기 802 단계 내지 814 단계를 통하여 상기 보행자의 전경 ROI가 검출되면, 상기 보행자 추적기는 다중 보행자 [0072]를 추적하기 위하여 816 단계 내지 822 단계를 수행한다.즉, 상기 보행자 추적기는 추출된 전경 블럽 마다 하나의 트랙을 할당한다. [0073]상기 할당된 트랙을 가진 전경 블럽이 카메라의 이전 프레임으로부터 일정 범위 안에서 지속적으로 매칭되고, [0074]일정 간격으로 지속적인 이동이 있는 경우, 상기 보행자 추적기는 816 단계로 이동하여 트랙 갱신을 수행한다. 만약, 상기 전경 블럽이 새롭게 생성되는 경우(즉, 새로운 보행자가 나타나는 경우), 상기 보행자 추적기는 818 [0075]단계로 이동하여 새로운 트랙을 생성한다. 한편, 한 카메라 내에서 인식된 2인 이상의 보행자들이 이동하는 경우 일부 보행자가 다른 보행자에 가려 잠시 [0076]사라졌다가 다시 나타나는 경우가 종종 발생한다. 이 때, 서로 다른 보행자가 겹치는 경우, 상기 보행자 추적기는 820 단계로 이동하여 트랙 병합을 수행하고, 상기 서로 다른 보행자가 떨어지는 경우에는 822 단계로 이동하여 트랙 나눔을 수행한다.전술한 과정들을 통해 다중 보행자를 추적하고, 상기 816 단계 내지 822 단계가 완료되면, 824 단계에서 상기 [0077]보행자 추적기는 추적 결과를 이용하여 전경 영역을 갱신한다. 이후, 상기 갱신된 전경 영역은 배경 갱신을 위하여 804 단계로 피드백된다. 이상, 전술한 과정을 통해 감시 카메라로부터 실시간으로 입력되는 영상을 기반으로 다중 보행자를 안정적으로 [0078]감지하고, 상기 감지된 보행자를 추적할 수 있다.상기 대표 프레임 추출기(220)는 상기 보행자 추적기(218)로부터 출력된 영상으로부터 프레임 간 영상의 차이가 [0079]일정 임계값 이상인 상이한 대표 프레임을 선별하여 원영상, 전경 영상, 보행자 영역 정보, 촬영 카메라 번호,촬영 시간등을 추출하고 이를 영상 데이터 저장부(106)에 저장한다. 상기 보행자 특성 추출기(222)는 상기 보행자 추적기(218)로부터 제공된 보행자 ROI와 상기 정지 영상/메타데이 [0080]터 입력기(210)로부터 제공된 정지 영상 및 메타데이터를 이용하여 보행자의 특성을 추출한다. 즉, 상기 보행자특성 추출기(222)는 상기 보행자의 ROI에서 인체 비율에 따라 머리 영역, 상체 영역, 하체 영역으로 구분하고,각 영역 별 색상 특성을 추출한다. 또한, 상기 보행자 특성 추출기(222)는 삼각 측량법을 이용하여 보행자의 신장을 추정하여 보행자 특성 정보로 활용한다.예를 들어, 도 9는 본 발명의 바람직한 실시 예에 따라 동일 보행자 ROI를 세부 영역으로 구분하는 배경차감 영 [0081]상(좌) 및 원 영상(우)을 도시하고 있다. 도 9를 참조하면, 보행자에 대한 개별 영역(ROI)이 추출되면 ROI의 높이를 기준으로 보행자의 머리 영역, 상체 [0082]영역, 하체 영역을 구분한다. 보행자의 머리 영역의 특성으로는 상기 ROI의 전체 높이를 h라 하였을 때, 상위h/6 에 해당하는 부분의 중앙 원형에 속하는 부분의 색상을 분석한다. 상체 영역의 특성으로는 상위 h/6영역에서 하위 h/2 위치의 영역에서 전경픽셀의 색상을 분석한다. 하위영역의 특성으로는 하위 h/2 영역에서 전경픽셀에 해당하는 색상을 분석한다. 상기 특성 매칭 및 결과 출력기(206)는 보행자 특성 매칭기(224)와 조회 결과 출력기(226)로 구성될 수 있다. [0083]상기 보행자 특성 매칭기(224)는 상기 쿼리 입력기(212)를 통해 입력된 보행자의 특성 정보와 상기 보행자 특성 [0084]추출기(222)로부터 추출된 보행자 특성 정보를 비교하여 유사 특성의 보행자를 추출한다. 즉, 상기 보행자 특성매칭기(224)는 상기 보행자 특성 추출기(222)로부터 추출된 보행자 특성 정보 중 검색하고자 하는 보행자의 특공개특허 10-2011-0035662-12-성 정보에 매칭되는 보행자 특성 정보가 포함된 영상을 검출한다. 상기 조회 결과 출력기(226)는 상기 보행자 특성 정보에 대한 매칭 결과 검출된 영상을 상기 사용자 인터페이스 [0085]부(108)로 제공하는 기능을 수행한다.상기 사용자 인터페이스 부(108)는 상기 검출된 영상을 영상 검색 창에 출력하고, 상기 영상 검색 창에 사용자 [0086]가 검색하고자 하는 보행자를 표시한다. 즉, 온라인 동영상의 경우에는 해당 보행자에 주석(annotation)을 표시하고, 오프라인 정지 영상의 경우에는 해당 영상에 보행자 주석(annotation)과 함께 촬영 카메라 정보, 촬영 시간 등을 함께 표시한다.예를 들어, 도 10은 본 발명의 바람직한 실시 예에 따른 영상 검색 화면을 도시하고 있다. 도 10의 (a)는 실시 [0087]간 영상 검색 화면의 구성을 나타내고, 도 10의 (b)는 대표 프레임 검색 화면의 구성을 나타낸다.도 10을 참조하면, 사용자가 영상 검색 화면 상의 쿼리 입력 창을 통해 검색하고자 하는 보행자의 키, 상의 색, [0088]하의 색, 모자색등의 정보를 입력하면, 상기 사용자 인터페이스 부(108)는 해당하는 보행자를 검색하여 상기 실시간 영상 검색 화면이나 대표 프레임 검색 화면에 표시한다.이상, 전술한 감시 카메라 영상 기반 지능화 검색 시스템의 동작을 통하여, 사용자는 감시 목표 지역에 설치되 [0089]어 있는 다수의 감시 카메라로부터 실시간 입력되는 영상으로부터 검색하고자 하는 보행자를 온라인 비디오 영상 혹은 오프라인 대표 프레임 영상에서 효율적으로 검색할 수 있다.도 11은 본 발명의 바람직한 실시 예에 따른 감시 카메라를 이용한 지능형 영상 검색 과정을 도시하고 있다. [0090]도 11을 참조하면, 1102 단계에서 다수의 감시 카메라는 감시 목표 지역에 설치되어 촬영된 영상을 데이터 스트 [0091]림 형태로 감시 카메라 영상 입력기로 제공한다. 상기 감시 카메라 영상 입력기는 상기 감시 카메라에 의해 촬영된 영상을 보행자 추적 및 특성 추출기로 제공한다. 1104 단계에서, 상기 보행자 추적 및 특성 추출기는 옵티컬 플로우 분석기를 통해 객체의 움직임 정보를 추출하 [0092]고, 이를 적응적 배경 차감기와 결합하여 보행자의 영역을 감지한다. 이후, 1106 단계에서 상기 보행자 추적 및특성 추출기는 감지된 보행자의 ROI를 검출하고, 상기 보행자의 이동을 추적한다. 상기 1106 단계가 완료되면, 1108 단계에서 상기 보행자 추적 및 특성 추출기는 보행자 추적기로부터 제공된 보 [0093]행자 ROI와 정지 영상/메타데이터 입력기로부터 제공된 정지 영상 및 메타데이터를 이용하여 보행자의 특성을추출한다.1110 단계에서, 사용자 인터페이스 부를 통해 검색하고자 하는 보행자의 특성 정보가 입력하는지 여부를 확인한 [0094]다. 만약, 사용자에 의한 검색 요청이 없는 경우 상기 영상 검색 과정은 종료한다.한편, 사용자에 의한 검색 요청이 존재하는 경우, 1112 단계로 이동한다. 상기 1112단계에서, 특성 매칭 및 결 [0095]과 출력기는 쿼리 입력기를 통하여 입력된 보행자 특성 정보와 상기 보행자 추적 및 특성 추출기를 통해 추출된보행자 특성 정보를 비교하여, 유사 특성의 보행자를 추출한다. 즉, 상기 보행자 특성 매칭기(224)는 상기 보행자 특성 추출기(222)로부터 추출된 보행자 특성 정보 중 검색하고자 하는 보행자의 특성 정보에 매칭되는 보행자 특성 정보가 포함된 영상을 검출한다.상기 1112 단계가 완료되면, 1114 단계에서 상기 특성 매칭 및 결과 출력기는 상기 검출된 영상을 상기 사용자 [0096]인터페이스 부로 제공한다. 상기 사용자 인터페이스 부(108)는 상기 검출된 영상을 영상 검색 창에 출력하고,상기 영상 검색 창에 사용자가 검색하고자 하는 보행자를 표시한다.이상, 전술한 감시 카메라 영상 기반 지능화 검색 방법을 통하여, 사용자는 감시 목표 지역에 설치되어 있는 다 [0097]수의 감시 카메라로부터 실시간 입력되는 영상으로부터 검색하고자 하는 보행자를 온라인 비디오 영상 혹은 오프라인 대표 프레임 영상에서 효율적으로 검색할 수 있다.이상에서는 본 발명의 구체적인 실시 예에 관해 설명하였으나, 본 발명의 범위에서 벗어나지 않는 한도 내에서 [0098]여러 가지 변형이 가능함은 물론이다. 그러므로 본 발명의 범위는 설명된 실시 예에 국한되지 않으며, 후술 되는 특허청구범위뿐만 아니라 이 특허청구범위와 균등한 것들에 의해 정해져야 한다.도면의 간단한 설명도 1은 본 발명의 바람직한 실시 예에 따른 감시 카메라 영상 기반 지능화 검색 시스템의 구성도; [0099]공개특허 10-2011-0035662-13-도 2는 본 발명의 바람직한 실시 예에 따른 영상 처리 서버의 구성도; [0100]도 3은 특정한 시점에서의 원 영상(좌) 및 배경 평균 영상(우)을 도시한 도면; [0101]도 4는 시간 별 원 영상(좌), 모션 히스토리 영상(중), 배경 차감 결과 영상(우)을 도시한 도면; [0102]도 5는 본 발명의 바람직한 실시 예에 따른 배경 갱신 절차의 흐름도; [0103]도 6은 본 발명의 바람직한 실시 예에 따른 보행자 ROI 검출 절차의 흐름도; [0104]도 7은 배경차감 영상과 모션 영상을 기반으로 하여 최종 동적 객체 영역을 추출하는 절차를 도시한 도면; [0105]도 8은 본 발명의 바람직한 실시 예에 따른 다중 보행자 영역 감지 및 추적 절차의 흐름도; [0106]도 9는 동일 보행자 ROI를 세부 영역으로 구분하는 배경차감 영상(좌) 및 원 영상(우)을 도시한 도면; [0107]도 10은 본 발명의 바람직한 실시 예에 따른 영상 검색 화면의 구성도; [0108]도 11은 본 발명의 바람직한 실시 예에 따른 감시 카메라를 이용한 지능형 영상 검색 과정의 흐름도. [0109]도면 도면1공개특허 10-2011-0035662-14- 도면2 도면3공개특허 10-2011-0035662-15- 도면4 도면5공개특허 10-2011-0035662-16- 도면6 도면7공개특허 10-2011-0035662-17- 도면8 도면9공개특허 10-2011-0035662-18- 도면10a 도면10b공개특허 10-2011-0035662-19- 도면11공개특허 10-2011-0035662-20-"}
{"patent_id": "10-2009-0093473", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 감시 카메라 영상에 대한 지능화 검색을 지원하기 위하여 다중 보행자를 안정적으로 감지 및 추적하고, 상기 다중 보행자 각각의 특성을 추출하여 보행자 특성에 기반한 영상 검색 기술을 제공한다. 또한, 본 발명은 감시 목표 지역에 설치되어 있는 다수의 감시 카메라로부터 실시간 영상을 입력 받아, 온라인 혹은 오 프라인 영상 조회를 원하는 사용자가 검색하고자 하는 보행자 특성 정보를 입력하면 상기 특성 정보에 해당하는 보행자를 검출하여 온라인 비디오 영상 혹은 오프라인 대표 프레임 영상에 표시할 수 있다."}
{"patent_id": "10-2009-0093473", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 영상 검색 시스템 및 그 방법에 관한 것으로, 보다 구체적으로는 감시 카메라를 이용한 지능형 영상 검색 시스템 및 그 방법에 관한 것이다."}
{"patent_id": "10-2009-0093473", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "어떤 특정 행위나 사건이 일어나는 것을 감지하는 영상 감시 시스템은 사람 추적을 이용한 연구 분야 중에서도 가장 중요하게 인식되고 있다. 그 이유는 사회가 발전할수록 공공 장소뿐 아니라 개인 공간에서도 개인 및 시설 물의 안전에 대한 중요성이 높이 인식되고 있기 때문이다. 현대사회가 정보화, 무인화, 자동화, 전산화의 성격이 증가함에 따라 자신과 사업장의 안전과 재산에 대한 안전 성과 보안성의 문제점에 대한 경고가 지속적으로 대두하고 있다. 따라서 자신과 사업장의 재산과 안전을 보호, 관리하기 위한 노력이 계속되고 있으며, 주요 시설물 및 관공서, 학교, 기업, 가정에 이르기까지 보안의 중요성 과 범위가 넓어져 가고 있어 영상 감시 시스템의 중요성과 개발의 필요성이 요구되고 있다. 특히, 영상 감시 및 보안 시스템인 CCTV 기술, IP 카메라 네트워크 기술이 최근 급속히 발전해 지능화 되어 가 고 있다. 영상 감시 시스템이 인공 지능을 부여 받아 지능형 시스템으로 거듭나기 위한 방법은 크게 3가지가 있 다. 첫 번째는 별도의 서버를 두고 이곳에서 여러 곳의 영상을 수집하고, 상기 수집된 영상을 다양하게 분석하는 기 능을 소프트웨어 형태로 구현하는 것이다. 두 번째 방법은 CCTV 카메라가 포착한 영상을 저장, 녹화, 재생하는 DVR에 움직임 감지 기능 보다 한 단계 진화한 지능형 기능을 추가하는 것이다. 그리고 마지막으로는 카메라 자 체 내에 또는 인코더 장비에 칩을 내장하거나 네트워크 연결을 통해 소프트웨어를 구동시키는 방법이 있다. 이 가운데 별도의 서버에 소프트웨어를 구동시켜 여러 가지 지능형 기능을 가능하도록 하는 지능형 영상 감시 시스템은 컴퓨터 소프트웨어의 발전과 그 궤를 같이 한다. 컴퓨터에 활용되는 각종 소프트웨어가 비디오 영상 처리에도 적용되기 시작하면서 영상이 분석, 추적, 분류되기 시작하였다. 이러한 지능형 감시 시스템의 등장은 각 카메라로부터 입력되는 영상 데이터를 단순하게 체크하는 정도에서 벗어나 컴퓨터 기술과 영상 처리 소프트 웨어를 통해 영상 데이터 내 관심있는 객체의 탐지 및 추적 등을 수행하는 영상 감시 체계를 구축할 수 있음을 의미하는 것이기도 하다. 이러한 지능형 영상 감시 시스템을 효율적으로 구현하기 위해서는 카메라 영상으로부터 다중 보행자의 안정적 검출 및 추적, 보행자의 특성 추출, 보행자 특성 기반 영상 검색 기술들이 요구된다."}
{"patent_id": "10-2009-0093473", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 2, "content": "발명의 내용 해결 하고자하는 과제 본 발명은 감시 카메라 영상에 대한 지능화 검색을 지원하기 위한 다중 보행자 감지 및 추적 방법을 제공한다. 또한, 본 발명은 감시 카메라로부터 입력되는 다중 보행자의 특성을 추출하고, 상기 추출된 다중 보행자 특성을 기반으로 사용자가 원하는 보행자를 검색하기 위한 방법을 제공한다. 과제 해결수단 본 발명은 감시 목표 지역을 촬영하는 복수의 감시 카메라와, 상기 복수의 감시 카메라에 의해 촬영된 영상을 기초로 보행자 특성 정보를 추출하고, 상기 추출된 보행자 특성 정보 중 검색하고자 하는 보행자 특성 정보에 매칭되는 보행자 특성 정보가 추출된 영상을 검출하는 영상 처리 서버 및 상기 검색하고자 하는 보행자 특성 정 보를 입력하거나 상기 검출된 영상을 영상 검색 화면에 표시하는 사용자 인터페이스 부를 포함하는 지능형 영상 검색 시스템을 제공한다. 또한, 본 발명은 복수의 감시 카메라로부터 촬영된 영상을 수신하는 과정과, 상기 수신된 영상을 기초로 보행자 의 특성 정보를 추출하는 과정과, 상기 추출된 보행자 특성 정보 중 사용자로부터 입력된 검색하고자 하는 보행자 특성 정보에 매칭되는 보행자 특성 정보가 추출된 영상을 검출하는 과정 및 상기 검출된 영상을 영상 검색 화면에 표시하는 과정을 포함하는 지능형 영상 검색 방법을 제공한다. 또한, 본 발명은 복수의 감시 카메라를 구비하는 지능형 영상 검색 시스템에 있어서, 상기 복수의 감시 카메라 에 의해 촬영된 영상을 기초로 상기 보행자의 특성 정보를 추출하고, 상기 추출된 보행자 특성 정보 중 검색하 고자 하는 보행자 특성 정보에 매칭되는 보행자 특성 정보가 추출된 영상을 검출하는 영상 처리 장치를 포함하 는 지능형 영상 검색 시스템을 제공한다. 효 과 본 발명은 감시 카메라 영상으로부터 다중 보행자를 안정적으로 검출 및 추적하여 보행자의 특성을 추출할 수 있다. 또한, 본 발명은 감시 목표 지역에 설치되어 있는 다수의 감시 카메라로부터 실시간 영상을 입력 받아, 온라인 혹은 오프라인 영상 조회를 원하는 사용자가 검색하고자 하는 보행자 특성 정보를 입력하면 상기 특성 정보에 해당하는 보행자를 검출하여 온라인 비디오 영상 혹은 오프라인 대표 프레임 영상에 표시할 수 있다. 발명의 실시를 위한 구체적인 내용 하기에서 본 발명을 설명함에 있어 관련된 공지 기능 또는 구성에 대한 구체적인 설명이 본 발명의 요지를 불필 요하게 흐릴 수 있다고 판단되는 경우에는 그 상세한 설명을 생략할 것이다. 그리고 후술 되는 용어들은 본 발 명에서의 기능을 고려하여 정의된 용어들로서 이는 사용자, 운용자의 의도 또는 관례 등에 따라 달라질 수 있다. 그러므로 그 정의는 본 명세서 전반에 걸친 내용을 토대로 내려져야 할 것이다. 본 발명의 실시 예는 감시 카메라 영상에 대한 지능화 검색을 지원하기 위하여 다중 보행자를 안정적으로 감지 및 추적하고, 상기 다중 보행자 각각의 특성을 추출하여 보행자 특성에 기반한 영상 검색 기술을 제공한다. 구체적으로, 본 발명의 실시 예는 감시 카메라로부터 실시간 입력되는 영상을 기반으로 다중 보행자를 감지하는 방법, 상기 다중 보행자를 추적하는 방법, 상기 다중 보행자 각각의 특성을 추출하는 방법을 제공함으로써 사용 자가 찾고자 하는 보행자를 효율적으로 검색할 수 있다. 이하에서는, 본 발명의 바람직한 실시 예에 대해 도면을 참조하여 상세히 설명하도록 한다. 도 1은 본 발명의 바람직한 실시 예에 따른 감시 카메라 영상 기반 지능화 검색 시스템을 도시하고 있다. 도 1을 참조하면, 상기 시스템은 감시 카메라, 영상 처리 서버, 영상 데이터 저장부 및 사 용자 인터페이스 부를 포함한다. 상기 영상 처리 서버는 영상 처리 장치(미도시) 내에 구현될 수 있 고, 상기 영상 처리 장치는 상기 감시 카메라를 포함할 수 있음은 당업자에게 자명하다. 이하, 본 발명의 내용과 관련 없는 상기 시스템의 다른 구성 요소들에 대해서는 생략하도록 한다. 상기 감시 카메라는 감시 목표 지역에 설치되어 보행자의 위치 및 움직임 등을 촬영한다. 상기 영상 처리 서버는 상기 감시 카메라로부터 입력되는 실시간 영상을 기반으로 보행자를 감지 및 추적하고, 보행자의 특성을 추출하는 기능을 수행한다. 또한, 상기 영상 처리 서버는 상기 감시 카메라로 부터 입력되는 보행자의 특성 정보와 사용자에 의해 입력된 보행자 특성 정보를 비교함으로써 사용자가 원하는 보행자를 검색하는 기능을 수행한다. 한편, 상기 영상 처리 서버는 상기 감시 카메라로부터 실시간 영상을 입력 받아 대표 프레임들을 추출하고, 상기 추출된 대표 프레임들을 상기 영상 데이터 저장부에 저 장한다. 상기 사용자 인터페이스 부는 온라인 또는 오프라인 영상 조회를 원하는 사용자에 의해 보행자 특성 정보 가 입력되면, 상기 보행자 특성 정보에 매칭되는 보행자를 온라인 비디오 영상 혹은 오프라인 대표 프레임 영상 에 표시하는 영상 검색 창을 제공한다. 상기 영상 검색 창은 실시간 영상 검색 모드와 오프라인 대표 영상 조회 모드로 구분될 수 있다. 또한, 상기 영상 검색 창에는 쿼리(query) 입력 창을 구비하고 있어 사용자가 검색하고 자 하는 보행자의 특성 정보를 입력할 수 있다. 이하에서는 상기 영상 처리 서버의 구성 및 동작에 대해 도면을 참조하여 상세히 설명하도록 한다. 도 2는 본 발명의 바람직한 실시 예에 따른 영상 처리 서버의 구성도를 도시하고 있다. 도 2를 참조하면, 상기 영상 처리 서버는 크게 세 가지의 주요 모듈인 영상 및 쿼리 입력기, 보행자 추적 및 특성 추출기, 특성 매칭 및 결과 출력기를 포함한다. 상기 영상 및 쿼리 입력기는 감시 카메라 영상 입력기, 정지 영상/메타데이터 입력기, 쿼리 입 력기로 구성될 수 있다. 상기 감시 카메라 영상 입력기는 감시 카메라로부터 데이터 스트림 형태의 영상 신호를 수신한 후 상 기 보행자 추적 및 특성 추출기로 전달하는 기능을 수행한다. 상기 감시 카메라 영상 입력기는 최대 2대의 감시 카메라의 영상을 동시에 확인할 수 있고, IP 주소 지정에 따라 임의의 권한이 주어진 감시 카메라로의 접 근이 가능하다. 상기 정지 영상/메타데이터 입력기는 영상 데이터 저장부로부터 정지 원영상, 배경차감 영상, 각 프 레임 영상 별 보행자 영역 정보를 읽어 상기 보행자 추적 및 특성 추출기로 제공한다. 상기 쿼리 입력기는 사용자 인터페이스 부로부터 검색하고자 하는 보행자의 특성 정보가 입력되면, 상기 보행자 특성 정보를 상기 특성 매칭 및 결과 출력기로 제공한다. 상기 보행자의 특성 정보는 보행자 의 키, 모자 색, 착용하는 의상의 색상 등의 정보가 될 수 있다. 상기 보행자 추적 및 특성 추출기는 옵티컬 플로우 분석기, 적응적 배경 차감기, 보행자 추적기 , 대표 프레임 추출기, 보행자 특성 추출기로 구성될 수 있다. 상기 보행자 추적 및 특성 추출기는 상기 옵티컬 플로우 분석기를 통하여 객체의 움직임 정보를 추출 하고, 이를 적응적 배경 차감기와 결합하여 보행자의 영역을 안정적으로 추출하는 기능을 수행한다. 또한, 조명 조건이 수시로 변화하는 실외 환경에서 배경의 변화를 빠르게 수용한다. 상기 보행자 추적 및 특성 추출기 는 배경으로 인식되는 보행자를 빠르게 제거하면서, 일시적으로 움직임이 없는 보행자의 경우에도 안정적 으로 영역을 추출하는 기능을 제공한다. 먼저, 상기 옵티컬 플로우 분석기는 상기 감시 카메라 영상 입력기로부터 제공된 영상을 이용하여 객 체의 움직임 정보(즉, 각 픽셀 별 모션 벡터)를 추출하고, 이를 적응적 메디안 배경 차감기의 입력 정보로 제공한다. 여기서, 옵티컬 플로우(optical flow)란 시간적으로 연속된 여러 영상에서 현재 영상과 이전 영상을 비교하여 밝기로 나타난 화소(pixel)의 이동 방향을 나타내는 벡터를 일컫는다. 객체의 동적 움직임을 나타내는 옵티컬 플로우를 통해 시간에 따라 변화하는 영상에서 객체의 움직임 정보가 결정되고, 나아가 배경(background)과 전 경(foreground)의 안정적인 구분이 가능하게 된다. 상기 옵티컬 플로우를 계산하는 대표적인 방법으로, Gradient 기반의 Lucas-Kanade 방법과 Horn-Schunck 방법이 있다. 상기 두 가지 방법 모두 렌즈 구경 문제(aperture problem)를 해결하기 위한 방안을 제시하고 있다. 첫 번째 방법인 Lucas-Kanade 방법은 가장 널리 이용되고 있는 방법으로서 속도가 빠르고 노이즈에 강하며 간단 하여 실시간 실행이 필요한 곳에 적합하다. 기본적으로 상기 Lucas-Kanade 방법은 하기 수학식 1의 잘 알려진 모션 제약 식에 기반을 둔다. 수학식 1 , 여기서 I는 (x,y,t)에서 명도(intensity)이며, 는 이미지 속도이다. 그러나, 이러한 한계만으로는 옵티컬 플로우의 국소에 한정된 해석에 기인한 렌즈구경문제(aperture problem)로 인하여 이동 위치추정이 어렵다. 이 때문에 Lucas와 Kanade는 국소 윈도우 내의 옵티컬 플로우 v를 상수로 가정 하고, 그 윈도우 내에서 하기 수학식 2와 같이 정의되는 에러 함수 E의 가중 제곱 합(weighted sum-of- squares)을 최소화하는 방법을 제안한다.수학식 2 , 여기서 w는 가중함수이다. 따라서, 상기 옵티컬 플로우 v는 하기 수학식 3과 같이 최소 제곱법으로 구할 수 있다. 수학식 3"}
{"patent_id": "10-2009-0093473", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 3, "content": "두 번째 방법인 Horn-Schunck 방법은 하기 수학식 4로 정의되는 옵티컬 플로우 구속 방정식(optical flow constraint equation)에 기반을 둔다. 수학식 4 , 여기서 , 는 옵티컬 플로우 벡터를 이루는 구 성 성분으로서 속도 벡터이고, 이다. 상기 수학식 4에서 는 영상으로부터 측정되는 값이며, 이를 이용하여 u와 v를 계산하게 된 다. 그런데 방정식은 하나이고 구해야 할 미지수는 두 개이므로, 다른 가정이 없는 한, 한 점에서 u, v의 값을 결정할 수 없다. 이를 렌즈 구경 문제라고 부른다. Horn과 Schunck는 상기 렌즈 구경 문제를 해결하기 위해 변 분법(variation of calculus)에 의해 오차함수(error function)를 최소화시킴으로써 옵티컬 플로우 필드 (optical flow field)를 얻는 방법을 제안한다. 즉, 상기 옵티컬 플로우 필드(optical flow field)가 평탄하다고 가정하면, 상기 수학식 4는 상기 변분법에 의 해 해를 계산해 낼 수가 있다. 이를 위하여 속도 필드의 평탄성 정도에 대한 척도(smoothness measure: ) 와 옵티컬 플로우 구속 방정식 상의 오차( )는 각각 하기 수학식 5와 같이 표현된다.수학식 5"}
{"patent_id": "10-2009-0093473", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 4, "content": "가중 상수(weighting constant) λ를 이용하고, 상기 수학식 5를 종합하여 오차함수 를 표현하면, 이 된다. 그리고, 상기 를 최소화함으로써 u, v를 구하면 하기 수학식 6과 같 이 표현된다. 수학식 6 , 여기서 이다. 상기 옵티컬 플로우 분석기는 전술한 두 가지 방법 중 어느 하나의 방법을 이용하여 객체의 움직임 정보를 추출할 수 있다. 즉, 상기 옵티컬 플로우 분석기는 각 픽셀 별 모션 벡터의 크기가 일정 임계값 이하의 경 우 정지 객체로 판별하여 0 값으로 표시하고, 일정 임계값 이상의 픽셀의 경우에만 255로 표시한 바이너리 영상 을 생성한다. 적응적 배경 차감기는 배경 학습을 위한 별도의 전처리 과정 없이 배경모델링을 미디언 모델링 기법을 적 용하여 수행한다. 이때, 상기 옵티컬 플로우 분석기의 출력에 의하여 생성된 모션 바이너리 영상을 읽어, 모션 정보가 있는 픽셀의 경우 배경 모델 갱신에서 제외하고 모션 정보가 없는 픽셀의 경우 배경 모델 갱신 과 정을 수행하도록 한다. 상기 적응적 배경 차감기는 미디언 배경 모델과 현재 입력된 프레임 영상 간의 차 영상(즉, 바이너리 영상)을 생성한다. 실외 영상의 경우, 조명이 안정적이지 못하고 배경 또한 나무, 물결, 분수 등 움직임이 많은 것이 특징이다. 또 한, 배경 모델링을 위하여 보행자나 차량 등 동적 객체가 전혀 없는 배경 프레임을 일정 기간 확보하는 것은 불 가능하다. 그러므로, 배경의 정보가 적응적으로 갱신되고, 시간에 따른 조명의 변화에 안정적으로 동적 객체 영 역을 추출할 수 있는 방법이 필요하다. 즉, 전술한 옵티컬 플로우 기법과 함께 효율적인 배경 차감 기법이 요구 된다. 상기 배경 차감 기법에는 Running Gaussian Average(RGA: Running Gaussian average) 기법, Gaussian Mixture Model(GMM: Gaussian mixture model) 기법, 변동 개수의 가우시안을 기반으로 한 GMM(GMM with adaptive number of Gaussians) 기법, 근사적 메디안 필터링 기반 배경 차감(AMF: Approximated median filtering) 기법 등이 있다. 이하, 본 발명의 바람직한 실시 예에서는 상기 배경 차감 기법들 중 근사적 메디안 필터링 기반 배경 차감(AMF) 기법을 이용하여 배경을 모델링하는 방법에 대해 설명하도록 한다. 하지만, 상기 배경을 모델링함에 있어서 상 기 근사적 메디안 필터링 기반 배경 차감(AMF) 기법이 아닌 다른 배경 차감 기법에 의해 구현될 수 있음은 당업 자에게 자명하다. 상기 근사적 메디안 필터링 기반 배경 차감(AMF) 기법은 상기 옵티컬 플로우 정보를 배경 갱신을 위한 기반 정 보로 활용함으로써, 움직임이 없는 배경에 대한 안정적인 갱신뿐 만 아니라, 배경에 포함되어 있던 보행자 영역 을 적응적으로 배경 영상에서 제거할 수 있다. 즉, 기본 배경 모델링 기법은 잡음에 강한 근사적 메디안 배경 모델링 기법을 이용한다. 그리고 배경 갱신 영역 을 선별할 때, 일정 기간의 옵티컬 플로우 영상 정보를 포함하고 있는 모션 히스토리 정보를 조회하여 상기 모 션 히스토리 정보가 없는 영역에 대해서만 배경 갱신을 수행한다. 예를 들어, 도 3은 어느 한 시점에서의 원 영상(좌) 및 배경 평균 영상(우)을 도시하고 있다. 도 3을 참조하면, 어느 한 시점에서의 배경 평균 영상에는 보행자의 영역이 배경 영상으로 포함되어 있음을 확인할 수 있다. 도 4는 시간 별 원 영상(좌), 모션 히스토리 영상(중), 배경 차감 결과 영상(우)을 도시하고 있다. 도 4를 참조 하면, 본 발명의 실시 예에 따른 옵티컬 플로우 이미지 기반 근사적 메디안 배경 모델링 기법을 적용함으로써 배경 차감 결과가 생성됨을 확인할 수 있다. 즉, 초기에 배경 영상에 포함되어 있던 보행자의 영역이 본연의 배 경 정보로 갱신되어 시간이 지남에 따라 정확한 보행자 영역이 배경 차감 결과 생성됨을 확인할 수 있다. 도 5는 본 발명의 바람직한 실시 예에 따른 배경 갱신 절차를 도시하고 있다. 도 5를 참조하면, 502 단계에서 상기 옵티컬 플로우 분석기는 원 영상을 기초로 모션 히스토리 영상을 추출한다. 504 단계에서, 상기 적응적 배경 차감기는 상기 모션 히스토리 영상을 기초로 배경 갱신을 수행한다. 즉, 상기 적응적 배경 차감기는 상기 모션 히스토리 정보를 조회하여 상기 모션 히스토리 정보가 없는 영역에 대해서만 배경 갱신을 수행한다. 상기 504 단계가 완료되면, 506 단계에서 상기 적응적 배경 차감기는 원 영상과 배경 갱 신 영상을 기초로 배경 차영상을 출력한다. 상기 504 단계인 배경 갱신 과정을 반복함으로써, 상기 적응적 배경 차감기는 시간에 따라 변화하는 배경을 적 응적으로 갱신하여 배경 차영상을 획득할 수 있다. 이상, 전술한 상기 옵티컬 플로우 분석기와 상기 적응적 배경 차감기를 이용하여 다중 보행자 영역을 안정적으 로 감지할 수 있다. 상기 다중 보행자 영역이 감지되면, 보행자의 관심 영역(Region Of Interest, 이하 'ROI'로 칭함)을 검출하고, 상기 보행자의 이동을 추적하는 동작을 수행한다. 상기 보행자 추적기는 상기 적응적 배경 차감기로부터 생성된 배경 차영상을 입력으로 그리드 기반 영역 분할을 수행하고, 그리드 패치 별 배경픽셀 대비 전경픽셀 비율을 계산하여 전경영역, 즉 동적 객체 영역 에 대한 관심 영역을 추출하는 기능을 수행한다. 도 6은 본 발명의 바람직한 실시 예에 따른 보행자 ROI 검출 절차를 도시하고 있다. 도 6을 참조하면, 602 단계 에서 상기 옵티컬 플로우 분석기는 원 영상을 기초로 모션 히스토리 영상을 추출한다. 604 단계에서, 상기 적응적 배경 차감기는 상기 모션 히스토리 영상을 기초로 배경 갱신을 수행한다. 이후, 606 단계에서 상기 적응적 배경 차감기는 원 영상과 배경 갱신 영상을 이용하여 배경 차감 영상을 출력한다. 608 단 계에서, 상기 적응적 배경 차감기는 상기 배경 차감 영상에 잡음 제거를 수행한 후 상기 보행자 추적기로 출력 한다. 상기 608 단계가 완료되면, 610 단계에서 상기 보행자 추적기는 배경 차영상을 입력으로 그리드 기반 영역 분할 을 수행한다. 그리고, 612 단계에서 상기 보행자 추적기는 그리드 패치 별 배경픽셀 대비 전경픽셀 비율을 계산 하여 전경영역, 즉 동적 객체 영역에 대한 관심 영역을 검출한다. 이후, 614 단계에서 상기 보행자 추적기는 상 기 모션 히스토리 영상을 이용하여 전경 ROI를 갱신한다. 이상, 전술한 과정을 통해 감시 카메라로부터 실시간으로 입력되는 영상을 기반으로 다중 보행자 영역을 감지하 고, 감지된 보행자의 ROI를 검출할 수 있다. 한편, 상기 보행자의 ROI를 검출하는 과정에서, 초기 배경 화면에 포함된 동적 객체로서 동적 객체가 움직여져 서 배경에서 제거되었음에도 불구하고, 배경영상에서 바로 사라지지 않고, 동적 객체 영역으로 표현되는 현상을 고스트(Ghost) 현상이라 한다. 이러한 현상을 제거하기 위하여, 전경영역으로 추적된 영역 별로 대응되는 모션 영상 영역을 검사하여 모션 픽셀의 비율이 일정 임계값 이하이면 해당 전경영역은 고스트 영역으로 판별하여 동 적 객체 후보에서 제외시키는 객체단위 정보정합 처리를 수행한다. 예를 들어, 도 7을 참조하면, 배경차감 영상 과 모션 영상을 기반으로 하여 최종 동적 객체 영역을 추출하는 과정을 예제 화면을 통해 확인할 수 있다. 보행자의 전경 ROI 검출이 완료되면, 상기 보행자 추적기는 프레임 간 최소거리의 인접 ROI끼리의 매칭을 통하여 동일 보행자를 추적하는 기능을 수행한다. 즉, 상기 보행자 추적기는 동일 프레임 내에서 ROI의 크 기 및 위치에 기반하여 트랙 갱신, 트랙 생성, 트랙 병합 및 트랙 나눔을 수행함으로써 다중 보행자의 영역을 추적한다. 실루엣이나 영역을 기반으로 다중 보행자를 추적하는 방법은 지능형 감시 시스템에서 있어서 가장 중요한 기술 요소로 꼽히고 있다. 추출된 전경 블럽 마다 하나의 트랙을 할당하고, 객체의 이동에 따라 트랙의 생성 및 제거 를 수행함으로써, 다수의 보행자 영역을 추적한다. 하나의 객체가 두 개의 이상의 영역으로 분리되어 표현되더 라도 전경 블럽의 크기와 거리를 고려하여 일정기간 동안 이들이 같이 움직이는 경우, 하나로 합쳐 하나의 트랙 으로 관리한다. 또한, 각 트랙은 움직이는 객체의 색 정보를 가지고 있어 프레임 간 추적 시 색 정보에 의한 확 인 과정을 수행할 수 있다. 도 8은 본 발명의 바람직한 실시 예에 따른 다중 보행자 영역 감지 및 추적 절차를 도시하고 있다. 도 8을 참조하면, 802 단계 내지 814 단계는 보행자의 전경 ROI를 검출하는 동작을 수행한다. 상기 802 단계 내 지 814 단계는 전술한 상기 602 단계 내지 614 단계와 동일한 동작을 수행하기 때문에, 이하에서는 상기 동작에 대한 구체적인 설명을 생략하도록 한다. 상기 802 단계 내지 814 단계를 통하여 상기 보행자의 전경 ROI가 검출되면, 상기 보행자 추적기는 다중 보행자 를 추적하기 위하여 816 단계 내지 822 단계를 수행한다. 즉, 상기 보행자 추적기는 추출된 전경 블럽 마다 하나의 트랙을 할당한다. 상기 할당된 트랙을 가진 전경 블럽이 카메라의 이전 프레임으로부터 일정 범위 안에서 지속적으로 매칭되고, 일정 간격으로 지속적인 이동이 있는 경우, 상기 보행자 추적기는 816 단계로 이동하여 트랙 갱신을 수행한다. 만약, 상기 전경 블럽이 새롭게 생성되는 경우(즉, 새로운 보행자가 나타나는 경우), 상기 보행자 추적기는 818 단계로 이동하여 새로운 트랙을 생성한다. 한편, 한 카메라 내에서 인식된 2인 이상의 보행자들이 이동하는 경우 일부 보행자가 다른 보행자에 가려 잠시 사라졌다가 다시 나타나는 경우가 종종 발생한다. 이 때, 서로 다른 보행자가 겹치는 경우, 상기 보행자 추적기 는 820 단계로 이동하여 트랙 병합을 수행하고, 상기 서로 다른 보행자가 떨어지는 경우에는 822 단계로 이동하 여 트랙 나눔을 수행한다. 전술한 과정들을 통해 다중 보행자를 추적하고, 상기 816 단계 내지 822 단계가 완료되면, 824 단계에서 상기 보행자 추적기는 추적 결과를 이용하여 전경 영역을 갱신한다. 이후, 상기 갱신된 전경 영역은 배경 갱신을 위 하여 804 단계로 피드백된다. 이상, 전술한 과정을 통해 감시 카메라로부터 실시간으로 입력되는 영상을 기반으로 다중 보행자를 안정적으로 감지하고, 상기 감지된 보행자를 추적할 수 있다. 상기 대표 프레임 추출기는 상기 보행자 추적기로부터 출력된 영상으로부터 프레임 간 영상의 차이가 일정 임계값 이상인 상이한 대표 프레임을 선별하여 원영상, 전경 영상, 보행자 영역 정보, 촬영 카메라 번호, 촬영 시간등을 추출하고 이를 영상 데이터 저장부에 저장한다. 상기 보행자 특성 추출기는 상기 보행자 추적기로부터 제공된 보행자 ROI와 상기 정지 영상/메타데이 터 입력기로부터 제공된 정지 영상 및 메타데이터를 이용하여 보행자의 특성을 추출한다. 즉, 상기 보행자 특성 추출기는 상기 보행자의 ROI에서 인체 비율에 따라 머리 영역, 상체 영역, 하체 영역으로 구분하고, 각 영역 별 색상 특성을 추출한다. 또한, 상기 보행자 특성 추출기는 삼각 측량법을 이용하여 보행자의 신 장을 추정하여 보행자 특성 정보로 활용한다. 예를 들어, 도 9는 본 발명의 바람직한 실시 예에 따라 동일 보행자 ROI를 세부 영역으로 구분하는 배경차감 영 상(좌) 및 원 영상(우)을 도시하고 있다. 도 9를 참조하면, 보행자에 대한 개별 영역(ROI)이 추출되면 ROI의 높이를 기준으로 보행자의 머리 영역, 상체 영역, 하체 영역을 구분한다. 보행자의 머리 영역의 특성으로는 상기 ROI의 전체 높이를 h라 하였을 때, 상위 h/6 에 해당하는 부분의 중앙 원형에 속하는 부분의 색상을 분석한다. 상체 영역의 특성으로는 상위 h/6영역에 서 하위 h/2 위치의 영역에서 전경픽셀의 색상을 분석한다. 하위영역의 특성으로는 하위 h/2 영역에서 전경픽셀 에 해당하는 색상을 분석한다. 상기 특성 매칭 및 결과 출력기는 보행자 특성 매칭기와 조회 결과 출력기로 구성될 수 있다. 상기 보행자 특성 매칭기는 상기 쿼리 입력기를 통해 입력된 보행자의 특성 정보와 상기 보행자 특성 추출기로부터 추출된 보행자 특성 정보를 비교하여 유사 특성의 보행자를 추출한다. 즉, 상기 보행자 특성 매칭기는 상기 보행자 특성 추출기로부터 추출된 보행자 특성 정보 중 검색하고자 하는 보행자의 특성 정보에 매칭되는 보행자 특성 정보가 포함된 영상을 검출한다. 상기 조회 결과 출력기는 상기 보행자 특성 정보에 대한 매칭 결과 검출된 영상을 상기 사용자 인터페이스 부로 제공하는 기능을 수행한다. 상기 사용자 인터페이스 부는 상기 검출된 영상을 영상 검색 창에 출력하고, 상기 영상 검색 창에 사용자 가 검색하고자 하는 보행자를 표시한다. 즉, 온라인 동영상의 경우에는 해당 보행자에 주석(annotation)을 표시 하고, 오프라인 정지 영상의 경우에는 해당 영상에 보행자 주석(annotation)과 함께 촬영 카메라 정보, 촬영 시 간 등을 함께 표시한다. 예를 들어, 도 10은 본 발명의 바람직한 실시 예에 따른 영상 검색 화면을 도시하고 있다. 도 10의 (a)는 실시 간 영상 검색 화면의 구성을 나타내고, 도 10의 (b)는 대표 프레임 검색 화면의 구성을 나타낸다. 도 10을 참조하면, 사용자가 영상 검색 화면 상의 쿼리 입력 창을 통해 검색하고자 하는 보행자의 키, 상의 색, 하의 색, 모자색등의 정보를 입력하면, 상기 사용자 인터페이스 부는 해당하는 보행자를 검색하여 상기 실 시간 영상 검색 화면이나 대표 프레임 검색 화면에 표시한다. 이상, 전술한 감시 카메라 영상 기반 지능화 검색 시스템의 동작을 통하여, 사용자는 감시 목표 지역에 설치되 어 있는 다수의 감시 카메라로부터 실시간 입력되는 영상으로부터 검색하고자 하는 보행자를 온라인 비디오 영 상 혹은 오프라인 대표 프레임 영상에서 효율적으로 검색할 수 있다. 도 11은 본 발명의 바람직한 실시 예에 따른 감시 카메라를 이용한 지능형 영상 검색 과정을 도시하고 있다. 도 11을 참조하면, 1102 단계에서 다수의 감시 카메라는 감시 목표 지역에 설치되어 촬영된 영상을 데이터 스트 림 형태로 감시 카메라 영상 입력기로 제공한다. 상기 감시 카메라 영상 입력기는 상기 감시 카메라에 의해 촬 영된 영상을 보행자 추적 및 특성 추출기로 제공한다. 1104 단계에서, 상기 보행자 추적 및 특성 추출기는 옵티컬 플로우 분석기를 통해 객체의 움직임 정보를 추출하 고, 이를 적응적 배경 차감기와 결합하여 보행자의 영역을 감지한다. 이후, 1106 단계에서 상기 보행자 추적 및 특성 추출기는 감지된 보행자의 ROI를 검출하고, 상기 보행자의 이동을 추적한다. 상기 1106 단계가 완료되면, 1108 단계에서 상기 보행자 추적 및 특성 추출기는 보행자 추적기로부터 제공된 보 행자 ROI와 정지 영상/메타데이터 입력기로부터 제공된 정지 영상 및 메타데이터를 이용하여 보행자의 특성을 추출한다. 1110 단계에서, 사용자 인터페이스 부를 통해 검색하고자 하는 보행자의 특성 정보가 입력하는지 여부를 확인한 다. 만약, 사용자에 의한 검색 요청이 없는 경우 상기 영상 검색 과정은 종료한다. 한편, 사용자에 의한 검색 요청이 존재하는 경우, 1112 단계로 이동한다. 상기 1112단계에서, 특성 매칭 및 결 과 출력기는 쿼리 입력기를 통하여 입력된 보행자 특성 정보와 상기 보행자 추적 및 특성 추출기를 통해 추출된 보행자 특성 정보를 비교하여, 유사 특성의 보행자를 추출한다. 즉, 상기 보행자 특성 매칭기는 상기 보행 자 특성 추출기로부터 추출된 보행자 특성 정보 중 검색하고자 하는 보행자의 특성 정보에 매칭되는 보행 자 특성 정보가 포함된 영상을 검출한다. 상기 1112 단계가 완료되면, 1114 단계에서 상기 특성 매칭 및 결과 출력기는 상기 검출된 영상을 상기 사용자 인터페이스 부로 제공한다. 상기 사용자 인터페이스 부는 상기 검출된 영상을 영상 검색 창에 출력하고, 상기 영상 검색 창에 사용자가 검색하고자 하는 보행자를 표시한다. 이상, 전술한 감시 카메라 영상 기반 지능화 검색 방법을 통하여, 사용자는 감시 목표 지역에 설치되어 있는 다 수의 감시 카메라로부터 실시간 입력되는 영상으로부터 검색하고자 하는 보행자를 온라인 비디오 영상 혹은 오 프라인 대표 프레임 영상에서 효율적으로 검색할 수 있다. 이상에서는 본 발명의 구체적인 실시 예에 관해 설명하였으나, 본 발명의 범위에서 벗어나지 않는 한도 내에서 여러 가지 변형이 가능함은 물론이다. 그러므로 본 발명의 범위는 설명된 실시 예에 국한되지 않으며, 후술 되 는 특허청구범위뿐만 아니라 이 특허청구범위와 균등한 것들에 의해 정해져야 한다."}
