{"patent_id": "10-2019-0136911", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2021-0051524", "출원번호": "10-2019-0136911", "발명의 명칭": "음성 합성 시스템 및 이의 방법", "출원인": "주식회사 솔트룩스", "발명자": "김성만"}}
{"patent_id": "10-2019-0136911", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "사용자로부터 영문을 포함하는 텍스트를 수신하는 단계;상기 영문에 대응하는 발음기호 및 이에 대응하는 특성을 생성하는 단계;상기 특성을 기반으로 상기 발음기호를 보정하는 단계;상기 발음기호로부터 한글 음성을 합성하는 단계; 및상기 한글 음성을 출력하는 단계를 포함하는 음성 합성 방법."}
{"patent_id": "10-2019-0136911", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,복수의 데이터베이스들로부터 복수의 영문-한글발음 쌍들을 수신하는 단계;복수의 국가들의 발음기호 정보들을 포함하는 글로벌 발음기호 데이터베이스를 이용하여 상기 영문-한글발음 쌍들로부터 영문에 대응하는 발음기호 및 발음기호의 특성을 학습하는 단계; 및상기 학습 결과를 기반으로 발음기호 생성 인공지능 모델을 생성하는 단계를 더 포함하는 것을 특징으로 하는음성 합성 방법."}
{"patent_id": "10-2019-0136911", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,상기 발음 기호 및 이에 대응하는 특성을 생성하는 단계 및 상기 발음기호를 보정하는 단계는, 상기 발음기호생성 인공지능 모델을 기반으로 수행되는 것을 특징으로 하는 음성 합성 방법."}
{"patent_id": "10-2019-0136911", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서,상기 발음기호 및 이에 대응하는 특성을 생성하는 단계에서,상기 특성은 상기 발음기호가 상기 발음기호에 대응하는 대표 발음기호와 유사도가 임계치 이상임을 나타내는제1 특성, 상기 발음기호가 한글 구어체에 해당하는 것을 나타내는 제2 특성 및 상기 발음기호가 보정될 필요가없음을 나타내는 제3 특성을 포함하는 것을 특징으로 하는 음성 합성 방법."}
{"patent_id": "10-2019-0136911", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서,상기 특성을 기반으로 상기 발음기호를 보정하는 단계는,상기 발음기호가 상기 제1 특성을 갖는 경우에, 상기 발음기호를 상기 대표 발음기호로 보정하는 단계;상기 발음기호가 상기 제2 특성을 갖는 경우에, 상기 발음기호에서 악센트(accent) 및 장음/단음을 보정하는 단계; 및상기 발음기호가 상기 제3 특성을 갖는 경우에, 별도의 보정을 수행하지 않는 단계를 더 포함하는 것을 특징으로 하는 음성 합성 방법."}
{"patent_id": "10-2019-0136911", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5항에 있어서,공개특허 10-2021-0051524-3-상기 발음기호로부터 한글 음성을 합성하는 단계는,상기 발음기호에 대응하는 국가를 기반으로 복수의 음성 타입들 중 어느 하나를 선택하는 단계; 및상기 선택된 음성 타입으로 상기 한글 음성을 합성하는 단계를 더 포함하는 것을 특징으로 하는 음성 합성방법."}
{"patent_id": "10-2019-0136911", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6항에 있어서,상기 사용자로부터 상기 출력된 한글 음성에 대한 피드백을 수신하는 단계; 및상기 피드백을 이용하여 상기 발음기호 생성 인공지능 모델에 대한 증강 학습을 수행하는 단계를 더 포함하는것을 특징으로 하는 음성 합성 방법."}
{"patent_id": "10-2019-0136911", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "사용자로부터 영문을 포함하는 텍스트를 수신하여 발음기호 생성 인공지능 모델을 기반으로 상기 영문에 대응하는 발음기호 및 이에 대응하는 특성을 생성하는 발음기호 생성부;상기 발음기호 생성 인공지능 모델 및 상기 특성을 기반으로 상기 발음기호를 보정하고, 한글로 변환하는 발음기호 변환부;상기 변환된 한글을 음성으로 합성하는 음성 합성부; 및상기 음성을 외부로 출력하는 음성 출력부를 포함하는 음성 합성 시스템."}
{"patent_id": "10-2019-0136911", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서,복수의 데이터베이스들로부터 복수의 영문-한글발음 쌍들 및 글로벌 발음기호 데이터베이스를 이용해 상기 영문-한글발음 쌍들로부터 영문에 대응하는 발음기호 및 발음 기호의 특성을 학습하여 상기 발음기호 생성 인공지능모델을 생성하는 모델 학습부를 더 포함하는 것을 특징으로 하는 음성 합성 시스템."}
{"patent_id": "10-2019-0136911", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9항에 있어서,상기 특성은, 상기 발음기호가 상기 발음기호에 대응하는 대표 발음기호와 유사도가 임계치 이상임을 나타내는제1 특성, 상기 발음기호가 한글 구어체에 해당하는 것을 나타내는 제2 특성 및 상기 발음기호가 보정될 필요가없음을 나타내는 제3 특성을 포함하는 것을 특징으로 하는 음성 합성 시스템."}
{"patent_id": "10-2019-0136911", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제10항에 있어서,상기 발음기호 변환부는, 상기 발음기호가 상기 제1 특성을 갖는 경우에, 상기 발음기호를 상기 대표 발음기호로 보정하고, 상기 발음기호가 상기 제2 특성을 갖는 경우에, 상기 발음기호에서 악센트 및 장음/단음을 보정하며, 상기 발음기호가 상기 제3 특성을 갖는 경우에, 별도의 보정을 수행하지 않는 것을 특징으로 하는 음성 합성 시스템."}
{"patent_id": "10-2019-0136911", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 개시에 예시적 실시 예에 따른 음성 합성 방법은 사용자로부터 영문을 포함하는 텍스트를 수신하는 단계, 상 기 영문에 대응하는 발음기호 및 이에 대응하는 특성을 생성하는 단계, 상기 특성을 기반으로 상기 발음기호를 보정하는 단계, 상기 발음기호로부터 한글 음성을 합성하는 단계 및 상기 한글 음성을 출력하는 단계를 포함한다."}
{"patent_id": "10-2019-0136911", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명의 기술적 사상은 음성 합성 시스템에 관한 것으로 구체적으로는, 영문을 포함하는 텍스트를 수신하였을 때에, 한글로 음성을 합성하여 출력하기 위한 음성 합성 시스템 및 이의 방법에 관한 것이다. 본 발명은 과학기술정보통신부의 국가연구개발사업의 일환으로 서울대학교 산업협력단이 주관하고 솔트룩스에서 연구하여 수행된 연구로부터 도출된 것이다. [연구기간: 2018.08.01~2020.12.31, 연구관리 전문기관: 한국연구재단, 연구과제명: 성범죄 피해자 진술 지원 인공지능 시스템 연구, 과제 고유번호: 2018M3E2A1081615]"}
{"patent_id": "10-2019-0136911", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "음성(speech)은 인간의 기초적이고 효과적인 의사를 전달할 수 있는 도구 중 하나이다. 음성 합성 시스템은 사 용자에게 객관적이고 편리한 서비스를 제공하고, 일부는 음성을 사용하여 상호 작용할 수 있는 음성 사용자 인 터페이스를 사용하고 있다. 종래의 음성 사용자 인터페이스에서 음성 응답을 구현하는 간단한 방법은 오디오 녹 음이지만, 녹음된 음성만이 이용될 수 있다는 한계가 있었다. 이러한 음성 합성 시스템은 녹음되지 않은 음성에 대해서는 음성 서비스를 제공할 수 없기 때문에, 유연성이 떨어졌다. 이 때문에, 많은 연구자들이 자연스럽고 빠른 음성 합성 모델을 만들려고 노력하고 있다. 또한, 텍스트로부터 음성을 생성할 수 있는 TTS(text-to- speech)라고도 하는 텍스트-음성 합성이 널리 연구되고 있다. 일반적으로, TTS 기술은 Concatenative TTS, Parametric TTS 등 다양한 음성 합성 방법이 있다. 예를 들어, Concatenative TTS는 음성을 음소 등 아주 짧은 단위로 미리 잘라서 저장해두고, 합성할 문장을 구성하는 음성 들을 결합하여 음성을 합성할 수 있으며, Parametric TTS는 음성의 특징을 parameter로 표현하고 합성할 문장을 구성하는 음성 특징들을 나타내는 parameter들을 보코더(vocoder)를 이용하여 문장에 대응하는 음성으로 합성할 수 있다."}
{"patent_id": "10-2019-0136911", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명의 기술적 사상이 해결하려는 과제는 영문을 포함하는 텍스트를 수신하였을 때, 영문을 최대한 적절하게 발음할 수 있는 한글로 변환하여 음성 합성을 수행하는 음성 합성 시스템 및 이의 방법을 제공함에 있다."}
{"patent_id": "10-2019-0136911", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 개시에 예시적 실시 예에 따른 음성 합성 방법은 사용자로부터 영문을 포함하는 텍스트를 수신하는 단계, 상 기 영문에 대응하는 발음기호 및 이에 대응하는 특성을 생성하는 단계, 상기 특성을 기반으로 상기 발음기호를 보정하는 단계, 상기 발음기호로부터 한글 음성을 합성하는 단계 및 상기 한글 음성을 출력하는 단계를 포함한 다. 다른 실시 예에 있어서, 음성 합성 방법은, 복수의 데이터베이스들로부터 복수의 영문-한글발음 쌍들을 수신하 는 단계, 복수의 국가들의 발음기호 정보들을 포함하는 글로벌 발음기호 데이터베이스를 이용하여 상기 영문-한 글발음 쌍들로부터 영문에 대응하는 발음기호 및 발음기호의 특성을 학습하는 단계 및 상기 학습 결과를 기반으 로 발음기호 생성 인공지능 모델을 생성하는 단계를 더 포함하는 것을 특징으로 한다. 다른 실시 예에 있어서, 음성 합성 방법은, 상기 발음 기호 및 이에 대응하는 특성을 생성하는 단계 및 상기 발 음기호를 보정하는 단계는, 상기 발음기호 생성 인공지능 모델을 기반으로 수행되는 것을 특징으로 한다. 다른 실시 예에 있어서, 상기 발음기호 및 이에 대응하는 특성을 생성하는 단계에서, 상기 특성은 상기 발음기 호가 상기 발음기호에 대응하는 대표 발음기호와 유사도가 임계치 이상임을 나타내는 제1 특성, 상기 발음기호 가 한글 구어체에 해당하는 것을 나타내는 제2 특성 및 상기 발음기호가 보정될 필요가 없음을 나타내는 제3 특 성을 포함하는 것을 특징으로 한다. 다른 실시 예에 있어서, 상기 특성을 기반으로 상기 발음기호를 보정하는 단계는, 상기 발음기호가 상기 제1 특 성을 갖는 경우에, 상기 발음기호를 상기 대표 발음기호로 보정하는 단계, 상기 발음기호가 상기 제2 특성을 갖 는 경우에, 상기 발음기호에서 악센트(accent) 및 장음/단음을 보정하는 단계 및 상기 발음기호가 상기 제3 특 성을 갖는 경우에, 별도의 보정을 수행하지 않는 단계를 더 포함하는 것을 특징으로 한다. 다른 실시 예에 있어서, 상기 발음기호로부터 한글 음성을 합성하는 단계는, 상기 발음기호에 대응하는 국가를 기반으로 복수의 음성 타입들 중 어느 하나를 선택하는 단계 및 상기 선택된 음성 타입으로 상기 한글 음성을 합성하는 단계를 더 포함하는 것을 특징으로 한다. 다른 실시 예에 있어서, 상기 사용자로부터 상기 출력된 한글 음성에 대한 피드백을 수신하는 단계 및 상기 피 드백을 이용하여 상기 발음기호 생성 인공지능 모델에 대한 증강 학습을 수행하는 단계를 더 포함하는 것을 특 징으로 한다.본 개시의 예시적 실시 예에 따른 음성 합성 시스템은, 사용자로부터 영문을 포함하는 텍스트를 수신하여 발음 기호 생성 인공지능 모델을 기반으로 상기 영문에 대응하는 발음기호 및 이에 대응하는 특성을 생성하는 발음기 호 생성부, 상기 발음기호 생성 인공지능 모델 및 상기 특성을 기반으로 상기 발음기호를 보정하고, 한글로 변 환하는 발음기호 변환부, 상기 변환된 한글을 음성으로 합성하는 음성 합성부 및 상기 음성을 외부로 출력하는 음성 출력부를 포함한다. 다른 실시 예에 있어서, 복수의 데이터베이스들로부터 복수의 영문-한글발음 쌍들 및 글로벌 발음기호 데이터베 이스를 이용해 상기 영문-한글발음 쌍들로부터 영문에 대응하는 발음기호 및 발음 기호의 특성을 학습하여 상기 발음기호 생성 인공지능 모델을 생성하는 모델 학습부를 더 포함하는 것을 특징으로 한다. 다른 실시 예에 있어서, 상기 특성은, 상기 발음기호가 상기 발음기호에 대응하는 대표 발음기호와 유사도가 임 계치 이상임을 나타내는 제1 특성, 상기 발음기호가 한글 구어체에 해당하는 것을 나타내는 제2 특성 및 상기 발음기호가 보정될 필요가 없음을 나타내는 제3 특성을 포함하는 것을 특징으로 한다. 다른 실시 예에 있어서, 상기 발음기호 변환부는, 상기 발음기호가 상기 제1 특성을 갖는 경우에, 상기 발음기 호를 상기 대표 발음기호로 보정하고, 상기 발음기호가 상기 제2 특성을 갖는 경우에, 상기 발음기호에서 악센 트 및 장음/단음을 보정하며, 상기 발음기호가 상기 제3 특성을 갖는 경우에, 별도의 보정을 수행하지 않는 것 을 특징으로 한다."}
{"patent_id": "10-2019-0136911", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 개시의 예시적 실시 예에 따른 음성 합성 시스템 또는 음성 합성 방법은 인공지능 모델을 기반으로 영문으로 부터 발음기호 및 특성을 생성하고, 특성에 따라 발음기호를 적절하게 보정한 후, 발음기호를 한글발음으로 변 환함으로써 정확한 한글 음성 출력을 할 수 있다. 또한, 음성 합성 시스템 또는 음성 합성 방법은 불명확한 영 문 입력에도 안정적인 음성 합성 서비스를 제공할 수 있다. 본 개시의 예시적 실시 예들에서 얻을 수 있는 효과는 이상에서 언급한 효과들로 제한되지 아니하며, 언급되지"}
{"patent_id": "10-2019-0136911", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 2, "content": "아니한 다른 효과들은 이하의 기재로부터 본 개시의 예시적 실시예들이 속하는 기술분야에서 통상의 지식을 가 진 자에게 명확하게 도출되고 이해될 수 있다. 즉, 본 개시의 예시적 실시예들을 실시함에 따른 의도하지 아니"}
{"patent_id": "10-2019-0136911", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 3, "content": "한 효과들 역시 본 개시의 예시적 실시예들로부터 당해 기술분야의 통상의 지식을 가진 자에 의해 도출될 수 있 다."}
{"patent_id": "10-2019-0136911", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 첨부한 도면을 참조하여 본 발명의 실시예에 대해 상세히 설명한다. 본 발명의 실시예는 당 업계에서 평 균적인 지식을 가진 자에게 본 발명을 보다 완전하게 설명하기 위하여 제공되는 것이다. 본 발명은 다양한 변경 을 가할 수 있고 여러 가지 형태를 가질 수 있는 바, 특정 실시예들을 도면에 예시하고 상세하게 설명하고자 한 다. 그러나, 이는 본 발명을 특정한 개시 형태에 대해 한정하려는 것이 아니며, 본 발명의 사상 및 기술 범위에 포함되는 모든 변경, 균등물 내지 대체물을 포함하는 것으로 이해되어야 한다. 각 도면을 설명하면서 유사한 참조부호를 유사한 구성요소에 대해 사용한다. 첨부된 도면에 있어서, 구조물들의 치수는 본 발명의 명확성을 기 하기 위하여 실제보다 확대하거나 축소하여 도시한 것이다. 본 출원에서 사용한 용어는 단지 특정한 실시예를 설명하기 위해 사용된 것으로, 본 발명을 한정하려는 의도가 아니다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 출원에서, \"포함 하다\" 또는 \"가지다\" 등의 용어는 명세서 상에 기재된 특징, 숫자, 단계, 동작, 구성요소, 부분품 또는 이들을 조합한 것이 존재함을 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성 요소, 부분품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되어야 한다. 또한, 제1, 제2 등의 용어는 다양한 구성요소들을 설명하는데 사용될 수 있지만, 상기 구성요소들은 상기 용어 들에 의해 한정되어서는 안 된다. 상기 용어들은 하나의 구성요소를 다른 구성요소로부터 구별하는 목적으로 사 용될 수 있다. 예를 들어, 본 발명의 권리 범위로부터 벗어나지 않으면서, 제1 구성요소는 제2 구성요소로 명명 될 수 있고, 유사하게 제2 구성요소도 제1 구성요소로 명명될 수 있다. 다르게 정의되지 않는 한, 기술적이거나 과학적인 용어를 포함해서 여기서 사용되는 모든 용어들은 본 발명이 속하는 기술 분야에서 통상의 지식을 가진 자에 의해 일반적으로 이해되는 것과 동일한 의미를 갖는다. 일반적 으로 사용되는 사전에 정의되어 있는 것과 같은 용어들은 관련 기술의 문맥상 가지는 의미와 일치하는 의미를 가지는 것으로 해석되어야 하며, 본 출원에서 명백하게 정의하지 않는 한, 이상적이거나 과도하게 형식적인 의 미로 해석되지 않는다. 도 1은 본 개시의 예시적 실시 예에 따른 음성 합성 시스템을 나타내는 블록도이다. 이하에서 서술되는 음 성 합성 시스템은 유저 단말, 휴대폰, 스마트 폰, 데스크 탑, 노트북 컴퓨터, 디지털 방송용 단말기, PDA(Personal Digital Assistants), PMP(Portable Multimedia Player), 네비게이션, 슬레이트 PC(slate PC), 태블릿 PC(tablet PC), 울트라북(ultrabook), 웨어러블 디바이스(wearable device), 서버 등에 적용될 수 있다. 도 1을 참조하면, 음성 합성 시스템은 발음기호 생성부, 발음기호 변환부, 모델 학습부, 음성 합성부, 음성 데이터베이스, 음성 출력부 및 후처리 프로세서를 포함할 수 있다. 음성 합성 시스템은 외부로부터 영문이 포함된 텍스트를 수신할 수 있다. 발음기호 생성부는 영문에 대응하는 발음기호 및 이에 대응하는 특성을 생성할 수 있다. 예를 들어, 'techlash' 라는 영문을 수신한 때에, 발음기호 생성부는 이에 대한 발음기호인 'tekwlζsi' 라는 발음기호와 함께, 이러한 발음기호의 특성을 생성할 수 있다. 이러한 특성은 발음기호를 보정할 때에 참고되는 인덱스로서 발음기호가 보정될 때에 참고될 수 있다. 발음기호 변환부는 발음기호 생성부로부터 출력된 발음기호 및 이의 특성을 기반으로 발음기호를 보 정하고, 보정된 발음기호를 한글발음으로 변환할 수 있다. 예를 들어, 발음기호인 'tekwlζsi'를 '테크래시'로 변환할 수 있다. 모델 학습부는 복수의 데이터베이스들로부터 복수의 영문-한글발음 쌍들을 수신하여, 이를 이용해서 영문 각각으로부터 발음기호, 특성을 생성하는 동작을 소정의 인공지능 알고리즘을 기반으로 반복적으로 수행함으로 써 발음기호 생성 인공지능 모델을 생성(또는, 구축)할 수 있다. 일부 실시 예들에 있어서, 모델 학습부는 오토인코더(auto encoder), RNN(Recurrent Neural Network), CNN(Convoltional Neural Network) 등과 같은 인 공 신경망을 이용할 수 있다. 발음기호 생성부 및 발음기호 변환부는 모델 학습부의 발음기호 생성 인공지능 모델을 기반으로 영문으로부터 발음기호를 생성, 보정, 한글발음으로의 변환을 수행할 수 있다. 음성 합성부는 발음기호 변환부로부터 출력된 한글발음에 음성을 합성할 수 있다. 음성 합성부 는 음성 데이터베이스에 저장된 음성 데이터들을 이용하여 한글발음에 적합한 음성을 합성할 수 있다. 음 성 출력부는 음성 합성부에 의해 합성된 한글 음성을 외부로 출력할 수 있다. 음성 출력부는 한 글 음성을 출력할 수 있는 구성을 포함할 수 있으며, 일부 실시 예들에서 음성 출력부는 스피커 장치를 포 함할 수 있다. 후처리 프로세서는 음성 출력부가 한글 음성을 출력하기 전에 노이즈 필터링 등을 수 행하여 출력의 품질을 향상시킬 수 있다. 본 개시의 예시적 실시 예에 따른 음성 합성 시스템은 인공지능 모델을 기반으로 영문으로부터 발음기호 및 특성을 생성하고, 특성에 따라 발음기호를 적절하게 보정한 후, 발음기호를 한글발음으로 변환함으로써 정확한 한글 음성 출력을 할 수 있다. 또한, 음성 합성 시스템은 불명확한 영문 입력에도 안정적인 음성 합성 서비스를 제공할 수 있다. 도 2는 본 개시의 예시적 실시 예에 따른 도 1의 모델 학습부를 설명하기 위한 도면이다. 도 2를 참조하면, 모델 학습부는 복수의 데이터베이스들(DB_1~DB_n)로부터 복수의 영문-한글발음 쌍들을 수신할 수 있다. 데이터베이스들(DB_1~DB_n)은 인터넷, 클라우드 소싱 및 소셜 네트워크 등 데이터가 생성되고 보유되며 유통될 수 있는 것을 나타낼 수 있다. 데이터베이스들(DB_1~DB_n)은 서로 다른 비정형 데이터, 반정형 데이터 및 정형 데이터를 포함할 수 있다. 비정형 데이터는 고정된 형태로 구현되지 아니하는 데이터로, 대응되 는 필드(field)에 대응되는 콘텐츠(contents)가 포함되는 정형 데이터(formal data 또는 structured data)와 대비된다. 예를 들어, 데이터 베이스(database) 또는 스프레드시트(spreadsheet) 등은 정형 데이터이고, 텍스트 문서, 음성 데이터 및 영상 데이터 등은 비정형 데이터일 수 있다. 고정된 필드에 저장되지는 않지만, 메타데이 터(metadata)나 스키마(schema) 등을 포함하는 데이터로, XML이나 HTML은 반정형 데이터로 분류될 수는 있으나, 본 발명은 반정형 데이터를 비정형 데이터의 일 유형으로 전제될 수 있음을 알려둔다. 도 2에서 모델 학습부는 데이터베이스들(DB_1~DB_n)로부터 정제된 영문-한글발음 쌍들을 직접 수신하는 것으로 도시되어 있으나, 이에 국한되지 않고, 모델 학습부는 데이터베이스들(DB_1~DB_n)로부터 정제되지 않 은 데이터들을 수신하여 이를 영문-한글발음 쌍들로 정제할 수 있다. 도 1의 음성 합성 시스템은 글로벌 발음기호 데이터베이스를 더 포함할 수 있으며, 모델 학습부(13 0)는 글로벌 발음기호 데이터베이스로부터 복수의 국가들의 발음기호 정보들을 이용하여 영문-한글발음 쌍 들로부터 영문에 대응하는 발음기호 및 발음기호의 특성을 학습할 수 있다. 모델 학습부는 학습 결과를 기 반으로 발음기호 생성 인공지능 모델을 생성할 수 있다. 이와 같은 방식으로, 모델 학습부로부터 생성된 발음기호 생성 인공지능 모델은 사용자로부터 입력된 소정의 영문이 어느 국가의 언어의 음성으로 출력되기를 원하는지를 추론하고, 추론 결과를 기반으로 영문으로부터 해당 국가의 발음기호를 생성할 수 있다. 예를 들어, 'gootentak'이라는 영문을 수신한 때에, 'gootentak'은 독일어임을 추론하여 'Guten Tag'에 대응하는 독일어의 발음기호를 생성할 수 있다. 도 3은 본 개시의 예시적 실시 예에 따른 발음기호 생성부 및 발음기호 변환부의 동작을 설명하기 위 한 도면이다. 도 3을 참조하면, 발음기호 생성부는 영문을 수신하여 발음기호 생성 인공지능 모델을 기반으로 발음기호 및 이의 특성을 생성할 수 있다. 발음기호 변환부는 발음기호 및 이의 특성을 수신하여 발음기호 생성 인 공지능 모델을 기반으로 발음기호를 보정하고, 보정된 발음기호를 한글발음으로 변환할 수 있다. 발음기호 변환 부는 발음기호에 대응하는 특성에 따라서 보정 방식을 다르게 수행할 수 있다. 발음기호 변환부는 발 음기호에 대응하는 특성에 부합하여 발음기호를 보정함으로써 사용자가 영문을 입력하였을 때 출력되기를 원하 는 한글 음성을 도 1의 음성 합성 시스템이 출력할 수 있도록 지원할 수 있다. 도 4는 본 개시의 예시적 실시 예에 따른 특성 추출 모델의 동작을 설명하기 위한 도면이다. 도 4를 참조하면, 특성 추출 모델은 도 1의 모델 학습부에 포함된 것으로, 특성 추출 모델은 복 수의 데이터베이스들(DB_1~DB_n)로부터 수신한 복수의 영문-한글발음 쌍들을 이용하여 쌍들 각각에 대한 특성을 추출하고, 그룹들로 분류하여 이를 학습할 수 있다. 예시적 실시 예로, 특성 추출 모델은 제1 내지 제3 특 성을 복수의 영문-한글발음 쌍들로부터 추출하여 이를 학습할 수 있다. 제1 특성은 소정의 영문으로부터 생성된 발음기호와 해당 발음기호에 대응하는 대표 발음기호간의 유사도가 임계치 이상인 것을 나타내는 특성이고, 제2 특성은 소정의 영문으로부터 생성된 발음기호가 한글 구어체에 해당하는 것을 나타내는 특성이며, 제3 특성은 소정의 영문으로부터 생성된 발음기호가 보정될 필요가 없음을 나타내는 것이다. 특성 추출 모델은 영문으로부터 생성된 발음기호로부터 특성을 추출할 수 있도록 학습되어 생성될 수 있다. 도 1의 발음기호 생성부는 특성 추출 모델을 기반으로 영문으로부터 생성된 발음기호로부터 특 성을 추출하여 발음기호 변환부에 제공할 수 있다. 도 5는 본 개시의 예시적 실시 예에 따른 도 4에 기반한 음성 합성 방법을 설명하기 위한 순서도이다. 도 5를 참조하면, 단계 S100에서 음성 합성 시스템은 사용자로부터 영문을 포함하는 텍스트를 입력받을 수 있다. 단계 S120에서 음성 합성 시스템은 영문으로부터 발음기호 및 이의 특성을 생성할 수 있다. 특성은 발음 기호에 대하여 어떠한 타입의 보정이 필요한지를 나타낼 수 있다. 예를 들어, 사용자가 잘못된 스펠링으로 영문을 입력하였을 때, 이러한 영문에 대한 발음기호에도 오류가 포함될 수 있는 바, 음성 합성 시스템은 학습을 통 하여 오류가 포함된 발음기호에 대응하는 대표 발음기호와의 유사도가 임계치 이상임을 나타내는 제1 특성을 생 성할 수 있다. 사용자가 영문을 단순히 한글 구어체로 표현하기 위해 입력한 경우, 즉, 사용자는 '안녕하세요' 라고 한글 음성으로 출력될 것을 원하여 'annyeonghaseyo' 라는 영문을 입력하였을 때, 음성 합성 시스템은 학 습을 통하여 입력된 영문으로부터 생성된 발음기호가 한글 구어체임을 나타내는 제2 특성을 생성할 수 있다. 제 2 특성이 추출이 필요한 이유는, 발음기호에는 악센트, 장음/단음이 포함되어 있기 때문에, 제2 특성이 고려되 지 않는 경우에 자칫 매우 어색한 음성이 출력될 우려가 있다. 또한, 음성 합성 시스템은 생성된 발음기호가 보 정될 필요가 없음을 나타내는 제3 특성을 생성할 수 있다. 단계 S140에서 음성 합성 시스템은 생성된 특성을 기반으로 발음기호를 보정할 수 있다. 단계 S160에서 음성 합 성 시스템은 보정된 발음기호로 음성을 합성할 수 있다. 이후, 음성 합성 시스템은 합성된 한글 음성을 사용자 에게 출력할 수 있다. 도 6은 본 개시의 예시적 실시 예에 따른 도 5의 단계 S140을 구체적으로 설명하기 위한 순서도이다. 도 6을 참조하면, 단계 S120에 후속하여 음성 합성 시스템은 단계 S141에서 생성된 발음기호에 대응하는 특성이 제1 특성인지 여부를 판별할 수 있다. 단계 S141이 'Yes'인 때에, 단계 S142를 후속하여 음성 합성 시스템은 생 성된 발음기호를 이에 대응하는 대표 발음기호로 보정할 수 있다. 단계 S141이 'No'인 때에, 단계 S143을 후속 하여 음성 합성 시스템은 생성된 발음기호에 대응하는 특성이 제2 특성인지 여부를 판별할 수 있다. 단계 S143 이 'Yes'인 때에, 단계 S144를 후속하여 음성 합성 시스템은 생성된 발음기호에서의 악센트, 장음/단음을 보정 할 수 있다. 즉, 음성 합성 시스템은 생성된 발음기호에서의 악센트, 장음/단음을 좀 더 한글 구어체 발음에 부 합하도록 보정할 수 있다. 단계 S143이 'No'인 때에, 단계 S145를 후속하여 음성 합성 시스템은 생성된 발음기 호의 특성은 제3 특성으로 판단하여 별도의 보정없이 단계 S160을 후속할 수 있다. 도 7은 본 개시의 예시적 실시 예에 따른 특성 추출 모듈의 동작을 설명하기 위한 도면이다. 도 7을 참조하면, 특성 추출 모델은 도 1의 모델 학습부에 포함된 것으로, 특성 추출 모델은 복 수의 데이터베이스들(DB_1~DB_n)로부터 수신한 복수의 영문-한글발음 쌍들을 이용하여 쌍들 각각에 대한 특성을 추출하고, 그룹들로 분류하여 이를 학습할 수 있다. 예시적 실시 예로, 특성 추출 모델은 각 영문으로부터 이에 대응하는 국가를 추출하여 이를 학습할 수 있다. 구체적으로, 특성 추출 모델은 각 영문이 제1 내지 제k 국가 중 어디에 해당하는지를 분류하여 학습할 수 있으며, 특성 추출 모델은 이를 위하여 글로벌 국가 언어 사전 정보 및 글로벌 발음기호 정보를 포함하는 데이터베이스를 참조할 수 있다. 위와 같이 특성 추출 모 델로부터 생성된 국가 특성은 도 1의 음성 합성부에서 이용하여 그에 부합하는 음성 합성을 수행할 수 있다. 도 8은 본 개시의 예시적 실시 예에 따른 도 7에 기반한 음성 합성 방법을 설명하기 위한 순서도이다. 도 8을 참조하면, 단계 S200에서 음성 합성 시스템은 사용자로부터 영문을 포함하는 텍스트를 입력받을 수 있다. 단계 S220에서 음성 합성 시스템은 영문으로부터 대응 국가를 탐색할 수 있다. 단계 S240에서 음성 합성 시스템은 탐색 결과를 기반으로 탐색 국가에 대응하는 발음기호 정보를 이용하여 입력된 영문로부터 발음기호를 생성할 수 있다. S260에서 음성 합성 시스템은 대응 국가를 기반으로 음성 타입을 선택할 수 있다. 예시적 실시 예로, 도 1의 음성 데이터베이스는 각 국가별 대응하는 음성 타입에 관한 정보를 저장할 수 있으며, 각각 의 음성 타입은 음성의 성별, 발언 패턴, 음역대 등이 고려되어 사용자가 들었을 때에 다른 사람으로부터 발성 되는 것으로 인식될 정도의 차이를 상호 가질 수 있다. 예를 들어, '미국'에 대응하는 것은 제1 음성 타입, '중 국'에 대응하는 것은 제2 음성 타입, '독일'에 대응하는 것은 제3 음성 타입으로 미리 설정되어 음성 데이터베 이스에 저장될 수 있다. 단계 S280에서 음성 합성 시스템은 선택된 음성 타입으로 발음기호를 이용하여 음 성을 합성하여 이를 출력할 수 있다. 한편, 도 8에 도시된 실시 예는, 도 6에 도시된 실시 예와 통합되어 수행 될 수 있다. 도 9는 본 개시의 예시적 실시 예에 따른 음성 합성 장치(300, 400)에 대한 도면이다. 도 9의 그림(a)를 참조하면, 음성 합성 장치는 클라이언트 장치 및 서비스 서버를 포함할 수 있 다. 음성 합성 장치는 모델 DB를 포함할 수 있다. 서비스 서버는 전술한 음성 합성 시스템에 해 당할 수 있다. 서비스 서버는 전술한 방법에 따라 클라이언트로부터 입력된 영문을 이용하여 발음기 호 및 이의 특성을 생성하고, 발음기호를 상기 특성에 따라 보정한 후에 음성을 합성하여 출력할 수 있다. 또한, 서비스 서버는 추가적으로 영문으로부터 국가 특성을 추출하여 국가 특성에 따라 선택된 음성 타입으로 음성 합성을 수행하고, 출력할 수 있다. 서비스 서버는 본 개시의 예시적 실시 예들에 따른 동작을 수행할 때에, 모델 DB에 저장된 인공지능 모델을 이용할 수 있다. 더 나아가, 서비스 서버는 음성 합 성 서비스를 클라이언트에 제공하고, 클라이언트로부터 수신되는 피드백을 이용하여 인공지능 모델에 대한 증강 학습을 수행할 수 있다. 도 9의 그림(b)를 더 참조하면, 음성 합성 장치는 컴퓨터 장치로서 PC, 노트북, 스마트기기 또는 서브 등 과 같은 장치를 의미할 수 있다. 음성 합성 장치는 입력장치, 연산장치, 저장장치 및 출력 장치를 포함할 수 있다. 음성 합성 장치는 도 9b에 도시된 내부 구조를 통하여 도 1 내지 도 8에서 서술된 실시 예들을 수행할 수 있으며, 이에 대한 구체적인 서술은 생략한다. 본 개시는 도면에 도시된 실시예를 참고로 설명되었으나 이는 예시적인 것에 불과하며, 본 기술 분야의 통상의 지식을 가진 자라면 이로부터 다양한 변형 및 균등한 다른 실시예가 가능하다는 점을 이해할 것이다. 따라서, 본 개시의 진정한 기술적 보호 범위는 첨부된 특허청구범위의 기술적 사상에 의하여 정해져야 할 것이다."}
{"patent_id": "10-2019-0136911", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 개시의 예시적 실시 예에 따른 음성 합성 시스템을 나타내는 블록도이다. 도 2는 본 개시의 예시적 실시 예에 따른 도 1의 모델 학습부를 설명하기 위한 도면이다. 도 3은 본 개시의 예시적 실시 예에 따른 발음기호 생성부 및 발음기호 변환부의 동작을 설명하기 위한 도면이 다. 도 4는 본 개시의 예시적 실시 예에 따른 특성 추출 모델의 동작을 설명하기 위한 도면이다. 도 5는 본 개시의 예시적 실시 예에 따른 도 4에 기반한 음성 합성 방법을 설명하기 위한 순서도이다. 도 6은 본 개시의 예시적 실시 예에 따른 도 5의 단계 S140을 구체적으로 설명하기 위한 순서도이다. 도 7은 본 개시의 예시적 실시 예에 따른 특성 추출 모듈의 동작을 설명하기 위한 도면이다. 도 8은 본 개시의 예시적 실시 예에 따른 도 7에 기반한 음성 합성 방법을 설명하기 위한 순서도이다. 도 9는 본 개시의 예시적 실시 예에 따른 음성 합성 장치에 대한 도면이다."}
