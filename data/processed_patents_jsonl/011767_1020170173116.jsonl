{"patent_id": "10-2017-0173116", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2019-0072066", "출원번호": "10-2017-0173116", "발명의 명칭": "영상 통화 서비스를 제공하는 단말과 서버", "출원인": "주식회사 하이퍼커넥트", "발명자": "안상일"}}
{"patent_id": "10-2017-0173116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "제1 단말에서,영상 통화 서비스를 제공하는 애플리케이션이 실행됨에 따라, 상기 제1 단말의 제1 사용자를 촬영한 제1 영상스트림을 수신하는 단계;상기 제1 영상 스트림으로부터 상기 제1 사용자의 안면 특징점들을 추출하는 단계;복수의 사용자의 안면 특징점들에 기초한 불량 사용자 판별을 위한 학습 모델에 상기 제1 사용자의 안면 특징점들의 분포 정보를 적용하여, 상기 제1 사용자가 불량 사용자인지를 예측하는 단계; 및상기 예측 결과에 기초하여, 상기 애플리케이션의 실행 화면 내의 컴포넌트의 표시를 제어하는 단계;를 포함하는 영상 통화 서비스를 제공하는 방법을 수행하도록 하는, 컴퓨터 판독 가능 저장매체에 저장된 애플리케이션."}
{"patent_id": "10-2017-0173116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 복수의 사용자의 안면 특징점들의 분포 정보 및 상기 복수의 사용자의 안면 특징점들의 분포 정보에 대응되는 필터링 항목의 정보를 이용하여 학습된, 상기 필터링 항목에 대한 불량 사용자를 판별하기 위한 학습 모델을 준비하는 단계;를 더 포함하는, 컴퓨터 판독 가능 저장매체에 저장된 애플리케이션."}
{"patent_id": "10-2017-0173116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,상기 필터링 항목에 대한 불량 사용자를 판별하기 위한 학습 모델은, 인공 신경망을 통해 상기 복수의 사용자의안면 특징점들의 분포 정보와 상기 복수의 사용자의 안면 특징점들의 분포 정보에 대응되는 상기 필터링 항목의정보의 상관 관계에 기초하여 학습된 것인, 컴퓨터 판독 가능 저장매체에 저장된 애플리케이션."}
{"patent_id": "10-2017-0173116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서,상기 제1 사용자가 불량 사용자인지를 예측하는 단계는,상기 인공 신경망을 이용하여 상기 제1 사용자의 안면 특징점들의 분포 정보를 상기 필터링 항목에 대한 불량사용자를 판별하기 위한 학습 모델에 따라 학습하는 단계; 및상기 학습 결과에 기초하여, 상기 제1 사용자가 상기 필터링 항목에 대한 불량 사용자인지를 예측하는 단계;를 포함하는, 컴퓨터 판독 가능 저장매체에 저장된 애플리케이션."}
{"patent_id": "10-2017-0173116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제2항에 있어서,상기 필터링 항목의 정보는,성별 정보, 나이 정보, 상기 애플리케이션이 실행되는 동안의 신체 노출 정도 정보 및 욕설 빈도 정보 중 적어도 하나를 포함하고,상기 필터링 항목의 정보가 적어도 둘의 정보를 포함하면,공개특허 10-2019-0072066-3-상기 제1 사용자가 불량 사용자인지를 예측하는 단계는,상기 제1 사용자의 안면 특징점들의 분포 정보를 상기 필터링 항목 각각에 대한 불량 사용자를 판별하기 위한학습 모델에 적용하여, 상기 제1 사용자가 상기 필터링 항목 각각에 대한 불량 사용자인지를 예측하는 것인, 컴퓨터 판독 가능 저장매체에 저장된 애플리케이션."}
{"patent_id": "10-2017-0173116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제2항에 있어서,상기 필터링 항목에 대한 불량 사용자를 판별하기 위한 학습 모델을 준비하는 단계는,상기 복수의 사용자에 대해서 상기 필터링 항목에 대한 불량 사용자 판별 이력을 학습하여, 상기 필터링 항목에대한 불량 사용자를 판별하기 위한 학습 모델을 업데이트 하는 단계;를 포함하는, 컴퓨터 판독 가능 저장매체에 저장된 애플리케이션."}
{"patent_id": "10-2017-0173116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에 있어서,상기 제1 영상 스트림으로부터 상기 제1 사용자의 안면 특징점들을 추출하는 단계는,상기 제1 영상 스트림으로부터 상기 제1 사용자의 안면 부위인 눈 부위, 코 부위, 입 부위, 이마 부위, 및 턱부위 중 적어도 하나의 부위의 특징점들을 추출하는 것이고,상기 복수의 사용자의 안면 특징점들에 기초한 불량 사용자 판별을 위한 학습 모델에 상기 제1 사용자의 안면특징점들의 분포 정보를 적용하여, 상기 제1 사용자가 불량 사용자인지를 예측하는 단계는,상기 학습 모델에 상기 제1 사용자의 안면 부위 중 하나의 부위에 대한 특징점들의 분포 정보를 적용하는 단계;및상기 학습 모델에 상기 제1 사용자의 안면 부위 중 적어도 둘 부위의 조합에 대한 특징점들의 분포 정보를 적용하는 단계;를 포함하는, 컴퓨터 판독 가능 저장매체에 저장된 애플리케이션."}
{"patent_id": "10-2017-0173116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1항에 있어서,상기 제1 사용자가 불량 사용자인 것으로 예측되면,상기 예측 결과에 기초하여, 상기 애플리케이션의 실행 화면 내의 컴포넌트의 표시를 제어하는 단계는,상기 애플리케이션의 실행 화면 상에 경고 메시지를 표시하는 단계;상기 애플리케이션의 실행 화면 상에서 상기 제1 사용자가 출력되는 영역을 모자이크 처리하여 표시하는 단계;및상기 제1 단말이 제2 단말과 수립된 영상 통화 세션을 자동으로 종료시키는 단계 중 적어도 하나의 단계를 수행하는, 컴퓨터 판독 가능 저장매체에 저장된 애플리케이션."}
{"patent_id": "10-2017-0173116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1항에 있어서,상기 제1 사용자가 정상 사용자인 것으로 예측되면,상기 예측 결과에 기초하여, 상기 애플리케이션의 실행 화면 내의 컴포넌트의 표시를 제어하는 단계는,상기 제1 단말이 제2 단말과 수립된 영상 통화 세션을 계속하여 유지시키는 단계를 포함하고,상기 영상 통화 서비스를 제공하는 방법은,제1항의 상기 제1 영상 스트림을 수신하는 단계, 상기 제1 사용자의 안면 특징점들을 추출하는 단계, 상기 제1공개특허 10-2019-0072066-4-사용자가 불량 사용자인지를 예측하는 단계, 및 상기 애플리케이션의 실행 화면 내의 컴포넌트의 표시를 제어하는 단계를 실시간 또는 소정의 주기마다 반복적으로 수행하는 단계를 더 포함하는, 컴퓨터 판독 가능 저장매체에 저장된 애플리케이션."}
{"patent_id": "10-2017-0173116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제2항에 있어서,상기 필터링 항목에 대한 불량 사용자를 판별하기 위한 학습 모델을 준비하는 단계는,상기 영상 통화 서비스를 제공하는 서버로부터 상기 필터링 항목에 대한 불량 사용자를 판별하기 위한 학습 모델을 수신하는 것인, 컴퓨터 판독 가능 저장매체에 저장된 애플리케이션."}
{"patent_id": "10-2017-0173116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "영상 통화를 지원하는 복수의 단말과 통신을 수행하는 통신 인터페이스;스토리지;프로세서; 및상기 프로세서에 의해 실행 가능한 명령어들을 저장하는 메모리;를 포함하고,상기 프로세서는, 상기 명령어들을 실행함으로써,상기 복수의 단말에서 영상 통화 서비스를 제공하는 애플리케이션이 실행됨에 따라, 상기 복수의 단말 각각으로부터 상기 복수의 단말 각각에 대응되는 복수의 사용자의 영상 스트림을 수신하고,상기 영상 스트림으로부터 상기 복수의 사용자의 안면 특징점들을 추출하고,상기 복수의 사용자의 안면 특징점들의 분포 정보 및 상기 복수의 사용자의 안면 특징점들의 분포 정보에 대응되는 필터링 항목의 정보에 기초하여, 상기 필터링 항목에 대한 불량 사용자를 판별하기 위한 학습 모델을 생성하고,상기 생성된 학습 모델을 상기 복수의 단말로 전송하는, 영상 통화 서비스를 제공하는 서버."}
{"patent_id": "10-2017-0173116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항에 있어서,상기 프로세서는, 상기 명령어들을 실행함으로써,인공 신경망을 통한 연산을 수행하여, 상기 복수의 사용자의 안면 특징점들의 분포 정보와 상기 복수의 사용자의 안면 특징점들의 분포 정보에 대응되는 상기 필터링 항목의 정보의 상관 관계를 학습하고, 상기 학습 결과에기초하여 상기 인공 신경망을 훈련하여, 상기 필터링 항목에 대한 불량 사용자를 판별하기 위한 학습 모델을 생성하는, 영상 통화 서비스를 제공하는 서버."}
{"patent_id": "10-2017-0173116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제11항에 있어서,상기 필터링 항목의 정보는, 성별 정보, 나이 정보, 상기 애플리케이션이 실행되는 동안의 신체 노출 정도 정보및 욕설 빈도 정보 중 적어도 하나를 포함하고,상기 필터링 항목의 정보가 적어도 둘의 정보를 포함하면,상기 프로세서는, 상기 명령어들을 실행함으로써,상기 복수의 사용자의 안면 특징점들의 분포 정보 및 상기 복수의 사용자의 안면 특징점들의 분포 정보에 대응되는 상기 필터링 항목 각각의 정보에 기초하여, 상기 필터링 항목 각각에 대한 불량 사용자를 판별하기 위한학습 모델을 생성하는, 영상 통화 서비스를 제공하는 서버."}
{"patent_id": "10-2017-0173116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "공개특허 10-2019-0072066-5-제11항에 있어서,상기 프로세서는, 상기 명령어들을 실행함으로써,상기 복수의 사용자에 대해서 상기 필터링 항목에 대한 불량 사용자 판별 이력을 학습하여, 상기 필터링 항목에대한 불량 사용자를 판별하기 위한 학습 모델을 업데이트 하는, 영상 통화 서비스를 제공하는 서버."}
{"patent_id": "10-2017-0173116", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제1 단말에서 영상 통화 서비스를 제공하는 애플리케이션이 실행됨에 따라, 상기 제1 단말의 제1 사용자를 촬영한 제1 영상 스트림을 수신하는 명령어들;상기 제1 영상 스트림으로부터 상기 제1 사용자의 안면 특징점들을 추출하는 명령어들;복수의 사용자의 안면 특징점들에 기초한 불량 사용자 판별을 위한 학습 모델에 상기 제1 사용자의 안면 특징점들의 분포 정보를 적용하여, 상기 제1 사용자가 불량 사용자인지를 예측하는 명령어들; 및상기 예측 결과에 기초하여, 상기 애플리케이션의 실행 화면 내의 컴포넌트의 표시를 제어하는 명령어들;을 포함하는 프로세서에 의해 실행 가능한 명령어들이 저장된 비일시적 컴퓨터 판독 가능 저장매체."}
{"patent_id": "10-2017-0173116", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "제1 단말에서, 영상 통화 서비스를 제공하는 애플리케이션이 실행됨에 따라, 상기 제1 단말의 제1 사용자를 촬영 한 제1 영상 스트림을 수신하는 단계; 상기 제1 영상 스트림으로부터 상기 제1 사용자의 안면 특징점들을 추출하 는 단계; 복수의 사용자의 안면 특징점들에 기초한 불량 사용자 판별을 위한 학습 모델에 상기 제1 사용자의 안 면 특징점들의 분포 정보를 적용하여, 상기 제1 사용자가 불량 사용자인지를 예측하는 단계; 및 상기 예측 결과 에 기초하여, 상기 애플리케이션의 실행 화면 내의 컴포넌트의 표시를 제어하는 단계를 포함하는 영상 통화 서비 스를 제공하는 방법을 수행할 수 있도록 컴퓨터 판독 가능 저장매체에 저장된 애플리케이션이 제공된다."}
{"patent_id": "10-2017-0173116", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "영상 통화 서비스를 제공하는 단말과 서버에 관한 것이다."}
{"patent_id": "10-2017-0173116", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "과학 기술의 발전에 따라, 대부분의 사람들이 스마트 폰, 태블릿 PC와 같은 단말을 보유하게 되었다. 이와 같은 단말은 영상을 촬영하고, 재생할 수 있으며, 다른 단말과 통신을 수행하여 정보를 주고받거나, 영상 통화(video call)를 지원할 수 있다. 한편, 인공지능(Artificial Intelligence, AI) 시스템은 인간 수준의 지능을 구현하는 컴퓨터 시스템이다. 최근 에, 인공지능 기술은 다양한 분야에서 응용되고 있다. 특히, 영상 통화 서비스를 제공하는 단말 및 서버에서도 중요성이 부각되고 있다."}
{"patent_id": "10-2017-0173116", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "단말은 사용자의 안면 특징점들을 영상 통화 서비스를 제공하는 애플리케이션의 불량 사용자 판별을 위한 학습 모델에 적용하여, 영상 통화 서비스 내에서 불량 사용자를 보다 효과적으로 검출함으로써, 영상 통화 서비스에 대한 사용자의 만족도를 향상시킬 수 있다. 또한, 안면 특징점들의 분포 정보를 이용하여 학습 시킴으로써, 영상 통화 서비스를 제공하는 애플리케이션의 불량 사용자 판별을 위한 학습 모델을 생성하는 데에 필요한 연산량, 연산 시간 및 저장 공간을 감소시킬 수 있 다."}
{"patent_id": "10-2017-0173116", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "일측에 따르면, 컴퓨터 판독 가능 저장매체에 저장된 애플리케이션은, 제1 단말에서, 영상 통화 서비스를 제공 하는 애플리케이션이 실행됨에 따라, 상기 제1 단말의 제1 사용자를 촬영한 제1 영상 스트림을 수신하는 단계; 상기 제1 영상 스트림으로부터 상기 제1 사용자의 안면 특징점들을 추출하는 단계; 복수의 사용자의 안면 특징 점들에 기초한 불량 사용자 판별을 위한 학습 모델에 상기 제1 사용자의 안면 특징점들의 분포 정보를 적용하여, 상기 제1 사용자가 불량 사용자인지를 예측하는 단계; 및 상기 예측 결과에 기초하여, 상기 애플리케 이션의 실행 화면 내의 컴포넌트의 표시를 제어하는 단계;를 포함하는 영상 통화 서비스를 제공하는 방법을 수 행할 수 있다. 다른 일측에 따르면, 영상 통화 서비스를 제공하는 서버는 영상 통화를 지원하는 복수의 단말과 통신을 수행하 는 통신 인터페이스; 스토리지; 프로세서; 및 상기 프로세서에 의해 실행 가능한 명령어들을 저장하는 메모리; 를 포함하고, 상기 프로세서는, 상기 명령어들을 실행함으로써, 상기 복수의 단말에서 영상 통화 서비스를 제공 하는 애플리케이션이 실행됨에 따라, 상기 복수의 단말 각각으로부터 상기 복수의 단말 각각에 대응되는 복수의 사용자의 영상 스트림을 수신하고, 상기 영상 스트림으로부터 상기 복수의 사용자의 안면 특징점들을 추출하고, 상기 복수의 사용자의 안면 특징점들의 분포 정보 및 상기 복수의 사용자의 안면 특징점들의 분포 정보에 대응 되는 필터링 항목의 정보에 기초하여, 상기 필터링 항목에 대한 불량 사용자를 판별하기 위한 학습 모델을 생성 하고, 상기 생성된 학습 모델을 상기 복수의 단말로 전송할 수 있다. 또 다른 일측에 따르면, 프로세서에 의해 실행 가능한 명령어들이 저장된 비일시적 컴퓨터 판독 가능 저장매체 는, 제1 단말에서 영상 통화 서비스를 제공하는 애플리케이션이 실행됨에 따라, 상기 제1 단말의 제1 사용자를 촬영한 제1 영상 스트림을 수신하는 명령어들; 상기 제1 영상 스트림으로부터 상기 제1 사용자의 안면 특징점들 을 추출하는 명령어들; 복수의 사용자의 안면 특징점들에 기초한 불량 사용자 판별을 위한 학습 모델에 상기 제 1 사용자의 안면 특징점들의 분포 정보를 적용하여, 상기 제1 사용자가 불량 사용자인지를 예측하는 명령어들; 및 상기 예측 결과에 기초하여, 상기 애플리케이션의 실행 화면 내의 컴포넌트의 표시를 제어하는 명령어들을 포함할 수 있다."}
{"patent_id": "10-2017-0173116", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하에서는 도면을 참조하여 다양한 실시예들을 상세히 설명한다. 이하에서 설명되는 실시예들은 여러 가지 상 이한 형태로 변형되어 실시될 수도 있다. 실시예들의 특징을 보다 명확히 설명하기 위하여 이하의 실시예들이"}
{"patent_id": "10-2017-0173116", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "속하는 기술분야에서 통상의 지식을 가진 자에게 널리 알려져 있는 사항들에 관해서 자세한 설명은 생략한다. 한편, 본 명세서에서 어떤 구성이 다른 구성과 \"연결\"되어 있다고 할 때, 이는 '직접적으로 연결'되어 있는 경 우뿐 아니라, '그 중간에 다른 구성을 사이에 두고 연결'되어 있는 경우도 포함한다. 또한, 어떤 구성이 다른 구성을 \"포함\"한다고 할 때, 이는 특별히 반대되는 기재가 없는 한, 그 외 다른 구성을 제외하는 것이 아니라 다른 구성들 더 포함할 수도 있다는 것을 의미한다. 또한, 본 명세서에서 사용되는 '제 1' 또는 '제 2' 등과 같이 서수를 포함하는 용어는 다양한 구성 요소들을 설 명하는데 사용할 수 있지만, 상기 구성 요소들은 상기 용어들에 의해 한정되어서는 안 된다. 상기 용어들은 하 나의 구성 요소를 다른 구성 요소로부터 구별하는 목적으로만 사용된다. 본 실시예들은 영상 통화 서비스를 제공하는 단말과 서버에 관한 것으로서 이하의 실시예들이 속하는 기술 분야 에서 통상의 지식을 가진 자에게 널리 알려져 있는 사항들에 관해서는 자세한 설명을 생략한다. 도 1은 영상 통화 서비스가 제공되는 환경을 설명하기 위한 도면이다. 영상 통화 서비스는 복수의 사용자가 각자의 단말을 이용하여 자신의 영상을 상대방에게 전송하고 상대방의 영 상을 수신함으로써 의사를 주고받을 수 있는 서비스를 의미한다. 영상 통화 서비스를 이용하는 사용자들은 각자 의 단말을 통해, 영상과 음성을 주고받을 수 있으며, 채팅 기능을 통해 텍스트를 주고 받을 수도 있다. 영상 통 화 서비스를 이용하려는 사용자는 상대방을 직접 지정하거나, 영상 통화 서비스를 제공하는 서버에서 랜덤 또는 소정의 방식에 따라 상대방을 지정해줌으로써, 상대방과 영상 통화 서비스를 이용할 수 있다. 도 1을 참조하면, 단말이 통신망을 통해 영상 통화 서비스를 제공하는 서버와 연결되어 있다. 서버 는 복수의 사용자가 각자의 단말을 이용하여 영상 통화 서비스를 이용할 수 있도록 도와주는 각종 프 로그램 또는 애플리케이션과 데이터를 저장할 수 있다. 영상 통화 서비스를 제공하는 서버는 근거리 통신 및 원격지 통신을 모두 수행할 수 있다. 영상 통화 서비스를 제공하는 서버는 통신망을 통해 복수의 단말 들과 연결될 수 있다. 단말은 영상 통화 서비스를 제공하는 서버와의 연결에 이용될 수 있는 다 양한 종류의 사용자 단말이 될 수 있다. 예를 들어, 단말은 영상 통화 서비스를 제공하는 서버와 통 신을 수행할 수 있는 장치로서, 스마트 왓치와 같은 웨어러블 장치, 또는 스마트 폰, 태블릿 PC, 랩톱 컴퓨터와 같은 모바일 장치, 및 데스크톱 컴퓨터와 같은 스테이셔너리(stationary) 장치 등이 될 수 있다. 또한, 단말 은 영상 통화 서비스를 통해 연결되는 사용자들 간 영상 통화가 이루어질 수 있도록, 영상을 촬영하고 재 생할 수 있는, 영상 통화를 지원하는 영상 통화 장치일 수 있다. 도 2는 일 실시예에 따른 단말의 구성을 나타낸 블록도이다. 도 2를 참고하면, 단말은 메모리, 프로세서, 사용자 인터페이스, 및 통신 인터페이스"}
{"patent_id": "10-2017-0173116", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": ", 음성 및 영상 입력부를 포함할 수 있다. 본 실시예와 관련된 기술분야에서 통상의 지식을 가진 자 라면 도 2에 도시된 구성요소들 외에 다른 범용적인 구성요소들이 더 포함될 수 있음을 알 수 있다. 메모리는 소프트웨어 또는 프로그램을 저장할 수 있다. 예를 들어, 메모리는 애플리케이션, 애플리케 이션 프로그래밍 인터페이스(API) 등과 같은 프로그램 및 다양한 종류의 데이터를 저장할 수 있다. 메모리(11 0)는 프로세서에 의해 실행 가능한 명령어들을 저장할 수 있다. 프로세서는 메모리에 저장된 명령어들을 실행할 수 있다. 프로세서는 메모리에 저장된 각 종 프로그램, 컨텐츠, 데이터를 이용하거나, 또는 새로운 프로그램, 컨텐츠, 데이터를 메모리에 저장할 수 도 있다. 프로세서는 메모리에 액세스하여, 메모리에 저장된 O/S를 이용하여 부팅을 수행할 수 있다. 프 로세서는 메모리에 저장된 각종 프로그램, 및 컨텐츠, 데이터 등을 이용하여 다양한 동작을 수행할 수 있다. 예를 들어, 프로세서는 메모리에 저장된 각종 프로그램, 컨텐츠, 및 데이터를 이용하여, 디 스플레이에 소정의 화면을 표시할 수 있다. 프로세서는 디스플레이의 일 영역에 대한 사용자 조작이 이루어지면, 사용자의 조작에 대응되는 제어 동작을 수행할 수 있다. 프로세서는 그래픽 처리에 특화된 GPU(Graphic Processing Unit)를 포함할 수 있다. GPU는 단말의 부팅이 완료되면, 디스플레이의 영역에 사용자 인터페이스 화면을 디스플레이한다. 구체적으로는, GPU는 컨텐츠, 아이콘, 메뉴 등과 같은 다양한 객체를 포함하는 영상 통화 레이아웃이 표시된 화면을 생성할 수 있다. GPU는 화면의 영상 통화 레이아웃에 따라 각 객체들이 표시될 좌표값, 형태, 크기, 및 컬러 등과 같은 속성값을 연산할 수 있다. 그리고, GPU는 연산된 속성값에 기초하여 객체를 포함하는 다양한 레이아웃의 화면을 생성할 수 있다. GPU에서 생성된 화면은 디스플레이로 제공되어, 디스플레이의 각 영역에 각각 표시될 수 있 다. 한편, 프로세서는 비디오 프로세서와 오디오 프로세서를 포함할 수 있다. 프로세서는 비디오 프로세 서와 오디오 프로세서를 제어하여, 통신 인터페이스를 통해 수신된 영상 스트림 또는, 메모리에 저장 된 영상 스트림에 포함된 비디오 데이터 또는 오디오 데이터를 처리할 수 있다. 사용자 인터페이스는 입력부와 출력부를 포함할 수 있다. 입력부는 사용자로부터 다양한 명령어를 입력받을 수 있다. 입력부는 키패드, 터치 패널 및 펜 인식 패널 중 적어도 하나를 포함할 수 있다. 키패드는 단말의 본체 외관의 전면부나 측면부, 배면부 등의 다양한 영역에 형성된 기계적 버튼, 휠 등과 같은 다양한 유형의 키를 포함할 수 있다. 터치 패널은 사용자의 터치 입력을 감지하고, 감지된 터치 신호에 해당하는 터치 이벤트 값을 출력할 수 있다. 터치 패널이 표시 패널과 결합하여 터치 스크린을 구성한 경우, 터치 스크린은 정전식이나, 감압식, 및 압전식 등과 같은 다양한 유형의 터치 센서로 구현될 수 있다. 펜 인식 패널은 사용자의 터치용 펜(예컨대, 스타일러스 펜(stylus pen))의 운용에 따른 펜의 근접 입력 또는 터치 입력을 감지하고 감지된 펜 근접 이벤트 또는 펜 터치 이벤트를 출력할 수 있다. 펜 인식 패널 은, 예로, EMR(Electromagnetic Radiation) 방식으로 구현될 수 있으며, 펜의 근접 또는 터치에 의한 전자기장 의 세기 변화에 따라 터치 또는 근접 입력을 감지할 수 있다. 펜 인식 패널은 그리드 구조를 가지는 전자 유도 코일 센서와 전자 유도 코일 센서의 각 루프 코일에 순차적으로 소정의 주파수를 가지는 교류 신호를 제공 하는 전자 신호 처리부를 포함하여 구성될 수 있다. 출력부는 디스플레이, 스피커를 포함할 수 있다. 디스플레이는 표시 패널 및 표시 패널을 제어하는 컨트롤러를 포함할 수 있다. 표시 패널은 LCD(Liquid Crystal Display), OLED(Organic Light Emitting Diodes) 디스플레이, AM-OLED(Active-Matrix Organic Light- Emitting Diode), 및 PDP(Plasma Display Panel) 등과 같은 다양한 방식으로 구현될 수 있다. 표시 패널은 유 연하게(flexible) 또는 착용할 수 있게(wearable) 구현될 수 있다. 디스플레이는 입력부의 터치 패널 과 결합되어 터치 스크린으로 제공될 수 있다. 스피커는 오디오 데이터에 기초하여 소리를 출력할 수 있다. 예를 들어, 스피커는 영상 스트림에 포 함된 오디오 데이터에 따라, 사용자의 음성을 출력할 수 있다. 통신 인터페이스는 다양한 유형의 통신방식에 따라 다양한 유형의 외부 기기와 통신을 수행할 수 있다. 통 신 인터페이스는 와이파이 칩, 블루투스 칩, NFC 칩, 및 무선통신 칩 중 적어도 하나를 포함할 수 있다. 프로세서는 통신 인터페이스를 이용하여 각종 외부 기기와 통신을 수행할 수 있다. 와이파이 칩, 및 블루투스 칩은 각각 WiFi 방식, 블루투스 방식으로 통신을 수행할 수 있다. 와이파이 칩이나 블루투스 칩을 이용하는 경우에는 SSID 및 세션 키 등과 같은 각종 연결 정보를 먼저 송수신하여, 이를 이용하 여 통신 연결한 후 각종 정보들을 송수신할 수 있다. NFC 칩은 다양한 RF-ID 주파수 대역들 중에서 13.56MHz 대 역을 사용하는 NFC(Near Field Communication) 방식으로 동작하는 칩을 의미한다. 무선 통신 칩은 IEEE(Institute of Electrical and Electronics Engineers), 지그비, 3G(3rd Generation), 3GPP(3rd Generation Partnership Project), LTE(Long Term Evolution), 및 5G(5th Generation) 등과 같은 다양한 통신 규격에 따라 통신을 수행하는 칩을 의미한다. 음성 및 영상 입력부는 마이크와 카메라를 포함할 수 있다. 마이크는 사용자 음성이나 기 타 소리를 입력받아 오디오 데이터로 변환할 수 있다. 프로세서는 마이크를 통해 입력되는 사용자 음성을 영상 통화에 이용하거나, 오디오 데이터로 변환하여 메모리에 저장할 수 있다. 카메라는 사용자 의 제어에 따라 정지 영상 또는 동영상을 촬영할 수 있다. 카메라는 단말의 전면 또는 후면에 위치한 카메라 모듈일 수 있다. 프로세서는 마이크를 통해 입력되는 음성과 카메라에 의해 촬영되는 영 상을 이용하여, 영상 통화를 위한 영상 스트림을 생성할 수 있다. 한편, 단말은 모션 제어 모드나 음성 제어 모드로 동작할 수 있다. 모션 제어 모드로 동작하는 경우, 프로 세서는 카메라를 활성화시켜 사용자를 촬영하고, 사용자의 모션 변화를 추적하여 그에 대응되는 제어 동작을 수행할 수 있다. 음성 제어 모드로 동작하는 경우, 프로세서는 마이크를 통해 입력된 사용자 음성을 분석하고, 분석된 사용자 음성에 따라 제어 동작을 수행할 수 있다. 전술한 단말의 구성 요소들의 명칭은 달라질 수 있다. 또한, 본 개시에 따른 단말은 전술한 구성요소 들 중 적어도 하나를 포함하여 구성될 수 있으며, 일부 구성요소가 생략되거나 또는 추가적인 다른 구성요소를 더 포함할 수 있다. 단말은 전술한 구성요소들 중 적어도 하나를 이용하여, 다음과 같은 동작을 수행할 수 있다. 도 3은 일 실시예에 따른 영상 통화 서비스를 제공하는 서버의 구성을 나타낸 블록도이다. 도 3을 참조하면, 영상 통화 서비스를 제공하는 서버는 메모리, 프로세서, 스토리지, 및"}
{"patent_id": "10-2017-0173116", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "통신 인터페이스를 포함한다. 본 실시예와 관련된 기술분야에서 통상의 지식을 가진 자라면 도 3에 도시된 구성요소들 외에 다른 범용적인 구성요소들이 더 포함될 수 있음을 알 수 있다. 도 3의 블록도의 각 구성요소는 영상 통화 서비스를 제공하는 서버의 구현 방식에 따라 분리, 추가, 또는 생략될 수 있다. 즉, 구현 방식 에 따라 하나의 구성요소가 2 이상의 구성요소로 세분화되거나, 2 이상의 구성요소가 하나의 구성요소로 합쳐질 수도 있고, 일부 구성요소가 더 추가되거나 제거될 수 있다. 메모리는 프로세서에 의해 실행 가능한 명령어들을 저장할 수 있다. 메모리는 소프트웨어 또는 프로그램을 저장할 수 있다. 프로세서는 메모리에 저장된 명령어들을 실행할 수 있다. 프로세서는 영상 통화 서비스를 제공 하는 서버의 전반적인 제어를 수행할 수 있다. 프로세서는 통신 인터페이스를 통해 수신되는 정 보 및 요청 사항을 획득하고, 수신되는 정보를 스토리지에 저장할 수 있다. 또한, 프로세서는 수신되 는 정보를 가공할 수 있다. 예를 들어, 프로세서는 단말로부터 수신되는 정보로부터 영상 통화 서비 스에 이용되는 정보를 생성하거나, 수신되는 정보들을 관리하기 위한 가공행위를 수행하여, 스토리지에 저 장할 수 있다. 또한, 프로세서는 단말로부터 획득된 요청 사항에 대한 응답으로써, 스토리지에 저장된 정보를 이용하여, 통신 인터페이스를 통해 단말에 영상 통화 서비스를 제공하기 위한 정보를 전송할 수 있다. 스토리지는 영상 통화 서비스를 제공하는 서버가 영상 통화 서비스를 제공하기 위해 필요한 각종 소 프트웨어 및 정보들을 저장할 수 있다. 예를 들어, 스토리지는 영상 통화 서비스를 제공하는 서버에 서 실행되는 프로그램, 애플리케이션, 및 영상 통화 서비스에 이용되는 각종 데이터를 저장할 수 있다. 스토리지는 영상 통화 서비스를 이용하는 사용자별 개인 정보를 데이터베이스화하여 저장 및 관리할 수 있 다. 스토리지는 영상 통화 서비스를 제공하는 서버에 접속하기 위한 계정별로 사용자의 신상 정보와 영상 통화 서비스에 이용되는 다양한 정보 등을 저장할 수 있다. 통신 인터페이스는 단말을 포함한 외부 기기와 통신을 수행할 수 있다. 예를 들어, 영상 통화 서비스 를 제공하는 서버는 단말로부터 영상 통화 서비스 개시 요청, 영상 통화 서비스 환경을 갖추기 위한 설정 정보에 대한 요청 등을 수신하고, 단말의 요청에 대한 응답으로, 영상 통화 서비스와 관련된 모든 사 항들을 제공할 수 있다. 도 4는 다른 실시예에 따라 영상 통화 서비스를 제공하는 서버가 복수 개의 분산 서버들로 구현된 모습을 설명하기 위한 도면이다. 이상에서 영상 통화 서비스를 제공하는 서버와 관련하여 기재된 내용은 이하 생 략된 내용이라 하더라도 그대로 적용될 수 있다. 도 4를 참고하면, 영상 통화 서비스를 제공하는 분산 서버들은 부하 분산 서버(200-1)와 영상 통화 서비스를 제 공하는 기능 서버들(200-3, 200-5, 200-7)로 구성될 수 있다. 부하 분산 서버(200-1)는 단말과 같은 외부 기기의 영상 통화 서비스에 관한 요청이 있을 때, 영상 통화 서비스를 제공하는 기능 서버들(200-3, 200-5, 200-7) 중 임의의 서버를 결정하여 단말에 연결시키거나, 영상 통화 서비스를 제공하는 기능 서버들(200-3, 200-5, 200-7)의 상태를 모니터링하여 최적의 서버를 선택하여 단말에 연결시킬 수 있다. 이하, 도 5 내지 도 13에서 설명되는 제1 단말은 도 2에 도시된 단말의 메모리, 프로세서, 사용자 인터페이스, 통신 인터페이스, 및 음성 및 영상 입력부를 포함할 수 있고, 도 2에 도시 된 단말과 동일한 동작을 수행할 수 있다. 또한, 도 5 내지 도 13에서 설명되는 서버는, 도 3에 도시된 서버의 메모리, 프로세서, 스 토리지, 및 통신 인터페이스를 포함할 수 있고, 도 2에 도시된 서버와 동일한 동작을 수행할 수 있다. 이하, 도 5 내지 도 13에서는, 제1 단말 및 서버가 수행하는 다양한 동작이나 응용들이 설명되는데, 제1 단말의 메모리, 프로세서, 사용자 인터페이스, 통신 인터페이스, 및 음성 및 영 상 입력부, 서버의 메모리, 프로세서, 스토리지, 및 통신 인터페이스 중 어느"}
{"patent_id": "10-2017-0173116", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "구성을 특정하지 않더라도 실시예가 속하는 기술분야에서 통상의 지식을 가진 자가 명확하게 이해하고 예상할 수 있는 정도의 내용은 통상의 구현으로 이해될 수 있으며, 제1 단말 및 서버의 권리범위가 특정한 구성의 명칭이나 물리적/논리적 구조에 의해 제한되는 것은 아니다. 도 5는 일 실시예에 따라, 사용자의 안면 특징점들을 이용하여 사용자가 불량 사용자인지를 예측하는 과정을 설 명하기 위한 도면이다. 도 5를 참고하면, 제1 사용자는 제1 사용자의 제1 단말에서 영상 통화 서비스를 제공하는 애플리케이션(이 하, '애플리케이션'이라 지칭한다.)을 실행할 수 있다. 제1 단말에서 애플리케이션이 실행됨에 따라, 제1 단말은 제1 사용자의 영상 통화의 상대방인 제2 사용자의 제2 단말과 영상 통화가 이루어질 수 있도록, 영 상 통화에 요구되는 정보들을 제1 단말의 디스플레이에 표시할 수 있다. 예를 들면, 제1 단말은 애플 리케이션에 대한 제1 사용자의 로그인을 위해 제1 사용자의 안면의 정면 촬영을 요청하는 실행 화면을 표시할 수 있다. 다른 예를 들면, 애플리케이션을 통해 제1 사용자의 제1 단말과 제2 사용자의 제2 단말 간의 영 상 통화가 이루어질 수 있도록, 제1 단말은 제1 사용자의 안면의 정면 촬영을 요청하는 실행 화면을 표시 할 수 있다. 제1 단말은 제1 단말의 카메라를 통해 제1 사용자를 촬영한 영상 또는 영상 스트림을 획 득할 수 있다. 여기서, 영상 스트림은 적어도 하나의 영상을 포함할 수 있다. 제1 단말은 소정의 영상 처리 알고리즘에 기초하여, 제1 사용자를 촬영한 영상 또는 영상 스트림으로부터 제1 사용자의 안면 특징점들을 추출할 수 있다. 여기서, 안면 특징점들은 안면 영상에 포함된 특정한 모양, 패 턴, 색상 또는 이들의 조합으로부터 획득될 수 있다. 또한, 소정의 영상 처리 알고리즘은, SIFT(Scale Invariant Feature Transform), HOG(Histogram of Oriented Gradient), Haar feature, Ferns, LBP(Local Binary Pattern) 및 MCT(Modified Census Transform) 중 하나일 수 있고, 이에 한정되지 않는다. 예를 들면, 제1 단말은 LBP(Local Binary Pattern) 알고리즘에 기초하여, 제1 사용자를 촬영한 영상 스트 림으로부터 제1 사용자의 안면 부위인 눈 부위, 코 부위, 입 부위, 이마 부위, 및 턱 부위 중 적어도 하나의 부 위의 특징점들을 추출할 수 있다. 제1 단말은 제1 사용자의 안면 특징점들을 애플리케이션의 불량 사용자 판별을 위한 학습 모델에 적용하여, 제1 사용자가 불량 사용자인지를 예측할 수 있다. 여기서, \"학습 모델\"은 애플리케이션을 사용하는 사용자들 중 불량 사용자를 검출하기 위해 이용되는 데이터 인식 모델일 수 있다. 데이터 인식 모델은, 인공 신 경망(Neural Network)을 기반으로 하는 모델일 수 있다. 예를 들면, 학습 모델은 DNN(Deep Neural Network), RNN(Recurrent Neural Network), BRDNN(Bidirectional Recurrent Deep Neural Network)과 같은 모델이 데이터 인식 모델로서 사용될 수 있으나, 이에 한정되지 않는다. \"불량 사용자 판별을 위한 학습 모델\"은, 복수의 사용자의 안면 특징점들의 분포 정보 및 복수의 사용자의 안면 특징점들의 분포 정보에 대응되는 필터링 항목의 정보를 이용하여 학습된 것일 수 있다. \"필터링 항목\"은 애플리케이션의 사용자들이 애플리케이션을 이용하면서 준수해야 하는 항목일 수 있다. 예를 들면, 필터링 항목은 성별, 나이, 신체 노출 정도, 및 욕설 빈도 중 적어도 하나를 포함할 수 있고, 이에 제한 되지 않는다. 또한, 필터링 항목의 정보는 필터링 항목에 대한 정보를 나타낸다. 예를 들면, 필터링 항목이 신 체 노출 정도이면, 필터링 항목의 정보는 사용자가 애플리케이션을 사용시에 신체 노출 수위를 나타내는 정보일 수 있다. 다른 예를 들면, 필터링 항목이 욕설 빈도이면, 필터링 항목의 정보는 사용자가 애플리케이션을 사용 시에 욕설 또는 욕설로 간주할 수 있는 행위의 빈도를 나타내는 정보일 수 있다. 또한, 욕설 빈도 정보는 사용 자가 애플리케이션을 통한 영상 통화 중에, 욕 제스처, 모욕 제스처, 인종 차별 제스처, 반사회적 컨텐츠, 반인륜적 컨텐츠, 폭력 행위 및 학대 행위 중 적어도 하나를 수행한 빈도에 의해 결정될 수 있다. 제1 단말은 소정의 필터링 항목에 대한 불량 사용자를 판별하기 위한 학습 모델을 준비할 수 있다. 여기서, 소정의 필터링 항목에 대한 불량 사용자를 판별하기 위한 학습 모델은, 인공 신경망을 통해 복수의 사 용자의 안면 특징점들의 분포 정보와 복수의 사용자의 안면 특징점들의 분포 정보에 대응되는 소정의 필터링 항 목의 정보의 상관 관계에 기초하여 학습된 것일 수 있다. 여기서, 제1 단말이 소정의 필터링 항목에 대한 불량 사용자를 판별하기 위한 학습 모델을 준비하는 과정 은 두 가지 방법이 있을 수 있다. 예를 들면, 제1 단말은 제1 단말이 직접 인공 신경망을 통해 복수의 사용자의 안면 특징점들의 분포 정보와 복수의 사용자의 안면 특징점들의 분포 정보에 대응되는 소정의 필터링 항목의 정보의 상관 관계를 학습 할 수 있다. 제1 단말은 학습 결과에 기초하여 인경 신경망을 훈련하여, 소정의 필터링 항목에 대한 불량 사용자를 판별하기 위한 학습 모델을 생성할 수 있다. 다른 예를 들면, 제1 단말은 서버로부터 소정의 필터링 항목에 대한 불량 사용자를 판별하기 위한 학 습 모델을 수신할 수 있다. 이 경우, 서버가 소정의 필터링 항목에 대한 불량 사용자 판별하기 위한 학습 모델을 생성할 수 있다. 한편, 제1 단말은 인공 신경망을 이용하여 제1 사용자의 안면 특징점들의 분포 정보를 소정의 필터링 항목 에 대한 불량 사용자를 판별하기 위한 학습 모델에 따라 학습할 수 있다. 제1 단말은 학습 결과에 기초하 여, 제1 사용자가 소정의 필터링 항목에 대한 불량 사용자인지를 예측할 수 있다. 또한, 제1 단말은 제1 영상 스트림으로부터 제1 사용자의 눈 부위, 코 부위, 입 부위, 이마 부위, 및 턱 부위 중 적어도 하나의 부위의 특징점들을 추출할 수 있다. 여기서, 제1 단말은 소정의 필터링 항목에 대 한 불량 사용자를 판별하기 위한 학습 모델에 제1 사용자의 안면 부위 중 하나의 부위에 대한 특징점들의 분포 정보를 적용하여, 제1 사용자가 불량 사용자인지를 예측할 수 있다. 또한, 제1 단말은 소정의 필터링 항목 에 대한 불량 사용자를 판별하기 위한 학습 모델에 제1 사용자의 안면 부위 중 적어도 둘 부위의 조합에 대한 특징점들의 분포 정보를 적용하여, 제1 사용자가 불량 사용자인지를 예측할 수 있다. 또한, 필터링 항목의 정보는 성별 정보, 나이 정보, 신체 노출 정보 및 욕설 빈도 정보 중 적어도 하나를 포함 할 수 있다. 여기서, 필터링 항목의 정보가 적어도 둘의 정보를 포함하면, 제1 단말은 제1 사용자의 안면 특징점들의 분포 정보를 필터링 항목 각각에 대한 불량 사용자를 판별하기 위한 학습 모델에 적용하여, 제1 사 용자가 필터링 항목 각각에 대한 불량 사용자인지를 예측할 수 있다. 소정의 필터링 항목에 대한 불량 사용자를 판별하기 위한 학습 모델을 생성하고, 생성된 학습 모델을 이용하여 소정의 필터링 항목에 대한 불량 사용자를 검출하는 방법은 도 9 내지 도 11에서 상세하게 설명한다. 제1 단말은 제1 사용자가 불량 사용자인지를 예측한 결과에 기초하여, 애플리케이션의 실행 화면 내의 컴 포넌트의 표시를 제어할 수 있다. 예를 들면, 제1 사용자가 정상 사용자인 것으로 예측되면, 제1 단말은 제1 단말과 제2 단말 사이에 수립된 영상 통화 세션을 계속하여 유지시킬 수 있다. 또한, 제1 단말은 제1 사용자가 불량 사용자인지를 실시간 또는 소정의 주기마다 반복적으로 제1 사용자를 촬영한 영상 스트림을 검사함으로써 제1 사용자가 불량 사용자인지를 판단할 수 있다. 다른 예를 들면, 제1 사용자가 불량 사용자인 것으로 예측되면, 제1 단말은 애플리케이션의 실행 화면 상 에 경고 메시지를 표시할 수 있다. 또한, 제1 단말은 애플리케이션의 실행 화면 상에서 제1 사용자가 출력 되는 영역을 모자이크 처리하여 표시할 수 있다. 또한, 제1 단말은 제1 단말과 제2 단말 사이에 수립 된 영상 통화 세션을 자동으로 종료시킬 수 있다. 도 6은 일 실시예에 따라, 사용자가 촬영된 안면 영상으로부터 안면 특징점들의 분포 정보를 획득하는 과정을 설명하기 위한 도면이다. 제1 단말은 제1 사용자를 촬영한 영상 또는 영상 스트림으로부터 제1 사용자의 안면 특징점들을 추출할 수 있다. 도 6의 610를 참고하면, 제1 단말은 제1 사용자의 영상 또는 영상 스트림으로부터 제1 사용자의 안면 부위 인 눈 부위, 코 부위, 입 부위, 이마 부위, 및 턱 부위 중 적어도 하나의 부위의 특징점들을 추출할 수 있다.도 6의 620을 참고하면, 제1 단말은 제1 사용자의 영상 또는 영상 스트림으로부터 제1 사용자의 안면 부위 의 영역만을 추출할 수 있다. 도 6의 630 및 640을 참고하면, 제1 단말은 추출된 안면 부위 영역 내의 특징점들로부터 특징 벡터를 획득 할 수 있다. 제1 단말은 안면 부위 영역을 n x n 블록으로 분할하고, 각 블록에 속한 픽셀들의 그래디언트 (gradient) 방향과 크기에 대한 히스토그램(histogram)을 획득할 수 있다. 제1 단말은 획득된 히스토그램 의 값들로부터 특징 벡터를 획득할 수 있다. 제1 단말은 특징 벡터에 기초하여, 제1 사용자의 안면 특징점 들의 분포 정보를 획득할 수 있다. 도 6에서 설명한 제1 사용자의 안면 특징점들의 분포 정보를 획득하는 방법은 일예시이고, 다른 공지된 방법에 의해서도 제1 사용자의 안면 특징점들의 분포 정보를 획득할 수 있다. 예를 들면, 제1 단말은 SIFT, HOG, Haar feature, Ferns, LBP 및 MCT 중 적어도 하나 또는 하나 이상을 조합하여, 제1 사용자의 안면 영상으로부터 제1 사용자의 안면 특징점들의 분포 정보를 획득할 수 있다. 도 7은 일 실시예에 따라, 복수의 사용자의 정보를 수집하고, 복수의 사용자의 정보를 학습하여 불량 사용자 판 별을 위한 학습 모델을 생성하는 과정을 설명하기 위한 도면이다. 본 개시에 따른 불량 사용자 판별을 위한 학습 모델을 생성 또는 업데이트 함에 있어서, 인공지능(Artificial Intelligence, AI) 시스템이 이용될 수 있다. 인공지능 시스템은 인간 수준의 지능을 구현하는 컴퓨터 기계가 스스로 학습하고 판단하여 정확도를 높여나가는 시스템이다. 인공지능 시스템은 사용할수록 반복되는 학습에 의해서 산출되는 결과의 정확도가 향상되고 사용자의 의도를 보 다 정확하게 반영할 수 있게 되어, 기존의 규정 기반 스마트 시스템은 점차 딥러닝(Deep learning) 기반 인공지 능 시스템으로 대체되고 있다. 인공지능 기술은 기계학습을 이용하는 기술이라 할 수 있으며, 딥러닝은 기계학습의 일 종류라 할 수 있다. 딥 러닝은 입력 데이터들의 특징을 스스로 분류 및 학습하는 알고리즘 기술이다. 그리고, 요소 기술은 딥러닝 등의 기계학습 알고리즘을 활용하여 인간 두뇌의 인지, 판단 등의 기능을 모사하는 기술로서, 언어적 이해, 시각적 이해, 추론/예측, 지식 표현, 동작 제어 등의 기술 분야로 구성된다. 이하에서는, 인공 신경망을 이용한 인공 지능 시스템을 적용하여, 애플리케이션의 불량 사용자 판별을 위한 학 습 모델을 생성하는 과정을 설명한다. 영상 통화 서비스를 제공하는 서버(이하, '서버'라 한다.)는 복수의 단말에서 영상 통화 서비스를 제 공하는 애플리케이션이 실행됨에 따라, 복수의 단말 각각으로부터 복수의 단말 각각에 대응되는 복수의 사용자 의 영상 스트림을 수신할 수 있다. 서버는 영상 스트림으로부터 복수의 사용자의 안면 특징점들을 추출할 수 있다. 서버는 복수의 사용 자의 안면 특징점들의 분포 정보 및 복수의 사용자의 안면 특징점들의 분포 정보에 대응되는 필터링 항목의 정 보에 기초하여, 필터링 항목에 대한 불량 사용자를 판별하기 위한 학습 모델을 생성할 수 있다. 필터링 항목의 정보는, 복수의 사용자의 성별 정보, 나이 정보, 신체 노출 정도 정보 및 욕설 빈도 정보 중 적어도 하나를 포 함할 수 있다. 예를 들면, 서버는 인공 신경망을 통한 연산을 수행하여, 복수의 사용자의 안면 특징점들의 분포 정보와 복수의 사용자의 안면 특징점들의 분포 정보에 대응되는 필터링 항목의 정보의 상관 관계를 학습할 수 있다. 서 버는 학습 결과에 기초하여 인공 신경망을 훈련하여, 필터링 항목에 대한 불량 사용자를 판별하기 위한 학 습 모델을 생성할 수 있다. 구체적으로, 서버는 인공지능 분야에서 사용되는 신경망(Neural Network)인 인공 신경망을 통해 애플리케 이션의 불량 사용자를 판별하는 학습 모델을 생성할 수 있다. 인공 신경망은 인간의 신경망과 유사한 구조를 갖 는 네트워크로써, 입력된 복수의 사용자의 안면 특징점들의 분포 정보 및 복수의 사용자의 안면 특징점들의 분 포 정보에 대응되는 필터링 항목의 정보를 복수의 레이어를 통해 연산하고, 연산된 결과 값들에 기초하여 학습 을 수행하고, 학습 결과에 따라 오차 범위를 줄임으로써, 소정의 필터링 항목에 대한 불량 사용자를 판별하기 위한 학습 모델을 생성할 수 있다. 또한, 서버는 복수의 사용자에 대해서 소정의 필터링 항목에 대한 불량 사용자 판별 이력을 학습하여, 소 정의 필터링 항목에 대한 불량 사용자를 판별하기 위한 학습 모델을 업데이트 할 수 있다. 한편, 단말에서도, 서버와 동일한 동작으로 불량 사용자를 판별하기 위한 학습 모델을 생성할 수 있다. 또 한, 단말은 서버로부터 소정의 필터링 항목에 대한 불량 사용자를 판별하기 위한 학습 모델을 수신할 수도 있다. 도 8은 일 실시예에 따라, 복수 개의 계층 구조를 갖는 인공 신경망을 개략적으로 도시한 도면이다. 도 8을 참고하면, 인공 신경망은 입력 레이어(input layer), 적어도 하나 이상의 히든 레이어(hidden layer)(820, 830) 및 출력 레이어(output layer)를 포함할 수 있다. 또한, 인공 신경망을 통한 연산은 단 말 내의 프로세서 또는 서버 내의 프로세서에서 수행될 수 있다. 또는, 단말 및 서버 는 별도의 인공 신경망을 통한 연산을 수행하기 위한 별도의 프로세서, 컨트롤러, 또는 칩을 통하여 수행 할 수도 있다. 또한, 히든 레이어(820, 830)에서 수행된 학습 및 훈련을 통해 각 레이어와 노드 사이의 가중치가 학습이 될 수 있다. 예를 들면, 단말 내의 프로세서 또는 서버 내의 프로세서는 반복적인 학습을 통하여 복수의 사용자의 안면 특징점들의 분포 정보 및 복수의 사용자의 안면 특징점들의 분포 정보에 대응되는 소정의 필터링 항목의 정보 각각에 적용되는 가중치의 값을 획득할 수 있다. 단말 내의 프로세서 또는 서버 내의 프로세서는 획득된 가중치의 값을 복수의 사용자의 안면 특징점들의 분포 정보 및 복수의 사용 자의 안면 특징점들의 분포 정보에 대응되는 소정의 필터링 항목의 정보에 다시 적용하여, 훈련된 인공 신경망 에서 소정의 항목에 대한 불량 사용자를 판별하기 위한 학습 모델을 생성할 수 있다. 도 9a는 일 실시예에 따라, 성별에 대한 불량 사용자 판별을 위한 학습 모델을 생성하는 과정을 설명하기 위한 도면이다. 도 9a의 910을 참고하면, 서버는 복수의 단말 각각으로부터 사용자의 안면을 촬영한 영상 또는 영상 스트 림을 수신할 수 있다. 또한, 서버는 복수의 단말 각각으로부터 사용자의 안면 특징점들의 분포 정보에 대 응되는 성별 정보를 수신할 수 있다. 여기서, 성별 정보는, 사용자가 남성인지 여성인지를 나타내는 정보이다. 서버는 수신된 영상 또는 영상 스트림에 기초하여, 복수의 사용자의 안면 특징점들의 분포 정보를 획득할 수 있다. 서버는 복수의 사용자의 안면 특징점들의 분포 정보 및 복수의 사용자의 안면 특징점들의 분포 정보에 대응되는 성별 정보를 서버 내의 스토리지에 저장할 수 있다. 예를 들면, 서버는 복수의 사용자 각각의 안면 특징점들의 분포 정보 및 복수의 사용자 각각이 남성인지 여성인지를 나타내는 정보를 저장할 수 있다. 여기서, 복수의 사용자 각각이 남성인지 여성인지를 나타내는 정 보는, 복수의 사용자 각각의 안면 특징점들의 분포 정보와 페어링되어 저장될 수 있다. 다른 예를 들면, 서버는 복수의 사용자 각각의 안면 특징점들의 분포 정보, 복수의 사용자 각각이 애플리 케이션에 가입 또는 로그인 시에 입력한 성별 정보, 및 복수의 사용자 각각의 실제 성별 정보를 저장할 수 있다. 또한, 서버는 복수의 사용자 각각이 애플리케이션에 가입 또는 로그인 시에 입력한 성별 정보가 복 수의 사용자 각각의 실제 성별 정보와 일치되는지에 대한 정보도 저장할 수 있다. 여기서, 복수의 사용자 각각 의 안면 특징점들의 분포 정보는, 복수의 사용자 각각이 애플리케이션에 가입 또는 로그인 시에 입력한 성별 정 보 및 복수의 사용자 각각의 실제 성별 정보와 페어링되어 저장될 수 있다. 도 9a의 920을 참고하면, 서버는 인공 신경망을 통해 스토리지에 저장된 정보를 연산 수행하여, 복수 의 사용자의 안면 특징점들의 분포 정보와 복수의 사용자의 안면 특징점들의 분포 정보에 대응되는 성별 정보의 상관 관계를 학습할 수 있다. 구체적으로, 서버는 제k 사용자의 안면 특징점들의 분포 정보와 제k 사용자 의 성별 정보의 상관 관계를 학습할 수 있다(여기서, k= 1, 2, 3, 4, 5, …..n). 즉, 서버는 입력된 안면 특징점들의 분포 정보 및 안면 특징점들의 분포 정보에 대응되는 성별 정보를 복수의 레이어를 통해 연산하고, 연산된 결과 값들에 기초하여 학습을 수행할 수 있다. 도 9a의 930을 참고하면, 서버는 학습 결과에 기초하여, 인공 신경망을 훈련하여 성별에 대한 불량 사용자 를 판별하기 위한 학습 모델을 생성할 수 있다. 즉, 서버는 학습 결과에 따라 오차 범위를 줄임으로써, 성 별에 대한 불량 사용자를 판별하기 위한 학습 모델을 생성할 수 있다. 또한, 서버는 복수의 사용자에 대해 서 성별에 대한 불량 사용자 판별 이력을 학습하여, 성별에 대한 불량 사용자를 판별하기 위한 학습 모델을 업 데이트 할 수 있다. 생성된 성별에 대한 불량 사용자를 판별하기 위한 학습 모델은, 제1 사용자의 안면 특징점 들의 분포 정보만으로 제1 사용자가 성별에 대한 불량 사용자인지를 판별할 수 있다.도 9b는 일 실시예에 따라, 성별에 대한 불량 사용자를 검출하고, 불량 사용자를 제재하는 과정을 설명하기 위 한 도면이다. 도 9b를 참고하면, 제1 단말의 제1 사용자의 애플리케이션의 회원 가입 단계에서, 제1 단말은 제1 사 용자의 성별 정보를 입력 받는 실행 화면을 표시할 수 있다. 제1 사용자는 제1 사용자의 성별 정보와 다른 성별 정보를 실행 화면 상에 입력할 수 있다. 예를 들면, 제1 사용자는 남성이지만, 제1 사용자는 성별 정보를 입력 하는 실행 화면에서 여성을 체크하여 성별 정보를 입력할 수 있다. 이후에, 제1 단말의 제1 사용자는 애플리케이션의 실행 화면 상에서 제2 단말의 사용자와 영상 통화 연결 을 위한 시도를 할 수 있다. 이 경우, 제1 단말은 제2 단말과의 영상 통화 세션을 수립하기 위해 애플리케 이션의 실행 화면에서 제1 단말의 제1 사용자의 안면 영상을 요청할 수 있다. 안면 영상의 요청에 따라, 제1 단말이 제1 사용자의 안면 영상을 획득하면, 제1 단말은 제1 사용자의 안면 영상으로부터 제1 사 용자의 안면 특징점들을 추출할 수 있다. 제1 단말은 성별에 대한 불량 사용자를 판별하기 위한 학습 모델 에 제1 사용자의 안면 특징점들의 분포 정보를 적용하여, 제1 사용자가 성별에 대한 불량 사용자임을 예측할 수 있다. 제1 단말은 예측 결과에 따라, 애플리케이션의 실행 화면 상에 경고 메시지를 표시할 수 있다. 도 9b에 도시된 바와 같이, 제1 단말은 \"개인 정보 설정에서 올바른 성별을 입력해 주세요\"와 같은 문구가 적 힌 메시지를 표시할 수 있다. 도 10a는 일 실시예에 따라, 나이에 대한 불량 사용자 판별을 위한 학습 모델을 생성하는 과정을 설명하기 위한 도면이다. 도 10a의 1010을 참고하면, 서버는 서버는 복수의 단말 각각으로부터 사용자의 안면을 촬영한 영상 또는 영상 스트림을 수신할 수 있다. 또한, 서버는 복수의 단말 각각으로부터 사용자의 안면 특징점들의 분포 정보에 대응되는 나이 정보를 수신할 수 있다. 서버는 수신된 영상 또는 영상 스트림에 기초하여, 복 수의 사용자의 안면 특징점들의 분포 정보를 획득할 수 있다. 서버는 복수의 사용자의 안면 특징점들의 분 포 정보 및 복수의 사용자의 안면 특징점들의 분포 정보에 대응되는 나이 정보를 서버 내의 스토리지에 저 장할 수 있다. 예를 들면, 서버는 복수의 사용자 각각의 안면 특징점들의 분포 정보 및 복수의 사용자 각각의 나이 정보 를 저장할 수 있다. 여기서, 복수의 사용자 각각의 나이 정보는, 복수의 사용자 각각의 안면 특징점들의 분포 정보와 페어링되어 저장될 수 있다. 다른 예를 들면, 서버는 복수의 사용자 각각의 안면 특징점들의 분포 정보 및 복수의 사용자 각각이 애플 리케이션에 가입 또는 로그인 시에 입력한 나이 정보, 및 복수의 사용자 각각의 실제 나이 정보를 저장할 수 있 다. 또한, 서버는 복수의 사용자 각각이 애플리케이션에 가입 또는 로그인 시에 입력한 나이 정보가 복수 의 사용자 각각의 실제 나이 정보와 일치되는지에 대한 정보도 저장할 수 있다. 여기서, 복수의 사용자 각각의 안면 특징점들의 분포 정보는, 복수의 사용자 각각이 애플리케이션에 가입 또는 로그인 시에 입력한 나이 정보, 및 복수의 사용자 각각의 실제 나이 정보와 페어링되어 저장될 수 있다. 도 10a의 1020을 참고하면, 서버는 인공 신경망을 통해 스토리지에 저장된 정보를 연산 수행하여, 복수의 사용자의 안면 특징점들의 분포 정보와 복수의 사용자의 안면 특징점들의 분포 정보에 대응되는 나이 정보의 상 관 관계를 학습할 수 있다. 구체적으로, 서버는 제k 사용자의 안면 특징점들의 분포 정보와 제k 사용자의 나이 정보의 상관 관계를 학습할 수 있다(여기서, k= 1, 2, 3, 4, 5, …..n). 즉, 서버는 입력된 안면 특 징점들의 분포 정보 및 안면 특징점들의 분포 정보에 대응되는 나이 정보를 복수의 레이어를 통해 연산하고, 연 산된 결과 값들에 기초하여 학습을 수행할 수 있다. 도 10a의 1030을 참고하면, 서버는 학습 결과에 기초하여, 인공 신경망을 훈련하여 나이에 대한 불량 사용 자를 판별하기 위한 학습 모델을 생성할 수 있다. 즉, 서버는 학습 결과에 따라 오차 범위를 줄임으로써, 나이에 대한 불량 사용자를 판별하기 위한 학습 모델을 생성할 수 있다. 또한, 서버는 복수의 사용자에 대 해서 나이에 대한 불량 사용자 판별 이력을 학습하여, 나이에 대한 불량 사용자를 판별하기 위한 학습 모델을 업데이트 할 수 있다. 생성된 나이에 대한 불량 사용자를 판별하기 위한 학습 모델은, 제1 사용자의 안면 특징 점들의 분포 정보만으로 제1 사용자가 나이에 대한 불량 사용자인지를 판별할 수 있다. 도 10b는 일 실시예에 따라, 나이에 대한 불량 사용자를 검출하고, 불량 사용자를 제재하는 과정을 설명하기 위 한 도면이다.도 10b를 참고하면, 제1 단말의 제1 사용자의 애플리케이션의 회원 가입 단계에서, 제1 단말은 제1 사용자의 나이 정보를 입력 받는 실행 화면을 표시할 수 있다. 제1 사용자는 제1 사용자의 나이 정보와 다른 나 이 정보를 실행 화면 상에 입력할 수 있다. 예를 들면, 제1 사용자는 7세이지만, 제1 사용자는 성별 정보를 입 력하는 실행 화면에서 22세로 입력하여 나이 정보를 입력할 수 있다. 이후에, 제1 단말의 제1 사용자는 애플리케이션의 실행 화면 상에서 제2 단말의 사용자와 영상 통화 연결 을 위한 시도를 할 수 있다. 이 경우, 제1 단말은 제2 단말과의 영상 통화 세션을 수립하기 위해 애플리케 이션의 실행 화면에서 제1 단말의 제1 사용자의 안면 영상을 요청할 수 있다. 안면 영상의 요청에 따라, 제1 단말이 제1 사용자의 안면 영상을 획득하면, 제1 단말은 제1 사용자의 안면 영상으로부터 제1 사 용자의 안면 특징점들을 추출할 수 있다. 제1 단말은 나이에 대한 불량 사용자를 판별하기 위한 학습 모델 에 제1 사용자의 안면 특징점들의 분포 정보를 적용하여, 제1 사용자가 나이에 대한 불량 사용자임을 예측할 수 있다. 제1 단말은 예측 결과에 따라, 애플리케이션의 실행 화면 상에 경고 메시지를 표시할 수 있다. 도 10b에 도시된 바와 같이, 제1 단말은 \"개인 정보 설정에서 올바른 나이를 입력해 주세요\"와 같은 문구가 적힌 메시지를 표시할 수 있다. 도 11a는 일 실시예에 따라, 신체 노출 또는 언행에 대한 불량 사용자 판별을 위한 학습 모델을 생성하는 과정 을 설명하기 위한 도면이다. 도 11a의 1110을 참고하면, 서버는 서버는 복수의 단말 각각으로부터 사용자의 안면을 촬영한 영상 또는 영상 스트림을 수신할 수 있다. 또한, 서버는 복수의 단말 각각으로부터 사용자의 안면 특징점들의 분포 정보에 대응되는 신체 노출 정도 정보 또는 욕설 빈도 정보를 수신할 수 있다. 여기서, 신체 노출 정도 정 보 또는 욕설 빈도 정보는 복수의 단말 각각에서 애플리케이션의 실행에 따라 사용자로부터 획득된 정보일 수 있다. 한편, 서버는 수신된 영상 또는 영상 스트림에 기초하여, 복수의 사용자의 안면 특징점들의 분포 정 보를 획득할 수 있다. 서버는 복수의 사용자의 안면 특징점들의 분포 정보 및 복수의 사용자의 안면 특징 점들의 분포 정보에 대응되는 신체 노출 정도 정보 또는 욕설 빈도 정보를 서버 내의 스토리지에 저장할 수 있다. 예를 들면, 서버는 복수의 사용자 각각의 안면 특징점들의 분포 정보, 및 복수의 사용자 각각이 상대방과 영상 통화를 수행하는 동안, 신체 노출 정도 정보 또는 욕설 빈도 정보를 저장할 수 있다. 여기서, 복수의 사용 자 각각의 신체 노출 정도 정보 또는 욕설 빈도 정보는, 복수의 사용자 각각의 안면 특징점들의 분포 정보와 페 어링되어 저장될 수 있다. 도 11a의 1120을 참고하면, 서버는 인공 신경망을 통해 스토리지에 저장된 정보를 연산 수행하여, 복수의 사용자의 안면 특징점들의 분포 정보와 복수의 사용자의 안면 특징점들의 분포 정보에 대응되는 신체 노출 정도 정보 또는 욕설 빈도 정보의 상관 관계를 학습할 수 있다. 구체적으로, 서버는 제k 사용자의 안면 특징점 들의 분포 정보와 제k 사용자의 신체 노출 정도 정보 또는 욕설 빈도 정보의 상관 관계를 학습할 수 있다(여기 서, k= 1, 2, 3, 4, 5, …..n). 즉, 서버는 입력된 안면 특징점들의 분포 정보 및 안면 특징점들의 분포 정보에 대응되는 신체 노출 정도 정보 또는 욕설 빈도 정보를 복수의 레이어를 통해 연산하고, 연산된 결과 값 들에 기초하여 학습을 수행할 수 있다. 도 11a의 1130을 참고하면, 서버는 학습 결과에 기초하여, 인공 신경망을 훈련하여 신체 노출 또는 욕설에 대한 불량 사용자를 판별하기 위한 학습 모델을 생성할 수 있다. 즉, 서버는 학습 결과에 따라, 오차 범위 를 줄임으로써, 신체 노출 또는 욕설에 대한 불량 사용자를 판별하기 위한 학습 모델을 생성할 수 있다. 또한, 서버는 복수의 사용자에 대해서 신체 노출 또는 욕설에 대한 불량 사용자 판별 이력을 학습하여, 신체 노 출 또는 욕설에 대한 불량 사용자를 판별하기 위한 학습 모델을 업데이트 할 수 있다. 생성된 신체 노출 또는 욕설에 대한 불량 사용자를 판별하기 위한 학습 모델은, 제1 사용자의 안면 특징점들의 분포 정보만으로 제1 사 용자가 신체 노출 또는 욕설에 대한 불량 사용자인지를 판별할 수 있다. 도 11b 및 도 11c는 일 실시예에 따라, 신체 노출에 대한 불량 사용자를 검출하고, 불량 사용자를 제재하는 과 정을 설명하기 위한 도면이다. 도 11b를 참고하면, 제1 사용자의 제1 단말(100-1)은 제2 사용자의 제2 단말(100-2)과의 영상 통화 세션을 수립 할 수 있다. 제1 단말(100-1) 및 제2 단말(100-2) 각각은 영상 통화 세션을 수립하기 위해 애플리케이션의 실행 화면에서 안면 영상을 요청할 수 있다. 한편, 제2 사용자는 애플리케이션의 사용시에 신체 노출 수위가 애플리 케이션에서 결정된 신체 노출 기준 수위 보다 높다고 가정한다. 안면 영상의 요청에 따라, 제2 단말(100-2)이제2 사용자의 안면 영상을 획득하면, 제2 단말(100-2)은 제2 사용자의 안면 영상으로부터 제2 사용자의 안면 특 징점들을 추출할 수 있다. 제2 단말(100-2)은 신체 노출에 대한 불량 사용자를 판별하기 위한 학습 모델에 제2 사용자의 안면 특징점들의 분포 정보를 적용하여, 제2 사용자가 신체 노출에 대한 불량 사용자 임을 예측할 수 있다. 도 11c에 도시된 바와 같이, 제2 단말(100-2)은 애플리케이션의 실행 화면 상에 \"복장을 제대로 갖추시기 바랍 니다. 상대방에게 불쾌감을 줄 수 있습니다.\"와 같은 경고 메시지를 표시할 수 있다. 또한, 제2 단말(100-2)은 영상 통화 세션을 자동으로 종료시키면서, 애플리케이션의 실행 화면 상에 \"상대방과의 영상 통화를 종료합니다. 이용해 주셔서 감사합니다.\"와 같은 경고 메시지를 표시할 수도 있다. 또한, 제2 단말(100-2)은 애 플리케이션의 실행 화면 상에서 제2 사용자가 출력되는 영역을 모자이크 처리하여 표시할 수 있다. 마찬가지로, 제1 단말(100-1)도 애플리케이션의 실행 화면 상에서 제2 사용자가 출력되는 영역을 모자이크 처리하여 표시할 수 있다. 또한, 제2 단말(100-2)은 제2 사용자가 신체 노출에 대한 불량 사용자 임을 예측한 후 바로, 제2 단말(100-2)에 서의 애플리케이션의 실행을 제재하지 않고, 제2 사용자의 행위를 모니터링 하고, 모니터링 결과에 기초하여 제 2 단말(100-2)에서의 애플리케이션의 실행을 제재할 수 있다. 도 12는 일 실시예에 따라, 사용자의 안면 특징점들의 분포 정보를 이용하여 영상 통화 서비스를 제공하는 방법 을 설명하기 위한 흐름도이다. 블록 S1210에서, 제1 단말에서 영상 통화 서비스를 제공하는 애플리케이션이 실행됨에 따라, 제1 단말 은 제1 단말의 제1 사용자를 촬영한 제1 영상 스트림을 수신할 수 있다. 블록 S1220에서, 제1 단말은 제1 영상 스트림으로부터 제1 사용자의 안면 특징점들을 추출할 수 있다. 블록 S1230에서, 제1 단말은 복수의 사용자의 안면 특징점들에 기초한 불량 사용자 판별을 위한 학습 모델 에 제1 사용자의 안면 특징점들의 분포 정보를 적용하여, 제1 사용자가 불량 사용자인지를 예측할 수 있다. 블록 S1240에서, 제1 단말은 예측 결과에 기초하여, 애플리케이션의 실행 화면 내의 컴포넌트의 표시를 제 어할 수 있다. 한편, 상술한 영상 통화 서비스를 제공하는 방법에 관한 실시예들은 영상 통화 서비스를 제공하는 제1 단말 에서, 사용자의 안면 특징점들의 분포 정보를 이용하여 영상 통화 서비스를 제공하는 방법을 수행할 수 있 도록 컴퓨터 판독가능 저장매체에 저장된 애플리케이션 형태 또는 컴퓨터 프로그램 형태로 제공될 수 있다. 다 시 말해서, 제1 단말로 하여금 상술한 영상 통화 서비스를 제공하는 방법의 각 단계는 실행시키기 위한 컴 퓨터 판독가능 저장매체에 저장된 애플리케이션 또는 컴퓨터 프로그램 형태로 제공될 수 있다. 도 13은 일 실시예에 따라, 복수의 사용자의 안면 특징점들을 이용하여 불량 사용자를 판별하기 위한 학습 모델 을 생성하는 방법을 설명하기 위한 흐름도이다. 블록 1310에서, 서버는 복수의 단말에서 영상 통화 서비스를 제공하는 애플리케이션이 실행됨에 따라, 복 수의 단말 각각으로부터 복수의 단말 각각에 대응되는 복수의 사용자의 영상 스트림을 수신할 수 있다. 블록 1320에서, 서버는 영상 스트림으로부터 복수의 사용자의 안면 특징점들을 추출할 수 있다. 블록 1330에서, 서버는 복수의 사용자의 안면 특징점들의 분포 정보 및 복수의 사용자의 안면 특징점들의 분포 정보에 대응되는 필터링 항목의 정보에 기초하여, 필터링 항목에 대한 불량 사용자를 판별하기 위한 학습 모델을 생성할 수 있다. 블록 1340에서, 서버는 학습 모델을 복수의 단말로 전송할 수 있다. 한편, 상술한 영상 통화 서비스를 제공하는 방법에 관한 실시예들은, 영상 통화 서비스를 제공하는 서버에 서, 복수의 사용자의 안면 특징점들을 이용하여 불량 사용자를 판별하기 위한 학습 모델을 생성하는 방법을 수 행할 수 있도록 컴퓨터 판독가능 저장매체에 저장된 컴퓨터 프로그램 형태로 제공될 수 있다. 다시 말해서, 서 버로 하여금 상술한 영상 통화 서비스를 제공하는 방법의 각 단계는 실행시키기 위한 컴퓨터 판독가능 저 장매체에 저장된 애플리케이션 또는 컴퓨터 프로그램 형태로 제공될 수 있다."}
{"patent_id": "10-2017-0173116", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "이상과 같이 실시예들이 비록 한정된 실시예와 도면에 의해 설명되었으나, 해당 기술분야에서 통상의 지식을 가 진 자라면 상기의 기재로부터 다양한 수정 및 변형이 가능하다. 예를 들어, 설명된 기술들이 설명된 방법과 다른 순서로 수행되거나, 및/또는 설명된 시스템, 구조, 장치, 회로 등의 구성요소들이 설명된 방법과 다른 형태 로 결합 또는 조합되거나, 다른 구성요소 또는 균등물에 의하여 대치되거나 치환되더라도 적절한 결과가 달성될 수 있다. 그러므로, 본 발명의 범위는 설명된 실시예에 국한되어 정해져서는 아니 되며, 후술하는 특허청구범위뿐 아니라 이 특허청구범위와 균등한 것들에 의해 정해져야 한다."}
{"patent_id": "10-2017-0173116", "section": "도면", "subsection": "도면설명", "item": 1, "content": "본 발명은, 다음의 자세한 설명과 그에 수반되는 도면들의 결합으로 쉽게 이해될 수 있으며, 참조 번호 (reference numerals)들은 구조적 구성요소(structural elements)를 의미한다. 도 1은 영상 통화 서비스가 제공되는 환경을 설명하기 위한 도면이다. 도 2는 일 실시예에 따른 단말의 구성을 나타낸 블록도이다. 도 3은 일 실시예에 따른 영상 통화 서비스를 제공하는 서버의 구성을 나타낸 블록도이다. 도 4는 다른 실시예에 따른 영상 통화 서비스를 제공하는 서버가 복수 개의 분산 서버들로 구현된 모습을 설명 하기 위한 도면이다. 도 5는 일 실시예에 따라, 사용자의 안면 특징점들을 이용하여 사용자가 불량 사용자인지를 예측하는 과정을 설 명하기 위한 도면이다. 도 6은 일 실시예에 따라, 사용자가 촬영된 안면 영상으로부터 안면 특징점들의 분포 정보를 획득하는 과정을 설명하기 위한 도면이다. 도 7은 일 실시예에 따라, 복수의 사용자의 정보를 수집하고, 복수의 사용자의 정보를 학습하여 불량 사용자 판 별을 위한 학습 모델을 생성하는 과정을 설명하기 위한 도면이다. 도 8은 일 실시예에 따라, 복수 개의 계층 구조를 갖는 인공 신경망을 개략적으로 도시한 도면이다. 도 9a는 일 실시예에 따라, 성별에 대한 불량 사용자 판별을 위한 학습 모델을 생성하는 과정을 설명하기 위한 도면이다. 도 9b는 일 실시예에 따라, 성별에 대한 불량 사용자를 검출하고, 불량 사용자를 제재하는 과정을 설명하기 위 한 도면이다. 도 10a는 일 실시예에 따라, 나이에 대한 불량 사용자 판별을 위한 학습 모델을 생성하는 과정을 설명하기 위한 도면이다. 도 10b는 일 실시예에 따라, 나이에 대한 불량 사용자를 검출하고, 불량 사용자를 제재하는 과정을 설명하기 위 한 도면이다. 도 11a는 일 실시예에 따라, 신체 노출 또는 언행에 대한 불량 사용자 판별을 위한 학습 모델을 생성하는 과정 을 설명하기 위한 도면이다. 도 11b 및 도 11c는 일 실시예에 따라, 신체 노출에 대한 불량 사용자를 검출하고, 불량 사용자를 제재하는 과 정을 설명하기 위한 도면이다. 도 12는 일 실시예에 따라, 사용자의 안면 특징점들의 분포 정보를 이용하여 영상 통화 서비스를 제공하는 방법 을 설명하기 위한 흐름도이다.도 13은 일 실시예에 따라, 복수의 사용자의 안면 특징점들을 이용하여 불량 사용자를 판별하기 위한 학습 모델 을 생성하는 방법을 설명하기 위한 흐름도이다."}
