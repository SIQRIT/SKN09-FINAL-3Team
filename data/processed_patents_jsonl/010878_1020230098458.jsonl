{"patent_id": "10-2023-0098458", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2025-0017563", "출원번호": "10-2023-0098458", "발명의 명칭": "가려짐에 강인한 이미지 복원 기반 얼굴 감정 인식 시스템", "출원인": "전남대학교산학협력단", "발명자": "유석봉"}}
{"patent_id": "10-2023-0098458", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "3차원 공간 내 설정된 하나 이상의 지점 각각에 설치되는 촬영 장치에서 촬영된 영상으로부터 사용자의 얼굴 일부를 가리는 물체로 인한 가려진 영역 탐지하는 가려짐 판단부;상기 가려진 영역을 복원하는 영상 복원부; 및상기 영상 복원부의 영상에서 얼굴 정보로부터 입력된 이미지의 표정을 인식하고, 추출된 표정 관련 정보를 분석하는 표정 인식부;를 포함하는 것을 특징으로 하는 가려짐에 강인한 이미지 복원 기반 얼굴 감정 인식시스템."}
{"patent_id": "10-2023-0098458", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 가려짐 판단부는 상기 촬영장치에서 촬영된 영상을 패치단위로 나눈 뒤 얼굴과 무관한 비정상 패치에 대하여 마스크 처리를 하여 상기 사용자의 얼굴을 가리는 영역을 마스킹하는 것을 특징으로 하는 가려짐에 강인한이미지 복원 기반 얼굴 감정 인식 시스템."}
{"patent_id": "10-2023-0098458", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 영상 복원부는 가려짐 판단부의 결과로부터 얼굴의 좌우 대칭성을 활용해 딥러닝 기반의 이미지 복원을 수행하는 것을 특징으로 하는 가려짐에 강인한 이미지 복원 기반 얼굴 감정 인식 시스템."}
{"patent_id": "10-2023-0098458", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,상기 표정인식부는 Latent code로부터 추출된 표정 관련 정보와 복원된 이미지로부터 추출된 표정 관련 정보를결합하여 학습하는 것을 특징으로 하는 가려짐에 강인한 이미지 복원 기반 얼굴 감정 인식 시스템."}
{"patent_id": "10-2023-0098458", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서,상기 표정인식부는 표정과 관련이 있는 Latent code만 추출하여 표정을 인식하는 것을 특징으로 하는 가려짐에강인한 이미지 복원 기반 얼굴 감정 인식 시스템."}
{"patent_id": "10-2023-0098458", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "가려짐에 강인한 이미지 복원 기반 얼굴 감정 인식 시스템을 이용한 방법에 있어서,(a)상기 얼굴 감정 인식 시스템이 3차원 공간 내 설정된 하나 이상의 지점 각각에 설치되는 촬영 장치에서 촬영된 영상으로부터 사용자의 얼굴 일부를 가리는 물체로 인한 가려진 영역 탐지하는 단계;(b)상기 얼굴 감정 인식 시스템이 가려진 영역을 복원하는 단계; 및(c)상기 얼굴 감정 인식 시스템이 상기 (b)단계에서 복원한 영상에서 얼굴 정보로부터 입력된 이미지의 표정을인식하고, 추출된 표정 관련 정보를 분석하는 표정 인식단계;를 포함하는 것을 특징으로 하는 가려짐에 강인한이미지 복원 기반 얼굴 감정 인식방법."}
{"patent_id": "10-2023-0098458", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명은 가려짐에 강인한 이미지 복원 기반 얼굴 감정 인식 시스템에 관한 것으로, 가려진 얼굴을 복원하는 생 성모델 기반 얼굴 감정 인식 기술에 관한 것이다. 본 발명에 따른 가려짐에 강인한 이미지 복원 기반 얼굴 감정 인식 시스템은 카메라를 통해 사용자의 이미지를 전달하는 데이터 수집부, 딥러닝 네트워크를 이용한 영상 내 가 려짐 판단부, 가려진 영역 복원부, 사용자의 표정을 인식하는 표정 인식부를 포함하여, 표정 인식이 불리한 가려 짐으로 인한 표정 인식을 방해하는 요소를 가려짐이 없게 재구성하여 잠재공간 내에 표정 인식에 유리한 정보만 사용하여 훈련된 딥러닝 사전 훈련 모델을 통해 표정을 추론할 수 있고, 사용자의 얼굴에 가려짐을 인식하여, 가 려짐이 있다면 hybrid reconstruction 모델을 통해 가려짐이 없는 이미지로 재생성하고 객체의 감정을 인식할 수 있는 효과가 있다."}
{"patent_id": "10-2023-0098458", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 가려짐에 강인한 이미지 복원 기반 얼굴 감정 인식 시스템에 관한 것으로, 더욱 상세하게는 가려진 얼굴을 복원하는 생성모델 기반 얼굴 감정 인식 기술에 관한 것이다."}
{"patent_id": "10-2023-0098458", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "컴퓨터 비전 분야에서 표정인식이란 가장 수요가 많고 큰 활용 가능성이 있는 분야 중 하나이다. 이러한 표정인 식 기술은 인간의 표정을 인식하고 해당 표정을 분석하여 감정을 추론하는 데 사용된다. 표정인식 기술은 다양 한 응용 분야에서 활용되고 있으며, 예를 들어 감정 인터페이스, 마케팅, 보안, 의료 등에 적용될 수 있다. 이러한 표정인식 기술은 일반적으로 정제된 환경 속 이미지에서 가장 좋은 성능을 보장한다. 즉, 이미지나 비디 오가 좋은 조명 조건, 각도 및 해상도를 갖추고, 얼굴이 완전히 노출되어 있고 가려지는 요소가 없는 경우에 성 능이 높다. 그러나 실제 사용자 환경에서는 다양한 도전과제가 있다. 예를 들어, 손, 물병, 모자, 안경과 같은 다른 물체에 의해 얼굴이 가려질 수 있다. 이러한 가려짐은 얼굴의 특징을 왜곡하거나 일부를 누락시킬 수 있으며, 표정 분 석에 오류를 초래할 수 있다. 또한, 조명 조건의 변화로 인해 얼굴이 어둡게 비춰질 수 있고, 사용자가 다양한 각도로 얼굴을 비추는 경우 얼 굴의 특징이 왜곡될 수 있다. 이러한 상황에서 표정인식 기술의 성능은 저하될 수 있다. 도 1은 얼굴 이미지의 가려짐 유형과 비율에 따른 표정 인식 네트워크의 성능 하락 기조에 대한 결과 그래프이 다. 도 1은 다양한 폐색 비율에 대한 얼굴 표정 인식(FER, Facial expression recognition)에 대한 정확도를 나타낸다. 얼굴 표정을 인식하는 전형적인 모델의 두 가지 유형의 오클루전인 무작위 증폭 오클루전(Random occlusion)과 그래드 오클루전(Grad occlusion)의 견고성을 평가했다. 랜덤 샘플링 오클루전은 전체 이미지를 196개의 패치로 나누고 비율에 따라 무작위로 마스크한다. Grad occlusion은 Grad-Cam(Grad-CAM)을 사용하여 FER에 영향을 주 는 의도적으로 가려진 영역이 있는 이미지를 처리한다. 이는 특히 폐색(가려짐) 영역이 정확한 FER에 중요한 경 우 두 번째 유형의 폐색으로 성능이 더 크게 감소함을 보여준다. 이 결과는 기계 학습 또는 인공지능 모델의 성 능을 평가하는 데 사용되는 지표 중 하나로, 모델이 주어진 데이터셋에서 얼마나 정확하게 예측하는지를 나타내 는 Accuracy를 통해 객관적으로 측정되었다. 이는 가려짐으로 인해 얼굴 랜드마크를 감지할 수 없어 FER 프로세스에서 오류가 발생할 수 있다. 종래에는 하 나는 가려지지 않은 이미지에 대해 훈련되고 다른 하나는 가려진 이미지에 대해 훈련하는 방식으로 하는 별개의 네트워크를 사용한다. 이 접근 방식은 가려지지 않은 이미지를 특권 정보로 활용하여 폐색(occlusion)이 있는 경우 표현 인식을 지원한다. 이는 가려진 이미지와 가려지지 않은 이미지를 구별할 수 없기 때문에 실제 상황에 서는 적합하지 않다. 그러므로 컴퓨터 비전 분야에서 표정인식은 좋은 성능을 어느 정도 보장하고 있으나 이는 정제된 환경 속 이미 지에서의 성능일 뿐 실제 사용자 환경에서 손, 물병 등 다양한 물체에 의한 가려짐과 같은 상황에서는 큰 성능 하락이 발생한다. 선행기술문헌 특허문헌 (특허문헌 0001) 공개특허 10-2018-0108361(2018.10.04 공개)"}
{"patent_id": "10-2023-0098458", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 발명은 상술한 문제를 해결하고자, 표정 인식이 불리한 가려짐으로 인한 표정 인식을 방해하는 요소를 가려 짐이 없게 재구성하여 잠재공간 내에 표정 인식에 유리한 정보만 사용하여 훈련된 딥러닝 사전 훈련 모델을 통 해 표정을 추론하기 위한 가려짐에 강인한 이미지 복원 기반 얼굴 감정 인식 시스템을 제공함에 목적이 있다. 또한 실제 사용자의 환경에 맞추어 사람 이미지로부터 표정 인식을 통해 다양한 서비스를 제공하기 위함에도 있다."}
{"patent_id": "10-2023-0098458", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명은 3차원 공간 내 설정된 하나 이상의 지점 각각에 설치되는 촬영 장치에서 촬영된 영상으로부터 사용자 의 얼굴 일부를 가리는 물체로 인한 가려진 영역 탐지하는 가려짐 판단부; 상기 가려진 영역을 복원하는 영상 복원부; 및 상기 영상 복원부의 영상에서 얼굴 정보로부터 입력된 이미지의 표정을 인식하고, 추출된 표정 관련 정보를 분석하는 표정 인식부;를 포함한다. 바람직하게 가려짐 판단부는 상기 촬영장치에서 촬영된 영상을 패치단위로 나눈 뒤 얼굴과 무관한 비정상 패치 에 대하여 마스크 처리를 하여 상기 사용자의 얼굴을 가리는 영역을 마스킹한다. 또한 영상 복원부는 가려짐 판단부의 결과로부터 얼굴의 좌우 대칭성을 활용해 딥러닝 기반의 이미지 복원을 수 행한다. 표정인식부는 Latent code로부터 추출된 표정 관련 정보와 복원된 이미지로부터 추출된 표정 관련 정보를 결합 하여 학습한다. 또한 표정인식부는 표정과 관련이 있는 Latent code만 추출하여 표정을 인식한다. 한편, 가려짐에 강인한 이미지 복원 기반 얼굴 감정 인식 시스템을 이용한 방법에 있어서, (a)상기 얼굴 감정 인식 시스템이 3차원 공간 내 설정된 하나 이상의 지점 각각에 설치되는 촬영 장치에서 촬영된 영상으로부터 사 용자의 얼굴 일부를 가리는 물체로 인한 가려진 영역 탐지하는 단계; (b)상기 얼굴 감정 인식 시스템이 가려진 영역을 복원하는 단계; 및 (c)상기 얼굴 감정 인식 시스템이 상기 (b)단계에서 복원한 영상에서 얼굴 정보로부 터 입력된 이미지의 표정을 인식하고, 추출된 표정 관련 정보를 분석하는 표정 인식단계;를 포함한다."}
{"patent_id": "10-2023-0098458", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명에 따르면, 표정 인식이 불리한 가려짐으로 인한 표정 인식을 방해하는 요소를 가려짐이 없게 재구성하 여 잠재공간 내에 표정 인식에 유리한 정보만 사용하여 훈련된 딥러닝 사전 훈련 모델을 통해 표정을 추론할 수 있고, 사용자의 얼굴에 가려짐을 인식하여, 가려짐이 있다면 hybrid reconstruction 모델을 통해 가려짐이 없는 이미지로 재생성하고 객체의 감정을 인식할 수 있는 효과가 있다."}
{"patent_id": "10-2023-0098458", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명은 Vit-CNN을 결합한 모델을 활용하여 가려짐이 있는 입력 이미지의 표정을 유지한 채 가려짐이 없는 이 미지로 재생성을 한다. 이 과정에서 추출된 ViT기반 잠재공간에서 표정과 관련이 있는 정보를 추출하여 활용함 으로써, 가려짐에 강인한 이미지 복원 기반 얼굴 감정 인식 시스템에 관한 것이다. 본 발명의 일 실시예에 따른 가려짐에 강인한 이미지 복원 기반 얼굴 감정 인식 시스템은 폐색 과정을 통해 폐 색된 이미지를 완전한 이미지로 변환하는 것을 목표로 하는 폐색 복구 기반 접근 방식이다. 여기서, 폐색(Occlusion)은 어떤 물체나 요소가 다른 물체를 가리는 현상을 의미한다. 이는 컴퓨터 비전 분야에 서 특히 얼굴이나 물체의 일부가 다른 물체에 의해 가려져서 인식이 어려워지는 상황을 가리킨다. 예를 들어, 손이나 다른 사물이 얼굴의 일부를 가리는 경우, 이는 폐색으로 간주될 수 있다. 본 실시예를 설명함에 있어서, 설명상의 편의를 위해 폐색 또는 가려짐으로 병행하여 표현하였지만, 어떤 물체나 요소가 다른 물체를 가리는 현상을 의미한다. 도 2는 본 발명의 일 실시예에 따른 표정 인식 시스템의 구성을 나타낸 블록도이다. 도 2에 도시된 바와 같이, 본 발명의 일 실시예에 따른 가려짐에 강인한 이미지 복원 기반 얼굴 감정 인식 시스템은 촬영장치, 데이 터 수집부, 가려짐 판단부, 영상 복원부, 표정 인식부를 포함한다. 데이터 수집부는 3차원 공간 내 설정된 하나 이상의 지점 각각에 설치되는 촬영 장치에서 촬영된 영 상을 수집하기 위한 구성이다. 이러한 데이터 수집부는 사용자가 원하는 객체의 얼굴이 포함된 얼굴 전체 이미 지를 입력 데이터로 수신하고 PC, 스마트 폰 내에 내장되어있는 카메라를 통해 사용자의 얼굴 전체 이미지를 입 력으로 받을 수 있다. 가려짐 판단부는 3차원 공간 내 설정된 하나 이상의 지점 각각에 설치되는 촬영 장치에서 촬영된 영상으로 부터 사용자의 얼굴 일부를 가리는 물체로 인한 가려진 영역 탐지하기 위한 구성이다. 이러한 가려짐 판단부는 데이터 수집부를 통해 이미지 입력을 받는다. 이후 데이터 처리부를 통해 이미지 내에 서 얼굴을 가리는 물체가 있는지 판단하고, 얼굴 일부가 가려진다면 해당 영역을 마스킹한다. 이때, 가려짐 판단부는 영상을 패치단위로 나눈 뒤 얼굴과 무관한 비정상 패치에 대하여 마스크 처리한다. 이러 한 가려짐 판단부가 사용자의 얼굴을 가리는 영역을 마스킹한다. 영상 복원부는 가려진 영역을 복원하기 위한 구성이다. 영상 복원부는 얼굴 복원 절차를 거쳐 마스킹한 영역을 채움으로써 자연스러운 얼굴 이미지로 복원한 다음, 표 정 인식부에서 표정을 인식하도록 한다. 영상 복원부의 영상 복원에 있어서, 가려짐 판단부의 결과로부터 얼굴의 좌우 대칭성을 활용해 정상 얼굴로 복 원하는 딥러닝 기반의 이미지 복원을 수행한다. 표정 인식부는 영상 복원부의 영상에서 얼굴 정보로부터 입력된 이미지의 표정을 인식하고, 추출된 표정 관련 정보를 분석하여 표정을 인식한다. 표정을 인식하는 방법은 GAN encoder를 통해 입력 이미지의 Latent code를 추출하고 표정과 연관성이 큰 정보를 선별한 후 결과와 최종 복원한 이미지를 합성곱 신경망으로 추출한 특징을 결합하고, 이를 학습하여 표정을 인식한다. 본 실시예에 따른 표정 인식부는 Latent code로부터 추출된 표정 관련 정보와 복원된 이미지로부터 추출된 표정 관련 정보를 결합하여 학습함으로써, 성능을 높일 수 있는 효과가 있다. 이때, 표정 인식부는 표정과 관련이 있 는 Latent code만 추출함으로써 성능을 Latent code 높인 딥러닝 기반의 표정 인식 방법을 수행한다. 본 발명의 일 실시예에 따른 가려짐에 강인한 이미지 복원 기반 얼굴 감정 인식 시스템은 치안, 방범을 목적으 로 설치한 CCTV속에서 객체의 얼굴이 가려진 경우 객체의 표정인식, 온라인 수업중 참여자의 집중도를 표정을 통해 파악이 가능하다. 또한 얼굴이미지 복원 기능을 통해 사진 복원에 활용 가능하다. 도 3은 본 발명의 일 실시예에 따른 표정 인식 알고리즘을 통해 입력 이미지의 표정 인식 방법의 동작을 도시한 순서도이다. 도 3에 도시된 바와 같이, 촬영장치를 통해 데이터 수집부에서 얼굴이 포함된 그림 이미 지를 수신한다(S2). 다음으로 데이터 수집부에서는 수신한 이미지에서 얼굴 위치에 대한 전처리를 수행한다(S4). 다음으로 가려짐 판단부는 이미지를 패치 단위로 분할 후, 가려짐 판단과 가려진 영역 마스킹을 한다(S6). 다음으로 영상 복원부는 마스킹 영역 복원(S8), 입력 이미지로부터 합성곱 신경망을 통해 표정 관련 특징 을 추출한다(S10). 영상 복원부는 (S8)과 (S10)과 병렬적으로 GAN encoder를 통해 입력이미지를 Latent code로 변환(S12)하 고, Latent code로부터 완전 연결층을 통해 표정 관련 특징을 추출한다(S14). 다음으로 표정 인식부는 S10와, S14에서 추출한 특징 융합 기반으로 표정을 인식한다. 도 4는 본 발명의 일 실시예에 따른 표정 인식을 위한 상세 구조를 나타낸 블록도이다. 도 4에서, 폐색을 지우 는 폐색 해제 이미지를 생성하는 Latent-OFER의 프레임워크를 나타낸 것이다. 이 과정에서 ViT(Vision Transformer)-latent vector와 CNN(Convolutional Neural Network) 클래스 활성화 맵을 매핑하여 표정 관련 latent 벡터를 추출한다. Latent-OFER는 CNN 기반 기능과 특정 VIT 기반 잠재 벡터를 결합한 얼굴 표정을 예측 한다. 도 4에서 볼 수 있듯이, 본 실시예에서는 얼굴 표정을 인식하기 위해 폐색을 감지, 마스킹 및 재구성하는 것과 관련된 OFER을 해결하기 위한 다단계 접근 방식을 제안한다. 제안하는 접근 방식은 이미지 재구성 과정에서 추 출한 ViT-latent vector와 기존 CNN 특징의 협력 학습을 통해 인식 정확도를 높인다. 본 실시예에 따른 가려짐에 강인한 이미지 복원 기반 얼굴 감정 인식 시스템은 얼굴 이미지를 패치로 나누고 각 패치를 폐색 또는 폐색되지 않은 것으로 분류하며, 폐색된 패치를 폐색 해제하도록 재구성한다. 그 후 재구성된 이미지와 표정 관련 잠재 벡터를 활용하여 얼굴표정을 예측한다. 도 5는 본 발명의 가려짐 판단부에서 가려짐을 처리하는 과정을 나타낸 블록도이다. 이미지를 (16*16) 패치 단 위로 분할 후 단일 클래스 분류 네트워크를 통해 얼굴에 해당하지 않는 비정상 패치를 선별한 뒤 마스킹한다. 도 6은 본 발명의 가려짐 복원부의 기작을 나타내는 이미지이다. 어두운 영역이 마스킹되어 복원해야할 영역을 나타내며 결과 이미지의 자연스러움을 위해 이전에 생성한 패치와, 얼굴의 대칭성을 활용한 수평 대칭 위치에 있는 패치, 주의 메커니즘을 통한 가장 유사한 패치 3가지를 고려하여 패치를 생성하는 예시이다. 이러한 도 6에서는 자체 조립 작업의 이미지로, (a) 자체 조립 레이어의 기능 맵과, (b) (a)의 뒤집기를 포함하 여, 마스킹된 영역의 패치는 3개의 패치 정보를 결합하여 생성된다. 도 7은 본 발명의 표정 인식부의 상세 구성을 나타낸 블록도이다. 본 실시예에서는 얼굴 이미지 재구성을 위한 deocclusive autoencoder를 제안한다. Deocclusive Autoencoder는 기능적으로 Occlusion Detector와 Reconstruction Module로 나눌 수 있다. 폐색 감지를 위한 재구성 모듈에 ViT(Vision Transformer) SVDD(Support Vector Data Description)를 사용한다. 이 접근 방식을 통해 모델은 보 이지 않는 물체로 인한 폐색을 감지할 수 있으며, 이는 폐색 해제된 얼굴 이미지를 정확하게 생성하는 데 필수 적인 단계이다. 재구성 네트워크는 얼굴 영상 재구성을 위한 ViT 구조와 CNN(Convolutional Neural Network) 구조로 구성된다. 본 실시예에서는 다양한 포즈에도 불구하고 사실적인 얼굴 이미지를 생성하는 ViT의 강점을 활용하고 CNN을 사 용하여 이를 더욱 세분화한다. 본 실시예에서는 그것을 하이브리드 재구성 네트워크라고 한다. 하이브리드 재구성 네트워크는 상세하고 생생한 얼굴 표정 속성을 표현하는 폐색 해제 이미지를 생성하여 FER 성능을 향상시킨다. 이러한 향상은 자체 조립 계 층과 의미론적 일관성 손실을 통합하여 달성된다. 반면 이미지 재구성에 대한 이전 작업은 주로 자연스러움을 달성하는 데 중점을 두어 얼굴 표정이 흐려질 수 있다. 또한 재구성 프로세스에서 얻은 유익한 ViTlatent 벡터를 사용한다. 향상된 표정 예측을 위해 CNN 기능과 ViT 잠재 벡터를 결합한다. 이 작업의 주요 기여는 다음과 같이 볼 수 있다. 본 실시예에는 특정 얼굴 특징에 더 높은 가중치를 할당하기 위해 공간 주의를 사용하는 표현 관련 특징 추출기 를 제안하여 FER에 대한 중요한 위치를 식별할 수 있도록 한다. ViT 잠재 공간에서 표정 관련 잠재 벡터를 검색 하여 이러한 위치를 중요한 값으로 사용하여 귀중한 정보를 추출할 수 있다. 또한 ViT 기반 네트워크에 최적화된 패치 기반 폐색 감지 모듈인 ViT-SVDD를 제안한다. 자체 감독 로컬 분류기 인 ViT-SVDD 모듈은 가려지지 않은 얼굴 이미지의 잠재 벡터에 대해서만 훈련된다. 이 방법은 후속 재구성을 위 해 보이지 않는 물체로 인한 폐색을 정확하게 분류한다. 또한 ViT와 CNN 구조의 장점을 self-assembly layer와 semantic consistency loss와 결합하여 자연스럽고 풍부 한 표정의 얼굴 이미지를 생성하는 하이브리드 재구성 네트워크를 제안한다. 이 접근 방식은 폐색 해제된 이미 지의 품질을 향상시키고 까다로운 조건에서 FER의 정확도를 향상시킨다. 본 실시예에 따른 폐색 감지를 위한 가려짐 판단부에 대해 추가로 설명하면 다음과 같다. 일반 객체 감지 및 세분화 모델은 보이지 않는 객체를 감지하지 못할 수 있으므로 실제 시나리오에는 적합하지 않을 수 있다. 이러한 한계를 해결하기 위해 이상 탐지에 자주 사용되는 단일 클래스 분류를 사용한다. 이 접근법은 학습을 위해 폐쇄되지 않은 패치만 사용하는 자가 지도 학습을 통해 훈련 중에 사용되지 않은 폐색을 분류 할 수 있게 하여 실제 응용 프로그램에 보다 효과적인 솔루션을 제공한다. 정상 또는 비정상을 분류하는 단일 클래스 분류 방법은 픽셀 수준의 낮은 수준의 이상 탐지에서 이미지 수준의 높은 수준의 이상 탐지에 이르기까지 다양한 세분화 수준에서 작동할 수 있다. 단위의 크기에 따라 감지 및 분 류가 이루어지며 사용자의 요구에 맞게 사용자 정의할 수 있다. 이에 본 실시예에서는 ViT 기반 재구성 방법을 사용한다. 따라서 ViT에 특별히 최적화된 중간 수준의 이상 탐지기를 제안한다. ViT 패치의 크기와 일치하도록 이미지를 분할하고 ViT 잠재 벡터를 생성한다. 이러한 패치는 ViT 잠재 벡터를 생성하는 유익한 기능으로 인코 딩된다. 폐색되지 않은 패치에 대해 가장 작은 기능 공간을 생성하기 위해 심층 SVDD 알고리즘을 사용한다. 여기서, ViT(Vision Transformer) 기반 재구성 방법은 이상 탐지를 위해 Vision Transformer 모델을 활용한 이 미지 재구성 방법이다. 이 방법은 단일 클래스 분류 방법으로 작동하며, 픽셀 수준의 낮은 수준의 이상 탐지에 서 이미지 수준의 높은 수준의 이상 탐지까지 다양한 세분화 수준에서 작동할 수 있다. 또한 SVDD(Support Vector Data Description) 알고리즘은 비지도 학습의 한 유형으로, 데이터의 정상 상태를 모델링하고 이상치를 감지하는 데 사용되는 알고리즘이다. SVDD는 지도 학습의 SVM(Support Vector Machine) 알 고리즘의 개념을 기반으로 하여 데이터를 최소한의 영역으로 둘러싸는 초구를 생성하는 방식으로 작동한다. One-class deep SVDD는 SVDD(Support Vector Data Description)를 딥러닝 네트워크에 적용한 변형된 형태로 정 상 데이터의 분포를 모델링하고 이상치를 감지하는 데 사용하고, 2차 손실을 사용하여 모든 네트워크 표현의 거 리에 페널티를 준다. 이는 식 로 정의된다. 식 1"}
{"patent_id": "10-2023-0098458", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "여기서, 여기서 n은 훈련 데이터의 수, L은 레이어의 수, W는 가중치 세트 를 나타내고 c 는 중심을 특징으로 하는 하이퍼스피어(hypersphere)를 나타낸다. 첫 번째 항은 모든 일반 이미지의 특징이 중심점 c에 수렴하도록 유도하는 반면, 마지막 항은 하이퍼파라미터 > 0을 사용하여 네트워크 매개변수 W에 대한 가중치 감쇠 정규화기이다. 여기서 는 Frobenius norm을 나타낸다. 식 은 단순히 모든 네트워크 표현 에서 까지의 거리에 페널티를 주기 위해 2차 손실을 사 용한다. 여기서 F는 출력 특징 공간이다. 네트워크는 데이터 포인트가 하이퍼스피어의 c에 밀접하게 매핑되도록 파라미터 W를 학습한다. 패치가 가려졌는지 확인하기 위해 새로운 입력 정보와 각 패치에 대한 특징 공간의 중 심 c 사이의 거리를 계산한다. 이 값이 임계값을 초과하면 해당 패치가 폐색 및 마스킹으로 분류된다. 이 과정 을 통해 보이지 않는 객체에 대한 오클루전 패치 감지가 가능하다. 제안된 ViT-SVDD 접근 방식은 폐색 패치 주 석이 있는 합성 이미지의 성능을 검증할 수 있다. 폐색 패치를 감지함으로써 재구성 방법의 정확도를 향상시키 고 실제 응용 프로그램에 더 적합하게 만들 수 있다. 부연설명하면, 2차 손실(Quadratic Loss)은 실제 값과 예측 값 사이의 차이를 제곱한 값으로 계산되는 손실 함 수이다. 2차 손실은 주로 회귀 문제에서 사용되며, 실제 값과 예측 값 간의 거리를 정량화하여 모델의 성능을 평가하고 손실을 최소화하는 방향으로 학습을 진행한다. 영상 복원부는 가려짐 판단부에서 가려짐을 처리하는 과정에 있어서, 이미지 재구성 모듈을 하이브리드 재구성 네트워크로 한다. 얼굴 이미지 재구성 프로세스는 폐색 검출기에 의해 생성된 폐색 마스크 이미지를 사용한다. 하이브리드 재구성 네트워크는 ViT 기반 및 CNN 기반 네트워크를 융합하여 협력하도록 한다. 이 메커니즘을 통 해 ViT와 CNN의 강점을 모두 활용한다. ViT 기반 방법은 입력 이미지로 16 × 16 패치를 사용한다. 그러나 이미 지가 가려짐 판단부에 의해 이미 패치 단위로 분할되었기 때문에 영상 복원부는 가려짐 판단부의 출력을 받아 영상 복원부의 입력으로 사용한다. 본 발명의 일 실시예에 따른 가려짐에 강인한 이미지 복원 기반 얼굴 감정 인식 시스템의 네트워크 구조에 대해 설명하면 다음과 같다. ViT 기반 접근 방식은 입력 패치를 인코딩하고 모든 토큰을 긍정적으로 포함한다. 가려진 패치 재구성은 다른 패치와의 상관관계를 통해 이루어진다. ViT는 유도 바이어스가 낮고 자유도가 높기 때문에 다양한 폐색 모양, 위치 및 얼굴 포즈에도 불구하고 신뢰할 수 있는 이미지를 생성할 수 있다. ViT 기반 접근 방식은 때때로 자세한 결과를 제공하지 않을 수 있다. 본 실 시예에서는 이 한계를 해결하기 위해 ViT와 CNN을 결합한다. 본 실시예에 따른 시스템의 네트워크는 U-Net 아키 텍처로 구성된다. 또한 자세한 표현을 생성하기 위해 인코더 내부에 자체 조립 레이어를 추가하였다. 이 다중 구조 접근 방식은 ViT 및 CNN 기반 네트워크의 강점을 효과적으로 결합하여 얼굴 표정을 잘 나타내는 고품질 얼 굴 이미지 재구성을 생성한다. 자기 조립층(Self-assembly layer)과 관련하여, FER의 이미지 재구성을 개선하기 위해 자체 조립 레이어를 구현 한다. 본 실시예에서는 마스킹된 영역을 재구성했지만 얼굴 이미지에 특정한 향상을 위해 사람 얼굴의 좌우 특 성이 대칭적이라는 개념을 바탕으로 마스킹된 영역을 재구성할 때 가로로 뒤집힌 이미지의 해당 위치에 존재하 는 특징 정보를 사용한다. 이전에 생성된 패치, 마스킹되지 않은 영역에서 가장 유사한 패치, 가로로 뒤집힌 이미지의 해당 위치에 있는 패치의 세 가지 소스의 정보를 통합하여 생성 프로세스에 사용되는 후보 패치의 범위를 확장한다. 이 과정에서 마스킹된 영역에는 ViT 네트워크를 사용한 재구성 결과가 포함된다. 현재 패치와의 유사성 값을 기준으로 각각 에 가중치를 할당한다. 가중치 계산은 교차 상관 메트릭을 기반으로 한다. 식 2"}
{"patent_id": "10-2023-0098458", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "여기서 p는 마스킹된 영역의 패치를 나타내고 패치 는 비교 대상이다. p와 사이의 유사성 값은 S로 표 시된다. 자체 조립 작업은 패치 값 를 생성하는 식 에서 정의된다. 도 6은 연산 과정을 나타낸 것으로, 여기서 는 p를 기준으로 대칭적으로 위치하며 주변 패치를 고려하여 평균화한 패치 값을 나타낸다. 은 와 를 통해 식 와 같이 계산된다. 또한 pk는 unmasked 영역 중 p와 가장 유사한 패치이며 은 로 계산된다. 또한, 은 이전에 생성된 패치를 나타내며, 은 에 의해 얻어진다. 유사도 값 S를 정규화하여 가중치로 사용한다. 식 3"}
{"patent_id": "10-2023-0098458", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "item": 4, "content": "도 6에서 (a)의 빨간색 패치는 (주황색 패치), (노란색 패치) 및 ((b)의 파란색 패치)를 결합한 결과인 이다. 에는 이전에 생성된 패치가 없으므로 는 0이다. 측면 이미지와 같은 특정한 경우 대칭위치의 패치는 패치 생성과 관련이 없을 수 있다. 따라서 이 상황에서 의 값은 최소이며 패치를 생성하 는데 거의 사용되지 않는다. 이미지 재구성의 목적은 FER에 대한 보충 정보를 제공하기 위해 마스킹된 부분을 채우는 것이다. 이를 위해 재 구성 손실 (reconstruction loss), 일관성 Lc(consistency), 기능 패치 판별자 (feature patch discriminator) 및 패치 판별자 (patch discriminator)를 유지하면서 작업을 최적화할 수 있는 의미론적 일관성 손실을 통합한다. 의미론적 일관성 손실 (semantic consistency loss)는 표정 속성을 강조한다. 는 클래스 내 가변성 을 줄이는 효과가 있으며 다음과 같이 정의할 수 있다. 식 4"}
{"patent_id": "10-2023-0098458", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "여기서, c는 7가지 기본 표현을 나타내고, 는 ground-truth 이미지에서 c의 예측 확률을 나타내며, 는 재구성 결과에서 c의 예측 확률을 나타낸다. 사전 훈련된 FER 네트워크를 통해 예측 확률 분포를 얻는다. 훈련(training) 중에 전체 손실 함수(overall loss function)는 다음과 같이 정의된다. 식 5"}
{"patent_id": "10-2023-0098458", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 6, "content": "여기서 는 각각 재구성, 일관성, 의미론적 일관성, 판별자 손실에 대한 절충 매개변수를 나타낸다. 또한 FER 네트워크는 FER의 ground-truth 레이블 및 예측에 대한 확률 분포를 사용하여 동일한 특징 추출 아키텍처로 훈련된다. 본 실시예에 따른 가려짐에 강인한 이미지 복원 기반 얼굴 감정 인식 시스템의 표정 인식 네트워크와 관련하여 설명하면 다음과 같다. 본 실시예에서 제안된 FER 네트워크는 얼굴 표정을 예측하기 위한 주의 기반 모델로 설계되었다. 우리는 공간 및 채널 주의 메커니즘을 사용한다. 어텐션 기반 모델을 사용하여 정제된 특징 맵과 공간주의 어텐션을 얻는다. 여기서, 공간주의 어텐션 모델은 입력 이미지의 특정부분이 어떤 클래스와 관련이 있는지를 시각적으로 표시한 다. 또한 공간주의 어텐션을 사용하여 ViT에서 표정 관련 잠재 벡터를 얻는다. 도 4에 표시된 것처럼 Latent-OFER은 CNN 기반 기능과 ViT 기반 잠재 벡터를 공동으로 사용한다. 따라서 모델이 더 잘 수행된다. 여기서, \"Latent-OFER\"는 \"Latent Optical Flow-based Facial Expression Recognition\"의 약어로 본 실시예에 서는 광학 흐름을 기반으로 한 잠재 벡터(Latent Vectors)를 사용하여 얼굴 표정을 인식한다. 이는 광학 흐름 정보를 통해 얼굴 표정의 변화를 추출하고, 이를 잠재 벡터로 표현하여 얼굴 표정을 예측한다. 또한, \"Latent- OFER\"는 CNN 기반 특징과 ViT 기반 잠재 벡터를 협력적으로 사용하여 얼굴 표정 인식 성능을 향상시킨다. 즉, \"Latent-OFER\"는 ViT와 CNN을 결합한 얼굴 표정 인식 모델로, 공간주의 어텐션을 통해 표정관련 잠재벡터를 추 출하여 CNN과 결합한 후 표정을 예측하는데 활용한다. 표정 관련 ViT-잠재 벡터. 제안된 방법은 FER 성능을 향상시키기 위해 전체 잠재 공간이 아닌 표정 관련 잠재 벡터만을 사용한다. 재구성 과정에서 입력 영상을 삽입하여 ViT 기반 잠재 벡터를 추출한다. 본 실시예에서는FER을 위해 이미지 내에서 공간적으로 중요한 영역을 식별하기 위해 공간주의 어텐션을 사용했으며 클래스 활성 화 맵은 CNN을 통해 생성된다. 참고로, 공간주의 어텐션은 기계학습과 컴퓨터 비전 분야에서 사용되는 기술로, 이미지 내에서 공간적으로 중요 한 영역을 강조하거나 관심 있는 부분에 집중하는 데 사용된다. 딥러닝 모델은 이미지의 모든 영역을 동일한 중 요도로 취급하여 처리한다. 그러나 이미지 내에서 중요한 패턴이나 객체가 있는 경우에는 이러한 정보를 감지하 고 강조하는 것이 성능 향상에 도움이 될 수 있다. 이 때 공간주의 어텐션은 주로 사용된다. 공간주의 어텐션은 주로 시각적 지식을 기반으로 하며, 주요한 패턴이나 객체가 어디에 위치하는지에 대한 정보를 활용하여 이미지 의 특정 부분에 가중치를 부여한다. 이러한 가중치는 해당 영역이 모델의 주의를 끌도록 유도하며, 중요한 정보 에 집중하도록 돕는다. 도 7은 표현 관련 비전 변환기(ViT)-잠재 벡터 추출 방법을 나타낸 것으로, 해당 영역의 위치를 키로 저장하고 각 공간에 대한 주의 가중치를 기록한다. 공간주의 가중치가 임계값을 초과하는 영역의 키가 사용된다. 이 키는 전체 ViT 잠재 벡터에서 검색되고 해당 값이 읽힌다. 활성화 맵은 도 7에 제시된 것처럼 표정 관련 잠재 벡터를 식별하는 데 사용된다. 이 과정을 통해 표현과 무관한 외모 정보와 같은 불필요한 세부 사항을 피하면서 FER과 관련된 위치를 선택할 수 있어 클래스 간 상이성을 높이고 보다 정확하고 효과적인 학습 결과로 이어질 수 있다. 본 실시예에 따른 ViT-latent 벡터 추출을 위한 구성은 패치 감지가 실패하는 경우 가려진 패치의 잠재 벡터가 훈련 및 추론에 사용된다. 그러나 공간적 주의는 가려진 영역에 집중되지 않고, 가려진 패치의 잠재 벡터는 검 색되지도 않고 학습 및 추론에 사용되지도 않으며, 이 상황에서 크게 영향을 받지 않는다. 본 발명에 따르면, 표정 인식이 불리한 가려짐으로 인한 표정 인식을 방해하는 요소를 가려짐이 없게 재구성하 여 잠재공간 내에 표정 인식에 유리한 정보만 사용하여 훈련된 딥러닝 사전 훈련 모델을 통해 표정을 추론할 수 있고, 사용자의 얼굴에 가려짐을 인식하여, 가려짐이 있다면 hybrid reconstruction 모델을 통해 가려짐이 없는 이미지로 재생성하고 객체의 감정을 인식할 수 있는 효과가 있다."}
{"patent_id": "10-2023-0098458", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 얼굴 이미지의 가려짐 유형과 비율에 따른 표정 인식 네트워크의 성능 하락 기조에 대한 결과 그래프이 다. 도 2는 본 발명의 일 실시예에 따른 표정 인식 시스템의 구성을 나타낸 블록도이다. 도 3은 본 발명의 일 실시예에 따른 표정 인식 알고리즘을 통해 입력 이미지의 표정 인식 방법의 동작을 도시한 순서도이다. 도 4는 본 발명의 표정 인식 시스템의 상세 구조를 나타낸 블록도이다. 도 5는 본 발명의 가려짐 판단부에서 가려짐을 처리하는 과정을 나타낸 블록도이다. 도 6은 본 발명의 가려짐 복원부의 기작을 나타내는 이미지이다. 도 7은 본 발명의 표정 인식부의 상세 구성을 나타낸 블록도이다."}
