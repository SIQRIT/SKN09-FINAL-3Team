{"patent_id": "10-2018-0107401", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2019-0028349", "출원번호": "10-2018-0107401", "발명의 명칭": "이미지 내 휴먼 분리를 위한 전자 장치 및 방법", "출원인": "삼성전자주식회사", "발명자": "수클라 알로크 샨칼랄"}}
{"patent_id": "10-2018-0107401", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "전자 장치가 이미지 내의 사람을 분리하는 방법에 있어서, 상기 방법은 적어도 하나의 사람을 포함하는 이미지를 획득하는 단계;상기 이미지 내의 사람을 검출하기 위해 얼굴 인식을 수행하는 단계; 소정의 풀(full) 인체 템플릿을 상기 이미지로부터 검출된 사람과 비교함으로써 제 1 휴먼 분리(humansegmentation) 를 획득하는 단계; 상기 이미지를 소정의 인공 지능 학습 모델에 입력함으로써, 상기 이미지로부터 제 2 휴먼 분리(humansegmentation) 를 획득하는 단계; 및상기 제 1 휴먼 분리 및 상기 제 2 휴먼 분리를 함께 이용하여, 상기 이미지로부터 상기 검출된 사람을 나타내는 합성 휴먼 분리(human segmentation)를 획득하는 단계를 포함하는, 방법."}
{"patent_id": "10-2018-0107401", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 얼굴 인식에 기반하는 템플릿 계수(coefficient)를 결정하는 단계를 포함하고, 상기 소정의 풀 인체 템플릿은, 상기 템플릿 계수에 기초하여 크기, 방향 혹은 상기 이미지 내에서의 위치가 조절되는,방법."}
{"patent_id": "10-2018-0107401", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서, 상기 제 1 휴먼 분리는상기 소정의 풀 인체 템플릿을 상기 이미지 내에서 검출된 상기 적어도 하나의 사람들에 맞춤으로써(aligning),상기 풀 인체 템플릿의 일부를 선택하고, 선택된 상기 일부의 풀 인체 템플릿을 변형함으로써 획득되는, 방법."}
{"patent_id": "10-2018-0107401", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 1항에 있어서, 상기 이미지는 상기 전자 장치의 카메라에 의해 캡처된 라이브 미리보기 이미지인, 방법."}
{"patent_id": "10-2018-0107401", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제 1항에 있어서, 상기 합성 휴먼 분리에 기초하여 상기 이미지 내에 보케 효과를 적용하는 단계를 더포함하는, 방법."}
{"patent_id": "10-2018-0107401", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제 5항에 있어서, 상기 보케 효과를 적용하는 단계는, 상기 이미지를 블러링하는 단계; 및 상기 블러링된 이미지와 상기 합성 휴먼 분리에 기초하여 획득된 사람에 관한 정보를 블렌딩하는 단계를 포함하는, 방법."}
{"patent_id": "10-2018-0107401", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제 1항에 있어서, 상기 이미지에 기초하여, 상기 제 1 휴먼 분리를 개선하는 단계를 더 포함하는, 방법."}
{"patent_id": "10-2018-0107401", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제 7항에 있어서, 상기 제 1 휴먼 분리를 개선하는 단계는 상기 제 1 휴먼 분리의 경계 및 영역을 조절하는 단계이고,상기 제 1 휴먼 분리는 컬러 유사도 기반 개선(color similarity based refinement)을 이용하여 개선되는, 방법.공개특허 10-2019-0028349-3-청구항 9 제 1항에 있어서, 구조광 데이터를 획득하는 단계; 및 상기 구조광 데이터와 상기 합성 휴먼 분리에 기초하여,상기 이미지로부터 검출된 적어도 하나의 사람을 깊이에 기초하여 각각 분리하는 단계를 더 포함하는, 방법."}
{"patent_id": "10-2018-0107401", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제 1항에 있어서, 상기 인공 지능 학습 모델은, 인공 지능 알고리즘으로서, 기계학습, 신경망, 유전자, 딥러닝,분류 알고리즘 중 적어도 하나를 이용하여 학습된 학습 모델인 것인, 방법."}
{"patent_id": "10-2018-0107401", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "이미지 내의 사람을 분리하는 전자 장치에 있어서, 상기 전자 장치는디스플레이; 하나 이상의 인스트럭션을 저장하는 메모리; 및상기 하나 이상의 인스터럭션을 실행하는 프로세서;를 포함하며,상기 프로세서는, 적어도 하나의 사람을 포함하는 이미지를 획득하고, 상기 이미지 내의 사람을 검출하기 위해얼굴 인식을 수행하고, 소정의 풀(full) 인체 템플릿을 상기 이미지로부터 검출된 사람과 비교함으로써 제 1 휴먼 분리(human segmentation) 를 획득하고, 상기 이미지를 소정의 인공 지능 학습 모델에 입력함으로써, 상기이미지로부터 제 2 휴먼 분리(human segmentation) 를 획득하고, 상기 제 1 휴먼 분리 및 상기 제 2 휴먼 분리를 함께 이용하여, 상기 이미지로부터 상기 검출된 사람을 나타내는 합성 휴먼 분리(human segmentation)를 획득하는, 전자 장치."}
{"patent_id": "10-2018-0107401", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항에 있어서, 상기 프로세서는 상기 얼굴 인식에 기반하는 템플릿 계수(coefficient)를 결정하고, 상기 소정의 풀 인체 템플릿은, 상기 템플릿 계수에 기초하여 크기, 방향 혹은 상기 이미지 내에서의 위치가 조절되는,전자 장치."}
{"patent_id": "10-2018-0107401", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제11항에 있어서, 상기 제 1 휴먼 분리는 상기 소정의 풀 인체 템플릿을 상기 이미지 내에서 검출된 상기 적어도 하나의 사람들에 맞춤으로써(aligning), 상기 풀 인체 템플릿의 일부를 선택하고, 선택된 상기 일부의 풀 인체 템플릿을 변형함으로써 획득되는, 전자 장치."}
{"patent_id": "10-2018-0107401", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제 11항에 있어서, 상기 이미지는 상기 전자 장치의 카메라에 의해 캡처된 라이브 미리보기 이미지인, 전자 장치."}
{"patent_id": "10-2018-0107401", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제 11항에 있어서, 상기 프로세서는 상기 합성 휴먼 분리에 기초하여 상기 이미지 내에 보케 효과를 적용하는,전자 장치."}
{"patent_id": "10-2018-0107401", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제 15항에 있어서, 상기 프로세서는 상기 이미지를 블러링하고, 상기 블러링된 이미지와 상기 합성 휴먼 분리에 기초하여 획득된 사람에 관한 정보를 블렌딩하여 상기 이미지 내에 상기 보케 효과를 적용하는, 전자 장치."}
{"patent_id": "10-2018-0107401", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제 11항에 있어서, 상기 프로세서는 컬러 유사도 기반 개선(color similarity based refinement)을 이용하여상기 제 1 휴먼 분리를 개선하는, 전자 장치.공개특허 10-2019-0028349-4-청구항 18 제 11항에 있어서, 상기 프로세서는 구조광 데이터를 획득하고, 상기 구조광 데이터와 상기 합성 휴먼 분리에기초하여, 상기 이미지로부터 검출된 적어도 하나의 사람을 깊이에 기초하여 각각 분리하는 전자 장치."}
{"patent_id": "10-2018-0107401", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제11항에 있어서, 상기 인공 지능 학습 모델은, 인공 지능 알고리즘으로서, 기계학습, 신경망, 유전자, 딥러닝,분류 알고리즘 중 적어도 하나를 이용하여 학습된 학습 모델인 것인, 전자 장치."}
{"patent_id": "10-2018-0107401", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "이미지 내의 사람을 분리하는 방법을 실행하는 인트스럭션을 포함하는 하나 이상의 프로그램이 기록된 컴퓨터로읽을 수 있는 기록 매체에 있어서,상기 이미지 내의 사람 분리 방법은,적어도 하나의 사람을 포함하는 이미지를 획득하는 동작;상기 이미지 내의 사람을 검출하기 위해 얼굴 인식을 수행하는 동작; 소정의 풀(full) 인체 템플릿을 상기 이미지로부터 검출된 사람과 비교함으로써 제 1 휴먼 분리(humansegmentation) 를 획득하는 동작; 상기 이미지를 소정의 인공 지능 학습 모델에 입력함으로써, 상기 이미지로부터 제 2 휴먼 분리(humansegmentation) 를 획득하는 동작; 및상기 제 1 휴먼 분리 및 상기 제 2 휴먼 분리를 함께 이용하여, 상기 이미지로부터 상기 검출된 사람을 나타내는 합성 휴먼 분리(human segmentation)를 획득하는 동작;을 포함하는 것을 특징으로 하는, 기록 매체."}
{"patent_id": "10-2018-0107401", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 개시는 전자 장치가 이미지 내의 사람을 분리하는 방법 및 그 전자 장치에 관한 것이다. 전자 장치가 이미지 내의 사람을 분리하는 방법은, 적어도 하나의 사람을 포함하는 이미지를 획득하는 단계, 상기 이미지 내의 사람 을 검출하기 위해 얼굴 인식을 수행하는 단계, 소정의 풀(full) 인체 템플릿을 상기 이미지로부터 검출된 사람과 비교함으로써 제 1 휴먼 분리(human segmentation) 를 획득하는 단계, 상기 이미지를 소정의 인공 지능 학습 모 델에 입력함으로써, 상기 이미지로부터 제 2 휴먼 분리(human segmentation) 를 획득하는 단계 및 상기 제 1 휴 먼 분리 및 상기 제 2 휴먼 분리를 함께 이용하여, 상기 이미지로부터 상기 검출된 사람을 나타내는 합성 휴먼 분리(human segmentation)를 획득하는 단계를 포함한다."}
{"patent_id": "10-2018-0107401", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시의 실시예들은 이미지 내 분리(segmentation)에 관한 것이다. 보다 상세하게 말하면, 휴먼 템플릿(human template) 및 인공 지능 학습 모델을 이용한 이미지 내 자동적 휴먼 분리를 위한 전자 장치 및 방법에 관한 것 이다."}
{"patent_id": "10-2018-0107401", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "일반적으로, 카메라를 가진 모바일 장치의 사용 증가는 사용자들로 하여금 모바일 장치 상에 방대한 양의 이미 지들을 캡처할 수 있게 한다. 그러나 그 이미지들은 종종, 좋은 이미지들을 캡처하거나 그 이미지들을 성공적으 로 후처리하는 데 필요한 숙련도가 부족한 사용자들에 의해 캡처될 수 있. 또한 많은 이미지 후처리 애플리케이 션들에서, 이미지의 주제는 이미지의 배경과 별도로 처리될 수 있다. 한 명 이상의 사람이 있는 이미지가 캡처될 때, 해당 이미지를 미학적으로, 혹은 인위적으로 개선하기 위한 임 의의 효과를 적용하기 전에 그 이미지 안의 사람들을 그 이미지의 배경으로부터 분리해야 할 수 있다. 일 실시 예에 의한 방법들과 시스템들은 고정된 인체(human body) 템플릿들을 이용하여 이미지에서 한 명 이상의 사람들 을 분리한다. 고정된 인체 템플릿들은, 이미지 안에서 오직 얼굴 인식에 기초하여 탐색된 사람들에 대하여만 적 용될 수 있다. 예를 들어, 만약 이미지가 오직 사람의 얼굴만을 포함하고 있는 경우, 일 실시예에 의한 방법들 과 시스템들은 사람의 존재를 탐지하고, 고정된 인체 템플릿을 적용할 수 있다. 그러나, 상술된 실시예에 의한 방법들 및 시스템들에 의하면, 이미지가 오직 사람의 얼굴만을 포함하고 있으며 사람의 신체는 포함하고 있지 않다는 것을 명확하게 판별하기 어려울 수 있다. 따라서, 얼굴 인식에만 기초하여 고정된 인체 템플릿을 적용하 는 방식은 휴먼 분리를 부정확하게 할 수 있다. 더하여, 인체는 변형될 수 있다, 즉 인체는 (도 1에 도시된 바와 같이) 다른 방향성을, 예컨대 기울어진 얼굴을 가질 수 있다. 그러나 고정된 인체 템플릿들은 기울어진 얼굴과 같은 인체의 방향성을 고려하지 못한다. 따라 서 인체의 방향성에 대한 고려 없이 고정된 인체 템플릿을 이용하는 것은 도 1에 도시된 것과 같은 부정확한 휴먼 분리를 야기할 수 있다. 상술된 정보는 독자가 본 발명을 이해하는 것을 돕기 위한 배경 정보로서만 제시된다. 출원인은 본 출원과 관련 하여 상술된 내용 중 어느 것이 선행 기술로서 적용될 수 있을 것인지 여부에 관해 아무 판단도 내리지 않았으 며 어떤 단정도 하지 않았다."}
{"patent_id": "10-2018-0107401", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 개시의 실시예들의 주요 목적은 이미지 내 자동적인 휴먼 분리를 위한 전자 장치 및 방법을 제공하는 것이다."}
{"patent_id": "10-2018-0107401", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상술한 기술적 과제를 달성하기 위한 기술적 수단으로서, 본 개시의 제 1 측면은, 적어도 하나의 사람을 포함하 는 이미지를 획득하는 단계, 상기 이미지 내의 사람을 검출하기 위해 얼굴 인식을 수행하는 단계, 소정의 풀 (full) 인체 템플릿을 상기 이미지로부터 검출된 사람과 비교함으로써 제 1 휴먼 분리(human segmentation) 를 획득하는 단계, 상기 이미지를 소정의 인공 지능 학습 모델에 입력함으로써, 상기 이미지로부터 제 2 휴먼 분 리(human segmentation) 를 획득하는 단계 및 상기 제 1 휴먼 분리 및 상기 제 2 휴먼 분리를 함께 이용하여, 상기 이미지로부터 상기 검출된 사람을 나타내는 합성 휴먼 분리(human segmentation)를 획득하는 단계를 포함 한다. 또한 본 개시의 제 2 측면은, 디스플레이, 하나 이상의 인스트럭션을 저장하는 메모리 및 상기 하나 이상의 인 스터럭션을 실행하는 프로세서를 포함하며, 상기 프로세서는, 적어도 하나의 사람을 포함하는 이미지를 획득하 고, 상기 이미지 내의 사람을 검출하기 위해 얼굴 인식을 수행하고, 소정의 풀(full) 인체 템플릿을 상기 이미 지로부터 검출된 사람과 비교함으로써 제 1 휴먼 분리(human segmentation) 를 획득하고, 상기 이미지를 소정의 인공 지능 학습 모델에 입력함으로써, 상기 이미지로부터 제 2 휴먼 분리(human segmentation) 를 획득하고, 상 기 제 1 휴먼 분리 및 상기 제 2 휴먼 분리를 함께 이용하여, 상기 이미지로부터 상기 검출된 사람을 나타내는 합성 휴먼 분리(human segmentation)를 획득한다. 또한 본 개시의 제 3 측면은, 제 1 측면의 방법을 컴퓨터에서 실행시키기 위한 프로그램을 기록한 컴퓨터로 읽 을 수 있는 기록매체를 제공할 수 있다. 본 발명의 실시예들에 대한 상술된 및 기타 양태들은 이하의 설명 및 첨부된 도면과 함께 고려될 때 보다 잘 예 상되고 이해될 것이다. 그러나 이하의 내용은 바람직한 실시예들과 그에 대한 수많은 특정 세부사항들을 나타낸 다고 해도 한정하는 것이 아닌 예로서 주어진다는 것을 알아야 한다. 본 명세서의 실시예들의 범위 안에서 그 사상으로부터 벗어나지 않은 많은 변화 및 변경이 이루어질 수 있으며, 본 명세서의 실시예들은 그러한 모든 변 경사항들을 포함한다."}
{"patent_id": "10-2018-0107401", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "첨부된 도면들을 참조하여 본 발명의 다양한 실시예들이 설명될 것이다. 이하의 설명에서, 상세한 구성 및 구성 요소들과 같은 구체적 세부사항들은 다만 그러한 본 개시의 실시예들의 전반적 이해를 돕기 위해서만 제공되는 것이다. 따라서 당업자라면 본 개시의 범위와 사상으로부터 벗어나지 않고 여기에 기술되는 실시예들에 대한 다 양한 변화와 변경이 이루어질 수 있다는 것을 자명하게 알 수 있을 것이다. 또한, 잘 알려진 기능들과 구성들에 대한 설명은 명확함과 간결함을 위해 생략될 수 있다. 또한 일부 실시예들이 한 개 이상의 다른 실시예들과 결합되어 새 실시예들을 형성할 수 있으므로, 여기 기술된 다양한 실시예들이 반드시 상호 배타적인 것은 아니다. 여기서 사용되는 \"또는\" 이라는 용어는 다르게 지시되지 않으면 비배타적임을 의미한다. 이 안에 사용된 예들은 단지 이 안의 실시예들이 실시될 수 있는 방식의 이해를 돕고 당업자가 이 안의 실시예들을 실시할 수 있게 하 도록 예정된 것이다. 따라서 그 예들이 본 발명의 실시예들의 범위를 한정하는 것으로 해석되어서는 안될 것이다. 이 분야에서 의례적인 바와 같이, 실시예들은 서술된 기능 내지 기능들을 수행하는 블록들을 이용하여 기술되고 예시될 수 있다. 본 개시에서 부(유닛), 엔진, 관리자, 모듈 등으로 불릴 수 있는 이러한 블록들은 로직 게이 트, 집적 회로, 마이크로프로세서, 메모리 회로, 수동 전자 구성요소, 능동 전자 구성요소, 광학적 구성요소, 하드웨어 회로 등과 같은 아날로그 및/또는 디지털 회로들에 의해 물리적으로 구현될 수 있으며, 옵션으로서 펌 웨어 및/또는 소프트웨어에 의해 구동될 수 있다. 상술된 회로들은 예컨대, 하나 이상의 반도체 칩들 내에서, 혹은 인쇄 회로 보드 등과 같은 기판 서포트들 상에서 실시될 수 있다. 하나의 블록을 구성하는 회로들은 전용 하드웨어, 프로세서(가령, 하나 이상의 프로그래밍된 마이크로프로세서들 및 관련 회로), 또는 블록의 일부 기 능들을 수행하기 위한 전용 하드웨어 및 블록의 다른 기능들을 수행하기 위한 프로세서의 조합을 통해 구현될 수 있다. 실시예들에서 각각의 블록은 본 개시의 범위에서 벗어나지 않고 둘 이상의 상호 동작하는 개별 블록 들로 물리적으로 분리될 수 있다. 마찬가지로 실시예들의 블록들은 본 개시의 범위에서 벗어나지 않고 보다 복 잡한 블록들 안에 물리적으로 결합될 수 있다. 본 개시의 실시예들은 전자 장치를 통해 이미지 내의 사람을 분리하는 휴먼 분리를 위한 방법을 제공한다. 본 실시예에 의한 방법은 이미지를 수신하는 단계 및 상술된 이미지 내에서 한 명 이상의 사람들의 존재를 검출하기 위한 얼굴 인식을 수행하는 단계를 포함할 수 있다. 한편, 본 개시의 실시예에서는 휴먼 분리 및 얼굴 인식이 예시적으로 사용되었으나, 이미지 내의 분리 대상은 반드시 사람에 한정되지 않고 다양할 수 있다. 이에 따라 얼굴 인식 역시 분리 대상에 적합한 검출 방법으로 대 체될 수 있다. 예를 들어, 본 개시의 일 실시예는 이미지 내의 소정의 동물을 분리하는 방법을 제공할 수 있고, 이에 따라 본 실시예에 의한 방법은 이미지 내에서 한 명 이상의 소정의 동물들의 존재를 검출하기 위한 동물 인식을 수행하는 단계를 포함할 수 있다. 혹은, 본 개시의 일 실시예는 이미지 내의 소정의 오브젝트를 분리하 는 방법을 제공할 수 있고, 이에 따라 본 실시예에 의한 방법은 이미지 내에서 한 개 이상의 소정의 오브젝트들 의 존재를 검출하기 위한 오브젝트 인식을 수행하는 단계를 포함할 수 있다. 따라서 본 개시의 실시예들은 전자 장치를 통해 이미지 내 자동적 휴먼 분리를 위한 방법을 제공한다. 본 실시 예에 의한 방법은 이미지를 수신하는 단계 및 상술된 이미지 내에서 한 명 이상의 사람들의 존재를 검출하기 위 한 얼굴 인식을 수행하는 단계를 포함할 수 있다. 또한 상술된 방법은 소정의 풀(full) 인체 템플릿을 상술된 이미지 내에서 검출된 한 명 이상의 사람들에 매핑함으로써 제 1 휴먼 분리를 생성하는 단계를 포함할 수 있다. 또한 상술된 방법은 심층 신경망(DNN)을 이용하여 상술된 이미지에서 제 2 휴먼 분리를 생성하는 단계를 포함할 수 있다. 또한 상술된 방법은 상술된 제1 휴먼 분리 및 제 2 휴먼 분리를 융합하여 합성 휴먼 분리 (segmentation)를 획득하는 단계를 포함할 수 있다. 일 실시예에서, 이미지에 대해 수행된 얼굴 인식에 기반하여 이미지 내에서 검출된 한 명 이상의 사람들의 얼굴 데이터에 대해, 소정의 풀(full) 인체 템플릿이 매핑된다. 일 실시예에서, 제 1 휴먼 분리는 이미지 내에서 검출된 한 명 이상의 사람들에게 미리 정의된 풀 인체 템플릿 을 맞추고(aligning), 제 1 휴먼 분리를 이미지 내에서 검출된 한 명 이상의 사람들의 데이터와 융합함으로써 개선(refining)함으로써 생성된다. 일 실시예에 의한 방법 및 시스템에서, 고해상도의 이미지가 DNN을 바로 거칠 수 있고, 이에 따라 이미지 처리 에 엄청난 시간이 걸리게 될 수 있다. 반면, 본 개시의 개선된 실시예에 의한 방법 및 시스템에서 고해상도의 이미지는 DNN을 통과하기 전에 크기가 조정될 수 있다. 그에 따라, 해당 이미지에 필요한 시간이 상대적으로 적 어질 수 있다. 일 실시예에 의한 방법 및 시스템에서, 보케(bokeh) 효과를 제공하기 위해서는 사람과 배경 간의 거리를 산출하 기 위해 두 대의 카메라가 사용되어야 하며, 그 거리는 휴먼 분리를 제공하고 그런 다음 보케 효과를 적용하는 데 사용될 수 있다. 이 경우, 프로세스에 비용이 들고 복잡해진다. 또한 일 실시예에 의한 방법 및 시스템은 이미지에서 검출된 휴먼 분리를 위해 얼굴 데이터만을 이용할 수 있 다. 반면, 본 개시의 개선된 실시예에 의한 방법은 이미지에서 검출된 사람의 얼굴 데이터와 함께 하나의 인체 템플릿을 이용하여, 이미지에서 검출된 휴먼 분리(segmentation)를 획득할 수 있다. 또한 본 개시의 실시예에 의한 방법은, DNN을 이용하여, 제 1 휴먼 분리와 융합되어 이미지로부터 사람을 분리 하기 위한 제 2 휴먼 분리를 생성하는 단계를 포함할 수 있다. 또한 본 개시의 실시예에 의한 방법은, 싱글 모노큘러(single monocular) 이미지를 이용하여 자동적으로 이미지 안의 사람을 분리하는 단계를 포함할 수 있다. 일 실시예에 의한 방법 및 시스템은, 이미지 안에서 사람들의 존재를 명확하고 지능적으로(intelligently) 판별 하지 못할 수 있다. 예를 들어, 사람의 몸은 포함하지 않고 얼굴만을 포함하고 있는 이미지에 대하여, 풀(full) 인체의 고정된 인체 템플릿을, 이미지 내에 사람의 몸이 존재하지 않는 다는 것에 대한 고려 없이 얼굴 인식에 만 기초하여 직접 적용할 수 있다. 반면, 본 개시의 개선된 실시예에 의한 방법 및 시스템에 의하면, 이미지 내 의 사람을 지능적으로 판별한 뒤 고정된 인체 템플릿을 적용할 수 있다. 따라서, 실시예에 의한 방법 및 시스템 에 의하면, 사람을 이미지로부터 보다 정확하게 분리하는 방법이 제공될 수 있다. 이제 일관되게 도면 전체를 통하여 유사한 참조 문자들이 해당 구성들을 나타내는 도면들, 특히 도 2 내지 도 14을 참조하여, 바람직한 실시예들이 설명된다. 도 2는 일 실시예에 있어서, 휴먼 분리에 기반하여 이미지에 적용될 수 있는 다양한 효과들을 설명하는 도면이 다. 도 2에서, 도 3의 전자 장치가 이미지를 수신한다고 가정한다. 실시예에 있어서, 전자 장치는 전자 장치 내의 카메라를 이용하여 이미지를 획득할 수 있다. 혹은, 전자 장치는 네트워크를 통하여 연결 된 외부 장치 혹은 서버로부터 이미지를 수신할 수 있다. 전자 장치의 이미지 획득 혹은 수신 방법은 상술 된 예에 한정되지 않는다. 본 실시예에서, 이미지는 사람의 존재를 포함한다고 가정한다. 이미지의 일차 포커스는 이미지 안의 사람에 맞 추어 질 수 있다. 그러나 이미지 내 사람의 배경과 주변에는 다수의 객체들이 있을 수 있다. 이미지의 일차적인 포커스가 사람에 맞추어져 있으므로, 사람은 배경에 있는 여러 객체들로부터 분리되어야 할 수 있다. 더하여, 이미지 내 사람이 그 사람의 배경과 주변의 여러 객체들과 분리되면, 본 개시에 의한 전자 장치는 다양한 효과들을 그 이미지에 적용하여 이미지의 미관상의 화질이 개선하거나 원하는 효과를 도출할 수 있다. 일 실시예에서, 단계 1을 참조하면, 이미지 안의 사람을 분리한 후, 그 이미지 내 사람의 배경을 블러링함으로 써(blurring) 이미지에 보케 효과가 적용될 수 있다. 실시예에 있어서, 블러링은 블러링 대상이 되는 위치의 픽 셀 값들을 평균화하는 방식으로 이루어질 수 있다. 혹은, 블러링은 소정의 방향으로 제공되는 모션 블러링을 포 함할 수 있다. 그러나 본 개시의 블러링 방법은 상술된 예시에 한정되지 않는다. 일 실시예에서, 단계 2를 참조하면, 이미지에서 사람을 분리한 후, 그 이미지의 배경에 있는 객체들, 배경 색깔 등이 변경될 수 있다. 실시예에 있어서, 이미지의 배경에 있는 객체들, 배경 색깔 등은 사용자로부터 입력되는 배경 변경 신호에 기초하여 변경될 수 있다. 또한, 전자 장치는 사용자에게 복수의 기 설정된 배경 혹은 배경에 제공될 효과들을 제공하고, 사용자로부터 수신된 선택 신호에 기초하여 이미지의 배경을 변경할 수 있다. 일 실시예에서, 단계 3을 참조하면, 이미지에서 사람을 분리한 후, 그 이미지에 달리(dolly) 효과가 적용될 수 있다. 달리 효과가 적용될 때, 이미지 안의 사람은 같은 크기로 유지되는 반면, 배경에 있는 다수의 객체들의 크기는 변경될 수 있다. 도 3a는 일 실시예에 의한, 이미지 내에서 휴먼 분리를 제공하기 위한 전자 장치를 도시하는 블록도이다. 보다 구체적으로, 도 3a는 휴먼 템플릿 및 인공 지능 학습 모델을 이용하여 이미지 내에서 휴먼 분리를 제공하기 위 한 전자 장치의 다양한 하드웨어 구성요소들을 도시한 블록도이다. 일 실시예에서, 전자 장치는 예컨대, 모바일 폰, 스마트 폰, PDA(Personal Digital Assistant), 태블릿, 웨어러블 장치, 디스플레이 장치, 사물 인터넷(IoT) 장치, 전자 회로, 칩셋, 및 전기 회로(즉, SoC(System on Chip)) 등일 수 있다. 도 3a를 참조하면, 전자 장치는 분리 엔진, 프로세서, 메모리 및 디스플레이를 포함 한다. 일 실시예에서, 분리 엔진은 얼굴 인식을 수행하여 이미지 안에서 한 명 이상의 사람들의 존재를 검출하도 록 구성된다. 분리 엔진은 다양한 알고리즘을 이용하여 얼굴 인식을 수행할 수 있다. 이때, 이미지는 전자 장치에 저장된 이미지, 전자 장치에 의해 수신된 이미지, 및 전자 장치의 카메라 애플리케이션 으로부터 나온 라이브 미리보기 이미지 중 하나일 수 있다. 그러나 상술된 바와 같이 전자 장치가 이미지 를 획득하는 방법은 상술된 예시에 한정되지 않는다. 또한, 분리 엔진은 소정의 풀(full) 인체 템플릿을 상술된 이미지 내에서 검출된 한 명 이상의 사람들에 매핑함으로써 제 1 휴먼 분리를 생성하도록 구성될 수 있다. 실시 예에 있어서, 풀 인체 템플릿은 인체의 전신 의 형상에 관한 정보를 포함하는 템플릿일 수 있다. 템플릿은 이미지의 일부를 식별할 수 있는 지표가 되는 기 설정된 정보이다. 실시 예에 있어서, 풀 인체 템플릿은 인체의 전신의 형상의 외곽을 나타내는 선을 포함할 수 있다. 혹은, 풀 인체 템플릿은 인체의 전신의 형상을 나타내는 영역을 포함하는 면을 포함할 수 있다. 실시 예 에 있어서, 소정의 풀 인체 템플릿은 전자 장치에 저장된 단일 템플릿일 수 있으며, 이미지 내에서 검출된 한 명 이상의 사람들에게 매핑하기 위해 사용될 수 있다. 또한, 분리 엔진은 DNN을 이용하여 이미지로부터 제 2 휴먼 분리를 생성하고, 제 1 휴먼 분리 및 제 2 휴먼 분리를 융합하여 이미지 내에서 합성 휴먼 분리를 획 득하도록 구성될 수 있다. 실시예에 있어서, 이미지가 라이브 미리보기 이미지일 때, 분리 엔진은 제 1 휴먼 분리를 이미지 자체의 블러링된(blurred) 버전과 융합함으로써 이미지 내에서 합성 휴먼 분리를 획득하도록 구성될 수 있다. 또한, 분 리 엔진은 휴먼 분리에 기반하여 이미지 안에 보케 효과와 같은 다양한 효과들을 적용하도록 구성될 수 있 다.일 실시예에서, 프로세서는 이미지 내에 휴먼 분리를 제공하도록 분리 엔진, 메모리 및 디스플 레이와 같은 하드웨어 구성요소들과 상호동작하도록 구성될 수 있다. 일 실시예에서 메모리는 한 명 이상의 사람들을 포함하는 이미지들을 저장하도록 구성된다. 메모리는 또한, 제1 휴먼 분리를 생성하기 위해 사용되는 소정의 풀 인체 템플릿을 저장하도록 구성될 수 있다. 메모리 는 비휘발성 저장 요소들을 포함할 수 있다. 그러한 비휘발성 저장 요소들의 예들에는 자기적 하드 디스크, 광 디스크, 플로피 디스크, 플래시 메모리, 또는 EPROM(electrically programmable memories)이나 EEPROM(electrically erasable and programmable) 메모리들의 형태들을 포함할 수 있다. 또한 메모리는 일부 예들에서, 비일시적(non-transitory) 저장 매체라고 간주될 수 있다. “비일시적”이라는 용어는 저장 매 체가 반송파나 전파 신호로 구현되지 않는다는 것을 가리킬 수 있다. 그러나, “비일시적”이라는 용어는 메모 리가 비이동성임이라고 해석되어서는 안된다. 일부 예들에서, 메모리는 메모리보다 많은 양의 정보를 저장하도록 구성될 수 있다. 소정 예들에서, 비일시적 저장 매체는 시간에 따라 변화할 수 있는 데이터를 저장 할 수 있다(가령, RAM(Random Access Memory)이나 캐시). 일 실시예에서, 디스플레이는 합성 휴먼 분리를 가진 이미지를 디스플레이 하도록 구성될 수 있다. 또한 디스플레이는 보케 효과가 있는 이미지를 디스플레이 하도록 구성될 수 있다. 디스플레이는 또한, 한 명 이상의 사람들을 포함하는 이미지의 라이브 미리보기를 제공하도록 구성될 수 있다. 도 3a는 전자 장치의 하드웨어 구성요소들을 도시하나, 상술된 바와 같이 본 개시의 실시예들이 이에 한정 되는 것은 아니다. 본 개시의 실시예들에서, 전자 장치는 더 적거나 더 많은 수의 구성요소들을 포함할 수 있다. 또한, 구성요소들의 표시들이나 명칭들은 예시적 목적만을 위해 사용되는 것으로 본 발명의 범위를 한정 하지 않는다. 하나 이상의 구성요소들이 함께 결합되어 이미지 내에 휴먼 분리를 제공하기 위한 기능 또는 실질 적으로 그와 유사한 기능을 수행하도록 할 수 있다. 예를 들어, 본 개시에서, 프로세서와 분리 엔진 이 별개의 장치인 것으로 설명하였지만, 이에 제한되지 않는다. 예를 들어, 하나의 프로세서에 의해 프로세서 및 분리 엔진의 기능이 구현될 수 있다. 또한 분리 엔진은 메모리에 저장된 소프트웨어 프로그 램에 의해 구현될 수도 있다 도 3b는 일 실시예에 의한 분리 엔진의 다양한 하드웨어 구성요소들을 도시한 블록도이다. 도 3b를 참조하면, 분리 엔진은 얼굴 인식 엔진, 제 1 휴먼 분리 생성 엔진, 제 1 휴먼 분리 개 선 엔진, DNN, 및 합성 휴먼 분리 생성 엔진을 포함한다. 일 실시예에서, 얼굴 인식 엔진은 이미지 내에서 한 명 이상의 사람들의 존재를 검출하기 위한 얼굴 인식 을 수행하도록 구성될 수 있다. 얼굴 인식 엔진은 다양한 알고리즘을 이용하여 얼굴 인식을 수행할 수 있 다. 또한, 얼굴 인식 엔진은 얼굴 인식에 기반하여 얼굴 데이터를 생성하도록 구성될 수 있다. 얼굴 데이 터는 얼굴 인식 및 이미지에 기초하여 생성된, 이미지 내에서 검출된 사람들의 얼굴에 관한 데이터일 수 있다. 제 1 휴먼 분리 생성 엔진는 상술된 얼굴 인식 및 소정의 풀 인체 템플릿에 기초하여 제 1 휴먼 분리를 생 성한다. 휴먼 분리는, 이미지 내의 인체 형상을 식별할 수 있는 지표가 되는 정보일 수 있다. 실시 예에 있어서, 휴먼 분리는 인체 형상의 외곽선을 나타내는 정보를 포함할 수 있다. 혹은, 휴먼 분리는 인체 형상을 나타내는 영역을 포함하는 면에 관한 정보를 포함할 수 있다. 혹은, 휴먼 분리는 인체의 형상 및 연관 프레임에 서 상술된 인체의 형상이 움직이는 영역에 관한 정보를 포함할 수 있다. 일 실시예에서, 제 1 휴먼 분리 생성 엔진은 얼굴 위치, 얼굴 크기 및 가시성(visibility; 시야 안의 얼굴 몸체) 및 색상 전파(색상 유사도)와 같은 정보를 이용하여 얼굴 인식에 기반하는 템플릿 계수(coefficient)를 결정하도록 구성될 수 있다. 실시 예 에 있어서, 템플릿 계수는 상술된 얼굴 인식에 기반한 정보 및 소정의 인체 풀 템플릿을 비교하여 결정될 수 있 다. 또한, 제 1 휴먼 분리 생성 엔진은 소정의 풀 인체 템플릿을 얼굴 인식에 따른 한 명 이상의 사람들에 게 맞춤으로써, 소정의 풀 인체 템플릿을 이미지 안에서 검출된 한 명 이상의 사람들에게 매핑하도록 구성될 수 있다. 예를 들어, 1 휴먼 분리 생성 엔진는 결정된 템플릿 계수 및 소정의 풀 인체 템플릿에 기초하여, 소 정의 풀 인체 템플릿의 크기, 방향 혹은 이미지 내에서의 위치를 조절할 수 있다. 실시 예에 있어서, 이미지 내 에서 검출된 사람이 인체의 일부만을 포함하고 있을 경우, 1 휴먼 분리 생성 엔진은 조절된 풀 인체 템플 릿의 일부만을 사용할 수 있다. 제 1 휴먼 분리 생성 엔진는 조절된 풀 인체 템플릿 및 이미지에 기초하여, 제 1 휴먼 분리를 획득할 수 있다. 제 1 휴먼 분리 개선 엔진은 제 1 휴먼 분리를 이미지에 기초하여 개선한다. 예를 들어, 제 1 휴먼 분리 개선 엔진은 다중 레벨 색상 유사도에 기반하는 정정을 수행하도록 구성될 수 있다. 예를 들어, 제 1 휴먼분리 개선 엔진은 다중 레벨 색상 유사도에 기반하여, 제 1 휴먼 분리 생성 엔진에서 생성된 제 1 휴 먼 분리의 경계 및 영역을 조절할 수 있다. 또한 제 1 휴먼 분리 개선 엔진은 경계 개선을 수행하여 제 1 휴먼 분리를 더 개선하도록 구성될 수 있다. 예를 들어, 제 1 휴먼 분리 개선 엔진은 경계 개선을 수행하 여, 제 1 휴먼 분리 생성 엔진에서 생성된 인체 템플릿의 경계를 이미지 내에서 검출된 사람의 형상의 경 계와 보다 근접하게 조절할 수 있다. 일 실시예에서 심층 신경망(DNN)은 학습 데이터에 기반하여 이미지로부터 제 2 휴먼 분리를 생성하도록 구 성된다. 실시예에 있어서, 제 2 휴먼 분리는 이미지는 보다 낮은 해상도로 크기 조정된 후 DNN을 통과하여, 이미지에서 제 2 휴먼 분리가 획득되게 한다. DNN에 의해 제공된 제 2 휴먼 분리 또한, 이미지 와 비교해 낮은 해상도를 가질 수 있다. 도 3b를 참조한 본 실시예에서 제 2 휴먼 분리는 심층 신경망을 이용하 여 획득되도록 예시되었으나, 본 개시에서 제 2 휴먼 분리를 획득하기 위한 인공 지능 학습 모델은 이에 한정되 지 않는다. 예를 들어, 심층 신경망(DNN)은 기계학습, 신경망, 유전자, 딥러닝, 분류 알고리즘, RNN(Recurrent Neural Network), BRDNN(Bidirectional Recurrent Deep Neural Network) 등 다양한 학습 모델 로 대체될 수 있다. 일 실시예에서, 합성 휴먼 분리 생성 엔진은 인체 제1 휴먼 분리를 DNN에서 획득된 제2 휴먼 분리에 매핑함으로써 이미지 내에서 합성 휴먼 분리를 획득하도록 구성될 수 있다. 또한, 라이브 미리보기 이미지의 경 우, 합성 휴먼 분리 생성 엔진은 제 1 휴먼 분리과 이미지를 융합함으로써 이미지 내에서 합성 휴먼 분리 를 획득하도록 구성될 수 있다. 도 4는 일 실시예에 의한 제1 휴먼 분리 및 제 2 휴먼 분리를 이용하여 이미지 내에서 휴먼 분리를 제공하기 위 한 방법을 도시하는 흐름도이다. 도 4를 참조하면, 단계 402에서, 전자 장치가 이미지를 수신한다. 예를 들어 도 3a에 도시된 바와 같은 전자 장치에서, 분리 엔진이 이미지를 수신하도록 구성될 수 있다. 도 2를 참조하여 설명된 바와 같 이, 전자 장치의 이미지 획득 혹은 수신 방법은 한정되지 않는다. 단계 404에서, 전자 장치는 이미지 내에서 한 명 이상의 사람들의 존재를 검출하기 위한 얼굴 인식을 수행 한다. 예를 들어, 도 3a에 도시된 전자 장치에서, 분리 엔진은 이미지 내에서 한 명 이상의 사람들의 존재를 검출하기 위한 얼굴 인식을 수행하도록 구성될 수 있다. 단계 406에서, 전자 장치는 소정의 풀 인체 템플릿을 이용하여 제1 휴먼 분리를 생성한다. 예를 들어, 도 3a에 도시된 전자 장치에서, 분리 엔진은 소정의 풀 인체 템플릿 및 분리 엔진의 얼굴 인식에 기초하여 제 1 휴먼 분리를 생성하도록 구성될 수 있다. 단계 408에서, 전자 장치는 인공 지능 학습 모델을 이용하여 이미지에서 제 2 휴먼 분리를 생성한다. 예를 들어, 도 3a에 도시된 전자 장치에서, 분리 엔진은 DNN을 이용하여 이미지에서 제 2 휴먼 분리 를 생성하도록 구성될 수 있다. 단계 410에서, 전자 장치는 제1 휴먼 분리 및 제 2 휴먼 분리를 융합하여 합성 휴먼 분리를 획득한다. 예 를 들어, 도 3a에 도시된 전자 장치에서, 분리 엔진은 제 1휴먼 분리와 제 2 휴먼 분리를 융합함으로 써 합성 휴먼 분리를 획득하도록 구성될 수 있다. 방법의 다양한 액션들, 행위들, 블록들, 단계들 등은 제시된 순서, 그와 상이한 순서, 혹은 동시에 수행될 수 있다. 또한 일부 실시예들에서, 상술된 액션들, 행위들, 블록들, 단계들 등 가운데 일부는 본 발명의 범위에서 벗어나지 않은 채, 생략되거나, 추가되거나, 변경되거나, 건너 뛰는 등의 동작이 이루어질 수 있다. 도 5는 일 실시예에 있어서, 제 1 휴먼 분리 및 제 2 휴먼 분리에 기반하여 이미지 내에서 합성 휴먼 분리를 제 공하기 위한 방법을 도시하는 도면이다. 도 5를 참조하면, 단계 1에서, 전자 장치가 사람을 포함하는 이미지를 수신한다. 이미지는 전자 장치(10 0)에서 이미 캡처되어 저장되어 있을 수 있다. 실시예에 있어서, 전자 장치는 전자 장치 내의 카메라 를 이용하여 이미지를 획득할 수 있다. 혹은, 전자 장치는 네트워크를 통하여 연결된 외부 장치 혹은 서버 로부터 이미지를 수신할 수 있다. 전자 장치의 이미지 획득 혹은 수신 방법은 상술된 예에 한정되지 않는 다. 단계 2에서, 얼굴 인식 엔진이 이미지 내의 사람들을 판단하기 위한 얼굴 인식을 수행한다. 또한, 단계 3에서, 제 1 휴먼 분리 생성 엔진은 제 1 휴먼 분리를 생성한다. 휴먼 분리는, 이미지 내의 인 체 형상을 식별할 수 있는 지표가 되는 정보일 수 있다. 실시 예에 있어서, 휴먼 분리는 인체 형상의 외곽선을 나타내는 정보를 포함할 수 있다. 혹은, 휴먼 분리는 인체 형상을 나타내는 영역을 포함하는 면에 관한 정보를 포함할 수 있다. 혹은, 휴먼 분리는 인체의 형상 및 연관 프레임에서 상술된 인체의 형상이 움직이는 영역에 관 한 정보를 포함할 수 있다. 예를 들어, 제 1 휴먼 분리 생성 엔진는 얼굴 데이터에 기반하여 소정의 풀 인체 템플릿을 이미지에서 검 출된 사람에 매핑할 수 있다 또한, 제 1 휴먼 분리 생성 엔진은 이미지 내에서 검출된 사람에 대한 소정의 풀 인체 템플릿의 매핑에 기반하여 제 1 휴먼 분리를 생성할 수 있다. 보다 구체적으로, 제 1 휴먼 분리 생성 엔진은 얼굴 위치, 얼굴 크기 및 가시성(visibility; 시야 안의 얼 굴 몸체) 및 색상 전파(색상 유사도)와 같은 정보를 이용하여 얼굴 인식에 기반하는 템플릿 계수(coefficient) 를 결정하도록 구성될 수 있다. 실시 예에 있어서, 템플릿 계수는 상술된 얼굴 인식에 기반한 정보 및 소정의 인체 풀 템플릿을 비교하여 결정될 수 있다. 또한, 제 1 휴먼 분리 생성 엔진은 소정의 풀 인체 템플릿을 얼굴 인식에 따른 한 명 이상의 사람들에게 맞춤으로써, 소정의 풀 인체 템플릿을 이미지 안에서 검출된 한 명 이상의 사람들에게 매핑하도록 구성될 수 있다. 예를 들어, 1 휴먼 분리 생성 엔진는 결정된 템플릿 계수 및 소정의 풀 인체 템플릿에 기초하여, 소정의 풀 인체 템플릿의 크기, 방향 혹은 이미지 내에서의 위치를 조절 할 수 있다. 실시 예에 있어서, 이미지 내에서 검출된 사람이 인체의 일부만을 포함하고 있을 경우, 1 휴먼 분 리 생성 엔진은 조절된 풀 인체 템플릿의 일부만을 사용할 수 있다. 제 1 휴먼 분리 생성 엔진는 조 절된 풀 인체 템플릿 및 이미지에 기초하여, 제 1 휴먼 분리를 획득할 수 있다. 단계 4는 검출된 사람에 대한 제 1 휴먼 분리를 도시한다. 단계 5에서, 전자 장치는 이미지 내에서 판단된 사람과 매치되는 제 1 휴먼 분리를 획득하기 위하여, 제 1 휴먼 분리를 개선한다. 실시 예에 있어서, 전자 장치는 매핑된 제 1 휴먼 분리에 대해 멀티 레벨 색상 유 사도 기반 템플릿 경계 개선을 수행할 수 있다. 또한, 멀티 레벨 색상 유사도 기반 템플릿 경계 개선은 대상 이 미지가 비디오인 경우 여러 개의 이미지 프레임들에 대해 병렬로 실행될 수 있다. 또한 병행하여 단계 6에서, 안에 사람을 포함하는 이미지는 훈련된 인공 지능 학습 모델에 입력되고, 훈련된 인 공 지능 학습 모델이 입력된 이미지로부터 제 2 휴먼 분리를 생성할 수 있다. 예를 들어, 이미지는 DNN을 통과할 수 있다. DNN에 의해 생성된 제 2 휴먼 분리(단계 7에 도시됨)는 단계 1의 이미지와 비교할 때 낮 은 해상도를 가질 수 있다. 단계 8에서, 단계 5에서 생성된 제 1 휴먼 분리와 단계 7에서 생성된 제 2 휴먼 분리가 서로 결합되어, 단계 9 에 도시된 것과 같이 이미지 내 합성 휴먼 분리를 획득한다. 이미지 내 사람이 분리된 후, 보케 효과, 달리 효 과 같은 다양한 효과들이 이미지에 더해질 수 있고, 배경 객체들을 추가 또는 제거하거나, 배경을 변경하거나, 그래픽을 추가하거나 하는 등의 동작이 수행될 수 있다. 도 6은 일 실시예에 있어서, 인공 지능 학습 모델만을 이용하여 획득되는 이미지 내 휴먼 분리 및, 인공 지능 학습 모델 및 고정된 휴먼 템플릿 둘 모두를 이용하여 획득되는 이미지 내 휴먼 분리 간의 비교를 설명하기 위 한 도면이다. 도 6를 참조하면, 단계 602에서, 이미지는 사람을 포함한다고 가정된다. 이미지 안의 사람의 존재를 검출하기 위해 이미지에 대한 얼굴 인식이 수행된다. 단계 604에서, 인공 지능 학습 모델, 예를 들어 DNN, 만을 사용하여, 이미지로부터 휴먼 분리가 생성된다. 그러나 DNN의 출력은 DNN을 학습시키기 위해 사용되는 학습 데이터에 의존하는 데이터일 수 있다. 따 라서, DNN을 기반으로 휴먼 분리를 생성하는 것은 단계 604에 보여진 바와 같은 에러가 나오기 쉬울 수 있 다. 예를 들어, 분리 시, 도시된 바와 같이 이미지 안에서 검출된 사람의 어깨에서 에러가 관찰될 수 있다. 게다가 이미지 내에서 검출된 사람이 다양한 포즈, 제스처 및 자세로 존재할 경우, 생성되는 템플릿도 에러를 가질 수 있다. 예를 들어, 이미지 안에서 사람이 손을 흔들고 있으면, DNN은 사람이 흔들고 있는 손을 분 리해 내지 못할 수 있다. 또한, DNN의 복잡도로 인해 이미지가 원래의 해상도로 사용되지 못할 수 있다. 예시적으로, DNN에서 휴먼 분리를 산출하기 위해, 12MP 이미지는 320x240으로 크기가 조정될 수 있다. 또한, 분리된 인체를 생성하기 위해, DNN의 출력이 다시 12MP로 상향 조정되면, 이미지의 경계 분리 시 에러를 일으킬 수 있다.따라서, 본 개시의 실시예에 의한 방법에서, DNN의 출력은 제 1 휴먼 분리, 즉 휴먼 템플릿,과 결합될 수 있다(단계 606에 보여짐). 휴먼 템플릿은 전자 장치에 저장된 소정의 풀 인체 템플릿을 이용하여 생성될 수 있다. 또한, 단계 608에 도시된 바와 같이, 인체 템플릿 및 인공 지능 학습 모델을 통해 생성된 휴먼 분리를 융합함으로써 이미지 내 합성 휴먼 분리가 획득될 수 있다. 따라서, 인체 템플릿 및 인공 지능 학습 모델을 통 해 생성된 휴먼 분리를 결합하여 생성되는 합성 휴먼 분리는 이미지 내에서 사람을 분리할 때 높은 정확도를 제 공하며, 경계 분리에 있어서도 정확하다. 또한 인체 템플릿 및 인공 지능 학습 모델을 통해 생성된 휴먼 분리를 결합하여 생성된 합성 휴먼 분리는 단계 602에서의 이미지의 해상도와 같은 오리지널 해상도를 가질 수 있다. 도 7은 본 개시의 실시예에 따라, 휴먼 분리에 기반하는 이미지 내 배경 변경에 대한 예를 도시한다. 도 7을 참조하면, 단계 702에 보여진 바와 같이, 이미지는 사람을 포함한다고 가정한다. 이때, 이미지 안의 사 람의 배경에는 나무와 같은 객체들이 존재할 수 있다. 단계 704에서 전자 장치는 이미지 내의 사람들을 판단하기 위한 얼굴 인식을 수행한다. 또한, 단계 706에 서 보여진 바와 같이, 전자 장치는 소정의 풀 인체 템플릿을 상술된 이미지 내에서 검출된 사람에 매핑함 으로써 제 1 휴먼 분리를 생성한다. 또한 전자 장치는 인공 지능 학습 모델, 예를 들어 DNN을 이용하 여 이미지에서 제 2 휴먼 분리를 생성하며, 제 1 휴먼 분리 및 제 2 휴먼 분리를 결합하여 이미지 내에서 합성 휴먼 분리를 획득한다. 다른 실시예에서, 이미지는 카메라 애플리케이션의 라이브 미리보기일 수 있으며, 이미지 안에 사람을 포함할 수 있다. 그러한 상황에서, 전자 장치는 제 1 휴먼 분리 및 이미지를 융합하여 이미지로부터 휴먼 분리를 생성할 수 있다. 또한 전자 장치는 휴먼 분리에 기반하여 이미지 내에 합성 휴먼 분리를 제공할 수 있다. 단계 708에서, 이미지에서 합성 휴먼 분리가 획득된 후 전자 장치는 이미지의 배경을 변경한다. 단계 708 에서는 예시적으로, 이미지의 배경이 거주 지역으로 변경되었다. 또한, 이미지 내에서 합성 휴먼 분리가 획득된 후, 조명을 변경하고, 다양한 컬러 필터들을 적용하는 등의 기능을 통해 기존의 배경이 변경될 수 있다. 또한, 배경은 3D 객체들 및 효과들을 제공하도록 변경될 수 있다. 예를 들어, GIF 등이 배경에 추가될 수 있다. 실시예에 있어서, 이미지의 배경에 있는 객체들, 배경 색깔 등은 사용자로부터 입력되는 배경 변경 신호에 기초 하여 변경될 수 있다. 또한, 전자 장치는 사용자에게 복수의 기 설정된 배경 혹은 배경에 제공될 효과들을 제공하고, 사용자로부터 수신된 선택 신호에 기초하여 이미지의 배경을 변경할 수 있다. 실시예에 있어서, 라이브 미리보기가 복수의 이미지들로 구성된 시퀀스인 경우, 전자 장치는 일부의 이미 지들을 선택하여 상술된 과정을 수행할 수 있다. 선택된 이미지들에 대한 합성 휴먼 분리 동작 및 이미지 배경 변경 동작은 병렬적으로 동작될 수 있다. 예를 들어, 전자 장치는 시퀀스의 키 프레임을 구성하는 이미지 들에 대하여 합성 휴먼 분리를 획득하고, 이에 기초하여 이미지의 배경을 변경할 수 있다. 따라서, 본 발명의 실시예에 의한 방법은 이미지가 전자 장치에 의해 캡처되기 전 라이브 미리보기에서도, 전자 장치의 사용자가 이미지의 배경을 바꾸는 것을 가능하게 한다. 도 8은 본 개시의 실시예에 따라, 휴먼 분리에 구조광 깊이(structured light depth)를 제공하는 예를 도시한다. 다양한 깊이 상에 위치한 여러 사람들을 포함한 이미지가 고려될 수 있다. 도 8을 참조하면, 단계 802에서 전자 장치는 이미지를 수신하여, 이미지 안에 존재하는 여러 사람들 각각에 대한 얼굴 인식을 수행한다. 이미지 는 전자 장치의 카메라 애플리케이션에 의해 얻어지는 라이브 미리보기 이미지일 수 있다. 또한 단계 804에서, 이미지 내 여러 사람들 각각의 깊이에 대한 추정치를 획득하기 위해, 이미지 내 여러 사람 들과 관련된 구조광 데이터가 휴먼 분리와 결합된다. 구조광 데이터는 다양한 알고리즘을 통해 획득될 수 있다. 이미지 내 여러 사람들 각각의 깊이에 대한 추정치에 기반하여, 이미지 내 사람들 각각이 따로 따로 분리될 수 있다. 혹은, 이미지 내 사람들은 깊이에 대한 추정치에 기반하여 유사한 깊이를 가지는 그룹으로 분리될 수 있 다. 이미지 내 여러 사람들과 관련된 구조광 데이터와 휴먼 분리와의 결합을 이용하여, 전자 장치는 이미 지의 전경에 위치하는 사람과 이미지의 배경에 위치하는 사람들에 대한 정보를 제공할 수 있다. 단계 806에서, 구조광에 기반하여 전경에 있는 사람이 분리된다. 이미지의 전경에 있는 사람이 분리된 후, 전경 에 있는 사람에 선택적으로 초점을 맞추기, 달리 효과 적용, 없는 사람 삽입 등과 같은 다양한 효과들이 이미지 에 적용될 수 있다. 또한, 둘 이상의 사람들이 전경의 일부로 간주될 수 있고, 휴먼 분리에 기반하여 전경에 있는 그 사람들과 떨어 진 이미지의 다른 부분이 블러링되거나, 배경에 있는 사람들이나 전경에 있는 그 둘 이상의 사람들 이외의 이미 지의 하나 이상의 부분들이 혹은 그 조합을 불명료하게 랜더링할 수 있다. 도 9는 본 개시의 실시예에 따라, 휴먼 분리에 기반하여 제1이미지 안에 제2이미지로부터의 사람을 삽입하는 예 를 도시한다. 도 9를 참조하면, 단계 902에서 전자 장치에 의해 제1이미지가 수신되고, 얼굴 인식 수행을 통해 제1이미 지 안의 사람이 검출된다. 또한, 인공 지능 학습 모델을 이용하여 결정된 제 2 휴먼 분리 및 인체 템플릿에 기초하여 결정된 제 1 휴먼 분리에 기초하여 제1이미지 안의 사람이 분리된다. 단계 904에서 전자 장치에 의해 제2이미지가 수신되고, 얼굴 인식 수행을 통해 제2이미지 안의 사람이 검 출된다. 또한, 인공 지능 학습 모델을 이용하여 결정된 제 2 휴먼 분리 및 인체 템플릿에 기초하여 결정된 제 1 휴먼 분리에 기초하여 제2이미지 안의 사람이 분리된다. 단계 906에서, 제2이미지에서 분리된 사람이 제1이미지 안으로 삽입된다(즉, 제2이미지 안의 사람이 제1이미지 에 중첩된다). 여기서 제1이미지는 제1이미지에서 분리된 사람과 제2이미지에서 분리된 사람을 포함할 수 있다. 따라서, 제1이미지에서는 없었던, 제2이미지에서 분리된 사람이 휴먼 분리에 기반하여 제1이미지 안에 삽입될 수 있다. 본 실시예에서는 시스템의 휴먼 분리 동작에 기반하여 제2이미지로부터의 사람을 제1이미지 안에 삽입 하는 동작을 두 개의 이미지들과 관련하여 설명하였으나, 본 실시예의 기술적 특징은 이에 한정되지 않는다. 예 를 들어, 전자 장치는 이미지들의 시퀀스를 처리하도록 구성될 수 있다. 실시예에 있어서, 제 2 이미지에 서 분리된 사람의 제 1 이미지에서의 상대적 위치는 깊이에 대한 추정치에 기반하여 결정될 수 있다. 혹은, 제 2 이미지에서 분리된 사람의 제 1 이미지에서의 상대적 위치 및 크기는 입력부(미도시)를 통하여 수신된 사용자 로부터의 입력 신호에 기초하여 결정될 수 도 있다. 마찬가지로, 전자 장치는 이미지에서 한 명 이상의 사람들을 분리한 후, 3D 워터마크, 클립아트, 텍스트와 같은 임의의 그래픽 객체들을 이미지 안에 삽입할 수 있다. 도 10은 본 개시의 실시예에 따라, 휴먼 분리에 기반하여 이미지에 달리(dolly) 효과를 주는 예를 도시한다. 도 10를 참조하면, 단계 1002에서 전자 장치가 이미지를 수신한다. 단계 1004에서, 전자 장치는 이미 지 안의 사람에 대해 얼굴 인식을 수행하여 얼굴 데이터 및 얼굴 랜드마크들을 획득한다. 단계 1006에서, 제 1 휴먼 분리 및 제 2 휴먼 분리를 이용하여, 이미지에 대해 수행된 합성 휴먼 분리에 기반하여 이미지 안의 사람 이 분리된다. 단계 1008에서, 전자 장치가 합성 휴먼 분리를 수행한 후, 달리 효과가 그 이미지에 적용된다. 실시예에 있어서, 이미지 안의 사람은 단계 1002에서와 같이 동일한 크기로 유지되고 이미지의 배경의 크기는 이미지 내 사람에 비해 달라지게 될 수 있다. 달리 효과는 전자 장치의 카메라 애플리케이션의 라이브 미리보기 이미지에도 적용될 수 있다. 이미지 안의 사람이 분리된 후, 달리 효과, 보케 효과, 이미지 내 사람의 재조명 등과 같은 다양한 효과들이 적 용될 수 있다. 그에 따라, 본 발명의 방법은 전자 장치에 의한 자동 휴먼 분리를 제공하며, 이는 사용자 에게 휴먼 분리에 기반하는 개선된 효과들을 적용한 이미지들을 얻을 수 있게 한다. 도 11은 본 개시의 실시예들에 따라, 라이브 미리보기 이미지 내에 휴먼 분리를 제공하는 방법을 도시한 흐름도 이다. 도 11를 참조하면, 단계 1102에서 전자 장치는 카메라에 의해 캡처된 라이브 미리보기 이미지(이미지)를 획득한다. 예를 들어 도 3a에 도시된 바와 같은 전자 장치에서, 분리 엔진은 카메라에 의해 캡처된 라이브 미리보기 이미지를 획득하도록 구성될 수 있다. 단계 1104에서, 전자 장치는 이미지 내에서 한 명 이상의 사람들의 존재를 검출하기 위한 얼굴 인식을 수 행한다. 예를 들어, 도 3a에 도시된 전자 장치에서, 분리 엔진은 이미지 내에서 한 명 이상의 사람들 의 존재를 검출하기 위한 얼굴 인식을 수행하도록 구성될 수 있다. 단계 1106에서, 전자 장치는 소정의 풀 인체 템플릿을 상술된 이미지 내에서 검출된 한 명 이상의 사람들 에 매핑함으로써 제 1 휴먼 분리를 생성한다. 단계 1108에서, 전자 장치는 제 1 휴먼 분리 및 이미지를 융합하여 합성 휴먼 분리를 획득한다. 예를 들어, 도 3a에 도시된 전자 장치에서, 분리 엔진은 제 1 휴먼 분리와 이미지를 융합함으로써 합성 휴 먼 분리를 획득하도록 구성될 수 있다. 단계 1110에서, 전자 장치는 합성 휴먼 분리에 기반하여 이미지 내에 휴먼 분리를 제공한다. 예를 들어, 도 3a에 도시된 전자 장치에서, 분리 엔진은 합성 휴먼 분리에 기반하여 이미지 내에 휴먼 분리를 제 공하도록 구성될 수 있다. 방법의 다양한 액션들, 행위들, 블록들, 단계들 등은 제시된 순서, 그와 상이한 순서, 혹은 동시에 수행될 수 있다. 또한 일부 실시예들에서, 상술된 액션들, 행위들, 블록들, 단계들 등 가운데 일부는 본 발명의 범위에서 벗어나지 않은 채, 생략되거나, 추가되거나, 변경되거나, 스킵되는 등의 동작이 이루어질 수 있다. 도 12는 본 개시의 실시예들에 따라 전자 장치의 카메라에 의해 캡처된 라이브 미리보기 이미지에 보케 (bokeh) 효과를 제공하는 방법을 도시한다. 도 12를 참조하면, 단계 1에서, 전자 장치의 카메라 애플리케이션의 라이브 미리보기에서 사람을 포함하는 이미지를 고려한다. 단계 2에서 얼굴 인식 엔진이 카메라 애플리케이션의 라이브 미리보기 이미지 내의 사람들을 판단하기 위 한 얼굴 인식을 수행한다. 또한 단계 3에서 제 1 휴먼 분리 생성 엔진이 얼굴 데이터에 기반하여 소정의 풀 인체 템플릿을 이미지에서 검출된 사람에 매핑하여 제 1 휴먼 분리를 생성한다. 단계 1에서 검출된 사람에 대해 매핑된 제 1 휴먼 분리는 단계 4에 보여진 바와 같다. 단계 5에서, 전자 장치는 이미지 내에서 판단된 사람과 완벽하게 매치되는 휴먼 분리를 획득하기 위하여, 매핑된 휴먼 템플릿에 대해 멀티 레벨 색상 유사도 기반 템플릿 경계 개선을 수행한다. 멀티 레벨 색상 유사도 기반 템플릿 경계 개선을 수행한 후의 제 1 휴먼 분리가 단계 6에서와 같이 도시된다. 또한, 멀티 레벨 색상 유 사도 기반 템플릿 경계 개선은 비디오의 경우 여러 개의 이미지 프레임들에 대해 병렬로 실행될 수 있다. 제 1 휴먼 분리가 추가 개선을 거침으로써 개선된 휴먼 분리가 생성되고, 개선된 휴먼 분리는 단계 8에서 템플릿 버 퍼를 거칠 수 있다. 또한, 병행하여 단계 9에서, 카메라 애플리케이션의 라이브 미리보기에서 사람을 포함하는 이미지가 완전히 블 러링된다. 단계 10에서 라이브 미리보기 내 사람을 포함한 블러링된 이미지와 개선된 휴먼 분리, 즉 최종 휴먼 템플릿에 기초하여 획득된 사람에 관한 정보가 블렌딩되어, 단계 11에서와 같이 카메라 애플리케이션의 라이브 미리보기 안에서 보케 효과를 얻게 된다. 도 13은 본 개시의 실시예에 따라, 휴먼 분리에 기반하여 이미지에 보케 효과를 적용하는 방법을 예시한 흐름도이다. 도 13를 참조하면, 단계 1302에서 전자 장치는 카메라 애플리케이션에 의해 캡처된 라이브 미리보기 이미 지(이미지)를 획득한다. 예를 들어 도 3a에 도시된 바와 같은 전자 장치에서, 분리 엔진은 카메라 애 플리케이션에 의해 캡처된 라이브 미리보기 이미지를 획득하도록 구성될 수 있다. 단계 1304에서, 전자 장치는 이미지 내에서 휴먼 분리를 획득한다. 예를 들어 도 3a에 도시된 바와 같은 전자 장치에서, 분리 엔진은 이미지 내에서 휴먼 분리를 획득하도록 구성될 수 있다. 단계 1306에서, 전자 장치는 휴먼 분리에 기반하여 이미지 내에 보케 효과를 적용한다. 예를 들어, 도 3a에 도시된 전자 장치에서, 분리 엔진은 휴먼 분리에 기반하여 이미지 내에 보케 효과를 적용하도록 구성될 수 있다. 방법의 다양한 액션들, 행위들, 블록들, 단계들 등은 제시된 순서, 그와 상이한 순서, 혹은 동시에 수행될 수 있다. 또한 일부 실시예들에서, 상술된 액션들, 행위들, 블록들, 단계들 등 가운데 일부는 본 발명의 범위에서 벗어나지 않은 채, 생략되거나, 추가되거나, 변경되거나, 건너 뛰는 등의 동작이 이루어질 수 있다. 도 14는 본 개시의 실시예에 따라, 휴먼 분리에 기반하여 이미지에 보케 효과를 주는 예를 도시한다. 사진에서, 포커스를 맞출 주요 대상(본 발명의 방법에서 분리된 사람)을 포함하지 않은 이미지의 배경 및/또는 전경을 블러링 처리하기 위해 필드의 깊이(depth of field)를 사용하여 보케 또는 블러링 효과가 제공될 수 있 다. 도 14를 참조하면, 단계 1402에서, 전자 장치의 카메라 애플리케이션에서 사람을 포함하는 라이브 미리보 기에 해당하는 이미지를 고려한다. 단계 1404에서 전자 장치는 이미지 내의 사람들을 판단하기 위한 얼굴 인식을 수행한다. 또한, 단계 1406에서 보여진 바와 같이, 전자 장치는 소정의 풀 인체 템플릿을 상술된 이미지 내에서 검출된 사람에 매핑함으로써 제 1 휴먼 분리를 생성한다. 또한 전자 장치는 제 1 휴먼 분리 및 이미지를 융합하여 이미지로부터 합성 휴먼 분리를 생성한다. 또한 전자 장치는 합성 휴먼 분리에 기반하여 이미지 내에 휴먼 분리를 제공한다. 다른 실시예에서, 이미지는 전자 장치에 캡처되어 저장된 임의의 이미지일 수 있다. 그러한 상황에서, 전 자 장치는 인공 지능 학습 모델, 예를 들어 DNN을 이용하여 이미지에서 제 2 휴먼 분리를 생성하며, 제 1 휴먼 분리 및 제 2 휴먼 분리를 융합하여 이미지 내에서 합성 휴먼 분리를 획득할 수 있다. 단계 1408에서, 이미지 안의 사람이 분리되고, 전자 장치는 그 이미지에 보케 효과를 적용한다. 보케 효과 는 예컨대, 필드 블러(filed blur), 아이리스 블러(iris blur) 및 경사-이동(tilt-shift) 블러와 같은 다양한 블러링 패턴들과 함께 사용될 수 있다. 또한 블러링 패턴들은 둘 이상의 블러링 패턴들과 함께 사용될 수 있다. 특정 실시예들에 대한 상술된 내용은 이 안의 실시예들의 일반적인 성격을 충분히 드러내어 타자들이 현재의 지 식을 적용하여 일반 개념으로부터 벗어나지 않고 그러한 특정 실시예들과 같은 다양한 적용예들을 용이하게 변 형 및/또는 적응시킬 수 있도록 할 것이며, 그에 따라 적응 및 변형들은 개시된 실시예들의 의미 및 범위 내에 포괄되어야 하며 그렇게 의도된다. 이 안에서 사용된 어법이나 용어는 한정하는 것이 아닌 설명의 목적을 위한 것임을 알아야 한다. 따라서 이 안의 실시예들은 바람직한 실시예들과 관련하여 기술되었으나 당업자는 이 안의 실시예들이 여기 기술된 것과 같은 실시예들의 사상 및 범위 안에서의 변형을 통해 실시될 수 있다는 것을 인지 할 것이다."}
{"patent_id": "10-2018-0107401", "section": "도면", "subsection": "도면설명", "item": 1, "content": "본 발명은 첨부된 도면들을 통해 예시되며, 도면들 전체에 걸쳐 유사 참조 부호들은 다양한 형태의 해당 구성요 소들을 나타낸다. 이 안의 실시예들은 도면들을 참조하는 이하의 설명으로부터 보다 잘 파악될 것이다. 도 1은 일 실시예에 있어서, 고정된 템플릿을 얼굴 인식에만 기초하여 이미지 내 사람들에 적용하는 방법을 설 명하기 위한 도면이다. 도 2는 일 실시예에 있어서, 휴먼 분리(segmentation)에 기반하여 이미지에 적용될 수 있는 다양한 효과들을 설 명하기 위한 도면이다. 도 3a는 일 실시예에 있어서, 이미지 내에 휴먼 분리를 제공하기 위한 전자 장치의 구성요소들을 도시한 블록도 이다. 도 3b는 일 실시예에 의한 분리 엔진의 구성요소들을 도시한 블록도이다. 도 4는 일 실시예에 의한 제 1 휴먼 분리 및 제 2 휴먼 분리를 이용하여 이미지 내에 휴먼 분리를 제공하기 위 한 방법을 설명하기 위한 흐름도이다.도 5는 일 실시예에 있어서, 제 1 휴먼 분리 및 제 2 휴먼 분리를 이용하여, 이미지 내에 휴먼 분리를 제공하기 위한 방법을 설명하기 위한 도면이다. 도 6은 일 실시예에 있어서, 인공 지능 학습 모델만을 이용하여 획득되는 이미지 내 휴먼 분리 및 인공 지능 학 습 모델 및 고정된 휴먼 템플릿 둘 모두를 이용하여 획득되는 이미지 내 휴먼 분리 간을 비교하는 도면이다. 도 7은 일 실시예에 있어서, 휴먼 분리에 기반하는 이미지 내 배경 변경 방법을 설명하기 위한 도면이다. 도 8은 일 실시예에 있어서, 구조광 깊이(structured light depth)와 함께 휴먼 분리를 제공하는 방법을 설명하 기 위한 도면이다. 도 9는 일 실시예에 있어서, 휴먼 분리에 기반하여 제1이미지 안에 제2이미지로부터의 사람을 삽입하는 방법을 설명하기 위한 도면이다. 도 10은 일 실시예에 있어서, 휴먼 분리에 기반하여 이미지에 달리(dolly) 효과를 주는 방법을 설명하기 위한 도면이다. 도 11은 일 실시예에 있어서, 라이브(live) 미리보기 이미지 내에 휴먼 분리를 제공하는 방법을 설명하기 위한 흐름도이다. 도 12는 일 실시예에 있어서, 전자 장치의 카메라에 의해 캡처된 라이브 미리보기 이미지에 보케(bokeh) 효과를 제공하는 방법을 설명하기 위한 도면이다. 도 13은 일 실시예에 있어서, 휴먼 분리에 기반하여 이미지에 보케 효과를 적용하는 방법을 설명하기 위한 흐름 도이다. 도 14는 일 실시예에 있어서, 휴먼 분리에 기반하여 이미지에 보케 효과를 주는 방법을 설명하기 위한 도면이다."}
