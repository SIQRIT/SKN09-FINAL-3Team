{"patent_id": "10-2023-0158972", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0074676", "출원번호": "10-2023-0158972", "발명의 명칭": "연합 학습을 이용한 기계 학습 모델 훈련 시스템", "출원인": "삼성전자주식회사", "발명자": "타시 안드레아"}}
{"patent_id": "10-2023-0158972", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "셀룰러 네트워크에서 기계 학습(ML) 모델을 훈련하기 위한 매개변수 서버로서, 훈련을 위한 적어도 하나의 ML 모델; 연합 학습 작업이 실행되는 것에 응답하여 상기 적어도 하나의 ML 모델을 업데이트하기 위한 적어도 하나의 모듈; 및 상기 셀룰러 네트워크에서 연합 학습 작업의 실행을 관리하기 위한 스케줄러를 포함하며,각 연합 학습 작업에 대해, 상기 스케줄러는,복수의 가입 사용자 장치(UE) 중에서 상기 연합 학습 작업을 수행하는 데 적합한 UE 세트를 선택하고; 상기 선택된 UE 세트를 복수의 클러스터로 그룹화하는 방법을 지정하는 상기 연합 학습 작업에 대한 클러스터링정책을 결정하고; 그리고상기 복수의 클러스터 중 각 클러스터에 상기 연합 학습 작업을 수행하도록 지시하도록 구성되는, 매개변수 서버."}
{"patent_id": "10-2023-0158972", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 스케줄러는,적어도 하나의 연합 학습 작업을 수행하기 위해 각각 가입한 상기 복수의 가입 UE에 대한 정보를 저장하고;특정 ML 모델에 대해 연합 학습 작업을 실행하거나 재실행하라는 요청을 상기 적어도 하나의 모듈로부터 수신하고 - 상기 요청은 상기 요청된 연합 학습 작업을 수행하는 UE들이 충족해야 할 적어도 하나의 조건을 지정함 -;상기 복수의 가입 UE에 대한 저장된 정보를 이용하여, 상기 복수의 가입 UE가 상기 적어도 하나의 조건을 만족하는지 여부를 결정하며; 그리고상기 결정에 기초하여 상기 요청이 승인되는지 여부를 지시하는 응답을 상기 적어도 하나의 모듈로 전송하도록더 구성되는, 매개변수 서버."}
{"patent_id": "10-2023-0158972", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,상기 적어도 하나의 조건은 서비스 품질(QoS) 프로파일; 상기 연합 학습 작업을 수행하는 데 필요한 최소 UE수; 및 상기 연합 학습 작업을 수행하기 위한 UE 하드웨어 용량 요구 사항 중 하나 이상을 지정하는 것인, 매개변수 서버."}
{"patent_id": "10-2023-0158972", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제3항에 있어서,상기 연합 학습 작업은 복수의 훈련 반복을 포함할 수 있으며, 훈련 반복이 시작되기 전에, 상기 스케줄러는,상기 UE들이 여전히 상기 연합 학습 작업의 상기 훈련 반복을 수행할 수 있는지 여부를 결정하기 위하여 상기복수의 클러스터의 상기 UE들로부터 수신된 UE 상태 메시지를 확인하고; 그리고적어도 하나의 UE가 상기 연합 학습 작업의 상기 훈련 반복을 수행할 수 없다고 결정한 경우에 응답하여, 코디네이터로 하여금 상기 클러스터링 정책 및 상기 UE 상태 메시지에 따라 상기 UE들을 복수의 클러스터로 재그룹화하도록 지시하도록 구성되는, 매개변수 서버.공개특허 10-2024-0074676-3-청구항 5 제4항에 있어서,상기 매개변수 서버의 상기 적어도 하나의 모듈은,상기 스케줄러를 통해 UE로부터 매개변수들의 제1 세트 및 매개변수들의 제2 세트를 수신하고; 그리고상기 제1 세트 및 상기 제2 세트를 사용하여 상기 UE들에 의해 수행된 상기 연합 학습 작업에 해당하는 상기 ML모델을 업데이트하도록 구성되며,상기 매개변수의 제1 세트는 상기 UE에 저장된 적어도 하나의 훈련 데이터 항목을 사용하는 상기 연합 학습 작업에 대응하는 상기 ML 모델의 로컬 버전의 훈련에 기반하여 생성되며, 그리고상기 매개변수의 제2 세트는 상기 UE에 의해 생성된 적어도 하나의 훈련 데이터 항목 및 상기 클러스터 내의 다른 UE로부터 수신된 적어도 하나의 생성된 코딩된 훈련 데이터 항목을 사용하는 상기 연합 학습 작업에 대응하는 상기 ML 모델의 로컬 버전의 훈련에 기반하여 생성되는, 매개변수 서버."}
{"patent_id": "10-2023-0158972", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5항에 있어서,상기 매개변수의 제1 세트가 미리 정의된 기간 내에 상기 복수의 클러스터로부터 미리 정의된 최소 개수의 UE로부터 수신되면, 상기 적어도 하나의 모듈은,상기 복수의 클러스터의 상기 UE로부터 수신된 상기 매개변수의 제1 세트를 집계하고; 상기 집계된 매개변수의 제1 세트를 사용하여 상기 ML 모델을 업데이트해서 상기 ML 모델을 업데이트하도록 구성되는, 매개변수 서버."}
{"patent_id": "10-2023-0158972", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제5항에 있어서,상기 매개변수들의 제1 세트가 미리 정의된 시간 기간 내에 상기 복수의 클러스터로부터 미리 정의된 최소 수보다 적은 수의 UE로부터 수신되는 경우, 상기 적어도 하나의 모듈은,상기 복수의 클러스터의 상기 UE들로부터 수신된 상기 매개변수들의 제1 세트를 집계하고; 상기 UE들로부터 수신된 상기 매개변수들의 제2 세트의 무작위 선택을 집계하고; 그리고 상기 집계된 매개변수들의 제1 세트와 상기 집계된 매개변수들의 제2 세트의 무작위 선택을 사용하여 상기 ML모델을 업데이트하는 것에 의해, 상기 ML 모델을 업데이트 하도록 구성되는, 매개변수 서버."}
{"patent_id": "10-2023-0158972", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서,상기 매개변수들의 제2 세트가 사전 정의된 시간 기간 내에 클러스터 내 사전 정의된 최소 수 미만의 UE로부터수신되는 경우, 상기 적어도 하나의 모듈은 상기 ML모델의 업데이트를 종료하도록 구성되는, 매개변수 서버."}
{"patent_id": "10-2023-0158972", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1항에 있어서,상기 셀룰러 네트워크는 개방형 무선 액세스 네트워크(ORAN)이며,상기 매개변수 서버는 비실시간 무선 지능형 컨트롤러(non-RT-RIC)를 포함하는 서비스 관리 및 오케스트레이션(SMO) 플랫폼이며,상기 적어도 하나의 ML 모델을 업데이트하기 위한 상기 적어도 하나의 모듈은 non-RT-RIC에서 실행되도록 구성된 소프트웨어 애플리케이션(rApp)이며,상기 스케줄러는 상기 non-RT-RIC에서 실행되도록 구성된 소프트웨어 애플리케이션인, 매개변수 서버. 공개특허 10-2024-0074676-4-청구항 10 셀룰러 네트워크에서 기계 학습(ML) 모델을 훈련하기 위한 사용자 장치(UE)로서,복수의 훈련데이터 항목을 저장하는 스토리지; 및 상기 스토리지에 연결되고, 데이터 코딩 최적화 정책을 수신하고; 매개변수 서버로부터 ML 모델에 대한 연합 학습 작업을 수행하라는 명령을 수신하고; 상기 수신된 데이터 코딩 최적화 정책에 기초하여, 상기 스토리지 내에 적어도 하나의 훈련 데이터 항목에 대해코딩된 훈련 데이터 항목을 생성하고; 그리고 상기 적어도 하나의 생성된 코딩된 훈련 데이터 항목을 UE의 클러스터 또는 상기 클러스터 내의 상기 UE에 연결된 노드로 전송하도록 구성되는 적어도 하나의 프로세서를 포함하는, 사용자 장치(UE)."}
{"patent_id": "10-2023-0158972", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제10항에 있어서,상기 적어도 하나의 프로세서는,상기 UE에 저장된 적어도 하나의 훈련 데이터 항목을 사용하는 상기 연합 학습 작업에 해당하는 상기 ML 모델의로컬 버전을 훈련함으로써 매개변수들의 제1 세트를 생성하고; 상기 UE에 의해 생성된 적어도 하나의 생성된 코딩된 훈련 데이터 항목 및 UE의 상기 클러스터 내의 다른 UE로부터 수신된 적어도 하나의 생성된 코딩된 훈련 데이터 항목을 사용하는 상기 연합 학습 작업에 해당하는 상기ML 모델의 로컬 버전을 훈련함으로써 매개변수들의 제2 세트를 생성하고; 그리고상기 제1 세트 및 제2 세트를 상기 매개변수 서버에 전송하도록 더 구성되는, 사용자 장치(UE)."}
{"patent_id": "10-2023-0158972", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항에 있어서,상기 적어도 하나의 프로세서는,상기 UE가 적어도 하나의 연합 학습 작업을 수행할 수 있음을 지시하는 가입 요청을 상기 매개변수 서버에 전송하고; 그리고 상태 업데이트 메시지를 상기 매개변수 서버로 주기적으로 전송하도록 더 구성되는, 사용자 장치(UE)."}
{"patent_id": "10-2023-0158972", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "셀룰러 네트워크에서 연합 학습을 사용하여 기계 학습(ML) 모델을 훈련하기 위한 매개변수 서버에 의해 수행되는 방법으로서,상기 셀룰러 네트워크에서 복수의 가입 사용자 장치(UE)로부터 연합 학습 작업을 수행하기에 적합한 가입 UE 세트를 선택하는 단계 - 각 가입 UE는 적어도 하나의 연합 학습 작업을 수행하기 위해 가입함 -; 상기 선택된 가입 UE 세트를 복수의 클러스터로 그룹화하는 방법을 지정하는, 상기 연합 학습 작업에 대한 클러스터링 정책을 결정하는 단계; 및상기 복수의 가입 UE의 클러스터 중 각 클러스터에게 상기 연합 학습 작업을 수행하도록 지시하는 단계를 포함하는, 방법."}
{"patent_id": "10-2023-0158972", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제13항에 있어서, 특정 ML 모델에 대해 연합 학습 작업을 실행하거나 재실행하라는 요청을 수신하는 단계를 더 포함하는, 방법. 공개특허 10-2024-0074676-5-청구항 15 제14항에 있어서, 상기 연합 학습 작업을 수행할 때, 각 클러스터의 상기 UE에 의한 연합 학습 작업의 상기 실행을 조정하기 위한코디네이터에게 상기 복수의 클러스터의 각 UE에 의해 사용될 클러스터별 데이터 코딩 최적화 정책을 결정하라는 요청을 전송하는 단계를 더 포함하며, 상기 클러스터별 데이터 코딩 최적화 정책은 각 클러스터 내의 UE가데이터를 전송하는 방법을 정의하는 것인, 방법."}
{"patent_id": "10-2023-0158972", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "셀룰러 네트워크에서 기계 학습(ML) 모델을 훈련하기 위한 코디네이터에 의해 수행되는 방법으로서,매개변수 서버로부터 연합 학습 작업을 위한 클러스터링 정책과 사용자 장치(UE) 세트에 대한 정보를 수신하는단계; 및상기 클러스터링 정책에 기초하여 상기 UE 세트를 복수의 클러스터로 그룹화하는 단계를 포함하며,상기 클러스터링 정책은 상기 UE 세트를 상기 복수의 클러스터로 그룹화하는 방법을 지정하며, 및상기 UE 세트는 상기 셀룰러 네트워크의 복수의 UE들 중에서 상기 연합 학습 작업을 수행하는 데 적합한 것으로선택되는, 방법."}
{"patent_id": "10-2023-0158972", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제16항에 있어서,상기 연합 학습 작업을 수행할 때 상기 복수의 클러스터의 각 UE가 사용할 클러스터별 데이터 코딩 최적화 정책을 결정하는 단계를 더 포함하며, 상기 클러스터별 데이터 코딩 최적화 정책은 각 클러스터 내의 UE가 데이터를전송하는 방법을 정의하는 것인, 방법."}
{"patent_id": "10-2023-0158972", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제17항에 있어서, 상기 연합 학습 작업이 실행되는 동안 미리 정의된 기간 후에 상기 UE 세트를 상기 클러스터링 정책에 기초하여복수의 클러스터로 주기적으로 재그룹화하는 단계; 및상기 재그룹화 후에 상기 연합 학습 작업을 수행할 때 상기 복수의 클러스터 내의 각 UE가 사용할 클러스터별데이터 코딩 최적화 정책을 다시 결정하는 단계를 더 포함하는, 방법."}
{"patent_id": "10-2023-0158972", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제16항에 있어서,상기 매개변수 서버가 각 클러스터의 UE들에게 상기 연합 학습 작업을 수행하도록 지시할 수 있도록, 상기 연합학습 작업을 위해 각 클러스터에 어떤 UE들이 있는지에 대한 정보를 상기 매개변수 서버로 전송하는 단계를 더포함하는, 방법."}
{"patent_id": "10-2023-0158972", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제16항에 있어서,상기 코디네이터는 상기 셀룰러 네트워크의 노드를 제어하는 근 실시간 무선 지능형 컨트롤러(near-real timeradio intelligent controller: near-RT-RIC)에서 실행되도록 구성된 소프트웨어 애플리케이션인 것인, 방법."}
{"patent_id": "10-2023-0158972", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "셀룰러 네트워크에서 사용자 장치(UE)를 사용하는 기계 학습(ML) 모델의 보다 효율적인 연합 학습(FL)을 위한 방 법 및 시스템이 개시된다. 특히, 연합 학습 프로세스에 대한 셀룰러 네트워크의 열악한 채널 조건의 영향을 줄이 기 위한 시스템이 제공된다. 셀룰러 네트워크는 5G, 6G 또는 차세대 셀룰러 네트워크일 수 있다. 유리하게는, 본 개시는 UE로부터 수신된 데이터를 사용하여 ML 모델을 업데이트하는 중앙 매개변수 서버와 UE 사이의 데이터 전 송 실패로 인해 FL 훈련 프로세스가 중단될 가능성을 줄이기 위해 FL 훈련된 모델 매개변수의 전송에 리던던시를 생성한다."}
{"patent_id": "10-2023-0158972", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 일반적으로 셀룰러 네트워크에서 사용자 장치(UE)를 사용하는 기계 학습(ML) 모델의 보다 효율적인 연합 학습(federated learning, FL)에 관한 것이다. 특히, 본 개시는 연합 학습 프로세스에 대한 셀룰러 네트워크의 열악한 채널 조건의 영향을 줄이기 위한 시스템을 제공한다."}
{"patent_id": "10-2023-0158972", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "무선 통신 세대를 거듭하면서 발전한 과정을 돌아보면 보이스 콜, 멀티미디어 서비스, 데이터 서비스 등 주로 인간 대상의 서비스를 위한 기술이 개발되어 왔다. 5G (5th-generation) 통신 시스템 상용화에 따라 커넥티드 기기들의 수가 기하급수적으로 늘어날 것으로 예상된다. 커넥티드 기기들은 점점 통신 네트워크에 연결될 것으 로 전망된다. 네트워크에 연결된 사물의 예로는 차량, 로봇, 드론, 가전제품, 디스플레이, 각종 인프라에 설치 된 스마트 센서, 건설기계, 공장 장비 등이 있을 수 있다. 모바일 기기는 증강현실(AR) 안경, 가상현실(VR) 헤 드셋, 홀로그램 기기 등 다양한 폼팩터로 진화할 것으로 예상된다. 6G (6th-generation) 시대에는 수천억 개의 기기 및 사물을 연결하여 다양한 서비스를 제공하기 위해, 개선된 6G 통신 시스템을 개발하기 위한 노력이 이 루어지고 있다. 이러한 이유로, 6G 통신 시스템은 5G 통신 이후 (Beyond 5G) 시스템이라 불리어지고 있다. 2030년쯤 상용화될 것으로 예측되는 6G 통신 시스템에서 최대 전송 속도는 테라 (즉, 1,000기가) bps, 무선 지연시간은 100마이크로초(μsec) 미만이다. 따라서, 5G 통신 시스템대비 6G 통신 시스템에서의 전송 속도 는 50배 빨라지고 무선 지연시간은 10분의 1로 줄어든다. 이러한 높은 데이터 전송 속도 및 초저(ultra low) 지연시간을 달성하기 위해, 6G 통신 시스템은 테라헤르츠 (terahertz) 대역 (예를 들어, 95기가헤르츠(95GHz)에서 3테라헤르츠(3THz)대역)에서의 구현이 고려되고 있다. 테라헤르츠 대역에서는 5G에서 도입된 밀리미터파(mmWave) 대역에 비해 더 심각한 경로손실 및 대기흡수 현상 으로 인해서 신호 도달거리 (즉, 커버리지)를 보장할 수 있는 기술의 중요성이 더 커질 것으로 예상된다. 커버 리지를 보장하기 위한 주요 기술로서 RF(radio frequency) 소자, 안테나, OFDM (orthogonal frequency division multiplexing)보다 커버리지 측면에서 더 우수한 신규 파형(waveform), 빔포밍(beamforming) 및 거대 배열 다중 입출력(massive multiple-input and multiple-output (MIMO)), 전차원 다중입출력(full dimensional MIMO: FD-MIMO), 어레이 안테나(array antenna), 대규모 안테나(large scale antenna)와 같은 다중 안테나 전 송 기술 등이 개발되어야 한다. 이 외에도 테라헤르츠 대역 신호의 커버리지를 개선하기 위해 메타물질 (metamaterial) 기반 렌즈 및 안테나, OAM(orbital angular momentum), RIS(reconfigurable intelligent surface) 등의 새로운 기술들이 논의되고 있다. 또한 주파수 효율 향상 및 전반적 네트워크 성능 개선을 위해, 6G 통신 시스템에서는 다음과 같은 기술들이 개발되어 왔다: 상향링크(uplink) 전송과 하향링크(downlink) 전송이 동일 시간에 동일 주파수 자원을 동시에 활용하는 전이중화(full duplex) 기술; 위성(satellite) 및 HAPS(high-altitude platform stations)등을 통합 적으로 활용하는 네트워크 기술; 이동 기지국 등을 지원하고 네트워크 운영 최적화 및 자동화 등을 가능하게 하 는 개선된 네트워크 구조; 스펙트럼 사용 예측에 기초한 충돌 회피를 통한 동적 주파수 공유 (dynamic spectrum sharing) 기술; 6G 개발을 위해 AI (artificial intelligence)를 설계 단계에서부터 활용하고 종단간(end-to- end) AI 지원 기능을 내재화하여 전반적인 네트워크 운영 개선을 위해 무선통신에 AI를 활용; 및 네트워크 상에 서 도달 가능한 초고성능 통신과 컴퓨팅 자원(mobile edge computing (MEC), 클라우드 등)을 활용하여 단말 연 산 능력의 한계를 넘어서는 차세대 분산 컴퓨팅 기술. 뿐만 아니라 6G 통신 시스템에서 이용될 새로운 프로토 콜의 설계, 하드웨어 기반의 보안 환경의 구현 및 데이터의 안전 활용을 위한 메커니즘 개발 및 프라이버시 유 지 방법에 관한 기술 개발을 통해 디바이스 간의 연결성을 더 강화하고, 네트워크를 더 최적화하고, 네트워크 엔티티의 소프트웨어화를 촉진하며, 무선 통신의 개방성을 높이려는 시도가 계속되고 있다. 6G 통신 시스템의 연구 및 개발로 인해, 사물 간의 연결(M2M)뿐만 아니라 사람과 사물 간의 연결(P2M)까지 포 함하는 6G 통신 시스템의 초연결성(hyper-connectivity)을 통해 새로운 차원의 초연결 경험(the next hyper- connected experience)이 가능해질 것으로 기대된다. 구체적으로 6G 통신 시스템을 통해 초실감 확장 현실 (truly immersive extended reality (XR)), 고정밀 모바일 홀로그램(high-fidelity mobile hologram), 디 지털 복제(digital replica) 등의 서비스 제공이 가능할 것으로 전망된다. 또한 보안 및 신뢰도 증진을 통한 원 격 수술(remote surgery), 산업 자동화(industrial automation) 및 비상 응답(emergency response)과 같은 서 비스가 6G 통신 시스템을 통해 제공됨으로써 이러한 기술들은 산업, 의료, 자동차, 가전 등 다양한 분야에서 응용될 것이다. 기계 학습 기술은 유비쿼터스 하며 다양한 데이터 유형을 사용하여 다양한 분야에서 분석하고 예측하는 데 매우 성공적인 것으로 나타났다. 성공적인 기계 학습/인공 지능 모델의 핵심은 대량의 훈련 데이터를 사용할 수 있다 는 것이다. 매일 수십억 대의 커넥티드 기기가 다양한 설정으로 데이터를 기록한다. 따라서 다수의 귀중한 데이 터 세트가 이미 존재하며 여러 사용자 장치에 걸쳐서 분산되어 있다. 하지만 이러한 분산된 데이터 세트를 중앙위치에서 수집하고 통합하는 것은 불가능한 경우가 종종 있다. 이는 통신 링크 버짓이 매우 제한된 기기와 같은 통신 관련 문제로 인해 발생할 수 있다. 또한 분산 데이터 세트에는 최종 사용자가 인터넷을 통해 공유할 의향 이 없거나 공유가 허용되지 않는 개인 정보(예: 건강 관련 데이터)가 포함될 수 있다. 이 문제는 최종 사용자가 자신의 훈련 데이터에 대해 기계 학습 모델을 로컬로 훈련하여 로컬 데이터 세트의 개인 정보를 보호함으로써, 즉 연합 학습 알고리즘을 사용함으로써 해결될 수 있다. 로컬로 훈련되고 개선된 모델 매개변수는 로컬로 얻은 지식을 글로벌 모델에 통합하는 중앙 서버로 전송될 수 있다. 그러나, 연합 학습 프로세스에 참여하는 사용자 기기 중 어느 하나라도 자신의 훈련 결과를 중앙 집중식 서버로 전송할 수 없는 경우 전체 FL 프로세스가 중단될 수 있다. 이는 제한된 통신 버짓 또는 예를 들어 5G 네트워크 의 불량한 무선 연결로 인해 모든 사용자 기기가 더 이상 훈련 결과를 중앙 서버에 전달할 수 없는 경우일 수 있다. 따라서, 연합 학습 프로세스 동안 향상된 데이터 전송을 위한 방법이 필요하다."}
{"patent_id": "10-2023-0158972", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 개시는 기계 학습/연합 학습 프로세스 동안 향상된 데이터 전송을 위한 방법을 제공한다."}
{"patent_id": "10-2023-0158972", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 개시의 일 측면에 따르면, 셀룰러 네트워크에서 기계 학습(ML) 모델을 훈련하기 위한 매개변수 서버가 제공 된다. 상기 매개변수 서버는 훈련을 위한 적어도 하나의 ML 모델, 연합 학습(FL) 작업이 실행되는 것에 응답하 여 상기 적어도 하나의 ML 모델을 업데이트하기 위한 적어도 하나의 모듈; 및 상기 셀룰러 네트워크에서 연합 학습 작업의 실행을 관리하기 위한 스케줄러를 포함한다. 각 연합 학습 작업에 대해, 상기 스케줄러는, 복수의 가입 사용자 장치(UE) 중에서 상기 연합 학습 작업을 수행하는 데 적합한 UE 세트를 선택하고; 상기 선택된 UE 세트를 복수의 클러스터로 그룹화하는 방법을 지정하는 상기 연합 학습 작업에 대한 클러스터링 정책을 결정하 고; 그리고 상기 복수의 클러스터 중 각 클러스터에 상기 연합 학습 작업을 수행하도록 지시하도록 구성된다. 본 개시의 다른 측면에 따르면, 셀룰러 네트워크에서 기계 학습(ML) 모델을 훈련하기 위한 UE가 제공된다. 상기 UE는 복수의 훈련 데이터 항목을 저장하는 스토리지; 및 적어도 하나의 프로세서를 포함한다. 상기 UE의 상기 적어도 하나의 프로세서는 데이터 코딩 최적화 정책을 수신하고; 매개변수 서버로부터 ML 모델에 대한 연합 학 습 작업을 수행하라는 명령을 수신하고; 상기 수신된 클러스터별 데이터 코딩 최적화 정책에 기초하여, 상기 스 토리지 내에 적어도 하나의 훈련 데이터 항목에 대해 코딩된 훈련 데이터 항목을 생성하고; 그리고 상기 적어도 하나의 생성된 코딩된 훈련 데이터 항목을 UE의 클러스터 또는 상기 클러스터 내의 상기 UE에 연결된 노드로 전 송하도록 구성된다. 본 개시의 또 다른 측면에 따르면, 셀룰러 네트워크에서 연합 학습을 사용하여 ML 모델을 훈련하기 위한 매개변 수 서버에 의해 수행되는 방법이 제공된다. 상기 방법은 상기 셀룰러 네트워크에서 복수의 가입 사용자 장치 (UE)로부터 연합 학습 작업을 수행하기에 적합한 가입 UE 세트를 선택하는 단계 - 각 가입 UE는 적어도 하나의 연합 학습 작업을 수행하기 위해 가입함 -; 상기 선택된 가입 UE 세트를 복수의 클러스터로 그룹화하는 방법을 지정하는, 상기 연합 학습 작업에 대한 클러스터링 정책을 결정하는 단계; 및 상기 복수의 가입 UE의 클러스터 중 각 클러스터에게 상기 연합 학습 작업을 수행하도록 지시하는 단계를 포함한다. 본 개시의 또 다른 측면에 따르면, 셀룰러 네트워크에서 ML 모델을 훈련하기 위한 코디네이터(coordinator)에 의해 수행되는 방법이 제공된다. 상기 방법은 매개변수 서버로부터 연합 학습 작업을 위한 클러스터링 정책과 UE 세트에 대한 정보를 수신하는 단계; 및 상기 클러스터링 정책에 따라 상기 UE 세트를 복수의 클러스터로 그 룹화하는 단계를 포함하며, 상기 클러스터링 정책은 상기 UE 세트를 상기 복수의 클러스터로 그룹화하는 방법을 지정하며, 상기 UE 세트는 상기 셀룰러 네트워크의 복수의 UE 중에서 상기 연합 학습 작업을 수행하는 데 적합 한 것으로 선택되는 것이다."}
{"patent_id": "10-2023-0158972", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 개시의 일 실시 예에 따르면, 연합 학습 프로세스에 대한 셀룰러 네트워크의 열악한 채널 조건의 영향을 줄 일 수 있다. 또한, 본 개시의 일 실시 예에 따르면 기계 학습/연합 학습 프로세스 동안 데이터 전송 효율이 향상될 수 있다."}
{"patent_id": "10-2023-0158972", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하에서 설명된 도 1 내지 도 5 및 본 개시의 원리를 설명하기 위해 사용된 다양한 실시예는 단지 예시일 뿐이 며 어떤 방식으로도 본 개시의 범위를 제한하는 것으로 해석되어서는 안 된다. 당업자는 본 개시의 원리가 임의 의 적절하게 배열된 시스템 또는 기기에서 구현될 수 있다는 것을 이해할 것이다. 넓은 의미에서, 본 개시의 실시예는 셀룰러 네트워크에서 사용자 장치인 UE를 사용하는 기계 학습(ML) 모델의 보다 효율적인 연합 학습(FL)을 위한 방법 및 시스템을 제공한다. 특히, 본 개시는 연합 학습 프로세스에 대한 셀룰러 네트워크의 열악한 채널 조건의 영향을 줄이기 위한 시스템을 제공한다. 셀룰러 네트워크는 5G, 6G 또는 차세대 셀룰러 네트워크일 수 있다. 유리하게도, 본 개시의 실시예는 UE로부터 수신된 데이터를 사용하여 ML 모 델을 업데이트하는 중앙 매개변수 서버와 UE 사이의 데이터 전송 실패로 인해 FL 훈련 프로세스가 중단될 가능 성을 줄이기 위해 FL 훈련된 모델 매개변수의 전송에 중복성을 생성한다. 연합 학습(FL)은 데이터가 UE를 떠나지 않고, 본 명세서에서 사용자 기기로도 지칭되는 다수의 UE로부터의 데이 터로 ML 모델이 훈련되게 할 수 있다. 특히 중앙 집중식 매개변수 서버는 분산 모델 훈련(즉, FL 워크로드)에 참여하기를 원하는 다수의 UE에 접근할 수 있도록 설정된다. 원래의 FL 원리에 따르면 매개변수 서버는 (i) UE 에 대한 모델 분산, (ii) 모델 매개변수 업데이트, (iii) 분산 훈련 조정을 담당한다. 각 학습 단계가 끝나면: (i) FL 워크로드에 참여하는 모든 UE는 로컬에서 계산된 부분 그래디언트(gradient)를 매개변수 서버에 보고해 야 하며; (ii) 그러면, 매개변수 서버는 부분 그래디언트를 결합하여 전역 그래디언트를 얻고 학습된 매개변수 를 업데이트하며; 및 (iii) 학습된 매개변수는 FL 워크로드에 참여하는 모든 UE에 브로드캐스팅된다. 도 1은 연합 학습 프로세스 내의 스트래글러 문제를 예시하는 개략도이다. 도 1을 참조하면, 특정 연합 학습 워크로드 또는 작업에 참여하는 각 UE는 자신의 모델 매개변수(부분 그래디언 트, 가중치, 편향(bias) 또는 ML 모델의 다른 매개변수일 수 있음)를 집계를 위해 서버에 전달한다. 이 특정 예 에서, 각각의 UE는 E2 노드 또는 기지국과 같은 셀룰러 네트워크의 다른 구성요소를 통해 서버와 통신할 수 있 다. 그러나 UE5와 UE6는 E2 노드와의 통신 링크가 좋지 않아 필요한 시간 내에 모델 매개변수를 전송할 수 없다. 따라서 UE5와 UE6는 차단으로 인해 감소된 통신 링크 버짓으로 인해 \"스트래글러(straggler)\"로 간주된다. UE 중 어느 하나가 로컬로 계산된 매개변수를 매개변수 서버에 성공적으로 전달할 수 없는 경우, 기존 FL 프레 임워크는 정지된다. \"스트래글러 UE\" 또는 \"스트래글러\"는 UE 관련 제한(예: CPU(central processing unit) 용 량 부족, 메모리 자원 부족 등) 또는 UE와 서빙 E2 노드/기지국 사이의 열악한 채널 조건과 관련된 제한으로 인 해 하나 이상의 매개변수를 통신할 수 없는 UE이다. 본 개시는 포인트-투-멀티포인트(point-to-multipoint) 통신을 위한 랜덤 코딩 원리를 FL 워크로드의 분산 훈련 단계와 결합하는 기술을 제공한다. 그렇게 하면 훈련 프로세스를 방해할 수 있는 스트래글러가 많을 확률이 대 폭 줄어든다. 따라서, 본 개시에 의해 제공되는 기술은 FL 워크로드에 참여하는 UE가 단지 열악한 채널 조건으로 인해 스트래글러가 되는 시나리오에 유리하게 영향을 미친다. 6G(이에 국한되지 않음)의 맥락에서, 분산 AI/ML은 고속 데이터 서비스를 요구하는 수많은 사용자가 있는 네트 워크에서의 엄격한 서비스 품질(QoS) 제약을 충족할 수 있는 핵심 지원 기술 중 하나가 될 것으로 기대되는 것 이 널리 받아들여지고 있다. 따라서 5G 시스템이 FL 운영에 지원을 제공하는 것이 점점 더 중요해지고 있다. 부 분적으로, 대역폭 제한 및/또는 개인 정보 보호 문제로 인해 사용자는 사용자 데이터에 대한 AI 모델을 훈련하 려는 중앙 집중식 서버와 로컬에 저장된 데이터를 공유할 수 없거나 공유하기를 꺼릴 것으로 예상된다. 결과적 으로 FL은 사용자 데이터를 중앙 위치에 수집하지 않고 분산 학습을 수행할 수 있는 유망한 프레임워크 중 하나 이다. 위에서 이미 언급한 바와 같이, FL의 주요 단점은 분산 학습(이 경우 FL) 워크로드에 참여하는 사용자 기기가 열악한 채널 조건으로 인해 로컬로 계산된 모델 매개변수를 중앙 서버와 공유할 수 없을 때 발생한다. 이러한 다소 그럴듯한 상황은 6G 네트워크에서 분산 학습 워크로드를 실행하는 실용성에 챌린지 하기에 충분할 것이다. 본 개시는 이러한 제한을 해결하여 모바일 환경에서 FL 워크로드를 완료할 때까지 실행의 신뢰도를 높인다. FL 워크로드를 자신 있게 실행할 수 있다는 것은 5G 및 6G 네트워크에서 다음과 같은(그러나 이에 국한되지는 않음) 실질적인 이점을 갖는다: 밀집된 다중 셀 네트워크의 연결 최적화; 사용자 기기 행동 예측; 및 채널 추정 및 신호 검출. 기존 기술은 UE 중에서 최악의 전파 조건을 경험하는 UE와 관련하여 FL 워크로드에 사용되는 랜덤 코드를 최적 화한다. 이 접근 방식은 (i) 스트래글러의 수가 FL 워크로드에 참여하는 전체 UE 수보다 현저히 작거나, 또는 (ii) 스트래글러가 경험하는 채널 상태가 나머지 UE가 경험하는 채널 상태보다 실제보다 훨씬 더 나쁜 경우에 불필요한 통신 오버헤드를 초래할 수 있다. 이에 반해, 본 개시는 FL 워크로드에 참여하는 UE가 클러스터링 기 준 세트에 따라 클러스터링되게 한다. 이어서, 매개변수 서버는 클러스터별로 무작위 코드를 최적화한다. 특히, 각 클러스터 내에서 가장 나쁜 채널 상태를 경험하는 스트래글러에 대해 코드 최적화가 수행된다. 이로써 전체 적인 통신 오버헤드가 줄어들 것으로 예상된다. 기존 기술은 스트래글러로 간주되는 UE 세트가 FL 워크로드 실행 중에 변경되지 않는다고 가정한다. 이는 일부 UE의 모바일 특성과 통신 채널 및 물리적 환경의 동적 특성으로 인해 다소 비현실적인 가정이다. 이에 반해, 본 개시는 FL 워크로드 실행 중에 하나 이상의 클러스터에 걸쳐 무작위 코드가 다시 최적화되도록 규정한다. 본 개 시는 또한 FL 워크로드 실행 중에 FL 워크로드에 참여하는 UE가 재클러스터링되도록 (그리고 이후에 클러스터 전체에 걸쳐 코드가 다시 최적화되도록) 규정을 만든다. 기존 기술은 FL 워크로드에 참여하는 UE가 부분 그래디언트(로컬적으로 사용 가능한 데이터 세트에 대해 계산됨)와 코딩된 예제 (즉, 로컬로 사용 가능한 훈련 예제를 비율 없는 방식으로 선형 결합하여 얻은 레이블이 지정된 훈련 예제) 모두를 매개변수 서버로 다시 전송한다고 가정한다. 다음으로, 매개변수 서버는 성공적으로 수신된 코딩된 예제에 대한 부분 그래디언트를 계산한다. 이에 반해, 본 개시에서는 각 UE가 매개변수 서버로 전송할 것으로 예상되는 전술한 복수의 데이터 유형을 제거한다. 대신, 각 UE는 자신이 속한 클러스터 내에서 코딩된 예제를 생성하고 멀티캐스트한다. 또한, 본 개시는 FL 워크로드에 참여하는 각 UE가 로컬에서 사용 가능 한 훈련 예제 또는 로컬에서 생성된 코딩된 예제(이것은 또한 동일한 클러스터에 속한 다른 UE로부터 수신되었 을 수 있는 코딩된 예제도 포함함)에 대해 계산된 그래디언트만을 매개변수 서버에 전송하도록 규정한다. 본 개시의 제1의 접근법에서는, 셀룰러 네트워크에서 연합 학습을 사용하여 ML 모델을 훈련하기 위한 시스템이 제공된다. 상기 시스템은 복수의 가입 UE - 각각의 가입 UE는 적어도 하나의 연합 학습을 수행하기 위해 가입된 것임- 와 복수의 비가입 UE - 각각의 비가입 UE는 적어도 하나의 연합 학습 작업을 수행하기 위해 가입하지 않 은 것임; 및 상기 셀룰러 네트워크에 의한 ML 모델의 훈련을 제어하기 위한 매개변수 서버를 포함하며, 상기 매 개변수 서버는 훈련을 위한 적어도 하나의 ML 모델; 연합 학습 작업이 실행되는 것에 응답하여 상기 적어도 하 나의 ML 모델을 업데이트하기 위한 적어도 하나의 모듈; 및 상기 셀룰러 네트워크에서 연합 학습 작업의 실행을 관리하기 위한 스케줄러를 포함하며, 각 연합 학습 작업에 대해 상기 스케줄러는 상기 복수의 가입 UE 중에서 상기 연합 학습 작업을 수행하는 데 적합한 UE 세트를 선택하고; 상기 선택된 UE 세트를 복수의 클러스터로 함 께 그룹화하는 방법을 지정하는 상기 연합 학습 작업에 대한 클러스터링 정책을 정의하고; 그리고 상기 복수의 클러스터 중 각 클러스터에 상기 연합 학습 작업을 수행하도록 지시하기 위한 것이다. 본 개시의 실시예에 따르면 UE 클러스터에 의한 연합 학습 작업의 실행을 완성까지 감독하는 스케줄러가 제공되 며, 스트래글러/UE를 낙오시키는 것의 영향이 감소되거나 완전히 제거되도록 한다. 이는 여러 가지 이유로 유리하다. 첫째, 스케줄러는 단순히 셀룰러 네트워크의 모든 UE가 연합 학습 프로세스에 참여할 것이라고 기대하는 대신, 네트워크의 어느 UE가 하나 이상의 연합 학습 작업을 수행할 수 있고 명시적으로 가입했는지를 결정한다. 이는 참여할 수 없는 UE가 연합 학습 프로세스를 늦추거나 중단하지 않게 함을 의미하며, 이는 참여할 수 없는 UE가 이제 단순히 관여되지 않았기 때문이며, 매개변수 서버는 이러한 UE로부터 데이터가 도착할 때까지 기다릴 필요가 없기 때문이다. 또한, 연합 학습을 수행할 수 있고 특정 연합 학습 작업을 수행하도록 선택된 UE는 클러스터로 그룹화되어 개별 UE가 스트래글러가 될 수 있는 열악한 통신 채널 조건의 영향을 감소시킨다. 이는 각 클러스터에 리던던시 (redundancy)가 있기 때문이며, 이는, 클러스터 내의 어느 UE가 매개변수 서버로 데이터를 전송할 수 없는 경우, 클러스터 내 다른 UE로부터 수신한 정보로 누락된 정보를 보완한다는 뜻이다. 아래에서 좀 더 자세히 설 명하겠지만, 클러스터 내의 UE는 서로 정보를 공유하며, UE는 자신의 정보와 다른 UE로부터 수신한 정보를 이용 하여 연합 학습 작업을 수행한다. 결과적으로, 주어진 UE가 매개변수 서버에 데이터를 전송할 수 없는 경우, 매 개변수 서버는 스트래글러를 포함하여 가능한 한 많은 UE로부터 ML 모델을 업데이트하는 데 필요한 정보를 여전 히 얻을 수 있다는 이점이 있다. 스케줄러는 적어도 하나의 연합 학습 작업을 수행하기 위해 각각 가입한 복수의 가입 UE에 관한 정보를 저장하 도록 구성될 수 있다. 각 UE에 대한 정보에는 UE의 하드웨어 사양, 연합 학습 작업을 수행하기 위해 할당될 수 있는 컴퓨팅 자원에 대한 정보가 포함될 수 있다. 이는 위에서 언급한 바와 같이 스케줄러가 하나 이상의 연합 학습 프로세스에 참여할 수 있다고 명시적으로 언급한 UE에 특정 연합 학습 작업을 할당할 수 있기 때문에 유리 하다. 이는 또한 스케줄러가 실시간 연합 학습 작업을 수행하는 데 사용되는 UE를 추적하기 때문에 스케줄러가 다수의 연합 학습 작업에 참여할 수 있음을 나타내는 UE의 오버로드를 방지할 수 있음을 의미한다. 마찬가지로, 특정 연합 학습 작업을 수행하는 데 특정 양의 RAM(Random Access Memory), 컴퓨팅 자원 또는 UE의 스토리지가 필요한 경우에, 스케줄러는 연합 학습 작업에 이용가능한 RAM, 컴퓨팅 자원 또는 스토리지가 있는 UE만 특정 작 업에 할당되는 것을 보장할 수 있다. 스케줄러는 특정 ML 모델에 대해 연합 학습 작업을 실행하거나 재실행하라는 요청을 적어도 하나의 모듈로부터 수신하고 - 상기 요청은 요청된 연합 학습 작업을 수행하는 UE가 충족해야 할 적어도 하나의 조건을 지정함 -; 상기 복수의 가입 UE에 대한 저장된 정보를 이용하여, 복수의 가입 UE가 상기 적어도 하나의 조건을 만족하는지 여부를 결정하며; 그리고 결정에 기초하여 요청이 승인되는지 여부를 지시하는 응답을 상기 모듈로 전송하도록 구성된다. 따라서, 모듈 중 하나가 특정 ML 모델과 관련하여 연합 학습 프로세스를 실행하거나 다시 실행하려고 할 때마다 모듈은 스케줄러에 요청을 보낸다. 요청에는 ML 모델과 관련하여 수행되는 연합 학습 프로세스에 대 한 정보가 포함된다. 이 정보는 연합 학습 과정에 참여할 UE가 충족해야 할 적어도 하나의 조건을 지정한다. 조 건(들)은 훈련 라운드 및/또는 ML 모델마다 다를 수 있다. 상기 적어도 하나의 조건은 서비스 품질(QoS) 프로파일; 연합 학습 작업을 수행하는 데 필요한 최소 UE 수; 연 합 학습 작업을 수행하기 위한 UE 하드웨어 용량 요구 사항 중 하나 이상을 지정할 수 있다. 상기 시스템은 각 클러스터의 UE에 의한 연합 학습 작업의 실행을 조정하기 위한 코디네이터를 더 포함할 수 있 다. 코디네이터는 스케줄러로부터 클러스터링 정책 및 선택된 UE 세트를 수신하고; 클러스터링 정책에 따라 선 택된 UE 세트를 복수의 클러스터로 그룹화하고; 그리고 상기 연합 학습 작업을 수행할 때 상기 복수의 클러스터 내의 각 UE가 사용할 클러스터별 데이터 코딩 최적화 정책을 결정하도록 구성될 수 있으며, 상기 클러스터별 데 이터 코딩 최적화 정책은 각 클러스터 내의 UE가 데이터를 전송하는 방법을 정의하는 것이다. 코디네이터는 셀 룰러 네트워크에서 UE와 더 가까운 위치에 위치하여서, UE와 직접 또는 간접적으로 통신할 수 있다. 이는 UE가 통신 채널 상태가 좋지 않아 스케줄러와 직접 또는 자주 통신하는 것이 어려울 수 있다는 점을 고려하면 특히 중요하다. 유리하게, 코디네이터는 UE에 대해 더 많은 것을 알고 있기 때문에 스케줄러가 설정한 클러스터링 정 책을 구현한다. 예를 들어, 이하에서 자세히 설명되는 것처럼 클러스터링 정책은 UE의 각 클러스터가 셀룰러 네 트워크 내의 동일한 노드/기지국에 연결된 UE만 포함해야 한다고 지정할 수 있으며, 이 정보는 코디네이터에게 알려질 수 있다. UE가 클러스터로 그룹화되면, 코디네이터는 각 클러스터의 특성을 기반으로 클러스터 별 코딩 최적화 정책을 결정한다. 이는 코딩 최적화가 모든 UE에 대해 수행되는 것이 아니라 클러스터별로 수행되기 때 문에 유리하며, 이는 아래에서 자세히 설명되는 것처럼 스트래글러의 수를 줄이는 데 도움이 될 수 있다. 코디네이터는 연합 학습 작업이 실행되는 동안 미리 정의된 기간 후에 상기 선택된 UE 세트를 클러스터링 정책 에 따라 복수의 클러스터로 주기적으로 재그룹화하고; 재그룹화 후에 연합 학습 작업을 수행할 때 복수의 클러 스터내의 각 UE가 사용할 클러스터별 데이터 코딩 최적화 정책을 다시 결정하도록 더 구성될 수 있다. 이는 UE가 특정 연합 학습 작업을 위해 클러스터로 처음 그룹화되었을 때와 동일한 노드에 더 이상 연결되지 않도록 셀 룰러 네트워크 내에서 이동할 수 있기 때문에 유리하다. 따라서 연합 학습 작업 실행 전반에 걸쳐 클러스터링 정책이 만족되도록 UE를 재그룹화하는 것이 유용하다. 일단 재그룹화가 수행되면(어떤 경우에는 클러스터가 변 경되지 않을 수 있음), 클러스터별 데이터 코딩 최적화 정책이 각 클러스터에 대해 다시 결정된다. 재그룹화는 미리 정의된 각 기간이 끝나면 즉시 발생할 수 있다. 바람직하게는, 재그룹화는 연합 학습 작업의 훈련 반복/라 운드 중 보다는 연합 학습 작업의 훈련 반복/라운드가 완료되었을 때 일어날 수 있다. 클러스터링 정책은 클러스터 내의 UE가 단일 노드에 의해 서비스를 받아야 함을 지정할 수 있다. 이 경우, 코디 네이터는 선택된 UE 세트를 각 UE가 현재 어느 노드에 의해 서비스되고 있는지에 따라 복수의 클러스터로 그룹 화하도록 구성될 수 있다. 코디네이터는 연합 학습 작업을 위해 각 클러스터에 어떤 UE가 있는지에 대한 정보를 스케줄러에 전송하여, 스 케줄러가 각 클러스터의 UE에게 연합 학습 작업을 수행하도록 지시할 수 있도록 구성될 수 있다. 이는 코디네이 터가 클러스터링/재클러스터링 작업을 수행할 때마다 발생할 수 있다. 상기 연합 학습 작업은 복수의 훈련 반복/라운드를 수행하는 것을 포함할 수 있다. 연합 학습 작업에 대한 훈련 반복이 시작되기 전에, 스케줄러는 복수의 클러스터의 UE로부터 수신된 메시지를 확인하여, UE가 여전히 연합 학습 작업의 훈련 반복을 수행할 수 있는지 여부를 결정하고; 적어도 하나의 UE가 연합 학습 작업의 훈련 반복 을 수행할 수 없다고 결정한 경우에 응답하여, 코디네이터로 하여금 클러스터링 정책 및 UE 상태 메시지에 따라 UE를 복수의 클러스터로 재그룹화하도록 지시하도록 구성될 수 있다. 따라서, 스케줄러는 연합 학습 작업을 수 행하도록 원래 선택된 UE가 여전히 그렇게 할 수 있는지 여부를 결정할 수 있으며, 이는 잠재적인 스트래글러의 수를 유리하게 감소시킨다. 스케줄러는 두 가지 방식으로 상태 메시지로부터 UE가 훈련 반복을 수행할 수 있는 지 여부를 결정할 수 있다: 상태 메시지는 UE가 훈련을 수행할 수 있는지 여부를 나타낼 수 있고/있거나 상태 메시지의 부재는 UE가 훈련을 수행할 수 없음을 나타낼 수 있다. 후자의 경우, 일정 시간 내에 UE로부터 상태 메시지가 수신되지 않으면 스케줄러는 UE의 통신 채널 상태가 좋지 않거나 UE가 연합 학습 작업을 수행하는 데 필요한 자원을 더 이상 지니고 있지 않다고 가정한다. 스케줄러가 적어도 하나의 UE가 이제 연합 학습 작업을 수행할 수 없다고 판단하면, 코디네이터는 스케줄러로부 터의 명령에 응답하여 선택된 UE 세트 중 일부 또는 전부를 연합 학습 작업이 실행되는 동안 클러스터링 정책에 따라 복수의 클러스터로 재그룹화하고; 재그룹화 후에 연합 학습 작업을 수행할 때 복수의 클러스터 중 각 UE가 사용할 클러스터별 데이터 코딩 최적화 정책을 다시 결정하도록 더 구성될 수 있다. 따라서 코디네이터는 연합 학습 작업을 실행하는 동안 및/또는 스케줄러의 명령에 응답하여 주기적으로 재그룹화를 수행한다. 이는 예를 들어 클러스터가 항상 연합 학습 작업을 수행할 수 있는 적어도 하나의 UE를 포함하고, 클러스터가 여전히 연합 학습 작업을 수행할 수 있는 UE만 포함하는 것을 보장한다. 코디네이터는 클러스터 내 모든 UE 중 가장 열악한 통신 채널 상황을 겪고 있는 UE의 통신 능력을 기반으로 클 러스터별 데이터 코딩 최적화 정책을 결정할 수 있다. 이는 최악의 채널 상황을 겪고 있는 UE가 연합 학습 작업 을 수행할 수 있는 가능성을 향상시킨다는 이점이 있다. 코디네이터는 연합 학습 작업을 수행할 때 각 클러스터의 각 UE에게 클러스터별 데이터 코딩 최적화 정책을 사 용하도록 지시할 수 있다. 일부 경우에, UE가 연합 학습 작업을 수행하도록 지시받은 경우, 클러스터 내의 각 UE는 UE에 저장된 적어도 하 나의 훈련 데이터 항목에 대해 클러스터별 데이터 코딩 최적화 정책을 기반으로 코딩된 훈련 데이터 항목을 생 성하고; 적어도 하나의 생성된 코딩된 훈련 데이터 항목을 클러스터 내의 UE들에 멀티캐스트하도록 구성될 수 있다. 즉, 각 UE는 자신의 코딩된 훈련 데이터 항목(들)을 클러스터 내의 다른 UE에 직접 제공할 수 있다. 대안적으로, UE가 연합 학습 작업을 수행하도록 지시받은 경우, 클러스터 내의 각 UE는 UE에 저장된 적어도 하 나의 훈련 데이터 항목에 대해, 클러스터별 데이터 코딩 최적화 정책에 기반하여 코딩된 훈련 데이터 항목을 생 성하고; 클러스터 내 UE에 대한 배포를 위해 클러스터 내의 UE에 연결된 노드/기지국에 적어도 하나의 생성된 코딩된 훈련 데이터 항목을 전송하도록 구성될 수 있다. 즉, 각 UE는 자신의 코딩된 훈련 데이터 항목(들)을 클 러스터 내의 다른 UE에 간접적으로 제공할 수 있다. 연합 학습 작업은 각 UE에서 글로벌 ML 모델의 로컬 버전을 훈련하는 것을 포함한다. 어떤 경우에도, 각 UE는 UE에 저장된 적어도 하나의 훈련 데이터 항목을 사용하여 연합 학습 작업에 대응하는 ML 모델의 로컬 버전을 훈 련함으로써 제1의 모델 매개변수 세트를 생성하며; UE에 의해 생성된 적어도 하나의 생성된 코딩된 훈련 데이터항목 및 클러스터 내의 다른 UE로부터 수신된 적어도 하나의 생성된 코딩된 훈련 데이터 항목을 사용하여 연합 학습 작업에 대응하는 ML 모델의 로컬 버전을 훈련함으로써 제2의 모델 매개변수 세트를 생성하며; 그리고 스케 줄러를 통해 제1 및 제2의 모델 매개변수 세트를 적어도 하나의 모듈에 전송하도록 더 구성될 수 있다. 즉, 각 UE는 기기 내에서 연합 학습 과정을 수행하여 두 세트의 매개변수를 생성한다. 제1의 매개변수 세트는 UE 자신 의 훈련 데이터를 사용하여 생성되는 반면, 제2의 매개변수 세트는 클러스터로부터 수신된 모든 코딩된 훈련 데 이터 항목(UE 자신의 코딩된 훈련 데이터 항목(들) 포함)을 사용하여 생성된다. 유리하게도 이는 스트래글러 문 제를 완화하는 연합 학습 프로세스에 일부 리던던시를 도입한다. 이는 제2의 매개변수 세트가 전체 클러스터와 관련되어 있기 때문에, 클러스터에 있는 하나 이상의 UE가 매개변수 서버에 데이터/매개변수를 전송할 수 없더 라도, 매개변수 서버는 클러스터 내의 다른 UE로부터 수신된 제2의 매개변수를 통해 전체 클러스터로부터 정보 를 수신하기 때문이다. 이러한 방식으로 매개변수 서버는 개별 UE가 채널 상태가 좋지 않은 경우에도 클러스터 전체(또는 대부분)의 데이터를 사용하여 ML 모델을 업데이트할 수 있다. 연합 학습 프로세스의 실행/재실행을 요청한 매개변수 서버의 적어도 하나의 모듈은 각 UE로부터 수신된 제1 및 제2의 매개변수 세트를 사용하여 UE에 의해 수행된 연합 학습 작업에 대응하는 ML 모델을 업데이트하도록 구성 될 수 있다. 미리 정의된 기간 내에 복수의 클러스터로부터 미리 정의된 최소 개수의 UE로부터 제1의 매개변수 세트가 수신 되면, 적어도 하나의 모듈은 복수의 클러스터의 UE로부터 수신된 제1의 매개변수 세트를 집계하고; 집계된 제1 의 매개변수 세트를 사용하여 글로벌 ML 모델을 업데이트해서 ML 모델을 업데이트하도록 구성될 수 있다. 즉, 제1의 매개변수 세트는 자체 원시 훈련 데이터를 사용하여 각 UE에서 직접 생성되었기 때문에 우선되거나 선호 된다. 제1의 매개변수 세트는 복수의 클러스터에 걸쳐 미리 정의된 최소 개수의 UE로부터 나올 수 있다. 즉, 최 소 개수의 UE로부터 제1의 매개변수 세트가 수신되는 한, 어느 클러스터 또는 클러스터들에서 수신되는지는 중 요하지 않다. 제1 세트의 매개변수 세트가 미리 정의된 기간 내에 복수의 클러스터로부터 미리 정의된 최소 수보다 적은 수의 UE로부터 수신된 경우, 적어도 하나의 모듈은 복수의 클러스터의 UE로부터 수신된 제1의 매개변수 세트를 집계 하고; UE로부터 수신된 제2의 매개변수 세트의 무작위 선택을 집계하고; 그리고 집계된 제1의 매개변수 세트와 집계된 제2의 매개변수 세트의 무작위 선택을 사용하여 글로벌 ML 모델을 업데이트하는 것에 의해 ML 모델을 업 데이트 하도록 구성될 수 있다. 이러한 방식으로, 클러스터의 UE로부터 누락된 제1의 매개변수 세트(들)는 제2 의 매개변수 세트를 사용하여 보상된다. 제2의 매개변수 세트가 사전 정의된 시간 기간 내에 클러스터 내 사전 정의된 최소 수 미만의 UE로부터 수신된 경우, 적어도 하나의 모듈은 ML모델의 업데이트를 종료하도록 구성된다. 즉, 클러스터에서 수신된 데이터가 충 분하지 않은 경우, ML 모델에 부정적인 영향을 미치지 않도록 연합 학습 작업이 종료될 수 있다. 셀룰러 네트워크는 임의의 셀룰러 통신 네트워크일 수 있다. 예를 들어, 셀룰러 네트워크는 5G, 6G 또는 차세대 셀룰러 네트워크일 수 있다. 일례에서, 셀룰러 네트워크는 개방형 무선 액세스 네트워크(open radio-access network: ORAN)일 수 있다. 이 경우, 매개변수 서버는 비 실시간 무선 지능형 컨트롤러 (non-real time radio intelligent controller: non- RT-RIC)를 포함하는 서비스 관리 및 오케스트레이션(service management and orchestration: SMO) 플랫폼일 수 있으며 ; 적어도 하나의 ML 모델을 업데이트하기 위한 적어도 하나의 모듈은 non-RT-RIC에서 실행되도록 구성된 소프트웨어 애플리케이션(rApp)일 수 있으며; 스케줄러는 non-RT-RIC에서 실행되도록 구성된 소프트웨어 애플리 케이션일 수 있으며; 코디네이터는 셀룰러 네트워크의 노드를 제어하는 근 실시간 무선 지능형 컨트롤러(near- real time radio intelligent controller: near-RT-RIC)에서 실행되도록 구성된 소프트웨어 애플리케이션일 수 있다. 본 개시의 제2의 접근법에서는, 셀룰러 네트워크에서 연합 학습을 사용하여 기계 학습(ML) 모델을 훈련하기 위 한 사용자 장치(UE)가 제공된다. 상기 UE는 복수의 훈련 데이터 항목을 저장하는 스토리지; 및 메모리에 연결되 고, 데이터 코딩 최적화 정책을 수신하고; 매개변수 서버로부터 ML 모델에 대한 연합 학습 작업을 수행하라는 명령을 수신하고; 상기 수신된 데이터 코딩 최적화 정책에 기초하여, 스토리지 내에 적어도 하나의 훈련 데이터 항목에 대해 코딩된 훈련 데이터 항목을 생성하고; 그리고 상기 적어도 하나의 생성된 코딩된 훈련 데이터 항목 을 UE의 정의된 클러스터에 전송하도록 구성되는 적어도 하나의 프로세서를 포함한다. 제1의 접근법에서의 UE에 관해 설명한 특징은 제2의 접근법에도 동일하게 적용되므로, 이에 대해서는 반복하지 않는다. 상기 UE의 적어도 하나의 프로세서는: UE에 저장된 적어도 하나의 훈련 데이터 항목을 사용하여 ML 모델의 로컬 버전을 훈련함으로써 제1의 모델 매개변수 세트를 생성하고; UE에 의해 생성된 적어도 하나의 생성된 코딩된 훈 련 데이터 항목 및 UE 클러스터 내의 다른 UE로부터 수신된 적어도 하나의 생성된 코딩된 훈련 데이터 항목을 사용하여 ML 모델의 로컬 버전을 훈련함으로써 제2의 모델 매개변수 세트를 생성하고; 제1 및 제2의 모델 매개 변수 세트를 매개변수 서버에 전송하도록 구성될 수 있다. 상기 UE의 적어도 하나의 프로세서는 UE가 적어도 하나의 연합 학습 작업을 수행할 수 있음을 지시하는 가입 요 청을 매개변수 서버에 전송하고; 그리고 상태 업데이트 메시지를 매개변수 서버로 주기적으로 전송하도록 구성 될 수 있다. 상기 UE는 자원이 제한된 기기일 수 있지만, ML 모델을 훈련하기 위한 최소한의 하드웨어 기능을 갖고 셀룰러 네트워크를 통해 통신한다. 상기 UE는 스마트폰, 태블릿, 랩톱, 컴퓨터 또는 컴퓨팅 장치, 가상 보조 장치, 차 량, 자율 주행 차량, 로봇 또는 로봇 기기, 로봇 보조 장치, 이미지 캡처 시스템 또는 기기, 증강 현실 시스템 또는 기기, 가상 현실 시스템 또는 기기, 게임 시스템, 사물 인터넷 기기 또는 스마트 소비자 기기(예: 스마트 냉장고 또는 가전) 중 어느 하나일 수 있다. 이는 예시적인 UE의 비완전하고 비제한적인 목록이라는 것이 이해 될 것이다. 본 개시의 제3의 접근법에서는, 셀룰러 네트워크에서 연합 학습을 사용하여 ML 모델을 훈련하기 위한 매개변수 서버가 제공된다. 상기 매개변수 서버는 훈련을 위한 적어도 하나의 ML 모델; 연합 학습 작업이 실행되는 것에 응답하여 상기 적어도 하나의 ML 모델을 업데이트하기 위한 적어도 하나의 모듈; 및 상기 셀룰러 네트워크에서 연합 학습 작업의 실행을 관리하기 위한 스케줄러를 포함하며, 각 연합 학습 작업에 대해 상기 스케줄러는 상기 셀룰러 네트워크의 복수의 UE로부터 상기 연합 학습을 수행하는 데 적합한 UE 세트를 선택하며; 상기 선택된 UE 세트를 복수의 클러스터로 함께 그룹화하는 방법을 지정하는 상기 연합 학습 작업에 대한 클러스터링 정책을 정 의하며; 그리고 상기 복수의 클러스터 중 각 클러스터에게 상기 연합 학습 작업을 수행하도록 지시하도록 구성 된다. 제1의 접근법에서의 매개변수 서버에 관해 설명한 특징은 제3의 접근법에도 동일하게 적용되므로, 간결한 설명 을 위해 이에 대해서는 반복하지 않는다. 본 개시의 제4의 접근법에서는, 셀룰러 네트워크에서 연합 학습을 사용하여 ML 모델을 훈련하는 방법이 제공된 다. 상기 방법은 특정 ML 모델에 대해 연합 학습 작업을 실행하거나 재실행하라는 요청을 수신하는 단계; 상기 셀룰러 네트워크에서 복수의 가입 사용자 장치(UE)로부터 상기 연합 학습 작업을 수행하기에 적합한 UE 세트를 선택하는 단계 - 각 가입 UE는 적어도 하나의 연합 학습 작업을 수행하기 위해 가입함 -; 상기 선택된 가입 UE 세트를 복수의 클러스터로 함께 그룹화하는 방법을 지정하는 상기 연합 학습 작업에 대한 클러스터링 정책을 정 의하는 단계; 및 상기 복수의 가입 UE의 클러스터 중 각 클러스터에게 상기 연합 학습 작업을 수행하도록 지시 하는 단계를 포함한다. 상기 방법은 상기 연합 학습 작업을 수행할 때, 각 클러스터의 상기 UE에 의한 연합 학습 작업의 상기 실행을 조정하기 위한 코디네이터에게 상기 복수의 클러스터의 각 UE에 의해 사용될 클러스터별 데이터 코딩 최적화 정 책을 결정하라는 요청을 전송하는 단계를 더 포함할 수 있으며, 상기 클러스터별 데이터 코딩 최적화 정책은 각 클러스터 내의 UE가 데이터를 전송하는 방법을 정의한다. 제1의 접근법에서의 매개변수 서버에 관해 설명한 특징은 제4의 접근법에도 동일하게 적용되므로, 간결한 설명 을 위해 이에 대해서는 반복하지 않는다. 도 2는 본 발명의 실시예에 따라 셀룰러 네트워크에서 연합 학습을 사용하여 ML 모델을 훈련하기 위한 시스템을 도시한다. 여기서 셀룰러 네트워크는 개방형 무선 액세스 네트워크인 ORAN으로 도시된다. 이는 본 개시의 실시 예가 구현될 수 있는 셀룰러 네트워크의 단지 하나의 비제한적이고 예시적인 유형의 예시라는 것이 이해될 것이다. 상기 시스템은 복수의 UE를 포함하며, 그 중 일부는 FL 워크로드에 참여하기 위해 명시적으로 가입했다. 즉, 시 스템의 모든 UE가 FL 작업을 수행하지는 않는다. 구체적으로, 상기 시스템은 각각의 가입 UE가 적어도 하나의 연합 학습 작업을 수행하기 위해 가입한 복수의 가입 UE와, 각각의 비가입 UE가 적어도 하나의 연합 학습 작업 을 수행하기 위해 가입하지 않은 복수의 비가입 UE를 포함한다. 도 2를 참조하면, 복수의 가입 UE(502a, 502b, 502c)가 있다. 시스템 내에 수십, 수백 또는 수천 개의 가입 및 비가입 UE가 있을 수 있으며, 단순화를 위해 본명세서에서는 3개의 가입 UE만 표시되어 있음이 이해될 것이다. 또한 여기에 표시된 UE는 연합 학습에 참여하고 있다. 시스템에는 연합 학습에 참여하지 않는 다른 UE가 있을 수 있다 (전혀 참여하지 않거나 특정 연합 학습 작업과 관련하여 참여하지 않음). \"연합 학습 작업(federal learning task)\"이라는 용어는 본 명세서에서 \"연합 학습 워크로드(federal learning workload)\"라는 용어와 상호교환적으로 사용된다. 상기 UE는 셀룰러 네트워크를 통해 통신하는 임의의 전자 기기일 수 있다. UE 중 일부 또는 전부는 제한된-자원 의 기기일 수 있지만, ML 모델을 훈련하기 위한 최소한의 하드웨어 기능을 갖고 셀룰러 네트워크를 통해 통신한 다. UE는 스마트폰, 태블릿, 랩톱, 컴퓨터 또는 컴퓨팅 기기, 가상 보조 기기, 차량, 자율 주행 차량, 로봇 또 는 로봇 기기, 로봇 보조 장치, 이미지 캡처 시스템 또는 기기, 증강 현실 시스템 또는 기기, 가상 현실 시스템 또는 기기, 게임 시스템, 사물 인터넷 장치 또는 스마트 소비자 기기(예: 스마트 냉장고 또는 가전) 중 하나 일 수 있다. 이는 예시적인 UE의 비완전하고 비제한적인 목록이라는 것이 이해될 것이다. UE(502a-502c) 각각은 적어도 하나의 연합 학습 작업을 수행하기 위해 가입했다. 가입 프로세스(subscription process)는 도 4와 관련하여 이하에서 더 자세히 설명된다. 상기 시스템은 셀룰러 네트워크에 의한 ML 모델의 훈련을 제어하기 위한 매개변수 서버를 포함한다. 이 예에서, 매개변수 서버는 비실시간 무선 지능형 컨트롤러(non-RT-RIC)를 포함하는 서비스 관리 및 오케스트레이션 (SMO) 플랫폼일 수 있다. 상기 매개변수 서버는 훈련을 위한 적어도 하나의 글로벌 ML 모델(미도시); 및 연합 학습 작업이 실행되는 것에 응답하여 적어도 하나의 글로벌 ML 모델을 업데이트하기 위한 적어도 하나의 모듈을 포함한다. 이 예에서, 적어도 하나의 모듈은 non-RT-RIC 에서 실행되도록 구성된 소프트웨어 애플리케이션인 \"FL 워크로드 rApp\"일 수 있다. 도 2에는 3개의 모듈이 도시되어 있지만, 0이 아닌 수의 모듈이 있을 수 있다는 것 을 이해해야 한다. 각 모듈은 특정 ML 모델과 관련하여 특정 연합 학습 작업을 구현한다. 예를 들어, 하나 의 모듈은 이미지 분류 ML 모델에 관한 FL 작업을 구현할 수 있는 반면, 다른 모듈은 음성 인식 ML 모델에 관한 FL 작업을 구현할 수 있다. 위에서 언급한 바와 같이, \"연합 학습 작업\"이라는 용어는 본 명세서에 서 \"연합 학습 워크로드\"라는 용어와 상호교환적으로 사용된다. 연합 학습 작업 또는 워크로드는 특정 ML 모델 을 훈련하는 것이다. 훈련 프로세스에는 참여하는 각 UE에서 글로벌 ML 모델의 로컬 버전을 훈련하는 것을 포함 한다. 상기 매개변수 서버는 셀룰러 네트워크에서 연합 학습 작업의 실행을 관리하기 위한 스케줄러를 포함한다. 이 예에서, 스케줄러는 non-RT-RIC에서 실행되도록 구성된 소프트웨어 애플리케이션인 \"FLLM(Federated Learning Lifecycle Manager) rApp\"이라고 불릴 수 있다. 이하에서 보다 자세히 설명되는 바 와 같이, 스케줄러는 FL 워크로드 생성/실행을 완료하고, FL 워크로드에 참여하려는 UE 풀의 가입 프로세 스를 감독하고, 시스템에서 채택될 클러스터링 정책을 시행한다. 각각의 연합 학습 작업에 대해, 스케줄러는 (모듈에 의해 요청된) 연합 학습 작업을 수행하는 데 적 합한 것으로 복수의 가입 UE(502a-502c)로부터 UE 세트를 선택하고; 선택된 UE 세트를 복수의 클러스터로 함께 그룹화하는 방법을 지정하는 연합 학습 작업에 대한 클러스터링 정책을 정의하며; 그리고 상기 복수의 클러스터 중 각 클러스터에 상기 연합 학습 작업을 수행하도록 지시하도록 구성될 수 있다. 도 2에 도시된 바와 같이, 본 개시는 하나 이상의 FL 워크로드를 지원하는 FLLM rApp을 추가함으로써 Non-RT RIC 기능을 확장한다. 각 FL 워크로드는 rApp에 의해 실행된다. 논리적 관점에서 보면, FL 워크로드를 실행하려 는 rApp과 FLLM rApp이 함께 매개변수 서버 역할을 한다. FL 워크로드에 참여하기를 원하는 UE(502a-502c)는 먼저 스케줄러에 가입해야 한다. UE는 셀룰러 네트워크 의 다른 구성요소를 통해, 특히 UE에 연결되어 있는 E2 노드/기지국을 통해 스케줄러와 통신한다. 여기서, UE(502a)는 E2 노드(402a)에 연결되고, UE(502b)는 E2 노드(402b)에 연결되고, UE(502c)는 E2 노드(402c)에 연 결된다. 그러나, 다수의 UE가 하나의 E2 노드에 연결될 수 있고, 일부 E2 노드가 어떤 UE에도 연결되지 않을 수 있다는 것이 이해될 것이다. UE는 이동성이 있어 서로 다른 지리적 위치로 이동할 수 있으므로 UE는 서로 다른 E2 노드에 연결할 수도 있다. 스케줄러는 적어도 하나의 연합 학습 작업을 수행하기 위해 각각 가입한 복수의 가입 UE(502a-502c)에 관 한 정보를 저장하도록 구성될 수 있다. 각 가입 UE에 대한 정보에는 UE의 하드웨어 사양, 연합 학습 작업을 수 행하기 위해 할당될 수 있는 컴퓨팅 자원에 대한 정보가 포함될 수 있다. 이는 위에서 언급한 바와 같이, 스케줄러가 하나 이상의 연합 학습 프로세스에 참여할 수 있다고 명시적으로 말한 가입 UE에게 특정 연합 학습 작업을 할당할 수 있기 때문에 유리하다. 이는 또한 스케줄러가 여러 연합 학습 작업에 참여할 수 있음을 지시 하는 모든 구독 UE의 오버로드를 방지할 수 있음을 의미한다. 왜냐하면 스케줄러가 실시간 연합 학습 작업을 수 행하는 데 사용되는 구독 UE를 추적하기 때문이다. 마찬가지로, 특정 연합 학습 작업을 수행하는 데 구독 UE의 특정 양의 RAM, 컴퓨팅 자원 또는 스토리지가 필요한 경우, 스케줄러는 연합 학습 작업에 이용 가능한 RAM, 컴 퓨팅 자원 또는 스토리지가 있는 구독 UE만이 특정 작업에 할당되는 것을 보장할 수 있다. 스케줄러는, 적어도 하나의 모듈로부터 특정 ML 모델과 관련하여 연합 학습 작업을 실행하거나 재실 행하라는 요청을 수신하고 - 상기 요청은 요청된 연합 학습 작업을 수행하는 UE에 의해 만족되는 적어도 하나의 조건을 지정함-; 상기 저장된 복수의 가입 UE들에 대한 정보를 이용하여, 복수의 가입 UE들이 적어도 하나의 조 건을 만족하는지 여부를 결정하며; 그리고 상기 결정에 기초하여 요청이 승인되는지 여부를 지시하는 응답을 모 듈로 전송하도록 구성될 수 있다. 따라서 모듈 중 하나가 특정 ML 모델과 관련하여 연합 학습 프로세스를 실행하거나 재실행하려고 할 때마다, 모듈은 스케줄러에 요청을 보낸다. 상기 요청에는 ML 모델과 관 련하여 수행될 연합 학습 프로세스에 대한 정보가 포함된다. 상기 정보는 연합 학습 프로세스에 참여할 가입 UE 가 충족해야 할 적어도 하나의 조건을 지정한다. 상기 조건(들)은 훈련 라운드 및/또는 ML 모델마다 다를 수 있 다. 상기 적어도 하나의 조건은 서비스 품질 프로파일; 연합 학습 작업을 수행하는 데 필요한 최소 UE 수; 연합 학 습 작업을 수행하기 위한 UE 하드웨어 용량 요구 사항 중 하나 이상을 지정할 수 있다. 상기 시스템은 각 클러스터의 UE에 의한 연합 학습 작업의 실행을 조정하기 위한 코디네이터를 더 포함할 수 있다. 이 예에서, 코디네이터는 셀룰러 네트워크의 노드(402a-402c)를 제어하는 근 실시간 무선 지능형 컨트롤러(near-RT-RIC)에서 실행되도록 구성된 소프트웨어 애플리케이션인 \"클러스터링 및 코드 최적화 (clustering and code optimisation: ClCoO) xApp\"일 수 있다. 코디네이터는 (스케줄러에 의해 시행 되는 클러스터링 정책에 기초하여) 특정 FL 워크로드에 참여하는 가입 UE 풀의 클러스터링과 선택된 무작위 코 드의 클러스터별 최적화를 담당한다. 코디네이터는 스케줄러로부터 클러스터링 정책 및 선택된 UE 세트를 수신하고; 클러스터링 정책에 따 라 선택된 UE 세트를 복수의 클러스터로 그룹화하고; 그리고 연합 학습 작업을 수행할 때 복수의 클러스터 내의 각 UE가 사용할 클러스터별 데이터 코딩 최적화 정책을 결정하도록 구성될 수 있으며, 상기 클러스터별 데이터 코딩 최적화 정책은 각 클러스터 내의 UE가 데이터를 전송하는 방법을 정의한다. 코디네이터는 셀룰러 네 트워크에서 UE와 더 가까이 위치하여, UE와 직접 또는 간접적으로 통신할 수 있다. 이는 UE가 통신 채널 상태가 좋지 않아 스케줄러와 직접 또는 자주 통신하는 것이 어려울 수 있다는 점을 고려하면 특히 중요하다. 코디네이 터는 UE에 대해 더 많은 것을 알고 있기 때문에 스케줄러가 설정한 클러스터링 정책을 구현하는 것이 유리하다. 예를 들어, 이하에서 보다 자세히 설명된 것처럼, 클러스터링 정책은 UE의 각 클러스터가 셀룰러 네트워크 내의 동일한 노드/기지국에 연결된 UE만 포함해야 한다고 지정할 수 있다. 이 정보는 코디네이터에게 알려질 수 있다. 일단 UE가 클러스터로 그룹화되면, 코디네이터는 각 클러스터의 특성을 기반으로 클러스터 별 코딩 최적 화 정책을 결정한다. 이는 코딩 최적화가 모든 UE에 대해 수행되는 것이 아니라 클러스터별로 수행되기 때문에 유리하며, 이는 아래에서 보다 자세히 설명되는 바와 같이 스트래글러의 수를 줄이는 데 도움이 될 수 있다."}
{"patent_id": "10-2023-0158972", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "연합 학습 프로세스를 상세히 설명하기 전에 도 2를 참조하여 전체 연합 학습 프로세스를 요약한다. 이 요약은 ORAN 시스템의 구성요소를 언급하지만 다른 유사한 네트워크 유형에도 동일하게 적용된다는 점을 이해해야 한다. FL 워크로드에 참여하기를 원하는 UE(502a-502c)는 그들이 연결된 노드(402a-402c)를 통해 스케줄러(20 2)에 가입한다. UE가 전송한 가입 메시지는 관련 근 실시간 RIC(near-RT RIC)의 E2 단말기 (terminator)를 거쳐 E2 인터페이스를 거쳐 다음으로, AI 인터페이스를 통해 SMO(Service Management and Orchestration)/Non-RT RIC으로 전달된다. 이어서, 스케줄러는 (A1 인터페이스를 통해) 코디네이터 에 의해 시행될 클러스터링 정책인 Near-RT RIC 세트(FL 워크로드에 참여하기를 원하는 각 UE에 서비 스를 제공하는 노드(402a-402c)를 제어함)와 통신한다. 코디네이터는 클러스터별로 무작위 코드를 최적화 한다(최적화된 코딩 매개변수는 E2 노드에 전달된 다음 E2 인터페이스를 통해 UE에 전달된다). 본 개시는 FL 워 크로드 실행 동안 스케줄러가 클러스터 및 코딩 매개변수 모두의 재최적화를 주기적으로 트리거하도록 규 정한다. 각 학습 단계에서 각 UE는 자신이 속한 클러스터 내에서 코딩된 예제를 생성하고 멀티캐스트한다. 또한, 각 UE 는 (스케줄러를 통해) FL 워크로드를 실행하는 모듈에 로컬로 사용 가능한 훈련 예제를 사용하여 계산된 매개변수와 로컬에서 생성된 코드 예제 (동일한 클러스터에 속한 다른 UE로부터 수신되었을 수 있는 코딩 된 예제를 포함함)를 사용하여 계산된 매개변수를 모두 전송한다. FL 워크로드를 실행하는 모듈은 매개변 수를 결합하고 ML 모델의 글로벌 매개변수를 업데이트한다. 업데이트된 ML 모델의 매개변수는 스케줄러 및 노드(402a-402c)를 통해 UE에 재분배된다(이 마지막 단계는 O1 인터페이스를 사용하여 가능해짐). FL 프로세스를 자세히 설명하기 전에 몇 가지 기본 가정을 설명할 필요가 있다. FL 프로세스는 W > 0 UE 세트,"}
{"patent_id": "10-2023-0158972", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": ", 로 구성된 시스템 모델을 기반으로 한다. UE가 반드시 동일한 E2 노드에 연결될 필요는 없다. i번째 FL 워크로드에 참여하는 복수의 UE의 부분 세트는 에 이다. 도 3은 본 발명의 실시예에 따른 연합 학습 과제를 생성하고 실행하는 프로세스를 예시하는 개략도이다. 도 3을 참조하면, 모듈이 FL 워크로드를 실행/재실행하기를 원하자마자, 모듈은 FlWorkloadSubscriptionRequest 메시지를 스케줄러에 전송한다. 따라서 스케줄러는, 적어도 하나의 모듈로부터 특정 ML 모델과 관련하여 연합 학습 작업을 실행하거나 재실행하라는 요청을 수신하도록 구성 될 수 있으며, 상기 요청은 요청된 연합 학습 작업을 수행하는 UE에 의해 충족될 적어도 하나의 조건을 지정한 다. 상기 요청에는 다음 정보 중 일부 또는 전부가 포함될 수 있지만, 이는 요청에 포함될 수 있는 정보의 비제한적, 비완전한 목록임을 이해해야 한다: ● 요청된 서비스 품질(QoS) 프로파일 - FL 워크로드에 포함된 UE와 FL 워크로드를 지원하는 모듈 간의 종 단 간 통신과 관련된 QoS 수준; ● 중지 기준의 정렬된 목록 - 학습 단계의 최대 수, 손실 함수 기준, 타이머 등을 포함할 수 있는 가장 높은 중지 기준에서 가장 낮은 중지 기준으로 정렬된다; ● 요청된 UE의 최소 수 - FL 워크로드에 참여할 것으로 예상되는 최소 UE 수; ● FL 워크로드에 관련된 각 UE가 예약할 최소/최대 자원 양(예: 메모리 및 CPU 풋프린트); ● UE 클러스터링 기준 목록 - 클러스터링 기준 목록(가장 높은 우선순위에서 가장 낮은 우선순위로 정렬); 무작위 코드 매개변수 - 최적화되지 않을 사용될 코드의 기본 매개변수 목록. 예를 들어, RLNC(Random Linear Network Coding) 코드가 사용되는 경우 FL 워크로드를 지원하는 rApp은 사용할 갈루아 필드(Galois field) 또 는 유한체(finite field)의 크기(예: 2, )를 지정할 수 있다. FlWorkloadSubscriptionRequest를 수신하면 스케줄러는 다음 메시지 중 하나로 응답할 수 있다: ● 긍정적인 FlWorkloadSubscriptionResponse - 이 메시지는 스케줄러가 FL 워크로드에 참여할 의향이 있 는 UE로부터 충분한 가입 요청을 수신한 경우에 전송된다. 따라서 UE 풀에서 새로운 FL 워크로드를 수용하기에 충분한 자원을 찾을 수 있다. ● 부정적인 FlWorkloadSubscriptionResponse - 이 메시지는 스케줄러가 새로운 FL 워크로드를 수용하기 위해 UE 풀 전체에 걸쳐 충분한 UE 및/또는 자원에 액세스할 수 없는 경우에 전송된다. 이 경우, FL 워크로드를 실행/재실행하려는 모듈은 이후 단계에서 다른 FlWorkloadSubscriptionRequest 메시지를 보낼 수 있다. 따라서, 스케줄러는 복수의 UE에 대해 저장된 정보를 사용하여 UE가 적어도 하나의 조건을 만족하는지 여 부를 결정하고; 이 결정에 기초하여 상기 요청이 승인되는지 여부를 지시하는 응답을 요청 모듈에 전송하 도록 구성될 수 있다. 따라서 모듈 중 하나가 특정 ML 모델과 관련하여 연합 학습 프로세스를 실행하거나 재실 행하려고 할 때마다 모듈은 스케줄러에 요청을 보낸다. 상기 요청에는 ML 모델과 관련하여 수행되는 연합 학습 프로세스에 대한 정보가 포함된다. 이 정보는 연합 학습 프로세스에 참여할 UE가 충족해야 할 적어도 하나의 조 건을 지정한다. 이 조건(들)은 훈련 라운드 및/또는 ML 모델마다 다를 수 있다. 도 4는 본 발명의 실시예에 따라 UE가 스케줄러에 가입 요청 및 상태 업데이트를 전달하는 프로세스를 예 시하는 개략도이다. 도 4를 참조하면, UE(502a-502c)의 관점에서 볼 때, 스케줄러로 유래하는/향하는 임의의 메시지의 종단점/ 소스는 UE 운영 체제(예: 기기 드라이버, 메모리 관리자 또는 가비지 수집기(garbage collector))의 일부로 실 행되거나 또는 사용자 공간(예: Android 또는 iOS 앱)에서 실행될 수 있는 애플리케이션의 일부이다. FL 워크로드에 참여하려는 각 UE는 (예를 들어 E2 및 A1 인터페이스를 통해) 구독 요청(UeSubscriptionRequest)을 스케줄 러에 제출해야 한다. 가입 요청의 일부로서 UE는 다음 정보 중 하나를 포함할 수 있지만, 이는 가입 요청 에 포함될 수 있는 정보의 비제한적이고 비완전한 목록이라는 점을 이해해야 한다: ● 텐서 관련 운영을 지원하는 데 적합한 UE에 장착될 수 있는 하드웨어 주변 장치(텐서 처리 유닛 또는 TPU(tensor processing unit)라고도 함); 및 ● UE가 FL 워크로드 실행을 위해 할당할 수 있는 최대 RAM 및 스토리지 용량. 스케줄러가 UeSubscriptionRequest 메시지를 수신하자마자, UE는 FL 워크로드에 참여할 의사가 있는 UE 풀 에 추가된다. UeSubscriptionRequest 메시지 뒤에는 항상 도 3에 표시된 것처럼 스케줄러로부터의 확인 메 시지가 따른다. 주기적으로, (UeSubscriptionRequest 메시지를 통해) 스케줄러에 성공적으로 가입한 각 UE는 (UeStatus 메시지를 통해) 다음 정보 중 하나를 포함하는 스케줄러 rApp에 자신의 상태를 전달하며, 이는 상태 메시지에 포함될 수 있는 정보의 비제한적이고 비완전한 목록이라는 점을 이해해야 한다: ● UE가 참여하고 있는 활성 FL 워크로드 수; ● 사용 가능한 계산, 메모리 및 스토리지 자원; 및 ● 세그먼트/패킷/서비스 데이터 단위(SDU)/패킷 데이터 단위(PDU) 오류율 목록 - 특정 시간 간격에 걸쳐 평균 을 낸 것이며, 프로토콜 스택(애플리케이션 및 네트워크 계층을 포함하되 이에 국한되지 않음)의 여러 지점에서 업링크/다운링크로 계산됨. UeStatus 메시지는 E2 노드, E2 및 A1 인터페이스를 통해 또는 E2 노드 및 O1 인터페이스를 통해 스케줄러(20 2)에 전달될 수 있다. UeStatus 메시지는 클러스터별 코드 최적화 또는 FL 워크로드에 참여하는 UE의 글로벌 재클러스터링을 트리거하 기 위해 스케줄러에 의해 사용된다. 따라서, 코디네이터는 연합 학습 작업이 실행되는 동안 미리 정의된 기간 후에 선택된 UE 세트를 클러스터 링 정책에 따라 복수의 클러스터로 주기적으로 재그룹화하고; 그리고 재그룹화 후에 연합 학습 작업을 수행할 때 복수의 클러스터 내의 각 UE가 사용할 클러스터별 데이터 코딩 최적화 정책을 다시 결정하도록 더 구성될 수 있다. 이는 UE가 특정 연합 학습 작업을 위해 클러스터로 처음 그룹화되었을 때와 동일한 노드에 더 이상 연결 되지 않도록 셀룰러 네트워크 내에서 이동할 수 있기 때문에 유리하다. 따라서 연합 학습 작업 실행 전반에 걸 쳐 클러스터링 정책이 충족되도록 UE를 재그룹화하는 것이 유용하다. 일단 재그룹화가 수행되면(어떤 경우에는 클러스터가 변경되지 않을 수 있음), 클러스터별 데이터 코딩 최적화 정책이 각 클러스터에 대해 다시 결정된다. 이제 클러스터링/재클러스터링 절차에 대해 설명한다. 전제 조건: i번째 FL 워크로드를 고려한다. 스케줄러는 고려된 FL 워크로드에 참여할 것으로 예상되는 UE로 UE 세트 를 선택했다. 클러스터링 절차를 실행하는 개체는 코디네이터이다. 클러스터링 절차는 다음 조건 하에서 실행된다: (i) (A1 인터페이스를 통해) 스케줄러에 의해 코디네이터로 전송된 명령의 결과로 서 실행/재실행; 및/또는 주어진 타이머 가 만료되면 실행/재실행. 클러스터링 절차는 동일한 Near-RT RIC에 등록된 노드(402a-402c)에 의해 서비스되는 내의 UE의 서브세트에 대해 수행된다. 클러스터링 절차는 다음과 같이 작동한다. 스케줄러는 클러스터링 프로파일(FL 워크로드를 실행하는 모듈 에 의해 선택된 클러스터링 기준 목록에 의해 정의됨)을 포함하는 메시지에 의해 절차의 실행을 트리거한 다. 통신된 클러스터 프로파일에 관계없이 이 절차 범위 내의 UE 세트는 다음 기준이 충족되도록 클러스터링된 다: ● 서로 다른 E2 노드에서 서비스를 제공받는 UE는 동일한 클러스터의 일부가 될 수 없음; ● 동일한 E2 노드에서 서비스를 제공받는 UE는 하나 이상의 클러스터로 클러스터링될 수 있음; 및 ● 클러스터는 비워둘 수 없음. 클러스터링 절차의 결과는 클러스터 세트 의 리턴이며, 여기서 는 i번째 FL 워크로 드와 r번째 Near-RT RIC에 속하는 j번째 클러스터를 형성하는 UE 목록에 의해 정의된다. 관련 코디네이터 (들)에게 알려진 클러스터 세트는 다음으로 A1 인터페이스를 통해 스케줄러로 전달된다. 이제 코드 최적화/재최적화 절차가 설명된다. 사전 조건: 코디네이터는 자신의 직접 제어 하에 UE의 클러스터링을 완료했다. 코드 최적화 절차를 실행하 는 개체는 코디네이터이다. 코드 최적화 절차는 다음 조건 하에서 실행된다: (i) (A1 인터페이스를 통해) 스케줄러에 의해 코디네이터로 전송된 명령의 결과로 실행/재실행; 및/또는 (ii) 주어진 타이머 가 만료되면 실행/재실행. 코드 최적화 절차는 주어진 클러스터 내의 UE에 대해 수행된다. 코드 최적화 절차는 다음과 같이 작동한다. 스케줄러는 다음을 포함하는 메시지에 의해 절차의 실행을 트 리거한다: ● 고려되는 클러스터의 UE 사이에서 가장 높은 PDU 오류율 ; 및 ● 무작위 코드 오버헤드 요인 . 코드 최적화 절차의 결과는 클러스터 내의 모든 UE가 채택할 전체 코딩 오버헤드 의 리턴이다. 전체 코딩 오버헤드는 절차를 실행하는 코디네이터와 이 절차의 범위에 있는 UE에게만 알려진다. 비고 1: 클러스터 의 일부 UE 에서 생성할 코딩된 예제의 실제 개수는 로 관찰되며, 여기서 는 UE 측에 저장된 훈련 예제의 개수이다. 코디네이터는 연합 학습 작업을 수행하기 위해 각 클러스터에 어떤 UE가 있는지에 대한 정보를 스케줄러에 전송 하도록 구성되어서, 스케줄러가 각 클러스터 내의 UE에게 연합 학습 작업을 수행하도록 지시할 수 있다. 이는 코디네이터가 클러스터링/재클러스터링 작업을 수행할 때마다 발생할 수 있다. 연합 학습 작업은 복수의 훈련 반복/라운드를 수행하는 것을 포함할 수 있다. 연합 학습 작업에 대한 훈련 반복 이 시작되기 전에, 스케줄러는 복수의 클러스터의 UE로부터 수신된 상태 메시지를 확인하여 UE가 여전히 연합 학습 작업의 훈련 반복을 수행할 수 있는지 여부를 결정하고; 적어도 하나의 UE가 연합 학습 작업의 훈련 반복 을 수행할 수 없다고 결정한 경우에 응답하여, 코디네이터로 하여금 클러스터링 정책 및 UE 상태 메시지에 따라 UE를 복수의 클러스터로 재그룹화하도록 지시하도록 구성될 수 있다. 따라서, 스케줄러는 연합 학습 작업을 수 행하도록 원래 선택된 UE가 여전히 그렇게 할 수 있는지 여부를 결정할 수 있으며, 이는 잠재적인 스트래글러의 수를 감소시키는데 유리하게 도움이 된다. 스케줄러는 두 가지 방식으로 UE가 상태 메시지로부터 훈련 반복을 수행할 수 있는지 여부를 결정할 수 있다: 상태 메시지는 UE가 훈련을 수행할 수 있는지 여부를 나타낼 수 있고 /있거나 상태 메시지의 부재는 UE가 훈련을 수행할 수 없음을 나타낼 수 있다. 스케줄러가 적어도 하나의 UE가 이제 연합 학습 작업을 수행할 수 없다고 결정하면, 코디네이터는 연합 학습 작 업이 실행되는 동안 스케줄러의 명령에 따라 선택된 UE 세트 중 일부 또는 전부를 클러스터링 정책에 따라 복수 의 클러스터로 재그룹화하고; 그리고 재그룹화 후에 연합 학습 작업을 수행할 때 복수의 클러스터 내의 각 UE가 사용할 클러스터별 데이터 코딩 최적화 정책을 다시 결정하도록 구성될 수 있다. 따라서 코디네이터는 연합 학 습 작업을 실행하는 동안 및/또는 스케줄러의 명령에 응답하여 주기적으로 재그룹화를 수행한다. 코디네이터는 클러스터 내 모든 UE 중 가장 열악한 통신 채널 상황을 겪고 있는 UE의 통신 능력을 기반으로 각 클러스터에서 클러스터별 데이터 코딩 최적화 정책을 결정할 수 있다. 이는 최악의 채널 상황을 겪고 있는 UE가 연합 학습 작업을 수행할 수 있는 가능성을 향상시킨다는 장점이 있다. 코디네이터는 연합 학습 작업을 수행할 때 각 클러스터의 각 UE에게 클러스터별 데이터 코딩 최적화 정책을 사 용하도록 지시할 수 있다. 도 5는 본 발명의 실시예에 따라 셀룰러 네트워크 내에서 연합 학습을 수행하는 프로세스를 예시하는 개략도이 다. 전제 조건: i번째 FL 워크로드를 고려함. 스케줄러는 고려된 FL 워크로드에 참여할 것으로 예상되는 UE로 서 UE 세트 를 선택했다. 이 연합 학습 절차는 FL 워크로드가 성공할 때까지 잠재적으로 실행/재실행되며, 내의 모든 UE가 포함된다. 상기 프로세스는 모듈이 스케줄러에 분산 학습 프로세스를 시작할 의도를 통지할 때 시작된다. 다음 으로, 스케줄러는 FL 워크로드에 참여하는 UE를 서비스하는 E2 노드를 제어하는 모든 Near-RT RIC에 걸쳐 상술한 클러스터링 및 코드 최적화 절차를 트리거한다. 따라서, 각 훈련 단계 (여기서 는 훈련 단계의 최대 수임)에 대해, 모듈은 새 로운 훈련 단계가 곧 시작될 것임을 스케줄러에 통지하도록 구성된다. 이에 응답하여, 그리고 UE로부터의 UeStatus 메시지를 통해 스케줄러에 전달되는 사용 가능한 자원의 현재 풀의 변경에 기초하여, 스케줄러는 다수의 클러스터에 걸쳐 코드 재최적화 트리거하거나 또는 모든 클러스 터에 걸쳐 재클러스터링 및 코드 재최적화를 트리거 할 수 있다. i번째 FL 워크로드 실행을 담당하는 모듈은 내의 각 UE가 비고 1에 따라 선택된 무작위 코드에 따라 다수의 코딩된 예제를 생성하도록 스케줄러에 요청할 수 있다. 이에 응답하여, UE가 연합 학습 작업을 수행하도록 지시받은 경우, 클러스터 내의 각 UE는, UE에 저장된 적어도 하나의 훈련 데이터 항목에 대해, 클러스터별 데이터 코딩 최적화 정책에 기초하여 코딩된 훈련 데이터 항목을 생성하고; 그리고 클러스터 내의 UE에 상기 적어도 하나의 생성된 코딩된 훈련 데이터 항목을 멀티캐스트하도록 구성될 수 있다. 즉, 각 UE는 자신의 코딩된 훈련 데이터 항목(들)을 클러스터 내의 다른 UE에 직접적으로 제공 할 수 있다. 대안적으로, UE가 연합 학습 작업을 수행하도록 지시받은 경우, 클러스터 내의 각 UE는, UE에 저장된 적어도 하 나의 훈련 데이터 항목에 대해 클러스터별 데이터 코딩 최적화 정책에 기초하여 코딩된 훈련 데이터 항목을 생 성하고; 그리고 클러스터 내의 UE에 대한 배포를 위해 클러스터 내의 UE에 연결된 노드/기지국에 상기 적어도 하나의 생성된 코딩된 훈련 데이터 항목을 전송하도록 구성될 수 있다. 즉, 각 UE는 자신의 코딩된 훈련 데이터 항목(들)을 클러스터 내의 다른 UE에 간접적으로 제공할 수 있다. 따라서, 각각의 UE는 생성된 코딩된 예제를 동일한 클러스터에 속하는 다른 모든 UE에게 간접적으로 또는 직접 적으로 전달한다. 각 UE는 다른 클러스터 구성원으로부터 성공적으로 수신한 코딩된 예제를 로컬에 저장한다. UE는 수신된 코딩된 예제(잠재적으로 로컬로 생성된 코딩된 예를 포함함)를 추가로 조작할 수 있다. 상기 저장 된 코딩된 예제는 UE의 코딩된 훈련 세트를 구성한다. 각각의 UE는 (스케줄러를 통해) 로컬에 저장된 훈련 예제에 대한 부분 그래디언트를 계산하여 FL 워크로드 를 실행하는 모듈에 전송한다. 각 UE는 또한 (스케줄러를 통해) 로컬에 저장된 코딩된 훈련 예제에 대한 부분 그래디언트를 계산하여 FL 워크로드를 실행하는 모듈에 전송한다. 즉, 각 UE는, UE에 저장된 적 어도 하나의 훈련 데이터 항목을 사용하여 제1의 매개변수 세트를 생성하고; UE에 의해 생성된 적어도 하나의 생성된 코딩된 훈련 데이터 항목 및 클러스터 내의 다른 UE로부터 수신된 적어도 하나의 생성된 코딩된 훈련 데 이터 항목을 사용하여 제2의 매개변수 세트를 생성하고; 그리고 스케줄러를 통해 제1 및 제2의 매개변수 세트를 적어도 하나의 모듈에 전송하도록 더 구성될 수 있다. 다시 말해서, 각 UE는 기기 내에서 연합 학습 프로세스를 수행하여 두 개의 매개변수 세트를 생성한다. 제1의 매개변수 세트는 UE 자신의 훈련 데이터를 사용하여 생성되 는 반면, 제2의 매개변수 세트는 클러스터로부터 수신된 모든 코딩된 훈련 데이터 항목(UE 자신의 코딩된 훈련 데이터 항목(들) 포함)을 사용하여 생성된다. 유리하게도 이는 스트래글러 문제를 완화하는, 연합 학습 프로세 스에 일부 리던던시를 도입한다. 이는 제2의 매개변수 세트가 전체 클러스터와 관련되어 있기 때문에, 클러스터 에 있는 하나 이상의 UE가 매개변수 서버에 데이터/매개변수를 전송할 수 없더라도, 매개변수 서버는 클러스터 내의 다른 UE로부터 수신된 제2의 매개변수 세트를 통해 전체 클러스터로부터 정보를 수신하기 때문이다. 이러 한 방식으로 매개변수 서버는 개별 UE가 채널 상태의 열화를 겪더라도 클러스터 전체(또는 대부분)의 데이터를 사용하여 ML 모델을 업데이트할 수 있다. 각각의 부분 그래디언트는 보조 코딩 정보(예를 들어, 부분 그래디언트가 계산된 코딩된 예제의 수)와 함께 FL 워크로드를 실행하는 모듈에 전달될 수 있다. 경사하강법(gradient descent step)의 계산은 FL 워크로드를 실행하는 모듈에서 일어난다. 즉, 연합 학습 프로세스의 실행/재실행을 요청한 모듈은 각 UE에서 수신된 제1 및 제2의 매개변수 세트를 사용하여 UE가수행한 연합 학습 작업에 대응하는 ML 모델을 업데이트하도록 구성될 수 있다. 미리 정의된 기간 내에 클러스터 내의 미리 정의된 최소 개수의 UE로부터 제1의 매개변수 세트가 수신되면, 적 어도 하나의 모듈은, 클러스터 내의 UE로부터 수신된 제1의 매개변수 세트를 사용하여 ML 모델을 업데이트 하도 록 구성될 수 있다. 즉, 코딩된 예제를 참조하지 않거나 관련되지 않은 제1의 매개변수 세트는, 각 UE가 자체 원시 훈련 데이터를 사용하여 직접 생성했기 때문에, 우선되거나 선호된다. 다수의 부분 그래디언트가 미리 결정된 기한까지 도달하지 못한 경우, 누락된 부분 그래디언트는 코딩된 예제에 대해 계산된 부분 그래디언트의 무작위 선택으로 대체될 것이다. 즉, 사전 정의된 기간 내에 클러스터 내 사전 정의된 최소 수 미만의 UE로부터 제1의 매개변수 세트가 수신된 경우, 적어도 하나의 모듈은, 클러스터 내의 UE 로부터 수신된 제1의 매개변수 세트를 사용하고; 그리고 클러스터 내의 UE로부터 수신된 제2의 매개변수 세트의 무작위 선택을 사용하는 것에 의해 ML 모델을 업데이트하도록 구성될 수 있다. 이러한 방식으로, 클러스터의 UE 로부터 누락된 제1의 매개변수 세트(들)는 제2의 매개변수 세트를 사용하여 보상된다. 이것이 가능하지 않으면, FL 워크로드는 실패하고 이 절차는 종료된다. 즉, 사전 정의된 기간 내에 클러스터 내 사전 정의된 최소 수 미만의 UE로부터 제2의 매개변수 세트가 수신된 경우, 적어도 하나의 모듈은 ML모델의 업 데이트를 종료하도록 구성된다. 즉, 클러스터에서 수신된 데이터가 충분하지 않은 경우, ML 모델에 부정적인 영 향을 미치지 않도록 연합 학습 작업이 종료될 수 있다. 모듈이 수신된 매개변수를 집계할 수 있는 경우, FL 워크로드를 실행하는 모듈은 ML 모델 매개변수를 업데이트한다. 연합 학습 작업에 대한 중지 기준(예: 훈련 라운드 수)이 충족되면, 모듈은 연합 학습 작업 을 완료하고, 업데이트된 ML 모델 매개변수를 스케줄러, SMO를 관련 E2 노드에 연결하는 O1인터페이스를 통해 FL 워크로드에 참여하는 UE에 배포하고, 다음으로 FL 워크로드에 참여하는 UE에 배포한다. 따라서, 본 개시는 FL 워크로드의 생성/실행에서부터 완료/파괴 까지를 감독하고; FL 워크로드에 참여하기를 원 하는 모바일 노드 풀의 가입 프로세스를 감독하고; 그리고 채택할 클러스터링 정책을 결정하는 새로운 rApp (FLLM rApp/스케줄러 )를 제공한다. 본 개시는 또한, (FLLM rApp에서 결정한 클러스터링 정책에 기반한) FL 워크로드에 참여하는 모바일 노드 풀의 클러스팅 (본 개시는 클러스터 정책에 구애받지 않음); 및 선택한 무 작위 코드의 클러스터별 최적화 (본 개시는 무작위 코드에 구애받지 않음)를 담당하는, FL 워크로드에 참여하기 를 원하는 UE와 함께 각 Near-RT RIC에 배포될 새로운 분류의 ClCoO xApps/코디네이터를 제공한다. 본 개 시는 UE와 이의 서빙 E2 노드 사이의 불리한 채널 조건을 완화하기 위해 코딩된 훈련 예제의 멀티캐스팅을 지원 한다. 또한, 본 개시의 실시예는 컴퓨터 판독 가능 프로그램 코드가 구현된 컴퓨터 판독 가능 매체에서 구현된 컴퓨터 프로그램 제품의 형태를 취할 수 있다. 상기 컴퓨터 판독 가능 매체는 컴퓨터 판독 가능 신호 매체 또는 컴퓨터 판독 가능 저장 매체일 수 있다. 컴퓨터 판독 가능 매체는 예를 들어, 전자, 자기, 광학, 전자기, 적외선 또는 반도체 시스템, 장비 또는 장치, 또는 상술한 것의 임의의 적절한 조합 일 수 있지만, 이에 한정되는 것은 아니 다. 본 개시의 동작을 수행하기 위한 컴퓨터 프로그램 코드는 객체 지향 프로그래밍 언어 및 종래의 절차형 프로그 래밍 언어를 포함하는 하나 이상의 프로그래밍 언어의 임의의 조합으로 기재될 수 있다. 코드 컴포넌트는 프로 시저, 방법 등으로 구현될 수 있으며, 원시 명령어 세트의 직접적인 기계 명령어로부터 고 레벨 컴파일 또는 번 역된 언어 구성까지의 임의의 추상화 레벨의 명령어 또는 명령어의 시퀀스의 형태를 취할 수 있는 서브 컴포넌 트를 포함할 수 있다. 본 개시의 실시예는 또한 프로세서 상에 구현될 때 프로세서로 하여금 여기에 설명된 방법들 중 임의의 방법을 수행하게 하는 코드를 전달하는 비일시적인 데이터 캐리어를 제공한다. 상기 기술은 예를 들어 범용 컴퓨터 시스템 또는 디지털 신호 프로세서(DSP)상에서 상술한 방법들을 구현하기 위한 프로세서 제어 코드를 더 제공한다. 또한, 상기 기술은, 실행시에, 특히 비일시적 데이터 캐리어 상에서 상기 방법들 중 임의의 것을 구현하는 프로세서 제어 코드를 전달하는 캐리어를 제공한다. 상기 코드는 디스크, 마이크로프로세서, CD- 또는 DVD-ROM과 같은 캐리어, 또는 비휘발성 메모리 (예를 들어, 플래시 메모리) 또는 판독 전용 메모리(ROM; 펌웨어)와 같은 프로그래밍된 메모리, 또는 광학 또는 전기 신호 캐리어와 같은 데이터 캐리어 상에서 제공될 수 있다. 상기 기술의 실시예를 구현하기 위한 코드(및/또는 데이터)는 Python, C 또는 어셈블리 코드와 같은 종래의 프로그래밍 언어(인터프리터 또는 컴파일)의 소스, 객체 또는 실행 가능 코드, ASIC(Application Specific Integrated Circuit) 또는 FPGA(Field Programmable Gate Array)를 설정 또는제어하기 위한 코드, 또는 Verilog (RTM(register transfer module)) 또는 VHDL(초고속 집적 회로 하드웨어 설 명 언어)과 같은 하드웨어 설명 언어용 코드를 포함할 수 있다. 당업자가 알 수 있는 바와 같이, 이러한 코드 및/또는 데이터는 서로 통신하는 복수의 결합된 컴포넌트들 사이에 분산될 수 있다. 상기 기술은 마이크로프로 세서, 작업 메모리 및 시스템의 하나 이상의 컴포넌트에 연결된 프로그램 메모리를 포함하는 컨트롤러를 포함할 수 있다. 또한, 본 개시의 실시예에 따른 논리 방법의 전부 또는 일부가 상술한 방법의 단계를 수행하기 위한 논리 소자 를 포함하는 논리 장치에서 적절하게 구현될 수 있고, 그러한 논리 소자는, 예를 들어, 프로그래밍 가능 논리 어레이 또는 주문형 집적 회로에서 논리 게이트와 같은 컴포넌트를 포함할 수 있다는 것이 당업자에게는 명확할 것이다. 그러한 논리 배열은 고정 또는 전송 가능 캐리어 매체를 사용하여 저장되고 전송될 수 있는, 예를 들어 가상 하드웨어 디스크립터 언어를 사용하여 그러한 어레이 또는 회로에 논리 구조를 일시적으로 또는 영구적으 로 설정할 수 있는 소자로 더 구현될 수 있다. 일 실시예에서, 본 개시는 기능적 데이터를 갖는 데이터 캐리어의 형태로 실현될 수 있으며, 상기 기능적 데이 터는 기능적 컴퓨터 데이터 구조를 포함하고, 컴퓨터 시스템 또는 네트워크에 로딩되고 그에 의해 동작될 때, 상기 컴퓨터 시스템으로 하여금 상술한 방법의 모든 단계를 수행하도록 할 수 있다. 상술한 방법은 기계 학습이나 인공 지능 모델을 이용하여 장치, 즉 전자 기기에서 전부 또는 부분적으로 수행될 수 있다. 상기 모델은 인공지능 모델 처리를 위해 지정된 하드웨어 구조로 설계된 인공지능 전용 프로세서에 의 해 처리될 수 있다. 인공지능 모델은 훈련을 통해 얻을 수 있다. 여기서, ＂훈련을 통해 획득된다＂는 것은, 기 본 인공지능 모델이 훈련 알고리즘에 의하여 다수의 훈련 데이터들을 이용하여 훈련됨으로써, 원하는 특성(또는, 목적)을 수행하도록 설정된 사전 정의된 동작 규칙 또는 인공지능 모델이 획득됨을 의미할 수 있다. 인공지능 모델은, 복수의 신경망 계층으로 구성될 수 있다. 복수의 신경망 계층 각각은 복수의 가중치들(weight values)을 갖고 있으며, 이전(previous) 계층의 연산 결과와 복수의 가중치들 간의 연산을 통해 신경망 연산을 수행한다. 상술한 바와 같이, 본 개시의 실시예는 AI 모델을 사용하여 구현될 수 있다. AI와 관련된 기능은 비휘발성 메모 리, 휘발성 메모리 및 프로세서를 통해 수행될 수 있다. 프로세서는 하나 또는 복수의 프로세서를 포함할 수 있 다. 이때, 하나 또는 복수의 프로세서는 CPU(Central Processing Unit), AP(Application Processor) 등과 같 은 범용 프로세서일 수도 있고, GPU(Graphics Processing Unit), VPU(Visual Processing Unit)와 같은 그래픽 전용 처리 장치일 수도 있으며, 및/또는 NPU(Neural Processing Unit)와 같은 AI 전용 프로세서일 수도 있다. 하나 또는 복수의 프로세서는 비휘발성 메모리 및 휘발성 메모리에 저장된 사전 정의된 동작 규칙 또는 인공 지 능(AI) 모델에 따라 입력 데이터의 처리를 제어한다. 사전 정의된 동작 규칙 또는 인공 지능 모델은 훈련 또는 학습을 통해 제공된다. 여기서, 학습을 통해 제공된다는 것은 다수의 학습 데이터에 학습 알고리즘을 적용하는 것에 의해서 원하는 특성의 사전 정의된 동작 규칙이나 AI 모델을 만든다는 것을 의미한다. 이러한 학습은 일 실시예에 따른 AI가 수행되는 장치 자체에서 수행될 수도 있고/있거나, 별도의 서버/시스템을 통해 구현될 수 도 있다. AI 모델은 복수의 신경망 계층으로 구성될 수 있다. 각 계층은 복수의 가중치를 가지며, 이전 계층의 계산과 복수의 가중 연산을 통해 계층 연산을 수행한다. 신경망의 예로는 CNN(Convolutional Neural Network), DNN(Deep Neural Network), RNN(Recurrent Neural Network), RBM(Restricted Boltzmann Machine), DBN(Deep Belief Network), BRDNN(Bidirectional Recurrent Deep Neural Network), GAN(Generative Adversarial Networks) 및 심층 Q-네트워크를 포함하나, 이에 제한되지 않는다. 학습 알고리즘은 복수의 학습 데이터를 이용하여 소정의 타겟 기기(예를 들어, 로봇)를 훈련시킴으로써 타겟 기 기로 하여금 판단 또는 예측을 하게 하거나, 판단 또는 예측을 가능하게 하거나, 또는 판단 또는 예측을 제어하 도록 하는 방법이다. 학습 알고리즘의 예로는 지도 학습, 비지도 학습, 반지도 학습 또는 강화 학습을 포함하나, 이에 제한되지 않는다. 당업자는 상술한 내용이 본 개시의 실시예를 수행하는 최선의 모드로 간주되는 경우와 적절한 경우 다른 모드를 설명했지만, 본 개시가 설명에 개시된 특정 구성 및 방법으로 제한되어서는 안 된다는 것을 이해할 것이다. 당 업자는 본 개시 내용이 광범위한 적용 범위를 갖고, 실시예가 첨부된 청구 범위에 정의된 바와 같은 임의의 발 명적 개념으로부터 벗어나지 않고 광범위한 변형을 포함할 수 있다는 것을 인지할 것이다. 본 개시는 다양한 실시 예를 참조하여 예시되고 설명되었으나, 당업자는 청구범위 및 이에 상응하는 범위에 정 의된 바에 따라 본 개시에 정의된 기술적 사상 및 범위를 벗어나지 않고 형태나 세부 사항에 있어서 다양한 변 경이 이루어질 수 있음을 이해할 수 있다."}
{"patent_id": "10-2023-0158972", "section": "도면", "subsection": "도면설명", "item": 1, "content": "본 개시의 실시 예의 상술한 측면 및 다른 측면, 특징 및 이점은 첨부 도면과 함께 후술하는 설명으로부터 더욱 명백해질 것이다. 도 1은 연합 학습 프로세스 내의 스트래글러(straggler) 문제를 예시하는 개략도이다. 도 2는 본 개시의 일 실시예에 따라 ORAN(open radio access network) 셀룰러 네트워크 내에서 ML 모델을 훈련 하기 위한 시스템의 블록도를 예시한다. 도 3은 본 개시의 실시예에 따라 연합 학습 작업을 생성하고 실행하는 프로세스를 예시하는 개략도이다. 도 4는 본 개시의 실시예에 따라 UE가 가입 요청 및 상태 업데이트를 스케줄러에 전달하는 프로세스를 예시하는 개략도이다. 그리고 도 5는 본 개시의 실시예에 따라 셀룰러 네트워크 내에서 연합 학습을 수행하는 프로세스를 예시하는 개략도이 다."}
