{"patent_id": "10-2023-0072322", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0173495", "출원번호": "10-2023-0072322", "발명의 명칭": "인공지능을 이용한 음성 인식을 수행하기 위한 방법 및 그 장치", "출원인": "한양대학교 산학협력단", "발명자": "장준혁"}}
{"patent_id": "10-2023-0072322", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "인공지능을 이용하여 전자 장치에 의해 수행되는 방법에 있어서,음성 데이터를 수신하는 단계; 및기 학습된 제1 인공지능 네트워크 모델을 통해 상기 음성 데이터를 입력 자료로 하여 제1 세논(senone)을 출력하는 단계를 포함하고,상기 기 학습된 제1 인공지능 네트워크 모델은:노이즈가 포함된 음성 데이터 셋을 수신하고, 제1 음향 모델(acoustic model)에서 상기 노이즈가 포함된 음성데이터 셋을 기반으로 차원 확장된 제1 임베딩을 생성하고, 상기 차원 확장된 제1 임베딩을 기반으로 차원 확장된 제2 세논을 출력하고, 차원 확장된 제1 타겟과 상기 차원 확장된 제2 세논을 기반으로 사전 학습되는 방법."}
{"patent_id": "10-2023-0072322", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 기 학습된 제1 인공지능 네트워크 모델은:상기 차원 확장된 제2 세논과 상기 차원 확장된 제1 타겟을 기반으로 제1 손실을 결정하는 방법."}
{"patent_id": "10-2023-0072322", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,상기 차원 확장된 제1 임베딩 및 상기 차원 확장된 제1 타겟은 노이즈 레이블의 개수를 기반으로 차원이 확장되는 방법."}
{"patent_id": "10-2023-0072322", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,상기 기 학습된 제1 인공지능 네트워크 모델은 상기 차원 확장된 제1 임베딩을 결합하여 제2 임베딩을생성하고, 상기 제2 임베딩을 기반으로 차원 확장된 제3 세논을 출력하고, 상기 차원 확장된 제3 세논을 제2 인공지능 네트워크 모델에 제2 타겟으로 할당하고, 그리고상기 제2 인공지능 네트워크 모델은:상기 노이즈가 포함된 음성 데이터 셋을 수신하고, 제2 음향 모델에서 상기 노이즈가 포함된 음성 데이터 셋을기반으로 제3 임베딩을 생성하고, 상기 제3 임베딩을 기반으로 제4 세논을 출력하고, 상기 기 학습된 제1 인공지능 네트워크 모델로부터 할당된 제2 타겟 및 상기 제4 세논을 기반으로 제2 손실을 결정하고 상기 제2 손실을기반으로 학습되는 방법."}
{"patent_id": "10-2023-0072322", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서,공개특허 10-2024-0173495-3-상기 제1 음향 모델은 상기 제2 음향 모델보다 레이어의 수가 하나 더 많도록 구성되는 방법."}
{"patent_id": "10-2023-0072322", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제4항에 있어서,상기 학습된 제2 인공지능 네트워크 모델을 통해 상기 음성 데이터를 입력 자료로 하여 제5 세논을 출력하는 단계를 더 포함하는 방법."}
{"patent_id": "10-2023-0072322", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제4항에 있어서,상기 제2 인공지능 네트워크 모델은 상기 기 학습된 제1 인공지능 네트워크 모델로부터 자가 증류(self-distillation) 프로세스를 통하여 학습되고,상기 제2 인공지능 네트워크 모델은 학생(student) 네트워크이고, 및상기 기 학습된 제1 인공지능 네트워크 모델은 교사(teacher) 네트워크인 방법."}
{"patent_id": "10-2023-0072322", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "전자 장치에 있어서,메모리;모뎀;기 학습된 제1 인공지능 네트워크 모델; 및상기 모뎀 및 상기 메모리에 연결되는 프로세서를 포함하고,상기 프로세서는:음성 데이터를 수신하고, 그리고상기 기 학습된 제1 인공지능 네트워크 모델을 통해 상기 음성 데이터를 입력 자료로 하여 제1 세논(senone)을출력하도록 구성되고,상기 기 학습된 제1 인공지능 네트워크 모델은:노이즈가 포함된 음성 데이터 셋을 수신하고, 제1 음향 모델(acoustic model)에서 상기 노이즈가 포함된 음성데이터 셋을 기반으로 차원 확장된 제1 임베딩을 생성하고, 상기 차원 확장된 제1 임베딩을 기반으로 차원 확장된 제2 세논을 출력하고, 차원 확장된 제1 타겟과 상기 차원 확장된 제2 세논을 기반으로 사전 학습되는 전자장치."}
{"patent_id": "10-2023-0072322", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제8항에 있어서,상기 기 학습된 제1 인공지능 네트워크 모델은:상기 차원 확장된 제2 세논과 상기 차원 확장된 제1 타겟을 기반으로 제1 손실을 결정하는 전자 장치."}
{"patent_id": "10-2023-0072322", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "공개특허 10-2024-0173495-4-제9항에 있어서,상기 차원 확장된 제1 임베딩 및 상기 차원 확장된 제1 타겟은 노이즈 레이블의 개수를 기반으로 차원이 확장되는 전자 장치."}
{"patent_id": "10-2023-0072322", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제8항에 있어서, 제2 인공지능 네트워크 모델을 더 포함하고,상기 기 학습된 제1 인공지능 네트워크 모델은 상기 차원 확장된 제1 임베딩을 결합하여 제2 임베딩을생성하고, 상기 제2 임베딩을 기반으로 차원 확장된 제3 세논을 출력하고, 상기 차원 확장된 제3 세논을 상기제2 인공지능 네트워크 모델에 제2 타겟으로 할당하고, 그리고상기 제2 인공지능 네트워크 모델은:상기 노이즈가 포함된 음성 데이터 셋을 수신하고, 제2 음향 모델에서 상기 노이즈가 포함된 음성 데이터 셋을기반으로 제3 임베딩을 생성하고, 상기 제3 임베딩을 기반으로 제4 세논을 출력하고, 상기 기 학습된 제1 인공지능 네트워크 모델로부터 할당된 제2 타겟 및 상기 제4 세논을 기반으로 제2 손실을 결정하고 상기 제2 손실을기반으로 학습되는 전자 장치."}
{"patent_id": "10-2023-0072322", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항에 있어서, 상기 프로세서는:상기 제1 음향 모델은 상기 제2 음향 모델보다 레이어의 수가 하나 더 많도록 구성되는 전자 장치."}
{"patent_id": "10-2023-0072322", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제11항에 있어서, 상기 프로세서는:상기 학습된 제2 인공지능 네트워크 모델을 통해 상기 음성 데이터를 입력 자료로 하여 제5 세논을 출력하는 단계를 더 포함하는 전자 장치."}
{"patent_id": "10-2023-0072322", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제11항에 있어서,상기 학습된 제2 인공지능 네트워크 모델은 상기 기 학습된 제1 인공지능 네트워크 모델로부터 자가 증류(self-distillation) 프로세스를 통하여 학습되고,상기 제2 인공지능 네트워크 모델은 학생(student) 네트워크이고, 및상기 기 학습된 제1 인공지능 네트워크 모델은 교사(teacher) 네트워크인 전자 장치."}
{"patent_id": "10-2023-0072322", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "프로세서(processor)에 의해 실행 가능한 인공지능 알고리즘을 통해 음성 인식을 수행하기 위한 매체에 저장된프로그램으로서,음성 데이터를 수신하는 단계; 및기 학습된 제1 인공지능 네트워크 모델을 통해 상기 음성 데이터를 입력 자료로 하여 제1 세논(senone)을 출력하는 단계를 포함하고,공개특허 10-2024-0173495-5-상기 기 학습된 제1 인공지능 네트워크 모델은:노이즈가 포함된 음성 데이터 셋을 수신하고, 제1 음향 모델(acoustic model)에서 상기 노이즈가 포함된 음성데이터 셋을 기반으로 차원 확장된 제1 임베딩을 생성하고, 상기 차원 확장된 제1 임베딩을 기반으로 차원 확장된 제2 세논을 출력하고, 차원 확장된 제1 타겟과 상기 차원 확장된 제2 세논을 기반으로 사전 학습되는 프로그램."}
{"patent_id": "10-2023-0072322", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 발명의 실시 예에 따른 인공지능을 이용하여 전자 장치에 의해 수행되는 방법에 있어서, 음성 데이터를 수신 하는 단계; 및 기 학습된 제1 인공지능 네트워크 모델을 통해 상기 음성 데이터를 입력 자료로 하여 제1 세논 (senone)을 출력하는 단계를 포함하고, 상기 기 학습된 제1 인공지능 네트워크 모델은 노이즈가 포함된 음성 데 이터 셋을 수신하고, 제1 음향 모델(acoustic model)에서 상기 노이즈가 포함된 음성 데이터 셋을 기반으로 차원 확장된 제1 임베딩을 생성하고, 상기 차원 확장된 제1 임베딩을 기반으로 상기 차원 확장된 제2 세논을 출력하고, 차원 확장된 제1 타겟과 상기 차원 확장된 제2 세논을 기반으로 사전 학습될 수 있다."}
{"patent_id": "10-2023-0072322", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 인공지능을 이용하여 음성을 인식하기 위한 방법 및 그 장치 나타낸다. 구체적으로, 인공지능을 학습 시킬 때 데이터를 증강을 통해 다양한 노이즈 환경에서도 동일한 성능을 가지는 음성 인식 방법을 제안한다."}
{"patent_id": "10-2023-0072322", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "본 개시는 다양한 환경에서 음성을 인식하는 장치 및 방법에 관한 것이다. 음성 인식 기술은 사람의 음성을 컴 퓨터가 이해하고 처리할 수 있는 텍스트나 명령으로 변환하는 기술이다. 음성을 분석하고, 음성 신호를 단어와 구문으로 분리하여 텍스트로 변환하거나 음성 명령을 이해하여 수행될 수 있다. 인공지능을 이용한 음성 인식 기술에서는 일반적인 음향 신호를 캡처하고 캡처한 음성 신호(또는 데이터) 대하여 전처리를 수행하고, 전처리 된 음성 데이터에서 음성 인식에 필요한 특징을 추출하고, 해당 특징들을 알고리즘 모델에 학습시킨 후 디코딩 및 후처리 하는 방식으로 수행된다. 인공지능을 기반으로 한 음성 인식 기술은 자율 주행 기술, 인공지능 스피 커 기술, 로봇 등 주변 환경에 영향을 받지 않고 강인한 음성 인식 성능을 요구하는 분야에 적용될 가능성이 크 다. 다만, 인공지능 기반의 음성 인식 기술에서 학습을 위한 음성 신호의 종류 및 음성 인식이 수행되는 환경에 따 라 성능이 일정하지 않고 다양하게 나타나는 문제점이 있다. 특히, 종래에 이러한 문제점을 극복하기 위하여 다 양한 노이즈 환경에서 강인하게 학습되도록 하는 AMTL(adversarial multi-task learning) 방식이 사용되었지만 서로 다른 branch에서 연산이 진행되어 분리된 표현 공간에서 진행될 수밖에 없어서 추가적인 계산이 필요하여 최적화된 학습이 어려운 한계점이 있었다. 이러한 한계를 극복하기 위하여, 데이터 증강을 통해 다양한 도메인에서도 성능을 유지할 수 있는 음성 인식 시 스템이 요구되고 있다."}
{"patent_id": "10-2023-0072322", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 개시에서는 데이터 증강 방식으로 노이즈 라벨 정보를 추가로 활용하여 데이터를 증강시켜 음성 인식 기능을 향상시키는 방법 및 그 장치를 제공하고자 한다. 본 개시에서는 데이터의 차원을 확장시켜 학습시킨 인공지능 알고리즘에 자기 증류 기법을 적용하여 음성 인식 기능을 향상시키는 방법 및 그 장치를 제공하고자 한다."}
{"patent_id": "10-2023-0072322", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 발명의 실시 예에 따른 인공지능을 이용하여 전자 장치에 의해 수행되는 방법에 있어서, 음성 데이터를 수신 하는 단계; 및 기 학습된 제1 인공지능 네트워크 모델을 통해 상기 음성 데이터를 입력 자료로 하여 제1 세논 (senone)을 출력하는 단계를 포함하고, 상기 기 학습된 제1 인공지능 네트워크 모델은 노이즈가 포함된 음성 데 이터 셋을 수신하고, 제1 음향 모델(acoustic model)에서 상기 노이즈가 포함된 음성 데이터 셋을 기반으로 차 원 확장된 제1 임베딩을 생성하고, 상기 차원 확장된 제1 임베딩을 기반으로 차원 확장된 제2 세논을 출력하고,차원 확장된 제1 타겟과 상기 차원 확장된 제2 세논을 기반으로 사전 학습될 수 있다. 일 실시예에서, 상기 기 학습된 제1 인공지능 네트워크 모델은 상기 차원 확장된 제2 세논과 상기 차원 확장된 제1 타겟을 기반으로 제1 손실을 결정할 수 있다. 일 실시예에서, 상기 차원 확장된 제1 임베딩 및 상기 차원 확장된 제1 타겟은 노이즈 레이블의 개수를 기반으 로 차원이 확장될 수 있다. 일 실시예에서, 상기 기 학습된 제1 인공지능 네트워크 모델은 상기 차원 확장된 제1 임베딩을 결합하여 제2 임 베딩을 생성하고, 상기 제2 임베딩을 기반으로 차원 확장된 제3 세논을 출력하고, 상기 차원 확장된 제3 세논을 제2 인공지능 네트워크 모델에 제2 타겟으로 할당하고, 그리고 상기 제2 인공지능 네트워크 모델은 상기 노이즈 가 포함된 음성 데이터 셋을 수신하고, 제2 음향 모델에서 상기 노이즈가 포함된 음성 데이터 셋을 기반으로 제 3 임베딩을 생성하고, 상기 제3 임베딩을 기반으로 제4 세논을 출력하고, 상기 기 학습된 제1 인공지능 네트워 크 모델로부터 할당된 제2 타겟 및 상기 제4 세논을 기반으로 제2 손실을 결정하고 상기 제2 손실을 기반으로 학습될 수 있다. 일 실시예에서, 상기 제1 음향 모델은 상기 제2 음향 모델보다 레이어의 수가 하나 더 많도록 구성될 수 있다. 일 실시예에서, 상기 학습된 제2 인공지능 네트워크 모델을 통해 상기 음성 데이터를 입력 자료로 하여 제5 세 논을 출력할 수 있다. 일 실시예에서, 상기 제2 인공지능 네트워크 모델은 상기 기 학습된 제1 인공지능 네트워크 모델로부터 자가 증 류(self-distillation) 프로세스를 통하여 학습되고, 상기 제2 인공지능 네트워크 모델은 학생(student) 네트워 크이고, 및 상기 기 학습된 제1 인공지능 네트워크 모델은 교사(teacher) 네트워크일 수 있다. 본 발명의 실시 예에 따른 전자 장치에 있어서, 메모리; 모뎀; 기 학습된 제1 인공지능 네트워크 모델; 및 상기 모뎀 및 상기 메모리에 연결되는 프로세서를 포함하고, 상기 프로세서는 음성 데이터를 수신하고, 그리고 상기 기 학습된 제1 인공지능 네트워크 모델을 통해 상기 음성 데이터를 입력 자료로 하여 제1 세논(senone)을 출력 하도록 구성되고, 상기 기 학습된 제1 인공지능 네트워크 모델은 노이즈가 포함된 음성 데이터 셋을 수신하고, 제1 음향 모델(acoustic model)에서 상기 노이즈가 포함된 음성 데이터 셋을 기반으로 차원 확장된 제1 임베딩 을 생성하고, 상기 차원 확장된 제1 임베딩을 기반으로 차원 확장된 제2 세논을 출력하고, 차원 확장된 제1 타 겟과 상기 차원 확장된 제2 세논을 기반으로 사전 학습될 수 있다. 본 발명의 실시 예에 따른 프로세서(processor)에 의해 실행 가능한 인공지능 알고리즘을 통해 방향 추정 방법 을 수행하기 위한 매체에 저장된 프로그램으로서, 음성 데이터를 수신하는 단계; 및 기 학습된 제1 인공지능 네 트워크 모델을 통해 상기 음성 데이터를 입력 자료로 하여 제1 세논(senone)을 출력하는 단계를 포함하고, 상기 기 학습된 제1 인공지능 네트워크 모델은 노이즈가 포함된 음성 데이터 셋을 수신하고, 제1 음향 모델(acoustic model)에서 상기 노이즈가 포함된 음성 데이터 셋을 기반으로 차원 확장된 제1 임베딩을 생성하고, 상기 차원 확장된 제1 임베딩을 기반으로 상기 차원 확장된 제2 세논을 출력하고, 차원 확장된 제1 타겟과 상기 차원 확장 된 제2 세논을 기반으로 사전 학습될 수 있다."}
{"patent_id": "10-2023-0072322", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 개시의 일 실시예에 따르면, 데이터 증강을 통해 다양한 노이즈 환경에서도 음성 인식 기능의 높은 성능을 유지할 수 있다."}
{"patent_id": "10-2023-0072322", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 발명의 기술적 사상은 다양한 변경을 가할 수 있고 여러 가지 실시 예를 가질 수 있는 바, 특정 실시 예들을 도면에 예시하고 이를 상세한 설명을 통해 상세히 설명하고자 한다. 그러나, 이는 본 발명의 기술적 사상을 특 정한 실시 형태에 대해 한정하려는 것이 아니며, 본 발명의 기술적 사상의 범위에 포함되는 모든 변경, 균등물 내지 대체물을 포함하는 것으로 이해되어야 한다. 본 발명의 기술적 사상을 설명함에 있어서, 관련된 공지 기술에 대한 구체적인 설명이 본 발명의 요지를 불필요 하게 흐릴 수 있다고 판단되는 경우 그 상세한 설명을 생략한다. 또한, 본 명세서의 설명 과정에서 이용되는 숫자(예를 들어, 제1, 제2 등)는 하나의 구성요소를 다른 구성요소와 구분하기 위한 식별기호에 불과하다. 또한, 본 명세서에서, 일 구성요소가 다른 구성요소와 \"연결된다\" 거나 \"접속된다\" 등으로 언급된 때에는, 상기 일 구성요소가 상기 다른 구성요소와 직접 연결되거나 또는 직접 접속될 수도 있지만, 특별히 반대되는 기재가 존재하지 않는 이상, 중간에 또 다른 구성요소를 매개하여 연결되거나 또는 접속될 수도 있다고 이해되어야 할 것이다. 또한, 본 명세서에 기재된 \"~부\", \"~기\", \"~자\", \"~모듈\" 등의 용어는 적어도 하나의 기능이나 동작을 처리하는 단위를 의미하며, 이는 프로세서(Processor), 마이크로 프로세서(Micro Processer), 마이크로 컨트롤러(Micro Controller), CPU(Central Processing Unit), GPU(Graphics Processing Unit), APU(Accelerate Processor Unit), DSP(Drive Signal Processor), ASIC(Application Specific Integrated Circuit), FPGA(Field Programmable Gate Array) 등과 같은 하드웨어나 소프트웨어 또는 하드웨어 및 소프트웨어의 결합으로 구현될 수 있으며, 적어도 하나의 기능이나 동작의 처리에 필요한 데이터를 저장하는 메모리(memory)와 결합되는 형태 로 구현될 수도 있다. 그리고 본 명세서에서의 구성부들에 대한 구분은 각 구성부가 담당하는 주기능 별로 구분한 것에 불과함을 명확 히 하고자 한다. 즉, 이하에서 설명할 2개 이상의 구성부가 하나의 구성부로 합쳐지거나 또는 하나의 구성부가 보다 세분화된 기능별로 2개 이상으로 분화되어 구비될 수도 있다. 그리고 이하에서 설명할 구성부 각각은 자 신이 담당하는 주기능 이외에도 다른 구성부가 담당하는 기능 중 일부 또는 전부의 기능을 추가적으로 수행할 수도 있으며, 구성부 각각이 담당하는 주기능 중 일부 기능이 다른 구성부에 의해 전담되어 수행될 수도 있음은 물론이다. 본 개시의 실시예들을 설명함에 있어서 관련된 기능 혹은 구성에 대한 구체적인 설명이 본 개시의 요지를 불필 요하게 흐릴 수 있다고 판단된 경우 그 상세한 설명은 생략한다. 그리고 후술되는 용어들은 본 개시에서의 기능 을 고려하여 정의된 용어들로서 이는 사용자, 운용자의 의도 또는 관례 등에 따라 달라질 수 있다. 그러므로 그 정의는 본 명세서 전반에 걸친 내용을 토대로 내려져야 할 것이다. 마찬가지 이유로 첨부 도면에 있어서 일부 구성요소는 과장되거나 생략되거나 개략적으로 도시될 수 있다. 또한, 각 구성요소의 크기는 실제 크기를 전적으로 반영하는 것이 아니다. 각 도면에서 동일한 또는 대응하는 구성요소에는 동일한 참조 번호를 부여하였다. 본 개시의 이점 및 특징, 그리고 그것들을 달성하는 방법은 첨부되는 도면과 함께 상세하게 후술되어 있는 실시 예들을 참조하면 명확해질 것이다. 그러나 본 개시는 이하에서 개시되는 실시예들에 한정되는 것이 아니라 서로 다른 다양한 형태로 구현될 수 있으며, 단지 실시예들은 본 개시의 설명이 완전하도록 하고, 본 개시의 실시예"}
{"patent_id": "10-2023-0072322", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "들이 속하는 기술분야에서 통상의 지식을 가진 자에게 발명의 범주를 완전하게 알려주기 위해 제공되는 것이며, 본 개시의 청구하고자 하는 범위는 청구항의 범주에 의해 정의될 뿐이다. 이때, 처리 흐름도를 보이는 도면들의 각 블록과 처리 흐름도 도면들의 조합들은 컴퓨터 프로그램 인스트럭션들 에 의해 수행될 수 있음을 이해할 수 있을 것이다. 이들 컴퓨터 프로그램 인스트럭션들은 범용 컴퓨터, 특수용 컴퓨터 또는 기타 프로그램 가능한 데이터 프로세싱 장비의 프로세서에 탑재될 수 있으므로, 컴퓨터 또는 기타 프로그램 가능한 데이터 프로세싱 장비의 프로세서를 통해 수행되는 그 인스트럭션들이 흐름도 블록(들)에서 설 명된 기능들을 수행하는 수단을 생성하게 된다. 이들 컴퓨터 프로그램 인스트럭션들은 특정 방식으로 기능을 구 현하기 위해 컴퓨터 또는 기타 프로그램 가능한 데이터 프로세싱 장비를 지향할 수 있는 컴퓨터 이용 가능 또는 컴퓨터 판독 가능 메모리에 저장되는 것도 가능하므로, 그 컴퓨터 이용가능 또는 컴퓨터 판독 가능 메모리에 저 장된 인스트럭션들은 흐름도 블록(들)에서 설명된 기능을 수행하는 인스트럭션 수단을 내포하는 제조 품목을 생 산하는 것도 가능하다. 컴퓨터 프로그램 인스트럭션들은 컴퓨터 또는 기타 프로그램 가능한 데이터 프로세싱 장 비 상에 탑재되는 것도 가능하므로, 컴퓨터 또는 기타 프로그램 가능한 데이터 프로세싱 장비 상에서 일련의 동 작 단계들이 수행되어 컴퓨터로 실행되는 프로세스를 생성해서 컴퓨터 또는 기타 프로그램 가능한 데이터 프로 세싱 장비를 수행하는 인스트럭션들은 흐름도 블록(들)에서 설명된 기능들을 실행하기 위한 단계들을 제공하는 것도 가능하다. 또한, 각 블록은 특정된 논리적 기능(들)을 실행하기 위한 하나 이상의 실행 가능한 인스트럭션들을 포함하는 모듈, 세그먼트 또는 코드의 일부를 나타낼 수 있다. 또, 몇 가지 대체 실행 예들에서는 블록들에서 언급된 기 능들이 순서를 벗어나서 발생하는 것도 가능함을 주목해야 한다. 예컨대, 잇달아 도시되어 있는 두 개의 블록들 은 사실 실질적으로 동시에 수행되는 것도 가능하고 또는 그 블록들이 때때로 해당하는 기능에 따라 역순으로 수행되는 것도 가능하다. 본 개시에서 사용되는 '~부(unit or part)'라는 용어는 소프트웨어 또는 FPGA(field-Programmable Gate Array) 또는 ASIC(Application Specific Integrated Circuit)과 같은 하드웨어 구성요소를 의미하며, '~부'는 특정한 역할들을 수행하도록 구성될 수 있다. 그렇지만 '~부'는 소프트웨어 또는 하드웨어에 한정되는 의미는 아니다. '~부'는 어드레싱할 수 있는 저장 매체에 있도록 구성될 수도 있고 하나 또는 그 이상의 프로세서들을 실행시키 도록 구성될 수도 있다. 따라서, 일 예로서 '~부'는 소프트웨어 구성요소들, 객체지향 소프트웨어 구성요소들, 클래스 구성요소들 및 태스크 구성요소들과 같은 구성요소들과, 프로세스들, 함수들, 속성들, 프로시저들, 서브 루틴들, 프로그램 코드의 세그먼트들, 드라이버들, 펌웨어, 마이크로코드, 회로, 데이터, 데이터베이스, 데이터 구조들, 테이블들, 어레이들, 및 변수들을 포함한다. 구성요소들과 '~부'들 안에서 제공되는 기능은 더 작은 수 의 구성요소들 및 '~부'들로 결합되거나 추가적인 구성요소들과 '~부'들로 더 분리될 수 있다. 뿐만 아니라, 구 성요소들 및 '~부'들은 디바이스 또는 보안 멀티미디어카드 내의 하나 또는 그 이상의 CPU들을 재생시키도록 구 현될 수도 있다. 또한 실시예에서 '~부'는 하나 이상의 프로세서 및/또는 장치를 포함할 수 있다. 이하, 본 발명의 기술적 사상에 따른 실시 예들을 차례로 상세히 설명한다. 도 1은 본 개시의 일 실시 예에 따른 인공지능 구조의 기본적인 원리를 나타낸 개념도이다. 도 1을 참조하면, 인공지능 구조에서 학습이 수행되는 기본적인 원리를 나타낸다. 인공지능 기술은 학습, 문제 해결, 인식 등과 같이 주로 인간 지능과 연결된 인지 문제를 해결하기 위한 기술을 나타낸다. 인공지능은 Machine learning(ML)이라고 불리는 기계 학습 방식과 Deep learning(DL)이라고 불리는 딥 러닝 방식을 통해 학습될 수 있다. 머신 러닝은 패턴 인식 및 학습에 사용되는 기법에 주로 사용되며 기록된 데이터를 학습하여 이를 기반으로 이후의 데이터를 예측하는 알고리즘을 나타낸다. 사전에 정의된 규칙이나 패 턴을 기반으로 하지 않고 데이터로부터 스스로 학습하는 기술을 나타낸다. 반면에 딥 러닝은 머신 러닝의 한 분 야로 인공 신경망(Artificial Neural Network: ANN)을 기반으로 하여 데이터를 처리하는 차이점이 있다. 딥 러 닝은 인공 신경망을 이용하기 때문에 머신 러닝보다 더욱 복잡하고 정교한 연산을 처리할 수 있다. 딥 러닝을 위한 알고리즘 종류로는 합성곱 신경망(Convolution neural network: CNN), DNN(deep neural network), 인공 신경망(ANN), 순환 신경망(Recurrent Neural Network: RNN)등을 포함할 수 있다. 도 1을 참고하면, 인공지능 구조는 인공지능 모듈로 나타낼 수 있다. 인공지능 모듈은 소정의 입력 데이터를 수신하여 모듈에서 미리 정해진 방식을 통해 학습을 수행하고, 학습 결과에 대한 출력 데이터 를 출력하게 된다. 일 실시예에 따르면, 입력 데이터에는 소정의 데이터(ex 그림, 음성 등), 음성 신 호, 입력 시퀀스를 포함할 수 있다. 출력 데이터에는 출력 시퀀스, 향상된 음성 신호, 음성 인식 정보(예를 들어, 특정한 음성) 등이 포함될 수 있다. 도 2는 본 개시의 일 실시예에 따른 인공지능 네트워크의 구조를 나타낸 도면이다. 도 2에서 사용되는 인공지능 알고리즘은 도 1의 인공지능 모듈의 종류 중 하나일 수 있다. 도 2를 참조하면, 인공지능 시스템의 구조는 음성 데이터와 인공지능 알고리즘 구조를 포함할 수 있다. 일 실시예에 따르면, 인공지능 알고리즘 구조는 데이터 전처리, 인공지능 학습, 출력 데이터 확인으로 단계가 나눠어질 수 있다. 본 개시에서의 데이터 전처리에서는 데이터 증강(augment)기법이 적용할 수 있다. 데이터 증 강 기법은 기존의 입력 데이터를 다양하게 변환하여 학습을 다채롭게 수행하는 방법을 나타낸다. 종래에는 데이 터 증강 기법으로 노이즈 신호와 클린 피쳐 시퀀스(clean feature sequence)(X)를 활용하여 노이즈 피쳐 시퀀스 (noisy feature sequence)( )를 생성하였다. 이때, 노이즈 피쳐 시퀀스에 대응되는 라벨링 정보로는 클린 피쳐 시퀀스를 통해 force-alignment 기법을 통하여 획득한 타겟 시퀀스(target sequence)(Y)를 동일하게 적용할 수 있다. 도 2의 (a)를 참조하면, 생성된 노이즈 피쳐 시퀀스( )를 입력 데이터로 사용할 수 있다. 노이즈 피쳐 시퀀스는 노이즈 데이터 셋을 포함할 수 있다. 입력된 노이즈 데이터 셋은 음향 모델(acoustic model)로 입력될 수 있다. 음향 모델은 음성 인식 시스템에서 음성 신호를 변환하여 음소 단위 간의 관계를 나타내 기 위하여 사용되는 모델로 음향 신호에서 특정 음소 또는 단어를 식별하는 방법을 학습할 수 있다. 음향 모델 은 \"bottom(바텀)\" 및 \"senone(세논)\"을 포함할 수 있다. \"bottom\"은 입력 데이터의 가장 낮은 수준을 나 타내는 것으로 즉, 음향 신호나 음향 피쳐(특징)을 나타낼 수 있다. 이러한 특징은 주파수 영역에서 추출되는 것이 일반적이며 멜-스펙트로그램과 같은 형태로 표현될 수 있다. \"senone\"은 음향 모델링에서 사용되는 음향 모델의 구성요소일 수 있다. \"senone\"은 음향 모델이 음성의 특정 부분을 인식할 때, 그 부분이 어떤 음소의 일 부인지를 나타내는 단위일 수 있다. 입력된 노이즈 데이터 셋은 \"bottom\"에서 음향 특징이 추출되고 \"senone\"을 통해 음소나 단어로 변환될 수 있다. 종래에는 입력 데이터에 노이즈 조건(noise condition)은 고려 되지 않거나 별도의 테스크(task)로 분리되어 학습되었다. 다만 본 개시에 따른 인공지능 알고리즘에서는 노이 즈 조건을 효율적으로 활용하기 위하여 노이즈 레이블(또는 조건)의 개수를 고려해 출력 차원을 N+1배로 확장하 는 방식을 적용하였다. 이하에서 이러한 방식을 noise-aware target extension(NATE) 방식이라고 한다. 음향 모델에서 출력된 임베딩은 클린 조건 출력 임베딩(230a)에 추가로 노이즈 레이블 개수(N)를 고려하여 N+1배로 증가된 출력 노이즈 임베딩(230b, 230c, 230d)을 나타낼 수 있다. 예를 들어, 도 2에서는 노이즈 조건 개수(N)를 3으로 정하여 나타낸 것일 수 있다. 동일한 피쳐 스페이스에서 클린 조건 임베딩(230a) 및 노이즈 조 건에 따른 출력 임베딩(230b, 230c, 230d)에 대하여 softmax 연산(또는 softmax 연산 및 로그 연산)(240a)을 수행할 수 있다. Softmax 연산(240a)을 수행하면 출력으로 noise-wise extended senone posterior(240b)(이하, 노이즈 관련 확장 세논)을 추출할 수 있다. 노이즈 관련 확장 세논은 클린 조건 및 각각의 노이즈 조건에 따라 생성될 수 있다. 즉 N+1개의 노이즈 관련 확장 세논이 추출될 수 있다. 예를 들어, 도 2의 경우 총 4개의 노이 즈 관련 확장 세논이 추출될 수 있다. 또한 타겟 시퀀스(Y)를 한 t-프레임의 타겟 의 출력 차원이 앞서 데이터 증강에 사용된 노이즈 레이블 개수(N)를 고려하여 확장할 수 있다. 즉, 한 t-프레임의 타겟이 로 확장될 수 있다. 확장된 타겟 시퀀스는 노이즈-인식 확장 타겟(noise-aware extended target)(240c)(Yt)으로 나타낼 수 있다. 노이즈-인식 확 장 타겟은 다음 수학식과 같이 나타낼 수 있다. [수학식 1]"}
{"patent_id": "10-2023-0072322", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "추출된 노이즈 관련 확장 세논과 노이즈-인식 확장 타겟을 기반으로 손실(loss)를 계산할 수 있다. 이렇게 획득 된 손실을 NATE 손실( )로 나타내고, 240a 내지 240c의 연산과정을 NATE 손실( ) 연산 프로세스 라고 할 수 있다. 도 2의 (a)에서는 학습을 위하여 NATE 손실을 획득하기 위한 절차를 나타내며, 도 2의 (b)는 디코딩을 통해 최 종 출력 senone posterior를 획득하는 절차를 나타낼 수 있다. 도 2의 (b)를 참조하면, 입력 노이즈 데이터 셋으로부터 확장된 임베딩을 추출하는 과정까지 동일하 게 진행될 수 있다. 도 2의 (b)에서는 추출된 임베딩 각각에 대하여 softmax 연산을 수행할 수 있다. Softmax 연산을 통해 노이즈 관련 확장 세논 각각을 출력하고 출력된 세논들을 모두 summation 연산 을 통해 합쳐서 최종 출력 세논을 도출할 수 있다. 다른 실시예에 따르면, 임베딩 각각에 대하여 summation 연산을 수행하여 획득된 최종 임베딩에 softmax 연산을 수행하여 최종 출력 세논을 도출할 수도 있다. 상기와 같은 NATE 방식에서 노이즈 라벨 개수만큼 출력을 확장시키는 과정을 통해 출력 차원이 증가하면 모델의 파라미터도 증가할 수 있다. 파라미터의 증가에 따라 연산 및이 복잡해지고 저장 공간이 커지는 등의 영향이 미 치기 때문에 이를 해결하기 위한 방안이 필요할 수 있다. 도 3은 본 개시의 일 실시예에 따른 자가 증류 기법이 적용된 인공지능 네트워크의 구조를 나타낸 도면이다. 도 3에서 사용되는 인공지능 알고리즘은 도 1의 인공지능 모듈의 종류 중 하나일 수 있다. 일 실시예 에 따르면, 도 3의 노이즈 데이터 셋은 도 2의 노이즈 데이터 셋과 동일한 것일 수 있다. 도 3의 인 공지능 알고리즘에는 도 2의 NATE 방식이 적용될 수 있다. 도 3의 인공지능 알고리즘에는 자가 증류 기법(self-distillation)이 적용될 수 있다. 자가 증류 기법이란 지식 증류 기법을 이용한 것으로 크기가 큰 모델(즉, 교사 모델)이 생성한 학습 결과를 이용하여 상대적으로 크 기가 작은 모델(즉, 학생 모델)을 학습시키는 것이다. 이를 응용한 것으로, 자가 증류 기법에서는 원래의 모델 의 큰 부분(즉, 교사 모델)이 생성한 부드러운(soft) 레이블을 사용하여 동일한 모델의 작은 부분을 다시 훈련 하는 방식을 나타낼 수 있다. 부드러운 레이블은 딱딱한(hard) 레이블보다 더욱 많은 정보를 제공하며 이러한 정보를 사용하여 모델은 자신의 예측에 대한 확신을 키울 수 있다. 도 3의 인공지능 방식은 도 2에서의 NATE 방식의 인공지능 알고리즘에 자가 증류 기법을 도입한 NATESD 방식이라 고 할 수 있다. 도 3을 참조하면, 생성된 노이즈 피쳐 시퀀스( )를 입력 데이터로 사용할 수 있다. 노이즈 피쳐 시퀀스는 노이 즈 데이터 셋을 포함할 수 있다. 노이즈 데이터 셋은 인공지능 학습 중에 NATE 손실을 계산하기 위한 교사 음향 모델((M+1)th)와 학생 음향 모델(M th)으로 구성된 모델에 입력될 수 있다. 여기서 M은 layer(계층)의 수를 나타내고, M-layer로 구성된 NATE 방식 인공지능 모델(즉, 학생 모델)에서 1개의 층을 더 쌓아 (M+1)-layer로 구성된 모델(즉, 교사 모델)을 생성할 수 있다. 교사 모델에서는 도 2의 NATE 방식 모델과 같이 확장된 타겟 (Yt)을 통해 학습을 진행한다. 입력된 노이즈 데이터 셋에 대하여 확장된 출력에 대응되도록 M+1개의 임베딩을 추출할 수 있다. 추출된 임베딩은 도 2의 (a)에서와 동일한 방식을 통해 NATE 손실 연산 프로세스(도 2의 NATE 손실 연산 프로세스)를 수행하여 NATE 손실( )을 도출할 수 있다. 교사 모델에서는 도출한 NATE 손실을 이용하여 학습을 수행할 수 있다. NATE 손실 연산 프로세스와는 별도로 획득된 M+1개의 임베딩에 대하여 summation 연산을 수행하여 결합된 임베딩을 도출할 수 있다. 결합된 임베 딩에 softmax 연산을 수행하여 확장된 세논( )을 도출할 수 있으며, 확장된 세논은 학생 모델의 타겟으로 할당될 수 있다. 학생 모델은 종래의 방식과 유사한 방식으로 입력된 노이즈 데이터 셋에 대하여 학생 음향 모델을 통해 임베딩을 추출할 수 있다. 추출된 임베딩에 softmax 연산 (또는, softmax 및 로그 연산)을 수행하여 세논( )을 도출할 수 있다. 학생 모델에서는 교사 모델에서 도출한 확장된 세논과 직접 도출한 세논을 기반으로 손실을 획득하여 학습을 수행할 수 있다. 여기서획득하는 손실은 자가 증류 손실( )이라고 명명할 수 있다. 자가 증류 손실은 다음의 수학식으로 획득될 수 있다. [수학식 2]"}
{"patent_id": "10-2023-0072322", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "여기서, KL(Kullback-leibler)-divergence 방식이 사용될 수 있다. KL-divergence은 확률 분포 간의 차이를 측 정하는 방식으로 지식 증류에서 학생 모델이 교사 모델로부터 지식을 잘 받아들였는지 평가하는데 사용될 수 있 다. 즉, 교사 모델에서는 NATE 손실을 통해 학습이 수행되며 학생 모델에서는 자가 증류 손실을 통해 학 습이 수행될 수 있다. 학생 모델에서 획득된 세논은 음성인식을 위해 필요한 값이므로 디코딩 시 교사 모 델의 연산을 사용하지 않지만 교사 모델에서 차원을 확장해 도출한 세논만을 이용하기 때문에 연산량 및 디코딩 속도에 영향을 주지 않고 결과를 획득할 수 있다. 즉, 학습이 종료된 이후 교사 모델에 대한 연산은 수행되지 않는다. 결론적으로 학생 모델을 통해 획득되는 출력은 기존의 음성 인식 시스템과 같이 출력 차원( )을 가지 기 때문에 음성 인식 시스템에서의 파라미터는 동일하게 되어 latency가 발생하지 않을 수 있다. 도 4a 내지 도 4c는 종래의 모델과 본 개시의 일 실시예에 따른 인공지능 모델을 활용한 출력 결과를 t-sne 기 법을 통해 나타낸 것이다. 도 4a는 일반적인 데이터 증강 기법을 사용한 결과이고, 도 4b는 NATE 모델로 학습하되 summation을 수행한 후 를 나타내고, 도 4c는 NATE 모델로 학습하여 summation을 수행하지 않은 경우의 인코더 출력을 나타낸 결과일 수 있다. 도 4a 내지 도 4c에서는 164번째 및 206번째 프레임에서 클린 조건, 노이즈 조건, 음악 조건, 바블(babble) 조 건에 따른 노이즈 라벨의 군집화를 나타낸 것이다. 도 4a와 도 4b를 비교하면 도 4a의 결과(400a)에서는 프레임 차수에 따른 군집화가 두드러지는 반면 도 4b의 결 과(400b)에서는 프레임 차수 및 서로 다른 타겟 간의 군집이 두드러지는 것을 확인할 수 있었다. 따라서, NATE 모델을 활용하여 학습한 경우 프레임에 따른 타겟의 군집이 더 잘 되는 것을 확인할 수 있다. 도 4c를 참조하면, summation연산을 수행하지 않은 도 4c의 결과(400c)에서 노이즈 라벨의 종류에 따른 군집화 성능을 나타낼 수 있다. 도 5는 본 개시의 일 실시예에 따른 인공지능 알고리즘 모델과 종래의 인공지능 모델에 대한 음성 인식 성능을 나타낸 도표이다. 도 5에서 사용된 데이터 셋은 공용 데이터인 월스트릿 저널(wall street journal, WSJ)을 사용한 것이다. 평가 데이터 셋으로는 WSJ중 development set, evaluation set, noisy test set을 사용하였다. Development set에는 dev93을 사용하였으며, evaluation set에는 eval92 및 eval93을 사용하였으며, noisy test set은 인공지능 학습 시 사용하지 않은 노이즈를 사용하여 생성하였으며 dev93, eval92, eval93을 모두 사용하였다. 측정된 결과는 WER(Word Error rate)로 비율이 낮을수록 성능이 좋은 것으로 해석될 수 있다. 도 5에서 사용된 인공지능 알고리즘으로 종래에 주로 사용되는 노이즈 추가 방식을 적용한 baseline 모델, 노이즈에 대하여 추가적인 task로 학습을 수행하는 MTL(multi-task learning) 모델, AMTL(Adversarial Multi-task learning) 모델, 본 개시에서 제안하는 모델 중 증강 배수가 2배수인 NATE 모델, 증강배 수가 4배수인 NATE 모델, 자가 증류 기법까지 적용된 2배수 NATEsd 모델, 4배수 NATEsd 모델이 사용되었다. 도 5를 참조하면, development set에서는 4배 증강을 수행한 NATE 모델들(525, 535)이 가장 성능이 뛰어 나며 특히 4배수 NATEsd 모델이 가장 좋은 성능을 나타내었다. Evaluation set에서는 NATE 모델들(520, 525, 530, 535)이 전반적으로 좋은 성능을 나타내었으며, 마찬가지로 4배수 NATEsd 모델이 가장 좋 은 성능을 나타내었다. Noisy test set에서는 4배수 증강 NATE 모델 및 NATEsd 모델에서 높은 성능을 보임을 확인할 수 있었다. 다양한 평가 방식에 상관없이 제안하는 NATE 방식이 적용된 모델들에서 기존의 알고리즘 모델들보다 성능이 향 상되었음을 확인할 수 있다. 도 6은 본 개시의 일 실시예에 따른 인공지능 알고리즘 모델과 종래의 인공지능 모델에 대한 노이즈 조건 분류 성능에 대한 실험 결과 표를 나타낸 것이다. 도 6에서 사용된 데이터 셋은 공용 데이터인 월스트릿 저널(wall street journal, WSJ)을 사용한 것이다. 평가 데이터 셋으로는 WSJ중 development set, evaluation set을 기반으로 생성된 noisy test set을 사용하였 다. noisy test set은 인공지능 학습 시 사용하지 않은 노이즈를 사용하여 생성하였으며 dev93, eval92, eval93을 사용하였다. 측정된 결과는 noise condition classification accuracy로 비율이 높을수록 성능이 좋 은 것으로 해석될 수 있다. 도 6에서 사용된 인공지능 알고리즘으로 노이즈에 대하여 추가적인 task로 학습을 수행하는 MTL(multi-task learning) 모델에 대하여 가중치(여기선 MTL coefficient)(α)를 각각 0.3, 0.5, 0.7로 설정한 모델들(605, 610, 615)과 본 개시에서 제안하는 모델들 중 증강 배수가 4배수인 NATE 모델, 4배수 NATEsd 모델이 사용되었다. 도 6를 참조하면, MTL 모델들에 대하여는 가중치가 높은 MTL(0.7) 모델의 성능이 가장 좋게 나타나는 것을 확인할 수 있으며, 전체적으로는 4배수 증강한 NATE 모델에서 성능이 가장 좋게 나타났다. 자가 증류 기법 이 사용된 NATE 모델은 연산 로드를 줄이기 위하여 규모를 작게 하여 노이즈 조건 분류 정확도는 상대적으 로 떨어지는 것으로 확인된다. 본 개시의 도 5 및 도 6의 실험에서는 baseline 모델에는 12 transformer encoder layer로 구성된 음향 모델이 사용될 수 있다. MTL과 AMTL에서는 2 transformer encoder layer를 사용하여 노이즈 분류를 수행할 수 있다. NATE 모델에서는 12 transformer encoder layer 사용하되 노이즈 조건(라벨)의 종류를 고려하여 출력단을 확장 하였다. NATEsd 모델에서는 1 transformer encoder layer를 추가하여 총 13-latyer transformer을 교사 모델로 사용하고 12 transformer encoder layer를 학생 모델로 사용하였다. 일 실시예에 따르면, 본 개시의 음성 인식 시스템은 파이썬을 기반으로 한 딥러닝 툴킷인 파이토치(Pytorch)를 기반으로 구현할 수 있다. 딥러닝 기반의 음성인식 시스템의 학습을 위하여 음성인식 소스코드인 Kaldi의 forge-alignment를 사용하여 데이터의 타겟을 추출할 수 있다. 노이즈 데이터 셋의 경우 공용 데이터 셋인 MUSAN 데이터셋을 활용할 수 있다. 본 개시의 NATE 방식 및 자가 증류 기법을 적용한 인공지능 알고리즘 모델의 경우 파라미터의 증가 없이 종래의 데이터 증강 기법을 활용한 인공지능 알고리즘 대비 9~10% 이상의 성능 개선을 확인할 수 있었다. 도 7은 본 개시의 일 실시예에 따른, 음성 인식을 위한 전자 장치에 대한 블록 구성도이다. 도 7을 참조하면, 전자 장치는 모뎀(MODEM, 720), 메모리(MEMORY, 740) 및 프로세서(PROCESSOR, 730)를 포함할 수 있다. 모뎀은 다른 전자 장치들과 전기적으로 연결되어 상호 통신이 이뤄지도록 하는 통신 모뎀일 수 있다. 특히 모뎀은 데이터 입력을 수신하여 프로세서로 전송할 수 있고, 프로세서는 입력된 데이터 값을 메 모리에 저장할 수 있다. 또한, 시스템에서 학습된 인공지능 알고리즘에 의해 출력된 데이터 값 또는 정보 를 다른 전자 장치로 전송할 수 있다. 메모리는 전자 장치의 동작을 위한 각종 정보 및 프로그램 명령어들이 저장되는 구성으로서, 하드 디 스크(Hard Disk), SSD(Solid State Drive) 등과 같은 기억장치일 수 있다. 특히, 메모리는 프로세서(73 0)의 제어에 의해 모뎀에서 입력되는 하나 이상의 데이터 입력 값을 저장할 수 있다. 또한, 메모리는 프로세서에 의해 실행 가능한 음성 인식을 위한 인공지능 알고리즘과 같은 프로그램 명령어들을 저장할 수있다. 또한, 메모리는 본 개시에서 설명한 NATE 방식 또는/및 자가 증류 방식을 통해 학습된 인공지능 알 고리즘과 같은 프로그램 (또는 프로그램 명령어)를 저장할 수 있다. 프로세서는 적어도 하나의 프로세서로 구성되며, 메모리에 저장된 데이터 및 프로그램 명령어들을 이 용하여 음성 인식과 관련된 인공지능 알고리즘을 학습하고 이를 활용하여 데이터를 계산할 수 있다. 프로세서 는 도 1 내지 도 6에서 설명한 모든 인공지능 알고리즘을 제어하고 계산할 수 있다. 프로세서는 이후 도 8에서 설명하는 방법에 대한 동작을 수행할 수 있다. 도 8은 본 개시의 일 실시예에 따른 음성 인식 방법을 설명하기 위한 순서도이다. 이하 도 8을 참조하여, 도 1 내지 도 7을 참조하여 설명한 전자 장치의 인공지능 알고리즘의 학습 동작 및 음성 인식 방법에 대해 정리하여 설명한다. 각 동작들은 일련의 과정에서 필수적으로 포함되어야 하는 동작들은 아니 며 상황에 따라 일부만이 구성되어 동작할 수 있다. 단계 S810에서, 인공지능을 통한 음성 인식을 수행하기 위하여 음성 데이터를 수신할 수 있다. 상기 음성 데이 터는 입력 정보로 활용되어 인공지능을 학습시키는데 사용될 수 있다. 상기 음성 데이터는 노이즈가 포함된 노 이즈 피쳐 시퀀스 일 수 있다. 상기 노이즈 피쳐 시퀀스는 노이즈 데이터 셋을 포함할 수 있다. 단계 S820에서, 기 학습된 제1 인공지능 네트워크 모델을 통해 상기 음성 데이터를 입력 자료로 하여 제1 세논 (senone)을 출력할 수 있다. 상기 기 학습된 제1 인공지능 네트워크 모델은 음성 인식 시스템 또는 음성 인식을 위한 전자 장치에 포함될 수 있다. 상기 세논은 세논 포스테리어(senone posterior)를 나타낼 수 있다. 노이즈 가 포함된 음성 데이터 셋(예를 들어, 도 2의 데이터 셋)을 수신하고, 제1 음향 모델(acoustic model)(예 를 들어, 도 2의 음향 모델 또는 도 3의 교사 음향 모델)에서 상기 노이즈가 포함된 음성 데이터 셋 을 기반으로 차원 확장된 제1 임베딩(예를 들어 도 2의 확장된 임베딩)을 생성하고, 상기 차원 확장된 제1 임베딩을 기반으로 상기 차원 확장된 제2 세논(예를 들어, 도 2의 확장된 세논(240b) 또는 확장된 세논)을 출력하고, 차원 확장된 제1 타겟과 상기 차원 확장된 제2 세논을 기반으로 사전 학습될 수 있다. 상기 기 학습 된 제1 인공지능 네트워크 모델은 상기 차원 확장된 제2 세논(예를 들어, 도 2의 노이즈 관련 확장 세논(240 b))과 상기 차원 확장된 제1 타겟(예를 들어, 도 2의 노이즈-인식 확장 타겟(240c))을 기반으로 제1 손실(예를 들어, 도 2의 NATE 손실)을 결정할 수 있다. 상기 차원 확장된 제1 임베딩(예를 들어, 도 2의 출력 임베딩 ) 및 상기 차원 확장된 제1 타겟은 노이즈 레이블의 개수를 기반으로 차원이 확장될 수 있다. 상기 기 학 습된 제1 인공지능 네트워크 모델은 상기 차원 확장된 제1 임베딩을 결합하여 제2 임베딩(예를 들어, 도 3의 결 합된 임베딩)을 생성하고, 상기 제2 임베딩을 기반으로 차원 확장된 제3 세논(예를 들어, 도 3의 확장된 세논)을 출력하고, 상기 차원 확장된 제3 세논을 제2 인공지능 네트워크 모델에 제2 타겟으로 할당하고, 그리고 상기 제2 인공지능 네트워크 모델 상기 노이즈가 포함된 음성 데이터 셋을 수신하고, 제2 음향 모델(예 를 들어, 도 3의 학생 음향 모델)에서 상기 노이즈가 포함된 음성 데이터 셋(예를 들어, 도 3의 데이터 셋 )을 기반으로 제3 임베딩(예를 들어, 도 3의 임베딩)을 생성하고, 상기 제3 임베딩을 기반으로 제4 세논(예를 들어, 도 3의 세논)을 출력하고, 상기 기 학습된 제1 인공지능 네트워크 모델로부터 할당된 제2 타겟 및 상기 제4 세논을 기반으로 제2 손실을 결정하고 상기 제2 손실(예를 들어, 도 3의 자가 증류 손실 )을 기반으로 학습될 수 있다. 상기 제2 인공지능 네트워크 모델은 음성 인식 시스템 또는 음성 인식을 위 한 전자 장치에 포함될 수 있다. 상기 제1 인공지능 네트워크 모델과 상기 제2 인공지능 네트워크 모델은 하나 의 인공지능 네트워크 모델에 포함될 수 있다. 상기 제1 음향 모델은 상기 제2 음향 모델보다 레이어의 수가 하 나 더 많도록 구성될 수 있다. 상기 학습된 제2 인공지능 네트워크 모델을 통해 상기 음성 데이터를 입력 자료 로 하여 제5 세논(예를 들어, 도 2의 최종 출력 세논)을 출력하는 단계를 더 포함할 수 있다. 상기 제2 인 공지능 네트워크 모델은 상기 기 학습된 제1 인공지능 네트워크 모델로부터 자가 증류(self-distillation) 프로 세스를 통하여 학습되고, 상기 제2 인공지능 네트워크 모델은 학생(student) 네트워크이고, 및 상기 기 학습된 제1 인공지능 네트워크 모델은 교사(teacher) 네트워크일 수 있다. 이상, 본 발명의 기술적 사상을 다양한 실시 예들을 들어 상세하게 설명하였으나, 본 발명의 기술적 사상은 상 기 실시 예들에 한정되지 않고, 본 발명의 기술적 사상의 범위 내에서 당 분야에서 통상의 지식을 가진 자에 의 하여 여러가지 변형 및 변경이 가능하다.부호의 설명 110: 인공지능 모듈 710: 전자 장치 720: 모뎀 730: 프로세서 740: 메모리"}
{"patent_id": "10-2023-0072322", "section": "도면", "subsection": "도면설명", "item": 1, "content": "본 발명의 상세한 설명에서 인용되는 도면을 보다 충분히 이해하기 위하여 각 도면의 간단한 설명이 제공된다. 도 1은 본 개시의 일 실시 예에 따른 인공지능 구조의 기본적인 원리를 나타낸 개념도이다. 도 2는 본 개시의 일 실시예에 따른 인공지능 네트워크의 구조를 나타낸 도면이다. 도 3은 본 개시의 일 실시예에 따른 자가 증류 기법이 적용된 인공지능 네트워크의 구조를 나타낸 도면이다.도 4a 내지 도 4c는 종래의 모델과 본 개시의 일 실시예에 따른 인공지능 모델을 활용한 출력 결과를 t-sne 기 법을 통해 나타낸 것이다. 도 5는 본 개시의 일 실시예에 따른 인공지능 알고리즘 모델과 종래의 인공지능 모델에 대한 음성 인식 성능을 나타낸 도표이다. 도 6은 본 개시의 일 실시예에 따른 인공지능 알고리즘 모델과 종래의 인공지능 모델에 대한 노이즈 조건 분류 성능에 대한 실험 결과 표를 나타낸 것이다. 도 7은 본 개시의 일 실시예에 따른, 음성 인식을 위한 전자 장치에 대한 블록 구성도이다. 도 8은 본 발명의 일 실시예에 따른 음성 인식 방법을 설명하기 위한 순서도이다."}
