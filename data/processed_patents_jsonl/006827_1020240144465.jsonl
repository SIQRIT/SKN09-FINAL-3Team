{"patent_id": "10-2024-0144465", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0159865", "출원번호": "10-2024-0144465", "발명의 명칭": "의도적으로 미숙하게 트레이닝된 인공 지능 모델을 포함하는 복수 개의 인공 지능 모델을 이", "출원인": "염중배", "발명자": "염중배"}}
{"patent_id": "10-2024-0144465", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "적어도 하나의 프로그램 명령어를 저장하는 컴퓨터로 독출가능한 저장 매체에 있어서,상기 적어도 하나의 프로그램 명령어는, 실행 시에, 적어도 하나의 프로세서가:각각이 복수 개의 파라미터 타입들 각각에 대응하는 복수 개의 값들을 포함하는 환경 정보를 획득하고,상기 복수 개의 값들에 기반하여, 복수 개의 인공 지능 모델들 각각에 대응하는 복수 개의 부분 집합들 각각을확인하고-상기 복수 개의 부분 집합들 각각은, 상기 복수 개의 값들 중 적어도 하나 이상을 원소로서 포함함-,상기 복수 개의 부분 집합들 각각을, 상기 복수 개의 인공 지능 모델들 각각에 입력하고,상기 복수 개의 인공 지능 모델들 각각으로부터 출력되는 복수 개의 출력값들 각각을 확인하고, 및상기 복수 개의 출력값들에 대한 가중치 합을 최종 값으로서 확인하도록 야기하는 저장 매체."}
{"patent_id": "10-2024-0144465", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1 항에 있어서,상기 복수 개의 인공 지능 모델들 중 적어도 두 개는, 상이한 인공 신경망 구조를 가지는 저장 매체."}
{"patent_id": "10-2024-0144465", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 2 항에 있어서,상기 복수 개의 인공 지능 모델들 중 상기 적어도 두 개 각각은, 트레이닝 데이터의 적어도 일부인 제 1 서브트레이닝 데이터 및 상기 트레이닝 데이터의 적어도 일부인 제 2 서브 트레이닝 데이터를 이용한 트레이닝들 각각에 따라 획득되는 저장 매체."}
{"patent_id": "10-2024-0144465", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 1 항에 있어서,상기 복수 개의 인공 지능 모델들 중 적어도 두 개는 동일한 인공 신경망 구조를 가지고, 상기 인공 신경망 구조를 구성하는 파라미터들 중 적어도 일부는 상이한 저장 매체."}
{"patent_id": "10-2024-0144465", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제 4 항에 있어서,상기 복수 개의 인공 지능 모델들 중 상기 적어도 두 개 각각은, 트레이닝 데이터 중 적어도 하나의 제 1 파라미터 타입에 대응하는 트레이닝 데이터의 적어도 일부인 제 3 서브 트레이닝 데이터 및 상기 트레이닝 데이터중 상기 적어도 하나의 제 1 파라미터 타입에 대응하는 트레이닝 데이터의 적어도 일부인 제 4 서브 트레이닝데이터를 이용한 트레이닝들 각각에 따라 획득되고,상기 제 3 서브 트레이닝 데이터는, 상기 제 4 서브 트레이닝 데이터와 적어도 일부 상이한 저장 매체."}
{"patent_id": "10-2024-0144465", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제 1 항에 있어서,상기 복수 개의 인공 지능 모델들 중 적어도 두 개는 상이한 부분 집합들 각각을 입력으로서 수신하는 저장 매체."}
{"patent_id": "10-2024-0144465", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "공개특허 10-2024-0159865-2-제 6 항에 있어서,상기 복수 개의 인공 지능 모델들 중 상기 적어도 두 개 각각은, 트레이닝 데이터 중 적어도 하나의 제 3 파라미터 타입에 대응하는 트레이닝 데이터의 적어도 일부인 제 5 서브 트레이닝 데이터 및 상기 트레이닝 데이터중 상기 적어도 하나의 제 3 파라미터 타입과 적어도 일부 상이한 적어도 하나의 제 4 파라미터 타입에 대응하는 트레이닝 데이터의 적어도 일부인 제 6 서브 트레이닝 데이터를 이용한 트레이닝들 각각에 따라 획득되는 저장 매체."}
{"patent_id": "10-2024-0144465", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제 1 항에 있어서,상기 적어도 하나의 프로그램 명령어는, 실행 시에, 상기 적어도 하나의 프로세서가,상기 복수 개의 출력값들 각각과 상기 복수 개의 출력값들 각각에 대응하는 복수 개의 구성 가중치들 각각을 곱하는 제 1 연산을 수행하고,상기 연산의 수행 결과들을 더하는 제 2 연산을 더 수행하도록 야기하는 저장 매체."}
{"patent_id": "10-2024-0144465", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제 8 항에 있어서,상기 복수 개의 구성 가중치들 각각은, 상기 복수 개의 인공 지능 모델들에 대응하는 집단에서, 상기 복수 개의인공 지능 모델들 각각이 차지하는 비율과 연관되는 저장 매체."}
{"patent_id": "10-2024-0144465", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "적어도 하나의 프로그램 명령어를 저장하는 컴퓨터로 독출가능한 저장 매체에 있어서,상기 적어도 하나의 프로그램 명령어는, 실행 시에, 적어도 하나의 프로세서가:복수 개의 파라미터 타입들과 연관된 복수 개의 데이터들을 포함하는 트레이닝 데이터를 획득하고,상기 트레이닝 데이터의 적어도 일부인 제 1 서브 트레이닝 데이터를 이용하여 제 1 트레이닝을 수행함으로써,제 1 인공 지능 모델을 생성하고,상기 트레이닝 데이터의 적어도 일부인 제 2 서브 트레이닝 데이터를 이용하여 제 2 트레이닝을 수행함으로써,제 2 인공 지능 모델을 생성하고,상기 제 1 서브 트레이닝 데이터의 일부는, 상기 제 2 서브 트레이닝 데이터의 적어도 일부와 동일하고,상기 제 1 인공 지능 모델의 제 1 인공 신경망 구조는, 상기 제 2 인공 지능 모델의 제 2 인공 신경망 구조와동일하고,상기 제 1 인공 신경망 구조를 구성하는 파라미터들은, 상기 제 2 인공 신경망 구조를 구성하는 파라미터들과적어도 일부 상이한 저장 매체."}
{"patent_id": "10-2024-0144465", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "적어도 하나의 프로그램 명령어를 저장하는 컴퓨터로 독출가능한 저장 매체에 있어서,상기 적어도 하나의 프로그램 명령어는, 실행 시에, 적어도 하나의 프로세서가:복수 개의 파라미터 타입들과 연관된 복수 개의 데이터들을 포함하는 트레이닝 데이터를 획득하고,상기 트레이닝 데이터의 적어도 일부인 제 1 서브 트레이닝 데이터를 이용하여 제 1 트레이닝을 수행함으로써,제 1 인공 지능 모델을 생성하고,상기 트레이닝 데이터의 적어도 일부인 제 2 서브 트레이닝 데이터를 이용하여 제 2 트레이닝을 수행함으로써,제 2 인공 지능 모델을 생성하고,상기 복수 개의 파라미터 타입들 중 상기 제 1 서브 트레이닝 데이터에 대응하는 적어도 하나의 제 1 파라미터타입은, 상기 복수 개의 파라미터 타입들 중 상기 제 2 서브 트레이닝 데이터에 대응하는 적어도 하나의 제 2공개특허 10-2024-0159865-3-파라미터 타입과 적어도 일부 상이한 저장 매체."}
{"patent_id": "10-2024-0144465", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "적어도 하나의 프로그램 명령어를 저장하는 컴퓨터로 독출가능한 저장 매체에 있어서,상기 적어도 하나의 프로그램 명령어는, 실행 시에, 적어도 하나의 프로세서가:복수 개의 트레이닝 데이터들을 획득하고-상기 복수 개의 트레이닝 데이터들 각각은, 복수 개의 인공 지능 모델들 각각에 대응하는 구성 가중치들, 상기 복수 개의 인공 지능 모델들 각각으로부터의 출력값들 및 상기 구성가중치들의 가중치 합과, 실제 값을 포함하고,상기 가중치 합 및 상기 실제 값에 기반하여, 상기 복수 개의 인공 지능 모델들 각각에 대응하는 구성 가중치들중 적어도 일부를 결정하도록 야기하는 저장 매체."}
{"patent_id": "10-2024-0144465", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "적어도 하나의 프로그램 명령어를 저장하는 컴퓨터로 독출가능한 저장 매체에 있어서,상기 적어도 하나의 프로그램 명령어는, 실행 시에, 적어도 하나의 프로세서가:각각이 복수 개의 파라미터 타입들 각각에 대응하는 복수 개의 값들을 포함하는 환경 정보를 입력 레이어에 제공하고-상기 입력 레이어는, 복수 개의 서브 인공 지능 모델들 각각에 대응하는 복수 개의 부분 집합들 각각을상기 복수 개의 서브 인공 지능 모델들 각각으로 전달하도록 설정되고, 상기 복수 개의 부분 집합들 각각은, 상기 복수 개의 값들 중 적어도 하나 이상을 원소로서 포함함-,상기 복수 개의 서브 인공 지능 모델들 각각에 의한 상기 복수 개의 부분 집합들 각각의 처리 결과인 복수 개의출력값들을 완전히 연결된 레이어에 제공하고-상기 완전히 연결된 레이어는, 상기 복수 개의 출력값들에 대한가중치 합을 최종 값으로서 제공하도록 설정됨-,상기 완전히 연결된 레이어로부터 제공되는 상기 최종 값을 출력 레이어를 통하여 제공하도록 야기하는 저장 매체."}
{"patent_id": "10-2024-0144465", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "다양한 실시예에 따라서, 적어도 하나의 프로그램 명령어를 저장하는 컴퓨터로 독출가능한 저장 매체가 제공되며, 상기 적어도 하나의 프로그램 명령어는, 실행 시에, 적어도 하나의 프로세서가, 각각이 복수 개의 파 라미터 타입들 각각에 대응하는 복수 개의 값들을 포함하는 환경 정보를 획득하고, 상기 복수 개의 값들에 기반 하여, 복수 개의 인공 지능 모델들 각각에 대응하는 복수 개의 부분 집합들 각각을 확인하고, 상기 복수 개의 부 분 집합들 각각을, 상기 복수 개의 인공 지능 모델들 각각에 입력하고, 상기 복수 개의 인공 지능 모델들 각각으 로부터 출력되는 복수 개의 출력값들 각각을 확인하고, 및 상기 복수 개의 출력값들에 대한 가중치 합을 최종 값 으로서 확인하도록 야기할 수 있다."}
{"patent_id": "10-2024-0144465", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "다양한 실시예는 복수 개의 인공 지능 모델을 이용한 집단 결정을 수행하는 전자 장치 및 그 동작 방법 에 관한 것이다."}
{"patent_id": "10-2024-0144465", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "신경망(artificial neural network) 구조를 가지는 인공 지능 모델에 대한 연구가 활발하게 진행 중이다. 인 공 신경망 구조는, 인간의 뉴런 구조를 모사한 구조로서, 각각이 적어도 하나의 노드를 가지는 적어도 하나의 레이어(layer)를 포함할 수 있다. 인공 지능 모델은, 트레이닝(또는, 학습)을 통하여 결정된 인공 신경망 구조 의 파라미터(예를 들어, 바이어스(bias) 및/또는 가중치(weight))를 포함할 수 있다. 보다 많은 트레이닝 데이 터(또는, 트레이닝 데이터)에 기반한 트레이닝(또는, 학습)을 수행할수록, 보다 정확한 파라미터(예를 들어, 바 이어스 및/또는 가중치)가 결정될 수 있다. 한편, 인공 신경망 구조의 종류 또한 다양하다. 예를 들어, 인공 신경망 구조는, GAN(generative adversarial network), DNN(deep neural network), CNN(convolutional neural network), RNN(recurrent neural network), LSTM(long short term memory) 등 다양한 종류로 구현될 수 있다. 아울러, DNN이라 하더라도, DNN을 구성하는 레이어의 개수나, 레이어 별 노드의 구성, 및/또는 노드 사이의 연결 관계는 다양하게 구현될 수 있다. 특정되는 목적에 따라서 인공 신경망 구조의 종류 및 인공 신경망의 노드들 사이의 연결 관계 및/또는 레이어의 구조 등이 결정될 수 있다. 인공 신경망 구조의 종류 및 인공 신경망의 노드들 사이의 연결 관계 및/또는 레이 어의 구조가 결정되면, 가능한 많은 량의 트레이닝 데이터를 이용하여 트레이닝을 수행함으로써, 보다 정확한 파라미터(예를 들어, 바이어스 및/또는 가중치)가 결정될 수 있다. 이에 따라, 특정되는 목적의 성공 확률이상대적으로 높은 인공 지능 모델이 생성될 수 있다."}
{"patent_id": "10-2024-0144465", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "상술한 바와 같이, 최근의 연구는, 하나의 특정되는 목적을 달성하기 위한 인공 지능 모델의 생성에 집중되어 있다. 하지만, 다수의 사람들에 의한 집단 결정에 대한 연구에 대하여서는 진행된 바가 없다. 예를 들어, 집 단에는 다양한 사람들이 속할 수 있으며, 각각의 사람들은 동일한 입력에 대하여서도 상이한 결정을 할 수 있다. 다양한 결정들에 기반한 집단 결정이 영향을 주는 분야, 예를 들어, 선거 결과, 또는 주식 시장에서는, 하나의 인공 지능 모델로 다수의 사람들의 결정을 모사하기에 한계가 있다. 다양한 사람들에 대응하는 복수 개 의 모델들의 출력값들을 이용하여, 전체 집단 결정을 수행하는 방법에 대하여서는 알려진 바가 없다. 다양한 실시예에 따른 전자 장치 및 그 동작 방법은, 복수 개의 인공 지능 모델들 각각의 출력 값을 이용하여, 집단 결정을 수행할 수 있다."}
{"patent_id": "10-2024-0144465", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "다양한 실시예에 따라서, 적어도 하나의 프로그램 명령어를 저장하는 컴퓨터로 독출가능한 저장 매체가 제공되 며, 상기 적어도 하나의 프로그램 명령어는, 실행 시에, 적어도 하나의 프로세서가, 각각이 복수 개의 파라미터 타입들 각각에 대응하는 복수 개의 값들을 포함하는 환경 정보를 획득하고, 상기 복수 개의 값들에 기반하여, 복수 개의 인공 지능 모델들 각각에 대응하는 복수 개의 부분 집합들 각각을 확인하고, 상기 복수 개의 부분 집 합들 각각을, 상기 복수 개의 인공 지능 모델들 각각에 입력하고, 상기 복수 개의 인공 지능 모델들 각각으로부 터 출력되는 복수 개의 출력값들 각각을 확인하고, 및 상기 복수 개의 출력값들에 대한 가중치 합을 최종 값으 로서 확인하도록 야기할 수 있다. 다양한 실시예에 따라서, 적어도 하나의 프로그램 명령어를 저장하는 컴퓨터로 독출가능한 저장 매체가 제공되 며, 상기 적어도 하나의 프로그램 명령어는, 실행 시에, 적어도 하나의 프로세서가, 복수 개의 파라미터 타입들 과 연관된 복수 개의 데이터들을 포함하는 트레이닝 데이터를 획득하고, 상기 트레이닝 데이터의 적어도 일부인 제 1 서브 트레이닝 데이터를 이용하여 제 1 트레이닝을 수행함으로써, 제 1 인공 지능 모델을 생성하고, 상기 트레이닝 데이터의 적어도 일부인 제 2 서브 트레이닝 데이터를 이용하여 제 2 트레이닝을 수행함으로써, 제 2 인공 지능 모델을 생성하고, 상기 제 1 서브 트레이닝 데이터의 일부는, 상기 제 2 서브 트레이닝 데이터의 적 어도 일부와 동일하고, 상기 제 1 인공 지능 모델의 제 1 인공 신경망 구조는, 상기 제 2 인공 지능 모델의 제 2 인공 신경망 구조와 동일하고, 상기 제 1 인공 신경망 구조를 구성하는 파라미터들은, 상기 제 2 인공 신경망 구조를 구성하는 파라미터들과 적어도 일부 상이할 수 있다. 다양한 실시예에 따라서, 적어도 하나의 프로그램 명령어를 저장하는 컴퓨터로 독출가능한 저장 매체가 제공되 며, 상기 적어도 하나의 프로그램 명령어는, 실행 시에, 적어도 하나의 프로세서가, 복수 개의 파라미터 타입들 과 연관된 복수 개의 데이터들을 포함하는 트레이닝 데이터를 획득하고, 상기 트레이닝 데이터의 적어도 일부인 제 1 서브 트레이닝 데이터를 이용하여 제 1 트레이닝을 수행함으로써, 제 1 인공 지능 모델을 생성하고, 상기 트레이닝 데이터의 적어도 일부인 제 2 서브 트레이닝 데이터를 이용하여 제 2 트레이닝을 수행함으로써, 제 2 인공 지능 모델을 생성하고, 상기 복수 개의 파라미터 타입들 중 상기 제 1 서브 트레이닝 데이터에 대응하는 적어도 하나의 제 1 파라미터 타입은, 상기 복수 개의 파라미터 타입들 중 상기 제 2 서브 트레이닝 데이터에 대응하는 적어도 하나의 제 2 파라미터 타입과 적어도 일부 상이할 수 있다. 다양한 실시예에 따라서, 적어도 하나의 프로그램 명령어를 저장하는 컴퓨터로 독출가능한 저장 매체가 제공되 며, 상기 적어도 하나의 프로그램 명령어는, 실행 시에, 적어도 하나의 프로세서가, 복수 개의 트레이닝 데이터 들을 획득하도록 야기할 수 있다. 상기 복수 개의 트레이닝 데이터들 각각은, 복수 개의 인공 지능 모델들 각 각에 대응하는 구성 가중치들, 상기 복수 개의 인공 지능 모델들 각각으로부터의 출력값들 및 상기 구성 가중치 들의 가중치 합과, 실제 값을 포함할 수 있다. 상기 적어도 하나의 프로그램 명령어는, 실행 시에, 적어도 하 나의 프로세서가, 상기 가중치 합 및 상기 실제 값에 기반하여, 상기 복수 개의 인공 지능 모델들 각각에 대응 하는 구성 가중치들 중 적어도 일부를 결정하도록 야기할 수 있다. 다양한 실시예에 따라서, 적어도 하나의 프로그램 명령어를 저장하는 컴퓨터로 독출가능한 저장 매체가 제공되 며, 상기 적어도 하나의 프로그램 명령어는, 실행 시에, 적어도 하나의 프로세서가, 각각이 복수 개의 파라미터 타입들 각각에 대응하는 복수 개의 값들을 포함하는 환경 정보를 입력 레이어에 제공하도록 야기할 수 있다.상기 입력 레이어는, 복수 개의 서브 인공 지능 모델들 각각에 대응하는 복수 개의 부분 집합들 각각을 상기 복 수 개의 서브 인공 지능 모델들 각각으로 전달하도록 설정되고, 상기 복수 개의 부분 집합들 각각은, 상기 복수 개의 값들 중 적어도 하나 이상을 원소로서 포함할 수 있다. 상기 적어도 하나의 프로그램 명령어는, 실행 시 에, 적어도 하나의 프로세서가, 상기 복수 개의 서브 인공 지능 모델들 각각에 의한 상기 복수 개의 부분 집합 들 각각의 처리 결과인 복수 개의 출력값들을 완전히 연결된 레이어에 제공하도록 야기할 수 있다. 상기 완전 히 연결된 레이어는, 상기 복수 개의 출력값들에 대한 가중치 합을 최종 값으로서 제공하도록 설정될 수 있다. 상기 적어도 하나의 프로그램 명령어는, 실행 시에, 적어도 하나의 프로세서가, 상기 완전히 연결된 레이어로부 터 제공되는 상기 최종 값을 출력 레이어를 통하여 제공하도록 야기할 수 있다."}
{"patent_id": "10-2024-0144465", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "다양한 실시예에 따라서, 복수 개의 인공 지능 모델들 각각의 출력 값을 이용하여, 집단 결정을 수행할 수 있는 전자 장치 및 그 동작 방법이 제공될 수 있다. 이에 따라, 다수의 사람들의 결정들에 의하여 집단 결정이 수행 되는 분야에서, 보다 정확한 예측이 가능할 수 있다."}
{"patent_id": "10-2024-0144465", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "item": 1, "content": "도 1은 다양한 실시예에 따른 전자 장치의 블록도를 도시한다. 다양한 실시예에 따라서, 전자 장치는, 프로세서 및 저장 장치를 포함할 수 있다. 다양한 실시예에 따라서, 프로세서는, 저장 장치에 저장된 적어도 하나의 프로그램 명령어를 실행함 으로써, 전자 장치의 적어도 하나의 동작을 수행할 수 있다. 프로세서는, CPU(central processing unit), GPU(graphics processing unit), 및/또는 NPU(neural processing unit)를 포함할 수 있으나, 적어도 하 나의 프로그램 명령어를 실행할 수 있는(예를 들어, 연산을 수행할 수 있는) 장치라면 제한이 없다. 다양한 실시예에 따라서, 저장 장치는, 프로세서에 의하여 수행될 수 있는 적어도 하나의 프로그램 명령어를 저장할 수 있다. 저장 장치는, 복수 개의 인공지능 모델들을 저장할 수 있다. 저장 장치 는, 트레이닝(또는, 학습)을 위한 데이터를 저장할 수 있다. 저장 장치는, 더욱 상세하게 후술할 복수 개 의 인공지능 모델의 출력값에 반영되는 가중치를 포함할 수도 있다. 저장 장치는, RAM, ROM, 플래시, 자 기 매체, 예를 들어, 하드 드라이브, 레지스터들과 같은, 데이터를 저장할 수 있는 장치라면 제한이 없다. 도 2는 집단 결정이 수행되는 과정을 설명하기 위한 도면이다. 예를 들어, 하나의 집단에는 복수 개의 엔티티(entity)들이 포함될 수 있다. 엔티티는, 예를 들어 사람일 수 있으나 이에 한정되지 않는다. 예를 들어, 환경(environment)을 나타내는 파라미터들(201,202,203)이 존재하는것을 상정하도록 한다. 만약, 환경이 주식 시장인 경우에는, 파라미터들(201,202,203)은, 예를 들어 금리, 원 유 가격, 호재 뉴스를 수치화한 값, 악재 뉴스를 수치화한 값 등일 수 있으나, 주식 시장의 매도 및 매수에 영 향을 미칠 수 있는 파라미터라면 제한이 없다. 또는, 환경이 선거 결과 예측인 경우에는, 파라미터들 (201,202,203)은, 특정 후보에 대한 호재 뉴스를 수치화한 값, 악재 뉴스를 수치화한 값 등일 수 있으나, 선거 결과에 영향을 미칠 수 있는 파라미터라면 제한이 없다. 아울러, 파라미터들(201,202,203)의 개수가 3개인 것 은 단순히 예시적인 것으로, 파라미터들의 개수에는 제한이 없음을 당업자는 이해할 것이다. 이 경우, 제 1 엔티티는, 제 1 파라미터, 제 2 파라미터, 및 제 3 파라미터를 모두 이용할 수 있으며, 그 결과 제 1 출력을 제공할 수 있다. 예를 들어, 제 1 엔티티는, 상대적으로 다수의 소 스에서 획득되는 파라미터들을 이용하는 사람에 대응될 수 있다. 반면, 제 2 엔티티는, 제 2 파라미터 , 및 제 3 파라미터를 이용하기는 하나, 제 1 파라미터는 이용하지 않을 수 있으며, 그 결과 제 2 출력을 제공할 수 있다. 예를 들어, 제 2 엔티티는, 주식 시장의 경우라면, 원유 가격, 호재 뉴스 를 수치화한 값, 악재 뉴스를 수치화한 값 등은 매수 및/또는 매도에 이용하지만, 금리는 무시하는 사람에 대응 될 수 있다. 한편, 제 3 엔티티는, 제 2 파라미터를 이용하기는 하나, 제 1 파라미터 및 제 3 파라미터는 이용하지 않을 수 있으며, 그 결과 제 3 출력을 제공할 수도 있다. 상술한 바와 같이, 환경에 존재하는 파라미터들 중, 이용하는 파라미터가 상이한 엔티티들이 하나의 그룹에 상존할 수 있다. 제 1 엔티티, 제 2 엔티티 및 제 3 엔티티를, 인공 지능 모델로 모사한다면, 각 모델들로 입력되는 입력값의 셋트가 상이할 수 있다. 한편, 제 4 엔티티는, 제 1 파라미터, 제 2 파라미터, 및 제 3 파라미터를 모두 이용할 수 있으며, 그 결과 제 4 출력을 제공할 수 있다. 제 4 엔티티는 및 제 1 엔티티와 동일한 파라미 터들(201,202,203)을 이용하기는 하나, 제 4 출력 및 제 1 출력은 상이할 수 있다. 예를 들어, 제 4 엔티티는, 그 동안 해당 환경에서 많은 경험을 하였던 사람에 대응할 수 있으며, 제 1 엔티티는, 상대적으로 소수의 경험을 하였던 사람에 대응할 수 있다. 제 1 엔티티 및 제 4 엔티티를, 인공 지 능 모델로 모사한다면, 제 1 엔티티는 상대적으로 적은 트레이닝 데이터에 의하여 트레이닝된 결과로 획득 된 인공 지능 모델에 대응될 수 있으며, 제 4 엔티티는 상대적으로 많은 트레이닝 데이터에 의하여 트레이 닝된 결과로 획득된 인공 지능 모델에 대응될 수 있다. 예를 들어, 제 1 엔티티에 대응하는 인공 지능 모 델 및 제 4 엔티티에 대응하는 인공 지능 모델은, 동일한 인공 신경망 구조를 가지되, 인공 신경망 구조를 구성하는 파라미터(예를 들어, 바이어스 및/또는 가중치)가 상이할 수 있다. 다른 예를 들어, 제 1 엔티티 에 대응하는 인공 지능 모델 및 제 4 엔티티에 대응하는 인공 지능 모델은, 상이한 인공 신경망 구조 를 가질 수도 있다. 한편, 제 5 엔티티는, 제 2 파라미터, 및 제 3 파라미터를 이용하기는 하 나, 제 1 파라미터는 이용하지 않을 수 있으며, 그 결과 제 5 출력을 제공할 수 있다. 예를 들어, 제 2 엔티티에 대응하는 인공 지능 모델 및 제 5 엔티티에 대응하는 인공 지능 모델은, 동일한 인공 신경망 구조를 가지되, 인공 신경망 구조를 구성하는 파라미터(예를 들어, 바이어스 및/또는 가중치)가 상이할 수 있다. 다른 예를 들어, 제 2 엔티티에 대응하는 인공 지능 모델 및 제 5 엔티티에 대응하는 인공 지능 모델은, 상이한 인공 신경망 구조를 가질 수도 있다. 상술한 바에 따라서, 엔티티들(211,212,213,214,215)로부터의 출력들(221,222,223,224,225)에 의하여 집단의 결정이 판단될 수 있다. 예를 들어, 환경이 주식 시장인 경우에는, 출력들(221,222,223,224,225) 각각이 매도 또는 매수를 나타내는 값일 수 있다. 한편, 엔티티들(211,212,213,214,215) 각각에 대응하는 사람 숫자와 이용하는 자본이 상이할 수 있으며, 출력들(221,222,223,224,225)과 각각에 대응하는 사람 숫자 및 자본이 고려 되어, 특정 주식에 대한 전체 매도 또는 매수 여부가 결정될 수 있다. 예를 들어, 환경이 선거 결과 예측인 경 우에는, 출력들(221,222,223,224,225) 각각이 특정 후보에 대한 지지 또는 반대 의사일 수 있다. 한편, 엔티티 들(211,212,213,214,215) 각각에 대응하는 사람 숫자가 상이할 수 있으며, 출력들(221,222,223,224,225)과 각 각에 대응하는 사람 숫자가 고려되어, 특정 후보에 대한 지지율이 예측될 수 있다. 상술한 바와 같이, 하나의 환경은, 다양한 엔티티들로 구성될 수 있다. 하지만, 모든 엔티티들이, 환경 내의 모든 정보들을 대량으로 트레이닝하는 것은 아니며, 일부 엔티티는 상대적으로 소량의 정보를 트레이닝할 수 있 다. 상대적으로 소량의 정보를 트레이닝한 엔티티에 의하여서는, 상대적으로 비합리적인 결정이 출력될 수도 있으나, 비합리적인 결정 또한 집단의 결정의 한 부분을 구성할 수 있다. 이에 따라, 현재의 가장 정확한 결정 을 수행할 수 있는 인공 지능 모델만으로는 집단 결정을 예측하는 데에 한계가 있다. 상대적으로 비합리적인 결정을 하는 인공 지능 모델과 같은 다양한 인공 지능 모델들의 출력값을 고려하여 전체 집단의 결정이 수행됨 에 따라, 더욱 높은 정확도가 담보될 수 있다. 본 개시에서는, 상대적으로 적은 수의 트레이닝 데이터를 이용하여 트레이닝됨에 따라 획득된 인공 지능 모델을 편의 상 미숙한 인공 지능 모델로 명명하도록 한다. 미숙한 인공 지능 모델은, 의도적으로 제한적인 정보에 기반하여 트레이닝된 인공 지능 모델 및/또는 의도적으로 상대 적으로 간단한 신경망 구조를 가지는 인공 지능 모델을 의미할 수 있다. 도 3a는 다양한 실시예에 따른 집단 결정을 위한 시스템을 도시한다. 다양한 실시예에 따른, 시스템은, 복수 개의 인공 지능 모델들(301,302,303,304,305)을 포함할 수 있다. 제 1 인공 지능 모델 및 제 4 인공 지능 모델 각각은, 환경의 상태들(311,312,313)의 3개의 값들을 입력값 으로 수신하여, 제 1 출력값 및 제 4 출력값 각각을 제공할 수 있다. 하나의 예에서, 제 1 인공 지 능 모델 및 제 4 인공 지능 모델은 동일한 인공 신경망 구조를 가지되, 인공 신경망 구조의 파라미터 (예를 들어, 바이어스 및/또는 가중치)가 상이할 수 있다. 인공 신경망 구조는, GAN, DNN, CNN, RNN, LSTM 등 으로 제한이 없음을 당업자는 이해할 것이다. 예를 들어, 제 1 인공 지능 모델 및 제 4 인공 지능 모델 은, 상이한 트레이닝 데이터를 이용하여 트레이닝됨에 따라서, 동일한 인공 신경망 구조를 가짐에도, 구성 파라미터가 상이할 수도 있으며, 이에 대하여서는 더욱 상세하게 후술하도록 한다. 예를 들어, 어느 하나의 인 공 지능 모델이 상대적으로 적은 트레이닝 데이터를 이용하여 트레이닝됨에 따라 획득된 미숙한 인공 지능 모델 일 수 있다. 또 다른 예에서, 제 1 인공 지능 모델 및 제 4 인공 지능 모델은, 상이한 인공 신경망 구조를 가질 수도 있다. 예를 들어, 제 1 인공 지능 모델 및 제 4 인공 지능 모델은, 모두 DNN을 가 지는 경우라 하더라도, 어느 하나의 인공 지능 모델의 레이어의 개수가 더 적을 수도 있으며, 이를 편의상 미숙 한 인공 지능 모델로 명명할 수도 있다. 또는, 제 1 인공 지능 모델 및 제 4 인공 지능 모델은 상이 한 종류의 인공 신경망을 가질 수도 있다. 다양한 실시예에 따라서, 제 2 인공 지능 모델 및 제 5 인공 지능 모델 각각은, 환경의 상태들 (311,312,313) 중 상태들(311,312)의 2개의 값들을 입력값으로 수신하여, 제 2 출력값 및 제 5 출력값 각각을 제공할 수 있다. 하나의 예에서, 제 2 인공 지능 모델 및 제 5 인공 지능 모델은 동일 한 인공 신경망 구조를 가지되, 인공 신경망 구조의 파라미터(예를 들어, 바이어스 및/또는 가중치)가 상이할 수 있다. 또 다른 예에서, 제 2 인공 지능 모델 및 제 5 인공 지능 모델은, 상이한 인공 신경망 구조 를 가질 수도 있다. 제 2 인공 지능 모델 및 제 5 인공 지능 모델은 2개의 값을 입력값으로서 이용 하는 점에서, 3개의 값을 입력값으로 이용하는 제 1 인공 지능 모델 및 제 4 인공 지능 모델에 비하 여 미숙한 인공 지능 모델일 수 있다. 즉, 미숙한 인공 지능 모델은, 보다 작은 수의 입력값을 이용하는 인공 지능 모델을 의미할 수도 있다. 한편, 제 3 인공 지능 모델은, 환경의 상태들(311,312,313) 중 상태(31 2)의 1개의 값을 입력값으로 수신하여, 제 3 출력값을 제공할 수 있다. 다양한 실시예에 따른 전자 장치는, 환경을 나타내는 상태들(311,312,313)을 획득하면, 상태들 (311,312,313) 중 적어도 일부를, 저장하고 있는 복수 개의 인공 지능 모델들(301,302,303,304,305) 각각으로 입력할 수 있다. 본 개시에서의 전자 장치가 특정 동작을 수행하는 것은, 예를 들어 적어도 하나의 프로 그램 명령어의 실행에 따라서, 프로세서가 특정 동작을 수행하는 것을 의미할 수 있다. 또는, 본 개시에 서의 전자 장치가 특정 동작을 수행하는 것은, 전자 장치가 특정 동작을 수행하도록 야기하는 적어도 하나의 프로그램 명령어가 컴퓨터로 독출 가능한 저장 장치에 저장된 것을 의미할 수도 있음을 당업자는 이해할 것이다. 다양한 실시예에 따른 전자 장치는, 복수 개의 인공 지능 모델들(301,302,303,304,305) 각각으로부터, 출 력값들(321,322,323,324,325)을 획득할 수 있다. 전자 장치는, 출력값들(321,322,323,324,325) 각각에 대응하는 구성 가중치(composition weight)들(αA, αB, αC, αD, αE) 각각을 곱할 수 있다. 구성 가중치는, 집단을 구성하는 엔티티의 구성 비율에 대응되도록 결정할 수 있으며, 인공 지능 모델의 인공 신경망의 가중치 와 구분되도록 용어가 정의되었다. 예를 들어, 시스템의 목적이 선거 예측 시스템인 경우, 제 1 인공 지능 모 델의 특성을 가지는 유권자의 비율이 전체 집단의 20%인 경우에는, 제 1 인공 지능 모델에 대응하는 구성 가중치(αA)는 0.2 일 수 있다. 예를 들어, 시스템의 목적이 특정 주식의 매수 또는 매도 예측인 경우, 해당 주식과 연관된 전체 자본에 대한, 제 1 인공 지능 모델의 특성을 가지는 자본의 비율이 구성 가중치 (αA)일 수 있다. 구성 가중치는, 예를 들어 실험적 또는 통계적인 방법으로 결정될 수 있다. 한편, 다른 예 시에서, 구성 가중치는, 트레이닝에 따라 결정될 수도 있으며, 이에 대하여서는 더욱 상세하게 후술하도록 한다. 다양한 실시예에 따라서, 전자 장치는, 출력값들(321,322,323,324,325) 각각과, 구성 가중치들(αA, αB, αC, αD, αE) 각각의 곱의 합계로 최종 결정(final decision)을 제공할 수 있으며, 간명하게 이를 가중치 합으 로 명명할 수도 있다. 만약, 집단에 상대적으로 미숙한 엔티티들이 많은 경우, 미숙한 엔티티를 모사한 미숙한 인공 지능 모델에 대응하는 구성 가중치가 높게 설정될 수 있으며, 이에 따라 최종 결정(final decision)이 다 소 비합리적인 결과가 제공될 수도 있다. 다양한 실시예에 따른 시스템은, 합리적인 결과를 제공하는 것에 목 적이 있다기 보다는, 미성숙한 엔티티를 포함하는 집단의 특성을 고려하여, 보다 실제에 가까운 집단 결정의 결 과를 제공하는 것에 있다. 한편, 도 3a에서와 같이, 시스템은, 복수 개의 인공 지능 모델의 출력값과 구성 가중치에 의한 가중치 합에 기 반한 결과를 출력하도록 구성될 수도 있으며, 또는 도 3b와 같이 하나의 인공 지능 모델로서 구성될 수도 있다. 복수 개의 인공 지능 모델들(301,302,303,304,305) 각각은, LLM(large languae model)일 수도 있다. 예를 들 어, 복수 개의 인공 지능 모델들(301,302,303,304,305) 각각은, 동일한 입력에 대하여 상이한 답변을 출력하도 록 상이하게 트레이닝된 모델들일 수도 있음을 당업자는 이해할 것이다. 도 3b는, 도 3a의 시스템을 하나의 인공 지능 모델로 구현한 구조를 설명하기 위한 도면이다. 다양한 실시예에 따른 인공 지능 모델은, 복수 개의 서브 인공 지능 모델들(331,332,333,334,335)을 포함 할 수 있다. 예를 들어, 제 1 서브 인공 지능 모델은, 3개의 입력값(311,312,313)을 수신하여, 제 1 출력 값을 출력할 수 있다. 인공 지능 모델은, 입력 레이어를 포함할 수 있으며, 입력 레이어는 전체 입 력값(예를 들어, 3개의 입력값(311,312,313))을 수신하여, 각 서브 인공 지능 모델들(331,332,333,334,335)에 대응하는 부분 집합들을, 서브 인공 지능 모델들(331,332,333,334,335)로 제공하는 레이어일 수 있다. 예를 들어, 제 1 서브 인공 지능 모델은, 1개의 입력 레이어(input layer), 2개의 은닉 레이어(hidden layer), 및 1개의 출력 레이어(output layer)를 포함하는 인공 신경망 구조를 가지는 것과 같이 도시되어 있지 만, 이는 단순히 예시적인 것으로 구조에는 제한이 없다. 예를 들어, 제 2 서브 인공 지능 모델은, 2개의 입력값(311,312)을 수신하여, 제 2 출력값을 출력할 수 있다. 예를 들어, 제 2 서브 인공 지능 모델(33 2)은, 1개의 입력 레이어, 2개의 은닉 레이어, 및 1개의 출력 레이어를 포함하는 인공 신경망 구조를 가지는 것 과 같이 도시되어 있지만, 이는 단순히 예시적인 것으로 구조에는 제한이 없다. 예를 들어, 상대적으로 많은 입력값을 이용하는 제 1 서브 인공 지능 모델이 제 2 서브 인공 지능 모델보다 성숙한 인공 지능 모 델이라 명명할 수도 있지만, 제한은 없다. 예를 들어, 제 3 서브 인공 지능 모델은, 1개의 입력값을 수신하여, 제 3 출력값을 출력할 수 있다. 예를 들어, 제 3 서브 인공 지능 모델은, 1개의 입력 레 이어, 2개의 은닉 레이어, 및 1개의 출력 레이어를 포함하는 인공 신경망 구조를 가지는 것과 같이 도시되어 있 지만, 이는 단순히 예시적인 것으로 구조에는 제한이 없다. 예를 들어, 제 4 서브 인공 지능 모델은, 3개 의 입력값(311,312,313)을 수신하여, 제 4 출력값을 출력할 수 있다. 예를 들어, 제 4 서브 인공 지능 모 델은, DNN 구조를 가지는 것과 같이 도시되어 있지만, 이는 단순히 예시적인 것으로 구조에는 제한이 없다. 예를 들어, DNN 구조를 가지는 제 4 서브 인공 지능 모델이 동일한 입력값을 이용하는 제 1 서브 인공 지능 모델보다 성숙한 인공 지능 모델이라 명명할 수도 있지만, 제한은 없다. 예를 들어, 제 5 서브 인공 지능 모델은, 2개의 입력값(311,312)을 수신하여, 제 5 출력값을 출력할 수 있다. 예를 들어, 제 5 서브 인공 지능 모델은, DNN 구조를 가지는 것과 같이 도시되어 있지만, 이는 단순히 예시적인 것으 로 구조에는 제한이 없다. 예를 들어, DNN 구조를 가지는 제 5 서브 인공 지능 모델이 동일한 입력값을 이용하는 제 2 서브 인공 지능 모델보다 성숙한 인공 지능 모델이라 명명할 수도 있지만, 제한은 없다. 다양한 실시예에 따라서, 복수 개의 서브 인공 지능 모델들(331,332,333,334,335)로부터의 출력값들 (321,322,323,324,325)은, 완전히 연결된 레이어(fully connected layer)로 입력될 수 있다. 완전히 연 결된 레이어(fully connected layer)는, 예를 들어 입력되는 출력값들(321,322,323,324,325) 각각에 대하 여, 대응하는 구성 가중치들 각각을 곱한 후, 이를 합산한 결과를 최종 값, 즉 최종 결정으로서 출력할 수 있으 나, 제한은 없다. 완전히 연결된 레이어를 구성하는 구성 가중치들 각각은, 실험적 방식 또는 통계적 방식에 의 하여 결정될 수 있거나, 또는 더욱 상세하게 후술할 것으로 구성 가중치들 역시 트레이닝되어 결정될 수도 있다. 도 3c는 다양한 실시예에 따른 전자 장치의 동작 방법을 설명하기 위한 흐름도를 도시한다. 다양한 실시예에 따라서, 전자 장치는, 351 동작에서, 복수 개의 인공 지능 모델을 저장할 수 있다. 본 개시에서의 \"복수 개의 인공 지능 모델\"은, 예를 들어 도 3a의 시스템에서의 복수 개의 인공 지능 모델들(301,302,303,304,305)을 의미할 수 있으며, 도 3b와 같은 구현에서는 복수 개의 서브 인공 지능 모델들 (331,332,33,334,335)을 의미할 수 있고, 치환될 수 있음을 당업자는 이해할 것이다. 예를 들어, 복수 개의 인 공 지능 모델은, 수신하는 입력값이 상이하거나, 인공 신경망의 구조가 상이하거나, 및/또는 인공 신경망 구조 를 구성하는 파라미터가 상이할 수 있다. 더욱 상세하게 후술할 것으로, 복수 개의 인공 지능 모델 각각은, 상 이한 트레이닝 데이터를 이용한 트레이닝 결과에 따라 획득됨에 따라서, 수신하는 입력값이 상이하거나, 인공 신경망의 구조가 상이하거나, 및/또는 인공 신경망 구조를 구성하는 파라미터가 상이할 수 있다. 다양한 실시예에 따라서, 전자 장치는, 353 동작에서, 환경 정보를 획득할 수 있다. 환경 정보는, 예를 들어 도 3a에서와 같은 상태들(311,312,313)을 포함할 수 있으며, 환경을 나타낼 수 있는 지표라면 제한이 없다. 전자 장치는, 355 동작에서, 환경 정보를 이용하여, 복수 개의 인공지능 모델 각각에 복수 개의 인 공지능 모델 별로 설정된 적어도 하나의 입력값을 입력할 수 있다. 예를 들어, 도 3a에서 설명한 바와 같이, 전자 장치는, 인공 지능 모델 별로 입력되는 입력값의 종류를 미리 저장할 수 있다. 이에 따라, 전자 장 치는, 환경 정보를 구성하는 복수의 값들 중, 인공 지능 모델 별 부분 집합을 결정하여, 부분 집합의 입력 값으로서 인공 지능 모델로 제공할 수 있다. 예를 들어, 도 3a의 예시에서는, 상태, 상태, 상태 이 전체 집합인 경우, 제 1 인공 지능 모델에 대응하는 부분 집합은 {상태, 상태, 상태 }이고, 제 2 인공 지능 모델에 대응하는 부분 집합은 {상태, 상태}이고, 제 3 인공 지능 모델에 대응하는 부분 집합은 {상태}이고, 제 4 인공 지능 모델에 대응하는 부분 집합은 {상태 , 상태, 상태}이고, 제 5 인공 지능 모델에 대응하는 부분 집합은 {상태, 상태 }일 수 있다. 전자 장치는, 357 동작에서, 복수 개의 인공지능으로부터 출력값들을 확인할 수 있다. 전자 장치는, 359 동작에서, 출력값들에 대한 가중치 합, 예를 들어 출력값들 각각과 구성 가중치 각각들 의 곱을 최종 값으로서 확인할 수 있다. 도 4a는 다양한 실시예에 따른 복수 개의 인공 지능 모델들의 트레이닝 과정을 설명하기 위한 도면이다. 도 4a 의 실시예는, 도 4b를 참조하여 설명하도록 한다. 도 4b는 다양한 실시예들에 따른 트레이닝을 위한 데이터를 설명하기 위한 도면이다. 다양한 실시예에 따른 전자 장치의 저장 장치에는, 트레이닝을 위한 데이터가 저장될 수 있다. 트레이닝을 위한 데이터는, 예를 들어 도 4b와 같은 포맷으로 표현될 수 있다. 트레이닝을 위한 데이터 는, 환경을 나타내기 위한 파라미터 타입들(S1,S2,S3,S4,S5,S6)로 분류될 수 있다. 만약 환경이 주식 매도 또는 매수 예측인 경우에는, 파라미터 타입들(S1,S2,S3,S4,S5,S6)은, 예를 들어 금리, 원유 가격, 호재 뉴스를 수치화한 값, 악재 뉴스를 수치화한 값 등일 수 있으나, 주식 시장의 매도 및 매수에 영향을 미칠 수 있는 파라 미터 타입이라면 제한이 없다. 한편, 각 파라미터 타입은 시점 별로 실제 값들로 표현될 수 있다. 예를 들어, \"S1\"이 금리인 경우에는, t1 시점에서의 값인 S1(t1)은 2.5%, t2 시점에서의 값인 S1(t2)은 2.0%, tn 시점에서 의 값인 S1(tn)은 1.5% 등의 실제 값들을 가질 수 있으며, 이를 편의 상 파라미터로 명명할 수 있다. 트레이닝 을 위한 데이터에는, 각 파라미터의 타입 별로, 시점 별 파라미터가 포함될 수 있다. 다양한 실시예에 따른 전자 장치는, 제 1 파라미터 타입(S1)에 대응하는 적어도 하나의 파라미터, 제 2 파 라미터 타입(S2)에 대응하는 적어도 하나의 파라미터, 및 제 3 파라미터 타입(S3)에 대응하는 적어도 하나의 파 라미터를 이용하여, 트레이닝을 수행할 수 있다. 트레이닝 결과에 따라 제 1 인공 지능 모델이 획득될 수 있다. 전자 장치는, 제 1 파라미터 타입(S1)에 대응하는 적어도 하나의 파라미터, 제 4 파라미 터 타입(S4)에 대응하는 적어도 하나의 파라미터에 대응하는 적어도 하나의 파라미터를 이용하여, 트레이닝 을 수행할 수 있다. 트레이닝 결과에 따라 제 2 인공 지능 모델이 획득될 수 있다. 예를 들어, 트레이닝이 제 1 파라미터 타입(S1)에 대응하는 적어도 하나의 파라미터를 이용하고, 트레이닝도 제 1 파라미터 타입(S1)에 대응하는 적어도 하나의 파라미터를 이용할 수 있다. 이 경우, 트레이닝이 이용하 는 제 1 파라미터 타입(S1)에 대응하는 적어도 하나의 파라미터는, 트레이닝이 이용하는 제 1 파라미터 타 입(S1)에 대응하는 적어도 하나의 파라미터와 동일할 수 있거나, 또는 적어도 일부 상이할 수도 있다. 다양한 실시예에 따라서, 전자 장치는, 제 1 파라미터 타입(S1)에 대응하는 적어도 하나의 파라미터, 제 4 파라미터 타입(S4)에 대응하는 적어도 하나의 파라미터에 대응하는 적어도 하나의 파라미터를 이용하여, 트레이 닝을 수행할 수 있다. 트레이닝 결과에 따라 제 2 인공 지능 모델이 획득될 수 있다. 전자 장 치는, 제 4 파라미터 타입(S4)에 대응하는 적어도 하나의 파라미터, 제 5 파라미터 타입(S5)에 대응하는 적어도 하나의 파라미터에 대응하는 적어도 하나의 파라미터를 이용하여, 트레이닝을 수행할 수 있다. 트 레이닝 결과에 따라 제 3 인공 지능 모델이 획득될 수 있다. 전자 장치는, 제 1 파라미터 타입 (S1)에 대응하는 적어도 하나의 파라미터, 제 2 파라미터 타입(S2)에 대응하는 적어도 하나의 파라미터, 제 4파라미터 타입(S4)에 대응하는 적어도 하나의 파라미터에 대응하는 적어도 하나의 파라미터를 이용하여, 트레이 닝을 수행할 수 있다. 트레이닝 결과에 따라 제 4 인공 지능 모델이 획득될 수 있다. 전자 장 치는, 제 1 파라미터 타입(S1)에 대응하는 적어도 하나의 파라미터, 제 4 파라미터 타입(S4)에 대응하는 적어도 하나의 파라미터에 대응하는 적어도 하나의 파라미터를 이용하여, 트레이닝을 수행할 수 있다. 트 레이닝 결과에 따라 제 5 인공 지능 모델이 획득될 수 있다. 예를 들어, 트레이닝이 제 1 파라 미터 타입(S1)에 대응하는 적어도 하나의 파라미터, 제 4 파라미터 타입(S4)에 대응하는 적어도 하나의 파라미 터를 이용하며, 트레이닝도 제 1 파라미터 타입(S1)에 대응하는 적어도 하나의 파라미터, 제 4 파라미터 타입(S4)에 대응하는 적어도 하나의 파라미터를 이용할 수 있다. 이 경우, 트레이닝이 이용하는 제 1 파 라미터 타입(S1)에 대응하는 적어도 하나의 파라미터는, 트레이닝이 이용하는 제 1 파라미터 타입(S1)에 대응하는 적어도 하나의 파라미터와 상이할 수도 있다. 또는, 트레이닝이 이용하는 제 1 파라미터 타입 (S1)에 대응하는 적어도 하나의 파라미터가, 트레이닝이 이용하는 제 1 파라미터 타입(S1)에 대응하는 적 어도 하나의 파라미터와 동일하되, 트레이닝에 대응하는 인공 신경망 구조와 트레이닝에 대응하는 인 공 신경망 구조가 상이할 수도 있다. 상술한 바와 같이, 전자 장치는, 인공 지능 모델 별로 적어도 일부 상이한 파라미터 타입에 대응하는 파라미터들을 이용하여 트레이닝을 수행할 수 있다. 이에 따라, 보다 많은 파라미터 타입들이 고려되는 인공 지능 모델 및 보다 적은 파라미터 타입이 고려되는 인공 지능 모델이 공존하 는 집단이 구성될 수 있다. 도 5a는 다양한 실시예에 따른 전자 장치의 동작 방법을 설명하기 위한 흐름도를 도시한다. 도 5a의 실시예는, 도 5b를 참조하여 설명하도록 한다. 도 5b는, 다양한 실시예에 따른 트레이닝 데이터 전체 셋트를 도시한다. 다양한 실시예에 따라서, 전자 장치는, 501 동작에서, 트레이닝 데이터를 획득할 수 있다. 예를 들어, 전 자 장치는, 도 5b와 같은 트레이닝 데이터의 전체 셋트를 저장할 수 있다. 503 동작에서, 전자 장치(10 1)는, 복수 개의 인공지능 모델 별로 설정된 서브 트레이닝 데이터를 확인할 수 있다. 예를 들어, 전자 장치 는, 제 1 인공 지능 모델에 대하여서는, 파라미터의 타입이 \"S1\", \"S2\" 및 \"S3\"가 설정되어 있음을 확인할 수 있다. 전자 장치는, 제 1 인공 지능 모델에 대응하는 서브 트레이닝 데이터로는, \"S1\"의 파라미터 타 입에 대응하는 제 1 서브 트레이닝 데이터, \"S2\"의 파라미터 타입에 대응하는 제 2 서브 트레이닝 데이터 , 및 \"S3\"의 파라미터 타입에 대응하는 제 3 서브 트레이닝 데이터를, 확인할 수 있다. 예를 들어, 전자 장치는, 제 2 인공 지능 모델에 대하여서는, 파라미터의 타입이 \"S1\" 및 \"S4\"가 설정되어 있음을 확 인할 수 있다. 전자 장치는, 제 1 인공 지능 모델에 대응하는 서브 트레이닝 데이터로는, \"S1\"의 파라미 터 타입에 대응하는 제 1 서브 트레이닝 데이터 및 \"S4\"의 파라미터 타입에 대응하는 제 4 서브 트레이닝 데이터를, 확인할 수 있다. 복수 개의 인공 지능 별로 이용하는(즉, 입력받는) 파라미터 타입이 상이하므 로, 전자 장치는, 트레이닝 데이터 전체 셋트에서 복수 개의 인공 지능 별 트레이닝하는 서브 트레이닝 데 이터를 상이하게 설정할 수 있다. 505 동작에서, 전자 장치는, 복수 개의 인공지능 모델 별로 설정된 서 브 트레이닝 데이터 각각을 이용하여, 복수 개의 인공지능 모델을 생성할 수 있다. 트레이닝의 종류에는 제한 이 없음을 당업자는 이해할 것이다. 상술한 바에 따라서, 상대적으로 많은 파라미터 타입의 서브 트레이닝 데 이터를 이용하는 상대적으로 원숙한(mature) 인공 지능 모델부터, 상대적으로 적은 파라미터 타입의 서브 트레 이닝 데이터를 이용하는 상대적으로 미숙한 인공 지능 모델이 생성될 수 있다. 즉, 트레이닝 데이터의 전체 셋 트를 이용할 수 있음에도 불구하고, 의도적으로 일부 파라미터만을 이용한 트레이닝을 수행함으로써, 상대적으 로 미숙한 인공 지능 모델이 생성될 수 있다. 이에 따라, 집단 내에서, 상대적으로 적은 파라미터 타입을 고려 하여 의사를 결정하는 엔티티 및 상대적으로 많은 파라미터 타입을 고려하여 의사를 결정하는 엔티티 모두를 모 사할 수 있는 복수 개의 인공 지능 모델들이 생성될 수 있다. 도 6은 다양한 실시예에 따른 트레이닝 데이터 전체 셋트를 도시한다. 예를 들어, 전자 장치는, 도 6과 같은 트레이닝 데이터의 전체 셋트를 저장할 수 있다. 전자 장치는, 복수 개의 인공지능 모델 별로 설정된 서브 트레이닝 데이터를 확인할 수 있다. 예를 들어, 전자 장치는, 제 1 인공 지능 모델 및 제 2 인공 지능 모델 모두 \"S1\"의 파라미터 타입을 이용하는 것을 확인할 수 있다. 전자 장치는, 제 1 인공 지능 모델에 대응하는 서브 트레이닝 데이터로는, \"S1\"의 파라미터 타 입에 대응하는 복수 개의 파라미터들(601,602,603,604)을 결정할 수 있다. 전자 장치는, 제 2 인공 지능 모델에 대응하는 서브 트레이닝 데이터로는, \"S1\"의 파라미터 타입에 대응하는 복수 개의 파라미터들 (601,602,603,604) 중 일부(602,604)를 결정할 수 있다. 전자 장치는, 복수 개의 인공지능 모델 별로 설 정된 서브 트레이닝 데이터 각각을 이용하여, 복수 개의 인공지능 모델을 생성할 수 있다. 트레이닝의 종류에 는 제한이 없음을 당업자는 이해할 것이다. 상술한 바에 따라서, 동일한 파라미터 타입에 대하여서도 제 1 인공 지능 모델 및 제 2 인공 지능 모델이 이용하는 파라미터들이 상이하게 설정될 수 있다. 동일한 파라미터 타 입에 대하여 상대적으로 많은 파라미터를 포함하는 서브 트레이닝 데이터를 이용하는 상대적으로 원숙한 (mature) 인공 지능 모델부터, 상대적으로 적은 파라미터를 포함하는 서브 트레이닝 데이터를 이용하는 상대적 으로 미숙한 인공 지능 모델이 생성될 수 있다. 즉, 트레이닝 데이터의 전체 셋트를 이용할 수 있음에도 불구 하고, 의도적으로 일부 파라미터만을 이용한 트레이닝을 수행함으로써, 상대적으로 미숙한 인공 지능 모델이 생 성될 수 있다. 이에 따라, 집단 내에서, 동일한 파라미터 타입이라 하더라도, 상대적으로 적은 파라미터를 고 려하여 의사를 결정하는 엔티티 및 상대적으로 많은 파라미터를 고려하여 의사를 결정하는 엔티티 모두를 모사 할 수 있는 복수 개의 인공 지능 모델들이 생성될 수 있다. 예를 들어, 환경이 특정 주식의 매도 또는 매수인 경우에는, 호재에 보다 용이하게 접근할 수 있는 엔티티와 접근이 어려운 엔티티가 혼재할 수 있으며, 양 엔티 티들 모두에 대응하는 복수 개의 인공 지능 모델들이 생성될 수 잇다. 한편, 다양한 실시예에 따라서, 전자 장 치는, 도 5b의 실시예 및 도 6의 실시예를 혼합하여 트레이닝을 수행함으로써, 복수 개의 인공 지능 모델 들이 생성될 수도 있음을 당업자는 이해할 것이다. 도 7은 다양한 실시예에 따른 전자 장치의 동작 방법을 설명하기 위한 흐름도를 도시한다. 도 7의 실시예는, 도 8을 참조하여 설명하도록 한다. 도 8은 다양한 실시예에 따른 최종 값 및 실제 값을 포함하는 트레이닝 데 이터를 설명하기 위한 도면이다. 다양한 실시예에 따라서, 전자 장치는, 701 동작에서, 트레이닝 데이터를 획득할 수 있다. 전자 장치 는, 703 동작에서, 트레이닝 데이터를 이용하여, 복수 개의 서브 트레이닝 데이터들을 생성할 수 있다. 예를 들어, 전자 장치는, 도 5b의 실시예 및/또는 도 6의 실시예에 기반하여, 복수 개의 서브 트레이닝 데 이터들을 생성할 수 있다. 전자 장치는, 705 동작에서, 복수 개의 서브 트레이닝 데이터들 각각을 이용하 여, 복수 개의 인공지능 모델을 생성할 수 있다. 전자 장치는, 707 동작에서, 복수 개의 인공지능 모델의 출력값 및 최종 값에 기반하여, 복수 개의 인공지능 모델 각각에 대응하는 구성 가중치를 확인할 수 있다. 예 를 들어, 전자 장치는, 도 8과 같은 최종 값 및 실제 값을 포함하는 트레이닝 데이터를 저장할 수 있다. 도 8을 참조하면, 전자 장치는, 구성 가중치들( )(예를 들어, 도 3a의 구성 가중치들(αA, αB, αC, αD, αE)), 최종 값(D) 및 실제 값(R)을 포함하는 트레이닝 데이터를 저장할 수 있다. 트레이닝 데이터는, 제 1 시 점에서의 구성 가중치들( ), 제 1 시점에서의 최종 값(D), 제 1 시점에서의 실제 값(R)이 연관되어 저장될 수 있으며, 이러한 연관 정보는 제 2 시점 내지 제 n 시점에 대하여 저장될 수 있다. 전자 장치는, 최종 값(D) 및 실제 값(R)의 차이(예를 들어, 손실 함수 등)에 기반하여, 트레이닝을 수행할 수 있으며, 이에 따라 구성 가중치들( )(예를 들어, 도 3a의 구성 가중치들(αA, αB, αC, αD, αE))이 확인(또 는, 트레이닝)될 수 있다. 구성 가중치들( )(예를 들어, 도 3a의 구성 가중치들(αA, αB, αC, αD, αE)) 각 각이 확인됨에 따라서, 특정 성향의 엔티티 내의 비율도 함께 확인될 수도 있다. 본 발명의 실시 예들은 하드웨어, 소프트웨어 또는 하드웨어 및 소프트웨어의 조합의 형태로 실현 가능하다는 것을 알 수 있을 것이다. 이러한 임의의 소프트웨어는 예를 들어, 삭제 가능 또는 재기록 가능 여부와 상관없이, ROM 등의 저장 장치와 같은 휘발성 또는 비휘발성 저장 장치, 또는 예를 들어, RAM, 메모리 칩, 장치 또는 집적 회로와 같은 메모리, 또는 예를 들어 CD, DVD, 자기 디스크 또는 자기 테이프 등과 같은 광학 또는 자기적으로 기록 가능함과 동시에 기계(예를 들어, 컴퓨터)로 읽을 수 있는 저장 매체에 저장될 수 있다. 본 발 명의 그래픽 화면 갱신 방법은 제어부 및 메모리를 포함하는 컴퓨터 또는 휴대 단말에 의해 구현될 수 있고, 상 기 메모리는 본 발명의 실시 예들을 구현하는 지시들을 포함하는 프로그램 또는 프로그램들을 저장하기에 적합 한 기계로 읽을 수 있는 저장 매체의 한 예임을 알 수 있을 것이다. 따라서, 본 발명은 본 명세서의 임의의 청 구항에 기재된 장치 또는 방법을 구현하기 위한 코드를 포함하는 프로그램 및 이러한 프로그램을 저장하는 기계 (컴퓨터 등)로 읽을 수 있는 저장 매체를 포함한다. 또한, 이러한 프로그램은 유선 또는 무선 연결을 통해 전달 되는 통신 신호와 같은 임의의 매체를 통해 전자적으로 이송될 수 있고, 본 발명은 이와 균등한 것을 적절하게 포함한다.도면 도면1 도면2 도면3a 도면3b 도면3c 도면4a 도면4b 도면5a 도면5b 도면6 도면7 도면8"}
{"patent_id": "10-2024-0144465", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 다양한 실시예에 따른 전자 장치의 블록도를 도시한다. 도 2는 집단 결정이 수행되는 과정을 설명하기 위한 도면이다. 도 3a는 다양한 실시예에 따른 집단 결정을 위한 시스템을 도시한다. 도 3b는, 도 3a의 시스템을 하나의 인공 지능 모델로 구현한 구조를 설명하기 위한 도면이다. 도 3c는 다양한 실시예에 따른 전자 장치의 동작 방법을 설명하기 위한 흐름도를 도시한다. 도 4a는 다양한 실시예에 따른 복수 개의 인공 지능 모델들의 트레이닝 과정을 설명하기 위한 도면이다. 도 4b는 다양한 실시예들에 따른 트레이닝을 위한 데이터를 설명하기 위한 도면이다. 도 5a는 다양한 실시예에 따른 전자 장치의 동작 방법을 설명하기 위한 흐름도를 도시한다. 도 5b는, 다양한 실시예에 따른 트레이닝 데이터 전체 셋트를 도시한다. 도 6은 다양한 실시예에 따른 트레이닝 데이터 전체 셋트를 도시한다. 도 7은 다양한 실시예에 따른 전자 장치의 동작 방법을 설명하기 위한 흐름도를 도시한다. 도 8은 다양한 실시예에 따른 최종 값 및 실제 값을 포함하는 트레이닝 데이터를 설명하기 위한 도면이다."}
