{"patent_id": "10-2021-0189697", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2023-0100101", "출원번호": "10-2021-0189697", "발명의 명칭": "로봇 제어 시스템 및 이를 이용한 로봇 설정 방법 및 로봇 제어 방법", "출원인": "주식회사 케이티", "발명자": "김대영"}}
{"patent_id": "10-2021-0189697", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "적어도 하나의 프로세서로 구현된 로봇 제어 시스템이 로봇을 설정하는 방법으로서, 관리자의 손 제스처를 확인하는 단계,상기 손 제스처에 해당하는 기능을 상기 로봇에 대응하는 가상 로봇이 수행하도록, 상기 로봇에 삽입될 프로그램을 포함하는 상기 가상 로봇을 제어하는 단계, 상기 가상 로봇이 가상 객체를 대상으로 상기 기능을 수행하면서 상기 프로그램을 학습시키는 단계, 그리고상기 가상 로봇이 학습시킨 상기 프로그램으로 상기 로봇을 설정하는 단계를 포함하는, 로봇 설정 방법."}
{"patent_id": "10-2021-0189697", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 손 제스처를 확인하는 단계 이전에,상기 로봇에 매핑된 가상 로봇을 구현하고, 상기 로봇이 동작하는 매장에 매핑된 가상 현실 매장으로 구현하는단계를 포함하고,상기 가상 현실 매장은 상기 임의의 가상 객체를 포함하는 복수의 가상 객체들이 포함되며, 상기 복수의 가상객체들은 상기 매장에 설치된 객체들에 매핑되는, 로봇 설정 방법."}
{"patent_id": "10-2021-0189697", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서,상기 프로그램을 학습시키는 단계는,상기 기능이 성공적으로 수행되지 않았다면, 상기 가상 로봇이 상기 기능을 반복적으로 수행하도록 제어하는 단계를 더 포함하는, 로봇 설정 방법."}
{"patent_id": "10-2021-0189697", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,상기 손 제스처를 확인하는 단계는,상기 관리자의 손에 복수의 손 좌표들이 기 설정되어 있으며, 상기 관리자의 각 손 좌표들을 인식하여 상기 손 제스처를 확인하는, 로봇 설정 방법."}
{"patent_id": "10-2021-0189697", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서,상기 손 제스처를 확인하는 단계는,상기 관리자가 착용한 헤드 마운티드 디스플레이를 통해 상기 관리자의 손 제스처를 이미지로 획득하고, 획득한이미지에서 상기 손 좌표들을 확인하는, 로봇 설정 방법.공개특허 10-2023-0100101-3-청구항 6 적어도 하나의 프로세서로 구현된 원격 로봇 제어 시스템이 로봇을 제어하는 방법으로서,매장에서 동작하는 상기 로봇으로부터 관리자 호출 신호를 수신하는 단계,상기 관리자 호출 신호에 따라 관리자 단말로 헤드 마운티드 디스플레이의 착용을 지시하는 단계,상기 로봇으로부터 매장 영상을 수신하는 단계,상기 헤드 마운티드 디스플레이로 상기 매장 영상을 제공하고, 상기 헤드 마운티드 디스플레이로부터 관리자의손 제스처를 수신하는 단계, 그리고상기 로봇으로 상기 손 제스처에 매핑된 기능을 실행하도록 제어 신호를 전송하는 단계를 포함하는, 로봇 제어 방법."}
{"patent_id": "10-2021-0189697", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제6항에 있어서,상기 관리자 호출 신호를 수신하는 단계 이전에,상기 로봇과 상기 매장을 상기 가상 로봇과 가상 현실 매장으로 구현하는 단계,상기 가상 현실 매장에 구현된 복수의 가상 객체들 중 임의의 가상 객체를 대상으로 상기 가상 로봇이 특정 기능을 동작하도록 제어하는 단계, 그리고상기 가상 로봇이 상기 특정 기능을 성공적으로 실행하면, 상기 가상 로봇이 취한 동작과 상기 특정 기능의 결과 정보를 포함하는 학습 데이터로, 상기 원격의 로봇에 탑재될 상기 프로그램을 학습시키는 단계를 포함하는, 로봇 제어 방법."}
{"patent_id": "10-2021-0189697", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서,상기 가상 로봇이 특정 기능을 동작하도록 제어하는 단계는,상기 가상 로봇이 동작할 상기 특정 기능에 대응하여 상기 관리자가 취하는 손 제스처를 확인하는 단계, 그리고상기 손 제스처에 해당하는 상기 특정 기능을 상기 가상 로봇이 수행하면, 상기 기능을 성공적으로 수행되었는지 확인하는 단계를 포함하는, 로봇 제어 방법."}
{"patent_id": "10-2021-0189697", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제6항에 있어서,상기 헤드 마운티드 디스플레이로 제공되는 화면은 상기 로봇 시선에서 바라보는 매장의 화면에 해당하는, 로봇제어 방법."}
{"patent_id": "10-2021-0189697", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "매장에서 동작하는 로봇을 제어하는 로봇 제어 시스템으로서,상기 로봇에 구비된 카메라로부터 촬영한 상기 매장의 화면과, 상기 로봇을 원격에서 제어하는 관리자를 호출하는 관리자 호출 신호를 수신하는 인터페이스, 그리고프로세서를 포함하고,상기 프로세서는,상기 매장과 동일하게 가상 현실 매장을 생성하고 상기 로봇에 대응하는 가상 로봇을 생성하며, 상기 가상 로봇공개특허 10-2023-0100101-4-이 상기 가상 현실 매장에서 동작하면서 수집한 학습 데이터로 상기 로봇에 탑재될 프로그램을 학습시키고, 상기 관리자가 상기 매장의 화면을 헤드 마운티드 디스플레이를 통해 확인하면서 학습된 프로그램이 탑재된 상기로봇이 실행할 기능에 대응하는 손 제스처를 취하면, 상기 손 제스처에 대응하는 상기 기능을 상기 로봇이 실행하도록 제어 신호를 생성하는, 로봇 제어 시스템."}
{"patent_id": "10-2021-0189697", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제10항에 있어서,상기 프로세서는,상기 관리자가 상기 가상 현실 매장에서 상기 가상 로봇이 임의의 가상 객체를 대상으로 수행할 기능에 해당하는 손 제스처를 취하면, 상기 손 제스처를 확인하는, 로봇 제어 시스템."}
{"patent_id": "10-2021-0189697", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항에 있어서,상기 프로세서는,상기 손 제스처에 해당하는 상기 기능을 상기 가상 로봇이 가상 객체를 대상으로 성공적으로 수행하면, 상기 가상 로봇에 구현된 팔의 관절 각도와 상기 가상 로봇과 상기 가상 객체 사이의 거리 정보, 그리고 상기 기능이수행된 결과를 포함하는 학습 데이터로, 상기 원격의 로봇에 탑재될 프로그램을 학습시키는, 로봇 제어 시스템."}
{"patent_id": "10-2021-0189697", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제12항에 있어서,상기 프로세서는,상기 관리자의 손에 복수의 손 좌표들이 기 설정되어 있으며, 상기 관리자의 각 손 좌표들을 인식하여 상기 손제스처를 확인하는, 로봇 제어 시스템."}
{"patent_id": "10-2021-0189697", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제13항에 있어서,상기 프로세서는,상기 로봇에 구비된 깊이 카메라를 통해 상기 헤드 마운티드 디스플레이에 표시되는 2차원 평면의 가상 객체와상기 가상 로봇 사이의 거리 또는 상기 매장의 객체에 대한 화면과 상기 로봇 사이의 거리를 계산하는, 로봇 제어 시스템."}
{"patent_id": "10-2021-0189697", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제14항에 있어서,상기 프로세서는,강화 학습을 통해 상기 가상 로봇과 상기 가상 객체 사이의 최적 거리와 상기 가상 로봇의 팔의 링크 회전각을계산하는, 로봇 제어 시스템."}
{"patent_id": "10-2021-0189697", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "로봇의 지역 맵 생성 방법으로서, 관리자의 손 제스처를 확인하면, 손 제스처에 해당하는 기능을 로봇에 대응하 며 로봇에 삽입될 프로그램을 포함하는 가상 로봇을 제어한다. 가상 로봇이 가상 객체를 대상으로 기능을 수행하 면서 프로그램을 학습시키고, 가상 로봇이 학습시킨 프로그램으로 로봇을 설정한다."}
{"patent_id": "10-2021-0189697", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 비대면 서비스를 제공하는 서비스 로봇을 원격지에서 가상 현실과 핸드 제스처 인식을 통해 제어하는 로봇 제어 시스템 및 이를 이용한 로봇 설정 방법 및 로봇 제어 방법에 관한 것이다."}
{"patent_id": "10-2021-0189697", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "서비스 로봇을 포함한 로봇 산업에서 사용되는 로봇들은, 미리 프로그래밍 된 동작만 수행한다. 그리고 로봇에 새로운 기능을 적용하려면 다시 프로그래밍하여, 펌웨어를 업데이트해야 한다. 따라서, 펌웨어가 업데이트되는동안 로봇은 서비스를 제공하지 못하므로, 서비스 로봇을 한 대 만 사용해서는 고객의 요구사항을 유연하게 응 대하기 어렵다. 이를 해결하기 위하여 인공지능 등 많은 연구들이 이루어지고 있다. 하지만, 인공지능을 이용한 방식을 이용하 여 로봇에 적용한다 하더라도, AI 개발자가 미리 예상한 시나리오를 로봇에게 학습하는 것이기 때문에, 고객의 돌발적인 시나리오를 해소해 주기 어렵다. 즉, 모든 상황을 프로그래밍화 할 수 없기 때문에, 고객이 원할 때 유연한 서비스를 제공하기 위해서는 로봇을 유연하게 제어하는 기술이 필요하다. 또한, 딥러닝을 활용하여 로봇을 학습한다 하더라도, 로봇이 투입되는 실제 현장에서 로봇을 학습시키기에는 충 돌과 파손 등 학습 여건을 구성하기 어렵다. 따라서 현장에서 로봇을 학습시키지 않고 다른 대안이 요구된다."}
{"patent_id": "10-2021-0189697", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "따라서, 본 발명은 코로나로 인하여 비대면 서비스가 중요해진 시점에 서비스 로봇을 가상 현실을 활용하여 원 격으로 제어하여, 유연한 고객 응대가 가능한 로봇 제어 시스템 및 이를 이용한 로봇 설정 방법 및 로봇 제어 방법을 제공한다."}
{"patent_id": "10-2021-0189697", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기 본 발명의 기술적 과제를 달성하기 위한 본 발명의 하나의 특징인 적어도 하나의 프로세서로 구현된 로봇 제어 시스템이 로봇을 설정하는 방법으로서, 관리자의 손 제스처를 확인하는 단계, 상기 손 제스처에 해당하는 기능을 가상 로봇이 수행하도록, 상기 로봇에 삽입될 프로그램을 포함하며 상기 로봇에 대응하는 상기 가상 로봇을 제어하는 단계, 상기 가상 로봇이 가상 객 체를 대상으로 상기 기능을 수행하면서 상기 프로그램을 학습시키는 단계, 그리고 상기 가상 로봇이 학습시킨 상기 프로그램으로 상기 로봇을 설정하는 단계를 포함한다. 상기 손 제스처를 확인하는 단계 이전에, 상기 로봇에 매핑된 가상 로봇을 구현하고, 상기 로봇이 동작하는 매 장에 매핑된 가상 현실 매장으로 구현하는 단계를 포함하고, 상기 가상 현실 매장은 상기 임의의 가상 객체를 포함하는 복수의 가상 객체들이 포함되며, 상기 복수의 가상 객체들은 상기 매장에 설치된 객체들에 매핑될 수 있다. 상기 프로그램을 학습시키는 단계는, 상기 기능이 성공적으로 수행되지 않았다면, 상기 가상 로봇이 상기 기능 을 반복적으로 수행하도록 제어하는 단계를 더 포함할 수 있다. 상기 손 제스처를 확인하는 단계는, 상기 관리자의 손에 복수의 손 좌표들이 기 설정되어 있으며, 상기 관리자 의 각 손 좌표들을 인식하여 상기 손 제스처를 확인할 수 있다. 상기 손 제스처를 확인하는 단계는, 상기 관리자가 착용한 헤드 마운티드 디스플레이를 통해 상기 관리자의 손 제스처를 이미지로 획득하고, 획득한 이미지에서 상기 손 좌표들을 확인할 수 있다. 상기 본 발명의 기술적 과제를 달성하기 위한 본 발명의 또 다른 특징인 적어도 하나의 프로세서로 구현된 원격 로봇 제어 시스템이 로봇을 제어하는 방법으로서, 매장에서 동작하는 상기 로봇으로부터 관리자 호출 신호를 수신하는 단계, 상기 관리자 호출 신호에 따라 관리 자 단말로 헤드 마운티드 디스플레이의 착용을 지시하는 단계, 상기 로봇으로부터 매장 영상을 수신하는 단계, 상기 헤드 마운티드 디스플레이로 상기 매장 영상을 제공하고, 상기 헤드 마운티드 디스플레이로부터 관리자의 손 제스처를 수신하는 단계, 그리고 상기 로봇으로 상기 손 제스처에 매핑된 기능을 실행하도록 제어 신호를 전 송하는 단계를 포함한다. 상기 관리자 호출 신호를 수신하는 단계 이전에, 상기 로봇과 상기 매장을 상기 가상 로봇과 가상 현실 매장으 로 구현하는 단계, 상기 가상 현실 매장에 구현된 복수의 가상 객체들 중 임의의 가상 객체를 대상으로 상기 가 상 로봇이 특정 기능을 동작하도록 제어하는 단계, 그리고 상기 가상 로봇이 상기 특정 기능을 성공적으로 실행 하면, 상기 가상 로봇이 취한 동작과 상기 특정 기능의 결과 정보를 포함하는 학습 데이터로, 상기 원격의 로봇 에 탑재될 상기 프로그램을 학습시키는 단계를 포함할 수 있다. 상기 가상 로봇이 특정 기능을 동작하도록 제어하는 단계는, 상기 가상 로봇이 동작할 상기 특정 기능에 대응하 여 상기 관리자가 취하는 손 제스처를 확인하는 단계, 그리고 상기 손 제스처에 해당하는 상기 특정 기능을 상 기 가상 로봇이 수행하면, 상기 기능을 성공적으로 수행되었는지 확인하는 단계를 포함할 수 있다. 상기 헤드 마운티드 디스플레이로 제공되는 화면은 상기 로봇 시선에서 바라보는 매장의 화면에 해당할 수 있다. 상기 본 발명의 기술적 과제를 달성하기 위한 본 발명의 또 다른 특징인 원격의 매장에 투입된 로봇을 제어하는 로봇 제어 시스템으로서, 상기 로봇에 구비된 카메라로부터 촬영한 상기 매장의 화면과, 상기 로봇을 원격에서 제어하는 관리자를 호출하 는 관리자 호출 신호를 수신하는 인터페이스, 그리고 프로세서를 포함하고, 상기 프로세서는, 상기 매장과 동일 하게 가상 현실 매장을 생성하고, 상기 로봇에 대응하는 가상 로봇을 생성하며, 상기 가상 로봇이 상기 가상 현 실 매장에서 동작하면서 수집한 학습 데이터로 상기 로봇에 탑재될 프로그램을 학습시키고, 상기 관리자가 상기 매장의 화면을 헤드 마운티드 디스플레이를 통해 확인하면서 학습된 프로그램이 탑재된 상기 로봇이 실행할 기 능에 대응하는 손 제스처를 취하면, 상기 손 제스처에 대응하는 상기 기능을 상기 로봇이 실행하도록 제어 신호 를 생성한다. 상기 프로세서는, 상기 관리자가 상기 가상 현실 매장에서 상기 가상 로봇이 임의의 가상 객체를 대상으로 수행 할 기능에 해당하는 손 제스처를 취하면, 상기 손 제스처를 확인할 수 있다. 상기 프로세서는, 상기 손 제스처에 해당하는 상기 기능을 상기 가상 로봇이 가상 객체를 대상으로 성공적으로 수행하면, 상기 가상 로봇에 구현된 팔의 관절 각도와 상기 가상 로봇과 상기 가상 객체 사이의 거리 정보, 그 리고 상기 기능이 수행된 결과를 포함하는 학습 데이터로, 상기 원격의 로봇에 탑재될 프로그램을 학습시킬 수 있다. 상기 프로세서는, 상기 관리자의 손에 복수의 손 좌표들이 기 설정되어 있으며, 상기 관리자의 각 손 좌표들을 인식하여 상기 손 제스처를 확인할 수 있다. 상기 프로세서는, 상기 로봇에 구비된 깊이 카메라를 통해 상기 헤드 마운티드 디스플레이에 표시되는 2차원 평 면의 가상 객체와 상기 가상 로봇 사이의 거리 또는 상기 매장의 객체에 대한 화면과 상기 로봇 사이의 거리를 계산할 수 있다. 상기 프로세서는, 강화 학습을 통해 상기 가상 로봇과 상기 가상 객체 사이의 최적 거리와 상기 가상 로봇의 팔 의 링크 회전각을 계산할 수 있다."}
{"patent_id": "10-2021-0189697", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "본 발명에 따르면, 서비스 로봇으로 고객에게 서비스를 제공하면서, 관리자가 서비스 로봇을 호출할 때 가상 현 실을 통해 원격으로 상황을 인식하고 로봇을 제어함으로써, 유연한 고객 응대가 가능하다. 또한, 가상 환경에서 로봇을 구현하여, 사전에 기초가 되는 로봇의 움직임을 정확도 높게 강화 학습함으로써, 실제 상황에서도 로봇을 부드럽고 정확하게 제어할 수 있다. 또한, 가상 환경에서 로봇이 사전에 학습되기 때문에 이를 활용하여 제어하면 매우 정확하고 유연한 서비스 제 공이 가능해진다."}
{"patent_id": "10-2021-0189697", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "아래에서는 첨부한 도면을 참고로 하여 본 발명의 실시예에 대하여 본 발명이 속하는 기술 분야에서 통상의 지 식을 가진 자가 용이하게 실시할 수 있도록 상세히 설명한다. 그러나 본 발명은 여러 가지 상이한 형태로 구현 될 수 있으며 여기에서 설명하는 실시예에 한정되지 않는다. 그리고 도면에서 본 발명을 명확하게 설명하기 위 해서 설명과 관계없는 부분은 생략하였으며, 명세서 전체를 통하여 유사한 부분에 대해서는 유사한 도면 부호를 붙였다. 명세서 전체에서, 어떤 부분이 어떤 구성요소를 \"포함\"한다고 할 때, 이는 특별히 반대되는 기재가 없는 한 다 른 구성요소를 제외하는 것이 아니라 다른 구성요소를 더 포함할 수 있는 것을 의미한다. 이하, 도면을 참조로 하여 본 발명의 실시예에 따른 원격 로봇 제어 시스템 및 가상 현실과 핸드 제스처 인식을 이용한 원격 로봇 제어 방법에 대해 상세히 설명한다. 도 1은 본 발명의 실시예에 따라 원격 로봇 제어 시스템이 적용된 환경의 예시도이다. 도 1에 도시된 바와 같이, 원격 로봇 제어 시스템은 사용자에게 서비스를 제공하기 위해 원격의 매장에 투입된 로봇(이하, 설명의 편의를 위하여 '원격 로봇'이라 지칭함)과, 원격 로봇을 학습시키는 로봇 학습 수 단으로 구성된다. 여기서, 로봇 학습 수단은 가상 로봇 학습 시스템, 가상 로봇 학습 시스템에 의해 가상으로 생 성된 로봇(이하, 설명의 편의를 위해 '가상 로봇'이라 지칭함), 그리고 헤드 마운티드 디스플레이(HMD: Head Mounted Display)를 포함한다. 가상 로봇 학습 시스템은 원격 로봇이 매장에서 서비스를 제공할 수 있도록, 매장 환경과 동일하게 가상 현실에서의 가상 매장을 생성하고, 원격 로봇과 동일하게 가상 로봇을 가상으로 생성한다. 그리 고, 가상 로봇 학습 시스템은 원격 로봇에 탑재될 프로그램을 가상 현실에서 학습시킨다. 한편, 헤드 마운티드 디스플레이는 가상 로봇이 가상 현실로 구현한 가상 매장 환경에서 동작하도록 관리자의 손의 이미지를 기초로 스켈레톤(skeleton) 모델을 생성한다. 그리고, 생성한 스켈레톤 모델을 기초로 관리자 손의 제스처를 인식한다. 이때, 관리자의 손이 향하는 방향을 판단하는데 사용되는 스켈레톤 모델은, 인간의 손에 포함된 뼈 및 관절의 구조와 손의 가동 범위에 관한 정보를 포함하는 3차원 모델이다. 스켈레톤 모델은 관리자의 손의 동작을 기하학 적인 측면에서 분석하기 위한 기준으로 사용된다. 스켈레톤 모델을 통해 관리자의 손의 동작을 분석하는 방법은 이미 알려진 기술로, 본 발명의 실시예에서는 상세한 설명은 생략한다. 원격 로봇은 투입된 매장에서 원격 로봇의 매장을 촬영하는 카메라가 포함되어 있다. 카메라를 통해 촬영한 영상은 원격 로봇에 구비된 통신 모듈을 통해 원격의 관리자가 착용한 헤드 마운티드 디스플레이 로 전달된다. 또한, 원격 로봇은 매장의 지도를 생성하기 위해 매장을 스캔하는 센서를 포함할 수 있다. 본 발명의 실시 예에서는 센서로 3차원 라이다(3D Lidar)를 예로 하여 설명하나, 반드시 이와 같이 한정되는 것은 아니다. 관리자는 헤드 마운티드 디스플레이를 통해 원격 로봇의 시선으로 원격의 매장에 대한 전방 상황을 확인할 수 있다. 그리고, 관리자가 헤드 마운티드 디스플레이를 착용한 채 원격 로봇의 동작을 제어 하기 위한 제스처를 수행하면, 헤드 마운티드 디스플레이는 관리자의 손의 제스처를 인지한다. 그리고, 손 의 제스처에 대응하는 동작을 원격 로봇이 수행하도록 원격 로봇으로 제어 신호를 전송한다. 이때, 관리자의 왼손 제스처는 원격 로봇으로 하여금 왼손 제스처에 따라 기 설정된 기능을 수행하도록 한 다. 그리고, 오른손의 제스처는 원격 로봇으로 하여금 오른손 제스처에 따라 기 설정된 동작을 수행하도록 한다. 여기서, 원격 로봇에 탑재되는 프로그램은 원격 로봇이 매장에 투입되기 전에 로봇 학습 수단에 서 학습된다. 즉, 원격 로봇이 매장에서 주요 서비스를 제공하기 위해 요구되는 동작 또는 기능들을 사전 에 가상 환경에서 학습시킨다. 이를 위해, 로봇 학습 수단의 가상 로봇 학습 시스템은 원격 로봇이 투입되는 매장을 가상 환경 으로 생성한다. 또한, 가상 로봇 학습 시스템은 가상 환경에서 관리자의 손 제스처에 따라 기능과 동작을 수행하며 탑재된 프로그램을 학습할 가상 로봇도 생성한다. 가상 로봇 학습 시스템은 다양한 방법으 로 매장이나 로봇을 가상 환경으로 생성할 수 있으므로, 본 발명의 실시예에서는 어느 하나의 방법으로 한정하 지 않는다. 가상 로봇 학습 시스템이 매장을 가상 환경으로 생성하고 가상 환경 내에 가상 로봇을 배치하면, 관 리자는 헤드 마운티드 디스플레이를 이용하여 가상 환경에 구현된 가상 객체들(예를 들어, 가상 문, 가상 물컵 등)을 이용하여 가상 로봇을 학습시킨다. 즉, 가상 로봇이 가상 객체들에 접근하도록 제어하거나, 접근한 가상 객체들을 이용하도록 동작을 제어한 다. 예를 들어, 관리자는 가상 로봇이 가상 문에 설치된 손잡이를 쥐고 돌리도록 제어할 수 있다. 이때, 관리자가 헤드 마운티드 디스플레이를 착용하고 보는 가상 환경의 화면은 가상 로봇에 구비된 가상 카메라 또는 원격 로봇에 구비된 카메라를 통해 가상 로봇 또는 원격 로봇이 바라보는 환 경이다. 또한, 가상 로봇이 가상 객체들로 접근하거나 가상 객체를 이용하는 동작을 취할 때, 관리자가 헤드 마운 티드 디스플레이를 착용하고 보는 화면과 가상 로봇의 움직임이 다를 수 있다. 예를 들어, 가상 로봇 이 가상 문에 설치된 손잡이를 쥐려고 시도하는 경우, 한 번에 손잡이를 쥘 수 없는 경우가 대부분이다. 따라서, 가상 로봇이 손잡이를 쥘 때까지 반복적으로 시도한 정보를 학습 정보로 수집하고, 가상 로봇 이 최종적으로 손잡이를 쥐었을 때의 정보로 프로그램을 학습시켜 원격 로봇에 탑재한다. 본 발명의 실시예에서는 가상 로봇이 기능을 수행해야 할 가상 객체의 표면에 가상 로봇의 손 부분의 접점 면적 이 80% 이상 닿을 경우, 해당 기능을 성공적으로 수행한 것으로 예를 들어 설명한다. 이에 대해서는 이후 설명 한다. 이와 같은 환경에서, 원격 로봇 제어 시스템이 원격 로봇을 관리자가 제어하는 방법에 대해 도 2를 참조로 설명한다. 도 2는 본 발명의 실시예에 따른 원격의 로봇을 제어하는 방법에 대한 흐름도이다. 도 2에 도시된 바와 같이, 원격 로봇 제어 시스템의 로봇 학습 수단은 원격 로봇이 투입될 매장 내부 와 동일하게 가상 현실의 환경을 구축하고, 가상 현실에서 동작할 가상 로봇을 생성한다. 이때, 가상 로봇 은 매장에 투입될 원격 로봇의 가상 현실 형태로, 원격 로봇에 탑재되는 프로그램을 학습시키는 대상이 된다. 로봇 학습 수단은 가상 현실에서 가상 로봇이 동작하거나 가상 로봇에 부여된 기능을 수행하도 록 관리자가 손으로 제스처를 취하면, 손의 제스처에 따라 가상 로봇이 동작하거나 기능을 수행하면서 가 상 로봇을 학습시킨다(S100). 가상 로봇의 동작이나 기능 수행에 따라 프로그램이 학습되면, 학습된 프로그램을 원격 로봇에 탑재 하여 원격 로봇에 학습된 내용을 적용한다(S200). 그리고, 학습된 프로그램이 탑재된 원격 로봇이 매 장에 투입되어 고객에게 서비스를 제공하는 과정에, 매장을 이용하는 고객이 관리자를 호출하거나 원격 로봇 으로부터 관리자 호출 신호가 발생하면, 이를 수신한 가상 로봇 학습 시스템이 관리자의 단말(도면 미도시)로 헤드 마운티드 디스플레이를 실행시켜 착용할 것을 지시한다. 가상 로봇 학습 시스템이 관 리자에게 헤드 마운티드 디스플레이를 착용하도록 지시하는 방법은 다양하므로, 본 발명의 실시예에서는 어느 하나의 방법으로 한정하지 않는다. 관리자가 헤드 마운티드 디스플레이를 실행시킨 후 착용하면, 헤드 마운티드 디스플레이를 통해 원격 로봇이 수집한 매장 영상을 제공한다. 그리고, 관리자가 원격 로봇이 실행할 기능에 대한 손의 제스 처를 취하면, 헤드 마운티드 디스플레이가 손의 제스처를 확인하여 가상 로봇 학습 시스템으로 전달 하고, 가상 로봇 학습 시스템이 관리자의 손의 제스처에 대응하는 기능을 원격 로봇이 실행하도록 제 어할 수 있다(S300). 여기서, S100 단계에서 가상 현실에서 가상 로봇을 동작시켜, 원격 로봇에 탑재되는 프로그램을 학습 하는 방법에 대해 도 3을 참조로 설명한다. 도 3은 본 발명의 실시예에 따른 가상 현실에서 로봇을 학습시키는 동작 방법의 흐름도이다. 도 3에 도시된 바와 같이, 가상 로봇 학습 시스템은 원격 로봇이 투입될 매장 환경을 가상 현실로 구 현한다(S101). 이때, 가상 환경에서 가상 로봇을 통해 학습된 프로그램이 원격 로봇에 탑재되더라도 실제 매장에서 원격 로봇과 사물 사이의 거리 오차를 최소화하기 위해, 매장의 실제 환경과 매우 유사하게 가상의 매장을 가상 현실로 구현한다. 즉, 실제 매장의 벽이나 기둥과 같이 정적인 객체들뿐만 아니라, 고객들이 이용하는 테이블, 의자 등과 같은 객 체들도 각 객체들의 크기를 반영하여 가상 현실로 구현한다. 가상 로봇 학습 시스템이 가상 현실로 매장 환경을 구현하는 방법은 다양하므로, 본 발명의 실시예에서는 어느 하나의 방법으로 한정하지 않는다. 또한, 가상 로봇 학습 시스템은 가상 현실에서 가상 객체들을 동작시킬 가상 로봇을 구현한다(S102). 이때, 가상 로봇은 매장에 투입되는 원격 로봇과 동일하게 구현된다. 여기서, 가상 로봇 학습 시스템은 원격 로봇에 구비된 센서 즉, 3차원 라이다가 스캔한 스캔 정보를 활용하여, 원격 로봇이 투입된 매장의 3차원 지도와 매장에 구비된 객체들의 모양을 본뜰 수 있다. 또는, 원격 로봇에 구비된 카메라를 활용하여 Visual SLAM 기술을 기초로 매장의 맵과 객체들의 모양을 본뜰 수 있다. 3차원 라이다가 스캔한 스캔 정보 또는 Visual SLAM 기술을 기초로 맵과 객체들의 모양을 본뜨는 방법은 다양한 형태로 구현 가능하므로, 본 발명의 실시예에서는 어느 하나의 방법으로 한정하지 않는다. 가상 현실로 매장 환경과 가상 로봇이 구현된 후, 관리자는 헤드 마운티드 디스플레이를 착용하여 가 상 로봇을 제어하는 손 제스처를 취한다. 그러면, 헤드 마운티드 디스플레이는 관리자가 취한 손의 제스처를 확인하고(S103), 관리자의 손에 기 설정되어 있는 좌표들을 인식하여 가상 로봇 학습 시스템으로 전달한다(S104). 본 발명의 실시예에서는 가상 현실에서 가상 로봇을 학습시킬 때 매번 관리자가 취한 손 의 제스처를 인식하지 않고, 기능 단위(예를 들어, 문에 다가가서 문을 여는 동작 등)로 반복 실행하도록 가상 로봇을 제어하고, 기능을 반복 수행하면서 가상 로봇이 프로그램을 학습시키는 것을 예로 하여 설명 한다. 가상 로봇 학습 시스템은 수신한 좌표들을 기초로 관리자의 손 제스처를 확인하고, 기 저장되어 있는 손 제스처 별 기능들을 가상 로봇이 수행하도록 가상 로봇을 제어한다(S105). 가상 로봇은 해당 기 능을 수행하면서, 원격 로봇에 탑재될 프로그램을 학습시킨다. 가상 로봇 학습 시스템은 가상 로봇 이 해당 기능의 수행을 성공했는지 확인한다(S106). 일반적으로 원격 로봇의 팔에는 촉각이 없으므로, 물체를 제대로 잡았는지를 인지하기 어렵다. 그러나, 유 니티(Unity)나 언리얼(Unreal) 엔진을 사용한 가상 환경에서는 물리 엔진을 활용하여, 프로그래밍으로 가상 로 봇이 물체를 제대로 잡았을 때, 또는 잡아야 할 물체 이외의 것을 잡았을 때 이벤트를 발생시킬 수 있으므 로, 물체를 제대로 잡았는지 인지할 수 있다. 가상 로봇 학습 시스템은 S105 단계의 제어에 따라 가상 로봇이 기능 수행을 성공한 것으로 인지하면, 가상 로봇이 기능을 수행하기 위해 회전시킨 팔의 관절 각도와 객체로부터 가상 로봇까지 의 거리 정보 등을 포함하는 기능 수행 정보와, 해당 기능을 수행하였을 때의 결과를 수집한다(S107). 그리고, 가상 로봇 학습 시스템은 S107 단계까지 가상 로봇에 의해 학습된 프로그램을 원격 로봇에 탑재 하여, 원격 로봇을 설정한다(S108). 여기서, 가상 로봇 학습 시스템은 가상 로봇에서 가상 객체 사이의 거리는 가상 공간상의 단위인 유 닛(Unit) 당 거리로 환산하여 정보를 획득할 수 있다. 이를 위해서는, 원격 로봇이 투입되는 매장을 실측 한 맵으로 가상 공간의 매장이 구현되어 있어야 한다. 그리고, 가상 로봇 학습 시스템은 가상 로봇의 팔의 각 관절의 회전 각도를 가상 로봇과 가상 객체 사이의 거리를 기초로, 역 기구학으로 각 관절마다 각도를 얼마나 조절했을 때 해당 가상 객체에 닿는지 계산할 수 있다. 가상 로봇 학습 시스템이 역 기구학(IK: Inverse Kinematics)으로 가상 로봇의 각 관절의 회전 각도를 계산하는 방법은 이미 알려진 기술로, 본 발명의 실시예에서는 상세한 설명을 생략한다. 한편, S106 단계에서 확인한 결과, 가상 로봇이 목표로 하는 기능을 수행하지 못했다면, 가상 로봇 학습 시스템은 해당 기능을 반복 수행하도록 가상 로봇을 제어한다(S109). 가상 로봇은 해당 기능을 반복 수행하면서, 프로그램을 계속 학습시킨다. 상술한 절차를 통해 학습된 프로그램이 탑재된 원격 로봇을 원격지에 있는 관리자가 손의 제스처로 원격 로봇이 수행할 기능을 선택할 때, 가상 로봇 학습 시스템이 관리자의 손의 제스처를 인지하기 위한핸드 좌표 인식에 대해 도 4를 참조로 설명한다. 도 4는 본 발명의 실시예에 따른 핸드 좌표 인식을 나타낸 예시도이다. 헤드 마운티드 디스플레이가 원격 로봇 또는 가상 로봇의 기능을 제어하기 위해 제스처를 취하 는 관리자의 손의 스켈레톤을 추출하기 위해, 도 4에 도시된 바와 같이 모션 제스처 알고리즘을 활용하여 손바 닥 및 손가락에 기 설정된 포인트들을 추출한다. 본 발명의 실시예에서는 도 4에 도시된 바와 같이 21개의 포인트가 손에 부여되어 있는 것을 예로 하여 설명하 나, 반드시 이와 같이 한정되는 것은 아니다. 그리고, 헤드 마운티드 디스플레이는 손에 부여된 포인트들 을 추출하여, 손의 제스처 인식에 활용한다. 헤드 마운티드 디스플레이가 포인트들을 추출하여 관리자가 취하는 손의 제스처를 인식하는 방법은 다양하므로, 본 발명의 실시예에서는 어느 하나의 방법으로 한정하지 않 는다. 다음은 헤드 마운티드 디스플레이가 인식한 손의 제스처에 따라 원격 로봇 또는 가상 로봇이 실 행할 기능에 대해 도 5를 참조로 설명한다. 도 5는 본 발명의 실시예에 따른 손 동작과 그에 따른 기능을 나타낸 예시도이다. 상술한 도 4를 통해 손가락의 21개의 포인트를 추출하여 핸드 제스처를 인식한 후, 헤드 마운티드 디스플레이 는 도 5에 도시된 바와 같이 관리자의 왼손과 오른손의 제스처에 기 매핑된 동작 또는 기능이 무엇인지 확 인한다. 도 5의 제1 영역(①)에는 왼손에 매핑된 기능들을 나타낸 예시도이고, 제2 영역(②)에는 오른손에 매핑된 동작 들의 예시도이다. 즉, 본 발명의 실시예에서는 관리자의 왼손이 취하는 제스처를 기초로 가상 로봇 또는 원격 로봇이 기능을 실행한다. 그리고 관리자의 오른손이 취하는 제스처는 가상 로봇 또는 원격 로봇 이 인식할 사물의 사물 영역을 설정하거나, 왼손이 취하는 제스처에 따라 가상 로봇 또는 원격 로봇 이 기능을 실행하도록 제어한다. 예를 들어, 관리자가 문 손잡이나 컵 등의 사물에 대한 원격 로봇의 동작 또는 기능을 지정하고자 할 때, 사물 의 객체 인식 기술이 필요하다. 본 발명의 실시예에서는 높은 정확도로 사물을 인식하기 위하여, 관리자가 오른 쪽 손의 검지를 펴서 목표로 하는 사물을 인식할 수 있는 사물 영역을 설정함으로써, 원격 로봇 또는 가상 로봇이 사물 영역 내에서 높은 정확도로 사물을 인식할 수 있도록 한다. 또한, 본 발명의 실시예에서는 관리자의 왼손이 취하는 제스처는 가상 로봇 또는 원격 로봇의 기능을 실행하도록 한다. 즉, 사물 영역을 설정한 후 관리자는 가상 로봇 또는 원격 로봇이 사물 영역에 위 치한 객체인 문고리로 이동하도록 이동 제스처를 취할 수도 있고 문고리를 잡도록 동작 제스처를 취할 수도 있 다. 이때, 왼손은 기능을 나타내고 오른손은 실행을 나타내기 때문에, 본 발명의 실시예에서는 원격 로봇 또는 가상 로봇의 팔(arm)은 1개인 것을 예로 하여 설명한다. 그러나, 반드시 이와 같이 한정되는 것은 아니다. 헤드 마운티드 디스플레이가 관리자의 제스처를 인식하였다면, 원격 로봇 또는 가상 로봇의 팔 이 해당 제스처에 매핑된 기능을 수행해야 한다. 이를 위해, 원격 로봇에 구비된 카메라로 수집한 화면을 헤드 마운티드 디스플레이와 공유하고, 원격 로봇 또는 가상 로봇이 최종 목적지에 근접하여 팔 의 관절을 움직이도록 하는 기능을 구현해야 한다. 실제 원격 로봇이 움직이는 공간은 3차원 입체 공간이지만, 헤드 마운티드 디스플레이를 통해 관리자 가 보는 화면은 2차원 평면이다. 따라서, 원격 로봇은 3차원의 최종 좌표에 맞춰 관절을 움직여야 하는데, 본 발명의 실시예에서는 역기구학을 응용하여 원격 로봇의 관절이 움직이도록 구현한다. 이때, 역기구학을 활용할 경우 2차원 평면상의 좌표에 로봇 팔의 끝을 올려 놓을 수는 있지만, 헤드 마운티드 디스플레이로 보는 화면에는 거리가 없다. 따라서, 정확한 역기구학을 위하여 원격 로봇에 구비되는 카메라는 깊이(Depth) 카메라를 사용하고, 깊이 카메라를 통해 2차원 평면상 객체와 가상 로봇의 거리를 계산한다. 즉, 원격 로봇은 3차원 라이다나 Visual SLAM을 활용하여, 사전에 스캔한 지도를 활용하여 이동할 수 있다. 원격 로봇이 지도를 활용하여 매장 내를 이동하면서, 깊이 카메라를 이용하여 매장 내에 구비되어 있는 객체들과의 거리를 측정한다.가상 로봇 학습 시스템은 원격 로봇이 계산한 객체와의 거리를 기초로, 신경망 학습 알고리즘에서 사 용되는 predict 함수에 거리 정보와 2차원 평면상 객체의 좌표를 매개변수로 입력한다. 여기서 신경망 학습 알 고리즘은 원격 로봇에 탑재된 프로그램을 학습시키기 위해 가상 로봇 학습 시스템에 구현되어 있다. 그리고, 가상 로봇 학습 시스템은 가상 현실에서 가상 로봇을 학습시킬 때 확인한 거리 정보와 가상 로봇의 관절 각도 정보를 참조하여, 원격 로봇 객체까지의 거리를 좁히고, 관절 각도 정보를 참조로 관절을 움직이는 동작을 수행하도록 제어 신호를 전송한다. 이때, 원격 로봇이 사물에 도달할 위치를 나타내는 예에 대해 도 6을 참조로 설명한다. 도 6은 본 발명의 실시예에 따라 원격 로봇이 사물에 도달할 위치를 나타낸 그래프이다. 도 6에 도시된 바와 같이, 가상 로봇 학습 시스템은 역기구학을 활용하여 가상 로봇의 링크를 얼만큼 회전해야 관리자에 의해 선택된 가상 객체가 있는 목표 위치에 도달하는지를 계산할 수 있다. 하지만 실제 상황 에서는 (0,0)에 해당하는 좌표(③)가 원격 로봇의 본체 위치가 되므로, 도달해야 하는 목표점인 사물과의 거리가 가변적이다. 여기서, P(x,y)가 원격 로봇의 손 위치이고, θ1, θ2, θ3는 원격 로봇의 팔에 구비된 관절의 각도를 의미한다. 따라서, 로봇과 사물 사이의 거리 오차를 최소화하기 위하여, 가상 로봇 학습 시스템은 가상공간에 가상 로봇을 구현하여, 시뮬레이션을 통해 원격 로봇이 주로 사용하는 동작들(예를 들어, 물병 집기, 문 열기 등)을 올바르게 수행할 수 있도록 강화 학습을 적용한다. 이와 같은 강화 학습을 통해, 가상 로봇 학습 시 스템은 상황에 맞는 최적의 거리와 링크 회전각을 알아 낼 수 있다. 이를 위해, 가상 로봇 학습 시스템이 생성하는 가상 공간은 원격 로봇이 투입되는 매장의 실제 환경 과 매우 유사하게 구현되어야 한다. 그리고, 원격 로봇이나 매장에 위치한 객체들의 실측 데이터를 가상 공간의 유닛 단위와 매칭하여 구성한다. 여기서 유닛 단위라 함은, 실측 데이터를 기반으로 구현한 가상 현실의 단위 유닛 당 거리를 의미한다. 예를 들어, 상술한 도 1의 가상 현실 화면에서, 가상 로봇이 탁자 위에 물컵을 집는 동작의 명령을 수행하 였다면, 가상 로봇의 위치에서 물컵까지의 거리가 짧지는 않은지, 물컵을 제대로 집어서 선반과 같은 다른 위치에 옮겼는지 등으로 리워드(Reward) 즉, 가중치를 적용하여, 실제 환경에서 안전상의 이유 등으로 원격 로 봇을 학습시킬 수 없는 행위를 가상 공간에서 미리 학습시켜 원격 로봇에 적용하는 방식을 사용한다. 즉, 가상 로봇이 제대로 동작하였을 때, 가중치를 적용하여 원격 로봇에 탑재될 프로그램을 학습시킨 다. 그리고, 원격 로봇의 팔에는 촉각이 없으므로, 물체를 제대로 잡았는지를 인지하기 어렵다. 그러나, 유니 티(Unity)나 언리얼(Unreal) 엔진을 사용한 가상 환경에서는 물리 엔진을 활용하여, 프로그래밍으로 가상 로봇 이 잡아야 할 물체 이외의 것을 잡았을 때 이벤트를 발생시킬 수 있으므로, 물체를 제대로 잡았는지 인지 할 수 있다. 단, 실제 상황에서 얻을 수 없는 정보를 바탕으로 원격 로봇을 제어할 때, 실제 상황에서는 동작할 수 없 을 가능성이 있다. 따라서, 실제 상황에서의 변수인 카메라 화면상의 객체 정보와 깊이 카메라를 활용한 거리, 원격 로봇의 이동 및 관절 회전각을 활용해서만 제어한다. 여기서, 객체 정보에는 카메라 화면상의 객체와, 해당 객체의 화면상의 위치, 그리고 깊이 카메라에 의해 계산된 객체의 거리 값을 포함한다. 도 7은 본 발명의 실시예에 따른 로봇의 구조도이다. 도 7에 도시된 바와 같이, 원격 로봇은 버스를 통해 통신하는 프로세서, 메모리, 정보 수 집 수단, 인터페이스, 저장 장치 그리고 구동 장치를 포함한다. 프로세서는 로봇의 동작을 제어하는 장치로서, 프로그램에 포함된 명령들을 처리하는 다양한 형태의 프로세서일 수 있고, 예를 들면, CPU(Central Processing Unit), MPU(Micro Processor Unit), MCU(Micro Controller Unit), GPU(Graphic Processing Unit) 등 일 수 있다. 또는 프로세서는 메모리 또는 저 장 장치에 저장된 명령을 실행하는 반도체 장치일 수 있다. 프로세서는 상술한 기능들 및 방법을 실 행하도록 구성될 수 있다. 메모리는 다양한 형태의 휘발성 또는 비휘발성 저장 매체를 포함할 수 있다. 예를 들어, 메모리는 본 발명의 동작을 실행하도록 기술된 명령들이 프로세서에 의해 처리되도록 해당 프로그램을 로드하며,ROM(read only memory) 및 RAM(random access memory)를 포함할 수 있다. 본 발명의 실시예에서 메모리는 프로세서의 내부 또는 외부에 위치할 수 있고, 메모리는 이미 알려진 다양한 수단을 통해 프로세서와 연결될 수 있다. 정보 수집 수단은 본 발명의 동작에 따라 주행 중인 원격 로봇이 정보를 수집하는 다양한 센서(예를 들어, 라이다, 깊이 카메라, 관성 측정 장치(IMU: Inertial Measurement Unit) 등)들에 해당한다. 본 발명의 실시예에서는 정보 수집 수단으로 깊이 카메라를 이용하는 것을 예로 하여 설명하나, 반드시 이와 같이 한 정되는 것은 아니다. 인터페이스는 로봇 학습 수단과 연동하며, 원격 로봇이 수집한 매장의 영상이나 원격 로봇(10 0)에서 요청되는 요청 신호를 로봇 학습 수단의 헤드 마운티드 디스플레이를 착용한 관리자에게 전달 한다. 또한 인터페이스는 헤드 마운티드 디스플레이로부터 전송되는 제어 신호를 수신하여 프로세서 로 전달할 수도 있다. 저장 장치는 원격 로봇이 주행하는 공간의 지역 맵을 저장할 수 있다. 구동 장치는 프로세서의 제어에 따라 원격 로봇이 투입된 공간에서 주행되도록 하거나, 특정 객 체 방향으로 이동하도록 한다. 도 8은 본 발명의 실시예에 따라 관리자가 착용하는 헤드 마운티드 디스플레이의 구조도이다. 도 8에 도시된 바와 같이, 일부 실시예에 따른 헤드 마운티드 디스플레이는 프로세서, 투명 디스플레 이, 카메라, 메모리 및 통신부를 포함한다. 프로세서는 투명 디스플레이를 통해 디스플레이 영역 내에 적어도 하나의 가상 객체 또는 원격의 매 장에 위치한 객체를 표시하도록 제어한다. 프로세서는 카메라를 통해, 디스플레이 영역에 표시된 객 체와 인터랙션하는 관리자의 손을 촬영하도록 제어할 수 있다. 프로세서는, 예를 들어, 카메라를 통해 촬영된 이미지에 기초하여 관리자의 손의 디스플레이 영역 상 의 위치, 형상 또는 이동 방향 중 적어도 하나에 관한 정보를 획득할 수 있다. 프로세서는 카메라를 통해 촬영된 이미지에 기초하여 디스플레이 영역에 표시된 객체와 인터랙션하는 관리자의 손이 향하는 방향을 판단할 수 있다. 프로세서는, 관리자의 손의 바닥 면과 투명 디스플레이의 표면 사이의 각도를 측정하고, 측정된 각도 에 기초하여 관리자의 손의 방향을 판단할 수 있다. 또한, 프로세서는, 관리자의 손의 방향을, 관리자의 손의 바닥 면이 투명 디스플레이를 향하는 내측 방향 및 관리자의 손의 바닥 면이 투명 디스플레이의 반대 방향을 향하는 외측 방향 중 어느 하나로 구분할 수 있다. 프로세서는 관리자의 손과 인터랙션하는 객체 및 관리자의 손이 향하는 방향에 매칭된 소정의 기능을 실행 할 수 있다. 프로세서는, 관리자의 손에 과 인터랙션하는 객체가 플로팅 객체이고, 관리자의 손이 향하는 방향이 내측 방향인 경우, 관리자의 손과 인터랙하는 플로팅 객체에 대응되는 소정의 기능을 실행할 수 있다. 프로세서는, 투명 디스플레이 및 상기 손 사이의 거리가 임계 거리 이하의 거리로 전환될 경우, 상기 플로팅 객체에 대한 인터랙션이 이루어진 것으로 판단할 수 있다. 또한, 프로세서는, 관리자의 손과 인터 랙션하는 객체가 배경 객체이고, 관리자의 손이 향하는 방향이 외측 방향인 경우, 관리자의 손과 인터랙하는 배 경 객체에 대응되는 소정의 기능을 실행할 수 있다. 프로세서는, 촬영된 이미지에 기초하여, 객체와 인터랙션하는 관리자의 손의 깊이를 식별하고, 식별된 손 의 깊이 및 객체의 종류에 기초하여, 디스플레이 영역 내에서 관리자의 손과 객체가 중첩되는 영역에 객체를 표 시할지 여부를 판단할 수 있다. 투명 디스플레이는 가상 현실로 구현한 적어도 하나의 가상 객체 또는 원격 매장에 위치한 객체 중 적어도 하나의 객체를 표시할 수 있다. 투명 디스플레이를 통해 적어도 하나의 객체가 표시되면, 관리자는 디스플 레이 영역 상의 특정 위치에 객체가 표시되는 것으로 인식한다. 투명 디스플레이는 헤드 마운티드 디스플레이의 제어를 위한 사용자 인터페이스, 헤드 마운티드 디스 플레이의 상태 표시를 위한 사용자 인터페이스 등을 표시할 수 있다. 메모리는 헤드 마운티드 디스플레이의 동작을 제어하기 위한 프로그램을 저장할 수 있다. 메모리 는 헤드 마운티드 디스플레이의 동작을 제어하기 위한 적어도 하나의 인스트럭션을 포함할 수 있다. 메모리에 저장된 프로그램들은 그 기능에 따라 복수 개의 모듈들로 분류될 수 있다. 메모리는 플래시 메모리 타입(flash memory type), 하드디스크 타입(hard disk type), 멀티미디어 카드 마이크로 타입(multimedia card micro type), 카드 타입의 메모리(예를 들어 SD 또는 XD 메모리 등), 램(RAM, Random Access Memory) SRAM(Static Random Access Memory), 롬(ROM, Read-Only Memory), EEPROM(Electrically Erasable Programmable Read-Only Memory), PROM(Programmable Read-Only Memory), 자기 메모리, 자기 디스크, 광디스크 중 적어도 하나의 타입의 저장매체를 포함할 수 있다. 통신부는 외부 장치와의 통신을 위한 하나 이상의 통신 모듈을 포함할 수 있다. 예를 들어, 통신부는, 근거리 통신부, 이동 통신부를 포함할 수 있으며, 어느 하나의 통신 프로토콜로 한정하지 않는 다. 이상에서 본 발명의 실시예에 대하여 상세하게 설명하였지만 본 발명의 권리범위는 이에 한정되는 것은 아니고 다음의 청구범위에서 정의하고 있는 본 발명의 기본 개념을 이용한 당업자의 여러 변형 및 개량 형태 또한 본 발명의 권리범위에 속하는 것이다."}
{"patent_id": "10-2021-0189697", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 실시예에 따라 원격 로봇 제어 시스템이 적용된 환경의 예시도이다. 도 2는 본 발명의 실시예에 따른 원격의 로봇을 제어하는 방법에 대한 흐름도이다. 도 3은 본 발명의 실시예에 따른 가상 현실에서 로봇을 학습시키는 동작 방법의 흐름도이다. 도 4는 본 발명의 실시예에 따른 핸드 좌표 인식을 나타낸 예시도이다. 도 5는 본 발명의 실시예에 따른 손 동작과 그에 따른 기능을 나타낸 예시도이다. 도 6은 본 발명의 실시예에 따라 원격 로봇이 사물에 도달할 위치를 나타낸 그래프이다. 도 7은 본 발명의 실시예에 따른 로봇의 구조도이다.도 8은 본 발명의 실시예에 따라 관리자가 착용하는 헤드 마운티드 디스플레이의 구조도이다."}
