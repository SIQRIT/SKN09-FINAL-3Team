{"patent_id": "10-2019-0162644", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2021-0072384", "출원번호": "10-2019-0162644", "발명의 명칭": "전자 장치 및 이의 제어 방법", "출원인": "삼성전자주식회사", "발명자": "황인우"}}
{"patent_id": "10-2019-0162644", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "전자 장치에 있어서, 입력부; 및 상기 입력부를 통해 오디오 신호가 수신되면, 상기 오디오 신호에 기초하여 상기 오디오 신호에 포함된 음성의명료도를 판단하고(identify), 상기 음성의 명료도가 상기 오디오 신호에 포함된 오디오 종류에 관한 씬(scene)정보에 기초하여 설정된 타겟 명료도가 되도록 상기 오디오 신호를 보정하는 프로세서;를 포함하고, 상기 오디오 종류는, 효과음, 함성, 음악 및 음성 중 적어도 하나를 포함하는 전자 장치."}
{"patent_id": "10-2019-0162644", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1 항에 있어서, 상기 프로세서는, 상기 오디오 신호에 포함된, 음성 신호 및 상기 음성 신호를 제외한 비음성 신호에 기초하여, 상기 음성의 명료도를 산출하는 것을 특징으로 하는 전자 장치."}
{"patent_id": "10-2019-0162644", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 2 항에 있어서, 상기 프로세서는, 오디오 신호에 포함된 음성 신호를 추출하도록 학습된 인공 지능 모델을 이용하여 상기 오디오 신호에 포함된음성 신호를 추출하고, 상기 오디오 신호에서 상기 추출된 음성 신호를 제외한 나머지 신호를 상기 비음성 신호로 추출하는 것을 특징으로 하는 전자 장치."}
{"patent_id": "10-2019-0162644", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 2 항에 있어서, 상기 명료도는, 상기 오디오 신호에 포함된 상기 음성 신호와 상기 비음성 신호의 신호 대 잡음비(Signal to Noise Ratio, SNR)및 상기 음성 신호와 상기 비음성 신호에 기초한 어음 명료도 지수(Speech Intelligibility Index, SII) 중 어느 하나인 것을 특징으로 하는 전자 장치."}
{"patent_id": "10-2019-0162644", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제 4 항에 있어서, 상기 프로세서는, 상기 명료도가 상기 신호 대 잡음비인 경우, 상기 타겟 명료도와 상기 판단된 음성의 명료도의 차이 값만큼 상기 음성 신호의 이득을 조정하여 상기 오디오 신호를 보정하는 것을 특징으로 하는 전자 장치."}
{"patent_id": "10-2019-0162644", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제 4 항에 있어서, 상기 프로세서는, 상기 명료도가 어음 명료도 지수인 경우, 아래 수학식에 기초하여 이득 조정값을 산출하고, 상기 산출된 이득조정값만큼 상기 음성 신호의 이득을 조정하여 상기 오디오 신호를 보정하는 것을 특징으로 하는 전자 장치. 공개특허 10-2021-0072384-3-이득 조정값 = α*(SII타겟-SII측정)+β 여기서, SII타겟은 상기 타겟 명료도, SII측정은 상기 판단된 음성의 명료도, α 및 β는 음성 신호의 이득 변화에따른 어음 명료도 지수의 수치 변화를 통해 실험적으로 산출한 상수값들이다."}
{"patent_id": "10-2019-0162644", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제 1 항에 있어서, 상기 프로세서는, 상기 오디오 신호에 대한 적어도 하나의 오디오 특징(audio feature)을 획득하고, 상기 획득된 적어도 하나의오디오 특징에 기초하여 상기 씬 정보를 획득하는 것을 특징으로 하는 전자 장치."}
{"patent_id": "10-2019-0162644", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제 1 항에 있어서, 상기 프로세서는, 오디오 신호에 포함된 오디오 종류를 식별하도록 학습된 인공 지능 모델을 이용하여 상기 씬 정보를 획득하는것을 특징으로 하는 전자 장치."}
{"patent_id": "10-2019-0162644", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제 1 항에 있어서, 상기 타겟 명료도는, 상기 오디오 종류마다 상이하게 설정되는 것을 특징으로 하는 전자 장치."}
{"patent_id": "10-2019-0162644", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제 1 항에 있어서, 상기 타겟 명료도는, 상기 오디오 종류가 상기 효과음인 경우, 상기 오디오 종류가 상기 함성인 경우보다 높게 설정되는 것을 특징으로 하는 전자 장치."}
{"patent_id": "10-2019-0162644", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "전자 장치의 제어 방법에 있어서, 오디오 신호를 수신하는 단계; 상기 오디오 신호에 기초하여 상기 오디오 신호에 포함된 음성의 명료도를 판단하는 단계; 및 상기 음성의 명료도가 상기 오디오 신호에 포함된 오디오 종류에 관한 씬(scene) 정보에 기초하여 설정된 타겟명료도가 되도록 상기 오디오 신호를 보정하는 단계;를 포함하고, 상기 오디오 종류는, 효과음, 함성, 음악 및 음성 중 적어도 하나를 포함하는 제어 방법."}
{"patent_id": "10-2019-0162644", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제 11 항에 있어서, 상기 판단하는 단계는, 상기 오디오 신호에 포함된, 음성 신호 및 상기 음성 신호를 제외한 비음성 신호에 기초하여, 상기 음성의 명료도를 산출하는 단계;를 포함하는 것을 특징으로 하는 제어 방법."}
{"patent_id": "10-2019-0162644", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제 12 항에 있어서, 공개특허 10-2021-0072384-4-상기 판단하는 단계, 오디오 신호에 포함된 음성 신호를 추출하도록 학습된 인공 지능 모델을 이용하여 상기 오디오 신호에 포함된음성 신호를 추출하고, 상기 오디오 신호에서 상기 추출된 음성 신호를 제외한 나머지 신호를 상기 비음성 신호로 추출하는 단계;를 포함하는 것을 특징으로 하는 제어 방법."}
{"patent_id": "10-2019-0162644", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제 12 항에 있어서, 상기 명료도는, 상기 오디오 신호에 포함된 상기 음성 신호와 상기 비음성 신호의 신호 대 잡음비(Signal to Noise Ratio, SNR)및 상기 음성 신호와 상기 비음성 신호에 기초한 어음 명료도 지수(Speech Intelligibility Index, SII) 중 어느 하나인 것을 특징으로 하는 제어 방법."}
{"patent_id": "10-2019-0162644", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제 14 항에 있어서, 상기 보정하는 단계는, 상기 명료도가 상기 신호 대 잡음비인 경우, 상기 타겟 명료도와 상기 판단된 음성의 명료도의 차이 값만큼 상기 음성 신호의 이득을 조정하여 상기 오디오 신호를 보정하는 단계;를 포함하는 것을 특징으로 하는 제어방법."}
{"patent_id": "10-2019-0162644", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제 14 항에 있어서, 상기 보정하는 단계는, 상기 명료도가 어음 명료도 지수인 경우, 아래 수학식에 기초하여 이득 조정값을 산출하고, 상기 산출된 이득조정값만큼 상기 음성 신호의 이득을 조정하여 상기 오디오 신호를 보정하는 단계;를 포함하는 것을 특징으로하는 제어 방법. 이득 조정값 = α*(SII타겟-SII측정)+β 여기서, SII타겟은 상기 타겟 명료도, SII측정은 상기 판단된 음성의 명료도, α 및 β는 음성 신호의 이득 변화에따른 어음 명료도 지수의 수치 변화를 통해 실험적으로 산출한 상수값들이다."}
{"patent_id": "10-2019-0162644", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제 11 항에 있어서, 상기 오디오 신호에 대한 적어도 하나의 오디오 특징(audio feature)을 획득하고, 상기 획득된 적어도 하나의오디오 특징에 기초하여 상기 씬 정보를 획득하는 단계;를 포함하는 것을 특징으로 하는 제어 방법."}
{"patent_id": "10-2019-0162644", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제 11 항에 있어서, 오디오 신호에 포함된 오디오 종류를 식별하도록 학습된 인공 지능 모델을 이용하여 상기 씬 정보를 획득하는단계;를 포함하는 것을 특징으로 하는 제어 방법."}
{"patent_id": "10-2019-0162644", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_19", "content": "제 11 항에 있어서, 상기 타겟 명료도는, 상기 오디오 종류마다 상이하게 설정되는 것을 특징으로 하는 제어 방법. 공개특허 10-2021-0072384-5-청구항 20 제 11 항에 있어서, 상기 타겟 명료도는, 상기 오디오 종류가 상기 효과음인 경우, 상기 오디오 종류가 상기 함성인 경우보다 높게 설정되는 것을 특징으로 하는 제어 방법."}
{"patent_id": "10-2019-0162644", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "전자 장치가 개시된다. 본 전자 장치는, 입력부 및 입력부를 통해 입력된 오디오 신호가 수신되면, 오디오 신호 에 기초하여 오디오 신호에 포함된 음성의 명료도를 판단하고, 음성의 명료도가 오디오 신호에 포함된 오디오 종 류에 관한 씬(scene) 정보에 기초하여 설정된 타겟 명료도가 되도록 오디오 신호를 보정하는 프로세서를 포함하 고, 오디오 종류는, 효과음, 함성, 음악 및 음성 중 적어도 하나를 포함한다."}
{"patent_id": "10-2019-0162644", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 전자 장치 및 이의 제어 방법에 관한 것으로, 보다 상세하게는, 오디오 신호에 포함된 음성의 명료도 를 조절하는 전자 장치 및 이의 제어 방법에 관한 것이다."}
{"patent_id": "10-2019-0162644", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "인터넷 및 스트리밍 서비스의 발달로 수많은 컨텐츠들이 멀티미디어 디바이스 기기에서 소비되고 있다. 이때, 컨텐츠 재생 환경(환경 잡음 등)이나 디바이스 스피커의 한계와 같은 환경요인과, 야외 녹음이나 편집 시간 부 족 등과 같은 컨텐츠 제작요인으로 인하여, 컨텐츠 재생 시 컨텐츠에 포함된 음성이 잘 안 들리는 상황이 자주 발생하고 있다. 구체적으로, 5개 방송사에서 제공되는 24시간 길이의 오디오 신호를 자체 분석한 결과, 음성 컨텐츠의 비율은 91.8%에 육박하며, 음성과 음성 외 나머지 신호의 파워가 동일하여 음성 전달력이 좋지 않은 구간이 30%이상이 라는 통계를 얻었다. 따라서, 컨텐츠의 음성 전달력의 중요성이 대두되고 있다. 한편, 종래에도, 입력되는 오디오 신호의 비음성 음량과 음성 확률을 바탕으로 각 주파수 밴드의 출력을 제어하 여 음성의 명료도를 높이는 기술 존재한다. 그러나, 종래 기술의 경우, 주파수 밴드별 파워의 최소값을 추적하여 비음성 음량을 측정하였는 바, 일정하게 유지되는 비음성 외에 순간적으로 커지는 비음성에 대해서는 제대로 측정이 불가능하며, 녹음 마이크의 감도 문 제나 후보정 등으로 인해 비음성의 측정이 잘 안되는 경우도 많다. 또한, 주파수 밴드별로 음성의 확률을 측정 하여 최종 출력과 관련된 파라미터를 조절하기 때문에, 경우에 따라 동일한 밴드의 음성과 비음성이 함께 커져 서 출력되는 경우가 발생하기 쉽다. 한편, 종래 기술의 경우, 입력되는 모든 종류의 컨텐츠에 대해 단순히 음성 명료도를 높이는 동작만을 수행하므 로, 음성 명료도 조절 시 오디오 컨텐츠의 종류에 따른 제작자의 제작 의도를 반영할 수 없는 문제가 있다."}
{"patent_id": "10-2019-0162644", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 개시는 상술한 문제점에 착안하여 안출된 것으로, 본 개시의 목적은, 보다 정확하게 음성 명료도를 조절할 수 있는 전자 장치 및 이의 제어 방법을 제공함에 있다. 또한, 본 개시의 목적은, 오디오 컨텐츠의 제작 의도를 반영하여 최적의 음성 명료도 조절을 할 수 있는 전자 장치 및 이의 제어 방법을 제공함에 있다."}
{"patent_id": "10-2019-0162644", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기 목적을 달성하기 위한 본 개시의 일 실시 예에 따른 전자 장치는, 입력부 및 상기 입력부를 통해 오디오 신호가 수신되면, 상기 오디오 신호에 기초하여 상기 오디오 신호에 포함된 음성의 명료도를 판단하고, 상기 음 성의 명료도가 상기 오디오 신호에 포함된 오디오 종류에 관한 씬(scene) 정보에 기초하여 설정된 타겟 명료도 가 되도록 상기 오디오 신호를 보정하는 프로세서를 포함하고, 상기 오디오 종류는, 효과음, 함성, 음악 및 음 성 중 적어도 하나를 포함한다. 또한, 상기 프로세서는, 상기 오디오 신호에 포함된, 음성 신호 및 상기 음성 신호를 제외한 비음성 신호에 기 초하여, 상기 음성의 명료도를 산출할 수 있다. 또한, 상기 프로세서는, 오디오 신호에 포함된 음성 신호를 추출하도록 학습된 인공 지능 모델을 이용하여 상기 오디오 신호에 포함된 음성 신호를 추출하고, 상기 오디오 신호에서 상기 추출된 음성 신호를 제외한 나머지 신 호를 상기 비음성 신호로 추출할 수 있다. 또한, 상기 명료도는, 상기 오디오 신호에 포함된 상기 음성 신호와 상기 비음성 신호의 신호 대 잡음비(Signal to Noise Ratio, SNR) 및 상기 음성 신호와 상기 비음성 신호에 기초한 어음 명료도 지수(Speech Intelligibility Index, SII) 중 어느 하나일 수 있다. 또한, 상기 프로세서는, 상기 명료도가 상기 신호 대 잡음비인 경우, 상기 타겟 명료도와 상기 판단된 음성의 명료도의 차이 값만큼 상기 음성 신호의 이득을 조정하여 상기 오디오 신호를 보정할 수 있다. 또한, 상기 프로세서는, 상기 명료도가 어음 명료도 지수인 경우, 아래 수학식에 기초하여 이득 조정값을 산출 하고, 상기 산출된 이득 조정값만큼 상기 음성 신호의 이득을 조정하여 상기 오디오 신호를 보정할 수 있다. 이득 조정값 = α*(SII타겟-SII측정)+β 여기서, SII타겟은 상기 타겟 명료도, SII측정은 상기 판단된 음성의 명료도, α 및 β는 음성 신호의 이득 변화에 따른 어음 명료도 지수의 수치 변화를 통해 실험적으로 산출한 상수값들이다. 또한, 상기 프로세서는, 상기 오디오 신호에 대한 적어도 하나의 오디오 특징(audio feature)을 획득하고, 상기 획득된 적어도 하나의 오디오 특징에 기초하여 상기 씬 정보를 획득할 수 있다. 또한, 상기 프로세서는, 오디오 신호에 포함된 오디오 종류를 식별하도록 학습된 인공 지능 모델을 이용하여 상 기 씬 정보를 획득할 수 있다. 또한, 상기 타겟 명료도는, 상기 오디오 종류마다 상이하게 설정될 수 있다. 또한, 상기 타겟 명료도는, 상기 오디오 종류가 상기 효과음인 경우, 상기 오디오 종류가 상기 함성인 경우보다 높게 설정될 수 있다. 한편, 본 개시의 일 실시 예에 따른 전자 장치의 제어 방법은, 오디오 신호를 수신하는 단계, 상기 오디오 신호 에 기초하여 상기 오디오 신호에 포함된 음성의 명료도를 판단하는 단계 및 상기 음성의 명료도가 상기 오디오 신호에 포함된 오디오 종류에 관한 씬(scene) 정보에 기초하여 설정된 타겟 명료도가 되도록 상기 오디오 신호 를 보정하는 단계를 포함하고, 상기 오디오 종류는, 효과음, 함성, 음악 및 음성 중 적어도 하나를 포함한다. 또한, 상기 판단하는 단계는, 상기 오디오 신호에 포함된, 음성 신호 및 상기 음성 신호를 제외한 비음성 신호 에 기초하여, 상기 음성의 명료도를 산출하는 단계를 포함할 수 있다. 또한, 상기 판단하는 단계, 오디오 신호에 포함된 음성 신호를 추출하도록 학습된 인공 지능 모델을 이용하여 상기 오디오 신호에 포함된 음성 신호를 추출하고, 상기 오디오 신호에서 상기 추출된 음성 신호를 제외한 나머 지 신호를 상기 비음성 신호로 추출하는 단계를 포함할 수 있다. 또한, 상기 명료도는, 상기 오디오 신호에 포함된 상기 음성 신호와 상기 비음성 신호의 신호 대 잡음비(Signal to Noise Ratio, SNR) 및 상기 음성 신호와 상기 비음성 신호에 기초한 어음 명료도 지수(Speech Intelligibility Index, SII) 중 어느 하나일 수 있다. 한, 상기 보정하는 단계는, 상기 명료도가 상기 신호 대 잡음비인 경우, 상기 타겟 명료도와 상기 판단된 음성 의 명료도의 차이 값만큼 상기 음성 신호의 이득을 조정하여 상기 오디오 신호를 보정하는 단계를 포함할 수 있 다. 또한, 상기 보정하는 단계는, 상기 명료도가 어음 명료도 지수인 경우, 아래 수학식에 기초하여 이득 조정값을 산출하고, 상기 산출된 이득 조정값만큼 상기 음성 신호의 이득을 조정하여 상기 오디오 신호를 보정하는 단계 를 포함할 수 있다. 이득 조정값 = α*(SII타겟-SII측정)+β 여기서, SII타겟은 상기 타겟 명료도, SII측정은 상기 판단된 음성의 명료도, α 및 β는 음성 신호의 이득 변화에 따른 어음 명료도 지수의 수치 변화를 통해 실험적으로 산출한 상수값들이다. 또한, 상기 오디오 신호에 대한 적어도 하나의 오디오 특징(audio feature)을 획득하고, 상기 획득된 적어도 하 나의 오디오 특징에 기초하여 상기 씬 정보를 획득하는 단계를 포함할 수 있다. 또한, 오디오 신호에 포함된 오디오 종류를 식별하도록 학습된 인공 지능 모델을 이용하여 상기 씬 정보를 획득 하는 단계를 포함할 수 있다. 또한, 상기 타겟 명료도는, 상기 오디오 종류마다 상이하게 설정될 수 있다. 또한, 상기 타겟 명료도는, 상기 오디오 종류가 상기 효과음인 경우, 상기 오디오 종류가 상기 함성인 경우보다 높게 설정될 수 있다."}
{"patent_id": "10-2019-0162644", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "이상과 같은 본 개시의 다양한 실시 예에 따르면, 보다 정확하게 음성 명료도를 조절할 수 있다. 또한, 오디오 컨텐츠 제작자의 제작 의도를 반영하여 최적의 음성 명료도 조절을 할 수 있다. 이에 따라, 사용자에게 최적의 사운드 경험을 제공할 수 있다."}
{"patent_id": "10-2019-0162644", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 개시를 설명함에 있어, 관련된 공지 기술에 대한 구체적인 설명이 본 개시의 요지를 불필요하게 흐릴 수 있 다고 판단되는 경우 그 상세한 설명을 생략한다. 또한, 동일한 구성의 중복 설명은 되도록 생략하기로 한다. 이하의 설명에서 사용되는 구성요소에 대한 접미사 \"부\"는 명세서 작성의 용이함만이 고려되어 부여되거나 혼용 되는 것으로서, 그 자체로 서로 구별되는 의미 또는 역할을 갖는 것은 아니다. 본 개시에서 사용한 용어는 실시 예를 설명하기 위해 사용된 것으로, 본 개시를 제한 및/또는 한정하려는 의도 가 아니다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 개시에서, '포함하다' 또는 '가지다' 등의 용어는 명세서상에 기재된 특징, 숫자, 단계, 동작, 구성요소, 부 품 또는 이들을 조합한 것이 존재함을 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성요소, 부품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되 어야 한다. 본 개시에서 사용된 \"제1,\" \"제2,\" \"첫째,\" 또는 \"둘째,\" 등의 표현들은 다양한 구성요소들을, 순서 및/또는 중 요도에 상관없이 수식할 수 있고, 한 구성요소를 다른 구성요소와 구분하기 위해 사용될 뿐 해당 구성요소들을 한정하지 않는다. 어떤 구성요소(예: 제1 구성요소)가 다른 구성요소(예: 제2 구성요소)에 \"(기능적으로 또는 통신적으로) 연결되 어((operatively or communicatively) coupled with/to)\" 있다거나 \"접속되어(connected to)\" 있다고 언급된 때에는, 상기 어떤 구성요소가 상기 다른 구성요소에 직접적으로 연결되거나, 다른 구성요소(예: 제3 구성요 소)를 통하여 연결될 수 있다고 이해되어야 할 것이다. 반면에, 어떤 구성요소(예: 제1 다른 구성요소(예: 제2 구성요소)에 \"직접 연결되어\" 있다거나 \"직접 접속되어\" 있다고 언급된 때에는, 상기 어떤 구성요소와 상기 다 른 구성요소 사이에 다른 구성요소(예: 제 3 구성요소)가 존재하지 않는 것으로 이해될 수 있다. 본 개시의 실시 예들에서 사용되는 용어들은 다르게 정의되지 않는 한, 해당 기술 분야에서 통상의 지식을 가진 자에게 통상적으로 알려진 의미로 해석될 수 있다. 이하에서 첨부된 도면을 참조하여 본 개시의 다양한 실시 예를 상세히 설명한다. 도 1은 본 개시의 일 실시 예에 따라 오디오 신호를 포함하는 오디오 컨텐츠가 네트워크를 통해 전자 장치(100- 1 내지 100-4)로 제공되는 환경을 도시한 도면이다. 도 1에 도시된 바와 같이, 오디오 컨텐츠(또는 사운드 소스)는 방송 송신소, 위성, 컨텐츠 제공 서버 등으로부터 통신 매체를 통해 전자 장치(100-1 내지 100-4)로 제공될 수 있다. 이때, 오디오 컨텐츠는 스테레오 채널 오디오 신호 또는 5.1 채널 오디오 신호와 같은 멀티 채널 오디오 신호로 구성된 것일 수 있으나, 이에 한정되는 것은 아니며, 단일 채널의 오디오 신호로 구성된 것일 수도 있다. 한편, 오디오 컨텐츠는 컨텐츠의 종류에 따라 오디오 컨텐츠 단독으로 전자 장치(100-1 내지 100-4)에 제공될 수도 있 고, 비디오 컨텐츠와 함께 전자 장치(100-1 내지 100-4)에 제공될 수도 있다. 방송 송신소는 지상파 방송 컨텐츠를 전송하기 위한 송신기 또는 중계기를 포함할 수 있다. 위성은 데이 터 또는 위성 방송 컨텐츠를 전송하기 위한 통신용 위성을 포함할 수 있다. 컨텐츠 제공 서버는 IPTV용 방송 컨텐츠, 케이블TV용 방송 컨텐츠, 각종 음원 컨텐츠 및 VOD 컨텐츠를 제공하는 통신망 상의 서버일 수 있다. 통신 매체는 공중(air) 매체나 구축된 통신망을 포함할 수 있다. 이때, 통신망은 무선 셀망, 인터넷, WAN(wide area network), LAN(local area network), 유선 전화 네트워크, 케이블망 등을 포함할 수 있다. 전자 장치(100-1 내지 100-4)는, 오디오 컨텐츠만을 재생할 수 있는 오디오 기기(100-3)뿐만 아니라, 비디오 및 오디오를 함께 재생할 수 있는 디스플레이 장치(100-1, 100-2, 100-4)를 포함한다. 디스플레이 장치(100-1, 100-2, 100-4)는 스마트 TV, 모니터, 스마트 폰, 데스크톱 컴퓨터, 랩톱 컴퓨터, 태블 릿, 네비게이션, 디지털 사이니지(digital signage) 등과 같이 디스플레이를 구비하여 비디오를 재생하고 스피 커를 통해 오디오를 출력할 수 있는 장치이다. 오디오 기기(100-3)는 오디오만을 재생하여 출력할 수 있도록 구성된 전자 장치로서, 예를 들어, 오디오 기기 (100-3)는, 라디오 장치, 오디오 장치, 축음기, 음성 인식 스피커 장치, 스피커가 설치된 콤팩트 디스크 플레이 어, DAP(Digital Audio Player), 차량용 오디오 장치, 스피커가 설치된 가전 기기, 사운드 바(Sound Bar) 또는 기타 사운드의 출력 동작을 수행할 수 있는 각종 장치 등을 포함할 수 있다. 전자 장치(100-1 내지 100-4)는 오디오 컨텐츠를 구성하는 오디오 신호가 통신 매체를 통해 수신되면, 수신 된 오디오 신호를 처리하여 출력 신호를 생성하고, 생성된 출력 신호를 적어도 하나의 스피커를 통해 출력할 수 있다. 이때, 적어도 하나의 스피커는 전자 장치(100-1 내지 100-4)에 구비된 것일 수도 있고, 실시 예에 따라 전자 장치(100-1 내지 100-4) 외부에 별도로 배치된 것일 수도 있다. 특히, 본 개시의 일 실시 예에 따르면, 전자 장치(100-1 내지 100-4)는, 수신된 오디오 신호에 포함된 음성의 명료도를 판단하고, 판단된 음성의 명료도가 타겟 명료도가 되도록 오디오 신호를 보정하여 출력 신호를 생성할 수 있다. 이때, 타겟 명료도는, 수신된 오디오 신호에 포함된 오디오의 종류(예를 들어, 효과음, 함성, 음악 등)에 관한 씬 정보에 기초하여 설정된 것일 수 있다. 구체적으로, 전자 장치(100-1 내지 100-4)는, 주파수 밴드별 파워의 최소값을 추적하여 비음성 음량을 측정하는 종래 기술과 달리, 수신된 오디오 신호에서 음성 신호와 비음성 신호를 분리하고, 분리된 음성 신호 및 비음성 신호에 기초하여 음성의 명료도를 판단할 수 있다. 또한, 전자 장치(100-1 내지 100-4)는, 주파수 밴드별로 음성의 확률을 측정하여 최종 출력과 관련된 파라미터 를 조절하는 종래 기술과 달리, 분리된 음성 신호 및 비음성 신호 중 적어도 하나의 이득을 조절하거나 분리된 음성 신호 및 비음성 신호에 각종 처리를 수행하여 음성의 명료도를 조절할 수 있다. 한편, 전자 장치(100-1 내지 100-4)는, 입력되는 모든 종류의 컨텐츠에 대해 단순히 음성 명료도를 높이는 동작 만을 수행하는 종래 기술과 달리, 오디오 신호에 포함된 오디오의 종류에 관한 씬 정보에 기초하여 타겟 명료도 를 설정하고, 수신된 오디오 신호의 음성의 명료도가 상기 설정된 타겟 명료도가 되도록 오디오 신호를 보정할 수 있다. 이와 같이, 본 개시의 실시 예들에 따르면, 오디오 신호에서 음성 신호와 비음성 신호를 분리하여 음성의 명료 도를 판단하고, 분리된 음성 신호 및 비음성 신호 중 적어도 하나를 처리하여 음성의 명료도를 조절하므로, 보 다 정확하게 음성 명료도를 조절할 수 있게 된다. 또한, 씬 정보에 기초하여 타겟 명료도가 설정되므로, 오디오 종류에 따라 음성의 명료도 조절을 상이하게 수행 할 수 있으며, 이를 통해, 오디오 컨텐츠 제작자의 제작 의도를 반영할 수 있게 된다. 한편, 이상에서는 오디오 컨텐츠가 전자 장치(100-1 내지 100-4)의 외부로부터 통신 매체를 통해 제공되는 것을 예로 들었으나, 실시 예가 이에 한정되는 것은 아니다. 예를 들어, 오디오 컨텐츠는 USB(Universal Serial Bus), SD(Secure Digital) 메모리 카드 등과 같은 휴대용 저장 매체 또는 각종 광 저장 매체 등을 통해 전자 장치(100-1 내지 100-4)로 제공될 수도 있다. 또한, 오디오 컨텐츠는 전자 장치(100-1 내지 100-4) 자체의 스토리지(예를 들어, 하드 디스크 드라이브(HDD), 솔리드 스테이트 드라이브(SSD), 시스템 메모리(Rom, BIOS 등))에 저장되어 있다가 출력이 필요한 때(예를 들어, 사용자의 요청이 있는 때) 전자 장치(100-1 내지 100-4)에 의해 출력될 수도 있음은 물론이다. 도 2는 본 개시의 일 실시 예에 따른 전자 장치의 블럭도이다. 도 2에 따르면, 전자 장치는 입력부 및 프로세서를 포함한다. 입력부는 오디오 신호를 입력받아 프로세서로 제공할 수 있다. 전술한 바와 같이, 오디오 신호는 통 신 매체를 통해 또는 외부의 휴대용 저장 매체 등을 통해 전자 장치로 제공될 수 있다. 따라서, 오디오 신호가 수신되는 각종 유, 무선 통신 인터페이스(미도시)가 입력부의 기능을 수행할 수 있다. 또한, 오디오 신호는 전자 장치에 포함된 스토리지(미도시)로부터 프로세서로 제공될 수도 있으므로, 이 경우에는 전자 장치에 포함된 스토리지(미도시)가 입력부의 기능을 수행할 수 있다. 프로세서는 오디오 출력 장치의 전반적인 동작을 제어한다. 특히, 프로세서는, 입력부를 통해 오디오 신호가 수신되면, 수신된 오디오 신호에 기초하여 오디오 신호에 포함된 음성의 명료도를 판단할 수 있다. 구체적으로, 프로세서는 오디오 신호에 포함된 음성 신호, 및 오디오 신호에서 음성 신호를 제외한 비음성 신호에 기초하여 음성의 명료도를 판단할 수 있다. 이를 위해, 프로세서는 오디오 신호에서 음성 신호를 추출하고, 추출된 음성 신호를 제외한 나머지 신호를 비음성 신호로 추출할 수 있다. 이때, 본 개시의 일 실시 예에 따르면, 프로세서는 오디오 신호에서 음성 신호를 추출하도록 학습된 인공 지능 모델을 이용하여, 입력부를 통해 수신된 오디오 신호에서 음성 신호 를 추출할 수 있으나, 실시 예가 이에 한정되는 것은 아니다. 이와 같이, 오디오 신호에서 음성 신호 및 비음성 신호가 추출되면, 프로세서는 추출된 음성 신호 및 비음 성 신호에 기초하여 오디오 신호에 포함된 음성의 명료도를 판단할 수 있다. 구체적으로, 프로세서는 추출된 음성 신호 및 비음성 신호의 신호 대 잡음비(Signal to Noise Ratio, SN R)를 산출하고, 산출된 신호 대 잡음비를 음성의 명료도로 판단할 수 있다. 또한, 프로세서는 추출된 음성 신호 및 비음성 신호에 기초한 어음 명료도 지수(Speech Intelligibility Index, SII)를 산출하고, 산출된 어 음 명료도 지수를 음성의 명료도로 판단할 수도 있다. 이에 따라, 프로세서는, 판단된 음성의 명료도가 타겟 명료도가 되도록 오디오 신호를 보정할 수 있다. 이 때, 신호 대 잡음비를 이용하여 음성의 명료도를 판단하는 실시 예에서는 타겟 명료도 역시 신호대 잡음비 값을 가지며, 어음 명료도 지수를 이용하여 음성의 명료도를 판단하는 실시 예의 경우에는 타겟 명료도 역시 어음 명 료도 지수 값을 가질 수 있다. 구체적으로, 신호 대 잡음비를 이용하여 음성의 명료도를 판단하는 경우, 프로세서는, 타겟 명료도와 판단 된 음성의 명료도의 차이 값만큼 음성 신호의 이득을 조정하여 오디오 신호를 보정할 수 있다. 한편, 어음 명료도 지수를 이용하여 음성의 명료도를 판단하는 경우, 프로세서는, 아래 수학식 1에 기초하 여 이득 조정값을 산출하고, 산출된 이득 조정값만큼 음성 신호의 이득을 조정하여 오디오 신호를 보정할 수 있 다. [수학식 1] 이득 조정값 = α*(SII타겟-SII측정)+ß 여기서, SII타겟은 어음 명료도 지수 형식의 타겟 명료도, SII측정은 어음 명료도 지수 형식의 상기 판단된 음성의 명료도, α 및 ß는 음성 신호의 이득 변화에 따른 어음 명료도 지수의 수치 변화를 통해 실험적으로 산출한 상 수값들이다. 한편, 이득 조정값을 산출하는 방식이 위 수학식 1에 한정되는 것은 아니다. 즉, 위 수학식 1은 1차 선형 회귀 를 이용한 것이지만, 프로세서는 α1*(SII타겟-SII측정)2 + α2*(SII타겟-SII측정) + ß)와 같은 2차식이나, 그 보다 높은 차수의 선형 회귀를 이용하여, 더욱 정교한 이득 조정값을 획득할 수도 있다. 또한, 프로세서는 선형 회귀가 아닌 다른 다양한 방법들을 이용하여 특정 인덱스 값들(예를 들어, SII나, 후술할 STI 등)로부터 이득 조정값을 획득할 수도 있다. 이와 같이, 음성의 명료도가 조정된 오디오 신호는 전자 장치의 내부 또는 외부에 배치된 적어도 하나의 스피커를 통해 출력될 수 있다. 한편, 본 개시의 다양한 실시 예들에서 상술한 타겟 명료도는, 오디오 신호에 포함된 오디오의 종류에 관한 씬 (scene) 정보에 기초하여 설정되는 값으로, 오디오의 종류별로 특정값을 가질 수 있다. 예를 들어, 음성의 명료 도가 어음 명로도 지수로 판단되는 예에서, 효과음은 0.6, 함성은 0.5, 음악은 0.4와 같이, 특정 값이 타겟 명 료도 값으로 직접 설정될 수 있다. 한편, 실시 예가 이에 한정되는 것은 아니다. 가령, 타겟 명료도는, 오디오 종류별로, 조정될 명료도의 퍼센트 값으로 설정될 수도 있다. 예를 들어, 효과음은 + 10%, 함성은 -10%, 음악은 0%와 같이, 조정될 명료도의 퍼센 트 값이 타겟 명료도로 설정될 수도 있을 것이다. 이 경우, 프로세서는 현재 측정된 음성의 명료도에, 조 정될 명료도의 퍼센트 값을 연산하여 실제 타겟 명료도 값을 산출할 수 있을 것이다. 이러한 타겟 명료도는, 오디오의 종류별로 미리 설정되어 저장부(미도시)에 매핑 테이블로 저장될 수 있으며, 프로세서는 매핑 테이블을 참조하여, 씬 정보에 대응되는 타겟 명료도 값을 확인할 수 있다. 씬 정보는, 장르 정보의 하위 개념으로, 오디오 신호에 포함된 오디오 종류가 효과음, 함성, 음악 및 음성 중 어느 종류에 해당하는지에 관한 정보를 포함한다. 예를 들어, \"영화\" 장르의 오디오 컨텐츠에는 음성, 효과음, 함성, 음악과 같은 다양한 종류의 오디오가 포함될 수 있으며, 이때, 음성, 효과음, 함성, 음악과 같은 오디오 종류 각각이 오디오 신호에 포함된 씬이 될 수 있다. 본 개시의 일 실시 예에 따르면, 프로세서는 오디오 신호에 대한 적어도 하나의 오디오 특징(audio feature)을 획득하고, 획득된 적어도 하나의 오디오 특징에 기초하여 씬 정보를 획득할 수 있다. 또한, 본 개시 의 다른 일 실시 예에 따르면, 프로세서는 오디오 신호에 포함된 오디오의 종류를 식별하도록 학습된 인공 지능 모델을 이용하여 씬 정보를 획득할 수도 있다. 타겟 명료도는, 이와 같이 획득된 오디오 신호의 씬 정보에 따라 설정될 수 있다. 구체적으로, 타겟 명료도는 씬 정보에 포함된 오디오의 종류마다 상이하게 설정될 수 있다. 예를 들어, 타겟 명료도는, 오디오의 종류가 효 과음인 경우가 오디오의 종류가 상기 함성인 경우보다 높게 설정될 수 있으나, 실시 예가 이에 한정되는 것은 아니다. 이와 같이, 본 개시의 다양한 실시 예들에 따르면, 씬 정보에 기초하여 타겟 명료도 값을 설정하고 이에 기초하 여 오디오 신호를 보정함으로써, 컨텐츠 제작자의 제작 의도를 명료도 조정에 반영할 수 있게 된다. 이하에서는, 도 3 및 도 4를 통해 본 개시의 다양한 실시 예들을 보다 자세히 설명한다. 도 3은 본 개시의 일 실시 예에 따른 프로세서의 기능 블럭도이다. 도 3에 따르면, 프로세서는 음성/비음 성 분리부, 음성 명료도 분석부, 씬 분석부 및 음성 명료도 렌더링부를 포함할 수 있다. 음성/비음성 분리부는 입력부를 통해 수신되는 오디오 신호에서 음성 신호와 비음성 신호를 분리 내 지 추출할 수 있다. 구체적으로, 음성/비음성 분리부는 오디오 신호에서 음성 신호를 추출하고, 추출된 음성 신호를 제외한 나 머지 신호를 비음성 신호로 추출할 수 있다. 이때, 본 개시의 일 실시 예에 따르면, 음성/비음성 분리부는 수신된 오디오 신호가 별도의 음성 채널을 포함하는 오디오 신호인 경우, 해당 음성 채널의 신호를 음성 신호로 추출하고, 나머지 채널의 신호를 비음성 신호로 추출할 수 있다. 그러나, 음성 채널의 신호에도 비음성 신호가 섞여 있을 수 있으므로, 본 개시의 다른 일 실시 예에 따르면, 음 성/비음성 분리부는 음성 채널의 신호에서 음성 신호를 추출하고, 추출된 음성 신호를 제외한 음성 채널의 나머지 비음성 신호 및 나머지 채널의 신호를 비음성 신호로 추출할 수 있다. 예를 들어, 멀티미디어 기기와 같은 전자 장치에서 재생되는 대부분의 오디오 신호는 5.1 채널 오디오 신 호 또는 스테레오 채널 오디오 신호이다. 이때, 5.1 채널 오디오 신호는 센터 채널에 음성이 존재하고, 스테레 오 채널 오디오 신호는 음상 각도가 0도인 신호에 음성이 존재한다. 따라서, 음성/비음성 분리부는 5.1 채널 오디오 신호가 수신되는 경우, 센터 채널 신호에서 음성을 추출할 수 있다. 이때, 센터 채널에는 음성 신호 외에 비음성 신호도 포함되어 있으므로, 음성/비음성 분리부는 추출된 음성 신호를 제외한 센터 채널의 비음성 신호와 나머지 채널(서브 우퍼 채널, 프론트 레프트 채널, 프론 트 라이트 채널, 리어(rear) 레프트 채널 및 리어 라이트 채널)의 신호를 비음성 신호로 추출할 수 있다. 또한, 음성/비음성 분리부는 스테레오 채널 오디오 신호가 수신되는 경우, 음상 각도가 0도인 신호에서 음 성 신호를 추출할 수 있다. 이때, 음상 각도가 0도인 신호에는 비음성 신호도 포함될 수 있으므로, 음성/비음성 분리부는 추출된 음성 신호를 제외한 음상 각도가 0도인 신호의 비음성 신호와 나머지 음상 각도의 신호 (즉, 음상 각도가 0도가 아닌 다른 각도의 신호)를 비음성 신호로 추출할 수 있다. 이때, 음성/비음성 분리부는 기존의 다양한 음성 신호 추출 알고리즘을 이용하여 음성 신호를 추출할 수 있다. 특히, 본 개시의 일 실시 예에 따르면, 음성/비음성 분리부는 음성 신호를 추출하도록 학습된 인공 지능 기반의 알고리즘을 이용하여 음성 신호를 추출할 수 있다. 여기서, 인공 지능 모델은 딥러닝 모델, CNN(Convolutional Neural Network) 모델, RNN(Recurrent Neural Network) 모델 중 적어도 하나를 포함할 수 있다. 음성 신호를 추출하도록 학습된 인공 지능 모델은 전자 장치의 저장부(미도시)에 포함되어 음성/비음성 분 리부에 의해 활용될 수도 있고, 전자 장치 외부에 존재하는 서버(미도시)에 포함되어 서버와 전자 장 치의 통신을 통해 음성/비음성 분리부에 의해 활용될 수도 있다. 또한, 음성/비음성 분리부는 간단한 잡음 제거 방법이나 오디오 특징(audio feature) 기반의 다양한 음성 추출 방법들을 이용하여 오디오 신호에서 음성 신호를 추출할 수도 있다. 여기서, 오디오 특징(audio feature)은, STE(Short Term Energy), ZCR(Zero Crossing Rate), LSTER(Low Short Term Energy Ratio), HZCRR(High Zero Crossing Rate Ratio) 등과 같은 시간 도메인 피쳐와, MFCC(Mel Frequency Cepstral Coefficient), 전체 파워 스펙트럼(Total Power Spectrum), 서브 밴드 파워(Subband Powers), 중심 주파수(Frequency Centroid), 대역폭(Bandwidth), 피치 주파수, 스펙트럼 플럭스(SF) 등과 같은 주파수 도메인 피쳐를 포함할 수 있다. 한편, 본 개시의 다양한 실시 예들에서 비음성 신호는, 전체 오디오 신호에서 상술한 바와 같이 추출된 음성 신 호를 제외한 나머지 신호를 의미하며, 아래의 수학식 2를 통해 추출될 수 있다. [수학식 2] 비음성 신호 = 수신된 전체 오디오 신호 - 음성 신호 이상과 같이 추출된 음성 신호 및 비음성 신호는 음성 명료도 분석부에서 오디오 신호에 포함된 음성의 명 료도를 판단하는데 이용된다. 예를 들어, 음성 명료도 분석부는 신호 대 잡음비(SNR), 어음 명료도 지수(SII), 음성 전달 지수(STI) 등 에 기초하여, 수신된 오디오 신호에 포함된 음성의 명료도를 판단할 수 있다. 구체적으로, 본 개시의 일 실시 예에 따르면, 음성 명료도 분석부는 아래의 수학식 3을 통해 측정되는 신 호 대 잡음비(SNR)를, 수신된 오디오 신호에 포함된 음성의 명료도로 판단할 수 있다. [수학식 3]"}
{"patent_id": "10-2019-0162644", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "한편, 본 개시의 다른 일 실시 예에 따르면, 음성 명료도 분석부는 미국 표준 방식을 이용하여 측정되는 어음 명료도 지수(SII)를, 수신된 오디오 신호에 포함된 음성의 명료도로 판단할 수 있다. 이때, 어음 명료도 지수 역시 오디오 신호에서 분리된 음성 신호 및 비음성 신호(나머지 신호)에 기초하여 측정됨은 물론이다. 한 편, 어음 명료도 지수를 측정하는 구체적인 방법은 본 개시의 요지와 무관하므로 보다 구체적인 내용의 설명은 생략한다. 한편, 도 4는 어음 명료도 지수에 따른 음성 인식 정확도를 도시한 그래프이다. 구체적으로, 도 4는 CID W-22, NU-6, CST와 같은 3개의 오디오 데이터 세트(Data set)에 대한 사용자의 음성 인식 정확도를 도시하고 있는데,그래프의 가로축은 어음 명료도 지수(SII)를, 세로축은 음성 인식 정확도를 나타낸다. 도 4를 참조하면, 어음 명료도 지수가 0.6이상인 경우, 3개의 데이터 세트 모두에 대해 약 90%이상의 음성 인식 정확도를 나타내는 것을 알 수 있다. 이 수치(즉, 0.6)는 음성 명료도 렌더링부에서 타겟 명료도 수준으로 사용될 수 있다. 한편, 본 개시의 또 다른 일 실시 예에 따르면, 음성 명료도 분석부는 음성 전달 지수(Speech Transmission Index, STI)와 같이 음성의 인식 정도를 반영하는 객관적 수치를, 수신된 오디오 신호에 포함된 음성의 명료도로 판단할 수도 있다. 씬 분석부는 오디오 신호를 분석하여 씬 정보를 획득할 수 있다. 구체적으로, 씬 분석부는 오디오 신 호에 포함된 복수의 오디오 프레임 중 기설정된 개수의 오디오 프레임에 대한 적어도 하나의 오디오 특징(audio feature)을 획득하고, 획득된 오디오 특징에 기초하여 상기 기설정된 개수의 오디오 프레임에 대한 씬 정보를 획득할 수 있다. 여기서, 오디오 특징은, STE(Short Term Energy), ZCR(Zero Crossing Rate), LSTER(Low Short Term Energy Ratio), HZCRR(High Zero Crossing Rate Ratio) 등과 같은 시간 도메인 피쳐와, MFCC(Mel Frequency Cepstral Coefficient), 전체 파워 스펙트럼(Total Power Spectrum), 서브 밴드 파워(Subband Powers), 중심 주파수 (Frequency Centroid), 대역폭(Bandwidth), 피치 주파수, 스펙트럼 플럭스(SF) 등과 같은 주파수 도메인 피쳐 를 포함할 수 있다. 예를 들어, 오디오 신호가 스테레오 오디오 신호이고, 씬 정보가 1 쌍의 L, R 오디오 프레임마다 획득되는 경우, 씬 분석부는, 1 쌍의 L, R 오디오 프레임을 분석하여 상기 오디오 특징들 중 적어도 하나를 추출하 고, 추출된 오디오 특징에 기초하여 해당 L, R 오디오 프레임이 효과음, 함성 및 음악 중 어떤 종류의 오디오를 포함하는지 식별할 수 있다. 오디오 신호로부터 상기 오디오 특징들을 추출하는 구체적인 방법 및 추출된 오디오 특징들로부터 기설정된 개 수의 오디오 프레임이 효과음, 함성 및 음악 중 어떤 종류의 오디오를 포함하는지를 식별하는 구체적인 방법은, 본 개시의 요지와 무관하므로, 이하 자세한 설명은 생략한다. 한편, 본 개시의 다른 일 실시 예에 따르면, 씬 분석부는 오디오 신호에 포함된 오디오의 종류를 식별하도 록 학습된 인공 지능 모델을 이용하여 씬 정보를 획득할 수도 있다. 여기서, 인공 지능 모델은, 딥러닝 모델, CNN(Convolutional Neural Network) 모델, RNN(Recurrent Neural Network) 모델 중 적어도 하나를 포함할 수 있다. 예를 들어, 오디오 신호가 스테레오 오디오 신호이고, 씬 정보가 1 쌍의 L, R 오디오 프레임마다 획득되는 예에 서, 씬 분석부는 1 쌍의 L, R 오디오 프레임을 2차원 축으로 변환한 스펙트로그램 패턴과 상기 학습된 CNN 모델을 활용하여 오디오 종류 별 일치 확률을 산출하는 방법을 통해, 해당 L, R 오디오 프레임이 효과음, 함성 및 음악 중 어떤 종류의 오디오를 포함하는지 식별할 수 있다. 한편, 오디오의 종류를 식별하도록 학습된 인공 지능 모델 역시 음성 신호를 추출하도록 학습된 인공 지능 모델 과 같이, 전자 장치의 저장부(미도시)에 포함되어 씬 분석부에 의해 활용될 수도 있고, 전자 장치 외부에 존재하는 서버(미도시)에 포함되어 서버와 전자 장치의 통신을 통해 씬 분석부에 의해 활용될 수도 있음은 물론이다. 한편, 이상에서는, 씬 분석부가 직접 오디오 신호를 분석 또는 처리하여 씬 정보를 획득하는 것을 예로 들 었으나, 실시 예가 이에 한정되는 것은 아니다. 예를 들어, 씬 분석부는, 수신된 오디오 신호에 대응되는 씬 정보를, 오디오 컨텐츠에 대한 씬 정보를 생성 및 관리하는 외부의 서버(미도시)로부터 수신하여 획득할 수 도 있을 것이다. 음성 명료도 렌더링부는 음성 명료도 분석부에서 판단된 음성의 명료도와 씬 분석부에서 획득된 씬 정보를 활용하여 음성 신호 및 나머지 신호 중 적어도 하나를 보정함으로써, 오디오 신호에 포함된 음성의 명료도를 조절할 수 있다. 구체적으로, 음성 명료도 렌더링부는 음성 신호의 이득을 조절하여 음성 명료도를 조절할 수 있다. 이때, 명료도 조절의 정도는 음성 명료도 분석부로부터 수신한 음성의 명료도 정보와 씬 분석부로부터 수신 한 씬 정보를 통해 결정될 수 있다. 예를 들어, 음성의 명료도가 어음 명료도 지수로 판단되는 예에서, 사용자가 90% 수준으로 음성을 인식하는 것 이 타겟이라면, 도 4에 관한 설명에서 전술한 바와 같이, 어음 명료도 지수는 0.6정도 되어야 한다. 만약, 현재 판단된 어음 명료도 지수 0.4라면 0.2를 더 올려야 원하는 수준의 음성 명료도를 확보할 수 있다. 이때, 어느 정도의 이득값을 조정해야 어음 명료도 지수를 0.2만큼 올릴 수 있는지는, 음성 신호의 이득 변화에 따른 어음 명료도 지수의 수치 변화를 미리 실험함으로써 예측할 수 있다. 예를 들어, 다양한 오디오 신호를 대 상으로 음성 신호의 이득을 1dB씩 올릴 때 마다 어음 명료도 지수의 수치 변화를 보고 그것을 역으로 추산하여 전술한 수학식 1의 α와 ß를 구할 수 있으며, 수학식 1을 통해 어음 명료도 지수를 0.2만큼 올리기 위한 음성 신호의 이득 조정값을 구할 수 있다. 한편, 본 개시의 다양한 실시 예들에서, 사용자가 몇 %수준까지 음성을 인식하는 것을 타겟으로 할지(즉, 타겟 명료도 값)는, 씬 정보에 의해 결정된다. 이와 같이, 본 개시의 다양한 실시 예들에 따르면, 오디오 신호에 포함된 오디오의 종류 별로 타겟 명료도를 다 르게 설정함으로써, 오디오 컨텐츠 제작자의 제작 의도를 반영하여 음성의 명료도를 조절할 수 있다. 구체적으로, 오디오의 종류가 효과음인 경우, 효과음도 중요하지만 시청자가 가장 중요하게 생각하는 것은 음성 이라는 통계가 있다. 따라서, 효과음으로 인하여 떨어지는 음성의 명료도를 충분히 보상할 필요가 있다. 예를 들어, 타겟 명료도가 어음 명료도 지수 0.6이고, 측정된 음성의 명료도가 어음 명료도 지수 0.5인 경우, 음성 명료도 렌더링부는 수학식 1을 통해 산출되는 이득 조정값만큼 음성 신호의 이득을 조정함으로써, 사 용자의 음성 인식 정확도를 90%까지 올릴 수 있다. 한편, 스포츠에서의 함성 소리는 시청자가 느끼는 현장감에 큰 영향을 미치게 된다. 따라서, 오디오의 종류가 함성인 경우, 타겟 명료도를 너무 높게 설정하면 음성 대비 함성 신호가 상대적으로 작아져 음성 명료도 조정 전보다 현장감이 떨어질 수 있으므로, 실험을 통한 적절한 수치로 타겟 명료도가 설정될 수 있다. 이때, 실험을 통한 적절한 수치는 오디오의 종류가 효과음인 경우의 타겟 명료도보다 작은 값일 수 있으나, 실시 예가 이에 한정되는 것은 아니다. 예를 들어, 타겟 명료도를 음성 명료도 지수 0.6으로 설정하면, 해설자 및 아나운서의 목소리가 명료해질 수는 있지만, 함성이 존재하는 나머지 신호가 상대적으로 작아지기 때문에 충분한 현장감을 즐길 수 없다. 따라서, 타겟 명료도를 음성 명료도 지수 0.5 정도로 설정하여 적절한 명료도와 현장감 둘다 유지하도록 할 수 있다. 한편, 음악은 제작자가 의도한 보컬과 악기음의 밸런스를 유지하는 것이 주요하다. 따라서, 오디오의 종류가 음 악인 경우, 음성 명료도 분석부에서 측정된 음성의 명료도 수치가 낮더라도 최대 3dB수준으로 음성 신호의 이득을 조정하거나 또는 음성 신호의 이득을 조정하지 않음으로써, 최대한 음악 컨텐츠 제작자의 의도를 반영할 수 있다. 이상에서는, 음성 명료도 렌더링부가 음성 신호의 이득을 조절하여 음성 명료도를 조절하는 것을 예로 들 어 설명하였으나, 실시 예가 이에 한정되는 것은 아니다. 예를 들어, 음성 명료도 렌더링부는 비음성 신호 의 이득을 조절하거나, Dynamic Range Compressor, LPC(Linear Prediction Coefficient) 필터, Harmonic Enhnacer 등의 기술을 활용하여 음성의 명료도를 조절할 수도 있다. 이상과 같이, 음성 명료도 렌더링부는 수신된 오디오 신호에 포함된 음성의 명료도를 조정하고, 조정된 음 성의 명료도를 갖는 오디오 신호를 출력 신호로 생성할 수 있다. 이와 같이, 생성된 출력 신호는 적어도 하나의 스피커를 통해 출력될 수 있다. 한편, 이상에서, 도면에 도시하지는 않았지만, 프로세서는, 음성/비음성 분리부, 음성 명료도 분석부 , 씬 분석부 및 음성 명료도 렌더링부의 동작을 제어하도록 마련된, 중앙 처리 장치(CPU, Central Processing Unit), 마이크로 컨트롤러 유닛(MCU, Micro Controller Unit), 마이컴(Micom, Micro Processor), 전자 제어 유닛(ECU, Electronic Control Unit) 또는 애플리케이션 프로세서(AP, Application Processor) 및/또는 각종 연산 처리 및 제어 신호의 생성이 가능한 다른 전자 유닛 등(이하, 'CPU 등'이라 한다.)을 포함할 수 있다. 이때, 상기 CPU 등은, 실시 예에 따라 음성/비음성 분리부, 음성 명료도 분석부 , 씬 분석부 및 음성 명료도 렌더링부 중 적어도 하나 또는 일부에 통합된 형태로 제공될 수도 있다. 한편, 음성/비음성 분리부, 음성 명료도 분석부, 씬 분석부 및 음성 명료도 렌더링부는, 하나 또는 그 이상의 기능 모듈로 통합되어 프로세서를 형성할 수 있다. 예를 들면, 음성 명료도 분석부, 씬 분석부 및 음성 명료도 렌더링부가 통합되어 하나의 신호 처리 모듈로 형성되거나, 음성/ 비음성 분리부, 음성 명료도 분석부, 씬 분석부 및 음성 명료도 렌더링부가 모두 통합되어 하나의 신호 처리 모듈로 형성될 수도 있다. 이때, 신호 처리 모듈은 DSP(Digital Signal Processor)일 수 있으 나, 이에 한정되는 것은 아니다. 도 5는 본 개시의 일 실시 예에 따른 전자 장치의 상세 블럭도이다. 도 5를 설명함에 있어, 전술한 것과 중복되 는 구성의 중복되는 설명은 생략한다. 도 5에 따르면, 전자 장치는 프로세서, 메모리, 디스플레 이, 사용자 입력부, 통신부 및 오디오 출력부를 포함할 수 있다. 구현 예에 따라, 도 5에 도시된 전자 장치의 일부의 구성은 생략될 수 있으며, 도시되지 않은 다른 구성이 추가될 수도 있다. 오디오 출력부는 오디오 신호를 출력 신호를 출력한다. 특히, 오디오 출력부는 전술한 바와 같이 프 로세서에 의해 보정된 오디오 신호를 출력할 수 있다. 이를 위해, 오디오 출력부는 적어도 하나의 스 피커를 포함할 수 있다. 통신부는 외부 장치와 통신을 수행한다. 통신부는, 무선 통신부, 유선 통신부 및 입력 인 터페이스을 포함할 수 있다. 무선 통신부는, 무선 통신 기술이나 이동 통신 기술을 이용하여 외부의 방송 송신소, 위성, 컨텐츠 제공 서버 및 다른 단말 장치와 통신을 수행할 수 있다. 이러한 무선 통신 기술로는, 예를 들어, 블루투스 (Bluetooth), 저전력 블루투스(Bluetooth Low Energy), 캔(CAN) 통신, 와이 파이(Wi-Fi), 와이파이 다이렉트 (Wi-Fi Direct), 초광대역 통신(UWB, ultra-wide band), 지그비(zigbee), 적외선 통신(IrDA, infrared Data Association) 또는 엔에프씨(NFC, Near Field Communication) 등이 포함될 수 있으며, 이동 통신 기술로는, 3GPP, 와이맥스(Wi-Max), LTE(Long Term Evolution), 5G 등이 포함될 수 있다. 무선 통신부는 다른 단말 장치나 서버로부터 오디오 컨텐츠를 수신하고, 수신한 오디오 컨텐츠를 프로세서 로 전달할 수 있다. 이를 위해, 무선 통신부는 전자기파를 외부로 송신하거나 또는 외부에서 전달된 전자기파를 수신할 수 있는 안테나, 통신 칩 및 기판 등을 이용하여 구현될 수 있다. 유선 통신부는 유선 통신 네트워크를 기반으로 외부의 방송 송신소, 위성, 컨텐츠 제공 서버 및 다른 단말 장치와 통신을 수행할 수 있다. 여기서, 유선 통신 네트워크는, 예를 들어, 페어 케이블, 동축 케이 블, 광섬유 케이블 또는 이더넷 케이블 등 물리적인 케이블을 이용하여 구현될 수 있다. 유선 통신부는 다 른 단말 장치나 서버로부터 오디오 컨텐츠를 수신하고, 수신한 오디오 컨텐츠를 프로세서로 전달할 수 있 다. 무선 통신부 및 유선 통신부는 실시예에 따라 어느 하나가 생략될 수도 있다. 따라서, 오디오 출력 장치는 무선 통신부만을 포함하거나 유선 통신부만을 포함할 수 있다. 뿐만 아니라, 오디오 출 력 장치는 무선 통신부에 의한 무선 접속과 유선 통신부에 의한 유선 접속을 모두 지원하는 통 합된 통신부를 구비할 수도 있다. 입력 인터페이스는, 오디오 출력 장치와 별도로 마련된 다른 장치, 예를 들어 외부 저장 장치와 연결 가능하게 마련되며, 다른 장치로부터 오디오 컨텐츠를 수신하고 수신한 오디오 컨텐츠를 소스를 프로세서로 전달할 수 있다. 예를 들어, 입력 인터페이스는, 범용 직렬 시스템 버스(USB: Universal Serial Bus) 단 자일수 있으며, 이외에도 HDMI(High Definition Multimedia Interface) 단자나, 썬더볼트 단자 등과 같은 다양 한 인터페이스용 단자 중 적어도 하나를 포함할 수 있다. 한편, 도 5에서는, 적어도 하나의 스피커를 포함하는 오디오 출력부가 전자 장치의 프로세서(구 체적으로는, 프로세서에 포함된 음성 명료도 렌더링부)에 직접 연결되어 전자 장치에 내장된 것 을 예로 들었으나, 실시 예가 이에 한정되는 것은 아니다. 전술한 바와 같이, 프로세서가 생성한 출력 신호는 전자 장치 외부에 설치된 별도의 스피커를 통해 출력될 수도 있다. 이 경우, 전자 장치 외부에 설치된 별도의 스피커는, 통신부를 통해 전자 장치 와 연결될 수 있으며, 프로세서에서 생성된 출력 신호는 통신부를 통해 전자 장치 외부에 설치된 별도의 스피커로 출력될 수 있다. 또한, 본 개시의 일 실시 예에 따르면, 통신부는, 오디오 컨텐츠에 대한 씬 정보를 생성 및 관리하는 외부 의 서버, 음성 신호를 추출하도록 학습된 인공 지능 모델을 생성 및 관리하는 외부의 서버, 오디오 신호에 포함 된 오디오의 종류를 식별하도록 학습된 인공 지능 모델을 생성 및 관리하는 외부의 서버와 통신하여, 외부의 서버로부터 씬 정보나 각종 인공 지능 모델을 수신할 수도 있다. 메모리는 오디오 컨텐츠를 일시적 또는 비일시적으로 저장하고, 프로세서의 호출에 따라서 오디오 컨 텐츠를 오디오 신호 형태로 프로세서에 전달한다. 또한, 메모리는, 프로세서의 연산, 처리 또는 제어 동작 등에 필요한 각종 정보를 전자적 포맷으로 저장할 수 있다. 예를 들어, 메모리는 프로세서의 동작에 필요한 각종 데이터나, 애플리케이션이나, 필터나, 알고리즘 등의 전부 또는 일부를 저장하고 있을 수 있으며, 필요에 따라서 이를 프로세서에 제공할 수 있다. 여기서, 애플리케이션은 무선 통신부 또는 유선 통신부를 통해 접속가능한 전자 소프트웨어 유통망을 통하여 획득된 것일 수 있다. 메모리는, 예를 들어, 주기억장치 및 보조기억장치 중 적어도 하나를 포함할 수 있다. 주기억장치는 롬 (ROM) 및/또는 램(RAM)과 같은 반도체 저 장 매체를 이용하여 구현된 것일 수 있다. 롬은, 예를 들어, 통상적인 롬, 이피롬(EPROM), 이이피롬(EEPROM) 및/또는 마스크롬(MASK-ROM) 등을 포함할 수 있다. 램은 예를 들어, 디램 (DRAM) 및/또는 에스램(SRAM) 등을 포함할 수 있다. 보조기억장치는, 플래시 메모리 장치, SD(Secure Digital) 카드, 솔리드 스테이트 드라이브 (SSD, Solid State Drive), 하드 디스크 드라이브(HDD, Hard Disc Drive), 자 기 드럼, 컴팩트 디스크(CD), 디브이디(DVD) 또는 레이저 디스크 등과 같은 광 기록 매체(optical media), 자기 테이프, 광자기 디스크 및/또는 플로피 디스크 등과 같이 데이터를 영구적 또는 반영구적으로 저장 가능한 적어 도 하나의 저장 매체를 이용하여 구현될 수 있다. 한편, 도 2의 전자 장치에서는 오디오 신호를 입력받아 프로세서로 제공하는 기능을 수행하는 구성으 로 입력부를 정의하였다. 도 5에서는 통신부 또는 메모리를 통해 오디오 신호가 프로세서 로 제공될 수 있으므로, 도 5에서는 통신부 및 메모리가 도 2에서 전술한 입력부에 해당될 수 있다. 디스플레이는 각종 영상을 디스플레이 한다. 특히, 통신부나 메모리를 통해 비디오 신호가 수신 되는 경우, 프로세서는 디스플레이를 통해 비디오를 재생할 수 있다. 이를 위해, 디스플레이는 LCD(Liquid Crystal Display) 패널, OLED(Organic Light Emitting Diodes) 패널, PDP(Plasma Display Panel) 패널, 무기 LED 패널, 마이크로 LED 패널 등 다양한 종류의 디스플레이 패널을 포함할 수 있으나, 이에 한정되 는 것은 아니다. 한편, 디스플레이는 터치 패널과 함께 터치스크린을 구성할 수도 있다. 사용자 입력부는 각종 사용자 입력을 입력받기 위한 구성이다. 이를 위해, 사용자 입력부는 각종 버 튼이나 터치 패널 등을 포함할 수 있으나, 이에 한정되는 것은 아니다. 프로세서는 오디오 출력 장치의 전반적인 동작을 제어한다. 특히, 프로세서는, 도 1 내지 도 4 를 통해 전술한 전자 장치, 프로세서 또는 프로세서의 기능 블럭들의 동작을 수행할 수 있다. 한편, 프로세서는, 메모리 또는 통신부를 통해 오디오 컨텐츠가 전달되면, 오디오 컨텐츠를 디 코딩하여 비압축 형태의 포맷으로 변환할 수 있다. 여기서 디코딩이란, MP3(MPEG Layer-3), AAC(Advanced Audio Coding), AC-3(Audio Codec-3), DTS(Digital Theater System), FLAC(free lossless audio codec), WMA(Windows Media Audio) 등 오디오 압축 포맷에 의해 압축된 오디오 신호를 비압축 형태의 오디오 신호로 복 원하는 과정을 의미한다. 물론, 오디오 컨텐츠가 압축되어 있지 않다면 이러한 디코딩 과정은 생략될 수 있다. 상기 복원된 오디오 신호는 하나 이상의 채널을 포함할 수 있다. 도 6은 본 개시의 일 실시 예에 따른 전자 장치의 제어 방법을 도시한 흐름도이다. 도 6에 따르면, 전자 장치 는 오디오 신호를 수신하고(S610), 수신된 오디오 신호에 기초하여 오디오 신호에 포함된 음성의 명료도를 판단할 수 있다(S620). 예를 들어, 전자 장치는 수신된 오디오 신호에 포함된, 음성 신호 및 상기 음성 신호를 제외한 비음성 신 호에 기초하여, 음성의 명료도를 산출할 수 있다. 이때, 전자 장치는 오디오 신호에 포함된 음성 신호를 추출하도록 학습된 인공 지능 모델을 이용하여 오디오 신호에 포함된 음성 신호를 추출하고, 오디오 신호에서 상기 추출된 음성 신호를 제외한 나머지 신호를 비음성 신호로 추출할 수 있다. 이에 따라, 전자 장치는, 판단된 음성의 명료도가 타겟 명료도가 되도록 오디오 신호를 보정할 수 있다 (S630). 여기서, 타겟 명료도는, 오디오 신호에 포함된 오디오의 종류에 관한 씬(scene) 정보에 기초하여 설정 된 값이며, 씬 정보에 포함되는 오디오의 종류는 효과음, 함성 및 음악 중 적어도 하나를 포함할 수 있다. 이때, 전자 장치는, 오디오 신호에 대한 적어도 하나의 오디오 특징(audio feature)을 획득하고, 획득된 적어도 하나의 오디오 특징에 기초하여 씬 정보를 획득할 수 있다. 또는, 전자 장치는, 오디오 신호에 포 함된 오디오의 종류를 식별하도록 학습된 인공 지능 모델을 이용하여 씬 정보를 획득할 수도 있다. 한편, 본 개시의 일 실시 예에 따르면, 타겟 명료도는, 오디오의 종류마다 상이하게 설정될 수 있다. 예를 들어, 타겟 명료도는 오디오의 종류가 효과음인 경우가 함성인 경우보다 높게 설정될 수 있으나, 이에 한정되는 것은 아니다. 한편, 상술한 명료도는, 오디오 신호에 포함된 음성 신호와 비음성 신호의 신호 대 잡음비(Signal to Noise Ratio, SNR), 및 음성 신호와 비음성 신호에 기초한 어음 명료도 지수(Speech Intelligibility Index, SII) 중 어느 하나일 수 있다. 이에 따라, 오디오 신호에 포함된 음성의 명료도가 신호 대 잡음비로 판단되는 경우, 전자 장치는, 타겟 명료도 및 상기 판단된 음성의 명료도의 차이 값만큼 음성 신호의 이득을 조정하여 오디오 신호를 보정할 수 있 다. 또한, 오디오 신호에 포함된 음성의 명료도가 어음 명료도 지수로 판단되는 경우, 전자 장치는 아래 수학 식 1에 기초하여 이득 조정값을 산출하고, 산출된 이득 조정값만큼 음성 신호의 이득을 조정하여 오디오 신호를 보정할 수 있다. [수학식 1] 이득 조정값 = α*(SII타겟-SII측정)+ß 여기서, SII타겟은 상기 타겟 명료도, SII측정은 상기 판단된 음성의 명료도, α 및 ß는 음성 신호의 이득 변화에 따른 어음 명료도 지수의 수치 변화를 통해 실험적으로 산출한 상수값들이다. 이상과 같은 본 발명의 다양한 실시 예에 따르면, 보다 정확하게 음성 명료도를 조절할 수 있다. 또한, 오디오 컨텐츠 제작자의 제작 의도를 반영하여 최적의 음성 명료도 조절을 할 수 있다. 이에 따라, 사용자에게 최적의 사운드 경험을 제공할 수 있다. 한편, 본 개시의 다양한 실시 예들은 기기(machine)(예: 컴퓨터)로 읽을 수 있는 저장 매체(machine-readable storage media)에 저장된 명령어를 포함하는 소프트웨어로 구현될 수 있다. 여기서, 기기는, 저장 매체로부터 저장된 명령어를 호출하고, 호출된 명령어에 따라 동작이 가능한 장치로서, 개시된 실시 예들에 따른 전자 장치 (100, 100-1 내지 100-4)를 포함할 수 있다. 상기 명령이 프로세서에 의해 실행될 경우, 프로세서가 직접, 또는 상기 프로세서의 제어하에 다른 구성요소들 을 이용하여 상기 명령에 해당하는 기능을 수행할 수 있다. 명령은 컴파일러 또는 인터프리터에 의해 생성 또는 실행되는 코드를 포함할 수 있다. 기기로 읽을 수 있는 저장매체는, 비일시적(non-transitory) 저장매체의 형태 로 제공될 수 있다. 여기서, '비일시적'은 저장매체가 신호(signal)를 포함하지 않으며 실재(tangible)한다는 것을 의미할 뿐 데이터가 저장매체에 반영구적 또는 임시적으로 저장됨을 구분하지 않는다. 일 실시 예에 따르면, 본 개시에 개시된 다양한 실시 예들에 따른 방법은 컴퓨터 프로그램 제품(computer program product)에 포함되어 제공될 수 있다. 컴퓨터 프로그램 제품은 상품으로서 판매자 및 구매자 간에 거래 될 수 있다. 컴퓨터 프로그램 제품은 기기로 읽을 수 있는 저장 매체(예: compact disc read only memory (CD- ROM))의 형태로, 또는 어플리케이션 스토어(예: 플레이 스토어TM)를 통해 온라인으로 배포될 수 있다. 온라인 배포의 경우에, 컴퓨터 프로그램 제품의 적어도 일부는 제조사의 서버, 어플리케이션 스토어의 서버, 또는 중계 서버의 메모리와 같은 저장 매체에 적어도 일시 저장되거나, 임시적으로 생성될 수 있다. 다양한 실시 예들에 따른 구성 요소(예: 모듈 또는 프로그램) 각각은 단수 또는 복수의 개체로 구성될 수 있으 며, 전술한 해당 서브 구성 요소들 중 일부 서브 구성 요소가 생략되거나, 또는 다른 서브 구성 요소가 다양한 실시 예에 더 포함될 수 있다. 대체적으로 또는 추가적으로, 일부 구성 요소들(예: 모듈 또는 프로그램)은 하나 의 개체로 통합되어, 통합되기 이전의 각각의 해당 구성 요소에 의해 수행되는 기능을 동일 또는 유사하게 수행 할 수 있다. 다양한 실시 예들에 따른, 모듈, 프로그램 또는 다른 구성 요소에 의해 수행되는 동작들은 순차적, 병렬적, 반복적 또는 휴리스틱하게 실행되거나, 적어도 일부 동작이 다른 순서로 실행되거나, 생략되거나, 또는 다른 동작이 추가될 수 있다. 이상의 설명은 본 개시의 기술 사상을 예시적으로 설명한 것에 불과한 것으로서, 본 개시가 속하는 기술 분야에 서 통상의 지식을 가진 자라면 본 개시의 본질적인 특성에서 벗어나지 않는 범위에서 다양한 수정 및 변형이 가 능할 것이다. 또한, 본 개시에 따른 실시 예들은 본 개시의 기술 사상을 한정하기 위한 것이 아니라 설명하기한 것이고, 이러한 실시 예에 의하여 본 개시의 기술 사상의 범위가 한정되는 것은 아니다. 따라서, 본 개시의 보호 범위는 아래의 청구범위에 의하여 해석되어야 하며, 그와 동등한 범위 내에 있는 모든 기술 사상은 본 개 시의 권리범위에 포함되는 것으로 해석되어야 할 것이다."}
{"patent_id": "10-2019-0162644", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 개시의 일 실시 예에 따라 오디오 신호를 포함하는 오디오 컨텐츠가 네트워크를 통해 전자 장치로 제 공되는 환경을 도시한 도면, 도 2는 본 개시의 일 실시 예에 따른 전자 장치의 블럭도, 도 3은 본 개시의 일 실시 예에 따른 프로세서의 기능 블럭도, 도 4는 어음 명료도 지수에 따른 음성 인식 정확도를 도시한 그래프, 도 5는 본 개시의 일 실시 예에 따른 전자 장치의 상세 블럭도, 및 도 6은 본 개시의 일 실시 예에 따른 전자 장치의 제어 방법을 도시한 흐름도이다."}
