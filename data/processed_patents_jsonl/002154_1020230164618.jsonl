{"patent_id": "10-2023-0164618", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2024-0078372", "출원번호": "10-2023-0164618", "발명의 명칭": "언어 패턴을 이용하여 언어 라벨링을 수행하는 전자 장치 및 그 제어 방법", "출원인": "주식회사 자이플래닛", "발명자": "전한철"}}
{"patent_id": "10-2023-0164618", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "전자 장치에 있어서,자연어에 대한 데이터를 입력 받기 위한 인터페이스;상기 자연어에 대한 데이터와 인공 지능 모델을 저장하는 메모리;프로세서;를 포함하며,상기 프로세서는,상기 자연어에 대한 데이터를 텍스트 형식의 자연어 텍스트 데이터로 변환하고, 상기 인공 지능 모델을 이용하여 변환된 자연어 텍스트 데이터에 대한 인과 관계 분석을 수행하며, 상기 인과 관계 분석 결과 데이터에 기초하여 상기 자연어 텍스트 데이터의 각 개체 간의 인과 관계 확률에 대한 가중치를 획득하고, 획득한 각 개체 간의 인과 관계 확률에 대한 가중치를 비교하여 상기 자연어 텍스트 데이터에 포함된 각 개체의 라벨링을 결정하는, 전자 장치."}
{"patent_id": "10-2023-0164618", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 프로세서는,상기 자연어 텍스트 데이터에 대한 토큰화(Tokenizer)를 수행하여 하나로 연결된 파일 형태로 변환하는, 전자장치."}
{"patent_id": "10-2023-0164618", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,상기 프로세서는,상기 토큰화가 수행된 자연어 텍스트 데이터에서 토큰의 수를 기설정된 개수 이내로 줄여 간략화하기 위한 전처리를 수행하는, 전자 장치."}
{"patent_id": "10-2023-0164618", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,상기 프로세서는,상기 인터페이스를 통해 개체명에 대한 데이터와 샘플(sample) 자연어 텍스트 데이터를 수집하여 상기 메모리에저장하고, 상기 인공 지능 모델을 이용하여 상기 개체명에 대한 데이터와 샘플 자연어 텍스트 데이터에 포함된각 개체의 인과 관계를 학습시키는, 전자 장치."}
{"patent_id": "10-2023-0164618", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서,상기 프로세서는,오픈 API 데이터를 이용하여 상기 개체명에 대한 데이터를 수집하고,상기 오픈 API 데이터에는 AI API/DATA 및 Google Cloud Natural Language API를 포함하는, 전자 장치."}
{"patent_id": "10-2023-0164618", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "공개특허 10-2024-0078372-3-제1항에 있어서,상기 프로세서는,상기 자연어 텍스트 데이터에서 표, 그림 및 특수문자를 제거하기 위한 전처리를 수행하는, 전자 장치."}
{"patent_id": "10-2023-0164618", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에 있어서,상기 프로세서는,상기 자연어 텍스트 데이터를 TSV 형식의 텍스트 데이터로 변환하고, 변환된 TSV 형식의 텍스트 데이터에 기초하여 원인 개체와 결과 개체를 태깅하고, 두 개체 간의 관계를 라벨링하는, 전자 장치."}
{"patent_id": "10-2023-0164618", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서,상기 프로세서는,상기 TSV 형식의 텍스트 데이터에 인덱스(id) 번호를 이용하여 상기 원인 개체와 결과 개체의 시작과 끝을 나타내는 특정 토큰(special token)을 추가하는, 전자 장치."}
{"patent_id": "10-2023-0164618", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "전자 장치의 제어 방법에 있어서,자연어에 대한 데이터를 입력 받는 단계;상기 자연어에 대한 데이터를 텍스트 형식의 자연어 텍스트 데이터로 변환하는 단계;인공 지능 모델을 이용하여 변환된 자연어 텍스트 데이터에 대한 인과 관계 분석을 수행하는 단계;상기 인과 관계 분석 결과 데이터에 기초하여 상기 자연어 텍스트 데이터의 각 개체 간의 인과 관계 확률에 대한 가중치를 획득하는 단계; 및획득한 각 개체 간의 인과 관계 확률에 대한 가중치를 비교하여 상기 자연어 텍스트 데이터에 포함된 각 개체의라벨링을 결정하는 단계를 포함하는, 제어 방법."}
{"patent_id": "10-2023-0164618", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제9항에 있어서,상기 자연어 텍스트 데이터에 대한 인과 관계 분석을 수행하는 단계는,상기 자연어 텍스트 데이터를 TSV 형식의 텍스트 데이터로 변환하는 단계; 및변환된 TSV 형식의 텍스트 데이터에 기초하여 원인 개체와 결과 개체를 태깅하는 단계;를 포함하는, 제어 방법."}
{"patent_id": "10-2023-0164618", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제9항에 있어서,개체명에 대한 데이터와 샘플(sample) 자연어 텍스트 데이터를 수집하여 메모리에 저장하는 단계; 및상기 인공 지능 모델을 이용하여 상기 개체명에 대한 데이터와 샘플 자연어 텍스트 데이터에 포함된 각 개체의인과 관계를 학습시키는 단계;를 더 포함하는, 제어 방법."}
{"patent_id": "10-2023-0164618", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "전자 장치의 제어 방법을 실행하기 위한 프로그램을 포함하는 컴퓨터 판독가능 기록매체에 있어서,상기 제어 방법은,자연어에 대한 데이터를 입력 받는 단계;공개특허 10-2024-0078372-4-상기 자연어에 대한 데이터를 텍스트 형식의 자연어 텍스트 데이터로 변환하는 단계;인공 지능 모델을 이용하여 변환된 자연어 텍스트 데이터에 대한 인과 관계 분석을 수행하는 단계;상기 인과 관계 분석 결과 데이터에 기초하여 상기 자연어 텍스트 데이터의 각 개체 간의 인과 관계 확률에 대한 가중치를 획득하는 단계; 및획득한 각 개체 간의 인과 관계 확률에 대한 가중치를 비교하여 상기 자연어 텍스트 데이터에 포함된 각 개체의라벨링을 결정하는 단계를 포함하는, 컴퓨터 판독가능 기록매체."}
{"patent_id": "10-2023-0164618", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "전자 장치가 개시된다. 전자 장치는 자연어에 대한 데이터를 입력 받기 위한 인터페이스, 자연어에 대한 데이터 와 인공 지능 모델을 저장하는 메모리 및 프로세서를 포함하며, 프로세서는, 자연어에 대한 데이터를 텍스트 형 식의 자연어 텍스트 데이터로 변환하고, 인공 지능 모델을 이용하여 변환된 자연어 텍스트 데이터에 대한 인과 관계 분석을 수행하며, 인과 관계 분석 결과 데이터에 기초하여 자연어 텍스트 데이터의 각 개체 간의 인과 관계 확률에 대한 가중치를 획득하고, 획득한 각 개체 간의 인과 관계 확률에 대한 가중치를 비교하여 자연어 텍스트 데이터에 포함된 각 개체의 라벨링을 결정한다."}
{"patent_id": "10-2023-0164618", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 언어 패턴을 이용하여 언어 라벨링을 수행하는 전자 장치 및 그 제어 방법에 관한 것으로, 더욱 상세 하게는 자연어 텍스트를 분류하여 라벨링을 수행하는 전자 장치 및 그 제어 방법에 관한 것이다."}
{"patent_id": "10-2023-0164618", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "인공지능을 통해 언어를 해석하고 추출하는 자연어 처리 모델을 학습하기 위해서는 관련 문장에서 추론하고자 하는 내용을 라벨링하는 작업이 필요하다. 이를 라벨링 저작도구라고 한다. 라벨링 작업은 먼저 문장을 읽고 문 장 내 필요한 단어나 어절 부분을 마우스로 밑줄을 긋고, 연관된 두 라벨을 연결한다. 자연어 처리를 학습하는데는 이미지 처리보다 많은 데이터 라벨링이 필요하므로 전체 기사에서 필요한 문장을 찾고 이를 손으로 연결하는 작업은 많은 시간을 필요로 한다. 따라서, 라벨링 저작도구에서 학습에 필요한 개체명, 술어 등을 자동으로 찾아 밑줄을 그어 놓으면 라벨러가 저 작도구의 사용을 편리하게 할 수 있다."}
{"patent_id": "10-2023-0164618", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "본 개시에 따르면, 적어도 하나의 실시 예에 따른 전자 장치는, 자연어에 대한 데이터를 입력 받기 위한 인터페 이스, 상기 자연어에 대한 데이터와 인공 지능 모델을 저장하는 메모리 및 프로세서를 포함한다. 상기 프로세서 는, 상기 자연어에 대한 데이터를 텍스트 형식의 자연어 텍스트 데이터로 변환하고, 상기 인공 지능 모델을 이 용하여 변환된 자연어 텍스트 데이터에 대한 인과 관계 분석을 수행하며, 상기 인과 관계 분석 결과 데이터에 기초하여 상기 자연어 텍스트 데이터의 각 개체 간의 인과 관계 확률에 대한 가중치를 획득하고, 획득한 각 개 체 간의 인과 관계 확률에 대한 가중치를 비교하여 상기 자연어 텍스트 데이터에 포함된 각 개체의 라벨링을 결 정한다. 한편, 본 개시의 하나 이상의 실시 예에 따른 전자 장치의 제어 방법은 자연어에 대한 데이터를 입력 받는 단계, 상기 자연어에 대한 데이터를 텍스트 형식의 자연어 텍스트 데이터로 변환하는 단계, 인공 지능 모델을 이용하여 변환된 자연어 텍스트 데이터에 대한 인과 관계 분석을 수행하는 단계, 상기 인과 관계 분석 결과 데 이터에 기초하여 상기 자연어 텍스트 데이터의 각 개체 간의 인과 관계 확률에 대한 가중치를 획득하는 단계 및 획득한 각 개체 간의 인과 관계 확률에 대한 가중치를 비교하여 상기 자연어 텍스트 데이터에 포함된 각 개체의 라벨링을 결정하는 단계를 포함한다."}
{"patent_id": "10-2023-0164618", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "본 명세서에서 사용되는 용어에 대해 간략히 설명하고, 본 개시에 대해 구체적으로 설명하기로 한다. 본 개시의 실시 예에서 사용되는 용어는 본 개시에서의 기능을 고려하면서 가능한 현재 널리 사용되는 일반적인 용어들을 선택하였으나, 이는 당 분야에 종사하는 기술자의 의도 또는 판례, 새로운 기술의 출현 등에 따라 달 라질 수 있다. 또한, 특정한 경우는 출원인이 임의로 선정한 용어도 있으며, 이 경우 해당되는 개시의 설명 부 분에서 상세히 그 의미를 기재할 것이다. 따라서 본 개시에서 사용되는 용어는 단순한 용어의 명칭이 아닌, 그 용어가 가지는 의미와 본 개시의 전반에 걸친 내용을 토대로 정의되어야 한다. 본 명세서에서, \"가진다,\" \"가질 수 있다,\" \"포함한다,\" 또는 \"포함할 수 있다\" 등의 표현은 해당 특징(예: 수 치, 기능, 동작, 또는 부품 등의 구성요소)의 존재를 가리키며, 추가적인 특징의 존재를 배제하지 않는다. 본 개시에서, \"A 또는 B,\" \"A 또는/및 B 중 적어도 하나,\" 또는 \"A 또는/및 B 중 하나 또는 그 이상\"등의 표현 은 함께 나열된 항목들의 모든 가능한 조합을 포함할 수 있다. 예를 들면, \"A 또는 B,\" \"A 및 B 중 적어도 하나,\" 또는 \"A 또는 B 중 적어도 하나\"는, 적어도 하나의 A를 포함, 적어도 하나의 B를 포함, 또는 적어도 하나의 A 및 적어도 하나의 B 모두를 포함하는 경우를 모두 지칭할 수 있다. 본 명세서에서 사용된 \"제1,\" \"제2,\" \"첫째,\" 또는 \"둘째,\"등의 표현들은 다양한 구성요소들을, 순서 및/또는 중요도에 상관없이 수식할 수 있고, 한 구성요소를 다른 구성요소와 구분하기 위해 사용될 뿐 해당 구성요소들 을 한정하지 않는다. 어떤 구성요소(예: 제1 구성요소)가 다른 구성요소(예: 제2 구성요소)에 \"(기능적으로 또는 통신적으로) 연결되 어(operatively or communicatively) coupled with/to)\" 있다거나 \"접속되어(connected to)\" 있다고 언급된 때 에는, 어떤 구성요소가 다른 구성요소에 직접적으로 연결되거나, 다른 구성요소(예: 제3 구성요소)를 통하여 연 결될 수 있다고 이해되어야 할 것이다. 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 출원에서, \"포함하다\" 또 는 \"구성되다\" 등의 용어는 명세서상에 기재된 특징, 숫자, 단계, 동작, 구성요소, 부품 또는 이들을 조합한 것 이 존재함을 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성요소, 부품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되어야 한다. 본 개시에서 \"모듈\" 혹은 \"부\"는 적어도 하나의 기능이나 동작을 수행하며, 하드웨어 또는 소프트웨어로 구현되 거나 하드웨어와 소프트웨어의 결합으로 구현될 수 있다. 또한, 복수의 \"모듈\" 혹은 복수의 \"부\"는 특정한 하드 웨어로 구현될 필요가 있는 \"모듈\" 혹은 \"부\"를 제외하고는 적어도 하나의 모듈로 일체화되어 적어도 하나의 프 로세서(미도시)로 구현될 수 있다. 이하 첨부된 도면들을 참조하여 본 개시의 일 실시 예를 보다 상세하게 설명한다. 도 1은 본 개시의 다양한 실시 예에 따른 전자 장치의 구성을 나타내는 블록도 이다. 도 1에 따르면, 전자 장치는 인터페이스, 메모리 및 프로세서를 포함한다. 인터페이스는 자연어(Natural Language)에 대한 데이터를 입력 받기 위한 구성이다. 여기서, 자연어는 컴 퓨터에서 사용하는 프로그래밍 언어와 같은 인공어(constructed language)에 대비되는 개념으로서, 일반 사회에 서 자연적으로 발생하여 사람이 의사소통을 위해 사용하는 언어를 나타낸다. 인터페이스는 통신 인터페이스, 조작 인터페이스 및 입출력 인터페이스 등을 포함할 수 있다. 예를 들어, 통신 인터페이스는 적어도 하나의 외부 장치와 통신을 수행하기 위한 구성이다. 통신 인터페이스는 적어도 하나 의 무선 통신 모듈, 적어도 하나의 유선 통신 모듈 등을 포함할 수 있다. 각 통신 모듈은 적어도 하나의 하드웨 어 칩 형태로 구현될 수 있다. 무선 통신 모듈은 와이파이 모듈, 블루투스 모듈, 적외선 통신 모듈 또는 기타 통신 모듈 중 적어도 하나의 모듈을 포함할 수 있다. 이 밖에, 통신 인터페이스는 지그비(zigbee), 3G(3rd Generation), 3GPP(3rd Generation Partnership Project), LTE(Long Term Evolution), LTE-A(LTE Advanced), 4G(4th Generation), 5G(5th Generation)등과 같은 다양한 무선 통신 규격에 따라 통신을 수행하는 적어도 하 나의 통신 칩을 포함할 수 있다. 유선 통신 모듈은 예를 들어, LAN(Local Area Network) 모듈, 이더넷 모듈, 페 어 케이블, 동축 케이블, 광섬유 케이블 또는 UWB(Ultra Wide-Band) 모듈 중 적어도 하나를 포함할 수 있다. 조작 인터페이스는 사용자 조작을 입력받기 위한 구성이다. 조작 인터페이스는 전자 장치의 본체에 구비된 각종 버튼, 터치 스크린 등을 포함할 수 있다. 입출력 인터페이스는 각종 외부 신호를 입출력하기 위한 구성이다. 입출력 인터페이스는 각종 컨텐츠 소스(예를 들어, 웹 서버, 사용자 단말 장치 등)로부터 데이터를 입력받을 수 있다. 입출력 인터페이스는 HDMI(High Definition Multimedia Interface), MHL (Mobile High- Definition Link), USB (Universal Serial Bus), USB C-type, DP(Display Port), 썬더볼트 (Thunderbolt), VGA(Video Graphics Array)포트, RGB 포트, D- SUB(Dsubminiature) 및 DVI(Digital Visual Interface) 중 적어도 하나 이상의 인터페이스로 구현될 수 있다. 입출력 인터페이스는 통신 인터페이스와 연결될 수 있다. 입출력 인터페이스는 외부 기기로부터 수신되는 정보 를 통신 인터페이스에 전송하거나 통신 인터페이스를 통해 수신되는 정보를 외부 기기에 전송할 수 있다. 메모리는 전자 장치의 동작에 필요한 적어도 하나의 명령어, 데이터, 프로그램 등을 저장할 수 있다. 일 예로, 메모리는 인터페이스를 통해 입력받은 자연어에 대한 데이터와 인공 지능 모델을 저장할 수 있다. 여기서, 인공 지능 모델은 전자 장치에 의해 학습된 모델일 수도 있고, 서버에 의해 학습된 후, 전 자 장치가 서버로부터 수신한 모델일 수도 있다. 메모리는 데이터 저장 용도에 따라 전자 장치에 임베디드된 메모리 형태로 구현되거나, 전자 장치 에 탈부착 가능한 메모리 형태로 구현될 수도 있다. 예를 들어, 전자 장치의 구동을 위한 데이터의 경우 전자 장치에 임베디드된 메모리에 저장되고, 전자 장치의 확장 기능을 위한 데이터의 경우 전자 장치와 탈부착이 가능한 메모리에 저장될 수 있다. 전자 장치에 임베디드된 메모리의 경우 휘발성 메모리(예: DRAM(dynamic RAM), SRAM(static RAM), 또는 SDRAM(synchronous dynamic RAM) 등), 비휘발성 메모리(non-volatile Memory)(예: OTPROM(one time programmable ROM), PROM(programmable ROM), EPROM(erasable and programmable ROM), EEPROM(electrically erasable and programmable ROM), mask ROM, flash ROM, 플래시 메모리(예: NAND flash 또는 NOR flash 등), 하드 드라이브, 또는 솔리드 스테이트 드라이브(solid state drive(SSD)) 중 적어도 하나로 구현될 수 있다. 메모리는 본 개시에 따른 다양한 동작들에서 생성되는 데이터를 저장하는 단일 메모리로 구현될 수 있으나, 이에 한정되는 것은 아니며, 메모리는 상이한 타입의 데이터를 각각 저장하거나, 상이한 단계에서 생성되는 데이터를 각각 저장하는 복수의 메모리를 포함하도록 구현될 수도 있다. 프로세서는 전자 장치의 각 구성과 연결되어 전자 장치의 동작을 전반적으로 제어하기 위한 구 성이다. 프로세서는 디지털 시그널 프로세서(digital signal processor(DSP)), 마이크로 프로세서 (microprocessor), GPU(Graphics Processing Unit), AI(Artificial Intelligence) 프로세서, NPU (Neural Processing Unit), TCON(Time controller)으로 구현될 수 있다. 다만, 이에 한정되는 것은 아니며, 중앙처리장 치(central processing unit(CPU)), MCU(Micro Controller Unit), MPU(micro processing unit), 컨트롤러 (controller), 어플리케이션 프로세서(application processor(AP)), 또는 커뮤니케이션 프로세서 (communication processor(CP)), ARM 프로세서 중 하나 또는 그 이상을 포함하거나, 해당 용어로 정의될 수 있 다. 또한, 프로세서는 프로세싱 알고리즘이 내장된 SoC(System on Chip), LSI(large scale integration) 로 구현될 수도 있고, ASIC(application specific integrated circuit), FPGA(Field Programmable gate array) 형태로 구현될 수도 있다. 또한, 일 실시 예에 따른 인공 지능 모델을 실행하기 위한 프로세서는 CPU, AP, DSP(Digital Signal Processor) 등과 같은 범용 프로세서, GPU, VPU(Vision Processing Unit)와 같은 그래픽 전용 프로세서 또는 NPU와 같은 인공 지능 전용 프로세서와 소프트웨어의 조합을 통해 구현될 수 있다. 프로세서는, 메모리에 저장된 기 정의된 동작 규칙 또는 인공 지능 모델에 따라, 입력 데이터를 처리하도 록 제어할 수 있다. 또는, 프로세서가 전용 프로세서(또는 인공 지능 전용 프로세서)인 경우, 특정 인공 지능 모델의 처리에 특화된 하드웨어 구조로 설계될 수 있다. 예를 들어, 특정 인공 지능 모델의 처리에 특화된 하드웨어는 ASIC, FPGA 등의 하드웨어 칩으로 설계될 수 있다. 프로세서가 전용 프로세서로 구현되는 경우, 본 개시의 실시 예를 구현하기 위한 메모리를 포함하도록 구 현되거나, 외부 메모리를 이용하기 위한 메모리 처리 기능을 포함하도록 구현될 수 있다. 프로세서는 하나 또는 복수 개로 구현될 수 있다. 프로세서는 인터페이스를 통해 개체명에 대한 데이터를 수집하여 메모리에 저장할 수 있다. 여 기서, 개체명에 대한 데이터는 개체명의 식별을 통한 라벨링 작업 또는 자연어 처리(Natural Language Processing) 등을 수행하기 위해 개체가 미리 정의된 데이터를 나타낸다. 프로세서는 오픈 API 데이터를 이용하여 개체명 식별을 위한 데이터셋(Data-set)을 수집할 수도 있다. 이러한 오픈 API 데이터에는 한국전자통신연구원(ETRI)에서 음성인식 기술 및 언어분석 기술 등을 지원하기 위 해 제공하는 AI API/DATA, 구글에서 제공하는 Google Cloud Natural Language API 등이 있다. 프로세서는 인터페이스를 통해 자연어에 대한 데이터를 입력 받아 메모리에 저장할 수도 있다. 프로세서는 자연어에 대한 데이터를 텍스트 형식(txt 형식)의 데이터로 변환할 수 있다. 이 경우, 프로세 서는 텍스트 형식으로 변환된 자연어 텍스트 데이터에 대한 토큰화(Tokenizer)를 수행하여 문서(file)를 하나로 연결된 파일 형태로 변환할 수 있다. 예를 들어, 복수의 페이지로 구성된 화재 관련 보고서를 이용하여 화재에 대한 라벨링을 수행할 때, 페이지별로 나눠서 라벨링을 수행하게 되면, 복수의 페이지 중에서 화재에 대 한 내용이 없는 페이지들이 존재한다. 따라서, 프로세서는 라벨링의 효율을 높이기 위해 변환된 자연어 텍스트 데이터가 복수의 페이지로 구성된 경우, 토큰화(Tokenizer)를 통해 자연어 텍스트 데이터를 페이지 구분이 없이 연결된 파일 형태로 변환할 수 있 다. 한편, 토큰화(Tokenizer)는 주어진 문장을 일정한 단위로 분류하여 기기가 받아들일 수 있도록 하는 작업을 나 타낸다. 인공 지능 모델에서 모델이 사람의 문장을 이해하고, 띄어쓰기를 보정해주고, 작문을 만드는 등의 텍스 트(Text) 관련 처리를 하기 위해서는 모델에 텍스트를 입력으로 넣어 주어야 한다. 하지만, 학습 모델에 텍스트 를 바로 입력할 수는 없고, 숫자 데이터만 입력할 수 있다. 이를 위해 텍스트 데이터를 숫자 데이터로 변환해주 는 토큰화(Tokenizer) 작업이 수행된다. 예를 들어, 인터페이스를 통해 \"What time is it\" 이라는 데이터 입력이 들어오면, 다음 예시와 같이 각 숫자에 해당되는 숫자값으로 텍스트 데이터를 변환한다. [예시] What time is it -> 101 981 112 303 837 234 249 543 332 857 943 653 원본 텍스트 데이터 대신 모델이 이해할 수 있는 숫자 데이터로 변환해줌으써 모델이 식별할 수 있게 되는 것이다. 이러한 토큰화에는 단어(어절) 단위로 토큰화하는 방법, 문자를 하나씩 나눠서 문자 단위로 토큰화하는 방 법, 서브워드 단위로 토큰화하는 방법 등이 있다. 예를 들어, 단어 단위로 토큰화하는 방법은 단어와 단어 사이 의 공백 문자를 이용하여 토큰화하는 방법을 포함할 수 있다. 한국어의 경우를 예로 들면, 자음과 모음이 결합하여 음절이 되고, 음절들이 결합하여 단어가 되며, 단어와 품 사들이 모여 문장을 이루게 된다. 이러한 문장들이 결합된 보고서가 주어지면, 공백을 기반으로 하는 토큰화는 띄어쓰기로 인해 생기는 공백을 이용하여 문장을 각각의 조각(토큰)으로 분류하고, 분류된 조각(토큰)을 이용하 여 사전으로 만들 수 있다. 여기서, 사전은 각각의 토큰에 번호 또는 인텍스를 부여하는 것을 나타낸다. 또한, 토큰화는 형태소 분석기를 이용하여 문장을 분류하는 형태소 토큰화 방법을 포함할 수도 있다. 여기서, 문장 분류를 위해 사용되는 형태소 분석기에는 미캡(Mecab), 코모란(Komoran), 꼬꼬마(Kkma), Okt, 센텐스피스 (Sentencepiece) 등이 있다. 프로세서는 개체명에 대한 데이터에 기초하여 자연어 텍스트 데이터에 대한 인과 관계 분석을 수행할 수 있다. 여기서, 인과 관계 분석은 자연어 텍스트 데이터의 특정 문장에서 인과 관계가 존재하는지 여부와, 인과 관계가 존재한다면 문장에서 원인과 결과의 위치까지 분석하는 것을 나타낸다. 예를 들어, 인터페이스를 통해 \"남성은 안전벨트를 매지 않았기 때문에 교통사고에서 크게 다쳤다.\"라는 자연어 텍스트 데이터가 입력되 는 경우, \"안전벨트를 매지 않았기\"의 부분이 원인에 해당하고, \"교통사고에서 크게 다쳤다\"는 결과를 의미할수 있다. 프로세서는 자연어 텍스트 데이터의 인과 관계 분석 결과에 기초하여 자연어 텍스트 데이터에서 각 개체의 위치 정보를 태깅할 수 있다. 프로세서가 각 개체의 위치 정보를 태깅하는 방법에 대해서는 후술하는 부분 에서 다시 설명한다. 프로세서는 자연어 텍스트 데이터의 인과 관계 분석 결과 데이터 또는 위치 정보의 태깅 결과 데이터를 인 공 지능 모델에 입력하여 각 개체에 대한 라벨링 확률을 획득할 수 있다. 여기서, 인공 지능 모델은 개체명에 대한 데이터와 샘플 자연어 텍스트 데이터에 포함된 각 개체의 인과 관계 분석을 수행하고, 각 개체 간의 인과 관계 확률에 대한 가중치를 인공 지능 모델을 통해 학습하여 획득된 모델일 수 있다. 또한, 프로세서는 인 공 지능 모델을 이용하여 획득한 인과 관계 확률에 대한 가중치를 비교하여 각 개체의 라벨링을 결정할 수 있다. 한편, 본 개시에 따른 인공 지능과 관련된 기능은 프로세서와 메모리를 통해 동작될 수 있다. 하나 또는 복수의 프로세서는, 메모리에 저장된 기 정의된 동작 규칙 또는 인공 지능 모델에 따라 입력 데이터 를 처리하도록 제어한다. 또는, 하나 또는 복수의 프로세서가 인공 지능 전용 프로세서인 경우, 인공 지능 전용 프로세서는 특정 인공 지능 모델의 처리에 특화된 하드웨어 구조로 설계될 수 있다. 기 정의된 동작 규칙 또는 인공 지능 모델은 학습을 통해 만들어진 것을 특징으로 한다. 여기서, 학습을 통해 만들어진다는 것은, 기본 인공 지능 모델이 학습 알고리즘에 의하여 다수의 학습 데이터들 을 이용하여 학습됨으로써, 원하는 특성(또는, 목적)을 수행하도록 설정된 기 정의된 동작 규칙 또는 인공 지능 모델이 만들어짐을 의미한다. 이러한 학습은 본 개시에 따른 인공 지능이 수행되는 기기 자체에서 이루어질 수 도 있고, 별도의 서버 및/또는 시스템을 통해 이루어 질 수도 있다. 학습 알고리즘의 예로는, 지도형 학습 (supervised learning), 비지도형 학습(unsupervised learning), 준지도형 학습(semi-supervised learning) 또 는 강화 학습(reinforcement learning)이 있으나, 전술한 예에 한정되지 않는다. 인공 지능 모델은 복수의 신경망 레이어들로 구성될 수 있다. 복수의 신경망 레이어들 각각은 복수의 가중치들 (weight values)을 갖고 있으며, 이전(previous) 레이어의 연산 결과와 복수의 가중치들 간의 연산을 통해 신경 망 연산을 수행한다. 복수의 신경망 레이어들이 갖고 있는 복수의 가중치들은 인공 지능 모델의 학습 결과에 의 해 최적화될 수 있다. 예를 들어, 학습 과정 동안 인공 지능 모델에서 획득한 로스(loss) 값 또는 코스트(cost) 값이 감소 또는 최소화되도록 복수의 가중치들이 갱신될 수 있다. 인공 지능 모델은 심층 신경망(DNN:Deep Neural Network)를 포함할 수 있으며, 예를 들어, CNN(Convolutional Neural Network), DNN (Deep Neural Network), RNN(Recurrent Neural Network), RBM(Restricted Boltzmann Machine), DBN(Deep Belief Network), BRDNN(Bidirectional Recurrent Deep Neural Network), GAN(Generative Adversarial Network) 또는 심층 Q-네트워크(Deep Q-Networks) 등이 있으나, 이에 한정되는 것은 아니다. 도 2 및 도 3은 본 개시의 다양한 실시 예에 따른 개체명에 대한 데이터를 설명하기 위한 도면들이다. 도 2는 한국전자통신연구원(ETRI)에서 제공하는 AI API/DATA이고, 도 3은 구글에서 제공하는 Google Cloud Natural Language API를 나타낸다. 프로세서는 인터페이스를 통해 오픈 API 데이터에 접속하여 개체명에 대한 데이터를 수집할 수 있다. 도 2에 따르면, AI API/DATA에서 제공하는 개체명 식별을 위한 개체명 태그셋은 인명, 지명, 기관명 등과 같은 개체명을 식별하는 기술과, 특정 개체를 표현하는 단어에 대한 의미 정보를 제공한다. 또한, 개체명 태그셋은 15개의 대분류와 146개의 세분류로 구성될 수 있다. 이 경우, 프로세서는 자연어 텍스트 데이터에서 비자연 언어 부호들을 제거하는 전처리를 수행할 수도 있 다. 예를 들어, 프로세서는 자연어 텍스트 데이터에서 표, 그림 및 특수문자 등을 제거할 수 있다. 도 4 및 도 5는 본 개시의 다양한 실시 예에 따른 자연어 텍스트 데이터의 간략화를 설명하기 위한 도면이다. 프로세서는 자연어 텍스트 데이터를 간략화하여 토큰의 수를 줄이기 위한 전처리를 수행할 수도 있다. 도 4와 같이, 자연어 처리를 위한 임베딩(Embedding) 과정에서 토큰의 수가 너무 많으면 에러가 발생할 수 있다. 프로세서는 자연어 처리 과정에서 토큰의 수가 많아 에러가 발생하는 경우, 도 5와 같이 순차적으로 토큰 의 수를 줄이는 간략화를 수행할 수 있다. 도 5에 따르면, 최초에 5개의 단락으로 구성된 5000개의 토큰이 순차"}
{"patent_id": "10-2023-0164618", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "적인 간략화 과정을 통해 1000~2000개 사이의 토큰으로 구성된 하나의 파일로 요약된 것을 확인할 수 있다. 도 6 내지 도 9는 본 개시의 다양한 실시 예에 따른 자연어 텍스트 데이터의 인과 관계 분석을 설명하기 위한 도면들이다. 도 6은 BERT 모델에서 개체의 위치 정보를 표시하지 않고 개체 간의 인과 관계를 예측하는 방법을 나타내고, 도 7은 BERT 모델에서 개체의 위치 정보를 표시하고, 두 개체 간의 인과 관계를 예측하는 방법을 나 타낸다. 이하의 설명에서는 설명의 편의를 위해 자연어 텍스트 데이터의 인과 관계 분석을 위한 인공 지능 모델을 BERT(Bidirectional Encoder Representations from Transformers)로 가정하여 설명한다. BERT는 인공 지능 학 습 및 자연어 처리를 위해 구글에서 제공하는 인공 지능 모델을 나타낸다. 도 6 및 도 7에 따르면, 프로세서는 자연어 텍스트 데이터의 언어적 분석을 수행하여 인과 관계를 분류할 수 있다. 구체적으로, 프로세서는 자연어 텍스트 데이터에서 언어적으로 분석된 텍스트와 목표 의미적 관 계 패턴들을 매칭한 결과를 기초로 의미적 관계 라벨들을 생성하여 라벨링된 텍스트를 생성할 수도 있다. 도 6 에서 CLS(Special Classification token)는 모든 문장의 첫번째(즉, 문장의 시작)를 나타내는 토큰이고, SEP(Special Separator token)는 문장의 끝을 나타내는 토큰이다. SEP는 앞의 문장과 다음 문장을 구별하기 때 문에 앞뒤 문장 사이를 더욱 쉽게 구별할 수 있도록 도와준다. 프로세서는 BERT를 기반으로 인과 관계 분류를 위한 개체들을 식별할 수 있다. 도 6은 개체 위치 정보가 태깅되지 않은 문장의 형태에서 [CLS] 토큰을 통해 인과 관계를 분류하는 모델을 나타낸다. 프로세서는 자연어 텍스트 데이터의 인과 관계 분석 결과에 기초하여 자연어 텍스트 데이터에서 각 개체의 위치 정보를 태깅할 수도 있다. 도 7에 따르면, 프로세서는 BERT를 이용하여 개체의 위치 정보를 태깅한 문장에 각 개체 시작 위치([E1], [E2])를 나타내는 개체 표시 토큰의 은닉 상태(hidden states) 값을 결합하여 두 개체 간의 인과 관계를 예측할 수 있다. 도 7에서, [E1] 및 [E2]는 각 개체의 시작 위치를 나타내는 토큰이 고, [/E1] 및 [/E2]는 각 개체의 끝을 나타내는 토큰이다. 이 경우, 개체 위치 정보를 표시하지 않는 모델보다 개체 시작 위치를 기반으로 각 개체의 위치 정보를 표시하는 모델의 인과 관계 분류 방법이 더욱 뛰어난 성능을 나타낸다. 인공 지능 모델의 학습에서 문장 내 두 개체 간의 위치 정보가 모델이 인과 관계를 학습하고 분류하 는데 큰 영향을 미치기 때문이다. 도 8 및 도 9는 BERT를 이용하여 한국어의 인과 관계를 분석하는 모델을 설명하기 위한 도면이다. 도 8에 따르 면, 프로세서는 자연어 텍스트 데이터가 CSV 형식으로 입력되는 경우, CSV 형식의 데이터를 TSV 형식으로 변환할 수 있다. 여기서, CSV(Comma Separated Value)는 쉼표를 기준으로 항목을 구분하여 저장한 데이터를 나타낸다. 일반적으 로, 데이터베이스나 표 계산 소프트웨어 데이터를 보존하기 위해 이런 형식이 사용된다. CSV 형식은 각 항목이 나 판매 내용마다 쉼표(comma)로 구분하여 기록한다. CSV 형식의 파일은 텍스트 파일로 보존하여 문서 처리기나 편집기에서 열람 및 편집할 수도 있다. CSV 형식은 수많은 애플리케이션에서 취급하는 범용 형식이기 때문에 모 바일 장치(mobile device)나 PDA(personal digital assistant)와 PC 사이에 주소록이나 표의 데이터를 주고 받 을 때에도 데이터 파일을 CSV 형식으로 변환해서 송수신할 수 있다. TSV(Tab-Separated-Values)는 데이터의 열을 탭으로 구분하여 저장하는 것을 나타낸다. TSV는 표 형식의 데이터 를 저장하기 위한 간단한 텍스트 기반 파일 형식이다. TSV는 광범위하게 지원되는 단순한 파일 형식이므로 형식 을 지원하는 서로 다른 컴퓨터 프로그램 간에 표 형식의 데이터를 이동하는 데이터 교환에 사용된다. 예를 들어, TSV 파일을 사용하여 데이터베이스에서 스프레드시트로 정보를 전송할 수 있다. 도 9에 따르면, CSV 형식의 데이터는 문장에서 두개의 대상 개체 사이의 관계를 나타내고, TSV 형식의 데이터는 문장에서 두개의 대상 개체 사이의 관계와, 주어 및 목적어를 나타낼 수 있다. 도 10은 본 개시의 다양한 실시 예에 따른 자연어 텍스트 데이터의 라벨링을 설명하기 위한 도면이다. 도 10에 따르면, 프로세서는 변환된 TSV 형식의 데이터에 기초하여 원인 개체와 결과 개체를 태깅하고, 두 개체가 어떤 재난 유형에 속하는지 두 개체 간의 관계를 라벨링할 수 있다. 예를 들어, 프로세서는 인덱스 (id) 번호를 이용하여 원인 개체와 결과 개체의 시작과 끝을 나타내는 특정 토큰(special token)을 추가할 수 있다. 도 10은 자연어 텍스트 데이터에 기초하여 원인 개체의 시작 인덱스 번호, 원인 개체의 끝 인덱스 번호, 결과 개체의 시작 인텍스 번호 및 결과 개체의 끝 인덱스 번호가 설정된 것을 나타낸다. 이 경우, 프로세서 는 라벨링 결과 데이터를 jsonl 파일 형식으로 출력할 수도 있다. 도 11 내지 도 13은 본 개시의 다양한 실시 예에 따른 개체명 식별 결과를 설명하기 위한 도면이다. 도 11은 인 터페이스를 통해 입력받은 자연어 텍스트 데이터를 나타내고, 도 12 및 도 13은 오픈 API 데이터에 기초하여 입력받은 자연어 텍스트 데이터에 대한 개체명 식별을 수행한 결과를 나타낸다. 프로세서는 오픈 API 데이터에 기초하여 자연어 텍스트 데이터에 대한 개체명을 식별하고, 자연어 텍스트 데이터에 대한 라벨링을 수행할 수 있다. 도 12에서는 형태소 분석을 통해 자연어 텍스트 데이터에 언어 분석을 수행한 것을 나타낸다. 도 13에 나타난 바와 같이, 프로세서는 인공 지능 모델을 통해 각 개체에 대한 개 체명 식별 확률의 가중치(weight)를 획득할 수도 있다. 도 14 내지 도 16은 본 개시의 다양한 실시 예에 따른 전자 장치의 제어 방법을 설명하기 위한 흐름도이다. 도 14에 따르면, 전자 장치는 자연어에 대한 데이터를 입력 받는다(S1410). 이 경우, 전자 장치는 텍스트 형식 으로 구현되지 않은 자연어에 대한 데이터를 입력받을 수도 있다. 전자 장치는 입력받은 자연어에 대한 데이터 가 텍스트 형식이 아니면, 자연어에 대한 데이터를 텍스트 형식의 자연어 텍스트 데이터로 변환한다(S1420). 전자 장치는 인공 지능 모델을 이용하여 변환된 자연어 텍스트 데이터에 대한 인과 관계 분석을 수행한다 (S1430). 자연어 텍스트 데이터에 대한 라벨링을 수행하기 위해서는 자연어 텍스트 데이터의 각 개체를 식별하 기 위한 언어적 분석을 먼저 수행해야 한다. 자연어 텍스트 데이터에 포함된 각각의 개체를 식별하는 작업은 라 벨링을 수행하는 전자 장치나 작업자에 의해 수행될 수 있다. 또는, 전자 장치가 오픈 소스로 제공된 오픈 API 데이터에 기초하여 자연어 텍스트 데이터의 각 개체를 식별할 수도 있다. 예를 들어, 오픈 API 데이터에는 한국 전자통신연구원(ETRI)의 AI API/DATA, 구글에서 제공하는 Google Cloud Natural Language API 등이 있다. 전자 장치는 오픈 API 데이터에 기초하여 자연어 텍스트 데이터로부터 원인 개체와 결과 개체를 식별할 수 있다. 전자 장치는 인과 관계 분석 결과 데이터에 기초하여 자연어 텍스트 데이터의 각 개체 간의 인과 관계 확률에 대한 가중치를 획득한다(S1440). 이 경우, 전자 장치는 미리 학습된 인공 지능 모델을 이용하여 자연어 텍스트 데이터의 각 개체 간의 인과 관계 확률에 대한 가중치를 획득할 수 있다. 전자 장치는 인공 지능 모델을 이용하여 획득한 각 개체 간의 인과 관계 확률에 대한 가중치를 비교하여 자연어 텍스트 데이터에 포함된 각 개체의 라벨링을 결정한다(S1450). 도 15는 자연어 텍스트 데이터에 대한 인과 관계 분석 과정을 설명하기 위한 도면이다. 도 15에 따르면, 전자 장치는 자연어 텍스트 데이터를 TSV 형식의 텍스트 데이터로 변환할 수 있다(S1510). 이 경우, 전자 장치는 자 연어 텍스트 데이터에 대한 토큰화(Tokenizer)를 먼저 수행하여 데이터를 하나로 연결된 파일 형태로 변환할 수 있다. 전자 장치는 토큰화가 수행된 자연어 텍스트 데이터에서 토큰의 수를 기설정된 개수 이내로 줄여 간략화 하기 위한 전처리를 수행할 수도 있다. 전자 장치는 변환된 TSV 형식의 텍스트 데이터에 기초하여 원인 개체와 결과 개체를 태깅할 수 있다(S1520). 예 를 들어, 전자 장치는 인덱스(id) 번호를 이용하여 원인 개체와 결과 개체의 시작과 끝을 나타내는 특정 토큰 (special token)을 추가하는 방식으로 원인 개체와 결과 개체를 태깅할 수도 있다. 도 16은 자연어 텍스트 데이터에 대한 인과 관계 분석을 위해 수행되는 인공 지능 모델의 학습을 설명하기 위한 도면이다. 전자 장치는 개체명에 대한 데이터와 샘플(sample) 자연어 텍스트 데이터를 수집하여 메모리에 저장 할 수 있다(S1610). 이 경우, 전자 장치는 오픈 API 데이터를 이용하여 개체명에 대한 데이터를 수집할 수 있다. 또한, 전자 장치는 미리 설정된 분석 리스트나 관심 대상이 되는 주제에 따라 샘플 자연어 텍스트 데이터 를 수집하여 메모리에 저장할 수 있다. 예를 들어, 화재에 관련된 보고서의 라벨링을 목표로 하는 경우, 전자 장치는 인터넷망이나 뉴스 등을 통해 화재 관련 문서를 수집하여 인공 지능 모델의 학습을 위한 학습 데이터로 저장할 수 있다. 전자 장치는 인공 지능 모델을 이용하여 메모리에 저장된 개체명에 대한 데이터와 샘플 자연어 텍스트 데이터에 포함된 각 개체의 인과 관계를 학습시킬 수 있다(S1620). 이 경우, 전자 장치는 미리 설정된 주제에 따라 수집 된 샘플 자연어 텍스트 데이터를 이용하여 인공 지능 모델을 학습시키기 때문에 원인 개체와 결과 개체의 식별 정확도를 높일 수 있다. 이와 같이 본 개시의 다양한 실시 예에 따른 전자 장치 및 그 제어 방법은 자연어 텍스트 데이터에 대한 라벨링 을 자동화하여 인공지능을 통해 언어를 해석하는 자연어 처리의 효율을 증대할 수 있다. 한편, 본 개시의 실시 예에 따르면, 이상에서 설명된 다양한 실시 예들은 기기(machine)(예: 컴퓨터)로 읽을 수 있는 저장 매체(machine-readable storage media)에 저장된 명령어를 포함하는 소프트웨어로 구현될 수 있다. 기기는, 저장 매체로부터 저장된 명령어를 호출하고, 호출된 명령어에 따라 동작이 가능한 장치로서, 개시된 실 시 예들에 따른 전자 장치를 포함할 수 있다. 명령이 프로세서에 의해 실행될 경우, 프로세서가 직접, 또는 프로세서의 제어 하에 다른 구성요소들을 이용하여 명령에 해당하는 기능을 수행할 수 있다. 명령은 컴파일러 또 는 인터프리터에 의해 생성 또는 실행되는 코드를 포함할 수 있다. 기기로 읽을 수 있는 저장 매체는, 비일시적 (non-transitory) 저장매체의 형태로 제공될 수 있다. 여기서, '비일시적'은 저장매체가 신호(signal)를 포함하 지 않으며 실재(tangible)한다는 것을 의미할 뿐 데이터가 저장매체에 반영구적 또는 임시적으로 저장됨을 구분 하지 않는다. 또한, 본 개시의 일 실시 예에 따르면, 이상에서 설명된 다양한 실시 예들에 따른 방법은 컴퓨터 프로그램 제품 (computer program product)에 포함되어 제공될 수 있다. 컴퓨터 프로그램 제품은 상품으로서 판매자 및 구매자 간에 거래될 수 있다. 컴퓨터 프로그램 제품은 기기로 읽을 수 있는 저장 매체(예: compact disc read only memory (CD-ROM))의 형태로, 또는 어플리케이션 스토어(예: 플레이 스토어TM)를 통해 온라인으로 배포될 수 있 다. 온라인 배포의 경우에, 컴퓨터 프로그램 제품의 적어도 일부는 제조사의 서버, 어플리케이션 스토어의 서버, 또는 중계 서버의 메모리와 같은 저장 매체에 적어도 일시 저장되거나, 임시적으로 생성될 수 있다. 또한, 본 개시의 일 실시 예에 따르면, 이상에서 설명된 다양한 실시 예들은 소프트웨어(software), 하드웨어 (hardware) 또는 이들의 조합을 이용하여 컴퓨터(computer) 또는 이와 유사한 장치로 읽을 수 있는 기록 매체 내에서 구현될 수 있다. 일부 경우에 있어 본 명세서에서 설명되는 실시 예들이 프로세서 자체로 구현될 수 있 다. 소프트웨어적인 구현에 의하면, 본 명세서에서 설명되는 절차 및 기능과 같은 실시 예들은 별도의 소프트웨 어로서 구현될 수도 있다. 소프트웨어 각각은 본 명세서에서 설명되는 하나 이상의 기능 및 동작을 수행할 수 있다. 한편, 상술한 다양한 실시 예들에 따른 기기의 프로세싱 동작을 수행하기 위한 컴퓨터 명령어(computer instructions)는 비일시적 컴퓨터 판독 가능 매체(non-transitory computer-readable medium)에 저장될 수 있 다. 이러한 비일시적 컴퓨터 판독 가능 매체에 저장된 컴퓨터 명령어는 특정 기기의 프로세서에 의해 실행되었 을 때 상술한 다양한 실시 예에 따른 기기에서의 처리 동작을 특정 기기가 수행하도록 한다. 비일시적 컴퓨터 판독 가능 매체란 레지스터, 캐쉬, 메모리 등과 같이 짧은 순간 동안 데이터를 저장하는 매체가 아니라 반영구 적으로 데이터를 저장하며, 기기에 의해 판독(reading)이 가능한 매체를 의미한다. 비일시적 컴퓨터 판독 가능 매체의 구체적인 예로는, CD, DVD, 하드 디스크, 블루레이 디스크, USB, 메모리카드, ROM 등이 있을 수 있다. 또한, 상술한 다양한 실시 예들에 따른 구성 요소(예: 모듈 또는 프로그램) 각각은 단수 또는 복수의 개체로 구 성될 수 있으며, 전술한 해당 서브 구성 요소들 중 일부 서브 구성 요소가 생략되거나, 또는 다른 서브 구성 요 소가 다양한 실시 예에 더 포함될 수 있다. 대체적으로 또는 추가적으로, 일부 구성 요소들(예: 모듈 또는 프로 그램)은 하나의 개체로 통합되어, 통합되기 이전의 각각의 해당 구성 요소에 의해 수행되는 기능을 동일 또는 유사하게 수행할 수 있다. 다양한 실시 예들에 따른, 모듈, 프로그램 또는 다른 구성 요소에 의해 수행되는 동 작들은 순차적, 병렬적, 반복적 또는 휴리스틱하게 실행되거나, 적어도 일부 동작이 다른 순서로 실행되거나, 생략되거나, 또는 다른 동작이 추가될 수 있다. 이상에서는 본 개시의 바람직한 실시 예에 대하여 도시하고 설명하였지만, 본 개시는 상술한 특정의 실시 예에"}
{"patent_id": "10-2023-0164618", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "한정되지 아니하며, 청구범위에서 청구하는 본 개시의 요지를 벗어남이 없이 당해 개시에 속하는 기술분야에서 통상의 지식을 가진 자에 의해 다양한 변형실시가 가능한 것은 물론이고, 이러한 변형실시들은 본 개시의 기술 적 사상이나 전망으로부터 개별적으로 이해되어서는 안될 것이다."}
{"patent_id": "10-2023-0164618", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 개시의 다양한 실시 예에 따른 전자 장치의 구성을 나타내는 블록도 이다. 도 2 및 도 3은 본 개시의 다양한 실시 예에 따른 개체명에 대한 데이터를 설명하기 위한 도면들이다. 도 4 및 도 5는 본 개시의 다양한 실시 예에 따른 자연어 텍스트 데이터의 간략화를 설명하기 위한 도면이다. 도 6 내지 도 9는 본 개시의 다양한 실시 예에 따른 자연어 텍스트 데이터의 인과 관계 분석을 설명하기 위한 도면들이다. 도 10은 본 개시의 다양한 실시 예에 따른 자연어 텍스트 데이터의 라벨링을 설명하기 위한 도면이다. 도 11 내지 도 13은 본 개시의 다양한 실시 예에 따른 개체명 식별 결과를 설명하기 위한 도면이다. 도 14 내지 도 16은 본 개시의 다양한 실시 예에 따른 전자 장치의 제어 방법을 설명하기 위한 흐름도이다."}
