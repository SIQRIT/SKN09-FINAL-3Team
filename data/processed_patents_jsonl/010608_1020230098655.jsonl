{"patent_id": "10-2023-0098655", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2025-0017814", "출원번호": "10-2023-0098655", "발명의 명칭": "치과 전자 차팅 시스템 및 방법", "출원인": "주식회사 비스윙", "발명자": "김상용"}}
{"patent_id": "10-2023-0098655", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "치과 전자 차팅 시스템에 있어서,진료 후 의사의 음성정보, 종이차트 정보, 전자 차트 입력정보 중 적어도 하나를 수집하는 정보 인식 단말;상기 정보 인식 단말로부터 의사의 음성정보, 종이차트 정보, 입력정보를 수집하여 전자 차트와 처방전을 생성하는 서버; 를 포함하고,상기 서버; 는음성인식 모델을 통해 의사의 음성정보에서 처방정보를 추출하는 제1추출부;의사의 음성정보가 수집된 경우, STT(Speech to text) 모델을 통해, 의사의 음성정보를 텍스트로 변환하는 변환부;의사의 음성정보를 변환한 텍스트에서 처방정보를 추출하는 제2추출부; 및상기 추출된 처방정보를 입력하여 전자 차트를 생성하는 생성부; 를 포함하고상기 생성부; 는음성정보에서 추출한 처방 정보 및 텍스트에서 추출한 처방정보가 일치하는 경우, 상기 처방정보를 입력하여 전자 차트를 생성하는 것을 특징으로 하는 치과 전자 차팅 시스템."}
{"patent_id": "10-2023-0098655", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 서버; 는처방전에 기록된 처방정보와 의사의 음성정보를 변환한 텍스트에서 추출한 처방정보의 일치 여부를 확인하거나,음성정보에서 추출된 처방정보와, 상기 텍스트에서 추출된 처방정보의 일치 여부를 확인하는 확인부; 음성인식을 통해, 전자차트를 검색하고 검색된 정보를 출력하는 검색부; 및상기 전자 차트에 입력된 처방 정보를 기반으로 처방전을 생성하는 처방전 생성부; 를 더 포함하는 것을 특징으로 하는 치과 전자 차팅 시스템."}
{"patent_id": "10-2023-0098655", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제1항에 있어서, 상기 변환부; 는종이차트를 스캔한 이미지가 수집된 경우, 텍스트 인식 모델을 통해 상기 이미지에서 텍스트 이미지를추출하고, 상기 이미지에서 의사가 그린 그림 이미지를 추출하고, 상기 추출된 텍스트 이미지를 텍스트로 변환하여, 변환된 텍스트와 그림 이미지를 생성하는 것을 특징으로 하는 치과 전자 차팅 시스템."}
{"patent_id": "10-2023-0098655", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서, 상기 전자차트 생성부; 는종이차트를 스캔한 이미지가 수집된 경우, 변환부로부터 입력된 텍스트에서 처방 정보를 추출하고, 추출된 처방정보를 입력하여 전자 차트를 생성하는 것을 특징으로 하는 치과 전자 차팅 시스템. 공개특허 10-2025-0017814-3-청구항 5 제2항에 있어서, 상기 확인부; 는생성된 처방전을 정보 인식 단말로 전송하여, 의사의 최종 승인 정보를 수집하는 것을 특징으로 하는 치과 전자차팅 시스템."}
{"patent_id": "10-2023-0098655", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제1항에 있어서, 상기 서버; 는최종 진료기록을 기반으로 보험진료에 대해 국민건강보험공단에 공단부담금을 청구하고, 보험청구에 관한 재료구매 내역 및 재고관리를 수행하는 관리부; 를 더 포함하는 것을 특징으로 하는 치과 전자 차팅 시스템."}
{"patent_id": "10-2023-0098655", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "치과 전자 차팅 방법에 있어서,(A) 제1추출부는 음성인식 모델을 통해 의사의 음성정보에서 처방정보를 추출하는 단계;(B) 변환부는 의사의 음성정보가 수집된 경우, STT(Speech to text) 모델을 통해, 의사의 음성정보를 텍스트로변환하고, 변환된 텍스트에서 처방정보를 추출하는 단계;(C) 생성부는 음성정보에서 추출된 처방정보와 텍스트에서 추출된 처방정보가 일치하는 경우, 전자 차트를 생성하는 단계;(D) 처방전 생성부는 전자 차트의 처방정보를 기반으로 처방전을 생성하고, 생성된 처방전을 의사가 소지한 정보수집 단말로 전송하는 단계;(E) 처방전 생성부는 의사가 소지한 정보수집 단말로부터 처방전에 대한 최종 승인 정보를 수신하는 경우, 상기처방전을 간호 스테이션 단말로 전송하는 단계; 를 포함하는 치과 전자 차팅 방법."}
{"patent_id": "10-2023-0098655", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "실시예에 따른 치과 전자 차팅 시스템 및 방법은 진료 후 의사의 음성인식을 통해, 자동으로 의료 차트를 생성 한다. 또한, 실시예에서는 인식된 의사의 음성을 STT(Speech to text) 모델을 통해 텍스트 변환하여 저장할 수 있다. 또한, 실시예에서는 종이차트를 스캔하여 차트 이미지를 생성하고, 생성된 차트 이미지와 차트 이미지에서 텍스 트 및 그림 데이터를 추출하여 저장할 수 있다. 또한, 실시예에서는 의사의 음성을 텍스트로 변환한 후, 텍스트 에서 처방 정보를 추출하여, 추출된 처방 정보와 처방전 정보를 비교하여, 의사의 처방이 제대로 기입되었는지 확인할 수 있다."}
{"patent_id": "10-2023-0098655", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 치과 전자 차팅 시스템 및 방법에 관한 것으로 구체적으로, 진료 후 치과의사가 차트 작성을 위해 발 화하는 음성을 인식하여 환자 별 차트 정보를 생성하는 치과 전자 차팅 시스템 및 방법에 관한 것이다."}
{"patent_id": "10-2023-0098655", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "본 명세서에서 달리 표시되지 않는 한, 이 섹션에 설명되는 내용들은 이 출원의 청구항들에 대한 종래 기술이 아니며, 이 섹션에 포함된다고 하여 종래 기술이라고 인정되는 것은 아니다. 의료 차트는 환자의 의료 정보를 기록하고 관리하는 도구이다. 치과진료 차트는 환자의 건강 상태, 진단 결과, 치료계획, 진료내용, 처방전, 검사 결과, 수술 기록, 기공의뢰서, 약물 알레르기, 예방 접종 내역 등 다양한 의 료 정보를 포함한다. 의료 차트는 의료진들이 환자의 건강 상태를 추적하고 의료 결정을 내리는 데 도움을 주는 중요한 도구이다. 의료 차트는 종이 기록뿐만 아니라 전자 의료 기록(Electronic Medical Record, EMR) 형식으 로도 사용될 수 있다. 전자 의료 기록은 의료 정보를 전자적으로 저장, 관리 및 공유하기 위한 시스템이다. 전 자 의료 기록을 사용하면 의료진들이 효율적으로 의료 정보에 접근하고 업데이트할 수 있으며, 의료 정보의 정 확성과 안전성을 향상시킬 수 있다. 또한, 의료 차트는 의료진들 간의 의사소통과 협력을 강화하고, 환자의 치료 과정을 추적하고 개선하는 데 도움 을 준다. 정확한 진료내용의 기록은 환자와의 의료 분쟁에 있어서도 중요한 자료가 된다. 아울러, 의료 차트는 환자들이 자신의 의료 정보를 열람하고 자기 관리를 위한 정보를 얻는 데에도 사용될 수 있다.특히, 건강보험제도가 발달된 한국의 경우에는 의료기관은 진료내용을 바탕으로 보험진료에 대한 공단부담액을 국민건강보험공단에 청구하는데 전자 차팅 시스템을 사용하면 청구과정을 간소화 할 수 있으며 청구 오류를 줄 일 수 있다. 하지만, 종래의 의료 차트는 진료 후 의사가 직접 컴퓨터를 통해 입력해만 하는 번거로움이 있다. 의료 차트에 는 증상, 처방약 등의 진료 정보를 입력하는데, 약의 경우 데이터베이스에서 약 코드와 수량을 불러와 입력해야 하므로 입력 시 불편함이 크다. 또한, 의사가 컴퓨터에서 직접 차트 입력을 해야만 하므로 의사의 움직임 및 가 동 범위를 제한하는 불편이 있다. 선행기술문헌 특허문헌 (특허문헌 0001) 1. 한국 특허등록 제10-2241021호 (2021.04.12) (특허문헌 0002) 2. 한국 특허공개 제10-2014-0033892호 (2014.03.19)"}
{"patent_id": "10-2023-0098655", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "실시예에 따른 치과 전자 차팅 시스템 및 방법은 진료 후 의사의 음성인식을 통해, 자동으로 의료 차트를 생성 한다. 또한, 실시예에서는 인식된 의사의 음성을 STT(Speech to text) 모델을 통해 텍스트 변환하여 저장할 수 있다. 또한, 실시예에서는 종이차트를 스캔하여 차트 이미지를 생성하고, 생성된 차트 이미지와 차트 이미지에서 텍스 트 및 그림 데이터를 추출하여 저장할 수 있다. 또한, 실시예에서는 의사의 음성을 텍스트로 변환한 후, 텍스트 에서 처방 정보를 추출하여, 추출된 처방 정보와 처방전 정보를 비교하여, 의사의 처방이 제대로 기입되었는지 확인할 수 있다. 또한, 작성된 진료 내용과 처방내용을 바탕으로 기공의뢰서가 작성되며, 관련 기공소로 기공의뢰서가 전송될 수 있도록 할 수 있다. 또한, 작성된 진료 내용을 바탕으로 보험진료에 대하여 건강보험 공단청구 업무 수행을 간편하게 할 수 있다. 또한, 보험진료에 관련된 치과재료들의 구매 및 재고 관리를 전자 차팅 시스템에 통합하여 치과재료 소진 및 현 황 파악을 청구업무와 연동해서 할 수 있도록 하며, 치과재료의 주문이 가능하도록 할 수 있다."}
{"patent_id": "10-2023-0098655", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "실시예에 따른 치과 전자 차팅 시스템은 진료 후 의사의 음성정보, 종이차트 정보, 전자 차트 입력정보 중 적어 도 하나를 수집하는 정보 인식 단말; 정보 인식 단말로부터 의사의 음성정보, 종이차트 정보, 입력정보를 수집하여 전자 차트와 처방전을 생성하는 서버; 를 포함하고, 서버; 는 음성인식 모델을 통해 의사의 음성정보에서 처방정보를 추출하는 제1추출부; 의사 의 음성정보가 수집된 경우, STT(Speech to text) 모델을 통해, 의사의 음성정보를 텍스트로 변환하는 변환부; 의사의 음성정보를 변환한 텍스트에서 처방정보를 추출하는 제2추출부; 및 추출된 처방정보를 입력하여 전자 차 트를 생성하는 생성부; 를 포함하고 생성부; 는 음성정보에서 추출한 처방 정보 및 텍스트에서 추출한 처방정보 가 일치하는 경우, 상기 처방정보를 입력하여 전자 차트를 생성한다."}
{"patent_id": "10-2023-0098655", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "이상에서와 같은 치과 전자 차팅 시스템 및 방법은 진료 후 의사의 음성인식을 통해 진료 차트를 작성하여, 차 트 작성을 편리하게 수행할 수 있도록 한다. 또한, 실시예에서는 위 기록을 바탕으로 진료비 수납과 건강보험 공단청구액의 청구과정을 간소화할 수 있으며, 전자 기공의뢰서로 치과기공소와의 간편한 기공의뢰를 가능하게 한다. 또한, 실시예에서는 종이차트 이미지에서 텍스트, 그림을 추출하여 저장함으로써, 종이 차트를 이용하는 경우에 도 진료 기록을 데이터베이스화 할 수 있도록 한다. 또한, 실시예에서는 의사의 음성을 텍스트 변환하고, 변환된 텍스트에서 추출한 처방 정보와 처방전 정보를 비 교하여 확인함으로써, 처방전에서 발생 가능한 오류를 방지 할 수 있다."}
{"patent_id": "10-2023-0098655", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 2, "content": "본 발명의 효과는 상기한 효과로 한정되는 것은 아니며, 본 발명의 상세한 설명 또는 특허청구범위에 기재된 발 명의 구성으로부터 추론 가능한 모든 효과를 포함하는 것으로 이해되어야 한다."}
{"patent_id": "10-2023-0098655", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 첨부된 도면을 참조하여 본 명세서에 개시된 실시예를 상세히 설명하되, 도면 부호에 관계없이 동일하거 나 유사한 구성요소는 동일한 참조 번호를 부여하고 이에 대한 중복되는 설명은 생략하기로 한다. 이하의 설명 에서 사용되는 구성요소에 대한 접미사 \"모듈\" 및 \"부\"는 명세서 작성의 용이함만이 고려되어 부여되거나 혼용 되는 것으로서, 그 자체로 서로 구별되는 의미 또는 역할을 갖는 것은 아니다. 또한, 본 명세서에 개시된 실시 예를 설명함에 있어서 관련된 공지 기술에 대한 구체적인 설명이 본 명세서에 개시된 실시 예의 요지를 흐릴 수 있다고 판단되는 경우 그 상세한 설명을 생략한다. 또한, 첨부된 도면은 본 명세서에 개시된 실시 예를 쉽게 이 해할 수 있도록 하기 위한 것일 뿐, 첨부된 도면에 의해 본 명세서에 개시된 기술적 사상이 제한되지 않으며, 본 발명의 사상 및 기술 범위에 포함되는 모든 변경, 균등물 내지 대체물을 포함하는 것으로 이해되어야 한다. 제1, 제2 등과 같이 서수를 포함하는 용어는 다양한 구성요소들을 설명하는데 사용될 수 있지만, 상기 구성요소 들은 상기 용어들에 의해 한정되지는 않는다. 상기 용어들은 하나의 구성요소를 다른 구성요소로부터 구별하는 목적으로만 사용된다. 어떤 구성요소가 다른 구성요소에 \"연결되어\" 있다거나 \"접속되어\" 있다고 언급된 때에는, 그 다른 구성요소에 직접적으로 연결되어 있거나 또는 접속되어 있을 수도 있지만, 중간에 다른 구성요소가 존재할 수도 있다고 이 해되어야 할 것이다. 반면에, 어떤 구성요소가 다른 구성요소에 \"직접 연결되어\" 있다거나 \"직접 접속되어\" 있 다고 언급된 때에는, 중간에 다른 구성요소가 존재하지 않는 것으로 이해되어야 할 것이다. 본 출원에서, \"포함한다\" 또는 \"가지다\" 등의 용어는 명세서상에 기재된 특징, 숫자, 단계, 동작, 구성요소, 부 품 또는 이들을 조합한 것이 존재함을 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성요소, 부품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되 어야 한다. 본 명세서에 있어서 '부(部)'란, 하드웨어에 의해 실현되는 유닛(unit), 소프트웨어에 의해 실현되는 유닛, 양 방을 이용하여 실현되는 유닛을 포함한다. 또한, 1개의 유닛이 2개 이상의 하드웨어를 이용하여 실현되어도 되 고, 2개 이상의 유닛이 1개의 하드웨어에 의해 실현되어도 된다. 본 명세서에 있어서 단말, 장치 또는 디바이스가 수행하는 것으로 기술된 동작이나 기능 중 일부는 해당 단말, 장치 또는 디바이스와 연결된 서버에서 대신 수행될 수도 있다. 이와 마찬가지로, 서버가 수행하는 것으로 기술 된 동작이나 기능 중 일부도 해당 서버와 연결된 단말, 장치 또는 디바이스에서 수행될 수도 있다. 이하, 첨부된 도면을 참고하여 본 발명을 상세히 설명하기로 한다. 도 1은 실시예에 따른 치과 전자 차팅 시스템 구성을 나타낸 도면이다. 도 1을 참조하면, 실시예에 따른 치과 전자 차팅 시스템은 정보인식 단말 및 서버를 포함하여 구성될 수 있다. 정보 인식 단말는 진료 후 의사의 음성정보, 종이차트 정보 및 전자차트 입력정보 중 적어도 하 나를 수집한다. 실시예에서 정보 인식 단말은 카메라 및 녹음기를 포함하여, 종이차트 정보와 음성정보를 수집할 수 있다. 카메라는 스캐너를 포함하고, 종이차트를 스캔하여 디지털 데이터로 변환할 수 있다. 녹음기는 진료 후 의사 음성 정보를 수집한다. 서버는 정보 인식 단말로부터 의사의 음성정보, 종이차트 정보, 입력정보를 수집하여 전자 차트를 생성한 다. 실시예에 따른 치과 전자 차팅 시스템 및 방법은 진료 후 의사의 음성인식을 통해, 자동으로 의료 차트를 생성한다. 또한, 실시예에서는 인식된 의사의 음성을 STT(Speech to text) 모델을 통해 텍스트 변환하여 저장할 수 있다. 또한, 실시예에서는 종이차트를 스캔하여 차트 이미지를 생성하고, 생성된 차트 이미지와 차트 이미지 에서 텍스트 및 그림 데이터를 추출하여 저장할 수 있다. 또한, 실시예에서는 의사의 음성을 텍스트로 변환한 후, 텍스트에서 처방 정보를 추출하여, 추출된 처방 정보와 처방전 정보를 비교하여, 의사의 처방이 제대로 기 입되었는지 확인할 수 있다. 도 2는 실시예에 따른 서버의 데이터 처리 구성을 나타낸 도면이다. 도 2를 참조하면, 실시예에 따른 서버는 수집부, 전처리부, 딥러닝부, 제1추출부, 생 성부, 처방전 생성부, 변환부, 제2추출부, 확인부, 검색부 및 피드백부를 포함하여 구성될 수 있다. 본 명세서에서 사용되는 '부' 라는 용어는 용어가 사용된 문맥에 따라서, 소프트웨어, 하드웨어 또는 그 조합을 포함할 수 있는 것으로 해석되어야 한다. 예를 들어, 소프트웨어는 기계 어, 펌웨어(firmware), 임베디드코드(embedded code), 및 애플리케이션 소프트웨어일 수 있다. 또 다른 예로, 하드웨어는 회로, 프로세서, 컴퓨터, 집적 회로, 집적 회로 코어, 센서, 멤스(MEMS; Micro-Electro-Mechanical System), 수동 디바이스, 또는 그 조합일 수 있다. 수집부는 정보 인식 단말로부터 진료 후 의사의 음성정보, 종이차트 정보 및 의사에 의해 입력되는 전자 차트 입력 정보를 수집한다. 또한, 수집부는 음성인식 모델, STT(Speech to Text) 모델 및 텍스트 인식 모 델을 포함하는 딥러닝 모델의 학습 데이터를 수집한다. 실시예에서 음성 인식 모델과 STT 모델의 학습 데이터는 음성데이터, 텍스트 데이터, 발음사전, 환경 소음데이터 등을 포함할 수 있다. 텍스트 인식 모델의 학습 데이터 는 텍스트 문장, 단어 시퀀스, 텍스트 레이블과 클래스 등을 포함할 수 있다. 전처리부는 수집된 인공지능 학습데이터 중 편향성이나 차별성을 가진 데이터를 제거하기 위해, 수집된 학 습데이터를 전처리한다. 실시예에서 전처리부는 수집된 데이터를 전처리하여 인공지능 모델 학습에 적합한 형태로 가공한다. 예컨대, 전처리부는 노이즈 제거, 이상치 제거, 결측치 처리 등의 과정을 수행할 수 있 다. 또한, 전처리부는 데이터 전처리를 통해 데이터를 정규화하거나, 이상치를 제거하거나, 데이터의 배율 조정 등을 수행하여 모델이 불필요한 패턴을 학습하는 것을 방지할 수 있다. 딥러닝부는 딥러닝 뉴럴 네트워크를 학습 데이터로 학습시켜 딥러닝 모델을 구현한다. 실시예에서 딥러닝 모델은 음성인식 모델, STT 모델 및 텍스트 인식 모델을 포함할 수 있다. 음성인식 모델과 STT 모델은 음성 입 력을 받아들여 텍스트로 변환하는 딥러닝 모델이다. 음성인식 모델 및 STT 모델은 실시예에서 의사가 발화한 음 성을 인식하고, 그 내용을 텍스트로 변환하여 이해하고 활용할 수 있다. 텍스트 인식 모델은 텍스트 입력을 받 아들여 해당 텍스트를 이해하거나 분류하는 모델이다. 실시예에서 텍스트 인식 모델은 의사의 음성이 변환된 텍 스트를 인식할 수 있다. 실시예에서 딥러닝부는 전자 차팅 시스템에서 질병과 처방 정보를 수집하여, 음성 인식 모델 및 텍스트 인식 모델의 학습 데이터로 이용할 수 있다. 예컨대, 딥러닝부는 전자 차팅 시스템 및 의료기관 데이터베이스에 저장된 환자 증상, 질병, 처방 정보를 수집하고 이를 음성인식모델, STT 모델 및 텍스트 인식 모델의 학습 데이터로 이용할 수 있다. 실시예에서 딥러닝 뉴럴 네트워크는 DNN(Deep Neural Network), CNN(Convolutional Neural Network) RNN(Recurrent Neural Network) 및BRDNN(Bidirectional Recurrent Deep Neural Network) 중 적어도 하나를 포 함하고, 이에 한정하지 않는다. 제1추출부는 음성인식 모델을 통해 의사의 음성정보에서 처방정보를 추출한다. 실시예에서 제1추출부(14 0)는 의사의 발화를 포함하는 음성 데이터를 수집하고, 음성 데이터에서 의사의 발화를 제외한 다른 음성은 삭 제한다. 즉, 실시예에서 제1추출부는 의사의 음성만을 필터링하고 필터링 된 음성데이터에서 처방 정보를 추출할 수 있다. 실시예에서 제1추출부는 미리 의사의 음성 정보를 저장하고, 저장된 음성 정보와 수집된 음성 데이터가 일정 수준 이상 유사한 음성 정보를 필터링할 수 있다. 실시예에서 제1 추출부는 수집한 의사의 음성 데이터를 음성 신호 처리 기술을 사용하여 전처리 한다. 실 시예에서 전처리는 음성 신호를 디지털 형식으로 변환하고, 노이즈 제거, 음량 정규화 등의 과정을 포함할 수 있다. 실시예에서 제1추출부는 전처리된 음성 데이터를 음성인식 모델에 입력하여, 의사의 발화 의도를 추 출한다. 예컨대, 의사의 발화 의도 추출과정에서 제1추출부는 의사의 발화가 처방 정보를 담고 있는지, 질 문을 포함하는지, 단순한 안부인지 등을 분류한다. 이후, 제1추출부는 처방 정보를 추출한다. 예컨대, 제1 추출부는 의도가 처방 정보를 나타낼 경우, 의사의 음성에서 처방 정보를 추출한다. 실시예에서 제1추출부 는 특정 패턴이나 키워드를 기반으로 처방 정보를 식별하고 추출할 수 있다. 예를 들어, 약물 이름, 용량, 횟수, 투여 방법, 환자 이름, 나이 등이 추출될 수 있다. 생성부는 추출된 처방 정보에 따라 전자 차트를 생성한다. 실시예에서 생성부는 음성정보에서 추출된 처방정보와 음성을 텍스트로 변환한후의 텍스트에서 추출된 처방정보를 비교하고, 두 정보가 일치하는 경우, 처 방정보를 입력하여 전자 차트를 생성할 수 있다. 이후, 처방전 생성부는 전자 차트에 입력된 처방 정보를 기반으로 환자에게 제공하는 처방전을 생성한다. 이후, 실시예에서는 음성인식 정보에서 추출된 처방정보를 포 함하는 처방전과 음성정보를 변환한 텍스트에서 추출한 처방정보를 비교하여, 두 정보가 일치하는 경우, 정보 수집 단말로 의사의 최종 승인을 요청할 수 있다. 또한, 실시예에서는 음성인식 정보에서 추출된 처방 정보와 음성정보가 변환된 텍스트에서 추출한 처방정보가 일치하는 경우, 전자 차트를 생성하고, 생성된 전자 차트를 기반으로 처방전을 생성할 수 있다. 또한, 실시예에서는 음성인식 정보에서 추출된 처방 정보로 전자 차트를 생 성하고, 음성인식 정보에서 추출한 처방 정보와 텍스트에서 추출한 처방정보가 일치하는 경우, 처방전을 생성할 수 있다. 변환부는 의사의 음성정보가 수집된 경우, STT(Speech to text) 모델을 통해, 의사의 음성정보를 텍스트로 변환한다. 실시예에서 변환부는 변환된 텍스트에서 텍스트 인식 모델을 통해 처방 정보를 추출하고, 처방 전에 기록된 처방정보와 텍스트에서 추출된 처방정보를 비교한다. 실시예에서 변환부는 처방전에 기록된 처방정보와 텍스트에서 추출된 처방정보가 일치하는 경우, 확인부으로 처방전에 대한 최종 승인 요청을 전 송한다. 확인부는 생성된 처방전을 정보 인식 단말로 전송하여, 의사의 최종 승인 정보를 수집한다. 실시예에서 확 인부는 음성 인식만을 통해, 처방전을 생성한 경우, 음성인식을 통해 생성된 처방전 정보를 정보 수집 단 말로 전송하고, 정보 수집 단말로부터 의사의 최종 승인 신호를 수신하고, 이를 간호사 스테이션 단말로 전송할 수 있다. 또한, 실시예에서 확인부는 음성인식 및 텍스트 변환을 수행하여 처방전을 생성한 경우, 음성인 식을 통해 추출된 처방 정보로 생성한 처방전을 생성한다. 이후, 처방전 생성부에서 음성을 텍스트로 변환 한 후 추출된 처방정보와 처방전에 기록된 정보를 비교하여 두 정보가 일치하는 경우, 정보 수집 단말로 의사의 처방전을 전송하고, 의사의 최종 승인 신호를 요청할 수 있다. 실시예에서 변환부는 종이차트를 스캔한 이미지가 수집된 경우, 텍스트 인식 모델을 통해 종이차트가 변환 된 이미지에서 텍스트 이미지를 추출하고, 종이차트가 변환된 이미지에서 의사가 그린 그림 이미지를 추출한다. 이후 변환부는 추출된 텍스트 이미지를 텍스트로 변환하여, 변환된 텍스트와 그림 이미지를 생성한다. 실시예에서 변환부는 종이차트를 스캔하여 디지털 이미지로 변환한다. 스캔된 이미지는 의사가 기록한 텍 스트와 의사가 그린 그림이 포함되어 있다. 이후, 텍스트 인식 모델을 사용하여 이미지에서 텍스트 이미지를 추 출한다. 이를 위해 이미지 처리 및 컴퓨터 비전 기술을 활용하여 텍스트 이미지를 감지하고 분리한다. 이후, 변 환부는 텍스트 이미지를 텍스트로 변환한다. 실시예에서는 추출된 텍스트 이미지를 텍스트 인식 모델에 입 력하여 텍스트로 변환한다. 텍스트 인식 모델은 이미지에서 텍스트를 인식하고, 해당 텍스트의 의미를 해석하여 텍스트로 변환할 수 있다. 또한, 변환부는 의사가 그린 그림 이미지 추출한다. 실시예에서는 이미지 처리 및 컴퓨터 비전 기술을 사용하여 의사가 그린 그림 이미지를 추출한다. 이를 위해 이미지에서 그림 부분을 감지 하고 분리한다. 실시예에서 전자차트 생성부는 종이차트를 스캔한 이미지가 수집된 경우, 변환부로부터 입력된 텍스 트에서 처방 정보를 추출하고, 추출된 처방 정보를 입력하여 전자 차트를 생성한다. 검색부 의사의 음성인식을 통해, 전자차트를 검색하고 검색된 정보를 출력한다. 실시예에서 검색부는 검색모드에서 의사의 음성 발화를 수집한다. 검색모드에서 수집되는 음성 데이터에는 검색어와 관련된 질의나 명령어를 포함할 수 있다. 이후 검색부는 수집한 음성 데이터를 음성 신호 처리 기술을 사용하여 전처리한 다. 검색부는 음성 신호를 디지털 형식으로 변환하고, 노이즈 제거 및 음량 정규화와 같은 전처리를 수행 한다. 이후, 검색부는 전처리된 음성 데이터를 음성인식 모델에 입력하여 음성을 텍스트로 변환한다. 실시예에서 음성인식 모델은 음성 데이터를 분석하여 음성에 포함된 단어와 구절을 텍스트로 변환한다. 이후 음성에 서 추출된 텍스트를 분석하여 검색어를 추출한다. 검색어 추출과정에서 검색부는 텍스트 처리 기술을 활용 하여 의도하는 검색어나 명령어를 식별한다. 이후 검색부는 추출된 검색어를 사용하여 전자차트 데이터베 이스나 정보 시스템에서 검색을 수행한다. 예컨대, 검색부는 검색어를 기반으로 검색 쿼리를 구성하고, 해 당하는 전자차트 데이터를 검색한다. 이후 검색부는 검색된 정보와 검색 결과를 출력한다. 예컨대, 검색부 는 검색된 전자차트 정보를 정보 수집 단말의 화면이나 출력 장치에 출력한다. 관리부는 최종 진료기록을 기반으로 보험진료에 대해 국민건강보험공단에 공단부담금을 청구하고, 보험청 구에 관한 재료구매 내역 및 재고관리를 수행한다. 예컨대, 관리부는 최종 진료 기록에서 보험 진료기록을 추출하고, 추출된 보험 진료에 해당하는 공단 부담금을 로딩하여 국민건강보험 공단에 청구한다. 또한, 관리부 는 보험 청구 결과 및 입출금 히스토리를 정산하여 미청구 및 미입금 이벤트를 검출할 수 있다. 아울러, 관리부는 작성된 진료 내용과 처방내용을 바탕으로 기공의뢰서를 생성하고, 관련 기공소로 기공의뢰서를 전송한다. 또한, 관리부는 보험진료에 관련된 치과재료들의 구매 및 재고 관리를 전자 차팅 시스템에 통합 하여 치과재료 소진 및 현황 파악을 청구업무와 연동해서 할 수 있도록 하며, 치과재료의 주문이 가능하도록 한 다. 피드백부는 학습된 인공신경망 모델 및 딥러닝 모델을 평가한다. 실시예에서 피드백부는 정확도 (Accuracy), 정밀도 (Precision) 및 재현율 (Recall) 중 적어도 하나를 통해, 인공신경망 모델을 평가할 수 있 다. 정확도는 인공 신경망 모델이 예측한 결과가 실제 결과와 얼마나 일치하는지를 측정하는 지표이다. 정밀도 는 양성으로 예측한 결과 중 실제 양성인 비율을 측정하는 지표이다. 재현율은 실제 양성 중에서 모델이 양성으 로 예측한 비율을 측정하는 지표이다. 실시예에서 피드백부는 인공신경망 모델의 정확도, 정밀도 및 재현 율을 산출하고, 산출된 지표 중 적어도 하나를 기반으로 인공신경망 모델을 평가할 수 있다. 실시예에서 피드백부는 인공신경망 모델의 정확도를 평가 데이터셋을 사용하여 측정할 수 있다. 평가 데이 터셋은 모델이 학습에 사용하지 않은 데이터로 구성되어 있으며, 모델의 성능을 객관적으로 평가하는 데 사용된 다. 실시예에서 피드백부는 평가 데이터셋을 사용하여 인공신경망 모델을 실행하고, 각 입력 데이터에 대 한 인공신경망 모델의 예측 값과 해당 데이터의 실제 정답 값을 비교한다. 이후, 비교 결과를 통해, 모델이 얼 마나 정확하게 예측하는지를 측정할 수 있다. 예컨대, 피드백부에서 정확도는 전체 데이터 중에서 모델이 맞게 예측한 데이터의 비율로 계산될 수 있다. 또한, 피드백부는 정밀도와 재현율의 조화 평균으로 계산되는 지표인 정밀도와 재현율의 균형을 나타내는 지표인 F1 스코어(F1 Score)를 산출하고, 산출된 F1 스코어를 기반으로 인공신경망 모델을 평가하고, 분류 모델 의 성능을 그래프로 시각화한 지표인 AUC-ROC 곡선을 생성하고, 생성된 AUC-ROC 곡선을 기반으로 인공신경망 모 델을 평가할 수 있다. 실시예에서 피드백부는 ROC 곡선 아래 면적 (AUC)이 1에 가까울수록 모델의 성능이 좋은 것으로 평가할 수 있다. 또한, 피드백부는 인공신경망 모델의 해석 가능성을 평가할 수 있다. 실시예에서 피드백부는 SHAP (SHapley Additive exPlanations), LIME (Local Interpretable Model-agnostic Explanations) 방법을 통해, 인공신경망 모델의 해석 가능성을 평가한다. SHAP (SHapley Additive exPlanations)는 모델이 예측한 결과에 대한 해석을 제공하는 라이브러리로서, 피드백부는 라이브러리에서 SHAP 값을 추출한다. 실시예에서 피드 백부는 SHAP값 추출을 통해, 모델에 입력된 특성정보가 모델 예측에 얼마나 영향을 미쳤는지를 예측할 수 있다. LIME (Local Interpretable Model-agnostic Explanations) 방법은 개별 샘플에 대한 모델의 예측을 설명하는 방법이다. 실시예에서 피드백부는 LIME 방법을 통해, 샘플을 해석 가능한 모델로 근사하여 각 특성정보의 중요도를 계산한다. 또한, 피드백부는 모델의 내부 가중치와 편향 값을 분석하여 각 특성 변수의 영향력을 추정할 수 있다. 피드백부는 인공신경망 모델의 공정성이 낮거나 차별성을 보이는 경우, 개선 작업을 수행한다. 실시예에서 피드백부는 특정 집단의 데이터가 일정수준 이상 부족한 경우 상기 특정 집단을 대표하는 데이터를 추가로 수집하고, 데이터 전처리 과정을 수행한다. 실시예에서 피드백부는 데이터 정규화, 이상치 제거, 데이터의 배율 조정을 포함하는 데이터 전처리 과정을 수행하여 모델이 불필요한 패턴을 학습하는 것을 방지한다. 또한, 실시예에서 피드백부는 모델 학습 알고리즘에 특정 조건을 추가하여 차별성을 방지하거나, 공정성을 보장 할 수 있다. 실시예에서 피드백부는 공정성 보장을 위해, 혼돈행렬(Confusion Matrix) 분석을 통해, 모델의 예측 결과 를 실제 결과와 비교하여 모델의 성능을 평가한다. 혼돈 행렬(confusion matrix)은 지도 학습에서 모델의 분류 성능을 평가하는 행렬이다. 혼돈 행렬은 모델이 예측한 결과와 실제 결과를 비교하여 분류 결과를 표시한다. 실 시예에서 피드백부는 혼돈행렬 분석을 통해, 각각의 클래스에 대한 정확도와 오분류율을 계산하여 모델의 성능을 평가할 수 있다. 또한, 실시예에서 피드백부는 학습데이터에 대한 시각화 분석을 통해 데이터의 분포를 확인할 수 있도록 한다. 예를 들어, 이미지 데이터의 경우 각 클래스에 대한 이미지 샘플을 시각화 하여 데이터의 다양성과 공정 성을 평가할 수 있다. 또한, 피드백부는 인공신경망 모델의 편향(Bias) 검증을 수행한다. 실시예에서 피드백부는 학습정보 에 대한 편향(Bias) 검증을 통해, 모델이 특정 클래스나 속성에 대해 편향되어 있는지 여부를 확인한다. 이를 위해 피드백부는 각 클래스에 대한 샘플의 수를 비교하거나, 각 클래스에 대한 분류 성능을 평가한다. 또한, 피드백부는 공정성(Fairness) 검증 및 평가 지표 계산을 통해, 학습데이터의 공정성과 다양항을 검 증하고 인공신경망 모델을 개선할 수 있도록 한다. 실시예에서 공정성 검증은 학습정보에 대해 인공신경망 모델 이 성별, 인종, 연령 등의 특정속성에 대해 차별성을 보이는지 여부를 확인하는 것이다. 실시예에서 피드백부 는 각 속성에 대한 샘플의 수를 비교하거나, 각 속성에 대한 분류 성능을 평가하여, 특정 속성에 대한 차 별성 여부를 확인할 수 있다. 또한, 피드백부는 인공신경망 모델의 성능을 평가하기 위한 다양한 지표를 계산한다. 예를 들어, 정확도, 정밀도, 재현율, F1-score 등의 지표를 계산하여 모델의 성능을 평가할 수 있다. 이때, 각 클래스에 대한 지표 를 계산하여 모델의 공정성과 다양성을 평가할 수 있다. 또한, 피드백부는 인공신경망 모델이 실제 환경에서 사용되면서 발생하는 문제점에 대한 피드백을 수집하 고, 수집된 피드백을 인공신경망 모델에 반영하여 인공신경망 모델을 지속적으로 개선한다. 이하에서는 치과 전자 차팅 방법방법에 대해서 차례로 설명한다. 실시예에 따른 치과 전자 차팅 방법의 작용(기 능)은 시스템의 기능과 본질적으로 같은 것이므로 도 1 및 도 2와 중복되는 설명은 생략하도록 한다. 도 3은 실시예에 따른 서버의 데이터 처리 흐름을 나타낸 도면이다. 도 3을 참조하면, S100 단계에서는 제1추출부에서 음성인식 모델을 통해 의사의 음성정보에서 처방정보를 추출 한다. S200 단계에서는 변환부에서 의사의 음성정보가 수집된 경우, STT(Speech to text) 모델을 통해, 의사의 음성정보를 텍스트로 변환하고, 변환된 텍스트에서 처방정보를 추출한다. S300 단계에서는 생성부에서 음성정보 에서 추출된 처방정보와 텍스트에서 추출된 처방정보가 일치하는 경우, 전자 차트를 생성한다. S400 단계에서는 처방전 생성부에서 전자 차트의 처방정보를 기반으로 처방전을 생성하고, 생성된 처방전을 의사가 소지한 정보 수집 단말로 전송한다. S400 단계에서는 음성정보에서 추출된 처방정보를 통해 처방전을 생성하고, 처방전의 기 록과 텍스트에서 추출된 처방정보를 비교하고, 처방전의 기록과 텍스트에서 추출된 처방정보가 일치하는 경우 처방전을 의사가 소지한 정보수집 단말로 전송할 수 있다. S500 단계에서는 처방전 생성부에서 의사가 소지한 정보수집 단말로부터 처방전에 대한 최종 승인 정보를 수신하는 경우, 처방전을 간호 스테이션 단말로 전송한다. 이상에서와 같은 치과 전자 차팅 시스템 및 방법은 진료 후 의사의 음성인식을 통해 진료 차트를 작성하여, 차 트 작성을 편리하게 수행할 수 있도록 한다. 또한, 실시예에서는 종이차트 이미지에서 텍스트, 그림을 추출하여 저장함으로써, 종이 차트를 이용하는 경우에도 진료 기록을 데이터베이스화 할 수 있도록 한다. 또한, 실시예에 서는 의사의 음성을 텍스트 변환하고, 변환된 텍스트에서 추출한 처방 정보와 처방전 정보를 비교하여 확인함으 로써, 처방전에서 발생 가능한 오류를 방지 할 수 있다."}
{"patent_id": "10-2023-0098655", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "개시된 내용은 예시에 불과하며, 특허청구범위에서 청구하는 청구의 요지를 벗어나지 않고 당해 기술분야에서 통상의 지식을 가진 자에 의하여 다양하게 변경 실시될 수 있으므로, 개시된 내용의 보호범위는 상술한 특정의 실시예에 한정되지 않는다.도면 도면1 도면2 도면3"}
{"patent_id": "10-2023-0098655", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 실시예에 따른 치과 전자 차팅 시스템 구성을 나타낸 도면 도 2는 실시예에 따른 서버의 데이터 처리 구성을 나타낸 도면 도 3은 실시예에 따른 서버의 데이터 처리 흐름을 나타낸 도면"}
