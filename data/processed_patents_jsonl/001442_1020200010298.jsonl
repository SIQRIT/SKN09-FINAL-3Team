{"patent_id": "10-2020-0010298", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2021-0096811", "출원번호": "10-2020-0010298", "발명의 명칭": "로봇 및 이의 제어 방법", "출원인": "삼성전자주식회사", "발명자": "김우목"}}
{"patent_id": "10-2020-0010298", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "로봇에 있어서, 복수의 센서;복수의 서비스 및 상기 복수의 서비스에 대응되는 제어 명령을 저장하는 메모리; 및상기 복수의 센서 중 적어도 하나의 센서에 기초하여 이벤트의 발생이 감지되면, 상기 적어도 하나의 센서에 의하여 감지된 정보를 바탕으로 상기 이벤트에 대응되는 서비스를 결정하고, 상기 결정된 서비스를 사용자에게 제공하도록 상기 로봇을 제어하는 프로세서;를 포함하고,상기 프로세서는,상기 감지된 정보를 바탕으로 상기 결정된 서비스에 대응되는 센싱 목표를 설정하고, 상기 복수의 센서에 대한정보를 바탕으로 상기 설정된 센싱 목표를 수행하기 위한 센서 조합을 결정하고, 상기 결정된 센서 조합을 바탕으로 추가 정보를 획득하여 상기 서비스를 사용자에게 제공하는 로봇."}
{"patent_id": "10-2020-0010298", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서,상기 프로세서는,상기 감지된 정보를 시간, 장소, 빈도 또는 관련 객체 중 적어도 하나를 포함하는 히스토리 정보에 따라 분석하고, 상기 분석된 히스토리 정보에 기초하여 상기 센싱 목표를 설정하는 로봇."}
{"patent_id": "10-2020-0010298", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서,상기 프로세서는,상기 복수의 서비스 중 적어도 하나의 서비스를 요청하는 사용자의 명령을 수신하면, 상기 사용자의 명령을 상기 히스토리 정보에 따라 분석하고, 상기 분석된 히스토리 정보에 기초하여 상기 센싱 목표를 설정하는 로봇."}
{"patent_id": "10-2020-0010298", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서,상기 프로세서는,상기 복수의 센서에 대한 정보를 바탕으로 각 센서에 대한 적어도 하나의 감지 역할을 결정하고, 상기 결정된감지 역할을 바탕으로 상기 센서 조합을 결정하는 로봇."}
{"patent_id": "10-2020-0010298", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제1항에 있어서,상기 프로세서는,상기 로봇이 이용할 수 있는 외부 센서를 식별하고, 상기 외부 센서 및 상기 외부 센서의 정보를 더 고려하여상기 센서 조합을 결정하는 로봇."}
{"patent_id": "10-2020-0010298", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5항에 있어서,공개특허 10-2021-0096811-3-상기 프로세서는,상기 외부 센서의 센싱 정보, 위치 정보 또는 사용 이력 정보 중 적어도 하나를 바탕으로 상기 센서 조합을 결정하는 로봇."}
{"patent_id": "10-2020-0010298", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에 있어서,상기 프로세서는,서버로부터 외부 정보를 획득하고, 상기 획득한 외부 정보를 바탕으로 상기 서비스를 결정하는 로봇."}
{"patent_id": "10-2020-0010298", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제1항에 있어서,상기 프로세서는,상기 로봇을 이용하는 목적에 따라 분류된 프로파일에 기초하여 상기 복수의 서비스에 대한 우선 순위를 획득하고, 상기 획득한 우선 순위를 바탕으로 상기 이벤트의 발생을 감지하는 로봇."}
{"patent_id": "10-2020-0010298", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1항에 있어서,상기 프로세서는,사용자로부터 상기 설정된 센싱 목표 또는 상기 제공된 서비스에 대한 피드백을 획득하고, 상기 피드백을 바탕으로 상기 센싱 목표 또는 상기 제공된 서비스에 대한 정보를 업데이트하는 로봇."}
{"patent_id": "10-2020-0010298", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "로봇의 제어 방법에 있어서, 복수의 센서 중 적어도 하나의 센서에 기초하여 이벤트의 발생이 감지되는 단계;상기 적어도 하나의 센서에 의하여 감지된 정보를 바탕으로 상기 이벤트에 대응되는 서비스를 결정하는 단계;상기 감지된 정보를 바탕으로 상기 결정된 서비스에 대응되는 센싱 목표를 설정하는 단계;상기 복수의 센서에 대한 정보를 바탕으로 상기 설정된 센싱 목표를 수행하기 위한 센서 조합을 결정하는 단계;및상기 결정된 센서 조합을 바탕으로 추가 정보를 획득하여 상기 서비스를 사용자에게 제공하는 단계;를 포함하는제어 방법."}
{"patent_id": "10-2020-0010298", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제10항에 있어서,상기 센싱 목표를 설정하는 단계는,상기 감지된 정보를 시간, 장소, 빈도 또는 관련 객체 중 적어도 하나를 포함하는 히스토리 정보에 따라 분석하고, 상기 분석된 히스토리 정보에 기초하여 상기 센싱 목표를 설정하는 제어 방법."}
{"patent_id": "10-2020-0010298", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제11항에 있어서,복수의 서비스 중 적어도 하나의 서비스를 요청하는 사용자의 명령을 수신하는 단계;를 더 포함하고,상기 센싱 목표를 설정하는 단계는,상기 사용자의 명령을 상기 히스토리 정보에 따라 분석하고, 상기 분석된 히스토리 정보에 기초하여 상기 센싱공개특허 10-2021-0096811-4-목표를 설정하는 제어 방법."}
{"patent_id": "10-2020-0010298", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제10항에 있어서,상기 센서 조합을 결정하는 단계는,상기 복수의 센서에 대한 정보를 바탕으로 각 센서에 대한 적어도 하나의 감지 역할을 결정하고, 상기 결정된감지 역할을 바탕으로 상기 센서 조합을 결정하는 제어 방법."}
{"patent_id": "10-2020-0010298", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제10항에 있어서,상기 센서 조합을 결정하는 단계는,상기 로봇이 이용할 수 있는 외부 센서를 식별하고, 상기 외부 센서 및 상기 외부 센서의 정보를 더 고려하여상기 센서 조합을 결정하는 제어 방법."}
{"patent_id": "10-2020-0010298", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제14항에 있어서,상기 센서 조합을 결정하는 단계는,상기 외부 센서의 센싱 정보, 위치 정보 또는 사용 이력 정보 중 적어도 하나를 바탕으로 상기 센서 조합을 결정하는 제어 방법."}
{"patent_id": "10-2020-0010298", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제10항에 있어서,상기 서비스를 결정하는 단계는,서버로부터 외부 정보를 획득하고, 상기 획득한 외부 정보를 바탕으로 상기 서비스를 결정하는 제어 방법."}
{"patent_id": "10-2020-0010298", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제10항에 있어서,상기 이벤트의 발생이 감지되는 단계는,상기 로봇을 이용하는 목적에 따라 분류된 프로파일에 기초하여 복수의 서비스에 대한 우선 순위를 획득하고,상기 획득한 우선 순위를 바탕으로 상기 이벤트의 발생을 감지하는 제어 방법."}
{"patent_id": "10-2020-0010298", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제10항에 있어서,사용자로부터 상기 설정된 센싱 목표 또는 상기 제공된 서비스에 대한 피드백을 획득하고, 상기 피드백을 바탕으로 상기 센싱 목표 또는 상기 제공된 서비스에 대한 정보를 업데이트하는 단계;를 더 포함하는 제어 방법."}
{"patent_id": "10-2020-0010298", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "로봇 및 로봇의 제어 방법이 개시된다. 본 로봇은 복수의 센서, 복수의 서비스 및 복수의 서비스에 대응되는 제 어 명령을 저장하는 메모리, 및 복수의 센서 중 적어도 하나의 센서에 기초하여 이벤트의 발생이 감지되면, 적어 도 하나의 센서에 의하여 감지된 정보를 바탕으로 이벤트에 대응되는 서비스를 결정하고, 결정된 서비스를 사용 자에게 제공하도록 로봇을 제어하는 프로세서를 포함하고, 프로세서는 감지된 정보를 바탕으로 결정된 서비스에 대응되는 센싱 목표를 설정하고, 복수의 센서에 대한 정보를 바탕으로 설정된 센싱 목표를 수행하기 위한 센서 조합을 결정하고, 결정된 센서 조합을 바탕으로 추가 정보를 획득하여 서비스를 사용자에게 제공한다."}
{"patent_id": "10-2020-0010298", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 개시는 로봇 및 이의 제어 방법에 관한 것으로, 더욱 상세하게는 이벤트의 발생이 감지되면 해당 이벤트에 대응하는 서비스를 제공하는 로봇 및 이의 제어 방법에 관한 것이다."}
{"patent_id": "10-2020-0010298", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "소셜 로봇은 언어, 몸짓 등 사회적 행동으로 인간과 교감하고 상호 작용을 하는 로봇으로, 구체적으로 생활 지 원, 정서 지원, 엔터테인먼트, 교육, 안내, 케어 서비스를 제공하는 로봇을 의미한다. 종래의 소셜 로봇은 인공 지능(AI, Artificial Intelligence), 빅데이터, 사물인터넷(IoT), 클라우드 컴퓨팅 기술을 이용하여 사용자와 상호 작용을 수행하였다. 다만, 종래의 소셜 로봇의 센싱 기술은 특정 지역(예컨대, 집, 오피스)에서 사용자로부터 서비스 제공에 대한 요청을 직접적으로 수신하고, 요청받은 서비스를 제공하는 등, Use-Case에서 벗어나지 못하는 한계가 존재하였 다. 따라서, 소셜 로봇이 Use-Case에 대한 서비스를 제공할 뿐만 아니라, 센싱 목표를 자율적으로 설정하고 설정된 센싱 목표에 대응되는 서비스를 제공하는 기술이 필요한 실정이다."}
{"patent_id": "10-2020-0010298", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 개시는 상술한 문제점을 해결하기 위해 안출된 것으로, 본 개시의 목적은 센싱 목표 및 센서 조합을 자율적 으로 설정하고, 설정된 센싱 목표 및 센서 조합을 바탕으로 서비스를 제공하는 로봇 및 이의 제어 방법을 제공 함에 있다."}
{"patent_id": "10-2020-0010298", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기 목적을 달성하기 위한 본 개시의 일 실시 예에 따른 로봇은 복수의 센서, 복수의 서비스 및 상기 복수의 서비스에 대응되는 제어 명령을 저장하는 메모리 및 상기 복수의 센서 중 적어도 하나의 센서에 기초하여 이벤 트의 발생이 감지되면, 상기 적어도 하나의 센서에 의하여 감지된 정보를 바탕으로 상기 이벤트에 대응되는 서 비스를 결정하고, 상기 결정된 서비스를 사용자에게 제공하도록 상기 로봇을 제어하는 프로세서를 포함하고, 상 기 프로세서는 상기 감지된 정보를 바탕으로 상기 결정된 서비스에 대응되는 센싱 목표를 설정하고, 상기 복수 의 센서에 대한 정보를 바탕으로 상기 설정된 센싱 목표를 수행하기 위한 센서 조합을 결정하고, 상기 결정된 센서 조합을 바탕으로 추가 정보를 획득하여 상기 서비스를 사용자에게 제공할 수 있다. 그리고, 상기 프로세서는 상기 감지된 정보를 시간, 장소, 빈도 또는 관련 객체 중 적어도 하나를 포함하는 히 스토리 정보에 따라 분석하고, 상기 분석된 히스토리 정보에 기초하여 상기 센싱 목표를 설정할 수 있다. 그리고, 상기 프로세서는 상기 복수의 서비스 중 적어도 하나의 서비스를 요청하는 사용자의 명령을 수신하면, 상기 사용자의 명령을 상기 히스토리 정보에 따라 분석하고, 상기 분석된 히스토리 정보에 기초하여 상기 센싱 목표를 설정할 수 있다. 그리고, 상기 프로세서는 상기 복수의 센서에 대한 정보를 바탕으로 각 센서에 대한 적어도 하나의 감지 역할을 결정하고, 상기 결정된 감지 역할을 바탕으로 상기 센서 조합을 결정할 수 있다. 그리고, 상기 프로세서는 상기 로봇이 이용할 수 있는 외부 센서를 식별하고, 상기 외부 센서 및 상기 외부 센 서의 정보를 더 고려하여 상기 센서 조합을 결정할 수 있다. 그리고, 상기 프로세서는 상기 외부 센서의 센싱 정보, 위치 정보 또는 사용 이력 정보 중 적어도 하나를 바탕 으로 상기 센서 조합을 결정할 수 있다. 그리고, 상기 프로세서는 서버로부터 외부 정보를 획득하고, 상기 획득한 외부 정보를 바탕으로 상기 서비스를 결정할 수 있다. 그리고, 상기 프로세서는 상기 로봇을 이용하는 목적에 따라 분류된 프로파일에 기초하여 상기 복수의 서비스에 대한 우선 순위를 획득하고, 상기 획득한 우선 순위를 바탕으로 상기 이벤트의 발생을 감지할 수 있다. 그리고, 상기 프로세서는 사용자로부터 상기 설정된 센싱 목표 또는 상기 제공된 서비스에 대한 피드백을 획득 하고, 상기 피드백을 바탕으로 상기 센싱 목표 또는 상기 제공된 서비스에 대한 정보를 업데이트할 수 있다. 한편, 상기 목적을 달성하기 위한 본 개시의 일 실시 예에 따른 로봇의 제어 방법은 복수의 센서 중 적어도 하 나의 센서에 기초하여 이벤트의 발생이 감지되는 단계, 상기 적어도 하나의 센서에 의하여 감지된 정보를 바탕 으로 상기 이벤트에 대응되는 서비스를 결정하는 단계, 상기 감지된 정보를 바탕으로 상기 결정된 서비스에 대 응되는 센싱 목표를 설정하는 단계, 상기 복수의 센서에 대한 정보를 바탕으로 상기 설정된 센싱 목표를 수행하 기 위한 센서 조합을 결정하는 단계 및 상기 결정된 센서 조합을 바탕으로 추가 정보를 획득하여 상기 서비스를사용자에게 제공하는 단계를 포함할 수 있다. 그리고, 상기 센싱 목표를 설정하는 단계는 상기 감지된 정보를 시간, 장소, 빈도 또는 관련 객체 중 적어도 하 나를 포함하는 히스토리 정보에 따라 분석하고, 상기 분석된 히스토리 정보에 기초하여 상기 센싱 목표를 설정 할 수 있다. 그리고, 본 개시의 일 실시 예에 따른 제어 방법은 복수의 서비스 중 적어도 하나의 서비스를 요청하는 사용자 의 명령을 수신하는 단계를 더 포함할 수 있고, 상기 센싱 목표를 설정하는 단계는 상기 사용자의 명령을 상기 히스토리 정보에 따라 분석하고, 상기 분석된 히스토리 정보에 기초하여 상기 센싱 목표를 설정할 수 있다. 그리고, 상기 센서 조합을 결정하는 단계는 상기 복수의 센서에 대한 정보를 바탕으로 각 센서에 대한 적어도 하나의 감지 역할을 결정하고, 상기 결정된 감지 역할을 바탕으로 상기 센서 조합을 결정할 수 있다. 그리고, 상기 센서 조합을 결정하는 단계는 상기 로봇이 이용할 수 있는 외부 센서를 식별하고, 상기 외부 센서 및 상기 외부 센서의 정보를 더 고려하여 상기 센서 조합을 결정할 수 있다. 그리고, 상기 센서 조합을 결정하는 단계는 상기 외부 센서의 센싱 정보, 위치 정보 또는 사용 이력 정보 중 적 어도 하나를 바탕으로 상기 센서 조합을 결정할 수 있다. 그리고, 상기 서비스를 결정하는 단계는 서버로부터 외부 정보를 획득하고, 상기 획득한 외부 정보를 바탕으로 상기 서비스를 결정할 수 있다. 그리고, 상기 이벤트의 발생이 감지되는 단계는 상기 로봇을 이용하는 목적에 따라 분류된 프로파일에 기초하여 복수의 서비스에 대한 우선 순위를 획득하고, 상기 획득한 우선 순위를 바탕으로 상기 이벤트의 발생을 감지할 수 있다. 그리고, 본 개시의 일 실시 예에 따른 제어 방법은 사용자로부터 상기 설정된 센싱 목표 또는 상기 제공된 서비 스에 대한 피드백을 획득하고, 상기 피드백을 바탕으로 상기 센싱 목표 또는 상기 제공된 서비스에 대한 정보를 업데이트하는 단계를 더 포함할 수 있다."}
{"patent_id": "10-2020-0010298", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하에서 설명되는 실시 예는 본 개시의 이해를 돕기 위하여 예시적으로 나타낸 것이며, 본 개시는 여기서 설명 되는 실시 예들과 다르게 다양하게 변형되어 실시될 수 있음이 이해되어야 할 것이다. 다만, 이하에서 본 개시 를 설명함에 있어서, 관련된 공지 기능 혹은 구성요소에 대한 구체적인 설명이 본 개시의 요지를 불필요하게 흐 릴 수 있다고 판단되는 경우 그 상세한 설명 및 구체적인 도시를 생략한다. 또한, 첨부된 도면은 개시의 이해를 돕기 위하여 실제 축척대로 도시된 것이 아니라 일부 구성요소의 치수가 과장되게 도시될 수 있다. 본 개시의 설명에 있어서 각 단계의 순서는 선행 단계가 논리적 및 시간적으로 반드시 후행 단계에 앞서서 수행 되어야 하는 경우가 아니라면 각 단계의 순서는 비제한적으로 이해되어야 한다. 즉, 위와 같은 예외적인 경우를 제외하고는 후행 단계로 설명된 과정이 선행단계로 설명된 과정보다 앞서서 수행되더라도 개시의 본질에는 영향 이 없으며 권리범위 역시 단계의 순서에 관계없이 정의되어야 한다. 본 명세서에서, \"가진다,\" \"가질 수 있다,\" \"포함한다,\" 또는 \"포함할 수 있다\" 등의 표현은 해당 특징(예: 수 치, 기능, 동작, 또는 부품 등의 구성요소)의 존재를 가리키며, 추가적인 특징의 존재를 배제하지 않는다. 그리고, 본 명세서에서는 본 개시의 각 실시 예의 설명에 필요한 구성요소를 설명한 것이므로, 반드시 이에 한 정되는 것은 아니다. 따라서, 일부 구성요소는 변경 또는 생략될 수도 있으며, 다른 구성요소가 추가될 수도 있 다. 또한, 서로 다른 독립적인 장치에 분산되어 배치될 수도 있다. 또한, 본 명세서 및 청구범위에서는 구성요소들 간의 구별을 위하여 “제1”, “제2” 등과 같이 서수를 포함하 는 용어가 사용될 수 있다. 이러한 서수는 동일 또는 유사한 구성요소들을 서로 구별하기 위하여 사용하는 것이 며 이러한 서수 사용으로 인하여 용어의 의미가 한정 해석되어서는 안된다. 일 예로, 이러한 서수와 결합된 구 성요소는 그 숫자에 의해 사용 순서나 배치 순서 등이 제한되어서는 안된다. 필요에 따라서는, 각 서수들은 서 로 교체되어 사용될 수 있다. 본 명세서에서 단수의 표현은 문맥상 명백하게 다르게 뜻하지 않는 한, 복수의 표현을 포함한다. 본 출원에서, “포함하다” 또는 “구성되다” 등의 용어는 명세서 상에 기재된 특징, 숫자, 단계, 동작, 구성요소, 부품 또 는 이들을 조합한 것이 존재함을 지정하려는 것이지, 하나 또는 그 이상의 다른 특징들이나 숫자, 단계, 동작, 구성요소, 부품 또는 이들을 조합한 것들의 존재 또는 부가 가능성을 미리 배제하지 않는 것으로 이해되어야 한 다. 본 개시의 실시 예에서 “모듈”, “유닛”, “부(part)” 등과 같은 용어는 적어도 하나의 기능이나 동작을 수 행하는 구성요소를 지칭하기 위한 용어이며, 이러한 구성요소는 하드웨어 또는 소프트웨어로 구현되거나 하드웨 어 및 소프트웨어의 결합으로 구현될 수 있다. 또한, 복수의 “모듈”, “유닛”, “부(part)” 등은 각각이 개 별적인 특정한 하드웨어로 구현될 필요가 있는 경우를 제외하고는, 적어도 하나의 모듈이나 칩으로 일체화되어 적어도 하나의 프로세서로 구현될 수 있다. 또한, 본 개시의 실시 예에서, 어떤 부분이 다른 부분과 연결되어 있다고 할 때, 이는 직접적인 연결뿐 아니라, 다른 매체를 통한 간접적인 연결의 경우도 포함한다. 또한, 어떤 부분이 어떤 구성요소를 포함한다는 의미는, 특별히 반대되는 기재가 없는 한 다른 구성요소를 제외하는 것이 아니라 다른 구성요소를 더 포함할 수 있는 것 을 의미한다. 본 명세서에서 “학습”이란 인공신경망에서 실제로 출력된 값과 출력층에서 계산되어 산출된 출력 값과의 차이 를 최소화되는 가중치를 찾는 과정을 의미할 수 있다. 이하에서는 도면을 참조하여 본 개시에 대해 더욱 상세히 설명하도록 한다. 도 1은 본 개시의 일 실시 예에 따른 로봇의 동작을 개략적으로 설명하기 위한 도면이다. 도 1에는 본 개시의 일 실시 예에 따라 사용자, 로봇 및 외부 장치가 도시되어 있다. 도 1을 참조하면, 로봇이 존재하는 공간 상에 이벤트가 발생할 수 있다. 그리고, 로봇은 복수의 센서 중 적어도 하나의 센서에 기초하여 이벤트의 발생을 감지할 수 있다(S1). 여기서, 이벤트는 사용자의 행위일 수 도 있고, 로봇의 주위에서 발생한 일련의 사건일 수도 있다. 예를 들어, 로봇은 카메라 또는 마이크 등의 센서를 통하여 감지된 정보를 바탕으로 이벤트의 발생을 감지할 수 있다. 또는, 로봇은 기설정된 수 치 이상으로 감지된 소리, 조도, 진동 등 다양한 경우를 통하여 이벤트의 발생을 감지할 수 있다. 그리고, 로봇은 감지된 정보를 바탕으로 이벤트에 대응되는 서비스를 결정할 수 있다(S2). 예를 들어, 로 봇은 소리를 감지할 수 있는 센서(예컨대, 마이크)를 이용하여 소리를 감지하고, 감지된 소리의 종류를 식 별할 수 있다. 나아가, 로봇은 감지된 소리를 분석하여 소리를 발생시킨 객체의 종류를 식별할 수 있다. 도 1에 도시된 바와 같이, 로봇은 무언가 깨지는 사운드를 감지하고, 감지된 소리가 유리컵이 깨지는 소리 임을 식별할 수 있다. 그리고, 로봇은 발생한 이벤트에 대하여 사용자에게 제공할 서비스를 notification 으로 결정할 수 있다. 여기서, 서비스는 사용자에게 제공되는 로봇의 기능으로, 정보 제공, 위험 알림, 긴 급 연락, 보안 점검 등을 포함할 수 있다. 즉, 로봇이 제공하는 서비스는 로봇이 획득한 정보에 따라 달라질 수 있고, 로봇의 용도에 따라 달라질 수도 있으므로 상술한 예에 한정되지 않는다. 그리고, 로봇은 결정한 서비스를 제공하기 위하여 감지된 정보를 바탕으로 센싱 목표를 설정할 수 있다 (S3). 그리고, 로봇은 복수의 센서에 대한 정보를 바탕으로 설정된 센싱 목표를 수행하기 위한 센서 조합 을 결정할 수 있다(S4). 예를 들어, 로봇이 감지된 정보를 바탕으로 이벤트가 '유리컵이 깨지는 소리' 또 는 '무언가 깨지는 소리'임을 식별하였으나, '유리컵이 깨진 위치' 또는 '깨진 객체가 무엇인지'를 식별하지 못 한 경우, 로봇은 '유리컵이 깨진 위치' 또는 '깨진 객체가 무엇'인지를 식별하는 것을 센싱 목표로 설정할수 있다. 그리고, 로봇은 객체를 감지할 수 있는 비전 센서(예컨대, 카메라) 및 액체를 감지할 수 있는 센 서(예컨대, 초음파 센서)를 센싱 목표를 수행하기 위한 센서 조합으로 결정할 수 있다. 그리고, 로봇은 센싱 목표를 수행하기 위한 센서 조합을 바탕으로 추가 정보를 획득하고(S7), 발생한 이벤 트에 대응하는 서비스를 사용자에게 제공할 수 있다(S8). 예를 들어, 로봇은 비전 센서(예컨대, 카메라) 및 액체를 감지할 수 있는 센서(예컨대, 초음파 센서)를 이용하여 '유리컵이 깨진 위치' 또는 '깨진 객체가 무 엇인지'에 대한 추가 정보를 획득할 수 있다. 그리고, 로봇은 사용자에게 피해를 끼칠만한 위험 요소가 발 생하였음을 notification할 수 있다. 한편, 로봇은 로봇에 포함된 복수의 센서뿐만 아니라, 외부 장치에 포함된 외부 센서를 이용하 여 센서 조합을 결정할 수도 있다. 로봇이 외부 장치에 포함된 외부 센서를 센싱 목표를 수행하기 위 한 센서 중 하나로 결정한 경우, 로봇은 외부 장치로 정보를 요청하고(S5), 외부 장치는 로봇 으로 정보 제공할 수 있다(S6). 예를 들어, 로봇은 비전 센서를 포함하는 외부 장치로 정보를 요청하고, 외부 장치로부터 정보를 수신할 수 있다. 그리고, 로봇은 외부 장치로부터 수신한 정 보를 분석하여 발생한 이벤트에 대한 추가 정보를 획득하고, 사용자에게 서비스를 제공할 수 있다. 도 1에서 설명하는 외부 장치는 로봇과 통신 연결을 수행할 수 있는 전자 장치일 수 있다. 일 실시 예로, 외부 장치는 스마트폰, 태블릿 PC, 영상 전화기, smart TV, 전자책 리더기, 데스크탑 PC, 랩탑 PC, 넷북 컴퓨터, 워크스테이션, 서버, PDA, PMP(portable multimedia player), AI 스피커, 마이크, 카메라, IoT 장치, IoT Gateway 또는 웨어러블 장치 중 적어도 하나를 포함할 수 있다. 본 개시에 따른 일 실시 예에 따르면, 로봇은 사용자가 직접적으로 특정 서비스를 요청하지 않은 경우에도 이벤트의 발생을 감지하고 자율적으로 해당 이벤트에 대응되는 특정 서비스를 제공할 수 있다. 또한, 로봇(10 0)은 자율적으로 이벤트에 대응되는 특정 서비스를 제공하기 위하여 센싱 목표를 설정하고, 센서 조합을 결정할 수 있다. 다만, 도 1에서는 설명의 편의를 위하여 사용자가 로봇에게 특정 서비스를 요청하지 않은 경우를 상정하여 설명하였으나, 사용자가 로봇에게 특정 서비스를 요청하는 경우, 로봇은 사용자가 요청한 특정 서비스를 제공할 수 있음은 물론이다. 도 2는 본 개시의 일 실시 예에 따른 로봇의 구성을 간략히 도시한 블록도이다. 도 2를 참조하면, 로봇은 복수의 센서, 메모리 및 프로세서를 포함할 수 있다. 복수의 센서는 로봇의 주변에 대한 다양한 정보를 획득하기 위한 구성일 수 있다. 복수의 센서 는 열, 빛, 온도, 압력, 소리 등의 물리적인 변화를 감지하여 전기적 신호로 변경할 수 있고, 변경된 전기적 신 호를 바탕으로 로봇의 주변에 대한 다양한 정보를 획득할 수 있다. 예를 들어, 로봇은 라이다 센서 또는 초음파 센서를 통하여 감지된 정보를 바탕으로 근접한 위치에 존재하는 사용자의 존재를 검출할 수 있다. 이외에도, 복수의 센서는 다양한 센서를 포함할 수 있으며, 복수의 센서에 대하여는 도 3을 참조하여 구체적으로 설명하도록 한다. 메모리는 로봇의 적어도 하나의 다른 구성요소에 관계된 인스트럭션(Instruction) 또는 데이터를 저 장할 수 있다. 특히, 메모리는 비휘발성 메모리, 휘발성 메모리, 플래시메모리(flash-memory), 하드디스크 드라이브(HDD) 또는 솔리드 스테이트 드라이브(SSD) 등으로 구현될 수 있다. 메모리는 프로세서에 의해 액세스되며, 프로세서에 의한 데이터의 독취/기록/수정/삭제/갱신 등 이 수행될 수 있다. 본 개시에서 메모리라는 용어는 프로세서 내 롬(미도시), 램(미도시) 또는 로봇 에 장착되는 메모리 카드(미도시)(예를 들어, micro SD 카드, 메모리 스틱)를 포함할 수 있다. 특히, 메모리에는 사용자에게 제공하기 위한 복수의 서비스 및 복수의 서비스에 대응되는 제어 명령이 저 장될 수 있다. 여기서, 서비스는 사용자에게 제공되는 로봇의 기능으로, 정보 제공, 위험 알림, 긴급 연락, 보안 점검 등을 포함할 수 있다. 즉, 로봇이 제공하는 서비스는 로봇이 획득한 정보에 따라 달 라질 수 있고, 로봇의 용도 및 기능에 따라 달라질 수 있다. 그리고, 메모리는 로봇을 이용하는 목적에 따라 분류된 프로파일을 저장할 수 있다. 여기서, 프로파 일은 로봇을 이용하려는 목적에 따라 다르게 설정되는 로봇의 동작 모드일 수 있다. 구체적으로, 프로파일 은 사용자에게 제공되는 서비스에 대한 우선 순위에 대한 정보를 포함하는 것으로, 예컨대, 로봇의 동작 모드가 사용자에게 care 관련 서비스를 제공하는 프로파일(예컨대, elderly care)로 설정되는 경우, 로봇 은 복약 지도, 건강 정보 제공, 위험 알림, 보호자 긴급 연락, 미끄러짐 주의 안내 등의 서비스를 우선적으로제공할 수 있다. 또한, 메모리는 로봇이 존재하는 공간에 대한 정보를 저장할 수 있다. 로봇은 로봇의 가동 범위 내에 존재하는 외부 장치 또는 외부 센서를 식별하고, 외부 장치 또는 외부 센서에 대한 정보를 메모리에 저장할 수 있다. 예를 들어, 메모리에 저장된 외부 장치 또는 외부 센서에 대한 정보 는 각 외부 장치의 위치 정보, 센싱 정보, 사용 이력 정보 등을 포함하는 속성 정보를 포함할 수 있다. 그리고, 메모리는 로봇에 포함된 복수의 센서뿐만 아니라, 로봇 주변의 외부 장치 또 는 외부 센서에 대한 정보를 저장할 수 있다. 구체적으로, 메모리는 로봇에 포함된 복수의 센서 각각의 활성화 조건에 대한 정보, 주변의 외부 장치 또는 외부 센서의 활성화 조건에 대한 정보를 저장할 수 있다. 그리고, 메모리는 서로 다른 상황에서 발생하는 이벤트를 식별하기 위한 데이터를 저장할 수 있다. 예를 들어, 메모리는 기학습된 객체 인식 모델 또는 객체 분석 모델에 따른 데이터를 저장하거나, 감지된 소리 를 분석하기 위한 데이터인 기학습된 음향 인식 모델 또는 음향 분석 모델에 따른 데이터를 저장할 수 있다. 이 외에도, 메모리는 발생한 이벤트를 식별하기 위한 다양한 데이터를 저장할 수 있다. 프로세서는 로봇에 포함된 구성들을 제어하기 위한 구성일 수 있다. 구체적으로, 프로세서는 로 봇와 전기적으로 연결되어 로봇의 전반적인 동작 및 기능을 제어할 수 있다. 예를 들어, 프로세서 는 운영 체제 또는 운영 프로그램을 구동하여 프로세서에 연결된 하드웨어 또는 소프트웨어 구성요소 들을 제어할 수 있고, 각종 데이터 처리 및 연산을 수행할 수 있다. 또한, 프로세서는 다른 구성요소들 중 적어도 하나로부터 수신된 명령 또는 데이터를 휘발성 메모리에 로드하여 처리하고, 다양한 데이터를 비휘발성 메모리에 저장할 수 있다. 이를 위해, 프로세서는 해당 동작을 수행하기 위한 전용 프로세서(예컨대, 임베디드 프로세서) 또는 메모 리 디바이스에 저장된 하나 이상의 소프트웨어 프로그램을 실행함으로써, 해당 동작들을 수행할 수 있는 범용 프로세서(예컨대, CPU(Central Processing Unit) 또는 application processor)로 구현될 수 있다. 특히, 프로세서는 복수의 센서 중 적어도 하나의 센서에 기초하여 이벤트가 발생되었는지 판단할 수 있다. 구체적으로, 프로세서는 복수의 센서 중 적어도 하나의 센서에 의하여 감지된 정보를 바탕으로 발생한 이벤트 및 주변 상황을 식별할 수 있다. 프로세서는 인공지능 모델을 이용하여 감지된 정보(예컨대, 감지된 소리 또는 촬상된 이미지)를 분석할 수 있다. 여기서, 인공지능 모델은 수학적 모델로서의 뉴런이 상호 연결되어 네트워크를 형성하는 것을 의미할 수 있다. 구체적으로, 프로세서는 생물의 신경 네 트워크 구조와 기능을 모방하여 생성된 인공 신경망(Neural Network) 중 하나를 이용할 수 있다. 그리고, 프로세서는 로봇을 이용하는 목적에 따라 분류된 프로파일에 기초하여 복수의 서비스에 대한 우선 순위를 획득하고, 획득한 우선 순위를 바탕으로 이벤트의 발생을 감지할 수 있다. 여기서, 프로파일은 로 봇을 이용하려는 목적에 따라 다르게 설정되는 로봇의 동작 모드일 수 있다. 구체적으로, 프로파일은 사용 자에게 제공되는 서비스에 대한 우선 순위에 대한 정보를 포함하는 것으로, 예컨대, 로봇의 동작 모드가 사용자에게 care 관련 서비스를 제공하는 프로파일(예컨대, elderly care)로 설정되는 경우, 프로세서는 복약 지도, 건강 정보 제공, 위험 알림, 보호자 긴급 연락, 미끄러짐 주의 안내 등의 서비스를 우선적으로 제공 할 수 있고, 해당 서비스와 관련된 이벤트의 발생을 우선적으로 감지하기 위한 동작을 수행할 수 있다. 그리고, 프로세서는 센서에 의하여 감지된 정보를 메모리에 저장된 데이터와 비교하여 발생한 이벤트 를 식별할 수 있다. 구체적으로, 메모리는 서로 다른 상황에서 발생하는 이벤트를 식별하기 위한 데이터를 저장할 수 있고, 프로세서는 기학습된 객체 인식 모델 또는 객체 분석 모델을 이용하거나, 감지된 소리를 분석하기 위한 데이터인 기학습된 음향 인식 모델 또는 음향 분석 모델을 이용하여 이벤트를 식별할 수 있다. 그리고, 프로세서는 이벤트에 대응되는 서비스를 결정할 수 있다. 여기서, 서비스는 사용자에게 제공되는 로봇의 기능으로, 정보 제공, 위험 알림, 긴급 연락, 보안 점검 등을 포함할 수 있다. 즉, 로봇이 제 공하는 서비스는 로봇이 획득한 정보에 따라 달라질 수 있고, 로봇의 용도에 따라 달라질 수도 있으 므로 상술한 예에 한정되지 않는다. 그리고, 프로세서는 감지된 정보를 바탕으로 결정된 서비스에 대응되는 센싱 목표를 설정할 수 있다. 프로 세서는 초기 로봇의 운용 환경에 대한 정보를 획득하고, 운용 환경에 대한 정보와 센서에 의하여 감 지된 정보를 바탕으로 센싱 목표를 설정할 수 있다. 구체적으로, 프로세서는 감지된 정보를 시간, 장소, 빈도 또는 관련 객체 중 적어도 하나를 포함하는 히스토리 정보에 따라 분석하고, 분석된 히스토리 정보에 기초하여 센싱 목표를 설정할 수 있다. 한편, 프로세서는 사용자로부터 명령을 수신하고, 수신한 명령에 기초하여 서비스를 제공할 수 있다. 구체 적으로, 복수의 서비스 중 적어도 하나의 서비스를 요청하는 사용자의 명령을 수신하면, 프로세서는 사용 자의 명령을 히스토리 정보에 따라 분석하고, 분석된 히스토리 정보에 기초하여 센싱 목표를 설정할 수 있다. 여기서, 프로세서가 히스토리 정보에 따라 분석하는 것은 프로세서가 육하원칙에 기초하여 감지된 정 보를 분석하는 것을 의미할 수 있다. 육하원칙은 “누가”, “언제”, “어디서”, “무엇을”, “어떻게”, “ 왜”의 여섯 가지를 의미할 수 있는데, 프로세서는 육하원칙에 기초하여 감지된 정보를 분석함으로써 사용 자의 개입을 최소화하여 발생된 이벤트를 분석할 수 있고, 분석된 정보를 학습할 수 있다. 예를 들어, 오전 8시 30분에 사용자가 창문 개방 여부를 확인하는 이벤트가 발생하였고, 복수의 센서에 의하여 발생된 이벤트가 감지된 경우, 프로세서는 감지된 정보를 “누가: 사용자가, 언제: 사용자의 출근 전에, 어디서: 부엌에서, 무엇을: 창문을, 어떻게: 개방 여부 확인함, 왜: 보안을 위하여”로 분석할 수 있다. 그리고, 프로세서는 분석된 정보를 바탕으로 “사용자의 출근 전에 창문의 개방 여부”를 확인이라는 센싱 목표를 설정할 수 있다. 프로세서는 복수의 센서에 대한 정보를 바탕으로 설정된 센싱 목표를 수행하기 위한 센서 조합을 결 정할 수 있다. 구체적으로, 프로세서는 복수의 센서에 대한 정보를 바탕으로 각 센서에 대한 적어도 하나의 감지 역할을 결정할 수 있다. 예를 들어, 로봇은 마이크를 포함할 수 있고, 프로세서는 마이 크에 대한 정보를 바탕으로 감지 역할 중 제1 역할을 “소리 측정 및 소리 감지”로 결정하고, 제2 역할을 “발 생한 소리의 방향 및 위치 감지”로 결정할 수 있다. 또는, 로봇은 초음파 센서를 포함할 수 있고, 프로세 서는 초음파 센서에 대한 정보를 바탕으로 감지 역할 중 제1 역할을 “거리 측정”으로 결정하고, 제2 역 할을 “액체 감지”로 결정할 수도 있다. 다만, 이는 본 개시에 따른 일 실시 예일뿐, 본 개시에 대한 기술적인 특징이 상술한 예시에 한정되는 것은 아니며, 구현시에는 각 센서의 역할이 다양하게 설정될 수 있다. 그리고, 프로세서는 결정된 감지 역할을 바탕으로 상기 센서 조합을 결정하고, 결정된 센서 조합을 바탕으 로 추가 정보를 획득하여 서비스를 사용자에게 제공하도록 로봇의 각 구성을 제어할 수 있다. 한편, 프로세서는 이용할 수 있는 외부 센서를 식별하고, 외부 센서 및 외부 센서의 정보를 더 고려하여 센서 조합을 결정할 수도 있다. 여기서, 외부 센서의 정보는 외부 센서가 감지하는 객체 또는 감지한 데이터의 종류와 관련된 센싱 정보, 외부 센서의 위치에 관련된 위치 정보 또는 로봇에 연결되어 사용된 정보와 관 련된 사용 이력 정보를 의미할 수 있다. 한편, 프로세서는 외부 서버로부터 외부 정보를 획득하고, 획득한 외부 정보를 바탕으로 사용자에게 제공 할 서비스를 결정할 수도 있다. 예를 들어, 프로세서는 뉴스 또는 인터넷으로부터 사용자가 존재하는 지역 의 환경 정보(예컨대, 일기예보 등)를 수신할 수 있고, 프로세서는 환경 정보를 바탕으로 사용자에게 제공 할 서비스(예컨대, 일기예보 알림)를 결정할 수 있다. 한편, 프로세서는 사용자로부터 설정된 센싱 목표 또는 제공된 서비스에 대한 피드백을 획득하고, 피드백 을 바탕으로 센싱 목표 또는 제공된 서비스에 대한 정보를 업데이트할 수 있다. 프로세서는 피드백 및 업 데이트를 통하여 잘못 설정된 센싱 목표를 수정할 수 있고, 프로세서는 제공된 서비스에 대한 만족도를 파 악할 수 있으므로, 사용자에게 맞춤 서비스를 제공할 수 있다. 도 3은 본 개시의 일 실시 예에 따른 로봇의 구성을 상세히 도시한 블록도이다. 도 3을 참조하면, 로봇은 복수의 센서, 메모리 및 프로세서 이외에도 디스플레이, 스피커, 통신 인터페이스 및 구동부를 포함할 수 있다. 한편, 도 2를 참조하여, 복수의 센서, 메모리 및 프로세서 에 대하여 상세히 설명하였는바, 중복되는 설명은 생략하기로 한다. 복수의 센서는 열, 빛, 온도, 압력, 소리 등의 물리적인 변화를 감지하여 전기적 신호로 변경할 수 있고, 변경된 전기적 신호를 바탕으로 로봇의 주변에 대한 다양한 정보를 획득할 수 있다. 그리고, 복수의 센서 는 마이크(110-1), 비전 센서(110-2), 모션 센서(110-3), 초음파 센서(110-4), 온도 센서(110-5), 조도 센서(110-6), 적외선 센서(110-7), 가속도 센서(미도시), 자이로 센서(미도시) 등을 포함할 수 있다. 마이크(110-1)는 소리를 감지하여 소리에 따라 다른 값을 출력할 수 있는 센서일 수 있다. 예를 들어, 다이나믹 마이크, 콘덴서 마이크 등으로 구현될 수 있고, 가청 주파수에 대한 소리를 감지하기 위한 장치일 수 있다. 마 이크(110-1)는 로봇에 복수개 포함될 수 있고, 각 마이크를 통해 수신되는 소리의 크기를 비교하여 소리의 방향을 감지할 수도 있다.비전 센서(110-2)는 객체를 감지하기 위한 센서일 수 있다. 예를 들어, 비전 센서(110-2)는 카메라, 레이더 (radar) 센서, 라이다(lidar) 센서, 초음파 센서, RF 센서 또는 뎁스(depth) 센서 중 적어도 하나를 포함할 수 있다. 비전 센서(110-2)가 투과형 레이더(radar)의 일종인 경우, 장애물 뒤에 위치한 객체까지 인식할 수 있으 나, 저출력 레이터(radar)의 일종인 경우, 음영이 생기는 구역(예컨대, 장애물 뒤)에는 정확한 감지가 불가능할 수 있다. 모션 센서(110-3)는 움직임을 감지하기 위한 센서일 수 있다. 모션 센서(110-3)는 사용자의 움직임 또는 객체의 움직임을 감지하는데 이용되는 센서일 수 있다. 초음파 센서(110-4)는 비가청 주파수를 이용하여 거리 측정 또는 객체 감지를 위한 센서일 수 있다. 예를 들어, 초음파 센서(110-4)는 액티브(active) 센서의 일종으로 특정 신호를 전송하여 ToF(Time of Flight)를 측정하는 방식으로 거리를 측정할 수 있다. 여기서, ToF는 비행시간 거리측정 방법으로, 펄스가 발사된 기준 시점과 측정 대상물에서 반사되어 되돌아온 펄스의 검출시점 사이의 시간차를 측정하여 거리를 측정하는 방법일 수 있다. 온도 센서(110-5)는 열을 감지하여 전기신호를 내는 센서일 수 있다. 온도 센서(110-5)는 온도에 따라 전기 특 성이 변화하는 성질을 이용하여 온도를 감지할 수 있다. 조도 센서(110-6)는 빛의 밝기를 측정하는 센서일 수 있다. 조도 센서(110-6)는 빛의 밝기에 따라 저항이 변화 하는 광 가변저항을 이용하여 빛의 밝기를 측정하는 센서를 의미할 수 있다. 적외선 센서(110-7)는 적외선을 이용해 온도, 압력, 방사선의 세기 등의 물리량이나 화학량을 감지하고 전기량 을 변환하는 장치를 의미할 수 있다. 적외선 센서(110-7)는 조도가 낮은 경우(예컨대, 밤)에 객체를 감지하는데 이용될 수 있다. 도 3에는 로봇에 포함될 수 있는 복수의 센서의 일 실시 예가 도시되어 있으나, 구현시에는 이에 한 정되지 않고, 사용자의 행위를 식별하거나 주변 상황을 감지하기 위한 센서를 추가로 포함할 수도 있다. 예컨대, 로봇은 가속도 센서, 가스 센서, 먼지 센서 등을 이용하여 주변 상황을 식별할 수도 있다. 디스플레이는 프로세서의 제어에 따라 다양한 정보를 표시할 수 있다. 특히, 디스플레이는 사용 자에게 제공되는 서비스를 텍스트 또는 이미지로 제공할 수 있다. 디스플레이는 LCD(Liquid Crystal Display Panel), LED(light emitting diode), OLED(Organic Light Emitting Diodes), LCoS(Liquid Crystal on Silicon), DLP(Digital Light Processing) 등과 같은 다양한 형태의 디스플레이로 구현될 수 있다. 또한, 디스 플레이 내에는 a-si TFT, LTPS(low temperature poly silicon) TFT, OTFT(organic TFT) 등과 같은 형태로 구현될 수 있는 구동 회로, 백라이트 유닛 등도 함께 포함될 수 있다. 또한, 디스플레이는 터치 패널과 함 께 결합되어 터치 스크린으로 구현될 수도 있다. 다만, 이는 일 실시 예일뿐이고, 디스플레이는 다양하게 구현 될 수 있다. 스피커는 오디오 처리부에 의해 디코딩이나 증폭, 노이즈 필터링과 같은 다양한 처리 작업이 수행된 각종 오디오 데이터뿐만 아니라 각종 알림 음이나 음성 메시지를 출력하는 구성일 수 있다. 특히, 스피커는 특 정 이벤트에 대한 서비스를 제공하는데 이용될 수 있다. 예를 들어, 로봇은 사용자에게 정보를 제공하는 서비스를 위하여, 스피커를 이용하여 자연어 형태의 음성 메시지로 출력할 수 있다. 한편, 오디오를 출력 하기 위한 구성은 스피커로 구현될 수 있으나, 이는 일 실시 예에 불과할 뿐, 오디오 데이터를 출력할 수 있는 출력 단자로 구현될 수 있다. 통신 인터페이스는 외부 장치 또는 서버와 통신을 수행하기 위해 다양한 통신 모듈을 포함할 수 있다. 예를 들어, 통신 인터페이스는 NFC 모듈(미도시), 무선 통신 모듈(미도시), 적외선 모듈(미도시) 및 방송 수신 모듈(미도시)을 포함할 수 있다. 통신 인터페이스는 유선 방식뿐만 아니라, WLAN(Wireless LAN), Wi-Fi, DLNA(Digital Living Network Alliance), HSDPA(High Speed Downlink Packet Access), HSUPA(High Speed Uplink Packet Access), LTE, LTE-A, 블루투스, RFID, 적외선 통신, ZigBee 등의 무선 통신 방식을 통해 외부 장치와 연결될 수 있다. 통신 인터페이스는 다양한 통신 모듈을 이용하여 외부 장치 또는 서버와 통신을 수행할 수 있다. 통신 인터페이스는 외부 장치 또는 서버로부터 사용자에 제공하기 위한 정보를 수신할 수 있다. 구동부는 로봇의 모션 내지는 이동을 제어하기 위한 구성일 수 있다. 그리고, 구동부는 로봇 의 이동 수단을 제어할 수 있고, 로봇의 물리적 움직임을 구현하는 기계적 구성과 전기적으로 연결되어 해당 구성을 구동/제어할 수 있다. 예를 들어, 도 1의 로봇의 형태로 구현되는 경우, 구동부는 로 봇의 바퀴, 로봇의 헤드의 회전을 제어하는 기계적 구성 등을 제어할 수 있다. 이밖에, 로봇에 팔이 나 다리와 같은 별도 구성이 포함된 경우라면, 구동부는 팔 및 다리의 움직임을 제어하도록 구현될 수도 있다. 도 4는 본 개시의 일 실시 예에 따른 로봇 시스템을 설명하기 위한 도면이다. 도 4를 참조하면, 로봇 시스템은 로봇, 외부 장치 및 서버를 포함할 수 있다. 그리고, 로 봇은 통신 인터페이스를 이용하여 외부 장치 또는 서버와 통신을 수행할 수 있다. 로봇 은 사용자에게 서비스를 제공하기 위하여 외부 장치에 포함된 외부 센서를 이용하여 서비스를 제공하 기 위한 정보를 획득할 수 있다. 구체적으로, 로봇은 로봇의 주변에 존재하는 외부 장치 또는 외부 센서를 식별할 수 있다. 그리고, 로봇은 외부 장치와 직접 연결하거나, IoT 장치(예컨대, IoT 게이트웨이)를 이용하여 외부 센서를 이용할 수 있다. 예를 들어, 제1 외부 장치(200-1)는 카메라로 구현될 수 있고, 제1 외부 장치(200-1)는 IoT 장치(예컨대, IoT 게이트웨이)를 통하여 로봇에 간적적으로 연결될 수 있다. 반면에, 제2 외부 장치(200-2)는 스마트폰으로 구현될 수 있고, 제2 외부 장치(200-2)는 근거리 통신 등 을 이용하여 로봇에 직접적으로 연결될 수 있다. 그리고, 로봇은 외부 장치로부터 외부 장치 및 외부 센서의 정보를 수신할 수 있고, 외부 장치 또는 외부 센서를 더 고려하여 센싱 목표를 수행하기 위한 센서 조합을 결정할 수 있다. 구체적으로, 로 봇은 외부 장치로부터 외부 센서의 센싱 정보, 위치 정보 또는 사용 이력 정보 중 적어도 하나를 포 함하는 외부 센서의 정보를 수신할 수 있다. 여기서, 외부 센서의 정보는 외부 센서가 감지하는 객체 또는 감지 한 데이터의 종류와 관련된 센싱 정보, 외부 센서의 위치에 관련된 위치 정보 또는 로봇에 연결되어 사용 된 정보와 관련된 사용 이력 정보를 의미할 수 있다. 한편, 로봇은 서버로부터 외부 정보를 획득하고, 획득한 외부 정보를 바탕으로 사용자에게 제공할 서 비스를 결정할 수도 있다. 예를 들어, 로봇은 뉴스 또는 인터넷으로부터 사용자가 존재하는 지역의 환경 정보(예컨대, 일기예보 등)를 수신할 수 있고, 로봇은 환경 정보를 바탕으로 사용자에게 제공할 서비스(예 컨대, 일기예보 알림)를 결정할 수 있다. 도 5는 본 개시의 일 실시 예에 따른 외부 장치의 구성을 도시한 블록도이다. 도 5를 참조하면, 외부 장치는 센서, 통신 인터페이스, 프로세서를 포함할 수 있다. 일 실 시 예로, 외부 장치는 스마트폰, 태블릿 PC, 영상 전화기, smart TV, 전자책 리더기, 데스크탑 PC, 랩탑 PC, 넷북 컴퓨터, 워크스테이션, 서버, PDA, PMP(portable multimedia player), AI 스피커, 마이크, 카메라, IoT 장치, IoT Gateway 또는 웨어러블 장치 중 적어도 하나를 포함할 수 있다. 센서는 외부 장치의 주변에 대한 다양한 정보를 획득하기 위한 구성일 수 있다. 구체적으로, 센서 는 열, 빛, 온도, 압력, 소리 등의 물리적인 변화를 감지하여 전기적 신호로 변경할 수도 있고, 변경된 전 기적 신호를 바탕으로 외부 장치의 주변에 대한 다양한 정보를 획득할 수 있다. 통신 인터페이스는 로봇과 연결하기 위한 구성일 수 있다. 구체적으로, 통신 인터페이스는 로봇 으로부터 정보 요청을 수신하고, 로봇으로 요청된 정보를 송신하기 위한 구성일 수 있다. 이를 위해, 통신 인터페이스는 다양한 통신 모듈을 포함할 수 있다. 예를 들어, 통신 인터페이스는 NFC 모듈(미 도시), 무선 통신 모듈(미도시), 적외선 모듈(미도시) 및 방송 수신 모듈(미도시)을 포함할 수 있다. 통신 인터 페이스는 유선 방식뿐만 아니라, WLAN(Wireless LAN), Wi-Fi, DLNA(Digital Living Network Alliance), HSDPA(High Speed Downlink Packet Access), HSUPA(High Speed Uplink Packet Access), LTE, LTE-A, 블루투스, RFID, 적외선 통신, ZigBee 등의 무선 통신 방식을 통해 로봇와 연결될 수 있다. 로봇과 외부 장치의 통신 방식은 3G, 4G와 같은 이동 통신망을 사용하는 방식, 근거리 무선 통신 방 식인 지그비(Zigbee), BT(BlueTooth), IR(InfraRed)을 사용하는 방식, Wi-Fi를 사용하는 방식, 유선망을 사용 하는 방식 등일 수 있다. 이는 일 실시 예일뿐이고, 다양한 방식으로 로봇과 외부 장치는 통신 연결 될 수 있다. 즉, 통신 인터페이스는 다양한 통신 모듈을 이용하여 로봇과 통신을 수행할 수 있고, 통 신 인터페이스는 로봇으로 사용자에 제공하기 위한 정보를 송신할 수 있다. 그리고, 통신 인터페이스가 로봇과 통신 연결되는 것은 제3 기기(예컨대, 중계기, 허브, 액세스 포인 트, 서버, 게이트웨이 등)를 거쳐서 통신하는 것을 포함할 수 있다.프로세서는 외부 장치의 각 구성과 전기적으로 연결되어 외부 장치의 전반적인 동작 및 기능을 제어할 수 있다. 예를 들어, 프로세서는 운영 체제 또는 운영 프로그램을 구동하여 프로세서에 연결 된 하드웨어 또는 소프트웨어 구성요소들을 제어할 수 있고, 각종 데이터 처리 및 연산을 수행할 수 있다. 또한, 프로세서는 다른 구성요소들 중 적어도 하나로부터 수신된 명령 또는 데이터를 휘발성 메모리에 로 드하여 처리하고, 다양한 데이터를 비휘발성 메모리에 저장할 수 있다. 특히, 프로세서는 로봇으로부터 요청된 정보를 감지하도록 외부 장치를 제어할 수 있다. 그리고, 프로세서는 감지한 정보를 로봇으로 전송하도록 통신 인터페이스를 제어할 수 있다. 도 5는 본 개시의 일 실시 예에 따른 외부 장치는 설명의 편의를 위하여 센서, 통신 인터페이스 및 프로세서를 포함하는 형태로 도시하였으나, 상술한 구성에 한정되는 것은 아니며, 외부 장치의 유 형에 따라 통신 인터페이스 또는 프로세서가 생략될 수 있고, 일부 구성이 추가될 수 있음은 물론이 다. 도 6 및 도 7은 본 개시의 일 실시 예에 따른 이격되어 배치된 외부 장치를 설명하기 위한 도면이다. 도 6을 참조하면, 로봇이 존재하는 공간에는 여섯 개의 외부 장치(200-1 내지 200-6)가 구비될 수 있다. 구체적으로, 제1 외부 장치(200-1), 제2 외부 장치(200-2) 및 제3 외부 장치(200-3)는 거실에 구비되며, 제4 외 부 장치(200-4)는 방에 구비되며, 제5 외부 장치(200-5)는 부엌에 구비되며, 제6 외부 장치(200-6)는 화장실에 구비될 수 있다. 그리고, 제1 내지 제6 외부 장치(200-1 내지 200-6)는 도 7에 도시된 바와 같이, 복수의 센서 를 포함할 수 있다. 구체적으로, 제1 외부 장치(200-1)는 비전 센서, 마이크를 포함하고, 제2 외부 장치(200-2)는 자이로 센서, 가 속도 센서, 비전 센서, 모션 센서, 근접 센서를 포함하고, 제3 외부 장치(200-3)는 홀 센서, 모션 센서, 조도 센서를 포함하고, 제4 외부 장치(200-4)는 비전 센서, 마이크, 조도 센서를 포함하고, 제5 외부 장치(200-5)는 온도 센서, 가스 센서를 포함하고, 제6 외부 장치(200-6)는 조도 센서, 모션 센서를 포함할 수 있다. 제1 내지 제6 외부 장치(200-1 내지 200-6)는 각각 다른 센서를 포함하고 있고, 로봇은 제1 내지 제6 외부 장치로부터 각 외부 장치에 포함된 외부 센서의 정보를 식별할 수 있다. 그리고, 로봇은 외부 센서의 정보 를 바탕으로 설정된 센싱 목표를 수행하기 위한 센서 조합을 결정할 수 있다. 예를 들어, 로봇이 소리를 감지하고, 감지된 소리를 바탕으로 “화장실에서 발생한 이벤트에 대한 정보를 제공”하는 것을 사용자에게 제공할 서비스로 결정하고, “화장실에서 발생한 이벤트를 식별”하는 것을 센싱 목표로 설정한 경우, 로봇은 비전 센서, 마이크, 모션 센서를 센싱 목표를 수행하기 위한 센서 조합으로 결정할 수 있다. 로봇은 외부 장치(200-1 내지 200-6)로부터 수신한 외부 센서에 대한 위치 정보를 바탕으 로 제6 외부 장치(200-6)가 화장실에 구비되어 있고, 제6 외부 장치(200-6)에 포함된 모션 센서를 이용할 수 있 음을 식별할 수 있다. 그리고, 로봇은 로봇에 포함된 비전 센서 및 마이크와, 제6 외부 장치(200- 6)에 포함된 모션 센서를 이용하여 “화장실에서 발생한 이벤트를 식별”하고, 사용자에게 “화장실에서 발생한 이벤트에 대한 정보를 제공”하는 서비스를 제공할 수 있다. 즉, 로봇은 외부 장치의 위치 정보를 이 용하여, 센싱 목표에 대응되는 위치에 구비된 외부 장치를 이용하여 추가 정보를 획득할 수 있다. 한편, 제1 내지 제6 외부 장치(200-1 내지 200-6)는 외부 장치의 종류에 따라 특정 위치에 유동적으로 구 비될 수 있다. 예를 들어, 제2 외부 장치(200-2)는 로봇 청소기일 수 있고, 특정 위치에 고정되어 구비되지 않 고, 시간에 따라 이동하는 특성을 가질 수 있다. 로봇은 제2 외부 장치(200-2)의 출몰 패턴 및 이동 경로 를 식별하고, 제2 외부 장치(200-2)의 출몰 패턴 및 이동 경로를 바탕으로 제2 외부 장치(200-2)의 주변 정보를 수신할 수도 있다. 또 다른 실시 예에 따르면, 로봇은 센서에 대한 정보를 바탕으로 각 센서에 대한 적어도 하나의 감지 역할 을 결정할 수 있다. 그리고, 로봇은 각 센서에 대한 적어도 하나의 감지 역할을 바탕으로 센서 조합을 결 정할 수 있다. 예를 들어, 로봇은 제1 외부 장치(200-1) 및 제4 외부 장치(200-4)에 대한 정보를 바탕으로 제1 외부 장치(200-1)는 거실에 구비되고, 제4 외부 장치(200-4)는 방에 구비된 것을 식별할 수 있다. 그리고, 로봇은 제1 외부 장치(200-1) 및 제4 외부 장치(200-4)에 포함된 마이크를 이벤트의 발생 위치를 감지하기 위한 장치로 이용할 수 있다. 즉, 로봇은 마이크를 음성 입력이 아닌 소음 측정으로 감지 역할을 결정하고, 결정된 감지 역할을 바탕으로 센서 조합을 결정할 수 있다. 도 8은 본 개시의 일 실시 예 따른 로봇의 제어 방법을 설명하기 위한 순서도이다. 로봇에 포함된 복수의 센서 중 적어도 하나의 센서에 기초하여 이벤트의 발생이 감지되면(S810), 로봇 은 적어도 하나의 센서에 의하여 감지된 정보를 바탕으로 이벤트에 대응되는 서비스를 결정할 수 있다 (S820). 여기서, 로봇은 로봇을 이용하는 목적에 따라 분류된 프로파일에 기초하여 이벤트의 발생을 감지할 수 있다. 프로파일은 로봇을 이용하려는 목적에 따라 다르게 설정되는 로봇의 동작 모드일 수 있다. 구체적으로, 프로파일은 사용자에게 제공되는 서비스에 대한 우선 순위에 대한 정보를 포함하는 것으로, 예컨대, 로봇의 동작 모드가 사용자에게 care 관련 서비스를 제공하는 프로파일(예컨대, elderly care)로 설정되는 경우, 로봇은 복약 지도, 건강 정보 제공, 위험 알림, 보호자 긴급 연락, 미끄러짐 주의 안내 등 의 서비스를 우선적으로 제공할 수 있다. 그리고, 로봇은 감지된 정보를 바탕으로 결정된 서비스에 대응되는 센싱 목표를 설정할 수 있다(S830). 구 체적으로, 로봇은 감지된 정보를 시간, 장소, 빈도 또는 관련 객체 중 적어도 하나를 포함하는 히스토리 정보에 따라 분석하고, 분석된 히스토리 정보에 기초하여 센싱 목표를 설정할 수 있다. 또 다른 실시 예에 따르 면, 로봇은 복수의 서비스 중 적어도 하나의 서비스를 요청하는 사용자의 명령을 수신하고, 사용자의 명령 을 히스토리 정보에 따라 분석하고, 분석된 히스토리 정보에 기초하여 센싱 목표를 설정할 수도 있다. 여기서, 로봇이 히스토리 정보에 따라 분석하는 것은 육하원칙에 기초하여 감지된 정보를 분석하는 것을 의미할 수 있다. 육하원칙은 “누가”, “언제”, “어디서”, “무엇을”, “어떻게”, “왜”의 여섯 가지를 의미할 수 있는데, 로봇은 육하원칙에 기초하여 감지된 정보를 분석함으로써 사용자의 개입을 최소화하여 발생된 이 벤트를 분석할 수 있고, 분석된 정보를 학습할 수 있다. 그리고, 로봇은 복수의 센서에 대한 정보를 바탕으로 설정된 센싱 목표를 수행하기 위한 센서 조합을 결정 할 수 있다(S840). 구체적으로, 로봇은 복수의 센서에 대한 정보를 바탕으로 각 센서에 대한 적어도 하나 의 감지 역할을 결정하고, 결정된 감지 역할을 바탕으로 센서 조합을 결정할 수 있다. 또는, 로봇은 로봇 이 이용할 수 있는 외부 센서를 식별하고, 외부 센서 및 외부 센서의 정보를 더 고려하여 센서 조합을 결 정할 수도 있다. 여기서, 외부 센서의 정보는 외부 센서의 센싱 정보, 위치 정보 또는 사용 이력 정보를 포함할 수 있다. 그리고, 로봇은 결정된 센서 조합을 바탕으로 추가 정보를 획득하여 서비스를 사용자에게 제공할 수 있다 (S850). 한편, 로봇은 서버로부터 외부 정보를 획득하고, 획득한 외부 정보를 바탕으로 서비스를 결정할 수도 있다. 한편, 로봇은 사용자로부터 설정된 센싱 목표 또는 제공된 서비스에 대한 피드백을 획득하고, 피드백을 바 탕으로 센싱 목표 또는 제공된 서비스에 대한 정보를 업데이트할 수도 있다. 한편, 본 개시에서 사용된 용어 \"부\" 또는 \"모듈\"은 하드웨어, 소프트웨어 또는 펌웨어로 구성된 유닛을 포함하 며, 예를 들면, 로직, 논리 블록, 부품, 또는 회로 등의 용어와 상호 호환적으로 사용될 수 있다. \"부\" 또는 \" 모듈\"은, 일체로 구성된 부품 또는 하나 또는 그 이상의 기능을 수행하는 최소 단위 또는 그 일부가 될 수 있다. 예를 들면, 모듈은 ASIC(application-specific integrated circuit)으로 구성될 수 있다. 본 개시의 다양한 실시 예들은 기기(machine)(예: 컴퓨터)로 읽을 수 있는 저장 매체(machine-readable storage media에 저장된 명령어를 포함하는 소프트웨어로 구현될 수 있다. 기기는, 저장 매체로부터 저장된 명 령어를 호출하고, 호출된 명령어에 따라 동작이 가능한 장치로서, 개시된 실시 예들에 따른 전자 장치를 포함할 수 있다. 명령이 프로세서에 의해 실행될 경우, 프로세서가 직접, 또는 상기 프로세서의 제어 하에 다른 구성요 소들을 이용하여 상기 명령에 해당하는 기능을 수행할 수 있다. 명령은 컴파일러 또는 인터프리터에 의해 생성 또는 실행되는 코드를 포함할 수 있다. 기기로 읽을 수 있는 저장매체는, 비일시적(non-transitory) 저장매체의 형태로 제공될 수 있다. 여기서, '비일시적'은 저장매체가 신호(signal)를 포함하지 않으며 실재(tangible)한다 는 것을 의미할 뿐 데이터가 저장매체에 반영구적 또는 임시적으로 저장됨을 구분하지 않는다. 다양한 실시 예들에 따른 구성 요소(예: 모듈 또는 프로그램) 각각은 단수 또는 복수의 개체로 구성될 수 있으 며, 전술한 해당 서브 구성 요소들 중 일부 서브 구성 요소가 생략되거나, 또는 다른 서브 구성 요소가 다양한 실시 예에 더 포함될 수 있다. 대체적으로 또는 추가적으로, 일부 구성 요소들(예: 모듈 또는 프로그램)은 하나 의 개체로 통합되어, 통합되기 이전의 각각의 해당 구성 요소에 의해 수행되는 기능을 동일 또는 유사하게 수행 할 수 있다. 다양한 실시 예들에 따른, 모듈, 프로그램 또는 다른 구성 요소에 의해 수행되는 동작들은 순차적, 병렬적, 반복적 또는 휴리스틱하게 실행되거나, 적어도 일부 동작이 다른 순서로 실행되거나, 생략되거나, 또는다른 동작이 추가될 수 있다."}
{"patent_id": "10-2020-0010298", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 개시의 일 실시 예에 따른 로봇의 동작을 개략적으로 설명하기 위한 도면이다. 도 2는 본 개시의 일 실시 예에 따른 로봇의 구성을 간략히 도시한 블록도이다. 도 3은 본 개시의 일 실시 예에 따른 로봇의 구성을 상세히 도시한 블록도이다. 도 4는 본 개시의 일 실시 예에 따른 로봇 시스템을 설명하기 위한 도면이다. 도 5는 본 개시의 일 실시 예에 따른 외부 장치의 구성을 도시한 블록도이다. 도 6은 본 개시의 일 실시 예에 따른 이격되어 배치된 외부 장치를 설명하기 위한 도면이다. 도 7은 본 개시의 일 실시 예에 따른 외부 장치에 포함된 센서를 설명하기 위한 도면이다. 도 8은 본 개시의 일 실시 예 따른 로봇의 제어 방법을 설명하기 위한 순서도이다."}
