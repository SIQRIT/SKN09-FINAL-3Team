{"patent_id": "10-2018-0037159", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2019-0119205", "출원번호": "10-2018-0037159", "발명의 명칭": "전자 장치 및 그 제어 방법", "출원인": "삼성전자주식회사", "발명자": "강성호"}}
{"patent_id": "10-2018-0037159", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "전자 장치의 제어 방법에 있어서,현재 프레임을 입력받는 단계;이전 프레임과 상기 현재 프레임을 바탕으로 상기 현재 프레임 중 움직임이 있는 영역을 판단하는 단계;상기 움직임이 있는 영역에 기초하여 상기 현재 프레임을 인공지능 학습 모델에 입력하여 상기 현재 프레임에포함된 적어도 하나의 오브젝트에 대한 정보를 획득하는 단계; 및상기 획득된 적어도 하나의 오브젝트에 대한 정보를 이용하여 상기 움직임이 있는 영역에 포함된 오브젝트를 판단하는 단계;를 포함하는 제어 방법."}
{"patent_id": "10-2018-0037159", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1 항에 있어서,상기 움직임이 있는 영역을 판단하는 단계는,상기 이전 프레임의 픽셀값과 상기 현재 프레임의 픽셀값을 비교하는 단계; 및상기 비교 결과, 픽셀값의 차이가 기설정된 임계값을 초과하는 영역을 움직임이 있는 영역으로 판단하는 단계;를 포함하는 것을 특징으로 하는 제어 방법."}
{"patent_id": "10-2018-0037159", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 2 항에 있어서,상기 움직임이 있는 영역을 판단하는 단계는,상기 움직임이 있는 영역으로 판단된 영역에 대한 좌표값을 저장하는 단계;를 더 포함하는 것을 특징으로 하는 제어 방법."}
{"patent_id": "10-2018-0037159", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 2 항에 있어서,상기 획득하는 단계는,상기 픽셀값의 차이가 상기 기설정된 임계값 이하인 영역을 리드(read)하고, 나머지 영역을 스킵하도록 상기 현재 프레임을 상기 인공지능 학습 모델에 입력하는 것을 특징으로 하는 제어 방법."}
{"patent_id": "10-2018-0037159", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제 3 항에 있어서,상기 획득하는 단계는,다음 프레임이 입력되면, 상기 저장된 좌표값에 기초하여 상기 다음 프레임에서 움직임이 있는 영역을 상기 인공지능 학습 모델에 입력하여 상기 다음 프레임에 포함된 오브젝트에 대한 정보를 획득하는 것을 특징으로 하는제어 방법."}
{"patent_id": "10-2018-0037159", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "공개특허 10-2019-0119205-3-제 1 항에 있어서,상기 오브젝트를 판단하는 단계는,상기 현재 프레임을 상기 인공지능 학습 모델에 입력하여 상기 현재 프레임에 포함된 적어도 하나의 오브젝트에대한 특징값을 획득하고,상기 획득된 적어도 하나의 특징값 중 상기 움직임이 있는 영역 내의 특징값을 바탕으로 오브젝트를 판단하는것을 특징으로 하는 제어 방법."}
{"patent_id": "10-2018-0037159", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제 6 항에 있어서,상기 오브젝트를 판단하는 단계는,CNN(Convolutinal Neural Netwok) 알고리즘을 통해 상기 특징값을 획득하는 것을 특징으로 하는 제어 방법."}
{"patent_id": "10-2018-0037159", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제 1 항에 있어서,상기 판단하는 단계는,입력된 복수의 프레임 중 최초 입력된 프레임을 제외한 나머지 프레임에서 움직임이 있는 영역을 판단하는 것을특징으로 하는 제어 방법."}
{"patent_id": "10-2018-0037159", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "전자 장치에 있어서,입력부; 및상기 입력부를 통해 입력된 현재 프레임과 이전 프레임을 바탕으로 상기 현재 프레임 중 움직임이 있는 영역을판단하고, 상기 움직이 있는 영역에 기초하여 상기 현재 프레임을 인공지능 학습 모델에 입력하여 상기 현재 프레임에 포함된 적어도 하나의 오브젝트에 대한 정보를 획득하며,상기 획득된 적어도 하나의 오브젝트에 대한 정보를 이용하여 상기 움직임이 있는 영역에 포함된 오브젝트를 판단하는 프로세서;를 포함하는 전자 장치."}
{"patent_id": "10-2018-0037159", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제 9 항에 있어서,상기 프로세서는,상기 이전 프레임의 픽셀값과 상기 현재 프레임의 픽셀값을 비교하여, 픽셀값의 차이가 기설정된 임계값을 초과하는 영역을 움직임이 있는 영역으로 판단하는 것을 특징으로 하는 전자 장치."}
{"patent_id": "10-2018-0037159", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제 10 항에 있어서,저장부;를 더 포함하며,상기 프로세서는,상기 움직임이 있는 영역으로 판단된 영역에 대한 좌표값을 상기 저장부에 저장하는 것을 특징으로 하는 전자장치."}
{"patent_id": "10-2018-0037159", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "공개특허 10-2019-0119205-4-제 10 항에 있어서,상기 프로세서는,상기 픽셀값의 차이가 상기 기설정된 임계값 이하인 영역을 리드(read)하고, 나머지 영역을 스킵하도록 상기 현재 프레임을 상기 인공지능 학습 모델에 입력하는 것을 특징으로 하는 전자 장치."}
{"patent_id": "10-2018-0037159", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제 11 항에 있어서,상기 프로세서는,상기 입력부를 통해 다음 프레임이 입력되면, 상기 저장된 좌표값에 기초하여 상기 다음 프레임에서 움직임이있는 영역을 상기 인공지능 학습 모델에 입력하여 상기 다음 프레임에 포함된 오브젝트에 대한 정보를 획득하는것을 특징으로 하는 전자 장치."}
{"patent_id": "10-2018-0037159", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제 9 항에 있어서,상기 프로세서는,상기 현재 프레임을 상기 인공지능 학습 모델에 입력하여 상기 현재 프레임에 포함된 적어도 하나의 오브젝트에대한 특징값을 획득하고,상기 획득된 적어도 하나의 특징값 중 상기 움직임이 있는 영역 내의 특징값을 바탕으로 오브젝트를 판단하는것을 특징으로 하는 전자 장치."}
{"patent_id": "10-2018-0037159", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제 14 항에 있어서,상기 인공지능 학습 모델은,CNN(Convolutinal Neural Netwok) 알고리즘을 통해 상기 특징값을 획득하는 것을 특징으로 하는 전자 장치."}
{"patent_id": "10-2018-0037159", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제 9 항에 있어서,상기 프로세서는,입력된 복수의 프레임 중 최초 입력된 프레임을 제외한 나머지 프레임에서 움직임이 있는 영역을 판단하는 것을특징으로 하는 전자 장치."}
{"patent_id": "10-2018-0037159", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "전자 장치 및 그 제어 방법이 개시된다. 본 발명에 따른 전자 장치의 제어 방법은 현재 프레임을 입력받는 단계, 이전 프레임과 현재 프레임을 바탕으로 현재 프레임 중 움직임이 있는 영역을 판단하는 단계, 움직임이 있 는 영역에 기초하여 현재 프레임을 인공지능 학습 모델에 입력하여 현재 프레임에 포함된 적어도 하나의 오브젝 트에 대한 정보를 획득하는 단계 및 획득된 적어도 하나의 오브젝트에 대한 정보를 이용하여 움직임이 있는 영역 에 포함된 오브젝트를 판단하는 단계를 포함한다. 이에 따라, 전자 장치는 촬영된 영상을 구성하는 프레임에 포 함된 오브젝트를 보다 신속하게 판단할 수 있다."}
{"patent_id": "10-2018-0037159", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 전자 장치 및 그 제어 방법에 관한 것으로써, 보다 상세하게는 촬영된 영상 내에 포함된 오브젝트를 판단하기 위한 전자 장치 및 그 제어 방법에 관한 기술이다."}
{"patent_id": "10-2018-0037159", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "근래에는 인간 수준의 지능을 구현하는 인공 지능 시스템이 다양한 분야에서 이용되고 있다. 인공 지능 시스템 은 기존의 룰(rule) 기반 스마트 시스템과 달리 기계가 스스로 학습하고 판단하며 똑똑해지는 시스템이다. 인공 지능 시스템은 사용할수록 인식률이 향상되고 사용자 취향을 보다 정확하게 이해할 수 있게 되어, 기존 룰 기반 스마트 시스템은 점차 딥러닝 기반 인공 지능 시스템으로 대체되고 있다. 인공 지능 기술은 기계학습(예로, 딥러닝) 및 기계학습을 활용한 요소 기술들로 구성된다. 기계학습은 입력 데이터들의 특징을 스스로 분류/학습하는 알고리즘 기술이며, 요소기술은 딥러닝 등의 기계학 습 알고리즘을 활용하여 인간 두뇌의 인지, 판단 등의 기능을 모사하는 기술로서, 언어적 이해, 시각적 이해, 추론/예측, 지식 표현, 동작 제어 등의 기술 분야로 구성된다. 인공 지능 기술이 응용되는 다양한 분야는 다음과 같다. 언어적 이해는 인간의 언어/문자를 인식하고 응용/처리 하는 기술로서, 자연어 처리, 기계 번역, 대화시스템, 질의 응답, 음성 인식/합성 등을 포함한다. 시각적 이해 는 사물을 인간의 시각처럼 인식하여 처리하는 기술로서, 오브젝트 인식, 오브젝트 추적, 영상 검색, 사람 인식, 장면 이해, 공간 이해, 영상 개선 등을 포함한다. 추론 예측은 정보를 판단하여 논리적으로 추론하고 예 측하는 기술로서, 지식/확률 기반 추론, 최적화 예측, 선호 기반 계획, 추천 등을 포함한다. 지식 표현은 인간 의 경험정보를 지식데이터로 자동화 처리하는 기술로서, 지식 구축(데이터 생성/분류), 지식 관리(데이터 활용) 등을 포함한다. 동작 제어는 차량의 자율 주행, 로봇의 움직임을 제어하는 기술로서, 움직임 제어(항법, 충돌, 주행), 조작 제어(행동 제어) 등을 포함한다. 한편, 근래에는 자율 주행이 가능한 차량에 대한 기술 개발이 진행중에 있다. 자율 주행이란 사용자의 조작 없 이 차량이 자율 주행하는 것이다. 구체적으로, 차량 내에 탑재된 전자 장치는 차량의 주변을 촬영하고, 촬영된 영상을 분석하여 차량 주변에 있는 건물, 신호등, 주변 차량, 사람 등의 다양한 오브젝트를 판단한다. 이후, 전자 장치는 판단된 오브젝트를 고려 하여 차량이 자율 주행하도록 제어한다. 이 같은 차량의 자율 주행이 원활하게 이루어지기 위해서는 차량 주변에 있는 오브젝트를 신속하게 판단해야 한 다. 그러나, 자율 주행 중인 차량의 속도 및 차량의 주변에 사람, 주변 차량 등과 같은 이동 가능한 오브젝트가 존 재하는 경우, 차량 주변에 있는 오브젝트를 보다 신속하게 검출하지 못하는 문제가 있다. 본 발명은 상술한 필요성에 의해 안출된 것으로, 본 발명의 목적은 전자 장치에서 촬영된 영상에 포함된 적어도 하나의 오브젝트를 보다 신속하게 인식하도록 함을 목적으로 한다. 나아가, 본 발명은 전자 장치를 통해 촬영된 영상에 포함된 오브젝트를 보다 신속하게 인식하여 차량의 자율 주 행이 보다 원활하게 이루어지도록 함을 목적으로 한다. 이상과 같은 목적을 달성하기 위한 본 발명의 일 실시예에 따른 전자 장치의 제어 방법은 현재 프레임을 입력받 는 단계, 이전 프레임과 상기 현재 프레임을 바탕으로 상기 현재 프레임 중 움직임이 있는 영역을 판단하는 단 계, 상기 움직임이 있는 영역에 기초하여 상기 현재 프레임을 인공지능 학습 모델에 입력하여 상기 현재 프레임 에 포함된 적어도 하나의 오브젝트에 대한 정보를 획득하는 단계 및 상기 획득된 적어도 하나의 오브젝트에 대 한 정보를 이용하여 상기 움직임이 있는 영역에 포함된 오브젝트를 판단하는 단계를 포함한다. 그리고, 상기 움직임이 있는 영역을 판단하는 단계는, 상기 이전 프레임의 픽셀값과 상기 현재 프레임의 픽셀값 을 비교하는 단계 및 상기 비교 결과, 픽셀값의 차이가 기설정된 임계값을 초과하는 영역을 움직임이 있는 영역 으로 판단하는 단계를 포함할 수 있다. 또한, 상기 움직임이 있는 영역을 판단하는 단계는, 상기 움직임이 있는 영역으로 판단된 영역에 대한 좌표값을 저장하는 단계를 더 포함할 수 있다. 그리고, 상기 획득하는 단계는, 상기 픽셀값의 차이가 상기 기설정된 임계값 이하인 영역을 리드(read)하고, 나 머지 영역을 스킵하도록 상기 현재 프레임을 상기 인공지능 학습 모델에 입력할 수 있다. 또한, 상기 획득하는 단계는, 다음 프레임이 입력되면, 상기 저장된 좌표값에 기초하여 상기 다음 프레임에서 움직임이 있는 영역을 상기 인공지능 학습 모델에 입력하여 상기 다음 프레임에 포함된 오브젝트에 대한 정보를 획득할 수 있다. 그리고, 상기 오브젝트를 판단하는 단계는, 상기 현재 프레임을 상기 인공지능 학습 모델에 입력하여 상기 현재 프레임에 포함된 적어도 하나의 오브젝트에 대한 특징값을 획득하고, 상기 획득된 적어도 하나의 특징값 중 상 기 움직임이 있는 영역 내의 특징값을 바탕으로 오브젝트를 판단할 수 있다. 또한, 상기 오브젝트를 판단하는 단계는, CNN(Convolutinal Neural Netwok) 알고리즘을 통해 상기 특징값을 획 득할 수 있다. 그리고, 상기 판단하는 단계는, 입력된 복수의 프레임 중 최초 입력된 프레임을 제외한 나머지 프레임에서 움직 임이 있는 영역을 판단할 수 있다. 한편, 본 발명의 또다른 실시 예에 따르면, 전자 장치는, 입력부 및 상기 입력부를 통해 입력된 현재 프레임과 이전 프레임을 바탕으로 상기 현재 프레임 중 움직임이 있는 영역을 판단하고, 상기 움직이 있는 영역에 기초하 여 상기 현재 프레임을 인공지능 학습 모델에 입력하여 상기 현재 프레임에 포함된 적어도 하나의 오브젝트에 대한 정보를 획득하며, 상기 획득된 적어도 하나의 오브젝트에 대한 정보를 이용하여 상기 움직임이 있는 영역 에 포함된 오브젝트를 판단하는 프로세서를 포함한다. 그리고, 상기 프로세서는, 상기 이전 프레임의 픽셀값과 상기 현재 프레임의 픽셀값을 비교하여, 픽셀값의 차이 가 기설정된 임계값을 초과하는 영역을 움직임이 있는 영역으로 판단할 수 있다. 또한, 저장부를 더 포함하며, 상기 프로세서는, 상기 움직임이 있는 영역으로 판단된 영역에 대한 좌표값을 상 기 저장부에 저장할 수 있다. 그리고, 상기 프로세서는, 상기 픽셀값의 차이가 상기 기설정된 임계값 이하인 영역을 리드(read)하고, 나머지 영역을 스킵하도록 상기 현재 프레임을 상기 인공지능 학습 모델에 입력할 수 있다. 또한, 상기 프로세서는, 상기 입력부를 통해 다음 프레임이 입력되면, 상기 저장된 좌표값에 기초하여 상기 다 음 프레임에서 움직임이 있는 영역을 상기 인공지능 학습 모델에 입력하여 상기 다음 프레임에 포함된 오브젝트 에 대한 정보를 획득할 수 있다. 그리고, 상기 프로세서는, 상기 현재 프레임을 상기 인공지능 학습 모델에 입력하여 상기 현재 프레임에 포함된 적어도 하나의 오브젝트에 대한 특징값을 획득하고, 상기 획득된 적어도 하나의 특징값 중 상기 움직임이 있는 영역 내의 특징값을 바탕으로 오브젝트를 판단할 수 있다. 또한, 상기 인공지능 학습 모델은, CNN(Convolutinal Neural Netwok) 알고리즘을 통해 상기 특징값을 획득할 수 있다. 그리고, 상기 프로세서는, 입력된 복수의 프레임 중 최초 입력된 프레임을 제외한 나머지 프레임에서 움직임이 있는 영역을 판단할 수 있다. 이상과 같이, 본 발명에 따르면, 전자 장치는 촬영된 영상을 구성하는 프레임에서 움직임이 있는 영역을 판단하 고, 판단된 움직임이 있는 영역에 포함된 오브젝트를 판단함으로써, 촬영된 영상에 포함된 적어도 하나의 오브 젝트를 보다 신속하게 인식할 수 있다."}
{"patent_id": "10-2018-0037159", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "이하, 본 문서의 다양한 실시 예가 첨부된 도면을 참조하여 기재된다. 그러나, 이는 본 문서에 기재된 기술을 특정한 실시 형태에 대해 한정하려는 것이 아니며, 본 문서의 실시 예의 다양한 변경(modifications), 균등물 (equivalents), 및/또는 대체물(alternatives)을 포함하는 것으로 이해되어야 한다. 도면의 설명과 관련하여, 유사한 구성요소에 대해서는 유사한 참조 부호가 사용될 수 있다. 본 문서에서, \"가진다,\" \"가질 수 있다,\" \"포함한다,\" 또는 \"포함할 수 있다\" 등의 표현은 해당 특징(예: 수치, 기능, 동작, 또는 부품 등의 구성요소)의 존재를 가리키며, 추가적인 특징의 존재를 배제하지 않는다. 본 문서에서, \"A 또는 B,\" \"A 또는/및 B 중 적어도 하나,\" 또는 \"A 또는/및 B 중 하나 또는 그 이상\"등의 표현 은 함께 나열된 항목들의 모든 가능한 조합을 포함할 수 있다. 예를 들면, \"A 또는 B,\" \"A 및 B 중 적어도 하나,\" 또는 \"A 또는 B 중 적어도 하나\"는, 적어도 하나의 A를 포함, 적어도 하나의 B를 포함, 또는 적어도 하나의 A 및 적어도 하나의 B 모두를 포함하는 경우를 모두 지칭할 수 있다. 본 문서에서 사용된 \"제1,\" \"제2,\" \"첫째,\" 또는 \"둘째,\"등의 표현들은 다양한 구성요소들을, 순서 및/또는 중 요도에 상관없이 수식할 수 있고, 한 구성요소를 다른 구성요소와 구분하기 위해 사용될 뿐 해당 구성요소들을 한정하지 않는다. 어떤 구성요소(예: 제1 구성요소)가 다른 구성요소(예: 제2 구성요소)에 \"(기능적으로 또는 통신적으로) 연결되 어((operatively or communicatively) coupled with/to)\" 있다거나 \"접속되어(connected to)\" 있다고 언급된 때에는, 상기 어떤 구성요소가 상기 다른 구성요소에 직접적으로 연결되거나, 다른 구성요소(예: 제3 구성요 소)를 통하여 연결될 수 있다고 이해되어야 할 것이다. 반면에, 어떤 구성요소(예: 제1 구성요소)가 다른 구성 요소(예: 제2 구성요소)에 \"직접 연결되어\" 있다거나 \"직접 접속되어\" 있다고 언급된 때에는, 상기 어떤 구성요 소와 상기 다른 구성요소 사이에 다른 구성요소(예: 제 3 구성요소)가 존재하지 않는 것으로 이해될 수 있다. 본 문서에서 사용된 표현 \"~하도록 구성된(또는 설정된)(configured to)\"은 상황에 따라, 예를 들면, \"~에 적합 한(suitable for),\" \"~하는 능력을 가지는(having the capacity to),\" \"~하도록 설계된(designed to),\" \"~하도 록 변경된(adapted to),\" \"~하도록 만들어진(made to),\" 또는 \"~를 할 수 있는(capable of)\"과 바꾸어 사용될 수 있다. 용어 \"~하도록 구성된(또는 설정된)\"은 하드웨어적으로 \"특별히 설계된(specifically designed to)\" 것만을 반드시 의미하지 않을 수 있다. 대신, 어떤 상황에서는, \"~하도록 구성된 장치\"라는 표현은, 그 장치가 다른 장치 또는 부품들과 함께 \"~할 수 있는\" 것을 의미할 수 있다. 예를 들면, 문구 \"A, B, 및 C를 수행하도록 구성된(또는 설정된) 부프로세서\"는 해당 동작을 수행하기 위한 전용 프로세서(예: 임베디드 프로세서), 또는 메모리 장치에 저장된 하나 이상의 소프트웨어 프로그램들을 실행함으로써, 해당 동작들을 수행할 수 있는 범용 프로세서(generic-purpose processor)(예: CPU 또는 application processor)를 의미할 수 있다. 본 문서의 다양한 실시예들에 따른 전자 장치는, 예를 들면, 스마트폰, 태블릿 PC, 이동 전화기, 영상 전화기, 전자책 리더기, 데스크탑 PC, 랩탑 PC, 넷북 컴퓨터, 워크스테이션, 서버, PDA, PMP(portable multimedia player), MP3 플레이어, 의료기기, 카메라, 또는 웨어러블 장치 중 적어도 하나를 포함할 수 있다. 웨어러블 장 치는 액세서리형(예: 시계, 반지, 팔찌, 발찌, 목걸이, 안경, 콘택트 렌즈, 또는 머리 착용형 장치(head- mounted-device(HMD)), 직물 또는 의류 일체형(예: 전자 의복), 신체 부착형(예: 스킨 패드 또는 문신), 또는 생체 이식형 회로 중 적어도 하나를 포함할 수 있다. 어떤 실시예들에서, 전자 장치는, 예를 들면, 텔레비전, DVD(digital video disk) 플레이어, 오디오, 냉장고, 에어컨, 청소기, 오븐, 전자레인지, 세탁기, 공기 청정기, 셋톱 박스, 홈 오토매이션 컨트롤 패널, 보안 컨트롤 패널, 미디어 박스(예: 삼성 HomeSyncTM, 애플TVTM, 또는 구글 TVTM), 게임 콘솔(예: XboxTM, PlayStationTM), 전자 사전, 전자 키, 캠코더, 또는 전자 액자 중 적어도 하나를 포함할 수 있다. 다른 실시예에서, 전자 장치는, 각종 의료기기(예: 각종 휴대용 의료측정기기(혈당 측정기, 심박 측정기, 혈압 측정기, 또는 체온 측정기 등), MRA(magnetic resonance angiography), MRI(magnetic resonance imaging), CT(computed tomography), 촬영기, 또는 초음파기 등), 네비게이션 장치, 위성 항법 시스템(GNSS(global navigation satellite system)), EDR(event data recorder), FDR(flight data recorder), 자동차 인포테인먼 트 장치, 선박용 전자 장비(예: 선박용 항법 장치, 자이로 콤파스 등), 항공 전자기기(avionics), 보안 기기, 차량용 헤드 유닛(head unit), 산업용 또는 가정용 로봇, 드론(drone), 금융 기관의 ATM, 상점의 POS(point ofsales), 또는 사물 인터넷 장치 (예: 전구, 각종 센서, 스프링클러 장치, 화재 경보기, 온도조절기, 가로등, 토 스터, 운동기구, 온수탱크, 히터, 보일러 등) 중 적어도 하나를 포함할 수 있다. 본 문서에서, 사용자라는 용어는 전자 장치를 사용하는 사람 또는 전자 장치를 사용하는 장치(예: 인공지능 전 자 장치)를 지칭할 수 있다. 도 1은 본 발명의 일 실시예에 따른 전자 장치의 개략적인 블록도이다. 도 1에 도시된 바와 같이, 전자 장치는 실시간으로 촬영된 영상으로부터 오브젝트를 검출하고, 검출된 오 브젝트의 위치, 타입 등을 판단한다. 실시예로써, 전자 장치는 자율 주행이 가능한 차량 내에 탑재되어 차량의 주변 환경을 실시간으로 촬영하 고, 촬영된 영상을 분석하여 사람, 건물 등의 다양한 오브젝트를 검출한다. 따라서, 차량 내에 탑재되어 차량 의 자율 주행을 수행하는 제어 장치(미도시)는 전자 장치를 통해 검출된 오브젝트 정보에 기초하여 차량의 자율 주행을 수행할 수 있다. 이 같은 전자 장치는 입력부 및 프로세서를 포함한다. 입력부는 카메라(미도시)를 통해 촬영된 영상을 구성하는 복수의 프레임을 입력받는다. 프로세서는 입력부를 통해 입력된 복수의 프레임을 분석하여 움직임이 있는 영역에 포함된 적어도 하 나의 오브젝트를 판단한다. 실시예에 따라, 프로세서는 입력부를 통해 입력된 복수의 프레임 중 최초 입력된 프레임을 제외한 나 머지 프레임에서 움직임이 있는 영역을 판단할 수 있다. 구체적으로, 프로세서는 입력부를 통해 입력된 현재 프레임이 최초 프레임인지 여부를 판단한다. 판 단 결과, 입력된 현재 프레임이 최초 입력된 프레임(시작 프레임이라 함)이면, 입력된 시작 프레임의 전체 영역 을 리드(Read)하도록 시작 프레임을 인공지능 학습 모델에 입력하고, 인공지능 학습 모델을 통해 시작 프레임에 포함된 모든 오브젝트에 대한 정보를 획득한다. 한편, 프로세서는 입력된 현재 프레임이 시작 프레임이 아니면, 현재 프레임(이하 제2 프레임이라 함)과, 제2 프레임이 입력되기 전에 입력된 이전 프레임(이하 제1 프레임이라 함)을 바탕으로 제2 프레임 중 움직임이 있는 영역을 판단한다. 실시예에 따라, 프로세서는 제1 프레임의 픽셀값과 제2 프레임의 픽셀값을 비교하여, 픽셀값의 차이가 기 설정된 임계값을 초과하는 영역을 제2 프레임 내에서 움직임이 있는 영역으로 판단할 수 있다. 이 같이, 제2 프레임 내에서 움직임이 있는 영역이 판단되면, 프로세서는 후술할 저장부에 움직임이 있는 영역으로 판단된 영역에 대한 좌표값을 저장할 수 있다. 한편, 프로세서는 제2 프레임 내에서 움직임이 있는 영역이 판단되면, 제2 프레임을 인공지능 학습 모델에 입력하여 제2 프레임에 포함된 적어도 하나의 오브젝트에 대한 정보를 획득한다. 여기서, 오브젝트에 대한 정 보는 오브젝트의 타입(종류)를 식별하기 위한 특징값 및 오브젝트가 위치하는 좌표값 중 적어도 하나를 포함할 수 있다. 구체적으로, 프로세서는 제2 프레임 내에서 움직임이 있는 영역이 판단되면, 제2 프레임 내에서 움직임이 있는 영역으로 판단된 영역을 리드(read)하고, 나머지 영역을 스킵하도록 제2 프레임을 상기 인공지능 학습 모 델에 입력한다. 이에 따라, 프로세서는 인공지능 학습 모델을 통해 제2 프레임 내에서 움직임이 있는 영역에 포함된 오브 젝트에 대한 정보를 획득할 수 있다. 이 같은 적어도 하나의 오브젝트에 대한 정보가 획득되면, 프로세서는 획득된 적어도 하나의 오브젝트에 대한 정보를 이용하여 제2 프레임 내에서 움직임이 있는 영역에 포함된 오브젝트를 판단한다. 실시예에 따라, 프로세서는 제2 프레임을 인공지능 학습 모델에 입력하여 제2 프레임에 포함된 적어도 하 나의 오브젝트에 대한 특징값을 획득한다. 여기서, 인공지능 학습 모델은 기정의된 CNN(Convolutinal Neural Netwok) 알고리즘를 통해 제2 프레임에 포함 된 적어도 하나의 오브젝트에 대한 특징값을 획득할 수 있다. 이 같이, 인공지능 학습 모델은 후술할 저장부에 저장될 수 있으며, 구체적인 설명은 하기에서 상세히 설 명하도록 한다. 한편, 프로세서는 인공지능 학습 모델을 통해 제2 프레임에 포함된 적어도 하나의 오브젝트에 대한 특징값 이 획득되면, 획득된 적어도 하나의 특징값 중 제2 프레임에서 움직임이 있는 영역 내의 특징값을 바탕으로 움 직임이 있는 영역에 포함된 오브젝트를 판단할 수 있다. 한편, 프로세서는 입력부를 통해 다음 프레임(이하 제3 프레임이라 함)이 입력되면, 다음과 같은 실 시예를 통해 제3 프레임에서 움직임이 있는 영역에 포함된 오브젝트에 대한 정보를 획득할 수 있다. 일 실시예에 따라, 프로세서는 입력부를 통해 제3 프레임이 입력되면, 저장부에 기저장된 좌표 값에 기초하여 제3 프레임에서 움직임이 있는 영역을 인공지능 학습 모델에 입력하여 제3 프레임에 포함된 오브 젝트에 대한 정보를 획득할 수 있다. 구체적으로, 프로세서는 입력부를 통해 제3 프레임이 입력되면, 저장부에 기저장된 좌표값에 기 초하여 제3 프레임에서 움직임이 있는 영역을 판단한다. 이후, 프로세서는 전술한 바와 같이, 움직임이 있는 영역을 리드하고, 나머지 나머지 영역을 스킵하도록 제3 프레임을 인공지능 학습 모델에 입력한다. 이에 따라, 프로세서는 인공지능 학습 모델을 통해 제3 프레임 내에서 움직임이 있는 영역에 포함된 오브 젝트에 대한 정보를 획득할 수 있으며, 획득된 정보를 이용하여 제3 프레임 내에서 움직임이 있는 영역에 포함 된 오브젝트를 판단할 수 있다. 또다른 실시예에 따라, 프로세서는 입력부를 통해 제3 프레임이 입력되면, 전술한 바와 같이, 제3 프 레임이 입력되기 전에 입력된 제2 프레임의 픽셀값과 현재 입력된 제3 프레임의 픽셀값을 비교하여, 픽셀값 간 의 차이가 기설정된 임계값을 초과하는 영역을 움직임이 있는 영역으로 판단한다. 이후, 프로세서는 제3 프레임 내에서 움직임이 있는 영역으로 판단된 영역을 리드(read)하고, 나머지 영역 을 스킵하도록 제3 프레임을 인공지능 학습 모델에 입력한다. 이에 따라, 프로세서는 인공지능 학습 모델을 통해 제3 프레임 내에서 움직임이 있는 영역에 포함된 오브 젝트에 대한 정보가 획득되면, 획득된 정보를 이용하여 제3 프레임 내에서 움직임이 있는 영역에 포함된 오브젝 트를 판단할 수 있다. 이하에서는, 전술한 프로세서에서 입력된 제2 프레임에서 움직임이 있는 영역에 포함된 오브젝트를 판단하 는 동작에 대해서 보다 상세히 설명하도록 한다. 도 2는 본 발명의 일 실시예에 따른 프로세서의 세부 블록도이다. 도 2에 도시된 바와 같이, 프로세서는 버퍼, 비교부, 움직임 영역 획득부, 오브젝트 정보 획득부 및 오브젝트 판단부를 포함할 수 있다. 버퍼는 카메라를 통해 촬영된 영상을 구성하는 복수의 프레임이 입력되면, 입력된 순서로 복수의 프레임을 임시 저장한다. 실시예에 따라, 버퍼는 후술할 RAM과 같은 휘발성 메모리(Volatile Memory)로 구현될 수 있다. 이 같은 버퍼는 기저장된 복수의 프레임 중 최초 저장된 프레임을 후술할 오브젝트 정보 획득부로 전 달할 수 있다. 한편, 버퍼는 기저장된 복수의 프레임 중 최초 저장된 프레임을 제외한 나머지 프레임 중 기설정된 조건에 대응하는 프레임을 비교부로 전달한다. 비교부는 버퍼에서 전달된 프레임들을 비교한다. 구체적으로, 비교부는 버퍼를 통해 제1 프레임이 입력된 후 제2 프레임을 입력받을 수 있다. 이 같은 제1 및 제2 프레임이 입력되면, 비교부는 입력된 제2 프레임의 영역별 픽셀값과 이전 프레임인 제1 프레임의 영역별 픽셀값 간의 차이값을 획득한다. 이후, 비교부는 획득한 제1 및 제2 프레임 각각에 대응되는 영역별 픽셀값 간의 차이값과 기설정된 임계값 을 비교하여, 제2 프레임을 구성하는 복수의 영역 중 기설정된 임계값을 초과하는 영역을 움직임이 있는 영역으 로 판단한다. 이후, 비교부는 제2 프레임에서 판단된 움직임이 있는 영역에 대한 정보를 움직임 영역 획득부로 출 력한다. 움직임 영역 획득부는 제2 프레임에서 판단된 움직임이 있는 영역에 대한 좌표값을 획득한다. 이후, 움직 임 영역 획득부는 제2 프레임 내에서 움직임이 있는 영역에 대한 좌표값을 후술할 저장부에 저장한다. 한편, 비교부는 제2 프레임에서 움직임이 있는 영역이 판단되면, 이에 대한 결과값을 생성하여 오브젝트 정보 획득부로 출력한다. 여기서, 결과값은 제2 프레임에서 움직임이 있는 영역을 리드하고, 나머지 영역을 스킵하도록 하기 위한 값이 될 수 있다. 오브젝트 정보 획득부는 버퍼를 통해 입력된 프레임을 구성하는 각 영역을 리드하여 적어도 하나의 오브젝트에 대한 정보를 획득한다. 이 같은 오브젝트 정보 획득부는 비교부를 통해 제2 프레임에서 움직임이 있는 영역에 대한 결과값이 입력되면, 입력된 결과값에 기초하여 움직임이 있는 영역에 포함된 오브젝트에 대한 정보를 획득한다. 구체적으로, 오브젝트 정보 획득부는 비교부를 통해 제2 프레임에 서 움직임이 있는 영역에 대한 결 과값이 입력되면, 입력된 결과값을 인공지능 학습 모델에 입력한다. 이에 따라, 인공지능 학습 모델은 입력된 결과값에 기초하여 제2 프레임에서 움직임이 있는 영역만을 리드하여 연산을 수행하며, 오브젝트 정보 획득부는 인공지능 학습 모델을 통해 수행된 연산 결과에 기초하여 제2 프레임에서 움직임이 있는 영역 내에 포함된 오브젝트에 대한 정보를 출력할 수 있다. 오브젝트 판단부는 오브젝트 정보 획득부로부터 출력된 정보에 기초하여 프레임 내에 포함된 적어도 하나의 오브젝트를 판단한다. 특히, 오브젝트 판단부는 오브젝트 정보 획득부로부터 제2 프레임에서 움직임이 있는 영역에 포함된 오브젝트에 대한 정보가 입력되면, 입력된 오브젝트에 대한 정보와 저장부에 기저장된 제2 프레임의 움직 임이 있는 영역에 대한 좌표값을 이용하여 제2 프레임에서 움직임이 있는 영역에 포함된 오브젝트를 판단할 수 있다. 도 3은 본 발명의 일 실시예에 따른 프로세서에서 입력된 프레임 내에서 움직임 영역을 판단하는 예시도이며, 도 4는 본 발명의 일 실시예에 따른 프로세서에서 움직임 영역 내 포함된 오브젝트의 정보를 획득하는 예시도이 다. 도 3에 도시된 바와 같이, 프로세서는 영상을 구성하는 복수의 프레임 중 N 번째 프레임이 입력되면, 입력된 N 번째 프레임과 이전에 입력된 N-1 번째 프레임을 비교하여 N 번째 프레임에서 움직임 이 발생한 영역을 판단한다. 구체적으로, 프로세서는 전술한 비교부를 통해 입력된 N 번째 프레임에서 움직임이 발생한 영역 을 판단할 수 있다. 구체적으로, 비교부는 버퍼에 임시 저장된 복수의 프레임 중 N 번째 프레임이 입력되면, 이전에 입력된 N-1 번째 프레임의 픽셀값과 현재 입력된 N 번째 프레임의 픽셀값을 비교하여 두 픽셀값 간의 차이가 기설정된 임계값을 초과하는 영역을 N 번째 프레임에서 움직임이 있는 영역으로 판단한다. 이후, 비교부는 N +1 번째 프레임이 입력되면, 이전에 입력된 N 번째 프레임의 픽셀값과 현재 입력된 N +1 번째 프레임의 픽셀값을 비교하여 두 픽셀값 간의 차이가 기설정된 임계값을 초과하는 영역을 N + 1 번째 프레임에서 움직임이 있는 영역으로 판단한다. 도시된 바와 같이, N - 1, N, N + 1 프레임(310~330)에는 건물, 자동차, 신호등 등의 다양한 오브젝트를 포함할 수 있다. 이 같은 N - 1, N, N + 1 프레임(310~330) 각각에 포함된 복수의 오브젝트 중 이동 중인 자동차 관련 오브젝트가 위치하는 영역은 서로 상이할 수 있다. 따라서, 비교부는 현재 입력된 프레임과 이전에 입력된 프레임 간의 비교를 통해 현재 입력된 프레임 내에 서 자동차 관련 오브젝트가 위치하는 영역을 움직임이 발생한 영역으로 판단할 수 있다. 한편, 비교부는 현재 입력된 프레임 내에서 움직임이 있는 영역이 판단되면, 인공지능 학습 모델에서 해당 움직임이 있는 영역만을 리드하고 나머지 영역을 스킵하기 위한 값으로 변환하고, 변환된 결과값을 오브젝트 정보 획득부로 전달한다. 오브젝트 정보 획득부는 비교부로부터 현재 입력된 프레임 내에서 움직임이 있는 영역으로 판단된 영 역에 대한 결과값이 입력되면, 입력된 결과값을 인공지능 학습 모델에 입력한다. 이에 따라, 인공지능 학습 모델은 입력된 결과값에 기초하여 현재 입력된 프레임에서 움직임이 있는 영역만을 리드하여 연산을 수행한다. 따라서, 오브젝트 정보 획득부는 인공지능 학습 모델을 통해 수행된 연산 결 과에 기초하여 해당 움직임이 있는 영역 내에 포함된 오브젝트에 대한 정보를 출력할 수 있다. 도 4의 (a)에 도시된 바와 같이, 입력된 프레임 내에서 박스 친 영역은 움직임이 있는 영역이 될 수 있다. 따라서, 오브젝트 정보 획득부는 비교부를 통해 해당 프레임에서 움직임이 있는 영역에 대한 결 과값이 입력되면, 입력된 결과값을 인공지능 학습 모델에 입력한다. 이에 따라, 인공지능 학습 모델은 입력된 결과값에 기초하여 움직임이 있는 영역을 리드하여 연산을 수행하고, 나머지 영역을 스킵하여 연산을 수행하지 않는다. 이 같이, 인공지능 학습 모델을 통해 입력된 프레임 내에서 움직임이 있는 영역에 대한 연산 결과가 출력 되면, 도 4의 (b)에 도시된 바와 같이, 오브젝트 정보 회득부는 출력된 연산 결과에 기초하여 프레임 (410') 내에서 움직임이 있는 영역에 포함된 오브젝트에 대한 정보를 획득할 수 있다. 지금까지, 본 발명에 따른 전자 장치에서 촬영된 영상으로부터 오브젝트를 판단하는 동작에 대해서 구체적 으로 설명하였다. 이하에서는, 본 발명에 따른 전자 장치의 세부 구성에 대해서 상세히 설명하도록 한다. 도 5는 본 발명의 일 실시예에 따른 전자 장치의 세부 블록도이다. 전술한 바와 같이, 입력부는 촬영된 영상을 구성하는 복수의 프레임을 입력받을 뿐만 아니라, 다양한 사용 자 명령을 입력받아 프로세서로 전달할 수 있다. 이를 위해, 입력부는 마이크, 조작부, 터치 입력부 및 사용자 입력부를 포함할 수 있 다. 마이크는 사용자의 음성 명령을 입력받으며, 조작부는 각종 기능키, 숫자키, 특수키, 문자키 등을 구 비한 키패드(Key Pad)로 구현될 수 있다. 그리고, 터치 입력부는 후술할 디스플레이부가 터치 스크린 형태로 구현될 경우, 디스플레이부 와 상호 레어어 구조를 이루는 터치 패드로 구현될 수 있다. 이 경우, 터치 입력부는 디스플레이부 를 통해 디스플레이된 다양한 어플리케이션 관련 아이콘에 대한 선택 명령을 입력받을 수 있다. 사용자 입력부는 원격 제어 장치와 같은 적어도 하나의 주변 기기(미도시)로부터 전자 장치의 동작을 제어하기 위한 IR 신호 혹은 RF 신호를 입력받을 수 있다. 한편, 전자 장치는 전술한 입력부 및 프로세서 구성 외에 도 5에 도시된 바와 같이, 저장부 , 통신부, 촬영부, 감지부 및 출력부를 더 포함할 수 있다. 저장부는 전술한 바와 같이, 촬영된 영상을 구성하는 복수의 프레임에 포함된 적어도 하나의 오브젝트에 대한 정보를 획득하기 위한 인공지능 학습모델을 저장할 수 있다. 뿐만 아니라, 저장부는 전자 장치의 동작을 제어하기 위한 운영 프로그램을 더 저장할 수 있다. 여기서, 운용 프로그램은 전자 장치가 턴 온(Turn On)되는 경우, 저장부에서 읽혀지고, 컴파일되어 전자 장치의 각 구성을 동작시키는 프로그램이 될 수 있다. 이 같은 저장부는 후술할 롬(ROM), 램(RAM) 또는 전자 장치에 탈착/장착 가능한 메모리 카드(예, SD 카드, 메모리 스틱), 비휘발성 메모 리, 휘발성 메모리, 하드 디스크 드라이브(HDD) 또는 솔리드 스테이트 드라이브(SSD) 중 적어도 하나로 구현될 수 있다. 통신부는 스마트 TV, 스마트 폰, 태블릿 PC 등의 주변 기기(미도시), 컨텐츠 서버(미도시)와 데이터를 송 수신하기 위한 중계 단말 장치(미도시) 등과 데이터 통신을 수행한다. 특히, 통신부는 전술한 인공지능 모델이 별도의 인공지능 서버(미도시)에 저장된 경우, 촬영된 영상을 구성하는 복수의 프레임에 대한 데이터를 인공지능 서버(미도시)로 전송하여 복수의 프레임에 포함된 적어도 하나의 오브젝트에 대한 정보를 인공지능 서 버(미도시)로부터 수신할 수 있다.이 같은 통신부는 근거리 통신 모듈, 무선 랜 모듈 등의 무선 통신 모듈과, HDMI(High- Definition Multimedia Interface), USB(Universal Serial Bus), IEEE(Institute of Electrical and Eletronics Engineers) 1394 등의 유선 통신 모듈 중 적어도 하나를 포함하는 커넥터를 포함할 수 있다. 근거리 통신 모듈은 전자 장치와 근거리에 위치한 주변 기기, 인공지능 서버 등과 무선으로 근거리 통신을 수행하는 구성이다. 이 같은 근거리 통신 모듈은 블루투스(bluetooth)모듈, 적외선 통신(IrDA, infrared data association)모듈, NFC(Near Field Communication)모듈, 와이파이(WIFI)모듈, 지그비(Zigbee) 모듈 중 적어도 하나를 포함할 수 있다. 또한, 무선 통신 모듈은 IEEE 등과 같은 무선 통신 프로토콜에 따라 외부 네트워크에 연결되어 통신을 수 행하는 모듈이다. 이 밖에 무선 통신 모듈은 3G(3rd Generation), 3GPP(3rd Generation Partnership Project), LTE(Long Term Evoloution) 등과 같은 다양한 이동 통신 규격에 따라 이동 통신 망에 접속하여 통신 을 수행하는 이동 통신 모듈을 더 포함할 수도 있다. 이처럼 통신부는 상술한 다양한 근거리 통신 방식에 의해 구현될 수 있고, 필요에 따라 본 명세서에 언급 되지 않은 다른 통신 기술을 채용할 수 있다. 한편, 커넥터는 USB 2.0, USB 3.0, HDMI, IEEE 1394 등 다양한 소스 장치와의 인터페이스를 제공하는 구 성이다. 이 같은 커넥터는 프로세서의 제어 명령에 따라 커넥터에 연결된 유선 케이블을 통해 외부 서버(미도시)로부터 전송된 컨텐츠 데이터를 수신하거나, 기저장된 컨텐츠 데이터를 외부 기록 매체로 전 송할 수 있다. 또한, 커넥터는 커넥터와 물리적으로 연결된 유선 케이블을 통해 전원 소스로부터 전 원을 입력받을 수 있다. 촬영부는 카메라를 통해 영상을 촬영한다. 여기서, 촬영된 영상은 동영상 또는 정지 영상이 될 수 있다. 이 같은 촬영부는 촬영된 영상을 구성하는 복수의 프레임을 프로세서로 전달하거나 혹은 입력부(11 0)를 통해 프로세서로 전달할 수 있다. 감지부는 전자 장치의 모션을 감지한다. 이 같은 감지부는 가속도 센서, 지자기 센서 및 자이 로 센서 등을 포함할 수 있으며, 이 같은 다양한 센서를 이용하여 전자 장치의 모션을 감지할 수 있다. 가속도 센서(Accelerometer Sensor)는 이동하는 전자 장치의 가속도나 충격의 세기를 측정하는 센서로써, 스마트 폰, 테블릿 PC와 같은 전자 장치 뿐만 아니라, 자동차, 기차, 비행기 등과 같은 각종 운송 수단 및 로봇 등의 제어 시스템에 이용되는 필수적인 센서이다. 지자기 센서(Magnetic Sensor)는 지구 자기장을 이용하여 방위각을 탐지할 수 있는 전자 나침판으로써, 위치 추 적, 3D 영상 게임 등에 사용되거나, 스마트 폰, 무전기, GPS, PDA, 네비게이션 항법 장치 등에 사용되는 센서이 다. 자이로 센서(Gyroscope Sensor)는 기존의 가속도 센서에 각각 회전을 넣어 6축 방향을 인식하여 하여 좀더 세밀 하고 정밀한 동작을 인식할 수 있도록 도와주는 센서이다. 출력부는 촬영부를 통해 촬영된 영상을 포함하는 다양한 컨텐츠를 출력한다. 이 같은 출력부는 컨텐츠의 영상 데이터를 출력하는 디스플레이부 및 해당 컨텐츠의 오디오 데이터를 출력하는 오디오 출력 부를 포함할 수 있다. 컨텐츠의 영상 데이터를 출력하는 디스플레이부는 인공지능 학습 모델을 통해 출력된 결과값에 기초하여 촬영된 영상 내에 포함된 오브젝트에 대한 정보를 제공한다. 이 같은 디스플레이부는 저장부에 저장 된 복수의 어플리케이션 각각을 실행하기 위한 아이콘을 포함하는 실행 화면을 디스플레이하거나 혹은 전자 장 치의 동작을 제어하기 위한 다양한 UI 화면을 디스플레할 수 있다. 이 같은 디스플레이부는 액정 표시 장치(Liquid Crystal Display, LCD), 유기 전기 발광 다이오드 (Organic Light Emitting Display, OLED) 등으로 구현될 수 있다. 특히, 디스플레이부는 전술한 바와 같이, 사용자의 터치 명령을 입력받는 터치 입력부와 함께 상호 레이어 구조를 이루는 터치 스크린 형태로 구현될 수 있다. 오디오 출력부는 인공지능 학습 모델을 통해 출력된 결과값에 기초하여 촬영된 영상 내에 포함된 오브젝트 에 대한 정보를 오디오 형태로 출력한다. 뿐만 아니라, 오디오 출력부는 사용자가 요청한 컨텐츠에 포함된 오디오 데이터 혹은 각종 알림 음이나 음성 메시지를 출력할 수 있다. 한편, 전술한 프로세서는 전자 장치의 동작을 전반적으로 제어하거나, 혹은 전자 장치의 전반적 인 동작을 제어할 수 있도록 하는 처리 장치가 될 수 있다. 이 같은 프로세서는 CPU, ROM, RAM 및 GPU를 포함할 수 있으며, CPU, ROM, RAM 및 GPU는 버스를 통해 서로 연결될 수 있다. CPU는 저장부를 액세스하여, 저장부에 저장된 OS를 이용하여 부팅을 수행한다. 또한 CPU 는 저장부에 저장된 각종 프로그램, 컨텐츠, 데이터 등을 이용하여 다양한 동작을 수행한다. GPU는 아이콘, 이미지, 텍스트 등과 같은 다양한 객체를 포함하는 디스플레이 화면을 생성한다. 구체적으 로, GPU는 수신된 제어 명령에 기초하여 화면의 레이아웃에 따라 각 객체들이 표시될 좌표값, 형태, 크기, 컬러 등과 같은 속성값을 연산하고, 연상된 속성값에 기초하여 객체를 포함하는 다양한 레이아웃의 디스플레이 화면을 생성한다. ROM은 시스템 부팅을 위한 명령어 세트 등이 저장된다. 턴 온 명령이 입력되어 전원이 공급되면, CPU는 ROM에 저장된 명령어에 따라 저장부에 저장된 OS를 RAM에 복사하고, OS를 실행시켜 시스템을 부팅시킨다. 부팅이 완료되면, CPU는 저장부에 저장된 각종 프로그램을 RAM에 복사하 고, RAM에 복사된 프로그램을 실행시켜 각종 동작을 수행한다. 이 같은 프로세서는 전술한 각 구성들과 결합되어 단일칩 시스템(System-on-a-chip 또는 System on chip, SOC, SoC)으로 구현될 수 있다. 이하에서는, 본 발명에 따른 프로세서에서 인공지능 학습 모델을 업데이트하고 이용하기 위한 동작에 대해 서 상세히 설명하도록 한다. 도 6은 본 발명의 일 실시예에 따른 인공지능 학습모델을 업데이트하고 이용하는 전자 장치의 프로세서의 세부 블록도이다. 도 6에 도시된 바와 같이, 프로세서는 학습부 및 획득부를 더 포함할 수 있다. 도 6에 도시된 바와 같이, 프로세서는 학습부 및 획득부 중 적어도 하나를 포함할 수 있다. 도 6의 프로세서는 도 1 및 도 5의 전자 장치의 프로세서 또는 데이터 학습 서버(미도시)의 프로세 서에 대응될 수 있다. 학습부는 학습 데이터를 이용하여 전자 장치를 통해 촬영된 영상에 포함된 복수의 오브젝트를 인식하 기 위한 모델(이하 제1 모델이라 함)을 생성 또는 학습시킬 수 있다. 뿐만 아니라, 학습부는 사용자 음성에 대한 키워드를 획득하기 위한 모델(이하 제2 모델이라 함)을 생성 또는 학습시킬 수 있다. 이 같은 학습부는 수집된 학습 데이터를 이용하여 인식 기준을 갖는 학습된 모델 을 생성할 수 있다. 일 예로, 학습부는 전자 장치를 통해 촬영된 영상을 구성하는 복수의 프레임을 입력 데이터로 사용하 여 해당 프레임에 포함된 복수의 오브젝트에 대한 정보를 획득하기 위한 제1 모델을 생성, 학습 또는 갱신시킬 수 있다. 또한, 학습부는 복수의 오브젝트에 대한 정보, 사용자 정보 및 사용자 음성을 입력 데이터로 사용하여 사 용자 음성에 대응되는 키워드를 획득하기 위한 제2 모델을 생성, 학습 또는 갱신시킬 수 있다. 한편, 본 발명의 일 실시예에 다른 실시예에 따르면, 제1 모델 및 제2 모델은 서로 통합된 모델로 구현될 수 있 다. 즉, 통합된 모델은 촬영된 영상에 대한 입력 데이터 및 사용자 음성을 입력 데이터로 사용하여 사용자 음 성에 대응되는 키워드를 획득할 수 있다. 획득부는 소정의 데이터를 학습된 모델의 입력 데이터로 사용하여, 다양한 정보를 획득할 수 있다. 일 예로, 획득부는 촬영된 영상을 구성하는 복수의 프레임을 학습된 제1 모델의 입력 데이터로 사용하여 해당 영상을 구성하는 복수의 프레임에 포함된 복수의 오브젝트에 대한 정보를 획득(또는, 인식, 추정)할 수 있 다. 또한, 획득부는 복수의 오브젝트에 대한 정보, 사용자 정보 및 사용자 음성을 학습된 제2 모델의 입력 데 이터로 사용하여 복수의 오브젝트 중 사용자 음성에 대응되는 키워드를 획득(또는 추정, 추론, 인식)할 수 있다. 학습부의 적어도 일부 및 획득부의 적어도 일부는, 소프트웨어 모듈로 구현되거나 적어도 하나의 하 드웨어 칩 형태로 제작되어 전자 장치에 탑재될 수 있다. 예를 들어, 학습부 및 획득부 중 적어도 하나는 인공 지능(AI; artificial intelligence)을 위한 전용 하드웨어 칩 형태로 제작될 수도 있고, 또는 기존 의 범용 프로세서(예: CPU 또는 application processor) 또는 그래픽 전용 프로세서(예: GPU)의 일부로 제작되 어 전술한 각종 전자 장치에 탑재될 수도 있다. 이때, 인공 지능을 위한 전용 하드웨어 칩은 확률 연산에 특화 된 전용 프로세서로서, 기존의 범용 프로세서보다 병렬처리 성능이 높아 기계 학습과 같은 인공 지능 분야의 연 산 작업을 빠르게 처리할 수 있다. 학습부 및 획득부가 소프트웨어 모듈(또는, 인스트럭션(instruction) 포함하는 프로그램 모듈)로 구 현되는 경우, 소프트웨어 모듈은 컴퓨터로 읽을 수 있는 판독 가능한 비일시적 판독 가능 기록매체(non- transitory computer readable media)에 저장될 수 있다. 이 경우, 소프트웨어 모듈은 OS(Operating System) 에 의해 제공되거나, 소정의 애플리케이션에 의해 제공될 수 있다. 또는, 소프트웨어 모듈 중 일부는 OS(Operating System)에 의해 제공되고, 나머지 일부는 소정의 애플리케이션에 의해 제공될 수 있다. 이 경우, 학습부 및 획득부는 하나의 전자 장치에 탑재될 수도 있으며, 또는 별개의 전자 장 치들에 각각 탑재될 수도 있다. 예를 들어, 학습부 및 획득부 중 하나는 전자 장치에 포함되고, 나머지 하나는 외부의 서버(미도시)에 포함될 수 있다. 또한, 학습부 및 획득부는 유선 또는 무선으로 통하여, 학습부가 구축한 모델 정보를 획득부로 제공할 수도 있고, 학습부로 입 력된 데이터가 추가 학습 데이터로서 학습부로 제공될 수도 있다. 도 7은 본 발명의 일 실시예에 따른 학습부 및 획득부의 세부 블록도이다. 도 7의 (a)에 도시된 바와 같이, 학습부는 학습 데이터 획득부 및 모델 학습부를 포함할 수 있 다. 또한, 학습부는 학습 데이터 전처리부, 학습 데이터 선택부 및 모델 평가부 중 적어 도 하나를 선택적으로 더 포함할 수 있다. 학습 데이터 획득부는 제1 모델 및 제2 모델에 필요한 학습 데이터를 획득할 수 있다. 실시예에 따라, 학 습 데이터 획득부는 영상 데이터, 복수의 오브젝트에 대한 정보, 사용자 정보, 사용자 음성 등을 학습 데 이터로서 획득할 수 있다. 학습 데이터는 학습부 또는 학습부의 제조사가 수집 또는 테스트한 데이 터가 될 수도 있다. 모델 학습부는 학습 데이터를 이용하여, 영상을 구성하는 복수의 프레 임에 포함된 오브젝트를 어떻게 인 식할지에 관한 기준을 갖도록 학습시킬 수 있다. 예로, 모델 학습부는 학습 데이터 중 적어도 일부를 판 단 기준으로 이용하는 지도 학습(supervised learning)을 통하여, 인공지능 학습 모델을 학습시킬 수 있다. 또 는, 모델 학습부는, 예를 들어, 별다른 지도 없이 학습 데이터를 이용하여 스스로 학습함으로써, 상황의 판단을 위한 판단 기준을 발견하는 비지도 학습(unsupervised learning)을 통하여, 인공지능 모델을 학습시킬 수 있다. 또한, 모델 학습부는 예를 들어, 학습에 따른 상황 판단의 결과가 올바른 지에 대한 피드백을 이용하는 강 화 학습(reinforcement learning)을 통하여, 인공지능 학습 모델을 학습시킬 수 있다. 또한, 모델 학습부(61 4)는, 예를 들어, 오류 역전파법(error back-propagation) 또는 경사 하강법(gradient descent)을 포함하는 학 습 알고리즘 등을 이용하여 인공지능 학습 모델을 학습시킬 수 있다 모델 학습부는 미리 구축된 인공지능 모델이 복수 개가 존재하는 경우, 입력된 학습 데이터와 기본 학습 데이터의 관련성이 큰 인공지능 학습 모델을 학습할 인공지능 학습 모델로 결정할 수 있다. 이 경우, 기본 학 습 데이터는 데이터의 타입별로 기 분류되어 있을 수 있으며, 인공지능 모델은 데이터의 타입별로 미리 구축되 어 있을 수 있다. 예를 들어, 기본 학습 데이터는 학습 데이터가 생성된 지역, 학습 데이터가 생성된 시간, 학습 데이터의 크기, 학습 데이터의 장르, 학습 데이터의 생성자, 학습 데이터 내의 오브젝트의 종류 등과 같은 다양한 기준으로 기 분류되어 있을 수 있다. 인공지능 학습 모델이 학습되면, 모델 학습부는 학습된 인공지능 학습 모델을 저장할 수 있다. 이 경우, 모델 학습부는 학습된 인공지능 학습 모델을 전자 장치의 저장부에 저장할 수 있다. 또는, 모델 학습부는 학습된 인공지능 학습 모델을 전자 장치와 유선 또는 무선 네트워크로 연결되는 서버(예 를 들어, 인공지능 서버)의 메모리에 저장할 수도 있다. 학습부는 인공지능 학습 모델의 인식 결과를 향상시키거나, 인공지능 학습 모델의 생성에 필요한 자원 또 는 시간을 절약하기 위하여, 학습 데이터 전처리부 및 학습 데이터 선택부를 더 포함할 수도 있다. 학습 데이터 전처리부는 오브젝트에 대한 정보 획득 및 키워드 생성을 위한 학습에 획득된 데이터가 이용 될 수 있도록, 획득된 데이터를 전처리할 수 있다. 학습 데이터 전처리부는 모델 학습부가 오브젝트 에 대한 정보를 획득하기 위하여 획득된 데이터를 이용할 수 있도록, 해당 데이터를 기설정된 포맷으로 가공할 수 있다. 학습 데이터 선택부는 학습 데이터 획득부에서 획득된 데이터 또는 학습 데이터 전처리부에서 전처리된 데이터 중에서 학습에 필요한 데이터를 선택할 수 있다. 선택된 학습 데이터는 모델 학습부에 제공될 수 있다. 학습 데이터 선택부는 기설정된 선별 기준에 따라, 획득되거나 전처리된 데이터 중에서 학습에 필요한 학 습 데이터를 선택할 수 있다. 또한, 학습 데이터 선택부는 모델 학습부에 의한 학습에 의해 기설정 된 선별 기준에 따라 학습 데이터를 선택할 수도 있다. 학습부는 인공지능 학습 모델의 인식 결과를 향상시키기 위하여, 모델 평가부를 더 포함할 수도 있다. 모델 평가부는 인공지능 학습 모델에 평가 데이터를 입력하고, 평가 데이터로부터 출력되는 인식 결과가 소정 기준을 만족하지 못하는 경우, 모델 학습부로 하여금 다시 학습하도록 할 수 있다. 이 경우, 평가 데이터는 인공지능 모델을 평가하기 위한 기정의된 데이터일 수 있다. 예를 들어, 모델 평가부는 평가 데이터에 대한 학습된 인공지능 학습 모델의 인식 결과 중에서, 인식 결과 가 정확하지 않은 평가 데이터의 개수 또는 비율이 미리 설정된 임계치를 초과하는 경우 소정 기준을 만족하지 못한 것으로 평가할 수 있다. 한편, 학습된 인공지능 학습 모델이 복수 개가 존재하는 경우, 모델 평가부는 각각의 학습된 인공지능 학 습 모델에 대하여 소정 기준을 만족하는지를 평가하고, 소정 기준을 만족하는 모델을 최종 인공지능 학습 모델 로서 결정할 수 있다. 이 경우, 소정 기준을 만족하는 학습 모델이 복수 개인 경우, 모델 평가부는 평가 점수가 높은 순으로 미리 설정된 어느 하나 또는 소정 개수의 학습 모델을 최종 인공지능 학습 모델로서 결정할 수 있다. 한편, 획득부는 도 7의 (b)에 도시된 바와 같이, 입력 데이터 획득부 및 제공부를 포함할 수 있 다. 획득부는 입력 데이터 전처리부, 입력 데이터 선택부 및 모델 갱신부 중 적어도 하나를 선 택적으로 더 포함할 수 있다. 입력 데이터 획득부는 영상을 구성하는 복수의 프레임에 포함된 오브젝트에 대한 정보를 획득하기 위해 필 요한 데이터를 획득할 수 있다. 제공부는 입력 데이터 획득부에서 획득된 입력 데이터를 입력 값으로 학습된 인공지능 학습 모델에 적용하여 영상을 구성하는 복수의 프레임에 포함된 오브젝트에 대한 정보를 획득할 수 있다. 이 같은 제공부는 후술할 입력 데이터 전처리부 또는 입력 데이터 선택부에 의해 선택된 데이터 를 입력 값으로 인공지능 학습 모델에 적용하여 인식 결과를 획득할 수 있다. 인식 결과는 인공지능 학습 모델 에 의해 결정될 수 있다. 일 실시예로, 제공부는 입력 데이터 획득부에서 획득한 영상 관련 데이터를 학습된 제1 모델에 적용 하여 영상을 구성하는 복수의 프레임에 포함된 오브젝트에 대한 정보를 획득(또는, 추정)할 수 있다. 또 다른 예로, 제공부는 입력 데이터 획득부에서 획득한 오브젝트에 대한 정보, 사용자 정보 및 사용 자 음성 등을 학습된 제2 모델에 적용하여 사용자 음성에 대응되는 오브젝트에 대한 키워드를 획득(또는, 추 정)할 수 있다. 획득부는 인공지능 학습 모델의 인식 결과를 향상시키거나, 인식 결과의 제공을 위한 자원 또는 시간을 절 약하기 위하여, 입력 데이터 전처리부 및 입력 데이터 선택부를 더 포함할 수도 있다. 입력 데이터 전처리부는 제1 및 제2 모델에 입력되기 위해 획득된 데이터가 이용될 수 있도록, 획득된 데 이터를 전처리할 수 있다. 입력 데이터 전처리부는 제공부가 오브젝트에 대한 정보 획득 및 키워드 생성을 위하여 획득된 데이터를 이용할 수 있도록, 획득된 데이터를 기정의된 포맷으로 가공할 수 있다. 입력 데이터 선택부는 입력 데이터 획득부에서 획득된 데이터 또는 입력 데이터 전처리부에서 전처리된 데이터 중에서 상황 판단에 필요한 데이터를 선택할 수 있다. 선택된 데이터는 제공부에게 제공 될 수 있다. 입력 데이터 선택부는 상황 판단을 위한 기설정된 선별 기준에 따라, 획득되거나 전처리된 데이터 중에서 일부 또는 전부를 선택할 수 있다. 또한, 입력 데이터 선택부는 모델 학습부에 의한 학습에 의해 기설정된 선별 기준에 따라 데이터를 선택할 수도 있다. 모델 갱신부는 제공부에 의해 제공되는 인식 결과에 대한 평가에 기초하여, 인공지능 모델이 갱신되 도록 제어할 수 있다. 예를 들어, 모델 갱신부는 제공부에 의해 제공되는 인식 결과를 모델 학습부에게 제공함으로써, 모델 학습부가 인공지능 학습 모델을 추가 학습 또는 갱신하도록 요청할 수 있다. 도 8은 본 발명의 일 실시예에 따른 전자 장치 및 외부 서버가 서로 연동하여 데이터를 학습하고 판단하는 예시 도이다. 도 8에 도시된 바와 같이, 외부의 서버(S)는 영상을 구성하는 복수의 프레임에 포함된 복수의 오브젝트에 대한 정보를 획득한다. 뿐만 아니라, 외부의 서버(S)는 사용자 음성에 대응되는 오브젝트에 대한 키워드를 획득하기 위한 기준을 학습할 수 있다. 전자 장치(A)는 서버(S)에 의한 학습 결과에 기초하여 생성된 모델들을 이용하여 영상을 구성하는 복수의 프레 임에 포함된 복수의 오브젝트에 대한 정보를 획득할 뿐만 아니라, 사용자 음성에 대응되는 오브젝트에 대한 키 워드를 획득할 수 있다. 이 경우, 서버(S)의 모델 학습부는 도 6에 도시된 학습부의 기능을 수행할 수 있다. 서버(S)의 모델 학습부는 제1 및 제2 모델에 대한 판단 기준(혹은, 인식 기준)을 학습할 수 있다. 또한, 전자 장치(A)의 제공부는 입력 데이터 선택부에 의해 선택된 데이터를 서버(S)에 의해 생성된 인공지능 학습 모델에 적용하여 영상을 구성하는 복수의 프레임에 포함된 오브젝트에 대한 정보를 획득할 뿐만 아니라, 사용자 음성에 대응되는 오브젝트에 대한 키워드를 획득할 수 있다. 또한, 전자 장치(A)의 제공부는 서버(S)에 의해 생성된 인공지능 학습 모델을 서버(S)로부터 수신하고, 수 신된 인공지능 학습 모델을 이용하여 영상을 구성하는 복수의 프레임에 포함된 오브젝트에 대한 정보를 획득할 뿐만 아니라, 사용자 음성에 대응되는 오브젝트에 대한 키워드를 획득할 수 있다. 지금까지, 본 발명에 따른 전자 장치에서 인공지능 학습 모델을 이용하여 영상을 구성하는 복수의 프레임 에 포함된 오브젝트를 판단하는 동작에 대해서 상세히 설명하였다. 이하에서는, 본 발명에 따른 전자 장치에서 입력된 영상을 구성하는 복수의 프레임을 인공지능 학습 모델 에 입력하여 복수의 프레임에 포함된 오브젝트를 판단하는 방법에 대해서 상세히 설명하도록 한다. 도 9는 본 발명의 일 실시예에 따른 전자 장치에서 입력된 영상으로부터 오브젝트를 판단하는 방법의 흐름도이 다. 도 9에 도시된 바와 같이, 전자 장치는 촬영된 영상을 구성하는 프레임이 입력되면, 입력된 현재 프레임 (이하 제2 프레임이라 함)과 이전에 입력된 이전 프레임(이하 제1 프레임)을 바탕으로 제2 프레임 중 움직임이 있는 영역을 판단한다(S910,S920). 이후, 전자 장치는 제2 프레임에서 판단된 움직임이 있는 영역에 기초하여 제2 프레임을 인공지능 학습 모 델에 입력하고, 인공지능 학습 모델을 통해 출력된 결과값에 기초하여 제2 프레임에 포함된 적어도 하나의 오브 젝트에 대한 정보를 획득한다(S930). 이후, 전자 장치는 획득된 적어도 하나의 오브젝트에 대한 정보를 이용하여 제2 프레임에서 움직임이 있는 영역에 포함된 오브젝트를 판단한다(S940). 구체적으로, 전자 장치는 촬영된 영상에 대한 프레임이 입력되면, 입력된 프레임이 최초 입력된 프레임(이 하 시작 프레임이라 함)인지 여부를 판단한다. 판단 결과, 입력된 프레임이 시작 프레임이면, 전자 장치 는 입력된 시작 프레임의 전체 영역을 리드하도록 시작 프레임을 인공지능 학습 모델에 입력한다. 이후, 전자 장치는 인공지능 학습 모델을 통해 출력된 결과값에 기초하여 시작 프레임이 포함된 적어도 하나의 오브젝 트에 대한 정보를 획득한다. 한편, 입력된 프레임이 시작 프레임이 아니면, 전자 장치는 입력된 제2 프레임과 제2 프레임이 입력되기 전에 입력된 제1 프레임을 바탕으로 제2 프레임 중 움직임이 있는 영역을 판단한다. 이하에서는, 전자 장치에서 입력된 프레임에 기초하여 움직임이 있는 영역을 판단하는 방법에 대해서 상세 히 설명하도록 한다. 도 10은 본 발명의 일 실시예에 따른 전자 장치에서 입력된 프레임에서 움직임이 있는 영역을 판단하는 방법의 흐름도이다. 도 10에 도시된 바와 같이, 전자 장치는 제2 프레임이 입력되면, 제2 프레임이 입력되기 전에 입력된 제1 프레임의 픽셀값과 현재 입력된 제2 프레임의 픽셀값을 비교한다(S1010). 이후, 전자 장치는 제1 및 제2 프레임의 픽셀값 간의 차이가 기설정된 임계값을 초과하는지 여부를 판단하 여, 픽셀값 간의 차이가 기설정된 임계값을 초과하는 영역을 제2 프레임 내에서 움직임이 있는 영역으로 판단한 다(S1020,S1030). 이후, 전자 장치는 제2 프레임에서 움직임이 있는 영역으로 판단된 영역에 대한 좌표값을 저장한다 (S1040). 이 같은 실시예를 통해 입력된 제2 프레임에서 움직임이 있는 영역이 판단되면, 전자 장치는 제2 프레임 내에서 움직임이 있는 영역으로 판단된 영역을 리드하고, 나머지 영역을 스킵하도록 제2 프레임을 상기 인공지 능 학습 모델에 입력한다. 이에 따라, 전자 장치는 인공지능 학습 모델을 통해 제2 프레임 내에서 움직임이 있는 영역에 포함된 오브 젝트에 대한 정보를 획득할 수 있다. 이 같은 적어도 하나의 오브젝트에 대한 정보가 획득되면, 전자 장치는 획득된 적어도 하나의 오브젝트에 대한 정보를 이용하여 제2 프레임 내에서 움직임이 있는 영역에 포함된 오브젝트를 판단한다. 구체적으로, 전자 장치는 제2 프레임에서 움직임이 있는 영역이 판단되면, 이에 대한 결과값을 생성한다. 여기서, 결과값은 제2 프레임에서 움직임이 있는 영역을 리드하고, 나머지 영역을 스킵하도록 하기 위한 값이 될 수 있다. 이 같은 결과값이 생성되면, 전자 장치는 제2 프레임에서 움직임이 있는 영역에 대한 결과값을 인공지능 학습 모델에 입력한다. 이에 따라, 인공지능 학습 모델은 입력된 결과값에 기초하여 제2 프레임에서 움직임이 있는 영역만을 리드하여 연산을 수행한다. 따라서, 전자 장치는 인공지능 학습 모델을 통해 수행된 연산 결과에 기초하여 제2 프 레임에 포함된 적어도 하나의 오브젝트에 대한 정보를 획득할 수 있다. 한편, 인공지능 학습 모델을 통해 수행된 연산 결과는 오브젝트에 대한 특징값이 될 수 있으며, 인공지능 학습 모델은 기정의된 CNN(Convolutinal Neural Netwok) 알고리즘를 통해 제2 프레임에서 움직임이 있는 영역에 포함 된 오브젝트에 대한 특징값을 획득할 수 있다. 따라서, 전자 장치는 인공지능 학습 모델을 통해 출력된 특징값에 기초하여 제2 프레임에서 움직임이 있는 영역에 포함된 오브젝트에 대한 정보를 획득할 수 있다. 제2 프레임에서 움직임이 있는 영역에 정보가 획득되면, 전자 장치는 제2 프레임에서 움직임이 있는 영역 에 대한 정보 및 해당 영역과 관련하여 기저장된 좌표값을 이용하여 제2 프레임에서 움직임이 있는 영역에 포함 된 오브젝트를 판단할 수 있다. 한편, 전자 장치는 제2 프레임이 입력된 이후 다음 프레임(이하 제3 프레임이라 함)이 입력되면, 다음과 같은 처리 과정을 통해 제3 프레임에서 움직임이 있는 영역에 포함된 오브젝트에 대한 정보를 획득할 수 있다. 도 11은 본 발명의 일 실시예에 따른 전자 장치에서 제2 프레임 이후 입력된 제3 프레임에서 움직임이 있는 영 역에 포함된 오브젝트에 대한 정보를 획득하는 방법의 흐름도이다. 도 11에 도시된 바와 같이, 전자 장치는 제2 프레임이 입력된 이후 제3 프레임이 입력되는지 여부를 판단 한다(S1110). 판단 결과, 제3 프레임이 입력되면, 전자 장치는 기저장된 좌표값에 기초하여 제3 프레임에 서 움직임이 있는 영역을 판단한다(S1120). 이후, 전자 장치는 전술한 바와 같이, 움직임이 있는 영역을 리드하고, 나머지 나머지 영역을 스킵하도록 제3 프레임을 인공지능 학습 모델에 입력하고, 인공지능 학습 모델을 통해 출력된 결과값에 기초하여 제3 프레 임에서 움직임이 있는 영역에 포함된 오브젝트에 대한 정보를 획득한다(S1130). 제3 프레임에서 움직임이 있는 영역에 포함된 오브젝트에 대한 정보가 획득되면, 전자 장치는 전술한 도 9 의 단계 S940를 통해 제3 프레임에서 움직임이 있는 영역에 포함된 오브젝트를 판단할 수 있다. 그러나, 본 발명은 이에 한정되지 않으며, 전자 장치는 제3 프레임이 입력되면, 전술한 바와 같이, 제3 프 레임이 입력되기 전에 입력된 제2 프레임의 픽셀값과 현재 입력된 제3 프레임의 픽셀값을 비교하여, 픽셀값 간 의 차이가 기설정된 임계값을 초과하는 영역을 움직임이 있는 영역으로 판단할 수 있다. 제2 및 제3 프레임의 픽셀값 간의 차이에 기초하여 제3 프레임에서 움직임이 있는 영역이 판단되면, 전자 장치 는 제3 프레임에서 움직임이 있는 영역으로 판단된 영역을 리드하고, 나머지 영역을 스킵하도록 제3 프레 임을 인공지능 학습 모델에 입력한다. 이에 따라, 전자 장치는 인공지능 학습 모델을 통해 제3 프레임 내에서 움직임이 있는 영역에 포함된 오브 젝트에 대한 정보를 획득할 수 있으며, 획득된 정보를 이용하여 제3 프레임 내에서 움직임이 있는 영역에 포함 된 오브젝트를 판단할 수 있다. 한편, 상술한 바와 같은 전자 장치의 제어 방법은 적어도 하나의 실행 프로그램으로 구현될 수 있으며, 이 러한 실행 프로그램은 비일시적 컴퓨터 판독 가능 매체에 저장될 수 있다. 비일시적 판독 가능 매체란 레지스터, 캐쉬, 메모리 등과 같이 짧은 순간 동안 데이터를 저장하는 매체가 아니 라 반영구적으로 데이터를 저장하며, 기기에 의해 판독(reading)이 가능한 매체를 의미한다. 구체적으로, 상술 한 프로그램들은 RAM(Random Access Memory), 플레시메모리, ROM(Read Only Memory), EPROM(Erasable Programmable ROM), EEPROM(Electronically Erasable and Programmable ROM), 레지스터, 하드디스크, 리무버블 디스크, 메모리 카드, USB 메모리, CD-ROM 등과 같이, 단말기에서 판독 가능한 다양한 유형의 기록 매체에 저장 되어 있을 수 있다. 이제까지 본 발명에 대하여 그 바람직한 실시예들을 중심으로 살펴보았다. 이상에서는 본 발명의 바람직한 실시예에 대하여 도시하고 설명하였지만, 본 발명은 상술한 특정의 실시예에 한"}
{"patent_id": "10-2018-0037159", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "정되지 아니하며, 청구범위에서 청구하는 본 발명의 요지를 벗어남이 없이 당해 발명이 속하는 기술분야에서 통 상의 지식을 가진 자에 의해 다양한 변형실시가 가능한 것은 물론이고, 이러한 변형실시들은 본 발명의 기술적 사상이나 전망으로부터 개별적으로 이해되어져서는 안될 것이다."}
{"patent_id": "10-2018-0037159", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일 실시예에 따른 전자 장치의 개략적인 블록도, 도 2는 본 발명의 일 실시예에 따른 프로세서의 세부 블록도, 도 3은 본 발명의 일 실시예에 따른 프로세서에서 입력된 프레임 내에서 움직임 영역을 판단하는 예시도, 도 4는 본 발명의 일 실시예에 따른 프로세서에서 움직임 영역 내 포함된 오브젝트의 정보를 획득하는 예시도, 도 5는 본 발명의 일 실시예에 따른 전자 장치의 세부 블록도, 도 6은 본 발명의 일 실시예에 따른 인공지능 학습모델을 업데이트하고 이용하는 전자 장치의 프로세서의 세부 블록도, 도 7은 본 발명의 일 실시예에 따른 학습부 및 획득부의 세부 블록도, 도 8은 본 발명의 일 실시예에 따른 전자 장치 및 외부 서버가 서로 연동하여 데이터를 학습하고 판단하는 예시 도, 도 9는 본 발명의 일 실시예에 따른 전자 장치에서 입력된 영상으로부터 오브젝트를 판단하는 방법의 흐름도, 도 10은 본 발명의 일 실시예에 따른 전자 장치에서 입력된 프레임에서 움직임이 있는 영역을 판단하는 방법의 흐름도,도 11은 본 발명의 일 실시예에 따른 전자 장치에서 제2 프레임 이후 입력된 제3 프레임에서 움직임이 있는 영 역에 포함된 오브젝트에 대한 정보를 획득하는 방법의 흐름도이다."}
