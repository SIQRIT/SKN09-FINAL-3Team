{"patent_id": "10-2021-0023846", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2022-0110015", "출원번호": "10-2021-0023846", "발명의 명칭": "인공지능을 이용하여 영상으로부터 판서 동작을 인식하는 방법 및 장치", "출원인": "라온피플 주식회사", "발명자": "이석중"}}
{"patent_id": "10-2021-0023846", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "영상으로부터 판서 동작을 인식하는 장치가 영상으로부터 판서 동작을 인식하는 방법에 있어서,영상으로부터 인물의 신체 정보를 검출하는 단계; 및상기 검출된 신체 정보에 기초하여 인물의 판서 동작 수행 여부를 결정하는 단계를 포함하는, 방법."}
{"patent_id": "10-2021-0023846", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제 1항에 있어서, 상기 판서 동작 수행 여부를 결정하는 단계는,상기 검출된 신체 정보에 포함된 인물의 코, 목, 팔목의 위치를 기초로 인물의 판서 동작 수행 여부를 결정하는단계를 포함하는, 방법."}
{"patent_id": "10-2021-0023846", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제 2항에 있어서,상기 검출된 신체 정보에 포함된 인물의 코의 위치와 목의 위치를 기초로 인물의 응시방향을 결정하는 단계;상기 결정된 인물의 응시방향이 좌측 또는 우측이고, 상기 검출된 신체 정보에 포함된 인물의 목의 위치에 대한y값과 팔목의 위치에 대한 y값의 차이가 미리 설정된 값 이하인 경우, 팔목의 위치에 대한 x값과 인물의 목의위치에 대한 x값의 차이와 코의 위치에 대한 x값과 목의 위치에 대한 x값의 차이를 비교하여 인물의 판서 동작수행 여부를 결정하는 단계를 포함하는, 방법."}
{"patent_id": "10-2021-0023846", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제 1항에 있어서, 상기 판서 동작 여부를 판단하는 단계는,상기 검출된 신체 정보에 포함된, 인물이 정면을 응시할 때의 어깨 넓이와 인물이 회전할 때 영상에서 나타나는어깨 넓이를 기초로 인물의 판서 동작 수행 여부를 결정하는 단계를 포함하는, 방법."}
{"patent_id": "10-2021-0023846", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제 1항에 있어서,상기 방법은,카메라를 이용하여 영상을 획득하는 단계; 및상기 인물의 판서 동작 수행 여부의 결과에 기초하여 상기 카메라의 배율을 조정하는 단계를 더 포함하는,방법."}
{"patent_id": "10-2021-0023846", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제 1항에 있어서,상기 신체 정보를 검출하는 단계는,적어도 하나 이상의 신체 부위를 인식하고, 상기 신체 부위의 위치와 상기 복수의 신체 부위 사이의 연결정보를표현하는 스켈레톤(skeleton)을 생성하는 단계를 포함하는, 방법."}
{"patent_id": "10-2021-0023846", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "공개특허 10-2022-0110015-3-영상으로부터 판서 동작을 인식하는 장치에 있어서,영상으로부터 판서 동작 인식을 수행하기 위한 프로그램 및 데이터가 저장되는 저장부; 및상기 프로그램을 실행함으로써 영상으로부터 판서 동작을 인식하는 제어부를 포함하며,상기 제어부는,영상으로부터 인물의 신체 정보를 검출하고,상기 검출된 신체 정보에 기초하여 인물의 판서 동작 수행 여부를 결정하는, 장치."}
{"patent_id": "10-2021-0023846", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제 7항에 있어서,상기 제어부는,상기 검출된 신체 정보에 포함된 인물의 코, 목, 팔목의 위치를 기초로 인물의 판서 동작 수행 여부를결정하는, 장치."}
{"patent_id": "10-2021-0023846", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제 8항에 있어서,상기 제어부는,상기 검출된 신체 정보에 포함된 인물의 코의 위치와 목의 위치를 기초로 인물의 응시방향을 결정하고,상기 결정된 인물의 응시방향이 좌측 또는 우측이고, 상기 검출된 신체 정보에 포함된 인물의 목의 위치에 대한y값과 팔목의 위치에 대한 y값의 차이가 미리 설정된 값 이하인 경우, 팔목의 위치에 대한 x값과 인물의 목의위치에 대한 x값의 차이와 코의 위치에 대한 x값과 목의 위치에 대한 x값의 차이를 비교하여 인물의 판서 동작수행 여부를 결정하는, 장치."}
{"patent_id": "10-2021-0023846", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제 7항에 있어서,상기 제어부는,상기 검출된 신체 정보에 포함된, 인물이 정면을 응시할 때의 어깨 넓이와 인물이 회전할 때 영상에서 나타나는어깨 넓이를 기초로 인물의 판서 동작 수행 여부를 결정하는, 장치."}
{"patent_id": "10-2021-0023846", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "제 7항에 있어서,상기 장치는,영상을 획득하는 카메라를 더 포함하고,상기 제어부는,상기 인물의 판서 동작 수행 여부의 결과에 기초하여 상기 카메라의 배율을 조정하는, 장치."}
{"patent_id": "10-2021-0023846", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_12", "content": "제 7항에 있어서,상기 제어부는,적어도 하나 이상의 신체 부위를 인식하고, 상기 신체 부위의 위치와 상기 복수의 신체 부위 사이의 연결정보를표현하는 스켈레톤(skeleton)을 생성하는, 장치."}
{"patent_id": "10-2021-0023846", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "공개특허 10-2022-0110015-4-컴퓨터에 제 1항에 기재된 방법을 실행시키기 위한 프로그램을 기록한 컴퓨터 판독 가능한 기록 매체."}
{"patent_id": "10-2021-0023846", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "판서동작인식 장치에 의해 수행되며, 제 1항에 기재된 방법을 수행하기 위해 매체에 저장된 컴퓨터 프로그램."}
{"patent_id": "10-2021-0023846", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "본 명세서에서 개시된 일 실시예에 따르면 영상으로부터 판서 동작을 인식하는 장치가 영상으로부터 판서 동작을 인식하는 방법은, 영상으로부터 인물의 신체 정보를 검출하는 단계; 및 상기 검출된 신체 정보에 기초하여 인물 의 판서 동작 수행 여부를 결정하는 단계를 포함한다."}
{"patent_id": "10-2021-0023846", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 명세서에서 개시되는 실시예들은 방법 및 장치에 관한 것으로, 보다 구체적으로는, 인공지능을 이용하여 영 상으로부터 판서 동작을 인식하고 자동으로 카메라의 배율을 조정하는, 판서 동작 인식 방법 및 장치에 관한 것 이다."}
{"patent_id": "10-2021-0023846", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "사람의 신체 위치 정보 변화를 검출하여 이를 기기제어에 필요한 인터페이스 장치로 사용하는 종래의 기술은 크 게 두 가지로 나눌 수 있다. 카메라로 입력된 영상 정보를 이용하는 영상 처리 기술을 이용하는 것과, 사람의 신체에 특정 장치를 장착하는 기술을 이용하는 것이다. 그러나, 종래의 기술에서는, 영상 속에서 인물이 판서 동작을 수행하는 경우 이를 인식하는 기술이 부재하였다. 따라서 상술된 문제점을 해결하기 위한 기술이 필요하게 되었다."}
{"patent_id": "10-2021-0023846", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 2, "content": "한편, 전술한 배경기술은 발명자가 본 발명의 도출을 위해 보유하고 있었거나, 본 발명의 도출 과정에서 습득한 기술 정보로서, 반드시 본 발명의 출원 전에 일반 공중에게 공개된 공지기술이라 할 수는 없다."}
{"patent_id": "10-2021-0023846", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "본 명세서에서 개시되는 실시예들은, 영상으로부터 판서 동작을 인식하고 자동으로 카메라의 배율을 조정하는, 영상으로부터 판서 동작 인식 방법 및 장치를 제시하는데 목적이 있다."}
{"patent_id": "10-2021-0023846", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상술한 기술적 과제를 달성하기 위한 기술적 수단으로서 일 실시예에 따르면, 영상으로부터 판서 동작을 인식하 는 장치는, 영상으로부터 판서 동작 인식을 수행하기 위한 프로그램 및 데이터가 저장되는 저장부; 및 상기 프 로그램을 실행함으로써 영상으로부터 판서 동작을 인식하는 제어부를 포함하며, 상기 제어부는, 영상으로부터 인물의 신체 정보를 검출하고, 상기 검출된 신체 정보에 기초하여 인물의 판서 동작 수행 여부를 결정할 수 있 다. 다른 실시예에 따르면, 영상으로부터 판서 동작을 인식하는 장치가 영상으로부터 판서 동작을 인식하는 방법은, 영상으로부터 인물의 신체 정보를 검출하는 단계; 및 상기 검출된 신체 정보에 기초하여 인물의 판서 동작 수행 여부를 결정하는 단계를 포함할 수 있다. 다른 실시예에 따르면, 영상으로부터 판서 동작을 인식하는 방법을 수행하는 프로그램이 기록된 컴퓨터 판독 가 능한 기록 매체가 개시된다. 상기 방법은, 영상으로부터 인물의 신체 정보를 검출하는 단계; 및 상기 검출된 신 체 정보에 기초하여 인물의 판서 동작 수행 여부를 결정하는 단계를 포함할 수 있다. 다른 실시에에 다르면, 영상으로부터 판서 동작을 인식하는 방법을 수행하기 위해 매체에 저장된 컴퓨터 프로그 램이 개시된다. 상기 방법은, 영상으로부터 인물의 신체 정보를 검출하는 단계; 및 상기 검출된 신체 정보에 기 초하여 인물의 판서 동작 수행 여부를 결정하는 단계를 포함할 수 있다."}
{"patent_id": "10-2021-0023846", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "전술한 과제 해결 수단 중 어느 하나에 의하면, 영상으로부터 판서 동작 인식 방법 및 장치가 제시된다. 전술한 과제 해결 수단 중 어느 하나에 의하면, 영상으로부터 판서 동작을 인식하고, 자동으로 카메라의 배율을 조정할 수 있다. 전술한 과제 해결 수단 중 어느 하나에 의하면, 판서 동작을 수행 시 자동으로 배율 조정이 되므로 판서 동작이 포함된 강의 동작을 수행하는 사람이 강의를 혼자서도 녹화할 수 있다. 즉, 녹화 중 카메라를 제어할 추가 인원 이 필요 없다. 과제 해결 수단 중 어느 하나에 의하면, 실시간 스트리밍할 수 있는 솔루션을 제공할 수 있다. 과제 해결 수단 중 어느 하나에 의하면, 혼자서도 간단하게 설치할 수 있으며, 원하는 장소에서 혼자서 녹화를 가능하게 할 수 있다. 개시되는 실시예들에서 얻을 수 있는 효과는 이상에서 언급한 효과들로 제한되지 않으며, 언급하지 않은 또 다"}
{"patent_id": "10-2021-0023846", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 2, "content": "른 효과들은 아래의 기재로부터 개시되는 실시예들이 속하는 기술분야에서 통상의 지식을 가진 자에게 명확하게 이해될 수 있을 것이다."}
{"patent_id": "10-2021-0023846", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "아래에서는 첨부한 도면을 참조하여 다양한 실시예들을 상세히 설명한다. 아래에서 설명되는 실시예들은 여러 가지 상이한 형태로 변형되어 실시될 수도 있다. 실시예들의 특징을 보다 명확히 설명하기 위하여, 이하의 실시"}
{"patent_id": "10-2021-0023846", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "예들이 속하는 기술분야에서 통상의 지식을 가진 자에게 널리 알려져 있는 사항들에 관해서 자세한 설명은 생략 하였다. 그리고, 도면에서 실시예들의 설명과 관계없는 부분은 생략하였으며, 명세서 전체를 통하여 유사한 부 분에 대해서는 유사한 도면 부호를 붙였다. 명세서 전체에서, 어떤 구성이 다른 구성과 \"연결\"되어 있다고 할 때, 이는 '직접적으로 연결'되어 있는 경우뿐 아니라, '그 중간에 다른 구성을 사이에 두고 연결'되어 있는 경우도 포함한다. 또한, 어떤 구성이 어떤 구성을 \"포함\"한다고 할 때, 이는 특별히 반대되는 기재가 없는 한, 그 외 다른 구성을 제외하는 것이 아니라 다른 구 성들을 더 포함할 수도 있음을 의미한다. 이하 첨부된 도면을 참고하여 실시예들을 상세히 설명하기로 한다. 도 1은 일 실시예에 따른 영상으로부터 판서동작인식 장치의 구성을 도시한 블록도이다. 일 실시예에 따른 영상으로부터 판서동작인식 장치는 카메라, 통신부, 저장부, 제어부를 포함할 수 있 다. 카메라는 영상을 획득하는 장치로서, 예를 들어 일반 카메라로 구현되어, 신체에 관련된 영상을 획득할 수 있다. 이외에도 카메라는 거리 측정 카메라로도 구현될 수 있다. 특히, 본 발명에서, 촬영대상의 움직임을 관찰하거나 필요한 부분에 회전, 줌을 함으로써 넓은 영역을 모니터링할 수 있는 PTZ(Pan Tilt Zoom) 카메라가 사용될 수 있다. 통신부는 다른 디바이스 또는 네트워크와 유무선 통신을 수행할 수 있다. 이를 위해, 통신부는 다양 한 유무선 통신 방법 중 적어도 하나를 지원하는 통신 모듈을 포함할 수 있다. 예를 들어, 통신 모듈은 칩셋 (chipset)의 형태로 구현될 수 있다. 통신부가 지원하는 무선 통신은, 예를 들어 Wi-Fi(Wireless Fidelity), Wi-Fi Direct, 블루투스 (Bluetooth), UWB(Ultra Wide Band) 또는 NFC(Near Field Communication) 등일 수 있다. 또한, 통신부가 지원하는 유선 통신은, 예를 들어 USB 또는 HDMI(High Definition Multimedia Interface) 등일 수 있다. 저장부에는 다양한 종류의 프로그램 및 데이터가 저장될 수 있다. 특히, 저장부에는 제어부가 카메라를 제어하는 동시에 영상으로부터 판서 동작 인식을 수행하기 위한 프로그램이 저장될 수 있다. 또 한, 저장부에는 영상으로부터 판서 동작 인식에 필요한 다양한 프로그램이나 데이터가 저장될 수 있다. 제어부는 CPU 등과 같은 적어도 하나의 프로세서를 포함하는 구성으로서, 영상으로부터 판서 동작 인식 장 치의 전반적인 동작을 제어한다. 특히, 제어부는 카메라를 제어하는 동시에 영상으로부터 판서 동작 인식할 수 있다. 제어부는 저장부에 저장된 판서 동작 인식을 수행하기 위한 프로그램을 실행함 으로써, 영상으로부터 판서 동작을 인식할 수 있다. 제어부가 카메라를 제어하는 동시에 영상으로부 터 판서 동작 인식하는 구체적인 방법에 대해서는 아래에서 다른 도면들을 참조하여 자세하게 설명한다. 특히, 제어부는 영상으로부터 판서 동작을 결정할 수 있고, 판서 동작으로 결정된 경우 카메라의 배 율을 조정할 수 있다. 이를 통해, 판서 동작을 수행 시 자동으로 배율 조정이 되므로 판서 동작에 따라 작성되 는 글씨를 자세히 촬영할 수 있고, 그에 따라 판서 동작이 포함된 강의 동작을 수행하는 사람이 강의를 혼자서 도 녹화할 수 있다. 도 2는 실시예에 따른 영상으로부터 판서 동작을 인식하는 방법을 설명하기 위한 순서도이다. 도 2를 참조하면, S210단계에서, 카메라를 이용하여 영상을 획득한다. 이후 S220단계에서, 제어부는 영상으로부터 인물의 신체 정보를 검출한다. 서버로부터 영상을 획득하는 경우나, 카메라를 이용하지 않고 영상을 획득하는 경우 S210단계는 생략될 수 있다. 이때, 인물의 신체정보는 인물의 신체 각 부위 및 인체의 뼈대를 포함한 정보일 수 있다. 관련하여, 제어부는 영상으로부터 추출된 이미지를 기반으로 판서 동작을 인식한다. 관련하여, 제어부가 영상으로부터 인물의 신체 정보를 검출하는 방법은 다양하게 존재할 수 있다. 일 실시예로 제어부는 영상으로부터 인물을 인식하고, 인식된 인물에 대하여 적어도 하나 이상의 신체 부 위를 인식하고, 신체 부위의 위치와 복수의 신체 부위 사이의 연결정보를 표현하는 스켈레톤(skeleton) 정보를 생성할 수 있다. 관련하여, 제어부는 영상으로부터 인물의 발목, 무릎, 엉덩이, 손목, 팔꿈치, 어깨, 턱 또는 이마의 정보 를 포함하는 스켈레톤 정보를 생성할 수 있다. 이후 S230단계에서, 제어부는 검출된 신체 정보에 기초하여 판서 동작 여부를 판단할 수 있다. 관련하여, 제어부는 저장부에 기 저장된 인물의 스켈레톤 정보에 기초하여 영상으로부터 인물을 인식 하고, 인식된 인물에 대하여 적어도 하나 이상의 신체 부위를 인식하고, 신체 부위의 위치와 복수의 신체 부위 사이의 연결정보를 표현하는 스켈레톤(skeleton) 정보를 학습하고, 이와 같이 학습된 정보에 기초하여 인식된 인물의 신체 정보를 추출할 수 있다. 이를 통해, 인물의 스켈레톤 정보를 이용한 빅데이터 딥러닝을 통하여 보 다 정확도 높은 데이터 추출이 가능하다. 이후, 제어부는 딥러닝을 이용하여 추출된 인물의 신체 정보를 분석할 수 있다. 이때 사용되는 빅데이터 딥러닝 은 Depthwise Separable Convolution 기법의 mobile net v1 알고리즘일 수 있다. 이를 통해, 기존 CNN 대비 구 조 간결성으로 인한 파라미터량과 연산량을 감소시킬 수 있다. 제어부는 인물의 판서 동작 여부를 판단하 는 조건 필터의 판별 값을 활용하여 판서 동작 수행 여부를 판단할 수 있다. 또는 제어부는 인물의 판서 동작 수행 여부를 판단하는 조건 필터의 판별 값과 Depthwise Separable Convolution 기법의 AI 알고리즘을 활 용하여 판서 동작 수행 여부를 판단할 수 있다. 제어부는 판서 동작 수행 여부에 대한 판별 값을 도출하고, 판서 동작으로 판정된 경우를 학습하고, 이와 같은 학습을 통하여 새롭게 인식된 인물의 신체 정보에 대해 판서 동작인지 여부를 판정할 수 있다. 이하, 제어부가 인물의 판서 동작 수행 여부를 판단하는 조건 필터에 대해 설명한다. 구체적으로, 제어부는 검출된 신체 정보에 포함된 인물의 코, 목, 팔목의 위치를 기초로 인물의 판서 동작 수행 여부를 결정할 수 있다. 제어부는 인물의 응시방향이 좌측 또는 우측 방향인 경우, 목의 위치와 팔목 의 위치를 상대적으로 비교하여 인물의 판서 동작 수행 여부를 결정할 수 있다. 먼저, 제어부가 영상에서 인물의 응시방향을 결정하는 방법을 설명한다. 이때, 좌측은 인물의 응시방향이 카메라가 바라보는 방향을 기준으로 좌측일 경우를 의미한다. 마찬가지로, 우측은 인물의 응시방향이 카메라가 바라보는 방향을 기준 으로 우측일 경우를 의미한다. 관련하여, 제어부는 검출된 신체 정보에 포함된 인물의 코의 위치와 목의 위치를 기초로 인물의 응시방향 을 결정할 수 있다. 제어부는 영상으로부터 인물의 코의 위치와 목의 위치를 검출한다. 이때, 제어부(14 0)는 영상으로부터 인물의 코의 위치와 목의 위치를 좌표평면을 이용하여 표현할 수 있다. 이후, 제어부는 검출된 코의 위치에 대한 x값과 목의 위치에 대한 y값을 각각 도출하고, 도출된 코의 위치에 대한 수평 성분 값 과 목의 위치에 대한 x값의 차이를 기초로 인물의 응시방향을 결정할 수 있다. 관련하여, 도 3은 인물의 코의 위치와 목의 위치 정보가 포함된 영상을 나타낸 도면이다. 도 3을 참조하면, 인물의 응시방향이 좌측인 제1영상, 우측인 제2영상, 정면인 제3영상이 나타 나 있음을 알 수 있다. 이때, 제어부는 영상으로부터 인물의 코의 위치(311, 321, 331)와 목의 위치(313, 323, 333)를 좌표평면을 이용하여 표현할 수 있다. 또한, 좌표평면의 기준점(0,0)은 영상의 왼쪽하단 모서리로 지정할 수 있다. 코의 위치(311, 321, 331)에 대한 수평 성분 값과 목의 위치(313, 323, 333)에 대한 x값의 차 가 30이상이면 응시방향은 우측, 30미만 -30초과이면 정면, -30이하이면 좌측이라고 가정한다. 제어부는 제1영상에서 인물의 코의 위치는 (150,250)으로, 목의 위치는 (200,200)으로 각각 검출한다. 이후, 제어부는, 검출된 코의 위치에 대한 x값인 150과 목의 위치에 대한 x값인 200의 차가 -50 으로 미리 설정된 값인 -30 이하이므로, 제1영상에서 인물의 응시방향을 좌측으로 결정할 수 있다. 또한, 제어 부는 제2영상에서 인물의 코의 위치는 (250,250)으로, 목의 위치는 (200.200)으로 각각 검출한다. 이후, 제어부는, 검출된 코의 위치에 대한 x값인 250과 목의 위치에 대한 x값인 200 의 차가 50으로 미리 설정된 값인 30이상이므로, 제2영상에서 인물의 응시방향을 우측으로 결정할 수 있다. 또한, 제어부는 제3영상에서 인물의 코의 위치는 (200, 300)으로, 목의 위치는 (200,200)으로 검출한다. 이후, 제어부는, 검출된 코의 위치에 대한 x값인 200과 목의 위치에 대한 x값인 200의 차가 0으로 미리 설정된 값인 30미만 -30초과이므로, 제3영상에서 인물의 응시방향을 정 면으로 결정할 수 있다. 한편, 제어부는 결정된 인물의 응시방향이 좌측 또는 우측이고, 검출된 신체 정보에 포함된 목의 위치에 대한 y값과 팔목의 위치에 대한 y값의 차이가 미리 설정된 값 이하인 경우, 팔목의 위치에 대한 x값과 인물의 목의 위치에 대한 x값의 차이와, 코의 위치에 대한 x값과 목의 위치에 대한 x값의 차이를 비교하여 인물의 판서 동작 수행 여부를 결정할 수 있다. 관련하여, 도 4는 인물의 코의 위치, 목의 위치 및 팔목의 위치 정보가 포함한 영상을 나타낸 도면이다. 도 4를 참조하면, 제4영상에서 인물의 코의 위치, 목의 위치 및 팔목의 위치가 도시되어 있음을 알 수 있다. 제어부는 제4영상으로부터 인물의 코의 위치, 목의 위치 및 팔목의 위 치를 좌표평면을 이용하여 표현할 수 있다. 제4영상에서 인물의 코의 위치는 (230,250)으로, 목 의 위치는 (250.200)으로, 팔목의 위치는 (150, 190)으로 각각 검출된다. 제어부는 도 3에서 설명한 인물의 응시방향을 결정하는 방법에 의하여 제4영상에서 인물의 응시방향을 좌측으로 결정할 수 있 다. 한편, 도 4에 도시된, 양방향 화살표는 각각 목의 위치에 대한 y값과 팔목의 위치에 대한 y값의 차이, 팔목 의 위치에 대한 x값과 인물의 목의 위치에 대한 x값의 차이 및 코의 위치에 대한 x값과 목의 위치에 대한 x값의 차이를 나타낸다. 제어부는, 목의 위치에 대한 y값인 200과 팔목의 위치에 대한 y값인 190의 차 이가 미리 설정된 값 20이하이고, 팔목의 위치에 대한 x값인 150과 인물의 목의 위치에 대한 x값인 250의 차이인 100이, 코의 위치에 대한 x값인 230과 목의 위치에 대한 x값인 250의 차이 20보다 2배 이상 큰 경우, 영상에서 인물이 판서 동작을 수행하고 있다고 판단할 수 있다. 또한, 제어부는 검출된 신체 정보에 포함된, 인물이 정면을 응시할 때의 어깨 넓이와 인물이 회전할 때 영 상에서 나타나는 어깨 넓이를 기초로 인물의 판서 동작 수행 여부를 결정할 수 있다. 관련하여, 도 5는 인물의 판서 동작 수행 여부를 결정하는 방법을 설명하기 위한 예시도이다. 도 5를 참조하면, 인물이 판서 동작을 수행하기 위해선 인물의 몸통이 회전해야 하고, 정면을 응시할 때의 어깨 넓이와 회전 시 어깨 넓이가 차이가 남을 알 수 있다. 자세하게는, 도면 5에 도시된, 정면을 응시할 때의 어깨 길이를 나타내는 선과 몸통 회전할 때의 어깨길이를 나타내는 선이 차이가 남을 알 수 있다. 한편, 회전하였을 경우 영상에서 검출되는 어깨길이는 점선임을 알 수 있다. 이때, 회전 시 점선의 거리를 산출 하는 방법은 영상에서 양 어깨의 위치를 좌표평면을 이용하여 검출하고, 좌표평면 상의 두 지점의 거리를 산출 한다. 관련하여, 제어부는 인물이 정면을 응시할 경우 인물의 좌측어깨의 위치와 우측어깨의 위치를 검출하고, 양 어깨 사이의 거리를 계산한다. 즉, 정면을 응시할 때의 어깨길이를 나타내는 선의 길이를 계산한다. 이후, 제어부는 지속적으로 좌측어깨의 위치와 우측어깨의 위치를 검출하고, 양 어깨 사이의 거리를 계산한 다. 이때, 양 어깨 사이의 거리를 계산하는 것은, 인물이 회전하였을 때 인물을 정면에서 바라보고 있는 카메라 를 통해 촬영된 영상에서 검출되는 어깨길이를 나타내는 점선의 길이를 계산하는 것이다. 제어부는, 영상에서의 양 어깨 사이의 거리가 미리 설정된 값 이하로 계산된 경우, 영상에서 인물이 판서 동작을 수행하고 있다고 판단할 수 있다. 이때, 미리 설정된 값은 정면을 응시할 때의 어깨길이를 나타내는 선의 길이를 기 초로 설정될 수 있다. 다시 도 2로 돌아가서, S230단계 이후 S240단계에서, 제어부는 인물의 판서 동작 수 행 여부의 결과에 기초하여 카메라의 배율을 조정할 수 있다. 제어부가 인물이 판서 동작을 수행하고 있다고 결정한 경우, 제어부는 카메라가 줌인(Zoom-in)을 수행하도록 하여, 카메라가 기존보다 확대된 영상을 획득하도록 할 수 있다. 경우에 따라서, 제어부가 인물이 판서 동작을 수행하고 있지 않다 고 결정한 경우, 제어부는 카메라가 줌아웃(Zoom-out)을 수행하도록 하여, 카메라가 기존보다 축소된 영상을 획득하도록 할 수 있다. 한편 제어부는, 인물의 판서 동작 수행 여부를 판단하는 조건 필터의 판별 값과 Depthwise Separable Convolution 기법 등의 AI 알고리즘을 활용하여 판서 동작 수행 여부를 판단할 수 있다. 조건 필터 관련하여, 상술된 판서 동작 수행 여부 결정방법을 사용함은 물론이다. 이때 사용되는 빅데이터 딥러닝은 Depthwise Separable Convolution 기법의 mobile net v1 알고리즘일 수 있다. 이를 통해, 기존 CNN 대비 구조 간결성으로 인한 파라미터량과 연산량을 감소시킬 수 있다. 도 6은 일 실시예에 따른 영상으로부터 판서 동작을 인식하는 방법을 설명하기 위한 순서도이다. 도 6을 참조하면, S610단계에서, 제어부는 영상으로부터 인물을 인식할 수 있다. 이때, 영상으로부터 인물 을 인식하기 위해서 AI Skeleton 기법을 사용할 수 있다. 또한, 제어부는 영상으로부터 인물을 인식하고, 인식된 인물에 대하여 적어도 하나 이상의 신체 부위를 인식하고, 신체 부위의 위치와 복수의 신체 부위 사이의 연결정보를 표현하는 스켈레톤(skeleton) 정보를 생성할 수 있다. 이때, AI Skeleton 기법은, 영상을 입력하였 을 때 스켈레톤 정보를 출력하도록 인공신경망을 학습시켜, 학습된 인공신경망에 영상이 입력되었을 때 영상에 서 인식된 인물의 스켈레톤 정보를 출력할 수 있다. 예를 들어, 제어부가 저장부에 기 저장된 인물의 스켈레톤 정보에 기초하여 영상으로부터 인물을 인식하고, 인식된 인물에 대하여 적어도 하나 이상의 신체 부위 를 인식하고, 신체 부위의 위치와 복수의 신체 부위 사이의 연결정보를 표현하는 스켈레톤(skeleton) 정보를 학 습하고, 이와 같이 학습된 정보에 기초하여 인식된 인물의 신체 정보를 분석하는 것을 말한다. 이후, 초기화 단계인 S620단계에서, 제어부는 영상에서 생성된 스켈레톤 정보에 기초하여 카메라를 제어할 수 있다. 즉 제어부는 영상 녹화를 시작하면서, 카메라의 초기설정을 인물을 적절하게 촬영할 수 있도록 초기화한다. 가령, 인물을 정중앙에 배치하는 경우가 이에 포함된다. 제어부가 영상에서 생성된 스켈레톤 정보에 기초하여 카메라를 제어하는 방법은 다양하게 존재한다. 카메라를 제어하는 방법을 설명하기에 앞서, 제어부는 좌측 또는 우측 트랙킹(tracking) 영역을 설정 할 수 있다, 이때, 제어부는 인물이 트랙킹 영역에 진입하였을 때 미리 설정된 값만큼 좌측 또는 우측으로 카메라를 이동시키는 트랙킹 알고리즘을 사용할 수 있다. 제어부가 트랙킹 영역을 설정하였을 경우, 트랙킹 영역으로 지정되지 않은 영역은 논-트랙킹(Non-Tracking)으로 설정된다. 논-트랙킹(Non-Tracking)영역을 설정하는 이유는, 논-트랙킹 영역은 트랙킹 알고리즘을 사용하지 않는 구간으로, 빈번하게 강의자 추적 시 산만 한 환경 조성할 수 있기에 이러한 수업 저해요인을 방지하기 위함이다. 다시 돌아와서, 제어부는 인식된 인물과 카메라의 거리에 기초하여 카메라를 제어할 수 있다. 예를 들어, 인물과 카메라의 거리가 임의의 제1거리인 경우, 제어부는 카메라의 최대 줌 아웃 수행 시, 눈과 어깨 거리가 영상 높이의 미리 설정된 제1비율이 되도록 카메라의 초기 배율을 설정한다. 이때 제어부는, 좌측 또는 우측 트랙킹 영역을 영상 좌우 양 끝단에서 인물의 어깨길이의 미리 설정된 제 2비율만큼을 트랙킹 영역으로 설정한다. 또한, 제어부는 영상에서 인물의 수행 동작이 판서 동작으로 결정 되더라도 카메라가 줌인을 수행하도록 제어하지 않는다. 인물과 카메라의 거리가 제1거리보다 큰 제2거리인 경우, 제어부는 카메라의 최대 줌 아웃 수행 시, 눈과 어깨 거리가 영상 높이의 미리 설정된 제3비율이 되도록 카메라의 초기 배율을 설정한다. 이때, 제어부는, 좌측 또는 우측 트랙킹 영역을 영상 좌우 양 끝단에서 인물의 어깨길이만큼 트랙킹 영역으로 설 정한다. 한편, 제어부는, 영상에서 인물의 수행 동작이 판서 동작으로 결정된 경우 수행하는 줌인의 배율 을 초기배율에서 미리 설정된 값만큼 더 높인 배율로 설정한다. 인물과 카메라의 거리가 제2거리보다 큰 제3거리인 경우, 제어부는 카메라의 최대 줌 아웃 수행 을 한 후 줌인을 하면서 영상에서 인물이 인식되는 배율에서, 눈과 어깨 거리가 영상 높이의 미리 설정된 제4비 율이 되도록 카메라의 초기 배율을 설정할 수 있다. 이때, 제어부는 카메라의 최대 줌 아웃시 인물 인식이 되지 않아, 줌인을 하면서 인식되는 배율에서 초기 배율을 계산한다. 또한, 제어부는, 좌측 또는 우측 트랙킹 영역을 영상 좌우 양 끝단에서 인물의 어깨길이의 미리 설정된 제5비율만큼을 트랙킹 영역으 로 설정한다. 한편, 제어부는, 영상에서 인물의 수행 동작이 판서 동작으로 결정된 경우 수행 하는 줌인의 배율을 초기배율에서 미리 설정된 값만큼 더 높인 배율로 설정한다. 초기화 설정이 완료된 후, S630단계에서, 제어부는 영상에서 생성된 스켈레톤 정보를 포함한 인물의 신체 정보에 기초하여 카메라를 제어할 수 있다. 이때에도, 제어부는 AI Skeleton 기법을 사용하여 영상으 로부터 인물을 인식하고, 인식된 인물에 대하여 적어도 하나 이상의 신체 부위를 인식하고, 신체 부위의 위치와 복수의 신체 부위 사이의 연결정보를 표현하는 스켈레톤(skeleton) 정보를 생성할 수 있다. 이후, 제어부 는 검출된 신체 정보에 기초하여 인물의 판서 동작 수행 여부를 결정한다. 이때, 제어부가 검출된 신체정 보에 기초하여 인물의 판서 동작 수행 여부를 결정하는 방법은 도 3내지 도5에 설명된 방법을 사용할 수 있음은 물론이다. 또한, 제어부는, 인물의 판서 동작 수행 여부를 판단하는 조건 필터의 판별 값과 Depthwise Separable Convolution 기법의 AI 알고리즘을 활용하여 판서 동작 수행 여부를 판단할 수 있다. 이때 사용되는 빅데이터 딥러닝은 Depthwise Separable Convolution 기법의 mobile net v1 알고리즘일 수 있다. 이를 통해, 기존 CNN 대비 구조 간결성으로 인한 파라미터량과 연산량을 감소시킬 수 있다. 제어부는 판서 동작 수행 여부에 대 한 판별 값을 도출하고, 판서 동작으로 판정된 경우를 학습하고, 이와 같은 학습을 통하여 새롭게 인식된 인물 의 신체 정보에 대해 판서 동작인지 여부를 판정할 수 있다. 또한, 조건 필터 관련하여, 상술된 판서 동작 수행 여부 결정방법을 사용함은 물론이다. 구체적으로, 조건 필터 는 도출된 코의 위치에 대한 수평 성분 값과 목의 위치에 대한 x값의 차이를 기초로 인물의 응시방향을 결정하 는 조건, 결정된 인물의 응시방향이 좌측 또는 우측이고, 검출된 신체 정보에 포함된 목의 위치에 대한 y값과 팔목의 위치에 대한 y값의 차이가 미리 설정된 값 이하인 경우, 팔목의 위치에 대한 x값과 인물의 목의 위치에 대한 x값의 차이와, 코의 위치에 대한 x값과 목의 위치에 대한 x 값의 차이를 비교하여 인물의 판서 동작 수행 여부를 결정하는 조건 및 검출된 신체 정보에 포함된, 인물이 정면을 응시할 때의 어깨 넓이와 인물이 회전할 때 영상에서 나타나는 어깨 넓이를 기초로 인물의 판서 동작 수행 여부를 결정하는 조건일 수 있다. S630단계에서 판서 동작으로 결정된 경우 S631단계로 진행하여, 제어부는 카메라가 초기화 단계에서 인식된 인물과 카메라의 거리에 따라 설정된 배율로 줌인을 수행하도록 한다. S630단계에서 판서 동작으로 결정되지 않은 경우 S633단계로 진행하여, 제어부는 카메라가 줌아웃을 수행하도록 한다. 또한, 명세서에 기재된 \"…부\", \"…모듈\"의 용어는 적어도 하나의 기능이나 동작을 처리하는 단위를 의미하며, 이는 하드웨어나 소프트웨어 또는 하드웨어 및 소프트웨어의 결합으로 구현될 수 있다. 이상의 실시예들에서 사용되는 '~부'라는 용어는 소프트웨어 또는 FPGA(field programmable gate array) 또는 ASIC 와 같은 하드웨어 구성요소를 의미하며, '~부'는 어떤 역할들을 수행한다. 그렇지만 '~부'는 소프트웨어 또는 하드웨어에 한정되는 의미는 아니다. '~부'는 어드레싱할 수 있는 저장 매체에 있도록 구성될 수도 있고 하나 또는 그 이상의 프로세서들을 재생시키도록 구성될 수도 있다. 따라서, 일 예로서 '~부'는 소프트웨어 구 성요소들, 객체지향 소프트웨어 구성요소들, 클래스 구성요소들 및 태스크 구성요소들과 같은 구성요소들과, 프 로세스들, 함수들, 속성들, 프로시저들, 서브루틴들, 프로그램특허 코드의 세그먼트들, 드라이버들, 펌웨어, 마 이크로코드, 회로, 데이터, 데이터베이스, 데이터 구조들, 테이블들, 어레이들, 및 변수들을 포함한다. 구성요소들과 '~부'들 안에서 제공되는 기능은 더 작은 수의 구성요소들 및 '~부'들로 결합되거나 추가적인 구 성요소들과 '~부'들로부터 분리될 수 있다. 뿐만 아니라, 구성요소들 및 '~부'들은 디바이스 또는 보안 멀티미디어카드 내의 하나 또는 그 이상의 CPU 들을 재생시키도록 구현될 수도 있다. 도 2 내지 도 5를 통해 설명된 실시예들에 따른 판서동작을 인식하는 방법은 컴퓨터에 의해 실행 가능한 명령어 및 데이터를 저장하는, 컴퓨터로 판독 가능한 매체의 형태로도 구현될 수 있다. 이때, 명령어 및 데이터는 프로그램 코드의 형태로 저장될 수 있으며, 프로세서에 의해 실행되었을 때, 소정의 프로그램 모듈을 생성하여 소정 의 동작을 수행할 수 있다. 또한, 컴퓨터로 판독 가능한 매체는 컴퓨터에 의해 액세스될 수 있는 임의의 가용 매체일 수 있고, 휘발성 및 비휘발성 매체, 분리형 및 비분리형 매체를 모두 포함한다. 또한, 컴퓨터로 판독 가 능한 매체는 컴퓨터 기록 매체일 수 있는데, 컴퓨터 기록 매체는 컴퓨터 판독 가능 명령어, 데이터 구조, 프로 그램 모듈 또는 기타 데이터와 같은 정보의 저장을 위한 임의의 방법 또는 기술로 구현된 휘발성 및 비휘발성, 분리형 및 비분리형 매체를 모두 포함할 수 있다. 예를 들어, 컴퓨터 기록 매체는 HDD 및 SSD 등과 같은 마그네 틱 저장 매체, CD, DVD 및 블루레이 디스크 등과 같은 광학적 기록 매체, 또는 네트워크를 통해 접근 가능한 서 버에 포함되는 메모리일 수 있다. 또한 도 2 내지 도 5를 통해 설명된 실시예들에 따른 판서동작을 인식하는 방법은 컴퓨터에 의해 실행 가능한 명령어를 포함하는 컴퓨터 프로그램(또는 컴퓨터 프로그램 제품)으로 구현될 수도 있다. 컴퓨터 프로그램은 프 로세서에 의해 처리되는 프로그래밍 가능한 기계 명령어를 포함하고, 고레벨 프로그래밍 언어(High-level Programming Language), 객체 지향 프로그래밍 언어(Object-oriented Programming Language), 어셈블리 언어 또는 기계 언어 등으로 구현될 수 있다. 또한 컴퓨터 프로그램은 유형의 컴퓨터 판독가능 기록매체(예를 들어, 메모리, 하드디스크, 자기/광학 매체 또는 SSD(Solid-State Drive) 등)에 기록될 수 있다. 따라서 도 2 내지 도5를 통해 설명된 실시예들에 따른 판서동작을 인식하는 방법은 상술한 바와 같은 컴퓨터 프 로그램이 컴퓨팅 장치에 의해 실행됨으로써 구현될 수 있다. 컴퓨팅 장치는 프로세서와, 메모리와, 저장 장치와, 메모리 및 고속 확장포트에 접속하고 있는 고속 인터페이스와, 저속 버스와 저장 장치에 접속하고 있는 저속 인터페이스 중 적어도 일부를 포함할 수 있다. 이러한 성분들 각각은 다양한 버스를 이용하여 서로 접속되 어 있으며, 공통 머더보드에 탑재되거나 다른 적절한 방식으로 장착될 수 있다. 여기서 프로세서는 컴퓨팅 장치 내에서 명령어를 처리할 수 있는데, 이런 명령어로는, 예컨대 고속 인터페이스 에 접속된 디스플레이처럼 외부 입력, 출력 장치상에 GUI(Graphic User Interface)를 제공하기 위한 그래픽 정 보를 표시하기 위해 메모리나 저장 장치에 저장된 명령어를 들 수 있다. 다른 실시예로서, 다수의 프로세서 및 (또는) 다수의 버스가 적절히 다수의 메모리 및 메모리 형태와 함께 이용될 수 있다. 또한 프로세서는 독립적인 다수의 아날로그 및(또는) 디지털 프로세서를 포함하는 칩들이 이루는 칩셋으로 구현될 수 있다. 또한 메모리는 컴퓨팅 장치 내에서 정보를 저장한다. 일례로, 메모리는 휘발성 메모리 유닛 또는 그들의 집합으 로 구성될 수 있다. 다른 예로, 메모리는 비휘발성 메모리 유닛 또는 그들의 집합으로 구성될 수 있다. 또한 메 모리는 예컨대, 자기 혹은 광 디스크와 같이 다른 형태의 컴퓨터 판독 가능한 매체일 수도 있다. 그리고 저장장치는 컴퓨팅 장치에게 대용량의 저장공간을 제공할 수 있다. 저장 장치는 컴퓨터 판독 가능한 매 체이거나 이런 매체를 포함하는 구성일 수 있으며, 예를 들어 SAN(Storage Area Network) 내의 장치들이나 다른 구성도 포함할 수 있고, 플로피 디스크 장치, 하드 디스크 장치, 광 디스크 장치, 혹은 테이프 장치, 플래시 메 모리, 그와 유사한 다른 반도체 메모리 장치 혹은 장치 어레이일 수 있다."}
{"patent_id": "10-2021-0023846", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "상술된 실시예들은 예시를 위한 것이며, 상술된 실시예들이 속하는 기술분야의 통상의 지식을 가진 자는 상술된 실시예들이 갖는 기술적 사상이나 필수적인 특징을 변경하지 않고서 다른 구체적인 형태로 쉽게 변형이 가능하 다는 것을 이해할 수 있을 것이다. 그러므로 상술된 실시예들은 모든 면에서 예시적인 것이며 한정적이 아닌 것으로 이해해야만 한다. 예를 들어, 단일형으로 설명되어 있는 각 구성 요소는 분산되어 실시될 수도 있으며, 마 찬가지로 분산된 것으로 설명되어 있는 구성 요소들도 결합된 형태로 실시될 수 있다. 본 명세서를 통해 보호받고자 하는 범위는 상기 상세한 설명보다는 후술하는 특허청구범위에 의하여 나타내어지 며, 특허청구범위의 의미 및 범위 그리고 그 균등 개념으로부터 도출되는 모든 변경 또는 변형된 형태를 포함하 는 것으로 해석되어야 한다."}
{"patent_id": "10-2021-0023846", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 일 실시예에 따른 영상으로부터 판서동작인식 장치를 설명하기 위한 일 예시도이다. 도 2는 일 실시예에 따른 영상으로부터 판서 동작을 인식하는 방법을 설명하기 위한 순서도이다. 도 3은 인물의 코의 위치와 목의 위치 정보가 포함된 영상을 나타낸 도면이다. 도 4는 인물의 코의 위치, 목의 위치 및 팔목의 위치 정보가 포함된 영상을 나타낸 도면이다. 도 5는 인물의 판서 동작 수행 여부를 결정하는 방법을 설명하기 위한 예시도이다. 도 6은 일 실시예에 따른 영상으로부터 판서 동작을 인식하는 방법을 설명하기 위한 순서도이다."}
