{"patent_id": "10-2017-0022051", "section": "특허_기본정보", "subsection": "특허정보", "content": {"공개번호": "10-2018-0084576", "출원번호": "10-2017-0022051", "발명의 명칭": "행동-인식 연결 학습 기반 의도 이해 장치, 방법 및 그 방법을 수행하기 위한 기록 매체", "출원인": "경북대학교 산학협력단", "발명자": "이민호"}}
{"patent_id": "10-2017-0022051", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_1", "content": "매 프레임마다 관측되는 사용자 행동의 관절 정보 및 사용자 주변 환경의 객체 정보를 검출하는 입력부;상기 입력부로부터 수신한 상기 관절 정보 및 상기 객체 정보를 인공 신경망 처리가 가능하도록 전처리하는 전처리부;상기 전처리부에서 출력된 상기 관절 정보 및 상기 객체 정보를 기초로, 사용자의 행동 정보를 분류하는 행동인식 처리부;상기 전처리부에서 출력된 객체 정보 및 상기 행동 인식 처리부에서 출력된 행동 정보를 이용하여, 사용자의 행동과 관련된 객체 후보군을 출력하는 객체 관계 정보 처리부; 및상기 행동 인식 처리부에서 출력된 행동 정보 및 상기 객체 관계 정보 처리부에서 출력된 객체 후보군을 입력으로 하는 인공 신경망을 통해 사용자 의도 인식 결과를 출력하는 의도 출력부를 포함하는, 행동-인식 연결 학습기반 의도 이해 장치."}
{"patent_id": "10-2017-0022051", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_2", "content": "제1항에 있어서, 상기 입력부는,가시광선대 영상 센서 및 능동적 적외선 패턴 투사 센서 중 적어도 하나의 정보를 바탕으로, 사용자의 주요 관절의 이차원 또는 삼차원 위치 정보를 실시간으로 수집하는, 행동-인식 연결 학습 기반 의도 이해 장치."}
{"patent_id": "10-2017-0022051", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_3", "content": "제2항에 있어서, 상기 입력부는,감지 영역 내에 사용자가 다수일 경우, 각 사용자의 행동 모델링 정보의 간섭을 피하기 위해 얼굴 인식 또는 추적 기능 중 적어도 하나를 수행하는, 행동-인식 연결 학습 기반 의도 이해 장치."}
{"patent_id": "10-2017-0022051", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_4", "content": "제1항에 있어서, 상기 전처리부는,상기 입력부로부터 수신한 상기 관절 정보를 정규화 및 부호화하여 상기 행동 인식 처리부로 전달하는 관절 정보 전처리부; 및상기 입력부로부터 수신한 영상 정보로부터 상기 객체 정보를 추출하고, 사용자가 손으로 집은 객체의 레이블을상기 객체 관계 정보 처리부로 전달하는 객체 정보 전처리부를 포함하는, 행동-인식 연결 학습 기반 의도 이해장치."}
{"patent_id": "10-2017-0022051", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_5", "content": "제4항에 있어서, 상기 관절 정보 전처리부는,상기 입력부의 감지 영역 내에서 획득되는 절대 좌표 기반의 주요 관절 정보를 사용자 별 상대 좌표 표현으로정규화하는 정규화부; 및정규화된 상대 좌표 표현을 신경망 친화적인 방식으로 표현하는 부호화부를 포함하는, 행동-인식 연결 학습 기공개특허 10-2018-0084576-3-반 의도 이해 장치."}
{"patent_id": "10-2017-0022051", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_6", "content": "제5항에 있어서, 상기 부호화부는,자가 생성 맵(SOM; self-organizing map)을 사용하는, 행동-인식 연결 학습 기반 의도 이해 장치."}
{"patent_id": "10-2017-0022051", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_7", "content": "제1항에 있어서, 상기 행동 인식 처리부는,상기 전처리부에서 출력된 상기 관절 정보 및 상기 객체 정보를 회귀 신경망을 통해 모델링하여, 행동 인식이가능하도록 인식 전용 노드를 지정하는, 행동-인식 연결 학습 기반 의도 이해 장치."}
{"patent_id": "10-2017-0022051", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_8", "content": "제7항에 있어서, 상기 행동 인식 처리부는,실시간 처리 단계 및 시험 단계에서 주어진 입력에 대응하여 출력되는 인식 전용 노드를 학습할 때, 사용자 행동 벡터들과 비교하여 가장 가까운 행동을 추출하는, 행동-인식 연결 학습 기반 의도 이해 장치."}
{"patent_id": "10-2017-0022051", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_9", "content": "제1항에 있어서, 상기 객체 관계 정보 처리부는,상기 전처리부에서 출력된 객체 정보 및 상기 행동 인식 처리부에서 출력된 행동 정보를 자가 부호화망을 통해객체 관계를 모델링하여, 객체 자가 부호화 결과를 출력하는, 행동-인식 연결 학습 기반 의도 이해 장치."}
{"patent_id": "10-2017-0022051", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_10", "content": "제1항에 있어서,상기 사용자 행동의 관절 정보는, 척추 중반, 목, 머리, 어깨 왼쪽, 팔꿈치 왼쪽, 손목 왼쪽, 어깨 오른쪽, 팔꿈치 오른쪽, 손목 오른쪽, 엉덩이 왼쪽, 엉덩이 오른쪽 및 어깨(Spine Shoulder) 중 적어도 하나의 골격점이사용되는, 행동-인식 연결 학습 기반 의도 이해 장치."}
{"patent_id": "10-2017-0022051", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_11", "content": "매 프레임마다 관측되는 사용자 행동의 관절 정보 및 사용자 주변 환경의 객체 정보를 검출하는 단계;상기 관절 정보 및 상기 객체 정보를 인공 신경망 처리가 가능하도록 전처리하는 전처리 단계;상기 전처리 단계에서 출력된 상기 관절 정보 및 상기 객체 정보를 기초로, 사용자의 행동 정보를 분류하는 행동 인식 처리 단계;상기 전처리 단계에서 출력된 객체 정보 및 상기 행동 인식 처리 단계에서 출력된 행동 정보를 이용하여, 사용자의 행동과 관련된 객체 후보군을 출력하는 객체 관계 정보 처리 단계; 및상기 행동 인식 처리 단계에서 출력된 행동 정보 및 상기 객체 관계 정보 처리 단계에서 출력된 객체 후보군을입력으로 하는 인공 신경망을 통해 사용자 의도 인식 결과를 출력하는 의도 출력 단계를 포함하는, 행동-인식연결 학습 기반 의도 이해 방법.공개특허 10-2018-0084576-4-청구항 12 제11항에 있어서, 상기 사용자 주변 환경의 객체 정보를 검출하는 단계는,가시광선대 영상 센서 및 능동적 적외선 패턴 투사 센서 중 적어도 하나의 정보를 바탕으로, 사용자의 주요 관절의 이차원 또는 삼차원 위치 정보를 실시간으로 수집하는, 행동-인식 연결 학습 기반 의도 이해 방법."}
{"patent_id": "10-2017-0022051", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_13", "content": "제12항에 있어서, 상기 사용자 주변 환경의 객체 정보를 검출하는 단계는,감지 영역 내에 사용자가 다수일 경우, 각 사용자의 행동 모델링 정보의 간섭을 피하기 위해 얼굴 인식 또는 추적 기능 중 적어도 하나를 수행하는, 행동-인식 연결 학습 기반 의도 이해 방법."}
{"patent_id": "10-2017-0022051", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_14", "content": "제11항에 있어서, 상기 전처리 단계는,감지 영역 내에서 획득되는 절대 좌표 기반의 주요 관절 정보를 사용자 별 상대 좌표 표현으로 정규화하는단계; 및정규화된 상대 좌표 표현을 신경망 친화적인 방식으로 표현하는 부호화 단계를 포함하는, 행동-인식 연결 학습기반 의도 이해 방법."}
{"patent_id": "10-2017-0022051", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_15", "content": "제14항에 있어서, 상기 부호화 단계는,자가 생성 맵(SOM; self-organizing map)을 사용하는, 행동-인식 연결 학습 기반 의도 이해 방법."}
{"patent_id": "10-2017-0022051", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_16", "content": "제11항에 있어서, 상기 전처리 단계는,수신한 영상 정보로부터 상기 객체 정보를 추출하고, 사용자가 손으로 집은 객체의 레이블을 송신하는, 행동-인식 연결 학습 기반 의도 이해 방법."}
{"patent_id": "10-2017-0022051", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_17", "content": "제11항에 있어서, 상기 행동 인식 처리 단계는,상기 전처리 단계에서 출력된 상기 관절 정보 및 상기 객체 정보를 회귀 신경망을 통해 모델링하여, 행동 인식이 가능하도록 인식 전용 노드를 지정하는, 행동-인식 연결 학습 기반 의도 이해 방법."}
{"patent_id": "10-2017-0022051", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_18", "content": "제17항에 있어서, 상기 행동 인식 처리 단계는,실시간 처리 단계 및 시험 단계에서 주어진 입력에 대응하여 출력되는 인식 전용 노드를 학습할 때, 사용자 행동 벡터들과 비교하여 가장 가까운 행동을 추출하는, 행동-인식 연결 학습 기반 의도 이해 방법.공개특허 10-2018-0084576-5-청구항 19 제11항에 있어서, 상기 객체 관계 정보 처리 단계는,상기 전처리부에서 출력된 객체 정보 및 상기 행동 인식 처리부에서 출력된 행동 정보를 자가 부호화망을 통해객체 관계를 모델링하여, 객체 자가 부호화 결과를 출력하는, 행동-인식 연결 학습 기반 의도 이해 방법."}
{"patent_id": "10-2017-0022051", "section": "청구범위", "subsection": "청구항", "claim_number": "청구항_20", "content": "제11항 내지 제19항 중 어느 하나의 항에 따른 행동-인식 연결 학습 기반 의도 이해 방법을 수행하기 위한, 컴퓨터 프로그램이 기록된 컴퓨터로 판독 가능한 기록 매체."}
{"patent_id": "10-2017-0022051", "section": "발명의_설명", "subsection": "요약", "paragraph": 1, "content": "행동-인식 연결 학습 기반 의도 이해 장치는, 매 프레임마다 관측되는 사용자 행동의 관절 정보 및 사용자 주변 환경의 객체 정보를 검출하는 입력부; 상기 입력부로부터 수신한 상기 관절 정보 및 상기 객체 정보를 인공 신경 망 처리가 가능하도록 전처리하는 전처리부; 상기 전처리부에서 출력된 상기 관절 정보 및 상기 객체 정보를 기 초로, 사용자의 행동 정보를 분류하는 행동 인식 처리부; 상기 전처리부에서 출력된 객체 정보 및 상기 행동 인 식 처리부에서 출력된 행동 정보를 이용하여, 사용자의 행동과 관련된 객체 후보군을 출력하는 객체 관계 정보 처리부; 및 상기 행동 인식 처리부에서 출력된 행동 정보 및 상기 객체 관계 정보 처리부에서 출력된 객체 후보 군을 입력으로 하는 인공 신경망을 통해 사용자 의도 인식 결과를 출력하는 의도 출력부를 포함한다. 이에 따라, 사용자 행동과, 그 행동에 관계된 객체 정보로부터 사용자의 의도를 정확하게 예측 가능하다."}
{"patent_id": "10-2017-0022051", "section": "발명의_설명", "subsection": "기술분야", "paragraph": 1, "content": "본 발명은 행동-인식 연결 학습 기반 의도 이해 장치, 방법 및 그 방법을 수행하기 위한 기록 매체에 관한 것으 로서, 더욱 상세하게는 사용자 행동과, 그에 관계된 객체 정보로부터 사용자의 의도를 예측하는 장치에 관한 것 이다."}
{"patent_id": "10-2017-0022051", "section": "발명의_설명", "subsection": "배경기술", "paragraph": 1, "content": "최근 IT 기술의 발달로 사용자 행동에 기반한 자연스러운 인터페이스 설계, 스마트 홈 기반 생활 관련 정보 획 득, 헬스 케어에서의 사용자 건강, 상태, 운동 관리 등 많은 서비스들이 기획되고 있으나 아직 실시간 환경에서 사용자 행동과 주변 객체간의 상호작용을 바탕으로 한 신뢰성 있는 의도 파악을 보장하지 못하여 제품 실시로 이어지기가 힘든 경우가 많다. 의도 이해는 인간에게 다양한 서비스를 제공할 수 있는 로봇과 같은 인공 지능 에이전트를 개발하는데 중요하다. 지난 수년간 인공 에이전트의 개발에 상당한 진전을 보았으나 아직 감정 또는 의도 인식과 같은 인지 의 기본 요소 중 일부를 구현하는 것과는 거리가 멀다. 이들은 자연적으로 인간에게 속하고, 인간과 인간의 상 호 작용을 독특하게 만드는 정신 능력의 일부이다. 특히, 다른 사람들의 의도를 이해하는 능력, 즉 \"공감(empathy)\"은 인간과 인간의 의사 소통의 기본이라고 주장 되어 왔다. Theory of Mind(Premack & Woodruff, 1978)는 인간은 다른 사람들의 의도를 이해하거나 다른 사람 들과 공감할 수 있는 타고난 고유의 능력을 가지고 있다고 주장한다. 인간이 일관되고 유용한 방식으로 반응할 수 있게 하는 이 능력은 또한 언어 이해, 학습 및 감정 인식과 같은 다른 인간 영역으로 확장된다. 따라서, 지능을 가진 인간과 비슷하게 행동하고 반응하는 인공 에이전트를 개발하기 위해서는 그러한 정신 능력 을 구현하는 것이 중요하고, 특히 다른 사람의 의도를 이해하는 능력이 중요하다. 그러나, 의도를 파악하기 위해서는 먼저 인간은 어떻게 이 능력을 얻는지, 감정 이입의 생리적, 생물학적 기초 또는 다른 사람의 의도를 이해하는 능력은 무엇인지, 이러한 인지 과정에서 무엇인가를 배울 수 있는지, 인공 에이전트에서 의도 인식 능력을 시뮬레이션 할 수 있는지 등의 문제를 해결하여야 한다. 현재, 인공 에이전트에서 의도를 인식하는 능력을 구현하기 위해 몇 가지 전산 모델이 제안되었다. 어떤 것들은 물체의 행동 유도성(affordance)을 기반으로 하는 반면, 다른 것들은 행동 예측에 기반을 두고 있다. 그러나, 제안된 모델들은 명시적인 제스처와 유사한 동작을 얻었지만, 동작과 관련된 객체는 고려하지 않은 한계가 있다. 선행기술문헌 특허문헌 (특허문헌 0001) KR 10-1605078 B1 (특허문헌 0002) KR 10-1592977 B1 비특허문헌 (비특허문헌 0001) Yu, Zhibin, and Minho Lee, Human motion based intent recognition using a deep dynamic neural model, Robotics and Autonomous Systems, 2015 (비특허문헌 0002) Kim, S., Kavuri, S., & Lee, M., Intention Recognition and Object Recommendation System using Deep Auto-encoder based Affordance Model, In The 1st International Conference on Human- Agent Interaction, 2013 (비특허문헌 0003) Yu, Z., & Lee, M., Real-time human action classification using a dynamic neural model, Neural Networks, 69, 29-43, 2015"}
{"patent_id": "10-2017-0022051", "section": "발명의_설명", "subsection": "해결하려는과제", "paragraph": 1, "content": "이에, 본 발명의 기술적 과제는 이러한 점에서 착안된 것으로 본 발명의 목적은 행동-인식 연결 학습 기반 의도 이해 장치를 제공하는 것이다. 본 발명의 다른 목적은 행동-인식 연결 학습 기반 의도 이해 방법을 제공하는 것이다. 본 발명의 또 다른 목적은 상기 행동-인식 연결 학습 기반 의도 이해 방법을 수행하기 위한 컴퓨터 프로그램이 기록된 기록 매체를 제공하는 것이다."}
{"patent_id": "10-2017-0022051", "section": "발명의_설명", "subsection": "과제의해결수단", "paragraph": 1, "content": "상기한 본 발명의 목적을 실현하기 위한 일 실시예에 따른 행동-인식 연결 학습 기반 의도 이해 장치는, 매 프 레임마다 관측되는 사용자 행동의 관절 정보 및 사용자 주변 환경의 객체 정보를 검출하는 입력부; 상기 입력부 로부터 수신한 상기 관절 정보 및 상기 객체 정보를 인공 신경망 처리가 가능하도록 전처리하는 전처리부; 상기 전처리부에서 출력된 상기 관절 정보 및 상기 객체 정보를 기초로, 사용자의 행동 정보를 분류하는 행동 인식 처리부; 상기 전처리부에서 출력된 객체 정보 및 상기 행동 인식 처리부에서 출력된 행동 정보를 이용하여, 사 용자의 행동과 관련된 객체 후보군을 출력하는 객체 관계 정보 처리부; 및 상기 행동 인식 처리부에서 출력된 행동 정보 및 상기 객체 관계 정보 처리부에서 출력된 객체 후보군을 입력으로 하는 인공 신경망을 통해 사용자 의도 인식 결과를 출력하는 의도 출력부를 포함한다. 본 발명의 실시예에서, 상기 입력부는, 가시광선대 영상 센서 및 능동적 적외선 패턴 투사 센서 중 적어도 하나 의 정보를 바탕으로, 사용자의 주요 관절의 이차원 또는 삼차원 위치 정보를 실시간으로 수집할 수 있다. 본 발명의 실시예에서, 상기 입력부는, 감지 영역 내에 사용자가 다수일 경우, 각 사용자의 행동 모델링 정보의 간섭을 피하기 위해 얼굴 인식 또는 추적 기능 중 적어도 하나를 수행할 수 있다. 본 발명의 실시예에서, 상기 전처리부는, 상기 입력부로부터 수신한 상기 관절 정보를 정규화 및 부호화하여 상 기 행동 인식 처리부로 전달하는 관절 정보 전처리부; 및 상기 입력부로부터 수신한 영상 정보로부터 상기 객체 정보를 추출하고, 사용자가 손으로 집은 객체의 레이블을 상기 객체 관계 정보 처리부로 전달하는 객체 정보 전 처리부를 포함할 수 있다. 본 발명의 실시예에서, 상기 관절 정보 전처리부는, 상기 입력부의 감지 영역 내에서 획득되는 절대 좌표 기반 의 주요 관절 정보를 사용자 별 상대 좌표 표현으로 정규화하는 정규화부; 및 정규화된 상대 좌표 표현을 신경 망 친화적인 방식으로 표현하는 부호화부를 포함할 수 있다. 본 발명의 실시예에서, 상기 부호화부는, 자가 생성 맵(SOM; self-organizing map)을 사용할 수 있다. 본 발명의 실시예에서, 상기 행동 인식 처리부는, 상기 전처리부에서 출력된 상기 관절 정보 및 상기 객체 정보 를 회귀 신경망을 통해 모델링하여, 행동 인식이 가능하도록 인식 전용 노드를 지정할 수 있다.본 발명의 실시예에서, 상기 행동 인식 처리부는, 실시간 처리 단계 및 시험 단계에서 주어진 입력에 대응하여 출력되는 인식 전용 노드를 학습할 때, 사용자 행동 벡터들과 비교하여 가장 가까운 행동을 추출할 수 있다. 본 발명의 실시예에서, 상기 객체 관계 정보 처리부는, 상기 전처리부에서 출력된 객체 정보 및 상기 행동 인식 처리부에서 출력된 행동 정보를 자가 부호화망을 통해 객체 관계를 모델링하여, 객체 자가 부호화 결과를 출력 할 수 있다. 본 발명의 실시예에서, 상기 사용자 행동의 관절 정보는, 척추 중반, 목, 머리, 어깨 왼쪽, 팔꿈치 왼쪽, 손목 왼쪽, 어깨 오른쪽, 팔꿈치 오른쪽, 손목 오른쪽, 엉덩이 왼쪽, 엉덩이 오른쪽 및 어깨(Spine Shoulder) 중 적 어도 하나의 골격점이 사용될 수 있다. 상기한 본 발명의 다른 목적을 실현하기 위한 일 실시예에 따른 행동-인식 연결 학습 기반 의도 이해 방법은, 매 프레임마다 관측되는 사용자 행동의 관절 정보 및 사용자 주변 환경의 객체 정보를 검출하는 단계; 상기 관 절 정보 및 상기 객체 정보를 인공 신경망 처리가 가능하도록 전처리하는 전처리 단계; 상기 전처리 단계에서 출력된 상기 관절 정보 및 상기 객체 정보를 기초로, 사용자의 행동 정보를 분류하는 행동 인식 처리 단계; 상 기 전처리 단계에서 출력된 객체 정보 및 상기 행동 인식 처리 단계에서 출력된 행동 정보를 이용하여, 사용자 의 행동과 관련된 객체 후보군을 출력하는 객체 관계 정보 처리 단계; 및 상기 행동 인식 처리 단계에서 출력된 행동 정보 및 상기 객체 관계 정보 처리 단계에서 출력된 객체 후보군을 입력으로 하는 인공 신경망을 통해 사 용자 의도 인식 결과를 출력하는 의도 출력 단계를 포함한다. 본 발명의 실시예에서, 상기 사용자 주변 환경의 객체 정보를 검출하는 단계는, 가시광선대 영상 센서 및 능동 적 적외선 패턴 투사 센서 중 적어도 하나의 정보를 바탕으로, 사용자의 주요 관절의 이차원 또는 삼차원 위치 정보를 실시간으로 수집할 수 있다. 본 발명의 실시예에서, 상기 사용자 주변 환경의 객체 정보를 검출하는 단계는, 감지 영역 내에 사용자가 다수 일 경우, 각 사용자의 행동 모델링 정보의 간섭을 피하기 위해 얼굴 인식 또는 추적 기능 중 적어도 하나를 수 행할 수 있다. 본 발명의 실시예에서, 상기 전처리 단계는, 감지 영역 내에서 획득되는 절대 좌표 기반의 주요 관절 정보를 사 용자 별 상대 좌표 표현으로 정규화하는 단계; 및 정규화된 상대 좌표 표현을 신경망 친화적인 방식으로 표현하 는 부호화 단계를 포함할 수 있다. 본 발명의 실시예에서, 상기 부호화 단계는, 자가 생성 맵(SOM; self-organizing map)을 사용할 수 있다. 본 발명의 실시예에서, 상기 전처리 단계는, 수신한 영상 정보로부터 상기 객체 정보를 추출하고, 사용자가 손 으로 집은 객체의 레이블을 송신할 수 있다. 본 발명의 실시예에서, 상기 행동 인식 처리 단계는, 상기 전처리 단계에서 출력된 상기 관절 정보 및 상기 객 체 정보를 회귀 신경망을 통해 모델링하여, 행동 인식이 가능하도록 인식 전용 노드를 지정할 수 있다. 본 발명의 실시예에서, 상기 행동 인식 처리 단계는, 실시간 처리 단계 및 시험 단계에서 주어진 입력에 대응 하여 출력되는 인식 전용 노드를 학습할 때, 사용자 행동 벡터들과 비교하여 가장 가까운 행동을 추출할 수 있 다. 본 발명의 실시예에서, 상기 객체 관계 정보 처리 단계는, 상기 전처리부에서 출력된 객체 정보 및 상기 행동 인식 처리부에서 출력된 행동 정보를 자가 부호화망을 통해 객체 관계를 모델링하여, 객체 자가 부호화 결과를 출력할 수 있다. 상기한 본 발명의 또 다른 목적을 실현하기 위한 일 실시예에 따른 컴퓨터로 판독 가능한 저장 매체에는, 행동- 인식 연결 학습 기반 의도 이해 방법을 수행하기 위한 컴퓨터 프로그램이 기록되어 있다."}
{"patent_id": "10-2017-0022051", "section": "발명의_설명", "subsection": "발명의효과", "paragraph": 1, "content": "이와 같은 행동-인식 연결 학습 기반 의도 이해 방법에 따르면, 기존 사용자 행동 기반 의도 인식 장치의 한계 를 극복하기 위하여 객체 인식 모델과 결합하고 적합한 학습 방법을 제안함으로써 더 높은 유연함과 정확성을 가지는 신뢰성 있는 사용자 의도 인식 장치를 제공한다. 또한, 본 발명이 제안하는 기술은 정적 성질을 가지는 객체간 관계 모델과 동적 성질을 가지는 사용자 행동 인 식 모델을 결합하여 상호 정보를 사용함으로써 성능을 획기적으로 개선할 수 있다. 나아가, 본 발명에서 제안하는 구조 및 학습 방법을 사용함으로써, 사용자 행동 인식 성능과 객체간 관계 모델 성능 모두를 향상시킬 수 있 다."}
{"patent_id": "10-2017-0022051", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 1, "content": "후술하는 본 발명에 대한 상세한 설명은, 본 발명이 실시될 수 있는 특정 실시예를 예시로서 도시하는 첨부 도 면을 참조한다. 이들 실시예는 당업자가 본 발명을 실시할 수 있기에 충분하도록 상세히 설명된다. 본 발명의 다양한 실시예는 서로 다르지만 상호 배타적일 필요는 없음이 이해되어야 한다. 예를 들어, 여기에 기재되어 있 는 특정 형상, 구조 및 특성은 일 실시예에 관련하여 본 발명의 정신 및 범위를 벗어나지 않으면서 다른 실시예 로 구현될 수 있다. 또한, 각각의 개시된 실시예 내의 개별 구성요소의 위치 또는 배치는 본 발명의 정신 및 범 위를 벗어나지 않으면서 변경될 수 있음이 이해되어야 한다. 따라서, 후술하는 상세한 설명은 한정적인 의미로 서 취하려는 것이 아니며, 본 발명의 범위는, 적절하게 설명된다면, 그 청구항들이 주장하는 것과 균등한 모든 범위와 더불어 첨부된 청구항에 의해서만 한정된다. 도면에서 유사한 참조부호는 여러 측면에 걸쳐서 동일하거 나 유사한 기능을 지칭한다. 이하, 도면들을 참조하여 본 발명의 바람직한 실시예들을 보다 상세하게 설명하기로 한다. 도 1은 본 발명의 일 실시예에 따른 행동-인식 연결 학습 기반 의도 이해 장치의 블록도이다. 본 발명에 따른 행동-인식 연결 학습 기반 의도 이해 장치(10, 이하 장치)는 기존 사용자 행동 기반 의도 인식 장치의 한계를 극복하기 위하여 객체 인식 모델과 결합하고 적합한 학습 방법을 제안함으로써, 높은 유연함과 정확성을 가지는 신뢰성 있는 사용자 의도 인식 장치를 제안한다. 먼저, 의도를 인식할 수 있는 능력을 구현하기 위해 두 가지 인지 프로세스로서, 환경에서의 객체 합리성에 대 한 인식과 인간 행동의 예측이 있다. 이 두 프로세스는 의도에 대한 암시적 및 명시적 정보를 제공하며, 다양한 수준에서 상호 작용한다. 본 발명은 인식과 행동 연결의 구현이 인공 에이전트에서 인간의 의도를 인식하는 기 능을 구현하기 위한 열쇠가 될 수 있다고 가정한다. 한편, 동적인 인간 행동에서 의도 신호를 추출하는 것과 마찬가지로, 행동 분류 문제를 관리하기 위한 다양한 동적 모델이 개발되었다. HMM은 인간 행동을 분석하고 분류하는 잘 알려진 모델이다(Gehrig, Kuehne, Woerner, & Schultz, 2009). 다른 하나는 Multiple Timescale Recurrent Neural Network(MTRNN) (Yamashita & Tani, 2008)와 같은 반복적 신경망(RNN) 기반 모델( & Stagge, 2003)이다. 이 모델은 행동 분류를 위해 슈퍼 바이저된(supervised) MTRNN(SMTRNN)으로 확장되었다(Yu & Lee, 2015). 본 발명에서 제안하는 시스템은 의도 분류를 위해 인식-행동 연결을 기반으로 독립적인 두 프로세스를 Object Augmented-SMTRNN(OA-SMTRNN)로 통합한다. 인식된 객체나 예측된 행동 순서의 합리성만을 근거로 의도를 결정하 는 것은 여러 가지 가능한 의도를 나타내기 때문에 오류가 발생할 가능성이 있다. 따라서, 특정한 의도를 정확하게 결정하기 위해서는 인식과 행동의 상호 작용을 파악해야 하며, 본 발명은 인식 과 행동이 함께 사용자 의도를 결정하는 정확성을 향상시키는 루프를 형성한다고 가정하고, 사용자 행동과, 그에 관계된 객체 정보로부터 사용자의 의도를 예측한다. 사용자 행동은 시간에 따른 사용자 신체의 움직임을 의미하며, 이를 모델링하기 위해서는 동적 신호를 다루어야 한다. 그리고 사용자의 행동 중에 사용하는 객체들은 단독으로 사용되거나 같이 사용되는 후보 객체들이 존재하 여 그를 도출할 수 있는 관계 모델링이 사용자 의도 인식에 요구된다. 본 발명은 인식-행동 연결 학습을 위한 전산 모델(Object Augmented Multiple Timescale Recurrent Neural Network; 이하, OA-SMTRN)이라는 새로 제안된 모델에서 인간의 의도를 이해하기 위한 인식-행동 연계 학습을 구 현한다. 본 발명에서 제안된 모델은 이전 연구(Kim, Kavuri, & Lee, 2013; Yu & Lee, 2015)의 확장이다. 본 발명에 따른 장치는 사용자의 주요 관절 정보 및 주변 환경 정보를 바탕으로 사용자의 현재 행동을 인식 하고, 관련 객체 및 후보군을 검출함으로써 사용자의 의도 정보를 인식한다. 도 1을 참조하면, 본 발명에 따른 장치는 입력부, 전처리부 및 처리부를 포함한다. 더욱 상 세하게, 상기 전처리부는 관절 정보 전처리부 및 객체 정보 전처리부를 포함하고, 상기 처리부 는 행동 인식 처리부, 객체 관계 정보 처리부 및 의도 출력부를 포함한다. 본 발명의 상기 장치는 행동-인식 연결 학습 기반 의도를 이해하기 위한 소프트웨어(애플리케이션)가 설치 되어 실행될 수 있으며, 상기 입력부, 상기 전처리부 및 상기 처리부의 구성은 상기 장치에 서 실행되는 상기 행동-인식 연결 학습 기반 의도를 이해하기 위한 소프트웨어에 의해 제어될 수 있다. 상기 장치는 별도의 단말이거나 또는 단말의 일부 모듈일 수 있다. 또한, 상기 입력부, 상기 전처리부 및 상기 처리부의 구성은 통합 모듈로 형성되거나, 하나 이상의 모듈로 이루어질 수 있다. 그러나, 이와 반대로 각 구성은 별도의 모듈로 이루어질 수도 있다. 상기 장치는 이동성을 갖거나 고정될 수 있다. 상기 장치는, 서버(server) 또는 엔진(engine) 형태일 수 있으며, 디바이스(device), 기구(apparatus), 단말(terminal), UE(user equipment), MS(mobile station), 무선기기(wireless device), 휴대기기(handheld device) 등 다른 용어로 불릴 수 있다. 상기 장치는 운영체제(Operation System; OS), 즉 시스템을 기반으로 다양한 소프트웨어를 실행하거나 제작 할 수 있다. 상기 운영체제는 소프트웨어가 장치의 하드웨어를 사용할 수 있도록 하기 위한 시스템 프로그램으 로서, 안드로이드 OS, iOS, 윈도우 모바일 OS, 바다 OS, 심비안 OS, 블랙베리 OS 등 모바일 컴퓨터 운영체제 및 윈도우 계열, 리눅스 계열, 유닉스 계열, MAC, AIX, HP-UX 등 컴퓨터 운영체제를 모두 포함할 수 있다. 상기 입력부는 매 프레임마다 관측되는 사용자 행동의 관절 정보 및 사용자 주변 환경의 객체 정보를 검출 하여, 상기 전처리부로 전달한다. 상기 입력부는 가시광선대 영상 센서 및 능동적 적외선 패턴 투사 센서 중 적어도 하나의 정보를 바탕으로, 사용자의 주요 관절의 이차원 또는 삼차원 위치 정보를 실시간으로 수 집할 수 있다. 만약, 상기 입력부는 감지 영역 내에 사용자가 다수일 경우, 각 사용자의 행동 모델링 정보의 간섭을 피하 기 위해 얼굴 인식 또는 추적 기능 중 적어도 하나를 수행할 수 있다. 상기 사용자 행동의 관절 정보는, 척추 중반, 목, 머리, 어깨 왼쪽, 팔꿈치 왼쪽, 손목 왼쪽, 어깨 오른쪽, 팔 꿈치 오른쪽, 손목 오른쪽, 엉덩이 왼쪽, 엉덩이 오른쪽 및 어깨(Spine Shoulder) 등의 골격점이 사용될 수 있 다. 또한, 상기 입력부는 사용자의 주변 객체 정보를 파악하기 위하여 가시광선대 영상 센서 정보를 바탕으로 사용자 주변 객체 정보를 실시간으로 검출하여 수집한다. 다른 실시예로 상기 입력부는 사용자의 주요 관절 위치 정보를 파악하기 위한 입력부와 사용자의 주변 객 체 정보를 파악하기 위한 입력부가 별도로 구비될 수 있다. 상기 전처리부는 상기 입력부로부터 수신한 상기 관절 정보를 정규화 및 부호화하여 상기 행동 인식 처리부로 전달하는 관절 정보 전처리부 및 상기 입력부로부터 수신한 영상 정보로부터 상기 객 체 정보를 추출하고, 사용자가 손으로 집은 객체의 레이블을 상기 객체 관계 정보 처리부로 전달하는 객체 정보 전처리부를 포함한다. 상기 관절 정보 전처리부는 상기 입력부의 감지 영역 내에서 획득되는 절대 좌표 기반의 주요 관절 정보를 사용자 별 상대 좌표 표현으로 정규화하는 정규화부 및 정규화된 상대 좌표 표현을 신경망 친화적인 방식으로 표현하는 부호화부를 포함할 수 있다. 상기 부호화부는 자가 생성 맵(SOM; self-organizing map) 등을 사용할 수 있다. 상기 처리부는 상기 전처리부에서 전처리되어 출력된 상기 관절 정보 및 상기 객체 정보를 기초로, 사용자의 행동 정보를 분류하는 행동 인식 처리부, 상기 전처리부에서 전처리되어 출력된 객체 정보 및 상기 행동 인식 처리부에서 출력된 행동 정보를 이용하여, 사용자의 행동과 관련된 객체 후보군을 출력하는 객체 관계 정보 처리부 및 상기 행동 인식 처리부에서 출력된 행동 정보 및 상기 객체 관계 정보 처 리부에서 출력된 객체 후보군을 입력으로 하는 인공 신경망을 통해 사용자 의도 인식 결과를 출력하는 의 도 출력부를 포함한다. 상기 행동 인식 처리부는, 전처리된 정보를 바탕으로 회귀 신경망을 통해 지속적으로 행동을 인식한다. 구 체적으로, 상기 전처리부에서 출력된 상기 관절 정보 및 상기 객체 정보를 회귀 신경망을 통해 모델링하여, 행동 인식이 가능하도록 인식 전용 노드를 지정한다. 상기 행동 인식 처리부는, 실시간 처리 단계 및 시험 단계에서 주어진 입력에 대응하여 출력되는 인식 전용 노드를 학습할 때, 사용자 행동 벡터들과 비교하여 가장 가까운 행동을 추출한다. 상기 객체 관계 정보 처리부는, 전처리된 정보를 바탕으로 객체관계 모델을 통해 지속적으로 관련 후보 객 체를 도출한다. 구체적으로, 상기 전처리부에서 출력된 객체 정보 및 상기 행동 인식 처리부에서 출 력된 행동 정보를 자가 부호화망을 통해 객체 관계를 모델링하여, 객체 자가 부호화 결과를 출력한다. 상기 의도 출력부는 행동 인식 처리부 및 객체 관계 정보 처리부의 결과를 종합하여 사용자 의 도 정보를 출력한다. 즉, 행동 인식 처리부 및 객체 관계 정보 처리부의 출력을 입력으로 하는 인공 신경망 혹은 회귀 신경망으로, 행동 및 객체 관계 정보를 종합하여 사용자 의도 인식 결과만을 출력한다. 상기 처리부는 본 발명에서 Object Augmented-SMTRNN(이하, OA-SMTRNN) 모델로 구현되며, 이하에서 자세 히 설명한다. 도 2는 본 발명에서 제안한 의도 인식을 위한 OA-SMTRN 모델을 나타내는 도면이다. 도 2의 오른쪽은 심층 자동 인코더(deep auto-encoder)(Hinton & Salakhutdinov, 2006)에 의해 모델화되었으며, 이는 객체의 관계 정보를 분석하는 데 사용된다. 심층 자동 인코더의 코드 계층은 가시적 계층 에서 정보를 정류하며, 의도된 사용자가 선택한 객체와 연관된 잠재적인 인간의 의도 정보를 나타낸다. 코딩된 정보는 가중치가 Wpa인 SMTRNN의 저속 컨텍스트 계층에 대한 추가 입력으로 사용된다. 도 2의 왼쪽에 도시된 SMTRNN은 특정 의도와 관련된 인간 동작의 뼈대 궤도를 분석하는데 사용된다. 나아가, 본 발명은 SMTRNN이 인간의 의도를 분류할 뿐만 아니라 현재의 행동과 관련된 물체의 선택을 예측을 시도한다. 따라서, 두 가지 분류 노드 그룹이 사람의 의도 분류와 대상 예측 모두에 대해 정의된다. 심층 자동 인코더의 코드 계층에서 얻은 추가 정보를 사용하여 SMTRNN은 비슷한 동작이지만 다른 객체를 사용하는 다양한 의도를 효 율적으로 이해할 수 있다. 또한, SMTRNN에 의해 예측된 객체는 Wap 연결을 통해 심층 자동 인코더의 숨겨진 계층에 추가의 가시적인 입력으 로 재사용될 수 있다. 심층 자동 인코더의 코드 계층의 뉴런 수를 C라고 가정한다. 심층 자동 인코더의 첫 번째 숨겨진 계층에는 H의 숨겨진 뉴런들이 포함된다. SMTRNN의 객체 예측 태스크는 객체들의 O개 유형을 포함한다. SMTRNN의 의도 분류 태스크는 I개의 의도가 있다. 그러면, Wap의 크기는 O*H가 되고, Wpa의 크기는 (S-I-O)*C로 정의된다. 여기서, S는 저속 컨텍스트 노드 번호이 다. Wpa는 회로 단락을 방지하도록 설계되었으므로, 코드 계층과 분류 출력(I 및 O) 간에 직접 연결은 없다. 도 2에서 화살표는 정보의 흐름을 나타내고, 두 모듈 사이에 있는 두 개의 화살표는 행동-인식 연결 학습을 위 한 경로를 설명한다. 도 3은 본 발명에서 제안된 모델의 간략한 실행의 흐름도이다. 도 3은 시간 인덱스 t의 기간에서 제안된 모델의 실행 흐름을 기술한다. 도 2의 OA-SMTRNN의 왼쪽과 오른쪽 부 분을 각각 행동 모듈과 인식 모듈로 부른다. 의도를 가진 사람이 시간 t에서 행동하면, 도 2의 왼쪽 모듈인 행 동 모듈이 인간 행동의 의미를 이해하려고 시도하고, 인간의 의도와 관련된 객체 레이블을 예측한다. 그 다음에, 인식 모듈인, 예측된 객체 레이블들을 갖는 심층 자동 인코더는 시간 t에서 코드 계층에서 잠재된 정보를 생성하고, 코드 계층은 저속 컨텍스트 유닛에 연결되어 인간의 의도 식별뿐만 아니라 시간 t+1에서의 다 음 객체 선택의 예측을 돕는다. 행동-인식 연결 학습을 위한 전산 모델의 보다 상세한 절차는 이하 설명한다. 본 발명에서 제안된 방법의 행동 모듈은 특정한 인간의 의도와 관련된 인간의 행동 이해에 기반한 객체 예측으 로 확장된다(Yu & Lee, 2015). 도 2의 OA-SMTRNN의 행동 모듈은 IPL 및 PMv를 모델링하기 위해 3 개의 계층을 사용하고, 상향식 모델로 간주한다. 입력-출력 계층의 입력 신호는 인간의 골격 데이터이고, 저속 컨텍스트 계 층에는 객체 행동 유동성을 위한 심층 자동 인코더의 코드 계층에 연결된 또 다른 입력 경로가 있다. 행동의 예측은 대응하는 가능한 객체를 구속하는 효과가 있다. 본 발명에서는 저속 컨텍스트 계층에 있는 특수 한 그룹의 뉴런을 행동 및 객체의 합리적인 정보에 기반한 의도 추론을 위한 분류 노드로 정의한다. 본 발명에 서는 객체 레이블 예측을 위해 저속 컨텍스트 계층에서 다른 출력 노드를 새로 정의한다. 이 모델은 인간의 현 재 행동 기반 의도에 따라 상호 작용하거나 상호 작용해야 하는 \"유형의 대상\"을 예측할 것이다. 도 4는 행동 모델링 및 의도 추론을 위한 생물학적 모델을 나타내는 도면이다. 입력-출력 계층은 행동 시퀀스를 수신하고 출력하기 위해, 자가 생성 맵(SOM; self-organizing map)에 의해 모 델링된다. SOM 알고리즘은 입력 공간의 토폴로지 특성을 보존할 수 있다. MTRNN의 주요 구성 요소인 컨텍스트 계층은 연속 시간 반복적인 신경망(CTRNN)을 사용하여 모델링된다. CTRNN은 특수 유형의 RNN이며 생물학적 신경 네트워크의 동적 시스템 모델이다. CTRNN에서 각 뉴런의 출력은 현재 입력 샘플과 신경 상태의 과거 이력을 사용하여 계산된다. 따라서, CTRNN은 연속적인 감각 운동 시퀀스를 예측하는데 적합하다. 역 전파 시간(BPTT) 알고리즘은 학습에 사용된다. 오류 함수는 Kullback-Leibler divergence를 사용하여 다음의 수학식 1과 같이 정의된다. [수학식 1]"}
{"patent_id": "10-2017-0022051", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 2, "content": "여기서, O는 입력-출력 계층의 노드이고, 는 시간 단계 t에서의 i 번째 뉴런의 원하는 출력 값이고, 는 기존의 가중치와 초기 상태에서 i번째 뉴런의 예측값이다. 로봇과 관련된 MTRNN에 대한 이전 연구에서 시각 입 력 및 모터 고유값을 포함한 포함한 두 개의 SOM 계층이 일반적이지만(Yamashita & Tani, 2008), 본 발명에서는 실제 로봇을 사용하지 않으므로, 고유값 비전(실험에서 골격 좌표) 입력을 단일 SOM 계층에 결합한다. 가중치 업데이트 규칙은 다음의 수학식 2를 통해 설명된다. [수학식 2] , 여기서, n은 반복 단계이고, α는 실험에서 0.0005로 설정된 학습률이다. 편미분 는 다음의 수학식 3과 같 이 주어진다. [수학식 3] 도 5는 행동 이해에 기반한 의도 추론 및 객체 예측을 위한 행동 모듈이다. OA-SMTRNN 모델의 행동 모듈의 상세 구조가 도 5의 입출력 계층과 고속 및 저속 컨텍스트 계층의 개념은 MTRNN 모델에서 상속된다. 시간 단계 t에서 시각 정보가 얻어지면, SOM 노드는 특징 추출에 사용된다. 입출력 계층과 저속 컨텍스트 계층은 연결되어 있지 않다. 고속 컨텍스트 계층은 입출력 및 저속 컨텍스트 계층 을 연결하는 연결부로 기능하며, 고속 및 컨텍스트 계층 내의 노드들은 완전히 연결된다. SOM 노드의 최종 출력 은 BPTT 알고리즘을 사용하여 예측 오차를 계산하는 데 사용된다. 본 발명에서 이용하는 Yu & Lee, 2015에 정의된 두뇌 모델에 따르면, 분류 노드라고 불리는 특별한 유형의 저속 컨텍스트 노드를 정의한다. 분류 노드는 저속 컨텍스트 계층의 일부이며 동일한 시간 상수 τ를 갖는다. 분류 노드와 다른 저속 컨텍스트 노드 간의 차이점은 의도 및 객체 레이블이 저속 컨텍스트 단위의 분류 노드를 학습 하는 데 사용된다는 것이다. 분류 노드는 행동 예측 오류뿐만 아니라 다른 노드에 의도 추론 및 객체 예측 오류를 역 전파해야 한다. 분류 노드를 포함한 모든 노드는 동기적으로 작동하고, 테스트 시퀀스가 주어지면 레이블에 해당하는 분류 노드가 활 성화된다. 분류 오차를 고려한 후 편미분 방정식은 아래의 수학식 4와 같이 정의된다. [수학식 4]"}
{"patent_id": "10-2017-0022051", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 3, "content": "여기에서, f'(x)는 시그모이드(Sigmoid) 함수의 도함수이고, 는 뉴런 출력과 이상 값의 차이고, 는 t 시간 단계에서 i번째 뉴런 상태이고, 는 뉴런 상태 업데이트 속도를 제어하는 상수이고, 는 크로네커 델 타(i=k라면 = 1, 그렇지 않으면 0)이다. O는 입출력 노드 집합을 나타내고, 및 는 각각 저속 컨텍스트 계층에서의 객체 예측 및 의도 분류에 사용되는 분류 노드를 나타낸다. 입력-출력 계층에서, 분류 작업이 저속 컨텍스트 계층에서 수행되는 동안 행동의 예측 신호가 생성된다. 그러나, 본 발명은 이 방정식을 객체 예측에 맞게 수정하였다. 분류에 사용된 Softmax 활성화 함수(Yu & Lee, 2015) 대신 시그모이드(Sigmoid) 함수를 사용하여 최종 출력을 계산한다. 하나의 의도에 대해 여러 객체를 사용 할 수 있도록 이 작업이 수행된다. Softmax 기능은 하나의 카테고리만 지원한다. 위에서 언급한 바와 같이, 사용자의 의도는 또한 행동 유동성(affordance)을 기반으로 추론할 수 있다. 본 발명 에서 제안된 OA-SMTRNN에서, 심층 구조화 네트워크는 고차원 관계 또는 직접 관찰할 수 없는 특징을 포착할 수 있는 능력으로 알려져 있기 때문에, 심층 학습 구조 중 하나인 심층 자동 인코더를 사용하여 행동 유동성을 모 델링한다(Kim, et al., 2013). 자동 인코더 모델은 통상적으로 인코더와 디코더의 두 부분으로 구성된다. 인코더는 원래의 입력 신호를 압축으 로 볼 수 있는 비교적 짧은 코드로 변환한다. 디코더는 인코더의 대응하며, 인코딩된 신호에서 원래 정보를 재 구성한다. 이 모델을 참조하는 이전 연구에서 자동 인코더의 입력은 행동 유동성 정보를 나타내는 벡터이다. 행 동 유동성 정보가 인코딩되고 관련 객체가 디코딩된다. 도 6은 자동 인코더의 간략도이다. 일반적으로, 자동 인코더의 작업은 정보를 불필요하게 압축하고 다시 복구하기 때문에 무의미한 것으로 간주될 수 있다. 그러나, 자동 인코더가 특정 목적을 위해 제작된 경우 자동 인코더는 신호에서 유용한 정보를 추출하 고 노이즈를 제거할 수 있다. 본 발명은 인간의 의도와 관련된 객체의 행동 유동성을 분석하고 의도된 추론을 돕기 위해 관찰된 객체로부터 의미 있는 잠재된 정보를 추출하는 자동 인코더가 필요하다. 구조가 깊기 때문에, 자동 인코더를 학습하는 것은 어렵다. 본 발명의 모델에서는 Hinton과 Salakhutdinov(Hinton & Salakhutdinov, 2006)가 제안한 방법을 사용한다. Building by Restricted Boltzmann Machine(RBM)은 계층별로 인코더 네트워크를 초기화한다. 디코더 네트워크는 인코더를 리버스한 다음 간단히 미 세 조정하여 간단하게 구축할 수 있다. 도 7은 심층 자동 인코더의 학습 과정을 보여주는 도면이다. 자동 인코더 네트워크의 미세 조정 절차에서는, 인공 신경망에 대한 강력한 학습 방법인 오류 역 전파가 사용된 다. 자동 인코더 네트워크가 구축된 후, 이 예측 모듈의 코드 계층에서 생성된 출력 벡터는 재구성을 위한 충분한 객체 행동 유동성 잠재 정보를 포함한다. 어떤 사람이 어떤 일을 할 의도가 있을 때, 그는 보통 대응하는 객체 를 사용한다. 잠재적 코드 벡터는 객체의 동시 발생에 대한 정보를 통합하는데 사용될 수 있다. 따라서, 객체 행동 유동성 정보인 코드는 관련 없는 의도에 대한 억제 효과가 있으며 관련 의도를 높인다. 최상위 계층에서 행동 유동성 코드와 관련된 객체가 재구성된다. 노이즈로 인해 원래 벡터에서 객체의 정보가 누락된 경우에도 행동 유동성 코드를 통해 디코딩 프로세스를 통해 정보를 공개할 수 있다. 이 특성은 심층 자 동 인코더 모델이 정적인 경우에도 객체의 미래 상태에 대한 예측을 산출할 수 있다. 이는 객체 선택이 순차적 으로 발생하고 현재 시간에 관찰되지 않은 누락 정보가 행동 유동성 및 디코딩에 의해 예측 될 수 있기 때문이 다. 도 8은 도 2의 OA-SMTRNN의 예측 모듈의 구조를 나타내는 도면이다. OA-SMTRNN 모델은 시각적 정보를 기반으로 관련 객체를 재구성할 수 있지만 노이즈로 인해 보이는 노드가 올바 른 정보를 얻지 못하는 경우가 있다. 이 경우 도 2의 OA-SMTRNN의 행동 모듈로부터의 예측된 객체 레이블은 이 모델이 노이즈 문제에 대해 견고성을 갖도록 도울 수 있다. 객체 레이블을 예측하는 추가 노드는 동적 바이어스로서 숨겨진 계층에 연결되고, 예측 노드와 숨겨진 계층 간 의 가중치가 학습된다. 동시에 다른 가중치는 추가작인 노드에 적합하게 조정되어 적합한 정보를 재구성한다. 상세한 인식-행동 순환 과정은 이하 설명된다. 본 발명에서 제안된 모델의 구조는 도 2에 보여진다. 도 2의 왼쪽에 도시된 행동 모듈은 의도 추론을 위해 골격 시퀀스를 분석할 수 있으며, SMTRNN을 기반으로 모델링된다. 도 2의 오른쪽에 표시된 인식 모듈은 심층 자동 인 코더를 사용하여 모델링되어 의미 있는 행동 유동성 정보를 분석하고 추출한다. 객체 레이블은 OA-SMTRNN의 액 션 모듈에 의해 예측된 다음 심층 자동 인코더로 공급된다. 위에서 언급되니 바와 같이, 저속 컨텍스트 계층에 서 행동에 관련된 객체 레이블을 예측하기 위해 새로운 그룹의 뉴런을 정의했다. OA-SMTRNN의 행동 모듈로부터의 예측 결과를 이용하여, 다음의 수학식 5와 같이 자동 인코더를 향상시킬 수 있 다. [수학식 5]"}
{"patent_id": "10-2017-0022051", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 4, "content": "여기서, 는 숨겨진 뉴런 출력이고, 는 보이는 계층과 현재 숨겨진 계층 사이의 연결이며, 는 행동 모 듈에서 인식 모듈로의 연결이고, b는 바이어스이다. 다음의 수학식 6과 같이 의 학습은 여전히 오류 역 전파 규칙을 따를 수 있다. [수학식 6] 여기서, 는 자동 인코더에서 뉴런의 시냅스 이전 값이고 는 인간 행동 이해에 기반한 객체 예측 출력의 시 냅스 이후 값이다. 그런 다음 예측된 객체 레이블은 심층 자동 인코더에 의해 구현된 인식 모듈의 상황 별 바이어스로 볼 수 있다. 그 후, 인식 모듈에 대한 새로운 입력 벡터는 다음의 수학식 7과 같다. [수학식 7]"}
{"patent_id": "10-2017-0022051", "section": "발명의_설명", "subsection": "발명을실시하기위한구체적인내용", "paragraph": 5, "content": "여기서 {,}는 벡터 연결을 의미하고, voriginal은 심층 자동 인코더의 원래 보이는 노드이며, ya는 OA-SMTRNN의 행 동 모듈로부터 객체 예측 출력이다. 의도 추론을 위한 노드와 객체의 예측 노드가 저속 컨텍스트 계층에 위치하는 동안 행동 예측 신호는 원래 행동 시퀀스만큼 빠르기 때문에 작은 시간 상수를 갖는 입력-출력 계층에서 생성된다. 행동 예측은 또한 학습에 필수 적인 역할을 한다. 이미 언급한 바와 같이, 거울 뉴런은 다른 사람들의 행동을 이해하고 모방을 통해 새로운 기 술을 습득하는데 중요하다. OA-SMTRNN의 액션 모듈에서 객체 레이블을 예측하는 방법은 심층 자동 인코더의 맨 아래 계층에 추가적인 가시 노드로 배치한다. 결과적으로, 보이는 계층에서 첫 번째 숨겨진 계층까지의 가중치가 증가한다. 따라서, 새로운 시퀀스를 얻으면 OA-SMTRNN의 작업 모듈을 사용하여 현재 및 과거 작업 시퀀스를 기반으로 가능 한 객체를 추정한다. 추가 정보는 인식 모듈이 관련 없는 객체를 제외시키고 혼동되거나 잘못된 객체 검출의 경 우 객체 레이블을 재구성하는데 도움이 될 수 있다고 가정한다. 위에서는 행동에서 인식으로의 개선에 대해 설명하였고, 이하에서는 인식에서 행동으로의 개선에 대해 설명한다. MTRNN의 기본 목표는 동적 신호를 예측하는 것이다. 따라서, MTRNN은 각 계층에서 상이한 시상수를 갖는 다수의 CTRNN 층을 포함한다. 작은 시정수(고속 컨텍스트)를 갖는 CTRNN 계층의 정보는 빠르게 변하지만, 저속 컨텍스 트 계층은 고속 컨텍스트 계층에 저장된 기본 행동 정보의 순서를 배열한다. 이전 모델에서 소개된 방법을 사용하여 행동 유동성 모델을 학습한다. 디코더 부분은 심층 자동 부호기를 학습 하는데 필요하지만 인식 모듈의 코드 계층 출력, 심층 자동 인코더는 행동 모듈의 저속 컨텍스트 계층에 대한 추가 입력으로 간주된다. 코드와 저속 컨텍스트 계층 간의 가중치는 완전히 연결된다. 코드와 저속 컨텍스트 계 층 사이의 가중치는 수학식 1의 Kullback-Leibler 발산 오차를 갖는 역 전파 규칙을 사용하여 수학식 3으로 업 데이트된다. 코드 계층에 저장된 정보는 의도와 관련이 있다(Kim, et al., 2013). 그들은 OA-SMTRNN의 다른 가중치와 함께 훈련받는다. 행동 모델에 대한 행동 유동성 모델의 정보는 도 2에서 컨텍스트 계층을 느리게 만드는 코드에서 화살표로 표시되고, 인간의 의도를 정확하게 인식하는데 필요한 기능을 풍부하게 한다. 객체 행동 유동성에 대한 인식 모듈의 정보는 이미 추상화되어 있으며, 빠르게 변하지 않는다. 인식 모듈의 코 드 계층으로부터의 출력은 저속 컨텍스트 계층에 직접 연결된다. 원래, MTRNN과 SMTRNN은 시간을 통한 잠재 상 태의 역동성을 기초로 행동 시퀀스를 예측했다. 그러나, 이러한 정보를 통합함으로써 OA-SMTRNN의 의도 분류 기 능은 통합 프레임 워크에서 골격 동역학과 객체 합리성을 동시에 고려할 수 있다. 객체 행동 유동성의 인식 모듈은 저속 컨텍스트 계층에 연결되므로, 정보는 행동 시퀀스를 예측하는 입력-출력 계층에 영향을 준다. 따라서, 인식 정보는 모듈이 관련 없는 행동을 쉽게 억제하도록 도와준다. 여러 가지 의도 가 비슷한 동적 특성을 공유한다면, 하위 계층의 행동 예측 모듈은 비슷한 출력을 제공한다. 즉, 그들의 특징은 거의 구별되지 않지만, 행동 유동성 인식 모듈의 부호화된 특징 정보는 객체 행동 유동성과 관련된 특징 차원을 삽입함으로써 데이터를 쉽게 분리 할 수 있다. 본 발명은 코드 계층에 저장된 정보가 OA-SMTRNN이 행동 시퀀스를 정확하게 예측하고 의도 추론 성능을 개선하 는데 도움이 될 것으로 기대한다. 본 발명은 정적 성질을 가지는 객체간 관계 모델과 동적 성질을 가지는 사용자 행위 인식 모델을 결합하여, 유 연함과 정확성을 가지는 신뢰성 있는 사용자 의도 인식 장치를 제공할 수 있다.도 9는 본 발명의 일 실시예에 따른 행동-인식 연결 학습 기반 의도 이해 방법의 흐름도이다. 본 실시예에 따른 행동-인식 연결 학습 기반 의도 이해 방법은, 도 1의 장치와 실질적으로 동일한 구성에서 진행될 수 있다. 따라서, 도 1의 장치와 동일한 구성요소는 동일한 도면부호를 부여하고, 반복되는 설명은 생략한다. 또한, 본 실시예에 따른 행동-인식 연결 학습 기반 의도 이해 방법은 행동-인식 연결 학습 기반 의도 이해를 수 행하기 위한 소프트웨어(애플리케이션)에 의해 실행될 수 있다. 도 9를 참조하면, 본 실시예에 따른 행동-인식 연결 학습 기반 의도 이해 방법은, 매 프레임마다 관측되는 사용 자 행동의 관절 정보 및 사용자 주변 환경의 객체 정보를 검출한다(단계 S10). 이는 가시광선대 영상 센서 및 능동적 적외선 패턴 투사 센서 중 적어도 하나의 정보를 바탕으로, 사용자의 주 요 관절의 이차원 또는 삼차원 위치 정보를 실시간으로 수집할 수 있다. 센서의 감지 영역 내에 사용자가 다수 일 경우, 각 사용자의 행동 모델링 정보의 간섭을 피하기 위해 얼굴 인식 또는 추적 기능 중 적어도 하나를 수 행할 수 있다. 상기 사용자 행동의 관절 정보는, 척추 중반, 목, 머리, 어깨 왼쪽, 팔꿈치 왼쪽, 손목 왼쪽, 어깨 오른쪽, 팔 꿈치 오른쪽, 손목 오른쪽, 엉덩이 왼쪽, 엉덩이 오른쪽 및 어깨(Spine Shoulder) 등의 골격점이 사용될 수 있 다. 또한, 사용자의 주변 객체 정보를 파악하기 위하여 가시광선대 영상 센서 정보를 바탕으로 사용자 주변 객체 정 보를 실시간으로 검출하여 수집한다. 사용자 행동의 관절 정보 및 사용자 주변 환경의 객체 정보가 검출되면, 상기 관절 정보 및 상기 객체 정보를 인공 신경망 처리가 가능하도록 전처리한다(단계 S30). 전처리 단계(단계 S30)는 상기 사용자 행동의 관절 정보를 전처리하는 과정과 상기 사용자 주변 환경의 객체 정 보를 전처리하는 과정이 별도로 수행될 수 있고, 이 경우 각 과정에서 정규화 단계 및 부호화 단계가 진행될 수 있다. 상기 사용자 행동의 관절 정보를 전처리하는 단계는 센서의 감지 영역 내에서 획득되는 절대 좌표 기반의 주요 관절 정보를 사용자 별 상대 좌표 표현으로 정규화하고, 정규화된 상대 좌표 표현을 신경망 친화적인 방식으로 표현하는 부호화할 수 있다. 예를 들어, 부호화 단계는 자가 생성 맵(SOM; self-organizing map)을 사용할 수 있다. 상기 사용자 주변 환경의 객체 정보를 전처리하는 단계는 수신한 영상 정보로부터 상기 객체 정보를 추출하고, 사용자가 손으로 집은 객체의 레이블을 송신할 수 있다. 상기 전처리 단계에서 전처리되어 출력된 상기 관절 정보 및 상기 객체 정보를 기초로, 사용자의 행동 정보를 분류하는 행동 인식 처리 단계를 수행한다(단계 S50). 상기 행동 인식 처리 단계(단계 S50)는, 상기 전처리 단계에서 출력된 상기 관절 정보 및 상기 객체 정보를 회 귀 신경망을 통해 모델링하여, 행동 인식이 가능하도록 인식 전용 노드를 지정한다. 또한, 실시간 처리 단계 및 시험 단계에서 주어진 입력에 대응하여 출력되는 인식 전용 노드를 학습할 때, 사용자 행동 벡터들과 비교하여 가장 가까운 행동을 추출한다. 상기 전처리 단계에서 전처리되어 출력된 객체 정보 및 상기 행동 인식 처리 단계에서 출력된 행동 정보를 이용 하여, 사용자의 행동과 관련된 객체 후보군을 지속적으로 출력하는 객체 관계 정보 처리 단계를 수행한다(단계 S70). 상기 전처리 단계에서 전처리되어 출력된 객체 정보 및 상기 행동 인식 처리 단계에서 출력된 행동 정보를 자가 부호화망을 통해 객체 관계를 모델링하여, 객체 자가 부호화 결과를 출력한다. 상기 행동 인식 처리 단계에서 출력된 행동 정보 및 상기 객체 관계 정보 처리 단계에서 출력된 객체 후보군을 입력으로 하는 인공 신경망을 통해 사용자 의도 인식 결과를 최종적으로 출력하는 의도 출력 단계를 수행한다 (단계 S90).즉, 상기 행동 인식 처리 단계 및 상기 객체 관계 정보 처리 단계의 출력을 입력으로 하는 인공 신경망 혹은 회 귀 신경망으로, 행동 및 객체 관계 정보를 종합하여 사용자 의도 인식 결과만을 출력한다. 이에 따라, 유연함과 정확성을 가지는 신뢰성 있는 사용자 의도 결과를 출력할 수 있고, 이를 이용하여 사람의 의도를 인식하거나 예측할 필요가 있는 모든 영역에서 핵심 기반기술로서 사용될 수 있다. 이와 같은, 행동-인식 연결 학습 기반 의도 이해 방법은 애플리케이션으로 구현되거나 다양한 컴퓨터 구성요소 를 통하여 수행될 수 있는 프로그램 명령어의 형태로 구현되어 컴퓨터 판독 가능한 기록 매체에 기록될 수 있다. 상기 컴퓨터 판독 가능한 기록 매체는 프로그램 명령어, 데이터 파일, 데이터 구조 등을 단독으로 또는 조합하여 포함할 수 있다. 상기 컴퓨터 판독 가능한 기록 매체에 기록되는 프로그램 명령어는 본 발명을 위하여 특별히 설계되고 구성된 것들이거니와 컴퓨터 소프트웨어 분야의 당업자에게 공지되어 사용 가능한 것일 수도 있다. 컴퓨터 판독 가능한 기록 매체의 예에는, 하드 디스크, 플로피 디스크 및 자기 테이프와 같은 자기 매체, CD- ROM, DVD와 같은 광기록 매체, 플롭티컬 디스크(floptical disk)와 같은 자기-광 매체(magneto-optical media), 및 ROM, RAM, 플래시 메모리 등과 같은 프로그램 명령어를 저장하고 수행하도록 특별히 구성된 하드웨 어 장치가 포함된다. 프로그램 명령어의 예에는, 컴파일러에 의해 만들어지는 것과 같은 기계어 코드뿐만 아니라 인터프리터 등을 사 용해서 컴퓨터에 의해서 실행될 수 있는 고급 언어 코드도 포함된다. 상기 하드웨어 장치는 본 발명에 따른 처 리를 수행하기 위해 하나 이상의 소프트웨어 모듈로서 작동하도록 구성될 수 있으며, 그 역도 마찬가지이다. 이상에서는 실시예들을 참조하여 설명하였지만, 해당 기술 분야의 숙련된 당업자는 하기의 특허 청구의 범위에 기재된 본 발명의 사상 및 영역으로부터 벗어나지 않는 범위 내에서 본 발명을 다양하게 수정 및 변경시킬 수 있음을 이해할 수 있을 것이다. 산업상 이용가능성 본 발명은 사람의 의도를 인식하거나 예측할 필요가 있는 모든 영역에서 핵심 기반기술로서 사용될 수 있다. 예 를 들면 스마트 홈, IoT 환경 등 수 많은 신성장형 사업에 필수적인 데이터 분석 기술로서, 다양한 산업에서의 경쟁력을 확보 할 수 있다. 이에, 본 발명은 IT 및 Human Computer Interface(HCI), 신호처리 등의 분야에 활 용 될 수 있는 핵심 원천 기술이며, 스마트홈, IoT, 헬스케어, 보안 등에 유용하게 적용될 수 있다."}
{"patent_id": "10-2017-0022051", "section": "도면", "subsection": "도면설명", "item": 1, "content": "도 1은 본 발명의 일 실시예에 따른 행동-인식 연결 학습 기반 의도 이해 장치의 블록도이다. 도 2는 본 발명에서 제안한 의도 인식을 위한 OA-SMTRN 모델을 나타내는 도면이다. 도 3은 본 발명에서 제안된 모델의 간략한 실행의 흐름도이다. 도 4는 행동 모델링 및 의도 추론을 위한 생물학적 모델을 나타내는 도면이다. 도 5는 행동 이해에 기반한 의도 추론 및 객체 예측을 위한 행동 모듈이다. 도 6은 자동 인코더의 간략도이다. 도 7은 심층 자동 인코더의 학습 과정을 보여주는 도면이다. 도 8은 도 2의 OA-SMTRNN의 예측 모듈의 구조를 나타내는 도면이다. 도 9는 본 발명의 일 실시예에 따른 행동-인식 연결 학습 기반 의도 이해 방법의 흐름도이다."}
